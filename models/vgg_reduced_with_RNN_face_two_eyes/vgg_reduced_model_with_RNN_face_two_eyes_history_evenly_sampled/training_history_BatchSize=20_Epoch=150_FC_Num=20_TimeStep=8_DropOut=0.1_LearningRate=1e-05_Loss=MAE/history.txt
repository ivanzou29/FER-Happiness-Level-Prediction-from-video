Epoch: 1| Step: 0
Training loss: 4.903682231903076
Validation loss: 5.176341610570108

Epoch: 5| Step: 1
Training loss: 5.205380439758301
Validation loss: 5.1667410583906275

Epoch: 5| Step: 2
Training loss: 5.241632461547852
Validation loss: 5.156399357703425

Epoch: 5| Step: 3
Training loss: 5.228111743927002
Validation loss: 5.146007040495514

Epoch: 5| Step: 4
Training loss: 5.469053268432617
Validation loss: 5.134511152903239

Epoch: 5| Step: 5
Training loss: 3.5248446464538574
Validation loss: 5.123014203963741

Epoch: 5| Step: 6
Training loss: 5.694728374481201
Validation loss: 5.110555941058744

Epoch: 5| Step: 7
Training loss: 4.758770942687988
Validation loss: 5.097016493479411

Epoch: 5| Step: 8
Training loss: 4.8426103591918945
Validation loss: 5.082624866116431

Epoch: 5| Step: 9
Training loss: 4.5029802322387695
Validation loss: 5.0672706839858845

Epoch: 5| Step: 10
Training loss: 4.671393871307373
Validation loss: 5.050746671615109

Epoch: 2| Step: 0
Training loss: 4.085791110992432
Validation loss: 5.03313841871036

Epoch: 5| Step: 1
Training loss: 4.106523036956787
Validation loss: 5.014139980398198

Epoch: 5| Step: 2
Training loss: 5.521238327026367
Validation loss: 4.994338435511435

Epoch: 5| Step: 3
Training loss: 5.666762351989746
Validation loss: 4.97175379209621

Epoch: 5| Step: 4
Training loss: 4.694301128387451
Validation loss: 4.948885635663104

Epoch: 5| Step: 5
Training loss: 4.718499660491943
Validation loss: 4.923778646735735

Epoch: 5| Step: 6
Training loss: 5.124122142791748
Validation loss: 4.8976699562482935

Epoch: 5| Step: 7
Training loss: 4.868330955505371
Validation loss: 4.870298231801679

Epoch: 5| Step: 8
Training loss: 4.273816108703613
Validation loss: 4.8405048001197075

Epoch: 5| Step: 9
Training loss: 5.264206886291504
Validation loss: 4.809406454845141

Epoch: 5| Step: 10
Training loss: 3.2563889026641846
Validation loss: 4.776497717826597

Epoch: 3| Step: 0
Training loss: 4.54518985748291
Validation loss: 4.74211657944546

Epoch: 5| Step: 1
Training loss: 4.279899597167969
Validation loss: 4.706029302330427

Epoch: 5| Step: 2
Training loss: 2.6487412452697754
Validation loss: 4.6705140580413165

Epoch: 5| Step: 3
Training loss: 4.464521884918213
Validation loss: 4.635116889912595

Epoch: 5| Step: 4
Training loss: 4.4864397048950195
Validation loss: 4.59790224670082

Epoch: 5| Step: 5
Training loss: 4.40380334854126
Validation loss: 4.5605159318575295

Epoch: 5| Step: 6
Training loss: 4.562984466552734
Validation loss: 4.523718859559747

Epoch: 5| Step: 7
Training loss: 4.524326801300049
Validation loss: 4.485025170028851

Epoch: 5| Step: 8
Training loss: 4.645761013031006
Validation loss: 4.449332283389184

Epoch: 5| Step: 9
Training loss: 5.360726833343506
Validation loss: 4.414209617081509

Epoch: 5| Step: 10
Training loss: 3.812784433364868
Validation loss: 4.380609673838461

Epoch: 4| Step: 0
Training loss: 3.9378650188446045
Validation loss: 4.349135275809996

Epoch: 5| Step: 1
Training loss: 4.128268718719482
Validation loss: 4.31794923351657

Epoch: 5| Step: 2
Training loss: 5.949458599090576
Validation loss: 4.288071396530316

Epoch: 5| Step: 3
Training loss: 3.4707252979278564
Validation loss: 4.255710268533358

Epoch: 5| Step: 4
Training loss: 4.566544532775879
Validation loss: 4.225251013232816

Epoch: 5| Step: 5
Training loss: 4.12368106842041
Validation loss: 4.1927815201461955

Epoch: 5| Step: 6
Training loss: 3.6324620246887207
Validation loss: 4.162308487840878

Epoch: 5| Step: 7
Training loss: 3.5715198516845703
Validation loss: 4.135234925054735

Epoch: 5| Step: 8
Training loss: 2.9041380882263184
Validation loss: 4.111391123904977

Epoch: 5| Step: 9
Training loss: 4.4145684242248535
Validation loss: 4.087758253979427

Epoch: 5| Step: 10
Training loss: 3.5375802516937256
Validation loss: 4.063205124229513

Epoch: 5| Step: 0
Training loss: 3.578929901123047
Validation loss: 4.0413161605917

Epoch: 5| Step: 1
Training loss: 4.206774711608887
Validation loss: 4.015697397211547

Epoch: 5| Step: 2
Training loss: 4.495662212371826
Validation loss: 3.9913564241060646

Epoch: 5| Step: 3
Training loss: 4.160715579986572
Validation loss: 3.9625388268501527

Epoch: 5| Step: 4
Training loss: 3.81492280960083
Validation loss: 3.933712423488658

Epoch: 5| Step: 5
Training loss: 3.7981224060058594
Validation loss: 3.90689359172698

Epoch: 5| Step: 6
Training loss: 3.9551119804382324
Validation loss: 3.8824411028174945

Epoch: 5| Step: 7
Training loss: 3.2973315715789795
Validation loss: 3.861838786832748

Epoch: 5| Step: 8
Training loss: 3.0820937156677246
Validation loss: 3.8416910274054414

Epoch: 5| Step: 9
Training loss: 3.9026901721954346
Validation loss: 3.822578340448359

Epoch: 5| Step: 10
Training loss: 3.2286007404327393
Validation loss: 3.7992711067199707

Epoch: 6| Step: 0
Training loss: 3.9551568031311035
Validation loss: 3.7766675897823867

Epoch: 5| Step: 1
Training loss: 4.924129009246826
Validation loss: 3.7545565046289915

Epoch: 5| Step: 2
Training loss: 3.0736591815948486
Validation loss: 3.737728459860689

Epoch: 5| Step: 3
Training loss: 3.643334150314331
Validation loss: 3.7199847390574794

Epoch: 5| Step: 4
Training loss: 3.6005427837371826
Validation loss: 3.701988217651203

Epoch: 5| Step: 5
Training loss: 3.4381866455078125
Validation loss: 3.681849718093872

Epoch: 5| Step: 6
Training loss: 3.5237698554992676
Validation loss: 3.6627863273825696

Epoch: 5| Step: 7
Training loss: 3.044358491897583
Validation loss: 3.645312393865278

Epoch: 5| Step: 8
Training loss: 4.162102222442627
Validation loss: 3.632550921491397

Epoch: 5| Step: 9
Training loss: 3.8484115600585938
Validation loss: 3.6188664564522366

Epoch: 5| Step: 10
Training loss: 2.0909953117370605
Validation loss: 3.60504178590672

Epoch: 7| Step: 0
Training loss: 3.794957399368286
Validation loss: 3.5912099474219867

Epoch: 5| Step: 1
Training loss: 3.0630857944488525
Validation loss: 3.576491427677934

Epoch: 5| Step: 2
Training loss: 4.667567253112793
Validation loss: 3.5636683151286137

Epoch: 5| Step: 3
Training loss: 2.9838528633117676
Validation loss: 3.553884747207806

Epoch: 5| Step: 4
Training loss: 3.524394989013672
Validation loss: 3.5399045969850276

Epoch: 5| Step: 5
Training loss: 2.966338634490967
Validation loss: 3.5300779496469805

Epoch: 5| Step: 6
Training loss: 3.0691051483154297
Validation loss: 3.5158179421578684

Epoch: 5| Step: 7
Training loss: 3.2031409740448
Validation loss: 3.5031312845086537

Epoch: 5| Step: 8
Training loss: 4.13197660446167
Validation loss: 3.4907996577601277

Epoch: 5| Step: 9
Training loss: 2.9384968280792236
Validation loss: 3.481377988733271

Epoch: 5| Step: 10
Training loss: 3.7316269874572754
Validation loss: 3.472292879576324

Epoch: 8| Step: 0
Training loss: 3.9689018726348877
Validation loss: 3.463259804633356

Epoch: 5| Step: 1
Training loss: 3.214913845062256
Validation loss: 3.452739977067517

Epoch: 5| Step: 2
Training loss: 2.286259651184082
Validation loss: 3.4410634630469867

Epoch: 5| Step: 3
Training loss: 3.6733345985412598
Validation loss: 3.4315235691685833

Epoch: 5| Step: 4
Training loss: 3.4798316955566406
Validation loss: 3.41935823809716

Epoch: 5| Step: 5
Training loss: 3.047964572906494
Validation loss: 3.4120083778135237

Epoch: 5| Step: 6
Training loss: 3.2755064964294434
Validation loss: 3.401274845164309

Epoch: 5| Step: 7
Training loss: 3.963736057281494
Validation loss: 3.3921740157629854

Epoch: 5| Step: 8
Training loss: 3.514883518218994
Validation loss: 3.3851316154644056

Epoch: 5| Step: 9
Training loss: 2.975227117538452
Validation loss: 3.382068698124219

Epoch: 5| Step: 10
Training loss: 3.63486385345459
Validation loss: 3.3904345189371417

Epoch: 9| Step: 0
Training loss: 3.407391309738159
Validation loss: 3.3773237787267214

Epoch: 5| Step: 1
Training loss: 2.8298935890197754
Validation loss: 3.359024986144035

Epoch: 5| Step: 2
Training loss: 4.174936771392822
Validation loss: 3.3536108950132966

Epoch: 5| Step: 3
Training loss: 4.2086663246154785
Validation loss: 3.3504862221338416

Epoch: 5| Step: 4
Training loss: 2.5954976081848145
Validation loss: 3.344486144281203

Epoch: 5| Step: 5
Training loss: 3.041100263595581
Validation loss: 3.3327689786111154

Epoch: 5| Step: 6
Training loss: 4.295316219329834
Validation loss: 3.3270480837873233

Epoch: 5| Step: 7
Training loss: 3.5869040489196777
Validation loss: 3.319698169667234

Epoch: 5| Step: 8
Training loss: 2.132850170135498
Validation loss: 3.314917472101027

Epoch: 5| Step: 9
Training loss: 2.991037607192993
Validation loss: 3.3109949737466793

Epoch: 5| Step: 10
Training loss: 3.002732753753662
Validation loss: 3.30436437360702

Epoch: 10| Step: 0
Training loss: 4.099334239959717
Validation loss: 3.3000997292098178

Epoch: 5| Step: 1
Training loss: 2.8753435611724854
Validation loss: 3.2956629876167542

Epoch: 5| Step: 2
Training loss: 2.7973074913024902
Validation loss: 3.283333129780267

Epoch: 5| Step: 3
Training loss: 3.148855209350586
Validation loss: 3.2767550637645106

Epoch: 5| Step: 4
Training loss: 2.84877872467041
Validation loss: 3.2688257540425947

Epoch: 5| Step: 5
Training loss: 3.6895904541015625
Validation loss: 3.262394799981066

Epoch: 5| Step: 6
Training loss: 3.362325668334961
Validation loss: 3.2567141568788918

Epoch: 5| Step: 7
Training loss: 3.419438123703003
Validation loss: 3.251601211486324

Epoch: 5| Step: 8
Training loss: 3.318734645843506
Validation loss: 3.2477640900560605

Epoch: 5| Step: 9
Training loss: 2.833512783050537
Validation loss: 3.245411329371955

Epoch: 5| Step: 10
Training loss: 3.3243095874786377
Validation loss: 3.2439391818097842

Epoch: 11| Step: 0
Training loss: 3.3953826427459717
Validation loss: 3.253187956348542

Epoch: 5| Step: 1
Training loss: 3.4971249103546143
Validation loss: 3.2235487250871557

Epoch: 5| Step: 2
Training loss: 3.1728315353393555
Validation loss: 3.2169339631193425

Epoch: 5| Step: 3
Training loss: 3.563641309738159
Validation loss: 3.2200347454317155

Epoch: 5| Step: 4
Training loss: 3.3955771923065186
Validation loss: 3.2088668243859404

Epoch: 5| Step: 5
Training loss: 2.407285690307617
Validation loss: 3.202517496642246

Epoch: 5| Step: 6
Training loss: 3.0888264179229736
Validation loss: 3.199910976553476

Epoch: 5| Step: 7
Training loss: 2.7614853382110596
Validation loss: 3.201816443474062

Epoch: 5| Step: 8
Training loss: 3.404813289642334
Validation loss: 3.196252651112054

Epoch: 5| Step: 9
Training loss: 3.033787488937378
Validation loss: 3.1923433811433855

Epoch: 5| Step: 10
Training loss: 3.6392078399658203
Validation loss: 3.180841176740585

Epoch: 12| Step: 0
Training loss: 3.7257676124572754
Validation loss: 3.173053026199341

Epoch: 5| Step: 1
Training loss: 3.219301700592041
Validation loss: 3.1653893070836223

Epoch: 5| Step: 2
Training loss: 2.5737946033477783
Validation loss: 3.1635710782902215

Epoch: 5| Step: 3
Training loss: 3.167141914367676
Validation loss: 3.163937912192396

Epoch: 5| Step: 4
Training loss: 3.2214789390563965
Validation loss: 3.1575749125531924

Epoch: 5| Step: 5
Training loss: 2.1738126277923584
Validation loss: 3.1485204824837307

Epoch: 5| Step: 6
Training loss: 3.688988447189331
Validation loss: 3.143693800895445

Epoch: 5| Step: 7
Training loss: 2.4680657386779785
Validation loss: 3.1393879203386206

Epoch: 5| Step: 8
Training loss: 3.6881237030029297
Validation loss: 3.133859811290618

Epoch: 5| Step: 9
Training loss: 3.7462775707244873
Validation loss: 3.127985677411479

Epoch: 5| Step: 10
Training loss: 3.0912106037139893
Validation loss: 3.121970504842779

Epoch: 13| Step: 0
Training loss: 2.0301146507263184
Validation loss: 3.116450919899889

Epoch: 5| Step: 1
Training loss: 2.9329075813293457
Validation loss: 3.114815324865362

Epoch: 5| Step: 2
Training loss: 3.162400007247925
Validation loss: 3.1130886180426485

Epoch: 5| Step: 3
Training loss: 4.140997886657715
Validation loss: 3.1100327122596

Epoch: 5| Step: 4
Training loss: 2.8381571769714355
Validation loss: 3.102053439745339

Epoch: 5| Step: 5
Training loss: 3.652306318283081
Validation loss: 3.097183924849315

Epoch: 5| Step: 6
Training loss: 3.1823036670684814
Validation loss: 3.0878270390213176

Epoch: 5| Step: 7
Training loss: 3.713310956954956
Validation loss: 3.0866909539827736

Epoch: 5| Step: 8
Training loss: 2.3656973838806152
Validation loss: 3.081862711137341

Epoch: 5| Step: 9
Training loss: 3.523489475250244
Validation loss: 3.0773166020711265

Epoch: 5| Step: 10
Training loss: 2.726865530014038
Validation loss: 3.0721081174829954

Epoch: 14| Step: 0
Training loss: 3.3614304065704346
Validation loss: 3.0692306231426936

Epoch: 5| Step: 1
Training loss: 3.275643825531006
Validation loss: 3.0655231398920857

Epoch: 5| Step: 2
Training loss: 3.0531764030456543
Validation loss: 3.0630747220849477

Epoch: 5| Step: 3
Training loss: 3.1021008491516113
Validation loss: 3.063776287981259

Epoch: 5| Step: 4
Training loss: 2.789937973022461
Validation loss: 3.066352249473654

Epoch: 5| Step: 5
Training loss: 3.249976634979248
Validation loss: 3.0467106834534676

Epoch: 5| Step: 6
Training loss: 2.719470739364624
Validation loss: 3.046814808281519

Epoch: 5| Step: 7
Training loss: 3.231463670730591
Validation loss: 3.051856635719217

Epoch: 5| Step: 8
Training loss: 2.7721242904663086
Validation loss: 3.062051434670725

Epoch: 5| Step: 9
Training loss: 2.9648537635803223
Validation loss: 3.043494934676796

Epoch: 5| Step: 10
Training loss: 3.6453864574432373
Validation loss: 3.0295825773669827

Epoch: 15| Step: 0
Training loss: 3.2918663024902344
Validation loss: 3.023605728662142

Epoch: 5| Step: 1
Training loss: 3.869358539581299
Validation loss: 3.028843618208362

Epoch: 5| Step: 2
Training loss: 2.807250499725342
Validation loss: 3.0273313829975743

Epoch: 5| Step: 3
Training loss: 3.0580251216888428
Validation loss: 3.026053720904935

Epoch: 5| Step: 4
Training loss: 2.9100098609924316
Validation loss: 3.0184498269070863

Epoch: 5| Step: 5
Training loss: 2.829850673675537
Validation loss: 3.005833705266317

Epoch: 5| Step: 6
Training loss: 2.2182230949401855
Validation loss: 3.0018510895390667

Epoch: 5| Step: 7
Training loss: 2.6245267391204834
Validation loss: 2.998476033569664

Epoch: 5| Step: 8
Training loss: 3.216660737991333
Validation loss: 3.000655489583169

Epoch: 5| Step: 9
Training loss: 3.3041789531707764
Validation loss: 2.9910459877342306

Epoch: 5| Step: 10
Training loss: 3.749056577682495
Validation loss: 2.9885624377958235

Epoch: 16| Step: 0
Training loss: 2.0832791328430176
Validation loss: 2.9853870919955674

Epoch: 5| Step: 1
Training loss: 2.6038529872894287
Validation loss: 2.988453121595485

Epoch: 5| Step: 2
Training loss: 3.111466884613037
Validation loss: 2.9797498487657115

Epoch: 5| Step: 3
Training loss: 2.1980483531951904
Validation loss: 2.9744144639661236

Epoch: 5| Step: 4
Training loss: 3.4153659343719482
Validation loss: 2.9740365782091693

Epoch: 5| Step: 5
Training loss: 2.3480536937713623
Validation loss: 2.9730898795589322

Epoch: 5| Step: 6
Training loss: 3.815457820892334
Validation loss: 2.971754435570009

Epoch: 5| Step: 7
Training loss: 3.002255916595459
Validation loss: 2.966792063046527

Epoch: 5| Step: 8
Training loss: 3.445574998855591
Validation loss: 2.9592196377374793

Epoch: 5| Step: 9
Training loss: 3.729363203048706
Validation loss: 2.954878940377184

Epoch: 5| Step: 10
Training loss: 3.835815906524658
Validation loss: 2.9558880380404893

Epoch: 17| Step: 0
Training loss: 3.0391228199005127
Validation loss: 2.951321663395051

Epoch: 5| Step: 1
Training loss: 3.2230350971221924
Validation loss: 2.9518403904412382

Epoch: 5| Step: 2
Training loss: 2.875791549682617
Validation loss: 2.951886764136694

Epoch: 5| Step: 3
Training loss: 3.2192986011505127
Validation loss: 2.9474845394011466

Epoch: 5| Step: 4
Training loss: 2.962902545928955
Validation loss: 2.9422602448412167

Epoch: 5| Step: 5
Training loss: 2.873871088027954
Validation loss: 2.9384616574933453

Epoch: 5| Step: 6
Training loss: 3.723184585571289
Validation loss: 2.937512497748098

Epoch: 5| Step: 7
Training loss: 2.8525006771087646
Validation loss: 2.935929057418659

Epoch: 5| Step: 8
Training loss: 3.011864185333252
Validation loss: 2.9380348292730187

Epoch: 5| Step: 9
Training loss: 2.509965181350708
Validation loss: 2.930316376429732

Epoch: 5| Step: 10
Training loss: 2.9324121475219727
Validation loss: 2.9323621565295803

Epoch: 18| Step: 0
Training loss: 2.309798240661621
Validation loss: 2.927961080305038

Epoch: 5| Step: 1
Training loss: 2.020425319671631
Validation loss: 2.9254514581413678

Epoch: 5| Step: 2
Training loss: 3.307979106903076
Validation loss: 2.91873493758581

Epoch: 5| Step: 3
Training loss: 2.683321475982666
Validation loss: 2.9162124151824624

Epoch: 5| Step: 4
Training loss: 2.9343247413635254
Validation loss: 2.915471702493647

Epoch: 5| Step: 5
Training loss: 3.403275966644287
Validation loss: 2.911769159378544

Epoch: 5| Step: 6
Training loss: 3.282719373703003
Validation loss: 2.91028400903107

Epoch: 5| Step: 7
Training loss: 3.4691309928894043
Validation loss: 2.908357781748618

Epoch: 5| Step: 8
Training loss: 2.7197673320770264
Validation loss: 2.9110618637454126

Epoch: 5| Step: 9
Training loss: 3.149052143096924
Validation loss: 2.9379357317442536

Epoch: 5| Step: 10
Training loss: 3.933565378189087
Validation loss: 2.9055154938851633

Epoch: 19| Step: 0
Training loss: 4.435247421264648
Validation loss: 2.9002770557198474

Epoch: 5| Step: 1
Training loss: 3.004849910736084
Validation loss: 2.9044008306277695

Epoch: 5| Step: 2
Training loss: 2.7127628326416016
Validation loss: 2.9141187360209804

Epoch: 5| Step: 3
Training loss: 2.8095014095306396
Validation loss: 2.9149957318459787

Epoch: 5| Step: 4
Training loss: 3.65436053276062
Validation loss: 2.9102523993420344

Epoch: 5| Step: 5
Training loss: 1.803026556968689
Validation loss: 2.8980890704739477

Epoch: 5| Step: 6
Training loss: 2.8155601024627686
Validation loss: 2.895665563562865

Epoch: 5| Step: 7
Training loss: 2.0229690074920654
Validation loss: 2.8898475323953936

Epoch: 5| Step: 8
Training loss: 3.531467914581299
Validation loss: 2.8871767649086575

Epoch: 5| Step: 9
Training loss: 3.15112566947937
Validation loss: 2.88880499716728

Epoch: 5| Step: 10
Training loss: 3.0201570987701416
Validation loss: 2.889411982669625

Epoch: 20| Step: 0
Training loss: 3.0718977451324463
Validation loss: 2.8884537527638097

Epoch: 5| Step: 1
Training loss: 2.2173407077789307
Validation loss: 2.8827212138842513

Epoch: 5| Step: 2
Training loss: 3.6558456420898438
Validation loss: 2.881975168822914

Epoch: 5| Step: 3
Training loss: 3.3271610736846924
Validation loss: 2.874655100607103

Epoch: 5| Step: 4
Training loss: 2.5086240768432617
Validation loss: 2.868395233667025

Epoch: 5| Step: 5
Training loss: 3.0178427696228027
Validation loss: 2.8681566587058445

Epoch: 5| Step: 6
Training loss: 3.120673656463623
Validation loss: 2.8725799975856656

Epoch: 5| Step: 7
Training loss: 2.238233804702759
Validation loss: 2.8700633869376233

Epoch: 5| Step: 8
Training loss: 3.079061508178711
Validation loss: 2.8648268586845806

Epoch: 5| Step: 9
Training loss: 3.0888607501983643
Validation loss: 2.8601945318201536

Epoch: 5| Step: 10
Training loss: 3.484318733215332
Validation loss: 2.861690869895361

Epoch: 21| Step: 0
Training loss: 2.965040683746338
Validation loss: 2.859466924462267

Epoch: 5| Step: 1
Training loss: 3.845188856124878
Validation loss: 2.857528519886796

Epoch: 5| Step: 2
Training loss: 3.972729444503784
Validation loss: 2.855754849731281

Epoch: 5| Step: 3
Training loss: 2.8005805015563965
Validation loss: 2.8504000274083947

Epoch: 5| Step: 4
Training loss: 2.6569111347198486
Validation loss: 2.8455746020040205

Epoch: 5| Step: 5
Training loss: 2.6792798042297363
Validation loss: 2.840258631654965

Epoch: 5| Step: 6
Training loss: 2.7208797931671143
Validation loss: 2.85013819766301

Epoch: 5| Step: 7
Training loss: 2.5194828510284424
Validation loss: 2.842903124388828

Epoch: 5| Step: 8
Training loss: 2.4317896366119385
Validation loss: 2.8451654808495634

Epoch: 5| Step: 9
Training loss: 3.1974036693573
Validation loss: 2.8346348347202426

Epoch: 5| Step: 10
Training loss: 2.7673158645629883
Validation loss: 2.8360701966029342

Epoch: 22| Step: 0
Training loss: 3.4744160175323486
Validation loss: 2.839213486640684

Epoch: 5| Step: 1
Training loss: 1.7031446695327759
Validation loss: 2.8406371813948437

Epoch: 5| Step: 2
Training loss: 2.6856021881103516
Validation loss: 2.8402883416862896

Epoch: 5| Step: 3
Training loss: 3.1327691078186035
Validation loss: 2.844717461575744

Epoch: 5| Step: 4
Training loss: 3.454591751098633
Validation loss: 2.838300479355679

Epoch: 5| Step: 5
Training loss: 3.099815607070923
Validation loss: 2.835792338976296

Epoch: 5| Step: 6
Training loss: 2.8621160984039307
Validation loss: 2.829442593359178

Epoch: 5| Step: 7
Training loss: 2.910756826400757
Validation loss: 2.825393115320513

Epoch: 5| Step: 8
Training loss: 3.4108314514160156
Validation loss: 2.820361578336326

Epoch: 5| Step: 9
Training loss: 2.7429277896881104
Validation loss: 2.821501524217667

Epoch: 5| Step: 10
Training loss: 2.994537353515625
Validation loss: 2.8266546034043833

Epoch: 23| Step: 0
Training loss: 3.4393653869628906
Validation loss: 2.8258873877986783

Epoch: 5| Step: 1
Training loss: 2.59002947807312
Validation loss: 2.815911862158006

Epoch: 5| Step: 2
Training loss: 3.7203903198242188
Validation loss: 2.810930244384273

Epoch: 5| Step: 3
Training loss: 2.590768814086914
Validation loss: 2.80775499087508

Epoch: 5| Step: 4
Training loss: 2.6993353366851807
Validation loss: 2.8084854977105254

Epoch: 5| Step: 5
Training loss: 2.300337314605713
Validation loss: 2.805998379184354

Epoch: 5| Step: 6
Training loss: 3.2646307945251465
Validation loss: 2.8031234484846874

Epoch: 5| Step: 7
Training loss: 3.2745044231414795
Validation loss: 2.800966032089726

Epoch: 5| Step: 8
Training loss: 3.32208251953125
Validation loss: 2.7975664113157537

Epoch: 5| Step: 9
Training loss: 2.058983325958252
Validation loss: 2.7949709200089976

Epoch: 5| Step: 10
Training loss: 3.0427863597869873
Validation loss: 2.7984262307484946

Epoch: 24| Step: 0
Training loss: 2.9515292644500732
Validation loss: 2.8114930788675943

Epoch: 5| Step: 1
Training loss: 2.5285561084747314
Validation loss: 2.7962490358660297

Epoch: 5| Step: 2
Training loss: 3.005866289138794
Validation loss: 2.798428722607192

Epoch: 5| Step: 3
Training loss: 3.2067863941192627
Validation loss: 2.8007414879337436

Epoch: 5| Step: 4
Training loss: 2.8408401012420654
Validation loss: 2.791136964674919

Epoch: 5| Step: 5
Training loss: 2.746702194213867
Validation loss: 2.7906293638290895

Epoch: 5| Step: 6
Training loss: 2.7824594974517822
Validation loss: 2.799832538891864

Epoch: 5| Step: 7
Training loss: 3.592721939086914
Validation loss: 2.812446722420313

Epoch: 5| Step: 8
Training loss: 3.236459255218506
Validation loss: 2.814711993740451

Epoch: 5| Step: 9
Training loss: 2.7849602699279785
Validation loss: 2.807118505559942

Epoch: 5| Step: 10
Training loss: 2.471895217895508
Validation loss: 2.7964438417906403

Epoch: 25| Step: 0
Training loss: 2.787390947341919
Validation loss: 2.7881231641256683

Epoch: 5| Step: 1
Training loss: 3.2256362438201904
Validation loss: 2.7861205916250906

Epoch: 5| Step: 2
Training loss: 3.084231376647949
Validation loss: 2.7873244516311155

Epoch: 5| Step: 3
Training loss: 2.863365650177002
Validation loss: 2.7814534479571926

Epoch: 5| Step: 4
Training loss: 2.614264488220215
Validation loss: 2.778325939691195

Epoch: 5| Step: 5
Training loss: 2.746816635131836
Validation loss: 2.7735227589966147

Epoch: 5| Step: 6
Training loss: 2.4473891258239746
Validation loss: 2.776690995821389

Epoch: 5| Step: 7
Training loss: 3.1619701385498047
Validation loss: 2.7716296821512203

Epoch: 5| Step: 8
Training loss: 3.1486477851867676
Validation loss: 2.772621618804111

Epoch: 5| Step: 9
Training loss: 2.9414432048797607
Validation loss: 2.7776301086589856

Epoch: 5| Step: 10
Training loss: 3.131634473800659
Validation loss: 2.7803760215800297

Epoch: 26| Step: 0
Training loss: 3.2880072593688965
Validation loss: 2.7694201469421387

Epoch: 5| Step: 1
Training loss: 3.0203511714935303
Validation loss: 2.7637107321011123

Epoch: 5| Step: 2
Training loss: 2.4928202629089355
Validation loss: 2.7636828371273574

Epoch: 5| Step: 3
Training loss: 2.3539958000183105
Validation loss: 2.7641020026258243

Epoch: 5| Step: 4
Training loss: 3.647123336791992
Validation loss: 2.7628132527874363

Epoch: 5| Step: 5
Training loss: 2.337052583694458
Validation loss: 2.76288878533148

Epoch: 5| Step: 6
Training loss: 3.145270824432373
Validation loss: 2.7613049630195863

Epoch: 5| Step: 7
Training loss: 2.8466522693634033
Validation loss: 2.7601911585818053

Epoch: 5| Step: 8
Training loss: 3.141479253768921
Validation loss: 2.765744701508553

Epoch: 5| Step: 9
Training loss: 2.594907522201538
Validation loss: 2.7912669079278105

Epoch: 5| Step: 10
Training loss: 3.189404249191284
Validation loss: 2.8019756014629076

Epoch: 27| Step: 0
Training loss: 3.1171436309814453
Validation loss: 2.756184765087661

Epoch: 5| Step: 1
Training loss: 2.6408286094665527
Validation loss: 2.7489719877960863

Epoch: 5| Step: 2
Training loss: 3.1500329971313477
Validation loss: 2.7508596861234276

Epoch: 5| Step: 3
Training loss: 2.5109384059906006
Validation loss: 2.760041803442022

Epoch: 5| Step: 4
Training loss: 3.5754051208496094
Validation loss: 2.773772398630778

Epoch: 5| Step: 5
Training loss: 3.2996888160705566
Validation loss: 2.763095727530859

Epoch: 5| Step: 6
Training loss: 2.868516445159912
Validation loss: 2.758886819244713

Epoch: 5| Step: 7
Training loss: 2.6753017902374268
Validation loss: 2.757879508438931

Epoch: 5| Step: 8
Training loss: 3.0887551307678223
Validation loss: 2.7547318038120063

Epoch: 5| Step: 9
Training loss: 2.985220432281494
Validation loss: 2.7566205506683676

Epoch: 5| Step: 10
Training loss: 1.9021319150924683
Validation loss: 2.75956456891952

Epoch: 28| Step: 0
Training loss: 2.753370761871338
Validation loss: 2.758701729518111

Epoch: 5| Step: 1
Training loss: 2.923600912094116
Validation loss: 2.7571558183239353

Epoch: 5| Step: 2
Training loss: 3.263169527053833
Validation loss: 2.7608243060368363

Epoch: 5| Step: 3
Training loss: 2.842263698577881
Validation loss: 2.7654385720529864

Epoch: 5| Step: 4
Training loss: 3.3683547973632812
Validation loss: 2.7690622422002975

Epoch: 5| Step: 5
Training loss: 2.6523964405059814
Validation loss: 2.751275747053085

Epoch: 5| Step: 6
Training loss: 3.368093490600586
Validation loss: 2.7475343468368694

Epoch: 5| Step: 7
Training loss: 2.607628345489502
Validation loss: 2.7427954366130214

Epoch: 5| Step: 8
Training loss: 2.927135944366455
Validation loss: 2.741524904004989

Epoch: 5| Step: 9
Training loss: 2.712986707687378
Validation loss: 2.737474203109741

Epoch: 5| Step: 10
Training loss: 2.4374570846557617
Validation loss: 2.7393506419274116

Epoch: 29| Step: 0
Training loss: 3.039515733718872
Validation loss: 2.7367045084635415

Epoch: 5| Step: 1
Training loss: 3.8818938732147217
Validation loss: 2.735615171411986

Epoch: 5| Step: 2
Training loss: 2.5216476917266846
Validation loss: 2.729312132763606

Epoch: 5| Step: 3
Training loss: 2.2730488777160645
Validation loss: 2.7289691458466234

Epoch: 5| Step: 4
Training loss: 3.4689419269561768
Validation loss: 2.7277250982099965

Epoch: 5| Step: 5
Training loss: 2.7277791500091553
Validation loss: 2.7263086559951946

Epoch: 5| Step: 6
Training loss: 2.646063804626465
Validation loss: 2.7250412202650502

Epoch: 5| Step: 7
Training loss: 3.0552377700805664
Validation loss: 2.723225485893988

Epoch: 5| Step: 8
Training loss: 2.3551573753356934
Validation loss: 2.7229469207025345

Epoch: 5| Step: 9
Training loss: 3.714517593383789
Validation loss: 2.720912669294624

Epoch: 5| Step: 10
Training loss: 1.9482452869415283
Validation loss: 2.720342841199649

Epoch: 30| Step: 0
Training loss: 2.450650215148926
Validation loss: 2.7174741427103677

Epoch: 5| Step: 1
Training loss: 2.399137020111084
Validation loss: 2.7178833253922

Epoch: 5| Step: 2
Training loss: 2.4764037132263184
Validation loss: 2.713993162237188

Epoch: 5| Step: 3
Training loss: 3.035273790359497
Validation loss: 2.7129275157887447

Epoch: 5| Step: 4
Training loss: 3.0670738220214844
Validation loss: 2.709438600847798

Epoch: 5| Step: 5
Training loss: 2.7115654945373535
Validation loss: 2.7088705109011744

Epoch: 5| Step: 6
Training loss: 2.682295322418213
Validation loss: 2.7069183831573813

Epoch: 5| Step: 7
Training loss: 3.3450770378112793
Validation loss: 2.7048114345919703

Epoch: 5| Step: 8
Training loss: 2.893123149871826
Validation loss: 2.7043114323769846

Epoch: 5| Step: 9
Training loss: 2.96328067779541
Validation loss: 2.7020301357392342

Epoch: 5| Step: 10
Training loss: 3.7163963317871094
Validation loss: 2.701209701517577

Epoch: 31| Step: 0
Training loss: 2.430962085723877
Validation loss: 2.700954383419406

Epoch: 5| Step: 1
Training loss: 3.5607471466064453
Validation loss: 2.7035737114567913

Epoch: 5| Step: 2
Training loss: 2.536278486251831
Validation loss: 2.6998085462918846

Epoch: 5| Step: 3
Training loss: 3.2350172996520996
Validation loss: 2.698980344239102

Epoch: 5| Step: 4
Training loss: 2.3419220447540283
Validation loss: 2.6963544968635804

Epoch: 5| Step: 5
Training loss: 3.0046136379241943
Validation loss: 2.696497973575387

Epoch: 5| Step: 6
Training loss: 3.0629429817199707
Validation loss: 2.696101934679093

Epoch: 5| Step: 7
Training loss: 3.0314247608184814
Validation loss: 2.696577041379867

Epoch: 5| Step: 8
Training loss: 2.563352108001709
Validation loss: 2.6948899274231284

Epoch: 5| Step: 9
Training loss: 2.4881227016448975
Validation loss: 2.6974042718128493

Epoch: 5| Step: 10
Training loss: 3.3621721267700195
Validation loss: 2.695446075931672

Epoch: 32| Step: 0
Training loss: 2.5926239490509033
Validation loss: 2.6969254350149505

Epoch: 5| Step: 1
Training loss: 2.8990254402160645
Validation loss: 2.6939474177616898

Epoch: 5| Step: 2
Training loss: 3.144606828689575
Validation loss: 2.6960916826801915

Epoch: 5| Step: 3
Training loss: 3.8000407218933105
Validation loss: 2.6941568774561726

Epoch: 5| Step: 4
Training loss: 2.753512382507324
Validation loss: 2.696888282734861

Epoch: 5| Step: 5
Training loss: 3.366178512573242
Validation loss: 2.6951235519942416

Epoch: 5| Step: 6
Training loss: 2.556492328643799
Validation loss: 2.69751218570176

Epoch: 5| Step: 7
Training loss: 3.4673142433166504
Validation loss: 2.696048528917374

Epoch: 5| Step: 8
Training loss: 2.1996312141418457
Validation loss: 2.691784768976191

Epoch: 5| Step: 9
Training loss: 1.8454322814941406
Validation loss: 2.698185956606301

Epoch: 5| Step: 10
Training loss: 2.8631949424743652
Validation loss: 2.698702541730737

Epoch: 33| Step: 0
Training loss: 2.8260974884033203
Validation loss: 2.6961917056832263

Epoch: 5| Step: 1
Training loss: 2.855818510055542
Validation loss: 2.699695448721609

Epoch: 5| Step: 2
Training loss: 3.228980541229248
Validation loss: 2.691913738045641

Epoch: 5| Step: 3
Training loss: 2.1993114948272705
Validation loss: 2.688649854352397

Epoch: 5| Step: 4
Training loss: 2.4148528575897217
Validation loss: 2.6911182198473202

Epoch: 5| Step: 5
Training loss: 3.2228381633758545
Validation loss: 2.690880085832329

Epoch: 5| Step: 6
Training loss: 2.805478572845459
Validation loss: 2.7002667739827144

Epoch: 5| Step: 7
Training loss: 2.133901596069336
Validation loss: 2.691053145675249

Epoch: 5| Step: 8
Training loss: 3.6900737285614014
Validation loss: 2.6846035219007924

Epoch: 5| Step: 9
Training loss: 3.2022690773010254
Validation loss: 2.6895147754300024

Epoch: 5| Step: 10
Training loss: 2.8693761825561523
Validation loss: 2.6861125833244732

Epoch: 34| Step: 0
Training loss: 3.7561068534851074
Validation loss: 2.6963741599872546

Epoch: 5| Step: 1
Training loss: 2.837888479232788
Validation loss: 2.6947346861644457

Epoch: 5| Step: 2
Training loss: 2.3700084686279297
Validation loss: 2.690785566965739

Epoch: 5| Step: 3
Training loss: 3.1146023273468018
Validation loss: 2.6947015613637944

Epoch: 5| Step: 4
Training loss: 2.72402024269104
Validation loss: 2.691952310582643

Epoch: 5| Step: 5
Training loss: 3.2333545684814453
Validation loss: 2.6902250756499586

Epoch: 5| Step: 6
Training loss: 3.006437301635742
Validation loss: 2.6927232075763006

Epoch: 5| Step: 7
Training loss: 2.3893637657165527
Validation loss: 2.6836966006986556

Epoch: 5| Step: 8
Training loss: 2.542748212814331
Validation loss: 2.681669904339698

Epoch: 5| Step: 9
Training loss: 2.4782989025115967
Validation loss: 2.677711930326236

Epoch: 5| Step: 10
Training loss: 2.955045700073242
Validation loss: 2.683826420896797

Epoch: 35| Step: 0
Training loss: 3.4415931701660156
Validation loss: 2.6823562755379626

Epoch: 5| Step: 1
Training loss: 3.4291281700134277
Validation loss: 2.689019359568114

Epoch: 5| Step: 2
Training loss: 3.138145685195923
Validation loss: 2.6922753190481536

Epoch: 5| Step: 3
Training loss: 2.17228627204895
Validation loss: 2.6880938993987216

Epoch: 5| Step: 4
Training loss: 2.292773485183716
Validation loss: 2.681723392137917

Epoch: 5| Step: 5
Training loss: 1.9449279308319092
Validation loss: 2.6831264829122894

Epoch: 5| Step: 6
Training loss: 2.851727247238159
Validation loss: 2.6805815209624586

Epoch: 5| Step: 7
Training loss: 2.929720163345337
Validation loss: 2.6822187464724303

Epoch: 5| Step: 8
Training loss: 3.196706771850586
Validation loss: 2.689419992508427

Epoch: 5| Step: 9
Training loss: 2.6418087482452393
Validation loss: 2.6902838753115748

Epoch: 5| Step: 10
Training loss: 3.379624843597412
Validation loss: 2.6900162619929158

Epoch: 36| Step: 0
Training loss: 3.0726726055145264
Validation loss: 2.679217912817514

Epoch: 5| Step: 1
Training loss: 2.081815242767334
Validation loss: 2.674954122112643

Epoch: 5| Step: 2
Training loss: 3.4474055767059326
Validation loss: 2.6777856273035847

Epoch: 5| Step: 3
Training loss: 3.4077415466308594
Validation loss: 2.678081161232405

Epoch: 5| Step: 4
Training loss: 2.7881016731262207
Validation loss: 2.676633358001709

Epoch: 5| Step: 5
Training loss: 2.5607895851135254
Validation loss: 2.6803265489557737

Epoch: 5| Step: 6
Training loss: 2.770641803741455
Validation loss: 2.6763266953088904

Epoch: 5| Step: 7
Training loss: 2.535414934158325
Validation loss: 2.685256945189609

Epoch: 5| Step: 8
Training loss: 2.208876848220825
Validation loss: 2.680182692825153

Epoch: 5| Step: 9
Training loss: 3.933175563812256
Validation loss: 2.6814802974782963

Epoch: 5| Step: 10
Training loss: 2.415968656539917
Validation loss: 2.674649243713707

Epoch: 37| Step: 0
Training loss: 2.567561626434326
Validation loss: 2.674300209168465

Epoch: 5| Step: 1
Training loss: 2.3004822731018066
Validation loss: 2.672610693080451

Epoch: 5| Step: 2
Training loss: 3.6172091960906982
Validation loss: 2.6694155200835197

Epoch: 5| Step: 3
Training loss: 3.2569236755371094
Validation loss: 2.6710666994894705

Epoch: 5| Step: 4
Training loss: 3.181445837020874
Validation loss: 2.667358006200483

Epoch: 5| Step: 5
Training loss: 2.9849600791931152
Validation loss: 2.667143944771059

Epoch: 5| Step: 6
Training loss: 1.840280294418335
Validation loss: 2.6698488112418883

Epoch: 5| Step: 7
Training loss: 3.5893352031707764
Validation loss: 2.6693174557019304

Epoch: 5| Step: 8
Training loss: 2.9846863746643066
Validation loss: 2.666635769669728

Epoch: 5| Step: 9
Training loss: 2.584007978439331
Validation loss: 2.6683529551311205

Epoch: 5| Step: 10
Training loss: 2.1649067401885986
Validation loss: 2.670886972899078

Epoch: 38| Step: 0
Training loss: 3.3046488761901855
Validation loss: 2.6713750875124367

Epoch: 5| Step: 1
Training loss: 2.641526699066162
Validation loss: 2.672668718522595

Epoch: 5| Step: 2
Training loss: 2.3616976737976074
Validation loss: 2.682643431489186

Epoch: 5| Step: 3
Training loss: 3.1638314723968506
Validation loss: 2.6843806159111763

Epoch: 5| Step: 4
Training loss: 2.678422212600708
Validation loss: 2.681985165483208

Epoch: 5| Step: 5
Training loss: 2.6295053958892822
Validation loss: 2.6818565373779624

Epoch: 5| Step: 6
Training loss: 2.32132625579834
Validation loss: 2.6805029530679025

Epoch: 5| Step: 7
Training loss: 3.473736524581909
Validation loss: 2.673683681795674

Epoch: 5| Step: 8
Training loss: 2.9583287239074707
Validation loss: 2.670174724312239

Epoch: 5| Step: 9
Training loss: 2.8779008388519287
Validation loss: 2.6661656851409585

Epoch: 5| Step: 10
Training loss: 2.722996711730957
Validation loss: 2.669763888082197

Epoch: 39| Step: 0
Training loss: 2.6348555088043213
Validation loss: 2.6604040438129055

Epoch: 5| Step: 1
Training loss: 2.5645110607147217
Validation loss: 2.670541330050397

Epoch: 5| Step: 2
Training loss: 2.6653177738189697
Validation loss: 2.6712614438867055

Epoch: 5| Step: 3
Training loss: 3.048443555831909
Validation loss: 2.6773215160574964

Epoch: 5| Step: 4
Training loss: 2.382708787918091
Validation loss: 2.670861926130069

Epoch: 5| Step: 5
Training loss: 2.7649292945861816
Validation loss: 2.6633659665302565

Epoch: 5| Step: 6
Training loss: 2.8710005283355713
Validation loss: 2.659810948115523

Epoch: 5| Step: 7
Training loss: 3.0913822650909424
Validation loss: 2.6582801572738157

Epoch: 5| Step: 8
Training loss: 3.0692930221557617
Validation loss: 2.6586618244007068

Epoch: 5| Step: 9
Training loss: 2.9913408756256104
Validation loss: 2.658914073821037

Epoch: 5| Step: 10
Training loss: 3.101076126098633
Validation loss: 2.6629544586263676

Epoch: 40| Step: 0
Training loss: 2.3396644592285156
Validation loss: 2.659517962445495

Epoch: 5| Step: 1
Training loss: 3.16279673576355
Validation loss: 2.656805799853417

Epoch: 5| Step: 2
Training loss: 2.3610336780548096
Validation loss: 2.661125890670284

Epoch: 5| Step: 3
Training loss: 2.6494596004486084
Validation loss: 2.6569342049219276

Epoch: 5| Step: 4
Training loss: 3.0236735343933105
Validation loss: 2.65889992765201

Epoch: 5| Step: 5
Training loss: 3.6693642139434814
Validation loss: 2.6661498802964405

Epoch: 5| Step: 6
Training loss: 2.000325918197632
Validation loss: 2.667873259513609

Epoch: 5| Step: 7
Training loss: 3.320889949798584
Validation loss: 2.67113616389613

Epoch: 5| Step: 8
Training loss: 3.651597261428833
Validation loss: 2.673771191668767

Epoch: 5| Step: 9
Training loss: 2.395486831665039
Validation loss: 2.6674527173401206

Epoch: 5| Step: 10
Training loss: 2.4041123390197754
Validation loss: 2.667496504322175

Epoch: 41| Step: 0
Training loss: 2.6845638751983643
Validation loss: 2.655690457231255

Epoch: 5| Step: 1
Training loss: 2.6304028034210205
Validation loss: 2.657375374147969

Epoch: 5| Step: 2
Training loss: 2.6766364574432373
Validation loss: 2.6597922566116496

Epoch: 5| Step: 3
Training loss: 2.155543088912964
Validation loss: 2.6677330950255036

Epoch: 5| Step: 4
Training loss: 3.371877670288086
Validation loss: 2.6665651003519693

Epoch: 5| Step: 5
Training loss: 2.2252755165100098
Validation loss: 2.6658112900231474

Epoch: 5| Step: 6
Training loss: 2.4498953819274902
Validation loss: 2.651217904142154

Epoch: 5| Step: 7
Training loss: 3.2946746349334717
Validation loss: 2.6455052975685365

Epoch: 5| Step: 8
Training loss: 3.4369349479675293
Validation loss: 2.6460473563081477

Epoch: 5| Step: 9
Training loss: 3.0218634605407715
Validation loss: 2.6483678869021836

Epoch: 5| Step: 10
Training loss: 3.139559745788574
Validation loss: 2.648884424599268

Epoch: 42| Step: 0
Training loss: 2.7846877574920654
Validation loss: 2.6525162727602067

Epoch: 5| Step: 1
Training loss: 3.0512943267822266
Validation loss: 2.6514537642079015

Epoch: 5| Step: 2
Training loss: 3.061941146850586
Validation loss: 2.655075337297173

Epoch: 5| Step: 3
Training loss: 2.6571357250213623
Validation loss: 2.651546634653563

Epoch: 5| Step: 4
Training loss: 2.986964464187622
Validation loss: 2.650585730870565

Epoch: 5| Step: 5
Training loss: 2.660921812057495
Validation loss: 2.649028742185203

Epoch: 5| Step: 6
Training loss: 2.603661060333252
Validation loss: 2.6495100785327215

Epoch: 5| Step: 7
Training loss: 3.1504483222961426
Validation loss: 2.650097849548504

Epoch: 5| Step: 8
Training loss: 3.3464951515197754
Validation loss: 2.647372535479966

Epoch: 5| Step: 9
Training loss: 2.626098155975342
Validation loss: 2.6485119455604145

Epoch: 5| Step: 10
Training loss: 1.8859988451004028
Validation loss: 2.646825998060165

Epoch: 43| Step: 0
Training loss: 2.794492721557617
Validation loss: 2.6475130716959634

Epoch: 5| Step: 1
Training loss: 2.6813161373138428
Validation loss: 2.6460829883493404

Epoch: 5| Step: 2
Training loss: 3.150341510772705
Validation loss: 2.64598871046497

Epoch: 5| Step: 3
Training loss: 2.6551990509033203
Validation loss: 2.6480557482729674

Epoch: 5| Step: 4
Training loss: 2.357520580291748
Validation loss: 2.645249823088287

Epoch: 5| Step: 5
Training loss: 2.73826265335083
Validation loss: 2.645705266665387

Epoch: 5| Step: 6
Training loss: 3.089207410812378
Validation loss: 2.6552146942384782

Epoch: 5| Step: 7
Training loss: 3.5810012817382812
Validation loss: 2.6543528418387137

Epoch: 5| Step: 8
Training loss: 2.5344579219818115
Validation loss: 2.646061587077315

Epoch: 5| Step: 9
Training loss: 2.894639253616333
Validation loss: 2.6394910966196368

Epoch: 5| Step: 10
Training loss: 2.372556447982788
Validation loss: 2.639077568566927

Epoch: 44| Step: 0
Training loss: 3.053349018096924
Validation loss: 2.647670756104172

Epoch: 5| Step: 1
Training loss: 2.711688756942749
Validation loss: 2.643818711721769

Epoch: 5| Step: 2
Training loss: 2.8751399517059326
Validation loss: 2.640608592699933

Epoch: 5| Step: 3
Training loss: 3.541348695755005
Validation loss: 2.6383560524191907

Epoch: 5| Step: 4
Training loss: 2.865001916885376
Validation loss: 2.6358252392020276

Epoch: 5| Step: 5
Training loss: 2.9570369720458984
Validation loss: 2.633783127671929

Epoch: 5| Step: 6
Training loss: 2.3851802349090576
Validation loss: 2.6323123311483734

Epoch: 5| Step: 7
Training loss: 2.792036294937134
Validation loss: 2.634394181671963

Epoch: 5| Step: 8
Training loss: 2.616913080215454
Validation loss: 2.6342965966911724

Epoch: 5| Step: 9
Training loss: 2.5723764896392822
Validation loss: 2.6319092217312066

Epoch: 5| Step: 10
Training loss: 2.3864221572875977
Validation loss: 2.6377668662737777

Epoch: 45| Step: 0
Training loss: 3.4464383125305176
Validation loss: 2.640058894311228

Epoch: 5| Step: 1
Training loss: 2.6849188804626465
Validation loss: 2.634536620109312

Epoch: 5| Step: 2
Training loss: 3.4082279205322266
Validation loss: 2.635206489152806

Epoch: 5| Step: 3
Training loss: 2.2210123538970947
Validation loss: 2.640745788492182

Epoch: 5| Step: 4
Training loss: 3.017570972442627
Validation loss: 2.644318749827723

Epoch: 5| Step: 5
Training loss: 3.1016623973846436
Validation loss: 2.643727017987159

Epoch: 5| Step: 6
Training loss: 2.7610268592834473
Validation loss: 2.642085131778512

Epoch: 5| Step: 7
Training loss: 1.8287956714630127
Validation loss: 2.636468820674445

Epoch: 5| Step: 8
Training loss: 2.506923198699951
Validation loss: 2.642441472699565

Epoch: 5| Step: 9
Training loss: 2.582275152206421
Validation loss: 2.6389062096995692

Epoch: 5| Step: 10
Training loss: 3.311952829360962
Validation loss: 2.6320348144859396

Epoch: 46| Step: 0
Training loss: 3.36627459526062
Validation loss: 2.631577753251599

Epoch: 5| Step: 1
Training loss: 3.1363093852996826
Validation loss: 2.6300375410305556

Epoch: 5| Step: 2
Training loss: 2.06740665435791
Validation loss: 2.6273517762461016

Epoch: 5| Step: 3
Training loss: 3.166053295135498
Validation loss: 2.6295823743266444

Epoch: 5| Step: 4
Training loss: 2.366393566131592
Validation loss: 2.6321782014703237

Epoch: 5| Step: 5
Training loss: 3.2224597930908203
Validation loss: 2.639470382403302

Epoch: 5| Step: 6
Training loss: 2.935734748840332
Validation loss: 2.6402221982197096

Epoch: 5| Step: 7
Training loss: 2.7208428382873535
Validation loss: 2.6413738394296296

Epoch: 5| Step: 8
Training loss: 2.475555896759033
Validation loss: 2.6313200458403556

Epoch: 5| Step: 9
Training loss: 2.7481298446655273
Validation loss: 2.6306189439629994

Epoch: 5| Step: 10
Training loss: 2.4740397930145264
Validation loss: 2.6286680775303997

Epoch: 47| Step: 0
Training loss: 1.657494306564331
Validation loss: 2.638398847272319

Epoch: 5| Step: 1
Training loss: 2.3507518768310547
Validation loss: 2.645058360151065

Epoch: 5| Step: 2
Training loss: 2.6606996059417725
Validation loss: 2.662128822777861

Epoch: 5| Step: 3
Training loss: 2.9802937507629395
Validation loss: 2.6850740063575005

Epoch: 5| Step: 4
Training loss: 2.573521375656128
Validation loss: 2.7207195887001614

Epoch: 5| Step: 5
Training loss: 3.8612542152404785
Validation loss: 2.7231823064947642

Epoch: 5| Step: 6
Training loss: 3.2467780113220215
Validation loss: 2.654036855184904

Epoch: 5| Step: 7
Training loss: 2.96623158454895
Validation loss: 2.62354181402473

Epoch: 5| Step: 8
Training loss: 2.700716972351074
Validation loss: 2.620975822530767

Epoch: 5| Step: 9
Training loss: 3.448090076446533
Validation loss: 2.629653469208748

Epoch: 5| Step: 10
Training loss: 2.487300395965576
Validation loss: 2.6369444939397995

Epoch: 48| Step: 0
Training loss: 2.3081984519958496
Validation loss: 2.6602299444137083

Epoch: 5| Step: 1
Training loss: 2.2046782970428467
Validation loss: 2.648935038556335

Epoch: 5| Step: 2
Training loss: 2.233325242996216
Validation loss: 2.6264328802785566

Epoch: 5| Step: 3
Training loss: 3.253286361694336
Validation loss: 2.6225518257387224

Epoch: 5| Step: 4
Training loss: 3.0579397678375244
Validation loss: 2.626415765413674

Epoch: 5| Step: 5
Training loss: 2.8704779148101807
Validation loss: 2.646383503431915

Epoch: 5| Step: 6
Training loss: 3.7502708435058594
Validation loss: 2.657894052484984

Epoch: 5| Step: 7
Training loss: 3.0567829608917236
Validation loss: 2.6701263150861188

Epoch: 5| Step: 8
Training loss: 2.8140623569488525
Validation loss: 2.6699218442363124

Epoch: 5| Step: 9
Training loss: 2.7138588428497314
Validation loss: 2.6651899660787275

Epoch: 5| Step: 10
Training loss: 2.6787047386169434
Validation loss: 2.650170398014848

Epoch: 49| Step: 0
Training loss: 3.1027164459228516
Validation loss: 2.640037816057923

Epoch: 5| Step: 1
Training loss: 2.5988383293151855
Validation loss: 2.6290905834526144

Epoch: 5| Step: 2
Training loss: 2.5693230628967285
Validation loss: 2.6165641174521497

Epoch: 5| Step: 3
Training loss: 2.828165054321289
Validation loss: 2.6193005038845922

Epoch: 5| Step: 4
Training loss: 2.5817713737487793
Validation loss: 2.621458779099167

Epoch: 5| Step: 5
Training loss: 3.053823947906494
Validation loss: 2.6240215968060236

Epoch: 5| Step: 6
Training loss: 2.623378276824951
Validation loss: 2.6225117611628708

Epoch: 5| Step: 7
Training loss: 2.7470574378967285
Validation loss: 2.621998207543486

Epoch: 5| Step: 8
Training loss: 2.4786312580108643
Validation loss: 2.617388412516604

Epoch: 5| Step: 9
Training loss: 3.161726474761963
Validation loss: 2.614178862622989

Epoch: 5| Step: 10
Training loss: 3.0358076095581055
Validation loss: 2.612529564929265

Epoch: 50| Step: 0
Training loss: 3.0434186458587646
Validation loss: 2.6155091075487036

Epoch: 5| Step: 1
Training loss: 2.5949153900146484
Validation loss: 2.6127713495685208

Epoch: 5| Step: 2
Training loss: 3.004204273223877
Validation loss: 2.618984730012955

Epoch: 5| Step: 3
Training loss: 2.067709445953369
Validation loss: 2.619746018481511

Epoch: 5| Step: 4
Training loss: 2.5432791709899902
Validation loss: 2.618312633165749

Epoch: 5| Step: 5
Training loss: 3.1722400188446045
Validation loss: 2.6199836192592496

Epoch: 5| Step: 6
Training loss: 3.067758083343506
Validation loss: 2.6241852339877876

Epoch: 5| Step: 7
Training loss: 2.5892791748046875
Validation loss: 2.6190648668555805

Epoch: 5| Step: 8
Training loss: 2.9850986003875732
Validation loss: 2.6238600233549714

Epoch: 5| Step: 9
Training loss: 3.135171413421631
Validation loss: 2.6181214932472474

Epoch: 5| Step: 10
Training loss: 2.415342330932617
Validation loss: 2.6099821880299556

Epoch: 51| Step: 0
Training loss: 2.6332595348358154
Validation loss: 2.6063263852109193

Epoch: 5| Step: 1
Training loss: 3.078251838684082
Validation loss: 2.6072627498257543

Epoch: 5| Step: 2
Training loss: 3.0541739463806152
Validation loss: 2.605690876642863

Epoch: 5| Step: 3
Training loss: 3.597817897796631
Validation loss: 2.6085434498325473

Epoch: 5| Step: 4
Training loss: 1.583336591720581
Validation loss: 2.6077936759559055

Epoch: 5| Step: 5
Training loss: 3.1440587043762207
Validation loss: 2.6125666069728073

Epoch: 5| Step: 6
Training loss: 2.4240963459014893
Validation loss: 2.614088732709167

Epoch: 5| Step: 7
Training loss: 1.8500896692276
Validation loss: 2.6154481826290006

Epoch: 5| Step: 8
Training loss: 3.0301010608673096
Validation loss: 2.6089570624853975

Epoch: 5| Step: 9
Training loss: 2.6161417961120605
Validation loss: 2.601946084730087

Epoch: 5| Step: 10
Training loss: 3.767271041870117
Validation loss: 2.601141204116165

Epoch: 52| Step: 0
Training loss: 3.3064029216766357
Validation loss: 2.603154043997488

Epoch: 5| Step: 1
Training loss: 2.5069093704223633
Validation loss: 2.6096839263874996

Epoch: 5| Step: 2
Training loss: 2.735588788986206
Validation loss: 2.610371282023768

Epoch: 5| Step: 3
Training loss: 2.908909320831299
Validation loss: 2.612680335198679

Epoch: 5| Step: 4
Training loss: 2.6921944618225098
Validation loss: 2.616506850847634

Epoch: 5| Step: 5
Training loss: 2.89603590965271
Validation loss: 2.6106285125978532

Epoch: 5| Step: 6
Training loss: 2.881077289581299
Validation loss: 2.6074345342574583

Epoch: 5| Step: 7
Training loss: 2.8787121772766113
Validation loss: 2.610412605347172

Epoch: 5| Step: 8
Training loss: 2.616821765899658
Validation loss: 2.6098249881498274

Epoch: 5| Step: 9
Training loss: 2.522343158721924
Validation loss: 2.6020967678357194

Epoch: 5| Step: 10
Training loss: 2.523975133895874
Validation loss: 2.601370826844246

Epoch: 53| Step: 0
Training loss: 2.452371597290039
Validation loss: 2.5965570147319506

Epoch: 5| Step: 1
Training loss: 3.255225658416748
Validation loss: 2.595064458026681

Epoch: 5| Step: 2
Training loss: 3.187553882598877
Validation loss: 2.5967422890406784

Epoch: 5| Step: 3
Training loss: 2.789609909057617
Validation loss: 2.594720217489427

Epoch: 5| Step: 4
Training loss: 2.5407168865203857
Validation loss: 2.5943858136412916

Epoch: 5| Step: 5
Training loss: 2.7342143058776855
Validation loss: 2.597901334044754

Epoch: 5| Step: 6
Training loss: 2.164228916168213
Validation loss: 2.5997106311141804

Epoch: 5| Step: 7
Training loss: 3.0292630195617676
Validation loss: 2.594493019965387

Epoch: 5| Step: 8
Training loss: 2.7170231342315674
Validation loss: 2.597527075839299

Epoch: 5| Step: 9
Training loss: 3.091057300567627
Validation loss: 2.599067267551217

Epoch: 5| Step: 10
Training loss: 2.4927122592926025
Validation loss: 2.603391380720241

Epoch: 54| Step: 0
Training loss: 1.81720769405365
Validation loss: 2.6260815858840942

Epoch: 5| Step: 1
Training loss: 2.7675182819366455
Validation loss: 2.6207138287123812

Epoch: 5| Step: 2
Training loss: 2.3491272926330566
Validation loss: 2.5977580111513854

Epoch: 5| Step: 3
Training loss: 2.8703255653381348
Validation loss: 2.603554505173878

Epoch: 5| Step: 4
Training loss: 3.2308528423309326
Validation loss: 2.617506565586213

Epoch: 5| Step: 5
Training loss: 3.155409336090088
Validation loss: 2.627503441226098

Epoch: 5| Step: 6
Training loss: 3.4173436164855957
Validation loss: 2.6318135697354554

Epoch: 5| Step: 7
Training loss: 2.4202051162719727
Validation loss: 2.627544451785344

Epoch: 5| Step: 8
Training loss: 3.0456013679504395
Validation loss: 2.6372705992831977

Epoch: 5| Step: 9
Training loss: 2.855079174041748
Validation loss: 2.6330363724821355

Epoch: 5| Step: 10
Training loss: 2.5721776485443115
Validation loss: 2.627093688134224

Epoch: 55| Step: 0
Training loss: 3.1457607746124268
Validation loss: 2.620919571127943

Epoch: 5| Step: 1
Training loss: 2.7936902046203613
Validation loss: 2.6084120709408998

Epoch: 5| Step: 2
Training loss: 2.8005995750427246
Validation loss: 2.5994971465038996

Epoch: 5| Step: 3
Training loss: 3.5553512573242188
Validation loss: 2.60314614670251

Epoch: 5| Step: 4
Training loss: 3.491121292114258
Validation loss: 2.6092971678703063

Epoch: 5| Step: 5
Training loss: 2.7239203453063965
Validation loss: 2.6085318826859996

Epoch: 5| Step: 6
Training loss: 2.428832769393921
Validation loss: 2.604411259774239

Epoch: 5| Step: 7
Training loss: 2.7974798679351807
Validation loss: 2.600754527635472

Epoch: 5| Step: 8
Training loss: 2.5395638942718506
Validation loss: 2.5960213368938816

Epoch: 5| Step: 9
Training loss: 2.1688449382781982
Validation loss: 2.5964215955426617

Epoch: 5| Step: 10
Training loss: 1.9693443775177002
Validation loss: 2.5863689889190016

Epoch: 56| Step: 0
Training loss: 2.3128814697265625
Validation loss: 2.5840456178111415

Epoch: 5| Step: 1
Training loss: 2.6215944290161133
Validation loss: 2.585708136199623

Epoch: 5| Step: 2
Training loss: 2.3835699558258057
Validation loss: 2.587373777102399

Epoch: 5| Step: 3
Training loss: 3.121452808380127
Validation loss: 2.586138702207996

Epoch: 5| Step: 4
Training loss: 2.44854474067688
Validation loss: 2.5872387962956584

Epoch: 5| Step: 5
Training loss: 2.3799171447753906
Validation loss: 2.5909275111331733

Epoch: 5| Step: 6
Training loss: 3.081757068634033
Validation loss: 2.5898026715042772

Epoch: 5| Step: 7
Training loss: 3.7026870250701904
Validation loss: 2.5897676098731255

Epoch: 5| Step: 8
Training loss: 2.4338459968566895
Validation loss: 2.582944218830396

Epoch: 5| Step: 9
Training loss: 2.5422606468200684
Validation loss: 2.5870483767601753

Epoch: 5| Step: 10
Training loss: 3.4787986278533936
Validation loss: 2.5818364748390774

Epoch: 57| Step: 0
Training loss: 3.0514369010925293
Validation loss: 2.582839991456719

Epoch: 5| Step: 1
Training loss: 3.093287706375122
Validation loss: 2.5833455900992117

Epoch: 5| Step: 2
Training loss: 2.8063056468963623
Validation loss: 2.579419461629724

Epoch: 5| Step: 3
Training loss: 2.694633960723877
Validation loss: 2.582376141701975

Epoch: 5| Step: 4
Training loss: 2.5811612606048584
Validation loss: 2.5793070203514508

Epoch: 5| Step: 5
Training loss: 2.9853196144104004
Validation loss: 2.581328684283841

Epoch: 5| Step: 6
Training loss: 2.3752710819244385
Validation loss: 2.5765503478306595

Epoch: 5| Step: 7
Training loss: 2.6172358989715576
Validation loss: 2.5747734910698346

Epoch: 5| Step: 8
Training loss: 2.8691329956054688
Validation loss: 2.574480136235555

Epoch: 5| Step: 9
Training loss: 2.311722755432129
Validation loss: 2.5714915670374388

Epoch: 5| Step: 10
Training loss: 2.9847352504730225
Validation loss: 2.573874265916886

Epoch: 58| Step: 0
Training loss: 2.3229422569274902
Validation loss: 2.576605155903806

Epoch: 5| Step: 1
Training loss: 2.1377265453338623
Validation loss: 2.5761829986367175

Epoch: 5| Step: 2
Training loss: 2.7662839889526367
Validation loss: 2.582583976048295

Epoch: 5| Step: 3
Training loss: 2.4502365589141846
Validation loss: 2.587908729430168

Epoch: 5| Step: 4
Training loss: 3.323633909225464
Validation loss: 2.5929874861112205

Epoch: 5| Step: 5
Training loss: 2.675443172454834
Validation loss: 2.599784625473843

Epoch: 5| Step: 6
Training loss: 3.0600497722625732
Validation loss: 2.6110013069645053

Epoch: 5| Step: 7
Training loss: 3.2030882835388184
Validation loss: 2.6136572232810398

Epoch: 5| Step: 8
Training loss: 2.5243237018585205
Validation loss: 2.6078185573700936

Epoch: 5| Step: 9
Training loss: 2.9742729663848877
Validation loss: 2.600401565592776

Epoch: 5| Step: 10
Training loss: 2.943132162094116
Validation loss: 2.582428063115766

Epoch: 59| Step: 0
Training loss: 3.6333775520324707
Validation loss: 2.5760279342692387

Epoch: 5| Step: 1
Training loss: 2.967406749725342
Validation loss: 2.5688307669854935

Epoch: 5| Step: 2
Training loss: 2.6552486419677734
Validation loss: 2.568365661046838

Epoch: 5| Step: 3
Training loss: 2.4133708477020264
Validation loss: 2.577226241429647

Epoch: 5| Step: 4
Training loss: 2.803844928741455
Validation loss: 2.5862972505630983

Epoch: 5| Step: 5
Training loss: 2.6252601146698
Validation loss: 2.5963818898764988

Epoch: 5| Step: 6
Training loss: 2.5324764251708984
Validation loss: 2.6048568910168064

Epoch: 5| Step: 7
Training loss: 2.9940080642700195
Validation loss: 2.593031567911948

Epoch: 5| Step: 8
Training loss: 2.7622230052948
Validation loss: 2.591143474783949

Epoch: 5| Step: 9
Training loss: 2.200516700744629
Validation loss: 2.5808257210639214

Epoch: 5| Step: 10
Training loss: 2.7768678665161133
Validation loss: 2.573360889188705

Epoch: 60| Step: 0
Training loss: 2.1622722148895264
Validation loss: 2.574720492926977

Epoch: 5| Step: 1
Training loss: 2.8958446979522705
Validation loss: 2.5837894203842326

Epoch: 5| Step: 2
Training loss: 2.3257644176483154
Validation loss: 2.6052720315994753

Epoch: 5| Step: 3
Training loss: 2.6061129570007324
Validation loss: 2.6170742434840046

Epoch: 5| Step: 4
Training loss: 2.555581569671631
Validation loss: 2.6299625340328423

Epoch: 5| Step: 5
Training loss: 2.9568381309509277
Validation loss: 2.6569378247825046

Epoch: 5| Step: 6
Training loss: 3.1692566871643066
Validation loss: 2.633149118833644

Epoch: 5| Step: 7
Training loss: 2.8040823936462402
Validation loss: 2.6015459260632916

Epoch: 5| Step: 8
Training loss: 2.477245330810547
Validation loss: 2.581207275390625

Epoch: 5| Step: 9
Training loss: 3.5645995140075684
Validation loss: 2.5688011851362003

Epoch: 5| Step: 10
Training loss: 2.9600231647491455
Validation loss: 2.5691095193227134

Epoch: 61| Step: 0
Training loss: 2.9529330730438232
Validation loss: 2.5801675294035222

Epoch: 5| Step: 1
Training loss: 2.93863582611084
Validation loss: 2.59120713767185

Epoch: 5| Step: 2
Training loss: 2.737985372543335
Validation loss: 2.5931505951830136

Epoch: 5| Step: 3
Training loss: 3.061833620071411
Validation loss: 2.613160556362521

Epoch: 5| Step: 4
Training loss: 3.4940638542175293
Validation loss: 2.571953841435012

Epoch: 5| Step: 5
Training loss: 2.550872564315796
Validation loss: 2.5622942498935166

Epoch: 5| Step: 6
Training loss: 1.7437282800674438
Validation loss: 2.563908143710065

Epoch: 5| Step: 7
Training loss: 2.4769320487976074
Validation loss: 2.5698431230360463

Epoch: 5| Step: 8
Training loss: 2.3373560905456543
Validation loss: 2.585503752513598

Epoch: 5| Step: 9
Training loss: 3.062685012817383
Validation loss: 2.5912971778582503

Epoch: 5| Step: 10
Training loss: 3.0050089359283447
Validation loss: 2.585710310166882

Epoch: 62| Step: 0
Training loss: 2.3538930416107178
Validation loss: 2.5781528770282702

Epoch: 5| Step: 1
Training loss: 3.0419349670410156
Validation loss: 2.572140452682331

Epoch: 5| Step: 2
Training loss: 3.525141477584839
Validation loss: 2.569064432574857

Epoch: 5| Step: 3
Training loss: 2.60426926612854
Validation loss: 2.569290776406565

Epoch: 5| Step: 4
Training loss: 2.759746789932251
Validation loss: 2.566440778393899

Epoch: 5| Step: 5
Training loss: 2.8304152488708496
Validation loss: 2.567914362876646

Epoch: 5| Step: 6
Training loss: 2.004638195037842
Validation loss: 2.5723508070873957

Epoch: 5| Step: 7
Training loss: 2.7460060119628906
Validation loss: 2.576096816729474

Epoch: 5| Step: 8
Training loss: 3.1273744106292725
Validation loss: 2.5783530153254026

Epoch: 5| Step: 9
Training loss: 1.9617440700531006
Validation loss: 2.580761827448363

Epoch: 5| Step: 10
Training loss: 3.3047242164611816
Validation loss: 2.5783918826810774

Epoch: 63| Step: 0
Training loss: 2.5604937076568604
Validation loss: 2.566261701686408

Epoch: 5| Step: 1
Training loss: 2.6535003185272217
Validation loss: 2.569297318817467

Epoch: 5| Step: 2
Training loss: 3.3336730003356934
Validation loss: 2.5621863667682936

Epoch: 5| Step: 3
Training loss: 2.931748867034912
Validation loss: 2.5607655176552395

Epoch: 5| Step: 4
Training loss: 2.892282009124756
Validation loss: 2.5627527621484574

Epoch: 5| Step: 5
Training loss: 2.958529233932495
Validation loss: 2.558945281531221

Epoch: 5| Step: 6
Training loss: 2.3980517387390137
Validation loss: 2.557678650784236

Epoch: 5| Step: 7
Training loss: 2.788651704788208
Validation loss: 2.5617527269547984

Epoch: 5| Step: 8
Training loss: 2.736987352371216
Validation loss: 2.557156470514113

Epoch: 5| Step: 9
Training loss: 2.131347179412842
Validation loss: 2.560040171428393

Epoch: 5| Step: 10
Training loss: 2.7246181964874268
Validation loss: 2.5603595113241546

Epoch: 64| Step: 0
Training loss: 2.429386615753174
Validation loss: 2.5617612587508334

Epoch: 5| Step: 1
Training loss: 2.278778314590454
Validation loss: 2.556823210049701

Epoch: 5| Step: 2
Training loss: 2.6672325134277344
Validation loss: 2.5523123818059124

Epoch: 5| Step: 3
Training loss: 2.225349187850952
Validation loss: 2.554003166896041

Epoch: 5| Step: 4
Training loss: 2.9027247428894043
Validation loss: 2.5524164630520727

Epoch: 5| Step: 5
Training loss: 3.4078891277313232
Validation loss: 2.551830389166391

Epoch: 5| Step: 6
Training loss: 3.378586530685425
Validation loss: 2.549617136678388

Epoch: 5| Step: 7
Training loss: 1.9003450870513916
Validation loss: 2.5508263649479037

Epoch: 5| Step: 8
Training loss: 2.869581460952759
Validation loss: 2.547796028916554

Epoch: 5| Step: 9
Training loss: 2.8944196701049805
Validation loss: 2.546327913961103

Epoch: 5| Step: 10
Training loss: 3.24432635307312
Validation loss: 2.5550864665738997

Epoch: 65| Step: 0
Training loss: 3.218175172805786
Validation loss: 2.5572798534106185

Epoch: 5| Step: 1
Training loss: 2.7610011100769043
Validation loss: 2.563960923943468

Epoch: 5| Step: 2
Training loss: 2.044006109237671
Validation loss: 2.5661142141588273

Epoch: 5| Step: 3
Training loss: 3.3225536346435547
Validation loss: 2.5751009551427697

Epoch: 5| Step: 4
Training loss: 2.43141508102417
Validation loss: 2.5694751816411174

Epoch: 5| Step: 5
Training loss: 2.663504123687744
Validation loss: 2.566061850517027

Epoch: 5| Step: 6
Training loss: 2.632634162902832
Validation loss: 2.5588562180919032

Epoch: 5| Step: 7
Training loss: 3.102195978164673
Validation loss: 2.5584307332192697

Epoch: 5| Step: 8
Training loss: 2.778966188430786
Validation loss: 2.5528273223548807

Epoch: 5| Step: 9
Training loss: 2.931798219680786
Validation loss: 2.5498853832162838

Epoch: 5| Step: 10
Training loss: 2.036160945892334
Validation loss: 2.545734190171765

Epoch: 66| Step: 0
Training loss: 2.951810359954834
Validation loss: 2.540289096934821

Epoch: 5| Step: 1
Training loss: 2.81013822555542
Validation loss: 2.544390111841181

Epoch: 5| Step: 2
Training loss: 2.4984593391418457
Validation loss: 2.54165990378267

Epoch: 5| Step: 3
Training loss: 2.9958341121673584
Validation loss: 2.5506498557265087

Epoch: 5| Step: 4
Training loss: 2.1192407608032227
Validation loss: 2.5466668426349597

Epoch: 5| Step: 5
Training loss: 3.360083818435669
Validation loss: 2.554214726212204

Epoch: 5| Step: 6
Training loss: 2.4311232566833496
Validation loss: 2.552335395607897

Epoch: 5| Step: 7
Training loss: 2.396993398666382
Validation loss: 2.550120046061854

Epoch: 5| Step: 8
Training loss: 2.6394829750061035
Validation loss: 2.5713207439709733

Epoch: 5| Step: 9
Training loss: 2.6281933784484863
Validation loss: 2.5695154461809384

Epoch: 5| Step: 10
Training loss: 3.2522153854370117
Validation loss: 2.5764014105642996

Epoch: 67| Step: 0
Training loss: 2.13354754447937
Validation loss: 2.551423898307226

Epoch: 5| Step: 1
Training loss: 2.3453242778778076
Validation loss: 2.5446432892994215

Epoch: 5| Step: 2
Training loss: 3.4680213928222656
Validation loss: 2.5396924018859863

Epoch: 5| Step: 3
Training loss: 2.874565839767456
Validation loss: 2.5393510787717757

Epoch: 5| Step: 4
Training loss: 2.7528672218322754
Validation loss: 2.539025778411537

Epoch: 5| Step: 5
Training loss: 2.04038667678833
Validation loss: 2.5401794577157624

Epoch: 5| Step: 6
Training loss: 2.4158380031585693
Validation loss: 2.540576047794793

Epoch: 5| Step: 7
Training loss: 3.1691200733184814
Validation loss: 2.550900436216785

Epoch: 5| Step: 8
Training loss: 2.632228374481201
Validation loss: 2.5538787354705152

Epoch: 5| Step: 9
Training loss: 3.390519380569458
Validation loss: 2.5546695391337075

Epoch: 5| Step: 10
Training loss: 2.740291118621826
Validation loss: 2.557895178435951

Epoch: 68| Step: 0
Training loss: 2.357715368270874
Validation loss: 2.5560728708902993

Epoch: 5| Step: 1
Training loss: 2.227942705154419
Validation loss: 2.547602394575714

Epoch: 5| Step: 2
Training loss: 2.9018568992614746
Validation loss: 2.551214994922761

Epoch: 5| Step: 3
Training loss: 2.365358352661133
Validation loss: 2.546989346063265

Epoch: 5| Step: 4
Training loss: 3.3634345531463623
Validation loss: 2.545906146367391

Epoch: 5| Step: 5
Training loss: 2.3669681549072266
Validation loss: 2.544842630304316

Epoch: 5| Step: 6
Training loss: 2.8952414989471436
Validation loss: 2.54347385385985

Epoch: 5| Step: 7
Training loss: 2.6516499519348145
Validation loss: 2.538570865508049

Epoch: 5| Step: 8
Training loss: 3.4235572814941406
Validation loss: 2.535323496787779

Epoch: 5| Step: 9
Training loss: 2.6171154975891113
Validation loss: 2.534933074828117

Epoch: 5| Step: 10
Training loss: 2.692213296890259
Validation loss: 2.536832050610614

Epoch: 69| Step: 0
Training loss: 3.3298606872558594
Validation loss: 2.535455637080695

Epoch: 5| Step: 1
Training loss: 2.7133214473724365
Validation loss: 2.536399572126327

Epoch: 5| Step: 2
Training loss: 2.2088160514831543
Validation loss: 2.5382007091276106

Epoch: 5| Step: 3
Training loss: 2.8792073726654053
Validation loss: 2.5393370889848277

Epoch: 5| Step: 4
Training loss: 2.9194788932800293
Validation loss: 2.5365025958707257

Epoch: 5| Step: 5
Training loss: 2.706167221069336
Validation loss: 2.529279108970396

Epoch: 5| Step: 6
Training loss: 2.5652101039886475
Validation loss: 2.532799772036973

Epoch: 5| Step: 7
Training loss: 3.0712428092956543
Validation loss: 2.525511492965042

Epoch: 5| Step: 8
Training loss: 2.3560945987701416
Validation loss: 2.5290977083226687

Epoch: 5| Step: 9
Training loss: 2.4307448863983154
Validation loss: 2.5302434839228147

Epoch: 5| Step: 10
Training loss: 2.6961543560028076
Validation loss: 2.5289785297968055

Epoch: 70| Step: 0
Training loss: 2.409316301345825
Validation loss: 2.5376263331341486

Epoch: 5| Step: 1
Training loss: 3.169250011444092
Validation loss: 2.539832930411062

Epoch: 5| Step: 2
Training loss: 2.2967402935028076
Validation loss: 2.548451510808801

Epoch: 5| Step: 3
Training loss: 1.936779260635376
Validation loss: 2.549883614304245

Epoch: 5| Step: 4
Training loss: 2.9598195552825928
Validation loss: 2.549205703120078

Epoch: 5| Step: 5
Training loss: 2.9457345008850098
Validation loss: 2.5510494683378484

Epoch: 5| Step: 6
Training loss: 2.9644601345062256
Validation loss: 2.542764994405931

Epoch: 5| Step: 7
Training loss: 2.9310379028320312
Validation loss: 2.5559310656721874

Epoch: 5| Step: 8
Training loss: 3.0112645626068115
Validation loss: 2.543481485818022

Epoch: 5| Step: 9
Training loss: 2.961547374725342
Validation loss: 2.553616157142065

Epoch: 5| Step: 10
Training loss: 2.1136579513549805
Validation loss: 2.537114526635857

Epoch: 71| Step: 0
Training loss: 2.7210352420806885
Validation loss: 2.534119975182318

Epoch: 5| Step: 1
Training loss: 3.235304594039917
Validation loss: 2.537052721105596

Epoch: 5| Step: 2
Training loss: 2.4831385612487793
Validation loss: 2.5425151881351264

Epoch: 5| Step: 3
Training loss: 2.087007761001587
Validation loss: 2.5452288325114916

Epoch: 5| Step: 4
Training loss: 2.4585983753204346
Validation loss: 2.5405249980188187

Epoch: 5| Step: 5
Training loss: 2.8683412075042725
Validation loss: 2.537425425744826

Epoch: 5| Step: 6
Training loss: 2.5305142402648926
Validation loss: 2.5419686186698174

Epoch: 5| Step: 7
Training loss: 3.090585470199585
Validation loss: 2.539105687090146

Epoch: 5| Step: 8
Training loss: 2.6500461101531982
Validation loss: 2.5387804226208757

Epoch: 5| Step: 9
Training loss: 2.831193447113037
Validation loss: 2.5331777039394585

Epoch: 5| Step: 10
Training loss: 2.892019510269165
Validation loss: 2.5215966368234284

Epoch: 72| Step: 0
Training loss: 2.8454973697662354
Validation loss: 2.5171355842262186

Epoch: 5| Step: 1
Training loss: 2.6222243309020996
Validation loss: 2.5173919585443314

Epoch: 5| Step: 2
Training loss: 3.0743792057037354
Validation loss: 2.520833143623926

Epoch: 5| Step: 3
Training loss: 2.524545192718506
Validation loss: 2.515711058852493

Epoch: 5| Step: 4
Training loss: 2.6332976818084717
Validation loss: 2.5161961586244646

Epoch: 5| Step: 5
Training loss: 2.667067289352417
Validation loss: 2.513654455061882

Epoch: 5| Step: 6
Training loss: 2.185037851333618
Validation loss: 2.5120491340596187

Epoch: 5| Step: 7
Training loss: 2.992802619934082
Validation loss: 2.5168833553150134

Epoch: 5| Step: 8
Training loss: 2.932968854904175
Validation loss: 2.5150258605198195

Epoch: 5| Step: 9
Training loss: 2.514554500579834
Validation loss: 2.522980705384285

Epoch: 5| Step: 10
Training loss: 2.7385690212249756
Validation loss: 2.5273745162512666

Epoch: 73| Step: 0
Training loss: 2.7892937660217285
Validation loss: 2.5283934147127214

Epoch: 5| Step: 1
Training loss: 3.3520679473876953
Validation loss: 2.524609855426255

Epoch: 5| Step: 2
Training loss: 2.1849236488342285
Validation loss: 2.524844761817686

Epoch: 5| Step: 3
Training loss: 2.9514355659484863
Validation loss: 2.517508581120481

Epoch: 5| Step: 4
Training loss: 2.3899002075195312
Validation loss: 2.515829211922102

Epoch: 5| Step: 5
Training loss: 2.871809244155884
Validation loss: 2.51468385675902

Epoch: 5| Step: 6
Training loss: 2.652984142303467
Validation loss: 2.518992470156762

Epoch: 5| Step: 7
Training loss: 2.6958374977111816
Validation loss: 2.515887878274405

Epoch: 5| Step: 8
Training loss: 2.52958345413208
Validation loss: 2.5121365670234925

Epoch: 5| Step: 9
Training loss: 3.0593178272247314
Validation loss: 2.5124313574965282

Epoch: 5| Step: 10
Training loss: 2.1733603477478027
Validation loss: 2.508583789230675

Epoch: 74| Step: 0
Training loss: 2.571174144744873
Validation loss: 2.5100624971492316

Epoch: 5| Step: 1
Training loss: 2.86279296875
Validation loss: 2.5098095709277737

Epoch: 5| Step: 2
Training loss: 2.745919704437256
Validation loss: 2.5117091517294607

Epoch: 5| Step: 3
Training loss: 2.86191725730896
Validation loss: 2.510861794153849

Epoch: 5| Step: 4
Training loss: 2.561336040496826
Validation loss: 2.5119674026325183

Epoch: 5| Step: 5
Training loss: 3.368932008743286
Validation loss: 2.5135919150485786

Epoch: 5| Step: 6
Training loss: 2.7715747356414795
Validation loss: 2.5128604571024575

Epoch: 5| Step: 7
Training loss: 2.557013988494873
Validation loss: 2.510459625592796

Epoch: 5| Step: 8
Training loss: 2.635786771774292
Validation loss: 2.5072703540966077

Epoch: 5| Step: 9
Training loss: 2.5641849040985107
Validation loss: 2.509141351587029

Epoch: 5| Step: 10
Training loss: 2.12172794342041
Validation loss: 2.5084059392252276

Epoch: 75| Step: 0
Training loss: 2.4655628204345703
Validation loss: 2.5074903477904615

Epoch: 5| Step: 1
Training loss: 2.9888100624084473
Validation loss: 2.5123976174221245

Epoch: 5| Step: 2
Training loss: 2.775759696960449
Validation loss: 2.5088065080745245

Epoch: 5| Step: 3
Training loss: 2.489772081375122
Validation loss: 2.5077715894227386

Epoch: 5| Step: 4
Training loss: 2.3733067512512207
Validation loss: 2.5059548706136723

Epoch: 5| Step: 5
Training loss: 3.171325206756592
Validation loss: 2.5062445107326714

Epoch: 5| Step: 6
Training loss: 2.7199158668518066
Validation loss: 2.5057299008933445

Epoch: 5| Step: 7
Training loss: 3.0016415119171143
Validation loss: 2.506291086955737

Epoch: 5| Step: 8
Training loss: 1.9833672046661377
Validation loss: 2.5081151890498337

Epoch: 5| Step: 9
Training loss: 2.946103096008301
Validation loss: 2.5177486301750265

Epoch: 5| Step: 10
Training loss: 2.7422091960906982
Validation loss: 2.5127739880674627

Epoch: 76| Step: 0
Training loss: 2.772878408432007
Validation loss: 2.514544084507932

Epoch: 5| Step: 1
Training loss: 2.990126848220825
Validation loss: 2.513977325090798

Epoch: 5| Step: 2
Training loss: 2.1825833320617676
Validation loss: 2.5096186181550384

Epoch: 5| Step: 3
Training loss: 1.9428861141204834
Validation loss: 2.5036577024767475

Epoch: 5| Step: 4
Training loss: 2.323561906814575
Validation loss: 2.502810726883591

Epoch: 5| Step: 5
Training loss: 2.6105220317840576
Validation loss: 2.4989562393516622

Epoch: 5| Step: 6
Training loss: 2.843576669692993
Validation loss: 2.5028020899782897

Epoch: 5| Step: 7
Training loss: 2.9557652473449707
Validation loss: 2.5029551854697605

Epoch: 5| Step: 8
Training loss: 3.6005616188049316
Validation loss: 2.508300778686359

Epoch: 5| Step: 9
Training loss: 2.7759013175964355
Validation loss: 2.5038297099451863

Epoch: 5| Step: 10
Training loss: 2.7026138305664062
Validation loss: 2.4993452077270835

Epoch: 77| Step: 0
Training loss: 3.1359610557556152
Validation loss: 2.4996790488560996

Epoch: 5| Step: 1
Training loss: 3.5858306884765625
Validation loss: 2.4971371389204458

Epoch: 5| Step: 2
Training loss: 2.6287407875061035
Validation loss: 2.4956928491592407

Epoch: 5| Step: 3
Training loss: 2.4788002967834473
Validation loss: 2.4968303454819547

Epoch: 5| Step: 4
Training loss: 2.487854480743408
Validation loss: 2.496403217315674

Epoch: 5| Step: 5
Training loss: 1.8868415355682373
Validation loss: 2.4969629318483415

Epoch: 5| Step: 6
Training loss: 2.5593714714050293
Validation loss: 2.5041407487725698

Epoch: 5| Step: 7
Training loss: 2.7569007873535156
Validation loss: 2.5167321594812537

Epoch: 5| Step: 8
Training loss: 2.812849521636963
Validation loss: 2.5260909244578373

Epoch: 5| Step: 9
Training loss: 2.665954113006592
Validation loss: 2.52871012431319

Epoch: 5| Step: 10
Training loss: 2.599475383758545
Validation loss: 2.528435643001269

Epoch: 78| Step: 0
Training loss: 1.8898786306381226
Validation loss: 2.523120795526812

Epoch: 5| Step: 1
Training loss: 3.3345093727111816
Validation loss: 2.5228286020217405

Epoch: 5| Step: 2
Training loss: 3.2723212242126465
Validation loss: 2.5104440617304977

Epoch: 5| Step: 3
Training loss: 2.704531669616699
Validation loss: 2.497105121612549

Epoch: 5| Step: 4
Training loss: 2.364333391189575
Validation loss: 2.4937975329737507

Epoch: 5| Step: 5
Training loss: 3.053619861602783
Validation loss: 2.4928721945772887

Epoch: 5| Step: 6
Training loss: 2.966548204421997
Validation loss: 2.489954138314852

Epoch: 5| Step: 7
Training loss: 2.119938373565674
Validation loss: 2.4921092499968824

Epoch: 5| Step: 8
Training loss: 2.7936954498291016
Validation loss: 2.4930851305684736

Epoch: 5| Step: 9
Training loss: 2.4857003688812256
Validation loss: 2.491507504575996

Epoch: 5| Step: 10
Training loss: 2.5939509868621826
Validation loss: 2.492828128158405

Epoch: 79| Step: 0
Training loss: 3.1938650608062744
Validation loss: 2.496356753892796

Epoch: 5| Step: 1
Training loss: 2.0945427417755127
Validation loss: 2.4889180352610927

Epoch: 5| Step: 2
Training loss: 2.793447971343994
Validation loss: 2.4878336793632916

Epoch: 5| Step: 3
Training loss: 2.7698357105255127
Validation loss: 2.4924126055932816

Epoch: 5| Step: 4
Training loss: 2.6124227046966553
Validation loss: 2.5011238923636814

Epoch: 5| Step: 5
Training loss: 3.114436388015747
Validation loss: 2.518168373774457

Epoch: 5| Step: 6
Training loss: 2.7135894298553467
Validation loss: 2.5075247646659933

Epoch: 5| Step: 7
Training loss: 2.8513848781585693
Validation loss: 2.504294136519073

Epoch: 5| Step: 8
Training loss: 2.7733302116394043
Validation loss: 2.490888741708571

Epoch: 5| Step: 9
Training loss: 2.199056625366211
Validation loss: 2.4896045936051237

Epoch: 5| Step: 10
Training loss: 2.4059641361236572
Validation loss: 2.4885005310017574

Epoch: 80| Step: 0
Training loss: 2.257023334503174
Validation loss: 2.4887148923771356

Epoch: 5| Step: 1
Training loss: 3.032747745513916
Validation loss: 2.4933121896559194

Epoch: 5| Step: 2
Training loss: 2.7615578174591064
Validation loss: 2.4959413748915478

Epoch: 5| Step: 3
Training loss: 2.8734078407287598
Validation loss: 2.4986699447836926

Epoch: 5| Step: 4
Training loss: 2.722425937652588
Validation loss: 2.50183976850202

Epoch: 5| Step: 5
Training loss: 3.0355217456817627
Validation loss: 2.5016064464405017

Epoch: 5| Step: 6
Training loss: 2.122056245803833
Validation loss: 2.494956911251109

Epoch: 5| Step: 7
Training loss: 2.6093852519989014
Validation loss: 2.4945836503018617

Epoch: 5| Step: 8
Training loss: 2.317584276199341
Validation loss: 2.495610898540866

Epoch: 5| Step: 9
Training loss: 2.975109815597534
Validation loss: 2.498305320739746

Epoch: 5| Step: 10
Training loss: 2.7204411029815674
Validation loss: 2.504454279458651

Epoch: 81| Step: 0
Training loss: 2.8907454013824463
Validation loss: 2.5189845408162763

Epoch: 5| Step: 1
Training loss: 2.9541611671447754
Validation loss: 2.5469467845014346

Epoch: 5| Step: 2
Training loss: 3.8280892372131348
Validation loss: 2.526255774241622

Epoch: 5| Step: 3
Training loss: 2.3613409996032715
Validation loss: 2.5195701147920344

Epoch: 5| Step: 4
Training loss: 2.1871604919433594
Validation loss: 2.5296736609551216

Epoch: 5| Step: 5
Training loss: 2.6463279724121094
Validation loss: 2.576000121331984

Epoch: 5| Step: 6
Training loss: 2.592451572418213
Validation loss: 2.5308480160210722

Epoch: 5| Step: 7
Training loss: 2.2506299018859863
Validation loss: 2.5186055680756927

Epoch: 5| Step: 8
Training loss: 2.6033928394317627
Validation loss: 2.5059281164600002

Epoch: 5| Step: 9
Training loss: 2.934394359588623
Validation loss: 2.49512465025789

Epoch: 5| Step: 10
Training loss: 2.4586267471313477
Validation loss: 2.4870318622999292

Epoch: 82| Step: 0
Training loss: 2.916618824005127
Validation loss: 2.488092848049697

Epoch: 5| Step: 1
Training loss: 2.4002411365509033
Validation loss: 2.4880873772405807

Epoch: 5| Step: 2
Training loss: 3.092724323272705
Validation loss: 2.4849985978936635

Epoch: 5| Step: 3
Training loss: 2.2083611488342285
Validation loss: 2.4871928486772763

Epoch: 5| Step: 4
Training loss: 1.8124818801879883
Validation loss: 2.4871562065616732

Epoch: 5| Step: 5
Training loss: 2.6974706649780273
Validation loss: 2.4883807679658294

Epoch: 5| Step: 6
Training loss: 3.1452245712280273
Validation loss: 2.485153741734002

Epoch: 5| Step: 7
Training loss: 2.7111644744873047
Validation loss: 2.4840797865262596

Epoch: 5| Step: 8
Training loss: 2.242872714996338
Validation loss: 2.4822233415419057

Epoch: 5| Step: 9
Training loss: 3.0824191570281982
Validation loss: 2.4838987678609867

Epoch: 5| Step: 10
Training loss: 3.393404722213745
Validation loss: 2.482314899403562

Epoch: 83| Step: 0
Training loss: 3.25148344039917
Validation loss: 2.481233517328898

Epoch: 5| Step: 1
Training loss: 1.9365917444229126
Validation loss: 2.4804440313769924

Epoch: 5| Step: 2
Training loss: 2.1837644577026367
Validation loss: 2.478935949264034

Epoch: 5| Step: 3
Training loss: 2.6577682495117188
Validation loss: 2.4778578794130715

Epoch: 5| Step: 4
Training loss: 2.4280285835266113
Validation loss: 2.475823320368285

Epoch: 5| Step: 5
Training loss: 2.743196725845337
Validation loss: 2.4768876670509257

Epoch: 5| Step: 6
Training loss: 2.909710168838501
Validation loss: 2.482147280887891

Epoch: 5| Step: 7
Training loss: 2.449094772338867
Validation loss: 2.4788732169776835

Epoch: 5| Step: 8
Training loss: 2.7223973274230957
Validation loss: 2.476123309904529

Epoch: 5| Step: 9
Training loss: 3.0639920234680176
Validation loss: 2.480610047617266

Epoch: 5| Step: 10
Training loss: 3.2737042903900146
Validation loss: 2.474513110294137

Epoch: 84| Step: 0
Training loss: 2.4349923133850098
Validation loss: 2.4781430023972706

Epoch: 5| Step: 1
Training loss: 3.1377146244049072
Validation loss: 2.476489705424155

Epoch: 5| Step: 2
Training loss: 2.878376007080078
Validation loss: 2.4730654737000823

Epoch: 5| Step: 3
Training loss: 2.343310594558716
Validation loss: 2.475380169448032

Epoch: 5| Step: 4
Training loss: 3.019740104675293
Validation loss: 2.475785591269052

Epoch: 5| Step: 5
Training loss: 2.7776694297790527
Validation loss: 2.471427312461279

Epoch: 5| Step: 6
Training loss: 2.7897703647613525
Validation loss: 2.4710206472745506

Epoch: 5| Step: 7
Training loss: 2.226269245147705
Validation loss: 2.4690324875616256

Epoch: 5| Step: 8
Training loss: 2.061134099960327
Validation loss: 2.4710195782364055

Epoch: 5| Step: 9
Training loss: 3.152378559112549
Validation loss: 2.47119523761093

Epoch: 5| Step: 10
Training loss: 2.6633074283599854
Validation loss: 2.4737930144033125

Epoch: 85| Step: 0
Training loss: 3.0726146697998047
Validation loss: 2.4700920299817155

Epoch: 5| Step: 1
Training loss: 2.311079502105713
Validation loss: 2.471689454970821

Epoch: 5| Step: 2
Training loss: 2.692584753036499
Validation loss: 2.47081002625086

Epoch: 5| Step: 3
Training loss: 2.790654420852661
Validation loss: 2.474004678828742

Epoch: 5| Step: 4
Training loss: 2.3450589179992676
Validation loss: 2.4732939145898305

Epoch: 5| Step: 5
Training loss: 2.677999496459961
Validation loss: 2.478200397183818

Epoch: 5| Step: 6
Training loss: 2.915184736251831
Validation loss: 2.483831436403336

Epoch: 5| Step: 7
Training loss: 2.5670690536499023
Validation loss: 2.48769550682396

Epoch: 5| Step: 8
Training loss: 2.3985893726348877
Validation loss: 2.491112862863848

Epoch: 5| Step: 9
Training loss: 3.527966260910034
Validation loss: 2.489989008954776

Epoch: 5| Step: 10
Training loss: 2.1093060970306396
Validation loss: 2.485990201273272

Epoch: 86| Step: 0
Training loss: 3.062776565551758
Validation loss: 2.4792277582230104

Epoch: 5| Step: 1
Training loss: 3.0205917358398438
Validation loss: 2.475186668416505

Epoch: 5| Step: 2
Training loss: 2.358344316482544
Validation loss: 2.4693209971151044

Epoch: 5| Step: 3
Training loss: 2.6834213733673096
Validation loss: 2.4740158947565223

Epoch: 5| Step: 4
Training loss: 2.9319705963134766
Validation loss: 2.466597128939885

Epoch: 5| Step: 5
Training loss: 3.416072368621826
Validation loss: 2.468789851793679

Epoch: 5| Step: 6
Training loss: 2.2325596809387207
Validation loss: 2.465181945472635

Epoch: 5| Step: 7
Training loss: 2.14555025100708
Validation loss: 2.464914068098991

Epoch: 5| Step: 8
Training loss: 2.4815282821655273
Validation loss: 2.467846155166626

Epoch: 5| Step: 9
Training loss: 2.7043488025665283
Validation loss: 2.464365654094245

Epoch: 5| Step: 10
Training loss: 2.304489850997925
Validation loss: 2.4651679454311246

Epoch: 87| Step: 0
Training loss: 2.5773754119873047
Validation loss: 2.4643803258096018

Epoch: 5| Step: 1
Training loss: 2.7356278896331787
Validation loss: 2.4678525873409805

Epoch: 5| Step: 2
Training loss: 2.1789050102233887
Validation loss: 2.4665762019413773

Epoch: 5| Step: 3
Training loss: 2.290358066558838
Validation loss: 2.4630290436488327

Epoch: 5| Step: 4
Training loss: 3.203730821609497
Validation loss: 2.4648777874567176

Epoch: 5| Step: 5
Training loss: 2.5067718029022217
Validation loss: 2.471362626680764

Epoch: 5| Step: 6
Training loss: 2.6775894165039062
Validation loss: 2.4683534522210397

Epoch: 5| Step: 7
Training loss: 3.2506160736083984
Validation loss: 2.4698556366787163

Epoch: 5| Step: 8
Training loss: 2.568474054336548
Validation loss: 2.465951960573914

Epoch: 5| Step: 9
Training loss: 2.422468662261963
Validation loss: 2.4659323256502867

Epoch: 5| Step: 10
Training loss: 3.0436341762542725
Validation loss: 2.463252834094468

Epoch: 88| Step: 0
Training loss: 2.2836813926696777
Validation loss: 2.464614196490216

Epoch: 5| Step: 1
Training loss: 2.723874568939209
Validation loss: 2.4663760123714322

Epoch: 5| Step: 2
Training loss: 2.5355401039123535
Validation loss: 2.4713245848173737

Epoch: 5| Step: 3
Training loss: 2.1742334365844727
Validation loss: 2.481259669027021

Epoch: 5| Step: 4
Training loss: 2.847266674041748
Validation loss: 2.483684819231751

Epoch: 5| Step: 5
Training loss: 2.190424919128418
Validation loss: 2.496189691687143

Epoch: 5| Step: 6
Training loss: 2.9826645851135254
Validation loss: 2.504181677295316

Epoch: 5| Step: 7
Training loss: 2.881173849105835
Validation loss: 2.505821058827062

Epoch: 5| Step: 8
Training loss: 2.8749022483825684
Validation loss: 2.489561629551713

Epoch: 5| Step: 9
Training loss: 2.960658073425293
Validation loss: 2.472682617043936

Epoch: 5| Step: 10
Training loss: 3.0686819553375244
Validation loss: 2.4639819565639702

Epoch: 89| Step: 0
Training loss: 2.2516865730285645
Validation loss: 2.4607723912885113

Epoch: 5| Step: 1
Training loss: 2.0367789268493652
Validation loss: 2.4693302749305643

Epoch: 5| Step: 2
Training loss: 2.29241943359375
Validation loss: 2.4793810639330136

Epoch: 5| Step: 3
Training loss: 3.0177180767059326
Validation loss: 2.482371953225905

Epoch: 5| Step: 4
Training loss: 2.669618606567383
Validation loss: 2.482917598498765

Epoch: 5| Step: 5
Training loss: 2.7633137702941895
Validation loss: 2.4807901741355978

Epoch: 5| Step: 6
Training loss: 2.8610098361968994
Validation loss: 2.4715501569932505

Epoch: 5| Step: 7
Training loss: 2.8056342601776123
Validation loss: 2.4660112498908915

Epoch: 5| Step: 8
Training loss: 2.7443361282348633
Validation loss: 2.4611020370196273

Epoch: 5| Step: 9
Training loss: 2.5958504676818848
Validation loss: 2.465318843882571

Epoch: 5| Step: 10
Training loss: 3.6587865352630615
Validation loss: 2.470747532383088

Epoch: 90| Step: 0
Training loss: 2.7842681407928467
Validation loss: 2.4686432525675785

Epoch: 5| Step: 1
Training loss: 2.2683472633361816
Validation loss: 2.468732951789774

Epoch: 5| Step: 2
Training loss: 3.3230228424072266
Validation loss: 2.480815338832076

Epoch: 5| Step: 3
Training loss: 3.086625337600708
Validation loss: 2.4914100913591284

Epoch: 5| Step: 4
Training loss: 2.5666794776916504
Validation loss: 2.4873930177380963

Epoch: 5| Step: 5
Training loss: 2.118251323699951
Validation loss: 2.476347992497106

Epoch: 5| Step: 6
Training loss: 2.520251512527466
Validation loss: 2.471632065311555

Epoch: 5| Step: 7
Training loss: 2.4296648502349854
Validation loss: 2.46029390827302

Epoch: 5| Step: 8
Training loss: 3.040931463241577
Validation loss: 2.4589867540585097

Epoch: 5| Step: 9
Training loss: 2.5514607429504395
Validation loss: 2.453151649044406

Epoch: 5| Step: 10
Training loss: 2.827533483505249
Validation loss: 2.4511820141987135

Epoch: 91| Step: 0
Training loss: 2.6530115604400635
Validation loss: 2.4525950288259857

Epoch: 5| Step: 1
Training loss: 2.906123161315918
Validation loss: 2.4570073004691833

Epoch: 5| Step: 2
Training loss: 2.418591022491455
Validation loss: 2.4534077644348145

Epoch: 5| Step: 3
Training loss: 2.9385437965393066
Validation loss: 2.4543052552848734

Epoch: 5| Step: 4
Training loss: 2.877110719680786
Validation loss: 2.452309403368222

Epoch: 5| Step: 5
Training loss: 3.4237022399902344
Validation loss: 2.452997185850656

Epoch: 5| Step: 6
Training loss: 2.781435251235962
Validation loss: 2.453313687796234

Epoch: 5| Step: 7
Training loss: 1.935441255569458
Validation loss: 2.450762635918074

Epoch: 5| Step: 8
Training loss: 2.615046977996826
Validation loss: 2.4492454285262735

Epoch: 5| Step: 9
Training loss: 2.210923910140991
Validation loss: 2.4490187065575713

Epoch: 5| Step: 10
Training loss: 2.624302387237549
Validation loss: 2.4524771423750025

Epoch: 92| Step: 0
Training loss: 3.1533093452453613
Validation loss: 2.4521621760501655

Epoch: 5| Step: 1
Training loss: 2.2000083923339844
Validation loss: 2.457853373660836

Epoch: 5| Step: 2
Training loss: 2.5588526725769043
Validation loss: 2.4554458433581936

Epoch: 5| Step: 3
Training loss: 3.278796672821045
Validation loss: 2.465024448210193

Epoch: 5| Step: 4
Training loss: 2.812192916870117
Validation loss: 2.469975450987457

Epoch: 5| Step: 5
Training loss: 2.1141197681427
Validation loss: 2.4744616016264884

Epoch: 5| Step: 6
Training loss: 2.8969104290008545
Validation loss: 2.474556674239456

Epoch: 5| Step: 7
Training loss: 2.4628777503967285
Validation loss: 2.4733255806789605

Epoch: 5| Step: 8
Training loss: 2.3320717811584473
Validation loss: 2.464554250881236

Epoch: 5| Step: 9
Training loss: 2.6749861240386963
Validation loss: 2.461562177186371

Epoch: 5| Step: 10
Training loss: 2.953572988510132
Validation loss: 2.4521323557822936

Epoch: 93| Step: 0
Training loss: 2.1736416816711426
Validation loss: 2.4509696088811403

Epoch: 5| Step: 1
Training loss: 2.411224603652954
Validation loss: 2.4441216761066067

Epoch: 5| Step: 2
Training loss: 2.4245901107788086
Validation loss: 2.4437302312543316

Epoch: 5| Step: 3
Training loss: 2.7533154487609863
Validation loss: 2.444895775087418

Epoch: 5| Step: 4
Training loss: 3.088951587677002
Validation loss: 2.4445798909792336

Epoch: 5| Step: 5
Training loss: 2.842255115509033
Validation loss: 2.4427952689509236

Epoch: 5| Step: 6
Training loss: 2.374079942703247
Validation loss: 2.444829176830989

Epoch: 5| Step: 7
Training loss: 3.014334201812744
Validation loss: 2.4438714237623316

Epoch: 5| Step: 8
Training loss: 2.794290065765381
Validation loss: 2.446919147686292

Epoch: 5| Step: 9
Training loss: 2.788215160369873
Validation loss: 2.445402342786071

Epoch: 5| Step: 10
Training loss: 2.6833009719848633
Validation loss: 2.440044051857405

Epoch: 94| Step: 0
Training loss: 3.2800700664520264
Validation loss: 2.441852620852891

Epoch: 5| Step: 1
Training loss: 2.827578067779541
Validation loss: 2.440647340589954

Epoch: 5| Step: 2
Training loss: 2.76947283744812
Validation loss: 2.444778142436858

Epoch: 5| Step: 3
Training loss: 2.0442299842834473
Validation loss: 2.446888751881097

Epoch: 5| Step: 4
Training loss: 2.334874391555786
Validation loss: 2.44465733087191

Epoch: 5| Step: 5
Training loss: 2.4196038246154785
Validation loss: 2.4494222953755367

Epoch: 5| Step: 6
Training loss: 2.989440679550171
Validation loss: 2.454938611676616

Epoch: 5| Step: 7
Training loss: 2.919471502304077
Validation loss: 2.4608890420647076

Epoch: 5| Step: 8
Training loss: 2.3384575843811035
Validation loss: 2.4634690900002756

Epoch: 5| Step: 9
Training loss: 3.348787784576416
Validation loss: 2.466200597824589

Epoch: 5| Step: 10
Training loss: 1.9088819026947021
Validation loss: 2.4607229822425434

Epoch: 95| Step: 0
Training loss: 2.009244203567505
Validation loss: 2.4575511229935514

Epoch: 5| Step: 1
Training loss: 3.039519786834717
Validation loss: 2.4468148703216226

Epoch: 5| Step: 2
Training loss: 2.6528897285461426
Validation loss: 2.439391915516187

Epoch: 5| Step: 3
Training loss: 2.7438971996307373
Validation loss: 2.4421109922470583

Epoch: 5| Step: 4
Training loss: 2.964139699935913
Validation loss: 2.439017422737614

Epoch: 5| Step: 5
Training loss: 2.747443675994873
Validation loss: 2.438013325455368

Epoch: 5| Step: 6
Training loss: 3.1192984580993652
Validation loss: 2.4372266697627243

Epoch: 5| Step: 7
Training loss: 2.234955072402954
Validation loss: 2.437814102377943

Epoch: 5| Step: 8
Training loss: 2.157930374145508
Validation loss: 2.438737110425067

Epoch: 5| Step: 9
Training loss: 2.4852423667907715
Validation loss: 2.438914542557091

Epoch: 5| Step: 10
Training loss: 3.2363810539245605
Validation loss: 2.4383281687254548

Epoch: 96| Step: 0
Training loss: 2.776337146759033
Validation loss: 2.436886892523817

Epoch: 5| Step: 1
Training loss: 3.2730801105499268
Validation loss: 2.4351433836003786

Epoch: 5| Step: 2
Training loss: 2.3824238777160645
Validation loss: 2.435767650604248

Epoch: 5| Step: 3
Training loss: 2.665290355682373
Validation loss: 2.4369689444059968

Epoch: 5| Step: 4
Training loss: 2.8687169551849365
Validation loss: 2.4361895540709138

Epoch: 5| Step: 5
Training loss: 2.579216241836548
Validation loss: 2.4387491646633355

Epoch: 5| Step: 6
Training loss: 2.17354154586792
Validation loss: 2.437892275471841

Epoch: 5| Step: 7
Training loss: 3.0750904083251953
Validation loss: 2.4372180046573764

Epoch: 5| Step: 8
Training loss: 2.983781337738037
Validation loss: 2.440185408438406

Epoch: 5| Step: 9
Training loss: 2.270052433013916
Validation loss: 2.438831877964799

Epoch: 5| Step: 10
Training loss: 2.1381821632385254
Validation loss: 2.437675655529063

Epoch: 97| Step: 0
Training loss: 2.468398332595825
Validation loss: 2.438881786920691

Epoch: 5| Step: 1
Training loss: 2.5979807376861572
Validation loss: 2.4356387199894076

Epoch: 5| Step: 2
Training loss: 2.3283302783966064
Validation loss: 2.4383839561093237

Epoch: 5| Step: 3
Training loss: 2.934905529022217
Validation loss: 2.4401422162209787

Epoch: 5| Step: 4
Training loss: 2.4909777641296387
Validation loss: 2.441651166126292

Epoch: 5| Step: 5
Training loss: 2.6201508045196533
Validation loss: 2.4453803211130123

Epoch: 5| Step: 6
Training loss: 3.139322519302368
Validation loss: 2.4424740524702173

Epoch: 5| Step: 7
Training loss: 2.605759620666504
Validation loss: 2.436543046787221

Epoch: 5| Step: 8
Training loss: 2.9143741130828857
Validation loss: 2.438145681094098

Epoch: 5| Step: 9
Training loss: 2.4475529193878174
Validation loss: 2.437258456342964

Epoch: 5| Step: 10
Training loss: 2.7179510593414307
Validation loss: 2.4404646068490963

Epoch: 98| Step: 0
Training loss: 3.617764949798584
Validation loss: 2.438003196511217

Epoch: 5| Step: 1
Training loss: 2.44545578956604
Validation loss: 2.437838274945495

Epoch: 5| Step: 2
Training loss: 2.448047161102295
Validation loss: 2.44082631603364

Epoch: 5| Step: 3
Training loss: 2.66630220413208
Validation loss: 2.4395178005259526

Epoch: 5| Step: 4
Training loss: 2.4340100288391113
Validation loss: 2.442215472139338

Epoch: 5| Step: 5
Training loss: 2.060534954071045
Validation loss: 2.441945340043755

Epoch: 5| Step: 6
Training loss: 2.5044562816619873
Validation loss: 2.4480792912103797

Epoch: 5| Step: 7
Training loss: 3.6959128379821777
Validation loss: 2.439140381351594

Epoch: 5| Step: 8
Training loss: 2.251913070678711
Validation loss: 2.441175901761619

Epoch: 5| Step: 9
Training loss: 2.7680563926696777
Validation loss: 2.435725781225389

Epoch: 5| Step: 10
Training loss: 2.3033437728881836
Validation loss: 2.4390510820573374

Epoch: 99| Step: 0
Training loss: 3.0459728240966797
Validation loss: 2.435356201664094

Epoch: 5| Step: 1
Training loss: 1.833167314529419
Validation loss: 2.4342798263795915

Epoch: 5| Step: 2
Training loss: 2.5245373249053955
Validation loss: 2.4310981714597313

Epoch: 5| Step: 3
Training loss: 3.0110714435577393
Validation loss: 2.4348103487363426

Epoch: 5| Step: 4
Training loss: 2.9535512924194336
Validation loss: 2.435711286401236

Epoch: 5| Step: 5
Training loss: 2.2419962882995605
Validation loss: 2.4258681420356996

Epoch: 5| Step: 6
Training loss: 3.2723007202148438
Validation loss: 2.4333016641678347

Epoch: 5| Step: 7
Training loss: 2.309962749481201
Validation loss: 2.4298179918719875

Epoch: 5| Step: 8
Training loss: 3.080634593963623
Validation loss: 2.4305054756902877

Epoch: 5| Step: 9
Training loss: 2.5003726482391357
Validation loss: 2.4320821172447613

Epoch: 5| Step: 10
Training loss: 2.2567920684814453
Validation loss: 2.4375769681827997

Epoch: 100| Step: 0
Training loss: 2.435002326965332
Validation loss: 2.433903101951845

Epoch: 5| Step: 1
Training loss: 2.190425395965576
Validation loss: 2.447676320229807

Epoch: 5| Step: 2
Training loss: 2.2538437843322754
Validation loss: 2.4511556292092926

Epoch: 5| Step: 3
Training loss: 3.029879331588745
Validation loss: 2.444261089448006

Epoch: 5| Step: 4
Training loss: 2.364004611968994
Validation loss: 2.4404542420500066

Epoch: 5| Step: 5
Training loss: 2.5477166175842285
Validation loss: 2.4360106068272747

Epoch: 5| Step: 6
Training loss: 3.145685911178589
Validation loss: 2.4367274750945387

Epoch: 5| Step: 7
Training loss: 2.5224790573120117
Validation loss: 2.437495372628653

Epoch: 5| Step: 8
Training loss: 3.1507973670959473
Validation loss: 2.4300361999901394

Epoch: 5| Step: 9
Training loss: 2.425248622894287
Validation loss: 2.4302994538378972

Epoch: 5| Step: 10
Training loss: 3.123819589614868
Validation loss: 2.42355546387293

Epoch: 101| Step: 0
Training loss: 3.0859322547912598
Validation loss: 2.428312022198913

Epoch: 5| Step: 1
Training loss: 2.741549253463745
Validation loss: 2.424284017214211

Epoch: 5| Step: 2
Training loss: 3.01911997795105
Validation loss: 2.4282860448283534

Epoch: 5| Step: 3
Training loss: 1.9049625396728516
Validation loss: 2.428512183568811

Epoch: 5| Step: 4
Training loss: 2.589507818222046
Validation loss: 2.422795526442989

Epoch: 5| Step: 5
Training loss: 2.5677108764648438
Validation loss: 2.4267521827451644

Epoch: 5| Step: 6
Training loss: 2.8871331214904785
Validation loss: 2.4229578382225445

Epoch: 5| Step: 7
Training loss: 2.2376351356506348
Validation loss: 2.418710272799256

Epoch: 5| Step: 8
Training loss: 2.879150390625
Validation loss: 2.422548911904776

Epoch: 5| Step: 9
Training loss: 2.6574761867523193
Validation loss: 2.423595410521312

Epoch: 5| Step: 10
Training loss: 2.588256359100342
Validation loss: 2.4265308508308987

Epoch: 102| Step: 0
Training loss: 2.429171562194824
Validation loss: 2.4288448364503923

Epoch: 5| Step: 1
Training loss: 2.4694552421569824
Validation loss: 2.439535125609367

Epoch: 5| Step: 2
Training loss: 2.3918919563293457
Validation loss: 2.4475074301483812

Epoch: 5| Step: 3
Training loss: 2.010913372039795
Validation loss: 2.4665172458976827

Epoch: 5| Step: 4
Training loss: 3.4133689403533936
Validation loss: 2.4819403643249185

Epoch: 5| Step: 5
Training loss: 2.4472694396972656
Validation loss: 2.4612710578467256

Epoch: 5| Step: 6
Training loss: 2.204650402069092
Validation loss: 2.4540004884043047

Epoch: 5| Step: 7
Training loss: 2.7683603763580322
Validation loss: 2.437495275210309

Epoch: 5| Step: 8
Training loss: 3.436011791229248
Validation loss: 2.4389742112928823

Epoch: 5| Step: 9
Training loss: 2.6760642528533936
Validation loss: 2.4308579532049035

Epoch: 5| Step: 10
Training loss: 2.955919027328491
Validation loss: 2.4209453957055205

Epoch: 103| Step: 0
Training loss: 2.9489095211029053
Validation loss: 2.4202729809668755

Epoch: 5| Step: 1
Training loss: 2.5389652252197266
Validation loss: 2.420875369861562

Epoch: 5| Step: 2
Training loss: 2.7292439937591553
Validation loss: 2.417828518857238

Epoch: 5| Step: 3
Training loss: 2.502770185470581
Validation loss: 2.4151296589964177

Epoch: 5| Step: 4
Training loss: 2.4393463134765625
Validation loss: 2.414782190835604

Epoch: 5| Step: 5
Training loss: 2.2694334983825684
Validation loss: 2.415956522828789

Epoch: 5| Step: 6
Training loss: 2.3318305015563965
Validation loss: 2.4154741892250637

Epoch: 5| Step: 7
Training loss: 2.770538806915283
Validation loss: 2.4142255142170894

Epoch: 5| Step: 8
Training loss: 2.963649272918701
Validation loss: 2.4289195281203075

Epoch: 5| Step: 9
Training loss: 2.5130417346954346
Validation loss: 2.4414043118876796

Epoch: 5| Step: 10
Training loss: 3.0738887786865234
Validation loss: 2.4502517587395123

Epoch: 104| Step: 0
Training loss: 2.124061107635498
Validation loss: 2.45615211097143

Epoch: 5| Step: 1
Training loss: 2.1255440711975098
Validation loss: 2.4576862550550893

Epoch: 5| Step: 2
Training loss: 2.8753113746643066
Validation loss: 2.484061215513496

Epoch: 5| Step: 3
Training loss: 2.0871808528900146
Validation loss: 2.4926966749211794

Epoch: 5| Step: 4
Training loss: 2.4045639038085938
Validation loss: 2.4970359879155315

Epoch: 5| Step: 5
Training loss: 3.3488383293151855
Validation loss: 2.4897269023362028

Epoch: 5| Step: 6
Training loss: 3.025458812713623
Validation loss: 2.4704155434844313

Epoch: 5| Step: 7
Training loss: 3.0627708435058594
Validation loss: 2.4478036639510945

Epoch: 5| Step: 8
Training loss: 2.8724868297576904
Validation loss: 2.429777478659025

Epoch: 5| Step: 9
Training loss: 2.059279203414917
Validation loss: 2.423817034690611

Epoch: 5| Step: 10
Training loss: 3.3619518280029297
Validation loss: 2.4168081283569336

Epoch: 105| Step: 0
Training loss: 2.845595359802246
Validation loss: 2.4163137712786273

Epoch: 5| Step: 1
Training loss: 2.2139010429382324
Validation loss: 2.4130773108492614

Epoch: 5| Step: 2
Training loss: 2.663898468017578
Validation loss: 2.4171151166321128

Epoch: 5| Step: 3
Training loss: 2.8163444995880127
Validation loss: 2.4324976654462915

Epoch: 5| Step: 4
Training loss: 1.9504731893539429
Validation loss: 2.4369618405577955

Epoch: 5| Step: 5
Training loss: 2.3483963012695312
Validation loss: 2.4461470444997153

Epoch: 5| Step: 6
Training loss: 2.5755324363708496
Validation loss: 2.4656099504040134

Epoch: 5| Step: 7
Training loss: 3.199819803237915
Validation loss: 2.464380387336977

Epoch: 5| Step: 8
Training loss: 2.4097237586975098
Validation loss: 2.4563586763156358

Epoch: 5| Step: 9
Training loss: 2.759726047515869
Validation loss: 2.4409285181312153

Epoch: 5| Step: 10
Training loss: 3.511686325073242
Validation loss: 2.426471464095577

Epoch: 106| Step: 0
Training loss: 2.5830140113830566
Validation loss: 2.4162743937584663

Epoch: 5| Step: 1
Training loss: 2.9019532203674316
Validation loss: 2.4081392442026446

Epoch: 5| Step: 2
Training loss: 2.211702346801758
Validation loss: 2.4106924559480403

Epoch: 5| Step: 3
Training loss: 2.3323395252227783
Validation loss: 2.4067660916236138

Epoch: 5| Step: 4
Training loss: 2.7871079444885254
Validation loss: 2.405202563090991

Epoch: 5| Step: 5
Training loss: 3.102447986602783
Validation loss: 2.410585564951743

Epoch: 5| Step: 6
Training loss: 2.6876769065856934
Validation loss: 2.4040909582568752

Epoch: 5| Step: 7
Training loss: 3.1968612670898438
Validation loss: 2.406236958760087

Epoch: 5| Step: 8
Training loss: 1.9758411645889282
Validation loss: 2.4066631922157864

Epoch: 5| Step: 9
Training loss: 3.017972707748413
Validation loss: 2.404727074407762

Epoch: 5| Step: 10
Training loss: 2.1590442657470703
Validation loss: 2.4074611612545547

Epoch: 107| Step: 0
Training loss: 2.9489715099334717
Validation loss: 2.4081398851128033

Epoch: 5| Step: 1
Training loss: 2.314389705657959
Validation loss: 2.4104440442977415

Epoch: 5| Step: 2
Training loss: 2.915595293045044
Validation loss: 2.4134092638569493

Epoch: 5| Step: 3
Training loss: 2.236452102661133
Validation loss: 2.4136858755542385

Epoch: 5| Step: 4
Training loss: 2.645768404006958
Validation loss: 2.4218944939233924

Epoch: 5| Step: 5
Training loss: 2.535612106323242
Validation loss: 2.423265682753696

Epoch: 5| Step: 6
Training loss: 2.515444278717041
Validation loss: 2.427226371662591

Epoch: 5| Step: 7
Training loss: 2.987304925918579
Validation loss: 2.420731211221346

Epoch: 5| Step: 8
Training loss: 2.4210309982299805
Validation loss: 2.4227100572278424

Epoch: 5| Step: 9
Training loss: 2.6984305381774902
Validation loss: 2.4167347185073362

Epoch: 5| Step: 10
Training loss: 2.9059057235717773
Validation loss: 2.41761274491587

Epoch: 108| Step: 0
Training loss: 2.980989456176758
Validation loss: 2.412335785486365

Epoch: 5| Step: 1
Training loss: 2.994011402130127
Validation loss: 2.4137556757978214

Epoch: 5| Step: 2
Training loss: 2.607100248336792
Validation loss: 2.4143406729544363

Epoch: 5| Step: 3
Training loss: 2.778367042541504
Validation loss: 2.4060312317263697

Epoch: 5| Step: 4
Training loss: 2.168592929840088
Validation loss: 2.406140583817677

Epoch: 5| Step: 5
Training loss: 2.172642230987549
Validation loss: 2.400615084555841

Epoch: 5| Step: 6
Training loss: 2.593839645385742
Validation loss: 2.4050030605767363

Epoch: 5| Step: 7
Training loss: 2.697911024093628
Validation loss: 2.414272367313344

Epoch: 5| Step: 8
Training loss: 2.4280452728271484
Validation loss: 2.429982018727128

Epoch: 5| Step: 9
Training loss: 3.1298162937164307
Validation loss: 2.43110345127762

Epoch: 5| Step: 10
Training loss: 2.469305992126465
Validation loss: 2.4249990435056787

Epoch: 109| Step: 0
Training loss: 2.5198869705200195
Validation loss: 2.4264489348216722

Epoch: 5| Step: 1
Training loss: 2.4676616191864014
Validation loss: 2.414885905481154

Epoch: 5| Step: 2
Training loss: 2.546818256378174
Validation loss: 2.4080622503834386

Epoch: 5| Step: 3
Training loss: 2.340369939804077
Validation loss: 2.400762017055224

Epoch: 5| Step: 4
Training loss: 2.6656501293182373
Validation loss: 2.4010288856362783

Epoch: 5| Step: 5
Training loss: 2.7775514125823975
Validation loss: 2.400139670218191

Epoch: 5| Step: 6
Training loss: 2.730199098587036
Validation loss: 2.4005452766213367

Epoch: 5| Step: 7
Training loss: 3.7609901428222656
Validation loss: 2.4002500605839554

Epoch: 5| Step: 8
Training loss: 2.488662004470825
Validation loss: 2.4081519829329623

Epoch: 5| Step: 9
Training loss: 2.226449728012085
Validation loss: 2.4065529377229753

Epoch: 5| Step: 10
Training loss: 2.544271469116211
Validation loss: 2.4105051896905385

Epoch: 110| Step: 0
Training loss: 2.9843108654022217
Validation loss: 2.4091443143865114

Epoch: 5| Step: 1
Training loss: 3.1959946155548096
Validation loss: 2.409668484041768

Epoch: 5| Step: 2
Training loss: 2.4659807682037354
Validation loss: 2.4039993952679377

Epoch: 5| Step: 3
Training loss: 2.6615633964538574
Validation loss: 2.410611447467599

Epoch: 5| Step: 4
Training loss: 2.465345621109009
Validation loss: 2.4107181461908485

Epoch: 5| Step: 5
Training loss: 3.0585215091705322
Validation loss: 2.409006452047697

Epoch: 5| Step: 6
Training loss: 2.63472056388855
Validation loss: 2.4117184659486175

Epoch: 5| Step: 7
Training loss: 2.619251251220703
Validation loss: 2.4079822776138142

Epoch: 5| Step: 8
Training loss: 1.8427356481552124
Validation loss: 2.4145113883479947

Epoch: 5| Step: 9
Training loss: 2.6479849815368652
Validation loss: 2.412662772722142

Epoch: 5| Step: 10
Training loss: 2.3390932083129883
Validation loss: 2.4174125861096125

Epoch: 111| Step: 0
Training loss: 2.6045823097229004
Validation loss: 2.4098246687202045

Epoch: 5| Step: 1
Training loss: 3.0830390453338623
Validation loss: 2.4186715836166055

Epoch: 5| Step: 2
Training loss: 2.7402710914611816
Validation loss: 2.4075540086274505

Epoch: 5| Step: 3
Training loss: 2.7311813831329346
Validation loss: 2.4065666352548907

Epoch: 5| Step: 4
Training loss: 2.433431386947632
Validation loss: 2.4084183016131

Epoch: 5| Step: 5
Training loss: 2.4268898963928223
Validation loss: 2.4013909985942226

Epoch: 5| Step: 6
Training loss: 2.8827033042907715
Validation loss: 2.3989229535543792

Epoch: 5| Step: 7
Training loss: 2.5154128074645996
Validation loss: 2.4004163408792145

Epoch: 5| Step: 8
Training loss: 2.153160810470581
Validation loss: 2.3983525127492924

Epoch: 5| Step: 9
Training loss: 2.6770827770233154
Validation loss: 2.394873560115855

Epoch: 5| Step: 10
Training loss: 2.633702516555786
Validation loss: 2.397282051783736

Epoch: 112| Step: 0
Training loss: 2.3219151496887207
Validation loss: 2.40132535401211

Epoch: 5| Step: 1
Training loss: 2.2903285026550293
Validation loss: 2.3986645872874925

Epoch: 5| Step: 2
Training loss: 2.331601858139038
Validation loss: 2.4034954886282645

Epoch: 5| Step: 3
Training loss: 2.995100259780884
Validation loss: 2.4065072767196165

Epoch: 5| Step: 4
Training loss: 2.9006659984588623
Validation loss: 2.4042571411337903

Epoch: 5| Step: 5
Training loss: 2.828233003616333
Validation loss: 2.40654686445831

Epoch: 5| Step: 6
Training loss: 2.2513041496276855
Validation loss: 2.4024128144787205

Epoch: 5| Step: 7
Training loss: 3.059112787246704
Validation loss: 2.4124749911728727

Epoch: 5| Step: 8
Training loss: 2.7869372367858887
Validation loss: 2.407844917748564

Epoch: 5| Step: 9
Training loss: 2.178926944732666
Validation loss: 2.3990836425494124

Epoch: 5| Step: 10
Training loss: 2.9660563468933105
Validation loss: 2.4001120187902965

Epoch: 113| Step: 0
Training loss: 2.370574712753296
Validation loss: 2.395823729935513

Epoch: 5| Step: 1
Training loss: 2.216986894607544
Validation loss: 2.3945593654468493

Epoch: 5| Step: 2
Training loss: 2.6452109813690186
Validation loss: 2.3918842090073453

Epoch: 5| Step: 3
Training loss: 2.6781678199768066
Validation loss: 2.3935664392286733

Epoch: 5| Step: 4
Training loss: 2.7639317512512207
Validation loss: 2.390905587903915

Epoch: 5| Step: 5
Training loss: 2.7344589233398438
Validation loss: 2.3952904311559533

Epoch: 5| Step: 6
Training loss: 2.9051928520202637
Validation loss: 2.399632238572644

Epoch: 5| Step: 7
Training loss: 2.2607791423797607
Validation loss: 2.3944204033062024

Epoch: 5| Step: 8
Training loss: 3.0295984745025635
Validation loss: 2.3910173536628805

Epoch: 5| Step: 9
Training loss: 2.1891961097717285
Validation loss: 2.3916230868267756

Epoch: 5| Step: 10
Training loss: 3.1089236736297607
Validation loss: 2.38978289276041

Epoch: 114| Step: 0
Training loss: 2.438748836517334
Validation loss: 2.3961344098532074

Epoch: 5| Step: 1
Training loss: 2.452932119369507
Validation loss: 2.4017729092669744

Epoch: 5| Step: 2
Training loss: 2.50495982170105
Validation loss: 2.405841629992249

Epoch: 5| Step: 3
Training loss: 2.4682810306549072
Validation loss: 2.4121225674947104

Epoch: 5| Step: 4
Training loss: 2.694492816925049
Validation loss: 2.418832912239977

Epoch: 5| Step: 5
Training loss: 2.113649368286133
Validation loss: 2.4195916883407103

Epoch: 5| Step: 6
Training loss: 2.87211275100708
Validation loss: 2.408262921917823

Epoch: 5| Step: 7
Training loss: 2.403081178665161
Validation loss: 2.4125874875694193

Epoch: 5| Step: 8
Training loss: 3.472555160522461
Validation loss: 2.4146665808975056

Epoch: 5| Step: 9
Training loss: 3.315288543701172
Validation loss: 2.413748438640307

Epoch: 5| Step: 10
Training loss: 2.091792345046997
Validation loss: 2.4146024668088524

Epoch: 115| Step: 0
Training loss: 1.9385521411895752
Validation loss: 2.416717852315595

Epoch: 5| Step: 1
Training loss: 2.6381747722625732
Validation loss: 2.419204185085912

Epoch: 5| Step: 2
Training loss: 2.530529737472534
Validation loss: 2.4219614408349477

Epoch: 5| Step: 3
Training loss: 2.8525490760803223
Validation loss: 2.418169075442899

Epoch: 5| Step: 4
Training loss: 1.9521987438201904
Validation loss: 2.4115412107077976

Epoch: 5| Step: 5
Training loss: 3.15899395942688
Validation loss: 2.4110475535033853

Epoch: 5| Step: 6
Training loss: 2.1546225547790527
Validation loss: 2.406895773385161

Epoch: 5| Step: 7
Training loss: 3.294121503829956
Validation loss: 2.3991711460134035

Epoch: 5| Step: 8
Training loss: 2.5098559856414795
Validation loss: 2.398065055570295

Epoch: 5| Step: 9
Training loss: 3.0164523124694824
Validation loss: 2.400514523188273

Epoch: 5| Step: 10
Training loss: 2.7958052158355713
Validation loss: 2.396535950322305

Epoch: 116| Step: 0
Training loss: 2.5615592002868652
Validation loss: 2.4025715345977456

Epoch: 5| Step: 1
Training loss: 2.4467544555664062
Validation loss: 2.403670072555542

Epoch: 5| Step: 2
Training loss: 2.0919384956359863
Validation loss: 2.403207125202302

Epoch: 5| Step: 3
Training loss: 2.9726767539978027
Validation loss: 2.402467332860475

Epoch: 5| Step: 4
Training loss: 2.966419219970703
Validation loss: 2.3981981341556837

Epoch: 5| Step: 5
Training loss: 3.1885604858398438
Validation loss: 2.403210691226426

Epoch: 5| Step: 6
Training loss: 2.074622631072998
Validation loss: 2.390044278995965

Epoch: 5| Step: 7
Training loss: 2.512697696685791
Validation loss: 2.3888779429979223

Epoch: 5| Step: 8
Training loss: 2.214888095855713
Validation loss: 2.4023292628667687

Epoch: 5| Step: 9
Training loss: 2.7276835441589355
Validation loss: 2.436000193319013

Epoch: 5| Step: 10
Training loss: 3.1548244953155518
Validation loss: 2.470402958572552

Epoch: 117| Step: 0
Training loss: 2.0412895679473877
Validation loss: 2.473531917859149

Epoch: 5| Step: 1
Training loss: 3.226214647293091
Validation loss: 2.4696181064010947

Epoch: 5| Step: 2
Training loss: 2.6960606575012207
Validation loss: 2.4436309491434405

Epoch: 5| Step: 3
Training loss: 3.1157307624816895
Validation loss: 2.4065441649447203

Epoch: 5| Step: 4
Training loss: 2.1682798862457275
Validation loss: 2.3793562791680776

Epoch: 5| Step: 5
Training loss: 2.270298480987549
Validation loss: 2.382032048317694

Epoch: 5| Step: 6
Training loss: 2.587207794189453
Validation loss: 2.3899895401411158

Epoch: 5| Step: 7
Training loss: 2.6567883491516113
Validation loss: 2.4129573299038793

Epoch: 5| Step: 8
Training loss: 2.5383081436157227
Validation loss: 2.4008149613616285

Epoch: 5| Step: 9
Training loss: 2.480692148208618
Validation loss: 2.385044910574472

Epoch: 5| Step: 10
Training loss: 3.1749935150146484
Validation loss: 2.386872722256568

Epoch: 118| Step: 0
Training loss: 2.7190194129943848
Validation loss: 2.385461817505539

Epoch: 5| Step: 1
Training loss: 2.469895839691162
Validation loss: 2.379151513499598

Epoch: 5| Step: 2
Training loss: 2.299668788909912
Validation loss: 2.3794622011082147

Epoch: 5| Step: 3
Training loss: 2.1105241775512695
Validation loss: 2.3780478431332495

Epoch: 5| Step: 4
Training loss: 2.8087992668151855
Validation loss: 2.37703340284286

Epoch: 5| Step: 5
Training loss: 2.687051296234131
Validation loss: 2.3825346167369554

Epoch: 5| Step: 6
Training loss: 2.630862236022949
Validation loss: 2.385855290197557

Epoch: 5| Step: 7
Training loss: 3.370417356491089
Validation loss: 2.3937331143245903

Epoch: 5| Step: 8
Training loss: 2.717454433441162
Validation loss: 2.391899501123736

Epoch: 5| Step: 9
Training loss: 2.653099536895752
Validation loss: 2.3870701059218375

Epoch: 5| Step: 10
Training loss: 2.2813518047332764
Validation loss: 2.3898484322332565

Epoch: 119| Step: 0
Training loss: 2.602830410003662
Validation loss: 2.3889141492946173

Epoch: 5| Step: 1
Training loss: 2.8567066192626953
Validation loss: 2.393114120729508

Epoch: 5| Step: 2
Training loss: 2.3186776638031006
Validation loss: 2.397781861725674

Epoch: 5| Step: 3
Training loss: 2.841585636138916
Validation loss: 2.4010266924417145

Epoch: 5| Step: 4
Training loss: 2.799575090408325
Validation loss: 2.4049113386420795

Epoch: 5| Step: 5
Training loss: 2.4719960689544678
Validation loss: 2.422874827538767

Epoch: 5| Step: 6
Training loss: 2.6099693775177
Validation loss: 2.428208725426787

Epoch: 5| Step: 7
Training loss: 2.8428421020507812
Validation loss: 2.4216783892723823

Epoch: 5| Step: 8
Training loss: 2.5857186317443848
Validation loss: 2.3936196501537035

Epoch: 5| Step: 9
Training loss: 2.598529815673828
Validation loss: 2.3690508693777104

Epoch: 5| Step: 10
Training loss: 2.391230821609497
Validation loss: 2.367897008055

Epoch: 120| Step: 0
Training loss: 3.1501564979553223
Validation loss: 2.3653698608439457

Epoch: 5| Step: 1
Training loss: 2.5030064582824707
Validation loss: 2.370066022360197

Epoch: 5| Step: 2
Training loss: 2.730760335922241
Validation loss: 2.370781117869962

Epoch: 5| Step: 3
Training loss: 2.701537609100342
Validation loss: 2.3750911745973813

Epoch: 5| Step: 4
Training loss: 2.9588475227355957
Validation loss: 2.3757546742757163

Epoch: 5| Step: 5
Training loss: 2.4348866939544678
Validation loss: 2.3784141976346254

Epoch: 5| Step: 6
Training loss: 2.5153565406799316
Validation loss: 2.3701011980733564

Epoch: 5| Step: 7
Training loss: 2.3778538703918457
Validation loss: 2.368270081858481

Epoch: 5| Step: 8
Training loss: 2.654686450958252
Validation loss: 2.365182225422193

Epoch: 5| Step: 9
Training loss: 2.0891237258911133
Validation loss: 2.366132443951022

Epoch: 5| Step: 10
Training loss: 2.7061221599578857
Validation loss: 2.3750541030719714

Epoch: 121| Step: 0
Training loss: 2.8326728343963623
Validation loss: 2.3777639660783993

Epoch: 5| Step: 1
Training loss: 2.5351309776306152
Validation loss: 2.3853162129720054

Epoch: 5| Step: 2
Training loss: 2.628155469894409
Validation loss: 2.4007756120415142

Epoch: 5| Step: 3
Training loss: 2.305363178253174
Validation loss: 2.4045632475165912

Epoch: 5| Step: 4
Training loss: 2.6632437705993652
Validation loss: 2.412723672005438

Epoch: 5| Step: 5
Training loss: 2.4102344512939453
Validation loss: 2.4213484512862338

Epoch: 5| Step: 6
Training loss: 2.478233575820923
Validation loss: 2.421278502351494

Epoch: 5| Step: 7
Training loss: 2.1552376747131348
Validation loss: 2.4253233350733274

Epoch: 5| Step: 8
Training loss: 2.9324584007263184
Validation loss: 2.4176334181139545

Epoch: 5| Step: 9
Training loss: 2.650007724761963
Validation loss: 2.4255377887397684

Epoch: 5| Step: 10
Training loss: 3.272801160812378
Validation loss: 2.4390444447917323

Epoch: 122| Step: 0
Training loss: 2.797482967376709
Validation loss: 2.4306316427005235

Epoch: 5| Step: 1
Training loss: 2.5247244834899902
Validation loss: 2.4366239629765993

Epoch: 5| Step: 2
Training loss: 2.532007932662964
Validation loss: 2.430393208739578

Epoch: 5| Step: 3
Training loss: 2.412558078765869
Validation loss: 2.418900764116677

Epoch: 5| Step: 4
Training loss: 2.7070159912109375
Validation loss: 2.399520097240325

Epoch: 5| Step: 5
Training loss: 2.876171588897705
Validation loss: 2.380485975614158

Epoch: 5| Step: 6
Training loss: 2.4208011627197266
Validation loss: 2.3683993380556823

Epoch: 5| Step: 7
Training loss: 2.2977025508880615
Validation loss: 2.3836816818483415

Epoch: 5| Step: 8
Training loss: 2.5054450035095215
Validation loss: 2.3989653010522165

Epoch: 5| Step: 9
Training loss: 3.3909544944763184
Validation loss: 2.428925300157198

Epoch: 5| Step: 10
Training loss: 2.3743836879730225
Validation loss: 2.4242419683805077

Epoch: 123| Step: 0
Training loss: 2.739391803741455
Validation loss: 2.4713826538414083

Epoch: 5| Step: 1
Training loss: 2.700911283493042
Validation loss: 2.443670872719057

Epoch: 5| Step: 2
Training loss: 3.092283248901367
Validation loss: 2.411728940984254

Epoch: 5| Step: 3
Training loss: 2.254744291305542
Validation loss: 2.395379022885394

Epoch: 5| Step: 4
Training loss: 2.042245864868164
Validation loss: 2.3801136503937426

Epoch: 5| Step: 5
Training loss: 2.967306137084961
Validation loss: 2.3767703528045327

Epoch: 5| Step: 6
Training loss: 2.842160940170288
Validation loss: 2.3726165448465655

Epoch: 5| Step: 7
Training loss: 2.299980878829956
Validation loss: 2.3749703156050814

Epoch: 5| Step: 8
Training loss: 2.300680160522461
Validation loss: 2.3788273180684736

Epoch: 5| Step: 9
Training loss: 2.535126209259033
Validation loss: 2.3803560118521414

Epoch: 5| Step: 10
Training loss: 3.239572286605835
Validation loss: 2.3975894566505187

Epoch: 124| Step: 0
Training loss: 1.8791992664337158
Validation loss: 2.402197681447511

Epoch: 5| Step: 1
Training loss: 3.6161446571350098
Validation loss: 2.408763882934406

Epoch: 5| Step: 2
Training loss: 2.5794734954833984
Validation loss: 2.404088625343897

Epoch: 5| Step: 3
Training loss: 2.679633617401123
Validation loss: 2.3996329153737714

Epoch: 5| Step: 4
Training loss: 2.2663486003875732
Validation loss: 2.4010881659805134

Epoch: 5| Step: 5
Training loss: 2.428191661834717
Validation loss: 2.4035028834496774

Epoch: 5| Step: 6
Training loss: 2.8084139823913574
Validation loss: 2.4076812062212216

Epoch: 5| Step: 7
Training loss: 2.404360294342041
Validation loss: 2.401162924305085

Epoch: 5| Step: 8
Training loss: 2.450634717941284
Validation loss: 2.403217864292924

Epoch: 5| Step: 9
Training loss: 2.2975900173187256
Validation loss: 2.4030224943673737

Epoch: 5| Step: 10
Training loss: 3.3592910766601562
Validation loss: 2.4054608652668614

Epoch: 125| Step: 0
Training loss: 2.660240888595581
Validation loss: 2.4103431650387344

Epoch: 5| Step: 1
Training loss: 2.849306106567383
Validation loss: 2.4173222357226956

Epoch: 5| Step: 2
Training loss: 2.7075486183166504
Validation loss: 2.4198952900466097

Epoch: 5| Step: 3
Training loss: 2.6683974266052246
Validation loss: 2.4200150120642876

Epoch: 5| Step: 4
Training loss: 2.3631880283355713
Validation loss: 2.41259906881599

Epoch: 5| Step: 5
Training loss: 2.026838779449463
Validation loss: 2.4182959577088714

Epoch: 5| Step: 6
Training loss: 2.2791457176208496
Validation loss: 2.4165408278024323

Epoch: 5| Step: 7
Training loss: 3.2414746284484863
Validation loss: 2.392878496518699

Epoch: 5| Step: 8
Training loss: 2.9683165550231934
Validation loss: 2.3848744259085706

Epoch: 5| Step: 9
Training loss: 2.6489245891571045
Validation loss: 2.3795818026347826

Epoch: 5| Step: 10
Training loss: 2.3344757556915283
Validation loss: 2.3603858947753906

Epoch: 126| Step: 0
Training loss: 2.712627649307251
Validation loss: 2.358798183420653

Epoch: 5| Step: 1
Training loss: 2.6425557136535645
Validation loss: 2.3560385883495374

Epoch: 5| Step: 2
Training loss: 2.183518171310425
Validation loss: 2.3546608481355893

Epoch: 5| Step: 3
Training loss: 3.001213788986206
Validation loss: 2.3531790164209183

Epoch: 5| Step: 4
Training loss: 2.5587496757507324
Validation loss: 2.357512999606389

Epoch: 5| Step: 5
Training loss: 2.6553537845611572
Validation loss: 2.3563276337039087

Epoch: 5| Step: 6
Training loss: 2.9829025268554688
Validation loss: 2.3529063245301605

Epoch: 5| Step: 7
Training loss: 2.7772393226623535
Validation loss: 2.359448689286427

Epoch: 5| Step: 8
Training loss: 2.179067611694336
Validation loss: 2.3596503350042526

Epoch: 5| Step: 9
Training loss: 2.481192111968994
Validation loss: 2.3585283320437194

Epoch: 5| Step: 10
Training loss: 2.5357251167297363
Validation loss: 2.3599781772141815

Epoch: 127| Step: 0
Training loss: 2.2493927478790283
Validation loss: 2.3602635424624205

Epoch: 5| Step: 1
Training loss: 2.146141529083252
Validation loss: 2.3643983128250285

Epoch: 5| Step: 2
Training loss: 2.999211311340332
Validation loss: 2.3759760754082793

Epoch: 5| Step: 3
Training loss: 2.5747809410095215
Validation loss: 2.3946387075608775

Epoch: 5| Step: 4
Training loss: 2.5290868282318115
Validation loss: 2.400443446251654

Epoch: 5| Step: 5
Training loss: 2.1045942306518555
Validation loss: 2.3957452107501287

Epoch: 5| Step: 6
Training loss: 2.6791317462921143
Validation loss: 2.384454616936304

Epoch: 5| Step: 7
Training loss: 2.9421966075897217
Validation loss: 2.3805273373921714

Epoch: 5| Step: 8
Training loss: 2.711235523223877
Validation loss: 2.3917650150996383

Epoch: 5| Step: 9
Training loss: 3.2179348468780518
Validation loss: 2.3880182312380884

Epoch: 5| Step: 10
Training loss: 2.3919849395751953
Validation loss: 2.3786746865959576

Epoch: 128| Step: 0
Training loss: 2.447136402130127
Validation loss: 2.375064662707749

Epoch: 5| Step: 1
Training loss: 2.8904895782470703
Validation loss: 2.384141150341239

Epoch: 5| Step: 2
Training loss: 2.921342372894287
Validation loss: 2.389132550967637

Epoch: 5| Step: 3
Training loss: 2.517859935760498
Validation loss: 2.3924167412583546

Epoch: 5| Step: 4
Training loss: 2.4986984729766846
Validation loss: 2.394474885796988

Epoch: 5| Step: 5
Training loss: 2.5702106952667236
Validation loss: 2.3934339425897084

Epoch: 5| Step: 6
Training loss: 2.3833389282226562
Validation loss: 2.39979620902769

Epoch: 5| Step: 7
Training loss: 2.471177577972412
Validation loss: 2.3923440235917286

Epoch: 5| Step: 8
Training loss: 3.2162773609161377
Validation loss: 2.3820158063724475

Epoch: 5| Step: 9
Training loss: 2.390007972717285
Validation loss: 2.3731975965602423

Epoch: 5| Step: 10
Training loss: 2.3980114459991455
Validation loss: 2.3678046375192623

Epoch: 129| Step: 0
Training loss: 2.2758190631866455
Validation loss: 2.372052195251629

Epoch: 5| Step: 1
Training loss: 2.8012919425964355
Validation loss: 2.364383477036671

Epoch: 5| Step: 2
Training loss: 2.640096664428711
Validation loss: 2.3726374615905104

Epoch: 5| Step: 3
Training loss: 2.605985164642334
Validation loss: 2.3663462925982732

Epoch: 5| Step: 4
Training loss: 2.682103157043457
Validation loss: 2.3621002730502876

Epoch: 5| Step: 5
Training loss: 1.9951622486114502
Validation loss: 2.363389492034912

Epoch: 5| Step: 6
Training loss: 2.566977024078369
Validation loss: 2.3639417258642053

Epoch: 5| Step: 7
Training loss: 3.065335512161255
Validation loss: 2.3695520149764193

Epoch: 5| Step: 8
Training loss: 2.5738072395324707
Validation loss: 2.377402292784824

Epoch: 5| Step: 9
Training loss: 2.5216479301452637
Validation loss: 2.378745784041702

Epoch: 5| Step: 10
Training loss: 2.871500015258789
Validation loss: 2.3959218404626332

Epoch: 130| Step: 0
Training loss: 2.1447508335113525
Validation loss: 2.399041670624928

Epoch: 5| Step: 1
Training loss: 2.736497402191162
Validation loss: 2.412311497554984

Epoch: 5| Step: 2
Training loss: 2.831880807876587
Validation loss: 2.417963679118823

Epoch: 5| Step: 3
Training loss: 2.8895368576049805
Validation loss: 2.4100785973251506

Epoch: 5| Step: 4
Training loss: 2.2691237926483154
Validation loss: 2.388091646214967

Epoch: 5| Step: 5
Training loss: 2.218096971511841
Validation loss: 2.37955714297551

Epoch: 5| Step: 6
Training loss: 2.927422046661377
Validation loss: 2.362500831645022

Epoch: 5| Step: 7
Training loss: 2.306175947189331
Validation loss: 2.3541162642099525

Epoch: 5| Step: 8
Training loss: 3.1041512489318848
Validation loss: 2.3640042299865396

Epoch: 5| Step: 9
Training loss: 2.3435304164886475
Validation loss: 2.347058593585927

Epoch: 5| Step: 10
Training loss: 2.919442892074585
Validation loss: 2.361199786586146

Epoch: 131| Step: 0
Training loss: 2.616518497467041
Validation loss: 2.3558821216706307

Epoch: 5| Step: 1
Training loss: 3.11940860748291
Validation loss: 2.3560387062770065

Epoch: 5| Step: 2
Training loss: 2.9667415618896484
Validation loss: 2.347546987636115

Epoch: 5| Step: 3
Training loss: 3.1169891357421875
Validation loss: 2.340740091057234

Epoch: 5| Step: 4
Training loss: 2.1758363246917725
Validation loss: 2.3390880861589984

Epoch: 5| Step: 5
Training loss: 2.3558225631713867
Validation loss: 2.331653377061249

Epoch: 5| Step: 6
Training loss: 2.5059897899627686
Validation loss: 2.330200272221719

Epoch: 5| Step: 7
Training loss: 2.2102551460266113
Validation loss: 2.3310611799199092

Epoch: 5| Step: 8
Training loss: 2.9681782722473145
Validation loss: 2.334258464074904

Epoch: 5| Step: 9
Training loss: 2.1098434925079346
Validation loss: 2.327949745680696

Epoch: 5| Step: 10
Training loss: 2.4028918743133545
Validation loss: 2.3360439961956394

Epoch: 132| Step: 0
Training loss: 2.1545403003692627
Validation loss: 2.3335005955029557

Epoch: 5| Step: 1
Training loss: 2.572714328765869
Validation loss: 2.3383827568382345

Epoch: 5| Step: 2
Training loss: 2.299664258956909
Validation loss: 2.3454209912207817

Epoch: 5| Step: 3
Training loss: 2.1815335750579834
Validation loss: 2.3551552218775593

Epoch: 5| Step: 4
Training loss: 2.722343921661377
Validation loss: 2.3787098161635862

Epoch: 5| Step: 5
Training loss: 3.026207447052002
Validation loss: 2.3817777120938866

Epoch: 5| Step: 6
Training loss: 3.0065760612487793
Validation loss: 2.3683283816101732

Epoch: 5| Step: 7
Training loss: 2.915804386138916
Validation loss: 2.3526627812334286

Epoch: 5| Step: 8
Training loss: 3.0608506202697754
Validation loss: 2.343567837951004

Epoch: 5| Step: 9
Training loss: 2.0044641494750977
Validation loss: 2.334383697919948

Epoch: 5| Step: 10
Training loss: 2.704275131225586
Validation loss: 2.3249598715894964

Epoch: 133| Step: 0
Training loss: 2.4344427585601807
Validation loss: 2.3246562327108076

Epoch: 5| Step: 1
Training loss: 1.9025665521621704
Validation loss: 2.3248303949192004

Epoch: 5| Step: 2
Training loss: 2.947810173034668
Validation loss: 2.3273389749629523

Epoch: 5| Step: 3
Training loss: 2.769109010696411
Validation loss: 2.328425927828717

Epoch: 5| Step: 4
Training loss: 2.7083263397216797
Validation loss: 2.332639942887009

Epoch: 5| Step: 5
Training loss: 2.7882132530212402
Validation loss: 2.328563246675717

Epoch: 5| Step: 6
Training loss: 2.8223624229431152
Validation loss: 2.326155654845699

Epoch: 5| Step: 7
Training loss: 2.485175609588623
Validation loss: 2.328943601218603

Epoch: 5| Step: 8
Training loss: 2.0976529121398926
Validation loss: 2.323304581385787

Epoch: 5| Step: 9
Training loss: 2.9821724891662598
Validation loss: 2.3255204949327695

Epoch: 5| Step: 10
Training loss: 2.6785900592803955
Validation loss: 2.3211508822697464

Epoch: 134| Step: 0
Training loss: 2.557889461517334
Validation loss: 2.3210968945616033

Epoch: 5| Step: 1
Training loss: 2.605454206466675
Validation loss: 2.321635369331606

Epoch: 5| Step: 2
Training loss: 2.756574869155884
Validation loss: 2.324484891788934

Epoch: 5| Step: 3
Training loss: 2.569657325744629
Validation loss: 2.3288919759053055

Epoch: 5| Step: 4
Training loss: 2.6073875427246094
Validation loss: 2.327152657252486

Epoch: 5| Step: 5
Training loss: 2.889465093612671
Validation loss: 2.330270098101708

Epoch: 5| Step: 6
Training loss: 2.1670148372650146
Validation loss: 2.3288304011027017

Epoch: 5| Step: 7
Training loss: 2.7530665397644043
Validation loss: 2.3308425103464434

Epoch: 5| Step: 8
Training loss: 2.3764703273773193
Validation loss: 2.333194640374953

Epoch: 5| Step: 9
Training loss: 2.596714973449707
Validation loss: 2.3362516280143493

Epoch: 5| Step: 10
Training loss: 2.498776912689209
Validation loss: 2.333309793985018

Epoch: 135| Step: 0
Training loss: 2.6596922874450684
Validation loss: 2.343401575601229

Epoch: 5| Step: 1
Training loss: 2.879476547241211
Validation loss: 2.342357340679374

Epoch: 5| Step: 2
Training loss: 2.5823874473571777
Validation loss: 2.360522431711997

Epoch: 5| Step: 3
Training loss: 3.03261399269104
Validation loss: 2.362830259466684

Epoch: 5| Step: 4
Training loss: 3.0180671215057373
Validation loss: 2.355484706099315

Epoch: 5| Step: 5
Training loss: 2.219595193862915
Validation loss: 2.364106560266146

Epoch: 5| Step: 6
Training loss: 2.241090774536133
Validation loss: 2.355717961506177

Epoch: 5| Step: 7
Training loss: 2.3927407264709473
Validation loss: 2.3662608323558683

Epoch: 5| Step: 8
Training loss: 2.1094322204589844
Validation loss: 2.3500829383891118

Epoch: 5| Step: 9
Training loss: 2.68047833442688
Validation loss: 2.3454386957230104

Epoch: 5| Step: 10
Training loss: 2.5198814868927
Validation loss: 2.349166367643623

Epoch: 136| Step: 0
Training loss: 2.391148567199707
Validation loss: 2.33853655733088

Epoch: 5| Step: 1
Training loss: 2.725426197052002
Validation loss: 2.337864480992799

Epoch: 5| Step: 2
Training loss: 1.7568902969360352
Validation loss: 2.3393532717099754

Epoch: 5| Step: 3
Training loss: 2.3769237995147705
Validation loss: 2.334225918657036

Epoch: 5| Step: 4
Training loss: 2.6084301471710205
Validation loss: 2.335365113391671

Epoch: 5| Step: 5
Training loss: 2.137244462966919
Validation loss: 2.340223721278611

Epoch: 5| Step: 6
Training loss: 3.4027771949768066
Validation loss: 2.3412546573146695

Epoch: 5| Step: 7
Training loss: 3.1072564125061035
Validation loss: 2.334635780703637

Epoch: 5| Step: 8
Training loss: 2.5836825370788574
Validation loss: 2.3449023282656105

Epoch: 5| Step: 9
Training loss: 2.7793002128601074
Validation loss: 2.331999958202403

Epoch: 5| Step: 10
Training loss: 2.563072681427002
Validation loss: 2.32751323715333

Epoch: 137| Step: 0
Training loss: 2.0689916610717773
Validation loss: 2.336247380061816

Epoch: 5| Step: 1
Training loss: 2.3437342643737793
Validation loss: 2.3418144205565095

Epoch: 5| Step: 2
Training loss: 2.712481737136841
Validation loss: 2.349900637903521

Epoch: 5| Step: 3
Training loss: 2.6524624824523926
Validation loss: 2.350931421402962

Epoch: 5| Step: 4
Training loss: 2.8034539222717285
Validation loss: 2.348305002335579

Epoch: 5| Step: 5
Training loss: 2.2444698810577393
Validation loss: 2.3481781713424192

Epoch: 5| Step: 6
Training loss: 2.726384401321411
Validation loss: 2.354838935277795

Epoch: 5| Step: 7
Training loss: 2.9817728996276855
Validation loss: 2.3617242536237164

Epoch: 5| Step: 8
Training loss: 2.9063873291015625
Validation loss: 2.360682584906137

Epoch: 5| Step: 9
Training loss: 2.3430466651916504
Validation loss: 2.3579056955152944

Epoch: 5| Step: 10
Training loss: 2.6109225749969482
Validation loss: 2.3575910727183023

Epoch: 138| Step: 0
Training loss: 2.2968661785125732
Validation loss: 2.355267534973801

Epoch: 5| Step: 1
Training loss: 2.4180378913879395
Validation loss: 2.38338368169723

Epoch: 5| Step: 2
Training loss: 2.631333112716675
Validation loss: 2.38205720532325

Epoch: 5| Step: 3
Training loss: 2.4397263526916504
Validation loss: 2.392142370182981

Epoch: 5| Step: 4
Training loss: 3.139958381652832
Validation loss: 2.3917974810446463

Epoch: 5| Step: 5
Training loss: 2.8906095027923584
Validation loss: 2.3711258160170687

Epoch: 5| Step: 6
Training loss: 2.7700376510620117
Validation loss: 2.3592538756708943

Epoch: 5| Step: 7
Training loss: 2.6524016857147217
Validation loss: 2.3491439998790784

Epoch: 5| Step: 8
Training loss: 2.706937074661255
Validation loss: 2.3516145060139317

Epoch: 5| Step: 9
Training loss: 2.499600648880005
Validation loss: 2.361400565793437

Epoch: 5| Step: 10
Training loss: 1.8391611576080322
Validation loss: 2.3665713341005388

Epoch: 139| Step: 0
Training loss: 2.8704240322113037
Validation loss: 2.3817011182026198

Epoch: 5| Step: 1
Training loss: 2.8892974853515625
Validation loss: 2.396452885802074

Epoch: 5| Step: 2
Training loss: 3.0507636070251465
Validation loss: 2.4198199728483796

Epoch: 5| Step: 3
Training loss: 1.9364465475082397
Validation loss: 2.42111712373713

Epoch: 5| Step: 4
Training loss: 2.730900526046753
Validation loss: 2.3953681466399983

Epoch: 5| Step: 5
Training loss: 2.9741575717926025
Validation loss: 2.383011253931189

Epoch: 5| Step: 6
Training loss: 2.4859368801116943
Validation loss: 2.3387951133071736

Epoch: 5| Step: 7
Training loss: 2.697936534881592
Validation loss: 2.320440133412679

Epoch: 5| Step: 8
Training loss: 2.317349910736084
Validation loss: 2.3150829756131737

Epoch: 5| Step: 9
Training loss: 2.1197705268859863
Validation loss: 2.314853581049109

Epoch: 5| Step: 10
Training loss: 2.5626699924468994
Validation loss: 2.3127114593341784

Epoch: 140| Step: 0
Training loss: 2.5096561908721924
Validation loss: 2.3130127793999127

Epoch: 5| Step: 1
Training loss: 2.668360710144043
Validation loss: 2.323279719198904

Epoch: 5| Step: 2
Training loss: 2.394491672515869
Validation loss: 2.3260541526220178

Epoch: 5| Step: 3
Training loss: 2.935344934463501
Validation loss: 2.3317451169413905

Epoch: 5| Step: 4
Training loss: 2.878286600112915
Validation loss: 2.3355794478488225

Epoch: 5| Step: 5
Training loss: 2.709995985031128
Validation loss: 2.3394575913747153

Epoch: 5| Step: 6
Training loss: 2.731919765472412
Validation loss: 2.332718341581283

Epoch: 5| Step: 7
Training loss: 2.3249197006225586
Validation loss: 2.3258305031766175

Epoch: 5| Step: 8
Training loss: 2.2075793743133545
Validation loss: 2.322486421113373

Epoch: 5| Step: 9
Training loss: 2.4531614780426025
Validation loss: 2.320721705754598

Epoch: 5| Step: 10
Training loss: 2.5714821815490723
Validation loss: 2.332873646930982

Epoch: 141| Step: 0
Training loss: 2.059095859527588
Validation loss: 2.363330784664359

Epoch: 5| Step: 1
Training loss: 2.215615749359131
Validation loss: 2.3945294451969925

Epoch: 5| Step: 2
Training loss: 2.826279401779175
Validation loss: 2.3822007063896424

Epoch: 5| Step: 3
Training loss: 2.495151996612549
Validation loss: 2.3661822990704606

Epoch: 5| Step: 4
Training loss: 2.648658275604248
Validation loss: 2.3375660552773425

Epoch: 5| Step: 5
Training loss: 3.1099424362182617
Validation loss: 2.312352127926324

Epoch: 5| Step: 6
Training loss: 2.2928643226623535
Validation loss: 2.29966260797234

Epoch: 5| Step: 7
Training loss: 2.702221393585205
Validation loss: 2.3012834748914166

Epoch: 5| Step: 8
Training loss: 3.091815233230591
Validation loss: 2.301565001087804

Epoch: 5| Step: 9
Training loss: 2.009172201156616
Validation loss: 2.2989501260942027

Epoch: 5| Step: 10
Training loss: 3.1715424060821533
Validation loss: 2.3050279104581444

Epoch: 142| Step: 0
Training loss: 2.113013982772827
Validation loss: 2.3163058450145106

Epoch: 5| Step: 1
Training loss: 2.804124355316162
Validation loss: 2.320272960970479

Epoch: 5| Step: 2
Training loss: 2.9031057357788086
Validation loss: 2.3207934364195792

Epoch: 5| Step: 3
Training loss: 1.9530080556869507
Validation loss: 2.32695911904817

Epoch: 5| Step: 4
Training loss: 2.0871169567108154
Validation loss: 2.332176873760839

Epoch: 5| Step: 5
Training loss: 2.3533499240875244
Validation loss: 2.3105113249953075

Epoch: 5| Step: 6
Training loss: 2.783841371536255
Validation loss: 2.3196782783795427

Epoch: 5| Step: 7
Training loss: 3.023935317993164
Validation loss: 2.319353293347102

Epoch: 5| Step: 8
Training loss: 2.7183115482330322
Validation loss: 2.3139170369794293

Epoch: 5| Step: 9
Training loss: 3.00940203666687
Validation loss: 2.3111016596517255

Epoch: 5| Step: 10
Training loss: 2.809131622314453
Validation loss: 2.306424161439301

Epoch: 143| Step: 0
Training loss: 3.291551113128662
Validation loss: 2.311820576267858

Epoch: 5| Step: 1
Training loss: 2.5668277740478516
Validation loss: 2.3179888930372012

Epoch: 5| Step: 2
Training loss: 2.640702962875366
Validation loss: 2.3231730050938104

Epoch: 5| Step: 3
Training loss: 3.001843214035034
Validation loss: 2.326216797674856

Epoch: 5| Step: 4
Training loss: 2.164367914199829
Validation loss: 2.3470989247804046

Epoch: 5| Step: 5
Training loss: 2.170215129852295
Validation loss: 2.360943055921985

Epoch: 5| Step: 6
Training loss: 2.253760814666748
Validation loss: 2.3757814989295056

Epoch: 5| Step: 7
Training loss: 3.021059036254883
Validation loss: 2.3938223085095807

Epoch: 5| Step: 8
Training loss: 2.243919849395752
Validation loss: 2.3945305501261065

Epoch: 5| Step: 9
Training loss: 2.6476190090179443
Validation loss: 2.382249378388928

Epoch: 5| Step: 10
Training loss: 2.302766799926758
Validation loss: 2.3595883513009674

Epoch: 144| Step: 0
Training loss: 2.217747449874878
Validation loss: 2.345886233032391

Epoch: 5| Step: 1
Training loss: 1.9701305627822876
Validation loss: 2.332666253530851

Epoch: 5| Step: 2
Training loss: 3.0134410858154297
Validation loss: 2.3204009917474564

Epoch: 5| Step: 3
Training loss: 2.321979522705078
Validation loss: 2.324358886288058

Epoch: 5| Step: 4
Training loss: 2.6406261920928955
Validation loss: 2.321270558141893

Epoch: 5| Step: 5
Training loss: 3.142211437225342
Validation loss: 2.3250904493434454

Epoch: 5| Step: 6
Training loss: 2.7493999004364014
Validation loss: 2.3276518955025622

Epoch: 5| Step: 7
Training loss: 3.125277280807495
Validation loss: 2.327369277195264

Epoch: 5| Step: 8
Training loss: 2.8905606269836426
Validation loss: 2.3220466721442437

Epoch: 5| Step: 9
Training loss: 1.4081037044525146
Validation loss: 2.3197003602981567

Epoch: 5| Step: 10
Training loss: 2.714252233505249
Validation loss: 2.327756804804648

Epoch: 145| Step: 0
Training loss: 2.9156432151794434
Validation loss: 2.3196571591079875

Epoch: 5| Step: 1
Training loss: 2.3028388023376465
Validation loss: 2.3216304932871172

Epoch: 5| Step: 2
Training loss: 2.090773105621338
Validation loss: 2.329998234266876

Epoch: 5| Step: 3
Training loss: 2.2503063678741455
Validation loss: 2.323361140425487

Epoch: 5| Step: 4
Training loss: 2.5389413833618164
Validation loss: 2.3332023774423907

Epoch: 5| Step: 5
Training loss: 2.238001823425293
Validation loss: 2.332761800417336

Epoch: 5| Step: 6
Training loss: 3.5103659629821777
Validation loss: 2.3301893870035806

Epoch: 5| Step: 7
Training loss: 2.907336473464966
Validation loss: 2.317493114420163

Epoch: 5| Step: 8
Training loss: 2.3110103607177734
Validation loss: 2.3149586903151644

Epoch: 5| Step: 9
Training loss: 2.4548258781433105
Validation loss: 2.3084987209689234

Epoch: 5| Step: 10
Training loss: 2.6601505279541016
Validation loss: 2.307374123604067

Epoch: 146| Step: 0
Training loss: 3.331578016281128
Validation loss: 2.3108467184087282

Epoch: 5| Step: 1
Training loss: 1.7665059566497803
Validation loss: 2.3045207377403014

Epoch: 5| Step: 2
Training loss: 2.4059486389160156
Validation loss: 2.3174886575309177

Epoch: 5| Step: 3
Training loss: 2.9287848472595215
Validation loss: 2.3213062171013124

Epoch: 5| Step: 4
Training loss: 2.9347681999206543
Validation loss: 2.3167919164062827

Epoch: 5| Step: 5
Training loss: 2.576829671859741
Validation loss: 2.3064658641815186

Epoch: 5| Step: 6
Training loss: 1.9680789709091187
Validation loss: 2.318012181148734

Epoch: 5| Step: 7
Training loss: 2.43710994720459
Validation loss: 2.3119498786105903

Epoch: 5| Step: 8
Training loss: 2.785068988800049
Validation loss: 2.3168196780707246

Epoch: 5| Step: 9
Training loss: 2.612034320831299
Validation loss: 2.3167156557882986

Epoch: 5| Step: 10
Training loss: 2.458794593811035
Validation loss: 2.3216322980901247

Epoch: 147| Step: 0
Training loss: 3.0905215740203857
Validation loss: 2.3323439039209837

Epoch: 5| Step: 1
Training loss: 2.522481918334961
Validation loss: 2.335365369755735

Epoch: 5| Step: 2
Training loss: 2.5429301261901855
Validation loss: 2.3604849461586244

Epoch: 5| Step: 3
Training loss: 2.0829455852508545
Validation loss: 2.3746257546127483

Epoch: 5| Step: 4
Training loss: 2.5432372093200684
Validation loss: 2.3815866644664476

Epoch: 5| Step: 5
Training loss: 3.1109066009521484
Validation loss: 2.41023680984333

Epoch: 5| Step: 6
Training loss: 2.008270740509033
Validation loss: 2.381593429914085

Epoch: 5| Step: 7
Training loss: 1.9980891942977905
Validation loss: 2.3655459598828386

Epoch: 5| Step: 8
Training loss: 2.790541887283325
Validation loss: 2.344054055470292

Epoch: 5| Step: 9
Training loss: 3.1527512073516846
Validation loss: 2.3404863034525225

Epoch: 5| Step: 10
Training loss: 2.45800518989563
Validation loss: 2.3237839873119066

Epoch: 148| Step: 0
Training loss: 2.484356641769409
Validation loss: 2.3245100372581073

Epoch: 5| Step: 1
Training loss: 1.8724956512451172
Validation loss: 2.3175531792384323

Epoch: 5| Step: 2
Training loss: 2.885122299194336
Validation loss: 2.3393400074333273

Epoch: 5| Step: 3
Training loss: 1.9663423299789429
Validation loss: 2.345164247738418

Epoch: 5| Step: 4
Training loss: 2.7453112602233887
Validation loss: 2.363664250220022

Epoch: 5| Step: 5
Training loss: 2.9069857597351074
Validation loss: 2.359113416364116

Epoch: 5| Step: 6
Training loss: 2.0845513343811035
Validation loss: 2.3616935386452624

Epoch: 5| Step: 7
Training loss: 2.891112804412842
Validation loss: 2.349703715693566

Epoch: 5| Step: 8
Training loss: 2.5946173667907715
Validation loss: 2.3532455121317217

Epoch: 5| Step: 9
Training loss: 2.9870731830596924
Validation loss: 2.3385770641347414

Epoch: 5| Step: 10
Training loss: 2.911235809326172
Validation loss: 2.338798156348608

Epoch: 149| Step: 0
Training loss: 2.587170362472534
Validation loss: 2.3344956956883913

Epoch: 5| Step: 1
Training loss: 3.2161552906036377
Validation loss: 2.3338085861616236

Epoch: 5| Step: 2
Training loss: 2.2199454307556152
Validation loss: 2.3352307042767926

Epoch: 5| Step: 3
Training loss: 2.5256142616271973
Validation loss: 2.3267337916999735

Epoch: 5| Step: 4
Training loss: 2.7079453468322754
Validation loss: 2.3204872582548406

Epoch: 5| Step: 5
Training loss: 2.4879021644592285
Validation loss: 2.318339373475762

Epoch: 5| Step: 6
Training loss: 2.7992215156555176
Validation loss: 2.316308649637366

Epoch: 5| Step: 7
Training loss: 2.233187675476074
Validation loss: 2.319011406231952

Epoch: 5| Step: 8
Training loss: 2.148803472518921
Validation loss: 2.3230864745314403

Epoch: 5| Step: 9
Training loss: 2.5739433765411377
Validation loss: 2.3125521905960573

Epoch: 5| Step: 10
Training loss: 2.441100597381592
Validation loss: 2.327778022776368

Epoch: 150| Step: 0
Training loss: 2.833834171295166
Validation loss: 2.331897476667999

Epoch: 5| Step: 1
Training loss: 3.1089272499084473
Validation loss: 2.336498204097953

Epoch: 5| Step: 2
Training loss: 2.953927755355835
Validation loss: 2.3400049850504887

Epoch: 5| Step: 3
Training loss: 2.559924364089966
Validation loss: 2.3368363098431657

Epoch: 5| Step: 4
Training loss: 2.6248743534088135
Validation loss: 2.3386666749113347

Epoch: 5| Step: 5
Training loss: 2.4828884601593018
Validation loss: 2.3414677548152145

Epoch: 5| Step: 6
Training loss: 1.6260325908660889
Validation loss: 2.3443228660091275

Epoch: 5| Step: 7
Training loss: 2.083817958831787
Validation loss: 2.3308570128615185

Epoch: 5| Step: 8
Training loss: 2.8218367099761963
Validation loss: 2.31337712400703

Epoch: 5| Step: 9
Training loss: 2.1599063873291016
Validation loss: 2.2967366992786364

Epoch: 5| Step: 10
Training loss: 2.8198256492614746
Validation loss: 2.294959719463061

Testing loss: 2.489216751522488
