Epoch: 1| Step: 0
Training loss: 5.3801759150791035
Validation loss: 5.7605055526031785

Epoch: 6| Step: 1
Training loss: 5.194830253992699
Validation loss: 5.749689462059853

Epoch: 6| Step: 2
Training loss: 6.0817533906102454
Validation loss: 5.740349466785476

Epoch: 6| Step: 3
Training loss: 6.608964911830789
Validation loss: 5.731691144438749

Epoch: 6| Step: 4
Training loss: 5.663403787127904
Validation loss: 5.723994792955097

Epoch: 6| Step: 5
Training loss: 6.47692295815377
Validation loss: 5.717203687126071

Epoch: 6| Step: 6
Training loss: 6.491611937201182
Validation loss: 5.709584320551022

Epoch: 6| Step: 7
Training loss: 4.432820391320192
Validation loss: 5.702119241816371

Epoch: 6| Step: 8
Training loss: 5.598554881145861
Validation loss: 5.694271394287985

Epoch: 6| Step: 9
Training loss: 6.574809999222708
Validation loss: 5.685286567084538

Epoch: 6| Step: 10
Training loss: 4.725277055963516
Validation loss: 5.676121127715552

Epoch: 6| Step: 11
Training loss: 5.475403493008975
Validation loss: 5.666321991289035

Epoch: 6| Step: 12
Training loss: 5.3447767910861534
Validation loss: 5.655478419922669

Epoch: 6| Step: 13
Training loss: 5.9250911142288825
Validation loss: 5.643892064426309

Epoch: 2| Step: 0
Training loss: 5.5661595340061725
Validation loss: 5.632047978074469

Epoch: 6| Step: 1
Training loss: 4.97362638900405
Validation loss: 5.618677694917703

Epoch: 6| Step: 2
Training loss: 6.007838850620853
Validation loss: 5.60418482079634

Epoch: 6| Step: 3
Training loss: 5.306982788242041
Validation loss: 5.588460168428797

Epoch: 6| Step: 4
Training loss: 5.7171001451631245
Validation loss: 5.5718408781590085

Epoch: 6| Step: 5
Training loss: 5.663789729423321
Validation loss: 5.5542594297387

Epoch: 6| Step: 6
Training loss: 6.7511482674940195
Validation loss: 5.534991816074176

Epoch: 6| Step: 7
Training loss: 5.806348601490549
Validation loss: 5.51482737835843

Epoch: 6| Step: 8
Training loss: 5.321141473883494
Validation loss: 5.493205513396475

Epoch: 6| Step: 9
Training loss: 5.891884100038885
Validation loss: 5.4705579731207274

Epoch: 6| Step: 10
Training loss: 5.043481589434896
Validation loss: 5.447103969103817

Epoch: 6| Step: 11
Training loss: 4.626123240398115
Validation loss: 5.423301137333017

Epoch: 6| Step: 12
Training loss: 4.266562334414251
Validation loss: 5.3991370410558845

Epoch: 6| Step: 13
Training loss: 7.037660922824318
Validation loss: 5.373138920178869

Epoch: 3| Step: 0
Training loss: 5.408974021890143
Validation loss: 5.3481520271024605

Epoch: 6| Step: 1
Training loss: 4.92574446420146
Validation loss: 5.32171896854741

Epoch: 6| Step: 2
Training loss: 5.283285798220989
Validation loss: 5.29514182290782

Epoch: 6| Step: 3
Training loss: 4.258789846257954
Validation loss: 5.270173005146916

Epoch: 6| Step: 4
Training loss: 5.479337895066387
Validation loss: 5.243410110609841

Epoch: 6| Step: 5
Training loss: 6.1173072306290335
Validation loss: 5.217517396021981

Epoch: 6| Step: 6
Training loss: 4.655939283820615
Validation loss: 5.188340321754826

Epoch: 6| Step: 7
Training loss: 5.721763942271997
Validation loss: 5.160054020453806

Epoch: 6| Step: 8
Training loss: 4.489227965319802
Validation loss: 5.130679757201193

Epoch: 6| Step: 9
Training loss: 5.371061434561877
Validation loss: 5.10118181834435

Epoch: 6| Step: 10
Training loss: 4.858611313646598
Validation loss: 5.073875348620178

Epoch: 6| Step: 11
Training loss: 5.299466289782677
Validation loss: 5.0440895579558385

Epoch: 6| Step: 12
Training loss: 5.1729038287016404
Validation loss: 5.013093024251968

Epoch: 6| Step: 13
Training loss: 6.275540466134359
Validation loss: 4.981502808545468

Epoch: 4| Step: 0
Training loss: 5.160344018631413
Validation loss: 4.944535889025168

Epoch: 6| Step: 1
Training loss: 4.514064004223745
Validation loss: 4.907878667327384

Epoch: 6| Step: 2
Training loss: 5.266533747738113
Validation loss: 4.874611331327232

Epoch: 6| Step: 3
Training loss: 4.677569640888453
Validation loss: 4.844612398889833

Epoch: 6| Step: 4
Training loss: 4.6456126116450545
Validation loss: 4.816067917194141

Epoch: 6| Step: 5
Training loss: 4.522704175364704
Validation loss: 4.790854122541204

Epoch: 6| Step: 6
Training loss: 4.905759944860397
Validation loss: 4.7671459087594945

Epoch: 6| Step: 7
Training loss: 5.880511032526179
Validation loss: 4.744838462000802

Epoch: 6| Step: 8
Training loss: 5.296161974962535
Validation loss: 4.722343258369231

Epoch: 6| Step: 9
Training loss: 5.063842595406643
Validation loss: 4.698441974307338

Epoch: 6| Step: 10
Training loss: 4.682966761423642
Validation loss: 4.6754881913592286

Epoch: 6| Step: 11
Training loss: 3.615496839726359
Validation loss: 4.651280442056955

Epoch: 6| Step: 12
Training loss: 5.009050570314378
Validation loss: 4.624417131629393

Epoch: 6| Step: 13
Training loss: 3.8786323504441755
Validation loss: 4.5968166994850845

Epoch: 5| Step: 0
Training loss: 4.1539812133981355
Validation loss: 4.570807273635585

Epoch: 6| Step: 1
Training loss: 5.1421593692256975
Validation loss: 4.547497834834801

Epoch: 6| Step: 2
Training loss: 4.73160907788697
Validation loss: 4.526473986117319

Epoch: 6| Step: 3
Training loss: 4.983079891500649
Validation loss: 4.504499836961955

Epoch: 6| Step: 4
Training loss: 4.820295089616046
Validation loss: 4.4832665047127085

Epoch: 6| Step: 5
Training loss: 4.31530250487937
Validation loss: 4.464224723246935

Epoch: 6| Step: 6
Training loss: 3.537856142697973
Validation loss: 4.44337851849164

Epoch: 6| Step: 7
Training loss: 4.832857349679744
Validation loss: 4.427719927867431

Epoch: 6| Step: 8
Training loss: 4.96070335015827
Validation loss: 4.409148830766041

Epoch: 6| Step: 9
Training loss: 4.290615113449098
Validation loss: 4.394072925435104

Epoch: 6| Step: 10
Training loss: 3.9330685822777602
Validation loss: 4.376595426849584

Epoch: 6| Step: 11
Training loss: 4.7592508681822965
Validation loss: 4.361101856217079

Epoch: 6| Step: 12
Training loss: 4.026030480820422
Validation loss: 4.3458011742140545

Epoch: 6| Step: 13
Training loss: 5.2388272153843145
Validation loss: 4.330761992981694

Epoch: 6| Step: 0
Training loss: 4.0221525936762275
Validation loss: 4.315357245561901

Epoch: 6| Step: 1
Training loss: 4.467129500213721
Validation loss: 4.302290309027084

Epoch: 6| Step: 2
Training loss: 4.269104596849074
Validation loss: 4.288451313515029

Epoch: 6| Step: 3
Training loss: 4.445798609322987
Validation loss: 4.277073097403566

Epoch: 6| Step: 4
Training loss: 3.4773798635369175
Validation loss: 4.2680406004791225

Epoch: 6| Step: 5
Training loss: 5.123596929761086
Validation loss: 4.25698392117108

Epoch: 6| Step: 6
Training loss: 4.29116319585801
Validation loss: 4.247619565472453

Epoch: 6| Step: 7
Training loss: 3.2771935957110516
Validation loss: 4.241794588910539

Epoch: 6| Step: 8
Training loss: 5.158213293664248
Validation loss: 4.234131222884238

Epoch: 6| Step: 9
Training loss: 3.9487797071420823
Validation loss: 4.226661103993713

Epoch: 6| Step: 10
Training loss: 5.151458918762647
Validation loss: 4.216025858691736

Epoch: 6| Step: 11
Training loss: 3.718789877797938
Validation loss: 4.206712251961642

Epoch: 6| Step: 12
Training loss: 4.435195539393528
Validation loss: 4.19556938462391

Epoch: 6| Step: 13
Training loss: 5.27875870852302
Validation loss: 4.184922087381463

Epoch: 7| Step: 0
Training loss: 3.355958558682633
Validation loss: 4.173356378866402

Epoch: 6| Step: 1
Training loss: 4.332824579353429
Validation loss: 4.163175325266159

Epoch: 6| Step: 2
Training loss: 3.902410710918246
Validation loss: 4.151856309433496

Epoch: 6| Step: 3
Training loss: 4.072106842677829
Validation loss: 4.14339897245204

Epoch: 6| Step: 4
Training loss: 3.349305573413193
Validation loss: 4.133466371918499

Epoch: 6| Step: 5
Training loss: 4.578308726715482
Validation loss: 4.125846860385422

Epoch: 6| Step: 6
Training loss: 4.813261492044235
Validation loss: 4.116085402106741

Epoch: 6| Step: 7
Training loss: 4.527149107388373
Validation loss: 4.1067543739796735

Epoch: 6| Step: 8
Training loss: 4.782454993299932
Validation loss: 4.098684080828665

Epoch: 6| Step: 9
Training loss: 3.9329228515662584
Validation loss: 4.088118527882145

Epoch: 6| Step: 10
Training loss: 4.763777377816422
Validation loss: 4.081092108065075

Epoch: 6| Step: 11
Training loss: 4.482947570957103
Validation loss: 4.070749025404607

Epoch: 6| Step: 12
Training loss: 3.982695580880595
Validation loss: 4.06145621269661

Epoch: 6| Step: 13
Training loss: 4.32527987065261
Validation loss: 4.0540220639386515

Epoch: 8| Step: 0
Training loss: 5.066978828116423
Validation loss: 4.0422061314451865

Epoch: 6| Step: 1
Training loss: 3.96980199613139
Validation loss: 4.032488984294577

Epoch: 6| Step: 2
Training loss: 4.659549440205327
Validation loss: 4.0197938628208085

Epoch: 6| Step: 3
Training loss: 4.67747014519906
Validation loss: 4.010008020547182

Epoch: 6| Step: 4
Training loss: 3.2526785743007016
Validation loss: 3.9974983452572626

Epoch: 6| Step: 5
Training loss: 4.535925406486849
Validation loss: 3.987597562681818

Epoch: 6| Step: 6
Training loss: 3.887844823527062
Validation loss: 3.980678013412572

Epoch: 6| Step: 7
Training loss: 4.296311220116352
Validation loss: 3.9724565979873923

Epoch: 6| Step: 8
Training loss: 4.8510305509248095
Validation loss: 3.9653945961292845

Epoch: 6| Step: 9
Training loss: 2.4801478861738224
Validation loss: 3.952625696271936

Epoch: 6| Step: 10
Training loss: 3.994615626362613
Validation loss: 3.945057224042843

Epoch: 6| Step: 11
Training loss: 3.8229190227005825
Validation loss: 3.9412307774184683

Epoch: 6| Step: 12
Training loss: 3.6266767635859387
Validation loss: 3.9345384506892542

Epoch: 6| Step: 13
Training loss: 4.012416879143559
Validation loss: 3.9293903972524795

Epoch: 9| Step: 0
Training loss: 4.660570840867472
Validation loss: 3.9193253108599073

Epoch: 6| Step: 1
Training loss: 4.454460720041932
Validation loss: 3.9131226451300845

Epoch: 6| Step: 2
Training loss: 3.6461248808047344
Validation loss: 3.9097981250166667

Epoch: 6| Step: 3
Training loss: 4.819759887476222
Validation loss: 3.9038741435956434

Epoch: 6| Step: 4
Training loss: 4.224710506475608
Validation loss: 3.8910063620806175

Epoch: 6| Step: 5
Training loss: 3.812911214695714
Validation loss: 3.889573530842391

Epoch: 6| Step: 6
Training loss: 4.867975700813024
Validation loss: 3.8914383322562975

Epoch: 6| Step: 7
Training loss: 2.8608354684666364
Validation loss: 3.8814423510377623

Epoch: 6| Step: 8
Training loss: 3.027817975709696
Validation loss: 3.8751887137579657

Epoch: 6| Step: 9
Training loss: 3.863126961893183
Validation loss: 3.8710164478315905

Epoch: 6| Step: 10
Training loss: 4.026555129352732
Validation loss: 3.8631048261873477

Epoch: 6| Step: 11
Training loss: 3.369321496503674
Validation loss: 3.8543163444547037

Epoch: 6| Step: 12
Training loss: 4.111796662732035
Validation loss: 3.851431284625851

Epoch: 6| Step: 13
Training loss: 4.553293842648954
Validation loss: 3.8470233898779203

Epoch: 10| Step: 0
Training loss: 3.0573701518099217
Validation loss: 3.8431370864526095

Epoch: 6| Step: 1
Training loss: 3.9038976071093914
Validation loss: 3.8391754891157026

Epoch: 6| Step: 2
Training loss: 4.486894810068662
Validation loss: 3.834760168058812

Epoch: 6| Step: 3
Training loss: 4.416467602160421
Validation loss: 3.827223813041379

Epoch: 6| Step: 4
Training loss: 4.045370521880753
Validation loss: 3.821152291012895

Epoch: 6| Step: 5
Training loss: 4.227814607018425
Validation loss: 3.8206340641794903

Epoch: 6| Step: 6
Training loss: 3.6718534428389806
Validation loss: 3.8189991963616796

Epoch: 6| Step: 7
Training loss: 3.57616280805104
Validation loss: 3.815136255402812

Epoch: 6| Step: 8
Training loss: 4.63558100148336
Validation loss: 3.804520224067062

Epoch: 6| Step: 9
Training loss: 3.261258066502951
Validation loss: 3.8038945694671074

Epoch: 6| Step: 10
Training loss: 3.3236440661629274
Validation loss: 3.805333131436327

Epoch: 6| Step: 11
Training loss: 4.838567114339813
Validation loss: 3.811095887119285

Epoch: 6| Step: 12
Training loss: 4.268495369461728
Validation loss: 3.8024052655438965

Epoch: 6| Step: 13
Training loss: 3.4122443693780986
Validation loss: 3.790458493925763

Epoch: 11| Step: 0
Training loss: 4.221510146701198
Validation loss: 3.7859804156198673

Epoch: 6| Step: 1
Training loss: 4.828974281847657
Validation loss: 3.7832934909587626

Epoch: 6| Step: 2
Training loss: 3.954574741306898
Validation loss: 3.782358938330332

Epoch: 6| Step: 3
Training loss: 3.682258371996681
Validation loss: 3.7774197012922857

Epoch: 6| Step: 4
Training loss: 4.406916574691318
Validation loss: 3.773088774068647

Epoch: 6| Step: 5
Training loss: 4.450562713705755
Validation loss: 3.7682277279944967

Epoch: 6| Step: 6
Training loss: 3.3960033600412016
Validation loss: 3.7646547338120957

Epoch: 6| Step: 7
Training loss: 3.932449735112892
Validation loss: 3.760601723732041

Epoch: 6| Step: 8
Training loss: 3.7115567945420596
Validation loss: 3.755567705188122

Epoch: 6| Step: 9
Training loss: 3.870730108740085
Validation loss: 3.7535235145928025

Epoch: 6| Step: 10
Training loss: 4.580051888917393
Validation loss: 3.751383572000621

Epoch: 6| Step: 11
Training loss: 3.258364404268408
Validation loss: 3.747133595140063

Epoch: 6| Step: 12
Training loss: 3.0345007386168183
Validation loss: 3.7515747250518445

Epoch: 6| Step: 13
Training loss: 2.983790155595221
Validation loss: 3.7499738603453387

Epoch: 12| Step: 0
Training loss: 3.873978510933408
Validation loss: 3.75147381195284

Epoch: 6| Step: 1
Training loss: 3.518651719016642
Validation loss: 3.7463184565473355

Epoch: 6| Step: 2
Training loss: 2.999084491909459
Validation loss: 3.740995427680733

Epoch: 6| Step: 3
Training loss: 4.311621313831009
Validation loss: 3.73974198170431

Epoch: 6| Step: 4
Training loss: 3.9326422865554282
Validation loss: 3.732310168377067

Epoch: 6| Step: 5
Training loss: 4.987374769278262
Validation loss: 3.723317598615596

Epoch: 6| Step: 6
Training loss: 3.302336305059845
Validation loss: 3.7176048809294366

Epoch: 6| Step: 7
Training loss: 4.287421908098384
Validation loss: 3.7160362557884907

Epoch: 6| Step: 8
Training loss: 3.8556512945957104
Validation loss: 3.71799429121386

Epoch: 6| Step: 9
Training loss: 3.64000464135178
Validation loss: 3.713047118172287

Epoch: 6| Step: 10
Training loss: 3.953353935518238
Validation loss: 3.7098006460741604

Epoch: 6| Step: 11
Training loss: 4.181756935123457
Validation loss: 3.7011076735005384

Epoch: 6| Step: 12
Training loss: 4.214963216564551
Validation loss: 3.6979244390969557

Epoch: 6| Step: 13
Training loss: 2.4301408056586244
Validation loss: 3.698716066859648

Epoch: 13| Step: 0
Training loss: 3.5481101418809504
Validation loss: 3.700991342156692

Epoch: 6| Step: 1
Training loss: 2.6739638344966075
Validation loss: 3.689592919149295

Epoch: 6| Step: 2
Training loss: 4.2443318435840895
Validation loss: 3.6844176752655726

Epoch: 6| Step: 3
Training loss: 4.8991175032020475
Validation loss: 3.681384115563249

Epoch: 6| Step: 4
Training loss: 3.822776452316081
Validation loss: 3.678107654111284

Epoch: 6| Step: 5
Training loss: 2.5912869260064286
Validation loss: 3.6749818203317166

Epoch: 6| Step: 6
Training loss: 4.0613490895270195
Validation loss: 3.6722130851298282

Epoch: 6| Step: 7
Training loss: 3.608326020501342
Validation loss: 3.6680948160057882

Epoch: 6| Step: 8
Training loss: 4.3202140479571165
Validation loss: 3.677882682152113

Epoch: 6| Step: 9
Training loss: 5.0552165065625685
Validation loss: 3.660681313181169

Epoch: 6| Step: 10
Training loss: 3.6782289760934854
Validation loss: 3.6573395067695915

Epoch: 6| Step: 11
Training loss: 4.02399211135
Validation loss: 3.662934493458842

Epoch: 6| Step: 12
Training loss: 3.4346277895389683
Validation loss: 3.6614131373609236

Epoch: 6| Step: 13
Training loss: 2.7440012614744975
Validation loss: 3.658531689335865

Epoch: 14| Step: 0
Training loss: 4.269938652795004
Validation loss: 3.655738322877685

Epoch: 6| Step: 1
Training loss: 4.112344459444636
Validation loss: 3.6524405753011604

Epoch: 6| Step: 2
Training loss: 4.738209194758186
Validation loss: 3.641633389619101

Epoch: 6| Step: 3
Training loss: 4.073422581828623
Validation loss: 3.6333717334754323

Epoch: 6| Step: 4
Training loss: 3.3729209147460524
Validation loss: 3.6252992624580855

Epoch: 6| Step: 5
Training loss: 2.539235176670366
Validation loss: 3.6216409004384817

Epoch: 6| Step: 6
Training loss: 3.365523137186621
Validation loss: 3.619823033511272

Epoch: 6| Step: 7
Training loss: 4.213634412929094
Validation loss: 3.6196545221755545

Epoch: 6| Step: 8
Training loss: 3.599118410884989
Validation loss: 3.6142611178978212

Epoch: 6| Step: 9
Training loss: 3.898252800061648
Validation loss: 3.611903976207994

Epoch: 6| Step: 10
Training loss: 3.46521296893928
Validation loss: 3.6019161386098886

Epoch: 6| Step: 11
Training loss: 3.5636483734101883
Validation loss: 3.601661563139338

Epoch: 6| Step: 12
Training loss: 3.522157423852034
Validation loss: 3.6023904602663395

Epoch: 6| Step: 13
Training loss: 4.546252230962794
Validation loss: 3.5993436121528193

Epoch: 15| Step: 0
Training loss: 3.75032321808565
Validation loss: 3.5912103026167594

Epoch: 6| Step: 1
Training loss: 4.194657770139746
Validation loss: 3.5891517858592166

Epoch: 6| Step: 2
Training loss: 3.0078822536554632
Validation loss: 3.594707816141331

Epoch: 6| Step: 3
Training loss: 3.3214725397718547
Validation loss: 3.5956427185353608

Epoch: 6| Step: 4
Training loss: 3.8793280027433426
Validation loss: 3.577047835461824

Epoch: 6| Step: 5
Training loss: 4.715352837638224
Validation loss: 3.584764256891585

Epoch: 6| Step: 6
Training loss: 4.6220266733823605
Validation loss: 3.588522967534777

Epoch: 6| Step: 7
Training loss: 3.8544104146776315
Validation loss: 3.5832583974532546

Epoch: 6| Step: 8
Training loss: 3.718462764642299
Validation loss: 3.57849453923079

Epoch: 6| Step: 9
Training loss: 2.822306934305162
Validation loss: 3.566940069448721

Epoch: 6| Step: 10
Training loss: 3.9629272038109757
Validation loss: 3.5720330510822924

Epoch: 6| Step: 11
Training loss: 3.214945201733069
Validation loss: 3.5589192458614614

Epoch: 6| Step: 12
Training loss: 4.201752505930561
Validation loss: 3.562902344725416

Epoch: 6| Step: 13
Training loss: 2.438156039644966
Validation loss: 3.5592308408425057

Epoch: 16| Step: 0
Training loss: 3.044230560654186
Validation loss: 3.5608208597094144

Epoch: 6| Step: 1
Training loss: 4.119947633873442
Validation loss: 3.5614065994111925

Epoch: 6| Step: 2
Training loss: 4.235353926784849
Validation loss: 3.555895633567644

Epoch: 6| Step: 3
Training loss: 3.076390431224091
Validation loss: 3.5478067457648677

Epoch: 6| Step: 4
Training loss: 3.4659811430262395
Validation loss: 3.5413885008546555

Epoch: 6| Step: 5
Training loss: 4.337033354972446
Validation loss: 3.5372926145185546

Epoch: 6| Step: 6
Training loss: 3.8329601659060915
Validation loss: 3.52954460545917

Epoch: 6| Step: 7
Training loss: 3.633393534473658
Validation loss: 3.5255517862707473

Epoch: 6| Step: 8
Training loss: 4.301489886839446
Validation loss: 3.5199659055305985

Epoch: 6| Step: 9
Training loss: 4.14074568662561
Validation loss: 3.512767537814476

Epoch: 6| Step: 10
Training loss: 3.496796913400098
Validation loss: 3.511312080920062

Epoch: 6| Step: 11
Training loss: 3.9477816569544886
Validation loss: 3.509289503805215

Epoch: 6| Step: 12
Training loss: 3.1562445612190144
Validation loss: 3.507830499017789

Epoch: 6| Step: 13
Training loss: 2.5947740670343262
Validation loss: 3.5058996473322095

Epoch: 17| Step: 0
Training loss: 3.9025856836603277
Validation loss: 3.498569134515725

Epoch: 6| Step: 1
Training loss: 3.8541327947554396
Validation loss: 3.507531214247794

Epoch: 6| Step: 2
Training loss: 3.743848587291942
Validation loss: 3.4987770762616925

Epoch: 6| Step: 3
Training loss: 3.9791978898080003
Validation loss: 3.4965543882425534

Epoch: 6| Step: 4
Training loss: 4.279028991643797
Validation loss: 3.487076399946085

Epoch: 6| Step: 5
Training loss: 3.918115767119545
Validation loss: 3.4807645829608327

Epoch: 6| Step: 6
Training loss: 4.143320494611699
Validation loss: 3.4824009913798584

Epoch: 6| Step: 7
Training loss: 3.4221715232539576
Validation loss: 3.4802374505756384

Epoch: 6| Step: 8
Training loss: 3.973803569268228
Validation loss: 3.4783302605001776

Epoch: 6| Step: 9
Training loss: 3.685066195841917
Validation loss: 3.4740686161897765

Epoch: 6| Step: 10
Training loss: 3.406260779127512
Validation loss: 3.4759822688025324

Epoch: 6| Step: 11
Training loss: 2.423419878051361
Validation loss: 3.472868191152231

Epoch: 6| Step: 12
Training loss: 2.77826727898637
Validation loss: 3.4710169136784232

Epoch: 6| Step: 13
Training loss: 3.906113278857338
Validation loss: 3.469472305699307

Epoch: 18| Step: 0
Training loss: 3.380342987309576
Validation loss: 3.457455902686811

Epoch: 6| Step: 1
Training loss: 4.3151263656766545
Validation loss: 3.4580245524464015

Epoch: 6| Step: 2
Training loss: 3.4604713694370957
Validation loss: 3.4532458209470356

Epoch: 6| Step: 3
Training loss: 3.0138411706134365
Validation loss: 3.447381173589014

Epoch: 6| Step: 4
Training loss: 4.021204771499588
Validation loss: 3.4510929140347746

Epoch: 6| Step: 5
Training loss: 3.932384377032961
Validation loss: 3.4453777952268663

Epoch: 6| Step: 6
Training loss: 3.0294939440653956
Validation loss: 3.4440093159816803

Epoch: 6| Step: 7
Training loss: 3.64265614443926
Validation loss: 3.4476504427403722

Epoch: 6| Step: 8
Training loss: 3.946722824775389
Validation loss: 3.442389477813745

Epoch: 6| Step: 9
Training loss: 4.060490507364891
Validation loss: 3.441605146915437

Epoch: 6| Step: 10
Training loss: 4.122551162244945
Validation loss: 3.4374752815677896

Epoch: 6| Step: 11
Training loss: 3.3400456239245386
Validation loss: 3.4295122849942277

Epoch: 6| Step: 12
Training loss: 3.3388082047747942
Validation loss: 3.4290363397098287

Epoch: 6| Step: 13
Training loss: 3.2059409068772107
Validation loss: 3.426113633427187

Epoch: 19| Step: 0
Training loss: 4.2811673567097595
Validation loss: 3.4241837621354274

Epoch: 6| Step: 1
Training loss: 3.5235040831777
Validation loss: 3.4223770355446406

Epoch: 6| Step: 2
Training loss: 3.710857575208384
Validation loss: 3.419142435114797

Epoch: 6| Step: 3
Training loss: 3.471238214722114
Validation loss: 3.4198581522384512

Epoch: 6| Step: 4
Training loss: 3.645752795101879
Validation loss: 3.4161676997441823

Epoch: 6| Step: 5
Training loss: 3.936866224842069
Validation loss: 3.410466070403231

Epoch: 6| Step: 6
Training loss: 3.2349550768225606
Validation loss: 3.4065627403927503

Epoch: 6| Step: 7
Training loss: 3.294841120916904
Validation loss: 3.408491496156576

Epoch: 6| Step: 8
Training loss: 3.5295537064564204
Validation loss: 3.401530170124526

Epoch: 6| Step: 9
Training loss: 3.8461066984074517
Validation loss: 3.4010170792461616

Epoch: 6| Step: 10
Training loss: 3.6065245102409538
Validation loss: 3.3971028484286854

Epoch: 6| Step: 11
Training loss: 3.6572256498246523
Validation loss: 3.3969003594026574

Epoch: 6| Step: 12
Training loss: 3.445698895920486
Validation loss: 3.3959389861462514

Epoch: 6| Step: 13
Training loss: 3.519627577196986
Validation loss: 3.3943991537485063

Epoch: 20| Step: 0
Training loss: 3.5105948171868233
Validation loss: 3.3895885534928447

Epoch: 6| Step: 1
Training loss: 3.9574782937105835
Validation loss: 3.390202342777881

Epoch: 6| Step: 2
Training loss: 2.666778879983596
Validation loss: 3.385789331161019

Epoch: 6| Step: 3
Training loss: 3.6852728373378434
Validation loss: 3.3876506805660576

Epoch: 6| Step: 4
Training loss: 3.6228755118672384
Validation loss: 3.383646654934934

Epoch: 6| Step: 5
Training loss: 2.8257669977404007
Validation loss: 3.3789423268995726

Epoch: 6| Step: 6
Training loss: 4.043287181753339
Validation loss: 3.377784452402975

Epoch: 6| Step: 7
Training loss: 4.461873986708567
Validation loss: 3.376434513527313

Epoch: 6| Step: 8
Training loss: 3.4903944904165876
Validation loss: 3.3725198058809385

Epoch: 6| Step: 9
Training loss: 4.2896450182181995
Validation loss: 3.372312200930408

Epoch: 6| Step: 10
Training loss: 2.652909995130016
Validation loss: 3.3724994488460283

Epoch: 6| Step: 11
Training loss: 3.1454009375762366
Validation loss: 3.372139046650295

Epoch: 6| Step: 12
Training loss: 4.139988803571958
Validation loss: 3.370266776918322

Epoch: 6| Step: 13
Training loss: 3.2425354552554806
Validation loss: 3.3675773407686482

Epoch: 21| Step: 0
Training loss: 3.8731539851395707
Validation loss: 3.3614032061020973

Epoch: 6| Step: 1
Training loss: 3.797795815915754
Validation loss: 3.365333162446521

Epoch: 6| Step: 2
Training loss: 3.9975199163440553
Validation loss: 3.360901684328342

Epoch: 6| Step: 3
Training loss: 3.887490967375145
Validation loss: 3.363165086596189

Epoch: 6| Step: 4
Training loss: 4.065837721423855
Validation loss: 3.355394430028787

Epoch: 6| Step: 5
Training loss: 2.604966236708428
Validation loss: 3.3566396815829775

Epoch: 6| Step: 6
Training loss: 3.7027185917218204
Validation loss: 3.3554793301133006

Epoch: 6| Step: 7
Training loss: 2.564056110083541
Validation loss: 3.355356843853327

Epoch: 6| Step: 8
Training loss: 3.480854531088819
Validation loss: 3.355050425252242

Epoch: 6| Step: 9
Training loss: 3.4438092678390877
Validation loss: 3.3566667893271185

Epoch: 6| Step: 10
Training loss: 3.165597350290697
Validation loss: 3.361291213806329

Epoch: 6| Step: 11
Training loss: 4.1558823960730935
Validation loss: 3.354780491161273

Epoch: 6| Step: 12
Training loss: 3.285092819272812
Validation loss: 3.346375699614605

Epoch: 6| Step: 13
Training loss: 3.9263359323234925
Validation loss: 3.344265037618848

Epoch: 22| Step: 0
Training loss: 2.7299156229023827
Validation loss: 3.3417885238560276

Epoch: 6| Step: 1
Training loss: 3.220653970781667
Validation loss: 3.340729744894434

Epoch: 6| Step: 2
Training loss: 3.5472656572617276
Validation loss: 3.341752145581413

Epoch: 6| Step: 3
Training loss: 3.839464232898013
Validation loss: 3.3402212163155895

Epoch: 6| Step: 4
Training loss: 2.9559198304017325
Validation loss: 3.3401785941194784

Epoch: 6| Step: 5
Training loss: 3.8909098203037717
Validation loss: 3.337692069450446

Epoch: 6| Step: 6
Training loss: 4.165992504257806
Validation loss: 3.33708648479622

Epoch: 6| Step: 7
Training loss: 3.7284515519229458
Validation loss: 3.334864345292716

Epoch: 6| Step: 8
Training loss: 2.7993942933930533
Validation loss: 3.330930397983228

Epoch: 6| Step: 9
Training loss: 3.844919662529207
Validation loss: 3.3312830408139225

Epoch: 6| Step: 10
Training loss: 4.0892493281467965
Validation loss: 3.329192911548983

Epoch: 6| Step: 11
Training loss: 4.059473171911804
Validation loss: 3.3275849788478773

Epoch: 6| Step: 12
Training loss: 3.176069370915054
Validation loss: 3.326278373725278

Epoch: 6| Step: 13
Training loss: 3.4726131337839394
Validation loss: 3.3226974501917614

Epoch: 23| Step: 0
Training loss: 3.411815331491605
Validation loss: 3.321400586656757

Epoch: 6| Step: 1
Training loss: 2.818554359294858
Validation loss: 3.3195752987789455

Epoch: 6| Step: 2
Training loss: 3.578976459060165
Validation loss: 3.3175992098571414

Epoch: 6| Step: 3
Training loss: 4.164340985059191
Validation loss: 3.315626007138998

Epoch: 6| Step: 4
Training loss: 3.3582960658376018
Validation loss: 3.314068225485248

Epoch: 6| Step: 5
Training loss: 3.6470421812412495
Validation loss: 3.3138224925334554

Epoch: 6| Step: 6
Training loss: 3.787600898028215
Validation loss: 3.3130897233853616

Epoch: 6| Step: 7
Training loss: 4.14377735986207
Validation loss: 3.308022270995449

Epoch: 6| Step: 8
Training loss: 2.7431279061563445
Validation loss: 3.306741138100781

Epoch: 6| Step: 9
Training loss: 4.317768140991403
Validation loss: 3.3068346150389836

Epoch: 6| Step: 10
Training loss: 3.005833993151446
Validation loss: 3.302306041205636

Epoch: 6| Step: 11
Training loss: 3.523228269061357
Validation loss: 3.2983189756385856

Epoch: 6| Step: 12
Training loss: 3.7196005481657624
Validation loss: 3.2990947467428047

Epoch: 6| Step: 13
Training loss: 2.6180580627087617
Validation loss: 3.2929915029345262

Epoch: 24| Step: 0
Training loss: 3.5531489469581796
Validation loss: 3.2927444555425303

Epoch: 6| Step: 1
Training loss: 3.8646456292710396
Validation loss: 3.2882088409380223

Epoch: 6| Step: 2
Training loss: 3.514779357930811
Validation loss: 3.2857156877865656

Epoch: 6| Step: 3
Training loss: 2.0002159955691448
Validation loss: 3.2838250013577333

Epoch: 6| Step: 4
Training loss: 3.502082613813125
Validation loss: 3.284173319334257

Epoch: 6| Step: 5
Training loss: 2.7253728419026215
Validation loss: 3.2857281871774946

Epoch: 6| Step: 6
Training loss: 3.994257142249132
Validation loss: 3.2838888172443257

Epoch: 6| Step: 7
Training loss: 3.451394592594284
Validation loss: 3.279119814442276

Epoch: 6| Step: 8
Training loss: 3.6594917728286247
Validation loss: 3.280579583921459

Epoch: 6| Step: 9
Training loss: 3.667656475907818
Validation loss: 3.2717145055899013

Epoch: 6| Step: 10
Training loss: 4.298390624034432
Validation loss: 3.2694881539918974

Epoch: 6| Step: 11
Training loss: 4.092629548703963
Validation loss: 3.2688537327714804

Epoch: 6| Step: 12
Training loss: 3.086973533069578
Validation loss: 3.2669641545968116

Epoch: 6| Step: 13
Training loss: 3.126899599645343
Validation loss: 3.267685566825464

Epoch: 25| Step: 0
Training loss: 3.4271326650916483
Validation loss: 3.2646778913909875

Epoch: 6| Step: 1
Training loss: 4.264099966340988
Validation loss: 3.265565137142262

Epoch: 6| Step: 2
Training loss: 3.6724289496542735
Validation loss: 3.261849510613054

Epoch: 6| Step: 3
Training loss: 3.4375033291887287
Validation loss: 3.2617741861606806

Epoch: 6| Step: 4
Training loss: 3.630237610241446
Validation loss: 3.260416228963904

Epoch: 6| Step: 5
Training loss: 3.935826506039682
Validation loss: 3.2592859185009884

Epoch: 6| Step: 6
Training loss: 3.4751579962290755
Validation loss: 3.256214158071491

Epoch: 6| Step: 7
Training loss: 3.2187931094940034
Validation loss: 3.255490723533377

Epoch: 6| Step: 8
Training loss: 3.56661615662743
Validation loss: 3.2573022268433096

Epoch: 6| Step: 9
Training loss: 3.3014217319619297
Validation loss: 3.2529321053962663

Epoch: 6| Step: 10
Training loss: 3.5968611808928985
Validation loss: 3.253801047763995

Epoch: 6| Step: 11
Training loss: 3.2931404838263156
Validation loss: 3.2540536689107276

Epoch: 6| Step: 12
Training loss: 2.9982294579989204
Validation loss: 3.252203442873385

Epoch: 6| Step: 13
Training loss: 2.7228836555688374
Validation loss: 3.252042718463845

Epoch: 26| Step: 0
Training loss: 2.52124201927
Validation loss: 3.250945719586724

Epoch: 6| Step: 1
Training loss: 3.1769536893481303
Validation loss: 3.2485800639504916

Epoch: 6| Step: 2
Training loss: 3.10330789109675
Validation loss: 3.2489548857258783

Epoch: 6| Step: 3
Training loss: 3.953058656882159
Validation loss: 3.2496171020540436

Epoch: 6| Step: 4
Training loss: 3.4025222959215364
Validation loss: 3.2450446505242683

Epoch: 6| Step: 5
Training loss: 3.084941770971641
Validation loss: 3.2450597129545833

Epoch: 6| Step: 6
Training loss: 3.9292375371426727
Validation loss: 3.2433873877582062

Epoch: 6| Step: 7
Training loss: 3.614891955184311
Validation loss: 3.242045277612928

Epoch: 6| Step: 8
Training loss: 3.823998293888238
Validation loss: 3.242485531431141

Epoch: 6| Step: 9
Training loss: 3.2368075304057857
Validation loss: 3.239380280564455

Epoch: 6| Step: 10
Training loss: 3.4133932823887063
Validation loss: 3.2376023480702685

Epoch: 6| Step: 11
Training loss: 3.685900325029787
Validation loss: 3.2383290615881895

Epoch: 6| Step: 12
Training loss: 4.040289155790999
Validation loss: 3.238737556917825

Epoch: 6| Step: 13
Training loss: 3.692550175144472
Validation loss: 3.238880693116701

Epoch: 27| Step: 0
Training loss: 3.8890253784811195
Validation loss: 3.23796960792805

Epoch: 6| Step: 1
Training loss: 3.535301382552627
Validation loss: 3.2360673435793523

Epoch: 6| Step: 2
Training loss: 3.6356451332567024
Validation loss: 3.2359410044262726

Epoch: 6| Step: 3
Training loss: 4.0320485824806696
Validation loss: 3.234831448999522

Epoch: 6| Step: 4
Training loss: 3.618819393882761
Validation loss: 3.2327257076592213

Epoch: 6| Step: 5
Training loss: 3.4399965410436937
Validation loss: 3.231998316442745

Epoch: 6| Step: 6
Training loss: 3.292560665235028
Validation loss: 3.2340084726461575

Epoch: 6| Step: 7
Training loss: 3.0556489255877075
Validation loss: 3.230606435858278

Epoch: 6| Step: 8
Training loss: 3.688169256997531
Validation loss: 3.229128396677118

Epoch: 6| Step: 9
Training loss: 3.843479302031117
Validation loss: 3.2289520356416137

Epoch: 6| Step: 10
Training loss: 3.22148312572919
Validation loss: 3.227242858469302

Epoch: 6| Step: 11
Training loss: 2.129192592017591
Validation loss: 3.229272624859908

Epoch: 6| Step: 12
Training loss: 3.292251019980775
Validation loss: 3.2283008686324584

Epoch: 6| Step: 13
Training loss: 3.907125756322698
Validation loss: 3.230212744708868

Epoch: 28| Step: 0
Training loss: 3.151275037630478
Validation loss: 3.231895729475498

Epoch: 6| Step: 1
Training loss: 3.332122264839902
Validation loss: 3.2286787751489507

Epoch: 6| Step: 2
Training loss: 2.9698058810518866
Validation loss: 3.2316155670982574

Epoch: 6| Step: 3
Training loss: 2.656347833963474
Validation loss: 3.2297293964952773

Epoch: 6| Step: 4
Training loss: 3.556984362679664
Validation loss: 3.2274264475792322

Epoch: 6| Step: 5
Training loss: 3.996288246351207
Validation loss: 3.2248510690247234

Epoch: 6| Step: 6
Training loss: 3.313295376852547
Validation loss: 3.224016294846796

Epoch: 6| Step: 7
Training loss: 4.001886876434333
Validation loss: 3.2230426022506786

Epoch: 6| Step: 8
Training loss: 3.3980993343785157
Validation loss: 3.2223224513507724

Epoch: 6| Step: 9
Training loss: 3.202446693614033
Validation loss: 3.219880224718789

Epoch: 6| Step: 10
Training loss: 3.6789592824156623
Validation loss: 3.220880437562037

Epoch: 6| Step: 11
Training loss: 3.232347968141115
Validation loss: 3.2212007198726265

Epoch: 6| Step: 12
Training loss: 3.719904359798101
Validation loss: 3.219344868951659

Epoch: 6| Step: 13
Training loss: 4.628101030966376
Validation loss: 3.2188685955146377

Epoch: 29| Step: 0
Training loss: 3.846615847202856
Validation loss: 3.2162734772035146

Epoch: 6| Step: 1
Training loss: 3.121395931964882
Validation loss: 3.215208165185135

Epoch: 6| Step: 2
Training loss: 3.3055366886002973
Validation loss: 3.2173907026875215

Epoch: 6| Step: 3
Training loss: 2.550508493325189
Validation loss: 3.215617287252237

Epoch: 6| Step: 4
Training loss: 3.4657729837040328
Validation loss: 3.215582141231644

Epoch: 6| Step: 5
Training loss: 4.237601652023284
Validation loss: 3.218422254663259

Epoch: 6| Step: 6
Training loss: 3.560975668862875
Validation loss: 3.21697841291703

Epoch: 6| Step: 7
Training loss: 3.6638162688786142
Validation loss: 3.2151557247571274

Epoch: 6| Step: 8
Training loss: 4.264685446978467
Validation loss: 3.2142501321077437

Epoch: 6| Step: 9
Training loss: 3.2849711798067034
Validation loss: 3.213706542506705

Epoch: 6| Step: 10
Training loss: 2.9553537183535132
Validation loss: 3.2152727784494797

Epoch: 6| Step: 11
Training loss: 3.300090360849307
Validation loss: 3.210631190239342

Epoch: 6| Step: 12
Training loss: 3.590729082290563
Validation loss: 3.2105168387724485

Epoch: 6| Step: 13
Training loss: 2.6369233680732127
Validation loss: 3.2082816797537697

Epoch: 30| Step: 0
Training loss: 2.7040267939509746
Validation loss: 3.208828693807444

Epoch: 6| Step: 1
Training loss: 3.109683227597463
Validation loss: 3.209929896954449

Epoch: 6| Step: 2
Training loss: 3.505666913458504
Validation loss: 3.209823171924011

Epoch: 6| Step: 3
Training loss: 3.4947475803889994
Validation loss: 3.209922776099479

Epoch: 6| Step: 4
Training loss: 3.3917701299259377
Validation loss: 3.2074995045404218

Epoch: 6| Step: 5
Training loss: 3.2246183953254364
Validation loss: 3.2064251146492397

Epoch: 6| Step: 6
Training loss: 4.282287249249285
Validation loss: 3.2057699748675716

Epoch: 6| Step: 7
Training loss: 4.1213036361689035
Validation loss: 3.209148441409859

Epoch: 6| Step: 8
Training loss: 3.265733342905966
Validation loss: 3.2109574058655617

Epoch: 6| Step: 9
Training loss: 2.46295461185838
Validation loss: 3.2108905069131835

Epoch: 6| Step: 10
Training loss: 3.5159198552567816
Validation loss: 3.207688101450727

Epoch: 6| Step: 11
Training loss: 3.561337063690178
Validation loss: 3.2097408007887926

Epoch: 6| Step: 12
Training loss: 3.94599627621954
Validation loss: 3.209417907470835

Epoch: 6| Step: 13
Training loss: 3.4827500732632166
Validation loss: 3.2106697185032256

Epoch: 31| Step: 0
Training loss: 3.131155132143384
Validation loss: 3.206096357273486

Epoch: 6| Step: 1
Training loss: 3.87094445426663
Validation loss: 3.2071598294945582

Epoch: 6| Step: 2
Training loss: 4.21932504761388
Validation loss: 3.2044012993008826

Epoch: 6| Step: 3
Training loss: 2.9066427642236112
Validation loss: 3.203432981429896

Epoch: 6| Step: 4
Training loss: 3.937973599486348
Validation loss: 3.203717954563367

Epoch: 6| Step: 5
Training loss: 3.9415190031258196
Validation loss: 3.202027152280871

Epoch: 6| Step: 6
Training loss: 3.23477465238257
Validation loss: 3.199390277213124

Epoch: 6| Step: 7
Training loss: 3.4379316579118697
Validation loss: 3.199354810301954

Epoch: 6| Step: 8
Training loss: 2.6174770821312223
Validation loss: 3.1985251688939993

Epoch: 6| Step: 9
Training loss: 3.8834225580227755
Validation loss: 3.1971791969504935

Epoch: 6| Step: 10
Training loss: 3.3014111882716777
Validation loss: 3.19524977937096

Epoch: 6| Step: 11
Training loss: 3.023143980776208
Validation loss: 3.1963916132477324

Epoch: 6| Step: 12
Training loss: 2.9272307407463307
Validation loss: 3.198719909954995

Epoch: 6| Step: 13
Training loss: 3.618365168162735
Validation loss: 3.1969000041463658

Epoch: 32| Step: 0
Training loss: 3.8040896343497206
Validation loss: 3.1978871873690853

Epoch: 6| Step: 1
Training loss: 3.7505693639218123
Validation loss: 3.1939855743258527

Epoch: 6| Step: 2
Training loss: 3.318977356790078
Validation loss: 3.1942750532463893

Epoch: 6| Step: 3
Training loss: 4.012732744448494
Validation loss: 3.1937526186168603

Epoch: 6| Step: 4
Training loss: 3.4193066577918296
Validation loss: 3.1912792609956875

Epoch: 6| Step: 5
Training loss: 2.7449714461823542
Validation loss: 3.191045428856962

Epoch: 6| Step: 6
Training loss: 3.3216821336425992
Validation loss: 3.196200179315401

Epoch: 6| Step: 7
Training loss: 3.4717193815856633
Validation loss: 3.189732930236864

Epoch: 6| Step: 8
Training loss: 3.2386793897286474
Validation loss: 3.1897832521305256

Epoch: 6| Step: 9
Training loss: 3.403817524431065
Validation loss: 3.1878255701574334

Epoch: 6| Step: 10
Training loss: 3.4752729788941803
Validation loss: 3.1891497790823147

Epoch: 6| Step: 11
Training loss: 3.4826576551035515
Validation loss: 3.186243324669136

Epoch: 6| Step: 12
Training loss: 3.4226551298841894
Validation loss: 3.1896068342874813

Epoch: 6| Step: 13
Training loss: 3.106316830935053
Validation loss: 3.1888762367678516

Epoch: 33| Step: 0
Training loss: 3.431863359616695
Validation loss: 3.189807912879851

Epoch: 6| Step: 1
Training loss: 4.1396656004524495
Validation loss: 3.1866693027523363

Epoch: 6| Step: 2
Training loss: 3.1229161753451566
Validation loss: 3.1843855560110703

Epoch: 6| Step: 3
Training loss: 4.076981307390377
Validation loss: 3.1905923344892657

Epoch: 6| Step: 4
Training loss: 3.2317582754443936
Validation loss: 3.1836402425133596

Epoch: 6| Step: 5
Training loss: 2.7569388499765033
Validation loss: 3.1819416026333944

Epoch: 6| Step: 6
Training loss: 3.7573297710018267
Validation loss: 3.1842723689613557

Epoch: 6| Step: 7
Training loss: 2.5233946994423175
Validation loss: 3.183752446308819

Epoch: 6| Step: 8
Training loss: 3.4494888701031954
Validation loss: 3.187025243545065

Epoch: 6| Step: 9
Training loss: 3.1993976026013473
Validation loss: 3.1877878289559227

Epoch: 6| Step: 10
Training loss: 3.0495371608068003
Validation loss: 3.1841631938405057

Epoch: 6| Step: 11
Training loss: 3.740852898433036
Validation loss: 3.1796713974237503

Epoch: 6| Step: 12
Training loss: 3.6035801992859193
Validation loss: 3.178420547587149

Epoch: 6| Step: 13
Training loss: 3.9037129212107833
Validation loss: 3.1758197748334114

Epoch: 34| Step: 0
Training loss: 3.255781606421625
Validation loss: 3.177162796928389

Epoch: 6| Step: 1
Training loss: 3.531230014980782
Validation loss: 3.1751849111529493

Epoch: 6| Step: 2
Training loss: 3.9003986937353945
Validation loss: 3.1728521280947812

Epoch: 6| Step: 3
Training loss: 3.990562152890435
Validation loss: 3.1756442701058907

Epoch: 6| Step: 4
Training loss: 3.2462137615544617
Validation loss: 3.174264732298488

Epoch: 6| Step: 5
Training loss: 3.095306929497133
Validation loss: 3.176357615815991

Epoch: 6| Step: 6
Training loss: 3.0326221938960094
Validation loss: 3.1820115537991005

Epoch: 6| Step: 7
Training loss: 3.1226868269823633
Validation loss: 3.1883359758244025

Epoch: 6| Step: 8
Training loss: 3.7295917858280436
Validation loss: 3.208369761594311

Epoch: 6| Step: 9
Training loss: 3.8240398174192065
Validation loss: 3.1936141538492864

Epoch: 6| Step: 10
Training loss: 3.461933758979582
Validation loss: 3.1785482971240415

Epoch: 6| Step: 11
Training loss: 3.100900420813252
Validation loss: 3.1744486056013965

Epoch: 6| Step: 12
Training loss: 3.3265567720363
Validation loss: 3.1713069922643724

Epoch: 6| Step: 13
Training loss: 3.220254787055628
Validation loss: 3.1700604769588963

Epoch: 35| Step: 0
Training loss: 2.3078090412008083
Validation loss: 3.174705700730688

Epoch: 6| Step: 1
Training loss: 4.178607665709451
Validation loss: 3.1892531960336505

Epoch: 6| Step: 2
Training loss: 3.545996603398813
Validation loss: 3.1672345517399045

Epoch: 6| Step: 3
Training loss: 3.590401856184291
Validation loss: 3.1723132305340513

Epoch: 6| Step: 4
Training loss: 3.1928553752217654
Validation loss: 3.1786838775884783

Epoch: 6| Step: 5
Training loss: 3.387009059338636
Validation loss: 3.193965816323945

Epoch: 6| Step: 6
Training loss: 3.8375643448296746
Validation loss: 3.2076146157518406

Epoch: 6| Step: 7
Training loss: 3.196018877739948
Validation loss: 3.195575477739418

Epoch: 6| Step: 8
Training loss: 4.152445263487499
Validation loss: 3.1908329238226947

Epoch: 6| Step: 9
Training loss: 3.7229779996055408
Validation loss: 3.1784092103218313

Epoch: 6| Step: 10
Training loss: 2.6872884977640275
Validation loss: 3.1694664589359522

Epoch: 6| Step: 11
Training loss: 3.368008754619175
Validation loss: 3.166395280723268

Epoch: 6| Step: 12
Training loss: 2.8062188263586845
Validation loss: 3.1682217562441477

Epoch: 6| Step: 13
Training loss: 3.839477894177531
Validation loss: 3.165778379305374

Epoch: 36| Step: 0
Training loss: 3.523444401973215
Validation loss: 3.1700628998351994

Epoch: 6| Step: 1
Training loss: 3.636154901409044
Validation loss: 3.1627362399549113

Epoch: 6| Step: 2
Training loss: 3.8680274744724765
Validation loss: 3.1608691476978916

Epoch: 6| Step: 3
Training loss: 2.665863502270519
Validation loss: 3.1550714060318183

Epoch: 6| Step: 4
Training loss: 2.978536597006085
Validation loss: 3.1569858579787033

Epoch: 6| Step: 5
Training loss: 3.4669099343360292
Validation loss: 3.157272135997178

Epoch: 6| Step: 6
Training loss: 4.304830171467369
Validation loss: 3.161047055848426

Epoch: 6| Step: 7
Training loss: 2.60728782280641
Validation loss: 3.1643140183694567

Epoch: 6| Step: 8
Training loss: 3.267869242065806
Validation loss: 3.1637875875929944

Epoch: 6| Step: 9
Training loss: 3.9534441551470296
Validation loss: 3.167468896055882

Epoch: 6| Step: 10
Training loss: 4.780093982043957
Validation loss: 3.1648572832273443

Epoch: 6| Step: 11
Training loss: 2.20449396983183
Validation loss: 3.158289515711135

Epoch: 6| Step: 12
Training loss: 2.929876946999745
Validation loss: 3.1570902668112337

Epoch: 6| Step: 13
Training loss: 2.270218290512692
Validation loss: 3.1537878731848967

Epoch: 37| Step: 0
Training loss: 3.310235166925692
Validation loss: 3.152542244024421

Epoch: 6| Step: 1
Training loss: 2.9890579311337926
Validation loss: 3.1526764537835694

Epoch: 6| Step: 2
Training loss: 3.5906450209627994
Validation loss: 3.154882533812555

Epoch: 6| Step: 3
Training loss: 3.2389547018173634
Validation loss: 3.1561133794660767

Epoch: 6| Step: 4
Training loss: 4.041956914069029
Validation loss: 3.1581646531476486

Epoch: 6| Step: 5
Training loss: 2.908949060124535
Validation loss: 3.151451905991552

Epoch: 6| Step: 6
Training loss: 3.226812542331768
Validation loss: 3.151167093233478

Epoch: 6| Step: 7
Training loss: 3.613444358649603
Validation loss: 3.149798801531515

Epoch: 6| Step: 8
Training loss: 3.3704732984756465
Validation loss: 3.1487214271285198

Epoch: 6| Step: 9
Training loss: 3.6986382581843262
Validation loss: 3.152588099105578

Epoch: 6| Step: 10
Training loss: 3.863784063035433
Validation loss: 3.1526938033869607

Epoch: 6| Step: 11
Training loss: 3.3860958102844316
Validation loss: 3.152019271317257

Epoch: 6| Step: 12
Training loss: 2.8506648910999863
Validation loss: 3.1524378000391655

Epoch: 6| Step: 13
Training loss: 3.5926980510744078
Validation loss: 3.152835691521625

Epoch: 38| Step: 0
Training loss: 3.58664897434546
Validation loss: 3.151727827690626

Epoch: 6| Step: 1
Training loss: 2.5316331361513598
Validation loss: 3.148267610241612

Epoch: 6| Step: 2
Training loss: 3.9983780672009903
Validation loss: 3.149480980374189

Epoch: 6| Step: 3
Training loss: 3.5541820124793877
Validation loss: 3.1499206661567456

Epoch: 6| Step: 4
Training loss: 3.922373584195746
Validation loss: 3.14589275055984

Epoch: 6| Step: 5
Training loss: 3.479929598611372
Validation loss: 3.1458320566060824

Epoch: 6| Step: 6
Training loss: 3.5737435113528395
Validation loss: 3.147608730256054

Epoch: 6| Step: 7
Training loss: 3.8267244229183737
Validation loss: 3.1465198838226804

Epoch: 6| Step: 8
Training loss: 3.189919096061294
Validation loss: 3.144784041072601

Epoch: 6| Step: 9
Training loss: 2.626328540845884
Validation loss: 3.1449485384227125

Epoch: 6| Step: 10
Training loss: 3.7296173562148836
Validation loss: 3.1446356353829774

Epoch: 6| Step: 11
Training loss: 3.5085774630480917
Validation loss: 3.1437343469401022

Epoch: 6| Step: 12
Training loss: 2.6044642672563745
Validation loss: 3.144370908476536

Epoch: 6| Step: 13
Training loss: 2.8685874743330366
Validation loss: 3.1438892966529375

Epoch: 39| Step: 0
Training loss: 3.758250506405405
Validation loss: 3.1416461557664412

Epoch: 6| Step: 1
Training loss: 3.617033524665577
Validation loss: 3.1424358683472033

Epoch: 6| Step: 2
Training loss: 3.1772496581185825
Validation loss: 3.141475121027252

Epoch: 6| Step: 3
Training loss: 3.269655505591398
Validation loss: 3.141321984763301

Epoch: 6| Step: 4
Training loss: 3.105085471630823
Validation loss: 3.1408761506217835

Epoch: 6| Step: 5
Training loss: 4.139803131877544
Validation loss: 3.139825583575792

Epoch: 6| Step: 6
Training loss: 3.4899492366126617
Validation loss: 3.1400917191046

Epoch: 6| Step: 7
Training loss: 3.3512987153077884
Validation loss: 3.137771561551575

Epoch: 6| Step: 8
Training loss: 3.5951881516499467
Validation loss: 3.140696760302735

Epoch: 6| Step: 9
Training loss: 2.8153979312562587
Validation loss: 3.140361667303451

Epoch: 6| Step: 10
Training loss: 3.697597837359507
Validation loss: 3.13880707232472

Epoch: 6| Step: 11
Training loss: 2.6613815107412413
Validation loss: 3.1373532213053

Epoch: 6| Step: 12
Training loss: 3.333484900525462
Validation loss: 3.137564812872306

Epoch: 6| Step: 13
Training loss: 3.2917709977882548
Validation loss: 3.136781487782305

Epoch: 40| Step: 0
Training loss: 3.6918252697035223
Validation loss: 3.137780123971329

Epoch: 6| Step: 1
Training loss: 2.9621634247879314
Validation loss: 3.1373698720178345

Epoch: 6| Step: 2
Training loss: 4.145514598971182
Validation loss: 3.1378727992317756

Epoch: 6| Step: 3
Training loss: 3.8471717800562573
Validation loss: 3.1375981895850003

Epoch: 6| Step: 4
Training loss: 3.299561477192456
Validation loss: 3.138431590234926

Epoch: 6| Step: 5
Training loss: 2.9174127623550543
Validation loss: 3.1370429235173876

Epoch: 6| Step: 6
Training loss: 3.3006253719203213
Validation loss: 3.1388231150121224

Epoch: 6| Step: 7
Training loss: 3.17409584207422
Validation loss: 3.1331826562811695

Epoch: 6| Step: 8
Training loss: 2.9449807544331987
Validation loss: 3.130268369825838

Epoch: 6| Step: 9
Training loss: 3.462806902893737
Validation loss: 3.1295744920129227

Epoch: 6| Step: 10
Training loss: 3.0545235904513857
Validation loss: 3.1284685750405754

Epoch: 6| Step: 11
Training loss: 3.5385055945916695
Validation loss: 3.1266463014292016

Epoch: 6| Step: 12
Training loss: 3.4063115945549107
Validation loss: 3.1255807201649235

Epoch: 6| Step: 13
Training loss: 3.5949869432066333
Validation loss: 3.124232332014709

Epoch: 41| Step: 0
Training loss: 4.100696755728993
Validation loss: 3.1207099146779984

Epoch: 6| Step: 1
Training loss: 2.7109783070595856
Validation loss: 3.1197810920205913

Epoch: 6| Step: 2
Training loss: 2.8870824602782457
Validation loss: 3.1126381195177366

Epoch: 6| Step: 3
Training loss: 3.8025464058978096
Validation loss: 3.108832619697625

Epoch: 6| Step: 4
Training loss: 3.2239727128816957
Validation loss: 3.105469090116088

Epoch: 6| Step: 5
Training loss: 3.770580276231609
Validation loss: 3.102833171491305

Epoch: 6| Step: 6
Training loss: 3.5310302936093887
Validation loss: 3.1005897987683393

Epoch: 6| Step: 7
Training loss: 3.174050472980746
Validation loss: 3.09936795683536

Epoch: 6| Step: 8
Training loss: 2.8178681747217813
Validation loss: 3.0982702649372493

Epoch: 6| Step: 9
Training loss: 3.4565349330342565
Validation loss: 3.0993709461521872

Epoch: 6| Step: 10
Training loss: 3.7958910259687744
Validation loss: 3.099460697930487

Epoch: 6| Step: 11
Training loss: 3.600806167195193
Validation loss: 3.0974842098191524

Epoch: 6| Step: 12
Training loss: 3.0460288413392456
Validation loss: 3.095971509880977

Epoch: 6| Step: 13
Training loss: 2.5137525899713453
Validation loss: 3.0983556045312266

Epoch: 42| Step: 0
Training loss: 3.659558486573263
Validation loss: 3.1026598129208747

Epoch: 6| Step: 1
Training loss: 3.636121198852109
Validation loss: 3.0974637030045935

Epoch: 6| Step: 2
Training loss: 2.312008161048609
Validation loss: 3.0969217448563624

Epoch: 6| Step: 3
Training loss: 3.5570243113161237
Validation loss: 3.1003096219138015

Epoch: 6| Step: 4
Training loss: 3.5174300921446897
Validation loss: 3.101641743354036

Epoch: 6| Step: 5
Training loss: 3.454671246004278
Validation loss: 3.0983980856250666

Epoch: 6| Step: 6
Training loss: 3.3054671574018264
Validation loss: 3.093912690675499

Epoch: 6| Step: 7
Training loss: 3.158097736626736
Validation loss: 3.0910321052917378

Epoch: 6| Step: 8
Training loss: 3.64029217291511
Validation loss: 3.0922635409232426

Epoch: 6| Step: 9
Training loss: 3.457401303243157
Validation loss: 3.092405321778844

Epoch: 6| Step: 10
Training loss: 3.4850054115023528
Validation loss: 3.0896717394581725

Epoch: 6| Step: 11
Training loss: 3.250526678985407
Validation loss: 3.0897169444817134

Epoch: 6| Step: 12
Training loss: 3.1964673331453324
Validation loss: 3.0907511117989035

Epoch: 6| Step: 13
Training loss: 3.2046564674455857
Validation loss: 3.0913408415586376

Epoch: 43| Step: 0
Training loss: 3.4758011916607363
Validation loss: 3.0912761805713456

Epoch: 6| Step: 1
Training loss: 3.1096516395075184
Validation loss: 3.0909282502248545

Epoch: 6| Step: 2
Training loss: 3.119578732636221
Validation loss: 3.088888203711896

Epoch: 6| Step: 3
Training loss: 3.5103586043056563
Validation loss: 3.0867939219765854

Epoch: 6| Step: 4
Training loss: 3.411690243513908
Validation loss: 3.0867722071535306

Epoch: 6| Step: 5
Training loss: 3.2050336408114206
Validation loss: 3.0857034208410075

Epoch: 6| Step: 6
Training loss: 3.4145965507644074
Validation loss: 3.0863251082980527

Epoch: 6| Step: 7
Training loss: 3.4091319919769463
Validation loss: 3.085769016105283

Epoch: 6| Step: 8
Training loss: 3.2949949571863235
Validation loss: 3.085462108592971

Epoch: 6| Step: 9
Training loss: 3.998671311000439
Validation loss: 3.08576195932678

Epoch: 6| Step: 10
Training loss: 2.3065335396660704
Validation loss: 3.0854723449851633

Epoch: 6| Step: 11
Training loss: 2.9842449379585863
Validation loss: 3.0849014580487313

Epoch: 6| Step: 12
Training loss: 3.7690588778671397
Validation loss: 3.086982716399359

Epoch: 6| Step: 13
Training loss: 3.90855620398779
Validation loss: 3.085994219722764

Epoch: 44| Step: 0
Training loss: 3.400579930381734
Validation loss: 3.085211013882379

Epoch: 6| Step: 1
Training loss: 3.0009131631258628
Validation loss: 3.0851468493049

Epoch: 6| Step: 2
Training loss: 3.5965343801254446
Validation loss: 3.0818180117711855

Epoch: 6| Step: 3
Training loss: 2.754617282710348
Validation loss: 3.0851292478118433

Epoch: 6| Step: 4
Training loss: 3.5457449974116755
Validation loss: 3.083201864267212

Epoch: 6| Step: 5
Training loss: 3.5636038157687673
Validation loss: 3.081994941616401

Epoch: 6| Step: 6
Training loss: 3.2020182860863167
Validation loss: 3.081721617672944

Epoch: 6| Step: 7
Training loss: 3.772490262068914
Validation loss: 3.0811203684203403

Epoch: 6| Step: 8
Training loss: 3.5196835297592033
Validation loss: 3.0804415070536963

Epoch: 6| Step: 9
Training loss: 2.9895836877767286
Validation loss: 3.0781668191753644

Epoch: 6| Step: 10
Training loss: 3.0455799969801105
Validation loss: 3.075880374200061

Epoch: 6| Step: 11
Training loss: 3.6952505610559583
Validation loss: 3.0788260715555804

Epoch: 6| Step: 12
Training loss: 3.2061101633850235
Validation loss: 3.0763504045789616

Epoch: 6| Step: 13
Training loss: 3.4462778551195634
Validation loss: 3.0779652903627097

Epoch: 45| Step: 0
Training loss: 2.8571355002172303
Validation loss: 3.0734669844190727

Epoch: 6| Step: 1
Training loss: 3.5313212969848924
Validation loss: 3.074423758111902

Epoch: 6| Step: 2
Training loss: 3.2246484136037874
Validation loss: 3.072802717801622

Epoch: 6| Step: 3
Training loss: 3.4624905858101234
Validation loss: 3.0743997445024727

Epoch: 6| Step: 4
Training loss: 3.079394083740117
Validation loss: 3.072973385067199

Epoch: 6| Step: 5
Training loss: 2.9242989180814742
Validation loss: 3.0731171837498494

Epoch: 6| Step: 6
Training loss: 2.9718271470253574
Validation loss: 3.0715981573494284

Epoch: 6| Step: 7
Training loss: 3.2429051351867066
Validation loss: 3.071533292745034

Epoch: 6| Step: 8
Training loss: 4.31000347022251
Validation loss: 3.0706465327889663

Epoch: 6| Step: 9
Training loss: 4.113375381015752
Validation loss: 3.0716321615593802

Epoch: 6| Step: 10
Training loss: 3.3647299026987643
Validation loss: 3.0694713657856414

Epoch: 6| Step: 11
Training loss: 3.204753480378033
Validation loss: 3.0695779428915633

Epoch: 6| Step: 12
Training loss: 2.811577285298641
Validation loss: 3.0690357465933142

Epoch: 6| Step: 13
Training loss: 3.3681642040718294
Validation loss: 3.0687026512410065

Epoch: 46| Step: 0
Training loss: 3.65737845458112
Validation loss: 3.068153916557292

Epoch: 6| Step: 1
Training loss: 2.8925479575676207
Validation loss: 3.067953635225371

Epoch: 6| Step: 2
Training loss: 3.254472149826915
Validation loss: 3.0682122601325807

Epoch: 6| Step: 3
Training loss: 3.0125710633313023
Validation loss: 3.067232859171024

Epoch: 6| Step: 4
Training loss: 3.3320083527935425
Validation loss: 3.0689103618302056

Epoch: 6| Step: 5
Training loss: 3.341927860798648
Validation loss: 3.070156933144821

Epoch: 6| Step: 6
Training loss: 4.396197600737092
Validation loss: 3.071881737367471

Epoch: 6| Step: 7
Training loss: 2.5091028429333093
Validation loss: 3.073666634593553

Epoch: 6| Step: 8
Training loss: 3.07713309634981
Validation loss: 3.0704680188964333

Epoch: 6| Step: 9
Training loss: 3.337208561549063
Validation loss: 3.067905066987982

Epoch: 6| Step: 10
Training loss: 3.376161446114432
Validation loss: 3.0651009192183674

Epoch: 6| Step: 11
Training loss: 3.3664905508326046
Validation loss: 3.0642010834478337

Epoch: 6| Step: 12
Training loss: 3.7041168816006054
Validation loss: 3.062791147093957

Epoch: 6| Step: 13
Training loss: 2.9155869983351277
Validation loss: 3.0634987403612657

Epoch: 47| Step: 0
Training loss: 3.101968964431918
Validation loss: 3.0629958303249865

Epoch: 6| Step: 1
Training loss: 3.0278745124443898
Validation loss: 3.070700152891606

Epoch: 6| Step: 2
Training loss: 3.9623272205313227
Validation loss: 3.0679351445903484

Epoch: 6| Step: 3
Training loss: 3.1429022129344655
Validation loss: 3.0621835923120897

Epoch: 6| Step: 4
Training loss: 2.9703406640111703
Validation loss: 3.0623972852306487

Epoch: 6| Step: 5
Training loss: 3.6104603906542043
Validation loss: 3.0612009678227765

Epoch: 6| Step: 6
Training loss: 3.361374938390603
Validation loss: 3.061149880516635

Epoch: 6| Step: 7
Training loss: 3.5345216971932265
Validation loss: 3.063635474350723

Epoch: 6| Step: 8
Training loss: 3.237131022632607
Validation loss: 3.063748228983068

Epoch: 6| Step: 9
Training loss: 3.439237952880435
Validation loss: 3.065420989893742

Epoch: 6| Step: 10
Training loss: 2.477268154563215
Validation loss: 3.0618300333979094

Epoch: 6| Step: 11
Training loss: 3.383363040236169
Validation loss: 3.060327226665206

Epoch: 6| Step: 12
Training loss: 3.95172395870316
Validation loss: 3.060130329489295

Epoch: 6| Step: 13
Training loss: 3.187339329877536
Validation loss: 3.060180142018544

Epoch: 48| Step: 0
Training loss: 2.4542967312278625
Validation loss: 3.057841590465758

Epoch: 6| Step: 1
Training loss: 2.875770631421835
Validation loss: 3.0582479693409876

Epoch: 6| Step: 2
Training loss: 3.310020958641058
Validation loss: 3.0590706317561773

Epoch: 6| Step: 3
Training loss: 2.9849661196730026
Validation loss: 3.056879214105609

Epoch: 6| Step: 4
Training loss: 3.4730169497273207
Validation loss: 3.057115830696656

Epoch: 6| Step: 5
Training loss: 3.5902675839215266
Validation loss: 3.060598318311556

Epoch: 6| Step: 6
Training loss: 2.4717592658379206
Validation loss: 3.060669511613946

Epoch: 6| Step: 7
Training loss: 3.089704855245772
Validation loss: 3.0624676891679203

Epoch: 6| Step: 8
Training loss: 4.388554312163137
Validation loss: 3.0627147188268817

Epoch: 6| Step: 9
Training loss: 3.578353674631946
Validation loss: 3.063313879774134

Epoch: 6| Step: 10
Training loss: 3.0230922452561115
Validation loss: 3.0585808571457695

Epoch: 6| Step: 11
Training loss: 3.579095700455636
Validation loss: 3.0572654148738523

Epoch: 6| Step: 12
Training loss: 3.5473049088130084
Validation loss: 3.0535170181488414

Epoch: 6| Step: 13
Training loss: 3.9715296105159017
Validation loss: 3.0531015035811038

Epoch: 49| Step: 0
Training loss: 2.661663328712901
Validation loss: 3.0523576250262274

Epoch: 6| Step: 1
Training loss: 3.7116282251905632
Validation loss: 3.0512546913899445

Epoch: 6| Step: 2
Training loss: 2.6306526538993187
Validation loss: 3.052310341446629

Epoch: 6| Step: 3
Training loss: 1.854579222426111
Validation loss: 3.054413605822189

Epoch: 6| Step: 4
Training loss: 3.2601915633197103
Validation loss: 3.052581184289033

Epoch: 6| Step: 5
Training loss: 2.7887933852353113
Validation loss: 3.0543143542244326

Epoch: 6| Step: 6
Training loss: 3.911075998338912
Validation loss: 3.051988919340643

Epoch: 6| Step: 7
Training loss: 3.2412040229946584
Validation loss: 3.050360239461815

Epoch: 6| Step: 8
Training loss: 3.8117984063640193
Validation loss: 3.0506067049470484

Epoch: 6| Step: 9
Training loss: 3.041331721288557
Validation loss: 3.049950732615431

Epoch: 6| Step: 10
Training loss: 3.9145138417495136
Validation loss: 3.0479948793410823

Epoch: 6| Step: 11
Training loss: 3.660681231944292
Validation loss: 3.0483027879936815

Epoch: 6| Step: 12
Training loss: 3.3440658562759853
Validation loss: 3.0479550080091546

Epoch: 6| Step: 13
Training loss: 4.3983175962647705
Validation loss: 3.049057017268318

Epoch: 50| Step: 0
Training loss: 3.8655738623651197
Validation loss: 3.0471279665065762

Epoch: 6| Step: 1
Training loss: 2.6465670752184556
Validation loss: 3.048665516647143

Epoch: 6| Step: 2
Training loss: 3.188321774334318
Validation loss: 3.04645648497833

Epoch: 6| Step: 3
Training loss: 2.9618250339509054
Validation loss: 3.0447645124022262

Epoch: 6| Step: 4
Training loss: 3.888632145232755
Validation loss: 3.045953182576504

Epoch: 6| Step: 5
Training loss: 3.258853883130049
Validation loss: 3.0463050462757995

Epoch: 6| Step: 6
Training loss: 3.0896884961192703
Validation loss: 3.046829525356059

Epoch: 6| Step: 7
Training loss: 2.9706329798897233
Validation loss: 3.0439276294112445

Epoch: 6| Step: 8
Training loss: 2.875586076790987
Validation loss: 3.044859581769596

Epoch: 6| Step: 9
Training loss: 3.310454114666521
Validation loss: 3.0447353745914114

Epoch: 6| Step: 10
Training loss: 3.9269955707055884
Validation loss: 3.044412974216983

Epoch: 6| Step: 11
Training loss: 4.2119451955506575
Validation loss: 3.045056398838872

Epoch: 6| Step: 12
Training loss: 3.028060808475725
Validation loss: 3.0477238934729667

Epoch: 6| Step: 13
Training loss: 2.295980370088726
Validation loss: 3.04562801383199

Epoch: 51| Step: 0
Training loss: 3.1653992643016466
Validation loss: 3.0441700361044144

Epoch: 6| Step: 1
Training loss: 2.37007755329706
Validation loss: 3.0437990339836127

Epoch: 6| Step: 2
Training loss: 2.8936214278394066
Validation loss: 3.0431867423439933

Epoch: 6| Step: 3
Training loss: 3.719387993460542
Validation loss: 3.041428295498435

Epoch: 6| Step: 4
Training loss: 3.2010136786910164
Validation loss: 3.042593921837562

Epoch: 6| Step: 5
Training loss: 3.095540308957763
Validation loss: 3.0400051619723913

Epoch: 6| Step: 6
Training loss: 2.7440646883955053
Validation loss: 3.0408438292876427

Epoch: 6| Step: 7
Training loss: 3.2138238635601626
Validation loss: 3.0376564242514124

Epoch: 6| Step: 8
Training loss: 3.34550729368866
Validation loss: 3.037844268135386

Epoch: 6| Step: 9
Training loss: 4.110863245688898
Validation loss: 3.0364411329181413

Epoch: 6| Step: 10
Training loss: 4.39833255730714
Validation loss: 3.03793226804132

Epoch: 6| Step: 11
Training loss: 3.2831370422502624
Validation loss: 3.035813244593823

Epoch: 6| Step: 12
Training loss: 2.961626199228647
Validation loss: 3.0375159517024053

Epoch: 6| Step: 13
Training loss: 3.3892314525821874
Validation loss: 3.0366592409711233

Epoch: 52| Step: 0
Training loss: 2.781321578229871
Validation loss: 3.0345748868480094

Epoch: 6| Step: 1
Training loss: 2.867597919578186
Validation loss: 3.0355856052203487

Epoch: 6| Step: 2
Training loss: 4.088180130769217
Validation loss: 3.0352039013242993

Epoch: 6| Step: 3
Training loss: 3.425689661243611
Validation loss: 3.035277637098327

Epoch: 6| Step: 4
Training loss: 3.877939032584434
Validation loss: 3.0366768633894137

Epoch: 6| Step: 5
Training loss: 3.545895613509272
Validation loss: 3.0362973695132935

Epoch: 6| Step: 6
Training loss: 2.6253688189851463
Validation loss: 3.037561204554364

Epoch: 6| Step: 7
Training loss: 2.8923770028408295
Validation loss: 3.0380942543179037

Epoch: 6| Step: 8
Training loss: 3.2672545825232295
Validation loss: 3.0371862391155253

Epoch: 6| Step: 9
Training loss: 2.8199794075937734
Validation loss: 3.0352016917573112

Epoch: 6| Step: 10
Training loss: 3.6521523491793455
Validation loss: 3.033677266309196

Epoch: 6| Step: 11
Training loss: 3.3265047382806645
Validation loss: 3.030878597164241

Epoch: 6| Step: 12
Training loss: 3.2209733117510004
Validation loss: 3.030171589760147

Epoch: 6| Step: 13
Training loss: 3.737206315459654
Validation loss: 3.0316704958552303

Epoch: 53| Step: 0
Training loss: 2.52463080473677
Validation loss: 3.031686423062556

Epoch: 6| Step: 1
Training loss: 3.103278389296489
Validation loss: 3.0374749485827635

Epoch: 6| Step: 2
Training loss: 3.1854094587352195
Validation loss: 3.0414201841953448

Epoch: 6| Step: 3
Training loss: 3.4798155919905085
Validation loss: 3.050335523741925

Epoch: 6| Step: 4
Training loss: 3.9709384921633983
Validation loss: 3.05310848302695

Epoch: 6| Step: 5
Training loss: 3.29944412867191
Validation loss: 3.046176541112554

Epoch: 6| Step: 6
Training loss: 3.281123858252437
Validation loss: 3.0412568054868925

Epoch: 6| Step: 7
Training loss: 3.3895177483539234
Validation loss: 3.0346517805227498

Epoch: 6| Step: 8
Training loss: 3.441059004100649
Validation loss: 3.0273485278020096

Epoch: 6| Step: 9
Training loss: 3.6147665074498723
Validation loss: 3.0257187633746567

Epoch: 6| Step: 10
Training loss: 3.4170554025214996
Validation loss: 3.0270432405710515

Epoch: 6| Step: 11
Training loss: 3.02739336526883
Validation loss: 3.024384543837766

Epoch: 6| Step: 12
Training loss: 2.944035989593201
Validation loss: 3.025909636699569

Epoch: 6| Step: 13
Training loss: 3.5081353325745166
Validation loss: 3.0240844600786865

Epoch: 54| Step: 0
Training loss: 3.1548186729786862
Validation loss: 3.022195586253136

Epoch: 6| Step: 1
Training loss: 2.9118761958119594
Validation loss: 3.0223993628997463

Epoch: 6| Step: 2
Training loss: 3.8269874595354887
Validation loss: 3.022596360904021

Epoch: 6| Step: 3
Training loss: 2.7004926797152775
Validation loss: 3.0221497648553948

Epoch: 6| Step: 4
Training loss: 3.570948571237801
Validation loss: 3.0209881876857443

Epoch: 6| Step: 5
Training loss: 2.6385020011473546
Validation loss: 3.0227630618498775

Epoch: 6| Step: 6
Training loss: 4.025984289526193
Validation loss: 3.0205083523017153

Epoch: 6| Step: 7
Training loss: 2.9544890951903398
Validation loss: 3.0227347093437027

Epoch: 6| Step: 8
Training loss: 2.850988711802742
Validation loss: 3.018885303827131

Epoch: 6| Step: 9
Training loss: 3.8590824155288197
Validation loss: 3.0175978655192157

Epoch: 6| Step: 10
Training loss: 3.340972317089678
Validation loss: 3.0133559978223357

Epoch: 6| Step: 11
Training loss: 3.2248771644087317
Validation loss: 3.0121062506024643

Epoch: 6| Step: 12
Training loss: 3.5010554220982444
Validation loss: 3.0094120804741578

Epoch: 6| Step: 13
Training loss: 3.169711874012812
Validation loss: 3.007280520616377

Epoch: 55| Step: 0
Training loss: 2.8792239134231865
Validation loss: 3.008836159230323

Epoch: 6| Step: 1
Training loss: 2.9916775022291007
Validation loss: 3.0058953714839634

Epoch: 6| Step: 2
Training loss: 3.213135053154786
Validation loss: 3.0068976040166837

Epoch: 6| Step: 3
Training loss: 3.9217157217562963
Validation loss: 3.0076421439323098

Epoch: 6| Step: 4
Training loss: 3.4701304395273076
Validation loss: 3.009309306906936

Epoch: 6| Step: 5
Training loss: 3.4042164743266765
Validation loss: 3.011609189378226

Epoch: 6| Step: 6
Training loss: 2.872113312805015
Validation loss: 3.012786663558016

Epoch: 6| Step: 7
Training loss: 3.0757877364319146
Validation loss: 3.00789410922957

Epoch: 6| Step: 8
Training loss: 3.1096192843837067
Validation loss: 3.0084321641838088

Epoch: 6| Step: 9
Training loss: 3.3971466769987937
Validation loss: 3.0051842847417682

Epoch: 6| Step: 10
Training loss: 3.033924456697588
Validation loss: 3.002319373375096

Epoch: 6| Step: 11
Training loss: 3.5810329830863257
Validation loss: 3.000076891142753

Epoch: 6| Step: 12
Training loss: 3.6279930386460717
Validation loss: 3.005083509575458

Epoch: 6| Step: 13
Training loss: 3.230370590397664
Validation loss: 3.0064419847272

Epoch: 56| Step: 0
Training loss: 3.65092772098777
Validation loss: 3.0034903334875063

Epoch: 6| Step: 1
Training loss: 3.2539507987646723
Validation loss: 3.0005926449223645

Epoch: 6| Step: 2
Training loss: 3.8615706526326097
Validation loss: 2.9979256274107016

Epoch: 6| Step: 3
Training loss: 2.7706257065923348
Validation loss: 2.998598275465596

Epoch: 6| Step: 4
Training loss: 3.386731703226382
Validation loss: 2.9984619144077005

Epoch: 6| Step: 5
Training loss: 4.091734644887765
Validation loss: 3.0009158079967664

Epoch: 6| Step: 6
Training loss: 3.7082062317286577
Validation loss: 2.9997501166675926

Epoch: 6| Step: 7
Training loss: 2.96760649492412
Validation loss: 2.9995713611366464

Epoch: 6| Step: 8
Training loss: 3.6818869591827768
Validation loss: 2.9970531295328544

Epoch: 6| Step: 9
Training loss: 2.5657647897457063
Validation loss: 2.999607019424435

Epoch: 6| Step: 10
Training loss: 2.489307617072376
Validation loss: 2.9964270661890167

Epoch: 6| Step: 11
Training loss: 3.3748667655360305
Validation loss: 2.9957064082895677

Epoch: 6| Step: 12
Training loss: 2.5494716022029844
Validation loss: 2.996801903782651

Epoch: 6| Step: 13
Training loss: 2.8523160591965073
Validation loss: 2.994060538323998

Epoch: 57| Step: 0
Training loss: 3.4807411027348154
Validation loss: 2.996647691385206

Epoch: 6| Step: 1
Training loss: 2.950716520028209
Validation loss: 2.995838296914015

Epoch: 6| Step: 2
Training loss: 3.013625356595772
Validation loss: 2.9939579347894734

Epoch: 6| Step: 3
Training loss: 3.0712219910204213
Validation loss: 2.9929537658789993

Epoch: 6| Step: 4
Training loss: 3.397006871559845
Validation loss: 2.993116690904143

Epoch: 6| Step: 5
Training loss: 3.1569811285770153
Validation loss: 2.991649316147898

Epoch: 6| Step: 6
Training loss: 3.6298315800460372
Validation loss: 2.992334981285845

Epoch: 6| Step: 7
Training loss: 3.2585923978902884
Validation loss: 2.98969221065133

Epoch: 6| Step: 8
Training loss: 3.2636075883854048
Validation loss: 2.991813261638419

Epoch: 6| Step: 9
Training loss: 3.0115026255442094
Validation loss: 2.9895542599707614

Epoch: 6| Step: 10
Training loss: 3.2854437775945677
Validation loss: 2.9893892995655076

Epoch: 6| Step: 11
Training loss: 3.6342741620153514
Validation loss: 2.990623431825166

Epoch: 6| Step: 12
Training loss: 2.978680835582032
Validation loss: 2.9886400563258024

Epoch: 6| Step: 13
Training loss: 3.8031145482793423
Validation loss: 2.9890357464266755

Epoch: 58| Step: 0
Training loss: 3.238281839000248
Validation loss: 2.990420459499834

Epoch: 6| Step: 1
Training loss: 2.7174990176538625
Validation loss: 2.9884108905953735

Epoch: 6| Step: 2
Training loss: 3.717894896599177
Validation loss: 2.988415986713266

Epoch: 6| Step: 3
Training loss: 3.672632017625731
Validation loss: 2.987278243470867

Epoch: 6| Step: 4
Training loss: 3.3095914919376166
Validation loss: 2.9878331688583963

Epoch: 6| Step: 5
Training loss: 3.588274424899616
Validation loss: 2.987818510294287

Epoch: 6| Step: 6
Training loss: 2.5274521393211065
Validation loss: 2.986864936487445

Epoch: 6| Step: 7
Training loss: 3.307986657518189
Validation loss: 2.9895271180790144

Epoch: 6| Step: 8
Training loss: 3.469719278814829
Validation loss: 2.9878212216707327

Epoch: 6| Step: 9
Training loss: 2.9133612476760327
Validation loss: 2.988203946381183

Epoch: 6| Step: 10
Training loss: 3.497127444075698
Validation loss: 2.988114818292409

Epoch: 6| Step: 11
Training loss: 2.840870331933312
Validation loss: 2.9874750139116046

Epoch: 6| Step: 12
Training loss: 3.137769625199593
Validation loss: 2.9862136618755715

Epoch: 6| Step: 13
Training loss: 3.7448512016448583
Validation loss: 2.986196971885331

Epoch: 59| Step: 0
Training loss: 2.9365950468800346
Validation loss: 2.984870686078376

Epoch: 6| Step: 1
Training loss: 3.051181039245775
Validation loss: 2.982622831975479

Epoch: 6| Step: 2
Training loss: 3.2279974676828957
Validation loss: 2.9836988584596904

Epoch: 6| Step: 3
Training loss: 2.172672152881108
Validation loss: 2.9832888675917957

Epoch: 6| Step: 4
Training loss: 3.5545049264154382
Validation loss: 2.9831545730558107

Epoch: 6| Step: 5
Training loss: 3.620264050880226
Validation loss: 2.9819920075721846

Epoch: 6| Step: 6
Training loss: 3.4716822971597083
Validation loss: 2.9817242362370484

Epoch: 6| Step: 7
Training loss: 3.2343586354601865
Validation loss: 2.9788715937251857

Epoch: 6| Step: 8
Training loss: 3.519953796560323
Validation loss: 2.981237701172571

Epoch: 6| Step: 9
Training loss: 3.8059329397254245
Validation loss: 2.980030763757324

Epoch: 6| Step: 10
Training loss: 3.662454931613307
Validation loss: 2.9798664935010906

Epoch: 6| Step: 11
Training loss: 2.7252683874828687
Validation loss: 2.980689427972613

Epoch: 6| Step: 12
Training loss: 2.979462259918116
Validation loss: 2.977384534333634

Epoch: 6| Step: 13
Training loss: 3.430472525253773
Validation loss: 2.978956476001143

Epoch: 60| Step: 0
Training loss: 2.3548579143578845
Validation loss: 2.979204924687944

Epoch: 6| Step: 1
Training loss: 3.719902565203085
Validation loss: 2.977516011903075

Epoch: 6| Step: 2
Training loss: 3.3970141707813433
Validation loss: 2.9789879249966615

Epoch: 6| Step: 3
Training loss: 2.479370643067625
Validation loss: 2.9802830419625046

Epoch: 6| Step: 4
Training loss: 3.4900776679023524
Validation loss: 2.9794020114851523

Epoch: 6| Step: 5
Training loss: 3.4158714268361
Validation loss: 2.9839329262464327

Epoch: 6| Step: 6
Training loss: 2.9756155835719587
Validation loss: 2.9813518686403357

Epoch: 6| Step: 7
Training loss: 3.6649207958286447
Validation loss: 2.980557407451883

Epoch: 6| Step: 8
Training loss: 3.387242752949252
Validation loss: 2.977275087529084

Epoch: 6| Step: 9
Training loss: 2.9263214712690826
Validation loss: 2.9779172830861347

Epoch: 6| Step: 10
Training loss: 3.3698794762767625
Validation loss: 2.9763166585386895

Epoch: 6| Step: 11
Training loss: 3.712374824443001
Validation loss: 2.976576083146402

Epoch: 6| Step: 12
Training loss: 3.081860749105949
Validation loss: 2.975715547501502

Epoch: 6| Step: 13
Training loss: 3.329250807926257
Validation loss: 2.9740942484737154

Epoch: 61| Step: 0
Training loss: 3.3879122099688557
Validation loss: 2.9722132845748597

Epoch: 6| Step: 1
Training loss: 3.5739449818309033
Validation loss: 2.9727641317538023

Epoch: 6| Step: 2
Training loss: 2.979930184077731
Validation loss: 2.972117890024524

Epoch: 6| Step: 3
Training loss: 4.12168057137157
Validation loss: 2.973610940330092

Epoch: 6| Step: 4
Training loss: 3.5043248295479583
Validation loss: 2.9748964835088505

Epoch: 6| Step: 5
Training loss: 3.6419249739065145
Validation loss: 2.9711209288206355

Epoch: 6| Step: 6
Training loss: 3.194094250783114
Validation loss: 2.9710625372579798

Epoch: 6| Step: 7
Training loss: 3.2389371826543893
Validation loss: 2.9717044086638564

Epoch: 6| Step: 8
Training loss: 3.275539697338118
Validation loss: 2.9694986570584008

Epoch: 6| Step: 9
Training loss: 2.845257370072719
Validation loss: 2.969374662093173

Epoch: 6| Step: 10
Training loss: 3.1930108396380206
Validation loss: 2.9699739101873366

Epoch: 6| Step: 11
Training loss: 2.869944232039977
Validation loss: 2.968173472668173

Epoch: 6| Step: 12
Training loss: 2.6930780409062827
Validation loss: 2.973207366045329

Epoch: 6| Step: 13
Training loss: 2.1677233857844067
Validation loss: 2.9726715404432085

Epoch: 62| Step: 0
Training loss: 3.7185118783317654
Validation loss: 2.9776651049194647

Epoch: 6| Step: 1
Training loss: 3.3824561374073094
Validation loss: 2.986741055639003

Epoch: 6| Step: 2
Training loss: 3.1199782649530263
Validation loss: 2.9840010636539525

Epoch: 6| Step: 3
Training loss: 2.846988720093367
Validation loss: 2.9845770451954015

Epoch: 6| Step: 4
Training loss: 3.022902172710253
Validation loss: 2.9800787218824194

Epoch: 6| Step: 5
Training loss: 3.2817553903014254
Validation loss: 2.9852480052539554

Epoch: 6| Step: 6
Training loss: 3.219210841696819
Validation loss: 2.977759721693382

Epoch: 6| Step: 7
Training loss: 3.2816330459084004
Validation loss: 2.967061139360725

Epoch: 6| Step: 8
Training loss: 3.8939411783815894
Validation loss: 2.9632245476279504

Epoch: 6| Step: 9
Training loss: 3.352802749606812
Validation loss: 2.964164844981616

Epoch: 6| Step: 10
Training loss: 3.335185696580667
Validation loss: 2.9682091263962365

Epoch: 6| Step: 11
Training loss: 3.1683588693209437
Validation loss: 2.9640347783314267

Epoch: 6| Step: 12
Training loss: 2.0127945773222975
Validation loss: 2.9632672581606028

Epoch: 6| Step: 13
Training loss: 3.7046600894243764
Validation loss: 2.9617855952608134

Epoch: 63| Step: 0
Training loss: 2.513115999992628
Validation loss: 2.9630489026559044

Epoch: 6| Step: 1
Training loss: 3.1004359892383295
Validation loss: 2.9701561197621653

Epoch: 6| Step: 2
Training loss: 3.6247336191104136
Validation loss: 2.9739197187461763

Epoch: 6| Step: 3
Training loss: 3.6712666758391377
Validation loss: 2.9819840844981376

Epoch: 6| Step: 4
Training loss: 3.6781557300615972
Validation loss: 2.9915815714625915

Epoch: 6| Step: 5
Training loss: 3.7597963168390134
Validation loss: 2.979918599225144

Epoch: 6| Step: 6
Training loss: 3.3979526919371708
Validation loss: 2.971857237759272

Epoch: 6| Step: 7
Training loss: 3.3345486968399007
Validation loss: 2.9656827754017403

Epoch: 6| Step: 8
Training loss: 2.1801692744688737
Validation loss: 2.9595247169321253

Epoch: 6| Step: 9
Training loss: 2.8209702842145266
Validation loss: 2.958560737860176

Epoch: 6| Step: 10
Training loss: 3.244953051493424
Validation loss: 2.9561306975817225

Epoch: 6| Step: 11
Training loss: 3.5792959371247273
Validation loss: 2.9504313882980777

Epoch: 6| Step: 12
Training loss: 2.6650038144082546
Validation loss: 2.9686949780411154

Epoch: 6| Step: 13
Training loss: 3.654500428590529
Validation loss: 3.0016481596087785

Epoch: 64| Step: 0
Training loss: 2.8392956400215374
Validation loss: 2.969472202954414

Epoch: 6| Step: 1
Training loss: 2.8359758358720883
Validation loss: 2.9348638047112323

Epoch: 6| Step: 2
Training loss: 3.3263590967750676
Validation loss: 2.9335976082254147

Epoch: 6| Step: 3
Training loss: 2.4255994154247493
Validation loss: 2.93988353644368

Epoch: 6| Step: 4
Training loss: 2.229434119131272
Validation loss: 2.948770375467689

Epoch: 6| Step: 5
Training loss: 3.1138890916285664
Validation loss: 2.9614094506256032

Epoch: 6| Step: 6
Training loss: 3.095132692170259
Validation loss: 2.9721584026344496

Epoch: 6| Step: 7
Training loss: 3.0286004196177787
Validation loss: 2.9617415130483415

Epoch: 6| Step: 8
Training loss: 2.840969193256282
Validation loss: 2.948960960273623

Epoch: 6| Step: 9
Training loss: 3.1198998603889487
Validation loss: 2.933610762857071

Epoch: 6| Step: 10
Training loss: 4.033387083425802
Validation loss: 2.93046396992978

Epoch: 6| Step: 11
Training loss: 4.28562937152846
Validation loss: 2.929488361987652

Epoch: 6| Step: 12
Training loss: 3.4762409875911358
Validation loss: 2.9286642145638697

Epoch: 6| Step: 13
Training loss: 4.348840379162314
Validation loss: 2.9273691158650044

Epoch: 65| Step: 0
Training loss: 3.450019924824993
Validation loss: 2.9286338778698986

Epoch: 6| Step: 1
Training loss: 3.267204961086994
Validation loss: 2.936962639700145

Epoch: 6| Step: 2
Training loss: 2.5125990966688367
Validation loss: 2.9343987691366245

Epoch: 6| Step: 3
Training loss: 3.4532909784947634
Validation loss: 2.9316551167310956

Epoch: 6| Step: 4
Training loss: 2.566741874963599
Validation loss: 2.9257738993450912

Epoch: 6| Step: 5
Training loss: 3.100184059831607
Validation loss: 2.9273898762976662

Epoch: 6| Step: 6
Training loss: 3.5065571805109452
Validation loss: 2.925321663172309

Epoch: 6| Step: 7
Training loss: 2.983892911150198
Validation loss: 2.925643584913521

Epoch: 6| Step: 8
Training loss: 3.027071717868546
Validation loss: 2.927415672939951

Epoch: 6| Step: 9
Training loss: 3.4258413798884866
Validation loss: 2.9291687558776895

Epoch: 6| Step: 10
Training loss: 3.147112015981906
Validation loss: 2.930756565627526

Epoch: 6| Step: 11
Training loss: 3.6814771701944706
Validation loss: 2.935609157891294

Epoch: 6| Step: 12
Training loss: 3.4070951480729827
Validation loss: 2.93373134699927

Epoch: 6| Step: 13
Training loss: 3.4036523555740796
Validation loss: 2.9269941924576743

Epoch: 66| Step: 0
Training loss: 3.0640286114504725
Validation loss: 2.9262760505778798

Epoch: 6| Step: 1
Training loss: 2.414931551356186
Validation loss: 2.9254007914528577

Epoch: 6| Step: 2
Training loss: 3.881986288361898
Validation loss: 2.9217123298138854

Epoch: 6| Step: 3
Training loss: 3.8072240626033835
Validation loss: 2.920595306583799

Epoch: 6| Step: 4
Training loss: 2.792135986809283
Validation loss: 2.920668480932951

Epoch: 6| Step: 5
Training loss: 3.75691678798334
Validation loss: 2.920884572612842

Epoch: 6| Step: 6
Training loss: 3.085596611413141
Validation loss: 2.919083546411211

Epoch: 6| Step: 7
Training loss: 3.157426973466439
Validation loss: 2.917858673609927

Epoch: 6| Step: 8
Training loss: 3.7268178920282375
Validation loss: 2.917497047902037

Epoch: 6| Step: 9
Training loss: 3.4723770836098447
Validation loss: 2.9169167096474458

Epoch: 6| Step: 10
Training loss: 3.009033747860625
Validation loss: 2.918970077153194

Epoch: 6| Step: 11
Training loss: 2.6382312646795425
Validation loss: 2.9169235245305036

Epoch: 6| Step: 12
Training loss: 2.58217086068288
Validation loss: 2.915927428219296

Epoch: 6| Step: 13
Training loss: 3.0678670137272923
Validation loss: 2.9164491121104517

Epoch: 67| Step: 0
Training loss: 3.541656419327815
Validation loss: 2.917025374989287

Epoch: 6| Step: 1
Training loss: 2.2642006441650335
Validation loss: 2.9142454915141776

Epoch: 6| Step: 2
Training loss: 3.2157522519274346
Validation loss: 2.915543390600367

Epoch: 6| Step: 3
Training loss: 3.3627194811580643
Validation loss: 2.916220937384452

Epoch: 6| Step: 4
Training loss: 3.0718903115279965
Validation loss: 2.919875570707862

Epoch: 6| Step: 5
Training loss: 3.2469133244474837
Validation loss: 2.9192291119495715

Epoch: 6| Step: 6
Training loss: 3.69309030699562
Validation loss: 2.926772641990099

Epoch: 6| Step: 7
Training loss: 3.107099304144531
Validation loss: 2.921970604738517

Epoch: 6| Step: 8
Training loss: 2.954881902358327
Validation loss: 2.920989747332957

Epoch: 6| Step: 9
Training loss: 3.1992627188580345
Validation loss: 2.9152569160412702

Epoch: 6| Step: 10
Training loss: 2.425550760078126
Validation loss: 2.922650048253285

Epoch: 6| Step: 11
Training loss: 3.335214147826978
Validation loss: 2.9128596952027466

Epoch: 6| Step: 12
Training loss: 3.342072395814421
Validation loss: 2.9103649398504734

Epoch: 6| Step: 13
Training loss: 4.141771380957565
Validation loss: 2.9057002522899236

Epoch: 68| Step: 0
Training loss: 3.36935914146443
Validation loss: 2.9041434936992485

Epoch: 6| Step: 1
Training loss: 3.7842550395723604
Validation loss: 2.9027806980532933

Epoch: 6| Step: 2
Training loss: 3.517789860801913
Validation loss: 2.908097922442242

Epoch: 6| Step: 3
Training loss: 3.714966203374119
Validation loss: 2.9149349500832322

Epoch: 6| Step: 4
Training loss: 3.4618617216600405
Validation loss: 2.9285501413263764

Epoch: 6| Step: 5
Training loss: 3.1567985133585688
Validation loss: 2.9117408633114317

Epoch: 6| Step: 6
Training loss: 2.9672770811582776
Validation loss: 2.910349597772225

Epoch: 6| Step: 7
Training loss: 2.638536970754592
Validation loss: 2.9154203619041588

Epoch: 6| Step: 8
Training loss: 3.198619073690498
Validation loss: 2.91758855556925

Epoch: 6| Step: 9
Training loss: 2.8310841627583403
Validation loss: 2.9111648691386387

Epoch: 6| Step: 10
Training loss: 3.4709526148369356
Validation loss: 2.90439235928257

Epoch: 6| Step: 11
Training loss: 2.8361905408051205
Validation loss: 2.9028537986464507

Epoch: 6| Step: 12
Training loss: 2.9680666488402863
Validation loss: 2.904263851010761

Epoch: 6| Step: 13
Training loss: 2.2631683711226183
Validation loss: 2.9110748997137152

Epoch: 69| Step: 0
Training loss: 2.3846700463289254
Validation loss: 2.916396664429036

Epoch: 6| Step: 1
Training loss: 3.9388829784650867
Validation loss: 2.9285966918814355

Epoch: 6| Step: 2
Training loss: 2.302461641967556
Validation loss: 2.919376031357572

Epoch: 6| Step: 3
Training loss: 3.80921819800721
Validation loss: 2.925847626742884

Epoch: 6| Step: 4
Training loss: 2.928386755513719
Validation loss: 2.9132207534345635

Epoch: 6| Step: 5
Training loss: 3.264956903333862
Validation loss: 2.907122989532043

Epoch: 6| Step: 6
Training loss: 2.423971732878086
Validation loss: 2.8999242206569322

Epoch: 6| Step: 7
Training loss: 2.961931771295561
Validation loss: 2.9024332163254747

Epoch: 6| Step: 8
Training loss: 2.7439969171111915
Validation loss: 2.9002382145243617

Epoch: 6| Step: 9
Training loss: 3.4944334723039727
Validation loss: 2.91152202289916

Epoch: 6| Step: 10
Training loss: 3.3846608105525484
Validation loss: 2.906914116326227

Epoch: 6| Step: 11
Training loss: 3.7709818998684868
Validation loss: 2.904593592098796

Epoch: 6| Step: 12
Training loss: 3.4863199185827787
Validation loss: 2.897307520814123

Epoch: 6| Step: 13
Training loss: 3.4389268168088702
Validation loss: 2.894988239379279

Epoch: 70| Step: 0
Training loss: 3.0528348099581297
Validation loss: 2.898480754804062

Epoch: 6| Step: 1
Training loss: 3.3685368005102156
Validation loss: 2.9005406764291624

Epoch: 6| Step: 2
Training loss: 2.621226641360338
Validation loss: 2.899782140035787

Epoch: 6| Step: 3
Training loss: 3.4401883796743578
Validation loss: 2.9045005099291252

Epoch: 6| Step: 4
Training loss: 3.1013042044524894
Validation loss: 2.897358992124534

Epoch: 6| Step: 5
Training loss: 3.464353369724963
Validation loss: 2.9001428586619022

Epoch: 6| Step: 6
Training loss: 3.877917391301961
Validation loss: 2.8981908342723135

Epoch: 6| Step: 7
Training loss: 3.656207744647654
Validation loss: 2.895749000058476

Epoch: 6| Step: 8
Training loss: 2.5578287859324225
Validation loss: 2.896802997642317

Epoch: 6| Step: 9
Training loss: 2.7037142072857767
Validation loss: 2.897037821894864

Epoch: 6| Step: 10
Training loss: 2.92564467148258
Validation loss: 2.8951945054313564

Epoch: 6| Step: 11
Training loss: 3.72847649067663
Validation loss: 2.8972964833546992

Epoch: 6| Step: 12
Training loss: 2.373449019905747
Validation loss: 2.898410355741803

Epoch: 6| Step: 13
Training loss: 3.5454390387651706
Validation loss: 2.8938345188280756

Epoch: 71| Step: 0
Training loss: 2.7501239748666295
Validation loss: 2.892285944642349

Epoch: 6| Step: 1
Training loss: 3.332347787756322
Validation loss: 2.890488347019245

Epoch: 6| Step: 2
Training loss: 3.270234427725369
Validation loss: 2.8921127840728396

Epoch: 6| Step: 3
Training loss: 3.19277248764094
Validation loss: 2.890007777502529

Epoch: 6| Step: 4
Training loss: 3.4495889501752086
Validation loss: 2.8897697125715633

Epoch: 6| Step: 5
Training loss: 3.0307371354554187
Validation loss: 2.890309252202131

Epoch: 6| Step: 6
Training loss: 2.4051125550450445
Validation loss: 2.890156240017067

Epoch: 6| Step: 7
Training loss: 2.846690575397274
Validation loss: 2.887687127148846

Epoch: 6| Step: 8
Training loss: 3.746344501269522
Validation loss: 2.888016845276652

Epoch: 6| Step: 9
Training loss: 3.8156760072540203
Validation loss: 2.888376820511236

Epoch: 6| Step: 10
Training loss: 3.4584624178285104
Validation loss: 2.888129620412723

Epoch: 6| Step: 11
Training loss: 2.4976941919293694
Validation loss: 2.8896525256262713

Epoch: 6| Step: 12
Training loss: 3.328915497651289
Validation loss: 2.8907734671758725

Epoch: 6| Step: 13
Training loss: 3.1397726695872445
Validation loss: 2.888506026714312

Epoch: 72| Step: 0
Training loss: 2.1530819161897874
Validation loss: 2.8861938986977287

Epoch: 6| Step: 1
Training loss: 2.803068325868948
Validation loss: 2.884873605008427

Epoch: 6| Step: 2
Training loss: 3.28394054729809
Validation loss: 2.8878500485586174

Epoch: 6| Step: 3
Training loss: 2.9922627173150413
Validation loss: 2.8872216132600754

Epoch: 6| Step: 4
Training loss: 3.488172027484131
Validation loss: 2.890728898025628

Epoch: 6| Step: 5
Training loss: 3.74118506398486
Validation loss: 2.887312023186439

Epoch: 6| Step: 6
Training loss: 3.738694123335549
Validation loss: 2.886910908389371

Epoch: 6| Step: 7
Training loss: 3.365163243317448
Validation loss: 2.885883754763187

Epoch: 6| Step: 8
Training loss: 3.350175619503932
Validation loss: 2.884756377355415

Epoch: 6| Step: 9
Training loss: 3.527480011902973
Validation loss: 2.8868860365597575

Epoch: 6| Step: 10
Training loss: 3.2740480859542402
Validation loss: 2.884955247610231

Epoch: 6| Step: 11
Training loss: 3.0928346455006577
Validation loss: 2.882844581651148

Epoch: 6| Step: 12
Training loss: 2.4117172354893306
Validation loss: 2.882049492476011

Epoch: 6| Step: 13
Training loss: 2.6650249275344278
Validation loss: 2.8806178778972824

Epoch: 73| Step: 0
Training loss: 3.39812936372461
Validation loss: 2.880634710590602

Epoch: 6| Step: 1
Training loss: 3.1020006307555787
Validation loss: 2.8819419039145786

Epoch: 6| Step: 2
Training loss: 3.209221820091556
Validation loss: 2.8815723375818245

Epoch: 6| Step: 3
Training loss: 3.3232067463857304
Validation loss: 2.879798497883942

Epoch: 6| Step: 4
Training loss: 3.6328308761295984
Validation loss: 2.878867597080181

Epoch: 6| Step: 5
Training loss: 3.3010753613420833
Validation loss: 2.880202904974474

Epoch: 6| Step: 6
Training loss: 3.0787126783741035
Validation loss: 2.8791493910219303

Epoch: 6| Step: 7
Training loss: 2.9835889490113408
Validation loss: 2.880758173440577

Epoch: 6| Step: 8
Training loss: 2.1428752126385984
Validation loss: 2.8781414172828965

Epoch: 6| Step: 9
Training loss: 3.2822596858452115
Validation loss: 2.8778767845781243

Epoch: 6| Step: 10
Training loss: 3.2011422324073715
Validation loss: 2.88008845667145

Epoch: 6| Step: 11
Training loss: 3.4453749186079805
Validation loss: 2.878227651359741

Epoch: 6| Step: 12
Training loss: 2.602812412356768
Validation loss: 2.881672208121129

Epoch: 6| Step: 13
Training loss: 3.704368929638369
Validation loss: 2.883689659995783

Epoch: 74| Step: 0
Training loss: 2.8068361685425414
Validation loss: 2.8868079652581753

Epoch: 6| Step: 1
Training loss: 3.6883608572913027
Validation loss: 2.8919455906494904

Epoch: 6| Step: 2
Training loss: 2.1871187150268283
Validation loss: 2.8910536949528582

Epoch: 6| Step: 3
Training loss: 3.427391865455371
Validation loss: 2.8820583218379063

Epoch: 6| Step: 4
Training loss: 3.662362361053268
Validation loss: 2.8759829769950556

Epoch: 6| Step: 5
Training loss: 3.1590107844628417
Validation loss: 2.874651915891349

Epoch: 6| Step: 6
Training loss: 2.646653736508908
Validation loss: 2.8755635194798708

Epoch: 6| Step: 7
Training loss: 2.627435371918015
Validation loss: 2.87401723806495

Epoch: 6| Step: 8
Training loss: 3.5655226349241214
Validation loss: 2.874312091581162

Epoch: 6| Step: 9
Training loss: 3.0626074324467902
Validation loss: 2.8740110653767648

Epoch: 6| Step: 10
Training loss: 3.5053735082894075
Validation loss: 2.8749574084736236

Epoch: 6| Step: 11
Training loss: 3.4571278014412554
Validation loss: 2.8751499213622265

Epoch: 6| Step: 12
Training loss: 2.9508383642622573
Validation loss: 2.8764317101154235

Epoch: 6| Step: 13
Training loss: 3.406136327124192
Validation loss: 2.8780770779570988

Epoch: 75| Step: 0
Training loss: 3.0512721488551944
Validation loss: 2.879160479350816

Epoch: 6| Step: 1
Training loss: 3.4214179025467186
Validation loss: 2.880613421853776

Epoch: 6| Step: 2
Training loss: 3.535597429092151
Validation loss: 2.882055066202878

Epoch: 6| Step: 3
Training loss: 2.495737542897114
Validation loss: 2.8808631926146795

Epoch: 6| Step: 4
Training loss: 3.0873283245837095
Validation loss: 2.8777545450711597

Epoch: 6| Step: 5
Training loss: 2.5479809752671794
Validation loss: 2.878510463578056

Epoch: 6| Step: 6
Training loss: 4.257997505298348
Validation loss: 2.8781074950499876

Epoch: 6| Step: 7
Training loss: 2.950940812947382
Validation loss: 2.87456670227225

Epoch: 6| Step: 8
Training loss: 3.1024777385641515
Validation loss: 2.871615092285445

Epoch: 6| Step: 9
Training loss: 2.886156577163275
Validation loss: 2.8691737003179503

Epoch: 6| Step: 10
Training loss: 3.077491346481887
Validation loss: 2.8699095773460566

Epoch: 6| Step: 11
Training loss: 3.229856569158517
Validation loss: 2.870146559040661

Epoch: 6| Step: 12
Training loss: 3.4414234312496763
Validation loss: 2.869709708203659

Epoch: 6| Step: 13
Training loss: 2.719128637146305
Validation loss: 2.8703778702976837

Epoch: 76| Step: 0
Training loss: 3.4529962990368395
Validation loss: 2.8673820088741073

Epoch: 6| Step: 1
Training loss: 2.7178181772390975
Validation loss: 2.867823524831996

Epoch: 6| Step: 2
Training loss: 2.7624243195122493
Validation loss: 2.8688959342535765

Epoch: 6| Step: 3
Training loss: 3.999286111069494
Validation loss: 2.869753422811801

Epoch: 6| Step: 4
Training loss: 3.498149382571191
Validation loss: 2.8730875942617526

Epoch: 6| Step: 5
Training loss: 2.922919591538336
Validation loss: 2.8689965900852705

Epoch: 6| Step: 6
Training loss: 3.107258291871988
Validation loss: 2.8721963543958555

Epoch: 6| Step: 7
Training loss: 3.077383348995111
Validation loss: 2.870917481522519

Epoch: 6| Step: 8
Training loss: 3.5086339995395086
Validation loss: 2.866901198884631

Epoch: 6| Step: 9
Training loss: 2.3318995657439445
Validation loss: 2.8667958779439178

Epoch: 6| Step: 10
Training loss: 3.21752639771535
Validation loss: 2.8654830823222097

Epoch: 6| Step: 11
Training loss: 2.7047435346999125
Validation loss: 2.865306207429007

Epoch: 6| Step: 12
Training loss: 2.747396537214192
Validation loss: 2.8648378577195075

Epoch: 6| Step: 13
Training loss: 4.267350179839129
Validation loss: 2.8662502083133137

Epoch: 77| Step: 0
Training loss: 2.8202779244710166
Validation loss: 2.8644394320293527

Epoch: 6| Step: 1
Training loss: 3.3219139635128188
Validation loss: 2.8637780441223253

Epoch: 6| Step: 2
Training loss: 3.5480765437542856
Validation loss: 2.863525016736054

Epoch: 6| Step: 3
Training loss: 2.6620117527840574
Validation loss: 2.8631016764304715

Epoch: 6| Step: 4
Training loss: 3.3847308280903947
Validation loss: 2.863668720786026

Epoch: 6| Step: 5
Training loss: 3.0337973047693514
Validation loss: 2.866369917201195

Epoch: 6| Step: 6
Training loss: 2.754001480512145
Validation loss: 2.8644970651354082

Epoch: 6| Step: 7
Training loss: 3.126584223681793
Validation loss: 2.862939033258374

Epoch: 6| Step: 8
Training loss: 2.611093834443348
Validation loss: 2.866568169746293

Epoch: 6| Step: 9
Training loss: 3.827005526285241
Validation loss: 2.8649754997287777

Epoch: 6| Step: 10
Training loss: 2.817650550536557
Validation loss: 2.8646427080521106

Epoch: 6| Step: 11
Training loss: 2.923049935320545
Validation loss: 2.8622075591139233

Epoch: 6| Step: 12
Training loss: 3.517534474933918
Validation loss: 2.867674039332267

Epoch: 6| Step: 13
Training loss: 3.9338223675961532
Validation loss: 2.869536711209077

Epoch: 78| Step: 0
Training loss: 3.4742014893741455
Validation loss: 2.8735038391855157

Epoch: 6| Step: 1
Training loss: 2.8866302104994275
Validation loss: 2.867169209602142

Epoch: 6| Step: 2
Training loss: 3.664503644402454
Validation loss: 2.8740352752617815

Epoch: 6| Step: 3
Training loss: 2.8754729835542516
Validation loss: 2.8739893127892824

Epoch: 6| Step: 4
Training loss: 3.640454202337451
Validation loss: 2.8748208837725495

Epoch: 6| Step: 5
Training loss: 3.348338463796581
Validation loss: 2.8808099146303197

Epoch: 6| Step: 6
Training loss: 2.398957435341613
Validation loss: 2.8608570791201453

Epoch: 6| Step: 7
Training loss: 3.4334316801287623
Validation loss: 2.857180790788535

Epoch: 6| Step: 8
Training loss: 3.2715461747894214
Validation loss: 2.857638655770983

Epoch: 6| Step: 9
Training loss: 2.500995819124909
Validation loss: 2.8602509869512582

Epoch: 6| Step: 10
Training loss: 2.7723421754624553
Validation loss: 2.8626398188083244

Epoch: 6| Step: 11
Training loss: 2.456038767344029
Validation loss: 2.8571757122793486

Epoch: 6| Step: 12
Training loss: 3.3392906043218678
Validation loss: 2.86206246497353

Epoch: 6| Step: 13
Training loss: 4.207519502917561
Validation loss: 2.857608636232523

Epoch: 79| Step: 0
Training loss: 3.64041150166973
Validation loss: 2.857630892993662

Epoch: 6| Step: 1
Training loss: 3.1435480132540206
Validation loss: 2.856107115194692

Epoch: 6| Step: 2
Training loss: 2.9291908758762877
Validation loss: 2.856275243219698

Epoch: 6| Step: 3
Training loss: 2.899034299870592
Validation loss: 2.8551814448443604

Epoch: 6| Step: 4
Training loss: 3.67118328965142
Validation loss: 2.8535033984469553

Epoch: 6| Step: 5
Training loss: 3.3498038277194833
Validation loss: 2.854879039022782

Epoch: 6| Step: 6
Training loss: 2.1665111143565294
Validation loss: 2.859782662759377

Epoch: 6| Step: 7
Training loss: 3.202382964736109
Validation loss: 2.8586077244296604

Epoch: 6| Step: 8
Training loss: 3.6488263006749935
Validation loss: 2.8603291879863306

Epoch: 6| Step: 9
Training loss: 3.3327139437911764
Validation loss: 2.864240795847263

Epoch: 6| Step: 10
Training loss: 3.4396802057171736
Validation loss: 2.8585910135892747

Epoch: 6| Step: 11
Training loss: 2.7119797343900696
Validation loss: 2.854547834591911

Epoch: 6| Step: 12
Training loss: 3.0696615446325985
Validation loss: 2.8532486054285493

Epoch: 6| Step: 13
Training loss: 2.122786996441985
Validation loss: 2.855454864587151

Epoch: 80| Step: 0
Training loss: 2.583717707269301
Validation loss: 2.853054009096312

Epoch: 6| Step: 1
Training loss: 3.3141825019804063
Validation loss: 2.852544796342888

Epoch: 6| Step: 2
Training loss: 3.1090787046721258
Validation loss: 2.8538599693068614

Epoch: 6| Step: 3
Training loss: 3.6454407108159392
Validation loss: 2.8546337831975657

Epoch: 6| Step: 4
Training loss: 3.153746868166765
Validation loss: 2.8563726235897664

Epoch: 6| Step: 5
Training loss: 3.2198441506810997
Validation loss: 2.8563445150398503

Epoch: 6| Step: 6
Training loss: 2.9905993676756326
Validation loss: 2.8545770897211327

Epoch: 6| Step: 7
Training loss: 2.9111337952866507
Validation loss: 2.853172618367643

Epoch: 6| Step: 8
Training loss: 3.37025089269507
Validation loss: 2.8541022780661334

Epoch: 6| Step: 9
Training loss: 3.193053848629713
Validation loss: 2.855546776756043

Epoch: 6| Step: 10
Training loss: 2.7077632206187356
Validation loss: 2.8542246772602

Epoch: 6| Step: 11
Training loss: 2.582629897625742
Validation loss: 2.855886047602195

Epoch: 6| Step: 12
Training loss: 3.697836661033
Validation loss: 2.8501003506776375

Epoch: 6| Step: 13
Training loss: 3.5820769095968736
Validation loss: 2.853358371126606

Epoch: 81| Step: 0
Training loss: 2.7134531974404323
Validation loss: 2.8536964054844276

Epoch: 6| Step: 1
Training loss: 3.3525181543824436
Validation loss: 2.8493070292103737

Epoch: 6| Step: 2
Training loss: 3.385688950764037
Validation loss: 2.8519967479400488

Epoch: 6| Step: 3
Training loss: 3.2787378776462903
Validation loss: 2.8479310889469676

Epoch: 6| Step: 4
Training loss: 2.9787900104148766
Validation loss: 2.8527300453926308

Epoch: 6| Step: 5
Training loss: 3.391803870522845
Validation loss: 2.8508972075141195

Epoch: 6| Step: 6
Training loss: 2.668093408936849
Validation loss: 2.8563997239621526

Epoch: 6| Step: 7
Training loss: 2.761627066249089
Validation loss: 2.8515954960133207

Epoch: 6| Step: 8
Training loss: 3.364010473718112
Validation loss: 2.8505526941714048

Epoch: 6| Step: 9
Training loss: 2.5653997622088855
Validation loss: 2.8464281294541345

Epoch: 6| Step: 10
Training loss: 3.5852656514210723
Validation loss: 2.845168682857342

Epoch: 6| Step: 11
Training loss: 3.3201549537530854
Validation loss: 2.846662542354513

Epoch: 6| Step: 12
Training loss: 3.3005259759369374
Validation loss: 2.8466468452429616

Epoch: 6| Step: 13
Training loss: 3.160015918836455
Validation loss: 2.8455474511617234

Epoch: 82| Step: 0
Training loss: 3.0637171914979326
Validation loss: 2.8430287355743764

Epoch: 6| Step: 1
Training loss: 2.746881103508844
Validation loss: 2.8438844699702677

Epoch: 6| Step: 2
Training loss: 2.550729093850871
Validation loss: 2.8458332543236544

Epoch: 6| Step: 3
Training loss: 3.512185546266223
Validation loss: 2.8486812134552677

Epoch: 6| Step: 4
Training loss: 2.515123968993723
Validation loss: 2.8518621274081166

Epoch: 6| Step: 5
Training loss: 4.0800094050878695
Validation loss: 2.8575883861882296

Epoch: 6| Step: 6
Training loss: 3.283035954855137
Validation loss: 2.859061176578155

Epoch: 6| Step: 7
Training loss: 2.8847887661986515
Validation loss: 2.85569964232717

Epoch: 6| Step: 8
Training loss: 3.3391158175105313
Validation loss: 2.8447838271745978

Epoch: 6| Step: 9
Training loss: 3.094075966048539
Validation loss: 2.8462357248118733

Epoch: 6| Step: 10
Training loss: 3.1868641537027074
Validation loss: 2.843312360192849

Epoch: 6| Step: 11
Training loss: 2.651345515996837
Validation loss: 2.842689878193209

Epoch: 6| Step: 12
Training loss: 3.555670633705477
Validation loss: 2.8406472446740256

Epoch: 6| Step: 13
Training loss: 3.2074818823073015
Validation loss: 2.83939177077679

Epoch: 83| Step: 0
Training loss: 3.1148330095085393
Validation loss: 2.8431863732207208

Epoch: 6| Step: 1
Training loss: 2.6707472177826834
Validation loss: 2.8406465335160043

Epoch: 6| Step: 2
Training loss: 2.9823946948458593
Validation loss: 2.838925244027583

Epoch: 6| Step: 3
Training loss: 3.576299343202062
Validation loss: 2.8380642123133457

Epoch: 6| Step: 4
Training loss: 2.9054485569596085
Validation loss: 2.837315669416533

Epoch: 6| Step: 5
Training loss: 3.6515945400518555
Validation loss: 2.8373777603071346

Epoch: 6| Step: 6
Training loss: 3.056971327956998
Validation loss: 2.837185738566367

Epoch: 6| Step: 7
Training loss: 3.595257782799486
Validation loss: 2.8379104121574823

Epoch: 6| Step: 8
Training loss: 3.1552241707311253
Validation loss: 2.8379227899010617

Epoch: 6| Step: 9
Training loss: 2.641794701811819
Validation loss: 2.836917332888143

Epoch: 6| Step: 10
Training loss: 3.0744219352922353
Validation loss: 2.835987785442933

Epoch: 6| Step: 11
Training loss: 3.2946337272585478
Validation loss: 2.8364747551915532

Epoch: 6| Step: 12
Training loss: 3.217480455411817
Validation loss: 2.8335753620389466

Epoch: 6| Step: 13
Training loss: 2.6897165783045702
Validation loss: 2.8357487528171887

Epoch: 84| Step: 0
Training loss: 1.979240021266455
Validation loss: 2.8356480930032495

Epoch: 6| Step: 1
Training loss: 4.220515807027402
Validation loss: 2.839255669529958

Epoch: 6| Step: 2
Training loss: 2.501565633720613
Validation loss: 2.839474821322187

Epoch: 6| Step: 3
Training loss: 3.254371490740363
Validation loss: 2.842215723518848

Epoch: 6| Step: 4
Training loss: 3.2766145933973605
Validation loss: 2.8453437101355963

Epoch: 6| Step: 5
Training loss: 2.7167105205093334
Validation loss: 2.8381580687788044

Epoch: 6| Step: 6
Training loss: 2.665096764588093
Validation loss: 2.8415493803425282

Epoch: 6| Step: 7
Training loss: 3.5839142587231905
Validation loss: 2.8394561077367904

Epoch: 6| Step: 8
Training loss: 2.7672186101783383
Validation loss: 2.8364282292666947

Epoch: 6| Step: 9
Training loss: 3.5755622048240756
Validation loss: 2.835241994691277

Epoch: 6| Step: 10
Training loss: 3.810177079738852
Validation loss: 2.8417455042376805

Epoch: 6| Step: 11
Training loss: 2.9993132758938543
Validation loss: 2.8397728163161564

Epoch: 6| Step: 12
Training loss: 3.0484493003159296
Validation loss: 2.840101122158569

Epoch: 6| Step: 13
Training loss: 2.542861022073717
Validation loss: 2.841496844857758

Epoch: 85| Step: 0
Training loss: 3.589804697913946
Validation loss: 2.8377650459637085

Epoch: 6| Step: 1
Training loss: 3.7703933599648707
Validation loss: 2.835393446830338

Epoch: 6| Step: 2
Training loss: 2.906164024475942
Validation loss: 2.8366698435876496

Epoch: 6| Step: 3
Training loss: 2.558795577380837
Validation loss: 2.8337176591293587

Epoch: 6| Step: 4
Training loss: 2.8120696692267355
Validation loss: 2.8327957966858004

Epoch: 6| Step: 5
Training loss: 3.4130686136005264
Validation loss: 2.8283538136584396

Epoch: 6| Step: 6
Training loss: 3.4974422645847927
Validation loss: 2.828422246584162

Epoch: 6| Step: 7
Training loss: 3.2252061408348625
Validation loss: 2.8273705805550406

Epoch: 6| Step: 8
Training loss: 2.4948996969789867
Validation loss: 2.82985431197148

Epoch: 6| Step: 9
Training loss: 3.266872915906225
Validation loss: 2.827357093931809

Epoch: 6| Step: 10
Training loss: 2.6624954402687537
Validation loss: 2.825273524727573

Epoch: 6| Step: 11
Training loss: 3.199370179184808
Validation loss: 2.825567012927607

Epoch: 6| Step: 12
Training loss: 3.3834656399819516
Validation loss: 2.8276147676182437

Epoch: 6| Step: 13
Training loss: 2.529747411007861
Validation loss: 2.8250527240763663

Epoch: 86| Step: 0
Training loss: 2.8206303383058002
Validation loss: 2.8273715416807703

Epoch: 6| Step: 1
Training loss: 2.9182303642031293
Validation loss: 2.825554849620145

Epoch: 6| Step: 2
Training loss: 3.0146838681307973
Validation loss: 2.8292010470972406

Epoch: 6| Step: 3
Training loss: 2.8931632779799616
Validation loss: 2.8293607100804663

Epoch: 6| Step: 4
Training loss: 3.608648846394178
Validation loss: 2.836363103258998

Epoch: 6| Step: 5
Training loss: 3.686895288572281
Validation loss: 2.8364063683169403

Epoch: 6| Step: 6
Training loss: 3.5279602661057834
Validation loss: 2.8356054772650747

Epoch: 6| Step: 7
Training loss: 2.892634502636779
Validation loss: 2.8349795026129154

Epoch: 6| Step: 8
Training loss: 2.836610992578604
Validation loss: 2.8310861313867823

Epoch: 6| Step: 9
Training loss: 3.63917846756974
Validation loss: 2.830050083211336

Epoch: 6| Step: 10
Training loss: 3.4955148569259773
Validation loss: 2.8249162777520533

Epoch: 6| Step: 11
Training loss: 2.2922780232929374
Validation loss: 2.8261451805255464

Epoch: 6| Step: 12
Training loss: 3.010323246933025
Validation loss: 2.827697939217471

Epoch: 6| Step: 13
Training loss: 2.623760839170009
Validation loss: 2.8258834210781427

Epoch: 87| Step: 0
Training loss: 3.08537948005585
Validation loss: 2.8264671211319907

Epoch: 6| Step: 1
Training loss: 2.3129785403432472
Validation loss: 2.8232824573445696

Epoch: 6| Step: 2
Training loss: 3.739659867349157
Validation loss: 2.8254810792997533

Epoch: 6| Step: 3
Training loss: 3.878921247532059
Validation loss: 2.8271920149531287

Epoch: 6| Step: 4
Training loss: 2.98124970570049
Validation loss: 2.826767278669859

Epoch: 6| Step: 5
Training loss: 2.546803385657985
Validation loss: 2.829299792439803

Epoch: 6| Step: 6
Training loss: 3.109186214677645
Validation loss: 2.827085499869927

Epoch: 6| Step: 7
Training loss: 3.1713684880273734
Validation loss: 2.831747637993494

Epoch: 6| Step: 8
Training loss: 2.6934332004136157
Validation loss: 2.832463307928949

Epoch: 6| Step: 9
Training loss: 3.381780524244611
Validation loss: 2.8291308605644234

Epoch: 6| Step: 10
Training loss: 3.4687295174208748
Validation loss: 2.829300228275925

Epoch: 6| Step: 11
Training loss: 2.937116070270581
Validation loss: 2.82726659388842

Epoch: 6| Step: 12
Training loss: 3.0982168298917387
Validation loss: 2.826773654736009

Epoch: 6| Step: 13
Training loss: 2.901482886977004
Validation loss: 2.8233954283183436

Epoch: 88| Step: 0
Training loss: 3.2372526921258062
Validation loss: 2.8264934316242933

Epoch: 6| Step: 1
Training loss: 3.6912067985138046
Validation loss: 2.82307095887949

Epoch: 6| Step: 2
Training loss: 3.3669260724536505
Validation loss: 2.819049902433402

Epoch: 6| Step: 3
Training loss: 3.5454042048759615
Validation loss: 2.8216083898925466

Epoch: 6| Step: 4
Training loss: 2.84450009692241
Validation loss: 2.819405400390277

Epoch: 6| Step: 5
Training loss: 3.11771673236858
Validation loss: 2.82249407622311

Epoch: 6| Step: 6
Training loss: 2.748411239836884
Validation loss: 2.821293253315463

Epoch: 6| Step: 7
Training loss: 3.0960265751765146
Validation loss: 2.820367915225185

Epoch: 6| Step: 8
Training loss: 2.1467761465354838
Validation loss: 2.8199693165761257

Epoch: 6| Step: 9
Training loss: 3.0381035162019563
Validation loss: 2.821484800195047

Epoch: 6| Step: 10
Training loss: 2.954868992517173
Validation loss: 2.8261665266913485

Epoch: 6| Step: 11
Training loss: 2.9471408825179517
Validation loss: 2.829210360346686

Epoch: 6| Step: 12
Training loss: 3.041456520102149
Validation loss: 2.8343086162633835

Epoch: 6| Step: 13
Training loss: 3.9770626210785243
Validation loss: 2.8338880273442513

Epoch: 89| Step: 0
Training loss: 3.2930137839354643
Validation loss: 2.832380154976757

Epoch: 6| Step: 1
Training loss: 3.922270371162849
Validation loss: 2.8272773969574496

Epoch: 6| Step: 2
Training loss: 2.9565755072141147
Validation loss: 2.828666475182235

Epoch: 6| Step: 3
Training loss: 3.3009088074003117
Validation loss: 2.821346289491826

Epoch: 6| Step: 4
Training loss: 3.007705964022352
Validation loss: 2.8163847242682536

Epoch: 6| Step: 5
Training loss: 2.5022957751069645
Validation loss: 2.821155507437441

Epoch: 6| Step: 6
Training loss: 2.8992905505332045
Validation loss: 2.8164692870061487

Epoch: 6| Step: 7
Training loss: 3.4538496128866845
Validation loss: 2.815587132170262

Epoch: 6| Step: 8
Training loss: 3.299093937031634
Validation loss: 2.816527124377723

Epoch: 6| Step: 9
Training loss: 3.0507937539756558
Validation loss: 2.815037338226904

Epoch: 6| Step: 10
Training loss: 3.3311335616669684
Validation loss: 2.815899612543121

Epoch: 6| Step: 11
Training loss: 3.0394908142302453
Validation loss: 2.817852175281988

Epoch: 6| Step: 12
Training loss: 2.5839157268375526
Validation loss: 2.816307076251556

Epoch: 6| Step: 13
Training loss: 2.4632572926651743
Validation loss: 2.811540146795188

Epoch: 90| Step: 0
Training loss: 2.938517941975597
Validation loss: 2.8124133662983186

Epoch: 6| Step: 1
Training loss: 2.9204282391729284
Validation loss: 2.8140529014306774

Epoch: 6| Step: 2
Training loss: 3.416921993732793
Validation loss: 2.814122704253665

Epoch: 6| Step: 3
Training loss: 3.643967563421975
Validation loss: 2.812813542434454

Epoch: 6| Step: 4
Training loss: 3.1695065229173953
Validation loss: 2.8176501529318805

Epoch: 6| Step: 5
Training loss: 3.9639722044708363
Validation loss: 2.8141615896385574

Epoch: 6| Step: 6
Training loss: 2.7608240558695987
Validation loss: 2.8154159979849727

Epoch: 6| Step: 7
Training loss: 2.807813342332581
Validation loss: 2.814155619990274

Epoch: 6| Step: 8
Training loss: 2.9602942258644704
Validation loss: 2.819483402251854

Epoch: 6| Step: 9
Training loss: 3.267522087460315
Validation loss: 2.821412358195411

Epoch: 6| Step: 10
Training loss: 2.658235503482315
Validation loss: 2.8199695729429672

Epoch: 6| Step: 11
Training loss: 2.774155386843275
Validation loss: 2.8166920493008227

Epoch: 6| Step: 12
Training loss: 2.933647226387174
Validation loss: 2.8150445053880078

Epoch: 6| Step: 13
Training loss: 3.1624783541575643
Validation loss: 2.813634003480259

Epoch: 91| Step: 0
Training loss: 3.559260183463534
Validation loss: 2.815580353361221

Epoch: 6| Step: 1
Training loss: 3.1745858470504413
Validation loss: 2.808831582342609

Epoch: 6| Step: 2
Training loss: 3.355045527278625
Validation loss: 2.8092391111988806

Epoch: 6| Step: 3
Training loss: 3.3178860044389933
Validation loss: 2.811933661425146

Epoch: 6| Step: 4
Training loss: 3.1784227559939713
Validation loss: 2.809920716361091

Epoch: 6| Step: 5
Training loss: 2.810293561323776
Validation loss: 2.8119392264379943

Epoch: 6| Step: 6
Training loss: 3.1087461822940345
Validation loss: 2.812268572803166

Epoch: 6| Step: 7
Training loss: 3.057959012053133
Validation loss: 2.814828721219106

Epoch: 6| Step: 8
Training loss: 3.042036547880807
Validation loss: 2.818505927606719

Epoch: 6| Step: 9
Training loss: 2.726992248070907
Validation loss: 2.822641410495836

Epoch: 6| Step: 10
Training loss: 2.8252675495215307
Validation loss: 2.81987311372812

Epoch: 6| Step: 11
Training loss: 2.873952425961831
Validation loss: 2.828836199667135

Epoch: 6| Step: 12
Training loss: 3.117459163444196
Validation loss: 2.821096948908261

Epoch: 6| Step: 13
Training loss: 3.6405261112256992
Validation loss: 2.81505107557322

Epoch: 92| Step: 0
Training loss: 3.3250057306455405
Validation loss: 2.810486798327506

Epoch: 6| Step: 1
Training loss: 3.0741173074312944
Validation loss: 2.804511012226119

Epoch: 6| Step: 2
Training loss: 2.6925096174119707
Validation loss: 2.8056359411719134

Epoch: 6| Step: 3
Training loss: 3.20705414739466
Validation loss: 2.8087026649770963

Epoch: 6| Step: 4
Training loss: 2.649548502912734
Validation loss: 2.8101672380253726

Epoch: 6| Step: 5
Training loss: 3.590437448780914
Validation loss: 2.8123800382017383

Epoch: 6| Step: 6
Training loss: 3.0426537640849944
Validation loss: 2.807463150285902

Epoch: 6| Step: 7
Training loss: 2.944404765727443
Validation loss: 2.8048848888698465

Epoch: 6| Step: 8
Training loss: 3.5724188603342517
Validation loss: 2.8030790904985725

Epoch: 6| Step: 9
Training loss: 3.1576359793407702
Validation loss: 2.8034300752594676

Epoch: 6| Step: 10
Training loss: 2.8196141442987357
Validation loss: 2.8043003414336667

Epoch: 6| Step: 11
Training loss: 3.5413658612731775
Validation loss: 2.806420301364781

Epoch: 6| Step: 12
Training loss: 2.7637167343974096
Validation loss: 2.8058997859233226

Epoch: 6| Step: 13
Training loss: 2.96709918251799
Validation loss: 2.806805053071466

Epoch: 93| Step: 0
Training loss: 3.089054744789835
Validation loss: 2.80470241460743

Epoch: 6| Step: 1
Training loss: 3.1555324531957183
Validation loss: 2.804188589610623

Epoch: 6| Step: 2
Training loss: 3.4082637049146842
Validation loss: 2.806825420148638

Epoch: 6| Step: 3
Training loss: 3.6096854468594013
Validation loss: 2.811254411927551

Epoch: 6| Step: 4
Training loss: 2.7957150062350142
Validation loss: 2.807291596654068

Epoch: 6| Step: 5
Training loss: 3.1625528383929717
Validation loss: 2.8098722672423904

Epoch: 6| Step: 6
Training loss: 3.030621178282981
Validation loss: 2.8169601769771537

Epoch: 6| Step: 7
Training loss: 2.580010389410584
Validation loss: 2.817157994514968

Epoch: 6| Step: 8
Training loss: 3.5486296628171394
Validation loss: 2.815986289204631

Epoch: 6| Step: 9
Training loss: 3.802411348311434
Validation loss: 2.808414170353094

Epoch: 6| Step: 10
Training loss: 2.0077792510014523
Validation loss: 2.8035600342830143

Epoch: 6| Step: 11
Training loss: 3.044246224248712
Validation loss: 2.79929934787186

Epoch: 6| Step: 12
Training loss: 3.0167202714685137
Validation loss: 2.8011112969183003

Epoch: 6| Step: 13
Training loss: 2.8240913583982783
Validation loss: 2.798017528670868

Epoch: 94| Step: 0
Training loss: 3.2997393707467197
Validation loss: 2.801595579923084

Epoch: 6| Step: 1
Training loss: 3.066731235266689
Validation loss: 2.8025633771327705

Epoch: 6| Step: 2
Training loss: 3.3606295350100748
Validation loss: 2.7985126373166853

Epoch: 6| Step: 3
Training loss: 3.1540088817348013
Validation loss: 2.7992344817678205

Epoch: 6| Step: 4
Training loss: 3.1656011160639603
Validation loss: 2.7988971021340547

Epoch: 6| Step: 5
Training loss: 2.5524295079046286
Validation loss: 2.7968305386132477

Epoch: 6| Step: 6
Training loss: 3.347039146921558
Validation loss: 2.8000797443490058

Epoch: 6| Step: 7
Training loss: 3.139575232428056
Validation loss: 2.799594788888268

Epoch: 6| Step: 8
Training loss: 3.1852923957596695
Validation loss: 2.7983800560329333

Epoch: 6| Step: 9
Training loss: 2.919412319669205
Validation loss: 2.7987027571381313

Epoch: 6| Step: 10
Training loss: 2.8080011626021104
Validation loss: 2.8007226499252997

Epoch: 6| Step: 11
Training loss: 3.1955554375481205
Validation loss: 2.8011574576251133

Epoch: 6| Step: 12
Training loss: 3.246744873259014
Validation loss: 2.804003479885307

Epoch: 6| Step: 13
Training loss: 2.8497218213763453
Validation loss: 2.8057872069497254

Epoch: 95| Step: 0
Training loss: 2.8059193235777906
Validation loss: 2.803642060511311

Epoch: 6| Step: 1
Training loss: 2.8634774217629673
Validation loss: 2.8022066171477524

Epoch: 6| Step: 2
Training loss: 3.2970996075093604
Validation loss: 2.803476277343584

Epoch: 6| Step: 3
Training loss: 2.8840045066935844
Validation loss: 2.800624307603796

Epoch: 6| Step: 4
Training loss: 3.4074760820160894
Validation loss: 2.797049688293112

Epoch: 6| Step: 5
Training loss: 3.176439430566037
Validation loss: 2.79636016670199

Epoch: 6| Step: 6
Training loss: 3.572088088039798
Validation loss: 2.794943740307567

Epoch: 6| Step: 7
Training loss: 3.368610833572065
Validation loss: 2.7954276336239636

Epoch: 6| Step: 8
Training loss: 2.9740216481717052
Validation loss: 2.7959006106211204

Epoch: 6| Step: 9
Training loss: 2.790808379672159
Validation loss: 2.7957879545299207

Epoch: 6| Step: 10
Training loss: 3.17324739278363
Validation loss: 2.7905923943335593

Epoch: 6| Step: 11
Training loss: 2.2454315005352963
Validation loss: 2.7936920553488087

Epoch: 6| Step: 12
Training loss: 3.295260354900594
Validation loss: 2.7947625167048282

Epoch: 6| Step: 13
Training loss: 3.6509217130552662
Validation loss: 2.796723243939653

Epoch: 96| Step: 0
Training loss: 2.957161702714029
Validation loss: 2.794331810329899

Epoch: 6| Step: 1
Training loss: 3.145946643801279
Validation loss: 2.799506642272842

Epoch: 6| Step: 2
Training loss: 2.7024925241711
Validation loss: 2.8077139326336646

Epoch: 6| Step: 3
Training loss: 3.1470701973464728
Validation loss: 2.802279561125947

Epoch: 6| Step: 4
Training loss: 2.616434290665329
Validation loss: 2.800278860553474

Epoch: 6| Step: 5
Training loss: 3.7814058634263366
Validation loss: 2.794063393934012

Epoch: 6| Step: 6
Training loss: 2.9708424472178603
Validation loss: 2.7956886894363704

Epoch: 6| Step: 7
Training loss: 3.92886544155395
Validation loss: 2.795722250440785

Epoch: 6| Step: 8
Training loss: 2.6329101182176333
Validation loss: 2.7928808293529643

Epoch: 6| Step: 9
Training loss: 2.697350745822647
Validation loss: 2.791473949694181

Epoch: 6| Step: 10
Training loss: 3.143550288566742
Validation loss: 2.79038822199527

Epoch: 6| Step: 11
Training loss: 3.2526562912823653
Validation loss: 2.7911759577207316

Epoch: 6| Step: 12
Training loss: 3.006705261146291
Validation loss: 2.797139897522541

Epoch: 6| Step: 13
Training loss: 3.0924218920231694
Validation loss: 2.7934101820932242

Epoch: 97| Step: 0
Training loss: 2.687696405375477
Validation loss: 2.798806466822128

Epoch: 6| Step: 1
Training loss: 3.4802725551464313
Validation loss: 2.791990545736522

Epoch: 6| Step: 2
Training loss: 3.3976948946195606
Validation loss: 2.7920731221206703

Epoch: 6| Step: 3
Training loss: 3.1250886523069763
Validation loss: 2.7945048430115147

Epoch: 6| Step: 4
Training loss: 2.89123908041258
Validation loss: 2.7916371479105333

Epoch: 6| Step: 5
Training loss: 2.9874888846856997
Validation loss: 2.790802147872937

Epoch: 6| Step: 6
Training loss: 2.7823148253484034
Validation loss: 2.7913614497120034

Epoch: 6| Step: 7
Training loss: 2.786378482613294
Validation loss: 2.79283989350119

Epoch: 6| Step: 8
Training loss: 3.397831163357747
Validation loss: 2.789043199065608

Epoch: 6| Step: 9
Training loss: 3.3977485046001705
Validation loss: 2.791444356041007

Epoch: 6| Step: 10
Training loss: 3.5312310952549826
Validation loss: 2.7873970138159736

Epoch: 6| Step: 11
Training loss: 2.9425790583929223
Validation loss: 2.7890117573203175

Epoch: 6| Step: 12
Training loss: 2.9990340903119983
Validation loss: 2.7863832908525494

Epoch: 6| Step: 13
Training loss: 2.4417598376762846
Validation loss: 2.7863491941294187

Epoch: 98| Step: 0
Training loss: 2.92665907929059
Validation loss: 2.7863541845930637

Epoch: 6| Step: 1
Training loss: 3.0935530166337273
Validation loss: 2.78573042606725

Epoch: 6| Step: 2
Training loss: 2.739414301735452
Validation loss: 2.7824360612641494

Epoch: 6| Step: 3
Training loss: 2.9205444896922854
Validation loss: 2.781863139585372

Epoch: 6| Step: 4
Training loss: 3.5730364068581624
Validation loss: 2.7841310491850595

Epoch: 6| Step: 5
Training loss: 3.2652841782562367
Validation loss: 2.7858307205331303

Epoch: 6| Step: 6
Training loss: 3.2438561982574297
Validation loss: 2.783438254590546

Epoch: 6| Step: 7
Training loss: 3.285456114157022
Validation loss: 2.783878900293048

Epoch: 6| Step: 8
Training loss: 3.8949590235698355
Validation loss: 2.7930655215624576

Epoch: 6| Step: 9
Training loss: 2.7483725500537877
Validation loss: 2.7863843047588115

Epoch: 6| Step: 10
Training loss: 3.039443279035187
Validation loss: 2.7847657491329945

Epoch: 6| Step: 11
Training loss: 2.024319136326642
Validation loss: 2.792821672466488

Epoch: 6| Step: 12
Training loss: 2.9789406395024387
Validation loss: 2.7830344496201525

Epoch: 6| Step: 13
Training loss: 3.2083423829054256
Validation loss: 2.7798310167683287

Epoch: 99| Step: 0
Training loss: 2.865504464679329
Validation loss: 2.7838021726904185

Epoch: 6| Step: 1
Training loss: 2.713008562220031
Validation loss: 2.781559386679061

Epoch: 6| Step: 2
Training loss: 3.3178608538404344
Validation loss: 2.77869508278329

Epoch: 6| Step: 3
Training loss: 3.373258070527065
Validation loss: 2.784183550205074

Epoch: 6| Step: 4
Training loss: 2.769697563654958
Validation loss: 2.778374123770818

Epoch: 6| Step: 5
Training loss: 2.928936427162657
Validation loss: 2.781148458159411

Epoch: 6| Step: 6
Training loss: 3.092797026621045
Validation loss: 2.7857385870621694

Epoch: 6| Step: 7
Training loss: 3.219452864561205
Validation loss: 2.785925038301054

Epoch: 6| Step: 8
Training loss: 2.810535507762367
Validation loss: 2.7849277690898813

Epoch: 6| Step: 9
Training loss: 3.636405759263988
Validation loss: 2.7855564397101515

Epoch: 6| Step: 10
Training loss: 3.077656821648707
Validation loss: 2.794647667244637

Epoch: 6| Step: 11
Training loss: 2.776133084297905
Validation loss: 2.7863346394794783

Epoch: 6| Step: 12
Training loss: 3.2786554160166173
Validation loss: 2.78242346064083

Epoch: 6| Step: 13
Training loss: 3.292723152169939
Validation loss: 2.792739260500443

Epoch: 100| Step: 0
Training loss: 3.3216650508016
Validation loss: 2.7883582336625365

Epoch: 6| Step: 1
Training loss: 2.882650065820952
Validation loss: 2.796210731611538

Epoch: 6| Step: 2
Training loss: 2.65339812725194
Validation loss: 2.797035263565326

Epoch: 6| Step: 3
Training loss: 3.0610056754168364
Validation loss: 2.803351715427758

Epoch: 6| Step: 4
Training loss: 3.4128868470635494
Validation loss: 2.806069851417618

Epoch: 6| Step: 5
Training loss: 3.387092684085562
Validation loss: 2.7825685403363973

Epoch: 6| Step: 6
Training loss: 3.128797741174041
Validation loss: 2.7780492472194838

Epoch: 6| Step: 7
Training loss: 3.029258152254926
Validation loss: 2.7783945645464496

Epoch: 6| Step: 8
Training loss: 2.805342063922254
Validation loss: 2.779818564805178

Epoch: 6| Step: 9
Training loss: 2.632423168339987
Validation loss: 2.779625133520372

Epoch: 6| Step: 10
Training loss: 3.133729567398392
Validation loss: 2.7779592070925756

Epoch: 6| Step: 11
Training loss: 2.9762712471310513
Validation loss: 2.778515079298636

Epoch: 6| Step: 12
Training loss: 3.6482407968170163
Validation loss: 2.777460384762574

Epoch: 6| Step: 13
Training loss: 2.9640134269420533
Validation loss: 2.777144763628572

Epoch: 101| Step: 0
Training loss: 2.9918260480527006
Validation loss: 2.7841147775996884

Epoch: 6| Step: 1
Training loss: 3.215975111575636
Validation loss: 2.780415375521758

Epoch: 6| Step: 2
Training loss: 2.7379670881211786
Validation loss: 2.7761902715786517

Epoch: 6| Step: 3
Training loss: 2.743187702928572
Validation loss: 2.773050979932871

Epoch: 6| Step: 4
Training loss: 3.437532736882468
Validation loss: 2.7763122911206906

Epoch: 6| Step: 5
Training loss: 2.6671795550486714
Validation loss: 2.775829039615932

Epoch: 6| Step: 6
Training loss: 3.3505983188437076
Validation loss: 2.7743871574005285

Epoch: 6| Step: 7
Training loss: 2.3824148377832
Validation loss: 2.777484739358451

Epoch: 6| Step: 8
Training loss: 3.3246695619607114
Validation loss: 2.7757859534281915

Epoch: 6| Step: 9
Training loss: 2.86968536087749
Validation loss: 2.7810336926769206

Epoch: 6| Step: 10
Training loss: 3.910247344366903
Validation loss: 2.7843346831968803

Epoch: 6| Step: 11
Training loss: 3.230584766375781
Validation loss: 2.776756024940412

Epoch: 6| Step: 12
Training loss: 3.0717580561531848
Validation loss: 2.7753744083975223

Epoch: 6| Step: 13
Training loss: 2.845695584613809
Validation loss: 2.76942256443071

Epoch: 102| Step: 0
Training loss: 2.7220211300783053
Validation loss: 2.7698766074561076

Epoch: 6| Step: 1
Training loss: 2.728720087297218
Validation loss: 2.7688103013192022

Epoch: 6| Step: 2
Training loss: 2.8656993194893423
Validation loss: 2.7694786767163917

Epoch: 6| Step: 3
Training loss: 3.4462305346670132
Validation loss: 2.7697922993626904

Epoch: 6| Step: 4
Training loss: 2.904283576119098
Validation loss: 2.7725778312983564

Epoch: 6| Step: 5
Training loss: 3.1913243706984207
Validation loss: 2.7694097268626225

Epoch: 6| Step: 6
Training loss: 3.435664987621105
Validation loss: 2.7702968268290644

Epoch: 6| Step: 7
Training loss: 3.2784257632634435
Validation loss: 2.7708024707833014

Epoch: 6| Step: 8
Training loss: 2.874404016171205
Validation loss: 2.7739389560409546

Epoch: 6| Step: 9
Training loss: 3.672645130964276
Validation loss: 2.772185385654373

Epoch: 6| Step: 10
Training loss: 2.946328875683936
Validation loss: 2.7696490495950843

Epoch: 6| Step: 11
Training loss: 3.5169290116309657
Validation loss: 2.768994467756032

Epoch: 6| Step: 12
Training loss: 2.4688499527024197
Validation loss: 2.7687244755678524

Epoch: 6| Step: 13
Training loss: 2.593892013155024
Validation loss: 2.7700711951667416

Epoch: 103| Step: 0
Training loss: 3.7144947228994356
Validation loss: 2.768249678957083

Epoch: 6| Step: 1
Training loss: 2.911888313729725
Validation loss: 2.764720361160545

Epoch: 6| Step: 2
Training loss: 2.89681706540344
Validation loss: 2.767096094209143

Epoch: 6| Step: 3
Training loss: 2.2306810267993837
Validation loss: 2.766092537015816

Epoch: 6| Step: 4
Training loss: 3.418073380094972
Validation loss: 2.7673929823996026

Epoch: 6| Step: 5
Training loss: 3.6313224115554705
Validation loss: 2.7677665841561407

Epoch: 6| Step: 6
Training loss: 3.1962605681112257
Validation loss: 2.7660342753081233

Epoch: 6| Step: 7
Training loss: 2.76218109361441
Validation loss: 2.7635908665081343

Epoch: 6| Step: 8
Training loss: 2.06740703037008
Validation loss: 2.766947245785568

Epoch: 6| Step: 9
Training loss: 2.82784906379499
Validation loss: 2.766109194511467

Epoch: 6| Step: 10
Training loss: 3.383333443577456
Validation loss: 2.768906613583005

Epoch: 6| Step: 11
Training loss: 3.5551191466118888
Validation loss: 2.769916884029487

Epoch: 6| Step: 12
Training loss: 2.951069111174081
Validation loss: 2.7756187207429335

Epoch: 6| Step: 13
Training loss: 3.028573968788583
Validation loss: 2.79167290143373

Epoch: 104| Step: 0
Training loss: 2.724841079977475
Validation loss: 2.7851394385647783

Epoch: 6| Step: 1
Training loss: 3.026734124606846
Validation loss: 2.803089092329797

Epoch: 6| Step: 2
Training loss: 3.142911922918714
Validation loss: 2.813235350155783

Epoch: 6| Step: 3
Training loss: 3.0872645361685773
Validation loss: 2.8129365069557584

Epoch: 6| Step: 4
Training loss: 3.366007374583715
Validation loss: 2.815159824049527

Epoch: 6| Step: 5
Training loss: 2.7713062963071513
Validation loss: 2.7892807090144287

Epoch: 6| Step: 6
Training loss: 3.265677857769737
Validation loss: 2.7830756936641468

Epoch: 6| Step: 7
Training loss: 3.428856542630707
Validation loss: 2.769804179972161

Epoch: 6| Step: 8
Training loss: 2.8345695117630476
Validation loss: 2.761761171015402

Epoch: 6| Step: 9
Training loss: 3.364814647994217
Validation loss: 2.7638098477892483

Epoch: 6| Step: 10
Training loss: 2.8382111989875938
Validation loss: 2.7655715793543716

Epoch: 6| Step: 11
Training loss: 3.0661449928513655
Validation loss: 2.759205749737195

Epoch: 6| Step: 12
Training loss: 2.7952690415391865
Validation loss: 2.760147258654886

Epoch: 6| Step: 13
Training loss: 3.4097103076389117
Validation loss: 2.7626546179203464

Epoch: 105| Step: 0
Training loss: 2.933461111348994
Validation loss: 2.7616694673220556

Epoch: 6| Step: 1
Training loss: 2.7414708953653872
Validation loss: 2.758848927761531

Epoch: 6| Step: 2
Training loss: 3.400782685791105
Validation loss: 2.760888891213923

Epoch: 6| Step: 3
Training loss: 2.6580569236176816
Validation loss: 2.762881225486996

Epoch: 6| Step: 4
Training loss: 3.023164958646402
Validation loss: 2.7646844913650255

Epoch: 6| Step: 5
Training loss: 3.260526775089298
Validation loss: 2.7625193046430216

Epoch: 6| Step: 6
Training loss: 3.270951449130415
Validation loss: 2.766283974926612

Epoch: 6| Step: 7
Training loss: 2.815199764203568
Validation loss: 2.762175410718457

Epoch: 6| Step: 8
Training loss: 2.777972401052743
Validation loss: 2.7632503688858385

Epoch: 6| Step: 9
Training loss: 2.824847772598462
Validation loss: 2.7620696907580924

Epoch: 6| Step: 10
Training loss: 3.3312429231207075
Validation loss: 2.761246190467403

Epoch: 6| Step: 11
Training loss: 3.044814758178417
Validation loss: 2.759889532749523

Epoch: 6| Step: 12
Training loss: 3.1171718969886753
Validation loss: 2.758048119214692

Epoch: 6| Step: 13
Training loss: 4.002828313358641
Validation loss: 2.7589294018062267

Epoch: 106| Step: 0
Training loss: 3.201784327852218
Validation loss: 2.755624550135537

Epoch: 6| Step: 1
Training loss: 2.9905781613691045
Validation loss: 2.7545796684806003

Epoch: 6| Step: 2
Training loss: 2.751700309148805
Validation loss: 2.7559638904265986

Epoch: 6| Step: 3
Training loss: 2.5774128248122836
Validation loss: 2.7538213589501335

Epoch: 6| Step: 4
Training loss: 2.3890271799833545
Validation loss: 2.7552963166179136

Epoch: 6| Step: 5
Training loss: 2.7802459961984374
Validation loss: 2.7526101620769565

Epoch: 6| Step: 6
Training loss: 3.2471692889050465
Validation loss: 2.754978535945994

Epoch: 6| Step: 7
Training loss: 3.088818714052155
Validation loss: 2.7549504332435366

Epoch: 6| Step: 8
Training loss: 3.2868761058050406
Validation loss: 2.7576443260889607

Epoch: 6| Step: 9
Training loss: 2.9372074712014875
Validation loss: 2.759415651936001

Epoch: 6| Step: 10
Training loss: 3.285942718313067
Validation loss: 2.755503700388447

Epoch: 6| Step: 11
Training loss: 3.955546726676527
Validation loss: 2.757438919982102

Epoch: 6| Step: 12
Training loss: 3.096555112452082
Validation loss: 2.754335561834117

Epoch: 6| Step: 13
Training loss: 3.1013890753624165
Validation loss: 2.751440163333062

Epoch: 107| Step: 0
Training loss: 2.5813603301403347
Validation loss: 2.7541687803530417

Epoch: 6| Step: 1
Training loss: 3.0549731499074215
Validation loss: 2.7516896677428857

Epoch: 6| Step: 2
Training loss: 2.9325594647062294
Validation loss: 2.7536819714609275

Epoch: 6| Step: 3
Training loss: 2.3536317155626625
Validation loss: 2.7538937161905923

Epoch: 6| Step: 4
Training loss: 2.945678364419871
Validation loss: 2.7511526583899517

Epoch: 6| Step: 5
Training loss: 2.5493688251021247
Validation loss: 2.7519501607384282

Epoch: 6| Step: 6
Training loss: 3.765839503340124
Validation loss: 2.7512459519351715

Epoch: 6| Step: 7
Training loss: 3.1634917321323948
Validation loss: 2.7499819724199615

Epoch: 6| Step: 8
Training loss: 3.5957116122251818
Validation loss: 2.7510051344677793

Epoch: 6| Step: 9
Training loss: 3.3093894893339857
Validation loss: 2.751980502813663

Epoch: 6| Step: 10
Training loss: 3.031714649572196
Validation loss: 2.749058046601935

Epoch: 6| Step: 11
Training loss: 2.998386584988185
Validation loss: 2.7555463575669887

Epoch: 6| Step: 12
Training loss: 2.945629639082634
Validation loss: 2.7643241402197387

Epoch: 6| Step: 13
Training loss: 3.593105225149492
Validation loss: 2.7672748181065443

Epoch: 108| Step: 0
Training loss: 2.81254467398873
Validation loss: 2.7705238928797313

Epoch: 6| Step: 1
Training loss: 3.6890498638138625
Validation loss: 2.772875253111663

Epoch: 6| Step: 2
Training loss: 3.300296400226153
Validation loss: 2.7723047693558525

Epoch: 6| Step: 3
Training loss: 2.85637670190036
Validation loss: 2.7691097007258825

Epoch: 6| Step: 4
Training loss: 2.56518414109677
Validation loss: 2.763626330278783

Epoch: 6| Step: 5
Training loss: 2.5600599441364693
Validation loss: 2.752940745963113

Epoch: 6| Step: 6
Training loss: 3.4535675455692307
Validation loss: 2.7488436556395888

Epoch: 6| Step: 7
Training loss: 2.7945214283903623
Validation loss: 2.7516492156772903

Epoch: 6| Step: 8
Training loss: 3.239580912859995
Validation loss: 2.7455147637986435

Epoch: 6| Step: 9
Training loss: 3.718615104729063
Validation loss: 2.744951138500008

Epoch: 6| Step: 10
Training loss: 2.734920774215471
Validation loss: 2.7471665974584187

Epoch: 6| Step: 11
Training loss: 2.9771218562764843
Validation loss: 2.745792582277026

Epoch: 6| Step: 12
Training loss: 2.996624318956242
Validation loss: 2.7513150084971993

Epoch: 6| Step: 13
Training loss: 2.874394560380519
Validation loss: 2.755075303826933

Epoch: 109| Step: 0
Training loss: 3.2887013434156773
Validation loss: 2.747196828593044

Epoch: 6| Step: 1
Training loss: 2.728546644838659
Validation loss: 2.7465666549562124

Epoch: 6| Step: 2
Training loss: 2.551313966793056
Validation loss: 2.7497321741415446

Epoch: 6| Step: 3
Training loss: 3.007000067834882
Validation loss: 2.7710049286405565

Epoch: 6| Step: 4
Training loss: 3.3968916260032547
Validation loss: 2.774457428716895

Epoch: 6| Step: 5
Training loss: 2.2777457299601207
Validation loss: 2.801887624005157

Epoch: 6| Step: 6
Training loss: 3.4349175202574633
Validation loss: 2.787559208240434

Epoch: 6| Step: 7
Training loss: 3.1686156114600705
Validation loss: 2.7869554166935355

Epoch: 6| Step: 8
Training loss: 2.835720253602152
Validation loss: 2.784580733828534

Epoch: 6| Step: 9
Training loss: 3.114225045884381
Validation loss: 2.764110665291909

Epoch: 6| Step: 10
Training loss: 3.2535857446913985
Validation loss: 2.746111442753864

Epoch: 6| Step: 11
Training loss: 3.2720769635874474
Validation loss: 2.7474817023568

Epoch: 6| Step: 12
Training loss: 2.8925288348792497
Validation loss: 2.7387028996596676

Epoch: 6| Step: 13
Training loss: 3.7652063414021497
Validation loss: 2.7416041439420478

Epoch: 110| Step: 0
Training loss: 3.436671764124566
Validation loss: 2.743094590460005

Epoch: 6| Step: 1
Training loss: 2.798873783865184
Validation loss: 2.7370126423496477

Epoch: 6| Step: 2
Training loss: 2.9475636265223284
Validation loss: 2.7414661832248037

Epoch: 6| Step: 3
Training loss: 3.2010692419388573
Validation loss: 2.740585533742178

Epoch: 6| Step: 4
Training loss: 3.2872091766637817
Validation loss: 2.74078752701781

Epoch: 6| Step: 5
Training loss: 3.077668596696023
Validation loss: 2.7387165158222637

Epoch: 6| Step: 6
Training loss: 3.099603375319099
Validation loss: 2.740954074238895

Epoch: 6| Step: 7
Training loss: 3.337738194341684
Validation loss: 2.7398828381509763

Epoch: 6| Step: 8
Training loss: 2.2523008873731687
Validation loss: 2.7376476461357937

Epoch: 6| Step: 9
Training loss: 3.1914379253706535
Validation loss: 2.7457035524814444

Epoch: 6| Step: 10
Training loss: 3.154207985396131
Validation loss: 2.7495995432266094

Epoch: 6| Step: 11
Training loss: 2.86371320976426
Validation loss: 2.759732205461362

Epoch: 6| Step: 12
Training loss: 3.126316556164872
Validation loss: 2.777389409456192

Epoch: 6| Step: 13
Training loss: 2.733759085906549
Validation loss: 2.7758414614506

Epoch: 111| Step: 0
Training loss: 3.2463563888560967
Validation loss: 2.8040566849147677

Epoch: 6| Step: 1
Training loss: 2.6575820275725013
Validation loss: 2.7948666853884108

Epoch: 6| Step: 2
Training loss: 3.529208513092112
Validation loss: 2.797500272808373

Epoch: 6| Step: 3
Training loss: 2.7980687667925443
Validation loss: 2.768725052421188

Epoch: 6| Step: 4
Training loss: 3.2159042370615896
Validation loss: 2.7469576734049914

Epoch: 6| Step: 5
Training loss: 2.872063837494826
Validation loss: 2.74022231192415

Epoch: 6| Step: 6
Training loss: 3.124735401395669
Validation loss: 2.7378303786601967

Epoch: 6| Step: 7
Training loss: 2.1970012861828865
Validation loss: 2.739219025251046

Epoch: 6| Step: 8
Training loss: 3.0616347978650307
Validation loss: 2.737476370258043

Epoch: 6| Step: 9
Training loss: 3.1962380409539146
Validation loss: 2.7360901500109365

Epoch: 6| Step: 10
Training loss: 3.5567722788476495
Validation loss: 2.73716617290094

Epoch: 6| Step: 11
Training loss: 3.164953337170209
Validation loss: 2.737139227141114

Epoch: 6| Step: 12
Training loss: 2.9565371222717793
Validation loss: 2.738690665087618

Epoch: 6| Step: 13
Training loss: 2.8537430460473785
Validation loss: 2.738754046505987

Epoch: 112| Step: 0
Training loss: 3.113120425484587
Validation loss: 2.7374508632165093

Epoch: 6| Step: 1
Training loss: 2.9434227180373034
Validation loss: 2.7369350355131505

Epoch: 6| Step: 2
Training loss: 3.148020979446632
Validation loss: 2.7380941226788553

Epoch: 6| Step: 3
Training loss: 3.0809774591648402
Validation loss: 2.7358127734157955

Epoch: 6| Step: 4
Training loss: 2.504034315812554
Validation loss: 2.736133687955632

Epoch: 6| Step: 5
Training loss: 2.7920149021352154
Validation loss: 2.734056702354259

Epoch: 6| Step: 6
Training loss: 3.4004091353244035
Validation loss: 2.7339342381446725

Epoch: 6| Step: 7
Training loss: 3.485755270687962
Validation loss: 2.7327012975567935

Epoch: 6| Step: 8
Training loss: 2.702262873237517
Validation loss: 2.7339983412032165

Epoch: 6| Step: 9
Training loss: 3.427771100230611
Validation loss: 2.7373579138326627

Epoch: 6| Step: 10
Training loss: 3.1635267015960884
Validation loss: 2.7384043595607674

Epoch: 6| Step: 11
Training loss: 3.356924183225446
Validation loss: 2.7414006631519956

Epoch: 6| Step: 12
Training loss: 2.5466660489918755
Validation loss: 2.7492714976908363

Epoch: 6| Step: 13
Training loss: 2.7683602293370346
Validation loss: 2.7467572314752964

Epoch: 113| Step: 0
Training loss: 2.9698847158130106
Validation loss: 2.740107022857704

Epoch: 6| Step: 1
Training loss: 3.3785856061734156
Validation loss: 2.7441805048426184

Epoch: 6| Step: 2
Training loss: 3.645242668624296
Validation loss: 2.734810527565862

Epoch: 6| Step: 3
Training loss: 2.965057325146725
Validation loss: 2.7353592467992813

Epoch: 6| Step: 4
Training loss: 3.0162016164137526
Validation loss: 2.730619625391323

Epoch: 6| Step: 5
Training loss: 2.6269457735433845
Validation loss: 2.7302605857709294

Epoch: 6| Step: 6
Training loss: 2.3710545343364338
Validation loss: 2.7289661752464336

Epoch: 6| Step: 7
Training loss: 3.430498240237055
Validation loss: 2.7284347453251163

Epoch: 6| Step: 8
Training loss: 2.3388351788650015
Validation loss: 2.7312803696309436

Epoch: 6| Step: 9
Training loss: 2.961238151323696
Validation loss: 2.730783427168711

Epoch: 6| Step: 10
Training loss: 2.8767767681859864
Validation loss: 2.730751228253181

Epoch: 6| Step: 11
Training loss: 3.0717602294095845
Validation loss: 2.7282765616918683

Epoch: 6| Step: 12
Training loss: 3.825480766251027
Validation loss: 2.730389787259627

Epoch: 6| Step: 13
Training loss: 2.724346407980727
Validation loss: 2.732696984012186

Epoch: 114| Step: 0
Training loss: 3.3241840365218938
Validation loss: 2.731681180747982

Epoch: 6| Step: 1
Training loss: 2.40358497374509
Validation loss: 2.7319574481886315

Epoch: 6| Step: 2
Training loss: 3.347652973898995
Validation loss: 2.7307311227490993

Epoch: 6| Step: 3
Training loss: 3.84699217976548
Validation loss: 2.733031487724581

Epoch: 6| Step: 4
Training loss: 2.7712878855867364
Validation loss: 2.729362209941988

Epoch: 6| Step: 5
Training loss: 3.573170792835197
Validation loss: 2.738646657619589

Epoch: 6| Step: 6
Training loss: 2.589735302157674
Validation loss: 2.733411297885525

Epoch: 6| Step: 7
Training loss: 3.58304387779103
Validation loss: 2.736944957778632

Epoch: 6| Step: 8
Training loss: 3.545187393207036
Validation loss: 2.7412596284631126

Epoch: 6| Step: 9
Training loss: 2.4564714870618887
Validation loss: 2.7357046027899417

Epoch: 6| Step: 10
Training loss: 2.420243630559165
Validation loss: 2.733217006014279

Epoch: 6| Step: 11
Training loss: 2.5031182868857975
Validation loss: 2.7275141134207392

Epoch: 6| Step: 12
Training loss: 2.429661888649933
Validation loss: 2.7246278282690604

Epoch: 6| Step: 13
Training loss: 3.3556934143811175
Validation loss: 2.7266534682640735

Epoch: 115| Step: 0
Training loss: 2.8754166011002322
Validation loss: 2.7270127186334308

Epoch: 6| Step: 1
Training loss: 2.6810614174990204
Validation loss: 2.7251743316204333

Epoch: 6| Step: 2
Training loss: 2.711614430805032
Validation loss: 2.7237278552895625

Epoch: 6| Step: 3
Training loss: 2.9015096746924667
Validation loss: 2.725200018946364

Epoch: 6| Step: 4
Training loss: 3.5105705038862767
Validation loss: 2.7229431013475263

Epoch: 6| Step: 5
Training loss: 3.6467392295531385
Validation loss: 2.7241576675202506

Epoch: 6| Step: 6
Training loss: 2.8750368198856586
Validation loss: 2.7247281071625253

Epoch: 6| Step: 7
Training loss: 2.5503775261057497
Validation loss: 2.7220207156796246

Epoch: 6| Step: 8
Training loss: 3.520008389289569
Validation loss: 2.7273201430876566

Epoch: 6| Step: 9
Training loss: 3.240452755035504
Validation loss: 2.7220538212263494

Epoch: 6| Step: 10
Training loss: 2.937876575762512
Validation loss: 2.7215534372562566

Epoch: 6| Step: 11
Training loss: 2.5028981576303666
Validation loss: 2.7215958503804076

Epoch: 6| Step: 12
Training loss: 3.2455942662497543
Validation loss: 2.722680853776967

Epoch: 6| Step: 13
Training loss: 3.140422909435903
Validation loss: 2.7198810197949506

Epoch: 116| Step: 0
Training loss: 3.0366323605500303
Validation loss: 2.7211970338921665

Epoch: 6| Step: 1
Training loss: 2.7912319945708326
Validation loss: 2.7233676227941217

Epoch: 6| Step: 2
Training loss: 3.2513864934268693
Validation loss: 2.7255466490520877

Epoch: 6| Step: 3
Training loss: 2.8766511239360906
Validation loss: 2.723631647222591

Epoch: 6| Step: 4
Training loss: 2.9804191535232887
Validation loss: 2.7220788062247223

Epoch: 6| Step: 5
Training loss: 3.0504936444138635
Validation loss: 2.7269617464126594

Epoch: 6| Step: 6
Training loss: 2.887517299847983
Validation loss: 2.730338981368815

Epoch: 6| Step: 7
Training loss: 3.240791185581836
Validation loss: 2.7286777163236584

Epoch: 6| Step: 8
Training loss: 3.4340872729969414
Validation loss: 2.7209865793813113

Epoch: 6| Step: 9
Training loss: 2.8441359708664367
Validation loss: 2.7213620886334344

Epoch: 6| Step: 10
Training loss: 2.9084692244676225
Validation loss: 2.7246763931155162

Epoch: 6| Step: 11
Training loss: 3.0588129386459593
Validation loss: 2.7183072384143574

Epoch: 6| Step: 12
Training loss: 3.0418540862010923
Validation loss: 2.7186188233002415

Epoch: 6| Step: 13
Training loss: 3.155499964061695
Validation loss: 2.7191968038447634

Epoch: 117| Step: 0
Training loss: 3.130998576229409
Validation loss: 2.719579451081323

Epoch: 6| Step: 1
Training loss: 2.6778148636243797
Validation loss: 2.7190614643784143

Epoch: 6| Step: 2
Training loss: 3.309688022351631
Validation loss: 2.71922417488324

Epoch: 6| Step: 3
Training loss: 2.705360502522427
Validation loss: 2.7226252299040112

Epoch: 6| Step: 4
Training loss: 2.8639456484235213
Validation loss: 2.723422770252405

Epoch: 6| Step: 5
Training loss: 2.9500404678413914
Validation loss: 2.7260939904299897

Epoch: 6| Step: 6
Training loss: 2.7262366682213752
Validation loss: 2.7355238265800303

Epoch: 6| Step: 7
Training loss: 3.6107935904428548
Validation loss: 2.7267197488588706

Epoch: 6| Step: 8
Training loss: 2.8219614043161454
Validation loss: 2.7234503002620296

Epoch: 6| Step: 9
Training loss: 2.643483888476348
Validation loss: 2.720724902688528

Epoch: 6| Step: 10
Training loss: 2.9743974476171813
Validation loss: 2.7179306779682886

Epoch: 6| Step: 11
Training loss: 3.358095005056927
Validation loss: 2.716501248201207

Epoch: 6| Step: 12
Training loss: 3.701428761286367
Validation loss: 2.716079124176012

Epoch: 6| Step: 13
Training loss: 2.5601530725193413
Validation loss: 2.7145547480018553

Epoch: 118| Step: 0
Training loss: 2.8912088990083507
Validation loss: 2.7151132743301245

Epoch: 6| Step: 1
Training loss: 3.0661246200785857
Validation loss: 2.715439154024767

Epoch: 6| Step: 2
Training loss: 2.900737004516707
Validation loss: 2.7165581742735174

Epoch: 6| Step: 3
Training loss: 3.2637867111192653
Validation loss: 2.713988786072141

Epoch: 6| Step: 4
Training loss: 2.5868634643444945
Validation loss: 2.714129617930292

Epoch: 6| Step: 5
Training loss: 3.741562060371487
Validation loss: 2.7178372661589454

Epoch: 6| Step: 6
Training loss: 2.9668524851807585
Validation loss: 2.7153623467909807

Epoch: 6| Step: 7
Training loss: 2.8780839384879693
Validation loss: 2.7167054285358865

Epoch: 6| Step: 8
Training loss: 2.8871818862663927
Validation loss: 2.7149245369270654

Epoch: 6| Step: 9
Training loss: 2.1631393942675037
Validation loss: 2.7152518404120713

Epoch: 6| Step: 10
Training loss: 2.6455584606055194
Validation loss: 2.7166191126606356

Epoch: 6| Step: 11
Training loss: 3.5356016099819327
Validation loss: 2.7160363889311028

Epoch: 6| Step: 12
Training loss: 3.0640715634427402
Validation loss: 2.7235186091790546

Epoch: 6| Step: 13
Training loss: 3.839530675937152
Validation loss: 2.7164978347317636

Epoch: 119| Step: 0
Training loss: 2.2381012263309716
Validation loss: 2.716657477078377

Epoch: 6| Step: 1
Training loss: 3.3745621291203776
Validation loss: 2.7190385117780926

Epoch: 6| Step: 2
Training loss: 3.232173446835687
Validation loss: 2.718957291733208

Epoch: 6| Step: 3
Training loss: 2.8014215777516824
Validation loss: 2.7242352412299313

Epoch: 6| Step: 4
Training loss: 2.722479881583598
Validation loss: 2.72632987687274

Epoch: 6| Step: 5
Training loss: 3.1149383308588487
Validation loss: 2.725291730677326

Epoch: 6| Step: 6
Training loss: 3.139925295190158
Validation loss: 2.723026178648072

Epoch: 6| Step: 7
Training loss: 3.2404398056864663
Validation loss: 2.7198871251956858

Epoch: 6| Step: 8
Training loss: 2.8095180385952134
Validation loss: 2.7201329298294463

Epoch: 6| Step: 9
Training loss: 3.0565797842387483
Validation loss: 2.7143641914340106

Epoch: 6| Step: 10
Training loss: 2.701704412718685
Validation loss: 2.714073455142535

Epoch: 6| Step: 11
Training loss: 3.1040685412026403
Validation loss: 2.7133610808424202

Epoch: 6| Step: 12
Training loss: 3.5489240600853846
Validation loss: 2.711938502826942

Epoch: 6| Step: 13
Training loss: 3.1241108964684043
Validation loss: 2.710981471207575

Epoch: 120| Step: 0
Training loss: 4.050289878361163
Validation loss: 2.7110592261943114

Epoch: 6| Step: 1
Training loss: 2.4704854153092786
Validation loss: 2.711025337682108

Epoch: 6| Step: 2
Training loss: 2.5972951537674134
Validation loss: 2.7128030565623287

Epoch: 6| Step: 3
Training loss: 2.9361530218759193
Validation loss: 2.7107089872721812

Epoch: 6| Step: 4
Training loss: 3.608933194686615
Validation loss: 2.710796781290166

Epoch: 6| Step: 5
Training loss: 3.3640433587762453
Validation loss: 2.7114585684689056

Epoch: 6| Step: 6
Training loss: 2.9136605893249055
Validation loss: 2.7110362606907987

Epoch: 6| Step: 7
Training loss: 2.9538988179393577
Validation loss: 2.7125348885760525

Epoch: 6| Step: 8
Training loss: 3.49465834490753
Validation loss: 2.7198606209178355

Epoch: 6| Step: 9
Training loss: 2.7483888588179988
Validation loss: 2.7226845005406037

Epoch: 6| Step: 10
Training loss: 2.796322560227958
Validation loss: 2.7202925935088405

Epoch: 6| Step: 11
Training loss: 2.501227077701278
Validation loss: 2.7216402164422315

Epoch: 6| Step: 12
Training loss: 1.8896741761812974
Validation loss: 2.723036742834342

Epoch: 6| Step: 13
Training loss: 3.6694883990938005
Validation loss: 2.7531225034819684

Epoch: 121| Step: 0
Training loss: 3.25551401559528
Validation loss: 2.7256035065989725

Epoch: 6| Step: 1
Training loss: 3.438559351593151
Validation loss: 2.7084155727297325

Epoch: 6| Step: 2
Training loss: 2.8250932829992896
Validation loss: 2.705379087087184

Epoch: 6| Step: 3
Training loss: 3.1356687391643367
Validation loss: 2.7081659645509197

Epoch: 6| Step: 4
Training loss: 2.6231553998980237
Validation loss: 2.705565276304681

Epoch: 6| Step: 5
Training loss: 2.598198626119459
Validation loss: 2.704561787624929

Epoch: 6| Step: 6
Training loss: 3.4642754640273083
Validation loss: 2.709796826892975

Epoch: 6| Step: 7
Training loss: 3.1961635957749457
Validation loss: 2.70696408388332

Epoch: 6| Step: 8
Training loss: 3.633288805510854
Validation loss: 2.7059676737657283

Epoch: 6| Step: 9
Training loss: 2.557601153777539
Validation loss: 2.704726600692534

Epoch: 6| Step: 10
Training loss: 3.2517246658676844
Validation loss: 2.708612899612963

Epoch: 6| Step: 11
Training loss: 2.367333335287054
Validation loss: 2.7109839942015923

Epoch: 6| Step: 12
Training loss: 2.8721574746103253
Validation loss: 2.7277373273819703

Epoch: 6| Step: 13
Training loss: 2.747956730625483
Validation loss: 2.755686028457871

Epoch: 122| Step: 0
Training loss: 2.8161195987424588
Validation loss: 2.7491581393573536

Epoch: 6| Step: 1
Training loss: 2.5895487759760734
Validation loss: 2.763787821507969

Epoch: 6| Step: 2
Training loss: 3.0600598014024465
Validation loss: 2.758310850184585

Epoch: 6| Step: 3
Training loss: 3.048695338385977
Validation loss: 2.721439073198472

Epoch: 6| Step: 4
Training loss: 2.0610313966776004
Validation loss: 2.702516444487473

Epoch: 6| Step: 5
Training loss: 3.3917501665813896
Validation loss: 2.705049764507389

Epoch: 6| Step: 6
Training loss: 2.267407367332477
Validation loss: 2.7073333225556238

Epoch: 6| Step: 7
Training loss: 3.231449149098659
Validation loss: 2.7075022211824065

Epoch: 6| Step: 8
Training loss: 3.1258957151369624
Validation loss: 2.7232735314076892

Epoch: 6| Step: 9
Training loss: 3.20661445910912
Validation loss: 2.7189154333565497

Epoch: 6| Step: 10
Training loss: 3.8128050385061276
Validation loss: 2.7092576096023664

Epoch: 6| Step: 11
Training loss: 3.1553698530611167
Validation loss: 2.707071570462066

Epoch: 6| Step: 12
Training loss: 3.4077117303346753
Validation loss: 2.700507881186573

Epoch: 6| Step: 13
Training loss: 2.789162684759651
Validation loss: 2.6985019592653674

Epoch: 123| Step: 0
Training loss: 2.9452224839112455
Validation loss: 2.6978966598221863

Epoch: 6| Step: 1
Training loss: 3.337033951469736
Validation loss: 2.7083032626871977

Epoch: 6| Step: 2
Training loss: 3.110928401425984
Validation loss: 2.721192747332269

Epoch: 6| Step: 3
Training loss: 2.977905611201207
Validation loss: 2.7394302951142335

Epoch: 6| Step: 4
Training loss: 2.79915078772943
Validation loss: 2.7841215464655247

Epoch: 6| Step: 5
Training loss: 3.3511675266246996
Validation loss: 2.7664316015116377

Epoch: 6| Step: 6
Training loss: 2.8151152425589863
Validation loss: 2.7511568386316836

Epoch: 6| Step: 7
Training loss: 3.463597775724247
Validation loss: 2.737882407002021

Epoch: 6| Step: 8
Training loss: 3.247698629294096
Validation loss: 2.713050955847704

Epoch: 6| Step: 9
Training loss: 2.9277645056092156
Validation loss: 2.7078766124559834

Epoch: 6| Step: 10
Training loss: 3.2036824555408017
Validation loss: 2.698214054445338

Epoch: 6| Step: 11
Training loss: 2.877569128775423
Validation loss: 2.697781142765158

Epoch: 6| Step: 12
Training loss: 2.5668774873263094
Validation loss: 2.695319738225267

Epoch: 6| Step: 13
Training loss: 2.0784181086981053
Validation loss: 2.6987260975828624

Epoch: 124| Step: 0
Training loss: 3.266583169791269
Validation loss: 2.7011167952626067

Epoch: 6| Step: 1
Training loss: 3.3589057062285868
Validation loss: 2.7028634578293054

Epoch: 6| Step: 2
Training loss: 3.4756445197805914
Validation loss: 2.701164692318178

Epoch: 6| Step: 3
Training loss: 2.8579561642701323
Validation loss: 2.7088913370316474

Epoch: 6| Step: 4
Training loss: 2.6765368209292926
Validation loss: 2.714385750807866

Epoch: 6| Step: 5
Training loss: 3.282358908602594
Validation loss: 2.7153758628464124

Epoch: 6| Step: 6
Training loss: 3.4980795905086555
Validation loss: 2.710304707698324

Epoch: 6| Step: 7
Training loss: 3.0941516345791062
Validation loss: 2.69876030012615

Epoch: 6| Step: 8
Training loss: 2.6065495892872583
Validation loss: 2.700264221094229

Epoch: 6| Step: 9
Training loss: 2.996054279808461
Validation loss: 2.701727908268182

Epoch: 6| Step: 10
Training loss: 2.6571276841558116
Validation loss: 2.730548012774363

Epoch: 6| Step: 11
Training loss: 3.058485241130786
Validation loss: 2.7419572103678314

Epoch: 6| Step: 12
Training loss: 2.7958007113225434
Validation loss: 2.746841214342839

Epoch: 6| Step: 13
Training loss: 2.2157385362554316
Validation loss: 2.7432951383341915

Epoch: 125| Step: 0
Training loss: 3.7780185479374726
Validation loss: 2.767539797652176

Epoch: 6| Step: 1
Training loss: 3.059951967847245
Validation loss: 2.7318755677713504

Epoch: 6| Step: 2
Training loss: 2.815744181999124
Validation loss: 2.722743830147119

Epoch: 6| Step: 3
Training loss: 2.5316416119592855
Validation loss: 2.7107007573829605

Epoch: 6| Step: 4
Training loss: 3.1903670637315034
Validation loss: 2.7120974720696487

Epoch: 6| Step: 5
Training loss: 2.517132230562728
Validation loss: 2.699247913521518

Epoch: 6| Step: 6
Training loss: 2.659603739313603
Validation loss: 2.70398980520513

Epoch: 6| Step: 7
Training loss: 3.4864089571774297
Validation loss: 2.705129894334138

Epoch: 6| Step: 8
Training loss: 2.77201105964403
Validation loss: 2.702030143910364

Epoch: 6| Step: 9
Training loss: 3.6289659049691707
Validation loss: 2.704870091863927

Epoch: 6| Step: 10
Training loss: 2.628084187411862
Validation loss: 2.6983365218287547

Epoch: 6| Step: 11
Training loss: 2.5786102762983107
Validation loss: 2.697733364291501

Epoch: 6| Step: 12
Training loss: 3.6159110731735535
Validation loss: 2.7030621498260916

Epoch: 6| Step: 13
Training loss: 2.482346576356026
Validation loss: 2.7099871095891808

Epoch: 126| Step: 0
Training loss: 2.7881365609458424
Validation loss: 2.699882252798337

Epoch: 6| Step: 1
Training loss: 3.500694614692826
Validation loss: 2.700112511627493

Epoch: 6| Step: 2
Training loss: 3.343932815260144
Validation loss: 2.7072754402212387

Epoch: 6| Step: 3
Training loss: 2.569284158008749
Validation loss: 2.704975779420041

Epoch: 6| Step: 4
Training loss: 3.63183646267474
Validation loss: 2.7025877090037205

Epoch: 6| Step: 5
Training loss: 3.150312825972884
Validation loss: 2.6977678968150034

Epoch: 6| Step: 6
Training loss: 3.2678426850927447
Validation loss: 2.707190647554312

Epoch: 6| Step: 7
Training loss: 2.3769613499369817
Validation loss: 2.7161106022426846

Epoch: 6| Step: 8
Training loss: 3.496706639277449
Validation loss: 2.7033744496326877

Epoch: 6| Step: 9
Training loss: 2.851384238327932
Validation loss: 2.7033437042560364

Epoch: 6| Step: 10
Training loss: 2.2334167986783506
Validation loss: 2.694391399431287

Epoch: 6| Step: 11
Training loss: 2.289956292647331
Validation loss: 2.6914540426834033

Epoch: 6| Step: 12
Training loss: 3.3878205826867624
Validation loss: 2.6889398137267064

Epoch: 6| Step: 13
Training loss: 2.6614547002858386
Validation loss: 2.6919547075422665

Epoch: 127| Step: 0
Training loss: 2.689008422520599
Validation loss: 2.690311483735949

Epoch: 6| Step: 1
Training loss: 2.92702825274971
Validation loss: 2.6893974449342113

Epoch: 6| Step: 2
Training loss: 3.375339914794549
Validation loss: 2.685695250170172

Epoch: 6| Step: 3
Training loss: 3.8627428194527007
Validation loss: 2.690501119707834

Epoch: 6| Step: 4
Training loss: 2.683917296782678
Validation loss: 2.6847510982671325

Epoch: 6| Step: 5
Training loss: 2.9283488152459642
Validation loss: 2.686051050853205

Epoch: 6| Step: 6
Training loss: 2.678867670661939
Validation loss: 2.684968995208812

Epoch: 6| Step: 7
Training loss: 3.4779379191986455
Validation loss: 2.6869605654118045

Epoch: 6| Step: 8
Training loss: 3.0070184625604957
Validation loss: 2.688998339579256

Epoch: 6| Step: 9
Training loss: 2.875770133985919
Validation loss: 2.6878247724203073

Epoch: 6| Step: 10
Training loss: 3.096986715109061
Validation loss: 2.686795805629495

Epoch: 6| Step: 11
Training loss: 2.0454778197919885
Validation loss: 2.68517963757113

Epoch: 6| Step: 12
Training loss: 2.6722725020410616
Validation loss: 2.6842635179696126

Epoch: 6| Step: 13
Training loss: 3.67188162295779
Validation loss: 2.6924724314068507

Epoch: 128| Step: 0
Training loss: 2.4714670801982006
Validation loss: 2.696494504258106

Epoch: 6| Step: 1
Training loss: 2.9414406175366077
Validation loss: 2.700516439274431

Epoch: 6| Step: 2
Training loss: 2.3635912479083014
Validation loss: 2.7138281970041325

Epoch: 6| Step: 3
Training loss: 3.305727531240774
Validation loss: 2.7448272064542634

Epoch: 6| Step: 4
Training loss: 2.817308342278351
Validation loss: 2.759136800540024

Epoch: 6| Step: 5
Training loss: 3.753380332729304
Validation loss: 2.7729173610738127

Epoch: 6| Step: 6
Training loss: 3.0336266078932925
Validation loss: 2.731548906591839

Epoch: 6| Step: 7
Training loss: 2.7182593944355293
Validation loss: 2.707269350411822

Epoch: 6| Step: 8
Training loss: 3.4156382959217
Validation loss: 2.6872456538271607

Epoch: 6| Step: 9
Training loss: 2.933873474357338
Validation loss: 2.6814580979115763

Epoch: 6| Step: 10
Training loss: 3.4756615317801147
Validation loss: 2.681387821641201

Epoch: 6| Step: 11
Training loss: 2.86462470747228
Validation loss: 2.685814701332197

Epoch: 6| Step: 12
Training loss: 3.1678432152801816
Validation loss: 2.6995057537440252

Epoch: 6| Step: 13
Training loss: 2.2619104913529036
Validation loss: 2.700183281323456

Epoch: 129| Step: 0
Training loss: 3.6921866424598297
Validation loss: 2.686333649566301

Epoch: 6| Step: 1
Training loss: 2.8640575319404196
Validation loss: 2.686600952793143

Epoch: 6| Step: 2
Training loss: 2.829265554176526
Validation loss: 2.6910544087675103

Epoch: 6| Step: 3
Training loss: 3.255647008202302
Validation loss: 2.709235840985921

Epoch: 6| Step: 4
Training loss: 2.7561574838210094
Validation loss: 2.712869326847057

Epoch: 6| Step: 5
Training loss: 3.3141288351410068
Validation loss: 2.7111924546172324

Epoch: 6| Step: 6
Training loss: 3.090843299430714
Validation loss: 2.7006378956954573

Epoch: 6| Step: 7
Training loss: 3.013166304856919
Validation loss: 2.7029220046756817

Epoch: 6| Step: 8
Training loss: 2.8914369834538447
Validation loss: 2.7023435069120114

Epoch: 6| Step: 9
Training loss: 2.494535768853075
Validation loss: 2.689743097970609

Epoch: 6| Step: 10
Training loss: 2.5677158956564656
Validation loss: 2.699260727667703

Epoch: 6| Step: 11
Training loss: 3.522419649267656
Validation loss: 2.697210037777701

Epoch: 6| Step: 12
Training loss: 2.7862708388140125
Validation loss: 2.7017788659883437

Epoch: 6| Step: 13
Training loss: 2.838046716124108
Validation loss: 2.7020570740367154

Epoch: 130| Step: 0
Training loss: 3.3570883842153445
Validation loss: 2.6927225708334674

Epoch: 6| Step: 1
Training loss: 3.042431217064946
Validation loss: 2.689705150291386

Epoch: 6| Step: 2
Training loss: 3.1175955980903653
Validation loss: 2.682355626975751

Epoch: 6| Step: 3
Training loss: 3.1687663963841697
Validation loss: 2.6817484784228713

Epoch: 6| Step: 4
Training loss: 3.3199725526801145
Validation loss: 2.6831269549117014

Epoch: 6| Step: 5
Training loss: 2.8263542575156873
Validation loss: 2.6831591730827666

Epoch: 6| Step: 6
Training loss: 3.0368320939541777
Validation loss: 2.682491698284771

Epoch: 6| Step: 7
Training loss: 3.1264791421296696
Validation loss: 2.681046194694157

Epoch: 6| Step: 8
Training loss: 2.8161627760788384
Validation loss: 2.6823813334522035

Epoch: 6| Step: 9
Training loss: 2.572447102024141
Validation loss: 2.6835350527794355

Epoch: 6| Step: 10
Training loss: 2.9681153271522116
Validation loss: 2.6803742550636964

Epoch: 6| Step: 11
Training loss: 2.3829582795122017
Validation loss: 2.6816549305023063

Epoch: 6| Step: 12
Training loss: 3.3260240684367877
Validation loss: 2.6829089599650757

Epoch: 6| Step: 13
Training loss: 2.8474464286875714
Validation loss: 2.681663811653194

Epoch: 131| Step: 0
Training loss: 3.24130759191341
Validation loss: 2.6921919664004705

Epoch: 6| Step: 1
Training loss: 2.762742345199909
Validation loss: 2.688798347074668

Epoch: 6| Step: 2
Training loss: 3.5190133953267724
Validation loss: 2.687872720348389

Epoch: 6| Step: 3
Training loss: 2.781880339439751
Validation loss: 2.683162763684159

Epoch: 6| Step: 4
Training loss: 2.8551532868556935
Validation loss: 2.693063196359766

Epoch: 6| Step: 5
Training loss: 3.1197907326282426
Validation loss: 2.690500742379702

Epoch: 6| Step: 6
Training loss: 1.9679438439126202
Validation loss: 2.6837026406769775

Epoch: 6| Step: 7
Training loss: 3.2464736000114476
Validation loss: 2.6836377708787955

Epoch: 6| Step: 8
Training loss: 3.248913803521103
Validation loss: 2.6838813643494723

Epoch: 6| Step: 9
Training loss: 3.409751002821924
Validation loss: 2.6837919562394212

Epoch: 6| Step: 10
Training loss: 2.56740528559725
Validation loss: 2.680703120316271

Epoch: 6| Step: 11
Training loss: 2.597126153766012
Validation loss: 2.6801264086019008

Epoch: 6| Step: 12
Training loss: 3.015142372527594
Validation loss: 2.676932431716185

Epoch: 6| Step: 13
Training loss: 3.581418849299966
Validation loss: 2.672843788653574

Epoch: 132| Step: 0
Training loss: 2.5309326538084758
Validation loss: 2.6725448644706966

Epoch: 6| Step: 1
Training loss: 3.140150651172734
Validation loss: 2.6720484847749333

Epoch: 6| Step: 2
Training loss: 3.018975012944655
Validation loss: 2.671008496481088

Epoch: 6| Step: 3
Training loss: 2.622718728019868
Validation loss: 2.670173959884759

Epoch: 6| Step: 4
Training loss: 3.477442666410037
Validation loss: 2.673845314138356

Epoch: 6| Step: 5
Training loss: 2.7834611311333726
Validation loss: 2.677886156534035

Epoch: 6| Step: 6
Training loss: 2.717576398433583
Validation loss: 2.6765161060748794

Epoch: 6| Step: 7
Training loss: 3.409600386263227
Validation loss: 2.6847582732972524

Epoch: 6| Step: 8
Training loss: 2.7120527892024704
Validation loss: 2.678643053604115

Epoch: 6| Step: 9
Training loss: 3.4226051143891794
Validation loss: 2.679181575476902

Epoch: 6| Step: 10
Training loss: 2.9897001201578193
Validation loss: 2.6747159267869978

Epoch: 6| Step: 11
Training loss: 2.8945177415128445
Validation loss: 2.677618947455378

Epoch: 6| Step: 12
Training loss: 3.013710006897855
Validation loss: 2.670133086089228

Epoch: 6| Step: 13
Training loss: 3.0796656746673996
Validation loss: 2.67143950517017

Epoch: 133| Step: 0
Training loss: 2.597793919636692
Validation loss: 2.668673028441351

Epoch: 6| Step: 1
Training loss: 2.7722930696141357
Validation loss: 2.666654298994651

Epoch: 6| Step: 2
Training loss: 3.2556629728086244
Validation loss: 2.66749710052865

Epoch: 6| Step: 3
Training loss: 2.951759305161156
Validation loss: 2.669805581077128

Epoch: 6| Step: 4
Training loss: 2.770466935639801
Validation loss: 2.6668419094596474

Epoch: 6| Step: 5
Training loss: 2.827664163884789
Validation loss: 2.667147392798347

Epoch: 6| Step: 6
Training loss: 3.5403298641334255
Validation loss: 2.6732351931548513

Epoch: 6| Step: 7
Training loss: 2.726725051537714
Validation loss: 2.6697241331862016

Epoch: 6| Step: 8
Training loss: 3.69054506943702
Validation loss: 2.6678001708362764

Epoch: 6| Step: 9
Training loss: 2.611710011898101
Validation loss: 2.671157017949661

Epoch: 6| Step: 10
Training loss: 2.994525205395592
Validation loss: 2.6687204751115448

Epoch: 6| Step: 11
Training loss: 3.1034609271847615
Validation loss: 2.676479428694307

Epoch: 6| Step: 12
Training loss: 3.2129499899530733
Validation loss: 2.6760195414108945

Epoch: 6| Step: 13
Training loss: 2.261581706637171
Validation loss: 2.6754935774400126

Epoch: 134| Step: 0
Training loss: 2.784758337415068
Validation loss: 2.673235247818023

Epoch: 6| Step: 1
Training loss: 3.43871743578175
Validation loss: 2.679313819929423

Epoch: 6| Step: 2
Training loss: 2.7995211055482607
Validation loss: 2.6776692600847545

Epoch: 6| Step: 3
Training loss: 3.323678498347272
Validation loss: 2.6769849895539872

Epoch: 6| Step: 4
Training loss: 3.009816639026624
Validation loss: 2.670156474441179

Epoch: 6| Step: 5
Training loss: 2.8539118038095257
Validation loss: 2.668054543185376

Epoch: 6| Step: 6
Training loss: 2.6392117843730234
Validation loss: 2.66721572786548

Epoch: 6| Step: 7
Training loss: 2.447049337634088
Validation loss: 2.6696342960735406

Epoch: 6| Step: 8
Training loss: 2.8339542568717486
Validation loss: 2.6655550451637158

Epoch: 6| Step: 9
Training loss: 3.1552664857939514
Validation loss: 2.6709398524437464

Epoch: 6| Step: 10
Training loss: 2.5754919304429698
Validation loss: 2.6630931208433357

Epoch: 6| Step: 11
Training loss: 3.4372394809838007
Validation loss: 2.6641195544518657

Epoch: 6| Step: 12
Training loss: 3.382061529167196
Validation loss: 2.66371617856688

Epoch: 6| Step: 13
Training loss: 3.032059708825151
Validation loss: 2.6669628442852287

Epoch: 135| Step: 0
Training loss: 3.3502093520154146
Validation loss: 2.669396213535145

Epoch: 6| Step: 1
Training loss: 2.6664448486896397
Validation loss: 2.6686682213821284

Epoch: 6| Step: 2
Training loss: 2.8202127454873986
Validation loss: 2.6663166320805978

Epoch: 6| Step: 3
Training loss: 2.9671085035787415
Validation loss: 2.6676749417765495

Epoch: 6| Step: 4
Training loss: 2.967864054946759
Validation loss: 2.6652548562335747

Epoch: 6| Step: 5
Training loss: 2.8273649933252263
Validation loss: 2.6715815565951693

Epoch: 6| Step: 6
Training loss: 3.88007391711742
Validation loss: 2.668293279629661

Epoch: 6| Step: 7
Training loss: 3.1910619841855254
Validation loss: 2.671998796447759

Epoch: 6| Step: 8
Training loss: 2.5036078169584095
Validation loss: 2.671525334676937

Epoch: 6| Step: 9
Training loss: 3.098672053259645
Validation loss: 2.673505696001013

Epoch: 6| Step: 10
Training loss: 3.1889764694728564
Validation loss: 2.6777372577048233

Epoch: 6| Step: 11
Training loss: 2.429956157587089
Validation loss: 2.674489199224574

Epoch: 6| Step: 12
Training loss: 2.97431408323786
Validation loss: 2.675437108582987

Epoch: 6| Step: 13
Training loss: 2.368003276597153
Validation loss: 2.6982035365410595

Epoch: 136| Step: 0
Training loss: 3.4300032276994736
Validation loss: 2.6926034889621286

Epoch: 6| Step: 1
Training loss: 2.9322186331634446
Validation loss: 2.690589858954434

Epoch: 6| Step: 2
Training loss: 2.7949762132482077
Validation loss: 2.696528762677581

Epoch: 6| Step: 3
Training loss: 3.3714476363171815
Validation loss: 2.7047834115652605

Epoch: 6| Step: 4
Training loss: 2.8720975405671267
Validation loss: 2.7027041493924413

Epoch: 6| Step: 5
Training loss: 2.2639758191519164
Validation loss: 2.67357252803671

Epoch: 6| Step: 6
Training loss: 3.1007801673908415
Validation loss: 2.6680174852416814

Epoch: 6| Step: 7
Training loss: 2.806057311241552
Validation loss: 2.6673950333720304

Epoch: 6| Step: 8
Training loss: 2.8367429487981726
Validation loss: 2.6675828838960194

Epoch: 6| Step: 9
Training loss: 2.6213095017621098
Validation loss: 2.664880644437655

Epoch: 6| Step: 10
Training loss: 3.320840663415213
Validation loss: 2.668161111572008

Epoch: 6| Step: 11
Training loss: 3.044387192972882
Validation loss: 2.665367069995961

Epoch: 6| Step: 12
Training loss: 3.51299407850766
Validation loss: 2.661837466511319

Epoch: 6| Step: 13
Training loss: 2.416289354883019
Validation loss: 2.661610739943939

Epoch: 137| Step: 0
Training loss: 2.4724117115947455
Validation loss: 2.6602757676296065

Epoch: 6| Step: 1
Training loss: 3.2006802789480355
Validation loss: 2.6626117689579196

Epoch: 6| Step: 2
Training loss: 3.0362543699532254
Validation loss: 2.666682177608766

Epoch: 6| Step: 3
Training loss: 2.9843912973008875
Validation loss: 2.6686386977407697

Epoch: 6| Step: 4
Training loss: 3.067375506149767
Validation loss: 2.685691995139705

Epoch: 6| Step: 5
Training loss: 2.9587745516571857
Validation loss: 2.6951512822793053

Epoch: 6| Step: 6
Training loss: 3.7326266613348453
Validation loss: 2.726446382735771

Epoch: 6| Step: 7
Training loss: 2.7773878735177373
Validation loss: 2.724962253766351

Epoch: 6| Step: 8
Training loss: 3.008025719157304
Validation loss: 2.70091977307796

Epoch: 6| Step: 9
Training loss: 3.0585011435334004
Validation loss: 2.67518194517319

Epoch: 6| Step: 10
Training loss: 3.5077603002797595
Validation loss: 2.659279281019363

Epoch: 6| Step: 11
Training loss: 2.6368747241193433
Validation loss: 2.662175792077764

Epoch: 6| Step: 12
Training loss: 2.4131106379629186
Validation loss: 2.6614213129411604

Epoch: 6| Step: 13
Training loss: 2.7480979757431223
Validation loss: 2.6649126315442975

Epoch: 138| Step: 0
Training loss: 3.322578787691127
Validation loss: 2.6672976488217945

Epoch: 6| Step: 1
Training loss: 2.8351811012404577
Validation loss: 2.6686795646446764

Epoch: 6| Step: 2
Training loss: 2.5776718203739213
Validation loss: 2.6722131359366648

Epoch: 6| Step: 3
Training loss: 3.146643191212301
Validation loss: 2.66967577816198

Epoch: 6| Step: 4
Training loss: 3.341529179992625
Validation loss: 2.6672152684274537

Epoch: 6| Step: 5
Training loss: 3.2613688938024783
Validation loss: 2.664624782828266

Epoch: 6| Step: 6
Training loss: 2.747308454284112
Validation loss: 2.659623588244553

Epoch: 6| Step: 7
Training loss: 2.893386264293424
Validation loss: 2.658290112887577

Epoch: 6| Step: 8
Training loss: 3.1319138910044293
Validation loss: 2.655537094971895

Epoch: 6| Step: 9
Training loss: 2.9967250432434147
Validation loss: 2.6539505069729454

Epoch: 6| Step: 10
Training loss: 3.1173753418888777
Validation loss: 2.659496711386727

Epoch: 6| Step: 11
Training loss: 3.1430486181068997
Validation loss: 2.6751647320407064

Epoch: 6| Step: 12
Training loss: 2.617515247377074
Validation loss: 2.6941012321191087

Epoch: 6| Step: 13
Training loss: 2.824102755495308
Validation loss: 2.7064740319925633

Epoch: 139| Step: 0
Training loss: 3.1571693214633973
Validation loss: 2.6818211800041043

Epoch: 6| Step: 1
Training loss: 3.471116779258725
Validation loss: 2.67374823259953

Epoch: 6| Step: 2
Training loss: 3.251315950856281
Validation loss: 2.6527793732297424

Epoch: 6| Step: 3
Training loss: 2.9666170187521184
Validation loss: 2.6527496824183574

Epoch: 6| Step: 4
Training loss: 2.667382283352807
Validation loss: 2.6530880962275862

Epoch: 6| Step: 5
Training loss: 2.8395626553412057
Validation loss: 2.6600450134077054

Epoch: 6| Step: 6
Training loss: 3.4935891157036187
Validation loss: 2.6567109356493614

Epoch: 6| Step: 7
Training loss: 3.1737313687174677
Validation loss: 2.655241084689855

Epoch: 6| Step: 8
Training loss: 2.5807817122072203
Validation loss: 2.65390094830678

Epoch: 6| Step: 9
Training loss: 2.8672703203510164
Validation loss: 2.656346669087818

Epoch: 6| Step: 10
Training loss: 2.5891704345747737
Validation loss: 2.6537966744461396

Epoch: 6| Step: 11
Training loss: 2.7918187474821363
Validation loss: 2.660891189737264

Epoch: 6| Step: 12
Training loss: 3.143870029471166
Validation loss: 2.671267628666729

Epoch: 6| Step: 13
Training loss: 2.365697309832614
Validation loss: 2.6855843850477923

Epoch: 140| Step: 0
Training loss: 2.691588463449323
Validation loss: 2.682972395946314

Epoch: 6| Step: 1
Training loss: 3.0157821693377502
Validation loss: 2.698472555873728

Epoch: 6| Step: 2
Training loss: 2.8110452916511086
Validation loss: 2.6973353117603733

Epoch: 6| Step: 3
Training loss: 3.645688313824315
Validation loss: 2.672183105573815

Epoch: 6| Step: 4
Training loss: 2.030690981895728
Validation loss: 2.6688828725374933

Epoch: 6| Step: 5
Training loss: 3.3247646506632322
Validation loss: 2.670218110792297

Epoch: 6| Step: 6
Training loss: 2.9522421188204073
Validation loss: 2.654840048587776

Epoch: 6| Step: 7
Training loss: 2.59374586357798
Validation loss: 2.651624433750222

Epoch: 6| Step: 8
Training loss: 3.598519121338413
Validation loss: 2.666011521849626

Epoch: 6| Step: 9
Training loss: 2.7850585749166124
Validation loss: 2.6550489177306535

Epoch: 6| Step: 10
Training loss: 2.5625518235339397
Validation loss: 2.658249460451075

Epoch: 6| Step: 11
Training loss: 3.172545413871356
Validation loss: 2.6514546317097802

Epoch: 6| Step: 12
Training loss: 2.851769677565893
Validation loss: 2.6525858807337555

Epoch: 6| Step: 13
Training loss: 3.5598806824137323
Validation loss: 2.65235181107067

Epoch: 141| Step: 0
Training loss: 2.990358436049064
Validation loss: 2.649512689764936

Epoch: 6| Step: 1
Training loss: 2.6789509731418755
Validation loss: 2.6491714425172264

Epoch: 6| Step: 2
Training loss: 3.1276906446475365
Validation loss: 2.652928030066233

Epoch: 6| Step: 3
Training loss: 2.943034700283079
Validation loss: 2.6544472692996637

Epoch: 6| Step: 4
Training loss: 2.627694881046583
Validation loss: 2.6492252159102043

Epoch: 6| Step: 5
Training loss: 3.146165960717961
Validation loss: 2.650809295589977

Epoch: 6| Step: 6
Training loss: 2.791651104176733
Validation loss: 2.6535279921674357

Epoch: 6| Step: 7
Training loss: 3.417469969187061
Validation loss: 2.657826210178512

Epoch: 6| Step: 8
Training loss: 2.213952909676963
Validation loss: 2.6493497871957805

Epoch: 6| Step: 9
Training loss: 2.9301041370412504
Validation loss: 2.650910550723148

Epoch: 6| Step: 10
Training loss: 2.903261678740678
Validation loss: 2.649796297804242

Epoch: 6| Step: 11
Training loss: 3.2631452718856524
Validation loss: 2.651285231678857

Epoch: 6| Step: 12
Training loss: 3.253811581849918
Validation loss: 2.650035298136185

Epoch: 6| Step: 13
Training loss: 3.3595749906404553
Validation loss: 2.656819476875573

Epoch: 142| Step: 0
Training loss: 3.180172145190709
Validation loss: 2.659310675626436

Epoch: 6| Step: 1
Training loss: 3.5751817083529756
Validation loss: 2.6661614111137757

Epoch: 6| Step: 2
Training loss: 2.1470088023061704
Validation loss: 2.658671804441136

Epoch: 6| Step: 3
Training loss: 3.081511827219942
Validation loss: 2.6669129035561103

Epoch: 6| Step: 4
Training loss: 2.4161000957848504
Validation loss: 2.657701898259244

Epoch: 6| Step: 5
Training loss: 3.4773115744095264
Validation loss: 2.668322886836685

Epoch: 6| Step: 6
Training loss: 2.8846204923926884
Validation loss: 2.6537391874574854

Epoch: 6| Step: 7
Training loss: 3.1817450836999694
Validation loss: 2.662740059983464

Epoch: 6| Step: 8
Training loss: 2.213986185356398
Validation loss: 2.652889032974318

Epoch: 6| Step: 9
Training loss: 2.3098853511350264
Validation loss: 2.661799450386349

Epoch: 6| Step: 10
Training loss: 4.035263783886005
Validation loss: 2.6590227078458066

Epoch: 6| Step: 11
Training loss: 2.411567361452809
Validation loss: 2.6692101051431596

Epoch: 6| Step: 12
Training loss: 2.7503827435565156
Validation loss: 2.671820236476709

Epoch: 6| Step: 13
Training loss: 3.400394831900758
Validation loss: 2.6614345500268604

Epoch: 143| Step: 0
Training loss: 2.7230310168452307
Validation loss: 2.660404100957837

Epoch: 6| Step: 1
Training loss: 2.7477190788749812
Validation loss: 2.653235001380872

Epoch: 6| Step: 2
Training loss: 3.0787018366154424
Validation loss: 2.6508375197591505

Epoch: 6| Step: 3
Training loss: 2.8578460441109876
Validation loss: 2.6442867820469953

Epoch: 6| Step: 4
Training loss: 2.9792135452814845
Validation loss: 2.6412105931590015

Epoch: 6| Step: 5
Training loss: 2.577147142323945
Validation loss: 2.6438322056564942

Epoch: 6| Step: 6
Training loss: 3.2043936845366
Validation loss: 2.644181870182556

Epoch: 6| Step: 7
Training loss: 2.9414652581647527
Validation loss: 2.643295184614842

Epoch: 6| Step: 8
Training loss: 3.2009758415037477
Validation loss: 2.643554741807132

Epoch: 6| Step: 9
Training loss: 3.228800073959758
Validation loss: 2.641975068872793

Epoch: 6| Step: 10
Training loss: 2.9379455553155736
Validation loss: 2.6421423926772634

Epoch: 6| Step: 11
Training loss: 2.9271194799686957
Validation loss: 2.6441527256433415

Epoch: 6| Step: 12
Training loss: 3.1660097511608836
Validation loss: 2.641285741246708

Epoch: 6| Step: 13
Training loss: 2.9928194578850085
Validation loss: 2.6420192165200818

Epoch: 144| Step: 0
Training loss: 2.7299942237317807
Validation loss: 2.6461926824163577

Epoch: 6| Step: 1
Training loss: 2.8234547363836
Validation loss: 2.6468462611503667

Epoch: 6| Step: 2
Training loss: 2.7930950856479453
Validation loss: 2.654736574505183

Epoch: 6| Step: 3
Training loss: 2.467199103996718
Validation loss: 2.657604444050796

Epoch: 6| Step: 4
Training loss: 3.1636480366083917
Validation loss: 2.6720330244923276

Epoch: 6| Step: 5
Training loss: 3.4072814219752376
Validation loss: 2.6733793720149905

Epoch: 6| Step: 6
Training loss: 2.9074294455472107
Validation loss: 2.7018690556563527

Epoch: 6| Step: 7
Training loss: 3.051922026831834
Validation loss: 2.6768317126889425

Epoch: 6| Step: 8
Training loss: 2.95430316331722
Validation loss: 2.6602790768867046

Epoch: 6| Step: 9
Training loss: 3.0263881430280457
Validation loss: 2.6466001094429727

Epoch: 6| Step: 10
Training loss: 3.349201927205097
Validation loss: 2.640898888680789

Epoch: 6| Step: 11
Training loss: 2.9235645651918998
Validation loss: 2.643107091918737

Epoch: 6| Step: 12
Training loss: 3.0096886270366685
Validation loss: 2.6354987777635004

Epoch: 6| Step: 13
Training loss: 2.8930637279127898
Validation loss: 2.639411293469045

Epoch: 145| Step: 0
Training loss: 3.0363822041952515
Validation loss: 2.638867451512887

Epoch: 6| Step: 1
Training loss: 3.107411747214011
Validation loss: 2.6364672245450986

Epoch: 6| Step: 2
Training loss: 3.116882003308176
Validation loss: 2.6388400581892264

Epoch: 6| Step: 3
Training loss: 3.172072080305523
Validation loss: 2.6371021561086176

Epoch: 6| Step: 4
Training loss: 2.736422834588431
Validation loss: 2.635932673078774

Epoch: 6| Step: 5
Training loss: 3.0277806514372494
Validation loss: 2.6397918801443945

Epoch: 6| Step: 6
Training loss: 2.7167735314754675
Validation loss: 2.6416593912612614

Epoch: 6| Step: 7
Training loss: 2.44457743263692
Validation loss: 2.640278376434144

Epoch: 6| Step: 8
Training loss: 3.2178210056707837
Validation loss: 2.637540544537385

Epoch: 6| Step: 9
Training loss: 3.039827304502466
Validation loss: 2.643563313592116

Epoch: 6| Step: 10
Training loss: 2.874920056102342
Validation loss: 2.643736455952435

Epoch: 6| Step: 11
Training loss: 2.67708886488604
Validation loss: 2.6464430103596768

Epoch: 6| Step: 12
Training loss: 3.2562512652198836
Validation loss: 2.6413432624538626

Epoch: 6| Step: 13
Training loss: 3.0687647988143203
Validation loss: 2.6391181770268943

Epoch: 146| Step: 0
Training loss: 3.596931442493998
Validation loss: 2.638543953738371

Epoch: 6| Step: 1
Training loss: 3.21768822795942
Validation loss: 2.6422003706659725

Epoch: 6| Step: 2
Training loss: 3.2417812598468663
Validation loss: 2.6412736989442123

Epoch: 6| Step: 3
Training loss: 2.826469990917665
Validation loss: 2.6356036189500984

Epoch: 6| Step: 4
Training loss: 3.4948268534238713
Validation loss: 2.636433497425955

Epoch: 6| Step: 5
Training loss: 2.5414662412404754
Validation loss: 2.63731537346552

Epoch: 6| Step: 6
Training loss: 2.732137233040913
Validation loss: 2.6353037499219565

Epoch: 6| Step: 7
Training loss: 2.819943813413545
Validation loss: 2.6354110424586956

Epoch: 6| Step: 8
Training loss: 2.5963662063385806
Validation loss: 2.6384833555531486

Epoch: 6| Step: 9
Training loss: 2.9917337656244483
Validation loss: 2.6414038862607065

Epoch: 6| Step: 10
Training loss: 2.665467459527787
Validation loss: 2.6516192960695757

Epoch: 6| Step: 11
Training loss: 3.096024572969844
Validation loss: 2.6563065428147676

Epoch: 6| Step: 12
Training loss: 2.8596888302206023
Validation loss: 2.672371945297672

Epoch: 6| Step: 13
Training loss: 2.2216438441476747
Validation loss: 2.6786737771899247

Epoch: 147| Step: 0
Training loss: 2.9626596721643286
Validation loss: 2.671767032027168

Epoch: 6| Step: 1
Training loss: 3.0235688725596805
Validation loss: 2.6658173203183972

Epoch: 6| Step: 2
Training loss: 3.1933548953523627
Validation loss: 2.6454677127304995

Epoch: 6| Step: 3
Training loss: 3.2846510926265773
Validation loss: 2.6368191617367516

Epoch: 6| Step: 4
Training loss: 2.524090472792873
Validation loss: 2.6314672075532415

Epoch: 6| Step: 5
Training loss: 3.3473183673928517
Validation loss: 2.632866469239938

Epoch: 6| Step: 6
Training loss: 2.742245752308178
Validation loss: 2.633424792084567

Epoch: 6| Step: 7
Training loss: 3.5164064344208183
Validation loss: 2.6348051150928233

Epoch: 6| Step: 8
Training loss: 2.960682558543448
Validation loss: 2.640841050061517

Epoch: 6| Step: 9
Training loss: 3.1487388750571075
Validation loss: 2.6359859822602467

Epoch: 6| Step: 10
Training loss: 2.637563341293152
Validation loss: 2.633054223449024

Epoch: 6| Step: 11
Training loss: 2.6397562798794674
Validation loss: 2.630336240235016

Epoch: 6| Step: 12
Training loss: 2.8692524721328256
Validation loss: 2.6346088049781353

Epoch: 6| Step: 13
Training loss: 2.246452289657956
Validation loss: 2.6268645567792026

Epoch: 148| Step: 0
Training loss: 2.3289129984596957
Validation loss: 2.629847527977625

Epoch: 6| Step: 1
Training loss: 2.6898732906406853
Validation loss: 2.6299973893757964

Epoch: 6| Step: 2
Training loss: 3.1225124376597515
Validation loss: 2.6380853014112384

Epoch: 6| Step: 3
Training loss: 2.963859304200801
Validation loss: 2.6394581763747667

Epoch: 6| Step: 4
Training loss: 3.2359431054450334
Validation loss: 2.6427274536474323

Epoch: 6| Step: 5
Training loss: 2.921189498046317
Validation loss: 2.6534643324389937

Epoch: 6| Step: 6
Training loss: 3.3791517929207635
Validation loss: 2.685328087449654

Epoch: 6| Step: 7
Training loss: 3.0589981298974047
Validation loss: 2.6961362926000825

Epoch: 6| Step: 8
Training loss: 2.8225154990487837
Validation loss: 2.687023745455907

Epoch: 6| Step: 9
Training loss: 3.212323337551123
Validation loss: 2.718687097078473

Epoch: 6| Step: 10
Training loss: 2.809209466964802
Validation loss: 2.661463096904487

Epoch: 6| Step: 11
Training loss: 2.7358738742055166
Validation loss: 2.640797181719312

Epoch: 6| Step: 12
Training loss: 2.8562060864033976
Validation loss: 2.6340050727508295

Epoch: 6| Step: 13
Training loss: 3.4100003376174715
Validation loss: 2.63130528348555

Epoch: 149| Step: 0
Training loss: 2.970253975024267
Validation loss: 2.632198183807488

Epoch: 6| Step: 1
Training loss: 2.7348260997879814
Validation loss: 2.6491696135368907

Epoch: 6| Step: 2
Training loss: 3.223365363507928
Validation loss: 2.656228622167122

Epoch: 6| Step: 3
Training loss: 3.015745961031375
Validation loss: 2.647328131267159

Epoch: 6| Step: 4
Training loss: 3.3018102362464203
Validation loss: 2.632227150995712

Epoch: 6| Step: 5
Training loss: 3.1522569230801043
Validation loss: 2.6312467409859606

Epoch: 6| Step: 6
Training loss: 3.1435781989354528
Validation loss: 2.6337153036877465

Epoch: 6| Step: 7
Training loss: 3.082099323947199
Validation loss: 2.636785021047464

Epoch: 6| Step: 8
Training loss: 2.489186935044296
Validation loss: 2.6400651866864098

Epoch: 6| Step: 9
Training loss: 2.7157337513735786
Validation loss: 2.663553389608642

Epoch: 6| Step: 10
Training loss: 2.493109935945457
Validation loss: 2.691016717746445

Epoch: 6| Step: 11
Training loss: 3.2215535814778122
Validation loss: 2.7123167694841874

Epoch: 6| Step: 12
Training loss: 3.076037323446251
Validation loss: 2.718629071737306

Epoch: 6| Step: 13
Training loss: 2.6269905172756993
Validation loss: 2.707164434224983

Epoch: 150| Step: 0
Training loss: 3.2360402119027754
Validation loss: 2.719355006564575

Epoch: 6| Step: 1
Training loss: 2.823577174841583
Validation loss: 2.723571292136497

Epoch: 6| Step: 2
Training loss: 2.806404119732572
Validation loss: 2.7091199302121205

Epoch: 6| Step: 3
Training loss: 2.4441103189109694
Validation loss: 2.6898988852447

Epoch: 6| Step: 4
Training loss: 3.349201642458349
Validation loss: 2.6947865952015944

Epoch: 6| Step: 5
Training loss: 3.213215189485894
Validation loss: 2.701736166438919

Epoch: 6| Step: 6
Training loss: 3.637119684951422
Validation loss: 2.6846623550996007

Epoch: 6| Step: 7
Training loss: 2.849519515107763
Validation loss: 2.6744500329263605

Epoch: 6| Step: 8
Training loss: 3.159631560612078
Validation loss: 2.6380693913680617

Epoch: 6| Step: 9
Training loss: 2.627167034303139
Validation loss: 2.6293596647901776

Epoch: 6| Step: 10
Training loss: 3.0737530793077235
Validation loss: 2.624651491671455

Epoch: 6| Step: 11
Training loss: 2.779564078616028
Validation loss: 2.627401338592036

Epoch: 6| Step: 12
Training loss: 2.539195083677824
Validation loss: 2.628081525328634

Epoch: 6| Step: 13
Training loss: 2.756822532650947
Validation loss: 2.6283148458555297

Epoch: 151| Step: 0
Training loss: 2.7698984696272637
Validation loss: 2.629267515387621

Epoch: 6| Step: 1
Training loss: 2.87864735654309
Validation loss: 2.6310212612266417

Epoch: 6| Step: 2
Training loss: 2.974692410507982
Validation loss: 2.629173059629455

Epoch: 6| Step: 3
Training loss: 3.24442811320243
Validation loss: 2.628073986809355

Epoch: 6| Step: 4
Training loss: 2.8180857821011696
Validation loss: 2.6241090808653698

Epoch: 6| Step: 5
Training loss: 3.270884535726862
Validation loss: 2.6268537229380335

Epoch: 6| Step: 6
Training loss: 2.9590046796951857
Validation loss: 2.6237724264102447

Epoch: 6| Step: 7
Training loss: 3.2058617786255765
Validation loss: 2.625813136068703

Epoch: 6| Step: 8
Training loss: 2.604705653044402
Validation loss: 2.6241603451842477

Epoch: 6| Step: 9
Training loss: 2.8066639006624463
Validation loss: 2.6339176789650236

Epoch: 6| Step: 10
Training loss: 3.3585480847729325
Validation loss: 2.63068261749394

Epoch: 6| Step: 11
Training loss: 2.798183028740097
Validation loss: 2.634468705465033

Epoch: 6| Step: 12
Training loss: 2.7384654811642815
Validation loss: 2.640373296137403

Epoch: 6| Step: 13
Training loss: 3.052135601615999
Validation loss: 2.6418648891494745

Epoch: 152| Step: 0
Training loss: 2.5745416881499934
Validation loss: 2.6333166699669532

Epoch: 6| Step: 1
Training loss: 2.760758595912063
Validation loss: 2.6309866194876177

Epoch: 6| Step: 2
Training loss: 2.844450811869064
Validation loss: 2.63164723229449

Epoch: 6| Step: 3
Training loss: 2.74849798624993
Validation loss: 2.633351500097903

Epoch: 6| Step: 4
Training loss: 3.1437471727240953
Validation loss: 2.6378702880913947

Epoch: 6| Step: 5
Training loss: 3.328622556933405
Validation loss: 2.643239180111837

Epoch: 6| Step: 6
Training loss: 2.981284733535955
Validation loss: 2.634622571839037

Epoch: 6| Step: 7
Training loss: 2.769542613362619
Validation loss: 2.639479013062372

Epoch: 6| Step: 8
Training loss: 3.0025077510990967
Validation loss: 2.6471556218608034

Epoch: 6| Step: 9
Training loss: 3.39335121917008
Validation loss: 2.6512514856508225

Epoch: 6| Step: 10
Training loss: 3.1465463567083436
Validation loss: 2.648664021403699

Epoch: 6| Step: 11
Training loss: 2.6542589691576826
Validation loss: 2.644606612962906

Epoch: 6| Step: 12
Training loss: 2.980904363593394
Validation loss: 2.6436172243330813

Epoch: 6| Step: 13
Training loss: 2.8933824738344875
Validation loss: 2.631221155574549

Epoch: 153| Step: 0
Training loss: 2.470078316192132
Validation loss: 2.637896176371215

Epoch: 6| Step: 1
Training loss: 3.175789057685667
Validation loss: 2.633987859155874

Epoch: 6| Step: 2
Training loss: 2.9449522572195033
Validation loss: 2.6328567185195113

Epoch: 6| Step: 3
Training loss: 2.9063376136617305
Validation loss: 2.6432432158043393

Epoch: 6| Step: 4
Training loss: 3.094377550383341
Validation loss: 2.636422506482875

Epoch: 6| Step: 5
Training loss: 3.0343897967463955
Validation loss: 2.6406768077261455

Epoch: 6| Step: 6
Training loss: 3.4478772363780283
Validation loss: 2.6258490415502984

Epoch: 6| Step: 7
Training loss: 3.0875746621436577
Validation loss: 2.636465370221113

Epoch: 6| Step: 8
Training loss: 2.2436492089715587
Validation loss: 2.6360375436900862

Epoch: 6| Step: 9
Training loss: 3.1911776401251877
Validation loss: 2.633098079616541

Epoch: 6| Step: 10
Training loss: 2.9939778601592937
Validation loss: 2.6337949873719717

Epoch: 6| Step: 11
Training loss: 2.82562718813853
Validation loss: 2.631887135083894

Epoch: 6| Step: 12
Training loss: 2.6579046144843623
Validation loss: 2.639649754454101

Epoch: 6| Step: 13
Training loss: 3.011355842069874
Validation loss: 2.633509742271419

Epoch: 154| Step: 0
Training loss: 2.8458103638853496
Validation loss: 2.627706142643452

Epoch: 6| Step: 1
Training loss: 3.4624860412095946
Validation loss: 2.630557826866905

Epoch: 6| Step: 2
Training loss: 3.3469348606487372
Validation loss: 2.6324273608513886

Epoch: 6| Step: 3
Training loss: 2.4715547684565324
Validation loss: 2.637623538788607

Epoch: 6| Step: 4
Training loss: 2.775151112883913
Validation loss: 2.6384954543143313

Epoch: 6| Step: 5
Training loss: 3.1870489362317667
Validation loss: 2.640882651942128

Epoch: 6| Step: 6
Training loss: 3.0879272227136245
Validation loss: 2.6445727569928463

Epoch: 6| Step: 7
Training loss: 2.9762805394668987
Validation loss: 2.65687116855341

Epoch: 6| Step: 8
Training loss: 2.845464336401686
Validation loss: 2.6797763887810238

Epoch: 6| Step: 9
Training loss: 2.941186742203672
Validation loss: 2.6754620421468975

Epoch: 6| Step: 10
Training loss: 2.8352996697393595
Validation loss: 2.682402251501068

Epoch: 6| Step: 11
Training loss: 2.4238646179452163
Validation loss: 2.6532264453824705

Epoch: 6| Step: 12
Training loss: 3.030482244105043
Validation loss: 2.6349126731174013

Epoch: 6| Step: 13
Training loss: 2.974654419646222
Validation loss: 2.625589061453933

Epoch: 155| Step: 0
Training loss: 3.103346150826257
Validation loss: 2.6198748271987076

Epoch: 6| Step: 1
Training loss: 2.168712261652138
Validation loss: 2.620951556715043

Epoch: 6| Step: 2
Training loss: 3.2270276932735324
Validation loss: 2.620892345710245

Epoch: 6| Step: 3
Training loss: 2.7669655519691045
Validation loss: 2.6242059238072777

Epoch: 6| Step: 4
Training loss: 2.9760860352129033
Validation loss: 2.6278476455729924

Epoch: 6| Step: 5
Training loss: 3.031582686267884
Validation loss: 2.6245877547242378

Epoch: 6| Step: 6
Training loss: 3.2105189883697336
Validation loss: 2.625002844907095

Epoch: 6| Step: 7
Training loss: 2.923255798140961
Validation loss: 2.618401251989083

Epoch: 6| Step: 8
Training loss: 3.171950766875247
Validation loss: 2.621115782148315

Epoch: 6| Step: 9
Training loss: 2.660158580269262
Validation loss: 2.617850702871227

Epoch: 6| Step: 10
Training loss: 2.718102564400053
Validation loss: 2.627227631990818

Epoch: 6| Step: 11
Training loss: 2.7334605404475996
Validation loss: 2.6354432301461563

Epoch: 6| Step: 12
Training loss: 3.31351268331513
Validation loss: 2.6342645273517724

Epoch: 6| Step: 13
Training loss: 3.4102407053903354
Validation loss: 2.642291211351179

Epoch: 156| Step: 0
Training loss: 3.2559730221617196
Validation loss: 2.637445869895382

Epoch: 6| Step: 1
Training loss: 2.880546030363763
Validation loss: 2.6378380396355356

Epoch: 6| Step: 2
Training loss: 2.78614068523248
Validation loss: 2.627577064073801

Epoch: 6| Step: 3
Training loss: 2.8077841322648784
Validation loss: 2.6277166129681353

Epoch: 6| Step: 4
Training loss: 2.9873016546956657
Validation loss: 2.627428776531955

Epoch: 6| Step: 5
Training loss: 2.754179812432185
Validation loss: 2.6241093094731998

Epoch: 6| Step: 6
Training loss: 3.180711436072595
Validation loss: 2.624072632316117

Epoch: 6| Step: 7
Training loss: 3.044950063010963
Validation loss: 2.6250951137392233

Epoch: 6| Step: 8
Training loss: 3.0198642798741573
Validation loss: 2.6235614473737696

Epoch: 6| Step: 9
Training loss: 3.1571604104962705
Validation loss: 2.621566316866024

Epoch: 6| Step: 10
Training loss: 2.6152124952408116
Validation loss: 2.621111546113936

Epoch: 6| Step: 11
Training loss: 3.135949445472702
Validation loss: 2.6160479231085647

Epoch: 6| Step: 12
Training loss: 2.6604091619287646
Validation loss: 2.617585801714944

Epoch: 6| Step: 13
Training loss: 2.850275454678285
Validation loss: 2.6270071033647637

Epoch: 157| Step: 0
Training loss: 2.9899278679251626
Validation loss: 2.633568365881391

Epoch: 6| Step: 1
Training loss: 2.9998027418770956
Validation loss: 2.6350631395684574

Epoch: 6| Step: 2
Training loss: 3.039863225972048
Validation loss: 2.629666182863032

Epoch: 6| Step: 3
Training loss: 2.7008983283229573
Validation loss: 2.6342464580658542

Epoch: 6| Step: 4
Training loss: 2.7654254216311385
Validation loss: 2.6294657764183516

Epoch: 6| Step: 5
Training loss: 3.0451060319551453
Validation loss: 2.634539014994517

Epoch: 6| Step: 6
Training loss: 3.1094081244309733
Validation loss: 2.6420903662607502

Epoch: 6| Step: 7
Training loss: 2.815868987796326
Validation loss: 2.6291116681975466

Epoch: 6| Step: 8
Training loss: 2.616325942612709
Validation loss: 2.6329651487051

Epoch: 6| Step: 9
Training loss: 2.4757902945115244
Validation loss: 2.6406088091489894

Epoch: 6| Step: 10
Training loss: 2.286673174404897
Validation loss: 2.635351896594584

Epoch: 6| Step: 11
Training loss: 3.7174836895808707
Validation loss: 2.652676606410474

Epoch: 6| Step: 12
Training loss: 3.178215117100541
Validation loss: 2.6431042761975156

Epoch: 6| Step: 13
Training loss: 3.3951105077901986
Validation loss: 2.6313619979387703

Epoch: 158| Step: 0
Training loss: 2.834636463357256
Validation loss: 2.623306763531855

Epoch: 6| Step: 1
Training loss: 2.4261856601994762
Validation loss: 2.610953564022893

Epoch: 6| Step: 2
Training loss: 2.818227234807243
Validation loss: 2.6113791768520844

Epoch: 6| Step: 3
Training loss: 2.6834713215227506
Validation loss: 2.6097412323953844

Epoch: 6| Step: 4
Training loss: 2.96495874154267
Validation loss: 2.6080709780979814

Epoch: 6| Step: 5
Training loss: 3.5361359139813104
Validation loss: 2.6078534994856373

Epoch: 6| Step: 6
Training loss: 2.480759875416958
Validation loss: 2.607765461291575

Epoch: 6| Step: 7
Training loss: 3.053123912986788
Validation loss: 2.6071470919526654

Epoch: 6| Step: 8
Training loss: 2.871376739880056
Validation loss: 2.6061641043620445

Epoch: 6| Step: 9
Training loss: 2.9858132935885195
Validation loss: 2.609181688317831

Epoch: 6| Step: 10
Training loss: 3.3362585266164397
Validation loss: 2.6092676704708535

Epoch: 6| Step: 11
Training loss: 2.4797979454053554
Validation loss: 2.6090489194146254

Epoch: 6| Step: 12
Training loss: 3.070845928882318
Validation loss: 2.612330114704534

Epoch: 6| Step: 13
Training loss: 3.7178907924494067
Validation loss: 2.6160329070311255

Epoch: 159| Step: 0
Training loss: 2.633525084101404
Validation loss: 2.617183301686896

Epoch: 6| Step: 1
Training loss: 2.998412665999295
Validation loss: 2.6208835462073163

Epoch: 6| Step: 2
Training loss: 2.607752038290218
Validation loss: 2.6332460454656723

Epoch: 6| Step: 3
Training loss: 3.305588186906163
Validation loss: 2.633402361561537

Epoch: 6| Step: 4
Training loss: 2.4203540579255245
Validation loss: 2.63980887186043

Epoch: 6| Step: 5
Training loss: 3.047040885908883
Validation loss: 2.6389246349004156

Epoch: 6| Step: 6
Training loss: 2.7072570618524936
Validation loss: 2.636127561030647

Epoch: 6| Step: 7
Training loss: 3.1524692968919905
Validation loss: 2.6267591364634986

Epoch: 6| Step: 8
Training loss: 2.5681247850623636
Validation loss: 2.620894136712614

Epoch: 6| Step: 9
Training loss: 3.091804277865427
Validation loss: 2.631045862508702

Epoch: 6| Step: 10
Training loss: 3.101033432274392
Validation loss: 2.630832774332351

Epoch: 6| Step: 11
Training loss: 3.125235891975702
Validation loss: 2.633299018643557

Epoch: 6| Step: 12
Training loss: 2.9371925355421844
Validation loss: 2.6253829711847607

Epoch: 6| Step: 13
Training loss: 3.4470794368097697
Validation loss: 2.6255472289629544

Epoch: 160| Step: 0
Training loss: 2.898341586024633
Validation loss: 2.6162041193055914

Epoch: 6| Step: 1
Training loss: 2.8469076546262837
Validation loss: 2.614161043309311

Epoch: 6| Step: 2
Training loss: 3.110919051448547
Validation loss: 2.6134557815473856

Epoch: 6| Step: 3
Training loss: 2.632093201132095
Validation loss: 2.608851157627025

Epoch: 6| Step: 4
Training loss: 2.8006773946705383
Validation loss: 2.6046461160313856

Epoch: 6| Step: 5
Training loss: 3.3370676739317693
Validation loss: 2.6037119370368114

Epoch: 6| Step: 6
Training loss: 2.7261678415518147
Validation loss: 2.6076416129507876

Epoch: 6| Step: 7
Training loss: 2.691739309490038
Validation loss: 2.6089365709168213

Epoch: 6| Step: 8
Training loss: 3.1349682323543715
Validation loss: 2.609257468031025

Epoch: 6| Step: 9
Training loss: 2.926159170925483
Validation loss: 2.611582861863369

Epoch: 6| Step: 10
Training loss: 2.6375385733581505
Validation loss: 2.6119486727935484

Epoch: 6| Step: 11
Training loss: 2.3577353735987727
Validation loss: 2.6204056954857395

Epoch: 6| Step: 12
Training loss: 3.375074880263799
Validation loss: 2.6216542680918105

Epoch: 6| Step: 13
Training loss: 3.6477512800690124
Validation loss: 2.618622542563521

Epoch: 161| Step: 0
Training loss: 2.9563303511105556
Validation loss: 2.623607164406953

Epoch: 6| Step: 1
Training loss: 3.244451040612516
Validation loss: 2.636620308251076

Epoch: 6| Step: 2
Training loss: 2.9877574985254607
Validation loss: 2.630659291390709

Epoch: 6| Step: 3
Training loss: 3.436556877457009
Validation loss: 2.63796180364516

Epoch: 6| Step: 4
Training loss: 3.1872323615713913
Validation loss: 2.619920512667787

Epoch: 6| Step: 5
Training loss: 2.6872276345565362
Validation loss: 2.6093381943347294

Epoch: 6| Step: 6
Training loss: 2.7762688596892984
Validation loss: 2.6044425677099627

Epoch: 6| Step: 7
Training loss: 2.7454909725287417
Validation loss: 2.603871317860829

Epoch: 6| Step: 8
Training loss: 2.2931128591453653
Validation loss: 2.611494675014507

Epoch: 6| Step: 9
Training loss: 2.9484441889538924
Validation loss: 2.6101175476963316

Epoch: 6| Step: 10
Training loss: 2.9809211597580636
Validation loss: 2.611727589254764

Epoch: 6| Step: 11
Training loss: 2.7686519975733663
Validation loss: 2.6123650568343506

Epoch: 6| Step: 12
Training loss: 2.678776622360454
Validation loss: 2.6130807397053366

Epoch: 6| Step: 13
Training loss: 3.422371466865389
Validation loss: 2.6220086178816513

Epoch: 162| Step: 0
Training loss: 2.772509696400011
Validation loss: 2.6325568199797793

Epoch: 6| Step: 1
Training loss: 2.7818613130622283
Validation loss: 2.6368513545969083

Epoch: 6| Step: 2
Training loss: 2.9997885947444995
Validation loss: 2.640287159846841

Epoch: 6| Step: 3
Training loss: 2.8860442285882724
Validation loss: 2.625408230713624

Epoch: 6| Step: 4
Training loss: 2.7373392658859954
Validation loss: 2.6368150277374673

Epoch: 6| Step: 5
Training loss: 3.3068883614927156
Validation loss: 2.614986838761722

Epoch: 6| Step: 6
Training loss: 2.485036126225335
Validation loss: 2.6227099014104236

Epoch: 6| Step: 7
Training loss: 2.755244888803504
Validation loss: 2.6173942277344504

Epoch: 6| Step: 8
Training loss: 3.1680900653983284
Validation loss: 2.6214644475872206

Epoch: 6| Step: 9
Training loss: 2.9692038741248745
Validation loss: 2.6362893289400113

Epoch: 6| Step: 10
Training loss: 2.643046155084181
Validation loss: 2.635645814157204

Epoch: 6| Step: 11
Training loss: 3.0949703083247213
Validation loss: 2.61885997930804

Epoch: 6| Step: 12
Training loss: 3.5714878676805353
Validation loss: 2.6311959333376906

Epoch: 6| Step: 13
Training loss: 2.326919653272202
Validation loss: 2.639239235033868

Epoch: 163| Step: 0
Training loss: 3.0936482730671195
Validation loss: 2.638513818052392

Epoch: 6| Step: 1
Training loss: 2.3013129923257853
Validation loss: 2.6445393600893286

Epoch: 6| Step: 2
Training loss: 3.2400714633266006
Validation loss: 2.6468480084396773

Epoch: 6| Step: 3
Training loss: 3.1290243557512105
Validation loss: 2.644970347540689

Epoch: 6| Step: 4
Training loss: 3.5594591246351923
Validation loss: 2.645032180197095

Epoch: 6| Step: 5
Training loss: 3.0096756354165346
Validation loss: 2.6442492116486753

Epoch: 6| Step: 6
Training loss: 3.48441441261342
Validation loss: 2.6462643835580804

Epoch: 6| Step: 7
Training loss: 2.9252365277505565
Validation loss: 2.649615370307258

Epoch: 6| Step: 8
Training loss: 2.237910960726465
Validation loss: 2.6575854077094005

Epoch: 6| Step: 9
Training loss: 3.056644057006859
Validation loss: 2.6755523792143925

Epoch: 6| Step: 10
Training loss: 2.235454911908869
Validation loss: 2.667126589639583

Epoch: 6| Step: 11
Training loss: 2.5100778585873895
Validation loss: 2.6601659083649203

Epoch: 6| Step: 12
Training loss: 2.815587616565394
Validation loss: 2.6366362353030155

Epoch: 6| Step: 13
Training loss: 3.0153338830399026
Validation loss: 2.6385395270709595

Epoch: 164| Step: 0
Training loss: 3.2380633125547873
Validation loss: 2.6269551480376174

Epoch: 6| Step: 1
Training loss: 3.13325463121742
Validation loss: 2.6128322351008806

Epoch: 6| Step: 2
Training loss: 3.1190589889324682
Validation loss: 2.6046114296067486

Epoch: 6| Step: 3
Training loss: 2.823650635367983
Validation loss: 2.6027921814008033

Epoch: 6| Step: 4
Training loss: 2.616924397922752
Validation loss: 2.596190857714742

Epoch: 6| Step: 5
Training loss: 2.7784241454125618
Validation loss: 2.5967257504475434

Epoch: 6| Step: 6
Training loss: 3.35829847962978
Validation loss: 2.595130357405191

Epoch: 6| Step: 7
Training loss: 2.889506685596764
Validation loss: 2.595139877450848

Epoch: 6| Step: 8
Training loss: 2.7831606356405834
Validation loss: 2.595989055035269

Epoch: 6| Step: 9
Training loss: 3.05589297965033
Validation loss: 2.596457739261831

Epoch: 6| Step: 10
Training loss: 2.6375214887710863
Validation loss: 2.592311605090723

Epoch: 6| Step: 11
Training loss: 3.2250538547957626
Validation loss: 2.59580527540812

Epoch: 6| Step: 12
Training loss: 2.8323019805941145
Validation loss: 2.5936190911517105

Epoch: 6| Step: 13
Training loss: 1.9894729969793103
Validation loss: 2.6044119055341595

Epoch: 165| Step: 0
Training loss: 2.631007087712472
Validation loss: 2.6029162437370217

Epoch: 6| Step: 1
Training loss: 2.914798101692948
Validation loss: 2.6233248270580196

Epoch: 6| Step: 2
Training loss: 3.366568453146206
Validation loss: 2.6161459179731805

Epoch: 6| Step: 3
Training loss: 2.6202087272608767
Validation loss: 2.6144420924071237

Epoch: 6| Step: 4
Training loss: 2.755396057156432
Validation loss: 2.604117055769041

Epoch: 6| Step: 5
Training loss: 2.1560592567000794
Validation loss: 2.5994893531375283

Epoch: 6| Step: 6
Training loss: 3.2838641697698225
Validation loss: 2.5949411089968946

Epoch: 6| Step: 7
Training loss: 2.950328006935965
Validation loss: 2.5993680357115534

Epoch: 6| Step: 8
Training loss: 2.657270616911316
Validation loss: 2.597465978552002

Epoch: 6| Step: 9
Training loss: 3.6717687713191007
Validation loss: 2.597882562192051

Epoch: 6| Step: 10
Training loss: 3.403606123669507
Validation loss: 2.601947530639175

Epoch: 6| Step: 11
Training loss: 2.394430485109656
Validation loss: 2.6019916982888542

Epoch: 6| Step: 12
Training loss: 3.002003477588853
Validation loss: 2.606713900855573

Epoch: 6| Step: 13
Training loss: 2.680172267472988
Validation loss: 2.6071235975583957

Epoch: 166| Step: 0
Training loss: 2.9918550550673784
Validation loss: 2.61571756027301

Epoch: 6| Step: 1
Training loss: 2.753930404232504
Validation loss: 2.621267175537334

Epoch: 6| Step: 2
Training loss: 3.4074744027534414
Validation loss: 2.6253833520129244

Epoch: 6| Step: 3
Training loss: 2.787545269654126
Validation loss: 2.617898935503015

Epoch: 6| Step: 4
Training loss: 3.3183823663859195
Validation loss: 2.6057470885451877

Epoch: 6| Step: 5
Training loss: 2.9353480471588007
Validation loss: 2.596582845724316

Epoch: 6| Step: 6
Training loss: 3.4547863584234313
Validation loss: 2.5975453550094803

Epoch: 6| Step: 7
Training loss: 2.555063202555893
Validation loss: 2.591434804025444

Epoch: 6| Step: 8
Training loss: 2.365864399697829
Validation loss: 2.5903775613085793

Epoch: 6| Step: 9
Training loss: 2.56721305068263
Validation loss: 2.5897248218130984

Epoch: 6| Step: 10
Training loss: 2.6578428989939233
Validation loss: 2.588853931902506

Epoch: 6| Step: 11
Training loss: 3.1991755257878247
Validation loss: 2.591431956891574

Epoch: 6| Step: 12
Training loss: 2.8506090216177347
Validation loss: 2.5917745580084177

Epoch: 6| Step: 13
Training loss: 2.8925219111160803
Validation loss: 2.588575946307454

Epoch: 167| Step: 0
Training loss: 2.9421476567062887
Validation loss: 2.592485141440027

Epoch: 6| Step: 1
Training loss: 3.707984793639046
Validation loss: 2.6015567727127356

Epoch: 6| Step: 2
Training loss: 2.610630304515181
Validation loss: 2.606226873434161

Epoch: 6| Step: 3
Training loss: 2.933299531163902
Validation loss: 2.6247903668852164

Epoch: 6| Step: 4
Training loss: 2.5290980669634213
Validation loss: 2.6439107660561803

Epoch: 6| Step: 5
Training loss: 3.1736766790790263
Validation loss: 2.683220734320054

Epoch: 6| Step: 6
Training loss: 3.1550728897404565
Validation loss: 2.665439822125833

Epoch: 6| Step: 7
Training loss: 2.3883832006934087
Validation loss: 2.631533604033169

Epoch: 6| Step: 8
Training loss: 3.1546486295258056
Validation loss: 2.609190823030593

Epoch: 6| Step: 9
Training loss: 2.840741924569502
Validation loss: 2.598418586605937

Epoch: 6| Step: 10
Training loss: 2.54628480028839
Validation loss: 2.5931423803445917

Epoch: 6| Step: 11
Training loss: 3.173163241655071
Validation loss: 2.5936447479997287

Epoch: 6| Step: 12
Training loss: 2.7411604911638925
Validation loss: 2.5878377218753834

Epoch: 6| Step: 13
Training loss: 2.8165300953125842
Validation loss: 2.6036732130247984

Epoch: 168| Step: 0
Training loss: 2.720523036848734
Validation loss: 2.6083001672855524

Epoch: 6| Step: 1
Training loss: 2.800989715181404
Validation loss: 2.606004378777067

Epoch: 6| Step: 2
Training loss: 2.8631436886080674
Validation loss: 2.6118371596690744

Epoch: 6| Step: 3
Training loss: 2.6205436481755857
Validation loss: 2.5873083764856357

Epoch: 6| Step: 4
Training loss: 2.486616646806469
Validation loss: 2.58148359815735

Epoch: 6| Step: 5
Training loss: 2.7434068886717338
Validation loss: 2.584485600532701

Epoch: 6| Step: 6
Training loss: 3.2225824151106166
Validation loss: 2.5948834453855705

Epoch: 6| Step: 7
Training loss: 2.889960630208106
Validation loss: 2.6131379880256986

Epoch: 6| Step: 8
Training loss: 3.474126000578492
Validation loss: 2.6383521583565503

Epoch: 6| Step: 9
Training loss: 3.0112811016726777
Validation loss: 2.621628169553067

Epoch: 6| Step: 10
Training loss: 3.529152441315128
Validation loss: 2.620928871743713

Epoch: 6| Step: 11
Training loss: 2.9874900019649973
Validation loss: 2.614541217219783

Epoch: 6| Step: 12
Training loss: 2.9502253753433525
Validation loss: 2.605903486027956

Epoch: 6| Step: 13
Training loss: 2.496408362105083
Validation loss: 2.610506540040542

Epoch: 169| Step: 0
Training loss: 3.038641187005583
Validation loss: 2.599503998304723

Epoch: 6| Step: 1
Training loss: 2.8114601756190316
Validation loss: 2.585812253254563

Epoch: 6| Step: 2
Training loss: 2.7137768741719586
Validation loss: 2.5859929184080492

Epoch: 6| Step: 3
Training loss: 2.8537771325778607
Validation loss: 2.5824867290983398

Epoch: 6| Step: 4
Training loss: 2.8927434633178017
Validation loss: 2.5786831721078576

Epoch: 6| Step: 5
Training loss: 2.9297919903241225
Validation loss: 2.583000088837239

Epoch: 6| Step: 6
Training loss: 3.675308764715042
Validation loss: 2.5811461287359645

Epoch: 6| Step: 7
Training loss: 2.780602540508307
Validation loss: 2.5856635440513758

Epoch: 6| Step: 8
Training loss: 2.6379893314530496
Validation loss: 2.581383273455172

Epoch: 6| Step: 9
Training loss: 3.060149555914781
Validation loss: 2.5810519858500847

Epoch: 6| Step: 10
Training loss: 2.516746223741682
Validation loss: 2.58592771805825

Epoch: 6| Step: 11
Training loss: 2.6171808498924376
Validation loss: 2.5900042336643483

Epoch: 6| Step: 12
Training loss: 3.190093836345944
Validation loss: 2.5894594229204877

Epoch: 6| Step: 13
Training loss: 3.0151803276831166
Validation loss: 2.5891448482463857

Epoch: 170| Step: 0
Training loss: 2.98227925637226
Validation loss: 2.590614983175506

Epoch: 6| Step: 1
Training loss: 2.4712504990557416
Validation loss: 2.5947303357440132

Epoch: 6| Step: 2
Training loss: 2.788657279189461
Validation loss: 2.600485195342421

Epoch: 6| Step: 3
Training loss: 2.045573046170495
Validation loss: 2.609937275067713

Epoch: 6| Step: 4
Training loss: 3.2449214576655714
Validation loss: 2.619525814142812

Epoch: 6| Step: 5
Training loss: 2.9610681026914687
Validation loss: 2.6085807441823774

Epoch: 6| Step: 6
Training loss: 2.6135403400618977
Validation loss: 2.6225846512601225

Epoch: 6| Step: 7
Training loss: 3.475656044047431
Validation loss: 2.637313694709604

Epoch: 6| Step: 8
Training loss: 2.860946473587272
Validation loss: 2.6485460105294174

Epoch: 6| Step: 9
Training loss: 2.76605135115194
Validation loss: 2.638775138655764

Epoch: 6| Step: 10
Training loss: 3.486728574690673
Validation loss: 2.6614799729008465

Epoch: 6| Step: 11
Training loss: 2.9799569066663327
Validation loss: 2.660048341263262

Epoch: 6| Step: 12
Training loss: 2.7648237544034915
Validation loss: 2.6635500136766024

Epoch: 6| Step: 13
Training loss: 3.052297764732708
Validation loss: 2.63044457842253

Epoch: 171| Step: 0
Training loss: 2.7762206820846873
Validation loss: 2.6208012113208996

Epoch: 6| Step: 1
Training loss: 3.0052691915730874
Validation loss: 2.618404428142918

Epoch: 6| Step: 2
Training loss: 2.4743554904107907
Validation loss: 2.5987370155720093

Epoch: 6| Step: 3
Training loss: 2.3287440763388956
Validation loss: 2.608461332661479

Epoch: 6| Step: 4
Training loss: 2.8031656285704436
Validation loss: 2.5987452315812294

Epoch: 6| Step: 5
Training loss: 3.0980589173183555
Validation loss: 2.5986051617670194

Epoch: 6| Step: 6
Training loss: 2.6353704777666893
Validation loss: 2.59663430200617

Epoch: 6| Step: 7
Training loss: 3.3583139562560524
Validation loss: 2.5968373537200824

Epoch: 6| Step: 8
Training loss: 2.810207619514368
Validation loss: 2.5971092317406694

Epoch: 6| Step: 9
Training loss: 3.416284462245136
Validation loss: 2.593704692723098

Epoch: 6| Step: 10
Training loss: 3.012305295358332
Validation loss: 2.5948082309128218

Epoch: 6| Step: 11
Training loss: 3.1874627503855186
Validation loss: 2.604823453383509

Epoch: 6| Step: 12
Training loss: 3.1521371161559344
Validation loss: 2.6010865166499135

Epoch: 6| Step: 13
Training loss: 1.9724234566383971
Validation loss: 2.6037245429672655

Epoch: 172| Step: 0
Training loss: 3.085413480280936
Validation loss: 2.6114382049868485

Epoch: 6| Step: 1
Training loss: 2.788741320327664
Validation loss: 2.6108047952879354

Epoch: 6| Step: 2
Training loss: 3.2097632124131437
Validation loss: 2.614142429063539

Epoch: 6| Step: 3
Training loss: 2.818378324173997
Validation loss: 2.617788527853761

Epoch: 6| Step: 4
Training loss: 2.904065695657945
Validation loss: 2.6239437472486267

Epoch: 6| Step: 5
Training loss: 2.7147028824739374
Validation loss: 2.598302810591123

Epoch: 6| Step: 6
Training loss: 3.0884143788106124
Validation loss: 2.597642518163817

Epoch: 6| Step: 7
Training loss: 2.669034105673994
Validation loss: 2.5867486220749623

Epoch: 6| Step: 8
Training loss: 2.3524753154955462
Validation loss: 2.579577496039225

Epoch: 6| Step: 9
Training loss: 2.853466161446721
Validation loss: 2.5859514258443186

Epoch: 6| Step: 10
Training loss: 3.290945931893739
Validation loss: 2.581563111510587

Epoch: 6| Step: 11
Training loss: 2.870630011443073
Validation loss: 2.5817920209789973

Epoch: 6| Step: 12
Training loss: 2.789740301098079
Validation loss: 2.5831747896234574

Epoch: 6| Step: 13
Training loss: 3.387664205364892
Validation loss: 2.588574035393293

Epoch: 173| Step: 0
Training loss: 2.710688071085566
Validation loss: 2.5866061850085127

Epoch: 6| Step: 1
Training loss: 2.8458850935943256
Validation loss: 2.5895585808691193

Epoch: 6| Step: 2
Training loss: 3.028316690934226
Validation loss: 2.591616568944891

Epoch: 6| Step: 3
Training loss: 3.27502432078875
Validation loss: 2.590932576817421

Epoch: 6| Step: 4
Training loss: 2.3795335565819227
Validation loss: 2.591427161867872

Epoch: 6| Step: 5
Training loss: 2.9711217140167707
Validation loss: 2.5965833838099788

Epoch: 6| Step: 6
Training loss: 3.0063177977469056
Validation loss: 2.5983250695382982

Epoch: 6| Step: 7
Training loss: 3.2290251341946443
Validation loss: 2.6046153046744687

Epoch: 6| Step: 8
Training loss: 2.9133695949622638
Validation loss: 2.60880369421819

Epoch: 6| Step: 9
Training loss: 2.834693488719335
Validation loss: 2.6089549560120435

Epoch: 6| Step: 10
Training loss: 2.4769514001137347
Validation loss: 2.619514924504508

Epoch: 6| Step: 11
Training loss: 2.9217353012225726
Validation loss: 2.6244320193926796

Epoch: 6| Step: 12
Training loss: 3.0186905375245625
Validation loss: 2.6131982831713922

Epoch: 6| Step: 13
Training loss: 3.2184403650182354
Validation loss: 2.617608505864483

Epoch: 174| Step: 0
Training loss: 2.6455087137203153
Validation loss: 2.6208745461515823

Epoch: 6| Step: 1
Training loss: 3.1560427153855017
Validation loss: 2.6157349401648795

Epoch: 6| Step: 2
Training loss: 2.6968253934503785
Validation loss: 2.601310816594842

Epoch: 6| Step: 3
Training loss: 3.069026920542352
Validation loss: 2.6025326044801758

Epoch: 6| Step: 4
Training loss: 2.68042329078669
Validation loss: 2.598068858113651

Epoch: 6| Step: 5
Training loss: 2.678626025415493
Validation loss: 2.6103085095860057

Epoch: 6| Step: 6
Training loss: 3.15258848618211
Validation loss: 2.631722624237337

Epoch: 6| Step: 7
Training loss: 2.8532965417373517
Validation loss: 2.6060941222106764

Epoch: 6| Step: 8
Training loss: 3.2209740519575423
Validation loss: 2.6110950116528335

Epoch: 6| Step: 9
Training loss: 3.152610568982189
Validation loss: 2.6035591082900478

Epoch: 6| Step: 10
Training loss: 2.7544539535975208
Validation loss: 2.620563615890946

Epoch: 6| Step: 11
Training loss: 3.1413679620078723
Validation loss: 2.614519505215427

Epoch: 6| Step: 12
Training loss: 2.8598760780750276
Validation loss: 2.608674915645796

Epoch: 6| Step: 13
Training loss: 2.0979941325073814
Validation loss: 2.619701144103753

Epoch: 175| Step: 0
Training loss: 2.1358695565658485
Validation loss: 2.6008017985811143

Epoch: 6| Step: 1
Training loss: 2.7438808331763176
Validation loss: 2.5987118011350288

Epoch: 6| Step: 2
Training loss: 3.2633235432754293
Validation loss: 2.5940674677580664

Epoch: 6| Step: 3
Training loss: 2.7601794062921767
Validation loss: 2.598824706084367

Epoch: 6| Step: 4
Training loss: 2.7031827710984735
Validation loss: 2.6155852819179284

Epoch: 6| Step: 5
Training loss: 3.2001605947250913
Validation loss: 2.6098678935850805

Epoch: 6| Step: 6
Training loss: 2.869891562456887
Validation loss: 2.6074035036752496

Epoch: 6| Step: 7
Training loss: 3.020152907637336
Validation loss: 2.60540456050602

Epoch: 6| Step: 8
Training loss: 3.403311205376983
Validation loss: 2.604877563575891

Epoch: 6| Step: 9
Training loss: 2.7692917476770917
Validation loss: 2.6016900303741686

Epoch: 6| Step: 10
Training loss: 2.859879412743154
Validation loss: 2.5959621089041627

Epoch: 6| Step: 11
Training loss: 3.017128209025879
Validation loss: 2.6014070349549177

Epoch: 6| Step: 12
Training loss: 2.953434034859523
Validation loss: 2.610234588167311

Epoch: 6| Step: 13
Training loss: 2.61582196039857
Validation loss: 2.5954724999670615

Testing loss: 2.812587482363396
