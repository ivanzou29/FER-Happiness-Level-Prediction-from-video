Epoch: 1| Step: 0
Training loss: 5.490030765533447
Validation loss: 5.177859183280699

Epoch: 5| Step: 1
Training loss: 4.696274280548096
Validation loss: 5.165421798665037

Epoch: 5| Step: 2
Training loss: 4.387377738952637
Validation loss: 5.153699239095052

Epoch: 5| Step: 3
Training loss: 4.260167598724365
Validation loss: 5.142986605244298

Epoch: 5| Step: 4
Training loss: 4.474459171295166
Validation loss: 5.132490640045495

Epoch: 5| Step: 5
Training loss: 5.0777764320373535
Validation loss: 5.120835242732879

Epoch: 5| Step: 6
Training loss: 5.718836784362793
Validation loss: 5.108432477520358

Epoch: 5| Step: 7
Training loss: 4.619027137756348
Validation loss: 5.095266019144366

Epoch: 5| Step: 8
Training loss: 5.354124546051025
Validation loss: 5.080820463036978

Epoch: 5| Step: 9
Training loss: 4.770454406738281
Validation loss: 5.065457451728083

Epoch: 5| Step: 10
Training loss: 5.261571884155273
Validation loss: 5.048199930498677

Epoch: 2| Step: 0
Training loss: 5.680561065673828
Validation loss: 5.029568477343488

Epoch: 5| Step: 1
Training loss: 3.8475146293640137
Validation loss: 5.010276727778937

Epoch: 5| Step: 2
Training loss: 3.6866040229797363
Validation loss: 4.9891437151098765

Epoch: 5| Step: 3
Training loss: 4.063777446746826
Validation loss: 4.965674856657623

Epoch: 5| Step: 4
Training loss: 4.110603332519531
Validation loss: 4.942136600453367

Epoch: 5| Step: 5
Training loss: 5.362432479858398
Validation loss: 4.915571735751245

Epoch: 5| Step: 6
Training loss: 5.768694877624512
Validation loss: 4.887654755705146

Epoch: 5| Step: 7
Training loss: 4.144505500793457
Validation loss: 4.858542124430339

Epoch: 5| Step: 8
Training loss: 5.309795379638672
Validation loss: 4.826649876051052

Epoch: 5| Step: 9
Training loss: 5.182994365692139
Validation loss: 4.793145984731694

Epoch: 5| Step: 10
Training loss: 4.474142551422119
Validation loss: 4.758129386491673

Epoch: 3| Step: 0
Training loss: 3.4898247718811035
Validation loss: 4.723486041509977

Epoch: 5| Step: 1
Training loss: 5.067011833190918
Validation loss: 4.685351920384233

Epoch: 5| Step: 2
Training loss: 4.118340492248535
Validation loss: 4.647300848396876

Epoch: 5| Step: 3
Training loss: 3.529656171798706
Validation loss: 4.6082320802955214

Epoch: 5| Step: 4
Training loss: 4.376433372497559
Validation loss: 4.5682286754731205

Epoch: 5| Step: 5
Training loss: 4.080755710601807
Validation loss: 4.527576702897266

Epoch: 5| Step: 6
Training loss: 5.830899238586426
Validation loss: 4.487915669718096

Epoch: 5| Step: 7
Training loss: 5.014141082763672
Validation loss: 4.446064190198016

Epoch: 5| Step: 8
Training loss: 3.389313220977783
Validation loss: 4.403518187102451

Epoch: 5| Step: 9
Training loss: 4.131923675537109
Validation loss: 4.364730447851201

Epoch: 5| Step: 10
Training loss: 4.542896270751953
Validation loss: 4.325145218961982

Epoch: 4| Step: 0
Training loss: 4.215781211853027
Validation loss: 4.282847389098136

Epoch: 5| Step: 1
Training loss: 4.59723424911499
Validation loss: 4.243223595362838

Epoch: 5| Step: 2
Training loss: 4.246096611022949
Validation loss: 4.203931998181087

Epoch: 5| Step: 3
Training loss: 4.9274492263793945
Validation loss: 4.162639176973733

Epoch: 5| Step: 4
Training loss: 3.234926223754883
Validation loss: 4.119278292502126

Epoch: 5| Step: 5
Training loss: 2.89505672454834
Validation loss: 4.079369796219693

Epoch: 5| Step: 6
Training loss: 4.240307331085205
Validation loss: 4.039174033749488

Epoch: 5| Step: 7
Training loss: 3.1441454887390137
Validation loss: 3.9997474993428876

Epoch: 5| Step: 8
Training loss: 4.409744739532471
Validation loss: 3.963528968954599

Epoch: 5| Step: 9
Training loss: 3.1157729625701904
Validation loss: 3.929279224846953

Epoch: 5| Step: 10
Training loss: 4.202576160430908
Validation loss: 3.8957573162612094

Epoch: 5| Step: 0
Training loss: 3.473013401031494
Validation loss: 3.866558290296985

Epoch: 5| Step: 1
Training loss: 3.3972697257995605
Validation loss: 3.8363239636985202

Epoch: 5| Step: 2
Training loss: 3.9019389152526855
Validation loss: 3.808292455570672

Epoch: 5| Step: 3
Training loss: 4.1840620040893555
Validation loss: 3.781751737799696

Epoch: 5| Step: 4
Training loss: 3.5340869426727295
Validation loss: 3.756350630073137

Epoch: 5| Step: 5
Training loss: 4.002717018127441
Validation loss: 3.732051485328264

Epoch: 5| Step: 6
Training loss: 3.5284931659698486
Validation loss: 3.712543410639609

Epoch: 5| Step: 7
Training loss: 4.334136009216309
Validation loss: 3.692096407695483

Epoch: 5| Step: 8
Training loss: 3.5366275310516357
Validation loss: 3.6767796957364647

Epoch: 5| Step: 9
Training loss: 3.6085383892059326
Validation loss: 3.6602414705420054

Epoch: 5| Step: 10
Training loss: 2.392183542251587
Validation loss: 3.64606886781672

Epoch: 6| Step: 0
Training loss: 4.858466148376465
Validation loss: 3.6326703409994803

Epoch: 5| Step: 1
Training loss: 4.386898994445801
Validation loss: 3.619485834593414

Epoch: 5| Step: 2
Training loss: 2.6777052879333496
Validation loss: 3.6077292837122434

Epoch: 5| Step: 3
Training loss: 3.1403260231018066
Validation loss: 3.5946272162980932

Epoch: 5| Step: 4
Training loss: 3.9437508583068848
Validation loss: 3.5851838306714128

Epoch: 5| Step: 5
Training loss: 3.9392542839050293
Validation loss: 3.5751636848654798

Epoch: 5| Step: 6
Training loss: 3.139720916748047
Validation loss: 3.5629729660608436

Epoch: 5| Step: 7
Training loss: 2.2918920516967773
Validation loss: 3.5543863773345947

Epoch: 5| Step: 8
Training loss: 3.108902931213379
Validation loss: 3.543610131868752

Epoch: 5| Step: 9
Training loss: 3.9841675758361816
Validation loss: 3.533506690814931

Epoch: 5| Step: 10
Training loss: 2.9546329975128174
Validation loss: 3.5245567701196157

Epoch: 7| Step: 0
Training loss: 3.7916884422302246
Validation loss: 3.5127937511731218

Epoch: 5| Step: 1
Training loss: 3.4910004138946533
Validation loss: 3.503772812504922

Epoch: 5| Step: 2
Training loss: 3.9840283393859863
Validation loss: 3.4935699175762873

Epoch: 5| Step: 3
Training loss: 3.1041100025177
Validation loss: 3.481583354293659

Epoch: 5| Step: 4
Training loss: 3.2873291969299316
Validation loss: 3.4721037367338776

Epoch: 5| Step: 5
Training loss: 4.0495805740356445
Validation loss: 3.4616455416525564

Epoch: 5| Step: 6
Training loss: 2.876044750213623
Validation loss: 3.4527071419582573

Epoch: 5| Step: 7
Training loss: 3.747559070587158
Validation loss: 3.441765216089064

Epoch: 5| Step: 8
Training loss: 2.3188157081604004
Validation loss: 3.4306401180964645

Epoch: 5| Step: 9
Training loss: 2.9649763107299805
Validation loss: 3.423280559560304

Epoch: 5| Step: 10
Training loss: 3.9308888912200928
Validation loss: 3.4135387302726827

Epoch: 8| Step: 0
Training loss: 3.483882188796997
Validation loss: 3.407883762031473

Epoch: 5| Step: 1
Training loss: 3.3398311138153076
Validation loss: 3.4026754799709527

Epoch: 5| Step: 2
Training loss: 2.487480878829956
Validation loss: 3.395068568568076

Epoch: 5| Step: 3
Training loss: 3.699496030807495
Validation loss: 3.3935521366775676

Epoch: 5| Step: 4
Training loss: 2.280343770980835
Validation loss: 3.3838606239646993

Epoch: 5| Step: 5
Training loss: 3.3335483074188232
Validation loss: 3.37532014231528

Epoch: 5| Step: 6
Training loss: 4.079634666442871
Validation loss: 3.369104218739335

Epoch: 5| Step: 7
Training loss: 4.105893135070801
Validation loss: 3.363001902898153

Epoch: 5| Step: 8
Training loss: 3.229907989501953
Validation loss: 3.3582268914868756

Epoch: 5| Step: 9
Training loss: 3.8764243125915527
Validation loss: 3.3520830472310386

Epoch: 5| Step: 10
Training loss: 2.6556098461151123
Validation loss: 3.3451293309529624

Epoch: 9| Step: 0
Training loss: 3.190321922302246
Validation loss: 3.340056432190762

Epoch: 5| Step: 1
Training loss: 3.882856845855713
Validation loss: 3.3326243174973356

Epoch: 5| Step: 2
Training loss: 2.484025239944458
Validation loss: 3.3251954611911567

Epoch: 5| Step: 3
Training loss: 2.822399616241455
Validation loss: 3.3232074655512327

Epoch: 5| Step: 4
Training loss: 4.777216911315918
Validation loss: 3.3208446707776798

Epoch: 5| Step: 5
Training loss: 2.8640666007995605
Validation loss: 3.3094940134274062

Epoch: 5| Step: 6
Training loss: 3.346414089202881
Validation loss: 3.300240839681318

Epoch: 5| Step: 7
Training loss: 3.3478572368621826
Validation loss: 3.2949974229258876

Epoch: 5| Step: 8
Training loss: 3.0221431255340576
Validation loss: 3.2905643729753393

Epoch: 5| Step: 9
Training loss: 3.2788074016571045
Validation loss: 3.286375412376978

Epoch: 5| Step: 10
Training loss: 3.0194878578186035
Validation loss: 3.2823180075614684

Epoch: 10| Step: 0
Training loss: 2.4676027297973633
Validation loss: 3.2740643126990205

Epoch: 5| Step: 1
Training loss: 3.3470821380615234
Validation loss: 3.2674215327027025

Epoch: 5| Step: 2
Training loss: 3.884929656982422
Validation loss: 3.2622241409876014

Epoch: 5| Step: 3
Training loss: 2.9080700874328613
Validation loss: 3.261316886512182

Epoch: 5| Step: 4
Training loss: 3.1152806282043457
Validation loss: 3.256808016889839

Epoch: 5| Step: 5
Training loss: 3.872814655303955
Validation loss: 3.2471581710282194

Epoch: 5| Step: 6
Training loss: 3.3449699878692627
Validation loss: 3.241911124157649

Epoch: 5| Step: 7
Training loss: 3.4029998779296875
Validation loss: 3.2363416533316336

Epoch: 5| Step: 8
Training loss: 3.8454596996307373
Validation loss: 3.2358166094749206

Epoch: 5| Step: 9
Training loss: 2.092747449874878
Validation loss: 3.227952629007319

Epoch: 5| Step: 10
Training loss: 3.2566165924072266
Validation loss: 3.2222576884813208

Epoch: 11| Step: 0
Training loss: 3.53381609916687
Validation loss: 3.2168073807993243

Epoch: 5| Step: 1
Training loss: 3.0894455909729004
Validation loss: 3.206776349775253

Epoch: 5| Step: 2
Training loss: 3.347285509109497
Validation loss: 3.199831916439918

Epoch: 5| Step: 3
Training loss: 2.9891796112060547
Validation loss: 3.1956481677229687

Epoch: 5| Step: 4
Training loss: 2.562098979949951
Validation loss: 3.1867948911523305

Epoch: 5| Step: 5
Training loss: 3.0009894371032715
Validation loss: 3.178843621284731

Epoch: 5| Step: 6
Training loss: 3.0478014945983887
Validation loss: 3.172725187834873

Epoch: 5| Step: 7
Training loss: 3.217036485671997
Validation loss: 3.1661790417086695

Epoch: 5| Step: 8
Training loss: 3.4460456371307373
Validation loss: 3.16048869522669

Epoch: 5| Step: 9
Training loss: 3.4928367137908936
Validation loss: 3.1608475664610505

Epoch: 5| Step: 10
Training loss: 3.3614978790283203
Validation loss: 3.1483739499122865

Epoch: 12| Step: 0
Training loss: 3.078622817993164
Validation loss: 3.1416227356080086

Epoch: 5| Step: 1
Training loss: 2.8992743492126465
Validation loss: 3.137878476932485

Epoch: 5| Step: 2
Training loss: 2.646414279937744
Validation loss: 3.1323255313340055

Epoch: 5| Step: 3
Training loss: 3.0219037532806396
Validation loss: 3.1296748474080074

Epoch: 5| Step: 4
Training loss: 3.18058443069458
Validation loss: 3.1243854543214202

Epoch: 5| Step: 5
Training loss: 3.47822642326355
Validation loss: 3.11865657888433

Epoch: 5| Step: 6
Training loss: 3.2641632556915283
Validation loss: 3.113300872105424

Epoch: 5| Step: 7
Training loss: 2.4883124828338623
Validation loss: 3.1064471019211637

Epoch: 5| Step: 8
Training loss: 3.2007973194122314
Validation loss: 3.1039143736644457

Epoch: 5| Step: 9
Training loss: 4.031785011291504
Validation loss: 3.0975491974943425

Epoch: 5| Step: 10
Training loss: 3.2635459899902344
Validation loss: 3.0942302339820453

Epoch: 13| Step: 0
Training loss: 3.5170109272003174
Validation loss: 3.0890843022254204

Epoch: 5| Step: 1
Training loss: 2.8480095863342285
Validation loss: 3.082413181181877

Epoch: 5| Step: 2
Training loss: 2.589509963989258
Validation loss: 3.07523190077915

Epoch: 5| Step: 3
Training loss: 3.25111722946167
Validation loss: 3.073310372649982

Epoch: 5| Step: 4
Training loss: 3.478424072265625
Validation loss: 3.069584446568643

Epoch: 5| Step: 5
Training loss: 3.460479259490967
Validation loss: 3.064016660054525

Epoch: 5| Step: 6
Training loss: 3.205651044845581
Validation loss: 3.0614922405571066

Epoch: 5| Step: 7
Training loss: 3.2092113494873047
Validation loss: 3.056787106298631

Epoch: 5| Step: 8
Training loss: 3.1180262565612793
Validation loss: 3.051337718963623

Epoch: 5| Step: 9
Training loss: 3.0648534297943115
Validation loss: 3.045524817641063

Epoch: 5| Step: 10
Training loss: 2.3119583129882812
Validation loss: 3.0416147760165635

Epoch: 14| Step: 0
Training loss: 3.1075656414031982
Validation loss: 3.036439523901991

Epoch: 5| Step: 1
Training loss: 2.8656888008117676
Validation loss: 3.0341194137450187

Epoch: 5| Step: 2
Training loss: 2.385162830352783
Validation loss: 3.0305649157493346

Epoch: 5| Step: 3
Training loss: 3.7344939708709717
Validation loss: 3.0254451638908795

Epoch: 5| Step: 4
Training loss: 3.6414427757263184
Validation loss: 3.0184989180616153

Epoch: 5| Step: 5
Training loss: 2.648477077484131
Validation loss: 3.016033552026236

Epoch: 5| Step: 6
Training loss: 3.6969387531280518
Validation loss: 3.0155070007488294

Epoch: 5| Step: 7
Training loss: 2.951927900314331
Validation loss: 3.0120849096646873

Epoch: 5| Step: 8
Training loss: 3.0384182929992676
Validation loss: 3.009237051010132

Epoch: 5| Step: 9
Training loss: 3.303250789642334
Validation loss: 3.002357752092423

Epoch: 5| Step: 10
Training loss: 2.3430347442626953
Validation loss: 2.9989402653068624

Epoch: 15| Step: 0
Training loss: 3.4225776195526123
Validation loss: 2.9930283690011628

Epoch: 5| Step: 1
Training loss: 2.969773054122925
Validation loss: 2.9877989292144775

Epoch: 5| Step: 2
Training loss: 3.067924976348877
Validation loss: 2.9864052700740036

Epoch: 5| Step: 3
Training loss: 3.22752046585083
Validation loss: 2.983182527685678

Epoch: 5| Step: 4
Training loss: 2.773085355758667
Validation loss: 2.983213163191272

Epoch: 5| Step: 5
Training loss: 2.8871922492980957
Validation loss: 2.987762628063079

Epoch: 5| Step: 6
Training loss: 2.589613199234009
Validation loss: 2.9751266920438377

Epoch: 5| Step: 7
Training loss: 2.905163526535034
Validation loss: 2.9669252082865727

Epoch: 5| Step: 8
Training loss: 3.66685152053833
Validation loss: 2.9639340575023363

Epoch: 5| Step: 9
Training loss: 3.14955472946167
Validation loss: 2.9628824700591383

Epoch: 5| Step: 10
Training loss: 2.8357975482940674
Validation loss: 2.961570314181748

Epoch: 16| Step: 0
Training loss: 2.5476622581481934
Validation loss: 2.95894371053224

Epoch: 5| Step: 1
Training loss: 3.3398756980895996
Validation loss: 2.9552891356970674

Epoch: 5| Step: 2
Training loss: 2.2569353580474854
Validation loss: 2.949988611282841

Epoch: 5| Step: 3
Training loss: 2.131941318511963
Validation loss: 2.9478702493893203

Epoch: 5| Step: 4
Training loss: 3.8640124797821045
Validation loss: 2.9437911664285967

Epoch: 5| Step: 5
Training loss: 3.2110297679901123
Validation loss: 2.9406823650483163

Epoch: 5| Step: 6
Training loss: 3.245692014694214
Validation loss: 2.9390175906560754

Epoch: 5| Step: 7
Training loss: 2.3434996604919434
Validation loss: 2.9343525158461703

Epoch: 5| Step: 8
Training loss: 3.542722225189209
Validation loss: 2.930060617385372

Epoch: 5| Step: 9
Training loss: 3.0055038928985596
Validation loss: 2.9255914585564726

Epoch: 5| Step: 10
Training loss: 3.911022901535034
Validation loss: 2.922761332604193

Epoch: 17| Step: 0
Training loss: 3.343135118484497
Validation loss: 2.9250652892615205

Epoch: 5| Step: 1
Training loss: 2.0985443592071533
Validation loss: 2.9157372136269846

Epoch: 5| Step: 2
Training loss: 3.4066433906555176
Validation loss: 2.9118258799276044

Epoch: 5| Step: 3
Training loss: 3.0817959308624268
Validation loss: 2.9086972872416177

Epoch: 5| Step: 4
Training loss: 2.213590145111084
Validation loss: 2.9053709071169616

Epoch: 5| Step: 5
Training loss: 3.3027682304382324
Validation loss: 2.9045353345973517

Epoch: 5| Step: 6
Training loss: 2.494354248046875
Validation loss: 2.90146307535069

Epoch: 5| Step: 7
Training loss: 3.681922197341919
Validation loss: 2.898238105158652

Epoch: 5| Step: 8
Training loss: 2.83117413520813
Validation loss: 2.8941069700384654

Epoch: 5| Step: 9
Training loss: 3.352360963821411
Validation loss: 2.8910852170759633

Epoch: 5| Step: 10
Training loss: 3.2441017627716064
Validation loss: 2.8902416408702893

Epoch: 18| Step: 0
Training loss: 3.710073471069336
Validation loss: 2.8889452565100884

Epoch: 5| Step: 1
Training loss: 2.6175358295440674
Validation loss: 2.8860575152981665

Epoch: 5| Step: 2
Training loss: 3.1585946083068848
Validation loss: 2.8803374972394717

Epoch: 5| Step: 3
Training loss: 3.18635630607605
Validation loss: 2.8833992224867626

Epoch: 5| Step: 4
Training loss: 2.714341640472412
Validation loss: 2.880771888199673

Epoch: 5| Step: 5
Training loss: 2.5165348052978516
Validation loss: 2.87709556600099

Epoch: 5| Step: 6
Training loss: 2.936127185821533
Validation loss: 2.8750937010652278

Epoch: 5| Step: 7
Training loss: 2.741300106048584
Validation loss: 2.873415188122821

Epoch: 5| Step: 8
Training loss: 3.3277294635772705
Validation loss: 2.8677241674033542

Epoch: 5| Step: 9
Training loss: 3.081986904144287
Validation loss: 2.8666899152981338

Epoch: 5| Step: 10
Training loss: 2.754366159439087
Validation loss: 2.863893885766306

Epoch: 19| Step: 0
Training loss: 2.6811351776123047
Validation loss: 2.861670119788057

Epoch: 5| Step: 1
Training loss: 2.480120897293091
Validation loss: 2.8597069222440004

Epoch: 5| Step: 2
Training loss: 2.552018404006958
Validation loss: 2.8568730892673617

Epoch: 5| Step: 3
Training loss: 3.411396026611328
Validation loss: 2.8566229727960404

Epoch: 5| Step: 4
Training loss: 2.5093536376953125
Validation loss: 2.8538558944579093

Epoch: 5| Step: 5
Training loss: 2.8423759937286377
Validation loss: 2.850630147482759

Epoch: 5| Step: 6
Training loss: 3.6063129901885986
Validation loss: 2.851708876189365

Epoch: 5| Step: 7
Training loss: 3.989737033843994
Validation loss: 2.8474988322104178

Epoch: 5| Step: 8
Training loss: 3.2859864234924316
Validation loss: 2.8477339360021774

Epoch: 5| Step: 9
Training loss: 2.6875388622283936
Validation loss: 2.846579113314229

Epoch: 5| Step: 10
Training loss: 2.467085123062134
Validation loss: 2.845288622763849

Epoch: 20| Step: 0
Training loss: 3.0317249298095703
Validation loss: 2.840719066640382

Epoch: 5| Step: 1
Training loss: 3.6260902881622314
Validation loss: 2.8403018597633607

Epoch: 5| Step: 2
Training loss: 2.6327576637268066
Validation loss: 2.833506653385778

Epoch: 5| Step: 3
Training loss: 2.626101016998291
Validation loss: 2.8333885285162155

Epoch: 5| Step: 4
Training loss: 3.72705340385437
Validation loss: 2.8302115727496404

Epoch: 5| Step: 5
Training loss: 2.5112228393554688
Validation loss: 2.826531215380597

Epoch: 5| Step: 6
Training loss: 2.8181722164154053
Validation loss: 2.825024071560111

Epoch: 5| Step: 7
Training loss: 2.9537625312805176
Validation loss: 2.828087865665395

Epoch: 5| Step: 8
Training loss: 2.1293394565582275
Validation loss: 2.8294677913829847

Epoch: 5| Step: 9
Training loss: 3.0969033241271973
Validation loss: 2.827981556615522

Epoch: 5| Step: 10
Training loss: 3.3882453441619873
Validation loss: 2.8216337465470835

Epoch: 21| Step: 0
Training loss: 2.8135886192321777
Validation loss: 2.8173032473492365

Epoch: 5| Step: 1
Training loss: 3.390394687652588
Validation loss: 2.814425999118436

Epoch: 5| Step: 2
Training loss: 3.7338356971740723
Validation loss: 2.8149829628647014

Epoch: 5| Step: 3
Training loss: 2.9909729957580566
Validation loss: 2.811386531399142

Epoch: 5| Step: 4
Training loss: 2.2284903526306152
Validation loss: 2.807797619091567

Epoch: 5| Step: 5
Training loss: 2.4748482704162598
Validation loss: 2.807525165619389

Epoch: 5| Step: 6
Training loss: 3.4866442680358887
Validation loss: 2.806723976647982

Epoch: 5| Step: 7
Training loss: 2.6875948905944824
Validation loss: 2.8100952204837593

Epoch: 5| Step: 8
Training loss: 2.698573589324951
Validation loss: 2.8103683507570656

Epoch: 5| Step: 9
Training loss: 3.1409008502960205
Validation loss: 2.850414353032266

Epoch: 5| Step: 10
Training loss: 2.6370625495910645
Validation loss: 2.8051064937345442

Epoch: 22| Step: 0
Training loss: 2.4228813648223877
Validation loss: 2.8020195909725722

Epoch: 5| Step: 1
Training loss: 2.3896872997283936
Validation loss: 2.8047447486590316

Epoch: 5| Step: 2
Training loss: 2.9580917358398438
Validation loss: 2.798461603861983

Epoch: 5| Step: 3
Training loss: 4.117861747741699
Validation loss: 2.794792144529281

Epoch: 5| Step: 4
Training loss: 2.844175338745117
Validation loss: 2.7928398552761284

Epoch: 5| Step: 5
Training loss: 3.124405860900879
Validation loss: 2.792132064860354

Epoch: 5| Step: 6
Training loss: 3.4831881523132324
Validation loss: 2.790597584939772

Epoch: 5| Step: 7
Training loss: 3.1432833671569824
Validation loss: 2.786603719957413

Epoch: 5| Step: 8
Training loss: 2.136204242706299
Validation loss: 2.782319945673789

Epoch: 5| Step: 9
Training loss: 2.2445993423461914
Validation loss: 2.780934956765944

Epoch: 5| Step: 10
Training loss: 3.400834560394287
Validation loss: 2.779202345878847

Epoch: 23| Step: 0
Training loss: 2.869032382965088
Validation loss: 2.779688399325135

Epoch: 5| Step: 1
Training loss: 3.050658702850342
Validation loss: 2.7849966172249085

Epoch: 5| Step: 2
Training loss: 2.70131254196167
Validation loss: 2.795531108815183

Epoch: 5| Step: 3
Training loss: 2.2372705936431885
Validation loss: 2.8006748691681893

Epoch: 5| Step: 4
Training loss: 3.038400650024414
Validation loss: 2.771495767818984

Epoch: 5| Step: 5
Training loss: 2.935234546661377
Validation loss: 2.773455407029839

Epoch: 5| Step: 6
Training loss: 3.4077847003936768
Validation loss: 2.7800066753100325

Epoch: 5| Step: 7
Training loss: 2.7022547721862793
Validation loss: 2.77804930492114

Epoch: 5| Step: 8
Training loss: 3.2403171062469482
Validation loss: 2.7729170988964778

Epoch: 5| Step: 9
Training loss: 3.1178793907165527
Validation loss: 2.7656269637487267

Epoch: 5| Step: 10
Training loss: 2.7711286544799805
Validation loss: 2.7589663843954764

Epoch: 24| Step: 0
Training loss: 2.9282829761505127
Validation loss: 2.7586692276821343

Epoch: 5| Step: 1
Training loss: 2.424225091934204
Validation loss: 2.763696955096337

Epoch: 5| Step: 2
Training loss: 3.6556572914123535
Validation loss: 2.7672420829854985

Epoch: 5| Step: 3
Training loss: 3.4898312091827393
Validation loss: 2.7609994847287416

Epoch: 5| Step: 4
Training loss: 3.15852952003479
Validation loss: 2.7522404424605833

Epoch: 5| Step: 5
Training loss: 2.3134922981262207
Validation loss: 2.7486514199164604

Epoch: 5| Step: 6
Training loss: 2.8754842281341553
Validation loss: 2.7509794337775118

Epoch: 5| Step: 7
Training loss: 2.859830379486084
Validation loss: 2.753209960076117

Epoch: 5| Step: 8
Training loss: 2.686002731323242
Validation loss: 2.7568161872125443

Epoch: 5| Step: 9
Training loss: 3.0974011421203613
Validation loss: 2.753489327687089

Epoch: 5| Step: 10
Training loss: 2.398625135421753
Validation loss: 2.7458147848806074

Epoch: 25| Step: 0
Training loss: 2.706360340118408
Validation loss: 2.741728892890356

Epoch: 5| Step: 1
Training loss: 3.1487390995025635
Validation loss: 2.7371326467042327

Epoch: 5| Step: 2
Training loss: 2.6119954586029053
Validation loss: 2.7374464106816117

Epoch: 5| Step: 3
Training loss: 3.2807700634002686
Validation loss: 2.742492985981767

Epoch: 5| Step: 4
Training loss: 2.2396411895751953
Validation loss: 2.7495592512110227

Epoch: 5| Step: 5
Training loss: 3.570326566696167
Validation loss: 2.7461706284553773

Epoch: 5| Step: 6
Training loss: 2.6975107192993164
Validation loss: 2.7462806445296093

Epoch: 5| Step: 7
Training loss: 3.0234410762786865
Validation loss: 2.7460888713918705

Epoch: 5| Step: 8
Training loss: 2.975409984588623
Validation loss: 2.7474067518788

Epoch: 5| Step: 9
Training loss: 2.810619831085205
Validation loss: 2.7441096408392793

Epoch: 5| Step: 10
Training loss: 2.74838924407959
Validation loss: 2.7385987261290192

Epoch: 26| Step: 0
Training loss: 2.0237314701080322
Validation loss: 2.737454265676519

Epoch: 5| Step: 1
Training loss: 3.0526041984558105
Validation loss: 2.738885497534147

Epoch: 5| Step: 2
Training loss: 2.8806324005126953
Validation loss: 2.7388743149336947

Epoch: 5| Step: 3
Training loss: 3.118346691131592
Validation loss: 2.7302343665912585

Epoch: 5| Step: 4
Training loss: 3.2740414142608643
Validation loss: 2.727142741603236

Epoch: 5| Step: 5
Training loss: 2.7147738933563232
Validation loss: 2.73227717286797

Epoch: 5| Step: 6
Training loss: 2.829786777496338
Validation loss: 2.7312148770978375

Epoch: 5| Step: 7
Training loss: 2.296391487121582
Validation loss: 2.728002728954438

Epoch: 5| Step: 8
Training loss: 3.551501750946045
Validation loss: 2.722500378085721

Epoch: 5| Step: 9
Training loss: 3.193077564239502
Validation loss: 2.721898986447242

Epoch: 5| Step: 10
Training loss: 2.791390895843506
Validation loss: 2.7164466124708935

Epoch: 27| Step: 0
Training loss: 3.1098484992980957
Validation loss: 2.7169052759806314

Epoch: 5| Step: 1
Training loss: 2.184675455093384
Validation loss: 2.7128000541399886

Epoch: 5| Step: 2
Training loss: 3.1214687824249268
Validation loss: 2.718869496417302

Epoch: 5| Step: 3
Training loss: 3.63928484916687
Validation loss: 2.7157202946242465

Epoch: 5| Step: 4
Training loss: 2.914069652557373
Validation loss: 2.7161808783008206

Epoch: 5| Step: 5
Training loss: 3.3108432292938232
Validation loss: 2.715410073598226

Epoch: 5| Step: 6
Training loss: 2.3391318321228027
Validation loss: 2.7196952527569187

Epoch: 5| Step: 7
Training loss: 2.6740612983703613
Validation loss: 2.7096040428325696

Epoch: 5| Step: 8
Training loss: 2.7253165245056152
Validation loss: 2.703375329253494

Epoch: 5| Step: 9
Training loss: 2.577846050262451
Validation loss: 2.7011710623259186

Epoch: 5| Step: 10
Training loss: 3.0095176696777344
Validation loss: 2.702076886289863

Epoch: 28| Step: 0
Training loss: 1.8574680089950562
Validation loss: 2.7019470558371594

Epoch: 5| Step: 1
Training loss: 2.554527759552002
Validation loss: 2.7088594154645036

Epoch: 5| Step: 2
Training loss: 2.658412218093872
Validation loss: 2.7176669028497513

Epoch: 5| Step: 3
Training loss: 3.0808448791503906
Validation loss: 2.708605653496199

Epoch: 5| Step: 4
Training loss: 3.2032699584960938
Validation loss: 2.7009325719648793

Epoch: 5| Step: 5
Training loss: 3.286144971847534
Validation loss: 2.705870287392729

Epoch: 5| Step: 6
Training loss: 2.5461955070495605
Validation loss: 2.714478510682301

Epoch: 5| Step: 7
Training loss: 3.0549075603485107
Validation loss: 2.711075882757864

Epoch: 5| Step: 8
Training loss: 3.627249240875244
Validation loss: 2.7047260294678392

Epoch: 5| Step: 9
Training loss: 2.743011474609375
Validation loss: 2.701660563868861

Epoch: 5| Step: 10
Training loss: 2.9361629486083984
Validation loss: 2.7064334346402075

Epoch: 29| Step: 0
Training loss: 2.8845155239105225
Validation loss: 2.710275037314302

Epoch: 5| Step: 1
Training loss: 3.0859856605529785
Validation loss: 2.718689372462611

Epoch: 5| Step: 2
Training loss: 2.5857131481170654
Validation loss: 2.705541479972101

Epoch: 5| Step: 3
Training loss: 3.3103625774383545
Validation loss: 2.7020980619615123

Epoch: 5| Step: 4
Training loss: 3.6999144554138184
Validation loss: 2.6995343110894643

Epoch: 5| Step: 5
Training loss: 3.246842622756958
Validation loss: 2.696730985436388

Epoch: 5| Step: 6
Training loss: 2.242046594619751
Validation loss: 2.6978729540301907

Epoch: 5| Step: 7
Training loss: 2.461717128753662
Validation loss: 2.6952673363429245

Epoch: 5| Step: 8
Training loss: 2.8761773109436035
Validation loss: 2.697575215370424

Epoch: 5| Step: 9
Training loss: 2.2485721111297607
Validation loss: 2.69764119578946

Epoch: 5| Step: 10
Training loss: 2.868711233139038
Validation loss: 2.6952577919088383

Epoch: 30| Step: 0
Training loss: 2.9864509105682373
Validation loss: 2.6968400042544127

Epoch: 5| Step: 1
Training loss: 2.779655933380127
Validation loss: 2.6960551097828853

Epoch: 5| Step: 2
Training loss: 2.8492727279663086
Validation loss: 2.693541967740623

Epoch: 5| Step: 3
Training loss: 3.088531017303467
Validation loss: 2.690025411626344

Epoch: 5| Step: 4
Training loss: 2.9233765602111816
Validation loss: 2.687707203690724

Epoch: 5| Step: 5
Training loss: 2.1414902210235596
Validation loss: 2.6884251461234143

Epoch: 5| Step: 6
Training loss: 2.7611985206604004
Validation loss: 2.690175776840538

Epoch: 5| Step: 7
Training loss: 3.02009654045105
Validation loss: 2.685362926093481

Epoch: 5| Step: 8
Training loss: 2.893686056137085
Validation loss: 2.6857153728444088

Epoch: 5| Step: 9
Training loss: 2.9794158935546875
Validation loss: 2.6842838794954362

Epoch: 5| Step: 10
Training loss: 3.037243366241455
Validation loss: 2.6881697306068997

Epoch: 31| Step: 0
Training loss: 3.174344062805176
Validation loss: 2.6840185939624743

Epoch: 5| Step: 1
Training loss: 2.716456174850464
Validation loss: 2.6834136286089496

Epoch: 5| Step: 2
Training loss: 2.7570736408233643
Validation loss: 2.6832233731464674

Epoch: 5| Step: 3
Training loss: 3.2020726203918457
Validation loss: 2.688438443727391

Epoch: 5| Step: 4
Training loss: 2.2052769660949707
Validation loss: 2.692217124405728

Epoch: 5| Step: 5
Training loss: 2.9900221824645996
Validation loss: 2.692370810816365

Epoch: 5| Step: 6
Training loss: 3.1635258197784424
Validation loss: 2.6828350533721266

Epoch: 5| Step: 7
Training loss: 3.096017837524414
Validation loss: 2.6797572694798952

Epoch: 5| Step: 8
Training loss: 2.618377685546875
Validation loss: 2.6791034847177486

Epoch: 5| Step: 9
Training loss: 3.0589544773101807
Validation loss: 2.6732927676170104

Epoch: 5| Step: 10
Training loss: 2.260599136352539
Validation loss: 2.6780754161137406

Epoch: 32| Step: 0
Training loss: 2.15022611618042
Validation loss: 2.6811120253737255

Epoch: 5| Step: 1
Training loss: 3.2632229328155518
Validation loss: 2.6810637750933246

Epoch: 5| Step: 2
Training loss: 3.1136367321014404
Validation loss: 2.676352042023854

Epoch: 5| Step: 3
Training loss: 2.5739853382110596
Validation loss: 2.6742882549121814

Epoch: 5| Step: 4
Training loss: 3.324242353439331
Validation loss: 2.671881660338371

Epoch: 5| Step: 5
Training loss: 2.5014467239379883
Validation loss: 2.67283966208017

Epoch: 5| Step: 6
Training loss: 2.8662397861480713
Validation loss: 2.6746729163713354

Epoch: 5| Step: 7
Training loss: 2.6261942386627197
Validation loss: 2.6714926817083873

Epoch: 5| Step: 8
Training loss: 2.3959903717041016
Validation loss: 2.6734466988553285

Epoch: 5| Step: 9
Training loss: 2.644904375076294
Validation loss: 2.6720420314419653

Epoch: 5| Step: 10
Training loss: 4.022912979125977
Validation loss: 2.677073699171825

Epoch: 33| Step: 0
Training loss: 2.5925040245056152
Validation loss: 2.6692189529377925

Epoch: 5| Step: 1
Training loss: 3.072049379348755
Validation loss: 2.666554517643426

Epoch: 5| Step: 2
Training loss: 3.2247910499572754
Validation loss: 2.6710798868568997

Epoch: 5| Step: 3
Training loss: 2.7396340370178223
Validation loss: 2.6717624766852266

Epoch: 5| Step: 4
Training loss: 3.060157537460327
Validation loss: 2.6748712960109917

Epoch: 5| Step: 5
Training loss: 3.1613211631774902
Validation loss: 2.673127958851476

Epoch: 5| Step: 6
Training loss: 2.607891082763672
Validation loss: 2.671811975458617

Epoch: 5| Step: 7
Training loss: 2.0842208862304688
Validation loss: 2.6698282636621946

Epoch: 5| Step: 8
Training loss: 3.1341824531555176
Validation loss: 2.665097754488709

Epoch: 5| Step: 9
Training loss: 2.8598246574401855
Validation loss: 2.6666282684572282

Epoch: 5| Step: 10
Training loss: 2.7101404666900635
Validation loss: 2.6744104149521037

Epoch: 34| Step: 0
Training loss: 2.2899622917175293
Validation loss: 2.6880867865777787

Epoch: 5| Step: 1
Training loss: 3.2135043144226074
Validation loss: 2.701833914684993

Epoch: 5| Step: 2
Training loss: 2.5780646800994873
Validation loss: 2.6773086722179125

Epoch: 5| Step: 3
Training loss: 3.359776258468628
Validation loss: 2.663387918985018

Epoch: 5| Step: 4
Training loss: 2.343312978744507
Validation loss: 2.6606231133143106

Epoch: 5| Step: 5
Training loss: 3.248569965362549
Validation loss: 2.6633983812024518

Epoch: 5| Step: 6
Training loss: 2.5994627475738525
Validation loss: 2.662936956651749

Epoch: 5| Step: 7
Training loss: 3.27685809135437
Validation loss: 2.6641092813143166

Epoch: 5| Step: 8
Training loss: 2.9082703590393066
Validation loss: 2.665648586006575

Epoch: 5| Step: 9
Training loss: 2.69697904586792
Validation loss: 2.661641341383739

Epoch: 5| Step: 10
Training loss: 2.7149415016174316
Validation loss: 2.6596658896374445

Epoch: 35| Step: 0
Training loss: 2.795159339904785
Validation loss: 2.6583648266330844

Epoch: 5| Step: 1
Training loss: 3.0119595527648926
Validation loss: 2.658826299892959

Epoch: 5| Step: 2
Training loss: 2.5213332176208496
Validation loss: 2.66112413970373

Epoch: 5| Step: 3
Training loss: 2.6133885383605957
Validation loss: 2.6646632327828357

Epoch: 5| Step: 4
Training loss: 2.6091854572296143
Validation loss: 2.6655482425484607

Epoch: 5| Step: 5
Training loss: 2.3119022846221924
Validation loss: 2.6564023392174834

Epoch: 5| Step: 6
Training loss: 3.1802468299865723
Validation loss: 2.6540297949185936

Epoch: 5| Step: 7
Training loss: 2.980867385864258
Validation loss: 2.658171187164963

Epoch: 5| Step: 8
Training loss: 2.800755023956299
Validation loss: 2.6563270438101982

Epoch: 5| Step: 9
Training loss: 2.719512462615967
Validation loss: 2.654520542390885

Epoch: 5| Step: 10
Training loss: 3.733816146850586
Validation loss: 2.6563182056591077

Epoch: 36| Step: 0
Training loss: 2.927015781402588
Validation loss: 2.6545099455823182

Epoch: 5| Step: 1
Training loss: 2.234403610229492
Validation loss: 2.6514357687324606

Epoch: 5| Step: 2
Training loss: 2.922166347503662
Validation loss: 2.6533909023448987

Epoch: 5| Step: 3
Training loss: 3.3982086181640625
Validation loss: 2.6569773099755727

Epoch: 5| Step: 4
Training loss: 2.225292921066284
Validation loss: 2.6549992407521894

Epoch: 5| Step: 5
Training loss: 2.7704529762268066
Validation loss: 2.659952240605508

Epoch: 5| Step: 6
Training loss: 2.3505897521972656
Validation loss: 2.659827370797434

Epoch: 5| Step: 7
Training loss: 3.286457061767578
Validation loss: 2.653698762257894

Epoch: 5| Step: 8
Training loss: 3.603306531906128
Validation loss: 2.650474850849439

Epoch: 5| Step: 9
Training loss: 3.362126588821411
Validation loss: 2.6466690853077877

Epoch: 5| Step: 10
Training loss: 1.8477206230163574
Validation loss: 2.648679692258117

Epoch: 37| Step: 0
Training loss: 3.187206745147705
Validation loss: 2.6524914823552614

Epoch: 5| Step: 1
Training loss: 2.6540307998657227
Validation loss: 2.6534253525477585

Epoch: 5| Step: 2
Training loss: 2.717285394668579
Validation loss: 2.6541311971602903

Epoch: 5| Step: 3
Training loss: 3.2072696685791016
Validation loss: 2.65223422614477

Epoch: 5| Step: 4
Training loss: 2.5788817405700684
Validation loss: 2.645402798088648

Epoch: 5| Step: 5
Training loss: 2.5460381507873535
Validation loss: 2.641850479187504

Epoch: 5| Step: 6
Training loss: 3.2111897468566895
Validation loss: 2.6487182314677904

Epoch: 5| Step: 7
Training loss: 3.065916061401367
Validation loss: 2.6744167266353482

Epoch: 5| Step: 8
Training loss: 2.4935238361358643
Validation loss: 2.6574083143664944

Epoch: 5| Step: 9
Training loss: 2.6265385150909424
Validation loss: 2.6482812973760788

Epoch: 5| Step: 10
Training loss: 2.821542978286743
Validation loss: 2.6508874047187065

Epoch: 38| Step: 0
Training loss: 2.4485225677490234
Validation loss: 2.653219271731633

Epoch: 5| Step: 1
Training loss: 2.62640380859375
Validation loss: 2.6503455356885026

Epoch: 5| Step: 2
Training loss: 2.2328693866729736
Validation loss: 2.6529375045530257

Epoch: 5| Step: 3
Training loss: 2.703000545501709
Validation loss: 2.6559877152084024

Epoch: 5| Step: 4
Training loss: 3.3426718711853027
Validation loss: 2.656301054903256

Epoch: 5| Step: 5
Training loss: 2.8922343254089355
Validation loss: 2.658545499206871

Epoch: 5| Step: 6
Training loss: 2.3474478721618652
Validation loss: 2.664735776121898

Epoch: 5| Step: 7
Training loss: 3.435119152069092
Validation loss: 2.6584439662195023

Epoch: 5| Step: 8
Training loss: 2.7017955780029297
Validation loss: 2.65407814774462

Epoch: 5| Step: 9
Training loss: 2.818371295928955
Validation loss: 2.6620023019852175

Epoch: 5| Step: 10
Training loss: 3.630741834640503
Validation loss: 2.6662502955364924

Epoch: 39| Step: 0
Training loss: 2.084322452545166
Validation loss: 2.6727316841002433

Epoch: 5| Step: 1
Training loss: 2.6561834812164307
Validation loss: 2.655243799250613

Epoch: 5| Step: 2
Training loss: 3.375054121017456
Validation loss: 2.6560563682228007

Epoch: 5| Step: 3
Training loss: 3.0667226314544678
Validation loss: 2.6433170380130893

Epoch: 5| Step: 4
Training loss: 3.0348079204559326
Validation loss: 2.644632488168696

Epoch: 5| Step: 5
Training loss: 2.564424991607666
Validation loss: 2.650524534204955

Epoch: 5| Step: 6
Training loss: 3.125260829925537
Validation loss: 2.6579382752859466

Epoch: 5| Step: 7
Training loss: 2.653529405593872
Validation loss: 2.6632439013450377

Epoch: 5| Step: 8
Training loss: 3.2178733348846436
Validation loss: 2.6472028968154744

Epoch: 5| Step: 9
Training loss: 2.6095595359802246
Validation loss: 2.646849542535761

Epoch: 5| Step: 10
Training loss: 2.662832260131836
Validation loss: 2.650189591992286

Epoch: 40| Step: 0
Training loss: 2.707247495651245
Validation loss: 2.6540687238016436

Epoch: 5| Step: 1
Training loss: 2.804300546646118
Validation loss: 2.656918341113675

Epoch: 5| Step: 2
Training loss: 3.245187759399414
Validation loss: 2.6453329875905025

Epoch: 5| Step: 3
Training loss: 2.9143881797790527
Validation loss: 2.643102894547165

Epoch: 5| Step: 4
Training loss: 2.951328992843628
Validation loss: 2.635829787100515

Epoch: 5| Step: 5
Training loss: 2.845970869064331
Validation loss: 2.6350090811329503

Epoch: 5| Step: 6
Training loss: 2.041597604751587
Validation loss: 2.630837422545238

Epoch: 5| Step: 7
Training loss: 2.4763245582580566
Validation loss: 2.636372532895816

Epoch: 5| Step: 8
Training loss: 2.851280689239502
Validation loss: 2.638646633394303

Epoch: 5| Step: 9
Training loss: 2.589869260787964
Validation loss: 2.6393410057149906

Epoch: 5| Step: 10
Training loss: 3.6929101943969727
Validation loss: 2.632990978097403

Epoch: 41| Step: 0
Training loss: 2.212801456451416
Validation loss: 2.6326711562372025

Epoch: 5| Step: 1
Training loss: 3.815308094024658
Validation loss: 2.629523523392216

Epoch: 5| Step: 2
Training loss: 2.4422099590301514
Validation loss: 2.6268319237616753

Epoch: 5| Step: 3
Training loss: 2.9544854164123535
Validation loss: 2.6240811065960954

Epoch: 5| Step: 4
Training loss: 1.667137861251831
Validation loss: 2.6245371398105415

Epoch: 5| Step: 5
Training loss: 3.3732948303222656
Validation loss: 2.619574826250794

Epoch: 5| Step: 6
Training loss: 3.382267713546753
Validation loss: 2.6265519716406382

Epoch: 5| Step: 7
Training loss: 3.2539660930633545
Validation loss: 2.622085953271517

Epoch: 5| Step: 8
Training loss: 2.6017465591430664
Validation loss: 2.623608717354395

Epoch: 5| Step: 9
Training loss: 2.4388720989227295
Validation loss: 2.6212532699749036

Epoch: 5| Step: 10
Training loss: 2.66019868850708
Validation loss: 2.6229623825319353

Epoch: 42| Step: 0
Training loss: 2.5594046115875244
Validation loss: 2.6250301740502797

Epoch: 5| Step: 1
Training loss: 2.762892246246338
Validation loss: 2.624714128432735

Epoch: 5| Step: 2
Training loss: 2.6652467250823975
Validation loss: 2.6244140235326623

Epoch: 5| Step: 3
Training loss: 2.6237401962280273
Validation loss: 2.627109637824438

Epoch: 5| Step: 4
Training loss: 3.4595580101013184
Validation loss: 2.6263709657935688

Epoch: 5| Step: 5
Training loss: 2.734862804412842
Validation loss: 2.627766998865271

Epoch: 5| Step: 6
Training loss: 3.0267415046691895
Validation loss: 2.6299605882295998

Epoch: 5| Step: 7
Training loss: 3.384239912033081
Validation loss: 2.6257855199998423

Epoch: 5| Step: 8
Training loss: 2.43039608001709
Validation loss: 2.62510093053182

Epoch: 5| Step: 9
Training loss: 2.4502506256103516
Validation loss: 2.6225051495336715

Epoch: 5| Step: 10
Training loss: 2.8115646839141846
Validation loss: 2.621232973631992

Epoch: 43| Step: 0
Training loss: 2.4859304428100586
Validation loss: 2.621916381261682

Epoch: 5| Step: 1
Training loss: 3.5415358543395996
Validation loss: 2.6208970315994753

Epoch: 5| Step: 2
Training loss: 2.1760497093200684
Validation loss: 2.6288531518751577

Epoch: 5| Step: 3
Training loss: 2.40037202835083
Validation loss: 2.633081236193257

Epoch: 5| Step: 4
Training loss: 2.980247974395752
Validation loss: 2.6491933612413305

Epoch: 5| Step: 5
Training loss: 2.347670793533325
Validation loss: 2.645076121053388

Epoch: 5| Step: 6
Training loss: 2.4832324981689453
Validation loss: 2.648219023981402

Epoch: 5| Step: 7
Training loss: 2.9661316871643066
Validation loss: 2.647061117233769

Epoch: 5| Step: 8
Training loss: 3.3901031017303467
Validation loss: 2.638069855269565

Epoch: 5| Step: 9
Training loss: 3.026127815246582
Validation loss: 2.6205450488675024

Epoch: 5| Step: 10
Training loss: 3.028414011001587
Validation loss: 2.613011247368269

Epoch: 44| Step: 0
Training loss: 2.2713706493377686
Validation loss: 2.6099798833170245

Epoch: 5| Step: 1
Training loss: 2.939542293548584
Validation loss: 2.6131174384906726

Epoch: 5| Step: 2
Training loss: 2.867093563079834
Validation loss: 2.6140495487438735

Epoch: 5| Step: 3
Training loss: 2.907996416091919
Validation loss: 2.6143423998227684

Epoch: 5| Step: 4
Training loss: 2.222785711288452
Validation loss: 2.6181213753197783

Epoch: 5| Step: 5
Training loss: 3.4022021293640137
Validation loss: 2.6138778578850532

Epoch: 5| Step: 6
Training loss: 2.7485692501068115
Validation loss: 2.6131896280473277

Epoch: 5| Step: 7
Training loss: 2.93865966796875
Validation loss: 2.6132092937346427

Epoch: 5| Step: 8
Training loss: 3.067418336868286
Validation loss: 2.614607710992136

Epoch: 5| Step: 9
Training loss: 2.527714490890503
Validation loss: 2.6226204851622223

Epoch: 5| Step: 10
Training loss: 2.8508002758026123
Validation loss: 2.6228542148426013

Epoch: 45| Step: 0
Training loss: 2.4403274059295654
Validation loss: 2.625085433324178

Epoch: 5| Step: 1
Training loss: 3.510761260986328
Validation loss: 2.6253607990921184

Epoch: 5| Step: 2
Training loss: 2.2991106510162354
Validation loss: 2.6140849359573854

Epoch: 5| Step: 3
Training loss: 2.7864603996276855
Validation loss: 2.6078905213263726

Epoch: 5| Step: 4
Training loss: 2.783398389816284
Validation loss: 2.6078875910851265

Epoch: 5| Step: 5
Training loss: 2.3552355766296387
Validation loss: 2.606773022682436

Epoch: 5| Step: 6
Training loss: 2.591360092163086
Validation loss: 2.6068901067139

Epoch: 5| Step: 7
Training loss: 3.445107936859131
Validation loss: 2.605963558279058

Epoch: 5| Step: 8
Training loss: 2.5923807621002197
Validation loss: 2.6071438558640017

Epoch: 5| Step: 9
Training loss: 2.7609362602233887
Validation loss: 2.603513538196523

Epoch: 5| Step: 10
Training loss: 3.122343063354492
Validation loss: 2.60356980241755

Epoch: 46| Step: 0
Training loss: 2.454157829284668
Validation loss: 2.6022112779719855

Epoch: 5| Step: 1
Training loss: 2.8142082691192627
Validation loss: 2.601200431905767

Epoch: 5| Step: 2
Training loss: 2.8609907627105713
Validation loss: 2.6036810669847714

Epoch: 5| Step: 3
Training loss: 2.8059921264648438
Validation loss: 2.601003216158959

Epoch: 5| Step: 4
Training loss: 2.7152552604675293
Validation loss: 2.5996389619765745

Epoch: 5| Step: 5
Training loss: 3.0855369567871094
Validation loss: 2.5981931071127615

Epoch: 5| Step: 6
Training loss: 3.0794739723205566
Validation loss: 2.5977391478835896

Epoch: 5| Step: 7
Training loss: 3.2229201793670654
Validation loss: 2.6038392128482943

Epoch: 5| Step: 8
Training loss: 2.2269186973571777
Validation loss: 2.6047455726131314

Epoch: 5| Step: 9
Training loss: 2.3662214279174805
Validation loss: 2.611489419014223

Epoch: 5| Step: 10
Training loss: 2.9339759349823
Validation loss: 2.6090582903995307

Epoch: 47| Step: 0
Training loss: 2.6414077281951904
Validation loss: 2.6036715481870916

Epoch: 5| Step: 1
Training loss: 3.137456178665161
Validation loss: 2.6003057110694145

Epoch: 5| Step: 2
Training loss: 2.1529481410980225
Validation loss: 2.602881275197511

Epoch: 5| Step: 3
Training loss: 3.0151619911193848
Validation loss: 2.6018534809030514

Epoch: 5| Step: 4
Training loss: 2.941693067550659
Validation loss: 2.6016167235630814

Epoch: 5| Step: 5
Training loss: 2.878958225250244
Validation loss: 2.5996454992601947

Epoch: 5| Step: 6
Training loss: 2.814948081970215
Validation loss: 2.600197381870721

Epoch: 5| Step: 7
Training loss: 2.586371421813965
Validation loss: 2.596557460805421

Epoch: 5| Step: 8
Training loss: 3.5650858879089355
Validation loss: 2.5990191633983324

Epoch: 5| Step: 9
Training loss: 2.3266589641571045
Validation loss: 2.5992864024254585

Epoch: 5| Step: 10
Training loss: 2.351997137069702
Validation loss: 2.598599649244739

Epoch: 48| Step: 0
Training loss: 2.5866761207580566
Validation loss: 2.592204583588467

Epoch: 5| Step: 1
Training loss: 2.9932479858398438
Validation loss: 2.5921437407052643

Epoch: 5| Step: 2
Training loss: 2.4517765045166016
Validation loss: 2.5987924170750443

Epoch: 5| Step: 3
Training loss: 2.9260013103485107
Validation loss: 2.6012764925597818

Epoch: 5| Step: 4
Training loss: 2.783219814300537
Validation loss: 2.605222286716584

Epoch: 5| Step: 5
Training loss: 2.6426808834075928
Validation loss: 2.616289051630164

Epoch: 5| Step: 6
Training loss: 2.206727981567383
Validation loss: 2.6279910995114233

Epoch: 5| Step: 7
Training loss: 3.712057590484619
Validation loss: 2.640554112772788

Epoch: 5| Step: 8
Training loss: 2.2629876136779785
Validation loss: 2.6385927969409573

Epoch: 5| Step: 9
Training loss: 2.9744620323181152
Validation loss: 2.6367007122244885

Epoch: 5| Step: 10
Training loss: 3.137956380844116
Validation loss: 2.6333881475592174

Epoch: 49| Step: 0
Training loss: 3.254610776901245
Validation loss: 2.6334514746101956

Epoch: 5| Step: 1
Training loss: 3.657268524169922
Validation loss: 2.630925081109488

Epoch: 5| Step: 2
Training loss: 2.5955071449279785
Validation loss: 2.6290017353591097

Epoch: 5| Step: 3
Training loss: 2.7729909420013428
Validation loss: 2.629614260888869

Epoch: 5| Step: 4
Training loss: 2.172755718231201
Validation loss: 2.633881409962972

Epoch: 5| Step: 5
Training loss: 2.7532567977905273
Validation loss: 2.6324227330505208

Epoch: 5| Step: 6
Training loss: 2.3939340114593506
Validation loss: 2.627608742765201

Epoch: 5| Step: 7
Training loss: 3.1309378147125244
Validation loss: 2.6268767900364374

Epoch: 5| Step: 8
Training loss: 2.6299142837524414
Validation loss: 2.6284625350788073

Epoch: 5| Step: 9
Training loss: 2.6864919662475586
Validation loss: 2.6261395228806363

Epoch: 5| Step: 10
Training loss: 2.6298696994781494
Validation loss: 2.6265247509043705

Epoch: 50| Step: 0
Training loss: 3.201321840286255
Validation loss: 2.6350238656484954

Epoch: 5| Step: 1
Training loss: 2.4765431880950928
Validation loss: 2.6325687234119703

Epoch: 5| Step: 2
Training loss: 2.290719509124756
Validation loss: 2.632384700159873

Epoch: 5| Step: 3
Training loss: 2.8868045806884766
Validation loss: 2.632033719811388

Epoch: 5| Step: 4
Training loss: 2.715792179107666
Validation loss: 2.6244833007935555

Epoch: 5| Step: 5
Training loss: 3.1088109016418457
Validation loss: 2.6212513780081146

Epoch: 5| Step: 6
Training loss: 2.9296767711639404
Validation loss: 2.6109078878997476

Epoch: 5| Step: 7
Training loss: 2.8803930282592773
Validation loss: 2.6016854240048315

Epoch: 5| Step: 8
Training loss: 2.587083101272583
Validation loss: 2.599341630935669

Epoch: 5| Step: 9
Training loss: 2.591412305831909
Validation loss: 2.603273686542306

Epoch: 5| Step: 10
Training loss: 3.0730838775634766
Validation loss: 2.5951550237594114

Epoch: 51| Step: 0
Training loss: 2.3234457969665527
Validation loss: 2.5806212476504746

Epoch: 5| Step: 1
Training loss: 2.506995439529419
Validation loss: 2.578156396906863

Epoch: 5| Step: 2
Training loss: 2.618077516555786
Validation loss: 2.587223296524376

Epoch: 5| Step: 3
Training loss: 2.5571351051330566
Validation loss: 2.597026435277795

Epoch: 5| Step: 4
Training loss: 2.3531413078308105
Validation loss: 2.6042028550178773

Epoch: 5| Step: 5
Training loss: 3.568429946899414
Validation loss: 2.6022862670242146

Epoch: 5| Step: 6
Training loss: 2.8738396167755127
Validation loss: 2.6078927593846477

Epoch: 5| Step: 7
Training loss: 2.7219340801239014
Validation loss: 2.5906780945357455

Epoch: 5| Step: 8
Training loss: 2.7586777210235596
Validation loss: 2.584377464427743

Epoch: 5| Step: 9
Training loss: 3.304929256439209
Validation loss: 2.5891050574600056

Epoch: 5| Step: 10
Training loss: 2.7355358600616455
Validation loss: 2.5811870457023702

Epoch: 52| Step: 0
Training loss: 3.0019819736480713
Validation loss: 2.5796256757551626

Epoch: 5| Step: 1
Training loss: 2.493978500366211
Validation loss: 2.581988952493155

Epoch: 5| Step: 2
Training loss: 3.116602659225464
Validation loss: 2.585130745364774

Epoch: 5| Step: 3
Training loss: 2.8031582832336426
Validation loss: 2.5862841965049825

Epoch: 5| Step: 4
Training loss: 2.8931803703308105
Validation loss: 2.5769542878673923

Epoch: 5| Step: 5
Training loss: 2.1330599784851074
Validation loss: 2.5725927173450427

Epoch: 5| Step: 6
Training loss: 2.6329305171966553
Validation loss: 2.5705468782814602

Epoch: 5| Step: 7
Training loss: 2.755924701690674
Validation loss: 2.5745857095205658

Epoch: 5| Step: 8
Training loss: 2.6228766441345215
Validation loss: 2.58632731181319

Epoch: 5| Step: 9
Training loss: 3.207223892211914
Validation loss: 2.589447549594346

Epoch: 5| Step: 10
Training loss: 2.6993539333343506
Validation loss: 2.582842767879527

Epoch: 53| Step: 0
Training loss: 2.9953773021698
Validation loss: 2.5823345030507734

Epoch: 5| Step: 1
Training loss: 1.416725993156433
Validation loss: 2.575315352409117

Epoch: 5| Step: 2
Training loss: 2.846351146697998
Validation loss: 2.5728839135939077

Epoch: 5| Step: 3
Training loss: 2.4992082118988037
Validation loss: 2.57364409969699

Epoch: 5| Step: 4
Training loss: 3.1031858921051025
Validation loss: 2.568910519282023

Epoch: 5| Step: 5
Training loss: 2.586202621459961
Validation loss: 2.5838236654958417

Epoch: 5| Step: 6
Training loss: 2.841881036758423
Validation loss: 2.602449281241304

Epoch: 5| Step: 7
Training loss: 2.5195658206939697
Validation loss: 2.6129612486849547

Epoch: 5| Step: 8
Training loss: 2.968914270401001
Validation loss: 2.6055444158533567

Epoch: 5| Step: 9
Training loss: 2.930147647857666
Validation loss: 2.5978055025941584

Epoch: 5| Step: 10
Training loss: 3.8607985973358154
Validation loss: 2.5864548708802912

Epoch: 54| Step: 0
Training loss: 2.127530336380005
Validation loss: 2.5662117542759066

Epoch: 5| Step: 1
Training loss: 3.165386915206909
Validation loss: 2.5676663639724895

Epoch: 5| Step: 2
Training loss: 2.4906790256500244
Validation loss: 2.571085981143418

Epoch: 5| Step: 3
Training loss: 3.763889789581299
Validation loss: 2.598269283130605

Epoch: 5| Step: 4
Training loss: 2.9733338356018066
Validation loss: 2.602747289083337

Epoch: 5| Step: 5
Training loss: 3.004394292831421
Validation loss: 2.5868520531603085

Epoch: 5| Step: 6
Training loss: 2.7723991870880127
Validation loss: 2.5689262420900407

Epoch: 5| Step: 7
Training loss: 2.8567264080047607
Validation loss: 2.5614957911993868

Epoch: 5| Step: 8
Training loss: 2.559998035430908
Validation loss: 2.5593525363552954

Epoch: 5| Step: 9
Training loss: 2.4844419956207275
Validation loss: 2.561397846027087

Epoch: 5| Step: 10
Training loss: 2.02435302734375
Validation loss: 2.572873418049146

Epoch: 55| Step: 0
Training loss: 2.51527738571167
Validation loss: 2.5899374946471183

Epoch: 5| Step: 1
Training loss: 2.5334665775299072
Validation loss: 2.5890792262169624

Epoch: 5| Step: 2
Training loss: 2.9489448070526123
Validation loss: 2.583822593894056

Epoch: 5| Step: 3
Training loss: 2.7470548152923584
Validation loss: 2.573850075403849

Epoch: 5| Step: 4
Training loss: 3.3149266242980957
Validation loss: 2.5679519650756673

Epoch: 5| Step: 5
Training loss: 3.1206624507904053
Validation loss: 2.570185110133181

Epoch: 5| Step: 6
Training loss: 2.2348549365997314
Validation loss: 2.572953401073333

Epoch: 5| Step: 7
Training loss: 2.5225830078125
Validation loss: 2.57455874002108

Epoch: 5| Step: 8
Training loss: 2.7982254028320312
Validation loss: 2.56709094970457

Epoch: 5| Step: 9
Training loss: 2.466264247894287
Validation loss: 2.5627786087733444

Epoch: 5| Step: 10
Training loss: 3.3385441303253174
Validation loss: 2.5599048906756985

Epoch: 56| Step: 0
Training loss: 2.631852626800537
Validation loss: 2.556671457905923

Epoch: 5| Step: 1
Training loss: 2.782201051712036
Validation loss: 2.5601806973898285

Epoch: 5| Step: 2
Training loss: 2.513446092605591
Validation loss: 2.5649483152615127

Epoch: 5| Step: 3
Training loss: 4.017857551574707
Validation loss: 2.5690520194268998

Epoch: 5| Step: 4
Training loss: 1.8271068334579468
Validation loss: 2.5645265425405195

Epoch: 5| Step: 5
Training loss: 2.2781519889831543
Validation loss: 2.5674724399402575

Epoch: 5| Step: 6
Training loss: 2.9647722244262695
Validation loss: 2.5600708376976753

Epoch: 5| Step: 7
Training loss: 2.913564920425415
Validation loss: 2.5560829254888717

Epoch: 5| Step: 8
Training loss: 2.8773903846740723
Validation loss: 2.5548210733680317

Epoch: 5| Step: 9
Training loss: 2.3824586868286133
Validation loss: 2.557059298279465

Epoch: 5| Step: 10
Training loss: 3.006963014602661
Validation loss: 2.552726448223155

Epoch: 57| Step: 0
Training loss: 1.8423793315887451
Validation loss: 2.5456159960839058

Epoch: 5| Step: 1
Training loss: 2.8962807655334473
Validation loss: 2.5487279084420975

Epoch: 5| Step: 2
Training loss: 2.130781888961792
Validation loss: 2.550870108348067

Epoch: 5| Step: 3
Training loss: 3.189664125442505
Validation loss: 2.5512025587020384

Epoch: 5| Step: 4
Training loss: 3.05177903175354
Validation loss: 2.5478355141096216

Epoch: 5| Step: 5
Training loss: 2.1843507289886475
Validation loss: 2.5510090089613393

Epoch: 5| Step: 6
Training loss: 3.036290168762207
Validation loss: 2.5549065272013345

Epoch: 5| Step: 7
Training loss: 2.879004955291748
Validation loss: 2.552531994799132

Epoch: 5| Step: 8
Training loss: 3.13033127784729
Validation loss: 2.5524877553345053

Epoch: 5| Step: 9
Training loss: 2.7240700721740723
Validation loss: 2.5400650757615284

Epoch: 5| Step: 10
Training loss: 3.0596282482147217
Validation loss: 2.542344800887569

Epoch: 58| Step: 0
Training loss: 3.021345853805542
Validation loss: 2.5384366153388895

Epoch: 5| Step: 1
Training loss: 2.401414394378662
Validation loss: 2.545817639238091

Epoch: 5| Step: 2
Training loss: 2.675962209701538
Validation loss: 2.5492014500402633

Epoch: 5| Step: 3
Training loss: 2.6642329692840576
Validation loss: 2.5509370398777786

Epoch: 5| Step: 4
Training loss: 2.906062602996826
Validation loss: 2.5489743166072394

Epoch: 5| Step: 5
Training loss: 3.0604662895202637
Validation loss: 2.547170836438415

Epoch: 5| Step: 6
Training loss: 3.637917995452881
Validation loss: 2.544744522340836

Epoch: 5| Step: 7
Training loss: 2.4961256980895996
Validation loss: 2.54027126168692

Epoch: 5| Step: 8
Training loss: 2.341374635696411
Validation loss: 2.5346802460250033

Epoch: 5| Step: 9
Training loss: 2.613950252532959
Validation loss: 2.5313913309445946

Epoch: 5| Step: 10
Training loss: 2.271972417831421
Validation loss: 2.537215427685809

Epoch: 59| Step: 0
Training loss: 2.476632595062256
Validation loss: 2.5347667483873266

Epoch: 5| Step: 1
Training loss: 1.8086252212524414
Validation loss: 2.5376970127064693

Epoch: 5| Step: 2
Training loss: 2.8510189056396484
Validation loss: 2.5412550715989966

Epoch: 5| Step: 3
Training loss: 2.318159580230713
Validation loss: 2.54477765739605

Epoch: 5| Step: 4
Training loss: 3.317610263824463
Validation loss: 2.5460527737935386

Epoch: 5| Step: 5
Training loss: 3.153452157974243
Validation loss: 2.5409683514666814

Epoch: 5| Step: 6
Training loss: 3.3519668579101562
Validation loss: 2.5402280515240085

Epoch: 5| Step: 7
Training loss: 2.758486032485962
Validation loss: 2.5347409581625335

Epoch: 5| Step: 8
Training loss: 2.7426576614379883
Validation loss: 2.5407345141133955

Epoch: 5| Step: 9
Training loss: 2.475165605545044
Validation loss: 2.534526894169469

Epoch: 5| Step: 10
Training loss: 2.812926769256592
Validation loss: 2.536437242261825

Epoch: 60| Step: 0
Training loss: 2.5093979835510254
Validation loss: 2.5401385676476265

Epoch: 5| Step: 1
Training loss: 3.0595693588256836
Validation loss: 2.5407385108291463

Epoch: 5| Step: 2
Training loss: 2.2519586086273193
Validation loss: 2.540114971899217

Epoch: 5| Step: 3
Training loss: 3.1005027294158936
Validation loss: 2.539121748298727

Epoch: 5| Step: 4
Training loss: 3.0932869911193848
Validation loss: 2.5386720421493694

Epoch: 5| Step: 5
Training loss: 2.85585355758667
Validation loss: 2.53938788752402

Epoch: 5| Step: 6
Training loss: 2.2105469703674316
Validation loss: 2.5382640284876667

Epoch: 5| Step: 7
Training loss: 3.2050445079803467
Validation loss: 2.5415855761497252

Epoch: 5| Step: 8
Training loss: 2.8923022747039795
Validation loss: 2.539531374490389

Epoch: 5| Step: 9
Training loss: 2.933168888092041
Validation loss: 2.5396498480150775

Epoch: 5| Step: 10
Training loss: 1.7432042360305786
Validation loss: 2.5421317469689155

Epoch: 61| Step: 0
Training loss: 2.9352047443389893
Validation loss: 2.544896653903428

Epoch: 5| Step: 1
Training loss: 2.11442232131958
Validation loss: 2.5482056525445755

Epoch: 5| Step: 2
Training loss: 3.2889068126678467
Validation loss: 2.551421526939638

Epoch: 5| Step: 3
Training loss: 2.899686336517334
Validation loss: 2.55357696676767

Epoch: 5| Step: 4
Training loss: 2.455639362335205
Validation loss: 2.5464921177074475

Epoch: 5| Step: 5
Training loss: 2.846986770629883
Validation loss: 2.5396408804001345

Epoch: 5| Step: 6
Training loss: 2.7219719886779785
Validation loss: 2.537718093523415

Epoch: 5| Step: 7
Training loss: 2.7208807468414307
Validation loss: 2.5364905608597623

Epoch: 5| Step: 8
Training loss: 2.339110851287842
Validation loss: 2.530424194951211

Epoch: 5| Step: 9
Training loss: 2.8341031074523926
Validation loss: 2.531154073694701

Epoch: 5| Step: 10
Training loss: 2.8198909759521484
Validation loss: 2.5318347331016295

Epoch: 62| Step: 0
Training loss: 2.3507943153381348
Validation loss: 2.5318101452242945

Epoch: 5| Step: 1
Training loss: 2.1791460514068604
Validation loss: 2.5347473775186846

Epoch: 5| Step: 2
Training loss: 2.5872857570648193
Validation loss: 2.5334901860965195

Epoch: 5| Step: 3
Training loss: 2.8034865856170654
Validation loss: 2.5309627645759174

Epoch: 5| Step: 4
Training loss: 3.059934139251709
Validation loss: 2.53159559670315

Epoch: 5| Step: 5
Training loss: 2.634398937225342
Validation loss: 2.5294093060237106

Epoch: 5| Step: 6
Training loss: 2.128777027130127
Validation loss: 2.5322921788820656

Epoch: 5| Step: 7
Training loss: 3.4111297130584717
Validation loss: 2.5323735437085553

Epoch: 5| Step: 8
Training loss: 2.904350996017456
Validation loss: 2.5304043395544893

Epoch: 5| Step: 9
Training loss: 2.982588052749634
Validation loss: 2.525082251077057

Epoch: 5| Step: 10
Training loss: 2.9001402854919434
Validation loss: 2.5227310760046846

Epoch: 63| Step: 0
Training loss: 2.6636438369750977
Validation loss: 2.523976815644131

Epoch: 5| Step: 1
Training loss: 3.1880385875701904
Validation loss: 2.5222421000080724

Epoch: 5| Step: 2
Training loss: 2.6281986236572266
Validation loss: 2.5267357954414944

Epoch: 5| Step: 3
Training loss: 2.9070005416870117
Validation loss: 2.5230434543343

Epoch: 5| Step: 4
Training loss: 2.817890167236328
Validation loss: 2.522693516105734

Epoch: 5| Step: 5
Training loss: 2.8293700218200684
Validation loss: 2.523857009026312

Epoch: 5| Step: 6
Training loss: 2.668328046798706
Validation loss: 2.526215076446533

Epoch: 5| Step: 7
Training loss: 2.8387653827667236
Validation loss: 2.5364813163716304

Epoch: 5| Step: 8
Training loss: 2.888772487640381
Validation loss: 2.548577518873317

Epoch: 5| Step: 9
Training loss: 2.2547662258148193
Validation loss: 2.540648559088348

Epoch: 5| Step: 10
Training loss: 2.234956741333008
Validation loss: 2.526007011372556

Epoch: 64| Step: 0
Training loss: 2.9272351264953613
Validation loss: 2.524264033122729

Epoch: 5| Step: 1
Training loss: 3.010263681411743
Validation loss: 2.515504957527243

Epoch: 5| Step: 2
Training loss: 3.067145586013794
Validation loss: 2.520654760381227

Epoch: 5| Step: 3
Training loss: 2.7363619804382324
Validation loss: 2.5277524507173927

Epoch: 5| Step: 4
Training loss: 2.8578383922576904
Validation loss: 2.5370593276075137

Epoch: 5| Step: 5
Training loss: 2.3496787548065186
Validation loss: 2.5502918612572456

Epoch: 5| Step: 6
Training loss: 2.9843292236328125
Validation loss: 2.55171376146296

Epoch: 5| Step: 7
Training loss: 2.4858384132385254
Validation loss: 2.539411703745524

Epoch: 5| Step: 8
Training loss: 2.4463565349578857
Validation loss: 2.5367718999103834

Epoch: 5| Step: 9
Training loss: 2.3014259338378906
Validation loss: 2.529634144998366

Epoch: 5| Step: 10
Training loss: 2.9711780548095703
Validation loss: 2.5164403197585896

Epoch: 65| Step: 0
Training loss: 2.004293918609619
Validation loss: 2.5158594756998043

Epoch: 5| Step: 1
Training loss: 2.480104446411133
Validation loss: 2.5154627087295696

Epoch: 5| Step: 2
Training loss: 2.0725345611572266
Validation loss: 2.519727204435615

Epoch: 5| Step: 3
Training loss: 3.0414600372314453
Validation loss: 2.5327853246401717

Epoch: 5| Step: 4
Training loss: 2.5309789180755615
Validation loss: 2.545530057722522

Epoch: 5| Step: 5
Training loss: 3.441072940826416
Validation loss: 2.546235135806504

Epoch: 5| Step: 6
Training loss: 3.2030861377716064
Validation loss: 2.537969043177943

Epoch: 5| Step: 7
Training loss: 2.6359026432037354
Validation loss: 2.5307607368756364

Epoch: 5| Step: 8
Training loss: 3.398951768875122
Validation loss: 2.5178176203081684

Epoch: 5| Step: 9
Training loss: 2.434709072113037
Validation loss: 2.507759448020689

Epoch: 5| Step: 10
Training loss: 2.678273916244507
Validation loss: 2.5076441175194195

Epoch: 66| Step: 0
Training loss: 3.037604808807373
Validation loss: 2.5104370835006877

Epoch: 5| Step: 1
Training loss: 2.8585150241851807
Validation loss: 2.5130278653995965

Epoch: 5| Step: 2
Training loss: 2.507781505584717
Validation loss: 2.520973649076236

Epoch: 5| Step: 3
Training loss: 2.482006311416626
Validation loss: 2.521741287682646

Epoch: 5| Step: 4
Training loss: 2.6206958293914795
Validation loss: 2.5195558763319448

Epoch: 5| Step: 5
Training loss: 2.725299119949341
Validation loss: 2.52236589565072

Epoch: 5| Step: 6
Training loss: 2.5354743003845215
Validation loss: 2.5164403761586835

Epoch: 5| Step: 7
Training loss: 2.9200243949890137
Validation loss: 2.515062011698241

Epoch: 5| Step: 8
Training loss: 3.4461047649383545
Validation loss: 2.507081300981583

Epoch: 5| Step: 9
Training loss: 2.885430097579956
Validation loss: 2.5046529410987772

Epoch: 5| Step: 10
Training loss: 1.8246674537658691
Validation loss: 2.5072996565090713

Epoch: 67| Step: 0
Training loss: 2.34000825881958
Validation loss: 2.5058342256853656

Epoch: 5| Step: 1
Training loss: 2.717406749725342
Validation loss: 2.511565867290702

Epoch: 5| Step: 2
Training loss: 2.1711719036102295
Validation loss: 2.513495981052358

Epoch: 5| Step: 3
Training loss: 3.004863977432251
Validation loss: 2.5132686656008483

Epoch: 5| Step: 4
Training loss: 2.953211545944214
Validation loss: 2.5104134236612627

Epoch: 5| Step: 5
Training loss: 2.698044776916504
Validation loss: 2.519591740382615

Epoch: 5| Step: 6
Training loss: 3.174546718597412
Validation loss: 2.5180634478087067

Epoch: 5| Step: 7
Training loss: 2.2458415031433105
Validation loss: 2.520790002679312

Epoch: 5| Step: 8
Training loss: 3.245861768722534
Validation loss: 2.526712776512228

Epoch: 5| Step: 9
Training loss: 2.5875394344329834
Validation loss: 2.518144174288678

Epoch: 5| Step: 10
Training loss: 2.7315828800201416
Validation loss: 2.5187260976401706

Epoch: 68| Step: 0
Training loss: 2.8952670097351074
Validation loss: 2.5154901883935414

Epoch: 5| Step: 1
Training loss: 2.997509717941284
Validation loss: 2.5107172535311792

Epoch: 5| Step: 2
Training loss: 3.1252994537353516
Validation loss: 2.5120244128729707

Epoch: 5| Step: 3
Training loss: 2.7377126216888428
Validation loss: 2.5045648031337286

Epoch: 5| Step: 4
Training loss: 2.269646167755127
Validation loss: 2.499931889195596

Epoch: 5| Step: 5
Training loss: 3.1204917430877686
Validation loss: 2.5015521587864047

Epoch: 5| Step: 6
Training loss: 3.019378900527954
Validation loss: 2.501536435978387

Epoch: 5| Step: 7
Training loss: 2.463135242462158
Validation loss: 2.5023920023313133

Epoch: 5| Step: 8
Training loss: 2.498574733734131
Validation loss: 2.502834230340937

Epoch: 5| Step: 9
Training loss: 1.77633798122406
Validation loss: 2.499957405110841

Epoch: 5| Step: 10
Training loss: 2.9093825817108154
Validation loss: 2.499381911370062

Epoch: 69| Step: 0
Training loss: 2.05509614944458
Validation loss: 2.4997420413519746

Epoch: 5| Step: 1
Training loss: 3.824030637741089
Validation loss: 2.5067365348979993

Epoch: 5| Step: 2
Training loss: 2.9266481399536133
Validation loss: 2.507190926100618

Epoch: 5| Step: 3
Training loss: 2.889382839202881
Validation loss: 2.5210335446942236

Epoch: 5| Step: 4
Training loss: 3.097353458404541
Validation loss: 2.526972770690918

Epoch: 5| Step: 5
Training loss: 2.327737331390381
Validation loss: 2.5228912317624657

Epoch: 5| Step: 6
Training loss: 2.5666093826293945
Validation loss: 2.5055819890832387

Epoch: 5| Step: 7
Training loss: 2.310136556625366
Validation loss: 2.4980046800387803

Epoch: 5| Step: 8
Training loss: 2.9246342182159424
Validation loss: 2.499008709384549

Epoch: 5| Step: 9
Training loss: 2.754093647003174
Validation loss: 2.5004221931580575

Epoch: 5| Step: 10
Training loss: 2.038743734359741
Validation loss: 2.502416818372665

Epoch: 70| Step: 0
Training loss: 2.580232620239258
Validation loss: 2.5043877324750348

Epoch: 5| Step: 1
Training loss: 1.842065453529358
Validation loss: 2.502643105804279

Epoch: 5| Step: 2
Training loss: 2.9721426963806152
Validation loss: 2.507917356747453

Epoch: 5| Step: 3
Training loss: 2.717317581176758
Validation loss: 2.505125472622533

Epoch: 5| Step: 4
Training loss: 2.8825905323028564
Validation loss: 2.5060753771053847

Epoch: 5| Step: 5
Training loss: 2.906933069229126
Validation loss: 2.4985896592499106

Epoch: 5| Step: 6
Training loss: 3.237769603729248
Validation loss: 2.501719303028558

Epoch: 5| Step: 7
Training loss: 2.8019909858703613
Validation loss: 2.509614121529364

Epoch: 5| Step: 8
Training loss: 2.21419095993042
Validation loss: 2.5194878091094313

Epoch: 5| Step: 9
Training loss: 2.9951248168945312
Validation loss: 2.5240262272537395

Epoch: 5| Step: 10
Training loss: 2.67494797706604
Validation loss: 2.5203483848161596

Epoch: 71| Step: 0
Training loss: 2.4055464267730713
Validation loss: 2.5065593206754295

Epoch: 5| Step: 1
Training loss: 2.3715121746063232
Validation loss: 2.4942597676348943

Epoch: 5| Step: 2
Training loss: 3.238649368286133
Validation loss: 2.4932218008143927

Epoch: 5| Step: 3
Training loss: 2.321040153503418
Validation loss: 2.4888966365527083

Epoch: 5| Step: 4
Training loss: 2.551753520965576
Validation loss: 2.489162088722311

Epoch: 5| Step: 5
Training loss: 2.6733880043029785
Validation loss: 2.499868587781024

Epoch: 5| Step: 6
Training loss: 2.6024889945983887
Validation loss: 2.5104398573598554

Epoch: 5| Step: 7
Training loss: 3.1066722869873047
Validation loss: 2.509450997075727

Epoch: 5| Step: 8
Training loss: 1.7786706686019897
Validation loss: 2.520724545242966

Epoch: 5| Step: 9
Training loss: 3.3996658325195312
Validation loss: 2.509366694317069

Epoch: 5| Step: 10
Training loss: 3.369234085083008
Validation loss: 2.497981809800671

Epoch: 72| Step: 0
Training loss: 2.4383416175842285
Validation loss: 2.495547233089324

Epoch: 5| Step: 1
Training loss: 2.9533023834228516
Validation loss: 2.495341980329124

Epoch: 5| Step: 2
Training loss: 2.801924228668213
Validation loss: 2.4948435188621603

Epoch: 5| Step: 3
Training loss: 2.1700916290283203
Validation loss: 2.49643144043543

Epoch: 5| Step: 4
Training loss: 2.589860439300537
Validation loss: 2.4956189688815864

Epoch: 5| Step: 5
Training loss: 3.225651264190674
Validation loss: 2.4962314918477047

Epoch: 5| Step: 6
Training loss: 2.9597463607788086
Validation loss: 2.4993193687931186

Epoch: 5| Step: 7
Training loss: 3.075939416885376
Validation loss: 2.5011107178144556

Epoch: 5| Step: 8
Training loss: 2.458632469177246
Validation loss: 2.500922892683296

Epoch: 5| Step: 9
Training loss: 2.7220380306243896
Validation loss: 2.5030580156592914

Epoch: 5| Step: 10
Training loss: 2.1775808334350586
Validation loss: 2.494953155517578

Epoch: 73| Step: 0
Training loss: 3.328354597091675
Validation loss: 2.492805181011077

Epoch: 5| Step: 1
Training loss: 3.6750903129577637
Validation loss: 2.5016128427238873

Epoch: 5| Step: 2
Training loss: 2.8787894248962402
Validation loss: 2.4947365637748473

Epoch: 5| Step: 3
Training loss: 2.3919577598571777
Validation loss: 2.4928012714591077

Epoch: 5| Step: 4
Training loss: 2.2164406776428223
Validation loss: 2.496690942395118

Epoch: 5| Step: 5
Training loss: 2.2082056999206543
Validation loss: 2.496506298741987

Epoch: 5| Step: 6
Training loss: 3.1326496601104736
Validation loss: 2.4904207337287163

Epoch: 5| Step: 7
Training loss: 2.7942893505096436
Validation loss: 2.504733529142154

Epoch: 5| Step: 8
Training loss: 2.5092997550964355
Validation loss: 2.5161994452117593

Epoch: 5| Step: 9
Training loss: 2.6224305629730225
Validation loss: 2.526027497424874

Epoch: 5| Step: 10
Training loss: 1.7605397701263428
Validation loss: 2.521157390327864

Epoch: 74| Step: 0
Training loss: 2.4237606525421143
Validation loss: 2.505331952084777

Epoch: 5| Step: 1
Training loss: 2.4451699256896973
Validation loss: 2.49451716228198

Epoch: 5| Step: 2
Training loss: 3.060554027557373
Validation loss: 2.4921046046800512

Epoch: 5| Step: 3
Training loss: 2.443652629852295
Validation loss: 2.4922773197133052

Epoch: 5| Step: 4
Training loss: 2.6629347801208496
Validation loss: 2.490687821501045

Epoch: 5| Step: 5
Training loss: 3.2600555419921875
Validation loss: 2.494024228024226

Epoch: 5| Step: 6
Training loss: 2.8530380725860596
Validation loss: 2.495191935570009

Epoch: 5| Step: 7
Training loss: 2.487933397293091
Validation loss: 2.4891510573766564

Epoch: 5| Step: 8
Training loss: 2.205850601196289
Validation loss: 2.4835787806459653

Epoch: 5| Step: 9
Training loss: 2.4951603412628174
Validation loss: 2.4842711469178558

Epoch: 5| Step: 10
Training loss: 3.3518190383911133
Validation loss: 2.4835681479464293

Epoch: 75| Step: 0
Training loss: 3.4506497383117676
Validation loss: 2.4846829265676518

Epoch: 5| Step: 1
Training loss: 3.5108656883239746
Validation loss: 2.4855479296817573

Epoch: 5| Step: 2
Training loss: 2.681830644607544
Validation loss: 2.4833671405751216

Epoch: 5| Step: 3
Training loss: 2.811802864074707
Validation loss: 2.4851228344825005

Epoch: 5| Step: 4
Training loss: 2.7184438705444336
Validation loss: 2.480737183683662

Epoch: 5| Step: 5
Training loss: 2.6206510066986084
Validation loss: 2.4845965370055167

Epoch: 5| Step: 6
Training loss: 2.2109122276306152
Validation loss: 2.478240143868231

Epoch: 5| Step: 7
Training loss: 2.190464496612549
Validation loss: 2.4770135418061288

Epoch: 5| Step: 8
Training loss: 2.568742275238037
Validation loss: 2.4832584499030985

Epoch: 5| Step: 9
Training loss: 2.343501091003418
Validation loss: 2.485965854378157

Epoch: 5| Step: 10
Training loss: 2.5353033542633057
Validation loss: 2.4799046952237367

Epoch: 76| Step: 0
Training loss: 2.979372501373291
Validation loss: 2.4833161113082722

Epoch: 5| Step: 1
Training loss: 2.239276885986328
Validation loss: 2.484021771338678

Epoch: 5| Step: 2
Training loss: 3.0344197750091553
Validation loss: 2.4812194224326842

Epoch: 5| Step: 3
Training loss: 2.6383862495422363
Validation loss: 2.4808627572110904

Epoch: 5| Step: 4
Training loss: 2.4697723388671875
Validation loss: 2.48569421358006

Epoch: 5| Step: 5
Training loss: 3.2334072589874268
Validation loss: 2.48045438848516

Epoch: 5| Step: 6
Training loss: 2.799370288848877
Validation loss: 2.4843787018970778

Epoch: 5| Step: 7
Training loss: 2.601378917694092
Validation loss: 2.4826037806849324

Epoch: 5| Step: 8
Training loss: 2.510361671447754
Validation loss: 2.480910926736811

Epoch: 5| Step: 9
Training loss: 2.576760768890381
Validation loss: 2.4808065109355475

Epoch: 5| Step: 10
Training loss: 2.403245210647583
Validation loss: 2.480276066769836

Epoch: 77| Step: 0
Training loss: 2.1347949504852295
Validation loss: 2.4889680313807663

Epoch: 5| Step: 1
Training loss: 3.147383689880371
Validation loss: 2.4862231208432104

Epoch: 5| Step: 2
Training loss: 2.412179470062256
Validation loss: 2.4812716719924763

Epoch: 5| Step: 3
Training loss: 3.0597293376922607
Validation loss: 2.4813055146125054

Epoch: 5| Step: 4
Training loss: 3.7471535205841064
Validation loss: 2.4802183540918494

Epoch: 5| Step: 5
Training loss: 3.077639102935791
Validation loss: 2.483382437818794

Epoch: 5| Step: 6
Training loss: 2.356898546218872
Validation loss: 2.480761161414526

Epoch: 5| Step: 7
Training loss: 1.9726871252059937
Validation loss: 2.47697441808639

Epoch: 5| Step: 8
Training loss: 2.6116013526916504
Validation loss: 2.4714046268052954

Epoch: 5| Step: 9
Training loss: 2.7944068908691406
Validation loss: 2.473638485836726

Epoch: 5| Step: 10
Training loss: 2.1257998943328857
Validation loss: 2.4741807394130255

Epoch: 78| Step: 0
Training loss: 2.8781208992004395
Validation loss: 2.4782399849225114

Epoch: 5| Step: 1
Training loss: 2.569958209991455
Validation loss: 2.4776309638895015

Epoch: 5| Step: 2
Training loss: 2.855286121368408
Validation loss: 2.485392009058306

Epoch: 5| Step: 3
Training loss: 2.657343864440918
Validation loss: 2.485472732974637

Epoch: 5| Step: 4
Training loss: 3.3019118309020996
Validation loss: 2.4857173555640766

Epoch: 5| Step: 5
Training loss: 2.7932066917419434
Validation loss: 2.481639826169578

Epoch: 5| Step: 6
Training loss: 2.93562912940979
Validation loss: 2.487860207916588

Epoch: 5| Step: 7
Training loss: 2.709134817123413
Validation loss: 2.4951241529116066

Epoch: 5| Step: 8
Training loss: 2.1217286586761475
Validation loss: 2.5014338236983105

Epoch: 5| Step: 9
Training loss: 2.235861301422119
Validation loss: 2.513840477953675

Epoch: 5| Step: 10
Training loss: 2.4660868644714355
Validation loss: 2.5175177948449248

Epoch: 79| Step: 0
Training loss: 2.7881722450256348
Validation loss: 2.4938649900497927

Epoch: 5| Step: 1
Training loss: 2.663017749786377
Validation loss: 2.4924037943604174

Epoch: 5| Step: 2
Training loss: 3.290374755859375
Validation loss: 2.4828381769118772

Epoch: 5| Step: 3
Training loss: 3.100188732147217
Validation loss: 2.487704846166795

Epoch: 5| Step: 4
Training loss: 2.2362236976623535
Validation loss: 2.4947519994551137

Epoch: 5| Step: 5
Training loss: 2.6876838207244873
Validation loss: 2.5122938463764806

Epoch: 5| Step: 6
Training loss: 2.1507177352905273
Validation loss: 2.495186500651862

Epoch: 5| Step: 7
Training loss: 2.7614359855651855
Validation loss: 2.4867305396705546

Epoch: 5| Step: 8
Training loss: 2.35853910446167
Validation loss: 2.4785377133277153

Epoch: 5| Step: 9
Training loss: 2.4506046772003174
Validation loss: 2.468565728074761

Epoch: 5| Step: 10
Training loss: 3.1580700874328613
Validation loss: 2.4717386230345695

Epoch: 80| Step: 0
Training loss: 1.794889211654663
Validation loss: 2.4698476304290113

Epoch: 5| Step: 1
Training loss: 2.97929048538208
Validation loss: 2.475571337566581

Epoch: 5| Step: 2
Training loss: 2.4441492557525635
Validation loss: 2.482473870759369

Epoch: 5| Step: 3
Training loss: 2.1161773204803467
Validation loss: 2.4881340047364593

Epoch: 5| Step: 4
Training loss: 3.415564775466919
Validation loss: 2.4834266785652406

Epoch: 5| Step: 5
Training loss: 2.559051036834717
Validation loss: 2.486038190062328

Epoch: 5| Step: 6
Training loss: 2.5852737426757812
Validation loss: 2.4806492661917083

Epoch: 5| Step: 7
Training loss: 2.6952168941497803
Validation loss: 2.4753517873825563

Epoch: 5| Step: 8
Training loss: 2.9096627235412598
Validation loss: 2.473178140578731

Epoch: 5| Step: 9
Training loss: 3.4530982971191406
Validation loss: 2.469798949456984

Epoch: 5| Step: 10
Training loss: 2.7198779582977295
Validation loss: 2.465526719247141

Epoch: 81| Step: 0
Training loss: 2.0549373626708984
Validation loss: 2.4715092797433176

Epoch: 5| Step: 1
Training loss: 2.1459970474243164
Validation loss: 2.481359884303103

Epoch: 5| Step: 2
Training loss: 2.9481215476989746
Validation loss: 2.485255438794372

Epoch: 5| Step: 3
Training loss: 3.074842691421509
Validation loss: 2.488714979540917

Epoch: 5| Step: 4
Training loss: 2.7053725719451904
Validation loss: 2.4880927788314

Epoch: 5| Step: 5
Training loss: 2.972681999206543
Validation loss: 2.494081853538431

Epoch: 5| Step: 6
Training loss: 2.513305187225342
Validation loss: 2.4936597116531862

Epoch: 5| Step: 7
Training loss: 3.235269069671631
Validation loss: 2.4804082788446897

Epoch: 5| Step: 8
Training loss: 3.3904476165771484
Validation loss: 2.478830296506164

Epoch: 5| Step: 9
Training loss: 2.1480181217193604
Validation loss: 2.4738505527537358

Epoch: 5| Step: 10
Training loss: 2.3233232498168945
Validation loss: 2.4775432155978296

Epoch: 82| Step: 0
Training loss: 2.874629020690918
Validation loss: 2.4768982805231565

Epoch: 5| Step: 1
Training loss: 2.916797399520874
Validation loss: 2.491208940423945

Epoch: 5| Step: 2
Training loss: 2.2770397663116455
Validation loss: 2.505167543247182

Epoch: 5| Step: 3
Training loss: 3.188655138015747
Validation loss: 2.486445455140965

Epoch: 5| Step: 4
Training loss: 2.5850958824157715
Validation loss: 2.462985959104312

Epoch: 5| Step: 5
Training loss: 2.379570484161377
Validation loss: 2.4584874952993085

Epoch: 5| Step: 6
Training loss: 2.630295753479004
Validation loss: 2.457381509965466

Epoch: 5| Step: 7
Training loss: 2.9854674339294434
Validation loss: 2.4593959469949045

Epoch: 5| Step: 8
Training loss: 2.3403820991516113
Validation loss: 2.464713840074437

Epoch: 5| Step: 9
Training loss: 2.3417179584503174
Validation loss: 2.4626592538690053

Epoch: 5| Step: 10
Training loss: 3.062798023223877
Validation loss: 2.4614424884960218

Epoch: 83| Step: 0
Training loss: 2.9701919555664062
Validation loss: 2.4583917587034163

Epoch: 5| Step: 1
Training loss: 3.0156967639923096
Validation loss: 2.45499857266744

Epoch: 5| Step: 2
Training loss: 2.7312090396881104
Validation loss: 2.4548321385537424

Epoch: 5| Step: 3
Training loss: 2.903489351272583
Validation loss: 2.460375888373262

Epoch: 5| Step: 4
Training loss: 2.7567875385284424
Validation loss: 2.455861735087569

Epoch: 5| Step: 5
Training loss: 2.476167678833008
Validation loss: 2.4536859502074537

Epoch: 5| Step: 6
Training loss: 2.0306735038757324
Validation loss: 2.466031356524396

Epoch: 5| Step: 7
Training loss: 3.059080123901367
Validation loss: 2.473152470845048

Epoch: 5| Step: 8
Training loss: 2.1968700885772705
Validation loss: 2.4835162778054514

Epoch: 5| Step: 9
Training loss: 2.627070665359497
Validation loss: 2.4902528896126697

Epoch: 5| Step: 10
Training loss: 2.6596810817718506
Validation loss: 2.497200163461829

Epoch: 84| Step: 0
Training loss: 2.7940261363983154
Validation loss: 2.5041230724703882

Epoch: 5| Step: 1
Training loss: 2.484513521194458
Validation loss: 2.512651120462725

Epoch: 5| Step: 2
Training loss: 3.1007211208343506
Validation loss: 2.504988255039338

Epoch: 5| Step: 3
Training loss: 2.540034770965576
Validation loss: 2.5203891928477953

Epoch: 5| Step: 4
Training loss: 2.4813475608825684
Validation loss: 2.519053372003699

Epoch: 5| Step: 5
Training loss: 2.8678433895111084
Validation loss: 2.492350116852791

Epoch: 5| Step: 6
Training loss: 2.6629371643066406
Validation loss: 2.4853459942725395

Epoch: 5| Step: 7
Training loss: 2.329526901245117
Validation loss: 2.485606247378934

Epoch: 5| Step: 8
Training loss: 2.7289233207702637
Validation loss: 2.4806948323403635

Epoch: 5| Step: 9
Training loss: 2.874953031539917
Validation loss: 2.472858505864297

Epoch: 5| Step: 10
Training loss: 2.6139514446258545
Validation loss: 2.4678650927800003

Epoch: 85| Step: 0
Training loss: 3.10821795463562
Validation loss: 2.460002790215195

Epoch: 5| Step: 1
Training loss: 2.8073480129241943
Validation loss: 2.4599019788926646

Epoch: 5| Step: 2
Training loss: 2.4433043003082275
Validation loss: 2.461078307961905

Epoch: 5| Step: 3
Training loss: 2.800912618637085
Validation loss: 2.4646725346965175

Epoch: 5| Step: 4
Training loss: 2.63897967338562
Validation loss: 2.4632816724879767

Epoch: 5| Step: 5
Training loss: 2.785311698913574
Validation loss: 2.4607762085494174

Epoch: 5| Step: 6
Training loss: 2.9443278312683105
Validation loss: 2.4596544657984087

Epoch: 5| Step: 7
Training loss: 3.136237621307373
Validation loss: 2.461048280039141

Epoch: 5| Step: 8
Training loss: 2.0800657272338867
Validation loss: 2.456915427279729

Epoch: 5| Step: 9
Training loss: 2.4790124893188477
Validation loss: 2.4543050873664116

Epoch: 5| Step: 10
Training loss: 2.2106552124023438
Validation loss: 2.451451793793709

Epoch: 86| Step: 0
Training loss: 2.5982887744903564
Validation loss: 2.4613940433789323

Epoch: 5| Step: 1
Training loss: 2.1704444885253906
Validation loss: 2.462788528011691

Epoch: 5| Step: 2
Training loss: 2.4146974086761475
Validation loss: 2.464274419251309

Epoch: 5| Step: 3
Training loss: 2.9482476711273193
Validation loss: 2.4690008522361837

Epoch: 5| Step: 4
Training loss: 2.660470724105835
Validation loss: 2.4675170298545592

Epoch: 5| Step: 5
Training loss: 3.431811571121216
Validation loss: 2.4564542462748866

Epoch: 5| Step: 6
Training loss: 2.449967861175537
Validation loss: 2.460919218678628

Epoch: 5| Step: 7
Training loss: 2.6129231452941895
Validation loss: 2.4621752744079917

Epoch: 5| Step: 8
Training loss: 2.4457221031188965
Validation loss: 2.4577806162577804

Epoch: 5| Step: 9
Training loss: 2.9266440868377686
Validation loss: 2.4673233673136723

Epoch: 5| Step: 10
Training loss: 2.710034132003784
Validation loss: 2.466112723914526

Epoch: 87| Step: 0
Training loss: 2.6902031898498535
Validation loss: 2.4919246268528763

Epoch: 5| Step: 1
Training loss: 2.9887075424194336
Validation loss: 2.4987310030127086

Epoch: 5| Step: 2
Training loss: 3.027428388595581
Validation loss: 2.4881038460680234

Epoch: 5| Step: 3
Training loss: 2.3790252208709717
Validation loss: 2.4643996915509625

Epoch: 5| Step: 4
Training loss: 2.627263307571411
Validation loss: 2.454083727252099

Epoch: 5| Step: 5
Training loss: 3.208460569381714
Validation loss: 2.4514796195491666

Epoch: 5| Step: 6
Training loss: 2.673100709915161
Validation loss: 2.453999924403365

Epoch: 5| Step: 7
Training loss: 2.166346311569214
Validation loss: 2.450901646767893

Epoch: 5| Step: 8
Training loss: 3.1061184406280518
Validation loss: 2.456916812927492

Epoch: 5| Step: 9
Training loss: 2.558662176132202
Validation loss: 2.4599439610717115

Epoch: 5| Step: 10
Training loss: 1.823563575744629
Validation loss: 2.456222029142482

Epoch: 88| Step: 0
Training loss: 2.3737001419067383
Validation loss: 2.454524017149402

Epoch: 5| Step: 1
Training loss: 2.3885467052459717
Validation loss: 2.4522888224612

Epoch: 5| Step: 2
Training loss: 2.6793060302734375
Validation loss: 2.4544312928312566

Epoch: 5| Step: 3
Training loss: 2.369243621826172
Validation loss: 2.456502487582545

Epoch: 5| Step: 4
Training loss: 2.9859888553619385
Validation loss: 2.4634262643834597

Epoch: 5| Step: 5
Training loss: 2.962446689605713
Validation loss: 2.47125937861781

Epoch: 5| Step: 6
Training loss: 3.15553617477417
Validation loss: 2.4939651104711715

Epoch: 5| Step: 7
Training loss: 3.2190260887145996
Validation loss: 2.5149861945900867

Epoch: 5| Step: 8
Training loss: 1.8945903778076172
Validation loss: 2.52114204437502

Epoch: 5| Step: 9
Training loss: 2.8243584632873535
Validation loss: 2.530613660812378

Epoch: 5| Step: 10
Training loss: 2.6774470806121826
Validation loss: 2.4832891264269428

Epoch: 89| Step: 0
Training loss: 2.80218505859375
Validation loss: 2.4632298946380615

Epoch: 5| Step: 1
Training loss: 2.284511089324951
Validation loss: 2.4545086660692768

Epoch: 5| Step: 2
Training loss: 3.4191555976867676
Validation loss: 2.4547236542547903

Epoch: 5| Step: 3
Training loss: 3.0982768535614014
Validation loss: 2.4661197380353044

Epoch: 5| Step: 4
Training loss: 2.0498979091644287
Validation loss: 2.48157335353154

Epoch: 5| Step: 5
Training loss: 2.7060561180114746
Validation loss: 2.470972261121196

Epoch: 5| Step: 6
Training loss: 3.2838287353515625
Validation loss: 2.474707334272323

Epoch: 5| Step: 7
Training loss: 2.6485397815704346
Validation loss: 2.468601970262425

Epoch: 5| Step: 8
Training loss: 2.117934465408325
Validation loss: 2.4605362235858874

Epoch: 5| Step: 9
Training loss: 2.142214298248291
Validation loss: 2.4653374354044595

Epoch: 5| Step: 10
Training loss: 2.862854480743408
Validation loss: 2.475752608750456

Epoch: 90| Step: 0
Training loss: 2.190829038619995
Validation loss: 2.483968451458921

Epoch: 5| Step: 1
Training loss: 2.753952741622925
Validation loss: 2.4880242757899786

Epoch: 5| Step: 2
Training loss: 2.5364909172058105
Validation loss: 2.4650327428694694

Epoch: 5| Step: 3
Training loss: 2.668361186981201
Validation loss: 2.4515275686017928

Epoch: 5| Step: 4
Training loss: 2.901292562484741
Validation loss: 2.4480186431638655

Epoch: 5| Step: 5
Training loss: 2.5038182735443115
Validation loss: 2.4431856191286476

Epoch: 5| Step: 6
Training loss: 2.3921072483062744
Validation loss: 2.451602779408937

Epoch: 5| Step: 7
Training loss: 2.5777196884155273
Validation loss: 2.46454361689988

Epoch: 5| Step: 8
Training loss: 3.0798096656799316
Validation loss: 2.4650200925847536

Epoch: 5| Step: 9
Training loss: 2.5821027755737305
Validation loss: 2.461050243787868

Epoch: 5| Step: 10
Training loss: 3.1969149112701416
Validation loss: 2.4668452483351513

Epoch: 91| Step: 0
Training loss: 2.8167521953582764
Validation loss: 2.4594584664990826

Epoch: 5| Step: 1
Training loss: 2.733985424041748
Validation loss: 2.447452909202986

Epoch: 5| Step: 2
Training loss: 2.419623613357544
Validation loss: 2.439433326003372

Epoch: 5| Step: 3
Training loss: 2.9749233722686768
Validation loss: 2.436989600940417

Epoch: 5| Step: 4
Training loss: 2.5436477661132812
Validation loss: 2.4329080735483477

Epoch: 5| Step: 5
Training loss: 2.4758238792419434
Validation loss: 2.434060242868239

Epoch: 5| Step: 6
Training loss: 3.347996473312378
Validation loss: 2.4360960952697264

Epoch: 5| Step: 7
Training loss: 1.9641649723052979
Validation loss: 2.438741712160008

Epoch: 5| Step: 8
Training loss: 3.3212947845458984
Validation loss: 2.4496245486761934

Epoch: 5| Step: 9
Training loss: 1.9482648372650146
Validation loss: 2.4551094834522535

Epoch: 5| Step: 10
Training loss: 2.760854959487915
Validation loss: 2.4516727693619265

Epoch: 92| Step: 0
Training loss: 2.4011013507843018
Validation loss: 2.4386587373671995

Epoch: 5| Step: 1
Training loss: 2.9263885021209717
Validation loss: 2.439726124527634

Epoch: 5| Step: 2
Training loss: 2.2553789615631104
Validation loss: 2.4377375110503166

Epoch: 5| Step: 3
Training loss: 2.5646166801452637
Validation loss: 2.435974105711906

Epoch: 5| Step: 4
Training loss: 3.066524028778076
Validation loss: 2.4334591152847453

Epoch: 5| Step: 5
Training loss: 2.7109858989715576
Validation loss: 2.430290109367781

Epoch: 5| Step: 6
Training loss: 2.719938278198242
Validation loss: 2.437037601265856

Epoch: 5| Step: 7
Training loss: 3.2451281547546387
Validation loss: 2.4328566289717153

Epoch: 5| Step: 8
Training loss: 1.9389041662216187
Validation loss: 2.4373614608600573

Epoch: 5| Step: 9
Training loss: 2.7333812713623047
Validation loss: 2.4341396080550326

Epoch: 5| Step: 10
Training loss: 2.7683651447296143
Validation loss: 2.436931574216453

Epoch: 93| Step: 0
Training loss: 2.2505905628204346
Validation loss: 2.433490578846265

Epoch: 5| Step: 1
Training loss: 3.110029935836792
Validation loss: 2.4321567396963797

Epoch: 5| Step: 2
Training loss: 2.342400074005127
Validation loss: 2.437766695535311

Epoch: 5| Step: 3
Training loss: 2.7727811336517334
Validation loss: 2.4448165047553276

Epoch: 5| Step: 4
Training loss: 2.863799571990967
Validation loss: 2.4550638865399104

Epoch: 5| Step: 5
Training loss: 2.634779453277588
Validation loss: 2.459057825867848

Epoch: 5| Step: 6
Training loss: 2.535996913909912
Validation loss: 2.467811425526937

Epoch: 5| Step: 7
Training loss: 2.849254608154297
Validation loss: 2.4660808655523483

Epoch: 5| Step: 8
Training loss: 2.6908955574035645
Validation loss: 2.4529907472672

Epoch: 5| Step: 9
Training loss: 2.47080135345459
Validation loss: 2.448349916806785

Epoch: 5| Step: 10
Training loss: 2.860201120376587
Validation loss: 2.445935267274098

Epoch: 94| Step: 0
Training loss: 2.650383472442627
Validation loss: 2.4365451874271518

Epoch: 5| Step: 1
Training loss: 2.446854591369629
Validation loss: 2.4339514957961215

Epoch: 5| Step: 2
Training loss: 2.715318202972412
Validation loss: 2.433564034841394

Epoch: 5| Step: 3
Training loss: 3.2165284156799316
Validation loss: 2.4360304391512306

Epoch: 5| Step: 4
Training loss: 2.6935322284698486
Validation loss: 2.4336112929928686

Epoch: 5| Step: 5
Training loss: 3.147007942199707
Validation loss: 2.433086533700266

Epoch: 5| Step: 6
Training loss: 2.6139957904815674
Validation loss: 2.4300974363921792

Epoch: 5| Step: 7
Training loss: 2.2991669178009033
Validation loss: 2.4385454141965477

Epoch: 5| Step: 8
Training loss: 3.0342700481414795
Validation loss: 2.4462075694914787

Epoch: 5| Step: 9
Training loss: 2.1664512157440186
Validation loss: 2.449957534831057

Epoch: 5| Step: 10
Training loss: 2.1732277870178223
Validation loss: 2.459842392193374

Epoch: 95| Step: 0
Training loss: 3.0976340770721436
Validation loss: 2.472930457002373

Epoch: 5| Step: 1
Training loss: 2.4574971199035645
Validation loss: 2.474956145850561

Epoch: 5| Step: 2
Training loss: 3.343182325363159
Validation loss: 2.480479468581497

Epoch: 5| Step: 3
Training loss: 2.654153823852539
Validation loss: 2.4696944939192904

Epoch: 5| Step: 4
Training loss: 2.9666762351989746
Validation loss: 2.4515203942534742

Epoch: 5| Step: 5
Training loss: 2.3175694942474365
Validation loss: 2.455039939572734

Epoch: 5| Step: 6
Training loss: 2.527010440826416
Validation loss: 2.4878155621149207

Epoch: 5| Step: 7
Training loss: 2.756929874420166
Validation loss: 2.5244422292196624

Epoch: 5| Step: 8
Training loss: 2.452374219894409
Validation loss: 2.536663609166299

Epoch: 5| Step: 9
Training loss: 2.6290667057037354
Validation loss: 2.5535874212941816

Epoch: 5| Step: 10
Training loss: 2.1841049194335938
Validation loss: 2.5543511016394502

Epoch: 96| Step: 0
Training loss: 2.6340198516845703
Validation loss: 2.5500886901732414

Epoch: 5| Step: 1
Training loss: 3.084761142730713
Validation loss: 2.5165206693833873

Epoch: 5| Step: 2
Training loss: 2.323789119720459
Validation loss: 2.4894872993551274

Epoch: 5| Step: 3
Training loss: 2.6234657764434814
Validation loss: 2.478508460906244

Epoch: 5| Step: 4
Training loss: 3.3109378814697266
Validation loss: 2.462028154762842

Epoch: 5| Step: 5
Training loss: 2.532538890838623
Validation loss: 2.458925688138572

Epoch: 5| Step: 6
Training loss: 1.9788682460784912
Validation loss: 2.450712542380056

Epoch: 5| Step: 7
Training loss: 2.472856044769287
Validation loss: 2.450736653420233

Epoch: 5| Step: 8
Training loss: 2.074514865875244
Validation loss: 2.442892510403869

Epoch: 5| Step: 9
Training loss: 3.1707518100738525
Validation loss: 2.4403454924142487

Epoch: 5| Step: 10
Training loss: 3.371151924133301
Validation loss: 2.4390889701022895

Epoch: 97| Step: 0
Training loss: 2.337764024734497
Validation loss: 2.4336342298856346

Epoch: 5| Step: 1
Training loss: 3.231835126876831
Validation loss: 2.43694947355537

Epoch: 5| Step: 2
Training loss: 2.40944504737854
Validation loss: 2.4342068831125894

Epoch: 5| Step: 3
Training loss: 2.8975179195404053
Validation loss: 2.427257635260141

Epoch: 5| Step: 4
Training loss: 2.7265803813934326
Validation loss: 2.4304301738739014

Epoch: 5| Step: 5
Training loss: 2.430166721343994
Validation loss: 2.424186868052329

Epoch: 5| Step: 6
Training loss: 2.657738208770752
Validation loss: 2.422471107975129

Epoch: 5| Step: 7
Training loss: 2.521122694015503
Validation loss: 2.4204765673606627

Epoch: 5| Step: 8
Training loss: 2.7348434925079346
Validation loss: 2.4196458990855882

Epoch: 5| Step: 9
Training loss: 2.6120874881744385
Validation loss: 2.4239772571030485

Epoch: 5| Step: 10
Training loss: 2.6243791580200195
Validation loss: 2.4250207690782446

Epoch: 98| Step: 0
Training loss: 2.317213535308838
Validation loss: 2.4261619378161687

Epoch: 5| Step: 1
Training loss: 2.7939460277557373
Validation loss: 2.4384268958081483

Epoch: 5| Step: 2
Training loss: 2.2900309562683105
Validation loss: 2.4474810707953667

Epoch: 5| Step: 3
Training loss: 2.7449779510498047
Validation loss: 2.4651300778952976

Epoch: 5| Step: 4
Training loss: 2.8717079162597656
Validation loss: 2.468634943808279

Epoch: 5| Step: 5
Training loss: 2.9719159603118896
Validation loss: 2.461804756554224

Epoch: 5| Step: 6
Training loss: 2.4825897216796875
Validation loss: 2.4471099915043

Epoch: 5| Step: 7
Training loss: 2.663663864135742
Validation loss: 2.4456054997700516

Epoch: 5| Step: 8
Training loss: 2.362488269805908
Validation loss: 2.442389057528588

Epoch: 5| Step: 9
Training loss: 3.705745220184326
Validation loss: 2.43727881164961

Epoch: 5| Step: 10
Training loss: 1.8754488229751587
Validation loss: 2.4282940049325266

Epoch: 99| Step: 0
Training loss: 2.388399600982666
Validation loss: 2.4243211848761446

Epoch: 5| Step: 1
Training loss: 3.0244247913360596
Validation loss: 2.420432634251092

Epoch: 5| Step: 2
Training loss: 3.008445978164673
Validation loss: 2.430622057248187

Epoch: 5| Step: 3
Training loss: 2.406228542327881
Validation loss: 2.430382856758692

Epoch: 5| Step: 4
Training loss: 1.812099814414978
Validation loss: 2.4261701619753273

Epoch: 5| Step: 5
Training loss: 2.7147469520568848
Validation loss: 2.417148954124861

Epoch: 5| Step: 6
Training loss: 2.9813642501831055
Validation loss: 2.415489581323439

Epoch: 5| Step: 7
Training loss: 2.646359443664551
Validation loss: 2.4127452091504167

Epoch: 5| Step: 8
Training loss: 2.6575331687927246
Validation loss: 2.415750503540039

Epoch: 5| Step: 9
Training loss: 2.343003988265991
Validation loss: 2.4120176787017495

Epoch: 5| Step: 10
Training loss: 3.2778565883636475
Validation loss: 2.4115308664178334

Epoch: 100| Step: 0
Training loss: 2.3943169116973877
Validation loss: 2.4133545301293813

Epoch: 5| Step: 1
Training loss: 2.7680258750915527
Validation loss: 2.416989275204238

Epoch: 5| Step: 2
Training loss: 3.091224193572998
Validation loss: 2.4171725203914027

Epoch: 5| Step: 3
Training loss: 3.3078131675720215
Validation loss: 2.4198714558796217

Epoch: 5| Step: 4
Training loss: 3.088606595993042
Validation loss: 2.4202828843106508

Epoch: 5| Step: 5
Training loss: 1.8316972255706787
Validation loss: 2.40948829086878

Epoch: 5| Step: 6
Training loss: 3.02309250831604
Validation loss: 2.4059938641004663

Epoch: 5| Step: 7
Training loss: 2.6443474292755127
Validation loss: 2.4042170791215796

Epoch: 5| Step: 8
Training loss: 1.9228521585464478
Validation loss: 2.407655759524274

Epoch: 5| Step: 9
Training loss: 2.4814815521240234
Validation loss: 2.410752906594225

Epoch: 5| Step: 10
Training loss: 2.502821445465088
Validation loss: 2.407056382907334

Epoch: 101| Step: 0
Training loss: 1.9279098510742188
Validation loss: 2.4108995545294976

Epoch: 5| Step: 1
Training loss: 3.079956293106079
Validation loss: 2.4094127096155638

Epoch: 5| Step: 2
Training loss: 2.137746810913086
Validation loss: 2.404079314201109

Epoch: 5| Step: 3
Training loss: 3.102647304534912
Validation loss: 2.4043723024347776

Epoch: 5| Step: 4
Training loss: 2.8881916999816895
Validation loss: 2.405507667090303

Epoch: 5| Step: 5
Training loss: 1.9686107635498047
Validation loss: 2.4108520195048344

Epoch: 5| Step: 6
Training loss: 3.3777098655700684
Validation loss: 2.41627936978494

Epoch: 5| Step: 7
Training loss: 3.3452861309051514
Validation loss: 2.4214020749574066

Epoch: 5| Step: 8
Training loss: 2.2095303535461426
Validation loss: 2.419923661857523

Epoch: 5| Step: 9
Training loss: 2.4719080924987793
Validation loss: 2.4236804541721138

Epoch: 5| Step: 10
Training loss: 2.5990653038024902
Validation loss: 2.425294722280195

Epoch: 102| Step: 0
Training loss: 3.236865997314453
Validation loss: 2.4240483391669487

Epoch: 5| Step: 1
Training loss: 2.578789234161377
Validation loss: 2.4232753502425326

Epoch: 5| Step: 2
Training loss: 2.294208526611328
Validation loss: 2.4219257011208484

Epoch: 5| Step: 3
Training loss: 2.7792015075683594
Validation loss: 2.41708065361105

Epoch: 5| Step: 4
Training loss: 2.6152570247650146
Validation loss: 2.4163755191269742

Epoch: 5| Step: 5
Training loss: 2.784425735473633
Validation loss: 2.401954250950967

Epoch: 5| Step: 6
Training loss: 2.4693589210510254
Validation loss: 2.404103663659865

Epoch: 5| Step: 7
Training loss: 2.326033115386963
Validation loss: 2.4067112579140613

Epoch: 5| Step: 8
Training loss: 3.1395020484924316
Validation loss: 2.4037362042293755

Epoch: 5| Step: 9
Training loss: 2.2142372131347656
Validation loss: 2.406784733136495

Epoch: 5| Step: 10
Training loss: 2.5669074058532715
Validation loss: 2.409066625820693

Epoch: 103| Step: 0
Training loss: 2.895413637161255
Validation loss: 2.4191953700075866

Epoch: 5| Step: 1
Training loss: 2.420968532562256
Validation loss: 2.411675860804896

Epoch: 5| Step: 2
Training loss: 3.0979411602020264
Validation loss: 2.4121258156273955

Epoch: 5| Step: 3
Training loss: 3.108546733856201
Validation loss: 2.4052841688997004

Epoch: 5| Step: 4
Training loss: 2.1026813983917236
Validation loss: 2.408290119581325

Epoch: 5| Step: 5
Training loss: 2.7270355224609375
Validation loss: 2.4054285121220413

Epoch: 5| Step: 6
Training loss: 2.526218891143799
Validation loss: 2.400555750375153

Epoch: 5| Step: 7
Training loss: 2.456268787384033
Validation loss: 2.397070551431307

Epoch: 5| Step: 8
Training loss: 2.2336180210113525
Validation loss: 2.40385522637316

Epoch: 5| Step: 9
Training loss: 2.5765576362609863
Validation loss: 2.405700296484014

Epoch: 5| Step: 10
Training loss: 2.918459177017212
Validation loss: 2.4194063550682476

Epoch: 104| Step: 0
Training loss: 3.3999104499816895
Validation loss: 2.420174216711393

Epoch: 5| Step: 1
Training loss: 2.2107090950012207
Validation loss: 2.429614115786809

Epoch: 5| Step: 2
Training loss: 2.383780002593994
Validation loss: 2.439896786084739

Epoch: 5| Step: 3
Training loss: 3.3029141426086426
Validation loss: 2.444902409789383

Epoch: 5| Step: 4
Training loss: 3.0044586658477783
Validation loss: 2.4497006221484114

Epoch: 5| Step: 5
Training loss: 2.960906505584717
Validation loss: 2.4535615110910065

Epoch: 5| Step: 6
Training loss: 2.2459495067596436
Validation loss: 2.427267889822683

Epoch: 5| Step: 7
Training loss: 2.1313071250915527
Validation loss: 2.412767012914022

Epoch: 5| Step: 8
Training loss: 2.815504312515259
Validation loss: 2.40563815639865

Epoch: 5| Step: 9
Training loss: 2.1755590438842773
Validation loss: 2.402161052150111

Epoch: 5| Step: 10
Training loss: 2.4558959007263184
Validation loss: 2.4013507263634795

Epoch: 105| Step: 0
Training loss: 2.923217535018921
Validation loss: 2.4001039971587477

Epoch: 5| Step: 1
Training loss: 2.8336124420166016
Validation loss: 2.4053233131285636

Epoch: 5| Step: 2
Training loss: 2.178321599960327
Validation loss: 2.406291251541466

Epoch: 5| Step: 3
Training loss: 2.087083339691162
Validation loss: 2.4173306290821364

Epoch: 5| Step: 4
Training loss: 2.451251268386841
Validation loss: 2.403368208997993

Epoch: 5| Step: 5
Training loss: 2.5513882637023926
Validation loss: 2.402426219755603

Epoch: 5| Step: 6
Training loss: 2.397378444671631
Validation loss: 2.4017831843386412

Epoch: 5| Step: 7
Training loss: 2.739964723587036
Validation loss: 2.391874538954868

Epoch: 5| Step: 8
Training loss: 3.7018020153045654
Validation loss: 2.393498146405784

Epoch: 5| Step: 9
Training loss: 2.1436614990234375
Validation loss: 2.3893512551502516

Epoch: 5| Step: 10
Training loss: 3.0660505294799805
Validation loss: 2.3927841750524377

Epoch: 106| Step: 0
Training loss: 3.3720977306365967
Validation loss: 2.4018324088024836

Epoch: 5| Step: 1
Training loss: 1.9862825870513916
Validation loss: 2.408145535376764

Epoch: 5| Step: 2
Training loss: 3.400019884109497
Validation loss: 2.4160554562845538

Epoch: 5| Step: 3
Training loss: 2.3654122352600098
Validation loss: 2.422813915437268

Epoch: 5| Step: 4
Training loss: 2.7935070991516113
Validation loss: 2.4263011973391295

Epoch: 5| Step: 5
Training loss: 2.4398398399353027
Validation loss: 2.422405327520063

Epoch: 5| Step: 6
Training loss: 2.882802963256836
Validation loss: 2.4313736295187347

Epoch: 5| Step: 7
Training loss: 2.9070751667022705
Validation loss: 2.4251876338835685

Epoch: 5| Step: 8
Training loss: 2.2823479175567627
Validation loss: 2.4136779385228313

Epoch: 5| Step: 9
Training loss: 2.268583297729492
Validation loss: 2.4149583872928413

Epoch: 5| Step: 10
Training loss: 2.2032058238983154
Validation loss: 2.4018470882087626

Epoch: 107| Step: 0
Training loss: 2.6067209243774414
Validation loss: 2.3992002394891556

Epoch: 5| Step: 1
Training loss: 2.4431490898132324
Validation loss: 2.3988068513972785

Epoch: 5| Step: 2
Training loss: 2.4510929584503174
Validation loss: 2.402327929773638

Epoch: 5| Step: 3
Training loss: 2.9368479251861572
Validation loss: 2.4034494687152166

Epoch: 5| Step: 4
Training loss: 3.10097599029541
Validation loss: 2.4007464583202074

Epoch: 5| Step: 5
Training loss: 1.805034875869751
Validation loss: 2.402977162791837

Epoch: 5| Step: 6
Training loss: 2.66462779045105
Validation loss: 2.4002474841251167

Epoch: 5| Step: 7
Training loss: 3.214104175567627
Validation loss: 2.398546746982041

Epoch: 5| Step: 8
Training loss: 3.0849766731262207
Validation loss: 2.398158952754031

Epoch: 5| Step: 9
Training loss: 2.5114829540252686
Validation loss: 2.401613009873257

Epoch: 5| Step: 10
Training loss: 2.0392284393310547
Validation loss: 2.3982318139845327

Epoch: 108| Step: 0
Training loss: 3.1695311069488525
Validation loss: 2.395574679938696

Epoch: 5| Step: 1
Training loss: 2.819176435470581
Validation loss: 2.4004565182552544

Epoch: 5| Step: 2
Training loss: 3.2682526111602783
Validation loss: 2.3952472876476985

Epoch: 5| Step: 3
Training loss: 2.055734157562256
Validation loss: 2.403745876845493

Epoch: 5| Step: 4
Training loss: 2.645458459854126
Validation loss: 2.3946445065159954

Epoch: 5| Step: 5
Training loss: 2.0389933586120605
Validation loss: 2.404047137947493

Epoch: 5| Step: 6
Training loss: 2.2067759037017822
Validation loss: 2.4048255464082122

Epoch: 5| Step: 7
Training loss: 3.021806240081787
Validation loss: 2.39875138959577

Epoch: 5| Step: 8
Training loss: 3.108654499053955
Validation loss: 2.3948241151789182

Epoch: 5| Step: 9
Training loss: 2.343294143676758
Validation loss: 2.3969466019702215

Epoch: 5| Step: 10
Training loss: 2.1280369758605957
Validation loss: 2.3945579990263908

Epoch: 109| Step: 0
Training loss: 3.205519199371338
Validation loss: 2.3925539396142446

Epoch: 5| Step: 1
Training loss: 2.4028167724609375
Validation loss: 2.3911639874981296

Epoch: 5| Step: 2
Training loss: 2.7046971321105957
Validation loss: 2.3883576264945408

Epoch: 5| Step: 3
Training loss: 3.1615777015686035
Validation loss: 2.389170867140575

Epoch: 5| Step: 4
Training loss: 2.7060189247131348
Validation loss: 2.385782775058541

Epoch: 5| Step: 5
Training loss: 2.6527130603790283
Validation loss: 2.382313441204768

Epoch: 5| Step: 6
Training loss: 3.0470399856567383
Validation loss: 2.3833629674808954

Epoch: 5| Step: 7
Training loss: 1.7443653345108032
Validation loss: 2.381809865274737

Epoch: 5| Step: 8
Training loss: 1.9501441717147827
Validation loss: 2.3811444313295427

Epoch: 5| Step: 9
Training loss: 2.689929962158203
Validation loss: 2.3803591023209276

Epoch: 5| Step: 10
Training loss: 2.562453508377075
Validation loss: 2.3779066019160773

Epoch: 110| Step: 0
Training loss: 1.8797216415405273
Validation loss: 2.3799008092572613

Epoch: 5| Step: 1
Training loss: 2.896064281463623
Validation loss: 2.3788438253505255

Epoch: 5| Step: 2
Training loss: 2.320402145385742
Validation loss: 2.382929307158275

Epoch: 5| Step: 3
Training loss: 2.8496148586273193
Validation loss: 2.3819260161410094

Epoch: 5| Step: 4
Training loss: 1.9175891876220703
Validation loss: 2.382483256760464

Epoch: 5| Step: 5
Training loss: 2.595449209213257
Validation loss: 2.3912707195487073

Epoch: 5| Step: 6
Training loss: 2.5732619762420654
Validation loss: 2.3903994893514984

Epoch: 5| Step: 7
Training loss: 2.9254918098449707
Validation loss: 2.3965301513671875

Epoch: 5| Step: 8
Training loss: 2.846628189086914
Validation loss: 2.402438476521482

Epoch: 5| Step: 9
Training loss: 2.8638720512390137
Validation loss: 2.4184567518131708

Epoch: 5| Step: 10
Training loss: 3.2735188007354736
Validation loss: 2.40981706752572

Epoch: 111| Step: 0
Training loss: 3.2006237506866455
Validation loss: 2.4007534570591424

Epoch: 5| Step: 1
Training loss: 3.1927905082702637
Validation loss: 2.3995480229777675

Epoch: 5| Step: 2
Training loss: 2.181457996368408
Validation loss: 2.391121499000057

Epoch: 5| Step: 3
Training loss: 2.344083786010742
Validation loss: 2.3897964210920435

Epoch: 5| Step: 4
Training loss: 2.7735798358917236
Validation loss: 2.3815160220669163

Epoch: 5| Step: 5
Training loss: 2.1929023265838623
Validation loss: 2.393692528047869

Epoch: 5| Step: 6
Training loss: 2.3616738319396973
Validation loss: 2.3900718714601252

Epoch: 5| Step: 7
Training loss: 3.0219779014587402
Validation loss: 2.39244536430605

Epoch: 5| Step: 8
Training loss: 2.7236015796661377
Validation loss: 2.3942826819676224

Epoch: 5| Step: 9
Training loss: 2.709207773208618
Validation loss: 2.3846044271223006

Epoch: 5| Step: 10
Training loss: 1.9847800731658936
Validation loss: 2.3782148194569412

Epoch: 112| Step: 0
Training loss: 2.711108446121216
Validation loss: 2.3825041555589244

Epoch: 5| Step: 1
Training loss: 3.0449957847595215
Validation loss: 2.387376432777733

Epoch: 5| Step: 2
Training loss: 2.366560220718384
Validation loss: 2.390826222717121

Epoch: 5| Step: 3
Training loss: 2.7069082260131836
Validation loss: 2.394580151445122

Epoch: 5| Step: 4
Training loss: 2.792285919189453
Validation loss: 2.39390968507336

Epoch: 5| Step: 5
Training loss: 3.4933669567108154
Validation loss: 2.388802477108535

Epoch: 5| Step: 6
Training loss: 2.197007179260254
Validation loss: 2.38490108777118

Epoch: 5| Step: 7
Training loss: 2.4967925548553467
Validation loss: 2.37275073605199

Epoch: 5| Step: 8
Training loss: 1.8995786905288696
Validation loss: 2.3725016655460482

Epoch: 5| Step: 9
Training loss: 2.3062727451324463
Validation loss: 2.3705975394095145

Epoch: 5| Step: 10
Training loss: 2.759059190750122
Validation loss: 2.372596461285827

Epoch: 113| Step: 0
Training loss: 2.7781636714935303
Validation loss: 2.3758798440297446

Epoch: 5| Step: 1
Training loss: 2.2766385078430176
Validation loss: 2.3719837511739423

Epoch: 5| Step: 2
Training loss: 2.8489153385162354
Validation loss: 2.380169854369215

Epoch: 5| Step: 3
Training loss: 2.262019634246826
Validation loss: 2.3812206381110737

Epoch: 5| Step: 4
Training loss: 2.7648284435272217
Validation loss: 2.3738957630690707

Epoch: 5| Step: 5
Training loss: 3.0724196434020996
Validation loss: 2.3829354034957064

Epoch: 5| Step: 6
Training loss: 2.683938503265381
Validation loss: 2.386557461113058

Epoch: 5| Step: 7
Training loss: 2.9611423015594482
Validation loss: 2.393939748887093

Epoch: 5| Step: 8
Training loss: 2.502932071685791
Validation loss: 2.3939031964989117

Epoch: 5| Step: 9
Training loss: 2.516857385635376
Validation loss: 2.410758933713359

Epoch: 5| Step: 10
Training loss: 1.9687174558639526
Validation loss: 2.4221245447794595

Epoch: 114| Step: 0
Training loss: 3.363251209259033
Validation loss: 2.417989489852741

Epoch: 5| Step: 1
Training loss: 1.7729060649871826
Validation loss: 2.4284990987470074

Epoch: 5| Step: 2
Training loss: 2.247640609741211
Validation loss: 2.448982939925245

Epoch: 5| Step: 3
Training loss: 2.4817392826080322
Validation loss: 2.4728029004989134

Epoch: 5| Step: 4
Training loss: 2.1448988914489746
Validation loss: 2.4604729042258313

Epoch: 5| Step: 5
Training loss: 3.2807812690734863
Validation loss: 2.466586373185599

Epoch: 5| Step: 6
Training loss: 3.1065378189086914
Validation loss: 2.4513919071484636

Epoch: 5| Step: 7
Training loss: 2.5421054363250732
Validation loss: 2.4381728787576

Epoch: 5| Step: 8
Training loss: 2.7539024353027344
Validation loss: 2.4305203473696144

Epoch: 5| Step: 9
Training loss: 2.5362343788146973
Validation loss: 2.4236174527034966

Epoch: 5| Step: 10
Training loss: 2.817934989929199
Validation loss: 2.431414109404369

Epoch: 115| Step: 0
Training loss: 3.109260320663452
Validation loss: 2.432287331550352

Epoch: 5| Step: 1
Training loss: 2.613083839416504
Validation loss: 2.4191114620495866

Epoch: 5| Step: 2
Training loss: 2.33068585395813
Validation loss: 2.3962075377023346

Epoch: 5| Step: 3
Training loss: 2.7399730682373047
Validation loss: 2.4065838347199144

Epoch: 5| Step: 4
Training loss: 2.8584508895874023
Validation loss: 2.387339048488166

Epoch: 5| Step: 5
Training loss: 2.642238140106201
Validation loss: 2.387023223343716

Epoch: 5| Step: 6
Training loss: 2.376544713973999
Validation loss: 2.380201393558133

Epoch: 5| Step: 7
Training loss: 1.9349753856658936
Validation loss: 2.382748055201705

Epoch: 5| Step: 8
Training loss: 3.126753568649292
Validation loss: 2.392824287055641

Epoch: 5| Step: 9
Training loss: 2.228825807571411
Validation loss: 2.385715410273562

Epoch: 5| Step: 10
Training loss: 2.8937275409698486
Validation loss: 2.3795356878670315

Epoch: 116| Step: 0
Training loss: 3.352573871612549
Validation loss: 2.373214647334109

Epoch: 5| Step: 1
Training loss: 2.2712178230285645
Validation loss: 2.3842789511526785

Epoch: 5| Step: 2
Training loss: 3.1564769744873047
Validation loss: 2.4011051680452082

Epoch: 5| Step: 3
Training loss: 2.384321689605713
Validation loss: 2.3872421864540345

Epoch: 5| Step: 4
Training loss: 2.4214816093444824
Validation loss: 2.39095837454642

Epoch: 5| Step: 5
Training loss: 2.4196808338165283
Validation loss: 2.392075089998143

Epoch: 5| Step: 6
Training loss: 2.026468276977539
Validation loss: 2.386460232478316

Epoch: 5| Step: 7
Training loss: 2.6866939067840576
Validation loss: 2.379030196897445

Epoch: 5| Step: 8
Training loss: 2.3519961833953857
Validation loss: 2.382026926163704

Epoch: 5| Step: 9
Training loss: 2.5064611434936523
Validation loss: 2.3737896898741364

Epoch: 5| Step: 10
Training loss: 3.2287375926971436
Validation loss: 2.3697170185786423

Epoch: 117| Step: 0
Training loss: 3.157438278198242
Validation loss: 2.37410492538124

Epoch: 5| Step: 1
Training loss: 2.814553737640381
Validation loss: 2.366509045324018

Epoch: 5| Step: 2
Training loss: 2.570128917694092
Validation loss: 2.3734413346936627

Epoch: 5| Step: 3
Training loss: 2.5628244876861572
Validation loss: 2.3658011574898996

Epoch: 5| Step: 4
Training loss: 2.6797025203704834
Validation loss: 2.3642886197695168

Epoch: 5| Step: 5
Training loss: 1.7545791864395142
Validation loss: 2.3701743720680155

Epoch: 5| Step: 6
Training loss: 2.550130605697632
Validation loss: 2.371965374997867

Epoch: 5| Step: 7
Training loss: 2.3037991523742676
Validation loss: 2.3726359772425827

Epoch: 5| Step: 8
Training loss: 3.0731329917907715
Validation loss: 2.373575218262211

Epoch: 5| Step: 9
Training loss: 2.570032835006714
Validation loss: 2.3636072604886946

Epoch: 5| Step: 10
Training loss: 2.713228225708008
Validation loss: 2.3701962335135347

Epoch: 118| Step: 0
Training loss: 2.6457629203796387
Validation loss: 2.36232094354527

Epoch: 5| Step: 1
Training loss: 2.7413344383239746
Validation loss: 2.3573515722828526

Epoch: 5| Step: 2
Training loss: 2.3599610328674316
Validation loss: 2.364921159641717

Epoch: 5| Step: 3
Training loss: 2.240363597869873
Validation loss: 2.3517329462112917

Epoch: 5| Step: 4
Training loss: 2.5795934200286865
Validation loss: 2.35513275413103

Epoch: 5| Step: 5
Training loss: 2.732609748840332
Validation loss: 2.3549106659427768

Epoch: 5| Step: 6
Training loss: 2.4681599140167236
Validation loss: 2.358240612091557

Epoch: 5| Step: 7
Training loss: 2.3187649250030518
Validation loss: 2.362081330309632

Epoch: 5| Step: 8
Training loss: 3.286823272705078
Validation loss: 2.3654979454573763

Epoch: 5| Step: 9
Training loss: 2.7677364349365234
Validation loss: 2.361691285205144

Epoch: 5| Step: 10
Training loss: 2.4625799655914307
Validation loss: 2.365355299365136

Epoch: 119| Step: 0
Training loss: 3.056246280670166
Validation loss: 2.360744153299639

Epoch: 5| Step: 1
Training loss: 3.0536434650421143
Validation loss: 2.3606789471000753

Epoch: 5| Step: 2
Training loss: 2.3077914714813232
Validation loss: 2.3553088095880326

Epoch: 5| Step: 3
Training loss: 2.623103380203247
Validation loss: 2.350156802003102

Epoch: 5| Step: 4
Training loss: 3.1098625659942627
Validation loss: 2.353507172676825

Epoch: 5| Step: 5
Training loss: 2.110903263092041
Validation loss: 2.3578171524950253

Epoch: 5| Step: 6
Training loss: 2.2195794582366943
Validation loss: 2.3566824159314557

Epoch: 5| Step: 7
Training loss: 2.3862242698669434
Validation loss: 2.355817230798865

Epoch: 5| Step: 8
Training loss: 2.3530378341674805
Validation loss: 2.361880979230327

Epoch: 5| Step: 9
Training loss: 2.9895524978637695
Validation loss: 2.3642402669434905

Epoch: 5| Step: 10
Training loss: 2.3520236015319824
Validation loss: 2.3653656974915536

Epoch: 120| Step: 0
Training loss: 2.4857120513916016
Validation loss: 2.369580712369693

Epoch: 5| Step: 1
Training loss: 2.4527390003204346
Validation loss: 2.373553224789199

Epoch: 5| Step: 2
Training loss: 2.137880325317383
Validation loss: 2.3771508278385287

Epoch: 5| Step: 3
Training loss: 3.013859272003174
Validation loss: 2.375465767357939

Epoch: 5| Step: 4
Training loss: 2.275495767593384
Validation loss: 2.3715115875326176

Epoch: 5| Step: 5
Training loss: 2.582040309906006
Validation loss: 2.364971378798126

Epoch: 5| Step: 6
Training loss: 2.3149514198303223
Validation loss: 2.3630405997717254

Epoch: 5| Step: 7
Training loss: 2.8574273586273193
Validation loss: 2.356278698931458

Epoch: 5| Step: 8
Training loss: 2.5233664512634277
Validation loss: 2.3572498521497174

Epoch: 5| Step: 9
Training loss: 3.2955379486083984
Validation loss: 2.3590471026717976

Epoch: 5| Step: 10
Training loss: 2.6225786209106445
Validation loss: 2.3555883105083177

Epoch: 121| Step: 0
Training loss: 2.2017529010772705
Validation loss: 2.3524001888049546

Epoch: 5| Step: 1
Training loss: 2.088876724243164
Validation loss: 2.3546252430126233

Epoch: 5| Step: 2
Training loss: 2.052239179611206
Validation loss: 2.3578463472345823

Epoch: 5| Step: 3
Training loss: 2.9224727153778076
Validation loss: 2.3594159926137617

Epoch: 5| Step: 4
Training loss: 2.346529483795166
Validation loss: 2.3596804654726418

Epoch: 5| Step: 5
Training loss: 3.277027130126953
Validation loss: 2.357548024064751

Epoch: 5| Step: 6
Training loss: 2.5853705406188965
Validation loss: 2.363327864677675

Epoch: 5| Step: 7
Training loss: 2.936305522918701
Validation loss: 2.3520345303320114

Epoch: 5| Step: 8
Training loss: 3.1115403175354004
Validation loss: 2.351222158760153

Epoch: 5| Step: 9
Training loss: 2.458223342895508
Validation loss: 2.345764790811846

Epoch: 5| Step: 10
Training loss: 2.618082284927368
Validation loss: 2.345359197226904

Epoch: 122| Step: 0
Training loss: 2.1868302822113037
Validation loss: 2.3424731018722698

Epoch: 5| Step: 1
Training loss: 3.0499794483184814
Validation loss: 2.3445954450996975

Epoch: 5| Step: 2
Training loss: 2.252307653427124
Validation loss: 2.3488410647197435

Epoch: 5| Step: 3
Training loss: 2.8218624591827393
Validation loss: 2.347858493046094

Epoch: 5| Step: 4
Training loss: 2.3978793621063232
Validation loss: 2.341569859494445

Epoch: 5| Step: 5
Training loss: 2.704725742340088
Validation loss: 2.3466165399038665

Epoch: 5| Step: 6
Training loss: 2.6384174823760986
Validation loss: 2.346924856144895

Epoch: 5| Step: 7
Training loss: 2.5745863914489746
Validation loss: 2.3543273992435907

Epoch: 5| Step: 8
Training loss: 3.1488680839538574
Validation loss: 2.353488478609311

Epoch: 5| Step: 9
Training loss: 2.6503946781158447
Validation loss: 2.346801742430656

Epoch: 5| Step: 10
Training loss: 2.015951156616211
Validation loss: 2.3477936431925785

Epoch: 123| Step: 0
Training loss: 2.6328039169311523
Validation loss: 2.3438195002976285

Epoch: 5| Step: 1
Training loss: 2.421933174133301
Validation loss: 2.347255722168953

Epoch: 5| Step: 2
Training loss: 2.870377540588379
Validation loss: 2.3542526639917845

Epoch: 5| Step: 3
Training loss: 2.77679443359375
Validation loss: 2.35200346157115

Epoch: 5| Step: 4
Training loss: 2.660304546356201
Validation loss: 2.3578570863252044

Epoch: 5| Step: 5
Training loss: 2.50207257270813
Validation loss: 2.354426368590324

Epoch: 5| Step: 6
Training loss: 2.475537061691284
Validation loss: 2.3502310681086716

Epoch: 5| Step: 7
Training loss: 2.386463165283203
Validation loss: 2.3523388139663206

Epoch: 5| Step: 8
Training loss: 2.667860984802246
Validation loss: 2.347061707127479

Epoch: 5| Step: 9
Training loss: 2.3765625953674316
Validation loss: 2.355003008278467

Epoch: 5| Step: 10
Training loss: 2.7588319778442383
Validation loss: 2.3483736463772353

Epoch: 124| Step: 0
Training loss: 2.4293832778930664
Validation loss: 2.3449089757857786

Epoch: 5| Step: 1
Training loss: 2.880537748336792
Validation loss: 2.3523260957451275

Epoch: 5| Step: 2
Training loss: 2.999276876449585
Validation loss: 2.349323336796094

Epoch: 5| Step: 3
Training loss: 2.627791166305542
Validation loss: 2.345252900995234

Epoch: 5| Step: 4
Training loss: 2.7526440620422363
Validation loss: 2.344790586861231

Epoch: 5| Step: 5
Training loss: 2.077972888946533
Validation loss: 2.345333468529486

Epoch: 5| Step: 6
Training loss: 2.584315776824951
Validation loss: 2.3497401488724576

Epoch: 5| Step: 7
Training loss: 2.449408769607544
Validation loss: 2.3554165927312707

Epoch: 5| Step: 8
Training loss: 2.521097421646118
Validation loss: 2.351289795291039

Epoch: 5| Step: 9
Training loss: 2.5190341472625732
Validation loss: 2.3491047684864332

Epoch: 5| Step: 10
Training loss: 2.626396417617798
Validation loss: 2.3500660286154798

Epoch: 125| Step: 0
Training loss: 2.2918925285339355
Validation loss: 2.3473784359552528

Epoch: 5| Step: 1
Training loss: 2.9192748069763184
Validation loss: 2.347270570775514

Epoch: 5| Step: 2
Training loss: 2.756303310394287
Validation loss: 2.340259552001953

Epoch: 5| Step: 3
Training loss: 3.163839817047119
Validation loss: 2.3406568778458463

Epoch: 5| Step: 4
Training loss: 2.338200330734253
Validation loss: 2.3384949366251626

Epoch: 5| Step: 5
Training loss: 2.361682891845703
Validation loss: 2.3293528838824202

Epoch: 5| Step: 6
Training loss: 2.2029387950897217
Validation loss: 2.3278202908013457

Epoch: 5| Step: 7
Training loss: 3.6258130073547363
Validation loss: 2.3307241560310445

Epoch: 5| Step: 8
Training loss: 2.166525363922119
Validation loss: 2.332782168542185

Epoch: 5| Step: 9
Training loss: 2.0531840324401855
Validation loss: 2.3445400832801737

Epoch: 5| Step: 10
Training loss: 2.548301935195923
Validation loss: 2.331968499768165

Epoch: 126| Step: 0
Training loss: 1.9801051616668701
Validation loss: 2.333608370955272

Epoch: 5| Step: 1
Training loss: 2.949237108230591
Validation loss: 2.346329194243236

Epoch: 5| Step: 2
Training loss: 2.4375789165496826
Validation loss: 2.35279465875318

Epoch: 5| Step: 3
Training loss: 3.1340880393981934
Validation loss: 2.364786186525899

Epoch: 5| Step: 4
Training loss: 2.1425671577453613
Validation loss: 2.3564963776578187

Epoch: 5| Step: 5
Training loss: 2.7974014282226562
Validation loss: 2.3585079921189176

Epoch: 5| Step: 6
Training loss: 3.1383719444274902
Validation loss: 2.358906179346064

Epoch: 5| Step: 7
Training loss: 2.87695574760437
Validation loss: 2.3567508369363765

Epoch: 5| Step: 8
Training loss: 2.2261462211608887
Validation loss: 2.3625802429773475

Epoch: 5| Step: 9
Training loss: 1.8523906469345093
Validation loss: 2.352807843556968

Epoch: 5| Step: 10
Training loss: 2.896906852722168
Validation loss: 2.358488687904932

Epoch: 127| Step: 0
Training loss: 2.4249534606933594
Validation loss: 2.356417538017355

Epoch: 5| Step: 1
Training loss: 2.3509254455566406
Validation loss: 2.351264125557356

Epoch: 5| Step: 2
Training loss: 2.948974370956421
Validation loss: 2.3413649476984495

Epoch: 5| Step: 3
Training loss: 2.9413692951202393
Validation loss: 2.3426931699117026

Epoch: 5| Step: 4
Training loss: 2.0438332557678223
Validation loss: 2.341985502550679

Epoch: 5| Step: 5
Training loss: 2.710923433303833
Validation loss: 2.342221067797753

Epoch: 5| Step: 6
Training loss: 3.216174602508545
Validation loss: 2.3411552777854343

Epoch: 5| Step: 7
Training loss: 2.0748562812805176
Validation loss: 2.3496434252749205

Epoch: 5| Step: 8
Training loss: 1.8417384624481201
Validation loss: 2.3556508761580273

Epoch: 5| Step: 9
Training loss: 3.05548095703125
Validation loss: 2.3523171358211066

Epoch: 5| Step: 10
Training loss: 2.683812141418457
Validation loss: 2.349357702398813

Epoch: 128| Step: 0
Training loss: 2.5431885719299316
Validation loss: 2.3434298423028763

Epoch: 5| Step: 1
Training loss: 2.1610934734344482
Validation loss: 2.345049547892745

Epoch: 5| Step: 2
Training loss: 2.2684624195098877
Validation loss: 2.343628047614969

Epoch: 5| Step: 3
Training loss: 2.4088680744171143
Validation loss: 2.3351959054188063

Epoch: 5| Step: 4
Training loss: 2.129946231842041
Validation loss: 2.336312335024598

Epoch: 5| Step: 5
Training loss: 2.9266304969787598
Validation loss: 2.34238314244055

Epoch: 5| Step: 6
Training loss: 3.2330775260925293
Validation loss: 2.3392446271834837

Epoch: 5| Step: 7
Training loss: 2.839050054550171
Validation loss: 2.333743118470715

Epoch: 5| Step: 8
Training loss: 2.2009434700012207
Validation loss: 2.343497783906998

Epoch: 5| Step: 9
Training loss: 3.048020601272583
Validation loss: 2.3511106275743052

Epoch: 5| Step: 10
Training loss: 2.3662657737731934
Validation loss: 2.3504404329484507

Epoch: 129| Step: 0
Training loss: 2.1089861392974854
Validation loss: 2.3620523150249193

Epoch: 5| Step: 1
Training loss: 2.044246196746826
Validation loss: 2.3610085056674097

Epoch: 5| Step: 2
Training loss: 1.6082334518432617
Validation loss: 2.352770492594729

Epoch: 5| Step: 3
Training loss: 3.3108749389648438
Validation loss: 2.349878252193492

Epoch: 5| Step: 4
Training loss: 2.5365097522735596
Validation loss: 2.3515463208639495

Epoch: 5| Step: 5
Training loss: 2.8347742557525635
Validation loss: 2.3362699606085338

Epoch: 5| Step: 6
Training loss: 3.561753749847412
Validation loss: 2.338901389029718

Epoch: 5| Step: 7
Training loss: 2.831838846206665
Validation loss: 2.335514565949799

Epoch: 5| Step: 8
Training loss: 2.7277023792266846
Validation loss: 2.331973309157997

Epoch: 5| Step: 9
Training loss: 1.900012731552124
Validation loss: 2.3349318247969433

Epoch: 5| Step: 10
Training loss: 2.8464670181274414
Validation loss: 2.3374365170796714

Epoch: 130| Step: 0
Training loss: 2.963820219039917
Validation loss: 2.3448765636772237

Epoch: 5| Step: 1
Training loss: 2.2966198921203613
Validation loss: 2.3395203903157222

Epoch: 5| Step: 2
Training loss: 2.830085039138794
Validation loss: 2.3449642786415676

Epoch: 5| Step: 3
Training loss: 2.6381232738494873
Validation loss: 2.348474774309384

Epoch: 5| Step: 4
Training loss: 2.0681004524230957
Validation loss: 2.3492810623620146

Epoch: 5| Step: 5
Training loss: 3.5634102821350098
Validation loss: 2.3526210733639297

Epoch: 5| Step: 6
Training loss: 1.9922668933868408
Validation loss: 2.350703159968058

Epoch: 5| Step: 7
Training loss: 3.012181043624878
Validation loss: 2.3470924208241124

Epoch: 5| Step: 8
Training loss: 2.1456196308135986
Validation loss: 2.3362503000485

Epoch: 5| Step: 9
Training loss: 2.565835475921631
Validation loss: 2.338530978848857

Epoch: 5| Step: 10
Training loss: 2.021651268005371
Validation loss: 2.338405837294876

Epoch: 131| Step: 0
Training loss: 2.6288559436798096
Validation loss: 2.362157937019102

Epoch: 5| Step: 1
Training loss: 2.289149522781372
Validation loss: 2.359391689300537

Epoch: 5| Step: 2
Training loss: 2.369319438934326
Validation loss: 2.3654398943788264

Epoch: 5| Step: 3
Training loss: 2.9238483905792236
Validation loss: 2.342801591401459

Epoch: 5| Step: 4
Training loss: 2.7820630073547363
Validation loss: 2.334659637943391

Epoch: 5| Step: 5
Training loss: 2.455470561981201
Validation loss: 2.3245269508771997

Epoch: 5| Step: 6
Training loss: 2.606400489807129
Validation loss: 2.3278932058683006

Epoch: 5| Step: 7
Training loss: 2.7438292503356934
Validation loss: 2.329329034333588

Epoch: 5| Step: 8
Training loss: 2.605471134185791
Validation loss: 2.3243813283981813

Epoch: 5| Step: 9
Training loss: 2.3013062477111816
Validation loss: 2.3235506396139822

Epoch: 5| Step: 10
Training loss: 2.5112340450286865
Validation loss: 2.337412562421573

Epoch: 132| Step: 0
Training loss: 2.556520938873291
Validation loss: 2.337706001855994

Epoch: 5| Step: 1
Training loss: 2.9211201667785645
Validation loss: 2.3510003679542133

Epoch: 5| Step: 2
Training loss: 1.980649709701538
Validation loss: 2.3624062794511036

Epoch: 5| Step: 3
Training loss: 2.378756284713745
Validation loss: 2.369011740530691

Epoch: 5| Step: 4
Training loss: 2.7629408836364746
Validation loss: 2.3595877206453713

Epoch: 5| Step: 5
Training loss: 2.0503716468811035
Validation loss: 2.3594229669981104

Epoch: 5| Step: 6
Training loss: 3.448343276977539
Validation loss: 2.3663399040058093

Epoch: 5| Step: 7
Training loss: 2.6068034172058105
Validation loss: 2.3295781074031705

Epoch: 5| Step: 8
Training loss: 2.382505416870117
Validation loss: 2.3211542098752913

Epoch: 5| Step: 9
Training loss: 2.3002374172210693
Validation loss: 2.333147410423525

Epoch: 5| Step: 10
Training loss: 2.8945088386535645
Validation loss: 2.362285562740859

Epoch: 133| Step: 0
Training loss: 2.6403732299804688
Validation loss: 2.4263466917058474

Epoch: 5| Step: 1
Training loss: 2.6728901863098145
Validation loss: 2.5267020553670902

Epoch: 5| Step: 2
Training loss: 3.200817584991455
Validation loss: 2.515670713557992

Epoch: 5| Step: 3
Training loss: 2.9427342414855957
Validation loss: 2.4487025609580417

Epoch: 5| Step: 4
Training loss: 2.3441147804260254
Validation loss: 2.3938154866618495

Epoch: 5| Step: 5
Training loss: 2.806647777557373
Validation loss: 2.3502246872071297

Epoch: 5| Step: 6
Training loss: 3.395479679107666
Validation loss: 2.3107556630206365

Epoch: 5| Step: 7
Training loss: 2.445181369781494
Validation loss: 2.316751592902727

Epoch: 5| Step: 8
Training loss: 2.248411178588867
Validation loss: 2.371107324477165

Epoch: 5| Step: 9
Training loss: 2.4588401317596436
Validation loss: 2.451247292180215

Epoch: 5| Step: 10
Training loss: 1.5536161661148071
Validation loss: 2.52370471595436

Epoch: 134| Step: 0
Training loss: 3.035930871963501
Validation loss: 2.601322932909894

Epoch: 5| Step: 1
Training loss: 1.9355418682098389
Validation loss: 2.645438758275842

Epoch: 5| Step: 2
Training loss: 2.5623395442962646
Validation loss: 2.648357806667205

Epoch: 5| Step: 3
Training loss: 2.9539833068847656
Validation loss: 2.5908771996857016

Epoch: 5| Step: 4
Training loss: 3.4891037940979004
Validation loss: 2.512406531200614

Epoch: 5| Step: 5
Training loss: 2.6397523880004883
Validation loss: 2.4493134252486692

Epoch: 5| Step: 6
Training loss: 2.433039665222168
Validation loss: 2.374506099249727

Epoch: 5| Step: 7
Training loss: 2.8359575271606445
Validation loss: 2.334502985400538

Epoch: 5| Step: 8
Training loss: 2.943202257156372
Validation loss: 2.333791320041944

Epoch: 5| Step: 9
Training loss: 2.595371961593628
Validation loss: 2.336550784367387

Epoch: 5| Step: 10
Training loss: 2.147707462310791
Validation loss: 2.349541961505849

Epoch: 135| Step: 0
Training loss: 2.2603328227996826
Validation loss: 2.376332659875193

Epoch: 5| Step: 1
Training loss: 3.037266969680786
Validation loss: 2.367181493389991

Epoch: 5| Step: 2
Training loss: 2.7238802909851074
Validation loss: 2.36570115499599

Epoch: 5| Step: 3
Training loss: 2.3364691734313965
Validation loss: 2.3601826467821674

Epoch: 5| Step: 4
Training loss: 3.044569492340088
Validation loss: 2.3618698479026876

Epoch: 5| Step: 5
Training loss: 2.04585599899292
Validation loss: 2.350459396198232

Epoch: 5| Step: 6
Training loss: 2.023029088973999
Validation loss: 2.34097945561973

Epoch: 5| Step: 7
Training loss: 3.0390543937683105
Validation loss: 2.3502054752842074

Epoch: 5| Step: 8
Training loss: 2.7690749168395996
Validation loss: 2.3511138628887873

Epoch: 5| Step: 9
Training loss: 2.886334180831909
Validation loss: 2.3492711513273177

Epoch: 5| Step: 10
Training loss: 2.352243185043335
Validation loss: 2.3538274790651057

Epoch: 136| Step: 0
Training loss: 2.691210985183716
Validation loss: 2.3598533484243576

Epoch: 5| Step: 1
Training loss: 2.130366802215576
Validation loss: 2.3799136351513606

Epoch: 5| Step: 2
Training loss: 2.4193785190582275
Validation loss: 2.386913025250999

Epoch: 5| Step: 3
Training loss: 2.9847571849823
Validation loss: 2.384158208806028

Epoch: 5| Step: 4
Training loss: 2.411616802215576
Validation loss: 2.3692864910248788

Epoch: 5| Step: 5
Training loss: 2.3582310676574707
Validation loss: 2.360873777379272

Epoch: 5| Step: 6
Training loss: 2.4966530799865723
Validation loss: 2.336951909526702

Epoch: 5| Step: 7
Training loss: 2.7655725479125977
Validation loss: 2.3234453790931293

Epoch: 5| Step: 8
Training loss: 2.6937825679779053
Validation loss: 2.3164291407472346

Epoch: 5| Step: 9
Training loss: 3.111422061920166
Validation loss: 2.3111272229943225

Epoch: 5| Step: 10
Training loss: 2.302133083343506
Validation loss: 2.313922269369966

Epoch: 137| Step: 0
Training loss: 2.9618492126464844
Validation loss: 2.312196454694194

Epoch: 5| Step: 1
Training loss: 2.689815044403076
Validation loss: 2.3135699879738594

Epoch: 5| Step: 2
Training loss: 2.5426249504089355
Validation loss: 2.3145014265532136

Epoch: 5| Step: 3
Training loss: 2.7514634132385254
Validation loss: 2.312386733229442

Epoch: 5| Step: 4
Training loss: 2.329524040222168
Validation loss: 2.3103587499228855

Epoch: 5| Step: 5
Training loss: 2.0365610122680664
Validation loss: 2.3143006037640315

Epoch: 5| Step: 6
Training loss: 2.901642322540283
Validation loss: 2.3193882485871673

Epoch: 5| Step: 7
Training loss: 2.288372755050659
Validation loss: 2.3107061129744335

Epoch: 5| Step: 8
Training loss: 2.11753249168396
Validation loss: 2.3162460686058126

Epoch: 5| Step: 9
Training loss: 2.952780246734619
Validation loss: 2.326896495716546

Epoch: 5| Step: 10
Training loss: 2.4834609031677246
Validation loss: 2.315795959964875

Epoch: 138| Step: 0
Training loss: 2.3163046836853027
Validation loss: 2.3247184138144217

Epoch: 5| Step: 1
Training loss: 2.601897954940796
Validation loss: 2.3409399037720053

Epoch: 5| Step: 2
Training loss: 2.8765945434570312
Validation loss: 2.349337685492731

Epoch: 5| Step: 3
Training loss: 2.747556209564209
Validation loss: 2.322996288217524

Epoch: 5| Step: 4
Training loss: 2.9715781211853027
Validation loss: 2.3141143591173234

Epoch: 5| Step: 5
Training loss: 2.705906867980957
Validation loss: 2.304324298776606

Epoch: 5| Step: 6
Training loss: 2.1854801177978516
Validation loss: 2.30380085719529

Epoch: 5| Step: 7
Training loss: 2.833411693572998
Validation loss: 2.3087365934925694

Epoch: 5| Step: 8
Training loss: 2.3297009468078613
Validation loss: 2.3227807180855864

Epoch: 5| Step: 9
Training loss: 2.524479389190674
Validation loss: 2.332556709166496

Epoch: 5| Step: 10
Training loss: 1.972502589225769
Validation loss: 2.330904568395307

Epoch: 139| Step: 0
Training loss: 2.6304759979248047
Validation loss: 2.3388181463364632

Epoch: 5| Step: 1
Training loss: 2.714048385620117
Validation loss: 2.347758931498374

Epoch: 5| Step: 2
Training loss: 2.9797427654266357
Validation loss: 2.337493504247358

Epoch: 5| Step: 3
Training loss: 2.4597091674804688
Validation loss: 2.3267935629813903

Epoch: 5| Step: 4
Training loss: 2.2490251064300537
Validation loss: 2.3133640622579925

Epoch: 5| Step: 5
Training loss: 2.6316633224487305
Validation loss: 2.3081637582471295

Epoch: 5| Step: 6
Training loss: 2.4438247680664062
Validation loss: 2.3028089718152116

Epoch: 5| Step: 7
Training loss: 2.218186616897583
Validation loss: 2.2988974612246276

Epoch: 5| Step: 8
Training loss: 2.5833818912506104
Validation loss: 2.3040214456537718

Epoch: 5| Step: 9
Training loss: 2.5467209815979004
Validation loss: 2.3053921345741517

Epoch: 5| Step: 10
Training loss: 2.6880736351013184
Validation loss: 2.3059338267131517

Epoch: 140| Step: 0
Training loss: 2.6452574729919434
Validation loss: 2.3065990042942826

Epoch: 5| Step: 1
Training loss: 2.8707027435302734
Validation loss: 2.3177887649946314

Epoch: 5| Step: 2
Training loss: 2.2604575157165527
Validation loss: 2.3397201222758137

Epoch: 5| Step: 3
Training loss: 2.6148571968078613
Validation loss: 2.333271752121628

Epoch: 5| Step: 4
Training loss: 2.4519808292388916
Validation loss: 2.340552745326873

Epoch: 5| Step: 5
Training loss: 2.912043809890747
Validation loss: 2.321385299005816

Epoch: 5| Step: 6
Training loss: 2.619101047515869
Validation loss: 2.312195990675239

Epoch: 5| Step: 7
Training loss: 2.132082939147949
Validation loss: 2.310998478243428

Epoch: 5| Step: 8
Training loss: 1.6993200778961182
Validation loss: 2.306659088339857

Epoch: 5| Step: 9
Training loss: 3.3289597034454346
Validation loss: 2.312913453707131

Epoch: 5| Step: 10
Training loss: 2.4242401123046875
Validation loss: 2.3302256189366823

Epoch: 141| Step: 0
Training loss: 2.3061516284942627
Validation loss: 2.340270857657156

Epoch: 5| Step: 1
Training loss: 2.220508575439453
Validation loss: 2.352065158146684

Epoch: 5| Step: 2
Training loss: 2.1314971446990967
Validation loss: 2.331900529963996

Epoch: 5| Step: 3
Training loss: 2.2265121936798096
Validation loss: 2.318346923397433

Epoch: 5| Step: 4
Training loss: 2.9965033531188965
Validation loss: 2.317525061227942

Epoch: 5| Step: 5
Training loss: 1.9739433526992798
Validation loss: 2.3181732905808317

Epoch: 5| Step: 6
Training loss: 2.8718457221984863
Validation loss: 2.3166336500516502

Epoch: 5| Step: 7
Training loss: 3.2389163970947266
Validation loss: 2.3225456130120063

Epoch: 5| Step: 8
Training loss: 2.537996292114258
Validation loss: 2.3346337579911753

Epoch: 5| Step: 9
Training loss: 2.675976037979126
Validation loss: 2.3348333374146493

Epoch: 5| Step: 10
Training loss: 2.8601083755493164
Validation loss: 2.335020121707711

Epoch: 142| Step: 0
Training loss: 2.4491124153137207
Validation loss: 2.3403131013275473

Epoch: 5| Step: 1
Training loss: 2.7224857807159424
Validation loss: 2.3373577287120204

Epoch: 5| Step: 2
Training loss: 2.5666940212249756
Validation loss: 2.334134519741099

Epoch: 5| Step: 3
Training loss: 2.465036153793335
Validation loss: 2.3309694310670257

Epoch: 5| Step: 4
Training loss: 2.5216422080993652
Validation loss: 2.326373166935418

Epoch: 5| Step: 5
Training loss: 2.5666027069091797
Validation loss: 2.3050997436687513

Epoch: 5| Step: 6
Training loss: 2.264315605163574
Validation loss: 2.3048372422495196

Epoch: 5| Step: 7
Training loss: 2.8118724822998047
Validation loss: 2.296135728077222

Epoch: 5| Step: 8
Training loss: 2.632293701171875
Validation loss: 2.296697452504148

Epoch: 5| Step: 9
Training loss: 2.5569090843200684
Validation loss: 2.2959005781399306

Epoch: 5| Step: 10
Training loss: 2.432115077972412
Validation loss: 2.291359373318252

Epoch: 143| Step: 0
Training loss: 2.9743850231170654
Validation loss: 2.295179866975354

Epoch: 5| Step: 1
Training loss: 2.2145304679870605
Validation loss: 2.305805124262328

Epoch: 5| Step: 2
Training loss: 2.5609467029571533
Validation loss: 2.30337534412261

Epoch: 5| Step: 3
Training loss: 2.5634894371032715
Validation loss: 2.304667124184229

Epoch: 5| Step: 4
Training loss: 2.768613815307617
Validation loss: 2.303559469920333

Epoch: 5| Step: 5
Training loss: 2.4431209564208984
Validation loss: 2.295265466936173

Epoch: 5| Step: 6
Training loss: 2.575684070587158
Validation loss: 2.2919654025826404

Epoch: 5| Step: 7
Training loss: 2.8259992599487305
Validation loss: 2.298122182969124

Epoch: 5| Step: 8
Training loss: 2.3132214546203613
Validation loss: 2.312475932541714

Epoch: 5| Step: 9
Training loss: 2.210184335708618
Validation loss: 2.332643123083217

Epoch: 5| Step: 10
Training loss: 2.6030266284942627
Validation loss: 2.3480037950700328

Epoch: 144| Step: 0
Training loss: 3.1972744464874268
Validation loss: 2.348727615930701

Epoch: 5| Step: 1
Training loss: 1.8004436492919922
Validation loss: 2.3431275070354505

Epoch: 5| Step: 2
Training loss: 2.247922420501709
Validation loss: 2.330321511914653

Epoch: 5| Step: 3
Training loss: 2.457073211669922
Validation loss: 2.328284291810887

Epoch: 5| Step: 4
Training loss: 2.345647096633911
Validation loss: 2.3184987178412815

Epoch: 5| Step: 5
Training loss: 2.614201784133911
Validation loss: 2.3106064181174

Epoch: 5| Step: 6
Training loss: 2.2795608043670654
Validation loss: 2.315863117094963

Epoch: 5| Step: 7
Training loss: 3.0699527263641357
Validation loss: 2.3307182814485286

Epoch: 5| Step: 8
Training loss: 2.7147207260131836
Validation loss: 2.3240286611741587

Epoch: 5| Step: 9
Training loss: 2.7368369102478027
Validation loss: 2.329979340235392

Epoch: 5| Step: 10
Training loss: 2.469592809677124
Validation loss: 2.3119933066829557

Epoch: 145| Step: 0
Training loss: 2.379887104034424
Validation loss: 2.316204294081657

Epoch: 5| Step: 1
Training loss: 2.466296911239624
Validation loss: 2.3107879431016984

Epoch: 5| Step: 2
Training loss: 2.872955322265625
Validation loss: 2.3074435162287887

Epoch: 5| Step: 3
Training loss: 2.088747978210449
Validation loss: 2.2964737235858874

Epoch: 5| Step: 4
Training loss: 2.109506130218506
Validation loss: 2.31113407176028

Epoch: 5| Step: 5
Training loss: 3.051830530166626
Validation loss: 2.3051472863843365

Epoch: 5| Step: 6
Training loss: 2.5986721515655518
Validation loss: 2.315330672007735

Epoch: 5| Step: 7
Training loss: 2.0591585636138916
Validation loss: 2.3109457595373994

Epoch: 5| Step: 8
Training loss: 2.85697603225708
Validation loss: 2.303493265182741

Epoch: 5| Step: 9
Training loss: 2.7560677528381348
Validation loss: 2.306995386718422

Epoch: 5| Step: 10
Training loss: 2.6077749729156494
Validation loss: 2.3067200747869347

Epoch: 146| Step: 0
Training loss: 2.753383159637451
Validation loss: 2.2940966852249636

Epoch: 5| Step: 1
Training loss: 2.453970432281494
Validation loss: 2.2987738988732778

Epoch: 5| Step: 2
Training loss: 2.4825150966644287
Validation loss: 2.2925134525504163

Epoch: 5| Step: 3
Training loss: 2.5625529289245605
Validation loss: 2.290533673378729

Epoch: 5| Step: 4
Training loss: 2.596250534057617
Validation loss: 2.286987437996813

Epoch: 5| Step: 5
Training loss: 2.2971274852752686
Validation loss: 2.293653702223173

Epoch: 5| Step: 6
Training loss: 2.1742498874664307
Validation loss: 2.286526185210033

Epoch: 5| Step: 7
Training loss: 2.553446054458618
Validation loss: 2.2833153227324128

Epoch: 5| Step: 8
Training loss: 3.2947514057159424
Validation loss: 2.282489061355591

Epoch: 5| Step: 9
Training loss: 2.148468494415283
Validation loss: 2.279299989823372

Epoch: 5| Step: 10
Training loss: 2.496502637863159
Validation loss: 2.2781549884426977

Epoch: 147| Step: 0
Training loss: 2.2361748218536377
Validation loss: 2.280537871904271

Epoch: 5| Step: 1
Training loss: 3.345050811767578
Validation loss: 2.2884985375147995

Epoch: 5| Step: 2
Training loss: 2.268045663833618
Validation loss: 2.282750448872966

Epoch: 5| Step: 3
Training loss: 2.011197328567505
Validation loss: 2.281222858736592

Epoch: 5| Step: 4
Training loss: 2.1950478553771973
Validation loss: 2.2800037271233013

Epoch: 5| Step: 5
Training loss: 3.015587091445923
Validation loss: 2.279428028291272

Epoch: 5| Step: 6
Training loss: 3.0263891220092773
Validation loss: 2.2774101739288657

Epoch: 5| Step: 7
Training loss: 2.3730690479278564
Validation loss: 2.2832334297959522

Epoch: 5| Step: 8
Training loss: 2.9897620677948
Validation loss: 2.2796905758560344

Epoch: 5| Step: 9
Training loss: 2.5570077896118164
Validation loss: 2.291391375244305

Epoch: 5| Step: 10
Training loss: 1.5745748281478882
Validation loss: 2.28763150143367

Epoch: 148| Step: 0
Training loss: 2.5545427799224854
Validation loss: 2.2958036276601974

Epoch: 5| Step: 1
Training loss: 2.7419941425323486
Validation loss: 2.3043143005781275

Epoch: 5| Step: 2
Training loss: 1.9313669204711914
Validation loss: 2.3136698481857136

Epoch: 5| Step: 3
Training loss: 2.704458713531494
Validation loss: 2.3022043038440008

Epoch: 5| Step: 4
Training loss: 2.454319477081299
Validation loss: 2.320542070173448

Epoch: 5| Step: 5
Training loss: 2.192889928817749
Validation loss: 2.2996131784172467

Epoch: 5| Step: 6
Training loss: 2.822694778442383
Validation loss: 2.299941316727669

Epoch: 5| Step: 7
Training loss: 2.5854575634002686
Validation loss: 2.3045048124046734

Epoch: 5| Step: 8
Training loss: 2.5146470069885254
Validation loss: 2.3163544465136785

Epoch: 5| Step: 9
Training loss: 2.881713628768921
Validation loss: 2.328375075453071

Epoch: 5| Step: 10
Training loss: 2.2518093585968018
Validation loss: 2.3186004520744405

Epoch: 149| Step: 0
Training loss: 2.411146879196167
Validation loss: 2.3160770862333235

Epoch: 5| Step: 1
Training loss: 2.30401349067688
Validation loss: 2.317180715581422

Epoch: 5| Step: 2
Training loss: 3.082717180252075
Validation loss: 2.307730628598121

Epoch: 5| Step: 3
Training loss: 2.4370484352111816
Validation loss: 2.312936839237008

Epoch: 5| Step: 4
Training loss: 2.321528911590576
Validation loss: 2.2977768221209125

Epoch: 5| Step: 5
Training loss: 2.301543712615967
Validation loss: 2.301126264756726

Epoch: 5| Step: 6
Training loss: 2.6712918281555176
Validation loss: 2.2907118835756854

Epoch: 5| Step: 7
Training loss: 2.325869083404541
Validation loss: 2.3056321913196194

Epoch: 5| Step: 8
Training loss: 2.804905414581299
Validation loss: 2.297548594013337

Epoch: 5| Step: 9
Training loss: 2.176872730255127
Validation loss: 2.2938178354693997

Epoch: 5| Step: 10
Training loss: 2.8328511714935303
Validation loss: 2.297016369399204

Epoch: 150| Step: 0
Training loss: 2.6574673652648926
Validation loss: 2.2894330011901034

Epoch: 5| Step: 1
Training loss: 2.8273251056671143
Validation loss: 2.289787282225906

Epoch: 5| Step: 2
Training loss: 2.569284439086914
Validation loss: 2.2866952855099916

Epoch: 5| Step: 3
Training loss: 2.576742649078369
Validation loss: 2.2963261809400333

Epoch: 5| Step: 4
Training loss: 2.4239439964294434
Validation loss: 2.292260972402429

Epoch: 5| Step: 5
Training loss: 1.9451892375946045
Validation loss: 2.2919561632217897

Epoch: 5| Step: 6
Training loss: 2.1889967918395996
Validation loss: 2.2933735206562984

Epoch: 5| Step: 7
Training loss: 2.348287343978882
Validation loss: 2.304393791383313

Epoch: 5| Step: 8
Training loss: 3.020890712738037
Validation loss: 2.298779414546105

Epoch: 5| Step: 9
Training loss: 2.8787732124328613
Validation loss: 2.2933428697688605

Epoch: 5| Step: 10
Training loss: 2.0636603832244873
Validation loss: 2.2853250042084725

Epoch: 151| Step: 0
Training loss: 2.3510453701019287
Validation loss: 2.290592024403234

Epoch: 5| Step: 1
Training loss: 2.523153066635132
Validation loss: 2.2919033881156676

Epoch: 5| Step: 2
Training loss: 2.8602817058563232
Validation loss: 2.304696447105818

Epoch: 5| Step: 3
Training loss: 2.2770495414733887
Validation loss: 2.2904848719155915

Epoch: 5| Step: 4
Training loss: 3.0447075366973877
Validation loss: 2.3084137234636533

Epoch: 5| Step: 5
Training loss: 2.1673407554626465
Validation loss: 2.2963945993813137

Epoch: 5| Step: 6
Training loss: 2.580017328262329
Validation loss: 2.2774456598425425

Epoch: 5| Step: 7
Training loss: 2.779432535171509
Validation loss: 2.277483481232838

Epoch: 5| Step: 8
Training loss: 2.808638334274292
Validation loss: 2.2668759284480924

Epoch: 5| Step: 9
Training loss: 2.1830286979675293
Validation loss: 2.2748006877078804

Epoch: 5| Step: 10
Training loss: 1.9953088760375977
Validation loss: 2.2882655435992825

Epoch: 152| Step: 0
Training loss: 2.61527419090271
Validation loss: 2.2791999668203373

Epoch: 5| Step: 1
Training loss: 2.38134765625
Validation loss: 2.267896321512038

Epoch: 5| Step: 2
Training loss: 2.5134377479553223
Validation loss: 2.273472539840206

Epoch: 5| Step: 3
Training loss: 2.374037265777588
Validation loss: 2.2750207019108597

Epoch: 5| Step: 4
Training loss: 2.6027867794036865
Validation loss: 2.2706351331485215

Epoch: 5| Step: 5
Training loss: 2.9409897327423096
Validation loss: 2.2852202897430747

Epoch: 5| Step: 6
Training loss: 1.6245830059051514
Validation loss: 2.2675065942989883

Epoch: 5| Step: 7
Training loss: 2.3269007205963135
Validation loss: 2.2748569532107283

Epoch: 5| Step: 8
Training loss: 2.7048611640930176
Validation loss: 2.2794893659571165

Epoch: 5| Step: 9
Training loss: 2.192906618118286
Validation loss: 2.2986375055005475

Epoch: 5| Step: 10
Training loss: 3.362339735031128
Validation loss: 2.3301038254973707

Epoch: 153| Step: 0
Training loss: 2.1324880123138428
Validation loss: 2.3427887244891097

Epoch: 5| Step: 1
Training loss: 2.258446455001831
Validation loss: 2.3595130366663777

Epoch: 5| Step: 2
Training loss: 2.7880382537841797
Validation loss: 2.339216911664573

Epoch: 5| Step: 3
Training loss: 3.122100353240967
Validation loss: 2.3169359109734975

Epoch: 5| Step: 4
Training loss: 2.2272660732269287
Validation loss: 2.303803333672144

Epoch: 5| Step: 5
Training loss: 2.3383800983428955
Validation loss: 2.295682430267334

Epoch: 5| Step: 6
Training loss: 2.316408157348633
Validation loss: 2.280929555175125

Epoch: 5| Step: 7
Training loss: 2.8513715267181396
Validation loss: 2.283168227441849

Epoch: 5| Step: 8
Training loss: 2.339233875274658
Validation loss: 2.2792979850563952

Epoch: 5| Step: 9
Training loss: 2.883763551712036
Validation loss: 2.2848049799601235

Epoch: 5| Step: 10
Training loss: 2.2104053497314453
Validation loss: 2.286826284982825

Epoch: 154| Step: 0
Training loss: 2.2780330181121826
Validation loss: 2.2849797651331913

Epoch: 5| Step: 1
Training loss: 2.8873934745788574
Validation loss: 2.2853182105607885

Epoch: 5| Step: 2
Training loss: 2.571056842803955
Validation loss: 2.2796091571930917

Epoch: 5| Step: 3
Training loss: 2.608319044113159
Validation loss: 2.261524749058549

Epoch: 5| Step: 4
Training loss: 2.691244125366211
Validation loss: 2.2632974988670758

Epoch: 5| Step: 5
Training loss: 2.7070040702819824
Validation loss: 2.2620342751984954

Epoch: 5| Step: 6
Training loss: 2.666919708251953
Validation loss: 2.262984883400702

Epoch: 5| Step: 7
Training loss: 2.8404839038848877
Validation loss: 2.281446997837354

Epoch: 5| Step: 8
Training loss: 2.1819939613342285
Validation loss: 2.28453234446946

Epoch: 5| Step: 9
Training loss: 1.8828986883163452
Validation loss: 2.2851300342108614

Epoch: 5| Step: 10
Training loss: 2.374058485031128
Validation loss: 2.3263548497230775

Epoch: 155| Step: 0
Training loss: 2.355471134185791
Validation loss: 2.3552507200548725

Epoch: 5| Step: 1
Training loss: 2.2402894496917725
Validation loss: 2.3693205284815964

Epoch: 5| Step: 2
Training loss: 2.677645444869995
Validation loss: 2.3609347625445296

Epoch: 5| Step: 3
Training loss: 2.4376306533813477
Validation loss: 2.321009216770049

Epoch: 5| Step: 4
Training loss: 2.9007887840270996
Validation loss: 2.305574617078227

Epoch: 5| Step: 5
Training loss: 2.48832631111145
Validation loss: 2.279745004510367

Epoch: 5| Step: 6
Training loss: 2.508439302444458
Validation loss: 2.2611794253831268

Epoch: 5| Step: 7
Training loss: 2.620478391647339
Validation loss: 2.261801199246478

Epoch: 5| Step: 8
Training loss: 3.0896685123443604
Validation loss: 2.2575565820099204

Epoch: 5| Step: 9
Training loss: 2.426567554473877
Validation loss: 2.269406675010599

Epoch: 5| Step: 10
Training loss: 1.9871525764465332
Validation loss: 2.267424119416104

Epoch: 156| Step: 0
Training loss: 2.5952796936035156
Validation loss: 2.280505067558699

Epoch: 5| Step: 1
Training loss: 2.132199287414551
Validation loss: 2.2840466755692677

Epoch: 5| Step: 2
Training loss: 2.8723182678222656
Validation loss: 2.285859433553552

Epoch: 5| Step: 3
Training loss: 2.8903229236602783
Validation loss: 2.270284520682468

Epoch: 5| Step: 4
Training loss: 1.5462710857391357
Validation loss: 2.247190680555118

Epoch: 5| Step: 5
Training loss: 2.2543601989746094
Validation loss: 2.2541017019620506

Epoch: 5| Step: 6
Training loss: 2.4192473888397217
Validation loss: 2.2607445768130723

Epoch: 5| Step: 7
Training loss: 2.6980209350585938
Validation loss: 2.269458709224578

Epoch: 5| Step: 8
Training loss: 2.4949216842651367
Validation loss: 2.2817241645628408

Epoch: 5| Step: 9
Training loss: 2.5942881107330322
Validation loss: 2.28618638489836

Epoch: 5| Step: 10
Training loss: 3.195148229598999
Validation loss: 2.304720850401027

Epoch: 157| Step: 0
Training loss: 2.869490146636963
Validation loss: 2.3185030465484946

Epoch: 5| Step: 1
Training loss: 2.3973212242126465
Validation loss: 2.315027940657831

Epoch: 5| Step: 2
Training loss: 2.916003704071045
Validation loss: 2.322982362521592

Epoch: 5| Step: 3
Training loss: 1.742078423500061
Validation loss: 2.317953117432133

Epoch: 5| Step: 4
Training loss: 2.5851683616638184
Validation loss: 2.3180144858616654

Epoch: 5| Step: 5
Training loss: 2.907733201980591
Validation loss: 2.319021227539227

Epoch: 5| Step: 6
Training loss: 2.451301336288452
Validation loss: 2.3100953461021505

Epoch: 5| Step: 7
Training loss: 2.8213019371032715
Validation loss: 2.3096807836204447

Epoch: 5| Step: 8
Training loss: 2.5337982177734375
Validation loss: 2.327130481760989

Epoch: 5| Step: 9
Training loss: 2.3398642539978027
Validation loss: 2.327984827820973

Epoch: 5| Step: 10
Training loss: 2.197126865386963
Validation loss: 2.302151482592347

Epoch: 158| Step: 0
Training loss: 1.9849458932876587
Validation loss: 2.275291483889344

Epoch: 5| Step: 1
Training loss: 2.4137661457061768
Validation loss: 2.2638597026948006

Epoch: 5| Step: 2
Training loss: 2.2290022373199463
Validation loss: 2.2629822889963784

Epoch: 5| Step: 3
Training loss: 2.0289416313171387
Validation loss: 2.263040042692615

Epoch: 5| Step: 4
Training loss: 2.820643186569214
Validation loss: 2.2622952973970802

Epoch: 5| Step: 5
Training loss: 2.917971134185791
Validation loss: 2.2668228226323284

Epoch: 5| Step: 6
Training loss: 2.9935829639434814
Validation loss: 2.2524281445369927

Epoch: 5| Step: 7
Training loss: 2.548426389694214
Validation loss: 2.265686627357237

Epoch: 5| Step: 8
Training loss: 2.6706290245056152
Validation loss: 2.263153053099109

Epoch: 5| Step: 9
Training loss: 2.351947784423828
Validation loss: 2.267088385038478

Epoch: 5| Step: 10
Training loss: 2.2242908477783203
Validation loss: 2.266182335474158

Epoch: 159| Step: 0
Training loss: 2.329308271408081
Validation loss: 2.2712309668141026

Epoch: 5| Step: 1
Training loss: 2.8905842304229736
Validation loss: 2.2755532392891507

Epoch: 5| Step: 2
Training loss: 2.5615100860595703
Validation loss: 2.2852433240541847

Epoch: 5| Step: 3
Training loss: 2.2566933631896973
Validation loss: 2.297617350855181

Epoch: 5| Step: 4
Training loss: 2.6269476413726807
Validation loss: 2.296303673457074

Epoch: 5| Step: 5
Training loss: 1.9718490839004517
Validation loss: 2.2841105538029827

Epoch: 5| Step: 6
Training loss: 2.8528988361358643
Validation loss: 2.2678239345550537

Epoch: 5| Step: 7
Training loss: 2.7541308403015137
Validation loss: 2.261081313574186

Epoch: 5| Step: 8
Training loss: 2.2994980812072754
Validation loss: 2.280366666855351

Epoch: 5| Step: 9
Training loss: 1.9888092279434204
Validation loss: 2.2726383439956175

Epoch: 5| Step: 10
Training loss: 2.8726160526275635
Validation loss: 2.2609535494158344

Epoch: 160| Step: 0
Training loss: 2.989272356033325
Validation loss: 2.2648165302891887

Epoch: 5| Step: 1
Training loss: 2.325347423553467
Validation loss: 2.2531838468326035

Epoch: 5| Step: 2
Training loss: 3.2500717639923096
Validation loss: 2.249863556636277

Epoch: 5| Step: 3
Training loss: 1.9692707061767578
Validation loss: 2.245974281782745

Epoch: 5| Step: 4
Training loss: 1.9637845754623413
Validation loss: 2.2611343142806843

Epoch: 5| Step: 5
Training loss: 2.4423532485961914
Validation loss: 2.276045476236651

Epoch: 5| Step: 6
Training loss: 2.8207173347473145
Validation loss: 2.274851006846274

Epoch: 5| Step: 7
Training loss: 2.2293527126312256
Validation loss: 2.2741402528619252

Epoch: 5| Step: 8
Training loss: 2.2334086894989014
Validation loss: 2.2646663624753236

Epoch: 5| Step: 9
Training loss: 2.5322818756103516
Validation loss: 2.2691218494087138

Epoch: 5| Step: 10
Training loss: 2.5104434490203857
Validation loss: 2.2805866426037205

Epoch: 161| Step: 0
Training loss: 2.6133346557617188
Validation loss: 2.2750219401492866

Epoch: 5| Step: 1
Training loss: 2.532755136489868
Validation loss: 2.2823806808840845

Epoch: 5| Step: 2
Training loss: 1.6920448541641235
Validation loss: 2.2818565855744066

Epoch: 5| Step: 3
Training loss: 2.861720561981201
Validation loss: 2.2864832673021542

Epoch: 5| Step: 4
Training loss: 2.2979726791381836
Validation loss: 2.269408138849402

Epoch: 5| Step: 5
Training loss: 2.477226734161377
Validation loss: 2.270219179891771

Epoch: 5| Step: 6
Training loss: 2.6722068786621094
Validation loss: 2.2739448598636094

Epoch: 5| Step: 7
Training loss: 2.2313647270202637
Validation loss: 2.2863067452625563

Epoch: 5| Step: 8
Training loss: 2.5183825492858887
Validation loss: 2.2795958160072245

Epoch: 5| Step: 9
Training loss: 2.5482687950134277
Validation loss: 2.2914148043560725

Epoch: 5| Step: 10
Training loss: 2.905806064605713
Validation loss: 2.308070205873059

Epoch: 162| Step: 0
Training loss: 2.3920931816101074
Validation loss: 2.309991093092067

Epoch: 5| Step: 1
Training loss: 2.8123555183410645
Validation loss: 2.3044741486990326

Epoch: 5| Step: 2
Training loss: 1.9439842700958252
Validation loss: 2.2819184231501755

Epoch: 5| Step: 3
Training loss: 3.0557141304016113
Validation loss: 2.2735513910170524

Epoch: 5| Step: 4
Training loss: 2.1259098052978516
Validation loss: 2.2660461241199124

Epoch: 5| Step: 5
Training loss: 2.4489974975585938
Validation loss: 2.250886619731944

Epoch: 5| Step: 6
Training loss: 2.413382053375244
Validation loss: 2.24756936488613

Epoch: 5| Step: 7
Training loss: 2.5442233085632324
Validation loss: 2.244485875611664

Epoch: 5| Step: 8
Training loss: 1.9024641513824463
Validation loss: 2.246827265267731

Epoch: 5| Step: 9
Training loss: 2.743396282196045
Validation loss: 2.2501863920560448

Epoch: 5| Step: 10
Training loss: 2.8716959953308105
Validation loss: 2.2630275000808058

Epoch: 163| Step: 0
Training loss: 2.799342632293701
Validation loss: 2.256456059794272

Epoch: 5| Step: 1
Training loss: 3.027036666870117
Validation loss: 2.274252273703134

Epoch: 5| Step: 2
Training loss: 2.4924845695495605
Validation loss: 2.271124320645486

Epoch: 5| Step: 3
Training loss: 2.625542402267456
Validation loss: 2.2756280873411443

Epoch: 5| Step: 4
Training loss: 2.6621241569519043
Validation loss: 2.2835056294677076

Epoch: 5| Step: 5
Training loss: 1.9521312713623047
Validation loss: 2.2954873013240036

Epoch: 5| Step: 6
Training loss: 2.847066640853882
Validation loss: 2.292895106859105

Epoch: 5| Step: 7
Training loss: 2.0992348194122314
Validation loss: 2.285419912748439

Epoch: 5| Step: 8
Training loss: 2.138643741607666
Validation loss: 2.2604660577671503

Epoch: 5| Step: 9
Training loss: 2.530994415283203
Validation loss: 2.257420984647607

Epoch: 5| Step: 10
Training loss: 1.939655065536499
Validation loss: 2.2507660004400436

Epoch: 164| Step: 0
Training loss: 2.1954267024993896
Validation loss: 2.2459672881710913

Epoch: 5| Step: 1
Training loss: 2.780949831008911
Validation loss: 2.25733922630228

Epoch: 5| Step: 2
Training loss: 2.5119805335998535
Validation loss: 2.248807684067757

Epoch: 5| Step: 3
Training loss: 2.4761404991149902
Validation loss: 2.2584517976289153

Epoch: 5| Step: 4
Training loss: 2.59417462348938
Validation loss: 2.2703241968667633

Epoch: 5| Step: 5
Training loss: 2.329282760620117
Validation loss: 2.285770464968938

Epoch: 5| Step: 6
Training loss: 2.3513240814208984
Validation loss: 2.2637582389257287

Epoch: 5| Step: 7
Training loss: 2.330998182296753
Validation loss: 2.2670941147752988

Epoch: 5| Step: 8
Training loss: 2.763392210006714
Validation loss: 2.2376313696625414

Epoch: 5| Step: 9
Training loss: 2.53149676322937
Validation loss: 2.2381183255103325

Epoch: 5| Step: 10
Training loss: 2.2574992179870605
Validation loss: 2.243793531130719

Epoch: 165| Step: 0
Training loss: 2.1212823390960693
Validation loss: 2.2401162039849067

Epoch: 5| Step: 1
Training loss: 2.223905086517334
Validation loss: 2.239373532674646

Epoch: 5| Step: 2
Training loss: 2.2737250328063965
Validation loss: 2.2437630776436097

Epoch: 5| Step: 3
Training loss: 2.406879425048828
Validation loss: 2.2351212680980725

Epoch: 5| Step: 4
Training loss: 2.475106716156006
Validation loss: 2.230915951472457

Epoch: 5| Step: 5
Training loss: 2.0287373065948486
Validation loss: 2.231916473757836

Epoch: 5| Step: 6
Training loss: 2.9833178520202637
Validation loss: 2.236282930579237

Epoch: 5| Step: 7
Training loss: 2.409646511077881
Validation loss: 2.249765826809791

Epoch: 5| Step: 8
Training loss: 2.385918378829956
Validation loss: 2.2546579440434775

Epoch: 5| Step: 9
Training loss: 2.615764617919922
Validation loss: 2.264589161001226

Epoch: 5| Step: 10
Training loss: 3.2347042560577393
Validation loss: 2.280607197874336

Epoch: 166| Step: 0
Training loss: 2.706101179122925
Validation loss: 2.27440764827113

Epoch: 5| Step: 1
Training loss: 2.574185848236084
Validation loss: 2.28749918424955

Epoch: 5| Step: 2
Training loss: 1.8656203746795654
Validation loss: 2.2720457712809243

Epoch: 5| Step: 3
Training loss: 2.83577823638916
Validation loss: 2.2628714166661745

Epoch: 5| Step: 4
Training loss: 2.095485210418701
Validation loss: 2.227994088203676

Epoch: 5| Step: 5
Training loss: 2.5745341777801514
Validation loss: 2.242251585888606

Epoch: 5| Step: 6
Training loss: 1.9796501398086548
Validation loss: 2.2413259654916744

Epoch: 5| Step: 7
Training loss: 2.9911344051361084
Validation loss: 2.2449065510944655

Epoch: 5| Step: 8
Training loss: 1.7610867023468018
Validation loss: 2.2694671756477764

Epoch: 5| Step: 9
Training loss: 2.8805813789367676
Validation loss: 2.2518224318822226

Epoch: 5| Step: 10
Training loss: 2.6857731342315674
Validation loss: 2.272290145197222

Epoch: 167| Step: 0
Training loss: 2.1552648544311523
Validation loss: 2.2742449929637294

Epoch: 5| Step: 1
Training loss: 2.537869930267334
Validation loss: 2.276629315909519

Epoch: 5| Step: 2
Training loss: 2.190605878829956
Validation loss: 2.2664622927224762

Epoch: 5| Step: 3
Training loss: 2.2989020347595215
Validation loss: 2.247912355648574

Epoch: 5| Step: 4
Training loss: 2.7407588958740234
Validation loss: 2.2222570142438336

Epoch: 5| Step: 5
Training loss: 2.407623052597046
Validation loss: 2.235056154189571

Epoch: 5| Step: 6
Training loss: 2.7031326293945312
Validation loss: 2.255426691424462

Epoch: 5| Step: 7
Training loss: 2.618455410003662
Validation loss: 2.2501677902795936

Epoch: 5| Step: 8
Training loss: 1.971077561378479
Validation loss: 2.289077498579538

Epoch: 5| Step: 9
Training loss: 3.0333988666534424
Validation loss: 2.314048779908047

Epoch: 5| Step: 10
Training loss: 2.4726409912109375
Validation loss: 2.2864099241072133

Epoch: 168| Step: 0
Training loss: 2.4914042949676514
Validation loss: 2.2944549514401342

Epoch: 5| Step: 1
Training loss: 2.209116220474243
Validation loss: 2.2823912507744244

Epoch: 5| Step: 2
Training loss: 1.972389817237854
Validation loss: 2.3072671877440585

Epoch: 5| Step: 3
Training loss: 2.0939793586730957
Validation loss: 2.314491161736109

Epoch: 5| Step: 4
Training loss: 2.652306318283081
Validation loss: 2.3101492338283087

Epoch: 5| Step: 5
Training loss: 2.4347610473632812
Validation loss: 2.3087176225518666

Epoch: 5| Step: 6
Training loss: 2.919178009033203
Validation loss: 2.2560436520525204

Epoch: 5| Step: 7
Training loss: 2.864871025085449
Validation loss: 2.2317066359263595

Epoch: 5| Step: 8
Training loss: 3.0168166160583496
Validation loss: 2.2302954017475085

Epoch: 5| Step: 9
Training loss: 2.3219387531280518
Validation loss: 2.241357126543599

Epoch: 5| Step: 10
Training loss: 2.1540441513061523
Validation loss: 2.2505687629022906

Epoch: 169| Step: 0
Training loss: 2.9823338985443115
Validation loss: 2.2355982744565575

Epoch: 5| Step: 1
Training loss: 2.2581839561462402
Validation loss: 2.2284553256086124

Epoch: 5| Step: 2
Training loss: 3.0450000762939453
Validation loss: 2.2165865539222636

Epoch: 5| Step: 3
Training loss: 2.3725814819335938
Validation loss: 2.219111313102066

Epoch: 5| Step: 4
Training loss: 2.2402682304382324
Validation loss: 2.200909004416517

Epoch: 5| Step: 5
Training loss: 2.8125851154327393
Validation loss: 2.211915082828973

Epoch: 5| Step: 6
Training loss: 2.1952948570251465
Validation loss: 2.2095932806691816

Epoch: 5| Step: 7
Training loss: 2.195420980453491
Validation loss: 2.2105130585291053

Epoch: 5| Step: 8
Training loss: 2.4822916984558105
Validation loss: 2.236196658944571

Epoch: 5| Step: 9
Training loss: 2.445981502532959
Validation loss: 2.2536794754766647

Epoch: 5| Step: 10
Training loss: 1.8068474531173706
Validation loss: 2.281678811196358

Epoch: 170| Step: 0
Training loss: 2.7271316051483154
Validation loss: 2.3038863315377185

Epoch: 5| Step: 1
Training loss: 2.3419647216796875
Validation loss: 2.290259873995217

Epoch: 5| Step: 2
Training loss: 2.118696689605713
Validation loss: 2.2721581125772126

Epoch: 5| Step: 3
Training loss: 2.6195318698883057
Validation loss: 2.2809311548868814

Epoch: 5| Step: 4
Training loss: 2.614109754562378
Validation loss: 2.2680220142487557

Epoch: 5| Step: 5
Training loss: 2.2273993492126465
Validation loss: 2.2570387753107215

Epoch: 5| Step: 6
Training loss: 2.8024468421936035
Validation loss: 2.261407179217185

Epoch: 5| Step: 7
Training loss: 2.749130964279175
Validation loss: 2.244503151985907

Epoch: 5| Step: 8
Training loss: 2.472128391265869
Validation loss: 2.2445989680546585

Epoch: 5| Step: 9
Training loss: 1.8487017154693604
Validation loss: 2.249855197885985

Epoch: 5| Step: 10
Training loss: 2.342484712600708
Validation loss: 2.241311647558725

Epoch: 171| Step: 0
Training loss: 2.503483533859253
Validation loss: 2.2450807068937566

Epoch: 5| Step: 1
Training loss: 2.5086658000946045
Validation loss: 2.23653228821293

Epoch: 5| Step: 2
Training loss: 2.371799945831299
Validation loss: 2.219844174641435

Epoch: 5| Step: 3
Training loss: 2.3674306869506836
Validation loss: 2.220588127772013

Epoch: 5| Step: 4
Training loss: 2.849254608154297
Validation loss: 2.2237658385307557

Epoch: 5| Step: 5
Training loss: 2.1406853199005127
Validation loss: 2.226296958102975

Epoch: 5| Step: 6
Training loss: 2.4687106609344482
Validation loss: 2.229245392225122

Epoch: 5| Step: 7
Training loss: 1.9121921062469482
Validation loss: 2.2436042242152716

Epoch: 5| Step: 8
Training loss: 2.6856908798217773
Validation loss: 2.2534861872273106

Epoch: 5| Step: 9
Training loss: 2.2842941284179688
Validation loss: 2.2799286970528225

Epoch: 5| Step: 10
Training loss: 2.7346413135528564
Validation loss: 2.29000598384488

Epoch: 172| Step: 0
Training loss: 2.0604615211486816
Validation loss: 2.248050341042139

Epoch: 5| Step: 1
Training loss: 2.61439847946167
Validation loss: 2.2381455424011394

Epoch: 5| Step: 2
Training loss: 2.655198574066162
Validation loss: 2.2276153974635626

Epoch: 5| Step: 3
Training loss: 2.8496360778808594
Validation loss: 2.2384456601194156

Epoch: 5| Step: 4
Training loss: 2.2668569087982178
Validation loss: 2.228996234555398

Epoch: 5| Step: 5
Training loss: 2.771427631378174
Validation loss: 2.2311719514990367

Epoch: 5| Step: 6
Training loss: 1.787875771522522
Validation loss: 2.2185271811741654

Epoch: 5| Step: 7
Training loss: 2.6245498657226562
Validation loss: 2.2256948768451648

Epoch: 5| Step: 8
Training loss: 2.2419004440307617
Validation loss: 2.2231931430037304

Epoch: 5| Step: 9
Training loss: 2.574514389038086
Validation loss: 2.212672136163199

Epoch: 5| Step: 10
Training loss: 2.140150308609009
Validation loss: 2.231403728967072

Epoch: 173| Step: 0
Training loss: 2.945495128631592
Validation loss: 2.222034474854828

Epoch: 5| Step: 1
Training loss: 2.479107618331909
Validation loss: 2.222211067394544

Epoch: 5| Step: 2
Training loss: 2.2242960929870605
Validation loss: 2.2248623960761615

Epoch: 5| Step: 3
Training loss: 2.4137871265411377
Validation loss: 2.2242788268673803

Epoch: 5| Step: 4
Training loss: 2.1053664684295654
Validation loss: 2.2288913137169293

Epoch: 5| Step: 5
Training loss: 2.6122522354125977
Validation loss: 2.2274298872998965

Epoch: 5| Step: 6
Training loss: 2.007063627243042
Validation loss: 2.2387340337999406

Epoch: 5| Step: 7
Training loss: 1.9244871139526367
Validation loss: 2.2357679746484243

Epoch: 5| Step: 8
Training loss: 3.0391621589660645
Validation loss: 2.2591066821928947

Epoch: 5| Step: 9
Training loss: 2.263301134109497
Validation loss: 2.2668451775786695

Epoch: 5| Step: 10
Training loss: 2.68593430519104
Validation loss: 2.2347034177472516

Epoch: 174| Step: 0
Training loss: 2.253129005432129
Validation loss: 2.2390720792995986

Epoch: 5| Step: 1
Training loss: 2.481250286102295
Validation loss: 2.2409892646215295

Epoch: 5| Step: 2
Training loss: 1.7478694915771484
Validation loss: 2.259129588321973

Epoch: 5| Step: 3
Training loss: 2.547065019607544
Validation loss: 2.2565482483115247

Epoch: 5| Step: 4
Training loss: 2.7692770957946777
Validation loss: 2.2548368502688665

Epoch: 5| Step: 5
Training loss: 2.654919147491455
Validation loss: 2.2542144457499185

Epoch: 5| Step: 6
Training loss: 2.166170835494995
Validation loss: 2.2516133785247803

Epoch: 5| Step: 7
Training loss: 2.7263829708099365
Validation loss: 2.2287130202016523

Epoch: 5| Step: 8
Training loss: 2.5609734058380127
Validation loss: 2.2398385360676754

Epoch: 5| Step: 9
Training loss: 2.386215925216675
Validation loss: 2.2372286550460325

Epoch: 5| Step: 10
Training loss: 2.4338808059692383
Validation loss: 2.222494730385401

Epoch: 175| Step: 0
Training loss: 2.4812686443328857
Validation loss: 2.226303146731469

Epoch: 5| Step: 1
Training loss: 2.3650717735290527
Validation loss: 2.239787055600074

Epoch: 5| Step: 2
Training loss: 2.52002215385437
Validation loss: 2.263639751301017

Epoch: 5| Step: 3
Training loss: 2.0590806007385254
Validation loss: 2.2880263405461467

Epoch: 5| Step: 4
Training loss: 2.1997230052948
Validation loss: 2.288550299982871

Epoch: 5| Step: 5
Training loss: 2.895815849304199
Validation loss: 2.3064722809740292

Epoch: 5| Step: 6
Training loss: 2.6086950302124023
Validation loss: 2.263777353430307

Epoch: 5| Step: 7
Training loss: 1.8517448902130127
Validation loss: 2.245403469249766

Epoch: 5| Step: 8
Training loss: 2.7037110328674316
Validation loss: 2.211357674291057

Epoch: 5| Step: 9
Training loss: 2.742097854614258
Validation loss: 2.1917311555595806

Epoch: 5| Step: 10
Training loss: 2.5092811584472656
Validation loss: 2.2025428895027406

Epoch: 176| Step: 0
Training loss: 2.6773478984832764
Validation loss: 2.1990709843174105

Epoch: 5| Step: 1
Training loss: 2.8685786724090576
Validation loss: 2.2036279760381228

Epoch: 5| Step: 2
Training loss: 1.9384136199951172
Validation loss: 2.195568524381166

Epoch: 5| Step: 3
Training loss: 2.546360969543457
Validation loss: 2.2159851340837378

Epoch: 5| Step: 4
Training loss: 2.3139395713806152
Validation loss: 2.2073378511654433

Epoch: 5| Step: 5
Training loss: 1.5555627346038818
Validation loss: 2.207873334166824

Epoch: 5| Step: 6
Training loss: 2.2152552604675293
Validation loss: 2.2087930581902944

Epoch: 5| Step: 7
Training loss: 2.615227460861206
Validation loss: 2.2094623811783327

Epoch: 5| Step: 8
Training loss: 3.1403543949127197
Validation loss: 2.20090570757466

Epoch: 5| Step: 9
Training loss: 2.8045639991760254
Validation loss: 2.2034304039452666

Epoch: 5| Step: 10
Training loss: 1.9073725938796997
Validation loss: 2.217233898819134

Epoch: 177| Step: 0
Training loss: 2.3222362995147705
Validation loss: 2.261026931065385

Epoch: 5| Step: 1
Training loss: 2.3974666595458984
Validation loss: 2.2858290851757093

Epoch: 5| Step: 2
Training loss: 2.6825642585754395
Validation loss: 2.3591588261306926

Epoch: 5| Step: 3
Training loss: 2.9428956508636475
Validation loss: 2.4091838200887046

Epoch: 5| Step: 4
Training loss: 2.134634017944336
Validation loss: 2.387984832127889

Epoch: 5| Step: 5
Training loss: 2.5797171592712402
Validation loss: 2.3313964823240876

Epoch: 5| Step: 6
Training loss: 1.9436622858047485
Validation loss: 2.2707971552366852

Epoch: 5| Step: 7
Training loss: 2.2877132892608643
Validation loss: 2.2587097793497066

Epoch: 5| Step: 8
Training loss: 2.290215492248535
Validation loss: 2.268922236657912

Epoch: 5| Step: 9
Training loss: 2.7736520767211914
Validation loss: 2.308534035118677

Epoch: 5| Step: 10
Training loss: 3.215737819671631
Validation loss: 2.346396956392514

Epoch: 178| Step: 0
Training loss: 2.051788806915283
Validation loss: 2.3687238577873475

Epoch: 5| Step: 1
Training loss: 2.061857223510742
Validation loss: 2.36108963207532

Epoch: 5| Step: 2
Training loss: 2.3432841300964355
Validation loss: 2.330481452326621

Epoch: 5| Step: 3
Training loss: 2.498115301132202
Validation loss: 2.30097093120698

Epoch: 5| Step: 4
Training loss: 2.2908473014831543
Validation loss: 2.292245395721928

Epoch: 5| Step: 5
Training loss: 2.5259487628936768
Validation loss: 2.2562287417791222

Epoch: 5| Step: 6
Training loss: 3.1119518280029297
Validation loss: 2.2435176090527604

Epoch: 5| Step: 7
Training loss: 2.820310592651367
Validation loss: 2.218221608028617

Epoch: 5| Step: 8
Training loss: 3.0395710468292236
Validation loss: 2.2041033647393666

Epoch: 5| Step: 9
Training loss: 2.52467679977417
Validation loss: 2.2058212026473014

Epoch: 5| Step: 10
Training loss: 1.7075746059417725
Validation loss: 2.2188385660930345

Epoch: 179| Step: 0
Training loss: 2.323784351348877
Validation loss: 2.2294868756366033

Epoch: 5| Step: 1
Training loss: 2.2196736335754395
Validation loss: 2.257385881998206

Epoch: 5| Step: 2
Training loss: 1.971035361289978
Validation loss: 2.274418898808059

Epoch: 5| Step: 3
Training loss: 1.9132438898086548
Validation loss: 2.26451357974801

Epoch: 5| Step: 4
Training loss: 3.34539794921875
Validation loss: 2.252563532962594

Epoch: 5| Step: 5
Training loss: 2.212689161300659
Validation loss: 2.2445186671390327

Epoch: 5| Step: 6
Training loss: 2.6002023220062256
Validation loss: 2.237931882181475

Epoch: 5| Step: 7
Training loss: 2.234196186065674
Validation loss: 2.2239105752719346

Epoch: 5| Step: 8
Training loss: 2.7205307483673096
Validation loss: 2.208994934635778

Epoch: 5| Step: 9
Training loss: 2.5363171100616455
Validation loss: 2.2138498752347884

Epoch: 5| Step: 10
Training loss: 2.896899938583374
Validation loss: 2.23019241773954

Epoch: 180| Step: 0
Training loss: 2.668196201324463
Validation loss: 2.2128540098026233

Epoch: 5| Step: 1
Training loss: 2.469844341278076
Validation loss: 2.205872210123206

Epoch: 5| Step: 2
Training loss: 2.4857938289642334
Validation loss: 2.2117008560447284

Epoch: 5| Step: 3
Training loss: 2.7261059284210205
Validation loss: 2.210124715681999

Epoch: 5| Step: 4
Training loss: 1.8068863153457642
Validation loss: 2.1969695898794357

Epoch: 5| Step: 5
Training loss: 2.8269855976104736
Validation loss: 2.197150889263358

Epoch: 5| Step: 6
Training loss: 2.286444664001465
Validation loss: 2.1938729286193848

Epoch: 5| Step: 7
Training loss: 2.666121244430542
Validation loss: 2.1883810233044367

Epoch: 5| Step: 8
Training loss: 2.331394672393799
Validation loss: 2.206442412509713

Epoch: 5| Step: 9
Training loss: 2.5884735584259033
Validation loss: 2.208239298994823

Epoch: 5| Step: 10
Training loss: 1.4330607652664185
Validation loss: 2.204858382542928

Epoch: 181| Step: 0
Training loss: 2.8223681449890137
Validation loss: 2.221629273506903

Epoch: 5| Step: 1
Training loss: 2.275475263595581
Validation loss: 2.208115518734019

Epoch: 5| Step: 2
Training loss: 2.0493836402893066
Validation loss: 2.2167848105071695

Epoch: 5| Step: 3
Training loss: 2.0672197341918945
Validation loss: 2.220910244090583

Epoch: 5| Step: 4
Training loss: 1.788304090499878
Validation loss: 2.2342096785063386

Epoch: 5| Step: 5
Training loss: 2.015542984008789
Validation loss: 2.2468004944503948

Epoch: 5| Step: 6
Training loss: 2.970463275909424
Validation loss: 2.2676421801249185

Epoch: 5| Step: 7
Training loss: 3.066545009613037
Validation loss: 2.2623386870148363

Epoch: 5| Step: 8
Training loss: 2.706895351409912
Validation loss: 2.267995595932007

Epoch: 5| Step: 9
Training loss: 2.821146011352539
Validation loss: 2.2439868680892454

Epoch: 5| Step: 10
Training loss: 1.8804787397384644
Validation loss: 2.2153201615938576

Epoch: 182| Step: 0
Training loss: 2.5625722408294678
Validation loss: 2.20600970842505

Epoch: 5| Step: 1
Training loss: 2.471389055252075
Validation loss: 2.1952563921610513

Epoch: 5| Step: 2
Training loss: 2.331533193588257
Validation loss: 2.194123129690847

Epoch: 5| Step: 3
Training loss: 1.9004850387573242
Validation loss: 2.1987203116058023

Epoch: 5| Step: 4
Training loss: 3.059115171432495
Validation loss: 2.2069739295590307

Epoch: 5| Step: 5
Training loss: 2.5077052116394043
Validation loss: 2.205988960881387

Epoch: 5| Step: 6
Training loss: 2.2592480182647705
Validation loss: 2.1951497549651773

Epoch: 5| Step: 7
Training loss: 1.8658885955810547
Validation loss: 2.19120228803286

Epoch: 5| Step: 8
Training loss: 2.26755952835083
Validation loss: 2.178078556573519

Epoch: 5| Step: 9
Training loss: 2.999434232711792
Validation loss: 2.1675261630806872

Epoch: 5| Step: 10
Training loss: 2.241276741027832
Validation loss: 2.1752588954023135

Epoch: 183| Step: 0
Training loss: 1.9274930953979492
Validation loss: 2.1643690293835056

Epoch: 5| Step: 1
Training loss: 2.4344491958618164
Validation loss: 2.163752660956434

Epoch: 5| Step: 2
Training loss: 2.5589632987976074
Validation loss: 2.1736812155733825

Epoch: 5| Step: 3
Training loss: 2.839886426925659
Validation loss: 2.1819429025855115

Epoch: 5| Step: 4
Training loss: 2.434282064437866
Validation loss: 2.204526614117366

Epoch: 5| Step: 5
Training loss: 2.7876877784729004
Validation loss: 2.1982998822325017

Epoch: 5| Step: 6
Training loss: 2.489846706390381
Validation loss: 2.2087925300803235

Epoch: 5| Step: 7
Training loss: 1.8106365203857422
Validation loss: 2.199178049641271

Epoch: 5| Step: 8
Training loss: 2.141815185546875
Validation loss: 2.2246112849122737

Epoch: 5| Step: 9
Training loss: 2.783245086669922
Validation loss: 2.207658028089872

Epoch: 5| Step: 10
Training loss: 2.0598855018615723
Validation loss: 2.2066233619566886

Epoch: 184| Step: 0
Training loss: 2.830655574798584
Validation loss: 2.208580401635939

Epoch: 5| Step: 1
Training loss: 2.8469014167785645
Validation loss: 2.229024589702647

Epoch: 5| Step: 2
Training loss: 2.730027914047241
Validation loss: 2.247224974375899

Epoch: 5| Step: 3
Training loss: 1.9366722106933594
Validation loss: 2.2617800786931026

Epoch: 5| Step: 4
Training loss: 1.8917697668075562
Validation loss: 2.2674491097850185

Epoch: 5| Step: 5
Training loss: 2.7281882762908936
Validation loss: 2.260891992558715

Epoch: 5| Step: 6
Training loss: 1.9608427286148071
Validation loss: 2.2361313425084597

Epoch: 5| Step: 7
Training loss: 2.3507211208343506
Validation loss: 2.2282308301618023

Epoch: 5| Step: 8
Training loss: 2.279287815093994
Validation loss: 2.215012417044691

Epoch: 5| Step: 9
Training loss: 2.392210006713867
Validation loss: 2.226437844255919

Epoch: 5| Step: 10
Training loss: 2.4245402812957764
Validation loss: 2.250431978574363

Epoch: 185| Step: 0
Training loss: 1.8912147283554077
Validation loss: 2.246254482576924

Epoch: 5| Step: 1
Training loss: 2.4585278034210205
Validation loss: 2.254062480823968

Epoch: 5| Step: 2
Training loss: 1.6034221649169922
Validation loss: 2.2496728076729724

Epoch: 5| Step: 3
Training loss: 2.1952853202819824
Validation loss: 2.253168195806524

Epoch: 5| Step: 4
Training loss: 2.3497314453125
Validation loss: 2.2364662770302064

Epoch: 5| Step: 5
Training loss: 2.512873411178589
Validation loss: 2.218165241261964

Epoch: 5| Step: 6
Training loss: 2.1715521812438965
Validation loss: 2.201033308941831

Epoch: 5| Step: 7
Training loss: 2.670950412750244
Validation loss: 2.2119205626108314

Epoch: 5| Step: 8
Training loss: 2.9686191082000732
Validation loss: 2.2118446468025126

Epoch: 5| Step: 9
Training loss: 2.8780903816223145
Validation loss: 2.2119193564179125

Epoch: 5| Step: 10
Training loss: 2.5711915493011475
Validation loss: 2.2134163841124503

Epoch: 186| Step: 0
Training loss: 2.791731357574463
Validation loss: 2.208684625164155

Epoch: 5| Step: 1
Training loss: 1.610259771347046
Validation loss: 2.2029273868888937

Epoch: 5| Step: 2
Training loss: 2.1680591106414795
Validation loss: 2.1998735986730105

Epoch: 5| Step: 3
Training loss: 2.3997445106506348
Validation loss: 2.1817967071328113

Epoch: 5| Step: 4
Training loss: 2.925567865371704
Validation loss: 2.1710897491824244

Epoch: 5| Step: 5
Training loss: 1.5810089111328125
Validation loss: 2.1642918509821736

Epoch: 5| Step: 6
Training loss: 2.048372268676758
Validation loss: 2.1700230593322427

Epoch: 5| Step: 7
Training loss: 2.3952877521514893
Validation loss: 2.1887698763160297

Epoch: 5| Step: 8
Training loss: 2.642704486846924
Validation loss: 2.1962137401744886

Epoch: 5| Step: 9
Training loss: 2.948850154876709
Validation loss: 2.213306062964983

Epoch: 5| Step: 10
Training loss: 3.3590588569641113
Validation loss: 2.224492678078272

Epoch: 187| Step: 0
Training loss: 1.8690084218978882
Validation loss: 2.2395213829573763

Epoch: 5| Step: 1
Training loss: 2.0300869941711426
Validation loss: 2.2504730814246723

Epoch: 5| Step: 2
Training loss: 3.0580897331237793
Validation loss: 2.241107468963951

Epoch: 5| Step: 3
Training loss: 2.869633674621582
Validation loss: 2.243417460431335

Epoch: 5| Step: 4
Training loss: 2.3335824012756348
Validation loss: 2.247518975247619

Epoch: 5| Step: 5
Training loss: 2.245555877685547
Validation loss: 2.23177517614057

Epoch: 5| Step: 6
Training loss: 2.6719300746917725
Validation loss: 2.2205173789813952

Epoch: 5| Step: 7
Training loss: 2.5724964141845703
Validation loss: 2.2338227764252694

Epoch: 5| Step: 8
Training loss: 2.699875593185425
Validation loss: 2.242100638727988

Epoch: 5| Step: 9
Training loss: 2.443077802658081
Validation loss: 2.248997944657521

Epoch: 5| Step: 10
Training loss: 1.523937702178955
Validation loss: 2.2160539857802855

Epoch: 188| Step: 0
Training loss: 2.1354172229766846
Validation loss: 2.199101291677003

Epoch: 5| Step: 1
Training loss: 2.034614324569702
Validation loss: 2.1912807572272515

Epoch: 5| Step: 2
Training loss: 2.5815582275390625
Validation loss: 2.189595942856163

Epoch: 5| Step: 3
Training loss: 2.7571914196014404
Validation loss: 2.170688321513514

Epoch: 5| Step: 4
Training loss: 1.887650489807129
Validation loss: 2.1824745439714

Epoch: 5| Step: 5
Training loss: 2.5757527351379395
Validation loss: 2.1743326212770198

Epoch: 5| Step: 6
Training loss: 2.582382917404175
Validation loss: 2.180971166139008

Epoch: 5| Step: 7
Training loss: 2.423593521118164
Validation loss: 2.1710684658378683

Epoch: 5| Step: 8
Training loss: 2.6957976818084717
Validation loss: 2.1770812490934968

Epoch: 5| Step: 9
Training loss: 2.543806791305542
Validation loss: 2.1919948798353954

Epoch: 5| Step: 10
Training loss: 2.031367301940918
Validation loss: 2.2079064384583504

Epoch: 189| Step: 0
Training loss: 3.215566635131836
Validation loss: 2.197659436092582

Epoch: 5| Step: 1
Training loss: 2.774418830871582
Validation loss: 2.184398043540216

Epoch: 5| Step: 2
Training loss: 2.864060401916504
Validation loss: 2.1694518648168093

Epoch: 5| Step: 3
Training loss: 2.316784620285034
Validation loss: 2.180189331372579

Epoch: 5| Step: 4
Training loss: 1.1303465366363525
Validation loss: 2.1675786484954176

Epoch: 5| Step: 5
Training loss: 2.372048854827881
Validation loss: 2.1734979614134757

Epoch: 5| Step: 6
Training loss: 2.5719916820526123
Validation loss: 2.1752709445133003

Epoch: 5| Step: 7
Training loss: 1.9924805164337158
Validation loss: 2.188026584604735

Epoch: 5| Step: 8
Training loss: 2.5543875694274902
Validation loss: 2.2080793380737305

Epoch: 5| Step: 9
Training loss: 2.0440289974212646
Validation loss: 2.216851585654802

Epoch: 5| Step: 10
Training loss: 2.236661911010742
Validation loss: 2.2184935923545592

Epoch: 190| Step: 0
Training loss: 2.671452760696411
Validation loss: 2.2351328480628228

Epoch: 5| Step: 1
Training loss: 2.5613932609558105
Validation loss: 2.2325861787283294

Epoch: 5| Step: 2
Training loss: 2.2672457695007324
Validation loss: 2.216122386276081

Epoch: 5| Step: 3
Training loss: 2.078552007675171
Validation loss: 2.1923294708292973

Epoch: 5| Step: 4
Training loss: 2.5826363563537598
Validation loss: 2.191175506960961

Epoch: 5| Step: 5
Training loss: 2.3069024085998535
Validation loss: 2.207471186114896

Epoch: 5| Step: 6
Training loss: 2.109898090362549
Validation loss: 2.213138141939717

Epoch: 5| Step: 7
Training loss: 2.530081272125244
Validation loss: 2.2374354177905666

Epoch: 5| Step: 8
Training loss: 2.974196434020996
Validation loss: 2.228453004232017

Epoch: 5| Step: 9
Training loss: 2.361785650253296
Validation loss: 2.219123449376834

Epoch: 5| Step: 10
Training loss: 1.708796739578247
Validation loss: 2.199876667350851

Epoch: 191| Step: 0
Training loss: 2.007956027984619
Validation loss: 2.1927977479914182

Epoch: 5| Step: 1
Training loss: 2.551053285598755
Validation loss: 2.1809044909733597

Epoch: 5| Step: 2
Training loss: 2.965125799179077
Validation loss: 2.1815938693220898

Epoch: 5| Step: 3
Training loss: 2.1977739334106445
Validation loss: 2.179250911999774

Epoch: 5| Step: 4
Training loss: 2.792952537536621
Validation loss: 2.1774231746632564

Epoch: 5| Step: 5
Training loss: 2.2589657306671143
Validation loss: 2.1767711408676638

Epoch: 5| Step: 6
Training loss: 1.8216625452041626
Validation loss: 2.1698522977931525

Epoch: 5| Step: 7
Training loss: 2.199032783508301
Validation loss: 2.171062969392346

Epoch: 5| Step: 8
Training loss: 2.583228588104248
Validation loss: 2.188454633118004

Epoch: 5| Step: 9
Training loss: 2.7257659435272217
Validation loss: 2.18662751618252

Epoch: 5| Step: 10
Training loss: 1.7610307931900024
Validation loss: 2.196852748112012

Epoch: 192| Step: 0
Training loss: 2.1628410816192627
Validation loss: 2.1860218125004924

Epoch: 5| Step: 1
Training loss: 2.142375946044922
Validation loss: 2.1746093239835513

Epoch: 5| Step: 2
Training loss: 2.914780378341675
Validation loss: 2.192680066631686

Epoch: 5| Step: 3
Training loss: 2.578345537185669
Validation loss: 2.181179669595534

Epoch: 5| Step: 4
Training loss: 2.659174680709839
Validation loss: 2.1761034727096558

Epoch: 5| Step: 5
Training loss: 2.392998218536377
Validation loss: 2.1841286946368474

Epoch: 5| Step: 6
Training loss: 2.660522937774658
Validation loss: 2.20445926215059

Epoch: 5| Step: 7
Training loss: 1.8823096752166748
Validation loss: 2.198620670585222

Epoch: 5| Step: 8
Training loss: 1.8414478302001953
Validation loss: 2.2068368824579383

Epoch: 5| Step: 9
Training loss: 2.9810023307800293
Validation loss: 2.244541819377612

Epoch: 5| Step: 10
Training loss: 1.6427342891693115
Validation loss: 2.231932742621309

Epoch: 193| Step: 0
Training loss: 2.0456671714782715
Validation loss: 2.1855891494340796

Epoch: 5| Step: 1
Training loss: 2.7038557529449463
Validation loss: 2.193224125010993

Epoch: 5| Step: 2
Training loss: 2.2894370555877686
Validation loss: 2.1851721245755433

Epoch: 5| Step: 3
Training loss: 2.084042549133301
Validation loss: 2.182809217001802

Epoch: 5| Step: 4
Training loss: 2.643852710723877
Validation loss: 2.202122447311237

Epoch: 5| Step: 5
Training loss: 1.7688583135604858
Validation loss: 2.2038467622572377

Epoch: 5| Step: 6
Training loss: 2.940702438354492
Validation loss: 2.1795924030324465

Epoch: 5| Step: 7
Training loss: 2.4232256412506104
Validation loss: 2.193093366520379

Epoch: 5| Step: 8
Training loss: 2.8144383430480957
Validation loss: 2.1968570550282798

Epoch: 5| Step: 9
Training loss: 1.9368984699249268
Validation loss: 2.1844046141511653

Epoch: 5| Step: 10
Training loss: 2.0871119499206543
Validation loss: 2.197422150642641

Epoch: 194| Step: 0
Training loss: 2.9620141983032227
Validation loss: 2.2032042639229887

Epoch: 5| Step: 1
Training loss: 2.75262451171875
Validation loss: 2.219134872959506

Epoch: 5| Step: 2
Training loss: 2.5671145915985107
Validation loss: 2.2043956556627826

Epoch: 5| Step: 3
Training loss: 2.0085556507110596
Validation loss: 2.2106558379306587

Epoch: 5| Step: 4
Training loss: 2.690718650817871
Validation loss: 2.203452789655296

Epoch: 5| Step: 5
Training loss: 2.268785238265991
Validation loss: 2.1942425645807737

Epoch: 5| Step: 6
Training loss: 2.3094217777252197
Validation loss: 2.1922111139502576

Epoch: 5| Step: 7
Training loss: 2.499851703643799
Validation loss: 2.1895686490561372

Epoch: 5| Step: 8
Training loss: 1.734931230545044
Validation loss: 2.1960166731188373

Epoch: 5| Step: 9
Training loss: 1.946056604385376
Validation loss: 2.20173220480642

Epoch: 5| Step: 10
Training loss: 2.3125314712524414
Validation loss: 2.1926045443422053

Epoch: 195| Step: 0
Training loss: 2.423330545425415
Validation loss: 2.1929500308088077

Epoch: 5| Step: 1
Training loss: 2.347684144973755
Validation loss: 2.192654246925026

Epoch: 5| Step: 2
Training loss: 2.2386364936828613
Validation loss: 2.210276185825307

Epoch: 5| Step: 3
Training loss: 3.357980251312256
Validation loss: 2.21733005585209

Epoch: 5| Step: 4
Training loss: 2.1707730293273926
Validation loss: 2.208671359605687

Epoch: 5| Step: 5
Training loss: 2.485184907913208
Validation loss: 2.1937222890956427

Epoch: 5| Step: 6
Training loss: 1.584632396697998
Validation loss: 2.185899278169037

Epoch: 5| Step: 7
Training loss: 2.146627187728882
Validation loss: 2.186478389206753

Epoch: 5| Step: 8
Training loss: 2.2811801433563232
Validation loss: 2.17163807986885

Epoch: 5| Step: 9
Training loss: 2.4917526245117188
Validation loss: 2.1940246679449595

Epoch: 5| Step: 10
Training loss: 2.3194990158081055
Validation loss: 2.1840055681044057

Epoch: 196| Step: 0
Training loss: 2.3703551292419434
Validation loss: 2.193885839113625

Epoch: 5| Step: 1
Training loss: 2.932419538497925
Validation loss: 2.1990446313734977

Epoch: 5| Step: 2
Training loss: 2.2224388122558594
Validation loss: 2.197379812117546

Epoch: 5| Step: 3
Training loss: 2.240480899810791
Validation loss: 2.192731018989317

Epoch: 5| Step: 4
Training loss: 2.122405767440796
Validation loss: 2.2041307700577604

Epoch: 5| Step: 5
Training loss: 2.395498752593994
Validation loss: 2.205428514429318

Epoch: 5| Step: 6
Training loss: 2.2066290378570557
Validation loss: 2.2194545166466826

Epoch: 5| Step: 7
Training loss: 2.5152640342712402
Validation loss: 2.1975303696047876

Epoch: 5| Step: 8
Training loss: 2.0642123222351074
Validation loss: 2.1945620403494885

Epoch: 5| Step: 9
Training loss: 2.0576655864715576
Validation loss: 2.1943921709573395

Epoch: 5| Step: 10
Training loss: 2.489372491836548
Validation loss: 2.214841427341584

Epoch: 197| Step: 0
Training loss: 2.2587649822235107
Validation loss: 2.212050522527387

Epoch: 5| Step: 1
Training loss: 2.3925554752349854
Validation loss: 2.242435852686564

Epoch: 5| Step: 2
Training loss: 1.9656283855438232
Validation loss: 2.263092435816283

Epoch: 5| Step: 3
Training loss: 2.9100067615509033
Validation loss: 2.2482062257746214

Epoch: 5| Step: 4
Training loss: 2.369380474090576
Validation loss: 2.2136082392866894

Epoch: 5| Step: 5
Training loss: 2.2350687980651855
Validation loss: 2.197813818531652

Epoch: 5| Step: 6
Training loss: 2.2583656311035156
Validation loss: 2.1654385930748394

Epoch: 5| Step: 7
Training loss: 2.3356053829193115
Validation loss: 2.1711192438679356

Epoch: 5| Step: 8
Training loss: 2.1509623527526855
Validation loss: 2.1585521723634455

Epoch: 5| Step: 9
Training loss: 2.267192840576172
Validation loss: 2.1742174343396257

Epoch: 5| Step: 10
Training loss: 2.8620071411132812
Validation loss: 2.171020079684514

Epoch: 198| Step: 0
Training loss: 2.4703187942504883
Validation loss: 2.2262695809846282

Epoch: 5| Step: 1
Training loss: 2.585696220397949
Validation loss: 2.224574645360311

Epoch: 5| Step: 2
Training loss: 2.2821640968322754
Validation loss: 2.199984642767137

Epoch: 5| Step: 3
Training loss: 1.7042700052261353
Validation loss: 2.1710121554713093

Epoch: 5| Step: 4
Training loss: 2.1189494132995605
Validation loss: 2.156452081536734

Epoch: 5| Step: 5
Training loss: 2.7434420585632324
Validation loss: 2.159894863764445

Epoch: 5| Step: 6
Training loss: 2.525616407394409
Validation loss: 2.1753102412787815

Epoch: 5| Step: 7
Training loss: 2.5760390758514404
Validation loss: 2.1856404658286803

Epoch: 5| Step: 8
Training loss: 2.7028965950012207
Validation loss: 2.18023092772371

Epoch: 5| Step: 9
Training loss: 1.7189970016479492
Validation loss: 2.198280096054077

Epoch: 5| Step: 10
Training loss: 2.7319188117980957
Validation loss: 2.2125413956180697

Epoch: 199| Step: 0
Training loss: 2.017775058746338
Validation loss: 2.1913642370572655

Epoch: 5| Step: 1
Training loss: 2.1507115364074707
Validation loss: 2.1947976363602506

Epoch: 5| Step: 2
Training loss: 2.246375560760498
Validation loss: 2.1869399906486593

Epoch: 5| Step: 3
Training loss: 2.5857365131378174
Validation loss: 2.1574640684230353

Epoch: 5| Step: 4
Training loss: 2.2622578144073486
Validation loss: 2.1773701790840394

Epoch: 5| Step: 5
Training loss: 2.4037609100341797
Validation loss: 2.1539081040249077

Epoch: 5| Step: 6
Training loss: 1.9178472757339478
Validation loss: 2.168476496973345

Epoch: 5| Step: 7
Training loss: 2.519369125366211
Validation loss: 2.185948610305786

Epoch: 5| Step: 8
Training loss: 2.767643451690674
Validation loss: 2.1805037042146087

Epoch: 5| Step: 9
Training loss: 2.4006218910217285
Validation loss: 2.1884952283674672

Epoch: 5| Step: 10
Training loss: 2.4274444580078125
Validation loss: 2.1873490400211786

Epoch: 200| Step: 0
Training loss: 2.3064780235290527
Validation loss: 2.2100836282135337

Epoch: 5| Step: 1
Training loss: 2.7451882362365723
Validation loss: 2.2313959406268213

Epoch: 5| Step: 2
Training loss: 2.7166507244110107
Validation loss: 2.27252281865766

Epoch: 5| Step: 3
Training loss: 2.3996388912200928
Validation loss: 2.31355276671789

Epoch: 5| Step: 4
Training loss: 2.533465623855591
Validation loss: 2.3476990525440504

Epoch: 5| Step: 5
Training loss: 2.27683687210083
Validation loss: 2.357422759456019

Epoch: 5| Step: 6
Training loss: 1.9465112686157227
Validation loss: 2.3607024095391713

Epoch: 5| Step: 7
Training loss: 2.610450267791748
Validation loss: 2.3198596918454735

Epoch: 5| Step: 8
Training loss: 2.6085305213928223
Validation loss: 2.3008202096467376

Epoch: 5| Step: 9
Training loss: 2.3181824684143066
Validation loss: 2.278270747071953

Epoch: 5| Step: 10
Training loss: 1.974735975265503
Validation loss: 2.256003910495389

Epoch: 201| Step: 0
Training loss: 2.481295108795166
Validation loss: 2.2287904049760554

Epoch: 5| Step: 1
Training loss: 2.2082912921905518
Validation loss: 2.217614504598802

Epoch: 5| Step: 2
Training loss: 3.081047773361206
Validation loss: 2.193850650582262

Epoch: 5| Step: 3
Training loss: 1.9079444408416748
Validation loss: 2.1675947071403585

Epoch: 5| Step: 4
Training loss: 2.1493029594421387
Validation loss: 2.137579151379165

Epoch: 5| Step: 5
Training loss: 2.3697736263275146
Validation loss: 2.1208990645664993

Epoch: 5| Step: 6
Training loss: 2.67050838470459
Validation loss: 2.123361925924978

Epoch: 5| Step: 7
Training loss: 2.319096088409424
Validation loss: 2.1220722826578284

Epoch: 5| Step: 8
Training loss: 2.190757989883423
Validation loss: 2.1151775980508454

Epoch: 5| Step: 9
Training loss: 2.652331590652466
Validation loss: 2.1150458987041185

Epoch: 5| Step: 10
Training loss: 1.891167163848877
Validation loss: 2.1271889414838565

Epoch: 202| Step: 0
Training loss: 2.1241073608398438
Validation loss: 2.1247702157625588

Epoch: 5| Step: 1
Training loss: 1.801253080368042
Validation loss: 2.1405869068637973

Epoch: 5| Step: 2
Training loss: 1.9431241750717163
Validation loss: 2.1939603359468522

Epoch: 5| Step: 3
Training loss: 2.5947866439819336
Validation loss: 2.2152461031431794

Epoch: 5| Step: 4
Training loss: 3.0471081733703613
Validation loss: 2.2423432757777553

Epoch: 5| Step: 5
Training loss: 2.1022262573242188
Validation loss: 2.2022810623209965

Epoch: 5| Step: 6
Training loss: 2.961637020111084
Validation loss: 2.1779573989170853

Epoch: 5| Step: 7
Training loss: 2.2811570167541504
Validation loss: 2.1787573650319088

Epoch: 5| Step: 8
Training loss: 2.430649518966675
Validation loss: 2.1779198902909473

Epoch: 5| Step: 9
Training loss: 2.215298891067505
Validation loss: 2.171801600404965

Epoch: 5| Step: 10
Training loss: 2.532952308654785
Validation loss: 2.170794483154051

Epoch: 203| Step: 0
Training loss: 2.515655040740967
Validation loss: 2.1748221279472433

Epoch: 5| Step: 1
Training loss: 2.2516682147979736
Validation loss: 2.1768388389259257

Epoch: 5| Step: 2
Training loss: 2.2070701122283936
Validation loss: 2.1863425367621967

Epoch: 5| Step: 3
Training loss: 2.7518582344055176
Validation loss: 2.1887378384990077

Epoch: 5| Step: 4
Training loss: 2.4173336029052734
Validation loss: 2.1869033126420874

Epoch: 5| Step: 5
Training loss: 2.0041255950927734
Validation loss: 2.174342002919925

Epoch: 5| Step: 6
Training loss: 2.561034679412842
Validation loss: 2.1892240252546085

Epoch: 5| Step: 7
Training loss: 2.314419746398926
Validation loss: 2.1734839267628168

Epoch: 5| Step: 8
Training loss: 1.9699828624725342
Validation loss: 2.1794543291932795

Epoch: 5| Step: 9
Training loss: 1.9517593383789062
Validation loss: 2.1886544778782833

Epoch: 5| Step: 10
Training loss: 2.668276071548462
Validation loss: 2.1949474529553483

Epoch: 204| Step: 0
Training loss: 2.3698201179504395
Validation loss: 2.1890902544862483

Epoch: 5| Step: 1
Training loss: 2.674950122833252
Validation loss: 2.187317704641691

Epoch: 5| Step: 2
Training loss: 2.268362045288086
Validation loss: 2.1703778056688208

Epoch: 5| Step: 3
Training loss: 1.9256080389022827
Validation loss: 2.1706079398432085

Epoch: 5| Step: 4
Training loss: 1.6670100688934326
Validation loss: 2.1584032966244604

Epoch: 5| Step: 5
Training loss: 2.095358371734619
Validation loss: 2.142415790147679

Epoch: 5| Step: 6
Training loss: 2.8552632331848145
Validation loss: 2.1558235947803785

Epoch: 5| Step: 7
Training loss: 2.1788480281829834
Validation loss: 2.1529236942209224

Epoch: 5| Step: 8
Training loss: 2.643763303756714
Validation loss: 2.1474445045635266

Epoch: 5| Step: 9
Training loss: 2.1676878929138184
Validation loss: 2.1540508347172893

Epoch: 5| Step: 10
Training loss: 2.733010768890381
Validation loss: 2.1723073015930834

Epoch: 205| Step: 0
Training loss: 2.29713773727417
Validation loss: 2.1953317401229695

Epoch: 5| Step: 1
Training loss: 2.478912591934204
Validation loss: 2.2392615784880934

Epoch: 5| Step: 2
Training loss: 2.084392547607422
Validation loss: 2.2536510703384236

Epoch: 5| Step: 3
Training loss: 2.802809000015259
Validation loss: 2.2944737352350706

Epoch: 5| Step: 4
Training loss: 2.4707448482513428
Validation loss: 2.2790761583594867

Epoch: 5| Step: 5
Training loss: 2.1730198860168457
Validation loss: 2.2366773441273677

Epoch: 5| Step: 6
Training loss: 2.326463222503662
Validation loss: 2.2183467213825514

Epoch: 5| Step: 7
Training loss: 2.810190439224243
Validation loss: 2.1784127155939736

Epoch: 5| Step: 8
Training loss: 1.9452321529388428
Validation loss: 2.2054312254792903

Epoch: 5| Step: 9
Training loss: 1.6699187755584717
Validation loss: 2.2464796163702525

Epoch: 5| Step: 10
Training loss: 2.9910080432891846
Validation loss: 2.2806915967695174

Epoch: 206| Step: 0
Training loss: 2.243628978729248
Validation loss: 2.305043512775052

Epoch: 5| Step: 1
Training loss: 2.3349106311798096
Validation loss: 2.2863253598572104

Epoch: 5| Step: 2
Training loss: 2.494870662689209
Validation loss: 2.269893979513517

Epoch: 5| Step: 3
Training loss: 2.511620044708252
Validation loss: 2.2288474882802656

Epoch: 5| Step: 4
Training loss: 2.5229830741882324
Validation loss: 2.1772381259549047

Epoch: 5| Step: 5
Training loss: 2.336515426635742
Validation loss: 2.160768731947868

Epoch: 5| Step: 6
Training loss: 2.384911060333252
Validation loss: 2.15542326178602

Epoch: 5| Step: 7
Training loss: 2.1007702350616455
Validation loss: 2.1605875363913913

Epoch: 5| Step: 8
Training loss: 2.2574174404144287
Validation loss: 2.189286128167183

Epoch: 5| Step: 9
Training loss: 2.285274028778076
Validation loss: 2.227784559290896

Epoch: 5| Step: 10
Training loss: 2.5764217376708984
Validation loss: 2.2424065348922566

Epoch: 207| Step: 0
Training loss: 2.9436464309692383
Validation loss: 2.2824629096574682

Epoch: 5| Step: 1
Training loss: 2.736546277999878
Validation loss: 2.2865669240233717

Epoch: 5| Step: 2
Training loss: 3.2358639240264893
Validation loss: 2.279226896583393

Epoch: 5| Step: 3
Training loss: 3.3045783042907715
Validation loss: 2.295558988407094

Epoch: 5| Step: 4
Training loss: 1.749036431312561
Validation loss: 2.2699037187842914

Epoch: 5| Step: 5
Training loss: 2.6002614498138428
Validation loss: 2.212817668914795

Epoch: 5| Step: 6
Training loss: 2.2388548851013184
Validation loss: 2.1713156366860993

Epoch: 5| Step: 7
Training loss: 2.1182703971862793
Validation loss: 2.142860302361109

Epoch: 5| Step: 8
Training loss: 1.755340337753296
Validation loss: 2.130799108935941

Epoch: 5| Step: 9
Training loss: 1.4343786239624023
Validation loss: 2.122019344760526

Epoch: 5| Step: 10
Training loss: 2.090221405029297
Validation loss: 2.112525132394606

Epoch: 208| Step: 0
Training loss: 2.087306499481201
Validation loss: 2.1437207101493754

Epoch: 5| Step: 1
Training loss: 1.9483048915863037
Validation loss: 2.1577918760238157

Epoch: 5| Step: 2
Training loss: 2.8570685386657715
Validation loss: 2.179420713455446

Epoch: 5| Step: 3
Training loss: 2.2733845710754395
Validation loss: 2.1798781758995465

Epoch: 5| Step: 4
Training loss: 2.682316780090332
Validation loss: 2.1835440974081717

Epoch: 5| Step: 5
Training loss: 3.31962513923645
Validation loss: 2.1762322584788003

Epoch: 5| Step: 6
Training loss: 2.109588623046875
Validation loss: 2.167922535250264

Epoch: 5| Step: 7
Training loss: 2.3944664001464844
Validation loss: 2.141567443006782

Epoch: 5| Step: 8
Training loss: 1.8941218852996826
Validation loss: 2.1364626012822634

Epoch: 5| Step: 9
Training loss: 1.8993343114852905
Validation loss: 2.159403088272259

Epoch: 5| Step: 10
Training loss: 2.303112745285034
Validation loss: 2.176814253612231

Epoch: 209| Step: 0
Training loss: 2.0833382606506348
Validation loss: 2.189409343145227

Epoch: 5| Step: 1
Training loss: 2.268688440322876
Validation loss: 2.2052042509919856

Epoch: 5| Step: 2
Training loss: 2.6433796882629395
Validation loss: 2.220106053095992

Epoch: 5| Step: 3
Training loss: 2.298722267150879
Validation loss: 2.2232988675435386

Epoch: 5| Step: 4
Training loss: 2.302250385284424
Validation loss: 2.225297958620133

Epoch: 5| Step: 5
Training loss: 1.9031034708023071
Validation loss: 2.2315525752241894

Epoch: 5| Step: 6
Training loss: 2.4774861335754395
Validation loss: 2.2153095071033766

Epoch: 5| Step: 7
Training loss: 2.2437024116516113
Validation loss: 2.2003089817621375

Epoch: 5| Step: 8
Training loss: 2.0558111667633057
Validation loss: 2.2012132816417243

Epoch: 5| Step: 9
Training loss: 2.2879438400268555
Validation loss: 2.18402018854695

Epoch: 5| Step: 10
Training loss: 3.0651769638061523
Validation loss: 2.1898299673552155

Epoch: 210| Step: 0
Training loss: 2.300236463546753
Validation loss: 2.155942904051914

Epoch: 5| Step: 1
Training loss: 2.6368861198425293
Validation loss: 2.150337121819937

Epoch: 5| Step: 2
Training loss: 2.518799304962158
Validation loss: 2.1323458635678856

Epoch: 5| Step: 3
Training loss: 1.9063564538955688
Validation loss: 2.137810032854798

Epoch: 5| Step: 4
Training loss: 2.3762850761413574
Validation loss: 2.1221046447753906

Epoch: 5| Step: 5
Training loss: 1.942375898361206
Validation loss: 2.1210358604308097

Epoch: 5| Step: 6
Training loss: 2.473992109298706
Validation loss: 2.1254326220481627

Epoch: 5| Step: 7
Training loss: 2.32737398147583
Validation loss: 2.129321707192288

Epoch: 5| Step: 8
Training loss: 2.0541365146636963
Validation loss: 2.1243144978759108

Epoch: 5| Step: 9
Training loss: 2.099247694015503
Validation loss: 2.139931132716517

Epoch: 5| Step: 10
Training loss: 2.6426351070404053
Validation loss: 2.1372271199380197

Epoch: 211| Step: 0
Training loss: 2.3993422985076904
Validation loss: 2.13928997132086

Epoch: 5| Step: 1
Training loss: 2.8917086124420166
Validation loss: 2.14928464992072

Epoch: 5| Step: 2
Training loss: 1.7578868865966797
Validation loss: 2.1425755164956533

Epoch: 5| Step: 3
Training loss: 2.1497550010681152
Validation loss: 2.1399053527462866

Epoch: 5| Step: 4
Training loss: 2.4274356365203857
Validation loss: 2.1381922075825353

Epoch: 5| Step: 5
Training loss: 2.156315326690674
Validation loss: 2.139139780434229

Epoch: 5| Step: 6
Training loss: 2.494112253189087
Validation loss: 2.135244959144182

Epoch: 5| Step: 7
Training loss: 2.727933168411255
Validation loss: 2.133574357596777

Epoch: 5| Step: 8
Training loss: 2.3025319576263428
Validation loss: 2.1277979522623043

Epoch: 5| Step: 9
Training loss: 1.9265962839126587
Validation loss: 2.1388181896619898

Epoch: 5| Step: 10
Training loss: 1.9785988330841064
Validation loss: 2.141616999462087

Epoch: 212| Step: 0
Training loss: 2.703106641769409
Validation loss: 2.135385372305429

Epoch: 5| Step: 1
Training loss: 1.5363759994506836
Validation loss: 2.129370591973746

Epoch: 5| Step: 2
Training loss: 2.662576675415039
Validation loss: 2.139696405779931

Epoch: 5| Step: 3
Training loss: 1.9946708679199219
Validation loss: 2.127158587978732

Epoch: 5| Step: 4
Training loss: 2.4905800819396973
Validation loss: 2.1314683780875257

Epoch: 5| Step: 5
Training loss: 2.475808620452881
Validation loss: 2.1346883748167302

Epoch: 5| Step: 6
Training loss: 2.5066475868225098
Validation loss: 2.1402639189074115

Epoch: 5| Step: 7
Training loss: 2.511387825012207
Validation loss: 2.1377547735809

Epoch: 5| Step: 8
Training loss: 2.3815994262695312
Validation loss: 2.1546860612848753

Epoch: 5| Step: 9
Training loss: 1.9578367471694946
Validation loss: 2.1550969616059334

Epoch: 5| Step: 10
Training loss: 1.635924220085144
Validation loss: 2.1630498632307975

Epoch: 213| Step: 0
Training loss: 2.3407628536224365
Validation loss: 2.170573772922639

Epoch: 5| Step: 1
Training loss: 2.4838192462921143
Validation loss: 2.1793908816511913

Epoch: 5| Step: 2
Training loss: 1.86865234375
Validation loss: 2.1872147129428003

Epoch: 5| Step: 3
Training loss: 2.753119945526123
Validation loss: 2.223380216988184

Epoch: 5| Step: 4
Training loss: 2.193249225616455
Validation loss: 2.231906179458864

Epoch: 5| Step: 5
Training loss: 2.5988311767578125
Validation loss: 2.2388616185034476

Epoch: 5| Step: 6
Training loss: 2.5259907245635986
Validation loss: 2.230650850521621

Epoch: 5| Step: 7
Training loss: 1.7313640117645264
Validation loss: 2.214077718796269

Epoch: 5| Step: 8
Training loss: 1.8517898321151733
Validation loss: 2.184684750854328

Epoch: 5| Step: 9
Training loss: 2.216108798980713
Validation loss: 2.180644163521387

Epoch: 5| Step: 10
Training loss: 2.5721492767333984
Validation loss: 2.166209631068732

Epoch: 214| Step: 0
Training loss: 2.308225393295288
Validation loss: 2.164814954162926

Epoch: 5| Step: 1
Training loss: 2.4568967819213867
Validation loss: 2.153528615992556

Epoch: 5| Step: 2
Training loss: 1.861280083656311
Validation loss: 2.1483637850771666

Epoch: 5| Step: 3
Training loss: 2.474208354949951
Validation loss: 2.143768673302025

Epoch: 5| Step: 4
Training loss: 3.081587553024292
Validation loss: 2.136797058966852

Epoch: 5| Step: 5
Training loss: 2.1457619667053223
Validation loss: 2.1237167696799

Epoch: 5| Step: 6
Training loss: 2.321744918823242
Validation loss: 2.137284104542066

Epoch: 5| Step: 7
Training loss: 2.6447572708129883
Validation loss: 2.1201137035123763

Epoch: 5| Step: 8
Training loss: 1.3898811340332031
Validation loss: 2.125508685265818

Epoch: 5| Step: 9
Training loss: 2.1986403465270996
Validation loss: 2.1415541838574153

Epoch: 5| Step: 10
Training loss: 1.881636381149292
Validation loss: 2.1478942235310874

Epoch: 215| Step: 0
Training loss: 1.8271558284759521
Validation loss: 2.1816127492535498

Epoch: 5| Step: 1
Training loss: 2.273581027984619
Validation loss: 2.1891386573032667

Epoch: 5| Step: 2
Training loss: 2.224306583404541
Validation loss: 2.186089031157955

Epoch: 5| Step: 3
Training loss: 2.0007941722869873
Validation loss: 2.198683423380698

Epoch: 5| Step: 4
Training loss: 2.537044048309326
Validation loss: 2.2254158630166003

Epoch: 5| Step: 5
Training loss: 2.768187999725342
Validation loss: 2.2230995009022374

Epoch: 5| Step: 6
Training loss: 2.075350761413574
Validation loss: 2.1980307166294386

Epoch: 5| Step: 7
Training loss: 2.9140114784240723
Validation loss: 2.1598537147686048

Epoch: 5| Step: 8
Training loss: 2.6280810832977295
Validation loss: 2.1551265152551795

Epoch: 5| Step: 9
Training loss: 1.7909355163574219
Validation loss: 2.144498595627405

Epoch: 5| Step: 10
Training loss: 1.7793607711791992
Validation loss: 2.138173408405755

Epoch: 216| Step: 0
Training loss: 2.0457730293273926
Validation loss: 2.1378444817758377

Epoch: 5| Step: 1
Training loss: 2.7178211212158203
Validation loss: 2.130450056445214

Epoch: 5| Step: 2
Training loss: 2.751451015472412
Validation loss: 2.1197582226927563

Epoch: 5| Step: 3
Training loss: 1.87484872341156
Validation loss: 2.1244296873769453

Epoch: 5| Step: 4
Training loss: 2.2308778762817383
Validation loss: 2.1287656330293223

Epoch: 5| Step: 5
Training loss: 2.585357666015625
Validation loss: 2.1311154621903614

Epoch: 5| Step: 6
Training loss: 1.76804518699646
Validation loss: 2.151233648741117

Epoch: 5| Step: 7
Training loss: 1.9339109659194946
Validation loss: 2.1562945330014793

Epoch: 5| Step: 8
Training loss: 1.761784553527832
Validation loss: 2.164938352441275

Epoch: 5| Step: 9
Training loss: 2.4993953704833984
Validation loss: 2.165867313261955

Epoch: 5| Step: 10
Training loss: 2.7256321907043457
Validation loss: 2.1629023295576855

Epoch: 217| Step: 0
Training loss: 2.2772631645202637
Validation loss: 2.160785767339891

Epoch: 5| Step: 1
Training loss: 2.6863527297973633
Validation loss: 2.1707280502524426

Epoch: 5| Step: 2
Training loss: 2.003321647644043
Validation loss: 2.1799472173055015

Epoch: 5| Step: 3
Training loss: 2.6024463176727295
Validation loss: 2.1691565411065215

Epoch: 5| Step: 4
Training loss: 2.273364782333374
Validation loss: 2.1724467995346233

Epoch: 5| Step: 5
Training loss: 1.8808965682983398
Validation loss: 2.179916668963689

Epoch: 5| Step: 6
Training loss: 2.244560956954956
Validation loss: 2.1880273408787225

Epoch: 5| Step: 7
Training loss: 2.174370288848877
Validation loss: 2.180609626154746

Epoch: 5| Step: 8
Training loss: 2.141420364379883
Validation loss: 2.1815846043248333

Epoch: 5| Step: 9
Training loss: 2.5631425380706787
Validation loss: 2.179874584239016

Epoch: 5| Step: 10
Training loss: 1.9426521062850952
Validation loss: 2.16320615173668

Epoch: 218| Step: 0
Training loss: 1.9929695129394531
Validation loss: 2.160250143338275

Epoch: 5| Step: 1
Training loss: 2.507963180541992
Validation loss: 2.1587078699501614

Epoch: 5| Step: 2
Training loss: 2.3849074840545654
Validation loss: 2.141257042525917

Epoch: 5| Step: 3
Training loss: 1.9182612895965576
Validation loss: 2.1413910235128095

Epoch: 5| Step: 4
Training loss: 2.0342986583709717
Validation loss: 2.146728648934313

Epoch: 5| Step: 5
Training loss: 1.4767814874649048
Validation loss: 2.151888967842184

Epoch: 5| Step: 6
Training loss: 2.646531105041504
Validation loss: 2.161699028425319

Epoch: 5| Step: 7
Training loss: 2.534691333770752
Validation loss: 2.1537841750729467

Epoch: 5| Step: 8
Training loss: 2.643728494644165
Validation loss: 2.1563067410581853

Epoch: 5| Step: 9
Training loss: 2.4035236835479736
Validation loss: 2.1564322466491372

Epoch: 5| Step: 10
Training loss: 2.0223886966705322
Validation loss: 2.164485090522356

Epoch: 219| Step: 0
Training loss: 2.4727859497070312
Validation loss: 2.1545398824958393

Epoch: 5| Step: 1
Training loss: 2.7761435508728027
Validation loss: 2.151159537735806

Epoch: 5| Step: 2
Training loss: 2.2741973400115967
Validation loss: 2.140549821238364

Epoch: 5| Step: 3
Training loss: 1.7620418071746826
Validation loss: 2.140013564017511

Epoch: 5| Step: 4
Training loss: 2.510014772415161
Validation loss: 2.132801536590822

Epoch: 5| Step: 5
Training loss: 2.2943332195281982
Validation loss: 2.137263371098426

Epoch: 5| Step: 6
Training loss: 1.6246408224105835
Validation loss: 2.126067482015138

Epoch: 5| Step: 7
Training loss: 2.415949583053589
Validation loss: 2.12527705777076

Epoch: 5| Step: 8
Training loss: 1.7860183715820312
Validation loss: 2.12202819701164

Epoch: 5| Step: 9
Training loss: 2.355217695236206
Validation loss: 2.133768053464992

Epoch: 5| Step: 10
Training loss: 2.378690719604492
Validation loss: 2.1309505867701706

Epoch: 220| Step: 0
Training loss: 1.9395326375961304
Validation loss: 2.1381502305307696

Epoch: 5| Step: 1
Training loss: 1.6129302978515625
Validation loss: 2.1548532157815914

Epoch: 5| Step: 2
Training loss: 2.521735668182373
Validation loss: 2.13923583492156

Epoch: 5| Step: 3
Training loss: 1.7562458515167236
Validation loss: 2.137583173731322

Epoch: 5| Step: 4
Training loss: 2.8372817039489746
Validation loss: 2.1308194232243363

Epoch: 5| Step: 5
Training loss: 2.1220710277557373
Validation loss: 2.131549717277609

Epoch: 5| Step: 6
Training loss: 2.016396999359131
Validation loss: 2.126000101848315

Epoch: 5| Step: 7
Training loss: 2.919203996658325
Validation loss: 2.1240789249379146

Epoch: 5| Step: 8
Training loss: 2.324368715286255
Validation loss: 2.1238967628889185

Epoch: 5| Step: 9
Training loss: 2.034416437149048
Validation loss: 2.1303447087605796

Epoch: 5| Step: 10
Training loss: 2.4751217365264893
Validation loss: 2.1365348882572626

Epoch: 221| Step: 0
Training loss: 2.443162441253662
Validation loss: 2.141994935210033

Epoch: 5| Step: 1
Training loss: 2.4478163719177246
Validation loss: 2.1493433188366633

Epoch: 5| Step: 2
Training loss: 1.9742454290390015
Validation loss: 2.139170117275689

Epoch: 5| Step: 3
Training loss: 1.815871238708496
Validation loss: 2.1342769681766467

Epoch: 5| Step: 4
Training loss: 2.195528268814087
Validation loss: 2.147140323474843

Epoch: 5| Step: 5
Training loss: 2.2746500968933105
Validation loss: 2.146895557321528

Epoch: 5| Step: 6
Training loss: 2.6453793048858643
Validation loss: 2.179083171711173

Epoch: 5| Step: 7
Training loss: 2.4278321266174316
Validation loss: 2.1897241223242974

Epoch: 5| Step: 8
Training loss: 1.946844458580017
Validation loss: 2.1669785643136628

Epoch: 5| Step: 9
Training loss: 1.62017023563385
Validation loss: 2.163557724286151

Epoch: 5| Step: 10
Training loss: 2.8835771083831787
Validation loss: 2.1496257397436325

Epoch: 222| Step: 0
Training loss: 2.6200919151306152
Validation loss: 2.1437195167746594

Epoch: 5| Step: 1
Training loss: 1.939992904663086
Validation loss: 2.149889620401526

Epoch: 5| Step: 2
Training loss: 1.7124675512313843
Validation loss: 2.1445911340816046

Epoch: 5| Step: 3
Training loss: 2.629443645477295
Validation loss: 2.160179025383406

Epoch: 5| Step: 4
Training loss: 2.0263640880584717
Validation loss: 2.1550657992721884

Epoch: 5| Step: 5
Training loss: 2.5354363918304443
Validation loss: 2.1656873123620146

Epoch: 5| Step: 6
Training loss: 2.9439284801483154
Validation loss: 2.1564295496991885

Epoch: 5| Step: 7
Training loss: 2.3341450691223145
Validation loss: 2.164140667966617

Epoch: 5| Step: 8
Training loss: 2.8204498291015625
Validation loss: 2.1568491074346725

Epoch: 5| Step: 9
Training loss: 1.642816185951233
Validation loss: 2.172094178456132

Epoch: 5| Step: 10
Training loss: 1.1602628231048584
Validation loss: 2.1867611228778796

Epoch: 223| Step: 0
Training loss: 2.1717562675476074
Validation loss: 2.2067499622221916

Epoch: 5| Step: 1
Training loss: 2.616058588027954
Validation loss: 2.1952903219448623

Epoch: 5| Step: 2
Training loss: 2.04661226272583
Validation loss: 2.2142327267636537

Epoch: 5| Step: 3
Training loss: 2.422144651412964
Validation loss: 2.1631831968984296

Epoch: 5| Step: 4
Training loss: 2.393854856491089
Validation loss: 2.1255547051788657

Epoch: 5| Step: 5
Training loss: 2.0985169410705566
Validation loss: 2.0957389006050686

Epoch: 5| Step: 6
Training loss: 1.766242265701294
Validation loss: 2.1104147152234147

Epoch: 5| Step: 7
Training loss: 2.266366481781006
Validation loss: 2.122540044528182

Epoch: 5| Step: 8
Training loss: 2.343303918838501
Validation loss: 2.136190004246209

Epoch: 5| Step: 9
Training loss: 2.7908217906951904
Validation loss: 2.1434930447609193

Epoch: 5| Step: 10
Training loss: 1.8507716655731201
Validation loss: 2.159532359851304

Epoch: 224| Step: 0
Training loss: 2.229518175125122
Validation loss: 2.1487411645150956

Epoch: 5| Step: 1
Training loss: 2.482313394546509
Validation loss: 2.0959922472635903

Epoch: 5| Step: 2
Training loss: 1.9178011417388916
Validation loss: 2.112221528125066

Epoch: 5| Step: 3
Training loss: 1.7951520681381226
Validation loss: 2.143846963041572

Epoch: 5| Step: 4
Training loss: 2.9732794761657715
Validation loss: 2.206687088935606

Epoch: 5| Step: 5
Training loss: 2.2250142097473145
Validation loss: 2.2457380371709026

Epoch: 5| Step: 6
Training loss: 2.3802952766418457
Validation loss: 2.2504816311661915

Epoch: 5| Step: 7
Training loss: 2.3638057708740234
Validation loss: 2.252402869603967

Epoch: 5| Step: 8
Training loss: 2.698716163635254
Validation loss: 2.256538309076781

Epoch: 5| Step: 9
Training loss: 2.2071261405944824
Validation loss: 2.2346910533084663

Epoch: 5| Step: 10
Training loss: 2.2054646015167236
Validation loss: 2.1778431553994455

Epoch: 225| Step: 0
Training loss: 2.2698616981506348
Validation loss: 2.173252523586314

Epoch: 5| Step: 1
Training loss: 1.8729336261749268
Validation loss: 2.1393049763094996

Epoch: 5| Step: 2
Training loss: 2.4325718879699707
Validation loss: 2.163300807758044

Epoch: 5| Step: 3
Training loss: 2.585890293121338
Validation loss: 2.193682211701588

Epoch: 5| Step: 4
Training loss: 2.0901451110839844
Validation loss: 2.22334595136745

Epoch: 5| Step: 5
Training loss: 2.160304307937622
Validation loss: 2.229822809978198

Epoch: 5| Step: 6
Training loss: 1.894667625427246
Validation loss: 2.2082824130212106

Epoch: 5| Step: 7
Training loss: 2.7652316093444824
Validation loss: 2.1821797970802552

Epoch: 5| Step: 8
Training loss: 2.133225440979004
Validation loss: 2.1621168710852183

Epoch: 5| Step: 9
Training loss: 2.289030075073242
Validation loss: 2.1245420735369445

Epoch: 5| Step: 10
Training loss: 2.424654245376587
Validation loss: 2.107432482063129

Epoch: 226| Step: 0
Training loss: 1.8646562099456787
Validation loss: 2.106508949751495

Epoch: 5| Step: 1
Training loss: 2.439444065093994
Validation loss: 2.1109887399981098

Epoch: 5| Step: 2
Training loss: 1.839850664138794
Validation loss: 2.123082358350036

Epoch: 5| Step: 3
Training loss: 2.1841540336608887
Validation loss: 2.099651023905764

Epoch: 5| Step: 4
Training loss: 1.9936492443084717
Validation loss: 2.088138485467562

Epoch: 5| Step: 5
Training loss: 2.288620948791504
Validation loss: 2.078500988662884

Epoch: 5| Step: 6
Training loss: 2.759178876876831
Validation loss: 2.0682419089860815

Epoch: 5| Step: 7
Training loss: 2.4621658325195312
Validation loss: 2.088410122420198

Epoch: 5| Step: 8
Training loss: 2.2965712547302246
Validation loss: 2.088068377587103

Epoch: 5| Step: 9
Training loss: 1.8523164987564087
Validation loss: 2.082936907327303

Epoch: 5| Step: 10
Training loss: 2.741441011428833
Validation loss: 2.0920862997731855

Epoch: 227| Step: 0
Training loss: 2.187990665435791
Validation loss: 2.0881085857268302

Epoch: 5| Step: 1
Training loss: 2.4921650886535645
Validation loss: 2.108947411660225

Epoch: 5| Step: 2
Training loss: 1.7602554559707642
Validation loss: 2.1236030235085437

Epoch: 5| Step: 3
Training loss: 2.0894217491149902
Validation loss: 2.159027268809657

Epoch: 5| Step: 4
Training loss: 2.4376420974731445
Validation loss: 2.1513709586153746

Epoch: 5| Step: 5
Training loss: 2.4464786052703857
Validation loss: 2.1429475815065446

Epoch: 5| Step: 6
Training loss: 2.3599860668182373
Validation loss: 2.1205741179886686

Epoch: 5| Step: 7
Training loss: 1.7909634113311768
Validation loss: 2.1102160253832416

Epoch: 5| Step: 8
Training loss: 2.1443989276885986
Validation loss: 2.1007453703111216

Epoch: 5| Step: 9
Training loss: 2.564363479614258
Validation loss: 2.111554991814398

Epoch: 5| Step: 10
Training loss: 1.9355756044387817
Validation loss: 2.1077763649725143

Epoch: 228| Step: 0
Training loss: 2.568096399307251
Validation loss: 2.1219194089212725

Epoch: 5| Step: 1
Training loss: 2.2340381145477295
Validation loss: 2.1192151833606023

Epoch: 5| Step: 2
Training loss: 1.9360042810440063
Validation loss: 2.1084573243253972

Epoch: 5| Step: 3
Training loss: 2.2248501777648926
Validation loss: 2.125871463488507

Epoch: 5| Step: 4
Training loss: 1.6340583562850952
Validation loss: 2.1344965837335073

Epoch: 5| Step: 5
Training loss: 2.3131229877471924
Validation loss: 2.1492702550785516

Epoch: 5| Step: 6
Training loss: 2.4008431434631348
Validation loss: 2.164527452120217

Epoch: 5| Step: 7
Training loss: 1.808807373046875
Validation loss: 2.1633939999406055

Epoch: 5| Step: 8
Training loss: 2.238971710205078
Validation loss: 2.1793290363845004

Epoch: 5| Step: 9
Training loss: 2.1933608055114746
Validation loss: 2.2040106455485025

Epoch: 5| Step: 10
Training loss: 2.736783266067505
Validation loss: 2.204527226827478

Epoch: 229| Step: 0
Training loss: 1.5766962766647339
Validation loss: 2.1860249991058023

Epoch: 5| Step: 1
Training loss: 2.4870445728302
Validation loss: 2.174220344071747

Epoch: 5| Step: 2
Training loss: 2.055133819580078
Validation loss: 2.1944679649927283

Epoch: 5| Step: 3
Training loss: 2.032905101776123
Validation loss: 2.1726035559049217

Epoch: 5| Step: 4
Training loss: 2.129946231842041
Validation loss: 2.151971229942896

Epoch: 5| Step: 5
Training loss: 2.3444504737854004
Validation loss: 2.1567946698075984

Epoch: 5| Step: 6
Training loss: 3.2506937980651855
Validation loss: 2.1550679001756894

Epoch: 5| Step: 7
Training loss: 2.376885175704956
Validation loss: 2.122848262069046

Epoch: 5| Step: 8
Training loss: 1.5839637517929077
Validation loss: 2.0792154137806227

Epoch: 5| Step: 9
Training loss: 2.042973279953003
Validation loss: 2.090238704476305

Epoch: 5| Step: 10
Training loss: 2.276639938354492
Validation loss: 2.097120641380228

Epoch: 230| Step: 0
Training loss: 1.9357436895370483
Validation loss: 2.100679628310665

Epoch: 5| Step: 1
Training loss: 2.291538953781128
Validation loss: 2.10109402543755

Epoch: 5| Step: 2
Training loss: 1.6282768249511719
Validation loss: 2.0898493361729447

Epoch: 5| Step: 3
Training loss: 2.6451809406280518
Validation loss: 2.0910883616375666

Epoch: 5| Step: 4
Training loss: 2.3745381832122803
Validation loss: 2.1002447989679154

Epoch: 5| Step: 5
Training loss: 1.8925749063491821
Validation loss: 2.110657852183106

Epoch: 5| Step: 6
Training loss: 1.935402512550354
Validation loss: 2.1290351729239188

Epoch: 5| Step: 7
Training loss: 2.282433271408081
Validation loss: 2.158271425513811

Epoch: 5| Step: 8
Training loss: 2.576711893081665
Validation loss: 2.151185402306177

Epoch: 5| Step: 9
Training loss: 2.558263063430786
Validation loss: 2.1724446999129428

Epoch: 5| Step: 10
Training loss: 2.1234569549560547
Validation loss: 2.1729456840022916

Epoch: 231| Step: 0
Training loss: 2.049431324005127
Validation loss: 2.1725206503304104

Epoch: 5| Step: 1
Training loss: 2.1472012996673584
Validation loss: 2.1486388175718245

Epoch: 5| Step: 2
Training loss: 1.4757039546966553
Validation loss: 2.136762644654961

Epoch: 5| Step: 3
Training loss: 2.3509106636047363
Validation loss: 2.107677600717032

Epoch: 5| Step: 4
Training loss: 2.4588286876678467
Validation loss: 2.1159440791735085

Epoch: 5| Step: 5
Training loss: 2.8418452739715576
Validation loss: 2.131448274017662

Epoch: 5| Step: 6
Training loss: 1.850794792175293
Validation loss: 2.1327922510844406

Epoch: 5| Step: 7
Training loss: 1.9998178482055664
Validation loss: 2.1475495830658944

Epoch: 5| Step: 8
Training loss: 1.9965393543243408
Validation loss: 2.119261157128119

Epoch: 5| Step: 9
Training loss: 2.1486899852752686
Validation loss: 2.1447682560131116

Epoch: 5| Step: 10
Training loss: 2.794875383377075
Validation loss: 2.149988007801835

Epoch: 232| Step: 0
Training loss: 2.1362500190734863
Validation loss: 2.161719588823216

Epoch: 5| Step: 1
Training loss: 2.3116917610168457
Validation loss: 2.1645836484047676

Epoch: 5| Step: 2
Training loss: 1.9044554233551025
Validation loss: 2.170954377420487

Epoch: 5| Step: 3
Training loss: 2.5617382526397705
Validation loss: 2.175735549260211

Epoch: 5| Step: 4
Training loss: 2.204683780670166
Validation loss: 2.1729995871102936

Epoch: 5| Step: 5
Training loss: 2.0683627128601074
Validation loss: 2.1784251274601107

Epoch: 5| Step: 6
Training loss: 2.1221096515655518
Validation loss: 2.18554671349064

Epoch: 5| Step: 7
Training loss: 2.277873992919922
Validation loss: 2.1764981708218976

Epoch: 5| Step: 8
Training loss: 1.8274444341659546
Validation loss: 2.1652189249633462

Epoch: 5| Step: 9
Training loss: 2.112968683242798
Validation loss: 2.173268154103269

Epoch: 5| Step: 10
Training loss: 2.444448232650757
Validation loss: 2.151105237263505

Epoch: 233| Step: 0
Training loss: 2.5131607055664062
Validation loss: 2.139448014638757

Epoch: 5| Step: 1
Training loss: 2.0745291709899902
Validation loss: 2.1070107336967223

Epoch: 5| Step: 2
Training loss: 2.094278335571289
Validation loss: 2.105113990845219

Epoch: 5| Step: 3
Training loss: 2.664219856262207
Validation loss: 2.1012542158044796

Epoch: 5| Step: 4
Training loss: 1.5182440280914307
Validation loss: 2.0993684889167867

Epoch: 5| Step: 5
Training loss: 1.5622559785842896
Validation loss: 2.1125917447510587

Epoch: 5| Step: 6
Training loss: 2.779421091079712
Validation loss: 2.0981475563459497

Epoch: 5| Step: 7
Training loss: 1.8280054330825806
Validation loss: 2.0811627731528333

Epoch: 5| Step: 8
Training loss: 2.7908496856689453
Validation loss: 2.078129247952533

Epoch: 5| Step: 9
Training loss: 1.8412431478500366
Validation loss: 2.0600440527803157

Epoch: 5| Step: 10
Training loss: 2.4792251586914062
Validation loss: 2.0778510647435344

Epoch: 234| Step: 0
Training loss: 2.504179000854492
Validation loss: 2.066980484993227

Epoch: 5| Step: 1
Training loss: 2.731698989868164
Validation loss: 2.0776950492653796

Epoch: 5| Step: 2
Training loss: 2.14957332611084
Validation loss: 2.09940367872997

Epoch: 5| Step: 3
Training loss: 1.783077597618103
Validation loss: 2.101354765635665

Epoch: 5| Step: 4
Training loss: 1.9664138555526733
Validation loss: 2.12023425614962

Epoch: 5| Step: 5
Training loss: 2.249673843383789
Validation loss: 2.1279830163524998

Epoch: 5| Step: 6
Training loss: 2.691178798675537
Validation loss: 2.1353536677616898

Epoch: 5| Step: 7
Training loss: 1.4491088390350342
Validation loss: 2.140193828972437

Epoch: 5| Step: 8
Training loss: 2.3765337467193604
Validation loss: 2.149765355612642

Epoch: 5| Step: 9
Training loss: 2.0956759452819824
Validation loss: 2.1525914989491945

Epoch: 5| Step: 10
Training loss: 1.7419710159301758
Validation loss: 2.161002364209903

Epoch: 235| Step: 0
Training loss: 2.5563385486602783
Validation loss: 2.1596857360614243

Epoch: 5| Step: 1
Training loss: 1.4293025732040405
Validation loss: 2.1568502328729116

Epoch: 5| Step: 2
Training loss: 2.118365526199341
Validation loss: 2.1426892395942443

Epoch: 5| Step: 3
Training loss: 1.731357216835022
Validation loss: 2.137032442195441

Epoch: 5| Step: 4
Training loss: 2.303328037261963
Validation loss: 2.1079965945213073

Epoch: 5| Step: 5
Training loss: 1.847277283668518
Validation loss: 2.107901293744323

Epoch: 5| Step: 6
Training loss: 2.06564998626709
Validation loss: 2.1037346547649753

Epoch: 5| Step: 7
Training loss: 2.399527072906494
Validation loss: 2.1063414491632932

Epoch: 5| Step: 8
Training loss: 2.5160038471221924
Validation loss: 2.094555554851409

Epoch: 5| Step: 9
Training loss: 2.575230836868286
Validation loss: 2.084642356441867

Epoch: 5| Step: 10
Training loss: 2.251786947250366
Validation loss: 2.0951978250216414

Epoch: 236| Step: 0
Training loss: 1.9329936504364014
Validation loss: 2.095304489135742

Epoch: 5| Step: 1
Training loss: 2.021561622619629
Validation loss: 2.1079454729633946

Epoch: 5| Step: 2
Training loss: 2.1880264282226562
Validation loss: 2.1032893888411985

Epoch: 5| Step: 3
Training loss: 1.601294755935669
Validation loss: 2.111660131844141

Epoch: 5| Step: 4
Training loss: 2.3079075813293457
Validation loss: 2.1193995911587953

Epoch: 5| Step: 5
Training loss: 2.0092594623565674
Validation loss: 2.109793870679794

Epoch: 5| Step: 6
Training loss: 1.6190922260284424
Validation loss: 2.1061227526716007

Epoch: 5| Step: 7
Training loss: 2.0778002738952637
Validation loss: 2.1382164032228532

Epoch: 5| Step: 8
Training loss: 2.5465121269226074
Validation loss: 2.1238087966877925

Epoch: 5| Step: 9
Training loss: 2.281635046005249
Validation loss: 2.1171103267259497

Epoch: 5| Step: 10
Training loss: 3.257615089416504
Validation loss: 2.147714784068446

Epoch: 237| Step: 0
Training loss: 1.9901634454727173
Validation loss: 2.1421230710962766

Epoch: 5| Step: 1
Training loss: 1.868341088294983
Validation loss: 2.12185090075257

Epoch: 5| Step: 2
Training loss: 2.3826756477355957
Validation loss: 2.1231840092648744

Epoch: 5| Step: 3
Training loss: 2.708648681640625
Validation loss: 2.109920338917804

Epoch: 5| Step: 4
Training loss: 1.9091804027557373
Validation loss: 2.126166610307591

Epoch: 5| Step: 5
Training loss: 1.9419052600860596
Validation loss: 2.1213744096858527

Epoch: 5| Step: 6
Training loss: 2.608358860015869
Validation loss: 2.13498862584432

Epoch: 5| Step: 7
Training loss: 2.697758197784424
Validation loss: 2.121699902319139

Epoch: 5| Step: 8
Training loss: 1.7577955722808838
Validation loss: 2.1051636203642814

Epoch: 5| Step: 9
Training loss: 2.508991241455078
Validation loss: 2.091251827055408

Epoch: 5| Step: 10
Training loss: 1.7559418678283691
Validation loss: 2.0983209827894806

Epoch: 238| Step: 0
Training loss: 2.6261210441589355
Validation loss: 2.1344007356192476

Epoch: 5| Step: 1
Training loss: 1.8223358392715454
Validation loss: 2.148257996446343

Epoch: 5| Step: 2
Training loss: 2.3597681522369385
Validation loss: 2.1623311683695805

Epoch: 5| Step: 3
Training loss: 1.3033459186553955
Validation loss: 2.1604734851467993

Epoch: 5| Step: 4
Training loss: 2.4213809967041016
Validation loss: 2.159387767955821

Epoch: 5| Step: 5
Training loss: 1.7996629476547241
Validation loss: 2.1386468179764284

Epoch: 5| Step: 6
Training loss: 2.5714735984802246
Validation loss: 2.1172292386331866

Epoch: 5| Step: 7
Training loss: 2.24145770072937
Validation loss: 2.1092783866390103

Epoch: 5| Step: 8
Training loss: 2.2174296379089355
Validation loss: 2.110057689810312

Epoch: 5| Step: 9
Training loss: 1.6324783563613892
Validation loss: 2.10346632875422

Epoch: 5| Step: 10
Training loss: 2.8459906578063965
Validation loss: 2.1199619462413173

Epoch: 239| Step: 0
Training loss: 2.6925060749053955
Validation loss: 2.115450200214181

Epoch: 5| Step: 1
Training loss: 1.7885675430297852
Validation loss: 2.113075976730675

Epoch: 5| Step: 2
Training loss: 2.6630444526672363
Validation loss: 2.110979862110589

Epoch: 5| Step: 3
Training loss: 2.0836422443389893
Validation loss: 2.126115906623102

Epoch: 5| Step: 4
Training loss: 2.653536796569824
Validation loss: 2.124891678492228

Epoch: 5| Step: 5
Training loss: 2.047611713409424
Validation loss: 2.127730559277278

Epoch: 5| Step: 6
Training loss: 2.2304348945617676
Validation loss: 2.1164490612604285

Epoch: 5| Step: 7
Training loss: 1.931968331336975
Validation loss: 2.132088780403137

Epoch: 5| Step: 8
Training loss: 1.3859713077545166
Validation loss: 2.1308834527128484

Epoch: 5| Step: 9
Training loss: 1.9470932483673096
Validation loss: 2.143485774276077

Epoch: 5| Step: 10
Training loss: 2.248607873916626
Validation loss: 2.1399548335741927

Epoch: 240| Step: 0
Training loss: 1.5799026489257812
Validation loss: 2.140536851780389

Epoch: 5| Step: 1
Training loss: 3.386086940765381
Validation loss: 2.144058576194189

Epoch: 5| Step: 2
Training loss: 2.259552478790283
Validation loss: 2.1377735471212738

Epoch: 5| Step: 3
Training loss: 2.1638150215148926
Validation loss: 2.1333326806304274

Epoch: 5| Step: 4
Training loss: 1.8725407123565674
Validation loss: 2.1237782457823395

Epoch: 5| Step: 5
Training loss: 2.0801029205322266
Validation loss: 2.1248807355921757

Epoch: 5| Step: 6
Training loss: 1.9599297046661377
Validation loss: 2.1138965365707234

Epoch: 5| Step: 7
Training loss: 1.9459327459335327
Validation loss: 2.129018270841209

Epoch: 5| Step: 8
Training loss: 2.2956128120422363
Validation loss: 2.129268720585813

Epoch: 5| Step: 9
Training loss: 1.6954447031021118
Validation loss: 2.117713584694811

Epoch: 5| Step: 10
Training loss: 2.263942241668701
Validation loss: 2.129540910003006

Epoch: 241| Step: 0
Training loss: 2.1464335918426514
Validation loss: 2.1249189017921366

Epoch: 5| Step: 1
Training loss: 2.4043681621551514
Validation loss: 2.125902304085352

Epoch: 5| Step: 2
Training loss: 2.2013535499572754
Validation loss: 2.1323701604720084

Epoch: 5| Step: 3
Training loss: 2.2835030555725098
Validation loss: 2.115128617132864

Epoch: 5| Step: 4
Training loss: 1.933847188949585
Validation loss: 2.1210891533923406

Epoch: 5| Step: 5
Training loss: 1.9869840145111084
Validation loss: 2.1384852163253294

Epoch: 5| Step: 6
Training loss: 1.9603525400161743
Validation loss: 2.1423227248653287

Epoch: 5| Step: 7
Training loss: 2.333555221557617
Validation loss: 2.1503611585145355

Epoch: 5| Step: 8
Training loss: 1.7520296573638916
Validation loss: 2.118202942673878

Epoch: 5| Step: 9
Training loss: 2.094663381576538
Validation loss: 2.11407402125738

Epoch: 5| Step: 10
Training loss: 2.185203790664673
Validation loss: 2.094235973973428

Epoch: 242| Step: 0
Training loss: 2.3334507942199707
Validation loss: 2.106287767810206

Epoch: 5| Step: 1
Training loss: 2.205334424972534
Validation loss: 2.0990831236685477

Epoch: 5| Step: 2
Training loss: 2.2773075103759766
Validation loss: 2.087183867731402

Epoch: 5| Step: 3
Training loss: 2.0794098377227783
Validation loss: 2.098936080932617

Epoch: 5| Step: 4
Training loss: 2.222729444503784
Validation loss: 2.0967731347648044

Epoch: 5| Step: 5
Training loss: 1.7422142028808594
Validation loss: 2.1137883534995456

Epoch: 5| Step: 6
Training loss: 1.9418007135391235
Validation loss: 2.112099011739095

Epoch: 5| Step: 7
Training loss: 1.6054052114486694
Validation loss: 2.107377424035021

Epoch: 5| Step: 8
Training loss: 1.9362043142318726
Validation loss: 2.1049206461957706

Epoch: 5| Step: 9
Training loss: 2.2022464275360107
Validation loss: 2.102220530151039

Epoch: 5| Step: 10
Training loss: 2.903853416442871
Validation loss: 2.13140276170546

Epoch: 243| Step: 0
Training loss: 2.4852182865142822
Validation loss: 2.141259419020786

Epoch: 5| Step: 1
Training loss: 2.2343883514404297
Validation loss: 2.152460753276784

Epoch: 5| Step: 2
Training loss: 2.025421142578125
Validation loss: 2.1711213255441315

Epoch: 5| Step: 3
Training loss: 1.9065501689910889
Validation loss: 2.177840259767348

Epoch: 5| Step: 4
Training loss: 1.3292925357818604
Validation loss: 2.164132300243583

Epoch: 5| Step: 5
Training loss: 1.775617003440857
Validation loss: 2.156832156642791

Epoch: 5| Step: 6
Training loss: 2.5422749519348145
Validation loss: 2.14809650246815

Epoch: 5| Step: 7
Training loss: 2.1673226356506348
Validation loss: 2.139611239074379

Epoch: 5| Step: 8
Training loss: 2.454498052597046
Validation loss: 2.117783918175646

Epoch: 5| Step: 9
Training loss: 2.7513363361358643
Validation loss: 2.107218106587728

Epoch: 5| Step: 10
Training loss: 1.4326871633529663
Validation loss: 2.0942411884184806

Epoch: 244| Step: 0
Training loss: 1.6007846593856812
Validation loss: 2.0812336629436863

Epoch: 5| Step: 1
Training loss: 1.9434998035430908
Validation loss: 2.0628479014160814

Epoch: 5| Step: 2
Training loss: 2.4727120399475098
Validation loss: 2.050138574774547

Epoch: 5| Step: 3
Training loss: 2.211900234222412
Validation loss: 2.064499528177323

Epoch: 5| Step: 4
Training loss: 1.973889708518982
Validation loss: 2.0560016529534453

Epoch: 5| Step: 5
Training loss: 2.070106029510498
Validation loss: 2.0674136787332515

Epoch: 5| Step: 6
Training loss: 2.1599955558776855
Validation loss: 2.067767668795842

Epoch: 5| Step: 7
Training loss: 2.211054801940918
Validation loss: 2.0776905180305563

Epoch: 5| Step: 8
Training loss: 2.4510769844055176
Validation loss: 2.0931708505076747

Epoch: 5| Step: 9
Training loss: 1.7433449029922485
Validation loss: 2.1094800810660086

Epoch: 5| Step: 10
Training loss: 2.360002279281616
Validation loss: 2.082062130333275

Epoch: 245| Step: 0
Training loss: 2.2163920402526855
Validation loss: 2.1156100842260543

Epoch: 5| Step: 1
Training loss: 1.6913936138153076
Validation loss: 2.1073475768489223

Epoch: 5| Step: 2
Training loss: 1.8735030889511108
Validation loss: 2.1078138184803787

Epoch: 5| Step: 3
Training loss: 1.7169796228408813
Validation loss: 2.0771335183933215

Epoch: 5| Step: 4
Training loss: 2.056626796722412
Validation loss: 2.0700777807543354

Epoch: 5| Step: 5
Training loss: 2.083120346069336
Validation loss: 2.0633447413803427

Epoch: 5| Step: 6
Training loss: 2.3738420009613037
Validation loss: 2.0737752247882146

Epoch: 5| Step: 7
Training loss: 2.4164223670959473
Validation loss: 2.0944605104384886

Epoch: 5| Step: 8
Training loss: 2.411137104034424
Validation loss: 2.0889012531567643

Epoch: 5| Step: 9
Training loss: 2.0368599891662598
Validation loss: 2.0983357506413616

Epoch: 5| Step: 10
Training loss: 2.327316999435425
Validation loss: 2.131685713286041

Epoch: 246| Step: 0
Training loss: 1.8996613025665283
Validation loss: 2.153101417326158

Epoch: 5| Step: 1
Training loss: 1.7995023727416992
Validation loss: 2.1643668425980436

Epoch: 5| Step: 2
Training loss: 1.8567755222320557
Validation loss: 2.141708738060408

Epoch: 5| Step: 3
Training loss: 2.8118515014648438
Validation loss: 2.147854671683363

Epoch: 5| Step: 4
Training loss: 1.566921353340149
Validation loss: 2.148865733095395

Epoch: 5| Step: 5
Training loss: 1.639137625694275
Validation loss: 2.1555694815933064

Epoch: 5| Step: 6
Training loss: 2.1661019325256348
Validation loss: 2.151274868237075

Epoch: 5| Step: 7
Training loss: 2.1266226768493652
Validation loss: 2.1461501941886

Epoch: 5| Step: 8
Training loss: 2.7933030128479004
Validation loss: 2.144859993329612

Epoch: 5| Step: 9
Training loss: 1.9590651988983154
Validation loss: 2.1207640735051965

Epoch: 5| Step: 10
Training loss: 2.3915157318115234
Validation loss: 2.1153756828718286

Epoch: 247| Step: 0
Training loss: 2.1557846069335938
Validation loss: 2.1142030608269478

Epoch: 5| Step: 1
Training loss: 1.430942177772522
Validation loss: 2.1001410048495055

Epoch: 5| Step: 2
Training loss: 2.258500576019287
Validation loss: 2.097058529494911

Epoch: 5| Step: 3
Training loss: 2.069002866744995
Validation loss: 2.092857619767548

Epoch: 5| Step: 4
Training loss: 2.4181227684020996
Validation loss: 2.0886442968922276

Epoch: 5| Step: 5
Training loss: 2.135453701019287
Validation loss: 2.1133154489660777

Epoch: 5| Step: 6
Training loss: 2.1781439781188965
Validation loss: 2.098919892823824

Epoch: 5| Step: 7
Training loss: 1.9022319316864014
Validation loss: 2.1049415911397626

Epoch: 5| Step: 8
Training loss: 2.0213780403137207
Validation loss: 2.105542149595035

Epoch: 5| Step: 9
Training loss: 1.7769489288330078
Validation loss: 2.0895624006948164

Epoch: 5| Step: 10
Training loss: 2.6547293663024902
Validation loss: 2.070352710703368

Epoch: 248| Step: 0
Training loss: 2.2724831104278564
Validation loss: 2.0853568943597938

Epoch: 5| Step: 1
Training loss: 1.9433997869491577
Validation loss: 2.08010349991501

Epoch: 5| Step: 2
Training loss: 2.128225326538086
Validation loss: 2.0839257637659707

Epoch: 5| Step: 3
Training loss: 2.0173845291137695
Validation loss: 2.093141560913414

Epoch: 5| Step: 4
Training loss: 1.7546449899673462
Validation loss: 2.07396633907031

Epoch: 5| Step: 5
Training loss: 2.2562713623046875
Validation loss: 2.082195178154976

Epoch: 5| Step: 6
Training loss: 1.808411955833435
Validation loss: 2.1083244995404313

Epoch: 5| Step: 7
Training loss: 2.256098747253418
Validation loss: 2.1290136062970726

Epoch: 5| Step: 8
Training loss: 2.0586624145507812
Validation loss: 2.1650052916619087

Epoch: 5| Step: 9
Training loss: 2.4619319438934326
Validation loss: 2.1752189461902907

Epoch: 5| Step: 10
Training loss: 2.2688236236572266
Validation loss: 2.1966049260990594

Epoch: 249| Step: 0
Training loss: 1.9223699569702148
Validation loss: 2.163867550511514

Epoch: 5| Step: 1
Training loss: 2.278730869293213
Validation loss: 2.1595830302084646

Epoch: 5| Step: 2
Training loss: 2.5054049491882324
Validation loss: 2.148580233256022

Epoch: 5| Step: 3
Training loss: 1.507145643234253
Validation loss: 2.1146629138659407

Epoch: 5| Step: 4
Training loss: 2.325265407562256
Validation loss: 2.0920143370987265

Epoch: 5| Step: 5
Training loss: 1.8338747024536133
Validation loss: 2.0929206212361655

Epoch: 5| Step: 6
Training loss: 2.166749954223633
Validation loss: 2.0976657111157655

Epoch: 5| Step: 7
Training loss: 2.4847493171691895
Validation loss: 2.0921568691089587

Epoch: 5| Step: 8
Training loss: 2.1280438899993896
Validation loss: 2.092398493520675

Epoch: 5| Step: 9
Training loss: 2.4872193336486816
Validation loss: 2.0870643264503888

Epoch: 5| Step: 10
Training loss: 1.4645509719848633
Validation loss: 2.0859670715947307

Epoch: 250| Step: 0
Training loss: 2.2192912101745605
Validation loss: 2.094407002131144

Epoch: 5| Step: 1
Training loss: 1.9151442050933838
Validation loss: 2.102588717655469

Epoch: 5| Step: 2
Training loss: 2.461554527282715
Validation loss: 2.1086340162061874

Epoch: 5| Step: 3
Training loss: 2.2063686847686768
Validation loss: 2.0981972781560754

Epoch: 5| Step: 4
Training loss: 1.9889824390411377
Validation loss: 2.0678063772057973

Epoch: 5| Step: 5
Training loss: 2.3416268825531006
Validation loss: 2.0850652084555676

Epoch: 5| Step: 6
Training loss: 1.792281150817871
Validation loss: 2.0728567390031714

Epoch: 5| Step: 7
Training loss: 2.037703037261963
Validation loss: 2.068127688541207

Epoch: 5| Step: 8
Training loss: 1.6714805364608765
Validation loss: 2.072404658922585

Epoch: 5| Step: 9
Training loss: 2.122765064239502
Validation loss: 2.081859488641062

Epoch: 5| Step: 10
Training loss: 2.2172961235046387
Validation loss: 2.078328783794116

Epoch: 251| Step: 0
Training loss: 2.2287745475769043
Validation loss: 2.0857694713018273

Epoch: 5| Step: 1
Training loss: 2.1898088455200195
Validation loss: 2.086983229524346

Epoch: 5| Step: 2
Training loss: 1.8719680309295654
Validation loss: 2.086598123273542

Epoch: 5| Step: 3
Training loss: 1.881717324256897
Validation loss: 2.0838643248363207

Epoch: 5| Step: 4
Training loss: 2.0206780433654785
Validation loss: 2.089632216320243

Epoch: 5| Step: 5
Training loss: 2.0248208045959473
Validation loss: 2.091710498256068

Epoch: 5| Step: 6
Training loss: 2.2479405403137207
Validation loss: 2.1108166812568583

Epoch: 5| Step: 7
Training loss: 2.58345365524292
Validation loss: 2.0971199120244672

Epoch: 5| Step: 8
Training loss: 1.3376482725143433
Validation loss: 2.106978021642213

Epoch: 5| Step: 9
Training loss: 2.0461087226867676
Validation loss: 2.0814329860030965

Epoch: 5| Step: 10
Training loss: 2.446723699569702
Validation loss: 2.0775861176111365

Epoch: 252| Step: 0
Training loss: 2.061898708343506
Validation loss: 2.096806767166302

Epoch: 5| Step: 1
Training loss: 2.2964954376220703
Validation loss: 2.108413137415404

Epoch: 5| Step: 2
Training loss: 1.7444347143173218
Validation loss: 2.100690269982943

Epoch: 5| Step: 3
Training loss: 1.9177430868148804
Validation loss: 2.1025879101086686

Epoch: 5| Step: 4
Training loss: 1.8032268285751343
Validation loss: 2.096536474843179

Epoch: 5| Step: 5
Training loss: 1.950761079788208
Validation loss: 2.101397111851682

Epoch: 5| Step: 6
Training loss: 1.9751482009887695
Validation loss: 2.1182520363920476

Epoch: 5| Step: 7
Training loss: 2.22710919380188
Validation loss: 2.1081357194531347

Epoch: 5| Step: 8
Training loss: 2.2198309898376465
Validation loss: 2.127690512646911

Epoch: 5| Step: 9
Training loss: 2.449798107147217
Validation loss: 2.116391872846952

Epoch: 5| Step: 10
Training loss: 2.1925652027130127
Validation loss: 2.1066183133791854

Epoch: 253| Step: 0
Training loss: 1.9465135335922241
Validation loss: 2.090799895665979

Epoch: 5| Step: 1
Training loss: 2.8106350898742676
Validation loss: 2.0929306476346907

Epoch: 5| Step: 2
Training loss: 1.2321745157241821
Validation loss: 2.0882609275079544

Epoch: 5| Step: 3
Training loss: 2.2349741458892822
Validation loss: 2.0845777526978524

Epoch: 5| Step: 4
Training loss: 2.060572385787964
Validation loss: 2.091228918362689

Epoch: 5| Step: 5
Training loss: 1.365906000137329
Validation loss: 2.107736551633445

Epoch: 5| Step: 6
Training loss: 1.8359979391098022
Validation loss: 2.12608459431638

Epoch: 5| Step: 7
Training loss: 2.5009689331054688
Validation loss: 2.141582396722609

Epoch: 5| Step: 8
Training loss: 2.591387987136841
Validation loss: 2.1361411412556968

Epoch: 5| Step: 9
Training loss: 1.7993297576904297
Validation loss: 2.146916671465802

Epoch: 5| Step: 10
Training loss: 2.4218809604644775
Validation loss: 2.150962286098029

Epoch: 254| Step: 0
Training loss: 2.622032403945923
Validation loss: 2.2035630672208724

Epoch: 5| Step: 1
Training loss: 1.7768405675888062
Validation loss: 2.207253143351565

Epoch: 5| Step: 2
Training loss: 2.4629640579223633
Validation loss: 2.218321336212979

Epoch: 5| Step: 3
Training loss: 1.651892900466919
Validation loss: 2.2049000199123094

Epoch: 5| Step: 4
Training loss: 2.097668170928955
Validation loss: 2.1804831771440405

Epoch: 5| Step: 5
Training loss: 2.364147663116455
Validation loss: 2.128721970383839

Epoch: 5| Step: 6
Training loss: 2.3672306537628174
Validation loss: 2.096444845199585

Epoch: 5| Step: 7
Training loss: 2.490661382675171
Validation loss: 2.116351872362116

Epoch: 5| Step: 8
Training loss: 2.2173194885253906
Validation loss: 2.130946784891108

Epoch: 5| Step: 9
Training loss: 1.5896272659301758
Validation loss: 2.1334791004016833

Epoch: 5| Step: 10
Training loss: 1.8881218433380127
Validation loss: 2.1017277010025515

Epoch: 255| Step: 0
Training loss: 2.5628790855407715
Validation loss: 2.065487475805385

Epoch: 5| Step: 1
Training loss: 2.1576826572418213
Validation loss: 2.049451187092771

Epoch: 5| Step: 2
Training loss: 2.0860848426818848
Validation loss: 2.0311047082306235

Epoch: 5| Step: 3
Training loss: 2.469371795654297
Validation loss: 2.044691918998636

Epoch: 5| Step: 4
Training loss: 1.8505971431732178
Validation loss: 2.0583884434033464

Epoch: 5| Step: 5
Training loss: 1.794115424156189
Validation loss: 2.0689063892569592

Epoch: 5| Step: 6
Training loss: 2.385303258895874
Validation loss: 2.0799241911980415

Epoch: 5| Step: 7
Training loss: 2.0573647022247314
Validation loss: 2.087308934939805

Epoch: 5| Step: 8
Training loss: 1.657299280166626
Validation loss: 2.0931787849754415

Epoch: 5| Step: 9
Training loss: 2.0147624015808105
Validation loss: 2.0883882109836867

Epoch: 5| Step: 10
Training loss: 1.9089452028274536
Validation loss: 2.0950108407646097

Epoch: 256| Step: 0
Training loss: 1.8748528957366943
Validation loss: 2.114242539610914

Epoch: 5| Step: 1
Training loss: 1.9366401433944702
Validation loss: 2.1224877859956477

Epoch: 5| Step: 2
Training loss: 2.6596436500549316
Validation loss: 2.1209149514475176

Epoch: 5| Step: 3
Training loss: 2.6731667518615723
Validation loss: 2.116383925560982

Epoch: 5| Step: 4
Training loss: 2.809657096862793
Validation loss: 2.1285998180348384

Epoch: 5| Step: 5
Training loss: 1.6017265319824219
Validation loss: 2.1207714285901798

Epoch: 5| Step: 6
Training loss: 2.424307107925415
Validation loss: 2.1136020178435952

Epoch: 5| Step: 7
Training loss: 1.8983659744262695
Validation loss: 2.1130439184045278

Epoch: 5| Step: 8
Training loss: 1.9785006046295166
Validation loss: 2.119923145540299

Epoch: 5| Step: 9
Training loss: 1.2789510488510132
Validation loss: 2.10949856235135

Epoch: 5| Step: 10
Training loss: 1.6038767099380493
Validation loss: 2.102710762331563

Epoch: 257| Step: 0
Training loss: 2.409356117248535
Validation loss: 2.0813902167863745

Epoch: 5| Step: 1
Training loss: 2.366529941558838
Validation loss: 2.092442630439676

Epoch: 5| Step: 2
Training loss: 2.1465189456939697
Validation loss: 2.0920085548072733

Epoch: 5| Step: 3
Training loss: 1.76458740234375
Validation loss: 2.0738959389348186

Epoch: 5| Step: 4
Training loss: 2.3929295539855957
Validation loss: 2.073638246905419

Epoch: 5| Step: 5
Training loss: 1.6871877908706665
Validation loss: 2.068008033178186

Epoch: 5| Step: 6
Training loss: 1.720902442932129
Validation loss: 2.0851391464151363

Epoch: 5| Step: 7
Training loss: 1.8047021627426147
Validation loss: 2.101661464219452

Epoch: 5| Step: 8
Training loss: 2.35398268699646
Validation loss: 2.1175093791818105

Epoch: 5| Step: 9
Training loss: 1.8521881103515625
Validation loss: 2.1348598823752454

Epoch: 5| Step: 10
Training loss: 1.9896624088287354
Validation loss: 2.1297828676880046

Epoch: 258| Step: 0
Training loss: 1.526067852973938
Validation loss: 2.1348684372440463

Epoch: 5| Step: 1
Training loss: 1.5019818544387817
Validation loss: 2.1254888221781743

Epoch: 5| Step: 2
Training loss: 2.0816869735717773
Validation loss: 2.115987072708786

Epoch: 5| Step: 3
Training loss: 2.217839002609253
Validation loss: 2.1165371043707735

Epoch: 5| Step: 4
Training loss: 1.7496929168701172
Validation loss: 2.0886685015052877

Epoch: 5| Step: 5
Training loss: 1.6358392238616943
Validation loss: 2.083726306115427

Epoch: 5| Step: 6
Training loss: 2.8735241889953613
Validation loss: 2.082141894166188

Epoch: 5| Step: 7
Training loss: 2.0964035987854004
Validation loss: 2.0733047967316

Epoch: 5| Step: 8
Training loss: 2.305234432220459
Validation loss: 2.058479165518156

Epoch: 5| Step: 9
Training loss: 2.3687424659729004
Validation loss: 2.062930537808326

Epoch: 5| Step: 10
Training loss: 2.243196487426758
Validation loss: 2.077188843040056

Epoch: 259| Step: 0
Training loss: 2.308694839477539
Validation loss: 2.0758816362709127

Epoch: 5| Step: 1
Training loss: 1.9873828887939453
Validation loss: 2.0542231067534416

Epoch: 5| Step: 2
Training loss: 1.283765196800232
Validation loss: 2.0641189980250534

Epoch: 5| Step: 3
Training loss: 1.4514707326889038
Validation loss: 2.0654430261222263

Epoch: 5| Step: 4
Training loss: 2.447648525238037
Validation loss: 2.0675017064617527

Epoch: 5| Step: 5
Training loss: 2.69320011138916
Validation loss: 2.0629083571895475

Epoch: 5| Step: 6
Training loss: 2.142197370529175
Validation loss: 2.098145070896354

Epoch: 5| Step: 7
Training loss: 1.8944066762924194
Validation loss: 2.1046008627901793

Epoch: 5| Step: 8
Training loss: 2.2458667755126953
Validation loss: 2.12143732911797

Epoch: 5| Step: 9
Training loss: 1.854435920715332
Validation loss: 2.143784402519144

Epoch: 5| Step: 10
Training loss: 2.0701160430908203
Validation loss: 2.145224037990775

Epoch: 260| Step: 0
Training loss: 2.5698602199554443
Validation loss: 2.16736711225202

Epoch: 5| Step: 1
Training loss: 2.3834421634674072
Validation loss: 2.167572077884469

Epoch: 5| Step: 2
Training loss: 1.9363361597061157
Validation loss: 2.157090994619554

Epoch: 5| Step: 3
Training loss: 1.5957796573638916
Validation loss: 2.1295901754850983

Epoch: 5| Step: 4
Training loss: 1.6283735036849976
Validation loss: 2.1050213972727456

Epoch: 5| Step: 5
Training loss: 2.36423921585083
Validation loss: 2.077947199985545

Epoch: 5| Step: 6
Training loss: 2.1883339881896973
Validation loss: 2.0513478145804456

Epoch: 5| Step: 7
Training loss: 1.797450065612793
Validation loss: 2.0386630591525825

Epoch: 5| Step: 8
Training loss: 2.3476250171661377
Validation loss: 2.024933886784379

Epoch: 5| Step: 9
Training loss: 1.7084214687347412
Validation loss: 2.0397903329582623

Epoch: 5| Step: 10
Training loss: 2.0783066749572754
Validation loss: 2.040599548688499

Epoch: 261| Step: 0
Training loss: 1.7745459079742432
Validation loss: 2.025206986293998

Epoch: 5| Step: 1
Training loss: 2.0619637966156006
Validation loss: 2.031481845404512

Epoch: 5| Step: 2
Training loss: 2.1295166015625
Validation loss: 2.0441370446194886

Epoch: 5| Step: 3
Training loss: 2.407921552658081
Validation loss: 2.05789941100664

Epoch: 5| Step: 4
Training loss: 1.9399693012237549
Validation loss: 2.0622669394298265

Epoch: 5| Step: 5
Training loss: 2.433037281036377
Validation loss: 2.06593055622552

Epoch: 5| Step: 6
Training loss: 2.3372063636779785
Validation loss: 2.095392919355823

Epoch: 5| Step: 7
Training loss: 1.9237492084503174
Validation loss: 2.110881931038313

Epoch: 5| Step: 8
Training loss: 1.8019567728042603
Validation loss: 2.1404931173529675

Epoch: 5| Step: 9
Training loss: 2.145890712738037
Validation loss: 2.1209501194697555

Epoch: 5| Step: 10
Training loss: 1.4581090211868286
Validation loss: 2.1055452003273913

Epoch: 262| Step: 0
Training loss: 1.8847367763519287
Validation loss: 2.094825533128554

Epoch: 5| Step: 1
Training loss: 2.225045919418335
Validation loss: 2.0938553938301663

Epoch: 5| Step: 2
Training loss: 2.198664426803589
Validation loss: 2.0911448463316886

Epoch: 5| Step: 3
Training loss: 1.815606713294983
Validation loss: 2.1024738947550454

Epoch: 5| Step: 4
Training loss: 2.335014820098877
Validation loss: 2.104706382238737

Epoch: 5| Step: 5
Training loss: 2.176818370819092
Validation loss: 2.1061837109186317

Epoch: 5| Step: 6
Training loss: 1.7639003992080688
Validation loss: 2.1044958047969367

Epoch: 5| Step: 7
Training loss: 2.42940616607666
Validation loss: 2.1149917007774435

Epoch: 5| Step: 8
Training loss: 2.357123613357544
Validation loss: 2.1076495109065885

Epoch: 5| Step: 9
Training loss: 1.8373781442642212
Validation loss: 2.1003089002383653

Epoch: 5| Step: 10
Training loss: 1.1680065393447876
Validation loss: 2.09755959305712

Epoch: 263| Step: 0
Training loss: 2.494459867477417
Validation loss: 2.107402742549937

Epoch: 5| Step: 1
Training loss: 2.0310542583465576
Validation loss: 2.116526876726458

Epoch: 5| Step: 2
Training loss: 1.7207040786743164
Validation loss: 2.1167161131417878

Epoch: 5| Step: 3
Training loss: 2.214254856109619
Validation loss: 2.11737201803474

Epoch: 5| Step: 4
Training loss: 2.3395731449127197
Validation loss: 2.1129929506650535

Epoch: 5| Step: 5
Training loss: 1.5832902193069458
Validation loss: 2.092903862717331

Epoch: 5| Step: 6
Training loss: 1.6888736486434937
Validation loss: 2.0736273206690305

Epoch: 5| Step: 7
Training loss: 2.2959399223327637
Validation loss: 2.0568013357859787

Epoch: 5| Step: 8
Training loss: 2.3063087463378906
Validation loss: 2.059450331554618

Epoch: 5| Step: 9
Training loss: 1.4397192001342773
Validation loss: 2.033958870877502

Epoch: 5| Step: 10
Training loss: 2.2060534954071045
Validation loss: 2.0078719303172123

Epoch: 264| Step: 0
Training loss: 2.2640011310577393
Validation loss: 2.0150551731868456

Epoch: 5| Step: 1
Training loss: 1.468990445137024
Validation loss: 2.010190067752715

Epoch: 5| Step: 2
Training loss: 2.387460708618164
Validation loss: 2.032695988173126

Epoch: 5| Step: 3
Training loss: 2.162317991256714
Validation loss: 2.0394486329888784

Epoch: 5| Step: 4
Training loss: 2.2186942100524902
Validation loss: 2.036128733747749

Epoch: 5| Step: 5
Training loss: 1.5400843620300293
Validation loss: 2.0611671657972437

Epoch: 5| Step: 6
Training loss: 1.8372596502304077
Validation loss: 2.047652840614319

Epoch: 5| Step: 7
Training loss: 2.437908172607422
Validation loss: 2.054097052543394

Epoch: 5| Step: 8
Training loss: 1.5740635395050049
Validation loss: 2.0482798263590825

Epoch: 5| Step: 9
Training loss: 2.3868393898010254
Validation loss: 2.0447187577524493

Epoch: 5| Step: 10
Training loss: 1.933453917503357
Validation loss: 2.0658049301434587

Epoch: 265| Step: 0
Training loss: 2.263913154602051
Validation loss: 2.056723681829309

Epoch: 5| Step: 1
Training loss: 2.114525079727173
Validation loss: 2.059964813211913

Epoch: 5| Step: 2
Training loss: 1.4125044345855713
Validation loss: 2.0720850113899476

Epoch: 5| Step: 3
Training loss: 2.175175428390503
Validation loss: 2.071362308276597

Epoch: 5| Step: 4
Training loss: 1.4510501623153687
Validation loss: 2.0529146232912616

Epoch: 5| Step: 5
Training loss: 2.5290565490722656
Validation loss: 2.055910679601854

Epoch: 5| Step: 6
Training loss: 2.250314712524414
Validation loss: 2.037110205619566

Epoch: 5| Step: 7
Training loss: 2.2222397327423096
Validation loss: 2.055640967943335

Epoch: 5| Step: 8
Training loss: 1.9209877252578735
Validation loss: 2.040870302466936

Epoch: 5| Step: 9
Training loss: 2.016803503036499
Validation loss: 2.0491475110412924

Epoch: 5| Step: 10
Training loss: 1.541946291923523
Validation loss: 2.0573280254999795

Epoch: 266| Step: 0
Training loss: 2.13667631149292
Validation loss: 2.0459519304255003

Epoch: 5| Step: 1
Training loss: 2.3687920570373535
Validation loss: 2.0614687422270417

Epoch: 5| Step: 2
Training loss: 2.009232997894287
Validation loss: 2.0608929421312068

Epoch: 5| Step: 3
Training loss: 2.0463242530822754
Validation loss: 2.069582554601854

Epoch: 5| Step: 4
Training loss: 2.225799798965454
Validation loss: 2.07406723114752

Epoch: 5| Step: 5
Training loss: 2.100698947906494
Validation loss: 2.0643363370690295

Epoch: 5| Step: 6
Training loss: 1.3616588115692139
Validation loss: 2.0527483481232838

Epoch: 5| Step: 7
Training loss: 1.7583959102630615
Validation loss: 2.0474863693278325

Epoch: 5| Step: 8
Training loss: 1.2421382665634155
Validation loss: 2.0522508569943008

Epoch: 5| Step: 9
Training loss: 2.3542399406433105
Validation loss: 2.0571368150813605

Epoch: 5| Step: 10
Training loss: 2.461585760116577
Validation loss: 2.07533142130862

Epoch: 267| Step: 0
Training loss: 1.4900327920913696
Validation loss: 2.075112981180991

Epoch: 5| Step: 1
Training loss: 1.8114677667617798
Validation loss: 2.053379456202189

Epoch: 5| Step: 2
Training loss: 2.151154041290283
Validation loss: 2.042044496023527

Epoch: 5| Step: 3
Training loss: 2.0789308547973633
Validation loss: 2.047295085845455

Epoch: 5| Step: 4
Training loss: 2.521080732345581
Validation loss: 2.041865974344233

Epoch: 5| Step: 5
Training loss: 2.45832896232605
Validation loss: 2.0554641933851343

Epoch: 5| Step: 6
Training loss: 1.7340061664581299
Validation loss: 2.055868823041198

Epoch: 5| Step: 7
Training loss: 2.365084171295166
Validation loss: 2.0441151101102113

Epoch: 5| Step: 8
Training loss: 1.7380657196044922
Validation loss: 2.058814392294935

Epoch: 5| Step: 9
Training loss: 1.4481117725372314
Validation loss: 2.0632758781474125

Epoch: 5| Step: 10
Training loss: 1.9988266229629517
Validation loss: 2.067487955093384

Epoch: 268| Step: 0
Training loss: 2.2169806957244873
Validation loss: 2.09114339787473

Epoch: 5| Step: 1
Training loss: 1.7184702157974243
Validation loss: 2.088310477554157

Epoch: 5| Step: 2
Training loss: 1.6807520389556885
Validation loss: 2.0862887059488604

Epoch: 5| Step: 3
Training loss: 2.3106284141540527
Validation loss: 2.095302217750139

Epoch: 5| Step: 4
Training loss: 1.6979491710662842
Validation loss: 2.0959976975635817

Epoch: 5| Step: 5
Training loss: 2.3024611473083496
Validation loss: 2.09118833849507

Epoch: 5| Step: 6
Training loss: 1.5683492422103882
Validation loss: 2.0635481111464964

Epoch: 5| Step: 7
Training loss: 1.6332778930664062
Validation loss: 2.081877339270807

Epoch: 5| Step: 8
Training loss: 2.572622299194336
Validation loss: 2.078977500238726

Epoch: 5| Step: 9
Training loss: 2.0405211448669434
Validation loss: 2.0788934346168273

Epoch: 5| Step: 10
Training loss: 1.9639859199523926
Validation loss: 2.0712126506272184

Epoch: 269| Step: 0
Training loss: 2.224536418914795
Validation loss: 2.034557580947876

Epoch: 5| Step: 1
Training loss: 1.8761413097381592
Validation loss: 2.049458662668864

Epoch: 5| Step: 2
Training loss: 2.853548526763916
Validation loss: 2.0247934467049054

Epoch: 5| Step: 3
Training loss: 2.1472506523132324
Validation loss: 2.026077496108188

Epoch: 5| Step: 4
Training loss: 1.872139573097229
Validation loss: 2.0073103238177556

Epoch: 5| Step: 5
Training loss: 1.8331642150878906
Validation loss: 2.031003427761857

Epoch: 5| Step: 6
Training loss: 1.775043249130249
Validation loss: 2.0318830987458587

Epoch: 5| Step: 7
Training loss: 2.0724074840545654
Validation loss: 2.049867426195452

Epoch: 5| Step: 8
Training loss: 2.0289466381073
Validation loss: 2.0404491296378513

Epoch: 5| Step: 9
Training loss: 1.8189303874969482
Validation loss: 2.0564603779905584

Epoch: 5| Step: 10
Training loss: 1.3775228261947632
Validation loss: 2.049666702106435

Epoch: 270| Step: 0
Training loss: 2.5376780033111572
Validation loss: 2.0615024053922264

Epoch: 5| Step: 1
Training loss: 1.8337453603744507
Validation loss: 2.075565481698641

Epoch: 5| Step: 2
Training loss: 1.6133625507354736
Validation loss: 2.092188496743479

Epoch: 5| Step: 3
Training loss: 1.999148964881897
Validation loss: 2.1076116895162933

Epoch: 5| Step: 4
Training loss: 2.3877947330474854
Validation loss: 2.1180592967617895

Epoch: 5| Step: 5
Training loss: 1.9424808025360107
Validation loss: 2.108793827795213

Epoch: 5| Step: 6
Training loss: 1.4457995891571045
Validation loss: 2.09900527615701

Epoch: 5| Step: 7
Training loss: 2.2016735076904297
Validation loss: 2.093109469259939

Epoch: 5| Step: 8
Training loss: 1.6506996154785156
Validation loss: 2.096086138038225

Epoch: 5| Step: 9
Training loss: 2.05198073387146
Validation loss: 2.095957904733637

Epoch: 5| Step: 10
Training loss: 2.0760951042175293
Validation loss: 2.0831188514668453

Epoch: 271| Step: 0
Training loss: 1.8095070123672485
Validation loss: 2.084470179773146

Epoch: 5| Step: 1
Training loss: 1.5712430477142334
Validation loss: 2.0865418064978813

Epoch: 5| Step: 2
Training loss: 2.2259087562561035
Validation loss: 2.056916748323748

Epoch: 5| Step: 3
Training loss: 1.332032322883606
Validation loss: 2.0579730131292857

Epoch: 5| Step: 4
Training loss: 2.4303481578826904
Validation loss: 2.0399761020496325

Epoch: 5| Step: 5
Training loss: 1.9831470251083374
Validation loss: 2.0415415815127793

Epoch: 5| Step: 6
Training loss: 1.9590238332748413
Validation loss: 2.0408409321179954

Epoch: 5| Step: 7
Training loss: 1.8224321603775024
Validation loss: 2.0462399451963362

Epoch: 5| Step: 8
Training loss: 2.4909043312072754
Validation loss: 2.0407168788294636

Epoch: 5| Step: 9
Training loss: 2.070122480392456
Validation loss: 2.0378475983937583

Epoch: 5| Step: 10
Training loss: 1.9385095834732056
Validation loss: 2.0736889954536193

Epoch: 272| Step: 0
Training loss: 1.3162225484848022
Validation loss: 2.076711073998482

Epoch: 5| Step: 1
Training loss: 2.422985553741455
Validation loss: 2.1078253792178248

Epoch: 5| Step: 2
Training loss: 1.8971551656723022
Validation loss: 2.0916392187918387

Epoch: 5| Step: 3
Training loss: 2.107299566268921
Validation loss: 2.1075299388618878

Epoch: 5| Step: 4
Training loss: 1.9486916065216064
Validation loss: 2.101724277260483

Epoch: 5| Step: 5
Training loss: 2.011482000350952
Validation loss: 2.102568039330103

Epoch: 5| Step: 6
Training loss: 1.8044519424438477
Validation loss: 2.080034561054681

Epoch: 5| Step: 7
Training loss: 1.9896271228790283
Validation loss: 2.0666921805309992

Epoch: 5| Step: 8
Training loss: 1.814164400100708
Validation loss: 2.0820120739680466

Epoch: 5| Step: 9
Training loss: 2.0122151374816895
Validation loss: 2.1009366755844443

Epoch: 5| Step: 10
Training loss: 2.501418113708496
Validation loss: 2.0877118495202835

Epoch: 273| Step: 0
Training loss: 1.3967174291610718
Validation loss: 2.1042185803895355

Epoch: 5| Step: 1
Training loss: 2.3801491260528564
Validation loss: 2.1042544559765886

Epoch: 5| Step: 2
Training loss: 2.6683290004730225
Validation loss: 2.0948745178919967

Epoch: 5| Step: 3
Training loss: 0.9736417531967163
Validation loss: 2.09303085009257

Epoch: 5| Step: 4
Training loss: 2.3188064098358154
Validation loss: 2.0835325794835247

Epoch: 5| Step: 5
Training loss: 1.9737240076065063
Validation loss: 2.063588921741773

Epoch: 5| Step: 6
Training loss: 2.1763923168182373
Validation loss: 2.040840777017737

Epoch: 5| Step: 7
Training loss: 1.4713513851165771
Validation loss: 2.0444035606999553

Epoch: 5| Step: 8
Training loss: 2.116382360458374
Validation loss: 2.039176833245062

Epoch: 5| Step: 9
Training loss: 2.2283802032470703
Validation loss: 2.0371353292977936

Epoch: 5| Step: 10
Training loss: 2.0030477046966553
Validation loss: 2.0449463603317097

Epoch: 274| Step: 0
Training loss: 1.985144853591919
Validation loss: 2.0392674271778395

Epoch: 5| Step: 1
Training loss: 1.175831913948059
Validation loss: 2.052570360963063

Epoch: 5| Step: 2
Training loss: 1.8064218759536743
Validation loss: 2.058234671110748

Epoch: 5| Step: 3
Training loss: 2.172637462615967
Validation loss: 2.082399219594976

Epoch: 5| Step: 4
Training loss: 2.145840883255005
Validation loss: 2.0940432574159358

Epoch: 5| Step: 5
Training loss: 2.37980318069458
Validation loss: 2.1001313911971224

Epoch: 5| Step: 6
Training loss: 1.908687949180603
Validation loss: 2.122545616601103

Epoch: 5| Step: 7
Training loss: 2.2807021141052246
Validation loss: 2.1004705813623246

Epoch: 5| Step: 8
Training loss: 1.6102561950683594
Validation loss: 2.123088272668982

Epoch: 5| Step: 9
Training loss: 2.1852364540100098
Validation loss: 2.1002966652634325

Epoch: 5| Step: 10
Training loss: 2.131848096847534
Validation loss: 2.109048422946725

Epoch: 275| Step: 0
Training loss: 2.1195755004882812
Validation loss: 2.1167138802107943

Epoch: 5| Step: 1
Training loss: 1.9578380584716797
Validation loss: 2.0944763370739516

Epoch: 5| Step: 2
Training loss: 1.765432357788086
Validation loss: 2.0908495405668854

Epoch: 5| Step: 3
Training loss: 1.789788007736206
Validation loss: 2.087427450764564

Epoch: 5| Step: 4
Training loss: 2.2559940814971924
Validation loss: 2.097988377335251

Epoch: 5| Step: 5
Training loss: 2.086820602416992
Validation loss: 2.0980221122823735

Epoch: 5| Step: 6
Training loss: 1.7891724109649658
Validation loss: 2.0790283039051998

Epoch: 5| Step: 7
Training loss: 1.8918354511260986
Validation loss: 2.0693740524271482

Epoch: 5| Step: 8
Training loss: 2.512993335723877
Validation loss: 2.062801963539534

Epoch: 5| Step: 9
Training loss: 1.5751464366912842
Validation loss: 2.0392608437486874

Epoch: 5| Step: 10
Training loss: 2.1499111652374268
Validation loss: 2.0294676955028246

Epoch: 276| Step: 0
Training loss: 1.4879003763198853
Validation loss: 2.0395656695929905

Epoch: 5| Step: 1
Training loss: 1.8461039066314697
Validation loss: 2.040688910791951

Epoch: 5| Step: 2
Training loss: 1.9732173681259155
Validation loss: 2.0561651888714043

Epoch: 5| Step: 3
Training loss: 1.9500831365585327
Validation loss: 2.0643488155898226

Epoch: 5| Step: 4
Training loss: 2.2139031887054443
Validation loss: 2.0622393572202293

Epoch: 5| Step: 5
Training loss: 1.9895427227020264
Validation loss: 2.0861905749126146

Epoch: 5| Step: 6
Training loss: 2.778083562850952
Validation loss: 2.0796395783783286

Epoch: 5| Step: 7
Training loss: 2.309871196746826
Validation loss: 2.088145379097231

Epoch: 5| Step: 8
Training loss: 2.0646469593048096
Validation loss: 2.078227940426078

Epoch: 5| Step: 9
Training loss: 1.299093246459961
Validation loss: 2.1045435987493044

Epoch: 5| Step: 10
Training loss: 1.9237345457077026
Validation loss: 2.0736507215807514

Epoch: 277| Step: 0
Training loss: 1.5399223566055298
Validation loss: 2.081510348986554

Epoch: 5| Step: 1
Training loss: 1.6231968402862549
Validation loss: 2.060102326895601

Epoch: 5| Step: 2
Training loss: 1.6249516010284424
Validation loss: 2.040822732833124

Epoch: 5| Step: 3
Training loss: 1.9622881412506104
Validation loss: 2.022915429966424

Epoch: 5| Step: 4
Training loss: 2.176021099090576
Validation loss: 2.0483077097964544

Epoch: 5| Step: 5
Training loss: 2.5357844829559326
Validation loss: 2.0467515222487913

Epoch: 5| Step: 6
Training loss: 2.9833407402038574
Validation loss: 2.065216309280806

Epoch: 5| Step: 7
Training loss: 1.6807191371917725
Validation loss: 2.0565639593267955

Epoch: 5| Step: 8
Training loss: 2.052372455596924
Validation loss: 2.079708412129392

Epoch: 5| Step: 9
Training loss: 1.6551624536514282
Validation loss: 2.0569636911474247

Epoch: 5| Step: 10
Training loss: 1.623949646949768
Validation loss: 2.0481067677979827

Epoch: 278| Step: 0
Training loss: 1.6895816326141357
Validation loss: 2.044307111411966

Epoch: 5| Step: 1
Training loss: 2.3898537158966064
Validation loss: 2.056305170059204

Epoch: 5| Step: 2
Training loss: 2.043297052383423
Validation loss: 2.072866291128179

Epoch: 5| Step: 3
Training loss: 1.8261390924453735
Validation loss: 2.0910872951630624

Epoch: 5| Step: 4
Training loss: 1.9798424243927002
Validation loss: 2.0723805248096423

Epoch: 5| Step: 5
Training loss: 1.3307939767837524
Validation loss: 2.06957858608615

Epoch: 5| Step: 6
Training loss: 1.7284460067749023
Validation loss: 2.05681953378903

Epoch: 5| Step: 7
Training loss: 1.9265791177749634
Validation loss: 2.0576736452758952

Epoch: 5| Step: 8
Training loss: 1.5399377346038818
Validation loss: 2.053489528676515

Epoch: 5| Step: 9
Training loss: 2.8320319652557373
Validation loss: 2.087177691921111

Epoch: 5| Step: 10
Training loss: 2.136496067047119
Validation loss: 2.1136230935332594

Epoch: 279| Step: 0
Training loss: 1.9083635807037354
Validation loss: 2.104709930317376

Epoch: 5| Step: 1
Training loss: 1.9215514659881592
Validation loss: 2.1032819158287457

Epoch: 5| Step: 2
Training loss: 1.6351985931396484
Validation loss: 2.1026168407932406

Epoch: 5| Step: 3
Training loss: 2.1177611351013184
Validation loss: 2.091115972047211

Epoch: 5| Step: 4
Training loss: 1.491694450378418
Validation loss: 2.1050820760829474

Epoch: 5| Step: 5
Training loss: 2.6496224403381348
Validation loss: 2.096743970788935

Epoch: 5| Step: 6
Training loss: 2.127692937850952
Validation loss: 2.084441049124605

Epoch: 5| Step: 7
Training loss: 1.8689243793487549
Validation loss: 2.064360885209935

Epoch: 5| Step: 8
Training loss: 1.5296199321746826
Validation loss: 2.04825932492492

Epoch: 5| Step: 9
Training loss: 2.3902487754821777
Validation loss: 2.0573126077651978

Epoch: 5| Step: 10
Training loss: 1.8573580980300903
Validation loss: 2.0735798240989767

Epoch: 280| Step: 0
Training loss: 2.2242350578308105
Validation loss: 2.051419287599543

Epoch: 5| Step: 1
Training loss: 2.0310184955596924
Validation loss: 2.0607902567873717

Epoch: 5| Step: 2
Training loss: 1.9765558242797852
Validation loss: 2.044490629626859

Epoch: 5| Step: 3
Training loss: 1.2939847707748413
Validation loss: 2.011909586127086

Epoch: 5| Step: 4
Training loss: 1.5280520915985107
Validation loss: 2.0237191197692708

Epoch: 5| Step: 5
Training loss: 1.9763844013214111
Validation loss: 2.026706544301843

Epoch: 5| Step: 6
Training loss: 2.2038464546203613
Validation loss: 2.045294254056869

Epoch: 5| Step: 7
Training loss: 2.1005303859710693
Validation loss: 2.0631044974891086

Epoch: 5| Step: 8
Training loss: 1.696088194847107
Validation loss: 2.0677248534335884

Epoch: 5| Step: 9
Training loss: 2.2345774173736572
Validation loss: 2.087284464989939

Epoch: 5| Step: 10
Training loss: 2.309138774871826
Validation loss: 2.112190277345719

Epoch: 281| Step: 0
Training loss: 1.1622090339660645
Validation loss: 2.1219206343414965

Epoch: 5| Step: 1
Training loss: 2.2332921028137207
Validation loss: 2.1317889434035107

Epoch: 5| Step: 2
Training loss: 2.214179039001465
Validation loss: 2.1455082380643455

Epoch: 5| Step: 3
Training loss: 2.7315280437469482
Validation loss: 2.170247972652476

Epoch: 5| Step: 4
Training loss: 1.7876217365264893
Validation loss: 2.172357718149821

Epoch: 5| Step: 5
Training loss: 2.519256114959717
Validation loss: 2.2002594842705676

Epoch: 5| Step: 6
Training loss: 1.918156385421753
Validation loss: 2.2011148160503757

Epoch: 5| Step: 7
Training loss: 1.63863205909729
Validation loss: 2.164001639171313

Epoch: 5| Step: 8
Training loss: 1.6549876928329468
Validation loss: 2.135020976425499

Epoch: 5| Step: 9
Training loss: 1.9780937433242798
Validation loss: 2.1104109056534304

Epoch: 5| Step: 10
Training loss: 2.0553619861602783
Validation loss: 2.1044243125505346

Epoch: 282| Step: 0
Training loss: 1.6947330236434937
Validation loss: 2.1214235892859836

Epoch: 5| Step: 1
Training loss: 2.4120166301727295
Validation loss: 2.089141248374857

Epoch: 5| Step: 2
Training loss: 1.198061466217041
Validation loss: 2.0687693883013982

Epoch: 5| Step: 3
Training loss: 1.9945337772369385
Validation loss: 2.0512004898440455

Epoch: 5| Step: 4
Training loss: 1.8442109823226929
Validation loss: 2.007746217071369

Epoch: 5| Step: 5
Training loss: 2.655430316925049
Validation loss: 1.997210152687565

Epoch: 5| Step: 6
Training loss: 2.4869003295898438
Validation loss: 2.003685280840884

Epoch: 5| Step: 7
Training loss: 2.559431314468384
Validation loss: 2.0359036717363583

Epoch: 5| Step: 8
Training loss: 1.9357154369354248
Validation loss: 2.077454839983294

Epoch: 5| Step: 9
Training loss: 1.898489236831665
Validation loss: 2.0900242251734578

Epoch: 5| Step: 10
Training loss: 1.5912165641784668
Validation loss: 2.1174342811748548

Epoch: 283| Step: 0
Training loss: 2.1575546264648438
Validation loss: 2.121185259152484

Epoch: 5| Step: 1
Training loss: 1.739905595779419
Validation loss: 2.12083928303052

Epoch: 5| Step: 2
Training loss: 1.8891559839248657
Validation loss: 2.0907945504752536

Epoch: 5| Step: 3
Training loss: 2.43147873878479
Validation loss: 2.0955771541082733

Epoch: 5| Step: 4
Training loss: 1.699798345565796
Validation loss: 2.0742685410284225

Epoch: 5| Step: 5
Training loss: 1.66745924949646
Validation loss: 2.0756015649405857

Epoch: 5| Step: 6
Training loss: 2.549790859222412
Validation loss: 2.0822044931432253

Epoch: 5| Step: 7
Training loss: 1.8846708536148071
Validation loss: 2.1170292297999063

Epoch: 5| Step: 8
Training loss: 2.17486572265625
Validation loss: 2.1039012619244155

Epoch: 5| Step: 9
Training loss: 1.8889100551605225
Validation loss: 2.1133360503822245

Epoch: 5| Step: 10
Training loss: 1.206659197807312
Validation loss: 2.0878652167576615

Epoch: 284| Step: 0
Training loss: 1.9606711864471436
Validation loss: 2.0759144931711178

Epoch: 5| Step: 1
Training loss: 1.6722606420516968
Validation loss: 2.0781864889206423

Epoch: 5| Step: 2
Training loss: 1.839130163192749
Validation loss: 2.068582962918025

Epoch: 5| Step: 3
Training loss: 2.0603187084198
Validation loss: 2.061899749181604

Epoch: 5| Step: 4
Training loss: 2.103473424911499
Validation loss: 2.0826474812722977

Epoch: 5| Step: 5
Training loss: 1.7775936126708984
Validation loss: 2.072770054622363

Epoch: 5| Step: 6
Training loss: 2.177351951599121
Validation loss: 2.0927848277553434

Epoch: 5| Step: 7
Training loss: 2.0480124950408936
Validation loss: 2.095323860004384

Epoch: 5| Step: 8
Training loss: 1.478108286857605
Validation loss: 2.0900492578424434

Epoch: 5| Step: 9
Training loss: 2.1538493633270264
Validation loss: 2.0899057029395975

Epoch: 5| Step: 10
Training loss: 2.036505699157715
Validation loss: 2.105442298355923

Epoch: 285| Step: 0
Training loss: 1.4410537481307983
Validation loss: 2.100643483541345

Epoch: 5| Step: 1
Training loss: 1.797308325767517
Validation loss: 2.084424432887826

Epoch: 5| Step: 2
Training loss: 1.9621760845184326
Validation loss: 2.0899202118637743

Epoch: 5| Step: 3
Training loss: 1.9739434719085693
Validation loss: 2.0931642337511946

Epoch: 5| Step: 4
Training loss: 1.717660665512085
Validation loss: 2.0699593162023895

Epoch: 5| Step: 5
Training loss: 2.106555700302124
Validation loss: 2.0772726869070404

Epoch: 5| Step: 6
Training loss: 1.6155952215194702
Validation loss: 2.064030030401804

Epoch: 5| Step: 7
Training loss: 2.5182435512542725
Validation loss: 2.0366944959086757

Epoch: 5| Step: 8
Training loss: 2.368950605392456
Validation loss: 2.0327351618838567

Epoch: 5| Step: 9
Training loss: 1.8933722972869873
Validation loss: 1.9993864797776746

Epoch: 5| Step: 10
Training loss: 1.823578953742981
Validation loss: 2.0053409645634312

Epoch: 286| Step: 0
Training loss: 2.1988720893859863
Validation loss: 2.015240853832614

Epoch: 5| Step: 1
Training loss: 1.5772979259490967
Validation loss: 2.019111733282766

Epoch: 5| Step: 2
Training loss: 2.112356185913086
Validation loss: 2.0135559574250252

Epoch: 5| Step: 3
Training loss: 1.6965965032577515
Validation loss: 2.0031701339188444

Epoch: 5| Step: 4
Training loss: 1.626826286315918
Validation loss: 2.0298401476234518

Epoch: 5| Step: 5
Training loss: 2.1788010597229004
Validation loss: 2.0207644713822233

Epoch: 5| Step: 6
Training loss: 2.9013280868530273
Validation loss: 2.0641887034139326

Epoch: 5| Step: 7
Training loss: 1.9748966693878174
Validation loss: 2.083795616703649

Epoch: 5| Step: 8
Training loss: 1.9699599742889404
Validation loss: 2.1130674141709522

Epoch: 5| Step: 9
Training loss: 1.693047285079956
Validation loss: 2.1487177802670385

Epoch: 5| Step: 10
Training loss: 1.1672132015228271
Validation loss: 2.197305089683943

Epoch: 287| Step: 0
Training loss: 2.390665054321289
Validation loss: 2.169073780377706

Epoch: 5| Step: 1
Training loss: 1.589402198791504
Validation loss: 2.168609542231406

Epoch: 5| Step: 2
Training loss: 2.7788543701171875
Validation loss: 2.1399805186897196

Epoch: 5| Step: 3
Training loss: 1.7524547576904297
Validation loss: 2.1389608998452463

Epoch: 5| Step: 4
Training loss: 1.9731948375701904
Validation loss: 2.079665414748653

Epoch: 5| Step: 5
Training loss: 1.8911300897598267
Validation loss: 2.045882325018606

Epoch: 5| Step: 6
Training loss: 2.207500696182251
Validation loss: 2.036588453477429

Epoch: 5| Step: 7
Training loss: 1.8812319040298462
Validation loss: 2.037254152759429

Epoch: 5| Step: 8
Training loss: 1.4945697784423828
Validation loss: 2.05006698254616

Epoch: 5| Step: 9
Training loss: 1.460789442062378
Validation loss: 2.0490815831768896

Epoch: 5| Step: 10
Training loss: 1.7099605798721313
Validation loss: 2.02415886745658

Epoch: 288| Step: 0
Training loss: 1.9379314184188843
Validation loss: 2.0407691950439126

Epoch: 5| Step: 1
Training loss: 2.2190346717834473
Validation loss: 2.0406389826087543

Epoch: 5| Step: 2
Training loss: 2.3717422485351562
Validation loss: 2.060827498794884

Epoch: 5| Step: 3
Training loss: 1.0464388132095337
Validation loss: 2.0675912646837133

Epoch: 5| Step: 4
Training loss: 1.8391368389129639
Validation loss: 2.0826474492267897

Epoch: 5| Step: 5
Training loss: 2.386813163757324
Validation loss: 2.0905069176868727

Epoch: 5| Step: 6
Training loss: 1.5109401941299438
Validation loss: 2.0960533900927474

Epoch: 5| Step: 7
Training loss: 1.7365213632583618
Validation loss: 2.075935350951328

Epoch: 5| Step: 8
Training loss: 1.8029733896255493
Validation loss: 2.0810646139165407

Epoch: 5| Step: 9
Training loss: 1.9814144372940063
Validation loss: 2.0962105335727816

Epoch: 5| Step: 10
Training loss: 2.3892359733581543
Validation loss: 2.0959819516827984

Epoch: 289| Step: 0
Training loss: 1.605843186378479
Validation loss: 2.0864773757996096

Epoch: 5| Step: 1
Training loss: 1.879916787147522
Validation loss: 2.072614574945101

Epoch: 5| Step: 2
Training loss: 1.776161551475525
Validation loss: 2.086927306267523

Epoch: 5| Step: 3
Training loss: 2.4086391925811768
Validation loss: 2.104722253737911

Epoch: 5| Step: 4
Training loss: 2.523305892944336
Validation loss: 2.089923338223529

Epoch: 5| Step: 5
Training loss: 1.8535293340682983
Validation loss: 2.0640589806341354

Epoch: 5| Step: 6
Training loss: 1.713001012802124
Validation loss: 2.0618261803862867

Epoch: 5| Step: 7
Training loss: 1.6231368780136108
Validation loss: 2.0480127924232074

Epoch: 5| Step: 8
Training loss: 1.5882339477539062
Validation loss: 2.030026461488457

Epoch: 5| Step: 9
Training loss: 1.8565117120742798
Validation loss: 2.0377507966051818

Epoch: 5| Step: 10
Training loss: 2.133361577987671
Validation loss: 2.053242552664972

Epoch: 290| Step: 0
Training loss: 1.871341347694397
Validation loss: 2.059247998781102

Epoch: 5| Step: 1
Training loss: 1.4553115367889404
Validation loss: 2.0592593018726637

Epoch: 5| Step: 2
Training loss: 1.5921603441238403
Validation loss: 2.051485541046307

Epoch: 5| Step: 3
Training loss: 1.8810440301895142
Validation loss: 2.062375440392443

Epoch: 5| Step: 4
Training loss: 1.4748094081878662
Validation loss: 2.0613654249457904

Epoch: 5| Step: 5
Training loss: 1.5640339851379395
Validation loss: 2.068841903440414

Epoch: 5| Step: 6
Training loss: 1.9980337619781494
Validation loss: 2.068538233798037

Epoch: 5| Step: 7
Training loss: 2.2989542484283447
Validation loss: 2.070751195312828

Epoch: 5| Step: 8
Training loss: 1.8911116123199463
Validation loss: 2.085549913426881

Epoch: 5| Step: 9
Training loss: 2.66520357131958
Validation loss: 2.077655057753286

Epoch: 5| Step: 10
Training loss: 2.4288861751556396
Validation loss: 2.057938334762409

Epoch: 291| Step: 0
Training loss: 2.426457643508911
Validation loss: 2.036400774473785

Epoch: 5| Step: 1
Training loss: 1.371870756149292
Validation loss: 2.0264116564104633

Epoch: 5| Step: 2
Training loss: 2.4763922691345215
Validation loss: 2.024541466466842

Epoch: 5| Step: 3
Training loss: 2.7696032524108887
Validation loss: 2.050283621716243

Epoch: 5| Step: 4
Training loss: 1.7612028121948242
Validation loss: 2.061571405779931

Epoch: 5| Step: 5
Training loss: 1.7514690160751343
Validation loss: 2.0568859859179427

Epoch: 5| Step: 6
Training loss: 2.4455323219299316
Validation loss: 2.0531858116067867

Epoch: 5| Step: 7
Training loss: 1.109987497329712
Validation loss: 2.042434525746171

Epoch: 5| Step: 8
Training loss: 1.5523784160614014
Validation loss: 2.036283932706361

Epoch: 5| Step: 9
Training loss: 1.6406456232070923
Validation loss: 2.0153861302201466

Epoch: 5| Step: 10
Training loss: 1.5642898082733154
Validation loss: 2.039633976515903

Epoch: 292| Step: 0
Training loss: 1.7944437265396118
Validation loss: 2.026482538510394

Epoch: 5| Step: 1
Training loss: 1.8859885931015015
Validation loss: 2.01151793490174

Epoch: 5| Step: 2
Training loss: 1.954800009727478
Validation loss: 2.0231784107864543

Epoch: 5| Step: 3
Training loss: 1.8216407299041748
Validation loss: 2.012967978754351

Epoch: 5| Step: 4
Training loss: 1.5207607746124268
Validation loss: 2.009834958660987

Epoch: 5| Step: 5
Training loss: 1.7195475101470947
Validation loss: 2.0189581096813245

Epoch: 5| Step: 6
Training loss: 2.1714017391204834
Validation loss: 2.0538129857791367

Epoch: 5| Step: 7
Training loss: 2.1844801902770996
Validation loss: 2.0795467463872765

Epoch: 5| Step: 8
Training loss: 2.0524260997772217
Validation loss: 2.1000501212253364

Epoch: 5| Step: 9
Training loss: 2.364683151245117
Validation loss: 2.121487884111302

Epoch: 5| Step: 10
Training loss: 1.7308380603790283
Validation loss: 2.133226727926603

Epoch: 293| Step: 0
Training loss: 1.9526159763336182
Validation loss: 2.1241755844444357

Epoch: 5| Step: 1
Training loss: 1.8996731042861938
Validation loss: 2.1105353152880104

Epoch: 5| Step: 2
Training loss: 3.2134156227111816
Validation loss: 2.103524374705489

Epoch: 5| Step: 3
Training loss: 2.0569021701812744
Validation loss: 2.1012671096350557

Epoch: 5| Step: 4
Training loss: 1.7717231512069702
Validation loss: 2.1130640981017903

Epoch: 5| Step: 5
Training loss: 1.7980258464813232
Validation loss: 2.1149324127422866

Epoch: 5| Step: 6
Training loss: 1.8383705615997314
Validation loss: 2.106107827155821

Epoch: 5| Step: 7
Training loss: 1.3409628868103027
Validation loss: 2.099313005324333

Epoch: 5| Step: 8
Training loss: 1.9971752166748047
Validation loss: 2.08457774244329

Epoch: 5| Step: 9
Training loss: 1.8110511302947998
Validation loss: 2.0602310549828315

Epoch: 5| Step: 10
Training loss: 2.107919692993164
Validation loss: 2.0275371754041283

Epoch: 294| Step: 0
Training loss: 2.29984188079834
Validation loss: 2.035893961947451

Epoch: 5| Step: 1
Training loss: 2.1690454483032227
Validation loss: 2.0633987842067594

Epoch: 5| Step: 2
Training loss: 1.7653038501739502
Validation loss: 2.078097794645576

Epoch: 5| Step: 3
Training loss: 1.5975360870361328
Validation loss: 2.0943173875090895

Epoch: 5| Step: 4
Training loss: 2.0052154064178467
Validation loss: 2.1027273901047243

Epoch: 5| Step: 5
Training loss: 1.4922245740890503
Validation loss: 2.0767558300366966

Epoch: 5| Step: 6
Training loss: 1.6650266647338867
Validation loss: 2.0865744506159136

Epoch: 5| Step: 7
Training loss: 1.8619219064712524
Validation loss: 2.0720038055091776

Epoch: 5| Step: 8
Training loss: 1.831546425819397
Validation loss: 2.06934065716241

Epoch: 5| Step: 9
Training loss: 2.12972354888916
Validation loss: 2.0557142842200493

Epoch: 5| Step: 10
Training loss: 2.147280693054199
Validation loss: 2.0604453830308813

Epoch: 295| Step: 0
Training loss: 1.3576478958129883
Validation loss: 2.0518218945431452

Epoch: 5| Step: 1
Training loss: 2.4092252254486084
Validation loss: 2.065220571333362

Epoch: 5| Step: 2
Training loss: 1.809988021850586
Validation loss: 2.063824551079863

Epoch: 5| Step: 3
Training loss: 1.7968559265136719
Validation loss: 2.064125940363894

Epoch: 5| Step: 4
Training loss: 2.0559287071228027
Validation loss: 2.068217915873374

Epoch: 5| Step: 5
Training loss: 2.1398842334747314
Validation loss: 2.0599781890069284

Epoch: 5| Step: 6
Training loss: 1.9457244873046875
Validation loss: 2.0897965303031345

Epoch: 5| Step: 7
Training loss: 1.4372961521148682
Validation loss: 2.1037348162743355

Epoch: 5| Step: 8
Training loss: 1.7798388004302979
Validation loss: 2.078463287763698

Epoch: 5| Step: 9
Training loss: 2.272453784942627
Validation loss: 2.0771400543951217

Epoch: 5| Step: 10
Training loss: 1.642916202545166
Validation loss: 2.0729778453867924

Epoch: 296| Step: 0
Training loss: 1.9413200616836548
Validation loss: 2.0546647489711805

Epoch: 5| Step: 1
Training loss: 2.5330395698547363
Validation loss: 2.0664154534698813

Epoch: 5| Step: 2
Training loss: 2.016458749771118
Validation loss: 2.056598177520178

Epoch: 5| Step: 3
Training loss: 2.3168959617614746
Validation loss: 2.0611807966745026

Epoch: 5| Step: 4
Training loss: 1.5855653285980225
Validation loss: 2.0662233675679853

Epoch: 5| Step: 5
Training loss: 1.3650010824203491
Validation loss: 2.072124969574713

Epoch: 5| Step: 6
Training loss: 2.244433879852295
Validation loss: 2.0779993892997823

Epoch: 5| Step: 7
Training loss: 1.6310129165649414
Validation loss: 2.0569786192268453

Epoch: 5| Step: 8
Training loss: 1.9134165048599243
Validation loss: 2.0549791320677726

Epoch: 5| Step: 9
Training loss: 1.1216539144515991
Validation loss: 2.053896716845933

Epoch: 5| Step: 10
Training loss: 1.8621731996536255
Validation loss: 2.0572994703887613

Epoch: 297| Step: 0
Training loss: 1.5939552783966064
Validation loss: 2.0295208346459175

Epoch: 5| Step: 1
Training loss: 1.6148345470428467
Validation loss: 2.033949189288642

Epoch: 5| Step: 2
Training loss: 2.567612886428833
Validation loss: 2.0430973614415815

Epoch: 5| Step: 3
Training loss: 2.3108232021331787
Validation loss: 2.037361782084229

Epoch: 5| Step: 4
Training loss: 1.8608314990997314
Validation loss: 2.058430105127314

Epoch: 5| Step: 5
Training loss: 1.24346923828125
Validation loss: 2.0744671731866817

Epoch: 5| Step: 6
Training loss: 1.9178552627563477
Validation loss: 2.0858718759270123

Epoch: 5| Step: 7
Training loss: 1.722659707069397
Validation loss: 2.066512556486232

Epoch: 5| Step: 8
Training loss: 1.8340117931365967
Validation loss: 2.0791321672419065

Epoch: 5| Step: 9
Training loss: 1.8479896783828735
Validation loss: 2.071906981929656

Epoch: 5| Step: 10
Training loss: 1.7979750633239746
Validation loss: 2.0738856612995105

Epoch: 298| Step: 0
Training loss: 2.2565948963165283
Validation loss: 2.0612642559953915

Epoch: 5| Step: 1
Training loss: 1.9203733205795288
Validation loss: 2.0697711744616107

Epoch: 5| Step: 2
Training loss: 1.7454462051391602
Validation loss: 2.047623139555736

Epoch: 5| Step: 3
Training loss: 2.1904549598693848
Validation loss: 2.049662541317683

Epoch: 5| Step: 4
Training loss: 2.0695319175720215
Validation loss: 2.060362313383369

Epoch: 5| Step: 5
Training loss: 1.6544700860977173
Validation loss: 2.0640794115681804

Epoch: 5| Step: 6
Training loss: 1.429362416267395
Validation loss: 2.0634819422998736

Epoch: 5| Step: 7
Training loss: 2.0805273056030273
Validation loss: 2.0822300218766734

Epoch: 5| Step: 8
Training loss: 1.6662371158599854
Validation loss: 2.0734937562737414

Epoch: 5| Step: 9
Training loss: 1.301592230796814
Validation loss: 2.046383019416563

Epoch: 5| Step: 10
Training loss: 2.0697126388549805
Validation loss: 2.0515299535566762

Epoch: 299| Step: 0
Training loss: 1.947587251663208
Validation loss: 2.0436918222776024

Epoch: 5| Step: 1
Training loss: 2.4794485569000244
Validation loss: 2.0318453504193212

Epoch: 5| Step: 2
Training loss: 1.5648777484893799
Validation loss: 2.0487256947384087

Epoch: 5| Step: 3
Training loss: 1.4717912673950195
Validation loss: 2.0523590733928065

Epoch: 5| Step: 4
Training loss: 1.727988839149475
Validation loss: 2.052034572888446

Epoch: 5| Step: 5
Training loss: 1.7763471603393555
Validation loss: 2.0507538780089347

Epoch: 5| Step: 6
Training loss: 1.9958040714263916
Validation loss: 2.048791359829646

Epoch: 5| Step: 7
Training loss: 1.765594720840454
Validation loss: 2.065328019921498

Epoch: 5| Step: 8
Training loss: 2.116607189178467
Validation loss: 2.085090708988969

Epoch: 5| Step: 9
Training loss: 2.2329764366149902
Validation loss: 2.0932692763625935

Epoch: 5| Step: 10
Training loss: 1.0080626010894775
Validation loss: 2.0957458839621594

Epoch: 300| Step: 0
Training loss: 1.5842134952545166
Validation loss: 2.1160256106366395

Epoch: 5| Step: 1
Training loss: 1.746835708618164
Validation loss: 2.1135005233108357

Epoch: 5| Step: 2
Training loss: 1.360085368156433
Validation loss: 2.1164479999132055

Epoch: 5| Step: 3
Training loss: 2.0113303661346436
Validation loss: 2.1313054074523268

Epoch: 5| Step: 4
Training loss: 2.6696677207946777
Validation loss: 2.0976555526897473

Epoch: 5| Step: 5
Training loss: 1.696552038192749
Validation loss: 2.0906510135178924

Epoch: 5| Step: 6
Training loss: 1.9293336868286133
Validation loss: 2.0935369909450574

Epoch: 5| Step: 7
Training loss: 2.079946994781494
Validation loss: 2.0861357668394684

Epoch: 5| Step: 8
Training loss: 2.0923495292663574
Validation loss: 2.079442693341163

Epoch: 5| Step: 9
Training loss: 1.4726998805999756
Validation loss: 2.0787806357106855

Epoch: 5| Step: 10
Training loss: 1.774885654449463
Validation loss: 2.0512161690701722

Epoch: 301| Step: 0
Training loss: 1.682896375656128
Validation loss: 2.0376876579817904

Epoch: 5| Step: 1
Training loss: 2.470608711242676
Validation loss: 2.030832512404329

Epoch: 5| Step: 2
Training loss: 1.599061131477356
Validation loss: 2.033671239370941

Epoch: 5| Step: 3
Training loss: 2.1741783618927
Validation loss: 2.0083194817266157

Epoch: 5| Step: 4
Training loss: 1.7189525365829468
Validation loss: 2.006488662894054

Epoch: 5| Step: 5
Training loss: 1.5554391145706177
Validation loss: 2.0113845999522875

Epoch: 5| Step: 6
Training loss: 2.1018385887145996
Validation loss: 2.024370406263618

Epoch: 5| Step: 7
Training loss: 1.8033523559570312
Validation loss: 2.041559780797651

Epoch: 5| Step: 8
Training loss: 1.9650341272354126
Validation loss: 2.0354514916737876

Epoch: 5| Step: 9
Training loss: 1.5708502531051636
Validation loss: 2.0457434141507713

Epoch: 5| Step: 10
Training loss: 1.4389119148254395
Validation loss: 2.0730126186083724

Epoch: 302| Step: 0
Training loss: 2.517652988433838
Validation loss: 2.05800203610492

Epoch: 5| Step: 1
Training loss: 1.7714414596557617
Validation loss: 2.0553444739310973

Epoch: 5| Step: 2
Training loss: 1.7955411672592163
Validation loss: 2.0360844699285363

Epoch: 5| Step: 3
Training loss: 1.753644347190857
Validation loss: 2.027417928941788

Epoch: 5| Step: 4
Training loss: 2.0876548290252686
Validation loss: 2.026768071677095

Epoch: 5| Step: 5
Training loss: 1.7970783710479736
Validation loss: 2.0304750345086537

Epoch: 5| Step: 6
Training loss: 1.9352620840072632
Validation loss: 2.0288814037076888

Epoch: 5| Step: 7
Training loss: 1.845666527748108
Validation loss: 2.0682562884464057

Epoch: 5| Step: 8
Training loss: 1.3099899291992188
Validation loss: 2.061786784920641

Epoch: 5| Step: 9
Training loss: 2.0583560466766357
Validation loss: 2.0966543933396697

Epoch: 5| Step: 10
Training loss: 1.234683632850647
Validation loss: 2.0924158327041136

Epoch: 303| Step: 0
Training loss: 1.7454538345336914
Validation loss: 2.1014836731777398

Epoch: 5| Step: 1
Training loss: 1.753615379333496
Validation loss: 2.103650901907234

Epoch: 5| Step: 2
Training loss: 1.6421668529510498
Validation loss: 2.108021923290786

Epoch: 5| Step: 3
Training loss: 1.3012367486953735
Validation loss: 2.092682788448949

Epoch: 5| Step: 4
Training loss: 1.6877660751342773
Validation loss: 2.0760646725213654

Epoch: 5| Step: 5
Training loss: 2.1602821350097656
Validation loss: 2.080379903957408

Epoch: 5| Step: 6
Training loss: 2.186997413635254
Validation loss: 2.068535130511048

Epoch: 5| Step: 7
Training loss: 2.4215452671051025
Validation loss: 2.0549548018363213

Epoch: 5| Step: 8
Training loss: 1.343071699142456
Validation loss: 2.0405783012349117

Epoch: 5| Step: 9
Training loss: 2.4034202098846436
Validation loss: 2.0310702298277166

Epoch: 5| Step: 10
Training loss: 1.5634686946868896
Validation loss: 2.035919166380359

Epoch: 304| Step: 0
Training loss: 1.6611369848251343
Validation loss: 2.04585507095501

Epoch: 5| Step: 1
Training loss: 1.9773757457733154
Validation loss: 2.0262550718040875

Epoch: 5| Step: 2
Training loss: 1.9985517263412476
Validation loss: 2.0276097123340895

Epoch: 5| Step: 3
Training loss: 1.3551054000854492
Validation loss: 2.0347848746084396

Epoch: 5| Step: 4
Training loss: 1.7517564296722412
Validation loss: 2.0500260296688286

Epoch: 5| Step: 5
Training loss: 2.1701693534851074
Validation loss: 2.043631536986238

Epoch: 5| Step: 6
Training loss: 2.183974504470825
Validation loss: 2.074922614200141

Epoch: 5| Step: 7
Training loss: 1.6227662563323975
Validation loss: 2.07476629236693

Epoch: 5| Step: 8
Training loss: 1.6727383136749268
Validation loss: 2.0945602373410295

Epoch: 5| Step: 9
Training loss: 1.720398187637329
Validation loss: 2.0907171234007804

Epoch: 5| Step: 10
Training loss: 1.9789247512817383
Validation loss: 2.103532173300302

Epoch: 305| Step: 0
Training loss: 2.1013665199279785
Validation loss: 2.090163900006202

Epoch: 5| Step: 1
Training loss: 1.9343597888946533
Validation loss: 2.0628343397571194

Epoch: 5| Step: 2
Training loss: 1.326861023902893
Validation loss: 2.0457516357462895

Epoch: 5| Step: 3
Training loss: 1.766417145729065
Validation loss: 2.062752580129972

Epoch: 5| Step: 4
Training loss: 2.009927272796631
Validation loss: 2.0412474755317933

Epoch: 5| Step: 5
Training loss: 1.8504854440689087
Validation loss: 2.035590212832215

Epoch: 5| Step: 6
Training loss: 1.6827218532562256
Validation loss: 2.010753095790904

Epoch: 5| Step: 7
Training loss: 2.0601346492767334
Validation loss: 2.011882907600813

Epoch: 5| Step: 8
Training loss: 1.5940511226654053
Validation loss: 2.009591164127473

Epoch: 5| Step: 9
Training loss: 1.441544771194458
Validation loss: 2.0352274576822915

Epoch: 5| Step: 10
Training loss: 2.170949935913086
Validation loss: 2.0513604840924664

Epoch: 306| Step: 0
Training loss: 2.2655038833618164
Validation loss: 2.052504406180433

Epoch: 5| Step: 1
Training loss: 2.129361629486084
Validation loss: 2.045664550155722

Epoch: 5| Step: 2
Training loss: 1.8071539402008057
Validation loss: 2.047744184411982

Epoch: 5| Step: 3
Training loss: 1.5841318368911743
Validation loss: 2.0446303877779233

Epoch: 5| Step: 4
Training loss: 1.4163812398910522
Validation loss: 2.0451516592374412

Epoch: 5| Step: 5
Training loss: 1.5713897943496704
Validation loss: 2.0506398908553587

Epoch: 5| Step: 6
Training loss: 1.6530187129974365
Validation loss: 2.0504755076541694

Epoch: 5| Step: 7
Training loss: 2.0391898155212402
Validation loss: 2.0606520522025322

Epoch: 5| Step: 8
Training loss: 2.1352176666259766
Validation loss: 2.068414503528226

Epoch: 5| Step: 9
Training loss: 1.5155138969421387
Validation loss: 2.076138101598268

Epoch: 5| Step: 10
Training loss: 1.7334598302841187
Validation loss: 2.0805678047159666

Epoch: 307| Step: 0
Training loss: 1.9656236171722412
Validation loss: 2.076227366283376

Epoch: 5| Step: 1
Training loss: 1.8953087329864502
Validation loss: 2.0636484315318446

Epoch: 5| Step: 2
Training loss: 1.9562766551971436
Validation loss: 2.0494225396904895

Epoch: 5| Step: 3
Training loss: 2.35585880279541
Validation loss: 2.0563433606137513

Epoch: 5| Step: 4
Training loss: 1.9393436908721924
Validation loss: 2.0499410885636524

Epoch: 5| Step: 5
Training loss: 1.3229868412017822
Validation loss: 2.026350441799369

Epoch: 5| Step: 6
Training loss: 1.347210168838501
Validation loss: 2.023074685886342

Epoch: 5| Step: 7
Training loss: 1.8163738250732422
Validation loss: 2.019831518973074

Epoch: 5| Step: 8
Training loss: 1.8065637350082397
Validation loss: 2.009853546337415

Epoch: 5| Step: 9
Training loss: 1.627322793006897
Validation loss: 1.9888981862734723

Epoch: 5| Step: 10
Training loss: 1.8752561807632446
Validation loss: 1.9941159653407272

Epoch: 308| Step: 0
Training loss: 1.6766910552978516
Validation loss: 2.026874029508201

Epoch: 5| Step: 1
Training loss: 1.4708311557769775
Validation loss: 2.043217655151121

Epoch: 5| Step: 2
Training loss: 2.2058334350585938
Validation loss: 2.0738803930180048

Epoch: 5| Step: 3
Training loss: 1.70415461063385
Validation loss: 2.08153760305015

Epoch: 5| Step: 4
Training loss: 1.5960172414779663
Validation loss: 2.0980066086656306

Epoch: 5| Step: 5
Training loss: 1.9162050485610962
Validation loss: 2.0814385862760645

Epoch: 5| Step: 6
Training loss: 2.2419304847717285
Validation loss: 2.103288073693552

Epoch: 5| Step: 7
Training loss: 1.2036411762237549
Validation loss: 2.1125105375884683

Epoch: 5| Step: 8
Training loss: 1.9891719818115234
Validation loss: 2.0968045265443864

Epoch: 5| Step: 9
Training loss: 1.6986420154571533
Validation loss: 2.085924830487979

Epoch: 5| Step: 10
Training loss: 2.0631070137023926
Validation loss: 2.0710698353346957

Epoch: 309| Step: 0
Training loss: 2.213740348815918
Validation loss: 2.049263528598252

Epoch: 5| Step: 1
Training loss: 2.028794765472412
Validation loss: 2.034221697879094

Epoch: 5| Step: 2
Training loss: 1.7015197277069092
Validation loss: 2.0428775472025715

Epoch: 5| Step: 3
Training loss: 1.2654918432235718
Validation loss: 2.0365049813383367

Epoch: 5| Step: 4
Training loss: 2.031524658203125
Validation loss: 2.029140326284593

Epoch: 5| Step: 5
Training loss: 2.117558240890503
Validation loss: 2.041140458917105

Epoch: 5| Step: 6
Training loss: 1.7544898986816406
Validation loss: 2.0466502763891734

Epoch: 5| Step: 7
Training loss: 1.5143976211547852
Validation loss: 2.042426787396913

Epoch: 5| Step: 8
Training loss: 1.7431195974349976
Validation loss: 2.029586422827936

Epoch: 5| Step: 9
Training loss: 1.9412567615509033
Validation loss: 2.0649956849313553

Epoch: 5| Step: 10
Training loss: 1.2845102548599243
Validation loss: 2.064652781332693

Epoch: 310| Step: 0
Training loss: 2.8533546924591064
Validation loss: 2.082432218777236

Epoch: 5| Step: 1
Training loss: 2.057361125946045
Validation loss: 2.0813780394933556

Epoch: 5| Step: 2
Training loss: 1.9185727834701538
Validation loss: 2.09993250139298

Epoch: 5| Step: 3
Training loss: 2.0137412548065186
Validation loss: 2.081126723238217

Epoch: 5| Step: 4
Training loss: 2.1804087162017822
Validation loss: 2.071550969154604

Epoch: 5| Step: 5
Training loss: 0.7240587472915649
Validation loss: 2.0593428509209746

Epoch: 5| Step: 6
Training loss: 1.7947279214859009
Validation loss: 2.0214716542151665

Epoch: 5| Step: 7
Training loss: 1.5003694295883179
Validation loss: 2.0133306851951023

Epoch: 5| Step: 8
Training loss: 1.205268383026123
Validation loss: 2.0016864730465795

Epoch: 5| Step: 9
Training loss: 1.7640193700790405
Validation loss: 2.0156516849353747

Epoch: 5| Step: 10
Training loss: 1.796143651008606
Validation loss: 2.0129982912412254

Epoch: 311| Step: 0
Training loss: 1.57271409034729
Validation loss: 2.04238143274861

Epoch: 5| Step: 1
Training loss: 1.8137127161026
Validation loss: 2.0622801831973496

Epoch: 5| Step: 2
Training loss: 2.2000746726989746
Validation loss: 2.0820477316456456

Epoch: 5| Step: 3
Training loss: 2.455911636352539
Validation loss: 2.0726744000629713

Epoch: 5| Step: 4
Training loss: 1.9282419681549072
Validation loss: 2.079176711779769

Epoch: 5| Step: 5
Training loss: 1.5656713247299194
Validation loss: 2.0321704033882386

Epoch: 5| Step: 6
Training loss: 1.2684218883514404
Validation loss: 2.0478334567880117

Epoch: 5| Step: 7
Training loss: 1.9298521280288696
Validation loss: 2.0712385549340198

Epoch: 5| Step: 8
Training loss: 1.7225879430770874
Validation loss: 2.0718306854207027

Epoch: 5| Step: 9
Training loss: 1.4618690013885498
Validation loss: 2.079963694336594

Epoch: 5| Step: 10
Training loss: 1.8220417499542236
Validation loss: 2.0773150972140733

Epoch: 312| Step: 0
Training loss: 1.3760510683059692
Validation loss: 2.0737940162740727

Epoch: 5| Step: 1
Training loss: 1.8388557434082031
Validation loss: 2.0841888227770404

Epoch: 5| Step: 2
Training loss: 2.0397305488586426
Validation loss: 2.085077808749291

Epoch: 5| Step: 3
Training loss: 1.6469662189483643
Validation loss: 2.0918979952412267

Epoch: 5| Step: 4
Training loss: 1.6224937438964844
Validation loss: 2.072155398707236

Epoch: 5| Step: 5
Training loss: 2.4885878562927246
Validation loss: 2.088252495693904

Epoch: 5| Step: 6
Training loss: 1.5568188428878784
Validation loss: 2.0657104471678376

Epoch: 5| Step: 7
Training loss: 1.8188810348510742
Validation loss: 2.0658215309983943

Epoch: 5| Step: 8
Training loss: 1.9741395711898804
Validation loss: 2.0567935692366732

Epoch: 5| Step: 9
Training loss: 1.6021554470062256
Validation loss: 2.058139447242983

Epoch: 5| Step: 10
Training loss: 1.6036018133163452
Validation loss: 2.0527484147779402

Epoch: 313| Step: 0
Training loss: 1.5789291858673096
Validation loss: 2.052048688293785

Epoch: 5| Step: 1
Training loss: 1.9137592315673828
Validation loss: 2.045852545768984

Epoch: 5| Step: 2
Training loss: 1.5267047882080078
Validation loss: 2.060396388012876

Epoch: 5| Step: 3
Training loss: 2.4333300590515137
Validation loss: 2.0582179484828824

Epoch: 5| Step: 4
Training loss: 1.968881607055664
Validation loss: 2.0245521132664015

Epoch: 5| Step: 5
Training loss: 1.6788002252578735
Validation loss: 2.0334786445863786

Epoch: 5| Step: 6
Training loss: 1.3484220504760742
Validation loss: 2.03999722901211

Epoch: 5| Step: 7
Training loss: 2.0979931354522705
Validation loss: 2.020353017314788

Epoch: 5| Step: 8
Training loss: 1.977041244506836
Validation loss: 2.038593130726968

Epoch: 5| Step: 9
Training loss: 1.9002628326416016
Validation loss: 2.0340400677855297

Epoch: 5| Step: 10
Training loss: 0.9514897465705872
Validation loss: 2.028152975984799

Epoch: 314| Step: 0
Training loss: 1.7668288946151733
Validation loss: 2.053822032866939

Epoch: 5| Step: 1
Training loss: 1.727405309677124
Validation loss: 2.0586039186805807

Epoch: 5| Step: 2
Training loss: 1.6485798358917236
Validation loss: 2.076338175804384

Epoch: 5| Step: 3
Training loss: 1.9995208978652954
Validation loss: 2.0877951447681715

Epoch: 5| Step: 4
Training loss: 1.2642699480056763
Validation loss: 2.0745213826497397

Epoch: 5| Step: 5
Training loss: 1.8846887350082397
Validation loss: 2.097413985959945

Epoch: 5| Step: 6
Training loss: 1.8109643459320068
Validation loss: 2.0898857629427345

Epoch: 5| Step: 7
Training loss: 1.8147557973861694
Validation loss: 2.068391523053569

Epoch: 5| Step: 8
Training loss: 2.059363842010498
Validation loss: 2.039240675587808

Epoch: 5| Step: 9
Training loss: 1.3256523609161377
Validation loss: 2.0628969771887666

Epoch: 5| Step: 10
Training loss: 2.154356002807617
Validation loss: 2.060264261819983

Epoch: 315| Step: 0
Training loss: 2.000598430633545
Validation loss: 2.0614154531109716

Epoch: 5| Step: 1
Training loss: 1.5842063426971436
Validation loss: 2.0640265018709245

Epoch: 5| Step: 2
Training loss: 1.3252956867218018
Validation loss: 2.069569715889551

Epoch: 5| Step: 3
Training loss: 1.8226900100708008
Validation loss: 2.052965094966273

Epoch: 5| Step: 4
Training loss: 1.2564400434494019
Validation loss: 2.0528626621410413

Epoch: 5| Step: 5
Training loss: 1.9318774938583374
Validation loss: 2.077555233432401

Epoch: 5| Step: 6
Training loss: 1.7566484212875366
Validation loss: 2.08657939844234

Epoch: 5| Step: 7
Training loss: 2.089751720428467
Validation loss: 2.084704283745058

Epoch: 5| Step: 8
Training loss: 1.620388388633728
Validation loss: 2.0948440772230907

Epoch: 5| Step: 9
Training loss: 1.894426703453064
Validation loss: 2.0968872501004125

Epoch: 5| Step: 10
Training loss: 2.002490520477295
Validation loss: 2.095679626669935

Epoch: 316| Step: 0
Training loss: 2.146333932876587
Validation loss: 2.083432689789803

Epoch: 5| Step: 1
Training loss: 1.7070815563201904
Validation loss: 2.0886998599575413

Epoch: 5| Step: 2
Training loss: 1.5754472017288208
Validation loss: 2.0842765505595873

Epoch: 5| Step: 3
Training loss: 2.0173370838165283
Validation loss: 2.0829449520316174

Epoch: 5| Step: 4
Training loss: 1.5720348358154297
Validation loss: 2.0714724550965014

Epoch: 5| Step: 5
Training loss: 1.7723979949951172
Validation loss: 2.0747975687826834

Epoch: 5| Step: 6
Training loss: 2.0441060066223145
Validation loss: 2.081435775244108

Epoch: 5| Step: 7
Training loss: 1.4094263315200806
Validation loss: 2.054580580803656

Epoch: 5| Step: 8
Training loss: 1.533219575881958
Validation loss: 2.0308775183975056

Epoch: 5| Step: 9
Training loss: 1.9237515926361084
Validation loss: 2.0319868646642214

Epoch: 5| Step: 10
Training loss: 1.6061445474624634
Validation loss: 2.045186693950366

Epoch: 317| Step: 0
Training loss: 1.5871025323867798
Validation loss: 2.0472401931721675

Epoch: 5| Step: 1
Training loss: 1.7552144527435303
Validation loss: 2.0885774512444772

Epoch: 5| Step: 2
Training loss: 1.4785760641098022
Validation loss: 2.0981426572286956

Epoch: 5| Step: 3
Training loss: 1.8957099914550781
Validation loss: 2.1093430890831897

Epoch: 5| Step: 4
Training loss: 1.935559630393982
Validation loss: 2.112273200865715

Epoch: 5| Step: 5
Training loss: 1.8385403156280518
Validation loss: 2.1319262596868698

Epoch: 5| Step: 6
Training loss: 1.876194715499878
Validation loss: 2.1358859064758464

Epoch: 5| Step: 7
Training loss: 1.8835208415985107
Validation loss: 2.1389994736640685

Epoch: 5| Step: 8
Training loss: 1.4431359767913818
Validation loss: 2.1294644442937707

Epoch: 5| Step: 9
Training loss: 1.7141414880752563
Validation loss: 2.1067186222281507

Epoch: 5| Step: 10
Training loss: 2.0746564865112305
Validation loss: 2.0377811795921734

Epoch: 318| Step: 0
Training loss: 1.9984452724456787
Validation loss: 2.0125547352657525

Epoch: 5| Step: 1
Training loss: 1.3010905981063843
Validation loss: 1.9975979481973956

Epoch: 5| Step: 2
Training loss: 2.4157967567443848
Validation loss: 2.003064536279248

Epoch: 5| Step: 3
Training loss: 1.570615530014038
Validation loss: 1.9978701222327448

Epoch: 5| Step: 4
Training loss: 1.9079742431640625
Validation loss: 1.9918022694126252

Epoch: 5| Step: 5
Training loss: 1.281922698020935
Validation loss: 1.991524415631448

Epoch: 5| Step: 6
Training loss: 1.7197234630584717
Validation loss: 2.0049380205010854

Epoch: 5| Step: 7
Training loss: 1.8013827800750732
Validation loss: 2.0465897834429176

Epoch: 5| Step: 8
Training loss: 1.3474481105804443
Validation loss: 2.055087019038457

Epoch: 5| Step: 9
Training loss: 1.909419298171997
Validation loss: 2.083468198776245

Epoch: 5| Step: 10
Training loss: 2.1745450496673584
Validation loss: 2.081158986655615

Epoch: 319| Step: 0
Training loss: 1.5186892747879028
Validation loss: 2.0631665081106205

Epoch: 5| Step: 1
Training loss: 1.1953513622283936
Validation loss: 2.073802812125093

Epoch: 5| Step: 2
Training loss: 2.5891716480255127
Validation loss: 2.065576725108649

Epoch: 5| Step: 3
Training loss: 1.8319847583770752
Validation loss: 2.089134300908735

Epoch: 5| Step: 4
Training loss: 1.9274451732635498
Validation loss: 2.0455805768248854

Epoch: 5| Step: 5
Training loss: 1.290254831314087
Validation loss: 2.0565448832768265

Epoch: 5| Step: 6
Training loss: 1.7752010822296143
Validation loss: 2.034256480073416

Epoch: 5| Step: 7
Training loss: 1.9380409717559814
Validation loss: 2.0259813570207164

Epoch: 5| Step: 8
Training loss: 1.224910855293274
Validation loss: 2.033872683842977

Epoch: 5| Step: 9
Training loss: 2.351884365081787
Validation loss: 2.0365627555436987

Epoch: 5| Step: 10
Training loss: 1.4725569486618042
Validation loss: 2.05221587868147

Epoch: 320| Step: 0
Training loss: 1.582939624786377
Validation loss: 2.0509902277300434

Epoch: 5| Step: 1
Training loss: 2.0291152000427246
Validation loss: 2.0569278540149813

Epoch: 5| Step: 2
Training loss: 2.4651312828063965
Validation loss: 2.0645463530735304

Epoch: 5| Step: 3
Training loss: 2.120914936065674
Validation loss: 2.0580631199703423

Epoch: 5| Step: 4
Training loss: 2.1281895637512207
Validation loss: 2.0487447759156585

Epoch: 5| Step: 5
Training loss: 1.7259113788604736
Validation loss: 2.03290065129598

Epoch: 5| Step: 6
Training loss: 1.385988712310791
Validation loss: 2.0354193769475466

Epoch: 5| Step: 7
Training loss: 1.6033376455307007
Validation loss: 2.021969364535424

Epoch: 5| Step: 8
Training loss: 1.272724986076355
Validation loss: 2.0204170480851205

Epoch: 5| Step: 9
Training loss: 1.5297352075576782
Validation loss: 2.032756624683257

Epoch: 5| Step: 10
Training loss: 1.5116209983825684
Validation loss: 2.0386695720816173

Epoch: 321| Step: 0
Training loss: 1.6167590618133545
Validation loss: 2.0619896073495187

Epoch: 5| Step: 1
Training loss: 1.618265151977539
Validation loss: 2.050094150727795

Epoch: 5| Step: 2
Training loss: 1.2411444187164307
Validation loss: 2.048512296010089

Epoch: 5| Step: 3
Training loss: 1.9021015167236328
Validation loss: 2.06042113355411

Epoch: 5| Step: 4
Training loss: 2.057140827178955
Validation loss: 2.02619791799976

Epoch: 5| Step: 5
Training loss: 1.929286241531372
Validation loss: 2.027819915484357

Epoch: 5| Step: 6
Training loss: 1.2821241617202759
Validation loss: 2.021117453934044

Epoch: 5| Step: 7
Training loss: 1.9592164754867554
Validation loss: 2.0327175163453624

Epoch: 5| Step: 8
Training loss: 1.6474720239639282
Validation loss: 2.007991447243639

Epoch: 5| Step: 9
Training loss: 1.9169962406158447
Validation loss: 2.0162171753503944

Epoch: 5| Step: 10
Training loss: 1.9821144342422485
Validation loss: 2.0395773162123976

Epoch: 322| Step: 0
Training loss: 1.430135726928711
Validation loss: 2.063037303186232

Epoch: 5| Step: 1
Training loss: 1.5290017127990723
Validation loss: 2.062819798787435

Epoch: 5| Step: 2
Training loss: 1.6213605403900146
Validation loss: 2.0773898863023326

Epoch: 5| Step: 3
Training loss: 1.7000501155853271
Validation loss: 2.082986443273483

Epoch: 5| Step: 4
Training loss: 1.752780556678772
Validation loss: 2.0966395998513825

Epoch: 5| Step: 5
Training loss: 1.4804894924163818
Validation loss: 2.0933678970542005

Epoch: 5| Step: 6
Training loss: 2.403848648071289
Validation loss: 2.086498163079703

Epoch: 5| Step: 7
Training loss: 1.840869665145874
Validation loss: 2.070413718941391

Epoch: 5| Step: 8
Training loss: 2.1284632682800293
Validation loss: 2.077300179389215

Epoch: 5| Step: 9
Training loss: 1.8612409830093384
Validation loss: 2.080502233197612

Epoch: 5| Step: 10
Training loss: 1.2942919731140137
Validation loss: 2.071451579370806

Epoch: 323| Step: 0
Training loss: 1.524741530418396
Validation loss: 2.0497773539635444

Epoch: 5| Step: 1
Training loss: 1.5767295360565186
Validation loss: 2.0569453188168105

Epoch: 5| Step: 2
Training loss: 1.3273484706878662
Validation loss: 2.04216944402264

Epoch: 5| Step: 3
Training loss: 1.5826587677001953
Validation loss: 2.0363856900122856

Epoch: 5| Step: 4
Training loss: 1.6007392406463623
Validation loss: 2.0335897425169587

Epoch: 5| Step: 5
Training loss: 1.845250129699707
Validation loss: 2.010641030085984

Epoch: 5| Step: 6
Training loss: 2.189286470413208
Validation loss: 2.0585353502663235

Epoch: 5| Step: 7
Training loss: 1.4988034963607788
Validation loss: 2.0508950602623726

Epoch: 5| Step: 8
Training loss: 2.2223739624023438
Validation loss: 2.085091096098705

Epoch: 5| Step: 9
Training loss: 1.650754690170288
Validation loss: 2.0672446117606214

Epoch: 5| Step: 10
Training loss: 2.0555338859558105
Validation loss: 2.089960255930501

Epoch: 324| Step: 0
Training loss: 1.758509874343872
Validation loss: 2.0938475772898686

Epoch: 5| Step: 1
Training loss: 1.8400455713272095
Validation loss: 2.073503630135649

Epoch: 5| Step: 2
Training loss: 1.8758704662322998
Validation loss: 2.0936120774156306

Epoch: 5| Step: 3
Training loss: 2.1766858100891113
Validation loss: 2.0873383937343473

Epoch: 5| Step: 4
Training loss: 1.4752299785614014
Validation loss: 2.073788491628503

Epoch: 5| Step: 5
Training loss: 1.4219859838485718
Validation loss: 2.0741845074520318

Epoch: 5| Step: 6
Training loss: 1.4182913303375244
Validation loss: 2.0508688188368276

Epoch: 5| Step: 7
Training loss: 1.4726988077163696
Validation loss: 2.072903465199214

Epoch: 5| Step: 8
Training loss: 2.1269521713256836
Validation loss: 2.0653708570746967

Epoch: 5| Step: 9
Training loss: 1.7694566249847412
Validation loss: 2.055208049794679

Epoch: 5| Step: 10
Training loss: 1.4017695188522339
Validation loss: 2.06885419096998

Epoch: 325| Step: 0
Training loss: 2.268009662628174
Validation loss: 2.043980963768498

Epoch: 5| Step: 1
Training loss: 1.545989751815796
Validation loss: 2.035068517090172

Epoch: 5| Step: 2
Training loss: 1.565048098564148
Validation loss: 2.0231302733062417

Epoch: 5| Step: 3
Training loss: 2.003523349761963
Validation loss: 2.031138732869138

Epoch: 5| Step: 4
Training loss: 1.785923957824707
Validation loss: 2.0198895085242485

Epoch: 5| Step: 5
Training loss: 1.8986698389053345
Validation loss: 2.0261843063498057

Epoch: 5| Step: 6
Training loss: 1.22500479221344
Validation loss: 2.045436510475733

Epoch: 5| Step: 7
Training loss: 2.177492141723633
Validation loss: 2.0795327950549383

Epoch: 5| Step: 8
Training loss: 1.3961730003356934
Validation loss: 2.053495330195273

Epoch: 5| Step: 9
Training loss: 1.249380350112915
Validation loss: 2.075080415253998

Epoch: 5| Step: 10
Training loss: 1.5663392543792725
Validation loss: 2.0626301726987286

Epoch: 326| Step: 0
Training loss: 1.9971469640731812
Validation loss: 2.0425564601857173

Epoch: 5| Step: 1
Training loss: 2.2441067695617676
Validation loss: 2.0368746634452575

Epoch: 5| Step: 2
Training loss: 2.219160318374634
Validation loss: 2.0312336721727924

Epoch: 5| Step: 3
Training loss: 1.3879001140594482
Validation loss: 2.036610890460271

Epoch: 5| Step: 4
Training loss: 1.693686842918396
Validation loss: 2.0416514591504167

Epoch: 5| Step: 5
Training loss: 1.6511863470077515
Validation loss: 2.052154533324703

Epoch: 5| Step: 6
Training loss: 0.9884147644042969
Validation loss: 2.0447150789281374

Epoch: 5| Step: 7
Training loss: 1.6274741888046265
Validation loss: 2.058688735449186

Epoch: 5| Step: 8
Training loss: 1.8947999477386475
Validation loss: 2.0808178788872174

Epoch: 5| Step: 9
Training loss: 1.4659734964370728
Validation loss: 2.083054757887317

Epoch: 5| Step: 10
Training loss: 1.4949909448623657
Validation loss: 2.0791963736216226

Epoch: 327| Step: 0
Training loss: 1.2077982425689697
Validation loss: 2.0538391400409

Epoch: 5| Step: 1
Training loss: 1.3813037872314453
Validation loss: 2.0596831242243447

Epoch: 5| Step: 2
Training loss: 1.7443946599960327
Validation loss: 2.0509766045437066

Epoch: 5| Step: 3
Training loss: 1.360133171081543
Validation loss: 2.0350593905295096

Epoch: 5| Step: 4
Training loss: 2.12900972366333
Validation loss: 2.0295431716467744

Epoch: 5| Step: 5
Training loss: 1.6801044940948486
Validation loss: 2.0257150357769382

Epoch: 5| Step: 6
Training loss: 1.805514931678772
Validation loss: 2.0546584052424275

Epoch: 5| Step: 7
Training loss: 2.2453207969665527
Validation loss: 2.054214444211734

Epoch: 5| Step: 8
Training loss: 1.5536096096038818
Validation loss: 2.080677622108049

Epoch: 5| Step: 9
Training loss: 1.8438405990600586
Validation loss: 2.099729323899874

Epoch: 5| Step: 10
Training loss: 1.9498248100280762
Validation loss: 2.064423390614089

Epoch: 328| Step: 0
Training loss: 1.6555293798446655
Validation loss: 2.0453733077613254

Epoch: 5| Step: 1
Training loss: 1.5682673454284668
Validation loss: 2.0220128374715007

Epoch: 5| Step: 2
Training loss: 1.551743507385254
Validation loss: 2.0119786172784786

Epoch: 5| Step: 3
Training loss: 1.2839542627334595
Validation loss: 2.032446260093361

Epoch: 5| Step: 4
Training loss: 2.1251444816589355
Validation loss: 2.017418292260939

Epoch: 5| Step: 5
Training loss: 1.8738912343978882
Validation loss: 2.0097793507319626

Epoch: 5| Step: 6
Training loss: 1.3884738683700562
Validation loss: 2.0048715593994304

Epoch: 5| Step: 7
Training loss: 2.057415008544922
Validation loss: 1.995015795512866

Epoch: 5| Step: 8
Training loss: 1.3680626153945923
Validation loss: 2.0197971277339484

Epoch: 5| Step: 9
Training loss: 1.8844869136810303
Validation loss: 2.0267537050349738

Epoch: 5| Step: 10
Training loss: 2.033007860183716
Validation loss: 2.060673870066161

Epoch: 329| Step: 0
Training loss: 2.3152503967285156
Validation loss: 2.045016115711581

Epoch: 5| Step: 1
Training loss: 1.4158656597137451
Validation loss: 2.046359483913709

Epoch: 5| Step: 2
Training loss: 1.3845105171203613
Validation loss: 2.0567030009403022

Epoch: 5| Step: 3
Training loss: 2.1136085987091064
Validation loss: 2.062517576320197

Epoch: 5| Step: 4
Training loss: 1.4778835773468018
Validation loss: 2.0696243060532438

Epoch: 5| Step: 5
Training loss: 1.4303057193756104
Validation loss: 2.0593539848122546

Epoch: 5| Step: 6
Training loss: 1.3974188566207886
Validation loss: 2.0330434742794243

Epoch: 5| Step: 7
Training loss: 1.5240141153335571
Validation loss: 2.026227548558225

Epoch: 5| Step: 8
Training loss: 1.6693241596221924
Validation loss: 2.0423933203502367

Epoch: 5| Step: 9
Training loss: 2.3688888549804688
Validation loss: 2.033937636242118

Epoch: 5| Step: 10
Training loss: 1.3644697666168213
Validation loss: 2.0365337992227204

Epoch: 330| Step: 0
Training loss: 1.381581425666809
Validation loss: 2.043909595858666

Epoch: 5| Step: 1
Training loss: 1.4948363304138184
Validation loss: 2.0547823265034664

Epoch: 5| Step: 2
Training loss: 1.5445902347564697
Validation loss: 2.0730047533589024

Epoch: 5| Step: 3
Training loss: 1.4143848419189453
Validation loss: 2.072104905241279

Epoch: 5| Step: 4
Training loss: 1.1202622652053833
Validation loss: 2.0813220213818293

Epoch: 5| Step: 5
Training loss: 1.886732816696167
Validation loss: 2.075679220179076

Epoch: 5| Step: 6
Training loss: 2.6881511211395264
Validation loss: 2.0843078564572077

Epoch: 5| Step: 7
Training loss: 1.7535364627838135
Validation loss: 2.0584186584718767

Epoch: 5| Step: 8
Training loss: 1.956502914428711
Validation loss: 2.0594149917684574

Epoch: 5| Step: 9
Training loss: 1.8008956909179688
Validation loss: 2.0523988328954226

Epoch: 5| Step: 10
Training loss: 1.5783089399337769
Validation loss: 2.0362961894722393

Epoch: 331| Step: 0
Training loss: 1.7189079523086548
Validation loss: 2.0456569604976202

Epoch: 5| Step: 1
Training loss: 1.9471412897109985
Validation loss: 2.0594666350272393

Epoch: 5| Step: 2
Training loss: 1.4004123210906982
Validation loss: 2.0581160001857306

Epoch: 5| Step: 3
Training loss: 1.5007903575897217
Validation loss: 2.0474331917301303

Epoch: 5| Step: 4
Training loss: 1.302654504776001
Validation loss: 2.060178195276568

Epoch: 5| Step: 5
Training loss: 1.5893760919570923
Validation loss: 2.061229044391263

Epoch: 5| Step: 6
Training loss: 1.8844398260116577
Validation loss: 2.045736530775665

Epoch: 5| Step: 7
Training loss: 1.472216248512268
Validation loss: 2.0527916210953907

Epoch: 5| Step: 8
Training loss: 2.075770854949951
Validation loss: 2.047338156289952

Epoch: 5| Step: 9
Training loss: 1.8148319721221924
Validation loss: 2.0386096969727547

Epoch: 5| Step: 10
Training loss: 1.7406538724899292
Validation loss: 2.0255284194023377

Epoch: 332| Step: 0
Training loss: 2.0791256427764893
Validation loss: 2.027978839412812

Epoch: 5| Step: 1
Training loss: 1.5271133184432983
Validation loss: 2.038467714863439

Epoch: 5| Step: 2
Training loss: 1.4039976596832275
Validation loss: 2.0461716728825725

Epoch: 5| Step: 3
Training loss: 2.554464101791382
Validation loss: 2.0455049417352162

Epoch: 5| Step: 4
Training loss: 2.2280728816986084
Validation loss: 2.0435720925690024

Epoch: 5| Step: 5
Training loss: 1.7831497192382812
Validation loss: 2.024506817581833

Epoch: 5| Step: 6
Training loss: 1.358303189277649
Validation loss: 2.0336853868217877

Epoch: 5| Step: 7
Training loss: 1.980797529220581
Validation loss: 2.035095763462846

Epoch: 5| Step: 8
Training loss: 1.2260215282440186
Validation loss: 2.0468368761001097

Epoch: 5| Step: 9
Training loss: 1.447888970375061
Validation loss: 2.035983980342906

Epoch: 5| Step: 10
Training loss: 0.719253659248352
Validation loss: 2.036203320308398

Epoch: 333| Step: 0
Training loss: 1.9184837341308594
Validation loss: 2.0501750028261574

Epoch: 5| Step: 1
Training loss: 1.192734956741333
Validation loss: 2.040160668793545

Epoch: 5| Step: 2
Training loss: 1.2695467472076416
Validation loss: 2.036521024601434

Epoch: 5| Step: 3
Training loss: 2.241886854171753
Validation loss: 2.016483877294807

Epoch: 5| Step: 4
Training loss: 1.9943199157714844
Validation loss: 2.0365787270248576

Epoch: 5| Step: 5
Training loss: 1.4846081733703613
Validation loss: 2.047272910353958

Epoch: 5| Step: 6
Training loss: 2.0714452266693115
Validation loss: 2.0536352075556272

Epoch: 5| Step: 7
Training loss: 1.627610445022583
Validation loss: 2.049219874925511

Epoch: 5| Step: 8
Training loss: 1.9506568908691406
Validation loss: 2.0457667612260386

Epoch: 5| Step: 9
Training loss: 1.4711381196975708
Validation loss: 2.0405067448974936

Epoch: 5| Step: 10
Training loss: 1.0280983448028564
Validation loss: 2.057016896945174

Epoch: 334| Step: 0
Training loss: 2.118086338043213
Validation loss: 2.084444958676574

Epoch: 5| Step: 1
Training loss: 1.4299042224884033
Validation loss: 2.0811141383263374

Epoch: 5| Step: 2
Training loss: 2.2664973735809326
Validation loss: 2.104261912325377

Epoch: 5| Step: 3
Training loss: 1.7961362600326538
Validation loss: 2.0962180617035076

Epoch: 5| Step: 4
Training loss: 1.4649510383605957
Validation loss: 2.0983085734869844

Epoch: 5| Step: 5
Training loss: 1.1386120319366455
Validation loss: 2.0892547458730717

Epoch: 5| Step: 6
Training loss: 1.539512038230896
Validation loss: 2.093374011337116

Epoch: 5| Step: 7
Training loss: 2.121704578399658
Validation loss: 2.063955610798251

Epoch: 5| Step: 8
Training loss: 1.2123159170150757
Validation loss: 2.0516550515287664

Epoch: 5| Step: 9
Training loss: 1.8670850992202759
Validation loss: 2.0029720926797516

Epoch: 5| Step: 10
Training loss: 1.4102345705032349
Validation loss: 1.9773039689628027

Epoch: 335| Step: 0
Training loss: 1.3519748449325562
Validation loss: 1.9791804462350824

Epoch: 5| Step: 1
Training loss: 1.5291489362716675
Validation loss: 1.996702290350391

Epoch: 5| Step: 2
Training loss: 1.827111005783081
Validation loss: 2.019573111687937

Epoch: 5| Step: 3
Training loss: 1.8355735540390015
Validation loss: 2.0044038244473037

Epoch: 5| Step: 4
Training loss: 1.0980656147003174
Validation loss: 2.043506846633009

Epoch: 5| Step: 5
Training loss: 1.9688501358032227
Validation loss: 2.077346417211717

Epoch: 5| Step: 6
Training loss: 1.898169755935669
Validation loss: 2.0851924291221042

Epoch: 5| Step: 7
Training loss: 1.7394468784332275
Validation loss: 2.0595899089690177

Epoch: 5| Step: 8
Training loss: 2.1442959308624268
Validation loss: 2.0644985745030064

Epoch: 5| Step: 9
Training loss: 1.718305230140686
Validation loss: 2.0568679122514624

Epoch: 5| Step: 10
Training loss: 1.0633853673934937
Validation loss: 2.049017595988448

Epoch: 336| Step: 0
Training loss: 1.6748170852661133
Validation loss: 2.0584313856658114

Epoch: 5| Step: 1
Training loss: 0.9890074729919434
Validation loss: 2.0528085462508665

Epoch: 5| Step: 2
Training loss: 1.536102533340454
Validation loss: 2.077266726442563

Epoch: 5| Step: 3
Training loss: 1.7577546834945679
Validation loss: 2.1182063253976966

Epoch: 5| Step: 4
Training loss: 2.0281691551208496
Validation loss: 2.1359656600541967

Epoch: 5| Step: 5
Training loss: 1.794507384300232
Validation loss: 2.138924580748363

Epoch: 5| Step: 6
Training loss: 2.2324230670928955
Validation loss: 2.131229144270702

Epoch: 5| Step: 7
Training loss: 2.1030280590057373
Validation loss: 2.1237992061081754

Epoch: 5| Step: 8
Training loss: 1.494655728340149
Validation loss: 2.1029309470166444

Epoch: 5| Step: 9
Training loss: 1.3330049514770508
Validation loss: 2.078011453792613

Epoch: 5| Step: 10
Training loss: 1.3232691287994385
Validation loss: 2.0566746752749205

Epoch: 337| Step: 0
Training loss: 2.281506299972534
Validation loss: 2.0264678309040685

Epoch: 5| Step: 1
Training loss: 1.5942456722259521
Validation loss: 2.004253464360391

Epoch: 5| Step: 2
Training loss: 1.3152449131011963
Validation loss: 2.012685351474311

Epoch: 5| Step: 3
Training loss: 1.4617063999176025
Validation loss: 1.9951051640254196

Epoch: 5| Step: 4
Training loss: 1.5152758359909058
Validation loss: 1.984076020538166

Epoch: 5| Step: 5
Training loss: 1.9533315896987915
Validation loss: 1.9776701722093808

Epoch: 5| Step: 6
Training loss: 1.6485977172851562
Validation loss: 1.9917155952863796

Epoch: 5| Step: 7
Training loss: 1.6511058807373047
Validation loss: 2.0085790041954286

Epoch: 5| Step: 8
Training loss: 1.789646863937378
Validation loss: 2.0278179542992705

Epoch: 5| Step: 9
Training loss: 1.4821888208389282
Validation loss: 2.0526440630676928

Epoch: 5| Step: 10
Training loss: 1.2898658514022827
Validation loss: 2.1069151188737605

Epoch: 338| Step: 0
Training loss: 1.6566470861434937
Validation loss: 2.1285482580943773

Epoch: 5| Step: 1
Training loss: 1.4644935131072998
Validation loss: 2.1158326223332393

Epoch: 5| Step: 2
Training loss: 1.4564318656921387
Validation loss: 2.0900849180836834

Epoch: 5| Step: 3
Training loss: 1.5143067836761475
Validation loss: 2.104941145066292

Epoch: 5| Step: 4
Training loss: 1.520627498626709
Validation loss: 2.086859113426619

Epoch: 5| Step: 5
Training loss: 1.9003509283065796
Validation loss: 2.0882933857620403

Epoch: 5| Step: 6
Training loss: 1.249856948852539
Validation loss: 2.0925581070684616

Epoch: 5| Step: 7
Training loss: 1.8421634435653687
Validation loss: 2.1057970357197586

Epoch: 5| Step: 8
Training loss: 1.812170386314392
Validation loss: 2.0922743274319555

Epoch: 5| Step: 9
Training loss: 1.8497612476348877
Validation loss: 2.073127788882102

Epoch: 5| Step: 10
Training loss: 1.828891634941101
Validation loss: 2.05563400894083

Epoch: 339| Step: 0
Training loss: 0.8576967120170593
Validation loss: 2.048549626463203

Epoch: 5| Step: 1
Training loss: 2.1392130851745605
Validation loss: 2.042239499348466

Epoch: 5| Step: 2
Training loss: 1.6204922199249268
Validation loss: 2.0251996594090618

Epoch: 5| Step: 3
Training loss: 1.2375954389572144
Validation loss: 2.028165896733602

Epoch: 5| Step: 4
Training loss: 1.5353891849517822
Validation loss: 2.0098254296087448

Epoch: 5| Step: 5
Training loss: 2.07474422454834
Validation loss: 2.006922411662276

Epoch: 5| Step: 6
Training loss: 1.8704017400741577
Validation loss: 1.9955321204277776

Epoch: 5| Step: 7
Training loss: 1.7222681045532227
Validation loss: 1.9815695824161652

Epoch: 5| Step: 8
Training loss: 1.825481653213501
Validation loss: 1.9876143906706123

Epoch: 5| Step: 9
Training loss: 2.042132616043091
Validation loss: 1.996732884837735

Epoch: 5| Step: 10
Training loss: 1.0401499271392822
Validation loss: 1.9954750204599032

Epoch: 340| Step: 0
Training loss: 1.5056030750274658
Validation loss: 2.006359064450828

Epoch: 5| Step: 1
Training loss: 2.14345121383667
Validation loss: 2.0258029507052515

Epoch: 5| Step: 2
Training loss: 1.5401253700256348
Validation loss: 2.0574778126132105

Epoch: 5| Step: 3
Training loss: 1.6398054361343384
Validation loss: 2.0543985546276136

Epoch: 5| Step: 4
Training loss: 1.0831936597824097
Validation loss: 2.0523677910527875

Epoch: 5| Step: 5
Training loss: 1.7829490900039673
Validation loss: 2.0764380706253873

Epoch: 5| Step: 6
Training loss: 1.805376410484314
Validation loss: 2.0488548560809066

Epoch: 5| Step: 7
Training loss: 1.3299648761749268
Validation loss: 2.0413714583202074

Epoch: 5| Step: 8
Training loss: 1.630552053451538
Validation loss: 2.0318931815444783

Epoch: 5| Step: 9
Training loss: 1.6371409893035889
Validation loss: 2.0204401503327074

Epoch: 5| Step: 10
Training loss: 1.889225721359253
Validation loss: 2.013046333866735

Epoch: 341| Step: 0
Training loss: 1.7482521533966064
Validation loss: 2.0104553122674265

Epoch: 5| Step: 1
Training loss: 1.5460275411605835
Validation loss: 1.9911415782026065

Epoch: 5| Step: 2
Training loss: 1.9535118341445923
Validation loss: 1.9916606667221233

Epoch: 5| Step: 3
Training loss: 1.496062994003296
Validation loss: 1.9950510378806823

Epoch: 5| Step: 4
Training loss: 1.7963756322860718
Validation loss: 2.029418315938724

Epoch: 5| Step: 5
Training loss: 1.3961824178695679
Validation loss: 2.0424203923953477

Epoch: 5| Step: 6
Training loss: 1.471917748451233
Validation loss: 2.065232103870761

Epoch: 5| Step: 7
Training loss: 1.5272204875946045
Validation loss: 2.0703533554589875

Epoch: 5| Step: 8
Training loss: 1.9055808782577515
Validation loss: 2.0458729523484425

Epoch: 5| Step: 9
Training loss: 2.065852165222168
Validation loss: 2.0487417585106305

Epoch: 5| Step: 10
Training loss: 1.0319769382476807
Validation loss: 2.046895888543898

Epoch: 342| Step: 0
Training loss: 1.9193814992904663
Validation loss: 2.0428924804092734

Epoch: 5| Step: 1
Training loss: 2.2243776321411133
Validation loss: 2.0401953240876556

Epoch: 5| Step: 2
Training loss: 0.9772677421569824
Validation loss: 2.0254893046553417

Epoch: 5| Step: 3
Training loss: 1.3529878854751587
Validation loss: 2.0142822765534922

Epoch: 5| Step: 4
Training loss: 2.1252431869506836
Validation loss: 2.0291887816562446

Epoch: 5| Step: 5
Training loss: 2.1323790550231934
Validation loss: 2.0716629925594536

Epoch: 5| Step: 6
Training loss: 0.817774772644043
Validation loss: 2.0765619124135664

Epoch: 5| Step: 7
Training loss: 1.8388763666152954
Validation loss: 2.0635584208273117

Epoch: 5| Step: 8
Training loss: 1.1516263484954834
Validation loss: 2.04706605275472

Epoch: 5| Step: 9
Training loss: 1.8177810907363892
Validation loss: 2.0549181379297727

Epoch: 5| Step: 10
Training loss: 1.492424488067627
Validation loss: 2.035898911055698

Epoch: 343| Step: 0
Training loss: 1.7533819675445557
Validation loss: 2.023329684811254

Epoch: 5| Step: 1
Training loss: 1.7872298955917358
Validation loss: 2.0391327937444053

Epoch: 5| Step: 2
Training loss: 1.9324815273284912
Validation loss: 2.0492413223430677

Epoch: 5| Step: 3
Training loss: 1.7720394134521484
Validation loss: 2.048868607449275

Epoch: 5| Step: 4
Training loss: 1.5592410564422607
Validation loss: 2.061776763649397

Epoch: 5| Step: 5
Training loss: 1.606713891029358
Validation loss: 2.0713484658989856

Epoch: 5| Step: 6
Training loss: 1.4000146389007568
Validation loss: 2.0699228637961933

Epoch: 5| Step: 7
Training loss: 1.6199901103973389
Validation loss: 2.0752448728007655

Epoch: 5| Step: 8
Training loss: 1.7060352563858032
Validation loss: 2.043944192189042

Epoch: 5| Step: 9
Training loss: 1.350907325744629
Validation loss: 2.030440389469106

Epoch: 5| Step: 10
Training loss: 1.0027598142623901
Validation loss: 2.0083398818969727

Epoch: 344| Step: 0
Training loss: 1.4879257678985596
Validation loss: 1.9868183610259846

Epoch: 5| Step: 1
Training loss: 1.2756668329238892
Validation loss: 2.0081493264885357

Epoch: 5| Step: 2
Training loss: 1.1212952136993408
Validation loss: 2.0118101514795774

Epoch: 5| Step: 3
Training loss: 1.5151933431625366
Validation loss: 2.0069917094322944

Epoch: 5| Step: 4
Training loss: 1.1563751697540283
Validation loss: 2.014093416993336

Epoch: 5| Step: 5
Training loss: 1.8193668127059937
Validation loss: 2.0615344483365297

Epoch: 5| Step: 6
Training loss: 2.1722702980041504
Validation loss: 2.0559682410250426

Epoch: 5| Step: 7
Training loss: 1.3520057201385498
Validation loss: 2.0507500915117163

Epoch: 5| Step: 8
Training loss: 2.047335624694824
Validation loss: 2.02819315848812

Epoch: 5| Step: 9
Training loss: 1.5603704452514648
Validation loss: 2.027976820545812

Epoch: 5| Step: 10
Training loss: 2.234528064727783
Validation loss: 2.0052549185291415

Epoch: 345| Step: 0
Training loss: 1.4228103160858154
Validation loss: 2.0093223894796064

Epoch: 5| Step: 1
Training loss: 2.012047052383423
Validation loss: 2.035731533522247

Epoch: 5| Step: 2
Training loss: 1.6937395334243774
Validation loss: 2.0251285670905985

Epoch: 5| Step: 3
Training loss: 1.6592929363250732
Validation loss: 2.0220369523571384

Epoch: 5| Step: 4
Training loss: 2.0152721405029297
Validation loss: 2.0090852693844865

Epoch: 5| Step: 5
Training loss: 1.7198225259780884
Validation loss: 2.0185783781031126

Epoch: 5| Step: 6
Training loss: 1.475120186805725
Validation loss: 2.02735657845774

Epoch: 5| Step: 7
Training loss: 1.171668529510498
Validation loss: 2.0270957703231485

Epoch: 5| Step: 8
Training loss: 1.5553237199783325
Validation loss: 2.0430545576157106

Epoch: 5| Step: 9
Training loss: 1.5382554531097412
Validation loss: 2.0452650964901014

Epoch: 5| Step: 10
Training loss: 1.543602466583252
Validation loss: 2.042582586247434

Epoch: 346| Step: 0
Training loss: 2.1557095050811768
Validation loss: 2.018396476263641

Epoch: 5| Step: 1
Training loss: 1.1549135446548462
Validation loss: 2.0292348489966443

Epoch: 5| Step: 2
Training loss: 1.5620858669281006
Validation loss: 2.0383250251893075

Epoch: 5| Step: 3
Training loss: 1.6346023082733154
Validation loss: 2.0282753949524253

Epoch: 5| Step: 4
Training loss: 1.3096163272857666
Validation loss: 2.0391477448965913

Epoch: 5| Step: 5
Training loss: 1.6630109548568726
Validation loss: 2.043090784421531

Epoch: 5| Step: 6
Training loss: 1.8837127685546875
Validation loss: 2.058308142487721

Epoch: 5| Step: 7
Training loss: 1.1825932264328003
Validation loss: 2.037865984824396

Epoch: 5| Step: 8
Training loss: 1.8527320623397827
Validation loss: 2.051017612539312

Epoch: 5| Step: 9
Training loss: 1.3788368701934814
Validation loss: 2.021411044623262

Epoch: 5| Step: 10
Training loss: 1.8634288311004639
Validation loss: 2.0297618604475454

Epoch: 347| Step: 0
Training loss: 1.9854809045791626
Validation loss: 2.0463671427901073

Epoch: 5| Step: 1
Training loss: 1.9006332159042358
Validation loss: 2.025280785816972

Epoch: 5| Step: 2
Training loss: 2.3904037475585938
Validation loss: 2.0126946126261065

Epoch: 5| Step: 3
Training loss: 2.0474777221679688
Validation loss: 1.997152110581757

Epoch: 5| Step: 4
Training loss: 1.0346362590789795
Validation loss: 1.9777266056306901

Epoch: 5| Step: 5
Training loss: 1.132843017578125
Validation loss: 1.9861863300364504

Epoch: 5| Step: 6
Training loss: 1.7423264980316162
Validation loss: 1.9791928593830397

Epoch: 5| Step: 7
Training loss: 1.382368803024292
Validation loss: 1.9899806386681014

Epoch: 5| Step: 8
Training loss: 1.0162644386291504
Validation loss: 2.017926485307755

Epoch: 5| Step: 9
Training loss: 1.521624207496643
Validation loss: 2.0410014032035746

Epoch: 5| Step: 10
Training loss: 1.1596908569335938
Validation loss: 2.069723803509948

Epoch: 348| Step: 0
Training loss: 2.1227917671203613
Validation loss: 2.076028959725493

Epoch: 5| Step: 1
Training loss: 1.7251688241958618
Validation loss: 2.083381261876834

Epoch: 5| Step: 2
Training loss: 1.4981788396835327
Validation loss: 2.0608375867207847

Epoch: 5| Step: 3
Training loss: 1.3469464778900146
Validation loss: 2.057279250955069

Epoch: 5| Step: 4
Training loss: 1.3649141788482666
Validation loss: 2.0460619080451226

Epoch: 5| Step: 5
Training loss: 1.7661077976226807
Validation loss: 2.0524170911440285

Epoch: 5| Step: 6
Training loss: 0.9530364871025085
Validation loss: 2.0401432796191146

Epoch: 5| Step: 7
Training loss: 2.48238468170166
Validation loss: 2.0364335096010597

Epoch: 5| Step: 8
Training loss: 1.400617003440857
Validation loss: 2.0497144627314743

Epoch: 5| Step: 9
Training loss: 1.3838151693344116
Validation loss: 2.0327765954438077

Epoch: 5| Step: 10
Training loss: 1.1728845834732056
Validation loss: 2.0430316758412186

Epoch: 349| Step: 0
Training loss: 1.9364922046661377
Validation loss: 2.0271700120741323

Epoch: 5| Step: 1
Training loss: 1.3422369956970215
Validation loss: 2.011126275985472

Epoch: 5| Step: 2
Training loss: 1.3032057285308838
Validation loss: 1.9871563296164236

Epoch: 5| Step: 3
Training loss: 1.401771903038025
Validation loss: 1.9963060771265337

Epoch: 5| Step: 4
Training loss: 2.2827138900756836
Validation loss: 2.0111593507951304

Epoch: 5| Step: 5
Training loss: 1.6336262226104736
Validation loss: 2.024381040244974

Epoch: 5| Step: 6
Training loss: 0.8516373634338379
Validation loss: 2.020901367228518

Epoch: 5| Step: 7
Training loss: 1.9887268543243408
Validation loss: 2.036413497822259

Epoch: 5| Step: 8
Training loss: 1.4372508525848389
Validation loss: 2.029439221146286

Epoch: 5| Step: 9
Training loss: 1.4188767671585083
Validation loss: 2.035414083029634

Epoch: 5| Step: 10
Training loss: 1.6685196161270142
Validation loss: 2.0132966054383146

Epoch: 350| Step: 0
Training loss: 1.9390900135040283
Validation loss: 2.0327345889101744

Epoch: 5| Step: 1
Training loss: 1.528583288192749
Validation loss: 2.0412013658913235

Epoch: 5| Step: 2
Training loss: 1.7042770385742188
Validation loss: 2.0470994890377088

Epoch: 5| Step: 3
Training loss: 1.4422438144683838
Validation loss: 2.0395472639350483

Epoch: 5| Step: 4
Training loss: 1.128067135810852
Validation loss: 2.0649867262891544

Epoch: 5| Step: 5
Training loss: 1.5545079708099365
Validation loss: 2.0659656204203123

Epoch: 5| Step: 6
Training loss: 1.5965440273284912
Validation loss: 2.0658918696065105

Epoch: 5| Step: 7
Training loss: 1.9098440408706665
Validation loss: 2.048804934306811

Epoch: 5| Step: 8
Training loss: 1.4902307987213135
Validation loss: 2.023946290375084

Epoch: 5| Step: 9
Training loss: 1.6066621541976929
Validation loss: 2.0007173643317273

Epoch: 5| Step: 10
Training loss: 1.2124271392822266
Validation loss: 2.0026972165671726

Epoch: 351| Step: 0
Training loss: 1.1503475904464722
Validation loss: 1.9682409942791026

Epoch: 5| Step: 1
Training loss: 1.2871493101119995
Validation loss: 1.9858661441392795

Epoch: 5| Step: 2
Training loss: 2.269920587539673
Validation loss: 1.986797965982909

Epoch: 5| Step: 3
Training loss: 1.8151473999023438
Validation loss: 1.9904247253171858

Epoch: 5| Step: 4
Training loss: 2.007854700088501
Validation loss: 2.015658192737128

Epoch: 5| Step: 5
Training loss: 1.3004146814346313
Validation loss: 2.041821341360769

Epoch: 5| Step: 6
Training loss: 1.4943163394927979
Validation loss: 2.0476251981591664

Epoch: 5| Step: 7
Training loss: 1.6307754516601562
Validation loss: 2.013191925582065

Epoch: 5| Step: 8
Training loss: 1.6957886219024658
Validation loss: 2.0177025987255957

Epoch: 5| Step: 9
Training loss: 1.0572715997695923
Validation loss: 2.015103429876348

Epoch: 5| Step: 10
Training loss: 1.6258676052093506
Validation loss: 2.0170450556662773

Epoch: 352| Step: 0
Training loss: 1.6162281036376953
Validation loss: 2.0219246520791003

Epoch: 5| Step: 1
Training loss: 1.5651319026947021
Validation loss: 2.0236575923940188

Epoch: 5| Step: 2
Training loss: 1.6520698070526123
Validation loss: 2.0329246482541485

Epoch: 5| Step: 3
Training loss: 1.6710805892944336
Validation loss: 2.0349658458463606

Epoch: 5| Step: 4
Training loss: 1.2205396890640259
Validation loss: 2.0108432180138043

Epoch: 5| Step: 5
Training loss: 1.7945051193237305
Validation loss: 2.015839022974814

Epoch: 5| Step: 6
Training loss: 1.6053040027618408
Validation loss: 1.9970935583114624

Epoch: 5| Step: 7
Training loss: 1.4892524480819702
Validation loss: 2.00585497835631

Epoch: 5| Step: 8
Training loss: 1.497635841369629
Validation loss: 2.0045691767046527

Epoch: 5| Step: 9
Training loss: 1.5131555795669556
Validation loss: 1.9953072032620829

Epoch: 5| Step: 10
Training loss: 1.6705812215805054
Validation loss: 1.9857615899014216

Epoch: 353| Step: 0
Training loss: 1.7129093408584595
Validation loss: 1.993895415336855

Epoch: 5| Step: 1
Training loss: 1.3566710948944092
Validation loss: 1.9824199189421952

Epoch: 5| Step: 2
Training loss: 1.4366018772125244
Validation loss: 1.9940224950031569

Epoch: 5| Step: 3
Training loss: 1.9974193572998047
Validation loss: 1.9907782769972278

Epoch: 5| Step: 4
Training loss: 1.972651481628418
Validation loss: 1.9786113782595562

Epoch: 5| Step: 5
Training loss: 1.470556616783142
Validation loss: 2.0159433452031945

Epoch: 5| Step: 6
Training loss: 1.298986792564392
Validation loss: 2.0156257229466594

Epoch: 5| Step: 7
Training loss: 1.2194879055023193
Validation loss: 2.051737703302855

Epoch: 5| Step: 8
Training loss: 1.013500452041626
Validation loss: 2.066502526242246

Epoch: 5| Step: 9
Training loss: 1.8870779275894165
Validation loss: 2.0579972933697444

Epoch: 5| Step: 10
Training loss: 1.7116236686706543
Validation loss: 2.069732666015625

Epoch: 354| Step: 0
Training loss: 1.603841781616211
Validation loss: 2.0533252826301

Epoch: 5| Step: 1
Training loss: 1.1104997396469116
Validation loss: 2.0287627814918436

Epoch: 5| Step: 2
Training loss: 1.414610743522644
Validation loss: 2.019656149289941

Epoch: 5| Step: 3
Training loss: 1.7368005514144897
Validation loss: 2.038625801763227

Epoch: 5| Step: 4
Training loss: 1.35683012008667
Validation loss: 2.0225103606459913

Epoch: 5| Step: 5
Training loss: 1.3549325466156006
Validation loss: 2.023988463545358

Epoch: 5| Step: 6
Training loss: 1.3008801937103271
Validation loss: 2.0192705841474634

Epoch: 5| Step: 7
Training loss: 1.442155361175537
Validation loss: 2.045546726513934

Epoch: 5| Step: 8
Training loss: 2.4703476428985596
Validation loss: 2.061640975295856

Epoch: 5| Step: 9
Training loss: 1.965763807296753
Validation loss: 2.059501192903006

Epoch: 5| Step: 10
Training loss: 1.3663250207901
Validation loss: 2.041955660748225

Epoch: 355| Step: 0
Training loss: 1.738762617111206
Validation loss: 2.0347952970894436

Epoch: 5| Step: 1
Training loss: 1.2114263772964478
Validation loss: 2.0258453866486907

Epoch: 5| Step: 2
Training loss: 1.45680832862854
Validation loss: 2.0140058955838605

Epoch: 5| Step: 3
Training loss: 1.65590500831604
Validation loss: 2.018279255077403

Epoch: 5| Step: 4
Training loss: 1.3934943675994873
Validation loss: 2.010185462172313

Epoch: 5| Step: 5
Training loss: 1.255102276802063
Validation loss: 2.036330633265998

Epoch: 5| Step: 6
Training loss: 1.4800522327423096
Validation loss: 2.0606456495100454

Epoch: 5| Step: 7
Training loss: 1.0288331508636475
Validation loss: 2.0645548297512915

Epoch: 5| Step: 8
Training loss: 1.5734087228775024
Validation loss: 2.0643853679780038

Epoch: 5| Step: 9
Training loss: 2.1623220443725586
Validation loss: 2.07264179952683

Epoch: 5| Step: 10
Training loss: 1.919459342956543
Validation loss: 2.0711796924632084

Epoch: 356| Step: 0
Training loss: 1.497201681137085
Validation loss: 2.0340376259178243

Epoch: 5| Step: 1
Training loss: 1.6272186040878296
Validation loss: 2.04565683744287

Epoch: 5| Step: 2
Training loss: 1.128734827041626
Validation loss: 2.050796913844283

Epoch: 5| Step: 3
Training loss: 1.8610255718231201
Validation loss: 2.063375664013688

Epoch: 5| Step: 4
Training loss: 1.848398208618164
Validation loss: 2.0553002985574866

Epoch: 5| Step: 5
Training loss: 1.676146149635315
Validation loss: 2.0625999537847375

Epoch: 5| Step: 6
Training loss: 1.0517220497131348
Validation loss: 2.065630538489229

Epoch: 5| Step: 7
Training loss: 1.6060549020767212
Validation loss: 2.0565310780720045

Epoch: 5| Step: 8
Training loss: 1.3294365406036377
Validation loss: 2.028012660241896

Epoch: 5| Step: 9
Training loss: 1.9469972848892212
Validation loss: 2.0401062465483144

Epoch: 5| Step: 10
Training loss: 1.2420984506607056
Validation loss: 2.0114440046330935

Epoch: 357| Step: 0
Training loss: 1.845452070236206
Validation loss: 1.9946812570735972

Epoch: 5| Step: 1
Training loss: 1.7556827068328857
Validation loss: 1.9839059242638208

Epoch: 5| Step: 2
Training loss: 1.3634154796600342
Validation loss: 1.9821093864338373

Epoch: 5| Step: 3
Training loss: 0.7607372999191284
Validation loss: 1.9919853518086095

Epoch: 5| Step: 4
Training loss: 1.3927440643310547
Validation loss: 1.988959039411237

Epoch: 5| Step: 5
Training loss: 1.5638481378555298
Validation loss: 2.0203763900264615

Epoch: 5| Step: 6
Training loss: 1.851161241531372
Validation loss: 2.0379553482096684

Epoch: 5| Step: 7
Training loss: 2.24056339263916
Validation loss: 2.0687785558803107

Epoch: 5| Step: 8
Training loss: 1.3304882049560547
Validation loss: 2.0820537818375455

Epoch: 5| Step: 9
Training loss: 1.3804782629013062
Validation loss: 2.10344002708312

Epoch: 5| Step: 10
Training loss: 1.9051237106323242
Validation loss: 2.114517875896987

Epoch: 358| Step: 0
Training loss: 1.9658416509628296
Validation loss: 2.087990555711972

Epoch: 5| Step: 1
Training loss: 1.4737756252288818
Validation loss: 2.0381610342251357

Epoch: 5| Step: 2
Training loss: 1.6486709117889404
Validation loss: 2.0019666302588677

Epoch: 5| Step: 3
Training loss: 1.5033427476882935
Validation loss: 2.005588775040001

Epoch: 5| Step: 4
Training loss: 0.9689935445785522
Validation loss: 1.978516750438239

Epoch: 5| Step: 5
Training loss: 1.5108383893966675
Validation loss: 1.9834291140238445

Epoch: 5| Step: 6
Training loss: 1.660179853439331
Validation loss: 1.9881055649890695

Epoch: 5| Step: 7
Training loss: 1.3871500492095947
Validation loss: 1.9647307306207635

Epoch: 5| Step: 8
Training loss: 1.34788978099823
Validation loss: 1.9677164631505166

Epoch: 5| Step: 9
Training loss: 1.8273082971572876
Validation loss: 1.9872909079315841

Epoch: 5| Step: 10
Training loss: 1.5912796258926392
Validation loss: 2.003641049067179

Epoch: 359| Step: 0
Training loss: 1.6098859310150146
Validation loss: 2.0142546687074887

Epoch: 5| Step: 1
Training loss: 0.9820594787597656
Validation loss: 2.0353227969138854

Epoch: 5| Step: 2
Training loss: 1.3172956705093384
Validation loss: 2.054373969313919

Epoch: 5| Step: 3
Training loss: 1.5863014459609985
Validation loss: 2.049378104107354

Epoch: 5| Step: 4
Training loss: 1.6926145553588867
Validation loss: 2.046715356970346

Epoch: 5| Step: 5
Training loss: 1.8570830821990967
Validation loss: 2.045516957518875

Epoch: 5| Step: 6
Training loss: 1.3141148090362549
Validation loss: 2.0381980249958653

Epoch: 5| Step: 7
Training loss: 1.4317704439163208
Validation loss: 2.026761672830069

Epoch: 5| Step: 8
Training loss: 1.4208219051361084
Validation loss: 2.0325841698595273

Epoch: 5| Step: 9
Training loss: 1.979809045791626
Validation loss: 2.012199371091781

Epoch: 5| Step: 10
Training loss: 1.6189826726913452
Validation loss: 1.9887812393967823

Epoch: 360| Step: 0
Training loss: 1.6756675243377686
Validation loss: 2.002336166238272

Epoch: 5| Step: 1
Training loss: 1.2613986730575562
Validation loss: 2.03808751157535

Epoch: 5| Step: 2
Training loss: 1.3851569890975952
Validation loss: 2.0389747696538127

Epoch: 5| Step: 3
Training loss: 1.4788360595703125
Validation loss: 2.022644700542573

Epoch: 5| Step: 4
Training loss: 1.4228907823562622
Validation loss: 2.055675455318984

Epoch: 5| Step: 5
Training loss: 1.2682173252105713
Validation loss: 2.0832105093104865

Epoch: 5| Step: 6
Training loss: 1.9518375396728516
Validation loss: 2.0618573850201023

Epoch: 5| Step: 7
Training loss: 1.7038028240203857
Validation loss: 2.057508848046744

Epoch: 5| Step: 8
Training loss: 0.8090365529060364
Validation loss: 2.0462846755981445

Epoch: 5| Step: 9
Training loss: 1.6522724628448486
Validation loss: 2.0209587773969098

Epoch: 5| Step: 10
Training loss: 2.0097923278808594
Validation loss: 2.037162083451466

Epoch: 361| Step: 0
Training loss: 0.8324251174926758
Validation loss: 2.046175520907166

Epoch: 5| Step: 1
Training loss: 2.0352180004119873
Validation loss: 2.0309358335310415

Epoch: 5| Step: 2
Training loss: 1.4710267782211304
Validation loss: 2.028148483204585

Epoch: 5| Step: 3
Training loss: 2.005791187286377
Validation loss: 2.0332341245425645

Epoch: 5| Step: 4
Training loss: 1.2239911556243896
Validation loss: 1.9964562833950084

Epoch: 5| Step: 5
Training loss: 1.3415167331695557
Validation loss: 2.0179680906316286

Epoch: 5| Step: 6
Training loss: 1.7164793014526367
Validation loss: 2.006542051992109

Epoch: 5| Step: 7
Training loss: 1.0710861682891846
Validation loss: 2.026271335540279

Epoch: 5| Step: 8
Training loss: 1.9947410821914673
Validation loss: 2.0396169424057007

Epoch: 5| Step: 9
Training loss: 1.304912805557251
Validation loss: 2.0556865187101465

Epoch: 5| Step: 10
Training loss: 1.5460327863693237
Validation loss: 2.053891792092272

Epoch: 362| Step: 0
Training loss: 1.855036735534668
Validation loss: 2.0543684369774273

Epoch: 5| Step: 1
Training loss: 0.8383671045303345
Validation loss: 2.054467790870256

Epoch: 5| Step: 2
Training loss: 1.423137903213501
Validation loss: 2.0550779886143182

Epoch: 5| Step: 3
Training loss: 1.1554665565490723
Validation loss: 2.0559166810845815

Epoch: 5| Step: 4
Training loss: 1.5137863159179688
Validation loss: 2.029013469655027

Epoch: 5| Step: 5
Training loss: 1.972635269165039
Validation loss: 2.0425676940589823

Epoch: 5| Step: 6
Training loss: 1.3484845161437988
Validation loss: 2.02097644857181

Epoch: 5| Step: 7
Training loss: 1.4827849864959717
Validation loss: 2.0028672218322754

Epoch: 5| Step: 8
Training loss: 1.6536859273910522
Validation loss: 1.9953580351286038

Epoch: 5| Step: 9
Training loss: 1.2858567237854004
Validation loss: 1.9991064635656213

Epoch: 5| Step: 10
Training loss: 2.064393997192383
Validation loss: 2.0047857953656103

Epoch: 363| Step: 0
Training loss: 1.684844970703125
Validation loss: 2.0054065232635825

Epoch: 5| Step: 1
Training loss: 0.7350500226020813
Validation loss: 2.014724616081484

Epoch: 5| Step: 2
Training loss: 1.2506825923919678
Validation loss: 2.0314543759951027

Epoch: 5| Step: 3
Training loss: 1.0560375452041626
Validation loss: 2.0407288741039973

Epoch: 5| Step: 4
Training loss: 1.632287621498108
Validation loss: 2.062915422583139

Epoch: 5| Step: 5
Training loss: 1.9635438919067383
Validation loss: 2.0629109169847224

Epoch: 5| Step: 6
Training loss: 1.826612114906311
Validation loss: 2.0703025338470296

Epoch: 5| Step: 7
Training loss: 1.8351964950561523
Validation loss: 2.0553926831932476

Epoch: 5| Step: 8
Training loss: 1.799477219581604
Validation loss: 2.0393840189903014

Epoch: 5| Step: 9
Training loss: 1.2183297872543335
Validation loss: 2.015023204588121

Epoch: 5| Step: 10
Training loss: 1.4782601594924927
Validation loss: 2.0033688724681897

Epoch: 364| Step: 0
Training loss: 1.7285048961639404
Validation loss: 1.999925862076462

Epoch: 5| Step: 1
Training loss: 1.334675908088684
Validation loss: 1.9755531510999125

Epoch: 5| Step: 2
Training loss: 1.0130698680877686
Validation loss: 1.9968890938707577

Epoch: 5| Step: 3
Training loss: 1.4311189651489258
Validation loss: 2.0116042872910858

Epoch: 5| Step: 4
Training loss: 1.462503433227539
Validation loss: 2.0165414284634333

Epoch: 5| Step: 5
Training loss: 1.5434497594833374
Validation loss: 2.044926207552674

Epoch: 5| Step: 6
Training loss: 1.320107102394104
Validation loss: 2.0573721008916057

Epoch: 5| Step: 7
Training loss: 1.3905748128890991
Validation loss: 2.0406600224074496

Epoch: 5| Step: 8
Training loss: 1.8864641189575195
Validation loss: 2.027296368793775

Epoch: 5| Step: 9
Training loss: 1.673227310180664
Validation loss: 2.035560566891906

Epoch: 5| Step: 10
Training loss: 1.5607106685638428
Validation loss: 2.0330683415935886

Epoch: 365| Step: 0
Training loss: 1.3001339435577393
Validation loss: 2.0242475668589273

Epoch: 5| Step: 1
Training loss: 1.7962977886199951
Validation loss: 2.026657663365846

Epoch: 5| Step: 2
Training loss: 0.9481737017631531
Validation loss: 2.0406067730278097

Epoch: 5| Step: 3
Training loss: 1.0769726037979126
Validation loss: 2.0394241297116844

Epoch: 5| Step: 4
Training loss: 1.8357139825820923
Validation loss: 2.034805308106125

Epoch: 5| Step: 5
Training loss: 1.8018451929092407
Validation loss: 2.05761218583712

Epoch: 5| Step: 6
Training loss: 1.6125211715698242
Validation loss: 2.052241740688201

Epoch: 5| Step: 7
Training loss: 1.630764365196228
Validation loss: 2.032672148878856

Epoch: 5| Step: 8
Training loss: 1.6398193836212158
Validation loss: 2.0370809160253054

Epoch: 5| Step: 9
Training loss: 1.189515471458435
Validation loss: 2.0474540418194187

Epoch: 5| Step: 10
Training loss: 1.3938870429992676
Validation loss: 2.052676216248543

Epoch: 366| Step: 0
Training loss: 1.6508620977401733
Validation loss: 2.0631365917062245

Epoch: 5| Step: 1
Training loss: 1.7586612701416016
Validation loss: 2.0428573200779576

Epoch: 5| Step: 2
Training loss: 1.2011849880218506
Validation loss: 2.0158814730182772

Epoch: 5| Step: 3
Training loss: 1.7335178852081299
Validation loss: 2.0121514848483506

Epoch: 5| Step: 4
Training loss: 1.216580867767334
Validation loss: 1.9849625300335627

Epoch: 5| Step: 5
Training loss: 1.3260128498077393
Validation loss: 1.9699040228320706

Epoch: 5| Step: 6
Training loss: 1.4287967681884766
Validation loss: 1.9817553438166136

Epoch: 5| Step: 7
Training loss: 1.2331011295318604
Validation loss: 1.9837326131841189

Epoch: 5| Step: 8
Training loss: 1.9836009740829468
Validation loss: 1.9845273545993272

Epoch: 5| Step: 9
Training loss: 1.0986554622650146
Validation loss: 2.002838125792883

Epoch: 5| Step: 10
Training loss: 1.5830152034759521
Validation loss: 2.021740951845723

Epoch: 367| Step: 0
Training loss: 1.116967797279358
Validation loss: 2.030731995900472

Epoch: 5| Step: 1
Training loss: 1.730595350265503
Validation loss: 2.057517474697482

Epoch: 5| Step: 2
Training loss: 1.8108621835708618
Validation loss: 2.067170771219397

Epoch: 5| Step: 3
Training loss: 0.9050437808036804
Validation loss: 2.0707307387423772

Epoch: 5| Step: 4
Training loss: 1.1862999200820923
Validation loss: 2.0749205466239684

Epoch: 5| Step: 5
Training loss: 1.4477565288543701
Validation loss: 2.092972369604213

Epoch: 5| Step: 6
Training loss: 1.7834316492080688
Validation loss: 2.0768836980224936

Epoch: 5| Step: 7
Training loss: 1.2012946605682373
Validation loss: 2.0638504156502346

Epoch: 5| Step: 8
Training loss: 1.5759917497634888
Validation loss: 2.0525831278934272

Epoch: 5| Step: 9
Training loss: 1.5514488220214844
Validation loss: 2.0373780406931394

Epoch: 5| Step: 10
Training loss: 1.77047860622406
Validation loss: 2.0128880123938284

Epoch: 368| Step: 0
Training loss: 1.5060135126113892
Validation loss: 1.9858780689136957

Epoch: 5| Step: 1
Training loss: 1.2782233953475952
Validation loss: 1.9732530937399915

Epoch: 5| Step: 2
Training loss: 1.017443060874939
Validation loss: 1.9810761918303788

Epoch: 5| Step: 3
Training loss: 1.558700442314148
Validation loss: 1.9829639978306268

Epoch: 5| Step: 4
Training loss: 1.2331773042678833
Validation loss: 2.0177026512802287

Epoch: 5| Step: 5
Training loss: 1.7958571910858154
Validation loss: 2.0244713803773284

Epoch: 5| Step: 6
Training loss: 1.095165491104126
Validation loss: 2.01775175012568

Epoch: 5| Step: 7
Training loss: 1.208315372467041
Validation loss: 2.024140578444286

Epoch: 5| Step: 8
Training loss: 1.3328288793563843
Validation loss: 2.0460114261155486

Epoch: 5| Step: 9
Training loss: 2.088045358657837
Validation loss: 2.041278085400981

Epoch: 5| Step: 10
Training loss: 2.009373903274536
Validation loss: 2.0454686469929193

Epoch: 369| Step: 0
Training loss: 1.37277090549469
Validation loss: 2.027624322522071

Epoch: 5| Step: 1
Training loss: 1.2123814821243286
Validation loss: 2.0434827317473707

Epoch: 5| Step: 2
Training loss: 1.122023344039917
Validation loss: 2.058065822047572

Epoch: 5| Step: 3
Training loss: 1.41383695602417
Validation loss: 2.0463561063171714

Epoch: 5| Step: 4
Training loss: 1.596678376197815
Validation loss: 2.046098275851178

Epoch: 5| Step: 5
Training loss: 0.9709909558296204
Validation loss: 2.033614859786085

Epoch: 5| Step: 6
Training loss: 1.5052906274795532
Validation loss: 2.0392654788109565

Epoch: 5| Step: 7
Training loss: 1.9315080642700195
Validation loss: 2.057186440754962

Epoch: 5| Step: 8
Training loss: 1.9234260320663452
Validation loss: 2.0405071012435423

Epoch: 5| Step: 9
Training loss: 1.6498790979385376
Validation loss: 2.024143090812109

Epoch: 5| Step: 10
Training loss: 1.4325238466262817
Validation loss: 1.9948034606954104

Epoch: 370| Step: 0
Training loss: 1.1815599203109741
Validation loss: 1.9810393728235716

Epoch: 5| Step: 1
Training loss: 1.6809619665145874
Validation loss: 1.9892503112875006

Epoch: 5| Step: 2
Training loss: 1.2375388145446777
Validation loss: 1.9647091678393784

Epoch: 5| Step: 3
Training loss: 1.0928071737289429
Validation loss: 1.969901127199973

Epoch: 5| Step: 4
Training loss: 1.8334405422210693
Validation loss: 1.9592701594034831

Epoch: 5| Step: 5
Training loss: 1.6868524551391602
Validation loss: 2.006536687574079

Epoch: 5| Step: 6
Training loss: 1.2968884706497192
Validation loss: 2.039530428506995

Epoch: 5| Step: 7
Training loss: 1.297182321548462
Validation loss: 2.040572653534592

Epoch: 5| Step: 8
Training loss: 1.454567551612854
Validation loss: 2.066540951369911

Epoch: 5| Step: 9
Training loss: 2.2403836250305176
Validation loss: 2.0741532900000132

Epoch: 5| Step: 10
Training loss: 0.8982921242713928
Validation loss: 2.082098058474961

Epoch: 371| Step: 0
Training loss: 1.0705522298812866
Validation loss: 2.0541363826362034

Epoch: 5| Step: 1
Training loss: 1.2539780139923096
Validation loss: 2.0260180299000075

Epoch: 5| Step: 2
Training loss: 1.8079341650009155
Validation loss: 2.0368119926862818

Epoch: 5| Step: 3
Training loss: 1.115107536315918
Validation loss: 2.0010235181418796

Epoch: 5| Step: 4
Training loss: 1.698331594467163
Validation loss: 2.0251943911275556

Epoch: 5| Step: 5
Training loss: 1.883077621459961
Validation loss: 2.0138291722984722

Epoch: 5| Step: 6
Training loss: 1.4335213899612427
Validation loss: 2.0190322322230183

Epoch: 5| Step: 7
Training loss: 1.1607398986816406
Validation loss: 1.9996146284123903

Epoch: 5| Step: 8
Training loss: 1.7432615756988525
Validation loss: 1.974071926968072

Epoch: 5| Step: 9
Training loss: 1.286043405532837
Validation loss: 1.9942211092159312

Epoch: 5| Step: 10
Training loss: 1.379955768585205
Validation loss: 2.003637134387929

Epoch: 372| Step: 0
Training loss: 0.9014021158218384
Validation loss: 2.025497874905986

Epoch: 5| Step: 1
Training loss: 1.6128791570663452
Validation loss: 2.0373485306257844

Epoch: 5| Step: 2
Training loss: 1.5130544900894165
Validation loss: 2.0330967005862983

Epoch: 5| Step: 3
Training loss: 1.2184784412384033
Validation loss: 2.056007021216936

Epoch: 5| Step: 4
Training loss: 1.1975171566009521
Validation loss: 1.9935198266019103

Epoch: 5| Step: 5
Training loss: 1.7736412286758423
Validation loss: 1.9927326915084675

Epoch: 5| Step: 6
Training loss: 1.4597336053848267
Validation loss: 1.9900858786798292

Epoch: 5| Step: 7
Training loss: 2.0448315143585205
Validation loss: 1.9967509097950433

Epoch: 5| Step: 8
Training loss: 1.1720939874649048
Validation loss: 2.014737093320457

Epoch: 5| Step: 9
Training loss: 1.7712901830673218
Validation loss: 2.0196533254397813

Epoch: 5| Step: 10
Training loss: 1.1302558183670044
Validation loss: 2.040959001869284

Epoch: 373| Step: 0
Training loss: 1.7017977237701416
Validation loss: 2.0449084492139917

Epoch: 5| Step: 1
Training loss: 1.4276800155639648
Validation loss: 2.0364583346151535

Epoch: 5| Step: 2
Training loss: 1.303436040878296
Validation loss: 2.031690811598173

Epoch: 5| Step: 3
Training loss: 1.0736966133117676
Validation loss: 2.0329935704508135

Epoch: 5| Step: 4
Training loss: 1.7538385391235352
Validation loss: 2.038253040723903

Epoch: 5| Step: 5
Training loss: 1.6979711055755615
Validation loss: 2.020158176781029

Epoch: 5| Step: 6
Training loss: 1.343873143196106
Validation loss: 2.0042601080350977

Epoch: 5| Step: 7
Training loss: 1.4298268556594849
Validation loss: 1.9941521152373283

Epoch: 5| Step: 8
Training loss: 1.3963209390640259
Validation loss: 1.9751482009887695

Epoch: 5| Step: 9
Training loss: 1.3083471059799194
Validation loss: 1.9620127908645137

Epoch: 5| Step: 10
Training loss: 1.3917474746704102
Validation loss: 1.9436935506841189

Epoch: 374| Step: 0
Training loss: 1.929363489151001
Validation loss: 1.9577455405266053

Epoch: 5| Step: 1
Training loss: 1.3982185125350952
Validation loss: 1.9506880250028384

Epoch: 5| Step: 2
Training loss: 1.5305615663528442
Validation loss: 1.971238718237928

Epoch: 5| Step: 3
Training loss: 1.587998390197754
Validation loss: 1.9911567613642702

Epoch: 5| Step: 4
Training loss: 1.6333448886871338
Validation loss: 1.9923481402858612

Epoch: 5| Step: 5
Training loss: 1.141986608505249
Validation loss: 2.009337914887295

Epoch: 5| Step: 6
Training loss: 0.8709374666213989
Validation loss: 2.0553934445945163

Epoch: 5| Step: 7
Training loss: 1.4630054235458374
Validation loss: 2.0873171078261508

Epoch: 5| Step: 8
Training loss: 1.6761856079101562
Validation loss: 2.0734626067582

Epoch: 5| Step: 9
Training loss: 1.605133056640625
Validation loss: 2.052153225867979

Epoch: 5| Step: 10
Training loss: 0.8415965437889099
Validation loss: 2.0454767775791947

Epoch: 375| Step: 0
Training loss: 1.5370782613754272
Validation loss: 2.01641050974528

Epoch: 5| Step: 1
Training loss: 1.8058452606201172
Validation loss: 1.9852419091809181

Epoch: 5| Step: 2
Training loss: 1.7461601495742798
Validation loss: 1.9677061650060839

Epoch: 5| Step: 3
Training loss: 1.4818317890167236
Validation loss: 1.9627213554997598

Epoch: 5| Step: 4
Training loss: 1.1721491813659668
Validation loss: 1.96989837256811

Epoch: 5| Step: 5
Training loss: 1.417264699935913
Validation loss: 1.969799308366673

Epoch: 5| Step: 6
Training loss: 1.108963966369629
Validation loss: 1.9523943906189294

Epoch: 5| Step: 7
Training loss: 1.4423271417617798
Validation loss: 1.9743414386626212

Epoch: 5| Step: 8
Training loss: 1.6911399364471436
Validation loss: 1.9961763005102835

Epoch: 5| Step: 9
Training loss: 1.1979081630706787
Validation loss: 2.012764432096994

Epoch: 5| Step: 10
Training loss: 0.975555956363678
Validation loss: 2.0297994741829495

Epoch: 376| Step: 0
Training loss: 1.0746521949768066
Validation loss: 2.057224363409063

Epoch: 5| Step: 1
Training loss: 1.3815358877182007
Validation loss: 2.0390242120271087

Epoch: 5| Step: 2
Training loss: 1.4193482398986816
Validation loss: 2.026316988852716

Epoch: 5| Step: 3
Training loss: 1.3471993207931519
Validation loss: 2.0296415872471307

Epoch: 5| Step: 4
Training loss: 1.1037988662719727
Validation loss: 2.0137085940248225

Epoch: 5| Step: 5
Training loss: 1.8391683101654053
Validation loss: 2.0021921742346978

Epoch: 5| Step: 6
Training loss: 1.2422058582305908
Validation loss: 2.0066373758418585

Epoch: 5| Step: 7
Training loss: 1.2703818082809448
Validation loss: 1.9874728802711732

Epoch: 5| Step: 8
Training loss: 1.775059700012207
Validation loss: 2.001749518097088

Epoch: 5| Step: 9
Training loss: 1.6848373413085938
Validation loss: 1.985506849904214

Epoch: 5| Step: 10
Training loss: 1.6093425750732422
Validation loss: 1.9753210006221649

Epoch: 377| Step: 0
Training loss: 1.4521950483322144
Validation loss: 1.9770000134744952

Epoch: 5| Step: 1
Training loss: 1.5701875686645508
Validation loss: 1.9701230423424834

Epoch: 5| Step: 2
Training loss: 1.2585339546203613
Validation loss: 2.00598055829284

Epoch: 5| Step: 3
Training loss: 1.208723783493042
Validation loss: 2.001626156991528

Epoch: 5| Step: 4
Training loss: 1.5572030544281006
Validation loss: 2.006746165214046

Epoch: 5| Step: 5
Training loss: 1.4151504039764404
Validation loss: 2.007460517268027

Epoch: 5| Step: 6
Training loss: 1.5352891683578491
Validation loss: 2.04228985950511

Epoch: 5| Step: 7
Training loss: 1.6084606647491455
Validation loss: 2.017512480417887

Epoch: 5| Step: 8
Training loss: 1.5706870555877686
Validation loss: 2.038683834896293

Epoch: 5| Step: 9
Training loss: 1.1304171085357666
Validation loss: 2.050491799590408

Epoch: 5| Step: 10
Training loss: 1.1728073358535767
Validation loss: 2.0430503660632717

Epoch: 378| Step: 0
Training loss: 1.079269289970398
Validation loss: 2.0285903100044496

Epoch: 5| Step: 1
Training loss: 1.656311273574829
Validation loss: 2.007223016472273

Epoch: 5| Step: 2
Training loss: 1.0767552852630615
Validation loss: 1.992803209571428

Epoch: 5| Step: 3
Training loss: 1.829406499862671
Validation loss: 2.0063854007310766

Epoch: 5| Step: 4
Training loss: 1.3086810111999512
Validation loss: 2.005203513688939

Epoch: 5| Step: 5
Training loss: 1.2199490070343018
Validation loss: 2.0046574531062955

Epoch: 5| Step: 6
Training loss: 1.8479092121124268
Validation loss: 1.9992063519775227

Epoch: 5| Step: 7
Training loss: 1.69427490234375
Validation loss: 1.9997202824520808

Epoch: 5| Step: 8
Training loss: 1.1288360357284546
Validation loss: 2.0266425955680107

Epoch: 5| Step: 9
Training loss: 1.6211884021759033
Validation loss: 2.011063321944206

Epoch: 5| Step: 10
Training loss: 1.0421757698059082
Validation loss: 2.0035393225249423

Epoch: 379| Step: 0
Training loss: 1.926165223121643
Validation loss: 2.0067629711602324

Epoch: 5| Step: 1
Training loss: 1.7262327671051025
Validation loss: 2.0023828373160413

Epoch: 5| Step: 2
Training loss: 1.580803632736206
Validation loss: 2.00430614461181

Epoch: 5| Step: 3
Training loss: 1.4666121006011963
Validation loss: 1.9847091628659157

Epoch: 5| Step: 4
Training loss: 1.4743486642837524
Validation loss: 1.9755056699117024

Epoch: 5| Step: 5
Training loss: 1.1011762619018555
Validation loss: 1.9619341922062699

Epoch: 5| Step: 6
Training loss: 1.2960143089294434
Validation loss: 1.9736962215874785

Epoch: 5| Step: 7
Training loss: 1.3708699941635132
Validation loss: 1.9840412703893517

Epoch: 5| Step: 8
Training loss: 1.5864466428756714
Validation loss: 2.016700795901719

Epoch: 5| Step: 9
Training loss: 0.9936878085136414
Validation loss: 2.013102949306529

Epoch: 5| Step: 10
Training loss: 1.0761662721633911
Validation loss: 2.0422360794518584

Epoch: 380| Step: 0
Training loss: 1.1259832382202148
Validation loss: 2.0653985520844818

Epoch: 5| Step: 1
Training loss: 1.3247359991073608
Validation loss: 2.09609027319057

Epoch: 5| Step: 2
Training loss: 1.8434741497039795
Validation loss: 2.0820150349729802

Epoch: 5| Step: 3
Training loss: 1.7039649486541748
Validation loss: 2.0995267591168805

Epoch: 5| Step: 4
Training loss: 1.0237669944763184
Validation loss: 2.063483266420262

Epoch: 5| Step: 5
Training loss: 1.3657219409942627
Validation loss: 2.0175732810010194

Epoch: 5| Step: 6
Training loss: 1.0613582134246826
Validation loss: 2.0018561283747354

Epoch: 5| Step: 7
Training loss: 1.0538886785507202
Validation loss: 1.9879897166323919

Epoch: 5| Step: 8
Training loss: 2.007385730743408
Validation loss: 1.9624044946444932

Epoch: 5| Step: 9
Training loss: 1.4359776973724365
Validation loss: 1.94978375845058

Epoch: 5| Step: 10
Training loss: 1.5466830730438232
Validation loss: 1.9398230224527337

Epoch: 381| Step: 0
Training loss: 1.590358853340149
Validation loss: 1.9244832428552772

Epoch: 5| Step: 1
Training loss: 1.8789198398590088
Validation loss: 1.9200445913499402

Epoch: 5| Step: 2
Training loss: 1.0103448629379272
Validation loss: 1.9269514724772463

Epoch: 5| Step: 3
Training loss: 1.4327552318572998
Validation loss: 1.9286128551729265

Epoch: 5| Step: 4
Training loss: 1.3640012741088867
Validation loss: 1.9451039375797394

Epoch: 5| Step: 5
Training loss: 1.1241792440414429
Validation loss: 1.972298029930361

Epoch: 5| Step: 6
Training loss: 2.0092856884002686
Validation loss: 2.0181612699262557

Epoch: 5| Step: 7
Training loss: 1.090541124343872
Validation loss: 2.0395681768335323

Epoch: 5| Step: 8
Training loss: 1.4127962589263916
Validation loss: 2.0211804413026377

Epoch: 5| Step: 9
Training loss: 1.2645771503448486
Validation loss: 2.044494818615657

Epoch: 5| Step: 10
Training loss: 1.3340950012207031
Validation loss: 2.0431615075757428

Epoch: 382| Step: 0
Training loss: 1.4541585445404053
Validation loss: 2.02586075311066

Epoch: 5| Step: 1
Training loss: 1.2757580280303955
Validation loss: 2.036756723157821

Epoch: 5| Step: 2
Training loss: 1.3747715950012207
Validation loss: 2.0216836262774724

Epoch: 5| Step: 3
Training loss: 1.419883131980896
Validation loss: 1.9943095535360358

Epoch: 5| Step: 4
Training loss: 1.5099974870681763
Validation loss: 1.9825015580782326

Epoch: 5| Step: 5
Training loss: 1.5116068124771118
Validation loss: 1.9837020417695403

Epoch: 5| Step: 6
Training loss: 1.2504758834838867
Validation loss: 1.9771992032245924

Epoch: 5| Step: 7
Training loss: 1.5451176166534424
Validation loss: 1.9857189014393797

Epoch: 5| Step: 8
Training loss: 1.2941195964813232
Validation loss: 1.9723586446495467

Epoch: 5| Step: 9
Training loss: 1.4255180358886719
Validation loss: 1.9614313417865383

Epoch: 5| Step: 10
Training loss: 1.291709065437317
Validation loss: 1.965310263377364

Epoch: 383| Step: 0
Training loss: 1.5503679513931274
Validation loss: 1.988641615836851

Epoch: 5| Step: 1
Training loss: 1.6993423700332642
Validation loss: 2.009668764247689

Epoch: 5| Step: 2
Training loss: 0.9284366369247437
Validation loss: 1.998889716722632

Epoch: 5| Step: 3
Training loss: 1.1328320503234863
Validation loss: 2.020428765204645

Epoch: 5| Step: 4
Training loss: 1.1783462762832642
Validation loss: 2.026343389223981

Epoch: 5| Step: 5
Training loss: 1.097251057624817
Validation loss: 2.0342758304329327

Epoch: 5| Step: 6
Training loss: 1.149841547012329
Validation loss: 2.0231227772210234

Epoch: 5| Step: 7
Training loss: 1.6304248571395874
Validation loss: 1.9975415609216178

Epoch: 5| Step: 8
Training loss: 1.9950129985809326
Validation loss: 2.0179274594911965

Epoch: 5| Step: 9
Training loss: 1.2580409049987793
Validation loss: 1.9915952323585429

Epoch: 5| Step: 10
Training loss: 1.7067341804504395
Validation loss: 2.0173004878464567

Epoch: 384| Step: 0
Training loss: 1.4367945194244385
Validation loss: 2.020236910030406

Epoch: 5| Step: 1
Training loss: 1.2278110980987549
Validation loss: 1.9948433342800345

Epoch: 5| Step: 2
Training loss: 1.4856075048446655
Validation loss: 1.9918071467389342

Epoch: 5| Step: 3
Training loss: 1.2225332260131836
Validation loss: 1.9911084995474866

Epoch: 5| Step: 4
Training loss: 1.0587670803070068
Validation loss: 1.9954583516684912

Epoch: 5| Step: 5
Training loss: 1.5641088485717773
Validation loss: 1.978562908787881

Epoch: 5| Step: 6
Training loss: 1.520403504371643
Validation loss: 1.9945249301131054

Epoch: 5| Step: 7
Training loss: 1.3649482727050781
Validation loss: 1.9949021313780098

Epoch: 5| Step: 8
Training loss: 1.2214537858963013
Validation loss: 1.9967716201659171

Epoch: 5| Step: 9
Training loss: 1.6809751987457275
Validation loss: 1.9931545001204296

Epoch: 5| Step: 10
Training loss: 1.265447974205017
Validation loss: 2.021007642951063

Epoch: 385| Step: 0
Training loss: 1.1508681774139404
Validation loss: 2.0130945969653387

Epoch: 5| Step: 1
Training loss: 2.138822078704834
Validation loss: 1.9895030644632155

Epoch: 5| Step: 2
Training loss: 1.2149583101272583
Validation loss: 1.9943781975776917

Epoch: 5| Step: 3
Training loss: 1.2214477062225342
Validation loss: 1.9996418619668612

Epoch: 5| Step: 4
Training loss: 1.509763479232788
Validation loss: 2.013981093642532

Epoch: 5| Step: 5
Training loss: 1.251581072807312
Validation loss: 2.0074989436775126

Epoch: 5| Step: 6
Training loss: 1.4323827028274536
Validation loss: 2.0230898985298733

Epoch: 5| Step: 7
Training loss: 1.181952953338623
Validation loss: 2.002331192775439

Epoch: 5| Step: 8
Training loss: 1.2586543560028076
Validation loss: 2.0182166522549045

Epoch: 5| Step: 9
Training loss: 1.0340763330459595
Validation loss: 2.0329946394889586

Epoch: 5| Step: 10
Training loss: 1.5963881015777588
Validation loss: 2.057411109247515

Epoch: 386| Step: 0
Training loss: 1.809994101524353
Validation loss: 2.0561655952084448

Epoch: 5| Step: 1
Training loss: 1.0502914190292358
Validation loss: 2.057600582799604

Epoch: 5| Step: 2
Training loss: 1.2380081415176392
Validation loss: 2.036997418249807

Epoch: 5| Step: 3
Training loss: 1.7843475341796875
Validation loss: 2.0248789530928417

Epoch: 5| Step: 4
Training loss: 1.3131425380706787
Validation loss: 2.003461060985442

Epoch: 5| Step: 5
Training loss: 1.7668793201446533
Validation loss: 1.9726707909696846

Epoch: 5| Step: 6
Training loss: 1.0406063795089722
Validation loss: 1.9653794611653974

Epoch: 5| Step: 7
Training loss: 1.3462204933166504
Validation loss: 1.9509196037887244

Epoch: 5| Step: 8
Training loss: 1.4771568775177002
Validation loss: 1.951241950834951

Epoch: 5| Step: 9
Training loss: 1.260493516921997
Validation loss: 1.9699826061084706

Epoch: 5| Step: 10
Training loss: 1.1546587944030762
Validation loss: 1.9865383102047829

Epoch: 387| Step: 0
Training loss: 1.2999941110610962
Validation loss: 1.9822435404664727

Epoch: 5| Step: 1
Training loss: 1.0203888416290283
Validation loss: 1.9997306946785218

Epoch: 5| Step: 2
Training loss: 1.3747025728225708
Validation loss: 1.9798672993977864

Epoch: 5| Step: 3
Training loss: 1.4263473749160767
Validation loss: 1.978663521428262

Epoch: 5| Step: 4
Training loss: 1.614911675453186
Validation loss: 1.9839386504183534

Epoch: 5| Step: 5
Training loss: 1.6352096796035767
Validation loss: 1.998124635347756

Epoch: 5| Step: 6
Training loss: 0.7038586735725403
Validation loss: 2.004658473435269

Epoch: 5| Step: 7
Training loss: 1.6343399286270142
Validation loss: 2.0034187070785032

Epoch: 5| Step: 8
Training loss: 1.299117088317871
Validation loss: 2.0195924492292505

Epoch: 5| Step: 9
Training loss: 1.4048161506652832
Validation loss: 2.029617947916831

Epoch: 5| Step: 10
Training loss: 1.568323016166687
Validation loss: 2.04689807532936

Epoch: 388| Step: 0
Training loss: 1.7134029865264893
Validation loss: 2.0400058377173638

Epoch: 5| Step: 1
Training loss: 1.0916340351104736
Validation loss: 2.032286672181981

Epoch: 5| Step: 2
Training loss: 1.4072396755218506
Validation loss: 2.0208647058856104

Epoch: 5| Step: 3
Training loss: 1.3238605260849
Validation loss: 2.0264694459976687

Epoch: 5| Step: 4
Training loss: 1.08039128780365
Validation loss: 1.985556911396724

Epoch: 5| Step: 5
Training loss: 1.5731648206710815
Validation loss: 1.9748806953430176

Epoch: 5| Step: 6
Training loss: 1.009963870048523
Validation loss: 1.9705176763637091

Epoch: 5| Step: 7
Training loss: 1.5047826766967773
Validation loss: 1.9500672304502098

Epoch: 5| Step: 8
Training loss: 1.3889192342758179
Validation loss: 1.9572891855752597

Epoch: 5| Step: 9
Training loss: 1.3527805805206299
Validation loss: 1.9375602340185514

Epoch: 5| Step: 10
Training loss: 1.2667680978775024
Validation loss: 1.9354537199902278

Epoch: 389| Step: 0
Training loss: 1.12565279006958
Validation loss: 1.9260043841536327

Epoch: 5| Step: 1
Training loss: 1.1054216623306274
Validation loss: 1.9328067405249483

Epoch: 5| Step: 2
Training loss: 1.771541953086853
Validation loss: 1.9227088676985873

Epoch: 5| Step: 3
Training loss: 1.351299524307251
Validation loss: 1.9387190521404307

Epoch: 5| Step: 4
Training loss: 1.6323398351669312
Validation loss: 1.9549110897125737

Epoch: 5| Step: 5
Training loss: 1.3339864015579224
Validation loss: 1.9713721403511621

Epoch: 5| Step: 6
Training loss: 1.2269961833953857
Validation loss: 1.991414236766036

Epoch: 5| Step: 7
Training loss: 1.5164909362792969
Validation loss: 1.9994024102405836

Epoch: 5| Step: 8
Training loss: 0.73853600025177
Validation loss: 2.0325680791690783

Epoch: 5| Step: 9
Training loss: 1.289054274559021
Validation loss: 2.0986684753048803

Epoch: 5| Step: 10
Training loss: 1.9019286632537842
Validation loss: 2.0672894511171567

Epoch: 390| Step: 0
Training loss: 1.7612273693084717
Validation loss: 2.081704079463918

Epoch: 5| Step: 1
Training loss: 1.1516903638839722
Validation loss: 2.0064600744555072

Epoch: 5| Step: 2
Training loss: 1.239333152770996
Validation loss: 1.9708966183406051

Epoch: 5| Step: 3
Training loss: 1.2140161991119385
Validation loss: 1.9413250377101283

Epoch: 5| Step: 4
Training loss: 1.259216547012329
Validation loss: 1.9232399309835126

Epoch: 5| Step: 5
Training loss: 1.260733723640442
Validation loss: 1.9130386280757126

Epoch: 5| Step: 6
Training loss: 1.5204401016235352
Validation loss: 1.9316940089707733

Epoch: 5| Step: 7
Training loss: 1.2854591608047485
Validation loss: 1.954832842273097

Epoch: 5| Step: 8
Training loss: 1.7142143249511719
Validation loss: 1.9623827254900368

Epoch: 5| Step: 9
Training loss: 1.2282941341400146
Validation loss: 1.9532898292746594

Epoch: 5| Step: 10
Training loss: 1.1584619283676147
Validation loss: 1.9913961220813055

Epoch: 391| Step: 0
Training loss: 1.0702872276306152
Validation loss: 2.0089714834767003

Epoch: 5| Step: 1
Training loss: 1.4079183340072632
Validation loss: 2.0088701812169885

Epoch: 5| Step: 2
Training loss: 1.0874582529067993
Validation loss: 2.024248497460478

Epoch: 5| Step: 3
Training loss: 1.490972876548767
Validation loss: 2.0521367288404897

Epoch: 5| Step: 4
Training loss: 1.6969165802001953
Validation loss: 2.0527689995304232

Epoch: 5| Step: 5
Training loss: 0.8915976285934448
Validation loss: 2.0101334920493503

Epoch: 5| Step: 6
Training loss: 1.4614183902740479
Validation loss: 2.007560928662618

Epoch: 5| Step: 7
Training loss: 1.2683628797531128
Validation loss: 1.9992499864229591

Epoch: 5| Step: 8
Training loss: 1.2020282745361328
Validation loss: 2.012256660769063

Epoch: 5| Step: 9
Training loss: 1.5267250537872314
Validation loss: 1.9760961378774335

Epoch: 5| Step: 10
Training loss: 1.4827115535736084
Validation loss: 1.9631790986625097

Epoch: 392| Step: 0
Training loss: 1.3470300436019897
Validation loss: 1.9885929066647765

Epoch: 5| Step: 1
Training loss: 1.1070233583450317
Validation loss: 1.978383723125663

Epoch: 5| Step: 2
Training loss: 1.7617568969726562
Validation loss: 1.9651222177731094

Epoch: 5| Step: 3
Training loss: 1.120259165763855
Validation loss: 1.963588865854407

Epoch: 5| Step: 4
Training loss: 1.3341727256774902
Validation loss: 1.9361493382402646

Epoch: 5| Step: 5
Training loss: 1.1456007957458496
Validation loss: 1.964645444705922

Epoch: 5| Step: 6
Training loss: 1.4933580160140991
Validation loss: 1.9700701595634542

Epoch: 5| Step: 7
Training loss: 1.4309279918670654
Validation loss: 1.9877309465921054

Epoch: 5| Step: 8
Training loss: 1.350048303604126
Validation loss: 1.9825252743177517

Epoch: 5| Step: 9
Training loss: 1.358459711074829
Validation loss: 1.9856100505398167

Epoch: 5| Step: 10
Training loss: 1.239867091178894
Validation loss: 2.0220229010428152

Epoch: 393| Step: 0
Training loss: 1.4216169118881226
Validation loss: 2.0125628722611295

Epoch: 5| Step: 1
Training loss: 1.3883309364318848
Validation loss: 2.0227731376565914

Epoch: 5| Step: 2
Training loss: 1.3932620286941528
Validation loss: 2.0020032569926274

Epoch: 5| Step: 3
Training loss: 1.1309583187103271
Validation loss: 2.003184296751535

Epoch: 5| Step: 4
Training loss: 1.2948435544967651
Validation loss: 1.9650551131976548

Epoch: 5| Step: 5
Training loss: 1.2993942499160767
Validation loss: 1.9545151905346942

Epoch: 5| Step: 6
Training loss: 1.01872980594635
Validation loss: 1.9548566469582178

Epoch: 5| Step: 7
Training loss: 1.7041079998016357
Validation loss: 1.9371360732663063

Epoch: 5| Step: 8
Training loss: 1.3423054218292236
Validation loss: 1.931822270475408

Epoch: 5| Step: 9
Training loss: 1.3939844369888306
Validation loss: 1.9339702398546281

Epoch: 5| Step: 10
Training loss: 1.229972004890442
Validation loss: 1.9571911417027956

Epoch: 394| Step: 0
Training loss: 1.517333984375
Validation loss: 1.9706510292586459

Epoch: 5| Step: 1
Training loss: 0.9171035885810852
Validation loss: 2.003773817452051

Epoch: 5| Step: 2
Training loss: 0.9714816808700562
Validation loss: 2.024068150469052

Epoch: 5| Step: 3
Training loss: 1.0719245672225952
Validation loss: 2.033750239238944

Epoch: 5| Step: 4
Training loss: 1.0736448764801025
Validation loss: 2.029845122368105

Epoch: 5| Step: 5
Training loss: 1.1352837085723877
Validation loss: 2.03492768092822

Epoch: 5| Step: 6
Training loss: 0.9969959259033203
Validation loss: 2.025890306759906

Epoch: 5| Step: 7
Training loss: 2.1430766582489014
Validation loss: 2.029712530874437

Epoch: 5| Step: 8
Training loss: 1.3285118341445923
Validation loss: 2.017606104573896

Epoch: 5| Step: 9
Training loss: 1.852439284324646
Validation loss: 2.0007581198087303

Epoch: 5| Step: 10
Training loss: 1.6384608745574951
Validation loss: 1.9824643160707207

Epoch: 395| Step: 0
Training loss: 1.3266916275024414
Validation loss: 1.971846982996951

Epoch: 5| Step: 1
Training loss: 0.8084536790847778
Validation loss: 1.9689580253375474

Epoch: 5| Step: 2
Training loss: 1.116187572479248
Validation loss: 1.9920752920130247

Epoch: 5| Step: 3
Training loss: 1.3176957368850708
Validation loss: 2.0047850249915995

Epoch: 5| Step: 4
Training loss: 1.7209084033966064
Validation loss: 1.9971000020221998

Epoch: 5| Step: 5
Training loss: 1.5257867574691772
Validation loss: 1.9860591068062732

Epoch: 5| Step: 6
Training loss: 1.3343175649642944
Validation loss: 2.005477810418734

Epoch: 5| Step: 7
Training loss: 0.9534507989883423
Validation loss: 1.981881591581529

Epoch: 5| Step: 8
Training loss: 1.173882007598877
Validation loss: 1.958510180955292

Epoch: 5| Step: 9
Training loss: 1.4060570001602173
Validation loss: 1.978828719867173

Epoch: 5| Step: 10
Training loss: 1.7958260774612427
Validation loss: 1.9317386227269326

Epoch: 396| Step: 0
Training loss: 1.1743874549865723
Validation loss: 1.9275346379126272

Epoch: 5| Step: 1
Training loss: 1.186773657798767
Validation loss: 1.9165235052826584

Epoch: 5| Step: 2
Training loss: 0.9234565496444702
Validation loss: 1.9346197356459915

Epoch: 5| Step: 3
Training loss: 1.2591615915298462
Validation loss: 1.9328337561699651

Epoch: 5| Step: 4
Training loss: 1.0879082679748535
Validation loss: 1.9520028150209816

Epoch: 5| Step: 5
Training loss: 0.8846985101699829
Validation loss: 1.957897424697876

Epoch: 5| Step: 6
Training loss: 1.3545538187026978
Validation loss: 1.9794827148478518

Epoch: 5| Step: 7
Training loss: 1.4041932821273804
Validation loss: 1.976151035678002

Epoch: 5| Step: 8
Training loss: 2.10859751701355
Validation loss: 1.9812890970578758

Epoch: 5| Step: 9
Training loss: 1.6948144435882568
Validation loss: 1.998524905532919

Epoch: 5| Step: 10
Training loss: 1.291144847869873
Validation loss: 1.9848900905219458

Epoch: 397| Step: 0
Training loss: 1.1989648342132568
Validation loss: 1.9753979918777302

Epoch: 5| Step: 1
Training loss: 1.6346575021743774
Validation loss: 1.9770485201189596

Epoch: 5| Step: 2
Training loss: 1.0730652809143066
Validation loss: 1.9645760572084816

Epoch: 5| Step: 3
Training loss: 1.5224676132202148
Validation loss: 1.9673870789107455

Epoch: 5| Step: 4
Training loss: 1.303128957748413
Validation loss: 1.97028886887335

Epoch: 5| Step: 5
Training loss: 1.5487661361694336
Validation loss: 1.97114061796537

Epoch: 5| Step: 6
Training loss: 1.1505327224731445
Validation loss: 1.929943000116656

Epoch: 5| Step: 7
Training loss: 1.4801949262619019
Validation loss: 1.9600253374345842

Epoch: 5| Step: 8
Training loss: 1.5247409343719482
Validation loss: 1.9598568690720426

Epoch: 5| Step: 9
Training loss: 0.9962730407714844
Validation loss: 2.0026178641985823

Epoch: 5| Step: 10
Training loss: 1.1816569566726685
Validation loss: 1.9883050354578162

Epoch: 398| Step: 0
Training loss: 1.3093650341033936
Validation loss: 1.97669223431618

Epoch: 5| Step: 1
Training loss: 1.1417347192764282
Validation loss: 1.9695159158399027

Epoch: 5| Step: 2
Training loss: 1.433023452758789
Validation loss: 1.984762184081539

Epoch: 5| Step: 3
Training loss: 1.343904733657837
Validation loss: 2.0193251999475623

Epoch: 5| Step: 4
Training loss: 2.040419816970825
Validation loss: 2.0293899505369124

Epoch: 5| Step: 5
Training loss: 1.1546754837036133
Validation loss: 2.0634937568377425

Epoch: 5| Step: 6
Training loss: 1.6250616312026978
Validation loss: 2.0466228146706857

Epoch: 5| Step: 7
Training loss: 0.8091161847114563
Validation loss: 2.0074797291909494

Epoch: 5| Step: 8
Training loss: 1.5988571643829346
Validation loss: 1.9973633673883253

Epoch: 5| Step: 9
Training loss: 0.8534237146377563
Validation loss: 1.94701454588162

Epoch: 5| Step: 10
Training loss: 1.0219148397445679
Validation loss: 1.9675409178580008

Epoch: 399| Step: 0
Training loss: 1.7803924083709717
Validation loss: 1.9403533499727967

Epoch: 5| Step: 1
Training loss: 1.284082055091858
Validation loss: 1.9082005536684425

Epoch: 5| Step: 2
Training loss: 1.2582066059112549
Validation loss: 1.9080933793898551

Epoch: 5| Step: 3
Training loss: 1.0511879920959473
Validation loss: 1.909032734491492

Epoch: 5| Step: 4
Training loss: 0.9744319915771484
Validation loss: 1.905587056631683

Epoch: 5| Step: 5
Training loss: 1.9699246883392334
Validation loss: 1.9302007370097662

Epoch: 5| Step: 6
Training loss: 0.7301084995269775
Validation loss: 1.930569758979223

Epoch: 5| Step: 7
Training loss: 1.460073471069336
Validation loss: 1.9680579913559781

Epoch: 5| Step: 8
Training loss: 1.283186674118042
Validation loss: 1.9920050149322839

Epoch: 5| Step: 9
Training loss: 1.141717791557312
Validation loss: 1.9933603784089446

Epoch: 5| Step: 10
Training loss: 1.2147977352142334
Validation loss: 1.9998349694795505

Epoch: 400| Step: 0
Training loss: 1.7429087162017822
Validation loss: 2.0408948108714116

Epoch: 5| Step: 1
Training loss: 1.6562296152114868
Validation loss: 2.060169280216258

Epoch: 5| Step: 2
Training loss: 1.4789326190948486
Validation loss: 2.05342201904584

Epoch: 5| Step: 3
Training loss: 0.8345016241073608
Validation loss: 2.0420271799128544

Epoch: 5| Step: 4
Training loss: 1.3130089044570923
Validation loss: 2.0255336428201325

Epoch: 5| Step: 5
Training loss: 1.0156164169311523
Validation loss: 1.9934074712055985

Epoch: 5| Step: 6
Training loss: 1.3110202550888062
Validation loss: 1.9648816841904835

Epoch: 5| Step: 7
Training loss: 1.1974331140518188
Validation loss: 1.9128697456852082

Epoch: 5| Step: 8
Training loss: 1.4204108715057373
Validation loss: 1.9101355319382043

Epoch: 5| Step: 9
Training loss: 1.2574621438980103
Validation loss: 1.894749810618739

Epoch: 5| Step: 10
Training loss: 1.0656832456588745
Validation loss: 1.912700496694093

Epoch: 401| Step: 0
Training loss: 1.2096747159957886
Validation loss: 1.9193138127685876

Epoch: 5| Step: 1
Training loss: 0.8967774510383606
Validation loss: 1.9178204767165645

Epoch: 5| Step: 2
Training loss: 1.139460563659668
Validation loss: 1.9421335112664007

Epoch: 5| Step: 3
Training loss: 1.4713923931121826
Validation loss: 1.932695637467087

Epoch: 5| Step: 4
Training loss: 1.6379228830337524
Validation loss: 1.9611503667728876

Epoch: 5| Step: 5
Training loss: 1.2874799966812134
Validation loss: 1.9416707408043645

Epoch: 5| Step: 6
Training loss: 1.3043181896209717
Validation loss: 1.936338246509593

Epoch: 5| Step: 7
Training loss: 1.7982885837554932
Validation loss: 1.95452251485599

Epoch: 5| Step: 8
Training loss: 1.2249443531036377
Validation loss: 1.9728938764141453

Epoch: 5| Step: 9
Training loss: 1.3001432418823242
Validation loss: 1.9839528299147082

Epoch: 5| Step: 10
Training loss: 0.8779287934303284
Validation loss: 1.9701662512235745

Epoch: 402| Step: 0
Training loss: 1.115244746208191
Validation loss: 1.9710956106903732

Epoch: 5| Step: 1
Training loss: 1.2877848148345947
Validation loss: 1.9704532443836171

Epoch: 5| Step: 2
Training loss: 1.2480121850967407
Validation loss: 1.9578168622909053

Epoch: 5| Step: 3
Training loss: 1.181532382965088
Validation loss: 1.948335047691099

Epoch: 5| Step: 4
Training loss: 1.0811760425567627
Validation loss: 1.9547222429706204

Epoch: 5| Step: 5
Training loss: 1.047471284866333
Validation loss: 1.9590519282125658

Epoch: 5| Step: 6
Training loss: 1.5254112482070923
Validation loss: 1.9641058034794305

Epoch: 5| Step: 7
Training loss: 1.7955801486968994
Validation loss: 1.9744524212293728

Epoch: 5| Step: 8
Training loss: 1.1710517406463623
Validation loss: 1.9848832725196757

Epoch: 5| Step: 9
Training loss: 1.3517805337905884
Validation loss: 1.9900885987025436

Epoch: 5| Step: 10
Training loss: 1.48470938205719
Validation loss: 1.9766387862543906

Epoch: 403| Step: 0
Training loss: 1.2883740663528442
Validation loss: 1.9975636877039427

Epoch: 5| Step: 1
Training loss: 0.9547948837280273
Validation loss: 1.9771541882586736

Epoch: 5| Step: 2
Training loss: 1.6262353658676147
Validation loss: 1.9740838978880195

Epoch: 5| Step: 3
Training loss: 1.2853662967681885
Validation loss: 1.985421428116419

Epoch: 5| Step: 4
Training loss: 1.0263097286224365
Validation loss: 1.9706062296385407

Epoch: 5| Step: 5
Training loss: 1.3336026668548584
Validation loss: 1.9673909218080583

Epoch: 5| Step: 6
Training loss: 1.1141985654830933
Validation loss: 1.9877882337057462

Epoch: 5| Step: 7
Training loss: 1.2879774570465088
Validation loss: 1.9600267871733634

Epoch: 5| Step: 8
Training loss: 0.8720026016235352
Validation loss: 1.9555493888034616

Epoch: 5| Step: 9
Training loss: 1.4530221223831177
Validation loss: 1.9798716729687107

Epoch: 5| Step: 10
Training loss: 1.8599554300308228
Validation loss: 1.9722543531848538

Epoch: 404| Step: 0
Training loss: 1.7528098821640015
Validation loss: 1.9901835123697917

Epoch: 5| Step: 1
Training loss: 1.120343565940857
Validation loss: 1.9858667004492976

Epoch: 5| Step: 2
Training loss: 1.115979552268982
Validation loss: 2.0087201826034056

Epoch: 5| Step: 3
Training loss: 1.0774625539779663
Validation loss: 2.0192558073228404

Epoch: 5| Step: 4
Training loss: 1.6699321269989014
Validation loss: 1.99965637986378

Epoch: 5| Step: 5
Training loss: 1.3387991189956665
Validation loss: 1.9883723656336467

Epoch: 5| Step: 6
Training loss: 1.3172380924224854
Validation loss: 1.9909590700621247

Epoch: 5| Step: 7
Training loss: 1.3349225521087646
Validation loss: 1.9765538554037771

Epoch: 5| Step: 8
Training loss: 0.81500643491745
Validation loss: 1.9533816922095515

Epoch: 5| Step: 9
Training loss: 0.9924960136413574
Validation loss: 1.9419471871468328

Epoch: 5| Step: 10
Training loss: 1.4926819801330566
Validation loss: 1.9340169839961554

Epoch: 405| Step: 0
Training loss: 1.112379789352417
Validation loss: 1.9460938566474504

Epoch: 5| Step: 1
Training loss: 1.2663013935089111
Validation loss: 1.947031472318916

Epoch: 5| Step: 2
Training loss: 1.2147136926651
Validation loss: 1.9423359581219253

Epoch: 5| Step: 3
Training loss: 1.2060182094573975
Validation loss: 1.9562427074678483

Epoch: 5| Step: 4
Training loss: 1.3422424793243408
Validation loss: 1.9637482935382473

Epoch: 5| Step: 5
Training loss: 1.6221662759780884
Validation loss: 1.9712725864943637

Epoch: 5| Step: 6
Training loss: 1.398027777671814
Validation loss: 1.9821361854512205

Epoch: 5| Step: 7
Training loss: 1.1827183961868286
Validation loss: 1.959247431447429

Epoch: 5| Step: 8
Training loss: 1.4253169298171997
Validation loss: 1.980475418029293

Epoch: 5| Step: 9
Training loss: 1.0051920413970947
Validation loss: 1.9646345774332683

Epoch: 5| Step: 10
Training loss: 1.1001744270324707
Validation loss: 1.964608673126467

Epoch: 406| Step: 0
Training loss: 1.2234965562820435
Validation loss: 1.9587620163476596

Epoch: 5| Step: 1
Training loss: 1.3537659645080566
Validation loss: 1.929223568208756

Epoch: 5| Step: 2
Training loss: 1.732659101486206
Validation loss: 1.92452226402939

Epoch: 5| Step: 3
Training loss: 1.0779469013214111
Validation loss: 1.9149194225188224

Epoch: 5| Step: 4
Training loss: 1.2871389389038086
Validation loss: 1.9256705699428436

Epoch: 5| Step: 5
Training loss: 1.3294875621795654
Validation loss: 1.9296773095284738

Epoch: 5| Step: 6
Training loss: 1.3386955261230469
Validation loss: 1.9407049532859557

Epoch: 5| Step: 7
Training loss: 1.0712356567382812
Validation loss: 1.950569760414862

Epoch: 5| Step: 8
Training loss: 1.1214454174041748
Validation loss: 1.963921800736458

Epoch: 5| Step: 9
Training loss: 1.2478843927383423
Validation loss: 1.9591745740623885

Epoch: 5| Step: 10
Training loss: 0.8448566198348999
Validation loss: 1.971358201837027

Epoch: 407| Step: 0
Training loss: 1.2196767330169678
Validation loss: 1.9745654341995076

Epoch: 5| Step: 1
Training loss: 1.5417613983154297
Validation loss: 1.9867974365911176

Epoch: 5| Step: 2
Training loss: 1.019525170326233
Validation loss: 1.9878086864307363

Epoch: 5| Step: 3
Training loss: 0.9906868934631348
Validation loss: 1.99770942682861

Epoch: 5| Step: 4
Training loss: 0.8859416246414185
Validation loss: 1.9806340266299505

Epoch: 5| Step: 5
Training loss: 1.0388033390045166
Validation loss: 1.9834316648462766

Epoch: 5| Step: 6
Training loss: 1.7685158252716064
Validation loss: 1.9624417289610832

Epoch: 5| Step: 7
Training loss: 0.8918827176094055
Validation loss: 1.9523673929193968

Epoch: 5| Step: 8
Training loss: 1.5038549900054932
Validation loss: 1.9663656603905462

Epoch: 5| Step: 9
Training loss: 1.3897510766983032
Validation loss: 1.9728221893310547

Epoch: 5| Step: 10
Training loss: 1.377440333366394
Validation loss: 1.9572915697610507

Epoch: 408| Step: 0
Training loss: 1.1558953523635864
Validation loss: 1.966258829639804

Epoch: 5| Step: 1
Training loss: 1.448420763015747
Validation loss: 1.9787469166581348

Epoch: 5| Step: 2
Training loss: 1.8067741394042969
Validation loss: 1.9826259190036404

Epoch: 5| Step: 3
Training loss: 0.7339462041854858
Validation loss: 1.9671392543341524

Epoch: 5| Step: 4
Training loss: 1.1493732929229736
Validation loss: 1.9587675461205103

Epoch: 5| Step: 5
Training loss: 1.0874074697494507
Validation loss: 1.9426519396484538

Epoch: 5| Step: 6
Training loss: 1.093822717666626
Validation loss: 1.9628110829220022

Epoch: 5| Step: 7
Training loss: 1.372280478477478
Validation loss: 1.9743417847541072

Epoch: 5| Step: 8
Training loss: 1.0976979732513428
Validation loss: 1.9887610225267307

Epoch: 5| Step: 9
Training loss: 1.7497408390045166
Validation loss: 1.9827611882199523

Epoch: 5| Step: 10
Training loss: 0.7828218936920166
Validation loss: 1.9646202005365843

Epoch: 409| Step: 0
Training loss: 1.277092695236206
Validation loss: 1.9743771758130801

Epoch: 5| Step: 1
Training loss: 1.2141895294189453
Validation loss: 1.9752187523790585

Epoch: 5| Step: 2
Training loss: 1.2867023944854736
Validation loss: 1.9613104084486603

Epoch: 5| Step: 3
Training loss: 1.064729928970337
Validation loss: 1.9508917370150167

Epoch: 5| Step: 4
Training loss: 0.8295572996139526
Validation loss: 1.955561226414096

Epoch: 5| Step: 5
Training loss: 1.246577262878418
Validation loss: 1.9508172555636334

Epoch: 5| Step: 6
Training loss: 1.5425435304641724
Validation loss: 1.9352644720385153

Epoch: 5| Step: 7
Training loss: 1.2501810789108276
Validation loss: 1.9324515147875714

Epoch: 5| Step: 8
Training loss: 1.3834598064422607
Validation loss: 1.9292387436794978

Epoch: 5| Step: 9
Training loss: 1.3617126941680908
Validation loss: 1.9168330674530358

Epoch: 5| Step: 10
Training loss: 0.9998624324798584
Validation loss: 1.919375091470698

Epoch: 410| Step: 0
Training loss: 1.1375328302383423
Validation loss: 1.9134015511440974

Epoch: 5| Step: 1
Training loss: 1.3199290037155151
Validation loss: 1.9265801009311472

Epoch: 5| Step: 2
Training loss: 0.5881415605545044
Validation loss: 1.9284214332539549

Epoch: 5| Step: 3
Training loss: 1.223828673362732
Validation loss: 1.9304370367398827

Epoch: 5| Step: 4
Training loss: 1.0360820293426514
Validation loss: 1.9434774024512178

Epoch: 5| Step: 5
Training loss: 1.7361122369766235
Validation loss: 1.9698690163191928

Epoch: 5| Step: 6
Training loss: 0.6819432973861694
Validation loss: 1.9867180496133783

Epoch: 5| Step: 7
Training loss: 1.4897371530532837
Validation loss: 2.0114066344435497

Epoch: 5| Step: 8
Training loss: 1.296228051185608
Validation loss: 2.006485962098645

Epoch: 5| Step: 9
Training loss: 1.4500739574432373
Validation loss: 1.9696866107243363

Epoch: 5| Step: 10
Training loss: 1.5479143857955933
Validation loss: 1.9817561411088513

Epoch: 411| Step: 0
Training loss: 1.605187177658081
Validation loss: 1.9648952022675545

Epoch: 5| Step: 1
Training loss: 1.4471168518066406
Validation loss: 1.9686456136806036

Epoch: 5| Step: 2
Training loss: 0.6945697069168091
Validation loss: 1.974451832873847

Epoch: 5| Step: 3
Training loss: 1.3308186531066895
Validation loss: 1.9818134974407893

Epoch: 5| Step: 4
Training loss: 1.1442147493362427
Validation loss: 1.9797629387147966

Epoch: 5| Step: 5
Training loss: 1.2688720226287842
Validation loss: 1.9841525452111357

Epoch: 5| Step: 6
Training loss: 1.1242889165878296
Validation loss: 1.97324510030849

Epoch: 5| Step: 7
Training loss: 0.8937010765075684
Validation loss: 1.9651383264090425

Epoch: 5| Step: 8
Training loss: 1.2819534540176392
Validation loss: 1.9735540318232712

Epoch: 5| Step: 9
Training loss: 1.3316138982772827
Validation loss: 1.976148638674008

Epoch: 5| Step: 10
Training loss: 1.2594554424285889
Validation loss: 1.9671917077033751

Epoch: 412| Step: 0
Training loss: 0.7796749472618103
Validation loss: 1.9543589533016246

Epoch: 5| Step: 1
Training loss: 1.494343876838684
Validation loss: 1.9726279807347122

Epoch: 5| Step: 2
Training loss: 1.1510664224624634
Validation loss: 1.9830308729602444

Epoch: 5| Step: 3
Training loss: 1.5287446975708008
Validation loss: 1.9962060400234756

Epoch: 5| Step: 4
Training loss: 1.142059564590454
Validation loss: 1.9598172069877706

Epoch: 5| Step: 5
Training loss: 1.1830346584320068
Validation loss: 1.9454291571852982

Epoch: 5| Step: 6
Training loss: 1.2026581764221191
Validation loss: 1.9337598252040085

Epoch: 5| Step: 7
Training loss: 1.2875988483428955
Validation loss: 1.9257092552800332

Epoch: 5| Step: 8
Training loss: 1.0017555952072144
Validation loss: 1.9235219545261835

Epoch: 5| Step: 9
Training loss: 1.5775903463363647
Validation loss: 1.9396137716949626

Epoch: 5| Step: 10
Training loss: 0.9924904108047485
Validation loss: 1.98094053165887

Epoch: 413| Step: 0
Training loss: 1.2816002368927002
Validation loss: 1.9748621781667073

Epoch: 5| Step: 1
Training loss: 1.0099327564239502
Validation loss: 1.9624314769621818

Epoch: 5| Step: 2
Training loss: 0.9670594334602356
Validation loss: 1.9769156876430716

Epoch: 5| Step: 3
Training loss: 1.300843358039856
Validation loss: 1.9736238384759555

Epoch: 5| Step: 4
Training loss: 0.7363203763961792
Validation loss: 1.97161393268134

Epoch: 5| Step: 5
Training loss: 1.5148195028305054
Validation loss: 1.9646949280974686

Epoch: 5| Step: 6
Training loss: 1.0899823904037476
Validation loss: 1.9750945311720653

Epoch: 5| Step: 7
Training loss: 1.620326280593872
Validation loss: 1.957453449567159

Epoch: 5| Step: 8
Training loss: 1.1318066120147705
Validation loss: 1.968362928718649

Epoch: 5| Step: 9
Training loss: 1.5227433443069458
Validation loss: 1.9696433505704325

Epoch: 5| Step: 10
Training loss: 1.1122251749038696
Validation loss: 1.981434513163823

Epoch: 414| Step: 0
Training loss: 1.38315749168396
Validation loss: 1.9711335000171457

Epoch: 5| Step: 1
Training loss: 1.054107904434204
Validation loss: 1.967499747071215

Epoch: 5| Step: 2
Training loss: 0.9104677438735962
Validation loss: 1.9415891478138585

Epoch: 5| Step: 3
Training loss: 0.8544452786445618
Validation loss: 1.9509504072127803

Epoch: 5| Step: 4
Training loss: 1.7217766046524048
Validation loss: 1.9636335603652462

Epoch: 5| Step: 5
Training loss: 1.2468976974487305
Validation loss: 1.99305123026653

Epoch: 5| Step: 6
Training loss: 0.8344890475273132
Validation loss: 1.975041566356536

Epoch: 5| Step: 7
Training loss: 1.56332266330719
Validation loss: 1.9787490944708548

Epoch: 5| Step: 8
Training loss: 1.4950778484344482
Validation loss: 2.0023055704691077

Epoch: 5| Step: 9
Training loss: 1.1929662227630615
Validation loss: 1.984531048805483

Epoch: 5| Step: 10
Training loss: 1.159136414527893
Validation loss: 1.9623448361632645

Epoch: 415| Step: 0
Training loss: 1.1509473323822021
Validation loss: 1.9660895486031809

Epoch: 5| Step: 1
Training loss: 1.1920316219329834
Validation loss: 1.957116675633256

Epoch: 5| Step: 2
Training loss: 1.0929172039031982
Validation loss: 1.9467143922723749

Epoch: 5| Step: 3
Training loss: 1.268984079360962
Validation loss: 1.9311746064052786

Epoch: 5| Step: 4
Training loss: 1.0623763799667358
Validation loss: 1.9284197412511355

Epoch: 5| Step: 5
Training loss: 1.2294009923934937
Validation loss: 1.9035911842059063

Epoch: 5| Step: 6
Training loss: 1.4442552328109741
Validation loss: 1.914604624112447

Epoch: 5| Step: 7
Training loss: 1.660280466079712
Validation loss: 1.943326796254804

Epoch: 5| Step: 8
Training loss: 1.5069111585617065
Validation loss: 1.9339879123113488

Epoch: 5| Step: 9
Training loss: 0.8609596490859985
Validation loss: 1.9348593975908013

Epoch: 5| Step: 10
Training loss: 0.965506374835968
Validation loss: 1.906508550849012

Epoch: 416| Step: 0
Training loss: 1.4245433807373047
Validation loss: 1.878587302341256

Epoch: 5| Step: 1
Training loss: 1.1492468118667603
Validation loss: 1.90814806056279

Epoch: 5| Step: 2
Training loss: 0.5774213075637817
Validation loss: 1.8942367581910984

Epoch: 5| Step: 3
Training loss: 1.0646663904190063
Validation loss: 1.909636692334247

Epoch: 5| Step: 4
Training loss: 1.1363049745559692
Validation loss: 1.9193467094052223

Epoch: 5| Step: 5
Training loss: 1.2921297550201416
Validation loss: 1.9229335272183983

Epoch: 5| Step: 6
Training loss: 1.3247331380844116
Validation loss: 1.9219963755658878

Epoch: 5| Step: 7
Training loss: 1.479619026184082
Validation loss: 1.9393247327496927

Epoch: 5| Step: 8
Training loss: 1.1136823892593384
Validation loss: 1.905213131699511

Epoch: 5| Step: 9
Training loss: 1.3639297485351562
Validation loss: 1.9226403082570722

Epoch: 5| Step: 10
Training loss: 1.1793931722640991
Validation loss: 1.911492710472435

Epoch: 417| Step: 0
Training loss: 0.7387577891349792
Validation loss: 1.9203210902470413

Epoch: 5| Step: 1
Training loss: 1.8440649509429932
Validation loss: 1.9223918337975778

Epoch: 5| Step: 2
Training loss: 0.999738335609436
Validation loss: 1.9158059217596566

Epoch: 5| Step: 3
Training loss: 1.1805499792099
Validation loss: 1.9194245312803535

Epoch: 5| Step: 4
Training loss: 0.8925226330757141
Validation loss: 1.9245806432539416

Epoch: 5| Step: 5
Training loss: 1.6734403371810913
Validation loss: 1.9309446209220475

Epoch: 5| Step: 6
Training loss: 1.1855164766311646
Validation loss: 1.9399246746493923

Epoch: 5| Step: 7
Training loss: 1.0767778158187866
Validation loss: 1.9546484895931777

Epoch: 5| Step: 8
Training loss: 0.6566885709762573
Validation loss: 1.9404301361371112

Epoch: 5| Step: 9
Training loss: 1.4434592723846436
Validation loss: 1.9417155135062434

Epoch: 5| Step: 10
Training loss: 1.246806263923645
Validation loss: 1.9451688002514582

Epoch: 418| Step: 0
Training loss: 1.550747275352478
Validation loss: 1.9332172434817079

Epoch: 5| Step: 1
Training loss: 1.1491949558258057
Validation loss: 1.92021906375885

Epoch: 5| Step: 2
Training loss: 0.9720023274421692
Validation loss: 1.9182639903919672

Epoch: 5| Step: 3
Training loss: 1.0323086977005005
Validation loss: 1.930505426981116

Epoch: 5| Step: 4
Training loss: 1.2351233959197998
Validation loss: 1.9448870151273665

Epoch: 5| Step: 5
Training loss: 0.8993871808052063
Validation loss: 1.9407654077776018

Epoch: 5| Step: 6
Training loss: 1.4945347309112549
Validation loss: 1.948008410392269

Epoch: 5| Step: 7
Training loss: 1.0258102416992188
Validation loss: 1.9458035961274178

Epoch: 5| Step: 8
Training loss: 1.263146996498108
Validation loss: 1.9307890015263711

Epoch: 5| Step: 9
Training loss: 1.4207664728164673
Validation loss: 1.969890312481952

Epoch: 5| Step: 10
Training loss: 0.854102611541748
Validation loss: 1.9623713967620686

Epoch: 419| Step: 0
Training loss: 1.6760801076889038
Validation loss: 1.9608604907989502

Epoch: 5| Step: 1
Training loss: 1.0893656015396118
Validation loss: 1.9305839205300936

Epoch: 5| Step: 2
Training loss: 1.16661536693573
Validation loss: 1.9387176652108469

Epoch: 5| Step: 3
Training loss: 1.0387629270553589
Validation loss: 1.91848208186447

Epoch: 5| Step: 4
Training loss: 1.3014800548553467
Validation loss: 1.9079075923530004

Epoch: 5| Step: 5
Training loss: 0.818503737449646
Validation loss: 1.9226785372662287

Epoch: 5| Step: 6
Training loss: 0.7822328805923462
Validation loss: 1.9279254533911263

Epoch: 5| Step: 7
Training loss: 1.0948853492736816
Validation loss: 1.9483369947761617

Epoch: 5| Step: 8
Training loss: 1.4280357360839844
Validation loss: 1.9332933092630038

Epoch: 5| Step: 9
Training loss: 1.0746837854385376
Validation loss: 1.9636643855802474

Epoch: 5| Step: 10
Training loss: 1.304869294166565
Validation loss: 1.9635478860588484

Epoch: 420| Step: 0
Training loss: 1.0265921354293823
Validation loss: 1.9562026787829656

Epoch: 5| Step: 1
Training loss: 1.1720383167266846
Validation loss: 1.984761538685009

Epoch: 5| Step: 2
Training loss: 0.7386058568954468
Validation loss: 1.9778690504771408

Epoch: 5| Step: 3
Training loss: 1.1105644702911377
Validation loss: 1.9707478374563239

Epoch: 5| Step: 4
Training loss: 1.5337960720062256
Validation loss: 1.9654738954318467

Epoch: 5| Step: 5
Training loss: 0.9989862442016602
Validation loss: 1.9631148640827467

Epoch: 5| Step: 6
Training loss: 1.0405280590057373
Validation loss: 1.9503916873726794

Epoch: 5| Step: 7
Training loss: 1.5501257181167603
Validation loss: 1.9479109433389479

Epoch: 5| Step: 8
Training loss: 0.9854979515075684
Validation loss: 1.9677107231591338

Epoch: 5| Step: 9
Training loss: 1.4049774408340454
Validation loss: 1.9482493708210606

Epoch: 5| Step: 10
Training loss: 1.0317786931991577
Validation loss: 1.938354745987923

Epoch: 421| Step: 0
Training loss: 1.4237533807754517
Validation loss: 1.912837109258098

Epoch: 5| Step: 1
Training loss: 0.5106497406959534
Validation loss: 1.9107872927060692

Epoch: 5| Step: 2
Training loss: 1.3698339462280273
Validation loss: 1.8960922930830268

Epoch: 5| Step: 3
Training loss: 0.9795747995376587
Validation loss: 1.906052476616316

Epoch: 5| Step: 4
Training loss: 0.748592734336853
Validation loss: 1.9059948421293689

Epoch: 5| Step: 5
Training loss: 1.1910768747329712
Validation loss: 1.9414061833453435

Epoch: 5| Step: 6
Training loss: 0.7347256541252136
Validation loss: 1.9229251953863329

Epoch: 5| Step: 7
Training loss: 1.2062604427337646
Validation loss: 1.9427159345278175

Epoch: 5| Step: 8
Training loss: 1.4671754837036133
Validation loss: 1.9663854978417838

Epoch: 5| Step: 9
Training loss: 1.3331286907196045
Validation loss: 1.986722953857914

Epoch: 5| Step: 10
Training loss: 1.8018829822540283
Validation loss: 2.0245160005425893

Epoch: 422| Step: 0
Training loss: 0.9196357727050781
Validation loss: 2.014401424315668

Epoch: 5| Step: 1
Training loss: 1.3758348226547241
Validation loss: 1.999270708330216

Epoch: 5| Step: 2
Training loss: 1.3965638875961304
Validation loss: 1.9522186991988972

Epoch: 5| Step: 3
Training loss: 1.284682035446167
Validation loss: 1.9160540565367667

Epoch: 5| Step: 4
Training loss: 1.303680419921875
Validation loss: 1.8977072982377903

Epoch: 5| Step: 5
Training loss: 1.1213642358779907
Validation loss: 1.9046661430789578

Epoch: 5| Step: 6
Training loss: 1.2349271774291992
Validation loss: 1.8589598055808776

Epoch: 5| Step: 7
Training loss: 0.8145490884780884
Validation loss: 1.8685046139583792

Epoch: 5| Step: 8
Training loss: 0.8116370439529419
Validation loss: 1.8694790358184485

Epoch: 5| Step: 9
Training loss: 1.1872127056121826
Validation loss: 1.870832775228767

Epoch: 5| Step: 10
Training loss: 1.5606857538223267
Validation loss: 1.9014537231896513

Epoch: 423| Step: 0
Training loss: 1.4881293773651123
Validation loss: 1.9177064434174569

Epoch: 5| Step: 1
Training loss: 0.9387785792350769
Validation loss: 1.9552255907366354

Epoch: 5| Step: 2
Training loss: 1.1598823070526123
Validation loss: 1.99572616751476

Epoch: 5| Step: 3
Training loss: 1.3050483465194702
Validation loss: 2.0053347541439916

Epoch: 5| Step: 4
Training loss: 0.7959662079811096
Validation loss: 2.021098231756559

Epoch: 5| Step: 5
Training loss: 1.5771465301513672
Validation loss: 2.016365331988181

Epoch: 5| Step: 6
Training loss: 1.0433006286621094
Validation loss: 1.982614428766312

Epoch: 5| Step: 7
Training loss: 1.4057948589324951
Validation loss: 1.9613907106461064

Epoch: 5| Step: 8
Training loss: 1.0586113929748535
Validation loss: 1.909626958190754

Epoch: 5| Step: 9
Training loss: 1.2350199222564697
Validation loss: 1.8939582993907313

Epoch: 5| Step: 10
Training loss: 0.7441179752349854
Validation loss: 1.878566272797123

Epoch: 424| Step: 0
Training loss: 0.8476313352584839
Validation loss: 1.8728554710265128

Epoch: 5| Step: 1
Training loss: 1.129111647605896
Validation loss: 1.8723937003843245

Epoch: 5| Step: 2
Training loss: 0.9715784788131714
Validation loss: 1.9047799687231741

Epoch: 5| Step: 3
Training loss: 1.1300435066223145
Validation loss: 1.9235113692539993

Epoch: 5| Step: 4
Training loss: 1.1026500463485718
Validation loss: 1.922001108046501

Epoch: 5| Step: 5
Training loss: 1.1829700469970703
Validation loss: 1.958502705379199

Epoch: 5| Step: 6
Training loss: 1.4812637567520142
Validation loss: 1.9231780267530871

Epoch: 5| Step: 7
Training loss: 1.2136571407318115
Validation loss: 1.918990663302842

Epoch: 5| Step: 8
Training loss: 1.3709132671356201
Validation loss: 1.9395213998774046

Epoch: 5| Step: 9
Training loss: 0.9717009663581848
Validation loss: 1.9574362231839089

Epoch: 5| Step: 10
Training loss: 1.458673357963562
Validation loss: 1.9406664691945559

Epoch: 425| Step: 0
Training loss: 1.3530094623565674
Validation loss: 1.9397385030664422

Epoch: 5| Step: 1
Training loss: 1.1622090339660645
Validation loss: 1.919646422068278

Epoch: 5| Step: 2
Training loss: 0.8591110110282898
Validation loss: 1.920679811508425

Epoch: 5| Step: 3
Training loss: 1.139149785041809
Validation loss: 1.9353294782741095

Epoch: 5| Step: 4
Training loss: 0.7869659662246704
Validation loss: 1.9111931067641064

Epoch: 5| Step: 5
Training loss: 1.3983572721481323
Validation loss: 1.921903738411524

Epoch: 5| Step: 6
Training loss: 1.370922327041626
Validation loss: 1.9311431812983688

Epoch: 5| Step: 7
Training loss: 0.8212936520576477
Validation loss: 1.9060967558173723

Epoch: 5| Step: 8
Training loss: 0.8337920308113098
Validation loss: 1.8835474457792056

Epoch: 5| Step: 9
Training loss: 1.4281963109970093
Validation loss: 1.9000599384307861

Epoch: 5| Step: 10
Training loss: 1.2741930484771729
Validation loss: 1.9060284604308426

Epoch: 426| Step: 0
Training loss: 0.995090126991272
Validation loss: 1.9107532321765859

Epoch: 5| Step: 1
Training loss: 1.3923128843307495
Validation loss: 1.89744657598516

Epoch: 5| Step: 2
Training loss: 0.8499347567558289
Validation loss: 1.907097557539581

Epoch: 5| Step: 3
Training loss: 1.4062210321426392
Validation loss: 1.918955401707721

Epoch: 5| Step: 4
Training loss: 1.0150583982467651
Validation loss: 1.916135335481295

Epoch: 5| Step: 5
Training loss: 1.1888200044631958
Validation loss: 1.9415160917466687

Epoch: 5| Step: 6
Training loss: 0.9200295209884644
Validation loss: 1.932007711420777

Epoch: 5| Step: 7
Training loss: 0.9945025444030762
Validation loss: 1.939685977915282

Epoch: 5| Step: 8
Training loss: 1.1489274501800537
Validation loss: 1.9485286384500482

Epoch: 5| Step: 9
Training loss: 1.0005203485488892
Validation loss: 1.9398027209825413

Epoch: 5| Step: 10
Training loss: 1.4446401596069336
Validation loss: 1.9198099336316508

Epoch: 427| Step: 0
Training loss: 1.2343566417694092
Validation loss: 1.9295509720361361

Epoch: 5| Step: 1
Training loss: 1.3384631872177124
Validation loss: 1.9010110875611663

Epoch: 5| Step: 2
Training loss: 1.0578856468200684
Validation loss: 1.8769310571814095

Epoch: 5| Step: 3
Training loss: 0.9515509605407715
Validation loss: 1.885036619760657

Epoch: 5| Step: 4
Training loss: 0.5558332204818726
Validation loss: 1.8939840332154305

Epoch: 5| Step: 5
Training loss: 1.102471947669983
Validation loss: 1.9182622842891242

Epoch: 5| Step: 6
Training loss: 1.6180601119995117
Validation loss: 1.9217560099017235

Epoch: 5| Step: 7
Training loss: 1.2118147611618042
Validation loss: 1.9334031330641879

Epoch: 5| Step: 8
Training loss: 0.9658874273300171
Validation loss: 1.9202042882160475

Epoch: 5| Step: 9
Training loss: 1.4287668466567993
Validation loss: 1.925470696982517

Epoch: 5| Step: 10
Training loss: 0.7707895040512085
Validation loss: 1.9230791650792605

Epoch: 428| Step: 0
Training loss: 0.826402485370636
Validation loss: 1.9143509249533377

Epoch: 5| Step: 1
Training loss: 1.1056346893310547
Validation loss: 1.916784858190885

Epoch: 5| Step: 2
Training loss: 1.262572169303894
Validation loss: 1.9613600277131604

Epoch: 5| Step: 3
Training loss: 1.2570374011993408
Validation loss: 1.9712422701620287

Epoch: 5| Step: 4
Training loss: 1.44381582736969
Validation loss: 1.9816408259894258

Epoch: 5| Step: 5
Training loss: 1.3057774305343628
Validation loss: 2.00197559402835

Epoch: 5| Step: 6
Training loss: 0.9200693964958191
Validation loss: 2.022891534272061

Epoch: 5| Step: 7
Training loss: 1.049783706665039
Validation loss: 2.0152933072018366

Epoch: 5| Step: 8
Training loss: 1.2199375629425049
Validation loss: 2.009411302945947

Epoch: 5| Step: 9
Training loss: 1.2667953968048096
Validation loss: 1.9627244857049757

Epoch: 5| Step: 10
Training loss: 0.9617782831192017
Validation loss: 1.9277985685615129

Epoch: 429| Step: 0
Training loss: 0.8107885122299194
Validation loss: 1.893246498159183

Epoch: 5| Step: 1
Training loss: 1.1154532432556152
Validation loss: 1.8671496170823292

Epoch: 5| Step: 2
Training loss: 1.316075325012207
Validation loss: 1.855329204631108

Epoch: 5| Step: 3
Training loss: 1.274091124534607
Validation loss: 1.8488325854783416

Epoch: 5| Step: 4
Training loss: 1.2867295742034912
Validation loss: 1.8262869081189554

Epoch: 5| Step: 5
Training loss: 0.8160296678543091
Validation loss: 1.8490315163007347

Epoch: 5| Step: 6
Training loss: 1.0287812948226929
Validation loss: 1.83464511235555

Epoch: 5| Step: 7
Training loss: 1.388959288597107
Validation loss: 1.8722445131630026

Epoch: 5| Step: 8
Training loss: 1.1567209959030151
Validation loss: 1.8680255361782607

Epoch: 5| Step: 9
Training loss: 1.0976173877716064
Validation loss: 1.9065834335101548

Epoch: 5| Step: 10
Training loss: 1.1333703994750977
Validation loss: 1.94535820586707

Epoch: 430| Step: 0
Training loss: 0.9202245473861694
Validation loss: 2.0021838347117105

Epoch: 5| Step: 1
Training loss: 0.7180505990982056
Validation loss: 1.9765999470987627

Epoch: 5| Step: 2
Training loss: 1.1479146480560303
Validation loss: 1.992773381612634

Epoch: 5| Step: 3
Training loss: 1.2530627250671387
Validation loss: 1.9741596265505719

Epoch: 5| Step: 4
Training loss: 1.5123308897018433
Validation loss: 1.959807126752792

Epoch: 5| Step: 5
Training loss: 1.301858901977539
Validation loss: 1.9085762885309034

Epoch: 5| Step: 6
Training loss: 1.3939554691314697
Validation loss: 1.8922131035917549

Epoch: 5| Step: 7
Training loss: 0.7467875480651855
Validation loss: 1.8626509648497387

Epoch: 5| Step: 8
Training loss: 1.2887026071548462
Validation loss: 1.8348459569356774

Epoch: 5| Step: 9
Training loss: 0.6481418609619141
Validation loss: 1.8412149619030695

Epoch: 5| Step: 10
Training loss: 1.5312902927398682
Validation loss: 1.8174687277886175

Epoch: 431| Step: 0
Training loss: 1.3167989253997803
Validation loss: 1.8370605117531233

Epoch: 5| Step: 1
Training loss: 0.8395160436630249
Validation loss: 1.8660157854839037

Epoch: 5| Step: 2
Training loss: 1.6445846557617188
Validation loss: 1.8781205043997815

Epoch: 5| Step: 3
Training loss: 0.811251163482666
Validation loss: 1.8701043667331818

Epoch: 5| Step: 4
Training loss: 1.1363532543182373
Validation loss: 1.9032681936858802

Epoch: 5| Step: 5
Training loss: 1.1584842205047607
Validation loss: 1.927751002773162

Epoch: 5| Step: 6
Training loss: 0.8912011981010437
Validation loss: 1.9349328382040865

Epoch: 5| Step: 7
Training loss: 1.5970042943954468
Validation loss: 1.9442970214351531

Epoch: 5| Step: 8
Training loss: 0.7256872653961182
Validation loss: 1.9520719897362493

Epoch: 5| Step: 9
Training loss: 1.1918487548828125
Validation loss: 1.9870581114163963

Epoch: 5| Step: 10
Training loss: 0.9327031970024109
Validation loss: 1.9720722782996394

Epoch: 432| Step: 0
Training loss: 1.0662734508514404
Validation loss: 1.9515257650806057

Epoch: 5| Step: 1
Training loss: 1.5851701498031616
Validation loss: 1.9456088581392843

Epoch: 5| Step: 2
Training loss: 1.2367528676986694
Validation loss: 1.9395041888759983

Epoch: 5| Step: 3
Training loss: 0.9852951765060425
Validation loss: 1.95294056400176

Epoch: 5| Step: 4
Training loss: 0.8506689071655273
Validation loss: 1.9350516603839012

Epoch: 5| Step: 5
Training loss: 1.4679532051086426
Validation loss: 1.911562660688995

Epoch: 5| Step: 6
Training loss: 1.3258088827133179
Validation loss: 1.8902850663790138

Epoch: 5| Step: 7
Training loss: 0.5681261420249939
Validation loss: 1.8232115558398667

Epoch: 5| Step: 8
Training loss: 0.8972452878952026
Validation loss: 1.8377132749044767

Epoch: 5| Step: 9
Training loss: 1.0863206386566162
Validation loss: 1.8196695991741714

Epoch: 5| Step: 10
Training loss: 1.2718058824539185
Validation loss: 1.8267743472130067

Epoch: 433| Step: 0
Training loss: 1.4162158966064453
Validation loss: 1.8555887463272258

Epoch: 5| Step: 1
Training loss: 1.1238384246826172
Validation loss: 1.8763760802566365

Epoch: 5| Step: 2
Training loss: 1.0864765644073486
Validation loss: 1.8948069657048872

Epoch: 5| Step: 3
Training loss: 1.4868667125701904
Validation loss: 1.9471863405678862

Epoch: 5| Step: 4
Training loss: 1.2375717163085938
Validation loss: 1.9745077779216151

Epoch: 5| Step: 5
Training loss: 1.2043304443359375
Validation loss: 1.971617688414871

Epoch: 5| Step: 6
Training loss: 1.2015012502670288
Validation loss: 1.974460571042953

Epoch: 5| Step: 7
Training loss: 0.6553875207901001
Validation loss: 1.9554346235849525

Epoch: 5| Step: 8
Training loss: 1.1808174848556519
Validation loss: 1.9346767292227796

Epoch: 5| Step: 9
Training loss: 1.1072990894317627
Validation loss: 1.9061578396827943

Epoch: 5| Step: 10
Training loss: 0.8566336035728455
Validation loss: 1.8898141140578895

Epoch: 434| Step: 0
Training loss: 1.2565932273864746
Validation loss: 1.8614402406959123

Epoch: 5| Step: 1
Training loss: 1.106353998184204
Validation loss: 1.8624370905660814

Epoch: 5| Step: 2
Training loss: 0.9077293276786804
Validation loss: 1.8574703085807063

Epoch: 5| Step: 3
Training loss: 0.8134166598320007
Validation loss: 1.8717944365675732

Epoch: 5| Step: 4
Training loss: 1.6258004903793335
Validation loss: 1.9020866975989392

Epoch: 5| Step: 5
Training loss: 0.9789673089981079
Validation loss: 1.9292862787041614

Epoch: 5| Step: 6
Training loss: 0.9084679484367371
Validation loss: 1.956366938929404

Epoch: 5| Step: 7
Training loss: 1.24115788936615
Validation loss: 1.999801835706157

Epoch: 5| Step: 8
Training loss: 1.0744619369506836
Validation loss: 2.0504424700173

Epoch: 5| Step: 9
Training loss: 1.3300844430923462
Validation loss: 2.063943429659772

Epoch: 5| Step: 10
Training loss: 1.2904596328735352
Validation loss: 2.0588474606954925

Epoch: 435| Step: 0
Training loss: 0.8357501029968262
Validation loss: 2.0618447706263554

Epoch: 5| Step: 1
Training loss: 1.224542260169983
Validation loss: 2.0152131818955943

Epoch: 5| Step: 2
Training loss: 1.269995093345642
Validation loss: 1.9709086366879043

Epoch: 5| Step: 3
Training loss: 1.1232397556304932
Validation loss: 1.9304263091856433

Epoch: 5| Step: 4
Training loss: 0.9036356210708618
Validation loss: 1.9150935270453011

Epoch: 5| Step: 5
Training loss: 1.3004734516143799
Validation loss: 1.90373856277876

Epoch: 5| Step: 6
Training loss: 1.2404050827026367
Validation loss: 1.8804318776694677

Epoch: 5| Step: 7
Training loss: 1.2269632816314697
Validation loss: 1.8807166045711887

Epoch: 5| Step: 8
Training loss: 1.0578858852386475
Validation loss: 1.8720597644006052

Epoch: 5| Step: 9
Training loss: 0.8464387059211731
Validation loss: 1.867725855560713

Epoch: 5| Step: 10
Training loss: 1.332943320274353
Validation loss: 1.8743380936243201

Epoch: 436| Step: 0
Training loss: 0.7832576036453247
Validation loss: 1.8833159028842885

Epoch: 5| Step: 1
Training loss: 1.3250200748443604
Validation loss: 1.8944764855087444

Epoch: 5| Step: 2
Training loss: 1.3333442211151123
Validation loss: 1.936821667096948

Epoch: 5| Step: 3
Training loss: 1.1648938655853271
Validation loss: 1.9372608482196767

Epoch: 5| Step: 4
Training loss: 1.2768125534057617
Validation loss: 1.9507145522743143

Epoch: 5| Step: 5
Training loss: 0.6962940692901611
Validation loss: 1.941455243736185

Epoch: 5| Step: 6
Training loss: 0.8210298418998718
Validation loss: 1.8992513456652242

Epoch: 5| Step: 7
Training loss: 0.720405638217926
Validation loss: 1.9139503637949626

Epoch: 5| Step: 8
Training loss: 1.5542943477630615
Validation loss: 1.8933099303194272

Epoch: 5| Step: 9
Training loss: 1.235740303993225
Validation loss: 1.9008831593298143

Epoch: 5| Step: 10
Training loss: 0.9175069332122803
Validation loss: 1.8783068503102949

Epoch: 437| Step: 0
Training loss: 1.2086400985717773
Validation loss: 1.9093114291467974

Epoch: 5| Step: 1
Training loss: 1.2123019695281982
Validation loss: 1.9109339150049354

Epoch: 5| Step: 2
Training loss: 0.8268700838088989
Validation loss: 1.9420651197433472

Epoch: 5| Step: 3
Training loss: 0.8417589068412781
Validation loss: 1.9598510726805656

Epoch: 5| Step: 4
Training loss: 0.9358344078063965
Validation loss: 1.9666430129799792

Epoch: 5| Step: 5
Training loss: 1.064653754234314
Validation loss: 1.9670636371899677

Epoch: 5| Step: 6
Training loss: 1.7504396438598633
Validation loss: 1.9377702743776384

Epoch: 5| Step: 7
Training loss: 0.9414070248603821
Validation loss: 1.916933701884362

Epoch: 5| Step: 8
Training loss: 0.9494593739509583
Validation loss: 1.9408665241733674

Epoch: 5| Step: 9
Training loss: 0.8488532900810242
Validation loss: 1.9410497885878368

Epoch: 5| Step: 10
Training loss: 1.3005658388137817
Validation loss: 1.913957932943939

Epoch: 438| Step: 0
Training loss: 0.7545692324638367
Validation loss: 1.8929222770916518

Epoch: 5| Step: 1
Training loss: 0.6226642727851868
Validation loss: 1.8832864440897459

Epoch: 5| Step: 2
Training loss: 1.4502030611038208
Validation loss: 1.8707430388337822

Epoch: 5| Step: 3
Training loss: 0.9590821266174316
Validation loss: 1.8731665675358107

Epoch: 5| Step: 4
Training loss: 0.7820863723754883
Validation loss: 1.8564536994503391

Epoch: 5| Step: 5
Training loss: 1.192867636680603
Validation loss: 1.8687736039520593

Epoch: 5| Step: 6
Training loss: 1.1792447566986084
Validation loss: 1.8510840733846028

Epoch: 5| Step: 7
Training loss: 1.5151360034942627
Validation loss: 1.865349764465004

Epoch: 5| Step: 8
Training loss: 0.8351081609725952
Validation loss: 1.9025144602662774

Epoch: 5| Step: 9
Training loss: 1.0047788619995117
Validation loss: 1.907675322665963

Epoch: 5| Step: 10
Training loss: 1.4855377674102783
Validation loss: 1.9159168466444938

Epoch: 439| Step: 0
Training loss: 1.1289342641830444
Validation loss: 1.9396295316757695

Epoch: 5| Step: 1
Training loss: 0.5711795687675476
Validation loss: 1.8988798510643743

Epoch: 5| Step: 2
Training loss: 0.739068865776062
Validation loss: 1.912113658843502

Epoch: 5| Step: 3
Training loss: 1.3253743648529053
Validation loss: 1.9291053113117014

Epoch: 5| Step: 4
Training loss: 1.1347534656524658
Validation loss: 1.9047568716028684

Epoch: 5| Step: 5
Training loss: 1.613459825515747
Validation loss: 1.909013339268264

Epoch: 5| Step: 6
Training loss: 1.0181964635849
Validation loss: 1.8851913367548296

Epoch: 5| Step: 7
Training loss: 1.1387293338775635
Validation loss: 1.8821190916081911

Epoch: 5| Step: 8
Training loss: 0.7794438600540161
Validation loss: 1.877302139036117

Epoch: 5| Step: 9
Training loss: 1.0835024118423462
Validation loss: 1.8751646985289872

Epoch: 5| Step: 10
Training loss: 1.082677960395813
Validation loss: 1.8649143044666578

Epoch: 440| Step: 0
Training loss: 1.0846143960952759
Validation loss: 1.8588767346515451

Epoch: 5| Step: 1
Training loss: 1.4136282205581665
Validation loss: 1.88926483995171

Epoch: 5| Step: 2
Training loss: 1.0620735883712769
Validation loss: 1.9071599706526725

Epoch: 5| Step: 3
Training loss: 0.5534506440162659
Validation loss: 1.9347837355829054

Epoch: 5| Step: 4
Training loss: 1.568181037902832
Validation loss: 1.8912984837767899

Epoch: 5| Step: 5
Training loss: 1.0179682970046997
Validation loss: 1.9103231404417305

Epoch: 5| Step: 6
Training loss: 1.1645923852920532
Validation loss: 1.912014797169675

Epoch: 5| Step: 7
Training loss: 0.6904522180557251
Validation loss: 1.885064172488387

Epoch: 5| Step: 8
Training loss: 0.8352670669555664
Validation loss: 1.8853678626398886

Epoch: 5| Step: 9
Training loss: 0.8167566061019897
Validation loss: 1.8919355741111181

Epoch: 5| Step: 10
Training loss: 1.4332990646362305
Validation loss: 1.8988497769960793

Epoch: 441| Step: 0
Training loss: 0.5101259350776672
Validation loss: 1.8977313451869513

Epoch: 5| Step: 1
Training loss: 1.2554658651351929
Validation loss: 1.9131358926014235

Epoch: 5| Step: 2
Training loss: 1.555083990097046
Validation loss: 1.8955805327302666

Epoch: 5| Step: 3
Training loss: 0.8491135835647583
Validation loss: 1.9170979351125739

Epoch: 5| Step: 4
Training loss: 1.1043630838394165
Validation loss: 1.9003590037745814

Epoch: 5| Step: 5
Training loss: 0.9091925621032715
Validation loss: 1.907779621821578

Epoch: 5| Step: 6
Training loss: 1.193272590637207
Validation loss: 1.9152032534281414

Epoch: 5| Step: 7
Training loss: 1.3443973064422607
Validation loss: 1.9154005178841211

Epoch: 5| Step: 8
Training loss: 0.8505458831787109
Validation loss: 1.9273422123283468

Epoch: 5| Step: 9
Training loss: 1.2601312398910522
Validation loss: 1.9176808070111018

Epoch: 5| Step: 10
Training loss: 0.6597074866294861
Validation loss: 1.9378201653880458

Epoch: 442| Step: 0
Training loss: 1.435368299484253
Validation loss: 1.9075538266089656

Epoch: 5| Step: 1
Training loss: 1.2846930027008057
Validation loss: 1.917835726532885

Epoch: 5| Step: 2
Training loss: 1.0641701221466064
Validation loss: 1.9117610441741122

Epoch: 5| Step: 3
Training loss: 0.8312228918075562
Validation loss: 1.9254680359235374

Epoch: 5| Step: 4
Training loss: 1.042111873626709
Validation loss: 1.917009179310132

Epoch: 5| Step: 5
Training loss: 1.2622791528701782
Validation loss: 1.8984703351092596

Epoch: 5| Step: 6
Training loss: 0.7410513162612915
Validation loss: 1.89130356747617

Epoch: 5| Step: 7
Training loss: 1.1217292547225952
Validation loss: 1.874436793788787

Epoch: 5| Step: 8
Training loss: 1.1120672225952148
Validation loss: 1.856141996640031

Epoch: 5| Step: 9
Training loss: 0.7835678458213806
Validation loss: 1.8572364571273967

Epoch: 5| Step: 10
Training loss: 0.8419297933578491
Validation loss: 1.837367514128326

Epoch: 443| Step: 0
Training loss: 1.2217984199523926
Validation loss: 1.8376815985607844

Epoch: 5| Step: 1
Training loss: 0.6858102679252625
Validation loss: 1.8285980955246957

Epoch: 5| Step: 2
Training loss: 1.0662178993225098
Validation loss: 1.8247244845154464

Epoch: 5| Step: 3
Training loss: 1.1556196212768555
Validation loss: 1.8675297267975346

Epoch: 5| Step: 4
Training loss: 0.8329126238822937
Validation loss: 1.8872431016737414

Epoch: 5| Step: 5
Training loss: 1.1123955249786377
Validation loss: 1.8984378653187906

Epoch: 5| Step: 6
Training loss: 1.0496548414230347
Validation loss: 1.9154718204211163

Epoch: 5| Step: 7
Training loss: 1.2290363311767578
Validation loss: 1.913257242530905

Epoch: 5| Step: 8
Training loss: 0.5320833921432495
Validation loss: 1.9327650685464182

Epoch: 5| Step: 9
Training loss: 1.672751784324646
Validation loss: 1.9611221205803655

Epoch: 5| Step: 10
Training loss: 1.011609435081482
Validation loss: 1.9458132738708167

Epoch: 444| Step: 0
Training loss: 1.1063202619552612
Validation loss: 1.9555114071856263

Epoch: 5| Step: 1
Training loss: 1.4059553146362305
Validation loss: 1.9788647120998752

Epoch: 5| Step: 2
Training loss: 1.074806809425354
Validation loss: 1.9512519938971407

Epoch: 5| Step: 3
Training loss: 0.9346297979354858
Validation loss: 1.9215055947662683

Epoch: 5| Step: 4
Training loss: 0.5589068531990051
Validation loss: 1.9102637280700028

Epoch: 5| Step: 5
Training loss: 0.7705646753311157
Validation loss: 1.8873488364681121

Epoch: 5| Step: 6
Training loss: 1.3294559717178345
Validation loss: 1.8843602339426677

Epoch: 5| Step: 7
Training loss: 1.1563044786453247
Validation loss: 1.8895749225411365

Epoch: 5| Step: 8
Training loss: 1.0826842784881592
Validation loss: 1.8762383178998066

Epoch: 5| Step: 9
Training loss: 1.0141249895095825
Validation loss: 1.9026177621656848

Epoch: 5| Step: 10
Training loss: 1.0642305612564087
Validation loss: 1.8792692692049089

Epoch: 445| Step: 0
Training loss: 1.019474744796753
Validation loss: 1.8810481127872263

Epoch: 5| Step: 1
Training loss: 1.4405691623687744
Validation loss: 1.8771131807757961

Epoch: 5| Step: 2
Training loss: 0.7446464896202087
Validation loss: 1.881137494117983

Epoch: 5| Step: 3
Training loss: 1.1860787868499756
Validation loss: 1.8907469882759997

Epoch: 5| Step: 4
Training loss: 1.149278163909912
Validation loss: 1.8979050561945925

Epoch: 5| Step: 5
Training loss: 0.9763075709342957
Validation loss: 1.8809013097516951

Epoch: 5| Step: 6
Training loss: 1.0052413940429688
Validation loss: 1.924217011338921

Epoch: 5| Step: 7
Training loss: 0.8240293264389038
Validation loss: 1.899821853124967

Epoch: 5| Step: 8
Training loss: 0.9762014150619507
Validation loss: 1.9183862811775618

Epoch: 5| Step: 9
Training loss: 1.0229268074035645
Validation loss: 1.9140996625346522

Epoch: 5| Step: 10
Training loss: 1.053632140159607
Validation loss: 1.89742027431406

Epoch: 446| Step: 0
Training loss: 0.7580605745315552
Validation loss: 1.898482959757569

Epoch: 5| Step: 1
Training loss: 1.1264160871505737
Validation loss: 1.915704737427414

Epoch: 5| Step: 2
Training loss: 1.1388605833053589
Validation loss: 1.9319386136147283

Epoch: 5| Step: 3
Training loss: 1.5229324102401733
Validation loss: 1.9385478573460733

Epoch: 5| Step: 4
Training loss: 1.1764687299728394
Validation loss: 1.9345267959820327

Epoch: 5| Step: 5
Training loss: 0.5891772508621216
Validation loss: 1.9250659865717734

Epoch: 5| Step: 6
Training loss: 0.743449330329895
Validation loss: 1.898422723175377

Epoch: 5| Step: 7
Training loss: 1.2947380542755127
Validation loss: 1.8944653067537534

Epoch: 5| Step: 8
Training loss: 0.56617671251297
Validation loss: 1.882285838486046

Epoch: 5| Step: 9
Training loss: 1.1222082376480103
Validation loss: 1.8804761478977818

Epoch: 5| Step: 10
Training loss: 1.4233970642089844
Validation loss: 1.8795483368699268

Epoch: 447| Step: 0
Training loss: 1.1090714931488037
Validation loss: 1.87774436320028

Epoch: 5| Step: 1
Training loss: 0.9912988543510437
Validation loss: 1.8803433807947303

Epoch: 5| Step: 2
Training loss: 1.1809972524642944
Validation loss: 1.8935121746473416

Epoch: 5| Step: 3
Training loss: 0.7870925664901733
Validation loss: 1.8968996463283416

Epoch: 5| Step: 4
Training loss: 1.4857103824615479
Validation loss: 1.91463122060222

Epoch: 5| Step: 5
Training loss: 1.1613273620605469
Validation loss: 1.915228202778806

Epoch: 5| Step: 6
Training loss: 1.2906876802444458
Validation loss: 1.919104096710041

Epoch: 5| Step: 7
Training loss: 1.0612019300460815
Validation loss: 1.8869831779951691

Epoch: 5| Step: 8
Training loss: 0.6879708170890808
Validation loss: 1.8909434580033826

Epoch: 5| Step: 9
Training loss: 0.725982666015625
Validation loss: 1.8963217402017245

Epoch: 5| Step: 10
Training loss: 0.8379608392715454
Validation loss: 1.911236737364082

Epoch: 448| Step: 0
Training loss: 0.6873277425765991
Validation loss: 1.91897568907789

Epoch: 5| Step: 1
Training loss: 1.2499185800552368
Validation loss: 1.9056342096738919

Epoch: 5| Step: 2
Training loss: 0.9278661608695984
Validation loss: 1.9048491857385124

Epoch: 5| Step: 3
Training loss: 0.7965188026428223
Validation loss: 1.9227871177017049

Epoch: 5| Step: 4
Training loss: 1.988621473312378
Validation loss: 1.9076681265266993

Epoch: 5| Step: 5
Training loss: 0.5393761992454529
Validation loss: 1.917251048549529

Epoch: 5| Step: 6
Training loss: 0.5839245915412903
Validation loss: 1.9189403698008547

Epoch: 5| Step: 7
Training loss: 1.254112958908081
Validation loss: 1.8689334956548547

Epoch: 5| Step: 8
Training loss: 1.061896562576294
Validation loss: 1.884374503166445

Epoch: 5| Step: 9
Training loss: 1.0463073253631592
Validation loss: 1.8733490820853942

Epoch: 5| Step: 10
Training loss: 1.0242642164230347
Validation loss: 1.8917759003177765

Epoch: 449| Step: 0
Training loss: 1.0812981128692627
Validation loss: 1.8766360244443339

Epoch: 5| Step: 1
Training loss: 1.230082392692566
Validation loss: 1.8932853591057561

Epoch: 5| Step: 2
Training loss: 0.8430131673812866
Validation loss: 1.9114499835557834

Epoch: 5| Step: 3
Training loss: 1.253953218460083
Validation loss: 1.942782421265879

Epoch: 5| Step: 4
Training loss: 0.7151206731796265
Validation loss: 1.9526681618023944

Epoch: 5| Step: 5
Training loss: 1.2141063213348389
Validation loss: 1.9383824461249894

Epoch: 5| Step: 6
Training loss: 1.709233283996582
Validation loss: 1.9646807229647072

Epoch: 5| Step: 7
Training loss: 0.4884629249572754
Validation loss: 1.9593693633233347

Epoch: 5| Step: 8
Training loss: 1.0121017694473267
Validation loss: 1.9301589804310952

Epoch: 5| Step: 9
Training loss: 0.9605344533920288
Validation loss: 1.9176304442908174

Epoch: 5| Step: 10
Training loss: 0.7474672794342041
Validation loss: 1.8892513628928893

Epoch: 450| Step: 0
Training loss: 0.7464742660522461
Validation loss: 1.8917772026472195

Epoch: 5| Step: 1
Training loss: 1.4337753057479858
Validation loss: 1.9117987309732745

Epoch: 5| Step: 2
Training loss: 1.4539304971694946
Validation loss: 1.9281238086761967

Epoch: 5| Step: 3
Training loss: 0.6956628561019897
Validation loss: 1.9285455749880882

Epoch: 5| Step: 4
Training loss: 0.9162658452987671
Validation loss: 1.9257618919495614

Epoch: 5| Step: 5
Training loss: 1.1927947998046875
Validation loss: 1.9408898404849473

Epoch: 5| Step: 6
Training loss: 1.3950086832046509
Validation loss: 1.921166249500808

Epoch: 5| Step: 7
Training loss: 0.8759571313858032
Validation loss: 1.919107356379109

Epoch: 5| Step: 8
Training loss: 0.8260809779167175
Validation loss: 1.9310991866614229

Epoch: 5| Step: 9
Training loss: 0.5933054089546204
Validation loss: 1.906967350231704

Epoch: 5| Step: 10
Training loss: 0.9675508141517639
Validation loss: 1.919161924751856

Epoch: 451| Step: 0
Training loss: 0.9655725359916687
Validation loss: 1.9245713756930443

Epoch: 5| Step: 1
Training loss: 0.8425960540771484
Validation loss: 1.895954849899456

Epoch: 5| Step: 2
Training loss: 0.9595030546188354
Validation loss: 1.8844541170263802

Epoch: 5| Step: 3
Training loss: 1.1137083768844604
Validation loss: 1.9002811113993328

Epoch: 5| Step: 4
Training loss: 0.9735504388809204
Validation loss: 1.8708856490350538

Epoch: 5| Step: 5
Training loss: 0.649307370185852
Validation loss: 1.8980978919613747

Epoch: 5| Step: 6
Training loss: 1.1982070207595825
Validation loss: 1.9017575171685988

Epoch: 5| Step: 7
Training loss: 1.0433484315872192
Validation loss: 1.903922329666794

Epoch: 5| Step: 8
Training loss: 0.8460854291915894
Validation loss: 1.8930006873223089

Epoch: 5| Step: 9
Training loss: 1.0333762168884277
Validation loss: 1.9043325467776226

Epoch: 5| Step: 10
Training loss: 1.3713382482528687
Validation loss: 1.9174941278273059

Epoch: 452| Step: 0
Training loss: 1.1589453220367432
Validation loss: 1.9000512015435003

Epoch: 5| Step: 1
Training loss: 0.562649130821228
Validation loss: 1.916309993754151

Epoch: 5| Step: 2
Training loss: 0.6047298312187195
Validation loss: 1.9297923516201716

Epoch: 5| Step: 3
Training loss: 0.6211806535720825
Validation loss: 1.9375391365379415

Epoch: 5| Step: 4
Training loss: 1.1374770402908325
Validation loss: 1.9279025370074856

Epoch: 5| Step: 5
Training loss: 0.8303607702255249
Validation loss: 1.908308261184282

Epoch: 5| Step: 6
Training loss: 1.1458251476287842
Validation loss: 1.912631711652202

Epoch: 5| Step: 7
Training loss: 1.6803724765777588
Validation loss: 1.885931432888072

Epoch: 5| Step: 8
Training loss: 1.1636842489242554
Validation loss: 1.8818031357180687

Epoch: 5| Step: 9
Training loss: 1.0733492374420166
Validation loss: 1.8709532163476432

Epoch: 5| Step: 10
Training loss: 1.0306576490402222
Validation loss: 1.8644311428070068

Epoch: 453| Step: 0
Training loss: 0.6473767161369324
Validation loss: 1.8796223036704525

Epoch: 5| Step: 1
Training loss: 1.3074710369110107
Validation loss: 1.8760497493128623

Epoch: 5| Step: 2
Training loss: 0.9608144760131836
Validation loss: 1.864900876117009

Epoch: 5| Step: 3
Training loss: 0.772726833820343
Validation loss: 1.8514889171046596

Epoch: 5| Step: 4
Training loss: 1.1518590450286865
Validation loss: 1.8449067851548553

Epoch: 5| Step: 5
Training loss: 0.43600645661354065
Validation loss: 1.8604230444918397

Epoch: 5| Step: 6
Training loss: 1.0580085515975952
Validation loss: 1.8623152599539807

Epoch: 5| Step: 7
Training loss: 1.2527010440826416
Validation loss: 1.8747484837808917

Epoch: 5| Step: 8
Training loss: 0.9886578321456909
Validation loss: 1.875392424162998

Epoch: 5| Step: 9
Training loss: 1.1902731657028198
Validation loss: 1.8673461624371108

Epoch: 5| Step: 10
Training loss: 1.0868077278137207
Validation loss: 1.877681291231545

Epoch: 454| Step: 0
Training loss: 0.9257615804672241
Validation loss: 1.8956709446445588

Epoch: 5| Step: 1
Training loss: 1.0127251148223877
Validation loss: 1.883996812246179

Epoch: 5| Step: 2
Training loss: 0.9885579347610474
Validation loss: 1.8555614948272705

Epoch: 5| Step: 3
Training loss: 1.1223111152648926
Validation loss: 1.8712082857726722

Epoch: 5| Step: 4
Training loss: 1.1604961156845093
Validation loss: 1.873844797893237

Epoch: 5| Step: 5
Training loss: 0.45323801040649414
Validation loss: 1.8659537966533373

Epoch: 5| Step: 6
Training loss: 0.9485839605331421
Validation loss: 1.8998773559447257

Epoch: 5| Step: 7
Training loss: 0.9437091946601868
Validation loss: 1.8846750336308633

Epoch: 5| Step: 8
Training loss: 1.2274131774902344
Validation loss: 1.8871447065825104

Epoch: 5| Step: 9
Training loss: 1.0180308818817139
Validation loss: 1.9118012356501755

Epoch: 5| Step: 10
Training loss: 1.1149792671203613
Validation loss: 1.9045779653774795

Epoch: 455| Step: 0
Training loss: 0.8954033851623535
Validation loss: 1.8770888210624777

Epoch: 5| Step: 1
Training loss: 1.2115814685821533
Validation loss: 1.8873174062339209

Epoch: 5| Step: 2
Training loss: 0.49337929487228394
Validation loss: 1.893992083047026

Epoch: 5| Step: 3
Training loss: 0.973910927772522
Validation loss: 1.9038602036814536

Epoch: 5| Step: 4
Training loss: 1.3336734771728516
Validation loss: 1.9356553195625223

Epoch: 5| Step: 5
Training loss: 0.6740326881408691
Validation loss: 1.9081777039394583

Epoch: 5| Step: 6
Training loss: 0.7393392324447632
Validation loss: 1.9058260558753886

Epoch: 5| Step: 7
Training loss: 1.350508451461792
Validation loss: 1.9083174954178512

Epoch: 5| Step: 8
Training loss: 0.869881808757782
Validation loss: 1.8924878399859193

Epoch: 5| Step: 9
Training loss: 1.497120976448059
Validation loss: 1.8941612730744064

Epoch: 5| Step: 10
Training loss: 0.7384133338928223
Validation loss: 1.8630888192884383

Epoch: 456| Step: 0
Training loss: 1.0580627918243408
Validation loss: 1.8886020811655189

Epoch: 5| Step: 1
Training loss: 1.1902196407318115
Validation loss: 1.888012779656277

Epoch: 5| Step: 2
Training loss: 1.3973370790481567
Validation loss: 1.8982896702263945

Epoch: 5| Step: 3
Training loss: 0.8811031579971313
Validation loss: 1.8498037438238821

Epoch: 5| Step: 4
Training loss: 1.0919396877288818
Validation loss: 1.8720228646391182

Epoch: 5| Step: 5
Training loss: 0.9008030891418457
Validation loss: 1.8805705373005202

Epoch: 5| Step: 6
Training loss: 0.7473618388175964
Validation loss: 1.8951388815397858

Epoch: 5| Step: 7
Training loss: 0.6234562993049622
Validation loss: 1.8913794050934494

Epoch: 5| Step: 8
Training loss: 0.952673077583313
Validation loss: 1.9009853370728031

Epoch: 5| Step: 9
Training loss: 0.7602745294570923
Validation loss: 1.9089917111140426

Epoch: 5| Step: 10
Training loss: 1.2266881465911865
Validation loss: 1.9164609665511756

Epoch: 457| Step: 0
Training loss: 0.7606976628303528
Validation loss: 1.9356198285215644

Epoch: 5| Step: 1
Training loss: 1.1536937952041626
Validation loss: 1.9329434120526878

Epoch: 5| Step: 2
Training loss: 0.8551114797592163
Validation loss: 1.9216465770557363

Epoch: 5| Step: 3
Training loss: 0.9885371923446655
Validation loss: 1.917208666442543

Epoch: 5| Step: 4
Training loss: 0.8909574747085571
Validation loss: 1.8874120391825193

Epoch: 5| Step: 5
Training loss: 0.71464604139328
Validation loss: 1.8760646773922829

Epoch: 5| Step: 6
Training loss: 1.1163018941879272
Validation loss: 1.9125839253907562

Epoch: 5| Step: 7
Training loss: 1.413945198059082
Validation loss: 1.900487733143632

Epoch: 5| Step: 8
Training loss: 1.115369200706482
Validation loss: 1.8713307765222364

Epoch: 5| Step: 9
Training loss: 0.899012565612793
Validation loss: 1.835072700695325

Epoch: 5| Step: 10
Training loss: 1.129728078842163
Validation loss: 1.842590719140986

Epoch: 458| Step: 0
Training loss: 0.9666423797607422
Validation loss: 1.798549489308429

Epoch: 5| Step: 1
Training loss: 1.1341490745544434
Validation loss: 1.8187926084764543

Epoch: 5| Step: 2
Training loss: 0.6495129466056824
Validation loss: 1.836788446672501

Epoch: 5| Step: 3
Training loss: 1.2653234004974365
Validation loss: 1.8811890822584911

Epoch: 5| Step: 4
Training loss: 0.8551891446113586
Validation loss: 1.9007121183538949

Epoch: 5| Step: 5
Training loss: 0.9935407638549805
Validation loss: 1.939446714616591

Epoch: 5| Step: 6
Training loss: 1.194214105606079
Validation loss: 1.9520273336800196

Epoch: 5| Step: 7
Training loss: 0.882343590259552
Validation loss: 1.9474452926266579

Epoch: 5| Step: 8
Training loss: 1.2126671075820923
Validation loss: 1.9779297408237253

Epoch: 5| Step: 9
Training loss: 1.238653540611267
Validation loss: 1.9641650325508528

Epoch: 5| Step: 10
Training loss: 0.7634977698326111
Validation loss: 1.9210103916865524

Epoch: 459| Step: 0
Training loss: 1.2030491828918457
Validation loss: 1.9089852174123128

Epoch: 5| Step: 1
Training loss: 0.7673930525779724
Validation loss: 1.844523766989349

Epoch: 5| Step: 2
Training loss: 0.8797715306282043
Validation loss: 1.8289697311257804

Epoch: 5| Step: 3
Training loss: 0.7067412734031677
Validation loss: 1.8032276374037548

Epoch: 5| Step: 4
Training loss: 0.9212231636047363
Validation loss: 1.8275360061276344

Epoch: 5| Step: 5
Training loss: 1.1889290809631348
Validation loss: 1.8518415574104554

Epoch: 5| Step: 6
Training loss: 1.2312147617340088
Validation loss: 1.8431172242728613

Epoch: 5| Step: 7
Training loss: 0.9264089465141296
Validation loss: 1.8493486117291194

Epoch: 5| Step: 8
Training loss: 1.2147047519683838
Validation loss: 1.884788884911486

Epoch: 5| Step: 9
Training loss: 0.9148728251457214
Validation loss: 1.884610673432709

Epoch: 5| Step: 10
Training loss: 1.0162550210952759
Validation loss: 1.9207599470692296

Epoch: 460| Step: 0
Training loss: 0.6679270267486572
Validation loss: 1.9161799107828448

Epoch: 5| Step: 1
Training loss: 0.8201693296432495
Validation loss: 1.9293709313997658

Epoch: 5| Step: 2
Training loss: 1.0623407363891602
Validation loss: 1.919838002932969

Epoch: 5| Step: 3
Training loss: 0.6968221664428711
Validation loss: 1.9251953747964674

Epoch: 5| Step: 4
Training loss: 1.2031209468841553
Validation loss: 1.9428864204755394

Epoch: 5| Step: 5
Training loss: 0.6977348923683167
Validation loss: 1.9175138012055428

Epoch: 5| Step: 6
Training loss: 1.2236716747283936
Validation loss: 1.9240788439268708

Epoch: 5| Step: 7
Training loss: 0.8015581965446472
Validation loss: 1.9019314627493582

Epoch: 5| Step: 8
Training loss: 0.757850706577301
Validation loss: 1.887016232295703

Epoch: 5| Step: 9
Training loss: 1.4123930931091309
Validation loss: 1.9049538566220192

Epoch: 5| Step: 10
Training loss: 1.3509438037872314
Validation loss: 1.8954883929221862

Epoch: 461| Step: 0
Training loss: 0.8068114519119263
Validation loss: 1.8926325446815901

Epoch: 5| Step: 1
Training loss: 0.936069667339325
Validation loss: 1.8811817092280234

Epoch: 5| Step: 2
Training loss: 0.7716666460037231
Validation loss: 1.885332425435384

Epoch: 5| Step: 3
Training loss: 1.131716251373291
Validation loss: 1.8795690946681525

Epoch: 5| Step: 4
Training loss: 1.237339735031128
Validation loss: 1.8938178746931014

Epoch: 5| Step: 5
Training loss: 0.9308404922485352
Validation loss: 1.90337416689883

Epoch: 5| Step: 6
Training loss: 0.6963144540786743
Validation loss: 1.8883723161553825

Epoch: 5| Step: 7
Training loss: 1.1969822645187378
Validation loss: 1.8843258132216751

Epoch: 5| Step: 8
Training loss: 1.298482894897461
Validation loss: 1.9423222452081659

Epoch: 5| Step: 9
Training loss: 0.7597726583480835
Validation loss: 1.926012101993766

Epoch: 5| Step: 10
Training loss: 0.7734719514846802
Validation loss: 1.910262600068123

Epoch: 462| Step: 0
Training loss: 1.0028412342071533
Validation loss: 1.9110403765914261

Epoch: 5| Step: 1
Training loss: 0.8778214454650879
Validation loss: 1.9096034893425562

Epoch: 5| Step: 2
Training loss: 0.7909703850746155
Validation loss: 1.8848447235681678

Epoch: 5| Step: 3
Training loss: 0.9843045473098755
Validation loss: 1.8849406319279824

Epoch: 5| Step: 4
Training loss: 0.6798256039619446
Validation loss: 1.8900836283160793

Epoch: 5| Step: 5
Training loss: 1.112831473350525
Validation loss: 1.8805300984331357

Epoch: 5| Step: 6
Training loss: 1.5701040029525757
Validation loss: 1.872119499791053

Epoch: 5| Step: 7
Training loss: 1.1271922588348389
Validation loss: 1.8582922361230338

Epoch: 5| Step: 8
Training loss: 0.493649423122406
Validation loss: 1.8841793216684812

Epoch: 5| Step: 9
Training loss: 0.5212174654006958
Validation loss: 1.899800508253036

Epoch: 5| Step: 10
Training loss: 1.421912431716919
Validation loss: 1.8998662733262586

Epoch: 463| Step: 0
Training loss: 0.9712004661560059
Validation loss: 1.9352577847819175

Epoch: 5| Step: 1
Training loss: 1.0826770067214966
Validation loss: 1.9267054309127152

Epoch: 5| Step: 2
Training loss: 0.9302328824996948
Validation loss: 1.9561368073186567

Epoch: 5| Step: 3
Training loss: 0.8491422533988953
Validation loss: 1.9384309527694539

Epoch: 5| Step: 4
Training loss: 1.0133739709854126
Validation loss: 1.9234461835635606

Epoch: 5| Step: 5
Training loss: 0.7783678770065308
Validation loss: 1.9207300216920915

Epoch: 5| Step: 6
Training loss: 0.7061752080917358
Validation loss: 1.8778973458915629

Epoch: 5| Step: 7
Training loss: 1.1162828207015991
Validation loss: 1.890922600223172

Epoch: 5| Step: 8
Training loss: 1.3064966201782227
Validation loss: 1.8604228906734015

Epoch: 5| Step: 9
Training loss: 0.946346640586853
Validation loss: 1.8760082644800986

Epoch: 5| Step: 10
Training loss: 0.8711223602294922
Validation loss: 1.929219776584256

Epoch: 464| Step: 0
Training loss: 1.0919451713562012
Validation loss: 1.8731497923533122

Epoch: 5| Step: 1
Training loss: 0.9267706871032715
Validation loss: 1.8797732745447466

Epoch: 5| Step: 2
Training loss: 0.725890576839447
Validation loss: 1.9007970261317428

Epoch: 5| Step: 3
Training loss: 1.0824064016342163
Validation loss: 1.8867892578083982

Epoch: 5| Step: 4
Training loss: 0.9328861236572266
Validation loss: 1.8737709368428876

Epoch: 5| Step: 5
Training loss: 1.0153064727783203
Validation loss: 1.910891024015283

Epoch: 5| Step: 6
Training loss: 1.0726478099822998
Validation loss: 1.8806079561992357

Epoch: 5| Step: 7
Training loss: 0.6921564936637878
Validation loss: 1.9021935565497285

Epoch: 5| Step: 8
Training loss: 0.9729619026184082
Validation loss: 1.8779845481277795

Epoch: 5| Step: 9
Training loss: 1.0610616207122803
Validation loss: 1.8648537871658162

Epoch: 5| Step: 10
Training loss: 1.0419301986694336
Validation loss: 1.8612319461760982

Epoch: 465| Step: 0
Training loss: 0.6571215391159058
Validation loss: 1.8744266417718702

Epoch: 5| Step: 1
Training loss: 1.171251893043518
Validation loss: 1.852370339055215

Epoch: 5| Step: 2
Training loss: 1.1071263551712036
Validation loss: 1.890044730196717

Epoch: 5| Step: 3
Training loss: 1.1519306898117065
Validation loss: 1.8897585740653418

Epoch: 5| Step: 4
Training loss: 0.9642401933670044
Validation loss: 1.9081880866840322

Epoch: 5| Step: 5
Training loss: 1.3168730735778809
Validation loss: 1.9161839433895644

Epoch: 5| Step: 6
Training loss: 0.7261077761650085
Validation loss: 1.901450321238528

Epoch: 5| Step: 7
Training loss: 1.0467275381088257
Validation loss: 1.8988191043176958

Epoch: 5| Step: 8
Training loss: 0.8954704403877258
Validation loss: 1.8983756931879188

Epoch: 5| Step: 9
Training loss: 0.6348243951797485
Validation loss: 1.8659405669858378

Epoch: 5| Step: 10
Training loss: 0.7015286684036255
Validation loss: 1.867640769609841

Epoch: 466| Step: 0
Training loss: 0.923708438873291
Validation loss: 1.8641302008782663

Epoch: 5| Step: 1
Training loss: 1.065950870513916
Validation loss: 1.8630920020482873

Epoch: 5| Step: 2
Training loss: 0.7340379953384399
Validation loss: 1.8484761535480458

Epoch: 5| Step: 3
Training loss: 0.7001866102218628
Validation loss: 1.8424883811704573

Epoch: 5| Step: 4
Training loss: 0.6775753498077393
Validation loss: 1.8466320114751016

Epoch: 5| Step: 5
Training loss: 0.7870932221412659
Validation loss: 1.843738937890658

Epoch: 5| Step: 6
Training loss: 1.1194435358047485
Validation loss: 1.8695862652153097

Epoch: 5| Step: 7
Training loss: 1.1517757177352905
Validation loss: 1.873278634522551

Epoch: 5| Step: 8
Training loss: 0.9430829286575317
Validation loss: 1.8598260584697928

Epoch: 5| Step: 9
Training loss: 1.484187364578247
Validation loss: 1.8944376617349603

Epoch: 5| Step: 10
Training loss: 0.8695552945137024
Validation loss: 1.8817491839008946

Epoch: 467| Step: 0
Training loss: 1.3776416778564453
Validation loss: 1.9128630879104778

Epoch: 5| Step: 1
Training loss: 0.9815369844436646
Validation loss: 1.888835677536585

Epoch: 5| Step: 2
Training loss: 1.1172330379486084
Validation loss: 1.8781021359146282

Epoch: 5| Step: 3
Training loss: 1.0307931900024414
Validation loss: 1.879627404674407

Epoch: 5| Step: 4
Training loss: 0.955531120300293
Validation loss: 1.8513844218305362

Epoch: 5| Step: 5
Training loss: 0.29753026366233826
Validation loss: 1.8450368783807243

Epoch: 5| Step: 6
Training loss: 0.9736111760139465
Validation loss: 1.857995016600496

Epoch: 5| Step: 7
Training loss: 0.6692949533462524
Validation loss: 1.8537850072306972

Epoch: 5| Step: 8
Training loss: 1.3611098527908325
Validation loss: 1.8718509110071326

Epoch: 5| Step: 9
Training loss: 0.6286658048629761
Validation loss: 1.8619231947006718

Epoch: 5| Step: 10
Training loss: 0.8812893033027649
Validation loss: 1.8583560656475764

Epoch: 468| Step: 0
Training loss: 0.8815996050834656
Validation loss: 1.8582744931661954

Epoch: 5| Step: 1
Training loss: 1.0640455484390259
Validation loss: 1.863914083409053

Epoch: 5| Step: 2
Training loss: 0.7063263058662415
Validation loss: 1.8668917173980384

Epoch: 5| Step: 3
Training loss: 1.1469905376434326
Validation loss: 1.8809729481256137

Epoch: 5| Step: 4
Training loss: 1.1749958992004395
Validation loss: 1.873815518553539

Epoch: 5| Step: 5
Training loss: 0.848633885383606
Validation loss: 1.85955463686297

Epoch: 5| Step: 6
Training loss: 1.016491174697876
Validation loss: 1.8316121332107052

Epoch: 5| Step: 7
Training loss: 0.8490668535232544
Validation loss: 1.8322962458415697

Epoch: 5| Step: 8
Training loss: 0.8755346536636353
Validation loss: 1.8317450656685779

Epoch: 5| Step: 9
Training loss: 0.6582433581352234
Validation loss: 1.844112394958414

Epoch: 5| Step: 10
Training loss: 1.135672688484192
Validation loss: 1.840171165363763

Epoch: 469| Step: 0
Training loss: 0.7361883521080017
Validation loss: 1.8471348336947861

Epoch: 5| Step: 1
Training loss: 0.489955335855484
Validation loss: 1.86601823119707

Epoch: 5| Step: 2
Training loss: 0.8755218386650085
Validation loss: 1.8767639975393973

Epoch: 5| Step: 3
Training loss: 0.8296867609024048
Validation loss: 1.9061622568356094

Epoch: 5| Step: 4
Training loss: 0.6392230987548828
Validation loss: 1.9120078304762482

Epoch: 5| Step: 5
Training loss: 0.9917124509811401
Validation loss: 1.8912660229590632

Epoch: 5| Step: 6
Training loss: 1.2312164306640625
Validation loss: 1.8709547468411025

Epoch: 5| Step: 7
Training loss: 1.2580900192260742
Validation loss: 1.8454195402001823

Epoch: 5| Step: 8
Training loss: 1.2721140384674072
Validation loss: 1.8503829509981218

Epoch: 5| Step: 9
Training loss: 0.8393373489379883
Validation loss: 1.8252761056346278

Epoch: 5| Step: 10
Training loss: 1.060155987739563
Validation loss: 1.819083268924426

Epoch: 470| Step: 0
Training loss: 0.7101019024848938
Validation loss: 1.8254430729855773

Epoch: 5| Step: 1
Training loss: 0.867156982421875
Validation loss: 1.8148107426140898

Epoch: 5| Step: 2
Training loss: 1.4606034755706787
Validation loss: 1.8167477705145394

Epoch: 5| Step: 3
Training loss: 0.8328655362129211
Validation loss: 1.847693003633971

Epoch: 5| Step: 4
Training loss: 0.6874549984931946
Validation loss: 1.8258646636880853

Epoch: 5| Step: 5
Training loss: 0.9756592512130737
Validation loss: 1.8598655744265484

Epoch: 5| Step: 6
Training loss: 0.6786261796951294
Validation loss: 1.8502672744053665

Epoch: 5| Step: 7
Training loss: 0.7753560543060303
Validation loss: 1.851301493183259

Epoch: 5| Step: 8
Training loss: 1.068827748298645
Validation loss: 1.85438871383667

Epoch: 5| Step: 9
Training loss: 1.3730742931365967
Validation loss: 1.8795008428635136

Epoch: 5| Step: 10
Training loss: 0.7462703585624695
Validation loss: 1.8809249196001279

Epoch: 471| Step: 0
Training loss: 0.615345299243927
Validation loss: 1.917736864859058

Epoch: 5| Step: 1
Training loss: 1.1787872314453125
Validation loss: 1.9329820345806819

Epoch: 5| Step: 2
Training loss: 1.2118791341781616
Validation loss: 1.950980842754405

Epoch: 5| Step: 3
Training loss: 1.529386043548584
Validation loss: 1.9247126656193887

Epoch: 5| Step: 4
Training loss: 0.6400539875030518
Validation loss: 1.8726560992579306

Epoch: 5| Step: 5
Training loss: 1.1133241653442383
Validation loss: 1.886035575661608

Epoch: 5| Step: 6
Training loss: 0.557991623878479
Validation loss: 1.8458616374641337

Epoch: 5| Step: 7
Training loss: 1.11674165725708
Validation loss: 1.8231939013286302

Epoch: 5| Step: 8
Training loss: 0.8194176554679871
Validation loss: 1.8099602614679644

Epoch: 5| Step: 9
Training loss: 0.6578187942504883
Validation loss: 1.8204000906277729

Epoch: 5| Step: 10
Training loss: 0.6831751465797424
Validation loss: 1.8238773371583672

Epoch: 472| Step: 0
Training loss: 0.9208530187606812
Validation loss: 1.8326706758109472

Epoch: 5| Step: 1
Training loss: 0.9523653984069824
Validation loss: 1.8394508759180705

Epoch: 5| Step: 2
Training loss: 0.7435819506645203
Validation loss: 1.8570266244232014

Epoch: 5| Step: 3
Training loss: 1.1922712326049805
Validation loss: 1.8429772597487255

Epoch: 5| Step: 4
Training loss: 0.7972748875617981
Validation loss: 1.8818233141335108

Epoch: 5| Step: 5
Training loss: 0.8687857389450073
Validation loss: 1.919571936771434

Epoch: 5| Step: 6
Training loss: 1.12729811668396
Validation loss: 1.9194665301230647

Epoch: 5| Step: 7
Training loss: 0.75788414478302
Validation loss: 1.890993300304618

Epoch: 5| Step: 8
Training loss: 0.9812597036361694
Validation loss: 1.886837936216785

Epoch: 5| Step: 9
Training loss: 1.1485471725463867
Validation loss: 1.8765878305640271

Epoch: 5| Step: 10
Training loss: 0.8123879432678223
Validation loss: 1.8850243835039036

Epoch: 473| Step: 0
Training loss: 0.8052213788032532
Validation loss: 1.8407130561849123

Epoch: 5| Step: 1
Training loss: 1.2371538877487183
Validation loss: 1.8553291200309672

Epoch: 5| Step: 2
Training loss: 0.8523105382919312
Validation loss: 1.8335464398066204

Epoch: 5| Step: 3
Training loss: 0.5718871355056763
Validation loss: 1.8504539446164203

Epoch: 5| Step: 4
Training loss: 0.7589295506477356
Validation loss: 1.8605432395012147

Epoch: 5| Step: 5
Training loss: 0.6466194987297058
Validation loss: 1.87500895479674

Epoch: 5| Step: 6
Training loss: 1.1955842971801758
Validation loss: 1.8749797831299484

Epoch: 5| Step: 7
Training loss: 1.0351717472076416
Validation loss: 1.875493650795311

Epoch: 5| Step: 8
Training loss: 1.2394022941589355
Validation loss: 1.870505170155597

Epoch: 5| Step: 9
Training loss: 0.9616333246231079
Validation loss: 1.8774740926681026

Epoch: 5| Step: 10
Training loss: 0.8197805881500244
Validation loss: 1.8823036916794316

Epoch: 474| Step: 0
Training loss: 1.026076316833496
Validation loss: 1.8825611170902048

Epoch: 5| Step: 1
Training loss: 0.6126210689544678
Validation loss: 1.8725782632827759

Epoch: 5| Step: 2
Training loss: 1.0318198204040527
Validation loss: 1.8704508145650227

Epoch: 5| Step: 3
Training loss: 0.9191869497299194
Validation loss: 1.8574329550548265

Epoch: 5| Step: 4
Training loss: 0.9753502607345581
Validation loss: 1.837887207667033

Epoch: 5| Step: 5
Training loss: 0.9954900741577148
Validation loss: 1.850768712259108

Epoch: 5| Step: 6
Training loss: 1.3014485836029053
Validation loss: 1.8557612895965576

Epoch: 5| Step: 7
Training loss: 0.9662648439407349
Validation loss: 1.8452600766253728

Epoch: 5| Step: 8
Training loss: 0.6974127888679504
Validation loss: 1.839365041384133

Epoch: 5| Step: 9
Training loss: 0.7489821314811707
Validation loss: 1.8402327747755154

Epoch: 5| Step: 10
Training loss: 0.7769498229026794
Validation loss: 1.858063385050784

Epoch: 475| Step: 0
Training loss: 1.0368527173995972
Validation loss: 1.852790254418568

Epoch: 5| Step: 1
Training loss: 1.023966908454895
Validation loss: 1.8542192853907102

Epoch: 5| Step: 2
Training loss: 0.760595440864563
Validation loss: 1.860809899145557

Epoch: 5| Step: 3
Training loss: 1.430877923965454
Validation loss: 1.8601483273249801

Epoch: 5| Step: 4
Training loss: 0.9703232645988464
Validation loss: 1.879256643274779

Epoch: 5| Step: 5
Training loss: 1.0570560693740845
Validation loss: 1.8527829672700615

Epoch: 5| Step: 6
Training loss: 0.4346230924129486
Validation loss: 1.8443641188324138

Epoch: 5| Step: 7
Training loss: 0.7801393270492554
Validation loss: 1.854183082939476

Epoch: 5| Step: 8
Training loss: 0.7043798565864563
Validation loss: 1.851767809160294

Epoch: 5| Step: 9
Training loss: 0.8281723260879517
Validation loss: 1.8495539695985856

Epoch: 5| Step: 10
Training loss: 0.6365828514099121
Validation loss: 1.8477470156967

Epoch: 476| Step: 0
Training loss: 1.2012220621109009
Validation loss: 1.8456454994857951

Epoch: 5| Step: 1
Training loss: 0.7481319904327393
Validation loss: 1.8453708053917013

Epoch: 5| Step: 2
Training loss: 0.9450640678405762
Validation loss: 1.8479978525510399

Epoch: 5| Step: 3
Training loss: 0.8946288824081421
Validation loss: 1.8327710449054677

Epoch: 5| Step: 4
Training loss: 1.1998169422149658
Validation loss: 1.8336198150470693

Epoch: 5| Step: 5
Training loss: 0.6347051858901978
Validation loss: 1.8504581438597811

Epoch: 5| Step: 6
Training loss: 0.9218136668205261
Validation loss: 1.8362261095354635

Epoch: 5| Step: 7
Training loss: 0.9712539911270142
Validation loss: 1.8277259180622716

Epoch: 5| Step: 8
Training loss: 0.7939459681510925
Validation loss: 1.8322281414462673

Epoch: 5| Step: 9
Training loss: 0.7941554188728333
Validation loss: 1.8466144505367483

Epoch: 5| Step: 10
Training loss: 0.6034185886383057
Validation loss: 1.849177880953717

Epoch: 477| Step: 0
Training loss: 0.918786883354187
Validation loss: 1.8374546804735739

Epoch: 5| Step: 1
Training loss: 1.2061644792556763
Validation loss: 1.8684919226554133

Epoch: 5| Step: 2
Training loss: 0.8644576072692871
Validation loss: 1.8689394074101602

Epoch: 5| Step: 3
Training loss: 0.5261403322219849
Validation loss: 1.886784404836675

Epoch: 5| Step: 4
Training loss: 0.8887176513671875
Validation loss: 1.8707031306400095

Epoch: 5| Step: 5
Training loss: 0.700716495513916
Validation loss: 1.8848390630496445

Epoch: 5| Step: 6
Training loss: 0.7878247499465942
Validation loss: 1.8679662096884944

Epoch: 5| Step: 7
Training loss: 1.3134186267852783
Validation loss: 1.8451777337699808

Epoch: 5| Step: 8
Training loss: 0.807562530040741
Validation loss: 1.8502986277303388

Epoch: 5| Step: 9
Training loss: 1.009456753730774
Validation loss: 1.834270251694546

Epoch: 5| Step: 10
Training loss: 0.7471345067024231
Validation loss: 1.8260486497673938

Epoch: 478| Step: 0
Training loss: 0.6229162216186523
Validation loss: 1.8294787932467718

Epoch: 5| Step: 1
Training loss: 0.4070805013179779
Validation loss: 1.8363983028678483

Epoch: 5| Step: 2
Training loss: 1.071413278579712
Validation loss: 1.8220274986759308

Epoch: 5| Step: 3
Training loss: 0.8653872609138489
Validation loss: 1.8422559422831382

Epoch: 5| Step: 4
Training loss: 1.1048005819320679
Validation loss: 1.8557485624026226

Epoch: 5| Step: 5
Training loss: 0.8307269811630249
Validation loss: 1.8722930236529278

Epoch: 5| Step: 6
Training loss: 0.651492178440094
Validation loss: 1.8710772811725576

Epoch: 5| Step: 7
Training loss: 0.9116684198379517
Validation loss: 1.894089283481721

Epoch: 5| Step: 8
Training loss: 1.0292580127716064
Validation loss: 1.8991599275219826

Epoch: 5| Step: 9
Training loss: 0.9208634495735168
Validation loss: 1.9179763819581719

Epoch: 5| Step: 10
Training loss: 1.3866283893585205
Validation loss: 1.9047214523438485

Epoch: 479| Step: 0
Training loss: 1.1765878200531006
Validation loss: 1.873002347125802

Epoch: 5| Step: 1
Training loss: 0.612610936164856
Validation loss: 1.8751449572142733

Epoch: 5| Step: 2
Training loss: 1.025037169456482
Validation loss: 1.854992989570864

Epoch: 5| Step: 3
Training loss: 0.7352892160415649
Validation loss: 1.8429893216779154

Epoch: 5| Step: 4
Training loss: 1.1259578466415405
Validation loss: 1.818197347784555

Epoch: 5| Step: 5
Training loss: 1.0669084787368774
Validation loss: 1.7865911786274244

Epoch: 5| Step: 6
Training loss: 1.1982444524765015
Validation loss: 1.813870837611537

Epoch: 5| Step: 7
Training loss: 0.8982614278793335
Validation loss: 1.8289091843430714

Epoch: 5| Step: 8
Training loss: 0.7579364776611328
Validation loss: 1.8127710485971102

Epoch: 5| Step: 9
Training loss: 0.7200113534927368
Validation loss: 1.814819634601634

Epoch: 5| Step: 10
Training loss: 0.5837893486022949
Validation loss: 1.8124316815407044

Epoch: 480| Step: 0
Training loss: 0.8206860423088074
Validation loss: 1.8414332610304638

Epoch: 5| Step: 1
Training loss: 0.8486872911453247
Validation loss: 1.8596896971425703

Epoch: 5| Step: 2
Training loss: 0.77854323387146
Validation loss: 1.8577695431247834

Epoch: 5| Step: 3
Training loss: 1.0399808883666992
Validation loss: 1.883975762192921

Epoch: 5| Step: 4
Training loss: 1.0461626052856445
Validation loss: 1.890109855641601

Epoch: 5| Step: 5
Training loss: 0.46654605865478516
Validation loss: 1.8948758315014582

Epoch: 5| Step: 6
Training loss: 1.1210827827453613
Validation loss: 1.8845469605538152

Epoch: 5| Step: 7
Training loss: 0.5502419471740723
Validation loss: 1.8642901842312147

Epoch: 5| Step: 8
Training loss: 1.210092306137085
Validation loss: 1.859193528852155

Epoch: 5| Step: 9
Training loss: 0.9677913784980774
Validation loss: 1.8212399149453768

Epoch: 5| Step: 10
Training loss: 0.8677783012390137
Validation loss: 1.829337909657468

Epoch: 481| Step: 0
Training loss: 0.8331114649772644
Validation loss: 1.8179362332949074

Epoch: 5| Step: 1
Training loss: 0.5699875354766846
Validation loss: 1.8125148409156389

Epoch: 5| Step: 2
Training loss: 0.7267066836357117
Validation loss: 1.8214316252739198

Epoch: 5| Step: 3
Training loss: 1.0214792490005493
Validation loss: 1.7967421931605185

Epoch: 5| Step: 4
Training loss: 0.7415820360183716
Validation loss: 1.8409925917143464

Epoch: 5| Step: 5
Training loss: 0.6639205813407898
Validation loss: 1.8580483608348395

Epoch: 5| Step: 6
Training loss: 1.0494027137756348
Validation loss: 1.8693611980766378

Epoch: 5| Step: 7
Training loss: 1.0247474908828735
Validation loss: 1.889891924396638

Epoch: 5| Step: 8
Training loss: 1.0907639265060425
Validation loss: 1.8834251857572986

Epoch: 5| Step: 9
Training loss: 1.0671170949935913
Validation loss: 1.906181368776547

Epoch: 5| Step: 10
Training loss: 0.9362392425537109
Validation loss: 1.9176216176761094

Epoch: 482| Step: 0
Training loss: 1.1767674684524536
Validation loss: 1.9344611821636077

Epoch: 5| Step: 1
Training loss: 0.5785912871360779
Validation loss: 1.9033428571557487

Epoch: 5| Step: 2
Training loss: 0.8376258015632629
Validation loss: 1.9051622741965837

Epoch: 5| Step: 3
Training loss: 0.9378331303596497
Validation loss: 1.8747515652769355

Epoch: 5| Step: 4
Training loss: 0.7735418081283569
Validation loss: 1.8834338905990764

Epoch: 5| Step: 5
Training loss: 0.9473007917404175
Validation loss: 1.8748936858228458

Epoch: 5| Step: 6
Training loss: 0.8089002370834351
Validation loss: 1.8725643439959454

Epoch: 5| Step: 7
Training loss: 1.2334353923797607
Validation loss: 1.8849290211995442

Epoch: 5| Step: 8
Training loss: 1.0349611043930054
Validation loss: 1.8693051568923458

Epoch: 5| Step: 9
Training loss: 0.311704158782959
Validation loss: 1.8558399203003093

Epoch: 5| Step: 10
Training loss: 0.9243897199630737
Validation loss: 1.8583037378967449

Epoch: 483| Step: 0
Training loss: 0.45716914534568787
Validation loss: 1.8616633120403494

Epoch: 5| Step: 1
Training loss: 0.6261942386627197
Validation loss: 1.854724378995998

Epoch: 5| Step: 2
Training loss: 0.7355655431747437
Validation loss: 1.867850847141717

Epoch: 5| Step: 3
Training loss: 1.0056545734405518
Validation loss: 1.8995571239020235

Epoch: 5| Step: 4
Training loss: 0.8918687105178833
Validation loss: 1.900722453671117

Epoch: 5| Step: 5
Training loss: 0.7794830203056335
Validation loss: 1.9159145406497422

Epoch: 5| Step: 6
Training loss: 1.026884913444519
Validation loss: 1.923380155717173

Epoch: 5| Step: 7
Training loss: 1.012702226638794
Validation loss: 1.9146399638986076

Epoch: 5| Step: 8
Training loss: 1.1419702768325806
Validation loss: 1.8865292610660676

Epoch: 5| Step: 9
Training loss: 0.9367498159408569
Validation loss: 1.8642430459299395

Epoch: 5| Step: 10
Training loss: 0.8956356048583984
Validation loss: 1.8642385390497023

Epoch: 484| Step: 0
Training loss: 0.5747466087341309
Validation loss: 1.844015613678963

Epoch: 5| Step: 1
Training loss: 1.269838809967041
Validation loss: 1.8423726609958115

Epoch: 5| Step: 2
Training loss: 1.025754451751709
Validation loss: 1.8576211173047301

Epoch: 5| Step: 3
Training loss: 0.6369397640228271
Validation loss: 1.843056086570986

Epoch: 5| Step: 4
Training loss: 0.9980179667472839
Validation loss: 1.8583276541002336

Epoch: 5| Step: 5
Training loss: 0.6341768503189087
Validation loss: 1.8583563566207886

Epoch: 5| Step: 6
Training loss: 1.236548662185669
Validation loss: 1.8743298874106458

Epoch: 5| Step: 7
Training loss: 0.5540857315063477
Validation loss: 1.8681908551082815

Epoch: 5| Step: 8
Training loss: 0.953229546546936
Validation loss: 1.8805734239598757

Epoch: 5| Step: 9
Training loss: 0.9320493936538696
Validation loss: 1.8723765919285436

Epoch: 5| Step: 10
Training loss: 0.7742648720741272
Validation loss: 1.861027866281489

Epoch: 485| Step: 0
Training loss: 0.843934178352356
Validation loss: 1.8358760136429981

Epoch: 5| Step: 1
Training loss: 0.6143306493759155
Validation loss: 1.8493843386250157

Epoch: 5| Step: 2
Training loss: 0.7195392847061157
Validation loss: 1.8390022388068579

Epoch: 5| Step: 3
Training loss: 0.6485680341720581
Validation loss: 1.8300242936739357

Epoch: 5| Step: 4
Training loss: 0.8732901811599731
Validation loss: 1.8347641255265923

Epoch: 5| Step: 5
Training loss: 0.6651968359947205
Validation loss: 1.8559921056993547

Epoch: 5| Step: 6
Training loss: 1.1760259866714478
Validation loss: 1.819135259556514

Epoch: 5| Step: 7
Training loss: 0.45814448595046997
Validation loss: 1.8373863120232858

Epoch: 5| Step: 8
Training loss: 0.8749348521232605
Validation loss: 1.830000541543448

Epoch: 5| Step: 9
Training loss: 0.8062726259231567
Validation loss: 1.8456252262156496

Epoch: 5| Step: 10
Training loss: 1.7235664129257202
Validation loss: 1.8365599058007682

Epoch: 486| Step: 0
Training loss: 0.902805507183075
Validation loss: 1.8318552624794744

Epoch: 5| Step: 1
Training loss: 0.8201515078544617
Validation loss: 1.8409703572591145

Epoch: 5| Step: 2
Training loss: 0.6519113779067993
Validation loss: 1.8693250238254506

Epoch: 5| Step: 3
Training loss: 1.351928949356079
Validation loss: 1.873554128472523

Epoch: 5| Step: 4
Training loss: 1.1126736402511597
Validation loss: 1.8701269318980556

Epoch: 5| Step: 5
Training loss: 0.7969045639038086
Validation loss: 1.89009904092358

Epoch: 5| Step: 6
Training loss: 0.4396035075187683
Validation loss: 1.8801758494428409

Epoch: 5| Step: 7
Training loss: 1.198689579963684
Validation loss: 1.8683568380212272

Epoch: 5| Step: 8
Training loss: 0.6327943801879883
Validation loss: 1.8831812873963387

Epoch: 5| Step: 9
Training loss: 0.6346508264541626
Validation loss: 1.8519946926383561

Epoch: 5| Step: 10
Training loss: 0.7818878293037415
Validation loss: 1.8732792074962328

Epoch: 487| Step: 0
Training loss: 0.45620518922805786
Validation loss: 1.8691160114862586

Epoch: 5| Step: 1
Training loss: 0.4104507863521576
Validation loss: 1.89535189572201

Epoch: 5| Step: 2
Training loss: 1.2885644435882568
Validation loss: 1.9134618095172349

Epoch: 5| Step: 3
Training loss: 1.1331775188446045
Validation loss: 1.8785669008890789

Epoch: 5| Step: 4
Training loss: 1.2582231760025024
Validation loss: 1.8661012444444882

Epoch: 5| Step: 5
Training loss: 0.9234733581542969
Validation loss: 1.85683233891764

Epoch: 5| Step: 6
Training loss: 0.4132658541202545
Validation loss: 1.8383909194700179

Epoch: 5| Step: 7
Training loss: 1.1140289306640625
Validation loss: 1.8459607990839149

Epoch: 5| Step: 8
Training loss: 0.7275146842002869
Validation loss: 1.8486324587175924

Epoch: 5| Step: 9
Training loss: 0.9357532262802124
Validation loss: 1.818498465322679

Epoch: 5| Step: 10
Training loss: 0.6541526913642883
Validation loss: 1.835062357687181

Epoch: 488| Step: 0
Training loss: 0.8711277842521667
Validation loss: 1.8642284806056688

Epoch: 5| Step: 1
Training loss: 0.6526160836219788
Validation loss: 1.8375606767592891

Epoch: 5| Step: 2
Training loss: 0.4818234443664551
Validation loss: 1.8550552693746423

Epoch: 5| Step: 3
Training loss: 0.9256213307380676
Validation loss: 1.8810115988536547

Epoch: 5| Step: 4
Training loss: 0.771041214466095
Validation loss: 1.8897191209177817

Epoch: 5| Step: 5
Training loss: 1.067129373550415
Validation loss: 1.8845835667784496

Epoch: 5| Step: 6
Training loss: 1.1591899394989014
Validation loss: 1.88490641245278

Epoch: 5| Step: 7
Training loss: 0.7385525107383728
Validation loss: 1.9039062889673377

Epoch: 5| Step: 8
Training loss: 0.7936606407165527
Validation loss: 1.8706972086301414

Epoch: 5| Step: 9
Training loss: 0.9764372706413269
Validation loss: 1.8929514551675448

Epoch: 5| Step: 10
Training loss: 0.9254959225654602
Validation loss: 1.8746171664166194

Epoch: 489| Step: 0
Training loss: 1.1319454908370972
Validation loss: 1.8875806882817259

Epoch: 5| Step: 1
Training loss: 0.8103538751602173
Validation loss: 1.869950226558152

Epoch: 5| Step: 2
Training loss: 1.2096388339996338
Validation loss: 1.8686882231825142

Epoch: 5| Step: 3
Training loss: 0.8357652425765991
Validation loss: 1.856388343277798

Epoch: 5| Step: 4
Training loss: 0.7493326663970947
Validation loss: 1.8808433804460751

Epoch: 5| Step: 5
Training loss: 0.9880269765853882
Validation loss: 1.886886017296904

Epoch: 5| Step: 6
Training loss: 0.7684222459793091
Validation loss: 1.8884890105134697

Epoch: 5| Step: 7
Training loss: 0.8731815218925476
Validation loss: 1.895190877299155

Epoch: 5| Step: 8
Training loss: 1.0417052507400513
Validation loss: 1.8549278654078

Epoch: 5| Step: 9
Training loss: 0.5098422765731812
Validation loss: 1.8689941014012983

Epoch: 5| Step: 10
Training loss: 0.28976136445999146
Validation loss: 1.8520662246211883

Epoch: 490| Step: 0
Training loss: 0.8393006324768066
Validation loss: 1.852927557883724

Epoch: 5| Step: 1
Training loss: 0.7639995813369751
Validation loss: 1.8774251091864802

Epoch: 5| Step: 2
Training loss: 0.8838618397712708
Validation loss: 1.854946505638861

Epoch: 5| Step: 3
Training loss: 1.0914549827575684
Validation loss: 1.8715408681541361

Epoch: 5| Step: 4
Training loss: 0.8138481378555298
Validation loss: 1.8496103543107227

Epoch: 5| Step: 5
Training loss: 0.9748183488845825
Validation loss: 1.8408034283627746

Epoch: 5| Step: 6
Training loss: 0.6591682434082031
Validation loss: 1.8594370939398324

Epoch: 5| Step: 7
Training loss: 0.7580373883247375
Validation loss: 1.8745564055699173

Epoch: 5| Step: 8
Training loss: 0.7212663888931274
Validation loss: 1.849481189122764

Epoch: 5| Step: 9
Training loss: 0.727715015411377
Validation loss: 1.867171984846874

Epoch: 5| Step: 10
Training loss: 1.0567868947982788
Validation loss: 1.8680445366008307

Epoch: 491| Step: 0
Training loss: 0.9154006242752075
Validation loss: 1.8751618477606005

Epoch: 5| Step: 1
Training loss: 0.7850050926208496
Validation loss: 1.8850805015974148

Epoch: 5| Step: 2
Training loss: 0.8385456204414368
Validation loss: 1.8984968354625087

Epoch: 5| Step: 3
Training loss: 1.1869884729385376
Validation loss: 1.9039051276381298

Epoch: 5| Step: 4
Training loss: 0.9137957692146301
Validation loss: 1.8942550882216422

Epoch: 5| Step: 5
Training loss: 0.8442682027816772
Validation loss: 1.8871367285328526

Epoch: 5| Step: 6
Training loss: 0.9061218500137329
Validation loss: 1.8674944216205227

Epoch: 5| Step: 7
Training loss: 0.7889535427093506
Validation loss: 1.8514675530054236

Epoch: 5| Step: 8
Training loss: 0.8262859582901001
Validation loss: 1.8428413816677627

Epoch: 5| Step: 9
Training loss: 0.7847917675971985
Validation loss: 1.8490227178860736

Epoch: 5| Step: 10
Training loss: 0.8432067632675171
Validation loss: 1.8350578226068968

Epoch: 492| Step: 0
Training loss: 0.6492477059364319
Validation loss: 1.8105306676639024

Epoch: 5| Step: 1
Training loss: 0.7599021196365356
Validation loss: 1.7879235154838973

Epoch: 5| Step: 2
Training loss: 0.8102018237113953
Validation loss: 1.8337220735447382

Epoch: 5| Step: 3
Training loss: 0.7892040014266968
Validation loss: 1.8294788919469362

Epoch: 5| Step: 4
Training loss: 0.5211924314498901
Validation loss: 1.8508658947483185

Epoch: 5| Step: 5
Training loss: 0.831747829914093
Validation loss: 1.8912797198500684

Epoch: 5| Step: 6
Training loss: 1.19668447971344
Validation loss: 1.8896262581630419

Epoch: 5| Step: 7
Training loss: 0.734839141368866
Validation loss: 1.9006068193784325

Epoch: 5| Step: 8
Training loss: 1.0460011959075928
Validation loss: 1.8557966511736634

Epoch: 5| Step: 9
Training loss: 1.262697696685791
Validation loss: 1.8688479726032545

Epoch: 5| Step: 10
Training loss: 0.8732759952545166
Validation loss: 1.8783382856717674

Epoch: 493| Step: 0
Training loss: 0.949962317943573
Validation loss: 1.8665875850185272

Epoch: 5| Step: 1
Training loss: 0.38585588335990906
Validation loss: 1.8968001334897933

Epoch: 5| Step: 2
Training loss: 1.0018460750579834
Validation loss: 1.8574261216707126

Epoch: 5| Step: 3
Training loss: 0.2029271125793457
Validation loss: 1.856263445269677

Epoch: 5| Step: 4
Training loss: 0.7999370694160461
Validation loss: 1.8323379678110923

Epoch: 5| Step: 5
Training loss: 1.65829598903656
Validation loss: 1.8534279459266252

Epoch: 5| Step: 6
Training loss: 0.6963683366775513
Validation loss: 1.880863904953003

Epoch: 5| Step: 7
Training loss: 0.783849835395813
Validation loss: 1.85532727549153

Epoch: 5| Step: 8
Training loss: 0.7081982493400574
Validation loss: 1.861569195665339

Epoch: 5| Step: 9
Training loss: 1.3143198490142822
Validation loss: 1.8761888319446194

Epoch: 5| Step: 10
Training loss: 0.5082746148109436
Validation loss: 1.8534572047571982

Epoch: 494| Step: 0
Training loss: 0.6912380456924438
Validation loss: 1.8492891301390946

Epoch: 5| Step: 1
Training loss: 0.7307416200637817
Validation loss: 1.8556959616240634

Epoch: 5| Step: 2
Training loss: 1.0606958866119385
Validation loss: 1.839327521221612

Epoch: 5| Step: 3
Training loss: 0.7777708768844604
Validation loss: 1.8415780221262286

Epoch: 5| Step: 4
Training loss: 0.5402544736862183
Validation loss: 1.8639222050225863

Epoch: 5| Step: 5
Training loss: 1.1174237728118896
Validation loss: 1.8719006802446099

Epoch: 5| Step: 6
Training loss: 0.8609110713005066
Validation loss: 1.8704321269066102

Epoch: 5| Step: 7
Training loss: 0.6523256897926331
Validation loss: 1.86386078147478

Epoch: 5| Step: 8
Training loss: 0.7177934050559998
Validation loss: 1.8898136282479892

Epoch: 5| Step: 9
Training loss: 0.9425839185714722
Validation loss: 1.8794043576845558

Epoch: 5| Step: 10
Training loss: 0.9092586636543274
Validation loss: 1.8836724732511787

Epoch: 495| Step: 0
Training loss: 0.7563425898551941
Validation loss: 1.8727197724003946

Epoch: 5| Step: 1
Training loss: 0.8281489610671997
Validation loss: 1.8529009101211384

Epoch: 5| Step: 2
Training loss: 0.8915729522705078
Validation loss: 1.8258193333943684

Epoch: 5| Step: 3
Training loss: 1.0367953777313232
Validation loss: 1.8324125966718119

Epoch: 5| Step: 4
Training loss: 0.7221682667732239
Validation loss: 1.8449110536165134

Epoch: 5| Step: 5
Training loss: 0.5540410876274109
Validation loss: 1.858027901700748

Epoch: 5| Step: 6
Training loss: 0.6346015334129333
Validation loss: 1.8557036820278372

Epoch: 5| Step: 7
Training loss: 0.6423207521438599
Validation loss: 1.8643843371381041

Epoch: 5| Step: 8
Training loss: 0.9654879570007324
Validation loss: 1.8643409090657388

Epoch: 5| Step: 9
Training loss: 0.964653491973877
Validation loss: 1.862445669789468

Epoch: 5| Step: 10
Training loss: 1.0028325319290161
Validation loss: 1.8679598172505696

Epoch: 496| Step: 0
Training loss: 1.0203664302825928
Validation loss: 1.8484166751625717

Epoch: 5| Step: 1
Training loss: 0.8177372813224792
Validation loss: 1.8251472237289592

Epoch: 5| Step: 2
Training loss: 0.7489851713180542
Validation loss: 1.8470961765576435

Epoch: 5| Step: 3
Training loss: 0.7876639366149902
Validation loss: 1.8403155021770026

Epoch: 5| Step: 4
Training loss: 1.1853629350662231
Validation loss: 1.836479297248266

Epoch: 5| Step: 5
Training loss: 0.5724530220031738
Validation loss: 1.8606574727642922

Epoch: 5| Step: 6
Training loss: 0.8098770380020142
Validation loss: 1.9069081326966644

Epoch: 5| Step: 7
Training loss: 0.705077052116394
Validation loss: 1.89541410118021

Epoch: 5| Step: 8
Training loss: 0.662623941898346
Validation loss: 1.8966857720446844

Epoch: 5| Step: 9
Training loss: 0.8827789425849915
Validation loss: 1.8855703710227885

Epoch: 5| Step: 10
Training loss: 0.8877933025360107
Validation loss: 1.885429032387272

Epoch: 497| Step: 0
Training loss: 1.0612952709197998
Validation loss: 1.8656874536186137

Epoch: 5| Step: 1
Training loss: 0.6895220279693604
Validation loss: 1.8602137283612323

Epoch: 5| Step: 2
Training loss: 0.9112476110458374
Validation loss: 1.845868193975059

Epoch: 5| Step: 3
Training loss: 1.1272386312484741
Validation loss: 1.8177588114174463

Epoch: 5| Step: 4
Training loss: 0.7048442959785461
Validation loss: 1.7900783759291454

Epoch: 5| Step: 5
Training loss: 0.7572599649429321
Validation loss: 1.797529048817132

Epoch: 5| Step: 6
Training loss: 0.7499585151672363
Validation loss: 1.8044500068951679

Epoch: 5| Step: 7
Training loss: 0.6992188096046448
Validation loss: 1.7899301667367258

Epoch: 5| Step: 8
Training loss: 1.1810404062271118
Validation loss: 1.8014543543579757

Epoch: 5| Step: 9
Training loss: 0.6907732486724854
Validation loss: 1.8585021098454793

Epoch: 5| Step: 10
Training loss: 0.5232205986976624
Validation loss: 1.8609120140793503

Epoch: 498| Step: 0
Training loss: 0.8222578763961792
Validation loss: 1.8565628349140126

Epoch: 5| Step: 1
Training loss: 0.8820421099662781
Validation loss: 1.8843851627842072

Epoch: 5| Step: 2
Training loss: 0.6645063161849976
Validation loss: 1.8681986613940167

Epoch: 5| Step: 3
Training loss: 0.6881162524223328
Validation loss: 1.8678689208081973

Epoch: 5| Step: 4
Training loss: 0.9786714315414429
Validation loss: 1.872422723359959

Epoch: 5| Step: 5
Training loss: 0.7726381421089172
Validation loss: 1.8604077113571988

Epoch: 5| Step: 6
Training loss: 0.7585647702217102
Validation loss: 1.8447939119031351

Epoch: 5| Step: 7
Training loss: 1.1758075952529907
Validation loss: 1.846758306667369

Epoch: 5| Step: 8
Training loss: 0.8339797854423523
Validation loss: 1.835777049423546

Epoch: 5| Step: 9
Training loss: 1.0643703937530518
Validation loss: 1.8485103781505297

Epoch: 5| Step: 10
Training loss: 0.3367367088794708
Validation loss: 1.8650491570913663

Epoch: 499| Step: 0
Training loss: 0.8171539306640625
Validation loss: 1.8780053969352477

Epoch: 5| Step: 1
Training loss: 0.7507138252258301
Validation loss: 1.8905894179497995

Epoch: 5| Step: 2
Training loss: 0.9384695887565613
Validation loss: 1.8677871714356125

Epoch: 5| Step: 3
Training loss: 0.8953483700752258
Validation loss: 1.8518165016687045

Epoch: 5| Step: 4
Training loss: 0.6822063326835632
Validation loss: 1.8674309484420284

Epoch: 5| Step: 5
Training loss: 0.6097065210342407
Validation loss: 1.864805338203266

Epoch: 5| Step: 6
Training loss: 0.7968274354934692
Validation loss: 1.862022228138421

Epoch: 5| Step: 7
Training loss: 0.592280387878418
Validation loss: 1.8770470401292205

Epoch: 5| Step: 8
Training loss: 0.9322493672370911
Validation loss: 1.883165140305796

Epoch: 5| Step: 9
Training loss: 0.7120012044906616
Validation loss: 1.884270812875481

Epoch: 5| Step: 10
Training loss: 1.1454529762268066
Validation loss: 1.8747529406701364

Epoch: 500| Step: 0
Training loss: 0.7373048067092896
Validation loss: 1.8789995126826788

Epoch: 5| Step: 1
Training loss: 0.5818554162979126
Validation loss: 1.9119477848852835

Epoch: 5| Step: 2
Training loss: 0.6163128614425659
Validation loss: 1.8693360167164956

Epoch: 5| Step: 3
Training loss: 0.6164910197257996
Validation loss: 1.8678179043595509

Epoch: 5| Step: 4
Training loss: 1.1077520847320557
Validation loss: 1.8774523478682323

Epoch: 5| Step: 5
Training loss: 0.8225189447402954
Validation loss: 1.8270707117613925

Epoch: 5| Step: 6
Training loss: 0.6402724981307983
Validation loss: 1.861108826052758

Epoch: 5| Step: 7
Training loss: 0.8771942257881165
Validation loss: 1.8533267539034608

Epoch: 5| Step: 8
Training loss: 1.0094822645187378
Validation loss: 1.8228129251028902

Epoch: 5| Step: 9
Training loss: 1.1721326112747192
Validation loss: 1.8405603939487087

Epoch: 5| Step: 10
Training loss: 0.6362746953964233
Validation loss: 1.8635020166315057

Epoch: 501| Step: 0
Training loss: 0.7064597606658936
Validation loss: 1.8629446311663556

Epoch: 5| Step: 1
Training loss: 1.0245490074157715
Validation loss: 1.8559115855924544

Epoch: 5| Step: 2
Training loss: 0.9233630895614624
Validation loss: 1.8722375541604974

Epoch: 5| Step: 3
Training loss: 0.8131116628646851
Validation loss: 1.8532150740264564

Epoch: 5| Step: 4
Training loss: 0.6819463968276978
Validation loss: 1.8561272954428067

Epoch: 5| Step: 5
Training loss: 1.0908739566802979
Validation loss: 1.8604110825446345

Epoch: 5| Step: 6
Training loss: 0.8831785917282104
Validation loss: 1.8830572866624402

Epoch: 5| Step: 7
Training loss: 0.6120620369911194
Validation loss: 1.8539816435947214

Epoch: 5| Step: 8
Training loss: 0.4779368042945862
Validation loss: 1.8729588985443115

Epoch: 5| Step: 9
Training loss: 0.6101479530334473
Validation loss: 1.8822288513183594

Epoch: 5| Step: 10
Training loss: 1.1162607669830322
Validation loss: 1.8636564003523959

Epoch: 502| Step: 0
Training loss: 0.6939627528190613
Validation loss: 1.872352243751608

Epoch: 5| Step: 1
Training loss: 0.8480135798454285
Validation loss: 1.8680974732163131

Epoch: 5| Step: 2
Training loss: 1.099565863609314
Validation loss: 1.8687248806799612

Epoch: 5| Step: 3
Training loss: 0.6263139247894287
Validation loss: 1.8861501652707335

Epoch: 5| Step: 4
Training loss: 0.6303563714027405
Validation loss: 1.8899907373612927

Epoch: 5| Step: 5
Training loss: 0.46980971097946167
Validation loss: 1.870625365164972

Epoch: 5| Step: 6
Training loss: 0.9865289926528931
Validation loss: 1.8695089150500555

Epoch: 5| Step: 7
Training loss: 0.7892483472824097
Validation loss: 1.8795320180154615

Epoch: 5| Step: 8
Training loss: 0.8021599650382996
Validation loss: 1.8709720514153922

Epoch: 5| Step: 9
Training loss: 1.0335073471069336
Validation loss: 1.8598806435062039

Epoch: 5| Step: 10
Training loss: 0.6444074511528015
Validation loss: 1.8525361553315194

Epoch: 503| Step: 0
Training loss: 0.5530096292495728
Validation loss: 1.8551684541086997

Epoch: 5| Step: 1
Training loss: 0.8494879603385925
Validation loss: 1.8397675457821097

Epoch: 5| Step: 2
Training loss: 1.1961387395858765
Validation loss: 1.8610499661455873

Epoch: 5| Step: 3
Training loss: 0.6310496926307678
Validation loss: 1.8707327560711933

Epoch: 5| Step: 4
Training loss: 0.6586259603500366
Validation loss: 1.8848693832274406

Epoch: 5| Step: 5
Training loss: 0.6520179510116577
Validation loss: 1.9050133728211927

Epoch: 5| Step: 6
Training loss: 0.8982466459274292
Validation loss: 1.8962945502291444

Epoch: 5| Step: 7
Training loss: 0.8160504102706909
Validation loss: 1.9051234350409558

Epoch: 5| Step: 8
Training loss: 0.4734574854373932
Validation loss: 1.8870875758509482

Epoch: 5| Step: 9
Training loss: 1.019249439239502
Validation loss: 1.8707274467714372

Epoch: 5| Step: 10
Training loss: 0.9771671295166016
Validation loss: 1.8621089843011671

Epoch: 504| Step: 0
Training loss: 0.8702237010002136
Validation loss: 1.8408221224302888

Epoch: 5| Step: 1
Training loss: 0.9710603952407837
Validation loss: 1.8168814336099932

Epoch: 5| Step: 2
Training loss: 0.5150972604751587
Validation loss: 1.8284929670313352

Epoch: 5| Step: 3
Training loss: 0.6858736276626587
Validation loss: 1.8289827787747948

Epoch: 5| Step: 4
Training loss: 1.127671241760254
Validation loss: 1.8473105007602322

Epoch: 5| Step: 5
Training loss: 0.9061533212661743
Validation loss: 1.851952665595598

Epoch: 5| Step: 6
Training loss: 0.9078013300895691
Validation loss: 1.8634635594583326

Epoch: 5| Step: 7
Training loss: 0.5213779807090759
Validation loss: 1.8728597753791398

Epoch: 5| Step: 8
Training loss: 0.30661100149154663
Validation loss: 1.8949960739381853

Epoch: 5| Step: 9
Training loss: 0.9928570985794067
Validation loss: 1.8746469841208508

Epoch: 5| Step: 10
Training loss: 0.8171275854110718
Validation loss: 1.8615644196028351

Epoch: 505| Step: 0
Training loss: 0.6076787710189819
Validation loss: 1.8569643805103917

Epoch: 5| Step: 1
Training loss: 0.45035320520401
Validation loss: 1.8425491984172533

Epoch: 5| Step: 2
Training loss: 0.7212887406349182
Validation loss: 1.8292906194604852

Epoch: 5| Step: 3
Training loss: 0.7519441843032837
Validation loss: 1.8507594831528202

Epoch: 5| Step: 4
Training loss: 0.8601372838020325
Validation loss: 1.8216884789928314

Epoch: 5| Step: 5
Training loss: 1.046924352645874
Validation loss: 1.8252652460528958

Epoch: 5| Step: 6
Training loss: 1.570034384727478
Validation loss: 1.8556503941935878

Epoch: 5| Step: 7
Training loss: 0.7529410123825073
Validation loss: 1.8900675901802637

Epoch: 5| Step: 8
Training loss: 0.4133068919181824
Validation loss: 1.852085905690347

Epoch: 5| Step: 9
Training loss: 0.6590754389762878
Validation loss: 1.8279730196922057

Epoch: 5| Step: 10
Training loss: 0.8897862434387207
Validation loss: 1.8319097539430023

Epoch: 506| Step: 0
Training loss: 0.8643137216567993
Validation loss: 1.824121670056415

Epoch: 5| Step: 1
Training loss: 0.6035899519920349
Validation loss: 1.834897901422234

Epoch: 5| Step: 2
Training loss: 0.7524362802505493
Validation loss: 1.8229278915671892

Epoch: 5| Step: 3
Training loss: 0.571195125579834
Validation loss: 1.833475124451422

Epoch: 5| Step: 4
Training loss: 0.5030127167701721
Validation loss: 1.8656762030816847

Epoch: 5| Step: 5
Training loss: 0.7955700755119324
Validation loss: 1.8331364265052221

Epoch: 5| Step: 6
Training loss: 0.6088494062423706
Validation loss: 1.8868459527210524

Epoch: 5| Step: 7
Training loss: 0.6111553907394409
Validation loss: 1.9184698545804588

Epoch: 5| Step: 8
Training loss: 1.1810297966003418
Validation loss: 1.9240641484978378

Epoch: 5| Step: 9
Training loss: 1.0697829723358154
Validation loss: 1.8843612696534844

Epoch: 5| Step: 10
Training loss: 1.1656817197799683
Validation loss: 1.846039577197003

Epoch: 507| Step: 0
Training loss: 0.9656461477279663
Validation loss: 1.833900523442094

Epoch: 5| Step: 1
Training loss: 0.347107857465744
Validation loss: 1.836558961099194

Epoch: 5| Step: 2
Training loss: 0.8556874990463257
Validation loss: 1.843458132077289

Epoch: 5| Step: 3
Training loss: 0.7606735229492188
Validation loss: 1.8350111989564792

Epoch: 5| Step: 4
Training loss: 0.7000712156295776
Validation loss: 1.8474366229067567

Epoch: 5| Step: 5
Training loss: 0.6041178703308105
Validation loss: 1.8566389032589492

Epoch: 5| Step: 6
Training loss: 0.6312730312347412
Validation loss: 1.8485484251412012

Epoch: 5| Step: 7
Training loss: 0.9590466618537903
Validation loss: 1.8670309128299836

Epoch: 5| Step: 8
Training loss: 1.129945993423462
Validation loss: 1.876294876939507

Epoch: 5| Step: 9
Training loss: 1.0438697338104248
Validation loss: 1.8847528555059945

Epoch: 5| Step: 10
Training loss: 0.46606773138046265
Validation loss: 1.862170583458357

Epoch: 508| Step: 0
Training loss: 0.6610318422317505
Validation loss: 1.8527329762776692

Epoch: 5| Step: 1
Training loss: 1.0100455284118652
Validation loss: 1.8452117289266279

Epoch: 5| Step: 2
Training loss: 0.6539134383201599
Validation loss: 1.8298589516711492

Epoch: 5| Step: 3
Training loss: 0.7767885327339172
Validation loss: 1.8165138024155811

Epoch: 5| Step: 4
Training loss: 0.9084433317184448
Validation loss: 1.8163366599749493

Epoch: 5| Step: 5
Training loss: 0.8559001684188843
Validation loss: 1.8319297118853497

Epoch: 5| Step: 6
Training loss: 0.8798604011535645
Validation loss: 1.8173360645130117

Epoch: 5| Step: 7
Training loss: 0.7603771090507507
Validation loss: 1.8441027287513978

Epoch: 5| Step: 8
Training loss: 0.6130110621452332
Validation loss: 1.8561291258822206

Epoch: 5| Step: 9
Training loss: 0.6324031949043274
Validation loss: 1.873012977261697

Epoch: 5| Step: 10
Training loss: 0.7084755897521973
Validation loss: 1.8824144307003225

Epoch: 509| Step: 0
Training loss: 0.6797796487808228
Validation loss: 1.8877807048059279

Epoch: 5| Step: 1
Training loss: 0.8125780820846558
Validation loss: 1.890294954340945

Epoch: 5| Step: 2
Training loss: 1.063739538192749
Validation loss: 1.899985231379027

Epoch: 5| Step: 3
Training loss: 0.6243206858634949
Validation loss: 1.8603257979116132

Epoch: 5| Step: 4
Training loss: 0.19491156935691833
Validation loss: 1.840947199893254

Epoch: 5| Step: 5
Training loss: 0.4388163685798645
Validation loss: 1.8484362991907264

Epoch: 5| Step: 6
Training loss: 0.785293698310852
Validation loss: 1.8299517657167168

Epoch: 5| Step: 7
Training loss: 0.829292893409729
Validation loss: 1.8139377358139201

Epoch: 5| Step: 8
Training loss: 1.0192617177963257
Validation loss: 1.8267818304800219

Epoch: 5| Step: 9
Training loss: 1.2743545770645142
Validation loss: 1.831084466749622

Epoch: 5| Step: 10
Training loss: 0.7328363060951233
Validation loss: 1.8285047238872898

Epoch: 510| Step: 0
Training loss: 0.42879024147987366
Validation loss: 1.8566578767632926

Epoch: 5| Step: 1
Training loss: 0.8060300946235657
Validation loss: 1.8367219022525254

Epoch: 5| Step: 2
Training loss: 0.8176229596138
Validation loss: 1.856271182337115

Epoch: 5| Step: 3
Training loss: 0.8951019048690796
Validation loss: 1.8333640585663498

Epoch: 5| Step: 4
Training loss: 0.8635672330856323
Validation loss: 1.8411019835420834

Epoch: 5| Step: 5
Training loss: 0.5496550798416138
Validation loss: 1.829812697184983

Epoch: 5| Step: 6
Training loss: 0.8781797289848328
Validation loss: 1.841868467228387

Epoch: 5| Step: 7
Training loss: 0.937963604927063
Validation loss: 1.8457001780950895

Epoch: 5| Step: 8
Training loss: 0.3601999282836914
Validation loss: 1.850088534816619

Epoch: 5| Step: 9
Training loss: 0.8975964784622192
Validation loss: 1.8427546075595322

Epoch: 5| Step: 10
Training loss: 0.7978837490081787
Validation loss: 1.8530559437249297

Epoch: 511| Step: 0
Training loss: 1.0200527906417847
Validation loss: 1.8416608123369114

Epoch: 5| Step: 1
Training loss: 0.6608749628067017
Validation loss: 1.8677664674738401

Epoch: 5| Step: 2
Training loss: 0.7183823585510254
Validation loss: 1.8271448458394697

Epoch: 5| Step: 3
Training loss: 0.7450157403945923
Validation loss: 1.8146858740878362

Epoch: 5| Step: 4
Training loss: 0.9529590606689453
Validation loss: 1.8220945865877214

Epoch: 5| Step: 5
Training loss: 0.5663975477218628
Validation loss: 1.8333752783395911

Epoch: 5| Step: 6
Training loss: 0.7279902696609497
Validation loss: 1.8324599958235217

Epoch: 5| Step: 7
Training loss: 0.9153249859809875
Validation loss: 1.8200806366500033

Epoch: 5| Step: 8
Training loss: 0.7494010329246521
Validation loss: 1.8006227477904289

Epoch: 5| Step: 9
Training loss: 0.6434906125068665
Validation loss: 1.8207590221076884

Epoch: 5| Step: 10
Training loss: 0.7554956674575806
Validation loss: 1.8303998657452163

Epoch: 512| Step: 0
Training loss: 0.4575168192386627
Validation loss: 1.846788760154478

Epoch: 5| Step: 1
Training loss: 0.8963508605957031
Validation loss: 1.8394679087464527

Epoch: 5| Step: 2
Training loss: 0.9316411018371582
Validation loss: 1.8616204748871505

Epoch: 5| Step: 3
Training loss: 0.6498640775680542
Validation loss: 1.8386155546352427

Epoch: 5| Step: 4
Training loss: 0.6890164613723755
Validation loss: 1.8229871731932445

Epoch: 5| Step: 5
Training loss: 0.5453716516494751
Validation loss: 1.8308905760447185

Epoch: 5| Step: 6
Training loss: 0.8714311718940735
Validation loss: 1.824644107972422

Epoch: 5| Step: 7
Training loss: 0.7215247750282288
Validation loss: 1.8139615417808614

Epoch: 5| Step: 8
Training loss: 1.051079511642456
Validation loss: 1.833864632473197

Epoch: 5| Step: 9
Training loss: 0.6942753195762634
Validation loss: 1.8186246759148055

Epoch: 5| Step: 10
Training loss: 0.9898625612258911
Validation loss: 1.8363590727570236

Epoch: 513| Step: 0
Training loss: 0.6640709638595581
Validation loss: 1.8103908890037126

Epoch: 5| Step: 1
Training loss: 0.9533817172050476
Validation loss: 1.8155321856980682

Epoch: 5| Step: 2
Training loss: 0.6627888679504395
Validation loss: 1.8359950793686735

Epoch: 5| Step: 3
Training loss: 0.633131206035614
Validation loss: 1.8171192343517015

Epoch: 5| Step: 4
Training loss: 0.6181646585464478
Validation loss: 1.8135660412491008

Epoch: 5| Step: 5
Training loss: 0.9539380073547363
Validation loss: 1.8347740301521875

Epoch: 5| Step: 6
Training loss: 0.7054471373558044
Validation loss: 1.809565374928136

Epoch: 5| Step: 7
Training loss: 0.9052568674087524
Validation loss: 1.7901745047620548

Epoch: 5| Step: 8
Training loss: 0.5169426202774048
Validation loss: 1.788652136761655

Epoch: 5| Step: 9
Training loss: 0.8592103719711304
Validation loss: 1.7871829027770667

Epoch: 5| Step: 10
Training loss: 0.8272745609283447
Validation loss: 1.7834134640232209

Epoch: 514| Step: 0
Training loss: 1.1077876091003418
Validation loss: 1.8011060530139553

Epoch: 5| Step: 1
Training loss: 0.5764383673667908
Validation loss: 1.8066790296185402

Epoch: 5| Step: 2
Training loss: 0.6267421841621399
Validation loss: 1.818531838796472

Epoch: 5| Step: 3
Training loss: 0.7572253942489624
Validation loss: 1.821521887215235

Epoch: 5| Step: 4
Training loss: 0.7701641321182251
Validation loss: 1.8362400634314424

Epoch: 5| Step: 5
Training loss: 0.7123645544052124
Validation loss: 1.8446375246970885

Epoch: 5| Step: 6
Training loss: 0.7067105174064636
Validation loss: 1.833644123487575

Epoch: 5| Step: 7
Training loss: 1.019897699356079
Validation loss: 1.8415638554480769

Epoch: 5| Step: 8
Training loss: 0.6747840642929077
Validation loss: 1.8564377625783284

Epoch: 5| Step: 9
Training loss: 0.6356834173202515
Validation loss: 1.8395696750251196

Epoch: 5| Step: 10
Training loss: 0.6937960982322693
Validation loss: 1.7989423685176398

Epoch: 515| Step: 0
Training loss: 0.8306439518928528
Validation loss: 1.8154775993798369

Epoch: 5| Step: 1
Training loss: 0.7424039840698242
Validation loss: 1.7859782967516171

Epoch: 5| Step: 2
Training loss: 0.9793488383293152
Validation loss: 1.7712550086359824

Epoch: 5| Step: 3
Training loss: 0.6013280749320984
Validation loss: 1.7398058246540766

Epoch: 5| Step: 4
Training loss: 0.8367886543273926
Validation loss: 1.7904306329706663

Epoch: 5| Step: 5
Training loss: 0.7567547559738159
Validation loss: 1.7862448512866933

Epoch: 5| Step: 6
Training loss: 0.6833134889602661
Validation loss: 1.8073053975259104

Epoch: 5| Step: 7
Training loss: 0.8245824575424194
Validation loss: 1.8319681729039838

Epoch: 5| Step: 8
Training loss: 0.5771158933639526
Validation loss: 1.816100574308826

Epoch: 5| Step: 9
Training loss: 0.649706244468689
Validation loss: 1.8136631442654518

Epoch: 5| Step: 10
Training loss: 0.8665377497673035
Validation loss: 1.8171385154929212

Epoch: 516| Step: 0
Training loss: 0.5971914529800415
Validation loss: 1.8357333470416326

Epoch: 5| Step: 1
Training loss: 0.755860447883606
Validation loss: 1.837976255724507

Epoch: 5| Step: 2
Training loss: 0.696816086769104
Validation loss: 1.8324988003700011

Epoch: 5| Step: 3
Training loss: 0.923932671546936
Validation loss: 1.8452702286422893

Epoch: 5| Step: 4
Training loss: 0.7973604798316956
Validation loss: 1.8028196006692865

Epoch: 5| Step: 5
Training loss: 0.6485785245895386
Validation loss: 1.813609941031343

Epoch: 5| Step: 6
Training loss: 1.07407808303833
Validation loss: 1.7900147104776034

Epoch: 5| Step: 7
Training loss: 0.7658382058143616
Validation loss: 1.7889884274492982

Epoch: 5| Step: 8
Training loss: 0.6481829881668091
Validation loss: 1.7800785341570455

Epoch: 5| Step: 9
Training loss: 0.6514951586723328
Validation loss: 1.8234482606252034

Epoch: 5| Step: 10
Training loss: 0.6540220975875854
Validation loss: 1.809580022288907

Epoch: 517| Step: 0
Training loss: 0.6593356132507324
Validation loss: 1.8324061055337229

Epoch: 5| Step: 1
Training loss: 0.640641450881958
Validation loss: 1.8317073698966735

Epoch: 5| Step: 2
Training loss: 0.738700807094574
Validation loss: 1.8375158950846682

Epoch: 5| Step: 3
Training loss: 1.0706348419189453
Validation loss: 1.829815318507533

Epoch: 5| Step: 4
Training loss: 0.6308401226997375
Validation loss: 1.8274441585745862

Epoch: 5| Step: 5
Training loss: 0.6460430026054382
Validation loss: 1.8221752617948799

Epoch: 5| Step: 6
Training loss: 0.8930586576461792
Validation loss: 1.8099359607183805

Epoch: 5| Step: 7
Training loss: 0.6659652590751648
Validation loss: 1.850791323569513

Epoch: 5| Step: 8
Training loss: 1.1278810501098633
Validation loss: 1.8636547852587957

Epoch: 5| Step: 9
Training loss: 0.8163508176803589
Validation loss: 1.8969300652063021

Epoch: 5| Step: 10
Training loss: 0.3042639493942261
Validation loss: 1.8865983665630381

Epoch: 518| Step: 0
Training loss: 0.45875492691993713
Validation loss: 1.8462458259315901

Epoch: 5| Step: 1
Training loss: 0.9541451334953308
Validation loss: 1.8432270634558894

Epoch: 5| Step: 2
Training loss: 0.703373908996582
Validation loss: 1.7498273490577616

Epoch: 5| Step: 3
Training loss: 0.7625422477722168
Validation loss: 1.7808043469664872

Epoch: 5| Step: 4
Training loss: 0.7971863746643066
Validation loss: 1.7515137631406066

Epoch: 5| Step: 5
Training loss: 0.7361809015274048
Validation loss: 1.7662372025110389

Epoch: 5| Step: 6
Training loss: 0.9632948040962219
Validation loss: 1.7540299687334286

Epoch: 5| Step: 7
Training loss: 0.6612520217895508
Validation loss: 1.7709669323377712

Epoch: 5| Step: 8
Training loss: 0.710689902305603
Validation loss: 1.8027566235552552

Epoch: 5| Step: 9
Training loss: 0.9224348068237305
Validation loss: 1.8120283695959276

Epoch: 5| Step: 10
Training loss: 0.7181867957115173
Validation loss: 1.8435497668481642

Epoch: 519| Step: 0
Training loss: 0.7319616079330444
Validation loss: 1.8785303074826476

Epoch: 5| Step: 1
Training loss: 0.8244826197624207
Validation loss: 1.8824894710253643

Epoch: 5| Step: 2
Training loss: 0.5671478509902954
Validation loss: 1.8478703421931113

Epoch: 5| Step: 3
Training loss: 1.1545312404632568
Validation loss: 1.8692578577226209

Epoch: 5| Step: 4
Training loss: 0.6532440185546875
Validation loss: 1.842653835973432

Epoch: 5| Step: 5
Training loss: 0.34468013048171997
Validation loss: 1.8210291426668885

Epoch: 5| Step: 6
Training loss: 0.7657254934310913
Validation loss: 1.7970623905940721

Epoch: 5| Step: 7
Training loss: 0.8772687911987305
Validation loss: 1.7862089731359994

Epoch: 5| Step: 8
Training loss: 0.6064671277999878
Validation loss: 1.7657361197215256

Epoch: 5| Step: 9
Training loss: 0.9018461108207703
Validation loss: 1.7741544515855852

Epoch: 5| Step: 10
Training loss: 0.9927066564559937
Validation loss: 1.8346599225075013

Epoch: 520| Step: 0
Training loss: 1.097381830215454
Validation loss: 1.8671928823635142

Epoch: 5| Step: 1
Training loss: 1.1168626546859741
Validation loss: 1.9024069142597977

Epoch: 5| Step: 2
Training loss: 1.3498996496200562
Validation loss: 1.8950914926426385

Epoch: 5| Step: 3
Training loss: 0.72075355052948
Validation loss: 1.8939491779573503

Epoch: 5| Step: 4
Training loss: 0.5369805693626404
Validation loss: 1.8611818154652913

Epoch: 5| Step: 5
Training loss: 0.43678197264671326
Validation loss: 1.8504035037050965

Epoch: 5| Step: 6
Training loss: 0.6910185813903809
Validation loss: 1.849122170479067

Epoch: 5| Step: 7
Training loss: 0.5840016603469849
Validation loss: 1.8560435515578075

Epoch: 5| Step: 8
Training loss: 0.669875979423523
Validation loss: 1.8173682023120183

Epoch: 5| Step: 9
Training loss: 0.9771605730056763
Validation loss: 1.776782347309974

Epoch: 5| Step: 10
Training loss: 0.37143248319625854
Validation loss: 1.7936190046289915

Epoch: 521| Step: 0
Training loss: 0.7732852697372437
Validation loss: 1.7555279770205099

Epoch: 5| Step: 1
Training loss: 0.7656664252281189
Validation loss: 1.7531935091941588

Epoch: 5| Step: 2
Training loss: 0.8440045118331909
Validation loss: 1.7862637453181769

Epoch: 5| Step: 3
Training loss: 0.9267487525939941
Validation loss: 1.8179328851802374

Epoch: 5| Step: 4
Training loss: 0.5559727549552917
Validation loss: 1.8334541487437424

Epoch: 5| Step: 5
Training loss: 0.6644611358642578
Validation loss: 1.8178772157238376

Epoch: 5| Step: 6
Training loss: 0.7899165749549866
Validation loss: 1.8395573093045143

Epoch: 5| Step: 7
Training loss: 0.5877145528793335
Validation loss: 1.8306729165456628

Epoch: 5| Step: 8
Training loss: 0.839194118976593
Validation loss: 1.8383020277946227

Epoch: 5| Step: 9
Training loss: 0.6645113229751587
Validation loss: 1.8316244656039822

Epoch: 5| Step: 10
Training loss: 1.028427243232727
Validation loss: 1.8147641189636723

Epoch: 522| Step: 0
Training loss: 0.8837282061576843
Validation loss: 1.7862142696175525

Epoch: 5| Step: 1
Training loss: 0.5989264249801636
Validation loss: 1.7762664671867125

Epoch: 5| Step: 2
Training loss: 0.9538053274154663
Validation loss: 1.777085304260254

Epoch: 5| Step: 3
Training loss: 0.8190709948539734
Validation loss: 1.791932709755436

Epoch: 5| Step: 4
Training loss: 0.5470999479293823
Validation loss: 1.7732679177356023

Epoch: 5| Step: 5
Training loss: 0.4782598614692688
Validation loss: 1.8068272324018582

Epoch: 5| Step: 6
Training loss: 1.0038678646087646
Validation loss: 1.8154017374079714

Epoch: 5| Step: 7
Training loss: 1.08474600315094
Validation loss: 1.8229129263149795

Epoch: 5| Step: 8
Training loss: 0.6564475893974304
Validation loss: 1.8300352583649337

Epoch: 5| Step: 9
Training loss: 0.6215871572494507
Validation loss: 1.8641817979915167

Epoch: 5| Step: 10
Training loss: 0.45572465658187866
Validation loss: 1.8466941143876763

Epoch: 523| Step: 0
Training loss: 0.6758022904396057
Validation loss: 1.855488158041431

Epoch: 5| Step: 1
Training loss: 0.5082452297210693
Validation loss: 1.8368171389384935

Epoch: 5| Step: 2
Training loss: 0.7629479169845581
Validation loss: 1.8194300525931901

Epoch: 5| Step: 3
Training loss: 0.6356404423713684
Validation loss: 1.825772455943528

Epoch: 5| Step: 4
Training loss: 0.6273255944252014
Validation loss: 1.8209038408853675

Epoch: 5| Step: 5
Training loss: 0.4595082402229309
Validation loss: 1.8205250834905973

Epoch: 5| Step: 6
Training loss: 1.2624465227127075
Validation loss: 1.7998279140841575

Epoch: 5| Step: 7
Training loss: 1.0864696502685547
Validation loss: 1.7783987496488838

Epoch: 5| Step: 8
Training loss: 0.7858401536941528
Validation loss: 1.7679307076238817

Epoch: 5| Step: 9
Training loss: 0.6926776170730591
Validation loss: 1.7643727640951834

Epoch: 5| Step: 10
Training loss: 0.6776586174964905
Validation loss: 1.7616543052017049

Epoch: 524| Step: 0
Training loss: 0.8194230198860168
Validation loss: 1.7638527398468347

Epoch: 5| Step: 1
Training loss: 0.42509546875953674
Validation loss: 1.7970742307683474

Epoch: 5| Step: 2
Training loss: 0.5498769283294678
Validation loss: 1.8146049719984814

Epoch: 5| Step: 3
Training loss: 0.5499863028526306
Validation loss: 1.8066538867130075

Epoch: 5| Step: 4
Training loss: 0.79081130027771
Validation loss: 1.82608066579347

Epoch: 5| Step: 5
Training loss: 0.46500134468078613
Validation loss: 1.8501563572114514

Epoch: 5| Step: 6
Training loss: 1.001881718635559
Validation loss: 1.855461315442157

Epoch: 5| Step: 7
Training loss: 0.9305121302604675
Validation loss: 1.8610510031382244

Epoch: 5| Step: 8
Training loss: 0.7377824783325195
Validation loss: 1.8743347852460799

Epoch: 5| Step: 9
Training loss: 1.011868953704834
Validation loss: 1.831944324636972

Epoch: 5| Step: 10
Training loss: 0.7345798015594482
Validation loss: 1.8179872484617337

Epoch: 525| Step: 0
Training loss: 0.7457722425460815
Validation loss: 1.8036483116047357

Epoch: 5| Step: 1
Training loss: 0.6269432306289673
Validation loss: 1.7864012231108963

Epoch: 5| Step: 2
Training loss: 0.36834484338760376
Validation loss: 1.7959833927051996

Epoch: 5| Step: 3
Training loss: 0.8698976635932922
Validation loss: 1.7911141662187473

Epoch: 5| Step: 4
Training loss: 0.4779300093650818
Validation loss: 1.7827325482522287

Epoch: 5| Step: 5
Training loss: 1.296491026878357
Validation loss: 1.7737978389186244

Epoch: 5| Step: 6
Training loss: 0.6379824280738831
Validation loss: 1.7730550189172067

Epoch: 5| Step: 7
Training loss: 0.7322404384613037
Validation loss: 1.7597830410926574

Epoch: 5| Step: 8
Training loss: 0.6028925180435181
Validation loss: 1.7747803926467896

Epoch: 5| Step: 9
Training loss: 0.994471549987793
Validation loss: 1.7861732975129159

Epoch: 5| Step: 10
Training loss: 0.676112949848175
Validation loss: 1.8164962414772279

Epoch: 526| Step: 0
Training loss: 1.0408737659454346
Validation loss: 1.8267683162484118

Epoch: 5| Step: 1
Training loss: 0.5294674634933472
Validation loss: 1.8331290778293405

Epoch: 5| Step: 2
Training loss: 0.6700658798217773
Validation loss: 1.8087282462786602

Epoch: 5| Step: 3
Training loss: 0.5492664575576782
Validation loss: 1.8069635539926507

Epoch: 5| Step: 4
Training loss: 0.7921954989433289
Validation loss: 1.7903557413367814

Epoch: 5| Step: 5
Training loss: 0.7702068090438843
Validation loss: 1.7753031279451104

Epoch: 5| Step: 6
Training loss: 0.795066237449646
Validation loss: 1.8202532901558826

Epoch: 5| Step: 7
Training loss: 0.8555418848991394
Validation loss: 1.821107978461891

Epoch: 5| Step: 8
Training loss: 0.6403511166572571
Validation loss: 1.8473251506846438

Epoch: 5| Step: 9
Training loss: 0.5201717615127563
Validation loss: 1.8380281489382508

Epoch: 5| Step: 10
Training loss: 0.7546467185020447
Validation loss: 1.8545460547170332

Epoch: 527| Step: 0
Training loss: 1.122749924659729
Validation loss: 1.8432957869704052

Epoch: 5| Step: 1
Training loss: 0.5821026563644409
Validation loss: 1.8570559409356886

Epoch: 5| Step: 2
Training loss: 0.9866442680358887
Validation loss: 1.8679559551259524

Epoch: 5| Step: 3
Training loss: 0.6685454249382019
Validation loss: 1.8561085616388628

Epoch: 5| Step: 4
Training loss: 0.4424789845943451
Validation loss: 1.850884452942879

Epoch: 5| Step: 5
Training loss: 0.6040979623794556
Validation loss: 1.8454156819210257

Epoch: 5| Step: 6
Training loss: 0.6163414716720581
Validation loss: 1.8444315464265886

Epoch: 5| Step: 7
Training loss: 0.9459377527236938
Validation loss: 1.8330833117167156

Epoch: 5| Step: 8
Training loss: 0.5244244933128357
Validation loss: 1.8363563732434345

Epoch: 5| Step: 9
Training loss: 0.6713287234306335
Validation loss: 1.8275547181406329

Epoch: 5| Step: 10
Training loss: 0.7006781101226807
Validation loss: 1.8123798267815703

Epoch: 528| Step: 0
Training loss: 0.548678994178772
Validation loss: 1.8221248465199624

Epoch: 5| Step: 1
Training loss: 0.588819146156311
Validation loss: 1.8546981632068593

Epoch: 5| Step: 2
Training loss: 0.6816200613975525
Validation loss: 1.8242757499858897

Epoch: 5| Step: 3
Training loss: 0.39245909452438354
Validation loss: 1.8369560536517893

Epoch: 5| Step: 4
Training loss: 1.1778678894042969
Validation loss: 1.8436568924175796

Epoch: 5| Step: 5
Training loss: 0.7330759167671204
Validation loss: 1.7972448846345306

Epoch: 5| Step: 6
Training loss: 1.2212315797805786
Validation loss: 1.824881031949033

Epoch: 5| Step: 7
Training loss: 0.6715008020401001
Validation loss: 1.8073034017316756

Epoch: 5| Step: 8
Training loss: 0.5078794360160828
Validation loss: 1.8081066031609812

Epoch: 5| Step: 9
Training loss: 0.6959802508354187
Validation loss: 1.8177966917714765

Epoch: 5| Step: 10
Training loss: 0.5537592172622681
Validation loss: 1.8135890550510858

Epoch: 529| Step: 0
Training loss: 0.6519513130187988
Validation loss: 1.8117435965486752

Epoch: 5| Step: 1
Training loss: 0.9104180335998535
Validation loss: 1.7891585967874015

Epoch: 5| Step: 2
Training loss: 0.7601824998855591
Validation loss: 1.7938327225305701

Epoch: 5| Step: 3
Training loss: 0.6017146706581116
Validation loss: 1.8083478276447584

Epoch: 5| Step: 4
Training loss: 0.8951358795166016
Validation loss: 1.7965342972868232

Epoch: 5| Step: 5
Training loss: 0.7493579983711243
Validation loss: 1.7775963185935892

Epoch: 5| Step: 6
Training loss: 0.4798645079135895
Validation loss: 1.7877062187399915

Epoch: 5| Step: 7
Training loss: 0.4281364977359772
Validation loss: 1.7859643492647397

Epoch: 5| Step: 8
Training loss: 0.5995798110961914
Validation loss: 1.8258223456721152

Epoch: 5| Step: 9
Training loss: 0.8191131353378296
Validation loss: 1.83117244192349

Epoch: 5| Step: 10
Training loss: 0.9739631414413452
Validation loss: 1.8697667480796896

Epoch: 530| Step: 0
Training loss: 0.7235615253448486
Validation loss: 1.8719507725008073

Epoch: 5| Step: 1
Training loss: 0.7953453660011292
Validation loss: 1.8634102498331377

Epoch: 5| Step: 2
Training loss: 0.6533302068710327
Validation loss: 1.8519699342789189

Epoch: 5| Step: 3
Training loss: 0.9051297903060913
Validation loss: 1.8287284143509404

Epoch: 5| Step: 4
Training loss: 0.5472911596298218
Validation loss: 1.817919667049121

Epoch: 5| Step: 5
Training loss: 0.43252843618392944
Validation loss: 1.8296773728503977

Epoch: 5| Step: 6
Training loss: 1.0116268396377563
Validation loss: 1.7834702025177658

Epoch: 5| Step: 7
Training loss: 0.5091310739517212
Validation loss: 1.799042163356658

Epoch: 5| Step: 8
Training loss: 0.7744429707527161
Validation loss: 1.7874075802423621

Epoch: 5| Step: 9
Training loss: 0.695782482624054
Validation loss: 1.8049602329090078

Epoch: 5| Step: 10
Training loss: 0.6570945978164673
Validation loss: 1.7904745724893385

Epoch: 531| Step: 0
Training loss: 0.810706615447998
Validation loss: 1.8337558418191888

Epoch: 5| Step: 1
Training loss: 0.6724007725715637
Validation loss: 1.8479824976254535

Epoch: 5| Step: 2
Training loss: 0.3948689103126526
Validation loss: 1.8417824775941911

Epoch: 5| Step: 3
Training loss: 0.9756374359130859
Validation loss: 1.8481616409876014

Epoch: 5| Step: 4
Training loss: 0.5672411918640137
Validation loss: 1.8695914155693465

Epoch: 5| Step: 5
Training loss: 0.9137473106384277
Validation loss: 1.8632038421528314

Epoch: 5| Step: 6
Training loss: 0.8574777841567993
Validation loss: 1.847309063839656

Epoch: 5| Step: 7
Training loss: 0.9077088236808777
Validation loss: 1.8478566510702974

Epoch: 5| Step: 8
Training loss: 0.48109546303749084
Validation loss: 1.8052043043157107

Epoch: 5| Step: 9
Training loss: 0.7027612328529358
Validation loss: 1.7806015309467111

Epoch: 5| Step: 10
Training loss: 0.5539939403533936
Validation loss: 1.7697033971868537

Epoch: 532| Step: 0
Training loss: 0.6294654011726379
Validation loss: 1.7920971044930079

Epoch: 5| Step: 1
Training loss: 0.8664692640304565
Validation loss: 1.8056321067194785

Epoch: 5| Step: 2
Training loss: 0.6939476728439331
Validation loss: 1.7938208221107401

Epoch: 5| Step: 3
Training loss: 0.9921057820320129
Validation loss: 1.7893343228165821

Epoch: 5| Step: 4
Training loss: 0.8356224894523621
Validation loss: 1.7934279467469902

Epoch: 5| Step: 5
Training loss: 0.6424339413642883
Validation loss: 1.8218061129252117

Epoch: 5| Step: 6
Training loss: 0.5458430051803589
Validation loss: 1.8269465225999073

Epoch: 5| Step: 7
Training loss: 0.5078949332237244
Validation loss: 1.8352002623260661

Epoch: 5| Step: 8
Training loss: 0.7932652831077576
Validation loss: 1.8415840966727144

Epoch: 5| Step: 9
Training loss: 0.4673720896244049
Validation loss: 1.8339939783978205

Epoch: 5| Step: 10
Training loss: 0.7727978229522705
Validation loss: 1.8536932263323056

Epoch: 533| Step: 0
Training loss: 0.9715284109115601
Validation loss: 1.8325033854412776

Epoch: 5| Step: 1
Training loss: 0.8132263422012329
Validation loss: 1.8511882033399356

Epoch: 5| Step: 2
Training loss: 0.7623361349105835
Validation loss: 1.836823792867763

Epoch: 5| Step: 3
Training loss: 0.5796629190444946
Validation loss: 1.831175805420004

Epoch: 5| Step: 4
Training loss: 0.749683678150177
Validation loss: 1.7886076922057776

Epoch: 5| Step: 5
Training loss: 0.4326418340206146
Validation loss: 1.7820828460877942

Epoch: 5| Step: 6
Training loss: 0.7768533229827881
Validation loss: 1.7974439231298303

Epoch: 5| Step: 7
Training loss: 0.5153912901878357
Validation loss: 1.8003071828555035

Epoch: 5| Step: 8
Training loss: 0.5432512164115906
Validation loss: 1.794847857567572

Epoch: 5| Step: 9
Training loss: 0.6853865385055542
Validation loss: 1.8091873571436892

Epoch: 5| Step: 10
Training loss: 0.9756011962890625
Validation loss: 1.810189325322387

Epoch: 534| Step: 0
Training loss: 0.7470359802246094
Validation loss: 1.792282400592681

Epoch: 5| Step: 1
Training loss: 0.7324783802032471
Validation loss: 1.820329027791177

Epoch: 5| Step: 2
Training loss: 1.0120489597320557
Validation loss: 1.8311368316732428

Epoch: 5| Step: 3
Training loss: 0.9447862505912781
Validation loss: 1.8147172876583633

Epoch: 5| Step: 4
Training loss: 0.37287241220474243
Validation loss: 1.826962726090544

Epoch: 5| Step: 5
Training loss: 0.6116225719451904
Validation loss: 1.8125165970094743

Epoch: 5| Step: 6
Training loss: 0.4112013876438141
Validation loss: 1.7851901144109747

Epoch: 5| Step: 7
Training loss: 0.3971160054206848
Validation loss: 1.776511166685371

Epoch: 5| Step: 8
Training loss: 0.7169505953788757
Validation loss: 1.7770870142085577

Epoch: 5| Step: 9
Training loss: 1.0341249704360962
Validation loss: 1.7982610246186614

Epoch: 5| Step: 10
Training loss: 0.6417597532272339
Validation loss: 1.8201103915450394

Epoch: 535| Step: 0
Training loss: 0.8413181304931641
Validation loss: 1.7998672134132796

Epoch: 5| Step: 1
Training loss: 0.8115854263305664
Validation loss: 1.8036904027385097

Epoch: 5| Step: 2
Training loss: 0.39455509185791016
Validation loss: 1.7909279510539065

Epoch: 5| Step: 3
Training loss: 0.6410380601882935
Validation loss: 1.7911442633598083

Epoch: 5| Step: 4
Training loss: 0.7696810960769653
Validation loss: 1.81115508848621

Epoch: 5| Step: 5
Training loss: 1.0626757144927979
Validation loss: 1.7878430248588644

Epoch: 5| Step: 6
Training loss: 0.5088927745819092
Validation loss: 1.8365919974542433

Epoch: 5| Step: 7
Training loss: 0.9119669795036316
Validation loss: 1.8324439717877297

Epoch: 5| Step: 8
Training loss: 0.5218427777290344
Validation loss: 1.825845028764458

Epoch: 5| Step: 9
Training loss: 0.48159995675086975
Validation loss: 1.798882358817644

Epoch: 5| Step: 10
Training loss: 0.6027942299842834
Validation loss: 1.8171608601847002

Epoch: 536| Step: 0
Training loss: 0.6639482378959656
Validation loss: 1.8003167721533007

Epoch: 5| Step: 1
Training loss: 1.0591884851455688
Validation loss: 1.7923830914241012

Epoch: 5| Step: 2
Training loss: 0.4816921353340149
Validation loss: 1.8022812694631598

Epoch: 5| Step: 3
Training loss: 0.28786003589630127
Validation loss: 1.8429341188041113

Epoch: 5| Step: 4
Training loss: 0.9537996053695679
Validation loss: 1.8340297822029359

Epoch: 5| Step: 5
Training loss: 0.43933945894241333
Validation loss: 1.830074482066657

Epoch: 5| Step: 6
Training loss: 0.630311131477356
Validation loss: 1.818933356192804

Epoch: 5| Step: 7
Training loss: 0.3835228979587555
Validation loss: 1.7999638075469642

Epoch: 5| Step: 8
Training loss: 1.0616672039031982
Validation loss: 1.783138309755633

Epoch: 5| Step: 9
Training loss: 0.8338956832885742
Validation loss: 1.7960445957799112

Epoch: 5| Step: 10
Training loss: 0.7895953059196472
Validation loss: 1.8010375640725578

Epoch: 537| Step: 0
Training loss: 0.7633545398712158
Validation loss: 1.8225738156226374

Epoch: 5| Step: 1
Training loss: 0.9143096208572388
Validation loss: 1.822612775269375

Epoch: 5| Step: 2
Training loss: 0.5461021065711975
Validation loss: 1.8428336753640124

Epoch: 5| Step: 3
Training loss: 0.7865577936172485
Validation loss: 1.8092354561692925

Epoch: 5| Step: 4
Training loss: 0.8749238848686218
Validation loss: 1.8199638153917046

Epoch: 5| Step: 5
Training loss: 0.8059277534484863
Validation loss: 1.7963602645422823

Epoch: 5| Step: 6
Training loss: 0.5440011620521545
Validation loss: 1.779844949322362

Epoch: 5| Step: 7
Training loss: 0.6078913807868958
Validation loss: 1.773717608503116

Epoch: 5| Step: 8
Training loss: 0.6461429595947266
Validation loss: 1.7785670077928932

Epoch: 5| Step: 9
Training loss: 0.5289410352706909
Validation loss: 1.7622288503954489

Epoch: 5| Step: 10
Training loss: 0.6473022103309631
Validation loss: 1.779993559724541

Epoch: 538| Step: 0
Training loss: 0.5586513876914978
Validation loss: 1.7997657175986999

Epoch: 5| Step: 1
Training loss: 0.7648263573646545
Validation loss: 1.8343151115602063

Epoch: 5| Step: 2
Training loss: 0.6373460292816162
Validation loss: 1.8311169634583175

Epoch: 5| Step: 3
Training loss: 0.5687358379364014
Validation loss: 1.7975085986557828

Epoch: 5| Step: 4
Training loss: 0.564233660697937
Validation loss: 1.7904440100475023

Epoch: 5| Step: 5
Training loss: 0.8570052981376648
Validation loss: 1.8179271285251906

Epoch: 5| Step: 6
Training loss: 0.5319749116897583
Validation loss: 1.8248922440313524

Epoch: 5| Step: 7
Training loss: 0.9378921389579773
Validation loss: 1.830971884471114

Epoch: 5| Step: 8
Training loss: 0.9798043966293335
Validation loss: 1.8099858004559752

Epoch: 5| Step: 9
Training loss: 0.9171222448348999
Validation loss: 1.8062066198677145

Epoch: 5| Step: 10
Training loss: 0.5523136854171753
Validation loss: 1.7744831192877986

Epoch: 539| Step: 0
Training loss: 0.7241328358650208
Validation loss: 1.7601259011094288

Epoch: 5| Step: 1
Training loss: 0.518218457698822
Validation loss: 1.7324893090032762

Epoch: 5| Step: 2
Training loss: 0.6984779238700867
Validation loss: 1.7507296005884807

Epoch: 5| Step: 3
Training loss: 0.8759706616401672
Validation loss: 1.8108233290333902

Epoch: 5| Step: 4
Training loss: 0.6799741983413696
Validation loss: 1.7785324781171736

Epoch: 5| Step: 5
Training loss: 0.8076928853988647
Validation loss: 1.7936983070065897

Epoch: 5| Step: 6
Training loss: 0.7520544528961182
Validation loss: 1.789175627052143

Epoch: 5| Step: 7
Training loss: 0.8825751543045044
Validation loss: 1.8230935078795238

Epoch: 5| Step: 8
Training loss: 0.6210920214653015
Validation loss: 1.8028865213035254

Epoch: 5| Step: 9
Training loss: 0.5533420443534851
Validation loss: 1.783551598107943

Epoch: 5| Step: 10
Training loss: 0.4238588809967041
Validation loss: 1.7816535426724343

Epoch: 540| Step: 0
Training loss: 0.9048563838005066
Validation loss: 1.7585966330702587

Epoch: 5| Step: 1
Training loss: 0.6077367067337036
Validation loss: 1.7603484917712469

Epoch: 5| Step: 2
Training loss: 0.6012163162231445
Validation loss: 1.74868223744054

Epoch: 5| Step: 3
Training loss: 0.7166672945022583
Validation loss: 1.746438407128857

Epoch: 5| Step: 4
Training loss: 0.6367758512496948
Validation loss: 1.7834187874230005

Epoch: 5| Step: 5
Training loss: 0.5558452606201172
Validation loss: 1.774391556298861

Epoch: 5| Step: 6
Training loss: 0.7486761808395386
Validation loss: 1.7979943611288582

Epoch: 5| Step: 7
Training loss: 0.7654436230659485
Validation loss: 1.8288229050174836

Epoch: 5| Step: 8
Training loss: 0.6021941304206848
Validation loss: 1.8002333192415134

Epoch: 5| Step: 9
Training loss: 0.5585991740226746
Validation loss: 1.8431387050177461

Epoch: 5| Step: 10
Training loss: 0.8196799159049988
Validation loss: 1.8516363661776307

Epoch: 541| Step: 0
Training loss: 0.46849504113197327
Validation loss: 1.8779587514938847

Epoch: 5| Step: 1
Training loss: 0.6079732179641724
Validation loss: 1.8521557379794378

Epoch: 5| Step: 2
Training loss: 0.8269160985946655
Validation loss: 1.8595302028040732

Epoch: 5| Step: 3
Training loss: 0.665943443775177
Validation loss: 1.8688872168141026

Epoch: 5| Step: 4
Training loss: 0.5686122179031372
Validation loss: 1.8621718447695497

Epoch: 5| Step: 5
Training loss: 0.6053019762039185
Validation loss: 1.8301719760382047

Epoch: 5| Step: 6
Training loss: 0.8269135355949402
Validation loss: 1.8093438597135647

Epoch: 5| Step: 7
Training loss: 0.6548548936843872
Validation loss: 1.8124727997728574

Epoch: 5| Step: 8
Training loss: 0.6182256937026978
Validation loss: 1.7861182689666748

Epoch: 5| Step: 9
Training loss: 0.9442831873893738
Validation loss: 1.7911641559293192

Epoch: 5| Step: 10
Training loss: 0.6083885431289673
Validation loss: 1.7635133497176632

Epoch: 542| Step: 0
Training loss: 0.7625067234039307
Validation loss: 1.7898202044989473

Epoch: 5| Step: 1
Training loss: 0.4278826117515564
Validation loss: 1.7906942290644492

Epoch: 5| Step: 2
Training loss: 0.5131758451461792
Validation loss: 1.79811772864352

Epoch: 5| Step: 3
Training loss: 0.8814598321914673
Validation loss: 1.8088361460675475

Epoch: 5| Step: 4
Training loss: 0.6041807532310486
Validation loss: 1.8099463690993607

Epoch: 5| Step: 5
Training loss: 0.629660964012146
Validation loss: 1.8269050454580655

Epoch: 5| Step: 6
Training loss: 0.700410008430481
Validation loss: 1.815750136170336

Epoch: 5| Step: 7
Training loss: 0.9024959802627563
Validation loss: 1.7951248794473627

Epoch: 5| Step: 8
Training loss: 0.815325140953064
Validation loss: 1.7900384100534583

Epoch: 5| Step: 9
Training loss: 0.7090761661529541
Validation loss: 1.774198479549859

Epoch: 5| Step: 10
Training loss: 0.5373454093933105
Validation loss: 1.7884439447874665

Epoch: 543| Step: 0
Training loss: 0.656581461429596
Validation loss: 1.7890679400454286

Epoch: 5| Step: 1
Training loss: 1.112113118171692
Validation loss: 1.795607683479145

Epoch: 5| Step: 2
Training loss: 0.7658723592758179
Validation loss: 1.8068337760945803

Epoch: 5| Step: 3
Training loss: 0.7608035206794739
Validation loss: 1.8029270415665002

Epoch: 5| Step: 4
Training loss: 0.43168821930885315
Validation loss: 1.7820386617414412

Epoch: 5| Step: 5
Training loss: 0.6302171945571899
Validation loss: 1.789400359635712

Epoch: 5| Step: 6
Training loss: 0.6747628450393677
Validation loss: 1.8129346088696552

Epoch: 5| Step: 7
Training loss: 0.5640424489974976
Validation loss: 1.7820663003511326

Epoch: 5| Step: 8
Training loss: 0.5580938458442688
Validation loss: 1.787599689217024

Epoch: 5| Step: 9
Training loss: 0.5427801012992859
Validation loss: 1.7824022526382117

Epoch: 5| Step: 10
Training loss: 0.7480906248092651
Validation loss: 1.7502979206782516

Epoch: 544| Step: 0
Training loss: 0.5919550657272339
Validation loss: 1.7431386657940444

Epoch: 5| Step: 1
Training loss: 0.9322894215583801
Validation loss: 1.7622645837004467

Epoch: 5| Step: 2
Training loss: 0.6265636086463928
Validation loss: 1.753086402852048

Epoch: 5| Step: 3
Training loss: 0.8777521252632141
Validation loss: 1.7633087801676925

Epoch: 5| Step: 4
Training loss: 0.6090916395187378
Validation loss: 1.7699260275851014

Epoch: 5| Step: 5
Training loss: 0.3654136061668396
Validation loss: 1.7811377356129308

Epoch: 5| Step: 6
Training loss: 0.7064822912216187
Validation loss: 1.8147097646549184

Epoch: 5| Step: 7
Training loss: 0.6021721363067627
Validation loss: 1.8359474699984315

Epoch: 5| Step: 8
Training loss: 1.0764318704605103
Validation loss: 1.8456861998445244

Epoch: 5| Step: 9
Training loss: 0.697854220867157
Validation loss: 1.8336012991525794

Epoch: 5| Step: 10
Training loss: 0.2733772397041321
Validation loss: 1.8414711042117047

Epoch: 545| Step: 0
Training loss: 0.45675259828567505
Validation loss: 1.8033467415840394

Epoch: 5| Step: 1
Training loss: 1.1588809490203857
Validation loss: 1.7898124533314859

Epoch: 5| Step: 2
Training loss: 0.4307215213775635
Validation loss: 1.781473700718213

Epoch: 5| Step: 3
Training loss: 0.6315065622329712
Validation loss: 1.7848545248790453

Epoch: 5| Step: 4
Training loss: 0.7957075238227844
Validation loss: 1.7744340204423474

Epoch: 5| Step: 5
Training loss: 0.5906604528427124
Validation loss: 1.75538222764128

Epoch: 5| Step: 6
Training loss: 0.7637043595314026
Validation loss: 1.751295990841363

Epoch: 5| Step: 7
Training loss: 0.9050416946411133
Validation loss: 1.785231710762106

Epoch: 5| Step: 8
Training loss: 0.5811041593551636
Validation loss: 1.7627312201325611

Epoch: 5| Step: 9
Training loss: 0.34852391481399536
Validation loss: 1.7580744169091667

Epoch: 5| Step: 10
Training loss: 0.5752367973327637
Validation loss: 1.7793607250336678

Epoch: 546| Step: 0
Training loss: 0.7115544676780701
Validation loss: 1.7650260553565076

Epoch: 5| Step: 1
Training loss: 0.5538656711578369
Validation loss: 1.8000631422124884

Epoch: 5| Step: 2
Training loss: 0.882673442363739
Validation loss: 1.8177299525148125

Epoch: 5| Step: 3
Training loss: 0.8274297714233398
Validation loss: 1.8161727369472545

Epoch: 5| Step: 4
Training loss: 0.8446623086929321
Validation loss: 1.808040552241828

Epoch: 5| Step: 5
Training loss: 0.5680555105209351
Validation loss: 1.8598260418061288

Epoch: 5| Step: 6
Training loss: 0.7534282207489014
Validation loss: 1.8621563885801582

Epoch: 5| Step: 7
Training loss: 0.7987266778945923
Validation loss: 1.86062728974127

Epoch: 5| Step: 8
Training loss: 0.40109696984291077
Validation loss: 1.8495555616194201

Epoch: 5| Step: 9
Training loss: 0.5302238464355469
Validation loss: 1.7928307658882552

Epoch: 5| Step: 10
Training loss: 0.3650365173816681
Validation loss: 1.7942025225649598

Epoch: 547| Step: 0
Training loss: 0.8175012469291687
Validation loss: 1.7699384894422305

Epoch: 5| Step: 1
Training loss: 0.475618451833725
Validation loss: 1.7597716393009308

Epoch: 5| Step: 2
Training loss: 0.8890768885612488
Validation loss: 1.7496488549376046

Epoch: 5| Step: 3
Training loss: 0.5633718967437744
Validation loss: 1.760528810562626

Epoch: 5| Step: 4
Training loss: 0.5661159753799438
Validation loss: 1.7655605731471893

Epoch: 5| Step: 5
Training loss: 0.8977344632148743
Validation loss: 1.7850367420463151

Epoch: 5| Step: 6
Training loss: 0.42968329787254333
Validation loss: 1.7860780941542758

Epoch: 5| Step: 7
Training loss: 0.5213955640792847
Validation loss: 1.7868320429196922

Epoch: 5| Step: 8
Training loss: 0.7463789582252502
Validation loss: 1.8154666628888858

Epoch: 5| Step: 9
Training loss: 0.5419788360595703
Validation loss: 1.8163348641446841

Epoch: 5| Step: 10
Training loss: 0.8606323003768921
Validation loss: 1.8070317558062974

Epoch: 548| Step: 0
Training loss: 0.3701215386390686
Validation loss: 1.8121444820075907

Epoch: 5| Step: 1
Training loss: 0.9665144085884094
Validation loss: 1.8018079688472133

Epoch: 5| Step: 2
Training loss: 0.5965273976325989
Validation loss: 1.7985504558009486

Epoch: 5| Step: 3
Training loss: 0.5818713307380676
Validation loss: 1.790037940907222

Epoch: 5| Step: 4
Training loss: 0.6295098066329956
Validation loss: 1.7868129591788016

Epoch: 5| Step: 5
Training loss: 0.799565851688385
Validation loss: 1.7501292651699436

Epoch: 5| Step: 6
Training loss: 0.679338276386261
Validation loss: 1.7642202172228085

Epoch: 5| Step: 7
Training loss: 0.68332439661026
Validation loss: 1.7598742720901326

Epoch: 5| Step: 8
Training loss: 0.49484729766845703
Validation loss: 1.772749541908182

Epoch: 5| Step: 9
Training loss: 0.5089324116706848
Validation loss: 1.7545612076277375

Epoch: 5| Step: 10
Training loss: 0.7876836657524109
Validation loss: 1.7755926129638508

Epoch: 549| Step: 0
Training loss: 0.6486455798149109
Validation loss: 1.7595331515035322

Epoch: 5| Step: 1
Training loss: 0.6655632853507996
Validation loss: 1.7779232353292487

Epoch: 5| Step: 2
Training loss: 0.9977954626083374
Validation loss: 1.7667889043849

Epoch: 5| Step: 3
Training loss: 0.4390939176082611
Validation loss: 1.8104512050587644

Epoch: 5| Step: 4
Training loss: 0.4435727000236511
Validation loss: 1.801270523378926

Epoch: 5| Step: 5
Training loss: 0.6763747930526733
Validation loss: 1.8124009255440003

Epoch: 5| Step: 6
Training loss: 0.4690268039703369
Validation loss: 1.7703400414477113

Epoch: 5| Step: 7
Training loss: 0.6379395723342896
Validation loss: 1.7950492200031076

Epoch: 5| Step: 8
Training loss: 0.5612690448760986
Validation loss: 1.791446534536218

Epoch: 5| Step: 9
Training loss: 0.8965160250663757
Validation loss: 1.774898963589822

Epoch: 5| Step: 10
Training loss: 0.7580081820487976
Validation loss: 1.737832816698218

Epoch: 550| Step: 0
Training loss: 1.0680135488510132
Validation loss: 1.731517779570754

Epoch: 5| Step: 1
Training loss: 0.3709188997745514
Validation loss: 1.7383697725111438

Epoch: 5| Step: 2
Training loss: 0.9133952856063843
Validation loss: 1.7501507997512817

Epoch: 5| Step: 3
Training loss: 0.4354158341884613
Validation loss: 1.7570371307352537

Epoch: 5| Step: 4
Training loss: 0.8284928202629089
Validation loss: 1.7871295790518484

Epoch: 5| Step: 5
Training loss: 0.49558791518211365
Validation loss: 1.7728113461566228

Epoch: 5| Step: 6
Training loss: 0.4305204749107361
Validation loss: 1.7947142636904152

Epoch: 5| Step: 7
Training loss: 0.7388515472412109
Validation loss: 1.825145685544578

Epoch: 5| Step: 8
Training loss: 0.4721953272819519
Validation loss: 1.7889595826466878

Epoch: 5| Step: 9
Training loss: 0.5971832275390625
Validation loss: 1.8241508391595656

Epoch: 5| Step: 10
Training loss: 0.78437739610672
Validation loss: 1.8060971575398599

Testing loss: 2.0892618232303195
