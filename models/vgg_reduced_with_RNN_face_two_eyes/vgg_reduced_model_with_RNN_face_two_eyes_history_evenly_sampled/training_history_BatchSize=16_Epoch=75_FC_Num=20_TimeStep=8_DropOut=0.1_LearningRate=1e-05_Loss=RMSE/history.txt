Epoch: 1| Step: 0
Training loss: 5.049257076495128
Validation loss: 5.72122989461905

Epoch: 6| Step: 1
Training loss: 5.439884759018913
Validation loss: 5.7100595957325115

Epoch: 6| Step: 2
Training loss: 6.362418531334692
Validation loss: 5.69929903567289

Epoch: 6| Step: 3
Training loss: 5.790746528844802
Validation loss: 5.688365842877271

Epoch: 6| Step: 4
Training loss: 5.437840242812182
Validation loss: 5.677718744979198

Epoch: 6| Step: 5
Training loss: 6.751391797157862
Validation loss: 5.666991855452201

Epoch: 6| Step: 6
Training loss: 5.195616106612855
Validation loss: 5.6557900946531285

Epoch: 6| Step: 7
Training loss: 5.78551363050421
Validation loss: 5.6444940288100085

Epoch: 6| Step: 8
Training loss: 5.44134630990407
Validation loss: 5.631823824478344

Epoch: 6| Step: 9
Training loss: 5.38044782058148
Validation loss: 5.618616952121283

Epoch: 6| Step: 10
Training loss: 5.630234042193366
Validation loss: 5.604941426815324

Epoch: 6| Step: 11
Training loss: 6.032629932406528
Validation loss: 5.590414130833427

Epoch: 6| Step: 12
Training loss: 5.234190251520413
Validation loss: 5.574280248866495

Epoch: 6| Step: 13
Training loss: 5.964284774479983
Validation loss: 5.558088868337036

Epoch: 2| Step: 0
Training loss: 5.299273192755773
Validation loss: 5.54020183903524

Epoch: 6| Step: 1
Training loss: 5.283455833836004
Validation loss: 5.522462058128635

Epoch: 6| Step: 2
Training loss: 6.436680713850932
Validation loss: 5.502967287604046

Epoch: 6| Step: 3
Training loss: 4.762255468623822
Validation loss: 5.482504748131425

Epoch: 6| Step: 4
Training loss: 5.425359919690003
Validation loss: 5.46216346231739

Epoch: 6| Step: 5
Training loss: 6.5318124337302885
Validation loss: 5.439889126723914

Epoch: 6| Step: 6
Training loss: 5.349369061780171
Validation loss: 5.416778397965666

Epoch: 6| Step: 7
Training loss: 5.70347681919971
Validation loss: 5.392498473714689

Epoch: 6| Step: 8
Training loss: 5.8827774837105276
Validation loss: 5.368253846602183

Epoch: 6| Step: 9
Training loss: 4.438474091549092
Validation loss: 5.341738579634756

Epoch: 6| Step: 10
Training loss: 5.3956397572950445
Validation loss: 5.313500168213066

Epoch: 6| Step: 11
Training loss: 6.145410279621924
Validation loss: 5.284471750837902

Epoch: 6| Step: 12
Training loss: 4.71680657995896
Validation loss: 5.253941971681487

Epoch: 6| Step: 13
Training loss: 3.2818762771932324
Validation loss: 5.223116020969019

Epoch: 3| Step: 0
Training loss: 4.944658329560673
Validation loss: 5.191644911594635

Epoch: 6| Step: 1
Training loss: 5.071986223412706
Validation loss: 5.1575544062850645

Epoch: 6| Step: 2
Training loss: 4.389972244557293
Validation loss: 5.123208515944225

Epoch: 6| Step: 3
Training loss: 5.236835140737177
Validation loss: 5.091169984150352

Epoch: 6| Step: 4
Training loss: 4.7018619501576016
Validation loss: 5.055285327388493

Epoch: 6| Step: 5
Training loss: 4.821612363672806
Validation loss: 5.019904471684985

Epoch: 6| Step: 6
Training loss: 4.667269576953433
Validation loss: 4.986783341053002

Epoch: 6| Step: 7
Training loss: 6.140166830971142
Validation loss: 4.951866991405435

Epoch: 6| Step: 8
Training loss: 5.395275641922231
Validation loss: 4.917356144841391

Epoch: 6| Step: 9
Training loss: 4.9297103276759495
Validation loss: 4.885726323126924

Epoch: 6| Step: 10
Training loss: 5.7032581052532345
Validation loss: 4.855518467428598

Epoch: 6| Step: 11
Training loss: 4.141854733368159
Validation loss: 4.827307753837335

Epoch: 6| Step: 12
Training loss: 4.886810862940805
Validation loss: 4.800628201760609

Epoch: 6| Step: 13
Training loss: 5.3772514418471875
Validation loss: 4.77877520086321

Epoch: 4| Step: 0
Training loss: 5.5018907244863975
Validation loss: 4.753502060483625

Epoch: 6| Step: 1
Training loss: 3.921512176630954
Validation loss: 4.733534191456437

Epoch: 6| Step: 2
Training loss: 4.505564745731496
Validation loss: 4.71372217396885

Epoch: 6| Step: 3
Training loss: 3.5116475981737927
Validation loss: 4.6930965493224495

Epoch: 6| Step: 4
Training loss: 4.940787464344349
Validation loss: 4.674402791934737

Epoch: 6| Step: 5
Training loss: 3.880015787898712
Validation loss: 4.655356357266666

Epoch: 6| Step: 6
Training loss: 5.465369351287806
Validation loss: 4.640694608415239

Epoch: 6| Step: 7
Training loss: 3.6956868213970924
Validation loss: 4.625893116096525

Epoch: 6| Step: 8
Training loss: 5.364338258743909
Validation loss: 4.613816686516658

Epoch: 6| Step: 9
Training loss: 4.574632373485225
Validation loss: 4.595599168063532

Epoch: 6| Step: 10
Training loss: 4.775627470481382
Validation loss: 4.579356680966288

Epoch: 6| Step: 11
Training loss: 5.956864751771559
Validation loss: 4.5639830755292925

Epoch: 6| Step: 12
Training loss: 5.050526718016105
Validation loss: 4.547816855132343

Epoch: 6| Step: 13
Training loss: 4.065123429905445
Validation loss: 4.534733919715921

Epoch: 5| Step: 0
Training loss: 5.264124806579727
Validation loss: 4.517760446219289

Epoch: 6| Step: 1
Training loss: 4.39264282341748
Validation loss: 4.499601711116407

Epoch: 6| Step: 2
Training loss: 4.7123606289357305
Validation loss: 4.482645229481915

Epoch: 6| Step: 3
Training loss: 4.094261778079937
Validation loss: 4.464023393462582

Epoch: 6| Step: 4
Training loss: 5.363810936095596
Validation loss: 4.448301584483357

Epoch: 6| Step: 5
Training loss: 5.233019844109401
Validation loss: 4.433559072204483

Epoch: 6| Step: 6
Training loss: 3.645770844423553
Validation loss: 4.416587767744711

Epoch: 6| Step: 7
Training loss: 4.416089698004921
Validation loss: 4.403689058352123

Epoch: 6| Step: 8
Training loss: 4.5812346537542465
Validation loss: 4.390081073069273

Epoch: 6| Step: 9
Training loss: 4.086525402479753
Validation loss: 4.372513929901273

Epoch: 6| Step: 10
Training loss: 5.427628951612016
Validation loss: 4.35614881083869

Epoch: 6| Step: 11
Training loss: 4.4136828774118335
Validation loss: 4.342367352779781

Epoch: 6| Step: 12
Training loss: 3.311517821756887
Validation loss: 4.325563485386205

Epoch: 6| Step: 13
Training loss: 3.4008999026294613
Validation loss: 4.312102865605753

Epoch: 6| Step: 0
Training loss: 3.3888685889409094
Validation loss: 4.299598133151081

Epoch: 6| Step: 1
Training loss: 3.328190905854192
Validation loss: 4.284082787964232

Epoch: 6| Step: 2
Training loss: 4.757305550462768
Validation loss: 4.266452213122562

Epoch: 6| Step: 3
Training loss: 4.326240873109481
Validation loss: 4.251774942660543

Epoch: 6| Step: 4
Training loss: 4.636747544929544
Validation loss: 4.235176227670304

Epoch: 6| Step: 5
Training loss: 4.697683031090508
Validation loss: 4.223251822437145

Epoch: 6| Step: 6
Training loss: 5.366776674142235
Validation loss: 4.20879472517936

Epoch: 6| Step: 7
Training loss: 4.473399910883813
Validation loss: 4.195508168225466

Epoch: 6| Step: 8
Training loss: 4.4339787656338405
Validation loss: 4.1820048858346786

Epoch: 6| Step: 9
Training loss: 3.809321344762872
Validation loss: 4.168554204384435

Epoch: 6| Step: 10
Training loss: 3.5644479077444693
Validation loss: 4.156753509540192

Epoch: 6| Step: 11
Training loss: 4.207092454725403
Validation loss: 4.146307504397196

Epoch: 6| Step: 12
Training loss: 4.4299445506601804
Validation loss: 4.1350971988219785

Epoch: 6| Step: 13
Training loss: 5.076805718050291
Validation loss: 4.1254635473020835

Epoch: 7| Step: 0
Training loss: 3.88104465696989
Validation loss: 4.115062209217449

Epoch: 6| Step: 1
Training loss: 4.741377181528026
Validation loss: 4.103969625254313

Epoch: 6| Step: 2
Training loss: 3.5582493637385646
Validation loss: 4.090996650553437

Epoch: 6| Step: 3
Training loss: 4.671669027323585
Validation loss: 4.082299960387242

Epoch: 6| Step: 4
Training loss: 4.654367360723093
Validation loss: 4.073257117761669

Epoch: 6| Step: 5
Training loss: 3.137604128868814
Validation loss: 4.064494478439383

Epoch: 6| Step: 6
Training loss: 4.252667879965474
Validation loss: 4.0561898572179205

Epoch: 6| Step: 7
Training loss: 4.264258085345283
Validation loss: 4.049908914254522

Epoch: 6| Step: 8
Training loss: 4.347037189894086
Validation loss: 4.04301961452959

Epoch: 6| Step: 9
Training loss: 3.625531256321474
Validation loss: 4.035979450993273

Epoch: 6| Step: 10
Training loss: 4.798881781980243
Validation loss: 4.031413904323741

Epoch: 6| Step: 11
Training loss: 3.324356883100589
Validation loss: 4.024959055323471

Epoch: 6| Step: 12
Training loss: 4.810944342910346
Validation loss: 4.019684899754224

Epoch: 6| Step: 13
Training loss: 4.400187332326921
Validation loss: 4.0140322260477665

Epoch: 8| Step: 0
Training loss: 3.029854836842258
Validation loss: 4.007460067212608

Epoch: 6| Step: 1
Training loss: 4.143718211884929
Validation loss: 4.004166227954903

Epoch: 6| Step: 2
Training loss: 4.630104753203189
Validation loss: 3.9982436974810684

Epoch: 6| Step: 3
Training loss: 3.970437119294792
Validation loss: 3.9919031484733427

Epoch: 6| Step: 4
Training loss: 5.244702709343916
Validation loss: 3.9880371237583816

Epoch: 6| Step: 5
Training loss: 3.4866063111176726
Validation loss: 3.9797253973716202

Epoch: 6| Step: 6
Training loss: 4.079686359243186
Validation loss: 3.974545123009847

Epoch: 6| Step: 7
Training loss: 4.21064080659907
Validation loss: 3.9683165445545554

Epoch: 6| Step: 8
Training loss: 4.495336659419243
Validation loss: 3.963130447348218

Epoch: 6| Step: 9
Training loss: 4.071326658460077
Validation loss: 3.9553055552391756

Epoch: 6| Step: 10
Training loss: 4.0853408757165885
Validation loss: 3.947013686561223

Epoch: 6| Step: 11
Training loss: 4.445187638981278
Validation loss: 3.9425293002660684

Epoch: 6| Step: 12
Training loss: 3.3369896544975433
Validation loss: 3.9358693444624357

Epoch: 6| Step: 13
Training loss: 4.000214570966104
Validation loss: 3.9300002517935995

Epoch: 9| Step: 0
Training loss: 4.726861108852556
Validation loss: 3.9326241014576477

Epoch: 6| Step: 1
Training loss: 3.809647540512714
Validation loss: 3.925382185894751

Epoch: 6| Step: 2
Training loss: 3.5214071915938363
Validation loss: 3.918829027541461

Epoch: 6| Step: 3
Training loss: 3.1755965626071556
Validation loss: 3.9110634956517583

Epoch: 6| Step: 4
Training loss: 2.9353486969449216
Validation loss: 3.902231554645188

Epoch: 6| Step: 5
Training loss: 3.3021129201692707
Validation loss: 3.892819002068104

Epoch: 6| Step: 6
Training loss: 4.392696882773801
Validation loss: 3.8890514523407385

Epoch: 6| Step: 7
Training loss: 4.389948565414226
Validation loss: 3.880987863418979

Epoch: 6| Step: 8
Training loss: 4.753325252089156
Validation loss: 3.8752275956473237

Epoch: 6| Step: 9
Training loss: 4.152100980306137
Validation loss: 3.868626529677438

Epoch: 6| Step: 10
Training loss: 4.556377117126246
Validation loss: 3.861748468933122

Epoch: 6| Step: 11
Training loss: 4.021223032881387
Validation loss: 3.855131649859693

Epoch: 6| Step: 12
Training loss: 4.078736708792127
Validation loss: 3.850948819418958

Epoch: 6| Step: 13
Training loss: 4.519545598778
Validation loss: 3.8420588597031227

Epoch: 10| Step: 0
Training loss: 4.52336370905378
Validation loss: 3.836821101428501

Epoch: 6| Step: 1
Training loss: 4.579288478037597
Validation loss: 3.8278257874612454

Epoch: 6| Step: 2
Training loss: 4.009744695208406
Validation loss: 3.8207491883824933

Epoch: 6| Step: 3
Training loss: 3.5370309148013876
Validation loss: 3.8143487566776395

Epoch: 6| Step: 4
Training loss: 4.610574857075342
Validation loss: 3.807095550612068

Epoch: 6| Step: 5
Training loss: 3.5356002613083497
Validation loss: 3.802038524508049

Epoch: 6| Step: 6
Training loss: 2.8638124480613074
Validation loss: 3.7949197078509047

Epoch: 6| Step: 7
Training loss: 4.599884297118244
Validation loss: 3.789361954884248

Epoch: 6| Step: 8
Training loss: 2.9716727876912175
Validation loss: 3.7802063693215864

Epoch: 6| Step: 9
Training loss: 4.4307558631593436
Validation loss: 3.7756879566880373

Epoch: 6| Step: 10
Training loss: 3.4090893311930386
Validation loss: 3.7688636555447417

Epoch: 6| Step: 11
Training loss: 4.354980441376906
Validation loss: 3.7632867852474243

Epoch: 6| Step: 12
Training loss: 3.5428652511670897
Validation loss: 3.757032622740443

Epoch: 6| Step: 13
Training loss: 4.011785549361703
Validation loss: 3.7524801645973964

Epoch: 11| Step: 0
Training loss: 3.7444986043900204
Validation loss: 3.7468914588258087

Epoch: 6| Step: 1
Training loss: 3.594226042689478
Validation loss: 3.7415164216745636

Epoch: 6| Step: 2
Training loss: 4.530972386767913
Validation loss: 3.7349201878282394

Epoch: 6| Step: 3
Training loss: 3.8828122543856813
Validation loss: 3.7226581630941395

Epoch: 6| Step: 4
Training loss: 3.852465912447167
Validation loss: 3.713076921636673

Epoch: 6| Step: 5
Training loss: 4.668460682760901
Validation loss: 3.7057082100000236

Epoch: 6| Step: 6
Training loss: 3.6048459127777717
Validation loss: 3.6996951000032587

Epoch: 6| Step: 7
Training loss: 4.369044582929654
Validation loss: 3.69374868452852

Epoch: 6| Step: 8
Training loss: 3.0973409754439474
Validation loss: 3.688304622150958

Epoch: 6| Step: 9
Training loss: 4.080501638503062
Validation loss: 3.687381359407468

Epoch: 6| Step: 10
Training loss: 3.8617143838168215
Validation loss: 3.682374921982098

Epoch: 6| Step: 11
Training loss: 3.137687713965278
Validation loss: 3.676268890735449

Epoch: 6| Step: 12
Training loss: 3.84636456645919
Validation loss: 3.670211847510268

Epoch: 6| Step: 13
Training loss: 3.845173517883087
Validation loss: 3.663576004199699

Epoch: 12| Step: 0
Training loss: 2.9604238905114975
Validation loss: 3.6604962256872198

Epoch: 6| Step: 1
Training loss: 4.191589180828656
Validation loss: 3.6542219145299533

Epoch: 6| Step: 2
Training loss: 3.536492026856284
Validation loss: 3.6513944753841017

Epoch: 6| Step: 3
Training loss: 3.9514822581068
Validation loss: 3.6493852564886806

Epoch: 6| Step: 4
Training loss: 3.8007930430026446
Validation loss: 3.6449359648467623

Epoch: 6| Step: 5
Training loss: 4.26203247370134
Validation loss: 3.6396981441921095

Epoch: 6| Step: 6
Training loss: 3.1571720400585304
Validation loss: 3.6361388066827374

Epoch: 6| Step: 7
Training loss: 4.8302100163957915
Validation loss: 3.63281961758565

Epoch: 6| Step: 8
Training loss: 3.8952437718001742
Validation loss: 3.6309464267306195

Epoch: 6| Step: 9
Training loss: 4.084742763455677
Validation loss: 3.632936841918775

Epoch: 6| Step: 10
Training loss: 3.231169950869779
Validation loss: 3.6289099277765713

Epoch: 6| Step: 11
Training loss: 4.457399906354701
Validation loss: 3.6211198571592753

Epoch: 6| Step: 12
Training loss: 3.0815509765211475
Validation loss: 3.618303130671234

Epoch: 6| Step: 13
Training loss: 3.540272621605648
Validation loss: 3.615824964034376

Epoch: 13| Step: 0
Training loss: 3.208372702088679
Validation loss: 3.6146636140230024

Epoch: 6| Step: 1
Training loss: 3.8883398001418534
Validation loss: 3.6102760900835578

Epoch: 6| Step: 2
Training loss: 3.9129300792129635
Validation loss: 3.6024253337868553

Epoch: 6| Step: 3
Training loss: 4.000713999919923
Validation loss: 3.6038905620119017

Epoch: 6| Step: 4
Training loss: 3.4553419910547905
Validation loss: 3.602704921763988

Epoch: 6| Step: 5
Training loss: 2.6279447477852553
Validation loss: 3.5992966060454847

Epoch: 6| Step: 6
Training loss: 4.899711382404006
Validation loss: 3.5961490222795307

Epoch: 6| Step: 7
Training loss: 4.041141410333896
Validation loss: 3.593972177936166

Epoch: 6| Step: 8
Training loss: 3.787142615248655
Validation loss: 3.5927712868452697

Epoch: 6| Step: 9
Training loss: 4.14276505353832
Validation loss: 3.586546237089618

Epoch: 6| Step: 10
Training loss: 3.1429295221887035
Validation loss: 3.584233855989881

Epoch: 6| Step: 11
Training loss: 3.228730071711874
Validation loss: 3.583612590438476

Epoch: 6| Step: 12
Training loss: 4.7793952485916815
Validation loss: 3.581221315572234

Epoch: 6| Step: 13
Training loss: 2.9593611172085605
Validation loss: 3.580525767645308

Epoch: 14| Step: 0
Training loss: 3.7199028215738545
Validation loss: 3.5799201330883426

Epoch: 6| Step: 1
Training loss: 3.810515966246056
Validation loss: 3.5781915313414716

Epoch: 6| Step: 2
Training loss: 3.463603144891212
Validation loss: 3.57573387093834

Epoch: 6| Step: 3
Training loss: 3.779826124723476
Validation loss: 3.5738420328829372

Epoch: 6| Step: 4
Training loss: 2.996933959762825
Validation loss: 3.5718433010704493

Epoch: 6| Step: 5
Training loss: 4.125735130695176
Validation loss: 3.570030961171715

Epoch: 6| Step: 6
Training loss: 2.894378534527793
Validation loss: 3.569315175987767

Epoch: 6| Step: 7
Training loss: 2.8633278794804755
Validation loss: 3.5694260079968148

Epoch: 6| Step: 8
Training loss: 4.409338768067388
Validation loss: 3.5686437525589225

Epoch: 6| Step: 9
Training loss: 3.9995733271964875
Validation loss: 3.5653352118371124

Epoch: 6| Step: 10
Training loss: 4.812196399971071
Validation loss: 3.563178053502253

Epoch: 6| Step: 11
Training loss: 3.952600376463949
Validation loss: 3.5631929251535026

Epoch: 6| Step: 12
Training loss: 3.7136482697853452
Validation loss: 3.5633407950586258

Epoch: 6| Step: 13
Training loss: 3.7443592881261623
Validation loss: 3.5630407191077986

Epoch: 15| Step: 0
Training loss: 4.395538079107359
Validation loss: 3.5622269375201983

Epoch: 6| Step: 1
Training loss: 3.3135339814598344
Validation loss: 3.560259765373626

Epoch: 6| Step: 2
Training loss: 3.693660826663596
Validation loss: 3.5575010541671435

Epoch: 6| Step: 3
Training loss: 3.4510654849723417
Validation loss: 3.556028877969067

Epoch: 6| Step: 4
Training loss: 4.104167234675696
Validation loss: 3.553992189424838

Epoch: 6| Step: 5
Training loss: 2.8988823150928034
Validation loss: 3.55369816872911

Epoch: 6| Step: 6
Training loss: 3.6472162003736583
Validation loss: 3.5543162558941015

Epoch: 6| Step: 7
Training loss: 4.5229293722322454
Validation loss: 3.553659143618166

Epoch: 6| Step: 8
Training loss: 3.786664380847438
Validation loss: 3.555261073128977

Epoch: 6| Step: 9
Training loss: 4.076250485885484
Validation loss: 3.5505664100317413

Epoch: 6| Step: 10
Training loss: 2.8364850821315426
Validation loss: 3.551344760123518

Epoch: 6| Step: 11
Training loss: 3.800553286577976
Validation loss: 3.551567633221869

Epoch: 6| Step: 12
Training loss: 4.090811803412313
Validation loss: 3.553592080832301

Epoch: 6| Step: 13
Training loss: 3.4932492410812803
Validation loss: 3.5522232978364783

Epoch: 16| Step: 0
Training loss: 4.440378679159139
Validation loss: 3.5500414935882856

Epoch: 6| Step: 1
Training loss: 3.5267705272050947
Validation loss: 3.5470274559577426

Epoch: 6| Step: 2
Training loss: 3.306852312516674
Validation loss: 3.544734048292692

Epoch: 6| Step: 3
Training loss: 4.33172699915011
Validation loss: 3.543709951030022

Epoch: 6| Step: 4
Training loss: 3.5413528004115067
Validation loss: 3.5417933741179874

Epoch: 6| Step: 5
Training loss: 3.2350287767218178
Validation loss: 3.5415223200202113

Epoch: 6| Step: 6
Training loss: 3.78573292216112
Validation loss: 3.5412556524974272

Epoch: 6| Step: 7
Training loss: 4.209088147647655
Validation loss: 3.539585449304645

Epoch: 6| Step: 8
Training loss: 3.5559785280040677
Validation loss: 3.540184619099234

Epoch: 6| Step: 9
Training loss: 3.3686126737612914
Validation loss: 3.5391591851238644

Epoch: 6| Step: 10
Training loss: 3.247184120420963
Validation loss: 3.5384599262827474

Epoch: 6| Step: 11
Training loss: 4.515430697052365
Validation loss: 3.5374093591155567

Epoch: 6| Step: 12
Training loss: 3.5642735935095735
Validation loss: 3.536493337494446

Epoch: 6| Step: 13
Training loss: 3.3277243789467192
Validation loss: 3.535842222518145

Epoch: 17| Step: 0
Training loss: 3.4357965583569525
Validation loss: 3.5353229891979128

Epoch: 6| Step: 1
Training loss: 3.2553936145187143
Validation loss: 3.5340840456554763

Epoch: 6| Step: 2
Training loss: 3.7571774776921245
Validation loss: 3.533401558330161

Epoch: 6| Step: 3
Training loss: 4.400399293988354
Validation loss: 3.5326549839695676

Epoch: 6| Step: 4
Training loss: 3.6032358779455804
Validation loss: 3.531668046328308

Epoch: 6| Step: 5
Training loss: 4.090642084212797
Validation loss: 3.53115616787262

Epoch: 6| Step: 6
Training loss: 3.5804975215081325
Validation loss: 3.530438449598713

Epoch: 6| Step: 7
Training loss: 4.447926481833189
Validation loss: 3.5301145331938955

Epoch: 6| Step: 8
Training loss: 3.7331145006712654
Validation loss: 3.529256725826892

Epoch: 6| Step: 9
Training loss: 3.1709859569843712
Validation loss: 3.5281355112361146

Epoch: 6| Step: 10
Training loss: 3.831291539525522
Validation loss: 3.528293354471873

Epoch: 6| Step: 11
Training loss: 3.378212424248897
Validation loss: 3.527039231901935

Epoch: 6| Step: 12
Training loss: 3.6550512712590266
Validation loss: 3.5261900027461843

Epoch: 6| Step: 13
Training loss: 3.799457566546545
Validation loss: 3.5258723969470473

Epoch: 18| Step: 0
Training loss: 3.404914944296416
Validation loss: 3.525169821821374

Epoch: 6| Step: 1
Training loss: 3.737541101542266
Validation loss: 3.5235732814342096

Epoch: 6| Step: 2
Training loss: 3.626367376848032
Validation loss: 3.5236065122374

Epoch: 6| Step: 3
Training loss: 4.53337731246559
Validation loss: 3.5227278910322317

Epoch: 6| Step: 4
Training loss: 3.1624454840382876
Validation loss: 3.5231838711198504

Epoch: 6| Step: 5
Training loss: 4.496448386860804
Validation loss: 3.521572799682188

Epoch: 6| Step: 6
Training loss: 3.552598007965603
Validation loss: 3.5207565982730844

Epoch: 6| Step: 7
Training loss: 2.8827324419354476
Validation loss: 3.520136795905011

Epoch: 6| Step: 8
Training loss: 4.000854877672679
Validation loss: 3.519164320667521

Epoch: 6| Step: 9
Training loss: 3.348760255895433
Validation loss: 3.519320716008976

Epoch: 6| Step: 10
Training loss: 3.6836725835364024
Validation loss: 3.5183851906798487

Epoch: 6| Step: 11
Training loss: 4.187419150411785
Validation loss: 3.5171687076070373

Epoch: 6| Step: 12
Training loss: 3.731622423662496
Validation loss: 3.51672785552698

Epoch: 6| Step: 13
Training loss: 3.349297173633897
Validation loss: 3.516446131039311

Epoch: 19| Step: 0
Training loss: 3.862792937889094
Validation loss: 3.5157706500547032

Epoch: 6| Step: 1
Training loss: 3.675920570968228
Validation loss: 3.515216717455419

Epoch: 6| Step: 2
Training loss: 3.7864880812087263
Validation loss: 3.5150617367485033

Epoch: 6| Step: 3
Training loss: 4.180990597100988
Validation loss: 3.513570255159233

Epoch: 6| Step: 4
Training loss: 3.4087765623875548
Validation loss: 3.513032189258587

Epoch: 6| Step: 5
Training loss: 3.205831138214108
Validation loss: 3.512379816923263

Epoch: 6| Step: 6
Training loss: 3.015492016325844
Validation loss: 3.511845755901379

Epoch: 6| Step: 7
Training loss: 3.6453274330457903
Validation loss: 3.5118350614133216

Epoch: 6| Step: 8
Training loss: 4.267238437567866
Validation loss: 3.5111546556640327

Epoch: 6| Step: 9
Training loss: 3.911608141567075
Validation loss: 3.5099289732643486

Epoch: 6| Step: 10
Training loss: 4.056963155209154
Validation loss: 3.509106494007592

Epoch: 6| Step: 11
Training loss: 3.511478538911471
Validation loss: 3.5090950737512694

Epoch: 6| Step: 12
Training loss: 3.801981690324083
Validation loss: 3.5086667376211778

Epoch: 6| Step: 13
Training loss: 3.516015874538237
Validation loss: 3.5083822891209864

Epoch: 20| Step: 0
Training loss: 4.061056262015688
Validation loss: 3.50747134750496

Epoch: 6| Step: 1
Training loss: 4.168488574659922
Validation loss: 3.506288659480344

Epoch: 6| Step: 2
Training loss: 3.8544775897557373
Validation loss: 3.505873795113289

Epoch: 6| Step: 3
Training loss: 4.24663140929561
Validation loss: 3.5052745089814605

Epoch: 6| Step: 4
Training loss: 3.276918440492105
Validation loss: 3.50538317666922

Epoch: 6| Step: 5
Training loss: 3.1821924039069978
Validation loss: 3.5045273120514793

Epoch: 6| Step: 6
Training loss: 4.199711090323655
Validation loss: 3.504322017411802

Epoch: 6| Step: 7
Training loss: 4.0121287997138335
Validation loss: 3.504102839425033

Epoch: 6| Step: 8
Training loss: 3.173609066959523
Validation loss: 3.503434267438133

Epoch: 6| Step: 9
Training loss: 2.976771229711905
Validation loss: 3.502666521171136

Epoch: 6| Step: 10
Training loss: 3.8406221642728164
Validation loss: 3.501561386441273

Epoch: 6| Step: 11
Training loss: 3.9955954143085797
Validation loss: 3.5013567408767465

Epoch: 6| Step: 12
Training loss: 3.465450332684164
Validation loss: 3.5007784310335817

Epoch: 6| Step: 13
Training loss: 2.8402042291306073
Validation loss: 3.5003451603454083

Epoch: 21| Step: 0
Training loss: 4.411590586199511
Validation loss: 3.500284562797105

Epoch: 6| Step: 1
Training loss: 2.8958549407226046
Validation loss: 3.498534301467346

Epoch: 6| Step: 2
Training loss: 3.6853252398829417
Validation loss: 3.498313954762161

Epoch: 6| Step: 3
Training loss: 4.1585682305071305
Validation loss: 3.4982401163266887

Epoch: 6| Step: 4
Training loss: 3.8573344778469516
Validation loss: 3.4969492183893576

Epoch: 6| Step: 5
Training loss: 3.6844583671786353
Validation loss: 3.496641050291621

Epoch: 6| Step: 6
Training loss: 3.218955616725893
Validation loss: 3.4955779353631624

Epoch: 6| Step: 7
Training loss: 3.314707758062889
Validation loss: 3.495101823741965

Epoch: 6| Step: 8
Training loss: 4.462401248469679
Validation loss: 3.4946394358831636

Epoch: 6| Step: 9
Training loss: 2.7896660330728342
Validation loss: 3.494109005449277

Epoch: 6| Step: 10
Training loss: 3.7879406713574753
Validation loss: 3.493273064350905

Epoch: 6| Step: 11
Training loss: 3.9391811354497652
Validation loss: 3.4929858562363187

Epoch: 6| Step: 12
Training loss: 3.90727940537717
Validation loss: 3.4925831394460576

Epoch: 6| Step: 13
Training loss: 3.1241156280356246
Validation loss: 3.4916690480934376

Epoch: 22| Step: 0
Training loss: 3.652624435655045
Validation loss: 3.491653487076642

Epoch: 6| Step: 1
Training loss: 4.235147666113211
Validation loss: 3.4907611052572873

Epoch: 6| Step: 2
Training loss: 4.024776969085232
Validation loss: 3.490242181450592

Epoch: 6| Step: 3
Training loss: 3.7380234520810736
Validation loss: 3.4893619742028252

Epoch: 6| Step: 4
Training loss: 3.075497197839077
Validation loss: 3.488624196790771

Epoch: 6| Step: 5
Training loss: 3.8281770663710497
Validation loss: 3.488098785762091

Epoch: 6| Step: 6
Training loss: 3.656712168639657
Validation loss: 3.487819656569698

Epoch: 6| Step: 7
Training loss: 3.895814185001962
Validation loss: 3.48730898215754

Epoch: 6| Step: 8
Training loss: 3.5896584480619707
Validation loss: 3.4870773645065545

Epoch: 6| Step: 9
Training loss: 2.789806192017606
Validation loss: 3.4860228979874113

Epoch: 6| Step: 10
Training loss: 3.011225361863778
Validation loss: 3.485552968632453

Epoch: 6| Step: 11
Training loss: 4.362132960402904
Validation loss: 3.48497132489902

Epoch: 6| Step: 12
Training loss: 4.468247392039716
Validation loss: 3.4849272568568614

Epoch: 6| Step: 13
Training loss: 2.4450231021343547
Validation loss: 3.4840376745978485

Epoch: 23| Step: 0
Training loss: 3.1563058980392045
Validation loss: 3.483880796204045

Epoch: 6| Step: 1
Training loss: 4.216333445976626
Validation loss: 3.4831272390655124

Epoch: 6| Step: 2
Training loss: 3.67785287788702
Validation loss: 3.482724679308667

Epoch: 6| Step: 3
Training loss: 3.3176043068443217
Validation loss: 3.48209686904019

Epoch: 6| Step: 4
Training loss: 3.234817548320593
Validation loss: 3.4816349836380853

Epoch: 6| Step: 5
Training loss: 3.887468030006957
Validation loss: 3.4806190766608927

Epoch: 6| Step: 6
Training loss: 3.3592678319116076
Validation loss: 3.4805249962008573

Epoch: 6| Step: 7
Training loss: 4.059809806390257
Validation loss: 3.4797711322858738

Epoch: 6| Step: 8
Training loss: 4.0440586261216325
Validation loss: 3.479841528766027

Epoch: 6| Step: 9
Training loss: 3.9379692403542306
Validation loss: 3.479175649897474

Epoch: 6| Step: 10
Training loss: 3.1163365629547135
Validation loss: 3.478359218366092

Epoch: 6| Step: 11
Training loss: 3.964921681807989
Validation loss: 3.478159667317177

Epoch: 6| Step: 12
Training loss: 3.3791413506540673
Validation loss: 3.477362116808843

Epoch: 6| Step: 13
Training loss: 4.454485983088863
Validation loss: 3.477130818645345

Epoch: 24| Step: 0
Training loss: 3.3783384695015624
Validation loss: 3.477273175378193

Epoch: 6| Step: 1
Training loss: 3.178273329372597
Validation loss: 3.47671901916967

Epoch: 6| Step: 2
Training loss: 2.8632189651521984
Validation loss: 3.475194813403783

Epoch: 6| Step: 3
Training loss: 4.069487211648599
Validation loss: 3.475010800354071

Epoch: 6| Step: 4
Training loss: 4.005364635313046
Validation loss: 3.474650213166246

Epoch: 6| Step: 5
Training loss: 3.2447527561130483
Validation loss: 3.474191176358389

Epoch: 6| Step: 6
Training loss: 4.00870567913433
Validation loss: 3.47384693606527

Epoch: 6| Step: 7
Training loss: 3.480140062560917
Validation loss: 3.472863239362328

Epoch: 6| Step: 8
Training loss: 4.471405307460283
Validation loss: 3.4721637546716666

Epoch: 6| Step: 9
Training loss: 4.152535291472407
Validation loss: 3.4714129276898205

Epoch: 6| Step: 10
Training loss: 3.766266447652358
Validation loss: 3.4717555987014346

Epoch: 6| Step: 11
Training loss: 3.5109319261575416
Validation loss: 3.47095626351195

Epoch: 6| Step: 12
Training loss: 3.8431881129501058
Validation loss: 3.470469747547154

Epoch: 6| Step: 13
Training loss: 3.086837135232548
Validation loss: 3.4702564675762986

Epoch: 25| Step: 0
Training loss: 4.2236155391626555
Validation loss: 3.4699331340947515

Epoch: 6| Step: 1
Training loss: 4.194001573728777
Validation loss: 3.4692433398212925

Epoch: 6| Step: 2
Training loss: 3.3482128557474624
Validation loss: 3.4685528451663865

Epoch: 6| Step: 3
Training loss: 3.735986338016599
Validation loss: 3.4674239879263054

Epoch: 6| Step: 4
Training loss: 4.485563858293744
Validation loss: 3.466617938930563

Epoch: 6| Step: 5
Training loss: 3.719231325944084
Validation loss: 3.4664060253490363

Epoch: 6| Step: 6
Training loss: 2.67068535270318
Validation loss: 3.4655095168404295

Epoch: 6| Step: 7
Training loss: 3.4123086505382374
Validation loss: 3.465141573905425

Epoch: 6| Step: 8
Training loss: 4.113346631869969
Validation loss: 3.4641389464882084

Epoch: 6| Step: 9
Training loss: 3.619989022928529
Validation loss: 3.4637008231961413

Epoch: 6| Step: 10
Training loss: 3.9783363208245475
Validation loss: 3.4633587498012384

Epoch: 6| Step: 11
Training loss: 3.5571702942963683
Validation loss: 3.4629646234461617

Epoch: 6| Step: 12
Training loss: 2.936078316000026
Validation loss: 3.4624203444850705

Epoch: 6| Step: 13
Training loss: 2.6054310488511074
Validation loss: 3.4615839302155567

Epoch: 26| Step: 0
Training loss: 3.379679226523478
Validation loss: 3.4610750252567697

Epoch: 6| Step: 1
Training loss: 3.8006732294114864
Validation loss: 3.460896000763433

Epoch: 6| Step: 2
Training loss: 4.284304232468518
Validation loss: 3.4602725219476786

Epoch: 6| Step: 3
Training loss: 3.9495743196214677
Validation loss: 3.460314036070265

Epoch: 6| Step: 4
Training loss: 3.3443989346837744
Validation loss: 3.4589447763892376

Epoch: 6| Step: 5
Training loss: 3.8102058637375564
Validation loss: 3.4585055043881865

Epoch: 6| Step: 6
Training loss: 2.4323649970578742
Validation loss: 3.4578950003476323

Epoch: 6| Step: 7
Training loss: 3.4671894033941655
Validation loss: 3.4574026839038012

Epoch: 6| Step: 8
Training loss: 3.733957434895362
Validation loss: 3.456712063778539

Epoch: 6| Step: 9
Training loss: 4.1080264355367
Validation loss: 3.457327902021222

Epoch: 6| Step: 10
Training loss: 3.304864973348447
Validation loss: 3.455947079898711

Epoch: 6| Step: 11
Training loss: 4.407471832341173
Validation loss: 3.4554965490701077

Epoch: 6| Step: 12
Training loss: 3.2050797615302797
Validation loss: 3.4550650748184935

Epoch: 6| Step: 13
Training loss: 3.9314281332294563
Validation loss: 3.454471522896914

Epoch: 27| Step: 0
Training loss: 4.079853962921302
Validation loss: 3.4538990794420332

Epoch: 6| Step: 1
Training loss: 3.661377010102541
Validation loss: 3.453453011636582

Epoch: 6| Step: 2
Training loss: 3.5903600211513518
Validation loss: 3.4532930096351335

Epoch: 6| Step: 3
Training loss: 3.4129126945481496
Validation loss: 3.4522726149962817

Epoch: 6| Step: 4
Training loss: 3.8532672691841805
Validation loss: 3.452149694015832

Epoch: 6| Step: 5
Training loss: 4.047490017968746
Validation loss: 3.4510516782450074

Epoch: 6| Step: 6
Training loss: 4.1661772376939155
Validation loss: 3.4511677255383915

Epoch: 6| Step: 7
Training loss: 3.0700186474758766
Validation loss: 3.4504267920945866

Epoch: 6| Step: 8
Training loss: 3.3635973986681504
Validation loss: 3.449394706093923

Epoch: 6| Step: 9
Training loss: 2.687616035263023
Validation loss: 3.449247843755162

Epoch: 6| Step: 10
Training loss: 4.363795510554381
Validation loss: 3.4485768798067347

Epoch: 6| Step: 11
Training loss: 3.7686195970942116
Validation loss: 3.4481374706270524

Epoch: 6| Step: 12
Training loss: 3.6176728485297365
Validation loss: 3.4478675881669263

Epoch: 6| Step: 13
Training loss: 3.12957352703537
Validation loss: 3.4472235528934436

Epoch: 28| Step: 0
Training loss: 4.03298794447168
Validation loss: 3.4468081074281747

Epoch: 6| Step: 1
Training loss: 3.610406901498052
Validation loss: 3.446089518662212

Epoch: 6| Step: 2
Training loss: 4.049506668373587
Validation loss: 3.4461151959668888

Epoch: 6| Step: 3
Training loss: 3.7056130851030327
Validation loss: 3.4450915918754275

Epoch: 6| Step: 4
Training loss: 3.3093319984646468
Validation loss: 3.4448538567879488

Epoch: 6| Step: 5
Training loss: 3.637739093696269
Validation loss: 3.443770353806019

Epoch: 6| Step: 6
Training loss: 3.2189372480425797
Validation loss: 3.443539495827218

Epoch: 6| Step: 7
Training loss: 3.247114514501773
Validation loss: 3.4429491662028564

Epoch: 6| Step: 8
Training loss: 4.293895451332351
Validation loss: 3.4429660151063857

Epoch: 6| Step: 9
Training loss: 4.071171119026503
Validation loss: 3.4420675306507853

Epoch: 6| Step: 10
Training loss: 3.9158669460164
Validation loss: 3.441959892434203

Epoch: 6| Step: 11
Training loss: 2.6755064440317957
Validation loss: 3.4415256453972

Epoch: 6| Step: 12
Training loss: 2.789414925841891
Validation loss: 3.4405236259509424

Epoch: 6| Step: 13
Training loss: 4.7236312982928625
Validation loss: 3.439896630541509

Epoch: 29| Step: 0
Training loss: 3.86436652357667
Validation loss: 3.4395119604598956

Epoch: 6| Step: 1
Training loss: 3.8297198029256525
Validation loss: 3.4388151097481843

Epoch: 6| Step: 2
Training loss: 3.228949968183727
Validation loss: 3.4386305872977387

Epoch: 6| Step: 3
Training loss: 3.3484982440972932
Validation loss: 3.4375428362104294

Epoch: 6| Step: 4
Training loss: 4.034314787021614
Validation loss: 3.4374943350020906

Epoch: 6| Step: 5
Training loss: 3.897805080451103
Validation loss: 3.436596945894106

Epoch: 6| Step: 6
Training loss: 3.939040715158485
Validation loss: 3.436364054251585

Epoch: 6| Step: 7
Training loss: 3.4003426659634877
Validation loss: 3.435536335508852

Epoch: 6| Step: 8
Training loss: 4.264789205979065
Validation loss: 3.4353491713261772

Epoch: 6| Step: 9
Training loss: 3.532785267579417
Validation loss: 3.434742807906094

Epoch: 6| Step: 10
Training loss: 3.507672619313933
Validation loss: 3.4347051660096795

Epoch: 6| Step: 11
Training loss: 3.435179048227878
Validation loss: 3.433599752938668

Epoch: 6| Step: 12
Training loss: 3.5899404485752138
Validation loss: 3.432610494248606

Epoch: 6| Step: 13
Training loss: 2.7666231067705973
Validation loss: 3.432583044462264

Epoch: 30| Step: 0
Training loss: 3.059064690007213
Validation loss: 3.432093840713158

Epoch: 6| Step: 1
Training loss: 3.3777666408232525
Validation loss: 3.4317414930210233

Epoch: 6| Step: 2
Training loss: 3.1455561703147934
Validation loss: 3.4321140668665793

Epoch: 6| Step: 3
Training loss: 4.19619326873875
Validation loss: 3.4340436157904057

Epoch: 6| Step: 4
Training loss: 4.36084397153154
Validation loss: 3.4356055400644046

Epoch: 6| Step: 5
Training loss: 2.6969854940010882
Validation loss: 3.4298745426053676

Epoch: 6| Step: 6
Training loss: 4.337403855371303
Validation loss: 3.4300200071564224

Epoch: 6| Step: 7
Training loss: 3.532030137569638
Validation loss: 3.432037455143398

Epoch: 6| Step: 8
Training loss: 4.147942752395268
Validation loss: 3.431844904653442

Epoch: 6| Step: 9
Training loss: 4.108247899733421
Validation loss: 3.4301402667469696

Epoch: 6| Step: 10
Training loss: 3.525169606558652
Validation loss: 3.4298886565695716

Epoch: 6| Step: 11
Training loss: 3.231744848613598
Validation loss: 3.430988118319905

Epoch: 6| Step: 12
Training loss: 3.089525671789757
Validation loss: 3.4309140638407363

Epoch: 6| Step: 13
Training loss: 3.9903554277174558
Validation loss: 3.4291974106991647

Epoch: 31| Step: 0
Training loss: 4.29320999592284
Validation loss: 3.4282158029879914

Epoch: 6| Step: 1
Training loss: 3.080091748543111
Validation loss: 3.427823883833467

Epoch: 6| Step: 2
Training loss: 3.470277192315321
Validation loss: 3.426019542311383

Epoch: 6| Step: 3
Training loss: 3.1695493995197634
Validation loss: 3.4251783242662186

Epoch: 6| Step: 4
Training loss: 3.521000664400809
Validation loss: 3.4243586673386046

Epoch: 6| Step: 5
Training loss: 4.309665356453926
Validation loss: 3.4237067511333548

Epoch: 6| Step: 6
Training loss: 3.776475145736721
Validation loss: 3.423758585045799

Epoch: 6| Step: 7
Training loss: 3.2712483881770393
Validation loss: 3.4222965682227473

Epoch: 6| Step: 8
Training loss: 3.9016262918496487
Validation loss: 3.4217718392314924

Epoch: 6| Step: 9
Training loss: 3.3121317532819603
Validation loss: 3.4213159253999517

Epoch: 6| Step: 10
Training loss: 3.9924343801706073
Validation loss: 3.420827716856106

Epoch: 6| Step: 11
Training loss: 2.95073639681831
Validation loss: 3.4203070243796456

Epoch: 6| Step: 12
Training loss: 3.992219032715487
Validation loss: 3.4198700339106365

Epoch: 6| Step: 13
Training loss: 3.7570029673520215
Validation loss: 3.4187758038764

Epoch: 32| Step: 0
Training loss: 3.7523383161770334
Validation loss: 3.4202862966693997

Epoch: 6| Step: 1
Training loss: 3.762931018360287
Validation loss: 3.418000433380899

Epoch: 6| Step: 2
Training loss: 4.45076949078006
Validation loss: 3.41802955435067

Epoch: 6| Step: 3
Training loss: 3.632062149490792
Validation loss: 3.4174141566402523

Epoch: 6| Step: 4
Training loss: 2.9266144364489404
Validation loss: 3.4163309998378146

Epoch: 6| Step: 5
Training loss: 2.860163845624218
Validation loss: 3.416129574002978

Epoch: 6| Step: 6
Training loss: 3.4663440505322254
Validation loss: 3.4156830364955497

Epoch: 6| Step: 7
Training loss: 3.628854740955751
Validation loss: 3.414823848994362

Epoch: 6| Step: 8
Training loss: 3.8031674585660187
Validation loss: 3.415023045709601

Epoch: 6| Step: 9
Training loss: 3.7796983293722755
Validation loss: 3.4139199239680313

Epoch: 6| Step: 10
Training loss: 4.1325549674604485
Validation loss: 3.4134067382349262

Epoch: 6| Step: 11
Training loss: 3.2417553717106182
Validation loss: 3.4134517964576814

Epoch: 6| Step: 12
Training loss: 3.6327828354803624
Validation loss: 3.412433830039496

Epoch: 6| Step: 13
Training loss: 3.607177858304249
Validation loss: 3.411909970607639

Epoch: 33| Step: 0
Training loss: 3.9057196905653035
Validation loss: 3.41177727583644

Epoch: 6| Step: 1
Training loss: 3.7370184955011627
Validation loss: 3.4114296682819734

Epoch: 6| Step: 2
Training loss: 3.6186689140445907
Validation loss: 3.410795302760346

Epoch: 6| Step: 3
Training loss: 3.6926758212804622
Validation loss: 3.4100505003983144

Epoch: 6| Step: 4
Training loss: 3.7968145922969176
Validation loss: 3.4096697503149365

Epoch: 6| Step: 5
Training loss: 3.243643339604863
Validation loss: 3.409025159284428

Epoch: 6| Step: 6
Training loss: 3.879260028790501
Validation loss: 3.40846264419344

Epoch: 6| Step: 7
Training loss: 3.9773416111913567
Validation loss: 3.4079658677470115

Epoch: 6| Step: 8
Training loss: 2.972656410407765
Validation loss: 3.4076694392126563

Epoch: 6| Step: 9
Training loss: 2.291203665923004
Validation loss: 3.4072121176498134

Epoch: 6| Step: 10
Training loss: 3.9080730609135848
Validation loss: 3.4067778436605027

Epoch: 6| Step: 11
Training loss: 4.0412046555141234
Validation loss: 3.405898058026495

Epoch: 6| Step: 12
Training loss: 3.6204990198971427
Validation loss: 3.4057267611182622

Epoch: 6| Step: 13
Training loss: 3.965181323183117
Validation loss: 3.4053573048259147

Epoch: 34| Step: 0
Training loss: 2.5590396871049546
Validation loss: 3.4049531323645454

Epoch: 6| Step: 1
Training loss: 4.203153815755661
Validation loss: 3.404090296023599

Epoch: 6| Step: 2
Training loss: 3.4099073461211318
Validation loss: 3.40374903833083

Epoch: 6| Step: 3
Training loss: 3.841619630030534
Validation loss: 3.4031886960080344

Epoch: 6| Step: 4
Training loss: 4.392657152468294
Validation loss: 3.4023838506366832

Epoch: 6| Step: 5
Training loss: 2.9114310730196475
Validation loss: 3.4021464075945222

Epoch: 6| Step: 6
Training loss: 3.2428027936487434
Validation loss: 3.4014776085800635

Epoch: 6| Step: 7
Training loss: 4.365036654848266
Validation loss: 3.400971226106504

Epoch: 6| Step: 8
Training loss: 3.088157454078668
Validation loss: 3.400192008125274

Epoch: 6| Step: 9
Training loss: 3.4479267469798516
Validation loss: 3.399997697126078

Epoch: 6| Step: 10
Training loss: 3.986772362021332
Validation loss: 3.3997733348232217

Epoch: 6| Step: 11
Training loss: 4.045968326054292
Validation loss: 3.3988856439628456

Epoch: 6| Step: 12
Training loss: 3.1860234449617133
Validation loss: 3.398502315383589

Epoch: 6| Step: 13
Training loss: 3.53769844496045
Validation loss: 3.398034885514546

Epoch: 35| Step: 0
Training loss: 2.749166622464435
Validation loss: 3.397491876461966

Epoch: 6| Step: 1
Training loss: 3.311854461531369
Validation loss: 3.3972743998172454

Epoch: 6| Step: 2
Training loss: 3.699621547211327
Validation loss: 3.3969743025925694

Epoch: 6| Step: 3
Training loss: 3.7798658627723496
Validation loss: 3.395894762262796

Epoch: 6| Step: 4
Training loss: 4.228747918706072
Validation loss: 3.3957210521957304

Epoch: 6| Step: 5
Training loss: 3.321255610543459
Validation loss: 3.395363500693674

Epoch: 6| Step: 6
Training loss: 3.0350560155786575
Validation loss: 3.3949318862058675

Epoch: 6| Step: 7
Training loss: 4.5705086429598945
Validation loss: 3.3943035551073533

Epoch: 6| Step: 8
Training loss: 3.6944078301803986
Validation loss: 3.393692189126116

Epoch: 6| Step: 9
Training loss: 4.155679764027476
Validation loss: 3.3933411907899087

Epoch: 6| Step: 10
Training loss: 2.903601639529621
Validation loss: 3.392822240217711

Epoch: 6| Step: 11
Training loss: 3.829557438871012
Validation loss: 3.3923613187913615

Epoch: 6| Step: 12
Training loss: 3.3239942535369082
Validation loss: 3.3916571962550326

Epoch: 6| Step: 13
Training loss: 3.6927731844108576
Validation loss: 3.391381987639971

Epoch: 36| Step: 0
Training loss: 2.3312346920707405
Validation loss: 3.3909401416132927

Epoch: 6| Step: 1
Training loss: 3.2575783039322324
Validation loss: 3.3904600323041496

Epoch: 6| Step: 2
Training loss: 3.3435560508879894
Validation loss: 3.3897734434115727

Epoch: 6| Step: 3
Training loss: 4.270694835867287
Validation loss: 3.3895283432009085

Epoch: 6| Step: 4
Training loss: 3.997582897402685
Validation loss: 3.3891168057159855

Epoch: 6| Step: 5
Training loss: 3.129247753922998
Validation loss: 3.3884252727234774

Epoch: 6| Step: 6
Training loss: 2.9368158720680233
Validation loss: 3.388013951592677

Epoch: 6| Step: 7
Training loss: 4.398420804739074
Validation loss: 3.3872176617068073

Epoch: 6| Step: 8
Training loss: 4.418269652247439
Validation loss: 3.387062817260256

Epoch: 6| Step: 9
Training loss: 3.644803641096914
Validation loss: 3.3867867856778644

Epoch: 6| Step: 10
Training loss: 3.8485288608376313
Validation loss: 3.3867220988285864

Epoch: 6| Step: 11
Training loss: 3.549301325857442
Validation loss: 3.38576357645637

Epoch: 6| Step: 12
Training loss: 2.937197568218477
Validation loss: 3.3849946809575626

Epoch: 6| Step: 13
Training loss: 4.133160235769465
Validation loss: 3.3841857722118793

Epoch: 37| Step: 0
Training loss: 3.818593642909385
Validation loss: 3.3838591526235446

Epoch: 6| Step: 1
Training loss: 2.8223401333698557
Validation loss: 3.383714306889933

Epoch: 6| Step: 2
Training loss: 3.682571220667441
Validation loss: 3.3832000083806735

Epoch: 6| Step: 3
Training loss: 3.2233292680285386
Validation loss: 3.3823563932958205

Epoch: 6| Step: 4
Training loss: 3.943157793610971
Validation loss: 3.382401902290511

Epoch: 6| Step: 5
Training loss: 3.398981861933645
Validation loss: 3.382194649996379

Epoch: 6| Step: 6
Training loss: 4.775436157758386
Validation loss: 3.3811633439617252

Epoch: 6| Step: 7
Training loss: 3.1557882745502845
Validation loss: 3.380867189832539

Epoch: 6| Step: 8
Training loss: 3.4700551369983437
Validation loss: 3.380410993565599

Epoch: 6| Step: 9
Training loss: 3.9245817411096646
Validation loss: 3.379965322624499

Epoch: 6| Step: 10
Training loss: 2.9391865859741553
Validation loss: 3.3795597307305747

Epoch: 6| Step: 11
Training loss: 4.071459471315231
Validation loss: 3.37888786315183

Epoch: 6| Step: 12
Training loss: 3.03406983401675
Validation loss: 3.378094856543822

Epoch: 6| Step: 13
Training loss: 3.9727637952502994
Validation loss: 3.377653144822046

Epoch: 38| Step: 0
Training loss: 4.078401870390686
Validation loss: 3.3773732153328977

Epoch: 6| Step: 1
Training loss: 2.791176900081546
Validation loss: 3.377048522470606

Epoch: 6| Step: 2
Training loss: 4.024859901027661
Validation loss: 3.376211227809898

Epoch: 6| Step: 3
Training loss: 2.8192553454178704
Validation loss: 3.375678978199186

Epoch: 6| Step: 4
Training loss: 3.185986776751935
Validation loss: 3.375093742110909

Epoch: 6| Step: 5
Training loss: 3.029834220052473
Validation loss: 3.3743567786202555

Epoch: 6| Step: 6
Training loss: 3.9287199190488935
Validation loss: 3.374457161840228

Epoch: 6| Step: 7
Training loss: 3.0420425043491095
Validation loss: 3.3735787480439674

Epoch: 6| Step: 8
Training loss: 4.064639892393173
Validation loss: 3.3731215493347855

Epoch: 6| Step: 9
Training loss: 4.3880851159825305
Validation loss: 3.372131044336934

Epoch: 6| Step: 10
Training loss: 2.9768458754648304
Validation loss: 3.371700598936844

Epoch: 6| Step: 11
Training loss: 4.349672958532792
Validation loss: 3.371185939894592

Epoch: 6| Step: 12
Training loss: 3.397627249405579
Validation loss: 3.3699118111004758

Epoch: 6| Step: 13
Training loss: 3.9622329910763363
Validation loss: 3.368751339553809

Epoch: 39| Step: 0
Training loss: 2.891902002291387
Validation loss: 3.3681291854134847

Epoch: 6| Step: 1
Training loss: 4.3948721655958
Validation loss: 3.3667807693014082

Epoch: 6| Step: 2
Training loss: 3.7848630935318894
Validation loss: 3.3668705554321705

Epoch: 6| Step: 3
Training loss: 4.090039617444509
Validation loss: 3.366171725776008

Epoch: 6| Step: 4
Training loss: 3.2118037556594525
Validation loss: 3.366591653675527

Epoch: 6| Step: 5
Training loss: 4.104624740417028
Validation loss: 3.3660804899398897

Epoch: 6| Step: 6
Training loss: 3.130215069874112
Validation loss: 3.3660682310426555

Epoch: 6| Step: 7
Training loss: 3.7065738118385587
Validation loss: 3.367251430761382

Epoch: 6| Step: 8
Training loss: 3.1515213698434725
Validation loss: 3.3658125189729846

Epoch: 6| Step: 9
Training loss: 3.867869553963087
Validation loss: 3.364837471289542

Epoch: 6| Step: 10
Training loss: 3.549161199413375
Validation loss: 3.364292656567006

Epoch: 6| Step: 11
Training loss: 2.571765523738145
Validation loss: 3.363618803445831

Epoch: 6| Step: 12
Training loss: 3.8645651817752347
Validation loss: 3.363312636008609

Epoch: 6| Step: 13
Training loss: 3.610053456933022
Validation loss: 3.3623175441652244

Epoch: 40| Step: 0
Training loss: 4.171970552071708
Validation loss: 3.3619814247984228

Epoch: 6| Step: 1
Training loss: 3.472212292127185
Validation loss: 3.3610342763834504

Epoch: 6| Step: 2
Training loss: 3.6009007174834538
Validation loss: 3.3607424052392725

Epoch: 6| Step: 3
Training loss: 3.1277677867482145
Validation loss: 3.360368703483561

Epoch: 6| Step: 4
Training loss: 4.2377569340143975
Validation loss: 3.3599933197367213

Epoch: 6| Step: 5
Training loss: 3.533610407444018
Validation loss: 3.3590575686125326

Epoch: 6| Step: 6
Training loss: 4.058127764770375
Validation loss: 3.358399159631047

Epoch: 6| Step: 7
Training loss: 3.5322455969127033
Validation loss: 3.358193906332912

Epoch: 6| Step: 8
Training loss: 3.291574275655678
Validation loss: 3.3573602478899542

Epoch: 6| Step: 9
Training loss: 3.5021249587478414
Validation loss: 3.356754373041498

Epoch: 6| Step: 10
Training loss: 3.1176497420236977
Validation loss: 3.35620176720202

Epoch: 6| Step: 11
Training loss: 3.252640165318621
Validation loss: 3.355805848647174

Epoch: 6| Step: 12
Training loss: 3.6689567494664703
Validation loss: 3.355006957587848

Epoch: 6| Step: 13
Training loss: 3.4748680528797515
Validation loss: 3.3546687882588837

Epoch: 41| Step: 0
Training loss: 3.4668645459944694
Validation loss: 3.3543101418703585

Epoch: 6| Step: 1
Training loss: 4.10895956862224
Validation loss: 3.3538833240658494

Epoch: 6| Step: 2
Training loss: 2.740048783557182
Validation loss: 3.353246760017661

Epoch: 6| Step: 3
Training loss: 3.0728536480837327
Validation loss: 3.352829636812704

Epoch: 6| Step: 4
Training loss: 4.209867040568809
Validation loss: 3.3524821234758195

Epoch: 6| Step: 5
Training loss: 3.378100631019007
Validation loss: 3.351966353789308

Epoch: 6| Step: 6
Training loss: 3.8103952069701092
Validation loss: 3.3514664107421672

Epoch: 6| Step: 7
Training loss: 3.0028075750070187
Validation loss: 3.351371375894119

Epoch: 6| Step: 8
Training loss: 3.6801487983806656
Validation loss: 3.3507303193949047

Epoch: 6| Step: 9
Training loss: 3.6258149381986464
Validation loss: 3.3500212714460122

Epoch: 6| Step: 10
Training loss: 4.1942148601921945
Validation loss: 3.349532777385271

Epoch: 6| Step: 11
Training loss: 2.4145189366106585
Validation loss: 3.3493574228693443

Epoch: 6| Step: 12
Training loss: 3.924213335450052
Validation loss: 3.348762448427539

Epoch: 6| Step: 13
Training loss: 4.345007844661045
Validation loss: 3.348024776347902

Epoch: 42| Step: 0
Training loss: 3.471112245952156
Validation loss: 3.347868796091704

Epoch: 6| Step: 1
Training loss: 3.8789723862218057
Validation loss: 3.3471465464679753

Epoch: 6| Step: 2
Training loss: 4.212138554945064
Validation loss: 3.3470034461358638

Epoch: 6| Step: 3
Training loss: 3.8522223164704155
Validation loss: 3.3464269586173523

Epoch: 6| Step: 4
Training loss: 3.0296242670441647
Validation loss: 3.3456396498889176

Epoch: 6| Step: 5
Training loss: 3.3459434088956477
Validation loss: 3.344886731470797

Epoch: 6| Step: 6
Training loss: 3.3598845339417394
Validation loss: 3.3448930330992654

Epoch: 6| Step: 7
Training loss: 4.218436674562619
Validation loss: 3.3444727079343983

Epoch: 6| Step: 8
Training loss: 3.1677221914881186
Validation loss: 3.3440771777578115

Epoch: 6| Step: 9
Training loss: 3.1734750404560392
Validation loss: 3.3431796550751653

Epoch: 6| Step: 10
Training loss: 3.682776707381025
Validation loss: 3.3431261776617442

Epoch: 6| Step: 11
Training loss: 3.5362837031549406
Validation loss: 3.341803095000708

Epoch: 6| Step: 12
Training loss: 3.2374238465532197
Validation loss: 3.3421886648797487

Epoch: 6| Step: 13
Training loss: 3.8476987574983816
Validation loss: 3.3414940517550877

Epoch: 43| Step: 0
Training loss: 4.326716775785229
Validation loss: 3.341653969059616

Epoch: 6| Step: 1
Training loss: 3.4684334000452304
Validation loss: 3.3409608500352497

Epoch: 6| Step: 2
Training loss: 3.704564068434205
Validation loss: 3.340413342930364

Epoch: 6| Step: 3
Training loss: 2.2325797171206094
Validation loss: 3.340616672755322

Epoch: 6| Step: 4
Training loss: 4.174465104061753
Validation loss: 3.3394941452936022

Epoch: 6| Step: 5
Training loss: 3.758350738236979
Validation loss: 3.338934125158112

Epoch: 6| Step: 6
Training loss: 3.306024519906152
Validation loss: 3.338167160939604

Epoch: 6| Step: 7
Training loss: 3.1305058613484515
Validation loss: 3.337522849268623

Epoch: 6| Step: 8
Training loss: 3.1671657838156895
Validation loss: 3.3372510227163525

Epoch: 6| Step: 9
Training loss: 4.032973756341087
Validation loss: 3.336810052905587

Epoch: 6| Step: 10
Training loss: 3.5968001980133275
Validation loss: 3.335824137847492

Epoch: 6| Step: 11
Training loss: 3.475225092781129
Validation loss: 3.336137323402708

Epoch: 6| Step: 12
Training loss: 3.5769498136229485
Validation loss: 3.335332832733748

Epoch: 6| Step: 13
Training loss: 3.710742182359927
Validation loss: 3.3348230299222754

Epoch: 44| Step: 0
Training loss: 4.026841939896714
Validation loss: 3.334765384039273

Epoch: 6| Step: 1
Training loss: 3.3926238044294488
Validation loss: 3.334267013798214

Epoch: 6| Step: 2
Training loss: 4.002209053401497
Validation loss: 3.3335880633410704

Epoch: 6| Step: 3
Training loss: 2.5527681846101715
Validation loss: 3.333271374177886

Epoch: 6| Step: 4
Training loss: 3.7439241142733515
Validation loss: 3.3332818478535655

Epoch: 6| Step: 5
Training loss: 4.0504958991225495
Validation loss: 3.3328289332281633

Epoch: 6| Step: 6
Training loss: 3.991759753220276
Validation loss: 3.33209559830941

Epoch: 6| Step: 7
Training loss: 3.805401055633147
Validation loss: 3.3315545555589066

Epoch: 6| Step: 8
Training loss: 3.597019598976681
Validation loss: 3.3309926402950296

Epoch: 6| Step: 9
Training loss: 2.6680489970659513
Validation loss: 3.330594370079607

Epoch: 6| Step: 10
Training loss: 3.311481391192079
Validation loss: 3.330260355943875

Epoch: 6| Step: 11
Training loss: 3.5356779440681416
Validation loss: 3.328936067302236

Epoch: 6| Step: 12
Training loss: 3.5892580569461745
Validation loss: 3.328828721743412

Epoch: 6| Step: 13
Training loss: 3.1413263704949217
Validation loss: 3.328313955893222

Epoch: 45| Step: 0
Training loss: 4.376083675777046
Validation loss: 3.3291910372499474

Epoch: 6| Step: 1
Training loss: 3.37581215023067
Validation loss: 3.328779593060651

Epoch: 6| Step: 2
Training loss: 3.7766006511991304
Validation loss: 3.327135173710093

Epoch: 6| Step: 3
Training loss: 4.221021704629939
Validation loss: 3.326574034751224

Epoch: 6| Step: 4
Training loss: 4.1296231343120535
Validation loss: 3.326276995671522

Epoch: 6| Step: 5
Training loss: 2.9852090838383427
Validation loss: 3.3250022178838035

Epoch: 6| Step: 6
Training loss: 3.1342374457681212
Validation loss: 3.32484659326337

Epoch: 6| Step: 7
Training loss: 3.74688744117383
Validation loss: 3.3253079499597726

Epoch: 6| Step: 8
Training loss: 3.105699369876261
Validation loss: 3.324719844774851

Epoch: 6| Step: 9
Training loss: 3.331941377561415
Validation loss: 3.324011136222833

Epoch: 6| Step: 10
Training loss: 3.370868838908743
Validation loss: 3.3223800022649903

Epoch: 6| Step: 11
Training loss: 3.0008178231995735
Validation loss: 3.322461429601295

Epoch: 6| Step: 12
Training loss: 3.0470652985444455
Validation loss: 3.32231471728539

Epoch: 6| Step: 13
Training loss: 4.153193217363819
Validation loss: 3.3217923843117974

Epoch: 46| Step: 0
Training loss: 3.0560290422507568
Validation loss: 3.3213956946342833

Epoch: 6| Step: 1
Training loss: 4.316959894499009
Validation loss: 3.3212980880947782

Epoch: 6| Step: 2
Training loss: 4.1693631157400475
Validation loss: 3.320829163900212

Epoch: 6| Step: 3
Training loss: 3.1669870682968186
Validation loss: 3.3191127605953104

Epoch: 6| Step: 4
Training loss: 3.4140535612011127
Validation loss: 3.318925777348915

Epoch: 6| Step: 5
Training loss: 3.8490425207336973
Validation loss: 3.3190026873968113

Epoch: 6| Step: 6
Training loss: 3.2771618761923484
Validation loss: 3.3195921699585287

Epoch: 6| Step: 7
Training loss: 3.438830863642502
Validation loss: 3.3190879158915423

Epoch: 6| Step: 8
Training loss: 3.9524518672514475
Validation loss: 3.3175640824696533

Epoch: 6| Step: 9
Training loss: 3.9813211144244707
Validation loss: 3.3173292654409723

Epoch: 6| Step: 10
Training loss: 2.8081225767959337
Validation loss: 3.316712324591148

Epoch: 6| Step: 11
Training loss: 2.9494260197240405
Validation loss: 3.316054478928847

Epoch: 6| Step: 12
Training loss: 3.746621071910253
Validation loss: 3.31595202308491

Epoch: 6| Step: 13
Training loss: 3.1186929762525444
Validation loss: 3.314991438736486

Epoch: 47| Step: 0
Training loss: 4.265046803618988
Validation loss: 3.31525711474781

Epoch: 6| Step: 1
Training loss: 3.1586666109152977
Validation loss: 3.315296103579235

Epoch: 6| Step: 2
Training loss: 2.4003475176026554
Validation loss: 3.3141688706948154

Epoch: 6| Step: 3
Training loss: 4.482951400163244
Validation loss: 3.312790102414768

Epoch: 6| Step: 4
Training loss: 4.233793887419692
Validation loss: 3.313542943846557

Epoch: 6| Step: 5
Training loss: 3.649674983773571
Validation loss: 3.3125995536668142

Epoch: 6| Step: 6
Training loss: 3.4316998185169374
Validation loss: 3.3122851765883223

Epoch: 6| Step: 7
Training loss: 2.8275709083630933
Validation loss: 3.3129965204369234

Epoch: 6| Step: 8
Training loss: 3.9572870712206734
Validation loss: 3.311026933087788

Epoch: 6| Step: 9
Training loss: 3.5387070500480213
Validation loss: 3.311375807022985

Epoch: 6| Step: 10
Training loss: 2.864487044132156
Validation loss: 3.3107463662704975

Epoch: 6| Step: 11
Training loss: 3.060770753268683
Validation loss: 3.309536082115133

Epoch: 6| Step: 12
Training loss: 4.0691607524311415
Validation loss: 3.310986235470416

Epoch: 6| Step: 13
Training loss: 2.6992017908295014
Validation loss: 3.309796984006132

Epoch: 48| Step: 0
Training loss: 3.9748184786441993
Validation loss: 3.3090616686070295

Epoch: 6| Step: 1
Training loss: 3.696384137441389
Validation loss: 3.309046978854208

Epoch: 6| Step: 2
Training loss: 3.7281494600272223
Validation loss: 3.308244928296892

Epoch: 6| Step: 3
Training loss: 4.009234259878803
Validation loss: 3.3073727037835257

Epoch: 6| Step: 4
Training loss: 4.057513654101814
Validation loss: 3.3069673492396925

Epoch: 6| Step: 5
Training loss: 3.487693540610375
Validation loss: 3.307199876496757

Epoch: 6| Step: 6
Training loss: 3.243560279781188
Validation loss: 3.3059259965826002

Epoch: 6| Step: 7
Training loss: 2.7369862322560343
Validation loss: 3.3052139780188785

Epoch: 6| Step: 8
Training loss: 2.3491644814670445
Validation loss: 3.3058888452410993

Epoch: 6| Step: 9
Training loss: 3.779456982437065
Validation loss: 3.3069438792481676

Epoch: 6| Step: 10
Training loss: 3.5876491342841734
Validation loss: 3.308904518724983

Epoch: 6| Step: 11
Training loss: 3.6952312049230307
Validation loss: 3.313979314052937

Epoch: 6| Step: 12
Training loss: 3.774772202648097
Validation loss: 3.3139061213891687

Epoch: 6| Step: 13
Training loss: 2.7900279535239987
Validation loss: 3.3114201090892372

Epoch: 49| Step: 0
Training loss: 3.272755699804901
Validation loss: 3.3082647120647644

Epoch: 6| Step: 1
Training loss: 3.995403509852662
Validation loss: 3.305967072880428

Epoch: 6| Step: 2
Training loss: 3.8271408372994835
Validation loss: 3.3072920909309973

Epoch: 6| Step: 3
Training loss: 3.736821988972783
Validation loss: 3.300482574695127

Epoch: 6| Step: 4
Training loss: 3.836290518061014
Validation loss: 3.3008083497000658

Epoch: 6| Step: 5
Training loss: 3.7040093890950647
Validation loss: 3.3016659940116058

Epoch: 6| Step: 6
Training loss: 4.1685924403027945
Validation loss: 3.2985578071045247

Epoch: 6| Step: 7
Training loss: 2.3910527064865246
Validation loss: 3.301933572176476

Epoch: 6| Step: 8
Training loss: 3.570773238956494
Validation loss: 3.3005580814278255

Epoch: 6| Step: 9
Training loss: 3.379655946680391
Validation loss: 3.302406335349992

Epoch: 6| Step: 10
Training loss: 3.11010672235904
Validation loss: 3.303306675691808

Epoch: 6| Step: 11
Training loss: 3.5503141559697364
Validation loss: 3.3047125522619383

Epoch: 6| Step: 12
Training loss: 3.3896771349800763
Validation loss: 3.30387507199442

Epoch: 6| Step: 13
Training loss: 3.2169249462210243
Validation loss: 3.2972304360538103

Epoch: 50| Step: 0
Training loss: 4.457123684405217
Validation loss: 3.2989900732191915

Epoch: 6| Step: 1
Training loss: 3.759103913969784
Validation loss: 3.3134180902931707

Epoch: 6| Step: 2
Training loss: 3.7481427997918964
Validation loss: 3.3030601312628005

Epoch: 6| Step: 3
Training loss: 2.4520535407016064
Validation loss: 3.2977580361624437

Epoch: 6| Step: 4
Training loss: 3.9416344144656295
Validation loss: 3.2984275783795836

Epoch: 6| Step: 5
Training loss: 2.6832427971139996
Validation loss: 3.2980587973392548

Epoch: 6| Step: 6
Training loss: 3.486528355594607
Validation loss: 3.310160229447478

Epoch: 6| Step: 7
Training loss: 3.7447993774051715
Validation loss: 3.3092342398482253

Epoch: 6| Step: 8
Training loss: 2.6462661709514355
Validation loss: 3.3078124463372003

Epoch: 6| Step: 9
Training loss: 3.969735691487043
Validation loss: 3.3094530105711546

Epoch: 6| Step: 10
Training loss: 3.945221369229068
Validation loss: 3.2969120149722015

Epoch: 6| Step: 11
Training loss: 3.298422789077806
Validation loss: 3.2969008627800855

Epoch: 6| Step: 12
Training loss: 2.84008939118806
Validation loss: 3.296349912141355

Epoch: 6| Step: 13
Training loss: 4.383945801351172
Validation loss: 3.3037389800418104

Epoch: 51| Step: 0
Training loss: 3.2725973211844344
Validation loss: 3.2964202484805347

Epoch: 6| Step: 1
Training loss: 4.280362447918035
Validation loss: 3.292024429171238

Epoch: 6| Step: 2
Training loss: 3.0756551835412944
Validation loss: 3.29021228240571

Epoch: 6| Step: 3
Training loss: 3.9494320956143367
Validation loss: 3.291179503069976

Epoch: 6| Step: 4
Training loss: 3.4152151296388147
Validation loss: 3.295612707273145

Epoch: 6| Step: 5
Training loss: 2.6487138542096114
Validation loss: 3.2976560955746903

Epoch: 6| Step: 6
Training loss: 3.574761554795651
Validation loss: 3.299880285879003

Epoch: 6| Step: 7
Training loss: 2.7424554503725
Validation loss: 3.2945918606935285

Epoch: 6| Step: 8
Training loss: 3.08198297847179
Validation loss: 3.2938012994681425

Epoch: 6| Step: 9
Training loss: 3.7073742915813637
Validation loss: 3.2918020080140806

Epoch: 6| Step: 10
Training loss: 3.984650127411241
Validation loss: 3.2915484862934585

Epoch: 6| Step: 11
Training loss: 3.598317304053979
Validation loss: 3.287880684589967

Epoch: 6| Step: 12
Training loss: 3.900835358580387
Validation loss: 3.287151918668534

Epoch: 6| Step: 13
Training loss: 4.107089839616805
Validation loss: 3.290579939791981

Epoch: 52| Step: 0
Training loss: 3.198988015374513
Validation loss: 3.2861386869420364

Epoch: 6| Step: 1
Training loss: 3.1584199301356564
Validation loss: 3.285682841157953

Epoch: 6| Step: 2
Training loss: 3.2418421549886305
Validation loss: 3.283300095493985

Epoch: 6| Step: 3
Training loss: 3.638092600998152
Validation loss: 3.2819313916139485

Epoch: 6| Step: 4
Training loss: 3.759299128932932
Validation loss: 3.282184695450559

Epoch: 6| Step: 5
Training loss: 3.957897095316433
Validation loss: 3.2811741708332893

Epoch: 6| Step: 6
Training loss: 3.6607481845256458
Validation loss: 3.2824386670349543

Epoch: 6| Step: 7
Training loss: 2.9874018952290573
Validation loss: 3.2814776832353565

Epoch: 6| Step: 8
Training loss: 3.008004952751303
Validation loss: 3.2811065423703987

Epoch: 6| Step: 9
Training loss: 3.8068072232175365
Validation loss: 3.280250263413421

Epoch: 6| Step: 10
Training loss: 4.1057393631822015
Validation loss: 3.27884674740322

Epoch: 6| Step: 11
Training loss: 4.134477766609453
Validation loss: 3.27769664400732

Epoch: 6| Step: 12
Training loss: 2.992571853374188
Validation loss: 3.276985308919856

Epoch: 6| Step: 13
Training loss: 3.40291551237685
Validation loss: 3.276546630620646

Epoch: 53| Step: 0
Training loss: 3.5780999461800276
Validation loss: 3.2753059000113915

Epoch: 6| Step: 1
Training loss: 3.385468530502168
Validation loss: 3.275676607115725

Epoch: 6| Step: 2
Training loss: 3.0292183271267983
Validation loss: 3.274525750415585

Epoch: 6| Step: 3
Training loss: 3.566869498810604
Validation loss: 3.2860881149074532

Epoch: 6| Step: 4
Training loss: 3.547360290400064
Validation loss: 3.2918812222466367

Epoch: 6| Step: 5
Training loss: 3.8994821742658337
Validation loss: 3.2762898900614736

Epoch: 6| Step: 6
Training loss: 3.4015355513437844
Validation loss: 3.277322772837948

Epoch: 6| Step: 7
Training loss: 3.1194208314280654
Validation loss: 3.2879438229428417

Epoch: 6| Step: 8
Training loss: 3.498321675763843
Validation loss: 3.3127748681427396

Epoch: 6| Step: 9
Training loss: 3.232709815347511
Validation loss: 3.293309832124114

Epoch: 6| Step: 10
Training loss: 4.120586924551308
Validation loss: 3.288638745019504

Epoch: 6| Step: 11
Training loss: 4.099708472331352
Validation loss: 3.2850999676013264

Epoch: 6| Step: 12
Training loss: 3.700455874634198
Validation loss: 3.2797612959380746

Epoch: 6| Step: 13
Training loss: 2.568830532472983
Validation loss: 3.2790772322356547

Epoch: 54| Step: 0
Training loss: 3.893082788409734
Validation loss: 3.283066094929263

Epoch: 6| Step: 1
Training loss: 4.059704567068274
Validation loss: 3.2800717036645644

Epoch: 6| Step: 2
Training loss: 3.681231067654123
Validation loss: 3.27826848594058

Epoch: 6| Step: 3
Training loss: 3.5779800052499944
Validation loss: 3.277533329206894

Epoch: 6| Step: 4
Training loss: 3.0011475275698745
Validation loss: 3.272461363668697

Epoch: 6| Step: 5
Training loss: 2.7474888693919874
Validation loss: 3.2724553926014854

Epoch: 6| Step: 6
Training loss: 3.316693225032217
Validation loss: 3.2708396140835707

Epoch: 6| Step: 7
Training loss: 3.0891586296471627
Validation loss: 3.271283785640024

Epoch: 6| Step: 8
Training loss: 3.733760256425929
Validation loss: 3.269643233295903

Epoch: 6| Step: 9
Training loss: 3.2445118856460726
Validation loss: 3.270272658286048

Epoch: 6| Step: 10
Training loss: 3.2344263045070463
Validation loss: 3.2691132068260487

Epoch: 6| Step: 11
Training loss: 4.150626601747475
Validation loss: 3.266330006031012

Epoch: 6| Step: 12
Training loss: 4.289553199033539
Validation loss: 3.2694796306975107

Epoch: 6| Step: 13
Training loss: 2.060592462839898
Validation loss: 3.2688951784490388

Epoch: 55| Step: 0
Training loss: 3.508865979883346
Validation loss: 3.265796099321221

Epoch: 6| Step: 1
Training loss: 3.72092303730025
Validation loss: 3.266949554129223

Epoch: 6| Step: 2
Training loss: 3.5508537662768402
Validation loss: 3.266079434892176

Epoch: 6| Step: 3
Training loss: 3.0616179772584093
Validation loss: 3.2646724981794626

Epoch: 6| Step: 4
Training loss: 3.0965315519598238
Validation loss: 3.2660448711434

Epoch: 6| Step: 5
Training loss: 3.686012097194482
Validation loss: 3.266452145820787

Epoch: 6| Step: 6
Training loss: 3.2742601330598813
Validation loss: 3.26481136818156

Epoch: 6| Step: 7
Training loss: 3.6706126538963284
Validation loss: 3.265987483868912

Epoch: 6| Step: 8
Training loss: 3.109801603410295
Validation loss: 3.2654014825316304

Epoch: 6| Step: 9
Training loss: 3.7017425660778596
Validation loss: 3.268367805019507

Epoch: 6| Step: 10
Training loss: 4.240592417806158
Validation loss: 3.270264673240726

Epoch: 6| Step: 11
Training loss: 3.402305629091837
Validation loss: 3.267443099447386

Epoch: 6| Step: 12
Training loss: 3.6141985744351706
Validation loss: 3.2664714991204327

Epoch: 6| Step: 13
Training loss: 3.3631973167517617
Validation loss: 3.2630778943599563

Epoch: 56| Step: 0
Training loss: 3.2750393173536714
Validation loss: 3.26638746106409

Epoch: 6| Step: 1
Training loss: 3.808450893755103
Validation loss: 3.262326410358985

Epoch: 6| Step: 2
Training loss: 3.3393323004775515
Validation loss: 3.2610961139006127

Epoch: 6| Step: 3
Training loss: 3.974658322794424
Validation loss: 3.260857920840628

Epoch: 6| Step: 4
Training loss: 3.3080356672179243
Validation loss: 3.261851118660093

Epoch: 6| Step: 5
Training loss: 3.60150186152518
Validation loss: 3.258300156135004

Epoch: 6| Step: 6
Training loss: 2.9924192015177793
Validation loss: 3.2561116238745167

Epoch: 6| Step: 7
Training loss: 3.970127017009527
Validation loss: 3.257672691065062

Epoch: 6| Step: 8
Training loss: 3.330540027074925
Validation loss: 3.255531763691239

Epoch: 6| Step: 9
Training loss: 3.4784769680439043
Validation loss: 3.2578466978275276

Epoch: 6| Step: 10
Training loss: 3.1770542497814995
Validation loss: 3.2575094316604596

Epoch: 6| Step: 11
Training loss: 3.41228657149368
Validation loss: 3.2560771826446047

Epoch: 6| Step: 12
Training loss: 4.021419871082975
Validation loss: 3.2575695873584407

Epoch: 6| Step: 13
Training loss: 3.0459269295717726
Validation loss: 3.2545887362907804

Epoch: 57| Step: 0
Training loss: 2.800669733059276
Validation loss: 3.2527672193524633

Epoch: 6| Step: 1
Training loss: 3.55873605085613
Validation loss: 3.2531734871979094

Epoch: 6| Step: 2
Training loss: 3.1045464063663513
Validation loss: 3.2516442928233116

Epoch: 6| Step: 3
Training loss: 3.6858166230527494
Validation loss: 3.252355945090136

Epoch: 6| Step: 4
Training loss: 4.393984123927082
Validation loss: 3.25120561985672

Epoch: 6| Step: 5
Training loss: 3.6271952854841008
Validation loss: 3.2546388730308804

Epoch: 6| Step: 6
Training loss: 4.122610382582515
Validation loss: 3.251654277278018

Epoch: 6| Step: 7
Training loss: 3.4679209775270357
Validation loss: 3.2539857872065907

Epoch: 6| Step: 8
Training loss: 2.9820809859619737
Validation loss: 3.2503370799651843

Epoch: 6| Step: 9
Training loss: 3.4663532671727726
Validation loss: 3.249627252095685

Epoch: 6| Step: 10
Training loss: 3.496524174795827
Validation loss: 3.251478292829662

Epoch: 6| Step: 11
Training loss: 3.1465428712168015
Validation loss: 3.250500718536389

Epoch: 6| Step: 12
Training loss: 3.281898797696656
Validation loss: 3.24810231403411

Epoch: 6| Step: 13
Training loss: 3.6197479611326564
Validation loss: 3.249109705514346

Epoch: 58| Step: 0
Training loss: 3.8524383106280657
Validation loss: 3.2476973726144753

Epoch: 6| Step: 1
Training loss: 3.573081647587576
Validation loss: 3.247448721248922

Epoch: 6| Step: 2
Training loss: 3.5296496250371514
Validation loss: 3.247363749600844

Epoch: 6| Step: 3
Training loss: 3.410376892292896
Validation loss: 3.245567455920826

Epoch: 6| Step: 4
Training loss: 2.858788768937438
Validation loss: 3.246783003770586

Epoch: 6| Step: 5
Training loss: 3.9640720462045085
Validation loss: 3.2478232560277878

Epoch: 6| Step: 6
Training loss: 3.940230134545899
Validation loss: 3.244851344972423

Epoch: 6| Step: 7
Training loss: 3.0012236324933084
Validation loss: 3.2478063514531224

Epoch: 6| Step: 8
Training loss: 3.480328729383935
Validation loss: 3.248562830287908

Epoch: 6| Step: 9
Training loss: 4.074746789846848
Validation loss: 3.2469211284727404

Epoch: 6| Step: 10
Training loss: 3.300417474869331
Validation loss: 3.246998782397409

Epoch: 6| Step: 11
Training loss: 3.1042739201051384
Validation loss: 3.242614229350384

Epoch: 6| Step: 12
Training loss: 3.6424151427596207
Validation loss: 3.241784064066224

Epoch: 6| Step: 13
Training loss: 2.3624966414493325
Validation loss: 3.2435277515867673

Epoch: 59| Step: 0
Training loss: 2.6843863792311473
Validation loss: 3.2421324975193473

Epoch: 6| Step: 1
Training loss: 3.1172899884271663
Validation loss: 3.2421367721849106

Epoch: 6| Step: 2
Training loss: 4.344180957081117
Validation loss: 3.2420834467914665

Epoch: 6| Step: 3
Training loss: 3.0650911852168194
Validation loss: 3.2408797286218674

Epoch: 6| Step: 4
Training loss: 2.6488017954134464
Validation loss: 3.2411613523715155

Epoch: 6| Step: 5
Training loss: 3.9000654166188355
Validation loss: 3.239757640907778

Epoch: 6| Step: 6
Training loss: 4.1129888736751505
Validation loss: 3.240890451838361

Epoch: 6| Step: 7
Training loss: 3.7807906951641277
Validation loss: 3.239503625583516

Epoch: 6| Step: 8
Training loss: 3.229341137182297
Validation loss: 3.2377902509418326

Epoch: 6| Step: 9
Training loss: 3.322939849740756
Validation loss: 3.240099442668957

Epoch: 6| Step: 10
Training loss: 3.482651767641399
Validation loss: 3.2497463647964127

Epoch: 6| Step: 11
Training loss: 3.394983540243662
Validation loss: 3.2519113837724007

Epoch: 6| Step: 12
Training loss: 3.5745522598841073
Validation loss: 3.2370435364979238

Epoch: 6| Step: 13
Training loss: 3.990074359898819
Validation loss: 3.2354227685072825

Epoch: 60| Step: 0
Training loss: 3.3980763210551674
Validation loss: 3.23555952966056

Epoch: 6| Step: 1
Training loss: 3.825362224506542
Validation loss: 3.2445143698666135

Epoch: 6| Step: 2
Training loss: 3.7967104778045044
Validation loss: 3.2483357695479356

Epoch: 6| Step: 3
Training loss: 3.2223323404927444
Validation loss: 3.2427970462490023

Epoch: 6| Step: 4
Training loss: 3.147701205730016
Validation loss: 3.2351120888700047

Epoch: 6| Step: 5
Training loss: 3.4333671000280015
Validation loss: 3.234319029221658

Epoch: 6| Step: 6
Training loss: 3.4062281616630794
Validation loss: 3.2338581469816687

Epoch: 6| Step: 7
Training loss: 3.1556253853833756
Validation loss: 3.234279909183106

Epoch: 6| Step: 8
Training loss: 3.779779069287261
Validation loss: 3.232338901177676

Epoch: 6| Step: 9
Training loss: 3.790392203859916
Validation loss: 3.233028520573476

Epoch: 6| Step: 10
Training loss: 3.6798772094807006
Validation loss: 3.2328058421026844

Epoch: 6| Step: 11
Training loss: 3.955932585169798
Validation loss: 3.2355002388378455

Epoch: 6| Step: 12
Training loss: 3.260220083987079
Validation loss: 3.2414047290599313

Epoch: 6| Step: 13
Training loss: 2.09970884575421
Validation loss: 3.2499996134818505

Epoch: 61| Step: 0
Training loss: 3.349185411853699
Validation loss: 3.268895380002036

Epoch: 6| Step: 1
Training loss: 2.9694826527076135
Validation loss: 3.286045704136138

Epoch: 6| Step: 2
Training loss: 3.3410385404006315
Validation loss: 3.2822285581269646

Epoch: 6| Step: 3
Training loss: 3.6106351163754438
Validation loss: 3.263465614483101

Epoch: 6| Step: 4
Training loss: 3.266498357627896
Validation loss: 3.2327684975580344

Epoch: 6| Step: 5
Training loss: 3.218876808409238
Validation loss: 3.233690795531516

Epoch: 6| Step: 6
Training loss: 3.513714215976128
Validation loss: 3.230610010789147

Epoch: 6| Step: 7
Training loss: 2.933393489336412
Validation loss: 3.231101526518007

Epoch: 6| Step: 8
Training loss: 3.510366075341738
Validation loss: 3.2294951611543214

Epoch: 6| Step: 9
Training loss: 3.6350497668190154
Validation loss: 3.2294372371141375

Epoch: 6| Step: 10
Training loss: 4.186314201420813
Validation loss: 3.2394909874063313

Epoch: 6| Step: 11
Training loss: 4.260570395882058
Validation loss: 3.228880640885889

Epoch: 6| Step: 12
Training loss: 3.110321207661926
Validation loss: 3.224639856061731

Epoch: 6| Step: 13
Training loss: 3.7952682800355295
Validation loss: 3.224473113021855

Epoch: 62| Step: 0
Training loss: 3.4318123667539675
Validation loss: 3.225041326925932

Epoch: 6| Step: 1
Training loss: 3.5859160910904353
Validation loss: 3.224137978191666

Epoch: 6| Step: 2
Training loss: 2.6468207451710573
Validation loss: 3.227756006083182

Epoch: 6| Step: 3
Training loss: 3.674839462614492
Validation loss: 3.2300425153790453

Epoch: 6| Step: 4
Training loss: 3.0332851853234852
Validation loss: 3.229865743100378

Epoch: 6| Step: 5
Training loss: 3.4796418343310926
Validation loss: 3.2293236087340933

Epoch: 6| Step: 6
Training loss: 2.707513587332858
Validation loss: 3.225710433074421

Epoch: 6| Step: 7
Training loss: 3.4263978096644356
Validation loss: 3.223779362095651

Epoch: 6| Step: 8
Training loss: 3.3653373857474778
Validation loss: 3.221459065568886

Epoch: 6| Step: 9
Training loss: 3.923701617041953
Validation loss: 3.2200787361621366

Epoch: 6| Step: 10
Training loss: 4.359771382348811
Validation loss: 3.2192360956664867

Epoch: 6| Step: 11
Training loss: 3.7189341267113565
Validation loss: 3.220132018335566

Epoch: 6| Step: 12
Training loss: 3.1865822461915467
Validation loss: 3.2184975311317188

Epoch: 6| Step: 13
Training loss: 4.011174804895654
Validation loss: 3.219263877034069

Epoch: 63| Step: 0
Training loss: 3.6007343920694073
Validation loss: 3.2214053469558293

Epoch: 6| Step: 1
Training loss: 3.1080856333636127
Validation loss: 3.2198761338852693

Epoch: 6| Step: 2
Training loss: 3.0288589328221485
Validation loss: 3.2226932757933295

Epoch: 6| Step: 3
Training loss: 2.5952511775002445
Validation loss: 3.221611297128898

Epoch: 6| Step: 4
Training loss: 3.6022481203674626
Validation loss: 3.222502882444388

Epoch: 6| Step: 5
Training loss: 3.575647954308681
Validation loss: 3.2332821272243892

Epoch: 6| Step: 6
Training loss: 3.8911311421682715
Validation loss: 3.231264447722023

Epoch: 6| Step: 7
Training loss: 3.5622851658341683
Validation loss: 3.2226487817861087

Epoch: 6| Step: 8
Training loss: 3.428371168146347
Validation loss: 3.219972965338704

Epoch: 6| Step: 9
Training loss: 2.927101397656577
Validation loss: 3.2192199663407814

Epoch: 6| Step: 10
Training loss: 3.9987465563488294
Validation loss: 3.2218768467835233

Epoch: 6| Step: 11
Training loss: 3.8855754148287085
Validation loss: 3.2329599801354765

Epoch: 6| Step: 12
Training loss: 3.331506291992255
Validation loss: 3.2331594551287868

Epoch: 6| Step: 13
Training loss: 4.061750372169052
Validation loss: 3.228875448305208

Epoch: 64| Step: 0
Training loss: 3.2993003276880866
Validation loss: 3.2213309501870913

Epoch: 6| Step: 1
Training loss: 3.4095294809002503
Validation loss: 3.218797348252449

Epoch: 6| Step: 2
Training loss: 3.5271490810069874
Validation loss: 3.2188878215558026

Epoch: 6| Step: 3
Training loss: 3.7646979619391656
Validation loss: 3.221761497168524

Epoch: 6| Step: 4
Training loss: 3.3247653677622706
Validation loss: 3.2156166032143987

Epoch: 6| Step: 5
Training loss: 3.8928966095249913
Validation loss: 3.2167180966803244

Epoch: 6| Step: 6
Training loss: 3.5007651718781787
Validation loss: 3.213123070830292

Epoch: 6| Step: 7
Training loss: 3.7762157882357954
Validation loss: 3.214994378643569

Epoch: 6| Step: 8
Training loss: 3.8973142423767944
Validation loss: 3.21166917263939

Epoch: 6| Step: 9
Training loss: 2.6676525637929016
Validation loss: 3.2105173578061

Epoch: 6| Step: 10
Training loss: 3.1784326575098607
Validation loss: 3.2126903623252807

Epoch: 6| Step: 11
Training loss: 2.482388932124306
Validation loss: 3.213060110632353

Epoch: 6| Step: 12
Training loss: 3.868967344128989
Validation loss: 3.2199782773697043

Epoch: 6| Step: 13
Training loss: 3.7188450135987727
Validation loss: 3.230957606906407

Epoch: 65| Step: 0
Training loss: 3.782674347766728
Validation loss: 3.2474174074797286

Epoch: 6| Step: 1
Training loss: 2.275298520299222
Validation loss: 3.2537599731699403

Epoch: 6| Step: 2
Training loss: 3.852638326509528
Validation loss: 3.246215969645889

Epoch: 6| Step: 3
Training loss: 3.5323658758295546
Validation loss: 3.2118557096491887

Epoch: 6| Step: 4
Training loss: 3.1482009230867116
Validation loss: 3.2045538915864236

Epoch: 6| Step: 5
Training loss: 3.638185002694416
Validation loss: 3.205953553366295

Epoch: 6| Step: 6
Training loss: 3.466757399643211
Validation loss: 3.209167239983949

Epoch: 6| Step: 7
Training loss: 3.4521518906895743
Validation loss: 3.210067107697402

Epoch: 6| Step: 8
Training loss: 3.691069346398395
Validation loss: 3.2086655586315604

Epoch: 6| Step: 9
Training loss: 2.2861774477701573
Validation loss: 3.2060685657568935

Epoch: 6| Step: 10
Training loss: 3.6904758148661947
Validation loss: 3.21034332511245

Epoch: 6| Step: 11
Training loss: 3.691859109539851
Validation loss: 3.2057225349650698

Epoch: 6| Step: 12
Training loss: 3.6865606889674205
Validation loss: 3.2035492886895987

Epoch: 6| Step: 13
Training loss: 4.023866974954429
Validation loss: 3.2001577524299174

Epoch: 66| Step: 0
Training loss: 3.4003934296010834
Validation loss: 3.199728201980186

Epoch: 6| Step: 1
Training loss: 3.7185232910805595
Validation loss: 3.2000472790804246

Epoch: 6| Step: 2
Training loss: 3.3801322344583378
Validation loss: 3.201109331643153

Epoch: 6| Step: 3
Training loss: 3.638932649253853
Validation loss: 3.2015528636714823

Epoch: 6| Step: 4
Training loss: 2.8678323711743112
Validation loss: 3.201888789130313

Epoch: 6| Step: 5
Training loss: 3.499494243592565
Validation loss: 3.1979045273793356

Epoch: 6| Step: 6
Training loss: 3.15217190903996
Validation loss: 3.1981593625771962

Epoch: 6| Step: 7
Training loss: 3.5088109419979543
Validation loss: 3.197078515766639

Epoch: 6| Step: 8
Training loss: 4.167746798067601
Validation loss: 3.1961258102569925

Epoch: 6| Step: 9
Training loss: 3.8468999593809756
Validation loss: 3.1912469317421537

Epoch: 6| Step: 10
Training loss: 3.2997100355894498
Validation loss: 3.193340200779509

Epoch: 6| Step: 11
Training loss: 3.3677292673388726
Validation loss: 3.191081723211565

Epoch: 6| Step: 12
Training loss: 3.43366832456878
Validation loss: 3.194303923291286

Epoch: 6| Step: 13
Training loss: 2.1929263794070395
Validation loss: 3.1926066843426093

Epoch: 67| Step: 0
Training loss: 3.5948899824474294
Validation loss: 3.1946144307263795

Epoch: 6| Step: 1
Training loss: 3.287827067187456
Validation loss: 3.1967952675786657

Epoch: 6| Step: 2
Training loss: 2.7209712633706493
Validation loss: 3.194275692094863

Epoch: 6| Step: 3
Training loss: 2.7678115735499853
Validation loss: 3.196559594947056

Epoch: 6| Step: 4
Training loss: 3.307854183548843
Validation loss: 3.1933092443339564

Epoch: 6| Step: 5
Training loss: 3.10764790018055
Validation loss: 3.196045508532116

Epoch: 6| Step: 6
Training loss: 3.9952511015505543
Validation loss: 3.1948570040936226

Epoch: 6| Step: 7
Training loss: 2.8175128767909063
Validation loss: 3.1972765586376872

Epoch: 6| Step: 8
Training loss: 3.75975421061579
Validation loss: 3.196313623326755

Epoch: 6| Step: 9
Training loss: 3.4175920551350574
Validation loss: 3.1932149216622947

Epoch: 6| Step: 10
Training loss: 3.9485521970875603
Validation loss: 3.195662900601178

Epoch: 6| Step: 11
Training loss: 4.482518253661571
Validation loss: 3.192186761277893

Epoch: 6| Step: 12
Training loss: 3.2184430318581696
Validation loss: 3.1909000520786672

Epoch: 6| Step: 13
Training loss: 3.2208831533220073
Validation loss: 3.1904209610342558

Epoch: 68| Step: 0
Training loss: 3.2686578274453755
Validation loss: 3.187654335874789

Epoch: 6| Step: 1
Training loss: 3.0770562344862062
Validation loss: 3.1872108033914737

Epoch: 6| Step: 2
Training loss: 3.3916658131241406
Validation loss: 3.186134077884479

Epoch: 6| Step: 3
Training loss: 3.795605859455382
Validation loss: 3.1850300789773995

Epoch: 6| Step: 4
Training loss: 2.7833969744718017
Validation loss: 3.1856058795710704

Epoch: 6| Step: 5
Training loss: 2.289615915730178
Validation loss: 3.184531268823515

Epoch: 6| Step: 6
Training loss: 3.3513135128412768
Validation loss: 3.1833997457833507

Epoch: 6| Step: 7
Training loss: 3.71132604873771
Validation loss: 3.187377560584493

Epoch: 6| Step: 8
Training loss: 3.625814675175197
Validation loss: 3.1832747213436208

Epoch: 6| Step: 9
Training loss: 4.027316991530286
Validation loss: 3.183033758854479

Epoch: 6| Step: 10
Training loss: 3.0906084852867037
Validation loss: 3.185445815695383

Epoch: 6| Step: 11
Training loss: 4.082280289203466
Validation loss: 3.1878601359772913

Epoch: 6| Step: 12
Training loss: 3.3221309932854624
Validation loss: 3.18461595274344

Epoch: 6| Step: 13
Training loss: 4.082603830581114
Validation loss: 3.1839131428409297

Epoch: 69| Step: 0
Training loss: 3.5519363656315135
Validation loss: 3.1859837431769473

Epoch: 6| Step: 1
Training loss: 3.4391345212848483
Validation loss: 3.1854398046529475

Epoch: 6| Step: 2
Training loss: 3.061029509348855
Validation loss: 3.1832752448191046

Epoch: 6| Step: 3
Training loss: 3.3870763534891317
Validation loss: 3.1841778510573353

Epoch: 6| Step: 4
Training loss: 2.9835657750226856
Validation loss: 3.1829347098567897

Epoch: 6| Step: 5
Training loss: 3.4729651881174934
Validation loss: 3.1848553136180646

Epoch: 6| Step: 6
Training loss: 3.1605968191811447
Validation loss: 3.1897919264928785

Epoch: 6| Step: 7
Training loss: 3.876387686057052
Validation loss: 3.188250322077304

Epoch: 6| Step: 8
Training loss: 3.739363016564896
Validation loss: 3.1825213364119667

Epoch: 6| Step: 9
Training loss: 3.349223425514654
Validation loss: 3.1778916617517794

Epoch: 6| Step: 10
Training loss: 3.4640705058651005
Validation loss: 3.1761171391134746

Epoch: 6| Step: 11
Training loss: 3.15211729916772
Validation loss: 3.1764028228218786

Epoch: 6| Step: 12
Training loss: 3.205865645841162
Validation loss: 3.1753076560123166

Epoch: 6| Step: 13
Training loss: 4.418918875093568
Validation loss: 3.1738597496356604

Epoch: 70| Step: 0
Training loss: 3.1054057948610896
Validation loss: 3.17496875343518

Epoch: 6| Step: 1
Training loss: 3.373252133484049
Validation loss: 3.1737499053378255

Epoch: 6| Step: 2
Training loss: 3.7099793170856254
Validation loss: 3.172724593615766

Epoch: 6| Step: 3
Training loss: 3.5355975639596404
Validation loss: 3.1731417737115035

Epoch: 6| Step: 4
Training loss: 2.9748095860170753
Validation loss: 3.170627195189259

Epoch: 6| Step: 5
Training loss: 3.4137330059912196
Validation loss: 3.1714640375942813

Epoch: 6| Step: 6
Training loss: 3.6870422079113663
Validation loss: 3.16953507017687

Epoch: 6| Step: 7
Training loss: 3.820601189125881
Validation loss: 3.1721198747546744

Epoch: 6| Step: 8
Training loss: 3.472221218532841
Validation loss: 3.1705795585503966

Epoch: 6| Step: 9
Training loss: 2.1450230324671233
Validation loss: 3.170895535018487

Epoch: 6| Step: 10
Training loss: 3.922019317524912
Validation loss: 3.1697936289856177

Epoch: 6| Step: 11
Training loss: 3.800203097085939
Validation loss: 3.173323387026312

Epoch: 6| Step: 12
Training loss: 3.35000310869215
Validation loss: 3.174212935147382

Epoch: 6| Step: 13
Training loss: 3.0990061181922925
Validation loss: 3.1746974276701247

Epoch: 71| Step: 0
Training loss: 4.271438605364639
Validation loss: 3.1773467590982145

Epoch: 6| Step: 1
Training loss: 3.7654922905167934
Validation loss: 3.1703328416228835

Epoch: 6| Step: 2
Training loss: 2.261334480491533
Validation loss: 3.1676371166279575

Epoch: 6| Step: 3
Training loss: 3.547260549151197
Validation loss: 3.169879959378557

Epoch: 6| Step: 4
Training loss: 3.4249324986843805
Validation loss: 3.166464139056591

Epoch: 6| Step: 5
Training loss: 3.7811074978797494
Validation loss: 3.1667743307268337

Epoch: 6| Step: 6
Training loss: 3.051145719866133
Validation loss: 3.1645717108299602

Epoch: 6| Step: 7
Training loss: 2.401948427998182
Validation loss: 3.1681492194956755

Epoch: 6| Step: 8
Training loss: 3.6338477187636884
Validation loss: 3.166082204131688

Epoch: 6| Step: 9
Training loss: 3.4418846603210884
Validation loss: 3.1639656573664285

Epoch: 6| Step: 10
Training loss: 3.416871754763555
Validation loss: 3.162583718145684

Epoch: 6| Step: 11
Training loss: 3.7686641348045216
Validation loss: 3.164548342406815

Epoch: 6| Step: 12
Training loss: 3.7044726788531106
Validation loss: 3.165119144095979

Epoch: 6| Step: 13
Training loss: 2.287628870601474
Validation loss: 3.1665771902965254

Epoch: 72| Step: 0
Training loss: 2.5283878298246436
Validation loss: 3.16227004125369

Epoch: 6| Step: 1
Training loss: 3.155962184964713
Validation loss: 3.1618946276675066

Epoch: 6| Step: 2
Training loss: 3.5121116885106662
Validation loss: 3.1633824119774716

Epoch: 6| Step: 3
Training loss: 3.341907599714465
Validation loss: 3.1633244159868914

Epoch: 6| Step: 4
Training loss: 3.839053502458486
Validation loss: 3.1638839008904758

Epoch: 6| Step: 5
Training loss: 3.4992007296609837
Validation loss: 3.1622137995081423

Epoch: 6| Step: 6
Training loss: 3.5467819672201513
Validation loss: 3.1599480257813357

Epoch: 6| Step: 7
Training loss: 3.1337922578571273
Validation loss: 3.1608331625780193

Epoch: 6| Step: 8
Training loss: 3.695976213849305
Validation loss: 3.1602393018909227

Epoch: 6| Step: 9
Training loss: 2.5397360509862437
Validation loss: 3.1606377710194473

Epoch: 6| Step: 10
Training loss: 4.0856039520137
Validation loss: 3.161132217234785

Epoch: 6| Step: 11
Training loss: 3.5035036806261717
Validation loss: 3.158912790366183

Epoch: 6| Step: 12
Training loss: 3.72611168267801
Validation loss: 3.1606090914859433

Epoch: 6| Step: 13
Training loss: 3.289777302031317
Validation loss: 3.160603896243099

Epoch: 73| Step: 0
Training loss: 3.4863962375174147
Validation loss: 3.1592871528282895

Epoch: 6| Step: 1
Training loss: 2.7233277290532483
Validation loss: 3.161383076720301

Epoch: 6| Step: 2
Training loss: 3.3474448636950713
Validation loss: 3.1599258449795005

Epoch: 6| Step: 3
Training loss: 4.013853402221049
Validation loss: 3.1592910381046893

Epoch: 6| Step: 4
Training loss: 4.045276222935664
Validation loss: 3.1586183231457254

Epoch: 6| Step: 5
Training loss: 3.2618304387688974
Validation loss: 3.1555897840429323

Epoch: 6| Step: 6
Training loss: 3.4023594467203933
Validation loss: 3.157495332374299

Epoch: 6| Step: 7
Training loss: 3.6373475347597797
Validation loss: 3.1576029613858383

Epoch: 6| Step: 8
Training loss: 3.6579077459332936
Validation loss: 3.1653985256774364

Epoch: 6| Step: 9
Training loss: 3.3719239522157625
Validation loss: 3.1722528659013878

Epoch: 6| Step: 10
Training loss: 3.1642813147717557
Validation loss: 3.1802883083979334

Epoch: 6| Step: 11
Training loss: 3.1114381625825693
Validation loss: 3.1817574968159006

Epoch: 6| Step: 12
Training loss: 2.8014054926179153
Validation loss: 3.182327004196482

Epoch: 6| Step: 13
Training loss: 3.4453329833929085
Validation loss: 3.1764701414245358

Epoch: 74| Step: 0
Training loss: 3.2884990726032894
Validation loss: 3.1710474759506715

Epoch: 6| Step: 1
Training loss: 3.2180171984206445
Validation loss: 3.175169045725973

Epoch: 6| Step: 2
Training loss: 3.615164469120865
Validation loss: 3.178731770216644

Epoch: 6| Step: 3
Training loss: 3.500164845535543
Validation loss: 3.1686064106710794

Epoch: 6| Step: 4
Training loss: 3.2638913165865766
Validation loss: 3.156422712972917

Epoch: 6| Step: 5
Training loss: 2.9178656338979887
Validation loss: 3.1533731389906148

Epoch: 6| Step: 6
Training loss: 2.1316988206734426
Validation loss: 3.149514168943843

Epoch: 6| Step: 7
Training loss: 3.687287922595833
Validation loss: 3.1507514680995077

Epoch: 6| Step: 8
Training loss: 3.9372046223611856
Validation loss: 3.153539458040611

Epoch: 6| Step: 9
Training loss: 3.376386145876519
Validation loss: 3.1518329963370024

Epoch: 6| Step: 10
Training loss: 3.9966039546302325
Validation loss: 3.1530552349980527

Epoch: 6| Step: 11
Training loss: 3.1816076531057034
Validation loss: 3.1502378944588276

Epoch: 6| Step: 12
Training loss: 3.7180552114047085
Validation loss: 3.1487575376388053

Epoch: 6| Step: 13
Training loss: 3.573736039381589
Validation loss: 3.147363535173436

Epoch: 75| Step: 0
Training loss: 3.6604003824831794
Validation loss: 3.1456432571690267

Epoch: 6| Step: 1
Training loss: 3.071188609992785
Validation loss: 3.1526843934995576

Epoch: 6| Step: 2
Training loss: 3.410670920005733
Validation loss: 3.1495267774643403

Epoch: 6| Step: 3
Training loss: 3.650187626026941
Validation loss: 3.1462384404315937

Epoch: 6| Step: 4
Training loss: 3.405351292754242
Validation loss: 3.148766003422269

Epoch: 6| Step: 5
Training loss: 3.2525577750561365
Validation loss: 3.1482338881862693

Epoch: 6| Step: 6
Training loss: 3.5106495554538757
Validation loss: 3.143765113076787

Epoch: 6| Step: 7
Training loss: 3.6530884988101726
Validation loss: 3.1462025479038567

Epoch: 6| Step: 8
Training loss: 2.9692854548983494
Validation loss: 3.1459768569913122

Epoch: 6| Step: 9
Training loss: 3.205577079249654
Validation loss: 3.1456354235583923

Epoch: 6| Step: 10
Training loss: 3.52643006447509
Validation loss: 3.1486157083627893

Epoch: 6| Step: 11
Training loss: 3.389131700610354
Validation loss: 3.1452567660025994

Epoch: 6| Step: 12
Training loss: 3.6783618523397132
Validation loss: 3.1450241200941345

Epoch: 6| Step: 13
Training loss: 2.906228834505842
Validation loss: 3.144376724900842

Testing loss: 3.3189448872329512
