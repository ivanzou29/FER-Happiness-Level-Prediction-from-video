Epoch: 1| Step: 0
Training loss: 7.185349914057851
Validation loss: 5.866264633674004

Epoch: 6| Step: 1
Training loss: 5.1651992354690295
Validation loss: 5.8567276130333825

Epoch: 6| Step: 2
Training loss: 5.819875652125325
Validation loss: 5.847643283724922

Epoch: 6| Step: 3
Training loss: 5.593838312741243
Validation loss: 5.8391352400231575

Epoch: 6| Step: 4
Training loss: 6.1514005973503325
Validation loss: 5.830779095061461

Epoch: 6| Step: 5
Training loss: 6.37496499444663
Validation loss: 5.82221652243872

Epoch: 6| Step: 6
Training loss: 5.022949954470698
Validation loss: 5.813265020293302

Epoch: 6| Step: 7
Training loss: 4.954452962385872
Validation loss: 5.804193481009292

Epoch: 6| Step: 8
Training loss: 5.3476118443988145
Validation loss: 5.794353742035133

Epoch: 6| Step: 9
Training loss: 5.257582502166737
Validation loss: 5.784539222846952

Epoch: 6| Step: 10
Training loss: 5.352779678813335
Validation loss: 5.773895483068637

Epoch: 6| Step: 11
Training loss: 6.206684004407378
Validation loss: 5.762858764593197

Epoch: 6| Step: 12
Training loss: 6.295549352549833
Validation loss: 5.750728758953671

Epoch: 6| Step: 13
Training loss: 7.044177568891227
Validation loss: 5.738582387648035

Epoch: 2| Step: 0
Training loss: 5.297375860699473
Validation loss: 5.724587370478798

Epoch: 6| Step: 1
Training loss: 6.185495996100348
Validation loss: 5.710509362502676

Epoch: 6| Step: 2
Training loss: 5.843431433495969
Validation loss: 5.69560443712815

Epoch: 6| Step: 3
Training loss: 6.824827467306122
Validation loss: 5.679299490886603

Epoch: 6| Step: 4
Training loss: 5.3580939983510945
Validation loss: 5.663004958251576

Epoch: 6| Step: 5
Training loss: 4.782660382259151
Validation loss: 5.64506137460631

Epoch: 6| Step: 6
Training loss: 6.063234265094659
Validation loss: 5.626129839055403

Epoch: 6| Step: 7
Training loss: 6.192279857531019
Validation loss: 5.606323095673206

Epoch: 6| Step: 8
Training loss: 6.486636877249637
Validation loss: 5.586585460359186

Epoch: 6| Step: 9
Training loss: 5.658700317407396
Validation loss: 5.56244357519324

Epoch: 6| Step: 10
Training loss: 4.5999817391738
Validation loss: 5.539364334260584

Epoch: 6| Step: 11
Training loss: 4.093150553603883
Validation loss: 5.513761624700074

Epoch: 6| Step: 12
Training loss: 5.566978794568013
Validation loss: 5.487972493530312

Epoch: 6| Step: 13
Training loss: 5.420510595841401
Validation loss: 5.462438808988348

Epoch: 3| Step: 0
Training loss: 6.286613944929188
Validation loss: 5.434469100363027

Epoch: 6| Step: 1
Training loss: 4.867437708318449
Validation loss: 5.4047968576705685

Epoch: 6| Step: 2
Training loss: 5.715598316662188
Validation loss: 5.374053911878953

Epoch: 6| Step: 3
Training loss: 5.805365993846535
Validation loss: 5.343396743950767

Epoch: 6| Step: 4
Training loss: 4.936935972036926
Validation loss: 5.313082998523091

Epoch: 6| Step: 5
Training loss: 4.869617718804518
Validation loss: 5.279692210694471

Epoch: 6| Step: 6
Training loss: 5.035683520685927
Validation loss: 5.24903360897833

Epoch: 6| Step: 7
Training loss: 6.164198029047136
Validation loss: 5.2183227560671

Epoch: 6| Step: 8
Training loss: 4.00459740604739
Validation loss: 5.186551124520989

Epoch: 6| Step: 9
Training loss: 5.430440068405861
Validation loss: 5.156195762152627

Epoch: 6| Step: 10
Training loss: 5.334572032290894
Validation loss: 5.123088893529082

Epoch: 6| Step: 11
Training loss: 5.456688708379492
Validation loss: 5.092248246943716

Epoch: 6| Step: 12
Training loss: 5.025562934278755
Validation loss: 5.0647491761740335

Epoch: 6| Step: 13
Training loss: 4.3126494893134755
Validation loss: 5.039546576044997

Epoch: 4| Step: 0
Training loss: 5.9493437845938235
Validation loss: 5.014801443351662

Epoch: 6| Step: 1
Training loss: 5.849079170462132
Validation loss: 4.991209864011107

Epoch: 6| Step: 2
Training loss: 4.35355812212883
Validation loss: 4.97082045676304

Epoch: 6| Step: 3
Training loss: 4.583376843795012
Validation loss: 4.949501103939645

Epoch: 6| Step: 4
Training loss: 4.415321481131162
Validation loss: 4.927023830322047

Epoch: 6| Step: 5
Training loss: 4.983145535267777
Validation loss: 4.905136388540536

Epoch: 6| Step: 6
Training loss: 5.8690616545227945
Validation loss: 4.883683837325542

Epoch: 6| Step: 7
Training loss: 5.09072917459304
Validation loss: 4.861396165841118

Epoch: 6| Step: 8
Training loss: 3.919402418325077
Validation loss: 4.83472082755281

Epoch: 6| Step: 9
Training loss: 4.546785229193277
Validation loss: 4.806991108952805

Epoch: 6| Step: 10
Training loss: 2.9018215772487674
Validation loss: 4.778277598201991

Epoch: 6| Step: 11
Training loss: 5.439686653425101
Validation loss: 4.746771049035046

Epoch: 6| Step: 12
Training loss: 5.3004201542562175
Validation loss: 4.710163547343116

Epoch: 6| Step: 13
Training loss: 5.333155072729946
Validation loss: 4.676691044281888

Epoch: 5| Step: 0
Training loss: 5.231853914210399
Validation loss: 4.644301787205319

Epoch: 6| Step: 1
Training loss: 4.61810613746317
Validation loss: 4.611069336881629

Epoch: 6| Step: 2
Training loss: 4.730650188768569
Validation loss: 4.579150073825062

Epoch: 6| Step: 3
Training loss: 5.467702013146422
Validation loss: 4.546502240181648

Epoch: 6| Step: 4
Training loss: 5.618845645824555
Validation loss: 4.5171498902027585

Epoch: 6| Step: 5
Training loss: 4.701023379977151
Validation loss: 4.488563696853184

Epoch: 6| Step: 6
Training loss: 4.546569604219826
Validation loss: 4.461394554656616

Epoch: 6| Step: 7
Training loss: 3.9377635080477473
Validation loss: 4.434148247951849

Epoch: 6| Step: 8
Training loss: 4.1839397725425815
Validation loss: 4.411977379020169

Epoch: 6| Step: 9
Training loss: 4.224992442829664
Validation loss: 4.393525584740864

Epoch: 6| Step: 10
Training loss: 3.7508721926787305
Validation loss: 4.37440857295694

Epoch: 6| Step: 11
Training loss: 4.489175705722121
Validation loss: 4.35666659895109

Epoch: 6| Step: 12
Training loss: 3.877418993577791
Validation loss: 4.341233989737465

Epoch: 6| Step: 13
Training loss: 4.054676915855044
Validation loss: 4.322629712046249

Epoch: 6| Step: 0
Training loss: 4.928440716196798
Validation loss: 4.309724180409863

Epoch: 6| Step: 1
Training loss: 4.4444330347762415
Validation loss: 4.28853819703739

Epoch: 6| Step: 2
Training loss: 4.897222876348876
Validation loss: 4.270595609750301

Epoch: 6| Step: 3
Training loss: 4.1900403871615515
Validation loss: 4.252964591542418

Epoch: 6| Step: 4
Training loss: 3.8374747558161055
Validation loss: 4.237867406536417

Epoch: 6| Step: 5
Training loss: 2.991120549105674
Validation loss: 4.22506755423647

Epoch: 6| Step: 6
Training loss: 4.45407961601834
Validation loss: 4.208255991696638

Epoch: 6| Step: 7
Training loss: 4.09006573239508
Validation loss: 4.1955371658354546

Epoch: 6| Step: 8
Training loss: 3.9042233512180484
Validation loss: 4.178343746313805

Epoch: 6| Step: 9
Training loss: 3.8945905093598356
Validation loss: 4.165148806002846

Epoch: 6| Step: 10
Training loss: 4.409076190126657
Validation loss: 4.151786371888233

Epoch: 6| Step: 11
Training loss: 5.315936245067381
Validation loss: 4.1359180582396915

Epoch: 6| Step: 12
Training loss: 4.012989411260959
Validation loss: 4.117469040888346

Epoch: 6| Step: 13
Training loss: 5.1371295953213
Validation loss: 4.106043811350718

Epoch: 7| Step: 0
Training loss: 3.761421865312709
Validation loss: 4.096388990048212

Epoch: 6| Step: 1
Training loss: 2.997370839394508
Validation loss: 4.080278799016677

Epoch: 6| Step: 2
Training loss: 5.060248545396414
Validation loss: 4.068546943530548

Epoch: 6| Step: 3
Training loss: 3.248213056670304
Validation loss: 4.054574062323792

Epoch: 6| Step: 4
Training loss: 3.067261089544003
Validation loss: 4.043427264759478

Epoch: 6| Step: 5
Training loss: 4.758352465126249
Validation loss: 4.036174275078563

Epoch: 6| Step: 6
Training loss: 4.597317717995495
Validation loss: 4.025156789742496

Epoch: 6| Step: 7
Training loss: 4.537284253248345
Validation loss: 4.015277171880525

Epoch: 6| Step: 8
Training loss: 4.039538947509637
Validation loss: 4.001356770258015

Epoch: 6| Step: 9
Training loss: 4.792188311944625
Validation loss: 3.991522137847015

Epoch: 6| Step: 10
Training loss: 4.257583584012593
Validation loss: 3.9850315827787592

Epoch: 6| Step: 11
Training loss: 4.62002625957474
Validation loss: 3.971064417163987

Epoch: 6| Step: 12
Training loss: 3.981047553599861
Validation loss: 3.9629382775291715

Epoch: 6| Step: 13
Training loss: 3.7427132064033097
Validation loss: 3.964080419913034

Epoch: 8| Step: 0
Training loss: 3.975505935812285
Validation loss: 3.957671892032007

Epoch: 6| Step: 1
Training loss: 4.554291748860654
Validation loss: 3.951122017255806

Epoch: 6| Step: 2
Training loss: 4.25077319124282
Validation loss: 3.931557162550516

Epoch: 6| Step: 3
Training loss: 3.5987267573812813
Validation loss: 3.9345528491321247

Epoch: 6| Step: 4
Training loss: 3.2746964175625908
Validation loss: 3.918706095022794

Epoch: 6| Step: 5
Training loss: 3.9579848018930797
Validation loss: 3.913002765895125

Epoch: 6| Step: 6
Training loss: 4.754861050891104
Validation loss: 3.9141410001200954

Epoch: 6| Step: 7
Training loss: 3.4242814194281577
Validation loss: 3.9076165395989815

Epoch: 6| Step: 8
Training loss: 4.921297941742248
Validation loss: 3.9032817104515627

Epoch: 6| Step: 9
Training loss: 4.993385517440172
Validation loss: 3.8931975784800943

Epoch: 6| Step: 10
Training loss: 3.595852178978775
Validation loss: 3.890446437034837

Epoch: 6| Step: 11
Training loss: 4.076406299410192
Validation loss: 3.8887348205080494

Epoch: 6| Step: 12
Training loss: 3.629036070572139
Validation loss: 3.884061343012312

Epoch: 6| Step: 13
Training loss: 2.9588670562551127
Validation loss: 3.8740056800208347

Epoch: 9| Step: 0
Training loss: 3.091236519172912
Validation loss: 3.866629594318208

Epoch: 6| Step: 1
Training loss: 3.9019532032110313
Validation loss: 3.8627050264456777

Epoch: 6| Step: 2
Training loss: 4.369222695641792
Validation loss: 3.85773548143753

Epoch: 6| Step: 3
Training loss: 3.828496673602467
Validation loss: 3.847855920161835

Epoch: 6| Step: 4
Training loss: 3.9677250056652182
Validation loss: 3.843444450580129

Epoch: 6| Step: 5
Training loss: 3.1253080597670406
Validation loss: 3.8412499629930754

Epoch: 6| Step: 6
Training loss: 3.8517179941355595
Validation loss: 3.8342251473683153

Epoch: 6| Step: 7
Training loss: 3.9095231647910205
Validation loss: 3.8264937949631572

Epoch: 6| Step: 8
Training loss: 3.5628206878345856
Validation loss: 3.815063492920977

Epoch: 6| Step: 9
Training loss: 3.856620021484137
Validation loss: 3.8071321340908426

Epoch: 6| Step: 10
Training loss: 4.839456341057532
Validation loss: 3.8032423144575804

Epoch: 6| Step: 11
Training loss: 5.3229013381806976
Validation loss: 3.803711173394422

Epoch: 6| Step: 12
Training loss: 4.125464210977316
Validation loss: 3.789221242208185

Epoch: 6| Step: 13
Training loss: 3.369654767155961
Validation loss: 3.794472873100219

Epoch: 10| Step: 0
Training loss: 3.1436529792997594
Validation loss: 3.7925467314405568

Epoch: 6| Step: 1
Training loss: 4.6654512775474295
Validation loss: 3.7921848549286805

Epoch: 6| Step: 2
Training loss: 5.095062086870716
Validation loss: 3.782843244376789

Epoch: 6| Step: 3
Training loss: 2.7469581773682776
Validation loss: 3.773700754948485

Epoch: 6| Step: 4
Training loss: 4.202523454354468
Validation loss: 3.7747643339954298

Epoch: 6| Step: 5
Training loss: 3.981756569150927
Validation loss: 3.7606120570813872

Epoch: 6| Step: 6
Training loss: 4.011132246638649
Validation loss: 3.7526565343951943

Epoch: 6| Step: 7
Training loss: 4.598329506116995
Validation loss: 3.7470857733872345

Epoch: 6| Step: 8
Training loss: 3.8466537796236575
Validation loss: 3.744402328808495

Epoch: 6| Step: 9
Training loss: 3.7461655404030823
Validation loss: 3.734834623256137

Epoch: 6| Step: 10
Training loss: 3.8927713012230103
Validation loss: 3.7252802576905437

Epoch: 6| Step: 11
Training loss: 3.5929390697244563
Validation loss: 3.7173781159662234

Epoch: 6| Step: 12
Training loss: 3.6992594828472827
Validation loss: 3.7112434078913394

Epoch: 6| Step: 13
Training loss: 2.44973763987941
Validation loss: 3.7015917603128434

Epoch: 11| Step: 0
Training loss: 3.8157307428177596
Validation loss: 3.7073032948371414

Epoch: 6| Step: 1
Training loss: 3.503480815257303
Validation loss: 3.690292449584062

Epoch: 6| Step: 2
Training loss: 4.552971073185258
Validation loss: 3.691390943433092

Epoch: 6| Step: 3
Training loss: 3.9437969658378034
Validation loss: 3.68794532563253

Epoch: 6| Step: 4
Training loss: 3.3404884474619805
Validation loss: 3.6891416090512217

Epoch: 6| Step: 5
Training loss: 5.11718526359684
Validation loss: 3.6851096744278444

Epoch: 6| Step: 6
Training loss: 4.497614334120516
Validation loss: 3.6769192515590103

Epoch: 6| Step: 7
Training loss: 3.1385609690852014
Validation loss: 3.672238881921526

Epoch: 6| Step: 8
Training loss: 4.151850846068299
Validation loss: 3.66369103948806

Epoch: 6| Step: 9
Training loss: 3.288094203611157
Validation loss: 3.664005092891183

Epoch: 6| Step: 10
Training loss: 4.403596985687214
Validation loss: 3.661598275826375

Epoch: 6| Step: 11
Training loss: 2.72499069772235
Validation loss: 3.6619775345891576

Epoch: 6| Step: 12
Training loss: 3.574045312561137
Validation loss: 3.6663027934267975

Epoch: 6| Step: 13
Training loss: 2.8913751402085506
Validation loss: 3.6535329456226884

Epoch: 12| Step: 0
Training loss: 3.6093403868233462
Validation loss: 3.6518868874427377

Epoch: 6| Step: 1
Training loss: 4.046742087284053
Validation loss: 3.643996890657091

Epoch: 6| Step: 2
Training loss: 3.663515094786897
Validation loss: 3.6352535025135944

Epoch: 6| Step: 3
Training loss: 3.580066404099744
Validation loss: 3.6274549652934085

Epoch: 6| Step: 4
Training loss: 4.014322151169986
Validation loss: 3.6292032209299077

Epoch: 6| Step: 5
Training loss: 3.6317618871013626
Validation loss: 3.6346166263813444

Epoch: 6| Step: 6
Training loss: 3.5914528844335347
Validation loss: 3.6118600820102036

Epoch: 6| Step: 7
Training loss: 3.781620102101565
Validation loss: 3.6056286399490083

Epoch: 6| Step: 8
Training loss: 3.4784716218353102
Validation loss: 3.6051219964134202

Epoch: 6| Step: 9
Training loss: 4.116717027569785
Validation loss: 3.6015116647717527

Epoch: 6| Step: 10
Training loss: 3.7993161238613986
Validation loss: 3.598651589704316

Epoch: 6| Step: 11
Training loss: 4.230273974047995
Validation loss: 3.595380414485764

Epoch: 6| Step: 12
Training loss: 3.8826514964811665
Validation loss: 3.589568259611344

Epoch: 6| Step: 13
Training loss: 3.8799885049630003
Validation loss: 3.584878627419147

Epoch: 13| Step: 0
Training loss: 3.2047098844389037
Validation loss: 3.5801339949564515

Epoch: 6| Step: 1
Training loss: 2.892756155898771
Validation loss: 3.576682929017217

Epoch: 6| Step: 2
Training loss: 3.322443594586518
Validation loss: 3.5720591134689172

Epoch: 6| Step: 3
Training loss: 4.523303621251221
Validation loss: 3.5707308982562904

Epoch: 6| Step: 4
Training loss: 4.847369607447534
Validation loss: 3.5651283786777603

Epoch: 6| Step: 5
Training loss: 3.84575966502368
Validation loss: 3.560397803233094

Epoch: 6| Step: 6
Training loss: 3.0339428453487343
Validation loss: 3.556033155232066

Epoch: 6| Step: 7
Training loss: 4.347240116189536
Validation loss: 3.553949517514548

Epoch: 6| Step: 8
Training loss: 3.6385421361230343
Validation loss: 3.5483781886245316

Epoch: 6| Step: 9
Training loss: 3.6914791039437724
Validation loss: 3.5473042236924397

Epoch: 6| Step: 10
Training loss: 4.157021357727611
Validation loss: 3.5440761995566485

Epoch: 6| Step: 11
Training loss: 3.3978842098542232
Validation loss: 3.5419195737544356

Epoch: 6| Step: 12
Training loss: 3.319270717769094
Validation loss: 3.5391858662586446

Epoch: 6| Step: 13
Training loss: 3.929122247104362
Validation loss: 3.535606573966399

Epoch: 14| Step: 0
Training loss: 3.789766918654694
Validation loss: 3.533444564002677

Epoch: 6| Step: 1
Training loss: 3.3433138839242167
Validation loss: 3.531002970019121

Epoch: 6| Step: 2
Training loss: 3.8319424026875257
Validation loss: 3.529168960026798

Epoch: 6| Step: 3
Training loss: 3.238755213307433
Validation loss: 3.524857691610294

Epoch: 6| Step: 4
Training loss: 3.466394948091926
Validation loss: 3.5257967929032095

Epoch: 6| Step: 5
Training loss: 3.752278335194892
Validation loss: 3.5208676962654004

Epoch: 6| Step: 6
Training loss: 4.135761903177623
Validation loss: 3.5176143611691306

Epoch: 6| Step: 7
Training loss: 2.8359640661419254
Validation loss: 3.5163940317784568

Epoch: 6| Step: 8
Training loss: 4.062275337462787
Validation loss: 3.5135306325770914

Epoch: 6| Step: 9
Training loss: 3.0009511393529373
Validation loss: 3.5125485715199907

Epoch: 6| Step: 10
Training loss: 2.9836197941101115
Validation loss: 3.507538013036065

Epoch: 6| Step: 11
Training loss: 4.66138436313808
Validation loss: 3.507727391488352

Epoch: 6| Step: 12
Training loss: 4.6302631433573405
Validation loss: 3.506324637973109

Epoch: 6| Step: 13
Training loss: 3.993414464475608
Validation loss: 3.5014026763934782

Epoch: 15| Step: 0
Training loss: 3.702727606330848
Validation loss: 3.503020427705079

Epoch: 6| Step: 1
Training loss: 3.3548093065625113
Validation loss: 3.5020769537280847

Epoch: 6| Step: 2
Training loss: 3.9315012695357026
Validation loss: 3.4956125162500893

Epoch: 6| Step: 3
Training loss: 4.145103249730667
Validation loss: 3.495356123166753

Epoch: 6| Step: 4
Training loss: 3.5232255622407656
Validation loss: 3.493788444411283

Epoch: 6| Step: 5
Training loss: 3.4823646390942833
Validation loss: 3.4892017849547887

Epoch: 6| Step: 6
Training loss: 3.4659616071244277
Validation loss: 3.489060479219615

Epoch: 6| Step: 7
Training loss: 3.908896930349682
Validation loss: 3.489762529753407

Epoch: 6| Step: 8
Training loss: 3.298141019463106
Validation loss: 3.4853421210031588

Epoch: 6| Step: 9
Training loss: 4.599374662270464
Validation loss: 3.4844037310504983

Epoch: 6| Step: 10
Training loss: 4.180046165977958
Validation loss: 3.4830053171983764

Epoch: 6| Step: 11
Training loss: 3.6007689555465827
Validation loss: 3.480887190180435

Epoch: 6| Step: 12
Training loss: 2.9824170785202098
Validation loss: 3.4763811846511397

Epoch: 6| Step: 13
Training loss: 3.087469797334167
Validation loss: 3.4731761036142736

Epoch: 16| Step: 0
Training loss: 3.049327626142789
Validation loss: 3.472169938271497

Epoch: 6| Step: 1
Training loss: 3.7135143448447425
Validation loss: 3.4697637890002864

Epoch: 6| Step: 2
Training loss: 3.161978329540216
Validation loss: 3.469908472343298

Epoch: 6| Step: 3
Training loss: 3.958117442350462
Validation loss: 3.468446566971715

Epoch: 6| Step: 4
Training loss: 3.3482424780249103
Validation loss: 3.4681384430600426

Epoch: 6| Step: 5
Training loss: 3.4966141808870574
Validation loss: 3.4647261881282967

Epoch: 6| Step: 6
Training loss: 4.700773240460291
Validation loss: 3.463589929945588

Epoch: 6| Step: 7
Training loss: 3.3542800947324682
Validation loss: 3.4596968739024243

Epoch: 6| Step: 8
Training loss: 3.525619474047256
Validation loss: 3.457883234505668

Epoch: 6| Step: 9
Training loss: 4.534978345590054
Validation loss: 3.4568364021661275

Epoch: 6| Step: 10
Training loss: 3.3804985748590433
Validation loss: 3.4532920118821187

Epoch: 6| Step: 11
Training loss: 3.28244810483168
Validation loss: 3.4517172904105555

Epoch: 6| Step: 12
Training loss: 3.7229909356124993
Validation loss: 3.4505290961635824

Epoch: 6| Step: 13
Training loss: 4.011641251837864
Validation loss: 3.446031402558698

Epoch: 17| Step: 0
Training loss: 3.342633355047612
Validation loss: 3.4470599841760565

Epoch: 6| Step: 1
Training loss: 3.401789693468911
Validation loss: 3.4438161328738612

Epoch: 6| Step: 2
Training loss: 4.142663533051084
Validation loss: 3.44224509305892

Epoch: 6| Step: 3
Training loss: 2.547496789962049
Validation loss: 3.440502288314912

Epoch: 6| Step: 4
Training loss: 4.638026270862314
Validation loss: 3.437822096007761

Epoch: 6| Step: 5
Training loss: 2.665599927527162
Validation loss: 3.4348414114179056

Epoch: 6| Step: 6
Training loss: 3.8614488967740415
Validation loss: 3.435095465688044

Epoch: 6| Step: 7
Training loss: 3.6688076762096222
Validation loss: 3.432564223673287

Epoch: 6| Step: 8
Training loss: 2.7452854144302283
Validation loss: 3.4337853990888534

Epoch: 6| Step: 9
Training loss: 4.478029020868798
Validation loss: 3.431365616799068

Epoch: 6| Step: 10
Training loss: 4.1007574544758745
Validation loss: 3.4309288945909127

Epoch: 6| Step: 11
Training loss: 3.75834109579724
Validation loss: 3.4286056136332936

Epoch: 6| Step: 12
Training loss: 3.68427316461821
Validation loss: 3.4264779562172865

Epoch: 6| Step: 13
Training loss: 3.314087109651967
Validation loss: 3.424303046802703

Epoch: 18| Step: 0
Training loss: 3.144644219874847
Validation loss: 3.431563019554203

Epoch: 6| Step: 1
Training loss: 4.33603295573418
Validation loss: 3.4305236292034826

Epoch: 6| Step: 2
Training loss: 4.694813427290314
Validation loss: 3.4233230371667163

Epoch: 6| Step: 3
Training loss: 3.3830828481571533
Validation loss: 3.420524447147765

Epoch: 6| Step: 4
Training loss: 3.8203162444862784
Validation loss: 3.4194359610112097

Epoch: 6| Step: 5
Training loss: 3.2438406165370712
Validation loss: 3.4178666226881917

Epoch: 6| Step: 6
Training loss: 3.0324270578340355
Validation loss: 3.4171479504207007

Epoch: 6| Step: 7
Training loss: 4.075574523117133
Validation loss: 3.4139321612242792

Epoch: 6| Step: 8
Training loss: 3.4159726314118335
Validation loss: 3.416256911295308

Epoch: 6| Step: 9
Training loss: 2.8405394823485994
Validation loss: 3.4179315294152355

Epoch: 6| Step: 10
Training loss: 3.8820360355267094
Validation loss: 3.415150430265279

Epoch: 6| Step: 11
Training loss: 3.699334631195455
Validation loss: 3.412773793378859

Epoch: 6| Step: 12
Training loss: 3.2087382932121735
Validation loss: 3.4078352115394854

Epoch: 6| Step: 13
Training loss: 3.8224707125932063
Validation loss: 3.404148738802479

Epoch: 19| Step: 0
Training loss: 3.451276603797912
Validation loss: 3.402975844399767

Epoch: 6| Step: 1
Training loss: 3.7401346776040314
Validation loss: 3.399554560760458

Epoch: 6| Step: 2
Training loss: 4.709910013428572
Validation loss: 3.3969870446457775

Epoch: 6| Step: 3
Training loss: 3.907459529537777
Validation loss: 3.3980712346249438

Epoch: 6| Step: 4
Training loss: 2.1061367468566616
Validation loss: 3.3961753987489156

Epoch: 6| Step: 5
Training loss: 4.169971274590294
Validation loss: 3.402683133239216

Epoch: 6| Step: 6
Training loss: 4.2131083878293065
Validation loss: 3.391359822246441

Epoch: 6| Step: 7
Training loss: 3.219695017332957
Validation loss: 3.388143595547638

Epoch: 6| Step: 8
Training loss: 2.4373245176090492
Validation loss: 3.3876242014084146

Epoch: 6| Step: 9
Training loss: 3.5257668925761574
Validation loss: 3.391910122488546

Epoch: 6| Step: 10
Training loss: 2.5594619792089817
Validation loss: 3.3879933864953524

Epoch: 6| Step: 11
Training loss: 4.106163946030963
Validation loss: 3.3893784980672446

Epoch: 6| Step: 12
Training loss: 3.8959035340102397
Validation loss: 3.379731638580353

Epoch: 6| Step: 13
Training loss: 3.7244415325400237
Validation loss: 3.3791472181740683

Epoch: 20| Step: 0
Training loss: 4.092310528619069
Validation loss: 3.3787517098053392

Epoch: 6| Step: 1
Training loss: 2.4944221260056003
Validation loss: 3.378504988211625

Epoch: 6| Step: 2
Training loss: 3.7473398310029205
Validation loss: 3.380640855686402

Epoch: 6| Step: 3
Training loss: 3.60933589501273
Validation loss: 3.378082433306419

Epoch: 6| Step: 4
Training loss: 3.4098038638808417
Validation loss: 3.376155330417446

Epoch: 6| Step: 5
Training loss: 3.7530005848104264
Validation loss: 3.3737919923186275

Epoch: 6| Step: 6
Training loss: 4.010865950085551
Validation loss: 3.3699282294403363

Epoch: 6| Step: 7
Training loss: 3.7666500485033945
Validation loss: 3.366763271097951

Epoch: 6| Step: 8
Training loss: 3.289793680788843
Validation loss: 3.366253375544713

Epoch: 6| Step: 9
Training loss: 3.641995151698799
Validation loss: 3.3661712878620866

Epoch: 6| Step: 10
Training loss: 3.193231702579671
Validation loss: 3.3649748344524415

Epoch: 6| Step: 11
Training loss: 3.9609934785938967
Validation loss: 3.3643632869729885

Epoch: 6| Step: 12
Training loss: 3.995437642786765
Validation loss: 3.359012797337816

Epoch: 6| Step: 13
Training loss: 2.780956467129666
Validation loss: 3.3569971634529585

Epoch: 21| Step: 0
Training loss: 4.55093527602807
Validation loss: 3.3588018738816454

Epoch: 6| Step: 1
Training loss: 3.7049223968162495
Validation loss: 3.3538611890828083

Epoch: 6| Step: 2
Training loss: 3.578294774987676
Validation loss: 3.351760179571291

Epoch: 6| Step: 3
Training loss: 3.1055859045806447
Validation loss: 3.3480301363650113

Epoch: 6| Step: 4
Training loss: 3.851297551263618
Validation loss: 3.346722287416621

Epoch: 6| Step: 5
Training loss: 3.3323978700892236
Validation loss: 3.341713888895271

Epoch: 6| Step: 6
Training loss: 3.4683147535387064
Validation loss: 3.34443694602509

Epoch: 6| Step: 7
Training loss: 3.1625151441611057
Validation loss: 3.335428322254944

Epoch: 6| Step: 8
Training loss: 4.452356104809363
Validation loss: 3.3375297793011187

Epoch: 6| Step: 9
Training loss: 3.0256544555919724
Validation loss: 3.3288477516738557

Epoch: 6| Step: 10
Training loss: 2.3134314233539586
Validation loss: 3.3341798558576747

Epoch: 6| Step: 11
Training loss: 3.332162476579542
Validation loss: 3.336570975276667

Epoch: 6| Step: 12
Training loss: 4.472259423921917
Validation loss: 3.3347969600168352

Epoch: 6| Step: 13
Training loss: 2.5545494672249482
Validation loss: 3.3269667288412497

Epoch: 22| Step: 0
Training loss: 4.083058847556854
Validation loss: 3.3239799737564084

Epoch: 6| Step: 1
Training loss: 3.7472636093695715
Validation loss: 3.3279957595759035

Epoch: 6| Step: 2
Training loss: 3.218529999260553
Validation loss: 3.3262888632544496

Epoch: 6| Step: 3
Training loss: 4.362253421493309
Validation loss: 3.3249695866480136

Epoch: 6| Step: 4
Training loss: 3.1764466361678223
Validation loss: 3.319306559276202

Epoch: 6| Step: 5
Training loss: 3.596868339684863
Validation loss: 3.3186754045306115

Epoch: 6| Step: 6
Training loss: 3.2751378852995807
Validation loss: 3.31520416513908

Epoch: 6| Step: 7
Training loss: 2.6399062944890415
Validation loss: 3.3154138715016006

Epoch: 6| Step: 8
Training loss: 4.015462552952045
Validation loss: 3.3102520686706054

Epoch: 6| Step: 9
Training loss: 3.785385896469853
Validation loss: 3.311106007154463

Epoch: 6| Step: 10
Training loss: 4.338826194979944
Validation loss: 3.3114063069502775

Epoch: 6| Step: 11
Training loss: 2.5173612490832995
Validation loss: 3.3108562710525176

Epoch: 6| Step: 12
Training loss: 3.381741607522495
Validation loss: 3.3105122458327183

Epoch: 6| Step: 13
Training loss: 2.6613138735708888
Validation loss: 3.309638962758819

Epoch: 23| Step: 0
Training loss: 2.901454455572872
Validation loss: 3.308623833916707

Epoch: 6| Step: 1
Training loss: 4.244036810597551
Validation loss: 3.308573974398406

Epoch: 6| Step: 2
Training loss: 2.794492761924381
Validation loss: 3.30797145847392

Epoch: 6| Step: 3
Training loss: 3.8291349363344116
Validation loss: 3.30515200883129

Epoch: 6| Step: 4
Training loss: 4.019806462274101
Validation loss: 3.302903533327698

Epoch: 6| Step: 5
Training loss: 3.8758888455761626
Validation loss: 3.303093225752374

Epoch: 6| Step: 6
Training loss: 4.191841721465908
Validation loss: 3.308475037276941

Epoch: 6| Step: 7
Training loss: 2.4949986020927106
Validation loss: 3.3045453593002247

Epoch: 6| Step: 8
Training loss: 4.193908342763346
Validation loss: 3.3048000575919185

Epoch: 6| Step: 9
Training loss: 3.000512079403691
Validation loss: 3.3012873047660793

Epoch: 6| Step: 10
Training loss: 2.6373868872807957
Validation loss: 3.298726716418401

Epoch: 6| Step: 11
Training loss: 4.042208186311583
Validation loss: 3.298390095417525

Epoch: 6| Step: 12
Training loss: 3.0371536496973803
Validation loss: 3.298634700867103

Epoch: 6| Step: 13
Training loss: 3.691264154837881
Validation loss: 3.2973685164209665

Epoch: 24| Step: 0
Training loss: 3.5014806068032613
Validation loss: 3.2959709994563715

Epoch: 6| Step: 1
Training loss: 3.3187144304513803
Validation loss: 3.2959079472060138

Epoch: 6| Step: 2
Training loss: 3.0123489848547056
Validation loss: 3.2951124610427334

Epoch: 6| Step: 3
Training loss: 2.756891458825877
Validation loss: 3.294063879546545

Epoch: 6| Step: 4
Training loss: 3.759459707521876
Validation loss: 3.2932435092365018

Epoch: 6| Step: 5
Training loss: 3.5261128285532073
Validation loss: 3.2942920234553457

Epoch: 6| Step: 6
Training loss: 3.247046081911472
Validation loss: 3.2943144995490616

Epoch: 6| Step: 7
Training loss: 3.8264202448180744
Validation loss: 3.2926766769852014

Epoch: 6| Step: 8
Training loss: 4.053519314046215
Validation loss: 3.2893903833538003

Epoch: 6| Step: 9
Training loss: 2.9624386809236105
Validation loss: 3.2916879187246137

Epoch: 6| Step: 10
Training loss: 4.369988759460658
Validation loss: 3.291986089099011

Epoch: 6| Step: 11
Training loss: 3.3045849074002147
Validation loss: 3.2898416056029762

Epoch: 6| Step: 12
Training loss: 4.177229399121008
Validation loss: 3.2922613609584115

Epoch: 6| Step: 13
Training loss: 3.133030453375349
Validation loss: 3.2935872303933382

Epoch: 25| Step: 0
Training loss: 3.939374689353024
Validation loss: 3.2955959933788663

Epoch: 6| Step: 1
Training loss: 2.3572663237698026
Validation loss: 3.3001184815435396

Epoch: 6| Step: 2
Training loss: 3.730397424465389
Validation loss: 3.317891014446362

Epoch: 6| Step: 3
Training loss: 3.6444526165066824
Validation loss: 3.306967787241254

Epoch: 6| Step: 4
Training loss: 3.531651836926401
Validation loss: 3.2911846658989217

Epoch: 6| Step: 5
Training loss: 3.631528040734992
Validation loss: 3.2870703045311243

Epoch: 6| Step: 6
Training loss: 3.6257691718313154
Validation loss: 3.2884087338953183

Epoch: 6| Step: 7
Training loss: 3.367147564927772
Validation loss: 3.2897159304491983

Epoch: 6| Step: 8
Training loss: 3.70507297706548
Validation loss: 3.2910079582541076

Epoch: 6| Step: 9
Training loss: 3.327177817369182
Validation loss: 3.289016729160169

Epoch: 6| Step: 10
Training loss: 3.827671319975717
Validation loss: 3.2866329247302812

Epoch: 6| Step: 11
Training loss: 2.5575097037063226
Validation loss: 3.2857044819875583

Epoch: 6| Step: 12
Training loss: 3.9454808567497834
Validation loss: 3.2843741424491677

Epoch: 6| Step: 13
Training loss: 4.186350878288567
Validation loss: 3.286125844290332

Epoch: 26| Step: 0
Training loss: 3.4099112616036975
Validation loss: 3.2844684479702138

Epoch: 6| Step: 1
Training loss: 3.316444495601762
Validation loss: 3.2825738957933175

Epoch: 6| Step: 2
Training loss: 4.082350839762091
Validation loss: 3.2817417899349626

Epoch: 6| Step: 3
Training loss: 3.2437763778995827
Validation loss: 3.27933485294029

Epoch: 6| Step: 4
Training loss: 3.445299075007503
Validation loss: 3.280437875653233

Epoch: 6| Step: 5
Training loss: 3.3197517908911505
Validation loss: 3.2802029002981254

Epoch: 6| Step: 6
Training loss: 3.0424299632328036
Validation loss: 3.2794190767174736

Epoch: 6| Step: 7
Training loss: 3.7652126735485716
Validation loss: 3.278938406618007

Epoch: 6| Step: 8
Training loss: 3.8495751877287137
Validation loss: 3.276517282639955

Epoch: 6| Step: 9
Training loss: 3.8606131725800164
Validation loss: 3.27631447558023

Epoch: 6| Step: 10
Training loss: 3.453835254656567
Validation loss: 3.2761059356999906

Epoch: 6| Step: 11
Training loss: 3.5661840296492264
Validation loss: 3.2743406759788543

Epoch: 6| Step: 12
Training loss: 3.6843035793742938
Validation loss: 3.2738910618975683

Epoch: 6| Step: 13
Training loss: 2.886353341850868
Validation loss: 3.271896276328328

Epoch: 27| Step: 0
Training loss: 3.007968967876255
Validation loss: 3.2717399513744008

Epoch: 6| Step: 1
Training loss: 3.3418229869578173
Validation loss: 3.2738478008899086

Epoch: 6| Step: 2
Training loss: 3.805049056590346
Validation loss: 3.272390468489127

Epoch: 6| Step: 3
Training loss: 3.365271782293545
Validation loss: 3.2708371671005323

Epoch: 6| Step: 4
Training loss: 2.513444038030688
Validation loss: 3.2723991189490143

Epoch: 6| Step: 5
Training loss: 3.143763098869564
Validation loss: 3.2698355012844433

Epoch: 6| Step: 6
Training loss: 3.740350897744333
Validation loss: 3.2718767333751617

Epoch: 6| Step: 7
Training loss: 3.774926944051019
Validation loss: 3.2673383048263034

Epoch: 6| Step: 8
Training loss: 3.4744569038444504
Validation loss: 3.27017407226209

Epoch: 6| Step: 9
Training loss: 3.3116285509342367
Validation loss: 3.269299712646863

Epoch: 6| Step: 10
Training loss: 3.6456736647746926
Validation loss: 3.267712917457579

Epoch: 6| Step: 11
Training loss: 4.06380735048855
Validation loss: 3.2693939903505167

Epoch: 6| Step: 12
Training loss: 4.252116854191477
Validation loss: 3.2681131541450967

Epoch: 6| Step: 13
Training loss: 3.4498113552984306
Validation loss: 3.2682516740057364

Epoch: 28| Step: 0
Training loss: 3.2672433447933873
Validation loss: 3.2667792984122963

Epoch: 6| Step: 1
Training loss: 3.4363198768835024
Validation loss: 3.2637325910679538

Epoch: 6| Step: 2
Training loss: 3.6664742216990684
Validation loss: 3.2631980111267245

Epoch: 6| Step: 3
Training loss: 3.2803831862873816
Validation loss: 3.2638140590773124

Epoch: 6| Step: 4
Training loss: 3.9608935592591683
Validation loss: 3.2720158366684977

Epoch: 6| Step: 5
Training loss: 4.50173408157467
Validation loss: 3.261572719795501

Epoch: 6| Step: 6
Training loss: 2.9207924862198946
Validation loss: 3.263326460962547

Epoch: 6| Step: 7
Training loss: 3.219832155106173
Validation loss: 3.2604145541605742

Epoch: 6| Step: 8
Training loss: 2.9084733231599706
Validation loss: 3.261812459292064

Epoch: 6| Step: 9
Training loss: 2.8957184327381036
Validation loss: 3.262532189706666

Epoch: 6| Step: 10
Training loss: 3.6222392125371563
Validation loss: 3.2620202688346938

Epoch: 6| Step: 11
Training loss: 3.9305021074942323
Validation loss: 3.2603453942535943

Epoch: 6| Step: 12
Training loss: 3.786007748974237
Validation loss: 3.2605485262733476

Epoch: 6| Step: 13
Training loss: 3.312737942192986
Validation loss: 3.2563542185729584

Epoch: 29| Step: 0
Training loss: 3.980873993225478
Validation loss: 3.2701237566380703

Epoch: 6| Step: 1
Training loss: 3.4629352392430626
Validation loss: 3.2608218850229655

Epoch: 6| Step: 2
Training loss: 4.575983477502618
Validation loss: 3.257679661901793

Epoch: 6| Step: 3
Training loss: 3.3120168657472355
Validation loss: 3.258050610404898

Epoch: 6| Step: 4
Training loss: 3.1188226297670836
Validation loss: 3.2564124731248083

Epoch: 6| Step: 5
Training loss: 3.6132654138166482
Validation loss: 3.255876114930544

Epoch: 6| Step: 6
Training loss: 3.466382292552297
Validation loss: 3.255815913770058

Epoch: 6| Step: 7
Training loss: 4.25704282750995
Validation loss: 3.2552232174768925

Epoch: 6| Step: 8
Training loss: 2.8004442169131374
Validation loss: 3.254970743807626

Epoch: 6| Step: 9
Training loss: 2.917907305661644
Validation loss: 3.2540053084034493

Epoch: 6| Step: 10
Training loss: 3.058460140111344
Validation loss: 3.2552070648519034

Epoch: 6| Step: 11
Training loss: 2.8774092157991737
Validation loss: 3.2528978984593877

Epoch: 6| Step: 12
Training loss: 3.785659866764453
Validation loss: 3.254299746140355

Epoch: 6| Step: 13
Training loss: 3.295439638205746
Validation loss: 3.253296714302106

Epoch: 30| Step: 0
Training loss: 4.2954405453643245
Validation loss: 3.2526343422970116

Epoch: 6| Step: 1
Training loss: 3.8893274801674695
Validation loss: 3.2532721187422746

Epoch: 6| Step: 2
Training loss: 2.594798140566874
Validation loss: 3.2526252609477027

Epoch: 6| Step: 3
Training loss: 3.759646406389066
Validation loss: 3.250844180049667

Epoch: 6| Step: 4
Training loss: 2.7543303467498412
Validation loss: 3.2481854708111193

Epoch: 6| Step: 5
Training loss: 3.3403145798426785
Validation loss: 3.250523260824151

Epoch: 6| Step: 6
Training loss: 3.8381973726412375
Validation loss: 3.2503588520144673

Epoch: 6| Step: 7
Training loss: 3.1934243291845865
Validation loss: 3.249644073041571

Epoch: 6| Step: 8
Training loss: 3.312164001698211
Validation loss: 3.2512374885246027

Epoch: 6| Step: 9
Training loss: 3.1112639090693417
Validation loss: 3.2515961361630357

Epoch: 6| Step: 10
Training loss: 3.3701229885762154
Validation loss: 3.2561982638762847

Epoch: 6| Step: 11
Training loss: 3.972722986011482
Validation loss: 3.2459123461375987

Epoch: 6| Step: 12
Training loss: 3.9370528678725956
Validation loss: 3.2431047684161185

Epoch: 6| Step: 13
Training loss: 2.959636311741414
Validation loss: 3.245474757869194

Epoch: 31| Step: 0
Training loss: 3.1984862442663
Validation loss: 3.2475018582859794

Epoch: 6| Step: 1
Training loss: 2.5749006048481586
Validation loss: 3.2467965713372973

Epoch: 6| Step: 2
Training loss: 4.194988785229721
Validation loss: 3.2515349537847125

Epoch: 6| Step: 3
Training loss: 3.224774398601397
Validation loss: 3.251328347523305

Epoch: 6| Step: 4
Training loss: 3.132005392544953
Validation loss: 3.253292898740131

Epoch: 6| Step: 5
Training loss: 3.723538049131836
Validation loss: 3.2514832443161805

Epoch: 6| Step: 6
Training loss: 3.3177756278231274
Validation loss: 3.2468523349176373

Epoch: 6| Step: 7
Training loss: 3.900920925470351
Validation loss: 3.2471994366177634

Epoch: 6| Step: 8
Training loss: 3.102338487231119
Validation loss: 3.2400139815645246

Epoch: 6| Step: 9
Training loss: 3.005888881129547
Validation loss: 3.2324790730186916

Epoch: 6| Step: 10
Training loss: 3.8736530547122117
Validation loss: 3.239944758079114

Epoch: 6| Step: 11
Training loss: 3.507671123960624
Validation loss: 3.2395175860824783

Epoch: 6| Step: 12
Training loss: 4.14885794310382
Validation loss: 3.2490621306837584

Epoch: 6| Step: 13
Training loss: 3.787869420935869
Validation loss: 3.2352955531484033

Epoch: 32| Step: 0
Training loss: 3.5008286448877644
Validation loss: 3.2360618551529696

Epoch: 6| Step: 1
Training loss: 3.9937391158598876
Validation loss: 3.2392874766835504

Epoch: 6| Step: 2
Training loss: 3.395618330501169
Validation loss: 3.251451564133688

Epoch: 6| Step: 3
Training loss: 3.806522999762025
Validation loss: 3.239681460163189

Epoch: 6| Step: 4
Training loss: 4.175214366777462
Validation loss: 3.238643699235095

Epoch: 6| Step: 5
Training loss: 3.5014035271811004
Validation loss: 3.2395449363306654

Epoch: 6| Step: 6
Training loss: 3.1745075895285115
Validation loss: 3.236464542141221

Epoch: 6| Step: 7
Training loss: 3.574662177923852
Validation loss: 3.2395754921115962

Epoch: 6| Step: 8
Training loss: 3.2768053742468988
Validation loss: 3.2381774204072866

Epoch: 6| Step: 9
Training loss: 3.0682978341616534
Validation loss: 3.234738969528273

Epoch: 6| Step: 10
Training loss: 3.2921276172176066
Validation loss: 3.234577825915192

Epoch: 6| Step: 11
Training loss: 3.729014871303196
Validation loss: 3.2332617324150887

Epoch: 6| Step: 12
Training loss: 2.952362608010277
Validation loss: 3.2352013452034303

Epoch: 6| Step: 13
Training loss: 2.9403628744277444
Validation loss: 3.232877070875348

Epoch: 33| Step: 0
Training loss: 3.9125320579507314
Validation loss: 3.231237026591677

Epoch: 6| Step: 1
Training loss: 4.040514804786057
Validation loss: 3.2299860131477023

Epoch: 6| Step: 2
Training loss: 2.722661766801934
Validation loss: 3.231427135401592

Epoch: 6| Step: 3
Training loss: 3.754241071013835
Validation loss: 3.228193882161617

Epoch: 6| Step: 4
Training loss: 3.507272793513518
Validation loss: 3.225527773966155

Epoch: 6| Step: 5
Training loss: 3.434562121249473
Validation loss: 3.2278785499593874

Epoch: 6| Step: 6
Training loss: 3.947561699334939
Validation loss: 3.226404561768237

Epoch: 6| Step: 7
Training loss: 3.0672732154190867
Validation loss: 3.2280004744817

Epoch: 6| Step: 8
Training loss: 3.885876066782944
Validation loss: 3.223385680955654

Epoch: 6| Step: 9
Training loss: 3.5949572318428626
Validation loss: 3.225709973707586

Epoch: 6| Step: 10
Training loss: 3.2408497451938207
Validation loss: 3.2251046048893475

Epoch: 6| Step: 11
Training loss: 2.561275096377531
Validation loss: 3.2215176662365517

Epoch: 6| Step: 12
Training loss: 3.1150528331703113
Validation loss: 3.220879710069089

Epoch: 6| Step: 13
Training loss: 3.6133927611593686
Validation loss: 3.221268585742429

Epoch: 34| Step: 0
Training loss: 3.258917239294487
Validation loss: 3.2187318037749093

Epoch: 6| Step: 1
Training loss: 2.220191809469939
Validation loss: 3.2194016503127414

Epoch: 6| Step: 2
Training loss: 3.1007575616871215
Validation loss: 3.2182498682314704

Epoch: 6| Step: 3
Training loss: 3.4142326120555455
Validation loss: 3.2168428796645347

Epoch: 6| Step: 4
Training loss: 3.7820762803380115
Validation loss: 3.2158341629618277

Epoch: 6| Step: 5
Training loss: 3.369201199636616
Validation loss: 3.2158437372360718

Epoch: 6| Step: 6
Training loss: 3.6228103601624917
Validation loss: 3.211548901544718

Epoch: 6| Step: 7
Training loss: 3.625032490551795
Validation loss: 3.2140419594304186

Epoch: 6| Step: 8
Training loss: 3.5132565806894624
Validation loss: 3.2121216667518455

Epoch: 6| Step: 9
Training loss: 3.9348337743760173
Validation loss: 3.21650440970007

Epoch: 6| Step: 10
Training loss: 3.5502077820911424
Validation loss: 3.21712633982511

Epoch: 6| Step: 11
Training loss: 3.7678307368980977
Validation loss: 3.209418078411204

Epoch: 6| Step: 12
Training loss: 3.4096430406529143
Validation loss: 3.1974661161211726

Epoch: 6| Step: 13
Training loss: 3.7588928319334203
Validation loss: 3.1900150792747897

Epoch: 35| Step: 0
Training loss: 3.1527064609910647
Validation loss: 3.1903333173884065

Epoch: 6| Step: 1
Training loss: 3.860389977555194
Validation loss: 3.188751055618884

Epoch: 6| Step: 2
Training loss: 3.5824596019950814
Validation loss: 3.189059198473299

Epoch: 6| Step: 3
Training loss: 3.242213237614334
Validation loss: 3.1865599305858456

Epoch: 6| Step: 4
Training loss: 3.2629966562425254
Validation loss: 3.188056549764209

Epoch: 6| Step: 5
Training loss: 3.0599769007989015
Validation loss: 3.189469010200918

Epoch: 6| Step: 6
Training loss: 4.0729896688463745
Validation loss: 3.195927193925951

Epoch: 6| Step: 7
Training loss: 3.9467241537787396
Validation loss: 3.1911873767430152

Epoch: 6| Step: 8
Training loss: 3.609262175675077
Validation loss: 3.1816282984505757

Epoch: 6| Step: 9
Training loss: 2.5890964908705287
Validation loss: 3.178833628468449

Epoch: 6| Step: 10
Training loss: 3.2752684796191023
Validation loss: 3.2006021900794237

Epoch: 6| Step: 11
Training loss: 3.8477117699040053
Validation loss: 3.1912583567533273

Epoch: 6| Step: 12
Training loss: 3.383828942090036
Validation loss: 3.1782906005505143

Epoch: 6| Step: 13
Training loss: 2.7077552961062246
Validation loss: 3.2021038805872357

Epoch: 36| Step: 0
Training loss: 3.2650998802154896
Validation loss: 3.2613609183999595

Epoch: 6| Step: 1
Training loss: 2.1606835382248732
Validation loss: 3.249910091484885

Epoch: 6| Step: 2
Training loss: 3.541823768871231
Validation loss: 3.2159374934645024

Epoch: 6| Step: 3
Training loss: 2.8500060968166525
Validation loss: 3.192228946161044

Epoch: 6| Step: 4
Training loss: 3.965359177935106
Validation loss: 3.2323475477873544

Epoch: 6| Step: 5
Training loss: 3.6767141068534492
Validation loss: 3.242261573171683

Epoch: 6| Step: 6
Training loss: 3.956948463048412
Validation loss: 3.198693451302561

Epoch: 6| Step: 7
Training loss: 3.439497350075909
Validation loss: 3.2064435342228172

Epoch: 6| Step: 8
Training loss: 4.15399154452114
Validation loss: 3.2082916249596716

Epoch: 6| Step: 9
Training loss: 2.5164519662621494
Validation loss: 3.200439111386542

Epoch: 6| Step: 10
Training loss: 3.6305357659042232
Validation loss: 3.202328693162653

Epoch: 6| Step: 11
Training loss: 3.2340640595838077
Validation loss: 3.2007165273244795

Epoch: 6| Step: 12
Training loss: 3.7565372706290296
Validation loss: 3.199025376011047

Epoch: 6| Step: 13
Training loss: 3.9723193120465417
Validation loss: 3.1913286154152014

Epoch: 37| Step: 0
Training loss: 2.705111264463072
Validation loss: 3.190673916005556

Epoch: 6| Step: 1
Training loss: 3.7296557114664375
Validation loss: 3.187360970836855

Epoch: 6| Step: 2
Training loss: 3.8775205720593107
Validation loss: 3.184389250456936

Epoch: 6| Step: 3
Training loss: 3.006505429525467
Validation loss: 3.181863031322943

Epoch: 6| Step: 4
Training loss: 3.014355960717008
Validation loss: 3.1812188281046203

Epoch: 6| Step: 5
Training loss: 4.175634169240887
Validation loss: 3.1783791989592927

Epoch: 6| Step: 6
Training loss: 3.436279635115991
Validation loss: 3.1773831429611317

Epoch: 6| Step: 7
Training loss: 3.5087704444346715
Validation loss: 3.176801906623772

Epoch: 6| Step: 8
Training loss: 3.5325956228263125
Validation loss: 3.173734551324269

Epoch: 6| Step: 9
Training loss: 3.3362898272026955
Validation loss: 3.173615282164773

Epoch: 6| Step: 10
Training loss: 3.0995626079490157
Validation loss: 3.1688082879022086

Epoch: 6| Step: 11
Training loss: 3.8982392224361186
Validation loss: 3.169718284499297

Epoch: 6| Step: 12
Training loss: 3.1715564285928344
Validation loss: 3.1708348668872945

Epoch: 6| Step: 13
Training loss: 3.304035961232516
Validation loss: 3.1714815139891486

Epoch: 38| Step: 0
Training loss: 2.811149612065935
Validation loss: 3.1669448272693344

Epoch: 6| Step: 1
Training loss: 4.547938271699976
Validation loss: 3.165057251516803

Epoch: 6| Step: 2
Training loss: 3.464661259022375
Validation loss: 3.17059233476475

Epoch: 6| Step: 3
Training loss: 3.612666755180219
Validation loss: 3.1686936390962153

Epoch: 6| Step: 4
Training loss: 3.3403815299399504
Validation loss: 3.1714679144198823

Epoch: 6| Step: 5
Training loss: 3.4610102454262273
Validation loss: 3.1652076989300504

Epoch: 6| Step: 6
Training loss: 3.8057248309155853
Validation loss: 3.1628774165872544

Epoch: 6| Step: 7
Training loss: 2.3075572622350355
Validation loss: 3.1666059801237534

Epoch: 6| Step: 8
Training loss: 3.397721559375333
Validation loss: 3.1634732164422603

Epoch: 6| Step: 9
Training loss: 3.3973005124796845
Validation loss: 3.1630342547410777

Epoch: 6| Step: 10
Training loss: 3.7584217870302465
Validation loss: 3.1596576250599475

Epoch: 6| Step: 11
Training loss: 2.862035795327828
Validation loss: 3.16087887386173

Epoch: 6| Step: 12
Training loss: 2.942196601776615
Validation loss: 3.1568471822230233

Epoch: 6| Step: 13
Training loss: 4.012685211755661
Validation loss: 3.1574731692555416

Epoch: 39| Step: 0
Training loss: 3.060088940742793
Validation loss: 3.158153511045415

Epoch: 6| Step: 1
Training loss: 3.4874310284976007
Validation loss: 3.1559189174339743

Epoch: 6| Step: 2
Training loss: 3.1100401813818372
Validation loss: 3.156413969647902

Epoch: 6| Step: 3
Training loss: 2.8577254076118055
Validation loss: 3.156494350471937

Epoch: 6| Step: 4
Training loss: 2.7691081898205336
Validation loss: 3.153595778070729

Epoch: 6| Step: 5
Training loss: 3.4657198756227574
Validation loss: 3.1559465754493283

Epoch: 6| Step: 6
Training loss: 3.569175355484889
Validation loss: 3.1521943851364607

Epoch: 6| Step: 7
Training loss: 3.781078744588417
Validation loss: 3.1534989538220914

Epoch: 6| Step: 8
Training loss: 3.736717096193184
Validation loss: 3.1533256067334268

Epoch: 6| Step: 9
Training loss: 3.528975978295021
Validation loss: 3.148923222839758

Epoch: 6| Step: 10
Training loss: 3.478042938827261
Validation loss: 3.1495215517311754

Epoch: 6| Step: 11
Training loss: 3.9199730870237772
Validation loss: 3.149644523469119

Epoch: 6| Step: 12
Training loss: 3.223142423081514
Validation loss: 3.147671810516237

Epoch: 6| Step: 13
Training loss: 3.8695243787637104
Validation loss: 3.1435962707344007

Epoch: 40| Step: 0
Training loss: 3.553730661914552
Validation loss: 3.141996125690149

Epoch: 6| Step: 1
Training loss: 4.074782364539163
Validation loss: 3.14006625805819

Epoch: 6| Step: 2
Training loss: 3.512227362100982
Validation loss: 3.1409154357797613

Epoch: 6| Step: 3
Training loss: 3.5813417592701056
Validation loss: 3.1379228612962784

Epoch: 6| Step: 4
Training loss: 2.7792325364237
Validation loss: 3.140612425942479

Epoch: 6| Step: 5
Training loss: 3.15181564199518
Validation loss: 3.1373979386909623

Epoch: 6| Step: 6
Training loss: 3.164879512090437
Validation loss: 3.1378831930827173

Epoch: 6| Step: 7
Training loss: 4.074639595803948
Validation loss: 3.1388836815027625

Epoch: 6| Step: 8
Training loss: 2.5241841726198757
Validation loss: 3.138072147323422

Epoch: 6| Step: 9
Training loss: 2.499555548261085
Validation loss: 3.1344178044724007

Epoch: 6| Step: 10
Training loss: 3.095694807264062
Validation loss: 3.133476191318363

Epoch: 6| Step: 11
Training loss: 3.956890378592852
Validation loss: 3.135812648474221

Epoch: 6| Step: 12
Training loss: 3.2275439379218094
Validation loss: 3.1361333139582226

Epoch: 6| Step: 13
Training loss: 4.354886714894033
Validation loss: 3.1345900871221097

Epoch: 41| Step: 0
Training loss: 3.6819646637074124
Validation loss: 3.1330580033268545

Epoch: 6| Step: 1
Training loss: 4.196615063080113
Validation loss: 3.133537368397472

Epoch: 6| Step: 2
Training loss: 3.904111963714633
Validation loss: 3.131717880478955

Epoch: 6| Step: 3
Training loss: 3.357191928980268
Validation loss: 3.132803200606748

Epoch: 6| Step: 4
Training loss: 3.337373732560699
Validation loss: 3.1314633493973423

Epoch: 6| Step: 5
Training loss: 3.6420802535506027
Validation loss: 3.128780280366759

Epoch: 6| Step: 6
Training loss: 3.5843677949708264
Validation loss: 3.130495998234367

Epoch: 6| Step: 7
Training loss: 3.2254181465119576
Validation loss: 3.1318000919231177

Epoch: 6| Step: 8
Training loss: 3.0697735417744285
Validation loss: 3.126096133704655

Epoch: 6| Step: 9
Training loss: 2.6543491518375726
Validation loss: 3.127336155529902

Epoch: 6| Step: 10
Training loss: 2.747562541996119
Validation loss: 3.1298403156149557

Epoch: 6| Step: 11
Training loss: 3.374742286167475
Validation loss: 3.1333388821594843

Epoch: 6| Step: 12
Training loss: 3.850751748942331
Validation loss: 3.133566966561458

Epoch: 6| Step: 13
Training loss: 1.5039651438093022
Validation loss: 3.1332856917135756

Epoch: 42| Step: 0
Training loss: 4.139076951182775
Validation loss: 3.1358520714613367

Epoch: 6| Step: 1
Training loss: 3.0557430229091755
Validation loss: 3.137597544915878

Epoch: 6| Step: 2
Training loss: 3.5811401723161933
Validation loss: 3.133366462944303

Epoch: 6| Step: 3
Training loss: 3.1708143744150448
Validation loss: 3.1252436126587773

Epoch: 6| Step: 4
Training loss: 3.7023126540092623
Validation loss: 3.121222631917386

Epoch: 6| Step: 5
Training loss: 3.93269381793045
Validation loss: 3.122246772669981

Epoch: 6| Step: 6
Training loss: 3.1125799942461003
Validation loss: 3.118988460172485

Epoch: 6| Step: 7
Training loss: 3.399136456050358
Validation loss: 3.121555227976541

Epoch: 6| Step: 8
Training loss: 3.1126864641706136
Validation loss: 3.1171268672403802

Epoch: 6| Step: 9
Training loss: 3.7486053416499168
Validation loss: 3.1172214855424523

Epoch: 6| Step: 10
Training loss: 3.2814931143659813
Validation loss: 3.115557110756759

Epoch: 6| Step: 11
Training loss: 2.4395419639860823
Validation loss: 3.11686148511412

Epoch: 6| Step: 12
Training loss: 2.671694743896733
Validation loss: 3.118136197610628

Epoch: 6| Step: 13
Training loss: 3.885998897888059
Validation loss: 3.1145670631755524

Epoch: 43| Step: 0
Training loss: 3.1025458249650884
Validation loss: 3.1147251232002837

Epoch: 6| Step: 1
Training loss: 3.8262481448179306
Validation loss: 3.11284923166592

Epoch: 6| Step: 2
Training loss: 3.8950788749964804
Validation loss: 3.1131246351906943

Epoch: 6| Step: 3
Training loss: 2.97098015792009
Validation loss: 3.11581657956908

Epoch: 6| Step: 4
Training loss: 3.801985076610127
Validation loss: 3.115864975284058

Epoch: 6| Step: 5
Training loss: 2.9136430781125715
Validation loss: 3.1215733352918584

Epoch: 6| Step: 6
Training loss: 3.2070462671409214
Validation loss: 3.1224591120495546

Epoch: 6| Step: 7
Training loss: 3.7262620464899308
Validation loss: 3.1141975869908283

Epoch: 6| Step: 8
Training loss: 2.8914008671592693
Validation loss: 3.112402000882661

Epoch: 6| Step: 9
Training loss: 3.4198287349895398
Validation loss: 3.1105210736749673

Epoch: 6| Step: 10
Training loss: 3.599838804238866
Validation loss: 3.1105247742573887

Epoch: 6| Step: 11
Training loss: 3.4415146012845117
Validation loss: 3.117047654031534

Epoch: 6| Step: 12
Training loss: 3.1202839169556524
Validation loss: 3.112446725040743

Epoch: 6| Step: 13
Training loss: 3.024487690064801
Validation loss: 3.109288648582329

Epoch: 44| Step: 0
Training loss: 3.714198556862544
Validation loss: 3.1128684931968253

Epoch: 6| Step: 1
Training loss: 3.329885957156926
Validation loss: 3.110041797031169

Epoch: 6| Step: 2
Training loss: 3.4990568252576058
Validation loss: 3.1111526408355945

Epoch: 6| Step: 3
Training loss: 3.21105154906944
Validation loss: 3.1125637454638806

Epoch: 6| Step: 4
Training loss: 3.4016520413488207
Validation loss: 3.113596364556634

Epoch: 6| Step: 5
Training loss: 2.775253174376126
Validation loss: 3.1119209082610455

Epoch: 6| Step: 6
Training loss: 2.954033283043558
Validation loss: 3.111471863223857

Epoch: 6| Step: 7
Training loss: 3.906378171725342
Validation loss: 3.11102148268499

Epoch: 6| Step: 8
Training loss: 3.388627408750043
Validation loss: 3.1131390825425407

Epoch: 6| Step: 9
Training loss: 3.8809031161035223
Validation loss: 3.1080498042144433

Epoch: 6| Step: 10
Training loss: 3.2895898826554864
Validation loss: 3.103579807959495

Epoch: 6| Step: 11
Training loss: 3.204020156454055
Validation loss: 3.10819989489025

Epoch: 6| Step: 12
Training loss: 3.1423461145613367
Validation loss: 3.1039786261549023

Epoch: 6| Step: 13
Training loss: 3.3493360402325103
Validation loss: 3.1035188663951843

Epoch: 45| Step: 0
Training loss: 3.0227037273749353
Validation loss: 3.107697712474875

Epoch: 6| Step: 1
Training loss: 3.8482304952986235
Validation loss: 3.1075285596005964

Epoch: 6| Step: 2
Training loss: 2.8899736650052414
Validation loss: 3.106928353723751

Epoch: 6| Step: 3
Training loss: 3.747463894619866
Validation loss: 3.1089542586786774

Epoch: 6| Step: 4
Training loss: 2.6684213368924445
Validation loss: 3.1057531962161646

Epoch: 6| Step: 5
Training loss: 3.003344896345781
Validation loss: 3.1051199628090362

Epoch: 6| Step: 6
Training loss: 3.1880938406885284
Validation loss: 3.1029410416489602

Epoch: 6| Step: 7
Training loss: 2.6129411096838333
Validation loss: 3.100685411168387

Epoch: 6| Step: 8
Training loss: 4.5664329821715395
Validation loss: 3.099641511223786

Epoch: 6| Step: 9
Training loss: 3.7944860910041847
Validation loss: 3.09782508044797

Epoch: 6| Step: 10
Training loss: 3.5791190153479655
Validation loss: 3.0997071018312155

Epoch: 6| Step: 11
Training loss: 3.7180913774692166
Validation loss: 3.098384224848368

Epoch: 6| Step: 12
Training loss: 3.292198588855465
Validation loss: 3.1027159840290834

Epoch: 6| Step: 13
Training loss: 1.9686534191843756
Validation loss: 3.109990003511915

Epoch: 46| Step: 0
Training loss: 2.79331069667023
Validation loss: 3.106349913700551

Epoch: 6| Step: 1
Training loss: 4.5825390676611395
Validation loss: 3.1038392191493855

Epoch: 6| Step: 2
Training loss: 3.6050354603201917
Validation loss: 3.0961105275801644

Epoch: 6| Step: 3
Training loss: 3.463335364753879
Validation loss: 3.0923753395911806

Epoch: 6| Step: 4
Training loss: 2.2486842865007137
Validation loss: 3.0923239515378724

Epoch: 6| Step: 5
Training loss: 3.6465522420622682
Validation loss: 3.0910958706965905

Epoch: 6| Step: 6
Training loss: 2.7329977000031773
Validation loss: 3.093204511106699

Epoch: 6| Step: 7
Training loss: 3.5807216500868075
Validation loss: 3.0930792789040096

Epoch: 6| Step: 8
Training loss: 2.8625580627682865
Validation loss: 3.091946655200106

Epoch: 6| Step: 9
Training loss: 2.7003457660389625
Validation loss: 3.0924750616137615

Epoch: 6| Step: 10
Training loss: 3.2148799407516395
Validation loss: 3.0920453787071205

Epoch: 6| Step: 11
Training loss: 3.881215064341499
Validation loss: 3.09127845455129

Epoch: 6| Step: 12
Training loss: 3.734412029513717
Validation loss: 3.0906896568269016

Epoch: 6| Step: 13
Training loss: 3.3492842180007982
Validation loss: 3.088831937176903

Epoch: 47| Step: 0
Training loss: 2.9399621262997844
Validation loss: 3.0911140867724938

Epoch: 6| Step: 1
Training loss: 2.57491727159066
Validation loss: 3.0883289471347273

Epoch: 6| Step: 2
Training loss: 4.411899272885975
Validation loss: 3.0867173654577758

Epoch: 6| Step: 3
Training loss: 3.3647432240069937
Validation loss: 3.086706134051955

Epoch: 6| Step: 4
Training loss: 2.2191621639345933
Validation loss: 3.0869113368419123

Epoch: 6| Step: 5
Training loss: 3.516501491217078
Validation loss: 3.0857049379040595

Epoch: 6| Step: 6
Training loss: 3.569855975924347
Validation loss: 3.0846335079063048

Epoch: 6| Step: 7
Training loss: 3.2132914655445597
Validation loss: 3.088093025296064

Epoch: 6| Step: 8
Training loss: 3.55045880321373
Validation loss: 3.0853701905841215

Epoch: 6| Step: 9
Training loss: 2.8239176102904016
Validation loss: 3.0848349567795874

Epoch: 6| Step: 10
Training loss: 4.042031943472944
Validation loss: 3.08616146854878

Epoch: 6| Step: 11
Training loss: 2.7906748494889313
Validation loss: 3.086238038857042

Epoch: 6| Step: 12
Training loss: 3.616356377248463
Validation loss: 3.0881462553054857

Epoch: 6| Step: 13
Training loss: 3.9798854291901393
Validation loss: 3.111024951938133

Epoch: 48| Step: 0
Training loss: 3.193006210163408
Validation loss: 3.085129089928107

Epoch: 6| Step: 1
Training loss: 2.426553256280687
Validation loss: 3.0920266416307958

Epoch: 6| Step: 2
Training loss: 3.8227316718941617
Validation loss: 3.09021017235607

Epoch: 6| Step: 3
Training loss: 2.715301606793789
Validation loss: 3.082951716381801

Epoch: 6| Step: 4
Training loss: 3.9523027492190392
Validation loss: 3.083354419967619

Epoch: 6| Step: 5
Training loss: 3.1843497472778144
Validation loss: 3.080815079806

Epoch: 6| Step: 6
Training loss: 3.831127126195093
Validation loss: 3.0825156436036814

Epoch: 6| Step: 7
Training loss: 3.0301459750021578
Validation loss: 3.081911309262941

Epoch: 6| Step: 8
Training loss: 2.5457038292877265
Validation loss: 3.082736525164801

Epoch: 6| Step: 9
Training loss: 4.168466153983297
Validation loss: 3.081302644818652

Epoch: 6| Step: 10
Training loss: 3.502186228647322
Validation loss: 3.0831421330265374

Epoch: 6| Step: 11
Training loss: 3.3373067221236554
Validation loss: 3.0809373190367446

Epoch: 6| Step: 12
Training loss: 3.308739885257815
Validation loss: 3.080497905205654

Epoch: 6| Step: 13
Training loss: 3.5094392738333045
Validation loss: 3.080871176550499

Epoch: 49| Step: 0
Training loss: 3.5827561438512268
Validation loss: 3.080300215861738

Epoch: 6| Step: 1
Training loss: 3.398892777738508
Validation loss: 3.0825375647250692

Epoch: 6| Step: 2
Training loss: 2.879521835951786
Validation loss: 3.0947973443052046

Epoch: 6| Step: 3
Training loss: 2.967033291425831
Validation loss: 3.092347883159858

Epoch: 6| Step: 4
Training loss: 2.9614094783274463
Validation loss: 3.0794744203542725

Epoch: 6| Step: 5
Training loss: 2.373106251668425
Validation loss: 3.077566811352079

Epoch: 6| Step: 6
Training loss: 3.4237417763997393
Validation loss: 3.075926034443328

Epoch: 6| Step: 7
Training loss: 3.848617077446583
Validation loss: 3.078913924293758

Epoch: 6| Step: 8
Training loss: 3.398944825638447
Validation loss: 3.079976482543954

Epoch: 6| Step: 9
Training loss: 2.771440157493902
Validation loss: 3.0794749981043013

Epoch: 6| Step: 10
Training loss: 3.5164237916310133
Validation loss: 3.0807711496518517

Epoch: 6| Step: 11
Training loss: 3.9525700959969745
Validation loss: 3.0795992268278995

Epoch: 6| Step: 12
Training loss: 4.167728034578893
Validation loss: 3.075557445984666

Epoch: 6| Step: 13
Training loss: 3.1612355354313024
Validation loss: 3.0775190095964224

Epoch: 50| Step: 0
Training loss: 4.2870986973101655
Validation loss: 3.0771938973094506

Epoch: 6| Step: 1
Training loss: 3.7686995621527735
Validation loss: 3.077187474025579

Epoch: 6| Step: 2
Training loss: 2.7125961989822427
Validation loss: 3.074862487543482

Epoch: 6| Step: 3
Training loss: 2.9920877385254228
Validation loss: 3.075565494763471

Epoch: 6| Step: 4
Training loss: 3.2865235593744404
Validation loss: 3.073772449049205

Epoch: 6| Step: 5
Training loss: 3.60963551295376
Validation loss: 3.0739859201358604

Epoch: 6| Step: 6
Training loss: 3.7482481361251714
Validation loss: 3.072608329663946

Epoch: 6| Step: 7
Training loss: 2.7281591773759883
Validation loss: 3.0753388639070067

Epoch: 6| Step: 8
Training loss: 2.5825082220074034
Validation loss: 3.0725043399600946

Epoch: 6| Step: 9
Training loss: 3.3758163877608203
Validation loss: 3.0719241489343423

Epoch: 6| Step: 10
Training loss: 3.399535674758404
Validation loss: 3.0738019938417787

Epoch: 6| Step: 11
Training loss: 2.4294005589456966
Validation loss: 3.0705984780289177

Epoch: 6| Step: 12
Training loss: 3.5657887587525288
Validation loss: 3.069564097297447

Epoch: 6| Step: 13
Training loss: 4.098469816161194
Validation loss: 3.071728419926485

Epoch: 51| Step: 0
Training loss: 3.540221035193614
Validation loss: 3.0725285794800707

Epoch: 6| Step: 1
Training loss: 3.421449957102977
Validation loss: 3.0683082046848273

Epoch: 6| Step: 2
Training loss: 2.9046143882213857
Validation loss: 3.0646047920436166

Epoch: 6| Step: 3
Training loss: 3.3144211865911104
Validation loss: 3.0668481024972793

Epoch: 6| Step: 4
Training loss: 3.4271383696584468
Validation loss: 3.0650007992120623

Epoch: 6| Step: 5
Training loss: 3.2068846433260716
Validation loss: 3.065245868376831

Epoch: 6| Step: 6
Training loss: 3.6546259476532947
Validation loss: 3.0645012694334803

Epoch: 6| Step: 7
Training loss: 3.293526055904281
Validation loss: 3.0628843302819084

Epoch: 6| Step: 8
Training loss: 3.641553637556728
Validation loss: 3.0645285202697683

Epoch: 6| Step: 9
Training loss: 2.319385073492676
Validation loss: 3.0644443576959506

Epoch: 6| Step: 10
Training loss: 3.25923985377549
Validation loss: 3.064546597290992

Epoch: 6| Step: 11
Training loss: 3.201718947542894
Validation loss: 3.0635300143707944

Epoch: 6| Step: 12
Training loss: 3.6317562413529965
Validation loss: 3.063349895734021

Epoch: 6| Step: 13
Training loss: 3.9234207572260744
Validation loss: 3.060397029020062

Epoch: 52| Step: 0
Training loss: 3.75053935940555
Validation loss: 3.060894424495607

Epoch: 6| Step: 1
Training loss: 2.6657447314009537
Validation loss: 3.057887535154027

Epoch: 6| Step: 2
Training loss: 3.437333397729408
Validation loss: 3.0585910611294125

Epoch: 6| Step: 3
Training loss: 2.8075683589504004
Validation loss: 3.0557065682804554

Epoch: 6| Step: 4
Training loss: 3.3273880550088717
Validation loss: 3.0505922219632144

Epoch: 6| Step: 5
Training loss: 3.2774412302062803
Validation loss: 3.049574154907733

Epoch: 6| Step: 6
Training loss: 3.6099282373285635
Validation loss: 3.0506803457467755

Epoch: 6| Step: 7
Training loss: 3.666763188796741
Validation loss: 3.0485218159069616

Epoch: 6| Step: 8
Training loss: 3.2260694519626694
Validation loss: 3.050640743133889

Epoch: 6| Step: 9
Training loss: 3.5456957768356436
Validation loss: 3.0467439491311117

Epoch: 6| Step: 10
Training loss: 2.9522615007914146
Validation loss: 3.0468583133094382

Epoch: 6| Step: 11
Training loss: 2.641487928615284
Validation loss: 3.0480528854614044

Epoch: 6| Step: 12
Training loss: 3.3281284385985757
Validation loss: 3.0488725002749475

Epoch: 6| Step: 13
Training loss: 4.434957931301828
Validation loss: 3.0482713274825564

Epoch: 53| Step: 0
Training loss: 3.307603203625961
Validation loss: 3.0464093504838203

Epoch: 6| Step: 1
Training loss: 3.7234498145843884
Validation loss: 3.0440025384349676

Epoch: 6| Step: 2
Training loss: 3.062734322439051
Validation loss: 3.0466055288912415

Epoch: 6| Step: 3
Training loss: 2.902368722554072
Validation loss: 3.0433516853472047

Epoch: 6| Step: 4
Training loss: 3.3501676489030867
Validation loss: 3.0517538054409177

Epoch: 6| Step: 5
Training loss: 3.2972588338286006
Validation loss: 3.046257674639927

Epoch: 6| Step: 6
Training loss: 3.223819629025216
Validation loss: 3.043987080767275

Epoch: 6| Step: 7
Training loss: 3.050242123608268
Validation loss: 3.04446685678374

Epoch: 6| Step: 8
Training loss: 3.0199132285378583
Validation loss: 3.0418917240744388

Epoch: 6| Step: 9
Training loss: 3.174544540537423
Validation loss: 3.045438312383123

Epoch: 6| Step: 10
Training loss: 2.945408503336316
Validation loss: 3.0602992732769816

Epoch: 6| Step: 11
Training loss: 3.8006340853045057
Validation loss: 3.065907248563562

Epoch: 6| Step: 12
Training loss: 3.8987772761030124
Validation loss: 3.0861150576008263

Epoch: 6| Step: 13
Training loss: 3.844767862165469
Validation loss: 3.0709729517971103

Epoch: 54| Step: 0
Training loss: 4.169805234756269
Validation loss: 3.069218728985826

Epoch: 6| Step: 1
Training loss: 2.679527077724726
Validation loss: 3.038959418229217

Epoch: 6| Step: 2
Training loss: 3.368057315646801
Validation loss: 3.043521784565021

Epoch: 6| Step: 3
Training loss: 3.463334814027893
Validation loss: 3.0486782227078995

Epoch: 6| Step: 4
Training loss: 3.884881003974132
Validation loss: 3.050543659682145

Epoch: 6| Step: 5
Training loss: 3.030477838387055
Validation loss: 3.0601960104814316

Epoch: 6| Step: 6
Training loss: 3.3097254811570274
Validation loss: 3.060300736754478

Epoch: 6| Step: 7
Training loss: 3.549370379423938
Validation loss: 3.061675497522803

Epoch: 6| Step: 8
Training loss: 3.1168569136164233
Validation loss: 3.0521814776484564

Epoch: 6| Step: 9
Training loss: 3.8779564930765824
Validation loss: 3.0453259405207613

Epoch: 6| Step: 10
Training loss: 3.1376614228931574
Validation loss: 3.045157475977056

Epoch: 6| Step: 11
Training loss: 2.2285796013357357
Validation loss: 3.044981598249447

Epoch: 6| Step: 12
Training loss: 2.980967708634133
Validation loss: 3.0411616934609924

Epoch: 6| Step: 13
Training loss: 3.381389221596965
Validation loss: 3.0491135973949905

Epoch: 55| Step: 0
Training loss: 3.4967360945343495
Validation loss: 3.0434313055055813

Epoch: 6| Step: 1
Training loss: 3.4978042254268695
Validation loss: 3.045162857234542

Epoch: 6| Step: 2
Training loss: 3.1920477643753564
Validation loss: 3.0458476641896506

Epoch: 6| Step: 3
Training loss: 3.392484655942913
Validation loss: 3.0485518055570853

Epoch: 6| Step: 4
Training loss: 3.3678116717748585
Validation loss: 3.0457426892605346

Epoch: 6| Step: 5
Training loss: 2.2709047032144576
Validation loss: 3.0451075978678936

Epoch: 6| Step: 6
Training loss: 3.321164010757755
Validation loss: 3.045492195328223

Epoch: 6| Step: 7
Training loss: 3.5166210882719513
Validation loss: 3.0439970389032616

Epoch: 6| Step: 8
Training loss: 3.754546651686776
Validation loss: 3.0403490037363676

Epoch: 6| Step: 9
Training loss: 3.6313309468424393
Validation loss: 3.043297653308067

Epoch: 6| Step: 10
Training loss: 3.4423310058158374
Validation loss: 3.035213356158146

Epoch: 6| Step: 11
Training loss: 2.4846849548073484
Validation loss: 3.034702962481333

Epoch: 6| Step: 12
Training loss: 3.378746778660917
Validation loss: 3.0321445276377252

Epoch: 6| Step: 13
Training loss: 3.3463798947464674
Validation loss: 3.033375174274284

Epoch: 56| Step: 0
Training loss: 2.5993743033567553
Validation loss: 3.032918711984811

Epoch: 6| Step: 1
Training loss: 2.5469598112436582
Validation loss: 3.0289115245720826

Epoch: 6| Step: 2
Training loss: 3.436324594852967
Validation loss: 3.03257914814244

Epoch: 6| Step: 3
Training loss: 3.65329172816103
Validation loss: 3.0329003492448074

Epoch: 6| Step: 4
Training loss: 3.0074454740051015
Validation loss: 3.0326565827196372

Epoch: 6| Step: 5
Training loss: 3.6573208275985754
Validation loss: 3.0322404762812667

Epoch: 6| Step: 6
Training loss: 3.6005450154051655
Validation loss: 3.0320747893265443

Epoch: 6| Step: 7
Training loss: 3.0397393029513613
Validation loss: 3.037640442262785

Epoch: 6| Step: 8
Training loss: 3.066208443062636
Validation loss: 3.043198699626531

Epoch: 6| Step: 9
Training loss: 3.3515661990983374
Validation loss: 3.062458413908835

Epoch: 6| Step: 10
Training loss: 2.601252723556772
Validation loss: 3.0692845671343334

Epoch: 6| Step: 11
Training loss: 3.7943531342506143
Validation loss: 3.057503383384636

Epoch: 6| Step: 12
Training loss: 3.31202233667259
Validation loss: 3.035532907830887

Epoch: 6| Step: 13
Training loss: 4.801962872343784
Validation loss: 3.023231865021236

Epoch: 57| Step: 0
Training loss: 3.1796548077826423
Validation loss: 3.0240078928302365

Epoch: 6| Step: 1
Training loss: 3.2456950506315803
Validation loss: 3.025206242426334

Epoch: 6| Step: 2
Training loss: 3.944989786074413
Validation loss: 3.026241330991008

Epoch: 6| Step: 3
Training loss: 3.770227682184817
Validation loss: 3.0267287698747265

Epoch: 6| Step: 4
Training loss: 3.1221017749431277
Validation loss: 3.0259585163774085

Epoch: 6| Step: 5
Training loss: 3.4121487838486932
Validation loss: 3.0252004290733763

Epoch: 6| Step: 6
Training loss: 2.811439483756532
Validation loss: 3.025411272070847

Epoch: 6| Step: 7
Training loss: 2.4413668942140396
Validation loss: 3.0235075435212995

Epoch: 6| Step: 8
Training loss: 3.5658155037675714
Validation loss: 3.0236161757296385

Epoch: 6| Step: 9
Training loss: 2.754792632175617
Validation loss: 3.0226981500779546

Epoch: 6| Step: 10
Training loss: 3.349560261802843
Validation loss: 3.0270796923107386

Epoch: 6| Step: 11
Training loss: 3.9474560041917246
Validation loss: 3.021063845407077

Epoch: 6| Step: 12
Training loss: 3.5773741088298783
Validation loss: 3.0188998497572457

Epoch: 6| Step: 13
Training loss: 2.146989924257513
Validation loss: 3.0203685803270033

Epoch: 58| Step: 0
Training loss: 3.5154526053651822
Validation loss: 3.0209479819759792

Epoch: 6| Step: 1
Training loss: 3.192685266673828
Validation loss: 3.0211801880717366

Epoch: 6| Step: 2
Training loss: 2.5988088703689334
Validation loss: 3.031600431216058

Epoch: 6| Step: 3
Training loss: 3.612456356431732
Validation loss: 3.047779621449219

Epoch: 6| Step: 4
Training loss: 2.938529625486747
Validation loss: 3.0490374081174156

Epoch: 6| Step: 5
Training loss: 3.562389974400882
Validation loss: 3.0372348292725664

Epoch: 6| Step: 6
Training loss: 3.288308100138731
Validation loss: 3.031937579027562

Epoch: 6| Step: 7
Training loss: 3.185088198891327
Validation loss: 3.0305556294986893

Epoch: 6| Step: 8
Training loss: 3.4632440807259175
Validation loss: 3.024328294493538

Epoch: 6| Step: 9
Training loss: 3.416492705839955
Validation loss: 3.021809275950874

Epoch: 6| Step: 10
Training loss: 2.5760575761521003
Validation loss: 3.0204729377946347

Epoch: 6| Step: 11
Training loss: 3.831660914826746
Validation loss: 3.0200608914756137

Epoch: 6| Step: 12
Training loss: 3.4441083330490394
Validation loss: 3.0186960636274005

Epoch: 6| Step: 13
Training loss: 3.35259879926025
Validation loss: 3.018537054404745

Epoch: 59| Step: 0
Training loss: 3.0658048586721107
Validation loss: 3.0169069146790557

Epoch: 6| Step: 1
Training loss: 3.2363098549197638
Validation loss: 3.019836120874791

Epoch: 6| Step: 2
Training loss: 3.1999045953833787
Validation loss: 3.024283197967838

Epoch: 6| Step: 3
Training loss: 2.662580777227927
Validation loss: 3.02029263781574

Epoch: 6| Step: 4
Training loss: 4.026206950372343
Validation loss: 3.0378462158588926

Epoch: 6| Step: 5
Training loss: 2.3769953527280756
Validation loss: 3.0458150184668424

Epoch: 6| Step: 6
Training loss: 2.955953706567248
Validation loss: 3.0323136052272925

Epoch: 6| Step: 7
Training loss: 4.303989582290237
Validation loss: 3.0278354429927963

Epoch: 6| Step: 8
Training loss: 3.39358883188758
Validation loss: 3.0153059350949043

Epoch: 6| Step: 9
Training loss: 3.059185024515711
Validation loss: 3.0125757105347764

Epoch: 6| Step: 10
Training loss: 3.103272857677716
Validation loss: 3.0134553869890968

Epoch: 6| Step: 11
Training loss: 3.389030960801551
Validation loss: 3.0120747192805806

Epoch: 6| Step: 12
Training loss: 3.9663876689169855
Validation loss: 3.011933027249139

Epoch: 6| Step: 13
Training loss: 2.415374201972228
Validation loss: 3.011013455696765

Epoch: 60| Step: 0
Training loss: 3.8935566469928604
Validation loss: 3.013437448416796

Epoch: 6| Step: 1
Training loss: 2.345360672956034
Validation loss: 3.0134992010308594

Epoch: 6| Step: 2
Training loss: 3.0115437933030185
Validation loss: 3.0128082547264787

Epoch: 6| Step: 3
Training loss: 2.884750748417125
Validation loss: 3.0105190748635597

Epoch: 6| Step: 4
Training loss: 3.427793914190884
Validation loss: 3.009316387919128

Epoch: 6| Step: 5
Training loss: 2.9451515700190614
Validation loss: 3.0069578608241887

Epoch: 6| Step: 6
Training loss: 3.0979308575474263
Validation loss: 3.007759063719075

Epoch: 6| Step: 7
Training loss: 3.121729245377522
Validation loss: 3.0041196781356976

Epoch: 6| Step: 8
Training loss: 2.888394046445447
Validation loss: 3.005268354732308

Epoch: 6| Step: 9
Training loss: 3.845267639766515
Validation loss: 3.0055298531497887

Epoch: 6| Step: 10
Training loss: 3.771321653217069
Validation loss: 3.006363627649595

Epoch: 6| Step: 11
Training loss: 3.6738477236900815
Validation loss: 3.00688440083145

Epoch: 6| Step: 12
Training loss: 3.6239617274876017
Validation loss: 3.0065512130810936

Epoch: 6| Step: 13
Training loss: 2.898722755399505
Validation loss: 3.0060580300290023

Epoch: 61| Step: 0
Training loss: 3.4099699933026697
Validation loss: 3.005368946272233

Epoch: 6| Step: 1
Training loss: 2.8359396858311996
Validation loss: 3.0021997918438

Epoch: 6| Step: 2
Training loss: 3.5465238288090704
Validation loss: 3.0004504730387898

Epoch: 6| Step: 3
Training loss: 2.6806163901726423
Validation loss: 2.9999639584143534

Epoch: 6| Step: 4
Training loss: 3.6435325701637074
Validation loss: 2.999150528499549

Epoch: 6| Step: 5
Training loss: 2.7202190946245506
Validation loss: 2.9978797352144

Epoch: 6| Step: 6
Training loss: 3.820915564619706
Validation loss: 2.999327379967278

Epoch: 6| Step: 7
Training loss: 3.1563551479236645
Validation loss: 2.9974060243733187

Epoch: 6| Step: 8
Training loss: 3.364064762240516
Validation loss: 3.0006687519581052

Epoch: 6| Step: 9
Training loss: 3.598077175769437
Validation loss: 2.9966970757357063

Epoch: 6| Step: 10
Training loss: 3.7807248594213365
Validation loss: 2.9976000081726024

Epoch: 6| Step: 11
Training loss: 2.9492538349009947
Validation loss: 2.997059933274259

Epoch: 6| Step: 12
Training loss: 2.778343653790353
Validation loss: 2.9954259296913204

Epoch: 6| Step: 13
Training loss: 3.3537776713557323
Validation loss: 2.996123440434637

Epoch: 62| Step: 0
Training loss: 3.456420154763434
Validation loss: 3.004386892952805

Epoch: 6| Step: 1
Training loss: 2.5766124565505035
Validation loss: 3.0060172203828883

Epoch: 6| Step: 2
Training loss: 3.5055742833248025
Validation loss: 3.005077618052135

Epoch: 6| Step: 3
Training loss: 3.6173093046109024
Validation loss: 3.0049828351113956

Epoch: 6| Step: 4
Training loss: 3.0009449424281933
Validation loss: 2.9941890472280455

Epoch: 6| Step: 5
Training loss: 3.7282989742746153
Validation loss: 2.9926768122139933

Epoch: 6| Step: 6
Training loss: 3.7782724810797035
Validation loss: 2.9925103217036444

Epoch: 6| Step: 7
Training loss: 3.1768162015749146
Validation loss: 2.9926395139636797

Epoch: 6| Step: 8
Training loss: 3.7604088329680927
Validation loss: 2.994913833216541

Epoch: 6| Step: 9
Training loss: 2.7873488859946938
Validation loss: 2.9936612134735006

Epoch: 6| Step: 10
Training loss: 2.6140755898740182
Validation loss: 2.9933058087947804

Epoch: 6| Step: 11
Training loss: 2.9223723778706585
Validation loss: 2.9931171756899473

Epoch: 6| Step: 12
Training loss: 3.142086011859066
Validation loss: 2.992787371296743

Epoch: 6| Step: 13
Training loss: 3.644297961325392
Validation loss: 2.993385209104222

Epoch: 63| Step: 0
Training loss: 3.328422998689188
Validation loss: 2.9888000136654367

Epoch: 6| Step: 1
Training loss: 2.9332697825338987
Validation loss: 2.991123224919755

Epoch: 6| Step: 2
Training loss: 2.9067449660939637
Validation loss: 2.9914631298363217

Epoch: 6| Step: 3
Training loss: 3.685040186917806
Validation loss: 2.990076689294152

Epoch: 6| Step: 4
Training loss: 3.927594273902984
Validation loss: 2.9894150440078593

Epoch: 6| Step: 5
Training loss: 3.363258281988213
Validation loss: 2.989898843928417

Epoch: 6| Step: 6
Training loss: 3.1298311654767654
Validation loss: 2.987169221811534

Epoch: 6| Step: 7
Training loss: 3.8739990664408617
Validation loss: 2.9866727936186694

Epoch: 6| Step: 8
Training loss: 2.619037395721563
Validation loss: 2.9864531621049784

Epoch: 6| Step: 9
Training loss: 3.4928480372754587
Validation loss: 2.9886171736975466

Epoch: 6| Step: 10
Training loss: 2.954807992754834
Validation loss: 2.9876323855801865

Epoch: 6| Step: 11
Training loss: 3.3302803045296776
Validation loss: 2.9856784857886574

Epoch: 6| Step: 12
Training loss: 2.7916837283699607
Validation loss: 2.9875360795036348

Epoch: 6| Step: 13
Training loss: 3.020181800473302
Validation loss: 2.9855263367249467

Epoch: 64| Step: 0
Training loss: 3.1852937430562385
Validation loss: 2.9861050769706465

Epoch: 6| Step: 1
Training loss: 3.4409503613156187
Validation loss: 2.9838532898769183

Epoch: 6| Step: 2
Training loss: 3.8624571566381465
Validation loss: 2.984471323900272

Epoch: 6| Step: 3
Training loss: 3.2577641984391437
Validation loss: 2.9844050724537605

Epoch: 6| Step: 4
Training loss: 2.76524117602727
Validation loss: 2.9823941343922566

Epoch: 6| Step: 5
Training loss: 3.2733476212209767
Validation loss: 2.983292124464709

Epoch: 6| Step: 6
Training loss: 3.1247875904373985
Validation loss: 2.9844567519036964

Epoch: 6| Step: 7
Training loss: 3.137809896172654
Validation loss: 2.9825824683808726

Epoch: 6| Step: 8
Training loss: 3.302739139420351
Validation loss: 2.9830541210461785

Epoch: 6| Step: 9
Training loss: 3.204398148752358
Validation loss: 2.985750715067996

Epoch: 6| Step: 10
Training loss: 3.2209540663212
Validation loss: 2.9830591390862384

Epoch: 6| Step: 11
Training loss: 2.7873333184054374
Validation loss: 2.981127038818553

Epoch: 6| Step: 12
Training loss: 3.796054076313056
Validation loss: 2.979494409986543

Epoch: 6| Step: 13
Training loss: 3.077277981940729
Validation loss: 2.9808142922232888

Epoch: 65| Step: 0
Training loss: 3.6049587430458203
Validation loss: 2.981265430183059

Epoch: 6| Step: 1
Training loss: 4.113903494897763
Validation loss: 2.9817772518048935

Epoch: 6| Step: 2
Training loss: 3.687540215741708
Validation loss: 2.9767104841390535

Epoch: 6| Step: 3
Training loss: 2.917808272967546
Validation loss: 2.97935606973053

Epoch: 6| Step: 4
Training loss: 2.963332201768325
Validation loss: 2.979341269643726

Epoch: 6| Step: 5
Training loss: 3.1577912146347815
Validation loss: 2.9792833438063067

Epoch: 6| Step: 6
Training loss: 3.019473767442829
Validation loss: 2.977933366073158

Epoch: 6| Step: 7
Training loss: 2.9401849691112787
Validation loss: 2.978213949514682

Epoch: 6| Step: 8
Training loss: 2.7375084933493206
Validation loss: 2.977746485736687

Epoch: 6| Step: 9
Training loss: 3.1035183905942683
Validation loss: 2.9763983225636146

Epoch: 6| Step: 10
Training loss: 2.991327465949678
Validation loss: 2.9800813663185406

Epoch: 6| Step: 11
Training loss: 3.049321527530227
Validation loss: 2.9774540709345216

Epoch: 6| Step: 12
Training loss: 3.768637311019307
Validation loss: 2.979396452942233

Epoch: 6| Step: 13
Training loss: 3.320971327099938
Validation loss: 2.9782073265274436

Epoch: 66| Step: 0
Training loss: 2.815287501422852
Validation loss: 2.9765310667199465

Epoch: 6| Step: 1
Training loss: 2.8666041973611587
Validation loss: 2.9728210635517383

Epoch: 6| Step: 2
Training loss: 4.033667497479757
Validation loss: 2.9769366473317938

Epoch: 6| Step: 3
Training loss: 2.8927653868317686
Validation loss: 2.976504585543087

Epoch: 6| Step: 4
Training loss: 3.8218808689524644
Validation loss: 2.975273364116477

Epoch: 6| Step: 5
Training loss: 3.5961421800029525
Validation loss: 2.976621088556955

Epoch: 6| Step: 6
Training loss: 3.239576791509338
Validation loss: 2.9733416097778624

Epoch: 6| Step: 7
Training loss: 3.032901589265781
Validation loss: 2.9736540767159196

Epoch: 6| Step: 8
Training loss: 3.8109024953387998
Validation loss: 2.9727073299492073

Epoch: 6| Step: 9
Training loss: 2.9061317009588317
Validation loss: 2.975595326747077

Epoch: 6| Step: 10
Training loss: 3.5641981394242372
Validation loss: 2.9732633969470372

Epoch: 6| Step: 11
Training loss: 2.6113394463806565
Validation loss: 2.974715438170406

Epoch: 6| Step: 12
Training loss: 2.698534557229401
Validation loss: 2.969533348683298

Epoch: 6| Step: 13
Training loss: 3.3085552695242346
Validation loss: 2.9717233462337407

Epoch: 67| Step: 0
Training loss: 2.618898384788423
Validation loss: 2.971122547532441

Epoch: 6| Step: 1
Training loss: 3.1775305928243966
Validation loss: 2.971137266034604

Epoch: 6| Step: 2
Training loss: 3.14596422609432
Validation loss: 2.9704249408190524

Epoch: 6| Step: 3
Training loss: 2.147361236103584
Validation loss: 2.9704545262033286

Epoch: 6| Step: 4
Training loss: 3.603089379219727
Validation loss: 2.97043829915711

Epoch: 6| Step: 5
Training loss: 3.6999655335341735
Validation loss: 2.96981601714097

Epoch: 6| Step: 6
Training loss: 3.459079493416198
Validation loss: 2.970586626354611

Epoch: 6| Step: 7
Training loss: 3.652867505059756
Validation loss: 2.9688641062613743

Epoch: 6| Step: 8
Training loss: 3.293008281429754
Validation loss: 2.971385285730771

Epoch: 6| Step: 9
Training loss: 3.0238568313353684
Validation loss: 2.978007595310442

Epoch: 6| Step: 10
Training loss: 3.9053792974915242
Validation loss: 2.9707693670364934

Epoch: 6| Step: 11
Training loss: 2.9610238175907746
Validation loss: 2.9716843546533966

Epoch: 6| Step: 12
Training loss: 3.3675916389395066
Validation loss: 2.964411263531117

Epoch: 6| Step: 13
Training loss: 2.9331000632675552
Validation loss: 2.9657373899159163

Epoch: 68| Step: 0
Training loss: 3.60824263343437
Validation loss: 2.9665543057810133

Epoch: 6| Step: 1
Training loss: 3.0307086579176903
Validation loss: 2.965371628098304

Epoch: 6| Step: 2
Training loss: 3.752323956410552
Validation loss: 2.966600463071345

Epoch: 6| Step: 3
Training loss: 2.763956892326058
Validation loss: 2.9636503086836417

Epoch: 6| Step: 4
Training loss: 3.558160648726872
Validation loss: 2.964719671033901

Epoch: 6| Step: 5
Training loss: 3.2472121679539967
Validation loss: 2.9652298061459126

Epoch: 6| Step: 6
Training loss: 3.638755219959327
Validation loss: 2.963147503080656

Epoch: 6| Step: 7
Training loss: 3.9497871631308445
Validation loss: 2.965555778504772

Epoch: 6| Step: 8
Training loss: 2.7692158119906267
Validation loss: 2.9648911392648807

Epoch: 6| Step: 9
Training loss: 3.2905836778384674
Validation loss: 2.962140159340243

Epoch: 6| Step: 10
Training loss: 2.9403834698812963
Validation loss: 2.9618064797243178

Epoch: 6| Step: 11
Training loss: 2.883984665997886
Validation loss: 2.9601404533609625

Epoch: 6| Step: 12
Training loss: 2.8496112156758104
Validation loss: 2.9603086466066757

Epoch: 6| Step: 13
Training loss: 2.578718544809322
Validation loss: 2.960010157908332

Epoch: 69| Step: 0
Training loss: 2.843348715838569
Validation loss: 2.9629172391002596

Epoch: 6| Step: 1
Training loss: 3.064641087288442
Validation loss: 2.9600780985688697

Epoch: 6| Step: 2
Training loss: 3.597455444696252
Validation loss: 2.9631852279237734

Epoch: 6| Step: 3
Training loss: 2.70865061931033
Validation loss: 2.9665987744869566

Epoch: 6| Step: 4
Training loss: 2.879741738978572
Validation loss: 2.9601399614424118

Epoch: 6| Step: 5
Training loss: 2.807694462251791
Validation loss: 2.959601268496691

Epoch: 6| Step: 6
Training loss: 2.952927194257827
Validation loss: 2.958620623917664

Epoch: 6| Step: 7
Training loss: 3.7242848215390025
Validation loss: 2.957735578110115

Epoch: 6| Step: 8
Training loss: 3.4758563406771272
Validation loss: 2.960093225343042

Epoch: 6| Step: 9
Training loss: 3.2331694046885424
Validation loss: 2.957712193756682

Epoch: 6| Step: 10
Training loss: 3.583189466087152
Validation loss: 2.956003170622228

Epoch: 6| Step: 11
Training loss: 3.6063444287186166
Validation loss: 2.9576158677559934

Epoch: 6| Step: 12
Training loss: 3.215106865277011
Validation loss: 2.9609130127609866

Epoch: 6| Step: 13
Training loss: 3.6341894022029155
Validation loss: 2.958873679211371

Epoch: 70| Step: 0
Training loss: 2.6045557163816495
Validation loss: 2.9610186972726815

Epoch: 6| Step: 1
Training loss: 3.3675868246755742
Validation loss: 2.959642045988051

Epoch: 6| Step: 2
Training loss: 3.992237904448803
Validation loss: 2.9623871158325352

Epoch: 6| Step: 3
Training loss: 2.7225126340798878
Validation loss: 2.958797077630141

Epoch: 6| Step: 4
Training loss: 3.4963272442977575
Validation loss: 2.9630638948662953

Epoch: 6| Step: 5
Training loss: 3.4602109262638656
Validation loss: 2.9570323510445022

Epoch: 6| Step: 6
Training loss: 3.7493000648871115
Validation loss: 2.956566567420476

Epoch: 6| Step: 7
Training loss: 3.052441954564628
Validation loss: 2.95559386044441

Epoch: 6| Step: 8
Training loss: 3.1633480819610234
Validation loss: 2.9547888704218175

Epoch: 6| Step: 9
Training loss: 3.1334173137151153
Validation loss: 2.9558533605247734

Epoch: 6| Step: 10
Training loss: 3.077323228235474
Validation loss: 2.955487579465885

Epoch: 6| Step: 11
Training loss: 3.2505636460041254
Validation loss: 2.9541979032932986

Epoch: 6| Step: 12
Training loss: 2.927197346667192
Validation loss: 2.9535060926839667

Epoch: 6| Step: 13
Training loss: 3.0445752977371585
Validation loss: 2.9557058534637437

Epoch: 71| Step: 0
Training loss: 3.445634407350294
Validation loss: 2.9547032105684177

Epoch: 6| Step: 1
Training loss: 2.715375274659594
Validation loss: 2.954702106920686

Epoch: 6| Step: 2
Training loss: 3.639515982086396
Validation loss: 2.9503587600916408

Epoch: 6| Step: 3
Training loss: 4.064663120401079
Validation loss: 2.9584061265441988

Epoch: 6| Step: 4
Training loss: 3.274738353731545
Validation loss: 2.9649983265157913

Epoch: 6| Step: 5
Training loss: 2.3852420615270136
Validation loss: 2.9775153506551693

Epoch: 6| Step: 6
Training loss: 3.0076130590330616
Validation loss: 2.9879475948241248

Epoch: 6| Step: 7
Training loss: 3.4606878392950904
Validation loss: 3.005555089150467

Epoch: 6| Step: 8
Training loss: 3.4236005499631537
Validation loss: 2.9789589682497657

Epoch: 6| Step: 9
Training loss: 3.69529649920558
Validation loss: 2.953580013166428

Epoch: 6| Step: 10
Training loss: 3.3578244911572623
Validation loss: 2.948224438215225

Epoch: 6| Step: 11
Training loss: 2.6576965880866448
Validation loss: 2.947669399154056

Epoch: 6| Step: 12
Training loss: 3.0877026881356024
Validation loss: 2.9515464944920735

Epoch: 6| Step: 13
Training loss: 2.5529276067658015
Validation loss: 2.9534105617618542

Epoch: 72| Step: 0
Training loss: 2.4176439304367054
Validation loss: 2.957504155102135

Epoch: 6| Step: 1
Training loss: 2.6543760084379797
Validation loss: 2.957815032738269

Epoch: 6| Step: 2
Training loss: 3.643890095499063
Validation loss: 2.9542197421625542

Epoch: 6| Step: 3
Training loss: 3.090637953743629
Validation loss: 2.9563606975647505

Epoch: 6| Step: 4
Training loss: 3.185893981845914
Validation loss: 2.955685798457321

Epoch: 6| Step: 5
Training loss: 3.623868042048667
Validation loss: 2.952265618575497

Epoch: 6| Step: 6
Training loss: 2.8744123106988275
Validation loss: 2.952585654080338

Epoch: 6| Step: 7
Training loss: 3.587033970565884
Validation loss: 2.950160528167065

Epoch: 6| Step: 8
Training loss: 3.1348158217359523
Validation loss: 2.9486119356196863

Epoch: 6| Step: 9
Training loss: 3.311010061623768
Validation loss: 2.948364940896288

Epoch: 6| Step: 10
Training loss: 3.5317628201159987
Validation loss: 2.947188973968422

Epoch: 6| Step: 11
Training loss: 3.264672099263638
Validation loss: 2.9466119317732447

Epoch: 6| Step: 12
Training loss: 3.6938951286295985
Validation loss: 2.9466670154646866

Epoch: 6| Step: 13
Training loss: 2.821761923855277
Validation loss: 2.9460828251457096

Epoch: 73| Step: 0
Training loss: 3.4565564535357285
Validation loss: 2.9460215860251875

Epoch: 6| Step: 1
Training loss: 4.055493930598117
Validation loss: 2.9452310055104287

Epoch: 6| Step: 2
Training loss: 3.6400922786627508
Validation loss: 2.943177379209065

Epoch: 6| Step: 3
Training loss: 3.8482759702781726
Validation loss: 2.9432663830076224

Epoch: 6| Step: 4
Training loss: 3.2688474680736097
Validation loss: 2.9443604929492597

Epoch: 6| Step: 5
Training loss: 3.2876933457989574
Validation loss: 2.9408030026243517

Epoch: 6| Step: 6
Training loss: 2.863426131971425
Validation loss: 2.942961639528377

Epoch: 6| Step: 7
Training loss: 2.4023931730815518
Validation loss: 2.942543062750244

Epoch: 6| Step: 8
Training loss: 2.7981315645776106
Validation loss: 2.960366935064307

Epoch: 6| Step: 9
Training loss: 3.5643725911278956
Validation loss: 2.9699775139877347

Epoch: 6| Step: 10
Training loss: 3.1747543720539984
Validation loss: 2.966439056329587

Epoch: 6| Step: 11
Training loss: 3.1341549857937125
Validation loss: 2.960746263495244

Epoch: 6| Step: 12
Training loss: 2.962116580407546
Validation loss: 2.9564979616252627

Epoch: 6| Step: 13
Training loss: 1.0777363283886963
Validation loss: 2.948315623464904

Epoch: 74| Step: 0
Training loss: 3.2714817513982015
Validation loss: 2.945327956767643

Epoch: 6| Step: 1
Training loss: 3.504968114427619
Validation loss: 2.9437140230648264

Epoch: 6| Step: 2
Training loss: 2.7617598426707684
Validation loss: 2.937067159243792

Epoch: 6| Step: 3
Training loss: 3.7633494232572615
Validation loss: 2.9395744820060483

Epoch: 6| Step: 4
Training loss: 3.6703013842573933
Validation loss: 2.9379926768870157

Epoch: 6| Step: 5
Training loss: 3.314422625264797
Validation loss: 2.939574579682684

Epoch: 6| Step: 6
Training loss: 2.9868093418488675
Validation loss: 2.9434395495353165

Epoch: 6| Step: 7
Training loss: 2.51527032662078
Validation loss: 2.9436588797605245

Epoch: 6| Step: 8
Training loss: 2.9169374249441895
Validation loss: 2.9427283873416035

Epoch: 6| Step: 9
Training loss: 3.6176928832455295
Validation loss: 2.945377673252783

Epoch: 6| Step: 10
Training loss: 3.18586928597201
Validation loss: 2.9448118215409975

Epoch: 6| Step: 11
Training loss: 3.429618400277354
Validation loss: 2.9454435970676345

Epoch: 6| Step: 12
Training loss: 3.225399371118319
Validation loss: 2.940238709261843

Epoch: 6| Step: 13
Training loss: 2.6317245091787083
Validation loss: 2.938954147228547

Epoch: 75| Step: 0
Training loss: 4.017271424243689
Validation loss: 2.93708149239924

Epoch: 6| Step: 1
Training loss: 3.6489490093286676
Validation loss: 2.9333313979937676

Epoch: 6| Step: 2
Training loss: 3.8512108818328366
Validation loss: 2.9344130428131523

Epoch: 6| Step: 3
Training loss: 2.841674550363413
Validation loss: 2.942574991524193

Epoch: 6| Step: 4
Training loss: 2.983718560208587
Validation loss: 2.94242661667009

Epoch: 6| Step: 5
Training loss: 2.923735164165979
Validation loss: 2.948638137811172

Epoch: 6| Step: 6
Training loss: 2.6089583195565993
Validation loss: 2.956847388891078

Epoch: 6| Step: 7
Training loss: 3.150686062170193
Validation loss: 2.9666511374391242

Epoch: 6| Step: 8
Training loss: 2.898273638183101
Validation loss: 2.9506800988816972

Epoch: 6| Step: 9
Training loss: 3.3230467544650706
Validation loss: 2.9479846576181186

Epoch: 6| Step: 10
Training loss: 3.092413719657412
Validation loss: 2.941188851559064

Epoch: 6| Step: 11
Training loss: 3.3285616735973824
Validation loss: 2.9318983925740025

Epoch: 6| Step: 12
Training loss: 2.8077314854452076
Validation loss: 2.9311459096105144

Epoch: 6| Step: 13
Training loss: 3.4759888593629062
Validation loss: 2.930222094692102

Epoch: 76| Step: 0
Training loss: 3.526144201834194
Validation loss: 2.9312318310803245

Epoch: 6| Step: 1
Training loss: 2.9054584040384497
Validation loss: 2.93215220829404

Epoch: 6| Step: 2
Training loss: 3.7873574107306287
Validation loss: 2.9331882812088046

Epoch: 6| Step: 3
Training loss: 3.5352549839458076
Validation loss: 2.9317664222409454

Epoch: 6| Step: 4
Training loss: 3.4630123489252234
Validation loss: 2.9339345039333597

Epoch: 6| Step: 5
Training loss: 3.7122539554327996
Validation loss: 2.934250307601367

Epoch: 6| Step: 6
Training loss: 3.3108271567377225
Validation loss: 2.932520174441881

Epoch: 6| Step: 7
Training loss: 2.5142807300939327
Validation loss: 2.9315442844731727

Epoch: 6| Step: 8
Training loss: 2.7287788892152487
Validation loss: 2.933789253834388

Epoch: 6| Step: 9
Training loss: 2.969918432689048
Validation loss: 2.9335642997316813

Epoch: 6| Step: 10
Training loss: 2.7622933875791906
Validation loss: 2.930850999816877

Epoch: 6| Step: 11
Training loss: 3.066483689806393
Validation loss: 2.9315289019468613

Epoch: 6| Step: 12
Training loss: 3.345004978147717
Validation loss: 2.9294167101557522

Epoch: 6| Step: 13
Training loss: 3.164336769555685
Validation loss: 2.930878099039372

Epoch: 77| Step: 0
Training loss: 3.178709587413308
Validation loss: 2.9290259485981798

Epoch: 6| Step: 1
Training loss: 3.647984740041304
Validation loss: 2.931635729695938

Epoch: 6| Step: 2
Training loss: 3.5087179871645637
Validation loss: 2.929461030253251

Epoch: 6| Step: 3
Training loss: 3.5446186703148106
Validation loss: 2.9294844379671785

Epoch: 6| Step: 4
Training loss: 3.347202835624836
Validation loss: 2.9292580102832577

Epoch: 6| Step: 5
Training loss: 3.34189732644175
Validation loss: 2.9308446782908577

Epoch: 6| Step: 6
Training loss: 3.047665537468225
Validation loss: 2.9303898372689225

Epoch: 6| Step: 7
Training loss: 3.0246557496969477
Validation loss: 2.930876064485226

Epoch: 6| Step: 8
Training loss: 2.5316735372477313
Validation loss: 2.92737220900891

Epoch: 6| Step: 9
Training loss: 2.8456667633980097
Validation loss: 2.9321363026132894

Epoch: 6| Step: 10
Training loss: 3.2762980560422714
Validation loss: 2.928878014742972

Epoch: 6| Step: 11
Training loss: 3.4779280477389154
Validation loss: 2.928807943685817

Epoch: 6| Step: 12
Training loss: 2.9161861750505835
Validation loss: 2.926247590229901

Epoch: 6| Step: 13
Training loss: 3.165079890443624
Validation loss: 2.9264274186032364

Epoch: 78| Step: 0
Training loss: 3.6054117481358756
Validation loss: 2.9249457384518758

Epoch: 6| Step: 1
Training loss: 2.7113503793062255
Validation loss: 2.924965573004741

Epoch: 6| Step: 2
Training loss: 2.9318551551148855
Validation loss: 2.924226400043783

Epoch: 6| Step: 3
Training loss: 2.3701574245914956
Validation loss: 2.9278949751867263

Epoch: 6| Step: 4
Training loss: 3.40054178970072
Validation loss: 2.926511292096925

Epoch: 6| Step: 5
Training loss: 3.359523610221288
Validation loss: 2.9244740641818274

Epoch: 6| Step: 6
Training loss: 3.5862172667963064
Validation loss: 2.929727575540753

Epoch: 6| Step: 7
Training loss: 2.9790296367440057
Validation loss: 2.929581317905264

Epoch: 6| Step: 8
Training loss: 3.011108178219026
Validation loss: 2.9333613644889187

Epoch: 6| Step: 9
Training loss: 3.7564980474187966
Validation loss: 2.925924172712506

Epoch: 6| Step: 10
Training loss: 2.861915335436573
Validation loss: 2.9272035289357556

Epoch: 6| Step: 11
Training loss: 3.4032719744146127
Validation loss: 2.9263524644456718

Epoch: 6| Step: 12
Training loss: 3.47806377785432
Validation loss: 2.9200706717018554

Epoch: 6| Step: 13
Training loss: 3.201923721958447
Validation loss: 2.9194232594651983

Epoch: 79| Step: 0
Training loss: 3.4219664121637083
Validation loss: 2.9202731803649242

Epoch: 6| Step: 1
Training loss: 3.182087810040846
Validation loss: 2.921006384239518

Epoch: 6| Step: 2
Training loss: 3.353352671037232
Validation loss: 2.9196175170008654

Epoch: 6| Step: 3
Training loss: 3.2173002366873193
Validation loss: 2.9210408794522373

Epoch: 6| Step: 4
Training loss: 2.9929591844645334
Validation loss: 2.921025144967512

Epoch: 6| Step: 5
Training loss: 3.082075962375685
Validation loss: 2.9208955253262117

Epoch: 6| Step: 6
Training loss: 3.2851751193163503
Validation loss: 2.9211653305529373

Epoch: 6| Step: 7
Training loss: 3.4250818841432005
Validation loss: 2.9191740585169437

Epoch: 6| Step: 8
Training loss: 3.5990177191965618
Validation loss: 2.9204670003940283

Epoch: 6| Step: 9
Training loss: 2.9724939129047616
Validation loss: 2.9187991654131995

Epoch: 6| Step: 10
Training loss: 2.6784830750925286
Validation loss: 2.916794770294431

Epoch: 6| Step: 11
Training loss: 2.947778777187712
Validation loss: 2.918976693145311

Epoch: 6| Step: 12
Training loss: 3.6374913428554225
Validation loss: 2.917830498419139

Epoch: 6| Step: 13
Training loss: 2.8349153552462782
Validation loss: 2.9161950153404717

Epoch: 80| Step: 0
Training loss: 3.2966051036408026
Validation loss: 2.9167160422603597

Epoch: 6| Step: 1
Training loss: 3.2242574147336382
Validation loss: 2.9211361428909717

Epoch: 6| Step: 2
Training loss: 3.461271455036316
Validation loss: 2.925331512587831

Epoch: 6| Step: 3
Training loss: 3.0997604400609093
Validation loss: 2.9212995024605286

Epoch: 6| Step: 4
Training loss: 2.725352371251349
Validation loss: 2.929931675952442

Epoch: 6| Step: 5
Training loss: 3.554442546075895
Validation loss: 2.941868330431585

Epoch: 6| Step: 6
Training loss: 3.1281647488167477
Validation loss: 2.967106319335764

Epoch: 6| Step: 7
Training loss: 3.103203250632141
Validation loss: 2.963517550720978

Epoch: 6| Step: 8
Training loss: 3.685629418706679
Validation loss: 2.937115195681958

Epoch: 6| Step: 9
Training loss: 2.943566571329936
Validation loss: 2.919234787692271

Epoch: 6| Step: 10
Training loss: 2.7589953428134417
Validation loss: 2.917087899537848

Epoch: 6| Step: 11
Training loss: 3.262354330852076
Validation loss: 2.912998036607582

Epoch: 6| Step: 12
Training loss: 3.6012010372266725
Validation loss: 2.9134353569436016

Epoch: 6| Step: 13
Training loss: 2.7129381696079027
Validation loss: 2.9120391601527746

Epoch: 81| Step: 0
Training loss: 2.6674754187926983
Validation loss: 2.914320106977852

Epoch: 6| Step: 1
Training loss: 3.3734033834650194
Validation loss: 2.915496342333806

Epoch: 6| Step: 2
Training loss: 2.7512254585443694
Validation loss: 2.9160663608097623

Epoch: 6| Step: 3
Training loss: 2.996756707841197
Validation loss: 2.919590681175718

Epoch: 6| Step: 4
Training loss: 2.8144689661410105
Validation loss: 2.918806830065464

Epoch: 6| Step: 5
Training loss: 3.545615220374962
Validation loss: 2.9171633729610837

Epoch: 6| Step: 6
Training loss: 3.826587601840646
Validation loss: 2.915342957566937

Epoch: 6| Step: 7
Training loss: 2.584436632226384
Validation loss: 2.912578971067142

Epoch: 6| Step: 8
Training loss: 3.624763217953756
Validation loss: 2.9107619938082534

Epoch: 6| Step: 9
Training loss: 3.4508300335618136
Validation loss: 2.908866970795575

Epoch: 6| Step: 10
Training loss: 3.647920428930783
Validation loss: 2.907603967852481

Epoch: 6| Step: 11
Training loss: 2.875584086919105
Validation loss: 2.9075759666211454

Epoch: 6| Step: 12
Training loss: 2.9936147129653503
Validation loss: 2.90761254680163

Epoch: 6| Step: 13
Training loss: 3.5733480091173173
Validation loss: 2.9057722683683855

Epoch: 82| Step: 0
Training loss: 2.562644396179371
Validation loss: 2.9072250457750566

Epoch: 6| Step: 1
Training loss: 3.183251335592551
Validation loss: 2.9043778533308244

Epoch: 6| Step: 2
Training loss: 3.235100264019914
Validation loss: 2.905090684762154

Epoch: 6| Step: 3
Training loss: 3.6491230682001006
Validation loss: 2.914464293676911

Epoch: 6| Step: 4
Training loss: 3.80850360470241
Validation loss: 2.917376885030869

Epoch: 6| Step: 5
Training loss: 3.4136292206648275
Validation loss: 2.935655854128572

Epoch: 6| Step: 6
Training loss: 2.985094552898801
Validation loss: 2.9239330193608386

Epoch: 6| Step: 7
Training loss: 3.439924737417474
Validation loss: 2.913291434352824

Epoch: 6| Step: 8
Training loss: 2.47350789570594
Validation loss: 2.9023036125641832

Epoch: 6| Step: 9
Training loss: 2.6343986645921924
Validation loss: 2.9029487431228085

Epoch: 6| Step: 10
Training loss: 3.512347376212456
Validation loss: 2.9036843924397275

Epoch: 6| Step: 11
Training loss: 3.020676882847023
Validation loss: 2.905143130944212

Epoch: 6| Step: 12
Training loss: 3.1633887809929266
Validation loss: 2.9104705290676574

Epoch: 6| Step: 13
Training loss: 3.548557504214603
Validation loss: 2.916857038751325

Epoch: 83| Step: 0
Training loss: 4.144497194428886
Validation loss: 2.9311745506718343

Epoch: 6| Step: 1
Training loss: 3.6199828319247835
Validation loss: 2.9157687239138035

Epoch: 6| Step: 2
Training loss: 3.3774961494971634
Validation loss: 2.904644767486042

Epoch: 6| Step: 3
Training loss: 1.974882474855085
Validation loss: 2.9040011578071705

Epoch: 6| Step: 4
Training loss: 2.247405145359896
Validation loss: 2.9021794462238146

Epoch: 6| Step: 5
Training loss: 2.6699656306422814
Validation loss: 2.899532303173587

Epoch: 6| Step: 6
Training loss: 3.921799374037407
Validation loss: 2.8990778517364393

Epoch: 6| Step: 7
Training loss: 3.0825649713133645
Validation loss: 2.8980264693156905

Epoch: 6| Step: 8
Training loss: 2.972308465611551
Validation loss: 2.8978385070856096

Epoch: 6| Step: 9
Training loss: 3.479385155919422
Validation loss: 2.898215573704385

Epoch: 6| Step: 10
Training loss: 3.156057219708202
Validation loss: 2.894037994346884

Epoch: 6| Step: 11
Training loss: 3.1924080554504437
Validation loss: 2.8955071325238553

Epoch: 6| Step: 12
Training loss: 3.3091730648745186
Validation loss: 2.897931616580116

Epoch: 6| Step: 13
Training loss: 2.7466338970797333
Validation loss: 2.9019360553858147

Epoch: 84| Step: 0
Training loss: 2.788638812028226
Validation loss: 2.9129295866402627

Epoch: 6| Step: 1
Training loss: 3.5202844556833446
Validation loss: 2.9253024295930756

Epoch: 6| Step: 2
Training loss: 3.0062529248641727
Validation loss: 2.903873169869607

Epoch: 6| Step: 3
Training loss: 3.1529504128430514
Validation loss: 2.893006825177762

Epoch: 6| Step: 4
Training loss: 2.748375239271571
Validation loss: 2.8944851940544574

Epoch: 6| Step: 5
Training loss: 3.447747786305378
Validation loss: 2.891853523322602

Epoch: 6| Step: 6
Training loss: 3.304364127712499
Validation loss: 2.909337677964123

Epoch: 6| Step: 7
Training loss: 3.915031998309915
Validation loss: 2.924473041170825

Epoch: 6| Step: 8
Training loss: 3.416432550984615
Validation loss: 2.920071496085402

Epoch: 6| Step: 9
Training loss: 3.0254122177348393
Validation loss: 2.8977017970501913

Epoch: 6| Step: 10
Training loss: 3.452544150543219
Validation loss: 2.894897381097633

Epoch: 6| Step: 11
Training loss: 3.1537199549806827
Validation loss: 2.8944083861639034

Epoch: 6| Step: 12
Training loss: 2.260700741217004
Validation loss: 2.893983859567566

Epoch: 6| Step: 13
Training loss: 3.28720453479312
Validation loss: 2.897061913684611

Epoch: 85| Step: 0
Training loss: 3.0297481316356816
Validation loss: 2.90730930922829

Epoch: 6| Step: 1
Training loss: 2.769751966368143
Validation loss: 2.894941545131818

Epoch: 6| Step: 2
Training loss: 3.405846808132854
Validation loss: 2.8986245318793773

Epoch: 6| Step: 3
Training loss: 2.9372564985927583
Validation loss: 2.8967594239647956

Epoch: 6| Step: 4
Training loss: 3.377181443129299
Validation loss: 2.895102010117687

Epoch: 6| Step: 5
Training loss: 2.9152816390380036
Validation loss: 2.8942084231293013

Epoch: 6| Step: 6
Training loss: 2.909339165390048
Validation loss: 2.8956917755970073

Epoch: 6| Step: 7
Training loss: 3.3924526088162184
Validation loss: 2.8942696159155457

Epoch: 6| Step: 8
Training loss: 3.508502985702534
Validation loss: 2.892942987934071

Epoch: 6| Step: 9
Training loss: 2.5152666298684587
Validation loss: 2.8959881208590086

Epoch: 6| Step: 10
Training loss: 3.469461453995666
Validation loss: 2.892119194690237

Epoch: 6| Step: 11
Training loss: 3.4394319133981783
Validation loss: 2.8928445256303448

Epoch: 6| Step: 12
Training loss: 3.4471181692082085
Validation loss: 2.8915726535904365

Epoch: 6| Step: 13
Training loss: 3.5822286603436964
Validation loss: 2.891024159390516

Epoch: 86| Step: 0
Training loss: 3.0744635013157744
Validation loss: 2.8932956392448834

Epoch: 6| Step: 1
Training loss: 2.7935761331480364
Validation loss: 2.895294327560969

Epoch: 6| Step: 2
Training loss: 3.72363959951355
Validation loss: 2.8992672987192525

Epoch: 6| Step: 3
Training loss: 2.49131984614695
Validation loss: 2.8971181801751817

Epoch: 6| Step: 4
Training loss: 3.3899102226680022
Validation loss: 2.901090854863962

Epoch: 6| Step: 5
Training loss: 2.633086781689591
Validation loss: 2.904536140293127

Epoch: 6| Step: 6
Training loss: 3.426655813217292
Validation loss: 2.8938328816891157

Epoch: 6| Step: 7
Training loss: 3.7327035650914193
Validation loss: 2.8968315083281837

Epoch: 6| Step: 8
Training loss: 3.573493725559933
Validation loss: 2.9021910030707554

Epoch: 6| Step: 9
Training loss: 2.942178450057444
Validation loss: 2.8935725789879903

Epoch: 6| Step: 10
Training loss: 2.637854573068278
Validation loss: 2.88791762735263

Epoch: 6| Step: 11
Training loss: 3.732369239392072
Validation loss: 2.8905733138820557

Epoch: 6| Step: 12
Training loss: 3.212551630102498
Validation loss: 2.89329513418924

Epoch: 6| Step: 13
Training loss: 2.610584823741271
Validation loss: 2.885221897148768

Epoch: 87| Step: 0
Training loss: 3.6277823458051004
Validation loss: 2.8903372007428634

Epoch: 6| Step: 1
Training loss: 3.0635838050542734
Validation loss: 2.8866517683630533

Epoch: 6| Step: 2
Training loss: 2.7730472773728843
Validation loss: 2.8859706187135505

Epoch: 6| Step: 3
Training loss: 2.5321156469755097
Validation loss: 2.8862649474678483

Epoch: 6| Step: 4
Training loss: 3.5417206404818047
Validation loss: 2.883582156634477

Epoch: 6| Step: 5
Training loss: 3.528671943971469
Validation loss: 2.8853235241193786

Epoch: 6| Step: 6
Training loss: 3.1636655205247024
Validation loss: 2.882498021156554

Epoch: 6| Step: 7
Training loss: 3.3111828758547173
Validation loss: 2.8846116335465553

Epoch: 6| Step: 8
Training loss: 3.299008659811642
Validation loss: 2.883873591137719

Epoch: 6| Step: 9
Training loss: 2.756290696723804
Validation loss: 2.882709154389278

Epoch: 6| Step: 10
Training loss: 2.738384163265366
Validation loss: 2.88627946184787

Epoch: 6| Step: 11
Training loss: 3.639715383951316
Validation loss: 2.8836045516464215

Epoch: 6| Step: 12
Training loss: 2.9692946085066962
Validation loss: 2.8835533718096897

Epoch: 6| Step: 13
Training loss: 3.4353364551465106
Validation loss: 2.8826926255065843

Epoch: 88| Step: 0
Training loss: 3.4093409521708757
Validation loss: 2.8857358426707127

Epoch: 6| Step: 1
Training loss: 2.529516497764618
Validation loss: 2.885703388055511

Epoch: 6| Step: 2
Training loss: 3.331285865118261
Validation loss: 2.8908355192791286

Epoch: 6| Step: 3
Training loss: 3.2507252984250012
Validation loss: 2.8915100232777635

Epoch: 6| Step: 4
Training loss: 3.218352802546314
Validation loss: 2.8840262148539537

Epoch: 6| Step: 5
Training loss: 3.404304999004219
Validation loss: 2.8852467033557563

Epoch: 6| Step: 6
Training loss: 3.5847443899968336
Validation loss: 2.8763412942107065

Epoch: 6| Step: 7
Training loss: 3.1234685578550616
Validation loss: 2.877571452254644

Epoch: 6| Step: 8
Training loss: 3.5916649118464905
Validation loss: 2.877640166878989

Epoch: 6| Step: 9
Training loss: 2.84531552326643
Validation loss: 2.8787292719042528

Epoch: 6| Step: 10
Training loss: 2.9878665012937278
Validation loss: 2.8775665291135493

Epoch: 6| Step: 11
Training loss: 2.926344935634214
Validation loss: 2.877524102976931

Epoch: 6| Step: 12
Training loss: 3.106320208057333
Validation loss: 2.8755229181919413

Epoch: 6| Step: 13
Training loss: 2.930089653388116
Validation loss: 2.874943121391595

Epoch: 89| Step: 0
Training loss: 3.547227749529377
Validation loss: 2.8777523660571855

Epoch: 6| Step: 1
Training loss: 2.8394723095720042
Validation loss: 2.874427824968768

Epoch: 6| Step: 2
Training loss: 3.5237714858683926
Validation loss: 2.876930628309327

Epoch: 6| Step: 3
Training loss: 3.1035816913004233
Validation loss: 2.8750001096792324

Epoch: 6| Step: 4
Training loss: 3.0233788299782325
Validation loss: 2.8772760096751777

Epoch: 6| Step: 5
Training loss: 3.1251329012266966
Validation loss: 2.875451623614228

Epoch: 6| Step: 6
Training loss: 3.4557060158516326
Validation loss: 2.8732211997841692

Epoch: 6| Step: 7
Training loss: 2.997106746428513
Validation loss: 2.871297286169426

Epoch: 6| Step: 8
Training loss: 2.789763375916229
Validation loss: 2.8719444212862255

Epoch: 6| Step: 9
Training loss: 2.9489458172549505
Validation loss: 2.8748275755066492

Epoch: 6| Step: 10
Training loss: 3.002696732580012
Validation loss: 2.872710587536748

Epoch: 6| Step: 11
Training loss: 2.6714159476358605
Validation loss: 2.8731876348095207

Epoch: 6| Step: 12
Training loss: 3.8100300276566728
Validation loss: 2.8706631330069774

Epoch: 6| Step: 13
Training loss: 3.5642198125697093
Validation loss: 2.8736994237291937

Epoch: 90| Step: 0
Training loss: 3.4794243509648135
Validation loss: 2.879604139524654

Epoch: 6| Step: 1
Training loss: 3.5523453929956887
Validation loss: 2.8844379598293317

Epoch: 6| Step: 2
Training loss: 3.089422416654976
Validation loss: 2.897939290865092

Epoch: 6| Step: 3
Training loss: 3.252941121264805
Validation loss: 2.923819494550145

Epoch: 6| Step: 4
Training loss: 2.9647694454004148
Validation loss: 2.924052865466028

Epoch: 6| Step: 5
Training loss: 3.6006908230756705
Validation loss: 2.9167156555233795

Epoch: 6| Step: 6
Training loss: 3.0235518401849246
Validation loss: 2.889642048016757

Epoch: 6| Step: 7
Training loss: 3.229772268953611
Validation loss: 2.87598172369156

Epoch: 6| Step: 8
Training loss: 3.349230117013309
Validation loss: 2.867529394337048

Epoch: 6| Step: 9
Training loss: 3.552655722998955
Validation loss: 2.8689423893741988

Epoch: 6| Step: 10
Training loss: 2.99786014534531
Validation loss: 2.8698634898405895

Epoch: 6| Step: 11
Training loss: 2.889928125457881
Validation loss: 2.8732756784598696

Epoch: 6| Step: 12
Training loss: 2.3366671542150375
Validation loss: 2.8726891704677175

Epoch: 6| Step: 13
Training loss: 2.679662053735322
Validation loss: 2.8724205622857464

Epoch: 91| Step: 0
Training loss: 2.647254341982927
Validation loss: 2.8756783716337826

Epoch: 6| Step: 1
Training loss: 3.7344360346574743
Validation loss: 2.8744814932619005

Epoch: 6| Step: 2
Training loss: 3.509519166099778
Validation loss: 2.8809695151555466

Epoch: 6| Step: 3
Training loss: 2.8217483204809324
Validation loss: 2.874537235876266

Epoch: 6| Step: 4
Training loss: 2.824656345766629
Validation loss: 2.881988104268676

Epoch: 6| Step: 5
Training loss: 3.529726628208657
Validation loss: 2.873246723464106

Epoch: 6| Step: 6
Training loss: 3.2714346719638536
Validation loss: 2.8738063422674105

Epoch: 6| Step: 7
Training loss: 3.55029924770152
Validation loss: 2.870956967452164

Epoch: 6| Step: 8
Training loss: 1.8592593373460038
Validation loss: 2.8668253273304005

Epoch: 6| Step: 9
Training loss: 3.397951990283483
Validation loss: 2.867439242202958

Epoch: 6| Step: 10
Training loss: 3.4939206322235403
Validation loss: 2.8664623325991427

Epoch: 6| Step: 11
Training loss: 3.4583576308779516
Validation loss: 2.8677258190278128

Epoch: 6| Step: 12
Training loss: 3.458559342931195
Validation loss: 2.8635177094970943

Epoch: 6| Step: 13
Training loss: 1.1208414465079992
Validation loss: 2.864791034466157

Epoch: 92| Step: 0
Training loss: 2.950966182182749
Validation loss: 2.86494567965918

Epoch: 6| Step: 1
Training loss: 3.1017491358951594
Validation loss: 2.862567246893802

Epoch: 6| Step: 2
Training loss: 3.2587744301252255
Validation loss: 2.860476166087866

Epoch: 6| Step: 3
Training loss: 3.082093444892896
Validation loss: 2.862422355483302

Epoch: 6| Step: 4
Training loss: 4.056059206573721
Validation loss: 2.8607810271051757

Epoch: 6| Step: 5
Training loss: 2.8176788967848987
Validation loss: 2.861875831356591

Epoch: 6| Step: 6
Training loss: 3.366472987152872
Validation loss: 2.861733139152546

Epoch: 6| Step: 7
Training loss: 3.1026852206779343
Validation loss: 2.8627354710380617

Epoch: 6| Step: 8
Training loss: 2.8102382466600093
Validation loss: 2.864608280076987

Epoch: 6| Step: 9
Training loss: 2.8499627629574635
Validation loss: 2.8639224336932627

Epoch: 6| Step: 10
Training loss: 2.9368218795800964
Validation loss: 2.8642010177292927

Epoch: 6| Step: 11
Training loss: 3.3752093779996692
Validation loss: 2.8704930451462185

Epoch: 6| Step: 12
Training loss: 2.980958750831302
Validation loss: 2.8731341457878323

Epoch: 6| Step: 13
Training loss: 3.5759665296383507
Validation loss: 2.864333863493724

Epoch: 93| Step: 0
Training loss: 3.0385032472654325
Validation loss: 2.8562371887779934

Epoch: 6| Step: 1
Training loss: 2.7684035487019547
Validation loss: 2.857156386944017

Epoch: 6| Step: 2
Training loss: 3.5989771767475824
Validation loss: 2.857610081505318

Epoch: 6| Step: 3
Training loss: 3.2239841014384867
Validation loss: 2.8568341160524304

Epoch: 6| Step: 4
Training loss: 3.307756013887982
Validation loss: 2.859955729863261

Epoch: 6| Step: 5
Training loss: 3.3627573418256693
Validation loss: 2.8580303288287783

Epoch: 6| Step: 6
Training loss: 2.935541027314535
Validation loss: 2.8599324908135064

Epoch: 6| Step: 7
Training loss: 2.7469927210313854
Validation loss: 2.8603036189478983

Epoch: 6| Step: 8
Training loss: 2.9026389709901306
Validation loss: 2.8582113646144753

Epoch: 6| Step: 9
Training loss: 2.95836404775516
Validation loss: 2.8592075716013166

Epoch: 6| Step: 10
Training loss: 3.7986801314761913
Validation loss: 2.858429846068039

Epoch: 6| Step: 11
Training loss: 3.4877426227138555
Validation loss: 2.857948455279487

Epoch: 6| Step: 12
Training loss: 3.151169720194193
Validation loss: 2.8586556439614608

Epoch: 6| Step: 13
Training loss: 2.490045565758921
Validation loss: 2.8575155415408977

Epoch: 94| Step: 0
Training loss: 3.3787030285707913
Validation loss: 2.8569446556867635

Epoch: 6| Step: 1
Training loss: 3.6047354600325954
Validation loss: 2.8565575292726426

Epoch: 6| Step: 2
Training loss: 3.113672095525961
Validation loss: 2.8547298240185692

Epoch: 6| Step: 3
Training loss: 2.974106303384768
Validation loss: 2.8543731444706366

Epoch: 6| Step: 4
Training loss: 2.941330056387816
Validation loss: 2.8542200578570527

Epoch: 6| Step: 5
Training loss: 2.8654247550929703
Validation loss: 2.85342087031432

Epoch: 6| Step: 6
Training loss: 3.2988068764579874
Validation loss: 2.8556712632185075

Epoch: 6| Step: 7
Training loss: 2.9950547785517845
Validation loss: 2.855451673787667

Epoch: 6| Step: 8
Training loss: 3.2715610415456977
Validation loss: 2.8508002381244655

Epoch: 6| Step: 9
Training loss: 2.8938842544555987
Validation loss: 2.85274328085869

Epoch: 6| Step: 10
Training loss: 3.116569744649813
Validation loss: 2.848237712163776

Epoch: 6| Step: 11
Training loss: 3.7684308120917467
Validation loss: 2.852160136884289

Epoch: 6| Step: 12
Training loss: 3.255610245370779
Validation loss: 2.8525315509686333

Epoch: 6| Step: 13
Training loss: 1.8850492115831703
Validation loss: 2.8604989750155627

Epoch: 95| Step: 0
Training loss: 3.610433315995193
Validation loss: 2.8598442533127773

Epoch: 6| Step: 1
Training loss: 3.6861981178893592
Validation loss: 2.862069449882324

Epoch: 6| Step: 2
Training loss: 2.194077982932792
Validation loss: 2.85243947243819

Epoch: 6| Step: 3
Training loss: 2.7663816289875314
Validation loss: 2.853289759973792

Epoch: 6| Step: 4
Training loss: 3.411692060467079
Validation loss: 2.852893446256609

Epoch: 6| Step: 5
Training loss: 3.2380412234815386
Validation loss: 2.8676707351836375

Epoch: 6| Step: 6
Training loss: 3.8103237507154315
Validation loss: 2.8719501904761384

Epoch: 6| Step: 7
Training loss: 3.0441069720667264
Validation loss: 2.8489710116188207

Epoch: 6| Step: 8
Training loss: 3.2065683604641255
Validation loss: 2.842164041919956

Epoch: 6| Step: 9
Training loss: 2.8653362232665263
Validation loss: 2.8454392914924607

Epoch: 6| Step: 10
Training loss: 3.3857012037377445
Validation loss: 2.839725501232381

Epoch: 6| Step: 11
Training loss: 3.0447868821303032
Validation loss: 2.839966185088401

Epoch: 6| Step: 12
Training loss: 2.6731382361907805
Validation loss: 2.8408531318739203

Epoch: 6| Step: 13
Training loss: 2.612501270348637
Validation loss: 2.8474937676305516

Epoch: 96| Step: 0
Training loss: 2.3700194085207693
Validation loss: 2.842045645239533

Epoch: 6| Step: 1
Training loss: 3.1446859191387135
Validation loss: 2.8474879353856375

Epoch: 6| Step: 2
Training loss: 3.3009179081362934
Validation loss: 2.851324488918807

Epoch: 6| Step: 3
Training loss: 3.7775690747250206
Validation loss: 2.8393530033933825

Epoch: 6| Step: 4
Training loss: 4.05745959475102
Validation loss: 2.8385743293489845

Epoch: 6| Step: 5
Training loss: 3.17122549538473
Validation loss: 2.8375620742447376

Epoch: 6| Step: 6
Training loss: 3.603793497924596
Validation loss: 2.8372072917156648

Epoch: 6| Step: 7
Training loss: 3.3106651262527347
Validation loss: 2.8376037607596345

Epoch: 6| Step: 8
Training loss: 3.192473178353553
Validation loss: 2.8365213029482086

Epoch: 6| Step: 9
Training loss: 2.2426020541406992
Validation loss: 2.8380504847377703

Epoch: 6| Step: 10
Training loss: 2.4090187690101876
Validation loss: 2.8371699004709363

Epoch: 6| Step: 11
Training loss: 2.7701294848754046
Validation loss: 2.8420853347499824

Epoch: 6| Step: 12
Training loss: 2.5131714981585507
Validation loss: 2.844747168146816

Epoch: 6| Step: 13
Training loss: 3.886214855252355
Validation loss: 2.8503299599847254

Epoch: 97| Step: 0
Training loss: 3.1897685636076925
Validation loss: 2.855962470535489

Epoch: 6| Step: 1
Training loss: 2.6598635160953976
Validation loss: 2.848032904290374

Epoch: 6| Step: 2
Training loss: 2.973895302197543
Validation loss: 2.843446093518784

Epoch: 6| Step: 3
Training loss: 3.589311861269674
Validation loss: 2.8340035562109325

Epoch: 6| Step: 4
Training loss: 2.6774446315365417
Validation loss: 2.831012318655575

Epoch: 6| Step: 5
Training loss: 2.629252123363305
Validation loss: 2.8343079831112155

Epoch: 6| Step: 6
Training loss: 3.6533032141323347
Validation loss: 2.834271946570203

Epoch: 6| Step: 7
Training loss: 3.3427777169122477
Validation loss: 2.8325049079267672

Epoch: 6| Step: 8
Training loss: 3.4415090591021023
Validation loss: 2.8323415133797223

Epoch: 6| Step: 9
Training loss: 3.384997783079788
Validation loss: 2.8318749531412433

Epoch: 6| Step: 10
Training loss: 3.0483804749239325
Validation loss: 2.831467589345092

Epoch: 6| Step: 11
Training loss: 3.2056496695798105
Validation loss: 2.832887432279595

Epoch: 6| Step: 12
Training loss: 2.827593337187187
Validation loss: 2.8298074072268187

Epoch: 6| Step: 13
Training loss: 3.0707092805302603
Validation loss: 2.830169803295624

Epoch: 98| Step: 0
Training loss: 3.0650018865632416
Validation loss: 2.827157209809477

Epoch: 6| Step: 1
Training loss: 3.0231092802202517
Validation loss: 2.8303859286865416

Epoch: 6| Step: 2
Training loss: 2.872501116587237
Validation loss: 2.8289258873630367

Epoch: 6| Step: 3
Training loss: 3.624374335654524
Validation loss: 2.829566729039929

Epoch: 6| Step: 4
Training loss: 2.913123094434919
Validation loss: 2.828331488757733

Epoch: 6| Step: 5
Training loss: 3.307995450488356
Validation loss: 2.826679349523248

Epoch: 6| Step: 6
Training loss: 2.8247723175390718
Validation loss: 2.8234673382108997

Epoch: 6| Step: 7
Training loss: 3.6011252975720627
Validation loss: 2.8305110951359054

Epoch: 6| Step: 8
Training loss: 3.1288942105827204
Validation loss: 2.8310807172025063

Epoch: 6| Step: 9
Training loss: 2.7892881670784586
Validation loss: 2.827358056875576

Epoch: 6| Step: 10
Training loss: 2.7702569481561405
Validation loss: 2.835775091102394

Epoch: 6| Step: 11
Training loss: 3.1518596669825834
Validation loss: 2.8346071543673177

Epoch: 6| Step: 12
Training loss: 3.087339753845739
Validation loss: 2.8379539065619945

Epoch: 6| Step: 13
Training loss: 3.831640505530633
Validation loss: 2.831175937058294

Epoch: 99| Step: 0
Training loss: 2.926951359028311
Validation loss: 2.833939992849253

Epoch: 6| Step: 1
Training loss: 3.1973576424697727
Validation loss: 2.8424486177535937

Epoch: 6| Step: 2
Training loss: 3.5064643019193515
Validation loss: 2.8348505987183663

Epoch: 6| Step: 3
Training loss: 3.598668986207267
Validation loss: 2.8310906844007677

Epoch: 6| Step: 4
Training loss: 3.098450451860852
Validation loss: 2.834935783522273

Epoch: 6| Step: 5
Training loss: 2.457697597565474
Validation loss: 2.8282513116342733

Epoch: 6| Step: 6
Training loss: 3.5286387012967975
Validation loss: 2.840069104690884

Epoch: 6| Step: 7
Training loss: 2.7762495372210187
Validation loss: 2.8449701636960634

Epoch: 6| Step: 8
Training loss: 2.6778422861872175
Validation loss: 2.829536035674772

Epoch: 6| Step: 9
Training loss: 3.085181962246853
Validation loss: 2.83745630713194

Epoch: 6| Step: 10
Training loss: 3.5279872978916
Validation loss: 2.8324006051579627

Epoch: 6| Step: 11
Training loss: 3.2088937311262167
Validation loss: 2.8232761610195447

Epoch: 6| Step: 12
Training loss: 2.8936004995529676
Validation loss: 2.8194851043841727

Epoch: 6| Step: 13
Training loss: 3.04896200058411
Validation loss: 2.8173398576903588

Epoch: 100| Step: 0
Training loss: 2.8255476192956777
Validation loss: 2.8158823937888138

Epoch: 6| Step: 1
Training loss: 3.8786373909607845
Validation loss: 2.8169105065510953

Epoch: 6| Step: 2
Training loss: 3.7054832450169792
Validation loss: 2.8169982414516337

Epoch: 6| Step: 3
Training loss: 2.9401509112597344
Validation loss: 2.8202297696345973

Epoch: 6| Step: 4
Training loss: 2.9731400004712767
Validation loss: 2.8189870477243146

Epoch: 6| Step: 5
Training loss: 3.7688766938987905
Validation loss: 2.815790269434116

Epoch: 6| Step: 6
Training loss: 2.153841414944183
Validation loss: 2.815132360368512

Epoch: 6| Step: 7
Training loss: 2.279876713682089
Validation loss: 2.8176017985077135

Epoch: 6| Step: 8
Training loss: 3.064974349694011
Validation loss: 2.8151900075625957

Epoch: 6| Step: 9
Training loss: 3.1984239273267834
Validation loss: 2.8157267956779406

Epoch: 6| Step: 10
Training loss: 3.106868174270502
Validation loss: 2.8136233165898954

Epoch: 6| Step: 11
Training loss: 3.318275167688927
Validation loss: 2.814339365116825

Epoch: 6| Step: 12
Training loss: 2.7979178588894946
Validation loss: 2.8182661554341775

Epoch: 6| Step: 13
Training loss: 3.3910409698576234
Validation loss: 2.823662537227881

Epoch: 101| Step: 0
Training loss: 3.184623916675503
Validation loss: 2.816640839589073

Epoch: 6| Step: 1
Training loss: 2.90141714920379
Validation loss: 2.81773613068055

Epoch: 6| Step: 2
Training loss: 3.7627745163851136
Validation loss: 2.8110159938717953

Epoch: 6| Step: 3
Training loss: 3.295376405417346
Validation loss: 2.8156871498025304

Epoch: 6| Step: 4
Training loss: 2.604789771238718
Validation loss: 2.811153750512566

Epoch: 6| Step: 5
Training loss: 3.5351287334909767
Validation loss: 2.8128023794005963

Epoch: 6| Step: 6
Training loss: 3.0670959863210414
Validation loss: 2.813688168050978

Epoch: 6| Step: 7
Training loss: 2.8247653965042985
Validation loss: 2.8137333580008157

Epoch: 6| Step: 8
Training loss: 3.4037592469368922
Validation loss: 2.810648315207183

Epoch: 6| Step: 9
Training loss: 2.680276789249981
Validation loss: 2.811940648687217

Epoch: 6| Step: 10
Training loss: 3.7199808856514056
Validation loss: 2.811696142536984

Epoch: 6| Step: 11
Training loss: 2.610496325747643
Validation loss: 2.8070067353317443

Epoch: 6| Step: 12
Training loss: 2.5951933004897225
Validation loss: 2.8077948642061616

Epoch: 6| Step: 13
Training loss: 3.277130156366631
Validation loss: 2.8119631511269523

Epoch: 102| Step: 0
Training loss: 3.134261179233224
Validation loss: 2.8190232832950652

Epoch: 6| Step: 1
Training loss: 3.4701837549283683
Validation loss: 2.829328628155287

Epoch: 6| Step: 2
Training loss: 2.8371873523700777
Validation loss: 2.82904505240772

Epoch: 6| Step: 3
Training loss: 3.3729449479297964
Validation loss: 2.827557546001481

Epoch: 6| Step: 4
Training loss: 3.1266116754648046
Validation loss: 2.824763683032803

Epoch: 6| Step: 5
Training loss: 3.1029423255588604
Validation loss: 2.816129137322105

Epoch: 6| Step: 6
Training loss: 3.047024923695262
Validation loss: 2.8245063673522393

Epoch: 6| Step: 7
Training loss: 3.4183922728676372
Validation loss: 2.8230965781793547

Epoch: 6| Step: 8
Training loss: 2.785517472521341
Validation loss: 2.8152570129854024

Epoch: 6| Step: 9
Training loss: 3.5407580088911548
Validation loss: 2.8104742988395994

Epoch: 6| Step: 10
Training loss: 2.812437946906597
Validation loss: 2.807204674361777

Epoch: 6| Step: 11
Training loss: 2.2251204254478814
Validation loss: 2.807443459006773

Epoch: 6| Step: 12
Training loss: 2.8864313170922697
Validation loss: 2.8049504761250987

Epoch: 6| Step: 13
Training loss: 3.945920991712753
Validation loss: 2.8078522712693434

Epoch: 103| Step: 0
Training loss: 3.398228149981424
Validation loss: 2.8055125662047855

Epoch: 6| Step: 1
Training loss: 3.5004966928362635
Validation loss: 2.8048261423721073

Epoch: 6| Step: 2
Training loss: 2.7653434308357268
Validation loss: 2.8012500357519534

Epoch: 6| Step: 3
Training loss: 2.85547726652073
Validation loss: 2.80427712111708

Epoch: 6| Step: 4
Training loss: 3.4446522605579495
Validation loss: 2.8074271179892754

Epoch: 6| Step: 5
Training loss: 3.170615561614303
Validation loss: 2.8063199434120043

Epoch: 6| Step: 6
Training loss: 2.732687380300009
Validation loss: 2.8030883524369576

Epoch: 6| Step: 7
Training loss: 2.649156500968936
Validation loss: 2.8014976040849007

Epoch: 6| Step: 8
Training loss: 2.1854106189024685
Validation loss: 2.8036803469479556

Epoch: 6| Step: 9
Training loss: 3.5159709844943476
Validation loss: 2.7999744896085534

Epoch: 6| Step: 10
Training loss: 3.5397844736039894
Validation loss: 2.801571998611888

Epoch: 6| Step: 11
Training loss: 3.1475079018370176
Validation loss: 2.799729051972606

Epoch: 6| Step: 12
Training loss: 3.1341029527377327
Validation loss: 2.804817247207502

Epoch: 6| Step: 13
Training loss: 3.338299024852851
Validation loss: 2.801046297048204

Epoch: 104| Step: 0
Training loss: 3.61033069459076
Validation loss: 2.802766876586785

Epoch: 6| Step: 1
Training loss: 3.140309180327134
Validation loss: 2.797731741402004

Epoch: 6| Step: 2
Training loss: 2.7483144276070677
Validation loss: 2.8011100366563633

Epoch: 6| Step: 3
Training loss: 3.08606652098759
Validation loss: 2.8052090025658822

Epoch: 6| Step: 4
Training loss: 3.5760318680779104
Validation loss: 2.811204992695389

Epoch: 6| Step: 5
Training loss: 3.5743200068905017
Validation loss: 2.799311729664741

Epoch: 6| Step: 6
Training loss: 2.5978619257450144
Validation loss: 2.797027739543532

Epoch: 6| Step: 7
Training loss: 2.9457120346138965
Validation loss: 2.7980688794873414

Epoch: 6| Step: 8
Training loss: 2.094735098868096
Validation loss: 2.7996221586636034

Epoch: 6| Step: 9
Training loss: 2.860479589679184
Validation loss: 2.798102486156032

Epoch: 6| Step: 10
Training loss: 3.5275980201906827
Validation loss: 2.8004025594739055

Epoch: 6| Step: 11
Training loss: 3.1333180920926864
Validation loss: 2.8027882059770413

Epoch: 6| Step: 12
Training loss: 3.4888949649971157
Validation loss: 2.804265090357752

Epoch: 6| Step: 13
Training loss: 2.4409019987068836
Validation loss: 2.8034448987092127

Epoch: 105| Step: 0
Training loss: 2.9387541995065165
Validation loss: 2.8014221204185774

Epoch: 6| Step: 1
Training loss: 2.925464241160051
Validation loss: 2.801087244762562

Epoch: 6| Step: 2
Training loss: 3.2051269229984163
Validation loss: 2.8026944017298456

Epoch: 6| Step: 3
Training loss: 2.8533047305066868
Validation loss: 2.8025451351588853

Epoch: 6| Step: 4
Training loss: 3.405275257876987
Validation loss: 2.801327879657294

Epoch: 6| Step: 5
Training loss: 2.9342175263714565
Validation loss: 2.8008157009992716

Epoch: 6| Step: 6
Training loss: 2.337312529690926
Validation loss: 2.799923017171627

Epoch: 6| Step: 7
Training loss: 3.3579904941335683
Validation loss: 2.79915046900884

Epoch: 6| Step: 8
Training loss: 3.0965905298482554
Validation loss: 2.800254391102503

Epoch: 6| Step: 9
Training loss: 3.288743970945915
Validation loss: 2.7988507232453275

Epoch: 6| Step: 10
Training loss: 3.4612441777393532
Validation loss: 2.798812590117577

Epoch: 6| Step: 11
Training loss: 3.0897394251904435
Validation loss: 2.7966632223185672

Epoch: 6| Step: 12
Training loss: 3.795430980229201
Validation loss: 2.7984978243841887

Epoch: 6| Step: 13
Training loss: 2.302797635336267
Validation loss: 2.7960571680921427

Epoch: 106| Step: 0
Training loss: 3.010562105636509
Validation loss: 2.7979744066706

Epoch: 6| Step: 1
Training loss: 3.1324809748017812
Validation loss: 2.795838319314207

Epoch: 6| Step: 2
Training loss: 3.6666464082562844
Validation loss: 2.7965114290974626

Epoch: 6| Step: 3
Training loss: 2.772619594268255
Validation loss: 2.793413950355192

Epoch: 6| Step: 4
Training loss: 3.1384512747227085
Validation loss: 2.7954650577180495

Epoch: 6| Step: 5
Training loss: 2.509303900256558
Validation loss: 2.8008189485502255

Epoch: 6| Step: 6
Training loss: 3.032113493010621
Validation loss: 2.797888410819846

Epoch: 6| Step: 7
Training loss: 3.8829502871836072
Validation loss: 2.803552792955501

Epoch: 6| Step: 8
Training loss: 2.851259649211071
Validation loss: 2.7997231513595975

Epoch: 6| Step: 9
Training loss: 3.2147019495230937
Validation loss: 2.8007620389765795

Epoch: 6| Step: 10
Training loss: 2.174735401764543
Validation loss: 2.801148599316603

Epoch: 6| Step: 11
Training loss: 2.7301519425696075
Validation loss: 2.810843220595261

Epoch: 6| Step: 12
Training loss: 3.477629697069043
Validation loss: 2.8118853992462896

Epoch: 6| Step: 13
Training loss: 3.739667135307359
Validation loss: 2.8107679550722953

Epoch: 107| Step: 0
Training loss: 3.3725780698026937
Validation loss: 2.7890565428109078

Epoch: 6| Step: 1
Training loss: 3.8183025541248594
Validation loss: 2.7906780381053204

Epoch: 6| Step: 2
Training loss: 3.2824867460937677
Validation loss: 2.7893526248027523

Epoch: 6| Step: 3
Training loss: 2.83110807959958
Validation loss: 2.788323972608703

Epoch: 6| Step: 4
Training loss: 3.1831945625402542
Validation loss: 2.787238242567019

Epoch: 6| Step: 5
Training loss: 2.924578227094718
Validation loss: 2.788824546312075

Epoch: 6| Step: 6
Training loss: 2.949799133186438
Validation loss: 2.7901813637433825

Epoch: 6| Step: 7
Training loss: 3.220393677807649
Validation loss: 2.791675125596576

Epoch: 6| Step: 8
Training loss: 2.4128280495670102
Validation loss: 2.79811624296791

Epoch: 6| Step: 9
Training loss: 1.9693039008949837
Validation loss: 2.799923829318568

Epoch: 6| Step: 10
Training loss: 3.055135942796537
Validation loss: 2.8083018820548395

Epoch: 6| Step: 11
Training loss: 3.718059058875101
Validation loss: 2.8110565273254693

Epoch: 6| Step: 12
Training loss: 3.2547757199510103
Validation loss: 2.8092026992310046

Epoch: 6| Step: 13
Training loss: 2.95092465408504
Validation loss: 2.8086202626113166

Epoch: 108| Step: 0
Training loss: 3.1263429426419815
Validation loss: 2.8327681030727816

Epoch: 6| Step: 1
Training loss: 3.3516509926946534
Validation loss: 2.850999176802072

Epoch: 6| Step: 2
Training loss: 3.2543723698725
Validation loss: 2.8172471813176787

Epoch: 6| Step: 3
Training loss: 2.240741329817728
Validation loss: 2.797861665484372

Epoch: 6| Step: 4
Training loss: 2.9714697977758817
Validation loss: 2.788404979683296

Epoch: 6| Step: 5
Training loss: 2.7384036658509636
Validation loss: 2.7886896561818153

Epoch: 6| Step: 6
Training loss: 3.80568248107071
Validation loss: 2.787900849195921

Epoch: 6| Step: 7
Training loss: 3.351857134621869
Validation loss: 2.790535972569744

Epoch: 6| Step: 8
Training loss: 3.099797820604674
Validation loss: 2.794764623746226

Epoch: 6| Step: 9
Training loss: 2.6215585219802895
Validation loss: 2.7984452419630017

Epoch: 6| Step: 10
Training loss: 2.9842295985726484
Validation loss: 2.7988903543463945

Epoch: 6| Step: 11
Training loss: 3.2784318720313195
Validation loss: 2.795732712324572

Epoch: 6| Step: 12
Training loss: 3.1374854342057934
Validation loss: 2.7929682038548536

Epoch: 6| Step: 13
Training loss: 3.5902703730106955
Validation loss: 2.788821759589447

Epoch: 109| Step: 0
Training loss: 3.1038066134626385
Validation loss: 2.7875547046021634

Epoch: 6| Step: 1
Training loss: 2.3597051124284256
Validation loss: 2.793244885666401

Epoch: 6| Step: 2
Training loss: 3.1710441515930583
Validation loss: 2.7958518727017987

Epoch: 6| Step: 3
Training loss: 3.2058794785356475
Validation loss: 2.7979705437630784

Epoch: 6| Step: 4
Training loss: 3.1855212783018985
Validation loss: 2.8199481907773847

Epoch: 6| Step: 5
Training loss: 2.67345145493326
Validation loss: 2.821433113213316

Epoch: 6| Step: 6
Training loss: 3.0317953346746513
Validation loss: 2.8188463243395687

Epoch: 6| Step: 7
Training loss: 3.7552223716752087
Validation loss: 2.8270277860122963

Epoch: 6| Step: 8
Training loss: 3.1701581846896203
Validation loss: 2.7943523279536375

Epoch: 6| Step: 9
Training loss: 3.2386165210657496
Validation loss: 2.7881587166896393

Epoch: 6| Step: 10
Training loss: 3.1093182582566117
Validation loss: 2.7783630917978277

Epoch: 6| Step: 11
Training loss: 3.1721738477211514
Validation loss: 2.7789156921752705

Epoch: 6| Step: 12
Training loss: 3.1513246687653034
Validation loss: 2.779960321326333

Epoch: 6| Step: 13
Training loss: 2.772424991236237
Validation loss: 2.7782852134590343

Epoch: 110| Step: 0
Training loss: 3.617971512462506
Validation loss: 2.7778649981625136

Epoch: 6| Step: 1
Training loss: 2.9160130086224028
Validation loss: 2.7781993085356396

Epoch: 6| Step: 2
Training loss: 3.098664666801678
Validation loss: 2.777689124576092

Epoch: 6| Step: 3
Training loss: 2.695549730558602
Validation loss: 2.7769374395306774

Epoch: 6| Step: 4
Training loss: 2.886139394723326
Validation loss: 2.778140078950708

Epoch: 6| Step: 5
Training loss: 2.0101772290946402
Validation loss: 2.776110432718969

Epoch: 6| Step: 6
Training loss: 3.1194040166949453
Validation loss: 2.778667725536788

Epoch: 6| Step: 7
Training loss: 3.035216734687307
Validation loss: 2.776970454452119

Epoch: 6| Step: 8
Training loss: 2.732680138795391
Validation loss: 2.774433271160223

Epoch: 6| Step: 9
Training loss: 3.3620790466238404
Validation loss: 2.7785135033851276

Epoch: 6| Step: 10
Training loss: 2.7853722187643446
Validation loss: 2.777122993580836

Epoch: 6| Step: 11
Training loss: 3.701516232537522
Validation loss: 2.7807949634577027

Epoch: 6| Step: 12
Training loss: 3.7544088513451865
Validation loss: 2.7764561850864284

Epoch: 6| Step: 13
Training loss: 3.2105293849900773
Validation loss: 2.774945895883248

Epoch: 111| Step: 0
Training loss: 2.8185306742868264
Validation loss: 2.7877990419882392

Epoch: 6| Step: 1
Training loss: 2.94492392164838
Validation loss: 2.781154352091756

Epoch: 6| Step: 2
Training loss: 2.7935035887053847
Validation loss: 2.7956280605463126

Epoch: 6| Step: 3
Training loss: 2.8468893978286616
Validation loss: 2.813916610486578

Epoch: 6| Step: 4
Training loss: 3.489096141606874
Validation loss: 2.826087611656169

Epoch: 6| Step: 5
Training loss: 3.654420182855793
Validation loss: 2.820365042866409

Epoch: 6| Step: 6
Training loss: 2.924473061332999
Validation loss: 2.8409140336934304

Epoch: 6| Step: 7
Training loss: 2.557106296220096
Validation loss: 2.8107546770041227

Epoch: 6| Step: 8
Training loss: 2.940538174424713
Validation loss: 2.815322553475123

Epoch: 6| Step: 9
Training loss: 3.555656686642652
Validation loss: 2.808188181550113

Epoch: 6| Step: 10
Training loss: 2.939581275757183
Validation loss: 2.8017223610699227

Epoch: 6| Step: 11
Training loss: 3.14170811134207
Validation loss: 2.7793637237397193

Epoch: 6| Step: 12
Training loss: 3.2112337518728653
Validation loss: 2.7727185988514806

Epoch: 6| Step: 13
Training loss: 3.386286055611257
Validation loss: 2.7712949901300594

Epoch: 112| Step: 0
Training loss: 3.6268417678196645
Validation loss: 2.7708752764897344

Epoch: 6| Step: 1
Training loss: 3.1499224395891474
Validation loss: 2.7679299103556714

Epoch: 6| Step: 2
Training loss: 3.2542213021811124
Validation loss: 2.767047455786642

Epoch: 6| Step: 3
Training loss: 2.8324878403485965
Validation loss: 2.7690735063542276

Epoch: 6| Step: 4
Training loss: 2.9021791229176435
Validation loss: 2.77060387699334

Epoch: 6| Step: 5
Training loss: 2.789798329629083
Validation loss: 2.7643483620075515

Epoch: 6| Step: 6
Training loss: 3.0461186961981843
Validation loss: 2.76767603166032

Epoch: 6| Step: 7
Training loss: 3.304191101163462
Validation loss: 2.7689295027846565

Epoch: 6| Step: 8
Training loss: 2.3190014150203124
Validation loss: 2.769364222814173

Epoch: 6| Step: 9
Training loss: 3.2438922123246736
Validation loss: 2.768164127550377

Epoch: 6| Step: 10
Training loss: 2.8551591321752885
Validation loss: 2.7708809008336877

Epoch: 6| Step: 11
Training loss: 3.2077788992718577
Validation loss: 2.772208390198071

Epoch: 6| Step: 12
Training loss: 3.396944827543855
Validation loss: 2.770705282500133

Epoch: 6| Step: 13
Training loss: 3.052775923921506
Validation loss: 2.7799661218705536

Epoch: 113| Step: 0
Training loss: 3.381206598197215
Validation loss: 2.783209694360055

Epoch: 6| Step: 1
Training loss: 2.9972979775150193
Validation loss: 2.7898952187431147

Epoch: 6| Step: 2
Training loss: 3.2481657867777556
Validation loss: 2.78587506299932

Epoch: 6| Step: 3
Training loss: 2.9298720644989014
Validation loss: 2.7752737739288187

Epoch: 6| Step: 4
Training loss: 3.259870652049069
Validation loss: 2.7772262112457997

Epoch: 6| Step: 5
Training loss: 2.662377325106311
Validation loss: 2.777264086454245

Epoch: 6| Step: 6
Training loss: 3.1578970662325916
Validation loss: 2.778434157567999

Epoch: 6| Step: 7
Training loss: 3.285463370936827
Validation loss: 2.7730027112904554

Epoch: 6| Step: 8
Training loss: 2.8326536560130884
Validation loss: 2.783434738081382

Epoch: 6| Step: 9
Training loss: 2.911108734123418
Validation loss: 2.7753844648082713

Epoch: 6| Step: 10
Training loss: 3.5208088951090355
Validation loss: 2.781740562661531

Epoch: 6| Step: 11
Training loss: 3.078735291062166
Validation loss: 2.7918360375157736

Epoch: 6| Step: 12
Training loss: 2.7906774979423856
Validation loss: 2.7838426603522284

Epoch: 6| Step: 13
Training loss: 2.9411763662450436
Validation loss: 2.779278259858382

Epoch: 114| Step: 0
Training loss: 2.91650746228908
Validation loss: 2.7724054931013193

Epoch: 6| Step: 1
Training loss: 2.919061132017631
Validation loss: 2.7704327679515592

Epoch: 6| Step: 2
Training loss: 2.9910118243494854
Validation loss: 2.7699234682407

Epoch: 6| Step: 3
Training loss: 2.8241591493430165
Validation loss: 2.776000599167878

Epoch: 6| Step: 4
Training loss: 2.813917692823019
Validation loss: 2.774872858840765

Epoch: 6| Step: 5
Training loss: 3.4368771075380824
Validation loss: 2.7747869217244006

Epoch: 6| Step: 6
Training loss: 2.6093629391328674
Validation loss: 2.7766843797983682

Epoch: 6| Step: 7
Training loss: 3.310472263631938
Validation loss: 2.772767317161981

Epoch: 6| Step: 8
Training loss: 3.35691225135261
Validation loss: 2.7639664838511235

Epoch: 6| Step: 9
Training loss: 2.9160551974248894
Validation loss: 2.7660122815697648

Epoch: 6| Step: 10
Training loss: 3.3408647014096515
Validation loss: 2.7628562921320197

Epoch: 6| Step: 11
Training loss: 3.0595670396268004
Validation loss: 2.763657224111851

Epoch: 6| Step: 12
Training loss: 3.472264339615439
Validation loss: 2.7665821345205557

Epoch: 6| Step: 13
Training loss: 3.087790094870911
Validation loss: 2.763896723088739

Epoch: 115| Step: 0
Training loss: 2.826230252183019
Validation loss: 2.7595032629361187

Epoch: 6| Step: 1
Training loss: 3.221715505446542
Validation loss: 2.766478309367371

Epoch: 6| Step: 2
Training loss: 3.006245152713413
Validation loss: 2.769663396657192

Epoch: 6| Step: 3
Training loss: 3.059988743879771
Validation loss: 2.7864271783031027

Epoch: 6| Step: 4
Training loss: 3.1108131341681213
Validation loss: 2.800611046435665

Epoch: 6| Step: 5
Training loss: 2.834086000288497
Validation loss: 2.785766980107307

Epoch: 6| Step: 6
Training loss: 3.213934546164375
Validation loss: 2.7688019589503114

Epoch: 6| Step: 7
Training loss: 3.026854799224095
Validation loss: 2.766146048620828

Epoch: 6| Step: 8
Training loss: 3.013447504103125
Validation loss: 2.7580603236888757

Epoch: 6| Step: 9
Training loss: 3.3291638682659612
Validation loss: 2.7596395768995885

Epoch: 6| Step: 10
Training loss: 3.1215567883897437
Validation loss: 2.7604888857037047

Epoch: 6| Step: 11
Training loss: 3.162278263324919
Validation loss: 2.76254906385048

Epoch: 6| Step: 12
Training loss: 3.0730995942749737
Validation loss: 2.762152150910906

Epoch: 6| Step: 13
Training loss: 3.181350910257587
Validation loss: 2.7603238691325496

Epoch: 116| Step: 0
Training loss: 3.356360071746382
Validation loss: 2.7615094786782968

Epoch: 6| Step: 1
Training loss: 2.9897712533263805
Validation loss: 2.764277762295207

Epoch: 6| Step: 2
Training loss: 2.8340886922995745
Validation loss: 2.7609939562830523

Epoch: 6| Step: 3
Training loss: 3.0667153755410816
Validation loss: 2.7584263714659616

Epoch: 6| Step: 4
Training loss: 3.25866029534703
Validation loss: 2.7585474834978396

Epoch: 6| Step: 5
Training loss: 2.88731285248372
Validation loss: 2.75850519893324

Epoch: 6| Step: 6
Training loss: 2.5123566430031077
Validation loss: 2.7572914283610053

Epoch: 6| Step: 7
Training loss: 3.166643761669107
Validation loss: 2.7584306819511353

Epoch: 6| Step: 8
Training loss: 3.7720049869670245
Validation loss: 2.754516469722406

Epoch: 6| Step: 9
Training loss: 3.453541173927806
Validation loss: 2.758438687651091

Epoch: 6| Step: 10
Training loss: 3.2444131221159256
Validation loss: 2.7602080408913054

Epoch: 6| Step: 11
Training loss: 2.7962650081417637
Validation loss: 2.7667725832497516

Epoch: 6| Step: 12
Training loss: 2.914029445920946
Validation loss: 2.762922354685007

Epoch: 6| Step: 13
Training loss: 2.366947879560698
Validation loss: 2.7730205124782414

Epoch: 117| Step: 0
Training loss: 3.154355226337214
Validation loss: 2.7747147235830885

Epoch: 6| Step: 1
Training loss: 3.341857945270443
Validation loss: 2.772395723638987

Epoch: 6| Step: 2
Training loss: 3.059954461151553
Validation loss: 2.7752430121817264

Epoch: 6| Step: 3
Training loss: 2.6462609453655164
Validation loss: 2.7701503011413844

Epoch: 6| Step: 4
Training loss: 2.900826099726085
Validation loss: 2.772063696802373

Epoch: 6| Step: 5
Training loss: 3.319063988611555
Validation loss: 2.7627694490708663

Epoch: 6| Step: 6
Training loss: 3.55146096483422
Validation loss: 2.759051001873955

Epoch: 6| Step: 7
Training loss: 2.500601791430499
Validation loss: 2.7640131035128737

Epoch: 6| Step: 8
Training loss: 2.6782186057826025
Validation loss: 2.7566806836865583

Epoch: 6| Step: 9
Training loss: 3.1379360245552586
Validation loss: 2.759655679733269

Epoch: 6| Step: 10
Training loss: 2.7559375819431047
Validation loss: 2.7621492105885004

Epoch: 6| Step: 11
Training loss: 3.461255887716403
Validation loss: 2.7542191187417346

Epoch: 6| Step: 12
Training loss: 3.6064465024622328
Validation loss: 2.7574554633348107

Epoch: 6| Step: 13
Training loss: 2.389441003748426
Validation loss: 2.7536260167441022

Epoch: 118| Step: 0
Training loss: 2.8936379066985918
Validation loss: 2.754233674630207

Epoch: 6| Step: 1
Training loss: 2.678353914784336
Validation loss: 2.7542196837402475

Epoch: 6| Step: 2
Training loss: 3.6806723538146198
Validation loss: 2.7566352550251882

Epoch: 6| Step: 3
Training loss: 2.974688403056004
Validation loss: 2.759742205540858

Epoch: 6| Step: 4
Training loss: 2.783287416486741
Validation loss: 2.7582720780554824

Epoch: 6| Step: 5
Training loss: 2.8189866603117557
Validation loss: 2.753135057563453

Epoch: 6| Step: 6
Training loss: 3.321034503301515
Validation loss: 2.756420298272311

Epoch: 6| Step: 7
Training loss: 2.810965564496505
Validation loss: 2.752028487157211

Epoch: 6| Step: 8
Training loss: 2.6636473032909866
Validation loss: 2.7521777847508244

Epoch: 6| Step: 9
Training loss: 3.398027768044626
Validation loss: 2.7574570773151272

Epoch: 6| Step: 10
Training loss: 3.678946969257957
Validation loss: 2.7558561981913807

Epoch: 6| Step: 11
Training loss: 3.0022545925603654
Validation loss: 2.753512435469296

Epoch: 6| Step: 12
Training loss: 2.7224874129411596
Validation loss: 2.7541344774905165

Epoch: 6| Step: 13
Training loss: 3.4719039737237534
Validation loss: 2.754479646156148

Epoch: 119| Step: 0
Training loss: 3.228175907527563
Validation loss: 2.749857827069801

Epoch: 6| Step: 1
Training loss: 3.0941960177034162
Validation loss: 2.7501308451052284

Epoch: 6| Step: 2
Training loss: 3.3294633493647567
Validation loss: 2.751432465245041

Epoch: 6| Step: 3
Training loss: 3.073527509246933
Validation loss: 2.7464091982844794

Epoch: 6| Step: 4
Training loss: 2.890587058978198
Validation loss: 2.7495828761526684

Epoch: 6| Step: 5
Training loss: 2.7010959661468825
Validation loss: 2.7491892246835166

Epoch: 6| Step: 6
Training loss: 3.17688974926797
Validation loss: 2.7490539088638926

Epoch: 6| Step: 7
Training loss: 2.9480144542924624
Validation loss: 2.746016920750778

Epoch: 6| Step: 8
Training loss: 3.4846310371789717
Validation loss: 2.7465279643909315

Epoch: 6| Step: 9
Training loss: 3.1694818498025867
Validation loss: 2.7455477279856257

Epoch: 6| Step: 10
Training loss: 2.993961615041808
Validation loss: 2.7472062094110545

Epoch: 6| Step: 11
Training loss: 2.960269580885517
Validation loss: 2.7467864698593174

Epoch: 6| Step: 12
Training loss: 3.0288082395236975
Validation loss: 2.749016010549279

Epoch: 6| Step: 13
Training loss: 2.6018579447011123
Validation loss: 2.7473090906897943

Epoch: 120| Step: 0
Training loss: 2.313747481927475
Validation loss: 2.7456146393153773

Epoch: 6| Step: 1
Training loss: 2.4715164715470577
Validation loss: 2.7483625953544477

Epoch: 6| Step: 2
Training loss: 2.5538209151151325
Validation loss: 2.742890456630038

Epoch: 6| Step: 3
Training loss: 2.7412362472947613
Validation loss: 2.744911591136288

Epoch: 6| Step: 4
Training loss: 2.655882866114948
Validation loss: 2.749122544898403

Epoch: 6| Step: 5
Training loss: 3.857913338945102
Validation loss: 2.747844269676934

Epoch: 6| Step: 6
Training loss: 3.4135793522995477
Validation loss: 2.747684594726585

Epoch: 6| Step: 7
Training loss: 2.4248939648284873
Validation loss: 2.747724725426444

Epoch: 6| Step: 8
Training loss: 3.4244947464543807
Validation loss: 2.746623063369579

Epoch: 6| Step: 9
Training loss: 2.654517652299496
Validation loss: 2.7415698606030396

Epoch: 6| Step: 10
Training loss: 3.48999692069631
Validation loss: 2.746809181261898

Epoch: 6| Step: 11
Training loss: 3.4347792522013028
Validation loss: 2.7450100456813225

Epoch: 6| Step: 12
Training loss: 3.2653215623266734
Validation loss: 2.742349143134713

Epoch: 6| Step: 13
Training loss: 4.007910773725084
Validation loss: 2.7467575161420092

Epoch: 121| Step: 0
Training loss: 2.830169444588611
Validation loss: 2.755388409197724

Epoch: 6| Step: 1
Training loss: 3.2979984629149177
Validation loss: 2.7586183729772435

Epoch: 6| Step: 2
Training loss: 3.15951942845725
Validation loss: 2.7688375342102893

Epoch: 6| Step: 3
Training loss: 2.5256396625926727
Validation loss: 2.768972615112629

Epoch: 6| Step: 4
Training loss: 3.68684795239737
Validation loss: 2.753146461596012

Epoch: 6| Step: 5
Training loss: 3.122792188841182
Validation loss: 2.7429854508702665

Epoch: 6| Step: 6
Training loss: 2.573967558163567
Validation loss: 2.742152254462238

Epoch: 6| Step: 7
Training loss: 3.426730399621402
Validation loss: 2.7420761113354417

Epoch: 6| Step: 8
Training loss: 2.8354088156481896
Validation loss: 2.740953569171669

Epoch: 6| Step: 9
Training loss: 3.3376270455743136
Validation loss: 2.739582887279322

Epoch: 6| Step: 10
Training loss: 2.602630945698613
Validation loss: 2.7431545879541637

Epoch: 6| Step: 11
Training loss: 2.8349543777374158
Validation loss: 2.742662321681004

Epoch: 6| Step: 12
Training loss: 3.4371692845173754
Validation loss: 2.7417642889500273

Epoch: 6| Step: 13
Training loss: 2.929093527027719
Validation loss: 2.7443296576784095

Epoch: 122| Step: 0
Training loss: 3.494667896214744
Validation loss: 2.7415361706308636

Epoch: 6| Step: 1
Training loss: 3.1505235146143087
Validation loss: 2.743535029075615

Epoch: 6| Step: 2
Training loss: 2.9504443722969182
Validation loss: 2.742382409928091

Epoch: 6| Step: 3
Training loss: 2.664098386998252
Validation loss: 2.744173020876786

Epoch: 6| Step: 4
Training loss: 3.8638198523376266
Validation loss: 2.7419450501547127

Epoch: 6| Step: 5
Training loss: 3.0751241395284747
Validation loss: 2.741942611747805

Epoch: 6| Step: 6
Training loss: 2.80995962066418
Validation loss: 2.7424955061549863

Epoch: 6| Step: 7
Training loss: 2.948780719488721
Validation loss: 2.7405968599702013

Epoch: 6| Step: 8
Training loss: 2.945811747930958
Validation loss: 2.7412661982727347

Epoch: 6| Step: 9
Training loss: 3.2954451366517454
Validation loss: 2.738850663137943

Epoch: 6| Step: 10
Training loss: 2.763542123720946
Validation loss: 2.7414527939309723

Epoch: 6| Step: 11
Training loss: 2.5114084292347583
Validation loss: 2.742021671873264

Epoch: 6| Step: 12
Training loss: 3.008771154046428
Validation loss: 2.7431422508090826

Epoch: 6| Step: 13
Training loss: 3.2634071229015675
Validation loss: 2.747980396060695

Epoch: 123| Step: 0
Training loss: 3.6223474202690555
Validation loss: 2.756355853551633

Epoch: 6| Step: 1
Training loss: 2.991051679924227
Validation loss: 2.752414905291191

Epoch: 6| Step: 2
Training loss: 2.720974855894915
Validation loss: 2.7592068228736797

Epoch: 6| Step: 3
Training loss: 3.534515491394985
Validation loss: 2.7826928303002214

Epoch: 6| Step: 4
Training loss: 3.0892705373603864
Validation loss: 2.769122791501193

Epoch: 6| Step: 5
Training loss: 3.691284952744228
Validation loss: 2.7700855641047473

Epoch: 6| Step: 6
Training loss: 2.7214070632879914
Validation loss: 2.752497092127159

Epoch: 6| Step: 7
Training loss: 2.6209090916813405
Validation loss: 2.741404600161084

Epoch: 6| Step: 8
Training loss: 3.608493978141463
Validation loss: 2.7432820579466597

Epoch: 6| Step: 9
Training loss: 3.406018170508201
Validation loss: 2.7373494573466632

Epoch: 6| Step: 10
Training loss: 2.7008398904302
Validation loss: 2.729996336626067

Epoch: 6| Step: 11
Training loss: 2.9894289692404117
Validation loss: 2.735038132660136

Epoch: 6| Step: 12
Training loss: 2.1163897260581988
Validation loss: 2.7311790040516066

Epoch: 6| Step: 13
Training loss: 2.151072159397849
Validation loss: 2.7326638160227397

Epoch: 124| Step: 0
Training loss: 3.103934277192632
Validation loss: 2.7313913031465784

Epoch: 6| Step: 1
Training loss: 3.171145951996651
Validation loss: 2.7323794741732557

Epoch: 6| Step: 2
Training loss: 3.4714188489828253
Validation loss: 2.7366608790094293

Epoch: 6| Step: 3
Training loss: 2.9550952293168242
Validation loss: 2.7512096665182275

Epoch: 6| Step: 4
Training loss: 2.660475298644448
Validation loss: 2.7369184261990482

Epoch: 6| Step: 5
Training loss: 3.273640118794424
Validation loss: 2.746973532338672

Epoch: 6| Step: 6
Training loss: 3.0548462497212583
Validation loss: 2.7575320649972577

Epoch: 6| Step: 7
Training loss: 3.3216341866224175
Validation loss: 2.7471684143874215

Epoch: 6| Step: 8
Training loss: 3.550668578253974
Validation loss: 2.742876348997277

Epoch: 6| Step: 9
Training loss: 2.8815700262252935
Validation loss: 2.741453016494151

Epoch: 6| Step: 10
Training loss: 2.7555422853933083
Validation loss: 2.7380666106973406

Epoch: 6| Step: 11
Training loss: 2.597368405104662
Validation loss: 2.7361300619281916

Epoch: 6| Step: 12
Training loss: 2.842760186277515
Validation loss: 2.732821618128384

Epoch: 6| Step: 13
Training loss: 2.902111100618312
Validation loss: 2.7375087387088577

Epoch: 125| Step: 0
Training loss: 3.05698911002693
Validation loss: 2.735041508930382

Epoch: 6| Step: 1
Training loss: 2.6627934361332657
Validation loss: 2.743722148784461

Epoch: 6| Step: 2
Training loss: 3.094612694881743
Validation loss: 2.7432293563521197

Epoch: 6| Step: 3
Training loss: 3.4950212762318738
Validation loss: 2.7380946226558147

Epoch: 6| Step: 4
Training loss: 2.707342661110331
Validation loss: 2.7336388600527295

Epoch: 6| Step: 5
Training loss: 2.7809737850573617
Validation loss: 2.72941830985796

Epoch: 6| Step: 6
Training loss: 2.8549184621200663
Validation loss: 2.727184732974652

Epoch: 6| Step: 7
Training loss: 2.6014433595795596
Validation loss: 2.7264458430112857

Epoch: 6| Step: 8
Training loss: 3.585344652024922
Validation loss: 2.7251509883610887

Epoch: 6| Step: 9
Training loss: 3.288087822755251
Validation loss: 2.725572056336203

Epoch: 6| Step: 10
Training loss: 3.532840201915868
Validation loss: 2.7255300888533607

Epoch: 6| Step: 11
Training loss: 3.1378076166974127
Validation loss: 2.7261175127541617

Epoch: 6| Step: 12
Training loss: 2.8939069931913326
Validation loss: 2.7244525406909705

Epoch: 6| Step: 13
Training loss: 2.7832283099189468
Validation loss: 2.7229052077440175

Epoch: 126| Step: 0
Training loss: 3.1907693888155784
Validation loss: 2.7245530584481665

Epoch: 6| Step: 1
Training loss: 2.9512893380722676
Validation loss: 2.7253844072540665

Epoch: 6| Step: 2
Training loss: 3.220941186623181
Validation loss: 2.725457122512657

Epoch: 6| Step: 3
Training loss: 3.1951840102050184
Validation loss: 2.7239757476032276

Epoch: 6| Step: 4
Training loss: 3.2970277289860825
Validation loss: 2.727441590234521

Epoch: 6| Step: 5
Training loss: 3.537470107744176
Validation loss: 2.727093738249119

Epoch: 6| Step: 6
Training loss: 3.2095489841092135
Validation loss: 2.72460191913628

Epoch: 6| Step: 7
Training loss: 2.4581748350956367
Validation loss: 2.72485690016327

Epoch: 6| Step: 8
Training loss: 2.8116894719665573
Validation loss: 2.72437953608058

Epoch: 6| Step: 9
Training loss: 3.2495206332639746
Validation loss: 2.7281076223397895

Epoch: 6| Step: 10
Training loss: 2.9222374349600235
Validation loss: 2.722794135623909

Epoch: 6| Step: 11
Training loss: 2.093958830027024
Validation loss: 2.7201907072705116

Epoch: 6| Step: 12
Training loss: 2.9649293105654966
Validation loss: 2.7272029281713355

Epoch: 6| Step: 13
Training loss: 3.414395034622329
Validation loss: 2.7264322107013137

Epoch: 127| Step: 0
Training loss: 3.073534025258049
Validation loss: 2.7309280078052436

Epoch: 6| Step: 1
Training loss: 2.9522942883360064
Validation loss: 2.7371597674590658

Epoch: 6| Step: 2
Training loss: 2.815045539934787
Validation loss: 2.7378737746954553

Epoch: 6| Step: 3
Training loss: 3.114307727335954
Validation loss: 2.7383928286018433

Epoch: 6| Step: 4
Training loss: 3.3160657584339024
Validation loss: 2.7493233654680624

Epoch: 6| Step: 5
Training loss: 3.2403275267747125
Validation loss: 2.7438964548275533

Epoch: 6| Step: 6
Training loss: 2.6274153178730604
Validation loss: 2.7284695441742586

Epoch: 6| Step: 7
Training loss: 3.294612451664845
Validation loss: 2.7270728668847073

Epoch: 6| Step: 8
Training loss: 3.113937021685637
Validation loss: 2.72986250736879

Epoch: 6| Step: 9
Training loss: 2.7866392748306272
Validation loss: 2.730806042600812

Epoch: 6| Step: 10
Training loss: 3.222346250478243
Validation loss: 2.727563214314733

Epoch: 6| Step: 11
Training loss: 2.6506405110299998
Validation loss: 2.7247586874542393

Epoch: 6| Step: 12
Training loss: 2.8494423705560563
Validation loss: 2.7248376835414296

Epoch: 6| Step: 13
Training loss: 3.7420001849159674
Validation loss: 2.720551276559548

Epoch: 128| Step: 0
Training loss: 3.5331394238315053
Validation loss: 2.72526324941338

Epoch: 6| Step: 1
Training loss: 3.084143162819633
Validation loss: 2.717822868124597

Epoch: 6| Step: 2
Training loss: 3.1683802402107006
Validation loss: 2.716870316432326

Epoch: 6| Step: 3
Training loss: 2.926312509135524
Validation loss: 2.715440444606407

Epoch: 6| Step: 4
Training loss: 2.795727712926318
Validation loss: 2.7222347215983986

Epoch: 6| Step: 5
Training loss: 3.2878959562356536
Validation loss: 2.724018948378066

Epoch: 6| Step: 6
Training loss: 2.251063201627117
Validation loss: 2.7293130296357253

Epoch: 6| Step: 7
Training loss: 3.349920550870357
Validation loss: 2.741400677179354

Epoch: 6| Step: 8
Training loss: 2.992824556346937
Validation loss: 2.746160732043967

Epoch: 6| Step: 9
Training loss: 3.1308782604311887
Validation loss: 2.739494564346771

Epoch: 6| Step: 10
Training loss: 2.550127071131644
Validation loss: 2.7449827673885334

Epoch: 6| Step: 11
Training loss: 3.544326471606291
Validation loss: 2.737774734844412

Epoch: 6| Step: 12
Training loss: 2.812726329597745
Validation loss: 2.7372372171345893

Epoch: 6| Step: 13
Training loss: 2.951771259346646
Validation loss: 2.7261897119407883

Epoch: 129| Step: 0
Training loss: 3.083734194154904
Validation loss: 2.7224890476516768

Epoch: 6| Step: 1
Training loss: 2.9622110732945792
Validation loss: 2.715918551099063

Epoch: 6| Step: 2
Training loss: 3.304735692892539
Validation loss: 2.714564226984054

Epoch: 6| Step: 3
Training loss: 2.952160390109776
Validation loss: 2.7122183210274717

Epoch: 6| Step: 4
Training loss: 2.684790465207952
Validation loss: 2.7212308927675366

Epoch: 6| Step: 5
Training loss: 2.903885402404484
Validation loss: 2.7140779333596603

Epoch: 6| Step: 6
Training loss: 3.6655485153349048
Validation loss: 2.714462393954134

Epoch: 6| Step: 7
Training loss: 2.6433775510933946
Validation loss: 2.7122808456068617

Epoch: 6| Step: 8
Training loss: 3.0981708113665727
Validation loss: 2.715043612359352

Epoch: 6| Step: 9
Training loss: 2.874476177759835
Validation loss: 2.7155640213297807

Epoch: 6| Step: 10
Training loss: 3.2893385238987927
Validation loss: 2.7386139417482354

Epoch: 6| Step: 11
Training loss: 2.8494495663400894
Validation loss: 2.7501235311437093

Epoch: 6| Step: 12
Training loss: 3.296134684820029
Validation loss: 2.756880956485498

Epoch: 6| Step: 13
Training loss: 2.7704303610957544
Validation loss: 2.766775034983645

Epoch: 130| Step: 0
Training loss: 3.038436707540972
Validation loss: 2.753992477041038

Epoch: 6| Step: 1
Training loss: 2.891316758971249
Validation loss: 2.748370856115741

Epoch: 6| Step: 2
Training loss: 3.2762529378831973
Validation loss: 2.752669966138619

Epoch: 6| Step: 3
Training loss: 3.3875842544944663
Validation loss: 2.7539959585356306

Epoch: 6| Step: 4
Training loss: 2.7016317840746567
Validation loss: 2.737149748564885

Epoch: 6| Step: 5
Training loss: 3.0388519292610545
Validation loss: 2.726440338567664

Epoch: 6| Step: 6
Training loss: 3.1825625007287637
Validation loss: 2.717834324113971

Epoch: 6| Step: 7
Training loss: 4.000744273561064
Validation loss: 2.7126157820686894

Epoch: 6| Step: 8
Training loss: 2.5202024526864615
Validation loss: 2.713682403010504

Epoch: 6| Step: 9
Training loss: 3.1553165075112894
Validation loss: 2.7141844099813266

Epoch: 6| Step: 10
Training loss: 3.0420086463740135
Validation loss: 2.7139632599583114

Epoch: 6| Step: 11
Training loss: 2.2030649379902982
Validation loss: 2.711954258373872

Epoch: 6| Step: 12
Training loss: 2.6547790942632417
Validation loss: 2.710803374805732

Epoch: 6| Step: 13
Training loss: 3.238269911724345
Validation loss: 2.714971301839779

Epoch: 131| Step: 0
Training loss: 2.6938628347887814
Validation loss: 2.7140735448769733

Epoch: 6| Step: 1
Training loss: 3.1558725867907937
Validation loss: 2.724899799077298

Epoch: 6| Step: 2
Training loss: 3.2469689833813513
Validation loss: 2.731769212936011

Epoch: 6| Step: 3
Training loss: 3.2500886171437093
Validation loss: 2.739777829044963

Epoch: 6| Step: 4
Training loss: 2.9177121786255418
Validation loss: 2.7582454058676276

Epoch: 6| Step: 5
Training loss: 3.0829493481152808
Validation loss: 2.7379780263060134

Epoch: 6| Step: 6
Training loss: 3.2620137520973254
Validation loss: 2.728327780903901

Epoch: 6| Step: 7
Training loss: 2.3917433173715374
Validation loss: 2.724948563230935

Epoch: 6| Step: 8
Training loss: 2.8162565786773333
Validation loss: 2.713294759263875

Epoch: 6| Step: 9
Training loss: 3.759815721054241
Validation loss: 2.714786537732014

Epoch: 6| Step: 10
Training loss: 2.6455407969635316
Validation loss: 2.717966302684322

Epoch: 6| Step: 11
Training loss: 3.0999805634412256
Validation loss: 2.719507046235388

Epoch: 6| Step: 12
Training loss: 3.1657164971853935
Validation loss: 2.7100287227472983

Epoch: 6| Step: 13
Training loss: 2.5657240891458954
Validation loss: 2.7067532349771857

Epoch: 132| Step: 0
Training loss: 2.7385200690202205
Validation loss: 2.7092489088005633

Epoch: 6| Step: 1
Training loss: 2.773947741356593
Validation loss: 2.7075182676656797

Epoch: 6| Step: 2
Training loss: 3.2621909159556486
Validation loss: 2.70462703376941

Epoch: 6| Step: 3
Training loss: 2.811376219986428
Validation loss: 2.711259606757478

Epoch: 6| Step: 4
Training loss: 2.581676187499755
Validation loss: 2.7115523541302173

Epoch: 6| Step: 5
Training loss: 3.5002882702505396
Validation loss: 2.714195035028378

Epoch: 6| Step: 6
Training loss: 3.159055162006761
Validation loss: 2.7114125532641746

Epoch: 6| Step: 7
Training loss: 3.3815876282739312
Validation loss: 2.7184100590940545

Epoch: 6| Step: 8
Training loss: 3.192384903639572
Validation loss: 2.7179484682188537

Epoch: 6| Step: 9
Training loss: 3.0365485062904374
Validation loss: 2.715687061895245

Epoch: 6| Step: 10
Training loss: 3.209039651646555
Validation loss: 2.7109093086129383

Epoch: 6| Step: 11
Training loss: 2.5363164988712055
Validation loss: 2.7108831652864613

Epoch: 6| Step: 12
Training loss: 2.924453006037451
Validation loss: 2.713109724127926

Epoch: 6| Step: 13
Training loss: 3.3094125430361325
Validation loss: 2.714433624340284

Epoch: 133| Step: 0
Training loss: 2.1732981019392112
Validation loss: 2.7144361667923436

Epoch: 6| Step: 1
Training loss: 2.830057400771687
Validation loss: 2.7166619623600083

Epoch: 6| Step: 2
Training loss: 3.2501748844923957
Validation loss: 2.704520297941895

Epoch: 6| Step: 3
Training loss: 3.38268591663786
Validation loss: 2.7115180321407464

Epoch: 6| Step: 4
Training loss: 2.4612289013982678
Validation loss: 2.705505435431893

Epoch: 6| Step: 5
Training loss: 2.5616408978144203
Validation loss: 2.709688295120616

Epoch: 6| Step: 6
Training loss: 3.497519704178337
Validation loss: 2.71050990433161

Epoch: 6| Step: 7
Training loss: 3.47691854303946
Validation loss: 2.7083764564229993

Epoch: 6| Step: 8
Training loss: 2.7432092572594184
Validation loss: 2.7038691156398764

Epoch: 6| Step: 9
Training loss: 3.0433907173431813
Validation loss: 2.7081063931959743

Epoch: 6| Step: 10
Training loss: 3.1226846891687208
Validation loss: 2.713984307707918

Epoch: 6| Step: 11
Training loss: 2.7049757955317904
Validation loss: 2.7288256609620345

Epoch: 6| Step: 12
Training loss: 3.542148347898217
Validation loss: 2.7211377186086527

Epoch: 6| Step: 13
Training loss: 3.4644618291570244
Validation loss: 2.7135632820174664

Epoch: 134| Step: 0
Training loss: 2.419487151352849
Validation loss: 2.7028987433470077

Epoch: 6| Step: 1
Training loss: 2.8657226146516654
Validation loss: 2.705458965527052

Epoch: 6| Step: 2
Training loss: 3.0977024301018625
Validation loss: 2.6979745629096343

Epoch: 6| Step: 3
Training loss: 2.3916451266002188
Validation loss: 2.699656086176797

Epoch: 6| Step: 4
Training loss: 3.1379446861979092
Validation loss: 2.698466062858646

Epoch: 6| Step: 5
Training loss: 3.471574750084227
Validation loss: 2.6999565227354827

Epoch: 6| Step: 6
Training loss: 3.395457537555618
Validation loss: 2.701748610106176

Epoch: 6| Step: 7
Training loss: 3.216378829279521
Validation loss: 2.7032385759631823

Epoch: 6| Step: 8
Training loss: 3.4677603744737766
Validation loss: 2.703761808009966

Epoch: 6| Step: 9
Training loss: 2.6892171297716234
Validation loss: 2.7012340241411454

Epoch: 6| Step: 10
Training loss: 2.519429428053966
Validation loss: 2.7056198163555023

Epoch: 6| Step: 11
Training loss: 3.026003357496498
Validation loss: 2.705490475243779

Epoch: 6| Step: 12
Training loss: 3.7187930833901355
Validation loss: 2.706934709903133

Epoch: 6| Step: 13
Training loss: 2.284384050886225
Validation loss: 2.707582617397501

Epoch: 135| Step: 0
Training loss: 2.791879550920735
Validation loss: 2.714043975802189

Epoch: 6| Step: 1
Training loss: 3.0155002390298953
Validation loss: 2.7112588238391817

Epoch: 6| Step: 2
Training loss: 3.1109379046529435
Validation loss: 2.7182434802079163

Epoch: 6| Step: 3
Training loss: 3.3583270190410714
Validation loss: 2.7225936416595613

Epoch: 6| Step: 4
Training loss: 3.1586426079401297
Validation loss: 2.7186563409918216

Epoch: 6| Step: 5
Training loss: 3.221213721891494
Validation loss: 2.7165024892043794

Epoch: 6| Step: 6
Training loss: 2.4847054891471245
Validation loss: 2.7089011642239416

Epoch: 6| Step: 7
Training loss: 2.813285209400852
Validation loss: 2.7227989346884556

Epoch: 6| Step: 8
Training loss: 2.7461703250458807
Validation loss: 2.713276820393857

Epoch: 6| Step: 9
Training loss: 3.1294651937162747
Validation loss: 2.7049058743766063

Epoch: 6| Step: 10
Training loss: 3.0553399289275207
Validation loss: 2.701738121144143

Epoch: 6| Step: 11
Training loss: 3.17266790692692
Validation loss: 2.7015345091718896

Epoch: 6| Step: 12
Training loss: 2.6559291870259987
Validation loss: 2.69983140836099

Epoch: 6| Step: 13
Training loss: 3.806422282612229
Validation loss: 2.703063401741389

Epoch: 136| Step: 0
Training loss: 3.402730821211983
Validation loss: 2.703151019197165

Epoch: 6| Step: 1
Training loss: 2.8310280752888572
Validation loss: 2.7008794120340314

Epoch: 6| Step: 2
Training loss: 3.4312515342166994
Validation loss: 2.6990513381102508

Epoch: 6| Step: 3
Training loss: 3.152616014032409
Validation loss: 2.6950919692559903

Epoch: 6| Step: 4
Training loss: 2.360256005319027
Validation loss: 2.700610831807751

Epoch: 6| Step: 5
Training loss: 3.098476460068108
Validation loss: 2.7012741383537673

Epoch: 6| Step: 6
Training loss: 3.0641036214213804
Validation loss: 2.7104951817369995

Epoch: 6| Step: 7
Training loss: 2.436937316113407
Validation loss: 2.7117813422150716

Epoch: 6| Step: 8
Training loss: 3.7045432163621106
Validation loss: 2.7166268725953056

Epoch: 6| Step: 9
Training loss: 3.165799340044435
Validation loss: 2.7120046061243985

Epoch: 6| Step: 10
Training loss: 2.681018287587783
Validation loss: 2.7018450831148777

Epoch: 6| Step: 11
Training loss: 2.368619680720088
Validation loss: 2.699486019521547

Epoch: 6| Step: 12
Training loss: 3.3950207602044555
Validation loss: 2.712744236276808

Epoch: 6| Step: 13
Training loss: 2.786745022199933
Validation loss: 2.7097772442479857

Epoch: 137| Step: 0
Training loss: 3.3331856376987656
Validation loss: 2.7016855979130088

Epoch: 6| Step: 1
Training loss: 2.7152882603158153
Validation loss: 2.7006082630500545

Epoch: 6| Step: 2
Training loss: 3.577160967764022
Validation loss: 2.7018806988432758

Epoch: 6| Step: 3
Training loss: 2.92819167542651
Validation loss: 2.690215671098905

Epoch: 6| Step: 4
Training loss: 2.9496917951544304
Validation loss: 2.693607960656789

Epoch: 6| Step: 5
Training loss: 2.8209670725851046
Validation loss: 2.6907940628259843

Epoch: 6| Step: 6
Training loss: 2.8172139822952382
Validation loss: 2.6886148069871383

Epoch: 6| Step: 7
Training loss: 2.8654265856093906
Validation loss: 2.690354929680564

Epoch: 6| Step: 8
Training loss: 2.399031674225663
Validation loss: 2.6914274893923564

Epoch: 6| Step: 9
Training loss: 2.889429123404775
Validation loss: 2.692172024300612

Epoch: 6| Step: 10
Training loss: 3.5156359863109587
Validation loss: 2.6914330616332034

Epoch: 6| Step: 11
Training loss: 3.0720726966302974
Validation loss: 2.6918419583306323

Epoch: 6| Step: 12
Training loss: 2.9625104686696955
Validation loss: 2.701650054577018

Epoch: 6| Step: 13
Training loss: 3.395476355638728
Validation loss: 2.6953955044418785

Epoch: 138| Step: 0
Training loss: 3.697520203448147
Validation loss: 2.7037076372542628

Epoch: 6| Step: 1
Training loss: 3.126304354250442
Validation loss: 2.71169948457531

Epoch: 6| Step: 2
Training loss: 2.3663677143171964
Validation loss: 2.7202009733465893

Epoch: 6| Step: 3
Training loss: 2.5462549308987543
Validation loss: 2.715663030080483

Epoch: 6| Step: 4
Training loss: 3.183214785247542
Validation loss: 2.718519161176037

Epoch: 6| Step: 5
Training loss: 3.2196387388026064
Validation loss: 2.7190190013497673

Epoch: 6| Step: 6
Training loss: 2.515755122829568
Validation loss: 2.7106805551782243

Epoch: 6| Step: 7
Training loss: 2.980802144893544
Validation loss: 2.7166507854736057

Epoch: 6| Step: 8
Training loss: 2.849868061960247
Validation loss: 2.7052154850871855

Epoch: 6| Step: 9
Training loss: 2.679539267663507
Validation loss: 2.7027171169409083

Epoch: 6| Step: 10
Training loss: 3.408317568368679
Validation loss: 2.700929121468525

Epoch: 6| Step: 11
Training loss: 3.6000083499387756
Validation loss: 2.693610800676471

Epoch: 6| Step: 12
Training loss: 3.1140498764463627
Validation loss: 2.6933196735624567

Epoch: 6| Step: 13
Training loss: 2.244961395101668
Validation loss: 2.691612844507817

Epoch: 139| Step: 0
Training loss: 2.977886396138319
Validation loss: 2.6915428171860567

Epoch: 6| Step: 1
Training loss: 3.6069561668547925
Validation loss: 2.691886796683474

Epoch: 6| Step: 2
Training loss: 2.909376861866684
Validation loss: 2.68593524386644

Epoch: 6| Step: 3
Training loss: 2.6815718095344643
Validation loss: 2.684174737669806

Epoch: 6| Step: 4
Training loss: 3.135888318720128
Validation loss: 2.6930170686511095

Epoch: 6| Step: 5
Training loss: 3.4686800288110966
Validation loss: 2.6856780404643796

Epoch: 6| Step: 6
Training loss: 3.2621432639165935
Validation loss: 2.692079709936755

Epoch: 6| Step: 7
Training loss: 2.8640884989272766
Validation loss: 2.6885022895955486

Epoch: 6| Step: 8
Training loss: 2.9764865655299495
Validation loss: 2.694818111743245

Epoch: 6| Step: 9
Training loss: 2.352431431418643
Validation loss: 2.686871130002499

Epoch: 6| Step: 10
Training loss: 2.9976578152483206
Validation loss: 2.6968748097285458

Epoch: 6| Step: 11
Training loss: 3.041000571976231
Validation loss: 2.7082831689686624

Epoch: 6| Step: 12
Training loss: 2.7229159654082777
Validation loss: 2.733079086242265

Epoch: 6| Step: 13
Training loss: 3.1162343492049884
Validation loss: 2.7048386971860534

Epoch: 140| Step: 0
Training loss: 3.809173383376507
Validation loss: 2.6895768253336674

Epoch: 6| Step: 1
Training loss: 2.748505619803213
Validation loss: 2.683917690319344

Epoch: 6| Step: 2
Training loss: 3.746892531658578
Validation loss: 2.6852085640401517

Epoch: 6| Step: 3
Training loss: 2.9194132996686553
Validation loss: 2.68577240564642

Epoch: 6| Step: 4
Training loss: 2.794854483868263
Validation loss: 2.6809970259739315

Epoch: 6| Step: 5
Training loss: 2.609279425235542
Validation loss: 2.6831295289399435

Epoch: 6| Step: 6
Training loss: 2.7134080342625198
Validation loss: 2.6783920376461543

Epoch: 6| Step: 7
Training loss: 3.0200567540779035
Validation loss: 2.680899840992

Epoch: 6| Step: 8
Training loss: 2.7306322040668016
Validation loss: 2.680358934623657

Epoch: 6| Step: 9
Training loss: 2.9133227843814518
Validation loss: 2.680994453723179

Epoch: 6| Step: 10
Training loss: 3.5166663767978736
Validation loss: 2.6822320781954003

Epoch: 6| Step: 11
Training loss: 2.9862505227204634
Validation loss: 2.6830914265725196

Epoch: 6| Step: 12
Training loss: 2.6072410034995976
Validation loss: 2.6868861175299394

Epoch: 6| Step: 13
Training loss: 2.5035774384032514
Validation loss: 2.687438933624754

Epoch: 141| Step: 0
Training loss: 2.764577031266121
Validation loss: 2.686829099980294

Epoch: 6| Step: 1
Training loss: 3.670096238456988
Validation loss: 2.6845130633639003

Epoch: 6| Step: 2
Training loss: 3.0555880650804217
Validation loss: 2.683258072425595

Epoch: 6| Step: 3
Training loss: 2.437805547881583
Validation loss: 2.692128302953234

Epoch: 6| Step: 4
Training loss: 3.1661532805708155
Validation loss: 2.686598607289831

Epoch: 6| Step: 5
Training loss: 3.333510648461799
Validation loss: 2.6903307621088

Epoch: 6| Step: 6
Training loss: 3.0456756578816293
Validation loss: 2.705992587495518

Epoch: 6| Step: 7
Training loss: 3.484760895986591
Validation loss: 2.695952008272854

Epoch: 6| Step: 8
Training loss: 2.8798846338265687
Validation loss: 2.6954031618863628

Epoch: 6| Step: 9
Training loss: 2.384119094574912
Validation loss: 2.69877004071839

Epoch: 6| Step: 10
Training loss: 3.125771236618162
Validation loss: 2.6932670299434855

Epoch: 6| Step: 11
Training loss: 3.228572782643995
Validation loss: 2.6988879452628374

Epoch: 6| Step: 12
Training loss: 2.5323032966282892
Validation loss: 2.700754491340822

Epoch: 6| Step: 13
Training loss: 2.499123705827222
Validation loss: 2.69927442122333

Epoch: 142| Step: 0
Training loss: 2.878194775393093
Validation loss: 2.700433219144786

Epoch: 6| Step: 1
Training loss: 2.914010464201121
Validation loss: 2.7110381160186967

Epoch: 6| Step: 2
Training loss: 2.9470870037820953
Validation loss: 2.705231183128302

Epoch: 6| Step: 3
Training loss: 2.9415393409153703
Validation loss: 2.700335546947629

Epoch: 6| Step: 4
Training loss: 3.2560825648981315
Validation loss: 2.6954637625018196

Epoch: 6| Step: 5
Training loss: 2.8585422324610117
Validation loss: 2.6923895920330807

Epoch: 6| Step: 6
Training loss: 2.826331144009085
Validation loss: 2.6999807057437595

Epoch: 6| Step: 7
Training loss: 2.6139470778918397
Validation loss: 2.6957061817726573

Epoch: 6| Step: 8
Training loss: 3.2514598208799805
Validation loss: 2.7000450119890984

Epoch: 6| Step: 9
Training loss: 3.190960071989349
Validation loss: 2.694820622281695

Epoch: 6| Step: 10
Training loss: 3.4016198002304465
Validation loss: 2.678423421670277

Epoch: 6| Step: 11
Training loss: 3.2298767949749685
Validation loss: 2.6866326598273713

Epoch: 6| Step: 12
Training loss: 2.505214974017208
Validation loss: 2.676661632507925

Epoch: 6| Step: 13
Training loss: 3.281247820172267
Validation loss: 2.6806376882779426

Epoch: 143| Step: 0
Training loss: 2.9573393929502267
Validation loss: 2.6755207190922743

Epoch: 6| Step: 1
Training loss: 3.526431687091866
Validation loss: 2.675778668902908

Epoch: 6| Step: 2
Training loss: 3.4974730770228257
Validation loss: 2.675773459754683

Epoch: 6| Step: 3
Training loss: 2.9148347460327297
Validation loss: 2.679140952017235

Epoch: 6| Step: 4
Training loss: 2.8104745989447184
Validation loss: 2.675966185737381

Epoch: 6| Step: 5
Training loss: 4.00124125295277
Validation loss: 2.678219083434636

Epoch: 6| Step: 6
Training loss: 3.108105884510863
Validation loss: 2.6748072819966624

Epoch: 6| Step: 7
Training loss: 2.9880393335493243
Validation loss: 2.677282088904016

Epoch: 6| Step: 8
Training loss: 2.117892777766437
Validation loss: 2.681349840807285

Epoch: 6| Step: 9
Training loss: 1.7372862979458146
Validation loss: 2.6842396508403716

Epoch: 6| Step: 10
Training loss: 2.3462098500998514
Validation loss: 2.6823975866001137

Epoch: 6| Step: 11
Training loss: 3.036172389879549
Validation loss: 2.7043777238470503

Epoch: 6| Step: 12
Training loss: 3.4704794481595274
Validation loss: 2.709223217852404

Epoch: 6| Step: 13
Training loss: 2.7572185968320597
Validation loss: 2.7144673182478645

Epoch: 144| Step: 0
Training loss: 3.185666173856332
Validation loss: 2.7152003093885964

Epoch: 6| Step: 1
Training loss: 2.552909302208748
Validation loss: 2.7113226886161508

Epoch: 6| Step: 2
Training loss: 2.927334341416359
Validation loss: 2.6916269703337408

Epoch: 6| Step: 3
Training loss: 3.2934711837747255
Validation loss: 2.705804693831213

Epoch: 6| Step: 4
Training loss: 3.276550560721646
Validation loss: 2.7013055360230576

Epoch: 6| Step: 5
Training loss: 3.178247824126901
Validation loss: 2.6964933367603128

Epoch: 6| Step: 6
Training loss: 3.0968926391715113
Validation loss: 2.7066407252481515

Epoch: 6| Step: 7
Training loss: 2.98962834730829
Validation loss: 2.7058198218763714

Epoch: 6| Step: 8
Training loss: 2.06747207124567
Validation loss: 2.703625566932518

Epoch: 6| Step: 9
Training loss: 3.061913726119456
Validation loss: 2.6932388848982525

Epoch: 6| Step: 10
Training loss: 2.5569084382743843
Validation loss: 2.6812991841980174

Epoch: 6| Step: 11
Training loss: 3.4210326669087276
Validation loss: 2.6957260691979177

Epoch: 6| Step: 12
Training loss: 3.148978742928108
Validation loss: 2.6734820329730917

Epoch: 6| Step: 13
Training loss: 3.0439066194505
Validation loss: 2.6820222892382253

Epoch: 145| Step: 0
Training loss: 2.71231659651536
Validation loss: 2.67625068083926

Epoch: 6| Step: 1
Training loss: 2.8420693597886753
Validation loss: 2.6808803284101654

Epoch: 6| Step: 2
Training loss: 3.0426617566681187
Validation loss: 2.69191929571304

Epoch: 6| Step: 3
Training loss: 3.2790377470765613
Validation loss: 2.685353069512893

Epoch: 6| Step: 4
Training loss: 3.432809299611617
Validation loss: 2.695963262413692

Epoch: 6| Step: 5
Training loss: 3.491116967703881
Validation loss: 2.704911392313736

Epoch: 6| Step: 6
Training loss: 2.969139635717997
Validation loss: 2.690254261479476

Epoch: 6| Step: 7
Training loss: 3.1367748440754104
Validation loss: 2.6735271130805924

Epoch: 6| Step: 8
Training loss: 2.8894159211221866
Validation loss: 2.672164700752971

Epoch: 6| Step: 9
Training loss: 3.3649226313818192
Validation loss: 2.673129719921476

Epoch: 6| Step: 10
Training loss: 2.5541667815846787
Validation loss: 2.670147788323052

Epoch: 6| Step: 11
Training loss: 2.8894142708326216
Validation loss: 2.6746949323313616

Epoch: 6| Step: 12
Training loss: 2.4708613770958943
Validation loss: 2.672845181329513

Epoch: 6| Step: 13
Training loss: 2.5416297493009754
Validation loss: 2.672804209305714

Epoch: 146| Step: 0
Training loss: 2.79624488594771
Validation loss: 2.691299915259579

Epoch: 6| Step: 1
Training loss: 2.4289147230548376
Validation loss: 2.6815886928231905

Epoch: 6| Step: 2
Training loss: 3.2257744147647975
Validation loss: 2.692994877453818

Epoch: 6| Step: 3
Training loss: 2.848802207746242
Validation loss: 2.709374864729661

Epoch: 6| Step: 4
Training loss: 2.9468695372513656
Validation loss: 2.7204035095543317

Epoch: 6| Step: 5
Training loss: 2.974701387180822
Validation loss: 2.7427553843304766

Epoch: 6| Step: 6
Training loss: 2.3348605630153516
Validation loss: 2.7513769064373528

Epoch: 6| Step: 7
Training loss: 2.710375285046522
Validation loss: 2.755642129598214

Epoch: 6| Step: 8
Training loss: 3.6558099465585525
Validation loss: 2.7546330547356472

Epoch: 6| Step: 9
Training loss: 3.327345492632791
Validation loss: 2.736674833202234

Epoch: 6| Step: 10
Training loss: 3.1517785758073122
Validation loss: 2.682034150491739

Epoch: 6| Step: 11
Training loss: 3.043792573916992
Validation loss: 2.6711338581429

Epoch: 6| Step: 12
Training loss: 3.3218487943977517
Validation loss: 2.677273588688763

Epoch: 6| Step: 13
Training loss: 3.264322267442762
Validation loss: 2.6855768819346317

Epoch: 147| Step: 0
Training loss: 3.1024165671147714
Validation loss: 2.696191592937482

Epoch: 6| Step: 1
Training loss: 3.345871154520719
Validation loss: 2.707624431310331

Epoch: 6| Step: 2
Training loss: 3.339523068029238
Validation loss: 2.7042272244483105

Epoch: 6| Step: 3
Training loss: 2.782055684523067
Validation loss: 2.6813597517295045

Epoch: 6| Step: 4
Training loss: 3.1970672639101325
Validation loss: 2.6759700408243923

Epoch: 6| Step: 5
Training loss: 3.3278421631027535
Validation loss: 2.671136141404911

Epoch: 6| Step: 6
Training loss: 2.6772933363029274
Validation loss: 2.6698472899968473

Epoch: 6| Step: 7
Training loss: 2.826977323054555
Validation loss: 2.673738269492626

Epoch: 6| Step: 8
Training loss: 3.1325919437538903
Validation loss: 2.6817413029876995

Epoch: 6| Step: 9
Training loss: 3.0560558795713306
Validation loss: 2.7078327233750854

Epoch: 6| Step: 10
Training loss: 2.580420379693491
Validation loss: 2.7163503247763203

Epoch: 6| Step: 11
Training loss: 3.002749137102714
Validation loss: 2.705225970043072

Epoch: 6| Step: 12
Training loss: 2.8441798964635248
Validation loss: 2.7154001832684695

Epoch: 6| Step: 13
Training loss: 3.0327352444194893
Validation loss: 2.722056134295502

Epoch: 148| Step: 0
Training loss: 2.771679302132487
Validation loss: 2.7233941706021385

Epoch: 6| Step: 1
Training loss: 2.838632359353677
Validation loss: 2.7226740912914247

Epoch: 6| Step: 2
Training loss: 2.8199066969133706
Validation loss: 2.6875677651105825

Epoch: 6| Step: 3
Training loss: 3.426943713342328
Validation loss: 2.6737967023788327

Epoch: 6| Step: 4
Training loss: 2.734367152611507
Validation loss: 2.668642885231857

Epoch: 6| Step: 5
Training loss: 3.252038903007214
Validation loss: 2.6642442058543834

Epoch: 6| Step: 6
Training loss: 3.149477197768337
Validation loss: 2.664337348033917

Epoch: 6| Step: 7
Training loss: 2.975375522025802
Validation loss: 2.6636562627694094

Epoch: 6| Step: 8
Training loss: 2.994166105974419
Validation loss: 2.6577529602602556

Epoch: 6| Step: 9
Training loss: 3.4950046313341097
Validation loss: 2.65858797743982

Epoch: 6| Step: 10
Training loss: 2.6082600478661866
Validation loss: 2.66113231347719

Epoch: 6| Step: 11
Training loss: 3.151759210441919
Validation loss: 2.6591073541234467

Epoch: 6| Step: 12
Training loss: 2.3557743108386204
Validation loss: 2.6620873768486297

Epoch: 6| Step: 13
Training loss: 3.5060482898700753
Validation loss: 2.6622496617844034

Epoch: 149| Step: 0
Training loss: 2.941425379150115
Validation loss: 2.6721480841148386

Epoch: 6| Step: 1
Training loss: 2.864266136409657
Validation loss: 2.6780639693558004

Epoch: 6| Step: 2
Training loss: 3.938719303322618
Validation loss: 2.685913035201114

Epoch: 6| Step: 3
Training loss: 3.3316093437094025
Validation loss: 2.675790097951276

Epoch: 6| Step: 4
Training loss: 3.09988580924112
Validation loss: 2.669899069355628

Epoch: 6| Step: 5
Training loss: 2.4223602793174557
Validation loss: 2.658580853281224

Epoch: 6| Step: 6
Training loss: 2.476978158816781
Validation loss: 2.6600975367563477

Epoch: 6| Step: 7
Training loss: 2.85072494120876
Validation loss: 2.656384318343942

Epoch: 6| Step: 8
Training loss: 2.6536264365812863
Validation loss: 2.655468345450689

Epoch: 6| Step: 9
Training loss: 2.629702760558067
Validation loss: 2.6539685647833196

Epoch: 6| Step: 10
Training loss: 3.158172626147572
Validation loss: 2.6542216480930323

Epoch: 6| Step: 11
Training loss: 2.9730776113470805
Validation loss: 2.659301182860275

Epoch: 6| Step: 12
Training loss: 3.5516830323186985
Validation loss: 2.6544822702917013

Epoch: 6| Step: 13
Training loss: 2.4304272669284104
Validation loss: 2.658422411033335

Epoch: 150| Step: 0
Training loss: 2.6827121935818106
Validation loss: 2.6550794431453113

Epoch: 6| Step: 1
Training loss: 3.4233609809489547
Validation loss: 2.654817696642458

Epoch: 6| Step: 2
Training loss: 2.589183786575233
Validation loss: 2.661222153415463

Epoch: 6| Step: 3
Training loss: 2.7425658570887137
Validation loss: 2.6747828790602672

Epoch: 6| Step: 4
Training loss: 3.0943313206606504
Validation loss: 2.6920389030479144

Epoch: 6| Step: 5
Training loss: 3.2735359705132523
Validation loss: 2.685385927331321

Epoch: 6| Step: 6
Training loss: 2.8873490199130707
Validation loss: 2.680769986175588

Epoch: 6| Step: 7
Training loss: 3.1169139770738807
Validation loss: 2.6799640142730476

Epoch: 6| Step: 8
Training loss: 3.094828099914045
Validation loss: 2.6844150010051355

Epoch: 6| Step: 9
Training loss: 2.4618821041782337
Validation loss: 2.6968636468469103

Epoch: 6| Step: 10
Training loss: 2.6473247699904854
Validation loss: 2.6795328244443963

Epoch: 6| Step: 11
Training loss: 3.4491696726848966
Validation loss: 2.6813565210750125

Epoch: 6| Step: 12
Training loss: 3.402606940792644
Validation loss: 2.66438502008981

Epoch: 6| Step: 13
Training loss: 2.650774979183426
Validation loss: 2.667829074337435

Epoch: 151| Step: 0
Training loss: 2.8482831100163986
Validation loss: 2.6551643966533307

Epoch: 6| Step: 1
Training loss: 2.827633641168352
Validation loss: 2.6530629118083033

Epoch: 6| Step: 2
Training loss: 2.548208998979092
Validation loss: 2.6534622977294324

Epoch: 6| Step: 3
Training loss: 2.600904043455221
Validation loss: 2.6508987968156643

Epoch: 6| Step: 4
Training loss: 3.2930628716716335
Validation loss: 2.6507505290892768

Epoch: 6| Step: 5
Training loss: 1.9669910626734446
Validation loss: 2.6562778555889146

Epoch: 6| Step: 6
Training loss: 3.02942563243853
Validation loss: 2.652938356396312

Epoch: 6| Step: 7
Training loss: 3.0283107074682407
Validation loss: 2.6504940540211517

Epoch: 6| Step: 8
Training loss: 3.2846667710924864
Validation loss: 2.652980829601388

Epoch: 6| Step: 9
Training loss: 3.4944899647195142
Validation loss: 2.655730422643742

Epoch: 6| Step: 10
Training loss: 3.3526248270871544
Validation loss: 2.6555564375436114

Epoch: 6| Step: 11
Training loss: 3.267462400586364
Validation loss: 2.6585086955101906

Epoch: 6| Step: 12
Training loss: 3.022202034801803
Validation loss: 2.6564207037858463

Epoch: 6| Step: 13
Training loss: 2.908605789786725
Validation loss: 2.6636018278670277

Epoch: 152| Step: 0
Training loss: 3.4178105432135584
Validation loss: 2.6720646654949523

Epoch: 6| Step: 1
Training loss: 2.790296351099508
Validation loss: 2.6856082268621297

Epoch: 6| Step: 2
Training loss: 2.6917008680251313
Validation loss: 2.688133567616749

Epoch: 6| Step: 3
Training loss: 3.548959531224956
Validation loss: 2.693393890312711

Epoch: 6| Step: 4
Training loss: 2.668357273481276
Validation loss: 2.6846797813975596

Epoch: 6| Step: 5
Training loss: 2.584040473219475
Validation loss: 2.676892900371179

Epoch: 6| Step: 6
Training loss: 2.638786624020012
Validation loss: 2.6735419165117476

Epoch: 6| Step: 7
Training loss: 3.199160024548772
Validation loss: 2.662440409675436

Epoch: 6| Step: 8
Training loss: 2.4147409022880915
Validation loss: 2.654397441755305

Epoch: 6| Step: 9
Training loss: 3.25946895650472
Validation loss: 2.6562077556920825

Epoch: 6| Step: 10
Training loss: 2.8328403343184045
Validation loss: 2.646470405388266

Epoch: 6| Step: 11
Training loss: 3.1802487639526813
Validation loss: 2.6526029320822855

Epoch: 6| Step: 12
Training loss: 3.5146344633214137
Validation loss: 2.6525317241198176

Epoch: 6| Step: 13
Training loss: 2.602456062524985
Validation loss: 2.649098625866837

Epoch: 153| Step: 0
Training loss: 3.017654605624649
Validation loss: 2.6500738158018966

Epoch: 6| Step: 1
Training loss: 1.9383582398554775
Validation loss: 2.6498997447017896

Epoch: 6| Step: 2
Training loss: 2.664304839715355
Validation loss: 2.6511999701441495

Epoch: 6| Step: 3
Training loss: 3.293488557634968
Validation loss: 2.657097443740133

Epoch: 6| Step: 4
Training loss: 3.281275140575191
Validation loss: 2.654136356286229

Epoch: 6| Step: 5
Training loss: 3.088120087042774
Validation loss: 2.6515119395671407

Epoch: 6| Step: 6
Training loss: 3.1660909296642674
Validation loss: 2.6600716245705973

Epoch: 6| Step: 7
Training loss: 2.6945906847390515
Validation loss: 2.6563885917435117

Epoch: 6| Step: 8
Training loss: 2.8202790234552326
Validation loss: 2.6611507656985403

Epoch: 6| Step: 9
Training loss: 3.03093285228791
Validation loss: 2.670436757724011

Epoch: 6| Step: 10
Training loss: 3.0070121195643744
Validation loss: 2.6871697999715436

Epoch: 6| Step: 11
Training loss: 2.8891323875445356
Validation loss: 2.6953559281089023

Epoch: 6| Step: 12
Training loss: 2.985042796890453
Validation loss: 2.694136871239311

Epoch: 6| Step: 13
Training loss: 4.0548276785137745
Validation loss: 2.693604587653652

Epoch: 154| Step: 0
Training loss: 2.748635560446825
Validation loss: 2.6702307560630043

Epoch: 6| Step: 1
Training loss: 2.7079993604493056
Validation loss: 2.6520405547620025

Epoch: 6| Step: 2
Training loss: 2.3952866524871315
Validation loss: 2.6587796147710163

Epoch: 6| Step: 3
Training loss: 3.4372145100730673
Validation loss: 2.6426653158104054

Epoch: 6| Step: 4
Training loss: 3.13745822954679
Validation loss: 2.643792154168112

Epoch: 6| Step: 5
Training loss: 3.05292649497426
Validation loss: 2.6466611344460533

Epoch: 6| Step: 6
Training loss: 2.932019416994591
Validation loss: 2.6444057566239776

Epoch: 6| Step: 7
Training loss: 2.7597638971818723
Validation loss: 2.6471347671537933

Epoch: 6| Step: 8
Training loss: 3.068593716186542
Validation loss: 2.645147735882118

Epoch: 6| Step: 9
Training loss: 3.237906182337233
Validation loss: 2.6439739867733056

Epoch: 6| Step: 10
Training loss: 3.5864395754180776
Validation loss: 2.6433563620486935

Epoch: 6| Step: 11
Training loss: 2.392152784258837
Validation loss: 2.648332936487283

Epoch: 6| Step: 12
Training loss: 3.1872848737339132
Validation loss: 2.648352534958284

Epoch: 6| Step: 13
Training loss: 2.8394226013801673
Validation loss: 2.646731073110338

Epoch: 155| Step: 0
Training loss: 2.9066967364456127
Validation loss: 2.653395742736828

Epoch: 6| Step: 1
Training loss: 2.7247339801256145
Validation loss: 2.657515006595971

Epoch: 6| Step: 2
Training loss: 2.538826236002813
Validation loss: 2.6544652570915512

Epoch: 6| Step: 3
Training loss: 3.3115579957095354
Validation loss: 2.6683143282969675

Epoch: 6| Step: 4
Training loss: 3.1755301926441404
Validation loss: 2.677398636897523

Epoch: 6| Step: 5
Training loss: 3.2428449952202314
Validation loss: 2.687533118694251

Epoch: 6| Step: 6
Training loss: 2.933883713615714
Validation loss: 2.6813957982650356

Epoch: 6| Step: 7
Training loss: 3.1554571987846414
Validation loss: 2.67700509841679

Epoch: 6| Step: 8
Training loss: 2.867905695717488
Validation loss: 2.6676399226381737

Epoch: 6| Step: 9
Training loss: 3.184416532386019
Validation loss: 2.658083690674357

Epoch: 6| Step: 10
Training loss: 3.1518614824327797
Validation loss: 2.6512408940890855

Epoch: 6| Step: 11
Training loss: 2.972448995937065
Validation loss: 2.6564138421059798

Epoch: 6| Step: 12
Training loss: 2.5585347641996035
Validation loss: 2.6581649874583

Epoch: 6| Step: 13
Training loss: 2.8882768320880974
Validation loss: 2.655390505440505

Epoch: 156| Step: 0
Training loss: 2.534225692772441
Validation loss: 2.648077467421424

Epoch: 6| Step: 1
Training loss: 3.160050926763873
Validation loss: 2.6467760557775395

Epoch: 6| Step: 2
Training loss: 2.5666649628505582
Validation loss: 2.652245225112027

Epoch: 6| Step: 3
Training loss: 3.5906579025261696
Validation loss: 2.6573071561547232

Epoch: 6| Step: 4
Training loss: 3.5249120498398887
Validation loss: 2.6596771874257272

Epoch: 6| Step: 5
Training loss: 2.738678950925105
Validation loss: 2.6619972194122945

Epoch: 6| Step: 6
Training loss: 3.0484292785439817
Validation loss: 2.6816816962324883

Epoch: 6| Step: 7
Training loss: 2.6945406928246762
Validation loss: 2.6847041745870097

Epoch: 6| Step: 8
Training loss: 2.8571850671375025
Validation loss: 2.691145844739376

Epoch: 6| Step: 9
Training loss: 2.8915278493960606
Validation loss: 2.682777031291786

Epoch: 6| Step: 10
Training loss: 2.8813265974409434
Validation loss: 2.684823022922999

Epoch: 6| Step: 11
Training loss: 2.44984751635557
Validation loss: 2.698947808425595

Epoch: 6| Step: 12
Training loss: 3.2129744776766684
Validation loss: 2.687574842955731

Epoch: 6| Step: 13
Training loss: 3.48213513831097
Validation loss: 2.6879115379813934

Epoch: 157| Step: 0
Training loss: 2.7255253171722913
Validation loss: 2.6834751667832095

Epoch: 6| Step: 1
Training loss: 2.7158814128105275
Validation loss: 2.679741053274969

Epoch: 6| Step: 2
Training loss: 2.8985898371144616
Validation loss: 2.678432789235846

Epoch: 6| Step: 3
Training loss: 3.022204874805454
Validation loss: 2.68925459053284

Epoch: 6| Step: 4
Training loss: 2.1037904635984503
Validation loss: 2.6772234907808636

Epoch: 6| Step: 5
Training loss: 3.4887677202693865
Validation loss: 2.6863102741799487

Epoch: 6| Step: 6
Training loss: 2.913981827751893
Validation loss: 2.6777417335024096

Epoch: 6| Step: 7
Training loss: 3.1904615220232233
Validation loss: 2.6691244614769656

Epoch: 6| Step: 8
Training loss: 3.5114959204800935
Validation loss: 2.6609952029334236

Epoch: 6| Step: 9
Training loss: 3.0843826432988504
Validation loss: 2.6569914369949306

Epoch: 6| Step: 10
Training loss: 3.1878892249529764
Validation loss: 2.6453025317081336

Epoch: 6| Step: 11
Training loss: 2.600192789119372
Validation loss: 2.654605700613631

Epoch: 6| Step: 12
Training loss: 3.032154066413958
Validation loss: 2.6543410601311868

Epoch: 6| Step: 13
Training loss: 2.923265585235753
Validation loss: 2.661750482829427

Epoch: 158| Step: 0
Training loss: 2.9881373152631663
Validation loss: 2.6550975463830637

Epoch: 6| Step: 1
Training loss: 3.3104955978698456
Validation loss: 2.6452144295884517

Epoch: 6| Step: 2
Training loss: 2.7562635356544765
Validation loss: 2.6458180971088856

Epoch: 6| Step: 3
Training loss: 3.1112269728142925
Validation loss: 2.6553184830313756

Epoch: 6| Step: 4
Training loss: 2.565392977855217
Validation loss: 2.6547298301490336

Epoch: 6| Step: 5
Training loss: 2.1658160545107052
Validation loss: 2.6510758136162065

Epoch: 6| Step: 6
Training loss: 2.7515992802810447
Validation loss: 2.64831876269285

Epoch: 6| Step: 7
Training loss: 2.9367686233689896
Validation loss: 2.652985359727239

Epoch: 6| Step: 8
Training loss: 3.1279338035115756
Validation loss: 2.6699786525363143

Epoch: 6| Step: 9
Training loss: 3.4841157962200002
Validation loss: 2.6808392783703905

Epoch: 6| Step: 10
Training loss: 3.2780539796770825
Validation loss: 2.6798760672963176

Epoch: 6| Step: 11
Training loss: 3.1042126304415225
Validation loss: 2.686589250066246

Epoch: 6| Step: 12
Training loss: 2.7554650190137235
Validation loss: 2.6877871143223255

Epoch: 6| Step: 13
Training loss: 3.153068374110204
Validation loss: 2.669472364035558

Epoch: 159| Step: 0
Training loss: 3.231744848613598
Validation loss: 2.6587941908001995

Epoch: 6| Step: 1
Training loss: 3.186800262837658
Validation loss: 2.6531314589026374

Epoch: 6| Step: 2
Training loss: 2.3281219277585645
Validation loss: 2.659568544496857

Epoch: 6| Step: 3
Training loss: 2.8979597083450637
Validation loss: 2.655847688594282

Epoch: 6| Step: 4
Training loss: 3.0197556425860315
Validation loss: 2.6606866930701836

Epoch: 6| Step: 5
Training loss: 3.1424649291103437
Validation loss: 2.666557407512225

Epoch: 6| Step: 6
Training loss: 2.551783973626898
Validation loss: 2.6609114356381767

Epoch: 6| Step: 7
Training loss: 3.1616750493103556
Validation loss: 2.6735653527129

Epoch: 6| Step: 8
Training loss: 3.3834212462430404
Validation loss: 2.6726917130910843

Epoch: 6| Step: 9
Training loss: 2.6235837294702016
Validation loss: 2.6495047303618255

Epoch: 6| Step: 10
Training loss: 3.6265527753851603
Validation loss: 2.640839216282524

Epoch: 6| Step: 11
Training loss: 2.954805410726532
Validation loss: 2.6359895272198544

Epoch: 6| Step: 12
Training loss: 2.8536162205274938
Validation loss: 2.6412560580900406

Epoch: 6| Step: 13
Training loss: 1.7710910684357457
Validation loss: 2.6413121822892416

Epoch: 160| Step: 0
Training loss: 3.4737850452918866
Validation loss: 2.6369747352077173

Epoch: 6| Step: 1
Training loss: 2.6350001633008873
Validation loss: 2.6317487756082754

Epoch: 6| Step: 2
Training loss: 2.890152021323422
Validation loss: 2.636241180911315

Epoch: 6| Step: 3
Training loss: 2.8817652839420145
Validation loss: 2.635878847344246

Epoch: 6| Step: 4
Training loss: 2.7425811571963723
Validation loss: 2.6353953643279

Epoch: 6| Step: 5
Training loss: 2.866927381976284
Validation loss: 2.632587041385149

Epoch: 6| Step: 6
Training loss: 3.4713062112314135
Validation loss: 2.6375148879887176

Epoch: 6| Step: 7
Training loss: 2.7438284373965454
Validation loss: 2.6520690674246628

Epoch: 6| Step: 8
Training loss: 2.5568256354945804
Validation loss: 2.655795202824766

Epoch: 6| Step: 9
Training loss: 3.2574262138435697
Validation loss: 2.651216031528599

Epoch: 6| Step: 10
Training loss: 2.7721153868953072
Validation loss: 2.6452848818633794

Epoch: 6| Step: 11
Training loss: 2.857984527866349
Validation loss: 2.6462784743851344

Epoch: 6| Step: 12
Training loss: 3.2918234357241007
Validation loss: 2.6397302641657157

Epoch: 6| Step: 13
Training loss: 3.0215410302441255
Validation loss: 2.6438886795126204

Epoch: 161| Step: 0
Training loss: 3.0482218577624276
Validation loss: 2.6400371085679075

Epoch: 6| Step: 1
Training loss: 2.9993396668082872
Validation loss: 2.639132686795816

Epoch: 6| Step: 2
Training loss: 2.7280347286989493
Validation loss: 2.6446580150453873

Epoch: 6| Step: 3
Training loss: 2.8604292463418206
Validation loss: 2.644386076550894

Epoch: 6| Step: 4
Training loss: 3.0768329212845615
Validation loss: 2.6539851667711405

Epoch: 6| Step: 5
Training loss: 3.2561426068130555
Validation loss: 2.656804205874418

Epoch: 6| Step: 6
Training loss: 3.309436028830057
Validation loss: 2.665007539134482

Epoch: 6| Step: 7
Training loss: 2.9719155550495064
Validation loss: 2.658184467146006

Epoch: 6| Step: 8
Training loss: 2.85902561075135
Validation loss: 2.6453241737343203

Epoch: 6| Step: 9
Training loss: 2.7719210925135185
Validation loss: 2.646494482361889

Epoch: 6| Step: 10
Training loss: 3.299437047162142
Validation loss: 2.6560846874471427

Epoch: 6| Step: 11
Training loss: 3.0343109092661873
Validation loss: 2.637169411998435

Epoch: 6| Step: 12
Training loss: 2.3505017495699607
Validation loss: 2.6329526584296046

Epoch: 6| Step: 13
Training loss: 2.7880936336912168
Validation loss: 2.630586062688503

Epoch: 162| Step: 0
Training loss: 2.601031183280998
Validation loss: 2.631942891197934

Epoch: 6| Step: 1
Training loss: 2.742705380478856
Validation loss: 2.633526795449741

Epoch: 6| Step: 2
Training loss: 3.320671510921739
Validation loss: 2.6321901330892596

Epoch: 6| Step: 3
Training loss: 3.0547265247866875
Validation loss: 2.634690910763911

Epoch: 6| Step: 4
Training loss: 3.178251724942442
Validation loss: 2.631969034536055

Epoch: 6| Step: 5
Training loss: 3.2802927709965384
Validation loss: 2.629221362445717

Epoch: 6| Step: 6
Training loss: 2.838718532453357
Validation loss: 2.629471676908047

Epoch: 6| Step: 7
Training loss: 3.428345576295209
Validation loss: 2.6323356188010516

Epoch: 6| Step: 8
Training loss: 3.1175191220061857
Validation loss: 2.630081115849524

Epoch: 6| Step: 9
Training loss: 2.2400667482036045
Validation loss: 2.6238858211578435

Epoch: 6| Step: 10
Training loss: 2.5122333669811288
Validation loss: 2.6388315176938573

Epoch: 6| Step: 11
Training loss: 3.156749572497691
Validation loss: 2.643752633467319

Epoch: 6| Step: 12
Training loss: 2.7398812793155205
Validation loss: 2.6437261402259082

Epoch: 6| Step: 13
Training loss: 3.067859708530223
Validation loss: 2.6521386948009846

Epoch: 163| Step: 0
Training loss: 3.1107783385582244
Validation loss: 2.6753404594816224

Epoch: 6| Step: 1
Training loss: 3.4631762012991945
Validation loss: 2.6671650594480987

Epoch: 6| Step: 2
Training loss: 2.980574339749873
Validation loss: 2.6780415432071645

Epoch: 6| Step: 3
Training loss: 3.052102011839353
Validation loss: 2.655508527832603

Epoch: 6| Step: 4
Training loss: 2.2396032879554038
Validation loss: 2.649501428934507

Epoch: 6| Step: 5
Training loss: 3.2355035112315065
Validation loss: 2.6292629307461923

Epoch: 6| Step: 6
Training loss: 2.85282957588607
Validation loss: 2.6337723234722876

Epoch: 6| Step: 7
Training loss: 2.8982904196383394
Validation loss: 2.626515917632044

Epoch: 6| Step: 8
Training loss: 2.8217306613443633
Validation loss: 2.6450175050673055

Epoch: 6| Step: 9
Training loss: 2.778150739003463
Validation loss: 2.6326313922323457

Epoch: 6| Step: 10
Training loss: 3.072305202532347
Validation loss: 2.627229711413235

Epoch: 6| Step: 11
Training loss: 3.250120894310967
Validation loss: 2.6306854552811574

Epoch: 6| Step: 12
Training loss: 3.010797461126987
Validation loss: 2.6328787388938504

Epoch: 6| Step: 13
Training loss: 2.3217751359578096
Validation loss: 2.633097309481902

Epoch: 164| Step: 0
Training loss: 3.009537794041578
Validation loss: 2.63082641207698

Epoch: 6| Step: 1
Training loss: 2.504531948806558
Validation loss: 2.6397261065612994

Epoch: 6| Step: 2
Training loss: 2.5074455967304146
Validation loss: 2.652726333879013

Epoch: 6| Step: 3
Training loss: 2.4490263892263293
Validation loss: 2.6575211390334834

Epoch: 6| Step: 4
Training loss: 3.090608793858389
Validation loss: 2.6773741905536075

Epoch: 6| Step: 5
Training loss: 2.9491977311957958
Validation loss: 2.681125259586071

Epoch: 6| Step: 6
Training loss: 3.166709263832963
Validation loss: 2.691691019942464

Epoch: 6| Step: 7
Training loss: 2.5119960981812515
Validation loss: 2.657352829984817

Epoch: 6| Step: 8
Training loss: 3.131607394656549
Validation loss: 2.636515334413206

Epoch: 6| Step: 9
Training loss: 3.2411045701795658
Validation loss: 2.6324122969953447

Epoch: 6| Step: 10
Training loss: 3.5465328370804277
Validation loss: 2.6349777958076386

Epoch: 6| Step: 11
Training loss: 3.097968568005823
Validation loss: 2.6302159030983665

Epoch: 6| Step: 12
Training loss: 3.152600132609648
Validation loss: 2.62992251823198

Epoch: 6| Step: 13
Training loss: 2.9424539551742033
Validation loss: 2.6259789006459973

Epoch: 165| Step: 0
Training loss: 2.6230890493631116
Validation loss: 2.6280902695156785

Epoch: 6| Step: 1
Training loss: 3.044522203564633
Validation loss: 2.637063699791911

Epoch: 6| Step: 2
Training loss: 3.223941209261789
Validation loss: 2.6349910742797724

Epoch: 6| Step: 3
Training loss: 2.6085194538569003
Validation loss: 2.639694260512213

Epoch: 6| Step: 4
Training loss: 2.391055398730821
Validation loss: 2.649216375038622

Epoch: 6| Step: 5
Training loss: 3.0645928530325848
Validation loss: 2.658354236640053

Epoch: 6| Step: 6
Training loss: 3.2274801136352695
Validation loss: 2.641407110458656

Epoch: 6| Step: 7
Training loss: 2.8105085315965077
Validation loss: 2.640160246112643

Epoch: 6| Step: 8
Training loss: 3.13338413873701
Validation loss: 2.6361293445996234

Epoch: 6| Step: 9
Training loss: 3.155442238356534
Validation loss: 2.6404359219122804

Epoch: 6| Step: 10
Training loss: 2.9756798424220925
Validation loss: 2.6451619538051996

Epoch: 6| Step: 11
Training loss: 3.273510187839674
Validation loss: 2.645560857998793

Epoch: 6| Step: 12
Training loss: 2.5769002143686572
Validation loss: 2.651954430323774

Epoch: 6| Step: 13
Training loss: 3.246904512919286
Validation loss: 2.6532515896004694

Epoch: 166| Step: 0
Training loss: 2.6759569541992896
Validation loss: 2.6562025766886586

Epoch: 6| Step: 1
Training loss: 2.753121598379088
Validation loss: 2.672363501412994

Epoch: 6| Step: 2
Training loss: 2.608189296300112
Validation loss: 2.6704768396769807

Epoch: 6| Step: 3
Training loss: 3.3312701197834307
Validation loss: 2.6769700758779744

Epoch: 6| Step: 4
Training loss: 3.0127787227614675
Validation loss: 2.6712865703838697

Epoch: 6| Step: 5
Training loss: 3.401549709788411
Validation loss: 2.6958896251524274

Epoch: 6| Step: 6
Training loss: 3.2111391621398053
Validation loss: 2.704006582651501

Epoch: 6| Step: 7
Training loss: 2.893028950509118
Validation loss: 2.6997876980535005

Epoch: 6| Step: 8
Training loss: 3.113941003062942
Validation loss: 2.69293768746515

Epoch: 6| Step: 9
Training loss: 3.1042542583899957
Validation loss: 2.6547316350192185

Epoch: 6| Step: 10
Training loss: 3.0375191268004733
Validation loss: 2.64512639625468

Epoch: 6| Step: 11
Training loss: 2.9516426685405235
Validation loss: 2.6380399091397115

Epoch: 6| Step: 12
Training loss: 2.058163911073404
Validation loss: 2.62206036910734

Epoch: 6| Step: 13
Training loss: 3.04036686616059
Validation loss: 2.625114690381718

Epoch: 167| Step: 0
Training loss: 2.5657803078409205
Validation loss: 2.6207791510949314

Epoch: 6| Step: 1
Training loss: 3.0938632828750787
Validation loss: 2.6166517757192973

Epoch: 6| Step: 2
Training loss: 3.0362897055092173
Validation loss: 2.6193681003183924

Epoch: 6| Step: 3
Training loss: 2.6540388889985027
Validation loss: 2.6173988556927323

Epoch: 6| Step: 4
Training loss: 2.705009200667495
Validation loss: 2.6246240730475354

Epoch: 6| Step: 5
Training loss: 2.50403936213795
Validation loss: 2.630885281597292

Epoch: 6| Step: 6
Training loss: 3.632879441167518
Validation loss: 2.6361038950761517

Epoch: 6| Step: 7
Training loss: 3.5272220831384145
Validation loss: 2.6388920505665214

Epoch: 6| Step: 8
Training loss: 3.550771849633459
Validation loss: 2.636082851794214

Epoch: 6| Step: 9
Training loss: 2.6320997229818612
Validation loss: 2.6444877986531594

Epoch: 6| Step: 10
Training loss: 3.1119631629862208
Validation loss: 2.6500899169025

Epoch: 6| Step: 11
Training loss: 2.8891165431710113
Validation loss: 2.6452539332954115

Epoch: 6| Step: 12
Training loss: 2.0828659932163234
Validation loss: 2.652627138952162

Epoch: 6| Step: 13
Training loss: 3.0341163532877387
Validation loss: 2.6426692446987112

Epoch: 168| Step: 0
Training loss: 2.5955646096177603
Validation loss: 2.634793682428355

Epoch: 6| Step: 1
Training loss: 3.032501748785032
Validation loss: 2.63692077324611

Epoch: 6| Step: 2
Training loss: 3.1831481247261735
Validation loss: 2.636078943237491

Epoch: 6| Step: 3
Training loss: 2.9652147626372716
Validation loss: 2.6351781566363512

Epoch: 6| Step: 4
Training loss: 3.2313374431886452
Validation loss: 2.6268548013468904

Epoch: 6| Step: 5
Training loss: 2.624105391874727
Validation loss: 2.6203628870091276

Epoch: 6| Step: 6
Training loss: 2.5957620928333034
Validation loss: 2.6194545026800427

Epoch: 6| Step: 7
Training loss: 2.811371470906027
Validation loss: 2.611518836393758

Epoch: 6| Step: 8
Training loss: 3.549989248984807
Validation loss: 2.6134971925390684

Epoch: 6| Step: 9
Training loss: 3.10581973989378
Validation loss: 2.617676549555914

Epoch: 6| Step: 10
Training loss: 2.985789018948564
Validation loss: 2.6210049603062266

Epoch: 6| Step: 11
Training loss: 3.3678564128577326
Validation loss: 2.622721046588319

Epoch: 6| Step: 12
Training loss: 2.380478212734002
Validation loss: 2.6184748327129284

Epoch: 6| Step: 13
Training loss: 2.546287983839037
Validation loss: 2.638653331649627

Epoch: 169| Step: 0
Training loss: 3.092846362763147
Validation loss: 2.6568066297874506

Epoch: 6| Step: 1
Training loss: 2.9509425904168376
Validation loss: 2.662693977906073

Epoch: 6| Step: 2
Training loss: 2.3630801785265905
Validation loss: 2.64191146457256

Epoch: 6| Step: 3
Training loss: 2.5390459735039075
Validation loss: 2.6306396770728835

Epoch: 6| Step: 4
Training loss: 3.0808663336345274
Validation loss: 2.6251028522239537

Epoch: 6| Step: 5
Training loss: 3.2617333691663397
Validation loss: 2.619003520494969

Epoch: 6| Step: 6
Training loss: 3.1930260720554995
Validation loss: 2.62030812409017

Epoch: 6| Step: 7
Training loss: 3.177596921005371
Validation loss: 2.6276568519465693

Epoch: 6| Step: 8
Training loss: 2.7961728370739243
Validation loss: 2.6206495757992356

Epoch: 6| Step: 9
Training loss: 2.8667690377106023
Validation loss: 2.617853909071753

Epoch: 6| Step: 10
Training loss: 2.4127740971108267
Validation loss: 2.6178116072782007

Epoch: 6| Step: 11
Training loss: 3.1234099348263076
Validation loss: 2.6150287735230355

Epoch: 6| Step: 12
Training loss: 3.0283699117693277
Validation loss: 2.6182569581159387

Epoch: 6| Step: 13
Training loss: 3.4266153187992647
Validation loss: 2.618007160681446

Epoch: 170| Step: 0
Training loss: 2.8220893144809347
Validation loss: 2.626124795862159

Epoch: 6| Step: 1
Training loss: 3.3871833456200307
Validation loss: 2.6218330960856617

Epoch: 6| Step: 2
Training loss: 2.8053408740991452
Validation loss: 2.6229174664670367

Epoch: 6| Step: 3
Training loss: 2.979528356261951
Validation loss: 2.631068069528344

Epoch: 6| Step: 4
Training loss: 3.133450031812806
Validation loss: 2.6374640582035145

Epoch: 6| Step: 5
Training loss: 2.6727000964687493
Validation loss: 2.6356061499034187

Epoch: 6| Step: 6
Training loss: 2.650846482881584
Validation loss: 2.6386462177927927

Epoch: 6| Step: 7
Training loss: 3.369048628725879
Validation loss: 2.6322788104021537

Epoch: 6| Step: 8
Training loss: 2.323975519868801
Validation loss: 2.624809923336606

Epoch: 6| Step: 9
Training loss: 2.773970088057634
Validation loss: 2.6284881987369535

Epoch: 6| Step: 10
Training loss: 2.743102613815359
Validation loss: 2.6393374217485253

Epoch: 6| Step: 11
Training loss: 3.2449656889384353
Validation loss: 2.634118287828197

Epoch: 6| Step: 12
Training loss: 3.1337852584991714
Validation loss: 2.6295860981618655

Epoch: 6| Step: 13
Training loss: 3.0810043887039322
Validation loss: 2.630612420266478

Epoch: 171| Step: 0
Training loss: 3.3072618057625056
Validation loss: 2.6300472337300893

Epoch: 6| Step: 1
Training loss: 2.6470518735407924
Validation loss: 2.6283726996957424

Epoch: 6| Step: 2
Training loss: 2.286024036451313
Validation loss: 2.633970681460481

Epoch: 6| Step: 3
Training loss: 2.992057618193269
Validation loss: 2.64446620261643

Epoch: 6| Step: 4
Training loss: 3.2902992080012767
Validation loss: 2.634817781454135

Epoch: 6| Step: 5
Training loss: 2.4381129154472028
Validation loss: 2.6348599532459067

Epoch: 6| Step: 6
Training loss: 2.711940612772896
Validation loss: 2.626728059412362

Epoch: 6| Step: 7
Training loss: 2.347108189849458
Validation loss: 2.615751126206306

Epoch: 6| Step: 8
Training loss: 3.8308175718824002
Validation loss: 2.6198636425135815

Epoch: 6| Step: 9
Training loss: 3.0265734276995224
Validation loss: 2.6300494376407166

Epoch: 6| Step: 10
Training loss: 2.7561201138503044
Validation loss: 2.626118174243727

Epoch: 6| Step: 11
Training loss: 2.6554075812589337
Validation loss: 2.634793561776993

Epoch: 6| Step: 12
Training loss: 3.5976241749214846
Validation loss: 2.6247735753534664

Epoch: 6| Step: 13
Training loss: 2.787746770909406
Validation loss: 2.6235862935163436

Epoch: 172| Step: 0
Training loss: 2.5950437329673623
Validation loss: 2.6308499033299935

Epoch: 6| Step: 1
Training loss: 2.6733873336963385
Validation loss: 2.6299881163793826

Epoch: 6| Step: 2
Training loss: 3.140990278722663
Validation loss: 2.634921633493405

Epoch: 6| Step: 3
Training loss: 2.6246288582143538
Validation loss: 2.629027305294877

Epoch: 6| Step: 4
Training loss: 3.0170948616871405
Validation loss: 2.6344174412756325

Epoch: 6| Step: 5
Training loss: 3.191542212812952
Validation loss: 2.626793503104091

Epoch: 6| Step: 6
Training loss: 2.8312535974340762
Validation loss: 2.627933220889871

Epoch: 6| Step: 7
Training loss: 3.09660977826323
Validation loss: 2.626845229354883

Epoch: 6| Step: 8
Training loss: 3.1970994797813477
Validation loss: 2.6351953342435093

Epoch: 6| Step: 9
Training loss: 2.7513212151260147
Validation loss: 2.640458213071257

Epoch: 6| Step: 10
Training loss: 1.964913035208275
Validation loss: 2.636292102345482

Epoch: 6| Step: 11
Training loss: 3.7107180239373925
Validation loss: 2.6334846558505185

Epoch: 6| Step: 12
Training loss: 2.96234966814106
Validation loss: 2.639643303703626

Epoch: 6| Step: 13
Training loss: 3.2103184755340815
Validation loss: 2.638031469064768

Epoch: 173| Step: 0
Training loss: 3.8130480262979236
Validation loss: 2.655686200777585

Epoch: 6| Step: 1
Training loss: 3.0553730149122393
Validation loss: 2.6248498943048792

Epoch: 6| Step: 2
Training loss: 2.639019991869439
Validation loss: 2.6549438392201368

Epoch: 6| Step: 3
Training loss: 2.5345628511210685
Validation loss: 2.646972632521309

Epoch: 6| Step: 4
Training loss: 2.9849375249564383
Validation loss: 2.644940657271845

Epoch: 6| Step: 5
Training loss: 2.3927739277341655
Validation loss: 2.6577658982679115

Epoch: 6| Step: 6
Training loss: 2.630692621849671
Validation loss: 2.6472478255108243

Epoch: 6| Step: 7
Training loss: 3.3312807121077816
Validation loss: 2.661198986141763

Epoch: 6| Step: 8
Training loss: 2.891457102837818
Validation loss: 2.6476324858484785

Epoch: 6| Step: 9
Training loss: 2.6736583446827678
Validation loss: 2.6448511618530266

Epoch: 6| Step: 10
Training loss: 2.5677937047873334
Validation loss: 2.627814347319684

Epoch: 6| Step: 11
Training loss: 3.408645907170645
Validation loss: 2.6345931035850167

Epoch: 6| Step: 12
Training loss: 3.2512522999052473
Validation loss: 2.645081008510202

Epoch: 6| Step: 13
Training loss: 2.440339415347211
Validation loss: 2.6392456469464576

Epoch: 174| Step: 0
Training loss: 3.1205721193673526
Validation loss: 2.619419533761428

Epoch: 6| Step: 1
Training loss: 3.0315633395557287
Validation loss: 2.6168217728700087

Epoch: 6| Step: 2
Training loss: 3.3105964229330507
Validation loss: 2.6286025267484288

Epoch: 6| Step: 3
Training loss: 2.6264332990849466
Validation loss: 2.6259064981838827

Epoch: 6| Step: 4
Training loss: 2.910958362613108
Validation loss: 2.629806342281425

Epoch: 6| Step: 5
Training loss: 3.1903589927984104
Validation loss: 2.6307223676754288

Epoch: 6| Step: 6
Training loss: 3.0269220661455827
Validation loss: 2.6163576253067733

Epoch: 6| Step: 7
Training loss: 2.5195656944108737
Validation loss: 2.6185746796239706

Epoch: 6| Step: 8
Training loss: 3.0447115528809263
Validation loss: 2.639010800120224

Epoch: 6| Step: 9
Training loss: 3.0550474457248424
Validation loss: 2.6350599270661035

Epoch: 6| Step: 10
Training loss: 2.5701657517117398
Validation loss: 2.6339088392721557

Epoch: 6| Step: 11
Training loss: 2.9276438184377414
Validation loss: 2.618864789690654

Epoch: 6| Step: 12
Training loss: 2.5300324891005928
Validation loss: 2.6258910659563335

Epoch: 6| Step: 13
Training loss: 3.2686451357182222
Validation loss: 2.6440775669290693

Epoch: 175| Step: 0
Training loss: 3.431387721009465
Validation loss: 2.6220181508216225

Epoch: 6| Step: 1
Training loss: 2.3559585998213692
Validation loss: 2.62677148149116

Epoch: 6| Step: 2
Training loss: 2.8930561461447812
Validation loss: 2.6383338479078793

Epoch: 6| Step: 3
Training loss: 3.0263856220699434
Validation loss: 2.621101764379208

Epoch: 6| Step: 4
Training loss: 3.1470886824639956
Validation loss: 2.6185102464961814

Epoch: 6| Step: 5
Training loss: 2.510149760850817
Validation loss: 2.6122078783422835

Epoch: 6| Step: 6
Training loss: 2.2709914219508227
Validation loss: 2.6194205114881663

Epoch: 6| Step: 7
Training loss: 2.6143180033694637
Validation loss: 2.6143078657472456

Epoch: 6| Step: 8
Training loss: 3.2555094750028752
Validation loss: 2.6130387864356854

Epoch: 6| Step: 9
Training loss: 2.9938220945210787
Validation loss: 2.622296137619927

Epoch: 6| Step: 10
Training loss: 2.9486474702805183
Validation loss: 2.6482439777791766

Epoch: 6| Step: 11
Training loss: 3.2517295050272472
Validation loss: 2.6612274690764948

Epoch: 6| Step: 12
Training loss: 3.4055676257977665
Validation loss: 2.6954710916257176

Epoch: 6| Step: 13
Training loss: 2.836473146405289
Validation loss: 2.6800236687971863

Epoch: 176| Step: 0
Training loss: 3.7408608014095446
Validation loss: 2.657692614855194

Epoch: 6| Step: 1
Training loss: 2.1597663844896022
Validation loss: 2.6158519243261833

Epoch: 6| Step: 2
Training loss: 2.8438980567034022
Validation loss: 2.6077571552400736

Epoch: 6| Step: 3
Training loss: 2.8092819453052007
Validation loss: 2.609991920152855

Epoch: 6| Step: 4
Training loss: 3.5248406232150953
Validation loss: 2.637851216241681

Epoch: 6| Step: 5
Training loss: 2.8364247305499215
Validation loss: 2.623021927966448

Epoch: 6| Step: 6
Training loss: 2.9136293309188668
Validation loss: 2.613148593244084

Epoch: 6| Step: 7
Training loss: 2.982877185693645
Validation loss: 2.6052351133469966

Epoch: 6| Step: 8
Training loss: 3.139493975836935
Validation loss: 2.6045414027832394

Epoch: 6| Step: 9
Training loss: 3.0435661934061855
Validation loss: 2.61815336499194

Epoch: 6| Step: 10
Training loss: 2.633181220703287
Validation loss: 2.631174623783857

Epoch: 6| Step: 11
Training loss: 2.3657346994823745
Validation loss: 2.6495579387011077

Epoch: 6| Step: 12
Training loss: 2.89859197569947
Validation loss: 2.677517384870534

Epoch: 6| Step: 13
Training loss: 3.2716788071886316
Validation loss: 2.6897632239198765

Epoch: 177| Step: 0
Training loss: 2.667024012305543
Validation loss: 2.6908889050155027

Epoch: 6| Step: 1
Training loss: 2.6293812474275637
Validation loss: 2.7371908672891574

Epoch: 6| Step: 2
Training loss: 3.608725485221278
Validation loss: 2.7221784953002084

Epoch: 6| Step: 3
Training loss: 2.4091151630495893
Validation loss: 2.7112390824985257

Epoch: 6| Step: 4
Training loss: 3.044947870619469
Validation loss: 2.686933072755684

Epoch: 6| Step: 5
Training loss: 3.085597847704524
Validation loss: 2.6590453599578003

Epoch: 6| Step: 6
Training loss: 3.2286901963352155
Validation loss: 2.621418628640161

Epoch: 6| Step: 7
Training loss: 2.243456757066023
Validation loss: 2.606091463733267

Epoch: 6| Step: 8
Training loss: 3.2183055385638544
Validation loss: 2.602150142134546

Epoch: 6| Step: 9
Training loss: 2.978203268713845
Validation loss: 2.609753924135109

Epoch: 6| Step: 10
Training loss: 3.019494612892223
Validation loss: 2.6139330932745093

Epoch: 6| Step: 11
Training loss: 3.1005777866526723
Validation loss: 2.618030847256386

Epoch: 6| Step: 12
Training loss: 2.7794732408465515
Validation loss: 2.6197971479386726

Epoch: 6| Step: 13
Training loss: 3.4142194838407636
Validation loss: 2.6157736796684388

Epoch: 178| Step: 0
Training loss: 2.9386018350457217
Validation loss: 2.6178781571826084

Epoch: 6| Step: 1
Training loss: 2.8868170322727114
Validation loss: 2.615262038125264

Epoch: 6| Step: 2
Training loss: 3.225603824834978
Validation loss: 2.605956665782515

Epoch: 6| Step: 3
Training loss: 2.8185084271158645
Validation loss: 2.607328559914329

Epoch: 6| Step: 4
Training loss: 3.230766015173461
Validation loss: 2.605980959667071

Epoch: 6| Step: 5
Training loss: 3.209787278777209
Validation loss: 2.6075862544964408

Epoch: 6| Step: 6
Training loss: 2.1836939807469116
Validation loss: 2.6134131250679418

Epoch: 6| Step: 7
Training loss: 2.8577742968759385
Validation loss: 2.614337180214946

Epoch: 6| Step: 8
Training loss: 3.288284753465406
Validation loss: 2.6254936414304293

Epoch: 6| Step: 9
Training loss: 2.7479442368503606
Validation loss: 2.6347195197185402

Epoch: 6| Step: 10
Training loss: 2.719165638689538
Validation loss: 2.641221917485525

Epoch: 6| Step: 11
Training loss: 2.832555009487883
Validation loss: 2.6560125796180394

Epoch: 6| Step: 12
Training loss: 3.1579169979482007
Validation loss: 2.690281096981569

Epoch: 6| Step: 13
Training loss: 3.111987372777273
Validation loss: 2.69321830802643

Epoch: 179| Step: 0
Training loss: 2.8625640595443653
Validation loss: 2.714203677470858

Epoch: 6| Step: 1
Training loss: 2.9221359381207668
Validation loss: 2.7149653709319983

Epoch: 6| Step: 2
Training loss: 3.300804074902592
Validation loss: 2.671704041977881

Epoch: 6| Step: 3
Training loss: 3.074382074808975
Validation loss: 2.628984798105185

Epoch: 6| Step: 4
Training loss: 2.716929911709465
Validation loss: 2.6225963590444032

Epoch: 6| Step: 5
Training loss: 3.2051661988965297
Validation loss: 2.615502537161987

Epoch: 6| Step: 6
Training loss: 3.0541599920667406
Validation loss: 2.6073074072964517

Epoch: 6| Step: 7
Training loss: 2.973638104213272
Validation loss: 2.603579314578112

Epoch: 6| Step: 8
Training loss: 3.0132693246215276
Validation loss: 2.606732630105781

Epoch: 6| Step: 9
Training loss: 3.037082056247713
Validation loss: 2.60343871018295

Epoch: 6| Step: 10
Training loss: 2.408766483394997
Validation loss: 2.6035538984078785

Epoch: 6| Step: 11
Training loss: 2.969684012201335
Validation loss: 2.6055881648574664

Epoch: 6| Step: 12
Training loss: 2.6847772334655553
Validation loss: 2.6040601496088045

Epoch: 6| Step: 13
Training loss: 3.2768430634287795
Validation loss: 2.601769576521101

Epoch: 180| Step: 0
Training loss: 3.018819589385367
Validation loss: 2.602281986259132

Epoch: 6| Step: 1
Training loss: 3.9510123295612134
Validation loss: 2.6003960253400145

Epoch: 6| Step: 2
Training loss: 2.924777134939088
Validation loss: 2.598757130617032

Epoch: 6| Step: 3
Training loss: 3.1044152350186685
Validation loss: 2.6042097426922908

Epoch: 6| Step: 4
Training loss: 3.3983788496196228
Validation loss: 2.6045691873528343

Epoch: 6| Step: 5
Training loss: 2.766547787268588
Validation loss: 2.6076273536502548

Epoch: 6| Step: 6
Training loss: 2.3974564624130843
Validation loss: 2.6173313434996075

Epoch: 6| Step: 7
Training loss: 2.541838739125717
Validation loss: 2.6232074099599596

Epoch: 6| Step: 8
Training loss: 2.948561598971554
Validation loss: 2.6283688367328533

Epoch: 6| Step: 9
Training loss: 2.8459655179945975
Validation loss: 2.6170520358657914

Epoch: 6| Step: 10
Training loss: 2.9676980815231477
Validation loss: 2.609994267707388

Epoch: 6| Step: 11
Training loss: 2.763246364659105
Validation loss: 2.6129176222547534

Epoch: 6| Step: 12
Training loss: 2.1181548326360686
Validation loss: 2.6077007807431816

Epoch: 6| Step: 13
Training loss: 2.872022330704691
Validation loss: 2.613388210163967

Epoch: 181| Step: 0
Training loss: 2.797014627221341
Validation loss: 2.5918213718363625

Epoch: 6| Step: 1
Training loss: 2.952535257540794
Validation loss: 2.5928128087886515

Epoch: 6| Step: 2
Training loss: 2.975234488854933
Validation loss: 2.5897190911146337

Epoch: 6| Step: 3
Training loss: 3.0368961566031873
Validation loss: 2.5864001444765345

Epoch: 6| Step: 4
Training loss: 3.1167851621027878
Validation loss: 2.586063298798081

Epoch: 6| Step: 5
Training loss: 3.119153466434117
Validation loss: 2.5864515223389133

Epoch: 6| Step: 6
Training loss: 2.920609633676541
Validation loss: 2.587035490269941

Epoch: 6| Step: 7
Training loss: 2.875777595515625
Validation loss: 2.587895387941955

Epoch: 6| Step: 8
Training loss: 2.818616785255279
Validation loss: 2.5840811611278416

Epoch: 6| Step: 9
Training loss: 2.613162187678007
Validation loss: 2.5893185087146087

Epoch: 6| Step: 10
Training loss: 3.40407065571703
Validation loss: 2.5834488298741687

Epoch: 6| Step: 11
Training loss: 2.651183378757549
Validation loss: 2.5920006093085637

Epoch: 6| Step: 12
Training loss: 3.0419997115677417
Validation loss: 2.5904532775248397

Epoch: 6| Step: 13
Training loss: 2.6141978938489614
Validation loss: 2.5949244473709436

Epoch: 182| Step: 0
Training loss: 2.981281374720257
Validation loss: 2.5929646109079774

Epoch: 6| Step: 1
Training loss: 2.3338957063439705
Validation loss: 2.5979297228448575

Epoch: 6| Step: 2
Training loss: 3.1048219403060555
Validation loss: 2.6141446385376086

Epoch: 6| Step: 3
Training loss: 2.8127791372167783
Validation loss: 2.604908264065489

Epoch: 6| Step: 4
Training loss: 2.678318218797038
Validation loss: 2.602598538375491

Epoch: 6| Step: 5
Training loss: 2.8442016913553085
Validation loss: 2.6247820092243077

Epoch: 6| Step: 6
Training loss: 2.7429282554564383
Validation loss: 2.622792846907733

Epoch: 6| Step: 7
Training loss: 3.1419819040439037
Validation loss: 2.620177877785321

Epoch: 6| Step: 8
Training loss: 2.768228114006199
Validation loss: 2.6134042454483235

Epoch: 6| Step: 9
Training loss: 2.826859501912801
Validation loss: 2.613866133980222

Epoch: 6| Step: 10
Training loss: 3.5222531377142237
Validation loss: 2.6117959795263057

Epoch: 6| Step: 11
Training loss: 3.486040341763746
Validation loss: 2.6214472670428455

Epoch: 6| Step: 12
Training loss: 2.570837181826225
Validation loss: 2.6237009255113537

Epoch: 6| Step: 13
Training loss: 2.770671916265841
Validation loss: 2.6621114801412333

Epoch: 183| Step: 0
Training loss: 3.2917744743623425
Validation loss: 2.6611799495029924

Epoch: 6| Step: 1
Training loss: 2.521332042533723
Validation loss: 2.667541168882714

Epoch: 6| Step: 2
Training loss: 2.971010652433781
Validation loss: 2.686483659850608

Epoch: 6| Step: 3
Training loss: 3.166672371976297
Validation loss: 2.702566999364358

Epoch: 6| Step: 4
Training loss: 2.652894087988388
Validation loss: 2.7018549435265777

Epoch: 6| Step: 5
Training loss: 2.8764094339452884
Validation loss: 2.6933450212512366

Epoch: 6| Step: 6
Training loss: 3.095977905786027
Validation loss: 2.6738942692113574

Epoch: 6| Step: 7
Training loss: 3.1024244057347055
Validation loss: 2.6178536720833328

Epoch: 6| Step: 8
Training loss: 2.857957499033913
Validation loss: 2.603796223205877

Epoch: 6| Step: 9
Training loss: 1.7740160296725496
Validation loss: 2.5891526763569828

Epoch: 6| Step: 10
Training loss: 3.1957113674585824
Validation loss: 2.581909695108301

Epoch: 6| Step: 11
Training loss: 2.6943670853808492
Validation loss: 2.588464705876665

Epoch: 6| Step: 12
Training loss: 3.408230546988537
Validation loss: 2.5854427631588117

Epoch: 6| Step: 13
Training loss: 3.145967257514223
Validation loss: 2.58727153831399

Epoch: 184| Step: 0
Training loss: 3.143312585330043
Validation loss: 2.5874269104302186

Epoch: 6| Step: 1
Training loss: 3.059032423343275
Validation loss: 2.587754483177827

Epoch: 6| Step: 2
Training loss: 3.2805497648478914
Validation loss: 2.5851175492677148

Epoch: 6| Step: 3
Training loss: 2.743833390274268
Validation loss: 2.5886032451393794

Epoch: 6| Step: 4
Training loss: 2.6999533684553696
Validation loss: 2.5866585176690724

Epoch: 6| Step: 5
Training loss: 2.929536454439614
Validation loss: 2.5876900930290576

Epoch: 6| Step: 6
Training loss: 2.837555226868253
Validation loss: 2.578148228654724

Epoch: 6| Step: 7
Training loss: 2.8421881442412684
Validation loss: 2.585254939597951

Epoch: 6| Step: 8
Training loss: 3.2837436464826895
Validation loss: 2.5820360177931727

Epoch: 6| Step: 9
Training loss: 2.5702002596480344
Validation loss: 2.5781588266589157

Epoch: 6| Step: 10
Training loss: 3.0429392900130425
Validation loss: 2.584303371758484

Epoch: 6| Step: 11
Training loss: 2.594720222370641
Validation loss: 2.580024885804983

Epoch: 6| Step: 12
Training loss: 3.155815774489165
Validation loss: 2.593245377015286

Epoch: 6| Step: 13
Training loss: 2.8420871442176345
Validation loss: 2.6073350453848834

Epoch: 185| Step: 0
Training loss: 3.1912837290970555
Validation loss: 2.6120407814860274

Epoch: 6| Step: 1
Training loss: 3.1421160598289584
Validation loss: 2.6153564101162563

Epoch: 6| Step: 2
Training loss: 2.177195885287449
Validation loss: 2.6399360035044004

Epoch: 6| Step: 3
Training loss: 3.0093692070418996
Validation loss: 2.624219925971843

Epoch: 6| Step: 4
Training loss: 2.8448896534844597
Validation loss: 2.6293614524625033

Epoch: 6| Step: 5
Training loss: 3.0195789407415923
Validation loss: 2.6195813655672824

Epoch: 6| Step: 6
Training loss: 2.9870745048617744
Validation loss: 2.6234987832763714

Epoch: 6| Step: 7
Training loss: 2.723049928944995
Validation loss: 2.646708225524147

Epoch: 6| Step: 8
Training loss: 3.1920310334535085
Validation loss: 2.6458489799731266

Epoch: 6| Step: 9
Training loss: 3.2356096205659943
Validation loss: 2.6676411681126697

Epoch: 6| Step: 10
Training loss: 2.538751107708207
Validation loss: 2.656667862995315

Epoch: 6| Step: 11
Training loss: 2.9725638536889014
Validation loss: 2.6472487174230226

Epoch: 6| Step: 12
Training loss: 3.200126025579281
Validation loss: 2.6361531912093588

Epoch: 6| Step: 13
Training loss: 2.2236817044196773
Validation loss: 2.5952523233710205

Epoch: 186| Step: 0
Training loss: 2.809624452304664
Validation loss: 2.5943797049248003

Epoch: 6| Step: 1
Training loss: 2.757705989001972
Validation loss: 2.595839446454384

Epoch: 6| Step: 2
Training loss: 2.441048118263942
Validation loss: 2.591977723379319

Epoch: 6| Step: 3
Training loss: 2.8183465165593713
Validation loss: 2.5944780696061196

Epoch: 6| Step: 4
Training loss: 2.930969771469766
Validation loss: 2.6005336228859384

Epoch: 6| Step: 5
Training loss: 3.058577224472438
Validation loss: 2.600133989800376

Epoch: 6| Step: 6
Training loss: 2.990043170579025
Validation loss: 2.5921666372675443

Epoch: 6| Step: 7
Training loss: 2.666487141367711
Validation loss: 2.5978874321407015

Epoch: 6| Step: 8
Training loss: 2.820066657935623
Validation loss: 2.614213786384852

Epoch: 6| Step: 9
Training loss: 2.662855305492719
Validation loss: 2.6110035235153317

Epoch: 6| Step: 10
Training loss: 2.97928748963957
Validation loss: 2.639239575979771

Epoch: 6| Step: 11
Training loss: 3.2697284233407435
Validation loss: 2.6788166474750525

Epoch: 6| Step: 12
Training loss: 3.1996838949954207
Validation loss: 2.696094139819545

Epoch: 6| Step: 13
Training loss: 3.8628600906367274
Validation loss: 2.676642773844086

Epoch: 187| Step: 0
Training loss: 3.285146234703446
Validation loss: 2.637675867135324

Epoch: 6| Step: 1
Training loss: 2.5832608017942498
Validation loss: 2.5920642940129794

Epoch: 6| Step: 2
Training loss: 3.058044306292511
Validation loss: 2.5782219325065596

Epoch: 6| Step: 3
Training loss: 3.3836371493677544
Validation loss: 2.5725254875604353

Epoch: 6| Step: 4
Training loss: 2.5941886990456386
Validation loss: 2.5788731727107015

Epoch: 6| Step: 5
Training loss: 2.703914549075542
Validation loss: 2.5772197577222586

Epoch: 6| Step: 6
Training loss: 2.8221526760216435
Validation loss: 2.580592781478733

Epoch: 6| Step: 7
Training loss: 2.97880617819512
Validation loss: 2.579517955481421

Epoch: 6| Step: 8
Training loss: 2.7848876138745027
Validation loss: 2.5770543913036317

Epoch: 6| Step: 9
Training loss: 3.2687042174770937
Validation loss: 2.580583742235051

Epoch: 6| Step: 10
Training loss: 2.685587712757682
Validation loss: 2.578060362382507

Epoch: 6| Step: 11
Training loss: 3.024779344818208
Validation loss: 2.5736806976531623

Epoch: 6| Step: 12
Training loss: 2.9581825504471526
Validation loss: 2.572653558503834

Epoch: 6| Step: 13
Training loss: 2.8503214604634537
Validation loss: 2.5755000498952008

Epoch: 188| Step: 0
Training loss: 2.6883032729408876
Validation loss: 2.57818587931389

Epoch: 6| Step: 1
Training loss: 2.719002985967727
Validation loss: 2.5807040622165185

Epoch: 6| Step: 2
Training loss: 3.313470662249757
Validation loss: 2.5916081003451747

Epoch: 6| Step: 3
Training loss: 2.9070789426537424
Validation loss: 2.6015504580978472

Epoch: 6| Step: 4
Training loss: 2.6143456359863047
Validation loss: 2.6071346746513404

Epoch: 6| Step: 5
Training loss: 2.527582973850169
Validation loss: 2.6116080865171263

Epoch: 6| Step: 6
Training loss: 2.4460510503599053
Validation loss: 2.628952080821223

Epoch: 6| Step: 7
Training loss: 3.0327638601562317
Validation loss: 2.625621185499538

Epoch: 6| Step: 8
Training loss: 3.1497339650998017
Validation loss: 2.6366326644742135

Epoch: 6| Step: 9
Training loss: 3.538877638142373
Validation loss: 2.627977860013339

Epoch: 6| Step: 10
Training loss: 3.100987148008559
Validation loss: 2.626272851983426

Epoch: 6| Step: 11
Training loss: 2.4382256625902916
Validation loss: 2.6190333853764867

Epoch: 6| Step: 12
Training loss: 3.5314355311984307
Validation loss: 2.6065189046873383

Epoch: 6| Step: 13
Training loss: 1.9495390053677606
Validation loss: 2.60706195781439

Epoch: 189| Step: 0
Training loss: 2.453456200273434
Validation loss: 2.608774835453875

Epoch: 6| Step: 1
Training loss: 2.175406021280137
Validation loss: 2.601176431726294

Epoch: 6| Step: 2
Training loss: 3.048928063054161
Validation loss: 2.5921790748426687

Epoch: 6| Step: 3
Training loss: 2.800973712687475
Validation loss: 2.5973106571972893

Epoch: 6| Step: 4
Training loss: 2.8803982019644234
Validation loss: 2.6157887246757823

Epoch: 6| Step: 5
Training loss: 2.500152869319114
Validation loss: 2.6238252459508296

Epoch: 6| Step: 6
Training loss: 3.7785604700830473
Validation loss: 2.637093672688308

Epoch: 6| Step: 7
Training loss: 2.94012496215566
Validation loss: 2.6300585310675553

Epoch: 6| Step: 8
Training loss: 3.0939574509242824
Validation loss: 2.61689611951682

Epoch: 6| Step: 9
Training loss: 3.0009989664698202
Validation loss: 2.6087558172092216

Epoch: 6| Step: 10
Training loss: 2.5515886930299794
Validation loss: 2.581830074267275

Epoch: 6| Step: 11
Training loss: 3.0241102312978008
Validation loss: 2.577003871142856

Epoch: 6| Step: 12
Training loss: 2.8798023418309695
Validation loss: 2.5664203347668875

Epoch: 6| Step: 13
Training loss: 3.586332810497225
Validation loss: 2.566722228155086

Epoch: 190| Step: 0
Training loss: 2.910447074132372
Validation loss: 2.565668130012772

Epoch: 6| Step: 1
Training loss: 3.263350137025031
Validation loss: 2.5689272668165577

Epoch: 6| Step: 2
Training loss: 3.1025178528547928
Validation loss: 2.5701554798356936

Epoch: 6| Step: 3
Training loss: 3.2985997321395475
Validation loss: 2.5625257573307634

Epoch: 6| Step: 4
Training loss: 2.6479882503490866
Validation loss: 2.566426312278634

Epoch: 6| Step: 5
Training loss: 2.819001799372775
Validation loss: 2.563612705598193

Epoch: 6| Step: 6
Training loss: 2.6621630209137557
Validation loss: 2.5578454165806543

Epoch: 6| Step: 7
Training loss: 2.965086433218688
Validation loss: 2.5707843645486266

Epoch: 6| Step: 8
Training loss: 2.7532043861262223
Validation loss: 2.565542034636167

Epoch: 6| Step: 9
Training loss: 2.437771708676899
Validation loss: 2.5947581848618237

Epoch: 6| Step: 10
Training loss: 3.09436506842628
Validation loss: 2.593032561757687

Epoch: 6| Step: 11
Training loss: 2.913202644693268
Validation loss: 2.624180344972443

Epoch: 6| Step: 12
Training loss: 2.739028632764677
Validation loss: 2.636526679879013

Epoch: 6| Step: 13
Training loss: 3.2246936623031717
Validation loss: 2.61707900778555

Epoch: 191| Step: 0
Training loss: 3.830410769274877
Validation loss: 2.628516843016815

Epoch: 6| Step: 1
Training loss: 3.3291088673742824
Validation loss: 2.6220970939655195

Epoch: 6| Step: 2
Training loss: 2.77934010968656
Validation loss: 2.6085572715455587

Epoch: 6| Step: 3
Training loss: 3.1715081665184104
Validation loss: 2.603010681192453

Epoch: 6| Step: 4
Training loss: 2.6650030092433523
Validation loss: 2.6058103536680974

Epoch: 6| Step: 5
Training loss: 2.6121749018577427
Validation loss: 2.592492584682441

Epoch: 6| Step: 6
Training loss: 3.1628126148215943
Validation loss: 2.5889123695051386

Epoch: 6| Step: 7
Training loss: 2.4366429118065254
Validation loss: 2.5798082859464517

Epoch: 6| Step: 8
Training loss: 2.4815731923894147
Validation loss: 2.5857077231509513

Epoch: 6| Step: 9
Training loss: 2.6985386213783484
Validation loss: 2.576291049198904

Epoch: 6| Step: 10
Training loss: 3.163428876564175
Validation loss: 2.585614226240763

Epoch: 6| Step: 11
Training loss: 2.703484748318975
Validation loss: 2.5724115738223325

Epoch: 6| Step: 12
Training loss: 2.3747221131631577
Validation loss: 2.5776043159469024

Epoch: 6| Step: 13
Training loss: 2.902303333437466
Validation loss: 2.5769847298473323

Epoch: 192| Step: 0
Training loss: 3.1809784239319367
Validation loss: 2.598021854908828

Epoch: 6| Step: 1
Training loss: 2.257196150869697
Validation loss: 2.595026809217533

Epoch: 6| Step: 2
Training loss: 3.1898927870285574
Validation loss: 2.592329522643699

Epoch: 6| Step: 3
Training loss: 2.7459412881085528
Validation loss: 2.6048729192766302

Epoch: 6| Step: 4
Training loss: 2.6509008064145325
Validation loss: 2.610190657231958

Epoch: 6| Step: 5
Training loss: 2.377927080658222
Validation loss: 2.618511182463498

Epoch: 6| Step: 6
Training loss: 2.7865156411430676
Validation loss: 2.604174907712305

Epoch: 6| Step: 7
Training loss: 2.892395796815258
Validation loss: 2.612176598732334

Epoch: 6| Step: 8
Training loss: 3.4248316981042084
Validation loss: 2.621110005647185

Epoch: 6| Step: 9
Training loss: 2.980620414104841
Validation loss: 2.6512426520195476

Epoch: 6| Step: 10
Training loss: 2.965581065938813
Validation loss: 2.6503115244315474

Epoch: 6| Step: 11
Training loss: 2.87937296134292
Validation loss: 2.622504842016573

Epoch: 6| Step: 12
Training loss: 3.0845026084528984
Validation loss: 2.6329167451495925

Epoch: 6| Step: 13
Training loss: 3.1505209416339888
Validation loss: 2.59019527890241

Epoch: 193| Step: 0
Training loss: 3.0552364548798923
Validation loss: 2.588121812724881

Epoch: 6| Step: 1
Training loss: 3.1289909818037165
Validation loss: 2.586488145708115

Epoch: 6| Step: 2
Training loss: 2.601001759259759
Validation loss: 2.5917670246697657

Epoch: 6| Step: 3
Training loss: 2.799400595811771
Validation loss: 2.5808492308731448

Epoch: 6| Step: 4
Training loss: 2.6750773374126804
Validation loss: 2.575441841506676

Epoch: 6| Step: 5
Training loss: 3.013202860660428
Validation loss: 2.573919650698013

Epoch: 6| Step: 6
Training loss: 3.05278795113535
Validation loss: 2.575884859881725

Epoch: 6| Step: 7
Training loss: 2.5014037006209584
Validation loss: 2.581368099427821

Epoch: 6| Step: 8
Training loss: 2.984561614747895
Validation loss: 2.571926637062707

Epoch: 6| Step: 9
Training loss: 2.797778788047866
Validation loss: 2.578768054144863

Epoch: 6| Step: 10
Training loss: 3.024847919014525
Validation loss: 2.574680985050587

Epoch: 6| Step: 11
Training loss: 3.7269308679881874
Validation loss: 2.587326277162619

Epoch: 6| Step: 12
Training loss: 2.744936529652161
Validation loss: 2.593958471079275

Epoch: 6| Step: 13
Training loss: 1.6735148008642013
Validation loss: 2.608893120260771

Epoch: 194| Step: 0
Training loss: 2.8356852773944503
Validation loss: 2.619379320395974

Epoch: 6| Step: 1
Training loss: 2.5446278774805315
Validation loss: 2.6324755426024167

Epoch: 6| Step: 2
Training loss: 3.1224391362631825
Validation loss: 2.614217838446298

Epoch: 6| Step: 3
Training loss: 3.1620237210449846
Validation loss: 2.647602361623167

Epoch: 6| Step: 4
Training loss: 2.9165019034214827
Validation loss: 2.626484388221495

Epoch: 6| Step: 5
Training loss: 3.4148506983099636
Validation loss: 2.616259399279278

Epoch: 6| Step: 6
Training loss: 3.126103625922353
Validation loss: 2.603100664728486

Epoch: 6| Step: 7
Training loss: 2.4673694661870402
Validation loss: 2.597277294159477

Epoch: 6| Step: 8
Training loss: 2.9936726920513186
Validation loss: 2.5773057468121108

Epoch: 6| Step: 9
Training loss: 3.1253341496155143
Validation loss: 2.5759130898966967

Epoch: 6| Step: 10
Training loss: 2.4280637362691397
Validation loss: 2.5752724297621237

Epoch: 6| Step: 11
Training loss: 2.8111597894601155
Validation loss: 2.5807311527604697

Epoch: 6| Step: 12
Training loss: 2.7719523147070486
Validation loss: 2.583786033265877

Epoch: 6| Step: 13
Training loss: 2.632005516916076
Validation loss: 2.589395952850847

Epoch: 195| Step: 0
Training loss: 2.7030814283089675
Validation loss: 2.593587570550525

Epoch: 6| Step: 1
Training loss: 3.103477521005859
Validation loss: 2.6089149586835805

Epoch: 6| Step: 2
Training loss: 2.011272610572243
Validation loss: 2.6065027940950425

Epoch: 6| Step: 3
Training loss: 2.8453408287519255
Validation loss: 2.6031849372058695

Epoch: 6| Step: 4
Training loss: 3.216651306379206
Validation loss: 2.5994252605759076

Epoch: 6| Step: 5
Training loss: 3.1320204649216437
Validation loss: 2.5851953185753196

Epoch: 6| Step: 6
Training loss: 2.2775824341579307
Validation loss: 2.589395079623475

Epoch: 6| Step: 7
Training loss: 3.010537396994293
Validation loss: 2.600965529989716

Epoch: 6| Step: 8
Training loss: 3.3479713104732474
Validation loss: 2.594400085472923

Epoch: 6| Step: 9
Training loss: 3.195652129910324
Validation loss: 2.613485186008682

Epoch: 6| Step: 10
Training loss: 3.293918531474661
Validation loss: 2.6156250655115842

Epoch: 6| Step: 11
Training loss: 2.556037569429575
Validation loss: 2.603886120522977

Epoch: 6| Step: 12
Training loss: 2.640087998541936
Validation loss: 2.609213001866117

Epoch: 6| Step: 13
Training loss: 2.8270619117264437
Validation loss: 2.6090520175374947

Epoch: 196| Step: 0
Training loss: 3.011876123178387
Validation loss: 2.58278111408351

Epoch: 6| Step: 1
Training loss: 2.608531153025808
Validation loss: 2.5762822152751252

Epoch: 6| Step: 2
Training loss: 2.7954367237411097
Validation loss: 2.579739862546868

Epoch: 6| Step: 3
Training loss: 2.5385204499529053
Validation loss: 2.56915263516547

Epoch: 6| Step: 4
Training loss: 2.716879979829544
Validation loss: 2.5760404998041677

Epoch: 6| Step: 5
Training loss: 2.532708395454607
Validation loss: 2.5676631449682437

Epoch: 6| Step: 6
Training loss: 2.7369322235892133
Validation loss: 2.6144675252992653

Epoch: 6| Step: 7
Training loss: 2.872095382254152
Validation loss: 2.63298901228857

Epoch: 6| Step: 8
Training loss: 3.142652322238214
Validation loss: 2.6384805640466467

Epoch: 6| Step: 9
Training loss: 3.182341047154637
Validation loss: 2.5925910882030694

Epoch: 6| Step: 10
Training loss: 3.6466342300655468
Validation loss: 2.5905510015844375

Epoch: 6| Step: 11
Training loss: 3.170740084252376
Validation loss: 2.578196232552156

Epoch: 6| Step: 12
Training loss: 2.715677037415423
Validation loss: 2.5633571990819535

Epoch: 6| Step: 13
Training loss: 2.594320762984493
Validation loss: 2.565332947185536

Epoch: 197| Step: 0
Training loss: 2.6660569407856296
Validation loss: 2.5610011299425737

Epoch: 6| Step: 1
Training loss: 2.485441446833626
Validation loss: 2.5749650519747576

Epoch: 6| Step: 2
Training loss: 2.8699345954061704
Validation loss: 2.572550614354948

Epoch: 6| Step: 3
Training loss: 2.54860071797436
Validation loss: 2.5720131051290664

Epoch: 6| Step: 4
Training loss: 3.0592169778320817
Validation loss: 2.5708605720594218

Epoch: 6| Step: 5
Training loss: 3.0810385919745986
Validation loss: 2.583992972758176

Epoch: 6| Step: 6
Training loss: 3.0676452077556986
Validation loss: 2.5909927683255547

Epoch: 6| Step: 7
Training loss: 3.388505686441789
Validation loss: 2.613692957905664

Epoch: 6| Step: 8
Training loss: 2.795808556831135
Validation loss: 2.615536796866574

Epoch: 6| Step: 9
Training loss: 3.191459739358204
Validation loss: 2.657391295610632

Epoch: 6| Step: 10
Training loss: 2.5572216285909115
Validation loss: 2.6438281020164953

Epoch: 6| Step: 11
Training loss: 3.025902189540988
Validation loss: 2.642038762852527

Epoch: 6| Step: 12
Training loss: 3.002335592909489
Validation loss: 2.6317287495612627

Epoch: 6| Step: 13
Training loss: 2.7374596335862043
Validation loss: 2.6172828467162597

Epoch: 198| Step: 0
Training loss: 2.7111894561915997
Validation loss: 2.5893685618846733

Epoch: 6| Step: 1
Training loss: 3.2419718843025764
Validation loss: 2.5777690046280415

Epoch: 6| Step: 2
Training loss: 2.807857071953153
Validation loss: 2.577352572785463

Epoch: 6| Step: 3
Training loss: 2.307905840164505
Validation loss: 2.5628134653052417

Epoch: 6| Step: 4
Training loss: 2.620910820070747
Validation loss: 2.5632758993043256

Epoch: 6| Step: 5
Training loss: 3.3345355409051454
Validation loss: 2.5675468278381963

Epoch: 6| Step: 6
Training loss: 2.993824961446523
Validation loss: 2.5570257210797918

Epoch: 6| Step: 7
Training loss: 2.8809441195162724
Validation loss: 2.5646552389772244

Epoch: 6| Step: 8
Training loss: 2.354760514249331
Validation loss: 2.5669426452299295

Epoch: 6| Step: 9
Training loss: 2.7771203746648108
Validation loss: 2.5760911960941546

Epoch: 6| Step: 10
Training loss: 2.579895336482585
Validation loss: 2.5791580730705053

Epoch: 6| Step: 11
Training loss: 3.3930337673477853
Validation loss: 2.596540835205891

Epoch: 6| Step: 12
Training loss: 3.0345950203043337
Validation loss: 2.631571926842669

Epoch: 6| Step: 13
Training loss: 3.613082236918006
Validation loss: 2.6564119640678663

Epoch: 199| Step: 0
Training loss: 3.0235109936359907
Validation loss: 2.6240168135098334

Epoch: 6| Step: 1
Training loss: 3.4368934789848624
Validation loss: 2.593864682515346

Epoch: 6| Step: 2
Training loss: 2.439504532772481
Validation loss: 2.57618597304907

Epoch: 6| Step: 3
Training loss: 2.89947589873855
Validation loss: 2.567716785242192

Epoch: 6| Step: 4
Training loss: 2.302309626393394
Validation loss: 2.572198424206356

Epoch: 6| Step: 5
Training loss: 3.1867496878956816
Validation loss: 2.560732041769177

Epoch: 6| Step: 6
Training loss: 2.6465629312602967
Validation loss: 2.5838564162219497

Epoch: 6| Step: 7
Training loss: 3.0624898793578788
Validation loss: 2.599520979691921

Epoch: 6| Step: 8
Training loss: 2.6831651370327343
Validation loss: 2.608199084196099

Epoch: 6| Step: 9
Training loss: 2.902074624235874
Validation loss: 2.622230518138609

Epoch: 6| Step: 10
Training loss: 3.49267602016854
Validation loss: 2.6030610629800246

Epoch: 6| Step: 11
Training loss: 2.6279423889510967
Validation loss: 2.586640653997446

Epoch: 6| Step: 12
Training loss: 2.302397854638177
Validation loss: 2.563840171985049

Epoch: 6| Step: 13
Training loss: 3.1758578245496016
Validation loss: 2.5559464234950675

Epoch: 200| Step: 0
Training loss: 2.4311817149793638
Validation loss: 2.5675356208896107

Epoch: 6| Step: 1
Training loss: 3.3330696160582547
Validation loss: 2.557144445172267

Epoch: 6| Step: 2
Training loss: 2.8901284281036053
Validation loss: 2.5555164810636573

Epoch: 6| Step: 3
Training loss: 3.0826667546246966
Validation loss: 2.55371958397564

Epoch: 6| Step: 4
Training loss: 3.4214842412090394
Validation loss: 2.5603017780046122

Epoch: 6| Step: 5
Training loss: 2.8639216728155223
Validation loss: 2.558076972565399

Epoch: 6| Step: 6
Training loss: 2.6276988732945368
Validation loss: 2.5608090389705302

Epoch: 6| Step: 7
Training loss: 3.152061326848723
Validation loss: 2.5604496958839285

Epoch: 6| Step: 8
Training loss: 3.1140431389635057
Validation loss: 2.5702239080295084

Epoch: 6| Step: 9
Training loss: 2.4041207541098673
Validation loss: 2.56574351328644

Epoch: 6| Step: 10
Training loss: 2.611282747683289
Validation loss: 2.5831258252493483

Epoch: 6| Step: 11
Training loss: 2.87260121325737
Validation loss: 2.59111498643621

Epoch: 6| Step: 12
Training loss: 3.039597177419495
Validation loss: 2.6024342871282173

Epoch: 6| Step: 13
Training loss: 2.0539786272729192
Validation loss: 2.610987202491914

Epoch: 201| Step: 0
Training loss: 2.8680771115416377
Validation loss: 2.6089283825801717

Epoch: 6| Step: 1
Training loss: 2.4996687669668476
Validation loss: 2.6087421526430856

Epoch: 6| Step: 2
Training loss: 2.943063864146897
Validation loss: 2.5901657783050815

Epoch: 6| Step: 3
Training loss: 3.219479672584161
Validation loss: 2.587701809094132

Epoch: 6| Step: 4
Training loss: 2.6904087737390414
Validation loss: 2.6107032897106888

Epoch: 6| Step: 5
Training loss: 3.08751350430767
Validation loss: 2.612795721470977

Epoch: 6| Step: 6
Training loss: 3.048287245323984
Validation loss: 2.602050669425427

Epoch: 6| Step: 7
Training loss: 2.6339061967024078
Validation loss: 2.5923283764699088

Epoch: 6| Step: 8
Training loss: 2.636813601447876
Validation loss: 2.578956601638521

Epoch: 6| Step: 9
Training loss: 2.9013226485453
Validation loss: 2.5722789909972374

Epoch: 6| Step: 10
Training loss: 2.965066652626312
Validation loss: 2.577845979260867

Epoch: 6| Step: 11
Training loss: 2.5387394626235342
Validation loss: 2.587247851542418

Epoch: 6| Step: 12
Training loss: 3.1486015182443965
Validation loss: 2.5838171326941803

Epoch: 6| Step: 13
Training loss: 3.0131596582995415
Validation loss: 2.570778652459322

Epoch: 202| Step: 0
Training loss: 3.1687232082219974
Validation loss: 2.5935040582318494

Epoch: 6| Step: 1
Training loss: 2.5945166867980887
Validation loss: 2.6017806882329038

Epoch: 6| Step: 2
Training loss: 3.1124883812377266
Validation loss: 2.620920083123015

Epoch: 6| Step: 3
Training loss: 3.165540109985537
Validation loss: 2.6541856710171787

Epoch: 6| Step: 4
Training loss: 3.086978784960925
Validation loss: 2.67275873765207

Epoch: 6| Step: 5
Training loss: 3.1051281628288345
Validation loss: 2.6277971009765704

Epoch: 6| Step: 6
Training loss: 2.247596410565379
Validation loss: 2.587190281032498

Epoch: 6| Step: 7
Training loss: 3.115986145576361
Validation loss: 2.569280098941047

Epoch: 6| Step: 8
Training loss: 2.645293583720621
Validation loss: 2.552402753765763

Epoch: 6| Step: 9
Training loss: 2.9820584398628616
Validation loss: 2.5556605896922706

Epoch: 6| Step: 10
Training loss: 2.8922309332275256
Validation loss: 2.556740479708193

Epoch: 6| Step: 11
Training loss: 2.8602246965826663
Validation loss: 2.55024758756995

Epoch: 6| Step: 12
Training loss: 2.2965364790597382
Validation loss: 2.55532385740443

Epoch: 6| Step: 13
Training loss: 3.0798630817745822
Validation loss: 2.5591297992448747

Epoch: 203| Step: 0
Training loss: 2.5846012039546618
Validation loss: 2.5672377581339094

Epoch: 6| Step: 1
Training loss: 2.8791566737250456
Validation loss: 2.5826631014650103

Epoch: 6| Step: 2
Training loss: 2.750829918216071
Validation loss: 2.6131997125399207

Epoch: 6| Step: 3
Training loss: 3.4192592429869886
Validation loss: 2.611486677781882

Epoch: 6| Step: 4
Training loss: 2.7760551027661085
Validation loss: 2.6129452353414386

Epoch: 6| Step: 5
Training loss: 2.7475712194401796
Validation loss: 2.612537602631262

Epoch: 6| Step: 6
Training loss: 2.9467462343661315
Validation loss: 2.6303775365388926

Epoch: 6| Step: 7
Training loss: 3.2452196029862828
Validation loss: 2.6285081987563172

Epoch: 6| Step: 8
Training loss: 2.9340930417318165
Validation loss: 2.603225602617078

Epoch: 6| Step: 9
Training loss: 2.6482114442207974
Validation loss: 2.5667949741795004

Epoch: 6| Step: 10
Training loss: 2.785928113646642
Validation loss: 2.5562176953063207

Epoch: 6| Step: 11
Training loss: 3.208980660137457
Validation loss: 2.5430984908810705

Epoch: 6| Step: 12
Training loss: 2.5777845678112152
Validation loss: 2.5548125948231064

Epoch: 6| Step: 13
Training loss: 2.6821739294390383
Validation loss: 2.54538810685825

Epoch: 204| Step: 0
Training loss: 2.414425325750517
Validation loss: 2.5534588828308054

Epoch: 6| Step: 1
Training loss: 2.487526100826868
Validation loss: 2.560472021575296

Epoch: 6| Step: 2
Training loss: 2.8608261345064294
Validation loss: 2.578710279408491

Epoch: 6| Step: 3
Training loss: 2.6614605231129893
Validation loss: 2.603130482593012

Epoch: 6| Step: 4
Training loss: 2.8836615741270126
Validation loss: 2.624980059194928

Epoch: 6| Step: 5
Training loss: 3.3201596931749524
Validation loss: 2.6419675738783894

Epoch: 6| Step: 6
Training loss: 3.2952089846013206
Validation loss: 2.664478570111307

Epoch: 6| Step: 7
Training loss: 3.325159318591901
Validation loss: 2.633482368175101

Epoch: 6| Step: 8
Training loss: 3.217913472626256
Validation loss: 2.6137615919805306

Epoch: 6| Step: 9
Training loss: 1.9808601429042032
Validation loss: 2.5863971460938466

Epoch: 6| Step: 10
Training loss: 2.186317124031529
Validation loss: 2.5695982393597228

Epoch: 6| Step: 11
Training loss: 3.131306502694739
Validation loss: 2.555473225622631

Epoch: 6| Step: 12
Training loss: 3.0833596580687535
Validation loss: 2.548269355580489

Epoch: 6| Step: 13
Training loss: 3.5588625357293266
Validation loss: 2.5478519810779234

Epoch: 205| Step: 0
Training loss: 3.080745452983992
Validation loss: 2.5448752853965186

Epoch: 6| Step: 1
Training loss: 3.136431119089804
Validation loss: 2.5468604145730844

Epoch: 6| Step: 2
Training loss: 2.483936007119221
Validation loss: 2.547615574222471

Epoch: 6| Step: 3
Training loss: 3.183816913669897
Validation loss: 2.551326880854787

Epoch: 6| Step: 4
Training loss: 2.5414805005376366
Validation loss: 2.5454571938104733

Epoch: 6| Step: 5
Training loss: 3.2781694756500896
Validation loss: 2.5498279087195685

Epoch: 6| Step: 6
Training loss: 2.5572874505551475
Validation loss: 2.54772029166201

Epoch: 6| Step: 7
Training loss: 3.1600652617946468
Validation loss: 2.5509972463522748

Epoch: 6| Step: 8
Training loss: 3.115415753193558
Validation loss: 2.5498157954253196

Epoch: 6| Step: 9
Training loss: 3.0940229507413735
Validation loss: 2.560511375914491

Epoch: 6| Step: 10
Training loss: 2.734892267619443
Validation loss: 2.552784456568228

Epoch: 6| Step: 11
Training loss: 2.631267513117193
Validation loss: 2.575471686945451

Epoch: 6| Step: 12
Training loss: 2.747384388012421
Validation loss: 2.5659904698206653

Epoch: 6| Step: 13
Training loss: 2.6017713491561465
Validation loss: 2.5763502996399286

Epoch: 206| Step: 0
Training loss: 2.584024418919218
Validation loss: 2.5860885121476915

Epoch: 6| Step: 1
Training loss: 2.568584568608982
Validation loss: 2.6156545181148587

Epoch: 6| Step: 2
Training loss: 2.878676841425734
Validation loss: 2.614597832018923

Epoch: 6| Step: 3
Training loss: 2.975546195275295
Validation loss: 2.633332379457647

Epoch: 6| Step: 4
Training loss: 3.088578959985551
Validation loss: 2.6426743988092536

Epoch: 6| Step: 5
Training loss: 2.7392515457816016
Validation loss: 2.652585175211674

Epoch: 6| Step: 6
Training loss: 2.9951536451868987
Validation loss: 2.638580910680402

Epoch: 6| Step: 7
Training loss: 2.817135276035332
Validation loss: 2.6563015029807415

Epoch: 6| Step: 8
Training loss: 2.764329337377484
Validation loss: 2.6211942790963096

Epoch: 6| Step: 9
Training loss: 2.9773957295260898
Validation loss: 2.606435920794526

Epoch: 6| Step: 10
Training loss: 2.5796727938495683
Validation loss: 2.574990954424538

Epoch: 6| Step: 11
Training loss: 3.2583904531273933
Validation loss: 2.5463803936729104

Epoch: 6| Step: 12
Training loss: 2.911862276519862
Validation loss: 2.540165006884617

Epoch: 6| Step: 13
Training loss: 3.1509568047984358
Validation loss: 2.5339182700034293

Epoch: 207| Step: 0
Training loss: 3.1798764484323794
Validation loss: 2.5379684294718627

Epoch: 6| Step: 1
Training loss: 2.716670326121231
Validation loss: 2.5377727080533616

Epoch: 6| Step: 2
Training loss: 3.496290693649765
Validation loss: 2.5323001359914614

Epoch: 6| Step: 3
Training loss: 2.644579933428368
Validation loss: 2.542239917465552

Epoch: 6| Step: 4
Training loss: 2.466115584115787
Validation loss: 2.5505589352154225

Epoch: 6| Step: 5
Training loss: 2.8568908239647013
Validation loss: 2.551624022875833

Epoch: 6| Step: 6
Training loss: 3.092982803933324
Validation loss: 2.5659375188087483

Epoch: 6| Step: 7
Training loss: 3.242005713088916
Validation loss: 2.561816000421189

Epoch: 6| Step: 8
Training loss: 2.6531779756862344
Validation loss: 2.5806386736049935

Epoch: 6| Step: 9
Training loss: 2.848915857606311
Validation loss: 2.5879302280806455

Epoch: 6| Step: 10
Training loss: 2.6398419003396896
Validation loss: 2.578243613101503

Epoch: 6| Step: 11
Training loss: 3.485175481288708
Validation loss: 2.604470627960096

Epoch: 6| Step: 12
Training loss: 1.702284439265162
Validation loss: 2.6034671505161597

Epoch: 6| Step: 13
Training loss: 2.8753426389106562
Validation loss: 2.6237318986928035

Epoch: 208| Step: 0
Training loss: 3.3209701784306027
Validation loss: 2.620947875995932

Epoch: 6| Step: 1
Training loss: 2.577803343156489
Validation loss: 2.6513324228924677

Epoch: 6| Step: 2
Training loss: 2.240015659447838
Validation loss: 2.628878085853103

Epoch: 6| Step: 3
Training loss: 2.6832427971139996
Validation loss: 2.5954334939943804

Epoch: 6| Step: 4
Training loss: 2.672591620820451
Validation loss: 2.568804738561049

Epoch: 6| Step: 5
Training loss: 3.342131891630653
Validation loss: 2.5655219354645165

Epoch: 6| Step: 6
Training loss: 2.3178914087119282
Validation loss: 2.5589168897804617

Epoch: 6| Step: 7
Training loss: 2.710199524970242
Validation loss: 2.5439840830640157

Epoch: 6| Step: 8
Training loss: 3.0554301342124828
Validation loss: 2.5344612309929753

Epoch: 6| Step: 9
Training loss: 2.861944159634106
Validation loss: 2.539689794249478

Epoch: 6| Step: 10
Training loss: 3.0751184022019435
Validation loss: 2.544949230594534

Epoch: 6| Step: 11
Training loss: 3.255570259827732
Validation loss: 2.5618874322666296

Epoch: 6| Step: 12
Training loss: 2.8433770574477655
Validation loss: 2.583361635109334

Epoch: 6| Step: 13
Training loss: 3.4715163738398083
Validation loss: 2.5902627273719534

Epoch: 209| Step: 0
Training loss: 3.325481959239964
Validation loss: 2.591871607134295

Epoch: 6| Step: 1
Training loss: 3.4319064320167114
Validation loss: 2.6085934454993622

Epoch: 6| Step: 2
Training loss: 3.2484963680069123
Validation loss: 2.6165243475215068

Epoch: 6| Step: 3
Training loss: 2.8404683052044595
Validation loss: 2.6100248908226167

Epoch: 6| Step: 4
Training loss: 3.2828866419165794
Validation loss: 2.6178167966196435

Epoch: 6| Step: 5
Training loss: 2.071576693364375
Validation loss: 2.6125715705279307

Epoch: 6| Step: 6
Training loss: 3.030605601608365
Validation loss: 2.621409733107593

Epoch: 6| Step: 7
Training loss: 2.5722265102972326
Validation loss: 2.6072988018593612

Epoch: 6| Step: 8
Training loss: 2.5412243838691504
Validation loss: 2.6048176820882145

Epoch: 6| Step: 9
Training loss: 2.6281111309760576
Validation loss: 2.605303800001723

Epoch: 6| Step: 10
Training loss: 2.7521199811352637
Validation loss: 2.6188390979944747

Epoch: 6| Step: 11
Training loss: 2.928362493339071
Validation loss: 2.6103725028695526

Epoch: 6| Step: 12
Training loss: 2.750170355635423
Validation loss: 2.6036971284613095

Epoch: 6| Step: 13
Training loss: 2.629474368782705
Validation loss: 2.6022254182753253

Epoch: 210| Step: 0
Training loss: 2.813362497958959
Validation loss: 2.593390142189902

Epoch: 6| Step: 1
Training loss: 2.744077460488566
Validation loss: 2.589832094109017

Epoch: 6| Step: 2
Training loss: 2.6897438795266684
Validation loss: 2.604291836263317

Epoch: 6| Step: 3
Training loss: 2.8059706449053956
Validation loss: 2.6080210504064194

Epoch: 6| Step: 4
Training loss: 2.7489899601092125
Validation loss: 2.598915153169536

Epoch: 6| Step: 5
Training loss: 2.590527290369835
Validation loss: 2.6019940796633163

Epoch: 6| Step: 6
Training loss: 3.043075618409827
Validation loss: 2.5938008917826836

Epoch: 6| Step: 7
Training loss: 3.232748018620086
Validation loss: 2.601711005969871

Epoch: 6| Step: 8
Training loss: 2.6159614082312967
Validation loss: 2.6026297252599266

Epoch: 6| Step: 9
Training loss: 3.1932823241851205
Validation loss: 2.6092962948613065

Epoch: 6| Step: 10
Training loss: 3.069834897699435
Validation loss: 2.604878944365111

Epoch: 6| Step: 11
Training loss: 2.5000318525192515
Validation loss: 2.606180720690806

Epoch: 6| Step: 12
Training loss: 3.1156389027613427
Validation loss: 2.606916854869778

Epoch: 6| Step: 13
Training loss: 3.2072575404519874
Validation loss: 2.6290567072185658

Epoch: 211| Step: 0
Training loss: 3.4360165256018464
Validation loss: 2.6241775099199067

Epoch: 6| Step: 1
Training loss: 2.8935073915620837
Validation loss: 2.6327200001517808

Epoch: 6| Step: 2
Training loss: 2.701967200903953
Validation loss: 2.6185216592045344

Epoch: 6| Step: 3
Training loss: 2.9049942420994332
Validation loss: 2.6026656417725933

Epoch: 6| Step: 4
Training loss: 2.845022734164027
Validation loss: 2.5761733776544884

Epoch: 6| Step: 5
Training loss: 2.6895795361654327
Validation loss: 2.580985743886514

Epoch: 6| Step: 6
Training loss: 2.751758360079174
Validation loss: 2.5790412873019752

Epoch: 6| Step: 7
Training loss: 2.6102754786599456
Validation loss: 2.579578452095726

Epoch: 6| Step: 8
Training loss: 2.922517267311585
Validation loss: 2.5872787488392994

Epoch: 6| Step: 9
Training loss: 2.789526379901043
Validation loss: 2.5844259012525126

Epoch: 6| Step: 10
Training loss: 3.1753552515924763
Validation loss: 2.57803689129306

Epoch: 6| Step: 11
Training loss: 2.4811178484491756
Validation loss: 2.5981959896577256

Epoch: 6| Step: 12
Training loss: 3.160260966184541
Validation loss: 2.6209440661576577

Epoch: 6| Step: 13
Training loss: 2.8410467357235483
Validation loss: 2.632138967696319

Epoch: 212| Step: 0
Training loss: 2.749867436074893
Validation loss: 2.6830642258253405

Epoch: 6| Step: 1
Training loss: 3.371417935056742
Validation loss: 2.6908154204262726

Epoch: 6| Step: 2
Training loss: 3.19473388208338
Validation loss: 2.66146531429322

Epoch: 6| Step: 3
Training loss: 3.11949221660403
Validation loss: 2.6759316918500935

Epoch: 6| Step: 4
Training loss: 2.529334391312017
Validation loss: 2.6431482604660435

Epoch: 6| Step: 5
Training loss: 2.302275556131073
Validation loss: 2.6115711086317

Epoch: 6| Step: 6
Training loss: 3.404261857518552
Validation loss: 2.614777674502034

Epoch: 6| Step: 7
Training loss: 2.5186105391369193
Validation loss: 2.5871185578792746

Epoch: 6| Step: 8
Training loss: 2.8080825871062842
Validation loss: 2.5858439955352863

Epoch: 6| Step: 9
Training loss: 2.607716655855571
Validation loss: 2.572437493014434

Epoch: 6| Step: 10
Training loss: 2.8025861853789706
Validation loss: 2.5833433318432553

Epoch: 6| Step: 11
Training loss: 2.7466039495653214
Validation loss: 2.569819433787018

Epoch: 6| Step: 12
Training loss: 3.35157900363798
Validation loss: 2.5639162059395497

Epoch: 6| Step: 13
Training loss: 1.9773958281460577
Validation loss: 2.5622983773639363

Epoch: 213| Step: 0
Training loss: 3.045791198466862
Validation loss: 2.577011145215697

Epoch: 6| Step: 1
Training loss: 2.85893471251613
Validation loss: 2.579040002022758

Epoch: 6| Step: 2
Training loss: 2.400944893321757
Validation loss: 2.5917536038777462

Epoch: 6| Step: 3
Training loss: 3.621717084547457
Validation loss: 2.6193279757180004

Epoch: 6| Step: 4
Training loss: 2.8072637345452542
Validation loss: 2.6180435438538736

Epoch: 6| Step: 5
Training loss: 2.093279657627385
Validation loss: 2.6477939536389137

Epoch: 6| Step: 6
Training loss: 3.060471777855786
Validation loss: 2.6430956592765957

Epoch: 6| Step: 7
Training loss: 3.2495219539306315
Validation loss: 2.6301140968857912

Epoch: 6| Step: 8
Training loss: 2.5060840960835824
Validation loss: 2.5876819216713653

Epoch: 6| Step: 9
Training loss: 3.0546792266811718
Validation loss: 2.554205889809605

Epoch: 6| Step: 10
Training loss: 2.7961044528753143
Validation loss: 2.5468221518401535

Epoch: 6| Step: 11
Training loss: 2.9532246244873117
Validation loss: 2.543671478126232

Epoch: 6| Step: 12
Training loss: 2.074788103429673
Validation loss: 2.5351022362894033

Epoch: 6| Step: 13
Training loss: 3.418656041390168
Validation loss: 2.543680423791765

Epoch: 214| Step: 0
Training loss: 3.0881874091445654
Validation loss: 2.5483474325315303

Epoch: 6| Step: 1
Training loss: 3.3807688259646294
Validation loss: 2.5477704788357665

Epoch: 6| Step: 2
Training loss: 2.6852590399727494
Validation loss: 2.546608147958972

Epoch: 6| Step: 3
Training loss: 2.8272850517510575
Validation loss: 2.5624499092238513

Epoch: 6| Step: 4
Training loss: 2.793928245644308
Validation loss: 2.5862967597219066

Epoch: 6| Step: 5
Training loss: 3.047693074269647
Validation loss: 2.601698689836345

Epoch: 6| Step: 6
Training loss: 2.5048546386086126
Validation loss: 2.604166452387319

Epoch: 6| Step: 7
Training loss: 3.229235560184735
Validation loss: 2.607897046105392

Epoch: 6| Step: 8
Training loss: 2.6792860258655544
Validation loss: 2.597716882778181

Epoch: 6| Step: 9
Training loss: 2.4698095824322412
Validation loss: 2.5945374802805987

Epoch: 6| Step: 10
Training loss: 2.640191127187544
Validation loss: 2.589938161278591

Epoch: 6| Step: 11
Training loss: 2.6566808014624894
Validation loss: 2.563913758201493

Epoch: 6| Step: 12
Training loss: 2.8831247713662385
Validation loss: 2.5695340527185113

Epoch: 6| Step: 13
Training loss: 3.155408237119771
Validation loss: 2.5650359240500555

Epoch: 215| Step: 0
Training loss: 2.474567367811374
Validation loss: 2.5372659930650663

Epoch: 6| Step: 1
Training loss: 3.394823559992331
Validation loss: 2.5403524040584946

Epoch: 6| Step: 2
Training loss: 2.7935734020972625
Validation loss: 2.5423305857413934

Epoch: 6| Step: 3
Training loss: 2.135387389439798
Validation loss: 2.546156277971312

Epoch: 6| Step: 4
Training loss: 2.818587264207832
Validation loss: 2.5375450568748055

Epoch: 6| Step: 5
Training loss: 3.189480633684187
Validation loss: 2.539802424020257

Epoch: 6| Step: 6
Training loss: 3.214284224736913
Validation loss: 2.54031730497652

Epoch: 6| Step: 7
Training loss: 2.48047048012981
Validation loss: 2.5432129323323345

Epoch: 6| Step: 8
Training loss: 3.066493797267361
Validation loss: 2.5520851337827484

Epoch: 6| Step: 9
Training loss: 2.4721596265814463
Validation loss: 2.57065647273631

Epoch: 6| Step: 10
Training loss: 2.780107670764077
Validation loss: 2.578675930091221

Epoch: 6| Step: 11
Training loss: 3.063685129475743
Validation loss: 2.5964022006092287

Epoch: 6| Step: 12
Training loss: 2.5215443220628586
Validation loss: 2.594762025244266

Epoch: 6| Step: 13
Training loss: 3.535495063183779
Validation loss: 2.651602872634128

Epoch: 216| Step: 0
Training loss: 3.0882165918932603
Validation loss: 2.6482840761686584

Epoch: 6| Step: 1
Training loss: 3.0945470534578163
Validation loss: 2.6239738236026313

Epoch: 6| Step: 2
Training loss: 2.751802114075523
Validation loss: 2.5878619629597472

Epoch: 6| Step: 3
Training loss: 3.273554032830278
Validation loss: 2.555371315926666

Epoch: 6| Step: 4
Training loss: 2.620919189098067
Validation loss: 2.559773983780891

Epoch: 6| Step: 5
Training loss: 2.4325421113841434
Validation loss: 2.552248587331941

Epoch: 6| Step: 6
Training loss: 2.6171774792835216
Validation loss: 2.5328408724658487

Epoch: 6| Step: 7
Training loss: 3.037358372530102
Validation loss: 2.541533333683461

Epoch: 6| Step: 8
Training loss: 2.7221628450764563
Validation loss: 2.5415772843106126

Epoch: 6| Step: 9
Training loss: 3.0485806899313754
Validation loss: 2.531778292342204

Epoch: 6| Step: 10
Training loss: 2.667573913579832
Validation loss: 2.5449079603626767

Epoch: 6| Step: 11
Training loss: 2.556016302268704
Validation loss: 2.5434421031774637

Epoch: 6| Step: 12
Training loss: 2.9992584265638005
Validation loss: 2.543863686100797

Epoch: 6| Step: 13
Training loss: 3.2144021603517694
Validation loss: 2.572680041262321

Epoch: 217| Step: 0
Training loss: 3.0383434867026597
Validation loss: 2.565392260345561

Epoch: 6| Step: 1
Training loss: 3.2117811890557038
Validation loss: 2.5983112119847673

Epoch: 6| Step: 2
Training loss: 3.247463997515774
Validation loss: 2.608540023681236

Epoch: 6| Step: 3
Training loss: 2.7590744114043058
Validation loss: 2.6163981124368316

Epoch: 6| Step: 4
Training loss: 1.7522602471275008
Validation loss: 2.6024631162171326

Epoch: 6| Step: 5
Training loss: 3.0723457107727814
Validation loss: 2.5855300711731712

Epoch: 6| Step: 6
Training loss: 2.391728564091668
Validation loss: 2.5630200066266635

Epoch: 6| Step: 7
Training loss: 2.442742310201605
Validation loss: 2.5560785365998138

Epoch: 6| Step: 8
Training loss: 3.1634311375774917
Validation loss: 2.5596253873514145

Epoch: 6| Step: 9
Training loss: 3.5104970196471
Validation loss: 2.5402163394302484

Epoch: 6| Step: 10
Training loss: 2.626148608364369
Validation loss: 2.5528114577672745

Epoch: 6| Step: 11
Training loss: 2.8150776389275123
Validation loss: 2.562241230806496

Epoch: 6| Step: 12
Training loss: 2.8368085043829714
Validation loss: 2.5544671499904426

Epoch: 6| Step: 13
Training loss: 2.557445658743176
Validation loss: 2.5644914125796845

Epoch: 218| Step: 0
Training loss: 3.2197400394489706
Validation loss: 2.559124505925586

Epoch: 6| Step: 1
Training loss: 2.294495991899319
Validation loss: 2.559629367582277

Epoch: 6| Step: 2
Training loss: 3.1360637888356933
Validation loss: 2.5581774917434252

Epoch: 6| Step: 3
Training loss: 3.077745133405489
Validation loss: 2.541329445364987

Epoch: 6| Step: 4
Training loss: 2.691585008860823
Validation loss: 2.538515052055179

Epoch: 6| Step: 5
Training loss: 3.151094058943742
Validation loss: 2.5404544913919853

Epoch: 6| Step: 6
Training loss: 3.060081305327498
Validation loss: 2.52686202633509

Epoch: 6| Step: 7
Training loss: 3.297454638396889
Validation loss: 2.548700962109194

Epoch: 6| Step: 8
Training loss: 2.971159108095303
Validation loss: 2.552708426478269

Epoch: 6| Step: 9
Training loss: 2.8071447462562964
Validation loss: 2.559878287977494

Epoch: 6| Step: 10
Training loss: 2.683167980462079
Validation loss: 2.5440893067001595

Epoch: 6| Step: 11
Training loss: 2.3606478055782065
Validation loss: 2.550268980240923

Epoch: 6| Step: 12
Training loss: 2.3307498753371796
Validation loss: 2.5566840050821176

Epoch: 6| Step: 13
Training loss: 2.3513674227380688
Validation loss: 2.5592227791609163

Epoch: 219| Step: 0
Training loss: 2.158732326061922
Validation loss: 2.581918338499052

Epoch: 6| Step: 1
Training loss: 2.7934736315682906
Validation loss: 2.574323748603716

Epoch: 6| Step: 2
Training loss: 2.8996359103300513
Validation loss: 2.584718596454693

Epoch: 6| Step: 3
Training loss: 2.999316455534403
Validation loss: 2.5901157543978712

Epoch: 6| Step: 4
Training loss: 3.217415394059668
Validation loss: 2.588624243587878

Epoch: 6| Step: 5
Training loss: 2.471172448013749
Validation loss: 2.603015634617501

Epoch: 6| Step: 6
Training loss: 2.9919286869954647
Validation loss: 2.5990424820209883

Epoch: 6| Step: 7
Training loss: 2.7186902796006875
Validation loss: 2.585437209384106

Epoch: 6| Step: 8
Training loss: 2.218527231987709
Validation loss: 2.610315284252713

Epoch: 6| Step: 9
Training loss: 3.256015199480501
Validation loss: 2.585367008286392

Epoch: 6| Step: 10
Training loss: 3.0235478974919077
Validation loss: 2.561786283098064

Epoch: 6| Step: 11
Training loss: 2.6244488092024243
Validation loss: 2.56159051101563

Epoch: 6| Step: 12
Training loss: 3.1102378069857326
Validation loss: 2.5550244977651677

Epoch: 6| Step: 13
Training loss: 3.152151940996953
Validation loss: 2.5531628269207847

Epoch: 220| Step: 0
Training loss: 2.9020424194811096
Validation loss: 2.572309074452549

Epoch: 6| Step: 1
Training loss: 2.8696983216065153
Validation loss: 2.580339680621329

Epoch: 6| Step: 2
Training loss: 2.336446445098669
Validation loss: 2.576922359733472

Epoch: 6| Step: 3
Training loss: 2.5603903483276387
Validation loss: 2.573655024070823

Epoch: 6| Step: 4
Training loss: 2.913490055096715
Validation loss: 2.5711434198766567

Epoch: 6| Step: 5
Training loss: 3.1740417596369057
Validation loss: 2.585692533851116

Epoch: 6| Step: 6
Training loss: 3.264075390693041
Validation loss: 2.561483271013607

Epoch: 6| Step: 7
Training loss: 2.5350048331491117
Validation loss: 2.5683432146943703

Epoch: 6| Step: 8
Training loss: 3.0199814395460507
Validation loss: 2.5941061029215353

Epoch: 6| Step: 9
Training loss: 2.630855025052083
Validation loss: 2.592855784400463

Epoch: 6| Step: 10
Training loss: 2.864235837262274
Validation loss: 2.5941342216139778

Epoch: 6| Step: 11
Training loss: 2.786059646367769
Validation loss: 2.586814179320871

Epoch: 6| Step: 12
Training loss: 3.1185483328343064
Validation loss: 2.5861363339619308

Epoch: 6| Step: 13
Training loss: 2.1764250373015757
Validation loss: 2.5971403019278525

Epoch: 221| Step: 0
Training loss: 2.648519419075536
Validation loss: 2.582180663806279

Epoch: 6| Step: 1
Training loss: 2.710541358169195
Validation loss: 2.584882942948706

Epoch: 6| Step: 2
Training loss: 2.8543927922204877
Validation loss: 2.587316930004577

Epoch: 6| Step: 3
Training loss: 3.1695885145107336
Validation loss: 2.5822649875970876

Epoch: 6| Step: 4
Training loss: 2.676614940550476
Validation loss: 2.571647125241777

Epoch: 6| Step: 5
Training loss: 2.6716400400105274
Validation loss: 2.570586728654118

Epoch: 6| Step: 6
Training loss: 2.654820315500236
Validation loss: 2.5836813001321466

Epoch: 6| Step: 7
Training loss: 2.8809954284610515
Validation loss: 2.544564671949459

Epoch: 6| Step: 8
Training loss: 2.8466553989637067
Validation loss: 2.562048349263038

Epoch: 6| Step: 9
Training loss: 2.811550234328707
Validation loss: 2.559093601297472

Epoch: 6| Step: 10
Training loss: 2.748830112956907
Validation loss: 2.544231134410746

Epoch: 6| Step: 11
Training loss: 2.6423214310551675
Validation loss: 2.5464234924822966

Epoch: 6| Step: 12
Training loss: 3.263103478986714
Validation loss: 2.5425875478394047

Epoch: 6| Step: 13
Training loss: 3.0249164916562807
Validation loss: 2.565610022309603

Epoch: 222| Step: 0
Training loss: 3.0824099696022147
Validation loss: 2.5765408399247036

Epoch: 6| Step: 1
Training loss: 2.8602492033153193
Validation loss: 2.612910982865102

Epoch: 6| Step: 2
Training loss: 3.145148061593556
Validation loss: 2.648175635256806

Epoch: 6| Step: 3
Training loss: 2.8693197777414907
Validation loss: 2.6636348885551544

Epoch: 6| Step: 4
Training loss: 3.2393533475793643
Validation loss: 2.7032717569442704

Epoch: 6| Step: 5
Training loss: 2.471727724185025
Validation loss: 2.675970351223801

Epoch: 6| Step: 6
Training loss: 2.419021204842475
Validation loss: 2.648714617867855

Epoch: 6| Step: 7
Training loss: 2.867208288465594
Validation loss: 2.6145613827576746

Epoch: 6| Step: 8
Training loss: 2.4635723238456215
Validation loss: 2.585523851273728

Epoch: 6| Step: 9
Training loss: 2.5404801856478696
Validation loss: 2.551234690385172

Epoch: 6| Step: 10
Training loss: 3.3271259366442707
Validation loss: 2.5381480458516616

Epoch: 6| Step: 11
Training loss: 3.031942386794449
Validation loss: 2.5350491770862766

Epoch: 6| Step: 12
Training loss: 2.3461610726609607
Validation loss: 2.5289385040423205

Epoch: 6| Step: 13
Training loss: 3.001495306562611
Validation loss: 2.5277981066713666

Epoch: 223| Step: 0
Training loss: 2.0963925439074225
Validation loss: 2.5241221330307155

Epoch: 6| Step: 1
Training loss: 2.871048907494199
Validation loss: 2.521483898158825

Epoch: 6| Step: 2
Training loss: 3.4555175225828263
Validation loss: 2.549875108594881

Epoch: 6| Step: 3
Training loss: 2.492041700158155
Validation loss: 2.563695035173164

Epoch: 6| Step: 4
Training loss: 3.204908218854977
Validation loss: 2.5891404787126846

Epoch: 6| Step: 5
Training loss: 2.8417307632988567
Validation loss: 2.589797290444735

Epoch: 6| Step: 6
Training loss: 2.974520085197552
Validation loss: 2.5894777997786846

Epoch: 6| Step: 7
Training loss: 2.138920125967151
Validation loss: 2.5899837076644965

Epoch: 6| Step: 8
Training loss: 1.844525125793088
Validation loss: 2.605922210281244

Epoch: 6| Step: 9
Training loss: 3.160340029131588
Validation loss: 2.614193414187921

Epoch: 6| Step: 10
Training loss: 2.9533880207460763
Validation loss: 2.634530620143322

Epoch: 6| Step: 11
Training loss: 3.2201324753136067
Validation loss: 2.6205798122171653

Epoch: 6| Step: 12
Training loss: 2.8245905925520334
Validation loss: 2.5991696053960367

Epoch: 6| Step: 13
Training loss: 3.2039246096081495
Validation loss: 2.589451800178864

Epoch: 224| Step: 0
Training loss: 2.8584624955454534
Validation loss: 2.5631720949342216

Epoch: 6| Step: 1
Training loss: 3.196589506197249
Validation loss: 2.5451308714964624

Epoch: 6| Step: 2
Training loss: 3.3217411333673326
Validation loss: 2.539440196226636

Epoch: 6| Step: 3
Training loss: 2.5696399121782174
Validation loss: 2.5360464726205714

Epoch: 6| Step: 4
Training loss: 3.0675349982642697
Validation loss: 2.5392665228898457

Epoch: 6| Step: 5
Training loss: 2.673913011116036
Validation loss: 2.5425158570994886

Epoch: 6| Step: 6
Training loss: 2.1401022391095132
Validation loss: 2.561763314381261

Epoch: 6| Step: 7
Training loss: 2.8649444537411997
Validation loss: 2.5723231089592513

Epoch: 6| Step: 8
Training loss: 2.3061487770093367
Validation loss: 2.5846069172359667

Epoch: 6| Step: 9
Training loss: 2.533581260629196
Validation loss: 2.609777560862332

Epoch: 6| Step: 10
Training loss: 2.3506315802979305
Validation loss: 2.6340181089131574

Epoch: 6| Step: 11
Training loss: 3.0398472260685923
Validation loss: 2.6130001986830402

Epoch: 6| Step: 12
Training loss: 3.3352750526941586
Validation loss: 2.624020778136045

Epoch: 6| Step: 13
Training loss: 3.171606644426483
Validation loss: 2.5981109070753794

Epoch: 225| Step: 0
Training loss: 2.7630332397604263
Validation loss: 2.602238921013075

Epoch: 6| Step: 1
Training loss: 3.2401705063589357
Validation loss: 2.5875324609262065

Epoch: 6| Step: 2
Training loss: 2.6901741031050554
Validation loss: 2.587692043728843

Epoch: 6| Step: 3
Training loss: 2.365141132006778
Validation loss: 2.5822795309015496

Epoch: 6| Step: 4
Training loss: 3.2405301557472996
Validation loss: 2.582443225536992

Epoch: 6| Step: 5
Training loss: 2.28409054677228
Validation loss: 2.5781698999258196

Epoch: 6| Step: 6
Training loss: 2.732619763094258
Validation loss: 2.5895722248941744

Epoch: 6| Step: 7
Training loss: 2.7868116683590847
Validation loss: 2.6259806510812833

Epoch: 6| Step: 8
Training loss: 2.8551412621606116
Validation loss: 2.6228869577128684

Epoch: 6| Step: 9
Training loss: 2.7576238551472265
Validation loss: 2.6058438170061162

Epoch: 6| Step: 10
Training loss: 2.9720453544431633
Validation loss: 2.6094762998482226

Epoch: 6| Step: 11
Training loss: 2.552360758332142
Validation loss: 2.583861896997028

Epoch: 6| Step: 12
Training loss: 2.6498075559303502
Validation loss: 2.596064889028445

Epoch: 6| Step: 13
Training loss: 3.5592666140591454
Validation loss: 2.5816799708803786

Epoch: 226| Step: 0
Training loss: 2.571661968840855
Validation loss: 2.5766346949295915

Epoch: 6| Step: 1
Training loss: 3.0530764338711815
Validation loss: 2.571262717961567

Epoch: 6| Step: 2
Training loss: 3.1179755034692582
Validation loss: 2.6016705395812134

Epoch: 6| Step: 3
Training loss: 2.748116541821926
Validation loss: 2.594446695802298

Epoch: 6| Step: 4
Training loss: 3.020761335545343
Validation loss: 2.5947300492187373

Epoch: 6| Step: 5
Training loss: 2.3409327550434367
Validation loss: 2.5810028063880703

Epoch: 6| Step: 6
Training loss: 2.665238554334991
Validation loss: 2.59626319918355

Epoch: 6| Step: 7
Training loss: 2.425795992746565
Validation loss: 2.59270797457441

Epoch: 6| Step: 8
Training loss: 2.7837004421363827
Validation loss: 2.591132264213303

Epoch: 6| Step: 9
Training loss: 2.7897117564293197
Validation loss: 2.5992410532196852

Epoch: 6| Step: 10
Training loss: 2.8105392402932265
Validation loss: 2.6097668810410184

Epoch: 6| Step: 11
Training loss: 2.9288849812302917
Validation loss: 2.618071068604555

Epoch: 6| Step: 12
Training loss: 2.686282924700614
Validation loss: 2.614955449258226

Epoch: 6| Step: 13
Training loss: 3.8012243406614545
Validation loss: 2.6318602691395627

Epoch: 227| Step: 0
Training loss: 2.528695784028609
Validation loss: 2.6167361251482695

Epoch: 6| Step: 1
Training loss: 3.456806412621456
Validation loss: 2.6261848416501543

Epoch: 6| Step: 2
Training loss: 3.5504841863841152
Validation loss: 2.6081449308592926

Epoch: 6| Step: 3
Training loss: 2.9450926357136153
Validation loss: 2.590863938605529

Epoch: 6| Step: 4
Training loss: 2.7100261288611422
Validation loss: 2.5804856476655473

Epoch: 6| Step: 5
Training loss: 2.76135165136657
Validation loss: 2.56507865143916

Epoch: 6| Step: 6
Training loss: 3.1199868236165704
Validation loss: 2.5588671406303294

Epoch: 6| Step: 7
Training loss: 2.0850816892726147
Validation loss: 2.576418123494993

Epoch: 6| Step: 8
Training loss: 2.518493533270241
Validation loss: 2.5646319790771988

Epoch: 6| Step: 9
Training loss: 2.583254802699762
Validation loss: 2.5697770735322747

Epoch: 6| Step: 10
Training loss: 2.3051020879749182
Validation loss: 2.552393196854622

Epoch: 6| Step: 11
Training loss: 2.9130677680773465
Validation loss: 2.5623422099388566

Epoch: 6| Step: 12
Training loss: 3.035292299577105
Validation loss: 2.569551951509449

Epoch: 6| Step: 13
Training loss: 2.3086756451276385
Validation loss: 2.5880923608032793

Epoch: 228| Step: 0
Training loss: 2.4530820417591164
Validation loss: 2.588219346482681

Epoch: 6| Step: 1
Training loss: 3.622411658853296
Validation loss: 2.6011992278532095

Epoch: 6| Step: 2
Training loss: 2.6631500381907753
Validation loss: 2.6125484801387304

Epoch: 6| Step: 3
Training loss: 2.9593483880366134
Validation loss: 2.5853055305614245

Epoch: 6| Step: 4
Training loss: 2.0671498451638284
Validation loss: 2.5953120047582936

Epoch: 6| Step: 5
Training loss: 2.6620037816376914
Validation loss: 2.6106031874086133

Epoch: 6| Step: 6
Training loss: 3.15070210458416
Validation loss: 2.606599277154696

Epoch: 6| Step: 7
Training loss: 2.49069513583539
Validation loss: 2.5781216906951716

Epoch: 6| Step: 8
Training loss: 3.1636861695083134
Validation loss: 2.57074861192602

Epoch: 6| Step: 9
Training loss: 2.298357530521361
Validation loss: 2.5518527849510555

Epoch: 6| Step: 10
Training loss: 2.7511062997729017
Validation loss: 2.557340733045497

Epoch: 6| Step: 11
Training loss: 2.757456121571137
Validation loss: 2.563079658373688

Epoch: 6| Step: 12
Training loss: 2.933040724233922
Validation loss: 2.564714678763863

Epoch: 6| Step: 13
Training loss: 2.9333060335565095
Validation loss: 2.5554183130906774

Epoch: 229| Step: 0
Training loss: 2.544633592861205
Validation loss: 2.5673030956242746

Epoch: 6| Step: 1
Training loss: 2.860080486045404
Validation loss: 2.585839251617357

Epoch: 6| Step: 2
Training loss: 2.87470840965684
Validation loss: 2.5878051847724377

Epoch: 6| Step: 3
Training loss: 1.8126403491172216
Validation loss: 2.5954015282170473

Epoch: 6| Step: 4
Training loss: 3.3072060080822028
Validation loss: 2.556145445090008

Epoch: 6| Step: 5
Training loss: 2.8832327683685612
Validation loss: 2.5827657388310636

Epoch: 6| Step: 6
Training loss: 2.8537493955299915
Validation loss: 2.5962615797899713

Epoch: 6| Step: 7
Training loss: 2.8585300552098603
Validation loss: 2.6111378198917436

Epoch: 6| Step: 8
Training loss: 2.8467587494381115
Validation loss: 2.5965358304292554

Epoch: 6| Step: 9
Training loss: 2.4055923950491205
Validation loss: 2.5888692917926277

Epoch: 6| Step: 10
Training loss: 3.2456202706828297
Validation loss: 2.552297658921683

Epoch: 6| Step: 11
Training loss: 2.8664300318199527
Validation loss: 2.5554315665640654

Epoch: 6| Step: 12
Training loss: 2.712882012394086
Validation loss: 2.5521985504949756

Epoch: 6| Step: 13
Training loss: 3.1277603165489394
Validation loss: 2.5471554265896987

Epoch: 230| Step: 0
Training loss: 2.764251712858917
Validation loss: 2.5529723583847916

Epoch: 6| Step: 1
Training loss: 2.4890260165714286
Validation loss: 2.542076927680811

Epoch: 6| Step: 2
Training loss: 2.960109464064734
Validation loss: 2.558052316938715

Epoch: 6| Step: 3
Training loss: 2.33923270728106
Validation loss: 2.5706275457367487

Epoch: 6| Step: 4
Training loss: 2.3174254055425183
Validation loss: 2.5971773811373686

Epoch: 6| Step: 5
Training loss: 2.8229477846652227
Validation loss: 2.614975139063914

Epoch: 6| Step: 6
Training loss: 2.979939785035349
Validation loss: 2.6393799768675215

Epoch: 6| Step: 7
Training loss: 3.148787031815349
Validation loss: 2.6903952256363564

Epoch: 6| Step: 8
Training loss: 2.180604584528094
Validation loss: 2.672855635008178

Epoch: 6| Step: 9
Training loss: 2.9236053402305866
Validation loss: 2.6426190679905566

Epoch: 6| Step: 10
Training loss: 2.7511890615034496
Validation loss: 2.594243713904255

Epoch: 6| Step: 11
Training loss: 3.1104835566086213
Validation loss: 2.5678046480360357

Epoch: 6| Step: 12
Training loss: 3.5088884024780445
Validation loss: 2.5474202890766344

Epoch: 6| Step: 13
Training loss: 2.8370564252683184
Validation loss: 2.522303477386333

Epoch: 231| Step: 0
Training loss: 2.4712928520504613
Validation loss: 2.5246706578549754

Epoch: 6| Step: 1
Training loss: 2.9679316948899324
Validation loss: 2.5174153155322205

Epoch: 6| Step: 2
Training loss: 2.7518575636852587
Validation loss: 2.5211723572219475

Epoch: 6| Step: 3
Training loss: 3.6513677098655686
Validation loss: 2.516906278485294

Epoch: 6| Step: 4
Training loss: 2.932222210799492
Validation loss: 2.527965174013694

Epoch: 6| Step: 5
Training loss: 2.7287922570822447
Validation loss: 2.534326510562771

Epoch: 6| Step: 6
Training loss: 2.684371102699941
Validation loss: 2.5506154650516164

Epoch: 6| Step: 7
Training loss: 3.0232769433103788
Validation loss: 2.5702025358229426

Epoch: 6| Step: 8
Training loss: 2.653051627394776
Validation loss: 2.586317227258744

Epoch: 6| Step: 9
Training loss: 2.620713321462967
Validation loss: 2.5971224955459937

Epoch: 6| Step: 10
Training loss: 2.778240504400756
Validation loss: 2.640645662437937

Epoch: 6| Step: 11
Training loss: 2.418238413722735
Validation loss: 2.6952054357226842

Epoch: 6| Step: 12
Training loss: 3.135761651780917
Validation loss: 2.685030482488403

Epoch: 6| Step: 13
Training loss: 2.131364044091493
Validation loss: 2.645082743396664

Epoch: 232| Step: 0
Training loss: 3.312055162034942
Validation loss: 2.6115647976162712

Epoch: 6| Step: 1
Training loss: 3.500522846951062
Validation loss: 2.569339389828094

Epoch: 6| Step: 2
Training loss: 2.5905271063002915
Validation loss: 2.5572840501259875

Epoch: 6| Step: 3
Training loss: 2.4523948020032535
Validation loss: 2.5308455956059226

Epoch: 6| Step: 4
Training loss: 2.7155197948450067
Validation loss: 2.5106049766030925

Epoch: 6| Step: 5
Training loss: 3.061115808439103
Validation loss: 2.509040633256502

Epoch: 6| Step: 6
Training loss: 2.6430435391093514
Validation loss: 2.512331843280556

Epoch: 6| Step: 7
Training loss: 3.0838674821497984
Validation loss: 2.5127495272970704

Epoch: 6| Step: 8
Training loss: 2.280049256244452
Validation loss: 2.5355456146278503

Epoch: 6| Step: 9
Training loss: 2.604124897939771
Validation loss: 2.528435794947773

Epoch: 6| Step: 10
Training loss: 2.972415468186629
Validation loss: 2.5429035433779146

Epoch: 6| Step: 11
Training loss: 2.367279151678191
Validation loss: 2.5666594423571416

Epoch: 6| Step: 12
Training loss: 2.8384924274805203
Validation loss: 2.560387899221393

Epoch: 6| Step: 13
Training loss: 2.813861856292019
Validation loss: 2.5656137519417896

Epoch: 233| Step: 0
Training loss: 2.928567168601523
Validation loss: 2.603353479885222

Epoch: 6| Step: 1
Training loss: 2.6737929927727544
Validation loss: 2.5908612600477383

Epoch: 6| Step: 2
Training loss: 3.090044056106119
Validation loss: 2.566491178973208

Epoch: 6| Step: 3
Training loss: 2.2809199264231954
Validation loss: 2.55997165429986

Epoch: 6| Step: 4
Training loss: 2.8857494580069156
Validation loss: 2.549162543431053

Epoch: 6| Step: 5
Training loss: 2.989356232810922
Validation loss: 2.5651164319686437

Epoch: 6| Step: 6
Training loss: 2.4772362018339136
Validation loss: 2.5504072145282253

Epoch: 6| Step: 7
Training loss: 2.8880329779646776
Validation loss: 2.5575330694789518

Epoch: 6| Step: 8
Training loss: 2.5540941581785024
Validation loss: 2.5611699642136196

Epoch: 6| Step: 9
Training loss: 3.407675768432383
Validation loss: 2.5756894965143786

Epoch: 6| Step: 10
Training loss: 3.0171602916626648
Validation loss: 2.5761336993209216

Epoch: 6| Step: 11
Training loss: 2.2923250350827837
Validation loss: 2.578101241125645

Epoch: 6| Step: 12
Training loss: 2.798206885977768
Validation loss: 2.579940320865529

Epoch: 6| Step: 13
Training loss: 2.7172598427195815
Validation loss: 2.5803849205383402

Epoch: 234| Step: 0
Training loss: 3.3966306596768563
Validation loss: 2.5875025267229765

Epoch: 6| Step: 1
Training loss: 2.438631919766942
Validation loss: 2.587041529154161

Epoch: 6| Step: 2
Training loss: 2.811877966016709
Validation loss: 2.5786613033328214

Epoch: 6| Step: 3
Training loss: 2.5838876765258862
Validation loss: 2.571652524374096

Epoch: 6| Step: 4
Training loss: 3.092804272916223
Validation loss: 2.580549313543171

Epoch: 6| Step: 5
Training loss: 2.219688754214964
Validation loss: 2.5733105610102824

Epoch: 6| Step: 6
Training loss: 3.1597999777443233
Validation loss: 2.5585361369332387

Epoch: 6| Step: 7
Training loss: 2.4437022406942948
Validation loss: 2.543100944540777

Epoch: 6| Step: 8
Training loss: 1.6250899363352105
Validation loss: 2.5412522518932694

Epoch: 6| Step: 9
Training loss: 2.8546969809789706
Validation loss: 2.5348908443630185

Epoch: 6| Step: 10
Training loss: 2.427841220999587
Validation loss: 2.538673127437902

Epoch: 6| Step: 11
Training loss: 2.8523750715121574
Validation loss: 2.5569557310303637

Epoch: 6| Step: 12
Training loss: 3.7826438415568377
Validation loss: 2.5667842483542658

Epoch: 6| Step: 13
Training loss: 2.7341306740731532
Validation loss: 2.6197675550007653

Epoch: 235| Step: 0
Training loss: 2.9041361350630592
Validation loss: 2.666227420527261

Epoch: 6| Step: 1
Training loss: 3.0019011831164266
Validation loss: 2.668382767984428

Epoch: 6| Step: 2
Training loss: 3.118541146358464
Validation loss: 2.634550240523992

Epoch: 6| Step: 3
Training loss: 2.6908870910523155
Validation loss: 2.589796336180848

Epoch: 6| Step: 4
Training loss: 2.5824450739792373
Validation loss: 2.542322189938229

Epoch: 6| Step: 5
Training loss: 2.8159690655179617
Validation loss: 2.5236326895411176

Epoch: 6| Step: 6
Training loss: 2.8535067684132747
Validation loss: 2.5099410745761817

Epoch: 6| Step: 7
Training loss: 3.0331070707283714
Validation loss: 2.5168092488291793

Epoch: 6| Step: 8
Training loss: 2.699393016969685
Validation loss: 2.5104385931233293

Epoch: 6| Step: 9
Training loss: 2.608334453773461
Validation loss: 2.524901670070167

Epoch: 6| Step: 10
Training loss: 2.933489720192754
Validation loss: 2.5175549128275123

Epoch: 6| Step: 11
Training loss: 2.5236612226677484
Validation loss: 2.5132036203307755

Epoch: 6| Step: 12
Training loss: 3.2281549324944856
Validation loss: 2.5516625079790893

Epoch: 6| Step: 13
Training loss: 2.5521133005887
Validation loss: 2.562559419748898

Epoch: 236| Step: 0
Training loss: 2.7705428370351766
Validation loss: 2.584310055876321

Epoch: 6| Step: 1
Training loss: 2.4912748668786646
Validation loss: 2.6166654205345425

Epoch: 6| Step: 2
Training loss: 3.020903873716176
Validation loss: 2.6041254541561054

Epoch: 6| Step: 3
Training loss: 2.6143590418041076
Validation loss: 2.6409762695515955

Epoch: 6| Step: 4
Training loss: 2.6287299404567057
Validation loss: 2.624408395475689

Epoch: 6| Step: 5
Training loss: 3.0754483586147807
Validation loss: 2.5979273081407586

Epoch: 6| Step: 6
Training loss: 2.8797425668949845
Validation loss: 2.577186706574917

Epoch: 6| Step: 7
Training loss: 3.001845427984383
Validation loss: 2.5678857270606983

Epoch: 6| Step: 8
Training loss: 2.8400195459579747
Validation loss: 2.5553492566770974

Epoch: 6| Step: 9
Training loss: 2.423541473971925
Validation loss: 2.5561971968718025

Epoch: 6| Step: 10
Training loss: 2.9270709344096733
Validation loss: 2.559083314030689

Epoch: 6| Step: 11
Training loss: 3.162448047316752
Validation loss: 2.5655280169944383

Epoch: 6| Step: 12
Training loss: 2.7152483961028433
Validation loss: 2.5475747305876357

Epoch: 6| Step: 13
Training loss: 2.2788787432119832
Validation loss: 2.5521211458526953

Epoch: 237| Step: 0
Training loss: 2.390409372615696
Validation loss: 2.558567264723213

Epoch: 6| Step: 1
Training loss: 2.7329411698286044
Validation loss: 2.5436614983707533

Epoch: 6| Step: 2
Training loss: 2.777026881345072
Validation loss: 2.56200608266268

Epoch: 6| Step: 3
Training loss: 3.251241300190656
Validation loss: 2.5813012597499694

Epoch: 6| Step: 4
Training loss: 2.423018154950047
Validation loss: 2.5882552084083463

Epoch: 6| Step: 5
Training loss: 2.514397173429837
Validation loss: 2.6230011110613414

Epoch: 6| Step: 6
Training loss: 2.7223430874866468
Validation loss: 2.6391302835631736

Epoch: 6| Step: 7
Training loss: 2.9338666481652345
Validation loss: 2.6379801808163115

Epoch: 6| Step: 8
Training loss: 2.8743786347679983
Validation loss: 2.6418386642155904

Epoch: 6| Step: 9
Training loss: 2.975123901351598
Validation loss: 2.686917596026868

Epoch: 6| Step: 10
Training loss: 3.0081376333504424
Validation loss: 2.676275329028571

Epoch: 6| Step: 11
Training loss: 2.324516828640589
Validation loss: 2.5794214394147117

Epoch: 6| Step: 12
Training loss: 2.7297196349778297
Validation loss: 2.5488604767215284

Epoch: 6| Step: 13
Training loss: 3.4290616587571163
Validation loss: 2.507042146346016

Epoch: 238| Step: 0
Training loss: 2.530197866791684
Validation loss: 2.502093028608107

Epoch: 6| Step: 1
Training loss: 2.365371057544284
Validation loss: 2.502301116412465

Epoch: 6| Step: 2
Training loss: 3.102398584323617
Validation loss: 2.5035562959728677

Epoch: 6| Step: 3
Training loss: 2.631967471202905
Validation loss: 2.5096293352425376

Epoch: 6| Step: 4
Training loss: 2.9627951881362407
Validation loss: 2.4984449944412

Epoch: 6| Step: 5
Training loss: 3.6208353783733767
Validation loss: 2.5119965880496022

Epoch: 6| Step: 6
Training loss: 2.5998056339092823
Validation loss: 2.5389935278221225

Epoch: 6| Step: 7
Training loss: 2.8583405504793595
Validation loss: 2.559980793363037

Epoch: 6| Step: 8
Training loss: 2.2497838234366574
Validation loss: 2.6059431380388105

Epoch: 6| Step: 9
Training loss: 3.2910149005470273
Validation loss: 2.691495708066701

Epoch: 6| Step: 10
Training loss: 3.059807664399061
Validation loss: 2.6756782072972505

Epoch: 6| Step: 11
Training loss: 2.9431046930707376
Validation loss: 2.652978399293909

Epoch: 6| Step: 12
Training loss: 2.5901160463824833
Validation loss: 2.579271304194243

Epoch: 6| Step: 13
Training loss: 2.3483550543916514
Validation loss: 2.5430208556235505

Epoch: 239| Step: 0
Training loss: 2.7969836847936222
Validation loss: 2.5222850532419185

Epoch: 6| Step: 1
Training loss: 2.68290948264822
Validation loss: 2.5138965223321086

Epoch: 6| Step: 2
Training loss: 2.3372941686406783
Validation loss: 2.521267547337302

Epoch: 6| Step: 3
Training loss: 2.821377624410445
Validation loss: 2.5233677451521377

Epoch: 6| Step: 4
Training loss: 2.4756923554851413
Validation loss: 2.5334383499801687

Epoch: 6| Step: 5
Training loss: 2.8859262578773146
Validation loss: 2.532828395536763

Epoch: 6| Step: 6
Training loss: 2.6660853785517706
Validation loss: 2.5390621163215696

Epoch: 6| Step: 7
Training loss: 3.310869067332332
Validation loss: 2.551881358174076

Epoch: 6| Step: 8
Training loss: 2.476122507186036
Validation loss: 2.5668594370530333

Epoch: 6| Step: 9
Training loss: 2.8645203369611916
Validation loss: 2.563572006831741

Epoch: 6| Step: 10
Training loss: 2.7722379427480894
Validation loss: 2.5703453123958857

Epoch: 6| Step: 11
Training loss: 2.9871781052067456
Validation loss: 2.5645536001876685

Epoch: 6| Step: 12
Training loss: 3.2050642888469634
Validation loss: 2.5748227446418013

Epoch: 6| Step: 13
Training loss: 2.6071974754211245
Validation loss: 2.5746275874518902

Epoch: 240| Step: 0
Training loss: 2.3313549601062915
Validation loss: 2.5582513901565984

Epoch: 6| Step: 1
Training loss: 3.458938055519906
Validation loss: 2.5648409027746197

Epoch: 6| Step: 2
Training loss: 2.521025647690776
Validation loss: 2.5735253832109866

Epoch: 6| Step: 3
Training loss: 3.089041469504316
Validation loss: 2.5936535974134625

Epoch: 6| Step: 4
Training loss: 2.8550522444399236
Validation loss: 2.593039544689446

Epoch: 6| Step: 5
Training loss: 2.671011534254277
Validation loss: 2.5869847735903018

Epoch: 6| Step: 6
Training loss: 2.1724165646034774
Validation loss: 2.597171591864293

Epoch: 6| Step: 7
Training loss: 2.770579151933344
Validation loss: 2.589042943018565

Epoch: 6| Step: 8
Training loss: 2.7379279024316134
Validation loss: 2.604379242783381

Epoch: 6| Step: 9
Training loss: 2.82573822638401
Validation loss: 2.6043132939231612

Epoch: 6| Step: 10
Training loss: 3.093763871595322
Validation loss: 2.631099258036042

Epoch: 6| Step: 11
Training loss: 2.8109633592451972
Validation loss: 2.6227783884739115

Epoch: 6| Step: 12
Training loss: 2.5340595430033943
Validation loss: 2.586239834663994

Epoch: 6| Step: 13
Training loss: 2.552776496849066
Validation loss: 2.5617810062757616

Epoch: 241| Step: 0
Training loss: 2.485491999347574
Validation loss: 2.5416183241818158

Epoch: 6| Step: 1
Training loss: 2.943330214064239
Validation loss: 2.545076284793386

Epoch: 6| Step: 2
Training loss: 3.258395575069548
Validation loss: 2.5338200432997793

Epoch: 6| Step: 3
Training loss: 3.1522892943716565
Validation loss: 2.508500216078998

Epoch: 6| Step: 4
Training loss: 2.8241664939678457
Validation loss: 2.5256865542410654

Epoch: 6| Step: 5
Training loss: 3.0059697835473345
Validation loss: 2.532494269927802

Epoch: 6| Step: 6
Training loss: 2.737405198776761
Validation loss: 2.545380878382986

Epoch: 6| Step: 7
Training loss: 2.577541585858714
Validation loss: 2.5796238216377914

Epoch: 6| Step: 8
Training loss: 2.429752851876835
Validation loss: 2.612768687672804

Epoch: 6| Step: 9
Training loss: 2.5283618981045546
Validation loss: 2.6449753740725424

Epoch: 6| Step: 10
Training loss: 3.197079046604387
Validation loss: 2.704033358466627

Epoch: 6| Step: 11
Training loss: 2.507463282338182
Validation loss: 2.688845874338703

Epoch: 6| Step: 12
Training loss: 2.2323466878196006
Validation loss: 2.6369411467992947

Epoch: 6| Step: 13
Training loss: 2.9763207525169046
Validation loss: 2.5996074401459226

Epoch: 242| Step: 0
Training loss: 2.546294257294837
Validation loss: 2.5767241967188115

Epoch: 6| Step: 1
Training loss: 2.474336315526154
Validation loss: 2.5504740597091797

Epoch: 6| Step: 2
Training loss: 2.3033370894729455
Validation loss: 2.5573054250362888

Epoch: 6| Step: 3
Training loss: 3.5952404082960605
Validation loss: 2.5607311948081124

Epoch: 6| Step: 4
Training loss: 3.3700202656031863
Validation loss: 2.542123809592845

Epoch: 6| Step: 5
Training loss: 2.2616198687770606
Validation loss: 2.5328539100673795

Epoch: 6| Step: 6
Training loss: 2.7595534408434808
Validation loss: 2.5419489459859848

Epoch: 6| Step: 7
Training loss: 2.28417853933944
Validation loss: 2.538092620104346

Epoch: 6| Step: 8
Training loss: 2.757413667795505
Validation loss: 2.5315839075510618

Epoch: 6| Step: 9
Training loss: 2.908190991726704
Validation loss: 2.5322796929943716

Epoch: 6| Step: 10
Training loss: 2.5477199907935835
Validation loss: 2.543266901805959

Epoch: 6| Step: 11
Training loss: 2.958413530435769
Validation loss: 2.5457528457685714

Epoch: 6| Step: 12
Training loss: 2.2918303228954082
Validation loss: 2.540952931945659

Epoch: 6| Step: 13
Training loss: 3.4135505763847442
Validation loss: 2.5538435818371084

Epoch: 243| Step: 0
Training loss: 2.7149681886105475
Validation loss: 2.599063120930912

Epoch: 6| Step: 1
Training loss: 2.882831687139739
Validation loss: 2.6046505569942537

Epoch: 6| Step: 2
Training loss: 2.4272747264486254
Validation loss: 2.6222882236768896

Epoch: 6| Step: 3
Training loss: 2.726106796876244
Validation loss: 2.6494953069627036

Epoch: 6| Step: 4
Training loss: 2.67228240537735
Validation loss: 2.6628077649056006

Epoch: 6| Step: 5
Training loss: 3.040765515616006
Validation loss: 2.613876060486123

Epoch: 6| Step: 6
Training loss: 2.4813695038043813
Validation loss: 2.6195448892507676

Epoch: 6| Step: 7
Training loss: 2.3179076605532765
Validation loss: 2.6318929278680443

Epoch: 6| Step: 8
Training loss: 2.7369299586863534
Validation loss: 2.6009936632341115

Epoch: 6| Step: 9
Training loss: 3.1186535287128834
Validation loss: 2.5645494496623957

Epoch: 6| Step: 10
Training loss: 2.526725021164861
Validation loss: 2.5538144834714185

Epoch: 6| Step: 11
Training loss: 2.7290103275471287
Validation loss: 2.5484133951780628

Epoch: 6| Step: 12
Training loss: 3.0989536488388087
Validation loss: 2.5311300537178325

Epoch: 6| Step: 13
Training loss: 3.189188341781951
Validation loss: 2.5467719459784846

Epoch: 244| Step: 0
Training loss: 3.2943765294102763
Validation loss: 2.5354814213276953

Epoch: 6| Step: 1
Training loss: 2.5450430992688964
Validation loss: 2.558763298172721

Epoch: 6| Step: 2
Training loss: 2.435050320271813
Validation loss: 2.544610860218734

Epoch: 6| Step: 3
Training loss: 2.3269873790259363
Validation loss: 2.566266975463967

Epoch: 6| Step: 4
Training loss: 2.8429705211762824
Validation loss: 2.578053256342052

Epoch: 6| Step: 5
Training loss: 2.5772981184625623
Validation loss: 2.6225029875955905

Epoch: 6| Step: 6
Training loss: 3.12308504559616
Validation loss: 2.6385235439804084

Epoch: 6| Step: 7
Training loss: 2.6008148493706327
Validation loss: 2.718679310963233

Epoch: 6| Step: 8
Training loss: 2.8220718264451956
Validation loss: 2.7932759567006005

Epoch: 6| Step: 9
Training loss: 3.042404259560006
Validation loss: 2.8647808722049857

Epoch: 6| Step: 10
Training loss: 3.083316046863933
Validation loss: 2.8107005462004806

Epoch: 6| Step: 11
Training loss: 2.4561546714862383
Validation loss: 2.686183411397181

Epoch: 6| Step: 12
Training loss: 3.1621190260044196
Validation loss: 2.6125981010164008

Epoch: 6| Step: 13
Training loss: 2.641178863044034
Validation loss: 2.5448926192181163

Epoch: 245| Step: 0
Training loss: 2.928690097145758
Validation loss: 2.5109771561004814

Epoch: 6| Step: 1
Training loss: 3.221243327810759
Validation loss: 2.500553228836806

Epoch: 6| Step: 2
Training loss: 3.1405454407289195
Validation loss: 2.509841202142654

Epoch: 6| Step: 3
Training loss: 3.2141023432181908
Validation loss: 2.513386968971873

Epoch: 6| Step: 4
Training loss: 2.6030707125824666
Validation loss: 2.517583465958732

Epoch: 6| Step: 5
Training loss: 2.575143095318151
Validation loss: 2.512388066415813

Epoch: 6| Step: 6
Training loss: 2.5168925817617724
Validation loss: 2.5121843608192576

Epoch: 6| Step: 7
Training loss: 3.1570027275279084
Validation loss: 2.5040734785731957

Epoch: 6| Step: 8
Training loss: 2.5187513933580203
Validation loss: 2.5034519236624297

Epoch: 6| Step: 9
Training loss: 2.6849206478675414
Validation loss: 2.5030945340188118

Epoch: 6| Step: 10
Training loss: 2.7221745813400626
Validation loss: 2.516519647164146

Epoch: 6| Step: 11
Training loss: 2.453336864482716
Validation loss: 2.5365028078444882

Epoch: 6| Step: 12
Training loss: 3.114677776491043
Validation loss: 2.5771295479592475

Epoch: 6| Step: 13
Training loss: 2.4369128571568712
Validation loss: 2.5924920872803

Epoch: 246| Step: 0
Training loss: 2.609922614284046
Validation loss: 2.611385585506056

Epoch: 6| Step: 1
Training loss: 2.9423643378112336
Validation loss: 2.6493814059053746

Epoch: 6| Step: 2
Training loss: 1.9619627928010495
Validation loss: 2.6577683145517823

Epoch: 6| Step: 3
Training loss: 3.0950729161857153
Validation loss: 2.685955247543181

Epoch: 6| Step: 4
Training loss: 3.21704174747243
Validation loss: 2.671472772108371

Epoch: 6| Step: 5
Training loss: 2.485063373517454
Validation loss: 2.6420394702205634

Epoch: 6| Step: 6
Training loss: 2.812120200050355
Validation loss: 2.637330883680987

Epoch: 6| Step: 7
Training loss: 2.3133860772062915
Validation loss: 2.60205243694279

Epoch: 6| Step: 8
Training loss: 3.2511553544726244
Validation loss: 2.597891602427872

Epoch: 6| Step: 9
Training loss: 2.951831837245058
Validation loss: 2.5806619600997753

Epoch: 6| Step: 10
Training loss: 2.5155854784781275
Validation loss: 2.5736696309700564

Epoch: 6| Step: 11
Training loss: 3.2574975023823645
Validation loss: 2.5860693166563364

Epoch: 6| Step: 12
Training loss: 2.6224239970377137
Validation loss: 2.6029539497936236

Epoch: 6| Step: 13
Training loss: 2.8761703762686235
Validation loss: 2.600632277266577

Epoch: 247| Step: 0
Training loss: 2.3391364912155366
Validation loss: 2.61354668652402

Epoch: 6| Step: 1
Training loss: 2.8682307286578923
Validation loss: 2.651471634254532

Epoch: 6| Step: 2
Training loss: 3.3616592093444733
Validation loss: 2.6637464150618078

Epoch: 6| Step: 3
Training loss: 2.8985342333504183
Validation loss: 2.6758643084519047

Epoch: 6| Step: 4
Training loss: 2.7901883457557592
Validation loss: 2.679852471041596

Epoch: 6| Step: 5
Training loss: 3.1259556644197577
Validation loss: 2.665495152426871

Epoch: 6| Step: 6
Training loss: 2.9379142306839845
Validation loss: 2.680321717774814

Epoch: 6| Step: 7
Training loss: 2.494169015506242
Validation loss: 2.6762968044082482

Epoch: 6| Step: 8
Training loss: 2.9114160051265823
Validation loss: 2.687444088681687

Epoch: 6| Step: 9
Training loss: 3.220350885879679
Validation loss: 2.6871599219266473

Epoch: 6| Step: 10
Training loss: 2.172817108224025
Validation loss: 2.667243585232901

Epoch: 6| Step: 11
Training loss: 2.986544793940546
Validation loss: 2.644971467994818

Epoch: 6| Step: 12
Training loss: 2.178702511294497
Validation loss: 2.612494843824232

Epoch: 6| Step: 13
Training loss: 2.534425509663281
Validation loss: 2.5809579527653566

Epoch: 248| Step: 0
Training loss: 2.6312019108163094
Validation loss: 2.560615738178098

Epoch: 6| Step: 1
Training loss: 2.9388239697323217
Validation loss: 2.5616840511124463

Epoch: 6| Step: 2
Training loss: 2.7007584989923017
Validation loss: 2.5590900870619944

Epoch: 6| Step: 3
Training loss: 2.816004455942183
Validation loss: 2.5565265620139948

Epoch: 6| Step: 4
Training loss: 2.462597774365381
Validation loss: 2.558638175072055

Epoch: 6| Step: 5
Training loss: 2.8141485680820986
Validation loss: 2.5585492269635512

Epoch: 6| Step: 6
Training loss: 2.6917181401798174
Validation loss: 2.559712738675418

Epoch: 6| Step: 7
Training loss: 3.183239052326704
Validation loss: 2.588857026465741

Epoch: 6| Step: 8
Training loss: 2.8429735402242207
Validation loss: 2.5982909795278912

Epoch: 6| Step: 9
Training loss: 2.4685165681211507
Validation loss: 2.5959528911023724

Epoch: 6| Step: 10
Training loss: 2.640519179531856
Validation loss: 2.6339518908858555

Epoch: 6| Step: 11
Training loss: 3.1803181840550256
Validation loss: 2.6378882995114052

Epoch: 6| Step: 12
Training loss: 3.3295941043037156
Validation loss: 2.653234193610774

Epoch: 6| Step: 13
Training loss: 1.7165076453741206
Validation loss: 2.6226167539443117

Epoch: 249| Step: 0
Training loss: 2.212060542024845
Validation loss: 2.5830472502617177

Epoch: 6| Step: 1
Training loss: 3.180711436072595
Validation loss: 2.581921028320322

Epoch: 6| Step: 2
Training loss: 3.0799573682336447
Validation loss: 2.560546308316072

Epoch: 6| Step: 3
Training loss: 2.7245529333031593
Validation loss: 2.570615038792491

Epoch: 6| Step: 4
Training loss: 2.4213737707451504
Validation loss: 2.543782272752945

Epoch: 6| Step: 5
Training loss: 2.962287373698744
Validation loss: 2.533097334794687

Epoch: 6| Step: 6
Training loss: 2.3780411774428485
Validation loss: 2.522910418092474

Epoch: 6| Step: 7
Training loss: 2.4195852961553337
Validation loss: 2.5373421160857865

Epoch: 6| Step: 8
Training loss: 2.351968622465447
Validation loss: 2.522059635994525

Epoch: 6| Step: 9
Training loss: 2.6410751410544533
Validation loss: 2.5169398288788067

Epoch: 6| Step: 10
Training loss: 3.019556516711881
Validation loss: 2.5243705676105077

Epoch: 6| Step: 11
Training loss: 3.383049020581756
Validation loss: 2.5229887905484345

Epoch: 6| Step: 12
Training loss: 2.753864001227341
Validation loss: 2.5292124045010227

Epoch: 6| Step: 13
Training loss: 2.6384442596186304
Validation loss: 2.5395672050272906

Epoch: 250| Step: 0
Training loss: 3.2941481174133638
Validation loss: 2.5517142693015646

Epoch: 6| Step: 1
Training loss: 1.977925369771782
Validation loss: 2.587413713838438

Epoch: 6| Step: 2
Training loss: 2.7965947868588303
Validation loss: 2.604774979617171

Epoch: 6| Step: 3
Training loss: 2.4578809375777553
Validation loss: 2.6344825168479837

Epoch: 6| Step: 4
Training loss: 2.6747444315958537
Validation loss: 2.654174567169126

Epoch: 6| Step: 5
Training loss: 2.9003980231913222
Validation loss: 2.638496046036773

Epoch: 6| Step: 6
Training loss: 2.4497661556828842
Validation loss: 2.6007348452268233

Epoch: 6| Step: 7
Training loss: 3.2189665786321213
Validation loss: 2.579530193657873

Epoch: 6| Step: 8
Training loss: 2.4059121030890815
Validation loss: 2.5533411766468768

Epoch: 6| Step: 9
Training loss: 2.4486892346821176
Validation loss: 2.5188722914275474

Epoch: 6| Step: 10
Training loss: 2.7402391603608875
Validation loss: 2.5220661730134464

Epoch: 6| Step: 11
Training loss: 3.7096532265782476
Validation loss: 2.5085806610792702

Epoch: 6| Step: 12
Training loss: 2.6761071667958793
Validation loss: 2.5143938709931497

Epoch: 6| Step: 13
Training loss: 2.1594475520045395
Validation loss: 2.519564246517818

Epoch: 251| Step: 0
Training loss: 2.9347284106227294
Validation loss: 2.520687900118637

Epoch: 6| Step: 1
Training loss: 2.5701549910777017
Validation loss: 2.524829187771384

Epoch: 6| Step: 2
Training loss: 2.653455363667133
Validation loss: 2.5296328478382817

Epoch: 6| Step: 3
Training loss: 2.293884510389129
Validation loss: 2.541790316872419

Epoch: 6| Step: 4
Training loss: 2.8181211459433197
Validation loss: 2.540357304570289

Epoch: 6| Step: 5
Training loss: 3.3394999366162827
Validation loss: 2.5546349449204686

Epoch: 6| Step: 6
Training loss: 2.9809323571485997
Validation loss: 2.5755943698356036

Epoch: 6| Step: 7
Training loss: 2.9854601739524758
Validation loss: 2.5828087108935565

Epoch: 6| Step: 8
Training loss: 2.579741277659809
Validation loss: 2.5664621311073197

Epoch: 6| Step: 9
Training loss: 2.753639067546589
Validation loss: 2.5672958409781192

Epoch: 6| Step: 10
Training loss: 2.8749084458078564
Validation loss: 2.579971947587032

Epoch: 6| Step: 11
Training loss: 2.4583445618798674
Validation loss: 2.588679531193931

Epoch: 6| Step: 12
Training loss: 2.383526604380892
Validation loss: 2.57152637152305

Epoch: 6| Step: 13
Training loss: 2.8371707137025446
Validation loss: 2.5536691382590755

Epoch: 252| Step: 0
Training loss: 3.111849466384971
Validation loss: 2.5415301492205824

Epoch: 6| Step: 1
Training loss: 2.6148430643345755
Validation loss: 2.554463182791529

Epoch: 6| Step: 2
Training loss: 2.641605623986018
Validation loss: 2.5417558518902013

Epoch: 6| Step: 3
Training loss: 2.3261501461779024
Validation loss: 2.5580321368700307

Epoch: 6| Step: 4
Training loss: 2.566878509036095
Validation loss: 2.572202383985007

Epoch: 6| Step: 5
Training loss: 2.6163480864398996
Validation loss: 2.5973857784782126

Epoch: 6| Step: 6
Training loss: 2.773132565350258
Validation loss: 2.586362856243127

Epoch: 6| Step: 7
Training loss: 3.0165890748669177
Validation loss: 2.598418524449145

Epoch: 6| Step: 8
Training loss: 3.115329886858706
Validation loss: 2.6046002344968286

Epoch: 6| Step: 9
Training loss: 2.9984307953489724
Validation loss: 2.6040986680207876

Epoch: 6| Step: 10
Training loss: 2.8188914261417533
Validation loss: 2.5758686532351915

Epoch: 6| Step: 11
Training loss: 2.4787263773120993
Validation loss: 2.5805817454311546

Epoch: 6| Step: 12
Training loss: 2.362809668535348
Validation loss: 2.5702012082207326

Epoch: 6| Step: 13
Training loss: 2.406415264845177
Validation loss: 2.5396691321301326

Epoch: 253| Step: 0
Training loss: 2.861438277796528
Validation loss: 2.5153971564864994

Epoch: 6| Step: 1
Training loss: 2.5243518224012473
Validation loss: 2.534345491531697

Epoch: 6| Step: 2
Training loss: 2.96794149532391
Validation loss: 2.52957433091851

Epoch: 6| Step: 3
Training loss: 3.0982543829643197
Validation loss: 2.529975811456293

Epoch: 6| Step: 4
Training loss: 2.4523364701030843
Validation loss: 2.569554987507161

Epoch: 6| Step: 5
Training loss: 2.8078897625838595
Validation loss: 2.570385622655743

Epoch: 6| Step: 6
Training loss: 2.648583332199034
Validation loss: 2.5910926437834405

Epoch: 6| Step: 7
Training loss: 2.4759097036187794
Validation loss: 2.59799720536758

Epoch: 6| Step: 8
Training loss: 2.697417921314794
Validation loss: 2.5987114094927515

Epoch: 6| Step: 9
Training loss: 2.651420780996096
Validation loss: 2.602527166964785

Epoch: 6| Step: 10
Training loss: 2.281935079468559
Validation loss: 2.5987686606538034

Epoch: 6| Step: 11
Training loss: 3.0145025981082627
Validation loss: 2.5837629882527957

Epoch: 6| Step: 12
Training loss: 2.8518606369723614
Validation loss: 2.5773342397761954

Epoch: 6| Step: 13
Training loss: 2.985854496144036
Validation loss: 2.5601310825099395

Epoch: 254| Step: 0
Training loss: 2.99880130979935
Validation loss: 2.5522218262741716

Epoch: 6| Step: 1
Training loss: 2.8119305352032344
Validation loss: 2.54728965219885

Epoch: 6| Step: 2
Training loss: 2.8696719015969303
Validation loss: 2.5445956986301925

Epoch: 6| Step: 3
Training loss: 2.2749863425043992
Validation loss: 2.5561805454709803

Epoch: 6| Step: 4
Training loss: 3.2692092135309934
Validation loss: 2.5584343402234064

Epoch: 6| Step: 5
Training loss: 2.822148451963187
Validation loss: 2.5630368426471937

Epoch: 6| Step: 6
Training loss: 2.6617970608767747
Validation loss: 2.5627664271966526

Epoch: 6| Step: 7
Training loss: 2.7381356672694372
Validation loss: 2.579538740668873

Epoch: 6| Step: 8
Training loss: 2.6541226114382606
Validation loss: 2.5963472675277037

Epoch: 6| Step: 9
Training loss: 2.6979326421983925
Validation loss: 2.618028232724964

Epoch: 6| Step: 10
Training loss: 2.394977073798619
Validation loss: 2.625241527784433

Epoch: 6| Step: 11
Training loss: 2.505937582506682
Validation loss: 2.5800656012687693

Epoch: 6| Step: 12
Training loss: 2.7221406861721382
Validation loss: 2.5903852797986664

Epoch: 6| Step: 13
Training loss: 2.2019386073119964
Validation loss: 2.5886828784988567

Epoch: 255| Step: 0
Training loss: 2.055003210840246
Validation loss: 2.5876102319601304

Epoch: 6| Step: 1
Training loss: 3.1089446570328594
Validation loss: 2.557656681990773

Epoch: 6| Step: 2
Training loss: 2.8395038805392847
Validation loss: 2.5739863424274976

Epoch: 6| Step: 3
Training loss: 3.035285073078559
Validation loss: 2.575851048147248

Epoch: 6| Step: 4
Training loss: 2.0450461567564093
Validation loss: 2.5655144339584406

Epoch: 6| Step: 5
Training loss: 2.7305998982161745
Validation loss: 2.59741086514031

Epoch: 6| Step: 6
Training loss: 2.439905398051414
Validation loss: 2.582962198686497

Epoch: 6| Step: 7
Training loss: 2.9906797270515884
Validation loss: 2.5680550870260848

Epoch: 6| Step: 8
Training loss: 2.4701580426392225
Validation loss: 2.5813152642364288

Epoch: 6| Step: 9
Training loss: 2.6844516587774474
Validation loss: 2.5735574264600936

Epoch: 6| Step: 10
Training loss: 2.729659892544726
Validation loss: 2.5733640262844015

Epoch: 6| Step: 11
Training loss: 2.494201898382286
Validation loss: 2.588220450893983

Epoch: 6| Step: 12
Training loss: 2.8103897655227956
Validation loss: 2.5803349196290646

Epoch: 6| Step: 13
Training loss: 3.3086070090864785
Validation loss: 2.5822151779704843

Epoch: 256| Step: 0
Training loss: 3.179241177213617
Validation loss: 2.5707712460704406

Epoch: 6| Step: 1
Training loss: 3.0686075461084448
Validation loss: 2.5452453635851797

Epoch: 6| Step: 2
Training loss: 3.227129057496051
Validation loss: 2.5395828948115238

Epoch: 6| Step: 3
Training loss: 2.083636554268331
Validation loss: 2.5354537593371522

Epoch: 6| Step: 4
Training loss: 2.3894432986888234
Validation loss: 2.5398748176559516

Epoch: 6| Step: 5
Training loss: 2.4549861578152936
Validation loss: 2.5494802540061983

Epoch: 6| Step: 6
Training loss: 2.475079016917264
Validation loss: 2.5516268129523056

Epoch: 6| Step: 7
Training loss: 2.6121772749301724
Validation loss: 2.5718082469803476

Epoch: 6| Step: 8
Training loss: 2.741491332626765
Validation loss: 2.5799503620040776

Epoch: 6| Step: 9
Training loss: 2.085393141678299
Validation loss: 2.5881632655410733

Epoch: 6| Step: 10
Training loss: 3.048848144152725
Validation loss: 2.5862929062737834

Epoch: 6| Step: 11
Training loss: 2.471370609873237
Validation loss: 2.6146185780680944

Epoch: 6| Step: 12
Training loss: 2.7596197933426616
Validation loss: 2.635278424728476

Epoch: 6| Step: 13
Training loss: 3.17441941607444
Validation loss: 2.620953612750947

Epoch: 257| Step: 0
Training loss: 2.9369324480807935
Validation loss: 2.6136201072020966

Epoch: 6| Step: 1
Training loss: 2.876848041508391
Validation loss: 2.5725343418586557

Epoch: 6| Step: 2
Training loss: 2.0132988807223025
Validation loss: 2.594640630050544

Epoch: 6| Step: 3
Training loss: 2.4916499882610847
Validation loss: 2.571654424435321

Epoch: 6| Step: 4
Training loss: 2.2909011487011215
Validation loss: 2.543014816039073

Epoch: 6| Step: 5
Training loss: 3.169613337235406
Validation loss: 2.5584879565478955

Epoch: 6| Step: 6
Training loss: 2.483985246519298
Validation loss: 2.534956904843102

Epoch: 6| Step: 7
Training loss: 2.446628204410649
Validation loss: 2.5307926639379925

Epoch: 6| Step: 8
Training loss: 2.44409519889213
Validation loss: 2.551473715932318

Epoch: 6| Step: 9
Training loss: 2.888196925489624
Validation loss: 2.53886580974586

Epoch: 6| Step: 10
Training loss: 2.943227824490566
Validation loss: 2.5498601431941395

Epoch: 6| Step: 11
Training loss: 2.754925737989752
Validation loss: 2.577803912013801

Epoch: 6| Step: 12
Training loss: 3.138747379935389
Validation loss: 2.6111532794226964

Epoch: 6| Step: 13
Training loss: 3.074701874710322
Validation loss: 2.642585431998566

Epoch: 258| Step: 0
Training loss: 2.788084569286004
Validation loss: 2.593598301179204

Epoch: 6| Step: 1
Training loss: 2.8103277506711963
Validation loss: 2.5958378534615587

Epoch: 6| Step: 2
Training loss: 2.5889550434804938
Validation loss: 2.516715225531419

Epoch: 6| Step: 3
Training loss: 2.5860909131230287
Validation loss: 2.5081649122220417

Epoch: 6| Step: 4
Training loss: 3.140135010410533
Validation loss: 2.48977214708048

Epoch: 6| Step: 5
Training loss: 2.396267284953818
Validation loss: 2.5053935505777303

Epoch: 6| Step: 6
Training loss: 2.5966953881095005
Validation loss: 2.4800158630397

Epoch: 6| Step: 7
Training loss: 3.1351945530148373
Validation loss: 2.4947503880929416

Epoch: 6| Step: 8
Training loss: 2.328187672840362
Validation loss: 2.5008633045907422

Epoch: 6| Step: 9
Training loss: 3.0065509478960974
Validation loss: 2.502527633722093

Epoch: 6| Step: 10
Training loss: 2.6806370245676514
Validation loss: 2.5129428119248653

Epoch: 6| Step: 11
Training loss: 3.0668503360755506
Validation loss: 2.566985214047195

Epoch: 6| Step: 12
Training loss: 1.9694080766704583
Validation loss: 2.6188360055763287

Epoch: 6| Step: 13
Training loss: 2.778498456503175
Validation loss: 2.6593817290667565

Epoch: 259| Step: 0
Training loss: 3.094520087680654
Validation loss: 2.744595280448641

Epoch: 6| Step: 1
Training loss: 2.6904296875
Validation loss: 2.753286757035624

Epoch: 6| Step: 2
Training loss: 3.4478589808929283
Validation loss: 2.7475169747013437

Epoch: 6| Step: 3
Training loss: 2.8632332874564095
Validation loss: 2.6538023208710215

Epoch: 6| Step: 4
Training loss: 2.6231914829775516
Validation loss: 2.5306879521252594

Epoch: 6| Step: 5
Training loss: 2.8114148907710717
Validation loss: 2.5035896330817566

Epoch: 6| Step: 6
Training loss: 2.787767382058795
Validation loss: 2.499175968545189

Epoch: 6| Step: 7
Training loss: 2.8377884638356177
Validation loss: 2.50177513494183

Epoch: 6| Step: 8
Training loss: 2.738340456073558
Validation loss: 2.4959965552676198

Epoch: 6| Step: 9
Training loss: 2.374591089483543
Validation loss: 2.489495295971154

Epoch: 6| Step: 10
Training loss: 2.2213511733422155
Validation loss: 2.4984129113388738

Epoch: 6| Step: 11
Training loss: 2.545367209992227
Validation loss: 2.4909519822434416

Epoch: 6| Step: 12
Training loss: 2.9896045821406134
Validation loss: 2.491215180368872

Epoch: 6| Step: 13
Training loss: 2.869562231032133
Validation loss: 2.4939723896380745

Epoch: 260| Step: 0
Training loss: 2.898624218789902
Validation loss: 2.502997739164735

Epoch: 6| Step: 1
Training loss: 3.0193161585543864
Validation loss: 2.5310208161033683

Epoch: 6| Step: 2
Training loss: 2.193378397450626
Validation loss: 2.5767896826743044

Epoch: 6| Step: 3
Training loss: 2.1337529718415227
Validation loss: 2.595119629159972

Epoch: 6| Step: 4
Training loss: 2.751034628702502
Validation loss: 2.625455676138624

Epoch: 6| Step: 5
Training loss: 2.631961311369044
Validation loss: 2.6900450266738325

Epoch: 6| Step: 6
Training loss: 3.5962535596398326
Validation loss: 2.7477779257838835

Epoch: 6| Step: 7
Training loss: 2.4075935873219687
Validation loss: 2.750055887730189

Epoch: 6| Step: 8
Training loss: 2.6491368813493743
Validation loss: 2.732776769413637

Epoch: 6| Step: 9
Training loss: 3.2419777675951225
Validation loss: 2.6818456383873412

Epoch: 6| Step: 10
Training loss: 2.044386187819887
Validation loss: 2.637882336212382

Epoch: 6| Step: 11
Training loss: 2.5835349916894277
Validation loss: 2.5788936847510224

Epoch: 6| Step: 12
Training loss: 2.684751569027615
Validation loss: 2.5244614349132934

Epoch: 6| Step: 13
Training loss: 3.4317328886287877
Validation loss: 2.5217972335254295

Epoch: 261| Step: 0
Training loss: 2.356921404389575
Validation loss: 2.4980818537334013

Epoch: 6| Step: 1
Training loss: 2.979100864635154
Validation loss: 2.4956475383692385

Epoch: 6| Step: 2
Training loss: 2.777172743284962
Validation loss: 2.4895383333318373

Epoch: 6| Step: 3
Training loss: 2.591074931390319
Validation loss: 2.490945395475862

Epoch: 6| Step: 4
Training loss: 2.455726361938903
Validation loss: 2.4908849672455475

Epoch: 6| Step: 5
Training loss: 2.4320913119302596
Validation loss: 2.4962225966169194

Epoch: 6| Step: 6
Training loss: 2.9468980159245017
Validation loss: 2.5029491738936747

Epoch: 6| Step: 7
Training loss: 2.725577539959296
Validation loss: 2.5298895836936155

Epoch: 6| Step: 8
Training loss: 2.824139563583423
Validation loss: 2.559930671319055

Epoch: 6| Step: 9
Training loss: 3.2142679062607358
Validation loss: 2.573887382376005

Epoch: 6| Step: 10
Training loss: 2.425391910778116
Validation loss: 2.6413497614639763

Epoch: 6| Step: 11
Training loss: 2.6705934897897734
Validation loss: 2.652770247517893

Epoch: 6| Step: 12
Training loss: 2.262827441721056
Validation loss: 2.656577777846386

Epoch: 6| Step: 13
Training loss: 3.612446060569949
Validation loss: 2.6526188912256443

Epoch: 262| Step: 0
Training loss: 2.578105024780571
Validation loss: 2.6585035860806134

Epoch: 6| Step: 1
Training loss: 2.992891154208168
Validation loss: 2.6704202119349723

Epoch: 6| Step: 2
Training loss: 2.5425251516712875
Validation loss: 2.6714853711357267

Epoch: 6| Step: 3
Training loss: 2.9329621997768442
Validation loss: 2.647089841911447

Epoch: 6| Step: 4
Training loss: 2.641412561110658
Validation loss: 2.6068248060715336

Epoch: 6| Step: 5
Training loss: 2.9772065834994588
Validation loss: 2.5718281594629913

Epoch: 6| Step: 6
Training loss: 2.6868799958201475
Validation loss: 2.5420623853185003

Epoch: 6| Step: 7
Training loss: 2.7711660620366634
Validation loss: 2.5369738165136475

Epoch: 6| Step: 8
Training loss: 2.984145230540566
Validation loss: 2.5408428281851636

Epoch: 6| Step: 9
Training loss: 3.142707248308658
Validation loss: 2.5403753160900755

Epoch: 6| Step: 10
Training loss: 2.6472500189751376
Validation loss: 2.5353013500880324

Epoch: 6| Step: 11
Training loss: 1.9642782136848222
Validation loss: 2.545408526157621

Epoch: 6| Step: 12
Training loss: 2.262898139276051
Validation loss: 2.569583690129164

Epoch: 6| Step: 13
Training loss: 2.1809721411771448
Validation loss: 2.6082538566156086

Epoch: 263| Step: 0
Training loss: 2.5705206418621223
Validation loss: 2.587444093938563

Epoch: 6| Step: 1
Training loss: 2.9740097834228
Validation loss: 2.5899015931295795

Epoch: 6| Step: 2
Training loss: 2.544816665641133
Validation loss: 2.575648057936747

Epoch: 6| Step: 3
Training loss: 2.9901945085316
Validation loss: 2.562073550791926

Epoch: 6| Step: 4
Training loss: 2.909783461074765
Validation loss: 2.5428650356022686

Epoch: 6| Step: 5
Training loss: 2.3764624861138652
Validation loss: 2.5416455509217113

Epoch: 6| Step: 6
Training loss: 2.589768352533001
Validation loss: 2.5225520412790443

Epoch: 6| Step: 7
Training loss: 2.1997837133727756
Validation loss: 2.5451359692980757

Epoch: 6| Step: 8
Training loss: 2.9181455586702514
Validation loss: 2.5422483478265225

Epoch: 6| Step: 9
Training loss: 2.624309812364381
Validation loss: 2.5688036667199023

Epoch: 6| Step: 10
Training loss: 2.657357198300204
Validation loss: 2.594357442760334

Epoch: 6| Step: 11
Training loss: 2.463492577825181
Validation loss: 2.6066249409803612

Epoch: 6| Step: 12
Training loss: 2.564078891290301
Validation loss: 2.6223699008726524

Epoch: 6| Step: 13
Training loss: 3.3315183148568406
Validation loss: 2.6611793657144385

Epoch: 264| Step: 0
Training loss: 2.5380250660024495
Validation loss: 2.641573201798856

Epoch: 6| Step: 1
Training loss: 2.903776202960111
Validation loss: 2.6195906372351594

Epoch: 6| Step: 2
Training loss: 2.346436956697143
Validation loss: 2.6068759628325866

Epoch: 6| Step: 3
Training loss: 3.097811258485688
Validation loss: 2.599291540620936

Epoch: 6| Step: 4
Training loss: 2.6945958165998936
Validation loss: 2.5857067743180586

Epoch: 6| Step: 5
Training loss: 2.5724336631533307
Validation loss: 2.5628197333199827

Epoch: 6| Step: 6
Training loss: 2.305011067063911
Validation loss: 2.5636688465951143

Epoch: 6| Step: 7
Training loss: 2.3867372302949126
Validation loss: 2.5535534838024962

Epoch: 6| Step: 8
Training loss: 2.2865945577049036
Validation loss: 2.5265418388529532

Epoch: 6| Step: 9
Training loss: 3.1735379975566755
Validation loss: 2.5612618050788427

Epoch: 6| Step: 10
Training loss: 2.5759738154768694
Validation loss: 2.5659387876716018

Epoch: 6| Step: 11
Training loss: 2.6956606432766974
Validation loss: 2.549636061883149

Epoch: 6| Step: 12
Training loss: 2.7702410263248045
Validation loss: 2.5617788752290442

Epoch: 6| Step: 13
Training loss: 2.798326424716451
Validation loss: 2.5649450798833957

Epoch: 265| Step: 0
Training loss: 2.3839944878328847
Validation loss: 2.5802130781585277

Epoch: 6| Step: 1
Training loss: 2.738457993749898
Validation loss: 2.5931716285960746

Epoch: 6| Step: 2
Training loss: 2.7497748369457717
Validation loss: 2.592618537083845

Epoch: 6| Step: 3
Training loss: 2.218635341206886
Validation loss: 2.6059216918318664

Epoch: 6| Step: 4
Training loss: 2.464603756980939
Validation loss: 2.5813768270617543

Epoch: 6| Step: 5
Training loss: 2.5486384178682897
Validation loss: 2.578691280020671

Epoch: 6| Step: 6
Training loss: 2.8465580752325055
Validation loss: 2.5840264120706804

Epoch: 6| Step: 7
Training loss: 2.1737581500558156
Validation loss: 2.5675969290100036

Epoch: 6| Step: 8
Training loss: 2.5136971046349434
Validation loss: 2.5467746145361363

Epoch: 6| Step: 9
Training loss: 2.7999480855761214
Validation loss: 2.5604701612753233

Epoch: 6| Step: 10
Training loss: 2.970209024183124
Validation loss: 2.5918625953567167

Epoch: 6| Step: 11
Training loss: 2.269898271675919
Validation loss: 2.5986033938779807

Epoch: 6| Step: 12
Training loss: 3.1500203813165975
Validation loss: 2.605878650335999

Epoch: 6| Step: 13
Training loss: 3.4790364924460744
Validation loss: 2.5989686189474632

Epoch: 266| Step: 0
Training loss: 2.586915352786107
Validation loss: 2.6208661427459172

Epoch: 6| Step: 1
Training loss: 2.5703399563978064
Validation loss: 2.569681334908601

Epoch: 6| Step: 2
Training loss: 2.646063176381951
Validation loss: 2.5471448062749356

Epoch: 6| Step: 3
Training loss: 2.408948301933173
Validation loss: 2.5305858922299027

Epoch: 6| Step: 4
Training loss: 2.3773099808514986
Validation loss: 2.5068709050667133

Epoch: 6| Step: 5
Training loss: 2.4161119372476407
Validation loss: 2.52082869724982

Epoch: 6| Step: 6
Training loss: 2.7380644403625047
Validation loss: 2.528205841835299

Epoch: 6| Step: 7
Training loss: 3.0857829767483396
Validation loss: 2.517217387018175

Epoch: 6| Step: 8
Training loss: 2.552598384862824
Validation loss: 2.5308559662500647

Epoch: 6| Step: 9
Training loss: 2.974392317568998
Validation loss: 2.557911104228832

Epoch: 6| Step: 10
Training loss: 2.5084275296627214
Validation loss: 2.5750527600399757

Epoch: 6| Step: 11
Training loss: 2.5956206412661116
Validation loss: 2.5776774694494704

Epoch: 6| Step: 12
Training loss: 3.0340516032971037
Validation loss: 2.591479162718964

Epoch: 6| Step: 13
Training loss: 2.749594918673817
Validation loss: 2.5765843197660265

Epoch: 267| Step: 0
Training loss: 2.0037149259908884
Validation loss: 2.6082043368939636

Epoch: 6| Step: 1
Training loss: 2.224891222748646
Validation loss: 2.6083605821256786

Epoch: 6| Step: 2
Training loss: 2.996087543028528
Validation loss: 2.6225908790610393

Epoch: 6| Step: 3
Training loss: 2.6229898839967096
Validation loss: 2.5878244481261525

Epoch: 6| Step: 4
Training loss: 2.7183337715128304
Validation loss: 2.569920991005744

Epoch: 6| Step: 5
Training loss: 2.963515314522464
Validation loss: 2.5527030977492733

Epoch: 6| Step: 6
Training loss: 3.4494924641891953
Validation loss: 2.5419706449956196

Epoch: 6| Step: 7
Training loss: 2.383085041406453
Validation loss: 2.5399037744315422

Epoch: 6| Step: 8
Training loss: 2.136503386584311
Validation loss: 2.5090908160503425

Epoch: 6| Step: 9
Training loss: 2.4643875401153887
Validation loss: 2.5242940031461343

Epoch: 6| Step: 10
Training loss: 2.8200786631008468
Validation loss: 2.532778474047378

Epoch: 6| Step: 11
Training loss: 2.925790865669696
Validation loss: 2.5237444512481786

Epoch: 6| Step: 12
Training loss: 2.6127009410331277
Validation loss: 2.541589701142998

Epoch: 6| Step: 13
Training loss: 2.3426384896914394
Validation loss: 2.5478311839103687

Epoch: 268| Step: 0
Training loss: 1.5929288805826707
Validation loss: 2.5715047250161267

Epoch: 6| Step: 1
Training loss: 2.4542453418635803
Validation loss: 2.56172346989402

Epoch: 6| Step: 2
Training loss: 2.7957765777178745
Validation loss: 2.613626276913035

Epoch: 6| Step: 3
Training loss: 2.893473608275968
Validation loss: 2.6242587424378883

Epoch: 6| Step: 4
Training loss: 2.1148009415328786
Validation loss: 2.635989075955028

Epoch: 6| Step: 5
Training loss: 3.1117858741563698
Validation loss: 2.6415818615353643

Epoch: 6| Step: 6
Training loss: 2.3056595126490476
Validation loss: 2.6095852152224652

Epoch: 6| Step: 7
Training loss: 3.099011195824517
Validation loss: 2.5840634373822766

Epoch: 6| Step: 8
Training loss: 2.7348940983271985
Validation loss: 2.5714735325108555

Epoch: 6| Step: 9
Training loss: 2.478256079729516
Validation loss: 2.539956193243719

Epoch: 6| Step: 10
Training loss: 3.046759030996141
Validation loss: 2.515047924735192

Epoch: 6| Step: 11
Training loss: 2.4027106276324535
Validation loss: 2.5403165137782837

Epoch: 6| Step: 12
Training loss: 2.753799934228845
Validation loss: 2.5219780077242806

Epoch: 6| Step: 13
Training loss: 2.5279473316585146
Validation loss: 2.5466955994836917

Epoch: 269| Step: 0
Training loss: 2.3483081490127584
Validation loss: 2.5323265841841134

Epoch: 6| Step: 1
Training loss: 2.253070431708529
Validation loss: 2.5601608260554856

Epoch: 6| Step: 2
Training loss: 2.7516935509012064
Validation loss: 2.5656719090212996

Epoch: 6| Step: 3
Training loss: 2.368910159531827
Validation loss: 2.5790990566114087

Epoch: 6| Step: 4
Training loss: 3.120097167140386
Validation loss: 2.590653515453496

Epoch: 6| Step: 5
Training loss: 3.0213614342009234
Validation loss: 2.5731064941185853

Epoch: 6| Step: 6
Training loss: 2.567472332263956
Validation loss: 2.580807490716713

Epoch: 6| Step: 7
Training loss: 2.4153535717544368
Validation loss: 2.5652304747816834

Epoch: 6| Step: 8
Training loss: 1.978927223043223
Validation loss: 2.575168059189516

Epoch: 6| Step: 9
Training loss: 2.794934670600951
Validation loss: 2.561524850666683

Epoch: 6| Step: 10
Training loss: 2.873334817052519
Validation loss: 2.5407588237789285

Epoch: 6| Step: 11
Training loss: 2.6014699375307924
Validation loss: 2.5410337498943565

Epoch: 6| Step: 12
Training loss: 2.9712099825451546
Validation loss: 2.5479962344303497

Epoch: 6| Step: 13
Training loss: 2.4568884099974273
Validation loss: 2.5507751584370935

Epoch: 270| Step: 0
Training loss: 2.8919232726411934
Validation loss: 2.5414684513560766

Epoch: 6| Step: 1
Training loss: 1.9256049456568918
Validation loss: 2.559947528658676

Epoch: 6| Step: 2
Training loss: 2.3342795724015897
Validation loss: 2.5886711440963963

Epoch: 6| Step: 3
Training loss: 2.885146108857922
Validation loss: 2.6067477872853657

Epoch: 6| Step: 4
Training loss: 2.779613399107605
Validation loss: 2.648605331198151

Epoch: 6| Step: 5
Training loss: 2.72495867496618
Validation loss: 2.6579589480851324

Epoch: 6| Step: 6
Training loss: 2.711910721718774
Validation loss: 2.6478172846749786

Epoch: 6| Step: 7
Training loss: 2.756979840935141
Validation loss: 2.586696598474247

Epoch: 6| Step: 8
Training loss: 2.0088571880918855
Validation loss: 2.5649680800771475

Epoch: 6| Step: 9
Training loss: 2.746488583479744
Validation loss: 2.517195585129697

Epoch: 6| Step: 10
Training loss: 3.003684324641111
Validation loss: 2.5012260588976143

Epoch: 6| Step: 11
Training loss: 2.736797371491009
Validation loss: 2.4859525707864654

Epoch: 6| Step: 12
Training loss: 2.6563792477746495
Validation loss: 2.488566115937297

Epoch: 6| Step: 13
Training loss: 2.839131723839614
Validation loss: 2.4765505562848795

Epoch: 271| Step: 0
Training loss: 2.6583385559158286
Validation loss: 2.480916075500999

Epoch: 6| Step: 1
Training loss: 2.7634983830537823
Validation loss: 2.4997821959093587

Epoch: 6| Step: 2
Training loss: 2.839332419094426
Validation loss: 2.5236371125625787

Epoch: 6| Step: 3
Training loss: 2.2757946261514728
Validation loss: 2.5468565412172417

Epoch: 6| Step: 4
Training loss: 2.357292721678301
Validation loss: 2.567507789023989

Epoch: 6| Step: 5
Training loss: 2.473760807115909
Validation loss: 2.559624690259514

Epoch: 6| Step: 6
Training loss: 2.5164587878167266
Validation loss: 2.5650267580223773

Epoch: 6| Step: 7
Training loss: 2.8584963589842425
Validation loss: 2.544102682675699

Epoch: 6| Step: 8
Training loss: 2.6598844907533845
Validation loss: 2.549079495072501

Epoch: 6| Step: 9
Training loss: 2.34656061131514
Validation loss: 2.5318514829507746

Epoch: 6| Step: 10
Training loss: 2.644900139868787
Validation loss: 2.5361390170674007

Epoch: 6| Step: 11
Training loss: 2.9582566981172485
Validation loss: 2.544237047169837

Epoch: 6| Step: 12
Training loss: 2.9006260426344146
Validation loss: 2.5393146267920024

Epoch: 6| Step: 13
Training loss: 2.333275748859282
Validation loss: 2.545018700153161

Epoch: 272| Step: 0
Training loss: 3.0395096398445602
Validation loss: 2.5609265270464943

Epoch: 6| Step: 1
Training loss: 2.731977534345578
Validation loss: 2.5407482937715686

Epoch: 6| Step: 2
Training loss: 2.183216806267519
Validation loss: 2.5341386789078286

Epoch: 6| Step: 3
Training loss: 2.0982253796130537
Validation loss: 2.554974999930091

Epoch: 6| Step: 4
Training loss: 2.4142174532149068
Validation loss: 2.542242570612073

Epoch: 6| Step: 5
Training loss: 2.4439216533970796
Validation loss: 2.5456266491260786

Epoch: 6| Step: 6
Training loss: 2.9525591595800944
Validation loss: 2.5253817434704895

Epoch: 6| Step: 7
Training loss: 2.9109462408240683
Validation loss: 2.566545457046158

Epoch: 6| Step: 8
Training loss: 2.556087192116813
Validation loss: 2.586611035551892

Epoch: 6| Step: 9
Training loss: 2.755590132356237
Validation loss: 2.6377834645769833

Epoch: 6| Step: 10
Training loss: 2.188640733014267
Validation loss: 2.6376298603498407

Epoch: 6| Step: 11
Training loss: 3.1266639856951945
Validation loss: 2.7224238345587324

Epoch: 6| Step: 12
Training loss: 2.716565010493545
Validation loss: 2.7286850680386774

Epoch: 6| Step: 13
Training loss: 2.505503795011132
Validation loss: 2.714663410076789

Epoch: 273| Step: 0
Training loss: 2.4945446574361254
Validation loss: 2.642015023704259

Epoch: 6| Step: 1
Training loss: 2.6085051040233878
Validation loss: 2.6104244346932894

Epoch: 6| Step: 2
Training loss: 2.614830846330109
Validation loss: 2.541220882248895

Epoch: 6| Step: 3
Training loss: 1.9553797410130676
Validation loss: 2.523415523265599

Epoch: 6| Step: 4
Training loss: 2.7593907495137757
Validation loss: 2.531059283271862

Epoch: 6| Step: 5
Training loss: 2.544300392835554
Validation loss: 2.526241649191665

Epoch: 6| Step: 6
Training loss: 2.952821423301815
Validation loss: 2.5145934612932273

Epoch: 6| Step: 7
Training loss: 2.4927555022909207
Validation loss: 2.4983133163700475

Epoch: 6| Step: 8
Training loss: 2.4850729675632803
Validation loss: 2.492691531179837

Epoch: 6| Step: 9
Training loss: 2.689181932615442
Validation loss: 2.500252778594557

Epoch: 6| Step: 10
Training loss: 2.682767738142161
Validation loss: 2.5063661847636016

Epoch: 6| Step: 11
Training loss: 2.357717070471627
Validation loss: 2.5024099834319102

Epoch: 6| Step: 12
Training loss: 3.191386079199185
Validation loss: 2.5096259805632806

Epoch: 6| Step: 13
Training loss: 3.1211148334120495
Validation loss: 2.5078147039952277

Epoch: 274| Step: 0
Training loss: 2.157100233434631
Validation loss: 2.536209678114483

Epoch: 6| Step: 1
Training loss: 2.4377854986985206
Validation loss: 2.513099574218244

Epoch: 6| Step: 2
Training loss: 2.394163716472964
Validation loss: 2.511488723919774

Epoch: 6| Step: 3
Training loss: 2.899867442817531
Validation loss: 2.5396673615738083

Epoch: 6| Step: 4
Training loss: 2.9329345612689752
Validation loss: 2.5436278922489914

Epoch: 6| Step: 5
Training loss: 2.5445119742863027
Validation loss: 2.5329599634675932

Epoch: 6| Step: 6
Training loss: 1.8636819020858886
Validation loss: 2.5708512896844087

Epoch: 6| Step: 7
Training loss: 2.5162330034859712
Validation loss: 2.6240545006644447

Epoch: 6| Step: 8
Training loss: 2.537611796354557
Validation loss: 2.6174846927959856

Epoch: 6| Step: 9
Training loss: 3.017533879125456
Validation loss: 2.64311430919116

Epoch: 6| Step: 10
Training loss: 2.937362992358444
Validation loss: 2.633449440031106

Epoch: 6| Step: 11
Training loss: 2.6034982255724857
Validation loss: 2.601130956157957

Epoch: 6| Step: 12
Training loss: 3.212216458999576
Validation loss: 2.5714090766377735

Epoch: 6| Step: 13
Training loss: 2.049513884803288
Validation loss: 2.5388342525856666

Epoch: 275| Step: 0
Training loss: 2.8660632015801153
Validation loss: 2.5333804937219466

Epoch: 6| Step: 1
Training loss: 3.117158588476122
Validation loss: 2.5219319518401733

Epoch: 6| Step: 2
Training loss: 3.167751394169636
Validation loss: 2.50422370933991

Epoch: 6| Step: 3
Training loss: 2.5562558274330924
Validation loss: 2.518579770504262

Epoch: 6| Step: 4
Training loss: 2.553909043164387
Validation loss: 2.513152959122599

Epoch: 6| Step: 5
Training loss: 2.5938356684129866
Validation loss: 2.5321979416287808

Epoch: 6| Step: 6
Training loss: 1.983006643856459
Validation loss: 2.5532751515399505

Epoch: 6| Step: 7
Training loss: 2.3334951231132894
Validation loss: 2.554374328165334

Epoch: 6| Step: 8
Training loss: 2.6892621672744172
Validation loss: 2.5287600867289166

Epoch: 6| Step: 9
Training loss: 1.69735552480554
Validation loss: 2.515838807587448

Epoch: 6| Step: 10
Training loss: 3.0174697214549577
Validation loss: 2.534212026935645

Epoch: 6| Step: 11
Training loss: 1.8550069455122156
Validation loss: 2.5269692604996323

Epoch: 6| Step: 12
Training loss: 3.0834969829397965
Validation loss: 2.5706943797171764

Epoch: 6| Step: 13
Training loss: 2.4656193838309375
Validation loss: 2.584845009980365

Epoch: 276| Step: 0
Training loss: 2.7966173788584148
Validation loss: 2.5762391622127625

Epoch: 6| Step: 1
Training loss: 2.7662842390490057
Validation loss: 2.577302727902191

Epoch: 6| Step: 2
Training loss: 2.6681768690845846
Validation loss: 2.5573750616749913

Epoch: 6| Step: 3
Training loss: 2.2151900194005933
Validation loss: 2.5511281154334386

Epoch: 6| Step: 4
Training loss: 2.836890026522531
Validation loss: 2.550502394074778

Epoch: 6| Step: 5
Training loss: 2.6278981150556033
Validation loss: 2.556740852712123

Epoch: 6| Step: 6
Training loss: 3.1199330259128386
Validation loss: 2.5187469352936196

Epoch: 6| Step: 7
Training loss: 1.8708693463343362
Validation loss: 2.525281762438305

Epoch: 6| Step: 8
Training loss: 2.546333114922971
Validation loss: 2.5037089031014785

Epoch: 6| Step: 9
Training loss: 2.4351220880877458
Validation loss: 2.529672846120545

Epoch: 6| Step: 10
Training loss: 2.505004451542171
Validation loss: 2.5590856521861043

Epoch: 6| Step: 11
Training loss: 2.551691754460937
Validation loss: 2.601789679452065

Epoch: 6| Step: 12
Training loss: 2.821913837828838
Validation loss: 2.607751263619509

Epoch: 6| Step: 13
Training loss: 2.47323847419986
Validation loss: 2.6131286856146185

Epoch: 277| Step: 0
Training loss: 2.2856632550537554
Validation loss: 2.6344335242087276

Epoch: 6| Step: 1
Training loss: 2.355462271964558
Validation loss: 2.6043571133449968

Epoch: 6| Step: 2
Training loss: 2.812398781544521
Validation loss: 2.6019977684740674

Epoch: 6| Step: 3
Training loss: 2.2695727451227583
Validation loss: 2.5996044343147138

Epoch: 6| Step: 4
Training loss: 2.51630037138882
Validation loss: 2.5825992405240843

Epoch: 6| Step: 5
Training loss: 2.699111163456013
Validation loss: 2.5759461205621617

Epoch: 6| Step: 6
Training loss: 2.6784357200031823
Validation loss: 2.540527410855005

Epoch: 6| Step: 7
Training loss: 2.231969111628764
Validation loss: 2.526096315916534

Epoch: 6| Step: 8
Training loss: 2.6065798653624523
Validation loss: 2.52129934368549

Epoch: 6| Step: 9
Training loss: 2.5720960000663133
Validation loss: 2.5072598637324095

Epoch: 6| Step: 10
Training loss: 2.9078650140299387
Validation loss: 2.4985216158460424

Epoch: 6| Step: 11
Training loss: 2.704754112476763
Validation loss: 2.491022722000081

Epoch: 6| Step: 12
Training loss: 2.9583809718921454
Validation loss: 2.499013911373931

Epoch: 6| Step: 13
Training loss: 2.8435955634468466
Validation loss: 2.513942150786891

Epoch: 278| Step: 0
Training loss: 2.8233869285255513
Validation loss: 2.518163319764463

Epoch: 6| Step: 1
Training loss: 2.2171042342677327
Validation loss: 2.5150861764955597

Epoch: 6| Step: 2
Training loss: 2.9011334736312513
Validation loss: 2.5380902393780618

Epoch: 6| Step: 3
Training loss: 2.5816202226093212
Validation loss: 2.5652319148881984

Epoch: 6| Step: 4
Training loss: 2.499316503551384
Validation loss: 2.5704216675674996

Epoch: 6| Step: 5
Training loss: 2.666549729723803
Validation loss: 2.5792375820781905

Epoch: 6| Step: 6
Training loss: 2.7478649347587143
Validation loss: 2.5727870845924024

Epoch: 6| Step: 7
Training loss: 2.646294010536973
Validation loss: 2.585083138314722

Epoch: 6| Step: 8
Training loss: 2.411217157704819
Validation loss: 2.5732231895821296

Epoch: 6| Step: 9
Training loss: 1.9194139058906665
Validation loss: 2.5651960988693987

Epoch: 6| Step: 10
Training loss: 2.726934981384814
Validation loss: 2.5722841815022357

Epoch: 6| Step: 11
Training loss: 3.155548017639088
Validation loss: 2.580312081249583

Epoch: 6| Step: 12
Training loss: 2.0161246929737278
Validation loss: 2.573765852743471

Epoch: 6| Step: 13
Training loss: 2.886411493078048
Validation loss: 2.57858732471473

Epoch: 279| Step: 0
Training loss: 2.1951969428549964
Validation loss: 2.569697160569792

Epoch: 6| Step: 1
Training loss: 2.085586346847392
Validation loss: 2.582908722168823

Epoch: 6| Step: 2
Training loss: 2.6585012432710338
Validation loss: 2.5747697163924244

Epoch: 6| Step: 3
Training loss: 2.458206550647889
Validation loss: 2.5363049628909264

Epoch: 6| Step: 4
Training loss: 2.4581354568068927
Validation loss: 2.540549955009055

Epoch: 6| Step: 5
Training loss: 2.6407447200925684
Validation loss: 2.547858898671871

Epoch: 6| Step: 6
Training loss: 3.263322082074115
Validation loss: 2.5445099340623143

Epoch: 6| Step: 7
Training loss: 2.7534463268429055
Validation loss: 2.5473744516500187

Epoch: 6| Step: 8
Training loss: 2.7479811106758625
Validation loss: 2.5578240291442293

Epoch: 6| Step: 9
Training loss: 2.302457085788348
Validation loss: 2.566022705071155

Epoch: 6| Step: 10
Training loss: 2.846671144659137
Validation loss: 2.5873611229830127

Epoch: 6| Step: 11
Training loss: 2.830035328459196
Validation loss: 2.61877955924847

Epoch: 6| Step: 12
Training loss: 2.422462835036647
Validation loss: 2.576219028079088

Epoch: 6| Step: 13
Training loss: 2.380433542850695
Validation loss: 2.5510710452522303

Epoch: 280| Step: 0
Training loss: 3.345914051290476
Validation loss: 2.5429822951856584

Epoch: 6| Step: 1
Training loss: 1.9685788761427516
Validation loss: 2.5745814547469763

Epoch: 6| Step: 2
Training loss: 3.1811382161644275
Validation loss: 2.5497314773400173

Epoch: 6| Step: 3
Training loss: 2.4643929578613952
Validation loss: 2.5508642117993343

Epoch: 6| Step: 4
Training loss: 3.0841934104267716
Validation loss: 2.5374168526644563

Epoch: 6| Step: 5
Training loss: 2.219946417806274
Validation loss: 2.5283710753783053

Epoch: 6| Step: 6
Training loss: 1.9715098458570786
Validation loss: 2.5458591573528024

Epoch: 6| Step: 7
Training loss: 3.0950515013124367
Validation loss: 2.543612961651654

Epoch: 6| Step: 8
Training loss: 1.8229777589279301
Validation loss: 2.560246014272057

Epoch: 6| Step: 9
Training loss: 2.4318815180941886
Validation loss: 2.5513725256910704

Epoch: 6| Step: 10
Training loss: 2.8565326175226327
Validation loss: 2.5283682069134894

Epoch: 6| Step: 11
Training loss: 2.473861231989701
Validation loss: 2.5116788158962193

Epoch: 6| Step: 12
Training loss: 2.6045423516447626
Validation loss: 2.5022119007209667

Epoch: 6| Step: 13
Training loss: 2.0541702605777687
Validation loss: 2.4850454397737547

Epoch: 281| Step: 0
Training loss: 2.472646414931566
Validation loss: 2.472686005872266

Epoch: 6| Step: 1
Training loss: 2.8966121220986203
Validation loss: 2.4746632618399786

Epoch: 6| Step: 2
Training loss: 2.520520676909247
Validation loss: 2.4893610415642335

Epoch: 6| Step: 3
Training loss: 2.197092983669089
Validation loss: 2.4817433880554676

Epoch: 6| Step: 4
Training loss: 2.5863698730417934
Validation loss: 2.512872893280307

Epoch: 6| Step: 5
Training loss: 2.291779555805852
Validation loss: 2.5610782121470113

Epoch: 6| Step: 6
Training loss: 3.0459668493339205
Validation loss: 2.629471108503882

Epoch: 6| Step: 7
Training loss: 2.5647290467041177
Validation loss: 2.747019281298256

Epoch: 6| Step: 8
Training loss: 2.929468416287564
Validation loss: 2.7652522603501395

Epoch: 6| Step: 9
Training loss: 3.0730859397343844
Validation loss: 2.8154690729397904

Epoch: 6| Step: 10
Training loss: 2.56726208588347
Validation loss: 2.760314688459909

Epoch: 6| Step: 11
Training loss: 2.770489482529908
Validation loss: 2.708903723225021

Epoch: 6| Step: 12
Training loss: 2.6161576251741945
Validation loss: 2.6786409671974343

Epoch: 6| Step: 13
Training loss: 2.415141929104732
Validation loss: 2.585866026632141

Epoch: 282| Step: 0
Training loss: 3.209387040603174
Validation loss: 2.53975536752996

Epoch: 6| Step: 1
Training loss: 2.6424720218444073
Validation loss: 2.4882438977412087

Epoch: 6| Step: 2
Training loss: 2.8182166599402008
Validation loss: 2.4674793845419707

Epoch: 6| Step: 3
Training loss: 2.488811729811344
Validation loss: 2.474510189523633

Epoch: 6| Step: 4
Training loss: 2.7747004682390575
Validation loss: 2.4664078528321047

Epoch: 6| Step: 5
Training loss: 2.373354894168657
Validation loss: 2.4566314323448615

Epoch: 6| Step: 6
Training loss: 2.839459714673276
Validation loss: 2.464183261178243

Epoch: 6| Step: 7
Training loss: 2.4902904788410423
Validation loss: 2.4666194078823294

Epoch: 6| Step: 8
Training loss: 2.5436245824089982
Validation loss: 2.465532209211855

Epoch: 6| Step: 9
Training loss: 2.516320363485519
Validation loss: 2.496050795883719

Epoch: 6| Step: 10
Training loss: 2.2890254203214804
Validation loss: 2.517504531646579

Epoch: 6| Step: 11
Training loss: 2.433431604656732
Validation loss: 2.5654506477870522

Epoch: 6| Step: 12
Training loss: 2.6973511877721412
Validation loss: 2.591445632602618

Epoch: 6| Step: 13
Training loss: 2.0301454328485002
Validation loss: 2.6215472887376112

Epoch: 283| Step: 0
Training loss: 3.057748339120718
Validation loss: 2.6231967242232184

Epoch: 6| Step: 1
Training loss: 2.8324351476532734
Validation loss: 2.590071002170532

Epoch: 6| Step: 2
Training loss: 2.943842756425782
Validation loss: 2.589657516736248

Epoch: 6| Step: 3
Training loss: 2.7634187508309065
Validation loss: 2.5330519516972387

Epoch: 6| Step: 4
Training loss: 2.3185907519992286
Validation loss: 2.5378602397812657

Epoch: 6| Step: 5
Training loss: 2.2846762650288834
Validation loss: 2.5586969450769836

Epoch: 6| Step: 6
Training loss: 2.585692333573851
Validation loss: 2.5605244037836115

Epoch: 6| Step: 7
Training loss: 2.390426926728531
Validation loss: 2.565050130278804

Epoch: 6| Step: 8
Training loss: 3.042090782661828
Validation loss: 2.5905785235405547

Epoch: 6| Step: 9
Training loss: 2.555187678004146
Validation loss: 2.58357517950904

Epoch: 6| Step: 10
Training loss: 2.463174632650933
Validation loss: 2.5424464492287853

Epoch: 6| Step: 11
Training loss: 2.439172806527356
Validation loss: 2.5502530098916707

Epoch: 6| Step: 12
Training loss: 2.019641039463125
Validation loss: 2.556326557702573

Epoch: 6| Step: 13
Training loss: 2.4950439920159178
Validation loss: 2.5590023558349726

Epoch: 284| Step: 0
Training loss: 2.0043388033704006
Validation loss: 2.5071284768443407

Epoch: 6| Step: 1
Training loss: 2.8024759313007523
Validation loss: 2.5013927989400915

Epoch: 6| Step: 2
Training loss: 2.6112959866197336
Validation loss: 2.4799618444077827

Epoch: 6| Step: 3
Training loss: 2.9592936036336988
Validation loss: 2.4778464519502603

Epoch: 6| Step: 4
Training loss: 3.333031847353276
Validation loss: 2.4898644963601813

Epoch: 6| Step: 5
Training loss: 2.474322247425837
Validation loss: 2.4960416302164683

Epoch: 6| Step: 6
Training loss: 1.95684691758354
Validation loss: 2.5058276732869413

Epoch: 6| Step: 7
Training loss: 2.467179583584513
Validation loss: 2.517153323127699

Epoch: 6| Step: 8
Training loss: 2.902616793494782
Validation loss: 2.553777516514621

Epoch: 6| Step: 9
Training loss: 2.8413102300245545
Validation loss: 2.569452806204379

Epoch: 6| Step: 10
Training loss: 2.0259088572404877
Validation loss: 2.6135229897170866

Epoch: 6| Step: 11
Training loss: 2.572229012914509
Validation loss: 2.6056304220761253

Epoch: 6| Step: 12
Training loss: 2.350742032201583
Validation loss: 2.636420625872789

Epoch: 6| Step: 13
Training loss: 2.7013547536158247
Validation loss: 2.612243068437168

Epoch: 285| Step: 0
Training loss: 2.927359100782075
Validation loss: 2.6235362697353204

Epoch: 6| Step: 1
Training loss: 2.4657021552755056
Validation loss: 2.5747895691323572

Epoch: 6| Step: 2
Training loss: 2.647021610023361
Validation loss: 2.5348978883476763

Epoch: 6| Step: 3
Training loss: 2.5665795022440103
Validation loss: 2.5291138698431768

Epoch: 6| Step: 4
Training loss: 2.1432944033317094
Validation loss: 2.520887518876425

Epoch: 6| Step: 5
Training loss: 2.024928188228034
Validation loss: 2.5231506495493528

Epoch: 6| Step: 6
Training loss: 2.8107337491893087
Validation loss: 2.515783861469347

Epoch: 6| Step: 7
Training loss: 2.5957467539775356
Validation loss: 2.522445454754274

Epoch: 6| Step: 8
Training loss: 2.6860361770159167
Validation loss: 2.5097640621563007

Epoch: 6| Step: 9
Training loss: 2.7911757896387988
Validation loss: 2.534456459175622

Epoch: 6| Step: 10
Training loss: 2.3267758960096403
Validation loss: 2.535573722508943

Epoch: 6| Step: 11
Training loss: 3.176243822256158
Validation loss: 2.534510380441758

Epoch: 6| Step: 12
Training loss: 2.19765035694253
Validation loss: 2.559192487781599

Epoch: 6| Step: 13
Training loss: 2.2896084183304253
Validation loss: 2.5924985366899276

Epoch: 286| Step: 0
Training loss: 2.1474026493837437
Validation loss: 2.65662377446363

Epoch: 6| Step: 1
Training loss: 2.5952042329128098
Validation loss: 2.643353775476176

Epoch: 6| Step: 2
Training loss: 2.8131114718864727
Validation loss: 2.642981948982781

Epoch: 6| Step: 3
Training loss: 2.44790716507603
Validation loss: 2.5471729099549387

Epoch: 6| Step: 4
Training loss: 2.2950368779363104
Validation loss: 2.514424489992047

Epoch: 6| Step: 5
Training loss: 2.669036606847386
Validation loss: 2.497613029851855

Epoch: 6| Step: 6
Training loss: 1.8477276713658666
Validation loss: 2.471867653169328

Epoch: 6| Step: 7
Training loss: 2.410143390046222
Validation loss: 2.479261506285542

Epoch: 6| Step: 8
Training loss: 3.0160843099147874
Validation loss: 2.465129465921032

Epoch: 6| Step: 9
Training loss: 3.065158546416947
Validation loss: 2.461610955125516

Epoch: 6| Step: 10
Training loss: 2.755364041654873
Validation loss: 2.458274445020486

Epoch: 6| Step: 11
Training loss: 2.8910311027022852
Validation loss: 2.4606230035279117

Epoch: 6| Step: 12
Training loss: 2.917617225155139
Validation loss: 2.4776659716881264

Epoch: 6| Step: 13
Training loss: 2.0260368942034557
Validation loss: 2.507982797903445

Epoch: 287| Step: 0
Training loss: 2.981286492914096
Validation loss: 2.548369395455602

Epoch: 6| Step: 1
Training loss: 2.5962000845462208
Validation loss: 2.598601915045768

Epoch: 6| Step: 2
Training loss: 2.1329822961758405
Validation loss: 2.6458469704129675

Epoch: 6| Step: 3
Training loss: 1.3865959005608037
Validation loss: 2.6708594849058236

Epoch: 6| Step: 4
Training loss: 2.8465361308678196
Validation loss: 2.708177187814483

Epoch: 6| Step: 5
Training loss: 2.6426058229967033
Validation loss: 2.6805552243632733

Epoch: 6| Step: 6
Training loss: 2.3343727203725693
Validation loss: 2.6707360071291175

Epoch: 6| Step: 7
Training loss: 2.1142615338087922
Validation loss: 2.60192203152977

Epoch: 6| Step: 8
Training loss: 2.556972123723253
Validation loss: 2.584863111197742

Epoch: 6| Step: 9
Training loss: 2.603610037760887
Validation loss: 2.541067495248036

Epoch: 6| Step: 10
Training loss: 2.710488493835313
Validation loss: 2.5120003304365355

Epoch: 6| Step: 11
Training loss: 2.5618725450424416
Validation loss: 2.4802588734079665

Epoch: 6| Step: 12
Training loss: 2.9528718062755237
Validation loss: 2.474942327295423

Epoch: 6| Step: 13
Training loss: 3.6049899592372197
Validation loss: 2.466829955428607

Epoch: 288| Step: 0
Training loss: 2.875665173083109
Validation loss: 2.469410406224647

Epoch: 6| Step: 1
Training loss: 2.7066845692510744
Validation loss: 2.467344136363157

Epoch: 6| Step: 2
Training loss: 2.146207560773398
Validation loss: 2.456930393899857

Epoch: 6| Step: 3
Training loss: 2.439643113348305
Validation loss: 2.4701067424767884

Epoch: 6| Step: 4
Training loss: 2.518575135022657
Validation loss: 2.4722360697411423

Epoch: 6| Step: 5
Training loss: 2.4109880443325618
Validation loss: 2.4797254380605684

Epoch: 6| Step: 6
Training loss: 2.7340063228017812
Validation loss: 2.5103025492585473

Epoch: 6| Step: 7
Training loss: 2.3662928536751844
Validation loss: 2.5411202976351372

Epoch: 6| Step: 8
Training loss: 2.853451790118465
Validation loss: 2.545734485594805

Epoch: 6| Step: 9
Training loss: 2.2101724871473527
Validation loss: 2.6134178316857266

Epoch: 6| Step: 10
Training loss: 2.869318448263271
Validation loss: 2.6575045842172935

Epoch: 6| Step: 11
Training loss: 2.535170544788281
Validation loss: 2.7393033281364843

Epoch: 6| Step: 12
Training loss: 2.6529577159826254
Validation loss: 2.7876501071560007

Epoch: 6| Step: 13
Training loss: 3.352763069862933
Validation loss: 2.847735958203955

Epoch: 289| Step: 0
Training loss: 2.559352523462813
Validation loss: 2.765199554721377

Epoch: 6| Step: 1
Training loss: 3.026481417001607
Validation loss: 2.6432634227858007

Epoch: 6| Step: 2
Training loss: 2.0569815357661008
Validation loss: 2.5752258904984417

Epoch: 6| Step: 3
Training loss: 2.197804295950192
Validation loss: 2.534774626409623

Epoch: 6| Step: 4
Training loss: 2.5318138530638783
Validation loss: 2.519661306929331

Epoch: 6| Step: 5
Training loss: 2.6660327952743783
Validation loss: 2.5257889511577507

Epoch: 6| Step: 6
Training loss: 2.7843312543692815
Validation loss: 2.5082961926953713

Epoch: 6| Step: 7
Training loss: 1.854221800366621
Validation loss: 2.491769878134586

Epoch: 6| Step: 8
Training loss: 2.6160305825350254
Validation loss: 2.49627983625285

Epoch: 6| Step: 9
Training loss: 2.584021558659853
Validation loss: 2.4814286925790183

Epoch: 6| Step: 10
Training loss: 2.407198236078267
Validation loss: 2.4875165935376584

Epoch: 6| Step: 11
Training loss: 2.8139161677124593
Validation loss: 2.4832142921183276

Epoch: 6| Step: 12
Training loss: 2.8961234919315126
Validation loss: 2.503002012240749

Epoch: 6| Step: 13
Training loss: 3.147068379132327
Validation loss: 2.523257354622188

Epoch: 290| Step: 0
Training loss: 2.4295825015621455
Validation loss: 2.5435707545740716

Epoch: 6| Step: 1
Training loss: 1.7721383465909224
Validation loss: 2.563680643438156

Epoch: 6| Step: 2
Training loss: 2.2531991044343225
Validation loss: 2.5855338786604256

Epoch: 6| Step: 3
Training loss: 2.79911739880275
Validation loss: 2.582822219356588

Epoch: 6| Step: 4
Training loss: 3.1116220607192773
Validation loss: 2.575577636803716

Epoch: 6| Step: 5
Training loss: 2.8190145702492977
Validation loss: 2.536834486425163

Epoch: 6| Step: 6
Training loss: 2.693279350923215
Validation loss: 2.511812785799711

Epoch: 6| Step: 7
Training loss: 1.9279894442645258
Validation loss: 2.478736274099616

Epoch: 6| Step: 8
Training loss: 2.183378205554129
Validation loss: 2.4876735441826696

Epoch: 6| Step: 9
Training loss: 2.852934374086912
Validation loss: 2.4774691008364496

Epoch: 6| Step: 10
Training loss: 2.49949049526116
Validation loss: 2.4861677082428613

Epoch: 6| Step: 11
Training loss: 2.235858451464254
Validation loss: 2.497563374476611

Epoch: 6| Step: 12
Training loss: 3.191337519340992
Validation loss: 2.501154311117073

Epoch: 6| Step: 13
Training loss: 2.7226198213129664
Validation loss: 2.5267523444661517

Epoch: 291| Step: 0
Training loss: 2.370734449937994
Validation loss: 2.5154830473721668

Epoch: 6| Step: 1
Training loss: 2.5847452878620363
Validation loss: 2.517020580629051

Epoch: 6| Step: 2
Training loss: 1.8859014221634285
Validation loss: 2.5186410946595856

Epoch: 6| Step: 3
Training loss: 2.455901306095333
Validation loss: 2.5298244523943403

Epoch: 6| Step: 4
Training loss: 2.6788857375522457
Validation loss: 2.5324569208921712

Epoch: 6| Step: 5
Training loss: 2.3852759462741973
Validation loss: 2.5062408403727328

Epoch: 6| Step: 6
Training loss: 2.4380167877896053
Validation loss: 2.510714292765157

Epoch: 6| Step: 7
Training loss: 2.7501962765094006
Validation loss: 2.493101213972313

Epoch: 6| Step: 8
Training loss: 2.3769842191243735
Validation loss: 2.5077786056624753

Epoch: 6| Step: 9
Training loss: 2.3706062230463525
Validation loss: 2.5156613638171956

Epoch: 6| Step: 10
Training loss: 3.493930594975012
Validation loss: 2.542591609188734

Epoch: 6| Step: 11
Training loss: 2.2768654689123355
Validation loss: 2.5300086048781933

Epoch: 6| Step: 12
Training loss: 2.7409846175387385
Validation loss: 2.519717338032197

Epoch: 6| Step: 13
Training loss: 2.07738223461643
Validation loss: 2.5256817176316675

Epoch: 292| Step: 0
Training loss: 2.3368518277468406
Validation loss: 2.5281083474076684

Epoch: 6| Step: 1
Training loss: 2.2620697539727592
Validation loss: 2.5044956168600776

Epoch: 6| Step: 2
Training loss: 2.3745075518386995
Validation loss: 2.521400808986512

Epoch: 6| Step: 3
Training loss: 2.2747916157621124
Validation loss: 2.528155890924198

Epoch: 6| Step: 4
Training loss: 2.5889543988457926
Validation loss: 2.558141161064957

Epoch: 6| Step: 5
Training loss: 1.8453065153407664
Validation loss: 2.549340480148817

Epoch: 6| Step: 6
Training loss: 2.2519254922618943
Validation loss: 2.5385091522256764

Epoch: 6| Step: 7
Training loss: 2.827093030949946
Validation loss: 2.542555304851305

Epoch: 6| Step: 8
Training loss: 2.583125218858209
Validation loss: 2.5461057468445527

Epoch: 6| Step: 9
Training loss: 2.222716211673343
Validation loss: 2.508338988217397

Epoch: 6| Step: 10
Training loss: 2.5918838957814883
Validation loss: 2.5135294397918067

Epoch: 6| Step: 11
Training loss: 3.0395188957288415
Validation loss: 2.5070707926208953

Epoch: 6| Step: 12
Training loss: 2.7901108425094456
Validation loss: 2.4882076700272253

Epoch: 6| Step: 13
Training loss: 3.2757541225046114
Validation loss: 2.4824878343099557

Epoch: 293| Step: 0
Training loss: 2.5327035945232876
Validation loss: 2.480889297270723

Epoch: 6| Step: 1
Training loss: 3.3694248068554273
Validation loss: 2.4657610838396633

Epoch: 6| Step: 2
Training loss: 2.610992204605557
Validation loss: 2.4822064521319493

Epoch: 6| Step: 3
Training loss: 2.484829075421007
Validation loss: 2.4713663038895426

Epoch: 6| Step: 4
Training loss: 2.8703680457740406
Validation loss: 2.4956645833818634

Epoch: 6| Step: 5
Training loss: 2.297646736714197
Validation loss: 2.508229131077155

Epoch: 6| Step: 6
Training loss: 2.2309608250713255
Validation loss: 2.52053869185397

Epoch: 6| Step: 7
Training loss: 2.3479591720059747
Validation loss: 2.5275979159678363

Epoch: 6| Step: 8
Training loss: 1.8412253988970109
Validation loss: 2.56080581841133

Epoch: 6| Step: 9
Training loss: 2.4482783165401107
Validation loss: 2.6009854883319017

Epoch: 6| Step: 10
Training loss: 2.620484237183865
Validation loss: 2.63133835927097

Epoch: 6| Step: 11
Training loss: 2.363466063279816
Validation loss: 2.634351759764657

Epoch: 6| Step: 12
Training loss: 2.656940864028375
Validation loss: 2.6093952300243157

Epoch: 6| Step: 13
Training loss: 2.5468853909333182
Validation loss: 2.5886353820156613

Epoch: 294| Step: 0
Training loss: 2.4815608946849443
Validation loss: 2.5690813773841645

Epoch: 6| Step: 1
Training loss: 2.6101040307136154
Validation loss: 2.5171773354381184

Epoch: 6| Step: 2
Training loss: 2.3038752789516095
Validation loss: 2.4903879817112697

Epoch: 6| Step: 3
Training loss: 2.893862339418023
Validation loss: 2.4678209996424534

Epoch: 6| Step: 4
Training loss: 2.7420789909086887
Validation loss: 2.4708833958702607

Epoch: 6| Step: 5
Training loss: 2.8161745439047383
Validation loss: 2.4760655956974076

Epoch: 6| Step: 6
Training loss: 2.85937866877753
Validation loss: 2.4853270425877754

Epoch: 6| Step: 7
Training loss: 2.5132835343113067
Validation loss: 2.508136365324498

Epoch: 6| Step: 8
Training loss: 1.858245827306699
Validation loss: 2.4988478846357696

Epoch: 6| Step: 9
Training loss: 1.8589697644676952
Validation loss: 2.517226704729424

Epoch: 6| Step: 10
Training loss: 2.7135185684909935
Validation loss: 2.505216792459059

Epoch: 6| Step: 11
Training loss: 2.205464629096121
Validation loss: 2.506998840909324

Epoch: 6| Step: 12
Training loss: 2.449222059719155
Validation loss: 2.487787441721829

Epoch: 6| Step: 13
Training loss: 2.635474243339268
Validation loss: 2.47519926820846

Epoch: 295| Step: 0
Training loss: 2.1084163041305284
Validation loss: 2.4916767635079835

Epoch: 6| Step: 1
Training loss: 2.871685937546334
Validation loss: 2.491350059287346

Epoch: 6| Step: 2
Training loss: 2.7658604236121627
Validation loss: 2.5008801326128913

Epoch: 6| Step: 3
Training loss: 2.0503233770853218
Validation loss: 2.5182459420994947

Epoch: 6| Step: 4
Training loss: 2.4860703543714857
Validation loss: 2.5264590332239827

Epoch: 6| Step: 5
Training loss: 2.2974973082085617
Validation loss: 2.5208049282045524

Epoch: 6| Step: 6
Training loss: 2.616092281918711
Validation loss: 2.5354647410561206

Epoch: 6| Step: 7
Training loss: 3.3913818077291
Validation loss: 2.534337661039413

Epoch: 6| Step: 8
Training loss: 1.2918636981855462
Validation loss: 2.5266629100317837

Epoch: 6| Step: 9
Training loss: 1.6184795580855496
Validation loss: 2.5315202614056362

Epoch: 6| Step: 10
Training loss: 3.0547845927464436
Validation loss: 2.525353231813774

Epoch: 6| Step: 11
Training loss: 2.7028379784056993
Validation loss: 2.4865537771307387

Epoch: 6| Step: 12
Training loss: 1.8614610142217998
Validation loss: 2.499972616066212

Epoch: 6| Step: 13
Training loss: 3.223116089351957
Validation loss: 2.5036868453495673

Epoch: 296| Step: 0
Training loss: 2.6803620937901105
Validation loss: 2.5309391446126077

Epoch: 6| Step: 1
Training loss: 2.1759418859715645
Validation loss: 2.522510523519494

Epoch: 6| Step: 2
Training loss: 2.5035072520558415
Validation loss: 2.5243405963326997

Epoch: 6| Step: 3
Training loss: 1.834213876227892
Validation loss: 2.5329462487989924

Epoch: 6| Step: 4
Training loss: 2.502925305729192
Validation loss: 2.5389034552729353

Epoch: 6| Step: 5
Training loss: 3.1426514118532682
Validation loss: 2.578135683616162

Epoch: 6| Step: 6
Training loss: 2.5122512086889484
Validation loss: 2.5411626059439705

Epoch: 6| Step: 7
Training loss: 2.1094757056038733
Validation loss: 2.5205561981233746

Epoch: 6| Step: 8
Training loss: 1.7683647976424133
Validation loss: 2.4845986854080975

Epoch: 6| Step: 9
Training loss: 2.698845976995343
Validation loss: 2.4436005879143923

Epoch: 6| Step: 10
Training loss: 2.6089729410495823
Validation loss: 2.4451975486974162

Epoch: 6| Step: 11
Training loss: 2.848218153367105
Validation loss: 2.4501297043936585

Epoch: 6| Step: 12
Training loss: 2.60853672839253
Validation loss: 2.458998927020124

Epoch: 6| Step: 13
Training loss: 2.821922371129805
Validation loss: 2.4538078123322125

Epoch: 297| Step: 0
Training loss: 2.2290352993579288
Validation loss: 2.47491570920944

Epoch: 6| Step: 1
Training loss: 2.354643770557314
Validation loss: 2.479971804491635

Epoch: 6| Step: 2
Training loss: 2.5871671305883353
Validation loss: 2.4912809331073844

Epoch: 6| Step: 3
Training loss: 2.5163081408481127
Validation loss: 2.5165531100094727

Epoch: 6| Step: 4
Training loss: 2.436391333781017
Validation loss: 2.5265433659513494

Epoch: 6| Step: 5
Training loss: 2.408873378917613
Validation loss: 2.54426794685602

Epoch: 6| Step: 6
Training loss: 1.8311218737673787
Validation loss: 2.5492186526925904

Epoch: 6| Step: 7
Training loss: 2.961567431755021
Validation loss: 2.561825608241416

Epoch: 6| Step: 8
Training loss: 2.926106372487643
Validation loss: 2.566251473298401

Epoch: 6| Step: 9
Training loss: 2.16411097503244
Validation loss: 2.564162931546085

Epoch: 6| Step: 10
Training loss: 2.2035045973121945
Validation loss: 2.547228191463553

Epoch: 6| Step: 11
Training loss: 2.5322446399518634
Validation loss: 2.5321411423645346

Epoch: 6| Step: 12
Training loss: 2.7475922187413984
Validation loss: 2.5418351647255553

Epoch: 6| Step: 13
Training loss: 3.2006624013052214
Validation loss: 2.530591658572755

Epoch: 298| Step: 0
Training loss: 2.539764213431369
Validation loss: 2.502283106429328

Epoch: 6| Step: 1
Training loss: 2.5005141683175944
Validation loss: 2.49090287129684

Epoch: 6| Step: 2
Training loss: 2.274226939724873
Validation loss: 2.4521927962699057

Epoch: 6| Step: 3
Training loss: 2.7747392205402646
Validation loss: 2.4282652503227573

Epoch: 6| Step: 4
Training loss: 2.391627880495251
Validation loss: 2.4234678600217423

Epoch: 6| Step: 5
Training loss: 2.523023636364376
Validation loss: 2.4346416385231153

Epoch: 6| Step: 6
Training loss: 2.587852483504304
Validation loss: 2.4472646560132123

Epoch: 6| Step: 7
Training loss: 2.4895934951979184
Validation loss: 2.4341839240789365

Epoch: 6| Step: 8
Training loss: 1.9047651918133122
Validation loss: 2.4762067911034755

Epoch: 6| Step: 9
Training loss: 2.895525104027205
Validation loss: 2.48063414040611

Epoch: 6| Step: 10
Training loss: 2.1182813458049785
Validation loss: 2.486078146121326

Epoch: 6| Step: 11
Training loss: 1.693287849015643
Validation loss: 2.507057305986459

Epoch: 6| Step: 12
Training loss: 2.8907427789561138
Validation loss: 2.5339525552710893

Epoch: 6| Step: 13
Training loss: 3.1895198032489755
Validation loss: 2.552017294100656

Epoch: 299| Step: 0
Training loss: 2.7810760615103653
Validation loss: 2.579975273398262

Epoch: 6| Step: 1
Training loss: 2.4082353006581774
Validation loss: 2.5728707537158795

Epoch: 6| Step: 2
Training loss: 2.48994397433573
Validation loss: 2.524019551687689

Epoch: 6| Step: 3
Training loss: 1.9585828892665758
Validation loss: 2.490650063970147

Epoch: 6| Step: 4
Training loss: 2.3389100009129478
Validation loss: 2.472658088239002

Epoch: 6| Step: 5
Training loss: 2.238029106278132
Validation loss: 2.4604752040772007

Epoch: 6| Step: 6
Training loss: 2.3947929002897768
Validation loss: 2.443396805391235

Epoch: 6| Step: 7
Training loss: 1.8311661424412435
Validation loss: 2.457650362114454

Epoch: 6| Step: 8
Training loss: 2.379459811543573
Validation loss: 2.4688536743061174

Epoch: 6| Step: 9
Training loss: 3.1705851821609947
Validation loss: 2.467914678301099

Epoch: 6| Step: 10
Training loss: 2.7978981746498977
Validation loss: 2.4886330553394638

Epoch: 6| Step: 11
Training loss: 2.796878409783187
Validation loss: 2.515486198564892

Epoch: 6| Step: 12
Training loss: 2.3857361914067097
Validation loss: 2.5583455032722413

Epoch: 6| Step: 13
Training loss: 2.414874289105716
Validation loss: 2.587701254301109

Epoch: 300| Step: 0
Training loss: 2.2308306559091924
Validation loss: 2.5503590494493595

Epoch: 6| Step: 1
Training loss: 2.427531276073179
Validation loss: 2.50060757206741

Epoch: 6| Step: 2
Training loss: 2.5038976803066104
Validation loss: 2.479374282704336

Epoch: 6| Step: 3
Training loss: 2.0017830529893472
Validation loss: 2.489411698820323

Epoch: 6| Step: 4
Training loss: 2.4889122179429086
Validation loss: 2.463266800959623

Epoch: 6| Step: 5
Training loss: 2.7995410338670115
Validation loss: 2.459972698099518

Epoch: 6| Step: 6
Training loss: 2.025376734598584
Validation loss: 2.4604761209746098

Epoch: 6| Step: 7
Training loss: 2.9763130624138996
Validation loss: 2.492221259719988

Epoch: 6| Step: 8
Training loss: 2.188980582404244
Validation loss: 2.48635458378943

Epoch: 6| Step: 9
Training loss: 2.7566614964016543
Validation loss: 2.4747421734443407

Epoch: 6| Step: 10
Training loss: 2.6195870857420216
Validation loss: 2.493489457215598

Epoch: 6| Step: 11
Training loss: 2.0713804549468313
Validation loss: 2.498824522070239

Epoch: 6| Step: 12
Training loss: 2.727210200199871
Validation loss: 2.5113763392246415

Epoch: 6| Step: 13
Training loss: 2.095336768275055
Validation loss: 2.5193607741655946

Epoch: 301| Step: 0
Training loss: 2.4114418990451965
Validation loss: 2.5024126306575614

Epoch: 6| Step: 1
Training loss: 2.7037046836268694
Validation loss: 2.4968636589773783

Epoch: 6| Step: 2
Training loss: 1.971154697124591
Validation loss: 2.488924313491564

Epoch: 6| Step: 3
Training loss: 2.348250074388423
Validation loss: 2.473353074822585

Epoch: 6| Step: 4
Training loss: 2.619296280504731
Validation loss: 2.48538255991923

Epoch: 6| Step: 5
Training loss: 2.9194458027973718
Validation loss: 2.4769634102055806

Epoch: 6| Step: 6
Training loss: 2.2011873639026365
Validation loss: 2.475596800597441

Epoch: 6| Step: 7
Training loss: 2.1259592920319412
Validation loss: 2.4710637594106366

Epoch: 6| Step: 8
Training loss: 2.7542715709596757
Validation loss: 2.465932421780081

Epoch: 6| Step: 9
Training loss: 2.1472613080102594
Validation loss: 2.5186193799089693

Epoch: 6| Step: 10
Training loss: 2.2940153628485906
Validation loss: 2.5426139364113896

Epoch: 6| Step: 11
Training loss: 2.317794512457379
Validation loss: 2.5555657116021004

Epoch: 6| Step: 12
Training loss: 2.748180220784187
Validation loss: 2.5527033176876106

Epoch: 6| Step: 13
Training loss: 2.7600330782027664
Validation loss: 2.4995481544215328

Epoch: 302| Step: 0
Training loss: 1.9998713690400938
Validation loss: 2.4764285941784636

Epoch: 6| Step: 1
Training loss: 2.225838098305482
Validation loss: 2.4686431207414947

Epoch: 6| Step: 2
Training loss: 3.009137859884462
Validation loss: 2.438558192609597

Epoch: 6| Step: 3
Training loss: 2.7124439638036586
Validation loss: 2.4506356482669065

Epoch: 6| Step: 4
Training loss: 1.966568722414253
Validation loss: 2.4423788868157734

Epoch: 6| Step: 5
Training loss: 2.4833195201651757
Validation loss: 2.432236485163715

Epoch: 6| Step: 6
Training loss: 2.423976257371608
Validation loss: 2.4380982503333564

Epoch: 6| Step: 7
Training loss: 2.3550865154208642
Validation loss: 2.453022054050089

Epoch: 6| Step: 8
Training loss: 2.784525624663335
Validation loss: 2.498488030525533

Epoch: 6| Step: 9
Training loss: 2.3169561186986996
Validation loss: 2.5043772308775263

Epoch: 6| Step: 10
Training loss: 2.7448117124536084
Validation loss: 2.523211554759099

Epoch: 6| Step: 11
Training loss: 2.8092805874143725
Validation loss: 2.530379934403983

Epoch: 6| Step: 12
Training loss: 2.267406946731213
Validation loss: 2.529128718783698

Epoch: 6| Step: 13
Training loss: 1.7158518545674362
Validation loss: 2.5139756112293696

Epoch: 303| Step: 0
Training loss: 1.39133803700004
Validation loss: 2.5272950398830423

Epoch: 6| Step: 1
Training loss: 3.190694666596028
Validation loss: 2.531929735083204

Epoch: 6| Step: 2
Training loss: 2.319714607245862
Validation loss: 2.5345907119780837

Epoch: 6| Step: 3
Training loss: 2.438121031851083
Validation loss: 2.5476230308220855

Epoch: 6| Step: 4
Training loss: 2.3383339929160587
Validation loss: 2.5451170325403427

Epoch: 6| Step: 5
Training loss: 1.9949015959752279
Validation loss: 2.5448416338529114

Epoch: 6| Step: 6
Training loss: 2.2417236273618046
Validation loss: 2.5016927208081077

Epoch: 6| Step: 7
Training loss: 2.1070487299255234
Validation loss: 2.507820528830433

Epoch: 6| Step: 8
Training loss: 2.5687468145865857
Validation loss: 2.4849760907579643

Epoch: 6| Step: 9
Training loss: 2.8182700414636153
Validation loss: 2.475523894734108

Epoch: 6| Step: 10
Training loss: 2.7448964880098696
Validation loss: 2.4624549886594647

Epoch: 6| Step: 11
Training loss: 2.5734686214415814
Validation loss: 2.435535117503024

Epoch: 6| Step: 12
Training loss: 2.406154482047961
Validation loss: 2.4607672019589497

Epoch: 6| Step: 13
Training loss: 2.6639147407073778
Validation loss: 2.488908392428867

Epoch: 304| Step: 0
Training loss: 2.2351016483617747
Validation loss: 2.5283866293160835

Epoch: 6| Step: 1
Training loss: 2.290699656520216
Validation loss: 2.539829391638913

Epoch: 6| Step: 2
Training loss: 2.750619991811931
Validation loss: 2.5488648720581977

Epoch: 6| Step: 3
Training loss: 2.4236932635540165
Validation loss: 2.527310508134988

Epoch: 6| Step: 4
Training loss: 1.7333565548417234
Validation loss: 2.513579796616433

Epoch: 6| Step: 5
Training loss: 2.99365437460429
Validation loss: 2.5139624400319085

Epoch: 6| Step: 6
Training loss: 2.4724082400552634
Validation loss: 2.477138790863281

Epoch: 6| Step: 7
Training loss: 2.277614466180608
Validation loss: 2.4857791475363897

Epoch: 6| Step: 8
Training loss: 2.6963651066784675
Validation loss: 2.505180891035621

Epoch: 6| Step: 9
Training loss: 2.209021718917874
Validation loss: 2.4839245096318887

Epoch: 6| Step: 10
Training loss: 2.0381923879872623
Validation loss: 2.4890845186022963

Epoch: 6| Step: 11
Training loss: 2.446764237782326
Validation loss: 2.4913851104341527

Epoch: 6| Step: 12
Training loss: 2.667312742487343
Validation loss: 2.4803208556142353

Epoch: 6| Step: 13
Training loss: 2.595005145352652
Validation loss: 2.5044910781446568

Epoch: 305| Step: 0
Training loss: 2.038857402206138
Validation loss: 2.506683695631018

Epoch: 6| Step: 1
Training loss: 2.9954316005598947
Validation loss: 2.5119886705406818

Epoch: 6| Step: 2
Training loss: 3.192884198687072
Validation loss: 2.5507720332516324

Epoch: 6| Step: 3
Training loss: 2.4926991669905694
Validation loss: 2.5806260155023986

Epoch: 6| Step: 4
Training loss: 2.4876011468460524
Validation loss: 2.5779755032855842

Epoch: 6| Step: 5
Training loss: 2.16418148223228
Validation loss: 2.5768866465080023

Epoch: 6| Step: 6
Training loss: 2.42792744072175
Validation loss: 2.5417098174995494

Epoch: 6| Step: 7
Training loss: 1.9811909278703508
Validation loss: 2.499309799327392

Epoch: 6| Step: 8
Training loss: 2.440212989641366
Validation loss: 2.4510688030890364

Epoch: 6| Step: 9
Training loss: 2.719861121418869
Validation loss: 2.433042302162583

Epoch: 6| Step: 10
Training loss: 2.088894694514132
Validation loss: 2.4361966531902333

Epoch: 6| Step: 11
Training loss: 1.69203424578701
Validation loss: 2.444465251135192

Epoch: 6| Step: 12
Training loss: 2.075653327213321
Validation loss: 2.4233120468539

Epoch: 6| Step: 13
Training loss: 2.6753302646577857
Validation loss: 2.4433472228131454

Epoch: 306| Step: 0
Training loss: 2.950316531769816
Validation loss: 2.4347898247760345

Epoch: 6| Step: 1
Training loss: 2.4220081907995374
Validation loss: 2.424287629690695

Epoch: 6| Step: 2
Training loss: 2.183832309091002
Validation loss: 2.4626793606958044

Epoch: 6| Step: 3
Training loss: 2.208173014261583
Validation loss: 2.467474449422645

Epoch: 6| Step: 4
Training loss: 2.328679985103677
Validation loss: 2.4841556370964244

Epoch: 6| Step: 5
Training loss: 2.6384242892496537
Validation loss: 2.524797902953634

Epoch: 6| Step: 6
Training loss: 2.4720178536322828
Validation loss: 2.52847152333393

Epoch: 6| Step: 7
Training loss: 2.708051657089617
Validation loss: 2.534907248776829

Epoch: 6| Step: 8
Training loss: 2.54016314786059
Validation loss: 2.498273312673943

Epoch: 6| Step: 9
Training loss: 2.39968412227917
Validation loss: 2.486525813120232

Epoch: 6| Step: 10
Training loss: 2.6190878274646754
Validation loss: 2.484418856635551

Epoch: 6| Step: 11
Training loss: 2.6015141113180067
Validation loss: 2.4676205788003376

Epoch: 6| Step: 12
Training loss: 1.5251854674326493
Validation loss: 2.4535770327668334

Epoch: 6| Step: 13
Training loss: 2.008948453774535
Validation loss: 2.439945568585083

Epoch: 307| Step: 0
Training loss: 2.1238823363692854
Validation loss: 2.465062743144752

Epoch: 6| Step: 1
Training loss: 2.96225823812235
Validation loss: 2.461298352889936

Epoch: 6| Step: 2
Training loss: 2.2801038397181523
Validation loss: 2.4997599476240757

Epoch: 6| Step: 3
Training loss: 2.6508534982348615
Validation loss: 2.537687248313726

Epoch: 6| Step: 4
Training loss: 1.9965042319268465
Validation loss: 2.5265527020325047

Epoch: 6| Step: 5
Training loss: 2.5615847744217
Validation loss: 2.5490054066897008

Epoch: 6| Step: 6
Training loss: 1.782018261585791
Validation loss: 2.556762501887306

Epoch: 6| Step: 7
Training loss: 2.5523243277808816
Validation loss: 2.5631371653123947

Epoch: 6| Step: 8
Training loss: 2.285276334818867
Validation loss: 2.557910247313552

Epoch: 6| Step: 9
Training loss: 1.7564322923423514
Validation loss: 2.5469472615559683

Epoch: 6| Step: 10
Training loss: 2.367097557046176
Validation loss: 2.5148589916270896

Epoch: 6| Step: 11
Training loss: 3.08258322449492
Validation loss: 2.4651916766947406

Epoch: 6| Step: 12
Training loss: 2.496929381044514
Validation loss: 2.441795426390622

Epoch: 6| Step: 13
Training loss: 2.5165903833545844
Validation loss: 2.4353191378695827

Epoch: 308| Step: 0
Training loss: 2.433857078449824
Validation loss: 2.4132545596103188

Epoch: 6| Step: 1
Training loss: 1.8473344647654044
Validation loss: 2.40548631822691

Epoch: 6| Step: 2
Training loss: 2.6479826680103113
Validation loss: 2.4061473488403373

Epoch: 6| Step: 3
Training loss: 2.727634252081584
Validation loss: 2.3961132818722635

Epoch: 6| Step: 4
Training loss: 2.306022645241944
Validation loss: 2.4078070603936124

Epoch: 6| Step: 5
Training loss: 2.553945451110602
Validation loss: 2.440070572970069

Epoch: 6| Step: 6
Training loss: 2.431877302425082
Validation loss: 2.4398555201893606

Epoch: 6| Step: 7
Training loss: 2.6356075856006864
Validation loss: 2.4783757155250745

Epoch: 6| Step: 8
Training loss: 1.9672323159709963
Validation loss: 2.528871287297132

Epoch: 6| Step: 9
Training loss: 2.3242234686795586
Validation loss: 2.5539992941690315

Epoch: 6| Step: 10
Training loss: 2.3011515761363874
Validation loss: 2.6404616151288827

Epoch: 6| Step: 11
Training loss: 2.9121583337077497
Validation loss: 2.640519747499558

Epoch: 6| Step: 12
Training loss: 2.1335308276591696
Validation loss: 2.620487462663283

Epoch: 6| Step: 13
Training loss: 2.4427660275758125
Validation loss: 2.604905425260935

Epoch: 309| Step: 0
Training loss: 2.7869982520167436
Validation loss: 2.56381489582777

Epoch: 6| Step: 1
Training loss: 2.563173717230205
Validation loss: 2.540765069517753

Epoch: 6| Step: 2
Training loss: 2.6947900238051763
Validation loss: 2.5047990175777395

Epoch: 6| Step: 3
Training loss: 2.5494176424036863
Validation loss: 2.492517149718297

Epoch: 6| Step: 4
Training loss: 2.2162726097438203
Validation loss: 2.47374061718868

Epoch: 6| Step: 5
Training loss: 1.520418275954417
Validation loss: 2.470015199931755

Epoch: 6| Step: 6
Training loss: 2.678801543024264
Validation loss: 2.4693233612873975

Epoch: 6| Step: 7
Training loss: 2.6620482943630073
Validation loss: 2.4920845690690903

Epoch: 6| Step: 8
Training loss: 2.1111847072734062
Validation loss: 2.5063590667292837

Epoch: 6| Step: 9
Training loss: 2.219333088510503
Validation loss: 2.4875585098463615

Epoch: 6| Step: 10
Training loss: 1.138169454243737
Validation loss: 2.506576202172787

Epoch: 6| Step: 11
Training loss: 2.564486594174206
Validation loss: 2.5328658919293967

Epoch: 6| Step: 12
Training loss: 2.77028827516794
Validation loss: 2.598353128761229

Epoch: 6| Step: 13
Training loss: 2.8934174117896743
Validation loss: 2.5843005147838762

Epoch: 310| Step: 0
Training loss: 2.2569222460576164
Validation loss: 2.527546571593182

Epoch: 6| Step: 1
Training loss: 2.3764896740310837
Validation loss: 2.530349820529384

Epoch: 6| Step: 2
Training loss: 2.6089630715508068
Validation loss: 2.484840868951134

Epoch: 6| Step: 3
Training loss: 2.3048318074193492
Validation loss: 2.482033395125738

Epoch: 6| Step: 4
Training loss: 2.7495650901214272
Validation loss: 2.450363495351692

Epoch: 6| Step: 5
Training loss: 2.52289237638877
Validation loss: 2.4366510320548227

Epoch: 6| Step: 6
Training loss: 2.8715325052718814
Validation loss: 2.438407799370377

Epoch: 6| Step: 7
Training loss: 2.541770359696541
Validation loss: 2.4140635258542718

Epoch: 6| Step: 8
Training loss: 2.553940596747761
Validation loss: 2.439532413663914

Epoch: 6| Step: 9
Training loss: 2.183096677267162
Validation loss: 2.4702550761069655

Epoch: 6| Step: 10
Training loss: 2.055704423594272
Validation loss: 2.5141476126163456

Epoch: 6| Step: 11
Training loss: 2.1814300244212586
Validation loss: 2.5563489299330246

Epoch: 6| Step: 12
Training loss: 1.97131682897674
Validation loss: 2.553290071823224

Epoch: 6| Step: 13
Training loss: 2.355981470485288
Validation loss: 2.551400356723318

Epoch: 311| Step: 0
Training loss: 2.6570729495519543
Validation loss: 2.5259085908238386

Epoch: 6| Step: 1
Training loss: 1.9284380987794176
Validation loss: 2.5017184329893407

Epoch: 6| Step: 2
Training loss: 2.421159404739634
Validation loss: 2.4892252762701834

Epoch: 6| Step: 3
Training loss: 2.2088946822598117
Validation loss: 2.475089459124713

Epoch: 6| Step: 4
Training loss: 2.558688888528183
Validation loss: 2.452234334712888

Epoch: 6| Step: 5
Training loss: 2.058801398038121
Validation loss: 2.4515491453625167

Epoch: 6| Step: 6
Training loss: 2.429827817931238
Validation loss: 2.440992608187979

Epoch: 6| Step: 7
Training loss: 2.5864668474327392
Validation loss: 2.456264110613266

Epoch: 6| Step: 8
Training loss: 1.557745910874254
Validation loss: 2.4389233983279563

Epoch: 6| Step: 9
Training loss: 2.137957839564401
Validation loss: 2.450602558458364

Epoch: 6| Step: 10
Training loss: 3.0814754627989545
Validation loss: 2.479899653711252

Epoch: 6| Step: 11
Training loss: 2.188032466933473
Validation loss: 2.50000443611982

Epoch: 6| Step: 12
Training loss: 2.6572425334300456
Validation loss: 2.5359335840404866

Epoch: 6| Step: 13
Training loss: 2.557018371605545
Validation loss: 2.5670241829114344

Epoch: 312| Step: 0
Training loss: 2.3542596804268006
Validation loss: 2.614312339328466

Epoch: 6| Step: 1
Training loss: 2.94799924988653
Validation loss: 2.609787593292635

Epoch: 6| Step: 2
Training loss: 2.2944028876263842
Validation loss: 2.607161847500073

Epoch: 6| Step: 3
Training loss: 2.8645864220804844
Validation loss: 2.574418096703515

Epoch: 6| Step: 4
Training loss: 2.5984440806311833
Validation loss: 2.499638080036118

Epoch: 6| Step: 5
Training loss: 2.1601822973960783
Validation loss: 2.4677897411211585

Epoch: 6| Step: 6
Training loss: 1.8812935428079307
Validation loss: 2.4392574212786777

Epoch: 6| Step: 7
Training loss: 2.0823445325981496
Validation loss: 2.4263365870148843

Epoch: 6| Step: 8
Training loss: 2.477128598949526
Validation loss: 2.4179286013479953

Epoch: 6| Step: 9
Training loss: 2.4501417936437804
Validation loss: 2.4299763420537013

Epoch: 6| Step: 10
Training loss: 2.567647648236729
Validation loss: 2.4431999941940665

Epoch: 6| Step: 11
Training loss: 2.7704181407875397
Validation loss: 2.4491169849435765

Epoch: 6| Step: 12
Training loss: 1.8759592781283396
Validation loss: 2.4326187134904003

Epoch: 6| Step: 13
Training loss: 1.9221136053570829
Validation loss: 2.458448311056787

Epoch: 313| Step: 0
Training loss: 2.136337999525771
Validation loss: 2.4688053324801706

Epoch: 6| Step: 1
Training loss: 2.748065354665344
Validation loss: 2.4712119790577938

Epoch: 6| Step: 2
Training loss: 2.408720853398577
Validation loss: 2.498763940685031

Epoch: 6| Step: 3
Training loss: 2.3042067204098853
Validation loss: 2.4795186902853454

Epoch: 6| Step: 4
Training loss: 2.3203588410447638
Validation loss: 2.503273292569099

Epoch: 6| Step: 5
Training loss: 2.165972806405842
Validation loss: 2.5378328744448466

Epoch: 6| Step: 6
Training loss: 2.3171762148478776
Validation loss: 2.5653868415422676

Epoch: 6| Step: 7
Training loss: 2.5601999148154038
Validation loss: 2.5658601329742883

Epoch: 6| Step: 8
Training loss: 2.55100388307474
Validation loss: 2.522826081800023

Epoch: 6| Step: 9
Training loss: 2.138896606343316
Validation loss: 2.477016233632466

Epoch: 6| Step: 10
Training loss: 2.2678474837999647
Validation loss: 2.424643364872113

Epoch: 6| Step: 11
Training loss: 2.69466907727176
Validation loss: 2.3911387088448897

Epoch: 6| Step: 12
Training loss: 2.2426455358869775
Validation loss: 2.3982534040968377

Epoch: 6| Step: 13
Training loss: 2.853205795230432
Validation loss: 2.415550919203825

Epoch: 314| Step: 0
Training loss: 2.2697909234512417
Validation loss: 2.407164171085883

Epoch: 6| Step: 1
Training loss: 2.323339780126281
Validation loss: 2.392891224910254

Epoch: 6| Step: 2
Training loss: 2.7671609697410986
Validation loss: 2.4117872570679744

Epoch: 6| Step: 3
Training loss: 1.821190618150434
Validation loss: 2.460953470761976

Epoch: 6| Step: 4
Training loss: 2.0929369130548556
Validation loss: 2.5019323069826815

Epoch: 6| Step: 5
Training loss: 2.770753749383312
Validation loss: 2.5430308298283038

Epoch: 6| Step: 6
Training loss: 2.156752928532303
Validation loss: 2.5927730469382513

Epoch: 6| Step: 7
Training loss: 2.3895436752296617
Validation loss: 2.5588006970514576

Epoch: 6| Step: 8
Training loss: 2.105034325109141
Validation loss: 2.5329290624700223

Epoch: 6| Step: 9
Training loss: 2.1959869326218335
Validation loss: 2.531352628619789

Epoch: 6| Step: 10
Training loss: 2.331240828345208
Validation loss: 2.520787706388484

Epoch: 6| Step: 11
Training loss: 2.906053597981851
Validation loss: 2.5137683516425473

Epoch: 6| Step: 12
Training loss: 2.419709252475618
Validation loss: 2.5292808452070847

Epoch: 6| Step: 13
Training loss: 2.6853700225859236
Validation loss: 2.5070224637297

Epoch: 315| Step: 0
Training loss: 2.5734781638420268
Validation loss: 2.4843004096431027

Epoch: 6| Step: 1
Training loss: 2.120879385497527
Validation loss: 2.4533726185978866

Epoch: 6| Step: 2
Training loss: 1.9209878005713226
Validation loss: 2.4589359142129146

Epoch: 6| Step: 3
Training loss: 2.301203690559694
Validation loss: 2.4229624910323855

Epoch: 6| Step: 4
Training loss: 2.0811935371323504
Validation loss: 2.4251899703395825

Epoch: 6| Step: 5
Training loss: 2.474407040243311
Validation loss: 2.4314095307053902

Epoch: 6| Step: 6
Training loss: 2.429975388327713
Validation loss: 2.4166090268512637

Epoch: 6| Step: 7
Training loss: 3.1850982293951304
Validation loss: 2.4201527452888496

Epoch: 6| Step: 8
Training loss: 2.6318312268046897
Validation loss: 2.4382711000161557

Epoch: 6| Step: 9
Training loss: 2.197228949346692
Validation loss: 2.4364123493260386

Epoch: 6| Step: 10
Training loss: 1.9703332499077761
Validation loss: 2.474672572989111

Epoch: 6| Step: 11
Training loss: 2.633189550731775
Validation loss: 2.495201898332907

Epoch: 6| Step: 12
Training loss: 2.14280088895801
Validation loss: 2.5619451470865435

Epoch: 6| Step: 13
Training loss: 2.6218062454320354
Validation loss: 2.6273292456139785

Epoch: 316| Step: 0
Training loss: 2.6711719324095697
Validation loss: 2.677195788968185

Epoch: 6| Step: 1
Training loss: 2.6924694159425715
Validation loss: 2.6846188036613334

Epoch: 6| Step: 2
Training loss: 2.351725829272646
Validation loss: 2.630428494490901

Epoch: 6| Step: 3
Training loss: 1.891327215258537
Validation loss: 2.5927092698874286

Epoch: 6| Step: 4
Training loss: 2.330353355300239
Validation loss: 2.560123046496264

Epoch: 6| Step: 5
Training loss: 1.789045708590006
Validation loss: 2.5039171673578293

Epoch: 6| Step: 6
Training loss: 2.375159509221304
Validation loss: 2.460054246436253

Epoch: 6| Step: 7
Training loss: 2.618466557205964
Validation loss: 2.427151363524401

Epoch: 6| Step: 8
Training loss: 2.4143144297081163
Validation loss: 2.4229387861314753

Epoch: 6| Step: 9
Training loss: 1.9905780948400653
Validation loss: 2.4060765547369045

Epoch: 6| Step: 10
Training loss: 2.751433605703885
Validation loss: 2.402920822809994

Epoch: 6| Step: 11
Training loss: 2.486656916380202
Validation loss: 2.408242701264882

Epoch: 6| Step: 12
Training loss: 2.7077024654301267
Validation loss: 2.405995401700487

Epoch: 6| Step: 13
Training loss: 1.6988094143726318
Validation loss: 2.4113009545493824

Epoch: 317| Step: 0
Training loss: 2.5672985830670183
Validation loss: 2.413014209109686

Epoch: 6| Step: 1
Training loss: 2.169276597350035
Validation loss: 2.442221171956481

Epoch: 6| Step: 2
Training loss: 2.6470223305873204
Validation loss: 2.4918966078242115

Epoch: 6| Step: 3
Training loss: 3.027319493350402
Validation loss: 2.4940793110525363

Epoch: 6| Step: 4
Training loss: 2.4868955481620576
Validation loss: 2.5613151480213814

Epoch: 6| Step: 5
Training loss: 2.284847297323964
Validation loss: 2.5685782028772737

Epoch: 6| Step: 6
Training loss: 2.627813829287155
Validation loss: 2.5490737846315903

Epoch: 6| Step: 7
Training loss: 2.050823102251512
Validation loss: 2.5182205574854

Epoch: 6| Step: 8
Training loss: 2.578603249320691
Validation loss: 2.5274195916700126

Epoch: 6| Step: 9
Training loss: 1.8005023334830221
Validation loss: 2.504855860630092

Epoch: 6| Step: 10
Training loss: 2.2239336523135256
Validation loss: 2.4946799328488334

Epoch: 6| Step: 11
Training loss: 1.9458551224571612
Validation loss: 2.4736076613349125

Epoch: 6| Step: 12
Training loss: 1.9694842225890878
Validation loss: 2.4451282742016693

Epoch: 6| Step: 13
Training loss: 2.447663952924611
Validation loss: 2.437547481843228

Epoch: 318| Step: 0
Training loss: 2.349646716245255
Validation loss: 2.444029770036306

Epoch: 6| Step: 1
Training loss: 2.3165360361314384
Validation loss: 2.4077424123815145

Epoch: 6| Step: 2
Training loss: 2.5998950460231454
Validation loss: 2.392517066027444

Epoch: 6| Step: 3
Training loss: 2.0142528979595578
Validation loss: 2.4013755615471624

Epoch: 6| Step: 4
Training loss: 2.772636276349452
Validation loss: 2.411185776729656

Epoch: 6| Step: 5
Training loss: 2.080655958839706
Validation loss: 2.4090675134918857

Epoch: 6| Step: 6
Training loss: 2.7034984176346084
Validation loss: 2.41199877317947

Epoch: 6| Step: 7
Training loss: 2.0709492405998544
Validation loss: 2.427865522148197

Epoch: 6| Step: 8
Training loss: 2.467537884175006
Validation loss: 2.4418759093363267

Epoch: 6| Step: 9
Training loss: 2.849366730052329
Validation loss: 2.4777747328115503

Epoch: 6| Step: 10
Training loss: 2.2022748889692387
Validation loss: 2.540573272927219

Epoch: 6| Step: 11
Training loss: 2.2117297367320283
Validation loss: 2.604514976260363

Epoch: 6| Step: 12
Training loss: 1.8887032444113154
Validation loss: 2.6020519049142785

Epoch: 6| Step: 13
Training loss: 2.8508542370097194
Validation loss: 2.6134343734475136

Epoch: 319| Step: 0
Training loss: 2.3050089983650706
Validation loss: 2.518089371911184

Epoch: 6| Step: 1
Training loss: 2.300204918896313
Validation loss: 2.4776460826075777

Epoch: 6| Step: 2
Training loss: 2.5083192687627767
Validation loss: 2.3992870360508287

Epoch: 6| Step: 3
Training loss: 2.6159297824791805
Validation loss: 2.391657930592366

Epoch: 6| Step: 4
Training loss: 2.335477241413393
Validation loss: 2.365042242183566

Epoch: 6| Step: 5
Training loss: 1.9962773845134347
Validation loss: 2.3840735670601623

Epoch: 6| Step: 6
Training loss: 3.018410142679207
Validation loss: 2.3770113126359154

Epoch: 6| Step: 7
Training loss: 2.744780442120199
Validation loss: 2.383057157401948

Epoch: 6| Step: 8
Training loss: 2.3686941658626175
Validation loss: 2.3850566332410903

Epoch: 6| Step: 9
Training loss: 1.8916437856267865
Validation loss: 2.4191446474848393

Epoch: 6| Step: 10
Training loss: 2.052673977762756
Validation loss: 2.4727606656155436

Epoch: 6| Step: 11
Training loss: 2.4266007125017124
Validation loss: 2.5286856620362785

Epoch: 6| Step: 12
Training loss: 2.2946195362680815
Validation loss: 2.6060874418280604

Epoch: 6| Step: 13
Training loss: 2.122944903973633
Validation loss: 2.6567448193143157

Epoch: 320| Step: 0
Training loss: 2.3015106547538102
Validation loss: 2.6332022862000772

Epoch: 6| Step: 1
Training loss: 2.7355367753756066
Validation loss: 2.6151265017004466

Epoch: 6| Step: 2
Training loss: 2.3089273021383887
Validation loss: 2.5245576830320333

Epoch: 6| Step: 3
Training loss: 2.220547445002104
Validation loss: 2.458000650380416

Epoch: 6| Step: 4
Training loss: 2.436695455162778
Validation loss: 2.425104998484853

Epoch: 6| Step: 5
Training loss: 2.313191284780165
Validation loss: 2.403677172316485

Epoch: 6| Step: 6
Training loss: 1.7583847131800503
Validation loss: 2.384762316125003

Epoch: 6| Step: 7
Training loss: 2.7082074845247437
Validation loss: 2.3870678213345853

Epoch: 6| Step: 8
Training loss: 2.691601307393319
Validation loss: 2.3658544598530296

Epoch: 6| Step: 9
Training loss: 1.6865446424007124
Validation loss: 2.416106085492592

Epoch: 6| Step: 10
Training loss: 2.0820701838819824
Validation loss: 2.3983920818118465

Epoch: 6| Step: 11
Training loss: 2.1736412276462365
Validation loss: 2.447120746216137

Epoch: 6| Step: 12
Training loss: 3.0140189998764457
Validation loss: 2.4558898496001023

Epoch: 6| Step: 13
Training loss: 2.3376201578356
Validation loss: 2.4686517525860614

Epoch: 321| Step: 0
Training loss: 1.658426617949131
Validation loss: 2.4993185683584866

Epoch: 6| Step: 1
Training loss: 2.6131634650037343
Validation loss: 2.5012320917671858

Epoch: 6| Step: 2
Training loss: 2.369115063560064
Validation loss: 2.5520166562084245

Epoch: 6| Step: 3
Training loss: 2.543933316310487
Validation loss: 2.5713182721887087

Epoch: 6| Step: 4
Training loss: 2.4174415617608647
Validation loss: 2.5308680882413683

Epoch: 6| Step: 5
Training loss: 2.734464022685895
Validation loss: 2.484334823459993

Epoch: 6| Step: 6
Training loss: 2.1662430226807396
Validation loss: 2.4397701338994726

Epoch: 6| Step: 7
Training loss: 2.5496129957745852
Validation loss: 2.430090445176367

Epoch: 6| Step: 8
Training loss: 2.3578809845763544
Validation loss: 2.4255618821412064

Epoch: 6| Step: 9
Training loss: 2.2418117939462086
Validation loss: 2.420716306573629

Epoch: 6| Step: 10
Training loss: 2.68443957996068
Validation loss: 2.4344278753306843

Epoch: 6| Step: 11
Training loss: 1.9899938136632407
Validation loss: 2.421850109468626

Epoch: 6| Step: 12
Training loss: 1.895613402580507
Validation loss: 2.419276778455575

Epoch: 6| Step: 13
Training loss: 2.360578015551463
Validation loss: 2.4291421656598158

Epoch: 322| Step: 0
Training loss: 2.2014181681336167
Validation loss: 2.4339021434565136

Epoch: 6| Step: 1
Training loss: 2.523902873774575
Validation loss: 2.440733744742063

Epoch: 6| Step: 2
Training loss: 2.9087564468476277
Validation loss: 2.4716562797274975

Epoch: 6| Step: 3
Training loss: 2.2151776420365947
Validation loss: 2.4930044085102154

Epoch: 6| Step: 4
Training loss: 2.164510852627017
Validation loss: 2.487844786811326

Epoch: 6| Step: 5
Training loss: 2.5115120003239078
Validation loss: 2.526884777629716

Epoch: 6| Step: 6
Training loss: 1.7602913565494285
Validation loss: 2.5473683348317864

Epoch: 6| Step: 7
Training loss: 2.2248110658816915
Validation loss: 2.5698588145703423

Epoch: 6| Step: 8
Training loss: 2.25627765163057
Validation loss: 2.533389806630711

Epoch: 6| Step: 9
Training loss: 1.9532415736695459
Validation loss: 2.5083141543935743

Epoch: 6| Step: 10
Training loss: 2.738756081501674
Validation loss: 2.5273676827360063

Epoch: 6| Step: 11
Training loss: 2.492449803435175
Validation loss: 2.467753268190459

Epoch: 6| Step: 12
Training loss: 2.2169775532096727
Validation loss: 2.4545576083342393

Epoch: 6| Step: 13
Training loss: 1.9612027175095568
Validation loss: 2.431252188243578

Epoch: 323| Step: 0
Training loss: 2.251143588739466
Validation loss: 2.396095392805098

Epoch: 6| Step: 1
Training loss: 2.373468507585522
Validation loss: 2.408613758457009

Epoch: 6| Step: 2
Training loss: 1.9537863870406362
Validation loss: 2.3939969333654365

Epoch: 6| Step: 3
Training loss: 2.283657945636977
Validation loss: 2.4081187753629467

Epoch: 6| Step: 4
Training loss: 2.3502036189069844
Validation loss: 2.429014986179414

Epoch: 6| Step: 5
Training loss: 2.3135843569890198
Validation loss: 2.465481904602117

Epoch: 6| Step: 6
Training loss: 3.2242103852001076
Validation loss: 2.491110886849459

Epoch: 6| Step: 7
Training loss: 2.33228805380424
Validation loss: 2.495513385854698

Epoch: 6| Step: 8
Training loss: 1.8275017613351583
Validation loss: 2.513478596458708

Epoch: 6| Step: 9
Training loss: 1.749359217903387
Validation loss: 2.5008354667587254

Epoch: 6| Step: 10
Training loss: 2.963199445991794
Validation loss: 2.4679761623697187

Epoch: 6| Step: 11
Training loss: 2.3517960847443278
Validation loss: 2.4389255710254822

Epoch: 6| Step: 12
Training loss: 1.887725182547075
Validation loss: 2.461540902147787

Epoch: 6| Step: 13
Training loss: 2.4211223786474934
Validation loss: 2.472693004152582

Epoch: 324| Step: 0
Training loss: 2.2502124474151763
Validation loss: 2.4927827207415767

Epoch: 6| Step: 1
Training loss: 2.641271207393027
Validation loss: 2.483898261824823

Epoch: 6| Step: 2
Training loss: 1.1218186536999843
Validation loss: 2.474149753870006

Epoch: 6| Step: 3
Training loss: 2.0421397640658694
Validation loss: 2.50304155525963

Epoch: 6| Step: 4
Training loss: 2.64477862464681
Validation loss: 2.4787872322595073

Epoch: 6| Step: 5
Training loss: 2.394517708719868
Validation loss: 2.4573051672571586

Epoch: 6| Step: 6
Training loss: 2.641941261660811
Validation loss: 2.4148531577820913

Epoch: 6| Step: 7
Training loss: 2.2659237368713754
Validation loss: 2.4032885830656485

Epoch: 6| Step: 8
Training loss: 2.083180409223024
Validation loss: 2.394235026647643

Epoch: 6| Step: 9
Training loss: 2.503138670008904
Validation loss: 2.4135903653646187

Epoch: 6| Step: 10
Training loss: 2.3408334514454476
Validation loss: 2.3968241775176624

Epoch: 6| Step: 11
Training loss: 2.4256427620933083
Validation loss: 2.394344020665397

Epoch: 6| Step: 12
Training loss: 1.8886284492810104
Validation loss: 2.436401443572404

Epoch: 6| Step: 13
Training loss: 2.8253643408593967
Validation loss: 2.436394738790378

Epoch: 325| Step: 0
Training loss: 2.3067142174437283
Validation loss: 2.5112802178197646

Epoch: 6| Step: 1
Training loss: 2.066984676176941
Validation loss: 2.522754698342725

Epoch: 6| Step: 2
Training loss: 2.4710163385336594
Validation loss: 2.601962864469384

Epoch: 6| Step: 3
Training loss: 2.5166326364738523
Validation loss: 2.608150696757946

Epoch: 6| Step: 4
Training loss: 2.37265551444285
Validation loss: 2.6186216722292643

Epoch: 6| Step: 5
Training loss: 2.3908274446425763
Validation loss: 2.5547038921949077

Epoch: 6| Step: 6
Training loss: 2.6777713252772903
Validation loss: 2.525870060945816

Epoch: 6| Step: 7
Training loss: 1.849833135554267
Validation loss: 2.512330251930732

Epoch: 6| Step: 8
Training loss: 2.5290907138771783
Validation loss: 2.460191566300992

Epoch: 6| Step: 9
Training loss: 2.0019843271196494
Validation loss: 2.4278803536065503

Epoch: 6| Step: 10
Training loss: 2.3165480777750043
Validation loss: 2.400142642750566

Epoch: 6| Step: 11
Training loss: 2.26551397643517
Validation loss: 2.400876347283764

Epoch: 6| Step: 12
Training loss: 2.3211489624318253
Validation loss: 2.4137914961921876

Epoch: 6| Step: 13
Training loss: 1.9529990193744937
Validation loss: 2.3981898000421995

Epoch: 326| Step: 0
Training loss: 2.8428611623895823
Validation loss: 2.4100909517840603

Epoch: 6| Step: 1
Training loss: 2.2369871009860622
Validation loss: 2.4139957383569484

Epoch: 6| Step: 2
Training loss: 2.8518086366374584
Validation loss: 2.41496918297716

Epoch: 6| Step: 3
Training loss: 1.92268701782161
Validation loss: 2.4249751725832516

Epoch: 6| Step: 4
Training loss: 2.0051589233123788
Validation loss: 2.4460367671761674

Epoch: 6| Step: 5
Training loss: 1.561694586119886
Validation loss: 2.4707726660708444

Epoch: 6| Step: 6
Training loss: 2.422006517346384
Validation loss: 2.490587590498482

Epoch: 6| Step: 7
Training loss: 2.20737950100897
Validation loss: 2.540432746635282

Epoch: 6| Step: 8
Training loss: 1.348041512526461
Validation loss: 2.5450516492793733

Epoch: 6| Step: 9
Training loss: 2.392194046021518
Validation loss: 2.562010388404364

Epoch: 6| Step: 10
Training loss: 2.4932134065328495
Validation loss: 2.562287269524085

Epoch: 6| Step: 11
Training loss: 2.0364360629243694
Validation loss: 2.5700877291117816

Epoch: 6| Step: 12
Training loss: 2.206313835279581
Validation loss: 2.5874963462422937

Epoch: 6| Step: 13
Training loss: 3.55596149796195
Validation loss: 2.5849182878375676

Epoch: 327| Step: 0
Training loss: 2.467867053557964
Validation loss: 2.4747444649034356

Epoch: 6| Step: 1
Training loss: 1.917217597010125
Validation loss: 2.432402378991698

Epoch: 6| Step: 2
Training loss: 2.54214712719315
Validation loss: 2.406880439299708

Epoch: 6| Step: 3
Training loss: 2.4039432318232086
Validation loss: 2.3932225973103893

Epoch: 6| Step: 4
Training loss: 2.477096163173995
Validation loss: 2.3872269945785685

Epoch: 6| Step: 5
Training loss: 2.773448503499299
Validation loss: 2.3897186004414572

Epoch: 6| Step: 6
Training loss: 2.6035719434022626
Validation loss: 2.3707151030719786

Epoch: 6| Step: 7
Training loss: 2.7141263384385517
Validation loss: 2.3967511163779025

Epoch: 6| Step: 8
Training loss: 1.7774323493756536
Validation loss: 2.411269814945979

Epoch: 6| Step: 9
Training loss: 2.0728470169200137
Validation loss: 2.4341171324159165

Epoch: 6| Step: 10
Training loss: 1.7197972661679486
Validation loss: 2.474636685298825

Epoch: 6| Step: 11
Training loss: 2.3175124410647174
Validation loss: 2.5760260217908075

Epoch: 6| Step: 12
Training loss: 1.7322009783335188
Validation loss: 2.59501544927008

Epoch: 6| Step: 13
Training loss: 2.500759486229151
Validation loss: 2.597305872039528

Epoch: 328| Step: 0
Training loss: 2.303607027913028
Validation loss: 2.528905760609271

Epoch: 6| Step: 1
Training loss: 2.0920190060993957
Validation loss: 2.4597260222061865

Epoch: 6| Step: 2
Training loss: 2.4400574399096824
Validation loss: 2.4132884196554762

Epoch: 6| Step: 3
Training loss: 1.8698271922470742
Validation loss: 2.389014389792106

Epoch: 6| Step: 4
Training loss: 2.9289614985870127
Validation loss: 2.3834805406624384

Epoch: 6| Step: 5
Training loss: 2.2929126011279046
Validation loss: 2.383191009481061

Epoch: 6| Step: 6
Training loss: 2.0458882989381846
Validation loss: 2.37890321424343

Epoch: 6| Step: 7
Training loss: 2.346797436932181
Validation loss: 2.369892579510294

Epoch: 6| Step: 8
Training loss: 2.663798031027082
Validation loss: 2.39312636227944

Epoch: 6| Step: 9
Training loss: 2.001769713397031
Validation loss: 2.395257676471815

Epoch: 6| Step: 10
Training loss: 2.621887723507659
Validation loss: 2.4424590367007815

Epoch: 6| Step: 11
Training loss: 2.507623302892886
Validation loss: 2.5313260051700697

Epoch: 6| Step: 12
Training loss: 2.2196090539590507
Validation loss: 2.590516445088784

Epoch: 6| Step: 13
Training loss: 2.204896687965686
Validation loss: 2.6291575324910355

Epoch: 329| Step: 0
Training loss: 2.299752023016961
Validation loss: 2.6287411771394154

Epoch: 6| Step: 1
Training loss: 2.7780044992958364
Validation loss: 2.621313824518449

Epoch: 6| Step: 2
Training loss: 1.899852147121839
Validation loss: 2.5435481202778547

Epoch: 6| Step: 3
Training loss: 2.08737213291369
Validation loss: 2.4525847202213056

Epoch: 6| Step: 4
Training loss: 2.384576563483647
Validation loss: 2.413012966075018

Epoch: 6| Step: 5
Training loss: 2.6931700221521466
Validation loss: 2.4154657817939476

Epoch: 6| Step: 6
Training loss: 2.3818789795337065
Validation loss: 2.377207432366441

Epoch: 6| Step: 7
Training loss: 2.026017595032096
Validation loss: 2.3835026686106517

Epoch: 6| Step: 8
Training loss: 2.052116032322131
Validation loss: 2.3975137450333723

Epoch: 6| Step: 9
Training loss: 2.661516869505316
Validation loss: 2.4085697551381178

Epoch: 6| Step: 10
Training loss: 2.6225020921551527
Validation loss: 2.419150837361005

Epoch: 6| Step: 11
Training loss: 1.996199453880817
Validation loss: 2.4449390664975597

Epoch: 6| Step: 12
Training loss: 2.3751995605149703
Validation loss: 2.47189858113953

Epoch: 6| Step: 13
Training loss: 2.320492721391674
Validation loss: 2.5176904405829377

Epoch: 330| Step: 0
Training loss: 2.5871450134615013
Validation loss: 2.5725609623693546

Epoch: 6| Step: 1
Training loss: 2.3784184198412373
Validation loss: 2.6389206013467805

Epoch: 6| Step: 2
Training loss: 2.4238658966637914
Validation loss: 2.6599010336488322

Epoch: 6| Step: 3
Training loss: 2.585421692266711
Validation loss: 2.580058248367461

Epoch: 6| Step: 4
Training loss: 1.9580347225784833
Validation loss: 2.544464911695763

Epoch: 6| Step: 5
Training loss: 2.9388054726710258
Validation loss: 2.5142773561299783

Epoch: 6| Step: 6
Training loss: 2.0258830841161126
Validation loss: 2.466938898112968

Epoch: 6| Step: 7
Training loss: 2.525154120396732
Validation loss: 2.427253586900555

Epoch: 6| Step: 8
Training loss: 1.2633821842256936
Validation loss: 2.4191827105746353

Epoch: 6| Step: 9
Training loss: 2.6823861016004167
Validation loss: 2.380563577287063

Epoch: 6| Step: 10
Training loss: 2.502349131301777
Validation loss: 2.3783197490061214

Epoch: 6| Step: 11
Training loss: 1.9146271787430427
Validation loss: 2.395968488935551

Epoch: 6| Step: 12
Training loss: 2.011023895850115
Validation loss: 2.398870568730772

Epoch: 6| Step: 13
Training loss: 1.767546764116648
Validation loss: 2.390866745590247

Epoch: 331| Step: 0
Training loss: 2.097023070972962
Validation loss: 2.4041729941606245

Epoch: 6| Step: 1
Training loss: 2.384411584815936
Validation loss: 2.404785991506357

Epoch: 6| Step: 2
Training loss: 1.9316242090034876
Validation loss: 2.4059426705780727

Epoch: 6| Step: 3
Training loss: 1.6988428862091147
Validation loss: 2.438377019606237

Epoch: 6| Step: 4
Training loss: 2.111060140507513
Validation loss: 2.4239042663685617

Epoch: 6| Step: 5
Training loss: 2.535497704127436
Validation loss: 2.4505401635324877

Epoch: 6| Step: 6
Training loss: 2.7986573235730057
Validation loss: 2.460980537794779

Epoch: 6| Step: 7
Training loss: 2.040838761400964
Validation loss: 2.4384335575162646

Epoch: 6| Step: 8
Training loss: 1.9360804741307063
Validation loss: 2.449293285633811

Epoch: 6| Step: 9
Training loss: 2.3059951434650876
Validation loss: 2.4674971477729235

Epoch: 6| Step: 10
Training loss: 2.542875554827902
Validation loss: 2.494038800527795

Epoch: 6| Step: 11
Training loss: 2.3941211940520226
Validation loss: 2.5013959145893736

Epoch: 6| Step: 12
Training loss: 2.4917792580808995
Validation loss: 2.5518968371284507

Epoch: 6| Step: 13
Training loss: 1.914415661675472
Validation loss: 2.5472238687860993

Epoch: 332| Step: 0
Training loss: 2.0894506922643696
Validation loss: 2.5541098806776854

Epoch: 6| Step: 1
Training loss: 2.163988683660396
Validation loss: 2.5612898189201365

Epoch: 6| Step: 2
Training loss: 2.6174308094400147
Validation loss: 2.604390180942637

Epoch: 6| Step: 3
Training loss: 2.5377759285471173
Validation loss: 2.564938966986502

Epoch: 6| Step: 4
Training loss: 2.1175910593245453
Validation loss: 2.5059659570099444

Epoch: 6| Step: 5
Training loss: 2.331363141379923
Validation loss: 2.440560695519589

Epoch: 6| Step: 6
Training loss: 2.656933775013662
Validation loss: 2.448400786176327

Epoch: 6| Step: 7
Training loss: 2.15922595336428
Validation loss: 2.4423972367112268

Epoch: 6| Step: 8
Training loss: 1.5041175594749725
Validation loss: 2.433874740526444

Epoch: 6| Step: 9
Training loss: 2.3147872747972924
Validation loss: 2.4190246131063047

Epoch: 6| Step: 10
Training loss: 2.3835650146912823
Validation loss: 2.4049210295086483

Epoch: 6| Step: 11
Training loss: 2.3123881338744474
Validation loss: 2.3980372674388475

Epoch: 6| Step: 12
Training loss: 1.7825338856390747
Validation loss: 2.4045706829856934

Epoch: 6| Step: 13
Training loss: 2.6589182298933673
Validation loss: 2.4062098657046773

Epoch: 333| Step: 0
Training loss: 1.799112668142181
Validation loss: 2.4134481293219787

Epoch: 6| Step: 1
Training loss: 2.195638286269134
Validation loss: 2.4038847608092793

Epoch: 6| Step: 2
Training loss: 2.484571341187587
Validation loss: 2.4089102495355847

Epoch: 6| Step: 3
Training loss: 2.1796789681872673
Validation loss: 2.4435937402708143

Epoch: 6| Step: 4
Training loss: 2.790771900851409
Validation loss: 2.445518816501919

Epoch: 6| Step: 5
Training loss: 2.1399646492293214
Validation loss: 2.476467055291829

Epoch: 6| Step: 6
Training loss: 2.26331332430565
Validation loss: 2.447296182980024

Epoch: 6| Step: 7
Training loss: 2.2279830951631485
Validation loss: 2.438048242967289

Epoch: 6| Step: 8
Training loss: 1.5731012433955598
Validation loss: 2.4785636941735607

Epoch: 6| Step: 9
Training loss: 2.8553386611633447
Validation loss: 2.483183801383955

Epoch: 6| Step: 10
Training loss: 2.401729846452464
Validation loss: 2.490223773931321

Epoch: 6| Step: 11
Training loss: 2.3414314500320046
Validation loss: 2.4881446386058985

Epoch: 6| Step: 12
Training loss: 1.5271115333829535
Validation loss: 2.4754835921480685

Epoch: 6| Step: 13
Training loss: 2.223611046672404
Validation loss: 2.44284934038706

Epoch: 334| Step: 0
Training loss: 2.27683677722933
Validation loss: 2.458278883436513

Epoch: 6| Step: 1
Training loss: 2.3609486567639477
Validation loss: 2.4402897007866873

Epoch: 6| Step: 2
Training loss: 2.071023149700814
Validation loss: 2.4356015639827593

Epoch: 6| Step: 3
Training loss: 2.0649886866668328
Validation loss: 2.4253811483744196

Epoch: 6| Step: 4
Training loss: 2.353162556990656
Validation loss: 2.4420031402399194

Epoch: 6| Step: 5
Training loss: 2.220664152341893
Validation loss: 2.4366813833211634

Epoch: 6| Step: 6
Training loss: 2.337221131034983
Validation loss: 2.4627793255623924

Epoch: 6| Step: 7
Training loss: 2.3872479290735016
Validation loss: 2.4727119128885477

Epoch: 6| Step: 8
Training loss: 2.0767317382185917
Validation loss: 2.5235951504343417

Epoch: 6| Step: 9
Training loss: 1.9349523838108669
Validation loss: 2.5448480871664967

Epoch: 6| Step: 10
Training loss: 2.2017694726582935
Validation loss: 2.5545745891892304

Epoch: 6| Step: 11
Training loss: 2.0603635878197983
Validation loss: 2.5345001370269435

Epoch: 6| Step: 12
Training loss: 2.427740758394916
Validation loss: 2.4975928202661093

Epoch: 6| Step: 13
Training loss: 2.4403064905816345
Validation loss: 2.4540037179365757

Epoch: 335| Step: 0
Training loss: 1.750259584520238
Validation loss: 2.409977274546607

Epoch: 6| Step: 1
Training loss: 2.5782657469275323
Validation loss: 2.3715149547454617

Epoch: 6| Step: 2
Training loss: 1.8746977244545189
Validation loss: 2.3656386553424587

Epoch: 6| Step: 3
Training loss: 2.16692254193935
Validation loss: 2.343083722972815

Epoch: 6| Step: 4
Training loss: 2.3108046219430705
Validation loss: 2.368774082720413

Epoch: 6| Step: 5
Training loss: 2.118731059211983
Validation loss: 2.3976852842337277

Epoch: 6| Step: 6
Training loss: 2.68051392737586
Validation loss: 2.460950813316043

Epoch: 6| Step: 7
Training loss: 1.7433942370355477
Validation loss: 2.4958246989151074

Epoch: 6| Step: 8
Training loss: 2.1918295385183653
Validation loss: 2.5575023170304885

Epoch: 6| Step: 9
Training loss: 2.675062275099251
Validation loss: 2.657173649545987

Epoch: 6| Step: 10
Training loss: 1.9873559143812225
Validation loss: 2.6262215908304034

Epoch: 6| Step: 11
Training loss: 2.156181444930346
Validation loss: 2.5721079675673315

Epoch: 6| Step: 12
Training loss: 2.8066339990461975
Validation loss: 2.502772368108158

Epoch: 6| Step: 13
Training loss: 2.519209209827004
Validation loss: 2.420510140940081

Epoch: 336| Step: 0
Training loss: 2.7234734030024184
Validation loss: 2.395435642836681

Epoch: 6| Step: 1
Training loss: 2.32009342071283
Validation loss: 2.3603365760774913

Epoch: 6| Step: 2
Training loss: 2.628152770486501
Validation loss: 2.3619396513347293

Epoch: 6| Step: 3
Training loss: 2.540634842181409
Validation loss: 2.35793025345907

Epoch: 6| Step: 4
Training loss: 1.4790839409417595
Validation loss: 2.3612806652201543

Epoch: 6| Step: 5
Training loss: 1.5858839805855691
Validation loss: 2.3701348032096594

Epoch: 6| Step: 6
Training loss: 2.7741060552586583
Validation loss: 2.3620128704937495

Epoch: 6| Step: 7
Training loss: 1.9112913663390614
Validation loss: 2.3608120765304013

Epoch: 6| Step: 8
Training loss: 2.2697804194383693
Validation loss: 2.37614812770559

Epoch: 6| Step: 9
Training loss: 2.2391653927722635
Validation loss: 2.3969722717529636

Epoch: 6| Step: 10
Training loss: 2.0554583013856913
Validation loss: 2.452214632450008

Epoch: 6| Step: 11
Training loss: 2.1394470760809483
Validation loss: 2.4959846018371974

Epoch: 6| Step: 12
Training loss: 2.5593681735924685
Validation loss: 2.5196838449710115

Epoch: 6| Step: 13
Training loss: 2.3620488255725003
Validation loss: 2.5406541029528307

Epoch: 337| Step: 0
Training loss: 2.55316228570875
Validation loss: 2.545663777749679

Epoch: 6| Step: 1
Training loss: 2.0763700718985705
Validation loss: 2.4863855109641455

Epoch: 6| Step: 2
Training loss: 3.055593370916469
Validation loss: 2.4477563973566974

Epoch: 6| Step: 3
Training loss: 2.2262261387586695
Validation loss: 2.418324969450025

Epoch: 6| Step: 4
Training loss: 1.8081381699800743
Validation loss: 2.3976811656147103

Epoch: 6| Step: 5
Training loss: 2.28181429637784
Validation loss: 2.395422061184503

Epoch: 6| Step: 6
Training loss: 1.900639391276685
Validation loss: 2.3783245931778474

Epoch: 6| Step: 7
Training loss: 2.415792690837473
Validation loss: 2.392208246667694

Epoch: 6| Step: 8
Training loss: 2.0810973056992252
Validation loss: 2.4009223110913487

Epoch: 6| Step: 9
Training loss: 1.6690940188010417
Validation loss: 2.3990305158469933

Epoch: 6| Step: 10
Training loss: 2.2710184027708533
Validation loss: 2.4297232412729692

Epoch: 6| Step: 11
Training loss: 2.1665102339783915
Validation loss: 2.4489175238018723

Epoch: 6| Step: 12
Training loss: 2.5004132882872887
Validation loss: 2.4818852582706867

Epoch: 6| Step: 13
Training loss: 1.248039758987318
Validation loss: 2.4849179376888992

Epoch: 338| Step: 0
Training loss: 2.4020417310470794
Validation loss: 2.478156024334323

Epoch: 6| Step: 1
Training loss: 2.5202983782491457
Validation loss: 2.4755565281946077

Epoch: 6| Step: 2
Training loss: 2.3996809429442254
Validation loss: 2.4929171106992287

Epoch: 6| Step: 3
Training loss: 2.187885359471882
Validation loss: 2.479729197101849

Epoch: 6| Step: 4
Training loss: 2.584634965693181
Validation loss: 2.5179097520990834

Epoch: 6| Step: 5
Training loss: 2.3266478082863573
Validation loss: 2.5193400674298974

Epoch: 6| Step: 6
Training loss: 2.0093677004478367
Validation loss: 2.5274351829073343

Epoch: 6| Step: 7
Training loss: 2.842292495977574
Validation loss: 2.5100955859073726

Epoch: 6| Step: 8
Training loss: 1.5786875109413352
Validation loss: 2.4247361963962093

Epoch: 6| Step: 9
Training loss: 1.8719407237237444
Validation loss: 2.380186702884623

Epoch: 6| Step: 10
Training loss: 2.106754964635913
Validation loss: 2.3498906613905715

Epoch: 6| Step: 11
Training loss: 1.872259744324135
Validation loss: 2.3357450229168055

Epoch: 6| Step: 12
Training loss: 2.1464654923390327
Validation loss: 2.3463472846955957

Epoch: 6| Step: 13
Training loss: 2.382626985926446
Validation loss: 2.3376951854637102

Epoch: 339| Step: 0
Training loss: 1.6322601698332058
Validation loss: 2.3341579657426568

Epoch: 6| Step: 1
Training loss: 1.8870284495672869
Validation loss: 2.3507035752386494

Epoch: 6| Step: 2
Training loss: 2.2852590162856576
Validation loss: 2.3743596090630703

Epoch: 6| Step: 3
Training loss: 2.4394583049196905
Validation loss: 2.44751596376321

Epoch: 6| Step: 4
Training loss: 2.0726917342891644
Validation loss: 2.537938111691419

Epoch: 6| Step: 5
Training loss: 2.5734947471527985
Validation loss: 2.5576511320302564

Epoch: 6| Step: 6
Training loss: 2.048533924897286
Validation loss: 2.5324024011429396

Epoch: 6| Step: 7
Training loss: 2.118691898775864
Validation loss: 2.537420778822585

Epoch: 6| Step: 8
Training loss: 2.728635333417765
Validation loss: 2.496147798501913

Epoch: 6| Step: 9
Training loss: 2.0287215708810815
Validation loss: 2.4746118546118727

Epoch: 6| Step: 10
Training loss: 2.7168704145667935
Validation loss: 2.4305757744607863

Epoch: 6| Step: 11
Training loss: 2.130285533696862
Validation loss: 2.3940417099754505

Epoch: 6| Step: 12
Training loss: 2.118812078506123
Validation loss: 2.3498937499010237

Epoch: 6| Step: 13
Training loss: 2.4395051191666783
Validation loss: 2.3530234514816972

Epoch: 340| Step: 0
Training loss: 2.583414281581791
Validation loss: 2.340512564972423

Epoch: 6| Step: 1
Training loss: 2.169765518282423
Validation loss: 2.338510404887094

Epoch: 6| Step: 2
Training loss: 1.8925397650548437
Validation loss: 2.3341692552949285

Epoch: 6| Step: 3
Training loss: 2.0091420087510303
Validation loss: 2.352676218898987

Epoch: 6| Step: 4
Training loss: 2.6872288766765906
Validation loss: 2.3472594120504646

Epoch: 6| Step: 5
Training loss: 2.3788938224480396
Validation loss: 2.3868096398781855

Epoch: 6| Step: 6
Training loss: 2.2847111195066145
Validation loss: 2.4035094387599423

Epoch: 6| Step: 7
Training loss: 1.9885558292876384
Validation loss: 2.4253260925734783

Epoch: 6| Step: 8
Training loss: 1.7966445111599572
Validation loss: 2.428351640794934

Epoch: 6| Step: 9
Training loss: 2.3290422923865814
Validation loss: 2.475795307283317

Epoch: 6| Step: 10
Training loss: 2.158413119909511
Validation loss: 2.500471443926506

Epoch: 6| Step: 11
Training loss: 1.994713233089705
Validation loss: 2.495937364787574

Epoch: 6| Step: 12
Training loss: 2.6005109431662357
Validation loss: 2.5020138679043273

Epoch: 6| Step: 13
Training loss: 1.2304409932230191
Validation loss: 2.461862368223447

Epoch: 341| Step: 0
Training loss: 2.3973563177274984
Validation loss: 2.4636741130306747

Epoch: 6| Step: 1
Training loss: 2.6861247602675062
Validation loss: 2.4486593871721607

Epoch: 6| Step: 2
Training loss: 2.288489156012652
Validation loss: 2.4177148046720305

Epoch: 6| Step: 3
Training loss: 2.356603548354846
Validation loss: 2.388141536481326

Epoch: 6| Step: 4
Training loss: 1.901773480862749
Validation loss: 2.383071846030481

Epoch: 6| Step: 5
Training loss: 2.163309014315444
Validation loss: 2.4179822882376767

Epoch: 6| Step: 6
Training loss: 1.91626609541671
Validation loss: 2.398851523592731

Epoch: 6| Step: 7
Training loss: 1.5158571675030956
Validation loss: 2.3683879782041566

Epoch: 6| Step: 8
Training loss: 2.1394801733101674
Validation loss: 2.3834229777789613

Epoch: 6| Step: 9
Training loss: 2.4071530715835627
Validation loss: 2.3902831568079685

Epoch: 6| Step: 10
Training loss: 2.1970023713826166
Validation loss: 2.404491974006512

Epoch: 6| Step: 11
Training loss: 2.427391905808781
Validation loss: 2.3877263375969364

Epoch: 6| Step: 12
Training loss: 1.8843846385702978
Validation loss: 2.437431907701882

Epoch: 6| Step: 13
Training loss: 1.945757834081405
Validation loss: 2.4467038814250066

Epoch: 342| Step: 0
Training loss: 2.5087074275412693
Validation loss: 2.46385858259419

Epoch: 6| Step: 1
Training loss: 1.6507357084218048
Validation loss: 2.448254041042059

Epoch: 6| Step: 2
Training loss: 2.210115637192032
Validation loss: 2.4478484822143525

Epoch: 6| Step: 3
Training loss: 2.068059076369259
Validation loss: 2.4597224754390696

Epoch: 6| Step: 4
Training loss: 1.8898551571562057
Validation loss: 2.4981726746453274

Epoch: 6| Step: 5
Training loss: 2.847825033578257
Validation loss: 2.4573953064952962

Epoch: 6| Step: 6
Training loss: 2.0102746020575126
Validation loss: 2.476897609629929

Epoch: 6| Step: 7
Training loss: 2.1749982811931967
Validation loss: 2.460263191551662

Epoch: 6| Step: 8
Training loss: 2.6365298507276713
Validation loss: 2.3922642907616942

Epoch: 6| Step: 9
Training loss: 1.8160644209606391
Validation loss: 2.37275347543155

Epoch: 6| Step: 10
Training loss: 1.7232331501502085
Validation loss: 2.37857543319777

Epoch: 6| Step: 11
Training loss: 2.5271752609384874
Validation loss: 2.3527108516248805

Epoch: 6| Step: 12
Training loss: 2.044157947574044
Validation loss: 2.3779060867451314

Epoch: 6| Step: 13
Training loss: 1.9976744244061677
Validation loss: 2.363822232496481

Epoch: 343| Step: 0
Training loss: 2.4320082788702946
Validation loss: 2.3949033482900175

Epoch: 6| Step: 1
Training loss: 2.232635033978077
Validation loss: 2.370085639844552

Epoch: 6| Step: 2
Training loss: 1.874001936717137
Validation loss: 2.374818973086339

Epoch: 6| Step: 3
Training loss: 2.342958952605651
Validation loss: 2.381610173114735

Epoch: 6| Step: 4
Training loss: 2.2275306069340286
Validation loss: 2.4047687660842647

Epoch: 6| Step: 5
Training loss: 2.4677939193352643
Validation loss: 2.42949998423015

Epoch: 6| Step: 6
Training loss: 1.9578068275704374
Validation loss: 2.4085520458691163

Epoch: 6| Step: 7
Training loss: 2.036944813358589
Validation loss: 2.4498465661796374

Epoch: 6| Step: 8
Training loss: 2.3648377896382806
Validation loss: 2.429189888964124

Epoch: 6| Step: 9
Training loss: 1.9121197241404686
Validation loss: 2.427530543161151

Epoch: 6| Step: 10
Training loss: 2.223724591183468
Validation loss: 2.4252653126296626

Epoch: 6| Step: 11
Training loss: 1.7150331709742859
Validation loss: 2.422044474070354

Epoch: 6| Step: 12
Training loss: 2.066330560404913
Validation loss: 2.4098004624170857

Epoch: 6| Step: 13
Training loss: 2.257598021988844
Validation loss: 2.3801555127297305

Epoch: 344| Step: 0
Training loss: 2.357669643475547
Validation loss: 2.3672524958417536

Epoch: 6| Step: 1
Training loss: 2.075961370553419
Validation loss: 2.361636952890004

Epoch: 6| Step: 2
Training loss: 2.4806211890289642
Validation loss: 2.35375900470464

Epoch: 6| Step: 3
Training loss: 1.4835086101028836
Validation loss: 2.380777137338327

Epoch: 6| Step: 4
Training loss: 2.124593134805899
Validation loss: 2.3815889683927076

Epoch: 6| Step: 5
Training loss: 2.56188138612471
Validation loss: 2.4048046932839577

Epoch: 6| Step: 6
Training loss: 1.8980811769754284
Validation loss: 2.425689222588155

Epoch: 6| Step: 7
Training loss: 2.163224922347824
Validation loss: 2.4478053978578815

Epoch: 6| Step: 8
Training loss: 2.3322962318047478
Validation loss: 2.464669631973976

Epoch: 6| Step: 9
Training loss: 1.9427756808336927
Validation loss: 2.5163530934131653

Epoch: 6| Step: 10
Training loss: 2.084147052797164
Validation loss: 2.4783731853727025

Epoch: 6| Step: 11
Training loss: 1.9421837706157943
Validation loss: 2.46101793508343

Epoch: 6| Step: 12
Training loss: 2.2068561315688693
Validation loss: 2.4582197786373445

Epoch: 6| Step: 13
Training loss: 2.7665107300104035
Validation loss: 2.417459599343068

Epoch: 345| Step: 0
Training loss: 1.9403651802233752
Validation loss: 2.3990818066942894

Epoch: 6| Step: 1
Training loss: 1.8713330969901503
Validation loss: 2.3710831801072176

Epoch: 6| Step: 2
Training loss: 2.0635335240082266
Validation loss: 2.3785297155012146

Epoch: 6| Step: 3
Training loss: 2.2880192485213064
Validation loss: 2.3754179618599047

Epoch: 6| Step: 4
Training loss: 2.118257371914625
Validation loss: 2.3836932209696955

Epoch: 6| Step: 5
Training loss: 1.9930625639233628
Validation loss: 2.4160607575195043

Epoch: 6| Step: 6
Training loss: 1.8465610347011845
Validation loss: 2.4788377684481038

Epoch: 6| Step: 7
Training loss: 2.150576882260588
Validation loss: 2.4703673079104176

Epoch: 6| Step: 8
Training loss: 2.5878867555985225
Validation loss: 2.479376438566175

Epoch: 6| Step: 9
Training loss: 2.0466198944231278
Validation loss: 2.4586353081771968

Epoch: 6| Step: 10
Training loss: 2.6333370421983058
Validation loss: 2.438295225720224

Epoch: 6| Step: 11
Training loss: 2.2524600885138675
Validation loss: 2.4362095513526403

Epoch: 6| Step: 12
Training loss: 2.3583061373954406
Validation loss: 2.406048740066799

Epoch: 6| Step: 13
Training loss: 1.836506272539726
Validation loss: 2.4270741552624497

Epoch: 346| Step: 0
Training loss: 1.7567728995039509
Validation loss: 2.4192581949107326

Epoch: 6| Step: 1
Training loss: 2.385237863383229
Validation loss: 2.424031576501311

Epoch: 6| Step: 2
Training loss: 1.9021269813813562
Validation loss: 2.4334531308986507

Epoch: 6| Step: 3
Training loss: 1.4146764276103656
Validation loss: 2.458272727426419

Epoch: 6| Step: 4
Training loss: 2.204612824752176
Validation loss: 2.5102630399389287

Epoch: 6| Step: 5
Training loss: 2.4181760042815545
Validation loss: 2.498182442058171

Epoch: 6| Step: 6
Training loss: 1.962522557608838
Validation loss: 2.432759818149756

Epoch: 6| Step: 7
Training loss: 2.1311337078506605
Validation loss: 2.3891813538645477

Epoch: 6| Step: 8
Training loss: 1.783569632528817
Validation loss: 2.371687588544265

Epoch: 6| Step: 9
Training loss: 2.3341022541492706
Validation loss: 2.3705709963394836

Epoch: 6| Step: 10
Training loss: 2.4846511783279173
Validation loss: 2.3549329675893858

Epoch: 6| Step: 11
Training loss: 2.107055971695789
Validation loss: 2.3672064782424966

Epoch: 6| Step: 12
Training loss: 2.413132176560226
Validation loss: 2.3867760701344793

Epoch: 6| Step: 13
Training loss: 2.691450630785436
Validation loss: 2.3939193535020005

Epoch: 347| Step: 0
Training loss: 2.102667649124745
Validation loss: 2.420673255597327

Epoch: 6| Step: 1
Training loss: 2.591406717378001
Validation loss: 2.420786928299694

Epoch: 6| Step: 2
Training loss: 2.299660168296272
Validation loss: 2.4511033561113638

Epoch: 6| Step: 3
Training loss: 1.9608965865650627
Validation loss: 2.4709769822911256

Epoch: 6| Step: 4
Training loss: 1.820057732431459
Validation loss: 2.494701485514601

Epoch: 6| Step: 5
Training loss: 1.7294697170424083
Validation loss: 2.513731863554738

Epoch: 6| Step: 6
Training loss: 2.2012961080943825
Validation loss: 2.531165608354257

Epoch: 6| Step: 7
Training loss: 2.3626482155138957
Validation loss: 2.474282201909338

Epoch: 6| Step: 8
Training loss: 2.120258426749818
Validation loss: 2.402169299117357

Epoch: 6| Step: 9
Training loss: 2.3252812369282445
Validation loss: 2.3685415580950466

Epoch: 6| Step: 10
Training loss: 1.9988989183250743
Validation loss: 2.3537251988437577

Epoch: 6| Step: 11
Training loss: 2.526214866337248
Validation loss: 2.3500496494927954

Epoch: 6| Step: 12
Training loss: 1.7330520670663896
Validation loss: 2.3141859859998792

Epoch: 6| Step: 13
Training loss: 1.7544328540467202
Validation loss: 2.3331146265917897

Epoch: 348| Step: 0
Training loss: 1.6803801771698688
Validation loss: 2.3593184767174957

Epoch: 6| Step: 1
Training loss: 1.6762760027775239
Validation loss: 2.394460318023207

Epoch: 6| Step: 2
Training loss: 2.3489279960032223
Validation loss: 2.4371881603664947

Epoch: 6| Step: 3
Training loss: 1.960559094153992
Validation loss: 2.492085500054487

Epoch: 6| Step: 4
Training loss: 2.2742861707280255
Validation loss: 2.574422905483053

Epoch: 6| Step: 5
Training loss: 2.7082103016613948
Validation loss: 2.6433863261478545

Epoch: 6| Step: 6
Training loss: 2.1502481494794035
Validation loss: 2.514612274148829

Epoch: 6| Step: 7
Training loss: 1.7271471371463003
Validation loss: 2.429082126047251

Epoch: 6| Step: 8
Training loss: 2.6525681952681435
Validation loss: 2.3576584784149768

Epoch: 6| Step: 9
Training loss: 1.8036204564770102
Validation loss: 2.3329741685701024

Epoch: 6| Step: 10
Training loss: 2.570314355171253
Validation loss: 2.30244383139757

Epoch: 6| Step: 11
Training loss: 1.7789002027647545
Validation loss: 2.3156841520560776

Epoch: 6| Step: 12
Training loss: 2.3630829026397984
Validation loss: 2.3179313988316137

Epoch: 6| Step: 13
Training loss: 2.1184947352394587
Validation loss: 2.316018952217636

Epoch: 349| Step: 0
Training loss: 2.2726574375520596
Validation loss: 2.308654203585166

Epoch: 6| Step: 1
Training loss: 1.7647273389596427
Validation loss: 2.324631728345916

Epoch: 6| Step: 2
Training loss: 1.7806099528101687
Validation loss: 2.3327169226728897

Epoch: 6| Step: 3
Training loss: 1.7494015351545715
Validation loss: 2.4474691356737495

Epoch: 6| Step: 4
Training loss: 2.17024268414974
Validation loss: 2.5508924805264197

Epoch: 6| Step: 5
Training loss: 2.7694723663742074
Validation loss: 2.634536611463872

Epoch: 6| Step: 6
Training loss: 2.000951421457786
Validation loss: 2.7005978569933253

Epoch: 6| Step: 7
Training loss: 2.096086251966649
Validation loss: 2.7223065208852906

Epoch: 6| Step: 8
Training loss: 2.319873293014532
Validation loss: 2.7306966315509933

Epoch: 6| Step: 9
Training loss: 2.183250659610112
Validation loss: 2.5922304405254653

Epoch: 6| Step: 10
Training loss: 2.334903245673468
Validation loss: 2.459842655153119

Epoch: 6| Step: 11
Training loss: 2.548303496055329
Validation loss: 2.3610490698709135

Epoch: 6| Step: 12
Training loss: 2.076698674199714
Validation loss: 2.323159281912864

Epoch: 6| Step: 13
Training loss: 2.579689984288628
Validation loss: 2.311266818905041

Epoch: 350| Step: 0
Training loss: 1.9785864799442465
Validation loss: 2.2943680965772155

Epoch: 6| Step: 1
Training loss: 2.5750926362198165
Validation loss: 2.30916096202494

Epoch: 6| Step: 2
Training loss: 2.540553573599098
Validation loss: 2.310204570341669

Epoch: 6| Step: 3
Training loss: 2.1347557968094897
Validation loss: 2.3243851863107357

Epoch: 6| Step: 4
Training loss: 1.7614622754083515
Validation loss: 2.38842350037212

Epoch: 6| Step: 5
Training loss: 2.080183801966398
Validation loss: 2.4256186342027304

Epoch: 6| Step: 6
Training loss: 2.1954595441885183
Validation loss: 2.5109609674956377

Epoch: 6| Step: 7
Training loss: 2.001404507526298
Validation loss: 2.6223865611557473

Epoch: 6| Step: 8
Training loss: 1.8943213277706292
Validation loss: 2.6486401374074533

Epoch: 6| Step: 9
Training loss: 2.8982996329449966
Validation loss: 2.729853681600615

Epoch: 6| Step: 10
Training loss: 2.2887312613636324
Validation loss: 2.6205707817700215

Epoch: 6| Step: 11
Training loss: 2.1340854744422355
Validation loss: 2.452999105750748

Epoch: 6| Step: 12
Training loss: 1.7920819917467008
Validation loss: 2.353003343414476

Epoch: 6| Step: 13
Training loss: 2.215833654653529
Validation loss: 2.304900955206969

Epoch: 351| Step: 0
Training loss: 2.028122592448494
Validation loss: 2.2914846293918423

Epoch: 6| Step: 1
Training loss: 2.5791093276577537
Validation loss: 2.314030280358404

Epoch: 6| Step: 2
Training loss: 2.3392773485606124
Validation loss: 2.308242083404007

Epoch: 6| Step: 3
Training loss: 2.5173960073105883
Validation loss: 2.3023000719165054

Epoch: 6| Step: 4
Training loss: 2.0169151967443137
Validation loss: 2.3324750678329966

Epoch: 6| Step: 5
Training loss: 2.0404671109911026
Validation loss: 2.3642884782972047

Epoch: 6| Step: 6
Training loss: 2.4218179019226946
Validation loss: 2.388231399132167

Epoch: 6| Step: 7
Training loss: 2.3193821952623925
Validation loss: 2.416415169274063

Epoch: 6| Step: 8
Training loss: 1.5707945581940765
Validation loss: 2.4524218683699686

Epoch: 6| Step: 9
Training loss: 2.009696581129989
Validation loss: 2.5029091316228445

Epoch: 6| Step: 10
Training loss: 1.6884680196745643
Validation loss: 2.5427754429831944

Epoch: 6| Step: 11
Training loss: 2.29760689006293
Validation loss: 2.5856583070345254

Epoch: 6| Step: 12
Training loss: 2.192137026868501
Validation loss: 2.5876050612996964

Epoch: 6| Step: 13
Training loss: 2.1065873552233167
Validation loss: 2.5166953292688956

Epoch: 352| Step: 0
Training loss: 2.080084772950057
Validation loss: 2.4869522046018893

Epoch: 6| Step: 1
Training loss: 1.3902944965015733
Validation loss: 2.4147994851935266

Epoch: 6| Step: 2
Training loss: 2.3282744084490594
Validation loss: 2.3751770227733107

Epoch: 6| Step: 3
Training loss: 1.8671336146284465
Validation loss: 2.35920665183552

Epoch: 6| Step: 4
Training loss: 2.0944670403046124
Validation loss: 2.328332007978387

Epoch: 6| Step: 5
Training loss: 2.3805701539363424
Validation loss: 2.3249744786354647

Epoch: 6| Step: 6
Training loss: 1.7451871357344204
Validation loss: 2.332203656043353

Epoch: 6| Step: 7
Training loss: 3.0372330913306964
Validation loss: 2.3365934990523782

Epoch: 6| Step: 8
Training loss: 1.8449125988735346
Validation loss: 2.336482789218741

Epoch: 6| Step: 9
Training loss: 2.096775886023811
Validation loss: 2.361348353255118

Epoch: 6| Step: 10
Training loss: 1.796328984105521
Validation loss: 2.3913627203131314

Epoch: 6| Step: 11
Training loss: 2.2000277777565427
Validation loss: 2.4333177071981433

Epoch: 6| Step: 12
Training loss: 2.1716481920550925
Validation loss: 2.502622661262085

Epoch: 6| Step: 13
Training loss: 2.968674508189015
Validation loss: 2.5214875085254773

Epoch: 353| Step: 0
Training loss: 2.271397150255911
Validation loss: 2.517742163125952

Epoch: 6| Step: 1
Training loss: 1.908565303357838
Validation loss: 2.5268312719406314

Epoch: 6| Step: 2
Training loss: 1.6919384971289637
Validation loss: 2.5346941702288697

Epoch: 6| Step: 3
Training loss: 2.15403600723221
Validation loss: 2.5106105294728143

Epoch: 6| Step: 4
Training loss: 2.152713473873879
Validation loss: 2.5293500224376797

Epoch: 6| Step: 5
Training loss: 2.2117218675123187
Validation loss: 2.4907341352222705

Epoch: 6| Step: 6
Training loss: 1.9643828380402857
Validation loss: 2.415615967944844

Epoch: 6| Step: 7
Training loss: 2.49491900050719
Validation loss: 2.3694356837346695

Epoch: 6| Step: 8
Training loss: 1.6181591266379534
Validation loss: 2.3366039199512074

Epoch: 6| Step: 9
Training loss: 1.858196494134953
Validation loss: 2.302581849691141

Epoch: 6| Step: 10
Training loss: 1.9475432937373807
Validation loss: 2.306943875322121

Epoch: 6| Step: 11
Training loss: 2.6288859350998144
Validation loss: 2.315790783256488

Epoch: 6| Step: 12
Training loss: 2.2272229737579496
Validation loss: 2.3195801011964163

Epoch: 6| Step: 13
Training loss: 2.6595167828249253
Validation loss: 2.330073337859284

Epoch: 354| Step: 0
Training loss: 2.144155000293403
Validation loss: 2.3487400609901945

Epoch: 6| Step: 1
Training loss: 2.4526662215308224
Validation loss: 2.397101619707442

Epoch: 6| Step: 2
Training loss: 2.083342348715031
Validation loss: 2.4353916451528925

Epoch: 6| Step: 3
Training loss: 2.204725617444895
Validation loss: 2.508715302267319

Epoch: 6| Step: 4
Training loss: 2.172155897239616
Validation loss: 2.514183837713325

Epoch: 6| Step: 5
Training loss: 1.319289493943367
Validation loss: 2.5243162794449066

Epoch: 6| Step: 6
Training loss: 2.743010916259494
Validation loss: 2.5186565122377145

Epoch: 6| Step: 7
Training loss: 1.8902009851069068
Validation loss: 2.534719781279296

Epoch: 6| Step: 8
Training loss: 1.4431873265450061
Validation loss: 2.5112931335818853

Epoch: 6| Step: 9
Training loss: 2.1853727624178383
Validation loss: 2.5238554969717493

Epoch: 6| Step: 10
Training loss: 2.1423043673389026
Validation loss: 2.443476110348101

Epoch: 6| Step: 11
Training loss: 1.7526078547702961
Validation loss: 2.401841408930186

Epoch: 6| Step: 12
Training loss: 2.1405436924995276
Validation loss: 2.3575153906775275

Epoch: 6| Step: 13
Training loss: 2.3099164191313943
Validation loss: 2.344500288558797

Epoch: 355| Step: 0
Training loss: 2.334223293701178
Validation loss: 2.3394837927138985

Epoch: 6| Step: 1
Training loss: 1.435686211084441
Validation loss: 2.330011997553782

Epoch: 6| Step: 2
Training loss: 2.368765327182592
Validation loss: 2.3280498082038474

Epoch: 6| Step: 3
Training loss: 2.580602114745256
Validation loss: 2.345353360860729

Epoch: 6| Step: 4
Training loss: 1.4944718536044164
Validation loss: 2.3550584289077574

Epoch: 6| Step: 5
Training loss: 1.4517594350669494
Validation loss: 2.369336325031983

Epoch: 6| Step: 6
Training loss: 2.6522563757009405
Validation loss: 2.389264610759146

Epoch: 6| Step: 7
Training loss: 2.291950578153411
Validation loss: 2.4322990613588127

Epoch: 6| Step: 8
Training loss: 2.322861834735653
Validation loss: 2.4453009655884297

Epoch: 6| Step: 9
Training loss: 1.9723667045586597
Validation loss: 2.4550726971406505

Epoch: 6| Step: 10
Training loss: 2.129894790021056
Validation loss: 2.408843255166592

Epoch: 6| Step: 11
Training loss: 2.075805402047405
Validation loss: 2.427218250755257

Epoch: 6| Step: 12
Training loss: 1.6069079999528597
Validation loss: 2.4508520145370043

Epoch: 6| Step: 13
Training loss: 1.9676992246202587
Validation loss: 2.4463807320685613

Epoch: 356| Step: 0
Training loss: 2.398446943531643
Validation loss: 2.4488142465571014

Epoch: 6| Step: 1
Training loss: 1.6155787773087105
Validation loss: 2.4539682540385948

Epoch: 6| Step: 2
Training loss: 2.0947867716070188
Validation loss: 2.452411677748615

Epoch: 6| Step: 3
Training loss: 1.9328673568502435
Validation loss: 2.44405006694141

Epoch: 6| Step: 4
Training loss: 1.4995604506846558
Validation loss: 2.4253122084544585

Epoch: 6| Step: 5
Training loss: 1.9358047944799452
Validation loss: 2.4241816126827933

Epoch: 6| Step: 6
Training loss: 1.7178114669433064
Validation loss: 2.4199130555635535

Epoch: 6| Step: 7
Training loss: 2.7083613663225186
Validation loss: 2.4087860184696415

Epoch: 6| Step: 8
Training loss: 1.880548342520803
Validation loss: 2.441660071651102

Epoch: 6| Step: 9
Training loss: 2.1804554451263507
Validation loss: 2.4477031467150945

Epoch: 6| Step: 10
Training loss: 2.7381823381743304
Validation loss: 2.4350764750423086

Epoch: 6| Step: 11
Training loss: 1.6306694605458474
Validation loss: 2.405893959752243

Epoch: 6| Step: 12
Training loss: 2.0176600156193687
Validation loss: 2.3751101325276185

Epoch: 6| Step: 13
Training loss: 2.335686405427122
Validation loss: 2.3410879909545956

Epoch: 357| Step: 0
Training loss: 2.671098384312026
Validation loss: 2.3315414398296586

Epoch: 6| Step: 1
Training loss: 2.0932261252841906
Validation loss: 2.334674137573724

Epoch: 6| Step: 2
Training loss: 2.1830713401247834
Validation loss: 2.3167663973779353

Epoch: 6| Step: 3
Training loss: 2.0384939285273984
Validation loss: 2.3283734130909637

Epoch: 6| Step: 4
Training loss: 1.8527524319500108
Validation loss: 2.314797516989482

Epoch: 6| Step: 5
Training loss: 2.1982074804290335
Validation loss: 2.3440799057092256

Epoch: 6| Step: 6
Training loss: 2.1915539914407542
Validation loss: 2.3808877359058296

Epoch: 6| Step: 7
Training loss: 1.9424015924572897
Validation loss: 2.426786246547577

Epoch: 6| Step: 8
Training loss: 1.7738977582814455
Validation loss: 2.508104185409157

Epoch: 6| Step: 9
Training loss: 1.9179348136556604
Validation loss: 2.5669960838431907

Epoch: 6| Step: 10
Training loss: 2.266902379327328
Validation loss: 2.5791860391423804

Epoch: 6| Step: 11
Training loss: 1.894894028370363
Validation loss: 2.6287065775212315

Epoch: 6| Step: 12
Training loss: 1.540674749658285
Validation loss: 2.5769427699110588

Epoch: 6| Step: 13
Training loss: 2.220952512347635
Validation loss: 2.491081186401282

Epoch: 358| Step: 0
Training loss: 1.7528811307254606
Validation loss: 2.4241138664739177

Epoch: 6| Step: 1
Training loss: 2.335020772118652
Validation loss: 2.363003420382793

Epoch: 6| Step: 2
Training loss: 1.8079864602890086
Validation loss: 2.3414541330303837

Epoch: 6| Step: 3
Training loss: 2.044256967550176
Validation loss: 2.315523620328538

Epoch: 6| Step: 4
Training loss: 1.4940400931252558
Validation loss: 2.3188590308445822

Epoch: 6| Step: 5
Training loss: 2.422547081016427
Validation loss: 2.2980585163835907

Epoch: 6| Step: 6
Training loss: 2.135969682742642
Validation loss: 2.320357483187864

Epoch: 6| Step: 7
Training loss: 2.0879342455540413
Validation loss: 2.3446433658306916

Epoch: 6| Step: 8
Training loss: 2.118257371914625
Validation loss: 2.3652370305152832

Epoch: 6| Step: 9
Training loss: 2.0394259892506774
Validation loss: 2.372012393821022

Epoch: 6| Step: 10
Training loss: 2.2263314110479704
Validation loss: 2.4223584378339904

Epoch: 6| Step: 11
Training loss: 2.4450799508469934
Validation loss: 2.442291182865823

Epoch: 6| Step: 12
Training loss: 1.6185510756170483
Validation loss: 2.42997025149402

Epoch: 6| Step: 13
Training loss: 2.1740632594081073
Validation loss: 2.3917656202262907

Epoch: 359| Step: 0
Training loss: 1.7373631485210186
Validation loss: 2.374166626323943

Epoch: 6| Step: 1
Training loss: 2.090698523718242
Validation loss: 2.344634285919316

Epoch: 6| Step: 2
Training loss: 1.6994186809912388
Validation loss: 2.335013712552244

Epoch: 6| Step: 3
Training loss: 2.188998880489755
Validation loss: 2.319353791889753

Epoch: 6| Step: 4
Training loss: 1.6159914173049381
Validation loss: 2.320271220633632

Epoch: 6| Step: 5
Training loss: 1.83353809455888
Validation loss: 2.3313052868431097

Epoch: 6| Step: 6
Training loss: 2.175012969932032
Validation loss: 2.3308130363424655

Epoch: 6| Step: 7
Training loss: 1.8802716217238298
Validation loss: 2.3403978117888413

Epoch: 6| Step: 8
Training loss: 1.7878509817131012
Validation loss: 2.3683789538749953

Epoch: 6| Step: 9
Training loss: 2.4631957334802985
Validation loss: 2.418613986611192

Epoch: 6| Step: 10
Training loss: 2.3552426155313886
Validation loss: 2.4654547159364837

Epoch: 6| Step: 11
Training loss: 2.345752623430444
Validation loss: 2.500973423777043

Epoch: 6| Step: 12
Training loss: 2.2317589871163745
Validation loss: 2.4832409792047128

Epoch: 6| Step: 13
Training loss: 2.129441612193777
Validation loss: 2.484437042553387

Epoch: 360| Step: 0
Training loss: 2.2277569695587265
Validation loss: 2.4395574022634157

Epoch: 6| Step: 1
Training loss: 1.8252603632569129
Validation loss: 2.402519404668108

Epoch: 6| Step: 2
Training loss: 1.5246391838848257
Validation loss: 2.3461146380882623

Epoch: 6| Step: 3
Training loss: 1.2722763665424854
Validation loss: 2.3216211329931333

Epoch: 6| Step: 4
Training loss: 2.4045468532783043
Validation loss: 2.3102599782510795

Epoch: 6| Step: 5
Training loss: 2.2810641696437903
Validation loss: 2.297585035032739

Epoch: 6| Step: 6
Training loss: 2.2051159675533816
Validation loss: 2.3262571980080575

Epoch: 6| Step: 7
Training loss: 2.3058371569793987
Validation loss: 2.3172741558749186

Epoch: 6| Step: 8
Training loss: 2.4697997360280013
Validation loss: 2.337786781618112

Epoch: 6| Step: 9
Training loss: 1.6645799289074945
Validation loss: 2.3434229982928425

Epoch: 6| Step: 10
Training loss: 2.289621955284347
Validation loss: 2.383418502687055

Epoch: 6| Step: 11
Training loss: 2.0344170163176867
Validation loss: 2.451362105490733

Epoch: 6| Step: 12
Training loss: 1.5345287642183514
Validation loss: 2.514541963528764

Epoch: 6| Step: 13
Training loss: 2.466440206734393
Validation loss: 2.495739006667551

Epoch: 361| Step: 0
Training loss: 2.6067956293827756
Validation loss: 2.4548472894110054

Epoch: 6| Step: 1
Training loss: 1.8456957620140835
Validation loss: 2.406513791486663

Epoch: 6| Step: 2
Training loss: 2.269250533951649
Validation loss: 2.363853413125448

Epoch: 6| Step: 3
Training loss: 1.6985779705056836
Validation loss: 2.3270566385323885

Epoch: 6| Step: 4
Training loss: 1.4969220371063285
Validation loss: 2.299680072804809

Epoch: 6| Step: 5
Training loss: 1.8796990322098572
Validation loss: 2.3059575589517345

Epoch: 6| Step: 6
Training loss: 1.9392826739164193
Validation loss: 2.302229060438855

Epoch: 6| Step: 7
Training loss: 2.5765313048871494
Validation loss: 2.285291929014782

Epoch: 6| Step: 8
Training loss: 2.543225253480589
Validation loss: 2.30622263192753

Epoch: 6| Step: 9
Training loss: 2.016005251007205
Validation loss: 2.318921614715544

Epoch: 6| Step: 10
Training loss: 1.6736740700191357
Validation loss: 2.370179738576552

Epoch: 6| Step: 11
Training loss: 2.2558004000002114
Validation loss: 2.4181944286397474

Epoch: 6| Step: 12
Training loss: 1.286783782112344
Validation loss: 2.4640473259161912

Epoch: 6| Step: 13
Training loss: 1.7676361243074161
Validation loss: 2.528161996426506

Epoch: 362| Step: 0
Training loss: 2.4878620171815045
Validation loss: 2.576144757409098

Epoch: 6| Step: 1
Training loss: 1.8562579915809072
Validation loss: 2.5083942895553255

Epoch: 6| Step: 2
Training loss: 2.200226954111136
Validation loss: 2.4467402521656587

Epoch: 6| Step: 3
Training loss: 1.7441224442204022
Validation loss: 2.3602109711709574

Epoch: 6| Step: 4
Training loss: 1.9251698109424933
Validation loss: 2.315221505417997

Epoch: 6| Step: 5
Training loss: 2.2346427063526133
Validation loss: 2.274622897482897

Epoch: 6| Step: 6
Training loss: 2.379267522630523
Validation loss: 2.2835225170027145

Epoch: 6| Step: 7
Training loss: 1.846855264161286
Validation loss: 2.2557808799743833

Epoch: 6| Step: 8
Training loss: 1.8533253707760433
Validation loss: 2.2647062283817294

Epoch: 6| Step: 9
Training loss: 2.1452453202677915
Validation loss: 2.3164679694010415

Epoch: 6| Step: 10
Training loss: 2.116780484761352
Validation loss: 2.350653350018968

Epoch: 6| Step: 11
Training loss: 2.0547467937544255
Validation loss: 2.4212539527567682

Epoch: 6| Step: 12
Training loss: 1.9688513593467172
Validation loss: 2.4728274699296526

Epoch: 6| Step: 13
Training loss: 2.1187631297197003
Validation loss: 2.5205911289310947

Epoch: 363| Step: 0
Training loss: 2.0185367341666525
Validation loss: 2.5627491962629514

Epoch: 6| Step: 1
Training loss: 2.423980486781829
Validation loss: 2.552259534956518

Epoch: 6| Step: 2
Training loss: 1.55417076226207
Validation loss: 2.511415913714348

Epoch: 6| Step: 3
Training loss: 2.1580237128481334
Validation loss: 2.5185275908158697

Epoch: 6| Step: 4
Training loss: 1.4880845147609356
Validation loss: 2.4272214521112287

Epoch: 6| Step: 5
Training loss: 1.7638270583375324
Validation loss: 2.3735302266967215

Epoch: 6| Step: 6
Training loss: 2.357965717936826
Validation loss: 2.3004886755879346

Epoch: 6| Step: 7
Training loss: 1.6831520014373709
Validation loss: 2.272182192316398

Epoch: 6| Step: 8
Training loss: 1.3666991315257653
Validation loss: 2.2380439179914613

Epoch: 6| Step: 9
Training loss: 2.2065452918394777
Validation loss: 2.243521555153181

Epoch: 6| Step: 10
Training loss: 2.1971830496636477
Validation loss: 2.2311170952566926

Epoch: 6| Step: 11
Training loss: 2.9214992995632625
Validation loss: 2.254946536444523

Epoch: 6| Step: 12
Training loss: 1.9491325160581128
Validation loss: 2.2511998865937506

Epoch: 6| Step: 13
Training loss: 2.1320745847441898
Validation loss: 2.3072872215062805

Epoch: 364| Step: 0
Training loss: 2.1836321832485317
Validation loss: 2.362167271856491

Epoch: 6| Step: 1
Training loss: 2.0573752342023277
Validation loss: 2.429295320160485

Epoch: 6| Step: 2
Training loss: 1.5165404082064218
Validation loss: 2.477960934644502

Epoch: 6| Step: 3
Training loss: 2.155813421750457
Validation loss: 2.507949258528531

Epoch: 6| Step: 4
Training loss: 2.4662998450801323
Validation loss: 2.5055486191158027

Epoch: 6| Step: 5
Training loss: 2.243713497619385
Validation loss: 2.510712945960021

Epoch: 6| Step: 6
Training loss: 1.9749782681778503
Validation loss: 2.53858214019095

Epoch: 6| Step: 7
Training loss: 1.6370332911839949
Validation loss: 2.4985140044989644

Epoch: 6| Step: 8
Training loss: 1.890228860511627
Validation loss: 2.483767643084459

Epoch: 6| Step: 9
Training loss: 1.6023523383466054
Validation loss: 2.4228177980119208

Epoch: 6| Step: 10
Training loss: 1.9584925025482844
Validation loss: 2.37283818873414

Epoch: 6| Step: 11
Training loss: 2.7992581917541624
Validation loss: 2.3358420525602055

Epoch: 6| Step: 12
Training loss: 1.5216592436014362
Validation loss: 2.2951145888703834

Epoch: 6| Step: 13
Training loss: 1.2192153042425957
Validation loss: 2.269504066245041

Epoch: 365| Step: 0
Training loss: 2.0787309035790633
Validation loss: 2.2774666961773997

Epoch: 6| Step: 1
Training loss: 1.5944296191889045
Validation loss: 2.2711588082629115

Epoch: 6| Step: 2
Training loss: 2.042589666669916
Validation loss: 2.2847325214992873

Epoch: 6| Step: 3
Training loss: 2.123528251364809
Validation loss: 2.2817327899064983

Epoch: 6| Step: 4
Training loss: 2.4343932477979635
Validation loss: 2.3070291382633914

Epoch: 6| Step: 5
Training loss: 1.983797965668709
Validation loss: 2.333059965840938

Epoch: 6| Step: 6
Training loss: 1.6337712589623212
Validation loss: 2.345740132254535

Epoch: 6| Step: 7
Training loss: 2.2147752862268995
Validation loss: 2.3920097611207876

Epoch: 6| Step: 8
Training loss: 1.5140637093648421
Validation loss: 2.3824353744545954

Epoch: 6| Step: 9
Training loss: 1.9856389743504106
Validation loss: 2.423504616500799

Epoch: 6| Step: 10
Training loss: 2.037559569254479
Validation loss: 2.3961335545603863

Epoch: 6| Step: 11
Training loss: 1.9776544381852406
Validation loss: 2.416430495380126

Epoch: 6| Step: 12
Training loss: 1.9289857151971899
Validation loss: 2.441265565292998

Epoch: 6| Step: 13
Training loss: 2.220420101385263
Validation loss: 2.480821069034706

Epoch: 366| Step: 0
Training loss: 2.322950308745724
Validation loss: 2.504111023160929

Epoch: 6| Step: 1
Training loss: 1.5551257258673314
Validation loss: 2.5037534265660257

Epoch: 6| Step: 2
Training loss: 2.2477339883937706
Validation loss: 2.499306633893474

Epoch: 6| Step: 3
Training loss: 1.9790687804526783
Validation loss: 2.4788169072955464

Epoch: 6| Step: 4
Training loss: 2.2091901904215567
Validation loss: 2.455208431791054

Epoch: 6| Step: 5
Training loss: 1.7035043276504263
Validation loss: 2.430987916414349

Epoch: 6| Step: 6
Training loss: 1.997291877226379
Validation loss: 2.3995422558484805

Epoch: 6| Step: 7
Training loss: 2.068669195988484
Validation loss: 2.3743944966796406

Epoch: 6| Step: 8
Training loss: 1.6496120806054653
Validation loss: 2.374649860756838

Epoch: 6| Step: 9
Training loss: 2.1990283727823425
Validation loss: 2.3553063377069625

Epoch: 6| Step: 10
Training loss: 1.9337164329372274
Validation loss: 2.318802155102528

Epoch: 6| Step: 11
Training loss: 2.072105581303612
Validation loss: 2.2989794017415277

Epoch: 6| Step: 12
Training loss: 1.644411639940269
Validation loss: 2.2872492377023295

Epoch: 6| Step: 13
Training loss: 2.008215719026596
Validation loss: 2.275504948758192

Epoch: 367| Step: 0
Training loss: 1.7525705803821972
Validation loss: 2.3120191440549016

Epoch: 6| Step: 1
Training loss: 2.5437946062605628
Validation loss: 2.333162142879879

Epoch: 6| Step: 2
Training loss: 1.8627991762470295
Validation loss: 2.3843643769914187

Epoch: 6| Step: 3
Training loss: 2.1511844344401956
Validation loss: 2.46375439009512

Epoch: 6| Step: 4
Training loss: 2.0531510675131224
Validation loss: 2.5063768725170705

Epoch: 6| Step: 5
Training loss: 2.2641844280259042
Validation loss: 2.543376878452101

Epoch: 6| Step: 6
Training loss: 1.127376166265578
Validation loss: 2.504204958691756

Epoch: 6| Step: 7
Training loss: 2.3570157817754063
Validation loss: 2.4655513319521347

Epoch: 6| Step: 8
Training loss: 2.1419956246553076
Validation loss: 2.4147237075358414

Epoch: 6| Step: 9
Training loss: 1.832983489324836
Validation loss: 2.3214848716748437

Epoch: 6| Step: 10
Training loss: 1.543857444082097
Validation loss: 2.3100104107884287

Epoch: 6| Step: 11
Training loss: 2.066722823989993
Validation loss: 2.2923645653513254

Epoch: 6| Step: 12
Training loss: 2.2252338929415707
Validation loss: 2.281455928168404

Epoch: 6| Step: 13
Training loss: 1.3475942846233067
Validation loss: 2.2619351051831034

Epoch: 368| Step: 0
Training loss: 2.0154461448626697
Validation loss: 2.280692076829616

Epoch: 6| Step: 1
Training loss: 2.2850181081375704
Validation loss: 2.2675000712614075

Epoch: 6| Step: 2
Training loss: 2.5610563351870947
Validation loss: 2.2994608885272836

Epoch: 6| Step: 3
Training loss: 1.6440588483278622
Validation loss: 2.342434476322403

Epoch: 6| Step: 4
Training loss: 1.751475393424633
Validation loss: 2.3825940028433004

Epoch: 6| Step: 5
Training loss: 1.9239091110610973
Validation loss: 2.4525748799245934

Epoch: 6| Step: 6
Training loss: 1.130454562506132
Validation loss: 2.483762944696813

Epoch: 6| Step: 7
Training loss: 2.5803806494312953
Validation loss: 2.5035149813442747

Epoch: 6| Step: 8
Training loss: 1.7290896050007305
Validation loss: 2.4754190985675844

Epoch: 6| Step: 9
Training loss: 1.9498151275835205
Validation loss: 2.432803378662142

Epoch: 6| Step: 10
Training loss: 1.6937883267166047
Validation loss: 2.3345786769164323

Epoch: 6| Step: 11
Training loss: 1.938821280550701
Validation loss: 2.289830042569417

Epoch: 6| Step: 12
Training loss: 2.0389406598985174
Validation loss: 2.2605875082164375

Epoch: 6| Step: 13
Training loss: 2.3254597404175756
Validation loss: 2.250803776535071

Epoch: 369| Step: 0
Training loss: 1.829617925896208
Validation loss: 2.2660401662283083

Epoch: 6| Step: 1
Training loss: 2.114904094352296
Validation loss: 2.260696904882778

Epoch: 6| Step: 2
Training loss: 1.6975361528324926
Validation loss: 2.263741515626997

Epoch: 6| Step: 3
Training loss: 1.6202552925097586
Validation loss: 2.28365999214083

Epoch: 6| Step: 4
Training loss: 2.0483204637231287
Validation loss: 2.3128798266270523

Epoch: 6| Step: 5
Training loss: 2.0202445388302834
Validation loss: 2.3436445227511786

Epoch: 6| Step: 6
Training loss: 2.277138126571454
Validation loss: 2.3762785703423184

Epoch: 6| Step: 7
Training loss: 2.1279802180711638
Validation loss: 2.4400277053491304

Epoch: 6| Step: 8
Training loss: 2.3191414392131593
Validation loss: 2.536028970170356

Epoch: 6| Step: 9
Training loss: 1.6569464316955285
Validation loss: 2.5271071471795277

Epoch: 6| Step: 10
Training loss: 2.3092363370115585
Validation loss: 2.5266338882600476

Epoch: 6| Step: 11
Training loss: 1.964022576678196
Validation loss: 2.4571331620003805

Epoch: 6| Step: 12
Training loss: 1.8268904470703555
Validation loss: 2.3691593668508255

Epoch: 6| Step: 13
Training loss: 1.8223721226751188
Validation loss: 2.3361438919732587

Epoch: 370| Step: 0
Training loss: 1.5011841550389773
Validation loss: 2.3074471574470716

Epoch: 6| Step: 1
Training loss: 1.826670010603097
Validation loss: 2.2873942339468623

Epoch: 6| Step: 2
Training loss: 2.053286114413981
Validation loss: 2.2807064872664524

Epoch: 6| Step: 3
Training loss: 1.6833307543190315
Validation loss: 2.2986962449988027

Epoch: 6| Step: 4
Training loss: 1.922509313593058
Validation loss: 2.3089065985244703

Epoch: 6| Step: 5
Training loss: 2.233923913197868
Validation loss: 2.3199467872642208

Epoch: 6| Step: 6
Training loss: 2.197371416724057
Validation loss: 2.3680196424619937

Epoch: 6| Step: 7
Training loss: 2.008133205820908
Validation loss: 2.4254391783260774

Epoch: 6| Step: 8
Training loss: 2.0361130235474216
Validation loss: 2.5084921270829454

Epoch: 6| Step: 9
Training loss: 2.092174335691874
Validation loss: 2.5003284659003073

Epoch: 6| Step: 10
Training loss: 2.0252094537235936
Validation loss: 2.511783390358137

Epoch: 6| Step: 11
Training loss: 2.0950930259280804
Validation loss: 2.477180254071165

Epoch: 6| Step: 12
Training loss: 1.9258354751968962
Validation loss: 2.441862844778342

Epoch: 6| Step: 13
Training loss: 1.7222042398983781
Validation loss: 2.421892989743808

Epoch: 371| Step: 0
Training loss: 2.186744232410864
Validation loss: 2.3738589414299645

Epoch: 6| Step: 1
Training loss: 2.3751272870136035
Validation loss: 2.338585263635703

Epoch: 6| Step: 2
Training loss: 1.9889529429527475
Validation loss: 2.3258361918600694

Epoch: 6| Step: 3
Training loss: 2.009952340011736
Validation loss: 2.3151756755523096

Epoch: 6| Step: 4
Training loss: 1.2620726286941164
Validation loss: 2.3505244028436385

Epoch: 6| Step: 5
Training loss: 1.7200940512293108
Validation loss: 2.327395235372903

Epoch: 6| Step: 6
Training loss: 2.020990372156826
Validation loss: 2.3236179997265918

Epoch: 6| Step: 7
Training loss: 1.3111293538668911
Validation loss: 2.3359867016274283

Epoch: 6| Step: 8
Training loss: 1.3633080072700987
Validation loss: 2.3282746176562292

Epoch: 6| Step: 9
Training loss: 1.9866926220770738
Validation loss: 2.3518875045199557

Epoch: 6| Step: 10
Training loss: 2.3697109557999023
Validation loss: 2.3715509538566986

Epoch: 6| Step: 11
Training loss: 2.221449271190192
Validation loss: 2.347650391412666

Epoch: 6| Step: 12
Training loss: 1.9992620775745937
Validation loss: 2.3898359875054687

Epoch: 6| Step: 13
Training loss: 2.0121752174785774
Validation loss: 2.3977227128755203

Epoch: 372| Step: 0
Training loss: 2.2437904290512414
Validation loss: 2.4314446435660204

Epoch: 6| Step: 1
Training loss: 1.3282345894871443
Validation loss: 2.4322530680991608

Epoch: 6| Step: 2
Training loss: 1.7988113584782877
Validation loss: 2.430048071936352

Epoch: 6| Step: 3
Training loss: 2.1279603869257517
Validation loss: 2.4461462104143243

Epoch: 6| Step: 4
Training loss: 1.7517210807781385
Validation loss: 2.4334259968250587

Epoch: 6| Step: 5
Training loss: 1.917680893563041
Validation loss: 2.466566203817264

Epoch: 6| Step: 6
Training loss: 1.6423917431043615
Validation loss: 2.419374077730695

Epoch: 6| Step: 7
Training loss: 2.0325944412643393
Validation loss: 2.3849045409320784

Epoch: 6| Step: 8
Training loss: 1.6768801627291137
Validation loss: 2.3698156655570464

Epoch: 6| Step: 9
Training loss: 1.9073892534737025
Validation loss: 2.391010086386582

Epoch: 6| Step: 10
Training loss: 2.1095706425113736
Validation loss: 2.3600265905982862

Epoch: 6| Step: 11
Training loss: 2.6494509578038272
Validation loss: 2.3565809072843646

Epoch: 6| Step: 12
Training loss: 1.3915273760379059
Validation loss: 2.376717203010821

Epoch: 6| Step: 13
Training loss: 1.9294824529889387
Validation loss: 2.3407673627990007

Epoch: 373| Step: 0
Training loss: 1.3042816170356655
Validation loss: 2.343704097394008

Epoch: 6| Step: 1
Training loss: 1.8311495418139594
Validation loss: 2.340400970881952

Epoch: 6| Step: 2
Training loss: 1.8635812833728367
Validation loss: 2.3415444068214426

Epoch: 6| Step: 3
Training loss: 1.8604570333865258
Validation loss: 2.354116802103103

Epoch: 6| Step: 4
Training loss: 1.9989237869985532
Validation loss: 2.3458469452620876

Epoch: 6| Step: 5
Training loss: 2.189928722876454
Validation loss: 2.3775796492177936

Epoch: 6| Step: 6
Training loss: 2.2110832894181396
Validation loss: 2.378764931801525

Epoch: 6| Step: 7
Training loss: 2.3034880022084683
Validation loss: 2.3939523882993337

Epoch: 6| Step: 8
Training loss: 1.8145081806350591
Validation loss: 2.392875918384607

Epoch: 6| Step: 9
Training loss: 2.0411240252314293
Validation loss: 2.3967917331529716

Epoch: 6| Step: 10
Training loss: 2.0524827855604473
Validation loss: 2.3753517788439846

Epoch: 6| Step: 11
Training loss: 1.7796110677675478
Validation loss: 2.398986123020834

Epoch: 6| Step: 12
Training loss: 1.8382574479507185
Validation loss: 2.3889868658065976

Epoch: 6| Step: 13
Training loss: 1.1802385571552725
Validation loss: 2.4081203775587823

Epoch: 374| Step: 0
Training loss: 1.8356711336442526
Validation loss: 2.410402551674675

Epoch: 6| Step: 1
Training loss: 1.8689446899655406
Validation loss: 2.4429458267272555

Epoch: 6| Step: 2
Training loss: 2.4437944374044265
Validation loss: 2.409490251886919

Epoch: 6| Step: 3
Training loss: 2.0755102012933127
Validation loss: 2.3691599728204333

Epoch: 6| Step: 4
Training loss: 1.78554345403697
Validation loss: 2.330714624803754

Epoch: 6| Step: 5
Training loss: 2.208660449386092
Validation loss: 2.3192429892152755

Epoch: 6| Step: 6
Training loss: 2.111205486508172
Validation loss: 2.3118163919004564

Epoch: 6| Step: 7
Training loss: 2.158953864936459
Validation loss: 2.2880789079099872

Epoch: 6| Step: 8
Training loss: 1.5804577950113485
Validation loss: 2.2727893113499995

Epoch: 6| Step: 9
Training loss: 1.6930493133627347
Validation loss: 2.278051137548986

Epoch: 6| Step: 10
Training loss: 1.4424193422189586
Validation loss: 2.278913803915181

Epoch: 6| Step: 11
Training loss: 1.91355746087409
Validation loss: 2.3079314086050577

Epoch: 6| Step: 12
Training loss: 1.6511232454219993
Validation loss: 2.3219770869799854

Epoch: 6| Step: 13
Training loss: 1.8607454778987125
Validation loss: 2.3444783195509116

Epoch: 375| Step: 0
Training loss: 1.8665483090934034
Validation loss: 2.4277953402240353

Epoch: 6| Step: 1
Training loss: 2.3094665633079328
Validation loss: 2.481617592339226

Epoch: 6| Step: 2
Training loss: 1.9823431591322607
Validation loss: 2.439077982976525

Epoch: 6| Step: 3
Training loss: 1.7481634857665713
Validation loss: 2.3939322202927773

Epoch: 6| Step: 4
Training loss: 1.9613743633570448
Validation loss: 2.382931056738837

Epoch: 6| Step: 5
Training loss: 2.1497228488159097
Validation loss: 2.377237280834471

Epoch: 6| Step: 6
Training loss: 1.729716049000083
Validation loss: 2.360989572395664

Epoch: 6| Step: 7
Training loss: 1.891512197609964
Validation loss: 2.3433194657174194

Epoch: 6| Step: 8
Training loss: 1.6391152110683493
Validation loss: 2.3587200905005066

Epoch: 6| Step: 9
Training loss: 1.6810490966789002
Validation loss: 2.3485660787986946

Epoch: 6| Step: 10
Training loss: 2.059799275665052
Validation loss: 2.3729051316800653

Epoch: 6| Step: 11
Training loss: 1.8601782850733155
Validation loss: 2.390386834567379

Epoch: 6| Step: 12
Training loss: 1.6484312807661856
Validation loss: 2.3827221978887705

Epoch: 6| Step: 13
Training loss: 2.394445420884801
Validation loss: 2.363462389413829

Epoch: 376| Step: 0
Training loss: 1.4716096999366897
Validation loss: 2.369270356255599

Epoch: 6| Step: 1
Training loss: 2.174465473307059
Validation loss: 2.3401815910879398

Epoch: 6| Step: 2
Training loss: 2.1133205106969974
Validation loss: 2.3226883291019824

Epoch: 6| Step: 3
Training loss: 2.232086717172089
Validation loss: 2.273462083753595

Epoch: 6| Step: 4
Training loss: 2.0494660728905574
Validation loss: 2.2943646137559814

Epoch: 6| Step: 5
Training loss: 1.8435606131835784
Validation loss: 2.268776594314772

Epoch: 6| Step: 6
Training loss: 1.6986415540424864
Validation loss: 2.291183710154545

Epoch: 6| Step: 7
Training loss: 1.7599668737025
Validation loss: 2.3065747603502884

Epoch: 6| Step: 8
Training loss: 1.8661966927152907
Validation loss: 2.3226406426923916

Epoch: 6| Step: 9
Training loss: 1.65261557216738
Validation loss: 2.3431755395567633

Epoch: 6| Step: 10
Training loss: 2.2366666978967764
Validation loss: 2.377314001044189

Epoch: 6| Step: 11
Training loss: 1.135911950161183
Validation loss: 2.4308909480614287

Epoch: 6| Step: 12
Training loss: 2.355766517960979
Validation loss: 2.4976126346738545

Epoch: 6| Step: 13
Training loss: 1.5686942345179675
Validation loss: 2.549322972429832

Epoch: 377| Step: 0
Training loss: 1.372409374114765
Validation loss: 2.5840666081211703

Epoch: 6| Step: 1
Training loss: 1.6756830075505997
Validation loss: 2.62601919941221

Epoch: 6| Step: 2
Training loss: 1.798718178834107
Validation loss: 2.5356875663513776

Epoch: 6| Step: 3
Training loss: 2.2020924630843504
Validation loss: 2.4615437516298786

Epoch: 6| Step: 4
Training loss: 1.874406593516952
Validation loss: 2.39758065874643

Epoch: 6| Step: 5
Training loss: 2.0657323304424406
Validation loss: 2.317459675657896

Epoch: 6| Step: 6
Training loss: 1.8622014977802377
Validation loss: 2.2523532329100457

Epoch: 6| Step: 7
Training loss: 2.192249917673185
Validation loss: 2.2476460141938657

Epoch: 6| Step: 8
Training loss: 2.2417354327388255
Validation loss: 2.249269719033549

Epoch: 6| Step: 9
Training loss: 1.88201570864698
Validation loss: 2.2450346890232953

Epoch: 6| Step: 10
Training loss: 2.011493085037168
Validation loss: 2.2719365174472665

Epoch: 6| Step: 11
Training loss: 2.0190576702722014
Validation loss: 2.321456314023914

Epoch: 6| Step: 12
Training loss: 1.5205114189404083
Validation loss: 2.346579156596951

Epoch: 6| Step: 13
Training loss: 2.1668782008664302
Validation loss: 2.387894967237803

Epoch: 378| Step: 0
Training loss: 1.39465728959535
Validation loss: 2.4374024981951536

Epoch: 6| Step: 1
Training loss: 1.975131334694324
Validation loss: 2.543442788577534

Epoch: 6| Step: 2
Training loss: 1.430581318932956
Validation loss: 2.591383630323539

Epoch: 6| Step: 3
Training loss: 1.8908529853500062
Validation loss: 2.6256335998310427

Epoch: 6| Step: 4
Training loss: 2.2459386622748467
Validation loss: 2.5430085586877977

Epoch: 6| Step: 5
Training loss: 2.0548965869880975
Validation loss: 2.509237826972249

Epoch: 6| Step: 6
Training loss: 1.5910840644230697
Validation loss: 2.44623550848638

Epoch: 6| Step: 7
Training loss: 1.7497961743046897
Validation loss: 2.4071221956981854

Epoch: 6| Step: 8
Training loss: 2.2590941912841958
Validation loss: 2.362761155665958

Epoch: 6| Step: 9
Training loss: 1.179462739867745
Validation loss: 2.361921122461257

Epoch: 6| Step: 10
Training loss: 2.5417629494695975
Validation loss: 2.311429241180917

Epoch: 6| Step: 11
Training loss: 1.7185499595059408
Validation loss: 2.3056644894650247

Epoch: 6| Step: 12
Training loss: 2.069882330199077
Validation loss: 2.2899157725595027

Epoch: 6| Step: 13
Training loss: 2.3859082732943064
Validation loss: 2.281917953528015

Epoch: 379| Step: 0
Training loss: 1.9664757323388675
Validation loss: 2.2834044731329874

Epoch: 6| Step: 1
Training loss: 1.92219379541231
Validation loss: 2.28361021038625

Epoch: 6| Step: 2
Training loss: 2.0594379930601265
Validation loss: 2.2841143884585224

Epoch: 6| Step: 3
Training loss: 1.4990416485304638
Validation loss: 2.292676356624316

Epoch: 6| Step: 4
Training loss: 1.634887472007575
Validation loss: 2.327268773500425

Epoch: 6| Step: 5
Training loss: 1.6345679962400694
Validation loss: 2.3838113650315593

Epoch: 6| Step: 6
Training loss: 2.075412787317851
Validation loss: 2.4514586458023744

Epoch: 6| Step: 7
Training loss: 2.0962692591056005
Validation loss: 2.525046117737707

Epoch: 6| Step: 8
Training loss: 1.987683099433867
Validation loss: 2.587905692429889

Epoch: 6| Step: 9
Training loss: 2.124043866640261
Validation loss: 2.5976074253637758

Epoch: 6| Step: 10
Training loss: 2.014393156504198
Validation loss: 2.5622633757990525

Epoch: 6| Step: 11
Training loss: 2.1291098401075215
Validation loss: 2.467757200257817

Epoch: 6| Step: 12
Training loss: 1.7354934797502453
Validation loss: 2.400037983923624

Epoch: 6| Step: 13
Training loss: 1.4757875699846477
Validation loss: 2.2986294902291493

Epoch: 380| Step: 0
Training loss: 1.8251277774340025
Validation loss: 2.2576874456593923

Epoch: 6| Step: 1
Training loss: 2.031420187056187
Validation loss: 2.234082644091297

Epoch: 6| Step: 2
Training loss: 2.0072097764255656
Validation loss: 2.2217719259117072

Epoch: 6| Step: 3
Training loss: 2.114346445529595
Validation loss: 2.222369583005498

Epoch: 6| Step: 4
Training loss: 1.5233727857098318
Validation loss: 2.24761287527268

Epoch: 6| Step: 5
Training loss: 1.8331171977634393
Validation loss: 2.2784589662120314

Epoch: 6| Step: 6
Training loss: 2.3690949362479263
Validation loss: 2.3272963411330454

Epoch: 6| Step: 7
Training loss: 1.9845925760010557
Validation loss: 2.4232600205072696

Epoch: 6| Step: 8
Training loss: 1.880224578308205
Validation loss: 2.547885998353912

Epoch: 6| Step: 9
Training loss: 1.7001265983565614
Validation loss: 2.579370449780569

Epoch: 6| Step: 10
Training loss: 1.5895855668211811
Validation loss: 2.6376248878561444

Epoch: 6| Step: 11
Training loss: 2.4328816016348274
Validation loss: 2.6168180128662017

Epoch: 6| Step: 12
Training loss: 1.7855058657406417
Validation loss: 2.579519756327661

Epoch: 6| Step: 13
Training loss: 2.1158383283021536
Validation loss: 2.4893076778341694

Epoch: 381| Step: 0
Training loss: 1.8408722483141076
Validation loss: 2.413836915102102

Epoch: 6| Step: 1
Training loss: 1.6958458408703647
Validation loss: 2.341970779902482

Epoch: 6| Step: 2
Training loss: 2.12063756712482
Validation loss: 2.29745930292337

Epoch: 6| Step: 3
Training loss: 1.8633587899058608
Validation loss: 2.2830317629169588

Epoch: 6| Step: 4
Training loss: 1.881518287158243
Validation loss: 2.2508319321658727

Epoch: 6| Step: 5
Training loss: 1.4696835736549356
Validation loss: 2.2637613373271708

Epoch: 6| Step: 6
Training loss: 1.7263927807827564
Validation loss: 2.2786408794484

Epoch: 6| Step: 7
Training loss: 2.4287054401576307
Validation loss: 2.2730359604283836

Epoch: 6| Step: 8
Training loss: 1.7096216027388609
Validation loss: 2.359081106306531

Epoch: 6| Step: 9
Training loss: 2.10049070801254
Validation loss: 2.416420607580889

Epoch: 6| Step: 10
Training loss: 1.9057374484026552
Validation loss: 2.5013667277727136

Epoch: 6| Step: 11
Training loss: 1.6421745611927834
Validation loss: 2.5102659750492187

Epoch: 6| Step: 12
Training loss: 2.235327670935014
Validation loss: 2.4718165243546584

Epoch: 6| Step: 13
Training loss: 1.8369852525786723
Validation loss: 2.4513634650336154

Epoch: 382| Step: 0
Training loss: 1.9370562137448462
Validation loss: 2.453050958067164

Epoch: 6| Step: 1
Training loss: 1.1437325147949453
Validation loss: 2.4032659716545295

Epoch: 6| Step: 2
Training loss: 2.29756185421372
Validation loss: 2.385427565674459

Epoch: 6| Step: 3
Training loss: 2.3109558723756245
Validation loss: 2.349465712489328

Epoch: 6| Step: 4
Training loss: 1.4936094848429728
Validation loss: 2.353180028351538

Epoch: 6| Step: 5
Training loss: 1.3189064981609246
Validation loss: 2.3281807929609846

Epoch: 6| Step: 6
Training loss: 1.678488440911585
Validation loss: 2.3087773517692463

Epoch: 6| Step: 7
Training loss: 1.968042761307094
Validation loss: 2.3034834714311074

Epoch: 6| Step: 8
Training loss: 1.5064187996013858
Validation loss: 2.3298331523701727

Epoch: 6| Step: 9
Training loss: 2.4727239373510987
Validation loss: 2.3153310583575926

Epoch: 6| Step: 10
Training loss: 1.8364071509083901
Validation loss: 2.3557020333850125

Epoch: 6| Step: 11
Training loss: 1.633166407145253
Validation loss: 2.3454131478706257

Epoch: 6| Step: 12
Training loss: 2.3542724405567923
Validation loss: 2.377673664314367

Epoch: 6| Step: 13
Training loss: 1.7560916191174358
Validation loss: 2.3822060283761615

Epoch: 383| Step: 0
Training loss: 1.2131994471634568
Validation loss: 2.3766559555244275

Epoch: 6| Step: 1
Training loss: 2.2769373012483056
Validation loss: 2.4256561655512376

Epoch: 6| Step: 2
Training loss: 1.7692834541679936
Validation loss: 2.3881610792454784

Epoch: 6| Step: 3
Training loss: 1.9382780420229901
Validation loss: 2.353949243202806

Epoch: 6| Step: 4
Training loss: 1.6553817488531264
Validation loss: 2.3229310693620375

Epoch: 6| Step: 5
Training loss: 1.6291715922691767
Validation loss: 2.2995495432447184

Epoch: 6| Step: 6
Training loss: 2.2299055734665423
Validation loss: 2.2814006365169215

Epoch: 6| Step: 7
Training loss: 1.5635453351422741
Validation loss: 2.2707859023816384

Epoch: 6| Step: 8
Training loss: 1.8629807843759691
Validation loss: 2.2754232602237296

Epoch: 6| Step: 9
Training loss: 1.9758160655558117
Validation loss: 2.29747941675169

Epoch: 6| Step: 10
Training loss: 1.7368463315790643
Validation loss: 2.3197197351522707

Epoch: 6| Step: 11
Training loss: 2.491385495280927
Validation loss: 2.3588906372080425

Epoch: 6| Step: 12
Training loss: 1.9364354069833316
Validation loss: 2.3975197223643963

Epoch: 6| Step: 13
Training loss: 1.2757351980873766
Validation loss: 2.443775367862168

Epoch: 384| Step: 0
Training loss: 2.3954521760571845
Validation loss: 2.4307327156330407

Epoch: 6| Step: 1
Training loss: 1.824249463363972
Validation loss: 2.4555622516009894

Epoch: 6| Step: 2
Training loss: 1.6123304174393038
Validation loss: 2.4573933702504918

Epoch: 6| Step: 3
Training loss: 1.6526362744119831
Validation loss: 2.4401383027174703

Epoch: 6| Step: 4
Training loss: 1.8201163517786
Validation loss: 2.44519520753186

Epoch: 6| Step: 5
Training loss: 1.6561076984813266
Validation loss: 2.46915400916749

Epoch: 6| Step: 6
Training loss: 2.502653811488655
Validation loss: 2.4626900912645175

Epoch: 6| Step: 7
Training loss: 1.768835878477773
Validation loss: 2.4407617208280015

Epoch: 6| Step: 8
Training loss: 1.7788228011630676
Validation loss: 2.385216125564576

Epoch: 6| Step: 9
Training loss: 1.6665371685581427
Validation loss: 2.3249971975917645

Epoch: 6| Step: 10
Training loss: 1.4614726835576355
Validation loss: 2.299241425791529

Epoch: 6| Step: 11
Training loss: 1.5249671494744792
Validation loss: 2.2578439234511816

Epoch: 6| Step: 12
Training loss: 1.900777873370601
Validation loss: 2.257889811690994

Epoch: 6| Step: 13
Training loss: 2.210331702389626
Validation loss: 2.2610102539911225

Epoch: 385| Step: 0
Training loss: 1.5412461334452272
Validation loss: 2.2924692909306934

Epoch: 6| Step: 1
Training loss: 1.521826572156846
Validation loss: 2.3855500353012795

Epoch: 6| Step: 2
Training loss: 1.4615689305361195
Validation loss: 2.4316999156471075

Epoch: 6| Step: 3
Training loss: 1.222921860579336
Validation loss: 2.4915556863972386

Epoch: 6| Step: 4
Training loss: 2.2769503899867236
Validation loss: 2.521302036153084

Epoch: 6| Step: 5
Training loss: 1.8627407481622051
Validation loss: 2.5497597686799653

Epoch: 6| Step: 6
Training loss: 1.80233842958906
Validation loss: 2.5367621480137554

Epoch: 6| Step: 7
Training loss: 1.9105913099738412
Validation loss: 2.4529165970132594

Epoch: 6| Step: 8
Training loss: 2.591038401052277
Validation loss: 2.3624350513307824

Epoch: 6| Step: 9
Training loss: 2.255588161794489
Validation loss: 2.3127541716936153

Epoch: 6| Step: 10
Training loss: 1.4939442623981063
Validation loss: 2.2599996362878794

Epoch: 6| Step: 11
Training loss: 1.4719528015696794
Validation loss: 2.2611874764675988

Epoch: 6| Step: 12
Training loss: 1.9271854751598545
Validation loss: 2.245495676505238

Epoch: 6| Step: 13
Training loss: 2.5445818728833225
Validation loss: 2.2508365575373963

Epoch: 386| Step: 0
Training loss: 1.978500682476891
Validation loss: 2.298052800205843

Epoch: 6| Step: 1
Training loss: 1.9189131328806284
Validation loss: 2.3712808117908115

Epoch: 6| Step: 2
Training loss: 1.566053393568159
Validation loss: 2.4213144389981824

Epoch: 6| Step: 3
Training loss: 1.9221936093603695
Validation loss: 2.498984660318249

Epoch: 6| Step: 4
Training loss: 1.7973216289574026
Validation loss: 2.5375390901317307

Epoch: 6| Step: 5
Training loss: 1.4615415252622548
Validation loss: 2.603942565791732

Epoch: 6| Step: 6
Training loss: 1.624345794450409
Validation loss: 2.632629456329176

Epoch: 6| Step: 7
Training loss: 1.7708002723150775
Validation loss: 2.596904580317866

Epoch: 6| Step: 8
Training loss: 2.4142349329724464
Validation loss: 2.5797497772649534

Epoch: 6| Step: 9
Training loss: 1.9209460362644528
Validation loss: 2.4822722379788638

Epoch: 6| Step: 10
Training loss: 1.9499628332459698
Validation loss: 2.377856326129163

Epoch: 6| Step: 11
Training loss: 1.3469205313153532
Validation loss: 2.309881538775748

Epoch: 6| Step: 12
Training loss: 1.6435622307462072
Validation loss: 2.2805806109355737

Epoch: 6| Step: 13
Training loss: 2.8182033778509785
Validation loss: 2.2479631497398245

Epoch: 387| Step: 0
Training loss: 1.9290771754732585
Validation loss: 2.263020990042868

Epoch: 6| Step: 1
Training loss: 1.9846201467400035
Validation loss: 2.3059105905118664

Epoch: 6| Step: 2
Training loss: 1.6388522788806157
Validation loss: 2.330300619920974

Epoch: 6| Step: 3
Training loss: 2.1942717233386357
Validation loss: 2.37448344849667

Epoch: 6| Step: 4
Training loss: 2.359795943344694
Validation loss: 2.4322130993751316

Epoch: 6| Step: 5
Training loss: 1.7297492673574353
Validation loss: 2.508967853675726

Epoch: 6| Step: 6
Training loss: 1.5422435746438607
Validation loss: 2.5788618092047413

Epoch: 6| Step: 7
Training loss: 1.7166138292100683
Validation loss: 2.6188664885935133

Epoch: 6| Step: 8
Training loss: 1.5467295722802468
Validation loss: 2.5915329095200232

Epoch: 6| Step: 9
Training loss: 2.095905617692831
Validation loss: 2.5344607965480788

Epoch: 6| Step: 10
Training loss: 1.9565933559965853
Validation loss: 2.490721612049449

Epoch: 6| Step: 11
Training loss: 1.7073944194316877
Validation loss: 2.4004260890703915

Epoch: 6| Step: 12
Training loss: 1.6506594467179796
Validation loss: 2.3337025077500946

Epoch: 6| Step: 13
Training loss: 1.8484738498702584
Validation loss: 2.29108115255339

Epoch: 388| Step: 0
Training loss: 2.121083633651635
Validation loss: 2.241482762596725

Epoch: 6| Step: 1
Training loss: 1.264950325182793
Validation loss: 2.2028592648401766

Epoch: 6| Step: 2
Training loss: 2.6736359621244414
Validation loss: 2.2213555473415

Epoch: 6| Step: 3
Training loss: 1.6307831340945944
Validation loss: 2.2248941702133735

Epoch: 6| Step: 4
Training loss: 1.8863968663458968
Validation loss: 2.2493359680831184

Epoch: 6| Step: 5
Training loss: 2.0016251160403575
Validation loss: 2.3209327412091736

Epoch: 6| Step: 6
Training loss: 1.4154814455789664
Validation loss: 2.3729431807586607

Epoch: 6| Step: 7
Training loss: 1.4192529333076584
Validation loss: 2.401818052743165

Epoch: 6| Step: 8
Training loss: 1.8606871775270355
Validation loss: 2.4332555533474833

Epoch: 6| Step: 9
Training loss: 2.3599187969526514
Validation loss: 2.4584813588750287

Epoch: 6| Step: 10
Training loss: 1.7870034441794669
Validation loss: 2.4679814543386667

Epoch: 6| Step: 11
Training loss: 1.5956086932737554
Validation loss: 2.497197493877339

Epoch: 6| Step: 12
Training loss: 1.8765045487399306
Validation loss: 2.510607629483539

Epoch: 6| Step: 13
Training loss: 0.9541650319536579
Validation loss: 2.4773214878791774

Epoch: 389| Step: 0
Training loss: 1.2966368123289373
Validation loss: 2.502118745897003

Epoch: 6| Step: 1
Training loss: 1.667971680256684
Validation loss: 2.469267717529367

Epoch: 6| Step: 2
Training loss: 1.2326835922707677
Validation loss: 2.418604921793109

Epoch: 6| Step: 3
Training loss: 1.9432524531869286
Validation loss: 2.4162737674088595

Epoch: 6| Step: 4
Training loss: 1.5545421129806274
Validation loss: 2.391114075179585

Epoch: 6| Step: 5
Training loss: 2.369688720702811
Validation loss: 2.3318763137692176

Epoch: 6| Step: 6
Training loss: 2.108529606706047
Validation loss: 2.3287150660755906

Epoch: 6| Step: 7
Training loss: 2.021582736510945
Validation loss: 2.3121320846984634

Epoch: 6| Step: 8
Training loss: 2.117488262589857
Validation loss: 2.307059958029348

Epoch: 6| Step: 9
Training loss: 1.6717800220356853
Validation loss: 2.29748330213542

Epoch: 6| Step: 10
Training loss: 1.6583848545882631
Validation loss: 2.2800415081321743

Epoch: 6| Step: 11
Training loss: 1.5852528865531048
Validation loss: 2.321574119247586

Epoch: 6| Step: 12
Training loss: 2.1312129132128756
Validation loss: 2.3359266020154035

Epoch: 6| Step: 13
Training loss: 1.9112820106555106
Validation loss: 2.3723591909206827

Epoch: 390| Step: 0
Training loss: 2.221288169485664
Validation loss: 2.41121161037767

Epoch: 6| Step: 1
Training loss: 2.044632943189434
Validation loss: 2.4727901175032576

Epoch: 6| Step: 2
Training loss: 2.0330512643290364
Validation loss: 2.48016865912392

Epoch: 6| Step: 3
Training loss: 2.200900422411827
Validation loss: 2.4688778147510266

Epoch: 6| Step: 4
Training loss: 1.9651288229572281
Validation loss: 2.5082622006420268

Epoch: 6| Step: 5
Training loss: 1.4917946343256525
Validation loss: 2.455548900717481

Epoch: 6| Step: 6
Training loss: 1.9149168637907241
Validation loss: 2.4284395715897635

Epoch: 6| Step: 7
Training loss: 1.8347969570656113
Validation loss: 2.4146114454928287

Epoch: 6| Step: 8
Training loss: 1.444480780405308
Validation loss: 2.3608473266886114

Epoch: 6| Step: 9
Training loss: 0.9810889664709684
Validation loss: 2.3823066851027828

Epoch: 6| Step: 10
Training loss: 1.9238330821636642
Validation loss: 2.4009677903269333

Epoch: 6| Step: 11
Training loss: 1.7730236494850544
Validation loss: 2.3944960155322734

Epoch: 6| Step: 12
Training loss: 1.6929219350780569
Validation loss: 2.3917498107580872

Epoch: 6| Step: 13
Training loss: 1.4623465041770396
Validation loss: 2.40705049834335

Epoch: 391| Step: 0
Training loss: 1.2262216082133526
Validation loss: 2.385473193086272

Epoch: 6| Step: 1
Training loss: 1.3940261225175197
Validation loss: 2.4211923209344715

Epoch: 6| Step: 2
Training loss: 1.880261350889856
Validation loss: 2.4173629982436835

Epoch: 6| Step: 3
Training loss: 1.5917984476842308
Validation loss: 2.421136475270086

Epoch: 6| Step: 4
Training loss: 2.3068453756831624
Validation loss: 2.3776006594913732

Epoch: 6| Step: 5
Training loss: 1.727421887587414
Validation loss: 2.3540200274816936

Epoch: 6| Step: 6
Training loss: 1.0553923900436155
Validation loss: 2.335785904798086

Epoch: 6| Step: 7
Training loss: 1.821962582820581
Validation loss: 2.3240011233103486

Epoch: 6| Step: 8
Training loss: 1.9089974787172401
Validation loss: 2.349156571173585

Epoch: 6| Step: 9
Training loss: 2.2675359625104243
Validation loss: 2.349172851714764

Epoch: 6| Step: 10
Training loss: 1.9886079830770231
Validation loss: 2.3774489970656543

Epoch: 6| Step: 11
Training loss: 2.0606793546348756
Validation loss: 2.432053190503753

Epoch: 6| Step: 12
Training loss: 1.7920967591252943
Validation loss: 2.4645791617148163

Epoch: 6| Step: 13
Training loss: 1.9950631125465237
Validation loss: 2.520221983541779

Epoch: 392| Step: 0
Training loss: 1.735350463385977
Validation loss: 2.5029297735374985

Epoch: 6| Step: 1
Training loss: 2.3756277359021136
Validation loss: 2.525766742149615

Epoch: 6| Step: 2
Training loss: 1.9352538101558927
Validation loss: 2.4793797431833697

Epoch: 6| Step: 3
Training loss: 1.640340943950157
Validation loss: 2.4763153595693943

Epoch: 6| Step: 4
Training loss: 1.8833457856343325
Validation loss: 2.436375696035534

Epoch: 6| Step: 5
Training loss: 1.543693430246334
Validation loss: 2.438595997885909

Epoch: 6| Step: 6
Training loss: 1.1222903149680865
Validation loss: 2.4292565301087397

Epoch: 6| Step: 7
Training loss: 1.7580854415918283
Validation loss: 2.3983075602835227

Epoch: 6| Step: 8
Training loss: 1.663197323826063
Validation loss: 2.397992887228436

Epoch: 6| Step: 9
Training loss: 1.3222250544805316
Validation loss: 2.3848779262263005

Epoch: 6| Step: 10
Training loss: 2.0259962951234645
Validation loss: 2.381750745561169

Epoch: 6| Step: 11
Training loss: 1.8183403628755677
Validation loss: 2.3807928016174635

Epoch: 6| Step: 12
Training loss: 2.2598902240187417
Validation loss: 2.3693996151571244

Epoch: 6| Step: 13
Training loss: 1.7693906479779917
Validation loss: 2.4072424369930405

Epoch: 393| Step: 0
Training loss: 1.7156531437578748
Validation loss: 2.378501907433647

Epoch: 6| Step: 1
Training loss: 1.9751169097678691
Validation loss: 2.3740456179603253

Epoch: 6| Step: 2
Training loss: 1.404714678712511
Validation loss: 2.4003971248986504

Epoch: 6| Step: 3
Training loss: 1.9522113952102484
Validation loss: 2.417299746404679

Epoch: 6| Step: 4
Training loss: 2.17216423907974
Validation loss: 2.4230325643006037

Epoch: 6| Step: 5
Training loss: 1.871412277982746
Validation loss: 2.421848709011377

Epoch: 6| Step: 6
Training loss: 2.0484226578350073
Validation loss: 2.435177757775147

Epoch: 6| Step: 7
Training loss: 1.7586161492987435
Validation loss: 2.405693736754101

Epoch: 6| Step: 8
Training loss: 1.9164609867805629
Validation loss: 2.3610297098751727

Epoch: 6| Step: 9
Training loss: 1.2743228572787706
Validation loss: 2.3340938979545784

Epoch: 6| Step: 10
Training loss: 2.027055253098689
Validation loss: 2.351846032667502

Epoch: 6| Step: 11
Training loss: 1.369147938750972
Validation loss: 2.33172139802832

Epoch: 6| Step: 12
Training loss: 1.424551906739276
Validation loss: 2.3236148619479673

Epoch: 6| Step: 13
Training loss: 1.8141549546029145
Validation loss: 2.3164991250771765

Epoch: 394| Step: 0
Training loss: 1.9189381063000825
Validation loss: 2.3392694766160225

Epoch: 6| Step: 1
Training loss: 2.1930211826385126
Validation loss: 2.3843000508344323

Epoch: 6| Step: 2
Training loss: 2.263683671237599
Validation loss: 2.3941757563775985

Epoch: 6| Step: 3
Training loss: 2.1791780484876626
Validation loss: 2.423885261393896

Epoch: 6| Step: 4
Training loss: 1.5204662594173577
Validation loss: 2.4265720839995537

Epoch: 6| Step: 5
Training loss: 1.4366870737654756
Validation loss: 2.420903083693463

Epoch: 6| Step: 6
Training loss: 1.9909664825308229
Validation loss: 2.457245136583731

Epoch: 6| Step: 7
Training loss: 1.3716171004856068
Validation loss: 2.4832605540260495

Epoch: 6| Step: 8
Training loss: 1.8777460969638802
Validation loss: 2.467860378167172

Epoch: 6| Step: 9
Training loss: 1.53662109375
Validation loss: 2.442505930931169

Epoch: 6| Step: 10
Training loss: 1.7770259363431584
Validation loss: 2.448123234237101

Epoch: 6| Step: 11
Training loss: 1.2186165761050953
Validation loss: 2.4533012739076856

Epoch: 6| Step: 12
Training loss: 1.6174126067571089
Validation loss: 2.4523762153942816

Epoch: 6| Step: 13
Training loss: 1.1118353840812794
Validation loss: 2.4313534990105787

Epoch: 395| Step: 0
Training loss: 1.7167134096516186
Validation loss: 2.451459392475845

Epoch: 6| Step: 1
Training loss: 1.9656357126595998
Validation loss: 2.410210141926828

Epoch: 6| Step: 2
Training loss: 1.6174487211657085
Validation loss: 2.410184748008724

Epoch: 6| Step: 3
Training loss: 1.116729642506146
Validation loss: 2.3911252255469897

Epoch: 6| Step: 4
Training loss: 1.997515446456369
Validation loss: 2.3906370159042636

Epoch: 6| Step: 5
Training loss: 1.9482251771265546
Validation loss: 2.3818726562029013

Epoch: 6| Step: 6
Training loss: 2.204191558447352
Validation loss: 2.4226557938759568

Epoch: 6| Step: 7
Training loss: 2.095816091033004
Validation loss: 2.4353934925714045

Epoch: 6| Step: 8
Training loss: 1.8515985541716506
Validation loss: 2.479801831495194

Epoch: 6| Step: 9
Training loss: 1.6539972207300897
Validation loss: 2.482222448197946

Epoch: 6| Step: 10
Training loss: 1.1425383732067287
Validation loss: 2.4880255632199426

Epoch: 6| Step: 11
Training loss: 1.5655877693302802
Validation loss: 2.457088694181433

Epoch: 6| Step: 12
Training loss: 1.8673142904862978
Validation loss: 2.4273432985378087

Epoch: 6| Step: 13
Training loss: 1.6077639469567389
Validation loss: 2.3428257104790964

Epoch: 396| Step: 0
Training loss: 1.6218301961660238
Validation loss: 2.3449671624935924

Epoch: 6| Step: 1
Training loss: 1.6471403541541196
Validation loss: 2.320340850757419

Epoch: 6| Step: 2
Training loss: 2.2974682515371763
Validation loss: 2.303350446685053

Epoch: 6| Step: 3
Training loss: 1.6072911966075527
Validation loss: 2.2913513746047958

Epoch: 6| Step: 4
Training loss: 1.9411036295832456
Validation loss: 2.314248507923444

Epoch: 6| Step: 5
Training loss: 2.088655793709717
Validation loss: 2.3322483878965428

Epoch: 6| Step: 6
Training loss: 1.369405723516137
Validation loss: 2.390112790183581

Epoch: 6| Step: 7
Training loss: 1.1328994717590248
Validation loss: 2.4156410988825727

Epoch: 6| Step: 8
Training loss: 2.105546429674988
Validation loss: 2.485521547920004

Epoch: 6| Step: 9
Training loss: 1.4162541050527393
Validation loss: 2.4979382791473403

Epoch: 6| Step: 10
Training loss: 1.543586317643584
Validation loss: 2.5138802133251583

Epoch: 6| Step: 11
Training loss: 1.826551754857055
Validation loss: 2.508089496151958

Epoch: 6| Step: 12
Training loss: 1.8838663278162047
Validation loss: 2.4550391857432583

Epoch: 6| Step: 13
Training loss: 1.8388488412064419
Validation loss: 2.4210845207675864

Epoch: 397| Step: 0
Training loss: 1.7887696938593514
Validation loss: 2.3659070897348866

Epoch: 6| Step: 1
Training loss: 1.4724755619009464
Validation loss: 2.3398762827929263

Epoch: 6| Step: 2
Training loss: 1.7027617600880172
Validation loss: 2.341204214852708

Epoch: 6| Step: 3
Training loss: 2.2117594885973455
Validation loss: 2.3454026792148133

Epoch: 6| Step: 4
Training loss: 1.347054786808365
Validation loss: 2.3641767139114256

Epoch: 6| Step: 5
Training loss: 2.046705399104291
Validation loss: 2.369671932541583

Epoch: 6| Step: 6
Training loss: 1.5790550588390562
Validation loss: 2.4027261446510013

Epoch: 6| Step: 7
Training loss: 2.142654014224044
Validation loss: 2.4111963909130925

Epoch: 6| Step: 8
Training loss: 1.5940805728129395
Validation loss: 2.3908447083164175

Epoch: 6| Step: 9
Training loss: 1.552174055618421
Validation loss: 2.435370486584529

Epoch: 6| Step: 10
Training loss: 1.55234308650747
Validation loss: 2.4260435518217385

Epoch: 6| Step: 11
Training loss: 1.7574315993562923
Validation loss: 2.4395220593826403

Epoch: 6| Step: 12
Training loss: 1.6955466394424714
Validation loss: 2.47138263878721

Epoch: 6| Step: 13
Training loss: 1.9503190293131722
Validation loss: 2.4296661809677

Epoch: 398| Step: 0
Training loss: 2.0166630400738015
Validation loss: 2.3587621805568317

Epoch: 6| Step: 1
Training loss: 1.182541180915814
Validation loss: 2.3172434188557456

Epoch: 6| Step: 2
Training loss: 2.6169498164868386
Validation loss: 2.2830397119874712

Epoch: 6| Step: 3
Training loss: 1.7704983861959493
Validation loss: 2.2744262099281243

Epoch: 6| Step: 4
Training loss: 1.787109375
Validation loss: 2.30929566641084

Epoch: 6| Step: 5
Training loss: 1.282404960546341
Validation loss: 2.3494341172227284

Epoch: 6| Step: 6
Training loss: 1.5766872995544081
Validation loss: 2.3892246375110027

Epoch: 6| Step: 7
Training loss: 1.6097622748018174
Validation loss: 2.4240331533730735

Epoch: 6| Step: 8
Training loss: 2.256722157283018
Validation loss: 2.415146900571797

Epoch: 6| Step: 9
Training loss: 1.3062526429072023
Validation loss: 2.469508712734283

Epoch: 6| Step: 10
Training loss: 1.7827930793740858
Validation loss: 2.489049802756688

Epoch: 6| Step: 11
Training loss: 1.8671186745699853
Validation loss: 2.4361933605016244

Epoch: 6| Step: 12
Training loss: 1.5355364690217952
Validation loss: 2.3633334121635823

Epoch: 6| Step: 13
Training loss: 1.0960847730534091
Validation loss: 2.3095329138206204

Epoch: 399| Step: 0
Training loss: 1.4015900437998645
Validation loss: 2.268494278449448

Epoch: 6| Step: 1
Training loss: 1.9358285646986089
Validation loss: 2.2443732613171443

Epoch: 6| Step: 2
Training loss: 1.8915786859943806
Validation loss: 2.2316985182789817

Epoch: 6| Step: 3
Training loss: 2.1600531610375473
Validation loss: 2.2166357040632994

Epoch: 6| Step: 4
Training loss: 2.0051525025625145
Validation loss: 2.245500969619365

Epoch: 6| Step: 5
Training loss: 1.7927731342857762
Validation loss: 2.305183450998387

Epoch: 6| Step: 6
Training loss: 1.262151024053592
Validation loss: 2.398632876798553

Epoch: 6| Step: 7
Training loss: 1.8725864771392065
Validation loss: 2.4882416084109233

Epoch: 6| Step: 8
Training loss: 2.0672339240272666
Validation loss: 2.5684282922218693

Epoch: 6| Step: 9
Training loss: 1.7915969953371689
Validation loss: 2.599330238186658

Epoch: 6| Step: 10
Training loss: 1.387811880027806
Validation loss: 2.6257864383922396

Epoch: 6| Step: 11
Training loss: 1.9229331476311882
Validation loss: 2.607511816424214

Epoch: 6| Step: 12
Training loss: 1.4426532923072022
Validation loss: 2.521629823617069

Epoch: 6| Step: 13
Training loss: 1.7881289382672532
Validation loss: 2.4802430104191986

Epoch: 400| Step: 0
Training loss: 2.2640139409367293
Validation loss: 2.393033669361459

Epoch: 6| Step: 1
Training loss: 1.6749806303356203
Validation loss: 2.3678042096047798

Epoch: 6| Step: 2
Training loss: 1.16883802439453
Validation loss: 2.3538904936461726

Epoch: 6| Step: 3
Training loss: 1.462866015157233
Validation loss: 2.3410518612369207

Epoch: 6| Step: 4
Training loss: 1.4601968121800921
Validation loss: 2.322806095019163

Epoch: 6| Step: 5
Training loss: 1.919972291984899
Validation loss: 2.309050532904884

Epoch: 6| Step: 6
Training loss: 1.3260430117488171
Validation loss: 2.3188374424500084

Epoch: 6| Step: 7
Training loss: 2.1880368255222096
Validation loss: 2.348943822468606

Epoch: 6| Step: 8
Training loss: 1.540714055518675
Validation loss: 2.383604212747195

Epoch: 6| Step: 9
Training loss: 1.9133491276655128
Validation loss: 2.403375060656645

Epoch: 6| Step: 10
Training loss: 1.5710922506771967
Validation loss: 2.4363983815979675

Epoch: 6| Step: 11
Training loss: 1.9339194900023722
Validation loss: 2.4784260377124387

Epoch: 6| Step: 12
Training loss: 1.9606488991941557
Validation loss: 2.4592182113042567

Epoch: 6| Step: 13
Training loss: 1.4757685873317343
Validation loss: 2.471036359824408

Epoch: 401| Step: 0
Training loss: 2.19200738015986
Validation loss: 2.373609018936217

Epoch: 6| Step: 1
Training loss: 1.5557219164687581
Validation loss: 2.2588971758625633

Epoch: 6| Step: 2
Training loss: 1.919228507152769
Validation loss: 2.223180641863806

Epoch: 6| Step: 3
Training loss: 1.562069184992263
Validation loss: 2.210254054378925

Epoch: 6| Step: 4
Training loss: 1.9486595681907644
Validation loss: 2.2140696508386615

Epoch: 6| Step: 5
Training loss: 1.6356053172681153
Validation loss: 2.26341043937587

Epoch: 6| Step: 6
Training loss: 1.546955145098676
Validation loss: 2.2861910027967642

Epoch: 6| Step: 7
Training loss: 1.5487043564592373
Validation loss: 2.3616249001591325

Epoch: 6| Step: 8
Training loss: 1.851091671083812
Validation loss: 2.4265754985615025

Epoch: 6| Step: 9
Training loss: 1.6878331173487038
Validation loss: 2.4707672270358465

Epoch: 6| Step: 10
Training loss: 1.5715654982323757
Validation loss: 2.4979554111584603

Epoch: 6| Step: 11
Training loss: 2.0106481573676263
Validation loss: 2.496932795903976

Epoch: 6| Step: 12
Training loss: 1.5846832276536644
Validation loss: 2.4916019673154026

Epoch: 6| Step: 13
Training loss: 1.7415591761928502
Validation loss: 2.459806149847924

Epoch: 402| Step: 0
Training loss: 1.527362716049722
Validation loss: 2.4659586638100843

Epoch: 6| Step: 1
Training loss: 1.9971522083605382
Validation loss: 2.4575103580101882

Epoch: 6| Step: 2
Training loss: 1.941434679648323
Validation loss: 2.4511642808269105

Epoch: 6| Step: 3
Training loss: 1.6951502709182638
Validation loss: 2.430890604258714

Epoch: 6| Step: 4
Training loss: 1.6818331476431396
Validation loss: 2.378614788923917

Epoch: 6| Step: 5
Training loss: 1.4480372134005473
Validation loss: 2.3353115923338446

Epoch: 6| Step: 6
Training loss: 1.467239333467098
Validation loss: 2.328945446176135

Epoch: 6| Step: 7
Training loss: 1.7526769599326928
Validation loss: 2.314949512639451

Epoch: 6| Step: 8
Training loss: 2.2530634476167815
Validation loss: 2.2710844158695034

Epoch: 6| Step: 9
Training loss: 1.5200128650120848
Validation loss: 2.2884015297247293

Epoch: 6| Step: 10
Training loss: 1.4503496800732316
Validation loss: 2.2962310671909627

Epoch: 6| Step: 11
Training loss: 1.4418269838193247
Validation loss: 2.316525585824278

Epoch: 6| Step: 12
Training loss: 1.661027675129399
Validation loss: 2.353904023049668

Epoch: 6| Step: 13
Training loss: 1.9608032666954616
Validation loss: 2.401930842817236

Epoch: 403| Step: 0
Training loss: 2.091277755306862
Validation loss: 2.4229401965393618

Epoch: 6| Step: 1
Training loss: 1.6185563785419397
Validation loss: 2.5112678532530395

Epoch: 6| Step: 2
Training loss: 2.1372860673178558
Validation loss: 2.531346806283226

Epoch: 6| Step: 3
Training loss: 2.1074619236376537
Validation loss: 2.512609881367199

Epoch: 6| Step: 4
Training loss: 1.8925795107305943
Validation loss: 2.4927104933915043

Epoch: 6| Step: 5
Training loss: 1.7403429470594343
Validation loss: 2.447903786553137

Epoch: 6| Step: 6
Training loss: 1.2384910044830462
Validation loss: 2.453805722811009

Epoch: 6| Step: 7
Training loss: 1.7390722639524376
Validation loss: 2.373530458917362

Epoch: 6| Step: 8
Training loss: 1.2595693509285562
Validation loss: 2.361338482339908

Epoch: 6| Step: 9
Training loss: 1.270300060178462
Validation loss: 2.294960404323315

Epoch: 6| Step: 10
Training loss: 1.920134834283737
Validation loss: 2.298560132585336

Epoch: 6| Step: 11
Training loss: 1.5209511837521064
Validation loss: 2.2894057116277535

Epoch: 6| Step: 12
Training loss: 1.3591045242096176
Validation loss: 2.307148622427596

Epoch: 6| Step: 13
Training loss: 1.1739401866973693
Validation loss: 2.2759237240332255

Epoch: 404| Step: 0
Training loss: 1.6785738779763204
Validation loss: 2.3079683222776093

Epoch: 6| Step: 1
Training loss: 1.4185526672794286
Validation loss: 2.335338494189582

Epoch: 6| Step: 2
Training loss: 2.093981601943958
Validation loss: 2.363477318051912

Epoch: 6| Step: 3
Training loss: 1.961765919812913
Validation loss: 2.456000938293028

Epoch: 6| Step: 4
Training loss: 1.22461161392713
Validation loss: 2.4759878103367776

Epoch: 6| Step: 5
Training loss: 1.6052781337618751
Validation loss: 2.490818084245362

Epoch: 6| Step: 6
Training loss: 0.9691368376639803
Validation loss: 2.517626247189368

Epoch: 6| Step: 7
Training loss: 1.5263375092084324
Validation loss: 2.423807451449329

Epoch: 6| Step: 8
Training loss: 1.683668944766182
Validation loss: 2.3432997732572103

Epoch: 6| Step: 9
Training loss: 1.6882648853813402
Validation loss: 2.270316386776526

Epoch: 6| Step: 10
Training loss: 2.0283118492541297
Validation loss: 2.2300397018013642

Epoch: 6| Step: 11
Training loss: 2.181496365250596
Validation loss: 2.2566070330510355

Epoch: 6| Step: 12
Training loss: 2.052586863232765
Validation loss: 2.2698429864946847

Epoch: 6| Step: 13
Training loss: 1.7865545693622353
Validation loss: 2.3209778714315434

Epoch: 405| Step: 0
Training loss: 2.110670581943321
Validation loss: 2.4002103574062854

Epoch: 6| Step: 1
Training loss: 1.4317337151585927
Validation loss: 2.44506928034615

Epoch: 6| Step: 2
Training loss: 1.9370279044611445
Validation loss: 2.545313529802117

Epoch: 6| Step: 3
Training loss: 1.5515673588333805
Validation loss: 2.5676511467660825

Epoch: 6| Step: 4
Training loss: 1.391169837774076
Validation loss: 2.506281840025205

Epoch: 6| Step: 5
Training loss: 1.5225612369994213
Validation loss: 2.4443974094986807

Epoch: 6| Step: 6
Training loss: 1.7803686538151442
Validation loss: 2.3677781974014334

Epoch: 6| Step: 7
Training loss: 1.624358857659172
Validation loss: 2.3243265448405

Epoch: 6| Step: 8
Training loss: 2.0785244435921033
Validation loss: 2.294190479362366

Epoch: 6| Step: 9
Training loss: 1.6858793176151792
Validation loss: 2.2485094625207007

Epoch: 6| Step: 10
Training loss: 2.1354348406754893
Validation loss: 2.2759368580250388

Epoch: 6| Step: 11
Training loss: 1.6980474534789531
Validation loss: 2.278872513191501

Epoch: 6| Step: 12
Training loss: 1.4298095651016098
Validation loss: 2.274313309724196

Epoch: 6| Step: 13
Training loss: 0.9744457956156346
Validation loss: 2.3035817887451593

Epoch: 406| Step: 0
Training loss: 1.5162565351001012
Validation loss: 2.3315879766149656

Epoch: 6| Step: 1
Training loss: 1.7582592883798311
Validation loss: 2.4166911452442985

Epoch: 6| Step: 2
Training loss: 1.7084090828577532
Validation loss: 2.4185117754272283

Epoch: 6| Step: 3
Training loss: 1.604789497380295
Validation loss: 2.4269791003766383

Epoch: 6| Step: 4
Training loss: 1.5332479093777784
Validation loss: 2.417323595687873

Epoch: 6| Step: 5
Training loss: 2.0729128072373646
Validation loss: 2.4440897823048715

Epoch: 6| Step: 6
Training loss: 1.7144024743894022
Validation loss: 2.4532051875396577

Epoch: 6| Step: 7
Training loss: 1.6988372023588394
Validation loss: 2.465812078295897

Epoch: 6| Step: 8
Training loss: 1.7269060302332202
Validation loss: 2.451793881411592

Epoch: 6| Step: 9
Training loss: 1.7041278651265237
Validation loss: 2.4098121864304796

Epoch: 6| Step: 10
Training loss: 1.7885252299930054
Validation loss: 2.3454677737664267

Epoch: 6| Step: 11
Training loss: 1.6366867025875043
Validation loss: 2.344293646433932

Epoch: 6| Step: 12
Training loss: 1.2095586987145297
Validation loss: 2.3404054718154983

Epoch: 6| Step: 13
Training loss: 1.2945589273241667
Validation loss: 2.3029946760892153

Epoch: 407| Step: 0
Training loss: 1.4150364509174054
Validation loss: 2.3552630331997353

Epoch: 6| Step: 1
Training loss: 1.1515409097497982
Validation loss: 2.3724666775924548

Epoch: 6| Step: 2
Training loss: 2.032668572035952
Validation loss: 2.427785373052079

Epoch: 6| Step: 3
Training loss: 1.3244074684184808
Validation loss: 2.4855179430707417

Epoch: 6| Step: 4
Training loss: 1.253668361451365
Validation loss: 2.5013373346089893

Epoch: 6| Step: 5
Training loss: 1.6779921381405878
Validation loss: 2.475463515691472

Epoch: 6| Step: 6
Training loss: 1.5844230749898534
Validation loss: 2.4369790209611413

Epoch: 6| Step: 7
Training loss: 1.6132617422776379
Validation loss: 2.3616838681806747

Epoch: 6| Step: 8
Training loss: 1.4781724337493527
Validation loss: 2.3411441079198516

Epoch: 6| Step: 9
Training loss: 1.8773223482039951
Validation loss: 2.308494617796317

Epoch: 6| Step: 10
Training loss: 1.957519287657443
Validation loss: 2.3179746597614903

Epoch: 6| Step: 11
Training loss: 1.9894560395374292
Validation loss: 2.3192647418508177

Epoch: 6| Step: 12
Training loss: 1.626568990469084
Validation loss: 2.33963120801557

Epoch: 6| Step: 13
Training loss: 2.1506384101323204
Validation loss: 2.35696223983128

Epoch: 408| Step: 0
Training loss: 1.2602318662410712
Validation loss: 2.3546266198117576

Epoch: 6| Step: 1
Training loss: 1.6528216453237206
Validation loss: 2.415141379254645

Epoch: 6| Step: 2
Training loss: 1.5182356226300164
Validation loss: 2.417366754571584

Epoch: 6| Step: 3
Training loss: 1.303391503908295
Validation loss: 2.420976505073893

Epoch: 6| Step: 4
Training loss: 1.682224150287985
Validation loss: 2.469068790910916

Epoch: 6| Step: 5
Training loss: 1.6451082282132048
Validation loss: 2.422626747325542

Epoch: 6| Step: 6
Training loss: 1.9048115039793672
Validation loss: 2.3970605932197886

Epoch: 6| Step: 7
Training loss: 1.6318264406796517
Validation loss: 2.3874022291304393

Epoch: 6| Step: 8
Training loss: 1.3195342077986618
Validation loss: 2.363144092923947

Epoch: 6| Step: 9
Training loss: 1.5349475048917594
Validation loss: 2.34799071123669

Epoch: 6| Step: 10
Training loss: 1.8630767006229707
Validation loss: 2.3634044073075318

Epoch: 6| Step: 11
Training loss: 1.9478870804387658
Validation loss: 2.3624159609654174

Epoch: 6| Step: 12
Training loss: 1.8542722036208301
Validation loss: 2.3440582750820838

Epoch: 6| Step: 13
Training loss: 1.819395169795312
Validation loss: 2.3888124579473096

Epoch: 409| Step: 0
Training loss: 2.0079488151379423
Validation loss: 2.3815206359975214

Epoch: 6| Step: 1
Training loss: 2.1015612520689255
Validation loss: 2.4155686440237942

Epoch: 6| Step: 2
Training loss: 1.5319288656288594
Validation loss: 2.4206163155721128

Epoch: 6| Step: 3
Training loss: 1.2271642484470553
Validation loss: 2.4621129643096795

Epoch: 6| Step: 4
Training loss: 1.3251901400190367
Validation loss: 2.464189128808381

Epoch: 6| Step: 5
Training loss: 2.004306329419757
Validation loss: 2.4832298883548596

Epoch: 6| Step: 6
Training loss: 1.5625231168944247
Validation loss: 2.4581553796424975

Epoch: 6| Step: 7
Training loss: 1.744496342352031
Validation loss: 2.436033823407268

Epoch: 6| Step: 8
Training loss: 1.4453331198381312
Validation loss: 2.404756592120284

Epoch: 6| Step: 9
Training loss: 1.5588568367400426
Validation loss: 2.354756736982698

Epoch: 6| Step: 10
Training loss: 1.6087757958016482
Validation loss: 2.3668352919142066

Epoch: 6| Step: 11
Training loss: 1.6069743204302354
Validation loss: 2.3372625102975477

Epoch: 6| Step: 12
Training loss: 1.6593835086927642
Validation loss: 2.3370814002735245

Epoch: 6| Step: 13
Training loss: 1.3160601424095428
Validation loss: 2.3691806947235694

Epoch: 410| Step: 0
Training loss: 1.7835051331998308
Validation loss: 2.381294341112275

Epoch: 6| Step: 1
Training loss: 1.581495029327078
Validation loss: 2.383047094552611

Epoch: 6| Step: 2
Training loss: 1.8148612065487666
Validation loss: 2.3903175127837772

Epoch: 6| Step: 3
Training loss: 1.7697449275134178
Validation loss: 2.4105251355245065

Epoch: 6| Step: 4
Training loss: 1.5643337932894605
Validation loss: 2.4044218028815503

Epoch: 6| Step: 5
Training loss: 1.6583765880496317
Validation loss: 2.417402752241218

Epoch: 6| Step: 6
Training loss: 1.1717463613477646
Validation loss: 2.4371584370827724

Epoch: 6| Step: 7
Training loss: 1.6887481453389135
Validation loss: 2.424471870958502

Epoch: 6| Step: 8
Training loss: 1.6756675699440382
Validation loss: 2.3979596958790177

Epoch: 6| Step: 9
Training loss: 1.5504114589314941
Validation loss: 2.414834180305169

Epoch: 6| Step: 10
Training loss: 1.722140764887387
Validation loss: 2.3903890041922184

Epoch: 6| Step: 11
Training loss: 1.1755168021756497
Validation loss: 2.4116462668484537

Epoch: 6| Step: 12
Training loss: 1.675235615001195
Validation loss: 2.406140015305509

Epoch: 6| Step: 13
Training loss: 1.8119337578595676
Validation loss: 2.4243570809440107

Epoch: 411| Step: 0
Training loss: 1.2035025957758652
Validation loss: 2.4214038074270565

Epoch: 6| Step: 1
Training loss: 1.4498796215731922
Validation loss: 2.4122682955230967

Epoch: 6| Step: 2
Training loss: 1.994322347253788
Validation loss: 2.389879400356695

Epoch: 6| Step: 3
Training loss: 2.0111468344736125
Validation loss: 2.3921179466541838

Epoch: 6| Step: 4
Training loss: 1.2645448855861339
Validation loss: 2.375239965689473

Epoch: 6| Step: 5
Training loss: 1.4232864919514225
Validation loss: 2.3891852553639983

Epoch: 6| Step: 6
Training loss: 1.7242951155406359
Validation loss: 2.3850036735022244

Epoch: 6| Step: 7
Training loss: 1.665083594300022
Validation loss: 2.383448818164549

Epoch: 6| Step: 8
Training loss: 1.847758574606141
Validation loss: 2.407084448855097

Epoch: 6| Step: 9
Training loss: 1.8478279921090142
Validation loss: 2.3965331797353793

Epoch: 6| Step: 10
Training loss: 1.498702839418795
Validation loss: 2.3932152252414283

Epoch: 6| Step: 11
Training loss: 1.7402723246160248
Validation loss: 2.3658189326663863

Epoch: 6| Step: 12
Training loss: 0.8011716309783727
Validation loss: 2.4250199744946754

Epoch: 6| Step: 13
Training loss: 1.6509688769479445
Validation loss: 2.430849584871154

Epoch: 412| Step: 0
Training loss: 1.903452963045222
Validation loss: 2.442009616512553

Epoch: 6| Step: 1
Training loss: 1.9999387850929995
Validation loss: 2.4150974428558656

Epoch: 6| Step: 2
Training loss: 1.8351988909668968
Validation loss: 2.3645340017774665

Epoch: 6| Step: 3
Training loss: 1.794311419629149
Validation loss: 2.340995669783324

Epoch: 6| Step: 4
Training loss: 1.344058334106432
Validation loss: 2.316281794657148

Epoch: 6| Step: 5
Training loss: 1.467504988211841
Validation loss: 2.336524863468533

Epoch: 6| Step: 6
Training loss: 1.1167913414736994
Validation loss: 2.357374370290123

Epoch: 6| Step: 7
Training loss: 1.7276826564871481
Validation loss: 2.4119884261198465

Epoch: 6| Step: 8
Training loss: 0.7394922003318588
Validation loss: 2.425434388088113

Epoch: 6| Step: 9
Training loss: 1.6492478245675573
Validation loss: 2.4404161802956406

Epoch: 6| Step: 10
Training loss: 1.8193565772908347
Validation loss: 2.463174982355408

Epoch: 6| Step: 11
Training loss: 1.5640054698077699
Validation loss: 2.4620688621039304

Epoch: 6| Step: 12
Training loss: 1.783482140128949
Validation loss: 2.5030615918031365

Epoch: 6| Step: 13
Training loss: 1.3940438666399253
Validation loss: 2.4914217025108925

Epoch: 413| Step: 0
Training loss: 2.0743051859344446
Validation loss: 2.491234502670733

Epoch: 6| Step: 1
Training loss: 1.5948464604920265
Validation loss: 2.4953661776565164

Epoch: 6| Step: 2
Training loss: 1.7783531592329622
Validation loss: 2.4835112913524497

Epoch: 6| Step: 3
Training loss: 1.6791136715132757
Validation loss: 2.4408671804893123

Epoch: 6| Step: 4
Training loss: 1.6238281719840022
Validation loss: 2.374455902908616

Epoch: 6| Step: 5
Training loss: 1.75138255410692
Validation loss: 2.4013962339169437

Epoch: 6| Step: 6
Training loss: 1.9419644510804654
Validation loss: 2.3796378987606057

Epoch: 6| Step: 7
Training loss: 1.1664427928476415
Validation loss: 2.3457183721273487

Epoch: 6| Step: 8
Training loss: 1.2593970890805724
Validation loss: 2.316176385325041

Epoch: 6| Step: 9
Training loss: 1.7026729858841778
Validation loss: 2.3263804078094195

Epoch: 6| Step: 10
Training loss: 1.3654700254588659
Validation loss: 2.3422486290808733

Epoch: 6| Step: 11
Training loss: 1.3937703682818154
Validation loss: 2.3681034631040756

Epoch: 6| Step: 12
Training loss: 1.2479680234926764
Validation loss: 2.4049062760532154

Epoch: 6| Step: 13
Training loss: 1.6999995399923262
Validation loss: 2.420622250682281

Epoch: 414| Step: 0
Training loss: 1.3468750389435447
Validation loss: 2.44918768165131

Epoch: 6| Step: 1
Training loss: 1.449849446471837
Validation loss: 2.4720545021640588

Epoch: 6| Step: 2
Training loss: 1.4596795362689357
Validation loss: 2.481208631623657

Epoch: 6| Step: 3
Training loss: 1.5401060178107226
Validation loss: 2.4745519272864027

Epoch: 6| Step: 4
Training loss: 1.8168964339843234
Validation loss: 2.4275901871139407

Epoch: 6| Step: 5
Training loss: 1.4508923842879982
Validation loss: 2.3987213711784325

Epoch: 6| Step: 6
Training loss: 1.2335684350323175
Validation loss: 2.333089067122578

Epoch: 6| Step: 7
Training loss: 1.293299791074798
Validation loss: 2.3211382159086464

Epoch: 6| Step: 8
Training loss: 1.5164553540478245
Validation loss: 2.317328577752784

Epoch: 6| Step: 9
Training loss: 2.3261281096651714
Validation loss: 2.3116288954243056

Epoch: 6| Step: 10
Training loss: 1.8558700609391299
Validation loss: 2.3274397611382573

Epoch: 6| Step: 11
Training loss: 1.64063364662435
Validation loss: 2.3875634277178808

Epoch: 6| Step: 12
Training loss: 1.676041802911494
Validation loss: 2.4007965481327913

Epoch: 6| Step: 13
Training loss: 1.5863072758187267
Validation loss: 2.4126723594798754

Epoch: 415| Step: 0
Training loss: 1.5909886841866094
Validation loss: 2.432434524381538

Epoch: 6| Step: 1
Training loss: 1.4197627716967782
Validation loss: 2.430144722629191

Epoch: 6| Step: 2
Training loss: 1.3734625543906516
Validation loss: 2.4549764806509162

Epoch: 6| Step: 3
Training loss: 1.5590578693222488
Validation loss: 2.4496607348208816

Epoch: 6| Step: 4
Training loss: 1.663476401975453
Validation loss: 2.461523067814327

Epoch: 6| Step: 5
Training loss: 1.9183389652124232
Validation loss: 2.46359515700607

Epoch: 6| Step: 6
Training loss: 1.8528897321061721
Validation loss: 2.427277540640377

Epoch: 6| Step: 7
Training loss: 1.1735615102204375
Validation loss: 2.438687502499827

Epoch: 6| Step: 8
Training loss: 1.0464784241123026
Validation loss: 2.4391436581741246

Epoch: 6| Step: 9
Training loss: 1.5262693250527726
Validation loss: 2.415764704693336

Epoch: 6| Step: 10
Training loss: 1.7012467132469342
Validation loss: 2.3984527678259426

Epoch: 6| Step: 11
Training loss: 2.069720489501683
Validation loss: 2.33890133142452

Epoch: 6| Step: 12
Training loss: 1.2696048187067064
Validation loss: 2.3060814820231137

Epoch: 6| Step: 13
Training loss: 1.6436308436845786
Validation loss: 2.3069926096124336

Epoch: 416| Step: 0
Training loss: 1.5400532278547565
Validation loss: 2.3091391319728474

Epoch: 6| Step: 1
Training loss: 1.2141902920150918
Validation loss: 2.2977385737404536

Epoch: 6| Step: 2
Training loss: 1.7595195704090205
Validation loss: 2.318917745352451

Epoch: 6| Step: 3
Training loss: 1.283432938479632
Validation loss: 2.361196396083859

Epoch: 6| Step: 4
Training loss: 1.2366089705266328
Validation loss: 2.4143630078113136

Epoch: 6| Step: 5
Training loss: 1.7674306902859303
Validation loss: 2.4196669352980935

Epoch: 6| Step: 6
Training loss: 1.5383830628187276
Validation loss: 2.4577235436625977

Epoch: 6| Step: 7
Training loss: 2.1246760626326706
Validation loss: 2.4933503180510947

Epoch: 6| Step: 8
Training loss: 1.4630258087729076
Validation loss: 2.4407884813583274

Epoch: 6| Step: 9
Training loss: 1.5868211361013267
Validation loss: 2.408959112212133

Epoch: 6| Step: 10
Training loss: 1.2284557528074973
Validation loss: 2.3640408049168804

Epoch: 6| Step: 11
Training loss: 1.63291259166809
Validation loss: 2.3766341920671774

Epoch: 6| Step: 12
Training loss: 1.7565551329836424
Validation loss: 2.381190850991706

Epoch: 6| Step: 13
Training loss: 1.7887894201300196
Validation loss: 2.394074135925274

Epoch: 417| Step: 0
Training loss: 1.4262964441358483
Validation loss: 2.414723876872261

Epoch: 6| Step: 1
Training loss: 1.4045006785840968
Validation loss: 2.4167837772982317

Epoch: 6| Step: 2
Training loss: 2.2211327451757343
Validation loss: 2.4442516034405224

Epoch: 6| Step: 3
Training loss: 1.1894974723779441
Validation loss: 2.4414144951137655

Epoch: 6| Step: 4
Training loss: 1.512852128078579
Validation loss: 2.436172879226107

Epoch: 6| Step: 5
Training loss: 1.5254629901908925
Validation loss: 2.4446501665892457

Epoch: 6| Step: 6
Training loss: 1.1334435119553603
Validation loss: 2.406214648401124

Epoch: 6| Step: 7
Training loss: 1.6205903891895976
Validation loss: 2.377944367372642

Epoch: 6| Step: 8
Training loss: 1.9155937453640404
Validation loss: 2.361245198416559

Epoch: 6| Step: 9
Training loss: 1.5467592446528935
Validation loss: 2.3765183438237347

Epoch: 6| Step: 10
Training loss: 1.6531680240332605
Validation loss: 2.358840672168981

Epoch: 6| Step: 11
Training loss: 1.0013490160726908
Validation loss: 2.3962111312085734

Epoch: 6| Step: 12
Training loss: 1.638349499097191
Validation loss: 2.39734052641368

Epoch: 6| Step: 13
Training loss: 1.708820095340746
Validation loss: 2.4344449940944264

Epoch: 418| Step: 0
Training loss: 1.7149138903339654
Validation loss: 2.394809420284398

Epoch: 6| Step: 1
Training loss: 1.800155431606364
Validation loss: 2.4098971464559713

Epoch: 6| Step: 2
Training loss: 1.588702192690221
Validation loss: 2.374945182793745

Epoch: 6| Step: 3
Training loss: 0.8978265758437374
Validation loss: 2.378614297452891

Epoch: 6| Step: 4
Training loss: 1.8016870169441601
Validation loss: 2.427838996145158

Epoch: 6| Step: 5
Training loss: 1.5324541145412605
Validation loss: 2.418913678859654

Epoch: 6| Step: 6
Training loss: 1.808528099763528
Validation loss: 2.3871659512322596

Epoch: 6| Step: 7
Training loss: 1.3660151223369106
Validation loss: 2.3492663061788384

Epoch: 6| Step: 8
Training loss: 1.068302187879722
Validation loss: 2.354803985857193

Epoch: 6| Step: 9
Training loss: 1.530116303829228
Validation loss: 2.3172704524745837

Epoch: 6| Step: 10
Training loss: 1.5662418574116206
Validation loss: 2.324988558372019

Epoch: 6| Step: 11
Training loss: 1.6963177350771883
Validation loss: 2.352533420942886

Epoch: 6| Step: 12
Training loss: 1.6630213529508524
Validation loss: 2.403156228031077

Epoch: 6| Step: 13
Training loss: 1.328618889025399
Validation loss: 2.47500338818801

Epoch: 419| Step: 0
Training loss: 1.82369209872203
Validation loss: 2.5339720084738824

Epoch: 6| Step: 1
Training loss: 1.7868444694587378
Validation loss: 2.542743675736202

Epoch: 6| Step: 2
Training loss: 1.4110850817781924
Validation loss: 2.509246303845264

Epoch: 6| Step: 3
Training loss: 1.4011528888029683
Validation loss: 2.4717835583718784

Epoch: 6| Step: 4
Training loss: 1.894500417556777
Validation loss: 2.4239298550005084

Epoch: 6| Step: 5
Training loss: 0.886855934051036
Validation loss: 2.4087955714945006

Epoch: 6| Step: 6
Training loss: 1.5773656547880803
Validation loss: 2.3465216225913976

Epoch: 6| Step: 7
Training loss: 1.3365596638672381
Validation loss: 2.327189815199979

Epoch: 6| Step: 8
Training loss: 1.1218230636603432
Validation loss: 2.3279562503088647

Epoch: 6| Step: 9
Training loss: 1.3866206604557743
Validation loss: 2.3408710115349107

Epoch: 6| Step: 10
Training loss: 1.583403343192143
Validation loss: 2.3528390361113685

Epoch: 6| Step: 11
Training loss: 1.9079618428331515
Validation loss: 2.384596315003231

Epoch: 6| Step: 12
Training loss: 1.3606753213922753
Validation loss: 2.385849652559272

Epoch: 6| Step: 13
Training loss: 1.9410160524548608
Validation loss: 2.3721240991942523

Epoch: 420| Step: 0
Training loss: 1.3444647551456972
Validation loss: 2.352561103346599

Epoch: 6| Step: 1
Training loss: 1.7745085855353164
Validation loss: 2.346189062992722

Epoch: 6| Step: 2
Training loss: 1.584361980317021
Validation loss: 2.3451016587282134

Epoch: 6| Step: 3
Training loss: 1.4010760599710406
Validation loss: 2.361133697139543

Epoch: 6| Step: 4
Training loss: 1.5577728480703799
Validation loss: 2.363712456339095

Epoch: 6| Step: 5
Training loss: 2.005992851533637
Validation loss: 2.3650407983318207

Epoch: 6| Step: 6
Training loss: 1.016825157589931
Validation loss: 2.371419752264233

Epoch: 6| Step: 7
Training loss: 1.7160624906903437
Validation loss: 2.3969208662433634

Epoch: 6| Step: 8
Training loss: 1.8034798681173543
Validation loss: 2.3926066180824783

Epoch: 6| Step: 9
Training loss: 1.2670684871454043
Validation loss: 2.4555449595411667

Epoch: 6| Step: 10
Training loss: 1.383901092151007
Validation loss: 2.435646543032428

Epoch: 6| Step: 11
Training loss: 1.2026421705177386
Validation loss: 2.4404516441636033

Epoch: 6| Step: 12
Training loss: 1.6574574513677516
Validation loss: 2.4080330770917135

Epoch: 6| Step: 13
Training loss: 1.49494025082305
Validation loss: 2.420980789494172

Epoch: 421| Step: 0
Training loss: 1.3392212425336028
Validation loss: 2.3525486521352885

Epoch: 6| Step: 1
Training loss: 1.1959488116253456
Validation loss: 2.343299253592825

Epoch: 6| Step: 2
Training loss: 1.8855912213813446
Validation loss: 2.3165517364036896

Epoch: 6| Step: 3
Training loss: 1.2371434902333018
Validation loss: 2.3069614755706294

Epoch: 6| Step: 4
Training loss: 1.6231965547990406
Validation loss: 2.3210215593636803

Epoch: 6| Step: 5
Training loss: 1.879294690368943
Validation loss: 2.3502965786232095

Epoch: 6| Step: 6
Training loss: 1.7959856569104
Validation loss: 2.3964842134676516

Epoch: 6| Step: 7
Training loss: 1.7133119036797624
Validation loss: 2.4505999745241858

Epoch: 6| Step: 8
Training loss: 1.2007584519415457
Validation loss: 2.5058249478232395

Epoch: 6| Step: 9
Training loss: 1.643469098243068
Validation loss: 2.5062952541164645

Epoch: 6| Step: 10
Training loss: 1.2356996792119799
Validation loss: 2.5374724639153414

Epoch: 6| Step: 11
Training loss: 1.7387979832383267
Validation loss: 2.5391440677083077

Epoch: 6| Step: 12
Training loss: 1.3290104326767245
Validation loss: 2.428532098601786

Epoch: 6| Step: 13
Training loss: 1.9009236198945754
Validation loss: 2.396157271076781

Epoch: 422| Step: 0
Training loss: 1.4207773687950895
Validation loss: 2.2807019415815435

Epoch: 6| Step: 1
Training loss: 1.6023015991797196
Validation loss: 2.2727335527991435

Epoch: 6| Step: 2
Training loss: 1.4288921541130868
Validation loss: 2.2610287934542237

Epoch: 6| Step: 3
Training loss: 1.1633052539078172
Validation loss: 2.275966503846807

Epoch: 6| Step: 4
Training loss: 2.1292500349570846
Validation loss: 2.312701276108718

Epoch: 6| Step: 5
Training loss: 2.0889329298034642
Validation loss: 2.3577143379840306

Epoch: 6| Step: 6
Training loss: 1.675189858679329
Validation loss: 2.3785623130405997

Epoch: 6| Step: 7
Training loss: 1.0541068279989387
Validation loss: 2.428274529290322

Epoch: 6| Step: 8
Training loss: 1.7814209170072708
Validation loss: 2.4784031244815488

Epoch: 6| Step: 9
Training loss: 1.409129394987317
Validation loss: 2.4934009559491415

Epoch: 6| Step: 10
Training loss: 1.5449782022463163
Validation loss: 2.5028407226316127

Epoch: 6| Step: 11
Training loss: 1.1009414762002312
Validation loss: 2.4828108310187256

Epoch: 6| Step: 12
Training loss: 1.0232658533489447
Validation loss: 2.4280807753142

Epoch: 6| Step: 13
Training loss: 1.9573539422160322
Validation loss: 2.3628630291543162

Epoch: 423| Step: 0
Training loss: 1.4962961244285773
Validation loss: 2.319033904413065

Epoch: 6| Step: 1
Training loss: 1.915896226310508
Validation loss: 2.285100527324917

Epoch: 6| Step: 2
Training loss: 1.3905649065042056
Validation loss: 2.2709109460626085

Epoch: 6| Step: 3
Training loss: 1.8538803851111334
Validation loss: 2.281878667523398

Epoch: 6| Step: 4
Training loss: 1.8597329700714302
Validation loss: 2.271653447134124

Epoch: 6| Step: 5
Training loss: 1.2760364246909497
Validation loss: 2.337601319945072

Epoch: 6| Step: 6
Training loss: 1.1641003903360387
Validation loss: 2.4070881221744145

Epoch: 6| Step: 7
Training loss: 1.6845655712116248
Validation loss: 2.4941405679534743

Epoch: 6| Step: 8
Training loss: 1.4636095875176078
Validation loss: 2.6037782565634413

Epoch: 6| Step: 9
Training loss: 1.5272769376771036
Validation loss: 2.633586355130408

Epoch: 6| Step: 10
Training loss: 1.4240731655087269
Validation loss: 2.5487026640265906

Epoch: 6| Step: 11
Training loss: 1.599543792535322
Validation loss: 2.441684478853828

Epoch: 6| Step: 12
Training loss: 1.137835868044393
Validation loss: 2.338063520023478

Epoch: 6| Step: 13
Training loss: 2.0931970805676476
Validation loss: 2.2462073484195453

Epoch: 424| Step: 0
Training loss: 1.6062361839086163
Validation loss: 2.20875158681191

Epoch: 6| Step: 1
Training loss: 1.7202061813443903
Validation loss: 2.192524340152539

Epoch: 6| Step: 2
Training loss: 1.4382071207100726
Validation loss: 2.2007229685880536

Epoch: 6| Step: 3
Training loss: 1.3428039769254398
Validation loss: 2.2274772671904186

Epoch: 6| Step: 4
Training loss: 1.654801220898896
Validation loss: 2.271410853305184

Epoch: 6| Step: 5
Training loss: 1.893004693143884
Validation loss: 2.3319117116478227

Epoch: 6| Step: 6
Training loss: 1.9987392027791715
Validation loss: 2.471977032383466

Epoch: 6| Step: 7
Training loss: 1.6226315477646258
Validation loss: 2.577912400355666

Epoch: 6| Step: 8
Training loss: 1.830475038459842
Validation loss: 2.7180226651643498

Epoch: 6| Step: 9
Training loss: 1.4644802608911447
Validation loss: 2.6797479987247432

Epoch: 6| Step: 10
Training loss: 1.1440382797399107
Validation loss: 2.6165676361817902

Epoch: 6| Step: 11
Training loss: 1.4654653628995802
Validation loss: 2.508717872328932

Epoch: 6| Step: 12
Training loss: 1.2217682364960354
Validation loss: 2.4291656369465477

Epoch: 6| Step: 13
Training loss: 1.5779900823651347
Validation loss: 2.389252631945384

Epoch: 425| Step: 0
Training loss: 1.1206471686821928
Validation loss: 2.3363092642263155

Epoch: 6| Step: 1
Training loss: 1.3030130754518867
Validation loss: 2.3249393924960384

Epoch: 6| Step: 2
Training loss: 1.296728424613505
Validation loss: 2.2880128820423677

Epoch: 6| Step: 3
Training loss: 1.5161182348198061
Validation loss: 2.292208436558747

Epoch: 6| Step: 4
Training loss: 1.8480631922531856
Validation loss: 2.2818065800997522

Epoch: 6| Step: 5
Training loss: 1.5527410543046198
Validation loss: 2.3057860645392294

Epoch: 6| Step: 6
Training loss: 1.5403472650048304
Validation loss: 2.327119575344815

Epoch: 6| Step: 7
Training loss: 1.7690986963560655
Validation loss: 2.3205825263495754

Epoch: 6| Step: 8
Training loss: 1.2734504184184658
Validation loss: 2.35445389632035

Epoch: 6| Step: 9
Training loss: 1.5516705401434048
Validation loss: 2.4091127729854644

Epoch: 6| Step: 10
Training loss: 1.7528214190101963
Validation loss: 2.449962344705842

Epoch: 6| Step: 11
Training loss: 1.8482800452918315
Validation loss: 2.528368130867188

Epoch: 6| Step: 12
Training loss: 1.4154689812315258
Validation loss: 2.520967597067313

Epoch: 6| Step: 13
Training loss: 1.4831631984365077
Validation loss: 2.5076561238434087

Epoch: 426| Step: 0
Training loss: 2.1192214036303474
Validation loss: 2.4200608936754935

Epoch: 6| Step: 1
Training loss: 1.5289486309526292
Validation loss: 2.3742430268059636

Epoch: 6| Step: 2
Training loss: 1.312279819003652
Validation loss: 2.317520567222212

Epoch: 6| Step: 3
Training loss: 1.528944810508719
Validation loss: 2.2927198654222987

Epoch: 6| Step: 4
Training loss: 1.1719046016769106
Validation loss: 2.2728806672763944

Epoch: 6| Step: 5
Training loss: 1.487459451459339
Validation loss: 2.2895831883250435

Epoch: 6| Step: 6
Training loss: 1.2644777160647942
Validation loss: 2.2972032776858846

Epoch: 6| Step: 7
Training loss: 1.3418024720987247
Validation loss: 2.3209030467717344

Epoch: 6| Step: 8
Training loss: 1.8502277440285424
Validation loss: 2.3548606860857144

Epoch: 6| Step: 9
Training loss: 1.5116206489689006
Validation loss: 2.3824818791114817

Epoch: 6| Step: 10
Training loss: 1.6895181808735287
Validation loss: 2.399230277674016

Epoch: 6| Step: 11
Training loss: 1.396689019847488
Validation loss: 2.4663418579541436

Epoch: 6| Step: 12
Training loss: 1.5291754234679962
Validation loss: 2.543487346241418

Epoch: 6| Step: 13
Training loss: 0.841711796756093
Validation loss: 2.547658301953176

Epoch: 427| Step: 0
Training loss: 1.680638811275297
Validation loss: 2.504064000836899

Epoch: 6| Step: 1
Training loss: 1.5392376950075572
Validation loss: 2.4738601055409055

Epoch: 6| Step: 2
Training loss: 1.134058037394586
Validation loss: 2.403512151183015

Epoch: 6| Step: 3
Training loss: 0.805721914352857
Validation loss: 2.348210530725539

Epoch: 6| Step: 4
Training loss: 1.3783085638093933
Validation loss: 2.327149010343977

Epoch: 6| Step: 5
Training loss: 1.4508995324285185
Validation loss: 2.2959932240960024

Epoch: 6| Step: 6
Training loss: 1.679827733063291
Validation loss: 2.270718472177993

Epoch: 6| Step: 7
Training loss: 1.4625659373490654
Validation loss: 2.2851310482481284

Epoch: 6| Step: 8
Training loss: 1.6808449948684419
Validation loss: 2.3225418385103063

Epoch: 6| Step: 9
Training loss: 1.3315758248203868
Validation loss: 2.3599705266763253

Epoch: 6| Step: 10
Training loss: 1.572850998608725
Validation loss: 2.4165332831283712

Epoch: 6| Step: 11
Training loss: 1.7052954047018842
Validation loss: 2.48688118618192

Epoch: 6| Step: 12
Training loss: 1.8175187836401823
Validation loss: 2.5351718634319225

Epoch: 6| Step: 13
Training loss: 1.6958498476741162
Validation loss: 2.5601639963567977

Epoch: 428| Step: 0
Training loss: 1.679394647662924
Validation loss: 2.5432562944856474

Epoch: 6| Step: 1
Training loss: 2.186335117260069
Validation loss: 2.5397295766079364

Epoch: 6| Step: 2
Training loss: 1.2954703847929798
Validation loss: 2.4888477767140786

Epoch: 6| Step: 3
Training loss: 1.4830948780857462
Validation loss: 2.45264806135195

Epoch: 6| Step: 4
Training loss: 1.1253281220779465
Validation loss: 2.4148306090067564

Epoch: 6| Step: 5
Training loss: 1.1912499497244504
Validation loss: 2.3677988815925612

Epoch: 6| Step: 6
Training loss: 1.5744896743159633
Validation loss: 2.3734944001802223

Epoch: 6| Step: 7
Training loss: 0.7580704397521226
Validation loss: 2.3281168557984198

Epoch: 6| Step: 8
Training loss: 1.2326632352522986
Validation loss: 2.304185749078707

Epoch: 6| Step: 9
Training loss: 1.682118984685907
Validation loss: 2.335532855445521

Epoch: 6| Step: 10
Training loss: 1.4911134059665365
Validation loss: 2.341703525317795

Epoch: 6| Step: 11
Training loss: 1.5796021450689863
Validation loss: 2.3699827446903696

Epoch: 6| Step: 12
Training loss: 1.6257505884170933
Validation loss: 2.3898413940414214

Epoch: 6| Step: 13
Training loss: 1.6677002880594154
Validation loss: 2.4487839341753825

Epoch: 429| Step: 0
Training loss: 1.3894285562877835
Validation loss: 2.491674790626534

Epoch: 6| Step: 1
Training loss: 1.6652840442484773
Validation loss: 2.5001893464032947

Epoch: 6| Step: 2
Training loss: 2.1117475941643074
Validation loss: 2.521776504098671

Epoch: 6| Step: 3
Training loss: 1.5125169642734477
Validation loss: 2.4873454937374326

Epoch: 6| Step: 4
Training loss: 1.333172530173323
Validation loss: 2.453785485706083

Epoch: 6| Step: 5
Training loss: 1.5131061505826047
Validation loss: 2.4834517496201536

Epoch: 6| Step: 6
Training loss: 1.1398577787962247
Validation loss: 2.4533472064370794

Epoch: 6| Step: 7
Training loss: 1.5442647778379992
Validation loss: 2.415389355841274

Epoch: 6| Step: 8
Training loss: 1.4492347078909986
Validation loss: 2.361720420406927

Epoch: 6| Step: 9
Training loss: 1.308502922891538
Validation loss: 2.3563518364964215

Epoch: 6| Step: 10
Training loss: 1.2213436795931976
Validation loss: 2.376286007631109

Epoch: 6| Step: 11
Training loss: 1.2801295242490367
Validation loss: 2.430949945363568

Epoch: 6| Step: 12
Training loss: 1.7772444812593995
Validation loss: 2.4254532826258184

Epoch: 6| Step: 13
Training loss: 1.0936201290955652
Validation loss: 2.4286554241149165

Epoch: 430| Step: 0
Training loss: 1.4266193591649505
Validation loss: 2.428538658301534

Epoch: 6| Step: 1
Training loss: 1.2598482326658225
Validation loss: 2.401361335044298

Epoch: 6| Step: 2
Training loss: 1.7076391189669498
Validation loss: 2.4010929672259187

Epoch: 6| Step: 3
Training loss: 1.0775606641044086
Validation loss: 2.4135894412774945

Epoch: 6| Step: 4
Training loss: 1.259084686061102
Validation loss: 2.380714706403653

Epoch: 6| Step: 5
Training loss: 1.3002923269982927
Validation loss: 2.4518917289456934

Epoch: 6| Step: 6
Training loss: 1.8078035478032317
Validation loss: 2.4444562465240494

Epoch: 6| Step: 7
Training loss: 1.6520213721234471
Validation loss: 2.4355126002116103

Epoch: 6| Step: 8
Training loss: 1.2793351728225002
Validation loss: 2.4674661646338194

Epoch: 6| Step: 9
Training loss: 1.5772593172855989
Validation loss: 2.467818502299572

Epoch: 6| Step: 10
Training loss: 1.701309846698498
Validation loss: 2.4644021268076277

Epoch: 6| Step: 11
Training loss: 1.2067658956748015
Validation loss: 2.4884081161492126

Epoch: 6| Step: 12
Training loss: 1.6867915891792702
Validation loss: 2.475418524823495

Epoch: 6| Step: 13
Training loss: 1.0418620434958301
Validation loss: 2.4125147890953946

Epoch: 431| Step: 0
Training loss: 1.7676720019960221
Validation loss: 2.355720537172806

Epoch: 6| Step: 1
Training loss: 1.428520017788741
Validation loss: 2.3467528644194804

Epoch: 6| Step: 2
Training loss: 1.4609436198223675
Validation loss: 2.308715308513641

Epoch: 6| Step: 3
Training loss: 1.1962091909720385
Validation loss: 2.2842156797401327

Epoch: 6| Step: 4
Training loss: 1.6981822393189232
Validation loss: 2.3009642139270037

Epoch: 6| Step: 5
Training loss: 1.3360841012569957
Validation loss: 2.311600974590406

Epoch: 6| Step: 6
Training loss: 1.5347492950184307
Validation loss: 2.326010012662119

Epoch: 6| Step: 7
Training loss: 1.0724571070952642
Validation loss: 2.404591903604581

Epoch: 6| Step: 8
Training loss: 1.1524604350350987
Validation loss: 2.47223715078466

Epoch: 6| Step: 9
Training loss: 1.6788878910699339
Validation loss: 2.521828323788045

Epoch: 6| Step: 10
Training loss: 1.4048721344890844
Validation loss: 2.5559101052364275

Epoch: 6| Step: 11
Training loss: 1.7334170746137174
Validation loss: 2.600796113975809

Epoch: 6| Step: 12
Training loss: 1.2599561916788817
Validation loss: 2.5566964137238637

Epoch: 6| Step: 13
Training loss: 1.7154009702290365
Validation loss: 2.4582959925375953

Epoch: 432| Step: 0
Training loss: 1.9177233505973352
Validation loss: 2.3459189559035365

Epoch: 6| Step: 1
Training loss: 0.9157751943156657
Validation loss: 2.277009178605185

Epoch: 6| Step: 2
Training loss: 1.9841908046509726
Validation loss: 2.229584203316835

Epoch: 6| Step: 3
Training loss: 1.6785916324315566
Validation loss: 2.2171471835093493

Epoch: 6| Step: 4
Training loss: 1.4759491145969073
Validation loss: 2.221128018127602

Epoch: 6| Step: 5
Training loss: 1.2830927553134235
Validation loss: 2.275053913275911

Epoch: 6| Step: 6
Training loss: 1.0156319251191186
Validation loss: 2.3402129941336103

Epoch: 6| Step: 7
Training loss: 1.6431756673367024
Validation loss: 2.4473631182991404

Epoch: 6| Step: 8
Training loss: 1.1722175606087013
Validation loss: 2.4959512001282116

Epoch: 6| Step: 9
Training loss: 1.7426255706026574
Validation loss: 2.565139427627728

Epoch: 6| Step: 10
Training loss: 1.2888626406086925
Validation loss: 2.623228169522735

Epoch: 6| Step: 11
Training loss: 1.9294131929592062
Validation loss: 2.623119815735279

Epoch: 6| Step: 12
Training loss: 1.3584616212390377
Validation loss: 2.4684795887315754

Epoch: 6| Step: 13
Training loss: 0.8255277246293882
Validation loss: 2.299545104486236

Epoch: 433| Step: 0
Training loss: 1.5143836532137733
Validation loss: 2.213036208136445

Epoch: 6| Step: 1
Training loss: 2.0192876849694272
Validation loss: 2.1925343806028676

Epoch: 6| Step: 2
Training loss: 1.5823933504877112
Validation loss: 2.1986733864910564

Epoch: 6| Step: 3
Training loss: 1.553018258492848
Validation loss: 2.1928056401038925

Epoch: 6| Step: 4
Training loss: 1.653191892139481
Validation loss: 2.2258969330985052

Epoch: 6| Step: 5
Training loss: 1.8072707938125843
Validation loss: 2.256499007647046

Epoch: 6| Step: 6
Training loss: 1.6033675279890043
Validation loss: 2.3011433704497377

Epoch: 6| Step: 7
Training loss: 1.173568214420063
Validation loss: 2.345559223782998

Epoch: 6| Step: 8
Training loss: 0.8803630707894099
Validation loss: 2.4154645548797227

Epoch: 6| Step: 9
Training loss: 1.2988602024792397
Validation loss: 2.477226324925533

Epoch: 6| Step: 10
Training loss: 1.4603851416536977
Validation loss: 2.5420429678071126

Epoch: 6| Step: 11
Training loss: 1.6372566158751067
Validation loss: 2.5568284359375495

Epoch: 6| Step: 12
Training loss: 0.9577473355353048
Validation loss: 2.562779098986449

Epoch: 6| Step: 13
Training loss: 1.4264473809112002
Validation loss: 2.5598708059861557

Epoch: 434| Step: 0
Training loss: 0.9312386275243487
Validation loss: 2.5389886771829846

Epoch: 6| Step: 1
Training loss: 1.381434384290244
Validation loss: 2.5164910361192754

Epoch: 6| Step: 2
Training loss: 1.8471877812717865
Validation loss: 2.463902235272636

Epoch: 6| Step: 3
Training loss: 1.390179594910876
Validation loss: 2.3830910968826746

Epoch: 6| Step: 4
Training loss: 1.3792442361428774
Validation loss: 2.3461222084232234

Epoch: 6| Step: 5
Training loss: 1.2532629341448827
Validation loss: 2.3247218332686708

Epoch: 6| Step: 6
Training loss: 1.5149143558630553
Validation loss: 2.308669522165654

Epoch: 6| Step: 7
Training loss: 1.6678149400321176
Validation loss: 2.3118293330676636

Epoch: 6| Step: 8
Training loss: 1.7656448498175548
Validation loss: 2.3010318563281302

Epoch: 6| Step: 9
Training loss: 1.4198463136488837
Validation loss: 2.3451283274823287

Epoch: 6| Step: 10
Training loss: 1.050825266997446
Validation loss: 2.4032063640665005

Epoch: 6| Step: 11
Training loss: 1.7114512051205388
Validation loss: 2.4236257914082784

Epoch: 6| Step: 12
Training loss: 1.3788896511040596
Validation loss: 2.4923788285199544

Epoch: 6| Step: 13
Training loss: 1.7589940825856722
Validation loss: 2.4664311399513

Epoch: 435| Step: 0
Training loss: 1.0039678176228193
Validation loss: 2.5069449056819373

Epoch: 6| Step: 1
Training loss: 1.6993826250001334
Validation loss: 2.4713182850759274

Epoch: 6| Step: 2
Training loss: 1.643955809614186
Validation loss: 2.414480859458307

Epoch: 6| Step: 3
Training loss: 1.3563001649781794
Validation loss: 2.4044018186524694

Epoch: 6| Step: 4
Training loss: 1.1868977274232808
Validation loss: 2.3438234401121383

Epoch: 6| Step: 5
Training loss: 1.5808150526299203
Validation loss: 2.3141219424526174

Epoch: 6| Step: 6
Training loss: 1.203401707127105
Validation loss: 2.3040973044588653

Epoch: 6| Step: 7
Training loss: 1.2587231958408742
Validation loss: 2.354241852281607

Epoch: 6| Step: 8
Training loss: 1.280054651300665
Validation loss: 2.3647472315212843

Epoch: 6| Step: 9
Training loss: 1.745938697433539
Validation loss: 2.406734945595984

Epoch: 6| Step: 10
Training loss: 1.4796839422970693
Validation loss: 2.421624560842673

Epoch: 6| Step: 11
Training loss: 1.7116843209227564
Validation loss: 2.4746490826785377

Epoch: 6| Step: 12
Training loss: 1.2207492667060633
Validation loss: 2.48304149222935

Epoch: 6| Step: 13
Training loss: 1.613894588455288
Validation loss: 2.493928612600922

Epoch: 436| Step: 0
Training loss: 1.3994471139458773
Validation loss: 2.4983359982550626

Epoch: 6| Step: 1
Training loss: 1.3849267690970952
Validation loss: 2.5157052732182277

Epoch: 6| Step: 2
Training loss: 1.3910671774125738
Validation loss: 2.5193179984759992

Epoch: 6| Step: 3
Training loss: 1.3398676833970737
Validation loss: 2.512931527747366

Epoch: 6| Step: 4
Training loss: 1.5925640106511387
Validation loss: 2.486792398191752

Epoch: 6| Step: 5
Training loss: 1.2504480989279354
Validation loss: 2.4160917685278736

Epoch: 6| Step: 6
Training loss: 1.710810408379014
Validation loss: 2.3530827380107406

Epoch: 6| Step: 7
Training loss: 1.5234082341439756
Validation loss: 2.349415519185178

Epoch: 6| Step: 8
Training loss: 1.8335648159349642
Validation loss: 2.3336637002313037

Epoch: 6| Step: 9
Training loss: 1.4772572169790126
Validation loss: 2.307024081048844

Epoch: 6| Step: 10
Training loss: 1.3751342881257191
Validation loss: 2.3206209731969953

Epoch: 6| Step: 11
Training loss: 0.9194295744319343
Validation loss: 2.3408092067096944

Epoch: 6| Step: 12
Training loss: 0.9903605905486287
Validation loss: 2.3776221962982094

Epoch: 6| Step: 13
Training loss: 1.3533085476119897
Validation loss: 2.3710551279282353

Epoch: 437| Step: 0
Training loss: 1.208098991733759
Validation loss: 2.3937367190034338

Epoch: 6| Step: 1
Training loss: 1.4087157777896093
Validation loss: 2.3959769289304047

Epoch: 6| Step: 2
Training loss: 1.0423352893090831
Validation loss: 2.400024714052117

Epoch: 6| Step: 3
Training loss: 1.4147970915441193
Validation loss: 2.424174793202023

Epoch: 6| Step: 4
Training loss: 1.7056988507166022
Validation loss: 2.459179832779725

Epoch: 6| Step: 5
Training loss: 1.3597718459778514
Validation loss: 2.4316134812438404

Epoch: 6| Step: 6
Training loss: 0.9212280848470226
Validation loss: 2.455517915070869

Epoch: 6| Step: 7
Training loss: 1.8224173888437731
Validation loss: 2.452345198023514

Epoch: 6| Step: 8
Training loss: 1.364566798025028
Validation loss: 2.441655915913623

Epoch: 6| Step: 9
Training loss: 1.5460904376286997
Validation loss: 2.418660291698875

Epoch: 6| Step: 10
Training loss: 1.3104147922682383
Validation loss: 2.3736799270694937

Epoch: 6| Step: 11
Training loss: 1.5287889438512823
Validation loss: 2.3580156036674507

Epoch: 6| Step: 12
Training loss: 1.5753140484590946
Validation loss: 2.3899890295820296

Epoch: 6| Step: 13
Training loss: 1.255323898039569
Validation loss: 2.365380102019625

Epoch: 438| Step: 0
Training loss: 1.222286473136355
Validation loss: 2.379081195496909

Epoch: 6| Step: 1
Training loss: 2.1043766282077856
Validation loss: 2.3837583528910677

Epoch: 6| Step: 2
Training loss: 1.4977013140899647
Validation loss: 2.3999562624394923

Epoch: 6| Step: 3
Training loss: 1.3231036236837714
Validation loss: 2.4099208785797326

Epoch: 6| Step: 4
Training loss: 1.3688596254805054
Validation loss: 2.438254727289592

Epoch: 6| Step: 5
Training loss: 1.2753331403644081
Validation loss: 2.4460571742441473

Epoch: 6| Step: 6
Training loss: 0.9659274729341238
Validation loss: 2.4968065179473977

Epoch: 6| Step: 7
Training loss: 1.5565316462450511
Validation loss: 2.483705032623381

Epoch: 6| Step: 8
Training loss: 1.6830832997569962
Validation loss: 2.5028790846473057

Epoch: 6| Step: 9
Training loss: 1.1653431753682082
Validation loss: 2.4563745154763086

Epoch: 6| Step: 10
Training loss: 1.333834414898794
Validation loss: 2.457757042449773

Epoch: 6| Step: 11
Training loss: 1.328259270556519
Validation loss: 2.390944907542034

Epoch: 6| Step: 12
Training loss: 1.471853750929958
Validation loss: 2.3527852994175626

Epoch: 6| Step: 13
Training loss: 0.5996338531766219
Validation loss: 2.307450646075396

Epoch: 439| Step: 0
Training loss: 1.4807503867689042
Validation loss: 2.3053145606581062

Epoch: 6| Step: 1
Training loss: 1.3422947921767854
Validation loss: 2.2981785004030506

Epoch: 6| Step: 2
Training loss: 1.3021587604292615
Validation loss: 2.3448882360053864

Epoch: 6| Step: 3
Training loss: 1.460165707316216
Validation loss: 2.348958041749036

Epoch: 6| Step: 4
Training loss: 1.0421009811336714
Validation loss: 2.404016539335315

Epoch: 6| Step: 5
Training loss: 1.1675947221971905
Validation loss: 2.4102183671843944

Epoch: 6| Step: 6
Training loss: 1.1211700945123615
Validation loss: 2.465909589468945

Epoch: 6| Step: 7
Training loss: 1.5653267277432537
Validation loss: 2.446649505572597

Epoch: 6| Step: 8
Training loss: 1.551885639204903
Validation loss: 2.419976842936069

Epoch: 6| Step: 9
Training loss: 1.3981672484043166
Validation loss: 2.381234530191231

Epoch: 6| Step: 10
Training loss: 1.98029677266971
Validation loss: 2.3615780200633436

Epoch: 6| Step: 11
Training loss: 1.3878476128434345
Validation loss: 2.3773399315550505

Epoch: 6| Step: 12
Training loss: 1.3545637379995614
Validation loss: 2.3485059648858213

Epoch: 6| Step: 13
Training loss: 1.0036744915220002
Validation loss: 2.3905041561083586

Epoch: 440| Step: 0
Training loss: 0.8309560284623643
Validation loss: 2.406179149252083

Epoch: 6| Step: 1
Training loss: 1.2502604213281032
Validation loss: 2.420332610076164

Epoch: 6| Step: 2
Training loss: 1.6240230704815806
Validation loss: 2.411170141908759

Epoch: 6| Step: 3
Training loss: 1.5520782043918462
Validation loss: 2.4578153033311243

Epoch: 6| Step: 4
Training loss: 1.0963826783641706
Validation loss: 2.5113465895529594

Epoch: 6| Step: 5
Training loss: 1.0919682840764906
Validation loss: 2.5331906893239418

Epoch: 6| Step: 6
Training loss: 1.8855922329198473
Validation loss: 2.508228675224134

Epoch: 6| Step: 7
Training loss: 1.2887310642364602
Validation loss: 2.462779573309494

Epoch: 6| Step: 8
Training loss: 1.6422361183410226
Validation loss: 2.3741809639518068

Epoch: 6| Step: 9
Training loss: 0.7739409532473808
Validation loss: 2.3373892365186344

Epoch: 6| Step: 10
Training loss: 1.4383332698434497
Validation loss: 2.3164792848519795

Epoch: 6| Step: 11
Training loss: 1.1474521068476693
Validation loss: 2.327968971258361

Epoch: 6| Step: 12
Training loss: 1.9501861434514673
Validation loss: 2.325394633702623

Epoch: 6| Step: 13
Training loss: 1.0820043126688415
Validation loss: 2.3311030376003377

Epoch: 441| Step: 0
Training loss: 1.2139209051054063
Validation loss: 2.3413220316152583

Epoch: 6| Step: 1
Training loss: 0.7197909488113143
Validation loss: 2.349890867582318

Epoch: 6| Step: 2
Training loss: 1.0890222002889418
Validation loss: 2.3647936959199742

Epoch: 6| Step: 3
Training loss: 1.6163569727263993
Validation loss: 2.386946139513333

Epoch: 6| Step: 4
Training loss: 1.5087286977204335
Validation loss: 2.4097038404596542

Epoch: 6| Step: 5
Training loss: 1.045614366038369
Validation loss: 2.4021223442256003

Epoch: 6| Step: 6
Training loss: 1.2196660145131177
Validation loss: 2.390486030418696

Epoch: 6| Step: 7
Training loss: 1.4709213925693942
Validation loss: 2.3876266416268317

Epoch: 6| Step: 8
Training loss: 1.4935223266240487
Validation loss: 2.386334481043682

Epoch: 6| Step: 9
Training loss: 1.557354197527851
Validation loss: 2.405015754343667

Epoch: 6| Step: 10
Training loss: 1.5281678925093711
Validation loss: 2.4224639906766288

Epoch: 6| Step: 11
Training loss: 0.8625292372240045
Validation loss: 2.4399774548937936

Epoch: 6| Step: 12
Training loss: 1.7616861344593808
Validation loss: 2.4224229709403007

Epoch: 6| Step: 13
Training loss: 1.8212039712863841
Validation loss: 2.4198764203928476

Epoch: 442| Step: 0
Training loss: 0.8591255172645791
Validation loss: 2.4219604000789654

Epoch: 6| Step: 1
Training loss: 1.0852015903961811
Validation loss: 2.391398462989444

Epoch: 6| Step: 2
Training loss: 1.0508327542413562
Validation loss: 2.3889868679528132

Epoch: 6| Step: 3
Training loss: 0.822993447950941
Validation loss: 2.378688467473162

Epoch: 6| Step: 4
Training loss: 1.811811250510606
Validation loss: 2.408547777658232

Epoch: 6| Step: 5
Training loss: 1.2237540974222074
Validation loss: 2.391832562913189

Epoch: 6| Step: 6
Training loss: 1.7250123120297005
Validation loss: 2.427266141268905

Epoch: 6| Step: 7
Training loss: 1.1672002503134007
Validation loss: 2.4101177252451778

Epoch: 6| Step: 8
Training loss: 1.4172596905710604
Validation loss: 2.435409532947416

Epoch: 6| Step: 9
Training loss: 1.4660963882411169
Validation loss: 2.435180864973578

Epoch: 6| Step: 10
Training loss: 1.3510176161147676
Validation loss: 2.4825488701922502

Epoch: 6| Step: 11
Training loss: 1.514682437360176
Validation loss: 2.4697144912649653

Epoch: 6| Step: 12
Training loss: 1.5127237611561895
Validation loss: 2.483515447246002

Epoch: 6| Step: 13
Training loss: 1.7208887837907358
Validation loss: 2.4223491605459997

Epoch: 443| Step: 0
Training loss: 1.0369368300073343
Validation loss: 2.3975730461272615

Epoch: 6| Step: 1
Training loss: 1.3800535966997056
Validation loss: 2.3712297488319387

Epoch: 6| Step: 2
Training loss: 1.7398830620067567
Validation loss: 2.340463785999892

Epoch: 6| Step: 3
Training loss: 1.4875909601177413
Validation loss: 2.336101435550801

Epoch: 6| Step: 4
Training loss: 0.8535303599048107
Validation loss: 2.3428344672106594

Epoch: 6| Step: 5
Training loss: 1.522623950190942
Validation loss: 2.3466284095865326

Epoch: 6| Step: 6
Training loss: 1.197945879151567
Validation loss: 2.325871126141505

Epoch: 6| Step: 7
Training loss: 1.2053812841995108
Validation loss: 2.3280433959269597

Epoch: 6| Step: 8
Training loss: 1.231345938803054
Validation loss: 2.3520870695443508

Epoch: 6| Step: 9
Training loss: 1.367050643610671
Validation loss: 2.340951286867995

Epoch: 6| Step: 10
Training loss: 1.3930853606070093
Validation loss: 2.3825419062017694

Epoch: 6| Step: 11
Training loss: 1.5081345604578889
Validation loss: 2.4144898840164326

Epoch: 6| Step: 12
Training loss: 1.7621924192816891
Validation loss: 2.4443053960017744

Epoch: 6| Step: 13
Training loss: 0.8042706641381602
Validation loss: 2.4546846858383313

Epoch: 444| Step: 0
Training loss: 1.7010872225278342
Validation loss: 2.494027626122739

Epoch: 6| Step: 1
Training loss: 1.663678048725411
Validation loss: 2.458874541897997

Epoch: 6| Step: 2
Training loss: 1.7583058660932098
Validation loss: 2.4235951285538433

Epoch: 6| Step: 3
Training loss: 0.7547028439306586
Validation loss: 2.393214022270159

Epoch: 6| Step: 4
Training loss: 1.1399074021595117
Validation loss: 2.362905519537488

Epoch: 6| Step: 5
Training loss: 0.9346389027839893
Validation loss: 2.335959429707761

Epoch: 6| Step: 6
Training loss: 1.1349766546528857
Validation loss: 2.288867873708376

Epoch: 6| Step: 7
Training loss: 1.3212575746606043
Validation loss: 2.275066960451545

Epoch: 6| Step: 8
Training loss: 1.690812145317863
Validation loss: 2.2483969963393564

Epoch: 6| Step: 9
Training loss: 1.2410049087402741
Validation loss: 2.2861806907570337

Epoch: 6| Step: 10
Training loss: 1.2370082918720295
Validation loss: 2.3394428340908315

Epoch: 6| Step: 11
Training loss: 1.635931804541408
Validation loss: 2.4010574820417614

Epoch: 6| Step: 12
Training loss: 1.419129120170817
Validation loss: 2.4559493831254464

Epoch: 6| Step: 13
Training loss: 0.9483900180852858
Validation loss: 2.5266576430559806

Epoch: 445| Step: 0
Training loss: 1.4791341518356564
Validation loss: 2.5522432234910335

Epoch: 6| Step: 1
Training loss: 1.3962922077407662
Validation loss: 2.545818886718341

Epoch: 6| Step: 2
Training loss: 1.7442425295459434
Validation loss: 2.5108241851370865

Epoch: 6| Step: 3
Training loss: 0.8097377921371064
Validation loss: 2.469538586465834

Epoch: 6| Step: 4
Training loss: 1.53503712587472
Validation loss: 2.3963767727884067

Epoch: 6| Step: 5
Training loss: 0.9801634354938381
Validation loss: 2.3566693375838876

Epoch: 6| Step: 6
Training loss: 1.046472614445803
Validation loss: 2.289908015289011

Epoch: 6| Step: 7
Training loss: 1.3872360768914478
Validation loss: 2.2613106265028446

Epoch: 6| Step: 8
Training loss: 1.0936271598498972
Validation loss: 2.3126622270321273

Epoch: 6| Step: 9
Training loss: 1.349876366358236
Validation loss: 2.3186162838796367

Epoch: 6| Step: 10
Training loss: 1.2294750257874432
Validation loss: 2.3191676597838784

Epoch: 6| Step: 11
Training loss: 1.6745118355023798
Validation loss: 2.3662666471781204

Epoch: 6| Step: 12
Training loss: 1.2565166361231546
Validation loss: 2.404244314552719

Epoch: 6| Step: 13
Training loss: 1.7211628017348282
Validation loss: 2.4350184736721596

Epoch: 446| Step: 0
Training loss: 1.1170010711268632
Validation loss: 2.488331183326617

Epoch: 6| Step: 1
Training loss: 1.297568446064754
Validation loss: 2.5363448205769465

Epoch: 6| Step: 2
Training loss: 0.9782851018069735
Validation loss: 2.520771277719909

Epoch: 6| Step: 3
Training loss: 1.055992393003866
Validation loss: 2.4994772426048564

Epoch: 6| Step: 4
Training loss: 1.2657867139946277
Validation loss: 2.459062693002718

Epoch: 6| Step: 5
Training loss: 1.5381506527804107
Validation loss: 2.3920990031521026

Epoch: 6| Step: 6
Training loss: 1.1259591464360748
Validation loss: 2.36935355486323

Epoch: 6| Step: 7
Training loss: 1.9951631948699882
Validation loss: 2.2995573945251606

Epoch: 6| Step: 8
Training loss: 1.1828077873025233
Validation loss: 2.336051226709252

Epoch: 6| Step: 9
Training loss: 1.6417586270183075
Validation loss: 2.3471234649858053

Epoch: 6| Step: 10
Training loss: 1.7254455543844376
Validation loss: 2.3616866123581866

Epoch: 6| Step: 11
Training loss: 1.049586414445204
Validation loss: 2.371694988615208

Epoch: 6| Step: 12
Training loss: 1.385802533137577
Validation loss: 2.412742869203515

Epoch: 6| Step: 13
Training loss: 0.7595090457360002
Validation loss: 2.427248224618693

Epoch: 447| Step: 0
Training loss: 1.1382241260278123
Validation loss: 2.479628637683328

Epoch: 6| Step: 1
Training loss: 1.3813083032239029
Validation loss: 2.4662665226180605

Epoch: 6| Step: 2
Training loss: 0.8368336517626135
Validation loss: 2.453001534572623

Epoch: 6| Step: 3
Training loss: 1.3139545010741218
Validation loss: 2.4419561040754934

Epoch: 6| Step: 4
Training loss: 1.201607279445374
Validation loss: 2.4310284452112825

Epoch: 6| Step: 5
Training loss: 1.180684760758654
Validation loss: 2.392299266617719

Epoch: 6| Step: 6
Training loss: 1.3979823048280786
Validation loss: 2.363773841814241

Epoch: 6| Step: 7
Training loss: 1.2809427869975678
Validation loss: 2.339137975168411

Epoch: 6| Step: 8
Training loss: 1.3678741474652678
Validation loss: 2.2998102872942447

Epoch: 6| Step: 9
Training loss: 1.6107855975871037
Validation loss: 2.317157312539704

Epoch: 6| Step: 10
Training loss: 1.5361261385841194
Validation loss: 2.3336682276161707

Epoch: 6| Step: 11
Training loss: 1.3985579454775983
Validation loss: 2.348711044478421

Epoch: 6| Step: 12
Training loss: 1.679490472637658
Validation loss: 2.3768555857117537

Epoch: 6| Step: 13
Training loss: 1.1757002894514188
Validation loss: 2.390693201921534

Epoch: 448| Step: 0
Training loss: 1.2143242022481429
Validation loss: 2.3912748895371125

Epoch: 6| Step: 1
Training loss: 0.8867186491709916
Validation loss: 2.4139906137161624

Epoch: 6| Step: 2
Training loss: 1.2076434215723582
Validation loss: 2.389055425685397

Epoch: 6| Step: 3
Training loss: 1.5596688370227219
Validation loss: 2.394999353497485

Epoch: 6| Step: 4
Training loss: 1.31048210882253
Validation loss: 2.398465733216496

Epoch: 6| Step: 5
Training loss: 1.382521561011282
Validation loss: 2.397569094121039

Epoch: 6| Step: 6
Training loss: 1.3583673710839197
Validation loss: 2.377119622660787

Epoch: 6| Step: 7
Training loss: 1.7994590423238925
Validation loss: 2.3807083207542865

Epoch: 6| Step: 8
Training loss: 0.9344255261491241
Validation loss: 2.3690974602871724

Epoch: 6| Step: 9
Training loss: 1.0433318116986408
Validation loss: 2.3642212200747403

Epoch: 6| Step: 10
Training loss: 1.402574355522432
Validation loss: 2.380871664157171

Epoch: 6| Step: 11
Training loss: 1.8312783717538728
Validation loss: 2.387385883384059

Epoch: 6| Step: 12
Training loss: 0.9445030277601494
Validation loss: 2.4172249093728366

Epoch: 6| Step: 13
Training loss: 0.8608553533947406
Validation loss: 2.453591220858372

Epoch: 449| Step: 0
Training loss: 1.3214990825325144
Validation loss: 2.494083611743025

Epoch: 6| Step: 1
Training loss: 1.5258971092664233
Validation loss: 2.489742159856174

Epoch: 6| Step: 2
Training loss: 1.507390017443432
Validation loss: 2.472029186641308

Epoch: 6| Step: 3
Training loss: 1.0662769057533985
Validation loss: 2.3765639820932822

Epoch: 6| Step: 4
Training loss: 1.1546884250250016
Validation loss: 2.3448885060477664

Epoch: 6| Step: 5
Training loss: 1.3130978176493613
Validation loss: 2.357257197048038

Epoch: 6| Step: 6
Training loss: 0.9570253644489785
Validation loss: 2.3153076610279575

Epoch: 6| Step: 7
Training loss: 0.9635764691365324
Validation loss: 2.3172923862538886

Epoch: 6| Step: 8
Training loss: 1.283190490567557
Validation loss: 2.342787433247631

Epoch: 6| Step: 9
Training loss: 1.153969138878192
Validation loss: 2.365079125142581

Epoch: 6| Step: 10
Training loss: 1.513052103460302
Validation loss: 2.384305968823044

Epoch: 6| Step: 11
Training loss: 1.6188229017890028
Validation loss: 2.412763354395054

Epoch: 6| Step: 12
Training loss: 1.3991581003238496
Validation loss: 2.4023961866251695

Epoch: 6| Step: 13
Training loss: 1.4619706524513925
Validation loss: 2.3959785157060356

Epoch: 450| Step: 0
Training loss: 1.2153913729423158
Validation loss: 2.402113666482891

Epoch: 6| Step: 1
Training loss: 0.7816830007341722
Validation loss: 2.4158488945506744

Epoch: 6| Step: 2
Training loss: 1.2781640081818622
Validation loss: 2.427853286074051

Epoch: 6| Step: 3
Training loss: 1.6480954072890015
Validation loss: 2.4381838844352663

Epoch: 6| Step: 4
Training loss: 0.9541997634500415
Validation loss: 2.3850743600336757

Epoch: 6| Step: 5
Training loss: 1.534285669775838
Validation loss: 2.384483384461926

Epoch: 6| Step: 6
Training loss: 0.9466258297146776
Validation loss: 2.3586379091472556

Epoch: 6| Step: 7
Training loss: 1.496216691745088
Validation loss: 2.3548510644964806

Epoch: 6| Step: 8
Training loss: 1.260039874838557
Validation loss: 2.3623676396877182

Epoch: 6| Step: 9
Training loss: 1.587635653249278
Validation loss: 2.3700307879359097

Epoch: 6| Step: 10
Training loss: 1.130172916449266
Validation loss: 2.3793058422311972

Epoch: 6| Step: 11
Training loss: 1.4339334776597106
Validation loss: 2.3854137690569024

Epoch: 6| Step: 12
Training loss: 1.3585847772057376
Validation loss: 2.353192032823686

Epoch: 6| Step: 13
Training loss: 1.3372290541826481
Validation loss: 2.3277017820267933

Testing loss: 2.6198960027527427
