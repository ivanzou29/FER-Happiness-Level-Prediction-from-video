Epoch: 1| Step: 0
Training loss: 4.481872081756592
Validation loss: 5.192768214851298

Epoch: 6| Step: 1
Training loss: 4.93285608291626
Validation loss: 5.18764373307587

Epoch: 6| Step: 2
Training loss: 4.978555202484131
Validation loss: 5.183067332031906

Epoch: 6| Step: 3
Training loss: 4.2867889404296875
Validation loss: 5.1784803944249305

Epoch: 6| Step: 4
Training loss: 4.6817851066589355
Validation loss: 5.174085083828177

Epoch: 6| Step: 5
Training loss: 6.288506031036377
Validation loss: 5.16962206235496

Epoch: 6| Step: 6
Training loss: 5.0893731117248535
Validation loss: 5.165566449524254

Epoch: 6| Step: 7
Training loss: 4.727605819702148
Validation loss: 5.1614915529886884

Epoch: 6| Step: 8
Training loss: 5.722622871398926
Validation loss: 5.157349232704409

Epoch: 6| Step: 9
Training loss: 4.057133197784424
Validation loss: 5.153089533569992

Epoch: 6| Step: 10
Training loss: 4.597846031188965
Validation loss: 5.149110091629849

Epoch: 6| Step: 11
Training loss: 5.678620338439941
Validation loss: 5.144730296186221

Epoch: 6| Step: 12
Training loss: 5.126685619354248
Validation loss: 5.140056097379294

Epoch: 6| Step: 13
Training loss: 4.666718482971191
Validation loss: 5.135242795431486

Epoch: 2| Step: 0
Training loss: 5.449258804321289
Validation loss: 5.130237007653841

Epoch: 6| Step: 1
Training loss: 5.170435905456543
Validation loss: 5.124925480094007

Epoch: 6| Step: 2
Training loss: 4.502255439758301
Validation loss: 5.119211919846073

Epoch: 6| Step: 3
Training loss: 5.33607816696167
Validation loss: 5.113522627020395

Epoch: 6| Step: 4
Training loss: 5.060640335083008
Validation loss: 5.106917852996498

Epoch: 6| Step: 5
Training loss: 5.782631874084473
Validation loss: 5.1004071748384865

Epoch: 6| Step: 6
Training loss: 3.9281911849975586
Validation loss: 5.093310053630542

Epoch: 6| Step: 7
Training loss: 4.649384498596191
Validation loss: 5.085645934586884

Epoch: 6| Step: 8
Training loss: 3.984445095062256
Validation loss: 5.078131660338371

Epoch: 6| Step: 9
Training loss: 5.3236470222473145
Validation loss: 5.069246763824134

Epoch: 6| Step: 10
Training loss: 4.758852958679199
Validation loss: 5.060607822992468

Epoch: 6| Step: 11
Training loss: 4.791421890258789
Validation loss: 5.051751429034818

Epoch: 6| Step: 12
Training loss: 4.771598815917969
Validation loss: 5.04240898419452

Epoch: 6| Step: 13
Training loss: 4.853766441345215
Validation loss: 5.032294442576747

Epoch: 3| Step: 0
Training loss: 4.118850231170654
Validation loss: 5.021866424109346

Epoch: 6| Step: 1
Training loss: 3.600996494293213
Validation loss: 5.011188219952327

Epoch: 6| Step: 2
Training loss: 5.357506275177002
Validation loss: 4.999630917784988

Epoch: 6| Step: 3
Training loss: 4.029636859893799
Validation loss: 4.987441247509372

Epoch: 6| Step: 4
Training loss: 5.407783031463623
Validation loss: 4.973779468126194

Epoch: 6| Step: 5
Training loss: 6.077051639556885
Validation loss: 4.960870168542349

Epoch: 6| Step: 6
Training loss: 4.781322002410889
Validation loss: 4.947081376147526

Epoch: 6| Step: 7
Training loss: 4.786500930786133
Validation loss: 4.931373298809093

Epoch: 6| Step: 8
Training loss: 4.6606526374816895
Validation loss: 4.916915457735779

Epoch: 6| Step: 9
Training loss: 4.976228713989258
Validation loss: 4.899097678481891

Epoch: 6| Step: 10
Training loss: 3.7844648361206055
Validation loss: 4.882287635598131

Epoch: 6| Step: 11
Training loss: 5.545032978057861
Validation loss: 4.864578877725909

Epoch: 6| Step: 12
Training loss: 4.89460563659668
Validation loss: 4.8455422565501225

Epoch: 6| Step: 13
Training loss: 3.650254249572754
Validation loss: 4.82567189329414

Epoch: 4| Step: 0
Training loss: 3.5609755516052246
Validation loss: 4.805485433147799

Epoch: 6| Step: 1
Training loss: 5.0161895751953125
Validation loss: 4.7830183685466805

Epoch: 6| Step: 2
Training loss: 4.896425247192383
Validation loss: 4.762082140932801

Epoch: 6| Step: 3
Training loss: 5.783751010894775
Validation loss: 4.738922447286626

Epoch: 6| Step: 4
Training loss: 5.266668319702148
Validation loss: 4.715548679392825

Epoch: 6| Step: 5
Training loss: 3.9075136184692383
Validation loss: 4.690705258359191

Epoch: 6| Step: 6
Training loss: 3.9482808113098145
Validation loss: 4.6660841100959365

Epoch: 6| Step: 7
Training loss: 4.604599475860596
Validation loss: 4.640559011890042

Epoch: 6| Step: 8
Training loss: 4.310503959655762
Validation loss: 4.615423986988683

Epoch: 6| Step: 9
Training loss: 4.296291351318359
Validation loss: 4.590026117140247

Epoch: 6| Step: 10
Training loss: 3.621021270751953
Validation loss: 4.564905325571696

Epoch: 6| Step: 11
Training loss: 4.044220447540283
Validation loss: 4.535877725129486

Epoch: 6| Step: 12
Training loss: 4.389383316040039
Validation loss: 4.509304141485563

Epoch: 6| Step: 13
Training loss: 4.53118371963501
Validation loss: 4.484403276956209

Epoch: 5| Step: 0
Training loss: 4.648073196411133
Validation loss: 4.457138579378846

Epoch: 6| Step: 1
Training loss: 5.247340679168701
Validation loss: 4.429232807569607

Epoch: 6| Step: 2
Training loss: 4.754001617431641
Validation loss: 4.403946389434158

Epoch: 6| Step: 3
Training loss: 3.4921329021453857
Validation loss: 4.3775182231780025

Epoch: 6| Step: 4
Training loss: 3.44814395904541
Validation loss: 4.354678928211171

Epoch: 6| Step: 5
Training loss: 3.871005058288574
Validation loss: 4.329810332226497

Epoch: 6| Step: 6
Training loss: 4.810066223144531
Validation loss: 4.3076685423492105

Epoch: 6| Step: 7
Training loss: 3.4774465560913086
Validation loss: 4.286388263907484

Epoch: 6| Step: 8
Training loss: 4.564655303955078
Validation loss: 4.262447044413577

Epoch: 6| Step: 9
Training loss: 3.6838088035583496
Validation loss: 4.242834427023447

Epoch: 6| Step: 10
Training loss: 4.895840167999268
Validation loss: 4.22170312430269

Epoch: 6| Step: 11
Training loss: 2.6628341674804688
Validation loss: 4.201368831819104

Epoch: 6| Step: 12
Training loss: 3.380265712738037
Validation loss: 4.180324949244017

Epoch: 6| Step: 13
Training loss: 4.8184661865234375
Validation loss: 4.162192611284153

Epoch: 6| Step: 0
Training loss: 5.832382678985596
Validation loss: 4.143861883430071

Epoch: 6| Step: 1
Training loss: 2.285247802734375
Validation loss: 4.124016566943097

Epoch: 6| Step: 2
Training loss: 4.08509635925293
Validation loss: 4.104031362841206

Epoch: 6| Step: 3
Training loss: 3.837359666824341
Validation loss: 4.0864139346666235

Epoch: 6| Step: 4
Training loss: 4.107295513153076
Validation loss: 4.067810884086034

Epoch: 6| Step: 5
Training loss: 5.432451248168945
Validation loss: 4.048561644810502

Epoch: 6| Step: 6
Training loss: 3.418144702911377
Validation loss: 4.029191350424162

Epoch: 6| Step: 7
Training loss: 4.122997283935547
Validation loss: 4.0130783050291

Epoch: 6| Step: 8
Training loss: 2.777980327606201
Validation loss: 3.996175632681898

Epoch: 6| Step: 9
Training loss: 3.4229555130004883
Validation loss: 3.9793030728576

Epoch: 6| Step: 10
Training loss: 3.4043641090393066
Validation loss: 3.9653502074621056

Epoch: 6| Step: 11
Training loss: 3.558281421661377
Validation loss: 3.9496662796184583

Epoch: 6| Step: 12
Training loss: 4.922791481018066
Validation loss: 3.9337695516565794

Epoch: 6| Step: 13
Training loss: 2.3535847663879395
Validation loss: 3.918517174259309

Epoch: 7| Step: 0
Training loss: 3.146841526031494
Validation loss: 3.9034922738229074

Epoch: 6| Step: 1
Training loss: 3.6210410594940186
Validation loss: 3.8884185385960404

Epoch: 6| Step: 2
Training loss: 3.281020402908325
Validation loss: 3.8749691952941236

Epoch: 6| Step: 3
Training loss: 3.3902904987335205
Validation loss: 3.861666371745448

Epoch: 6| Step: 4
Training loss: 3.8564586639404297
Validation loss: 3.848321607035975

Epoch: 6| Step: 5
Training loss: 4.777013778686523
Validation loss: 3.8326010704040527

Epoch: 6| Step: 6
Training loss: 4.036352157592773
Validation loss: 3.819951424034693

Epoch: 6| Step: 7
Training loss: 3.8832499980926514
Validation loss: 3.8058619191569667

Epoch: 6| Step: 8
Training loss: 4.109821796417236
Validation loss: 3.793763227360223

Epoch: 6| Step: 9
Training loss: 3.525160312652588
Validation loss: 3.779990703828873

Epoch: 6| Step: 10
Training loss: 3.370993137359619
Validation loss: 3.767813354410151

Epoch: 6| Step: 11
Training loss: 3.8167049884796143
Validation loss: 3.7566606690806728

Epoch: 6| Step: 12
Training loss: 2.9959301948547363
Validation loss: 3.7465850153276996

Epoch: 6| Step: 13
Training loss: 4.146529197692871
Validation loss: 3.733900308609009

Epoch: 8| Step: 0
Training loss: 3.090789556503296
Validation loss: 3.726001560047109

Epoch: 6| Step: 1
Training loss: 1.92850661277771
Validation loss: 3.714178216072821

Epoch: 6| Step: 2
Training loss: 4.173276901245117
Validation loss: 3.704638204266948

Epoch: 6| Step: 3
Training loss: 3.5089521408081055
Validation loss: 3.692837225493564

Epoch: 6| Step: 4
Training loss: 2.615893602371216
Validation loss: 3.684511682038666

Epoch: 6| Step: 5
Training loss: 3.231790781021118
Validation loss: 3.6750796456490793

Epoch: 6| Step: 6
Training loss: 3.843088150024414
Validation loss: 3.665762157850368

Epoch: 6| Step: 7
Training loss: 3.7147293090820312
Validation loss: 3.655615488688151

Epoch: 6| Step: 8
Training loss: 3.6236653327941895
Validation loss: 3.646396872817829

Epoch: 6| Step: 9
Training loss: 3.6875545978546143
Validation loss: 3.637972544598323

Epoch: 6| Step: 10
Training loss: 4.066339492797852
Validation loss: 3.6282313792936263

Epoch: 6| Step: 11
Training loss: 3.9916296005249023
Validation loss: 3.618748418746456

Epoch: 6| Step: 12
Training loss: 4.6685261726379395
Validation loss: 3.6106840359267367

Epoch: 6| Step: 13
Training loss: 3.9389123916625977
Validation loss: 3.6026924630647064

Epoch: 9| Step: 0
Training loss: 3.2495975494384766
Validation loss: 3.5945483330757386

Epoch: 6| Step: 1
Training loss: 2.9690744876861572
Validation loss: 3.5854616600980043

Epoch: 6| Step: 2
Training loss: 2.8556246757507324
Validation loss: 3.576928900134179

Epoch: 6| Step: 3
Training loss: 3.4577934741973877
Validation loss: 3.5690820729860695

Epoch: 6| Step: 4
Training loss: 3.613990306854248
Validation loss: 3.5606820993526007

Epoch: 6| Step: 5
Training loss: 2.9601938724517822
Validation loss: 3.554679719350671

Epoch: 6| Step: 6
Training loss: 2.5283043384552
Validation loss: 3.546550827641641

Epoch: 6| Step: 7
Training loss: 4.266209602355957
Validation loss: 3.541671840093469

Epoch: 6| Step: 8
Training loss: 4.0080461502075195
Validation loss: 3.534623089657035

Epoch: 6| Step: 9
Training loss: 3.411146640777588
Validation loss: 3.528216643999982

Epoch: 6| Step: 10
Training loss: 4.0943779945373535
Validation loss: 3.519003124647243

Epoch: 6| Step: 11
Training loss: 3.580763339996338
Validation loss: 3.5122669589134956

Epoch: 6| Step: 12
Training loss: 3.9485645294189453
Validation loss: 3.504508961913406

Epoch: 6| Step: 13
Training loss: 3.748448610305786
Validation loss: 3.4975932567350325

Epoch: 10| Step: 0
Training loss: 2.8210365772247314
Validation loss: 3.488234714795184

Epoch: 6| Step: 1
Training loss: 3.5651636123657227
Validation loss: 3.481483869655158

Epoch: 6| Step: 2
Training loss: 3.105682134628296
Validation loss: 3.473018487294515

Epoch: 6| Step: 3
Training loss: 3.7322001457214355
Validation loss: 3.4656161569779917

Epoch: 6| Step: 4
Training loss: 2.979922294616699
Validation loss: 3.459236908984441

Epoch: 6| Step: 5
Training loss: 4.308163166046143
Validation loss: 3.450546864540346

Epoch: 6| Step: 6
Training loss: 2.5488686561584473
Validation loss: 3.4458309296638734

Epoch: 6| Step: 7
Training loss: 4.289155960083008
Validation loss: 3.44063393018579

Epoch: 6| Step: 8
Training loss: 4.000579833984375
Validation loss: 3.4330752511178293

Epoch: 6| Step: 9
Training loss: 2.3768181800842285
Validation loss: 3.426064032380299

Epoch: 6| Step: 10
Training loss: 3.2244606018066406
Validation loss: 3.4174191977388118

Epoch: 6| Step: 11
Training loss: 3.134012460708618
Validation loss: 3.4152203631657425

Epoch: 6| Step: 12
Training loss: 3.3116726875305176
Validation loss: 3.4082654317220054

Epoch: 6| Step: 13
Training loss: 4.436378479003906
Validation loss: 3.4017125688573366

Epoch: 11| Step: 0
Training loss: 2.811833381652832
Validation loss: 3.3945992915861067

Epoch: 6| Step: 1
Training loss: 3.701566219329834
Validation loss: 3.3898384724893877

Epoch: 6| Step: 2
Training loss: 4.231822490692139
Validation loss: 3.3813274727072766

Epoch: 6| Step: 3
Training loss: 3.402308940887451
Validation loss: 3.3735414064058693

Epoch: 6| Step: 4
Training loss: 4.926511287689209
Validation loss: 3.3710876408443657

Epoch: 6| Step: 5
Training loss: 3.3028616905212402
Validation loss: 3.365159862784929

Epoch: 6| Step: 6
Training loss: 3.566987991333008
Validation loss: 3.359253365506408

Epoch: 6| Step: 7
Training loss: 2.663573741912842
Validation loss: 3.353720482959542

Epoch: 6| Step: 8
Training loss: 2.353588104248047
Validation loss: 3.3483411419776177

Epoch: 6| Step: 9
Training loss: 3.1354546546936035
Validation loss: 3.3403613080260572

Epoch: 6| Step: 10
Training loss: 2.612558603286743
Validation loss: 3.335645424422397

Epoch: 6| Step: 11
Training loss: 3.3885276317596436
Validation loss: 3.332348403110299

Epoch: 6| Step: 12
Training loss: 3.2051398754119873
Validation loss: 3.3234471633870113

Epoch: 6| Step: 13
Training loss: 2.9429073333740234
Validation loss: 3.3204231518571095

Epoch: 12| Step: 0
Training loss: 3.127084255218506
Validation loss: 3.3147752054276003

Epoch: 6| Step: 1
Training loss: 3.2572245597839355
Validation loss: 3.3092138382696334

Epoch: 6| Step: 2
Training loss: 3.6113104820251465
Validation loss: 3.301473876481415

Epoch: 6| Step: 3
Training loss: 2.607424020767212
Validation loss: 3.298892198070403

Epoch: 6| Step: 4
Training loss: 2.3738303184509277
Validation loss: 3.2931778533484346

Epoch: 6| Step: 5
Training loss: 3.968003749847412
Validation loss: 3.2891607387091524

Epoch: 6| Step: 6
Training loss: 3.618316650390625
Validation loss: 3.282891547808083

Epoch: 6| Step: 7
Training loss: 3.0808095932006836
Validation loss: 3.278540019066103

Epoch: 6| Step: 8
Training loss: 3.6622886657714844
Validation loss: 3.276090973167009

Epoch: 6| Step: 9
Training loss: 3.744960069656372
Validation loss: 3.269946082945793

Epoch: 6| Step: 10
Training loss: 2.7492990493774414
Validation loss: 3.265669681692636

Epoch: 6| Step: 11
Training loss: 3.541520118713379
Validation loss: 3.260308393868067

Epoch: 6| Step: 12
Training loss: 2.4703621864318848
Validation loss: 3.258264849262853

Epoch: 6| Step: 13
Training loss: 4.143232345581055
Validation loss: 3.2512984173272246

Epoch: 13| Step: 0
Training loss: 2.541933536529541
Validation loss: 3.2472369183776197

Epoch: 6| Step: 1
Training loss: 3.874298095703125
Validation loss: 3.2418313846793225

Epoch: 6| Step: 2
Training loss: 4.179692268371582
Validation loss: 3.2395400975340154

Epoch: 6| Step: 3
Training loss: 2.54215669631958
Validation loss: 3.235572886723344

Epoch: 6| Step: 4
Training loss: 2.853994131088257
Validation loss: 3.2305362147669636

Epoch: 6| Step: 5
Training loss: 3.9033315181732178
Validation loss: 3.228504103998984

Epoch: 6| Step: 6
Training loss: 3.1479923725128174
Validation loss: 3.225173834831484

Epoch: 6| Step: 7
Training loss: 2.7661383152008057
Validation loss: 3.2193476512867916

Epoch: 6| Step: 8
Training loss: 3.36895489692688
Validation loss: 3.218272029712636

Epoch: 6| Step: 9
Training loss: 4.268649101257324
Validation loss: 3.2117545297068935

Epoch: 6| Step: 10
Training loss: 2.226905345916748
Validation loss: 3.2056602278063373

Epoch: 6| Step: 11
Training loss: 3.169983386993408
Validation loss: 3.2035333853895946

Epoch: 6| Step: 12
Training loss: 2.8353819847106934
Validation loss: 3.197430597838535

Epoch: 6| Step: 13
Training loss: 3.3134827613830566
Validation loss: 3.1916389593514065

Epoch: 14| Step: 0
Training loss: 3.1659066677093506
Validation loss: 3.184810261572561

Epoch: 6| Step: 1
Training loss: 2.405473232269287
Validation loss: 3.1838488091704664

Epoch: 6| Step: 2
Training loss: 2.986952781677246
Validation loss: 3.1788419164637083

Epoch: 6| Step: 3
Training loss: 3.2382149696350098
Validation loss: 3.1767628244174424

Epoch: 6| Step: 4
Training loss: 3.9902451038360596
Validation loss: 3.1738640826235534

Epoch: 6| Step: 5
Training loss: 3.608504056930542
Validation loss: 3.1787829168381228

Epoch: 6| Step: 6
Training loss: 2.976107120513916
Validation loss: 3.1623486754714802

Epoch: 6| Step: 7
Training loss: 3.197784662246704
Validation loss: 3.1583919320055234

Epoch: 6| Step: 8
Training loss: 3.4120733737945557
Validation loss: 3.1563160496373333

Epoch: 6| Step: 9
Training loss: 3.404738426208496
Validation loss: 3.1530272089025027

Epoch: 6| Step: 10
Training loss: 2.4353723526000977
Validation loss: 3.1472863535727225

Epoch: 6| Step: 11
Training loss: 2.661869764328003
Validation loss: 3.147338136549919

Epoch: 6| Step: 12
Training loss: 3.3572728633880615
Validation loss: 3.143655069412724

Epoch: 6| Step: 13
Training loss: 3.6925206184387207
Validation loss: 3.1389255395499607

Epoch: 15| Step: 0
Training loss: 2.580083131790161
Validation loss: 3.136655584458382

Epoch: 6| Step: 1
Training loss: 3.952190399169922
Validation loss: 3.1313262113960842

Epoch: 6| Step: 2
Training loss: 3.195221424102783
Validation loss: 3.127722073626775

Epoch: 6| Step: 3
Training loss: 3.7605738639831543
Validation loss: 3.1262326112357517

Epoch: 6| Step: 4
Training loss: 2.8881092071533203
Validation loss: 3.1224500492054927

Epoch: 6| Step: 5
Training loss: 2.847107172012329
Validation loss: 3.119693312593686

Epoch: 6| Step: 6
Training loss: 2.053450584411621
Validation loss: 3.1165929353365334

Epoch: 6| Step: 7
Training loss: 2.19016695022583
Validation loss: 3.1141169814653296

Epoch: 6| Step: 8
Training loss: 2.9310202598571777
Validation loss: 3.1152451551088722

Epoch: 6| Step: 9
Training loss: 2.923226833343506
Validation loss: 3.1079151297128327

Epoch: 6| Step: 10
Training loss: 3.6600253582000732
Validation loss: 3.1061851055391374

Epoch: 6| Step: 11
Training loss: 3.414825201034546
Validation loss: 3.100699476016465

Epoch: 6| Step: 12
Training loss: 4.566768646240234
Validation loss: 3.099707172762963

Epoch: 6| Step: 13
Training loss: 2.722964286804199
Validation loss: 3.0963146327644266

Epoch: 16| Step: 0
Training loss: 3.5767626762390137
Validation loss: 3.0932450961041194

Epoch: 6| Step: 1
Training loss: 3.8131754398345947
Validation loss: 3.0867749029590237

Epoch: 6| Step: 2
Training loss: 4.341313362121582
Validation loss: 3.085748780158258

Epoch: 6| Step: 3
Training loss: 3.1026198863983154
Validation loss: 3.083249092102051

Epoch: 6| Step: 4
Training loss: 3.5751867294311523
Validation loss: 3.0842974109034382

Epoch: 6| Step: 5
Training loss: 2.358713150024414
Validation loss: 3.077438603165329

Epoch: 6| Step: 6
Training loss: 2.7210910320281982
Validation loss: 3.071695194449476

Epoch: 6| Step: 7
Training loss: 2.58186674118042
Validation loss: 3.068139281324161

Epoch: 6| Step: 8
Training loss: 2.5861377716064453
Validation loss: 3.0658857642963366

Epoch: 6| Step: 9
Training loss: 2.7240006923675537
Validation loss: 3.0636171756252164

Epoch: 6| Step: 10
Training loss: 2.800004482269287
Validation loss: 3.068459895349318

Epoch: 6| Step: 11
Training loss: 2.837299346923828
Validation loss: 3.0634245821224746

Epoch: 6| Step: 12
Training loss: 2.8464908599853516
Validation loss: 3.0584235396436465

Epoch: 6| Step: 13
Training loss: 4.081988334655762
Validation loss: 3.057750863413657

Epoch: 17| Step: 0
Training loss: 3.031275749206543
Validation loss: 3.050411711456955

Epoch: 6| Step: 1
Training loss: 2.7592945098876953
Validation loss: 3.0491318625788533

Epoch: 6| Step: 2
Training loss: 3.4948692321777344
Validation loss: 3.0495994885762534

Epoch: 6| Step: 3
Training loss: 3.9620776176452637
Validation loss: 3.049070417240102

Epoch: 6| Step: 4
Training loss: 3.4220385551452637
Validation loss: 3.047957920259045

Epoch: 6| Step: 5
Training loss: 3.102062225341797
Validation loss: 3.0434375398902485

Epoch: 6| Step: 6
Training loss: 3.060795307159424
Validation loss: 3.0479944752108667

Epoch: 6| Step: 7
Training loss: 2.713365077972412
Validation loss: 3.042303726237307

Epoch: 6| Step: 8
Training loss: 2.75787615776062
Validation loss: 3.0364388009553314

Epoch: 6| Step: 9
Training loss: 2.456876754760742
Validation loss: 3.0332056373678227

Epoch: 6| Step: 10
Training loss: 3.276920795440674
Validation loss: 3.0333287305729364

Epoch: 6| Step: 11
Training loss: 2.3129220008850098
Validation loss: 3.030165749211465

Epoch: 6| Step: 12
Training loss: 4.09512996673584
Validation loss: 3.028667990879346

Epoch: 6| Step: 13
Training loss: 2.547553062438965
Validation loss: 3.02905124233615

Epoch: 18| Step: 0
Training loss: 3.4554247856140137
Validation loss: 3.024976243254959

Epoch: 6| Step: 1
Training loss: 3.199246644973755
Validation loss: 3.025701666391024

Epoch: 6| Step: 2
Training loss: 2.721431016921997
Validation loss: 3.025483118590488

Epoch: 6| Step: 3
Training loss: 2.405881881713867
Validation loss: 3.0224119335092525

Epoch: 6| Step: 4
Training loss: 3.9895546436309814
Validation loss: 3.0258997281392417

Epoch: 6| Step: 5
Training loss: 2.598158836364746
Validation loss: 3.0191067367471676

Epoch: 6| Step: 6
Training loss: 2.9569191932678223
Validation loss: 3.013407548268636

Epoch: 6| Step: 7
Training loss: 3.2393829822540283
Validation loss: 3.01391105241673

Epoch: 6| Step: 8
Training loss: 2.2041616439819336
Validation loss: 3.0098753975283716

Epoch: 6| Step: 9
Training loss: 3.110832691192627
Validation loss: 3.0087062081983014

Epoch: 6| Step: 10
Training loss: 3.300898313522339
Validation loss: 3.0066415597033758

Epoch: 6| Step: 11
Training loss: 3.559460163116455
Validation loss: 3.0080696536648657

Epoch: 6| Step: 12
Training loss: 3.3289918899536133
Validation loss: 3.0025322591104815

Epoch: 6| Step: 13
Training loss: 2.762911558151245
Validation loss: 2.997503993331745

Epoch: 19| Step: 0
Training loss: 3.223971366882324
Validation loss: 2.997459824367236

Epoch: 6| Step: 1
Training loss: 2.937666893005371
Validation loss: 2.9960145155588784

Epoch: 6| Step: 2
Training loss: 3.0841031074523926
Validation loss: 2.9923990234251945

Epoch: 6| Step: 3
Training loss: 3.0354087352752686
Validation loss: 2.9891069319940384

Epoch: 6| Step: 4
Training loss: 2.340435028076172
Validation loss: 2.9905967686765935

Epoch: 6| Step: 5
Training loss: 3.3113298416137695
Validation loss: 2.994556429565594

Epoch: 6| Step: 6
Training loss: 3.6307098865509033
Validation loss: 2.9932637701752367

Epoch: 6| Step: 7
Training loss: 2.8146755695343018
Validation loss: 2.984759722986529

Epoch: 6| Step: 8
Training loss: 3.0010721683502197
Validation loss: 2.9781104441612

Epoch: 6| Step: 9
Training loss: 3.4097747802734375
Validation loss: 2.9754367643787014

Epoch: 6| Step: 10
Training loss: 3.1471030712127686
Validation loss: 2.9779501576577463

Epoch: 6| Step: 11
Training loss: 2.9899561405181885
Validation loss: 2.9782397721403386

Epoch: 6| Step: 12
Training loss: 3.1000897884368896
Validation loss: 2.9717854222943707

Epoch: 6| Step: 13
Training loss: 2.40490460395813
Validation loss: 2.9724900568685224

Epoch: 20| Step: 0
Training loss: 2.963083267211914
Validation loss: 2.9696817218616443

Epoch: 6| Step: 1
Training loss: 2.9662766456604004
Validation loss: 2.9689554347786853

Epoch: 6| Step: 2
Training loss: 3.3158507347106934
Validation loss: 2.972599103886594

Epoch: 6| Step: 3
Training loss: 2.7732534408569336
Validation loss: 2.9631776655873945

Epoch: 6| Step: 4
Training loss: 2.091301202774048
Validation loss: 2.962464763272193

Epoch: 6| Step: 5
Training loss: 3.458292007446289
Validation loss: 2.961029088625344

Epoch: 6| Step: 6
Training loss: 3.563338279724121
Validation loss: 2.962099490627166

Epoch: 6| Step: 7
Training loss: 2.700655221939087
Validation loss: 2.962808350081085

Epoch: 6| Step: 8
Training loss: 2.9900994300842285
Validation loss: 2.9683542097768476

Epoch: 6| Step: 9
Training loss: 4.278522491455078
Validation loss: 2.9651913463428454

Epoch: 6| Step: 10
Training loss: 1.4614366292953491
Validation loss: 2.959914617640998

Epoch: 6| Step: 11
Training loss: 3.103447437286377
Validation loss: 2.951896495716546

Epoch: 6| Step: 12
Training loss: 3.6091036796569824
Validation loss: 2.9481138772861932

Epoch: 6| Step: 13
Training loss: 3.320812463760376
Validation loss: 2.958647886912028

Epoch: 21| Step: 0
Training loss: 4.524945259094238
Validation loss: 2.9750975049952024

Epoch: 6| Step: 1
Training loss: 2.2926580905914307
Validation loss: 2.938331985986361

Epoch: 6| Step: 2
Training loss: 2.694054126739502
Validation loss: 2.9379543437752673

Epoch: 6| Step: 3
Training loss: 3.1543569564819336
Validation loss: 2.9348561430490143

Epoch: 6| Step: 4
Training loss: 2.884247303009033
Validation loss: 2.939311073672387

Epoch: 6| Step: 5
Training loss: 3.360501766204834
Validation loss: 2.945787868192119

Epoch: 6| Step: 6
Training loss: 3.325876474380493
Validation loss: 2.9477971446129585

Epoch: 6| Step: 7
Training loss: 3.0023269653320312
Validation loss: 2.941268418424873

Epoch: 6| Step: 8
Training loss: 3.0689620971679688
Validation loss: 2.940542080069101

Epoch: 6| Step: 9
Training loss: 3.315433979034424
Validation loss: 2.939412442586755

Epoch: 6| Step: 10
Training loss: 2.984121322631836
Validation loss: 2.933957172978309

Epoch: 6| Step: 11
Training loss: 2.3148505687713623
Validation loss: 2.930615701983052

Epoch: 6| Step: 12
Training loss: 2.3142008781433105
Validation loss: 2.9315972558913694

Epoch: 6| Step: 13
Training loss: 3.169522762298584
Validation loss: 2.929302885968198

Epoch: 22| Step: 0
Training loss: 2.950878620147705
Validation loss: 2.9294333611765215

Epoch: 6| Step: 1
Training loss: 2.78812837600708
Validation loss: 2.9289788533282537

Epoch: 6| Step: 2
Training loss: 3.0879733562469482
Validation loss: 2.9298055248875774

Epoch: 6| Step: 3
Training loss: 3.1935482025146484
Validation loss: 2.926120606801843

Epoch: 6| Step: 4
Training loss: 2.7990150451660156
Validation loss: 2.9243501565789662

Epoch: 6| Step: 5
Training loss: 2.546630382537842
Validation loss: 2.9176016084609495

Epoch: 6| Step: 6
Training loss: 3.6644175052642822
Validation loss: 2.9165323062609603

Epoch: 6| Step: 7
Training loss: 3.095536470413208
Validation loss: 2.9169474032617386

Epoch: 6| Step: 8
Training loss: 3.410520315170288
Validation loss: 2.9136935075124106

Epoch: 6| Step: 9
Training loss: 3.6142215728759766
Validation loss: 2.91623951542762

Epoch: 6| Step: 10
Training loss: 2.4008405208587646
Validation loss: 2.9071998596191406

Epoch: 6| Step: 11
Training loss: 3.341602087020874
Validation loss: 2.9068051025431645

Epoch: 6| Step: 12
Training loss: 2.703488349914551
Validation loss: 2.908640492346979

Epoch: 6| Step: 13
Training loss: 2.090456962585449
Validation loss: 2.907644015486522

Epoch: 23| Step: 0
Training loss: 2.6400790214538574
Validation loss: 2.9069016184858096

Epoch: 6| Step: 1
Training loss: 3.2439215183258057
Validation loss: 2.904742702361076

Epoch: 6| Step: 2
Training loss: 2.5958945751190186
Validation loss: 2.9001231372997327

Epoch: 6| Step: 3
Training loss: 2.9760632514953613
Validation loss: 2.898762656796363

Epoch: 6| Step: 4
Training loss: 2.58785343170166
Validation loss: 2.894577726241081

Epoch: 6| Step: 5
Training loss: 2.621885299682617
Validation loss: 2.8959750821513515

Epoch: 6| Step: 6
Training loss: 3.13358473777771
Validation loss: 2.8939603297941145

Epoch: 6| Step: 7
Training loss: 3.080040454864502
Validation loss: 2.896427680087346

Epoch: 6| Step: 8
Training loss: 3.3123440742492676
Validation loss: 2.8918956146445325

Epoch: 6| Step: 9
Training loss: 2.5448172092437744
Validation loss: 2.8876782386533675

Epoch: 6| Step: 10
Training loss: 3.0080788135528564
Validation loss: 2.887013166181503

Epoch: 6| Step: 11
Training loss: 3.2409892082214355
Validation loss: 2.8874523357678483

Epoch: 6| Step: 12
Training loss: 3.3507275581359863
Validation loss: 2.883169038321382

Epoch: 6| Step: 13
Training loss: 3.961947441101074
Validation loss: 2.8834738039201304

Epoch: 24| Step: 0
Training loss: 3.232048511505127
Validation loss: 2.880595120050574

Epoch: 6| Step: 1
Training loss: 3.0175766944885254
Validation loss: 2.877691996994839

Epoch: 6| Step: 2
Training loss: 3.8047537803649902
Validation loss: 2.879823746219758

Epoch: 6| Step: 3
Training loss: 3.4650025367736816
Validation loss: 2.8765662947008686

Epoch: 6| Step: 4
Training loss: 2.980935573577881
Validation loss: 2.8780569722575526

Epoch: 6| Step: 5
Training loss: 2.3716137409210205
Validation loss: 2.8754193167532645

Epoch: 6| Step: 6
Training loss: 3.225116014480591
Validation loss: 2.8736878928317817

Epoch: 6| Step: 7
Training loss: 3.415072441101074
Validation loss: 2.8732086407241

Epoch: 6| Step: 8
Training loss: 3.2085368633270264
Validation loss: 2.873128229571927

Epoch: 6| Step: 9
Training loss: 3.1946117877960205
Validation loss: 2.870102254293298

Epoch: 6| Step: 10
Training loss: 2.3365044593811035
Validation loss: 2.8677429665801344

Epoch: 6| Step: 11
Training loss: 2.6302361488342285
Validation loss: 2.869748338576286

Epoch: 6| Step: 12
Training loss: 2.5624327659606934
Validation loss: 2.865876487506333

Epoch: 6| Step: 13
Training loss: 1.6813130378723145
Validation loss: 2.8681165633663053

Epoch: 25| Step: 0
Training loss: 3.28810453414917
Validation loss: 2.865119400844779

Epoch: 6| Step: 1
Training loss: 1.762763261795044
Validation loss: 2.8626643483356764

Epoch: 6| Step: 2
Training loss: 2.739941358566284
Validation loss: 2.863982780005342

Epoch: 6| Step: 3
Training loss: 2.942440986633301
Validation loss: 2.868559347685947

Epoch: 6| Step: 4
Training loss: 2.497375726699829
Validation loss: 2.870095650355021

Epoch: 6| Step: 5
Training loss: 3.1899523735046387
Validation loss: 2.8698962683318765

Epoch: 6| Step: 6
Training loss: 2.6788382530212402
Validation loss: 2.864966277153261

Epoch: 6| Step: 7
Training loss: 3.109323024749756
Validation loss: 2.865720166954943

Epoch: 6| Step: 8
Training loss: 2.5996227264404297
Validation loss: 2.8636464431721675

Epoch: 6| Step: 9
Training loss: 3.282705545425415
Validation loss: 2.860592947211317

Epoch: 6| Step: 10
Training loss: 3.0451817512512207
Validation loss: 2.860028220761207

Epoch: 6| Step: 11
Training loss: 3.7460739612579346
Validation loss: 2.8558561340455086

Epoch: 6| Step: 12
Training loss: 3.713369846343994
Validation loss: 2.861723828059371

Epoch: 6| Step: 13
Training loss: 2.969414234161377
Validation loss: 2.8609063830426944

Epoch: 26| Step: 0
Training loss: 2.848060131072998
Validation loss: 2.8548573242720736

Epoch: 6| Step: 1
Training loss: 4.063276290893555
Validation loss: 2.856339305959722

Epoch: 6| Step: 2
Training loss: 2.799201488494873
Validation loss: 2.855004087571175

Epoch: 6| Step: 3
Training loss: 3.953716993331909
Validation loss: 2.8575666386594056

Epoch: 6| Step: 4
Training loss: 2.7501559257507324
Validation loss: 2.8609088467013453

Epoch: 6| Step: 5
Training loss: 2.241720199584961
Validation loss: 2.858952094149846

Epoch: 6| Step: 6
Training loss: 1.81168532371521
Validation loss: 2.8621989039964575

Epoch: 6| Step: 7
Training loss: 3.2802820205688477
Validation loss: 2.86529355408043

Epoch: 6| Step: 8
Training loss: 2.8699662685394287
Validation loss: 2.8568813749538955

Epoch: 6| Step: 9
Training loss: 2.936417818069458
Validation loss: 2.854500183495142

Epoch: 6| Step: 10
Training loss: 3.100841522216797
Validation loss: 2.8520576646251063

Epoch: 6| Step: 11
Training loss: 2.962925434112549
Validation loss: 2.8466543920578493

Epoch: 6| Step: 12
Training loss: 3.377336025238037
Validation loss: 2.849393288294474

Epoch: 6| Step: 13
Training loss: 2.184251070022583
Validation loss: 2.849777703644127

Epoch: 27| Step: 0
Training loss: 4.004378795623779
Validation loss: 2.8496858022546254

Epoch: 6| Step: 1
Training loss: 3.061703681945801
Validation loss: 2.847681337787259

Epoch: 6| Step: 2
Training loss: 2.843230962753296
Validation loss: 2.848292842988045

Epoch: 6| Step: 3
Training loss: 2.4231109619140625
Validation loss: 2.8485085579656784

Epoch: 6| Step: 4
Training loss: 2.733153820037842
Validation loss: 2.847442744880594

Epoch: 6| Step: 5
Training loss: 2.7964224815368652
Validation loss: 2.8489235754935973

Epoch: 6| Step: 6
Training loss: 2.457362651824951
Validation loss: 2.8471596266633723

Epoch: 6| Step: 7
Training loss: 2.683255195617676
Validation loss: 2.8450052366461804

Epoch: 6| Step: 8
Training loss: 3.8098623752593994
Validation loss: 2.8385945366274927

Epoch: 6| Step: 9
Training loss: 2.8823890686035156
Validation loss: 2.839638912549583

Epoch: 6| Step: 10
Training loss: 3.142765522003174
Validation loss: 2.835891359595842

Epoch: 6| Step: 11
Training loss: 3.6040430068969727
Validation loss: 2.837440865014189

Epoch: 6| Step: 12
Training loss: 2.819119691848755
Validation loss: 2.8371354687598442

Epoch: 6| Step: 13
Training loss: 1.4812099933624268
Validation loss: 2.8361102560515046

Epoch: 28| Step: 0
Training loss: 2.381014585494995
Validation loss: 2.8368683784238753

Epoch: 6| Step: 1
Training loss: 2.4426069259643555
Validation loss: 2.8387786803707

Epoch: 6| Step: 2
Training loss: 3.997020721435547
Validation loss: 2.845981559445781

Epoch: 6| Step: 3
Training loss: 2.332869052886963
Validation loss: 2.837701477030272

Epoch: 6| Step: 4
Training loss: 2.299365520477295
Validation loss: 2.8371338408480407

Epoch: 6| Step: 5
Training loss: 3.521425724029541
Validation loss: 2.832708035745928

Epoch: 6| Step: 6
Training loss: 2.6288108825683594
Validation loss: 2.8334753410790556

Epoch: 6| Step: 7
Training loss: 2.999889850616455
Validation loss: 2.832886431806831

Epoch: 6| Step: 8
Training loss: 3.722109317779541
Validation loss: 2.831135416543612

Epoch: 6| Step: 9
Training loss: 2.7399840354919434
Validation loss: 2.8307113647460938

Epoch: 6| Step: 10
Training loss: 2.7066121101379395
Validation loss: 2.830516392184842

Epoch: 6| Step: 11
Training loss: 3.1098783016204834
Validation loss: 2.828248062441426

Epoch: 6| Step: 12
Training loss: 3.0709428787231445
Validation loss: 2.8291126015365764

Epoch: 6| Step: 13
Training loss: 3.7048349380493164
Validation loss: 2.8315861712219896

Epoch: 29| Step: 0
Training loss: 3.2584123611450195
Validation loss: 2.829441337175267

Epoch: 6| Step: 1
Training loss: 1.9270304441452026
Validation loss: 2.82923323364668

Epoch: 6| Step: 2
Training loss: 3.3411765098571777
Validation loss: 2.826727972235731

Epoch: 6| Step: 3
Training loss: 3.16068172454834
Validation loss: 2.8245790414912726

Epoch: 6| Step: 4
Training loss: 2.8778791427612305
Validation loss: 2.824154523111159

Epoch: 6| Step: 5
Training loss: 3.1642749309539795
Validation loss: 2.823735498612927

Epoch: 6| Step: 6
Training loss: 3.378730297088623
Validation loss: 2.822171493243146

Epoch: 6| Step: 7
Training loss: 2.238986015319824
Validation loss: 2.8225407010765484

Epoch: 6| Step: 8
Training loss: 2.992374897003174
Validation loss: 2.821935092249224

Epoch: 6| Step: 9
Training loss: 3.2767064571380615
Validation loss: 2.825208571649367

Epoch: 6| Step: 10
Training loss: 1.9105193614959717
Validation loss: 2.823521411547097

Epoch: 6| Step: 11
Training loss: 3.2461256980895996
Validation loss: 2.8207394948569675

Epoch: 6| Step: 12
Training loss: 3.196734666824341
Validation loss: 2.819631407337804

Epoch: 6| Step: 13
Training loss: 3.526240348815918
Validation loss: 2.8172057802959154

Epoch: 30| Step: 0
Training loss: 2.677229881286621
Validation loss: 2.819527659364926

Epoch: 6| Step: 1
Training loss: 3.108565330505371
Validation loss: 2.8174473598439205

Epoch: 6| Step: 2
Training loss: 3.061953067779541
Validation loss: 2.817692323397565

Epoch: 6| Step: 3
Training loss: 2.9315185546875
Validation loss: 2.8192556083843274

Epoch: 6| Step: 4
Training loss: 3.6396360397338867
Validation loss: 2.818502290274507

Epoch: 6| Step: 5
Training loss: 2.7599754333496094
Validation loss: 2.8181687478096253

Epoch: 6| Step: 6
Training loss: 2.7637038230895996
Validation loss: 2.819773797065981

Epoch: 6| Step: 7
Training loss: 2.209188938140869
Validation loss: 2.816896310416601

Epoch: 6| Step: 8
Training loss: 2.537520170211792
Validation loss: 2.8167612116823912

Epoch: 6| Step: 9
Training loss: 2.8925132751464844
Validation loss: 2.816653169611449

Epoch: 6| Step: 10
Training loss: 3.430305004119873
Validation loss: 2.8164526672773462

Epoch: 6| Step: 11
Training loss: 3.218008518218994
Validation loss: 2.8174476187716246

Epoch: 6| Step: 12
Training loss: 2.4661335945129395
Validation loss: 2.8139405558186192

Epoch: 6| Step: 13
Training loss: 3.859646797180176
Validation loss: 2.8148097120305544

Epoch: 31| Step: 0
Training loss: 2.578874349594116
Validation loss: 2.8125467966961604

Epoch: 6| Step: 1
Training loss: 2.6426525115966797
Validation loss: 2.8111905615816832

Epoch: 6| Step: 2
Training loss: 2.38179349899292
Validation loss: 2.8098503133302093

Epoch: 6| Step: 3
Training loss: 2.4070489406585693
Validation loss: 2.8103740702393236

Epoch: 6| Step: 4
Training loss: 3.0975048542022705
Validation loss: 2.809906123786844

Epoch: 6| Step: 5
Training loss: 3.1352005004882812
Validation loss: 2.810330508857645

Epoch: 6| Step: 6
Training loss: 3.4786250591278076
Validation loss: 2.8147285548589562

Epoch: 6| Step: 7
Training loss: 3.682011365890503
Validation loss: 2.813183187156595

Epoch: 6| Step: 8
Training loss: 3.1235570907592773
Validation loss: 2.8120405289434616

Epoch: 6| Step: 9
Training loss: 2.790684700012207
Validation loss: 2.8132834460145686

Epoch: 6| Step: 10
Training loss: 2.824026584625244
Validation loss: 2.808985515307355

Epoch: 6| Step: 11
Training loss: 2.4546899795532227
Validation loss: 2.8062646517189602

Epoch: 6| Step: 12
Training loss: 3.7305405139923096
Validation loss: 2.8084066349972963

Epoch: 6| Step: 13
Training loss: 2.6223881244659424
Validation loss: 2.8068970352090816

Epoch: 32| Step: 0
Training loss: 2.147541046142578
Validation loss: 2.8056819310752292

Epoch: 6| Step: 1
Training loss: 2.9893908500671387
Validation loss: 2.8110676324495705

Epoch: 6| Step: 2
Training loss: 3.773926258087158
Validation loss: 2.815007658414943

Epoch: 6| Step: 3
Training loss: 3.3677151203155518
Validation loss: 2.8138358259713776

Epoch: 6| Step: 4
Training loss: 4.074991226196289
Validation loss: 2.8022623215952227

Epoch: 6| Step: 5
Training loss: 3.4677486419677734
Validation loss: 2.8009792399662796

Epoch: 6| Step: 6
Training loss: 2.268481492996216
Validation loss: 2.8001253579252507

Epoch: 6| Step: 7
Training loss: 2.886610507965088
Validation loss: 2.8011989747324297

Epoch: 6| Step: 8
Training loss: 2.509552001953125
Validation loss: 2.802896730361446

Epoch: 6| Step: 9
Training loss: 3.9695985317230225
Validation loss: 2.8005174770150134

Epoch: 6| Step: 10
Training loss: 2.75993275642395
Validation loss: 2.798965233628468

Epoch: 6| Step: 11
Training loss: 2.251530885696411
Validation loss: 2.7977181019321566

Epoch: 6| Step: 12
Training loss: 2.1668615341186523
Validation loss: 2.798103483774329

Epoch: 6| Step: 13
Training loss: 1.9711672067642212
Validation loss: 2.7976926219078804

Epoch: 33| Step: 0
Training loss: 2.828545570373535
Validation loss: 2.7971772173399567

Epoch: 6| Step: 1
Training loss: 3.489633321762085
Validation loss: 2.798085287053098

Epoch: 6| Step: 2
Training loss: 2.8604185581207275
Validation loss: 2.7984223186328845

Epoch: 6| Step: 3
Training loss: 2.9543533325195312
Validation loss: 2.7972367066209034

Epoch: 6| Step: 4
Training loss: 2.6460185050964355
Validation loss: 2.7994071258011686

Epoch: 6| Step: 5
Training loss: 3.1264617443084717
Validation loss: 2.7971997953230336

Epoch: 6| Step: 6
Training loss: 2.5041890144348145
Validation loss: 2.800371439226212

Epoch: 6| Step: 7
Training loss: 3.590277910232544
Validation loss: 2.7957066207803707

Epoch: 6| Step: 8
Training loss: 3.5586721897125244
Validation loss: 2.7952779416115052

Epoch: 6| Step: 9
Training loss: 3.0694515705108643
Validation loss: 2.796986245339917

Epoch: 6| Step: 10
Training loss: 3.002103805541992
Validation loss: 2.7928663351202525

Epoch: 6| Step: 11
Training loss: 1.965003252029419
Validation loss: 2.7926533850290443

Epoch: 6| Step: 12
Training loss: 2.356145143508911
Validation loss: 2.793219686836325

Epoch: 6| Step: 13
Training loss: 3.1485376358032227
Validation loss: 2.7950712096306587

Epoch: 34| Step: 0
Training loss: 2.9121694564819336
Validation loss: 2.7958840913670038

Epoch: 6| Step: 1
Training loss: 2.9276137351989746
Validation loss: 2.7942618144455778

Epoch: 6| Step: 2
Training loss: 2.838900089263916
Validation loss: 2.791844150071503

Epoch: 6| Step: 3
Training loss: 2.7656283378601074
Validation loss: 2.791792390167072

Epoch: 6| Step: 4
Training loss: 2.894886016845703
Validation loss: 2.7936226885805846

Epoch: 6| Step: 5
Training loss: 2.703881025314331
Validation loss: 2.7900763993622153

Epoch: 6| Step: 6
Training loss: 2.4157867431640625
Validation loss: 2.79145537653277

Epoch: 6| Step: 7
Training loss: 2.905221700668335
Validation loss: 2.7892361199983986

Epoch: 6| Step: 8
Training loss: 3.3274734020233154
Validation loss: 2.7908429125303864

Epoch: 6| Step: 9
Training loss: 3.7637887001037598
Validation loss: 2.7889713651390484

Epoch: 6| Step: 10
Training loss: 2.921746253967285
Validation loss: 2.7904317660998275

Epoch: 6| Step: 11
Training loss: 2.7420430183410645
Validation loss: 2.7886835836595103

Epoch: 6| Step: 12
Training loss: 3.1191883087158203
Validation loss: 2.793299492969308

Epoch: 6| Step: 13
Training loss: 2.512301206588745
Validation loss: 2.791178777653684

Epoch: 35| Step: 0
Training loss: 2.7046377658843994
Validation loss: 2.785384967762937

Epoch: 6| Step: 1
Training loss: 3.6381776332855225
Validation loss: 2.7832432818669144

Epoch: 6| Step: 2
Training loss: 3.1702535152435303
Validation loss: 2.7858306413055747

Epoch: 6| Step: 3
Training loss: 2.528902053833008
Validation loss: 2.785068868308939

Epoch: 6| Step: 4
Training loss: 3.4437637329101562
Validation loss: 2.7839006505986696

Epoch: 6| Step: 5
Training loss: 2.6646997928619385
Validation loss: 2.7842748934222805

Epoch: 6| Step: 6
Training loss: 1.7097276449203491
Validation loss: 2.784057891497048

Epoch: 6| Step: 7
Training loss: 3.38576602935791
Validation loss: 2.7827817342614614

Epoch: 6| Step: 8
Training loss: 2.5147948265075684
Validation loss: 2.781510594070599

Epoch: 6| Step: 9
Training loss: 3.320077657699585
Validation loss: 2.7808980070134646

Epoch: 6| Step: 10
Training loss: 2.775402069091797
Validation loss: 2.7795566410146733

Epoch: 6| Step: 11
Training loss: 2.9416654109954834
Validation loss: 2.782344771969703

Epoch: 6| Step: 12
Training loss: 2.8697714805603027
Validation loss: 2.7790959573561147

Epoch: 6| Step: 13
Training loss: 3.440290689468384
Validation loss: 2.7816111426199637

Epoch: 36| Step: 0
Training loss: 3.05902099609375
Validation loss: 2.779571710094329

Epoch: 6| Step: 1
Training loss: 3.1591458320617676
Validation loss: 2.779171451445549

Epoch: 6| Step: 2
Training loss: 3.368748188018799
Validation loss: 2.778233353809644

Epoch: 6| Step: 3
Training loss: 1.947225570678711
Validation loss: 2.7774073975060576

Epoch: 6| Step: 4
Training loss: 1.933506965637207
Validation loss: 2.7765409049167427

Epoch: 6| Step: 5
Training loss: 2.632796287536621
Validation loss: 2.7778913410761024

Epoch: 6| Step: 6
Training loss: 2.2228288650512695
Validation loss: 2.7783083428618727

Epoch: 6| Step: 7
Training loss: 3.6710901260375977
Validation loss: 2.7785542011260986

Epoch: 6| Step: 8
Training loss: 2.934293746948242
Validation loss: 2.7790309562478015

Epoch: 6| Step: 9
Training loss: 2.886622428894043
Validation loss: 2.775660537904309

Epoch: 6| Step: 10
Training loss: 3.319718599319458
Validation loss: 2.776114479187996

Epoch: 6| Step: 11
Training loss: 3.477749824523926
Validation loss: 2.7726508519982778

Epoch: 6| Step: 12
Training loss: 3.158702850341797
Validation loss: 2.773953227586644

Epoch: 6| Step: 13
Training loss: 3.1515932083129883
Validation loss: 2.7723282921698784

Epoch: 37| Step: 0
Training loss: 3.1367218494415283
Validation loss: 2.771489989372992

Epoch: 6| Step: 1
Training loss: 2.6655545234680176
Validation loss: 2.769872719241727

Epoch: 6| Step: 2
Training loss: 2.7302513122558594
Validation loss: 2.7696321266953663

Epoch: 6| Step: 3
Training loss: 3.624406576156616
Validation loss: 2.7677821625945387

Epoch: 6| Step: 4
Training loss: 2.8103842735290527
Validation loss: 2.7712072633927867

Epoch: 6| Step: 5
Training loss: 2.0549373626708984
Validation loss: 2.7840200188339397

Epoch: 6| Step: 6
Training loss: 3.2499656677246094
Validation loss: 2.7685651753538396

Epoch: 6| Step: 7
Training loss: 2.75787091255188
Validation loss: 2.7647196118549635

Epoch: 6| Step: 8
Training loss: 2.9621877670288086
Validation loss: 2.765657937654885

Epoch: 6| Step: 9
Training loss: 3.088061809539795
Validation loss: 2.765569107506865

Epoch: 6| Step: 10
Training loss: 2.6684679985046387
Validation loss: 2.765859760263915

Epoch: 6| Step: 11
Training loss: 2.8030943870544434
Validation loss: 2.767176156402916

Epoch: 6| Step: 12
Training loss: 3.606411933898926
Validation loss: 2.76583694898954

Epoch: 6| Step: 13
Training loss: 2.273221015930176
Validation loss: 2.7650356984907583

Epoch: 38| Step: 0
Training loss: 2.702002763748169
Validation loss: 2.7649942751853698

Epoch: 6| Step: 1
Training loss: 2.5997610092163086
Validation loss: 2.7652491369555072

Epoch: 6| Step: 2
Training loss: 2.218897819519043
Validation loss: 2.7642541828975884

Epoch: 6| Step: 3
Training loss: 2.291538715362549
Validation loss: 2.764881410906392

Epoch: 6| Step: 4
Training loss: 2.7133920192718506
Validation loss: 2.763032651716663

Epoch: 6| Step: 5
Training loss: 3.6816909313201904
Validation loss: 2.763679381339781

Epoch: 6| Step: 6
Training loss: 3.155669689178467
Validation loss: 2.7612457121572187

Epoch: 6| Step: 7
Training loss: 3.65183162689209
Validation loss: 2.761833098626906

Epoch: 6| Step: 8
Training loss: 3.03995418548584
Validation loss: 2.760651739694739

Epoch: 6| Step: 9
Training loss: 2.800394296646118
Validation loss: 2.7606509603479856

Epoch: 6| Step: 10
Training loss: 2.7166924476623535
Validation loss: 2.759718302757509

Epoch: 6| Step: 11
Training loss: 3.5089547634124756
Validation loss: 2.758201683721235

Epoch: 6| Step: 12
Training loss: 3.0448760986328125
Validation loss: 2.75704030324054

Epoch: 6| Step: 13
Training loss: 2.21228289604187
Validation loss: 2.7608554645251204

Epoch: 39| Step: 0
Training loss: 2.930424690246582
Validation loss: 2.760353406270345

Epoch: 6| Step: 1
Training loss: 2.3092586994171143
Validation loss: 2.7546473318530666

Epoch: 6| Step: 2
Training loss: 3.3258309364318848
Validation loss: 2.7566646991237516

Epoch: 6| Step: 3
Training loss: 2.4202780723571777
Validation loss: 2.758659703757173

Epoch: 6| Step: 4
Training loss: 3.1630868911743164
Validation loss: 2.7537513804692093

Epoch: 6| Step: 5
Training loss: 1.8245925903320312
Validation loss: 2.75492028779881

Epoch: 6| Step: 6
Training loss: 3.3544740676879883
Validation loss: 2.7571403493163404

Epoch: 6| Step: 7
Training loss: 3.225553512573242
Validation loss: 2.7557095686594644

Epoch: 6| Step: 8
Training loss: 2.978536605834961
Validation loss: 2.7585257663521716

Epoch: 6| Step: 9
Training loss: 2.8789401054382324
Validation loss: 2.7558998882129626

Epoch: 6| Step: 10
Training loss: 3.453134775161743
Validation loss: 2.7565134853445072

Epoch: 6| Step: 11
Training loss: 3.0525104999542236
Validation loss: 2.7543022401871218

Epoch: 6| Step: 12
Training loss: 2.9112071990966797
Validation loss: 2.7509707635448826

Epoch: 6| Step: 13
Training loss: 2.6459405422210693
Validation loss: 2.749910675069337

Epoch: 40| Step: 0
Training loss: 3.088435173034668
Validation loss: 2.7507785545882357

Epoch: 6| Step: 1
Training loss: 3.2068662643432617
Validation loss: 2.749438173027449

Epoch: 6| Step: 2
Training loss: 2.6586713790893555
Validation loss: 2.747752061454199

Epoch: 6| Step: 3
Training loss: 3.1899890899658203
Validation loss: 2.745087690250848

Epoch: 6| Step: 4
Training loss: 2.438901662826538
Validation loss: 2.74718669409393

Epoch: 6| Step: 5
Training loss: 3.0528743267059326
Validation loss: 2.748470913979315

Epoch: 6| Step: 6
Training loss: 2.0818238258361816
Validation loss: 2.7462355039452993

Epoch: 6| Step: 7
Training loss: 3.2707834243774414
Validation loss: 2.747860159925235

Epoch: 6| Step: 8
Training loss: 3.2759156227111816
Validation loss: 2.7461529470259145

Epoch: 6| Step: 9
Training loss: 2.4074182510375977
Validation loss: 2.7462355039452993

Epoch: 6| Step: 10
Training loss: 3.4586691856384277
Validation loss: 2.7464237136225544

Epoch: 6| Step: 11
Training loss: 3.0521273612976074
Validation loss: 2.7505662928345385

Epoch: 6| Step: 12
Training loss: 2.390368938446045
Validation loss: 2.7472211776241178

Epoch: 6| Step: 13
Training loss: 2.9982731342315674
Validation loss: 2.743536538975213

Epoch: 41| Step: 0
Training loss: 3.446049928665161
Validation loss: 2.7418022027579685

Epoch: 6| Step: 1
Training loss: 2.704768657684326
Validation loss: 2.741582780755976

Epoch: 6| Step: 2
Training loss: 2.933581829071045
Validation loss: 2.7425751173368065

Epoch: 6| Step: 3
Training loss: 2.789893865585327
Validation loss: 2.7418879129553355

Epoch: 6| Step: 4
Training loss: 3.0497167110443115
Validation loss: 2.74424974636365

Epoch: 6| Step: 5
Training loss: 2.940506935119629
Validation loss: 2.742735557658698

Epoch: 6| Step: 6
Training loss: 3.0944814682006836
Validation loss: 2.740620864334927

Epoch: 6| Step: 7
Training loss: 3.252863883972168
Validation loss: 2.7422234383962487

Epoch: 6| Step: 8
Training loss: 1.8467570543289185
Validation loss: 2.7398804413375033

Epoch: 6| Step: 9
Training loss: 2.3101630210876465
Validation loss: 2.7387756327147126

Epoch: 6| Step: 10
Training loss: 3.5695223808288574
Validation loss: 2.740383061029578

Epoch: 6| Step: 11
Training loss: 3.1642544269561768
Validation loss: 2.738774258603332

Epoch: 6| Step: 12
Training loss: 2.726032257080078
Validation loss: 2.7409213537810952

Epoch: 6| Step: 13
Training loss: 2.4195268154144287
Validation loss: 2.7327442399917112

Epoch: 42| Step: 0
Training loss: 2.8694353103637695
Validation loss: 2.738298452028664

Epoch: 6| Step: 1
Training loss: 2.514805793762207
Validation loss: 2.738353019119591

Epoch: 6| Step: 2
Training loss: 3.5924572944641113
Validation loss: 2.7344392243252007

Epoch: 6| Step: 3
Training loss: 2.6805026531219482
Validation loss: 2.73471478749347

Epoch: 6| Step: 4
Training loss: 1.6118279695510864
Validation loss: 2.7325433813115603

Epoch: 6| Step: 5
Training loss: 3.392608165740967
Validation loss: 2.7319620117064445

Epoch: 6| Step: 6
Training loss: 2.3716607093811035
Validation loss: 2.729703708361554

Epoch: 6| Step: 7
Training loss: 3.6437950134277344
Validation loss: 2.728085143591768

Epoch: 6| Step: 8
Training loss: 3.6614670753479004
Validation loss: 2.7270200585806244

Epoch: 6| Step: 9
Training loss: 3.6700644493103027
Validation loss: 2.728179839349562

Epoch: 6| Step: 10
Training loss: 2.1085267066955566
Validation loss: 2.725850769268569

Epoch: 6| Step: 11
Training loss: 2.966660499572754
Validation loss: 2.727660779030092

Epoch: 6| Step: 12
Training loss: 2.4032578468322754
Validation loss: 2.7302580366852465

Epoch: 6| Step: 13
Training loss: 2.8506367206573486
Validation loss: 2.729704608199417

Epoch: 43| Step: 0
Training loss: 2.5427358150482178
Validation loss: 2.727584772212531

Epoch: 6| Step: 1
Training loss: 2.0585834980010986
Validation loss: 2.7277052735769622

Epoch: 6| Step: 2
Training loss: 2.9602808952331543
Validation loss: 2.7289804950837167

Epoch: 6| Step: 3
Training loss: 2.3504111766815186
Validation loss: 2.7268512633539017

Epoch: 6| Step: 4
Training loss: 2.844430446624756
Validation loss: 2.724700520115514

Epoch: 6| Step: 5
Training loss: 3.176980495452881
Validation loss: 2.7258457496602047

Epoch: 6| Step: 6
Training loss: 2.8522157669067383
Validation loss: 2.724287102299352

Epoch: 6| Step: 7
Training loss: 3.121413230895996
Validation loss: 2.7235007721890687

Epoch: 6| Step: 8
Training loss: 3.75763201713562
Validation loss: 2.721888639593637

Epoch: 6| Step: 9
Training loss: 3.0868849754333496
Validation loss: 2.7234402010517735

Epoch: 6| Step: 10
Training loss: 3.697323799133301
Validation loss: 2.71956269971786

Epoch: 6| Step: 11
Training loss: 3.0602293014526367
Validation loss: 2.723892814369612

Epoch: 6| Step: 12
Training loss: 2.010057210922241
Validation loss: 2.7699452882171958

Epoch: 6| Step: 13
Training loss: 2.8194220066070557
Validation loss: 2.7620171936609412

Epoch: 44| Step: 0
Training loss: 2.9705657958984375
Validation loss: 2.780491413608674

Epoch: 6| Step: 1
Training loss: 1.856024980545044
Validation loss: 2.7590903518020466

Epoch: 6| Step: 2
Training loss: 3.626854658126831
Validation loss: 2.736265241458852

Epoch: 6| Step: 3
Training loss: 3.4898087978363037
Validation loss: 2.725597338009906

Epoch: 6| Step: 4
Training loss: 2.6995110511779785
Validation loss: 2.723266460562265

Epoch: 6| Step: 5
Training loss: 2.996392250061035
Validation loss: 2.7234790914802143

Epoch: 6| Step: 6
Training loss: 2.904170036315918
Validation loss: 2.722069045548798

Epoch: 6| Step: 7
Training loss: 2.6070921421051025
Validation loss: 2.724792975251393

Epoch: 6| Step: 8
Training loss: 2.8384358882904053
Validation loss: 2.718513268296437

Epoch: 6| Step: 9
Training loss: 3.2453484535217285
Validation loss: 2.720309688198951

Epoch: 6| Step: 10
Training loss: 3.332150459289551
Validation loss: 2.7208907552944717

Epoch: 6| Step: 11
Training loss: 2.3848347663879395
Validation loss: 2.7250861326853433

Epoch: 6| Step: 12
Training loss: 2.6082544326782227
Validation loss: 2.72642376858701

Epoch: 6| Step: 13
Training loss: 2.642622709274292
Validation loss: 2.7278219653714086

Epoch: 45| Step: 0
Training loss: 3.0546436309814453
Validation loss: 2.7267366557992916

Epoch: 6| Step: 1
Training loss: 2.3537685871124268
Validation loss: 2.7260728574568227

Epoch: 6| Step: 2
Training loss: 2.540255308151245
Validation loss: 2.724012521005446

Epoch: 6| Step: 3
Training loss: 3.261247158050537
Validation loss: 2.724443215195851

Epoch: 6| Step: 4
Training loss: 2.879513740539551
Validation loss: 2.7182113880752237

Epoch: 6| Step: 5
Training loss: 3.829930305480957
Validation loss: 2.7235088886753207

Epoch: 6| Step: 6
Training loss: 2.0458292961120605
Validation loss: 2.721635377535256

Epoch: 6| Step: 7
Training loss: 3.067141056060791
Validation loss: 2.721350162259994

Epoch: 6| Step: 8
Training loss: 2.2916221618652344
Validation loss: 2.7203048659909155

Epoch: 6| Step: 9
Training loss: 3.438509225845337
Validation loss: 2.7175384670175533

Epoch: 6| Step: 10
Training loss: 2.649911403656006
Validation loss: 2.715699957263085

Epoch: 6| Step: 11
Training loss: 2.6181509494781494
Validation loss: 2.7163232244471067

Epoch: 6| Step: 12
Training loss: 3.6274964809417725
Validation loss: 2.720497336438907

Epoch: 6| Step: 13
Training loss: 2.386298656463623
Validation loss: 2.7176656338476364

Epoch: 46| Step: 0
Training loss: 2.531583547592163
Validation loss: 2.718342537521034

Epoch: 6| Step: 1
Training loss: 2.6997616291046143
Validation loss: 2.7197717697389665

Epoch: 6| Step: 2
Training loss: 2.670039415359497
Validation loss: 2.719167745241555

Epoch: 6| Step: 3
Training loss: 3.1401047706604004
Validation loss: 2.7168392827433925

Epoch: 6| Step: 4
Training loss: 3.589630603790283
Validation loss: 2.71633719628857

Epoch: 6| Step: 5
Training loss: 3.3594741821289062
Validation loss: 2.716866124060846

Epoch: 6| Step: 6
Training loss: 2.5483996868133545
Validation loss: 2.7179752549817486

Epoch: 6| Step: 7
Training loss: 3.197518825531006
Validation loss: 2.7186339016883605

Epoch: 6| Step: 8
Training loss: 2.483281135559082
Validation loss: 2.7181326804622525

Epoch: 6| Step: 9
Training loss: 3.4140677452087402
Validation loss: 2.7166843081033356

Epoch: 6| Step: 10
Training loss: 2.4051008224487305
Validation loss: 2.7180482033760316

Epoch: 6| Step: 11
Training loss: 2.3383078575134277
Validation loss: 2.7194214123551563

Epoch: 6| Step: 12
Training loss: 3.2116198539733887
Validation loss: 2.7170915193455194

Epoch: 6| Step: 13
Training loss: 2.4303181171417236
Validation loss: 2.714435254373858

Epoch: 47| Step: 0
Training loss: 3.108217716217041
Validation loss: 2.7135862227409118

Epoch: 6| Step: 1
Training loss: 3.1824283599853516
Validation loss: 2.713372471512005

Epoch: 6| Step: 2
Training loss: 2.07981538772583
Validation loss: 2.712021558515487

Epoch: 6| Step: 3
Training loss: 2.3426342010498047
Validation loss: 2.709268100800053

Epoch: 6| Step: 4
Training loss: 2.8374884128570557
Validation loss: 2.71191390099064

Epoch: 6| Step: 5
Training loss: 2.9664101600646973
Validation loss: 2.7090466817220054

Epoch: 6| Step: 6
Training loss: 1.6283677816390991
Validation loss: 2.707121995187575

Epoch: 6| Step: 7
Training loss: 3.5902702808380127
Validation loss: 2.7086355122186805

Epoch: 6| Step: 8
Training loss: 3.9430503845214844
Validation loss: 2.709687150934691

Epoch: 6| Step: 9
Training loss: 3.5526087284088135
Validation loss: 2.7087829318097842

Epoch: 6| Step: 10
Training loss: 2.823040008544922
Validation loss: 2.7118705113728843

Epoch: 6| Step: 11
Training loss: 2.978503465652466
Validation loss: 2.7081324746531825

Epoch: 6| Step: 12
Training loss: 2.521790027618408
Validation loss: 2.7092718693517868

Epoch: 6| Step: 13
Training loss: 2.4223101139068604
Validation loss: 2.707189075408443

Epoch: 48| Step: 0
Training loss: 3.2339820861816406
Validation loss: 2.7044387632800686

Epoch: 6| Step: 1
Training loss: 2.75791597366333
Validation loss: 2.705347148321008

Epoch: 6| Step: 2
Training loss: 2.532398223876953
Validation loss: 2.707254684099587

Epoch: 6| Step: 3
Training loss: 2.96712064743042
Validation loss: 2.7055627120438444

Epoch: 6| Step: 4
Training loss: 2.0890932083129883
Validation loss: 2.7033202981436126

Epoch: 6| Step: 5
Training loss: 2.4211864471435547
Validation loss: 2.706233027160809

Epoch: 6| Step: 6
Training loss: 2.577810287475586
Validation loss: 2.7067232285776446

Epoch: 6| Step: 7
Training loss: 2.491593837738037
Validation loss: 2.70526550662133

Epoch: 6| Step: 8
Training loss: 3.8164544105529785
Validation loss: 2.7052967010005826

Epoch: 6| Step: 9
Training loss: 3.04353928565979
Validation loss: 2.708341008873396

Epoch: 6| Step: 10
Training loss: 2.807828426361084
Validation loss: 2.7069297964854906

Epoch: 6| Step: 11
Training loss: 2.767021417617798
Validation loss: 2.7092128415261545

Epoch: 6| Step: 12
Training loss: 3.3655741214752197
Validation loss: 2.7144285350717525

Epoch: 6| Step: 13
Training loss: 3.5232226848602295
Validation loss: 2.7146022729976202

Epoch: 49| Step: 0
Training loss: 2.9234228134155273
Validation loss: 2.7121522272786787

Epoch: 6| Step: 1
Training loss: 3.0395007133483887
Validation loss: 2.710496599956225

Epoch: 6| Step: 2
Training loss: 3.2133255004882812
Validation loss: 2.7121736362416256

Epoch: 6| Step: 3
Training loss: 2.7730119228363037
Validation loss: 2.7148611776290403

Epoch: 6| Step: 4
Training loss: 2.234861373901367
Validation loss: 2.7135905296571794

Epoch: 6| Step: 5
Training loss: 2.4591383934020996
Validation loss: 2.710210374606553

Epoch: 6| Step: 6
Training loss: 2.6364030838012695
Validation loss: 2.7063549077639015

Epoch: 6| Step: 7
Training loss: 3.8192849159240723
Validation loss: 2.7087542908166045

Epoch: 6| Step: 8
Training loss: 2.570791721343994
Validation loss: 2.707249605527488

Epoch: 6| Step: 9
Training loss: 3.018016815185547
Validation loss: 2.7051314487252185

Epoch: 6| Step: 10
Training loss: 3.4694409370422363
Validation loss: 2.7044578521482405

Epoch: 6| Step: 11
Training loss: 2.1070008277893066
Validation loss: 2.7050888051268873

Epoch: 6| Step: 12
Training loss: 2.986830711364746
Validation loss: 2.701708878240278

Epoch: 6| Step: 13
Training loss: 2.708184003829956
Validation loss: 2.704196822258734

Epoch: 50| Step: 0
Training loss: 3.630279064178467
Validation loss: 2.703668245705225

Epoch: 6| Step: 1
Training loss: 2.3825316429138184
Validation loss: 2.705804365937428

Epoch: 6| Step: 2
Training loss: 2.1843605041503906
Validation loss: 2.714800283473025

Epoch: 6| Step: 3
Training loss: 2.5068917274475098
Validation loss: 2.712685723458567

Epoch: 6| Step: 4
Training loss: 3.2464370727539062
Validation loss: 2.7132206245135237

Epoch: 6| Step: 5
Training loss: 2.8917369842529297
Validation loss: 2.7077182672357045

Epoch: 6| Step: 6
Training loss: 2.0837535858154297
Validation loss: 2.701009904184649

Epoch: 6| Step: 7
Training loss: 3.1622257232666016
Validation loss: 2.700830962068291

Epoch: 6| Step: 8
Training loss: 2.8331594467163086
Validation loss: 2.697658695200438

Epoch: 6| Step: 9
Training loss: 3.508713960647583
Validation loss: 2.6973768331671275

Epoch: 6| Step: 10
Training loss: 2.752960205078125
Validation loss: 2.6982029304709485

Epoch: 6| Step: 11
Training loss: 2.75577712059021
Validation loss: 2.701220497008293

Epoch: 6| Step: 12
Training loss: 2.9618749618530273
Validation loss: 2.706116332802721

Epoch: 6| Step: 13
Training loss: 3.439401865005493
Validation loss: 2.70291228448191

Epoch: 51| Step: 0
Training loss: 2.6298108100891113
Validation loss: 2.7086852981198217

Epoch: 6| Step: 1
Training loss: 1.8067357540130615
Validation loss: 2.7105261587327525

Epoch: 6| Step: 2
Training loss: 2.6882009506225586
Validation loss: 2.715935032854798

Epoch: 6| Step: 3
Training loss: 2.8066959381103516
Validation loss: 2.7091761789014264

Epoch: 6| Step: 4
Training loss: 3.1830997467041016
Validation loss: 2.704447495040073

Epoch: 6| Step: 5
Training loss: 3.1086103916168213
Validation loss: 2.69976411327239

Epoch: 6| Step: 6
Training loss: 3.7634081840515137
Validation loss: 2.696765617657733

Epoch: 6| Step: 7
Training loss: 2.084214687347412
Validation loss: 2.6959152375498125

Epoch: 6| Step: 8
Training loss: 2.3269479274749756
Validation loss: 2.6964229076139388

Epoch: 6| Step: 9
Training loss: 3.7313590049743652
Validation loss: 2.6946988541592836

Epoch: 6| Step: 10
Training loss: 2.7506752014160156
Validation loss: 2.6954652109453754

Epoch: 6| Step: 11
Training loss: 3.0215749740600586
Validation loss: 2.6947787218196417

Epoch: 6| Step: 12
Training loss: 2.633819103240967
Validation loss: 2.6944210606236614

Epoch: 6| Step: 13
Training loss: 3.93390154838562
Validation loss: 2.6960035062605336

Epoch: 52| Step: 0
Training loss: 2.4155383110046387
Validation loss: 2.69805476486042

Epoch: 6| Step: 1
Training loss: 3.193361759185791
Validation loss: 2.6950779499546176

Epoch: 6| Step: 2
Training loss: 2.260986328125
Validation loss: 2.6960364362244964

Epoch: 6| Step: 3
Training loss: 2.6093924045562744
Validation loss: 2.6962542354419665

Epoch: 6| Step: 4
Training loss: 3.335153818130493
Validation loss: 2.6937135829720447

Epoch: 6| Step: 5
Training loss: 3.1039907932281494
Validation loss: 2.6944880382989043

Epoch: 6| Step: 6
Training loss: 3.0647759437561035
Validation loss: 2.6911774655824066

Epoch: 6| Step: 7
Training loss: 2.535104274749756
Validation loss: 2.6934103760668027

Epoch: 6| Step: 8
Training loss: 2.8715736865997314
Validation loss: 2.6964929257669756

Epoch: 6| Step: 9
Training loss: 3.7958693504333496
Validation loss: 2.691655961416101

Epoch: 6| Step: 10
Training loss: 2.206503391265869
Validation loss: 2.693902225904567

Epoch: 6| Step: 11
Training loss: 2.1625170707702637
Validation loss: 2.6907595613951325

Epoch: 6| Step: 12
Training loss: 3.3394837379455566
Validation loss: 2.692484999215731

Epoch: 6| Step: 13
Training loss: 3.2316794395446777
Validation loss: 2.699764661891486

Epoch: 53| Step: 0
Training loss: 2.79434871673584
Validation loss: 2.704653092609939

Epoch: 6| Step: 1
Training loss: 3.2533376216888428
Validation loss: 2.7054405289311565

Epoch: 6| Step: 2
Training loss: 2.722508668899536
Validation loss: 2.7009998700952016

Epoch: 6| Step: 3
Training loss: 2.6897246837615967
Validation loss: 2.7000906313619306

Epoch: 6| Step: 4
Training loss: 3.0593528747558594
Validation loss: 2.7021083216513357

Epoch: 6| Step: 5
Training loss: 2.7303693294525146
Validation loss: 2.6946418541733936

Epoch: 6| Step: 6
Training loss: 2.226687431335449
Validation loss: 2.6905644709064114

Epoch: 6| Step: 7
Training loss: 3.6899876594543457
Validation loss: 2.6888753137280865

Epoch: 6| Step: 8
Training loss: 2.167494297027588
Validation loss: 2.6866873515549528

Epoch: 6| Step: 9
Training loss: 3.091026782989502
Validation loss: 2.6876618118696314

Epoch: 6| Step: 10
Training loss: 3.1322543621063232
Validation loss: 2.6899316054518505

Epoch: 6| Step: 11
Training loss: 2.114506244659424
Validation loss: 2.6891615698414464

Epoch: 6| Step: 12
Training loss: 3.0414717197418213
Validation loss: 2.691624754218645

Epoch: 6| Step: 13
Training loss: 3.4296159744262695
Validation loss: 2.6931471209372244

Epoch: 54| Step: 0
Training loss: 2.7154760360717773
Validation loss: 2.68697444341516

Epoch: 6| Step: 1
Training loss: 2.8919498920440674
Validation loss: 2.6909882740307878

Epoch: 6| Step: 2
Training loss: 2.7594804763793945
Validation loss: 2.6866289902758855

Epoch: 6| Step: 3
Training loss: 2.5094492435455322
Validation loss: 2.6827266011186826

Epoch: 6| Step: 4
Training loss: 3.129209041595459
Validation loss: 2.6848506850581013

Epoch: 6| Step: 5
Training loss: 2.665236473083496
Validation loss: 2.6848484880180767

Epoch: 6| Step: 6
Training loss: 3.2750940322875977
Validation loss: 2.6870877717130925

Epoch: 6| Step: 7
Training loss: 2.663630962371826
Validation loss: 2.685243083584693

Epoch: 6| Step: 8
Training loss: 2.7007641792297363
Validation loss: 2.6884870247174333

Epoch: 6| Step: 9
Training loss: 2.929746150970459
Validation loss: 2.6919704944856706

Epoch: 6| Step: 10
Training loss: 2.797356605529785
Validation loss: 2.6867852236634944

Epoch: 6| Step: 11
Training loss: 3.4820475578308105
Validation loss: 2.6910443331605647

Epoch: 6| Step: 12
Training loss: 2.7335798740386963
Validation loss: 2.6917806158783617

Epoch: 6| Step: 13
Training loss: 2.4600589275360107
Validation loss: 2.68474474517248

Epoch: 55| Step: 0
Training loss: 2.6106505393981934
Validation loss: 2.6823356664308937

Epoch: 6| Step: 1
Training loss: 2.180969476699829
Validation loss: 2.6838749326685423

Epoch: 6| Step: 2
Training loss: 2.877552032470703
Validation loss: 2.682517892570906

Epoch: 6| Step: 3
Training loss: 4.0566864013671875
Validation loss: 2.682741747107557

Epoch: 6| Step: 4
Training loss: 3.4362854957580566
Validation loss: 2.681586821873983

Epoch: 6| Step: 5
Training loss: 2.9314815998077393
Validation loss: 2.6813015963441584

Epoch: 6| Step: 6
Training loss: 2.244805097579956
Validation loss: 2.6811836740022064

Epoch: 6| Step: 7
Training loss: 3.358799934387207
Validation loss: 2.684322923742315

Epoch: 6| Step: 8
Training loss: 2.5546681880950928
Validation loss: 2.6805015815201627

Epoch: 6| Step: 9
Training loss: 2.2313528060913086
Validation loss: 2.6882469730992473

Epoch: 6| Step: 10
Training loss: 3.1226537227630615
Validation loss: 2.692098991845244

Epoch: 6| Step: 11
Training loss: 3.0805490016937256
Validation loss: 2.6904542856318976

Epoch: 6| Step: 12
Training loss: 2.21401309967041
Validation loss: 2.68936494088942

Epoch: 6| Step: 13
Training loss: 2.968266725540161
Validation loss: 2.6825826808970463

Epoch: 56| Step: 0
Training loss: 2.2409121990203857
Validation loss: 2.6931650612943914

Epoch: 6| Step: 1
Training loss: 3.32159423828125
Validation loss: 2.6818359564709406

Epoch: 6| Step: 2
Training loss: 2.774890661239624
Validation loss: 2.6857813353179605

Epoch: 6| Step: 3
Training loss: 2.9521093368530273
Validation loss: 2.6921818076923327

Epoch: 6| Step: 4
Training loss: 3.133688449859619
Validation loss: 2.6919772394241823

Epoch: 6| Step: 5
Training loss: 2.838343381881714
Validation loss: 2.685144021946897

Epoch: 6| Step: 6
Training loss: 2.176241397857666
Validation loss: 2.6854096843350317

Epoch: 6| Step: 7
Training loss: 3.1384663581848145
Validation loss: 2.681376975069764

Epoch: 6| Step: 8
Training loss: 3.758908748626709
Validation loss: 2.6827935505938787

Epoch: 6| Step: 9
Training loss: 3.214843273162842
Validation loss: 2.6820601109535462

Epoch: 6| Step: 10
Training loss: 2.1933183670043945
Validation loss: 2.6818836171139955

Epoch: 6| Step: 11
Training loss: 2.8754372596740723
Validation loss: 2.6826117243818057

Epoch: 6| Step: 12
Training loss: 2.585554599761963
Validation loss: 2.6842856073892243

Epoch: 6| Step: 13
Training loss: 2.4289660453796387
Validation loss: 2.6807324373593895

Epoch: 57| Step: 0
Training loss: 3.036527633666992
Validation loss: 2.681573083323817

Epoch: 6| Step: 1
Training loss: 2.6389355659484863
Validation loss: 2.6756197124399166

Epoch: 6| Step: 2
Training loss: 2.701021194458008
Validation loss: 2.6776387332588114

Epoch: 6| Step: 3
Training loss: 2.5381698608398438
Validation loss: 2.6787871494088122

Epoch: 6| Step: 4
Training loss: 2.876138687133789
Validation loss: 2.6805844563309864

Epoch: 6| Step: 5
Training loss: 3.093324661254883
Validation loss: 2.683401902516683

Epoch: 6| Step: 6
Training loss: 2.431668758392334
Validation loss: 2.689016557508899

Epoch: 6| Step: 7
Training loss: 2.5479910373687744
Validation loss: 2.6883273765604985

Epoch: 6| Step: 8
Training loss: 3.720172643661499
Validation loss: 2.6923155579515683

Epoch: 6| Step: 9
Training loss: 2.368133068084717
Validation loss: 2.690025103989468

Epoch: 6| Step: 10
Training loss: 2.7534923553466797
Validation loss: 2.691983304997926

Epoch: 6| Step: 11
Training loss: 2.9745230674743652
Validation loss: 2.6831642145751626

Epoch: 6| Step: 12
Training loss: 3.025693416595459
Validation loss: 2.6864773278595298

Epoch: 6| Step: 13
Training loss: 3.2313077449798584
Validation loss: 2.6814565299659647

Epoch: 58| Step: 0
Training loss: 3.0137646198272705
Validation loss: 2.6832101575789915

Epoch: 6| Step: 1
Training loss: 2.6755871772766113
Validation loss: 2.6782567090885614

Epoch: 6| Step: 2
Training loss: 2.6478896141052246
Validation loss: 2.680557973923222

Epoch: 6| Step: 3
Training loss: 3.0456862449645996
Validation loss: 2.6805132435214136

Epoch: 6| Step: 4
Training loss: 2.350926399230957
Validation loss: 2.679581411423222

Epoch: 6| Step: 5
Training loss: 3.292233467102051
Validation loss: 2.671839234649494

Epoch: 6| Step: 6
Training loss: 3.4636332988739014
Validation loss: 2.6741660769267748

Epoch: 6| Step: 7
Training loss: 2.8665783405303955
Validation loss: 2.675012396227929

Epoch: 6| Step: 8
Training loss: 3.159559965133667
Validation loss: 2.6697534233011226

Epoch: 6| Step: 9
Training loss: 2.5822644233703613
Validation loss: 2.669259809678601

Epoch: 6| Step: 10
Training loss: 2.5784037113189697
Validation loss: 2.6703300168437343

Epoch: 6| Step: 11
Training loss: 2.516292095184326
Validation loss: 2.6718302080708165

Epoch: 6| Step: 12
Training loss: 3.208527088165283
Validation loss: 2.677491844341319

Epoch: 6| Step: 13
Training loss: 1.9186227321624756
Validation loss: 2.679590294438024

Epoch: 59| Step: 0
Training loss: 2.4172656536102295
Validation loss: 2.681138277053833

Epoch: 6| Step: 1
Training loss: 3.308684825897217
Validation loss: 2.6768385723072994

Epoch: 6| Step: 2
Training loss: 2.1263632774353027
Validation loss: 2.674439776328302

Epoch: 6| Step: 3
Training loss: 2.5563652515411377
Validation loss: 2.669426202774048

Epoch: 6| Step: 4
Training loss: 2.915182590484619
Validation loss: 2.671430423695554

Epoch: 6| Step: 5
Training loss: 2.4911561012268066
Validation loss: 2.6682940503602386

Epoch: 6| Step: 6
Training loss: 2.8457298278808594
Validation loss: 2.6682628457264235

Epoch: 6| Step: 7
Training loss: 2.667304039001465
Validation loss: 2.66697096824646

Epoch: 6| Step: 8
Training loss: 2.801741600036621
Validation loss: 2.667352138027068

Epoch: 6| Step: 9
Training loss: 3.3514323234558105
Validation loss: 2.670355266140353

Epoch: 6| Step: 10
Training loss: 2.761262893676758
Validation loss: 2.668145006702792

Epoch: 6| Step: 11
Training loss: 3.1166152954101562
Validation loss: 2.666825996932163

Epoch: 6| Step: 12
Training loss: 3.052076578140259
Validation loss: 2.6683462435199368

Epoch: 6| Step: 13
Training loss: 3.595733165740967
Validation loss: 2.6636401812235513

Epoch: 60| Step: 0
Training loss: 3.630974531173706
Validation loss: 2.66144230545208

Epoch: 6| Step: 1
Training loss: 1.844518780708313
Validation loss: 2.664513485406035

Epoch: 6| Step: 2
Training loss: 3.2231833934783936
Validation loss: 2.6640451338983353

Epoch: 6| Step: 3
Training loss: 2.568934202194214
Validation loss: 2.665043200215986

Epoch: 6| Step: 4
Training loss: 3.409055233001709
Validation loss: 2.669190240162675

Epoch: 6| Step: 5
Training loss: 2.868468761444092
Validation loss: 2.6649895252720004

Epoch: 6| Step: 6
Training loss: 2.6726536750793457
Validation loss: 2.6664811026665474

Epoch: 6| Step: 7
Training loss: 3.4326961040496826
Validation loss: 2.667701708373203

Epoch: 6| Step: 8
Training loss: 2.2117698192596436
Validation loss: 2.677084517735307

Epoch: 6| Step: 9
Training loss: 2.0751914978027344
Validation loss: 2.6855956969722623

Epoch: 6| Step: 10
Training loss: 3.3483657836914062
Validation loss: 2.6916552410330823

Epoch: 6| Step: 11
Training loss: 2.8459157943725586
Validation loss: 2.6904053124048377

Epoch: 6| Step: 12
Training loss: 2.8952813148498535
Validation loss: 2.6766948597405547

Epoch: 6| Step: 13
Training loss: 2.3791768550872803
Validation loss: 2.6702512925670994

Epoch: 61| Step: 0
Training loss: 3.502747058868408
Validation loss: 2.66369875015751

Epoch: 6| Step: 1
Training loss: 2.765834331512451
Validation loss: 2.66315354839448

Epoch: 6| Step: 2
Training loss: 3.038715362548828
Validation loss: 2.6602801533155542

Epoch: 6| Step: 3
Training loss: 3.124753952026367
Validation loss: 2.659412419924172

Epoch: 6| Step: 4
Training loss: 2.171078681945801
Validation loss: 2.6610734334556003

Epoch: 6| Step: 5
Training loss: 2.8240444660186768
Validation loss: 2.6600122195418163

Epoch: 6| Step: 6
Training loss: 2.9270801544189453
Validation loss: 2.6597153268834597

Epoch: 6| Step: 7
Training loss: 2.191941738128662
Validation loss: 2.658592462539673

Epoch: 6| Step: 8
Training loss: 2.949174642562866
Validation loss: 2.6613686776930288

Epoch: 6| Step: 9
Training loss: 2.5628182888031006
Validation loss: 2.6615093574729016

Epoch: 6| Step: 10
Training loss: 2.4306247234344482
Validation loss: 2.663508184494511

Epoch: 6| Step: 11
Training loss: 2.399588108062744
Validation loss: 2.666089847523679

Epoch: 6| Step: 12
Training loss: 3.10982084274292
Validation loss: 2.6708338696469545

Epoch: 6| Step: 13
Training loss: 4.020011901855469
Validation loss: 2.6665339828819357

Epoch: 62| Step: 0
Training loss: 2.7912793159484863
Validation loss: 2.668488317920316

Epoch: 6| Step: 1
Training loss: 2.825995445251465
Validation loss: 2.667693896960187

Epoch: 6| Step: 2
Training loss: 3.6985507011413574
Validation loss: 2.66538603075089

Epoch: 6| Step: 3
Training loss: 2.915247678756714
Validation loss: 2.6637460954727663

Epoch: 6| Step: 4
Training loss: 2.424145460128784
Validation loss: 2.6631613726256997

Epoch: 6| Step: 5
Training loss: 2.5809521675109863
Validation loss: 2.659531057521861

Epoch: 6| Step: 6
Training loss: 2.5625479221343994
Validation loss: 2.6582804187651603

Epoch: 6| Step: 7
Training loss: 2.2486393451690674
Validation loss: 2.6590740937058643

Epoch: 6| Step: 8
Training loss: 3.1045637130737305
Validation loss: 2.6576526600827455

Epoch: 6| Step: 9
Training loss: 3.461555004119873
Validation loss: 2.6591155734113467

Epoch: 6| Step: 10
Training loss: 2.318932056427002
Validation loss: 2.655473965470509

Epoch: 6| Step: 11
Training loss: 3.0365042686462402
Validation loss: 2.6570474255469536

Epoch: 6| Step: 12
Training loss: 2.912696361541748
Validation loss: 2.6571756639788227

Epoch: 6| Step: 13
Training loss: 2.3542211055755615
Validation loss: 2.658779562160533

Epoch: 63| Step: 0
Training loss: 2.747885227203369
Validation loss: 2.656047723626578

Epoch: 6| Step: 1
Training loss: 2.873002529144287
Validation loss: 2.6578897506959978

Epoch: 6| Step: 2
Training loss: 2.3335256576538086
Validation loss: 2.665259704794935

Epoch: 6| Step: 3
Training loss: 3.4558825492858887
Validation loss: 2.666009041570848

Epoch: 6| Step: 4
Training loss: 2.403784990310669
Validation loss: 2.668129733813706

Epoch: 6| Step: 5
Training loss: 3.198421001434326
Validation loss: 2.6676310339281635

Epoch: 6| Step: 6
Training loss: 2.7062642574310303
Validation loss: 2.661283746842415

Epoch: 6| Step: 7
Training loss: 2.6574556827545166
Validation loss: 2.6614746278332126

Epoch: 6| Step: 8
Training loss: 2.124156951904297
Validation loss: 2.662939974056777

Epoch: 6| Step: 9
Training loss: 3.20745849609375
Validation loss: 2.6598657151704193

Epoch: 6| Step: 10
Training loss: 3.3751561641693115
Validation loss: 2.6607656953155354

Epoch: 6| Step: 11
Training loss: 2.6773815155029297
Validation loss: 2.6631720630071496

Epoch: 6| Step: 12
Training loss: 2.35491943359375
Validation loss: 2.658963172666488

Epoch: 6| Step: 13
Training loss: 3.8272085189819336
Validation loss: 2.65469434953505

Epoch: 64| Step: 0
Training loss: 2.8879642486572266
Validation loss: 2.6498418725946897

Epoch: 6| Step: 1
Training loss: 2.7943434715270996
Validation loss: 2.6514095926797516

Epoch: 6| Step: 2
Training loss: 2.466012954711914
Validation loss: 2.652413275934035

Epoch: 6| Step: 3
Training loss: 2.0413193702697754
Validation loss: 2.65221139436127

Epoch: 6| Step: 4
Training loss: 3.70753812789917
Validation loss: 2.651616152896676

Epoch: 6| Step: 5
Training loss: 2.4882829189300537
Validation loss: 2.656366845612885

Epoch: 6| Step: 6
Training loss: 2.9928321838378906
Validation loss: 2.6547803827511367

Epoch: 6| Step: 7
Training loss: 2.959418296813965
Validation loss: 2.6550448709918606

Epoch: 6| Step: 8
Training loss: 2.5010547637939453
Validation loss: 2.6578823366472797

Epoch: 6| Step: 9
Training loss: 2.9535486698150635
Validation loss: 2.651788370583647

Epoch: 6| Step: 10
Training loss: 3.016042709350586
Validation loss: 2.6558714348782777

Epoch: 6| Step: 11
Training loss: 2.194286346435547
Validation loss: 2.647071989633704

Epoch: 6| Step: 12
Training loss: 3.145145893096924
Validation loss: 2.6468559542009906

Epoch: 6| Step: 13
Training loss: 3.709425210952759
Validation loss: 2.6512971770378853

Epoch: 65| Step: 0
Training loss: 2.9048964977264404
Validation loss: 2.656561860474207

Epoch: 6| Step: 1
Training loss: 3.508209466934204
Validation loss: 2.6594638696280857

Epoch: 6| Step: 2
Training loss: 3.1482300758361816
Validation loss: 2.657619550663938

Epoch: 6| Step: 3
Training loss: 2.540924310684204
Validation loss: 2.6540438898148073

Epoch: 6| Step: 4
Training loss: 2.0393011569976807
Validation loss: 2.655574611438218

Epoch: 6| Step: 5
Training loss: 2.7310516834259033
Validation loss: 2.6531034567022838

Epoch: 6| Step: 6
Training loss: 3.2672712802886963
Validation loss: 2.655602583321192

Epoch: 6| Step: 7
Training loss: 2.9863319396972656
Validation loss: 2.651635523765318

Epoch: 6| Step: 8
Training loss: 2.0396969318389893
Validation loss: 2.6550946158747517

Epoch: 6| Step: 9
Training loss: 2.413325071334839
Validation loss: 2.6523672175663773

Epoch: 6| Step: 10
Training loss: 2.294370651245117
Validation loss: 2.655675736806726

Epoch: 6| Step: 11
Training loss: 2.5625433921813965
Validation loss: 2.6521416838451097

Epoch: 6| Step: 12
Training loss: 3.611666679382324
Validation loss: 2.6514109667911323

Epoch: 6| Step: 13
Training loss: 3.6670749187469482
Validation loss: 2.6489264375420025

Epoch: 66| Step: 0
Training loss: 2.374647617340088
Validation loss: 2.644335498091995

Epoch: 6| Step: 1
Training loss: 3.1359081268310547
Validation loss: 2.6447218682176326

Epoch: 6| Step: 2
Training loss: 3.329948902130127
Validation loss: 2.645342448706268

Epoch: 6| Step: 3
Training loss: 2.6049623489379883
Validation loss: 2.6423851213147564

Epoch: 6| Step: 4
Training loss: 2.3838906288146973
Validation loss: 2.644746488140475

Epoch: 6| Step: 5
Training loss: 2.3910844326019287
Validation loss: 2.6436429049379084

Epoch: 6| Step: 6
Training loss: 3.0400805473327637
Validation loss: 2.643545801921557

Epoch: 6| Step: 7
Training loss: 2.838014602661133
Validation loss: 2.644798004499046

Epoch: 6| Step: 8
Training loss: 2.9311461448669434
Validation loss: 2.64037767276969

Epoch: 6| Step: 9
Training loss: 3.094557046890259
Validation loss: 2.6452600186870945

Epoch: 6| Step: 10
Training loss: 2.7610182762145996
Validation loss: 2.6416623900013585

Epoch: 6| Step: 11
Training loss: 2.7336418628692627
Validation loss: 2.645292530777634

Epoch: 6| Step: 12
Training loss: 3.0635292530059814
Validation loss: 2.6429525267693306

Epoch: 6| Step: 13
Training loss: 2.53478741645813
Validation loss: 2.64252362456373

Epoch: 67| Step: 0
Training loss: 2.3337364196777344
Validation loss: 2.6401587417048793

Epoch: 6| Step: 1
Training loss: 3.4975881576538086
Validation loss: 2.640058425164992

Epoch: 6| Step: 2
Training loss: 3.0243277549743652
Validation loss: 2.640378026552098

Epoch: 6| Step: 3
Training loss: 2.783703327178955
Validation loss: 2.638955100890129

Epoch: 6| Step: 4
Training loss: 2.7389185428619385
Validation loss: 2.6385737285819104

Epoch: 6| Step: 5
Training loss: 3.196733236312866
Validation loss: 2.640489629519883

Epoch: 6| Step: 6
Training loss: 1.7847050428390503
Validation loss: 2.637692460449793

Epoch: 6| Step: 7
Training loss: 2.3587751388549805
Validation loss: 2.6410710683432956

Epoch: 6| Step: 8
Training loss: 2.556572198867798
Validation loss: 2.643602991616854

Epoch: 6| Step: 9
Training loss: 2.8885350227355957
Validation loss: 2.646032025737147

Epoch: 6| Step: 10
Training loss: 3.4118595123291016
Validation loss: 2.6524631489989576

Epoch: 6| Step: 11
Training loss: 2.493525505065918
Validation loss: 2.6584926830824984

Epoch: 6| Step: 12
Training loss: 3.0806291103363037
Validation loss: 2.6636724702773558

Epoch: 6| Step: 13
Training loss: 3.3182668685913086
Validation loss: 2.6589737220477034

Epoch: 68| Step: 0
Training loss: 3.0455026626586914
Validation loss: 2.647291962818433

Epoch: 6| Step: 1
Training loss: 2.0353338718414307
Validation loss: 2.657173643830002

Epoch: 6| Step: 2
Training loss: 2.4657065868377686
Validation loss: 2.6612656962487007

Epoch: 6| Step: 3
Training loss: 3.2681407928466797
Validation loss: 2.664960133132114

Epoch: 6| Step: 4
Training loss: 2.617069721221924
Validation loss: 2.673027128301641

Epoch: 6| Step: 5
Training loss: 2.6332602500915527
Validation loss: 2.668495329477454

Epoch: 6| Step: 6
Training loss: 2.3466055393218994
Validation loss: 2.6588285994786087

Epoch: 6| Step: 7
Training loss: 3.3995230197906494
Validation loss: 2.653890550777476

Epoch: 6| Step: 8
Training loss: 2.2456493377685547
Validation loss: 2.640392872595018

Epoch: 6| Step: 9
Training loss: 2.8181121349334717
Validation loss: 2.636661970487205

Epoch: 6| Step: 10
Training loss: 3.2508816719055176
Validation loss: 2.6348782803422663

Epoch: 6| Step: 11
Training loss: 3.769981622695923
Validation loss: 2.633940963334935

Epoch: 6| Step: 12
Training loss: 2.469014883041382
Validation loss: 2.6358801293116745

Epoch: 6| Step: 13
Training loss: 2.9098215103149414
Validation loss: 2.635982346791093

Epoch: 69| Step: 0
Training loss: 2.400737762451172
Validation loss: 2.640401981210196

Epoch: 6| Step: 1
Training loss: 2.6202280521392822
Validation loss: 2.6376930103507092

Epoch: 6| Step: 2
Training loss: 2.965428352355957
Validation loss: 2.637765493444217

Epoch: 6| Step: 3
Training loss: 2.7287979125976562
Validation loss: 2.6420652276726178

Epoch: 6| Step: 4
Training loss: 2.8226442337036133
Validation loss: 2.6408416455791843

Epoch: 6| Step: 5
Training loss: 3.1743946075439453
Validation loss: 2.637969773302796

Epoch: 6| Step: 6
Training loss: 2.250547409057617
Validation loss: 2.6370443477425525

Epoch: 6| Step: 7
Training loss: 3.128638982772827
Validation loss: 2.6381858420628372

Epoch: 6| Step: 8
Training loss: 2.5009560585021973
Validation loss: 2.634444982774796

Epoch: 6| Step: 9
Training loss: 3.337109088897705
Validation loss: 2.633709748586019

Epoch: 6| Step: 10
Training loss: 3.0071794986724854
Validation loss: 2.6359916271701938

Epoch: 6| Step: 11
Training loss: 2.9062483310699463
Validation loss: 2.632477375768846

Epoch: 6| Step: 12
Training loss: 3.25852370262146
Validation loss: 2.6332826870743946

Epoch: 6| Step: 13
Training loss: 1.6654962301254272
Validation loss: 2.6344031262141403

Epoch: 70| Step: 0
Training loss: 3.3995625972747803
Validation loss: 2.6333921212022022

Epoch: 6| Step: 1
Training loss: 1.723684549331665
Validation loss: 2.634099539890084

Epoch: 6| Step: 2
Training loss: 2.877220869064331
Validation loss: 2.6372549738935245

Epoch: 6| Step: 3
Training loss: 2.8454999923706055
Validation loss: 2.6414530072160947

Epoch: 6| Step: 4
Training loss: 2.8298656940460205
Validation loss: 2.639015902755081

Epoch: 6| Step: 5
Training loss: 3.497971296310425
Validation loss: 2.6438965720515095

Epoch: 6| Step: 6
Training loss: 2.5442798137664795
Validation loss: 2.642251491546631

Epoch: 6| Step: 7
Training loss: 2.6185574531555176
Validation loss: 2.642375943481281

Epoch: 6| Step: 8
Training loss: 2.942333698272705
Validation loss: 2.641500311513101

Epoch: 6| Step: 9
Training loss: 2.0628340244293213
Validation loss: 2.6437013995262886

Epoch: 6| Step: 10
Training loss: 3.3419089317321777
Validation loss: 2.6316660655442106

Epoch: 6| Step: 11
Training loss: 2.730422019958496
Validation loss: 2.6308142882521435

Epoch: 6| Step: 12
Training loss: 3.0201072692871094
Validation loss: 2.625822328752087

Epoch: 6| Step: 13
Training loss: 2.7063798904418945
Validation loss: 2.6245403776886644

Epoch: 71| Step: 0
Training loss: 2.618542194366455
Validation loss: 2.622494295079221

Epoch: 6| Step: 1
Training loss: 2.6327009201049805
Validation loss: 2.624736411597139

Epoch: 6| Step: 2
Training loss: 3.3461878299713135
Validation loss: 2.6224038344557568

Epoch: 6| Step: 3
Training loss: 2.579486131668091
Validation loss: 2.6273422689848047

Epoch: 6| Step: 4
Training loss: 2.2993056774139404
Validation loss: 2.623775161722655

Epoch: 6| Step: 5
Training loss: 2.669266700744629
Validation loss: 2.6265559222108577

Epoch: 6| Step: 6
Training loss: 2.856832265853882
Validation loss: 2.62575852230031

Epoch: 6| Step: 7
Training loss: 3.0023908615112305
Validation loss: 2.625377698611188

Epoch: 6| Step: 8
Training loss: 2.707756996154785
Validation loss: 2.6239191255261822

Epoch: 6| Step: 9
Training loss: 2.251997470855713
Validation loss: 2.6267114429063696

Epoch: 6| Step: 10
Training loss: 2.5747365951538086
Validation loss: 2.6260419994272213

Epoch: 6| Step: 11
Training loss: 3.598137140274048
Validation loss: 2.6278928633659118

Epoch: 6| Step: 12
Training loss: 2.7965304851531982
Validation loss: 2.62635987804782

Epoch: 6| Step: 13
Training loss: 3.460892915725708
Validation loss: 2.626716547114875

Epoch: 72| Step: 0
Training loss: 2.7392630577087402
Validation loss: 2.6333406638073664

Epoch: 6| Step: 1
Training loss: 2.9233460426330566
Validation loss: 2.631684334047379

Epoch: 6| Step: 2
Training loss: 3.8699965476989746
Validation loss: 2.6288617477622083

Epoch: 6| Step: 3
Training loss: 2.4123215675354004
Validation loss: 2.62508967614943

Epoch: 6| Step: 4
Training loss: 3.2291407585144043
Validation loss: 2.6233645895475983

Epoch: 6| Step: 5
Training loss: 2.9277000427246094
Validation loss: 2.620571750466542

Epoch: 6| Step: 6
Training loss: 2.5412185192108154
Validation loss: 2.6213660727265062

Epoch: 6| Step: 7
Training loss: 2.609447479248047
Validation loss: 2.625025300569432

Epoch: 6| Step: 8
Training loss: 2.6031696796417236
Validation loss: 2.6276651249136975

Epoch: 6| Step: 9
Training loss: 2.814629077911377
Validation loss: 2.6270526070748605

Epoch: 6| Step: 10
Training loss: 2.520059108734131
Validation loss: 2.633088150332051

Epoch: 6| Step: 11
Training loss: 2.517620801925659
Validation loss: 2.635241631538637

Epoch: 6| Step: 12
Training loss: 2.5739521980285645
Validation loss: 2.6388500531514487

Epoch: 6| Step: 13
Training loss: 2.833932399749756
Validation loss: 2.634208661253734

Epoch: 73| Step: 0
Training loss: 2.734020233154297
Validation loss: 2.6314035948886665

Epoch: 6| Step: 1
Training loss: 2.652658224105835
Validation loss: 2.631311165389194

Epoch: 6| Step: 2
Training loss: 2.934464931488037
Validation loss: 2.6266420041361163

Epoch: 6| Step: 3
Training loss: 2.8507091999053955
Validation loss: 2.6209833160523446

Epoch: 6| Step: 4
Training loss: 2.6125199794769287
Validation loss: 2.6208138055698846

Epoch: 6| Step: 5
Training loss: 2.6982975006103516
Validation loss: 2.6180988024639826

Epoch: 6| Step: 6
Training loss: 2.137934923171997
Validation loss: 2.616984777553107

Epoch: 6| Step: 7
Training loss: 4.113819122314453
Validation loss: 2.6154237511337444

Epoch: 6| Step: 8
Training loss: 2.405646324157715
Validation loss: 2.6177500140282417

Epoch: 6| Step: 9
Training loss: 2.889969825744629
Validation loss: 2.617525298108337

Epoch: 6| Step: 10
Training loss: 2.731271505355835
Validation loss: 2.6145895757982807

Epoch: 6| Step: 11
Training loss: 2.866546630859375
Validation loss: 2.6193702092734714

Epoch: 6| Step: 12
Training loss: 2.8227481842041016
Validation loss: 2.6167569314279864

Epoch: 6| Step: 13
Training loss: 2.520955801010132
Validation loss: 2.614148234808317

Epoch: 74| Step: 0
Training loss: 3.223978281021118
Validation loss: 2.6187323857379217

Epoch: 6| Step: 1
Training loss: 2.81374192237854
Validation loss: 2.6183828000099427

Epoch: 6| Step: 2
Training loss: 2.8443474769592285
Validation loss: 2.6178034326081634

Epoch: 6| Step: 3
Training loss: 2.886355400085449
Validation loss: 2.6151488109301497

Epoch: 6| Step: 4
Training loss: 1.8943870067596436
Validation loss: 2.61509039837827

Epoch: 6| Step: 5
Training loss: 2.406864643096924
Validation loss: 2.6142194860724994

Epoch: 6| Step: 6
Training loss: 3.7433300018310547
Validation loss: 2.6172859181639967

Epoch: 6| Step: 7
Training loss: 3.0410237312316895
Validation loss: 2.6158704911508868

Epoch: 6| Step: 8
Training loss: 1.6431567668914795
Validation loss: 2.6146961950486705

Epoch: 6| Step: 9
Training loss: 3.0309433937072754
Validation loss: 2.6130453489160024

Epoch: 6| Step: 10
Training loss: 2.683671474456787
Validation loss: 2.6106140075191373

Epoch: 6| Step: 11
Training loss: 2.798600435256958
Validation loss: 2.612645923450429

Epoch: 6| Step: 12
Training loss: 3.280027389526367
Validation loss: 2.615788908414943

Epoch: 6| Step: 13
Training loss: 2.543820858001709
Validation loss: 2.6217191270602647

Epoch: 75| Step: 0
Training loss: 2.221529483795166
Validation loss: 2.6200511352990263

Epoch: 6| Step: 1
Training loss: 2.339293956756592
Validation loss: 2.620200052056261

Epoch: 6| Step: 2
Training loss: 2.6685290336608887
Validation loss: 2.6213231689186505

Epoch: 6| Step: 3
Training loss: 2.6025471687316895
Validation loss: 2.614818642216344

Epoch: 6| Step: 4
Training loss: 3.0647315979003906
Validation loss: 2.617217681741202

Epoch: 6| Step: 5
Training loss: 2.700775146484375
Validation loss: 2.6150482469989407

Epoch: 6| Step: 6
Training loss: 2.4092230796813965
Validation loss: 2.6177807982249925

Epoch: 6| Step: 7
Training loss: 2.5881943702697754
Validation loss: 2.6145216418850805

Epoch: 6| Step: 8
Training loss: 3.0209059715270996
Validation loss: 2.615657347504811

Epoch: 6| Step: 9
Training loss: 3.151353597640991
Validation loss: 2.6185808540672384

Epoch: 6| Step: 10
Training loss: 2.4955403804779053
Validation loss: 2.6164319592137493

Epoch: 6| Step: 11
Training loss: 2.67056941986084
Validation loss: 2.6237273318793184

Epoch: 6| Step: 12
Training loss: 4.095005989074707
Validation loss: 2.6248737048077326

Epoch: 6| Step: 13
Training loss: 3.0259978771209717
Validation loss: 2.627590028188562

Epoch: 76| Step: 0
Training loss: 1.527522325515747
Validation loss: 2.625345053211335

Epoch: 6| Step: 1
Training loss: 2.6904406547546387
Validation loss: 2.6190702043553835

Epoch: 6| Step: 2
Training loss: 2.6574954986572266
Validation loss: 2.6181486909107496

Epoch: 6| Step: 3
Training loss: 3.2830569744110107
Validation loss: 2.614174163469704

Epoch: 6| Step: 4
Training loss: 3.0951058864593506
Validation loss: 2.6193092407718783

Epoch: 6| Step: 5
Training loss: 3.464195966720581
Validation loss: 2.614114620352304

Epoch: 6| Step: 6
Training loss: 2.5430920124053955
Validation loss: 2.608976061626147

Epoch: 6| Step: 7
Training loss: 3.486339807510376
Validation loss: 2.61098466637314

Epoch: 6| Step: 8
Training loss: 2.6404263973236084
Validation loss: 2.610194593347529

Epoch: 6| Step: 9
Training loss: 2.8678483963012695
Validation loss: 2.6132292875679592

Epoch: 6| Step: 10
Training loss: 2.506395101547241
Validation loss: 2.6104484065886466

Epoch: 6| Step: 11
Training loss: 2.4024064540863037
Validation loss: 2.61392411621668

Epoch: 6| Step: 12
Training loss: 3.1601192951202393
Validation loss: 2.6111046447548816

Epoch: 6| Step: 13
Training loss: 2.5389790534973145
Validation loss: 2.6069310980458416

Epoch: 77| Step: 0
Training loss: 2.6013989448547363
Validation loss: 2.6085545093782487

Epoch: 6| Step: 1
Training loss: 3.084179401397705
Validation loss: 2.6086254068600234

Epoch: 6| Step: 2
Training loss: 2.2611217498779297
Validation loss: 2.6101169714363675

Epoch: 6| Step: 3
Training loss: 2.9733567237854004
Validation loss: 2.607697679150489

Epoch: 6| Step: 4
Training loss: 2.349959373474121
Validation loss: 2.606148612114691

Epoch: 6| Step: 5
Training loss: 2.620711088180542
Validation loss: 2.6059188945319063

Epoch: 6| Step: 6
Training loss: 2.1238315105438232
Validation loss: 2.6082426886404715

Epoch: 6| Step: 7
Training loss: 3.349112033843994
Validation loss: 2.6044200005069857

Epoch: 6| Step: 8
Training loss: 2.8040108680725098
Validation loss: 2.6080980198357695

Epoch: 6| Step: 9
Training loss: 2.97632098197937
Validation loss: 2.607334183108422

Epoch: 6| Step: 10
Training loss: 4.038925647735596
Validation loss: 2.608115775610811

Epoch: 6| Step: 11
Training loss: 2.3554139137268066
Validation loss: 2.6100597894319923

Epoch: 6| Step: 12
Training loss: 2.8850691318511963
Validation loss: 2.6081213438382713

Epoch: 6| Step: 13
Training loss: 2.242248773574829
Validation loss: 2.6072291302424606

Epoch: 78| Step: 0
Training loss: 2.7908225059509277
Validation loss: 2.6038813180820917

Epoch: 6| Step: 1
Training loss: 3.953612804412842
Validation loss: 2.601793037947788

Epoch: 6| Step: 2
Training loss: 3.5522451400756836
Validation loss: 2.601647441105176

Epoch: 6| Step: 3
Training loss: 3.6117355823516846
Validation loss: 2.6030200886470016

Epoch: 6| Step: 4
Training loss: 1.8335378170013428
Validation loss: 2.6010590445610786

Epoch: 6| Step: 5
Training loss: 2.447732448577881
Validation loss: 2.59929968080213

Epoch: 6| Step: 6
Training loss: 2.1690409183502197
Validation loss: 2.6031366727685414

Epoch: 6| Step: 7
Training loss: 2.1679978370666504
Validation loss: 2.602849009216473

Epoch: 6| Step: 8
Training loss: 1.8298484086990356
Validation loss: 2.602952677716491

Epoch: 6| Step: 9
Training loss: 2.9444167613983154
Validation loss: 2.6051663608961206

Epoch: 6| Step: 10
Training loss: 3.096250534057617
Validation loss: 2.6046443780263266

Epoch: 6| Step: 11
Training loss: 2.5098419189453125
Validation loss: 2.5977666044747956

Epoch: 6| Step: 12
Training loss: 3.3838002681732178
Validation loss: 2.6002158170105307

Epoch: 6| Step: 13
Training loss: 2.371678113937378
Validation loss: 2.6019653376712593

Epoch: 79| Step: 0
Training loss: 3.70837140083313
Validation loss: 2.598703533090571

Epoch: 6| Step: 1
Training loss: 2.9330360889434814
Validation loss: 2.6027228242607525

Epoch: 6| Step: 2
Training loss: 2.3758959770202637
Validation loss: 2.6014880057304137

Epoch: 6| Step: 3
Training loss: 2.190423011779785
Validation loss: 2.6033968002565446

Epoch: 6| Step: 4
Training loss: 3.0794215202331543
Validation loss: 2.6040525590219805

Epoch: 6| Step: 5
Training loss: 2.5578298568725586
Validation loss: 2.6051550039681057

Epoch: 6| Step: 6
Training loss: 2.6455326080322266
Validation loss: 2.6071317426619993

Epoch: 6| Step: 7
Training loss: 3.11643648147583
Validation loss: 2.6039519822725685

Epoch: 6| Step: 8
Training loss: 3.2497401237487793
Validation loss: 2.600796345741518

Epoch: 6| Step: 9
Training loss: 2.0090410709381104
Validation loss: 2.599634180786789

Epoch: 6| Step: 10
Training loss: 2.701827049255371
Validation loss: 2.6015491716323362

Epoch: 6| Step: 11
Training loss: 2.562526226043701
Validation loss: 2.597813642153176

Epoch: 6| Step: 12
Training loss: 2.976694107055664
Validation loss: 2.5972448113144084

Epoch: 6| Step: 13
Training loss: 2.576744318008423
Validation loss: 2.5974123606117825

Epoch: 80| Step: 0
Training loss: 3.2677135467529297
Validation loss: 2.5986564646485033

Epoch: 6| Step: 1
Training loss: 2.8085124492645264
Validation loss: 2.599088163786037

Epoch: 6| Step: 2
Training loss: 2.502607583999634
Validation loss: 2.6036108181040776

Epoch: 6| Step: 3
Training loss: 2.788890838623047
Validation loss: 2.6070963208393385

Epoch: 6| Step: 4
Training loss: 2.5582728385925293
Validation loss: 2.617942140948388

Epoch: 6| Step: 5
Training loss: 2.0985279083251953
Validation loss: 2.6081542148384997

Epoch: 6| Step: 6
Training loss: 2.7749242782592773
Validation loss: 2.6032758682004866

Epoch: 6| Step: 7
Training loss: 3.6303298473358154
Validation loss: 2.6010262761064755

Epoch: 6| Step: 8
Training loss: 2.844156503677368
Validation loss: 2.601031977643249

Epoch: 6| Step: 9
Training loss: 2.6302785873413086
Validation loss: 2.5987057942216114

Epoch: 6| Step: 10
Training loss: 2.670339345932007
Validation loss: 2.59769763997806

Epoch: 6| Step: 11
Training loss: 2.7612993717193604
Validation loss: 2.596315678729806

Epoch: 6| Step: 12
Training loss: 2.4494409561157227
Validation loss: 2.5962850868061023

Epoch: 6| Step: 13
Training loss: 3.168607234954834
Validation loss: 2.599306866686831

Epoch: 81| Step: 0
Training loss: 3.3918371200561523
Validation loss: 2.595965544382731

Epoch: 6| Step: 1
Training loss: 2.2077856063842773
Validation loss: 2.5970795487844818

Epoch: 6| Step: 2
Training loss: 2.878143072128296
Validation loss: 2.595872445773053

Epoch: 6| Step: 3
Training loss: 2.536802291870117
Validation loss: 2.594971151762111

Epoch: 6| Step: 4
Training loss: 2.2790260314941406
Validation loss: 2.5961860636229157

Epoch: 6| Step: 5
Training loss: 3.0037848949432373
Validation loss: 2.6003362645385084

Epoch: 6| Step: 6
Training loss: 3.072774887084961
Validation loss: 2.602875642879035

Epoch: 6| Step: 7
Training loss: 3.368056535720825
Validation loss: 2.6057708135215183

Epoch: 6| Step: 8
Training loss: 2.7418439388275146
Validation loss: 2.595628235929756

Epoch: 6| Step: 9
Training loss: 2.2499217987060547
Validation loss: 2.5926618550413396

Epoch: 6| Step: 10
Training loss: 2.4579927921295166
Validation loss: 2.59453934238803

Epoch: 6| Step: 11
Training loss: 2.149116039276123
Validation loss: 2.592279816186556

Epoch: 6| Step: 12
Training loss: 2.784923553466797
Validation loss: 2.5924646854400635

Epoch: 6| Step: 13
Training loss: 4.322042465209961
Validation loss: 2.590546384934456

Epoch: 82| Step: 0
Training loss: 2.8418545722961426
Validation loss: 2.5908504198956233

Epoch: 6| Step: 1
Training loss: 2.8034708499908447
Validation loss: 2.5928783134747575

Epoch: 6| Step: 2
Training loss: 2.8219690322875977
Validation loss: 2.5934087537950083

Epoch: 6| Step: 3
Training loss: 3.523594617843628
Validation loss: 2.5955623631836264

Epoch: 6| Step: 4
Training loss: 2.420733690261841
Validation loss: 2.5957026225264355

Epoch: 6| Step: 5
Training loss: 2.697988986968994
Validation loss: 2.607852937072836

Epoch: 6| Step: 6
Training loss: 2.462235450744629
Validation loss: 2.6054696959833943

Epoch: 6| Step: 7
Training loss: 2.734715461730957
Validation loss: 2.6095278750183764

Epoch: 6| Step: 8
Training loss: 2.343169689178467
Validation loss: 2.6032458941141763

Epoch: 6| Step: 9
Training loss: 3.228926658630371
Validation loss: 2.593781404597785

Epoch: 6| Step: 10
Training loss: 2.4934468269348145
Validation loss: 2.5893949718885523

Epoch: 6| Step: 11
Training loss: 2.095597743988037
Validation loss: 2.589796612339635

Epoch: 6| Step: 12
Training loss: 2.912658214569092
Validation loss: 2.589176970143472

Epoch: 6| Step: 13
Training loss: 3.824465751647949
Validation loss: 2.5894459498825895

Epoch: 83| Step: 0
Training loss: 3.5550358295440674
Validation loss: 2.5903109478694137

Epoch: 6| Step: 1
Training loss: 2.923293113708496
Validation loss: 2.593464805233863

Epoch: 6| Step: 2
Training loss: 2.198336124420166
Validation loss: 2.5987359926264775

Epoch: 6| Step: 3
Training loss: 2.7590510845184326
Validation loss: 2.596245842595254

Epoch: 6| Step: 4
Training loss: 2.2685604095458984
Validation loss: 2.5979163313424714

Epoch: 6| Step: 5
Training loss: 2.731544017791748
Validation loss: 2.605493817278134

Epoch: 6| Step: 6
Training loss: 3.041672468185425
Validation loss: 2.6013990474003617

Epoch: 6| Step: 7
Training loss: 2.7218358516693115
Validation loss: 2.5959918165719635

Epoch: 6| Step: 8
Training loss: 3.0750389099121094
Validation loss: 2.5889063522379887

Epoch: 6| Step: 9
Training loss: 3.8336100578308105
Validation loss: 2.5981060843313895

Epoch: 6| Step: 10
Training loss: 2.925940990447998
Validation loss: 2.5985850826386483

Epoch: 6| Step: 11
Training loss: 2.5325279235839844
Validation loss: 2.6002639416725404

Epoch: 6| Step: 12
Training loss: 2.0498859882354736
Validation loss: 2.599259115034534

Epoch: 6| Step: 13
Training loss: 1.7429851293563843
Validation loss: 2.599160635343162

Epoch: 84| Step: 0
Training loss: 3.438904047012329
Validation loss: 2.5995548925092145

Epoch: 6| Step: 1
Training loss: 2.0961737632751465
Validation loss: 2.602532207324941

Epoch: 6| Step: 2
Training loss: 2.2689943313598633
Validation loss: 2.601197229918613

Epoch: 6| Step: 3
Training loss: 2.5133273601531982
Validation loss: 2.6018121370705227

Epoch: 6| Step: 4
Training loss: 2.970015048980713
Validation loss: 2.600999524516444

Epoch: 6| Step: 5
Training loss: 1.8399468660354614
Validation loss: 2.597224332953012

Epoch: 6| Step: 6
Training loss: 3.4289283752441406
Validation loss: 2.596764600405129

Epoch: 6| Step: 7
Training loss: 2.762483596801758
Validation loss: 2.599842684243315

Epoch: 6| Step: 8
Training loss: 2.8264548778533936
Validation loss: 2.594452699025472

Epoch: 6| Step: 9
Training loss: 3.0873422622680664
Validation loss: 2.5934424297783965

Epoch: 6| Step: 10
Training loss: 2.657285690307617
Validation loss: 2.5925359187587613

Epoch: 6| Step: 11
Training loss: 3.5655975341796875
Validation loss: 2.592037413709907

Epoch: 6| Step: 12
Training loss: 2.9252877235412598
Validation loss: 2.589475308695147

Epoch: 6| Step: 13
Training loss: 1.9225016832351685
Validation loss: 2.5915855541024158

Epoch: 85| Step: 0
Training loss: 2.7065815925598145
Validation loss: 2.5904201845968924

Epoch: 6| Step: 1
Training loss: 3.0734353065490723
Validation loss: 2.5869529926648704

Epoch: 6| Step: 2
Training loss: 2.6730241775512695
Validation loss: 2.5879242650924192

Epoch: 6| Step: 3
Training loss: 2.412792205810547
Validation loss: 2.582609699618432

Epoch: 6| Step: 4
Training loss: 3.041104555130005
Validation loss: 2.5833845958914807

Epoch: 6| Step: 5
Training loss: 3.25400972366333
Validation loss: 2.584920383268787

Epoch: 6| Step: 6
Training loss: 2.553703784942627
Validation loss: 2.5845338554792505

Epoch: 6| Step: 7
Training loss: 3.114734172821045
Validation loss: 2.582528552701396

Epoch: 6| Step: 8
Training loss: 2.5267493724823
Validation loss: 2.58341186277328

Epoch: 6| Step: 9
Training loss: 2.501532554626465
Validation loss: 2.5813874377999255

Epoch: 6| Step: 10
Training loss: 2.2149605751037598
Validation loss: 2.5809744481117494

Epoch: 6| Step: 11
Training loss: 2.888026237487793
Validation loss: 2.5842567643811627

Epoch: 6| Step: 12
Training loss: 3.329465866088867
Validation loss: 2.5897709990060456

Epoch: 6| Step: 13
Training loss: 2.0860772132873535
Validation loss: 2.5895980865724626

Epoch: 86| Step: 0
Training loss: 2.5160622596740723
Validation loss: 2.5921424614485873

Epoch: 6| Step: 1
Training loss: 3.300097942352295
Validation loss: 2.5857084592183432

Epoch: 6| Step: 2
Training loss: 2.4302427768707275
Validation loss: 2.589667550979122

Epoch: 6| Step: 3
Training loss: 3.4265971183776855
Validation loss: 2.5898531944521013

Epoch: 6| Step: 4
Training loss: 2.816143035888672
Validation loss: 2.5904533375975904

Epoch: 6| Step: 5
Training loss: 2.9227170944213867
Validation loss: 2.584321452725318

Epoch: 6| Step: 6
Training loss: 2.681830883026123
Validation loss: 2.5913427286250617

Epoch: 6| Step: 7
Training loss: 3.077665328979492
Validation loss: 2.59437031643365

Epoch: 6| Step: 8
Training loss: 2.633816719055176
Validation loss: 2.586410948025283

Epoch: 6| Step: 9
Training loss: 2.4824776649475098
Validation loss: 2.581596225820562

Epoch: 6| Step: 10
Training loss: 2.2000856399536133
Validation loss: 2.5783921800633913

Epoch: 6| Step: 11
Training loss: 2.629437208175659
Validation loss: 2.5796891156063286

Epoch: 6| Step: 12
Training loss: 2.3585000038146973
Validation loss: 2.5845835824166574

Epoch: 6| Step: 13
Training loss: 3.4827091693878174
Validation loss: 2.580690715902595

Epoch: 87| Step: 0
Training loss: 1.7057812213897705
Validation loss: 2.583164927779987

Epoch: 6| Step: 1
Training loss: 2.9683523178100586
Validation loss: 2.5791494256706646

Epoch: 6| Step: 2
Training loss: 2.48002290725708
Validation loss: 2.5841271056923816

Epoch: 6| Step: 3
Training loss: 3.144033908843994
Validation loss: 2.5847485116733018

Epoch: 6| Step: 4
Training loss: 2.532258987426758
Validation loss: 2.584088040936378

Epoch: 6| Step: 5
Training loss: 3.173245906829834
Validation loss: 2.5795884491294943

Epoch: 6| Step: 6
Training loss: 2.4035892486572266
Validation loss: 2.582079969426637

Epoch: 6| Step: 7
Training loss: 2.758697986602783
Validation loss: 2.5800541780328237

Epoch: 6| Step: 8
Training loss: 3.053225517272949
Validation loss: 2.5776550795442317

Epoch: 6| Step: 9
Training loss: 3.233818292617798
Validation loss: 2.5763548727958434

Epoch: 6| Step: 10
Training loss: 2.493269920349121
Validation loss: 2.581487073693224

Epoch: 6| Step: 11
Training loss: 2.5960211753845215
Validation loss: 2.581630322241014

Epoch: 6| Step: 12
Training loss: 3.2063827514648438
Validation loss: 2.5894230181171047

Epoch: 6| Step: 13
Training loss: 2.9780170917510986
Validation loss: 2.5994671801085114

Epoch: 88| Step: 0
Training loss: 2.4687037467956543
Validation loss: 2.597738589009931

Epoch: 6| Step: 1
Training loss: 2.3886213302612305
Validation loss: 2.589554686700144

Epoch: 6| Step: 2
Training loss: 2.71980619430542
Validation loss: 2.585597979125156

Epoch: 6| Step: 3
Training loss: 2.8038315773010254
Validation loss: 2.583449879000264

Epoch: 6| Step: 4
Training loss: 3.498213768005371
Validation loss: 2.576345416807359

Epoch: 6| Step: 5
Training loss: 2.678192138671875
Validation loss: 2.5734145128598778

Epoch: 6| Step: 6
Training loss: 2.7158703804016113
Validation loss: 2.57432472449477

Epoch: 6| Step: 7
Training loss: 3.4823646545410156
Validation loss: 2.5777934341020483

Epoch: 6| Step: 8
Training loss: 3.8413496017456055
Validation loss: 2.5730942859444568

Epoch: 6| Step: 9
Training loss: 3.075253963470459
Validation loss: 2.5731220258179532

Epoch: 6| Step: 10
Training loss: 2.0800154209136963
Validation loss: 2.5755776461734565

Epoch: 6| Step: 11
Training loss: 2.409247875213623
Validation loss: 2.5726829292953655

Epoch: 6| Step: 12
Training loss: 1.8001645803451538
Validation loss: 2.5765104639914727

Epoch: 6| Step: 13
Training loss: 2.531606435775757
Validation loss: 2.572561587056806

Epoch: 89| Step: 0
Training loss: 2.4893040657043457
Validation loss: 2.5745759317951817

Epoch: 6| Step: 1
Training loss: 2.762640953063965
Validation loss: 2.572372060950084

Epoch: 6| Step: 2
Training loss: 2.5645315647125244
Validation loss: 2.5804597305995163

Epoch: 6| Step: 3
Training loss: 3.0285418033599854
Validation loss: 2.588461431123877

Epoch: 6| Step: 4
Training loss: 2.2712559700012207
Validation loss: 2.590129539530764

Epoch: 6| Step: 5
Training loss: 2.9084434509277344
Validation loss: 2.595756556398125

Epoch: 6| Step: 6
Training loss: 2.9668097496032715
Validation loss: 2.5878161794395855

Epoch: 6| Step: 7
Training loss: 2.693237066268921
Validation loss: 2.583835568479312

Epoch: 6| Step: 8
Training loss: 3.1944169998168945
Validation loss: 2.580436175869357

Epoch: 6| Step: 9
Training loss: 2.463798761367798
Validation loss: 2.5763824139871905

Epoch: 6| Step: 10
Training loss: 2.483840227127075
Validation loss: 2.5729986288214244

Epoch: 6| Step: 11
Training loss: 2.9728033542633057
Validation loss: 2.5707109487184914

Epoch: 6| Step: 12
Training loss: 3.6950018405914307
Validation loss: 2.572628128913141

Epoch: 6| Step: 13
Training loss: 1.6363271474838257
Validation loss: 2.5763769995781685

Epoch: 90| Step: 0
Training loss: 2.6683568954467773
Validation loss: 2.577689519492529

Epoch: 6| Step: 1
Training loss: 3.0020012855529785
Validation loss: 2.5767203223320747

Epoch: 6| Step: 2
Training loss: 3.0305466651916504
Validation loss: 2.5791513586557038

Epoch: 6| Step: 3
Training loss: 2.6266162395477295
Validation loss: 2.5765653271828928

Epoch: 6| Step: 4
Training loss: 1.8477647304534912
Validation loss: 2.580699918090656

Epoch: 6| Step: 5
Training loss: 3.0186514854431152
Validation loss: 2.5800235835454797

Epoch: 6| Step: 6
Training loss: 3.1150877475738525
Validation loss: 2.583038032695811

Epoch: 6| Step: 7
Training loss: 3.880286455154419
Validation loss: 2.579615295574229

Epoch: 6| Step: 8
Training loss: 2.1710004806518555
Validation loss: 2.583197916707685

Epoch: 6| Step: 9
Training loss: 2.215994358062744
Validation loss: 2.586115878115418

Epoch: 6| Step: 10
Training loss: 2.806793212890625
Validation loss: 2.592637618382772

Epoch: 6| Step: 11
Training loss: 1.991950511932373
Validation loss: 2.5827987681153

Epoch: 6| Step: 12
Training loss: 3.5953099727630615
Validation loss: 2.577586379102481

Epoch: 6| Step: 13
Training loss: 2.4492130279541016
Validation loss: 2.586792694625034

Epoch: 91| Step: 0
Training loss: 2.550008773803711
Validation loss: 2.5832562677321897

Epoch: 6| Step: 1
Training loss: 2.069803476333618
Validation loss: 2.5833913844118834

Epoch: 6| Step: 2
Training loss: 3.076897621154785
Validation loss: 2.584707065295148

Epoch: 6| Step: 3
Training loss: 2.626809597015381
Validation loss: 2.5874825369927192

Epoch: 6| Step: 4
Training loss: 2.959230899810791
Validation loss: 2.576966065232472

Epoch: 6| Step: 5
Training loss: 2.105433940887451
Validation loss: 2.575145093343591

Epoch: 6| Step: 6
Training loss: 3.6111392974853516
Validation loss: 2.569320232637467

Epoch: 6| Step: 7
Training loss: 3.1168036460876465
Validation loss: 2.570181764582152

Epoch: 6| Step: 8
Training loss: 2.7077622413635254
Validation loss: 2.5628758912445395

Epoch: 6| Step: 9
Training loss: 2.1196582317352295
Validation loss: 2.5677051031461327

Epoch: 6| Step: 10
Training loss: 2.8633761405944824
Validation loss: 2.568774352791489

Epoch: 6| Step: 11
Training loss: 3.4975624084472656
Validation loss: 2.5680680198054158

Epoch: 6| Step: 12
Training loss: 2.7203903198242188
Validation loss: 2.5679778847643124

Epoch: 6| Step: 13
Training loss: 2.3003456592559814
Validation loss: 2.5694869384970715

Epoch: 92| Step: 0
Training loss: 2.2387280464172363
Validation loss: 2.570107824058943

Epoch: 6| Step: 1
Training loss: 2.2811107635498047
Validation loss: 2.566666131378502

Epoch: 6| Step: 2
Training loss: 2.8490638732910156
Validation loss: 2.57044622975011

Epoch: 6| Step: 3
Training loss: 3.3013253211975098
Validation loss: 2.5681550195140224

Epoch: 6| Step: 4
Training loss: 2.9105587005615234
Validation loss: 2.565452111664639

Epoch: 6| Step: 5
Training loss: 2.230576276779175
Validation loss: 2.564708632807578

Epoch: 6| Step: 6
Training loss: 2.4816231727600098
Validation loss: 2.562534668112314

Epoch: 6| Step: 7
Training loss: 3.2544586658477783
Validation loss: 2.566459301979311

Epoch: 6| Step: 8
Training loss: 2.404381275177002
Validation loss: 2.563843363074846

Epoch: 6| Step: 9
Training loss: 2.8113865852355957
Validation loss: 2.5649809939886934

Epoch: 6| Step: 10
Training loss: 2.8693976402282715
Validation loss: 2.5653707160744617

Epoch: 6| Step: 11
Training loss: 2.627194404602051
Validation loss: 2.572384536907237

Epoch: 6| Step: 12
Training loss: 3.4947047233581543
Validation loss: 2.5716121632565736

Epoch: 6| Step: 13
Training loss: 2.7317862510681152
Validation loss: 2.5858857503501316

Epoch: 93| Step: 0
Training loss: 2.9760570526123047
Validation loss: 2.5844943343952136

Epoch: 6| Step: 1
Training loss: 3.318268299102783
Validation loss: 2.5850664082393853

Epoch: 6| Step: 2
Training loss: 3.329343795776367
Validation loss: 2.5769065913333686

Epoch: 6| Step: 3
Training loss: 1.9723526239395142
Validation loss: 2.5804269877813195

Epoch: 6| Step: 4
Training loss: 2.6868791580200195
Validation loss: 2.5680114966566845

Epoch: 6| Step: 5
Training loss: 3.1823582649230957
Validation loss: 2.568455301305299

Epoch: 6| Step: 6
Training loss: 2.8155150413513184
Validation loss: 2.564485453790234

Epoch: 6| Step: 7
Training loss: 2.4881627559661865
Validation loss: 2.5633088927115164

Epoch: 6| Step: 8
Training loss: 2.8269786834716797
Validation loss: 2.560189930341577

Epoch: 6| Step: 9
Training loss: 2.1078603267669678
Validation loss: 2.5632904652626283

Epoch: 6| Step: 10
Training loss: 2.844191074371338
Validation loss: 2.5631574712773806

Epoch: 6| Step: 11
Training loss: 2.461519718170166
Validation loss: 2.5601742165063017

Epoch: 6| Step: 12
Training loss: 2.8113369941711426
Validation loss: 2.5626253440815914

Epoch: 6| Step: 13
Training loss: 2.509345293045044
Validation loss: 2.562885540787892

Epoch: 94| Step: 0
Training loss: 2.8275938034057617
Validation loss: 2.5632378696113505

Epoch: 6| Step: 1
Training loss: 3.4808528423309326
Validation loss: 2.5662220344748548

Epoch: 6| Step: 2
Training loss: 2.1308627128601074
Validation loss: 2.560945887719431

Epoch: 6| Step: 3
Training loss: 2.8588900566101074
Validation loss: 2.5585489170525664

Epoch: 6| Step: 4
Training loss: 2.9843645095825195
Validation loss: 2.5596267587395123

Epoch: 6| Step: 5
Training loss: 2.259495258331299
Validation loss: 2.5599259125289096

Epoch: 6| Step: 6
Training loss: 2.4157402515411377
Validation loss: 2.5595194370515886

Epoch: 6| Step: 7
Training loss: 3.5621159076690674
Validation loss: 2.5593201703922723

Epoch: 6| Step: 8
Training loss: 3.500802516937256
Validation loss: 2.5615971344773487

Epoch: 6| Step: 9
Training loss: 2.7230000495910645
Validation loss: 2.559808272187428

Epoch: 6| Step: 10
Training loss: 2.3735671043395996
Validation loss: 2.561724308998354

Epoch: 6| Step: 11
Training loss: 2.698105812072754
Validation loss: 2.55606242405471

Epoch: 6| Step: 12
Training loss: 2.4493303298950195
Validation loss: 2.5591879916447464

Epoch: 6| Step: 13
Training loss: 1.7408257722854614
Validation loss: 2.5549083461043653

Epoch: 95| Step: 0
Training loss: 2.4927093982696533
Validation loss: 2.563402557885775

Epoch: 6| Step: 1
Training loss: 3.7056996822357178
Validation loss: 2.563070402350477

Epoch: 6| Step: 2
Training loss: 2.4764246940612793
Validation loss: 2.5605551709410963

Epoch: 6| Step: 3
Training loss: 3.4166908264160156
Validation loss: 2.562556110402589

Epoch: 6| Step: 4
Training loss: 2.2802445888519287
Validation loss: 2.5668501020759664

Epoch: 6| Step: 5
Training loss: 2.2749760150909424
Validation loss: 2.565809098623132

Epoch: 6| Step: 6
Training loss: 2.6550517082214355
Validation loss: 2.566702150529431

Epoch: 6| Step: 7
Training loss: 2.9373161792755127
Validation loss: 2.56345619181151

Epoch: 6| Step: 8
Training loss: 3.0226378440856934
Validation loss: 2.5612724929727535

Epoch: 6| Step: 9
Training loss: 2.356372356414795
Validation loss: 2.555735300945979

Epoch: 6| Step: 10
Training loss: 2.512394428253174
Validation loss: 2.562407475645824

Epoch: 6| Step: 11
Training loss: 2.3748507499694824
Validation loss: 2.564417733941027

Epoch: 6| Step: 12
Training loss: 3.1054513454437256
Validation loss: 2.5614063996140675

Epoch: 6| Step: 13
Training loss: 2.659686326980591
Validation loss: 2.5570176621919036

Epoch: 96| Step: 0
Training loss: 3.254291534423828
Validation loss: 2.5567060644908617

Epoch: 6| Step: 1
Training loss: 2.638309955596924
Validation loss: 2.5588842386840494

Epoch: 6| Step: 2
Training loss: 2.585705280303955
Validation loss: 2.562005535248787

Epoch: 6| Step: 3
Training loss: 2.8790781497955322
Validation loss: 2.562328225822859

Epoch: 6| Step: 4
Training loss: 2.190546989440918
Validation loss: 2.562891980653168

Epoch: 6| Step: 5
Training loss: 2.8514342308044434
Validation loss: 2.569696134136569

Epoch: 6| Step: 6
Training loss: 2.27829647064209
Validation loss: 2.584387856145059

Epoch: 6| Step: 7
Training loss: 2.949615716934204
Validation loss: 2.5744042858000724

Epoch: 6| Step: 8
Training loss: 3.3800127506256104
Validation loss: 2.5696377933666272

Epoch: 6| Step: 9
Training loss: 2.2437305450439453
Validation loss: 2.56010034520139

Epoch: 6| Step: 10
Training loss: 2.8892221450805664
Validation loss: 2.5573777639737694

Epoch: 6| Step: 11
Training loss: 2.678800582885742
Validation loss: 2.5567291782748316

Epoch: 6| Step: 12
Training loss: 3.462153673171997
Validation loss: 2.554515269494826

Epoch: 6| Step: 13
Training loss: 1.7731982469558716
Validation loss: 2.5585845132027902

Epoch: 97| Step: 0
Training loss: 2.5646867752075195
Validation loss: 2.555474870948381

Epoch: 6| Step: 1
Training loss: 2.3688299655914307
Validation loss: 2.557620184395903

Epoch: 6| Step: 2
Training loss: 2.7149806022644043
Validation loss: 2.5647089301898913

Epoch: 6| Step: 3
Training loss: 3.368180513381958
Validation loss: 2.5653032384892946

Epoch: 6| Step: 4
Training loss: 2.2015132904052734
Validation loss: 2.56368080774943

Epoch: 6| Step: 5
Training loss: 3.861389636993408
Validation loss: 2.567922599854008

Epoch: 6| Step: 6
Training loss: 2.9845051765441895
Validation loss: 2.564166658668108

Epoch: 6| Step: 7
Training loss: 2.368299961090088
Validation loss: 2.563023433890394

Epoch: 6| Step: 8
Training loss: 2.5072202682495117
Validation loss: 2.5583980596193703

Epoch: 6| Step: 9
Training loss: 3.2308380603790283
Validation loss: 2.552605782785723

Epoch: 6| Step: 10
Training loss: 2.439215660095215
Validation loss: 2.553237533056608

Epoch: 6| Step: 11
Training loss: 2.394167900085449
Validation loss: 2.549994840416857

Epoch: 6| Step: 12
Training loss: 2.756460666656494
Validation loss: 2.551987871046989

Epoch: 6| Step: 13
Training loss: 2.423065185546875
Validation loss: 2.5498448084759455

Epoch: 98| Step: 0
Training loss: 2.6134958267211914
Validation loss: 2.553684117973492

Epoch: 6| Step: 1
Training loss: 2.983111619949341
Validation loss: 2.5539073174999607

Epoch: 6| Step: 2
Training loss: 2.4105324745178223
Validation loss: 2.5495307522435344

Epoch: 6| Step: 3
Training loss: 3.0429530143737793
Validation loss: 2.5527023346193376

Epoch: 6| Step: 4
Training loss: 3.0207645893096924
Validation loss: 2.551379285832887

Epoch: 6| Step: 5
Training loss: 3.0457024574279785
Validation loss: 2.5486987636935328

Epoch: 6| Step: 6
Training loss: 2.3007495403289795
Validation loss: 2.547295903646818

Epoch: 6| Step: 7
Training loss: 2.7256875038146973
Validation loss: 2.550753037134806

Epoch: 6| Step: 8
Training loss: 2.593254566192627
Validation loss: 2.548825917705413

Epoch: 6| Step: 9
Training loss: 2.531813621520996
Validation loss: 2.5462613182683147

Epoch: 6| Step: 10
Training loss: 2.8101601600646973
Validation loss: 2.5476085857678483

Epoch: 6| Step: 11
Training loss: 2.4056525230407715
Validation loss: 2.553948025549612

Epoch: 6| Step: 12
Training loss: 2.856053352355957
Validation loss: 2.5554638985664613

Epoch: 6| Step: 13
Training loss: 3.113662004470825
Validation loss: 2.560935087101434

Epoch: 99| Step: 0
Training loss: 2.7174370288848877
Validation loss: 2.558755974615774

Epoch: 6| Step: 1
Training loss: 2.3104076385498047
Validation loss: 2.5640330006999354

Epoch: 6| Step: 2
Training loss: 2.53240704536438
Validation loss: 2.561276082069643

Epoch: 6| Step: 3
Training loss: 2.2490649223327637
Validation loss: 2.5561017426111365

Epoch: 6| Step: 4
Training loss: 2.9319584369659424
Validation loss: 2.547828353861327

Epoch: 6| Step: 5
Training loss: 2.611384153366089
Validation loss: 2.5451447168986

Epoch: 6| Step: 6
Training loss: 2.263671875
Validation loss: 2.5430411549024683

Epoch: 6| Step: 7
Training loss: 3.4039158821105957
Validation loss: 2.543380396340483

Epoch: 6| Step: 8
Training loss: 2.4998815059661865
Validation loss: 2.5448534668132825

Epoch: 6| Step: 9
Training loss: 3.379488468170166
Validation loss: 2.5597182832738405

Epoch: 6| Step: 10
Training loss: 3.067873001098633
Validation loss: 2.560737071498748

Epoch: 6| Step: 11
Training loss: 2.6092545986175537
Validation loss: 2.5597820820346957

Epoch: 6| Step: 12
Training loss: 3.284425735473633
Validation loss: 2.549906205105525

Epoch: 6| Step: 13
Training loss: 2.229619026184082
Validation loss: 2.5460867138319117

Epoch: 100| Step: 0
Training loss: 3.3484535217285156
Validation loss: 2.542838465782904

Epoch: 6| Step: 1
Training loss: 2.3757271766662598
Validation loss: 2.541115317293393

Epoch: 6| Step: 2
Training loss: 2.099578857421875
Validation loss: 2.5430301517568608

Epoch: 6| Step: 3
Training loss: 3.0518014430999756
Validation loss: 2.5443117157105477

Epoch: 6| Step: 4
Training loss: 2.0957300662994385
Validation loss: 2.54394801457723

Epoch: 6| Step: 5
Training loss: 3.1963162422180176
Validation loss: 2.542666822351435

Epoch: 6| Step: 6
Training loss: 3.262603759765625
Validation loss: 2.547208491192069

Epoch: 6| Step: 7
Training loss: 3.3195128440856934
Validation loss: 2.54957430337065

Epoch: 6| Step: 8
Training loss: 2.410891056060791
Validation loss: 2.556738794490855

Epoch: 6| Step: 9
Training loss: 2.796048402786255
Validation loss: 2.558441500509939

Epoch: 6| Step: 10
Training loss: 2.608610153198242
Validation loss: 2.5513386572560957

Epoch: 6| Step: 11
Training loss: 2.344761610031128
Validation loss: 2.550223860689389

Epoch: 6| Step: 12
Training loss: 2.3748385906219482
Validation loss: 2.5456083179802023

Epoch: 6| Step: 13
Training loss: 3.1361262798309326
Validation loss: 2.546315804604561

Testing loss: 2.6689916398790148
