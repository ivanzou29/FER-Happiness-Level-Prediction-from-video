Epoch: 1| Step: 0
Training loss: 6.012670172743651
Validation loss: 5.820184767437019

Epoch: 5| Step: 1
Training loss: 4.657588484738005
Validation loss: 5.8123449189536975

Epoch: 5| Step: 2
Training loss: 5.9482183786309335
Validation loss: 5.804649002119113

Epoch: 5| Step: 3
Training loss: 5.415175110300656
Validation loss: 5.7972912298568815

Epoch: 5| Step: 4
Training loss: 6.918472452635831
Validation loss: 5.789649770957316

Epoch: 5| Step: 5
Training loss: 5.851865304769584
Validation loss: 5.781688723425841

Epoch: 5| Step: 6
Training loss: 4.947304178442357
Validation loss: 5.773267923734029

Epoch: 5| Step: 7
Training loss: 6.279087586422788
Validation loss: 5.76465197478273

Epoch: 5| Step: 8
Training loss: 5.6306495270145644
Validation loss: 5.755487968107744

Epoch: 5| Step: 9
Training loss: 5.443496904938694
Validation loss: 5.745453587376233

Epoch: 5| Step: 10
Training loss: 6.586684070414872
Validation loss: 5.734267815963503

Epoch: 2| Step: 0
Training loss: 5.731556046196649
Validation loss: 5.72211888782133

Epoch: 5| Step: 1
Training loss: 5.847281465006269
Validation loss: 5.70863571905016

Epoch: 5| Step: 2
Training loss: 4.458329221539369
Validation loss: 5.6935973120145

Epoch: 5| Step: 3
Training loss: 6.093050716087024
Validation loss: 5.677839615538227

Epoch: 5| Step: 4
Training loss: 5.828965686371845
Validation loss: 5.660548212601838

Epoch: 5| Step: 5
Training loss: 5.617688322488446
Validation loss: 5.641943701900719

Epoch: 5| Step: 6
Training loss: 5.345270308679587
Validation loss: 5.621552068501649

Epoch: 5| Step: 7
Training loss: 5.686064822036449
Validation loss: 5.59898079373738

Epoch: 5| Step: 8
Training loss: 5.685550565204059
Validation loss: 5.576048311432266

Epoch: 5| Step: 9
Training loss: 5.9056305737105275
Validation loss: 5.551328628734314

Epoch: 5| Step: 10
Training loss: 6.044666291042737
Validation loss: 5.5248536764240495

Epoch: 3| Step: 0
Training loss: 5.534851970398893
Validation loss: 5.496239970099731

Epoch: 5| Step: 1
Training loss: 5.962694861468791
Validation loss: 5.467740803549447

Epoch: 5| Step: 2
Training loss: 5.231262557038581
Validation loss: 5.4369779814053185

Epoch: 5| Step: 3
Training loss: 4.573651624749125
Validation loss: 5.405058152361589

Epoch: 5| Step: 4
Training loss: 4.78232038895475
Validation loss: 5.375386950335835

Epoch: 5| Step: 5
Training loss: 5.083899961482265
Validation loss: 5.342200934025104

Epoch: 5| Step: 6
Training loss: 6.1105656158817325
Validation loss: 5.309454387639185

Epoch: 5| Step: 7
Training loss: 5.600835138445594
Validation loss: 5.274480418903026

Epoch: 5| Step: 8
Training loss: 5.672556938601823
Validation loss: 5.239509911618957

Epoch: 5| Step: 9
Training loss: 5.258405042704456
Validation loss: 5.20385011666096

Epoch: 5| Step: 10
Training loss: 5.196760437620779
Validation loss: 5.168704885560754

Epoch: 4| Step: 0
Training loss: 4.89613748241449
Validation loss: 5.1352386267360215

Epoch: 5| Step: 1
Training loss: 5.566027604994477
Validation loss: 5.102444512367098

Epoch: 5| Step: 2
Training loss: 5.11479305710092
Validation loss: 5.070187821188809

Epoch: 5| Step: 3
Training loss: 5.047847689499626
Validation loss: 5.03985022489481

Epoch: 5| Step: 4
Training loss: 4.852376037303525
Validation loss: 5.007823189050227

Epoch: 5| Step: 5
Training loss: 5.534936743067247
Validation loss: 4.975559032417799

Epoch: 5| Step: 6
Training loss: 4.616595286748231
Validation loss: 4.942734497807422

Epoch: 5| Step: 7
Training loss: 4.213317085508413
Validation loss: 4.913884644778873

Epoch: 5| Step: 8
Training loss: 5.101203006153093
Validation loss: 4.882869999241422

Epoch: 5| Step: 9
Training loss: 5.304902332208621
Validation loss: 4.853080417072319

Epoch: 5| Step: 10
Training loss: 5.122187517277965
Validation loss: 4.825166363839141

Epoch: 5| Step: 0
Training loss: 4.498276698427436
Validation loss: 4.798913680995016

Epoch: 5| Step: 1
Training loss: 4.686802519723519
Validation loss: 4.771892439542025

Epoch: 5| Step: 2
Training loss: 4.793835798587428
Validation loss: 4.747005920110463

Epoch: 5| Step: 3
Training loss: 5.148129258602706
Validation loss: 4.7212951007409405

Epoch: 5| Step: 4
Training loss: 4.989331880842113
Validation loss: 4.699043373284084

Epoch: 5| Step: 5
Training loss: 4.653238026390765
Validation loss: 4.678387365997809

Epoch: 5| Step: 6
Training loss: 4.053250626004643
Validation loss: 4.6576829120314525

Epoch: 5| Step: 7
Training loss: 4.926843273075689
Validation loss: 4.636988198969623

Epoch: 5| Step: 8
Training loss: 4.136311598382793
Validation loss: 4.6154061753285065

Epoch: 5| Step: 9
Training loss: 5.3671784380040855
Validation loss: 4.593043353552172

Epoch: 5| Step: 10
Training loss: 5.12874020193653
Validation loss: 4.574402510311464

Epoch: 6| Step: 0
Training loss: 4.899540097199175
Validation loss: 4.554720296470613

Epoch: 5| Step: 1
Training loss: 4.254545810005867
Validation loss: 4.531830093315369

Epoch: 5| Step: 2
Training loss: 4.870118851983624
Validation loss: 4.509064949721922

Epoch: 5| Step: 3
Training loss: 4.169512933694779
Validation loss: 4.485161037442406

Epoch: 5| Step: 4
Training loss: 4.742123548400127
Validation loss: 4.463635281106057

Epoch: 5| Step: 5
Training loss: 4.5331865053147515
Validation loss: 4.443225562113508

Epoch: 5| Step: 6
Training loss: 4.919424070438983
Validation loss: 4.420351346933756

Epoch: 5| Step: 7
Training loss: 4.738799894649311
Validation loss: 4.401397131903892

Epoch: 5| Step: 8
Training loss: 3.7134164982585207
Validation loss: 4.383193146870318

Epoch: 5| Step: 9
Training loss: 4.788580168538226
Validation loss: 4.361940140039164

Epoch: 5| Step: 10
Training loss: 4.267343251903394
Validation loss: 4.346532780591984

Epoch: 7| Step: 0
Training loss: 4.732369278171912
Validation loss: 4.328827815087177

Epoch: 5| Step: 1
Training loss: 3.8577536447515346
Validation loss: 4.314756509599367

Epoch: 5| Step: 2
Training loss: 4.64358333735247
Validation loss: 4.3003488433011405

Epoch: 5| Step: 3
Training loss: 4.335898129396144
Validation loss: 4.280165760534315

Epoch: 5| Step: 4
Training loss: 3.7397160980260855
Validation loss: 4.262701250848427

Epoch: 5| Step: 5
Training loss: 4.815400673742699
Validation loss: 4.2483916330756735

Epoch: 5| Step: 6
Training loss: 5.109738771513702
Validation loss: 4.235360045107254

Epoch: 5| Step: 7
Training loss: 4.422107919550182
Validation loss: 4.220035572525123

Epoch: 5| Step: 8
Training loss: 4.22570182794772
Validation loss: 4.208422650234433

Epoch: 5| Step: 9
Training loss: 4.676890866993017
Validation loss: 4.19738848692827

Epoch: 5| Step: 10
Training loss: 3.0036713070508867
Validation loss: 4.183357610576099

Epoch: 8| Step: 0
Training loss: 3.393923513005823
Validation loss: 4.172560439458913

Epoch: 5| Step: 1
Training loss: 4.175387728841146
Validation loss: 4.160049331572108

Epoch: 5| Step: 2
Training loss: 5.043203240578477
Validation loss: 4.150646496253749

Epoch: 5| Step: 3
Training loss: 4.851325430122688
Validation loss: 4.137477575819517

Epoch: 5| Step: 4
Training loss: 3.9335413818510125
Validation loss: 4.130662791783934

Epoch: 5| Step: 5
Training loss: 4.141168983281859
Validation loss: 4.1164263351518064

Epoch: 5| Step: 6
Training loss: 5.100563781094181
Validation loss: 4.105077660018745

Epoch: 5| Step: 7
Training loss: 3.886387980586155
Validation loss: 4.094468582938226

Epoch: 5| Step: 8
Training loss: 4.294698934072815
Validation loss: 4.082527188218334

Epoch: 5| Step: 9
Training loss: 3.9213279555369365
Validation loss: 4.076083199457544

Epoch: 5| Step: 10
Training loss: 3.657828357113015
Validation loss: 4.065996725864895

Epoch: 9| Step: 0
Training loss: 4.839252180225614
Validation loss: 4.053931570827451

Epoch: 5| Step: 1
Training loss: 4.720783730111903
Validation loss: 4.042141292263247

Epoch: 5| Step: 2
Training loss: 4.2952387243146966
Validation loss: 4.029854316253292

Epoch: 5| Step: 3
Training loss: 5.005980919929992
Validation loss: 4.021648811193364

Epoch: 5| Step: 4
Training loss: 3.297207639283995
Validation loss: 4.008878593478746

Epoch: 5| Step: 5
Training loss: 3.768606944239595
Validation loss: 4.001007591519559

Epoch: 5| Step: 6
Training loss: 4.147022990365159
Validation loss: 3.9945867759479348

Epoch: 5| Step: 7
Training loss: 3.82970585781695
Validation loss: 3.9836167329990473

Epoch: 5| Step: 8
Training loss: 4.252725512643471
Validation loss: 3.974232737780865

Epoch: 5| Step: 9
Training loss: 3.4972260245283238
Validation loss: 3.9620689307972947

Epoch: 5| Step: 10
Training loss: 3.60739543845213
Validation loss: 3.9577553815595055

Epoch: 10| Step: 0
Training loss: 5.153747876278118
Validation loss: 3.951355886817441

Epoch: 5| Step: 1
Training loss: 4.238807750995832
Validation loss: 3.939205117558381

Epoch: 5| Step: 2
Training loss: 3.8482147586001623
Validation loss: 3.9290475436170467

Epoch: 5| Step: 3
Training loss: 3.712258579611859
Validation loss: 3.9192262706349714

Epoch: 5| Step: 4
Training loss: 3.077475852096854
Validation loss: 3.912910793534409

Epoch: 5| Step: 5
Training loss: 4.165967094185213
Validation loss: 3.9063651302968094

Epoch: 5| Step: 6
Training loss: 4.214855968326822
Validation loss: 3.8959398468409563

Epoch: 5| Step: 7
Training loss: 3.7695674281780733
Validation loss: 3.884367265356092

Epoch: 5| Step: 8
Training loss: 3.2098719552904833
Validation loss: 3.875366325938992

Epoch: 5| Step: 9
Training loss: 3.952713292813318
Validation loss: 3.870744027916367

Epoch: 5| Step: 10
Training loss: 5.054393730293967
Validation loss: 3.8661464462850827

Epoch: 11| Step: 0
Training loss: 3.885235711486946
Validation loss: 3.8585265257660764

Epoch: 5| Step: 1
Training loss: 4.024822937287263
Validation loss: 3.853693439107597

Epoch: 5| Step: 2
Training loss: 4.188514245028963
Validation loss: 3.8455695977574225

Epoch: 5| Step: 3
Training loss: 4.38319196775271
Validation loss: 3.8435007823737535

Epoch: 5| Step: 4
Training loss: 3.605646098064099
Validation loss: 3.8356936109306177

Epoch: 5| Step: 5
Training loss: 3.768727018118607
Validation loss: 3.8280658850459517

Epoch: 5| Step: 6
Training loss: 4.458329221539369
Validation loss: 3.8193987879754183

Epoch: 5| Step: 7
Training loss: 3.605032418114536
Validation loss: 3.8122092192771793

Epoch: 5| Step: 8
Training loss: 4.3089089299951775
Validation loss: 3.803772291124403

Epoch: 5| Step: 9
Training loss: 3.35630679517602
Validation loss: 3.798878199918482

Epoch: 5| Step: 10
Training loss: 4.270031787119704
Validation loss: 3.7938472509027923

Epoch: 12| Step: 0
Training loss: 3.516589223240987
Validation loss: 3.7899450138943336

Epoch: 5| Step: 1
Training loss: 3.189540733353578
Validation loss: 3.7829885598816566

Epoch: 5| Step: 2
Training loss: 3.8449831589427945
Validation loss: 3.7778511511243997

Epoch: 5| Step: 3
Training loss: 3.997404209919291
Validation loss: 3.771760042913119

Epoch: 5| Step: 4
Training loss: 4.709892802385308
Validation loss: 3.7655044936012105

Epoch: 5| Step: 5
Training loss: 4.341460138974636
Validation loss: 3.7577148381147474

Epoch: 5| Step: 6
Training loss: 3.314781986392102
Validation loss: 3.754972616068273

Epoch: 5| Step: 7
Training loss: 3.997053014446139
Validation loss: 3.757252926425206

Epoch: 5| Step: 8
Training loss: 4.430604762352501
Validation loss: 3.7461801506327763

Epoch: 5| Step: 9
Training loss: 3.8606585017031048
Validation loss: 3.740859319774048

Epoch: 5| Step: 10
Training loss: 3.8358375551834647
Validation loss: 3.740620535786188

Epoch: 13| Step: 0
Training loss: 3.253397119813975
Validation loss: 3.7394156222864297

Epoch: 5| Step: 1
Training loss: 3.4665446101000166
Validation loss: 3.7311951897061184

Epoch: 5| Step: 2
Training loss: 4.505721799075489
Validation loss: 3.7244269784859374

Epoch: 5| Step: 3
Training loss: 3.6779690433130803
Validation loss: 3.7201128094884552

Epoch: 5| Step: 4
Training loss: 3.6702460388947973
Validation loss: 3.714108078026497

Epoch: 5| Step: 5
Training loss: 4.377178412737319
Validation loss: 3.711385249277298

Epoch: 5| Step: 6
Training loss: 3.6217272223933836
Validation loss: 3.707700225738592

Epoch: 5| Step: 7
Training loss: 4.263932447732168
Validation loss: 3.7087667464725427

Epoch: 5| Step: 8
Training loss: 3.8782960963104323
Validation loss: 3.707878168278368

Epoch: 5| Step: 9
Training loss: 3.718053159418871
Validation loss: 3.700929373567711

Epoch: 5| Step: 10
Training loss: 4.295765348550776
Validation loss: 3.6926011386512423

Epoch: 14| Step: 0
Training loss: 4.096895596403701
Validation loss: 3.692814027231217

Epoch: 5| Step: 1
Training loss: 3.8683483500739086
Validation loss: 3.681661927097467

Epoch: 5| Step: 2
Training loss: 3.9134737893091063
Validation loss: 3.678306561349972

Epoch: 5| Step: 3
Training loss: 3.453240025878677
Validation loss: 3.6729139475767916

Epoch: 5| Step: 4
Training loss: 3.9520649449884724
Validation loss: 3.6682485531625098

Epoch: 5| Step: 5
Training loss: 3.5950795243636855
Validation loss: 3.662779564571556

Epoch: 5| Step: 6
Training loss: 3.5521295419560523
Validation loss: 3.6603803069753087

Epoch: 5| Step: 7
Training loss: 3.201017849692165
Validation loss: 3.655807854024762

Epoch: 5| Step: 8
Training loss: 4.011731586974349
Validation loss: 3.656801151187385

Epoch: 5| Step: 9
Training loss: 4.744695612929304
Validation loss: 3.651093459066617

Epoch: 5| Step: 10
Training loss: 3.827936782880944
Validation loss: 3.650156167072514

Epoch: 15| Step: 0
Training loss: 3.140767412135733
Validation loss: 3.648098764524355

Epoch: 5| Step: 1
Training loss: 2.9209441471891475
Validation loss: 3.640681925140254

Epoch: 5| Step: 2
Training loss: 4.218193639167676
Validation loss: 3.641089830682771

Epoch: 5| Step: 3
Training loss: 4.168579628821569
Validation loss: 3.638379101328508

Epoch: 5| Step: 4
Training loss: 3.0608441294303064
Validation loss: 3.6342725804936222

Epoch: 5| Step: 5
Training loss: 4.162375160155191
Validation loss: 3.630062015873445

Epoch: 5| Step: 6
Training loss: 4.29366734854096
Validation loss: 3.6294169025004805

Epoch: 5| Step: 7
Training loss: 4.611035684686166
Validation loss: 3.623868051952717

Epoch: 5| Step: 8
Training loss: 4.0109596314245035
Validation loss: 3.619933762427908

Epoch: 5| Step: 9
Training loss: 3.8012081584741306
Validation loss: 3.6160415517095035

Epoch: 5| Step: 10
Training loss: 3.154031408140248
Validation loss: 3.6141210543350977

Epoch: 16| Step: 0
Training loss: 3.8120543422688304
Validation loss: 3.6244966194934087

Epoch: 5| Step: 1
Training loss: 3.991429923303377
Validation loss: 3.607112649076717

Epoch: 5| Step: 2
Training loss: 4.285603558154442
Validation loss: 3.612083818883395

Epoch: 5| Step: 3
Training loss: 3.750663444323285
Validation loss: 3.614053771390946

Epoch: 5| Step: 4
Training loss: 4.332622958913176
Validation loss: 3.6071830549780923

Epoch: 5| Step: 5
Training loss: 4.558957331393099
Validation loss: 3.6024225726111037

Epoch: 5| Step: 6
Training loss: 2.823114751831398
Validation loss: 3.594522531019653

Epoch: 5| Step: 7
Training loss: 2.9575913980892894
Validation loss: 3.590922616203196

Epoch: 5| Step: 8
Training loss: 4.233494515742206
Validation loss: 3.5909606580787563

Epoch: 5| Step: 9
Training loss: 3.3502083557013775
Validation loss: 3.586922334664313

Epoch: 5| Step: 10
Training loss: 3.1633765713383357
Validation loss: 3.5816189718364573

Epoch: 17| Step: 0
Training loss: 3.976915744762816
Validation loss: 3.578698637772291

Epoch: 5| Step: 1
Training loss: 3.191320336444953
Validation loss: 3.577738666755885

Epoch: 5| Step: 2
Training loss: 4.237729928859456
Validation loss: 3.573612834251304

Epoch: 5| Step: 3
Training loss: 3.39527173849497
Validation loss: 3.5739952723589616

Epoch: 5| Step: 4
Training loss: 3.1545190880512806
Validation loss: 3.573010271239968

Epoch: 5| Step: 5
Training loss: 3.8637792499660564
Validation loss: 3.5713248599356726

Epoch: 5| Step: 6
Training loss: 4.284988219201575
Validation loss: 3.571075548195285

Epoch: 5| Step: 7
Training loss: 3.2401946412007736
Validation loss: 3.565052293333728

Epoch: 5| Step: 8
Training loss: 3.2323081373966445
Validation loss: 3.5599167789245985

Epoch: 5| Step: 9
Training loss: 4.593873729466795
Validation loss: 3.56002069657824

Epoch: 5| Step: 10
Training loss: 4.000913515681255
Validation loss: 3.555281090354782

Epoch: 18| Step: 0
Training loss: 2.8534330738615257
Validation loss: 3.5557448440800936

Epoch: 5| Step: 1
Training loss: 4.305586650011452
Validation loss: 3.5540504675371736

Epoch: 5| Step: 2
Training loss: 3.2034362641733027
Validation loss: 3.5508166722636187

Epoch: 5| Step: 3
Training loss: 4.821026271606849
Validation loss: 3.552081117865981

Epoch: 5| Step: 4
Training loss: 3.669451104260033
Validation loss: 3.5498392528864127

Epoch: 5| Step: 5
Training loss: 3.67575180252717
Validation loss: 3.548586459726058

Epoch: 5| Step: 6
Training loss: 3.5978903098909
Validation loss: 3.5499414478137274

Epoch: 5| Step: 7
Training loss: 4.282389022894605
Validation loss: 3.543056003200614

Epoch: 5| Step: 8
Training loss: 3.9083795464771955
Validation loss: 3.5406927088189377

Epoch: 5| Step: 9
Training loss: 2.107845175499024
Validation loss: 3.5384346263915805

Epoch: 5| Step: 10
Training loss: 4.189452669726083
Validation loss: 3.5433845267464457

Epoch: 19| Step: 0
Training loss: 3.295473062827962
Validation loss: 3.5341133939507716

Epoch: 5| Step: 1
Training loss: 3.7044173291373483
Validation loss: 3.5352283616145153

Epoch: 5| Step: 2
Training loss: 3.6529544421763886
Validation loss: 3.5373727459385056

Epoch: 5| Step: 3
Training loss: 3.869588457251134
Validation loss: 3.536967775444761

Epoch: 5| Step: 4
Training loss: 3.310900175884258
Validation loss: 3.5365206534608924

Epoch: 5| Step: 5
Training loss: 4.385596820577132
Validation loss: 3.5367588360941498

Epoch: 5| Step: 6
Training loss: 4.123501129642396
Validation loss: 3.5346573182906185

Epoch: 5| Step: 7
Training loss: 3.186311387989327
Validation loss: 3.5281911719243957

Epoch: 5| Step: 8
Training loss: 4.183260465395131
Validation loss: 3.5295449323110337

Epoch: 5| Step: 9
Training loss: 3.8085536856867086
Validation loss: 3.5278003456023246

Epoch: 5| Step: 10
Training loss: 3.397027926963843
Validation loss: 3.524957015113561

Epoch: 20| Step: 0
Training loss: 3.298238174147792
Validation loss: 3.523566288039643

Epoch: 5| Step: 1
Training loss: 3.8593493009012785
Validation loss: 3.522737306558847

Epoch: 5| Step: 2
Training loss: 3.511105221798407
Validation loss: 3.5207340590307297

Epoch: 5| Step: 3
Training loss: 3.441962380132171
Validation loss: 3.5211181297291794

Epoch: 5| Step: 4
Training loss: 3.7999634289236557
Validation loss: 3.518326455874523

Epoch: 5| Step: 5
Training loss: 3.4470806817864887
Validation loss: 3.513163226838493

Epoch: 5| Step: 6
Training loss: 4.04056625854561
Validation loss: 3.512252957338903

Epoch: 5| Step: 7
Training loss: 3.727674018589499
Validation loss: 3.5069437804631494

Epoch: 5| Step: 8
Training loss: 3.8694260408673258
Validation loss: 3.5034880155815693

Epoch: 5| Step: 9
Training loss: 3.607648956966864
Validation loss: 3.469595428705291

Epoch: 5| Step: 10
Training loss: 4.279602402018247
Validation loss: 3.4948611424559246

Epoch: 21| Step: 0
Training loss: 3.945288690174132
Validation loss: 3.4919968353613484

Epoch: 5| Step: 1
Training loss: 3.3123901636879345
Validation loss: 3.489907215548212

Epoch: 5| Step: 2
Training loss: 3.400531693566492
Validation loss: 3.466056600633374

Epoch: 5| Step: 3
Training loss: 3.6486181177689074
Validation loss: 3.4715968980920358

Epoch: 5| Step: 4
Training loss: 3.7348857195221683
Validation loss: 3.477917583607194

Epoch: 5| Step: 5
Training loss: 3.874072794579394
Validation loss: 3.4761872872006716

Epoch: 5| Step: 6
Training loss: 2.999468120473579
Validation loss: 3.4691692683881707

Epoch: 5| Step: 7
Training loss: 3.824434954227384
Validation loss: 3.465666827385107

Epoch: 5| Step: 8
Training loss: 4.138557119250244
Validation loss: 3.4621661775657833

Epoch: 5| Step: 9
Training loss: 3.931505514553161
Validation loss: 3.458414196655887

Epoch: 5| Step: 10
Training loss: 3.5874662444224623
Validation loss: 3.4530707960914158

Epoch: 22| Step: 0
Training loss: 3.647626831694259
Validation loss: 3.4519611372637

Epoch: 5| Step: 1
Training loss: 3.543367777669248
Validation loss: 3.4793400069474756

Epoch: 5| Step: 2
Training loss: 3.042741994770625
Validation loss: 3.4435914153566203

Epoch: 5| Step: 3
Training loss: 3.576728514971749
Validation loss: 3.4314108456295975

Epoch: 5| Step: 4
Training loss: 3.496891139643482
Validation loss: 3.427204738221609

Epoch: 5| Step: 5
Training loss: 3.683310375458529
Validation loss: 3.429676746661103

Epoch: 5| Step: 6
Training loss: 4.010579423780699
Validation loss: 3.4380047022127296

Epoch: 5| Step: 7
Training loss: 4.006106959986655
Validation loss: 3.4297021028397148

Epoch: 5| Step: 8
Training loss: 3.6654378103346215
Validation loss: 3.427001111825595

Epoch: 5| Step: 9
Training loss: 3.7123235744080763
Validation loss: 3.427269095590155

Epoch: 5| Step: 10
Training loss: 3.8111895200660553
Validation loss: 3.426494298042901

Epoch: 23| Step: 0
Training loss: 3.6780402187536017
Validation loss: 3.423769836189809

Epoch: 5| Step: 1
Training loss: 3.1911891457194015
Validation loss: 3.4242518006039324

Epoch: 5| Step: 2
Training loss: 4.204360723537875
Validation loss: 3.42185727257809

Epoch: 5| Step: 3
Training loss: 4.016382524457011
Validation loss: 3.422580348306673

Epoch: 5| Step: 4
Training loss: 3.5531922937091682
Validation loss: 3.416891657616796

Epoch: 5| Step: 5
Training loss: 3.450993911653784
Validation loss: 3.414121773015816

Epoch: 5| Step: 6
Training loss: 3.8387388733404766
Validation loss: 3.4116275813316435

Epoch: 5| Step: 7
Training loss: 3.8299312145141924
Validation loss: 3.4090497907195445

Epoch: 5| Step: 8
Training loss: 3.101278373714545
Validation loss: 3.4047868379684294

Epoch: 5| Step: 9
Training loss: 3.3814935733971563
Validation loss: 3.40267391290474

Epoch: 5| Step: 10
Training loss: 3.62172340424695
Validation loss: 3.401316718779325

Epoch: 24| Step: 0
Training loss: 2.7449027418406478
Validation loss: 3.3996718501065653

Epoch: 5| Step: 1
Training loss: 4.2543978656609935
Validation loss: 3.3989989936480853

Epoch: 5| Step: 2
Training loss: 3.714575468016873
Validation loss: 3.3987442551422546

Epoch: 5| Step: 3
Training loss: 3.171361120530351
Validation loss: 3.3978063344035654

Epoch: 5| Step: 4
Training loss: 3.3583153761264506
Validation loss: 3.396426891787807

Epoch: 5| Step: 5
Training loss: 3.580831245585694
Validation loss: 3.3969458388284406

Epoch: 5| Step: 6
Training loss: 3.5962397699671333
Validation loss: 3.3949464542887284

Epoch: 5| Step: 7
Training loss: 3.850567733717749
Validation loss: 3.392608483564465

Epoch: 5| Step: 8
Training loss: 3.8723154921193874
Validation loss: 3.392136197468748

Epoch: 5| Step: 9
Training loss: 3.9478893966873696
Validation loss: 3.3908996380072303

Epoch: 5| Step: 10
Training loss: 3.5407835962745553
Validation loss: 3.390063988754468

Epoch: 25| Step: 0
Training loss: 4.187446935516742
Validation loss: 3.390305828967012

Epoch: 5| Step: 1
Training loss: 3.660140877185566
Validation loss: 3.3888510898001982

Epoch: 5| Step: 2
Training loss: 3.2867169568107033
Validation loss: 3.389156897197468

Epoch: 5| Step: 3
Training loss: 4.175334967235928
Validation loss: 3.388852421226842

Epoch: 5| Step: 4
Training loss: 2.50317610213447
Validation loss: 3.3853808021381084

Epoch: 5| Step: 5
Training loss: 3.5984365671134264
Validation loss: 3.385618250345631

Epoch: 5| Step: 6
Training loss: 3.589858892531311
Validation loss: 3.3845208847504424

Epoch: 5| Step: 7
Training loss: 3.312466603236717
Validation loss: 3.3849050332441393

Epoch: 5| Step: 8
Training loss: 3.368050661553217
Validation loss: 3.382517342151572

Epoch: 5| Step: 9
Training loss: 3.8587025662773127
Validation loss: 3.3829865675022286

Epoch: 5| Step: 10
Training loss: 3.982131146664846
Validation loss: 3.381963923200124

Epoch: 26| Step: 0
Training loss: 3.7071925490955193
Validation loss: 3.3802144821467275

Epoch: 5| Step: 1
Training loss: 3.909214695266993
Validation loss: 3.3795960767716804

Epoch: 5| Step: 2
Training loss: 4.190209494294898
Validation loss: 3.379040231063145

Epoch: 5| Step: 3
Training loss: 3.0738044275380374
Validation loss: 3.37854932362411

Epoch: 5| Step: 4
Training loss: 3.0852399206612753
Validation loss: 3.3764515895676936

Epoch: 5| Step: 5
Training loss: 3.4461185956883895
Validation loss: 3.375370852970169

Epoch: 5| Step: 6
Training loss: 3.68141940233899
Validation loss: 3.375679174135846

Epoch: 5| Step: 7
Training loss: 3.9318048373711028
Validation loss: 3.3753695731892273

Epoch: 5| Step: 8
Training loss: 3.385865980800393
Validation loss: 3.372675745206293

Epoch: 5| Step: 9
Training loss: 3.1582899394279336
Validation loss: 3.3726304964379543

Epoch: 5| Step: 10
Training loss: 3.9841156519836805
Validation loss: 3.3721026628079533

Epoch: 27| Step: 0
Training loss: 3.7755343532684167
Validation loss: 3.369914899720236

Epoch: 5| Step: 1
Training loss: 3.3709706872996965
Validation loss: 3.369052900634952

Epoch: 5| Step: 2
Training loss: 3.800171602289579
Validation loss: 3.3679539024530096

Epoch: 5| Step: 3
Training loss: 3.5513836273113273
Validation loss: 3.366747681020577

Epoch: 5| Step: 4
Training loss: 3.8347797705568274
Validation loss: 3.3652584364147407

Epoch: 5| Step: 5
Training loss: 3.138947147815226
Validation loss: 3.364231319916426

Epoch: 5| Step: 6
Training loss: 3.3309633571839026
Validation loss: 3.362186562776582

Epoch: 5| Step: 7
Training loss: 3.4938526663939014
Validation loss: 3.360460114991434

Epoch: 5| Step: 8
Training loss: 4.305120152160232
Validation loss: 3.359315650837318

Epoch: 5| Step: 9
Training loss: 3.1594942245853193
Validation loss: 3.355764378569816

Epoch: 5| Step: 10
Training loss: 3.6702725424120066
Validation loss: 3.3547338348735734

Epoch: 28| Step: 0
Training loss: 3.682064511614101
Validation loss: 3.3597380426454087

Epoch: 5| Step: 1
Training loss: 3.863733093560414
Validation loss: 3.3554236053635345

Epoch: 5| Step: 2
Training loss: 3.907160660450848
Validation loss: 3.351395967503801

Epoch: 5| Step: 3
Training loss: 3.5226604679071416
Validation loss: 3.3505903324155244

Epoch: 5| Step: 4
Training loss: 3.0809855070977354
Validation loss: 3.3501884722108968

Epoch: 5| Step: 5
Training loss: 3.742561847224151
Validation loss: 3.3501078733837266

Epoch: 5| Step: 6
Training loss: 3.2158166055342283
Validation loss: 3.3497724192220493

Epoch: 5| Step: 7
Training loss: 3.503588063434014
Validation loss: 3.3479612487715644

Epoch: 5| Step: 8
Training loss: 3.778771210616305
Validation loss: 3.348214402409252

Epoch: 5| Step: 9
Training loss: 3.923135744778716
Validation loss: 3.3481747678269476

Epoch: 5| Step: 10
Training loss: 3.0119126946409254
Validation loss: 3.3460995662468256

Epoch: 29| Step: 0
Training loss: 2.787162325809858
Validation loss: 3.347568742234846

Epoch: 5| Step: 1
Training loss: 4.656905979314044
Validation loss: 3.3463227926974652

Epoch: 5| Step: 2
Training loss: 4.611710916648544
Validation loss: 3.3467143928531398

Epoch: 5| Step: 3
Training loss: 3.1712578234126836
Validation loss: 3.3450256281977233

Epoch: 5| Step: 4
Training loss: 3.3418018691060727
Validation loss: 3.341587144958416

Epoch: 5| Step: 5
Training loss: 2.9165944408375015
Validation loss: 3.3405744339454078

Epoch: 5| Step: 6
Training loss: 4.1748105126055854
Validation loss: 3.3405641458288096

Epoch: 5| Step: 7
Training loss: 3.262335914197897
Validation loss: 3.3396975103558826

Epoch: 5| Step: 8
Training loss: 3.0788407631186634
Validation loss: 3.341681555869606

Epoch: 5| Step: 9
Training loss: 3.5599441729679464
Validation loss: 3.3433741681371343

Epoch: 5| Step: 10
Training loss: 3.1389292223954346
Validation loss: 3.3404997465333097

Epoch: 30| Step: 0
Training loss: 3.7167878945142427
Validation loss: 3.3366723093421924

Epoch: 5| Step: 1
Training loss: 2.688832507142244
Validation loss: 3.334663120223296

Epoch: 5| Step: 2
Training loss: 3.8712102755071807
Validation loss: 3.3337731260972054

Epoch: 5| Step: 3
Training loss: 2.1846785742340415
Validation loss: 3.3330497410843845

Epoch: 5| Step: 4
Training loss: 4.136833556746114
Validation loss: 3.3345708631502022

Epoch: 5| Step: 5
Training loss: 3.2663938356504403
Validation loss: 3.3324036645127086

Epoch: 5| Step: 6
Training loss: 3.6428754015339413
Validation loss: 3.3316186068191747

Epoch: 5| Step: 7
Training loss: 4.093340671255222
Validation loss: 3.3313823979392327

Epoch: 5| Step: 8
Training loss: 3.760204418388235
Validation loss: 3.3307122497865325

Epoch: 5| Step: 9
Training loss: 3.689899245956792
Validation loss: 3.33073853946796

Epoch: 5| Step: 10
Training loss: 3.7763050627647905
Validation loss: 3.3298717041821186

Epoch: 31| Step: 0
Training loss: 2.422919361990963
Validation loss: 3.328339668347715

Epoch: 5| Step: 1
Training loss: 3.14285578665766
Validation loss: 3.3275329904471063

Epoch: 5| Step: 2
Training loss: 3.882574001179345
Validation loss: 3.3270282200470365

Epoch: 5| Step: 3
Training loss: 3.3142886820671813
Validation loss: 3.3271394208408607

Epoch: 5| Step: 4
Training loss: 3.6332423458314036
Validation loss: 3.3268103661822295

Epoch: 5| Step: 5
Training loss: 4.013021968748149
Validation loss: 3.3261969380921186

Epoch: 5| Step: 6
Training loss: 3.716023447346702
Validation loss: 3.3262250299883727

Epoch: 5| Step: 7
Training loss: 4.106723408575383
Validation loss: 3.325006549466992

Epoch: 5| Step: 8
Training loss: 3.617595608389617
Validation loss: 3.3245339788633097

Epoch: 5| Step: 9
Training loss: 2.813189612720611
Validation loss: 3.3235196877240933

Epoch: 5| Step: 10
Training loss: 4.233376022684316
Validation loss: 3.322599030844147

Epoch: 32| Step: 0
Training loss: 3.703936910351506
Validation loss: 3.3220507771426817

Epoch: 5| Step: 1
Training loss: 3.561937388114528
Validation loss: 3.321581311657665

Epoch: 5| Step: 2
Training loss: 3.535225040335541
Validation loss: 3.320752367178845

Epoch: 5| Step: 3
Training loss: 3.8477468412162144
Validation loss: 3.320091757726405

Epoch: 5| Step: 4
Training loss: 2.9652203909934056
Validation loss: 3.319510283002938

Epoch: 5| Step: 5
Training loss: 3.406461096705662
Validation loss: 3.319254731618471

Epoch: 5| Step: 6
Training loss: 3.1925514435712126
Validation loss: 3.3184666049684464

Epoch: 5| Step: 7
Training loss: 3.1701959384568026
Validation loss: 3.317770603732923

Epoch: 5| Step: 8
Training loss: 3.5224325095886413
Validation loss: 3.317263941340795

Epoch: 5| Step: 9
Training loss: 4.266317793371479
Validation loss: 3.316779346090696

Epoch: 5| Step: 10
Training loss: 3.857297392176535
Validation loss: 3.3161450416803664

Epoch: 33| Step: 0
Training loss: 3.38665468711937
Validation loss: 3.315594732614896

Epoch: 5| Step: 1
Training loss: 3.407288419293767
Validation loss: 3.3151041042854152

Epoch: 5| Step: 2
Training loss: 3.5014076127160263
Validation loss: 3.3138358560250567

Epoch: 5| Step: 3
Training loss: 3.9838529356964014
Validation loss: 3.3135871302869426

Epoch: 5| Step: 4
Training loss: 4.0002624902429496
Validation loss: 3.3131369181398123

Epoch: 5| Step: 5
Training loss: 2.9777366745264473
Validation loss: 3.3123294277933955

Epoch: 5| Step: 6
Training loss: 3.380115164877083
Validation loss: 3.3116786400510168

Epoch: 5| Step: 7
Training loss: 3.0635013111149676
Validation loss: 3.312255854247341

Epoch: 5| Step: 8
Training loss: 3.51269463376592
Validation loss: 3.313720656222823

Epoch: 5| Step: 9
Training loss: 4.309155701609977
Validation loss: 3.311315378463984

Epoch: 5| Step: 10
Training loss: 3.332910097591582
Validation loss: 3.309146622458224

Epoch: 34| Step: 0
Training loss: 3.4510846906874604
Validation loss: 3.3096907504451964

Epoch: 5| Step: 1
Training loss: 3.7363487996846967
Validation loss: 3.310050753863687

Epoch: 5| Step: 2
Training loss: 3.83299512338664
Validation loss: 3.309299864991822

Epoch: 5| Step: 3
Training loss: 3.1413837484233595
Validation loss: 3.309228999820554

Epoch: 5| Step: 4
Training loss: 3.9242499102495065
Validation loss: 3.3078888684427694

Epoch: 5| Step: 5
Training loss: 3.167090504708485
Validation loss: 3.3091454805302956

Epoch: 5| Step: 6
Training loss: 3.6823721970848857
Validation loss: 3.31170986175999

Epoch: 5| Step: 7
Training loss: 3.898519083212918
Validation loss: 3.3138881567812346

Epoch: 5| Step: 8
Training loss: 2.792366186912806
Validation loss: 3.311771698949199

Epoch: 5| Step: 9
Training loss: 3.580013659573714
Validation loss: 3.311249205631398

Epoch: 5| Step: 10
Training loss: 3.726945965308931
Validation loss: 3.307184650581434

Epoch: 35| Step: 0
Training loss: 2.340993964701177
Validation loss: 3.3056473691812083

Epoch: 5| Step: 1
Training loss: 3.5860856301955097
Validation loss: 3.305322005186823

Epoch: 5| Step: 2
Training loss: 3.90387427756069
Validation loss: 3.304035610520344

Epoch: 5| Step: 3
Training loss: 2.89226901755097
Validation loss: 3.3035901985168943

Epoch: 5| Step: 4
Training loss: 3.4955941125605623
Validation loss: 3.3031531333860333

Epoch: 5| Step: 5
Training loss: 3.210123743304401
Validation loss: 3.3022136456134223

Epoch: 5| Step: 6
Training loss: 3.412053055890746
Validation loss: 3.30196195900618

Epoch: 5| Step: 7
Training loss: 3.7941784486364973
Validation loss: 3.301807198831771

Epoch: 5| Step: 8
Training loss: 4.177754691468248
Validation loss: 3.300042061275093

Epoch: 5| Step: 9
Training loss: 3.655525853101755
Validation loss: 3.2996404686275627

Epoch: 5| Step: 10
Training loss: 4.225900876761646
Validation loss: 3.2979629868339204

Epoch: 36| Step: 0
Training loss: 4.107119793560595
Validation loss: 3.298354743245047

Epoch: 5| Step: 1
Training loss: 3.517438903798553
Validation loss: 3.294524831373921

Epoch: 5| Step: 2
Training loss: 3.1208502109887797
Validation loss: 3.2922487430924803

Epoch: 5| Step: 3
Training loss: 2.964935743590921
Validation loss: 3.2904733234336643

Epoch: 5| Step: 4
Training loss: 4.136795057650188
Validation loss: 3.2886394356959636

Epoch: 5| Step: 5
Training loss: 3.659057191621248
Validation loss: 3.2888741294477373

Epoch: 5| Step: 6
Training loss: 3.2891845680473244
Validation loss: 3.289852282221356

Epoch: 5| Step: 7
Training loss: 3.1101229740864635
Validation loss: 3.2844536006111476

Epoch: 5| Step: 8
Training loss: 3.3041502603810664
Validation loss: 3.2824535891132065

Epoch: 5| Step: 9
Training loss: 3.6215252500878585
Validation loss: 3.2803374287652995

Epoch: 5| Step: 10
Training loss: 3.875360902776672
Validation loss: 3.278967419409354

Epoch: 37| Step: 0
Training loss: 3.486118855326352
Validation loss: 3.2798677891823025

Epoch: 5| Step: 1
Training loss: 3.003841007551002
Validation loss: 3.2777368946096965

Epoch: 5| Step: 2
Training loss: 3.565749710670325
Validation loss: 3.2764982523577273

Epoch: 5| Step: 3
Training loss: 3.6446455991740954
Validation loss: 3.2761229524831985

Epoch: 5| Step: 4
Training loss: 3.063818200238279
Validation loss: 3.274534669250425

Epoch: 5| Step: 5
Training loss: 3.1277560478556286
Validation loss: 3.273132587258107

Epoch: 5| Step: 6
Training loss: 3.6280081533826163
Validation loss: 3.271444392271422

Epoch: 5| Step: 7
Training loss: 3.440542227349676
Validation loss: 3.271741361801946

Epoch: 5| Step: 8
Training loss: 3.7320489382708963
Validation loss: 3.2703921651023844

Epoch: 5| Step: 9
Training loss: 3.5326816053744743
Validation loss: 3.2667663718053115

Epoch: 5| Step: 10
Training loss: 4.454990999874181
Validation loss: 3.2654691253591848

Epoch: 38| Step: 0
Training loss: 3.885672730436031
Validation loss: 3.26365476030503

Epoch: 5| Step: 1
Training loss: 3.1753256683331847
Validation loss: 3.26285768700503

Epoch: 5| Step: 2
Training loss: 3.1614892362103384
Validation loss: 3.261600305613444

Epoch: 5| Step: 3
Training loss: 3.827922457572322
Validation loss: 3.2623976908334256

Epoch: 5| Step: 4
Training loss: 3.3591106931817314
Validation loss: 3.2630755759028283

Epoch: 5| Step: 5
Training loss: 3.3196824137905385
Validation loss: 3.257356744934768

Epoch: 5| Step: 6
Training loss: 3.632131598865472
Validation loss: 3.257624582598864

Epoch: 5| Step: 7
Training loss: 3.569720663687882
Validation loss: 3.257653193418586

Epoch: 5| Step: 8
Training loss: 3.1600125990990673
Validation loss: 3.258344397772473

Epoch: 5| Step: 9
Training loss: 3.246975004475319
Validation loss: 3.2582768855636743

Epoch: 5| Step: 10
Training loss: 4.228253546295186
Validation loss: 3.2588072034067523

Epoch: 39| Step: 0
Training loss: 3.621164331499284
Validation loss: 3.2581388276088155

Epoch: 5| Step: 1
Training loss: 3.3372425680138496
Validation loss: 3.257944152348535

Epoch: 5| Step: 2
Training loss: 3.6824125983179137
Validation loss: 3.2561552701146304

Epoch: 5| Step: 3
Training loss: 4.089898780372371
Validation loss: 3.2569649161019107

Epoch: 5| Step: 4
Training loss: 3.7592717309531585
Validation loss: 3.2549960377366953

Epoch: 5| Step: 5
Training loss: 2.747568442661062
Validation loss: 3.2532937576753733

Epoch: 5| Step: 6
Training loss: 3.1915254792408527
Validation loss: 3.253261097488179

Epoch: 5| Step: 7
Training loss: 2.9606348854368587
Validation loss: 3.2524612200797147

Epoch: 5| Step: 8
Training loss: 3.489020428401744
Validation loss: 3.2513474305078414

Epoch: 5| Step: 9
Training loss: 4.065895422255323
Validation loss: 3.251068660511266

Epoch: 5| Step: 10
Training loss: 3.3484634975148606
Validation loss: 3.2498429310141197

Epoch: 40| Step: 0
Training loss: 3.029594992080631
Validation loss: 3.2501410571236087

Epoch: 5| Step: 1
Training loss: 3.042541238823462
Validation loss: 3.2487717856346774

Epoch: 5| Step: 2
Training loss: 3.8323540196794608
Validation loss: 3.248891505728655

Epoch: 5| Step: 3
Training loss: 3.1398852032129247
Validation loss: 3.2469831652268724

Epoch: 5| Step: 4
Training loss: 3.261661734625184
Validation loss: 3.247293773323312

Epoch: 5| Step: 5
Training loss: 3.7176495374350336
Validation loss: 3.2470117853320937

Epoch: 5| Step: 6
Training loss: 3.771147291626462
Validation loss: 3.2465926925968795

Epoch: 5| Step: 7
Training loss: 3.3832873568362802
Validation loss: 3.245794215882749

Epoch: 5| Step: 8
Training loss: 3.712306747801225
Validation loss: 3.2452636090057347

Epoch: 5| Step: 9
Training loss: 3.670843490834784
Validation loss: 3.2449559872783618

Epoch: 5| Step: 10
Training loss: 3.845318729995461
Validation loss: 3.244543285927365

Epoch: 41| Step: 0
Training loss: 3.5711505999699895
Validation loss: 3.244203636322692

Epoch: 5| Step: 1
Training loss: 2.893212227667326
Validation loss: 3.2431154653039296

Epoch: 5| Step: 2
Training loss: 3.891450480324825
Validation loss: 3.242920474755139

Epoch: 5| Step: 3
Training loss: 3.4998311955752914
Validation loss: 3.242562893107564

Epoch: 5| Step: 4
Training loss: 2.9330677114501076
Validation loss: 3.2413983322203963

Epoch: 5| Step: 5
Training loss: 3.2467351800737934
Validation loss: 3.2414500902623975

Epoch: 5| Step: 6
Training loss: 3.395738674474923
Validation loss: 3.2402564870992236

Epoch: 5| Step: 7
Training loss: 4.198642992868932
Validation loss: 3.2401045397223887

Epoch: 5| Step: 8
Training loss: 3.082383671133322
Validation loss: 3.2401558041454956

Epoch: 5| Step: 9
Training loss: 2.9380002508922907
Validation loss: 3.239390249004392

Epoch: 5| Step: 10
Training loss: 4.55902615337564
Validation loss: 3.23870114120077

Epoch: 42| Step: 0
Training loss: 4.368543165383327
Validation loss: 3.2383816001631858

Epoch: 5| Step: 1
Training loss: 2.485064908567275
Validation loss: 3.23871927035026

Epoch: 5| Step: 2
Training loss: 2.5971673720535366
Validation loss: 3.2380906901289275

Epoch: 5| Step: 3
Training loss: 3.5239835261069183
Validation loss: 3.237588397525029

Epoch: 5| Step: 4
Training loss: 3.8999930357259536
Validation loss: 3.2362812059208226

Epoch: 5| Step: 5
Training loss: 3.6762401849692856
Validation loss: 3.2361548275856715

Epoch: 5| Step: 6
Training loss: 2.5474413844619246
Validation loss: 3.2351399906536344

Epoch: 5| Step: 7
Training loss: 3.885054556955727
Validation loss: 3.2352556501332113

Epoch: 5| Step: 8
Training loss: 3.5328616625179734
Validation loss: 3.2340832048030177

Epoch: 5| Step: 9
Training loss: 3.7562648576134765
Validation loss: 3.2339738126688844

Epoch: 5| Step: 10
Training loss: 3.591181625103016
Validation loss: 3.2335311980282033

Epoch: 43| Step: 0
Training loss: 2.7955023098210967
Validation loss: 3.2332145880547443

Epoch: 5| Step: 1
Training loss: 3.9650365322205117
Validation loss: 3.232366666690096

Epoch: 5| Step: 2
Training loss: 3.2064019537122186
Validation loss: 3.2316086050899417

Epoch: 5| Step: 3
Training loss: 3.9915418606693924
Validation loss: 3.2310205095455053

Epoch: 5| Step: 4
Training loss: 3.5657470361284997
Validation loss: 3.230761336643335

Epoch: 5| Step: 5
Training loss: 3.6553534036053237
Validation loss: 3.2308378332520933

Epoch: 5| Step: 6
Training loss: 2.901556018499593
Validation loss: 3.2297454320614785

Epoch: 5| Step: 7
Training loss: 3.2001266216022
Validation loss: 3.229307294807552

Epoch: 5| Step: 8
Training loss: 4.06605069440996
Validation loss: 3.2295055046236008

Epoch: 5| Step: 9
Training loss: 2.7815684446985527
Validation loss: 3.2288707717995577

Epoch: 5| Step: 10
Training loss: 3.9377722267626503
Validation loss: 3.2279348690854044

Epoch: 44| Step: 0
Training loss: 3.3771284950306883
Validation loss: 3.227213085161727

Epoch: 5| Step: 1
Training loss: 3.695271981724877
Validation loss: 3.2270281016094158

Epoch: 5| Step: 2
Training loss: 3.0125327587325126
Validation loss: 3.226568768933258

Epoch: 5| Step: 3
Training loss: 3.3214804356711025
Validation loss: 3.2260053299027516

Epoch: 5| Step: 4
Training loss: 3.648643732879046
Validation loss: 3.225296718921976

Epoch: 5| Step: 5
Training loss: 3.1725120468452013
Validation loss: 3.2253396359939845

Epoch: 5| Step: 6
Training loss: 3.987698115386927
Validation loss: 3.224559599776701

Epoch: 5| Step: 7
Training loss: 3.875448877730972
Validation loss: 3.224190152859574

Epoch: 5| Step: 8
Training loss: 2.9437382788941115
Validation loss: 3.2236333771377232

Epoch: 5| Step: 9
Training loss: 3.421236161471259
Validation loss: 3.223593782274132

Epoch: 5| Step: 10
Training loss: 3.725325597063723
Validation loss: 3.222417048541591

Epoch: 45| Step: 0
Training loss: 3.7606521631330962
Validation loss: 3.221931951574533

Epoch: 5| Step: 1
Training loss: 3.7650921076517587
Validation loss: 3.221059933863705

Epoch: 5| Step: 2
Training loss: 3.6732868483337375
Validation loss: 3.220678723103272

Epoch: 5| Step: 3
Training loss: 3.5880923642759246
Validation loss: 3.2192070382942117

Epoch: 5| Step: 4
Training loss: 3.1646583278694274
Validation loss: 3.2203564058585763

Epoch: 5| Step: 5
Training loss: 3.7142719907821493
Validation loss: 3.220320603842693

Epoch: 5| Step: 6
Training loss: 3.581299552108647
Validation loss: 3.221307103766616

Epoch: 5| Step: 7
Training loss: 3.0634485449587467
Validation loss: 3.2264682547741845

Epoch: 5| Step: 8
Training loss: 2.9054350992312195
Validation loss: 3.2551679863511005

Epoch: 5| Step: 9
Training loss: 3.5590107209745407
Validation loss: 3.218830296006395

Epoch: 5| Step: 10
Training loss: 3.359443273515895
Validation loss: 3.2182637687781366

Epoch: 46| Step: 0
Training loss: 3.8037637141316147
Validation loss: 3.218457207174566

Epoch: 5| Step: 1
Training loss: 4.353528768486216
Validation loss: 3.2185394078038736

Epoch: 5| Step: 2
Training loss: 3.6962442977391707
Validation loss: 3.219333153415986

Epoch: 5| Step: 3
Training loss: 3.909320814456992
Validation loss: 3.2181924969732214

Epoch: 5| Step: 4
Training loss: 2.5671490620517563
Validation loss: 3.2189738618599884

Epoch: 5| Step: 5
Training loss: 2.9733103209262177
Validation loss: 3.2185263177184216

Epoch: 5| Step: 6
Training loss: 3.3401084393469445
Validation loss: 3.217798084506541

Epoch: 5| Step: 7
Training loss: 2.7691563189720054
Validation loss: 3.2167302919531036

Epoch: 5| Step: 8
Training loss: 2.677942625443958
Validation loss: 3.2165811887789615

Epoch: 5| Step: 9
Training loss: 3.8556808521555825
Validation loss: 3.2164642169749165

Epoch: 5| Step: 10
Training loss: 3.8382827209059873
Validation loss: 3.2169604122750446

Epoch: 47| Step: 0
Training loss: 3.667465354168112
Validation loss: 3.215630395557626

Epoch: 5| Step: 1
Training loss: 3.120340306478584
Validation loss: 3.215443380696721

Epoch: 5| Step: 2
Training loss: 3.781660830035244
Validation loss: 3.213857432644842

Epoch: 5| Step: 3
Training loss: 3.3599336381444167
Validation loss: 3.2132770536218356

Epoch: 5| Step: 4
Training loss: 3.578683201589158
Validation loss: 3.2132166208155764

Epoch: 5| Step: 5
Training loss: 4.305681006678783
Validation loss: 3.212951785247067

Epoch: 5| Step: 6
Training loss: 2.80230781951152
Validation loss: 3.2122553672901377

Epoch: 5| Step: 7
Training loss: 3.9034171857115156
Validation loss: 3.21206437758757

Epoch: 5| Step: 8
Training loss: 3.2346808984552933
Validation loss: 3.2106945973018712

Epoch: 5| Step: 9
Training loss: 3.1005181156460315
Validation loss: 3.210408608042367

Epoch: 5| Step: 10
Training loss: 2.9854052298291944
Validation loss: 3.21001095346928

Epoch: 48| Step: 0
Training loss: 4.256828656401493
Validation loss: 3.208965867751824

Epoch: 5| Step: 1
Training loss: 2.973697755602409
Validation loss: 3.208122868713708

Epoch: 5| Step: 2
Training loss: 2.936673636570719
Validation loss: 3.208155443437491

Epoch: 5| Step: 3
Training loss: 3.892316213200058
Validation loss: 3.2076287494077027

Epoch: 5| Step: 4
Training loss: 4.068857002316234
Validation loss: 3.2074047167587945

Epoch: 5| Step: 5
Training loss: 2.7137950600740424
Validation loss: 3.2061189023206476

Epoch: 5| Step: 6
Training loss: 3.5004402973612656
Validation loss: 3.205731182991259

Epoch: 5| Step: 7
Training loss: 3.262760640106612
Validation loss: 3.205622653130161

Epoch: 5| Step: 8
Training loss: 3.6166703120153194
Validation loss: 3.2048488345282657

Epoch: 5| Step: 9
Training loss: 3.582098607685258
Validation loss: 3.2038691806976964

Epoch: 5| Step: 10
Training loss: 2.8683402838909986
Validation loss: 3.2038150367237694

Epoch: 49| Step: 0
Training loss: 3.360770144301688
Validation loss: 3.2036149485373424

Epoch: 5| Step: 1
Training loss: 3.1454552092679275
Validation loss: 3.203212204012985

Epoch: 5| Step: 2
Training loss: 3.6977028081958205
Validation loss: 3.2028033431427008

Epoch: 5| Step: 3
Training loss: 3.3883525774913226
Validation loss: 3.202012162841358

Epoch: 5| Step: 4
Training loss: 4.109915230055504
Validation loss: 3.2020984188121084

Epoch: 5| Step: 5
Training loss: 3.3400604713128126
Validation loss: 3.201545019523502

Epoch: 5| Step: 6
Training loss: 2.318199865675524
Validation loss: 3.2013515602247558

Epoch: 5| Step: 7
Training loss: 3.248994671780534
Validation loss: 3.2001558610364933

Epoch: 5| Step: 8
Training loss: 3.7365504356726134
Validation loss: 3.200247339590551

Epoch: 5| Step: 9
Training loss: 3.748555604601401
Validation loss: 3.1995641653197358

Epoch: 5| Step: 10
Training loss: 3.726045776626557
Validation loss: 3.1991005495466265

Epoch: 50| Step: 0
Training loss: 3.3495515779452374
Validation loss: 3.1986031305395826

Epoch: 5| Step: 1
Training loss: 3.227754755935669
Validation loss: 3.1984206602787606

Epoch: 5| Step: 2
Training loss: 3.7038066252783843
Validation loss: 3.1981249361292052

Epoch: 5| Step: 3
Training loss: 3.723945130367038
Validation loss: 3.1971545754176938

Epoch: 5| Step: 4
Training loss: 4.1338570037456535
Validation loss: 3.1969960905097725

Epoch: 5| Step: 5
Training loss: 3.486571299729949
Validation loss: 3.1963490429758163

Epoch: 5| Step: 6
Training loss: 2.784046181936995
Validation loss: 3.195753480145427

Epoch: 5| Step: 7
Training loss: 3.750795407180114
Validation loss: 3.1955167334698342

Epoch: 5| Step: 8
Training loss: 3.0398793826518475
Validation loss: 3.195134251576062

Epoch: 5| Step: 9
Training loss: 3.6712331657296464
Validation loss: 3.194334589201868

Epoch: 5| Step: 10
Training loss: 2.84176583289532
Validation loss: 3.1944890089762317

Epoch: 51| Step: 0
Training loss: 2.7119462392874154
Validation loss: 3.1934841298594967

Epoch: 5| Step: 1
Training loss: 3.6698877029492745
Validation loss: 3.193096712525557

Epoch: 5| Step: 2
Training loss: 3.605275389672192
Validation loss: 3.1926821736196476

Epoch: 5| Step: 3
Training loss: 3.338103473410364
Validation loss: 3.192414073448294

Epoch: 5| Step: 4
Training loss: 3.637682335337591
Validation loss: 3.191980917264225

Epoch: 5| Step: 5
Training loss: 3.7896410942743755
Validation loss: 3.1913271549890583

Epoch: 5| Step: 6
Training loss: 3.295935763677529
Validation loss: 3.190881825585637

Epoch: 5| Step: 7
Training loss: 3.789669153473116
Validation loss: 3.1905378519095806

Epoch: 5| Step: 8
Training loss: 3.021980979662657
Validation loss: 3.190082578336971

Epoch: 5| Step: 9
Training loss: 4.011261108801495
Validation loss: 3.189805725214514

Epoch: 5| Step: 10
Training loss: 2.7694727107265353
Validation loss: 3.189689749477821

Epoch: 52| Step: 0
Training loss: 3.117546500659911
Validation loss: 3.188757569327497

Epoch: 5| Step: 1
Training loss: 3.929912462108904
Validation loss: 3.1890043166911504

Epoch: 5| Step: 2
Training loss: 3.066168942350083
Validation loss: 3.187775411978813

Epoch: 5| Step: 3
Training loss: 3.35610163696391
Validation loss: 3.18789555224451

Epoch: 5| Step: 4
Training loss: 3.2394736088429763
Validation loss: 3.1870780116973694

Epoch: 5| Step: 5
Training loss: 3.4144517340601075
Validation loss: 3.1882550099193514

Epoch: 5| Step: 6
Training loss: 4.098264810848472
Validation loss: 3.1863086355218697

Epoch: 5| Step: 7
Training loss: 3.71086618455323
Validation loss: 3.1859719186442175

Epoch: 5| Step: 8
Training loss: 3.4918966492240724
Validation loss: 3.1862446667360294

Epoch: 5| Step: 9
Training loss: 2.8037364484210334
Validation loss: 3.185556133089795

Epoch: 5| Step: 10
Training loss: 3.540092133222883
Validation loss: 3.1848808061965324

Epoch: 53| Step: 0
Training loss: 3.8454870005372883
Validation loss: 3.184618096478451

Epoch: 5| Step: 1
Training loss: 2.7943128219440827
Validation loss: 3.184080831184471

Epoch: 5| Step: 2
Training loss: 3.3804180313371535
Validation loss: 3.1835382022487164

Epoch: 5| Step: 3
Training loss: 2.965086594035971
Validation loss: 3.182888158711014

Epoch: 5| Step: 4
Training loss: 3.8698565895655244
Validation loss: 3.1830585363276453

Epoch: 5| Step: 5
Training loss: 4.096967059162461
Validation loss: 3.1821885610930942

Epoch: 5| Step: 6
Training loss: 3.818218008092809
Validation loss: 3.182287783155728

Epoch: 5| Step: 7
Training loss: 3.410270627824848
Validation loss: 3.18110209284237

Epoch: 5| Step: 8
Training loss: 3.3662153287703442
Validation loss: 3.1807261889888245

Epoch: 5| Step: 9
Training loss: 2.644231737043297
Validation loss: 3.180424398280049

Epoch: 5| Step: 10
Training loss: 3.405858848581362
Validation loss: 3.180148815625912

Epoch: 54| Step: 0
Training loss: 2.305853080191624
Validation loss: 3.1800981349021207

Epoch: 5| Step: 1
Training loss: 3.5218854306598812
Validation loss: 3.1791753413642563

Epoch: 5| Step: 2
Training loss: 2.6239552008072673
Validation loss: 3.179000429942766

Epoch: 5| Step: 3
Training loss: 2.308205508974748
Validation loss: 3.178495092164501

Epoch: 5| Step: 4
Training loss: 4.324729937462271
Validation loss: 3.1781679967087455

Epoch: 5| Step: 5
Training loss: 3.390125290572431
Validation loss: 3.1775419913141603

Epoch: 5| Step: 6
Training loss: 3.738997276237824
Validation loss: 3.1778300897335208

Epoch: 5| Step: 7
Training loss: 3.8813928353629996
Validation loss: 3.1766815808381494

Epoch: 5| Step: 8
Training loss: 3.084459013408268
Validation loss: 3.17744539169097

Epoch: 5| Step: 9
Training loss: 4.412760800875365
Validation loss: 3.1759959688915047

Epoch: 5| Step: 10
Training loss: 3.5176059143561518
Validation loss: 3.175698509309473

Epoch: 55| Step: 0
Training loss: 2.6861362989529654
Validation loss: 3.1761282787348475

Epoch: 5| Step: 1
Training loss: 3.9725375387483925
Validation loss: 3.175228137378171

Epoch: 5| Step: 2
Training loss: 3.4747699359508806
Validation loss: 3.1742370368302124

Epoch: 5| Step: 3
Training loss: 3.8496805975067367
Validation loss: 3.174127728957584

Epoch: 5| Step: 4
Training loss: 3.1863808256567956
Validation loss: 3.1736972112294244

Epoch: 5| Step: 5
Training loss: 2.800929194630332
Validation loss: 3.173423374212223

Epoch: 5| Step: 6
Training loss: 3.4719527296812545
Validation loss: 3.176034594439813

Epoch: 5| Step: 7
Training loss: 3.363415368714498
Validation loss: 3.2042607456615473

Epoch: 5| Step: 8
Training loss: 3.469819187653346
Validation loss: 3.171946387925014

Epoch: 5| Step: 9
Training loss: 3.5348508587013567
Validation loss: 3.1959627261478794

Epoch: 5| Step: 10
Training loss: 3.9331815744207996
Validation loss: 3.1780083858712067

Epoch: 56| Step: 0
Training loss: 3.707888344343866
Validation loss: 3.178885830978923

Epoch: 5| Step: 1
Training loss: 3.638152105338251
Validation loss: 3.1839337184842282

Epoch: 5| Step: 2
Training loss: 3.4490973687766133
Validation loss: 3.1828277554178817

Epoch: 5| Step: 3
Training loss: 3.2799129123291335
Validation loss: 3.1877188433505377

Epoch: 5| Step: 4
Training loss: 2.744090753828412
Validation loss: 3.1806936525275464

Epoch: 5| Step: 5
Training loss: 3.5489960768767443
Validation loss: 3.18544835885626

Epoch: 5| Step: 6
Training loss: 3.2775506373726695
Validation loss: 3.185586643391379

Epoch: 5| Step: 7
Training loss: 3.323866864775636
Validation loss: 3.1842488536701086

Epoch: 5| Step: 8
Training loss: 2.999331081837509
Validation loss: 3.1807553875357937

Epoch: 5| Step: 9
Training loss: 4.1462782935717355
Validation loss: 3.181886243578334

Epoch: 5| Step: 10
Training loss: 3.6433263097231756
Validation loss: 3.179252900180441

Epoch: 57| Step: 0
Training loss: 3.512372899046741
Validation loss: 3.1738323503060686

Epoch: 5| Step: 1
Training loss: 3.7352309263608037
Validation loss: 3.1701377218078886

Epoch: 5| Step: 2
Training loss: 3.220607776977041
Validation loss: 3.166524903881211

Epoch: 5| Step: 3
Training loss: 3.341123030305483
Validation loss: 3.166147902525581

Epoch: 5| Step: 4
Training loss: 3.144765676917714
Validation loss: 3.16626257549882

Epoch: 5| Step: 5
Training loss: 3.2453333288781514
Validation loss: 3.164891722427117

Epoch: 5| Step: 6
Training loss: 3.1034581615392858
Validation loss: 3.164837623651602

Epoch: 5| Step: 7
Training loss: 3.718766412778907
Validation loss: 3.16466949243421

Epoch: 5| Step: 8
Training loss: 4.237779438178725
Validation loss: 3.1636601001644302

Epoch: 5| Step: 9
Training loss: 3.0318684684385815
Validation loss: 3.16316862718528

Epoch: 5| Step: 10
Training loss: 3.279493315801426
Validation loss: 3.1632779911981306

Epoch: 58| Step: 0
Training loss: 3.4747331585420036
Validation loss: 3.1623362614772574

Epoch: 5| Step: 1
Training loss: 2.9162743077448483
Validation loss: 3.161648722559692

Epoch: 5| Step: 2
Training loss: 3.5344739392477744
Validation loss: 3.1614939004837095

Epoch: 5| Step: 3
Training loss: 3.7689698112495345
Validation loss: 3.1611069126825635

Epoch: 5| Step: 4
Training loss: 3.396440432211068
Validation loss: 3.1603816299972616

Epoch: 5| Step: 5
Training loss: 3.067451056079838
Validation loss: 3.1599299030880936

Epoch: 5| Step: 6
Training loss: 3.6775890287181285
Validation loss: 3.159507929246049

Epoch: 5| Step: 7
Training loss: 3.532185118423924
Validation loss: 3.1589147137578246

Epoch: 5| Step: 8
Training loss: 2.961392571498148
Validation loss: 3.158672157529385

Epoch: 5| Step: 9
Training loss: 3.4532031572567643
Validation loss: 3.1575446733143155

Epoch: 5| Step: 10
Training loss: 3.867979889423909
Validation loss: 3.1580727746820263

Epoch: 59| Step: 0
Training loss: 3.4613769803324783
Validation loss: 3.1574241235564435

Epoch: 5| Step: 1
Training loss: 3.887013547826131
Validation loss: 3.1569061961736216

Epoch: 5| Step: 2
Training loss: 3.4081147015750215
Validation loss: 3.155896668509743

Epoch: 5| Step: 3
Training loss: 3.4743694803709078
Validation loss: 3.156159432028699

Epoch: 5| Step: 4
Training loss: 2.6761960787020365
Validation loss: 3.155717593441276

Epoch: 5| Step: 5
Training loss: 3.6598834380886376
Validation loss: 3.155073310639056

Epoch: 5| Step: 6
Training loss: 3.256884838463464
Validation loss: 3.1546045394392888

Epoch: 5| Step: 7
Training loss: 3.327637542702117
Validation loss: 3.154690586618768

Epoch: 5| Step: 8
Training loss: 4.391478757559985
Validation loss: 3.1540948086144867

Epoch: 5| Step: 9
Training loss: 3.2508722748649093
Validation loss: 3.1536361087075253

Epoch: 5| Step: 10
Training loss: 2.2909467317673298
Validation loss: 3.153751009011725

Epoch: 60| Step: 0
Training loss: 3.2497391229243973
Validation loss: 3.1528666176590003

Epoch: 5| Step: 1
Training loss: 3.444322231818138
Validation loss: 3.152559970874933

Epoch: 5| Step: 2
Training loss: 3.202155734161784
Validation loss: 3.152329875940267

Epoch: 5| Step: 3
Training loss: 3.9553083941455
Validation loss: 3.152153565967058

Epoch: 5| Step: 4
Training loss: 4.08866321682708
Validation loss: 3.1514487301670804

Epoch: 5| Step: 5
Training loss: 3.3507429067810843
Validation loss: 3.151485217789516

Epoch: 5| Step: 6
Training loss: 2.9647752354361154
Validation loss: 3.150580749456794

Epoch: 5| Step: 7
Training loss: 3.5902713027066038
Validation loss: 3.149447262356789

Epoch: 5| Step: 8
Training loss: 2.962198034421297
Validation loss: 3.149569626521309

Epoch: 5| Step: 9
Training loss: 3.4355751890888393
Validation loss: 3.1496010112420314

Epoch: 5| Step: 10
Training loss: 3.1645459217892986
Validation loss: 3.1479419792718346

Epoch: 61| Step: 0
Training loss: 3.3743746142767828
Validation loss: 3.148304054931321

Epoch: 5| Step: 1
Training loss: 2.9739650496870764
Validation loss: 3.1478105924120827

Epoch: 5| Step: 2
Training loss: 3.9025200698013887
Validation loss: 3.1470768706395686

Epoch: 5| Step: 3
Training loss: 3.0325938912972985
Validation loss: 3.146709345159584

Epoch: 5| Step: 4
Training loss: 3.517463711874718
Validation loss: 3.14691733498117

Epoch: 5| Step: 5
Training loss: 3.1273977617587927
Validation loss: 3.1457060997543573

Epoch: 5| Step: 6
Training loss: 3.1810470786138048
Validation loss: 3.145660285343578

Epoch: 5| Step: 7
Training loss: 3.9696271032282215
Validation loss: 3.145787660402617

Epoch: 5| Step: 8
Training loss: 3.563284135151142
Validation loss: 3.1452625628569595

Epoch: 5| Step: 9
Training loss: 3.3551435923654034
Validation loss: 3.1453017451390557

Epoch: 5| Step: 10
Training loss: 3.453211304289495
Validation loss: 3.1438655249716536

Epoch: 62| Step: 0
Training loss: 4.158131797254022
Validation loss: 3.1438442483816478

Epoch: 5| Step: 1
Training loss: 3.0854978610389723
Validation loss: 3.143134869086749

Epoch: 5| Step: 2
Training loss: 2.9563247058292474
Validation loss: 3.144357870809039

Epoch: 5| Step: 3
Training loss: 3.114206518813627
Validation loss: 3.1424194998286943

Epoch: 5| Step: 4
Training loss: 2.798900616619434
Validation loss: 3.1422647909273396

Epoch: 5| Step: 5
Training loss: 3.923108518625705
Validation loss: 3.1421827129483115

Epoch: 5| Step: 6
Training loss: 3.2419635005922514
Validation loss: 3.1412927273534508

Epoch: 5| Step: 7
Training loss: 3.3676587547257886
Validation loss: 3.140337702381691

Epoch: 5| Step: 8
Training loss: 3.541830231124637
Validation loss: 3.1401307895630377

Epoch: 5| Step: 9
Training loss: 3.189028205294685
Validation loss: 3.140484569554473

Epoch: 5| Step: 10
Training loss: 3.9799978110532637
Validation loss: 3.1398373981843473

Epoch: 63| Step: 0
Training loss: 2.9009270271556855
Validation loss: 3.1394233084111502

Epoch: 5| Step: 1
Training loss: 3.7086845545945644
Validation loss: 3.1391040014889104

Epoch: 5| Step: 2
Training loss: 3.594346502805004
Validation loss: 3.1384154752963496

Epoch: 5| Step: 3
Training loss: 3.654382734243221
Validation loss: 3.1380328273871614

Epoch: 5| Step: 4
Training loss: 3.6244194618230514
Validation loss: 3.1376372216431694

Epoch: 5| Step: 5
Training loss: 3.164742102458468
Validation loss: 3.1373221561361313

Epoch: 5| Step: 6
Training loss: 3.1950414864439014
Validation loss: 3.1372255577311896

Epoch: 5| Step: 7
Training loss: 3.278520302443643
Validation loss: 3.136323581746046

Epoch: 5| Step: 8
Training loss: 3.7929192175415363
Validation loss: 3.136317369476292

Epoch: 5| Step: 9
Training loss: 3.244398865822345
Validation loss: 3.1355278345106323

Epoch: 5| Step: 10
Training loss: 3.213242346344697
Validation loss: 3.1353050530674533

Epoch: 64| Step: 0
Training loss: 4.158156337806297
Validation loss: 3.1354047465497263

Epoch: 5| Step: 1
Training loss: 3.551862126209101
Validation loss: 3.134811053980167

Epoch: 5| Step: 2
Training loss: 3.687506853517532
Validation loss: 3.1341221981654

Epoch: 5| Step: 3
Training loss: 3.130822213012452
Validation loss: 3.133194126103581

Epoch: 5| Step: 4
Training loss: 2.767421160697495
Validation loss: 3.133231629789652

Epoch: 5| Step: 5
Training loss: 3.8812893925386205
Validation loss: 3.1327061265171996

Epoch: 5| Step: 6
Training loss: 3.89289256738466
Validation loss: 3.132687437052846

Epoch: 5| Step: 7
Training loss: 3.09720303273398
Validation loss: 3.1319336524726937

Epoch: 5| Step: 8
Training loss: 2.635779635999713
Validation loss: 3.131730359272218

Epoch: 5| Step: 9
Training loss: 3.4545577861255503
Validation loss: 3.13098701320917

Epoch: 5| Step: 10
Training loss: 2.7295614544263316
Validation loss: 3.130985599966407

Epoch: 65| Step: 0
Training loss: 3.5624983938113157
Validation loss: 3.1302483292159757

Epoch: 5| Step: 1
Training loss: 3.280515025340066
Validation loss: 3.1302444979805686

Epoch: 5| Step: 2
Training loss: 3.136439784888426
Validation loss: 3.129807024906812

Epoch: 5| Step: 3
Training loss: 3.3778112500467494
Validation loss: 3.128999198739567

Epoch: 5| Step: 4
Training loss: 3.389655189870111
Validation loss: 3.1289729829600677

Epoch: 5| Step: 5
Training loss: 2.464250641330366
Validation loss: 3.12830180813307

Epoch: 5| Step: 6
Training loss: 3.455373040912902
Validation loss: 3.1282644371101545

Epoch: 5| Step: 7
Training loss: 4.014376316298997
Validation loss: 3.128138632584477

Epoch: 5| Step: 8
Training loss: 3.4910723038471256
Validation loss: 3.126869530072259

Epoch: 5| Step: 9
Training loss: 3.4824546003702816
Validation loss: 3.127200831190964

Epoch: 5| Step: 10
Training loss: 3.610221202128188
Validation loss: 3.126670882925386

Epoch: 66| Step: 0
Training loss: 3.017970462712674
Validation loss: 3.126181568195616

Epoch: 5| Step: 1
Training loss: 3.0379757543906
Validation loss: 3.125596089270515

Epoch: 5| Step: 2
Training loss: 3.802886348561856
Validation loss: 3.1260262344502707

Epoch: 5| Step: 3
Training loss: 3.2513891332438765
Validation loss: 3.1251704655576074

Epoch: 5| Step: 4
Training loss: 2.8446613570131656
Validation loss: 3.1248850852592907

Epoch: 5| Step: 5
Training loss: 3.4994505042194746
Validation loss: 3.1242140817401296

Epoch: 5| Step: 6
Training loss: 3.55409212261585
Validation loss: 3.124166084510748

Epoch: 5| Step: 7
Training loss: 3.243343873224125
Validation loss: 3.123555216540104

Epoch: 5| Step: 8
Training loss: 3.6902772175932785
Validation loss: 3.123525552642648

Epoch: 5| Step: 9
Training loss: 4.010916357575388
Validation loss: 3.1228448364212222

Epoch: 5| Step: 10
Training loss: 3.2312784160493453
Validation loss: 3.1216677137018927

Epoch: 67| Step: 0
Training loss: 3.235338592733587
Validation loss: 3.121714762228096

Epoch: 5| Step: 1
Training loss: 3.8201433702097516
Validation loss: 3.1214686993797525

Epoch: 5| Step: 2
Training loss: 3.5962902876447296
Validation loss: 3.1206932794050464

Epoch: 5| Step: 3
Training loss: 3.039109884250618
Validation loss: 3.1204566677548717

Epoch: 5| Step: 4
Training loss: 2.7428348135890777
Validation loss: 3.119515551087626

Epoch: 5| Step: 5
Training loss: 4.051999180303191
Validation loss: 3.1194235730592412

Epoch: 5| Step: 6
Training loss: 3.4042493912082152
Validation loss: 3.118912051120098

Epoch: 5| Step: 7
Training loss: 3.3738418287321554
Validation loss: 3.1179520439938058

Epoch: 5| Step: 8
Training loss: 3.1549630137843403
Validation loss: 3.117903782630835

Epoch: 5| Step: 9
Training loss: 3.5309918064485837
Validation loss: 3.116913868504773

Epoch: 5| Step: 10
Training loss: 3.1773875773520968
Validation loss: 3.115728785750034

Epoch: 68| Step: 0
Training loss: 3.3018223672427047
Validation loss: 3.1161108981536705

Epoch: 5| Step: 1
Training loss: 3.6774810201335346
Validation loss: 3.114888403083277

Epoch: 5| Step: 2
Training loss: 3.1516844711190815
Validation loss: 3.1140235422235185

Epoch: 5| Step: 3
Training loss: 3.4895913802476404
Validation loss: 3.113889684398902

Epoch: 5| Step: 4
Training loss: 3.2799113131372772
Validation loss: 3.1129266682591763

Epoch: 5| Step: 5
Training loss: 3.826775511501777
Validation loss: 3.112645800617225

Epoch: 5| Step: 6
Training loss: 3.3849935570434377
Validation loss: 3.111912172536631

Epoch: 5| Step: 7
Training loss: 3.575901190004935
Validation loss: 3.1117789356951846

Epoch: 5| Step: 8
Training loss: 3.0913253684907565
Validation loss: 3.11136396748296

Epoch: 5| Step: 9
Training loss: 2.9783097392981546
Validation loss: 3.110911773181191

Epoch: 5| Step: 10
Training loss: 3.4571603524622225
Validation loss: 3.109895250924961

Epoch: 69| Step: 0
Training loss: 3.4271321085480375
Validation loss: 3.1108884186621224

Epoch: 5| Step: 1
Training loss: 3.597394604441314
Validation loss: 3.1095173181160187

Epoch: 5| Step: 2
Training loss: 2.988173698534325
Validation loss: 3.109245829816607

Epoch: 5| Step: 3
Training loss: 3.7506245410920815
Validation loss: 3.108393932731522

Epoch: 5| Step: 4
Training loss: 3.3742002316651485
Validation loss: 3.1082063068722388

Epoch: 5| Step: 5
Training loss: 3.3747364930317008
Validation loss: 3.107356608116804

Epoch: 5| Step: 6
Training loss: 3.129520198865932
Validation loss: 3.1068824691828403

Epoch: 5| Step: 7
Training loss: 3.8033273133729795
Validation loss: 3.106756690841123

Epoch: 5| Step: 8
Training loss: 3.8875240852615653
Validation loss: 3.106346285722014

Epoch: 5| Step: 9
Training loss: 2.944895423884724
Validation loss: 3.105524825724106

Epoch: 5| Step: 10
Training loss: 2.6569195071925296
Validation loss: 3.1049550067038805

Epoch: 70| Step: 0
Training loss: 3.1779034832749766
Validation loss: 3.1047717210382726

Epoch: 5| Step: 1
Training loss: 2.8916825293143433
Validation loss: 3.1051391633046705

Epoch: 5| Step: 2
Training loss: 3.374251388600393
Validation loss: 3.1045878134905895

Epoch: 5| Step: 3
Training loss: 3.4939600736348986
Validation loss: 3.104176681435229

Epoch: 5| Step: 4
Training loss: 3.500278189366397
Validation loss: 3.104271822465052

Epoch: 5| Step: 5
Training loss: 3.373184846266222
Validation loss: 3.1038480321080524

Epoch: 5| Step: 6
Training loss: 3.8396752321474663
Validation loss: 3.1033817121089533

Epoch: 5| Step: 7
Training loss: 3.526704952149959
Validation loss: 3.102768778093794

Epoch: 5| Step: 8
Training loss: 3.404841560565083
Validation loss: 3.1028808377406114

Epoch: 5| Step: 9
Training loss: 3.4203292630178246
Validation loss: 3.1015349885139822

Epoch: 5| Step: 10
Training loss: 3.07956007602398
Validation loss: 3.101253513244699

Epoch: 71| Step: 0
Training loss: 3.3450936443181694
Validation loss: 3.100445073159062

Epoch: 5| Step: 1
Training loss: 3.606164602660213
Validation loss: 3.101810503989684

Epoch: 5| Step: 2
Training loss: 3.7114912724146287
Validation loss: 3.100073315153397

Epoch: 5| Step: 3
Training loss: 2.9437593366794776
Validation loss: 3.0996340617368476

Epoch: 5| Step: 4
Training loss: 3.1995952230985103
Validation loss: 3.09933096152632

Epoch: 5| Step: 5
Training loss: 3.1625035342471914
Validation loss: 3.099453975466842

Epoch: 5| Step: 6
Training loss: 3.5845326183621276
Validation loss: 3.0983434017206477

Epoch: 5| Step: 7
Training loss: 3.3313492751224523
Validation loss: 3.0990178485193796

Epoch: 5| Step: 8
Training loss: 3.6214708710041075
Validation loss: 3.098095677915542

Epoch: 5| Step: 9
Training loss: 2.795528066222349
Validation loss: 3.097471128743332

Epoch: 5| Step: 10
Training loss: 3.796742001311641
Validation loss: 3.0979522839629405

Epoch: 72| Step: 0
Training loss: 3.080322565552043
Validation loss: 3.0962265491883794

Epoch: 5| Step: 1
Training loss: 2.8471474945269026
Validation loss: 3.0961363020713617

Epoch: 5| Step: 2
Training loss: 3.4389645317713367
Validation loss: 3.096976250227338

Epoch: 5| Step: 3
Training loss: 3.7955529693899446
Validation loss: 3.0955915558334524

Epoch: 5| Step: 4
Training loss: 3.356034005885105
Validation loss: 3.0953731759696943

Epoch: 5| Step: 5
Training loss: 3.2817841594606905
Validation loss: 3.094690633358976

Epoch: 5| Step: 6
Training loss: 2.9346900648922944
Validation loss: 3.095089063800059

Epoch: 5| Step: 7
Training loss: 4.02420872083661
Validation loss: 3.0941636128158914

Epoch: 5| Step: 8
Training loss: 3.175586351933902
Validation loss: 3.0937347196282623

Epoch: 5| Step: 9
Training loss: 3.682217839574217
Validation loss: 3.0931624949243774

Epoch: 5| Step: 10
Training loss: 3.325636815632788
Validation loss: 3.0935497830279237

Epoch: 73| Step: 0
Training loss: 3.355791886816295
Validation loss: 3.09396372338932

Epoch: 5| Step: 1
Training loss: 3.4382941975834096
Validation loss: 3.091860637899048

Epoch: 5| Step: 2
Training loss: 3.45723634962741
Validation loss: 3.092292028603085

Epoch: 5| Step: 3
Training loss: 2.9239675607095137
Validation loss: 3.091650493957535

Epoch: 5| Step: 4
Training loss: 3.0463696182927844
Validation loss: 3.090491506195539

Epoch: 5| Step: 5
Training loss: 3.447274477679851
Validation loss: 3.091253470535446

Epoch: 5| Step: 6
Training loss: 3.6105170486738665
Validation loss: 3.089794920161644

Epoch: 5| Step: 7
Training loss: 3.9833565401388187
Validation loss: 3.090314146956013

Epoch: 5| Step: 8
Training loss: 3.3833644495944117
Validation loss: 3.089075940645075

Epoch: 5| Step: 9
Training loss: 2.722297283573671
Validation loss: 3.0894772335673615

Epoch: 5| Step: 10
Training loss: 3.593761278217697
Validation loss: 3.0896046529917784

Epoch: 74| Step: 0
Training loss: 3.522759687436781
Validation loss: 3.0893564193204104

Epoch: 5| Step: 1
Training loss: 3.1126250337665278
Validation loss: 3.0873070453174893

Epoch: 5| Step: 2
Training loss: 3.0402903295213046
Validation loss: 3.0871085463596106

Epoch: 5| Step: 3
Training loss: 3.299076881763981
Validation loss: 3.085767381100822

Epoch: 5| Step: 4
Training loss: 3.4327969369722178
Validation loss: 3.0870043201206165

Epoch: 5| Step: 5
Training loss: 3.5354080700624637
Validation loss: 3.086084826561081

Epoch: 5| Step: 6
Training loss: 3.875608088864466
Validation loss: 3.0873830524622083

Epoch: 5| Step: 7
Training loss: 3.0133128418971187
Validation loss: 3.0867291208911904

Epoch: 5| Step: 8
Training loss: 2.8708647137067844
Validation loss: 3.083288227894348

Epoch: 5| Step: 9
Training loss: 3.6326389722500583
Validation loss: 3.0910124240383947

Epoch: 5| Step: 10
Training loss: 3.6547128429406692
Validation loss: 3.102231991061196

Epoch: 75| Step: 0
Training loss: 3.4668986560763364
Validation loss: 3.0848921687996067

Epoch: 5| Step: 1
Training loss: 2.8857200453888256
Validation loss: 3.087295204894304

Epoch: 5| Step: 2
Training loss: 3.336392302410053
Validation loss: 3.096035474961216

Epoch: 5| Step: 3
Training loss: 3.7765337323066506
Validation loss: 3.144755269945027

Epoch: 5| Step: 4
Training loss: 4.160426973659003
Validation loss: 3.2000000876124175

Epoch: 5| Step: 5
Training loss: 3.874130028310527
Validation loss: 3.1007896951057066

Epoch: 5| Step: 6
Training loss: 3.1236787673259347
Validation loss: 3.093240415241398

Epoch: 5| Step: 7
Training loss: 2.9976158204979844
Validation loss: 3.094990188055873

Epoch: 5| Step: 8
Training loss: 2.9137609085409037
Validation loss: 3.1168035405968118

Epoch: 5| Step: 9
Training loss: 3.688146243607132
Validation loss: 3.153059697098715

Epoch: 5| Step: 10
Training loss: 2.7986608163749147
Validation loss: 3.1585383965196234

Testing loss: 3.3800300508024774
