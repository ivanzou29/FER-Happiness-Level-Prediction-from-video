Epoch: 1| Step: 0
Training loss: 5.88862847206227
Validation loss: 5.745368683175535

Epoch: 6| Step: 1
Training loss: 5.9303417221855375
Validation loss: 5.736999281400365

Epoch: 6| Step: 2
Training loss: 5.350308860348442
Validation loss: 5.729235033389931

Epoch: 6| Step: 3
Training loss: 5.817386009237203
Validation loss: 5.722508541626873

Epoch: 6| Step: 4
Training loss: 5.459272269912998
Validation loss: 5.715747963613765

Epoch: 6| Step: 5
Training loss: 5.925222452228983
Validation loss: 5.709165893995101

Epoch: 6| Step: 6
Training loss: 6.247996505052515
Validation loss: 5.701964956929458

Epoch: 6| Step: 7
Training loss: 6.307248792389719
Validation loss: 5.695029421350433

Epoch: 6| Step: 8
Training loss: 4.855132087458581
Validation loss: 5.686850096757538

Epoch: 6| Step: 9
Training loss: 4.525636550220574
Validation loss: 5.67863909637726

Epoch: 6| Step: 10
Training loss: 5.787276472549636
Validation loss: 5.669560199773918

Epoch: 6| Step: 11
Training loss: 6.333785024229532
Validation loss: 5.66047551867576

Epoch: 6| Step: 12
Training loss: 5.938014279228559
Validation loss: 5.649628198637576

Epoch: 6| Step: 13
Training loss: 5.536134621267785
Validation loss: 5.638637006623212

Epoch: 2| Step: 0
Training loss: 4.214723374960854
Validation loss: 5.626380340864019

Epoch: 6| Step: 1
Training loss: 6.758743274954175
Validation loss: 5.613245215480015

Epoch: 6| Step: 2
Training loss: 5.51718644904054
Validation loss: 5.598668626948641

Epoch: 6| Step: 3
Training loss: 4.992814814117024
Validation loss: 5.58310212397519

Epoch: 6| Step: 4
Training loss: 5.6117411009056495
Validation loss: 5.566161059434355

Epoch: 6| Step: 5
Training loss: 6.1369692571005805
Validation loss: 5.547641618097918

Epoch: 6| Step: 6
Training loss: 6.204033849902996
Validation loss: 5.528524812134431

Epoch: 6| Step: 7
Training loss: 5.939947968842707
Validation loss: 5.507493153017166

Epoch: 6| Step: 8
Training loss: 4.279659449139657
Validation loss: 5.4847890934021315

Epoch: 6| Step: 9
Training loss: 5.208112828991126
Validation loss: 5.461383189522567

Epoch: 6| Step: 10
Training loss: 5.942415471484822
Validation loss: 5.436289157309291

Epoch: 6| Step: 11
Training loss: 5.573267084911314
Validation loss: 5.4096635982072145

Epoch: 6| Step: 12
Training loss: 5.646580814367972
Validation loss: 5.380849689979429

Epoch: 6| Step: 13
Training loss: 4.726396642880291
Validation loss: 5.352114599922908

Epoch: 3| Step: 0
Training loss: 5.513582278208444
Validation loss: 5.321660447460784

Epoch: 6| Step: 1
Training loss: 4.736796650473247
Validation loss: 5.2902819961823955

Epoch: 6| Step: 2
Training loss: 4.789417546165562
Validation loss: 5.258338537071088

Epoch: 6| Step: 3
Training loss: 5.38154381139328
Validation loss: 5.224521264786253

Epoch: 6| Step: 4
Training loss: 5.422614934819109
Validation loss: 5.190699601096478

Epoch: 6| Step: 5
Training loss: 5.052061268342064
Validation loss: 5.156671475374685

Epoch: 6| Step: 6
Training loss: 5.5533557266449405
Validation loss: 5.120295648748843

Epoch: 6| Step: 7
Training loss: 4.879476594840845
Validation loss: 5.08344909291398

Epoch: 6| Step: 8
Training loss: 4.498838698691121
Validation loss: 5.048093611509226

Epoch: 6| Step: 9
Training loss: 4.687681270909088
Validation loss: 5.011219014225685

Epoch: 6| Step: 10
Training loss: 5.761247994539885
Validation loss: 4.975111444224426

Epoch: 6| Step: 11
Training loss: 5.27038902048474
Validation loss: 4.938950146680256

Epoch: 6| Step: 12
Training loss: 4.4047520032302545
Validation loss: 4.907261444459224

Epoch: 6| Step: 13
Training loss: 6.626714808380645
Validation loss: 4.874795171590617

Epoch: 4| Step: 0
Training loss: 4.151992337993395
Validation loss: 4.8435775233909135

Epoch: 6| Step: 1
Training loss: 5.135869664555723
Validation loss: 4.8149124318792005

Epoch: 6| Step: 2
Training loss: 4.697655827737799
Validation loss: 4.788192593199338

Epoch: 6| Step: 3
Training loss: 5.203137463620583
Validation loss: 4.761585514937225

Epoch: 6| Step: 4
Training loss: 4.53866937875125
Validation loss: 4.73776267411149

Epoch: 6| Step: 5
Training loss: 4.837578170105356
Validation loss: 4.716343193712528

Epoch: 6| Step: 6
Training loss: 5.582017753056198
Validation loss: 4.695633829662015

Epoch: 6| Step: 7
Training loss: 4.691620096864279
Validation loss: 4.675106074711455

Epoch: 6| Step: 8
Training loss: 3.8461617447698626
Validation loss: 4.655980903693735

Epoch: 6| Step: 9
Training loss: 4.13410615054094
Validation loss: 4.6387761156581195

Epoch: 6| Step: 10
Training loss: 4.795189179158213
Validation loss: 4.619701191451751

Epoch: 6| Step: 11
Training loss: 4.834107676773414
Validation loss: 4.604947387505925

Epoch: 6| Step: 12
Training loss: 4.9903897434839815
Validation loss: 4.5858318413606165

Epoch: 6| Step: 13
Training loss: 5.507913791455567
Validation loss: 4.569186468233626

Epoch: 5| Step: 0
Training loss: 3.696791371087259
Validation loss: 4.551435897281494

Epoch: 6| Step: 1
Training loss: 4.611860839888183
Validation loss: 4.537455791286389

Epoch: 6| Step: 2
Training loss: 5.598515531787687
Validation loss: 4.520588611829205

Epoch: 6| Step: 3
Training loss: 5.039744155081847
Validation loss: 4.507445027470918

Epoch: 6| Step: 4
Training loss: 4.824873832673835
Validation loss: 4.492719042247015

Epoch: 6| Step: 5
Training loss: 5.0878668200618735
Validation loss: 4.478571594651881

Epoch: 6| Step: 6
Training loss: 4.71450958711218
Validation loss: 4.465286600541631

Epoch: 6| Step: 7
Training loss: 4.353004312588049
Validation loss: 4.452603346259365

Epoch: 6| Step: 8
Training loss: 4.609805743247596
Validation loss: 4.439692860003351

Epoch: 6| Step: 9
Training loss: 3.9360830997130485
Validation loss: 4.426078423870626

Epoch: 6| Step: 10
Training loss: 4.958392979025386
Validation loss: 4.412652613046251

Epoch: 6| Step: 11
Training loss: 4.352869354650142
Validation loss: 4.400317585764635

Epoch: 6| Step: 12
Training loss: 3.2116328690761
Validation loss: 4.386920923017855

Epoch: 6| Step: 13
Training loss: 4.57446309258794
Validation loss: 4.3762388171861435

Epoch: 6| Step: 0
Training loss: 5.366308415146275
Validation loss: 4.362824557324918

Epoch: 6| Step: 1
Training loss: 5.993325972052196
Validation loss: 4.352307139189798

Epoch: 6| Step: 2
Training loss: 4.152846240468416
Validation loss: 4.342519608744153

Epoch: 6| Step: 3
Training loss: 3.6556479455570483
Validation loss: 4.331300601048966

Epoch: 6| Step: 4
Training loss: 4.192258266515667
Validation loss: 4.318821633915451

Epoch: 6| Step: 5
Training loss: 3.2382597514176292
Validation loss: 4.308236202989652

Epoch: 6| Step: 6
Training loss: 4.801869727601883
Validation loss: 4.300761408595829

Epoch: 6| Step: 7
Training loss: 3.250364136470454
Validation loss: 4.292826242097127

Epoch: 6| Step: 8
Training loss: 4.447829139199669
Validation loss: 4.284960189496367

Epoch: 6| Step: 9
Training loss: 4.414752953465994
Validation loss: 4.274811189928389

Epoch: 6| Step: 10
Training loss: 5.094695769895683
Validation loss: 4.266742742408846

Epoch: 6| Step: 11
Training loss: 4.748847620865118
Validation loss: 4.257552302977791

Epoch: 6| Step: 12
Training loss: 3.10717572976248
Validation loss: 4.249858928657849

Epoch: 6| Step: 13
Training loss: 4.5714719165722535
Validation loss: 4.241735768171834

Epoch: 7| Step: 0
Training loss: 4.335564014742227
Validation loss: 4.228918715189156

Epoch: 6| Step: 1
Training loss: 4.613664913131865
Validation loss: 4.2176165894563855

Epoch: 6| Step: 2
Training loss: 4.009395532116903
Validation loss: 4.207631069099406

Epoch: 6| Step: 3
Training loss: 4.650804240911487
Validation loss: 4.197261983478718

Epoch: 6| Step: 4
Training loss: 4.029009292406249
Validation loss: 4.188635512825547

Epoch: 6| Step: 5
Training loss: 3.141205843073575
Validation loss: 4.177034915969463

Epoch: 6| Step: 6
Training loss: 5.584392883579541
Validation loss: 4.1690198459433425

Epoch: 6| Step: 7
Training loss: 4.310099279052408
Validation loss: 4.159294054247412

Epoch: 6| Step: 8
Training loss: 3.8568838627969493
Validation loss: 4.150960125084121

Epoch: 6| Step: 9
Training loss: 4.44873065632374
Validation loss: 4.141058147402191

Epoch: 6| Step: 10
Training loss: 3.7646389378528005
Validation loss: 4.130946214396779

Epoch: 6| Step: 11
Training loss: 4.420375178712894
Validation loss: 4.123041811195782

Epoch: 6| Step: 12
Training loss: 4.455263715103536
Validation loss: 4.117507970977439

Epoch: 6| Step: 13
Training loss: 4.033508614338559
Validation loss: 4.107135390897362

Epoch: 8| Step: 0
Training loss: 4.421734379665564
Validation loss: 4.10267072871634

Epoch: 6| Step: 1
Training loss: 4.160795780508773
Validation loss: 4.094590480995483

Epoch: 6| Step: 2
Training loss: 5.177103309925409
Validation loss: 4.087975627884233

Epoch: 6| Step: 3
Training loss: 2.9293894705182018
Validation loss: 4.075421473287144

Epoch: 6| Step: 4
Training loss: 2.5946249347923285
Validation loss: 4.069035923979191

Epoch: 6| Step: 5
Training loss: 3.9953928880059855
Validation loss: 4.064740026436832

Epoch: 6| Step: 6
Training loss: 4.424421998976184
Validation loss: 4.061479429876704

Epoch: 6| Step: 7
Training loss: 4.837836217901577
Validation loss: 4.048743092977692

Epoch: 6| Step: 8
Training loss: 4.736472291620327
Validation loss: 4.03950458685031

Epoch: 6| Step: 9
Training loss: 4.3109950881324774
Validation loss: 4.033202524961553

Epoch: 6| Step: 10
Training loss: 3.301075794689167
Validation loss: 4.02818449770032

Epoch: 6| Step: 11
Training loss: 5.2217460757947745
Validation loss: 4.0212450708747856

Epoch: 6| Step: 12
Training loss: 3.6431930718350616
Validation loss: 4.01402949254065

Epoch: 6| Step: 13
Training loss: 3.9856552161641163
Validation loss: 4.003699290491493

Epoch: 9| Step: 0
Training loss: 4.753525479692308
Validation loss: 3.9984481528950275

Epoch: 6| Step: 1
Training loss: 4.135663669746104
Validation loss: 3.9923666572750722

Epoch: 6| Step: 2
Training loss: 4.467541724694874
Validation loss: 3.9867387426388676

Epoch: 6| Step: 3
Training loss: 4.476130226661225
Validation loss: 3.9806950232615397

Epoch: 6| Step: 4
Training loss: 4.542065570823279
Validation loss: 3.9729634266632523

Epoch: 6| Step: 5
Training loss: 3.9239213323844426
Validation loss: 3.9650519940661026

Epoch: 6| Step: 6
Training loss: 4.515369025238361
Validation loss: 3.9601239949487352

Epoch: 6| Step: 7
Training loss: 3.5362749384583565
Validation loss: 3.9555635270219707

Epoch: 6| Step: 8
Training loss: 3.6271164076230367
Validation loss: 3.950903714655447

Epoch: 6| Step: 9
Training loss: 5.146179908273265
Validation loss: 3.946390432570728

Epoch: 6| Step: 10
Training loss: 4.026063169723799
Validation loss: 3.9331981274528287

Epoch: 6| Step: 11
Training loss: 2.9421090835274955
Validation loss: 3.9351749095478303

Epoch: 6| Step: 12
Training loss: 3.0620026476529048
Validation loss: 3.93226129978806

Epoch: 6| Step: 13
Training loss: 3.7475985149034106
Validation loss: 3.929956387856045

Epoch: 10| Step: 0
Training loss: 3.807267898227934
Validation loss: 3.91579458092426

Epoch: 6| Step: 1
Training loss: 4.607791538132635
Validation loss: 3.9115451564808916

Epoch: 6| Step: 2
Training loss: 5.322959028798326
Validation loss: 3.910068802866167

Epoch: 6| Step: 3
Training loss: 3.6660880730471246
Validation loss: 3.904867096282224

Epoch: 6| Step: 4
Training loss: 4.05348778765015
Validation loss: 3.899769837072094

Epoch: 6| Step: 5
Training loss: 3.696890818545114
Validation loss: 3.8930143236614128

Epoch: 6| Step: 6
Training loss: 4.196126904993177
Validation loss: 3.890103562146909

Epoch: 6| Step: 7
Training loss: 3.4021977109695385
Validation loss: 3.880895112527798

Epoch: 6| Step: 8
Training loss: 4.573185778833461
Validation loss: 3.873765815711286

Epoch: 6| Step: 9
Training loss: 2.3490743559091194
Validation loss: 3.8704267515180626

Epoch: 6| Step: 10
Training loss: 3.6471792007572814
Validation loss: 3.8717732909895743

Epoch: 6| Step: 11
Training loss: 3.496571905587297
Validation loss: 3.865683340204943

Epoch: 6| Step: 12
Training loss: 4.7706544445543
Validation loss: 3.854777642501468

Epoch: 6| Step: 13
Training loss: 4.406818975412499
Validation loss: 3.8508293267573372

Epoch: 11| Step: 0
Training loss: 4.4289085066529355
Validation loss: 3.8494765040435386

Epoch: 6| Step: 1
Training loss: 3.1966123292167885
Validation loss: 3.8414896232994007

Epoch: 6| Step: 2
Training loss: 4.497364544018739
Validation loss: 3.835696835118596

Epoch: 6| Step: 3
Training loss: 4.388459346906739
Validation loss: 3.831140834601619

Epoch: 6| Step: 4
Training loss: 4.355352918513011
Validation loss: 3.8252243949885405

Epoch: 6| Step: 5
Training loss: 3.3560129774567913
Validation loss: 3.8174433849674743

Epoch: 6| Step: 6
Training loss: 4.255934890980435
Validation loss: 3.8085289764575663

Epoch: 6| Step: 7
Training loss: 3.0409615278485487
Validation loss: 3.8010447883059753

Epoch: 6| Step: 8
Training loss: 4.5923893788429115
Validation loss: 3.803037848222971

Epoch: 6| Step: 9
Training loss: 3.7501015967275886
Validation loss: 3.7954287404216798

Epoch: 6| Step: 10
Training loss: 3.434780362810273
Validation loss: 3.7882677728864365

Epoch: 6| Step: 11
Training loss: 4.6809795551077675
Validation loss: 3.786235055217925

Epoch: 6| Step: 12
Training loss: 3.4953628884282897
Validation loss: 3.780607046301413

Epoch: 6| Step: 13
Training loss: 3.669788173414364
Validation loss: 3.7789715802987995

Epoch: 12| Step: 0
Training loss: 3.393889793481493
Validation loss: 3.7708931111803192

Epoch: 6| Step: 1
Training loss: 3.6015783876412044
Validation loss: 3.761226152539182

Epoch: 6| Step: 2
Training loss: 3.225905529315734
Validation loss: 3.755622419833359

Epoch: 6| Step: 3
Training loss: 3.412657145141188
Validation loss: 3.753415603809945

Epoch: 6| Step: 4
Training loss: 4.076665039644413
Validation loss: 3.7485812070288986

Epoch: 6| Step: 5
Training loss: 4.098187320358129
Validation loss: 3.745695847563988

Epoch: 6| Step: 6
Training loss: 3.991596454382466
Validation loss: 3.742330564811495

Epoch: 6| Step: 7
Training loss: 4.834435742815909
Validation loss: 3.733423091886881

Epoch: 6| Step: 8
Training loss: 3.580140724612962
Validation loss: 3.730228680969017

Epoch: 6| Step: 9
Training loss: 3.4763125897712013
Validation loss: 3.722732479636037

Epoch: 6| Step: 10
Training loss: 4.4045084223723565
Validation loss: 3.7144050753631412

Epoch: 6| Step: 11
Training loss: 4.04259131692335
Validation loss: 3.7095088572680788

Epoch: 6| Step: 12
Training loss: 3.9403144829038874
Validation loss: 3.7025893716052622

Epoch: 6| Step: 13
Training loss: 4.721344695491167
Validation loss: 3.70051855917231

Epoch: 13| Step: 0
Training loss: 4.014612686268995
Validation loss: 3.695623146161648

Epoch: 6| Step: 1
Training loss: 3.4733505670579996
Validation loss: 3.6889138713566787

Epoch: 6| Step: 2
Training loss: 3.703279001116095
Validation loss: 3.6857730387359675

Epoch: 6| Step: 3
Training loss: 3.405445248793364
Validation loss: 3.6815270990079942

Epoch: 6| Step: 4
Training loss: 3.550276146477561
Validation loss: 3.67729144916485

Epoch: 6| Step: 5
Training loss: 4.452282206773834
Validation loss: 3.666950032162963

Epoch: 6| Step: 6
Training loss: 4.092773087978689
Validation loss: 3.6591869723865234

Epoch: 6| Step: 7
Training loss: 4.076974757715435
Validation loss: 3.6541960564942153

Epoch: 6| Step: 8
Training loss: 4.464711959108629
Validation loss: 3.6516712267295257

Epoch: 6| Step: 9
Training loss: 4.255551022847293
Validation loss: 3.63756270280409

Epoch: 6| Step: 10
Training loss: 2.916506971801189
Validation loss: 3.6407915422573933

Epoch: 6| Step: 11
Training loss: 3.9895397744983927
Validation loss: 3.6444524279857218

Epoch: 6| Step: 12
Training loss: 3.561881429944558
Validation loss: 3.628590097050253

Epoch: 6| Step: 13
Training loss: 3.4245667343643977
Validation loss: 3.6238770165213725

Epoch: 14| Step: 0
Training loss: 4.433385526498062
Validation loss: 3.62802100403897

Epoch: 6| Step: 1
Training loss: 3.6833567214384386
Validation loss: 3.6240738140603246

Epoch: 6| Step: 2
Training loss: 3.2344979525430038
Validation loss: 3.6086670372516023

Epoch: 6| Step: 3
Training loss: 3.4056331530953114
Validation loss: 3.6049744052219306

Epoch: 6| Step: 4
Training loss: 3.5219834535243653
Validation loss: 3.6008328229899433

Epoch: 6| Step: 5
Training loss: 4.430681174373226
Validation loss: 3.602786579800696

Epoch: 6| Step: 6
Training loss: 3.6637159236493297
Validation loss: 3.5953536683541087

Epoch: 6| Step: 7
Training loss: 3.7260380981758114
Validation loss: 3.5864111027958594

Epoch: 6| Step: 8
Training loss: 4.073604255777729
Validation loss: 3.583422653752453

Epoch: 6| Step: 9
Training loss: 4.006960058741978
Validation loss: 3.5755556128163355

Epoch: 6| Step: 10
Training loss: 3.224141466468365
Validation loss: 3.5706871024502616

Epoch: 6| Step: 11
Training loss: 3.331742590579346
Validation loss: 3.5676504560530073

Epoch: 6| Step: 12
Training loss: 4.453277478200922
Validation loss: 3.5626100063700346

Epoch: 6| Step: 13
Training loss: 3.2451730241773156
Validation loss: 3.55545295984758

Epoch: 15| Step: 0
Training loss: 4.481827813302928
Validation loss: 3.556875648339405

Epoch: 6| Step: 1
Training loss: 3.849987025053281
Validation loss: 3.5541634114799243

Epoch: 6| Step: 2
Training loss: 3.803039193733063
Validation loss: 3.5550915033802157

Epoch: 6| Step: 3
Training loss: 3.5874106844639835
Validation loss: 3.54630512507394

Epoch: 6| Step: 4
Training loss: 3.3199656585847586
Validation loss: 3.550758769942265

Epoch: 6| Step: 5
Training loss: 3.42164799185474
Validation loss: 3.547932858679111

Epoch: 6| Step: 6
Training loss: 4.018319617403203
Validation loss: 3.557439302879

Epoch: 6| Step: 7
Training loss: 3.7405212132994987
Validation loss: 3.5359265716627317

Epoch: 6| Step: 8
Training loss: 3.646836119299889
Validation loss: 3.5306094067092326

Epoch: 6| Step: 9
Training loss: 3.283813492444664
Validation loss: 3.5261461910094516

Epoch: 6| Step: 10
Training loss: 3.573707619062507
Validation loss: 3.524232907431066

Epoch: 6| Step: 11
Training loss: 4.142510441897578
Validation loss: 3.5197640023447807

Epoch: 6| Step: 12
Training loss: 3.6056874912484997
Validation loss: 3.5261559507478175

Epoch: 6| Step: 13
Training loss: 3.7801100849086815
Validation loss: 3.52859705814955

Epoch: 16| Step: 0
Training loss: 3.5417015223564383
Validation loss: 3.5319842940782054

Epoch: 6| Step: 1
Training loss: 3.9630197322565017
Validation loss: 3.522461995718385

Epoch: 6| Step: 2
Training loss: 3.8271951597125726
Validation loss: 3.504959284587311

Epoch: 6| Step: 3
Training loss: 3.4514256779641443
Validation loss: 3.5032246548253356

Epoch: 6| Step: 4
Training loss: 3.7340751751042824
Validation loss: 3.5116873442066683

Epoch: 6| Step: 5
Training loss: 2.55503651512614
Validation loss: 3.5061161933118234

Epoch: 6| Step: 6
Training loss: 3.6025744028237443
Validation loss: 3.5054205496064377

Epoch: 6| Step: 7
Training loss: 4.139660071455403
Validation loss: 3.4977806690234328

Epoch: 6| Step: 8
Training loss: 3.3436657190842216
Validation loss: 3.4881200292095498

Epoch: 6| Step: 9
Training loss: 3.2039061547488403
Validation loss: 3.494244114369772

Epoch: 6| Step: 10
Training loss: 4.479353269489986
Validation loss: 3.494181877606278

Epoch: 6| Step: 11
Training loss: 3.341896184965054
Validation loss: 3.486655346763363

Epoch: 6| Step: 12
Training loss: 4.7021422515860145
Validation loss: 3.4799034886313582

Epoch: 6| Step: 13
Training loss: 3.4556693115263504
Validation loss: 3.478173289783645

Epoch: 17| Step: 0
Training loss: 3.4514986238660614
Validation loss: 3.4790053221824366

Epoch: 6| Step: 1
Training loss: 3.586229233520418
Validation loss: 3.476257903750294

Epoch: 6| Step: 2
Training loss: 4.684071418641228
Validation loss: 3.474557001101601

Epoch: 6| Step: 3
Training loss: 2.621037171345851
Validation loss: 3.472474754311005

Epoch: 6| Step: 4
Training loss: 3.630173378789338
Validation loss: 3.471335654554814

Epoch: 6| Step: 5
Training loss: 3.777938275262625
Validation loss: 3.469177261167717

Epoch: 6| Step: 6
Training loss: 3.3579317053097455
Validation loss: 3.4686263724862667

Epoch: 6| Step: 7
Training loss: 3.042061941164551
Validation loss: 3.4661177167034594

Epoch: 6| Step: 8
Training loss: 3.1970633860518927
Validation loss: 3.463166477268793

Epoch: 6| Step: 9
Training loss: 4.0247160722565605
Validation loss: 3.4619634064206206

Epoch: 6| Step: 10
Training loss: 3.6419609794725942
Validation loss: 3.456135954743709

Epoch: 6| Step: 11
Training loss: 4.538391799092528
Validation loss: 3.4546346212195727

Epoch: 6| Step: 12
Training loss: 4.081373535903715
Validation loss: 3.451973327297544

Epoch: 6| Step: 13
Training loss: 3.127039129633929
Validation loss: 3.4565156982680767

Epoch: 18| Step: 0
Training loss: 3.803008976265974
Validation loss: 3.4564677050794455

Epoch: 6| Step: 1
Training loss: 2.9628450796289276
Validation loss: 3.457606250424486

Epoch: 6| Step: 2
Training loss: 3.911320927319104
Validation loss: 3.4490294889239443

Epoch: 6| Step: 3
Training loss: 4.499182096962288
Validation loss: 3.444236779599086

Epoch: 6| Step: 4
Training loss: 2.322290778124135
Validation loss: 3.4421469265559317

Epoch: 6| Step: 5
Training loss: 3.762415107453708
Validation loss: 3.444598158505906

Epoch: 6| Step: 6
Training loss: 4.153792493696391
Validation loss: 3.4469165834338678

Epoch: 6| Step: 7
Training loss: 4.037174809354207
Validation loss: 3.4378501497477476

Epoch: 6| Step: 8
Training loss: 4.387333080453078
Validation loss: 3.4363321507526186

Epoch: 6| Step: 9
Training loss: 2.836555350600274
Validation loss: 3.435718172642954

Epoch: 6| Step: 10
Training loss: 3.6081215799997053
Validation loss: 3.434995051409052

Epoch: 6| Step: 11
Training loss: 3.8986476314078238
Validation loss: 3.440505915632957

Epoch: 6| Step: 12
Training loss: 3.0056663089292406
Validation loss: 3.432004272931278

Epoch: 6| Step: 13
Training loss: 3.1578697354180303
Validation loss: 3.431880128484904

Epoch: 19| Step: 0
Training loss: 2.830595844478302
Validation loss: 3.4259328239076092

Epoch: 6| Step: 1
Training loss: 4.1164077512630115
Validation loss: 3.4262159511407333

Epoch: 6| Step: 2
Training loss: 4.317295669818638
Validation loss: 3.420348112155466

Epoch: 6| Step: 3
Training loss: 2.756534442367446
Validation loss: 3.4166765780621544

Epoch: 6| Step: 4
Training loss: 4.071505380924178
Validation loss: 3.41788491460645

Epoch: 6| Step: 5
Training loss: 2.3872854805484005
Validation loss: 3.4125106211860645

Epoch: 6| Step: 6
Training loss: 2.592700424172055
Validation loss: 3.4099915971713495

Epoch: 6| Step: 7
Training loss: 4.255123416173171
Validation loss: 3.4069108670950095

Epoch: 6| Step: 8
Training loss: 2.8198672970870726
Validation loss: 3.4074009597831854

Epoch: 6| Step: 9
Training loss: 2.8906621157351116
Validation loss: 3.4079687353209165

Epoch: 6| Step: 10
Training loss: 4.0940840490199335
Validation loss: 3.4044547827994904

Epoch: 6| Step: 11
Training loss: 4.710486850724626
Validation loss: 3.4027045754304943

Epoch: 6| Step: 12
Training loss: 3.867764270041337
Validation loss: 3.4012373255041104

Epoch: 6| Step: 13
Training loss: 4.3469805882215535
Validation loss: 3.4002891255332246

Epoch: 20| Step: 0
Training loss: 3.1199197291783185
Validation loss: 3.4009500714921983

Epoch: 6| Step: 1
Training loss: 3.16401397291105
Validation loss: 3.3911296494826884

Epoch: 6| Step: 2
Training loss: 3.5610829262123116
Validation loss: 3.3880714602584443

Epoch: 6| Step: 3
Training loss: 3.0804756599830565
Validation loss: 3.391110256919025

Epoch: 6| Step: 4
Training loss: 4.427828713292533
Validation loss: 3.3893716468169757

Epoch: 6| Step: 5
Training loss: 3.912159714205897
Validation loss: 3.3873221851236974

Epoch: 6| Step: 6
Training loss: 4.279421896350928
Validation loss: 3.3844888220561455

Epoch: 6| Step: 7
Training loss: 3.0062857580140134
Validation loss: 3.382077185095001

Epoch: 6| Step: 8
Training loss: 3.7996257346706894
Validation loss: 3.3832685315759856

Epoch: 6| Step: 9
Training loss: 2.729583378396179
Validation loss: 3.3832481679881905

Epoch: 6| Step: 10
Training loss: 3.9125671575955487
Validation loss: 3.380574015838858

Epoch: 6| Step: 11
Training loss: 3.4250371944886044
Validation loss: 3.3741592855001503

Epoch: 6| Step: 12
Training loss: 4.094356346361564
Validation loss: 3.374352255113236

Epoch: 6| Step: 13
Training loss: 3.60726854032542
Validation loss: 3.370763265301143

Epoch: 21| Step: 0
Training loss: 4.117751023238277
Validation loss: 3.3704727234488434

Epoch: 6| Step: 1
Training loss: 3.006162195648367
Validation loss: 3.3673914727264322

Epoch: 6| Step: 2
Training loss: 3.22594588255262
Validation loss: 3.3637973181327894

Epoch: 6| Step: 3
Training loss: 4.069533846541814
Validation loss: 3.3681633896531595

Epoch: 6| Step: 4
Training loss: 3.673200911704142
Validation loss: 3.3662144560001077

Epoch: 6| Step: 5
Training loss: 3.830405167346232
Validation loss: 3.361502742186402

Epoch: 6| Step: 6
Training loss: 3.256882642328157
Validation loss: 3.3583882085657413

Epoch: 6| Step: 7
Training loss: 4.366285090967546
Validation loss: 3.3578964974848944

Epoch: 6| Step: 8
Training loss: 3.6171200047698515
Validation loss: 3.3578240979636904

Epoch: 6| Step: 9
Training loss: 3.0694903566389504
Validation loss: 3.3551344079589045

Epoch: 6| Step: 10
Training loss: 3.309760922559506
Validation loss: 3.3549049516240306

Epoch: 6| Step: 11
Training loss: 2.9136821917969917
Validation loss: 3.354915463214029

Epoch: 6| Step: 12
Training loss: 4.252542969107021
Validation loss: 3.3567633498650573

Epoch: 6| Step: 13
Training loss: 2.7433355378999194
Validation loss: 3.35000143276105

Epoch: 22| Step: 0
Training loss: 3.56463732935848
Validation loss: 3.348216655021333

Epoch: 6| Step: 1
Training loss: 3.593882284632241
Validation loss: 3.350243811136995

Epoch: 6| Step: 2
Training loss: 3.458737330604789
Validation loss: 3.3493688336221146

Epoch: 6| Step: 3
Training loss: 3.7093402195676193
Validation loss: 3.348044785247998

Epoch: 6| Step: 4
Training loss: 3.0573466012796855
Validation loss: 3.344599317994499

Epoch: 6| Step: 5
Training loss: 3.8056798498517805
Validation loss: 3.348270626908619

Epoch: 6| Step: 6
Training loss: 3.2999081512153516
Validation loss: 3.3437779612958685

Epoch: 6| Step: 7
Training loss: 2.9906384315308685
Validation loss: 3.3446243073853994

Epoch: 6| Step: 8
Training loss: 4.446844229253276
Validation loss: 3.341693620376407

Epoch: 6| Step: 9
Training loss: 3.2091204845982286
Validation loss: 3.3419512623054035

Epoch: 6| Step: 10
Training loss: 3.3639600115382637
Validation loss: 3.3381817893621712

Epoch: 6| Step: 11
Training loss: 3.7276054538313996
Validation loss: 3.3402967818229707

Epoch: 6| Step: 12
Training loss: 3.2625639225920193
Validation loss: 3.3404674639191505

Epoch: 6| Step: 13
Training loss: 4.770906717105284
Validation loss: 3.3366355479781227

Epoch: 23| Step: 0
Training loss: 3.1244182808173844
Validation loss: 3.3359981273046726

Epoch: 6| Step: 1
Training loss: 3.168727120762678
Validation loss: 3.3432588597042536

Epoch: 6| Step: 2
Training loss: 3.1807803963412082
Validation loss: 3.3474854734106305

Epoch: 6| Step: 3
Training loss: 4.1607201422410975
Validation loss: 3.3480735736271177

Epoch: 6| Step: 4
Training loss: 2.7263335648313607
Validation loss: 3.3398653668837035

Epoch: 6| Step: 5
Training loss: 3.4670485714089425
Validation loss: 3.3337784805753703

Epoch: 6| Step: 6
Training loss: 3.758423816976033
Validation loss: 3.3333164435133087

Epoch: 6| Step: 7
Training loss: 3.687352322999616
Validation loss: 3.3322056098359063

Epoch: 6| Step: 8
Training loss: 3.9634001711211133
Validation loss: 3.334137274074107

Epoch: 6| Step: 9
Training loss: 3.6514109353574074
Validation loss: 3.3313743562094715

Epoch: 6| Step: 10
Training loss: 3.23451903386456
Validation loss: 3.3311873085633397

Epoch: 6| Step: 11
Training loss: 3.7720230642363983
Validation loss: 3.3316017749955074

Epoch: 6| Step: 12
Training loss: 4.056160543481013
Validation loss: 3.32772576718653

Epoch: 6| Step: 13
Training loss: 3.871502189760748
Validation loss: 3.3209900454135934

Epoch: 24| Step: 0
Training loss: 3.7650918543579954
Validation loss: 3.3219240099570353

Epoch: 6| Step: 1
Training loss: 3.4137141488650062
Validation loss: 3.3218400056840007

Epoch: 6| Step: 2
Training loss: 4.046684820353362
Validation loss: 3.3302228402084393

Epoch: 6| Step: 3
Training loss: 3.2374323893081995
Validation loss: 3.318321301347233

Epoch: 6| Step: 4
Training loss: 3.002758665099491
Validation loss: 3.3140059066621697

Epoch: 6| Step: 5
Training loss: 3.409695064300993
Validation loss: 3.3133260773033992

Epoch: 6| Step: 6
Training loss: 3.3246725738617737
Validation loss: 3.3113086297023475

Epoch: 6| Step: 7
Training loss: 3.408046703520071
Validation loss: 3.309332841305636

Epoch: 6| Step: 8
Training loss: 2.711510325658891
Validation loss: 3.305879454977241

Epoch: 6| Step: 9
Training loss: 3.904038436450293
Validation loss: 3.3089729054348327

Epoch: 6| Step: 10
Training loss: 4.355753388961457
Validation loss: 3.306425182087823

Epoch: 6| Step: 11
Training loss: 3.185861502990259
Validation loss: 3.3064354213595277

Epoch: 6| Step: 12
Training loss: 3.5506903339828657
Validation loss: 3.304867997092747

Epoch: 6| Step: 13
Training loss: 4.383574448445967
Validation loss: 3.3026420426227627

Epoch: 25| Step: 0
Training loss: 3.391764084700203
Validation loss: 3.301162963861217

Epoch: 6| Step: 1
Training loss: 3.715439164091894
Validation loss: 3.2973906418946806

Epoch: 6| Step: 2
Training loss: 3.3117289095518263
Validation loss: 3.296611572994835

Epoch: 6| Step: 3
Training loss: 4.3236942679614545
Validation loss: 3.3001071218963802

Epoch: 6| Step: 4
Training loss: 3.0119093699808626
Validation loss: 3.300603761346908

Epoch: 6| Step: 5
Training loss: 3.3406711557338227
Validation loss: 3.295402777843163

Epoch: 6| Step: 6
Training loss: 3.939794084038096
Validation loss: 3.2949521350964583

Epoch: 6| Step: 7
Training loss: 3.7303955070934856
Validation loss: 3.293361257734712

Epoch: 6| Step: 8
Training loss: 3.0666528687650456
Validation loss: 3.292156658616749

Epoch: 6| Step: 9
Training loss: 3.6235051196896344
Validation loss: 3.295998778838977

Epoch: 6| Step: 10
Training loss: 2.4469483969874664
Validation loss: 3.291167423202591

Epoch: 6| Step: 11
Training loss: 4.035744697080053
Validation loss: 3.291026270545404

Epoch: 6| Step: 12
Training loss: 3.2197367812906537
Validation loss: 3.2967549492543813

Epoch: 6| Step: 13
Training loss: 4.232374781622518
Validation loss: 3.300526002345995

Epoch: 26| Step: 0
Training loss: 3.978170912748113
Validation loss: 3.2965944341170554

Epoch: 6| Step: 1
Training loss: 3.28341574266936
Validation loss: 3.2933634964894023

Epoch: 6| Step: 2
Training loss: 3.5184820476300045
Validation loss: 3.286289739970454

Epoch: 6| Step: 3
Training loss: 4.610579200818115
Validation loss: 3.2843423486548984

Epoch: 6| Step: 4
Training loss: 3.5243949857910564
Validation loss: 3.2834238659428863

Epoch: 6| Step: 5
Training loss: 3.9532304229550723
Validation loss: 3.2846877411578

Epoch: 6| Step: 6
Training loss: 3.151833191548403
Validation loss: 3.2873152048130487

Epoch: 6| Step: 7
Training loss: 3.578717445068239
Validation loss: 3.286157199557211

Epoch: 6| Step: 8
Training loss: 2.949523990826475
Validation loss: 3.284490391841255

Epoch: 6| Step: 9
Training loss: 3.0562716617869703
Validation loss: 3.2820129109224707

Epoch: 6| Step: 10
Training loss: 3.422800992627505
Validation loss: 3.280650863209334

Epoch: 6| Step: 11
Training loss: 3.0648777353316623
Validation loss: 3.280529965546005

Epoch: 6| Step: 12
Training loss: 3.2696916729983285
Validation loss: 3.2781493741814445

Epoch: 6| Step: 13
Training loss: 3.822817490180825
Validation loss: 3.2792492885985047

Epoch: 27| Step: 0
Training loss: 3.0491893879295056
Validation loss: 3.2835632405091597

Epoch: 6| Step: 1
Training loss: 3.438355772826923
Validation loss: 3.28063482484036

Epoch: 6| Step: 2
Training loss: 3.4128703604576076
Validation loss: 3.278632608944617

Epoch: 6| Step: 3
Training loss: 4.371122767511481
Validation loss: 3.2804105271767767

Epoch: 6| Step: 4
Training loss: 2.7873588081490714
Validation loss: 3.2766984990326185

Epoch: 6| Step: 5
Training loss: 1.7188319793570568
Validation loss: 3.2772500733423953

Epoch: 6| Step: 6
Training loss: 4.254398762308883
Validation loss: 3.282676759264379

Epoch: 6| Step: 7
Training loss: 3.705316209156631
Validation loss: 3.27393733784171

Epoch: 6| Step: 8
Training loss: 3.6426316653655673
Validation loss: 3.274380216213201

Epoch: 6| Step: 9
Training loss: 3.6625586963936576
Validation loss: 3.276193635432722

Epoch: 6| Step: 10
Training loss: 3.2490978456031043
Validation loss: 3.2739720500475875

Epoch: 6| Step: 11
Training loss: 3.7099587525082405
Validation loss: 3.27812663710091

Epoch: 6| Step: 12
Training loss: 3.6089663583863394
Validation loss: 3.2738683860781186

Epoch: 6| Step: 13
Training loss: 4.2015947583975715
Validation loss: 3.2782373946165597

Epoch: 28| Step: 0
Training loss: 3.4201770210184352
Validation loss: 3.2737122304730653

Epoch: 6| Step: 1
Training loss: 3.9968533059755025
Validation loss: 3.2718148520715626

Epoch: 6| Step: 2
Training loss: 3.730223834401406
Validation loss: 3.2716055646160687

Epoch: 6| Step: 3
Training loss: 3.242805734542608
Validation loss: 3.269841006720231

Epoch: 6| Step: 4
Training loss: 3.3945121457316265
Validation loss: 3.2708566206434946

Epoch: 6| Step: 5
Training loss: 3.7425901319802697
Validation loss: 3.2700417190775046

Epoch: 6| Step: 6
Training loss: 3.71697442757731
Validation loss: 3.2667676070236094

Epoch: 6| Step: 7
Training loss: 3.050779061798991
Validation loss: 3.267115467972925

Epoch: 6| Step: 8
Training loss: 2.837015246689508
Validation loss: 3.2690923830962046

Epoch: 6| Step: 9
Training loss: 3.6947724348925863
Validation loss: 3.2644028105359864

Epoch: 6| Step: 10
Training loss: 4.645992167997882
Validation loss: 3.265400034821631

Epoch: 6| Step: 11
Training loss: 3.133776433199466
Validation loss: 3.2668096763651744

Epoch: 6| Step: 12
Training loss: 3.0100292409699514
Validation loss: 3.2663875191433616

Epoch: 6| Step: 13
Training loss: 2.915101385169207
Validation loss: 3.266420918477901

Epoch: 29| Step: 0
Training loss: 3.181476061869864
Validation loss: 3.264364468822229

Epoch: 6| Step: 1
Training loss: 2.9880714093500993
Validation loss: 3.266126235166684

Epoch: 6| Step: 2
Training loss: 3.8864851531561424
Validation loss: 3.270065203836938

Epoch: 6| Step: 3
Training loss: 3.5780726266551177
Validation loss: 3.268467736574905

Epoch: 6| Step: 4
Training loss: 3.7693025351598535
Validation loss: 3.27344425870422

Epoch: 6| Step: 5
Training loss: 3.5164023663122856
Validation loss: 3.2744482560547485

Epoch: 6| Step: 6
Training loss: 3.6204011618961625
Validation loss: 3.2721469708328104

Epoch: 6| Step: 7
Training loss: 3.1945259599835447
Validation loss: 3.269359576127969

Epoch: 6| Step: 8
Training loss: 3.73143368369524
Validation loss: 3.2702266699274554

Epoch: 6| Step: 9
Training loss: 3.5238287258115966
Validation loss: 3.262958621705702

Epoch: 6| Step: 10
Training loss: 4.158697569241133
Validation loss: 3.2598746565178014

Epoch: 6| Step: 11
Training loss: 3.682230400787993
Validation loss: 3.259307237492409

Epoch: 6| Step: 12
Training loss: 2.45525097902335
Validation loss: 3.2577005648791144

Epoch: 6| Step: 13
Training loss: 3.4979248707175064
Validation loss: 3.25900473608309

Epoch: 30| Step: 0
Training loss: 3.9254248613885383
Validation loss: 3.2562039128276425

Epoch: 6| Step: 1
Training loss: 3.4974663964730253
Validation loss: 3.258030096812642

Epoch: 6| Step: 2
Training loss: 4.036307540866172
Validation loss: 3.2541202390648514

Epoch: 6| Step: 3
Training loss: 3.2572925619269104
Validation loss: 3.25210201197653

Epoch: 6| Step: 4
Training loss: 3.5581845028296044
Validation loss: 3.2555467689387

Epoch: 6| Step: 5
Training loss: 2.62385134315412
Validation loss: 3.255923902785523

Epoch: 6| Step: 6
Training loss: 3.509757473383689
Validation loss: 3.2569706298420122

Epoch: 6| Step: 7
Training loss: 3.5166372240711232
Validation loss: 3.259535208424022

Epoch: 6| Step: 8
Training loss: 3.492497304534418
Validation loss: 3.2555815347012955

Epoch: 6| Step: 9
Training loss: 4.047287143060619
Validation loss: 3.2580883450054516

Epoch: 6| Step: 10
Training loss: 3.217794332016759
Validation loss: 3.254126399762465

Epoch: 6| Step: 11
Training loss: 3.0076983541652638
Validation loss: 3.2522802643931294

Epoch: 6| Step: 12
Training loss: 4.125751311343988
Validation loss: 3.251966403750659

Epoch: 6| Step: 13
Training loss: 2.1008385755066747
Validation loss: 3.247187182087111

Epoch: 31| Step: 0
Training loss: 4.643724632964026
Validation loss: 3.2494171888421177

Epoch: 6| Step: 1
Training loss: 3.409250040675185
Validation loss: 3.2525457188460556

Epoch: 6| Step: 2
Training loss: 3.190460176908951
Validation loss: 3.258602406686141

Epoch: 6| Step: 3
Training loss: 3.56377428253261
Validation loss: 3.252418389739045

Epoch: 6| Step: 4
Training loss: 4.228105133077632
Validation loss: 3.250554595148921

Epoch: 6| Step: 5
Training loss: 2.5679371533888604
Validation loss: 3.2477041896219587

Epoch: 6| Step: 6
Training loss: 3.568599097807713
Validation loss: 3.2503924846696224

Epoch: 6| Step: 7
Training loss: 3.080591752810708
Validation loss: 3.2473781839250586

Epoch: 6| Step: 8
Training loss: 3.2496349423128716
Validation loss: 3.246818472932468

Epoch: 6| Step: 9
Training loss: 3.1343334434850307
Validation loss: 3.245096231908218

Epoch: 6| Step: 10
Training loss: 2.8100059471203194
Validation loss: 3.2489927393803866

Epoch: 6| Step: 11
Training loss: 3.9332764998602663
Validation loss: 3.2541945518985953

Epoch: 6| Step: 12
Training loss: 4.067252094050431
Validation loss: 3.2525492672985115

Epoch: 6| Step: 13
Training loss: 2.3113945045500266
Validation loss: 3.249306886469365

Epoch: 32| Step: 0
Training loss: 3.252464826952249
Validation loss: 3.2460914786444524

Epoch: 6| Step: 1
Training loss: 3.5631661043337224
Validation loss: 3.246200186023733

Epoch: 6| Step: 2
Training loss: 3.6995368667664947
Validation loss: 3.2472754496756284

Epoch: 6| Step: 3
Training loss: 2.502775749387306
Validation loss: 3.242357438802227

Epoch: 6| Step: 4
Training loss: 3.8111801364259335
Validation loss: 3.2417872431275363

Epoch: 6| Step: 5
Training loss: 3.581635864134828
Validation loss: 3.2429597419489173

Epoch: 6| Step: 6
Training loss: 4.097709313586353
Validation loss: 3.2413024176589005

Epoch: 6| Step: 7
Training loss: 3.5853255005232296
Validation loss: 3.241197701690664

Epoch: 6| Step: 8
Training loss: 3.753367882587068
Validation loss: 3.2431959975392872

Epoch: 6| Step: 9
Training loss: 3.7961069593967154
Validation loss: 3.242502827438301

Epoch: 6| Step: 10
Training loss: 3.22829939157909
Validation loss: 3.2422669625456293

Epoch: 6| Step: 11
Training loss: 3.18460999165521
Validation loss: 3.2401110308977343

Epoch: 6| Step: 12
Training loss: 2.778916140526133
Validation loss: 3.2415799206799685

Epoch: 6| Step: 13
Training loss: 3.857042233098159
Validation loss: 3.2433828017338726

Epoch: 33| Step: 0
Training loss: 4.568338499311003
Validation loss: 3.245071087547486

Epoch: 6| Step: 1
Training loss: 3.46749002753641
Validation loss: 3.2425028116255734

Epoch: 6| Step: 2
Training loss: 3.371630222603183
Validation loss: 3.242812667768394

Epoch: 6| Step: 3
Training loss: 3.597002365548462
Validation loss: 3.2395929571765247

Epoch: 6| Step: 4
Training loss: 4.239748090062369
Validation loss: 3.236963695456514

Epoch: 6| Step: 5
Training loss: 3.3222435216600115
Validation loss: 3.236279377623502

Epoch: 6| Step: 6
Training loss: 3.041681019648998
Validation loss: 3.2369770531206132

Epoch: 6| Step: 7
Training loss: 3.8195315695949956
Validation loss: 3.2341453784219665

Epoch: 6| Step: 8
Training loss: 3.862752941947924
Validation loss: 3.235754309361322

Epoch: 6| Step: 9
Training loss: 2.226073094171272
Validation loss: 3.2339979081424333

Epoch: 6| Step: 10
Training loss: 2.9622661256823695
Validation loss: 3.233847049257154

Epoch: 6| Step: 11
Training loss: 3.833683136169421
Validation loss: 3.2342346455808957

Epoch: 6| Step: 12
Training loss: 2.1669949380686124
Validation loss: 3.233374552426482

Epoch: 6| Step: 13
Training loss: 3.4344707666569945
Validation loss: 3.2379374772433756

Epoch: 34| Step: 0
Training loss: 3.4784185705508652
Validation loss: 3.236351586660927

Epoch: 6| Step: 1
Training loss: 4.034427780172516
Validation loss: 3.235063193207184

Epoch: 6| Step: 2
Training loss: 3.1787839913360294
Validation loss: 3.2323606723163483

Epoch: 6| Step: 3
Training loss: 2.7570056113101944
Validation loss: 3.2338007616874527

Epoch: 6| Step: 4
Training loss: 2.7467594126749004
Validation loss: 3.2321629072675404

Epoch: 6| Step: 5
Training loss: 3.0822824972845053
Validation loss: 3.2300018982250065

Epoch: 6| Step: 6
Training loss: 3.912493301727119
Validation loss: 3.2308260181499957

Epoch: 6| Step: 7
Training loss: 3.641417322999282
Validation loss: 3.230618354130728

Epoch: 6| Step: 8
Training loss: 3.5151910810775018
Validation loss: 3.229546548739042

Epoch: 6| Step: 9
Training loss: 3.468745188666779
Validation loss: 3.2313125821045263

Epoch: 6| Step: 10
Training loss: 3.8342628319585206
Validation loss: 3.232637664538682

Epoch: 6| Step: 11
Training loss: 3.8385684436431773
Validation loss: 3.2317954761843772

Epoch: 6| Step: 12
Training loss: 3.4222261431562853
Validation loss: 3.2310125219137023

Epoch: 6| Step: 13
Training loss: 3.4818649488504994
Validation loss: 3.2321714401324804

Epoch: 35| Step: 0
Training loss: 2.9861700441523373
Validation loss: 3.2269045339532405

Epoch: 6| Step: 1
Training loss: 4.201334405270796
Validation loss: 3.2267382193852154

Epoch: 6| Step: 2
Training loss: 3.5341255835265275
Validation loss: 3.225491941922274

Epoch: 6| Step: 3
Training loss: 3.407320186939179
Validation loss: 3.225084582847064

Epoch: 6| Step: 4
Training loss: 2.759200657211097
Validation loss: 3.2244194239507964

Epoch: 6| Step: 5
Training loss: 3.5244645273385533
Validation loss: 3.2235599606798924

Epoch: 6| Step: 6
Training loss: 3.4996529815849047
Validation loss: 3.2260442928084045

Epoch: 6| Step: 7
Training loss: 3.8700183718144223
Validation loss: 3.226084680863941

Epoch: 6| Step: 8
Training loss: 4.371581567674568
Validation loss: 3.2239956410382953

Epoch: 6| Step: 9
Training loss: 2.9451412080288257
Validation loss: 3.222592777585467

Epoch: 6| Step: 10
Training loss: 2.5806414720485837
Validation loss: 3.222400741019032

Epoch: 6| Step: 11
Training loss: 3.78549599082411
Validation loss: 3.2229082371851616

Epoch: 6| Step: 12
Training loss: 3.417401599151082
Validation loss: 3.2214409037452163

Epoch: 6| Step: 13
Training loss: 2.9978884577445712
Validation loss: 3.2210675617573994

Epoch: 36| Step: 0
Training loss: 3.2750126729239537
Validation loss: 3.218524592442144

Epoch: 6| Step: 1
Training loss: 3.775924337033122
Validation loss: 3.2180264204538545

Epoch: 6| Step: 2
Training loss: 2.78326514459408
Validation loss: 3.218018205388929

Epoch: 6| Step: 3
Training loss: 3.6793950120534924
Validation loss: 3.2162656291033227

Epoch: 6| Step: 4
Training loss: 2.9905434018346626
Validation loss: 3.217959075741033

Epoch: 6| Step: 5
Training loss: 3.2429416009312875
Validation loss: 3.214061696113983

Epoch: 6| Step: 6
Training loss: 3.5569859713582583
Validation loss: 3.212536030611942

Epoch: 6| Step: 7
Training loss: 4.038873605350878
Validation loss: 3.21037076020347

Epoch: 6| Step: 8
Training loss: 2.960153762844528
Validation loss: 3.208943468134635

Epoch: 6| Step: 9
Training loss: 3.709292398511642
Validation loss: 3.2096830002797065

Epoch: 6| Step: 10
Training loss: 3.312837835394393
Validation loss: 3.206683511496826

Epoch: 6| Step: 11
Training loss: 4.074148994938573
Validation loss: 3.205556113095658

Epoch: 6| Step: 12
Training loss: 3.5930812047524494
Validation loss: 3.208091877509374

Epoch: 6| Step: 13
Training loss: 2.891963174735861
Validation loss: 3.207061655120928

Epoch: 37| Step: 0
Training loss: 3.8618025461744736
Validation loss: 3.206579289564592

Epoch: 6| Step: 1
Training loss: 3.910678519964436
Validation loss: 3.212386206846797

Epoch: 6| Step: 2
Training loss: 2.5629863742640313
Validation loss: 3.205194249386923

Epoch: 6| Step: 3
Training loss: 4.211464702039356
Validation loss: 3.2061334687596315

Epoch: 6| Step: 4
Training loss: 2.7986392631618817
Validation loss: 3.2057570221692857

Epoch: 6| Step: 5
Training loss: 4.35424940891528
Validation loss: 3.2013739264758465

Epoch: 6| Step: 6
Training loss: 2.419320315760748
Validation loss: 3.199711532049917

Epoch: 6| Step: 7
Training loss: 2.91813363014133
Validation loss: 3.199701875853335

Epoch: 6| Step: 8
Training loss: 3.791324655946725
Validation loss: 3.200685174457182

Epoch: 6| Step: 9
Training loss: 2.893459600456287
Validation loss: 3.199160476509038

Epoch: 6| Step: 10
Training loss: 3.0817750309372998
Validation loss: 3.1980078439934227

Epoch: 6| Step: 11
Training loss: 3.4142599856176226
Validation loss: 3.197669832024746

Epoch: 6| Step: 12
Training loss: 3.896986085337797
Validation loss: 3.1949107638664014

Epoch: 6| Step: 13
Training loss: 3.485597130997663
Validation loss: 3.1959056767499554

Epoch: 38| Step: 0
Training loss: 3.7219793578922724
Validation loss: 3.1956002261593106

Epoch: 6| Step: 1
Training loss: 3.264288669929466
Validation loss: 3.199885311365936

Epoch: 6| Step: 2
Training loss: 3.5066104859999636
Validation loss: 3.193109757525978

Epoch: 6| Step: 3
Training loss: 4.201350975741292
Validation loss: 3.197996127249125

Epoch: 6| Step: 4
Training loss: 2.9200823991724176
Validation loss: 3.1998968393286806

Epoch: 6| Step: 5
Training loss: 3.2908249434744703
Validation loss: 3.196606185992614

Epoch: 6| Step: 6
Training loss: 3.2851443477600974
Validation loss: 3.1969500921388345

Epoch: 6| Step: 7
Training loss: 2.879155845640157
Validation loss: 3.198176449411094

Epoch: 6| Step: 8
Training loss: 2.753150176020849
Validation loss: 3.1986319502996214

Epoch: 6| Step: 9
Training loss: 3.348135808115824
Validation loss: 3.20729924575393

Epoch: 6| Step: 10
Training loss: 4.030436115757589
Validation loss: 3.1976742382830414

Epoch: 6| Step: 11
Training loss: 3.723117987866448
Validation loss: 3.1958760599138984

Epoch: 6| Step: 12
Training loss: 3.242636775865109
Validation loss: 3.1956096693209073

Epoch: 6| Step: 13
Training loss: 3.938621240252726
Validation loss: 3.187202832249295

Epoch: 39| Step: 0
Training loss: 3.2858013739802483
Validation loss: 3.1893233236352034

Epoch: 6| Step: 1
Training loss: 4.437406297151084
Validation loss: 3.1897554374312405

Epoch: 6| Step: 2
Training loss: 3.7242748348301475
Validation loss: 3.187393076496928

Epoch: 6| Step: 3
Training loss: 3.159462530808293
Validation loss: 3.183139789042668

Epoch: 6| Step: 4
Training loss: 2.9354830371364637
Validation loss: 3.1856362678789694

Epoch: 6| Step: 5
Training loss: 3.350456001788693
Validation loss: 3.188277080476565

Epoch: 6| Step: 6
Training loss: 3.7540786179615933
Validation loss: 3.1882113701049843

Epoch: 6| Step: 7
Training loss: 2.9961838292154486
Validation loss: 3.189240212427368

Epoch: 6| Step: 8
Training loss: 3.0299001618105423
Validation loss: 3.187510806279903

Epoch: 6| Step: 9
Training loss: 3.058381561675134
Validation loss: 3.1887145683139066

Epoch: 6| Step: 10
Training loss: 4.370224880830872
Validation loss: 3.1884379429491503

Epoch: 6| Step: 11
Training loss: 2.866429532763083
Validation loss: 3.194189215247858

Epoch: 6| Step: 12
Training loss: 3.211737391576206
Validation loss: 3.1948688671575223

Epoch: 6| Step: 13
Training loss: 3.6096972036838095
Validation loss: 3.1879272480225054

Epoch: 40| Step: 0
Training loss: 3.28427246398282
Validation loss: 3.181237043879815

Epoch: 6| Step: 1
Training loss: 3.8805510845323923
Validation loss: 3.1827493952713244

Epoch: 6| Step: 2
Training loss: 3.8789293609268714
Validation loss: 3.183201263188681

Epoch: 6| Step: 3
Training loss: 3.743388387445617
Validation loss: 3.1897874635351884

Epoch: 6| Step: 4
Training loss: 3.632787167040368
Validation loss: 3.1916701745069385

Epoch: 6| Step: 5
Training loss: 2.5998198483483366
Validation loss: 3.181477761306399

Epoch: 6| Step: 6
Training loss: 3.4133730264183653
Validation loss: 3.180075881820392

Epoch: 6| Step: 7
Training loss: 3.3992845904585147
Validation loss: 3.1811833278345945

Epoch: 6| Step: 8
Training loss: 3.1088900547360185
Validation loss: 3.179651853630629

Epoch: 6| Step: 9
Training loss: 2.9336961507385864
Validation loss: 3.1782081058731193

Epoch: 6| Step: 10
Training loss: 3.1268689479613005
Validation loss: 3.1782692027312898

Epoch: 6| Step: 11
Training loss: 3.7980791858937506
Validation loss: 3.1790559166663654

Epoch: 6| Step: 12
Training loss: 2.8106942207782164
Validation loss: 3.1785420238147584

Epoch: 6| Step: 13
Training loss: 4.57152490429195
Validation loss: 3.1820031877454564

Epoch: 41| Step: 0
Training loss: 3.6189543196953995
Validation loss: 3.1785487487889275

Epoch: 6| Step: 1
Training loss: 3.8544940431414965
Validation loss: 3.1806295716192503

Epoch: 6| Step: 2
Training loss: 3.330250379296751
Validation loss: 3.1774751932259813

Epoch: 6| Step: 3
Training loss: 3.266124048384947
Validation loss: 3.1752096352241757

Epoch: 6| Step: 4
Training loss: 3.549350765123368
Validation loss: 3.1740936080419644

Epoch: 6| Step: 5
Training loss: 3.547085793570988
Validation loss: 3.175760792674661

Epoch: 6| Step: 6
Training loss: 2.365242741488867
Validation loss: 3.1776995215487522

Epoch: 6| Step: 7
Training loss: 4.005982217155977
Validation loss: 3.176784958219108

Epoch: 6| Step: 8
Training loss: 3.522664934876464
Validation loss: 3.17695256768837

Epoch: 6| Step: 9
Training loss: 3.423855978922638
Validation loss: 3.174691154826623

Epoch: 6| Step: 10
Training loss: 3.307427030581638
Validation loss: 3.175800641633894

Epoch: 6| Step: 11
Training loss: 3.413664281740396
Validation loss: 3.177585364582026

Epoch: 6| Step: 12
Training loss: 2.7366927432894426
Validation loss: 3.1768284184859636

Epoch: 6| Step: 13
Training loss: 3.97393064210109
Validation loss: 3.176073634405289

Epoch: 42| Step: 0
Training loss: 3.6000200059122935
Validation loss: 3.1697786909298156

Epoch: 6| Step: 1
Training loss: 3.512098383088127
Validation loss: 3.171755104015526

Epoch: 6| Step: 2
Training loss: 3.9527645625267867
Validation loss: 3.1737979523870794

Epoch: 6| Step: 3
Training loss: 3.5232169004008975
Validation loss: 3.1742563862091133

Epoch: 6| Step: 4
Training loss: 4.049447556481663
Validation loss: 3.180291616643814

Epoch: 6| Step: 5
Training loss: 3.3687689446250997
Validation loss: 3.1758824222990087

Epoch: 6| Step: 6
Training loss: 2.346428319935579
Validation loss: 3.1760725172777686

Epoch: 6| Step: 7
Training loss: 3.169189819871931
Validation loss: 3.175301931770618

Epoch: 6| Step: 8
Training loss: 3.3617603438612496
Validation loss: 3.17487973524877

Epoch: 6| Step: 9
Training loss: 3.507889030998043
Validation loss: 3.17296023564583

Epoch: 6| Step: 10
Training loss: 3.3957125558418304
Validation loss: 3.1665318778279783

Epoch: 6| Step: 11
Training loss: 3.779602700804376
Validation loss: 3.1647981696656635

Epoch: 6| Step: 12
Training loss: 2.436739680722265
Validation loss: 3.1630575387118394

Epoch: 6| Step: 13
Training loss: 3.532645160907863
Validation loss: 3.1631553128217544

Epoch: 43| Step: 0
Training loss: 3.6725903402685796
Validation loss: 3.1633621281297333

Epoch: 6| Step: 1
Training loss: 3.380996886420318
Validation loss: 3.1643115343791735

Epoch: 6| Step: 2
Training loss: 3.9449108561414707
Validation loss: 3.164200766360597

Epoch: 6| Step: 3
Training loss: 3.7154353139085035
Validation loss: 3.1654079658002034

Epoch: 6| Step: 4
Training loss: 3.5322354722378644
Validation loss: 3.1622179211587715

Epoch: 6| Step: 5
Training loss: 3.1911632954301457
Validation loss: 3.1646270714150124

Epoch: 6| Step: 6
Training loss: 2.8534681667425836
Validation loss: 3.161692106281138

Epoch: 6| Step: 7
Training loss: 3.591742045827775
Validation loss: 3.1595691572765685

Epoch: 6| Step: 8
Training loss: 3.935971038905648
Validation loss: 3.158754246928402

Epoch: 6| Step: 9
Training loss: 3.4109789018831234
Validation loss: 3.1578476074002584

Epoch: 6| Step: 10
Training loss: 3.2611334909526453
Validation loss: 3.1612055799897045

Epoch: 6| Step: 11
Training loss: 2.907683972403814
Validation loss: 3.165349280435018

Epoch: 6| Step: 12
Training loss: 3.2946521081030293
Validation loss: 3.1638643616712403

Epoch: 6| Step: 13
Training loss: 2.4632019281848723
Validation loss: 3.169542802659407

Epoch: 44| Step: 0
Training loss: 3.0094083441514123
Validation loss: 3.166229041860886

Epoch: 6| Step: 1
Training loss: 4.172459707825557
Validation loss: 3.179175123640186

Epoch: 6| Step: 2
Training loss: 2.641711220430738
Validation loss: 3.1656316874983057

Epoch: 6| Step: 3
Training loss: 3.469857116527805
Validation loss: 3.1659720025369

Epoch: 6| Step: 4
Training loss: 3.0084535386294062
Validation loss: 3.164288933704813

Epoch: 6| Step: 5
Training loss: 3.819710588526641
Validation loss: 3.1628370967974493

Epoch: 6| Step: 6
Training loss: 3.280108734747612
Validation loss: 3.1596656186334893

Epoch: 6| Step: 7
Training loss: 2.567651826702313
Validation loss: 3.157419070034503

Epoch: 6| Step: 8
Training loss: 3.8445456076844025
Validation loss: 3.1561152566393704

Epoch: 6| Step: 9
Training loss: 3.3119651794538165
Validation loss: 3.15499294236468

Epoch: 6| Step: 10
Training loss: 4.0439020378857595
Validation loss: 3.155552658197387

Epoch: 6| Step: 11
Training loss: 3.5132877973275383
Validation loss: 3.1549271936978482

Epoch: 6| Step: 12
Training loss: 3.2582021064056974
Validation loss: 3.1551161818737063

Epoch: 6| Step: 13
Training loss: 3.351584979073072
Validation loss: 3.1545625568215487

Epoch: 45| Step: 0
Training loss: 3.388051124024894
Validation loss: 3.1528828059081624

Epoch: 6| Step: 1
Training loss: 3.7334656186736033
Validation loss: 3.1514175851164126

Epoch: 6| Step: 2
Training loss: 2.4485573004728174
Validation loss: 3.1514875280452315

Epoch: 6| Step: 3
Training loss: 3.3446172142253263
Validation loss: 3.150766969912878

Epoch: 6| Step: 4
Training loss: 2.4463044613412546
Validation loss: 3.15009112189673

Epoch: 6| Step: 5
Training loss: 3.512618750468804
Validation loss: 3.150523784768983

Epoch: 6| Step: 6
Training loss: 3.704605772226284
Validation loss: 3.15115707919684

Epoch: 6| Step: 7
Training loss: 4.132641967254918
Validation loss: 3.151371328217817

Epoch: 6| Step: 8
Training loss: 3.395297158316769
Validation loss: 3.150195959441332

Epoch: 6| Step: 9
Training loss: 3.3638973580031637
Validation loss: 3.1521565523964172

Epoch: 6| Step: 10
Training loss: 3.9119943115255427
Validation loss: 3.1483781449129142

Epoch: 6| Step: 11
Training loss: 3.517729269335733
Validation loss: 3.1493128197421028

Epoch: 6| Step: 12
Training loss: 3.179399107055577
Validation loss: 3.149497897447372

Epoch: 6| Step: 13
Training loss: 3.0331064418851468
Validation loss: 3.1500616220260023

Epoch: 46| Step: 0
Training loss: 3.933530229284792
Validation loss: 3.1501334945172172

Epoch: 6| Step: 1
Training loss: 4.150587311515995
Validation loss: 3.149516483901292

Epoch: 6| Step: 2
Training loss: 3.42653585928925
Validation loss: 3.15353535431319

Epoch: 6| Step: 3
Training loss: 3.9684634368046496
Validation loss: 3.162081479021203

Epoch: 6| Step: 4
Training loss: 2.618730869997205
Validation loss: 3.1483990358424343

Epoch: 6| Step: 5
Training loss: 3.124704270675035
Validation loss: 3.144243847821012

Epoch: 6| Step: 6
Training loss: 3.343352677456342
Validation loss: 3.1519758284734425

Epoch: 6| Step: 7
Training loss: 3.0960733956402593
Validation loss: 3.1519424990867013

Epoch: 6| Step: 8
Training loss: 2.4645719302750146
Validation loss: 3.1532261513825572

Epoch: 6| Step: 9
Training loss: 3.249839925491839
Validation loss: 3.145802753128446

Epoch: 6| Step: 10
Training loss: 3.4710965853930014
Validation loss: 3.15581500112774

Epoch: 6| Step: 11
Training loss: 3.5888063345181007
Validation loss: 3.1493556765942317

Epoch: 6| Step: 12
Training loss: 3.8095101061074974
Validation loss: 3.149836442838515

Epoch: 6| Step: 13
Training loss: 2.685602005826163
Validation loss: 3.151499025609579

Epoch: 47| Step: 0
Training loss: 2.84404962658942
Validation loss: 3.151886503329366

Epoch: 6| Step: 1
Training loss: 3.645865536502122
Validation loss: 3.1588429087769883

Epoch: 6| Step: 2
Training loss: 3.0487970012124537
Validation loss: 3.160108039346549

Epoch: 6| Step: 3
Training loss: 3.4469873072847297
Validation loss: 3.152683354279368

Epoch: 6| Step: 4
Training loss: 3.7315880499312417
Validation loss: 3.1513290812516495

Epoch: 6| Step: 5
Training loss: 4.232478206102982
Validation loss: 3.1481924508977657

Epoch: 6| Step: 6
Training loss: 3.5073317982154806
Validation loss: 3.1451382077171774

Epoch: 6| Step: 7
Training loss: 3.3895571385086347
Validation loss: 3.1437840432997506

Epoch: 6| Step: 8
Training loss: 3.2936155288144895
Validation loss: 3.1408245831578325

Epoch: 6| Step: 9
Training loss: 2.6320913895042923
Validation loss: 3.141661678843487

Epoch: 6| Step: 10
Training loss: 3.4093333996158735
Validation loss: 3.1397899239272093

Epoch: 6| Step: 11
Training loss: 3.188294853886225
Validation loss: 3.1419528216784243

Epoch: 6| Step: 12
Training loss: 3.6730444811073104
Validation loss: 3.140746112925447

Epoch: 6| Step: 13
Training loss: 3.148039458981214
Validation loss: 3.1411284694813033

Epoch: 48| Step: 0
Training loss: 3.5492368388234565
Validation loss: 3.143994256196971

Epoch: 6| Step: 1
Training loss: 3.4431818387832434
Validation loss: 3.1431944716283677

Epoch: 6| Step: 2
Training loss: 2.879098210346736
Validation loss: 3.137437649809919

Epoch: 6| Step: 3
Training loss: 4.2392963934045484
Validation loss: 3.1365225370732914

Epoch: 6| Step: 4
Training loss: 3.5116353772952125
Validation loss: 3.1385804730621816

Epoch: 6| Step: 5
Training loss: 3.430178804769575
Validation loss: 3.137644573548372

Epoch: 6| Step: 6
Training loss: 2.981780677123944
Validation loss: 3.1348992178530253

Epoch: 6| Step: 7
Training loss: 3.0699742254610407
Validation loss: 3.1346938475051003

Epoch: 6| Step: 8
Training loss: 2.8933851106760122
Validation loss: 3.13468658763687

Epoch: 6| Step: 9
Training loss: 2.8390408604856896
Validation loss: 3.1334484642318214

Epoch: 6| Step: 10
Training loss: 3.0450045590922485
Validation loss: 3.136392671165155

Epoch: 6| Step: 11
Training loss: 4.059717957044192
Validation loss: 3.132740014082852

Epoch: 6| Step: 12
Training loss: 3.6274612226983454
Validation loss: 3.132505972089161

Epoch: 6| Step: 13
Training loss: 3.76207391601177
Validation loss: 3.1322951731671798

Epoch: 49| Step: 0
Training loss: 3.696269066780459
Validation loss: 3.1337030606849865

Epoch: 6| Step: 1
Training loss: 3.716778914006787
Validation loss: 3.1343915878019075

Epoch: 6| Step: 2
Training loss: 3.1730790882947955
Validation loss: 3.133139198544849

Epoch: 6| Step: 3
Training loss: 3.523718169340232
Validation loss: 3.133893499743629

Epoch: 6| Step: 4
Training loss: 3.088265229194943
Validation loss: 3.135528121491922

Epoch: 6| Step: 5
Training loss: 3.050431743143924
Validation loss: 3.135077737849678

Epoch: 6| Step: 6
Training loss: 2.976883197639386
Validation loss: 3.13402075834788

Epoch: 6| Step: 7
Training loss: 3.2822556180839797
Validation loss: 3.1351894178705573

Epoch: 6| Step: 8
Training loss: 3.752474286463379
Validation loss: 3.1392631747436623

Epoch: 6| Step: 9
Training loss: 3.1469086752247954
Validation loss: 3.1393420625868407

Epoch: 6| Step: 10
Training loss: 3.1195068908703343
Validation loss: 3.1377064014253917

Epoch: 6| Step: 11
Training loss: 3.9179239622315447
Validation loss: 3.135954218037726

Epoch: 6| Step: 12
Training loss: 3.3857158509124945
Validation loss: 3.1347101246950198

Epoch: 6| Step: 13
Training loss: 3.4619417477295675
Validation loss: 3.1315150751084317

Epoch: 50| Step: 0
Training loss: 2.904957145335427
Validation loss: 3.1265657993660905

Epoch: 6| Step: 1
Training loss: 3.4607902133850894
Validation loss: 3.1307441897452373

Epoch: 6| Step: 2
Training loss: 3.2136216279916194
Validation loss: 3.1264599808510476

Epoch: 6| Step: 3
Training loss: 2.54113440855387
Validation loss: 3.1228417053882067

Epoch: 6| Step: 4
Training loss: 3.251402185640916
Validation loss: 3.1268668162864413

Epoch: 6| Step: 5
Training loss: 3.756541332556202
Validation loss: 3.126318227364229

Epoch: 6| Step: 6
Training loss: 3.689410215969379
Validation loss: 3.1271750381056105

Epoch: 6| Step: 7
Training loss: 3.605522047911519
Validation loss: 3.124966002248595

Epoch: 6| Step: 8
Training loss: 3.5824566737215116
Validation loss: 3.126217681566435

Epoch: 6| Step: 9
Training loss: 3.5331048735648114
Validation loss: 3.129047455289298

Epoch: 6| Step: 10
Training loss: 4.124709610398917
Validation loss: 3.123142065851724

Epoch: 6| Step: 11
Training loss: 3.5175149542321877
Validation loss: 3.1246365145050583

Epoch: 6| Step: 12
Training loss: 3.066451034704808
Validation loss: 3.122347059618747

Epoch: 6| Step: 13
Training loss: 2.2298789505542125
Validation loss: 3.1202275297001147

Epoch: 51| Step: 0
Training loss: 3.43513560042726
Validation loss: 3.1204330921960954

Epoch: 6| Step: 1
Training loss: 3.5618250692723077
Validation loss: 3.123011504806196

Epoch: 6| Step: 2
Training loss: 3.8288695564994737
Validation loss: 3.122768130134316

Epoch: 6| Step: 3
Training loss: 3.2809587621867364
Validation loss: 3.1196111833366413

Epoch: 6| Step: 4
Training loss: 3.241234623246915
Validation loss: 3.123049124205053

Epoch: 6| Step: 5
Training loss: 3.1928314799237203
Validation loss: 3.121573328721734

Epoch: 6| Step: 6
Training loss: 2.2893339132901795
Validation loss: 3.119684593911625

Epoch: 6| Step: 7
Training loss: 3.2155479132751794
Validation loss: 3.1223807730650184

Epoch: 6| Step: 8
Training loss: 3.0270000434928415
Validation loss: 3.117162003198147

Epoch: 6| Step: 9
Training loss: 3.963009504901231
Validation loss: 3.119037413258627

Epoch: 6| Step: 10
Training loss: 3.531189099352129
Validation loss: 3.1200198715382785

Epoch: 6| Step: 11
Training loss: 2.840823501684786
Validation loss: 3.1204396696437415

Epoch: 6| Step: 12
Training loss: 3.760265160605561
Validation loss: 3.11730182594417

Epoch: 6| Step: 13
Training loss: 4.027610614567059
Validation loss: 3.1178763668247416

Epoch: 52| Step: 0
Training loss: 3.61130831905399
Validation loss: 3.1174302980246877

Epoch: 6| Step: 1
Training loss: 3.683898718983533
Validation loss: 3.113592229591689

Epoch: 6| Step: 2
Training loss: 2.893302873049718
Validation loss: 3.114871496394485

Epoch: 6| Step: 3
Training loss: 2.318226708438221
Validation loss: 3.116636590405081

Epoch: 6| Step: 4
Training loss: 2.8624786042992185
Validation loss: 3.1133083068995213

Epoch: 6| Step: 5
Training loss: 3.4764064110851853
Validation loss: 3.112314000366371

Epoch: 6| Step: 6
Training loss: 3.0147302120327075
Validation loss: 3.115412838520173

Epoch: 6| Step: 7
Training loss: 3.249682777768921
Validation loss: 3.113118402979002

Epoch: 6| Step: 8
Training loss: 4.389933575798928
Validation loss: 3.1140949704455876

Epoch: 6| Step: 9
Training loss: 2.9016441025606166
Validation loss: 3.114556784123461

Epoch: 6| Step: 10
Training loss: 3.3631199034868637
Validation loss: 3.114245844871944

Epoch: 6| Step: 11
Training loss: 3.7286609043854577
Validation loss: 3.114550449418473

Epoch: 6| Step: 12
Training loss: 3.370428026223977
Validation loss: 3.1124046292622247

Epoch: 6| Step: 13
Training loss: 4.170230384152557
Validation loss: 3.1175388217669955

Epoch: 53| Step: 0
Training loss: 3.147406094387224
Validation loss: 3.1259553626177166

Epoch: 6| Step: 1
Training loss: 3.6755998913316485
Validation loss: 3.1318013099754873

Epoch: 6| Step: 2
Training loss: 3.728252675379528
Validation loss: 3.1175501550760694

Epoch: 6| Step: 3
Training loss: 2.8881331967417263
Validation loss: 3.118123816515471

Epoch: 6| Step: 4
Training loss: 3.732392235622766
Validation loss: 3.118376181686109

Epoch: 6| Step: 5
Training loss: 3.9342829565502972
Validation loss: 3.1146729877861583

Epoch: 6| Step: 6
Training loss: 3.2494638440899526
Validation loss: 3.1097463022393033

Epoch: 6| Step: 7
Training loss: 3.6360026472982208
Validation loss: 3.1094014197633033

Epoch: 6| Step: 8
Training loss: 2.6194771387624796
Validation loss: 3.107284356713614

Epoch: 6| Step: 9
Training loss: 3.412023009335569
Validation loss: 3.109970915397591

Epoch: 6| Step: 10
Training loss: 3.1470759550176717
Validation loss: 3.1110313877632914

Epoch: 6| Step: 11
Training loss: 3.3133719394310064
Validation loss: 3.110466668835944

Epoch: 6| Step: 12
Training loss: 3.627822697783106
Validation loss: 3.1090376245219002

Epoch: 6| Step: 13
Training loss: 2.2442164794213477
Validation loss: 3.1077222285451547

Epoch: 54| Step: 0
Training loss: 2.912437169784841
Validation loss: 3.1079264437972522

Epoch: 6| Step: 1
Training loss: 3.395735023495279
Validation loss: 3.1090329244299646

Epoch: 6| Step: 2
Training loss: 3.7482075539994963
Validation loss: 3.111446596428466

Epoch: 6| Step: 3
Training loss: 4.207719185209149
Validation loss: 3.106539137113113

Epoch: 6| Step: 4
Training loss: 3.1932225935920227
Validation loss: 3.1061033088032035

Epoch: 6| Step: 5
Training loss: 2.6037906120894636
Validation loss: 3.1076736185798994

Epoch: 6| Step: 6
Training loss: 3.270791087920522
Validation loss: 3.106475784435937

Epoch: 6| Step: 7
Training loss: 2.9188820917271174
Validation loss: 3.1064635012876676

Epoch: 6| Step: 8
Training loss: 3.3473670861292995
Validation loss: 3.1071662051280757

Epoch: 6| Step: 9
Training loss: 3.6313159772489554
Validation loss: 3.113395413894422

Epoch: 6| Step: 10
Training loss: 3.204031020634626
Validation loss: 3.1084199220712687

Epoch: 6| Step: 11
Training loss: 3.8357305218392796
Validation loss: 3.1049558678683113

Epoch: 6| Step: 12
Training loss: 2.5892266966760142
Validation loss: 3.1030785442244335

Epoch: 6| Step: 13
Training loss: 4.0811293486305855
Validation loss: 3.10742802953613

Epoch: 55| Step: 0
Training loss: 3.043438817591998
Validation loss: 3.1055468807864512

Epoch: 6| Step: 1
Training loss: 3.8521583204602474
Validation loss: 3.1046633430756345

Epoch: 6| Step: 2
Training loss: 3.7734612568804433
Validation loss: 3.101769325925649

Epoch: 6| Step: 3
Training loss: 3.6277873405368153
Validation loss: 3.0994477931033697

Epoch: 6| Step: 4
Training loss: 2.784482127996222
Validation loss: 3.0994559676004676

Epoch: 6| Step: 5
Training loss: 3.5084688723758366
Validation loss: 3.1026213414624446

Epoch: 6| Step: 6
Training loss: 3.548314277259707
Validation loss: 3.1012171686878407

Epoch: 6| Step: 7
Training loss: 3.8878462953051485
Validation loss: 3.098966673194098

Epoch: 6| Step: 8
Training loss: 2.767639460991109
Validation loss: 3.0980222208306603

Epoch: 6| Step: 9
Training loss: 2.602323220411648
Validation loss: 3.099152974053191

Epoch: 6| Step: 10
Training loss: 4.009090822039375
Validation loss: 3.098062376262217

Epoch: 6| Step: 11
Training loss: 2.805664317432768
Validation loss: 3.098721312409236

Epoch: 6| Step: 12
Training loss: 3.1117860273922173
Validation loss: 3.099097257860749

Epoch: 6| Step: 13
Training loss: 3.2329766388086565
Validation loss: 3.0981516454678277

Epoch: 56| Step: 0
Training loss: 3.735183181458153
Validation loss: 3.0985396933385587

Epoch: 6| Step: 1
Training loss: 2.5623034890351835
Validation loss: 3.0975543757504194

Epoch: 6| Step: 2
Training loss: 2.9339397851112574
Validation loss: 3.0974562623501725

Epoch: 6| Step: 3
Training loss: 3.101439812297146
Validation loss: 3.0984716099188936

Epoch: 6| Step: 4
Training loss: 3.028435413051662
Validation loss: 3.0951783044589574

Epoch: 6| Step: 5
Training loss: 3.8399695436938797
Validation loss: 3.0981815336927108

Epoch: 6| Step: 6
Training loss: 3.9790460591570884
Validation loss: 3.101192469753274

Epoch: 6| Step: 7
Training loss: 3.7367870250400697
Validation loss: 3.098892192732801

Epoch: 6| Step: 8
Training loss: 3.935100247997755
Validation loss: 3.100909007330445

Epoch: 6| Step: 9
Training loss: 2.691771196002896
Validation loss: 3.098765273512035

Epoch: 6| Step: 10
Training loss: 3.069173587070037
Validation loss: 3.0919157448994854

Epoch: 6| Step: 11
Training loss: 3.4591947348336687
Validation loss: 3.093666740946991

Epoch: 6| Step: 12
Training loss: 3.2651220783118196
Validation loss: 3.0917476332220595

Epoch: 6| Step: 13
Training loss: 3.1010724888915226
Validation loss: 3.0962915514159386

Epoch: 57| Step: 0
Training loss: 3.375429055527449
Validation loss: 3.0958620570385333

Epoch: 6| Step: 1
Training loss: 3.5918826351745077
Validation loss: 3.0929748526973206

Epoch: 6| Step: 2
Training loss: 2.6983567005423534
Validation loss: 3.095119736166514

Epoch: 6| Step: 3
Training loss: 3.267472761955648
Validation loss: 3.092185990627514

Epoch: 6| Step: 4
Training loss: 3.3488284610386363
Validation loss: 3.0945630141048057

Epoch: 6| Step: 5
Training loss: 3.7924277551316736
Validation loss: 3.090827201795797

Epoch: 6| Step: 6
Training loss: 2.770207202887526
Validation loss: 3.093467536263326

Epoch: 6| Step: 7
Training loss: 3.397748083582676
Validation loss: 3.092187721726537

Epoch: 6| Step: 8
Training loss: 3.42373007738961
Validation loss: 3.092559625219571

Epoch: 6| Step: 9
Training loss: 3.73705728517907
Validation loss: 3.0890710707566695

Epoch: 6| Step: 10
Training loss: 3.711080383762402
Validation loss: 3.0895399374126176

Epoch: 6| Step: 11
Training loss: 2.8319079983955966
Validation loss: 3.0879955128774697

Epoch: 6| Step: 12
Training loss: 3.369107506630703
Validation loss: 3.0872393328296273

Epoch: 6| Step: 13
Training loss: 3.4181351800998208
Validation loss: 3.0870997420832573

Epoch: 58| Step: 0
Training loss: 4.062675589654845
Validation loss: 3.0867165963781216

Epoch: 6| Step: 1
Training loss: 2.825577489516342
Validation loss: 3.0850377428602638

Epoch: 6| Step: 2
Training loss: 3.132122315747848
Validation loss: 3.0858075730478

Epoch: 6| Step: 3
Training loss: 3.1466819847940997
Validation loss: 3.0851257851703573

Epoch: 6| Step: 4
Training loss: 2.837216427787184
Validation loss: 3.0848468673119736

Epoch: 6| Step: 5
Training loss: 3.437638436044107
Validation loss: 3.08575486265381

Epoch: 6| Step: 6
Training loss: 3.6195929090788117
Validation loss: 3.0905016214094747

Epoch: 6| Step: 7
Training loss: 3.503924485651405
Validation loss: 3.0847394630969394

Epoch: 6| Step: 8
Training loss: 2.821977541254921
Validation loss: 3.0855357400667422

Epoch: 6| Step: 9
Training loss: 4.1638570595281745
Validation loss: 3.0848436013109484

Epoch: 6| Step: 10
Training loss: 3.0475265979936115
Validation loss: 3.0834902867814376

Epoch: 6| Step: 11
Training loss: 3.421300691808174
Validation loss: 3.0829235282375995

Epoch: 6| Step: 12
Training loss: 3.8772455907475964
Validation loss: 3.082638392557241

Epoch: 6| Step: 13
Training loss: 1.160283605090953
Validation loss: 3.080619624424554

Epoch: 59| Step: 0
Training loss: 3.366996317168925
Validation loss: 3.080233064278708

Epoch: 6| Step: 1
Training loss: 3.6439661239992343
Validation loss: 3.0815954063572324

Epoch: 6| Step: 2
Training loss: 3.2068950517288113
Validation loss: 3.084231318774512

Epoch: 6| Step: 3
Training loss: 3.747034553394983
Validation loss: 3.081890670544171

Epoch: 6| Step: 4
Training loss: 2.90845463307598
Validation loss: 3.0800710235544426

Epoch: 6| Step: 5
Training loss: 3.0639216957245723
Validation loss: 3.078734398415381

Epoch: 6| Step: 6
Training loss: 3.267149063095879
Validation loss: 3.0788590833429903

Epoch: 6| Step: 7
Training loss: 3.5572304820453478
Validation loss: 3.0789352307592366

Epoch: 6| Step: 8
Training loss: 3.1550577763558554
Validation loss: 3.0786157756790535

Epoch: 6| Step: 9
Training loss: 3.5593589186200454
Validation loss: 3.076939079269284

Epoch: 6| Step: 10
Training loss: 2.486991512141451
Validation loss: 3.0791920765962812

Epoch: 6| Step: 11
Training loss: 3.318315978324975
Validation loss: 3.0789092489915406

Epoch: 6| Step: 12
Training loss: 3.9020996017374907
Validation loss: 3.0788022538215882

Epoch: 6| Step: 13
Training loss: 3.325827221757675
Validation loss: 3.0768779291645916

Epoch: 60| Step: 0
Training loss: 2.969193917262823
Validation loss: 3.076523765728813

Epoch: 6| Step: 1
Training loss: 3.205646694598583
Validation loss: 3.0757279562272153

Epoch: 6| Step: 2
Training loss: 2.7152038774463794
Validation loss: 3.074953892606677

Epoch: 6| Step: 3
Training loss: 3.6615892859854124
Validation loss: 3.0768214863219354

Epoch: 6| Step: 4
Training loss: 3.920063953267227
Validation loss: 3.077253089197057

Epoch: 6| Step: 5
Training loss: 2.803772503460234
Validation loss: 3.07876579910893

Epoch: 6| Step: 6
Training loss: 3.4312251300292633
Validation loss: 3.0789917064591914

Epoch: 6| Step: 7
Training loss: 3.6187677412635866
Validation loss: 3.0736547874981808

Epoch: 6| Step: 8
Training loss: 4.059832357318618
Validation loss: 3.077324037984137

Epoch: 6| Step: 9
Training loss: 3.669756079111496
Validation loss: 3.072667848508363

Epoch: 6| Step: 10
Training loss: 3.1059553041109997
Validation loss: 3.075990869757401

Epoch: 6| Step: 11
Training loss: 3.2201247751453486
Validation loss: 3.0724459986206214

Epoch: 6| Step: 12
Training loss: 3.1334873148100018
Validation loss: 3.0741764634895103

Epoch: 6| Step: 13
Training loss: 2.4188327509009495
Validation loss: 3.0711716714240938

Epoch: 61| Step: 0
Training loss: 3.9036721230152445
Validation loss: 3.0717603646121208

Epoch: 6| Step: 1
Training loss: 3.1247750773547875
Validation loss: 3.070059748707469

Epoch: 6| Step: 2
Training loss: 2.8920085173569823
Validation loss: 3.0695658695503423

Epoch: 6| Step: 3
Training loss: 3.17642516943098
Validation loss: 3.0691974427725337

Epoch: 6| Step: 4
Training loss: 2.787518242062122
Validation loss: 3.0708529932230917

Epoch: 6| Step: 5
Training loss: 3.196856361252789
Validation loss: 3.067374857587066

Epoch: 6| Step: 6
Training loss: 3.156267222744625
Validation loss: 3.071169773216755

Epoch: 6| Step: 7
Training loss: 4.1109887497250845
Validation loss: 3.06769965834418

Epoch: 6| Step: 8
Training loss: 3.1328319824830615
Validation loss: 3.068451366459546

Epoch: 6| Step: 9
Training loss: 3.009157509238304
Validation loss: 3.069347033680077

Epoch: 6| Step: 10
Training loss: 3.547699550960007
Validation loss: 3.068668694769613

Epoch: 6| Step: 11
Training loss: 2.895446220887931
Validation loss: 3.070880218582944

Epoch: 6| Step: 12
Training loss: 3.795781233116278
Validation loss: 3.0702893902517583

Epoch: 6| Step: 13
Training loss: 3.758669178597742
Validation loss: 3.0727769244612047

Epoch: 62| Step: 0
Training loss: 3.5685612830722806
Validation loss: 3.0743928901077076

Epoch: 6| Step: 1
Training loss: 1.9780501244522548
Validation loss: 3.0685746178591904

Epoch: 6| Step: 2
Training loss: 3.6647813169178427
Validation loss: 3.075031547341207

Epoch: 6| Step: 3
Training loss: 3.7780185479374726
Validation loss: 3.069329402553649

Epoch: 6| Step: 4
Training loss: 3.685742880941591
Validation loss: 3.070675414708821

Epoch: 6| Step: 5
Training loss: 2.4615291792437795
Validation loss: 3.075450365881337

Epoch: 6| Step: 6
Training loss: 3.212710445650646
Validation loss: 3.0724347125420577

Epoch: 6| Step: 7
Training loss: 4.1532898880924805
Validation loss: 3.0682300723071623

Epoch: 6| Step: 8
Training loss: 3.4833618880809616
Validation loss: 3.067009223577704

Epoch: 6| Step: 9
Training loss: 3.199997133015302
Validation loss: 3.06446597976324

Epoch: 6| Step: 10
Training loss: 3.0156224700442755
Validation loss: 3.0647397267385363

Epoch: 6| Step: 11
Training loss: 3.875194052482659
Validation loss: 3.0640844030732612

Epoch: 6| Step: 12
Training loss: 2.770433459193497
Validation loss: 3.0613183794711487

Epoch: 6| Step: 13
Training loss: 2.7721714622455926
Validation loss: 3.06363000587817

Epoch: 63| Step: 0
Training loss: 2.942378436926302
Validation loss: 3.0632588022205782

Epoch: 6| Step: 1
Training loss: 3.5953978367989263
Validation loss: 3.0633331063037823

Epoch: 6| Step: 2
Training loss: 3.80257938580532
Validation loss: 3.0590054126774713

Epoch: 6| Step: 3
Training loss: 3.2838776739107494
Validation loss: 3.060648965025812

Epoch: 6| Step: 4
Training loss: 2.4484394786756125
Validation loss: 3.0599142915600543

Epoch: 6| Step: 5
Training loss: 3.297255073804348
Validation loss: 3.0591480779204714

Epoch: 6| Step: 6
Training loss: 3.0438262553914366
Validation loss: 3.0577479685443643

Epoch: 6| Step: 7
Training loss: 3.5089783632052196
Validation loss: 3.0569981570052662

Epoch: 6| Step: 8
Training loss: 3.36860021707613
Validation loss: 3.0573149101602355

Epoch: 6| Step: 9
Training loss: 3.1337886060201443
Validation loss: 3.056834983576427

Epoch: 6| Step: 10
Training loss: 3.378427531116779
Validation loss: 3.0546070964575205

Epoch: 6| Step: 11
Training loss: 3.4450785931617762
Validation loss: 3.058760726914394

Epoch: 6| Step: 12
Training loss: 3.7565969297428903
Validation loss: 3.05716596403918

Epoch: 6| Step: 13
Training loss: 3.2653360193329006
Validation loss: 3.0572003082250507

Epoch: 64| Step: 0
Training loss: 3.4052884205739344
Validation loss: 3.055997855901006

Epoch: 6| Step: 1
Training loss: 3.413331256831054
Validation loss: 3.056765695342044

Epoch: 6| Step: 2
Training loss: 2.591751431697032
Validation loss: 3.057943322288362

Epoch: 6| Step: 3
Training loss: 2.3912358718989126
Validation loss: 3.05650537133875

Epoch: 6| Step: 4
Training loss: 4.152312514581483
Validation loss: 3.05899388257877

Epoch: 6| Step: 5
Training loss: 3.1396779013003187
Validation loss: 3.0584800945417054

Epoch: 6| Step: 6
Training loss: 3.189367308341052
Validation loss: 3.0641139910799158

Epoch: 6| Step: 7
Training loss: 3.013731999764785
Validation loss: 3.062723829248758

Epoch: 6| Step: 8
Training loss: 4.1358684353886
Validation loss: 3.059657889465715

Epoch: 6| Step: 9
Training loss: 3.0248635253385943
Validation loss: 3.059603418094307

Epoch: 6| Step: 10
Training loss: 3.1137633674300957
Validation loss: 3.055830484726725

Epoch: 6| Step: 11
Training loss: 3.661217339273306
Validation loss: 3.0557745893869868

Epoch: 6| Step: 12
Training loss: 3.275936511140656
Validation loss: 3.0490359686618707

Epoch: 6| Step: 13
Training loss: 3.6050318890350295
Validation loss: 3.0507058956552053

Epoch: 65| Step: 0
Training loss: 2.5742374587356
Validation loss: 3.049674542628448

Epoch: 6| Step: 1
Training loss: 3.1019588188423692
Validation loss: 3.0524934177281184

Epoch: 6| Step: 2
Training loss: 2.869895716244606
Validation loss: 3.0499440006311107

Epoch: 6| Step: 3
Training loss: 4.1720770740503355
Validation loss: 3.0519820213337208

Epoch: 6| Step: 4
Training loss: 3.547618502357468
Validation loss: 3.053372872367916

Epoch: 6| Step: 5
Training loss: 3.268588095278553
Validation loss: 3.0526803729856473

Epoch: 6| Step: 6
Training loss: 3.26799954320748
Validation loss: 3.0522858397359838

Epoch: 6| Step: 7
Training loss: 3.854392105245205
Validation loss: 3.0506442407159082

Epoch: 6| Step: 8
Training loss: 3.2792826249504263
Validation loss: 3.0503318610784214

Epoch: 6| Step: 9
Training loss: 3.406353590203774
Validation loss: 3.0460170197288416

Epoch: 6| Step: 10
Training loss: 3.45593147672609
Validation loss: 3.0461336868992017

Epoch: 6| Step: 11
Training loss: 2.395330149566264
Validation loss: 3.0461520573926886

Epoch: 6| Step: 12
Training loss: 3.6727504254803662
Validation loss: 3.0447675233327405

Epoch: 6| Step: 13
Training loss: 2.8880554325564036
Validation loss: 3.0452578695481742

Epoch: 66| Step: 0
Training loss: 3.4574852941590617
Validation loss: 3.044185041454221

Epoch: 6| Step: 1
Training loss: 3.9514902225157655
Validation loss: 3.046686401083373

Epoch: 6| Step: 2
Training loss: 3.4915312079933645
Validation loss: 3.047162424670782

Epoch: 6| Step: 3
Training loss: 3.7048634500604405
Validation loss: 3.0442174520163032

Epoch: 6| Step: 4
Training loss: 3.105668048341493
Validation loss: 3.0432113737555806

Epoch: 6| Step: 5
Training loss: 3.0337212311049018
Validation loss: 3.0419144292825337

Epoch: 6| Step: 6
Training loss: 2.9032508387563167
Validation loss: 3.043878836152977

Epoch: 6| Step: 7
Training loss: 3.423346355553374
Validation loss: 3.0425851109250215

Epoch: 6| Step: 8
Training loss: 3.0472325824324584
Validation loss: 3.0395122781202617

Epoch: 6| Step: 9
Training loss: 3.7248720697542295
Validation loss: 3.042802738136542

Epoch: 6| Step: 10
Training loss: 3.375481747753785
Validation loss: 3.0484532713523493

Epoch: 6| Step: 11
Training loss: 2.159568113312279
Validation loss: 3.048464044087108

Epoch: 6| Step: 12
Training loss: 3.375975291301829
Validation loss: 3.0487759827641323

Epoch: 6| Step: 13
Training loss: 3.0746246418933154
Validation loss: 3.0461237222824478

Epoch: 67| Step: 0
Training loss: 3.7657493475805994
Validation loss: 3.0473015128309253

Epoch: 6| Step: 1
Training loss: 3.332431353286251
Validation loss: 3.0431961218311114

Epoch: 6| Step: 2
Training loss: 3.1305361727866963
Validation loss: 3.039999205728707

Epoch: 6| Step: 3
Training loss: 3.560363396517101
Validation loss: 3.0381988437853176

Epoch: 6| Step: 4
Training loss: 2.0779883547723697
Validation loss: 3.0393365798133294

Epoch: 6| Step: 5
Training loss: 3.6037716658275376
Validation loss: 3.0363045640510204

Epoch: 6| Step: 6
Training loss: 3.088599956577812
Validation loss: 3.039363949153518

Epoch: 6| Step: 7
Training loss: 3.3237621383760962
Validation loss: 3.036751993481522

Epoch: 6| Step: 8
Training loss: 3.70326535244639
Validation loss: 3.0377619301043413

Epoch: 6| Step: 9
Training loss: 3.300440302287688
Validation loss: 3.039953198982088

Epoch: 6| Step: 10
Training loss: 3.5569693483110334
Validation loss: 3.0389045201664477

Epoch: 6| Step: 11
Training loss: 3.2297368356362752
Validation loss: 3.039571449791676

Epoch: 6| Step: 12
Training loss: 2.773547189182134
Validation loss: 3.0376446409504143

Epoch: 6| Step: 13
Training loss: 3.5546799879728317
Validation loss: 3.0343045523525674

Epoch: 68| Step: 0
Training loss: 4.067515402438234
Validation loss: 3.03314560741233

Epoch: 6| Step: 1
Training loss: 3.249409255111173
Validation loss: 3.03606549802145

Epoch: 6| Step: 2
Training loss: 2.9364510144461287
Validation loss: 3.034549202811417

Epoch: 6| Step: 3
Training loss: 2.219916238665201
Validation loss: 3.0357418289651625

Epoch: 6| Step: 4
Training loss: 3.6455351498690374
Validation loss: 3.03362244336306

Epoch: 6| Step: 5
Training loss: 3.2871259121130363
Validation loss: 3.034432807521178

Epoch: 6| Step: 6
Training loss: 3.8195474244694223
Validation loss: 3.0323728801700844

Epoch: 6| Step: 7
Training loss: 3.8790152881121407
Validation loss: 3.0357071989415694

Epoch: 6| Step: 8
Training loss: 3.1890522786135036
Validation loss: 3.0370901259578695

Epoch: 6| Step: 9
Training loss: 3.8580137006438258
Validation loss: 3.0399759464980036

Epoch: 6| Step: 10
Training loss: 1.7427740777431442
Validation loss: 3.039893548982031

Epoch: 6| Step: 11
Training loss: 3.422330085766477
Validation loss: 3.03757924372742

Epoch: 6| Step: 12
Training loss: 3.026135564103423
Validation loss: 3.0415126532854337

Epoch: 6| Step: 13
Training loss: 2.8751220677211036
Validation loss: 3.031248616373761

Epoch: 69| Step: 0
Training loss: 2.608440848705189
Validation loss: 3.0312082879584032

Epoch: 6| Step: 1
Training loss: 3.4798554673271025
Validation loss: 3.032893271732982

Epoch: 6| Step: 2
Training loss: 3.186864004076885
Validation loss: 3.0352668699288308

Epoch: 6| Step: 3
Training loss: 3.256469449722742
Validation loss: 3.0399313840100914

Epoch: 6| Step: 4
Training loss: 3.5415935434010715
Validation loss: 3.0539643048137703

Epoch: 6| Step: 5
Training loss: 3.529959924054335
Validation loss: 3.0669308959433583

Epoch: 6| Step: 6
Training loss: 2.614337519505382
Validation loss: 3.0394281414692466

Epoch: 6| Step: 7
Training loss: 3.550140490908492
Validation loss: 3.025805584931699

Epoch: 6| Step: 8
Training loss: 3.3169393481648557
Validation loss: 3.0319768661908504

Epoch: 6| Step: 9
Training loss: 3.6851959789238036
Validation loss: 3.028802791966552

Epoch: 6| Step: 10
Training loss: 3.266279237180559
Validation loss: 3.0296809697690716

Epoch: 6| Step: 11
Training loss: 2.6305811450988745
Validation loss: 3.03366119659737

Epoch: 6| Step: 12
Training loss: 3.2970823973013967
Validation loss: 3.037242296756016

Epoch: 6| Step: 13
Training loss: 4.406522485410544
Validation loss: 3.039035618903021

Epoch: 70| Step: 0
Training loss: 3.0240645041877467
Validation loss: 3.0289228746416477

Epoch: 6| Step: 1
Training loss: 3.4884089225480843
Validation loss: 3.02730068508272

Epoch: 6| Step: 2
Training loss: 3.195893549610865
Validation loss: 3.0258337476856374

Epoch: 6| Step: 3
Training loss: 4.370974405277034
Validation loss: 3.0240071044109644

Epoch: 6| Step: 4
Training loss: 3.5601164222282584
Validation loss: 3.0248416083210308

Epoch: 6| Step: 5
Training loss: 3.2904535464462645
Validation loss: 3.0209681112048314

Epoch: 6| Step: 6
Training loss: 3.1747898182422483
Validation loss: 3.021498048921115

Epoch: 6| Step: 7
Training loss: 2.0830850707587105
Validation loss: 3.021361592022871

Epoch: 6| Step: 8
Training loss: 2.5950671608820697
Validation loss: 3.0234318036513854

Epoch: 6| Step: 9
Training loss: 3.1298130354936533
Validation loss: 3.0272191366376227

Epoch: 6| Step: 10
Training loss: 3.8295802250393196
Validation loss: 3.0224830117319863

Epoch: 6| Step: 11
Training loss: 3.4283847985108316
Validation loss: 3.0180189443171845

Epoch: 6| Step: 12
Training loss: 3.3276421281710435
Validation loss: 3.0188770487322256

Epoch: 6| Step: 13
Training loss: 2.931082350241372
Validation loss: 3.0225071027837793

Epoch: 71| Step: 0
Training loss: 3.0001465443740787
Validation loss: 3.0187929271704035

Epoch: 6| Step: 1
Training loss: 3.1014302799666704
Validation loss: 3.0248120158577296

Epoch: 6| Step: 2
Training loss: 3.5079522391779387
Validation loss: 3.0313211358056846

Epoch: 6| Step: 3
Training loss: 3.5326315278811324
Validation loss: 3.0290075908606897

Epoch: 6| Step: 4
Training loss: 3.276072459033215
Validation loss: 3.0665451951555744

Epoch: 6| Step: 5
Training loss: 3.953595159865303
Validation loss: 3.1189740284081515

Epoch: 6| Step: 6
Training loss: 2.860772630325492
Validation loss: 3.075400930726131

Epoch: 6| Step: 7
Training loss: 3.7386576464032215
Validation loss: 3.0204458543347594

Epoch: 6| Step: 8
Training loss: 2.502443740471472
Validation loss: 3.0181667084262847

Epoch: 6| Step: 9
Training loss: 2.7956872900972365
Validation loss: 3.0285933557588707

Epoch: 6| Step: 10
Training loss: 3.185586392305473
Validation loss: 3.0646953503371215

Epoch: 6| Step: 11
Training loss: 3.26318516460805
Validation loss: 3.019878852498915

Epoch: 6| Step: 12
Training loss: 3.567327608088124
Validation loss: 3.016887518041733

Epoch: 6| Step: 13
Training loss: 3.865469256064531
Validation loss: 3.015953250553481

Epoch: 72| Step: 0
Training loss: 3.139901300810745
Validation loss: 3.0180054771885594

Epoch: 6| Step: 1
Training loss: 3.490666478524471
Validation loss: 3.0246559242986213

Epoch: 6| Step: 2
Training loss: 3.349237520357945
Validation loss: 3.0359113581185184

Epoch: 6| Step: 3
Training loss: 3.079255027346306
Validation loss: 3.039584855107222

Epoch: 6| Step: 4
Training loss: 2.8687427263022234
Validation loss: 3.0451806021836325

Epoch: 6| Step: 5
Training loss: 3.285941992741668
Validation loss: 3.0873569175882696

Epoch: 6| Step: 6
Training loss: 3.494251980827596
Validation loss: 3.0834562952809934

Epoch: 6| Step: 7
Training loss: 3.239642438114283
Validation loss: 3.0502634378832445

Epoch: 6| Step: 8
Training loss: 2.9274662803577836
Validation loss: 3.0219461045673564

Epoch: 6| Step: 9
Training loss: 2.7724193154677756
Validation loss: 3.0168886873159635

Epoch: 6| Step: 10
Training loss: 3.4713913766975284
Validation loss: 3.022334560372536

Epoch: 6| Step: 11
Training loss: 3.4456673437236387
Validation loss: 3.0207615799633527

Epoch: 6| Step: 12
Training loss: 4.357388607840289
Validation loss: 3.020336881472034

Epoch: 6| Step: 13
Training loss: 2.700025159224098
Validation loss: 3.0144817861739024

Epoch: 73| Step: 0
Training loss: 3.143230211731306
Validation loss: 3.0128928786342493

Epoch: 6| Step: 1
Training loss: 3.3457054053553232
Validation loss: 3.0099700455637834

Epoch: 6| Step: 2
Training loss: 3.2580654128447146
Validation loss: 3.0084164427956956

Epoch: 6| Step: 3
Training loss: 2.7731610227510175
Validation loss: 3.008840447530995

Epoch: 6| Step: 4
Training loss: 3.922172991005689
Validation loss: 3.0068517907787635

Epoch: 6| Step: 5
Training loss: 2.415656393816861
Validation loss: 3.0067993349833873

Epoch: 6| Step: 6
Training loss: 3.1202365428560097
Validation loss: 3.0086594031609195

Epoch: 6| Step: 7
Training loss: 3.6589395135267626
Validation loss: 3.0073619465124493

Epoch: 6| Step: 8
Training loss: 2.8098131697371134
Validation loss: 3.009896448707812

Epoch: 6| Step: 9
Training loss: 3.2402131837010475
Validation loss: 3.0094035497934057

Epoch: 6| Step: 10
Training loss: 3.691653611710473
Validation loss: 3.012234741985837

Epoch: 6| Step: 11
Training loss: 3.452782523316566
Validation loss: 3.0115767883957396

Epoch: 6| Step: 12
Training loss: 3.4781804466797763
Validation loss: 3.022512424282337

Epoch: 6| Step: 13
Training loss: 3.56082970797938
Validation loss: 3.0192913873960254

Epoch: 74| Step: 0
Training loss: 3.2143085539475624
Validation loss: 3.0172718313581735

Epoch: 6| Step: 1
Training loss: 3.252063682899189
Validation loss: 3.010705434072019

Epoch: 6| Step: 2
Training loss: 3.203165789088616
Validation loss: 3.0149509893012003

Epoch: 6| Step: 3
Training loss: 3.929075159252577
Validation loss: 3.011404171366925

Epoch: 6| Step: 4
Training loss: 2.870492469989021
Validation loss: 3.008630343433396

Epoch: 6| Step: 5
Training loss: 3.6436055961248472
Validation loss: 3.006663133557158

Epoch: 6| Step: 6
Training loss: 3.269511561180637
Validation loss: 3.0104427808436607

Epoch: 6| Step: 7
Training loss: 2.796786173683314
Validation loss: 3.009449602744984

Epoch: 6| Step: 8
Training loss: 3.069787366381014
Validation loss: 3.004716928357876

Epoch: 6| Step: 9
Training loss: 3.766259864062418
Validation loss: 3.0031341021621376

Epoch: 6| Step: 10
Training loss: 3.496461987415759
Validation loss: 3.0024183858845808

Epoch: 6| Step: 11
Training loss: 3.0016214439406927
Validation loss: 2.9995854614325563

Epoch: 6| Step: 12
Training loss: 2.8899020553940074
Validation loss: 3.000042369844129

Epoch: 6| Step: 13
Training loss: 3.3095582099033654
Validation loss: 2.9992845410216344

Epoch: 75| Step: 0
Training loss: 3.0897201339743736
Validation loss: 2.999567051892487

Epoch: 6| Step: 1
Training loss: 3.0504456554074584
Validation loss: 3.000010792907661

Epoch: 6| Step: 2
Training loss: 3.868983982387267
Validation loss: 3.0014071522778587

Epoch: 6| Step: 3
Training loss: 3.5887822853477718
Validation loss: 2.9959117376713866

Epoch: 6| Step: 4
Training loss: 3.3973932876277178
Validation loss: 2.9975738354221817

Epoch: 6| Step: 5
Training loss: 2.632155973265345
Validation loss: 2.9991400282540983

Epoch: 6| Step: 6
Training loss: 3.7097726378987628
Validation loss: 2.9977222310279568

Epoch: 6| Step: 7
Training loss: 3.5184949223431725
Validation loss: 3.0019047426099545

Epoch: 6| Step: 8
Training loss: 3.53058908404752
Validation loss: 2.999042854790239

Epoch: 6| Step: 9
Training loss: 3.0131971636812613
Validation loss: 2.99984577425148

Epoch: 6| Step: 10
Training loss: 3.203756577168358
Validation loss: 2.9998994642933603

Epoch: 6| Step: 11
Training loss: 2.7000591554166036
Validation loss: 3.0014108003342352

Epoch: 6| Step: 12
Training loss: 3.4290948933675964
Validation loss: 2.9986898644687834

Epoch: 6| Step: 13
Training loss: 2.4647106491400517
Validation loss: 2.998676344729753

Epoch: 76| Step: 0
Training loss: 2.8163366639830225
Validation loss: 3.001204360005545

Epoch: 6| Step: 1
Training loss: 3.1513512997837037
Validation loss: 3.000972607232867

Epoch: 6| Step: 2
Training loss: 3.52895422382019
Validation loss: 2.996290381295409

Epoch: 6| Step: 3
Training loss: 3.101964660246465
Validation loss: 2.9982790044045315

Epoch: 6| Step: 4
Training loss: 3.2987520921707025
Validation loss: 2.9956982587649974

Epoch: 6| Step: 5
Training loss: 3.255787025384659
Validation loss: 2.997580307860376

Epoch: 6| Step: 6
Training loss: 3.3863912421841635
Validation loss: 2.992997503160593

Epoch: 6| Step: 7
Training loss: 3.562523289654547
Validation loss: 2.9911087478970746

Epoch: 6| Step: 8
Training loss: 3.423913914355897
Validation loss: 2.9936799933082203

Epoch: 6| Step: 9
Training loss: 3.11002684235105
Validation loss: 2.9944894591978986

Epoch: 6| Step: 10
Training loss: 2.880511763985861
Validation loss: 2.9908195064517655

Epoch: 6| Step: 11
Training loss: 3.5208141770302572
Validation loss: 2.9911746803075108

Epoch: 6| Step: 12
Training loss: 3.300214332787188
Validation loss: 2.9924616906911643

Epoch: 6| Step: 13
Training loss: 3.4628048373556615
Validation loss: 2.9912024594723268

Epoch: 77| Step: 0
Training loss: 3.172372111936012
Validation loss: 2.990697370096226

Epoch: 6| Step: 1
Training loss: 2.8475835762117225
Validation loss: 2.9903933023231404

Epoch: 6| Step: 2
Training loss: 3.772215588101406
Validation loss: 2.9887020382375318

Epoch: 6| Step: 3
Training loss: 3.1393759601826217
Validation loss: 2.989222368662445

Epoch: 6| Step: 4
Training loss: 2.978837873192844
Validation loss: 2.9956531736849037

Epoch: 6| Step: 5
Training loss: 3.100831529397567
Validation loss: 3.004039072371888

Epoch: 6| Step: 6
Training loss: 3.052990376092141
Validation loss: 2.9862060530509953

Epoch: 6| Step: 7
Training loss: 3.5920180418075436
Validation loss: 2.9883522762506685

Epoch: 6| Step: 8
Training loss: 3.0231236336803367
Validation loss: 2.9892316550434024

Epoch: 6| Step: 9
Training loss: 4.1728640180527306
Validation loss: 2.988346899068705

Epoch: 6| Step: 10
Training loss: 3.469101896564873
Validation loss: 2.985572161206389

Epoch: 6| Step: 11
Training loss: 3.1795282347436746
Validation loss: 2.987775339015185

Epoch: 6| Step: 12
Training loss: 3.3483418816368262
Validation loss: 2.989174986058236

Epoch: 6| Step: 13
Training loss: 1.9745154353736536
Validation loss: 2.9862932447435053

Epoch: 78| Step: 0
Training loss: 3.3660238073983755
Validation loss: 2.986808674075197

Epoch: 6| Step: 1
Training loss: 2.4411577998582135
Validation loss: 2.9868538248523

Epoch: 6| Step: 2
Training loss: 2.4359256844420587
Validation loss: 2.9870343232947074

Epoch: 6| Step: 3
Training loss: 3.4906040501798303
Validation loss: 2.9867770482118554

Epoch: 6| Step: 4
Training loss: 3.359759925258216
Validation loss: 2.9882988008266183

Epoch: 6| Step: 5
Training loss: 3.062284968086583
Validation loss: 2.989129057285689

Epoch: 6| Step: 6
Training loss: 3.641784745199954
Validation loss: 2.98715014786868

Epoch: 6| Step: 7
Training loss: 2.3845950603802204
Validation loss: 2.989160093933456

Epoch: 6| Step: 8
Training loss: 3.4087926491397362
Validation loss: 2.9945567442931407

Epoch: 6| Step: 9
Training loss: 3.9427219459503626
Validation loss: 2.987981643257741

Epoch: 6| Step: 10
Training loss: 2.7317940874931264
Validation loss: 2.9858973019644535

Epoch: 6| Step: 11
Training loss: 4.092402112532342
Validation loss: 2.9833149018517178

Epoch: 6| Step: 12
Training loss: 3.391090888436235
Validation loss: 2.9844855487941118

Epoch: 6| Step: 13
Training loss: 3.4250199310391083
Validation loss: 2.983133406639081

Epoch: 79| Step: 0
Training loss: 2.3386764544162926
Validation loss: 2.9826595248970147

Epoch: 6| Step: 1
Training loss: 3.5429259511093294
Validation loss: 2.9827406843572875

Epoch: 6| Step: 2
Training loss: 3.4698333423180303
Validation loss: 2.979838104505529

Epoch: 6| Step: 3
Training loss: 3.5110001046167945
Validation loss: 2.9793896312363786

Epoch: 6| Step: 4
Training loss: 3.0521276338419594
Validation loss: 2.9876177088691747

Epoch: 6| Step: 5
Training loss: 2.231760482734409
Validation loss: 2.9851683567336638

Epoch: 6| Step: 6
Training loss: 3.604709268346306
Validation loss: 2.995398512353839

Epoch: 6| Step: 7
Training loss: 3.40336738893194
Validation loss: 2.9952815474385406

Epoch: 6| Step: 8
Training loss: 3.269443743228612
Validation loss: 3.0158502170633827

Epoch: 6| Step: 9
Training loss: 3.594767948773576
Validation loss: 2.9984810429311315

Epoch: 6| Step: 10
Training loss: 3.6329140925814842
Validation loss: 2.9979583020621243

Epoch: 6| Step: 11
Training loss: 3.1960657253262905
Validation loss: 2.9824971494963712

Epoch: 6| Step: 12
Training loss: 3.4781121732710054
Validation loss: 2.9793809965244944

Epoch: 6| Step: 13
Training loss: 2.7370709888700393
Validation loss: 2.9761810889498896

Epoch: 80| Step: 0
Training loss: 3.798690926788225
Validation loss: 2.978411410031766

Epoch: 6| Step: 1
Training loss: 3.3171595783828414
Validation loss: 2.98074805582136

Epoch: 6| Step: 2
Training loss: 3.709268744858214
Validation loss: 2.984880343290264

Epoch: 6| Step: 3
Training loss: 2.491256683539705
Validation loss: 2.9903732836276706

Epoch: 6| Step: 4
Training loss: 3.267805329864244
Validation loss: 2.9857992184083724

Epoch: 6| Step: 5
Training loss: 3.0485897618624933
Validation loss: 2.9833016956975626

Epoch: 6| Step: 6
Training loss: 3.33657409168619
Validation loss: 2.9806587228474055

Epoch: 6| Step: 7
Training loss: 3.4431045619699385
Validation loss: 2.974990482578787

Epoch: 6| Step: 8
Training loss: 3.46338300222028
Validation loss: 2.9762985503911987

Epoch: 6| Step: 9
Training loss: 2.8180279130385757
Validation loss: 2.9761814791577086

Epoch: 6| Step: 10
Training loss: 3.2696601723760628
Validation loss: 2.974733467188874

Epoch: 6| Step: 11
Training loss: 2.7955412001899074
Validation loss: 2.9802525167351335

Epoch: 6| Step: 12
Training loss: 3.658914622104898
Validation loss: 2.980026749719815

Epoch: 6| Step: 13
Training loss: 2.7336057616365403
Validation loss: 2.9861977290794393

Epoch: 81| Step: 0
Training loss: 3.2878079230272412
Validation loss: 2.9862753610605397

Epoch: 6| Step: 1
Training loss: 2.7176557070597185
Validation loss: 2.9924938304595354

Epoch: 6| Step: 2
Training loss: 3.420613652995837
Validation loss: 3.0008645862741687

Epoch: 6| Step: 3
Training loss: 3.3755224318054933
Validation loss: 3.0024124805929815

Epoch: 6| Step: 4
Training loss: 3.313628958006296
Validation loss: 2.9823062106396474

Epoch: 6| Step: 5
Training loss: 3.0806905056657703
Validation loss: 2.972647442220561

Epoch: 6| Step: 6
Training loss: 3.6310345636696266
Validation loss: 2.971287665309088

Epoch: 6| Step: 7
Training loss: 3.281109034825433
Validation loss: 2.9696900455928095

Epoch: 6| Step: 8
Training loss: 2.577667843138833
Validation loss: 2.9695273227432963

Epoch: 6| Step: 9
Training loss: 3.12452022684271
Validation loss: 2.972383228613233

Epoch: 6| Step: 10
Training loss: 3.1451614032805293
Validation loss: 2.972033462827696

Epoch: 6| Step: 11
Training loss: 3.7903381088137738
Validation loss: 2.971580590284413

Epoch: 6| Step: 12
Training loss: 3.678011696884532
Validation loss: 2.9735291307810874

Epoch: 6| Step: 13
Training loss: 2.842121202766233
Validation loss: 2.9750102730202523

Epoch: 82| Step: 0
Training loss: 3.540989904631148
Validation loss: 2.9733163029862504

Epoch: 6| Step: 1
Training loss: 3.6328214255602718
Validation loss: 2.9709096146439222

Epoch: 6| Step: 2
Training loss: 3.357504248371405
Validation loss: 2.973009447787893

Epoch: 6| Step: 3
Training loss: 4.212916883900547
Validation loss: 2.9704000372574058

Epoch: 6| Step: 4
Training loss: 3.2119234153957015
Validation loss: 2.9655001803161944

Epoch: 6| Step: 5
Training loss: 3.352897040447674
Validation loss: 2.9672838875121204

Epoch: 6| Step: 6
Training loss: 2.7221176512305845
Validation loss: 2.9661697374775944

Epoch: 6| Step: 7
Training loss: 3.2853716440609286
Validation loss: 2.963942697960627

Epoch: 6| Step: 8
Training loss: 3.089583548719245
Validation loss: 2.967214159228616

Epoch: 6| Step: 9
Training loss: 3.2442064732179334
Validation loss: 2.967774751379454

Epoch: 6| Step: 10
Training loss: 3.364566641530932
Validation loss: 2.9705239229686136

Epoch: 6| Step: 11
Training loss: 2.5499325051444472
Validation loss: 2.9714038845400497

Epoch: 6| Step: 12
Training loss: 2.328901532618503
Validation loss: 2.97411425434119

Epoch: 6| Step: 13
Training loss: 3.1388711919445087
Validation loss: 2.976058042588732

Epoch: 83| Step: 0
Training loss: 2.9582649187227474
Validation loss: 2.9787482126902325

Epoch: 6| Step: 1
Training loss: 3.3692014826931094
Validation loss: 2.9795183134429712

Epoch: 6| Step: 2
Training loss: 3.719171452081502
Validation loss: 2.9775007721679425

Epoch: 6| Step: 3
Training loss: 3.242332657471553
Validation loss: 2.9712786662435877

Epoch: 6| Step: 4
Training loss: 3.1515933896292343
Validation loss: 2.973626025851014

Epoch: 6| Step: 5
Training loss: 2.9625375093427415
Validation loss: 2.972025435572192

Epoch: 6| Step: 6
Training loss: 3.584791877270524
Validation loss: 2.96502371900088

Epoch: 6| Step: 7
Training loss: 3.2868964159699963
Validation loss: 2.960837755788694

Epoch: 6| Step: 8
Training loss: 3.187749067561124
Validation loss: 2.9610952361874294

Epoch: 6| Step: 9
Training loss: 3.67017484222449
Validation loss: 2.9589024357006464

Epoch: 6| Step: 10
Training loss: 3.2799685927957545
Validation loss: 2.962350511048179

Epoch: 6| Step: 11
Training loss: 3.2734632832460875
Validation loss: 2.9591129473909237

Epoch: 6| Step: 12
Training loss: 2.724779655577264
Validation loss: 2.960634480191381

Epoch: 6| Step: 13
Training loss: 2.515534393384785
Validation loss: 2.9639255962639868

Epoch: 84| Step: 0
Training loss: 3.191303751127117
Validation loss: 2.9687989088950815

Epoch: 6| Step: 1
Training loss: 3.696823230680819
Validation loss: 2.967334767925192

Epoch: 6| Step: 2
Training loss: 3.417309088128932
Validation loss: 2.9665558016783957

Epoch: 6| Step: 3
Training loss: 2.8432039847548367
Validation loss: 2.9657338959310513

Epoch: 6| Step: 4
Training loss: 3.1202093406285583
Validation loss: 2.9648963013165552

Epoch: 6| Step: 5
Training loss: 2.767100484762604
Validation loss: 2.96141801394551

Epoch: 6| Step: 6
Training loss: 2.625829474776119
Validation loss: 2.963613446149238

Epoch: 6| Step: 7
Training loss: 3.878542111794568
Validation loss: 2.961169478879924

Epoch: 6| Step: 8
Training loss: 3.068100615431895
Validation loss: 2.958056495142476

Epoch: 6| Step: 9
Training loss: 3.5994709420868016
Validation loss: 2.959459305155055

Epoch: 6| Step: 10
Training loss: 2.761407081898728
Validation loss: 2.957822457177553

Epoch: 6| Step: 11
Training loss: 3.1353670202910395
Validation loss: 2.9557452188894096

Epoch: 6| Step: 12
Training loss: 3.6421952033564904
Validation loss: 2.955539505203042

Epoch: 6| Step: 13
Training loss: 3.593200110783257
Validation loss: 2.9553716000466097

Epoch: 85| Step: 0
Training loss: 3.3973510408623704
Validation loss: 2.95455380137468

Epoch: 6| Step: 1
Training loss: 3.0819631745491938
Validation loss: 2.9546435626763947

Epoch: 6| Step: 2
Training loss: 2.896420170078185
Validation loss: 2.952084516615535

Epoch: 6| Step: 3
Training loss: 3.9079345732866813
Validation loss: 2.953217759688224

Epoch: 6| Step: 4
Training loss: 3.727751792012387
Validation loss: 2.9539969027908985

Epoch: 6| Step: 5
Training loss: 2.837988413985342
Validation loss: 2.952231496890564

Epoch: 6| Step: 6
Training loss: 3.016406022363045
Validation loss: 2.954664041233388

Epoch: 6| Step: 7
Training loss: 2.9803349976131956
Validation loss: 2.956991142223866

Epoch: 6| Step: 8
Training loss: 2.7147937797503228
Validation loss: 2.9576276500493357

Epoch: 6| Step: 9
Training loss: 3.183147525524145
Validation loss: 2.9509140439194006

Epoch: 6| Step: 10
Training loss: 2.6998007736172167
Validation loss: 2.958983882022864

Epoch: 6| Step: 11
Training loss: 3.9117734386780216
Validation loss: 2.959412426633973

Epoch: 6| Step: 12
Training loss: 3.7376917710112814
Validation loss: 2.953850538042457

Epoch: 6| Step: 13
Training loss: 2.3875765843116676
Validation loss: 2.957828907393238

Epoch: 86| Step: 0
Training loss: 2.94073275977752
Validation loss: 2.9577591165603483

Epoch: 6| Step: 1
Training loss: 2.893980645695671
Validation loss: 2.9603024182956963

Epoch: 6| Step: 2
Training loss: 2.8657685388456104
Validation loss: 2.9486029482065526

Epoch: 6| Step: 3
Training loss: 2.242248215335132
Validation loss: 2.9534828224043763

Epoch: 6| Step: 4
Training loss: 3.878614278294195
Validation loss: 2.954208167564601

Epoch: 6| Step: 5
Training loss: 3.5043732705068633
Validation loss: 2.9509191348576462

Epoch: 6| Step: 6
Training loss: 3.6927000977388915
Validation loss: 2.944640963610757

Epoch: 6| Step: 7
Training loss: 3.2077035327061245
Validation loss: 2.9475406128728796

Epoch: 6| Step: 8
Training loss: 3.5102591700931636
Validation loss: 2.943638340318235

Epoch: 6| Step: 9
Training loss: 2.686298367866759
Validation loss: 2.9426311814219024

Epoch: 6| Step: 10
Training loss: 3.65347654349687
Validation loss: 2.9423337607440825

Epoch: 6| Step: 11
Training loss: 3.4848193240296363
Validation loss: 2.944487975643566

Epoch: 6| Step: 12
Training loss: 2.894158425561485
Validation loss: 2.9438322261085834

Epoch: 6| Step: 13
Training loss: 3.3931894756268597
Validation loss: 2.9428547464040133

Epoch: 87| Step: 0
Training loss: 3.3798826714190233
Validation loss: 2.942667629008705

Epoch: 6| Step: 1
Training loss: 3.120677094226223
Validation loss: 2.941318654195217

Epoch: 6| Step: 2
Training loss: 3.8948877720463186
Validation loss: 2.9430876114022286

Epoch: 6| Step: 3
Training loss: 3.0544463157563273
Validation loss: 2.9402113205146434

Epoch: 6| Step: 4
Training loss: 2.655377682333295
Validation loss: 2.937381748113695

Epoch: 6| Step: 5
Training loss: 3.2053009829779624
Validation loss: 2.940146167892224

Epoch: 6| Step: 6
Training loss: 3.2822624461088905
Validation loss: 2.9465647783826863

Epoch: 6| Step: 7
Training loss: 3.576775575409464
Validation loss: 2.940944075173782

Epoch: 6| Step: 8
Training loss: 2.700426375313719
Validation loss: 2.945993290326465

Epoch: 6| Step: 9
Training loss: 3.5969325030359527
Validation loss: 2.944394498625775

Epoch: 6| Step: 10
Training loss: 3.18211133646801
Validation loss: 2.9522963845451553

Epoch: 6| Step: 11
Training loss: 3.1193022091932407
Validation loss: 2.9441376379076827

Epoch: 6| Step: 12
Training loss: 3.3088618038182824
Validation loss: 2.9440370571830203

Epoch: 6| Step: 13
Training loss: 2.5619969688355906
Validation loss: 2.947628849151001

Epoch: 88| Step: 0
Training loss: 3.252508515824027
Validation loss: 2.9450196956526984

Epoch: 6| Step: 1
Training loss: 3.65997724390512
Validation loss: 2.943352424480604

Epoch: 6| Step: 2
Training loss: 3.324171987130692
Validation loss: 2.948923829790719

Epoch: 6| Step: 3
Training loss: 3.022108155401109
Validation loss: 2.9609497998216696

Epoch: 6| Step: 4
Training loss: 3.300211732025127
Validation loss: 2.9501053472027516

Epoch: 6| Step: 5
Training loss: 2.734933240309345
Validation loss: 2.9504399426422214

Epoch: 6| Step: 6
Training loss: 3.936411389228029
Validation loss: 2.950768897227651

Epoch: 6| Step: 7
Training loss: 2.8726812216861486
Validation loss: 2.936585800074149

Epoch: 6| Step: 8
Training loss: 3.1679512898332036
Validation loss: 2.9354041064032748

Epoch: 6| Step: 9
Training loss: 2.4978903452229066
Validation loss: 2.9383622027563887

Epoch: 6| Step: 10
Training loss: 3.182442486191617
Validation loss: 2.935434436009973

Epoch: 6| Step: 11
Training loss: 2.9554556878346028
Validation loss: 2.9354348604545604

Epoch: 6| Step: 12
Training loss: 3.796955751415922
Validation loss: 2.935709959250924

Epoch: 6| Step: 13
Training loss: 2.8960326055303525
Validation loss: 2.9362860645271955

Epoch: 89| Step: 0
Training loss: 3.426067831825436
Validation loss: 2.9355919985491066

Epoch: 6| Step: 1
Training loss: 3.334852412902965
Validation loss: 2.9354600702569695

Epoch: 6| Step: 2
Training loss: 3.0689218880863978
Validation loss: 2.9348784220353794

Epoch: 6| Step: 3
Training loss: 3.2724559832848206
Validation loss: 2.9373819383762103

Epoch: 6| Step: 4
Training loss: 3.205587640649871
Validation loss: 2.935648551777506

Epoch: 6| Step: 5
Training loss: 3.793259520144965
Validation loss: 2.937219521269574

Epoch: 6| Step: 6
Training loss: 3.501623594541761
Validation loss: 2.9350979421823977

Epoch: 6| Step: 7
Training loss: 2.57795169132211
Validation loss: 2.938454280331439

Epoch: 6| Step: 8
Training loss: 2.377226037286891
Validation loss: 2.9348355141209477

Epoch: 6| Step: 9
Training loss: 3.3152247324812643
Validation loss: 2.9323123733056637

Epoch: 6| Step: 10
Training loss: 3.0674933383561527
Validation loss: 2.9343553667039504

Epoch: 6| Step: 11
Training loss: 3.0632239284079916
Validation loss: 2.9296698159398518

Epoch: 6| Step: 12
Training loss: 3.725903722726258
Validation loss: 2.9320880788107697

Epoch: 6| Step: 13
Training loss: 2.9956270772066005
Validation loss: 2.929345446891823

Epoch: 90| Step: 0
Training loss: 2.86218323933109
Validation loss: 2.9278616517269165

Epoch: 6| Step: 1
Training loss: 3.2555049344041374
Validation loss: 2.9276625891721273

Epoch: 6| Step: 2
Training loss: 3.3167464190787452
Validation loss: 2.9302166248349732

Epoch: 6| Step: 3
Training loss: 3.4331032117245637
Validation loss: 2.928674012471561

Epoch: 6| Step: 4
Training loss: 3.2129443503296833
Validation loss: 2.950718311533882

Epoch: 6| Step: 5
Training loss: 2.6187516278464416
Validation loss: 2.964269450116608

Epoch: 6| Step: 6
Training loss: 3.432623160778942
Validation loss: 2.977189609659436

Epoch: 6| Step: 7
Training loss: 2.7849097871808337
Validation loss: 2.968885749170036

Epoch: 6| Step: 8
Training loss: 2.625789342003486
Validation loss: 2.9460197794805185

Epoch: 6| Step: 9
Training loss: 3.086384955692754
Validation loss: 2.938098508752307

Epoch: 6| Step: 10
Training loss: 4.512621240228751
Validation loss: 2.923633037995417

Epoch: 6| Step: 11
Training loss: 2.9627446520258727
Validation loss: 2.923802397538856

Epoch: 6| Step: 12
Training loss: 3.140021119016344
Validation loss: 2.927045168011284

Epoch: 6| Step: 13
Training loss: 3.5116993327553425
Validation loss: 2.9249984018303734

Epoch: 91| Step: 0
Training loss: 3.6378786918962986
Validation loss: 2.9246911123750907

Epoch: 6| Step: 1
Training loss: 2.9627362829052903
Validation loss: 2.9259866017308562

Epoch: 6| Step: 2
Training loss: 3.105603101211328
Validation loss: 2.924301469185586

Epoch: 6| Step: 3
Training loss: 3.0992136788621227
Validation loss: 2.9232888697952446

Epoch: 6| Step: 4
Training loss: 3.791418856952175
Validation loss: 2.922852212432937

Epoch: 6| Step: 5
Training loss: 3.1161550853365982
Validation loss: 2.923012685310705

Epoch: 6| Step: 6
Training loss: 2.9186809850207642
Validation loss: 2.9219585163507413

Epoch: 6| Step: 7
Training loss: 2.964256982450714
Validation loss: 2.9224517868900115

Epoch: 6| Step: 8
Training loss: 2.826955985731591
Validation loss: 2.9217482442770777

Epoch: 6| Step: 9
Training loss: 3.2307981902001837
Validation loss: 2.921431494567707

Epoch: 6| Step: 10
Training loss: 3.116625130388501
Validation loss: 2.9214410122309107

Epoch: 6| Step: 11
Training loss: 3.3308889168294584
Validation loss: 2.919821068564248

Epoch: 6| Step: 12
Training loss: 3.6955666968760785
Validation loss: 2.9180315249287383

Epoch: 6| Step: 13
Training loss: 2.804539668615535
Validation loss: 2.918389815721661

Epoch: 92| Step: 0
Training loss: 3.3410385404006315
Validation loss: 2.9190465944498345

Epoch: 6| Step: 1
Training loss: 2.9801639586025814
Validation loss: 2.91525053168067

Epoch: 6| Step: 2
Training loss: 2.5665879555395152
Validation loss: 2.9183752589977128

Epoch: 6| Step: 3
Training loss: 3.7303961462175628
Validation loss: 2.9202439969542575

Epoch: 6| Step: 4
Training loss: 3.622637537944314
Validation loss: 2.9193390435812607

Epoch: 6| Step: 5
Training loss: 3.9993555026585854
Validation loss: 2.9217511301553873

Epoch: 6| Step: 6
Training loss: 2.716699462723869
Validation loss: 2.9264102991587158

Epoch: 6| Step: 7
Training loss: 3.089657320940276
Validation loss: 2.92100067244455

Epoch: 6| Step: 8
Training loss: 3.5893361725883346
Validation loss: 2.9166270773408467

Epoch: 6| Step: 9
Training loss: 2.8045205409262985
Validation loss: 2.9164754925025624

Epoch: 6| Step: 10
Training loss: 2.8000350234702265
Validation loss: 2.9164394471808026

Epoch: 6| Step: 11
Training loss: 2.8036389954523906
Validation loss: 2.9149298534650487

Epoch: 6| Step: 12
Training loss: 3.6976712140929644
Validation loss: 2.914424521963516

Epoch: 6| Step: 13
Training loss: 2.4104343049885784
Validation loss: 2.9155507046181

Epoch: 93| Step: 0
Training loss: 3.6655231484444655
Validation loss: 2.9192164466519768

Epoch: 6| Step: 1
Training loss: 2.740713739643989
Validation loss: 2.9163475949078803

Epoch: 6| Step: 2
Training loss: 3.292174690413573
Validation loss: 2.9165710580042186

Epoch: 6| Step: 3
Training loss: 2.8937104125641575
Validation loss: 2.915507374203095

Epoch: 6| Step: 4
Training loss: 3.487170410989512
Validation loss: 2.9151067180549424

Epoch: 6| Step: 5
Training loss: 2.912032742326709
Validation loss: 2.9154976384443176

Epoch: 6| Step: 6
Training loss: 3.527030922503501
Validation loss: 2.9139853912676106

Epoch: 6| Step: 7
Training loss: 3.005107029486137
Validation loss: 2.9137810770216914

Epoch: 6| Step: 8
Training loss: 2.9295082953004052
Validation loss: 2.915988520409941

Epoch: 6| Step: 9
Training loss: 3.5700873172457266
Validation loss: 2.9108338661604716

Epoch: 6| Step: 10
Training loss: 3.4493724749860526
Validation loss: 2.9122004216573183

Epoch: 6| Step: 11
Training loss: 3.144747481404788
Validation loss: 2.910099959863133

Epoch: 6| Step: 12
Training loss: 3.3803443979269616
Validation loss: 2.9114737350218216

Epoch: 6| Step: 13
Training loss: 2.234022846347577
Validation loss: 2.909903031838651

Epoch: 94| Step: 0
Training loss: 3.676533442689241
Validation loss: 2.9106914514011546

Epoch: 6| Step: 1
Training loss: 2.8058225412352886
Validation loss: 2.9094761974094308

Epoch: 6| Step: 2
Training loss: 3.7707049662341405
Validation loss: 2.9158696809962468

Epoch: 6| Step: 3
Training loss: 2.7492568138893536
Validation loss: 2.922484534301892

Epoch: 6| Step: 4
Training loss: 3.3234070482818283
Validation loss: 2.9152395217036484

Epoch: 6| Step: 5
Training loss: 3.0949544392376813
Validation loss: 2.9148519791970418

Epoch: 6| Step: 6
Training loss: 3.654621772452331
Validation loss: 2.912648729293044

Epoch: 6| Step: 7
Training loss: 3.617045257605833
Validation loss: 2.910937152971932

Epoch: 6| Step: 8
Training loss: 2.659404362696853
Validation loss: 2.9040235480760592

Epoch: 6| Step: 9
Training loss: 2.5699001549647873
Validation loss: 2.907433459293489

Epoch: 6| Step: 10
Training loss: 3.1539122733794973
Validation loss: 2.9080991848249718

Epoch: 6| Step: 11
Training loss: 2.899603349591274
Validation loss: 2.907280351051225

Epoch: 6| Step: 12
Training loss: 3.2699312719652784
Validation loss: 2.9073531321719557

Epoch: 6| Step: 13
Training loss: 3.254967927320597
Validation loss: 2.9066537997079633

Epoch: 95| Step: 0
Training loss: 3.1604537918099695
Validation loss: 2.9136529177339834

Epoch: 6| Step: 1
Training loss: 3.12486266788082
Validation loss: 2.9138824804052375

Epoch: 6| Step: 2
Training loss: 2.72333000526863
Validation loss: 2.913189888074333

Epoch: 6| Step: 3
Training loss: 3.2416941807485515
Validation loss: 2.9156935854357315

Epoch: 6| Step: 4
Training loss: 2.3951389356862443
Validation loss: 2.9170427815279374

Epoch: 6| Step: 5
Training loss: 3.5376566606211943
Validation loss: 2.9094746166532266

Epoch: 6| Step: 6
Training loss: 3.1763514608596566
Validation loss: 2.906706146246547

Epoch: 6| Step: 7
Training loss: 3.055754882399135
Validation loss: 2.9076862118647626

Epoch: 6| Step: 8
Training loss: 2.946634254047153
Validation loss: 2.908192812955059

Epoch: 6| Step: 9
Training loss: 3.9849811167730267
Validation loss: 2.9039582050496433

Epoch: 6| Step: 10
Training loss: 3.6312035720142006
Validation loss: 2.90704386464217

Epoch: 6| Step: 11
Training loss: 3.8018178908125444
Validation loss: 2.905203982224695

Epoch: 6| Step: 12
Training loss: 2.415945263318344
Validation loss: 2.9037255561192503

Epoch: 6| Step: 13
Training loss: 3.2591656772186433
Validation loss: 2.904075532418616

Epoch: 96| Step: 0
Training loss: 2.9566021183312112
Validation loss: 2.9050274837016214

Epoch: 6| Step: 1
Training loss: 3.086765303824305
Validation loss: 2.904919926310367

Epoch: 6| Step: 2
Training loss: 3.07645708003268
Validation loss: 2.903350716784161

Epoch: 6| Step: 3
Training loss: 3.504902675654219
Validation loss: 2.901460308340407

Epoch: 6| Step: 4
Training loss: 2.8991069997283687
Validation loss: 2.90052150567607

Epoch: 6| Step: 5
Training loss: 2.9136962660486994
Validation loss: 2.9054243608863164

Epoch: 6| Step: 6
Training loss: 3.0134593718115865
Validation loss: 2.9026503255195353

Epoch: 6| Step: 7
Training loss: 3.5006346808314825
Validation loss: 2.897021884479585

Epoch: 6| Step: 8
Training loss: 2.5092639941298183
Validation loss: 2.8983371448471145

Epoch: 6| Step: 9
Training loss: 3.7942626506199657
Validation loss: 2.8988025540315747

Epoch: 6| Step: 10
Training loss: 3.426240548778749
Validation loss: 2.899736361105788

Epoch: 6| Step: 11
Training loss: 3.245164207923716
Validation loss: 2.903191526300593

Epoch: 6| Step: 12
Training loss: 2.8299635501307008
Validation loss: 2.900890205364706

Epoch: 6| Step: 13
Training loss: 4.024509916619628
Validation loss: 2.9036042626762617

Epoch: 97| Step: 0
Training loss: 2.818426542479687
Validation loss: 2.903395405638631

Epoch: 6| Step: 1
Training loss: 2.952905071485715
Validation loss: 2.910529080139777

Epoch: 6| Step: 2
Training loss: 2.9370563253184745
Validation loss: 2.914083561090841

Epoch: 6| Step: 3
Training loss: 3.212042773768366
Validation loss: 2.9243659070580623

Epoch: 6| Step: 4
Training loss: 3.146974588161257
Validation loss: 2.917787758908234

Epoch: 6| Step: 5
Training loss: 2.351577809432879
Validation loss: 2.9121890585870993

Epoch: 6| Step: 6
Training loss: 3.5923124672423317
Validation loss: 2.905715311002518

Epoch: 6| Step: 7
Training loss: 3.139302141185965
Validation loss: 2.8996799783223075

Epoch: 6| Step: 8
Training loss: 3.4312882218029985
Validation loss: 2.898879909646613

Epoch: 6| Step: 9
Training loss: 3.6414558215757995
Validation loss: 2.901338253957377

Epoch: 6| Step: 10
Training loss: 3.6920870682936013
Validation loss: 2.8966355067412977

Epoch: 6| Step: 11
Training loss: 2.8095784589949675
Validation loss: 2.8974023143482315

Epoch: 6| Step: 12
Training loss: 3.595538946295959
Validation loss: 2.8947184085087296

Epoch: 6| Step: 13
Training loss: 2.868755525072549
Validation loss: 2.8971083012088874

Epoch: 98| Step: 0
Training loss: 2.9956573208251767
Validation loss: 2.89696652849166

Epoch: 6| Step: 1
Training loss: 3.7156792793127162
Validation loss: 2.898551471445051

Epoch: 6| Step: 2
Training loss: 2.784098591555044
Validation loss: 2.9013455534194854

Epoch: 6| Step: 3
Training loss: 3.133435422843959
Validation loss: 2.9011499292617677

Epoch: 6| Step: 4
Training loss: 3.281479455100337
Validation loss: 2.905897552469839

Epoch: 6| Step: 5
Training loss: 3.1969710618070564
Validation loss: 2.9025245824038555

Epoch: 6| Step: 6
Training loss: 3.2779710644416014
Validation loss: 2.905315214873395

Epoch: 6| Step: 7
Training loss: 3.4658031146111066
Validation loss: 2.898063890100888

Epoch: 6| Step: 8
Training loss: 3.474922942260861
Validation loss: 2.8987236221148343

Epoch: 6| Step: 9
Training loss: 2.94066319699264
Validation loss: 2.894571045289549

Epoch: 6| Step: 10
Training loss: 2.867878594120615
Validation loss: 2.892503635563284

Epoch: 6| Step: 11
Training loss: 2.634387351806934
Validation loss: 2.8946666573209296

Epoch: 6| Step: 12
Training loss: 3.419041963206505
Validation loss: 2.8939074653628123

Epoch: 6| Step: 13
Training loss: 3.4652369124543325
Validation loss: 2.8931888800404164

Epoch: 99| Step: 0
Training loss: 3.006125712849121
Validation loss: 2.8889828696699587

Epoch: 6| Step: 1
Training loss: 2.8804448854364684
Validation loss: 2.8890981342708257

Epoch: 6| Step: 2
Training loss: 3.4739275258465
Validation loss: 2.891331933382897

Epoch: 6| Step: 3
Training loss: 3.754983642176772
Validation loss: 2.8880531299390837

Epoch: 6| Step: 4
Training loss: 3.4332907133944635
Validation loss: 2.8903489982986965

Epoch: 6| Step: 5
Training loss: 3.584715790915054
Validation loss: 2.8919118529454555

Epoch: 6| Step: 6
Training loss: 2.9339110181300128
Validation loss: 2.887018586162878

Epoch: 6| Step: 7
Training loss: 3.743515639062402
Validation loss: 2.8944519093207104

Epoch: 6| Step: 8
Training loss: 2.469412606082586
Validation loss: 2.896900743983676

Epoch: 6| Step: 9
Training loss: 3.6151920359402867
Validation loss: 2.894740820097571

Epoch: 6| Step: 10
Training loss: 2.445334437457757
Validation loss: 2.8955168381057312

Epoch: 6| Step: 11
Training loss: 2.737626937640486
Validation loss: 2.8865813730035184

Epoch: 6| Step: 12
Training loss: 3.3698532987183305
Validation loss: 2.88867607455578

Epoch: 6| Step: 13
Training loss: 2.041356225318712
Validation loss: 2.8943887629306766

Epoch: 100| Step: 0
Training loss: 3.2859263203603506
Validation loss: 2.892768313144817

Epoch: 6| Step: 1
Training loss: 3.5544903040254776
Validation loss: 2.892545137386729

Epoch: 6| Step: 2
Training loss: 3.8466185743828447
Validation loss: 2.902168814201991

Epoch: 6| Step: 3
Training loss: 2.8372732332337
Validation loss: 2.892615598543162

Epoch: 6| Step: 4
Training loss: 3.2829559251265072
Validation loss: 2.8916937903361246

Epoch: 6| Step: 5
Training loss: 3.077443623526099
Validation loss: 2.90648248567155

Epoch: 6| Step: 6
Training loss: 3.0320785805778234
Validation loss: 2.8919809555106086

Epoch: 6| Step: 7
Training loss: 3.0670891456944513
Validation loss: 2.8930598156308207

Epoch: 6| Step: 8
Training loss: 3.1122824719261253
Validation loss: 2.885943011639442

Epoch: 6| Step: 9
Training loss: 3.2137680757089178
Validation loss: 2.884606062982105

Epoch: 6| Step: 10
Training loss: 3.5298983257229106
Validation loss: 2.890315616262065

Epoch: 6| Step: 11
Training loss: 3.044239802184704
Validation loss: 2.887689277359389

Epoch: 6| Step: 12
Training loss: 2.529307620935184
Validation loss: 2.8820265285364637

Epoch: 6| Step: 13
Training loss: 2.6404729494639
Validation loss: 2.8779067699681637

Testing loss: 3.081399806234556
