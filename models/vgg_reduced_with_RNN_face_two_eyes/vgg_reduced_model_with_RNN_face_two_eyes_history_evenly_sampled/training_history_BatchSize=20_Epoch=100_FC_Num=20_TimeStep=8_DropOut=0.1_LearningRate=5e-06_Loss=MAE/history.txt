Epoch: 1| Step: 0
Training loss: 4.555439472198486
Validation loss: 5.1123792740606495

Epoch: 5| Step: 1
Training loss: 4.770382881164551
Validation loss: 5.107633154879334

Epoch: 5| Step: 2
Training loss: 4.016347885131836
Validation loss: 5.103330325054866

Epoch: 5| Step: 3
Training loss: 5.369660377502441
Validation loss: 5.098729077205863

Epoch: 5| Step: 4
Training loss: 5.6346282958984375
Validation loss: 5.094590571618849

Epoch: 5| Step: 5
Training loss: 4.70281982421875
Validation loss: 5.090180586743099

Epoch: 5| Step: 6
Training loss: 4.714652061462402
Validation loss: 5.085912991595524

Epoch: 5| Step: 7
Training loss: 4.739288330078125
Validation loss: 5.081857819711009

Epoch: 5| Step: 8
Training loss: 5.266610145568848
Validation loss: 5.076988491960751

Epoch: 5| Step: 9
Training loss: 4.351191520690918
Validation loss: 5.07264909949354

Epoch: 5| Step: 10
Training loss: 5.767698764801025
Validation loss: 5.068101001042192

Epoch: 2| Step: 0
Training loss: 5.732222557067871
Validation loss: 5.063350036580076

Epoch: 5| Step: 1
Training loss: 4.3411993980407715
Validation loss: 5.058832071160757

Epoch: 5| Step: 2
Training loss: 4.90918493270874
Validation loss: 5.053681481269098

Epoch: 5| Step: 3
Training loss: 4.057525157928467
Validation loss: 5.048492336785921

Epoch: 5| Step: 4
Training loss: 5.026933193206787
Validation loss: 5.04347098770962

Epoch: 5| Step: 5
Training loss: 5.077418327331543
Validation loss: 5.038099345340524

Epoch: 5| Step: 6
Training loss: 4.235333442687988
Validation loss: 5.032436432376985

Epoch: 5| Step: 7
Training loss: 5.151595115661621
Validation loss: 5.026525482054679

Epoch: 5| Step: 8
Training loss: 3.3866779804229736
Validation loss: 5.020569114274876

Epoch: 5| Step: 9
Training loss: 5.22581148147583
Validation loss: 5.0139724003371375

Epoch: 5| Step: 10
Training loss: 6.240796089172363
Validation loss: 5.007536149794055

Epoch: 3| Step: 0
Training loss: 4.0790696144104
Validation loss: 5.000687030053908

Epoch: 5| Step: 1
Training loss: 5.055377006530762
Validation loss: 4.9939134505487255

Epoch: 5| Step: 2
Training loss: 5.756166934967041
Validation loss: 4.985932416813348

Epoch: 5| Step: 3
Training loss: 5.021804332733154
Validation loss: 4.977839664746356

Epoch: 5| Step: 4
Training loss: 4.907273769378662
Validation loss: 4.969672326118715

Epoch: 5| Step: 5
Training loss: 3.5352001190185547
Validation loss: 4.960970324854697

Epoch: 5| Step: 6
Training loss: 5.046998023986816
Validation loss: 4.95211983752507

Epoch: 5| Step: 7
Training loss: 3.9357693195343018
Validation loss: 4.942551115507721

Epoch: 5| Step: 8
Training loss: 5.222325801849365
Validation loss: 4.9318838350234495

Epoch: 5| Step: 9
Training loss: 4.670213222503662
Validation loss: 4.921308968656806

Epoch: 5| Step: 10
Training loss: 5.100833415985107
Validation loss: 4.910478335554882

Epoch: 4| Step: 0
Training loss: 4.782092094421387
Validation loss: 4.89872375611336

Epoch: 5| Step: 1
Training loss: 4.964998722076416
Validation loss: 4.885349704373267

Epoch: 5| Step: 2
Training loss: 4.269593238830566
Validation loss: 4.872490482945596

Epoch: 5| Step: 3
Training loss: 4.52416467666626
Validation loss: 4.85950017744495

Epoch: 5| Step: 4
Training loss: 5.046680450439453
Validation loss: 4.844367396446966

Epoch: 5| Step: 5
Training loss: 5.706357002258301
Validation loss: 4.828692000399354

Epoch: 5| Step: 6
Training loss: 4.916839599609375
Validation loss: 4.813700117090697

Epoch: 5| Step: 7
Training loss: 4.2456560134887695
Validation loss: 4.796814554481096

Epoch: 5| Step: 8
Training loss: 3.1888718605041504
Validation loss: 4.779507278114237

Epoch: 5| Step: 9
Training loss: 4.93192195892334
Validation loss: 4.760371585046092

Epoch: 5| Step: 10
Training loss: 4.094357013702393
Validation loss: 4.741984500679918

Epoch: 5| Step: 0
Training loss: 5.2670722007751465
Validation loss: 4.721889424067672

Epoch: 5| Step: 1
Training loss: 4.02089786529541
Validation loss: 4.7021134232962005

Epoch: 5| Step: 2
Training loss: 4.122491359710693
Validation loss: 4.681195556476552

Epoch: 5| Step: 3
Training loss: 4.38828706741333
Validation loss: 4.660286570108065

Epoch: 5| Step: 4
Training loss: 5.053290367126465
Validation loss: 4.638209686484388

Epoch: 5| Step: 5
Training loss: 4.58352518081665
Validation loss: 4.6149179884182505

Epoch: 5| Step: 6
Training loss: 4.948351860046387
Validation loss: 4.5927085415009525

Epoch: 5| Step: 7
Training loss: 4.482544898986816
Validation loss: 4.569316992195704

Epoch: 5| Step: 8
Training loss: 3.774275302886963
Validation loss: 4.544061368511569

Epoch: 5| Step: 9
Training loss: 3.88214373588562
Validation loss: 4.520136366608322

Epoch: 5| Step: 10
Training loss: 3.740527868270874
Validation loss: 4.493812058561591

Epoch: 6| Step: 0
Training loss: 4.495591163635254
Validation loss: 4.46864935146865

Epoch: 5| Step: 1
Training loss: 3.6453452110290527
Validation loss: 4.4438074788739605

Epoch: 5| Step: 2
Training loss: 4.680975914001465
Validation loss: 4.4183120881357505

Epoch: 5| Step: 3
Training loss: 4.177528381347656
Validation loss: 4.39427573193786

Epoch: 5| Step: 4
Training loss: 3.568316698074341
Validation loss: 4.370544341302687

Epoch: 5| Step: 5
Training loss: 5.059255123138428
Validation loss: 4.347695801847724

Epoch: 5| Step: 6
Training loss: 4.070097923278809
Validation loss: 4.324623056637344

Epoch: 5| Step: 7
Training loss: 4.710646629333496
Validation loss: 4.303017675235707

Epoch: 5| Step: 8
Training loss: 3.002715587615967
Validation loss: 4.281424317308652

Epoch: 5| Step: 9
Training loss: 4.939862251281738
Validation loss: 4.260030577259679

Epoch: 5| Step: 10
Training loss: 3.0712311267852783
Validation loss: 4.238609390874063

Epoch: 7| Step: 0
Training loss: 3.327868700027466
Validation loss: 4.220077509521156

Epoch: 5| Step: 1
Training loss: 4.162631511688232
Validation loss: 4.200323504786337

Epoch: 5| Step: 2
Training loss: 3.251345157623291
Validation loss: 4.182213101335751

Epoch: 5| Step: 3
Training loss: 4.300993919372559
Validation loss: 4.162776990603375

Epoch: 5| Step: 4
Training loss: 3.6345977783203125
Validation loss: 4.145816241541216

Epoch: 5| Step: 5
Training loss: 3.9571661949157715
Validation loss: 4.128175817510133

Epoch: 5| Step: 6
Training loss: 3.538867235183716
Validation loss: 4.10823086256622

Epoch: 5| Step: 7
Training loss: 3.0576183795928955
Validation loss: 4.091369269996561

Epoch: 5| Step: 8
Training loss: 4.884577751159668
Validation loss: 4.073696515893423

Epoch: 5| Step: 9
Training loss: 4.3138251304626465
Validation loss: 4.05859649309548

Epoch: 5| Step: 10
Training loss: 5.226491451263428
Validation loss: 4.041113484290339

Epoch: 8| Step: 0
Training loss: 3.8685615062713623
Validation loss: 4.02733467214851

Epoch: 5| Step: 1
Training loss: 4.337735176086426
Validation loss: 4.01027605097781

Epoch: 5| Step: 2
Training loss: 3.684690475463867
Validation loss: 3.993363316341113

Epoch: 5| Step: 3
Training loss: 3.4459407329559326
Validation loss: 3.9762342847803587

Epoch: 5| Step: 4
Training loss: 3.6974430084228516
Validation loss: 3.95878271133669

Epoch: 5| Step: 5
Training loss: 2.620683193206787
Validation loss: 3.938641478938441

Epoch: 5| Step: 6
Training loss: 3.0501725673675537
Validation loss: 3.920989533906342

Epoch: 5| Step: 7
Training loss: 4.949583530426025
Validation loss: 3.9025639231486986

Epoch: 5| Step: 8
Training loss: 3.976041316986084
Validation loss: 3.8904348650286273

Epoch: 5| Step: 9
Training loss: 4.3931684494018555
Validation loss: 3.8735215228091002

Epoch: 5| Step: 10
Training loss: 3.6995837688446045
Validation loss: 3.8606011918796006

Epoch: 9| Step: 0
Training loss: 3.3597846031188965
Validation loss: 3.8435646769821004

Epoch: 5| Step: 1
Training loss: 4.0440497398376465
Validation loss: 3.8288390944080968

Epoch: 5| Step: 2
Training loss: 4.099678039550781
Validation loss: 3.812601104859383

Epoch: 5| Step: 3
Training loss: 2.781468391418457
Validation loss: 3.7973963470869165

Epoch: 5| Step: 4
Training loss: 3.3351974487304688
Validation loss: 3.784194266924294

Epoch: 5| Step: 5
Training loss: 3.6933486461639404
Validation loss: 3.7702704706499652

Epoch: 5| Step: 6
Training loss: 3.058802843093872
Validation loss: 3.753500717942433

Epoch: 5| Step: 7
Training loss: 4.114874839782715
Validation loss: 3.738129705511114

Epoch: 5| Step: 8
Training loss: 3.962839126586914
Validation loss: 3.7244666673803843

Epoch: 5| Step: 9
Training loss: 4.313405513763428
Validation loss: 3.706632332135272

Epoch: 5| Step: 10
Training loss: 3.44642972946167
Validation loss: 3.6921543511011268

Epoch: 10| Step: 0
Training loss: 3.157539129257202
Validation loss: 3.680922354421308

Epoch: 5| Step: 1
Training loss: 3.848606824874878
Validation loss: 3.664617605106805

Epoch: 5| Step: 2
Training loss: 4.13134241104126
Validation loss: 3.6576701851301294

Epoch: 5| Step: 3
Training loss: 3.4570415019989014
Validation loss: 3.6401356625300583

Epoch: 5| Step: 4
Training loss: 1.6689040660858154
Validation loss: 3.628641338758571

Epoch: 5| Step: 5
Training loss: 3.9370312690734863
Validation loss: 3.6156102098444456

Epoch: 5| Step: 6
Training loss: 3.9271023273468018
Validation loss: 3.605492412403066

Epoch: 5| Step: 7
Training loss: 3.698359727859497
Validation loss: 3.595672256203108

Epoch: 5| Step: 8
Training loss: 3.0491645336151123
Validation loss: 3.58165475373627

Epoch: 5| Step: 9
Training loss: 4.111722946166992
Validation loss: 3.5715830095352663

Epoch: 5| Step: 10
Training loss: 3.8624918460845947
Validation loss: 3.55817384617303

Epoch: 11| Step: 0
Training loss: 3.0321996212005615
Validation loss: 3.552379213353639

Epoch: 5| Step: 1
Training loss: 2.9060144424438477
Validation loss: 3.542802110795052

Epoch: 5| Step: 2
Training loss: 3.152117967605591
Validation loss: 3.5279853113235964

Epoch: 5| Step: 3
Training loss: 3.9391162395477295
Validation loss: 3.5171321899660173

Epoch: 5| Step: 4
Training loss: 3.5726935863494873
Validation loss: 3.506773482086838

Epoch: 5| Step: 5
Training loss: 3.7341887950897217
Validation loss: 3.498880781153197

Epoch: 5| Step: 6
Training loss: 2.830111503601074
Validation loss: 3.4892914859197472

Epoch: 5| Step: 7
Training loss: 4.406153202056885
Validation loss: 3.4830742343779533

Epoch: 5| Step: 8
Training loss: 3.5910086631774902
Validation loss: 3.4685427655455885

Epoch: 5| Step: 9
Training loss: 3.18469500541687
Validation loss: 3.4605988789630193

Epoch: 5| Step: 10
Training loss: 3.3856284618377686
Validation loss: 3.4549952706983014

Epoch: 12| Step: 0
Training loss: 4.422417163848877
Validation loss: 3.4408124518650833

Epoch: 5| Step: 1
Training loss: 3.4531331062316895
Validation loss: 3.43248261174848

Epoch: 5| Step: 2
Training loss: 3.672717332839966
Validation loss: 3.4212005651125343

Epoch: 5| Step: 3
Training loss: 4.212955951690674
Validation loss: 3.4144469025314494

Epoch: 5| Step: 4
Training loss: 3.7258827686309814
Validation loss: 3.403920712009553

Epoch: 5| Step: 5
Training loss: 3.0616893768310547
Validation loss: 3.3963723644133537

Epoch: 5| Step: 6
Training loss: 2.7618253231048584
Validation loss: 3.3903632240910686

Epoch: 5| Step: 7
Training loss: 3.239966869354248
Validation loss: 3.3869985816299275

Epoch: 5| Step: 8
Training loss: 2.1689324378967285
Validation loss: 3.3774120243646766

Epoch: 5| Step: 9
Training loss: 2.6045567989349365
Validation loss: 3.372043830092235

Epoch: 5| Step: 10
Training loss: 3.5692708492279053
Validation loss: 3.3630954885995514

Epoch: 13| Step: 0
Training loss: 3.7595810890197754
Validation loss: 3.359019289734543

Epoch: 5| Step: 1
Training loss: 2.8618783950805664
Validation loss: 3.3536796954370316

Epoch: 5| Step: 2
Training loss: 2.877133846282959
Validation loss: 3.351716472256568

Epoch: 5| Step: 3
Training loss: 3.754688262939453
Validation loss: 3.3423376057737615

Epoch: 5| Step: 4
Training loss: 2.760044574737549
Validation loss: 3.337603615176293

Epoch: 5| Step: 5
Training loss: 2.562147855758667
Validation loss: 3.333731269323698

Epoch: 5| Step: 6
Training loss: 3.839087724685669
Validation loss: 3.3304554185559674

Epoch: 5| Step: 7
Training loss: 3.292558193206787
Validation loss: 3.319348668539396

Epoch: 5| Step: 8
Training loss: 3.5916240215301514
Validation loss: 3.3202992126505864

Epoch: 5| Step: 9
Training loss: 3.963618516921997
Validation loss: 3.3234582818964475

Epoch: 5| Step: 10
Training loss: 2.9149346351623535
Validation loss: 3.3104886624120895

Epoch: 14| Step: 0
Training loss: 3.315106153488159
Validation loss: 3.3025960383876676

Epoch: 5| Step: 1
Training loss: 3.3245856761932373
Validation loss: 3.300375066777711

Epoch: 5| Step: 2
Training loss: 2.7497379779815674
Validation loss: 3.297865390777588

Epoch: 5| Step: 3
Training loss: 3.708770751953125
Validation loss: 3.295821112971152

Epoch: 5| Step: 4
Training loss: 4.268669128417969
Validation loss: 3.293937801032938

Epoch: 5| Step: 5
Training loss: 3.008239269256592
Validation loss: 3.290921357370192

Epoch: 5| Step: 6
Training loss: 3.5380470752716064
Validation loss: 3.283195836569673

Epoch: 5| Step: 7
Training loss: 3.041764497756958
Validation loss: 3.275908198407901

Epoch: 5| Step: 8
Training loss: 3.065377712249756
Validation loss: 3.27315273592549

Epoch: 5| Step: 9
Training loss: 2.8426666259765625
Validation loss: 3.268273691977224

Epoch: 5| Step: 10
Training loss: 2.9245471954345703
Validation loss: 3.268438705834009

Epoch: 15| Step: 0
Training loss: 3.039726734161377
Validation loss: 3.2684967979308097

Epoch: 5| Step: 1
Training loss: 3.9757609367370605
Validation loss: 3.2672690781213904

Epoch: 5| Step: 2
Training loss: 2.884347915649414
Validation loss: 3.2592058566308792

Epoch: 5| Step: 3
Training loss: 2.1903882026672363
Validation loss: 3.25006805440431

Epoch: 5| Step: 4
Training loss: 3.257329225540161
Validation loss: 3.249570236411146

Epoch: 5| Step: 5
Training loss: 3.219203472137451
Validation loss: 3.245922642369424

Epoch: 5| Step: 6
Training loss: 3.3828139305114746
Validation loss: 3.2478128094826975

Epoch: 5| Step: 7
Training loss: 4.212191581726074
Validation loss: 3.2411263706863567

Epoch: 5| Step: 8
Training loss: 2.315127372741699
Validation loss: 3.2389772553597727

Epoch: 5| Step: 9
Training loss: 3.3295235633850098
Validation loss: 3.233372252474549

Epoch: 5| Step: 10
Training loss: 3.7695913314819336
Validation loss: 3.230861889418735

Epoch: 16| Step: 0
Training loss: 2.7674994468688965
Validation loss: 3.226610904098839

Epoch: 5| Step: 1
Training loss: 4.112524032592773
Validation loss: 3.2235279493434454

Epoch: 5| Step: 2
Training loss: 3.4494431018829346
Validation loss: 3.220747806692636

Epoch: 5| Step: 3
Training loss: 3.290827989578247
Validation loss: 3.217871727481965

Epoch: 5| Step: 4
Training loss: 2.2975640296936035
Validation loss: 3.2207756555208595

Epoch: 5| Step: 5
Training loss: 3.6701011657714844
Validation loss: 3.212537165611021

Epoch: 5| Step: 6
Training loss: 3.2813308238983154
Validation loss: 3.2144649541506203

Epoch: 5| Step: 7
Training loss: 3.238457202911377
Validation loss: 3.2077732419454925

Epoch: 5| Step: 8
Training loss: 3.8961777687072754
Validation loss: 3.204900469831241

Epoch: 5| Step: 9
Training loss: 2.947913646697998
Validation loss: 3.201029610890214

Epoch: 5| Step: 10
Training loss: 2.124372959136963
Validation loss: 3.1974625177280878

Epoch: 17| Step: 0
Training loss: 3.405951976776123
Validation loss: 3.1944882792811238

Epoch: 5| Step: 1
Training loss: 3.068845272064209
Validation loss: 3.1939747205344577

Epoch: 5| Step: 2
Training loss: 2.796016216278076
Validation loss: 3.1881152276069886

Epoch: 5| Step: 3
Training loss: 2.5988292694091797
Validation loss: 3.186829302900581

Epoch: 5| Step: 4
Training loss: 3.7855591773986816
Validation loss: 3.180916986157817

Epoch: 5| Step: 5
Training loss: 3.7662353515625
Validation loss: 3.1819846348095964

Epoch: 5| Step: 6
Training loss: 3.570394992828369
Validation loss: 3.176646870951499

Epoch: 5| Step: 7
Training loss: 3.0960874557495117
Validation loss: 3.1768777498634915

Epoch: 5| Step: 8
Training loss: 3.097275972366333
Validation loss: 3.1736130355506815

Epoch: 5| Step: 9
Training loss: 3.0585408210754395
Validation loss: 3.1739065493306806

Epoch: 5| Step: 10
Training loss: 2.6642513275146484
Validation loss: 3.167008581981864

Epoch: 18| Step: 0
Training loss: 3.2973830699920654
Validation loss: 3.1660952286053727

Epoch: 5| Step: 1
Training loss: 2.841203212738037
Validation loss: 3.163405833705779

Epoch: 5| Step: 2
Training loss: 1.981956124305725
Validation loss: 3.15955420976044

Epoch: 5| Step: 3
Training loss: 2.84031343460083
Validation loss: 3.1590347136220625

Epoch: 5| Step: 4
Training loss: 2.9537320137023926
Validation loss: 3.1509565025247555

Epoch: 5| Step: 5
Training loss: 2.7458090782165527
Validation loss: 3.1512914011555333

Epoch: 5| Step: 6
Training loss: 3.7749266624450684
Validation loss: 3.147686912167457

Epoch: 5| Step: 7
Training loss: 3.0357751846313477
Validation loss: 3.1498032487848753

Epoch: 5| Step: 8
Training loss: 4.094988822937012
Validation loss: 3.144745421665971

Epoch: 5| Step: 9
Training loss: 3.854996919631958
Validation loss: 3.1494172029597785

Epoch: 5| Step: 10
Training loss: 3.364492893218994
Validation loss: 3.1451391225220053

Epoch: 19| Step: 0
Training loss: 3.423614025115967
Validation loss: 3.1371302091947166

Epoch: 5| Step: 1
Training loss: 3.3930721282958984
Validation loss: 3.136833903610065

Epoch: 5| Step: 2
Training loss: 3.517859935760498
Validation loss: 3.1337547122791247

Epoch: 5| Step: 3
Training loss: 2.678877353668213
Validation loss: 3.1273205844304894

Epoch: 5| Step: 4
Training loss: 2.660478115081787
Validation loss: 3.127634576571885

Epoch: 5| Step: 5
Training loss: 3.3911819458007812
Validation loss: 3.1253652008630897

Epoch: 5| Step: 6
Training loss: 2.370710849761963
Validation loss: 3.118923294928766

Epoch: 5| Step: 7
Training loss: 3.5175158977508545
Validation loss: 3.120990591664468

Epoch: 5| Step: 8
Training loss: 3.1592555046081543
Validation loss: 3.1120950534779537

Epoch: 5| Step: 9
Training loss: 2.7977988719940186
Validation loss: 3.1110283738823346

Epoch: 5| Step: 10
Training loss: 3.736051559448242
Validation loss: 3.10777985665106

Epoch: 20| Step: 0
Training loss: 2.1613457202911377
Validation loss: 3.1095402599662862

Epoch: 5| Step: 1
Training loss: 3.2303199768066406
Validation loss: 3.105925411306402

Epoch: 5| Step: 2
Training loss: 3.836225986480713
Validation loss: 3.108119087834512

Epoch: 5| Step: 3
Training loss: 3.0964717864990234
Validation loss: 3.1057491097398984

Epoch: 5| Step: 4
Training loss: 2.561708927154541
Validation loss: 3.105108291872086

Epoch: 5| Step: 5
Training loss: 2.7652878761291504
Validation loss: 3.0999772292311474

Epoch: 5| Step: 6
Training loss: 3.5143070220947266
Validation loss: 3.0926219827385357

Epoch: 5| Step: 7
Training loss: 2.8718104362487793
Validation loss: 3.090143311408258

Epoch: 5| Step: 8
Training loss: 4.156423568725586
Validation loss: 3.086137148641771

Epoch: 5| Step: 9
Training loss: 3.2774930000305176
Validation loss: 3.0873542395971154

Epoch: 5| Step: 10
Training loss: 2.881999969482422
Validation loss: 3.0839890767169256

Epoch: 21| Step: 0
Training loss: 2.8153510093688965
Validation loss: 3.0860181059888614

Epoch: 5| Step: 1
Training loss: 2.929978609085083
Validation loss: 3.081266967199182

Epoch: 5| Step: 2
Training loss: 3.0708510875701904
Validation loss: 3.0817966794454925

Epoch: 5| Step: 3
Training loss: 2.6660189628601074
Validation loss: 3.07544114769146

Epoch: 5| Step: 4
Training loss: 3.8639073371887207
Validation loss: 3.073066862680579

Epoch: 5| Step: 5
Training loss: 3.152334690093994
Validation loss: 3.0731889817022506

Epoch: 5| Step: 6
Training loss: 2.765876293182373
Validation loss: 3.070682023161201

Epoch: 5| Step: 7
Training loss: 3.4194235801696777
Validation loss: 3.0667402641747588

Epoch: 5| Step: 8
Training loss: 2.823132276535034
Validation loss: 3.0650602156116116

Epoch: 5| Step: 9
Training loss: 2.7588257789611816
Validation loss: 3.063607382517989

Epoch: 5| Step: 10
Training loss: 4.083924770355225
Validation loss: 3.0623386931675736

Epoch: 22| Step: 0
Training loss: 2.9943506717681885
Validation loss: 3.060079138766053

Epoch: 5| Step: 1
Training loss: 3.5562236309051514
Validation loss: 3.0652200073324223

Epoch: 5| Step: 2
Training loss: 3.758624315261841
Validation loss: 3.058699248939432

Epoch: 5| Step: 3
Training loss: 2.924064874649048
Validation loss: 3.057938365526097

Epoch: 5| Step: 4
Training loss: 2.687328577041626
Validation loss: 3.0527754881048716

Epoch: 5| Step: 5
Training loss: 2.4381508827209473
Validation loss: 3.053325827403735

Epoch: 5| Step: 6
Training loss: 3.1768105030059814
Validation loss: 3.049640752935922

Epoch: 5| Step: 7
Training loss: 2.6664175987243652
Validation loss: 3.0476065963827152

Epoch: 5| Step: 8
Training loss: 3.2889742851257324
Validation loss: 3.042301821452315

Epoch: 5| Step: 9
Training loss: 3.4206840991973877
Validation loss: 3.0397191073304866

Epoch: 5| Step: 10
Training loss: 3.0970187187194824
Validation loss: 3.03834790824562

Epoch: 23| Step: 0
Training loss: 3.2071526050567627
Validation loss: 3.0396908611379643

Epoch: 5| Step: 1
Training loss: 2.026319980621338
Validation loss: 3.0371094826729066

Epoch: 5| Step: 2
Training loss: 3.049522876739502
Validation loss: 3.0420844554901123

Epoch: 5| Step: 3
Training loss: 3.1519694328308105
Validation loss: 3.050097132241854

Epoch: 5| Step: 4
Training loss: 3.803213596343994
Validation loss: 3.0364469456416305

Epoch: 5| Step: 5
Training loss: 2.6446075439453125
Validation loss: 3.0269478187766126

Epoch: 5| Step: 6
Training loss: 2.608062267303467
Validation loss: 3.0210846444611907

Epoch: 5| Step: 7
Training loss: 3.6077492237091064
Validation loss: 3.02187543530618

Epoch: 5| Step: 8
Training loss: 3.0121006965637207
Validation loss: 3.0216266826916764

Epoch: 5| Step: 9
Training loss: 3.482119083404541
Validation loss: 3.0185819851454867

Epoch: 5| Step: 10
Training loss: 3.2911829948425293
Validation loss: 3.019254522938882

Epoch: 24| Step: 0
Training loss: 3.0447216033935547
Validation loss: 3.0162503975693897

Epoch: 5| Step: 1
Training loss: 3.0051321983337402
Validation loss: 3.0154141815759803

Epoch: 5| Step: 2
Training loss: 2.195030689239502
Validation loss: 3.0130797765588246

Epoch: 5| Step: 3
Training loss: 3.638042449951172
Validation loss: 3.010702999689246

Epoch: 5| Step: 4
Training loss: 3.2417571544647217
Validation loss: 3.006005935771491

Epoch: 5| Step: 5
Training loss: 3.0077528953552246
Validation loss: 3.005455740036503

Epoch: 5| Step: 6
Training loss: 2.662815570831299
Validation loss: 3.008971909041046

Epoch: 5| Step: 7
Training loss: 3.8359363079071045
Validation loss: 3.0062179155247186

Epoch: 5| Step: 8
Training loss: 3.021106243133545
Validation loss: 3.005788880009805

Epoch: 5| Step: 9
Training loss: 3.426647663116455
Validation loss: 3.004961936704574

Epoch: 5| Step: 10
Training loss: 2.580016851425171
Validation loss: 3.0054700425876084

Epoch: 25| Step: 0
Training loss: 3.113715887069702
Validation loss: 2.9936829561828286

Epoch: 5| Step: 1
Training loss: 2.4439809322357178
Validation loss: 2.9914840498278217

Epoch: 5| Step: 2
Training loss: 3.510394334793091
Validation loss: 2.9940359079709618

Epoch: 5| Step: 3
Training loss: 2.839256763458252
Validation loss: 2.9927404131940616

Epoch: 5| Step: 4
Training loss: 3.2598977088928223
Validation loss: 2.9926576511834257

Epoch: 5| Step: 5
Training loss: 2.5276472568511963
Validation loss: 2.996313738566573

Epoch: 5| Step: 6
Training loss: 2.6640923023223877
Validation loss: 2.995912149388303

Epoch: 5| Step: 7
Training loss: 3.9425418376922607
Validation loss: 2.994997127081758

Epoch: 5| Step: 8
Training loss: 3.1524481773376465
Validation loss: 2.989374486348962

Epoch: 5| Step: 9
Training loss: 3.165092706680298
Validation loss: 2.9834399146418416

Epoch: 5| Step: 10
Training loss: 2.971994161605835
Validation loss: 2.9789371054659606

Epoch: 26| Step: 0
Training loss: 2.8628427982330322
Validation loss: 2.9760065360735823

Epoch: 5| Step: 1
Training loss: 3.7155470848083496
Validation loss: 2.9780248160003335

Epoch: 5| Step: 2
Training loss: 3.309119701385498
Validation loss: 2.9706373881268244

Epoch: 5| Step: 3
Training loss: 2.644369602203369
Validation loss: 2.9716198828912552

Epoch: 5| Step: 4
Training loss: 2.678117275238037
Validation loss: 2.968223617922875

Epoch: 5| Step: 5
Training loss: 3.0270824432373047
Validation loss: 2.971580889917189

Epoch: 5| Step: 6
Training loss: 3.3045783042907715
Validation loss: 2.9706096290260233

Epoch: 5| Step: 7
Training loss: 2.8240880966186523
Validation loss: 2.9666696722789476

Epoch: 5| Step: 8
Training loss: 2.6779284477233887
Validation loss: 2.9618264987904537

Epoch: 5| Step: 9
Training loss: 3.452007293701172
Validation loss: 2.961651602099019

Epoch: 5| Step: 10
Training loss: 2.8839662075042725
Validation loss: 2.9565483241952877

Epoch: 27| Step: 0
Training loss: 3.2911159992218018
Validation loss: 2.9538239407283005

Epoch: 5| Step: 1
Training loss: 3.1344614028930664
Validation loss: 2.956954143380606

Epoch: 5| Step: 2
Training loss: 3.359039783477783
Validation loss: 2.9594295409417923

Epoch: 5| Step: 3
Training loss: 2.9657673835754395
Validation loss: 2.954835519995741

Epoch: 5| Step: 4
Training loss: 2.818476915359497
Validation loss: 2.9544226841260026

Epoch: 5| Step: 5
Training loss: 3.2338314056396484
Validation loss: 2.9469611324289793

Epoch: 5| Step: 6
Training loss: 2.7177023887634277
Validation loss: 2.948479493459066

Epoch: 5| Step: 7
Training loss: 3.6618080139160156
Validation loss: 2.941564816300587

Epoch: 5| Step: 8
Training loss: 2.975706100463867
Validation loss: 2.942201460561445

Epoch: 5| Step: 9
Training loss: 2.211650848388672
Validation loss: 2.9403025052880727

Epoch: 5| Step: 10
Training loss: 2.8836114406585693
Validation loss: 2.9372490759818786

Epoch: 28| Step: 0
Training loss: 3.528904438018799
Validation loss: 2.9327687012251986

Epoch: 5| Step: 1
Training loss: 2.3901004791259766
Validation loss: 2.9301902940196376

Epoch: 5| Step: 2
Training loss: 2.7691407203674316
Validation loss: 2.9331192021728842

Epoch: 5| Step: 3
Training loss: 3.03568696975708
Validation loss: 2.9354818636371243

Epoch: 5| Step: 4
Training loss: 2.8383545875549316
Validation loss: 2.9264694772740847

Epoch: 5| Step: 5
Training loss: 3.1649363040924072
Validation loss: 2.9225706336318806

Epoch: 5| Step: 6
Training loss: 2.7800955772399902
Validation loss: 2.9194716202315463

Epoch: 5| Step: 7
Training loss: 2.846752643585205
Validation loss: 2.9193190169590775

Epoch: 5| Step: 8
Training loss: 3.4972445964813232
Validation loss: 2.9162258281502673

Epoch: 5| Step: 9
Training loss: 3.4600181579589844
Validation loss: 2.914213772742979

Epoch: 5| Step: 10
Training loss: 2.6818959712982178
Validation loss: 2.914235102233066

Epoch: 29| Step: 0
Training loss: 3.2056381702423096
Validation loss: 2.9108868824538363

Epoch: 5| Step: 1
Training loss: 2.675762414932251
Validation loss: 2.9161899346177296

Epoch: 5| Step: 2
Training loss: 3.2056496143341064
Validation loss: 2.909490264872069

Epoch: 5| Step: 3
Training loss: 2.2124688625335693
Validation loss: 2.910718371791224

Epoch: 5| Step: 4
Training loss: 3.2411468029022217
Validation loss: 2.9113322663050827

Epoch: 5| Step: 5
Training loss: 3.3748486042022705
Validation loss: 2.9074007721357447

Epoch: 5| Step: 6
Training loss: 2.9145164489746094
Validation loss: 2.8984796949612197

Epoch: 5| Step: 7
Training loss: 2.921025037765503
Validation loss: 2.89643165116669

Epoch: 5| Step: 8
Training loss: 3.2057437896728516
Validation loss: 2.8914198644699587

Epoch: 5| Step: 9
Training loss: 2.439754009246826
Validation loss: 2.8918978783392135

Epoch: 5| Step: 10
Training loss: 3.586866855621338
Validation loss: 2.8965155155427995

Epoch: 30| Step: 0
Training loss: 3.115354061126709
Validation loss: 2.898953830042193

Epoch: 5| Step: 1
Training loss: 2.7849812507629395
Validation loss: 2.887088075760872

Epoch: 5| Step: 2
Training loss: 3.212977886199951
Validation loss: 2.8877788923119985

Epoch: 5| Step: 3
Training loss: 2.840346097946167
Validation loss: 2.883549449264362

Epoch: 5| Step: 4
Training loss: 2.9861390590667725
Validation loss: 2.8797250178552445

Epoch: 5| Step: 5
Training loss: 3.4032490253448486
Validation loss: 2.876586098824778

Epoch: 5| Step: 6
Training loss: 2.295197010040283
Validation loss: 2.876297579016737

Epoch: 5| Step: 7
Training loss: 2.671034336090088
Validation loss: 2.874688930408929

Epoch: 5| Step: 8
Training loss: 4.025855541229248
Validation loss: 2.876768442892259

Epoch: 5| Step: 9
Training loss: 2.7060298919677734
Validation loss: 2.871888329905848

Epoch: 5| Step: 10
Training loss: 2.616943836212158
Validation loss: 2.8716178555642404

Epoch: 31| Step: 0
Training loss: 2.7763447761535645
Validation loss: 2.870842372217486

Epoch: 5| Step: 1
Training loss: 3.486870527267456
Validation loss: 2.8646762012153544

Epoch: 5| Step: 2
Training loss: 2.5845611095428467
Validation loss: 2.866337699274863

Epoch: 5| Step: 3
Training loss: 2.9248533248901367
Validation loss: 2.8583334697190153

Epoch: 5| Step: 4
Training loss: 2.9228615760803223
Validation loss: 2.8561172485351562

Epoch: 5| Step: 5
Training loss: 3.6257083415985107
Validation loss: 2.8559471125243814

Epoch: 5| Step: 6
Training loss: 3.1705713272094727
Validation loss: 2.8581311779637493

Epoch: 5| Step: 7
Training loss: 2.2309956550598145
Validation loss: 2.852779039772608

Epoch: 5| Step: 8
Training loss: 3.4151084423065186
Validation loss: 2.850768691749983

Epoch: 5| Step: 9
Training loss: 2.9031832218170166
Validation loss: 2.8488512859549573

Epoch: 5| Step: 10
Training loss: 2.4870102405548096
Validation loss: 2.846071107413179

Epoch: 32| Step: 0
Training loss: 3.53778338432312
Validation loss: 2.8441020622048327

Epoch: 5| Step: 1
Training loss: 2.17683744430542
Validation loss: 2.8444262576359574

Epoch: 5| Step: 2
Training loss: 3.8053085803985596
Validation loss: 2.849371269185056

Epoch: 5| Step: 3
Training loss: 3.066591739654541
Validation loss: 2.854896299300655

Epoch: 5| Step: 4
Training loss: 3.876178026199341
Validation loss: 2.838873565837901

Epoch: 5| Step: 5
Training loss: 2.4533584117889404
Validation loss: 2.841335188957953

Epoch: 5| Step: 6
Training loss: 2.917397975921631
Validation loss: 2.838912951048984

Epoch: 5| Step: 7
Training loss: 2.3709354400634766
Validation loss: 2.8405845139616277

Epoch: 5| Step: 8
Training loss: 3.0511415004730225
Validation loss: 2.8327542633138676

Epoch: 5| Step: 9
Training loss: 2.676537036895752
Validation loss: 2.8342626479364212

Epoch: 5| Step: 10
Training loss: 2.4164347648620605
Validation loss: 2.8287044725110455

Epoch: 33| Step: 0
Training loss: 2.900127410888672
Validation loss: 2.830389884210402

Epoch: 5| Step: 1
Training loss: 2.6866867542266846
Validation loss: 2.82859266701565

Epoch: 5| Step: 2
Training loss: 3.1721749305725098
Validation loss: 2.826616907632479

Epoch: 5| Step: 3
Training loss: 2.691563367843628
Validation loss: 2.8268384677107616

Epoch: 5| Step: 4
Training loss: 3.998310089111328
Validation loss: 2.825507451129216

Epoch: 5| Step: 5
Training loss: 3.2006092071533203
Validation loss: 2.821413378561697

Epoch: 5| Step: 6
Training loss: 3.526038646697998
Validation loss: 2.821473229315973

Epoch: 5| Step: 7
Training loss: 2.2323925495147705
Validation loss: 2.82032020374011

Epoch: 5| Step: 8
Training loss: 2.693655014038086
Validation loss: 2.8141442434762114

Epoch: 5| Step: 9
Training loss: 2.4854190349578857
Validation loss: 2.8150183898146435

Epoch: 5| Step: 10
Training loss: 2.67958664894104
Validation loss: 2.8134023912491335

Epoch: 34| Step: 0
Training loss: 2.6557669639587402
Validation loss: 2.8117284826053086

Epoch: 5| Step: 1
Training loss: 3.444301128387451
Validation loss: 2.805031248318252

Epoch: 5| Step: 2
Training loss: 2.1684024333953857
Validation loss: 2.8103134016836844

Epoch: 5| Step: 3
Training loss: 3.4679102897644043
Validation loss: 2.807456975342125

Epoch: 5| Step: 4
Training loss: 3.2694251537323
Validation loss: 2.8028261533347507

Epoch: 5| Step: 5
Training loss: 2.641045093536377
Validation loss: 2.8022687819696244

Epoch: 5| Step: 6
Training loss: 2.61604380607605
Validation loss: 2.798688127148536

Epoch: 5| Step: 7
Training loss: 3.703937530517578
Validation loss: 2.808048632837111

Epoch: 5| Step: 8
Training loss: 2.805436372756958
Validation loss: 2.799784929521622

Epoch: 5| Step: 9
Training loss: 2.624174118041992
Validation loss: 2.800411283328969

Epoch: 5| Step: 10
Training loss: 2.793760299682617
Validation loss: 2.7940784141581547

Epoch: 35| Step: 0
Training loss: 4.048935890197754
Validation loss: 2.7927820323615946

Epoch: 5| Step: 1
Training loss: 2.060922622680664
Validation loss: 2.7947939570232103

Epoch: 5| Step: 2
Training loss: 2.4591739177703857
Validation loss: 2.801693639447612

Epoch: 5| Step: 3
Training loss: 2.79276967048645
Validation loss: 2.8009671165097143

Epoch: 5| Step: 4
Training loss: 3.045532464981079
Validation loss: 2.7956972019646757

Epoch: 5| Step: 5
Training loss: 2.7646782398223877
Validation loss: 2.7908505291067143

Epoch: 5| Step: 6
Training loss: 3.229687452316284
Validation loss: 2.7872595966503186

Epoch: 5| Step: 7
Training loss: 3.228755235671997
Validation loss: 2.784643339854415

Epoch: 5| Step: 8
Training loss: 2.6283679008483887
Validation loss: 2.7882322854893182

Epoch: 5| Step: 9
Training loss: 3.014369010925293
Validation loss: 2.7839191831568235

Epoch: 5| Step: 10
Training loss: 2.822446584701538
Validation loss: 2.785494524945495

Epoch: 36| Step: 0
Training loss: 2.306232452392578
Validation loss: 2.783279941928002

Epoch: 5| Step: 1
Training loss: 3.02309250831604
Validation loss: 2.783286363847794

Epoch: 5| Step: 2
Training loss: 3.7268576622009277
Validation loss: 2.781875935933923

Epoch: 5| Step: 3
Training loss: 2.700085163116455
Validation loss: 2.778537037552044

Epoch: 5| Step: 4
Training loss: 3.217597484588623
Validation loss: 2.7763899551924838

Epoch: 5| Step: 5
Training loss: 2.9015285968780518
Validation loss: 2.7714678907907135

Epoch: 5| Step: 6
Training loss: 2.6217124462127686
Validation loss: 2.7683745686725905

Epoch: 5| Step: 7
Training loss: 2.829232692718506
Validation loss: 2.770077492601128

Epoch: 5| Step: 8
Training loss: 2.8864734172821045
Validation loss: 2.775313941381311

Epoch: 5| Step: 9
Training loss: 2.809291362762451
Validation loss: 2.7706422369967223

Epoch: 5| Step: 10
Training loss: 2.95479679107666
Validation loss: 2.7693531974669425

Epoch: 37| Step: 0
Training loss: 3.0870563983917236
Validation loss: 2.7686362830541467

Epoch: 5| Step: 1
Training loss: 2.5162506103515625
Validation loss: 2.7705123142529557

Epoch: 5| Step: 2
Training loss: 2.677964687347412
Validation loss: 2.7691277791095037

Epoch: 5| Step: 3
Training loss: 2.12056040763855
Validation loss: 2.764247420013592

Epoch: 5| Step: 4
Training loss: 2.305021286010742
Validation loss: 2.7632420960293023

Epoch: 5| Step: 5
Training loss: 2.618746280670166
Validation loss: 2.7642771377358386

Epoch: 5| Step: 6
Training loss: 3.0097622871398926
Validation loss: 2.7577056910402034

Epoch: 5| Step: 7
Training loss: 3.1949989795684814
Validation loss: 2.752260233766289

Epoch: 5| Step: 8
Training loss: 3.859109401702881
Validation loss: 2.753774194307225

Epoch: 5| Step: 9
Training loss: 3.3737576007843018
Validation loss: 2.752952875629548

Epoch: 5| Step: 10
Training loss: 3.0878753662109375
Validation loss: 2.7592073179060415

Epoch: 38| Step: 0
Training loss: 2.959388256072998
Validation loss: 2.755194689637871

Epoch: 5| Step: 1
Training loss: 2.6792359352111816
Validation loss: 2.752980503984677

Epoch: 5| Step: 2
Training loss: 3.068984270095825
Validation loss: 2.751500727027975

Epoch: 5| Step: 3
Training loss: 3.043560743331909
Validation loss: 2.7475186701743834

Epoch: 5| Step: 4
Training loss: 2.6617770195007324
Validation loss: 2.743879505383071

Epoch: 5| Step: 5
Training loss: 3.2346558570861816
Validation loss: 2.7456096346660326

Epoch: 5| Step: 6
Training loss: 3.0928051471710205
Validation loss: 2.749961914554719

Epoch: 5| Step: 7
Training loss: 2.7803471088409424
Validation loss: 2.7491483739627305

Epoch: 5| Step: 8
Training loss: 2.935168743133545
Validation loss: 2.7480751801562566

Epoch: 5| Step: 9
Training loss: 2.3044674396514893
Validation loss: 2.747982043091969

Epoch: 5| Step: 10
Training loss: 3.0250701904296875
Validation loss: 2.7456811730579664

Epoch: 39| Step: 0
Training loss: 2.726566791534424
Validation loss: 2.7418245500133884

Epoch: 5| Step: 1
Training loss: 2.4847588539123535
Validation loss: 2.741768334501533

Epoch: 5| Step: 2
Training loss: 2.969566822052002
Validation loss: 2.741451140372984

Epoch: 5| Step: 3
Training loss: 2.9693026542663574
Validation loss: 2.7389881251960673

Epoch: 5| Step: 4
Training loss: 2.767829418182373
Validation loss: 2.7355412539615425

Epoch: 5| Step: 5
Training loss: 2.934087038040161
Validation loss: 2.732455981675015

Epoch: 5| Step: 6
Training loss: 3.076591968536377
Validation loss: 2.731832834982103

Epoch: 5| Step: 7
Training loss: 2.873290538787842
Validation loss: 2.732834364778252

Epoch: 5| Step: 8
Training loss: 2.902543783187866
Validation loss: 2.734545874339278

Epoch: 5| Step: 9
Training loss: 3.4163100719451904
Validation loss: 2.7373863753452095

Epoch: 5| Step: 10
Training loss: 2.442330837249756
Validation loss: 2.7352280616760254

Epoch: 40| Step: 0
Training loss: 2.8695297241210938
Validation loss: 2.730035142232013

Epoch: 5| Step: 1
Training loss: 2.7345917224884033
Validation loss: 2.7315972979350756

Epoch: 5| Step: 2
Training loss: 3.056347370147705
Validation loss: 2.736440938006165

Epoch: 5| Step: 3
Training loss: 3.1548495292663574
Validation loss: 2.737127214349726

Epoch: 5| Step: 4
Training loss: 3.241732358932495
Validation loss: 2.725989459663309

Epoch: 5| Step: 5
Training loss: 2.3419811725616455
Validation loss: 2.725134277856478

Epoch: 5| Step: 6
Training loss: 3.220824718475342
Validation loss: 2.728346368317963

Epoch: 5| Step: 7
Training loss: 2.8825020790100098
Validation loss: 2.736224079644808

Epoch: 5| Step: 8
Training loss: 2.3120498657226562
Validation loss: 2.7360082108487367

Epoch: 5| Step: 9
Training loss: 3.0302908420562744
Validation loss: 2.7395174016234694

Epoch: 5| Step: 10
Training loss: 2.764566421508789
Validation loss: 2.738500807874946

Epoch: 41| Step: 0
Training loss: 3.708266496658325
Validation loss: 2.733944503209924

Epoch: 5| Step: 1
Training loss: 2.2123022079467773
Validation loss: 2.727798056858842

Epoch: 5| Step: 2
Training loss: 3.3454391956329346
Validation loss: 2.7187130938294115

Epoch: 5| Step: 3
Training loss: 2.6134438514709473
Validation loss: 2.7253664898616012

Epoch: 5| Step: 4
Training loss: 2.6195008754730225
Validation loss: 2.723544636080342

Epoch: 5| Step: 5
Training loss: 2.846024990081787
Validation loss: 2.7299911770769345

Epoch: 5| Step: 6
Training loss: 2.680091381072998
Validation loss: 2.7391876636012906

Epoch: 5| Step: 7
Training loss: 3.067993640899658
Validation loss: 2.7544130176626225

Epoch: 5| Step: 8
Training loss: 2.8004541397094727
Validation loss: 2.7525023542424685

Epoch: 5| Step: 9
Training loss: 2.755321502685547
Validation loss: 2.7208799598037556

Epoch: 5| Step: 10
Training loss: 2.9927964210510254
Validation loss: 2.7111040725502917

Epoch: 42| Step: 0
Training loss: 2.6650261878967285
Validation loss: 2.7199816883251233

Epoch: 5| Step: 1
Training loss: 2.68323016166687
Validation loss: 2.723130000534878

Epoch: 5| Step: 2
Training loss: 2.7236080169677734
Validation loss: 2.729027489180206

Epoch: 5| Step: 3
Training loss: 3.4834320545196533
Validation loss: 2.7343264882282545

Epoch: 5| Step: 4
Training loss: 2.5925111770629883
Validation loss: 2.7366564812198764

Epoch: 5| Step: 5
Training loss: 2.518617630004883
Validation loss: 2.7382092091345016

Epoch: 5| Step: 6
Training loss: 3.125800371170044
Validation loss: 2.7245972310343096

Epoch: 5| Step: 7
Training loss: 2.9138197898864746
Validation loss: 2.720648727109355

Epoch: 5| Step: 8
Training loss: 3.00425124168396
Validation loss: 2.718765438243907

Epoch: 5| Step: 9
Training loss: 3.020634412765503
Validation loss: 2.725813350369853

Epoch: 5| Step: 10
Training loss: 2.864039182662964
Validation loss: 2.7355643498000277

Epoch: 43| Step: 0
Training loss: 3.5622684955596924
Validation loss: 2.7337648714742353

Epoch: 5| Step: 1
Training loss: 2.8688530921936035
Validation loss: 2.720434155515445

Epoch: 5| Step: 2
Training loss: 3.3184731006622314
Validation loss: 2.707440483954645

Epoch: 5| Step: 3
Training loss: 2.9987220764160156
Validation loss: 2.708558613254178

Epoch: 5| Step: 4
Training loss: 3.3956217765808105
Validation loss: 2.70520693256009

Epoch: 5| Step: 5
Training loss: 2.218930721282959
Validation loss: 2.7064660569672943

Epoch: 5| Step: 6
Training loss: 2.6996638774871826
Validation loss: 2.731250250211326

Epoch: 5| Step: 7
Training loss: 1.731083869934082
Validation loss: 2.7951341405991585

Epoch: 5| Step: 8
Training loss: 2.9976859092712402
Validation loss: 2.8876758339584514

Epoch: 5| Step: 9
Training loss: 3.07000994682312
Validation loss: 2.9282784641429944

Epoch: 5| Step: 10
Training loss: 3.089470863342285
Validation loss: 2.9327009518941245

Epoch: 44| Step: 0
Training loss: 3.4825539588928223
Validation loss: 2.9348835022218767

Epoch: 5| Step: 1
Training loss: 4.531285762786865
Validation loss: 2.9207734728372223

Epoch: 5| Step: 2
Training loss: 3.302842378616333
Validation loss: 2.913304569900677

Epoch: 5| Step: 3
Training loss: 2.684835910797119
Validation loss: 2.8933816443207445

Epoch: 5| Step: 4
Training loss: 2.5977089405059814
Validation loss: 2.892253975714407

Epoch: 5| Step: 5
Training loss: 2.7236878871917725
Validation loss: 2.89888136617599

Epoch: 5| Step: 6
Training loss: 2.874147891998291
Validation loss: 2.892084990778277

Epoch: 5| Step: 7
Training loss: 2.4111928939819336
Validation loss: 2.8859168073182464

Epoch: 5| Step: 8
Training loss: 2.7655231952667236
Validation loss: 2.8762415967961794

Epoch: 5| Step: 9
Training loss: 2.840466260910034
Validation loss: 2.86791423315643

Epoch: 5| Step: 10
Training loss: 2.603788375854492
Validation loss: 2.8655313625130603

Epoch: 45| Step: 0
Training loss: 2.8407320976257324
Validation loss: 2.867943548387097

Epoch: 5| Step: 1
Training loss: 3.07572078704834
Validation loss: 2.844488928394933

Epoch: 5| Step: 2
Training loss: 2.6906142234802246
Validation loss: 2.818475572011804

Epoch: 5| Step: 3
Training loss: 3.220259189605713
Validation loss: 2.7990426299392537

Epoch: 5| Step: 4
Training loss: 3.5907444953918457
Validation loss: 2.7960184107544603

Epoch: 5| Step: 5
Training loss: 2.0037524700164795
Validation loss: 2.780342891652097

Epoch: 5| Step: 6
Training loss: 3.334362745285034
Validation loss: 2.781588041654197

Epoch: 5| Step: 7
Training loss: 3.0232715606689453
Validation loss: 2.7776184030758437

Epoch: 5| Step: 8
Training loss: 2.4062588214874268
Validation loss: 2.7811424193843717

Epoch: 5| Step: 9
Training loss: 3.0290794372558594
Validation loss: 2.775213626123244

Epoch: 5| Step: 10
Training loss: 2.8537280559539795
Validation loss: 2.7746661709200953

Epoch: 46| Step: 0
Training loss: 3.1286587715148926
Validation loss: 2.7667423396982174

Epoch: 5| Step: 1
Training loss: 4.015337944030762
Validation loss: 2.7683486502657653

Epoch: 5| Step: 2
Training loss: 2.2960400581359863
Validation loss: 2.7554835017009447

Epoch: 5| Step: 3
Training loss: 1.919024109840393
Validation loss: 2.715119723350771

Epoch: 5| Step: 4
Training loss: 2.7533087730407715
Validation loss: 2.698560304539178

Epoch: 5| Step: 5
Training loss: 3.1466243267059326
Validation loss: 2.701297744627922

Epoch: 5| Step: 6
Training loss: 2.9747066497802734
Validation loss: 2.7080380044957644

Epoch: 5| Step: 7
Training loss: 3.0056283473968506
Validation loss: 2.712613075010238

Epoch: 5| Step: 8
Training loss: 2.566943645477295
Validation loss: 2.710882220216977

Epoch: 5| Step: 9
Training loss: 2.5474495887756348
Validation loss: 2.7048201842974593

Epoch: 5| Step: 10
Training loss: 3.313793182373047
Validation loss: 2.6980850388926845

Epoch: 47| Step: 0
Training loss: 2.217355489730835
Validation loss: 2.6998159116314304

Epoch: 5| Step: 1
Training loss: 3.2455763816833496
Validation loss: 2.6990451274379605

Epoch: 5| Step: 2
Training loss: 2.49013614654541
Validation loss: 2.69483349656546

Epoch: 5| Step: 3
Training loss: 2.9790029525756836
Validation loss: 2.6965028855108444

Epoch: 5| Step: 4
Training loss: 2.9393534660339355
Validation loss: 2.6921447169396187

Epoch: 5| Step: 5
Training loss: 2.9072885513305664
Validation loss: 2.68767951637186

Epoch: 5| Step: 6
Training loss: 3.0321927070617676
Validation loss: 2.685954950189078

Epoch: 5| Step: 7
Training loss: 2.8287460803985596
Validation loss: 2.6809474191358014

Epoch: 5| Step: 8
Training loss: 3.0699825286865234
Validation loss: 2.6794131878883607

Epoch: 5| Step: 9
Training loss: 2.337050199508667
Validation loss: 2.678628900999664

Epoch: 5| Step: 10
Training loss: 3.339672803878784
Validation loss: 2.679475825320008

Epoch: 48| Step: 0
Training loss: 3.455012083053589
Validation loss: 2.677925084226875

Epoch: 5| Step: 1
Training loss: 2.6427106857299805
Validation loss: 2.6760772761478218

Epoch: 5| Step: 2
Training loss: 2.5390467643737793
Validation loss: 2.6733708868744555

Epoch: 5| Step: 3
Training loss: 2.925506591796875
Validation loss: 2.6716046282040176

Epoch: 5| Step: 4
Training loss: 2.531402826309204
Validation loss: 2.670211443337061

Epoch: 5| Step: 5
Training loss: 3.2443954944610596
Validation loss: 2.67773191390499

Epoch: 5| Step: 6
Training loss: 3.0564303398132324
Validation loss: 2.677622974559825

Epoch: 5| Step: 7
Training loss: 3.007544755935669
Validation loss: 2.6720940477104596

Epoch: 5| Step: 8
Training loss: 2.7546801567077637
Validation loss: 2.6660160146733767

Epoch: 5| Step: 9
Training loss: 2.5842578411102295
Validation loss: 2.662119819271949

Epoch: 5| Step: 10
Training loss: 2.336050033569336
Validation loss: 2.665577644942909

Epoch: 49| Step: 0
Training loss: 2.646660327911377
Validation loss: 2.6732191039669897

Epoch: 5| Step: 1
Training loss: 3.2018706798553467
Validation loss: 2.6728835541714906

Epoch: 5| Step: 2
Training loss: 2.7897794246673584
Validation loss: 2.667780940250684

Epoch: 5| Step: 3
Training loss: 3.558850049972534
Validation loss: 2.661323731945407

Epoch: 5| Step: 4
Training loss: 2.8180837631225586
Validation loss: 2.6623509878753335

Epoch: 5| Step: 5
Training loss: 2.394432306289673
Validation loss: 2.6734412331734934

Epoch: 5| Step: 6
Training loss: 2.210930347442627
Validation loss: 2.7036924516001055

Epoch: 5| Step: 7
Training loss: 3.1849849224090576
Validation loss: 2.728422062371367

Epoch: 5| Step: 8
Training loss: 2.8374252319335938
Validation loss: 2.686719448335709

Epoch: 5| Step: 9
Training loss: 2.79048752784729
Validation loss: 2.666068164251184

Epoch: 5| Step: 10
Training loss: 2.709048271179199
Validation loss: 2.649782680696057

Epoch: 50| Step: 0
Training loss: 2.5437331199645996
Validation loss: 2.6650858643234416

Epoch: 5| Step: 1
Training loss: 2.6085619926452637
Validation loss: 2.6963228948654665

Epoch: 5| Step: 2
Training loss: 2.811394214630127
Validation loss: 2.758066313241118

Epoch: 5| Step: 3
Training loss: 3.6461868286132812
Validation loss: 2.7123939760269655

Epoch: 5| Step: 4
Training loss: 2.893601655960083
Validation loss: 2.6722335533429216

Epoch: 5| Step: 5
Training loss: 2.6460115909576416
Validation loss: 2.6656108492164203

Epoch: 5| Step: 6
Training loss: 2.6004416942596436
Validation loss: 2.6593058673284387

Epoch: 5| Step: 7
Training loss: 3.272988796234131
Validation loss: 2.660702456710159

Epoch: 5| Step: 8
Training loss: 2.8969249725341797
Validation loss: 2.6535597155171056

Epoch: 5| Step: 9
Training loss: 2.6956164836883545
Validation loss: 2.654551039459885

Epoch: 5| Step: 10
Training loss: 2.617473602294922
Validation loss: 2.653246138685493

Epoch: 51| Step: 0
Training loss: 2.8022265434265137
Validation loss: 2.655720377481112

Epoch: 5| Step: 1
Training loss: 2.2988433837890625
Validation loss: 2.65600573888389

Epoch: 5| Step: 2
Training loss: 2.4851698875427246
Validation loss: 2.6568338742820163

Epoch: 5| Step: 3
Training loss: 2.967644453048706
Validation loss: 2.6578953291780207

Epoch: 5| Step: 4
Training loss: 3.2694778442382812
Validation loss: 2.6604905410479476

Epoch: 5| Step: 5
Training loss: 3.1756556034088135
Validation loss: 2.6573135980995755

Epoch: 5| Step: 6
Training loss: 2.9016997814178467
Validation loss: 2.6580206553141275

Epoch: 5| Step: 7
Training loss: 2.597895622253418
Validation loss: 2.6565935098996727

Epoch: 5| Step: 8
Training loss: 2.986924171447754
Validation loss: 2.6521907801269204

Epoch: 5| Step: 9
Training loss: 2.5402309894561768
Validation loss: 2.6491292650981615

Epoch: 5| Step: 10
Training loss: 3.068411350250244
Validation loss: 2.645788126094367

Epoch: 52| Step: 0
Training loss: 2.8215491771698
Validation loss: 2.6471915321965374

Epoch: 5| Step: 1
Training loss: 2.8121726512908936
Validation loss: 2.64441789350202

Epoch: 5| Step: 2
Training loss: 2.5769972801208496
Validation loss: 2.6452024444457023

Epoch: 5| Step: 3
Training loss: 2.636974811553955
Validation loss: 2.6431196812660462

Epoch: 5| Step: 4
Training loss: 2.9324264526367188
Validation loss: 2.6440597605961624

Epoch: 5| Step: 5
Training loss: 3.201354503631592
Validation loss: 2.6438464118588354

Epoch: 5| Step: 6
Training loss: 2.692777156829834
Validation loss: 2.6414451240211405

Epoch: 5| Step: 7
Training loss: 2.7850990295410156
Validation loss: 2.6399881788479385

Epoch: 5| Step: 8
Training loss: 2.4990358352661133
Validation loss: 2.6405165028828446

Epoch: 5| Step: 9
Training loss: 3.1090080738067627
Validation loss: 2.635992165534727

Epoch: 5| Step: 10
Training loss: 2.9256813526153564
Validation loss: 2.6402731403227775

Epoch: 53| Step: 0
Training loss: 3.059906244277954
Validation loss: 2.632480259864561

Epoch: 5| Step: 1
Training loss: 2.1161718368530273
Validation loss: 2.639032938147104

Epoch: 5| Step: 2
Training loss: 2.4709672927856445
Validation loss: 2.637803375080068

Epoch: 5| Step: 3
Training loss: 2.8064186573028564
Validation loss: 2.63560143850183

Epoch: 5| Step: 4
Training loss: 3.0717647075653076
Validation loss: 2.6307810352694605

Epoch: 5| Step: 5
Training loss: 3.0162785053253174
Validation loss: 2.628158677008844

Epoch: 5| Step: 6
Training loss: 2.8118462562561035
Validation loss: 2.6297260561297016

Epoch: 5| Step: 7
Training loss: 2.845740795135498
Validation loss: 2.6289296662935646

Epoch: 5| Step: 8
Training loss: 2.799853563308716
Validation loss: 2.6271312185513076

Epoch: 5| Step: 9
Training loss: 3.158240795135498
Validation loss: 2.6245818932851157

Epoch: 5| Step: 10
Training loss: 2.6921489238739014
Validation loss: 2.625876816370154

Epoch: 54| Step: 0
Training loss: 2.9598960876464844
Validation loss: 2.625223098262664

Epoch: 5| Step: 1
Training loss: 3.1321651935577393
Validation loss: 2.6262388998462307

Epoch: 5| Step: 2
Training loss: 2.764975070953369
Validation loss: 2.6279762188593545

Epoch: 5| Step: 3
Training loss: 2.188631534576416
Validation loss: 2.6253664801197667

Epoch: 5| Step: 4
Training loss: 2.487949848175049
Validation loss: 2.626983432359593

Epoch: 5| Step: 5
Training loss: 2.262098550796509
Validation loss: 2.627603389883554

Epoch: 5| Step: 6
Training loss: 2.862957715988159
Validation loss: 2.6239406293438328

Epoch: 5| Step: 7
Training loss: 3.1578590869903564
Validation loss: 2.6236146573097474

Epoch: 5| Step: 8
Training loss: 3.118011713027954
Validation loss: 2.632123375451693

Epoch: 5| Step: 9
Training loss: 2.728325128555298
Validation loss: 2.627399580453032

Epoch: 5| Step: 10
Training loss: 3.2423017024993896
Validation loss: 2.6250574178593133

Epoch: 55| Step: 0
Training loss: 2.6990418434143066
Validation loss: 2.6238542731090257

Epoch: 5| Step: 1
Training loss: 2.935225009918213
Validation loss: 2.6233601980311896

Epoch: 5| Step: 2
Training loss: 2.6265053749084473
Validation loss: 2.6207136441302556

Epoch: 5| Step: 3
Training loss: 2.653862476348877
Validation loss: 2.6267408555553806

Epoch: 5| Step: 4
Training loss: 3.361971378326416
Validation loss: 2.62894844752486

Epoch: 5| Step: 5
Training loss: 2.532491445541382
Validation loss: 2.622913060649749

Epoch: 5| Step: 6
Training loss: 2.880530834197998
Validation loss: 2.6225482443327546

Epoch: 5| Step: 7
Training loss: 2.0546441078186035
Validation loss: 2.621460832575316

Epoch: 5| Step: 8
Training loss: 2.9190540313720703
Validation loss: 2.621910971979941

Epoch: 5| Step: 9
Training loss: 3.339282512664795
Validation loss: 2.617953254330543

Epoch: 5| Step: 10
Training loss: 2.6726274490356445
Validation loss: 2.6227026985537623

Epoch: 56| Step: 0
Training loss: 2.7019951343536377
Validation loss: 2.6209914402295182

Epoch: 5| Step: 1
Training loss: 2.7769179344177246
Validation loss: 2.6311114859837357

Epoch: 5| Step: 2
Training loss: 3.2989795207977295
Validation loss: 2.6576270621309996

Epoch: 5| Step: 3
Training loss: 2.879582166671753
Validation loss: 2.658301035563151

Epoch: 5| Step: 4
Training loss: 2.7639472484588623
Validation loss: 2.646447712375272

Epoch: 5| Step: 5
Training loss: 2.8033745288848877
Validation loss: 2.620060077277563

Epoch: 5| Step: 6
Training loss: 2.3577284812927246
Validation loss: 2.610630576328565

Epoch: 5| Step: 7
Training loss: 2.2047688961029053
Validation loss: 2.6103341169254755

Epoch: 5| Step: 8
Training loss: 3.190174102783203
Validation loss: 2.6172724436688166

Epoch: 5| Step: 9
Training loss: 2.65171480178833
Validation loss: 2.6192992348824777

Epoch: 5| Step: 10
Training loss: 3.3817830085754395
Validation loss: 2.6225959588122625

Epoch: 57| Step: 0
Training loss: 2.529428005218506
Validation loss: 2.6182090825932

Epoch: 5| Step: 1
Training loss: 2.505927324295044
Validation loss: 2.6091577006924536

Epoch: 5| Step: 2
Training loss: 2.9531362056732178
Validation loss: 2.6047487899821293

Epoch: 5| Step: 3
Training loss: 2.878251552581787
Validation loss: 2.6080154321526967

Epoch: 5| Step: 4
Training loss: 2.6293365955352783
Validation loss: 2.6084909797996603

Epoch: 5| Step: 5
Training loss: 2.618136167526245
Validation loss: 2.6101308048412366

Epoch: 5| Step: 6
Training loss: 2.578099012374878
Validation loss: 2.6137010999905166

Epoch: 5| Step: 7
Training loss: 2.9963936805725098
Validation loss: 2.615520892604705

Epoch: 5| Step: 8
Training loss: 3.4643235206604004
Validation loss: 2.619525883787422

Epoch: 5| Step: 9
Training loss: 3.045940399169922
Validation loss: 2.6169386422762306

Epoch: 5| Step: 10
Training loss: 2.526362657546997
Validation loss: 2.618569440739129

Epoch: 58| Step: 0
Training loss: 3.078059673309326
Validation loss: 2.6286262081515406

Epoch: 5| Step: 1
Training loss: 3.439573287963867
Validation loss: 2.6369482624915337

Epoch: 5| Step: 2
Training loss: 2.188697338104248
Validation loss: 2.6247763300454743

Epoch: 5| Step: 3
Training loss: 2.2920987606048584
Validation loss: 2.640556917395643

Epoch: 5| Step: 4
Training loss: 3.548361301422119
Validation loss: 2.639191642884285

Epoch: 5| Step: 5
Training loss: 2.8259758949279785
Validation loss: 2.6331100143412107

Epoch: 5| Step: 6
Training loss: 2.8962535858154297
Validation loss: 2.624372641245524

Epoch: 5| Step: 7
Training loss: 1.9982637166976929
Validation loss: 2.6240987880255586

Epoch: 5| Step: 8
Training loss: 3.046961545944214
Validation loss: 2.619270416998094

Epoch: 5| Step: 9
Training loss: 2.402824878692627
Validation loss: 2.625774319453906

Epoch: 5| Step: 10
Training loss: 3.0384252071380615
Validation loss: 2.6291325938317085

Epoch: 59| Step: 0
Training loss: 2.7915568351745605
Validation loss: 2.6156081358591714

Epoch: 5| Step: 1
Training loss: 2.2612686157226562
Validation loss: 2.6015935226153304

Epoch: 5| Step: 2
Training loss: 3.3004937171936035
Validation loss: 2.597703879879367

Epoch: 5| Step: 3
Training loss: 2.3642659187316895
Validation loss: 2.599441912866408

Epoch: 5| Step: 4
Training loss: 3.808457612991333
Validation loss: 2.6235660301741732

Epoch: 5| Step: 5
Training loss: 2.1948578357696533
Validation loss: 2.6296744602982716

Epoch: 5| Step: 6
Training loss: 3.3857455253601074
Validation loss: 2.6541199837961504

Epoch: 5| Step: 7
Training loss: 2.9491028785705566
Validation loss: 2.6371017040744906

Epoch: 5| Step: 8
Training loss: 2.8026955127716064
Validation loss: 2.624687866498065

Epoch: 5| Step: 9
Training loss: 2.020033359527588
Validation loss: 2.604717926312518

Epoch: 5| Step: 10
Training loss: 2.8279337882995605
Validation loss: 2.597231113782493

Epoch: 60| Step: 0
Training loss: 2.95828914642334
Validation loss: 2.601252773756622

Epoch: 5| Step: 1
Training loss: 2.4416937828063965
Validation loss: 2.6012679735819497

Epoch: 5| Step: 2
Training loss: 3.147852659225464
Validation loss: 2.6037584966228855

Epoch: 5| Step: 3
Training loss: 2.97404408454895
Validation loss: 2.609077861232142

Epoch: 5| Step: 4
Training loss: 2.510862350463867
Validation loss: 2.604123479576521

Epoch: 5| Step: 5
Training loss: 2.885255813598633
Validation loss: 2.6145765089219615

Epoch: 5| Step: 6
Training loss: 2.513148784637451
Validation loss: 2.608275903168545

Epoch: 5| Step: 7
Training loss: 3.4830398559570312
Validation loss: 2.608317995584139

Epoch: 5| Step: 8
Training loss: 2.968851089477539
Validation loss: 2.6041768238108647

Epoch: 5| Step: 9
Training loss: 2.383877754211426
Validation loss: 2.6006782541992846

Epoch: 5| Step: 10
Training loss: 2.381296157836914
Validation loss: 2.595079597606454

Epoch: 61| Step: 0
Training loss: 3.1780753135681152
Validation loss: 2.589689936689151

Epoch: 5| Step: 1
Training loss: 3.1964077949523926
Validation loss: 2.59243602906504

Epoch: 5| Step: 2
Training loss: 3.2152938842773438
Validation loss: 2.589360111503191

Epoch: 5| Step: 3
Training loss: 2.758915662765503
Validation loss: 2.5882429615143807

Epoch: 5| Step: 4
Training loss: 2.774014711380005
Validation loss: 2.5858762648797806

Epoch: 5| Step: 5
Training loss: 2.7674665451049805
Validation loss: 2.5897644386496594

Epoch: 5| Step: 6
Training loss: 2.1692402362823486
Validation loss: 2.5871247399237847

Epoch: 5| Step: 7
Training loss: 2.368306875228882
Validation loss: 2.59172752852081

Epoch: 5| Step: 8
Training loss: 3.0171196460723877
Validation loss: 2.610584515397267

Epoch: 5| Step: 9
Training loss: 2.644416332244873
Validation loss: 2.6178834053777877

Epoch: 5| Step: 10
Training loss: 2.466491222381592
Validation loss: 2.622674065251504

Epoch: 62| Step: 0
Training loss: 2.6972036361694336
Validation loss: 2.6169070671963435

Epoch: 5| Step: 1
Training loss: 3.347745418548584
Validation loss: 2.6069162404665382

Epoch: 5| Step: 2
Training loss: 2.717261791229248
Validation loss: 2.5933199287742696

Epoch: 5| Step: 3
Training loss: 1.9144890308380127
Validation loss: 2.586815223898939

Epoch: 5| Step: 4
Training loss: 2.800793170928955
Validation loss: 2.5877559261937297

Epoch: 5| Step: 5
Training loss: 2.742140293121338
Validation loss: 2.5853181500588693

Epoch: 5| Step: 6
Training loss: 3.2582592964172363
Validation loss: 2.587087215915803

Epoch: 5| Step: 7
Training loss: 3.360260009765625
Validation loss: 2.591099716001941

Epoch: 5| Step: 8
Training loss: 2.7933273315429688
Validation loss: 2.5942765692228913

Epoch: 5| Step: 9
Training loss: 2.49827241897583
Validation loss: 2.596951683362325

Epoch: 5| Step: 10
Training loss: 2.347099542617798
Validation loss: 2.597550489569223

Epoch: 63| Step: 0
Training loss: 2.5106892585754395
Validation loss: 2.6034442481174263

Epoch: 5| Step: 1
Training loss: 2.408449649810791
Validation loss: 2.6006305807380268

Epoch: 5| Step: 2
Training loss: 2.16131591796875
Validation loss: 2.596654451021584

Epoch: 5| Step: 3
Training loss: 2.99963641166687
Validation loss: 2.591293147815171

Epoch: 5| Step: 4
Training loss: 2.8241584300994873
Validation loss: 2.584922295744701

Epoch: 5| Step: 5
Training loss: 2.338134288787842
Validation loss: 2.5819190368857434

Epoch: 5| Step: 6
Training loss: 2.8614706993103027
Validation loss: 2.585882027943929

Epoch: 5| Step: 7
Training loss: 2.9562039375305176
Validation loss: 2.5972235997517905

Epoch: 5| Step: 8
Training loss: 3.4205849170684814
Validation loss: 2.5901132399036038

Epoch: 5| Step: 9
Training loss: 2.767528533935547
Validation loss: 2.5868016366035707

Epoch: 5| Step: 10
Training loss: 3.298952341079712
Validation loss: 2.590404910425986

Epoch: 64| Step: 0
Training loss: 2.5106887817382812
Validation loss: 2.5846472427409184

Epoch: 5| Step: 1
Training loss: 2.646292209625244
Validation loss: 2.5813991741467546

Epoch: 5| Step: 2
Training loss: 2.55326509475708
Validation loss: 2.579864873681017

Epoch: 5| Step: 3
Training loss: 2.442945718765259
Validation loss: 2.5845599635954826

Epoch: 5| Step: 4
Training loss: 3.0884296894073486
Validation loss: 2.5849243210208033

Epoch: 5| Step: 5
Training loss: 2.320051670074463
Validation loss: 2.579178794737785

Epoch: 5| Step: 6
Training loss: 3.0257363319396973
Validation loss: 2.577327702635078

Epoch: 5| Step: 7
Training loss: 3.179983377456665
Validation loss: 2.575912598640688

Epoch: 5| Step: 8
Training loss: 3.1798298358917236
Validation loss: 2.578942911599272

Epoch: 5| Step: 9
Training loss: 2.544255256652832
Validation loss: 2.579534912622103

Epoch: 5| Step: 10
Training loss: 2.904581308364868
Validation loss: 2.5794375840053765

Epoch: 65| Step: 0
Training loss: 2.835373640060425
Validation loss: 2.59023618185392

Epoch: 5| Step: 1
Training loss: 3.2143797874450684
Validation loss: 2.5752726831743793

Epoch: 5| Step: 2
Training loss: 2.1233344078063965
Validation loss: 2.575263492522701

Epoch: 5| Step: 3
Training loss: 3.2976784706115723
Validation loss: 2.573572163940758

Epoch: 5| Step: 4
Training loss: 3.4176907539367676
Validation loss: 2.5737394414922243

Epoch: 5| Step: 5
Training loss: 2.1408987045288086
Validation loss: 2.576796252240417

Epoch: 5| Step: 6
Training loss: 2.5831189155578613
Validation loss: 2.5817509312783518

Epoch: 5| Step: 7
Training loss: 2.525510311126709
Validation loss: 2.579359269911243

Epoch: 5| Step: 8
Training loss: 2.976710796356201
Validation loss: 2.5851062241420952

Epoch: 5| Step: 9
Training loss: 2.708047866821289
Validation loss: 2.5823639413361907

Epoch: 5| Step: 10
Training loss: 2.48582124710083
Validation loss: 2.578105390712779

Epoch: 66| Step: 0
Training loss: 2.429835796356201
Validation loss: 2.578088552721085

Epoch: 5| Step: 1
Training loss: 2.7263429164886475
Validation loss: 2.5842235677985737

Epoch: 5| Step: 2
Training loss: 2.8901705741882324
Validation loss: 2.585190478191581

Epoch: 5| Step: 3
Training loss: 3.1336348056793213
Validation loss: 2.580105781555176

Epoch: 5| Step: 4
Training loss: 2.747863292694092
Validation loss: 2.575032816138319

Epoch: 5| Step: 5
Training loss: 2.2334203720092773
Validation loss: 2.575091936255014

Epoch: 5| Step: 6
Training loss: 3.036606550216675
Validation loss: 2.5764312718504216

Epoch: 5| Step: 7
Training loss: 2.8468635082244873
Validation loss: 2.573591519427556

Epoch: 5| Step: 8
Training loss: 2.6498544216156006
Validation loss: 2.5736050631410334

Epoch: 5| Step: 9
Training loss: 2.8169891834259033
Validation loss: 2.5732011231043006

Epoch: 5| Step: 10
Training loss: 2.8109874725341797
Validation loss: 2.568102918645387

Epoch: 67| Step: 0
Training loss: 2.1725621223449707
Validation loss: 2.5732863308281027

Epoch: 5| Step: 1
Training loss: 2.430964708328247
Validation loss: 2.574590080527849

Epoch: 5| Step: 2
Training loss: 2.4773049354553223
Validation loss: 2.5798857032611804

Epoch: 5| Step: 3
Training loss: 2.8843016624450684
Validation loss: 2.5908900460889264

Epoch: 5| Step: 4
Training loss: 2.5900182723999023
Validation loss: 2.5929053970562514

Epoch: 5| Step: 5
Training loss: 2.9707436561584473
Validation loss: 2.6115164192773963

Epoch: 5| Step: 6
Training loss: 2.9772443771362305
Validation loss: 2.5868675554952314

Epoch: 5| Step: 7
Training loss: 3.006216526031494
Validation loss: 2.5730983518785044

Epoch: 5| Step: 8
Training loss: 2.4231514930725098
Validation loss: 2.5716953123769453

Epoch: 5| Step: 9
Training loss: 3.3969788551330566
Validation loss: 2.5654686856013473

Epoch: 5| Step: 10
Training loss: 3.1149959564208984
Validation loss: 2.567284499445269

Epoch: 68| Step: 0
Training loss: 2.508739471435547
Validation loss: 2.5724291570724978

Epoch: 5| Step: 1
Training loss: 2.779834747314453
Validation loss: 2.5796890258789062

Epoch: 5| Step: 2
Training loss: 2.8380229473114014
Validation loss: 2.570208836627263

Epoch: 5| Step: 3
Training loss: 1.9411201477050781
Validation loss: 2.5679071026463665

Epoch: 5| Step: 4
Training loss: 3.3044910430908203
Validation loss: 2.562250788493823

Epoch: 5| Step: 5
Training loss: 2.9330949783325195
Validation loss: 2.56181489780385

Epoch: 5| Step: 6
Training loss: 2.473907709121704
Validation loss: 2.5647553167035504

Epoch: 5| Step: 7
Training loss: 3.0424256324768066
Validation loss: 2.563452874460528

Epoch: 5| Step: 8
Training loss: 2.5067622661590576
Validation loss: 2.563560208966655

Epoch: 5| Step: 9
Training loss: 2.973447799682617
Validation loss: 2.5623815418571554

Epoch: 5| Step: 10
Training loss: 3.10884690284729
Validation loss: 2.565788786898377

Epoch: 69| Step: 0
Training loss: 2.548194408416748
Validation loss: 2.5595248514606106

Epoch: 5| Step: 1
Training loss: 3.0935914516448975
Validation loss: 2.5612900667293097

Epoch: 5| Step: 2
Training loss: 3.0735831260681152
Validation loss: 2.5578013645705355

Epoch: 5| Step: 3
Training loss: 2.8108527660369873
Validation loss: 2.563285284144904

Epoch: 5| Step: 4
Training loss: 2.174398899078369
Validation loss: 2.5668446171668267

Epoch: 5| Step: 5
Training loss: 2.0828752517700195
Validation loss: 2.561014170287758

Epoch: 5| Step: 6
Training loss: 2.495997428894043
Validation loss: 2.565181924450782

Epoch: 5| Step: 7
Training loss: 2.8526530265808105
Validation loss: 2.5607675288313176

Epoch: 5| Step: 8
Training loss: 2.8343591690063477
Validation loss: 2.5603792641752507

Epoch: 5| Step: 9
Training loss: 2.4966983795166016
Validation loss: 2.5576187513207875

Epoch: 5| Step: 10
Training loss: 3.9901676177978516
Validation loss: 2.5619894612220024

Epoch: 70| Step: 0
Training loss: 2.711668014526367
Validation loss: 2.5645007523157264

Epoch: 5| Step: 1
Training loss: 2.955796718597412
Validation loss: 2.5563272224959506

Epoch: 5| Step: 2
Training loss: 2.9035866260528564
Validation loss: 2.5581371809846614

Epoch: 5| Step: 3
Training loss: 2.944218158721924
Validation loss: 2.557911770318144

Epoch: 5| Step: 4
Training loss: 2.8001768589019775
Validation loss: 2.5598922186000372

Epoch: 5| Step: 5
Training loss: 2.846475124359131
Validation loss: 2.560527168294435

Epoch: 5| Step: 6
Training loss: 2.5456104278564453
Validation loss: 2.557641419031287

Epoch: 5| Step: 7
Training loss: 2.8793790340423584
Validation loss: 2.5561078056212394

Epoch: 5| Step: 8
Training loss: 2.0291693210601807
Validation loss: 2.5530696094677015

Epoch: 5| Step: 9
Training loss: 2.705927610397339
Validation loss: 2.55787923771848

Epoch: 5| Step: 10
Training loss: 2.9309210777282715
Validation loss: 2.566119140194308

Epoch: 71| Step: 0
Training loss: 2.009744167327881
Validation loss: 2.5601557762392106

Epoch: 5| Step: 1
Training loss: 2.949345827102661
Validation loss: 2.5671835817316526

Epoch: 5| Step: 2
Training loss: 3.1818857192993164
Validation loss: 2.5745198367744364

Epoch: 5| Step: 3
Training loss: 2.993220806121826
Validation loss: 2.5743228466280046

Epoch: 5| Step: 4
Training loss: 2.9769864082336426
Validation loss: 2.5660171560061875

Epoch: 5| Step: 5
Training loss: 2.232016086578369
Validation loss: 2.5720003881762104

Epoch: 5| Step: 6
Training loss: 3.166027545928955
Validation loss: 2.5677645283360637

Epoch: 5| Step: 7
Training loss: 2.8037450313568115
Validation loss: 2.573559038100704

Epoch: 5| Step: 8
Training loss: 2.5823376178741455
Validation loss: 2.5701879352651615

Epoch: 5| Step: 9
Training loss: 2.5779736042022705
Validation loss: 2.56638244916034

Epoch: 5| Step: 10
Training loss: 2.7099523544311523
Validation loss: 2.5673821485170754

Epoch: 72| Step: 0
Training loss: 2.363866090774536
Validation loss: 2.558364032417215

Epoch: 5| Step: 1
Training loss: 2.3043007850646973
Validation loss: 2.5580825446754374

Epoch: 5| Step: 2
Training loss: 2.8231418132781982
Validation loss: 2.561355265237952

Epoch: 5| Step: 3
Training loss: 2.082918643951416
Validation loss: 2.558226634097356

Epoch: 5| Step: 4
Training loss: 2.9856364727020264
Validation loss: 2.569763611721736

Epoch: 5| Step: 5
Training loss: 2.935892105102539
Validation loss: 2.5704970564893497

Epoch: 5| Step: 6
Training loss: 2.3404078483581543
Validation loss: 2.577787435182961

Epoch: 5| Step: 7
Training loss: 2.717297077178955
Validation loss: 2.570177952448527

Epoch: 5| Step: 8
Training loss: 3.3194680213928223
Validation loss: 2.5610859599164737

Epoch: 5| Step: 9
Training loss: 3.1817026138305664
Validation loss: 2.5563874090871503

Epoch: 5| Step: 10
Training loss: 3.3121390342712402
Validation loss: 2.5539221712338027

Epoch: 73| Step: 0
Training loss: 2.488208770751953
Validation loss: 2.553138179163779

Epoch: 5| Step: 1
Training loss: 3.0193772315979004
Validation loss: 2.5546842339218303

Epoch: 5| Step: 2
Training loss: 2.5436208248138428
Validation loss: 2.5516286588484243

Epoch: 5| Step: 3
Training loss: 2.869075059890747
Validation loss: 2.548801093973139

Epoch: 5| Step: 4
Training loss: 2.8911590576171875
Validation loss: 2.5501111040833178

Epoch: 5| Step: 5
Training loss: 2.4989521503448486
Validation loss: 2.54878112833987

Epoch: 5| Step: 6
Training loss: 2.7760090827941895
Validation loss: 2.549209648563016

Epoch: 5| Step: 7
Training loss: 3.0741982460021973
Validation loss: 2.5504709238647134

Epoch: 5| Step: 8
Training loss: 2.5578644275665283
Validation loss: 2.5500002548258793

Epoch: 5| Step: 9
Training loss: 2.617820978164673
Validation loss: 2.5560573916281424

Epoch: 5| Step: 10
Training loss: 2.898447275161743
Validation loss: 2.5576183949747393

Epoch: 74| Step: 0
Training loss: 2.661271333694458
Validation loss: 2.5615097399680846

Epoch: 5| Step: 1
Training loss: 3.422548294067383
Validation loss: 2.559195041656494

Epoch: 5| Step: 2
Training loss: 2.9968924522399902
Validation loss: 2.5541428084014566

Epoch: 5| Step: 3
Training loss: 2.8551716804504395
Validation loss: 2.548575347469699

Epoch: 5| Step: 4
Training loss: 3.178985834121704
Validation loss: 2.5470852210957515

Epoch: 5| Step: 5
Training loss: 1.6100711822509766
Validation loss: 2.545413368491716

Epoch: 5| Step: 6
Training loss: 2.9747061729431152
Validation loss: 2.54797690145431

Epoch: 5| Step: 7
Training loss: 2.310710906982422
Validation loss: 2.5460065923711306

Epoch: 5| Step: 8
Training loss: 2.3539538383483887
Validation loss: 2.546515400691699

Epoch: 5| Step: 9
Training loss: 2.9251115322113037
Validation loss: 2.5431577313330864

Epoch: 5| Step: 10
Training loss: 2.9500041007995605
Validation loss: 2.545263751860588

Epoch: 75| Step: 0
Training loss: 2.713874340057373
Validation loss: 2.54355421117557

Epoch: 5| Step: 1
Training loss: 3.1234688758850098
Validation loss: 2.550208935173609

Epoch: 5| Step: 2
Training loss: 3.2723870277404785
Validation loss: 2.54770597334831

Epoch: 5| Step: 3
Training loss: 2.3739089965820312
Validation loss: 2.554682921337825

Epoch: 5| Step: 4
Training loss: 2.4135990142822266
Validation loss: 2.557366919773881

Epoch: 5| Step: 5
Training loss: 2.499854564666748
Validation loss: 2.555298069471954

Epoch: 5| Step: 6
Training loss: 2.3594746589660645
Validation loss: 2.5642131528546734

Epoch: 5| Step: 7
Training loss: 2.5100595951080322
Validation loss: 2.566412969302106

Epoch: 5| Step: 8
Training loss: 3.011263847351074
Validation loss: 2.569273119331688

Epoch: 5| Step: 9
Training loss: 2.8954050540924072
Validation loss: 2.5707122074660433

Epoch: 5| Step: 10
Training loss: 2.982950210571289
Validation loss: 2.5715984836701424

Epoch: 76| Step: 0
Training loss: 2.4927749633789062
Validation loss: 2.5681562628797305

Epoch: 5| Step: 1
Training loss: 2.673177480697632
Validation loss: 2.5635506824780534

Epoch: 5| Step: 2
Training loss: 2.3866639137268066
Validation loss: 2.564144244758032

Epoch: 5| Step: 3
Training loss: 2.841683864593506
Validation loss: 2.5585367833414385

Epoch: 5| Step: 4
Training loss: 2.4464972019195557
Validation loss: 2.5579394012369137

Epoch: 5| Step: 5
Training loss: 3.454690456390381
Validation loss: 2.554536939949118

Epoch: 5| Step: 6
Training loss: 3.345790386199951
Validation loss: 2.5476441306452595

Epoch: 5| Step: 7
Training loss: 3.073404312133789
Validation loss: 2.5518867918240127

Epoch: 5| Step: 8
Training loss: 2.1028213500976562
Validation loss: 2.546756996903368

Epoch: 5| Step: 9
Training loss: 2.7105648517608643
Validation loss: 2.5455999118025585

Epoch: 5| Step: 10
Training loss: 2.5698978900909424
Validation loss: 2.5467500468736053

Epoch: 77| Step: 0
Training loss: 2.966158628463745
Validation loss: 2.550081650416056

Epoch: 5| Step: 1
Training loss: 3.383896589279175
Validation loss: 2.5600543432338263

Epoch: 5| Step: 2
Training loss: 2.723224639892578
Validation loss: 2.5593701536937425

Epoch: 5| Step: 3
Training loss: 2.9080605506896973
Validation loss: 2.55430962962489

Epoch: 5| Step: 4
Training loss: 2.9947762489318848
Validation loss: 2.5495863473543556

Epoch: 5| Step: 5
Training loss: 3.1231467723846436
Validation loss: 2.551604240171371

Epoch: 5| Step: 6
Training loss: 2.482513427734375
Validation loss: 2.5528929964188607

Epoch: 5| Step: 7
Training loss: 1.96271550655365
Validation loss: 2.5574686360615555

Epoch: 5| Step: 8
Training loss: 2.5304694175720215
Validation loss: 2.5535019033698627

Epoch: 5| Step: 9
Training loss: 2.407806396484375
Validation loss: 2.544895177246422

Epoch: 5| Step: 10
Training loss: 2.6721930503845215
Validation loss: 2.542623148169569

Epoch: 78| Step: 0
Training loss: 3.1000254154205322
Validation loss: 2.5414928261951735

Epoch: 5| Step: 1
Training loss: 3.1868138313293457
Validation loss: 2.5429395603877243

Epoch: 5| Step: 2
Training loss: 3.08398175239563
Validation loss: 2.543710026689755

Epoch: 5| Step: 3
Training loss: 2.072930097579956
Validation loss: 2.543069298549365

Epoch: 5| Step: 4
Training loss: 3.245833158493042
Validation loss: 2.552251705559351

Epoch: 5| Step: 5
Training loss: 2.7648708820343018
Validation loss: 2.557133097802439

Epoch: 5| Step: 6
Training loss: 2.3659403324127197
Validation loss: 2.557160036538237

Epoch: 5| Step: 7
Training loss: 2.6425468921661377
Validation loss: 2.550106817676175

Epoch: 5| Step: 8
Training loss: 2.568108558654785
Validation loss: 2.5433070352000575

Epoch: 5| Step: 9
Training loss: 1.9472362995147705
Validation loss: 2.5395496686299643

Epoch: 5| Step: 10
Training loss: 3.2786290645599365
Validation loss: 2.5387827478429323

Epoch: 79| Step: 0
Training loss: 2.22947096824646
Validation loss: 2.5407020597047705

Epoch: 5| Step: 1
Training loss: 2.9485230445861816
Validation loss: 2.5470708441990677

Epoch: 5| Step: 2
Training loss: 2.7488956451416016
Validation loss: 2.5464502124376196

Epoch: 5| Step: 3
Training loss: 2.563504219055176
Validation loss: 2.5482086622586815

Epoch: 5| Step: 4
Training loss: 2.927464246749878
Validation loss: 2.552930029489661

Epoch: 5| Step: 5
Training loss: 3.1566290855407715
Validation loss: 2.5497859549778763

Epoch: 5| Step: 6
Training loss: 2.977792739868164
Validation loss: 2.5471948808239353

Epoch: 5| Step: 7
Training loss: 2.637371778488159
Validation loss: 2.5388723727195495

Epoch: 5| Step: 8
Training loss: 2.999387264251709
Validation loss: 2.5364202119970836

Epoch: 5| Step: 9
Training loss: 2.10947585105896
Validation loss: 2.5370401541392007

Epoch: 5| Step: 10
Training loss: 2.7515676021575928
Validation loss: 2.5464971808977026

Epoch: 80| Step: 0
Training loss: 2.442222833633423
Validation loss: 2.5520500162596345

Epoch: 5| Step: 1
Training loss: 2.618194818496704
Validation loss: 2.5607024097955353

Epoch: 5| Step: 2
Training loss: 2.7319648265838623
Validation loss: 2.5535815300480014

Epoch: 5| Step: 3
Training loss: 2.8741559982299805
Validation loss: 2.5461988115823395

Epoch: 5| Step: 4
Training loss: 3.0676074028015137
Validation loss: 2.543058805568244

Epoch: 5| Step: 5
Training loss: 2.555880069732666
Validation loss: 2.5391711881083827

Epoch: 5| Step: 6
Training loss: 2.744678020477295
Validation loss: 2.537456830342611

Epoch: 5| Step: 7
Training loss: 2.601170301437378
Validation loss: 2.5357871568331154

Epoch: 5| Step: 8
Training loss: 2.3636977672576904
Validation loss: 2.5373802620877504

Epoch: 5| Step: 9
Training loss: 3.405717372894287
Validation loss: 2.538759175167289

Epoch: 5| Step: 10
Training loss: 2.712066411972046
Validation loss: 2.541572101654545

Epoch: 81| Step: 0
Training loss: 3.1225132942199707
Validation loss: 2.549268445660991

Epoch: 5| Step: 1
Training loss: 2.899383068084717
Validation loss: 2.5493531944931194

Epoch: 5| Step: 2
Training loss: 3.188342809677124
Validation loss: 2.5367591124708935

Epoch: 5| Step: 3
Training loss: 3.15286922454834
Validation loss: 2.5403304407673497

Epoch: 5| Step: 4
Training loss: 2.5844714641571045
Validation loss: 2.5374190909888155

Epoch: 5| Step: 5
Training loss: 2.490057945251465
Validation loss: 2.5332597558216383

Epoch: 5| Step: 6
Training loss: 3.0384840965270996
Validation loss: 2.5375735554643857

Epoch: 5| Step: 7
Training loss: 2.21825909614563
Validation loss: 2.5419825635930544

Epoch: 5| Step: 8
Training loss: 2.654942274093628
Validation loss: 2.541277265035978

Epoch: 5| Step: 9
Training loss: 2.2794575691223145
Validation loss: 2.5354249887568976

Epoch: 5| Step: 10
Training loss: 2.4385576248168945
Validation loss: 2.5413158529548237

Epoch: 82| Step: 0
Training loss: 2.3350608348846436
Validation loss: 2.541633011192404

Epoch: 5| Step: 1
Training loss: 2.791449785232544
Validation loss: 2.5415558148455877

Epoch: 5| Step: 2
Training loss: 2.4792098999023438
Validation loss: 2.5501402783137497

Epoch: 5| Step: 3
Training loss: 3.149602174758911
Validation loss: 2.5498712678109445

Epoch: 5| Step: 4
Training loss: 2.6561474800109863
Validation loss: 2.5546921606986754

Epoch: 5| Step: 5
Training loss: 3.0486207008361816
Validation loss: 2.5610209613718014

Epoch: 5| Step: 6
Training loss: 2.4541993141174316
Validation loss: 2.5682925408886326

Epoch: 5| Step: 7
Training loss: 2.512612819671631
Validation loss: 2.55752202515961

Epoch: 5| Step: 8
Training loss: 2.6663365364074707
Validation loss: 2.5415937721088366

Epoch: 5| Step: 9
Training loss: 2.778653621673584
Validation loss: 2.533134878322642

Epoch: 5| Step: 10
Training loss: 3.2796342372894287
Validation loss: 2.5280037592816096

Epoch: 83| Step: 0
Training loss: 2.488619327545166
Validation loss: 2.5256070988152617

Epoch: 5| Step: 1
Training loss: 2.2408323287963867
Validation loss: 2.528719932802262

Epoch: 5| Step: 2
Training loss: 2.500885486602783
Validation loss: 2.5274536994195755

Epoch: 5| Step: 3
Training loss: 3.600473403930664
Validation loss: 2.525451644774406

Epoch: 5| Step: 4
Training loss: 2.401742696762085
Validation loss: 2.527013599231679

Epoch: 5| Step: 5
Training loss: 3.0294365882873535
Validation loss: 2.527264177158315

Epoch: 5| Step: 6
Training loss: 2.2108354568481445
Validation loss: 2.5273749828338623

Epoch: 5| Step: 7
Training loss: 3.0197970867156982
Validation loss: 2.5270216772633214

Epoch: 5| Step: 8
Training loss: 2.4877066612243652
Validation loss: 2.5262181271788893

Epoch: 5| Step: 9
Training loss: 3.0363476276397705
Validation loss: 2.5255498834835586

Epoch: 5| Step: 10
Training loss: 2.9986226558685303
Validation loss: 2.5329210501845165

Epoch: 84| Step: 0
Training loss: 3.131936550140381
Validation loss: 2.5287855773843746

Epoch: 5| Step: 1
Training loss: 2.1644349098205566
Validation loss: 2.5268467856991674

Epoch: 5| Step: 2
Training loss: 2.7260608673095703
Validation loss: 2.5273689287965015

Epoch: 5| Step: 3
Training loss: 2.386338710784912
Validation loss: 2.5285731515576764

Epoch: 5| Step: 4
Training loss: 3.8550708293914795
Validation loss: 2.529552516116891

Epoch: 5| Step: 5
Training loss: 2.9436841011047363
Validation loss: 2.52797120617282

Epoch: 5| Step: 6
Training loss: 2.3738646507263184
Validation loss: 2.5289518730614775

Epoch: 5| Step: 7
Training loss: 2.4692471027374268
Validation loss: 2.5312274194532827

Epoch: 5| Step: 8
Training loss: 2.5501646995544434
Validation loss: 2.528254511535809

Epoch: 5| Step: 9
Training loss: 2.4392802715301514
Validation loss: 2.526464257189023

Epoch: 5| Step: 10
Training loss: 2.9842209815979004
Validation loss: 2.529349298887355

Epoch: 85| Step: 0
Training loss: 3.253831148147583
Validation loss: 2.5310403198324223

Epoch: 5| Step: 1
Training loss: 2.338303804397583
Validation loss: 2.531282430054039

Epoch: 5| Step: 2
Training loss: 2.537968635559082
Validation loss: 2.5292042352819957

Epoch: 5| Step: 3
Training loss: 3.3436005115509033
Validation loss: 2.5351400195911364

Epoch: 5| Step: 4
Training loss: 3.48555326461792
Validation loss: 2.5325215247369584

Epoch: 5| Step: 5
Training loss: 2.1133551597595215
Validation loss: 2.535652845136581

Epoch: 5| Step: 6
Training loss: 3.1702728271484375
Validation loss: 2.5339025297472553

Epoch: 5| Step: 7
Training loss: 2.3833911418914795
Validation loss: 2.532030374773087

Epoch: 5| Step: 8
Training loss: 2.3842833042144775
Validation loss: 2.5296788010545956

Epoch: 5| Step: 9
Training loss: 1.9773868322372437
Validation loss: 2.531130611255605

Epoch: 5| Step: 10
Training loss: 3.034269094467163
Validation loss: 2.5299091723657425

Epoch: 86| Step: 0
Training loss: 3.3587193489074707
Validation loss: 2.529717089027487

Epoch: 5| Step: 1
Training loss: 2.3876609802246094
Validation loss: 2.532326062520345

Epoch: 5| Step: 2
Training loss: 2.083693742752075
Validation loss: 2.5314939201519056

Epoch: 5| Step: 3
Training loss: 2.5726664066314697
Validation loss: 2.5416921236181773

Epoch: 5| Step: 4
Training loss: 2.1197876930236816
Validation loss: 2.5460872701419297

Epoch: 5| Step: 5
Training loss: 2.667480945587158
Validation loss: 2.547264217048563

Epoch: 5| Step: 6
Training loss: 3.1791396141052246
Validation loss: 2.5460491257329143

Epoch: 5| Step: 7
Training loss: 2.480531930923462
Validation loss: 2.551609564852971

Epoch: 5| Step: 8
Training loss: 2.77540922164917
Validation loss: 2.550944552626661

Epoch: 5| Step: 9
Training loss: 3.000641345977783
Validation loss: 2.551430238190518

Epoch: 5| Step: 10
Training loss: 3.397618293762207
Validation loss: 2.545675552019509

Epoch: 87| Step: 0
Training loss: 2.6597421169281006
Validation loss: 2.538210012579477

Epoch: 5| Step: 1
Training loss: 2.70969820022583
Validation loss: 2.5287335457340365

Epoch: 5| Step: 2
Training loss: 2.6211531162261963
Validation loss: 2.5232579067189205

Epoch: 5| Step: 3
Training loss: 2.6323463916778564
Validation loss: 2.5238604186683573

Epoch: 5| Step: 4
Training loss: 2.8581058979034424
Validation loss: 2.524237068750525

Epoch: 5| Step: 5
Training loss: 2.400658130645752
Validation loss: 2.5292556285858154

Epoch: 5| Step: 6
Training loss: 2.614905834197998
Validation loss: 2.5382703401709117

Epoch: 5| Step: 7
Training loss: 3.205646514892578
Validation loss: 2.5385439062631256

Epoch: 5| Step: 8
Training loss: 3.157897710800171
Validation loss: 2.544259471278037

Epoch: 5| Step: 9
Training loss: 2.4992804527282715
Validation loss: 2.5463927356145715

Epoch: 5| Step: 10
Training loss: 2.600017786026001
Validation loss: 2.5386091547627605

Epoch: 88| Step: 0
Training loss: 2.9415767192840576
Validation loss: 2.5365075065243627

Epoch: 5| Step: 1
Training loss: 3.092144250869751
Validation loss: 2.5324549290441696

Epoch: 5| Step: 2
Training loss: 2.5047926902770996
Validation loss: 2.533880518328759

Epoch: 5| Step: 3
Training loss: 3.1131350994110107
Validation loss: 2.5264232876480266

Epoch: 5| Step: 4
Training loss: 3.465270519256592
Validation loss: 2.524739988388554

Epoch: 5| Step: 5
Training loss: 2.3889198303222656
Validation loss: 2.5231280608843734

Epoch: 5| Step: 6
Training loss: 2.1745588779449463
Validation loss: 2.5208402628539712

Epoch: 5| Step: 7
Training loss: 2.270780086517334
Validation loss: 2.521520048059443

Epoch: 5| Step: 8
Training loss: 3.587109327316284
Validation loss: 2.5227888989192184

Epoch: 5| Step: 9
Training loss: 2.2465670108795166
Validation loss: 2.523872565197688

Epoch: 5| Step: 10
Training loss: 2.098186731338501
Validation loss: 2.5210292826416674

Epoch: 89| Step: 0
Training loss: 2.7952418327331543
Validation loss: 2.5236646283057427

Epoch: 5| Step: 1
Training loss: 3.217655897140503
Validation loss: 2.528469060056953

Epoch: 5| Step: 2
Training loss: 2.8151538372039795
Validation loss: 2.533093742145005

Epoch: 5| Step: 3
Training loss: 3.442431926727295
Validation loss: 2.5453180292601227

Epoch: 5| Step: 4
Training loss: 2.490239381790161
Validation loss: 2.551402438071466

Epoch: 5| Step: 5
Training loss: 2.569690227508545
Validation loss: 2.557998472644437

Epoch: 5| Step: 6
Training loss: 2.9904017448425293
Validation loss: 2.5544247088893766

Epoch: 5| Step: 7
Training loss: 3.2415854930877686
Validation loss: 2.5581417109376643

Epoch: 5| Step: 8
Training loss: 1.7804462909698486
Validation loss: 2.555295728868054

Epoch: 5| Step: 9
Training loss: 2.2498340606689453
Validation loss: 2.5412089593948854

Epoch: 5| Step: 10
Training loss: 2.2838079929351807
Validation loss: 2.5328886688396497

Epoch: 90| Step: 0
Training loss: 3.427534580230713
Validation loss: 2.526508605608376

Epoch: 5| Step: 1
Training loss: 1.95041024684906
Validation loss: 2.5236294628471456

Epoch: 5| Step: 2
Training loss: 2.698582172393799
Validation loss: 2.522582551484467

Epoch: 5| Step: 3
Training loss: 2.8643910884857178
Validation loss: 2.5140517296329623

Epoch: 5| Step: 4
Training loss: 2.467893600463867
Validation loss: 2.5183330351306545

Epoch: 5| Step: 5
Training loss: 3.205670118331909
Validation loss: 2.519530939799483

Epoch: 5| Step: 6
Training loss: 2.8312244415283203
Validation loss: 2.5208007186971684

Epoch: 5| Step: 7
Training loss: 2.465012788772583
Validation loss: 2.522711697445121

Epoch: 5| Step: 8
Training loss: 2.824171543121338
Validation loss: 2.532895008722941

Epoch: 5| Step: 9
Training loss: 2.3757195472717285
Validation loss: 2.5330930807257213

Epoch: 5| Step: 10
Training loss: 2.7813174724578857
Validation loss: 2.535247149006013

Epoch: 91| Step: 0
Training loss: 2.5214555263519287
Validation loss: 2.535735507165232

Epoch: 5| Step: 1
Training loss: 2.9046411514282227
Validation loss: 2.5346563759670464

Epoch: 5| Step: 2
Training loss: 2.0901334285736084
Validation loss: 2.532532912428661

Epoch: 5| Step: 3
Training loss: 3.0598678588867188
Validation loss: 2.5265083774443595

Epoch: 5| Step: 4
Training loss: 2.1933484077453613
Validation loss: 2.5220110544594387

Epoch: 5| Step: 5
Training loss: 2.6659884452819824
Validation loss: 2.524672092929963

Epoch: 5| Step: 6
Training loss: 2.217390537261963
Validation loss: 2.5256544748942056

Epoch: 5| Step: 7
Training loss: 3.1388022899627686
Validation loss: 2.5246266459905975

Epoch: 5| Step: 8
Training loss: 2.9211649894714355
Validation loss: 2.5318926124162573

Epoch: 5| Step: 9
Training loss: 3.238981246948242
Validation loss: 2.535117185243996

Epoch: 5| Step: 10
Training loss: 2.9981937408447266
Validation loss: 2.523777151620516

Epoch: 92| Step: 0
Training loss: 3.158634662628174
Validation loss: 2.532594898695587

Epoch: 5| Step: 1
Training loss: 2.53660249710083
Validation loss: 2.5297905040043656

Epoch: 5| Step: 2
Training loss: 2.7627155780792236
Validation loss: 2.5392623357875372

Epoch: 5| Step: 3
Training loss: 3.3642239570617676
Validation loss: 2.5464930944545294

Epoch: 5| Step: 4
Training loss: 2.6890594959259033
Validation loss: 2.5471095987545547

Epoch: 5| Step: 5
Training loss: 2.894531011581421
Validation loss: 2.540417425094112

Epoch: 5| Step: 6
Training loss: 2.6469244956970215
Validation loss: 2.536522275658064

Epoch: 5| Step: 7
Training loss: 2.3070709705352783
Validation loss: 2.536917701844246

Epoch: 5| Step: 8
Training loss: 2.6907620429992676
Validation loss: 2.5404846822061846

Epoch: 5| Step: 9
Training loss: 2.438708782196045
Validation loss: 2.539664727385326

Epoch: 5| Step: 10
Training loss: 2.321530342102051
Validation loss: 2.5443774782201296

Epoch: 93| Step: 0
Training loss: 3.0427584648132324
Validation loss: 2.5436002131431334

Epoch: 5| Step: 1
Training loss: 2.768120527267456
Validation loss: 2.5395239322416243

Epoch: 5| Step: 2
Training loss: 2.152024507522583
Validation loss: 2.529632763196063

Epoch: 5| Step: 3
Training loss: 3.0454211235046387
Validation loss: 2.521656249159126

Epoch: 5| Step: 4
Training loss: 2.6422300338745117
Validation loss: 2.527089439412599

Epoch: 5| Step: 5
Training loss: 2.868877410888672
Validation loss: 2.526483787003384

Epoch: 5| Step: 6
Training loss: 2.8770413398742676
Validation loss: 2.5413804669534006

Epoch: 5| Step: 7
Training loss: 2.3513073921203613
Validation loss: 2.5390865777128484

Epoch: 5| Step: 8
Training loss: 2.9561469554901123
Validation loss: 2.5337887784486175

Epoch: 5| Step: 9
Training loss: 2.9306788444519043
Validation loss: 2.5318006853903494

Epoch: 5| Step: 10
Training loss: 2.274754047393799
Validation loss: 2.5255037097520727

Epoch: 94| Step: 0
Training loss: 3.0384223461151123
Validation loss: 2.5183167380671345

Epoch: 5| Step: 1
Training loss: 2.9420337677001953
Validation loss: 2.5242924664610173

Epoch: 5| Step: 2
Training loss: 2.281118154525757
Validation loss: 2.5132560601798435

Epoch: 5| Step: 3
Training loss: 3.2832858562469482
Validation loss: 2.517687346345635

Epoch: 5| Step: 4
Training loss: 2.831608295440674
Validation loss: 2.5116571687882945

Epoch: 5| Step: 5
Training loss: 2.7653346061706543
Validation loss: 2.5155464474872877

Epoch: 5| Step: 6
Training loss: 1.8756834268569946
Validation loss: 2.5154261871050765

Epoch: 5| Step: 7
Training loss: 2.952155828475952
Validation loss: 2.513961430518858

Epoch: 5| Step: 8
Training loss: 2.2638745307922363
Validation loss: 2.517833414898124

Epoch: 5| Step: 9
Training loss: 2.4555068016052246
Validation loss: 2.51953766422887

Epoch: 5| Step: 10
Training loss: 3.284803867340088
Validation loss: 2.5186875251031693

Epoch: 95| Step: 0
Training loss: 3.6704018115997314
Validation loss: 2.513187336665328

Epoch: 5| Step: 1
Training loss: 2.6873879432678223
Validation loss: 2.5142866539698776

Epoch: 5| Step: 2
Training loss: 3.3851547241210938
Validation loss: 2.517425614018594

Epoch: 5| Step: 3
Training loss: 2.4172816276550293
Validation loss: 2.5206270320441133

Epoch: 5| Step: 4
Training loss: 2.184537410736084
Validation loss: 2.5227019504834245

Epoch: 5| Step: 5
Training loss: 2.724061965942383
Validation loss: 2.5264516056224866

Epoch: 5| Step: 6
Training loss: 2.070157527923584
Validation loss: 2.5297577637498097

Epoch: 5| Step: 7
Training loss: 3.2034199237823486
Validation loss: 2.5427211305146575

Epoch: 5| Step: 8
Training loss: 2.559558391571045
Validation loss: 2.5253061940593104

Epoch: 5| Step: 9
Training loss: 2.2302093505859375
Validation loss: 2.5319251014340307

Epoch: 5| Step: 10
Training loss: 2.7452855110168457
Validation loss: 2.5299551333150556

Epoch: 96| Step: 0
Training loss: 2.55120587348938
Validation loss: 2.5212610690824446

Epoch: 5| Step: 1
Training loss: 2.7669882774353027
Validation loss: 2.5203174929465018

Epoch: 5| Step: 2
Training loss: 2.806994676589966
Validation loss: 2.5190338344984156

Epoch: 5| Step: 3
Training loss: 2.1831631660461426
Validation loss: 2.5143737485331874

Epoch: 5| Step: 4
Training loss: 3.1380951404571533
Validation loss: 2.5168459723072667

Epoch: 5| Step: 5
Training loss: 3.0471224784851074
Validation loss: 2.510656210684007

Epoch: 5| Step: 6
Training loss: 2.5768094062805176
Validation loss: 2.5093419667213195

Epoch: 5| Step: 7
Training loss: 3.3510303497314453
Validation loss: 2.5036938831370366

Epoch: 5| Step: 8
Training loss: 2.376068353652954
Validation loss: 2.507541800058016

Epoch: 5| Step: 9
Training loss: 2.0293197631835938
Validation loss: 2.509712516620595

Epoch: 5| Step: 10
Training loss: 3.0053915977478027
Validation loss: 2.5108819238601194

Epoch: 97| Step: 0
Training loss: 2.5998165607452393
Validation loss: 2.516431677726007

Epoch: 5| Step: 1
Training loss: 2.615961790084839
Validation loss: 2.5188811004802747

Epoch: 5| Step: 2
Training loss: 2.3532891273498535
Validation loss: 2.528535791622695

Epoch: 5| Step: 3
Training loss: 2.405240774154663
Validation loss: 2.5238864857663392

Epoch: 5| Step: 4
Training loss: 3.0491275787353516
Validation loss: 2.5249012849664174

Epoch: 5| Step: 5
Training loss: 2.4351680278778076
Validation loss: 2.5271816407480547

Epoch: 5| Step: 6
Training loss: 2.957228899002075
Validation loss: 2.5236786693655033

Epoch: 5| Step: 7
Training loss: 2.921314239501953
Validation loss: 2.5178266327868224

Epoch: 5| Step: 8
Training loss: 2.8082566261291504
Validation loss: 2.5199076539726666

Epoch: 5| Step: 9
Training loss: 2.8972713947296143
Validation loss: 2.5179866642080326

Epoch: 5| Step: 10
Training loss: 2.852581262588501
Validation loss: 2.5176947116851807

Epoch: 98| Step: 0
Training loss: 2.2708346843719482
Validation loss: 2.5124041700875885

Epoch: 5| Step: 1
Training loss: 2.573683977127075
Validation loss: 2.5079212445084766

Epoch: 5| Step: 2
Training loss: 2.061004161834717
Validation loss: 2.509681540150796

Epoch: 5| Step: 3
Training loss: 2.9703478813171387
Validation loss: 2.5094241890856015

Epoch: 5| Step: 4
Training loss: 2.8096327781677246
Validation loss: 2.5031561364409742

Epoch: 5| Step: 5
Training loss: 3.0049591064453125
Validation loss: 2.5062973012206373

Epoch: 5| Step: 6
Training loss: 3.105026960372925
Validation loss: 2.5028650376104538

Epoch: 5| Step: 7
Training loss: 2.6877872943878174
Validation loss: 2.5040968848812963

Epoch: 5| Step: 8
Training loss: 2.3303513526916504
Validation loss: 2.5008722838535102

Epoch: 5| Step: 9
Training loss: 2.734447956085205
Validation loss: 2.5053355360543854

Epoch: 5| Step: 10
Training loss: 3.3427371978759766
Validation loss: 2.5049323279370546

Epoch: 99| Step: 0
Training loss: 2.701868772506714
Validation loss: 2.5043008583848194

Epoch: 5| Step: 1
Training loss: 3.005415439605713
Validation loss: 2.5048770853268203

Epoch: 5| Step: 2
Training loss: 2.629753828048706
Validation loss: 2.509234243823636

Epoch: 5| Step: 3
Training loss: 2.6339499950408936
Validation loss: 2.5104474662452616

Epoch: 5| Step: 4
Training loss: 2.361560821533203
Validation loss: 2.509944837580445

Epoch: 5| Step: 5
Training loss: 2.6862149238586426
Validation loss: 2.5124670997742684

Epoch: 5| Step: 6
Training loss: 2.9620652198791504
Validation loss: 2.512752522704422

Epoch: 5| Step: 7
Training loss: 3.314659833908081
Validation loss: 2.5202303086557696

Epoch: 5| Step: 8
Training loss: 2.629619836807251
Validation loss: 2.5219868011372064

Epoch: 5| Step: 9
Training loss: 3.003688097000122
Validation loss: 2.5189037066633984

Epoch: 5| Step: 10
Training loss: 1.6953058242797852
Validation loss: 2.514797595239455

Epoch: 100| Step: 0
Training loss: 3.0738682746887207
Validation loss: 2.5118880323184434

Epoch: 5| Step: 1
Training loss: 2.6363577842712402
Validation loss: 2.514479826855403

Epoch: 5| Step: 2
Training loss: 3.0352044105529785
Validation loss: 2.5110969069183513

Epoch: 5| Step: 3
Training loss: 3.241305112838745
Validation loss: 2.51447287682564

Epoch: 5| Step: 4
Training loss: 3.2988076210021973
Validation loss: 2.5159559378059964

Epoch: 5| Step: 5
Training loss: 1.7367950677871704
Validation loss: 2.521387346329228

Epoch: 5| Step: 6
Training loss: 2.4251904487609863
Validation loss: 2.5194802617514007

Epoch: 5| Step: 7
Training loss: 2.3642380237579346
Validation loss: 2.511392185764928

Epoch: 5| Step: 8
Training loss: 2.6031601428985596
Validation loss: 2.5147141333549254

Epoch: 5| Step: 9
Training loss: 2.7696399688720703
Validation loss: 2.5159782542977283

Epoch: 5| Step: 10
Training loss: 2.522601366043091
Validation loss: 2.511993759421892

Testing loss: 2.655348155233595
