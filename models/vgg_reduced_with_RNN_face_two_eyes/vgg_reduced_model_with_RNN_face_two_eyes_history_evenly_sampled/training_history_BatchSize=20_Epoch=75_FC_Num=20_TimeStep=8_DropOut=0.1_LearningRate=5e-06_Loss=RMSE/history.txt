Epoch: 1| Step: 0
Training loss: 5.662634181439124
Validation loss: 5.777828066985378

Epoch: 5| Step: 1
Training loss: 6.1315254172898195
Validation loss: 5.774097473565259

Epoch: 5| Step: 2
Training loss: 6.0239244949451995
Validation loss: 5.77039929239187

Epoch: 5| Step: 3
Training loss: 5.580277398983798
Validation loss: 5.767138125435243

Epoch: 5| Step: 4
Training loss: 5.280125424889401
Validation loss: 5.76371156106984

Epoch: 5| Step: 5
Training loss: 4.715198114789955
Validation loss: 5.760183496708512

Epoch: 5| Step: 6
Training loss: 6.171049193170579
Validation loss: 5.756607669383336

Epoch: 5| Step: 7
Training loss: 5.9214920282455985
Validation loss: 5.752985096949813

Epoch: 5| Step: 8
Training loss: 5.252645643376566
Validation loss: 5.749230242794986

Epoch: 5| Step: 9
Training loss: 6.590113500332572
Validation loss: 5.7452285858239

Epoch: 5| Step: 10
Training loss: 6.237671556578937
Validation loss: 5.740794627647965

Epoch: 2| Step: 0
Training loss: 5.579933877642048
Validation loss: 5.736149346216751

Epoch: 5| Step: 1
Training loss: 5.023861405921079
Validation loss: 5.731368147517401

Epoch: 5| Step: 2
Training loss: 5.4044173998915905
Validation loss: 5.726402781548095

Epoch: 5| Step: 3
Training loss: 5.518160229249766
Validation loss: 5.721471346896641

Epoch: 5| Step: 4
Training loss: 6.901269558196708
Validation loss: 5.715474146726834

Epoch: 5| Step: 5
Training loss: 4.931379363438536
Validation loss: 5.70966755677457

Epoch: 5| Step: 6
Training loss: 5.56844843295145
Validation loss: 5.703547690327573

Epoch: 5| Step: 7
Training loss: 6.3142163049079985
Validation loss: 5.69682621954703

Epoch: 5| Step: 8
Training loss: 4.880330814655256
Validation loss: 5.688807111348029

Epoch: 5| Step: 9
Training loss: 5.914900323539049
Validation loss: 5.681691460442701

Epoch: 5| Step: 10
Training loss: 6.882307573171827
Validation loss: 5.673309216255329

Epoch: 3| Step: 0
Training loss: 5.717103481379087
Validation loss: 5.664683837756931

Epoch: 5| Step: 1
Training loss: 5.781748157380352
Validation loss: 5.655409486748301

Epoch: 5| Step: 2
Training loss: 5.89869877318692
Validation loss: 5.6456792345946205

Epoch: 5| Step: 3
Training loss: 4.976067678622983
Validation loss: 5.635002864218879

Epoch: 5| Step: 4
Training loss: 6.29973255376952
Validation loss: 5.624039188486008

Epoch: 5| Step: 5
Training loss: 5.250133331058982
Validation loss: 5.611451105418069

Epoch: 5| Step: 6
Training loss: 5.556365327099484
Validation loss: 5.599366359929264

Epoch: 5| Step: 7
Training loss: 5.228943697163927
Validation loss: 5.586094185452875

Epoch: 5| Step: 8
Training loss: 6.511147550119993
Validation loss: 5.572076164333115

Epoch: 5| Step: 9
Training loss: 4.791801229605403
Validation loss: 5.557137751451441

Epoch: 5| Step: 10
Training loss: 5.897450507240528
Validation loss: 5.541166483588416

Epoch: 4| Step: 0
Training loss: 5.82547484987812
Validation loss: 5.525040090386971

Epoch: 5| Step: 1
Training loss: 5.938987144146706
Validation loss: 5.508629955754426

Epoch: 5| Step: 2
Training loss: 6.27065282754076
Validation loss: 5.489778294050908

Epoch: 5| Step: 3
Training loss: 5.058299075937086
Validation loss: 5.471075876786368

Epoch: 5| Step: 4
Training loss: 5.366649261983445
Validation loss: 5.4494939547501655

Epoch: 5| Step: 5
Training loss: 4.666566824980313
Validation loss: 5.42924159029321

Epoch: 5| Step: 6
Training loss: 5.726917875121719
Validation loss: 5.407173339173125

Epoch: 5| Step: 7
Training loss: 4.934746469402978
Validation loss: 5.384452983837178

Epoch: 5| Step: 8
Training loss: 5.984130854394774
Validation loss: 5.361232910410565

Epoch: 5| Step: 9
Training loss: 5.374358027955198
Validation loss: 5.337319135770378

Epoch: 5| Step: 10
Training loss: 4.666150927428201
Validation loss: 5.311947825120859

Epoch: 5| Step: 0
Training loss: 5.813403643844932
Validation loss: 5.286119690038482

Epoch: 5| Step: 1
Training loss: 5.706767217754437
Validation loss: 5.260023007993904

Epoch: 5| Step: 2
Training loss: 5.835428606389052
Validation loss: 5.2333155610881565

Epoch: 5| Step: 3
Training loss: 5.159161479743803
Validation loss: 5.205007011520204

Epoch: 5| Step: 4
Training loss: 5.165117810983867
Validation loss: 5.178033991976417

Epoch: 5| Step: 5
Training loss: 5.321958491711486
Validation loss: 5.148034538866775

Epoch: 5| Step: 6
Training loss: 4.940046402253818
Validation loss: 5.120275373084341

Epoch: 5| Step: 7
Training loss: 4.592158865928612
Validation loss: 5.0928575740689785

Epoch: 5| Step: 8
Training loss: 4.701025408629284
Validation loss: 5.063594831899286

Epoch: 5| Step: 9
Training loss: 5.207095352545222
Validation loss: 5.034641208055813

Epoch: 5| Step: 10
Training loss: 4.568003431449176
Validation loss: 5.007562064586504

Epoch: 6| Step: 0
Training loss: 4.416474728042435
Validation loss: 4.98044341037263

Epoch: 5| Step: 1
Training loss: 5.609661636892186
Validation loss: 4.952978516357398

Epoch: 5| Step: 2
Training loss: 4.995171695236569
Validation loss: 4.9276182044835775

Epoch: 5| Step: 3
Training loss: 4.517042313798758
Validation loss: 4.900894005716072

Epoch: 5| Step: 4
Training loss: 6.167736510530429
Validation loss: 4.874690466457461

Epoch: 5| Step: 5
Training loss: 5.584289734567827
Validation loss: 4.84875387538327

Epoch: 5| Step: 6
Training loss: 4.831152698084787
Validation loss: 4.823467274857915

Epoch: 5| Step: 7
Training loss: 3.0421658633206725
Validation loss: 4.796626205435022

Epoch: 5| Step: 8
Training loss: 4.43624967771235
Validation loss: 4.774147417668194

Epoch: 5| Step: 9
Training loss: 5.72261258782405
Validation loss: 4.751263589106486

Epoch: 5| Step: 10
Training loss: 3.8540610359082095
Validation loss: 4.729582552475876

Epoch: 7| Step: 0
Training loss: 3.2241339237709474
Validation loss: 4.706859316872989

Epoch: 5| Step: 1
Training loss: 4.954659113085368
Validation loss: 4.68421186731038

Epoch: 5| Step: 2
Training loss: 4.594910766930592
Validation loss: 4.662367562527742

Epoch: 5| Step: 3
Training loss: 5.60270613271136
Validation loss: 4.6435387752556165

Epoch: 5| Step: 4
Training loss: 5.01353035323246
Validation loss: 4.623005546441481

Epoch: 5| Step: 5
Training loss: 4.585439001800525
Validation loss: 4.603290182480802

Epoch: 5| Step: 6
Training loss: 4.95045702587293
Validation loss: 4.5823362114157185

Epoch: 5| Step: 7
Training loss: 4.598814994101805
Validation loss: 4.561263137723958

Epoch: 5| Step: 8
Training loss: 4.128487932998598
Validation loss: 4.541282015848738

Epoch: 5| Step: 9
Training loss: 4.670624326350857
Validation loss: 4.521696830582285

Epoch: 5| Step: 10
Training loss: 4.942029782485298
Validation loss: 4.503480349289089

Epoch: 8| Step: 0
Training loss: 4.646178958278891
Validation loss: 4.484382477606479

Epoch: 5| Step: 1
Training loss: 4.709719878530836
Validation loss: 4.46503164193012

Epoch: 5| Step: 2
Training loss: 4.233039222973539
Validation loss: 4.44703101618193

Epoch: 5| Step: 3
Training loss: 4.476585294921785
Validation loss: 4.430685282509054

Epoch: 5| Step: 4
Training loss: 4.15638468818124
Validation loss: 4.411878344869625

Epoch: 5| Step: 5
Training loss: 5.087281408464274
Validation loss: 4.396381685531659

Epoch: 5| Step: 6
Training loss: 4.813973733739192
Validation loss: 4.379508681105812

Epoch: 5| Step: 7
Training loss: 4.294785313952763
Validation loss: 4.3619731938176285

Epoch: 5| Step: 8
Training loss: 4.6467639122250475
Validation loss: 4.345100859106014

Epoch: 5| Step: 9
Training loss: 4.0988079012742045
Validation loss: 4.329321657670986

Epoch: 5| Step: 10
Training loss: 4.275441259621928
Validation loss: 4.315499383692416

Epoch: 9| Step: 0
Training loss: 4.7237736316421906
Validation loss: 4.299251186802771

Epoch: 5| Step: 1
Training loss: 4.1933978096311515
Validation loss: 4.282343333888772

Epoch: 5| Step: 2
Training loss: 4.7714274118453055
Validation loss: 4.268819212877524

Epoch: 5| Step: 3
Training loss: 4.4565313862992495
Validation loss: 4.252577427807636

Epoch: 5| Step: 4
Training loss: 3.786767386408826
Validation loss: 4.239856505675562

Epoch: 5| Step: 5
Training loss: 4.3227269632776775
Validation loss: 4.22596667224044

Epoch: 5| Step: 6
Training loss: 4.092557777178705
Validation loss: 4.209848813138612

Epoch: 5| Step: 7
Training loss: 4.4951113531558375
Validation loss: 4.198466524370751

Epoch: 5| Step: 8
Training loss: 4.229876729553332
Validation loss: 4.185109913004366

Epoch: 5| Step: 9
Training loss: 4.049610759727144
Validation loss: 4.173771154657208

Epoch: 5| Step: 10
Training loss: 4.682824816988306
Validation loss: 4.164673639085898

Epoch: 10| Step: 0
Training loss: 3.9932496809649116
Validation loss: 4.154170897114863

Epoch: 5| Step: 1
Training loss: 4.528266082103298
Validation loss: 4.145295058972415

Epoch: 5| Step: 2
Training loss: 4.294169514025447
Validation loss: 4.135703906360453

Epoch: 5| Step: 3
Training loss: 4.155458991707498
Validation loss: 4.126663108909102

Epoch: 5| Step: 4
Training loss: 5.186926752612079
Validation loss: 4.116661552351958

Epoch: 5| Step: 5
Training loss: 3.795602844364573
Validation loss: 4.108981393103543

Epoch: 5| Step: 6
Training loss: 4.469721761829681
Validation loss: 4.098828335003428

Epoch: 5| Step: 7
Training loss: 4.59185232812911
Validation loss: 4.0914628773443855

Epoch: 5| Step: 8
Training loss: 4.304857198759209
Validation loss: 4.0794074242716425

Epoch: 5| Step: 9
Training loss: 3.4587031400351016
Validation loss: 4.069408812821817

Epoch: 5| Step: 10
Training loss: 3.5606402177236047
Validation loss: 4.060368685443936

Epoch: 11| Step: 0
Training loss: 4.802543943522825
Validation loss: 4.052093882074736

Epoch: 5| Step: 1
Training loss: 3.738358802748331
Validation loss: 4.041935469773195

Epoch: 5| Step: 2
Training loss: 4.1745135360829115
Validation loss: 4.033079216437794

Epoch: 5| Step: 3
Training loss: 4.344484774789069
Validation loss: 4.026777447949958

Epoch: 5| Step: 4
Training loss: 4.392345810747534
Validation loss: 4.01549405867277

Epoch: 5| Step: 5
Training loss: 3.5808251200448535
Validation loss: 4.00802851147608

Epoch: 5| Step: 6
Training loss: 4.997934296187166
Validation loss: 4.0006461570142084

Epoch: 5| Step: 7
Training loss: 4.658635290159944
Validation loss: 3.992586565955426

Epoch: 5| Step: 8
Training loss: 2.8309165707728425
Validation loss: 3.983423985020271

Epoch: 5| Step: 9
Training loss: 3.9511750127428225
Validation loss: 3.9748481071883

Epoch: 5| Step: 10
Training loss: 3.7415978717780773
Validation loss: 3.9666082500610735

Epoch: 12| Step: 0
Training loss: 3.7690689989405093
Validation loss: 3.962272464224225

Epoch: 5| Step: 1
Training loss: 3.6099126506181247
Validation loss: 3.953953129122788

Epoch: 5| Step: 2
Training loss: 4.741350027729362
Validation loss: 3.946684503037602

Epoch: 5| Step: 3
Training loss: 3.243368866566715
Validation loss: 3.942428951980075

Epoch: 5| Step: 4
Training loss: 4.258886359349189
Validation loss: 3.9357226036015125

Epoch: 5| Step: 5
Training loss: 4.280015976421449
Validation loss: 3.928392663933552

Epoch: 5| Step: 6
Training loss: 4.7843065651871
Validation loss: 3.9198608115730087

Epoch: 5| Step: 7
Training loss: 3.61353818237688
Validation loss: 3.914543075357571

Epoch: 5| Step: 8
Training loss: 4.629673426668198
Validation loss: 3.9100841896542495

Epoch: 5| Step: 9
Training loss: 3.304211737833255
Validation loss: 3.9031328603630433

Epoch: 5| Step: 10
Training loss: 4.333600598431807
Validation loss: 3.8947187119746105

Epoch: 13| Step: 0
Training loss: 4.367496268014782
Validation loss: 3.889434021998049

Epoch: 5| Step: 1
Training loss: 3.95875239245406
Validation loss: 3.886946544587353

Epoch: 5| Step: 2
Training loss: 3.5385264818106967
Validation loss: 3.87783325120688

Epoch: 5| Step: 3
Training loss: 3.86101012398974
Validation loss: 3.8727782989533974

Epoch: 5| Step: 4
Training loss: 4.175405544297534
Validation loss: 3.8653940625683556

Epoch: 5| Step: 5
Training loss: 4.4592127898132405
Validation loss: 3.8572131146616213

Epoch: 5| Step: 6
Training loss: 3.4294972986126417
Validation loss: 3.8532145265570974

Epoch: 5| Step: 7
Training loss: 3.007963102459343
Validation loss: 3.847325575224766

Epoch: 5| Step: 8
Training loss: 4.840848385881629
Validation loss: 3.8391801327029125

Epoch: 5| Step: 9
Training loss: 3.943426244054447
Validation loss: 3.833701388027609

Epoch: 5| Step: 10
Training loss: 4.362928466742058
Validation loss: 3.8265559986035003

Epoch: 14| Step: 0
Training loss: 4.4842529280260015
Validation loss: 3.8210415185144964

Epoch: 5| Step: 1
Training loss: 4.0687916087002165
Validation loss: 3.8157001246458675

Epoch: 5| Step: 2
Training loss: 3.8087305914919862
Validation loss: 3.8075784271919075

Epoch: 5| Step: 3
Training loss: 4.218244960366135
Validation loss: 3.8011247456716357

Epoch: 5| Step: 4
Training loss: 4.7340194518282335
Validation loss: 3.7947965741891796

Epoch: 5| Step: 5
Training loss: 3.6018757383950475
Validation loss: 3.7860231090870693

Epoch: 5| Step: 6
Training loss: 4.344560067366439
Validation loss: 3.7799225533711764

Epoch: 5| Step: 7
Training loss: 3.0160795669684624
Validation loss: 3.77497108272915

Epoch: 5| Step: 8
Training loss: 3.203718623537159
Validation loss: 3.765368484571724

Epoch: 5| Step: 9
Training loss: 3.6141145312385534
Validation loss: 3.75763202628098

Epoch: 5| Step: 10
Training loss: 4.121249487948885
Validation loss: 3.7490917678329243

Epoch: 15| Step: 0
Training loss: 3.6541669079306742
Validation loss: 3.7398789103600083

Epoch: 5| Step: 1
Training loss: 3.2757501922306917
Validation loss: 3.7335743724854518

Epoch: 5| Step: 2
Training loss: 4.282957084745364
Validation loss: 3.723621666018566

Epoch: 5| Step: 3
Training loss: 3.4186186603095554
Validation loss: 3.7152815061687297

Epoch: 5| Step: 4
Training loss: 4.2111789159983255
Validation loss: 3.710107541840923

Epoch: 5| Step: 5
Training loss: 4.310077373757163
Validation loss: 3.703396766915104

Epoch: 5| Step: 6
Training loss: 4.388087941306515
Validation loss: 3.6970768757331767

Epoch: 5| Step: 7
Training loss: 3.138312556001667
Validation loss: 3.6914065861326084

Epoch: 5| Step: 8
Training loss: 3.5524817697270685
Validation loss: 3.682937612524624

Epoch: 5| Step: 9
Training loss: 3.6108458853587893
Validation loss: 3.6794349951806264

Epoch: 5| Step: 10
Training loss: 4.669117397575142
Validation loss: 3.6742497494026356

Epoch: 16| Step: 0
Training loss: 3.632701847483154
Validation loss: 3.6705900877768936

Epoch: 5| Step: 1
Training loss: 3.8866704123093454
Validation loss: 3.6610966257560915

Epoch: 5| Step: 2
Training loss: 3.3707183239857526
Validation loss: 3.654220571751876

Epoch: 5| Step: 3
Training loss: 3.17089076815172
Validation loss: 3.6490027189739487

Epoch: 5| Step: 4
Training loss: 4.570696014224022
Validation loss: 3.644342202049575

Epoch: 5| Step: 5
Training loss: 3.9162278572087246
Validation loss: 3.6384255419195557

Epoch: 5| Step: 6
Training loss: 3.404227680109317
Validation loss: 3.6325241830105783

Epoch: 5| Step: 7
Training loss: 4.494941623465677
Validation loss: 3.629509773695651

Epoch: 5| Step: 8
Training loss: 3.7652420545686285
Validation loss: 3.622092255129321

Epoch: 5| Step: 9
Training loss: 3.9144942298697534
Validation loss: 3.6176973079888275

Epoch: 5| Step: 10
Training loss: 3.7185624019202765
Validation loss: 3.61132122771586

Epoch: 17| Step: 0
Training loss: 3.7747497172470186
Validation loss: 3.6064409891094202

Epoch: 5| Step: 1
Training loss: 3.4894651174686175
Validation loss: 3.6047426131433338

Epoch: 5| Step: 2
Training loss: 4.2112294168442
Validation loss: 3.601660741729114

Epoch: 5| Step: 3
Training loss: 3.8432706208308316
Validation loss: 3.594070721297345

Epoch: 5| Step: 4
Training loss: 2.706765077834512
Validation loss: 3.5929598788162704

Epoch: 5| Step: 5
Training loss: 4.746182564112422
Validation loss: 3.586762642929396

Epoch: 5| Step: 6
Training loss: 4.285948910421605
Validation loss: 3.5838915043653543

Epoch: 5| Step: 7
Training loss: 3.4610335291506185
Validation loss: 3.5796977289737377

Epoch: 5| Step: 8
Training loss: 2.8784830307664913
Validation loss: 3.57510646584377

Epoch: 5| Step: 9
Training loss: 4.03698110169038
Validation loss: 3.5724394846848844

Epoch: 5| Step: 10
Training loss: 3.7183942865094726
Validation loss: 3.5660414508774507

Epoch: 18| Step: 0
Training loss: 2.8943447614098066
Validation loss: 3.561578537529188

Epoch: 5| Step: 1
Training loss: 3.8085924979965893
Validation loss: 3.5566221406552985

Epoch: 5| Step: 2
Training loss: 3.9121299739301048
Validation loss: 3.554993820830044

Epoch: 5| Step: 3
Training loss: 4.057666426634154
Validation loss: 3.550183880168806

Epoch: 5| Step: 4
Training loss: 4.037574951609959
Validation loss: 3.545550138464747

Epoch: 5| Step: 5
Training loss: 3.8342373376336147
Validation loss: 3.541373061304137

Epoch: 5| Step: 6
Training loss: 3.2677195279569378
Validation loss: 3.5374045107177987

Epoch: 5| Step: 7
Training loss: 3.8113043739491324
Validation loss: 3.5338005752061226

Epoch: 5| Step: 8
Training loss: 4.3640835399236595
Validation loss: 3.529673583212038

Epoch: 5| Step: 9
Training loss: 3.089879707291173
Validation loss: 3.524998165989194

Epoch: 5| Step: 10
Training loss: 3.864373803777878
Validation loss: 3.5200619877790222

Epoch: 19| Step: 0
Training loss: 2.821511729568742
Validation loss: 3.516376184494719

Epoch: 5| Step: 1
Training loss: 3.7374977239391325
Validation loss: 3.5152426322361787

Epoch: 5| Step: 2
Training loss: 3.334018128307465
Validation loss: 3.5119454707625493

Epoch: 5| Step: 3
Training loss: 4.045532710924624
Validation loss: 3.5088051846331045

Epoch: 5| Step: 4
Training loss: 3.869694184435598
Validation loss: 3.5065555545462734

Epoch: 5| Step: 5
Training loss: 3.4640212260029846
Validation loss: 3.5039659654785233

Epoch: 5| Step: 6
Training loss: 4.07854661187168
Validation loss: 3.5012645033976226

Epoch: 5| Step: 7
Training loss: 3.2374412266172157
Validation loss: 3.4986116509409864

Epoch: 5| Step: 8
Training loss: 3.385389372886771
Validation loss: 3.496406999171744

Epoch: 5| Step: 9
Training loss: 4.52976681342795
Validation loss: 3.489833221279723

Epoch: 5| Step: 10
Training loss: 4.030560101758405
Validation loss: 3.489329304798222

Epoch: 20| Step: 0
Training loss: 4.608987669107433
Validation loss: 3.4855813060428407

Epoch: 5| Step: 1
Training loss: 4.290949838765169
Validation loss: 3.480874009920011

Epoch: 5| Step: 2
Training loss: 3.1699564726816503
Validation loss: 3.47596475389984

Epoch: 5| Step: 3
Training loss: 3.3339720749809723
Validation loss: 3.4734524321313898

Epoch: 5| Step: 4
Training loss: 3.63669436207921
Validation loss: 3.473284088253164

Epoch: 5| Step: 5
Training loss: 3.321820946412436
Validation loss: 3.4720316149716988

Epoch: 5| Step: 6
Training loss: 2.843148639519462
Validation loss: 3.467208346776258

Epoch: 5| Step: 7
Training loss: 3.117243486633031
Validation loss: 3.463763594319656

Epoch: 5| Step: 8
Training loss: 3.8722866772383697
Validation loss: 3.4631521739521673

Epoch: 5| Step: 9
Training loss: 3.598942993543572
Validation loss: 3.4626793006705565

Epoch: 5| Step: 10
Training loss: 4.4019061381321825
Validation loss: 3.4555151054791486

Epoch: 21| Step: 0
Training loss: 3.5057083989950133
Validation loss: 3.4492551617502913

Epoch: 5| Step: 1
Training loss: 3.3164249415146116
Validation loss: 3.4488083639607092

Epoch: 5| Step: 2
Training loss: 3.2792692472965146
Validation loss: 3.4477151404686426

Epoch: 5| Step: 3
Training loss: 4.31295685490539
Validation loss: 3.445112558783509

Epoch: 5| Step: 4
Training loss: 3.658568861439074
Validation loss: 3.441985882085855

Epoch: 5| Step: 5
Training loss: 3.5632977847213523
Validation loss: 3.433222104353711

Epoch: 5| Step: 6
Training loss: 3.6337381475706065
Validation loss: 3.430667057566551

Epoch: 5| Step: 7
Training loss: 3.433139879523269
Validation loss: 3.4349189935462685

Epoch: 5| Step: 8
Training loss: 4.160153728358978
Validation loss: 3.4379111811285865

Epoch: 5| Step: 9
Training loss: 3.823149020057344
Validation loss: 3.4211084489909136

Epoch: 5| Step: 10
Training loss: 3.305076630320029
Validation loss: 3.419041204396102

Epoch: 22| Step: 0
Training loss: 3.324406655511033
Validation loss: 3.425092439337429

Epoch: 5| Step: 1
Training loss: 3.6713651262519216
Validation loss: 3.4240671821541735

Epoch: 5| Step: 2
Training loss: 4.210726872486238
Validation loss: 3.4242068275957465

Epoch: 5| Step: 3
Training loss: 3.076971932170052
Validation loss: 3.4159101948846122

Epoch: 5| Step: 4
Training loss: 3.486334143027019
Validation loss: 3.4146988231762823

Epoch: 5| Step: 5
Training loss: 3.640739995752897
Validation loss: 3.411192391193572

Epoch: 5| Step: 6
Training loss: 3.380512398247791
Validation loss: 3.4078990222004673

Epoch: 5| Step: 7
Training loss: 3.471232445260023
Validation loss: 3.406390247917917

Epoch: 5| Step: 8
Training loss: 3.8263245377357387
Validation loss: 3.4119338358531435

Epoch: 5| Step: 9
Training loss: 4.067401921661293
Validation loss: 3.404598724310647

Epoch: 5| Step: 10
Training loss: 3.697942011929905
Validation loss: 3.3978035669010196

Epoch: 23| Step: 0
Training loss: 3.595438021740365
Validation loss: 3.3926238150085672

Epoch: 5| Step: 1
Training loss: 3.5128108311297854
Validation loss: 3.393914800650071

Epoch: 5| Step: 2
Training loss: 2.3090256030487555
Validation loss: 3.3935817035819302

Epoch: 5| Step: 3
Training loss: 3.3714221781099676
Validation loss: 3.3933976489601303

Epoch: 5| Step: 4
Training loss: 3.4303435304288943
Validation loss: 3.386163569269059

Epoch: 5| Step: 5
Training loss: 4.245799513293118
Validation loss: 3.378794555600946

Epoch: 5| Step: 6
Training loss: 2.8577886464670503
Validation loss: 3.370125337606073

Epoch: 5| Step: 7
Training loss: 4.6580153837298
Validation loss: 3.3687679066179155

Epoch: 5| Step: 8
Training loss: 3.602486382272728
Validation loss: 3.3702303606928483

Epoch: 5| Step: 9
Training loss: 3.512810966872122
Validation loss: 3.365849702005774

Epoch: 5| Step: 10
Training loss: 4.082473249096661
Validation loss: 3.3593937088487618

Epoch: 24| Step: 0
Training loss: 3.5532181941470022
Validation loss: 3.360012200629296

Epoch: 5| Step: 1
Training loss: 3.982283817609149
Validation loss: 3.3571461416246455

Epoch: 5| Step: 2
Training loss: 3.2101963793617645
Validation loss: 3.351632841831947

Epoch: 5| Step: 3
Training loss: 4.252489594946348
Validation loss: 3.35064020481522

Epoch: 5| Step: 4
Training loss: 3.4906790460212096
Validation loss: 3.3486519848226286

Epoch: 5| Step: 5
Training loss: 3.963537923816947
Validation loss: 3.349859757687469

Epoch: 5| Step: 6
Training loss: 3.07704678158411
Validation loss: 3.3423642405620866

Epoch: 5| Step: 7
Training loss: 3.6520766216650897
Validation loss: 3.340022041739798

Epoch: 5| Step: 8
Training loss: 2.5464404150768227
Validation loss: 3.3372209141678355

Epoch: 5| Step: 9
Training loss: 3.1525128589824667
Validation loss: 3.3354417782677066

Epoch: 5| Step: 10
Training loss: 4.187794006047213
Validation loss: 3.3313101340281848

Epoch: 25| Step: 0
Training loss: 2.946665809625469
Validation loss: 3.326846972571332

Epoch: 5| Step: 1
Training loss: 3.5882103725071866
Validation loss: 3.3225213984997395

Epoch: 5| Step: 2
Training loss: 3.4846018901219695
Validation loss: 3.3229230487916626

Epoch: 5| Step: 3
Training loss: 3.0800180568413476
Validation loss: 3.320722161536086

Epoch: 5| Step: 4
Training loss: 3.8476103959037995
Validation loss: 3.3205072863854683

Epoch: 5| Step: 5
Training loss: 3.2731301247580475
Validation loss: 3.316230485860571

Epoch: 5| Step: 6
Training loss: 4.012873200265756
Validation loss: 3.312594332892895

Epoch: 5| Step: 7
Training loss: 3.785011879261076
Validation loss: 3.3084747707213817

Epoch: 5| Step: 8
Training loss: 3.284856939118298
Validation loss: 3.3072850851365385

Epoch: 5| Step: 9
Training loss: 3.10444426522072
Validation loss: 3.3036933364892302

Epoch: 5| Step: 10
Training loss: 4.503125271079104
Validation loss: 3.300155936329633

Epoch: 26| Step: 0
Training loss: 3.84153025971788
Validation loss: 3.299641689985578

Epoch: 5| Step: 1
Training loss: 4.005448921560781
Validation loss: 3.294628471790385

Epoch: 5| Step: 2
Training loss: 2.934039248432156
Validation loss: 3.2939597948655375

Epoch: 5| Step: 3
Training loss: 3.7918756168906342
Validation loss: 3.291566256612532

Epoch: 5| Step: 4
Training loss: 3.5124825908188733
Validation loss: 3.2912468653554763

Epoch: 5| Step: 5
Training loss: 2.281666025347883
Validation loss: 3.288850701048123

Epoch: 5| Step: 6
Training loss: 3.4676514681714936
Validation loss: 3.2871233236126725

Epoch: 5| Step: 7
Training loss: 3.70689296966967
Validation loss: 3.281572011059167

Epoch: 5| Step: 8
Training loss: 3.177548150418807
Validation loss: 3.280578897799798

Epoch: 5| Step: 9
Training loss: 3.392912062580505
Validation loss: 3.2760590307088986

Epoch: 5| Step: 10
Training loss: 4.367646931893613
Validation loss: 3.2731328284952905

Epoch: 27| Step: 0
Training loss: 3.156883553852281
Validation loss: 3.274154089299875

Epoch: 5| Step: 1
Training loss: 3.5847695303965597
Validation loss: 3.27077392739458

Epoch: 5| Step: 2
Training loss: 3.8220159871132817
Validation loss: 3.266574901043615

Epoch: 5| Step: 3
Training loss: 4.054023232557651
Validation loss: 3.265072269002637

Epoch: 5| Step: 4
Training loss: 3.522037067086136
Validation loss: 3.260832893301508

Epoch: 5| Step: 5
Training loss: 3.01590312406542
Validation loss: 3.2586936346328867

Epoch: 5| Step: 6
Training loss: 3.747209273469039
Validation loss: 3.2543451560537893

Epoch: 5| Step: 7
Training loss: 2.9254948841311683
Validation loss: 3.2517809409536538

Epoch: 5| Step: 8
Training loss: 2.6703676132130694
Validation loss: 3.253275883895456

Epoch: 5| Step: 9
Training loss: 4.2509773476983534
Validation loss: 3.2488440421213443

Epoch: 5| Step: 10
Training loss: 3.4348966971110237
Validation loss: 3.2513676929476993

Epoch: 28| Step: 0
Training loss: 3.4353038361394233
Validation loss: 3.2479832010283816

Epoch: 5| Step: 1
Training loss: 3.576416140620198
Validation loss: 3.242737666396249

Epoch: 5| Step: 2
Training loss: 4.020866802385935
Validation loss: 3.238991443153471

Epoch: 5| Step: 3
Training loss: 3.0994518410660765
Validation loss: 3.2381619483246524

Epoch: 5| Step: 4
Training loss: 3.0298118719234113
Validation loss: 3.237910152213302

Epoch: 5| Step: 5
Training loss: 3.955601334991523
Validation loss: 3.2366617631710866

Epoch: 5| Step: 6
Training loss: 3.6855656350956694
Validation loss: 3.2289952756959406

Epoch: 5| Step: 7
Training loss: 2.706559837876462
Validation loss: 3.229471168623439

Epoch: 5| Step: 8
Training loss: 3.725320605107679
Validation loss: 3.2281292066828713

Epoch: 5| Step: 9
Training loss: 3.463919222720236
Validation loss: 3.2278504075008434

Epoch: 5| Step: 10
Training loss: 3.3723897376674317
Validation loss: 3.226262349245748

Epoch: 29| Step: 0
Training loss: 3.989104332650378
Validation loss: 3.2243671985295994

Epoch: 5| Step: 1
Training loss: 3.343170686253808
Validation loss: 3.2254693486852593

Epoch: 5| Step: 2
Training loss: 3.2663674126656246
Validation loss: 3.212736698695769

Epoch: 5| Step: 3
Training loss: 3.467830226715726
Validation loss: 3.208417943811775

Epoch: 5| Step: 4
Training loss: 3.043559456565522
Validation loss: 3.2109730928653564

Epoch: 5| Step: 5
Training loss: 4.146925943574848
Validation loss: 3.208549145995305

Epoch: 5| Step: 6
Training loss: 2.9787893701049417
Validation loss: 3.205587124016988

Epoch: 5| Step: 7
Training loss: 3.308847536984781
Validation loss: 3.200813805441917

Epoch: 5| Step: 8
Training loss: 3.4042669000580807
Validation loss: 3.201672064169314

Epoch: 5| Step: 9
Training loss: 3.85631424465484
Validation loss: 3.200241837797361

Epoch: 5| Step: 10
Training loss: 2.9940044573672338
Validation loss: 3.1995237261368183

Epoch: 30| Step: 0
Training loss: 3.4054690524453584
Validation loss: 3.1961044339860116

Epoch: 5| Step: 1
Training loss: 2.5757458430718287
Validation loss: 3.1955915531230863

Epoch: 5| Step: 2
Training loss: 3.4164250141067285
Validation loss: 3.1940615519189297

Epoch: 5| Step: 3
Training loss: 3.6509296800940576
Validation loss: 3.187414441216102

Epoch: 5| Step: 4
Training loss: 3.1517404501307267
Validation loss: 3.1850542774927577

Epoch: 5| Step: 5
Training loss: 3.4578506102187716
Validation loss: 3.186041269566422

Epoch: 5| Step: 6
Training loss: 3.5085603388348785
Validation loss: 3.1798195828753797

Epoch: 5| Step: 7
Training loss: 3.582102201834449
Validation loss: 3.1794787874557366

Epoch: 5| Step: 8
Training loss: 3.7264799672710125
Validation loss: 3.1765576558963184

Epoch: 5| Step: 9
Training loss: 3.6695338800854156
Validation loss: 3.1763135849361266

Epoch: 5| Step: 10
Training loss: 3.559962389457994
Validation loss: 3.1725999452382054

Epoch: 31| Step: 0
Training loss: 3.3943180065536374
Validation loss: 3.1719114272299413

Epoch: 5| Step: 1
Training loss: 3.2431258348959013
Validation loss: 3.16869410349252

Epoch: 5| Step: 2
Training loss: 3.621770406665927
Validation loss: 3.169877450634851

Epoch: 5| Step: 3
Training loss: 3.545314764944255
Validation loss: 3.168100300231844

Epoch: 5| Step: 4
Training loss: 2.960786277110042
Validation loss: 3.1635498992848348

Epoch: 5| Step: 5
Training loss: 4.092044853762612
Validation loss: 3.162233363518789

Epoch: 5| Step: 6
Training loss: 3.3594783323497333
Validation loss: 3.1619609919635687

Epoch: 5| Step: 7
Training loss: 3.1736568463399304
Validation loss: 3.1581166377611876

Epoch: 5| Step: 8
Training loss: 3.142146562777213
Validation loss: 3.156252896455703

Epoch: 5| Step: 9
Training loss: 3.4992664113325906
Validation loss: 3.153010039611656

Epoch: 5| Step: 10
Training loss: 3.4645346382161364
Validation loss: 3.1495097587986765

Epoch: 32| Step: 0
Training loss: 3.786210518571621
Validation loss: 3.153305442745858

Epoch: 5| Step: 1
Training loss: 3.6236014463536965
Validation loss: 3.1460913101638632

Epoch: 5| Step: 2
Training loss: 3.3701405332337577
Validation loss: 3.1525719345520122

Epoch: 5| Step: 3
Training loss: 3.2029375719268467
Validation loss: 3.1481960485678675

Epoch: 5| Step: 4
Training loss: 3.7748252575579784
Validation loss: 3.1452089855615353

Epoch: 5| Step: 5
Training loss: 2.808365304540408
Validation loss: 3.1429061184660108

Epoch: 5| Step: 6
Training loss: 2.783878498785857
Validation loss: 3.14004409275353

Epoch: 5| Step: 7
Training loss: 3.7740462860519735
Validation loss: 3.1439936193626203

Epoch: 5| Step: 8
Training loss: 3.3499380589922065
Validation loss: 3.1442502123905287

Epoch: 5| Step: 9
Training loss: 3.1513287542202404
Validation loss: 3.140253858003245

Epoch: 5| Step: 10
Training loss: 3.6903745147949745
Validation loss: 3.1374925593132805

Epoch: 33| Step: 0
Training loss: 3.012429238908956
Validation loss: 3.1348755186584802

Epoch: 5| Step: 1
Training loss: 2.89753252486767
Validation loss: 3.1317934777595053

Epoch: 5| Step: 2
Training loss: 3.1514109161340897
Validation loss: 3.1288155640430433

Epoch: 5| Step: 3
Training loss: 3.233208192455178
Validation loss: 3.1289113118835368

Epoch: 5| Step: 4
Training loss: 3.4545169286143333
Validation loss: 3.123172122061734

Epoch: 5| Step: 5
Training loss: 3.773103118676329
Validation loss: 3.1240866690251043

Epoch: 5| Step: 6
Training loss: 3.2463469882793716
Validation loss: 3.1186064734619543

Epoch: 5| Step: 7
Training loss: 3.338681666889964
Validation loss: 3.1191353302765563

Epoch: 5| Step: 8
Training loss: 3.8531185202687177
Validation loss: 3.1188330081940254

Epoch: 5| Step: 9
Training loss: 3.684901728361377
Validation loss: 3.1189326939137394

Epoch: 5| Step: 10
Training loss: 3.504309317413955
Validation loss: 3.115022455013143

Epoch: 34| Step: 0
Training loss: 2.850270268525021
Validation loss: 3.111709825404605

Epoch: 5| Step: 1
Training loss: 3.588928703766997
Validation loss: 3.1142302962712183

Epoch: 5| Step: 2
Training loss: 3.1993864246066805
Validation loss: 3.1199040198622736

Epoch: 5| Step: 3
Training loss: 3.7852026087202386
Validation loss: 3.115054582012181

Epoch: 5| Step: 4
Training loss: 3.7369295584368776
Validation loss: 3.1100689051937

Epoch: 5| Step: 5
Training loss: 3.5817788470915755
Validation loss: 3.105024343299432

Epoch: 5| Step: 6
Training loss: 3.4371212837367566
Validation loss: 3.1037353383333084

Epoch: 5| Step: 7
Training loss: 3.4421308363009486
Validation loss: 3.10008522668097

Epoch: 5| Step: 8
Training loss: 2.759239800015
Validation loss: 3.1027315424083817

Epoch: 5| Step: 9
Training loss: 3.325116297473463
Validation loss: 3.0955297961211534

Epoch: 5| Step: 10
Training loss: 3.2184914790655994
Validation loss: 3.0968470811063984

Epoch: 35| Step: 0
Training loss: 3.0086714669895174
Validation loss: 3.092656981296148

Epoch: 5| Step: 1
Training loss: 3.4388070135961124
Validation loss: 3.089828770575806

Epoch: 5| Step: 2
Training loss: 3.868769404989702
Validation loss: 3.0917317990037647

Epoch: 5| Step: 3
Training loss: 3.8316865507397804
Validation loss: 3.084722255702915

Epoch: 5| Step: 4
Training loss: 3.391846326963724
Validation loss: 3.0861330646663085

Epoch: 5| Step: 5
Training loss: 2.398928713122191
Validation loss: 3.0875727590751363

Epoch: 5| Step: 6
Training loss: 3.743907047601356
Validation loss: 3.083392228880778

Epoch: 5| Step: 7
Training loss: 3.0607090598480027
Validation loss: 3.083156762448207

Epoch: 5| Step: 8
Training loss: 3.244776562961228
Validation loss: 3.0795523839937964

Epoch: 5| Step: 9
Training loss: 3.07210963799612
Validation loss: 3.075018776763672

Epoch: 5| Step: 10
Training loss: 3.640012894282716
Validation loss: 3.0744535601429304

Epoch: 36| Step: 0
Training loss: 3.4800507265537393
Validation loss: 3.0789856699334064

Epoch: 5| Step: 1
Training loss: 3.143425750695295
Validation loss: 3.073207668891055

Epoch: 5| Step: 2
Training loss: 3.7014595503719274
Validation loss: 3.072037454714052

Epoch: 5| Step: 3
Training loss: 3.1888133316599707
Validation loss: 3.070482037419911

Epoch: 5| Step: 4
Training loss: 3.1445667335924994
Validation loss: 3.067136254099115

Epoch: 5| Step: 5
Training loss: 3.0798681909670207
Validation loss: 3.06532394802346

Epoch: 5| Step: 6
Training loss: 2.8425102465871825
Validation loss: 3.0673175561968367

Epoch: 5| Step: 7
Training loss: 3.5234862195218186
Validation loss: 3.0640855610302564

Epoch: 5| Step: 8
Training loss: 3.261875756419515
Validation loss: 3.067933730713995

Epoch: 5| Step: 9
Training loss: 3.8877660825871505
Validation loss: 3.0597443897871024

Epoch: 5| Step: 10
Training loss: 3.369842827638019
Validation loss: 3.057824362077665

Epoch: 37| Step: 0
Training loss: 3.0239457681526014
Validation loss: 3.0644643635093654

Epoch: 5| Step: 1
Training loss: 3.304933651533725
Validation loss: 3.06674103093859

Epoch: 5| Step: 2
Training loss: 3.31841081800546
Validation loss: 3.062446252226921

Epoch: 5| Step: 3
Training loss: 3.4845345635935265
Validation loss: 3.061519453271125

Epoch: 5| Step: 4
Training loss: 2.915867141857606
Validation loss: 3.0594313807286952

Epoch: 5| Step: 5
Training loss: 3.433088350043101
Validation loss: 3.059278282347769

Epoch: 5| Step: 6
Training loss: 3.1366545978223423
Validation loss: 3.0564795042120325

Epoch: 5| Step: 7
Training loss: 3.2766519937222305
Validation loss: 3.051217216903755

Epoch: 5| Step: 8
Training loss: 3.817633128065148
Validation loss: 3.050978939586103

Epoch: 5| Step: 9
Training loss: 3.1846327507965952
Validation loss: 3.0522729823905173

Epoch: 5| Step: 10
Training loss: 3.7239058199650055
Validation loss: 3.045707774813085

Epoch: 38| Step: 0
Training loss: 3.4210164983285214
Validation loss: 3.045213887785612

Epoch: 5| Step: 1
Training loss: 3.8031473978804557
Validation loss: 3.0460162454227007

Epoch: 5| Step: 2
Training loss: 3.6044796199574325
Validation loss: 3.0441138163347543

Epoch: 5| Step: 3
Training loss: 3.1074499564157776
Validation loss: 3.043603086567743

Epoch: 5| Step: 4
Training loss: 3.3450270736351375
Validation loss: 3.0480953072996817

Epoch: 5| Step: 5
Training loss: 3.9840092509824903
Validation loss: 3.040789400277152

Epoch: 5| Step: 6
Training loss: 3.394569036802415
Validation loss: 3.0425310905503955

Epoch: 5| Step: 7
Training loss: 2.784910129624335
Validation loss: 3.0386506193327505

Epoch: 5| Step: 8
Training loss: 2.3861005266473168
Validation loss: 3.0343605356547685

Epoch: 5| Step: 9
Training loss: 3.2850003562706416
Validation loss: 3.038527456820387

Epoch: 5| Step: 10
Training loss: 3.085139922395624
Validation loss: 3.038735546080503

Epoch: 39| Step: 0
Training loss: 3.3484529595456527
Validation loss: 3.0398637876369583

Epoch: 5| Step: 1
Training loss: 3.180692696610824
Validation loss: 3.0359332070433687

Epoch: 5| Step: 2
Training loss: 2.9827361874937197
Validation loss: 3.0380814769894595

Epoch: 5| Step: 3
Training loss: 3.085688713765022
Validation loss: 3.0427905939415214

Epoch: 5| Step: 4
Training loss: 3.308329277772764
Validation loss: 3.0418045694261435

Epoch: 5| Step: 5
Training loss: 3.25622973884239
Validation loss: 3.040291132268838

Epoch: 5| Step: 6
Training loss: 2.7906774979423856
Validation loss: 3.0339337549707412

Epoch: 5| Step: 7
Training loss: 3.9221771245446413
Validation loss: 3.0283356994501913

Epoch: 5| Step: 8
Training loss: 3.8410257749598933
Validation loss: 3.0300220234523794

Epoch: 5| Step: 9
Training loss: 3.679267616370287
Validation loss: 3.0223702809039024

Epoch: 5| Step: 10
Training loss: 2.703347610392031
Validation loss: 3.021732143708094

Epoch: 40| Step: 0
Training loss: 3.2071475194932946
Validation loss: 3.0268857420920092

Epoch: 5| Step: 1
Training loss: 3.52330690129187
Validation loss: 3.01848791865792

Epoch: 5| Step: 2
Training loss: 3.332434501261832
Validation loss: 3.0180461264298275

Epoch: 5| Step: 3
Training loss: 3.8664535288329795
Validation loss: 3.0180548977055555

Epoch: 5| Step: 4
Training loss: 2.784814500640665
Validation loss: 3.0199163236694924

Epoch: 5| Step: 5
Training loss: 3.4823190413956753
Validation loss: 3.016286112821065

Epoch: 5| Step: 6
Training loss: 2.960040517735895
Validation loss: 3.0132649958305975

Epoch: 5| Step: 7
Training loss: 2.9589748671980085
Validation loss: 3.0194271516339795

Epoch: 5| Step: 8
Training loss: 3.026026521645934
Validation loss: 3.020179404206831

Epoch: 5| Step: 9
Training loss: 3.7635602553424414
Validation loss: 3.0182358626496892

Epoch: 5| Step: 10
Training loss: 3.2047966293583863
Validation loss: 3.0144954731495246

Epoch: 41| Step: 0
Training loss: 2.7994218876619597
Validation loss: 3.0133437434604793

Epoch: 5| Step: 1
Training loss: 3.168219804517409
Validation loss: 3.0135536499495235

Epoch: 5| Step: 2
Training loss: 3.482218395713333
Validation loss: 3.021981019534221

Epoch: 5| Step: 3
Training loss: 3.7737636385731546
Validation loss: 3.01670132233393

Epoch: 5| Step: 4
Training loss: 3.2272644018439487
Validation loss: 3.0161857782798673

Epoch: 5| Step: 5
Training loss: 3.5210645851770854
Validation loss: 3.012540477218132

Epoch: 5| Step: 6
Training loss: 3.774096950617932
Validation loss: 3.0110804396617654

Epoch: 5| Step: 7
Training loss: 3.3663294997886735
Validation loss: 3.00799456352861

Epoch: 5| Step: 8
Training loss: 2.821169736140445
Validation loss: 3.0076619837602436

Epoch: 5| Step: 9
Training loss: 2.4666327560087127
Validation loss: 3.00786010039707

Epoch: 5| Step: 10
Training loss: 3.6309193918604126
Validation loss: 3.010277593135061

Epoch: 42| Step: 0
Training loss: 2.78760915978698
Validation loss: 3.010382436671329

Epoch: 5| Step: 1
Training loss: 3.9436539289135344
Validation loss: 3.0089018054320036

Epoch: 5| Step: 2
Training loss: 3.2108186945782418
Validation loss: 3.007537698837546

Epoch: 5| Step: 3
Training loss: 3.1543739710972973
Validation loss: 3.004098471692055

Epoch: 5| Step: 4
Training loss: 3.0281656835320927
Validation loss: 3.0052521544384283

Epoch: 5| Step: 5
Training loss: 3.4011156776090443
Validation loss: 3.0033914578930636

Epoch: 5| Step: 6
Training loss: 3.694365753126116
Validation loss: 2.9970159182514906

Epoch: 5| Step: 7
Training loss: 3.217361150559931
Validation loss: 2.996668791433173

Epoch: 5| Step: 8
Training loss: 2.9542356955601687
Validation loss: 2.991864693162437

Epoch: 5| Step: 9
Training loss: 2.605693481453087
Validation loss: 2.992395508204334

Epoch: 5| Step: 10
Training loss: 3.92543129950659
Validation loss: 2.994360992295933

Epoch: 43| Step: 0
Training loss: 3.822834329298765
Validation loss: 2.9960035825075124

Epoch: 5| Step: 1
Training loss: 3.457601967809171
Validation loss: 2.9965421974720723

Epoch: 5| Step: 2
Training loss: 3.363939599654987
Validation loss: 2.99047460251687

Epoch: 5| Step: 3
Training loss: 3.3673268442020285
Validation loss: 2.9962936633938844

Epoch: 5| Step: 4
Training loss: 2.8269343952329655
Validation loss: 2.988952008094379

Epoch: 5| Step: 5
Training loss: 3.398645293799994
Validation loss: 2.9891008668998666

Epoch: 5| Step: 6
Training loss: 2.632481223072929
Validation loss: 2.988516660818799

Epoch: 5| Step: 7
Training loss: 3.3682536762777815
Validation loss: 2.986504912556738

Epoch: 5| Step: 8
Training loss: 3.2818544830105205
Validation loss: 2.9887868454716604

Epoch: 5| Step: 9
Training loss: 3.1580726723985295
Validation loss: 2.987468210652663

Epoch: 5| Step: 10
Training loss: 3.2171529122374296
Validation loss: 2.98850870786198

Epoch: 44| Step: 0
Training loss: 3.1073258131561365
Validation loss: 2.98719944893403

Epoch: 5| Step: 1
Training loss: 3.398530384416728
Validation loss: 2.9886275033267324

Epoch: 5| Step: 2
Training loss: 2.3332338538989146
Validation loss: 2.986191438009634

Epoch: 5| Step: 3
Training loss: 3.186277267201699
Validation loss: 2.986065236074927

Epoch: 5| Step: 4
Training loss: 3.8212114458319792
Validation loss: 2.9888517114743713

Epoch: 5| Step: 5
Training loss: 3.152968863486249
Validation loss: 2.9902384850740673

Epoch: 5| Step: 6
Training loss: 3.488273868360751
Validation loss: 2.9908324308324907

Epoch: 5| Step: 7
Training loss: 2.7824298199271484
Validation loss: 2.988487963678486

Epoch: 5| Step: 8
Training loss: 3.506774476887627
Validation loss: 2.9873915845321806

Epoch: 5| Step: 9
Training loss: 2.9973878614561036
Validation loss: 2.980119802425092

Epoch: 5| Step: 10
Training loss: 3.967632586950528
Validation loss: 2.9798270578628525

Epoch: 45| Step: 0
Training loss: 3.6798691755343493
Validation loss: 2.9786630593936434

Epoch: 5| Step: 1
Training loss: 2.779632440871932
Validation loss: 2.9784666647838454

Epoch: 5| Step: 2
Training loss: 3.0499776057687566
Validation loss: 2.9745571465395027

Epoch: 5| Step: 3
Training loss: 3.5322007781319753
Validation loss: 2.9728139896079306

Epoch: 5| Step: 4
Training loss: 3.8152082235924785
Validation loss: 2.9728077400668296

Epoch: 5| Step: 5
Training loss: 3.088396777678035
Validation loss: 2.9717740643715067

Epoch: 5| Step: 6
Training loss: 3.485211464419511
Validation loss: 2.9726257620185845

Epoch: 5| Step: 7
Training loss: 3.0777634151718853
Validation loss: 2.969549751609895

Epoch: 5| Step: 8
Training loss: 2.7517070673798054
Validation loss: 2.9686070682506487

Epoch: 5| Step: 9
Training loss: 3.3230994163333363
Validation loss: 2.9678847463371256

Epoch: 5| Step: 10
Training loss: 3.057206854003985
Validation loss: 2.967743535139465

Epoch: 46| Step: 0
Training loss: 3.1046348747781076
Validation loss: 2.966529996262589

Epoch: 5| Step: 1
Training loss: 3.768182795972391
Validation loss: 2.969068443434109

Epoch: 5| Step: 2
Training loss: 2.5678788464449664
Validation loss: 2.9645721969641494

Epoch: 5| Step: 3
Training loss: 3.3165165284134717
Validation loss: 2.9664930848205375

Epoch: 5| Step: 4
Training loss: 3.2717854922055687
Validation loss: 2.9632194190004726

Epoch: 5| Step: 5
Training loss: 3.36056568424717
Validation loss: 2.962398464625783

Epoch: 5| Step: 6
Training loss: 3.200748511033597
Validation loss: 2.964887658117421

Epoch: 5| Step: 7
Training loss: 3.708758226262745
Validation loss: 2.9660122123833434

Epoch: 5| Step: 8
Training loss: 3.291752021423308
Validation loss: 2.963709883431416

Epoch: 5| Step: 9
Training loss: 3.1716497933250802
Validation loss: 2.96184234685411

Epoch: 5| Step: 10
Training loss: 2.7839461556138576
Validation loss: 2.961227523570267

Epoch: 47| Step: 0
Training loss: 3.2029674956512193
Validation loss: 2.9655448809477396

Epoch: 5| Step: 1
Training loss: 2.8662417148581807
Validation loss: 2.9666821811109507

Epoch: 5| Step: 2
Training loss: 3.096129148032095
Validation loss: 2.964471271811813

Epoch: 5| Step: 3
Training loss: 3.5494770470788026
Validation loss: 2.970083125408802

Epoch: 5| Step: 4
Training loss: 2.99697898708203
Validation loss: 2.9586763565828385

Epoch: 5| Step: 5
Training loss: 3.5702200779544806
Validation loss: 2.955307867719889

Epoch: 5| Step: 6
Training loss: 3.317154259679119
Validation loss: 2.9540356140721453

Epoch: 5| Step: 7
Training loss: 3.577459415016314
Validation loss: 2.953387272500843

Epoch: 5| Step: 8
Training loss: 3.092850525464134
Validation loss: 2.953075104024052

Epoch: 5| Step: 9
Training loss: 2.885196186184898
Validation loss: 2.950351986813095

Epoch: 5| Step: 10
Training loss: 3.4942446118015966
Validation loss: 2.95051635629473

Epoch: 48| Step: 0
Training loss: 2.4247915119330927
Validation loss: 2.950233942450306

Epoch: 5| Step: 1
Training loss: 2.689801317556687
Validation loss: 2.9528820907836484

Epoch: 5| Step: 2
Training loss: 3.6404724089115668
Validation loss: 2.948397124862141

Epoch: 5| Step: 3
Training loss: 3.791958109515622
Validation loss: 2.948381276385334

Epoch: 5| Step: 4
Training loss: 2.6110939257531935
Validation loss: 2.948104642530937

Epoch: 5| Step: 5
Training loss: 2.6296392045371584
Validation loss: 2.9475993312436812

Epoch: 5| Step: 6
Training loss: 3.6175985082198943
Validation loss: 2.9465222894837466

Epoch: 5| Step: 7
Training loss: 3.1039706857417864
Validation loss: 2.9472075436727585

Epoch: 5| Step: 8
Training loss: 3.72870707032891
Validation loss: 2.946993169025878

Epoch: 5| Step: 9
Training loss: 3.921639971130877
Validation loss: 2.9450829368231126

Epoch: 5| Step: 10
Training loss: 2.950726539239955
Validation loss: 2.944598648937215

Epoch: 49| Step: 0
Training loss: 3.128947701816559
Validation loss: 2.9418131751880705

Epoch: 5| Step: 1
Training loss: 2.761922049155104
Validation loss: 2.9420300430052495

Epoch: 5| Step: 2
Training loss: 3.273602538398139
Validation loss: 2.943012654718954

Epoch: 5| Step: 3
Training loss: 3.375809466458824
Validation loss: 2.941056058585557

Epoch: 5| Step: 4
Training loss: 3.4850277139664554
Validation loss: 2.943605481615432

Epoch: 5| Step: 5
Training loss: 3.1502976897521315
Validation loss: 2.9437260917844172

Epoch: 5| Step: 6
Training loss: 3.0371443866048664
Validation loss: 2.9411799817966107

Epoch: 5| Step: 7
Training loss: 3.0898037798161413
Validation loss: 2.9442695552644604

Epoch: 5| Step: 8
Training loss: 3.470721260328252
Validation loss: 2.9433669360664334

Epoch: 5| Step: 9
Training loss: 3.567496827624701
Validation loss: 2.940519707326775

Epoch: 5| Step: 10
Training loss: 3.1184468032143084
Validation loss: 2.9391293027187864

Epoch: 50| Step: 0
Training loss: 3.702130019037209
Validation loss: 2.9381889612264165

Epoch: 5| Step: 1
Training loss: 3.4607571453695036
Validation loss: 2.9346445693080017

Epoch: 5| Step: 2
Training loss: 3.7675080082738015
Validation loss: 2.9333951131359464

Epoch: 5| Step: 3
Training loss: 2.753354021260986
Validation loss: 2.9382985377379596

Epoch: 5| Step: 4
Training loss: 3.374879764251867
Validation loss: 2.938199131349552

Epoch: 5| Step: 5
Training loss: 3.11042836811567
Validation loss: 2.935787161482874

Epoch: 5| Step: 6
Training loss: 3.0062816340631935
Validation loss: 2.934205221957607

Epoch: 5| Step: 7
Training loss: 3.5356405864262106
Validation loss: 2.9321143639635

Epoch: 5| Step: 8
Training loss: 2.9333886126887037
Validation loss: 2.9308419072066605

Epoch: 5| Step: 9
Training loss: 2.82320300312223
Validation loss: 2.9322253477846925

Epoch: 5| Step: 10
Training loss: 2.732550486441139
Validation loss: 2.9296381726778145

Epoch: 51| Step: 0
Training loss: 3.0386334976968175
Validation loss: 2.9320186318191634

Epoch: 5| Step: 1
Training loss: 3.787248125923303
Validation loss: 2.938760428123644

Epoch: 5| Step: 2
Training loss: 3.2367879371697366
Validation loss: 2.9368827361543497

Epoch: 5| Step: 3
Training loss: 2.9574354895733217
Validation loss: 2.937172485487192

Epoch: 5| Step: 4
Training loss: 3.4816726674535987
Validation loss: 2.9342007476919334

Epoch: 5| Step: 5
Training loss: 3.8610715033118104
Validation loss: 2.9272620220613583

Epoch: 5| Step: 6
Training loss: 2.921259687780624
Validation loss: 2.925815406776386

Epoch: 5| Step: 7
Training loss: 3.064074987126359
Validation loss: 2.928536141962508

Epoch: 5| Step: 8
Training loss: 3.0415182904846287
Validation loss: 2.9268817989151827

Epoch: 5| Step: 9
Training loss: 2.778851020956968
Validation loss: 2.9306623672060725

Epoch: 5| Step: 10
Training loss: 3.1488883403268195
Validation loss: 2.9307853075885397

Epoch: 52| Step: 0
Training loss: 3.2456515638769172
Validation loss: 2.929556200154765

Epoch: 5| Step: 1
Training loss: 3.4271969452706337
Validation loss: 2.9276538702002375

Epoch: 5| Step: 2
Training loss: 3.499489883305762
Validation loss: 2.9265335732176285

Epoch: 5| Step: 3
Training loss: 2.572636536291858
Validation loss: 2.9278163039637652

Epoch: 5| Step: 4
Training loss: 2.9272678810307835
Validation loss: 2.9241092017489216

Epoch: 5| Step: 5
Training loss: 3.0393213784541313
Validation loss: 2.9287984911029126

Epoch: 5| Step: 6
Training loss: 3.4534413464664326
Validation loss: 2.9362957121507107

Epoch: 5| Step: 7
Training loss: 3.2222001926356003
Validation loss: 2.93014709061729

Epoch: 5| Step: 8
Training loss: 3.7586265522887894
Validation loss: 2.9319037054001313

Epoch: 5| Step: 9
Training loss: 2.607254354403246
Validation loss: 2.927073148527889

Epoch: 5| Step: 10
Training loss: 3.469770676568357
Validation loss: 2.9274609778686616

Epoch: 53| Step: 0
Training loss: 3.954714368881894
Validation loss: 2.9241263688574204

Epoch: 5| Step: 1
Training loss: 3.638473202272121
Validation loss: 2.921883668656909

Epoch: 5| Step: 2
Training loss: 2.601034849802377
Validation loss: 2.9218471355336844

Epoch: 5| Step: 3
Training loss: 3.2436617153847194
Validation loss: 2.9216942605418637

Epoch: 5| Step: 4
Training loss: 3.3269806089807887
Validation loss: 2.9186492480931814

Epoch: 5| Step: 5
Training loss: 2.9359363695988043
Validation loss: 2.9183126039066813

Epoch: 5| Step: 6
Training loss: 2.8422071023173836
Validation loss: 2.9192222304370468

Epoch: 5| Step: 7
Training loss: 3.0180322397986186
Validation loss: 2.920538494343276

Epoch: 5| Step: 8
Training loss: 2.96002746930135
Validation loss: 2.9175916318430155

Epoch: 5| Step: 9
Training loss: 3.143130693049347
Validation loss: 2.921633502639614

Epoch: 5| Step: 10
Training loss: 3.4929014154649054
Validation loss: 2.921779963336413

Epoch: 54| Step: 0
Training loss: 2.966411432438026
Validation loss: 2.9161819720354205

Epoch: 5| Step: 1
Training loss: 3.521154234819279
Validation loss: 2.918848695232801

Epoch: 5| Step: 2
Training loss: 3.69500485968367
Validation loss: 2.9163429930321167

Epoch: 5| Step: 3
Training loss: 3.3826819696417307
Validation loss: 2.919399642872469

Epoch: 5| Step: 4
Training loss: 2.828046344485252
Validation loss: 2.920408517768988

Epoch: 5| Step: 5
Training loss: 3.180280250579971
Validation loss: 2.9155584107838

Epoch: 5| Step: 6
Training loss: 3.2783368939482362
Validation loss: 2.913825364836923

Epoch: 5| Step: 7
Training loss: 3.6687385311954737
Validation loss: 2.9111811711980202

Epoch: 5| Step: 8
Training loss: 2.8264716779584522
Validation loss: 2.9128276933011916

Epoch: 5| Step: 9
Training loss: 2.5695700457234376
Validation loss: 2.9172883365919016

Epoch: 5| Step: 10
Training loss: 3.1683253077031295
Validation loss: 2.9176994346937537

Epoch: 55| Step: 0
Training loss: 3.3530443734663833
Validation loss: 2.91950426431425

Epoch: 5| Step: 1
Training loss: 2.7439854479590156
Validation loss: 2.915522919518592

Epoch: 5| Step: 2
Training loss: 3.479456008179153
Validation loss: 2.913486649801049

Epoch: 5| Step: 3
Training loss: 3.118413468973696
Validation loss: 2.9158999623400477

Epoch: 5| Step: 4
Training loss: 3.2842601229742576
Validation loss: 2.9128259647431607

Epoch: 5| Step: 5
Training loss: 3.060694259473753
Validation loss: 2.91169433646908

Epoch: 5| Step: 6
Training loss: 3.282502725430103
Validation loss: 2.913331455606406

Epoch: 5| Step: 7
Training loss: 3.505376092864958
Validation loss: 2.9135839833731545

Epoch: 5| Step: 8
Training loss: 3.4269925523848985
Validation loss: 2.9131849089649484

Epoch: 5| Step: 9
Training loss: 2.724583735738459
Validation loss: 2.9117139408037485

Epoch: 5| Step: 10
Training loss: 3.2034469814828195
Validation loss: 2.9125099646362496

Epoch: 56| Step: 0
Training loss: 3.307589075528233
Validation loss: 2.9144130813599602

Epoch: 5| Step: 1
Training loss: 3.1603839353720176
Validation loss: 2.912084552883067

Epoch: 5| Step: 2
Training loss: 3.469255565194894
Validation loss: 2.909706034097971

Epoch: 5| Step: 3
Training loss: 2.939366660636543
Validation loss: 2.9102146294510947

Epoch: 5| Step: 4
Training loss: 3.2899471733234984
Validation loss: 2.9097966361428704

Epoch: 5| Step: 5
Training loss: 3.0137218735726097
Validation loss: 2.9096443077797085

Epoch: 5| Step: 6
Training loss: 2.5727196642453443
Validation loss: 2.90567068341428

Epoch: 5| Step: 7
Training loss: 3.5497180450653953
Validation loss: 2.9074547271184743

Epoch: 5| Step: 8
Training loss: 3.286560121502568
Validation loss: 2.905187627211563

Epoch: 5| Step: 9
Training loss: 3.3837701794206163
Validation loss: 2.904536721065852

Epoch: 5| Step: 10
Training loss: 3.1372121610488217
Validation loss: 2.9072231763222938

Epoch: 57| Step: 0
Training loss: 2.3130184314156694
Validation loss: 2.9059273898757465

Epoch: 5| Step: 1
Training loss: 2.885763503252493
Validation loss: 2.9060562303834683

Epoch: 5| Step: 2
Training loss: 2.8697337140683707
Validation loss: 2.904141371560879

Epoch: 5| Step: 3
Training loss: 2.9576516955595182
Validation loss: 2.9010630868038585

Epoch: 5| Step: 4
Training loss: 3.4690691826861415
Validation loss: 2.902782566392856

Epoch: 5| Step: 5
Training loss: 3.3033883357032003
Validation loss: 2.9034279927227566

Epoch: 5| Step: 6
Training loss: 2.9273323867206726
Validation loss: 2.903678738391837

Epoch: 5| Step: 7
Training loss: 3.57909996376158
Validation loss: 2.90387610529423

Epoch: 5| Step: 8
Training loss: 3.6329175052028604
Validation loss: 2.9017230398501583

Epoch: 5| Step: 9
Training loss: 3.28951769508233
Validation loss: 2.9019267476131634

Epoch: 5| Step: 10
Training loss: 3.733432028237913
Validation loss: 2.904021925509049

Epoch: 58| Step: 0
Training loss: 3.5782185504794306
Validation loss: 2.9040616454770367

Epoch: 5| Step: 1
Training loss: 2.8477932199783895
Validation loss: 2.9025752325358325

Epoch: 5| Step: 2
Training loss: 2.7228739362738326
Validation loss: 2.9014526840127384

Epoch: 5| Step: 3
Training loss: 3.6348137706292136
Validation loss: 2.9032782565270456

Epoch: 5| Step: 4
Training loss: 2.990892095008915
Validation loss: 2.901834397978687

Epoch: 5| Step: 5
Training loss: 2.465908588302299
Validation loss: 2.9006292871476234

Epoch: 5| Step: 6
Training loss: 3.1515029107258457
Validation loss: 2.901564739025713

Epoch: 5| Step: 7
Training loss: 3.2782599495019897
Validation loss: 2.899986812461144

Epoch: 5| Step: 8
Training loss: 3.562272315529484
Validation loss: 2.8996837746949296

Epoch: 5| Step: 9
Training loss: 3.2259516472595404
Validation loss: 2.897262631875116

Epoch: 5| Step: 10
Training loss: 3.493213886762016
Validation loss: 2.8989620385862924

Epoch: 59| Step: 0
Training loss: 3.382849290044242
Validation loss: 2.8954786087973594

Epoch: 5| Step: 1
Training loss: 3.0367135430858854
Validation loss: 2.8979107840007763

Epoch: 5| Step: 2
Training loss: 2.866382787384385
Validation loss: 2.895841140069632

Epoch: 5| Step: 3
Training loss: 3.067235904881039
Validation loss: 2.8965604259862476

Epoch: 5| Step: 4
Training loss: 2.4280229858806113
Validation loss: 2.894976899075428

Epoch: 5| Step: 5
Training loss: 3.65793225313568
Validation loss: 2.8971296421761763

Epoch: 5| Step: 6
Training loss: 3.233798210572085
Validation loss: 2.8954529977647794

Epoch: 5| Step: 7
Training loss: 3.224439610726592
Validation loss: 2.895487706210847

Epoch: 5| Step: 8
Training loss: 4.00937983333448
Validation loss: 2.8942505382616597

Epoch: 5| Step: 9
Training loss: 3.0502142971610957
Validation loss: 2.8926944082109602

Epoch: 5| Step: 10
Training loss: 2.8001062917970323
Validation loss: 2.894900487683235

Epoch: 60| Step: 0
Training loss: 3.105858275737527
Validation loss: 2.892771033851143

Epoch: 5| Step: 1
Training loss: 3.2646456623436455
Validation loss: 2.89240325977255

Epoch: 5| Step: 2
Training loss: 2.9257848355076495
Validation loss: 2.8947486773083764

Epoch: 5| Step: 3
Training loss: 3.203295000728833
Validation loss: 2.894857822317282

Epoch: 5| Step: 4
Training loss: 3.338619538746443
Validation loss: 2.8927608015006454

Epoch: 5| Step: 5
Training loss: 3.4986505631807
Validation loss: 2.892277435460762

Epoch: 5| Step: 6
Training loss: 2.973075526340888
Validation loss: 2.8912057104262967

Epoch: 5| Step: 7
Training loss: 2.6345240070018794
Validation loss: 2.89417799455154

Epoch: 5| Step: 8
Training loss: 3.7473128545753847
Validation loss: 2.8931959594889585

Epoch: 5| Step: 9
Training loss: 3.00401704779815
Validation loss: 2.8922220391902647

Epoch: 5| Step: 10
Training loss: 3.257126404307216
Validation loss: 2.8947174786002825

Epoch: 61| Step: 0
Training loss: 2.977487335306261
Validation loss: 2.891736553804286

Epoch: 5| Step: 1
Training loss: 2.8143729860966555
Validation loss: 2.890497179872041

Epoch: 5| Step: 2
Training loss: 2.8618373586958
Validation loss: 2.8893426438082357

Epoch: 5| Step: 3
Training loss: 3.244565381302988
Validation loss: 2.8878978756815075

Epoch: 5| Step: 4
Training loss: 2.823694879636416
Validation loss: 2.8919504573991595

Epoch: 5| Step: 5
Training loss: 3.2577942040384777
Validation loss: 2.8898459083287302

Epoch: 5| Step: 6
Training loss: 3.855390831991904
Validation loss: 2.8881552511165394

Epoch: 5| Step: 7
Training loss: 3.5923702079034565
Validation loss: 2.8892811328347148

Epoch: 5| Step: 8
Training loss: 3.187200794014583
Validation loss: 2.886980557785153

Epoch: 5| Step: 9
Training loss: 3.020760072718645
Validation loss: 2.8865762050084802

Epoch: 5| Step: 10
Training loss: 3.2361415885250517
Validation loss: 2.885825967787973

Epoch: 62| Step: 0
Training loss: 3.727255446907806
Validation loss: 2.883146790250496

Epoch: 5| Step: 1
Training loss: 3.2857341824989423
Validation loss: 2.8845892765703187

Epoch: 5| Step: 2
Training loss: 2.9197342317947306
Validation loss: 2.884598706052327

Epoch: 5| Step: 3
Training loss: 3.4797562577400805
Validation loss: 2.8821614506244595

Epoch: 5| Step: 4
Training loss: 2.3656018678045654
Validation loss: 2.8812302010543527

Epoch: 5| Step: 5
Training loss: 3.5295176349917523
Validation loss: 2.88006251473241

Epoch: 5| Step: 6
Training loss: 2.956643889238025
Validation loss: 2.880532365512979

Epoch: 5| Step: 7
Training loss: 2.521826923956779
Validation loss: 2.8792113731017577

Epoch: 5| Step: 8
Training loss: 3.33116677128382
Validation loss: 2.879294932068729

Epoch: 5| Step: 9
Training loss: 3.46833991298635
Validation loss: 2.876417981155875

Epoch: 5| Step: 10
Training loss: 3.090630393799799
Validation loss: 2.8762361705394595

Epoch: 63| Step: 0
Training loss: 2.7411677972424746
Validation loss: 2.8775714745272505

Epoch: 5| Step: 1
Training loss: 2.649019520590815
Validation loss: 2.8767188321357753

Epoch: 5| Step: 2
Training loss: 2.8732588097923437
Validation loss: 2.8720872925827767

Epoch: 5| Step: 3
Training loss: 3.4798531378526523
Validation loss: 2.879796494898858

Epoch: 5| Step: 4
Training loss: 3.320157108036591
Validation loss: 2.881742115795107

Epoch: 5| Step: 5
Training loss: 2.8896126288863586
Validation loss: 2.875940055050672

Epoch: 5| Step: 6
Training loss: 3.0007269296494212
Validation loss: 2.8800279782288123

Epoch: 5| Step: 7
Training loss: 3.551964691656769
Validation loss: 2.879401920618814

Epoch: 5| Step: 8
Training loss: 3.0845709370349366
Validation loss: 2.8759483157317693

Epoch: 5| Step: 9
Training loss: 3.5923245463999325
Validation loss: 2.8769329326999724

Epoch: 5| Step: 10
Training loss: 3.5854292366004024
Validation loss: 2.871625302673982

Epoch: 64| Step: 0
Training loss: 3.8195612818254556
Validation loss: 2.8702100753205166

Epoch: 5| Step: 1
Training loss: 2.857415199923851
Validation loss: 2.8686988139860237

Epoch: 5| Step: 2
Training loss: 3.2686000578061893
Validation loss: 2.8711330031367437

Epoch: 5| Step: 3
Training loss: 3.3141496976885283
Validation loss: 2.871121067689809

Epoch: 5| Step: 4
Training loss: 2.8158980293288978
Validation loss: 2.8819233201988137

Epoch: 5| Step: 5
Training loss: 3.4288340138744173
Validation loss: 2.874488337402265

Epoch: 5| Step: 6
Training loss: 2.764431625914352
Validation loss: 2.872855452650476

Epoch: 5| Step: 7
Training loss: 3.2161140388842555
Validation loss: 2.8737167224785094

Epoch: 5| Step: 8
Training loss: 2.7252012860912007
Validation loss: 2.8734298402520144

Epoch: 5| Step: 9
Training loss: 3.375777543535341
Validation loss: 2.8687985053597416

Epoch: 5| Step: 10
Training loss: 3.1042917384269195
Validation loss: 2.864728132747876

Epoch: 65| Step: 0
Training loss: 2.8487645466304636
Validation loss: 2.8664071037339887

Epoch: 5| Step: 1
Training loss: 2.862208895477851
Validation loss: 2.868790069492553

Epoch: 5| Step: 2
Training loss: 3.18855133669979
Validation loss: 2.8696318181883322

Epoch: 5| Step: 3
Training loss: 3.369966921997735
Validation loss: 2.875361176890632

Epoch: 5| Step: 4
Training loss: 3.3680553335777463
Validation loss: 2.8785248701079853

Epoch: 5| Step: 5
Training loss: 2.9690082638485165
Validation loss: 2.882660074375916

Epoch: 5| Step: 6
Training loss: 3.0949914156250853
Validation loss: 2.8813721626074367

Epoch: 5| Step: 7
Training loss: 3.3473049767387204
Validation loss: 2.8819821105490844

Epoch: 5| Step: 8
Training loss: 3.7714551690431177
Validation loss: 2.880329923398439

Epoch: 5| Step: 9
Training loss: 3.4127366483467836
Validation loss: 2.8658748658811284

Epoch: 5| Step: 10
Training loss: 2.271568657581623
Validation loss: 2.8618154490780197

Epoch: 66| Step: 0
Training loss: 2.8742386182931465
Validation loss: 2.8606531119957346

Epoch: 5| Step: 1
Training loss: 2.8599884542485583
Validation loss: 2.85988676872044

Epoch: 5| Step: 2
Training loss: 3.316689343271098
Validation loss: 2.863204075108809

Epoch: 5| Step: 3
Training loss: 3.4456248585109175
Validation loss: 2.8627154802459325

Epoch: 5| Step: 4
Training loss: 3.420762948269639
Validation loss: 2.8658105888597607

Epoch: 5| Step: 5
Training loss: 2.577718066843018
Validation loss: 2.8672414799561516

Epoch: 5| Step: 6
Training loss: 3.0473588608188775
Validation loss: 2.8718257321152483

Epoch: 5| Step: 7
Training loss: 2.9690837471734426
Validation loss: 2.864776705631691

Epoch: 5| Step: 8
Training loss: 3.809197918826224
Validation loss: 2.86186601795693

Epoch: 5| Step: 9
Training loss: 2.8743535849280906
Validation loss: 2.857857436667015

Epoch: 5| Step: 10
Training loss: 3.493385058401058
Validation loss: 2.8583606481046733

Epoch: 67| Step: 0
Training loss: 3.122844868437537
Validation loss: 2.8564808566049726

Epoch: 5| Step: 1
Training loss: 3.285521424598254
Validation loss: 2.855503156192742

Epoch: 5| Step: 2
Training loss: 3.3328544431641247
Validation loss: 2.8565263155100844

Epoch: 5| Step: 3
Training loss: 3.3815554778757027
Validation loss: 2.8564128867791823

Epoch: 5| Step: 4
Training loss: 3.0322847468250136
Validation loss: 2.85499763622861

Epoch: 5| Step: 5
Training loss: 3.0863948434837063
Validation loss: 2.854479807062263

Epoch: 5| Step: 6
Training loss: 2.640610282902082
Validation loss: 2.8554280488321577

Epoch: 5| Step: 7
Training loss: 3.2904106512292874
Validation loss: 2.855071409820233

Epoch: 5| Step: 8
Training loss: 3.3048838744199287
Validation loss: 2.8604133057135206

Epoch: 5| Step: 9
Training loss: 3.1399480744946184
Validation loss: 2.859927331136187

Epoch: 5| Step: 10
Training loss: 3.045261679744471
Validation loss: 2.8586669920384074

Epoch: 68| Step: 0
Training loss: 3.5701090882033792
Validation loss: 2.8528852185649867

Epoch: 5| Step: 1
Training loss: 3.059485684224971
Validation loss: 2.8515717581973594

Epoch: 5| Step: 2
Training loss: 3.0443434933665134
Validation loss: 2.853166150793235

Epoch: 5| Step: 3
Training loss: 3.5223719979848096
Validation loss: 2.8544744138986746

Epoch: 5| Step: 4
Training loss: 3.11893867120747
Validation loss: 2.852498612517267

Epoch: 5| Step: 5
Training loss: 3.0668469154902005
Validation loss: 2.853286879426523

Epoch: 5| Step: 6
Training loss: 2.8770789217978394
Validation loss: 2.8503324801553673

Epoch: 5| Step: 7
Training loss: 2.9250298262159533
Validation loss: 2.84738178968224

Epoch: 5| Step: 8
Training loss: 3.1150430363457473
Validation loss: 2.8475288616831924

Epoch: 5| Step: 9
Training loss: 3.028490363755813
Validation loss: 2.849050288917151

Epoch: 5| Step: 10
Training loss: 3.3131251195142255
Validation loss: 2.849534476658866

Epoch: 69| Step: 0
Training loss: 3.605915475862875
Validation loss: 2.8502855373391194

Epoch: 5| Step: 1
Training loss: 3.1464910430174533
Validation loss: 2.8499942456014438

Epoch: 5| Step: 2
Training loss: 2.3976419229038997
Validation loss: 2.8470105799274794

Epoch: 5| Step: 3
Training loss: 2.944246053509862
Validation loss: 2.8502502991384664

Epoch: 5| Step: 4
Training loss: 3.6780114375937987
Validation loss: 2.8489118275565377

Epoch: 5| Step: 5
Training loss: 2.8246173498214935
Validation loss: 2.848109881791852

Epoch: 5| Step: 6
Training loss: 3.0774109297753336
Validation loss: 2.8480938722127314

Epoch: 5| Step: 7
Training loss: 3.5472863584764625
Validation loss: 2.8503087947806036

Epoch: 5| Step: 8
Training loss: 2.7492226455630524
Validation loss: 2.8511799896133168

Epoch: 5| Step: 9
Training loss: 3.0992207562974032
Validation loss: 2.8479805100082762

Epoch: 5| Step: 10
Training loss: 3.4550145015605436
Validation loss: 2.8475103189687867

Epoch: 70| Step: 0
Training loss: 3.063247745080652
Validation loss: 2.847943610374535

Epoch: 5| Step: 1
Training loss: 2.3114101831808456
Validation loss: 2.8477594885322843

Epoch: 5| Step: 2
Training loss: 3.1428833997546146
Validation loss: 2.850744040356714

Epoch: 5| Step: 3
Training loss: 2.8893825850901886
Validation loss: 2.850228960648257

Epoch: 5| Step: 4
Training loss: 3.1908273720521616
Validation loss: 2.8497648206507686

Epoch: 5| Step: 5
Training loss: 3.9669373946138404
Validation loss: 2.8515477972231755

Epoch: 5| Step: 6
Training loss: 3.1094713052375482
Validation loss: 2.8460832048470253

Epoch: 5| Step: 7
Training loss: 2.786995942254153
Validation loss: 2.8467384816505636

Epoch: 5| Step: 8
Training loss: 3.7460964230715827
Validation loss: 2.846102964771576

Epoch: 5| Step: 9
Training loss: 2.8133367353421774
Validation loss: 2.8458017427634523

Epoch: 5| Step: 10
Training loss: 3.3579031625386127
Validation loss: 2.847539424026057

Epoch: 71| Step: 0
Training loss: 3.3345494118348675
Validation loss: 2.8460557026805624

Epoch: 5| Step: 1
Training loss: 3.276933719415214
Validation loss: 2.8437867539176382

Epoch: 5| Step: 2
Training loss: 3.8384683188785313
Validation loss: 2.8450044544573725

Epoch: 5| Step: 3
Training loss: 3.0178527509539674
Validation loss: 2.8466150436923265

Epoch: 5| Step: 4
Training loss: 2.705898912310846
Validation loss: 2.8443512026947495

Epoch: 5| Step: 5
Training loss: 3.33836101612555
Validation loss: 2.8440701064379366

Epoch: 5| Step: 6
Training loss: 3.255765495937718
Validation loss: 2.846703092375116

Epoch: 5| Step: 7
Training loss: 2.794571252738656
Validation loss: 2.848235731987987

Epoch: 5| Step: 8
Training loss: 2.8696926720651623
Validation loss: 2.845015902040542

Epoch: 5| Step: 9
Training loss: 3.201574778498371
Validation loss: 2.8505249401378387

Epoch: 5| Step: 10
Training loss: 2.731182305306725
Validation loss: 2.850467745830968

Epoch: 72| Step: 0
Training loss: 2.8227251464138807
Validation loss: 2.8592554447672565

Epoch: 5| Step: 1
Training loss: 3.1727499671138286
Validation loss: 2.852314759542077

Epoch: 5| Step: 2
Training loss: 3.0776342010366706
Validation loss: 2.846888292007229

Epoch: 5| Step: 3
Training loss: 3.0424752575911276
Validation loss: 2.8468715344375246

Epoch: 5| Step: 4
Training loss: 3.5722725661154544
Validation loss: 2.8404696472834106

Epoch: 5| Step: 5
Training loss: 2.391332085452336
Validation loss: 2.8404339813423505

Epoch: 5| Step: 6
Training loss: 3.268026682545164
Validation loss: 2.8390005360399084

Epoch: 5| Step: 7
Training loss: 3.5358772680636936
Validation loss: 2.8409926063738897

Epoch: 5| Step: 8
Training loss: 2.8265018758182183
Validation loss: 2.8406984403639317

Epoch: 5| Step: 9
Training loss: 3.745078608626265
Validation loss: 2.842328392045939

Epoch: 5| Step: 10
Training loss: 2.9370394406552247
Validation loss: 2.8387434506201807

Epoch: 73| Step: 0
Training loss: 3.291772156646692
Validation loss: 2.8404882170061003

Epoch: 5| Step: 1
Training loss: 3.8743076321190473
Validation loss: 2.842504537597553

Epoch: 5| Step: 2
Training loss: 2.646657519993323
Validation loss: 2.840851349595285

Epoch: 5| Step: 3
Training loss: 3.2670581355998487
Validation loss: 2.837852978070429

Epoch: 5| Step: 4
Training loss: 3.053569462264853
Validation loss: 2.839390151905799

Epoch: 5| Step: 5
Training loss: 3.1119818566389177
Validation loss: 2.838901257587511

Epoch: 5| Step: 6
Training loss: 3.2539184130456196
Validation loss: 2.836652305359124

Epoch: 5| Step: 7
Training loss: 3.1071011457477895
Validation loss: 2.83972231262003

Epoch: 5| Step: 8
Training loss: 3.168263902567309
Validation loss: 2.8419757163857513

Epoch: 5| Step: 9
Training loss: 2.9188690226627094
Validation loss: 2.8445333136509627

Epoch: 5| Step: 10
Training loss: 2.6617759221472608
Validation loss: 2.8472374139742804

Epoch: 74| Step: 0
Training loss: 3.0504483127988937
Validation loss: 2.8508920143987324

Epoch: 5| Step: 1
Training loss: 3.5000767018224237
Validation loss: 2.8469077122582895

Epoch: 5| Step: 2
Training loss: 2.7041840876491783
Validation loss: 2.838636891232699

Epoch: 5| Step: 3
Training loss: 4.082460868166687
Validation loss: 2.8357536292244108

Epoch: 5| Step: 4
Training loss: 2.4673720751591945
Validation loss: 2.8366512479647805

Epoch: 5| Step: 5
Training loss: 2.8514370825373203
Validation loss: 2.837700809790545

Epoch: 5| Step: 6
Training loss: 2.8881280785688457
Validation loss: 2.83555415074561

Epoch: 5| Step: 7
Training loss: 2.8567297534660816
Validation loss: 2.835580706013523

Epoch: 5| Step: 8
Training loss: 3.316001049579965
Validation loss: 2.8372602563055085

Epoch: 5| Step: 9
Training loss: 2.831383950809974
Validation loss: 2.8352652399039995

Epoch: 5| Step: 10
Training loss: 3.7727459575946636
Validation loss: 2.8360278119350153

Epoch: 75| Step: 0
Training loss: 3.461264842378004
Validation loss: 2.837053513780802

Epoch: 5| Step: 1
Training loss: 3.478368945619568
Validation loss: 2.8360228618748247

Epoch: 5| Step: 2
Training loss: 2.9658175792813384
Validation loss: 2.8346697088468797

Epoch: 5| Step: 3
Training loss: 3.179174883337306
Validation loss: 2.8358414899058766

Epoch: 5| Step: 4
Training loss: 2.88737709477421
Validation loss: 2.8376778429098404

Epoch: 5| Step: 5
Training loss: 2.9605680451603225
Validation loss: 2.8355591459251346

Epoch: 5| Step: 6
Training loss: 3.2204249199980177
Validation loss: 2.838449203251168

Epoch: 5| Step: 7
Training loss: 2.9087279226057876
Validation loss: 2.836197624682695

Epoch: 5| Step: 8
Training loss: 3.0847326316774275
Validation loss: 2.8330511143199333

Epoch: 5| Step: 9
Training loss: 3.441069258472076
Validation loss: 2.833602893053863

Epoch: 5| Step: 10
Training loss: 2.8306891687977895
Validation loss: 2.8339716001184683

Testing loss: 3.0480638667952746
