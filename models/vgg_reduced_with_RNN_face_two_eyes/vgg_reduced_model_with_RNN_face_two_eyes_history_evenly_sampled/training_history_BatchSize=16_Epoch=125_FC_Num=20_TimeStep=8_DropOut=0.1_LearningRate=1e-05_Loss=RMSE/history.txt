Epoch: 1| Step: 0
Training loss: 5.039036382563131
Validation loss: 5.808593464003209

Epoch: 6| Step: 1
Training loss: 6.236571878555295
Validation loss: 5.800215084117585

Epoch: 6| Step: 2
Training loss: 6.0583869116651465
Validation loss: 5.7913752574236375

Epoch: 6| Step: 3
Training loss: 5.926787661220973
Validation loss: 5.782161471622629

Epoch: 6| Step: 4
Training loss: 6.228418243594329
Validation loss: 5.77203884070658

Epoch: 6| Step: 5
Training loss: 5.227312384896
Validation loss: 5.761767108061486

Epoch: 6| Step: 6
Training loss: 5.00960343304702
Validation loss: 5.75098260274586

Epoch: 6| Step: 7
Training loss: 5.988555165375869
Validation loss: 5.739353047641602

Epoch: 6| Step: 8
Training loss: 3.6476035625143775
Validation loss: 5.7272834231709995

Epoch: 6| Step: 9
Training loss: 6.379091931716537
Validation loss: 5.714573338736708

Epoch: 6| Step: 10
Training loss: 5.733508135474369
Validation loss: 5.700789758603159

Epoch: 6| Step: 11
Training loss: 6.852665358966003
Validation loss: 5.685921267002633

Epoch: 6| Step: 12
Training loss: 6.119680780799495
Validation loss: 5.6700604583039675

Epoch: 6| Step: 13
Training loss: 5.63050793025037
Validation loss: 5.652984661042629

Epoch: 2| Step: 0
Training loss: 6.44104380423592
Validation loss: 5.635124230647821

Epoch: 6| Step: 1
Training loss: 3.871134891541593
Validation loss: 5.614889704972355

Epoch: 6| Step: 2
Training loss: 5.960945819333972
Validation loss: 5.595087022334909

Epoch: 6| Step: 3
Training loss: 5.2831081755562135
Validation loss: 5.572920809278385

Epoch: 6| Step: 4
Training loss: 4.940347936632131
Validation loss: 5.550093047531525

Epoch: 6| Step: 5
Training loss: 6.581649307353018
Validation loss: 5.52617482182314

Epoch: 6| Step: 6
Training loss: 6.04964255545963
Validation loss: 5.50088289917528

Epoch: 6| Step: 7
Training loss: 5.891946902303223
Validation loss: 5.473755775768235

Epoch: 6| Step: 8
Training loss: 5.204572046809391
Validation loss: 5.443060871931259

Epoch: 6| Step: 9
Training loss: 4.62489009417291
Validation loss: 5.413816194543234

Epoch: 6| Step: 10
Training loss: 5.9527751189013465
Validation loss: 5.382704089756767

Epoch: 6| Step: 11
Training loss: 5.249232281455807
Validation loss: 5.350603476602519

Epoch: 6| Step: 12
Training loss: 5.155644051753273
Validation loss: 5.318226206069695

Epoch: 6| Step: 13
Training loss: 5.399628923170051
Validation loss: 5.2851354426406765

Epoch: 3| Step: 0
Training loss: 3.952242183492497
Validation loss: 5.251810772383549

Epoch: 6| Step: 1
Training loss: 4.3714578730850455
Validation loss: 5.217575297671471

Epoch: 6| Step: 2
Training loss: 5.0345101544964175
Validation loss: 5.185558728287437

Epoch: 6| Step: 3
Training loss: 6.144854382495982
Validation loss: 5.152230665517125

Epoch: 6| Step: 4
Training loss: 5.3099042946331965
Validation loss: 5.118338336427971

Epoch: 6| Step: 5
Training loss: 5.950692708700299
Validation loss: 5.084893624459538

Epoch: 6| Step: 6
Training loss: 5.205921418261166
Validation loss: 5.049045872151615

Epoch: 6| Step: 7
Training loss: 4.333365782591784
Validation loss: 5.014768518966647

Epoch: 6| Step: 8
Training loss: 5.890381825737489
Validation loss: 4.981185272554244

Epoch: 6| Step: 9
Training loss: 5.546698596996932
Validation loss: 4.9489909124949225

Epoch: 6| Step: 10
Training loss: 6.215987162062498
Validation loss: 4.917610150235515

Epoch: 6| Step: 11
Training loss: 3.244113285838295
Validation loss: 4.887673500216185

Epoch: 6| Step: 12
Training loss: 4.955466887094675
Validation loss: 4.861663173065814

Epoch: 6| Step: 13
Training loss: 3.5451099188244997
Validation loss: 4.834513342338409

Epoch: 4| Step: 0
Training loss: 5.021410116197811
Validation loss: 4.810023106815913

Epoch: 6| Step: 1
Training loss: 4.156567324807717
Validation loss: 4.786368725783805

Epoch: 6| Step: 2
Training loss: 5.116181765431482
Validation loss: 4.765148407041356

Epoch: 6| Step: 3
Training loss: 3.841410103020744
Validation loss: 4.742926171019349

Epoch: 6| Step: 4
Training loss: 5.530410616704285
Validation loss: 4.721140800700022

Epoch: 6| Step: 5
Training loss: 5.4159647364517856
Validation loss: 4.699622046224431

Epoch: 6| Step: 6
Training loss: 3.2593699147083264
Validation loss: 4.676617643201572

Epoch: 6| Step: 7
Training loss: 5.0719805825761295
Validation loss: 4.656319533398269

Epoch: 6| Step: 8
Training loss: 4.820728549901047
Validation loss: 4.632955425576764

Epoch: 6| Step: 9
Training loss: 6.35384734138283
Validation loss: 4.609652580911858

Epoch: 6| Step: 10
Training loss: 4.608558918752931
Validation loss: 4.583709255400184

Epoch: 6| Step: 11
Training loss: 4.401783945663039
Validation loss: 4.561613838825398

Epoch: 6| Step: 12
Training loss: 4.59494480502546
Validation loss: 4.5394416537625775

Epoch: 6| Step: 13
Training loss: 2.0873567132256747
Validation loss: 4.516233521086267

Epoch: 5| Step: 0
Training loss: 3.8897827952723754
Validation loss: 4.496481227260304

Epoch: 6| Step: 1
Training loss: 4.678529828634405
Validation loss: 4.4768225009094245

Epoch: 6| Step: 2
Training loss: 4.2758973903066995
Validation loss: 4.457258481143382

Epoch: 6| Step: 3
Training loss: 3.118454754448426
Validation loss: 4.4374989716550175

Epoch: 6| Step: 4
Training loss: 3.5870862130704357
Validation loss: 4.4195212234895855

Epoch: 6| Step: 5
Training loss: 5.008787444098247
Validation loss: 4.404071325965087

Epoch: 6| Step: 6
Training loss: 4.491343755680415
Validation loss: 4.389460821872788

Epoch: 6| Step: 7
Training loss: 4.54597931000163
Validation loss: 4.3703577190124365

Epoch: 6| Step: 8
Training loss: 3.834011736561816
Validation loss: 4.354171043252882

Epoch: 6| Step: 9
Training loss: 5.0485636717491325
Validation loss: 4.337117343038437

Epoch: 6| Step: 10
Training loss: 4.934069057109674
Validation loss: 4.319734531551749

Epoch: 6| Step: 11
Training loss: 4.753042752308613
Validation loss: 4.30684086411288

Epoch: 6| Step: 12
Training loss: 5.018002335853079
Validation loss: 4.291811193431406

Epoch: 6| Step: 13
Training loss: 5.547199594375864
Validation loss: 4.2766378380135786

Epoch: 6| Step: 0
Training loss: 4.11107272625665
Validation loss: 4.2617755480549615

Epoch: 6| Step: 1
Training loss: 4.023414508050204
Validation loss: 4.246959406908774

Epoch: 6| Step: 2
Training loss: 3.8536988807873582
Validation loss: 4.236008057847318

Epoch: 6| Step: 3
Training loss: 4.108769709461778
Validation loss: 4.222779395539989

Epoch: 6| Step: 4
Training loss: 4.6358003036105915
Validation loss: 4.208776938979362

Epoch: 6| Step: 5
Training loss: 4.266781604728695
Validation loss: 4.197298455963016

Epoch: 6| Step: 6
Training loss: 5.057506594688955
Validation loss: 4.1875940703207535

Epoch: 6| Step: 7
Training loss: 3.8658881576629445
Validation loss: 4.175974350094596

Epoch: 6| Step: 8
Training loss: 4.1959153067275405
Validation loss: 4.166034836804107

Epoch: 6| Step: 9
Training loss: 4.281620427277081
Validation loss: 4.155440178903748

Epoch: 6| Step: 10
Training loss: 4.71914408471854
Validation loss: 4.144398339150621

Epoch: 6| Step: 11
Training loss: 5.1113232739038885
Validation loss: 4.134686048286398

Epoch: 6| Step: 12
Training loss: 4.088391939892114
Validation loss: 4.124076347070628

Epoch: 6| Step: 13
Training loss: 3.5501873665377737
Validation loss: 4.115308649016866

Epoch: 7| Step: 0
Training loss: 4.2263165471124475
Validation loss: 4.104897622582762

Epoch: 6| Step: 1
Training loss: 4.042304916062595
Validation loss: 4.092847499014407

Epoch: 6| Step: 2
Training loss: 4.091007158279218
Validation loss: 4.084625949062998

Epoch: 6| Step: 3
Training loss: 4.53818922456835
Validation loss: 4.072663286431209

Epoch: 6| Step: 4
Training loss: 3.3678360245898835
Validation loss: 4.063449215488345

Epoch: 6| Step: 5
Training loss: 4.7343008709130565
Validation loss: 4.055329082790515

Epoch: 6| Step: 6
Training loss: 3.0373202235391354
Validation loss: 4.044940510988018

Epoch: 6| Step: 7
Training loss: 3.8818082988402858
Validation loss: 4.034490141865719

Epoch: 6| Step: 8
Training loss: 4.369633898730596
Validation loss: 4.027819569877372

Epoch: 6| Step: 9
Training loss: 4.286766118447852
Validation loss: 4.01689260668796

Epoch: 6| Step: 10
Training loss: 4.928610803513973
Validation loss: 4.007762421920754

Epoch: 6| Step: 11
Training loss: 3.688060265344506
Validation loss: 3.999110133134476

Epoch: 6| Step: 12
Training loss: 4.373284575803069
Validation loss: 3.9875770784362428

Epoch: 6| Step: 13
Training loss: 4.979077049736418
Validation loss: 3.9765994945826146

Epoch: 8| Step: 0
Training loss: 4.5074382342329224
Validation loss: 3.9648745031420445

Epoch: 6| Step: 1
Training loss: 3.892603359724401
Validation loss: 3.949396055216281

Epoch: 6| Step: 2
Training loss: 4.090370705366962
Validation loss: 3.9405408980668186

Epoch: 6| Step: 3
Training loss: 4.0748595979994455
Validation loss: 3.929224267542453

Epoch: 6| Step: 4
Training loss: 3.847576562666247
Validation loss: 3.9325016966646613

Epoch: 6| Step: 5
Training loss: 3.3703288495724353
Validation loss: 3.9266864655174505

Epoch: 6| Step: 6
Training loss: 4.824836277531132
Validation loss: 3.9122034447921936

Epoch: 6| Step: 7
Training loss: 4.047253447404708
Validation loss: 3.9051454500923968

Epoch: 6| Step: 8
Training loss: 3.8704810095438082
Validation loss: 3.9051782672713014

Epoch: 6| Step: 9
Training loss: 4.726407942333535
Validation loss: 3.8954545861803984

Epoch: 6| Step: 10
Training loss: 4.025434453985676
Validation loss: 3.884631290362147

Epoch: 6| Step: 11
Training loss: 4.012457997705348
Validation loss: 3.879346676900997

Epoch: 6| Step: 12
Training loss: 3.398567986449662
Validation loss: 3.872225477014101

Epoch: 6| Step: 13
Training loss: 4.138372305109022
Validation loss: 3.8668628843511867

Epoch: 9| Step: 0
Training loss: 3.9881382542007167
Validation loss: 3.8602798780789502

Epoch: 6| Step: 1
Training loss: 3.4522041024949846
Validation loss: 3.8588986301449655

Epoch: 6| Step: 2
Training loss: 4.663941654959275
Validation loss: 3.8421024326720934

Epoch: 6| Step: 3
Training loss: 3.141445071823193
Validation loss: 3.8326167609018134

Epoch: 6| Step: 4
Training loss: 4.425991555020998
Validation loss: 3.8283054412244732

Epoch: 6| Step: 5
Training loss: 3.4392443305981852
Validation loss: 3.8247621640728475

Epoch: 6| Step: 6
Training loss: 4.557971326736978
Validation loss: 3.8206109294149577

Epoch: 6| Step: 7
Training loss: 3.877988954627689
Validation loss: 3.8155479573136324

Epoch: 6| Step: 8
Training loss: 4.465441779721905
Validation loss: 3.8056815689689114

Epoch: 6| Step: 9
Training loss: 3.739754732218855
Validation loss: 3.801165431881019

Epoch: 6| Step: 10
Training loss: 4.793622930600742
Validation loss: 3.7930117311375597

Epoch: 6| Step: 11
Training loss: 3.8687339079834957
Validation loss: 3.7882271809521617

Epoch: 6| Step: 12
Training loss: 3.343734313357626
Validation loss: 3.7872864011455163

Epoch: 6| Step: 13
Training loss: 3.3039619244466722
Validation loss: 3.7828523309950115

Epoch: 10| Step: 0
Training loss: 4.54132223427253
Validation loss: 3.7797934007132357

Epoch: 6| Step: 1
Training loss: 4.46699969819911
Validation loss: 3.774768575979563

Epoch: 6| Step: 2
Training loss: 3.40844431900849
Validation loss: 3.7712213772873473

Epoch: 6| Step: 3
Training loss: 3.310919330541669
Validation loss: 3.7702862652002804

Epoch: 6| Step: 4
Training loss: 4.478441519775035
Validation loss: 3.7619159363851025

Epoch: 6| Step: 5
Training loss: 4.388242027375007
Validation loss: 3.7566835395504024

Epoch: 6| Step: 6
Training loss: 4.4832366668225525
Validation loss: 3.7519569213107986

Epoch: 6| Step: 7
Training loss: 4.053898082172828
Validation loss: 3.7455647536136096

Epoch: 6| Step: 8
Training loss: 4.356364643005913
Validation loss: 3.741477086218386

Epoch: 6| Step: 9
Training loss: 3.635601458001933
Validation loss: 3.742360707755575

Epoch: 6| Step: 10
Training loss: 2.519441824812008
Validation loss: 3.734189087619041

Epoch: 6| Step: 11
Training loss: 4.181470943252814
Validation loss: 3.728583048165962

Epoch: 6| Step: 12
Training loss: 3.2947780213669944
Validation loss: 3.7256345347887034

Epoch: 6| Step: 13
Training loss: 2.6384976637994204
Validation loss: 3.7208191404588824

Epoch: 11| Step: 0
Training loss: 3.810410849579128
Validation loss: 3.715712816351916

Epoch: 6| Step: 1
Training loss: 3.340673724997646
Validation loss: 3.7106758278436183

Epoch: 6| Step: 2
Training loss: 4.302418077698588
Validation loss: 3.703906291362592

Epoch: 6| Step: 3
Training loss: 3.635067869284787
Validation loss: 3.698609807822087

Epoch: 6| Step: 4
Training loss: 4.7753704546480975
Validation loss: 3.695180119508088

Epoch: 6| Step: 5
Training loss: 3.608755215362596
Validation loss: 3.6805657577347453

Epoch: 6| Step: 6
Training loss: 4.034924156109584
Validation loss: 3.677734391729695

Epoch: 6| Step: 7
Training loss: 3.3196437745696543
Validation loss: 3.6738407665369115

Epoch: 6| Step: 8
Training loss: 3.488235456245115
Validation loss: 3.6691454933936236

Epoch: 6| Step: 9
Training loss: 3.522389055052177
Validation loss: 3.6675091686338703

Epoch: 6| Step: 10
Training loss: 3.995134971353415
Validation loss: 3.6628229087573354

Epoch: 6| Step: 11
Training loss: 4.052477166160345
Validation loss: 3.6602461013659493

Epoch: 6| Step: 12
Training loss: 4.114984085589907
Validation loss: 3.6581323176608453

Epoch: 6| Step: 13
Training loss: 3.9546160995567
Validation loss: 3.6548212704570404

Epoch: 12| Step: 0
Training loss: 4.087777943158513
Validation loss: 3.6553044203828624

Epoch: 6| Step: 1
Training loss: 4.0472096190688704
Validation loss: 3.6489670737534348

Epoch: 6| Step: 2
Training loss: 4.448914367606211
Validation loss: 3.648456651871387

Epoch: 6| Step: 3
Training loss: 3.4513082428756356
Validation loss: 3.6566046020545477

Epoch: 6| Step: 4
Training loss: 3.932832888647736
Validation loss: 3.6427429029986533

Epoch: 6| Step: 5
Training loss: 3.4487166077012437
Validation loss: 3.639729083571001

Epoch: 6| Step: 6
Training loss: 2.8189506307110506
Validation loss: 3.6391439702022508

Epoch: 6| Step: 7
Training loss: 3.7818456763821953
Validation loss: 3.6383120260047415

Epoch: 6| Step: 8
Training loss: 4.205190158313667
Validation loss: 3.636979096159683

Epoch: 6| Step: 9
Training loss: 3.5877736695009697
Validation loss: 3.633291807122711

Epoch: 6| Step: 10
Training loss: 2.5444245514885626
Validation loss: 3.632394885157545

Epoch: 6| Step: 11
Training loss: 4.277371619843565
Validation loss: 3.630093965352946

Epoch: 6| Step: 12
Training loss: 4.279157363797296
Validation loss: 3.6255445569906697

Epoch: 6| Step: 13
Training loss: 4.50437777880523
Validation loss: 3.6217478618330947

Epoch: 13| Step: 0
Training loss: 3.398734945675675
Validation loss: 3.62020072452354

Epoch: 6| Step: 1
Training loss: 4.271864802160697
Validation loss: 3.6181077438824234

Epoch: 6| Step: 2
Training loss: 3.58424593519337
Validation loss: 3.615185784246003

Epoch: 6| Step: 3
Training loss: 3.677336182514587
Validation loss: 3.613740188201038

Epoch: 6| Step: 4
Training loss: 4.338123876903737
Validation loss: 3.6106512566241244

Epoch: 6| Step: 5
Training loss: 4.561230208442049
Validation loss: 3.6088449257338233

Epoch: 6| Step: 6
Training loss: 4.165088863455198
Validation loss: 3.6043172251584794

Epoch: 6| Step: 7
Training loss: 3.410965341759295
Validation loss: 3.604119183817172

Epoch: 6| Step: 8
Training loss: 3.996028358916347
Validation loss: 3.6017070407863914

Epoch: 6| Step: 9
Training loss: 3.082159196835269
Validation loss: 3.5991420049278564

Epoch: 6| Step: 10
Training loss: 2.6197788448032613
Validation loss: 3.5981109952759627

Epoch: 6| Step: 11
Training loss: 3.712876241095231
Validation loss: 3.597814777011594

Epoch: 6| Step: 12
Training loss: 4.166402248893518
Validation loss: 3.59550289653478

Epoch: 6| Step: 13
Training loss: 3.823996797536363
Validation loss: 3.592333094416851

Epoch: 14| Step: 0
Training loss: 3.4777459691237995
Validation loss: 3.5897435237425204

Epoch: 6| Step: 1
Training loss: 3.413081746242062
Validation loss: 3.587985229120239

Epoch: 6| Step: 2
Training loss: 3.351497480566508
Validation loss: 3.587661420647739

Epoch: 6| Step: 3
Training loss: 4.528927543291327
Validation loss: 3.5899334987733513

Epoch: 6| Step: 4
Training loss: 3.625242554014759
Validation loss: 3.5856734664375978

Epoch: 6| Step: 5
Training loss: 3.705934641706936
Validation loss: 3.5989310477236782

Epoch: 6| Step: 6
Training loss: 3.514090648248341
Validation loss: 3.5980971970468896

Epoch: 6| Step: 7
Training loss: 3.667965629990686
Validation loss: 3.5950540766919747

Epoch: 6| Step: 8
Training loss: 4.336820715226262
Validation loss: 3.587658469466193

Epoch: 6| Step: 9
Training loss: 3.3844993561417076
Validation loss: 3.589341194392878

Epoch: 6| Step: 10
Training loss: 3.325028245848952
Validation loss: 3.585950318403678

Epoch: 6| Step: 11
Training loss: 3.9692442578704696
Validation loss: 3.584299060889574

Epoch: 6| Step: 12
Training loss: 4.650855709628832
Validation loss: 3.5831281961463515

Epoch: 6| Step: 13
Training loss: 3.8080642410357233
Validation loss: 3.5812258097166594

Epoch: 15| Step: 0
Training loss: 3.340611205683634
Validation loss: 3.577626839692064

Epoch: 6| Step: 1
Training loss: 3.7867071952352336
Validation loss: 3.5739408386230562

Epoch: 6| Step: 2
Training loss: 3.3037581343159177
Validation loss: 3.572386578752526

Epoch: 6| Step: 3
Training loss: 3.7890582212443626
Validation loss: 3.570637632646375

Epoch: 6| Step: 4
Training loss: 4.175089879696009
Validation loss: 3.56562855191267

Epoch: 6| Step: 5
Training loss: 4.497540755625317
Validation loss: 3.5621993818316717

Epoch: 6| Step: 6
Training loss: 4.0166175892048965
Validation loss: 3.557441470569866

Epoch: 6| Step: 7
Training loss: 3.844610846660018
Validation loss: 3.5540422472592863

Epoch: 6| Step: 8
Training loss: 3.0713839226706017
Validation loss: 3.551229308885921

Epoch: 6| Step: 9
Training loss: 3.794019339488544
Validation loss: 3.5481934161759088

Epoch: 6| Step: 10
Training loss: 4.067850433615837
Validation loss: 3.5459674084012156

Epoch: 6| Step: 11
Training loss: 3.8790245076541403
Validation loss: 3.5463292035018785

Epoch: 6| Step: 12
Training loss: 2.95068533097386
Validation loss: 3.5453819438067513

Epoch: 6| Step: 13
Training loss: 3.9425511734083867
Validation loss: 3.541620447242075

Epoch: 16| Step: 0
Training loss: 3.7809087425908343
Validation loss: 3.5418500463120224

Epoch: 6| Step: 1
Training loss: 2.642945844126465
Validation loss: 3.5372027781433237

Epoch: 6| Step: 2
Training loss: 3.8905198416229063
Validation loss: 3.535066085206764

Epoch: 6| Step: 3
Training loss: 3.854054107397059
Validation loss: 3.5344307517109796

Epoch: 6| Step: 4
Training loss: 2.9037852346488786
Validation loss: 3.532970893757686

Epoch: 6| Step: 5
Training loss: 4.422716040544879
Validation loss: 3.5324767698179285

Epoch: 6| Step: 6
Training loss: 3.4872960731743925
Validation loss: 3.529807364251752

Epoch: 6| Step: 7
Training loss: 3.1213137438111995
Validation loss: 3.5272566546879225

Epoch: 6| Step: 8
Training loss: 4.442417911936795
Validation loss: 3.5248443062949235

Epoch: 6| Step: 9
Training loss: 3.397011082651085
Validation loss: 3.5230213193522526

Epoch: 6| Step: 10
Training loss: 3.7201880231121556
Validation loss: 3.520697573899757

Epoch: 6| Step: 11
Training loss: 4.267739020136323
Validation loss: 3.51914143466711

Epoch: 6| Step: 12
Training loss: 4.071636314159244
Validation loss: 3.5175511050520183

Epoch: 6| Step: 13
Training loss: 3.9181837971812468
Validation loss: 3.516856951965604

Epoch: 17| Step: 0
Training loss: 3.8784406830133205
Validation loss: 3.51361928369196

Epoch: 6| Step: 1
Training loss: 3.6764007597631028
Validation loss: 3.5121539066885146

Epoch: 6| Step: 2
Training loss: 4.239202808795725
Validation loss: 3.509808907135919

Epoch: 6| Step: 3
Training loss: 3.819970987419481
Validation loss: 3.508312248301269

Epoch: 6| Step: 4
Training loss: 3.741606792715716
Validation loss: 3.506095025268225

Epoch: 6| Step: 5
Training loss: 3.3170191329942464
Validation loss: 3.505106701678989

Epoch: 6| Step: 6
Training loss: 3.6612267165454653
Validation loss: 3.5032393938679345

Epoch: 6| Step: 7
Training loss: 3.909199813954872
Validation loss: 3.500679527333316

Epoch: 6| Step: 8
Training loss: 3.641663104534953
Validation loss: 3.499621086587743

Epoch: 6| Step: 9
Training loss: 4.271284994417961
Validation loss: 3.496472624809186

Epoch: 6| Step: 10
Training loss: 3.560007930275303
Validation loss: 3.4956222834992126

Epoch: 6| Step: 11
Training loss: 2.1450824967105793
Validation loss: 3.493938378492409

Epoch: 6| Step: 12
Training loss: 3.9055416838277646
Validation loss: 3.492104100000482

Epoch: 6| Step: 13
Training loss: 3.8880578576088305
Validation loss: 3.490999128848208

Epoch: 18| Step: 0
Training loss: 3.831350905814915
Validation loss: 3.4895652235452284

Epoch: 6| Step: 1
Training loss: 3.2585152798818715
Validation loss: 3.4897356206105274

Epoch: 6| Step: 2
Training loss: 3.9924586254405305
Validation loss: 3.4878949085283195

Epoch: 6| Step: 3
Training loss: 3.7977417007686074
Validation loss: 3.4875300006485386

Epoch: 6| Step: 4
Training loss: 3.684618583826061
Validation loss: 3.4868823149531134

Epoch: 6| Step: 5
Training loss: 4.126865312009443
Validation loss: 3.485117140132281

Epoch: 6| Step: 6
Training loss: 3.5570771286232477
Validation loss: 3.4851622010230616

Epoch: 6| Step: 7
Training loss: 3.563655197504273
Validation loss: 3.4833403241707117

Epoch: 6| Step: 8
Training loss: 4.11817089403186
Validation loss: 3.48141191342807

Epoch: 6| Step: 9
Training loss: 3.618999249928616
Validation loss: 3.481059184468961

Epoch: 6| Step: 10
Training loss: 3.424689124262136
Validation loss: 3.4789344091607206

Epoch: 6| Step: 11
Training loss: 3.92175535954216
Validation loss: 3.478601588240762

Epoch: 6| Step: 12
Training loss: 3.5644916521890453
Validation loss: 3.476660393791528

Epoch: 6| Step: 13
Training loss: 2.7238458691654577
Validation loss: 3.4764473520299117

Epoch: 19| Step: 0
Training loss: 3.8059107637112315
Validation loss: 3.4763111178012163

Epoch: 6| Step: 1
Training loss: 2.7654369742923013
Validation loss: 3.4742938579781177

Epoch: 6| Step: 2
Training loss: 3.453461919720128
Validation loss: 3.4733930083723283

Epoch: 6| Step: 3
Training loss: 4.283838311101293
Validation loss: 3.4722431291066997

Epoch: 6| Step: 4
Training loss: 3.441752352506125
Validation loss: 3.471756202735272

Epoch: 6| Step: 5
Training loss: 4.551906462957007
Validation loss: 3.470965900722573

Epoch: 6| Step: 6
Training loss: 3.0089410423418173
Validation loss: 3.4692220532030094

Epoch: 6| Step: 7
Training loss: 3.7720191453951477
Validation loss: 3.468721071296522

Epoch: 6| Step: 8
Training loss: 3.456676745153269
Validation loss: 3.466885449255629

Epoch: 6| Step: 9
Training loss: 3.6862524476145073
Validation loss: 3.4669581112882253

Epoch: 6| Step: 10
Training loss: 3.8935872639407205
Validation loss: 3.464955533888285

Epoch: 6| Step: 11
Training loss: 3.827555711416755
Validation loss: 3.4630160489030923

Epoch: 6| Step: 12
Training loss: 3.3722173734403467
Validation loss: 3.4634905890079355

Epoch: 6| Step: 13
Training loss: 4.09759201421291
Validation loss: 3.4614179894285466

Epoch: 20| Step: 0
Training loss: 2.723564882959812
Validation loss: 3.461060827366192

Epoch: 6| Step: 1
Training loss: 3.6195445609882317
Validation loss: 3.459780057732816

Epoch: 6| Step: 2
Training loss: 3.8792939544565335
Validation loss: 3.4589764876285085

Epoch: 6| Step: 3
Training loss: 3.862710476668229
Validation loss: 3.4582975118605224

Epoch: 6| Step: 4
Training loss: 2.775214944711376
Validation loss: 3.457244607283276

Epoch: 6| Step: 5
Training loss: 3.3648873458528685
Validation loss: 3.4555462279708964

Epoch: 6| Step: 6
Training loss: 3.7401803194527243
Validation loss: 3.4555401830330514

Epoch: 6| Step: 7
Training loss: 3.656373111575826
Validation loss: 3.4548415757603954

Epoch: 6| Step: 8
Training loss: 3.5709452329274645
Validation loss: 3.4659589399016664

Epoch: 6| Step: 9
Training loss: 4.021550775010348
Validation loss: 3.453518476606504

Epoch: 6| Step: 10
Training loss: 3.8999526876856496
Validation loss: 3.452124744813261

Epoch: 6| Step: 11
Training loss: 4.608654728880672
Validation loss: 3.4516023244543295

Epoch: 6| Step: 12
Training loss: 3.935367672912952
Validation loss: 3.451649245204133

Epoch: 6| Step: 13
Training loss: 3.1490434011531487
Validation loss: 3.452029660528311

Epoch: 21| Step: 0
Training loss: 3.1992439390129404
Validation loss: 3.4509799560654546

Epoch: 6| Step: 1
Training loss: 4.0130816171817525
Validation loss: 3.450773674804021

Epoch: 6| Step: 2
Training loss: 2.858692025087578
Validation loss: 3.450778578056963

Epoch: 6| Step: 3
Training loss: 3.7644808602051074
Validation loss: 3.448966445180162

Epoch: 6| Step: 4
Training loss: 4.477303382053886
Validation loss: 3.4487504423441115

Epoch: 6| Step: 5
Training loss: 3.9616885103408004
Validation loss: 3.446907154171614

Epoch: 6| Step: 6
Training loss: 3.417630842671898
Validation loss: 3.4454224174838366

Epoch: 6| Step: 7
Training loss: 3.2326431429177465
Validation loss: 3.4450177929399084

Epoch: 6| Step: 8
Training loss: 4.132952566964248
Validation loss: 3.444785289018696

Epoch: 6| Step: 9
Training loss: 3.106788671441787
Validation loss: 3.4441828645487886

Epoch: 6| Step: 10
Training loss: 3.1594596632604017
Validation loss: 3.4434573907969708

Epoch: 6| Step: 11
Training loss: 3.336528216553242
Validation loss: 3.4421186054522925

Epoch: 6| Step: 12
Training loss: 4.113908826693973
Validation loss: 3.441660516883317

Epoch: 6| Step: 13
Training loss: 4.465062040130775
Validation loss: 3.4418551989399875

Epoch: 22| Step: 0
Training loss: 2.962666914861184
Validation loss: 3.4407568961892867

Epoch: 6| Step: 1
Training loss: 2.8027786091892644
Validation loss: 3.4401540256186047

Epoch: 6| Step: 2
Training loss: 4.043439076658679
Validation loss: 3.4396672491601454

Epoch: 6| Step: 3
Training loss: 4.227522256297444
Validation loss: 3.4390981626509545

Epoch: 6| Step: 4
Training loss: 3.726472417674321
Validation loss: 3.4387150873856083

Epoch: 6| Step: 5
Training loss: 4.266742266541511
Validation loss: 3.4375853169015897

Epoch: 6| Step: 6
Training loss: 3.5912889097544345
Validation loss: 3.4391990885004455

Epoch: 6| Step: 7
Training loss: 3.2303108075242557
Validation loss: 3.4397927879746204

Epoch: 6| Step: 8
Training loss: 3.676650298270354
Validation loss: 3.436101297387345

Epoch: 6| Step: 9
Training loss: 4.256359951486845
Validation loss: 3.4358444164772948

Epoch: 6| Step: 10
Training loss: 2.7441116928801765
Validation loss: 3.4352878168174605

Epoch: 6| Step: 11
Training loss: 3.472269832708526
Validation loss: 3.4347222732995912

Epoch: 6| Step: 12
Training loss: 4.019014464318871
Validation loss: 3.4352899899451774

Epoch: 6| Step: 13
Training loss: 3.817035041478338
Validation loss: 3.4340173644628282

Epoch: 23| Step: 0
Training loss: 3.9656780699296923
Validation loss: 3.433401965518508

Epoch: 6| Step: 1
Training loss: 4.412538842740797
Validation loss: 3.4325278962713144

Epoch: 6| Step: 2
Training loss: 3.5506482996459
Validation loss: 3.4320753474000956

Epoch: 6| Step: 3
Training loss: 3.671830976506372
Validation loss: 3.431304645318

Epoch: 6| Step: 4
Training loss: 4.511609255300127
Validation loss: 3.431200767615316

Epoch: 6| Step: 5
Training loss: 3.372877513209783
Validation loss: 3.4299549263224947

Epoch: 6| Step: 6
Training loss: 3.7380772836940688
Validation loss: 3.4292458049798142

Epoch: 6| Step: 7
Training loss: 2.3949951917245658
Validation loss: 3.4286022578595188

Epoch: 6| Step: 8
Training loss: 3.147038529966584
Validation loss: 3.4282654793862495

Epoch: 6| Step: 9
Training loss: 3.806269448016112
Validation loss: 3.4275359065526496

Epoch: 6| Step: 10
Training loss: 3.020970483933089
Validation loss: 3.4273482291787714

Epoch: 6| Step: 11
Training loss: 4.3374790509952055
Validation loss: 3.4269312681997692

Epoch: 6| Step: 12
Training loss: 3.3602188824703596
Validation loss: 3.426740256971263

Epoch: 6| Step: 13
Training loss: 2.9316066305386643
Validation loss: 3.4265295267495417

Epoch: 24| Step: 0
Training loss: 3.547407606022545
Validation loss: 3.425426375955423

Epoch: 6| Step: 1
Training loss: 3.8160501429144382
Validation loss: 3.4250709397002557

Epoch: 6| Step: 2
Training loss: 4.163958979423815
Validation loss: 3.4248025331698284

Epoch: 6| Step: 3
Training loss: 3.9745713440671295
Validation loss: 3.4241248369951083

Epoch: 6| Step: 4
Training loss: 3.4816777348346246
Validation loss: 3.423195896819288

Epoch: 6| Step: 5
Training loss: 3.7765036815502637
Validation loss: 3.422096732606684

Epoch: 6| Step: 6
Training loss: 3.001303866283138
Validation loss: 3.4214407723568945

Epoch: 6| Step: 7
Training loss: 3.294248863820435
Validation loss: 3.4209216869820467

Epoch: 6| Step: 8
Training loss: 4.089738583966054
Validation loss: 3.420461509097577

Epoch: 6| Step: 9
Training loss: 4.26522523452977
Validation loss: 3.419780988581205

Epoch: 6| Step: 10
Training loss: 2.887920207044062
Validation loss: 3.419245412795289

Epoch: 6| Step: 11
Training loss: 2.7974154839860965
Validation loss: 3.418759885578966

Epoch: 6| Step: 12
Training loss: 3.633610857125863
Validation loss: 3.418436756913464

Epoch: 6| Step: 13
Training loss: 4.159416655941625
Validation loss: 3.418009631871964

Epoch: 25| Step: 0
Training loss: 3.125353373575026
Validation loss: 3.4176075002907567

Epoch: 6| Step: 1
Training loss: 3.392726826854068
Validation loss: 3.417058188943233

Epoch: 6| Step: 2
Training loss: 2.4443172099012904
Validation loss: 3.416724235795994

Epoch: 6| Step: 3
Training loss: 3.4873611586631155
Validation loss: 3.416181552901971

Epoch: 6| Step: 4
Training loss: 3.6910869157510917
Validation loss: 3.4157432285678078

Epoch: 6| Step: 5
Training loss: 3.968288484907654
Validation loss: 3.415173272984871

Epoch: 6| Step: 6
Training loss: 3.6827087310038666
Validation loss: 3.414581251157226

Epoch: 6| Step: 7
Training loss: 3.7480690117083384
Validation loss: 3.414436882796713

Epoch: 6| Step: 8
Training loss: 3.594812916011492
Validation loss: 3.4137849582995377

Epoch: 6| Step: 9
Training loss: 4.590703460043639
Validation loss: 3.4129973401219895

Epoch: 6| Step: 10
Training loss: 3.3776919614057497
Validation loss: 3.4127597911735066

Epoch: 6| Step: 11
Training loss: 3.8909681544200456
Validation loss: 3.4119830295004285

Epoch: 6| Step: 12
Training loss: 4.407214336517775
Validation loss: 3.411775977401196

Epoch: 6| Step: 13
Training loss: 2.5088887504826882
Validation loss: 3.411465244932797

Epoch: 26| Step: 0
Training loss: 3.040340988209211
Validation loss: 3.4106534981506775

Epoch: 6| Step: 1
Training loss: 3.5241540150668245
Validation loss: 3.4101058256526424

Epoch: 6| Step: 2
Training loss: 3.934487052939808
Validation loss: 3.4095456889156077

Epoch: 6| Step: 3
Training loss: 4.017407211058258
Validation loss: 3.40916838670073

Epoch: 6| Step: 4
Training loss: 3.3691656758579556
Validation loss: 3.4084938698890723

Epoch: 6| Step: 5
Training loss: 2.6801183593291973
Validation loss: 3.408270573849931

Epoch: 6| Step: 6
Training loss: 3.4367840107945433
Validation loss: 3.4079130443774224

Epoch: 6| Step: 7
Training loss: 4.202618082669337
Validation loss: 3.4072654575016004

Epoch: 6| Step: 8
Training loss: 3.892107455159079
Validation loss: 3.4070027063401627

Epoch: 6| Step: 9
Training loss: 3.526948046957871
Validation loss: 3.4062416789297654

Epoch: 6| Step: 10
Training loss: 3.902864988415286
Validation loss: 3.4057185607144524

Epoch: 6| Step: 11
Training loss: 3.4435522725411247
Validation loss: 3.40515786791886

Epoch: 6| Step: 12
Training loss: 3.694049772694533
Validation loss: 3.4047065753642696

Epoch: 6| Step: 13
Training loss: 4.149505190478217
Validation loss: 3.4046933200611766

Epoch: 27| Step: 0
Training loss: 3.6745386729388683
Validation loss: 3.4038566828278576

Epoch: 6| Step: 1
Training loss: 3.6639982108065974
Validation loss: 3.403207426143518

Epoch: 6| Step: 2
Training loss: 3.702276076217338
Validation loss: 3.4027714085025766

Epoch: 6| Step: 3
Training loss: 3.1572807819443547
Validation loss: 3.4023716743189545

Epoch: 6| Step: 4
Training loss: 3.674708664952615
Validation loss: 3.401619856000761

Epoch: 6| Step: 5
Training loss: 3.4125322277517522
Validation loss: 3.4012981244546614

Epoch: 6| Step: 6
Training loss: 3.7146175728826454
Validation loss: 3.4007431874440455

Epoch: 6| Step: 7
Training loss: 3.5513417354498906
Validation loss: 3.400229136390354

Epoch: 6| Step: 8
Training loss: 3.50681187008763
Validation loss: 3.4003033570228367

Epoch: 6| Step: 9
Training loss: 3.879247490969274
Validation loss: 3.399468066173673

Epoch: 6| Step: 10
Training loss: 3.9557502081359335
Validation loss: 3.398218451335663

Epoch: 6| Step: 11
Training loss: 2.984652840827762
Validation loss: 3.3981903676553435

Epoch: 6| Step: 12
Training loss: 4.181448592186871
Validation loss: 3.397721757058932

Epoch: 6| Step: 13
Training loss: 3.5777824937566893
Validation loss: 3.397118727841992

Epoch: 28| Step: 0
Training loss: 3.4101266062213855
Validation loss: 3.396440643555671

Epoch: 6| Step: 1
Training loss: 3.9925634875233103
Validation loss: 3.396405433363357

Epoch: 6| Step: 2
Training loss: 3.3036888543545864
Validation loss: 3.3956897513235487

Epoch: 6| Step: 3
Training loss: 3.821475111470424
Validation loss: 3.3950997370574214

Epoch: 6| Step: 4
Training loss: 3.1876705348452656
Validation loss: 3.394879828132517

Epoch: 6| Step: 5
Training loss: 3.6699531882728107
Validation loss: 3.394239423900691

Epoch: 6| Step: 6
Training loss: 3.4939386470410594
Validation loss: 3.3937114158541113

Epoch: 6| Step: 7
Training loss: 3.5527392068067747
Validation loss: 3.3929180710039204

Epoch: 6| Step: 8
Training loss: 3.4967572312556072
Validation loss: 3.3925293648363932

Epoch: 6| Step: 9
Training loss: 4.090659336211174
Validation loss: 3.392450585079276

Epoch: 6| Step: 10
Training loss: 4.045634311504424
Validation loss: 3.3916678902398405

Epoch: 6| Step: 11
Training loss: 3.2423417755557726
Validation loss: 3.3910934814908913

Epoch: 6| Step: 12
Training loss: 2.7277432483767496
Validation loss: 3.390783524081118

Epoch: 6| Step: 13
Training loss: 4.8672286471224195
Validation loss: 3.390011019533788

Epoch: 29| Step: 0
Training loss: 3.167206433789607
Validation loss: 3.389492791942982

Epoch: 6| Step: 1
Training loss: 2.7151521576172617
Validation loss: 3.389392657374764

Epoch: 6| Step: 2
Training loss: 3.8215664480926534
Validation loss: 3.389003752612075

Epoch: 6| Step: 3
Training loss: 3.9974908111256715
Validation loss: 3.388478980940274

Epoch: 6| Step: 4
Training loss: 4.211572942401677
Validation loss: 3.387869452997727

Epoch: 6| Step: 5
Training loss: 2.9511321271520834
Validation loss: 3.3873733815303027

Epoch: 6| Step: 6
Training loss: 4.168063476401307
Validation loss: 3.3867715496804296

Epoch: 6| Step: 7
Training loss: 3.6205680325631184
Validation loss: 3.386712230977893

Epoch: 6| Step: 8
Training loss: 4.075082162602125
Validation loss: 3.387056176283634

Epoch: 6| Step: 9
Training loss: 3.536904458103435
Validation loss: 3.3855651646206173

Epoch: 6| Step: 10
Training loss: 3.034687884902969
Validation loss: 3.38480354051488

Epoch: 6| Step: 11
Training loss: 4.0243532786676965
Validation loss: 3.3846476615576058

Epoch: 6| Step: 12
Training loss: 3.601343375799175
Validation loss: 3.3835673713531413

Epoch: 6| Step: 13
Training loss: 3.040311973274523
Validation loss: 3.3834423179981883

Epoch: 30| Step: 0
Training loss: 3.779685461288981
Validation loss: 3.3832982045759574

Epoch: 6| Step: 1
Training loss: 3.056984118579146
Validation loss: 3.3828326343118214

Epoch: 6| Step: 2
Training loss: 2.7290539220764454
Validation loss: 3.382165096172476

Epoch: 6| Step: 3
Training loss: 3.7155132151761268
Validation loss: 3.381561336658088

Epoch: 6| Step: 4
Training loss: 3.5854558351110986
Validation loss: 3.381167426175876

Epoch: 6| Step: 5
Training loss: 3.434469794786565
Validation loss: 3.380767401116609

Epoch: 6| Step: 6
Training loss: 3.801704004604126
Validation loss: 3.3800650917878077

Epoch: 6| Step: 7
Training loss: 4.43780108222919
Validation loss: 3.379649005175126

Epoch: 6| Step: 8
Training loss: 2.922376620231149
Validation loss: 3.3795797463618653

Epoch: 6| Step: 9
Training loss: 3.776246093828794
Validation loss: 3.3788811878984615

Epoch: 6| Step: 10
Training loss: 3.9117010306263094
Validation loss: 3.378382506599997

Epoch: 6| Step: 11
Training loss: 3.688599761933429
Validation loss: 3.377869966107433

Epoch: 6| Step: 12
Training loss: 3.477556339468456
Validation loss: 3.3772219867680566

Epoch: 6| Step: 13
Training loss: 4.118715990588913
Validation loss: 3.3770293451110898

Epoch: 31| Step: 0
Training loss: 4.109485001052681
Validation loss: 3.3765976624907403

Epoch: 6| Step: 1
Training loss: 3.839089025484205
Validation loss: 3.375839122247078

Epoch: 6| Step: 2
Training loss: 3.6397715865770497
Validation loss: 3.375250450421664

Epoch: 6| Step: 3
Training loss: 3.725063958355004
Validation loss: 3.375065048241133

Epoch: 6| Step: 4
Training loss: 3.1522188031890663
Validation loss: 3.3744195418443197

Epoch: 6| Step: 5
Training loss: 3.2749844266797847
Validation loss: 3.3743896373026394

Epoch: 6| Step: 6
Training loss: 3.6519260759256724
Validation loss: 3.3735769971942027

Epoch: 6| Step: 7
Training loss: 3.8692392166262497
Validation loss: 3.372776854945713

Epoch: 6| Step: 8
Training loss: 3.514906881952059
Validation loss: 3.3730472200568085

Epoch: 6| Step: 9
Training loss: 2.7389426310151936
Validation loss: 3.3723247184038345

Epoch: 6| Step: 10
Training loss: 4.421974207974996
Validation loss: 3.371762716665624

Epoch: 6| Step: 11
Training loss: 2.6769795873901825
Validation loss: 3.3712172766449804

Epoch: 6| Step: 12
Training loss: 3.8636049881339445
Validation loss: 3.3710706025091994

Epoch: 6| Step: 13
Training loss: 3.597890442423331
Validation loss: 3.3704755544660983

Epoch: 32| Step: 0
Training loss: 4.023372079261821
Validation loss: 3.369996311977731

Epoch: 6| Step: 1
Training loss: 4.136674486307094
Validation loss: 3.3694595077099447

Epoch: 6| Step: 2
Training loss: 3.573079378892074
Validation loss: 3.36916537453655

Epoch: 6| Step: 3
Training loss: 3.572576627129762
Validation loss: 3.3687350783342085

Epoch: 6| Step: 4
Training loss: 4.0338136077017355
Validation loss: 3.368054214667281

Epoch: 6| Step: 5
Training loss: 3.600705919990331
Validation loss: 3.367340896767254

Epoch: 6| Step: 6
Training loss: 3.7734984082978964
Validation loss: 3.367395857889418

Epoch: 6| Step: 7
Training loss: 3.4685048884488903
Validation loss: 3.366351589342386

Epoch: 6| Step: 8
Training loss: 3.770268786129913
Validation loss: 3.3663788800905396

Epoch: 6| Step: 9
Training loss: 2.8843675673235083
Validation loss: 3.3653424728984116

Epoch: 6| Step: 10
Training loss: 3.3559996214947128
Validation loss: 3.3653939655854246

Epoch: 6| Step: 11
Training loss: 3.152077210986202
Validation loss: 3.364424471868648

Epoch: 6| Step: 12
Training loss: 3.4505880711560164
Validation loss: 3.364524587574718

Epoch: 6| Step: 13
Training loss: 3.268374950708748
Validation loss: 3.3638366527996424

Epoch: 33| Step: 0
Training loss: 4.311379328530203
Validation loss: 3.3632505878368852

Epoch: 6| Step: 1
Training loss: 3.566835141585057
Validation loss: 3.3628946695066197

Epoch: 6| Step: 2
Training loss: 3.2855532085433397
Validation loss: 3.362584884870669

Epoch: 6| Step: 3
Training loss: 4.363726232065661
Validation loss: 3.361929030362405

Epoch: 6| Step: 4
Training loss: 3.462897785349337
Validation loss: 3.361313823066454

Epoch: 6| Step: 5
Training loss: 2.6824214768093486
Validation loss: 3.3611022522873797

Epoch: 6| Step: 6
Training loss: 3.4332112694927006
Validation loss: 3.3606588388238365

Epoch: 6| Step: 7
Training loss: 3.251285005503473
Validation loss: 3.360851948945037

Epoch: 6| Step: 8
Training loss: 3.5172543967149914
Validation loss: 3.3598516280170476

Epoch: 6| Step: 9
Training loss: 3.408834614222876
Validation loss: 3.359168740932989

Epoch: 6| Step: 10
Training loss: 3.3149343218849214
Validation loss: 3.359103322281906

Epoch: 6| Step: 11
Training loss: 4.2192753217493
Validation loss: 3.3583315229114574

Epoch: 6| Step: 12
Training loss: 3.4324120060032244
Validation loss: 3.3587368449881763

Epoch: 6| Step: 13
Training loss: 3.814518878641538
Validation loss: 3.3584687598163323

Epoch: 34| Step: 0
Training loss: 3.9503163850806087
Validation loss: 3.3574225759610186

Epoch: 6| Step: 1
Training loss: 3.3193008856453194
Validation loss: 3.3568812683024825

Epoch: 6| Step: 2
Training loss: 3.3163550634668812
Validation loss: 3.3563802677374723

Epoch: 6| Step: 3
Training loss: 3.819907574559079
Validation loss: 3.356225524435456

Epoch: 6| Step: 4
Training loss: 3.4202651325987152
Validation loss: 3.355623114885342

Epoch: 6| Step: 5
Training loss: 3.497775869771568
Validation loss: 3.355350512977854

Epoch: 6| Step: 6
Training loss: 3.2289926461531517
Validation loss: 3.354691539968515

Epoch: 6| Step: 7
Training loss: 2.8825562732824728
Validation loss: 3.354410687844259

Epoch: 6| Step: 8
Training loss: 3.1527235518472847
Validation loss: 3.353875253734303

Epoch: 6| Step: 9
Training loss: 3.8303609740663336
Validation loss: 3.3534391028492636

Epoch: 6| Step: 10
Training loss: 2.9525187844010765
Validation loss: 3.353195187829591

Epoch: 6| Step: 11
Training loss: 3.4636685379234233
Validation loss: 3.3527699561604054

Epoch: 6| Step: 12
Training loss: 5.1066196489950135
Validation loss: 3.3521947692920695

Epoch: 6| Step: 13
Training loss: 3.923543992870382
Validation loss: 3.3515342854443975

Epoch: 35| Step: 0
Training loss: 3.119366871099594
Validation loss: 3.3513684369444965

Epoch: 6| Step: 1
Training loss: 3.741599401083183
Validation loss: 3.3508770009771407

Epoch: 6| Step: 2
Training loss: 4.707613301992702
Validation loss: 3.3506608507400446

Epoch: 6| Step: 3
Training loss: 4.466882702361923
Validation loss: 3.35027290889255

Epoch: 6| Step: 4
Training loss: 3.068223237551208
Validation loss: 3.349034834877095

Epoch: 6| Step: 5
Training loss: 3.393282503697908
Validation loss: 3.349469985627997

Epoch: 6| Step: 6
Training loss: 3.4328209676798727
Validation loss: 3.3482133580297853

Epoch: 6| Step: 7
Training loss: 3.5596577867766954
Validation loss: 3.348326551861039

Epoch: 6| Step: 8
Training loss: 3.6592722082645404
Validation loss: 3.347346488817561

Epoch: 6| Step: 9
Training loss: 3.611130192698087
Validation loss: 3.347343549397602

Epoch: 6| Step: 10
Training loss: 3.1165639306201594
Validation loss: 3.3468538326469846

Epoch: 6| Step: 11
Training loss: 3.7154790774246425
Validation loss: 3.3466048613319357

Epoch: 6| Step: 12
Training loss: 2.763222378143275
Validation loss: 3.3455858332571013

Epoch: 6| Step: 13
Training loss: 3.1694711680896486
Validation loss: 3.345636327369914

Epoch: 36| Step: 0
Training loss: 3.8348135923517765
Validation loss: 3.3452709098336837

Epoch: 6| Step: 1
Training loss: 3.041685095604934
Validation loss: 3.3445200684580527

Epoch: 6| Step: 2
Training loss: 4.678251170238813
Validation loss: 3.3444489883277333

Epoch: 6| Step: 3
Training loss: 3.2662653683031877
Validation loss: 3.3435990770344297

Epoch: 6| Step: 4
Training loss: 3.8937678990327718
Validation loss: 3.3430845671671094

Epoch: 6| Step: 5
Training loss: 2.793606515907825
Validation loss: 3.342848057240406

Epoch: 6| Step: 6
Training loss: 3.8341472977832547
Validation loss: 3.342574879018214

Epoch: 6| Step: 7
Training loss: 3.0392134366639394
Validation loss: 3.3417481717180597

Epoch: 6| Step: 8
Training loss: 3.1642312840784292
Validation loss: 3.3415020177273678

Epoch: 6| Step: 9
Training loss: 3.1100849510439357
Validation loss: 3.340835239320832

Epoch: 6| Step: 10
Training loss: 3.6394216488824833
Validation loss: 3.340618612780856

Epoch: 6| Step: 11
Training loss: 3.3425523270795834
Validation loss: 3.339997071644432

Epoch: 6| Step: 12
Training loss: 3.8071090856243863
Validation loss: 3.339574095979914

Epoch: 6| Step: 13
Training loss: 4.602980701181488
Validation loss: 3.3393305209240234

Epoch: 37| Step: 0
Training loss: 3.944699804490373
Validation loss: 3.339105747550963

Epoch: 6| Step: 1
Training loss: 3.4324553493587935
Validation loss: 3.3383436561663937

Epoch: 6| Step: 2
Training loss: 3.15763628136237
Validation loss: 3.3379869668148086

Epoch: 6| Step: 3
Training loss: 2.946724227009366
Validation loss: 3.3372996011197973

Epoch: 6| Step: 4
Training loss: 3.1300992941417247
Validation loss: 3.337395641979318

Epoch: 6| Step: 5
Training loss: 3.628315034632405
Validation loss: 3.3366573992411346

Epoch: 6| Step: 6
Training loss: 4.025336134244237
Validation loss: 3.336503553779273

Epoch: 6| Step: 7
Training loss: 4.042784755777009
Validation loss: 3.336080519407323

Epoch: 6| Step: 8
Training loss: 3.274181927724451
Validation loss: 3.335627871040788

Epoch: 6| Step: 9
Training loss: 3.454179421567356
Validation loss: 3.335018739124488

Epoch: 6| Step: 10
Training loss: 3.644775644103435
Validation loss: 3.3355960262435738

Epoch: 6| Step: 11
Training loss: 3.7617409330131886
Validation loss: 3.335019699235043

Epoch: 6| Step: 12
Training loss: 3.7626147129149747
Validation loss: 3.334717283796639

Epoch: 6| Step: 13
Training loss: 3.6867275398797923
Validation loss: 3.3336864520251273

Epoch: 38| Step: 0
Training loss: 3.743610660972215
Validation loss: 3.333091657604109

Epoch: 6| Step: 1
Training loss: 3.3257209799253933
Validation loss: 3.3319552700623833

Epoch: 6| Step: 2
Training loss: 3.6167060416285888
Validation loss: 3.332734686921071

Epoch: 6| Step: 3
Training loss: 4.2203022679554785
Validation loss: 3.331496837730195

Epoch: 6| Step: 4
Training loss: 4.359899564513669
Validation loss: 3.330422630842374

Epoch: 6| Step: 5
Training loss: 2.6015916427492147
Validation loss: 3.3305662765503024

Epoch: 6| Step: 6
Training loss: 3.8329058007922114
Validation loss: 3.33018480211291

Epoch: 6| Step: 7
Training loss: 4.032026349208657
Validation loss: 3.329794143617621

Epoch: 6| Step: 8
Training loss: 3.3476576743907414
Validation loss: 3.3294888789273656

Epoch: 6| Step: 9
Training loss: 2.9892825375182133
Validation loss: 3.329636674893454

Epoch: 6| Step: 10
Training loss: 3.02511952061628
Validation loss: 3.328881082669895

Epoch: 6| Step: 11
Training loss: 3.861530890999521
Validation loss: 3.3284476473963593

Epoch: 6| Step: 12
Training loss: 3.2169885352454832
Validation loss: 3.3276396998455446

Epoch: 6| Step: 13
Training loss: 3.199305643804297
Validation loss: 3.3279213768661884

Epoch: 39| Step: 0
Training loss: 3.650413092660927
Validation loss: 3.3268737582306933

Epoch: 6| Step: 1
Training loss: 3.8391259144322465
Validation loss: 3.3266237462458395

Epoch: 6| Step: 2
Training loss: 3.7813448302933095
Validation loss: 3.325760398780747

Epoch: 6| Step: 3
Training loss: 2.403563151206637
Validation loss: 3.3247678675837307

Epoch: 6| Step: 4
Training loss: 3.8987667579205114
Validation loss: 3.3245908089555654

Epoch: 6| Step: 5
Training loss: 3.5327489591584427
Validation loss: 3.3243917104479466

Epoch: 6| Step: 6
Training loss: 3.0729692530038806
Validation loss: 3.3243996001849276

Epoch: 6| Step: 7
Training loss: 3.7338759595621926
Validation loss: 3.3231126021136337

Epoch: 6| Step: 8
Training loss: 3.8290934680560325
Validation loss: 3.3226903117661313

Epoch: 6| Step: 9
Training loss: 3.5823161137752306
Validation loss: 3.3221009390822958

Epoch: 6| Step: 10
Training loss: 4.154136866262076
Validation loss: 3.322787895154475

Epoch: 6| Step: 11
Training loss: 2.8322629215586494
Validation loss: 3.3200275458596535

Epoch: 6| Step: 12
Training loss: 3.408531614721314
Validation loss: 3.320060646499265

Epoch: 6| Step: 13
Training loss: 3.950462077673475
Validation loss: 3.3178183369188314

Epoch: 40| Step: 0
Training loss: 2.9614983583568457
Validation loss: 3.316884132198515

Epoch: 6| Step: 1
Training loss: 3.963301154653841
Validation loss: 3.3168418524087353

Epoch: 6| Step: 2
Training loss: 4.2730924756457025
Validation loss: 3.3139209636620888

Epoch: 6| Step: 3
Training loss: 3.817943126888326
Validation loss: 3.3141467365607484

Epoch: 6| Step: 4
Training loss: 3.676177016710555
Validation loss: 3.3128457054428497

Epoch: 6| Step: 5
Training loss: 3.167460559578347
Validation loss: 3.312357984034319

Epoch: 6| Step: 6
Training loss: 3.583764575174189
Validation loss: 3.312760300875314

Epoch: 6| Step: 7
Training loss: 3.6675272422980103
Validation loss: 3.313468591821139

Epoch: 6| Step: 8
Training loss: 3.232727368258541
Validation loss: 3.310575214303046

Epoch: 6| Step: 9
Training loss: 3.082701248814247
Validation loss: 3.3254589028436685

Epoch: 6| Step: 10
Training loss: 4.045606495358045
Validation loss: 3.3732023689184527

Epoch: 6| Step: 11
Training loss: 2.8602028570725464
Validation loss: 3.309597388259015

Epoch: 6| Step: 12
Training loss: 3.2103362994043843
Validation loss: 3.3107972298976795

Epoch: 6| Step: 13
Training loss: 4.266194623425121
Validation loss: 3.3125945867344497

Epoch: 41| Step: 0
Training loss: 3.0734216997043973
Validation loss: 3.315075873297612

Epoch: 6| Step: 1
Training loss: 3.4352395688489823
Validation loss: 3.3168268392514557

Epoch: 6| Step: 2
Training loss: 2.7448842408833216
Validation loss: 3.3156642323594783

Epoch: 6| Step: 3
Training loss: 3.5020043219905133
Validation loss: 3.3143199503513103

Epoch: 6| Step: 4
Training loss: 4.319667002241482
Validation loss: 3.3116797981361263

Epoch: 6| Step: 5
Training loss: 3.663720739241921
Validation loss: 3.310854260934118

Epoch: 6| Step: 6
Training loss: 3.319784252556257
Validation loss: 3.3114950196053323

Epoch: 6| Step: 7
Training loss: 3.7011252367609067
Validation loss: 3.3114497461779777

Epoch: 6| Step: 8
Training loss: 2.736299197406872
Validation loss: 3.3103824626076337

Epoch: 6| Step: 9
Training loss: 3.652721430380563
Validation loss: 3.31005720390932

Epoch: 6| Step: 10
Training loss: 3.1804651157749135
Validation loss: 3.3086766943514685

Epoch: 6| Step: 11
Training loss: 4.091723224277493
Validation loss: 3.3086332396367295

Epoch: 6| Step: 12
Training loss: 3.834818690464115
Validation loss: 3.3059884661633787

Epoch: 6| Step: 13
Training loss: 4.402405272141103
Validation loss: 3.3055103163672444

Epoch: 42| Step: 0
Training loss: 3.9175140329972615
Validation loss: 3.30509162626642

Epoch: 6| Step: 1
Training loss: 3.242705007409043
Validation loss: 3.3035138826168327

Epoch: 6| Step: 2
Training loss: 4.277286894956042
Validation loss: 3.303168096930714

Epoch: 6| Step: 3
Training loss: 3.9823264446863647
Validation loss: 3.3059241028886

Epoch: 6| Step: 4
Training loss: 3.0428817795358
Validation loss: 3.3020853995138184

Epoch: 6| Step: 5
Training loss: 3.0313170120854713
Validation loss: 3.302208886645619

Epoch: 6| Step: 6
Training loss: 4.235505463431929
Validation loss: 3.3015625535469666

Epoch: 6| Step: 7
Training loss: 3.72833376201638
Validation loss: 3.3008073975018344

Epoch: 6| Step: 8
Training loss: 2.061875682320761
Validation loss: 3.2992336271410685

Epoch: 6| Step: 9
Training loss: 3.5956043269204474
Validation loss: 3.302307365604402

Epoch: 6| Step: 10
Training loss: 2.5809358936789333
Validation loss: 3.3065173390436597

Epoch: 6| Step: 11
Training loss: 3.1885410179645155
Validation loss: 3.3085268323339823

Epoch: 6| Step: 12
Training loss: 4.141122464220525
Validation loss: 3.3065465347246974

Epoch: 6| Step: 13
Training loss: 4.0176051857073585
Validation loss: 3.2988618572261954

Epoch: 43| Step: 0
Training loss: 3.9665877091272317
Validation loss: 3.3022493244557025

Epoch: 6| Step: 1
Training loss: 3.2109876939697535
Validation loss: 3.298221719178572

Epoch: 6| Step: 2
Training loss: 2.499578058875559
Validation loss: 3.330040148379358

Epoch: 6| Step: 3
Training loss: 2.576793349862481
Validation loss: 3.3070966905180774

Epoch: 6| Step: 4
Training loss: 3.6077102851513607
Validation loss: 3.3131817537718846

Epoch: 6| Step: 5
Training loss: 4.042081254492532
Validation loss: 3.311827187480792

Epoch: 6| Step: 6
Training loss: 4.179122287645191
Validation loss: 3.3021458440373235

Epoch: 6| Step: 7
Training loss: 4.374443672775895
Validation loss: 3.293987447227778

Epoch: 6| Step: 8
Training loss: 2.8196684294762493
Validation loss: 3.2956092285248846

Epoch: 6| Step: 9
Training loss: 3.2754708395719585
Validation loss: 3.301075709262327

Epoch: 6| Step: 10
Training loss: 3.458794268182457
Validation loss: 3.3058293625211386

Epoch: 6| Step: 11
Training loss: 3.359392600789648
Validation loss: 3.3055449389927793

Epoch: 6| Step: 12
Training loss: 3.898985799328679
Validation loss: 3.2962988885808358

Epoch: 6| Step: 13
Training loss: 3.9707709746185986
Validation loss: 3.2917256135180977

Epoch: 44| Step: 0
Training loss: 3.176125070276064
Validation loss: 3.3076268557308555

Epoch: 6| Step: 1
Training loss: 3.6020118284142453
Validation loss: 3.304615082116161

Epoch: 6| Step: 2
Training loss: 3.7138339333822143
Validation loss: 3.290151864090221

Epoch: 6| Step: 3
Training loss: 4.2642934208983085
Validation loss: 3.29027541887029

Epoch: 6| Step: 4
Training loss: 3.4976316340817672
Validation loss: 3.2894752365652673

Epoch: 6| Step: 5
Training loss: 2.857539687527699
Validation loss: 3.2906479952570957

Epoch: 6| Step: 6
Training loss: 3.582472779196526
Validation loss: 3.2917583616877564

Epoch: 6| Step: 7
Training loss: 3.466407603585351
Validation loss: 3.2910594611189246

Epoch: 6| Step: 8
Training loss: 3.0482928767230146
Validation loss: 3.2891048859015983

Epoch: 6| Step: 9
Training loss: 4.218268472953341
Validation loss: 3.2877580722088546

Epoch: 6| Step: 10
Training loss: 3.6492853588574152
Validation loss: 3.2851156626540803

Epoch: 6| Step: 11
Training loss: 3.2561862463393596
Validation loss: 3.2845191635823547

Epoch: 6| Step: 12
Training loss: 2.986776134948492
Validation loss: 3.2830777868421808

Epoch: 6| Step: 13
Training loss: 4.08257229518476
Validation loss: 3.281870956770082

Epoch: 45| Step: 0
Training loss: 2.183574533122059
Validation loss: 3.280668617539209

Epoch: 6| Step: 1
Training loss: 4.364476872544025
Validation loss: 3.2805755359578765

Epoch: 6| Step: 2
Training loss: 3.4888337350307306
Validation loss: 3.279502676085533

Epoch: 6| Step: 3
Training loss: 3.4180842614409825
Validation loss: 3.2788053266554362

Epoch: 6| Step: 4
Training loss: 3.549123043220047
Validation loss: 3.27844743479328

Epoch: 6| Step: 5
Training loss: 2.7482682757738552
Validation loss: 3.278449178581219

Epoch: 6| Step: 6
Training loss: 3.294224546004275
Validation loss: 3.277067501220569

Epoch: 6| Step: 7
Training loss: 3.2564977101359376
Validation loss: 3.2776394009051866

Epoch: 6| Step: 8
Training loss: 4.227293956028351
Validation loss: 3.2764492771576132

Epoch: 6| Step: 9
Training loss: 3.159177423443934
Validation loss: 3.2765122703988903

Epoch: 6| Step: 10
Training loss: 3.9380611443681555
Validation loss: 3.2756469782000064

Epoch: 6| Step: 11
Training loss: 3.693353565197374
Validation loss: 3.275700123477853

Epoch: 6| Step: 12
Training loss: 3.931715333989644
Validation loss: 3.2769643255516705

Epoch: 6| Step: 13
Training loss: 3.511580111235469
Validation loss: 3.273705144202927

Epoch: 46| Step: 0
Training loss: 2.771489278454304
Validation loss: 3.273666631869391

Epoch: 6| Step: 1
Training loss: 3.513154242461216
Validation loss: 3.2747530400317264

Epoch: 6| Step: 2
Training loss: 2.9846961362927678
Validation loss: 3.273764995255611

Epoch: 6| Step: 3
Training loss: 3.5954836437037385
Validation loss: 3.273286229812987

Epoch: 6| Step: 4
Training loss: 3.7903581114905602
Validation loss: 3.2733100993389876

Epoch: 6| Step: 5
Training loss: 3.7114833069006714
Validation loss: 3.272162585423602

Epoch: 6| Step: 6
Training loss: 4.28583809809995
Validation loss: 3.27071302067389

Epoch: 6| Step: 7
Training loss: 2.6341837133644255
Validation loss: 3.2714843483565037

Epoch: 6| Step: 8
Training loss: 3.0357894727868557
Validation loss: 3.26934226537362

Epoch: 6| Step: 9
Training loss: 4.51967874482478
Validation loss: 3.2702073866713883

Epoch: 6| Step: 10
Training loss: 4.076251655678879
Validation loss: 3.268279501522424

Epoch: 6| Step: 11
Training loss: 3.447271572896781
Validation loss: 3.270669982564076

Epoch: 6| Step: 12
Training loss: 2.9805669805855457
Validation loss: 3.2699006313601995

Epoch: 6| Step: 13
Training loss: 3.2099304847677024
Validation loss: 3.270505238282281

Epoch: 47| Step: 0
Training loss: 3.7487277097888385
Validation loss: 3.2694592358615013

Epoch: 6| Step: 1
Training loss: 3.395029187308737
Validation loss: 3.269775750010148

Epoch: 6| Step: 2
Training loss: 3.7828459091003257
Validation loss: 3.26825410252999

Epoch: 6| Step: 3
Training loss: 2.140200162065131
Validation loss: 3.2699318803526674

Epoch: 6| Step: 4
Training loss: 4.029623487126067
Validation loss: 3.2688595112152568

Epoch: 6| Step: 5
Training loss: 3.6031956476330937
Validation loss: 3.2692778456025025

Epoch: 6| Step: 6
Training loss: 3.2974793662119044
Validation loss: 3.267524802114624

Epoch: 6| Step: 7
Training loss: 3.2702767127312073
Validation loss: 3.2675848142287953

Epoch: 6| Step: 8
Training loss: 3.776068423823123
Validation loss: 3.2672774674497105

Epoch: 6| Step: 9
Training loss: 3.386190159783968
Validation loss: 3.265728256022711

Epoch: 6| Step: 10
Training loss: 4.122353369405162
Validation loss: 3.2652042473287075

Epoch: 6| Step: 11
Training loss: 2.722685847949325
Validation loss: 3.2645531055229373

Epoch: 6| Step: 12
Training loss: 3.765866093812078
Validation loss: 3.2640899207637406

Epoch: 6| Step: 13
Training loss: 3.82394193089659
Validation loss: 3.2630017442415524

Epoch: 48| Step: 0
Training loss: 3.2317612263887394
Validation loss: 3.2631121100702685

Epoch: 6| Step: 1
Training loss: 2.6193616348540933
Validation loss: 3.263892328252808

Epoch: 6| Step: 2
Training loss: 3.211699235319119
Validation loss: 3.262195096753092

Epoch: 6| Step: 3
Training loss: 3.9766887652243326
Validation loss: 3.26341248992375

Epoch: 6| Step: 4
Training loss: 1.977137606337794
Validation loss: 3.261401369037677

Epoch: 6| Step: 5
Training loss: 2.998666625936985
Validation loss: 3.2623750168522125

Epoch: 6| Step: 6
Training loss: 3.73243809990423
Validation loss: 3.262483165940974

Epoch: 6| Step: 7
Training loss: 4.316085430667958
Validation loss: 3.2609687979028315

Epoch: 6| Step: 8
Training loss: 3.69121919995669
Validation loss: 3.2598065484227523

Epoch: 6| Step: 9
Training loss: 3.703058298532323
Validation loss: 3.260577086276015

Epoch: 6| Step: 10
Training loss: 3.156204072221537
Validation loss: 3.2587448032985527

Epoch: 6| Step: 11
Training loss: 4.038608665720657
Validation loss: 3.2602755409123985

Epoch: 6| Step: 12
Training loss: 3.304731797086019
Validation loss: 3.25861784544128

Epoch: 6| Step: 13
Training loss: 4.965838268926483
Validation loss: 3.2579896704155487

Epoch: 49| Step: 0
Training loss: 3.081689310384372
Validation loss: 3.2600098728689995

Epoch: 6| Step: 1
Training loss: 2.571092666908576
Validation loss: 3.2567075433937807

Epoch: 6| Step: 2
Training loss: 4.119211701837582
Validation loss: 3.2576664143088165

Epoch: 6| Step: 3
Training loss: 3.462116255995997
Validation loss: 3.2550113549798474

Epoch: 6| Step: 4
Training loss: 2.7330584162957012
Validation loss: 3.2551492140128846

Epoch: 6| Step: 5
Training loss: 3.652831868076206
Validation loss: 3.2552914513917943

Epoch: 6| Step: 6
Training loss: 4.319173542016988
Validation loss: 3.254232319395453

Epoch: 6| Step: 7
Training loss: 4.133768414599685
Validation loss: 3.2544350003363536

Epoch: 6| Step: 8
Training loss: 3.159009727847055
Validation loss: 3.25464179535279

Epoch: 6| Step: 9
Training loss: 4.1493263800970555
Validation loss: 3.253584852739618

Epoch: 6| Step: 10
Training loss: 3.3163119281345503
Validation loss: 3.2539638519162053

Epoch: 6| Step: 11
Training loss: 3.149432079648076
Validation loss: 3.25347282732526

Epoch: 6| Step: 12
Training loss: 3.7154043839571655
Validation loss: 3.252132297635037

Epoch: 6| Step: 13
Training loss: 2.4324033222804995
Validation loss: 3.2521021507177936

Epoch: 50| Step: 0
Training loss: 2.9940130576114643
Validation loss: 3.2501171381233793

Epoch: 6| Step: 1
Training loss: 3.8622941934512935
Validation loss: 3.249649123568406

Epoch: 6| Step: 2
Training loss: 3.552652501719473
Validation loss: 3.2511483601846196

Epoch: 6| Step: 3
Training loss: 3.5931151783056317
Validation loss: 3.2492289989326277

Epoch: 6| Step: 4
Training loss: 2.8429524068213263
Validation loss: 3.2491306754610316

Epoch: 6| Step: 5
Training loss: 3.219972841136436
Validation loss: 3.249130523968505

Epoch: 6| Step: 6
Training loss: 3.9243851489892556
Validation loss: 3.2509107883250294

Epoch: 6| Step: 7
Training loss: 3.970713212450295
Validation loss: 3.2482509513284814

Epoch: 6| Step: 8
Training loss: 4.227078954482251
Validation loss: 3.2471042318621084

Epoch: 6| Step: 9
Training loss: 3.032363058018813
Validation loss: 3.2467578858961805

Epoch: 6| Step: 10
Training loss: 3.7159002588722316
Validation loss: 3.247854681916077

Epoch: 6| Step: 11
Training loss: 2.8164206410541657
Validation loss: 3.2474847728391802

Epoch: 6| Step: 12
Training loss: 3.266408141928715
Validation loss: 3.247615752126182

Epoch: 6| Step: 13
Training loss: 3.7321395248220903
Validation loss: 3.24628424757724

Epoch: 51| Step: 0
Training loss: 3.277587008627093
Validation loss: 3.245237737589544

Epoch: 6| Step: 1
Training loss: 4.31582601798651
Validation loss: 3.245783445680025

Epoch: 6| Step: 2
Training loss: 3.931895794004733
Validation loss: 3.2447241437353767

Epoch: 6| Step: 3
Training loss: 4.287510658895962
Validation loss: 3.24524535447188

Epoch: 6| Step: 4
Training loss: 2.572367023853267
Validation loss: 3.243964975010453

Epoch: 6| Step: 5
Training loss: 3.7579365985388438
Validation loss: 3.2433859033477304

Epoch: 6| Step: 6
Training loss: 2.6907743866639504
Validation loss: 3.2429180003810947

Epoch: 6| Step: 7
Training loss: 4.026067196599332
Validation loss: 3.2427674884840405

Epoch: 6| Step: 8
Training loss: 4.30846227063104
Validation loss: 3.2418212810309113

Epoch: 6| Step: 9
Training loss: 2.097210430030709
Validation loss: 3.2418540264187974

Epoch: 6| Step: 10
Training loss: 3.085382880095219
Validation loss: 3.243307342443705

Epoch: 6| Step: 11
Training loss: 3.1078321760273004
Validation loss: 3.242204824481158

Epoch: 6| Step: 12
Training loss: 3.1366396997355355
Validation loss: 3.241095703310197

Epoch: 6| Step: 13
Training loss: 3.408803000574911
Validation loss: 3.2419892494740186

Epoch: 52| Step: 0
Training loss: 3.1128627826117135
Validation loss: 3.239838061160339

Epoch: 6| Step: 1
Training loss: 3.407182618303606
Validation loss: 3.238711196428165

Epoch: 6| Step: 2
Training loss: 4.0366917040232435
Validation loss: 3.2396001631699853

Epoch: 6| Step: 3
Training loss: 3.4286142812049047
Validation loss: 3.240901345881223

Epoch: 6| Step: 4
Training loss: 4.1317213381132465
Validation loss: 3.2407429609927534

Epoch: 6| Step: 5
Training loss: 3.562016236771038
Validation loss: 3.2409675003803997

Epoch: 6| Step: 6
Training loss: 3.236974436397682
Validation loss: 3.2385175389586225

Epoch: 6| Step: 7
Training loss: 3.887586763155834
Validation loss: 3.2398233083782775

Epoch: 6| Step: 8
Training loss: 3.5838180628135454
Validation loss: 3.241595427854425

Epoch: 6| Step: 9
Training loss: 3.9272883165255594
Validation loss: 3.2371177289599795

Epoch: 6| Step: 10
Training loss: 2.953838282430994
Validation loss: 3.238496368881642

Epoch: 6| Step: 11
Training loss: 2.7465224385896194
Validation loss: 3.239918640043934

Epoch: 6| Step: 12
Training loss: 2.790276783985775
Validation loss: 3.241181197587361

Epoch: 6| Step: 13
Training loss: 3.8289553617524037
Validation loss: 3.236830244091261

Epoch: 53| Step: 0
Training loss: 3.425405414282704
Validation loss: 3.244435893179225

Epoch: 6| Step: 1
Training loss: 3.6533504628617535
Validation loss: 3.2461821104994693

Epoch: 6| Step: 2
Training loss: 3.6146853796252802
Validation loss: 3.235905239363727

Epoch: 6| Step: 3
Training loss: 2.891434179922014
Validation loss: 3.234422102875426

Epoch: 6| Step: 4
Training loss: 2.968088497950329
Validation loss: 3.2326030112761583

Epoch: 6| Step: 5
Training loss: 4.3954643106670375
Validation loss: 3.232371407932059

Epoch: 6| Step: 6
Training loss: 3.7483602117510766
Validation loss: 3.234880394130151

Epoch: 6| Step: 7
Training loss: 3.308691750688513
Validation loss: 3.2327337759117225

Epoch: 6| Step: 8
Training loss: 3.7675710374479734
Validation loss: 3.235161154958835

Epoch: 6| Step: 9
Training loss: 2.4319363211275764
Validation loss: 3.2348300716145038

Epoch: 6| Step: 10
Training loss: 3.4417520754163586
Validation loss: 3.2322863452826027

Epoch: 6| Step: 11
Training loss: 3.3047795564712206
Validation loss: 3.2309488605678864

Epoch: 6| Step: 12
Training loss: 3.923399123745136
Validation loss: 3.2320118945154785

Epoch: 6| Step: 13
Training loss: 3.5746548412667614
Validation loss: 3.232379069409056

Epoch: 54| Step: 0
Training loss: 3.60561740027394
Validation loss: 3.2304513355979148

Epoch: 6| Step: 1
Training loss: 4.042968042345953
Validation loss: 3.2288596418476625

Epoch: 6| Step: 2
Training loss: 3.687639136841409
Validation loss: 3.2315748705519094

Epoch: 6| Step: 3
Training loss: 2.650078459243976
Validation loss: 3.2285511082465486

Epoch: 6| Step: 4
Training loss: 2.9641350463290257
Validation loss: 3.231671362578922

Epoch: 6| Step: 5
Training loss: 2.7315648925268023
Validation loss: 3.2302948890465517

Epoch: 6| Step: 6
Training loss: 3.2369831276478345
Validation loss: 3.226130166884924

Epoch: 6| Step: 7
Training loss: 3.8090997760791168
Validation loss: 3.2279075030624176

Epoch: 6| Step: 8
Training loss: 4.015313399875376
Validation loss: 3.2305724186655653

Epoch: 6| Step: 9
Training loss: 3.796040761216274
Validation loss: 3.2297225971117673

Epoch: 6| Step: 10
Training loss: 3.5912835987084812
Validation loss: 3.228484877196076

Epoch: 6| Step: 11
Training loss: 3.5303196314405128
Validation loss: 3.228183680612131

Epoch: 6| Step: 12
Training loss: 3.1074456598221567
Validation loss: 3.2268218584002732

Epoch: 6| Step: 13
Training loss: 3.6456798121508984
Validation loss: 3.2252600679866816

Epoch: 55| Step: 0
Training loss: 3.473427445521112
Validation loss: 3.2247849988865096

Epoch: 6| Step: 1
Training loss: 3.0693334518165245
Validation loss: 3.2315010077876463

Epoch: 6| Step: 2
Training loss: 2.9057583957115303
Validation loss: 3.2366367647682637

Epoch: 6| Step: 3
Training loss: 3.2274130376776204
Validation loss: 3.242025766639464

Epoch: 6| Step: 4
Training loss: 4.123695167160764
Validation loss: 3.2356550519187453

Epoch: 6| Step: 5
Training loss: 3.1326631810093875
Validation loss: 3.2322846876292486

Epoch: 6| Step: 6
Training loss: 4.003312170103504
Validation loss: 3.2307275392990875

Epoch: 6| Step: 7
Training loss: 3.284926906567959
Validation loss: 3.228281277767495

Epoch: 6| Step: 8
Training loss: 2.9138356956602256
Validation loss: 3.22470294633303

Epoch: 6| Step: 9
Training loss: 3.690509667076243
Validation loss: 3.226720252532377

Epoch: 6| Step: 10
Training loss: 3.3582760454944287
Validation loss: 3.2243051782524175

Epoch: 6| Step: 11
Training loss: 3.8517578570670223
Validation loss: 3.2257250040293255

Epoch: 6| Step: 12
Training loss: 3.4390170824448036
Validation loss: 3.2217672096831906

Epoch: 6| Step: 13
Training loss: 4.160298376386772
Validation loss: 3.2239651610424596

Epoch: 56| Step: 0
Training loss: 3.479192737474052
Validation loss: 3.2213904190354707

Epoch: 6| Step: 1
Training loss: 3.8991654505724043
Validation loss: 3.2222038954398795

Epoch: 6| Step: 2
Training loss: 3.8092552510467126
Validation loss: 3.2200609678110346

Epoch: 6| Step: 3
Training loss: 3.5033180312945547
Validation loss: 3.2230869381046596

Epoch: 6| Step: 4
Training loss: 3.8332403144054767
Validation loss: 3.222763641447453

Epoch: 6| Step: 5
Training loss: 3.8363361345741023
Validation loss: 3.2205943808726505

Epoch: 6| Step: 6
Training loss: 2.832660052768129
Validation loss: 3.220935949405822

Epoch: 6| Step: 7
Training loss: 3.339206639250446
Validation loss: 3.2204026932239187

Epoch: 6| Step: 8
Training loss: 4.195776432463463
Validation loss: 3.2228107318662587

Epoch: 6| Step: 9
Training loss: 2.721814062266337
Validation loss: 3.2152070552761653

Epoch: 6| Step: 10
Training loss: 3.709488049578516
Validation loss: 3.2199146295536165

Epoch: 6| Step: 11
Training loss: 2.827961953874386
Validation loss: 3.218634352740506

Epoch: 6| Step: 12
Training loss: 2.737573115796372
Validation loss: 3.22031936752645

Epoch: 6| Step: 13
Training loss: 3.3407079816598135
Validation loss: 3.2182389978824832

Epoch: 57| Step: 0
Training loss: 4.142868873504417
Validation loss: 3.217677094383486

Epoch: 6| Step: 1
Training loss: 2.402533298861065
Validation loss: 3.2165727476571604

Epoch: 6| Step: 2
Training loss: 2.8036837255950435
Validation loss: 3.220089431518966

Epoch: 6| Step: 3
Training loss: 2.9175462940403625
Validation loss: 3.2278110565715443

Epoch: 6| Step: 4
Training loss: 3.1379334412536988
Validation loss: 3.2301464921723997

Epoch: 6| Step: 5
Training loss: 3.3894486737988663
Validation loss: 3.232014946758116

Epoch: 6| Step: 6
Training loss: 4.028980177962416
Validation loss: 3.2312748743866986

Epoch: 6| Step: 7
Training loss: 3.6850531267039908
Validation loss: 3.2208504510261284

Epoch: 6| Step: 8
Training loss: 3.8580774759331535
Validation loss: 3.214468247705888

Epoch: 6| Step: 9
Training loss: 3.2326729391735625
Validation loss: 3.2161891023474363

Epoch: 6| Step: 10
Training loss: 3.51371136611875
Validation loss: 3.241112979840928

Epoch: 6| Step: 11
Training loss: 3.908117595539311
Validation loss: 3.2386043353815444

Epoch: 6| Step: 12
Training loss: 4.264481499516301
Validation loss: 3.219256657373628

Epoch: 6| Step: 13
Training loss: 1.6904215071473068
Validation loss: 3.2153710943897598

Epoch: 58| Step: 0
Training loss: 3.704467272638247
Validation loss: 3.2247787646447534

Epoch: 6| Step: 1
Training loss: 3.102788341811215
Validation loss: 3.2422500669548397

Epoch: 6| Step: 2
Training loss: 3.128268249463365
Validation loss: 3.272761899055513

Epoch: 6| Step: 3
Training loss: 3.2540009153959164
Validation loss: 3.2713752022362326

Epoch: 6| Step: 4
Training loss: 3.329297642683679
Validation loss: 3.2691536368237113

Epoch: 6| Step: 5
Training loss: 3.705732497935117
Validation loss: 3.223968078565685

Epoch: 6| Step: 6
Training loss: 3.126176841395374
Validation loss: 3.2126150008574808

Epoch: 6| Step: 7
Training loss: 3.2440727176253636
Validation loss: 3.215481090694814

Epoch: 6| Step: 8
Training loss: 4.027705090330936
Validation loss: 3.218489369840619

Epoch: 6| Step: 9
Training loss: 2.8111339218443843
Validation loss: 3.2248219167666314

Epoch: 6| Step: 10
Training loss: 4.555358732566849
Validation loss: 3.2163683511373367

Epoch: 6| Step: 11
Training loss: 2.811150120936519
Validation loss: 3.2138026975387777

Epoch: 6| Step: 12
Training loss: 2.9087920197917723
Validation loss: 3.2090826439356035

Epoch: 6| Step: 13
Training loss: 4.984349935343033
Validation loss: 3.2119996710491456

Epoch: 59| Step: 0
Training loss: 4.520184495249475
Validation loss: 3.2102762312885527

Epoch: 6| Step: 1
Training loss: 3.847644104914208
Validation loss: 3.2074944268087417

Epoch: 6| Step: 2
Training loss: 2.9860981864550924
Validation loss: 3.2056933119172006

Epoch: 6| Step: 3
Training loss: 2.9895010658845407
Validation loss: 3.206786556460807

Epoch: 6| Step: 4
Training loss: 3.5941331742056777
Validation loss: 3.2026654313713943

Epoch: 6| Step: 5
Training loss: 3.8179025362102914
Validation loss: 3.2082467618165986

Epoch: 6| Step: 6
Training loss: 3.6807382950112473
Validation loss: 3.2042966623111404

Epoch: 6| Step: 7
Training loss: 3.420423225851636
Validation loss: 3.204458570260856

Epoch: 6| Step: 8
Training loss: 3.315722643307016
Validation loss: 3.2040073975159173

Epoch: 6| Step: 9
Training loss: 2.5612466119359376
Validation loss: 3.2060812221374584

Epoch: 6| Step: 10
Training loss: 3.4240737887836405
Validation loss: 3.2061539881597456

Epoch: 6| Step: 11
Training loss: 3.5171817299902695
Validation loss: 3.211700569941678

Epoch: 6| Step: 12
Training loss: 3.061402883392011
Validation loss: 3.216031883080683

Epoch: 6| Step: 13
Training loss: 3.003534301429854
Validation loss: 3.2097686164186077

Epoch: 60| Step: 0
Training loss: 3.741954820124702
Validation loss: 3.20534321601287

Epoch: 6| Step: 1
Training loss: 2.482248896012765
Validation loss: 3.201144365875953

Epoch: 6| Step: 2
Training loss: 3.0686359827183143
Validation loss: 3.1995955772461504

Epoch: 6| Step: 3
Training loss: 2.660098440743692
Validation loss: 3.1993690990384147

Epoch: 6| Step: 4
Training loss: 3.3582105880783946
Validation loss: 3.2001503406607292

Epoch: 6| Step: 5
Training loss: 3.1860719361502525
Validation loss: 3.1998182746664976

Epoch: 6| Step: 6
Training loss: 3.623533017839367
Validation loss: 3.2004718348061054

Epoch: 6| Step: 7
Training loss: 3.523711132580823
Validation loss: 3.199674158593506

Epoch: 6| Step: 8
Training loss: 3.6415528518966656
Validation loss: 3.1985945433902807

Epoch: 6| Step: 9
Training loss: 3.976578688073325
Validation loss: 3.197783993524202

Epoch: 6| Step: 10
Training loss: 3.834878250835412
Validation loss: 3.199402559368419

Epoch: 6| Step: 11
Training loss: 3.4567379929465125
Validation loss: 3.1964896982832207

Epoch: 6| Step: 12
Training loss: 3.9731860262384746
Validation loss: 3.1967374350929254

Epoch: 6| Step: 13
Training loss: 3.3071520838480777
Validation loss: 3.195501315567599

Epoch: 61| Step: 0
Training loss: 3.5937733525056483
Validation loss: 3.196707343983281

Epoch: 6| Step: 1
Training loss: 3.9459259462750094
Validation loss: 3.1936669062509475

Epoch: 6| Step: 2
Training loss: 3.0656025021473146
Validation loss: 3.19526656564815

Epoch: 6| Step: 3
Training loss: 3.764945827666862
Validation loss: 3.1939201258777294

Epoch: 6| Step: 4
Training loss: 3.4624937532554494
Validation loss: 3.196755852746056

Epoch: 6| Step: 5
Training loss: 2.9715384789199115
Validation loss: 3.1949402083068206

Epoch: 6| Step: 6
Training loss: 3.6488614540550417
Validation loss: 3.1957501157074146

Epoch: 6| Step: 7
Training loss: 3.277877964133794
Validation loss: 3.2000907382610917

Epoch: 6| Step: 8
Training loss: 3.169932555194192
Validation loss: 3.1956493349478197

Epoch: 6| Step: 9
Training loss: 3.4829502357434747
Validation loss: 3.1980219896443436

Epoch: 6| Step: 10
Training loss: 3.0712637556091718
Validation loss: 3.1999878638304

Epoch: 6| Step: 11
Training loss: 3.528709645650328
Validation loss: 3.201772288636231

Epoch: 6| Step: 12
Training loss: 3.2957133917961157
Validation loss: 3.1974583725922847

Epoch: 6| Step: 13
Training loss: 4.0151509402205425
Validation loss: 3.19407247164313

Epoch: 62| Step: 0
Training loss: 3.4279712736423975
Validation loss: 3.189671184931307

Epoch: 6| Step: 1
Training loss: 3.8444492355370725
Validation loss: 3.1966449634937972

Epoch: 6| Step: 2
Training loss: 4.038144861457937
Validation loss: 3.190813654075851

Epoch: 6| Step: 3
Training loss: 3.6204624057730816
Validation loss: 3.189170910972134

Epoch: 6| Step: 4
Training loss: 3.080216834622364
Validation loss: 3.18697929029925

Epoch: 6| Step: 5
Training loss: 3.054078492630461
Validation loss: 3.188304058968243

Epoch: 6| Step: 6
Training loss: 3.7269270296765526
Validation loss: 3.1858749002968136

Epoch: 6| Step: 7
Training loss: 2.9781152074598807
Validation loss: 3.186366877741037

Epoch: 6| Step: 8
Training loss: 2.8535811294671776
Validation loss: 3.1865338947104855

Epoch: 6| Step: 9
Training loss: 2.881060308140999
Validation loss: 3.1858005951904693

Epoch: 6| Step: 10
Training loss: 3.8018172636951872
Validation loss: 3.18382491422459

Epoch: 6| Step: 11
Training loss: 3.8223497072541517
Validation loss: 3.186578304084953

Epoch: 6| Step: 12
Training loss: 2.7078921227654464
Validation loss: 3.186342409203247

Epoch: 6| Step: 13
Training loss: 4.21055519194489
Validation loss: 3.184960545857814

Epoch: 63| Step: 0
Training loss: 3.302790970094637
Validation loss: 3.187093665008669

Epoch: 6| Step: 1
Training loss: 4.1730923251760625
Validation loss: 3.184653146300955

Epoch: 6| Step: 2
Training loss: 3.5434053229850777
Validation loss: 3.1834115967817747

Epoch: 6| Step: 3
Training loss: 4.062022019657648
Validation loss: 3.183676164713997

Epoch: 6| Step: 4
Training loss: 3.5264938868387583
Validation loss: 3.184127017076929

Epoch: 6| Step: 5
Training loss: 2.629212586918272
Validation loss: 3.1875837806856153

Epoch: 6| Step: 6
Training loss: 2.977883513868192
Validation loss: 3.190813419470144

Epoch: 6| Step: 7
Training loss: 2.89669739344388
Validation loss: 3.18298167269739

Epoch: 6| Step: 8
Training loss: 3.5628700733376264
Validation loss: 3.1855698672683634

Epoch: 6| Step: 9
Training loss: 3.3927301999774264
Validation loss: 3.1840025348885126

Epoch: 6| Step: 10
Training loss: 3.396813015341564
Validation loss: 3.1832309568780075

Epoch: 6| Step: 11
Training loss: 3.431056555348299
Validation loss: 3.1850046326686368

Epoch: 6| Step: 12
Training loss: 3.2525395961406667
Validation loss: 3.183877577599595

Epoch: 6| Step: 13
Training loss: 3.6836035881032463
Validation loss: 3.1835702780124984

Epoch: 64| Step: 0
Training loss: 2.9354672805036044
Validation loss: 3.184141660773116

Epoch: 6| Step: 1
Training loss: 3.5629909244050255
Validation loss: 3.179537405540215

Epoch: 6| Step: 2
Training loss: 3.0207760158669674
Validation loss: 3.179726100055535

Epoch: 6| Step: 3
Training loss: 3.932389591168265
Validation loss: 3.183233095908236

Epoch: 6| Step: 4
Training loss: 3.6979706379708364
Validation loss: 3.1808298572456803

Epoch: 6| Step: 5
Training loss: 3.070478362051453
Validation loss: 3.1792984659694667

Epoch: 6| Step: 6
Training loss: 3.9534393306200557
Validation loss: 3.1756310427618555

Epoch: 6| Step: 7
Training loss: 2.91212673169291
Validation loss: 3.1765228315009275

Epoch: 6| Step: 8
Training loss: 3.442672167581802
Validation loss: 3.174014913535231

Epoch: 6| Step: 9
Training loss: 3.1998338119745173
Validation loss: 3.1738838281531394

Epoch: 6| Step: 10
Training loss: 3.3909425367044257
Validation loss: 3.1760699230220255

Epoch: 6| Step: 11
Training loss: 3.8551825481886586
Validation loss: 3.176316098281729

Epoch: 6| Step: 12
Training loss: 3.7325401746525793
Validation loss: 3.1777668772212486

Epoch: 6| Step: 13
Training loss: 2.729261576237404
Validation loss: 3.1840460633063317

Epoch: 65| Step: 0
Training loss: 3.316387845944223
Validation loss: 3.1803331096869507

Epoch: 6| Step: 1
Training loss: 3.7779173233089436
Validation loss: 3.1731871800344487

Epoch: 6| Step: 2
Training loss: 3.6859338311617367
Validation loss: 3.1738830850416115

Epoch: 6| Step: 3
Training loss: 4.088394272530614
Validation loss: 3.1779752923962215

Epoch: 6| Step: 4
Training loss: 2.6739674010133574
Validation loss: 3.185187317749265

Epoch: 6| Step: 5
Training loss: 3.730606795547915
Validation loss: 3.1812132966257844

Epoch: 6| Step: 6
Training loss: 3.023482921170446
Validation loss: 3.179464456096921

Epoch: 6| Step: 7
Training loss: 3.384446945200638
Validation loss: 3.1759856238935207

Epoch: 6| Step: 8
Training loss: 2.917159084351261
Validation loss: 3.1724160981239864

Epoch: 6| Step: 9
Training loss: 3.7311990552328496
Validation loss: 3.1748472842191293

Epoch: 6| Step: 10
Training loss: 3.357246327762298
Validation loss: 3.17334519789258

Epoch: 6| Step: 11
Training loss: 3.6779733216571566
Validation loss: 3.1736610888375507

Epoch: 6| Step: 12
Training loss: 3.013443706426546
Validation loss: 3.1723822052729442

Epoch: 6| Step: 13
Training loss: 3.253200129246988
Validation loss: 3.1729942378602973

Epoch: 66| Step: 0
Training loss: 2.714302546943729
Validation loss: 3.1712434435843777

Epoch: 6| Step: 1
Training loss: 3.9514009236780256
Validation loss: 3.171560853347483

Epoch: 6| Step: 2
Training loss: 3.309719142004378
Validation loss: 3.168631211962974

Epoch: 6| Step: 3
Training loss: 3.3946135656913845
Validation loss: 3.1677959325154044

Epoch: 6| Step: 4
Training loss: 3.0058546159197217
Validation loss: 3.1669433313136826

Epoch: 6| Step: 5
Training loss: 3.675650485851535
Validation loss: 3.1664393742264956

Epoch: 6| Step: 6
Training loss: 3.480503822775025
Validation loss: 3.164449358055032

Epoch: 6| Step: 7
Training loss: 4.068386332348879
Validation loss: 3.1645848248094848

Epoch: 6| Step: 8
Training loss: 3.660409501310633
Validation loss: 3.1665127387034993

Epoch: 6| Step: 9
Training loss: 3.521959895792165
Validation loss: 3.1636995902219596

Epoch: 6| Step: 10
Training loss: 3.2076984784746516
Validation loss: 3.161985571339352

Epoch: 6| Step: 11
Training loss: 2.6778919666085597
Validation loss: 3.1636908499906884

Epoch: 6| Step: 12
Training loss: 2.79510646719653
Validation loss: 3.1635335233193222

Epoch: 6| Step: 13
Training loss: 4.445662178003152
Validation loss: 3.1638281253941285

Epoch: 67| Step: 0
Training loss: 2.898370377002421
Validation loss: 3.165024173283129

Epoch: 6| Step: 1
Training loss: 3.3908206162519305
Validation loss: 3.1619940892695038

Epoch: 6| Step: 2
Training loss: 3.9503649096395543
Validation loss: 3.1645688948979394

Epoch: 6| Step: 3
Training loss: 3.7969696912221425
Validation loss: 3.1623840198572015

Epoch: 6| Step: 4
Training loss: 4.304727820676637
Validation loss: 3.1617874342094736

Epoch: 6| Step: 5
Training loss: 3.5749180177478426
Validation loss: 3.16012728297164

Epoch: 6| Step: 6
Training loss: 3.2218103766782247
Validation loss: 3.1595585313043086

Epoch: 6| Step: 7
Training loss: 3.646184384838115
Validation loss: 3.1629271947374384

Epoch: 6| Step: 8
Training loss: 2.966498072973513
Validation loss: 3.1654731242325784

Epoch: 6| Step: 9
Training loss: 3.084796008718449
Validation loss: 3.1692745893490195

Epoch: 6| Step: 10
Training loss: 3.5587557474189766
Validation loss: 3.166829775855443

Epoch: 6| Step: 11
Training loss: 2.5273650697637287
Validation loss: 3.164643945596666

Epoch: 6| Step: 12
Training loss: 3.4895454670384107
Validation loss: 3.1633580371449606

Epoch: 6| Step: 13
Training loss: 2.5699542413341274
Validation loss: 3.1644699379234162

Epoch: 68| Step: 0
Training loss: 3.4713595085742064
Validation loss: 3.158579853915603

Epoch: 6| Step: 1
Training loss: 3.24842987279836
Validation loss: 3.1563930310525747

Epoch: 6| Step: 2
Training loss: 2.84166397885133
Validation loss: 3.1543806484441688

Epoch: 6| Step: 3
Training loss: 3.8004931882745288
Validation loss: 3.156897404651023

Epoch: 6| Step: 4
Training loss: 2.9934531938758924
Validation loss: 3.154474524788347

Epoch: 6| Step: 5
Training loss: 3.3456596554294435
Validation loss: 3.157189275637367

Epoch: 6| Step: 6
Training loss: 3.891774448206485
Validation loss: 3.156537920363435

Epoch: 6| Step: 7
Training loss: 3.1109530791003213
Validation loss: 3.1532757160353513

Epoch: 6| Step: 8
Training loss: 3.3129780262484063
Validation loss: 3.154544871293716

Epoch: 6| Step: 9
Training loss: 3.4283372310850555
Validation loss: 3.1554142460627226

Epoch: 6| Step: 10
Training loss: 3.3768558344772823
Validation loss: 3.159484245867182

Epoch: 6| Step: 11
Training loss: 3.514838236617703
Validation loss: 3.157979445296417

Epoch: 6| Step: 12
Training loss: 4.253529821857908
Validation loss: 3.1549170250160867

Epoch: 6| Step: 13
Training loss: 2.4043730313893197
Validation loss: 3.1541279340060155

Epoch: 69| Step: 0
Training loss: 3.901188982162789
Validation loss: 3.1523333281958896

Epoch: 6| Step: 1
Training loss: 3.5744802243839198
Validation loss: 3.1531317354090067

Epoch: 6| Step: 2
Training loss: 3.3549153378943077
Validation loss: 3.1508561844093714

Epoch: 6| Step: 3
Training loss: 3.142800256288607
Validation loss: 3.1527557345774033

Epoch: 6| Step: 4
Training loss: 3.0066660888513432
Validation loss: 3.1518839745701848

Epoch: 6| Step: 5
Training loss: 2.838449589813702
Validation loss: 3.1519722050238292

Epoch: 6| Step: 6
Training loss: 2.9756183077907803
Validation loss: 3.1509985881244886

Epoch: 6| Step: 7
Training loss: 3.1615098994080624
Validation loss: 3.1500063464609784

Epoch: 6| Step: 8
Training loss: 3.621040286232204
Validation loss: 3.1505929712694445

Epoch: 6| Step: 9
Training loss: 4.209702121226974
Validation loss: 3.1503331246700372

Epoch: 6| Step: 10
Training loss: 3.697403749524727
Validation loss: 3.149921842205421

Epoch: 6| Step: 11
Training loss: 3.3521524545874084
Validation loss: 3.1490002437140987

Epoch: 6| Step: 12
Training loss: 3.0484937231528852
Validation loss: 3.1489926073290695

Epoch: 6| Step: 13
Training loss: 3.6356977264858013
Validation loss: 3.148102462205693

Epoch: 70| Step: 0
Training loss: 2.736401488187218
Validation loss: 3.147875927782795

Epoch: 6| Step: 1
Training loss: 4.474465296676477
Validation loss: 3.1487122593960772

Epoch: 6| Step: 2
Training loss: 4.320459732388943
Validation loss: 3.147235596675171

Epoch: 6| Step: 3
Training loss: 3.814750382442694
Validation loss: 3.1478588545851016

Epoch: 6| Step: 4
Training loss: 3.401433777027263
Validation loss: 3.1476522765395423

Epoch: 6| Step: 5
Training loss: 3.167930066569849
Validation loss: 3.147052525107656

Epoch: 6| Step: 6
Training loss: 3.719133629765767
Validation loss: 3.146189561827943

Epoch: 6| Step: 7
Training loss: 3.3336282281766647
Validation loss: 3.1463780644915293

Epoch: 6| Step: 8
Training loss: 2.8722328469501925
Validation loss: 3.146064269557581

Epoch: 6| Step: 9
Training loss: 3.5208959780806297
Validation loss: 3.1453302349617176

Epoch: 6| Step: 10
Training loss: 2.7969044944870283
Validation loss: 3.1447915336039496

Epoch: 6| Step: 11
Training loss: 2.8495482973556356
Validation loss: 3.146207251951387

Epoch: 6| Step: 12
Training loss: 2.4547395677586694
Validation loss: 3.1454424686917917

Epoch: 6| Step: 13
Training loss: 3.5370030084348594
Validation loss: 3.147560105874429

Epoch: 71| Step: 0
Training loss: 4.003376489343675
Validation loss: 3.1448971428920056

Epoch: 6| Step: 1
Training loss: 3.6148391911577047
Validation loss: 3.145732237205941

Epoch: 6| Step: 2
Training loss: 3.7560828147915304
Validation loss: 3.142714009177251

Epoch: 6| Step: 3
Training loss: 2.3203044852686707
Validation loss: 3.142247610550867

Epoch: 6| Step: 4
Training loss: 2.9470999477124358
Validation loss: 3.1409902321999095

Epoch: 6| Step: 5
Training loss: 3.673158851352011
Validation loss: 3.1412040459489754

Epoch: 6| Step: 6
Training loss: 2.914974448352146
Validation loss: 3.1401604986572322

Epoch: 6| Step: 7
Training loss: 3.57244742438228
Validation loss: 3.1388543458267772

Epoch: 6| Step: 8
Training loss: 3.4297418611775967
Validation loss: 3.139641487941783

Epoch: 6| Step: 9
Training loss: 4.029833404278067
Validation loss: 3.1392533979419825

Epoch: 6| Step: 10
Training loss: 3.1670189878992447
Validation loss: 3.1384065078134507

Epoch: 6| Step: 11
Training loss: 3.1053987315219733
Validation loss: 3.1388236148644193

Epoch: 6| Step: 12
Training loss: 3.294268839035134
Validation loss: 3.1374009138351133

Epoch: 6| Step: 13
Training loss: 3.3823856498522122
Validation loss: 3.1362416768854073

Epoch: 72| Step: 0
Training loss: 4.098486569831105
Validation loss: 3.1366273091288615

Epoch: 6| Step: 1
Training loss: 3.9795002156744173
Validation loss: 3.1376341429562555

Epoch: 6| Step: 2
Training loss: 3.1102548245847217
Validation loss: 3.134639436113201

Epoch: 6| Step: 3
Training loss: 2.934200300352362
Validation loss: 3.1378450873019896

Epoch: 6| Step: 4
Training loss: 3.384903118600952
Validation loss: 3.1351220158690665

Epoch: 6| Step: 5
Training loss: 3.1471874699399884
Validation loss: 3.13781551887117

Epoch: 6| Step: 6
Training loss: 3.9687862845136364
Validation loss: 3.1357839062191872

Epoch: 6| Step: 7
Training loss: 2.9693718509902265
Validation loss: 3.1354066631035047

Epoch: 6| Step: 8
Training loss: 3.784955187674628
Validation loss: 3.141433345684362

Epoch: 6| Step: 9
Training loss: 2.8323359884535693
Validation loss: 3.1433607306133715

Epoch: 6| Step: 10
Training loss: 3.3838262646764474
Validation loss: 3.137174065912557

Epoch: 6| Step: 11
Training loss: 3.3928027213184873
Validation loss: 3.1356676943048343

Epoch: 6| Step: 12
Training loss: 2.725319740365402
Validation loss: 3.1403436160753886

Epoch: 6| Step: 13
Training loss: 3.3443778330976803
Validation loss: 3.1368798553331345

Epoch: 73| Step: 0
Training loss: 3.7407098771666103
Validation loss: 3.143371052490303

Epoch: 6| Step: 1
Training loss: 3.24514378351086
Validation loss: 3.155380101530224

Epoch: 6| Step: 2
Training loss: 2.533741795922252
Validation loss: 3.156472619717074

Epoch: 6| Step: 3
Training loss: 3.188013970319323
Validation loss: 3.160784800033899

Epoch: 6| Step: 4
Training loss: 4.3356018486356165
Validation loss: 3.14981515611936

Epoch: 6| Step: 5
Training loss: 3.510546597907035
Validation loss: 3.1327432416068124

Epoch: 6| Step: 6
Training loss: 3.6757031553041775
Validation loss: 3.128766821303521

Epoch: 6| Step: 7
Training loss: 3.1832102913236917
Validation loss: 3.131287400430012

Epoch: 6| Step: 8
Training loss: 3.6449289707960615
Validation loss: 3.1321061176003138

Epoch: 6| Step: 9
Training loss: 3.4974289033547197
Validation loss: 3.1362836415411923

Epoch: 6| Step: 10
Training loss: 3.8598701684493424
Validation loss: 3.1375525999576923

Epoch: 6| Step: 11
Training loss: 3.522723411043349
Validation loss: 3.135333497177594

Epoch: 6| Step: 12
Training loss: 2.4914522910207646
Validation loss: 3.1316239825956074

Epoch: 6| Step: 13
Training loss: 1.91372092176954
Validation loss: 3.128929267657198

Epoch: 74| Step: 0
Training loss: 3.255558395890815
Validation loss: 3.129897537159694

Epoch: 6| Step: 1
Training loss: 2.7584459479662753
Validation loss: 3.130458656681156

Epoch: 6| Step: 2
Training loss: 3.206188095714682
Validation loss: 3.1274705321587697

Epoch: 6| Step: 3
Training loss: 2.9252045779945233
Validation loss: 3.1289337731760187

Epoch: 6| Step: 4
Training loss: 4.102686090520287
Validation loss: 3.1311190929136097

Epoch: 6| Step: 5
Training loss: 3.5892542042599676
Validation loss: 3.13369825769459

Epoch: 6| Step: 6
Training loss: 3.41289802437821
Validation loss: 3.128178531726756

Epoch: 6| Step: 7
Training loss: 3.728122216836765
Validation loss: 3.126630222500765

Epoch: 6| Step: 8
Training loss: 2.387896607695863
Validation loss: 3.126323238496887

Epoch: 6| Step: 9
Training loss: 3.9305713789538625
Validation loss: 3.127916628020011

Epoch: 6| Step: 10
Training loss: 3.515772701975423
Validation loss: 3.127205388387216

Epoch: 6| Step: 11
Training loss: 3.3769042682809043
Validation loss: 3.1245524260244726

Epoch: 6| Step: 12
Training loss: 3.495472159083691
Validation loss: 3.1245775425343

Epoch: 6| Step: 13
Training loss: 3.2304325862829955
Validation loss: 3.1255486332839806

Epoch: 75| Step: 0
Training loss: 2.7130686713195096
Validation loss: 3.1251843387829794

Epoch: 6| Step: 1
Training loss: 4.008226994130274
Validation loss: 3.1238288177790365

Epoch: 6| Step: 2
Training loss: 3.320029284796189
Validation loss: 3.122349972745493

Epoch: 6| Step: 3
Training loss: 3.49402871973542
Validation loss: 3.1223331450494087

Epoch: 6| Step: 4
Training loss: 3.3186696015872856
Validation loss: 3.1237172026736597

Epoch: 6| Step: 5
Training loss: 3.238080247408898
Validation loss: 3.1226717473194

Epoch: 6| Step: 6
Training loss: 2.877440370526816
Validation loss: 3.121402402255878

Epoch: 6| Step: 7
Training loss: 3.441979004462852
Validation loss: 3.1208370758822364

Epoch: 6| Step: 8
Training loss: 3.9171958457635716
Validation loss: 3.122903384682744

Epoch: 6| Step: 9
Training loss: 3.5563117372218995
Validation loss: 3.1211337334511593

Epoch: 6| Step: 10
Training loss: 2.500474694007827
Validation loss: 3.1220786987386253

Epoch: 6| Step: 11
Training loss: 3.4562752969378256
Validation loss: 3.119334281429637

Epoch: 6| Step: 12
Training loss: 3.5514812388020562
Validation loss: 3.121210659782753

Epoch: 6| Step: 13
Training loss: 3.7402849876226347
Validation loss: 3.120762977730924

Epoch: 76| Step: 0
Training loss: 3.001944547503198
Validation loss: 3.1205489669498974

Epoch: 6| Step: 1
Training loss: 3.6867883286455188
Validation loss: 3.1203264790869354

Epoch: 6| Step: 2
Training loss: 3.1852013770717855
Validation loss: 3.1222000770229683

Epoch: 6| Step: 3
Training loss: 3.796388948200712
Validation loss: 3.125030643764089

Epoch: 6| Step: 4
Training loss: 2.674748531892728
Validation loss: 3.1369151868386136

Epoch: 6| Step: 5
Training loss: 3.4508734219422736
Validation loss: 3.1542539519918624

Epoch: 6| Step: 6
Training loss: 3.4533003680547156
Validation loss: 3.1250832610164676

Epoch: 6| Step: 7
Training loss: 3.1020575063504348
Validation loss: 3.1172763103398684

Epoch: 6| Step: 8
Training loss: 3.3909487240153555
Validation loss: 3.1181165410883924

Epoch: 6| Step: 9
Training loss: 3.780419628930204
Validation loss: 3.1191477739308673

Epoch: 6| Step: 10
Training loss: 4.050049939259767
Validation loss: 3.122419900929782

Epoch: 6| Step: 11
Training loss: 2.7494144683315125
Validation loss: 3.121587155517905

Epoch: 6| Step: 12
Training loss: 3.8429867366548986
Validation loss: 3.119792192850653

Epoch: 6| Step: 13
Training loss: 2.206668033925965
Validation loss: 3.1148896590238806

Epoch: 77| Step: 0
Training loss: 3.8030228938843758
Validation loss: 3.114738035514961

Epoch: 6| Step: 1
Training loss: 3.2957382773586072
Validation loss: 3.1138703699074046

Epoch: 6| Step: 2
Training loss: 2.9181117338106533
Validation loss: 3.113396921581125

Epoch: 6| Step: 3
Training loss: 3.13946086507149
Validation loss: 3.11261699186645

Epoch: 6| Step: 4
Training loss: 3.9772177645365874
Validation loss: 3.112311640439575

Epoch: 6| Step: 5
Training loss: 3.3149817904379293
Validation loss: 3.1101917075023677

Epoch: 6| Step: 6
Training loss: 3.1473183737201804
Validation loss: 3.1110131844794733

Epoch: 6| Step: 7
Training loss: 3.990252539116758
Validation loss: 3.111431721007263

Epoch: 6| Step: 8
Training loss: 2.3757911167611003
Validation loss: 3.111352109022579

Epoch: 6| Step: 9
Training loss: 3.454201370880931
Validation loss: 3.1089649998869593

Epoch: 6| Step: 10
Training loss: 3.3079202049714707
Validation loss: 3.1097880193402987

Epoch: 6| Step: 11
Training loss: 3.0070880760637175
Validation loss: 3.1099813068773634

Epoch: 6| Step: 12
Training loss: 3.796651951396001
Validation loss: 3.112032000744975

Epoch: 6| Step: 13
Training loss: 3.258309818062641
Validation loss: 3.1104261188506186

Epoch: 78| Step: 0
Training loss: 2.499058736989359
Validation loss: 3.111645884290196

Epoch: 6| Step: 1
Training loss: 3.277422461854626
Validation loss: 3.111674268671845

Epoch: 6| Step: 2
Training loss: 3.2116036199832707
Validation loss: 3.1089840826329898

Epoch: 6| Step: 3
Training loss: 3.4595003265588007
Validation loss: 3.113793267173697

Epoch: 6| Step: 4
Training loss: 3.8764395962243845
Validation loss: 3.1140919475149857

Epoch: 6| Step: 5
Training loss: 3.6936483043219623
Validation loss: 3.1081329303753935

Epoch: 6| Step: 6
Training loss: 2.154758545698053
Validation loss: 3.1090733862167848

Epoch: 6| Step: 7
Training loss: 3.3803728922721095
Validation loss: 3.107366947287696

Epoch: 6| Step: 8
Training loss: 3.6832572969439323
Validation loss: 3.1083997900839146

Epoch: 6| Step: 9
Training loss: 3.580401100619985
Validation loss: 3.1078821825152567

Epoch: 6| Step: 10
Training loss: 3.480646713279527
Validation loss: 3.10748750103227

Epoch: 6| Step: 11
Training loss: 3.104028139714373
Validation loss: 3.107887519506718

Epoch: 6| Step: 12
Training loss: 3.5799166928620045
Validation loss: 3.1038890553992418

Epoch: 6| Step: 13
Training loss: 3.945942018348776
Validation loss: 3.1030395475558277

Epoch: 79| Step: 0
Training loss: 3.7011598934090366
Validation loss: 3.1037002007078116

Epoch: 6| Step: 1
Training loss: 3.5319683053310773
Validation loss: 3.1037551255808027

Epoch: 6| Step: 2
Training loss: 3.2188649573676638
Validation loss: 3.1018042143324047

Epoch: 6| Step: 3
Training loss: 3.4875160736479245
Validation loss: 3.1027959349261867

Epoch: 6| Step: 4
Training loss: 2.462931282500455
Validation loss: 3.1025969809164367

Epoch: 6| Step: 5
Training loss: 3.6346580493551506
Validation loss: 3.0994465259427275

Epoch: 6| Step: 6
Training loss: 3.478581148930176
Validation loss: 3.100117722656742

Epoch: 6| Step: 7
Training loss: 3.7687711749897463
Validation loss: 3.1006763163765556

Epoch: 6| Step: 8
Training loss: 3.518171278418251
Validation loss: 3.100459505177193

Epoch: 6| Step: 9
Training loss: 3.243236105606026
Validation loss: 3.101281134690787

Epoch: 6| Step: 10
Training loss: 3.091557506131934
Validation loss: 3.0986949885627237

Epoch: 6| Step: 11
Training loss: 3.0839194350746664
Validation loss: 3.0986532213973303

Epoch: 6| Step: 12
Training loss: 2.9194105230026914
Validation loss: 3.0981016788612252

Epoch: 6| Step: 13
Training loss: 3.902509439519283
Validation loss: 3.0991012037059513

Epoch: 80| Step: 0
Training loss: 3.4899586641765734
Validation loss: 3.099184862714023

Epoch: 6| Step: 1
Training loss: 3.7502998232192164
Validation loss: 3.0970324962744553

Epoch: 6| Step: 2
Training loss: 4.002601731083893
Validation loss: 3.0986952359341244

Epoch: 6| Step: 3
Training loss: 3.3926426382305204
Validation loss: 3.0985111183084935

Epoch: 6| Step: 4
Training loss: 3.0587823841296577
Validation loss: 3.0968882877818964

Epoch: 6| Step: 5
Training loss: 3.647194105241534
Validation loss: 3.1000955156767627

Epoch: 6| Step: 6
Training loss: 2.583808137473054
Validation loss: 3.105026116779413

Epoch: 6| Step: 7
Training loss: 3.5760345349276363
Validation loss: 3.102148257210801

Epoch: 6| Step: 8
Training loss: 2.5002836066551524
Validation loss: 3.094584619583211

Epoch: 6| Step: 9
Training loss: 3.427340110427319
Validation loss: 3.0971707354598084

Epoch: 6| Step: 10
Training loss: 3.421390586253077
Validation loss: 3.095057208315272

Epoch: 6| Step: 11
Training loss: 3.7557270822222555
Validation loss: 3.0941459673332576

Epoch: 6| Step: 12
Training loss: 2.945012975382434
Validation loss: 3.0968210724603136

Epoch: 6| Step: 13
Training loss: 2.868812537083036
Validation loss: 3.093369725848762

Epoch: 81| Step: 0
Training loss: 3.488130880192645
Validation loss: 3.0937913245752346

Epoch: 6| Step: 1
Training loss: 2.5279489349809054
Validation loss: 3.095487260756825

Epoch: 6| Step: 2
Training loss: 3.3765136715219457
Validation loss: 3.0953253626339405

Epoch: 6| Step: 3
Training loss: 3.6370634413465206
Validation loss: 3.0912603389622375

Epoch: 6| Step: 4
Training loss: 3.4728417534730154
Validation loss: 3.0901620377168424

Epoch: 6| Step: 5
Training loss: 3.0858858900945396
Validation loss: 3.092820277370741

Epoch: 6| Step: 6
Training loss: 2.787769006997702
Validation loss: 3.0930998628585713

Epoch: 6| Step: 7
Training loss: 3.2229737651347814
Validation loss: 3.088109156277442

Epoch: 6| Step: 8
Training loss: 3.0909509808970754
Validation loss: 3.091229944274988

Epoch: 6| Step: 9
Training loss: 3.3463330140787364
Validation loss: 3.0958385094898984

Epoch: 6| Step: 10
Training loss: 3.3509199331218524
Validation loss: 3.0932291403884653

Epoch: 6| Step: 11
Training loss: 3.168033622707773
Validation loss: 3.0994082404082

Epoch: 6| Step: 12
Training loss: 3.9171357110719405
Validation loss: 3.0910601548007537

Epoch: 6| Step: 13
Training loss: 4.720813830414788
Validation loss: 3.0881734859359096

Epoch: 82| Step: 0
Training loss: 3.488806536553655
Validation loss: 3.0908584282115097

Epoch: 6| Step: 1
Training loss: 3.5432325304919967
Validation loss: 3.087292097595698

Epoch: 6| Step: 2
Training loss: 3.512305290282785
Validation loss: 3.0887888530867955

Epoch: 6| Step: 3
Training loss: 3.71762914355031
Validation loss: 3.087185295798776

Epoch: 6| Step: 4
Training loss: 3.0114397644575353
Validation loss: 3.088170097270453

Epoch: 6| Step: 5
Training loss: 2.668727068836046
Validation loss: 3.0872701263643414

Epoch: 6| Step: 6
Training loss: 3.470922940773969
Validation loss: 3.088974727050639

Epoch: 6| Step: 7
Training loss: 3.090834351518274
Validation loss: 3.088158609650283

Epoch: 6| Step: 8
Training loss: 3.6100946674984553
Validation loss: 3.085133109313136

Epoch: 6| Step: 9
Training loss: 3.0120697410685953
Validation loss: 3.0870576967915193

Epoch: 6| Step: 10
Training loss: 2.8919222833260667
Validation loss: 3.083639752151313

Epoch: 6| Step: 11
Training loss: 3.3231017121996165
Validation loss: 3.0837482995182213

Epoch: 6| Step: 12
Training loss: 3.495174078146588
Validation loss: 3.084503181936568

Epoch: 6| Step: 13
Training loss: 4.19765982145821
Validation loss: 3.085226223461988

Epoch: 83| Step: 0
Training loss: 2.7562095587222313
Validation loss: 3.083129115826181

Epoch: 6| Step: 1
Training loss: 3.1379238678234924
Validation loss: 3.083488568259186

Epoch: 6| Step: 2
Training loss: 2.854912282260927
Validation loss: 3.0837981204386273

Epoch: 6| Step: 3
Training loss: 3.6771044563933097
Validation loss: 3.083679551162347

Epoch: 6| Step: 4
Training loss: 3.0570309130821753
Validation loss: 3.080677304183146

Epoch: 6| Step: 5
Training loss: 3.702207556282457
Validation loss: 3.0795619124517213

Epoch: 6| Step: 6
Training loss: 3.3725989949463147
Validation loss: 3.080786416100504

Epoch: 6| Step: 7
Training loss: 3.2193327441040855
Validation loss: 3.08038315708205

Epoch: 6| Step: 8
Training loss: 3.774634130065712
Validation loss: 3.0801612053698464

Epoch: 6| Step: 9
Training loss: 3.1962002964205585
Validation loss: 3.0781964683699816

Epoch: 6| Step: 10
Training loss: 3.2252598088612583
Validation loss: 3.0819957800828677

Epoch: 6| Step: 11
Training loss: 3.5916473871998478
Validation loss: 3.0805683764776997

Epoch: 6| Step: 12
Training loss: 3.5752119841782144
Validation loss: 3.08420617626411

Epoch: 6| Step: 13
Training loss: 3.5767018515594406
Validation loss: 3.0843339015506914

Epoch: 84| Step: 0
Training loss: 2.8969847953589634
Validation loss: 3.090753235204359

Epoch: 6| Step: 1
Training loss: 3.178764940497494
Validation loss: 3.0855211933786366

Epoch: 6| Step: 2
Training loss: 3.484364599374892
Validation loss: 3.0832828150642935

Epoch: 6| Step: 3
Training loss: 3.3359968193551324
Validation loss: 3.081267591670543

Epoch: 6| Step: 4
Training loss: 3.6929999246687664
Validation loss: 3.0784892688132555

Epoch: 6| Step: 5
Training loss: 3.518360209854042
Validation loss: 3.079598220384591

Epoch: 6| Step: 6
Training loss: 4.0358945128735675
Validation loss: 3.0770488594587864

Epoch: 6| Step: 7
Training loss: 2.549461128293141
Validation loss: 3.0779781386680583

Epoch: 6| Step: 8
Training loss: 3.9268905362968316
Validation loss: 3.0745262095131918

Epoch: 6| Step: 9
Training loss: 3.704177256262582
Validation loss: 3.0742378407829314

Epoch: 6| Step: 10
Training loss: 2.750179458311308
Validation loss: 3.073139906849857

Epoch: 6| Step: 11
Training loss: 2.85268983896283
Validation loss: 3.072834514495181

Epoch: 6| Step: 12
Training loss: 3.3129971688923714
Validation loss: 3.072854897844812

Epoch: 6| Step: 13
Training loss: 2.9431351523751816
Validation loss: 3.0753546308116726

Epoch: 85| Step: 0
Training loss: 3.053000215852132
Validation loss: 3.073111413478863

Epoch: 6| Step: 1
Training loss: 3.0965030635434836
Validation loss: 3.074215729554255

Epoch: 6| Step: 2
Training loss: 3.3219122409975927
Validation loss: 3.072672134494812

Epoch: 6| Step: 3
Training loss: 3.200339245695153
Validation loss: 3.0733320858853443

Epoch: 6| Step: 4
Training loss: 3.078015320658587
Validation loss: 3.0720916597199617

Epoch: 6| Step: 5
Training loss: 3.305350018548291
Validation loss: 3.0716336321566002

Epoch: 6| Step: 6
Training loss: 4.2391323940140735
Validation loss: 3.07206276774886

Epoch: 6| Step: 7
Training loss: 3.9058295672179932
Validation loss: 3.0715689160318504

Epoch: 6| Step: 8
Training loss: 2.325911935780848
Validation loss: 3.0756363924585526

Epoch: 6| Step: 9
Training loss: 3.1774468552701878
Validation loss: 3.075847846364144

Epoch: 6| Step: 10
Training loss: 3.426068806079244
Validation loss: 3.0744775299720364

Epoch: 6| Step: 11
Training loss: 3.705316852606596
Validation loss: 3.06771331513157

Epoch: 6| Step: 12
Training loss: 3.3681157861591706
Validation loss: 3.0680879597253146

Epoch: 6| Step: 13
Training loss: 2.9826062138615166
Validation loss: 3.0692878655614453

Epoch: 86| Step: 0
Training loss: 3.300981757038765
Validation loss: 3.0684712492326107

Epoch: 6| Step: 1
Training loss: 3.1123223066354906
Validation loss: 3.0699251196645263

Epoch: 6| Step: 2
Training loss: 2.2483604603519587
Validation loss: 3.068003999245981

Epoch: 6| Step: 3
Training loss: 3.792455416513512
Validation loss: 3.0676232537564836

Epoch: 6| Step: 4
Training loss: 3.9321391836079678
Validation loss: 3.0676954798999594

Epoch: 6| Step: 5
Training loss: 2.8801521907436944
Validation loss: 3.0684736854858845

Epoch: 6| Step: 6
Training loss: 3.8830161089252324
Validation loss: 3.0689382877408424

Epoch: 6| Step: 7
Training loss: 3.208760584006484
Validation loss: 3.0675912292170238

Epoch: 6| Step: 8
Training loss: 2.988714927170799
Validation loss: 3.0672596502826943

Epoch: 6| Step: 9
Training loss: 3.453270266139889
Validation loss: 3.0655843552524034

Epoch: 6| Step: 10
Training loss: 3.2982539325992244
Validation loss: 3.069281104993175

Epoch: 6| Step: 11
Training loss: 3.203631700585766
Validation loss: 3.0643648233825083

Epoch: 6| Step: 12
Training loss: 3.6323105331965095
Validation loss: 3.0653406680062982

Epoch: 6| Step: 13
Training loss: 3.423423660508026
Validation loss: 3.0646126554363518

Epoch: 87| Step: 0
Training loss: 3.1281324327439637
Validation loss: 3.0637306116590937

Epoch: 6| Step: 1
Training loss: 4.1889928178067715
Validation loss: 3.0651849207446604

Epoch: 6| Step: 2
Training loss: 3.2469752981869346
Validation loss: 3.06331723400633

Epoch: 6| Step: 3
Training loss: 3.3653456038005993
Validation loss: 3.062803468115025

Epoch: 6| Step: 4
Training loss: 2.29010069546593
Validation loss: 3.063130393995078

Epoch: 6| Step: 5
Training loss: 3.6698309220701204
Validation loss: 3.0643773940741195

Epoch: 6| Step: 6
Training loss: 3.83327638887873
Validation loss: 3.061574856866241

Epoch: 6| Step: 7
Training loss: 2.346076624322224
Validation loss: 3.0634271207394574

Epoch: 6| Step: 8
Training loss: 2.959158733002421
Validation loss: 3.059406250601932

Epoch: 6| Step: 9
Training loss: 3.6437895941178016
Validation loss: 3.0608325241768255

Epoch: 6| Step: 10
Training loss: 3.9046129382136745
Validation loss: 3.0591283155659856

Epoch: 6| Step: 11
Training loss: 2.966253093938102
Validation loss: 3.058605065358426

Epoch: 6| Step: 12
Training loss: 3.150207022267281
Validation loss: 3.0584372333443968

Epoch: 6| Step: 13
Training loss: 3.31371299558949
Validation loss: 3.05907201955935

Epoch: 88| Step: 0
Training loss: 2.9823065974671996
Validation loss: 3.0576586499491443

Epoch: 6| Step: 1
Training loss: 3.4965477675256174
Validation loss: 3.056237203151529

Epoch: 6| Step: 2
Training loss: 3.6407555814581203
Validation loss: 3.058192208721141

Epoch: 6| Step: 3
Training loss: 3.941887001078603
Validation loss: 3.054744008568651

Epoch: 6| Step: 4
Training loss: 2.5399218234849834
Validation loss: 3.0548055052331966

Epoch: 6| Step: 5
Training loss: 3.1580619520956086
Validation loss: 3.0556109210529896

Epoch: 6| Step: 6
Training loss: 3.053529329575393
Validation loss: 3.057719035782687

Epoch: 6| Step: 7
Training loss: 3.343003947372913
Validation loss: 3.0583444226362797

Epoch: 6| Step: 8
Training loss: 4.171987239170766
Validation loss: 3.0593072045531002

Epoch: 6| Step: 9
Training loss: 2.4643983755954912
Validation loss: 3.057090513817759

Epoch: 6| Step: 10
Training loss: 3.3618138176846424
Validation loss: 3.0556724925580974

Epoch: 6| Step: 11
Training loss: 3.498872439091162
Validation loss: 3.055396208114882

Epoch: 6| Step: 12
Training loss: 3.1828330786989683
Validation loss: 3.055591803665414

Epoch: 6| Step: 13
Training loss: 3.2893676616246905
Validation loss: 3.054294078803649

Epoch: 89| Step: 0
Training loss: 2.342870928893251
Validation loss: 3.053573777576399

Epoch: 6| Step: 1
Training loss: 3.4877315485391494
Validation loss: 3.055403837618097

Epoch: 6| Step: 2
Training loss: 3.022884978836588
Validation loss: 3.054541149252289

Epoch: 6| Step: 3
Training loss: 3.8172361629224554
Validation loss: 3.0523268353915896

Epoch: 6| Step: 4
Training loss: 3.541744874576908
Validation loss: 3.053733319766658

Epoch: 6| Step: 5
Training loss: 3.320398953378152
Validation loss: 3.054036373831015

Epoch: 6| Step: 6
Training loss: 2.8777552132067576
Validation loss: 3.0537615750347693

Epoch: 6| Step: 7
Training loss: 4.295266478046693
Validation loss: 3.052280784322902

Epoch: 6| Step: 8
Training loss: 3.4883677780509106
Validation loss: 3.0514437069534495

Epoch: 6| Step: 9
Training loss: 2.223833519845138
Validation loss: 3.052136308853634

Epoch: 6| Step: 10
Training loss: 3.3741756421440314
Validation loss: 3.0521745800767226

Epoch: 6| Step: 11
Training loss: 3.9878448337224306
Validation loss: 3.0497039358719653

Epoch: 6| Step: 12
Training loss: 2.6606793442477232
Validation loss: 3.04950715226401

Epoch: 6| Step: 13
Training loss: 3.4630873915209004
Validation loss: 3.0509570068262524

Epoch: 90| Step: 0
Training loss: 2.563207668188914
Validation loss: 3.0498575106682155

Epoch: 6| Step: 1
Training loss: 3.8396408322369235
Validation loss: 3.0472700773166914

Epoch: 6| Step: 2
Training loss: 3.332239893544563
Validation loss: 3.0462409610036785

Epoch: 6| Step: 3
Training loss: 4.077633882964003
Validation loss: 3.047965625219479

Epoch: 6| Step: 4
Training loss: 2.9845082517903823
Validation loss: 3.0460124496364873

Epoch: 6| Step: 5
Training loss: 2.8852067634629113
Validation loss: 3.045679588764424

Epoch: 6| Step: 6
Training loss: 3.7015408374801435
Validation loss: 3.04713409559057

Epoch: 6| Step: 7
Training loss: 2.4297418618943647
Validation loss: 3.0454939883234418

Epoch: 6| Step: 8
Training loss: 4.052967331407092
Validation loss: 3.0448577370413963

Epoch: 6| Step: 9
Training loss: 2.948060552277965
Validation loss: 3.0436853617611725

Epoch: 6| Step: 10
Training loss: 3.433796222432598
Validation loss: 3.0462582115618675

Epoch: 6| Step: 11
Training loss: 2.906847984567356
Validation loss: 3.0514415561936876

Epoch: 6| Step: 12
Training loss: 3.176396797087673
Validation loss: 3.0590692565230637

Epoch: 6| Step: 13
Training loss: 3.7426402031189747
Validation loss: 3.0597522874551313

Epoch: 91| Step: 0
Training loss: 2.4893084790658175
Validation loss: 3.055397325733832

Epoch: 6| Step: 1
Training loss: 3.4253717262528887
Validation loss: 3.057581102336301

Epoch: 6| Step: 2
Training loss: 2.9614885366006387
Validation loss: 3.0443987514450255

Epoch: 6| Step: 3
Training loss: 3.290199210214407
Validation loss: 3.0455063195563334

Epoch: 6| Step: 4
Training loss: 3.257693793972301
Validation loss: 3.0451303540251815

Epoch: 6| Step: 5
Training loss: 3.3948939297585605
Validation loss: 3.043163777052349

Epoch: 6| Step: 6
Training loss: 3.057207477889947
Validation loss: 3.0435069359880886

Epoch: 6| Step: 7
Training loss: 3.404687085442695
Validation loss: 3.0417198337207294

Epoch: 6| Step: 8
Training loss: 3.6051841284596904
Validation loss: 3.041427495579763

Epoch: 6| Step: 9
Training loss: 2.9951546004041703
Validation loss: 3.0429058531551703

Epoch: 6| Step: 10
Training loss: 2.7308229754192035
Validation loss: 3.042480643592673

Epoch: 6| Step: 11
Training loss: 3.8426559255777675
Validation loss: 3.0443507606779474

Epoch: 6| Step: 12
Training loss: 4.41153135393128
Validation loss: 3.03975959111662

Epoch: 6| Step: 13
Training loss: 2.849558002931815
Validation loss: 3.0391850748219427

Epoch: 92| Step: 0
Training loss: 3.120351767639122
Validation loss: 3.0407784258340125

Epoch: 6| Step: 1
Training loss: 3.3686416919969475
Validation loss: 3.0371395499324305

Epoch: 6| Step: 2
Training loss: 3.3642036688313652
Validation loss: 3.040016129930727

Epoch: 6| Step: 3
Training loss: 3.6356557568879886
Validation loss: 3.0406632149754125

Epoch: 6| Step: 4
Training loss: 3.556611799932959
Validation loss: 3.040812134793045

Epoch: 6| Step: 5
Training loss: 3.0385184695919274
Validation loss: 3.0404396099342246

Epoch: 6| Step: 6
Training loss: 2.9231127396987713
Validation loss: 3.039084753110084

Epoch: 6| Step: 7
Training loss: 3.25416269013133
Validation loss: 3.038903658843743

Epoch: 6| Step: 8
Training loss: 3.419039452833105
Validation loss: 3.0406058519966144

Epoch: 6| Step: 9
Training loss: 3.2921467362583705
Validation loss: 3.039339869410518

Epoch: 6| Step: 10
Training loss: 3.1199351656119507
Validation loss: 3.037754848728598

Epoch: 6| Step: 11
Training loss: 3.5949405190928303
Validation loss: 3.037794231129209

Epoch: 6| Step: 12
Training loss: 3.0913264482410665
Validation loss: 3.038894342876503

Epoch: 6| Step: 13
Training loss: 3.643897031039014
Validation loss: 3.035504735406552

Epoch: 93| Step: 0
Training loss: 3.7215185037911684
Validation loss: 3.0330787371546544

Epoch: 6| Step: 1
Training loss: 2.733593463924946
Validation loss: 3.032880253564973

Epoch: 6| Step: 2
Training loss: 2.506904033453769
Validation loss: 3.0329051512591314

Epoch: 6| Step: 3
Training loss: 3.104000949063107
Validation loss: 3.0372400143938583

Epoch: 6| Step: 4
Training loss: 3.2581301015187916
Validation loss: 3.0465752752110267

Epoch: 6| Step: 5
Training loss: 3.59165375980852
Validation loss: 3.048424932402727

Epoch: 6| Step: 6
Training loss: 3.3515926617596787
Validation loss: 3.0509179128159234

Epoch: 6| Step: 7
Training loss: 4.092781243468158
Validation loss: 3.0614966548075215

Epoch: 6| Step: 8
Training loss: 4.478932763431577
Validation loss: 3.0527825598053013

Epoch: 6| Step: 9
Training loss: 2.595067436503337
Validation loss: 3.0342372057631555

Epoch: 6| Step: 10
Training loss: 3.452246230492505
Validation loss: 3.030332353040798

Epoch: 6| Step: 11
Training loss: 2.629137139575235
Validation loss: 3.031873781116281

Epoch: 6| Step: 12
Training loss: 2.9113254323435322
Validation loss: 3.0318332064987588

Epoch: 6| Step: 13
Training loss: 3.235500858453558
Validation loss: 3.0319468072951583

Epoch: 94| Step: 0
Training loss: 2.734733165716703
Validation loss: 3.0333465296532514

Epoch: 6| Step: 1
Training loss: 3.1833463046090915
Validation loss: 3.035233688089856

Epoch: 6| Step: 2
Training loss: 3.1212889952815055
Validation loss: 3.035879630706908

Epoch: 6| Step: 3
Training loss: 2.5081188929787874
Validation loss: 3.033822961370642

Epoch: 6| Step: 4
Training loss: 3.4537181776294776
Validation loss: 3.0386110219230322

Epoch: 6| Step: 5
Training loss: 3.4202504939649208
Validation loss: 3.034820694774101

Epoch: 6| Step: 6
Training loss: 2.588375912635625
Validation loss: 3.0320684547810473

Epoch: 6| Step: 7
Training loss: 4.190362208331366
Validation loss: 3.0307531208579124

Epoch: 6| Step: 8
Training loss: 3.7303741602863942
Validation loss: 3.0281811288364002

Epoch: 6| Step: 9
Training loss: 3.432159853513644
Validation loss: 3.029301500776077

Epoch: 6| Step: 10
Training loss: 3.294991484010195
Validation loss: 3.0299373025985576

Epoch: 6| Step: 11
Training loss: 3.1128033471027967
Validation loss: 3.035737130242959

Epoch: 6| Step: 12
Training loss: 3.615769439950963
Validation loss: 3.0301200723698036

Epoch: 6| Step: 13
Training loss: 3.6526220858181646
Validation loss: 3.0319058962788223

Epoch: 95| Step: 0
Training loss: 4.077944462898001
Validation loss: 3.0274216064010835

Epoch: 6| Step: 1
Training loss: 3.979621954364284
Validation loss: 3.0274413326968577

Epoch: 6| Step: 2
Training loss: 3.3141622151540036
Validation loss: 3.0259679560439645

Epoch: 6| Step: 3
Training loss: 3.335571697824912
Validation loss: 3.0273609693595223

Epoch: 6| Step: 4
Training loss: 2.988835222344672
Validation loss: 3.0262256106311174

Epoch: 6| Step: 5
Training loss: 3.2510446190120383
Validation loss: 3.028086513681637

Epoch: 6| Step: 6
Training loss: 2.5715191915983806
Validation loss: 3.0268936052261917

Epoch: 6| Step: 7
Training loss: 2.8393554267653696
Validation loss: 3.035936606726667

Epoch: 6| Step: 8
Training loss: 3.3197885616029827
Validation loss: 3.029747146709524

Epoch: 6| Step: 9
Training loss: 2.645586037280182
Validation loss: 3.0312375101285265

Epoch: 6| Step: 10
Training loss: 3.5600572208563563
Validation loss: 3.03024320434756

Epoch: 6| Step: 11
Training loss: 3.372056030278544
Validation loss: 3.0355434358962095

Epoch: 6| Step: 12
Training loss: 3.3728990019880976
Validation loss: 3.0244546645999897

Epoch: 6| Step: 13
Training loss: 3.249066145317819
Validation loss: 3.024939113252666

Epoch: 96| Step: 0
Training loss: 2.7645015697754216
Validation loss: 3.023982097001411

Epoch: 6| Step: 1
Training loss: 3.4385926330789243
Validation loss: 3.02062109914882

Epoch: 6| Step: 2
Training loss: 2.9460759071572515
Validation loss: 3.021865409298588

Epoch: 6| Step: 3
Training loss: 4.031542626930638
Validation loss: 3.019458440613794

Epoch: 6| Step: 4
Training loss: 3.8534903817913695
Validation loss: 3.0216617188154875

Epoch: 6| Step: 5
Training loss: 3.181275816926954
Validation loss: 3.0210261474675475

Epoch: 6| Step: 6
Training loss: 3.6229415837126244
Validation loss: 3.019254067250736

Epoch: 6| Step: 7
Training loss: 2.6002864056343684
Validation loss: 3.0204918993397394

Epoch: 6| Step: 8
Training loss: 2.860976307562522
Validation loss: 3.0171035150706063

Epoch: 6| Step: 9
Training loss: 3.1181113038227712
Validation loss: 3.020268973029079

Epoch: 6| Step: 10
Training loss: 2.948664773612551
Validation loss: 3.020617476839224

Epoch: 6| Step: 11
Training loss: 2.968143923280035
Validation loss: 3.017856108143

Epoch: 6| Step: 12
Training loss: 3.4002940050801325
Validation loss: 3.020847870166216

Epoch: 6| Step: 13
Training loss: 4.424601546629431
Validation loss: 3.0254908881480707

Epoch: 97| Step: 0
Training loss: 3.180285348385544
Validation loss: 3.017818906168379

Epoch: 6| Step: 1
Training loss: 3.373436035608254
Validation loss: 3.0206718246062465

Epoch: 6| Step: 2
Training loss: 3.6545009505082393
Validation loss: 3.0187321813477817

Epoch: 6| Step: 3
Training loss: 3.132751007618132
Validation loss: 3.0171742103465684

Epoch: 6| Step: 4
Training loss: 3.2917610026173
Validation loss: 3.0158525054124303

Epoch: 6| Step: 5
Training loss: 3.209591622921099
Validation loss: 3.0149047763413312

Epoch: 6| Step: 6
Training loss: 3.004226409557917
Validation loss: 3.014686133554432

Epoch: 6| Step: 7
Training loss: 3.1644338130891403
Validation loss: 3.014497119596487

Epoch: 6| Step: 8
Training loss: 3.753142375413503
Validation loss: 3.0136395051264993

Epoch: 6| Step: 9
Training loss: 2.3599439528647372
Validation loss: 3.013402472742915

Epoch: 6| Step: 10
Training loss: 4.103065898205225
Validation loss: 3.012980616035548

Epoch: 6| Step: 11
Training loss: 2.807248871901151
Validation loss: 3.0138869014248466

Epoch: 6| Step: 12
Training loss: 3.6749937407771154
Validation loss: 3.013882965652419

Epoch: 6| Step: 13
Training loss: 2.725498549325739
Validation loss: 3.013809552815129

Epoch: 98| Step: 0
Training loss: 3.110587645573334
Validation loss: 3.0129882261651204

Epoch: 6| Step: 1
Training loss: 3.548336988106478
Validation loss: 3.0120637576707603

Epoch: 6| Step: 2
Training loss: 3.3466436396968002
Validation loss: 3.012962894161101

Epoch: 6| Step: 3
Training loss: 2.8952135113399007
Validation loss: 3.0115729849550847

Epoch: 6| Step: 4
Training loss: 3.4001376404670878
Validation loss: 3.010478066812721

Epoch: 6| Step: 5
Training loss: 3.6973641569345554
Validation loss: 3.0105389263881532

Epoch: 6| Step: 6
Training loss: 3.210049471607635
Validation loss: 3.0126420189906455

Epoch: 6| Step: 7
Training loss: 2.630350926125233
Validation loss: 3.0111162460215355

Epoch: 6| Step: 8
Training loss: 3.79402084766345
Validation loss: 3.011170823167198

Epoch: 6| Step: 9
Training loss: 2.933516215634428
Validation loss: 3.0144327629211793

Epoch: 6| Step: 10
Training loss: 3.7508449874004173
Validation loss: 3.0126493491591253

Epoch: 6| Step: 11
Training loss: 3.1397896789769932
Validation loss: 3.0110652489046554

Epoch: 6| Step: 12
Training loss: 3.3238150758315657
Validation loss: 3.013712939969912

Epoch: 6| Step: 13
Training loss: 2.705768152910047
Validation loss: 3.011966818160622

Epoch: 99| Step: 0
Training loss: 2.7585248594451715
Validation loss: 3.0140455716334347

Epoch: 6| Step: 1
Training loss: 2.881002048903494
Validation loss: 3.0184632833882996

Epoch: 6| Step: 2
Training loss: 2.625192725963126
Validation loss: 3.0158954260863173

Epoch: 6| Step: 3
Training loss: 4.12673382011667
Validation loss: 3.0181062948643205

Epoch: 6| Step: 4
Training loss: 3.0249606295459013
Validation loss: 3.0195091550380777

Epoch: 6| Step: 5
Training loss: 2.611761863140405
Validation loss: 3.020024751446194

Epoch: 6| Step: 6
Training loss: 2.778946683566452
Validation loss: 3.021465318290414

Epoch: 6| Step: 7
Training loss: 3.1533868474902214
Validation loss: 3.0149684375959844

Epoch: 6| Step: 8
Training loss: 3.505673034306239
Validation loss: 3.0091832174603304

Epoch: 6| Step: 9
Training loss: 4.128551688078725
Validation loss: 3.0038032522081326

Epoch: 6| Step: 10
Training loss: 3.837307500826067
Validation loss: 3.003346458424498

Epoch: 6| Step: 11
Training loss: 3.838643970273562
Validation loss: 3.0056860466536115

Epoch: 6| Step: 12
Training loss: 2.9161413718805638
Validation loss: 3.002687621032357

Epoch: 6| Step: 13
Training loss: 3.0589315683392977
Validation loss: 3.004360542107701

Epoch: 100| Step: 0
Training loss: 3.4417592797430308
Validation loss: 3.004267753823356

Epoch: 6| Step: 1
Training loss: 3.221578595858247
Validation loss: 3.0036648562729056

Epoch: 6| Step: 2
Training loss: 2.9486450445716508
Validation loss: 3.005673716668222

Epoch: 6| Step: 3
Training loss: 3.610299788731423
Validation loss: 3.004722812056386

Epoch: 6| Step: 4
Training loss: 3.6287667008454867
Validation loss: 3.002589927999387

Epoch: 6| Step: 5
Training loss: 1.7334908646132965
Validation loss: 3.000977210035678

Epoch: 6| Step: 6
Training loss: 3.584026151408426
Validation loss: 3.001573662614527

Epoch: 6| Step: 7
Training loss: 4.070533204638965
Validation loss: 3.002507217453334

Epoch: 6| Step: 8
Training loss: 3.472096521433468
Validation loss: 3.0017412885002464

Epoch: 6| Step: 9
Training loss: 3.1893526564855823
Validation loss: 3.0012332584404318

Epoch: 6| Step: 10
Training loss: 3.4376936424506623
Validation loss: 3.0030818648471196

Epoch: 6| Step: 11
Training loss: 3.0412699471167226
Validation loss: 3.00472146826025

Epoch: 6| Step: 12
Training loss: 3.0078988991750855
Validation loss: 3.006541524007662

Epoch: 6| Step: 13
Training loss: 2.704720792339601
Validation loss: 3.0038685415632598

Epoch: 101| Step: 0
Training loss: 3.0902255240795697
Validation loss: 3.0006635523403813

Epoch: 6| Step: 1
Training loss: 3.1782493244411376
Validation loss: 3.0013421160243343

Epoch: 6| Step: 2
Training loss: 3.8773149528102735
Validation loss: 3.0052190984365126

Epoch: 6| Step: 3
Training loss: 3.140872319290682
Validation loss: 3.000501127671198

Epoch: 6| Step: 4
Training loss: 3.2678153983077123
Validation loss: 2.9996579028158155

Epoch: 6| Step: 5
Training loss: 2.4176094145606046
Validation loss: 2.99820241430769

Epoch: 6| Step: 6
Training loss: 3.3674398447170644
Validation loss: 2.9979985031100878

Epoch: 6| Step: 7
Training loss: 2.8057860026962187
Validation loss: 3.000344053317285

Epoch: 6| Step: 8
Training loss: 3.242066898171103
Validation loss: 2.9955238905967603

Epoch: 6| Step: 9
Training loss: 3.8787775392873183
Validation loss: 2.9975648913243087

Epoch: 6| Step: 10
Training loss: 3.279933556372188
Validation loss: 2.999567004030954

Epoch: 6| Step: 11
Training loss: 2.8739225607721135
Validation loss: 2.999735967577565

Epoch: 6| Step: 12
Training loss: 3.8884469795433403
Validation loss: 2.9992152678039017

Epoch: 6| Step: 13
Training loss: 3.1168062746599707
Validation loss: 2.997776470500521

Epoch: 102| Step: 0
Training loss: 3.265474890950432
Validation loss: 2.996230190599604

Epoch: 6| Step: 1
Training loss: 2.980196119165886
Validation loss: 2.9951050416866307

Epoch: 6| Step: 2
Training loss: 2.7747038193463487
Validation loss: 2.9945249519872523

Epoch: 6| Step: 3
Training loss: 3.239191716474068
Validation loss: 2.992788761568509

Epoch: 6| Step: 4
Training loss: 3.5235090903983246
Validation loss: 2.993872143725965

Epoch: 6| Step: 5
Training loss: 3.387333128925816
Validation loss: 2.990193946110524

Epoch: 6| Step: 6
Training loss: 3.635694316474062
Validation loss: 2.989257912841278

Epoch: 6| Step: 7
Training loss: 3.5203589546805882
Validation loss: 2.9908559248101105

Epoch: 6| Step: 8
Training loss: 3.554176511821699
Validation loss: 2.990346332633199

Epoch: 6| Step: 9
Training loss: 2.979040681180261
Validation loss: 2.990883336646013

Epoch: 6| Step: 10
Training loss: 3.5129753469920932
Validation loss: 2.9920365661681925

Epoch: 6| Step: 11
Training loss: 2.799211006036726
Validation loss: 2.9873469439101403

Epoch: 6| Step: 12
Training loss: 3.3168254897334744
Validation loss: 2.9910940008205786

Epoch: 6| Step: 13
Training loss: 2.94986169135231
Validation loss: 2.9892109184498286

Epoch: 103| Step: 0
Training loss: 4.1003723161566095
Validation loss: 2.988599819462706

Epoch: 6| Step: 1
Training loss: 3.202428528035068
Validation loss: 2.991436301783799

Epoch: 6| Step: 2
Training loss: 3.276765501821982
Validation loss: 2.988636419272593

Epoch: 6| Step: 3
Training loss: 2.5072112981966503
Validation loss: 2.989699339841002

Epoch: 6| Step: 4
Training loss: 2.4621418261609844
Validation loss: 2.9893400191791164

Epoch: 6| Step: 5
Training loss: 3.5277733356384453
Validation loss: 2.9862623851933785

Epoch: 6| Step: 6
Training loss: 3.2169883870207805
Validation loss: 2.987586920492305

Epoch: 6| Step: 7
Training loss: 2.8773991070118714
Validation loss: 2.9877920210466082

Epoch: 6| Step: 8
Training loss: 2.915013707751961
Validation loss: 2.9864197040154967

Epoch: 6| Step: 9
Training loss: 3.5721344086839193
Validation loss: 2.9855290604873486

Epoch: 6| Step: 10
Training loss: 3.8169613359355443
Validation loss: 2.9877668066203467

Epoch: 6| Step: 11
Training loss: 3.232573666422793
Validation loss: 2.9852463091832493

Epoch: 6| Step: 12
Training loss: 2.888105459438146
Validation loss: 2.990052222058111

Epoch: 6| Step: 13
Training loss: 4.0207031439752745
Validation loss: 2.9872826837223965

Epoch: 104| Step: 0
Training loss: 2.887861425726099
Validation loss: 2.9901625472428814

Epoch: 6| Step: 1
Training loss: 2.7006058613638193
Validation loss: 2.9908401118894425

Epoch: 6| Step: 2
Training loss: 3.007875912480901
Validation loss: 2.9951709708635756

Epoch: 6| Step: 3
Training loss: 2.548902395050589
Validation loss: 3.005921337025806

Epoch: 6| Step: 4
Training loss: 3.452547189001934
Validation loss: 3.0086297571915757

Epoch: 6| Step: 5
Training loss: 3.6667293774415066
Validation loss: 3.0186430153402126

Epoch: 6| Step: 6
Training loss: 3.4366831415807013
Validation loss: 3.0196886889036656

Epoch: 6| Step: 7
Training loss: 3.3395344908901192
Validation loss: 2.9999653735606513

Epoch: 6| Step: 8
Training loss: 3.684321957530743
Validation loss: 2.9928654859226356

Epoch: 6| Step: 9
Training loss: 3.358394603943363
Validation loss: 2.9802853404170606

Epoch: 6| Step: 10
Training loss: 3.5849697161769387
Validation loss: 2.981993051256802

Epoch: 6| Step: 11
Training loss: 3.5426283633949485
Validation loss: 2.980573428026433

Epoch: 6| Step: 12
Training loss: 2.8530664109965334
Validation loss: 2.983203948746465

Epoch: 6| Step: 13
Training loss: 3.531793873182081
Validation loss: 2.9850411153032463

Epoch: 105| Step: 0
Training loss: 2.7757189326292644
Validation loss: 2.987924950564851

Epoch: 6| Step: 1
Training loss: 3.5553702233279108
Validation loss: 2.9873571955478173

Epoch: 6| Step: 2
Training loss: 3.5326861946510237
Validation loss: 2.986310337673913

Epoch: 6| Step: 3
Training loss: 3.596019525816526
Validation loss: 2.985149600643325

Epoch: 6| Step: 4
Training loss: 3.168258183400938
Validation loss: 2.9842480430235017

Epoch: 6| Step: 5
Training loss: 3.1777064645171036
Validation loss: 2.982788856754842

Epoch: 6| Step: 6
Training loss: 2.968489625454855
Validation loss: 2.9819145400503384

Epoch: 6| Step: 7
Training loss: 2.819002391401442
Validation loss: 2.981747438294496

Epoch: 6| Step: 8
Training loss: 3.0622027505914726
Validation loss: 2.9792712091652893

Epoch: 6| Step: 9
Training loss: 3.885377708151108
Validation loss: 2.9771458115041693

Epoch: 6| Step: 10
Training loss: 2.7705568639361493
Validation loss: 2.978809854790837

Epoch: 6| Step: 11
Training loss: 3.6217938418178077
Validation loss: 2.9788366950069634

Epoch: 6| Step: 12
Training loss: 3.5266919722006724
Validation loss: 2.975919748477165

Epoch: 6| Step: 13
Training loss: 2.748675113922519
Validation loss: 2.975330409026454

Epoch: 106| Step: 0
Training loss: 3.524604553334353
Validation loss: 2.9768612408415023

Epoch: 6| Step: 1
Training loss: 3.8828980956438692
Validation loss: 2.9825669244693294

Epoch: 6| Step: 2
Training loss: 3.3045507091591584
Validation loss: 2.987805989881014

Epoch: 6| Step: 3
Training loss: 4.256276152722286
Validation loss: 3.0015508341734565

Epoch: 6| Step: 4
Training loss: 2.0002798838281257
Validation loss: 2.988891445751779

Epoch: 6| Step: 5
Training loss: 3.6027577169175675
Validation loss: 3.002038324754551

Epoch: 6| Step: 6
Training loss: 3.7681309129849216
Validation loss: 2.992499290998948

Epoch: 6| Step: 7
Training loss: 3.362633548622897
Validation loss: 3.001454300780014

Epoch: 6| Step: 8
Training loss: 3.400555812059643
Validation loss: 2.993816081504255

Epoch: 6| Step: 9
Training loss: 2.562831019909211
Validation loss: 2.980972741366387

Epoch: 6| Step: 10
Training loss: 2.8828895785977817
Validation loss: 2.9832660143840704

Epoch: 6| Step: 11
Training loss: 2.898469909322259
Validation loss: 2.9780707445759043

Epoch: 6| Step: 12
Training loss: 2.787466238869435
Validation loss: 2.9749171690742844

Epoch: 6| Step: 13
Training loss: 2.0843929901948055
Validation loss: 2.974823961386281

Epoch: 107| Step: 0
Training loss: 2.6973639158865015
Validation loss: 2.9699394766251177

Epoch: 6| Step: 1
Training loss: 3.4555249741956775
Validation loss: 2.9723459793095577

Epoch: 6| Step: 2
Training loss: 2.740563066363431
Validation loss: 2.972750357851375

Epoch: 6| Step: 3
Training loss: 2.8578991025355385
Validation loss: 2.973018513185559

Epoch: 6| Step: 4
Training loss: 3.0974976930771336
Validation loss: 2.972064568453636

Epoch: 6| Step: 5
Training loss: 3.5518484326922453
Validation loss: 2.9718137440337284

Epoch: 6| Step: 6
Training loss: 3.7984221646035814
Validation loss: 2.9726845971948386

Epoch: 6| Step: 7
Training loss: 3.1485854651276943
Validation loss: 2.971248976899401

Epoch: 6| Step: 8
Training loss: 3.331922200644466
Validation loss: 2.972365804608341

Epoch: 6| Step: 9
Training loss: 3.7261983185683714
Validation loss: 2.971267168452554

Epoch: 6| Step: 10
Training loss: 3.1385389393616197
Validation loss: 2.9711539500218156

Epoch: 6| Step: 11
Training loss: 3.0563326646979716
Validation loss: 2.9715575840534214

Epoch: 6| Step: 12
Training loss: 3.4358708075503595
Validation loss: 2.9689995151880613

Epoch: 6| Step: 13
Training loss: 3.3741858171400203
Validation loss: 2.9716842045454346

Epoch: 108| Step: 0
Training loss: 3.554518743847922
Validation loss: 2.9694297318919833

Epoch: 6| Step: 1
Training loss: 3.6355946377946657
Validation loss: 2.9693905875972715

Epoch: 6| Step: 2
Training loss: 3.005610464992586
Validation loss: 2.9694940624424095

Epoch: 6| Step: 3
Training loss: 3.3415227584737397
Validation loss: 2.97113271278082

Epoch: 6| Step: 4
Training loss: 3.2133399904216438
Validation loss: 2.9722431359296273

Epoch: 6| Step: 5
Training loss: 3.338052619587908
Validation loss: 2.9749252316144896

Epoch: 6| Step: 6
Training loss: 3.544950929632998
Validation loss: 2.973313757723781

Epoch: 6| Step: 7
Training loss: 3.854877523215769
Validation loss: 2.9781407033114626

Epoch: 6| Step: 8
Training loss: 3.116381548183313
Validation loss: 2.9723906373636937

Epoch: 6| Step: 9
Training loss: 3.2096220788685006
Validation loss: 2.9737636455815295

Epoch: 6| Step: 10
Training loss: 3.0703402996018028
Validation loss: 2.9737968960608203

Epoch: 6| Step: 11
Training loss: 2.6607129470953494
Validation loss: 2.9781528511669424

Epoch: 6| Step: 12
Training loss: 2.2019690328459545
Validation loss: 2.9690527182503406

Epoch: 6| Step: 13
Training loss: 3.5413441829093895
Validation loss: 2.9695003923399304

Epoch: 109| Step: 0
Training loss: 2.923749026934008
Validation loss: 2.969567218037178

Epoch: 6| Step: 1
Training loss: 3.679569056198165
Validation loss: 2.9664929154375104

Epoch: 6| Step: 2
Training loss: 2.7324584347703813
Validation loss: 2.967306011942117

Epoch: 6| Step: 3
Training loss: 3.2083404507908995
Validation loss: 2.967254483053023

Epoch: 6| Step: 4
Training loss: 3.379422433928389
Validation loss: 2.964764616903215

Epoch: 6| Step: 5
Training loss: 3.865788123745013
Validation loss: 2.9658280462331477

Epoch: 6| Step: 6
Training loss: 2.076818987963238
Validation loss: 2.9657201896508276

Epoch: 6| Step: 7
Training loss: 3.3379087676419608
Validation loss: 2.964073557444433

Epoch: 6| Step: 8
Training loss: 3.265762983263483
Validation loss: 2.9675374739759213

Epoch: 6| Step: 9
Training loss: 3.6546828342911915
Validation loss: 2.9751002943423357

Epoch: 6| Step: 10
Training loss: 2.9578890041446524
Validation loss: 2.964980651599214

Epoch: 6| Step: 11
Training loss: 3.292570657978468
Validation loss: 2.9617685832469

Epoch: 6| Step: 12
Training loss: 3.638269800483917
Validation loss: 2.95897418881075

Epoch: 6| Step: 13
Training loss: 2.8743875929358986
Validation loss: 2.9584523087084413

Epoch: 110| Step: 0
Training loss: 3.461544216183827
Validation loss: 2.959617751589304

Epoch: 6| Step: 1
Training loss: 3.3010278372667003
Validation loss: 2.960867430908522

Epoch: 6| Step: 2
Training loss: 2.9021878309712816
Validation loss: 2.961341798488967

Epoch: 6| Step: 3
Training loss: 3.0945202417714768
Validation loss: 2.959394733948633

Epoch: 6| Step: 4
Training loss: 3.3486978875548417
Validation loss: 2.960175642646336

Epoch: 6| Step: 5
Training loss: 3.913031467013883
Validation loss: 2.9616433817208225

Epoch: 6| Step: 6
Training loss: 3.153344658420649
Validation loss: 2.9594667687818816

Epoch: 6| Step: 7
Training loss: 2.090059814692321
Validation loss: 2.959931181404482

Epoch: 6| Step: 8
Training loss: 3.2758922613590675
Validation loss: 2.95843483991775

Epoch: 6| Step: 9
Training loss: 3.260332262858097
Validation loss: 2.958465686444676

Epoch: 6| Step: 10
Training loss: 3.265410639832074
Validation loss: 2.9581716066621504

Epoch: 6| Step: 11
Training loss: 3.1475162341461984
Validation loss: 2.956774015694663

Epoch: 6| Step: 12
Training loss: 3.904567630877232
Validation loss: 2.9552563308834596

Epoch: 6| Step: 13
Training loss: 2.693332995644476
Validation loss: 2.9547003282422626

Epoch: 111| Step: 0
Training loss: 2.9346658548298805
Validation loss: 2.9525231623127666

Epoch: 6| Step: 1
Training loss: 3.640136686001425
Validation loss: 2.954010687765691

Epoch: 6| Step: 2
Training loss: 3.348082400676356
Validation loss: 2.9517296730939075

Epoch: 6| Step: 3
Training loss: 2.8833730095869576
Validation loss: 2.955138916186733

Epoch: 6| Step: 4
Training loss: 2.7860489494038188
Validation loss: 2.9548707693588727

Epoch: 6| Step: 5
Training loss: 3.472183590144247
Validation loss: 2.9609685066044062

Epoch: 6| Step: 6
Training loss: 3.749831640914706
Validation loss: 2.9637411092866497

Epoch: 6| Step: 7
Training loss: 3.683073587594435
Validation loss: 2.9603183770173453

Epoch: 6| Step: 8
Training loss: 3.2498764601482293
Validation loss: 2.956805407569602

Epoch: 6| Step: 9
Training loss: 3.1240260323039397
Validation loss: 2.9649740388257264

Epoch: 6| Step: 10
Training loss: 3.5184108970497627
Validation loss: 2.9629452710801334

Epoch: 6| Step: 11
Training loss: 2.9059164204454926
Validation loss: 2.9563157895580705

Epoch: 6| Step: 12
Training loss: 2.413982303608249
Validation loss: 2.9586213292474426

Epoch: 6| Step: 13
Training loss: 3.4490622531385817
Validation loss: 2.956690438816832

Epoch: 112| Step: 0
Training loss: 3.0093571647519584
Validation loss: 2.962614391495204

Epoch: 6| Step: 1
Training loss: 3.2030648574765346
Validation loss: 2.961573373477462

Epoch: 6| Step: 2
Training loss: 3.125868409611797
Validation loss: 2.9602141588107935

Epoch: 6| Step: 3
Training loss: 3.8225398211404027
Validation loss: 2.958793657762144

Epoch: 6| Step: 4
Training loss: 3.0559199742030074
Validation loss: 2.9679523966059174

Epoch: 6| Step: 5
Training loss: 2.8385559268324907
Validation loss: 2.9718915248829068

Epoch: 6| Step: 6
Training loss: 2.8416715299354025
Validation loss: 2.9798328995115506

Epoch: 6| Step: 7
Training loss: 3.6410705555714538
Validation loss: 2.984788748823612

Epoch: 6| Step: 8
Training loss: 2.8870130912819567
Validation loss: 2.9803556161857787

Epoch: 6| Step: 9
Training loss: 3.1109078620943484
Validation loss: 2.9725099131168595

Epoch: 6| Step: 10
Training loss: 3.5915228535359067
Validation loss: 2.9612125030162977

Epoch: 6| Step: 11
Training loss: 3.337757052120039
Validation loss: 2.9552838092116143

Epoch: 6| Step: 12
Training loss: 3.325359216087132
Validation loss: 2.951435835913517

Epoch: 6| Step: 13
Training loss: 3.428716222226061
Validation loss: 2.9473188220100335

Epoch: 113| Step: 0
Training loss: 3.4080654520904408
Validation loss: 2.945748666004131

Epoch: 6| Step: 1
Training loss: 3.4855265403769162
Validation loss: 2.9499247522422496

Epoch: 6| Step: 2
Training loss: 3.1296577836909867
Validation loss: 2.945249393453264

Epoch: 6| Step: 3
Training loss: 2.8649362982413686
Validation loss: 2.94544976627957

Epoch: 6| Step: 4
Training loss: 3.2734911056171647
Validation loss: 2.9483610028708322

Epoch: 6| Step: 5
Training loss: 2.813848723107844
Validation loss: 2.9442409005307018

Epoch: 6| Step: 6
Training loss: 3.4644509558391845
Validation loss: 2.9440475919923026

Epoch: 6| Step: 7
Training loss: 2.9235873992836265
Validation loss: 2.9436725450639734

Epoch: 6| Step: 8
Training loss: 3.013154752497787
Validation loss: 2.945206044727982

Epoch: 6| Step: 9
Training loss: 3.4435720740461337
Validation loss: 2.941319562397777

Epoch: 6| Step: 10
Training loss: 3.396379360617784
Validation loss: 2.941888277461368

Epoch: 6| Step: 11
Training loss: 3.7884041440370546
Validation loss: 2.941922322171221

Epoch: 6| Step: 12
Training loss: 3.2267178181726384
Validation loss: 2.9417367489749884

Epoch: 6| Step: 13
Training loss: 2.49739157975
Validation loss: 2.9463227500782763

Epoch: 114| Step: 0
Training loss: 3.6408773834108605
Validation loss: 2.949618174427671

Epoch: 6| Step: 1
Training loss: 3.0093907562825772
Validation loss: 2.9466572973957743

Epoch: 6| Step: 2
Training loss: 3.2796673545563992
Validation loss: 2.954528695487874

Epoch: 6| Step: 3
Training loss: 3.0545288981364673
Validation loss: 2.9583649541911665

Epoch: 6| Step: 4
Training loss: 2.97537247706204
Validation loss: 2.9460304707976355

Epoch: 6| Step: 5
Training loss: 2.892634172946191
Validation loss: 2.940170238659336

Epoch: 6| Step: 6
Training loss: 3.1957503114449644
Validation loss: 2.939806592650213

Epoch: 6| Step: 7
Training loss: 3.4176908369158085
Validation loss: 2.937997287608681

Epoch: 6| Step: 8
Training loss: 3.5864685596176606
Validation loss: 2.9415241527177916

Epoch: 6| Step: 9
Training loss: 2.9008740982249543
Validation loss: 2.943398468317356

Epoch: 6| Step: 10
Training loss: 3.7837958474684945
Validation loss: 2.9410593901197966

Epoch: 6| Step: 11
Training loss: 3.428937478052575
Validation loss: 2.941870941243176

Epoch: 6| Step: 12
Training loss: 2.418196709014039
Validation loss: 2.9435307166625098

Epoch: 6| Step: 13
Training loss: 3.5603656733153364
Validation loss: 2.9415073686529167

Epoch: 115| Step: 0
Training loss: 3.089529993304614
Validation loss: 2.9407486128601037

Epoch: 6| Step: 1
Training loss: 3.6726857690328805
Validation loss: 2.9379037314737215

Epoch: 6| Step: 2
Training loss: 2.887084772549417
Validation loss: 2.93885913511278

Epoch: 6| Step: 3
Training loss: 3.6181263704177073
Validation loss: 2.939344517787038

Epoch: 6| Step: 4
Training loss: 3.1744870109346444
Validation loss: 2.936703811645619

Epoch: 6| Step: 5
Training loss: 3.767239173208834
Validation loss: 2.9364934299390097

Epoch: 6| Step: 6
Training loss: 2.80153383069068
Validation loss: 2.941118277982022

Epoch: 6| Step: 7
Training loss: 3.0289946355510877
Validation loss: 2.9364692487132102

Epoch: 6| Step: 8
Training loss: 3.2016400128164753
Validation loss: 2.9373435557188485

Epoch: 6| Step: 9
Training loss: 3.5235850098175767
Validation loss: 2.937206854993577

Epoch: 6| Step: 10
Training loss: 2.9682359752363863
Validation loss: 2.9389817186601026

Epoch: 6| Step: 11
Training loss: 3.0399564002072683
Validation loss: 2.9393307878806265

Epoch: 6| Step: 12
Training loss: 2.8938213100668757
Validation loss: 2.9331897040993735

Epoch: 6| Step: 13
Training loss: 3.35106408029985
Validation loss: 2.9386570017088647

Epoch: 116| Step: 0
Training loss: 3.5952705152066997
Validation loss: 2.932564842773722

Epoch: 6| Step: 1
Training loss: 3.7881054485592527
Validation loss: 2.930184206185517

Epoch: 6| Step: 2
Training loss: 2.6183951708773874
Validation loss: 2.932292261467662

Epoch: 6| Step: 3
Training loss: 3.8316337853727567
Validation loss: 2.933487844755958

Epoch: 6| Step: 4
Training loss: 3.1839072231117695
Validation loss: 2.935916672033131

Epoch: 6| Step: 5
Training loss: 2.7214425445272297
Validation loss: 2.9411197990197127

Epoch: 6| Step: 6
Training loss: 3.0512844945449435
Validation loss: 2.9466913392069656

Epoch: 6| Step: 7
Training loss: 3.4080674108903497
Validation loss: 2.9491696850278895

Epoch: 6| Step: 8
Training loss: 3.5719584671374034
Validation loss: 2.948115540205531

Epoch: 6| Step: 9
Training loss: 2.3779203630143155
Validation loss: 2.9365890685859006

Epoch: 6| Step: 10
Training loss: 3.9967953242278407
Validation loss: 2.931787342161195

Epoch: 6| Step: 11
Training loss: 2.842233106552385
Validation loss: 2.934918812780832

Epoch: 6| Step: 12
Training loss: 2.728901556596889
Validation loss: 2.9336655479908216

Epoch: 6| Step: 13
Training loss: 2.5735936889314925
Validation loss: 2.93156292704241

Epoch: 117| Step: 0
Training loss: 3.32266432103931
Validation loss: 2.9354997263942995

Epoch: 6| Step: 1
Training loss: 3.813311631156504
Validation loss: 2.932290846010122

Epoch: 6| Step: 2
Training loss: 3.026737275441312
Validation loss: 2.9354040103345684

Epoch: 6| Step: 3
Training loss: 3.2145963367356556
Validation loss: 2.9372531225962524

Epoch: 6| Step: 4
Training loss: 2.5558555802391876
Validation loss: 2.934032962609464

Epoch: 6| Step: 5
Training loss: 3.0141237307074293
Validation loss: 2.932858457877259

Epoch: 6| Step: 6
Training loss: 3.3492221441623227
Validation loss: 2.9308182689122346

Epoch: 6| Step: 7
Training loss: 3.465016598352087
Validation loss: 2.93182536035005

Epoch: 6| Step: 8
Training loss: 3.5026717206639932
Validation loss: 2.930417458660208

Epoch: 6| Step: 9
Training loss: 2.5546805938720683
Validation loss: 2.92881169267381

Epoch: 6| Step: 10
Training loss: 2.670822739443744
Validation loss: 2.929782202280416

Epoch: 6| Step: 11
Training loss: 3.8115495841644176
Validation loss: 2.925718914739067

Epoch: 6| Step: 12
Training loss: 3.336332275473797
Validation loss: 2.9293604820708032

Epoch: 6| Step: 13
Training loss: 3.113873625222678
Validation loss: 2.928832463888535

Epoch: 118| Step: 0
Training loss: 3.051464048361039
Validation loss: 2.926476001117646

Epoch: 6| Step: 1
Training loss: 3.0709088161375373
Validation loss: 2.9240046424921453

Epoch: 6| Step: 2
Training loss: 3.7119447646142145
Validation loss: 2.924823972560485

Epoch: 6| Step: 3
Training loss: 3.3629240938502516
Validation loss: 2.9251327230714286

Epoch: 6| Step: 4
Training loss: 2.804701186122814
Validation loss: 2.927865803827227

Epoch: 6| Step: 5
Training loss: 3.542924605223879
Validation loss: 2.9281269750390235

Epoch: 6| Step: 6
Training loss: 3.050593684214906
Validation loss: 2.9293779229567734

Epoch: 6| Step: 7
Training loss: 2.322290059467226
Validation loss: 2.9349158228015773

Epoch: 6| Step: 8
Training loss: 3.913335005409451
Validation loss: 2.937121420792115

Epoch: 6| Step: 9
Training loss: 3.2368673406032666
Validation loss: 2.927039819215223

Epoch: 6| Step: 10
Training loss: 2.883432047776661
Validation loss: 2.924736521742102

Epoch: 6| Step: 11
Training loss: 3.602774128699205
Validation loss: 2.922745193457972

Epoch: 6| Step: 12
Training loss: 3.103170674613114
Validation loss: 2.9236847525897574

Epoch: 6| Step: 13
Training loss: 2.755671980750017
Validation loss: 2.922632125125692

Epoch: 119| Step: 0
Training loss: 3.3559947906017222
Validation loss: 2.924129879242968

Epoch: 6| Step: 1
Training loss: 3.5158559765704056
Validation loss: 2.924573628527573

Epoch: 6| Step: 2
Training loss: 3.4865470924320787
Validation loss: 2.9217879364798263

Epoch: 6| Step: 3
Training loss: 3.6195063563181837
Validation loss: 2.9207924704209183

Epoch: 6| Step: 4
Training loss: 3.3863696982124076
Validation loss: 2.9216429582221703

Epoch: 6| Step: 5
Training loss: 3.0300702817716267
Validation loss: 2.9225478025851723

Epoch: 6| Step: 6
Training loss: 2.997536601526366
Validation loss: 2.919917941635248

Epoch: 6| Step: 7
Training loss: 2.4086565146247683
Validation loss: 2.9237605765599994

Epoch: 6| Step: 8
Training loss: 2.722293692794571
Validation loss: 2.925091550828343

Epoch: 6| Step: 9
Training loss: 2.9413636142432047
Validation loss: 2.9227159242103813

Epoch: 6| Step: 10
Training loss: 3.5298315929841615
Validation loss: 2.9235080807396296

Epoch: 6| Step: 11
Training loss: 3.2366487186561526
Validation loss: 2.9222547402702745

Epoch: 6| Step: 12
Training loss: 2.9602396200465364
Validation loss: 2.9199291174695867

Epoch: 6| Step: 13
Training loss: 3.8546638924100383
Validation loss: 2.917558604566369

Epoch: 120| Step: 0
Training loss: 3.318786988707774
Validation loss: 2.916950015765016

Epoch: 6| Step: 1
Training loss: 3.718188844543995
Validation loss: 2.9190157511699417

Epoch: 6| Step: 2
Training loss: 2.142880330641493
Validation loss: 2.9197007598767093

Epoch: 6| Step: 3
Training loss: 3.4412187748222234
Validation loss: 2.9227794830757254

Epoch: 6| Step: 4
Training loss: 2.493318402794726
Validation loss: 2.920887945586004

Epoch: 6| Step: 5
Training loss: 3.4051847979662986
Validation loss: 2.9169045027581735

Epoch: 6| Step: 6
Training loss: 2.326183969256448
Validation loss: 2.916942458290852

Epoch: 6| Step: 7
Training loss: 2.8220821334165707
Validation loss: 2.914628072049878

Epoch: 6| Step: 8
Training loss: 3.620670758904317
Validation loss: 2.9175302278910316

Epoch: 6| Step: 9
Training loss: 3.57531801423217
Validation loss: 2.91392408772062

Epoch: 6| Step: 10
Training loss: 3.1926241807078894
Validation loss: 2.914761375975066

Epoch: 6| Step: 11
Training loss: 3.2425283965173968
Validation loss: 2.912324206529697

Epoch: 6| Step: 12
Training loss: 3.6141487028839334
Validation loss: 2.91570969335837

Epoch: 6| Step: 13
Training loss: 3.667372910079431
Validation loss: 2.9121071186927505

Epoch: 121| Step: 0
Training loss: 2.7447025253230355
Validation loss: 2.914240509809867

Epoch: 6| Step: 1
Training loss: 3.2030489284507215
Validation loss: 2.9149357970268572

Epoch: 6| Step: 2
Training loss: 3.7771850678843286
Validation loss: 2.9190786932818975

Epoch: 6| Step: 3
Training loss: 3.2648870921219006
Validation loss: 2.917690490008992

Epoch: 6| Step: 4
Training loss: 3.655024005064823
Validation loss: 2.918780551989494

Epoch: 6| Step: 5
Training loss: 3.3249261374623162
Validation loss: 2.9249183204450464

Epoch: 6| Step: 6
Training loss: 3.1353448160415334
Validation loss: 2.927678331767466

Epoch: 6| Step: 7
Training loss: 2.865850069116028
Validation loss: 2.923994100350686

Epoch: 6| Step: 8
Training loss: 3.5056325004934026
Validation loss: 2.926861909027803

Epoch: 6| Step: 9
Training loss: 2.502681629094857
Validation loss: 2.937623617677642

Epoch: 6| Step: 10
Training loss: 2.9828744681042583
Validation loss: 2.9339262195251194

Epoch: 6| Step: 11
Training loss: 3.4122491206357277
Validation loss: 2.915232976375716

Epoch: 6| Step: 12
Training loss: 2.978404999226348
Validation loss: 2.9119454989857587

Epoch: 6| Step: 13
Training loss: 3.319379608145352
Validation loss: 2.9116120242932806

Epoch: 122| Step: 0
Training loss: 3.1587783204753817
Validation loss: 2.9086474858043463

Epoch: 6| Step: 1
Training loss: 3.4987153011562575
Validation loss: 2.911565068788598

Epoch: 6| Step: 2
Training loss: 3.3257044913475897
Validation loss: 2.911680249018731

Epoch: 6| Step: 3
Training loss: 2.7463081026593987
Validation loss: 2.9104275528722847

Epoch: 6| Step: 4
Training loss: 2.6727912625642403
Validation loss: 2.9111419578629554

Epoch: 6| Step: 5
Training loss: 3.078710819789616
Validation loss: 2.9106770966271074

Epoch: 6| Step: 6
Training loss: 3.0307176260109223
Validation loss: 2.910221291774807

Epoch: 6| Step: 7
Training loss: 2.468195599463688
Validation loss: 2.911834541625749

Epoch: 6| Step: 8
Training loss: 3.0754609173465326
Validation loss: 2.9102384227651013

Epoch: 6| Step: 9
Training loss: 4.0690020833248
Validation loss: 2.9110128290175354

Epoch: 6| Step: 10
Training loss: 3.6865544804156567
Validation loss: 2.9095326141594047

Epoch: 6| Step: 11
Training loss: 3.3932275584234883
Validation loss: 2.913287442757012

Epoch: 6| Step: 12
Training loss: 2.9550366546887705
Validation loss: 2.907023238464398

Epoch: 6| Step: 13
Training loss: 3.4013188216576378
Validation loss: 2.9065658621747175

Epoch: 123| Step: 0
Training loss: 2.903668641598107
Validation loss: 2.9113252932126654

Epoch: 6| Step: 1
Training loss: 3.264669908366802
Validation loss: 2.909223143884153

Epoch: 6| Step: 2
Training loss: 2.9850312954333993
Validation loss: 2.910060253598534

Epoch: 6| Step: 3
Training loss: 3.429610197199724
Validation loss: 2.9075697047055127

Epoch: 6| Step: 4
Training loss: 3.7732039669582575
Validation loss: 2.90566281691689

Epoch: 6| Step: 5
Training loss: 3.3564822494876223
Validation loss: 2.9080919560896357

Epoch: 6| Step: 6
Training loss: 3.3646399116286303
Validation loss: 2.9101707817662366

Epoch: 6| Step: 7
Training loss: 3.6091385140499432
Validation loss: 2.9113386761626634

Epoch: 6| Step: 8
Training loss: 3.0156814490850916
Validation loss: 2.9111197016011894

Epoch: 6| Step: 9
Training loss: 2.8253643408593967
Validation loss: 2.90663191920872

Epoch: 6| Step: 10
Training loss: 3.357620845843944
Validation loss: 2.9048395746920597

Epoch: 6| Step: 11
Training loss: 3.052099199655236
Validation loss: 2.911272903804773

Epoch: 6| Step: 12
Training loss: 2.8381740693683093
Validation loss: 2.9086810443756703

Epoch: 6| Step: 13
Training loss: 2.4340968706449613
Validation loss: 2.910287015666162

Epoch: 124| Step: 0
Training loss: 2.691200901829209
Validation loss: 2.909034473927767

Epoch: 6| Step: 1
Training loss: 2.9107257464999843
Validation loss: 2.914130396399616

Epoch: 6| Step: 2
Training loss: 3.352564806329573
Validation loss: 2.907407449202188

Epoch: 6| Step: 3
Training loss: 3.550248612845683
Validation loss: 2.9050595803544

Epoch: 6| Step: 4
Training loss: 3.5728116627083857
Validation loss: 2.911935275907296

Epoch: 6| Step: 5
Training loss: 2.9941407842567633
Validation loss: 2.910881375536901

Epoch: 6| Step: 6
Training loss: 3.3627153689250573
Validation loss: 2.9075749967392914

Epoch: 6| Step: 7
Training loss: 3.3281367485304663
Validation loss: 2.9089109668042017

Epoch: 6| Step: 8
Training loss: 3.4101320595773594
Validation loss: 2.9070356447014816

Epoch: 6| Step: 9
Training loss: 3.207052660555814
Validation loss: 2.9041517915631796

Epoch: 6| Step: 10
Training loss: 3.305000741240033
Validation loss: 2.900927797769464

Epoch: 6| Step: 11
Training loss: 2.612319381529935
Validation loss: 2.900827185869702

Epoch: 6| Step: 12
Training loss: 3.2678518779155357
Validation loss: 2.899324665707021

Epoch: 6| Step: 13
Training loss: 2.7855643766541056
Validation loss: 2.8970563493617636

Epoch: 125| Step: 0
Training loss: 2.824296161440162
Validation loss: 2.8972166025369046

Epoch: 6| Step: 1
Training loss: 2.869810147003838
Validation loss: 2.897178956668209

Epoch: 6| Step: 2
Training loss: 3.8785028929803484
Validation loss: 2.895312907800625

Epoch: 6| Step: 3
Training loss: 3.4286852091120283
Validation loss: 2.8965392666898695

Epoch: 6| Step: 4
Training loss: 3.3752976745443752
Validation loss: 2.8971478102353143

Epoch: 6| Step: 5
Training loss: 2.678832693528013
Validation loss: 2.8979090124859423

Epoch: 6| Step: 6
Training loss: 3.3666674573034987
Validation loss: 2.897016816522439

Epoch: 6| Step: 7
Training loss: 3.0815579397834916
Validation loss: 2.896168569366953

Epoch: 6| Step: 8
Training loss: 2.9069086784555807
Validation loss: 2.902454988037797

Epoch: 6| Step: 9
Training loss: 3.492854590140593
Validation loss: 2.911540319956368

Epoch: 6| Step: 10
Training loss: 3.059606937270816
Validation loss: 2.9075341238604393

Epoch: 6| Step: 11
Training loss: 2.65129965455545
Validation loss: 2.9216806363439134

Epoch: 6| Step: 12
Training loss: 3.646705624815705
Validation loss: 2.9039052474992264

Epoch: 6| Step: 13
Training loss: 3.142797373537741
Validation loss: 2.8985943681179664

Testing loss: 3.098978035487528
