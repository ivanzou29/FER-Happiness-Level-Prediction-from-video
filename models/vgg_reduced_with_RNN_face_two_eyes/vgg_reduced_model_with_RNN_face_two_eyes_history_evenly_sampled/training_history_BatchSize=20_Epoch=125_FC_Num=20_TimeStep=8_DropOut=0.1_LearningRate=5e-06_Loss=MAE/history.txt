Epoch: 1| Step: 0
Training loss: 5.846511363983154
Validation loss: 5.2040499000139135

Epoch: 5| Step: 1
Training loss: 5.6349711418151855
Validation loss: 5.197924511407011

Epoch: 5| Step: 2
Training loss: 5.684276103973389
Validation loss: 5.1919513107627955

Epoch: 5| Step: 3
Training loss: 5.527177333831787
Validation loss: 5.186014170287757

Epoch: 5| Step: 4
Training loss: 4.805314064025879
Validation loss: 5.179689648330853

Epoch: 5| Step: 5
Training loss: 3.7140166759490967
Validation loss: 5.173071328029837

Epoch: 5| Step: 6
Training loss: 4.901392936706543
Validation loss: 5.166790757127988

Epoch: 5| Step: 7
Training loss: 4.827723503112793
Validation loss: 5.159898004224224

Epoch: 5| Step: 8
Training loss: 4.1964545249938965
Validation loss: 5.153038168466219

Epoch: 5| Step: 9
Training loss: 5.2592620849609375
Validation loss: 5.146004061545095

Epoch: 5| Step: 10
Training loss: 4.124118804931641
Validation loss: 5.139379188578616

Epoch: 2| Step: 0
Training loss: 4.348604679107666
Validation loss: 5.131595524408484

Epoch: 5| Step: 1
Training loss: 6.4888916015625
Validation loss: 5.124027162469844

Epoch: 5| Step: 2
Training loss: 4.641434669494629
Validation loss: 5.11615869563113

Epoch: 5| Step: 3
Training loss: 5.666924953460693
Validation loss: 5.107890441853513

Epoch: 5| Step: 4
Training loss: 4.5644450187683105
Validation loss: 5.099553533779678

Epoch: 5| Step: 5
Training loss: 5.107253074645996
Validation loss: 5.090448558971446

Epoch: 5| Step: 6
Training loss: 5.07586669921875
Validation loss: 5.0813093390516055

Epoch: 5| Step: 7
Training loss: 4.034224510192871
Validation loss: 5.071459011365008

Epoch: 5| Step: 8
Training loss: 4.7825927734375
Validation loss: 5.061242036922003

Epoch: 5| Step: 9
Training loss: 5.004220485687256
Validation loss: 5.050880062964655

Epoch: 5| Step: 10
Training loss: 3.859037160873413
Validation loss: 5.041508900221958

Epoch: 3| Step: 0
Training loss: 5.592610836029053
Validation loss: 5.028970451765163

Epoch: 5| Step: 1
Training loss: 5.816403865814209
Validation loss: 5.017446507689773

Epoch: 5| Step: 2
Training loss: 3.7505035400390625
Validation loss: 5.005224468887493

Epoch: 5| Step: 3
Training loss: 4.171339988708496
Validation loss: 4.992693388333884

Epoch: 5| Step: 4
Training loss: 3.8846945762634277
Validation loss: 4.979016416816301

Epoch: 5| Step: 5
Training loss: 4.222825527191162
Validation loss: 4.965841188225695

Epoch: 5| Step: 6
Training loss: 5.823261260986328
Validation loss: 4.950553058296122

Epoch: 5| Step: 7
Training loss: 5.786038875579834
Validation loss: 4.9361298776442

Epoch: 5| Step: 8
Training loss: 4.484023571014404
Validation loss: 4.919429379124796

Epoch: 5| Step: 9
Training loss: 5.077075004577637
Validation loss: 4.904492209034581

Epoch: 5| Step: 10
Training loss: 3.5046603679656982
Validation loss: 4.8861960903290775

Epoch: 4| Step: 0
Training loss: 6.287196636199951
Validation loss: 4.868431614291284

Epoch: 5| Step: 1
Training loss: 4.445642948150635
Validation loss: 4.849591321842645

Epoch: 5| Step: 2
Training loss: 4.1987996101379395
Validation loss: 4.829961171714208

Epoch: 5| Step: 3
Training loss: 3.3922977447509766
Validation loss: 4.808606373366489

Epoch: 5| Step: 4
Training loss: 5.633817195892334
Validation loss: 4.789094237871067

Epoch: 5| Step: 5
Training loss: 5.013330936431885
Validation loss: 4.766292705330797

Epoch: 5| Step: 6
Training loss: 4.593269348144531
Validation loss: 4.743234644653977

Epoch: 5| Step: 7
Training loss: 3.290728807449341
Validation loss: 4.717513674048967

Epoch: 5| Step: 8
Training loss: 4.118659019470215
Validation loss: 4.693805909925891

Epoch: 5| Step: 9
Training loss: 5.538242340087891
Validation loss: 4.668113206022529

Epoch: 5| Step: 10
Training loss: 3.3106751441955566
Validation loss: 4.6412615263333885

Epoch: 5| Step: 0
Training loss: 2.82878041267395
Validation loss: 4.614849757122737

Epoch: 5| Step: 1
Training loss: 4.679834842681885
Validation loss: 4.586254340346142

Epoch: 5| Step: 2
Training loss: 2.9486021995544434
Validation loss: 4.5618408367198

Epoch: 5| Step: 3
Training loss: 4.802029609680176
Validation loss: 4.532908829309607

Epoch: 5| Step: 4
Training loss: 5.327311038970947
Validation loss: 4.50422344925583

Epoch: 5| Step: 5
Training loss: 4.652918338775635
Validation loss: 4.4769653402349

Epoch: 5| Step: 6
Training loss: 3.7937893867492676
Validation loss: 4.4504675762627715

Epoch: 5| Step: 7
Training loss: 5.840522766113281
Validation loss: 4.423542209850845

Epoch: 5| Step: 8
Training loss: 4.34432315826416
Validation loss: 4.39661842776883

Epoch: 5| Step: 9
Training loss: 4.862120628356934
Validation loss: 4.370463735313826

Epoch: 5| Step: 10
Training loss: 2.5551233291625977
Validation loss: 4.346430250393447

Epoch: 6| Step: 0
Training loss: 3.6993186473846436
Validation loss: 4.321998293681811

Epoch: 5| Step: 1
Training loss: 5.402859687805176
Validation loss: 4.298079013824463

Epoch: 5| Step: 2
Training loss: 3.7261180877685547
Validation loss: 4.275353252246815

Epoch: 5| Step: 3
Training loss: 4.0319132804870605
Validation loss: 4.2543306632708475

Epoch: 5| Step: 4
Training loss: 3.530625581741333
Validation loss: 4.2340238735239994

Epoch: 5| Step: 5
Training loss: 4.470874309539795
Validation loss: 4.213831427276776

Epoch: 5| Step: 6
Training loss: 3.570030689239502
Validation loss: 4.19325735235727

Epoch: 5| Step: 7
Training loss: 3.647514820098877
Validation loss: 4.173312520468107

Epoch: 5| Step: 8
Training loss: 3.9682323932647705
Validation loss: 4.1550758602798625

Epoch: 5| Step: 9
Training loss: 3.9382781982421875
Validation loss: 4.136675129654587

Epoch: 5| Step: 10
Training loss: 4.356306076049805
Validation loss: 4.117740272193827

Epoch: 7| Step: 0
Training loss: 4.1619954109191895
Validation loss: 4.100330081037296

Epoch: 5| Step: 1
Training loss: 4.32794713973999
Validation loss: 4.081500966061828

Epoch: 5| Step: 2
Training loss: 4.518636703491211
Validation loss: 4.063576152247768

Epoch: 5| Step: 3
Training loss: 4.278988361358643
Validation loss: 4.042781983652422

Epoch: 5| Step: 4
Training loss: 3.0796990394592285
Validation loss: 4.024500503334948

Epoch: 5| Step: 5
Training loss: 3.2316009998321533
Validation loss: 4.004146752818938

Epoch: 5| Step: 6
Training loss: 3.9757702350616455
Validation loss: 3.9839731390758226

Epoch: 5| Step: 7
Training loss: 3.225724697113037
Validation loss: 3.966584138972785

Epoch: 5| Step: 8
Training loss: 3.5705058574676514
Validation loss: 3.951529792560044

Epoch: 5| Step: 9
Training loss: 4.6602582931518555
Validation loss: 3.935659957188432

Epoch: 5| Step: 10
Training loss: 3.240241765975952
Validation loss: 3.920783483853904

Epoch: 8| Step: 0
Training loss: 4.289101600646973
Validation loss: 3.9047019276567685

Epoch: 5| Step: 1
Training loss: 3.7278316020965576
Validation loss: 3.891515213956115

Epoch: 5| Step: 2
Training loss: 3.926434278488159
Validation loss: 3.8774895386029313

Epoch: 5| Step: 3
Training loss: 3.4286983013153076
Validation loss: 3.8648741681088685

Epoch: 5| Step: 4
Training loss: 4.236916542053223
Validation loss: 3.851948002333282

Epoch: 5| Step: 5
Training loss: 4.013653755187988
Validation loss: 3.836332769804103

Epoch: 5| Step: 6
Training loss: 4.069003105163574
Validation loss: 3.823908687919699

Epoch: 5| Step: 7
Training loss: 2.9609620571136475
Validation loss: 3.8104585216891382

Epoch: 5| Step: 8
Training loss: 3.0841317176818848
Validation loss: 3.7996177365702968

Epoch: 5| Step: 9
Training loss: 3.1622118949890137
Validation loss: 3.786310908614948

Epoch: 5| Step: 10
Training loss: 4.013935089111328
Validation loss: 3.7766751884132304

Epoch: 9| Step: 0
Training loss: 4.081518173217773
Validation loss: 3.765853989508844

Epoch: 5| Step: 1
Training loss: 4.040624141693115
Validation loss: 3.7574953084350913

Epoch: 5| Step: 2
Training loss: 3.3409924507141113
Validation loss: 3.7480927769855787

Epoch: 5| Step: 3
Training loss: 3.5343070030212402
Validation loss: 3.7394316683533373

Epoch: 5| Step: 4
Training loss: 3.8916664123535156
Validation loss: 3.732146486159294

Epoch: 5| Step: 5
Training loss: 3.8812758922576904
Validation loss: 3.7247839743091213

Epoch: 5| Step: 6
Training loss: 3.3249382972717285
Validation loss: 3.7171786010906263

Epoch: 5| Step: 7
Training loss: 3.3851680755615234
Validation loss: 3.7103861480630855

Epoch: 5| Step: 8
Training loss: 3.4460501670837402
Validation loss: 3.7044346691459737

Epoch: 5| Step: 9
Training loss: 3.769859790802002
Validation loss: 3.697792560823502

Epoch: 5| Step: 10
Training loss: 3.082284927368164
Validation loss: 3.690271746727728

Epoch: 10| Step: 0
Training loss: 3.7499213218688965
Validation loss: 3.6856123580727527

Epoch: 5| Step: 1
Training loss: 3.4558041095733643
Validation loss: 3.679981959763394

Epoch: 5| Step: 2
Training loss: 3.8432822227478027
Validation loss: 3.673400648178593

Epoch: 5| Step: 3
Training loss: 3.5562751293182373
Validation loss: 3.666171330277638

Epoch: 5| Step: 4
Training loss: 3.206841230392456
Validation loss: 3.660075451738091

Epoch: 5| Step: 5
Training loss: 3.6509792804718018
Validation loss: 3.6529076355759815

Epoch: 5| Step: 6
Training loss: 3.2197883129119873
Validation loss: 3.6463888383680776

Epoch: 5| Step: 7
Training loss: 3.827024459838867
Validation loss: 3.6417126347941737

Epoch: 5| Step: 8
Training loss: 3.8164639472961426
Validation loss: 3.634392738342285

Epoch: 5| Step: 9
Training loss: 3.368767261505127
Validation loss: 3.6284627811883086

Epoch: 5| Step: 10
Training loss: 3.52915096282959
Validation loss: 3.6229172675840315

Epoch: 11| Step: 0
Training loss: 3.714522123336792
Validation loss: 3.6184322603287233

Epoch: 5| Step: 1
Training loss: 3.228221893310547
Validation loss: 3.6104943931743665

Epoch: 5| Step: 2
Training loss: 4.049696922302246
Validation loss: 3.604925540185744

Epoch: 5| Step: 3
Training loss: 3.9941399097442627
Validation loss: 3.5996320196377334

Epoch: 5| Step: 4
Training loss: 3.2943615913391113
Validation loss: 3.5934601112078597

Epoch: 5| Step: 5
Training loss: 2.9608330726623535
Validation loss: 3.5879393341720744

Epoch: 5| Step: 6
Training loss: 3.3244946002960205
Validation loss: 3.58138943231234

Epoch: 5| Step: 7
Training loss: 3.537268877029419
Validation loss: 3.5764582618590324

Epoch: 5| Step: 8
Training loss: 3.1718404293060303
Validation loss: 3.5709811897688013

Epoch: 5| Step: 9
Training loss: 3.6204867362976074
Validation loss: 3.5652734797487975

Epoch: 5| Step: 10
Training loss: 3.741185426712036
Validation loss: 3.558802153474541

Epoch: 12| Step: 0
Training loss: 3.6516082286834717
Validation loss: 3.5515262490959576

Epoch: 5| Step: 1
Training loss: 4.118285179138184
Validation loss: 3.545018747288694

Epoch: 5| Step: 2
Training loss: 2.6351962089538574
Validation loss: 3.5377439170755367

Epoch: 5| Step: 3
Training loss: 4.061115264892578
Validation loss: 3.529185328432309

Epoch: 5| Step: 4
Training loss: 2.7127418518066406
Validation loss: 3.5223283742063787

Epoch: 5| Step: 5
Training loss: 3.17060923576355
Validation loss: 3.512898393856582

Epoch: 5| Step: 6
Training loss: 3.977961778640747
Validation loss: 3.502497460252495

Epoch: 5| Step: 7
Training loss: 2.086111545562744
Validation loss: 3.4916552728222263

Epoch: 5| Step: 8
Training loss: 3.9402732849121094
Validation loss: 3.4803982806462113

Epoch: 5| Step: 9
Training loss: 4.592049598693848
Validation loss: 3.470070198018064

Epoch: 5| Step: 10
Training loss: 2.7957725524902344
Validation loss: 3.4618192872693463

Epoch: 13| Step: 0
Training loss: 3.366812229156494
Validation loss: 3.4535158885422574

Epoch: 5| Step: 1
Training loss: 2.911698579788208
Validation loss: 3.4416070138254473

Epoch: 5| Step: 2
Training loss: 3.6141796112060547
Validation loss: 3.4335883740455873

Epoch: 5| Step: 3
Training loss: 3.861581325531006
Validation loss: 3.426461181332988

Epoch: 5| Step: 4
Training loss: 4.122527122497559
Validation loss: 3.418759358826504

Epoch: 5| Step: 5
Training loss: 3.4126663208007812
Validation loss: 3.40851685308641

Epoch: 5| Step: 6
Training loss: 2.706178903579712
Validation loss: 3.3974963900863484

Epoch: 5| Step: 7
Training loss: 3.1530368328094482
Validation loss: 3.390759568060598

Epoch: 5| Step: 8
Training loss: 3.1890969276428223
Validation loss: 3.3804309598861204

Epoch: 5| Step: 9
Training loss: 2.8429269790649414
Validation loss: 3.3721101873664447

Epoch: 5| Step: 10
Training loss: 3.7628982067108154
Validation loss: 3.3641950904682116

Epoch: 14| Step: 0
Training loss: 3.6792213916778564
Validation loss: 3.3567770732346403

Epoch: 5| Step: 1
Training loss: 2.9229865074157715
Validation loss: 3.3487879486494165

Epoch: 5| Step: 2
Training loss: 3.1279895305633545
Validation loss: 3.3413796322320097

Epoch: 5| Step: 3
Training loss: 3.85832142829895
Validation loss: 3.334304560897171

Epoch: 5| Step: 4
Training loss: 3.4048874378204346
Validation loss: 3.3274206986991306

Epoch: 5| Step: 5
Training loss: 2.539412260055542
Validation loss: 3.3187819193768244

Epoch: 5| Step: 6
Training loss: 3.3490729331970215
Validation loss: 3.3106631386664604

Epoch: 5| Step: 7
Training loss: 3.2179388999938965
Validation loss: 3.3026416378636516

Epoch: 5| Step: 8
Training loss: 3.3848278522491455
Validation loss: 3.2932936017231276

Epoch: 5| Step: 9
Training loss: 3.1403419971466064
Validation loss: 3.2896575697006716

Epoch: 5| Step: 10
Training loss: 3.5442094802856445
Validation loss: 3.2778907924570064

Epoch: 15| Step: 0
Training loss: 2.9849746227264404
Validation loss: 3.273368925176641

Epoch: 5| Step: 1
Training loss: 3.0940160751342773
Validation loss: 3.2691802824697187

Epoch: 5| Step: 2
Training loss: 3.2843785285949707
Validation loss: 3.2598275625577537

Epoch: 5| Step: 3
Training loss: 4.292362213134766
Validation loss: 3.254314507207563

Epoch: 5| Step: 4
Training loss: 2.934846878051758
Validation loss: 3.246607939402262

Epoch: 5| Step: 5
Training loss: 3.170659303665161
Validation loss: 3.242303930303102

Epoch: 5| Step: 6
Training loss: 2.840080738067627
Validation loss: 3.237675984700521

Epoch: 5| Step: 7
Training loss: 2.384162187576294
Validation loss: 3.22864858822156

Epoch: 5| Step: 8
Training loss: 3.635908842086792
Validation loss: 3.224723449317358

Epoch: 5| Step: 9
Training loss: 3.7568745613098145
Validation loss: 3.2202935064992597

Epoch: 5| Step: 10
Training loss: 3.0935070514678955
Validation loss: 3.2145348569398284

Epoch: 16| Step: 0
Training loss: 3.3211493492126465
Validation loss: 3.2079335310125865

Epoch: 5| Step: 1
Training loss: 2.1517698764801025
Validation loss: 3.2036206542804675

Epoch: 5| Step: 2
Training loss: 4.46335506439209
Validation loss: 3.1981849388409684

Epoch: 5| Step: 3
Training loss: 3.106290340423584
Validation loss: 3.1919383028502106

Epoch: 5| Step: 4
Training loss: 2.7845160961151123
Validation loss: 3.185098942889962

Epoch: 5| Step: 5
Training loss: 3.7577290534973145
Validation loss: 3.1814969124332553

Epoch: 5| Step: 6
Training loss: 2.5732522010803223
Validation loss: 3.177660006348805

Epoch: 5| Step: 7
Training loss: 3.073061466217041
Validation loss: 3.1716225916339504

Epoch: 5| Step: 8
Training loss: 3.0844948291778564
Validation loss: 3.1651786194052747

Epoch: 5| Step: 9
Training loss: 3.9008872509002686
Validation loss: 3.164899787595195

Epoch: 5| Step: 10
Training loss: 2.769486665725708
Validation loss: 3.1607387552979174

Epoch: 17| Step: 0
Training loss: 3.2741050720214844
Validation loss: 3.1556703685432352

Epoch: 5| Step: 1
Training loss: 3.247499465942383
Validation loss: 3.1519195033657934

Epoch: 5| Step: 2
Training loss: 2.95744252204895
Validation loss: 3.148393113126037

Epoch: 5| Step: 3
Training loss: 3.329831600189209
Validation loss: 3.144332931887719

Epoch: 5| Step: 4
Training loss: 3.7907943725585938
Validation loss: 3.142974381805748

Epoch: 5| Step: 5
Training loss: 3.351834774017334
Validation loss: 3.138183678350141

Epoch: 5| Step: 6
Training loss: 3.699434757232666
Validation loss: 3.1308302648605837

Epoch: 5| Step: 7
Training loss: 3.2638041973114014
Validation loss: 3.1263216490386636

Epoch: 5| Step: 8
Training loss: 2.0494019985198975
Validation loss: 3.1236514122255388

Epoch: 5| Step: 9
Training loss: 3.1421897411346436
Validation loss: 3.1234246659022507

Epoch: 5| Step: 10
Training loss: 2.451784372329712
Validation loss: 3.1196822479207027

Epoch: 18| Step: 0
Training loss: 3.7335784435272217
Validation loss: 3.1195937100277153

Epoch: 5| Step: 1
Training loss: 3.271005630493164
Validation loss: 3.1106523672739663

Epoch: 5| Step: 2
Training loss: 3.6112608909606934
Validation loss: 3.1074155838258806

Epoch: 5| Step: 3
Training loss: 2.1670541763305664
Validation loss: 3.103480298032043

Epoch: 5| Step: 4
Training loss: 2.2542972564697266
Validation loss: 3.10014788053369

Epoch: 5| Step: 5
Training loss: 3.896406650543213
Validation loss: 3.10027208892248

Epoch: 5| Step: 6
Training loss: 2.3030014038085938
Validation loss: 3.0980639047520135

Epoch: 5| Step: 7
Training loss: 3.096609115600586
Validation loss: 3.0968315908985753

Epoch: 5| Step: 8
Training loss: 2.896044969558716
Validation loss: 3.0913432592986734

Epoch: 5| Step: 9
Training loss: 4.066186428070068
Validation loss: 3.086413014319635

Epoch: 5| Step: 10
Training loss: 3.104616641998291
Validation loss: 3.0861414196670696

Epoch: 19| Step: 0
Training loss: 3.871809482574463
Validation loss: 3.0830327977416334

Epoch: 5| Step: 1
Training loss: 3.756549835205078
Validation loss: 3.0778845561447965

Epoch: 5| Step: 2
Training loss: 2.031022548675537
Validation loss: 3.076303010345787

Epoch: 5| Step: 3
Training loss: 3.3296656608581543
Validation loss: 3.0725250808141564

Epoch: 5| Step: 4
Training loss: 2.792224407196045
Validation loss: 3.072559582289829

Epoch: 5| Step: 5
Training loss: 3.4454925060272217
Validation loss: 3.06878258592339

Epoch: 5| Step: 6
Training loss: 1.9549767971038818
Validation loss: 3.066520106407904

Epoch: 5| Step: 7
Training loss: 3.0759963989257812
Validation loss: 3.0649016518746652

Epoch: 5| Step: 8
Training loss: 3.159261703491211
Validation loss: 3.063337310667961

Epoch: 5| Step: 9
Training loss: 3.438098907470703
Validation loss: 3.0559359750440045

Epoch: 5| Step: 10
Training loss: 3.377800226211548
Validation loss: 3.054982451982396

Epoch: 20| Step: 0
Training loss: 3.466362476348877
Validation loss: 3.0513066578936834

Epoch: 5| Step: 1
Training loss: 3.5625271797180176
Validation loss: 3.052368099971484

Epoch: 5| Step: 2
Training loss: 3.026459217071533
Validation loss: 3.049356224716351

Epoch: 5| Step: 3
Training loss: 3.537970781326294
Validation loss: 3.0475045070853284

Epoch: 5| Step: 4
Training loss: 2.431351900100708
Validation loss: 3.0481537465126283

Epoch: 5| Step: 5
Training loss: 3.2900474071502686
Validation loss: 3.0434066839115594

Epoch: 5| Step: 6
Training loss: 2.7727386951446533
Validation loss: 3.0407230290033485

Epoch: 5| Step: 7
Training loss: 3.2158095836639404
Validation loss: 3.035791274039976

Epoch: 5| Step: 8
Training loss: 2.7956254482269287
Validation loss: 3.0344924132029214

Epoch: 5| Step: 9
Training loss: 3.0574543476104736
Validation loss: 3.0332185017165316

Epoch: 5| Step: 10
Training loss: 2.79815411567688
Validation loss: 3.030983796683691

Epoch: 21| Step: 0
Training loss: 2.812894344329834
Validation loss: 3.025312569833571

Epoch: 5| Step: 1
Training loss: 3.5164217948913574
Validation loss: 3.0192708789661364

Epoch: 5| Step: 2
Training loss: 2.8594887256622314
Validation loss: 3.0193515823733423

Epoch: 5| Step: 3
Training loss: 3.2812447547912598
Validation loss: 3.0178039202126126

Epoch: 5| Step: 4
Training loss: 2.4299495220184326
Validation loss: 3.0140502657941592

Epoch: 5| Step: 5
Training loss: 2.684936046600342
Validation loss: 3.0131634281527613

Epoch: 5| Step: 6
Training loss: 2.8677191734313965
Validation loss: 3.010728964241602

Epoch: 5| Step: 7
Training loss: 2.3633270263671875
Validation loss: 3.007754969340499

Epoch: 5| Step: 8
Training loss: 4.1407270431518555
Validation loss: 3.0035278310057936

Epoch: 5| Step: 9
Training loss: 3.7026901245117188
Validation loss: 3.0004041092370146

Epoch: 5| Step: 10
Training loss: 3.1410470008850098
Validation loss: 2.9971741502003004

Epoch: 22| Step: 0
Training loss: 3.5980193614959717
Validation loss: 2.9928249697531424

Epoch: 5| Step: 1
Training loss: 2.949706792831421
Validation loss: 2.9941800768657396

Epoch: 5| Step: 2
Training loss: 3.0098540782928467
Validation loss: 2.992118899540235

Epoch: 5| Step: 3
Training loss: 3.617539167404175
Validation loss: 2.9887958316392798

Epoch: 5| Step: 4
Training loss: 3.2989983558654785
Validation loss: 2.9883833546792307

Epoch: 5| Step: 5
Training loss: 2.3806116580963135
Validation loss: 2.9820341217902397

Epoch: 5| Step: 6
Training loss: 3.2292637825012207
Validation loss: 2.982869568691459

Epoch: 5| Step: 7
Training loss: 2.9624247550964355
Validation loss: 2.9759972838945288

Epoch: 5| Step: 8
Training loss: 3.795893907546997
Validation loss: 2.974577211564587

Epoch: 5| Step: 9
Training loss: 1.8706868886947632
Validation loss: 2.974903127198578

Epoch: 5| Step: 10
Training loss: 2.864713668823242
Validation loss: 2.9704046557026524

Epoch: 23| Step: 0
Training loss: 3.4930248260498047
Validation loss: 2.9730287598025416

Epoch: 5| Step: 1
Training loss: 3.282890796661377
Validation loss: 2.9718528947522564

Epoch: 5| Step: 2
Training loss: 2.7544608116149902
Validation loss: 2.9631270490666872

Epoch: 5| Step: 3
Training loss: 3.0650265216827393
Validation loss: 2.965061003162015

Epoch: 5| Step: 4
Training loss: 3.023679494857788
Validation loss: 2.9619545628947597

Epoch: 5| Step: 5
Training loss: 3.086115837097168
Validation loss: 2.9632407106379026

Epoch: 5| Step: 6
Training loss: 3.0137012004852295
Validation loss: 2.9593262057150564

Epoch: 5| Step: 7
Training loss: 3.1429214477539062
Validation loss: 2.963241777112407

Epoch: 5| Step: 8
Training loss: 2.6850879192352295
Validation loss: 2.954314262636246

Epoch: 5| Step: 9
Training loss: 2.9674553871154785
Validation loss: 2.948997594976938

Epoch: 5| Step: 10
Training loss: 2.9157280921936035
Validation loss: 2.9495210442491757

Epoch: 24| Step: 0
Training loss: 2.872453212738037
Validation loss: 2.9493221723905174

Epoch: 5| Step: 1
Training loss: 3.510941982269287
Validation loss: 2.9489421690663984

Epoch: 5| Step: 2
Training loss: 2.8723340034484863
Validation loss: 2.946202270446285

Epoch: 5| Step: 3
Training loss: 2.786296844482422
Validation loss: 2.944397787893972

Epoch: 5| Step: 4
Training loss: 2.8876469135284424
Validation loss: 2.9399608617187827

Epoch: 5| Step: 5
Training loss: 2.7938475608825684
Validation loss: 2.9384105102990263

Epoch: 5| Step: 6
Training loss: 3.1542446613311768
Validation loss: 2.9379376442201677

Epoch: 5| Step: 7
Training loss: 2.8315041065216064
Validation loss: 2.939545618590488

Epoch: 5| Step: 8
Training loss: 2.4662086963653564
Validation loss: 2.938700152981666

Epoch: 5| Step: 9
Training loss: 3.141035556793213
Validation loss: 2.9374515984648015

Epoch: 5| Step: 10
Training loss: 4.120342254638672
Validation loss: 2.935922663698914

Epoch: 25| Step: 0
Training loss: 3.0250492095947266
Validation loss: 2.9336156409273864

Epoch: 5| Step: 1
Training loss: 3.1829288005828857
Validation loss: 2.9295371322221655

Epoch: 5| Step: 2
Training loss: 3.0379257202148438
Validation loss: 2.924287273037818

Epoch: 5| Step: 3
Training loss: 3.356738567352295
Validation loss: 2.9242123890948553

Epoch: 5| Step: 4
Training loss: 2.959378719329834
Validation loss: 2.922105368747506

Epoch: 5| Step: 5
Training loss: 2.759016513824463
Validation loss: 2.922451462796939

Epoch: 5| Step: 6
Training loss: 2.710420608520508
Validation loss: 2.920229293966806

Epoch: 5| Step: 7
Training loss: 3.2929482460021973
Validation loss: 2.918832330293553

Epoch: 5| Step: 8
Training loss: 3.2500908374786377
Validation loss: 2.9151707644103677

Epoch: 5| Step: 9
Training loss: 2.487705945968628
Validation loss: 2.9142071021500455

Epoch: 5| Step: 10
Training loss: 3.0388834476470947
Validation loss: 2.9151911838080293

Epoch: 26| Step: 0
Training loss: 3.6682324409484863
Validation loss: 2.910187518724831

Epoch: 5| Step: 1
Training loss: 2.9483304023742676
Validation loss: 2.910932861348634

Epoch: 5| Step: 2
Training loss: 2.642228841781616
Validation loss: 2.907558220689015

Epoch: 5| Step: 3
Training loss: 3.503711223602295
Validation loss: 2.9064377918038318

Epoch: 5| Step: 4
Training loss: 1.8679039478302002
Validation loss: 2.907529943732805

Epoch: 5| Step: 5
Training loss: 3.606351375579834
Validation loss: 2.9017108486544703

Epoch: 5| Step: 6
Training loss: 2.345951557159424
Validation loss: 2.9034580748568297

Epoch: 5| Step: 7
Training loss: 3.704212188720703
Validation loss: 2.9035430877439437

Epoch: 5| Step: 8
Training loss: 3.0051052570343018
Validation loss: 2.8985152116385837

Epoch: 5| Step: 9
Training loss: 2.8251121044158936
Validation loss: 2.895608550758772

Epoch: 5| Step: 10
Training loss: 2.8683221340179443
Validation loss: 2.9003878972863637

Epoch: 27| Step: 0
Training loss: 3.371323347091675
Validation loss: 2.895713916388891

Epoch: 5| Step: 1
Training loss: 3.777703046798706
Validation loss: 2.893617727423227

Epoch: 5| Step: 2
Training loss: 2.483203172683716
Validation loss: 2.8963746998899724

Epoch: 5| Step: 3
Training loss: 4.1550750732421875
Validation loss: 2.893982959050004

Epoch: 5| Step: 4
Training loss: 2.8073534965515137
Validation loss: 2.8918767077948457

Epoch: 5| Step: 5
Training loss: 2.5884931087493896
Validation loss: 2.8903398436884724

Epoch: 5| Step: 6
Training loss: 2.7524056434631348
Validation loss: 2.8882293265352965

Epoch: 5| Step: 7
Training loss: 2.7787082195281982
Validation loss: 2.8869079082242903

Epoch: 5| Step: 8
Training loss: 2.719331741333008
Validation loss: 2.8864351011091665

Epoch: 5| Step: 9
Training loss: 2.462038040161133
Validation loss: 2.887311489351334

Epoch: 5| Step: 10
Training loss: 2.995129108428955
Validation loss: 2.8867378132317656

Epoch: 28| Step: 0
Training loss: 3.360405445098877
Validation loss: 2.8893043559084655

Epoch: 5| Step: 1
Training loss: 2.7795357704162598
Validation loss: 2.880345703453146

Epoch: 5| Step: 2
Training loss: 3.2597012519836426
Validation loss: 2.881993773163006

Epoch: 5| Step: 3
Training loss: 2.37748384475708
Validation loss: 2.882162747844573

Epoch: 5| Step: 4
Training loss: 2.564690113067627
Validation loss: 2.888677215063444

Epoch: 5| Step: 5
Training loss: 2.568272352218628
Validation loss: 2.88315902474106

Epoch: 5| Step: 6
Training loss: 2.8762526512145996
Validation loss: 2.8898750735867407

Epoch: 5| Step: 7
Training loss: 3.6735386848449707
Validation loss: 2.8816239192921627

Epoch: 5| Step: 8
Training loss: 3.097163438796997
Validation loss: 2.8795936210181123

Epoch: 5| Step: 9
Training loss: 2.948861837387085
Validation loss: 2.8743993082354145

Epoch: 5| Step: 10
Training loss: 3.4029455184936523
Validation loss: 2.8755880401980494

Epoch: 29| Step: 0
Training loss: 3.3978404998779297
Validation loss: 2.8773646764857794

Epoch: 5| Step: 1
Training loss: 3.231128215789795
Validation loss: 2.876971931867702

Epoch: 5| Step: 2
Training loss: 3.673358917236328
Validation loss: 2.873007066788212

Epoch: 5| Step: 3
Training loss: 2.7800042629241943
Validation loss: 2.869799083279025

Epoch: 5| Step: 4
Training loss: 2.42265248298645
Validation loss: 2.866286869971983

Epoch: 5| Step: 5
Training loss: 2.882114887237549
Validation loss: 2.8643762783337663

Epoch: 5| Step: 6
Training loss: 3.133817672729492
Validation loss: 2.864938930798602

Epoch: 5| Step: 7
Training loss: 3.1536753177642822
Validation loss: 2.8729241817228255

Epoch: 5| Step: 8
Training loss: 2.2025246620178223
Validation loss: 2.868160888712893

Epoch: 5| Step: 9
Training loss: 2.4049365520477295
Validation loss: 2.865147759837489

Epoch: 5| Step: 10
Training loss: 3.5449020862579346
Validation loss: 2.86716281214068

Epoch: 30| Step: 0
Training loss: 3.279006242752075
Validation loss: 2.863889771123086

Epoch: 5| Step: 1
Training loss: 2.7957606315612793
Validation loss: 2.8608631190433296

Epoch: 5| Step: 2
Training loss: 2.6597416400909424
Validation loss: 2.8596595923105874

Epoch: 5| Step: 3
Training loss: 2.6706318855285645
Validation loss: 2.8607369007602816

Epoch: 5| Step: 4
Training loss: 2.700439929962158
Validation loss: 2.865483107105378

Epoch: 5| Step: 5
Training loss: 3.5712947845458984
Validation loss: 2.8686161271987425

Epoch: 5| Step: 6
Training loss: 2.858628034591675
Validation loss: 2.8612264330669115

Epoch: 5| Step: 7
Training loss: 3.1868088245391846
Validation loss: 2.855199116532521

Epoch: 5| Step: 8
Training loss: 2.8128623962402344
Validation loss: 2.854365848725842

Epoch: 5| Step: 9
Training loss: 3.6299004554748535
Validation loss: 2.8553922432725147

Epoch: 5| Step: 10
Training loss: 2.4399826526641846
Validation loss: 2.856338336903562

Epoch: 31| Step: 0
Training loss: 2.957923173904419
Validation loss: 2.854461410994171

Epoch: 5| Step: 1
Training loss: 2.553860902786255
Validation loss: 2.8518371889668126

Epoch: 5| Step: 2
Training loss: 2.8745694160461426
Validation loss: 2.8523036997805358

Epoch: 5| Step: 3
Training loss: 2.769381046295166
Validation loss: 2.85113021122512

Epoch: 5| Step: 4
Training loss: 2.164687395095825
Validation loss: 2.8509842862365065

Epoch: 5| Step: 5
Training loss: 3.0285286903381348
Validation loss: 2.8521002287505777

Epoch: 5| Step: 6
Training loss: 2.8867504596710205
Validation loss: 2.8494447354347474

Epoch: 5| Step: 7
Training loss: 3.0443625450134277
Validation loss: 2.8484096347644763

Epoch: 5| Step: 8
Training loss: 3.015341281890869
Validation loss: 2.8476592289504183

Epoch: 5| Step: 9
Training loss: 3.5721771717071533
Validation loss: 2.8452653474705194

Epoch: 5| Step: 10
Training loss: 3.8951025009155273
Validation loss: 2.8463200471734487

Epoch: 32| Step: 0
Training loss: 3.3505825996398926
Validation loss: 2.845168939200781

Epoch: 5| Step: 1
Training loss: 2.9925520420074463
Validation loss: 2.844057383075837

Epoch: 5| Step: 2
Training loss: 2.4468283653259277
Validation loss: 2.844519966392107

Epoch: 5| Step: 3
Training loss: 3.0761780738830566
Validation loss: 2.8432693686536563

Epoch: 5| Step: 4
Training loss: 2.571524143218994
Validation loss: 2.841634160728865

Epoch: 5| Step: 5
Training loss: 2.8028202056884766
Validation loss: 2.842844291399884

Epoch: 5| Step: 6
Training loss: 2.83715558052063
Validation loss: 2.8432557429036787

Epoch: 5| Step: 7
Training loss: 3.1641182899475098
Validation loss: 2.8411111934210664

Epoch: 5| Step: 8
Training loss: 3.292243242263794
Validation loss: 2.842613873943206

Epoch: 5| Step: 9
Training loss: 2.9582083225250244
Validation loss: 2.840165476645193

Epoch: 5| Step: 10
Training loss: 3.0746748447418213
Validation loss: 2.8356836636861167

Epoch: 33| Step: 0
Training loss: 2.280003309249878
Validation loss: 2.8367534042686544

Epoch: 5| Step: 1
Training loss: 3.0123398303985596
Validation loss: 2.837861112369004

Epoch: 5| Step: 2
Training loss: 3.2925772666931152
Validation loss: 2.836317898124777

Epoch: 5| Step: 3
Training loss: 2.677405834197998
Validation loss: 2.8341889227590253

Epoch: 5| Step: 4
Training loss: 2.690621852874756
Validation loss: 2.8350551589842765

Epoch: 5| Step: 5
Training loss: 2.8020029067993164
Validation loss: 2.831301643002418

Epoch: 5| Step: 6
Training loss: 2.986384391784668
Validation loss: 2.8313643829796904

Epoch: 5| Step: 7
Training loss: 2.833162784576416
Validation loss: 2.8307227678196405

Epoch: 5| Step: 8
Training loss: 3.9528098106384277
Validation loss: 2.8314983972939114

Epoch: 5| Step: 9
Training loss: 2.657688617706299
Validation loss: 2.829171944690007

Epoch: 5| Step: 10
Training loss: 3.348173141479492
Validation loss: 2.830539277804795

Epoch: 34| Step: 0
Training loss: 2.9437077045440674
Validation loss: 2.828334980113532

Epoch: 5| Step: 1
Training loss: 3.295581817626953
Validation loss: 2.8277904987335205

Epoch: 5| Step: 2
Training loss: 2.704636335372925
Validation loss: 2.8254202335111556

Epoch: 5| Step: 3
Training loss: 3.547741651535034
Validation loss: 2.8271716948478454

Epoch: 5| Step: 4
Training loss: 3.1325020790100098
Validation loss: 2.8291292139278945

Epoch: 5| Step: 5
Training loss: 2.538141965866089
Validation loss: 2.8230494427424606

Epoch: 5| Step: 6
Training loss: 2.866689682006836
Validation loss: 2.821993927801809

Epoch: 5| Step: 7
Training loss: 2.2798304557800293
Validation loss: 2.822844023345619

Epoch: 5| Step: 8
Training loss: 2.6420810222625732
Validation loss: 2.8251776105614117

Epoch: 5| Step: 9
Training loss: 2.8135759830474854
Validation loss: 2.8262273368015083

Epoch: 5| Step: 10
Training loss: 3.8184702396392822
Validation loss: 2.831777580322758

Epoch: 35| Step: 0
Training loss: 2.9216670989990234
Validation loss: 2.8252786385115756

Epoch: 5| Step: 1
Training loss: 3.1028048992156982
Validation loss: 2.8248446192792667

Epoch: 5| Step: 2
Training loss: 2.5053763389587402
Validation loss: 2.8223415805447485

Epoch: 5| Step: 3
Training loss: 2.697740316390991
Validation loss: 2.817645572846936

Epoch: 5| Step: 4
Training loss: 3.0233023166656494
Validation loss: 2.8176090281496764

Epoch: 5| Step: 5
Training loss: 2.8543384075164795
Validation loss: 2.816990206318517

Epoch: 5| Step: 6
Training loss: 2.87895131111145
Validation loss: 2.815957587252381

Epoch: 5| Step: 7
Training loss: 3.1943469047546387
Validation loss: 2.8166260104025564

Epoch: 5| Step: 8
Training loss: 3.076209545135498
Validation loss: 2.817382061353294

Epoch: 5| Step: 9
Training loss: 3.469221830368042
Validation loss: 2.8165611759308846

Epoch: 5| Step: 10
Training loss: 2.620342493057251
Validation loss: 2.8169369800116426

Epoch: 36| Step: 0
Training loss: 2.905388355255127
Validation loss: 2.8193451819881314

Epoch: 5| Step: 1
Training loss: 3.0853710174560547
Validation loss: 2.818830326039304

Epoch: 5| Step: 2
Training loss: 2.8367271423339844
Validation loss: 2.8151709341233775

Epoch: 5| Step: 3
Training loss: 2.7786033153533936
Validation loss: 2.8137965663786857

Epoch: 5| Step: 4
Training loss: 2.7757935523986816
Validation loss: 2.811081617109237

Epoch: 5| Step: 5
Training loss: 2.4272055625915527
Validation loss: 2.817856886053598

Epoch: 5| Step: 6
Training loss: 2.7539401054382324
Validation loss: 2.8243243155940885

Epoch: 5| Step: 7
Training loss: 3.229384183883667
Validation loss: 2.8203136997838176

Epoch: 5| Step: 8
Training loss: 3.168383836746216
Validation loss: 2.810034280182213

Epoch: 5| Step: 9
Training loss: 2.923798084259033
Validation loss: 2.81171908942602

Epoch: 5| Step: 10
Training loss: 3.5931222438812256
Validation loss: 2.813214082871714

Epoch: 37| Step: 0
Training loss: 3.039728879928589
Validation loss: 2.8118772224713395

Epoch: 5| Step: 1
Training loss: 2.3269553184509277
Validation loss: 2.812696264636132

Epoch: 5| Step: 2
Training loss: 3.2160086631774902
Validation loss: 2.8132763114026798

Epoch: 5| Step: 3
Training loss: 3.767803907394409
Validation loss: 2.8124629579564577

Epoch: 5| Step: 4
Training loss: 3.026445150375366
Validation loss: 2.8105026137444282

Epoch: 5| Step: 5
Training loss: 2.697866201400757
Validation loss: 2.8055900527584936

Epoch: 5| Step: 6
Training loss: 2.3996100425720215
Validation loss: 2.8073363868139123

Epoch: 5| Step: 7
Training loss: 2.9468116760253906
Validation loss: 2.804243205696024

Epoch: 5| Step: 8
Training loss: 2.867884397506714
Validation loss: 2.806366487215924

Epoch: 5| Step: 9
Training loss: 3.110034465789795
Validation loss: 2.8048104675867225

Epoch: 5| Step: 10
Training loss: 2.9280264377593994
Validation loss: 2.804493755422613

Epoch: 38| Step: 0
Training loss: 3.053460121154785
Validation loss: 2.8019503393480854

Epoch: 5| Step: 1
Training loss: 2.192580461502075
Validation loss: 2.8021747860857236

Epoch: 5| Step: 2
Training loss: 3.3116042613983154
Validation loss: 2.803943713506063

Epoch: 5| Step: 3
Training loss: 2.8011574745178223
Validation loss: 2.80407630243609

Epoch: 5| Step: 4
Training loss: 3.212477922439575
Validation loss: 2.8113567342040358

Epoch: 5| Step: 5
Training loss: 2.067436695098877
Validation loss: 2.8042772098254134

Epoch: 5| Step: 6
Training loss: 3.209540843963623
Validation loss: 2.8057570688186155

Epoch: 5| Step: 7
Training loss: 2.8673486709594727
Validation loss: 2.803279281944357

Epoch: 5| Step: 8
Training loss: 3.328434467315674
Validation loss: 2.803807138114847

Epoch: 5| Step: 9
Training loss: 3.300661563873291
Validation loss: 2.805234432220459

Epoch: 5| Step: 10
Training loss: 2.940671920776367
Validation loss: 2.803388918599775

Epoch: 39| Step: 0
Training loss: 2.9257357120513916
Validation loss: 2.796277120549192

Epoch: 5| Step: 1
Training loss: 3.3294384479522705
Validation loss: 2.7960817454963602

Epoch: 5| Step: 2
Training loss: 3.708885908126831
Validation loss: 2.7938382112851707

Epoch: 5| Step: 3
Training loss: 2.657125949859619
Validation loss: 2.7950306605267268

Epoch: 5| Step: 4
Training loss: 3.166459560394287
Validation loss: 2.7947792058349936

Epoch: 5| Step: 5
Training loss: 3.1483235359191895
Validation loss: 2.79365954091472

Epoch: 5| Step: 6
Training loss: 3.2576255798339844
Validation loss: 2.792709894077752

Epoch: 5| Step: 7
Training loss: 2.2998878955841064
Validation loss: 2.7957671919176654

Epoch: 5| Step: 8
Training loss: 3.301386594772339
Validation loss: 2.792779476411881

Epoch: 5| Step: 9
Training loss: 1.8097883462905884
Validation loss: 2.7940161099997898

Epoch: 5| Step: 10
Training loss: 2.5520780086517334
Validation loss: 2.7926619898888374

Epoch: 40| Step: 0
Training loss: 3.091240644454956
Validation loss: 2.7903664547909974

Epoch: 5| Step: 1
Training loss: 2.7311935424804688
Validation loss: 2.797638331690142

Epoch: 5| Step: 2
Training loss: 2.600497007369995
Validation loss: 2.7937137285868325

Epoch: 5| Step: 3
Training loss: 2.466716766357422
Validation loss: 2.8001998880858063

Epoch: 5| Step: 4
Training loss: 2.5499048233032227
Validation loss: 2.797388917656355

Epoch: 5| Step: 5
Training loss: 3.548516035079956
Validation loss: 2.8017238775889077

Epoch: 5| Step: 6
Training loss: 3.0699849128723145
Validation loss: 2.797797636319232

Epoch: 5| Step: 7
Training loss: 3.4577438831329346
Validation loss: 2.7882774158190657

Epoch: 5| Step: 8
Training loss: 2.3574485778808594
Validation loss: 2.783911076925134

Epoch: 5| Step: 9
Training loss: 3.0925207138061523
Validation loss: 2.78275792829452

Epoch: 5| Step: 10
Training loss: 3.23517107963562
Validation loss: 2.784087783546858

Epoch: 41| Step: 0
Training loss: 3.154297113418579
Validation loss: 2.780254784450736

Epoch: 5| Step: 1
Training loss: 3.033907413482666
Validation loss: 2.785180261058192

Epoch: 5| Step: 2
Training loss: 2.786771297454834
Validation loss: 2.784128286505258

Epoch: 5| Step: 3
Training loss: 2.268314838409424
Validation loss: 2.7801767677389164

Epoch: 5| Step: 4
Training loss: 2.9284520149230957
Validation loss: 2.77912482138603

Epoch: 5| Step: 5
Training loss: 2.3782846927642822
Validation loss: 2.7776740033139466

Epoch: 5| Step: 6
Training loss: 3.7771689891815186
Validation loss: 2.7788754124795236

Epoch: 5| Step: 7
Training loss: 2.723130464553833
Validation loss: 2.7741853831916727

Epoch: 5| Step: 8
Training loss: 3.0037248134613037
Validation loss: 2.7718991130910893

Epoch: 5| Step: 9
Training loss: 3.188040256500244
Validation loss: 2.771534340355986

Epoch: 5| Step: 10
Training loss: 2.852266550064087
Validation loss: 2.7728649211186234

Epoch: 42| Step: 0
Training loss: 2.9237473011016846
Validation loss: 2.768883656429988

Epoch: 5| Step: 1
Training loss: 3.081407070159912
Validation loss: 2.768177322162095

Epoch: 5| Step: 2
Training loss: 3.4257850646972656
Validation loss: 2.766273670299079

Epoch: 5| Step: 3
Training loss: 2.435504198074341
Validation loss: 2.7678743844391196

Epoch: 5| Step: 4
Training loss: 2.9955086708068848
Validation loss: 2.765096074791365

Epoch: 5| Step: 5
Training loss: 2.9742703437805176
Validation loss: 2.7644536315753894

Epoch: 5| Step: 6
Training loss: 2.5986123085021973
Validation loss: 2.7638518041180027

Epoch: 5| Step: 7
Training loss: 3.0874557495117188
Validation loss: 2.76667159347124

Epoch: 5| Step: 8
Training loss: 2.965627670288086
Validation loss: 2.759448028379871

Epoch: 5| Step: 9
Training loss: 2.881118059158325
Validation loss: 2.758952030571558

Epoch: 5| Step: 10
Training loss: 2.5886738300323486
Validation loss: 2.7567881973840858

Epoch: 43| Step: 0
Training loss: 3.6496212482452393
Validation loss: 2.7761891554760676

Epoch: 5| Step: 1
Training loss: 2.7965190410614014
Validation loss: 2.7563634892945648

Epoch: 5| Step: 2
Training loss: 2.679525852203369
Validation loss: 2.7515649180258475

Epoch: 5| Step: 3
Training loss: 3.0186045169830322
Validation loss: 2.7526596951228317

Epoch: 5| Step: 4
Training loss: 2.768650770187378
Validation loss: 2.7534275106204453

Epoch: 5| Step: 5
Training loss: 3.166914701461792
Validation loss: 2.751428058070521

Epoch: 5| Step: 6
Training loss: 2.4765286445617676
Validation loss: 2.7533514525300715

Epoch: 5| Step: 7
Training loss: 2.5511696338653564
Validation loss: 2.758059404229605

Epoch: 5| Step: 8
Training loss: 2.55027437210083
Validation loss: 2.756119848579489

Epoch: 5| Step: 9
Training loss: 3.3078010082244873
Validation loss: 2.758649992686446

Epoch: 5| Step: 10
Training loss: 3.0122406482696533
Validation loss: 2.7524416754322667

Epoch: 44| Step: 0
Training loss: 3.8375496864318848
Validation loss: 2.7509898165220856

Epoch: 5| Step: 1
Training loss: 2.743263006210327
Validation loss: 2.7472790646296676

Epoch: 5| Step: 2
Training loss: 2.7821648120880127
Validation loss: 2.745496614004976

Epoch: 5| Step: 3
Training loss: 2.9694786071777344
Validation loss: 2.742649378315095

Epoch: 5| Step: 4
Training loss: 3.2380740642547607
Validation loss: 2.744437386912684

Epoch: 5| Step: 5
Training loss: 2.307565689086914
Validation loss: 2.743165075138051

Epoch: 5| Step: 6
Training loss: 3.176171064376831
Validation loss: 2.746787419883154

Epoch: 5| Step: 7
Training loss: 2.769618511199951
Validation loss: 2.741285211296492

Epoch: 5| Step: 8
Training loss: 2.1376500129699707
Validation loss: 2.7419708851845033

Epoch: 5| Step: 9
Training loss: 2.7161412239074707
Validation loss: 2.7399525334758144

Epoch: 5| Step: 10
Training loss: 3.2342700958251953
Validation loss: 2.7381859287138908

Epoch: 45| Step: 0
Training loss: 2.9524497985839844
Validation loss: 2.736972498637374

Epoch: 5| Step: 1
Training loss: 2.968780279159546
Validation loss: 2.739333486044279

Epoch: 5| Step: 2
Training loss: 2.824381113052368
Validation loss: 2.7425470890537387

Epoch: 5| Step: 3
Training loss: 3.1555137634277344
Validation loss: 2.7415345253482943

Epoch: 5| Step: 4
Training loss: 2.6418442726135254
Validation loss: 2.7451526811045985

Epoch: 5| Step: 5
Training loss: 3.4751136302948
Validation loss: 2.745808634706723

Epoch: 5| Step: 6
Training loss: 2.8094239234924316
Validation loss: 2.7422218245844685

Epoch: 5| Step: 7
Training loss: 2.1977410316467285
Validation loss: 2.7343994007315686

Epoch: 5| Step: 8
Training loss: 3.0135421752929688
Validation loss: 2.7341951554821384

Epoch: 5| Step: 9
Training loss: 3.5062127113342285
Validation loss: 2.732683389417587

Epoch: 5| Step: 10
Training loss: 2.1585097312927246
Validation loss: 2.733508156191918

Epoch: 46| Step: 0
Training loss: 2.5939855575561523
Validation loss: 2.7339983832451606

Epoch: 5| Step: 1
Training loss: 2.336878538131714
Validation loss: 2.7364409585152902

Epoch: 5| Step: 2
Training loss: 2.775083303451538
Validation loss: 2.7515526458781254

Epoch: 5| Step: 3
Training loss: 3.4124748706817627
Validation loss: 2.7405141656116774

Epoch: 5| Step: 4
Training loss: 3.4954802989959717
Validation loss: 2.742327956743138

Epoch: 5| Step: 5
Training loss: 3.0805046558380127
Validation loss: 2.73344071449772

Epoch: 5| Step: 6
Training loss: 2.9014382362365723
Validation loss: 2.7329871526328464

Epoch: 5| Step: 7
Training loss: 2.7704615592956543
Validation loss: 2.729835169289702

Epoch: 5| Step: 8
Training loss: 2.5551514625549316
Validation loss: 2.730813226392192

Epoch: 5| Step: 9
Training loss: 3.172647476196289
Validation loss: 2.732166151846609

Epoch: 5| Step: 10
Training loss: 2.6669561862945557
Validation loss: 2.730757482590214

Epoch: 47| Step: 0
Training loss: 1.9019956588745117
Validation loss: 2.7275978083251626

Epoch: 5| Step: 1
Training loss: 2.9461441040039062
Validation loss: 2.7279355038878736

Epoch: 5| Step: 2
Training loss: 3.3221569061279297
Validation loss: 2.73017991230052

Epoch: 5| Step: 3
Training loss: 3.565298080444336
Validation loss: 2.7251361057322514

Epoch: 5| Step: 4
Training loss: 3.2676005363464355
Validation loss: 2.7269628278670774

Epoch: 5| Step: 5
Training loss: 3.086263418197632
Validation loss: 2.726149461602652

Epoch: 5| Step: 6
Training loss: 2.4816341400146484
Validation loss: 2.7275329277079594

Epoch: 5| Step: 7
Training loss: 2.5125250816345215
Validation loss: 2.7236492582546767

Epoch: 5| Step: 8
Training loss: 2.5270094871520996
Validation loss: 2.725970193903933

Epoch: 5| Step: 9
Training loss: 2.9597034454345703
Validation loss: 2.722492410290626

Epoch: 5| Step: 10
Training loss: 3.2011663913726807
Validation loss: 2.7221369666437947

Epoch: 48| Step: 0
Training loss: 3.671645402908325
Validation loss: 2.7201100241753364

Epoch: 5| Step: 1
Training loss: 2.220590114593506
Validation loss: 2.7196272496254212

Epoch: 5| Step: 2
Training loss: 2.883068561553955
Validation loss: 2.722695771084037

Epoch: 5| Step: 3
Training loss: 2.5089192390441895
Validation loss: 2.7209409513781146

Epoch: 5| Step: 4
Training loss: 2.4489519596099854
Validation loss: 2.721469694568265

Epoch: 5| Step: 5
Training loss: 2.9396870136260986
Validation loss: 2.7223150960860716

Epoch: 5| Step: 6
Training loss: 3.140993595123291
Validation loss: 2.7182289605499594

Epoch: 5| Step: 7
Training loss: 3.59684419631958
Validation loss: 2.7188160701464583

Epoch: 5| Step: 8
Training loss: 3.165165424346924
Validation loss: 2.718653778876028

Epoch: 5| Step: 9
Training loss: 2.6183834075927734
Validation loss: 2.717527545908446

Epoch: 5| Step: 10
Training loss: 2.4345099925994873
Validation loss: 2.7168923552318285

Epoch: 49| Step: 0
Training loss: 2.4959025382995605
Validation loss: 2.7171046272400887

Epoch: 5| Step: 1
Training loss: 2.4030239582061768
Validation loss: 2.717344581439931

Epoch: 5| Step: 2
Training loss: 2.7130701541900635
Validation loss: 2.715286229246406

Epoch: 5| Step: 3
Training loss: 3.0291008949279785
Validation loss: 2.716938385399439

Epoch: 5| Step: 4
Training loss: 3.2083237171173096
Validation loss: 2.7175990663548952

Epoch: 5| Step: 5
Training loss: 2.6674163341522217
Validation loss: 2.7166707951535463

Epoch: 5| Step: 6
Training loss: 3.0766773223876953
Validation loss: 2.718801934231994

Epoch: 5| Step: 7
Training loss: 2.821053981781006
Validation loss: 2.7171984590509886

Epoch: 5| Step: 8
Training loss: 2.8833250999450684
Validation loss: 2.726029944676225

Epoch: 5| Step: 9
Training loss: 3.3960120677948
Validation loss: 2.715261241441132

Epoch: 5| Step: 10
Training loss: 2.978484630584717
Validation loss: 2.7148215411811747

Epoch: 50| Step: 0
Training loss: 3.3953499794006348
Validation loss: 2.7171062192609234

Epoch: 5| Step: 1
Training loss: 3.0871450901031494
Validation loss: 2.7203951394686134

Epoch: 5| Step: 2
Training loss: 2.939568281173706
Validation loss: 2.7254571196853474

Epoch: 5| Step: 3
Training loss: 2.7217745780944824
Validation loss: 2.7263687144043627

Epoch: 5| Step: 4
Training loss: 2.693110704421997
Validation loss: 2.7287795620579876

Epoch: 5| Step: 5
Training loss: 2.225182056427002
Validation loss: 2.726786485282324

Epoch: 5| Step: 6
Training loss: 3.45084810256958
Validation loss: 2.722698919234737

Epoch: 5| Step: 7
Training loss: 2.540678024291992
Validation loss: 2.71743486004491

Epoch: 5| Step: 8
Training loss: 2.630629062652588
Validation loss: 2.7067999198872554

Epoch: 5| Step: 9
Training loss: 2.8375601768493652
Validation loss: 2.7084537782976703

Epoch: 5| Step: 10
Training loss: 3.1072239875793457
Validation loss: 2.7083838652538996

Epoch: 51| Step: 0
Training loss: 2.098050117492676
Validation loss: 2.711201601130988

Epoch: 5| Step: 1
Training loss: 2.7867093086242676
Validation loss: 2.7107923133398897

Epoch: 5| Step: 2
Training loss: 3.5189011096954346
Validation loss: 2.712300095506894

Epoch: 5| Step: 3
Training loss: 2.6256003379821777
Validation loss: 2.7128041405831613

Epoch: 5| Step: 4
Training loss: 2.426110029220581
Validation loss: 2.7131709488489295

Epoch: 5| Step: 5
Training loss: 3.8674464225769043
Validation loss: 2.7108902623576503

Epoch: 5| Step: 6
Training loss: 2.6436691284179688
Validation loss: 2.709165093719318

Epoch: 5| Step: 7
Training loss: 2.06306529045105
Validation loss: 2.7101013839885755

Epoch: 5| Step: 8
Training loss: 3.3556694984436035
Validation loss: 2.704882239782682

Epoch: 5| Step: 9
Training loss: 3.1243510246276855
Validation loss: 2.702067777674685

Epoch: 5| Step: 10
Training loss: 3.1206891536712646
Validation loss: 2.6996658899450816

Epoch: 52| Step: 0
Training loss: 3.2462527751922607
Validation loss: 2.7073027805615495

Epoch: 5| Step: 1
Training loss: 2.382230043411255
Validation loss: 2.7110407403720322

Epoch: 5| Step: 2
Training loss: 2.636913537979126
Validation loss: 2.7075921053527505

Epoch: 5| Step: 3
Training loss: 3.336442470550537
Validation loss: 2.715734456175117

Epoch: 5| Step: 4
Training loss: 2.887531042098999
Validation loss: 2.7210729506707962

Epoch: 5| Step: 5
Training loss: 3.2419612407684326
Validation loss: 2.711521033317812

Epoch: 5| Step: 6
Training loss: 2.6904098987579346
Validation loss: 2.7091020435415287

Epoch: 5| Step: 7
Training loss: 2.7237064838409424
Validation loss: 2.7099140382582143

Epoch: 5| Step: 8
Training loss: 2.8079466819763184
Validation loss: 2.7001791461821525

Epoch: 5| Step: 9
Training loss: 3.004714012145996
Validation loss: 2.7017801346317416

Epoch: 5| Step: 10
Training loss: 2.5034332275390625
Validation loss: 2.6989332270878617

Epoch: 53| Step: 0
Training loss: 2.2922043800354004
Validation loss: 2.700973149268858

Epoch: 5| Step: 1
Training loss: 2.9229559898376465
Validation loss: 2.7034745600915726

Epoch: 5| Step: 2
Training loss: 3.26771879196167
Validation loss: 2.700190959438201

Epoch: 5| Step: 3
Training loss: 2.98807430267334
Validation loss: 2.7058797728630806

Epoch: 5| Step: 4
Training loss: 2.438809633255005
Validation loss: 2.7074413094469296

Epoch: 5| Step: 5
Training loss: 2.934342861175537
Validation loss: 2.6993598271441717

Epoch: 5| Step: 6
Training loss: 2.6555628776550293
Validation loss: 2.7029996149001585

Epoch: 5| Step: 7
Training loss: 3.3695626258850098
Validation loss: 2.6961325753119683

Epoch: 5| Step: 8
Training loss: 2.6252708435058594
Validation loss: 2.696720410418767

Epoch: 5| Step: 9
Training loss: 3.0175282955169678
Validation loss: 2.698392714223554

Epoch: 5| Step: 10
Training loss: 3.040393829345703
Validation loss: 2.697999292804349

Epoch: 54| Step: 0
Training loss: 3.6552863121032715
Validation loss: 2.701893993603286

Epoch: 5| Step: 1
Training loss: 2.7087252140045166
Validation loss: 2.706515391667684

Epoch: 5| Step: 2
Training loss: 2.8168959617614746
Validation loss: 2.7073656102662444

Epoch: 5| Step: 3
Training loss: 2.8803749084472656
Validation loss: 2.709363604104647

Epoch: 5| Step: 4
Training loss: 3.8489181995391846
Validation loss: 2.7001268017676567

Epoch: 5| Step: 5
Training loss: 2.8964037895202637
Validation loss: 2.697651699025144

Epoch: 5| Step: 6
Training loss: 2.5895280838012695
Validation loss: 2.6984189992309897

Epoch: 5| Step: 7
Training loss: 2.5977301597595215
Validation loss: 2.706556168935632

Epoch: 5| Step: 8
Training loss: 2.1894824504852295
Validation loss: 2.707828998565674

Epoch: 5| Step: 9
Training loss: 2.658400774002075
Validation loss: 2.700588177609187

Epoch: 5| Step: 10
Training loss: 2.6798136234283447
Validation loss: 2.6999030318311465

Epoch: 55| Step: 0
Training loss: 2.9933738708496094
Validation loss: 2.695884863535563

Epoch: 5| Step: 1
Training loss: 3.0658137798309326
Validation loss: 2.6957065392565984

Epoch: 5| Step: 2
Training loss: 2.8670220375061035
Validation loss: 2.696703344263056

Epoch: 5| Step: 3
Training loss: 2.4538910388946533
Validation loss: 2.695845793652278

Epoch: 5| Step: 4
Training loss: 2.8798372745513916
Validation loss: 2.6953521569569907

Epoch: 5| Step: 5
Training loss: 3.9153549671173096
Validation loss: 2.694191584023096

Epoch: 5| Step: 6
Training loss: 2.8291831016540527
Validation loss: 2.6927770671024116

Epoch: 5| Step: 7
Training loss: 3.331294536590576
Validation loss: 2.6916914755298245

Epoch: 5| Step: 8
Training loss: 2.269615650177002
Validation loss: 2.691168669731386

Epoch: 5| Step: 9
Training loss: 2.258768081665039
Validation loss: 2.6893707962446314

Epoch: 5| Step: 10
Training loss: 2.5767483711242676
Validation loss: 2.6886371592039704

Epoch: 56| Step: 0
Training loss: 2.4834890365600586
Validation loss: 2.690348222691526

Epoch: 5| Step: 1
Training loss: 2.738405704498291
Validation loss: 2.6899957477405505

Epoch: 5| Step: 2
Training loss: 2.7477564811706543
Validation loss: 2.698392601423366

Epoch: 5| Step: 3
Training loss: 3.344789505004883
Validation loss: 2.704326606565906

Epoch: 5| Step: 4
Training loss: 2.2788925170898438
Validation loss: 2.7080642023394184

Epoch: 5| Step: 5
Training loss: 2.0959324836730957
Validation loss: 2.7155055871573825

Epoch: 5| Step: 6
Training loss: 2.7228755950927734
Validation loss: 2.7066498238553285

Epoch: 5| Step: 7
Training loss: 2.7494189739227295
Validation loss: 2.691845186295048

Epoch: 5| Step: 8
Training loss: 4.022971153259277
Validation loss: 2.6907156308492026

Epoch: 5| Step: 9
Training loss: 2.9521713256835938
Validation loss: 2.689345803312076

Epoch: 5| Step: 10
Training loss: 3.3918404579162598
Validation loss: 2.6868833854634273

Epoch: 57| Step: 0
Training loss: 3.9031224250793457
Validation loss: 2.689906374100716

Epoch: 5| Step: 1
Training loss: 3.748944044113159
Validation loss: 2.6846214981489283

Epoch: 5| Step: 2
Training loss: 2.582345485687256
Validation loss: 2.686943672036612

Epoch: 5| Step: 3
Training loss: 2.1109511852264404
Validation loss: 2.6949950264346216

Epoch: 5| Step: 4
Training loss: 2.86706805229187
Validation loss: 2.6991347266781713

Epoch: 5| Step: 5
Training loss: 2.3531746864318848
Validation loss: 2.6964550043946955

Epoch: 5| Step: 6
Training loss: 2.4804139137268066
Validation loss: 2.698574419944517

Epoch: 5| Step: 7
Training loss: 2.8823792934417725
Validation loss: 2.6915442738481747

Epoch: 5| Step: 8
Training loss: 2.85400652885437
Validation loss: 2.687934970342985

Epoch: 5| Step: 9
Training loss: 2.8684210777282715
Validation loss: 2.680852105540614

Epoch: 5| Step: 10
Training loss: 2.747396945953369
Validation loss: 2.681133431773032

Epoch: 58| Step: 0
Training loss: 2.0166168212890625
Validation loss: 2.6919101233123452

Epoch: 5| Step: 1
Training loss: 2.3153584003448486
Validation loss: 2.69422774417426

Epoch: 5| Step: 2
Training loss: 3.1482186317443848
Validation loss: 2.7060884788472164

Epoch: 5| Step: 3
Training loss: 3.0716023445129395
Validation loss: 2.7149928103211107

Epoch: 5| Step: 4
Training loss: 3.2709038257598877
Validation loss: 2.723154587130393

Epoch: 5| Step: 5
Training loss: 3.0634005069732666
Validation loss: 2.711673572499265

Epoch: 5| Step: 6
Training loss: 3.271634578704834
Validation loss: 2.691712764001662

Epoch: 5| Step: 7
Training loss: 2.7439987659454346
Validation loss: 2.6911596739163963

Epoch: 5| Step: 8
Training loss: 2.5317788124084473
Validation loss: 2.6832652758526545

Epoch: 5| Step: 9
Training loss: 3.0715272426605225
Validation loss: 2.686385590543029

Epoch: 5| Step: 10
Training loss: 2.952219247817993
Validation loss: 2.689971467500092

Epoch: 59| Step: 0
Training loss: 3.6707801818847656
Validation loss: 2.690372085058561

Epoch: 5| Step: 1
Training loss: 3.0780880451202393
Validation loss: 2.691042464266541

Epoch: 5| Step: 2
Training loss: 2.8389458656311035
Validation loss: 2.692263731392481

Epoch: 5| Step: 3
Training loss: 2.824214220046997
Validation loss: 2.7032400638826433

Epoch: 5| Step: 4
Training loss: 2.5949671268463135
Validation loss: 2.720007893859699

Epoch: 5| Step: 5
Training loss: 3.206418514251709
Validation loss: 2.752993240151354

Epoch: 5| Step: 6
Training loss: 2.3205080032348633
Validation loss: 2.7458337609485914

Epoch: 5| Step: 7
Training loss: 2.80472731590271
Validation loss: 2.7354870355257423

Epoch: 5| Step: 8
Training loss: 2.9483742713928223
Validation loss: 2.7447533428028064

Epoch: 5| Step: 9
Training loss: 2.651238203048706
Validation loss: 2.736144435021185

Epoch: 5| Step: 10
Training loss: 2.5577845573425293
Validation loss: 2.7020450945823424

Epoch: 60| Step: 0
Training loss: 3.1175570487976074
Validation loss: 2.692650495036956

Epoch: 5| Step: 1
Training loss: 2.195107936859131
Validation loss: 2.6856669815637733

Epoch: 5| Step: 2
Training loss: 3.468193769454956
Validation loss: 2.6851543277822514

Epoch: 5| Step: 3
Training loss: 2.3270511627197266
Validation loss: 2.68276455069101

Epoch: 5| Step: 4
Training loss: 2.751913070678711
Validation loss: 2.685773488013975

Epoch: 5| Step: 5
Training loss: 2.975618362426758
Validation loss: 2.6851768570561565

Epoch: 5| Step: 6
Training loss: 2.3020122051239014
Validation loss: 2.684306924061109

Epoch: 5| Step: 7
Training loss: 3.4617905616760254
Validation loss: 2.6804950826911518

Epoch: 5| Step: 8
Training loss: 2.7994511127471924
Validation loss: 2.6832430721611105

Epoch: 5| Step: 9
Training loss: 2.7703914642333984
Validation loss: 2.6850947923557733

Epoch: 5| Step: 10
Training loss: 3.282724142074585
Validation loss: 2.68318425455401

Epoch: 61| Step: 0
Training loss: 2.9973347187042236
Validation loss: 2.6825970244664017

Epoch: 5| Step: 1
Training loss: 3.580073118209839
Validation loss: 2.6858666276419036

Epoch: 5| Step: 2
Training loss: 2.842695951461792
Validation loss: 2.6944332738076486

Epoch: 5| Step: 3
Training loss: 2.5025534629821777
Validation loss: 2.7106955999969156

Epoch: 5| Step: 4
Training loss: 2.9399116039276123
Validation loss: 2.712845959971028

Epoch: 5| Step: 5
Training loss: 2.9866950511932373
Validation loss: 2.7141919828230336

Epoch: 5| Step: 6
Training loss: 2.758906602859497
Validation loss: 2.684791959742064

Epoch: 5| Step: 7
Training loss: 2.652224540710449
Validation loss: 2.6752456183074624

Epoch: 5| Step: 8
Training loss: 2.714327812194824
Validation loss: 2.6907268544679046

Epoch: 5| Step: 9
Training loss: 2.8042266368865967
Validation loss: 2.7029455759192027

Epoch: 5| Step: 10
Training loss: 2.6450412273406982
Validation loss: 2.6990872916354927

Epoch: 62| Step: 0
Training loss: 2.717278003692627
Validation loss: 2.679876007059569

Epoch: 5| Step: 1
Training loss: 2.2062551975250244
Validation loss: 2.6770203421192784

Epoch: 5| Step: 2
Training loss: 3.0019733905792236
Validation loss: 2.6841989076265724

Epoch: 5| Step: 3
Training loss: 2.5458617210388184
Validation loss: 2.687422606252855

Epoch: 5| Step: 4
Training loss: 2.488041400909424
Validation loss: 2.696130460308444

Epoch: 5| Step: 5
Training loss: 3.059732437133789
Validation loss: 2.6951529082431587

Epoch: 5| Step: 6
Training loss: 2.7869315147399902
Validation loss: 2.6935727083554832

Epoch: 5| Step: 7
Training loss: 3.9643630981445312
Validation loss: 2.693759387539279

Epoch: 5| Step: 8
Training loss: 2.587531805038452
Validation loss: 2.6940832625153246

Epoch: 5| Step: 9
Training loss: 2.9399378299713135
Validation loss: 2.6874655728699057

Epoch: 5| Step: 10
Training loss: 3.141547441482544
Validation loss: 2.6922857299927743

Epoch: 63| Step: 0
Training loss: 3.081005811691284
Validation loss: 2.6835447793365805

Epoch: 5| Step: 1
Training loss: 2.9573938846588135
Validation loss: 2.6748325491464264

Epoch: 5| Step: 2
Training loss: 2.5276567935943604
Validation loss: 2.675241880519416

Epoch: 5| Step: 3
Training loss: 2.570655584335327
Validation loss: 2.6763058708560084

Epoch: 5| Step: 4
Training loss: 3.16489577293396
Validation loss: 2.675109019843481

Epoch: 5| Step: 5
Training loss: 3.192736864089966
Validation loss: 2.677267466821978

Epoch: 5| Step: 6
Training loss: 2.9633820056915283
Validation loss: 2.674240219977594

Epoch: 5| Step: 7
Training loss: 2.874483108520508
Validation loss: 2.6767754477839314

Epoch: 5| Step: 8
Training loss: 2.5784549713134766
Validation loss: 2.678903318220569

Epoch: 5| Step: 9
Training loss: 2.681385040283203
Validation loss: 2.6758658578318935

Epoch: 5| Step: 10
Training loss: 2.77118182182312
Validation loss: 2.678066586935392

Epoch: 64| Step: 0
Training loss: 2.4829115867614746
Validation loss: 2.6739864759547736

Epoch: 5| Step: 1
Training loss: 3.15681529045105
Validation loss: 2.671076759215324

Epoch: 5| Step: 2
Training loss: 2.4323384761810303
Validation loss: 2.6770377210391465

Epoch: 5| Step: 3
Training loss: 2.728257656097412
Validation loss: 2.6776172166229575

Epoch: 5| Step: 4
Training loss: 2.695535659790039
Validation loss: 2.684667243752428

Epoch: 5| Step: 5
Training loss: 3.2325263023376465
Validation loss: 2.6824848510885753

Epoch: 5| Step: 6
Training loss: 2.519296646118164
Validation loss: 2.689808068736907

Epoch: 5| Step: 7
Training loss: 3.0338962078094482
Validation loss: 2.686491520174088

Epoch: 5| Step: 8
Training loss: 3.3326683044433594
Validation loss: 2.68064441732181

Epoch: 5| Step: 9
Training loss: 2.8981237411499023
Validation loss: 2.6814233103106098

Epoch: 5| Step: 10
Training loss: 2.767526626586914
Validation loss: 2.675158880090201

Epoch: 65| Step: 0
Training loss: 2.451491117477417
Validation loss: 2.6710085407380135

Epoch: 5| Step: 1
Training loss: 3.0535049438476562
Validation loss: 2.6704947820273777

Epoch: 5| Step: 2
Training loss: 3.1273980140686035
Validation loss: 2.672188812686551

Epoch: 5| Step: 3
Training loss: 2.536898136138916
Validation loss: 2.676582549207954

Epoch: 5| Step: 4
Training loss: 2.905236005783081
Validation loss: 2.6746084767003215

Epoch: 5| Step: 5
Training loss: 2.743203639984131
Validation loss: 2.6758304667729202

Epoch: 5| Step: 6
Training loss: 3.1709625720977783
Validation loss: 2.669416883940338

Epoch: 5| Step: 7
Training loss: 3.0069632530212402
Validation loss: 2.6721523141348236

Epoch: 5| Step: 8
Training loss: 2.3116157054901123
Validation loss: 2.6706916260462936

Epoch: 5| Step: 9
Training loss: 3.0009870529174805
Validation loss: 2.665624785166915

Epoch: 5| Step: 10
Training loss: 2.9670145511627197
Validation loss: 2.667617997815532

Epoch: 66| Step: 0
Training loss: 3.3407905101776123
Validation loss: 2.6698043730951126

Epoch: 5| Step: 1
Training loss: 2.549008846282959
Validation loss: 2.6668861912142847

Epoch: 5| Step: 2
Training loss: 2.6311984062194824
Validation loss: 2.6652460918631604

Epoch: 5| Step: 3
Training loss: 2.272148609161377
Validation loss: 2.667277753994029

Epoch: 5| Step: 4
Training loss: 2.9663443565368652
Validation loss: 2.668959209995885

Epoch: 5| Step: 5
Training loss: 3.028717041015625
Validation loss: 2.666218473065284

Epoch: 5| Step: 6
Training loss: 2.935331344604492
Validation loss: 2.6714271986356346

Epoch: 5| Step: 7
Training loss: 2.468383312225342
Validation loss: 2.6701507645268596

Epoch: 5| Step: 8
Training loss: 3.166584014892578
Validation loss: 2.6733138381793933

Epoch: 5| Step: 9
Training loss: 3.2310688495635986
Validation loss: 2.6723689263866794

Epoch: 5| Step: 10
Training loss: 2.5929527282714844
Validation loss: 2.6671205002774476

Epoch: 67| Step: 0
Training loss: 2.7198939323425293
Validation loss: 2.6656177877098

Epoch: 5| Step: 1
Training loss: 2.5222105979919434
Validation loss: 2.6590656618918143

Epoch: 5| Step: 2
Training loss: 2.8166537284851074
Validation loss: 2.657795580484534

Epoch: 5| Step: 3
Training loss: 3.734651565551758
Validation loss: 2.6652087011644916

Epoch: 5| Step: 4
Training loss: 1.947821021080017
Validation loss: 2.660013514180337

Epoch: 5| Step: 5
Training loss: 3.330298900604248
Validation loss: 2.6634242150091354

Epoch: 5| Step: 6
Training loss: 2.7190427780151367
Validation loss: 2.6596028445869364

Epoch: 5| Step: 7
Training loss: 2.4446723461151123
Validation loss: 2.6651259929903093

Epoch: 5| Step: 8
Training loss: 2.6532046794891357
Validation loss: 2.6626983842542096

Epoch: 5| Step: 9
Training loss: 3.5023608207702637
Validation loss: 2.658158166434175

Epoch: 5| Step: 10
Training loss: 2.7936251163482666
Validation loss: 2.6650472712773148

Epoch: 68| Step: 0
Training loss: 3.325389862060547
Validation loss: 2.6630609522583666

Epoch: 5| Step: 1
Training loss: 2.7716801166534424
Validation loss: 2.6632655923084547

Epoch: 5| Step: 2
Training loss: 2.4729673862457275
Validation loss: 2.657711439235236

Epoch: 5| Step: 3
Training loss: 3.1682751178741455
Validation loss: 2.661405219826647

Epoch: 5| Step: 4
Training loss: 3.4800148010253906
Validation loss: 2.6603206306375484

Epoch: 5| Step: 5
Training loss: 3.2484002113342285
Validation loss: 2.660957436407766

Epoch: 5| Step: 6
Training loss: 2.5543112754821777
Validation loss: 2.661597700529201

Epoch: 5| Step: 7
Training loss: 2.7238590717315674
Validation loss: 2.653287656845585

Epoch: 5| Step: 8
Training loss: 2.4699454307556152
Validation loss: 2.6575651579005743

Epoch: 5| Step: 9
Training loss: 2.0009725093841553
Validation loss: 2.655404229317942

Epoch: 5| Step: 10
Training loss: 2.898481845855713
Validation loss: 2.6744754673332296

Epoch: 69| Step: 0
Training loss: 3.1082751750946045
Validation loss: 2.686814195366316

Epoch: 5| Step: 1
Training loss: 2.791996479034424
Validation loss: 2.6983318457039456

Epoch: 5| Step: 2
Training loss: 3.079909324645996
Validation loss: 2.7024707614734607

Epoch: 5| Step: 3
Training loss: 2.7910265922546387
Validation loss: 2.6893363870600218

Epoch: 5| Step: 4
Training loss: 2.666515588760376
Validation loss: 2.674660646787254

Epoch: 5| Step: 5
Training loss: 2.7404637336730957
Validation loss: 2.669033391501314

Epoch: 5| Step: 6
Training loss: 3.468721389770508
Validation loss: 2.6682242270438903

Epoch: 5| Step: 7
Training loss: 2.8151206970214844
Validation loss: 2.6702063493831183

Epoch: 5| Step: 8
Training loss: 2.686203956604004
Validation loss: 2.6601521533022643

Epoch: 5| Step: 9
Training loss: 2.214287281036377
Validation loss: 2.6630886267590266

Epoch: 5| Step: 10
Training loss: 2.7832744121551514
Validation loss: 2.658664826423891

Epoch: 70| Step: 0
Training loss: 2.7306206226348877
Validation loss: 2.66183138919133

Epoch: 5| Step: 1
Training loss: 2.6825594902038574
Validation loss: 2.654820378108691

Epoch: 5| Step: 2
Training loss: 3.5859742164611816
Validation loss: 2.659035869823989

Epoch: 5| Step: 3
Training loss: 2.5536904335021973
Validation loss: 2.660575541116858

Epoch: 5| Step: 4
Training loss: 2.7609004974365234
Validation loss: 2.6596656307097404

Epoch: 5| Step: 5
Training loss: 2.452524423599243
Validation loss: 2.658803657818866

Epoch: 5| Step: 6
Training loss: 3.2048065662384033
Validation loss: 2.660324901662847

Epoch: 5| Step: 7
Training loss: 2.052868127822876
Validation loss: 2.6618698540554253

Epoch: 5| Step: 8
Training loss: 3.164593458175659
Validation loss: 2.659182151158651

Epoch: 5| Step: 9
Training loss: 2.755711317062378
Validation loss: 2.6625812310044483

Epoch: 5| Step: 10
Training loss: 3.2056570053100586
Validation loss: 2.662076865473101

Epoch: 71| Step: 0
Training loss: 2.738581657409668
Validation loss: 2.662241320456228

Epoch: 5| Step: 1
Training loss: 2.7375926971435547
Validation loss: 2.6628961845110823

Epoch: 5| Step: 2
Training loss: 3.210503101348877
Validation loss: 2.662601791402345

Epoch: 5| Step: 3
Training loss: 2.579597234725952
Validation loss: 2.659855052989016

Epoch: 5| Step: 4
Training loss: 2.9509873390197754
Validation loss: 2.6620909219147055

Epoch: 5| Step: 5
Training loss: 2.991055965423584
Validation loss: 2.6564177287522184

Epoch: 5| Step: 6
Training loss: 2.860291004180908
Validation loss: 2.659852755967007

Epoch: 5| Step: 7
Training loss: 2.4293103218078613
Validation loss: 2.660815779880811

Epoch: 5| Step: 8
Training loss: 3.177870273590088
Validation loss: 2.6587680539777203

Epoch: 5| Step: 9
Training loss: 2.9610397815704346
Validation loss: 2.663218831503263

Epoch: 5| Step: 10
Training loss: 2.333653211593628
Validation loss: 2.663857585640364

Epoch: 72| Step: 0
Training loss: 2.8892154693603516
Validation loss: 2.676146258590042

Epoch: 5| Step: 1
Training loss: 2.5150387287139893
Validation loss: 2.6894160009199575

Epoch: 5| Step: 2
Training loss: 2.838805675506592
Validation loss: 2.7237305077173377

Epoch: 5| Step: 3
Training loss: 2.766173839569092
Validation loss: 2.7580852970000236

Epoch: 5| Step: 4
Training loss: 3.237520217895508
Validation loss: 2.7607930270574426

Epoch: 5| Step: 5
Training loss: 3.312539577484131
Validation loss: 2.7258696658636934

Epoch: 5| Step: 6
Training loss: 2.92794132232666
Validation loss: 2.6954722865935294

Epoch: 5| Step: 7
Training loss: 2.48932147026062
Validation loss: 2.6654088574071086

Epoch: 5| Step: 8
Training loss: 2.6133358478546143
Validation loss: 2.655639215182233

Epoch: 5| Step: 9
Training loss: 2.4828643798828125
Validation loss: 2.669019253023209

Epoch: 5| Step: 10
Training loss: 3.292954444885254
Validation loss: 2.679420965974049

Epoch: 73| Step: 0
Training loss: 2.4906113147735596
Validation loss: 2.694760245661582

Epoch: 5| Step: 1
Training loss: 2.184792995452881
Validation loss: 2.715674449038762

Epoch: 5| Step: 2
Training loss: 2.702089786529541
Validation loss: 2.7432100413947977

Epoch: 5| Step: 3
Training loss: 3.320056438446045
Validation loss: 2.755550297357703

Epoch: 5| Step: 4
Training loss: 3.8486132621765137
Validation loss: 2.7460903095942673

Epoch: 5| Step: 5
Training loss: 3.224090576171875
Validation loss: 2.728593913457727

Epoch: 5| Step: 6
Training loss: 2.4218146800994873
Validation loss: 2.708751437484577

Epoch: 5| Step: 7
Training loss: 2.660325288772583
Validation loss: 2.6792099860406693

Epoch: 5| Step: 8
Training loss: 2.7580323219299316
Validation loss: 2.662507813463929

Epoch: 5| Step: 9
Training loss: 2.884551525115967
Validation loss: 2.6543458174633723

Epoch: 5| Step: 10
Training loss: 3.0032386779785156
Validation loss: 2.657302092480403

Epoch: 74| Step: 0
Training loss: 2.0881118774414062
Validation loss: 2.6607944708998486

Epoch: 5| Step: 1
Training loss: 3.0284295082092285
Validation loss: 2.675152711970832

Epoch: 5| Step: 2
Training loss: 2.2965762615203857
Validation loss: 2.7021004025654127

Epoch: 5| Step: 3
Training loss: 2.371856927871704
Validation loss: 2.7161532730184574

Epoch: 5| Step: 4
Training loss: 3.2706198692321777
Validation loss: 2.719655180490145

Epoch: 5| Step: 5
Training loss: 2.9193191528320312
Validation loss: 2.705547119981499

Epoch: 5| Step: 6
Training loss: 3.0551695823669434
Validation loss: 2.6941646222145326

Epoch: 5| Step: 7
Training loss: 2.940882682800293
Validation loss: 2.683534942647462

Epoch: 5| Step: 8
Training loss: 3.012606620788574
Validation loss: 2.6634187236908944

Epoch: 5| Step: 9
Training loss: 2.9713242053985596
Validation loss: 2.6611287158022643

Epoch: 5| Step: 10
Training loss: 3.3183250427246094
Validation loss: 2.6580421488772155

Epoch: 75| Step: 0
Training loss: 2.7890849113464355
Validation loss: 2.6602542502905733

Epoch: 5| Step: 1
Training loss: 2.676201581954956
Validation loss: 2.658485133160827

Epoch: 5| Step: 2
Training loss: 2.073401927947998
Validation loss: 2.6566079662692164

Epoch: 5| Step: 3
Training loss: 3.065385580062866
Validation loss: 2.654032035540509

Epoch: 5| Step: 4
Training loss: 3.278034210205078
Validation loss: 2.6532412831501295

Epoch: 5| Step: 5
Training loss: 2.8340466022491455
Validation loss: 2.6504097241227345

Epoch: 5| Step: 6
Training loss: 2.8867478370666504
Validation loss: 2.649560587380522

Epoch: 5| Step: 7
Training loss: 2.7792770862579346
Validation loss: 2.6465143542135916

Epoch: 5| Step: 8
Training loss: 3.115398645401001
Validation loss: 2.652316088317543

Epoch: 5| Step: 9
Training loss: 2.901869773864746
Validation loss: 2.646230146449099

Epoch: 5| Step: 10
Training loss: 2.569345712661743
Validation loss: 2.6457644278003323

Epoch: 76| Step: 0
Training loss: 3.3897719383239746
Validation loss: 2.6448931181302635

Epoch: 5| Step: 1
Training loss: 2.6143338680267334
Validation loss: 2.648993574162965

Epoch: 5| Step: 2
Training loss: 3.5624263286590576
Validation loss: 2.645338730145526

Epoch: 5| Step: 3
Training loss: 2.860879898071289
Validation loss: 2.642963704242501

Epoch: 5| Step: 4
Training loss: 2.890167713165283
Validation loss: 2.648509358847013

Epoch: 5| Step: 5
Training loss: 2.3090627193450928
Validation loss: 2.643492856333333

Epoch: 5| Step: 6
Training loss: 2.1121225357055664
Validation loss: 2.643847711624638

Epoch: 5| Step: 7
Training loss: 2.6960043907165527
Validation loss: 2.6473845179362963

Epoch: 5| Step: 8
Training loss: 2.8370327949523926
Validation loss: 2.6461889871986966

Epoch: 5| Step: 9
Training loss: 2.7767701148986816
Validation loss: 2.643356648824548

Epoch: 5| Step: 10
Training loss: 2.877983570098877
Validation loss: 2.6446115662974696

Epoch: 77| Step: 0
Training loss: 3.0954012870788574
Validation loss: 2.643599646065825

Epoch: 5| Step: 1
Training loss: 2.7997934818267822
Validation loss: 2.6437233032718783

Epoch: 5| Step: 2
Training loss: 2.746251106262207
Validation loss: 2.644163259895899

Epoch: 5| Step: 3
Training loss: 2.629244565963745
Validation loss: 2.642748337919994

Epoch: 5| Step: 4
Training loss: 3.2533984184265137
Validation loss: 2.6427166205580517

Epoch: 5| Step: 5
Training loss: 2.4810662269592285
Validation loss: 2.6451123042773177

Epoch: 5| Step: 6
Training loss: 3.104083776473999
Validation loss: 2.645806486888598

Epoch: 5| Step: 7
Training loss: 2.7098350524902344
Validation loss: 2.6492114015804824

Epoch: 5| Step: 8
Training loss: 2.789090633392334
Validation loss: 2.657740495538199

Epoch: 5| Step: 9
Training loss: 2.9656360149383545
Validation loss: 2.6584426459445747

Epoch: 5| Step: 10
Training loss: 2.219391345977783
Validation loss: 2.664409614378406

Epoch: 78| Step: 0
Training loss: 2.784487247467041
Validation loss: 2.6639645535458802

Epoch: 5| Step: 1
Training loss: 2.1514105796813965
Validation loss: 2.664279173779231

Epoch: 5| Step: 2
Training loss: 2.803609848022461
Validation loss: 2.663478869263844

Epoch: 5| Step: 3
Training loss: 2.8402764797210693
Validation loss: 2.6586909012127946

Epoch: 5| Step: 4
Training loss: 3.1675784587860107
Validation loss: 2.6480576966398504

Epoch: 5| Step: 5
Training loss: 2.20973539352417
Validation loss: 2.6376565835809194

Epoch: 5| Step: 6
Training loss: 2.9206268787384033
Validation loss: 2.640990972518921

Epoch: 5| Step: 7
Training loss: 2.722104549407959
Validation loss: 2.632891067894556

Epoch: 5| Step: 8
Training loss: 2.7389492988586426
Validation loss: 2.6386941863644506

Epoch: 5| Step: 9
Training loss: 2.794813871383667
Validation loss: 2.6391113855505504

Epoch: 5| Step: 10
Training loss: 3.965831995010376
Validation loss: 2.6424854775910736

Epoch: 79| Step: 0
Training loss: 1.8960893154144287
Validation loss: 2.635918935139974

Epoch: 5| Step: 1
Training loss: 2.5570168495178223
Validation loss: 2.6380184824748705

Epoch: 5| Step: 2
Training loss: 3.0801422595977783
Validation loss: 2.639428920643304

Epoch: 5| Step: 3
Training loss: 3.262406826019287
Validation loss: 2.6384066048488823

Epoch: 5| Step: 4
Training loss: 2.7558257579803467
Validation loss: 2.638836286401236

Epoch: 5| Step: 5
Training loss: 2.8088505268096924
Validation loss: 2.637482561090941

Epoch: 5| Step: 6
Training loss: 2.4557251930236816
Validation loss: 2.6436871713207615

Epoch: 5| Step: 7
Training loss: 2.545989990234375
Validation loss: 2.6436969823734735

Epoch: 5| Step: 8
Training loss: 2.7830944061279297
Validation loss: 2.645137007518481

Epoch: 5| Step: 9
Training loss: 3.2796521186828613
Validation loss: 2.638843333849343

Epoch: 5| Step: 10
Training loss: 3.5406899452209473
Validation loss: 2.6419052718788065

Epoch: 80| Step: 0
Training loss: 1.7658195495605469
Validation loss: 2.642735590216934

Epoch: 5| Step: 1
Training loss: 3.4448935985565186
Validation loss: 2.6425003825977282

Epoch: 5| Step: 2
Training loss: 2.7743165493011475
Validation loss: 2.6401741837942474

Epoch: 5| Step: 3
Training loss: 3.0402896404266357
Validation loss: 2.6378541966920257

Epoch: 5| Step: 4
Training loss: 2.9662411212921143
Validation loss: 2.635453677946521

Epoch: 5| Step: 5
Training loss: 3.194972515106201
Validation loss: 2.6348715520674184

Epoch: 5| Step: 6
Training loss: 3.1170926094055176
Validation loss: 2.637170091752083

Epoch: 5| Step: 7
Training loss: 2.7891459465026855
Validation loss: 2.635738085674983

Epoch: 5| Step: 8
Training loss: 3.5076301097869873
Validation loss: 2.6374364847777994

Epoch: 5| Step: 9
Training loss: 2.144713878631592
Validation loss: 2.637209864072902

Epoch: 5| Step: 10
Training loss: 1.9835848808288574
Validation loss: 2.633461949645832

Epoch: 81| Step: 0
Training loss: 2.380540370941162
Validation loss: 2.63634233320913

Epoch: 5| Step: 1
Training loss: 3.29109525680542
Validation loss: 2.6400975975939023

Epoch: 5| Step: 2
Training loss: 2.0640571117401123
Validation loss: 2.6471650933706634

Epoch: 5| Step: 3
Training loss: 2.75982928276062
Validation loss: 2.660967380769791

Epoch: 5| Step: 4
Training loss: 3.493692398071289
Validation loss: 2.676779854682184

Epoch: 5| Step: 5
Training loss: 2.9261975288391113
Validation loss: 2.67446034185348

Epoch: 5| Step: 6
Training loss: 2.3628077507019043
Validation loss: 2.6787407346951064

Epoch: 5| Step: 7
Training loss: 3.1351068019866943
Validation loss: 2.671258282917802

Epoch: 5| Step: 8
Training loss: 2.8906736373901367
Validation loss: 2.6617990257919475

Epoch: 5| Step: 9
Training loss: 2.236485719680786
Validation loss: 2.6472555975760184

Epoch: 5| Step: 10
Training loss: 3.430971145629883
Validation loss: 2.6351106833386164

Epoch: 82| Step: 0
Training loss: 2.549112319946289
Validation loss: 2.631260612959503

Epoch: 5| Step: 1
Training loss: 2.8200995922088623
Validation loss: 2.635125414017708

Epoch: 5| Step: 2
Training loss: 2.7275640964508057
Validation loss: 2.6376510999536

Epoch: 5| Step: 3
Training loss: 3.6878960132598877
Validation loss: 2.637288913931898

Epoch: 5| Step: 4
Training loss: 2.534188747406006
Validation loss: 2.640198633234988

Epoch: 5| Step: 5
Training loss: 2.2405495643615723
Validation loss: 2.638690702376827

Epoch: 5| Step: 6
Training loss: 2.2512786388397217
Validation loss: 2.642208517238658

Epoch: 5| Step: 7
Training loss: 2.932055950164795
Validation loss: 2.6409550866773053

Epoch: 5| Step: 8
Training loss: 2.749356508255005
Validation loss: 2.63790395182948

Epoch: 5| Step: 9
Training loss: 3.3862838745117188
Validation loss: 2.642469747092134

Epoch: 5| Step: 10
Training loss: 3.0004634857177734
Validation loss: 2.639986599645307

Epoch: 83| Step: 0
Training loss: 2.438121795654297
Validation loss: 2.6391865822576706

Epoch: 5| Step: 1
Training loss: 2.3249149322509766
Validation loss: 2.6342684838079635

Epoch: 5| Step: 2
Training loss: 2.9589715003967285
Validation loss: 2.6321426412110687

Epoch: 5| Step: 3
Training loss: 3.353879928588867
Validation loss: 2.634143037180747

Epoch: 5| Step: 4
Training loss: 3.1040472984313965
Validation loss: 2.638648820179765

Epoch: 5| Step: 5
Training loss: 2.5290865898132324
Validation loss: 2.647944332450949

Epoch: 5| Step: 6
Training loss: 2.8466286659240723
Validation loss: 2.648608569175966

Epoch: 5| Step: 7
Training loss: 2.4876701831817627
Validation loss: 2.6483219182619484

Epoch: 5| Step: 8
Training loss: 3.009424924850464
Validation loss: 2.6519924466327955

Epoch: 5| Step: 9
Training loss: 2.7087490558624268
Validation loss: 2.6543414464560886

Epoch: 5| Step: 10
Training loss: 3.0668346881866455
Validation loss: 2.657500236265121

Epoch: 84| Step: 0
Training loss: 2.901857614517212
Validation loss: 2.6479070571161087

Epoch: 5| Step: 1
Training loss: 3.2750167846679688
Validation loss: 2.651943968188378

Epoch: 5| Step: 2
Training loss: 2.4583334922790527
Validation loss: 2.6430847798624346

Epoch: 5| Step: 3
Training loss: 2.346693992614746
Validation loss: 2.6382339436520814

Epoch: 5| Step: 4
Training loss: 1.9846761226654053
Validation loss: 2.6327756220294583

Epoch: 5| Step: 5
Training loss: 2.7181458473205566
Validation loss: 2.629327827884305

Epoch: 5| Step: 6
Training loss: 3.3375344276428223
Validation loss: 2.6259444195737123

Epoch: 5| Step: 7
Training loss: 2.8328235149383545
Validation loss: 2.625412779469644

Epoch: 5| Step: 8
Training loss: 3.0912065505981445
Validation loss: 2.628115923173966

Epoch: 5| Step: 9
Training loss: 2.7612369060516357
Validation loss: 2.6305305650157313

Epoch: 5| Step: 10
Training loss: 3.016533613204956
Validation loss: 2.632119219790223

Epoch: 85| Step: 0
Training loss: 2.4151103496551514
Validation loss: 2.6344101710986068

Epoch: 5| Step: 1
Training loss: 2.9516384601593018
Validation loss: 2.629779833619313

Epoch: 5| Step: 2
Training loss: 2.7331137657165527
Validation loss: 2.6328521569569907

Epoch: 5| Step: 3
Training loss: 2.9021573066711426
Validation loss: 2.638823196452151

Epoch: 5| Step: 4
Training loss: 2.7284932136535645
Validation loss: 2.6386199664044123

Epoch: 5| Step: 5
Training loss: 2.7603988647460938
Validation loss: 2.630036118210003

Epoch: 5| Step: 6
Training loss: 3.372847080230713
Validation loss: 2.6232989475291264

Epoch: 5| Step: 7
Training loss: 2.664388656616211
Validation loss: 2.6298827637908277

Epoch: 5| Step: 8
Training loss: 2.5104269981384277
Validation loss: 2.628652036830943

Epoch: 5| Step: 9
Training loss: 2.427112579345703
Validation loss: 2.628853251857142

Epoch: 5| Step: 10
Training loss: 3.313821792602539
Validation loss: 2.630227591401787

Epoch: 86| Step: 0
Training loss: 2.895334482192993
Validation loss: 2.6264198928750973

Epoch: 5| Step: 1
Training loss: 1.8027808666229248
Validation loss: 2.623222674092939

Epoch: 5| Step: 2
Training loss: 3.659543514251709
Validation loss: 2.6273850497379097

Epoch: 5| Step: 3
Training loss: 2.7573189735412598
Validation loss: 2.6250510754123813

Epoch: 5| Step: 4
Training loss: 2.292316198348999
Validation loss: 2.6250543132905038

Epoch: 5| Step: 5
Training loss: 3.371586561203003
Validation loss: 2.6223350494138655

Epoch: 5| Step: 6
Training loss: 2.9673924446105957
Validation loss: 2.6268279321732058

Epoch: 5| Step: 7
Training loss: 2.720320701599121
Validation loss: 2.6257455528423352

Epoch: 5| Step: 8
Training loss: 2.533644199371338
Validation loss: 2.6268776744924565

Epoch: 5| Step: 9
Training loss: 3.018231153488159
Validation loss: 2.630543085836595

Epoch: 5| Step: 10
Training loss: 2.5829830169677734
Validation loss: 2.6262141658413793

Epoch: 87| Step: 0
Training loss: 2.7483065128326416
Validation loss: 2.633881027980517

Epoch: 5| Step: 1
Training loss: 2.429497241973877
Validation loss: 2.628393793618807

Epoch: 5| Step: 2
Training loss: 3.1863160133361816
Validation loss: 2.620927292813537

Epoch: 5| Step: 3
Training loss: 2.694413900375366
Validation loss: 2.6262531203608357

Epoch: 5| Step: 4
Training loss: 2.686959981918335
Validation loss: 2.6271834219655683

Epoch: 5| Step: 5
Training loss: 3.5861077308654785
Validation loss: 2.621691511523339

Epoch: 5| Step: 6
Training loss: 2.6292872428894043
Validation loss: 2.62136237852035

Epoch: 5| Step: 7
Training loss: 2.9950122833251953
Validation loss: 2.628920042386619

Epoch: 5| Step: 8
Training loss: 3.172182559967041
Validation loss: 2.622926950454712

Epoch: 5| Step: 9
Training loss: 2.49307918548584
Validation loss: 2.6436659136126117

Epoch: 5| Step: 10
Training loss: 1.8916066884994507
Validation loss: 2.6277180589655393

Epoch: 88| Step: 0
Training loss: 2.8796417713165283
Validation loss: 2.6333975125384588

Epoch: 5| Step: 1
Training loss: 3.330702543258667
Validation loss: 2.627637852904617

Epoch: 5| Step: 2
Training loss: 2.610243558883667
Validation loss: 2.6193341849952616

Epoch: 5| Step: 3
Training loss: 2.519489049911499
Validation loss: 2.6276690703566357

Epoch: 5| Step: 4
Training loss: 3.697990894317627
Validation loss: 2.6127496739869476

Epoch: 5| Step: 5
Training loss: 2.0093464851379395
Validation loss: 2.6151447603779454

Epoch: 5| Step: 6
Training loss: 2.802368640899658
Validation loss: 2.6215336809876146

Epoch: 5| Step: 7
Training loss: 3.446084976196289
Validation loss: 2.6225936156447216

Epoch: 5| Step: 8
Training loss: 2.241074323654175
Validation loss: 2.621545701898554

Epoch: 5| Step: 9
Training loss: 2.15990948677063
Validation loss: 2.6183184757027576

Epoch: 5| Step: 10
Training loss: 2.908172845840454
Validation loss: 2.622583878937588

Epoch: 89| Step: 0
Training loss: 3.4988930225372314
Validation loss: 2.622855007007558

Epoch: 5| Step: 1
Training loss: 2.6069602966308594
Validation loss: 2.619655191257436

Epoch: 5| Step: 2
Training loss: 3.314788818359375
Validation loss: 2.624142477589269

Epoch: 5| Step: 3
Training loss: 3.0502429008483887
Validation loss: 2.619591054096017

Epoch: 5| Step: 4
Training loss: 2.4831154346466064
Validation loss: 2.621534921789682

Epoch: 5| Step: 5
Training loss: 2.434130907058716
Validation loss: 2.6242322178297144

Epoch: 5| Step: 6
Training loss: 3.204740047454834
Validation loss: 2.620353688475906

Epoch: 5| Step: 7
Training loss: 2.5350887775421143
Validation loss: 2.6249802881671536

Epoch: 5| Step: 8
Training loss: 2.744476795196533
Validation loss: 2.622367617904499

Epoch: 5| Step: 9
Training loss: 2.3593201637268066
Validation loss: 2.6264147476483415

Epoch: 5| Step: 10
Training loss: 2.209686040878296
Validation loss: 2.6254694564368135

Epoch: 90| Step: 0
Training loss: 2.7744345664978027
Validation loss: 2.616880178451538

Epoch: 5| Step: 1
Training loss: 3.5059609413146973
Validation loss: 2.617427349090576

Epoch: 5| Step: 2
Training loss: 2.6476426124572754
Validation loss: 2.6194521278463383

Epoch: 5| Step: 3
Training loss: 2.645753860473633
Validation loss: 2.6177932549548406

Epoch: 5| Step: 4
Training loss: 3.5240962505340576
Validation loss: 2.6186843866943033

Epoch: 5| Step: 5
Training loss: 2.5664658546447754
Validation loss: 2.626500283518145

Epoch: 5| Step: 6
Training loss: 2.0814993381500244
Validation loss: 2.6186440349907003

Epoch: 5| Step: 7
Training loss: 2.7590231895446777
Validation loss: 2.622692825973675

Epoch: 5| Step: 8
Training loss: 3.045612335205078
Validation loss: 2.6186286095649964

Epoch: 5| Step: 9
Training loss: 2.344491958618164
Validation loss: 2.6221504621608283

Epoch: 5| Step: 10
Training loss: 2.6505167484283447
Validation loss: 2.628807460108111

Epoch: 91| Step: 0
Training loss: 2.705519914627075
Validation loss: 2.647421985544184

Epoch: 5| Step: 1
Training loss: 2.6678686141967773
Validation loss: 2.639358699962657

Epoch: 5| Step: 2
Training loss: 3.0597727298736572
Validation loss: 2.642185554709486

Epoch: 5| Step: 3
Training loss: 2.283194065093994
Validation loss: 2.6294683794821463

Epoch: 5| Step: 4
Training loss: 3.133699655532837
Validation loss: 2.62449219406292

Epoch: 5| Step: 5
Training loss: 3.0751090049743652
Validation loss: 2.6220171733569075

Epoch: 5| Step: 6
Training loss: 2.706752061843872
Validation loss: 2.6344805763613794

Epoch: 5| Step: 7
Training loss: 2.3678390979766846
Validation loss: 2.641478548767746

Epoch: 5| Step: 8
Training loss: 3.254013776779175
Validation loss: 2.636678541860273

Epoch: 5| Step: 9
Training loss: 2.8774983882904053
Validation loss: 2.640762380374375

Epoch: 5| Step: 10
Training loss: 2.543332099914551
Validation loss: 2.6340368998947965

Epoch: 92| Step: 0
Training loss: 2.51279878616333
Validation loss: 2.630936781565348

Epoch: 5| Step: 1
Training loss: 2.6399459838867188
Validation loss: 2.623808458287229

Epoch: 5| Step: 2
Training loss: 2.89107608795166
Validation loss: 2.619420641212053

Epoch: 5| Step: 3
Training loss: 2.587831974029541
Validation loss: 2.6196569704240367

Epoch: 5| Step: 4
Training loss: 3.1169629096984863
Validation loss: 2.617084972320064

Epoch: 5| Step: 5
Training loss: 2.947444438934326
Validation loss: 2.6128814604974564

Epoch: 5| Step: 6
Training loss: 2.5261549949645996
Validation loss: 2.6142525775458223

Epoch: 5| Step: 7
Training loss: 3.5592684745788574
Validation loss: 2.610119906804895

Epoch: 5| Step: 8
Training loss: 3.5497653484344482
Validation loss: 2.6048337054508988

Epoch: 5| Step: 9
Training loss: 1.8770980834960938
Validation loss: 2.6026919631547827

Epoch: 5| Step: 10
Training loss: 2.2086639404296875
Validation loss: 2.607440451140045

Epoch: 93| Step: 0
Training loss: 2.8823821544647217
Validation loss: 2.5988476558398177

Epoch: 5| Step: 1
Training loss: 2.334012985229492
Validation loss: 2.595948680754631

Epoch: 5| Step: 2
Training loss: 2.9684841632843018
Validation loss: 2.6005009784493396

Epoch: 5| Step: 3
Training loss: 2.6526050567626953
Validation loss: 2.6037879861811155

Epoch: 5| Step: 4
Training loss: 2.680689811706543
Validation loss: 2.597553563374345

Epoch: 5| Step: 5
Training loss: 2.469219923019409
Validation loss: 2.595875470869003

Epoch: 5| Step: 6
Training loss: 2.309736967086792
Validation loss: 2.595139744461224

Epoch: 5| Step: 7
Training loss: 3.4898345470428467
Validation loss: 2.5982471794210453

Epoch: 5| Step: 8
Training loss: 2.590178966522217
Validation loss: 2.594317854091685

Epoch: 5| Step: 9
Training loss: 2.5220203399658203
Validation loss: 2.595938282628213

Epoch: 5| Step: 10
Training loss: 3.664919137954712
Validation loss: 2.5962134663776686

Epoch: 94| Step: 0
Training loss: 3.065969705581665
Validation loss: 2.591950467837754

Epoch: 5| Step: 1
Training loss: 2.7748076915740967
Validation loss: 2.5951778863065984

Epoch: 5| Step: 2
Training loss: 3.126171112060547
Validation loss: 2.5983777687113774

Epoch: 5| Step: 3
Training loss: 3.1443164348602295
Validation loss: 2.596141797240062

Epoch: 5| Step: 4
Training loss: 2.9892075061798096
Validation loss: 2.601628557328255

Epoch: 5| Step: 5
Training loss: 3.0103275775909424
Validation loss: 2.6018459155995357

Epoch: 5| Step: 6
Training loss: 2.4093356132507324
Validation loss: 2.6018186102631273

Epoch: 5| Step: 7
Training loss: 2.8978400230407715
Validation loss: 2.6015356381734214

Epoch: 5| Step: 8
Training loss: 1.9785406589508057
Validation loss: 2.600211351148544

Epoch: 5| Step: 9
Training loss: 2.6196024417877197
Validation loss: 2.593355373669696

Epoch: 5| Step: 10
Training loss: 2.309633255004883
Validation loss: 2.5925909908868934

Epoch: 95| Step: 0
Training loss: 3.043030261993408
Validation loss: 2.5911567621333624

Epoch: 5| Step: 1
Training loss: 2.5307977199554443
Validation loss: 2.5904161148173834

Epoch: 5| Step: 2
Training loss: 2.8915998935699463
Validation loss: 2.5906796968111427

Epoch: 5| Step: 3
Training loss: 3.4994518756866455
Validation loss: 2.5928515798302105

Epoch: 5| Step: 4
Training loss: 2.5666892528533936
Validation loss: 2.589696894409836

Epoch: 5| Step: 5
Training loss: 2.9684157371520996
Validation loss: 2.5945663887967347

Epoch: 5| Step: 6
Training loss: 2.124614715576172
Validation loss: 2.5920243288881037

Epoch: 5| Step: 7
Training loss: 2.5290658473968506
Validation loss: 2.5944787276688444

Epoch: 5| Step: 8
Training loss: 2.874655246734619
Validation loss: 2.5860996297610703

Epoch: 5| Step: 9
Training loss: 2.6148436069488525
Validation loss: 2.5899608314678235

Epoch: 5| Step: 10
Training loss: 2.7682178020477295
Validation loss: 2.592836259513773

Epoch: 96| Step: 0
Training loss: 2.411180257797241
Validation loss: 2.594819773909866

Epoch: 5| Step: 1
Training loss: 2.28818941116333
Validation loss: 2.5954828031601442

Epoch: 5| Step: 2
Training loss: 2.42454195022583
Validation loss: 2.608084568413355

Epoch: 5| Step: 3
Training loss: 2.6409480571746826
Validation loss: 2.6174445075373494

Epoch: 5| Step: 4
Training loss: 2.715108871459961
Validation loss: 2.605684382941133

Epoch: 5| Step: 5
Training loss: 3.160770893096924
Validation loss: 2.597334361845447

Epoch: 5| Step: 6
Training loss: 2.6625046730041504
Validation loss: 2.5970732345375964

Epoch: 5| Step: 7
Training loss: 3.1267800331115723
Validation loss: 2.595176745486516

Epoch: 5| Step: 8
Training loss: 2.868454694747925
Validation loss: 2.592993692685199

Epoch: 5| Step: 9
Training loss: 3.196254253387451
Validation loss: 2.588354197881555

Epoch: 5| Step: 10
Training loss: 2.8839292526245117
Validation loss: 2.585927412074099

Epoch: 97| Step: 0
Training loss: 2.8904683589935303
Validation loss: 2.584912687219599

Epoch: 5| Step: 1
Training loss: 2.8629844188690186
Validation loss: 2.5907281393645913

Epoch: 5| Step: 2
Training loss: 2.759474277496338
Validation loss: 2.5942675298260105

Epoch: 5| Step: 3
Training loss: 2.7524898052215576
Validation loss: 2.5958461146200857

Epoch: 5| Step: 4
Training loss: 1.8960100412368774
Validation loss: 2.598121653320969

Epoch: 5| Step: 5
Training loss: 2.961684465408325
Validation loss: 2.598757856635637

Epoch: 5| Step: 6
Training loss: 2.7247118949890137
Validation loss: 2.593567886660176

Epoch: 5| Step: 7
Training loss: 3.3737633228302
Validation loss: 2.5940312723959646

Epoch: 5| Step: 8
Training loss: 2.7279911041259766
Validation loss: 2.5936447497337096

Epoch: 5| Step: 9
Training loss: 2.662956476211548
Validation loss: 2.5908563957419446

Epoch: 5| Step: 10
Training loss: 2.9442365169525146
Validation loss: 2.5854097591933383

Epoch: 98| Step: 0
Training loss: 2.3516287803649902
Validation loss: 2.585002355678107

Epoch: 5| Step: 1
Training loss: 3.446577548980713
Validation loss: 2.583289864242718

Epoch: 5| Step: 2
Training loss: 3.5986855030059814
Validation loss: 2.5837809962611042

Epoch: 5| Step: 3
Training loss: 2.599128484725952
Validation loss: 2.587743979628368

Epoch: 5| Step: 4
Training loss: 2.0928053855895996
Validation loss: 2.5867105632699947

Epoch: 5| Step: 5
Training loss: 3.0270626544952393
Validation loss: 2.5915047302041003

Epoch: 5| Step: 6
Training loss: 2.776790142059326
Validation loss: 2.6031146100772324

Epoch: 5| Step: 7
Training loss: 2.348609209060669
Validation loss: 2.6148258332283265

Epoch: 5| Step: 8
Training loss: 2.6135449409484863
Validation loss: 2.621445140530986

Epoch: 5| Step: 9
Training loss: 2.72944712638855
Validation loss: 2.616170024359098

Epoch: 5| Step: 10
Training loss: 2.6698431968688965
Validation loss: 2.615311768747145

Epoch: 99| Step: 0
Training loss: 2.5796103477478027
Validation loss: 2.6224693995650097

Epoch: 5| Step: 1
Training loss: 2.977637767791748
Validation loss: 2.607560852522491

Epoch: 5| Step: 2
Training loss: 2.016669511795044
Validation loss: 2.606715909896358

Epoch: 5| Step: 3
Training loss: 3.275134325027466
Validation loss: 2.60342147017038

Epoch: 5| Step: 4
Training loss: 2.4430432319641113
Validation loss: 2.602270410906884

Epoch: 5| Step: 5
Training loss: 2.321068525314331
Validation loss: 2.5964610358720184

Epoch: 5| Step: 6
Training loss: 2.606032371520996
Validation loss: 2.596240912714312

Epoch: 5| Step: 7
Training loss: 2.254845380783081
Validation loss: 2.5928333856726207

Epoch: 5| Step: 8
Training loss: 2.85192608833313
Validation loss: 2.5926922264919487

Epoch: 5| Step: 9
Training loss: 3.7156028747558594
Validation loss: 2.595267662438013

Epoch: 5| Step: 10
Training loss: 3.463160753250122
Validation loss: 2.5923993792585147

Epoch: 100| Step: 0
Training loss: 3.262755870819092
Validation loss: 2.5945563316345215

Epoch: 5| Step: 1
Training loss: 3.0476789474487305
Validation loss: 2.5931154835608696

Epoch: 5| Step: 2
Training loss: 1.9844192266464233
Validation loss: 2.590067619918495

Epoch: 5| Step: 3
Training loss: 3.0439646244049072
Validation loss: 2.5898803600700955

Epoch: 5| Step: 4
Training loss: 2.8836450576782227
Validation loss: 2.586521110227031

Epoch: 5| Step: 5
Training loss: 3.1653242111206055
Validation loss: 2.589035654580721

Epoch: 5| Step: 6
Training loss: 2.826829195022583
Validation loss: 2.584710454428068

Epoch: 5| Step: 7
Training loss: 2.285250663757324
Validation loss: 2.5814430636744343

Epoch: 5| Step: 8
Training loss: 2.221066474914551
Validation loss: 2.5818889346174014

Epoch: 5| Step: 9
Training loss: 2.8293678760528564
Validation loss: 2.5790266657388337

Epoch: 5| Step: 10
Training loss: 2.6866888999938965
Validation loss: 2.5789497385742846

Epoch: 101| Step: 0
Training loss: 2.8270392417907715
Validation loss: 2.587938324097664

Epoch: 5| Step: 1
Training loss: 2.522348165512085
Validation loss: 2.5968961049151678

Epoch: 5| Step: 2
Training loss: 1.9777748584747314
Validation loss: 2.603662593390352

Epoch: 5| Step: 3
Training loss: 2.803800106048584
Validation loss: 2.6045564323343258

Epoch: 5| Step: 4
Training loss: 2.38836932182312
Validation loss: 2.6056812091540267

Epoch: 5| Step: 5
Training loss: 2.7272849082946777
Validation loss: 2.6012116298880628

Epoch: 5| Step: 6
Training loss: 2.8502917289733887
Validation loss: 2.593652594474054

Epoch: 5| Step: 7
Training loss: 3.006481885910034
Validation loss: 2.598113295852497

Epoch: 5| Step: 8
Training loss: 3.26725697517395
Validation loss: 2.5935209207637335

Epoch: 5| Step: 9
Training loss: 3.325073719024658
Validation loss: 2.596276770355881

Epoch: 5| Step: 10
Training loss: 2.51824688911438
Validation loss: 2.587139086056781

Epoch: 102| Step: 0
Training loss: 2.9274697303771973
Validation loss: 2.584898018067883

Epoch: 5| Step: 1
Training loss: 2.2945494651794434
Validation loss: 2.582013773661788

Epoch: 5| Step: 2
Training loss: 3.1995246410369873
Validation loss: 2.5807400339393207

Epoch: 5| Step: 3
Training loss: 3.241783857345581
Validation loss: 2.584391866960833

Epoch: 5| Step: 4
Training loss: 2.3267784118652344
Validation loss: 2.585189832154141

Epoch: 5| Step: 5
Training loss: 2.573071241378784
Validation loss: 2.579096401891401

Epoch: 5| Step: 6
Training loss: 2.6460206508636475
Validation loss: 2.5829206025728615

Epoch: 5| Step: 7
Training loss: 3.3092169761657715
Validation loss: 2.5799291569699525

Epoch: 5| Step: 8
Training loss: 2.301487445831299
Validation loss: 2.587476473982616

Epoch: 5| Step: 9
Training loss: 2.6680569648742676
Validation loss: 2.5760294109262447

Epoch: 5| Step: 10
Training loss: 2.7570228576660156
Validation loss: 2.579397991139402

Epoch: 103| Step: 0
Training loss: 2.720628261566162
Validation loss: 2.5765592667364303

Epoch: 5| Step: 1
Training loss: 3.0096168518066406
Validation loss: 2.579509032669888

Epoch: 5| Step: 2
Training loss: 2.4395453929901123
Validation loss: 2.5749224385907574

Epoch: 5| Step: 3
Training loss: 3.508545398712158
Validation loss: 2.575425459492591

Epoch: 5| Step: 4
Training loss: 3.0664422512054443
Validation loss: 2.5748403661994526

Epoch: 5| Step: 5
Training loss: 2.413989305496216
Validation loss: 2.5796472949366414

Epoch: 5| Step: 6
Training loss: 2.4529929161071777
Validation loss: 2.5741722404315905

Epoch: 5| Step: 7
Training loss: 2.094639301300049
Validation loss: 2.5738588507457445

Epoch: 5| Step: 8
Training loss: 2.52473521232605
Validation loss: 2.580844158767372

Epoch: 5| Step: 9
Training loss: 3.5080478191375732
Validation loss: 2.5827899799552014

Epoch: 5| Step: 10
Training loss: 2.3988912105560303
Validation loss: 2.587468162659676

Epoch: 104| Step: 0
Training loss: 2.8237991333007812
Validation loss: 2.6044389458112818

Epoch: 5| Step: 1
Training loss: 2.8649754524230957
Validation loss: 2.6099788142788793

Epoch: 5| Step: 2
Training loss: 2.295619010925293
Validation loss: 2.6116560505282496

Epoch: 5| Step: 3
Training loss: 2.9701778888702393
Validation loss: 2.6027251161554807

Epoch: 5| Step: 4
Training loss: 2.7645959854125977
Validation loss: 2.5932971969727547

Epoch: 5| Step: 5
Training loss: 2.739758014678955
Validation loss: 2.5778352240080475

Epoch: 5| Step: 6
Training loss: 2.637721538543701
Validation loss: 2.5746042369514384

Epoch: 5| Step: 7
Training loss: 2.412360906600952
Validation loss: 2.569976378512639

Epoch: 5| Step: 8
Training loss: 2.557070255279541
Validation loss: 2.5855364235498572

Epoch: 5| Step: 9
Training loss: 3.206272840499878
Validation loss: 2.5889324603542203

Epoch: 5| Step: 10
Training loss: 3.116443395614624
Validation loss: 2.588126185119793

Epoch: 105| Step: 0
Training loss: 2.6205525398254395
Validation loss: 2.589064831374794

Epoch: 5| Step: 1
Training loss: 2.6811840534210205
Validation loss: 2.5797070764726207

Epoch: 5| Step: 2
Training loss: 2.7728869915008545
Validation loss: 2.570857496671779

Epoch: 5| Step: 3
Training loss: 2.4635884761810303
Validation loss: 2.5703795340753373

Epoch: 5| Step: 4
Training loss: 3.2899882793426514
Validation loss: 2.5720370969464703

Epoch: 5| Step: 5
Training loss: 2.833636522293091
Validation loss: 2.5743140379587808

Epoch: 5| Step: 6
Training loss: 2.859027147293091
Validation loss: 2.5742994687890493

Epoch: 5| Step: 7
Training loss: 2.7199442386627197
Validation loss: 2.5809640038398003

Epoch: 5| Step: 8
Training loss: 2.8616576194763184
Validation loss: 2.580580613946402

Epoch: 5| Step: 9
Training loss: 2.3421266078948975
Validation loss: 2.580770919399877

Epoch: 5| Step: 10
Training loss: 2.796977996826172
Validation loss: 2.581305458981504

Epoch: 106| Step: 0
Training loss: 3.3769595623016357
Validation loss: 2.581927543045372

Epoch: 5| Step: 1
Training loss: 3.3991782665252686
Validation loss: 2.579592517627183

Epoch: 5| Step: 2
Training loss: 2.6261348724365234
Validation loss: 2.573854643811462

Epoch: 5| Step: 3
Training loss: 2.100682258605957
Validation loss: 2.5782351596381075

Epoch: 5| Step: 4
Training loss: 2.8533852100372314
Validation loss: 2.5720441700309835

Epoch: 5| Step: 5
Training loss: 2.121522903442383
Validation loss: 2.580934332263085

Epoch: 5| Step: 6
Training loss: 2.78108286857605
Validation loss: 2.5869728031978814

Epoch: 5| Step: 7
Training loss: 2.1755452156066895
Validation loss: 2.5870019902465162

Epoch: 5| Step: 8
Training loss: 3.0785489082336426
Validation loss: 2.594183732104558

Epoch: 5| Step: 9
Training loss: 3.241781711578369
Validation loss: 2.6107274383626957

Epoch: 5| Step: 10
Training loss: 2.4694905281066895
Validation loss: 2.6118299884180867

Epoch: 107| Step: 0
Training loss: 2.9711034297943115
Validation loss: 2.607089196482012

Epoch: 5| Step: 1
Training loss: 2.379748582839966
Validation loss: 2.608119213452903

Epoch: 5| Step: 2
Training loss: 3.0050926208496094
Validation loss: 2.604015859224463

Epoch: 5| Step: 3
Training loss: 2.7197930812835693
Validation loss: 2.6152921158780336

Epoch: 5| Step: 4
Training loss: 2.9945826530456543
Validation loss: 2.6173022383002826

Epoch: 5| Step: 5
Training loss: 2.773658275604248
Validation loss: 2.6142911398282616

Epoch: 5| Step: 6
Training loss: 2.5992698669433594
Validation loss: 2.6134309307221444

Epoch: 5| Step: 7
Training loss: 2.571995496749878
Validation loss: 2.616578589203537

Epoch: 5| Step: 8
Training loss: 2.62512469291687
Validation loss: 2.6109186064812446

Epoch: 5| Step: 9
Training loss: 2.4667418003082275
Validation loss: 2.5935503923764793

Epoch: 5| Step: 10
Training loss: 3.452648878097534
Validation loss: 2.5885928907702045

Epoch: 108| Step: 0
Training loss: 2.7292022705078125
Validation loss: 2.583941639110606

Epoch: 5| Step: 1
Training loss: 1.8696346282958984
Validation loss: 2.5809013023171374

Epoch: 5| Step: 2
Training loss: 2.7762951850891113
Validation loss: 2.58019499112201

Epoch: 5| Step: 3
Training loss: 3.469942569732666
Validation loss: 2.582885803714875

Epoch: 5| Step: 4
Training loss: 2.874905586242676
Validation loss: 2.5725638533151276

Epoch: 5| Step: 5
Training loss: 2.8353500366210938
Validation loss: 2.5700510548007105

Epoch: 5| Step: 6
Training loss: 3.018083095550537
Validation loss: 2.571686262725502

Epoch: 5| Step: 7
Training loss: 3.0285158157348633
Validation loss: 2.5708381796395905

Epoch: 5| Step: 8
Training loss: 2.5712485313415527
Validation loss: 2.5754680300271637

Epoch: 5| Step: 9
Training loss: 2.3754286766052246
Validation loss: 2.578086826109117

Epoch: 5| Step: 10
Training loss: 2.5821516513824463
Validation loss: 2.5798988214103122

Epoch: 109| Step: 0
Training loss: 2.718092441558838
Validation loss: 2.5723360533355386

Epoch: 5| Step: 1
Training loss: 1.7837326526641846
Validation loss: 2.57001825558242

Epoch: 5| Step: 2
Training loss: 3.552633285522461
Validation loss: 2.562794344399565

Epoch: 5| Step: 3
Training loss: 2.9983859062194824
Validation loss: 2.5578049946856756

Epoch: 5| Step: 4
Training loss: 2.9649405479431152
Validation loss: 2.562494977827995

Epoch: 5| Step: 5
Training loss: 2.1971163749694824
Validation loss: 2.5666538310307327

Epoch: 5| Step: 6
Training loss: 2.4235901832580566
Validation loss: 2.5669309400743052

Epoch: 5| Step: 7
Training loss: 2.842585325241089
Validation loss: 2.573450776838487

Epoch: 5| Step: 8
Training loss: 3.14382266998291
Validation loss: 2.570899445523498

Epoch: 5| Step: 9
Training loss: 3.7558281421661377
Validation loss: 2.5748340980980986

Epoch: 5| Step: 10
Training loss: 1.648219108581543
Validation loss: 2.570744970793365

Epoch: 110| Step: 0
Training loss: 3.232543468475342
Validation loss: 2.5766941321793424

Epoch: 5| Step: 1
Training loss: 2.593867778778076
Validation loss: 2.575168225073045

Epoch: 5| Step: 2
Training loss: 3.213672637939453
Validation loss: 2.570023759718864

Epoch: 5| Step: 3
Training loss: 2.7284984588623047
Validation loss: 2.565777558152394

Epoch: 5| Step: 4
Training loss: 2.5164883136749268
Validation loss: 2.5615871439697924

Epoch: 5| Step: 5
Training loss: 2.7993483543395996
Validation loss: 2.556793761509721

Epoch: 5| Step: 6
Training loss: 2.7332663536071777
Validation loss: 2.5627406233100483

Epoch: 5| Step: 7
Training loss: 2.5555028915405273
Validation loss: 2.568549084407027

Epoch: 5| Step: 8
Training loss: 2.8436648845672607
Validation loss: 2.5760957425640476

Epoch: 5| Step: 9
Training loss: 2.4848744869232178
Validation loss: 2.572820976216306

Epoch: 5| Step: 10
Training loss: 2.3225157260894775
Validation loss: 2.5669117973696802

Epoch: 111| Step: 0
Training loss: 2.8410327434539795
Validation loss: 2.5736100135311

Epoch: 5| Step: 1
Training loss: 3.270799160003662
Validation loss: 2.569830035650602

Epoch: 5| Step: 2
Training loss: 2.9232726097106934
Validation loss: 2.5672084182821293

Epoch: 5| Step: 3
Training loss: 2.3041138648986816
Validation loss: 2.574422646594304

Epoch: 5| Step: 4
Training loss: 2.219287395477295
Validation loss: 2.5699063629232426

Epoch: 5| Step: 5
Training loss: 2.7055470943450928
Validation loss: 2.570208611026887

Epoch: 5| Step: 6
Training loss: 2.7154905796051025
Validation loss: 2.57179384205931

Epoch: 5| Step: 7
Training loss: 2.0614256858825684
Validation loss: 2.568091238698652

Epoch: 5| Step: 8
Training loss: 2.7125866413116455
Validation loss: 2.570510579693702

Epoch: 5| Step: 9
Training loss: 2.927377700805664
Validation loss: 2.570716747673609

Epoch: 5| Step: 10
Training loss: 3.519724130630493
Validation loss: 2.5650341920955206

Epoch: 112| Step: 0
Training loss: 2.0297250747680664
Validation loss: 2.557084534757881

Epoch: 5| Step: 1
Training loss: 3.218597888946533
Validation loss: 2.554992793708719

Epoch: 5| Step: 2
Training loss: 2.9773013591766357
Validation loss: 2.556120623824417

Epoch: 5| Step: 3
Training loss: 3.4711456298828125
Validation loss: 2.5603972455506683

Epoch: 5| Step: 4
Training loss: 2.5491275787353516
Validation loss: 2.5652297414759153

Epoch: 5| Step: 5
Training loss: 2.7777984142303467
Validation loss: 2.5682390530904136

Epoch: 5| Step: 6
Training loss: 2.294908285140991
Validation loss: 2.5671783595956783

Epoch: 5| Step: 7
Training loss: 3.0204060077667236
Validation loss: 2.5683433830097155

Epoch: 5| Step: 8
Training loss: 2.2117557525634766
Validation loss: 2.5604648410633044

Epoch: 5| Step: 9
Training loss: 2.6367669105529785
Validation loss: 2.556172970802553

Epoch: 5| Step: 10
Training loss: 2.9479472637176514
Validation loss: 2.5563988583062285

Epoch: 113| Step: 0
Training loss: 1.7882392406463623
Validation loss: 2.551224095847017

Epoch: 5| Step: 1
Training loss: 2.924163341522217
Validation loss: 2.5481235365713797

Epoch: 5| Step: 2
Training loss: 2.3969480991363525
Validation loss: 2.549813949933616

Epoch: 5| Step: 3
Training loss: 2.407834529876709
Validation loss: 2.551656189785209

Epoch: 5| Step: 4
Training loss: 3.2747738361358643
Validation loss: 2.550120743372107

Epoch: 5| Step: 5
Training loss: 3.117964029312134
Validation loss: 2.550765075991231

Epoch: 5| Step: 6
Training loss: 2.9484424591064453
Validation loss: 2.548714345501315

Epoch: 5| Step: 7
Training loss: 2.326571226119995
Validation loss: 2.5507576773243565

Epoch: 5| Step: 8
Training loss: 2.8139808177948
Validation loss: 2.5535566934975247

Epoch: 5| Step: 9
Training loss: 3.4319236278533936
Validation loss: 2.5516190836506505

Epoch: 5| Step: 10
Training loss: 2.6006038188934326
Validation loss: 2.5552181684842674

Epoch: 114| Step: 0
Training loss: 3.7381012439727783
Validation loss: 2.557083768229331

Epoch: 5| Step: 1
Training loss: 2.8683910369873047
Validation loss: 2.5590121310244323

Epoch: 5| Step: 2
Training loss: 3.064236879348755
Validation loss: 2.560518862098776

Epoch: 5| Step: 3
Training loss: 3.1246440410614014
Validation loss: 2.56244037740974

Epoch: 5| Step: 4
Training loss: 3.0092592239379883
Validation loss: 2.5571886647132134

Epoch: 5| Step: 5
Training loss: 2.535919427871704
Validation loss: 2.552621505593741

Epoch: 5| Step: 6
Training loss: 2.3475756645202637
Validation loss: 2.5653241936878493

Epoch: 5| Step: 7
Training loss: 2.803158760070801
Validation loss: 2.5672457397625013

Epoch: 5| Step: 8
Training loss: 1.541583776473999
Validation loss: 2.566585340807515

Epoch: 5| Step: 9
Training loss: 2.283503293991089
Validation loss: 2.5730580078658236

Epoch: 5| Step: 10
Training loss: 2.843785524368286
Validation loss: 2.579797124349943

Epoch: 115| Step: 0
Training loss: 2.282099485397339
Validation loss: 2.588076860673966

Epoch: 5| Step: 1
Training loss: 2.940183401107788
Validation loss: 2.6039114357322775

Epoch: 5| Step: 2
Training loss: 3.042029857635498
Validation loss: 2.620802423005463

Epoch: 5| Step: 3
Training loss: 2.2921254634857178
Validation loss: 2.6346481769315657

Epoch: 5| Step: 4
Training loss: 2.7214341163635254
Validation loss: 2.6322326788338284

Epoch: 5| Step: 5
Training loss: 2.9859671592712402
Validation loss: 2.617346691828902

Epoch: 5| Step: 6
Training loss: 2.7761528491973877
Validation loss: 2.6081962123993905

Epoch: 5| Step: 7
Training loss: 2.816275119781494
Validation loss: 2.5651878490242908

Epoch: 5| Step: 8
Training loss: 2.480584144592285
Validation loss: 2.547972732974637

Epoch: 5| Step: 9
Training loss: 2.449958324432373
Validation loss: 2.5478028174369567

Epoch: 5| Step: 10
Training loss: 3.6417155265808105
Validation loss: 2.546536473817723

Epoch: 116| Step: 0
Training loss: 2.567709445953369
Validation loss: 2.5576378248071157

Epoch: 5| Step: 1
Training loss: 3.1506738662719727
Validation loss: 2.5563865605221

Epoch: 5| Step: 2
Training loss: 2.5959630012512207
Validation loss: 2.55669145430288

Epoch: 5| Step: 3
Training loss: 2.3217601776123047
Validation loss: 2.557349422926544

Epoch: 5| Step: 4
Training loss: 3.5582549571990967
Validation loss: 2.551320086243332

Epoch: 5| Step: 5
Training loss: 3.0309395790100098
Validation loss: 2.5460878136337444

Epoch: 5| Step: 6
Training loss: 3.200819492340088
Validation loss: 2.545698742712698

Epoch: 5| Step: 7
Training loss: 2.4402379989624023
Validation loss: 2.546833766404019

Epoch: 5| Step: 8
Training loss: 2.3942389488220215
Validation loss: 2.5461251889505694

Epoch: 5| Step: 9
Training loss: 2.4803943634033203
Validation loss: 2.547501282025409

Epoch: 5| Step: 10
Training loss: 2.3457067012786865
Validation loss: 2.545989462124404

Epoch: 117| Step: 0
Training loss: 2.7307915687561035
Validation loss: 2.552531316716184

Epoch: 5| Step: 1
Training loss: 2.151787281036377
Validation loss: 2.562071472085932

Epoch: 5| Step: 2
Training loss: 2.9119181632995605
Validation loss: 2.570711058955039

Epoch: 5| Step: 3
Training loss: 3.32141375541687
Validation loss: 2.573569159353933

Epoch: 5| Step: 4
Training loss: 2.2245681285858154
Validation loss: 2.5967970022591214

Epoch: 5| Step: 5
Training loss: 3.1431474685668945
Validation loss: 2.6003632237834315

Epoch: 5| Step: 6
Training loss: 2.577690362930298
Validation loss: 2.5914245651614283

Epoch: 5| Step: 7
Training loss: 2.172328472137451
Validation loss: 2.586168855749151

Epoch: 5| Step: 8
Training loss: 3.2371528148651123
Validation loss: 2.5841569541603007

Epoch: 5| Step: 9
Training loss: 3.028563976287842
Validation loss: 2.5727872976692776

Epoch: 5| Step: 10
Training loss: 2.6520965099334717
Validation loss: 2.5669434608951693

Epoch: 118| Step: 0
Training loss: 1.6078811883926392
Validation loss: 2.563768325313445

Epoch: 5| Step: 1
Training loss: 2.864528179168701
Validation loss: 2.564247005729265

Epoch: 5| Step: 2
Training loss: 2.125750780105591
Validation loss: 2.5639394316622006

Epoch: 5| Step: 3
Training loss: 3.447500705718994
Validation loss: 2.5611393451690674

Epoch: 5| Step: 4
Training loss: 2.8360424041748047
Validation loss: 2.5580232092129287

Epoch: 5| Step: 5
Training loss: 2.2755463123321533
Validation loss: 2.5633886244989212

Epoch: 5| Step: 6
Training loss: 2.4703829288482666
Validation loss: 2.567182994657947

Epoch: 5| Step: 7
Training loss: 3.074604034423828
Validation loss: 2.5674886370217926

Epoch: 5| Step: 8
Training loss: 2.8427300453186035
Validation loss: 2.565853431660642

Epoch: 5| Step: 9
Training loss: 3.3371052742004395
Validation loss: 2.5596336472419

Epoch: 5| Step: 10
Training loss: 3.169923782348633
Validation loss: 2.5618315204497306

Epoch: 119| Step: 0
Training loss: 2.2702183723449707
Validation loss: 2.5601131685318483

Epoch: 5| Step: 1
Training loss: 2.3029959201812744
Validation loss: 2.5538784329609205

Epoch: 5| Step: 2
Training loss: 2.3881449699401855
Validation loss: 2.5567908979231313

Epoch: 5| Step: 3
Training loss: 2.600024461746216
Validation loss: 2.55332044119476

Epoch: 5| Step: 4
Training loss: 2.651902437210083
Validation loss: 2.55731786194668

Epoch: 5| Step: 5
Training loss: 2.5141794681549072
Validation loss: 2.554820901604109

Epoch: 5| Step: 6
Training loss: 2.903776168823242
Validation loss: 2.5551748993576213

Epoch: 5| Step: 7
Training loss: 3.1028151512145996
Validation loss: 2.5592930701471146

Epoch: 5| Step: 8
Training loss: 3.674717664718628
Validation loss: 2.5721690526572605

Epoch: 5| Step: 9
Training loss: 2.776854991912842
Validation loss: 2.5624595124234437

Epoch: 5| Step: 10
Training loss: 2.7073113918304443
Validation loss: 2.564307516621005

Epoch: 120| Step: 0
Training loss: 3.1191070079803467
Validation loss: 2.5728569133307344

Epoch: 5| Step: 1
Training loss: 2.720792055130005
Validation loss: 2.560224402335382

Epoch: 5| Step: 2
Training loss: 2.5102367401123047
Validation loss: 2.573335604001117

Epoch: 5| Step: 3
Training loss: 3.0514116287231445
Validation loss: 2.5653951501333587

Epoch: 5| Step: 4
Training loss: 2.527042865753174
Validation loss: 2.5624463250560146

Epoch: 5| Step: 5
Training loss: 2.513612985610962
Validation loss: 2.5676041623597503

Epoch: 5| Step: 6
Training loss: 2.2990376949310303
Validation loss: 2.5612032823665167

Epoch: 5| Step: 7
Training loss: 2.6211941242218018
Validation loss: 2.5645142960292038

Epoch: 5| Step: 8
Training loss: 3.060786247253418
Validation loss: 2.560934799973683

Epoch: 5| Step: 9
Training loss: 2.5880463123321533
Validation loss: 2.559180792941842

Epoch: 5| Step: 10
Training loss: 2.95257830619812
Validation loss: 2.5596256973922893

Epoch: 121| Step: 0
Training loss: 2.7524123191833496
Validation loss: 2.553179684505668

Epoch: 5| Step: 1
Training loss: 2.9872868061065674
Validation loss: 2.5534962915605113

Epoch: 5| Step: 2
Training loss: 3.001009464263916
Validation loss: 2.5531115480648574

Epoch: 5| Step: 3
Training loss: 2.430009126663208
Validation loss: 2.5531517972228346

Epoch: 5| Step: 4
Training loss: 2.3520667552948
Validation loss: 2.5536062717437744

Epoch: 5| Step: 5
Training loss: 2.9248805046081543
Validation loss: 2.5518402899465253

Epoch: 5| Step: 6
Training loss: 2.4168314933776855
Validation loss: 2.556339345952516

Epoch: 5| Step: 7
Training loss: 2.9770004749298096
Validation loss: 2.5531105841359785

Epoch: 5| Step: 8
Training loss: 2.900724411010742
Validation loss: 2.554893878198439

Epoch: 5| Step: 9
Training loss: 2.517796277999878
Validation loss: 2.5518551231712423

Epoch: 5| Step: 10
Training loss: 2.545888900756836
Validation loss: 2.555861980684342

Epoch: 122| Step: 0
Training loss: 2.6305384635925293
Validation loss: 2.556836953727148

Epoch: 5| Step: 1
Training loss: 2.269315004348755
Validation loss: 2.554301274720059

Epoch: 5| Step: 2
Training loss: 2.940638303756714
Validation loss: 2.554673833231772

Epoch: 5| Step: 3
Training loss: 2.635897636413574
Validation loss: 2.5516151100076656

Epoch: 5| Step: 4
Training loss: 3.236060380935669
Validation loss: 2.547774286680324

Epoch: 5| Step: 5
Training loss: 2.3934319019317627
Validation loss: 2.5464193244134226

Epoch: 5| Step: 6
Training loss: 2.3442068099975586
Validation loss: 2.5440470582695416

Epoch: 5| Step: 7
Training loss: 3.0941100120544434
Validation loss: 2.544529922546879

Epoch: 5| Step: 8
Training loss: 2.8430449962615967
Validation loss: 2.5488658002627793

Epoch: 5| Step: 9
Training loss: 1.9876339435577393
Validation loss: 2.5567042699424167

Epoch: 5| Step: 10
Training loss: 3.6008596420288086
Validation loss: 2.5579360633768062

Epoch: 123| Step: 0
Training loss: 3.0042757987976074
Validation loss: 2.561491068973336

Epoch: 5| Step: 1
Training loss: 2.5271286964416504
Validation loss: 2.5510381652462866

Epoch: 5| Step: 2
Training loss: 2.367745876312256
Validation loss: 2.55752759082343

Epoch: 5| Step: 3
Training loss: 2.4069299697875977
Validation loss: 2.5553255029903945

Epoch: 5| Step: 4
Training loss: 2.688591480255127
Validation loss: 2.5564418300505607

Epoch: 5| Step: 5
Training loss: 3.3519184589385986
Validation loss: 2.559438728517102

Epoch: 5| Step: 6
Training loss: 2.536961078643799
Validation loss: 2.5593006546779344

Epoch: 5| Step: 7
Training loss: 2.944819211959839
Validation loss: 2.5675426349844983

Epoch: 5| Step: 8
Training loss: 2.8685460090637207
Validation loss: 2.5689786018863803

Epoch: 5| Step: 9
Training loss: 2.631312608718872
Validation loss: 2.5722289085388184

Epoch: 5| Step: 10
Training loss: 2.557058811187744
Validation loss: 2.573008934656779

Epoch: 124| Step: 0
Training loss: 2.65035343170166
Validation loss: 2.5675157654669976

Epoch: 5| Step: 1
Training loss: 2.860947608947754
Validation loss: 2.5648877236150924

Epoch: 5| Step: 2
Training loss: 3.1714553833007812
Validation loss: 2.564167562351432

Epoch: 5| Step: 3
Training loss: 2.2778854370117188
Validation loss: 2.570317929790866

Epoch: 5| Step: 4
Training loss: 2.687373638153076
Validation loss: 2.561910080653365

Epoch: 5| Step: 5
Training loss: 2.374098777770996
Validation loss: 2.560483568458147

Epoch: 5| Step: 6
Training loss: 3.2563400268554688
Validation loss: 2.5570949251933763

Epoch: 5| Step: 7
Training loss: 2.1779696941375732
Validation loss: 2.5486518144607544

Epoch: 5| Step: 8
Training loss: 3.10416579246521
Validation loss: 2.5497364715863298

Epoch: 5| Step: 9
Training loss: 2.8177385330200195
Validation loss: 2.5485116281817035

Epoch: 5| Step: 10
Training loss: 2.4214248657226562
Validation loss: 2.5449504185748357

Epoch: 125| Step: 0
Training loss: 3.085101366043091
Validation loss: 2.548954645792643

Epoch: 5| Step: 1
Training loss: 2.808835029602051
Validation loss: 2.554025447496804

Epoch: 5| Step: 2
Training loss: 2.093013286590576
Validation loss: 2.552649644113356

Epoch: 5| Step: 3
Training loss: 2.99735426902771
Validation loss: 2.556461793120189

Epoch: 5| Step: 4
Training loss: 2.766092300415039
Validation loss: 2.556618936600224

Epoch: 5| Step: 5
Training loss: 2.8058409690856934
Validation loss: 2.546656841872841

Epoch: 5| Step: 6
Training loss: 2.737112522125244
Validation loss: 2.5475005334423435

Epoch: 5| Step: 7
Training loss: 2.8906266689300537
Validation loss: 2.546997067748859

Epoch: 5| Step: 8
Training loss: 2.1393823623657227
Validation loss: 2.552761480372439

Epoch: 5| Step: 9
Training loss: 2.4711971282958984
Validation loss: 2.550788184647919

Epoch: 5| Step: 10
Training loss: 3.0857131481170654
Validation loss: 2.5428459798136065

Testing loss: 2.66142037179735
