Epoch: 1| Step: 0
Training loss: 5.70660110513217
Validation loss: 5.748197006246281

Epoch: 6| Step: 1
Training loss: 5.914048954533695
Validation loss: 5.74408073765205

Epoch: 6| Step: 2
Training loss: 5.287717932861018
Validation loss: 5.739748883283446

Epoch: 6| Step: 3
Training loss: 6.264868788140514
Validation loss: 5.735669515931429

Epoch: 6| Step: 4
Training loss: 6.4363520811709
Validation loss: 5.731252639195018

Epoch: 6| Step: 5
Training loss: 5.955084210496235
Validation loss: 5.72663015587441

Epoch: 6| Step: 6
Training loss: 5.957296036635684
Validation loss: 5.722502839576097

Epoch: 6| Step: 7
Training loss: 5.517466121650812
Validation loss: 5.717614853631523

Epoch: 6| Step: 8
Training loss: 5.615534808538995
Validation loss: 5.712998499090665

Epoch: 6| Step: 9
Training loss: 5.157183013657024
Validation loss: 5.708120876400811

Epoch: 6| Step: 10
Training loss: 5.592316001487939
Validation loss: 5.703095723907357

Epoch: 6| Step: 11
Training loss: 4.867547035714956
Validation loss: 5.697280967407949

Epoch: 6| Step: 12
Training loss: 5.343730011841273
Validation loss: 5.692284689188145

Epoch: 6| Step: 13
Training loss: 7.348382535709017
Validation loss: 5.686063965395216

Epoch: 2| Step: 0
Training loss: 6.437627105939498
Validation loss: 5.680318339420895

Epoch: 6| Step: 1
Training loss: 4.886469333787825
Validation loss: 5.673891056389472

Epoch: 6| Step: 2
Training loss: 6.611425347789577
Validation loss: 5.667510168330779

Epoch: 6| Step: 3
Training loss: 5.529467106782113
Validation loss: 5.660191096325805

Epoch: 6| Step: 4
Training loss: 5.6260873379401835
Validation loss: 5.653605391574631

Epoch: 6| Step: 5
Training loss: 4.708373123045827
Validation loss: 5.645163660239383

Epoch: 6| Step: 6
Training loss: 6.9889171603139255
Validation loss: 5.637280198721232

Epoch: 6| Step: 7
Training loss: 5.787938882817481
Validation loss: 5.628932029783103

Epoch: 6| Step: 8
Training loss: 4.574194565211471
Validation loss: 5.620554541263321

Epoch: 6| Step: 9
Training loss: 4.900617926424281
Validation loss: 5.611436023576171

Epoch: 6| Step: 10
Training loss: 5.958211012787344
Validation loss: 5.601274564391922

Epoch: 6| Step: 11
Training loss: 5.79464308553767
Validation loss: 5.591412382406717

Epoch: 6| Step: 12
Training loss: 5.890414206378451
Validation loss: 5.580677575690556

Epoch: 6| Step: 13
Training loss: 4.594287451619713
Validation loss: 5.568940332771432

Epoch: 3| Step: 0
Training loss: 5.3660827121566115
Validation loss: 5.556778165492384

Epoch: 6| Step: 1
Training loss: 5.302999101357093
Validation loss: 5.544169278228803

Epoch: 6| Step: 2
Training loss: 5.556757330716422
Validation loss: 5.5320732403687325

Epoch: 6| Step: 3
Training loss: 4.624841223388402
Validation loss: 5.518813612835427

Epoch: 6| Step: 4
Training loss: 5.7357329130252
Validation loss: 5.504293162689626

Epoch: 6| Step: 5
Training loss: 5.967993563507945
Validation loss: 5.489930052532541

Epoch: 6| Step: 6
Training loss: 5.929581350952072
Validation loss: 5.473580830648024

Epoch: 6| Step: 7
Training loss: 6.135586678481542
Validation loss: 5.457532902750128

Epoch: 6| Step: 8
Training loss: 4.240647740819644
Validation loss: 5.439577419865196

Epoch: 6| Step: 9
Training loss: 5.754217176977614
Validation loss: 5.4213965590425595

Epoch: 6| Step: 10
Training loss: 6.006845066471075
Validation loss: 5.40339140175289

Epoch: 6| Step: 11
Training loss: 5.341382310810038
Validation loss: 5.383416081442154

Epoch: 6| Step: 12
Training loss: 4.722213989450097
Validation loss: 5.3629488050923495

Epoch: 6| Step: 13
Training loss: 6.299386179252036
Validation loss: 5.3422982844733085

Epoch: 4| Step: 0
Training loss: 5.096499584412425
Validation loss: 5.321307979670836

Epoch: 6| Step: 1
Training loss: 5.885079685342589
Validation loss: 5.29877539688832

Epoch: 6| Step: 2
Training loss: 4.820775632697052
Validation loss: 5.276279174886661

Epoch: 6| Step: 3
Training loss: 5.055694526932793
Validation loss: 5.251856792458549

Epoch: 6| Step: 4
Training loss: 5.562226878115268
Validation loss: 5.227839345044464

Epoch: 6| Step: 5
Training loss: 5.194755902985391
Validation loss: 5.204780764267246

Epoch: 6| Step: 6
Training loss: 5.1743856830212485
Validation loss: 5.178231617954409

Epoch: 6| Step: 7
Training loss: 6.189132012812579
Validation loss: 5.153904419823426

Epoch: 6| Step: 8
Training loss: 3.970059396602125
Validation loss: 5.127877560827174

Epoch: 6| Step: 9
Training loss: 4.676537066236594
Validation loss: 5.1023605268499965

Epoch: 6| Step: 10
Training loss: 5.858076027889631
Validation loss: 5.077635867255391

Epoch: 6| Step: 11
Training loss: 5.594324178370012
Validation loss: 5.050743153450637

Epoch: 6| Step: 12
Training loss: 5.157990133097849
Validation loss: 5.025855787732403

Epoch: 6| Step: 13
Training loss: 3.781224022137649
Validation loss: 5.000565027285081

Epoch: 5| Step: 0
Training loss: 5.677181735337938
Validation loss: 4.975134257228571

Epoch: 6| Step: 1
Training loss: 5.161853127212085
Validation loss: 4.950191110365007

Epoch: 6| Step: 2
Training loss: 5.180387101603599
Validation loss: 4.925773030989728

Epoch: 6| Step: 3
Training loss: 4.772437657408178
Validation loss: 4.902245339726008

Epoch: 6| Step: 4
Training loss: 4.739338806328051
Validation loss: 4.876546866220455

Epoch: 6| Step: 5
Training loss: 5.2760149950995805
Validation loss: 4.852608155331271

Epoch: 6| Step: 6
Training loss: 5.652623652742671
Validation loss: 4.829981768802194

Epoch: 6| Step: 7
Training loss: 4.891674380104097
Validation loss: 4.805577999322362

Epoch: 6| Step: 8
Training loss: 3.453610209211927
Validation loss: 4.7835107239144135

Epoch: 6| Step: 9
Training loss: 5.122355825723382
Validation loss: 4.762427910342657

Epoch: 6| Step: 10
Training loss: 4.086607781422104
Validation loss: 4.742887840516177

Epoch: 6| Step: 11
Training loss: 4.329882543790025
Validation loss: 4.72145776192864

Epoch: 6| Step: 12
Training loss: 5.43879789450127
Validation loss: 4.701550991996164

Epoch: 6| Step: 13
Training loss: 3.897807527146095
Validation loss: 4.684311648873582

Epoch: 6| Step: 0
Training loss: 5.035820253565521
Validation loss: 4.666662274781957

Epoch: 6| Step: 1
Training loss: 4.7278998382466995
Validation loss: 4.6518843670012835

Epoch: 6| Step: 2
Training loss: 3.704671416133106
Validation loss: 4.635060088031917

Epoch: 6| Step: 3
Training loss: 4.94248170269448
Validation loss: 4.621328391456786

Epoch: 6| Step: 4
Training loss: 4.7856893437107715
Validation loss: 4.607561844740128

Epoch: 6| Step: 5
Training loss: 5.192857847927688
Validation loss: 4.592764496402376

Epoch: 6| Step: 6
Training loss: 4.943437892933818
Validation loss: 4.580283943622797

Epoch: 6| Step: 7
Training loss: 4.102129797077405
Validation loss: 4.568278269046541

Epoch: 6| Step: 8
Training loss: 5.170160199455826
Validation loss: 4.555817465394346

Epoch: 6| Step: 9
Training loss: 3.926549428302518
Validation loss: 4.544522495730934

Epoch: 6| Step: 10
Training loss: 5.307357632941774
Validation loss: 4.533764403427891

Epoch: 6| Step: 11
Training loss: 3.712927355075424
Validation loss: 4.522325223744242

Epoch: 6| Step: 12
Training loss: 4.650671978049205
Validation loss: 4.513573853274616

Epoch: 6| Step: 13
Training loss: 4.946214542411251
Validation loss: 4.502476517770825

Epoch: 7| Step: 0
Training loss: 4.11081777562857
Validation loss: 4.492306719852509

Epoch: 6| Step: 1
Training loss: 4.522979555025181
Validation loss: 4.484717635364109

Epoch: 6| Step: 2
Training loss: 4.624083144578881
Validation loss: 4.475339504023371

Epoch: 6| Step: 3
Training loss: 5.379844079576716
Validation loss: 4.466764045930909

Epoch: 6| Step: 4
Training loss: 4.150801450255524
Validation loss: 4.457106288680042

Epoch: 6| Step: 5
Training loss: 4.57366163345133
Validation loss: 4.4479857343315246

Epoch: 6| Step: 6
Training loss: 5.271562528366568
Validation loss: 4.441777364448078

Epoch: 6| Step: 7
Training loss: 4.006341437428522
Validation loss: 4.431437703775649

Epoch: 6| Step: 8
Training loss: 3.480612189936684
Validation loss: 4.423496270454104

Epoch: 6| Step: 9
Training loss: 3.7677102547787356
Validation loss: 4.416838070094957

Epoch: 6| Step: 10
Training loss: 4.273491058850846
Validation loss: 4.40910010843303

Epoch: 6| Step: 11
Training loss: 5.329980432070084
Validation loss: 4.402577728477701

Epoch: 6| Step: 12
Training loss: 5.053123928015695
Validation loss: 4.39413534282927

Epoch: 6| Step: 13
Training loss: 4.691391613736536
Validation loss: 4.386777526019311

Epoch: 8| Step: 0
Training loss: 3.944153024238953
Validation loss: 4.379239804585498

Epoch: 6| Step: 1
Training loss: 4.378615928642466
Validation loss: 4.372023171804256

Epoch: 6| Step: 2
Training loss: 3.4444404588354973
Validation loss: 4.3656959596689475

Epoch: 6| Step: 3
Training loss: 5.181946873017456
Validation loss: 4.3582536949907

Epoch: 6| Step: 4
Training loss: 4.380133750301722
Validation loss: 4.352173624007424

Epoch: 6| Step: 5
Training loss: 4.668497044503832
Validation loss: 4.344945866179714

Epoch: 6| Step: 6
Training loss: 3.6745747482373115
Validation loss: 4.337383482868328

Epoch: 6| Step: 7
Training loss: 5.015181001874946
Validation loss: 4.330636538130345

Epoch: 6| Step: 8
Training loss: 4.765958380372962
Validation loss: 4.324459808167125

Epoch: 6| Step: 9
Training loss: 5.482903698879947
Validation loss: 4.317362945258789

Epoch: 6| Step: 10
Training loss: 4.437028027002122
Validation loss: 4.309417552735377

Epoch: 6| Step: 11
Training loss: 4.17384274827808
Validation loss: 4.302719770318319

Epoch: 6| Step: 12
Training loss: 4.516913523854804
Validation loss: 4.2954501853248

Epoch: 6| Step: 13
Training loss: 3.2358048821226006
Validation loss: 4.287026890112015

Epoch: 9| Step: 0
Training loss: 5.039418100037673
Validation loss: 4.279187908172408

Epoch: 6| Step: 1
Training loss: 3.7850874667221768
Validation loss: 4.269888524500954

Epoch: 6| Step: 2
Training loss: 4.637187673739804
Validation loss: 4.261789087560061

Epoch: 6| Step: 3
Training loss: 4.922536654125193
Validation loss: 4.253011501535898

Epoch: 6| Step: 4
Training loss: 4.674175601832124
Validation loss: 4.247266564777691

Epoch: 6| Step: 5
Training loss: 3.2393370081892545
Validation loss: 4.240286365341697

Epoch: 6| Step: 6
Training loss: 4.475240622077017
Validation loss: 4.233139947148486

Epoch: 6| Step: 7
Training loss: 3.8098335321859866
Validation loss: 4.225802329041913

Epoch: 6| Step: 8
Training loss: 3.7637400361141102
Validation loss: 4.219401494519263

Epoch: 6| Step: 9
Training loss: 4.43464568846285
Validation loss: 4.2138824225726506

Epoch: 6| Step: 10
Training loss: 3.986167115731117
Validation loss: 4.2082074021721505

Epoch: 6| Step: 11
Training loss: 4.710080703076349
Validation loss: 4.203488067500609

Epoch: 6| Step: 12
Training loss: 4.677431406550852
Validation loss: 4.196087842854612

Epoch: 6| Step: 13
Training loss: 4.617918831212285
Validation loss: 4.188487194141519

Epoch: 10| Step: 0
Training loss: 4.709258987222961
Validation loss: 4.182469549073928

Epoch: 6| Step: 1
Training loss: 4.154193799776153
Validation loss: 4.175587248278759

Epoch: 6| Step: 2
Training loss: 3.2441782527167633
Validation loss: 4.167689774121844

Epoch: 6| Step: 3
Training loss: 4.777862346009155
Validation loss: 4.16026824580115

Epoch: 6| Step: 4
Training loss: 3.9511267395006047
Validation loss: 4.151606743379618

Epoch: 6| Step: 5
Training loss: 4.404599144283867
Validation loss: 4.142770734334743

Epoch: 6| Step: 6
Training loss: 4.912511244122787
Validation loss: 4.134325059399021

Epoch: 6| Step: 7
Training loss: 4.927292134522842
Validation loss: 4.121695623481753

Epoch: 6| Step: 8
Training loss: 3.6813214798676257
Validation loss: 4.112293031014359

Epoch: 6| Step: 9
Training loss: 2.9027102663827757
Validation loss: 4.1037946879885325

Epoch: 6| Step: 10
Training loss: 5.264022628619594
Validation loss: 4.095339389755048

Epoch: 6| Step: 11
Training loss: 4.263718399024687
Validation loss: 4.085386825117613

Epoch: 6| Step: 12
Training loss: 3.644918897482641
Validation loss: 4.076770301453882

Epoch: 6| Step: 13
Training loss: 4.123058208845744
Validation loss: 4.067812908884468

Epoch: 11| Step: 0
Training loss: 5.122065937051277
Validation loss: 4.058568769137632

Epoch: 6| Step: 1
Training loss: 4.103288559802355
Validation loss: 4.049263988336179

Epoch: 6| Step: 2
Training loss: 4.58375385551613
Validation loss: 4.042283542107163

Epoch: 6| Step: 3
Training loss: 4.022690787049496
Validation loss: 4.031719419864929

Epoch: 6| Step: 4
Training loss: 3.9195902579117874
Validation loss: 4.025892850341441

Epoch: 6| Step: 5
Training loss: 3.9375242202256078
Validation loss: 4.02013876848366

Epoch: 6| Step: 6
Training loss: 4.895610181984987
Validation loss: 4.011493298735089

Epoch: 6| Step: 7
Training loss: 3.227776176757182
Validation loss: 4.004794500643987

Epoch: 6| Step: 8
Training loss: 4.513747725928554
Validation loss: 4.001116830002153

Epoch: 6| Step: 9
Training loss: 3.7631797607370676
Validation loss: 3.99097974130743

Epoch: 6| Step: 10
Training loss: 4.276277870905868
Validation loss: 3.987034551582843

Epoch: 6| Step: 11
Training loss: 3.525843710063997
Validation loss: 3.9783216310509566

Epoch: 6| Step: 12
Training loss: 4.250931132919725
Validation loss: 3.9720907119018767

Epoch: 6| Step: 13
Training loss: 3.324028108287452
Validation loss: 3.968205346201721

Epoch: 12| Step: 0
Training loss: 3.791969049713726
Validation loss: 3.9628824208562903

Epoch: 6| Step: 1
Training loss: 3.6796802431589803
Validation loss: 3.9561642885283024

Epoch: 6| Step: 2
Training loss: 4.0973723015894015
Validation loss: 3.948693310128642

Epoch: 6| Step: 3
Training loss: 4.814502646170263
Validation loss: 3.943411201899101

Epoch: 6| Step: 4
Training loss: 3.6561081035499687
Validation loss: 3.9362721596777357

Epoch: 6| Step: 5
Training loss: 4.834907187800861
Validation loss: 3.9311792464944957

Epoch: 6| Step: 6
Training loss: 4.045566892378977
Validation loss: 3.9215826567743326

Epoch: 6| Step: 7
Training loss: 3.944016166205092
Validation loss: 3.916485437735482

Epoch: 6| Step: 8
Training loss: 3.4835069883825915
Validation loss: 3.9105697511049855

Epoch: 6| Step: 9
Training loss: 4.695778009629784
Validation loss: 3.9045145779613857

Epoch: 6| Step: 10
Training loss: 4.048582210332199
Validation loss: 3.8965131241023117

Epoch: 6| Step: 11
Training loss: 3.482150201475342
Validation loss: 3.8864815251916656

Epoch: 6| Step: 12
Training loss: 4.347386875358917
Validation loss: 3.8824453631964606

Epoch: 6| Step: 13
Training loss: 3.6529583582140246
Validation loss: 3.879177740503384

Epoch: 13| Step: 0
Training loss: 3.913829560496124
Validation loss: 3.8723930351539115

Epoch: 6| Step: 1
Training loss: 4.373576777435718
Validation loss: 3.868380653673809

Epoch: 6| Step: 2
Training loss: 4.470120093249318
Validation loss: 3.8576047830661038

Epoch: 6| Step: 3
Training loss: 3.65232259978836
Validation loss: 3.849183782571301

Epoch: 6| Step: 4
Training loss: 4.130996968748652
Validation loss: 3.844988783637543

Epoch: 6| Step: 5
Training loss: 3.5933553727794596
Validation loss: 3.8376755368870104

Epoch: 6| Step: 6
Training loss: 3.8939190137500974
Validation loss: 3.829278815151172

Epoch: 6| Step: 7
Training loss: 4.586564237278875
Validation loss: 3.8253088089532348

Epoch: 6| Step: 8
Training loss: 3.682650076092864
Validation loss: 3.814289163402151

Epoch: 6| Step: 9
Training loss: 4.642957724016228
Validation loss: 3.8103614550470852

Epoch: 6| Step: 10
Training loss: 4.289347765943226
Validation loss: 3.804276434161569

Epoch: 6| Step: 11
Training loss: 3.7250113467869337
Validation loss: 3.798740369141284

Epoch: 6| Step: 12
Training loss: 3.1070693779385956
Validation loss: 3.7914428514162943

Epoch: 6| Step: 13
Training loss: 3.2642711406548193
Validation loss: 3.788261008270995

Epoch: 14| Step: 0
Training loss: 3.7826299750164654
Validation loss: 3.7814189724316103

Epoch: 6| Step: 1
Training loss: 4.04159378038473
Validation loss: 3.7762507102508263

Epoch: 6| Step: 2
Training loss: 3.40890651319784
Validation loss: 3.769490623605868

Epoch: 6| Step: 3
Training loss: 3.872126344369178
Validation loss: 3.763394049222965

Epoch: 6| Step: 4
Training loss: 3.9839629315486373
Validation loss: 3.762311709092184

Epoch: 6| Step: 5
Training loss: 3.983350794180637
Validation loss: 3.7523514515780647

Epoch: 6| Step: 6
Training loss: 4.789966491709437
Validation loss: 3.74919368319941

Epoch: 6| Step: 7
Training loss: 3.512205096588599
Validation loss: 3.7436009107160566

Epoch: 6| Step: 8
Training loss: 4.0633989953318235
Validation loss: 3.7417533561537204

Epoch: 6| Step: 9
Training loss: 3.6549646449433864
Validation loss: 3.7348361017903677

Epoch: 6| Step: 10
Training loss: 3.840869103070156
Validation loss: 3.7276347241279537

Epoch: 6| Step: 11
Training loss: 3.9289830450448004
Validation loss: 3.7234493601663066

Epoch: 6| Step: 12
Training loss: 3.6326741510114497
Validation loss: 3.717388894973306

Epoch: 6| Step: 13
Training loss: 4.4975394833640925
Validation loss: 3.7124668647295866

Epoch: 15| Step: 0
Training loss: 4.076297745271495
Validation loss: 3.7062010036599102

Epoch: 6| Step: 1
Training loss: 3.505317735405374
Validation loss: 3.70266933778151

Epoch: 6| Step: 2
Training loss: 3.8409704067020787
Validation loss: 3.699603712105525

Epoch: 6| Step: 3
Training loss: 4.4597127806549945
Validation loss: 3.6940016162824207

Epoch: 6| Step: 4
Training loss: 4.329882103281833
Validation loss: 3.6864043468289203

Epoch: 6| Step: 5
Training loss: 2.497646272822532
Validation loss: 3.6820959374594566

Epoch: 6| Step: 6
Training loss: 3.6739963328717518
Validation loss: 3.6796621720577725

Epoch: 6| Step: 7
Training loss: 3.2997101800982525
Validation loss: 3.674803080168504

Epoch: 6| Step: 8
Training loss: 2.779115179024376
Validation loss: 3.67412228695471

Epoch: 6| Step: 9
Training loss: 5.009936187398662
Validation loss: 3.6673438550626427

Epoch: 6| Step: 10
Training loss: 4.003434613990354
Validation loss: 3.663992805044634

Epoch: 6| Step: 11
Training loss: 4.454418757376146
Validation loss: 3.6568094475337305

Epoch: 6| Step: 12
Training loss: 4.251826623060771
Validation loss: 3.653759362133753

Epoch: 6| Step: 13
Training loss: 2.202078279785979
Validation loss: 3.6496319414285403

Epoch: 16| Step: 0
Training loss: 4.397703065418004
Validation loss: 3.646682119171607

Epoch: 6| Step: 1
Training loss: 4.285877038499325
Validation loss: 3.6396908118461733

Epoch: 6| Step: 2
Training loss: 3.0899838730474563
Validation loss: 3.6364758377137285

Epoch: 6| Step: 3
Training loss: 3.7280338349751116
Validation loss: 3.6326077904054386

Epoch: 6| Step: 4
Training loss: 3.8899574779549777
Validation loss: 3.6345605373086074

Epoch: 6| Step: 5
Training loss: 4.124560939657249
Validation loss: 3.626196467562927

Epoch: 6| Step: 6
Training loss: 4.294442670941586
Validation loss: 3.6217082576189763

Epoch: 6| Step: 7
Training loss: 3.6675013690262044
Validation loss: 3.6143099125948237

Epoch: 6| Step: 8
Training loss: 3.02122775605062
Validation loss: 3.6120618481028566

Epoch: 6| Step: 9
Training loss: 4.396375047230184
Validation loss: 3.6088346948689547

Epoch: 6| Step: 10
Training loss: 3.432870417624181
Validation loss: 3.6065867929877573

Epoch: 6| Step: 11
Training loss: 3.6518951303690104
Validation loss: 3.6001472008370454

Epoch: 6| Step: 12
Training loss: 3.7792136013112487
Validation loss: 3.5978845760772327

Epoch: 6| Step: 13
Training loss: 2.8349126640201936
Validation loss: 3.5935790147450275

Epoch: 17| Step: 0
Training loss: 3.474109118314304
Validation loss: 3.5918527682320303

Epoch: 6| Step: 1
Training loss: 3.1976332316256317
Validation loss: 3.588539015779413

Epoch: 6| Step: 2
Training loss: 4.521950696457922
Validation loss: 3.5866158358763562

Epoch: 6| Step: 3
Training loss: 3.140662349649646
Validation loss: 3.5839287925376335

Epoch: 6| Step: 4
Training loss: 3.6316677463828086
Validation loss: 3.580367511940133

Epoch: 6| Step: 5
Training loss: 2.8914232955962027
Validation loss: 3.580018748162513

Epoch: 6| Step: 6
Training loss: 4.280014416679274
Validation loss: 3.5751096468133183

Epoch: 6| Step: 7
Training loss: 3.743136673808943
Validation loss: 3.575502550798231

Epoch: 6| Step: 8
Training loss: 4.2190192242654785
Validation loss: 3.571783378939766

Epoch: 6| Step: 9
Training loss: 4.042340776260212
Validation loss: 3.5671875774441806

Epoch: 6| Step: 10
Training loss: 3.9924677024495185
Validation loss: 3.5653401905093305

Epoch: 6| Step: 11
Training loss: 3.90538564655782
Validation loss: 3.5654724621667127

Epoch: 6| Step: 12
Training loss: 3.6247333560085
Validation loss: 3.560575770451211

Epoch: 6| Step: 13
Training loss: 3.8437910620504243
Validation loss: 3.560141133101809

Epoch: 18| Step: 0
Training loss: 3.6518896463189576
Validation loss: 3.5559915149604606

Epoch: 6| Step: 1
Training loss: 3.7199442252213037
Validation loss: 3.5539080641874192

Epoch: 6| Step: 2
Training loss: 4.099739643297153
Validation loss: 3.550368829193358

Epoch: 6| Step: 3
Training loss: 2.8427070130293535
Validation loss: 3.550925931642217

Epoch: 6| Step: 4
Training loss: 3.8197677629588234
Validation loss: 3.5479056334676096

Epoch: 6| Step: 5
Training loss: 3.916613449925547
Validation loss: 3.5467790384029194

Epoch: 6| Step: 6
Training loss: 4.165141983817758
Validation loss: 3.546194031677293

Epoch: 6| Step: 7
Training loss: 2.9505125731947115
Validation loss: 3.5414624458707524

Epoch: 6| Step: 8
Training loss: 4.495214460813417
Validation loss: 3.5375854695794984

Epoch: 6| Step: 9
Training loss: 3.525470155785741
Validation loss: 3.535750849862264

Epoch: 6| Step: 10
Training loss: 3.4544516384125785
Validation loss: 3.5356534218609914

Epoch: 6| Step: 11
Training loss: 3.241757431001752
Validation loss: 3.5370707372733747

Epoch: 6| Step: 12
Training loss: 4.156492527360645
Validation loss: 3.5344061004444534

Epoch: 6| Step: 13
Training loss: 4.260243580977817
Validation loss: 3.531869672584266

Epoch: 19| Step: 0
Training loss: 3.3047902337016084
Validation loss: 3.5285801211819847

Epoch: 6| Step: 1
Training loss: 3.613481439766856
Validation loss: 3.527426901143988

Epoch: 6| Step: 2
Training loss: 3.650346864914606
Validation loss: 3.523917240077108

Epoch: 6| Step: 3
Training loss: 3.6163102274631918
Validation loss: 3.5241289718349678

Epoch: 6| Step: 4
Training loss: 4.422659113616366
Validation loss: 3.5222665008516647

Epoch: 6| Step: 5
Training loss: 3.7599755166656728
Validation loss: 3.5228513999570215

Epoch: 6| Step: 6
Training loss: 3.374731265071368
Validation loss: 3.5191030811964756

Epoch: 6| Step: 7
Training loss: 2.6851495622291335
Validation loss: 3.520123849999105

Epoch: 6| Step: 8
Training loss: 3.9212320112229833
Validation loss: 3.517688633945904

Epoch: 6| Step: 9
Training loss: 4.345238300281179
Validation loss: 3.5150426603363547

Epoch: 6| Step: 10
Training loss: 3.3046482525742715
Validation loss: 3.5139433162266247

Epoch: 6| Step: 11
Training loss: 4.0574990816520735
Validation loss: 3.512343990963298

Epoch: 6| Step: 12
Training loss: 3.5911613097029114
Validation loss: 3.510720477768075

Epoch: 6| Step: 13
Training loss: 4.51350537879854
Validation loss: 3.5081592242929323

Epoch: 20| Step: 0
Training loss: 4.256124235247295
Validation loss: 3.5064846108679717

Epoch: 6| Step: 1
Training loss: 3.821058079645278
Validation loss: 3.503989467130406

Epoch: 6| Step: 2
Training loss: 4.055179749819326
Validation loss: 3.5036668759605276

Epoch: 6| Step: 3
Training loss: 2.967149323051613
Validation loss: 3.501533250105914

Epoch: 6| Step: 4
Training loss: 3.939968969929686
Validation loss: 3.499925220001205

Epoch: 6| Step: 5
Training loss: 4.216469607567222
Validation loss: 3.499464328047868

Epoch: 6| Step: 6
Training loss: 3.7653403273491386
Validation loss: 3.495737499483199

Epoch: 6| Step: 7
Training loss: 3.427800730527603
Validation loss: 3.4936241272075614

Epoch: 6| Step: 8
Training loss: 3.503353691973514
Validation loss: 3.492666222659982

Epoch: 6| Step: 9
Training loss: 3.5336925869768825
Validation loss: 3.493304273160712

Epoch: 6| Step: 10
Training loss: 3.183987645781813
Validation loss: 3.4918954011373455

Epoch: 6| Step: 11
Training loss: 3.387958515287068
Validation loss: 3.4907191350933693

Epoch: 6| Step: 12
Training loss: 3.9680763934534107
Validation loss: 3.487569477578472

Epoch: 6| Step: 13
Training loss: 3.6435874052068966
Validation loss: 3.4893058645727764

Epoch: 21| Step: 0
Training loss: 3.1591908568195133
Validation loss: 3.488237932989011

Epoch: 6| Step: 1
Training loss: 4.519956629722271
Validation loss: 3.48455830077226

Epoch: 6| Step: 2
Training loss: 3.503398063151203
Validation loss: 3.48177383843274

Epoch: 6| Step: 3
Training loss: 3.737537529288089
Validation loss: 3.4810318574923826

Epoch: 6| Step: 4
Training loss: 3.756897749564605
Validation loss: 3.4808629227311387

Epoch: 6| Step: 5
Training loss: 4.243979958777248
Validation loss: 3.4815694877279237

Epoch: 6| Step: 6
Training loss: 3.583813672067256
Validation loss: 3.479445317288772

Epoch: 6| Step: 7
Training loss: 3.609103370122622
Validation loss: 3.4787795423933123

Epoch: 6| Step: 8
Training loss: 4.283164160290734
Validation loss: 3.480746585396495

Epoch: 6| Step: 9
Training loss: 3.7996675245498968
Validation loss: 3.474845319273828

Epoch: 6| Step: 10
Training loss: 3.444935473099367
Validation loss: 3.472112198156381

Epoch: 6| Step: 11
Training loss: 3.5428220472487295
Validation loss: 3.469570848787194

Epoch: 6| Step: 12
Training loss: 2.8507179159131826
Validation loss: 3.469799949688395

Epoch: 6| Step: 13
Training loss: 3.089365462794507
Validation loss: 3.470875969617161

Epoch: 22| Step: 0
Training loss: 2.950703591962783
Validation loss: 3.469462611137954

Epoch: 6| Step: 1
Training loss: 3.5827590718800324
Validation loss: 3.470172162252335

Epoch: 6| Step: 2
Training loss: 4.446122724176918
Validation loss: 3.470504538728239

Epoch: 6| Step: 3
Training loss: 4.287721073245451
Validation loss: 3.466309169519299

Epoch: 6| Step: 4
Training loss: 3.238267997466097
Validation loss: 3.4663575552467414

Epoch: 6| Step: 5
Training loss: 2.879454437610772
Validation loss: 3.4635828391227927

Epoch: 6| Step: 6
Training loss: 3.756315254241263
Validation loss: 3.465327734139152

Epoch: 6| Step: 7
Training loss: 3.8138206570912017
Validation loss: 3.4655466584436057

Epoch: 6| Step: 8
Training loss: 3.595320250740301
Validation loss: 3.461893512816358

Epoch: 6| Step: 9
Training loss: 3.575777574820252
Validation loss: 3.462190429453102

Epoch: 6| Step: 10
Training loss: 3.548286594019133
Validation loss: 3.4651218172365463

Epoch: 6| Step: 11
Training loss: 3.476042633620461
Validation loss: 3.463599569888493

Epoch: 6| Step: 12
Training loss: 4.2391890858789205
Validation loss: 3.456954772225643

Epoch: 6| Step: 13
Training loss: 3.9280546219984416
Validation loss: 3.4595927423560013

Epoch: 23| Step: 0
Training loss: 3.541260430468418
Validation loss: 3.4607082939096987

Epoch: 6| Step: 1
Training loss: 3.9843778722416117
Validation loss: 3.4638891316739406

Epoch: 6| Step: 2
Training loss: 4.155365814006966
Validation loss: 3.4644884062614736

Epoch: 6| Step: 3
Training loss: 4.3498575647646485
Validation loss: 3.4623677728801874

Epoch: 6| Step: 4
Training loss: 3.8016608573961728
Validation loss: 3.458989852124856

Epoch: 6| Step: 5
Training loss: 3.0986431228653712
Validation loss: 3.4564714254134983

Epoch: 6| Step: 6
Training loss: 3.955532742969104
Validation loss: 3.459550072459159

Epoch: 6| Step: 7
Training loss: 2.872757576199873
Validation loss: 3.457451117901427

Epoch: 6| Step: 8
Training loss: 2.7072394485007334
Validation loss: 3.4654511908187446

Epoch: 6| Step: 9
Training loss: 3.428194246662035
Validation loss: 3.458174569293108

Epoch: 6| Step: 10
Training loss: 3.3844263750933825
Validation loss: 3.452659283389392

Epoch: 6| Step: 11
Training loss: 3.860723097871685
Validation loss: 3.449631257256215

Epoch: 6| Step: 12
Training loss: 4.354992266537515
Validation loss: 3.4479354552046515

Epoch: 6| Step: 13
Training loss: 3.3661486091742012
Validation loss: 3.446664822653051

Epoch: 24| Step: 0
Training loss: 3.090552479015575
Validation loss: 3.4445669624004296

Epoch: 6| Step: 1
Training loss: 3.374792728417233
Validation loss: 3.443143300364969

Epoch: 6| Step: 2
Training loss: 3.739582214071944
Validation loss: 3.441202288365861

Epoch: 6| Step: 3
Training loss: 3.903755551205077
Validation loss: 3.4434261128843064

Epoch: 6| Step: 4
Training loss: 3.03039444323134
Validation loss: 3.439629354081044

Epoch: 6| Step: 5
Training loss: 3.9217297044565544
Validation loss: 3.437886942902358

Epoch: 6| Step: 6
Training loss: 3.8625451785905147
Validation loss: 3.43799932140412

Epoch: 6| Step: 7
Training loss: 4.5316707021160525
Validation loss: 3.437124265717888

Epoch: 6| Step: 8
Training loss: 3.644049478724672
Validation loss: 3.4363393709184575

Epoch: 6| Step: 9
Training loss: 3.53927860905436
Validation loss: 3.433999798267892

Epoch: 6| Step: 10
Training loss: 3.8103022259767916
Validation loss: 3.4341323525115337

Epoch: 6| Step: 11
Training loss: 3.3834724046910245
Validation loss: 3.439113648382428

Epoch: 6| Step: 12
Training loss: 3.606523055874074
Validation loss: 3.4441556484193776

Epoch: 6| Step: 13
Training loss: 3.456979111100465
Validation loss: 3.434239623938679

Epoch: 25| Step: 0
Training loss: 3.5615353533098584
Validation loss: 3.427361734956713

Epoch: 6| Step: 1
Training loss: 3.120213772468303
Validation loss: 3.424719640581934

Epoch: 6| Step: 2
Training loss: 4.038210751358539
Validation loss: 3.425539824816581

Epoch: 6| Step: 3
Training loss: 3.577268273014919
Validation loss: 3.4231375253477014

Epoch: 6| Step: 4
Training loss: 4.433860468298901
Validation loss: 3.420212088428073

Epoch: 6| Step: 5
Training loss: 2.8105985359708723
Validation loss: 3.420590327971739

Epoch: 6| Step: 6
Training loss: 4.059318822834679
Validation loss: 3.42004260061286

Epoch: 6| Step: 7
Training loss: 4.500832798508178
Validation loss: 3.418829601444177

Epoch: 6| Step: 8
Training loss: 3.804268001169113
Validation loss: 3.4128655184221612

Epoch: 6| Step: 9
Training loss: 3.2426133944669635
Validation loss: 3.414320539157832

Epoch: 6| Step: 10
Training loss: 3.787899633292436
Validation loss: 3.4120017053486644

Epoch: 6| Step: 11
Training loss: 2.7291197056891727
Validation loss: 3.410445448257055

Epoch: 6| Step: 12
Training loss: 3.784926967546164
Validation loss: 3.4153100288438343

Epoch: 6| Step: 13
Training loss: 2.400827217593001
Validation loss: 3.41410752854314

Epoch: 26| Step: 0
Training loss: 3.103874824339876
Validation loss: 3.404744098645822

Epoch: 6| Step: 1
Training loss: 3.6451535853719124
Validation loss: 3.404967208836199

Epoch: 6| Step: 2
Training loss: 3.9208888299617657
Validation loss: 3.4090299797020216

Epoch: 6| Step: 3
Training loss: 3.710820567647851
Validation loss: 3.4164976868059918

Epoch: 6| Step: 4
Training loss: 3.7564071597007005
Validation loss: 3.407504271235237

Epoch: 6| Step: 5
Training loss: 3.225904790240754
Validation loss: 3.4006515771940635

Epoch: 6| Step: 6
Training loss: 3.705038485719691
Validation loss: 3.4046957205368424

Epoch: 6| Step: 7
Training loss: 3.6248566171636525
Validation loss: 3.409009010459815

Epoch: 6| Step: 8
Training loss: 4.43889628189441
Validation loss: 3.4163050671546706

Epoch: 6| Step: 9
Training loss: 2.703495948343996
Validation loss: 3.4188588975655207

Epoch: 6| Step: 10
Training loss: 4.346866505091448
Validation loss: 3.4176335971193654

Epoch: 6| Step: 11
Training loss: 3.219375253335583
Validation loss: 3.413809821232064

Epoch: 6| Step: 12
Training loss: 4.0926265194117795
Validation loss: 3.408503954473086

Epoch: 6| Step: 13
Training loss: 2.264579794938576
Validation loss: 3.4096100074198357

Epoch: 27| Step: 0
Training loss: 3.7659810637870623
Validation loss: 3.4039212549380333

Epoch: 6| Step: 1
Training loss: 2.7628230324621974
Validation loss: 3.403680767773189

Epoch: 6| Step: 2
Training loss: 3.1185475683163872
Validation loss: 3.400467361670272

Epoch: 6| Step: 3
Training loss: 3.4457012484849923
Validation loss: 3.400873250732591

Epoch: 6| Step: 4
Training loss: 3.818481006294855
Validation loss: 3.401211075735349

Epoch: 6| Step: 5
Training loss: 3.6557366426468176
Validation loss: 3.3988409673905724

Epoch: 6| Step: 6
Training loss: 3.378846696097285
Validation loss: 3.3956103699308358

Epoch: 6| Step: 7
Training loss: 3.5358802349124514
Validation loss: 3.394785119024941

Epoch: 6| Step: 8
Training loss: 4.014762578003743
Validation loss: 3.391848115244076

Epoch: 6| Step: 9
Training loss: 3.944106357633773
Validation loss: 3.389343595726701

Epoch: 6| Step: 10
Training loss: 4.122956665729155
Validation loss: 3.3904915099983906

Epoch: 6| Step: 11
Training loss: 3.7002548490855536
Validation loss: 3.388201610473416

Epoch: 6| Step: 12
Training loss: 3.897867593026489
Validation loss: 3.3851233045567093

Epoch: 6| Step: 13
Training loss: 3.0189445290765304
Validation loss: 3.3844234057642892

Epoch: 28| Step: 0
Training loss: 3.280489297517663
Validation loss: 3.3816527036927275

Epoch: 6| Step: 1
Training loss: 3.370384168150267
Validation loss: 3.380962090152204

Epoch: 6| Step: 2
Training loss: 3.756612923301731
Validation loss: 3.37998294513407

Epoch: 6| Step: 3
Training loss: 2.9242361391790275
Validation loss: 3.3813081215572667

Epoch: 6| Step: 4
Training loss: 3.296771441094219
Validation loss: 3.380862732665563

Epoch: 6| Step: 5
Training loss: 3.4872836302220596
Validation loss: 3.379602325817883

Epoch: 6| Step: 6
Training loss: 3.744088918282114
Validation loss: 3.3796248854005446

Epoch: 6| Step: 7
Training loss: 4.16754245454964
Validation loss: 3.379228288140676

Epoch: 6| Step: 8
Training loss: 3.026438561749105
Validation loss: 3.3781594847206584

Epoch: 6| Step: 9
Training loss: 3.3284969211568143
Validation loss: 3.3763045566395813

Epoch: 6| Step: 10
Training loss: 4.418484847383503
Validation loss: 3.3770027067566346

Epoch: 6| Step: 11
Training loss: 3.6987067153218294
Validation loss: 3.374463648318396

Epoch: 6| Step: 12
Training loss: 4.134023333966712
Validation loss: 3.374957357461574

Epoch: 6| Step: 13
Training loss: 3.530692267470112
Validation loss: 3.3733798277636877

Epoch: 29| Step: 0
Training loss: 4.286825072435328
Validation loss: 3.3733267880756084

Epoch: 6| Step: 1
Training loss: 3.2115136439464034
Validation loss: 3.3703246446966184

Epoch: 6| Step: 2
Training loss: 3.841149419578128
Validation loss: 3.369614479397379

Epoch: 6| Step: 3
Training loss: 2.807071872993741
Validation loss: 3.3692760779028084

Epoch: 6| Step: 4
Training loss: 3.6162933496803578
Validation loss: 3.3692090643372117

Epoch: 6| Step: 5
Training loss: 4.38086895340014
Validation loss: 3.371932611909681

Epoch: 6| Step: 6
Training loss: 4.232137053464436
Validation loss: 3.3670630565140343

Epoch: 6| Step: 7
Training loss: 3.179831761642215
Validation loss: 3.3678210804226936

Epoch: 6| Step: 8
Training loss: 3.748539195046753
Validation loss: 3.3651061004166314

Epoch: 6| Step: 9
Training loss: 3.9173466653521247
Validation loss: 3.365620805578526

Epoch: 6| Step: 10
Training loss: 3.3759371551341175
Validation loss: 3.3659467074345653

Epoch: 6| Step: 11
Training loss: 2.4927569369593647
Validation loss: 3.3654463533068477

Epoch: 6| Step: 12
Training loss: 3.2731575129177815
Validation loss: 3.3641913375598733

Epoch: 6| Step: 13
Training loss: 3.4361503032099745
Validation loss: 3.3667152069180233

Epoch: 30| Step: 0
Training loss: 2.8118933977185296
Validation loss: 3.3672933516885517

Epoch: 6| Step: 1
Training loss: 4.01753017487793
Validation loss: 3.3676971673376728

Epoch: 6| Step: 2
Training loss: 4.085419076740203
Validation loss: 3.3646845120249824

Epoch: 6| Step: 3
Training loss: 4.701752015513032
Validation loss: 3.3586034806025578

Epoch: 6| Step: 4
Training loss: 2.487849846396549
Validation loss: 3.3595417596589012

Epoch: 6| Step: 5
Training loss: 3.649981611022612
Validation loss: 3.3578201683158926

Epoch: 6| Step: 6
Training loss: 3.651681507474502
Validation loss: 3.3567106998490384

Epoch: 6| Step: 7
Training loss: 2.9205916743272096
Validation loss: 3.357178675453023

Epoch: 6| Step: 8
Training loss: 3.1859893210903207
Validation loss: 3.3592274104228657

Epoch: 6| Step: 9
Training loss: 3.0197354305663393
Validation loss: 3.3572778679309603

Epoch: 6| Step: 10
Training loss: 3.535772887345661
Validation loss: 3.3553222936007634

Epoch: 6| Step: 11
Training loss: 3.7768074609606415
Validation loss: 3.3559675116621306

Epoch: 6| Step: 12
Training loss: 3.9398188953118702
Validation loss: 3.35522525454011

Epoch: 6| Step: 13
Training loss: 4.097889212649057
Validation loss: 3.35318183440577

Epoch: 31| Step: 0
Training loss: 3.0618860057439123
Validation loss: 3.3525131747106123

Epoch: 6| Step: 1
Training loss: 2.9784813650693587
Validation loss: 3.3521968938080713

Epoch: 6| Step: 2
Training loss: 3.386462491206082
Validation loss: 3.3513006307903708

Epoch: 6| Step: 3
Training loss: 2.8694726636282093
Validation loss: 3.3511026754810125

Epoch: 6| Step: 4
Training loss: 3.39102943926457
Validation loss: 3.3522045613265465

Epoch: 6| Step: 5
Training loss: 4.215014803352471
Validation loss: 3.350199801315438

Epoch: 6| Step: 6
Training loss: 4.665400583091232
Validation loss: 3.350037765841047

Epoch: 6| Step: 7
Training loss: 2.995728949230197
Validation loss: 3.349942266499066

Epoch: 6| Step: 8
Training loss: 3.6374731213602343
Validation loss: 3.3476620915297888

Epoch: 6| Step: 9
Training loss: 3.5943136022050295
Validation loss: 3.3490727201159602

Epoch: 6| Step: 10
Training loss: 3.7701431963612917
Validation loss: 3.3471313253399235

Epoch: 6| Step: 11
Training loss: 3.8619930638350275
Validation loss: 3.3469764707648526

Epoch: 6| Step: 12
Training loss: 4.082878061462344
Validation loss: 3.346558437318996

Epoch: 6| Step: 13
Training loss: 2.832687827984324
Validation loss: 3.3466680821996437

Epoch: 32| Step: 0
Training loss: 3.699007086655015
Validation loss: 3.345980152277186

Epoch: 6| Step: 1
Training loss: 4.173765518511506
Validation loss: 3.3474452695955446

Epoch: 6| Step: 2
Training loss: 3.03837267737375
Validation loss: 3.3451826667986686

Epoch: 6| Step: 3
Training loss: 3.9346528431636534
Validation loss: 3.344166955567604

Epoch: 6| Step: 4
Training loss: 3.905316538857863
Validation loss: 3.344503999099731

Epoch: 6| Step: 5
Training loss: 4.488335857274965
Validation loss: 3.342840887455362

Epoch: 6| Step: 6
Training loss: 3.427177188287678
Validation loss: 3.344374797549058

Epoch: 6| Step: 7
Training loss: 2.894158425561485
Validation loss: 3.346814623164855

Epoch: 6| Step: 8
Training loss: 4.061306587405021
Validation loss: 3.3471696043575614

Epoch: 6| Step: 9
Training loss: 4.015591751139103
Validation loss: 3.344505700781285

Epoch: 6| Step: 10
Training loss: 2.704658382089345
Validation loss: 3.3431102043603573

Epoch: 6| Step: 11
Training loss: 3.5882297743899234
Validation loss: 3.3425578722751723

Epoch: 6| Step: 12
Training loss: 2.7006533573977483
Validation loss: 3.343490506180258

Epoch: 6| Step: 13
Training loss: 2.1988576047069506
Validation loss: 3.343849739562935

Epoch: 33| Step: 0
Training loss: 3.477015090799922
Validation loss: 3.3423344127830936

Epoch: 6| Step: 1
Training loss: 3.041729930759746
Validation loss: 3.340837533741933

Epoch: 6| Step: 2
Training loss: 3.3714334928924625
Validation loss: 3.3415002546735963

Epoch: 6| Step: 3
Training loss: 4.24469246153565
Validation loss: 3.3420192642854096

Epoch: 6| Step: 4
Training loss: 3.7535110567295153
Validation loss: 3.341791942258104

Epoch: 6| Step: 5
Training loss: 2.7093262735140926
Validation loss: 3.338748857049222

Epoch: 6| Step: 6
Training loss: 3.2711462045367337
Validation loss: 3.340351402025001

Epoch: 6| Step: 7
Training loss: 4.133085706943119
Validation loss: 3.3382363888763886

Epoch: 6| Step: 8
Training loss: 3.646401599011943
Validation loss: 3.339120566872506

Epoch: 6| Step: 9
Training loss: 3.5266945411527604
Validation loss: 3.338137633571341

Epoch: 6| Step: 10
Training loss: 3.4142613822220484
Validation loss: 3.338779324988149

Epoch: 6| Step: 11
Training loss: 3.8725579473052196
Validation loss: 3.3385622778578106

Epoch: 6| Step: 12
Training loss: 3.6615500875003644
Validation loss: 3.3359183967759787

Epoch: 6| Step: 13
Training loss: 3.7415848726594407
Validation loss: 3.3362553392176366

Epoch: 34| Step: 0
Training loss: 4.19370345474997
Validation loss: 3.3344973275099914

Epoch: 6| Step: 1
Training loss: 2.6183154052794015
Validation loss: 3.3343702385273866

Epoch: 6| Step: 2
Training loss: 2.676073311786535
Validation loss: 3.334902194716552

Epoch: 6| Step: 3
Training loss: 3.839061575902285
Validation loss: 3.337181262713957

Epoch: 6| Step: 4
Training loss: 3.630966275238445
Validation loss: 3.3346067523944374

Epoch: 6| Step: 5
Training loss: 4.442567966952359
Validation loss: 3.3334949705455106

Epoch: 6| Step: 6
Training loss: 3.9637361830485887
Validation loss: 3.335511786781077

Epoch: 6| Step: 7
Training loss: 3.7876081998874294
Validation loss: 3.33529491363879

Epoch: 6| Step: 8
Training loss: 3.1307303722740794
Validation loss: 3.3345375521243383

Epoch: 6| Step: 9
Training loss: 3.7812513871623876
Validation loss: 3.3358542313365516

Epoch: 6| Step: 10
Training loss: 4.14743276954321
Validation loss: 3.336041943317936

Epoch: 6| Step: 11
Training loss: 2.951829414152991
Validation loss: 3.338362399942173

Epoch: 6| Step: 12
Training loss: 3.1417361898512572
Validation loss: 3.3337069676301225

Epoch: 6| Step: 13
Training loss: 2.734639443825425
Validation loss: 3.335333516815381

Epoch: 35| Step: 0
Training loss: 4.272429129345881
Validation loss: 3.3324079910910664

Epoch: 6| Step: 1
Training loss: 3.092278641200404
Validation loss: 3.3344816919053653

Epoch: 6| Step: 2
Training loss: 3.926932307542678
Validation loss: 3.3323386866924283

Epoch: 6| Step: 3
Training loss: 2.825605334352921
Validation loss: 3.3319434349724455

Epoch: 6| Step: 4
Training loss: 3.0677558795933852
Validation loss: 3.3327128960927683

Epoch: 6| Step: 5
Training loss: 3.22403527549585
Validation loss: 3.332411460658202

Epoch: 6| Step: 6
Training loss: 3.4826757281810106
Validation loss: 3.3317983374460787

Epoch: 6| Step: 7
Training loss: 2.626865632255818
Validation loss: 3.3314927869946946

Epoch: 6| Step: 8
Training loss: 3.5595297226338025
Validation loss: 3.33208653040942

Epoch: 6| Step: 9
Training loss: 3.6301820481314273
Validation loss: 3.3312216243002117

Epoch: 6| Step: 10
Training loss: 3.783818531152991
Validation loss: 3.330991378097273

Epoch: 6| Step: 11
Training loss: 4.287140518110117
Validation loss: 3.329973224405495

Epoch: 6| Step: 12
Training loss: 3.8833078724649983
Validation loss: 3.330121023510266

Epoch: 6| Step: 13
Training loss: 4.0856207584419195
Validation loss: 3.329140911295034

Epoch: 36| Step: 0
Training loss: 3.9363586951542544
Validation loss: 3.3291860981512147

Epoch: 6| Step: 1
Training loss: 3.716185382649495
Validation loss: 3.327882779381231

Epoch: 6| Step: 2
Training loss: 3.2090179571622293
Validation loss: 3.326275252293973

Epoch: 6| Step: 3
Training loss: 3.6444064299867422
Validation loss: 3.326933276180156

Epoch: 6| Step: 4
Training loss: 3.3212759976128656
Validation loss: 3.32677772339886

Epoch: 6| Step: 5
Training loss: 3.6518828565312917
Validation loss: 3.3275154769220845

Epoch: 6| Step: 6
Training loss: 3.79115951555881
Validation loss: 3.3271218374376756

Epoch: 6| Step: 7
Training loss: 3.878562643115966
Validation loss: 3.324710045815923

Epoch: 6| Step: 8
Training loss: 3.607628337774104
Validation loss: 3.3272476592037874

Epoch: 6| Step: 9
Training loss: 2.405898824059592
Validation loss: 3.325014481692991

Epoch: 6| Step: 10
Training loss: 3.704311003874774
Validation loss: 3.325890415175692

Epoch: 6| Step: 11
Training loss: 3.822364926692963
Validation loss: 3.325665069516973

Epoch: 6| Step: 12
Training loss: 3.4331636300475328
Validation loss: 3.32431610806619

Epoch: 6| Step: 13
Training loss: 3.5420173620986395
Validation loss: 3.3254003221646857

Epoch: 37| Step: 0
Training loss: 3.0127348812231345
Validation loss: 3.3248721906591645

Epoch: 6| Step: 1
Training loss: 2.931795790884529
Validation loss: 3.324296575603372

Epoch: 6| Step: 2
Training loss: 3.186792033242013
Validation loss: 3.3214774270501226

Epoch: 6| Step: 3
Training loss: 4.173994690245106
Validation loss: 3.3220470544393925

Epoch: 6| Step: 4
Training loss: 2.9960245176669407
Validation loss: 3.3227244760767016

Epoch: 6| Step: 5
Training loss: 3.9028858804871502
Validation loss: 3.31900079498456

Epoch: 6| Step: 6
Training loss: 3.514682083837976
Validation loss: 3.3213920561010624

Epoch: 6| Step: 7
Training loss: 3.7656822358526236
Validation loss: 3.3197144915549

Epoch: 6| Step: 8
Training loss: 3.3587256935185636
Validation loss: 3.319446659200382

Epoch: 6| Step: 9
Training loss: 3.042306144763672
Validation loss: 3.3195858442415798

Epoch: 6| Step: 10
Training loss: 3.7281319374346076
Validation loss: 3.3208691356600957

Epoch: 6| Step: 11
Training loss: 4.189290589067371
Validation loss: 3.3217855225486903

Epoch: 6| Step: 12
Training loss: 3.9708361812126354
Validation loss: 3.3206205954982937

Epoch: 6| Step: 13
Training loss: 3.8692201146948815
Validation loss: 3.3213196705366452

Epoch: 38| Step: 0
Training loss: 3.3379907654393968
Validation loss: 3.3188498140856493

Epoch: 6| Step: 1
Training loss: 4.08956788744012
Validation loss: 3.3179602821997873

Epoch: 6| Step: 2
Training loss: 2.70240677128424
Validation loss: 3.317412747162723

Epoch: 6| Step: 3
Training loss: 4.057317626765606
Validation loss: 3.3160515380563846

Epoch: 6| Step: 4
Training loss: 3.7313207162772444
Validation loss: 3.3226626652674223

Epoch: 6| Step: 5
Training loss: 4.0847663440906175
Validation loss: 3.3275837076533374

Epoch: 6| Step: 6
Training loss: 4.300834911818948
Validation loss: 3.3232342402437016

Epoch: 6| Step: 7
Training loss: 2.728075192620577
Validation loss: 3.317791489742398

Epoch: 6| Step: 8
Training loss: 2.973819780657461
Validation loss: 3.3165791293501137

Epoch: 6| Step: 9
Training loss: 3.747034553394983
Validation loss: 3.316630208847786

Epoch: 6| Step: 10
Training loss: 2.9288294641946075
Validation loss: 3.3186658565513807

Epoch: 6| Step: 11
Training loss: 3.3617464433646833
Validation loss: 3.315990079100689

Epoch: 6| Step: 12
Training loss: 3.4748946743378712
Validation loss: 3.316243924684771

Epoch: 6| Step: 13
Training loss: 4.018925479362237
Validation loss: 3.3155099787798807

Epoch: 39| Step: 0
Training loss: 3.8280407954705904
Validation loss: 3.317138312790948

Epoch: 6| Step: 1
Training loss: 3.0786098350124447
Validation loss: 3.318881042487599

Epoch: 6| Step: 2
Training loss: 4.341944037795023
Validation loss: 3.31731155739525

Epoch: 6| Step: 3
Training loss: 3.8125769185295906
Validation loss: 3.3170730993139013

Epoch: 6| Step: 4
Training loss: 3.8925033998566407
Validation loss: 3.314287773964476

Epoch: 6| Step: 5
Training loss: 3.348951625471185
Validation loss: 3.3162109289653823

Epoch: 6| Step: 6
Training loss: 2.4798719754552727
Validation loss: 3.31262801471122

Epoch: 6| Step: 7
Training loss: 4.12288218376668
Validation loss: 3.315745655295553

Epoch: 6| Step: 8
Training loss: 2.9122210454988955
Validation loss: 3.3143228943072565

Epoch: 6| Step: 9
Training loss: 3.889068414692042
Validation loss: 3.312599615579293

Epoch: 6| Step: 10
Training loss: 2.8592612655616505
Validation loss: 3.3152252567739904

Epoch: 6| Step: 11
Training loss: 3.8814067176224887
Validation loss: 3.3141689294838192

Epoch: 6| Step: 12
Training loss: 3.7074139058874813
Validation loss: 3.3114057727626793

Epoch: 6| Step: 13
Training loss: 2.7181052835661186
Validation loss: 3.312156948932005

Epoch: 40| Step: 0
Training loss: 3.7939794983176682
Validation loss: 3.313325896249102

Epoch: 6| Step: 1
Training loss: 3.830729567758767
Validation loss: 3.3130064732081146

Epoch: 6| Step: 2
Training loss: 3.314003369326769
Validation loss: 3.309536913284816

Epoch: 6| Step: 3
Training loss: 3.928748562770366
Validation loss: 3.308481857682524

Epoch: 6| Step: 4
Training loss: 4.236007094365592
Validation loss: 3.3105567515023204

Epoch: 6| Step: 5
Training loss: 2.759235393237001
Validation loss: 3.3108319799752794

Epoch: 6| Step: 6
Training loss: 4.0224148237600135
Validation loss: 3.3072698262819107

Epoch: 6| Step: 7
Training loss: 3.4872140309117383
Validation loss: 3.3114310637412583

Epoch: 6| Step: 8
Training loss: 2.8890218052079146
Validation loss: 3.3085017632370963

Epoch: 6| Step: 9
Training loss: 3.488304625087905
Validation loss: 3.3087960956060054

Epoch: 6| Step: 10
Training loss: 2.8860767770813043
Validation loss: 3.309142913127801

Epoch: 6| Step: 11
Training loss: 3.740201227823093
Validation loss: 3.3085718466661858

Epoch: 6| Step: 12
Training loss: 3.554735254658621
Validation loss: 3.306205376681132

Epoch: 6| Step: 13
Training loss: 3.365911184343864
Validation loss: 3.306715397250766

Epoch: 41| Step: 0
Training loss: 3.649133521922078
Validation loss: 3.305729099331334

Epoch: 6| Step: 1
Training loss: 3.2447728890763017
Validation loss: 3.3060427528973713

Epoch: 6| Step: 2
Training loss: 4.178530524010551
Validation loss: 3.3054428073314663

Epoch: 6| Step: 3
Training loss: 3.3035466815507633
Validation loss: 3.306028493284644

Epoch: 6| Step: 4
Training loss: 3.5391797178953097
Validation loss: 3.305472424333505

Epoch: 6| Step: 5
Training loss: 4.242323730979018
Validation loss: 3.3046926820651783

Epoch: 6| Step: 6
Training loss: 3.187969696743292
Validation loss: 3.3047579474634796

Epoch: 6| Step: 7
Training loss: 3.2478686459857253
Validation loss: 3.3058290151011906

Epoch: 6| Step: 8
Training loss: 3.6929818479379533
Validation loss: 3.3035999949351704

Epoch: 6| Step: 9
Training loss: 3.7103471467096822
Validation loss: 3.307121904373384

Epoch: 6| Step: 10
Training loss: 2.65324105771631
Validation loss: 3.305416591018113

Epoch: 6| Step: 11
Training loss: 3.761818509150671
Validation loss: 3.3031086987095417

Epoch: 6| Step: 12
Training loss: 3.9187453955907707
Validation loss: 3.307143473129088

Epoch: 6| Step: 13
Training loss: 2.4569813733883383
Validation loss: 3.3056615110063254

Epoch: 42| Step: 0
Training loss: 3.4052860400899574
Validation loss: 3.3038484878531866

Epoch: 6| Step: 1
Training loss: 4.0276638906462425
Validation loss: 3.3051874977236597

Epoch: 6| Step: 2
Training loss: 3.3130944636286417
Validation loss: 3.3028566316706076

Epoch: 6| Step: 3
Training loss: 3.8321773333999074
Validation loss: 3.3036821854608647

Epoch: 6| Step: 4
Training loss: 3.222722833118983
Validation loss: 3.301317042139194

Epoch: 6| Step: 5
Training loss: 3.0500700020183
Validation loss: 3.304546270080185

Epoch: 6| Step: 6
Training loss: 3.981051027125703
Validation loss: 3.303925539372823

Epoch: 6| Step: 7
Training loss: 3.2243100633347104
Validation loss: 3.300479682087245

Epoch: 6| Step: 8
Training loss: 3.3223824544971032
Validation loss: 3.303222579803865

Epoch: 6| Step: 9
Training loss: 3.6538140422938965
Validation loss: 3.3017526429104413

Epoch: 6| Step: 10
Training loss: 3.1136188012977635
Validation loss: 3.3017606962236714

Epoch: 6| Step: 11
Training loss: 3.631495214380081
Validation loss: 3.3028865939783847

Epoch: 6| Step: 12
Training loss: 3.858920792635927
Validation loss: 3.3017302407445177

Epoch: 6| Step: 13
Training loss: 3.980308581902354
Validation loss: 3.302861214286658

Epoch: 43| Step: 0
Training loss: 4.106012745684627
Validation loss: 3.3002174462415836

Epoch: 6| Step: 1
Training loss: 3.0345771070091114
Validation loss: 3.3019416405765063

Epoch: 6| Step: 2
Training loss: 4.03040393556143
Validation loss: 3.300677880449288

Epoch: 6| Step: 3
Training loss: 4.578544935945125
Validation loss: 3.2995328412813136

Epoch: 6| Step: 4
Training loss: 3.2675664505918167
Validation loss: 3.299071716521322

Epoch: 6| Step: 5
Training loss: 3.0041616502385753
Validation loss: 3.3019626717405726

Epoch: 6| Step: 6
Training loss: 4.179564743378405
Validation loss: 3.302984116683686

Epoch: 6| Step: 7
Training loss: 3.7436808431666773
Validation loss: 3.2998727003262656

Epoch: 6| Step: 8
Training loss: 3.398051763983364
Validation loss: 3.2980907915950355

Epoch: 6| Step: 9
Training loss: 2.189847286247368
Validation loss: 3.2967652916569845

Epoch: 6| Step: 10
Training loss: 2.8551659795344504
Validation loss: 3.2973787138430666

Epoch: 6| Step: 11
Training loss: 3.4646221722237835
Validation loss: 3.2963519871003992

Epoch: 6| Step: 12
Training loss: 3.8850349191007068
Validation loss: 3.2966033850099374

Epoch: 6| Step: 13
Training loss: 2.7115521792217256
Validation loss: 3.296738482216183

Epoch: 44| Step: 0
Training loss: 3.2324677524595535
Validation loss: 3.293268217293558

Epoch: 6| Step: 1
Training loss: 3.1362524766786786
Validation loss: 3.2933864895640603

Epoch: 6| Step: 2
Training loss: 3.575460449657217
Validation loss: 3.2939945388966745

Epoch: 6| Step: 3
Training loss: 3.4070951480729827
Validation loss: 3.2933302917713863

Epoch: 6| Step: 4
Training loss: 3.879362788229556
Validation loss: 3.2970131745645626

Epoch: 6| Step: 5
Training loss: 2.7271726958396583
Validation loss: 3.2943127034594046

Epoch: 6| Step: 6
Training loss: 3.3341713010995226
Validation loss: 3.2942751767902694

Epoch: 6| Step: 7
Training loss: 3.8150291183780323
Validation loss: 3.2941513844668378

Epoch: 6| Step: 8
Training loss: 3.919862147067695
Validation loss: 3.294597069532005

Epoch: 6| Step: 9
Training loss: 3.377329269826407
Validation loss: 3.2927378080829004

Epoch: 6| Step: 10
Training loss: 4.107514515048365
Validation loss: 3.2921814822920914

Epoch: 6| Step: 11
Training loss: 3.648657847250645
Validation loss: 3.291894096180298

Epoch: 6| Step: 12
Training loss: 2.7883142488065538
Validation loss: 3.292821265505789

Epoch: 6| Step: 13
Training loss: 4.6825179008960465
Validation loss: 3.2918865825628014

Epoch: 45| Step: 0
Training loss: 4.072012694483307
Validation loss: 3.2899493193348586

Epoch: 6| Step: 1
Training loss: 3.210966606657918
Validation loss: 3.290580185982751

Epoch: 6| Step: 2
Training loss: 3.3845199258054057
Validation loss: 3.291714912602006

Epoch: 6| Step: 3
Training loss: 3.132099936253815
Validation loss: 3.2885860037258854

Epoch: 6| Step: 4
Training loss: 3.1963106941962023
Validation loss: 3.2896819298785376

Epoch: 6| Step: 5
Training loss: 3.784065900507004
Validation loss: 3.290504077877655

Epoch: 6| Step: 6
Training loss: 3.958665184699972
Validation loss: 3.2910476955164394

Epoch: 6| Step: 7
Training loss: 2.9043128007402124
Validation loss: 3.290704120440923

Epoch: 6| Step: 8
Training loss: 3.217837602499475
Validation loss: 3.288567811930605

Epoch: 6| Step: 9
Training loss: 3.9377237892133468
Validation loss: 3.2881137827192912

Epoch: 6| Step: 10
Training loss: 3.4808491885319053
Validation loss: 3.288952559119322

Epoch: 6| Step: 11
Training loss: 3.84838426547726
Validation loss: 3.289288521693934

Epoch: 6| Step: 12
Training loss: 3.655893552962567
Validation loss: 3.2889814523952077

Epoch: 6| Step: 13
Training loss: 3.427275276413101
Validation loss: 3.2874015511695474

Epoch: 46| Step: 0
Training loss: 3.5190835852228854
Validation loss: 3.2859649675311444

Epoch: 6| Step: 1
Training loss: 2.963976264467326
Validation loss: 3.286431851168275

Epoch: 6| Step: 2
Training loss: 3.5079579482477845
Validation loss: 3.288305558566759

Epoch: 6| Step: 3
Training loss: 3.1172578655513563
Validation loss: 3.2883752639745185

Epoch: 6| Step: 4
Training loss: 4.202157628933417
Validation loss: 3.2907828165547084

Epoch: 6| Step: 5
Training loss: 3.0138960709806106
Validation loss: 3.2908317895543613

Epoch: 6| Step: 6
Training loss: 4.171638167727567
Validation loss: 3.2925530978567767

Epoch: 6| Step: 7
Training loss: 2.889553386933687
Validation loss: 3.287858789857268

Epoch: 6| Step: 8
Training loss: 4.495195154827037
Validation loss: 3.2874043913382995

Epoch: 6| Step: 9
Training loss: 3.1160972428628635
Validation loss: 3.2884188749053522

Epoch: 6| Step: 10
Training loss: 3.504286185156753
Validation loss: 3.2886135313317113

Epoch: 6| Step: 11
Training loss: 3.7034597768637445
Validation loss: 3.2864238297182586

Epoch: 6| Step: 12
Training loss: 2.5781481192737066
Validation loss: 3.2901175532301075

Epoch: 6| Step: 13
Training loss: 4.489488616911935
Validation loss: 3.2889844330618643

Epoch: 47| Step: 0
Training loss: 3.6504810173064652
Validation loss: 3.2898341932773634

Epoch: 6| Step: 1
Training loss: 3.4263198759683915
Validation loss: 3.292233046225336

Epoch: 6| Step: 2
Training loss: 2.871215651642576
Validation loss: 3.2939284734011975

Epoch: 6| Step: 3
Training loss: 4.01953125
Validation loss: 3.2897989572281903

Epoch: 6| Step: 4
Training loss: 3.6630207199356293
Validation loss: 3.289123473794427

Epoch: 6| Step: 5
Training loss: 3.5356602767848715
Validation loss: 3.2883382464628204

Epoch: 6| Step: 6
Training loss: 3.550721355810175
Validation loss: 3.2875157205888987

Epoch: 6| Step: 7
Training loss: 4.178164880372497
Validation loss: 3.287065797390109

Epoch: 6| Step: 8
Training loss: 3.73703138290592
Validation loss: 3.2861630957993455

Epoch: 6| Step: 9
Training loss: 3.40617104535071
Validation loss: 3.2835351427728976

Epoch: 6| Step: 10
Training loss: 3.35421001019323
Validation loss: 3.286511763492695

Epoch: 6| Step: 11
Training loss: 3.356150654435971
Validation loss: 3.2872142069093666

Epoch: 6| Step: 12
Training loss: 3.2252219604285783
Validation loss: 3.2875563781188686

Epoch: 6| Step: 13
Training loss: 3.047969523710541
Validation loss: 3.2883209560969178

Epoch: 48| Step: 0
Training loss: 3.8484961507945754
Validation loss: 3.2876753642816734

Epoch: 6| Step: 1
Training loss: 2.6265670095537765
Validation loss: 3.2871744778980423

Epoch: 6| Step: 2
Training loss: 3.5720034545334944
Validation loss: 3.2910579763994257

Epoch: 6| Step: 3
Training loss: 3.118113903546617
Validation loss: 3.2865524849250973

Epoch: 6| Step: 4
Training loss: 3.5028730589407924
Validation loss: 3.2845666705125005

Epoch: 6| Step: 5
Training loss: 4.268044927630503
Validation loss: 3.2876645893600567

Epoch: 6| Step: 6
Training loss: 3.7521473140793304
Validation loss: 3.283676035025806

Epoch: 6| Step: 7
Training loss: 3.4090648534530446
Validation loss: 3.285179430058111

Epoch: 6| Step: 8
Training loss: 3.851482150649916
Validation loss: 3.2836656076759922

Epoch: 6| Step: 9
Training loss: 3.674878649102896
Validation loss: 3.2826793598615622

Epoch: 6| Step: 10
Training loss: 3.4676872206175373
Validation loss: 3.2833294398454047

Epoch: 6| Step: 11
Training loss: 3.4574077853733645
Validation loss: 3.2804428787703337

Epoch: 6| Step: 12
Training loss: 3.1751185778004043
Validation loss: 3.279937516024235

Epoch: 6| Step: 13
Training loss: 3.248140243133369
Validation loss: 3.2835024687413776

Epoch: 49| Step: 0
Training loss: 3.2485219088510324
Validation loss: 3.2843647336037853

Epoch: 6| Step: 1
Training loss: 3.7767125167375437
Validation loss: 3.281767709481904

Epoch: 6| Step: 2
Training loss: 3.2635319038843327
Validation loss: 3.2806336620477468

Epoch: 6| Step: 3
Training loss: 3.704982372247149
Validation loss: 3.2805849384787407

Epoch: 6| Step: 4
Training loss: 3.6040018885583196
Validation loss: 3.278441762393271

Epoch: 6| Step: 5
Training loss: 4.133887225129381
Validation loss: 3.2816647550206643

Epoch: 6| Step: 6
Training loss: 3.76419787450497
Validation loss: 3.2800795069566786

Epoch: 6| Step: 7
Training loss: 2.80142813092785
Validation loss: 3.2781335300331564

Epoch: 6| Step: 8
Training loss: 3.11788802533468
Validation loss: 3.275728620249007

Epoch: 6| Step: 9
Training loss: 3.384267445666614
Validation loss: 3.2781335237768143

Epoch: 6| Step: 10
Training loss: 3.446747565313088
Validation loss: 3.2782850770350325

Epoch: 6| Step: 11
Training loss: 3.5630226421123914
Validation loss: 3.2775774285560497

Epoch: 6| Step: 12
Training loss: 3.919293287176994
Validation loss: 3.2750910478523307

Epoch: 6| Step: 13
Training loss: 3.277439775299142
Validation loss: 3.27460786196592

Epoch: 50| Step: 0
Training loss: 3.8712583135429988
Validation loss: 3.277487222147514

Epoch: 6| Step: 1
Training loss: 4.153459343465669
Validation loss: 3.2743718418847814

Epoch: 6| Step: 2
Training loss: 2.580934046142425
Validation loss: 3.273908724465167

Epoch: 6| Step: 3
Training loss: 3.453424639237347
Validation loss: 3.274005999998606

Epoch: 6| Step: 4
Training loss: 2.9556944633608846
Validation loss: 3.2731220855910137

Epoch: 6| Step: 5
Training loss: 3.552630489564844
Validation loss: 3.273242448591346

Epoch: 6| Step: 6
Training loss: 3.888603941756569
Validation loss: 3.272766495611312

Epoch: 6| Step: 7
Training loss: 3.0762044269111017
Validation loss: 3.270960261715047

Epoch: 6| Step: 8
Training loss: 3.8527400632768134
Validation loss: 3.2692562967834156

Epoch: 6| Step: 9
Training loss: 3.584493774468253
Validation loss: 3.2731006482378877

Epoch: 6| Step: 10
Training loss: 3.1332003003820956
Validation loss: 3.2718386861026265

Epoch: 6| Step: 11
Training loss: 3.99956033197664
Validation loss: 3.2704233490389747

Epoch: 6| Step: 12
Training loss: 3.276882207332516
Validation loss: 3.270596740914986

Epoch: 6| Step: 13
Training loss: 3.5279786477426733
Validation loss: 3.2722930853894154

Epoch: 51| Step: 0
Training loss: 3.1549011974310317
Validation loss: 3.2714744142354077

Epoch: 6| Step: 1
Training loss: 2.4980840971010094
Validation loss: 3.2733944851804404

Epoch: 6| Step: 2
Training loss: 3.2269074114794094
Validation loss: 3.2739038632750055

Epoch: 6| Step: 3
Training loss: 3.365771073170632
Validation loss: 3.2751574886342123

Epoch: 6| Step: 4
Training loss: 3.861156716447138
Validation loss: 3.275649700208356

Epoch: 6| Step: 5
Training loss: 3.9157483397327297
Validation loss: 3.275061535752267

Epoch: 6| Step: 6
Training loss: 4.139842754823904
Validation loss: 3.2748745298456923

Epoch: 6| Step: 7
Training loss: 3.6594723578580624
Validation loss: 3.2704895185787146

Epoch: 6| Step: 8
Training loss: 3.001942641389469
Validation loss: 3.269593889609647

Epoch: 6| Step: 9
Training loss: 2.741720567384047
Validation loss: 3.268051336503595

Epoch: 6| Step: 10
Training loss: 3.9223452586279115
Validation loss: 3.266561554537555

Epoch: 6| Step: 11
Training loss: 4.297092501597465
Validation loss: 3.264078375253382

Epoch: 6| Step: 12
Training loss: 3.1476407616661013
Validation loss: 3.2670667813459526

Epoch: 6| Step: 13
Training loss: 3.9392730111899397
Validation loss: 3.263994300715059

Epoch: 52| Step: 0
Training loss: 3.4710408112487663
Validation loss: 3.2665297961321116

Epoch: 6| Step: 1
Training loss: 3.2343226626672044
Validation loss: 3.2663861982320994

Epoch: 6| Step: 2
Training loss: 4.033754502262314
Validation loss: 3.2644166245001274

Epoch: 6| Step: 3
Training loss: 4.373233547545449
Validation loss: 3.2620867212083007

Epoch: 6| Step: 4
Training loss: 3.042946811738954
Validation loss: 3.265624094065698

Epoch: 6| Step: 5
Training loss: 3.495216097502028
Validation loss: 3.2645441735535266

Epoch: 6| Step: 6
Training loss: 3.6231863812427116
Validation loss: 3.2655555186627634

Epoch: 6| Step: 7
Training loss: 2.61378371535767
Validation loss: 3.2670886474955196

Epoch: 6| Step: 8
Training loss: 3.6063692863212564
Validation loss: 3.2599899551108003

Epoch: 6| Step: 9
Training loss: 3.6951682322690678
Validation loss: 3.2592231846091457

Epoch: 6| Step: 10
Training loss: 3.8331880680147314
Validation loss: 3.261812319391917

Epoch: 6| Step: 11
Training loss: 3.811548833544973
Validation loss: 3.2625676298755955

Epoch: 6| Step: 12
Training loss: 2.9182496452713678
Validation loss: 3.261782151121158

Epoch: 6| Step: 13
Training loss: 2.5329703618908628
Validation loss: 3.264271228615572

Epoch: 53| Step: 0
Training loss: 3.7968982334760484
Validation loss: 3.264825958580464

Epoch: 6| Step: 1
Training loss: 3.669796619236889
Validation loss: 3.265475948445434

Epoch: 6| Step: 2
Training loss: 3.2307494847599014
Validation loss: 3.2654036022793878

Epoch: 6| Step: 3
Training loss: 3.8078554973593115
Validation loss: 3.2702047698844834

Epoch: 6| Step: 4
Training loss: 3.134932792223044
Validation loss: 3.2670553860312173

Epoch: 6| Step: 5
Training loss: 2.5588401151665088
Validation loss: 3.265235626060807

Epoch: 6| Step: 6
Training loss: 3.9419616368409374
Validation loss: 3.266885573712147

Epoch: 6| Step: 7
Training loss: 3.1367417046074
Validation loss: 3.2641592526580134

Epoch: 6| Step: 8
Training loss: 3.5942907838701186
Validation loss: 3.2640107295232244

Epoch: 6| Step: 9
Training loss: 4.4927438938718565
Validation loss: 3.2636785282466745

Epoch: 6| Step: 10
Training loss: 3.4214356022736085
Validation loss: 3.2607768499115304

Epoch: 6| Step: 11
Training loss: 3.0409714065306357
Validation loss: 3.261481149493388

Epoch: 6| Step: 12
Training loss: 3.5481036910653088
Validation loss: 3.26136341179618

Epoch: 6| Step: 13
Training loss: 3.164832805538346
Validation loss: 3.2602267128244056

Epoch: 54| Step: 0
Training loss: 3.5497387319783997
Validation loss: 3.2603083195487352

Epoch: 6| Step: 1
Training loss: 3.4546586855441968
Validation loss: 3.2569191310422547

Epoch: 6| Step: 2
Training loss: 3.9630476467859683
Validation loss: 3.2576856395909526

Epoch: 6| Step: 3
Training loss: 2.253689919177112
Validation loss: 3.260935296342409

Epoch: 6| Step: 4
Training loss: 3.8715445586079866
Validation loss: 3.257918666485738

Epoch: 6| Step: 5
Training loss: 3.64669908689306
Validation loss: 3.262169695968417

Epoch: 6| Step: 6
Training loss: 3.40122292908449
Validation loss: 3.259908208299

Epoch: 6| Step: 7
Training loss: 3.9654724524626612
Validation loss: 3.259211289920677

Epoch: 6| Step: 8
Training loss: 2.8921818020608376
Validation loss: 3.259484941717406

Epoch: 6| Step: 9
Training loss: 3.5850536445636925
Validation loss: 3.259314576088761

Epoch: 6| Step: 10
Training loss: 3.173434771297602
Validation loss: 3.257547393672657

Epoch: 6| Step: 11
Training loss: 3.869230343482762
Validation loss: 3.258007814986521

Epoch: 6| Step: 12
Training loss: 3.955739720899487
Validation loss: 3.256721648982462

Epoch: 6| Step: 13
Training loss: 2.5946061892830325
Validation loss: 3.2578930316992056

Epoch: 55| Step: 0
Training loss: 4.139395822861147
Validation loss: 3.2562368954221275

Epoch: 6| Step: 1
Training loss: 3.244625783305965
Validation loss: 3.2549972490679897

Epoch: 6| Step: 2
Training loss: 3.8844371443892536
Validation loss: 3.2563051710788287

Epoch: 6| Step: 3
Training loss: 2.506529863290363
Validation loss: 3.254281398918719

Epoch: 6| Step: 4
Training loss: 3.5165945115001516
Validation loss: 3.253992893572381

Epoch: 6| Step: 5
Training loss: 3.4777929978719784
Validation loss: 3.2551606132044877

Epoch: 6| Step: 6
Training loss: 3.378408335784883
Validation loss: 3.25670971130842

Epoch: 6| Step: 7
Training loss: 2.8327570123387904
Validation loss: 3.2514755427014084

Epoch: 6| Step: 8
Training loss: 3.144890313350819
Validation loss: 3.255386897089189

Epoch: 6| Step: 9
Training loss: 4.105011106004455
Validation loss: 3.258459314645144

Epoch: 6| Step: 10
Training loss: 3.0879076113345256
Validation loss: 3.2573109457066427

Epoch: 6| Step: 11
Training loss: 3.970890219015092
Validation loss: 3.257758176825829

Epoch: 6| Step: 12
Training loss: 3.81274100620639
Validation loss: 3.2573754526071808

Epoch: 6| Step: 13
Training loss: 3.437581009343748
Validation loss: 3.2633242204556017

Epoch: 56| Step: 0
Training loss: 4.168594499287177
Validation loss: 3.2555952049803287

Epoch: 6| Step: 1
Training loss: 3.655536549398632
Validation loss: 3.2539941100041716

Epoch: 6| Step: 2
Training loss: 3.252290652059504
Validation loss: 3.254899009265874

Epoch: 6| Step: 3
Training loss: 3.1826290236911694
Validation loss: 3.2546658740826846

Epoch: 6| Step: 4
Training loss: 3.3645945608859127
Validation loss: 3.2546680394188625

Epoch: 6| Step: 5
Training loss: 4.432421289768182
Validation loss: 3.2538000108992438

Epoch: 6| Step: 6
Training loss: 4.188069319099438
Validation loss: 3.2556927363457646

Epoch: 6| Step: 7
Training loss: 3.765354130923439
Validation loss: 3.2503389003551266

Epoch: 6| Step: 8
Training loss: 2.767166570135195
Validation loss: 3.2535112729671485

Epoch: 6| Step: 9
Training loss: 3.3660260739872054
Validation loss: 3.253568645491934

Epoch: 6| Step: 10
Training loss: 2.9649709641577164
Validation loss: 3.2485584457037926

Epoch: 6| Step: 11
Training loss: 2.6591413133018875
Validation loss: 3.2496666544052353

Epoch: 6| Step: 12
Training loss: 2.8209721435772575
Validation loss: 3.2506785540260386

Epoch: 6| Step: 13
Training loss: 3.904578866168712
Validation loss: 3.250375222757961

Epoch: 57| Step: 0
Training loss: 4.336270046369236
Validation loss: 3.252683494798075

Epoch: 6| Step: 1
Training loss: 3.501777470061326
Validation loss: 3.2529033064641784

Epoch: 6| Step: 2
Training loss: 3.6923070060900516
Validation loss: 3.2506805824276626

Epoch: 6| Step: 3
Training loss: 3.80589823483253
Validation loss: 3.251120732994167

Epoch: 6| Step: 4
Training loss: 3.609659291090214
Validation loss: 3.251721496521742

Epoch: 6| Step: 5
Training loss: 3.5127620992921145
Validation loss: 3.2507788337846226

Epoch: 6| Step: 6
Training loss: 2.969539497201452
Validation loss: 3.250768099023591

Epoch: 6| Step: 7
Training loss: 3.183271707733851
Validation loss: 3.2494816725671822

Epoch: 6| Step: 8
Training loss: 4.266075697343959
Validation loss: 3.2492034257744113

Epoch: 6| Step: 9
Training loss: 3.184615980918712
Validation loss: 3.246746302440767

Epoch: 6| Step: 10
Training loss: 2.532475304440803
Validation loss: 3.250229197167319

Epoch: 6| Step: 11
Training loss: 3.135179039620167
Validation loss: 3.247297070937339

Epoch: 6| Step: 12
Training loss: 3.4453263401436867
Validation loss: 3.2478935176834227

Epoch: 6| Step: 13
Training loss: 3.178590477508239
Validation loss: 3.2481880800810066

Epoch: 58| Step: 0
Training loss: 4.00390625
Validation loss: 3.2500096487402166

Epoch: 6| Step: 1
Training loss: 3.225066274509035
Validation loss: 3.248194401987559

Epoch: 6| Step: 2
Training loss: 3.7056645566231947
Validation loss: 3.24783342904096

Epoch: 6| Step: 3
Training loss: 3.7805164981356425
Validation loss: 3.250419627471878

Epoch: 6| Step: 4
Training loss: 4.1618971929432504
Validation loss: 3.24895819664616

Epoch: 6| Step: 5
Training loss: 3.201260801131003
Validation loss: 3.249608714400496

Epoch: 6| Step: 6
Training loss: 3.1170501296289923
Validation loss: 3.247280377570706

Epoch: 6| Step: 7
Training loss: 3.4902507694074947
Validation loss: 3.2461253608493337

Epoch: 6| Step: 8
Training loss: 3.4561020114113026
Validation loss: 3.2457514808095613

Epoch: 6| Step: 9
Training loss: 3.04117900823543
Validation loss: 3.2442397792888475

Epoch: 6| Step: 10
Training loss: 2.628292017652093
Validation loss: 3.2448273379951424

Epoch: 6| Step: 11
Training loss: 4.317707400749422
Validation loss: 3.245915817332556

Epoch: 6| Step: 12
Training loss: 2.919957148616373
Validation loss: 3.245512163163683

Epoch: 6| Step: 13
Training loss: 3.216824001621734
Validation loss: 3.2457404940467716

Epoch: 59| Step: 0
Training loss: 3.6481201556645604
Validation loss: 3.245789503725996

Epoch: 6| Step: 1
Training loss: 3.939097247032882
Validation loss: 3.2451699795705813

Epoch: 6| Step: 2
Training loss: 2.6150147486137683
Validation loss: 3.243842001160413

Epoch: 6| Step: 3
Training loss: 3.6926917043005707
Validation loss: 3.2446280414654187

Epoch: 6| Step: 4
Training loss: 3.2351524413804253
Validation loss: 3.243835811446917

Epoch: 6| Step: 5
Training loss: 3.3771437441682006
Validation loss: 3.243398516863029

Epoch: 6| Step: 6
Training loss: 2.835294456193274
Validation loss: 3.2440416446990374

Epoch: 6| Step: 7
Training loss: 3.0155517885482426
Validation loss: 3.243813270104965

Epoch: 6| Step: 8
Training loss: 4.020144757753259
Validation loss: 3.242587761227627

Epoch: 6| Step: 9
Training loss: 3.5479979228945804
Validation loss: 3.2424620667151576

Epoch: 6| Step: 10
Training loss: 3.0732702709135515
Validation loss: 3.242548672954217

Epoch: 6| Step: 11
Training loss: 4.184321777369932
Validation loss: 3.242827705781407

Epoch: 6| Step: 12
Training loss: 3.7317027981775
Validation loss: 3.2417336415226785

Epoch: 6| Step: 13
Training loss: 3.4552989347898344
Validation loss: 3.240938285842974

Epoch: 60| Step: 0
Training loss: 3.7353371374312974
Validation loss: 3.241325493726262

Epoch: 6| Step: 1
Training loss: 2.8601781832268998
Validation loss: 3.240174250341067

Epoch: 6| Step: 2
Training loss: 4.094559218237097
Validation loss: 3.241419234210625

Epoch: 6| Step: 3
Training loss: 2.6563317678993195
Validation loss: 3.2432023544717086

Epoch: 6| Step: 4
Training loss: 2.6252345025811468
Validation loss: 3.240251474150497

Epoch: 6| Step: 5
Training loss: 4.236019026514537
Validation loss: 3.2418960806024857

Epoch: 6| Step: 6
Training loss: 2.58074494378547
Validation loss: 3.238154107355609

Epoch: 6| Step: 7
Training loss: 3.5791978851721375
Validation loss: 3.2380920075401916

Epoch: 6| Step: 8
Training loss: 3.5459983515340263
Validation loss: 3.241323541726376

Epoch: 6| Step: 9
Training loss: 4.130482584766172
Validation loss: 3.239482488065956

Epoch: 6| Step: 10
Training loss: 2.7518576503243994
Validation loss: 3.238338550355716

Epoch: 6| Step: 11
Training loss: 2.651432470708714
Validation loss: 3.238992668385159

Epoch: 6| Step: 12
Training loss: 4.145886802648029
Validation loss: 3.238009785482606

Epoch: 6| Step: 13
Training loss: 4.728193925253046
Validation loss: 3.2426559511105735

Epoch: 61| Step: 0
Training loss: 3.638858481191949
Validation loss: 3.240306033857129

Epoch: 6| Step: 1
Training loss: 3.095306775445473
Validation loss: 3.238078048812224

Epoch: 6| Step: 2
Training loss: 3.8862996397777563
Validation loss: 3.2382676649645488

Epoch: 6| Step: 3
Training loss: 3.268311340190597
Validation loss: 3.2389205166454316

Epoch: 6| Step: 4
Training loss: 3.8978568277229306
Validation loss: 3.23607702435493

Epoch: 6| Step: 5
Training loss: 2.9027919089557934
Validation loss: 3.236066245577937

Epoch: 6| Step: 6
Training loss: 3.7873239205602744
Validation loss: 3.2372656114601464

Epoch: 6| Step: 7
Training loss: 4.039370379344216
Validation loss: 3.2364260405428587

Epoch: 6| Step: 8
Training loss: 3.900474245629666
Validation loss: 3.234107186899737

Epoch: 6| Step: 9
Training loss: 3.919101053237939
Validation loss: 3.233919591647842

Epoch: 6| Step: 10
Training loss: 3.1940782770204437
Validation loss: 3.234296316923944

Epoch: 6| Step: 11
Training loss: 2.3083787227350028
Validation loss: 3.2351037444386637

Epoch: 6| Step: 12
Training loss: 2.8431843624764754
Validation loss: 3.2323761602706536

Epoch: 6| Step: 13
Training loss: 3.626528713557071
Validation loss: 3.2344160084787177

Epoch: 62| Step: 0
Training loss: 3.486386253235646
Validation loss: 3.2318257308205034

Epoch: 6| Step: 1
Training loss: 2.2676399478813956
Validation loss: 3.234008192818448

Epoch: 6| Step: 2
Training loss: 3.5977811015082777
Validation loss: 3.2337424597161593

Epoch: 6| Step: 3
Training loss: 3.1119858405175997
Validation loss: 3.2332935591081173

Epoch: 6| Step: 4
Training loss: 3.0032218480843262
Validation loss: 3.2350828793038975

Epoch: 6| Step: 5
Training loss: 2.9345966356972477
Validation loss: 3.2369426110485024

Epoch: 6| Step: 6
Training loss: 4.529964290924464
Validation loss: 3.244573030578876

Epoch: 6| Step: 7
Training loss: 3.185072928511453
Validation loss: 3.256214215544911

Epoch: 6| Step: 8
Training loss: 2.94136734287017
Validation loss: 3.2457545738411766

Epoch: 6| Step: 9
Training loss: 4.238192143360536
Validation loss: 3.237250783601406

Epoch: 6| Step: 10
Training loss: 3.9197048551036398
Validation loss: 3.235775277916636

Epoch: 6| Step: 11
Training loss: 4.221434692643937
Validation loss: 3.2312951928779463

Epoch: 6| Step: 12
Training loss: 3.2020229025312985
Validation loss: 3.231797340335064

Epoch: 6| Step: 13
Training loss: 3.2593943462730315
Validation loss: 3.2314009326550495

Epoch: 63| Step: 0
Training loss: 3.228656228033322
Validation loss: 3.2314304690408613

Epoch: 6| Step: 1
Training loss: 3.5263532597602967
Validation loss: 3.239257586151469

Epoch: 6| Step: 2
Training loss: 3.71762067813134
Validation loss: 3.237632296642463

Epoch: 6| Step: 3
Training loss: 3.741329214147728
Validation loss: 3.2429196241398657

Epoch: 6| Step: 4
Training loss: 2.943372011315775
Validation loss: 3.232799658221013

Epoch: 6| Step: 5
Training loss: 3.4346220974113537
Validation loss: 3.231683529981369

Epoch: 6| Step: 6
Training loss: 3.3739890951128504
Validation loss: 3.229592002672337

Epoch: 6| Step: 7
Training loss: 3.8729577374071855
Validation loss: 3.228238590393636

Epoch: 6| Step: 8
Training loss: 3.4398812109375707
Validation loss: 3.2281253057825032

Epoch: 6| Step: 9
Training loss: 4.301730433191814
Validation loss: 3.22719960287884

Epoch: 6| Step: 10
Training loss: 3.2757529579794973
Validation loss: 3.231772237670992

Epoch: 6| Step: 11
Training loss: 3.0003054781198752
Validation loss: 3.235081372064112

Epoch: 6| Step: 12
Training loss: 3.318851355892542
Validation loss: 3.2423810023179844

Epoch: 6| Step: 13
Training loss: 3.054158743049644
Validation loss: 3.2393452230048134

Epoch: 64| Step: 0
Training loss: 3.4737781819191818
Validation loss: 3.233651417367759

Epoch: 6| Step: 1
Training loss: 4.308520042363077
Validation loss: 3.2279981475087554

Epoch: 6| Step: 2
Training loss: 4.110584849677292
Validation loss: 3.2263786614931886

Epoch: 6| Step: 3
Training loss: 3.7248129266449044
Validation loss: 3.2243531128024148

Epoch: 6| Step: 4
Training loss: 2.4878012584963702
Validation loss: 3.222824484671516

Epoch: 6| Step: 5
Training loss: 3.40018055380327
Validation loss: 3.2239865776212535

Epoch: 6| Step: 6
Training loss: 3.30581176968744
Validation loss: 3.2246040435671612

Epoch: 6| Step: 7
Training loss: 3.7513827000007924
Validation loss: 3.222127618722214

Epoch: 6| Step: 8
Training loss: 3.885047683717761
Validation loss: 3.220851266080326

Epoch: 6| Step: 9
Training loss: 2.9215867823465773
Validation loss: 3.2218935914065825

Epoch: 6| Step: 10
Training loss: 2.4366161993865165
Validation loss: 3.2211273729229135

Epoch: 6| Step: 11
Training loss: 3.038739106297238
Validation loss: 3.2178586702783423

Epoch: 6| Step: 12
Training loss: 4.272706131357096
Validation loss: 3.2190561603933148

Epoch: 6| Step: 13
Training loss: 1.9057348837344925
Validation loss: 3.214557239857033

Epoch: 65| Step: 0
Training loss: 3.268753086766961
Validation loss: 3.212350069402312

Epoch: 6| Step: 1
Training loss: 3.6668409537306164
Validation loss: 3.2095718132209616

Epoch: 6| Step: 2
Training loss: 4.38258793709461
Validation loss: 3.208697704393956

Epoch: 6| Step: 3
Training loss: 2.811629181728646
Validation loss: 3.205195729089466

Epoch: 6| Step: 4
Training loss: 3.838651423478897
Validation loss: 3.203852317866575

Epoch: 6| Step: 5
Training loss: 3.1592873037601685
Validation loss: 3.2013999193387495

Epoch: 6| Step: 6
Training loss: 3.694442549842852
Validation loss: 3.2022875219492115

Epoch: 6| Step: 7
Training loss: 3.971969139970369
Validation loss: 3.2044501444072906

Epoch: 6| Step: 8
Training loss: 3.4666043080321116
Validation loss: 3.20118883043317

Epoch: 6| Step: 9
Training loss: 2.809625470598204
Validation loss: 3.2025955526971375

Epoch: 6| Step: 10
Training loss: 3.192955434840034
Validation loss: 3.2050190909706906

Epoch: 6| Step: 11
Training loss: 3.62110718165996
Validation loss: 3.2049194223857893

Epoch: 6| Step: 12
Training loss: 3.119225316340049
Validation loss: 3.1971995412850616

Epoch: 6| Step: 13
Training loss: 2.465678561829111
Validation loss: 3.194866715857064

Epoch: 66| Step: 0
Training loss: 3.3205264751824664
Validation loss: 3.1953624965433787

Epoch: 6| Step: 1
Training loss: 3.1918047092422364
Validation loss: 3.1952805830286652

Epoch: 6| Step: 2
Training loss: 3.8041500518759115
Validation loss: 3.193554370058715

Epoch: 6| Step: 3
Training loss: 3.0339822941303054
Validation loss: 3.195206371488209

Epoch: 6| Step: 4
Training loss: 3.9373655750398373
Validation loss: 3.19490267151251

Epoch: 6| Step: 5
Training loss: 4.064100214435972
Validation loss: 3.193944929664982

Epoch: 6| Step: 6
Training loss: 3.399711282476678
Validation loss: 3.193035483488593

Epoch: 6| Step: 7
Training loss: 3.376111871746023
Validation loss: 3.1912013582171848

Epoch: 6| Step: 8
Training loss: 3.2636686606993446
Validation loss: 3.193006006228715

Epoch: 6| Step: 9
Training loss: 3.8605438809844963
Validation loss: 3.1906367404059623

Epoch: 6| Step: 10
Training loss: 2.9131728545217266
Validation loss: 3.191073286138534

Epoch: 6| Step: 11
Training loss: 3.278672577514326
Validation loss: 3.1924469787027143

Epoch: 6| Step: 12
Training loss: 3.082981519130831
Validation loss: 3.190965381703818

Epoch: 6| Step: 13
Training loss: 3.44762289557108
Validation loss: 3.189873784050266

Epoch: 67| Step: 0
Training loss: 3.2344481234185745
Validation loss: 3.1905938289987374

Epoch: 6| Step: 1
Training loss: 3.606338610957086
Validation loss: 3.1927088820276603

Epoch: 6| Step: 2
Training loss: 3.0925020725795305
Validation loss: 3.1918195249373427

Epoch: 6| Step: 3
Training loss: 3.828035563767116
Validation loss: 3.196142810105671

Epoch: 6| Step: 4
Training loss: 3.508485181577392
Validation loss: 3.1914846506275274

Epoch: 6| Step: 5
Training loss: 3.104590948069324
Validation loss: 3.1901344866773558

Epoch: 6| Step: 6
Training loss: 3.254397131996804
Validation loss: 3.1906337401776654

Epoch: 6| Step: 7
Training loss: 3.8653087637722336
Validation loss: 3.18887928045412

Epoch: 6| Step: 8
Training loss: 2.9406070915430873
Validation loss: 3.1895318340570684

Epoch: 6| Step: 9
Training loss: 3.124900358518874
Validation loss: 3.188924629909914

Epoch: 6| Step: 10
Training loss: 3.8248019996208575
Validation loss: 3.187003698443401

Epoch: 6| Step: 11
Training loss: 3.605204497104482
Validation loss: 3.1869468345704908

Epoch: 6| Step: 12
Training loss: 3.3705013103768335
Validation loss: 3.1885286007044438

Epoch: 6| Step: 13
Training loss: 3.751685336007352
Validation loss: 3.1873620277059285

Epoch: 68| Step: 0
Training loss: 3.66170596736421
Validation loss: 3.1881763955853857

Epoch: 6| Step: 1
Training loss: 3.5392406157751606
Validation loss: 3.186649745562942

Epoch: 6| Step: 2
Training loss: 3.401786469501287
Validation loss: 3.186348430611471

Epoch: 6| Step: 3
Training loss: 3.8715384003741056
Validation loss: 3.1847773020015264

Epoch: 6| Step: 4
Training loss: 2.7870112550889408
Validation loss: 3.18647861785145

Epoch: 6| Step: 5
Training loss: 2.9124283286514108
Validation loss: 3.1863546145311625

Epoch: 6| Step: 6
Training loss: 3.9889379366093904
Validation loss: 3.185116064006836

Epoch: 6| Step: 7
Training loss: 3.5857319159988923
Validation loss: 3.185623753992628

Epoch: 6| Step: 8
Training loss: 3.1849663332323064
Validation loss: 3.186210974892882

Epoch: 6| Step: 9
Training loss: 2.8711138458586674
Validation loss: 3.183846459901838

Epoch: 6| Step: 10
Training loss: 3.122599633538458
Validation loss: 3.1833682239744108

Epoch: 6| Step: 11
Training loss: 3.383820768926129
Validation loss: 3.1838907650474004

Epoch: 6| Step: 12
Training loss: 3.8701302477384982
Validation loss: 3.1860733555347376

Epoch: 6| Step: 13
Training loss: 3.7794181232569164
Validation loss: 3.1860875461262634

Epoch: 69| Step: 0
Training loss: 3.075767582559487
Validation loss: 3.182874482229358

Epoch: 6| Step: 1
Training loss: 3.8254118354838047
Validation loss: 3.181275982932666

Epoch: 6| Step: 2
Training loss: 3.740706435411003
Validation loss: 3.1811569771782384

Epoch: 6| Step: 3
Training loss: 3.1819671781754506
Validation loss: 3.1789303842927508

Epoch: 6| Step: 4
Training loss: 3.265229853766011
Validation loss: 3.181657112430527

Epoch: 6| Step: 5
Training loss: 3.8944433387927706
Validation loss: 3.18109061362478

Epoch: 6| Step: 6
Training loss: 3.5435135158637925
Validation loss: 3.1855077233803266

Epoch: 6| Step: 7
Training loss: 2.276490563674496
Validation loss: 3.1818031121435

Epoch: 6| Step: 8
Training loss: 3.8796397089079107
Validation loss: 3.1807749841909283

Epoch: 6| Step: 9
Training loss: 3.7896541802045727
Validation loss: 3.183947440336951

Epoch: 6| Step: 10
Training loss: 3.033740406877827
Validation loss: 3.181262085162334

Epoch: 6| Step: 11
Training loss: 3.612662531486473
Validation loss: 3.1805487238899905

Epoch: 6| Step: 12
Training loss: 3.4587213382836204
Validation loss: 3.1806954869841277

Epoch: 6| Step: 13
Training loss: 2.93533992482015
Validation loss: 3.181787384461076

Epoch: 70| Step: 0
Training loss: 3.2629411245699282
Validation loss: 3.180822940438167

Epoch: 6| Step: 1
Training loss: 2.969158264999073
Validation loss: 3.182795903340421

Epoch: 6| Step: 2
Training loss: 3.694622596390698
Validation loss: 3.1819281106142245

Epoch: 6| Step: 3
Training loss: 3.3033395457538144
Validation loss: 3.18047976988294

Epoch: 6| Step: 4
Training loss: 3.583165778449221
Validation loss: 3.1764601772959535

Epoch: 6| Step: 5
Training loss: 3.6423961604181265
Validation loss: 3.177321774905301

Epoch: 6| Step: 6
Training loss: 3.767995507676996
Validation loss: 3.178506203288049

Epoch: 6| Step: 7
Training loss: 3.7690027054159323
Validation loss: 3.1785609340380905

Epoch: 6| Step: 8
Training loss: 3.253352563467673
Validation loss: 3.1770793676057405

Epoch: 6| Step: 9
Training loss: 2.7010967605529026
Validation loss: 3.1786587942190514

Epoch: 6| Step: 10
Training loss: 3.0171947445577514
Validation loss: 3.17770277924367

Epoch: 6| Step: 11
Training loss: 2.914156751156756
Validation loss: 3.17680930508004

Epoch: 6| Step: 12
Training loss: 4.1197696239912185
Validation loss: 3.176546894674317

Epoch: 6| Step: 13
Training loss: 4.022657122438728
Validation loss: 3.1773253468541047

Epoch: 71| Step: 0
Training loss: 3.6262730960840237
Validation loss: 3.1764373095591716

Epoch: 6| Step: 1
Training loss: 3.4431156411894612
Validation loss: 3.1771147184605364

Epoch: 6| Step: 2
Training loss: 3.5149413397765703
Validation loss: 3.1788818946508024

Epoch: 6| Step: 3
Training loss: 3.6003049032579644
Validation loss: 3.180273986329833

Epoch: 6| Step: 4
Training loss: 3.2452870455658736
Validation loss: 3.177796328038436

Epoch: 6| Step: 5
Training loss: 3.5936338986425906
Validation loss: 3.1784296393091163

Epoch: 6| Step: 6
Training loss: 3.5480695553039685
Validation loss: 3.1738138165904726

Epoch: 6| Step: 7
Training loss: 2.9289488001001995
Validation loss: 3.1771950354962044

Epoch: 6| Step: 8
Training loss: 3.8437303992291145
Validation loss: 3.1751408930775074

Epoch: 6| Step: 9
Training loss: 2.8276860860745123
Validation loss: 3.174209187667357

Epoch: 6| Step: 10
Training loss: 4.0043549672342085
Validation loss: 3.1729711528493567

Epoch: 6| Step: 11
Training loss: 3.5941578509226098
Validation loss: 3.1710826482815144

Epoch: 6| Step: 12
Training loss: 2.8334223415381166
Validation loss: 3.1727221760041906

Epoch: 6| Step: 13
Training loss: 2.973988939830375
Validation loss: 3.1728178286289346

Epoch: 72| Step: 0
Training loss: 3.6385020340796776
Validation loss: 3.172351556663124

Epoch: 6| Step: 1
Training loss: 4.06524002398834
Validation loss: 3.1718477096123143

Epoch: 6| Step: 2
Training loss: 3.145284811202175
Validation loss: 3.1700964010051

Epoch: 6| Step: 3
Training loss: 3.0448783396703316
Validation loss: 3.1699531746767597

Epoch: 6| Step: 4
Training loss: 3.5855224635141734
Validation loss: 3.169726092561084

Epoch: 6| Step: 5
Training loss: 3.1645917285023466
Validation loss: 3.16902216063138

Epoch: 6| Step: 6
Training loss: 3.03129089957105
Validation loss: 3.1690153393975713

Epoch: 6| Step: 7
Training loss: 3.300136886994294
Validation loss: 3.169071683707648

Epoch: 6| Step: 8
Training loss: 3.49245033725826
Validation loss: 3.1687204259139707

Epoch: 6| Step: 9
Training loss: 4.12620157023301
Validation loss: 3.1680511164079173

Epoch: 6| Step: 10
Training loss: 2.8433217155812494
Validation loss: 3.168670883593906

Epoch: 6| Step: 11
Training loss: 3.2778479969096685
Validation loss: 3.166842610102672

Epoch: 6| Step: 12
Training loss: 3.130153221791951
Validation loss: 3.168382507400225

Epoch: 6| Step: 13
Training loss: 4.132708196639852
Validation loss: 3.1675911046794316

Epoch: 73| Step: 0
Training loss: 3.061563776897317
Validation loss: 3.1686288672807392

Epoch: 6| Step: 1
Training loss: 3.632134880939165
Validation loss: 3.1674081185846994

Epoch: 6| Step: 2
Training loss: 3.7028808513265847
Validation loss: 3.1663454235021793

Epoch: 6| Step: 3
Training loss: 3.1102523716032238
Validation loss: 3.168192472125006

Epoch: 6| Step: 4
Training loss: 3.4894151030266474
Validation loss: 3.1709816429962547

Epoch: 6| Step: 5
Training loss: 2.6452015600583185
Validation loss: 3.1666701618514232

Epoch: 6| Step: 6
Training loss: 3.8200764651409695
Validation loss: 3.165892493966602

Epoch: 6| Step: 7
Training loss: 3.5131192241866214
Validation loss: 3.167433814715322

Epoch: 6| Step: 8
Training loss: 2.758073486427957
Validation loss: 3.1652583135389203

Epoch: 6| Step: 9
Training loss: 4.029448350582219
Validation loss: 3.163945107438905

Epoch: 6| Step: 10
Training loss: 3.727730941730906
Validation loss: 3.1657060505712407

Epoch: 6| Step: 11
Training loss: 3.308572564175456
Validation loss: 3.1641818489060634

Epoch: 6| Step: 12
Training loss: 3.6664799440408387
Validation loss: 3.165393447631324

Epoch: 6| Step: 13
Training loss: 2.8940149173628917
Validation loss: 3.165632024389818

Epoch: 74| Step: 0
Training loss: 3.6715630581425387
Validation loss: 3.1646564387518272

Epoch: 6| Step: 1
Training loss: 3.695201783406797
Validation loss: 3.162429489847115

Epoch: 6| Step: 2
Training loss: 3.130224514547576
Validation loss: 3.164884573140573

Epoch: 6| Step: 3
Training loss: 3.851442903901939
Validation loss: 3.1644027715372602

Epoch: 6| Step: 4
Training loss: 3.151433007185667
Validation loss: 3.1625991117040924

Epoch: 6| Step: 5
Training loss: 3.6359470421403985
Validation loss: 3.1613962542038556

Epoch: 6| Step: 6
Training loss: 3.0334335799647265
Validation loss: 3.1637902243323204

Epoch: 6| Step: 7
Training loss: 3.053496379774567
Validation loss: 3.1630080860053216

Epoch: 6| Step: 8
Training loss: 3.4526214922964527
Validation loss: 3.1618239760361817

Epoch: 6| Step: 9
Training loss: 3.3938754625822054
Validation loss: 3.1614028534669782

Epoch: 6| Step: 10
Training loss: 4.299018907624766
Validation loss: 3.1627199278652283

Epoch: 6| Step: 11
Training loss: 3.36205436845034
Validation loss: 3.160761390635695

Epoch: 6| Step: 12
Training loss: 2.925613378132125
Validation loss: 3.162350237557989

Epoch: 6| Step: 13
Training loss: 2.4370726186258405
Validation loss: 3.162153269644826

Epoch: 75| Step: 0
Training loss: 3.172583590128484
Validation loss: 3.1634353435442013

Epoch: 6| Step: 1
Training loss: 3.7916529029903794
Validation loss: 3.162681559592137

Epoch: 6| Step: 2
Training loss: 3.964094660609341
Validation loss: 3.162183465810244

Epoch: 6| Step: 3
Training loss: 3.3032376330614834
Validation loss: 3.171312444824236

Epoch: 6| Step: 4
Training loss: 3.5178840669372042
Validation loss: 3.1644513704371535

Epoch: 6| Step: 5
Training loss: 2.745634862724459
Validation loss: 3.161345707510962

Epoch: 6| Step: 6
Training loss: 3.9400334760531455
Validation loss: 3.1603622881450666

Epoch: 6| Step: 7
Training loss: 3.5063351109148395
Validation loss: 3.161253115408038

Epoch: 6| Step: 8
Training loss: 3.188748732162457
Validation loss: 3.159448869767331

Epoch: 6| Step: 9
Training loss: 3.216423453061916
Validation loss: 3.1597650854920665

Epoch: 6| Step: 10
Training loss: 3.20924767350275
Validation loss: 3.1596424508455283

Epoch: 6| Step: 11
Training loss: 3.238388593525833
Validation loss: 3.158871644112598

Epoch: 6| Step: 12
Training loss: 3.495829413453103
Validation loss: 3.161035359441193

Epoch: 6| Step: 13
Training loss: 3.2633165295031548
Validation loss: 3.1591545523292317

Epoch: 76| Step: 0
Training loss: 2.652088091162534
Validation loss: 3.16071522506187

Epoch: 6| Step: 1
Training loss: 3.714866084564169
Validation loss: 3.1574569144166618

Epoch: 6| Step: 2
Training loss: 2.6800342035246056
Validation loss: 3.158544095949562

Epoch: 6| Step: 3
Training loss: 3.380281060626191
Validation loss: 3.1595535558444148

Epoch: 6| Step: 4
Training loss: 3.293545890723516
Validation loss: 3.1587761843633317

Epoch: 6| Step: 5
Training loss: 3.732853280152465
Validation loss: 3.158412162305034

Epoch: 6| Step: 6
Training loss: 3.654900065254796
Validation loss: 3.1564980020297573

Epoch: 6| Step: 7
Training loss: 3.6013615152875094
Validation loss: 3.156166283484006

Epoch: 6| Step: 8
Training loss: 4.135703101755979
Validation loss: 3.1578574711394083

Epoch: 6| Step: 9
Training loss: 2.535963591172869
Validation loss: 3.155607142001006

Epoch: 6| Step: 10
Training loss: 3.3890360260030987
Validation loss: 3.157193194351435

Epoch: 6| Step: 11
Training loss: 3.7619171248722023
Validation loss: 3.156823800472096

Epoch: 6| Step: 12
Training loss: 3.7204742281133547
Validation loss: 3.158156139500585

Epoch: 6| Step: 13
Training loss: 2.8856518003505225
Validation loss: 3.1571629082329866

Epoch: 77| Step: 0
Training loss: 3.167358490177241
Validation loss: 3.156974005227173

Epoch: 6| Step: 1
Training loss: 3.3639982834855826
Validation loss: 3.1547303149124875

Epoch: 6| Step: 2
Training loss: 2.947254299700739
Validation loss: 3.1542879697348307

Epoch: 6| Step: 3
Training loss: 3.0561822614593503
Validation loss: 3.1537099027150806

Epoch: 6| Step: 4
Training loss: 3.5109100598772627
Validation loss: 3.154011001567935

Epoch: 6| Step: 5
Training loss: 3.9576862542476188
Validation loss: 3.1532806526204

Epoch: 6| Step: 6
Training loss: 3.528188002423388
Validation loss: 3.151982096909435

Epoch: 6| Step: 7
Training loss: 2.799522808828912
Validation loss: 3.154764846786234

Epoch: 6| Step: 8
Training loss: 3.0297435674648647
Validation loss: 3.1538311601971274

Epoch: 6| Step: 9
Training loss: 2.650935612463917
Validation loss: 3.1580547743591985

Epoch: 6| Step: 10
Training loss: 4.2645367362503865
Validation loss: 3.154397520547821

Epoch: 6| Step: 11
Training loss: 3.830218556196555
Validation loss: 3.1610838333139917

Epoch: 6| Step: 12
Training loss: 3.981611422867013
Validation loss: 3.1525718158262395

Epoch: 6| Step: 13
Training loss: 3.15748194456035
Validation loss: 3.152435967843133

Epoch: 78| Step: 0
Training loss: 4.017448990693256
Validation loss: 3.151827235968483

Epoch: 6| Step: 1
Training loss: 3.813877044632177
Validation loss: 3.150580591598185

Epoch: 6| Step: 2
Training loss: 3.584183673358568
Validation loss: 3.1513002616818437

Epoch: 6| Step: 3
Training loss: 2.8846935555063187
Validation loss: 3.149952754629826

Epoch: 6| Step: 4
Training loss: 3.0682752999600957
Validation loss: 3.15136301586366

Epoch: 6| Step: 5
Training loss: 3.52046216704979
Validation loss: 3.1494913969651015

Epoch: 6| Step: 6
Training loss: 3.1944732683143706
Validation loss: 3.150094017504773

Epoch: 6| Step: 7
Training loss: 2.789126611822221
Validation loss: 3.148747290411715

Epoch: 6| Step: 8
Training loss: 4.060487219228689
Validation loss: 3.147690660232721

Epoch: 6| Step: 9
Training loss: 3.906213867020384
Validation loss: 3.1475265334363014

Epoch: 6| Step: 10
Training loss: 2.990930357902496
Validation loss: 3.1491501264097046

Epoch: 6| Step: 11
Training loss: 3.395944948448886
Validation loss: 3.150507961152214

Epoch: 6| Step: 12
Training loss: 2.897855715701428
Validation loss: 3.152639015525188

Epoch: 6| Step: 13
Training loss: 3.1966983988767765
Validation loss: 3.1496431283653252

Epoch: 79| Step: 0
Training loss: 3.513123839017971
Validation loss: 3.1512177161463493

Epoch: 6| Step: 1
Training loss: 3.24420970680135
Validation loss: 3.1497368740589398

Epoch: 6| Step: 2
Training loss: 3.6827625942935467
Validation loss: 3.1493618387247175

Epoch: 6| Step: 3
Training loss: 3.380622701222729
Validation loss: 3.148282261129243

Epoch: 6| Step: 4
Training loss: 3.5883819293534858
Validation loss: 3.1478930546382164

Epoch: 6| Step: 5
Training loss: 3.5346853374629386
Validation loss: 3.1472401305631057

Epoch: 6| Step: 6
Training loss: 3.047898497215518
Validation loss: 3.1482735269544397

Epoch: 6| Step: 7
Training loss: 3.4484866651686783
Validation loss: 3.1468263517674564

Epoch: 6| Step: 8
Training loss: 3.4095069642930764
Validation loss: 3.148263401926024

Epoch: 6| Step: 9
Training loss: 3.9133977572993954
Validation loss: 3.148020901267514

Epoch: 6| Step: 10
Training loss: 3.4235668441734037
Validation loss: 3.1470809436874823

Epoch: 6| Step: 11
Training loss: 2.5922735217205717
Validation loss: 3.1451792882904455

Epoch: 6| Step: 12
Training loss: 3.6091406279594724
Validation loss: 3.1471591614769876

Epoch: 6| Step: 13
Training loss: 3.019267516073752
Validation loss: 3.1483347389548415

Epoch: 80| Step: 0
Training loss: 3.599612686726976
Validation loss: 3.1507994818139418

Epoch: 6| Step: 1
Training loss: 2.902871742329825
Validation loss: 3.157573038058517

Epoch: 6| Step: 2
Training loss: 3.5180942934030903
Validation loss: 3.163095378040709

Epoch: 6| Step: 3
Training loss: 3.25899229939181
Validation loss: 3.162041468519696

Epoch: 6| Step: 4
Training loss: 4.277125244133483
Validation loss: 3.1615290039476025

Epoch: 6| Step: 5
Training loss: 3.0205374912662513
Validation loss: 3.149797440680128

Epoch: 6| Step: 6
Training loss: 3.0677852566999513
Validation loss: 3.146372496204678

Epoch: 6| Step: 7
Training loss: 3.4845340162180456
Validation loss: 3.1475632334954495

Epoch: 6| Step: 8
Training loss: 2.5436406105009026
Validation loss: 3.145319953746897

Epoch: 6| Step: 9
Training loss: 3.0016544866094135
Validation loss: 3.145035140792018

Epoch: 6| Step: 10
Training loss: 3.833251012388128
Validation loss: 3.143104840644311

Epoch: 6| Step: 11
Training loss: 3.1556271986671325
Validation loss: 3.145252349072793

Epoch: 6| Step: 12
Training loss: 4.167323912600183
Validation loss: 3.143200879103466

Epoch: 6| Step: 13
Training loss: 3.422817710023396
Validation loss: 3.1436089502901647

Epoch: 81| Step: 0
Training loss: 3.691121149911332
Validation loss: 3.1448815974717492

Epoch: 6| Step: 1
Training loss: 3.72918954057267
Validation loss: 3.14499187780994

Epoch: 6| Step: 2
Training loss: 3.06265990170684
Validation loss: 3.1426196762892027

Epoch: 6| Step: 3
Training loss: 2.3864182503135716
Validation loss: 3.14269396798872

Epoch: 6| Step: 4
Training loss: 3.2012496296421777
Validation loss: 3.1417334497392653

Epoch: 6| Step: 5
Training loss: 3.4190966331034027
Validation loss: 3.1432027648039345

Epoch: 6| Step: 6
Training loss: 3.341701414794878
Validation loss: 3.1444616089022923

Epoch: 6| Step: 7
Training loss: 2.704958784314709
Validation loss: 3.1423302889251845

Epoch: 6| Step: 8
Training loss: 3.8728932221790457
Validation loss: 3.1440317337936206

Epoch: 6| Step: 9
Training loss: 3.87191760614705
Validation loss: 3.1523810990557144

Epoch: 6| Step: 10
Training loss: 3.2568750290476274
Validation loss: 3.1558523464695667

Epoch: 6| Step: 11
Training loss: 3.22096132038132
Validation loss: 3.161687760151664

Epoch: 6| Step: 12
Training loss: 3.654012924898086
Validation loss: 3.1607598528214704

Epoch: 6| Step: 13
Training loss: 4.1533266269717455
Validation loss: 3.1565216444649398

Epoch: 82| Step: 0
Training loss: 3.5430096641794178
Validation loss: 3.1463633411831027

Epoch: 6| Step: 1
Training loss: 4.1069676995689575
Validation loss: 3.140459495774761

Epoch: 6| Step: 2
Training loss: 3.6132307059387143
Validation loss: 3.1394036969794454

Epoch: 6| Step: 3
Training loss: 3.015929686022656
Validation loss: 3.138949888726051

Epoch: 6| Step: 4
Training loss: 3.065009976443908
Validation loss: 3.139119572254043

Epoch: 6| Step: 5
Training loss: 3.8482557730102656
Validation loss: 3.1387209409178967

Epoch: 6| Step: 6
Training loss: 3.4059896107110315
Validation loss: 3.138669577364556

Epoch: 6| Step: 7
Training loss: 3.902992293924694
Validation loss: 3.139526550583841

Epoch: 6| Step: 8
Training loss: 2.5980121569506895
Validation loss: 3.1391068631311776

Epoch: 6| Step: 9
Training loss: 3.571894923143734
Validation loss: 3.138278849509379

Epoch: 6| Step: 10
Training loss: 2.83484168200987
Validation loss: 3.1394736119572766

Epoch: 6| Step: 11
Training loss: 3.35424498156624
Validation loss: 3.137732796701246

Epoch: 6| Step: 12
Training loss: 2.7595895547713654
Validation loss: 3.1390101073050474

Epoch: 6| Step: 13
Training loss: 3.728295393165124
Validation loss: 3.1387998089020166

Epoch: 83| Step: 0
Training loss: 3.1979498017589822
Validation loss: 3.1383725000885323

Epoch: 6| Step: 1
Training loss: 3.89777082655995
Validation loss: 3.1366673078908263

Epoch: 6| Step: 2
Training loss: 3.700018630109743
Validation loss: 3.13639676626183

Epoch: 6| Step: 3
Training loss: 3.657443251257555
Validation loss: 3.136209869103816

Epoch: 6| Step: 4
Training loss: 3.2286780859381423
Validation loss: 3.1359238461536063

Epoch: 6| Step: 5
Training loss: 3.6840385095693877
Validation loss: 3.135502387914246

Epoch: 6| Step: 6
Training loss: 2.8254277133392858
Validation loss: 3.136927000967155

Epoch: 6| Step: 7
Training loss: 3.0282839391861867
Validation loss: 3.1366120120564314

Epoch: 6| Step: 8
Training loss: 2.6258000562426242
Validation loss: 3.139625407792341

Epoch: 6| Step: 9
Training loss: 3.5823107894264306
Validation loss: 3.1378006246623094

Epoch: 6| Step: 10
Training loss: 3.459948258426529
Validation loss: 3.1373100566773573

Epoch: 6| Step: 11
Training loss: 3.493185630349967
Validation loss: 3.1426613820224145

Epoch: 6| Step: 12
Training loss: 3.0114098376857066
Validation loss: 3.1393049316010844

Epoch: 6| Step: 13
Training loss: 4.183771551718934
Validation loss: 3.139593565701583

Epoch: 84| Step: 0
Training loss: 3.4964877625824977
Validation loss: 3.134999195733412

Epoch: 6| Step: 1
Training loss: 3.6734698788649043
Validation loss: 3.134362018281745

Epoch: 6| Step: 2
Training loss: 3.5271164999384674
Validation loss: 3.1341675783963363

Epoch: 6| Step: 3
Training loss: 3.7565602458467597
Validation loss: 3.132983407850726

Epoch: 6| Step: 4
Training loss: 2.12953588291666
Validation loss: 3.131473014621315

Epoch: 6| Step: 5
Training loss: 3.3594953648495056
Validation loss: 3.1320176974835263

Epoch: 6| Step: 6
Training loss: 3.5288266669338793
Validation loss: 3.132598721543387

Epoch: 6| Step: 7
Training loss: 3.573788876557218
Validation loss: 3.1324857935714956

Epoch: 6| Step: 8
Training loss: 3.0802330892473444
Validation loss: 3.136160128744404

Epoch: 6| Step: 9
Training loss: 3.601036711933912
Validation loss: 3.1342563566495425

Epoch: 6| Step: 10
Training loss: 3.497004725936563
Validation loss: 3.1336408723932223

Epoch: 6| Step: 11
Training loss: 2.855654103829414
Validation loss: 3.1315689988440947

Epoch: 6| Step: 12
Training loss: 3.51440340646969
Validation loss: 3.1327400795499027

Epoch: 6| Step: 13
Training loss: 3.718644853916618
Validation loss: 3.1307990397711922

Epoch: 85| Step: 0
Training loss: 3.185264252101055
Validation loss: 3.1315214418071307

Epoch: 6| Step: 1
Training loss: 3.105876545552147
Validation loss: 3.1295827459174217

Epoch: 6| Step: 2
Training loss: 3.868232231435113
Validation loss: 3.129651530338858

Epoch: 6| Step: 3
Training loss: 3.422042772891939
Validation loss: 3.1309663761987805

Epoch: 6| Step: 4
Training loss: 3.6218063492806256
Validation loss: 3.129430292559713

Epoch: 6| Step: 5
Training loss: 3.3962232369781913
Validation loss: 3.128703317276452

Epoch: 6| Step: 6
Training loss: 3.202069066615061
Validation loss: 3.129761547865886

Epoch: 6| Step: 7
Training loss: 2.5262782874168144
Validation loss: 3.1290330977756433

Epoch: 6| Step: 8
Training loss: 3.900416175938155
Validation loss: 3.1283079560095626

Epoch: 6| Step: 9
Training loss: 3.5085983925285196
Validation loss: 3.129134013544117

Epoch: 6| Step: 10
Training loss: 2.8261420954234007
Validation loss: 3.1280655031876154

Epoch: 6| Step: 11
Training loss: 3.6514187707392094
Validation loss: 3.1290339514940584

Epoch: 6| Step: 12
Training loss: 3.999387098086325
Validation loss: 3.1292071417285503

Epoch: 6| Step: 13
Training loss: 2.467124210485682
Validation loss: 3.1312494788307483

Epoch: 86| Step: 0
Training loss: 3.2512194473139284
Validation loss: 3.1333835561999757

Epoch: 6| Step: 1
Training loss: 4.0744289442722925
Validation loss: 3.13304999669064

Epoch: 6| Step: 2
Training loss: 3.1480882323137984
Validation loss: 3.1303222732700866

Epoch: 6| Step: 3
Training loss: 3.8653426885247115
Validation loss: 3.1292313508282703

Epoch: 6| Step: 4
Training loss: 2.716199270267106
Validation loss: 3.1279021309006705

Epoch: 6| Step: 5
Training loss: 2.923565870001946
Validation loss: 3.1261365189730057

Epoch: 6| Step: 6
Training loss: 3.4998280619214275
Validation loss: 3.1254245904406823

Epoch: 6| Step: 7
Training loss: 3.3485159020583866
Validation loss: 3.12712791104868

Epoch: 6| Step: 8
Training loss: 2.873969681263322
Validation loss: 3.1267031157138563

Epoch: 6| Step: 9
Training loss: 3.7169051522917305
Validation loss: 3.1257933202380697

Epoch: 6| Step: 10
Training loss: 3.257656029618844
Validation loss: 3.12586879179566

Epoch: 6| Step: 11
Training loss: 4.357559099349232
Validation loss: 3.12564058690801

Epoch: 6| Step: 12
Training loss: 2.5086021249750714
Validation loss: 3.126608986053463

Epoch: 6| Step: 13
Training loss: 3.3882588511353973
Validation loss: 3.1262139241158517

Epoch: 87| Step: 0
Training loss: 3.6965380324010995
Validation loss: 3.1251509394135604

Epoch: 6| Step: 1
Training loss: 2.8879524041689324
Validation loss: 3.1268371251840663

Epoch: 6| Step: 2
Training loss: 2.8044799047801927
Validation loss: 3.125334989579349

Epoch: 6| Step: 3
Training loss: 3.499513319783452
Validation loss: 3.124737413100344

Epoch: 6| Step: 4
Training loss: 3.000789856246608
Validation loss: 3.1255929642743783

Epoch: 6| Step: 5
Training loss: 3.5375561066077044
Validation loss: 3.125978568485284

Epoch: 6| Step: 6
Training loss: 4.21450660071273
Validation loss: 3.1241723324309136

Epoch: 6| Step: 7
Training loss: 3.137108043489398
Validation loss: 3.123403757610091

Epoch: 6| Step: 8
Training loss: 3.5166411563134834
Validation loss: 3.123888675421728

Epoch: 6| Step: 9
Training loss: 3.359381813219835
Validation loss: 3.1223798009379125

Epoch: 6| Step: 10
Training loss: 3.325839121778538
Validation loss: 3.1219418778037515

Epoch: 6| Step: 11
Training loss: 3.5978740083646508
Validation loss: 3.122543316014759

Epoch: 6| Step: 12
Training loss: 3.3289003140715088
Validation loss: 3.1222768260032923

Epoch: 6| Step: 13
Training loss: 3.1250868213036953
Validation loss: 3.1215229436736345

Epoch: 88| Step: 0
Training loss: 2.9932817893344636
Validation loss: 3.121046051417001

Epoch: 6| Step: 1
Training loss: 3.8699127767033707
Validation loss: 3.1218255998071704

Epoch: 6| Step: 2
Training loss: 3.42056263182853
Validation loss: 3.1211205781818068

Epoch: 6| Step: 3
Training loss: 2.398416624692847
Validation loss: 3.122109135512777

Epoch: 6| Step: 4
Training loss: 3.2826479885562603
Validation loss: 3.1219848196990965

Epoch: 6| Step: 5
Training loss: 2.6501889359400774
Validation loss: 3.119162548445658

Epoch: 6| Step: 6
Training loss: 3.821190606361646
Validation loss: 3.1205724060809765

Epoch: 6| Step: 7
Training loss: 4.1135650276041735
Validation loss: 3.121348651125982

Epoch: 6| Step: 8
Training loss: 4.051636005151167
Validation loss: 3.1218396077914257

Epoch: 6| Step: 9
Training loss: 3.0042687880627015
Validation loss: 3.1206321290225567

Epoch: 6| Step: 10
Training loss: 2.5045725014904576
Validation loss: 3.1201386193144662

Epoch: 6| Step: 11
Training loss: 2.9363519576012496
Validation loss: 3.11860947228743

Epoch: 6| Step: 12
Training loss: 4.068375080607587
Validation loss: 3.1198630658178295

Epoch: 6| Step: 13
Training loss: 3.6642627783333444
Validation loss: 3.118264054064255

Epoch: 89| Step: 0
Training loss: 4.0057736689393195
Validation loss: 3.118876100572324

Epoch: 6| Step: 1
Training loss: 3.1303673998403765
Validation loss: 3.1197905321249433

Epoch: 6| Step: 2
Training loss: 3.6422353956558275
Validation loss: 3.119050843619423

Epoch: 6| Step: 3
Training loss: 3.680698393603156
Validation loss: 3.1194398395282255

Epoch: 6| Step: 4
Training loss: 4.115946226104229
Validation loss: 3.1179245620117153

Epoch: 6| Step: 5
Training loss: 3.350366196616158
Validation loss: 3.12002000136284

Epoch: 6| Step: 6
Training loss: 2.6498951009465466
Validation loss: 3.119957418724405

Epoch: 6| Step: 7
Training loss: 3.3239949708021475
Validation loss: 3.120107296475711

Epoch: 6| Step: 8
Training loss: 2.9511912639998417
Validation loss: 3.1200295294849045

Epoch: 6| Step: 9
Training loss: 3.5408696493284184
Validation loss: 3.123442355572115

Epoch: 6| Step: 10
Training loss: 2.156602360780307
Validation loss: 3.1236005048910194

Epoch: 6| Step: 11
Training loss: 3.0331581638047287
Validation loss: 3.1275076503618613

Epoch: 6| Step: 12
Training loss: 3.6414670829872255
Validation loss: 3.1255237443987642

Epoch: 6| Step: 13
Training loss: 3.6856475314984243
Validation loss: 3.1271524034998572

Epoch: 90| Step: 0
Training loss: 3.6543385000218165
Validation loss: 3.1224180782140514

Epoch: 6| Step: 1
Training loss: 3.1702030078373338
Validation loss: 3.122452166927305

Epoch: 6| Step: 2
Training loss: 3.1306647265794885
Validation loss: 3.1184266603259787

Epoch: 6| Step: 3
Training loss: 3.2076523954085965
Validation loss: 3.1152873255877607

Epoch: 6| Step: 4
Training loss: 3.5736690577987167
Validation loss: 3.1157528395705683

Epoch: 6| Step: 5
Training loss: 3.386936836304698
Validation loss: 3.1171335347304407

Epoch: 6| Step: 6
Training loss: 3.1623625533199284
Validation loss: 3.116759219486294

Epoch: 6| Step: 7
Training loss: 3.8765277927110406
Validation loss: 3.114485559106206

Epoch: 6| Step: 8
Training loss: 3.136054817898089
Validation loss: 3.1174781941956486

Epoch: 6| Step: 9
Training loss: 3.201422113083899
Validation loss: 3.113916910548116

Epoch: 6| Step: 10
Training loss: 3.6422488802692703
Validation loss: 3.116957006332537

Epoch: 6| Step: 11
Training loss: 3.3027924138343656
Validation loss: 3.1129335456904745

Epoch: 6| Step: 12
Training loss: 2.995156351635044
Validation loss: 3.1133086231026907

Epoch: 6| Step: 13
Training loss: 3.9472320419309885
Validation loss: 3.1112283439444335

Epoch: 91| Step: 0
Training loss: 3.26225172245478
Validation loss: 3.1121494585234943

Epoch: 6| Step: 1
Training loss: 3.3299303486272778
Validation loss: 3.1128616938603777

Epoch: 6| Step: 2
Training loss: 3.7095979541597695
Validation loss: 3.1118096816439933

Epoch: 6| Step: 3
Training loss: 3.6195790765847886
Validation loss: 3.112409715512207

Epoch: 6| Step: 4
Training loss: 3.860060163829547
Validation loss: 3.1111880090642234

Epoch: 6| Step: 5
Training loss: 3.9882046115846097
Validation loss: 3.1091577506882384

Epoch: 6| Step: 6
Training loss: 2.708506788910401
Validation loss: 3.1220562217947383

Epoch: 6| Step: 7
Training loss: 2.4755748620622566
Validation loss: 3.1152180380181815

Epoch: 6| Step: 8
Training loss: 3.3895198585523874
Validation loss: 3.113008281495636

Epoch: 6| Step: 9
Training loss: 3.687612240909643
Validation loss: 3.1162462269294493

Epoch: 6| Step: 10
Training loss: 3.532052818119422
Validation loss: 3.118563920738373

Epoch: 6| Step: 11
Training loss: 3.4843533776129836
Validation loss: 3.117304054622696

Epoch: 6| Step: 12
Training loss: 2.951984003442361
Validation loss: 3.112137594818586

Epoch: 6| Step: 13
Training loss: 2.4030344892702464
Validation loss: 3.11316404902912

Epoch: 92| Step: 0
Training loss: 3.34645641284498
Validation loss: 3.1147206292281306

Epoch: 6| Step: 1
Training loss: 3.6274779170683256
Validation loss: 3.1144150963463004

Epoch: 6| Step: 2
Training loss: 3.6329203928030593
Validation loss: 3.1133698391019693

Epoch: 6| Step: 3
Training loss: 3.913227410992313
Validation loss: 3.1098274260048218

Epoch: 6| Step: 4
Training loss: 2.9434489620676905
Validation loss: 3.1090129415387153

Epoch: 6| Step: 5
Training loss: 3.3082005651114788
Validation loss: 3.1091702021181185

Epoch: 6| Step: 6
Training loss: 2.9107981543531567
Validation loss: 3.1097712728817726

Epoch: 6| Step: 7
Training loss: 3.231449296660055
Validation loss: 3.1076947880880232

Epoch: 6| Step: 8
Training loss: 3.8079789668071315
Validation loss: 3.1099311973020773

Epoch: 6| Step: 9
Training loss: 2.166450147325049
Validation loss: 3.109520096510283

Epoch: 6| Step: 10
Training loss: 4.076316461708548
Validation loss: 3.1096633131891616

Epoch: 6| Step: 11
Training loss: 3.0875703378920236
Validation loss: 3.10728883668938

Epoch: 6| Step: 12
Training loss: 3.4334151532938986
Validation loss: 3.108012009862511

Epoch: 6| Step: 13
Training loss: 3.200431472776519
Validation loss: 3.1094193587568633

Epoch: 93| Step: 0
Training loss: 3.1036434543372393
Validation loss: 3.1062643860326418

Epoch: 6| Step: 1
Training loss: 3.285111834104471
Validation loss: 3.1093582018475105

Epoch: 6| Step: 2
Training loss: 3.902170965972745
Validation loss: 3.105723743233434

Epoch: 6| Step: 3
Training loss: 2.8245827425794654
Validation loss: 3.104415898139757

Epoch: 6| Step: 4
Training loss: 3.7759730821716877
Validation loss: 3.1092834162353196

Epoch: 6| Step: 5
Training loss: 3.2574238716885144
Validation loss: 3.110453534387717

Epoch: 6| Step: 6
Training loss: 2.779760669176246
Validation loss: 3.10407914404914

Epoch: 6| Step: 7
Training loss: 3.187143642476492
Validation loss: 3.106518251866723

Epoch: 6| Step: 8
Training loss: 3.1661490636400043
Validation loss: 3.102800636203509

Epoch: 6| Step: 9
Training loss: 3.2058892952503646
Validation loss: 3.105045257583848

Epoch: 6| Step: 10
Training loss: 3.902476693180923
Validation loss: 3.105396924407503

Epoch: 6| Step: 11
Training loss: 3.8420416284199366
Validation loss: 3.1027425398137067

Epoch: 6| Step: 12
Training loss: 3.3647021261843104
Validation loss: 3.1078756032377455

Epoch: 6| Step: 13
Training loss: 3.277769440749893
Validation loss: 3.102572836668472

Epoch: 94| Step: 0
Training loss: 3.63833035040078
Validation loss: 3.101756296808519

Epoch: 6| Step: 1
Training loss: 3.955974290831739
Validation loss: 3.103498884346006

Epoch: 6| Step: 2
Training loss: 3.235343161634505
Validation loss: 3.1022274632897937

Epoch: 6| Step: 3
Training loss: 3.267595052817778
Validation loss: 3.103288775098887

Epoch: 6| Step: 4
Training loss: 3.3951950565535847
Validation loss: 3.103683424705409

Epoch: 6| Step: 5
Training loss: 3.798154764389915
Validation loss: 3.1073905337019214

Epoch: 6| Step: 6
Training loss: 3.8709661345324715
Validation loss: 3.105654259634016

Epoch: 6| Step: 7
Training loss: 3.3236274238126233
Validation loss: 3.104433619028062

Epoch: 6| Step: 8
Training loss: 2.479006551065287
Validation loss: 3.1038999066414075

Epoch: 6| Step: 9
Training loss: 3.6727216028672753
Validation loss: 3.102661295252319

Epoch: 6| Step: 10
Training loss: 3.0669664782323713
Validation loss: 3.102562187359349

Epoch: 6| Step: 11
Training loss: 3.214273246862059
Validation loss: 3.102843568698607

Epoch: 6| Step: 12
Training loss: 2.4620553520481767
Validation loss: 3.1031908851354637

Epoch: 6| Step: 13
Training loss: 3.453270266139889
Validation loss: 3.102678075128783

Epoch: 95| Step: 0
Training loss: 2.51959389305604
Validation loss: 3.103007946362184

Epoch: 6| Step: 1
Training loss: 3.8254504767540327
Validation loss: 3.103213433459393

Epoch: 6| Step: 2
Training loss: 3.2530023938324706
Validation loss: 3.1035913590991955

Epoch: 6| Step: 3
Training loss: 3.836076225056452
Validation loss: 3.1044122191785055

Epoch: 6| Step: 4
Training loss: 2.7946124595336492
Validation loss: 3.1071506689543837

Epoch: 6| Step: 5
Training loss: 3.3183743194189677
Validation loss: 3.1047895497144666

Epoch: 6| Step: 6
Training loss: 3.8654090568158077
Validation loss: 3.106280824575122

Epoch: 6| Step: 7
Training loss: 3.0286082918437645
Validation loss: 3.105072743747679

Epoch: 6| Step: 8
Training loss: 4.091968410783925
Validation loss: 3.1051508044142317

Epoch: 6| Step: 9
Training loss: 2.8744240888869266
Validation loss: 3.105281878644523

Epoch: 6| Step: 10
Training loss: 3.346729127926682
Validation loss: 3.1106218977244855

Epoch: 6| Step: 11
Training loss: 3.8977960276662778
Validation loss: 3.112522549874312

Epoch: 6| Step: 12
Training loss: 2.659958886710789
Validation loss: 3.1094254549240543

Epoch: 6| Step: 13
Training loss: 3.2218179248153707
Validation loss: 3.1057280430346816

Epoch: 96| Step: 0
Training loss: 3.165869378225026
Validation loss: 3.1065642177086685

Epoch: 6| Step: 1
Training loss: 2.488485139311509
Validation loss: 3.101741290609606

Epoch: 6| Step: 2
Training loss: 3.162713109250629
Validation loss: 3.1007121108426934

Epoch: 6| Step: 3
Training loss: 3.677569190644486
Validation loss: 3.099741291434389

Epoch: 6| Step: 4
Training loss: 3.3738368820530815
Validation loss: 3.1003497245663074

Epoch: 6| Step: 5
Training loss: 4.428146174884313
Validation loss: 3.0994596193596333

Epoch: 6| Step: 6
Training loss: 3.15325816150233
Validation loss: 3.097680032010838

Epoch: 6| Step: 7
Training loss: 3.850443276982568
Validation loss: 3.097315538745777

Epoch: 6| Step: 8
Training loss: 3.073175468969146
Validation loss: 3.098643399197914

Epoch: 6| Step: 9
Training loss: 3.470271696068083
Validation loss: 3.098037349309516

Epoch: 6| Step: 10
Training loss: 3.101385385371149
Validation loss: 3.0964566146925154

Epoch: 6| Step: 11
Training loss: 3.25379077207305
Validation loss: 3.096850437098229

Epoch: 6| Step: 12
Training loss: 3.395420041511916
Validation loss: 3.097423905641314

Epoch: 6| Step: 13
Training loss: 2.8848031467071484
Validation loss: 3.0958201506248484

Epoch: 97| Step: 0
Training loss: 2.8246845373051
Validation loss: 3.097302525656785

Epoch: 6| Step: 1
Training loss: 3.421447309129274
Validation loss: 3.0963186582506736

Epoch: 6| Step: 2
Training loss: 4.639312044641812
Validation loss: 3.0958892529259443

Epoch: 6| Step: 3
Training loss: 3.631632295270511
Validation loss: 3.0955911897873487

Epoch: 6| Step: 4
Training loss: 3.3126554632593046
Validation loss: 3.0945530256622096

Epoch: 6| Step: 5
Training loss: 2.954342222893398
Validation loss: 3.095412874639807

Epoch: 6| Step: 6
Training loss: 4.011837371587903
Validation loss: 3.0948198494090278

Epoch: 6| Step: 7
Training loss: 2.223198098907811
Validation loss: 3.094450762601067

Epoch: 6| Step: 8
Training loss: 2.707987914921941
Validation loss: 3.0941672766209116

Epoch: 6| Step: 9
Training loss: 2.9127947220240853
Validation loss: 3.0931714742270735

Epoch: 6| Step: 10
Training loss: 3.2582062041969326
Validation loss: 3.093459921908602

Epoch: 6| Step: 11
Training loss: 3.3540132538835565
Validation loss: 3.0947392981421435

Epoch: 6| Step: 12
Training loss: 3.746370593711632
Validation loss: 3.0940677665661656

Epoch: 6| Step: 13
Training loss: 3.324413540396748
Validation loss: 3.093538141356078

Epoch: 98| Step: 0
Training loss: 3.561021196721662
Validation loss: 3.0954133690789654

Epoch: 6| Step: 1
Training loss: 3.190244054516891
Validation loss: 3.0945037606375263

Epoch: 6| Step: 2
Training loss: 3.4016589100693357
Validation loss: 3.092674417263165

Epoch: 6| Step: 3
Training loss: 3.807370847338756
Validation loss: 3.0943125187188705

Epoch: 6| Step: 4
Training loss: 3.3762591803438973
Validation loss: 3.0924043211613874

Epoch: 6| Step: 5
Training loss: 2.6363011460387034
Validation loss: 3.09575356922125

Epoch: 6| Step: 6
Training loss: 3.6549153296478063
Validation loss: 3.094879421537454

Epoch: 6| Step: 7
Training loss: 3.276775106173072
Validation loss: 3.0949282249975765

Epoch: 6| Step: 8
Training loss: 3.187260039029838
Validation loss: 3.1009985517300893

Epoch: 6| Step: 9
Training loss: 2.4875071233139407
Validation loss: 3.0958998258195676

Epoch: 6| Step: 10
Training loss: 3.4585672016042563
Validation loss: 3.093072887779961

Epoch: 6| Step: 11
Training loss: 2.6141620514423303
Validation loss: 3.0951976916937207

Epoch: 6| Step: 12
Training loss: 3.589704010643942
Validation loss: 3.093884611510661

Epoch: 6| Step: 13
Training loss: 4.845230368539637
Validation loss: 3.091930404114913

Epoch: 99| Step: 0
Training loss: 2.7634472219867083
Validation loss: 3.0926808498286276

Epoch: 6| Step: 1
Training loss: 3.4884768577487137
Validation loss: 3.0917460096711498

Epoch: 6| Step: 2
Training loss: 3.525198147662858
Validation loss: 3.091365567788262

Epoch: 6| Step: 3
Training loss: 3.351788137527799
Validation loss: 3.0902446594958546

Epoch: 6| Step: 4
Training loss: 2.836720592316429
Validation loss: 3.0887118679323633

Epoch: 6| Step: 5
Training loss: 4.09554222420298
Validation loss: 3.0884127833904484

Epoch: 6| Step: 6
Training loss: 3.7063197266065053
Validation loss: 3.093552410022132

Epoch: 6| Step: 7
Training loss: 3.0651843704105914
Validation loss: 3.0900589083812093

Epoch: 6| Step: 8
Training loss: 3.365275324629336
Validation loss: 3.090462310917647

Epoch: 6| Step: 9
Training loss: 3.8926305542442554
Validation loss: 3.0894519528518054

Epoch: 6| Step: 10
Training loss: 3.151760572073062
Validation loss: 3.088188184499081

Epoch: 6| Step: 11
Training loss: 3.1882311412534996
Validation loss: 3.0870944671454223

Epoch: 6| Step: 12
Training loss: 3.233148019599193
Validation loss: 3.0881169888758047

Epoch: 6| Step: 13
Training loss: 2.689238584739073
Validation loss: 3.0872736306114263

Epoch: 100| Step: 0
Training loss: 3.3431709715142284
Validation loss: 3.0874389252474335

Epoch: 6| Step: 1
Training loss: 3.216049098157211
Validation loss: 3.087121047691328

Epoch: 6| Step: 2
Training loss: 3.874404123082666
Validation loss: 3.085897155223843

Epoch: 6| Step: 3
Training loss: 3.553163843269705
Validation loss: 3.0875337309661877

Epoch: 6| Step: 4
Training loss: 3.520636483432239
Validation loss: 3.087028187514179

Epoch: 6| Step: 5
Training loss: 3.6245615463809435
Validation loss: 3.0871631303195644

Epoch: 6| Step: 6
Training loss: 2.7682130417783295
Validation loss: 3.087132642975871

Epoch: 6| Step: 7
Training loss: 3.3085182298420643
Validation loss: 3.085745294332187

Epoch: 6| Step: 8
Training loss: 2.6395367970287236
Validation loss: 3.084214892379759

Epoch: 6| Step: 9
Training loss: 3.637925616661011
Validation loss: 3.0846904909587636

Epoch: 6| Step: 10
Training loss: 3.493683428462778
Validation loss: 3.0866357555696307

Epoch: 6| Step: 11
Training loss: 3.1123969187385065
Validation loss: 3.084295462501161

Epoch: 6| Step: 12
Training loss: 2.9450978167987385
Validation loss: 3.085539533759939

Epoch: 6| Step: 13
Training loss: 3.83343685397364
Validation loss: 3.0864931706246153

Testing loss: 3.27633567222602
