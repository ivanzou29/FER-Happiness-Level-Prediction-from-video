Epoch: 1| Step: 0
Training loss: 2.93440580368042
Validation loss: 5.20278791202012

Epoch: 6| Step: 1
Training loss: 4.958338737487793
Validation loss: 5.1957212058446745

Epoch: 6| Step: 2
Training loss: 4.789644241333008
Validation loss: 5.189247080074844

Epoch: 6| Step: 3
Training loss: 4.715086460113525
Validation loss: 5.183726992658389

Epoch: 6| Step: 4
Training loss: 5.552191734313965
Validation loss: 5.177864925835722

Epoch: 6| Step: 5
Training loss: 4.371476173400879
Validation loss: 5.172456120931974

Epoch: 6| Step: 6
Training loss: 4.721536636352539
Validation loss: 5.167151035801057

Epoch: 6| Step: 7
Training loss: 5.08734130859375
Validation loss: 5.161233466158631

Epoch: 6| Step: 8
Training loss: 5.767354965209961
Validation loss: 5.155708794952721

Epoch: 6| Step: 9
Training loss: 5.5378570556640625
Validation loss: 5.150013472444268

Epoch: 6| Step: 10
Training loss: 4.302544593811035
Validation loss: 5.144163480368993

Epoch: 6| Step: 11
Training loss: 6.05291748046875
Validation loss: 5.138275443866688

Epoch: 6| Step: 12
Training loss: 5.738818645477295
Validation loss: 5.131617946009482

Epoch: 6| Step: 13
Training loss: 4.874212265014648
Validation loss: 5.12524898077852

Epoch: 2| Step: 0
Training loss: 5.578734874725342
Validation loss: 5.118823810290265

Epoch: 6| Step: 1
Training loss: 4.647465705871582
Validation loss: 5.111789195768295

Epoch: 6| Step: 2
Training loss: 4.496388912200928
Validation loss: 5.104096843350318

Epoch: 6| Step: 3
Training loss: 4.3952717781066895
Validation loss: 5.096418103864116

Epoch: 6| Step: 4
Training loss: 5.026458740234375
Validation loss: 5.088636034278459

Epoch: 6| Step: 5
Training loss: 4.194328308105469
Validation loss: 5.080423980630854

Epoch: 6| Step: 6
Training loss: 5.418375015258789
Validation loss: 5.070508556981241

Epoch: 6| Step: 7
Training loss: 4.309877395629883
Validation loss: 5.061225055366434

Epoch: 6| Step: 8
Training loss: 4.429727554321289
Validation loss: 5.051658312479655

Epoch: 6| Step: 9
Training loss: 5.6367998123168945
Validation loss: 5.041592167269799

Epoch: 6| Step: 10
Training loss: 3.2085771560668945
Validation loss: 5.031371178165559

Epoch: 6| Step: 11
Training loss: 6.076314449310303
Validation loss: 5.019698407060357

Epoch: 6| Step: 12
Training loss: 5.155640602111816
Validation loss: 5.007971825138215

Epoch: 6| Step: 13
Training loss: 5.895829677581787
Validation loss: 4.996591127046975

Epoch: 3| Step: 0
Training loss: 4.265330791473389
Validation loss: 4.982580943774152

Epoch: 6| Step: 1
Training loss: 4.10573673248291
Validation loss: 4.969441388242988

Epoch: 6| Step: 2
Training loss: 5.172454833984375
Validation loss: 4.955405645473029

Epoch: 6| Step: 3
Training loss: 4.8225250244140625
Validation loss: 4.941337231666811

Epoch: 6| Step: 4
Training loss: 6.122570991516113
Validation loss: 4.926092711828089

Epoch: 6| Step: 5
Training loss: 4.401124000549316
Validation loss: 4.910695214425364

Epoch: 6| Step: 6
Training loss: 4.781411647796631
Validation loss: 4.893578601139848

Epoch: 6| Step: 7
Training loss: 4.3793625831604
Validation loss: 4.87668857266826

Epoch: 6| Step: 8
Training loss: 4.438893795013428
Validation loss: 4.858016567845499

Epoch: 6| Step: 9
Training loss: 5.300785064697266
Validation loss: 4.841277609589279

Epoch: 6| Step: 10
Training loss: 4.665246963500977
Validation loss: 4.821595284246629

Epoch: 6| Step: 11
Training loss: 4.217377662658691
Validation loss: 4.801337298526559

Epoch: 6| Step: 12
Training loss: 4.5266923904418945
Validation loss: 4.782302148880497

Epoch: 6| Step: 13
Training loss: 3.918544292449951
Validation loss: 4.761883294710549

Epoch: 4| Step: 0
Training loss: 5.016099452972412
Validation loss: 4.741788013007051

Epoch: 6| Step: 1
Training loss: 4.4564032554626465
Validation loss: 4.719357593085176

Epoch: 6| Step: 2
Training loss: 5.332614421844482
Validation loss: 4.69873837501772

Epoch: 6| Step: 3
Training loss: 4.043264389038086
Validation loss: 4.678291997601909

Epoch: 6| Step: 4
Training loss: 2.7890095710754395
Validation loss: 4.655131868136826

Epoch: 6| Step: 5
Training loss: 3.677964210510254
Validation loss: 4.634073277955414

Epoch: 6| Step: 6
Training loss: 4.095067501068115
Validation loss: 4.611978987211822

Epoch: 6| Step: 7
Training loss: 5.084991455078125
Validation loss: 4.591537383294875

Epoch: 6| Step: 8
Training loss: 3.6591532230377197
Validation loss: 4.570613630356327

Epoch: 6| Step: 9
Training loss: 5.059457778930664
Validation loss: 4.549546974961475

Epoch: 6| Step: 10
Training loss: 4.717298984527588
Validation loss: 4.528065983967115

Epoch: 6| Step: 11
Training loss: 4.820785045623779
Validation loss: 4.508484876284036

Epoch: 6| Step: 12
Training loss: 4.833065032958984
Validation loss: 4.487584757548507

Epoch: 6| Step: 13
Training loss: 3.5025410652160645
Validation loss: 4.468891441181142

Epoch: 5| Step: 0
Training loss: 4.091116905212402
Validation loss: 4.450520889733427

Epoch: 6| Step: 1
Training loss: 4.352685928344727
Validation loss: 4.433522819190897

Epoch: 6| Step: 2
Training loss: 4.050625801086426
Validation loss: 4.415322754972724

Epoch: 6| Step: 3
Training loss: 4.527405738830566
Validation loss: 4.397716793962704

Epoch: 6| Step: 4
Training loss: 3.515876054763794
Validation loss: 4.381698510980093

Epoch: 6| Step: 5
Training loss: 5.594934463500977
Validation loss: 4.366696332090644

Epoch: 6| Step: 6
Training loss: 4.231832981109619
Validation loss: 4.350102747640302

Epoch: 6| Step: 7
Training loss: 3.5268077850341797
Validation loss: 4.335112607607278

Epoch: 6| Step: 8
Training loss: 4.560861587524414
Validation loss: 4.3199382699945925

Epoch: 6| Step: 9
Training loss: 3.8976192474365234
Validation loss: 4.303828121513448

Epoch: 6| Step: 10
Training loss: 3.886552333831787
Validation loss: 4.29083372956963

Epoch: 6| Step: 11
Training loss: 4.215287208557129
Validation loss: 4.276137331480621

Epoch: 6| Step: 12
Training loss: 3.2275612354278564
Validation loss: 4.262487790917837

Epoch: 6| Step: 13
Training loss: 4.507334232330322
Validation loss: 4.24597720689671

Epoch: 6| Step: 0
Training loss: 5.027947902679443
Validation loss: 4.232578539079236

Epoch: 6| Step: 1
Training loss: 3.8335626125335693
Validation loss: 4.21652332685327

Epoch: 6| Step: 2
Training loss: 4.363656997680664
Validation loss: 4.202926225559686

Epoch: 6| Step: 3
Training loss: 3.7583460807800293
Validation loss: 4.189027176108412

Epoch: 6| Step: 4
Training loss: 2.7086126804351807
Validation loss: 4.1756811552150275

Epoch: 6| Step: 5
Training loss: 3.2888174057006836
Validation loss: 4.162926961016911

Epoch: 6| Step: 6
Training loss: 4.993703842163086
Validation loss: 4.151103978515954

Epoch: 6| Step: 7
Training loss: 4.757730007171631
Validation loss: 4.138781309127808

Epoch: 6| Step: 8
Training loss: 3.4631335735321045
Validation loss: 4.127346902765254

Epoch: 6| Step: 9
Training loss: 4.805060386657715
Validation loss: 4.115454799385481

Epoch: 6| Step: 10
Training loss: 4.121295928955078
Validation loss: 4.104656398937267

Epoch: 6| Step: 11
Training loss: 3.3408255577087402
Validation loss: 4.092749080350322

Epoch: 6| Step: 12
Training loss: 4.166218280792236
Validation loss: 4.080275448419714

Epoch: 6| Step: 13
Training loss: 2.2884774208068848
Validation loss: 4.06821927203927

Epoch: 7| Step: 0
Training loss: 3.7294435501098633
Validation loss: 4.058681088109171

Epoch: 6| Step: 1
Training loss: 3.0839521884918213
Validation loss: 4.047938864718201

Epoch: 6| Step: 2
Training loss: 3.9773366451263428
Validation loss: 4.039269257617253

Epoch: 6| Step: 3
Training loss: 3.8084001541137695
Validation loss: 4.0271140580536215

Epoch: 6| Step: 4
Training loss: 4.04801082611084
Validation loss: 4.01623276997638

Epoch: 6| Step: 5
Training loss: 4.152031421661377
Validation loss: 4.004807144083003

Epoch: 6| Step: 6
Training loss: 3.5277230739593506
Validation loss: 3.9948160007435787

Epoch: 6| Step: 7
Training loss: 3.9031412601470947
Validation loss: 3.984986743619365

Epoch: 6| Step: 8
Training loss: 3.851778984069824
Validation loss: 3.9754489262898765

Epoch: 6| Step: 9
Training loss: 3.5052084922790527
Validation loss: 3.9644798771027596

Epoch: 6| Step: 10
Training loss: 3.65159273147583
Validation loss: 3.951789184283185

Epoch: 6| Step: 11
Training loss: 4.726040840148926
Validation loss: 3.942313876203311

Epoch: 6| Step: 12
Training loss: 4.006624221801758
Validation loss: 3.929996539187688

Epoch: 6| Step: 13
Training loss: 3.7012851238250732
Validation loss: 3.918383818800731

Epoch: 8| Step: 0
Training loss: 3.7800395488739014
Validation loss: 3.9061298113997265

Epoch: 6| Step: 1
Training loss: 3.3975563049316406
Validation loss: 3.893578390921316

Epoch: 6| Step: 2
Training loss: 3.168325901031494
Validation loss: 3.881817809997066

Epoch: 6| Step: 3
Training loss: 3.0028529167175293
Validation loss: 3.869798557732695

Epoch: 6| Step: 4
Training loss: 3.588317394256592
Validation loss: 3.858814277956563

Epoch: 6| Step: 5
Training loss: 3.3272552490234375
Validation loss: 3.8462121871209916

Epoch: 6| Step: 6
Training loss: 3.8699491024017334
Validation loss: 3.835480366983721

Epoch: 6| Step: 7
Training loss: 4.414756774902344
Validation loss: 3.820706070110362

Epoch: 6| Step: 8
Training loss: 3.260904550552368
Validation loss: 3.8094612859910533

Epoch: 6| Step: 9
Training loss: 3.8260819911956787
Validation loss: 3.795484309555382

Epoch: 6| Step: 10
Training loss: 4.349997520446777
Validation loss: 3.7840794004419798

Epoch: 6| Step: 11
Training loss: 3.913553237915039
Validation loss: 3.7707376787739415

Epoch: 6| Step: 12
Training loss: 4.433448314666748
Validation loss: 3.759611934743902

Epoch: 6| Step: 13
Training loss: 3.337822198867798
Validation loss: 3.749362653301608

Epoch: 9| Step: 0
Training loss: 5.291491508483887
Validation loss: 3.7417468870839765

Epoch: 6| Step: 1
Training loss: 3.0076475143432617
Validation loss: 3.7301605337409565

Epoch: 6| Step: 2
Training loss: 4.172180652618408
Validation loss: 3.720078665723083

Epoch: 6| Step: 3
Training loss: 3.1404547691345215
Validation loss: 3.7102743118040022

Epoch: 6| Step: 4
Training loss: 3.3099589347839355
Validation loss: 3.700369711845152

Epoch: 6| Step: 5
Training loss: 3.1575746536254883
Validation loss: 3.6905562262381277

Epoch: 6| Step: 6
Training loss: 4.980356216430664
Validation loss: 3.6811742628774335

Epoch: 6| Step: 7
Training loss: 3.710020065307617
Validation loss: 3.6728707590410785

Epoch: 6| Step: 8
Training loss: 3.87630033493042
Validation loss: 3.661841259207777

Epoch: 6| Step: 9
Training loss: 3.8974220752716064
Validation loss: 3.650335460580805

Epoch: 6| Step: 10
Training loss: 3.1196446418762207
Validation loss: 3.642169088445684

Epoch: 6| Step: 11
Training loss: 2.7711098194122314
Validation loss: 3.634253768510716

Epoch: 6| Step: 12
Training loss: 2.6537058353424072
Validation loss: 3.627804387000299

Epoch: 6| Step: 13
Training loss: 2.9336578845977783
Validation loss: 3.6172004515124905

Epoch: 10| Step: 0
Training loss: 4.785351276397705
Validation loss: 3.6123567499140257

Epoch: 6| Step: 1
Training loss: 3.6245553493499756
Validation loss: 3.6040850300942697

Epoch: 6| Step: 2
Training loss: 2.7534403800964355
Validation loss: 3.5954797293550227

Epoch: 6| Step: 3
Training loss: 3.206667423248291
Validation loss: 3.5890901678351947

Epoch: 6| Step: 4
Training loss: 3.404627799987793
Validation loss: 3.581871978698238

Epoch: 6| Step: 5
Training loss: 4.123167037963867
Validation loss: 3.5766023615355134

Epoch: 6| Step: 6
Training loss: 2.9022321701049805
Validation loss: 3.5696833261879544

Epoch: 6| Step: 7
Training loss: 3.6355485916137695
Validation loss: 3.5589782704589186

Epoch: 6| Step: 8
Training loss: 3.6980063915252686
Validation loss: 3.5545825394251014

Epoch: 6| Step: 9
Training loss: 2.9877681732177734
Validation loss: 3.5495062233299337

Epoch: 6| Step: 10
Training loss: 3.4800214767456055
Validation loss: 3.5396515425815376

Epoch: 6| Step: 11
Training loss: 3.511382579803467
Validation loss: 3.5333406079200005

Epoch: 6| Step: 12
Training loss: 3.0118281841278076
Validation loss: 3.5299272101412535

Epoch: 6| Step: 13
Training loss: 3.862949848175049
Validation loss: 3.5200257660240255

Epoch: 11| Step: 0
Training loss: 3.562906503677368
Validation loss: 3.512436184831845

Epoch: 6| Step: 1
Training loss: 3.9261016845703125
Validation loss: 3.506083329518636

Epoch: 6| Step: 2
Training loss: 3.6080026626586914
Validation loss: 3.499311113870272

Epoch: 6| Step: 3
Training loss: 3.6670053005218506
Validation loss: 3.494273644621654

Epoch: 6| Step: 4
Training loss: 2.6051459312438965
Validation loss: 3.484775609867547

Epoch: 6| Step: 5
Training loss: 3.9264700412750244
Validation loss: 3.48058505212107

Epoch: 6| Step: 6
Training loss: 3.191722869873047
Validation loss: 3.474848993362919

Epoch: 6| Step: 7
Training loss: 2.810697555541992
Validation loss: 3.4691585545898764

Epoch: 6| Step: 8
Training loss: 3.7559871673583984
Validation loss: 3.4663629506223943

Epoch: 6| Step: 9
Training loss: 3.599709987640381
Validation loss: 3.4591233063769597

Epoch: 6| Step: 10
Training loss: 3.06210994720459
Validation loss: 3.4499796667406635

Epoch: 6| Step: 11
Training loss: 3.2242255210876465
Validation loss: 3.4463014064296598

Epoch: 6| Step: 12
Training loss: 3.0023961067199707
Validation loss: 3.4397332873395694

Epoch: 6| Step: 13
Training loss: 4.1162333488464355
Validation loss: 3.431684993928479

Epoch: 12| Step: 0
Training loss: 3.6462414264678955
Validation loss: 3.420741783675327

Epoch: 6| Step: 1
Training loss: 4.093158721923828
Validation loss: 3.4180625843745407

Epoch: 6| Step: 2
Training loss: 3.7980830669403076
Validation loss: 3.4206834095780567

Epoch: 6| Step: 3
Training loss: 2.454529285430908
Validation loss: 3.4114468456596456

Epoch: 6| Step: 4
Training loss: 3.4606220722198486
Validation loss: 3.405073212039086

Epoch: 6| Step: 5
Training loss: 2.3557581901550293
Validation loss: 3.39439679473959

Epoch: 6| Step: 6
Training loss: 2.9719653129577637
Validation loss: 3.3870645594853226

Epoch: 6| Step: 7
Training loss: 2.5906941890716553
Validation loss: 3.3843895414824128

Epoch: 6| Step: 8
Training loss: 4.093840599060059
Validation loss: 3.37902432616039

Epoch: 6| Step: 9
Training loss: 3.72369384765625
Validation loss: 3.3741166463462253

Epoch: 6| Step: 10
Training loss: 3.193385601043701
Validation loss: 3.36636322288103

Epoch: 6| Step: 11
Training loss: 3.119630813598633
Validation loss: 3.3585500281344176

Epoch: 6| Step: 12
Training loss: 4.264793395996094
Validation loss: 3.351881040039883

Epoch: 6| Step: 13
Training loss: 2.757613182067871
Validation loss: 3.3521761304588726

Epoch: 13| Step: 0
Training loss: 2.6649367809295654
Validation loss: 3.3463015376880603

Epoch: 6| Step: 1
Training loss: 3.9340462684631348
Validation loss: 3.3411697495368218

Epoch: 6| Step: 2
Training loss: 3.4264721870422363
Validation loss: 3.3317858378092446

Epoch: 6| Step: 3
Training loss: 3.056361436843872
Validation loss: 3.32531673677506

Epoch: 6| Step: 4
Training loss: 2.8536853790283203
Validation loss: 3.3219658610641316

Epoch: 6| Step: 5
Training loss: 3.3097543716430664
Validation loss: 3.316859209409324

Epoch: 6| Step: 6
Training loss: 3.9594712257385254
Validation loss: 3.3094006225626957

Epoch: 6| Step: 7
Training loss: 3.7870168685913086
Validation loss: 3.3053964055994505

Epoch: 6| Step: 8
Training loss: 2.971803665161133
Validation loss: 3.301876316788376

Epoch: 6| Step: 9
Training loss: 2.1884002685546875
Validation loss: 3.2983302172794136

Epoch: 6| Step: 10
Training loss: 4.116981029510498
Validation loss: 3.302328622469338

Epoch: 6| Step: 11
Training loss: 2.9405617713928223
Validation loss: 3.292888943867017

Epoch: 6| Step: 12
Training loss: 3.654214382171631
Validation loss: 3.2840759677271687

Epoch: 6| Step: 13
Training loss: 2.9304709434509277
Validation loss: 3.278844807737617

Epoch: 14| Step: 0
Training loss: 3.8765363693237305
Validation loss: 3.275676535021874

Epoch: 6| Step: 1
Training loss: 2.7435901165008545
Validation loss: 3.2711348841267247

Epoch: 6| Step: 2
Training loss: 3.2869479656219482
Validation loss: 3.269628478634742

Epoch: 6| Step: 3
Training loss: 4.470099449157715
Validation loss: 3.2616701972100044

Epoch: 6| Step: 4
Training loss: 3.966562032699585
Validation loss: 3.2554897057112826

Epoch: 6| Step: 5
Training loss: 2.78232479095459
Validation loss: 3.2525312669815554

Epoch: 6| Step: 6
Training loss: 3.960500717163086
Validation loss: 3.2374457031167965

Epoch: 6| Step: 7
Training loss: 2.4149680137634277
Validation loss: 3.2052693777186896

Epoch: 6| Step: 8
Training loss: 2.6484851837158203
Validation loss: 3.210673455269106

Epoch: 6| Step: 9
Training loss: 3.3295655250549316
Validation loss: 3.189490300352855

Epoch: 6| Step: 10
Training loss: 2.4141249656677246
Validation loss: 3.1848351699049755

Epoch: 6| Step: 11
Training loss: 2.6497161388397217
Validation loss: 3.19427990400663

Epoch: 6| Step: 12
Training loss: 3.5364880561828613
Validation loss: 3.2085609589853594

Epoch: 6| Step: 13
Training loss: 2.9987881183624268
Validation loss: 3.2171626655004357

Epoch: 15| Step: 0
Training loss: 3.0501928329467773
Validation loss: 3.248913972608505

Epoch: 6| Step: 1
Training loss: 3.0138731002807617
Validation loss: 3.226613844594648

Epoch: 6| Step: 2
Training loss: 3.9009816646575928
Validation loss: 3.211808466142224

Epoch: 6| Step: 3
Training loss: 4.319385051727295
Validation loss: 3.20246789532323

Epoch: 6| Step: 4
Training loss: 2.5262739658355713
Validation loss: 3.1902488739259782

Epoch: 6| Step: 5
Training loss: 3.4034862518310547
Validation loss: 3.1859449160996305

Epoch: 6| Step: 6
Training loss: 3.411442756652832
Validation loss: 3.1742534739996797

Epoch: 6| Step: 7
Training loss: 3.5590553283691406
Validation loss: 3.17138998739181

Epoch: 6| Step: 8
Training loss: 2.9839837551116943
Validation loss: 3.164760369126515

Epoch: 6| Step: 9
Training loss: 3.416703224182129
Validation loss: 3.159048234262774

Epoch: 6| Step: 10
Training loss: 2.6340150833129883
Validation loss: 3.1502247471963205

Epoch: 6| Step: 11
Training loss: 2.6173393726348877
Validation loss: 3.1412720885328067

Epoch: 6| Step: 12
Training loss: 2.5038089752197266
Validation loss: 3.1347592364075365

Epoch: 6| Step: 13
Training loss: 3.1991052627563477
Validation loss: 3.129674288534349

Epoch: 16| Step: 0
Training loss: 2.759965181350708
Validation loss: 3.1228640182043916

Epoch: 6| Step: 1
Training loss: 2.7670154571533203
Validation loss: 3.1222523053487143

Epoch: 6| Step: 2
Training loss: 2.7009458541870117
Validation loss: 3.1149444605714534

Epoch: 6| Step: 3
Training loss: 3.4318456649780273
Validation loss: 3.1160032056993052

Epoch: 6| Step: 4
Training loss: 2.903108596801758
Validation loss: 3.1136999771159184

Epoch: 6| Step: 5
Training loss: 4.40707540512085
Validation loss: 3.106299995094217

Epoch: 6| Step: 6
Training loss: 2.5945494174957275
Validation loss: 3.1021014798072075

Epoch: 6| Step: 7
Training loss: 3.0454134941101074
Validation loss: 3.09931246952344

Epoch: 6| Step: 8
Training loss: 3.267904758453369
Validation loss: 3.09561510239878

Epoch: 6| Step: 9
Training loss: 3.691127061843872
Validation loss: 3.0930309500745548

Epoch: 6| Step: 10
Training loss: 2.639030933380127
Validation loss: 3.0909309438479844

Epoch: 6| Step: 11
Training loss: 2.7532005310058594
Validation loss: 3.0877699236715994

Epoch: 6| Step: 12
Training loss: 3.9337046146392822
Validation loss: 3.080772466557

Epoch: 6| Step: 13
Training loss: 2.525251626968384
Validation loss: 3.0764363119679112

Epoch: 17| Step: 0
Training loss: 3.4181623458862305
Validation loss: 3.074809346147763

Epoch: 6| Step: 1
Training loss: 3.8040623664855957
Validation loss: 3.068548725497338

Epoch: 6| Step: 2
Training loss: 1.8769762516021729
Validation loss: 3.0607189157957673

Epoch: 6| Step: 3
Training loss: 3.2836644649505615
Validation loss: 3.0588636552133868

Epoch: 6| Step: 4
Training loss: 3.4550013542175293
Validation loss: 3.061147718019383

Epoch: 6| Step: 5
Training loss: 3.530538558959961
Validation loss: 3.054930486986714

Epoch: 6| Step: 6
Training loss: 3.0531277656555176
Validation loss: 3.054130228616858

Epoch: 6| Step: 7
Training loss: 2.480658531188965
Validation loss: 3.0544524218446467

Epoch: 6| Step: 8
Training loss: 2.4442849159240723
Validation loss: 3.048301814704813

Epoch: 6| Step: 9
Training loss: 3.234245538711548
Validation loss: 3.0475253315382105

Epoch: 6| Step: 10
Training loss: 2.939542055130005
Validation loss: 3.0446195576780584

Epoch: 6| Step: 11
Training loss: 3.2562384605407715
Validation loss: 3.032908078162901

Epoch: 6| Step: 12
Training loss: 3.211005687713623
Validation loss: 3.0324132442474365

Epoch: 6| Step: 13
Training loss: 3.467532157897949
Validation loss: 3.0277243070704962

Epoch: 18| Step: 0
Training loss: 3.2475357055664062
Validation loss: 3.023008966958651

Epoch: 6| Step: 1
Training loss: 2.138533115386963
Validation loss: 3.019701193737727

Epoch: 6| Step: 2
Training loss: 2.8294997215270996
Validation loss: 3.0189718020859586

Epoch: 6| Step: 3
Training loss: 2.3964083194732666
Validation loss: 3.0137015158130276

Epoch: 6| Step: 4
Training loss: 2.669495105743408
Validation loss: 3.013779294106268

Epoch: 6| Step: 5
Training loss: 3.7692267894744873
Validation loss: 3.008667148569579

Epoch: 6| Step: 6
Training loss: 3.181119441986084
Validation loss: 3.007194813861642

Epoch: 6| Step: 7
Training loss: 2.624349594116211
Validation loss: 3.008817688111336

Epoch: 6| Step: 8
Training loss: 3.0466439723968506
Validation loss: 2.9980953893353863

Epoch: 6| Step: 9
Training loss: 3.8898167610168457
Validation loss: 2.997890385248328

Epoch: 6| Step: 10
Training loss: 3.350313663482666
Validation loss: 2.991435358601232

Epoch: 6| Step: 11
Training loss: 3.3746862411499023
Validation loss: 2.9881900638662358

Epoch: 6| Step: 12
Training loss: 3.0066490173339844
Validation loss: 2.985251775351904

Epoch: 6| Step: 13
Training loss: 3.52411150932312
Validation loss: 2.983541319447179

Epoch: 19| Step: 0
Training loss: 3.011168956756592
Validation loss: 2.9787597169158277

Epoch: 6| Step: 1
Training loss: 3.511518716812134
Validation loss: 2.9759414119105183

Epoch: 6| Step: 2
Training loss: 2.925887107849121
Validation loss: 2.9726600646972656

Epoch: 6| Step: 3
Training loss: 3.205942153930664
Validation loss: 2.9724457084491687

Epoch: 6| Step: 4
Training loss: 3.292381525039673
Validation loss: 2.9728914332646195

Epoch: 6| Step: 5
Training loss: 2.5421717166900635
Validation loss: 2.9644801283395417

Epoch: 6| Step: 6
Training loss: 3.249645709991455
Validation loss: 2.9662970753126245

Epoch: 6| Step: 7
Training loss: 4.2111287117004395
Validation loss: 2.96090805146002

Epoch: 6| Step: 8
Training loss: 2.016697406768799
Validation loss: 2.953849838626

Epoch: 6| Step: 9
Training loss: 3.4769301414489746
Validation loss: 2.9535298911474084

Epoch: 6| Step: 10
Training loss: 3.5263867378234863
Validation loss: 2.947670582802065

Epoch: 6| Step: 11
Training loss: 2.8568997383117676
Validation loss: 2.943674441306822

Epoch: 6| Step: 12
Training loss: 2.0454232692718506
Validation loss: 2.944075048610728

Epoch: 6| Step: 13
Training loss: 2.244426727294922
Validation loss: 2.944118566410516

Epoch: 20| Step: 0
Training loss: 3.1653084754943848
Validation loss: 2.945384512665451

Epoch: 6| Step: 1
Training loss: 3.1642255783081055
Validation loss: 2.9563528145513227

Epoch: 6| Step: 2
Training loss: 3.4383788108825684
Validation loss: 2.942563964474586

Epoch: 6| Step: 3
Training loss: 3.423116683959961
Validation loss: 2.9444454921189176

Epoch: 6| Step: 4
Training loss: 3.3667216300964355
Validation loss: 2.933856625710764

Epoch: 6| Step: 5
Training loss: 2.7699971199035645
Validation loss: 2.929777253058649

Epoch: 6| Step: 6
Training loss: 2.208066701889038
Validation loss: 2.9434433367944535

Epoch: 6| Step: 7
Training loss: 2.761850357055664
Validation loss: 2.937457151310418

Epoch: 6| Step: 8
Training loss: 3.4724369049072266
Validation loss: 2.9342947954772622

Epoch: 6| Step: 9
Training loss: 2.763636589050293
Validation loss: 2.9353980761702343

Epoch: 6| Step: 10
Training loss: 3.040560245513916
Validation loss: 2.9306006123942714

Epoch: 6| Step: 11
Training loss: 2.8624181747436523
Validation loss: 2.9275646363535235

Epoch: 6| Step: 12
Training loss: 3.3048899173736572
Validation loss: 2.9197740170263473

Epoch: 6| Step: 13
Training loss: 2.0819790363311768
Validation loss: 2.917342121883105

Epoch: 21| Step: 0
Training loss: 2.6256017684936523
Validation loss: 2.910281055717058

Epoch: 6| Step: 1
Training loss: 3.4434351921081543
Validation loss: 2.9087010942479616

Epoch: 6| Step: 2
Training loss: 3.3046064376831055
Validation loss: 2.9074732718929166

Epoch: 6| Step: 3
Training loss: 2.781388282775879
Validation loss: 2.907795439484299

Epoch: 6| Step: 4
Training loss: 3.368760108947754
Validation loss: 2.898640363447128

Epoch: 6| Step: 5
Training loss: 2.4941208362579346
Validation loss: 2.8961944990260626

Epoch: 6| Step: 6
Training loss: 3.130876302719116
Validation loss: 2.893424416101107

Epoch: 6| Step: 7
Training loss: 3.738983631134033
Validation loss: 2.8864110618509273

Epoch: 6| Step: 8
Training loss: 2.853404998779297
Validation loss: 2.886221524207823

Epoch: 6| Step: 9
Training loss: 2.872058391571045
Validation loss: 2.8812631330182477

Epoch: 6| Step: 10
Training loss: 2.739182710647583
Validation loss: 2.8771976681165796

Epoch: 6| Step: 11
Training loss: 2.7536983489990234
Validation loss: 2.877246443943311

Epoch: 6| Step: 12
Training loss: 3.2110366821289062
Validation loss: 2.875954827954692

Epoch: 6| Step: 13
Training loss: 2.1540801525115967
Validation loss: 2.874952167593023

Epoch: 22| Step: 0
Training loss: 2.7366719245910645
Validation loss: 2.88765129991757

Epoch: 6| Step: 1
Training loss: 3.208566665649414
Validation loss: 2.9243239587353123

Epoch: 6| Step: 2
Training loss: 3.1993565559387207
Validation loss: 2.929216718160978

Epoch: 6| Step: 3
Training loss: 3.2408950328826904
Validation loss: 2.915129674378262

Epoch: 6| Step: 4
Training loss: 3.532515525817871
Validation loss: 2.9044861434608378

Epoch: 6| Step: 5
Training loss: 2.9566397666931152
Validation loss: 2.8619028983577603

Epoch: 6| Step: 6
Training loss: 3.1421499252319336
Validation loss: 2.872255976482104

Epoch: 6| Step: 7
Training loss: 2.2822041511535645
Validation loss: 2.8694397403347875

Epoch: 6| Step: 8
Training loss: 2.381957530975342
Validation loss: 2.8711284770760486

Epoch: 6| Step: 9
Training loss: 2.293412208557129
Validation loss: 2.8721291711253505

Epoch: 6| Step: 10
Training loss: 3.1511073112487793
Validation loss: 2.8753517391861125

Epoch: 6| Step: 11
Training loss: 3.3191709518432617
Validation loss: 2.8703839983991397

Epoch: 6| Step: 12
Training loss: 3.0494818687438965
Validation loss: 2.8616103946521716

Epoch: 6| Step: 13
Training loss: 3.617588520050049
Validation loss: 2.855964101770873

Epoch: 23| Step: 0
Training loss: 2.713491439819336
Validation loss: 2.8554560087060414

Epoch: 6| Step: 1
Training loss: 2.585193157196045
Validation loss: 2.851800733996976

Epoch: 6| Step: 2
Training loss: 3.0728578567504883
Validation loss: 2.8499877657941592

Epoch: 6| Step: 3
Training loss: 2.71785831451416
Validation loss: 2.8554891232521302

Epoch: 6| Step: 4
Training loss: 2.94889235496521
Validation loss: 2.852478260635048

Epoch: 6| Step: 5
Training loss: 3.787118673324585
Validation loss: 2.850107328866118

Epoch: 6| Step: 6
Training loss: 2.03029465675354
Validation loss: 2.8453098932902017

Epoch: 6| Step: 7
Training loss: 2.749927043914795
Validation loss: 2.8382946137459046

Epoch: 6| Step: 8
Training loss: 2.611462354660034
Validation loss: 2.8351292635804866

Epoch: 6| Step: 9
Training loss: 3.6111323833465576
Validation loss: 2.8368723520668606

Epoch: 6| Step: 10
Training loss: 3.2684507369995117
Validation loss: 2.8348862278846

Epoch: 6| Step: 11
Training loss: 3.595594644546509
Validation loss: 2.8354949233352498

Epoch: 6| Step: 12
Training loss: 2.0507400035858154
Validation loss: 2.8291756286416003

Epoch: 6| Step: 13
Training loss: 4.105816841125488
Validation loss: 2.829454811670447

Epoch: 24| Step: 0
Training loss: 3.588604211807251
Validation loss: 2.8299821089672785

Epoch: 6| Step: 1
Training loss: 3.7427725791931152
Validation loss: 2.830697913323679

Epoch: 6| Step: 2
Training loss: 2.751960277557373
Validation loss: 2.8272074499437885

Epoch: 6| Step: 3
Training loss: 3.0813138484954834
Validation loss: 2.834355172290597

Epoch: 6| Step: 4
Training loss: 2.6799840927124023
Validation loss: 2.8255825196543047

Epoch: 6| Step: 5
Training loss: 2.4867753982543945
Validation loss: 2.829512603821293

Epoch: 6| Step: 6
Training loss: 2.8864450454711914
Validation loss: 2.8252378561163463

Epoch: 6| Step: 7
Training loss: 2.898533344268799
Validation loss: 2.8185004059986403

Epoch: 6| Step: 8
Training loss: 2.7169697284698486
Validation loss: 2.8170607628360873

Epoch: 6| Step: 9
Training loss: 2.722057819366455
Validation loss: 2.811633853502171

Epoch: 6| Step: 10
Training loss: 2.699364185333252
Validation loss: 2.8130461067281742

Epoch: 6| Step: 11
Training loss: 2.80637788772583
Validation loss: 2.81383329309443

Epoch: 6| Step: 12
Training loss: 2.4938833713531494
Validation loss: 2.808170331421719

Epoch: 6| Step: 13
Training loss: 4.044212341308594
Validation loss: 2.8046242934401318

Epoch: 25| Step: 0
Training loss: 2.1022634506225586
Validation loss: 2.8023881553321757

Epoch: 6| Step: 1
Training loss: 2.897240161895752
Validation loss: 2.805079860071982

Epoch: 6| Step: 2
Training loss: 2.3287911415100098
Validation loss: 2.8028345287487073

Epoch: 6| Step: 3
Training loss: 3.107382297515869
Validation loss: 2.7996074332985827

Epoch: 6| Step: 4
Training loss: 2.9456610679626465
Validation loss: 2.797105312347412

Epoch: 6| Step: 5
Training loss: 2.612359046936035
Validation loss: 2.7962726418690016

Epoch: 6| Step: 6
Training loss: 2.799968719482422
Validation loss: 2.7963950377638622

Epoch: 6| Step: 7
Training loss: 2.996703624725342
Validation loss: 2.7909191398210424

Epoch: 6| Step: 8
Training loss: 2.329491376876831
Validation loss: 2.7898530998537616

Epoch: 6| Step: 9
Training loss: 3.279585599899292
Validation loss: 2.7970461358306227

Epoch: 6| Step: 10
Training loss: 3.325165033340454
Validation loss: 2.7880474380267564

Epoch: 6| Step: 11
Training loss: 3.980337619781494
Validation loss: 2.791810066469254

Epoch: 6| Step: 12
Training loss: 2.379406690597534
Validation loss: 2.788556037410613

Epoch: 6| Step: 13
Training loss: 4.586113452911377
Validation loss: 2.787416470948086

Epoch: 26| Step: 0
Training loss: 3.182307243347168
Validation loss: 2.784494753806822

Epoch: 6| Step: 1
Training loss: 3.1599011421203613
Validation loss: 2.783788832285071

Epoch: 6| Step: 2
Training loss: 2.381214141845703
Validation loss: 2.78860814597017

Epoch: 6| Step: 3
Training loss: 3.3625385761260986
Validation loss: 2.7836490907976703

Epoch: 6| Step: 4
Training loss: 3.2127645015716553
Validation loss: 2.7810058465567966

Epoch: 6| Step: 5
Training loss: 3.0708041191101074
Validation loss: 2.7785525911597797

Epoch: 6| Step: 6
Training loss: 2.873946189880371
Validation loss: 2.7765330294127106

Epoch: 6| Step: 7
Training loss: 2.5415873527526855
Validation loss: 2.774502702938613

Epoch: 6| Step: 8
Training loss: 3.160834312438965
Validation loss: 2.7765329730126167

Epoch: 6| Step: 9
Training loss: 2.256014108657837
Validation loss: 2.7754355733112623

Epoch: 6| Step: 10
Training loss: 2.798173666000366
Validation loss: 2.774354978274274

Epoch: 6| Step: 11
Training loss: 2.641754627227783
Validation loss: 2.773131796108779

Epoch: 6| Step: 12
Training loss: 2.7936363220214844
Validation loss: 2.770677558837398

Epoch: 6| Step: 13
Training loss: 3.792731761932373
Validation loss: 2.771596893187492

Epoch: 27| Step: 0
Training loss: 2.0179009437561035
Validation loss: 2.7695991839132

Epoch: 6| Step: 1
Training loss: 2.8262827396392822
Validation loss: 2.7680853515542965

Epoch: 6| Step: 2
Training loss: 2.8854494094848633
Validation loss: 2.771087905412079

Epoch: 6| Step: 3
Training loss: 2.766176223754883
Validation loss: 2.7720606480875323

Epoch: 6| Step: 4
Training loss: 3.24410343170166
Validation loss: 2.766245713797949

Epoch: 6| Step: 5
Training loss: 2.063365936279297
Validation loss: 2.770031018923688

Epoch: 6| Step: 6
Training loss: 3.547701835632324
Validation loss: 2.7663008474534556

Epoch: 6| Step: 7
Training loss: 3.303821086883545
Validation loss: 2.764553423850767

Epoch: 6| Step: 8
Training loss: 2.5873758792877197
Validation loss: 2.763527403595627

Epoch: 6| Step: 9
Training loss: 3.4736227989196777
Validation loss: 2.7570722949120308

Epoch: 6| Step: 10
Training loss: 2.3210296630859375
Validation loss: 2.7559551654323453

Epoch: 6| Step: 11
Training loss: 3.1144044399261475
Validation loss: 2.7557840167835193

Epoch: 6| Step: 12
Training loss: 3.421030044555664
Validation loss: 2.7562128933527137

Epoch: 6| Step: 13
Training loss: 3.269002676010132
Validation loss: 2.757759660802862

Epoch: 28| Step: 0
Training loss: 2.5544097423553467
Validation loss: 2.7568267468483216

Epoch: 6| Step: 1
Training loss: 1.2905607223510742
Validation loss: 2.7498194709900887

Epoch: 6| Step: 2
Training loss: 2.468376636505127
Validation loss: 2.7549228411848827

Epoch: 6| Step: 3
Training loss: 3.6453051567077637
Validation loss: 2.753178701605848

Epoch: 6| Step: 4
Training loss: 3.5984668731689453
Validation loss: 2.749746561050415

Epoch: 6| Step: 5
Training loss: 3.069013833999634
Validation loss: 2.7514039444667038

Epoch: 6| Step: 6
Training loss: 2.749028444290161
Validation loss: 2.749049266179403

Epoch: 6| Step: 7
Training loss: 2.5628371238708496
Validation loss: 2.7469987715444257

Epoch: 6| Step: 8
Training loss: 2.341876983642578
Validation loss: 2.7474288504610778

Epoch: 6| Step: 9
Training loss: 3.6594042778015137
Validation loss: 2.7434236234234226

Epoch: 6| Step: 10
Training loss: 2.827787160873413
Validation loss: 2.7470314938534974

Epoch: 6| Step: 11
Training loss: 2.7512097358703613
Validation loss: 2.742773840504308

Epoch: 6| Step: 12
Training loss: 3.415785789489746
Validation loss: 2.746266057414393

Epoch: 6| Step: 13
Training loss: 4.160439968109131
Validation loss: 2.7428097007095174

Epoch: 29| Step: 0
Training loss: 3.2574210166931152
Validation loss: 2.7454811603792253

Epoch: 6| Step: 1
Training loss: 2.978689193725586
Validation loss: 2.746473399541711

Epoch: 6| Step: 2
Training loss: 2.231184244155884
Validation loss: 2.7439502439191266

Epoch: 6| Step: 3
Training loss: 3.598543643951416
Validation loss: 2.740140612407397

Epoch: 6| Step: 4
Training loss: 2.533747434616089
Validation loss: 2.7416249705899145

Epoch: 6| Step: 5
Training loss: 1.9535040855407715
Validation loss: 2.7363612959461827

Epoch: 6| Step: 6
Training loss: 3.55098819732666
Validation loss: 2.735706111436249

Epoch: 6| Step: 7
Training loss: 3.674041986465454
Validation loss: 2.732433634419595

Epoch: 6| Step: 8
Training loss: 1.628286361694336
Validation loss: 2.7335980041052705

Epoch: 6| Step: 9
Training loss: 3.163135528564453
Validation loss: 2.731742041085356

Epoch: 6| Step: 10
Training loss: 3.5625853538513184
Validation loss: 2.7350650346407326

Epoch: 6| Step: 11
Training loss: 2.930211067199707
Validation loss: 2.7266729057476087

Epoch: 6| Step: 12
Training loss: 2.587419033050537
Validation loss: 2.72594460364311

Epoch: 6| Step: 13
Training loss: 2.6125593185424805
Validation loss: 2.7320167736340593

Epoch: 30| Step: 0
Training loss: 2.9050254821777344
Validation loss: 2.7242686005048853

Epoch: 6| Step: 1
Training loss: 3.500491142272949
Validation loss: 2.7246248311893915

Epoch: 6| Step: 2
Training loss: 3.471524238586426
Validation loss: 2.7297159907638386

Epoch: 6| Step: 3
Training loss: 2.655571460723877
Validation loss: 2.7245615861749135

Epoch: 6| Step: 4
Training loss: 2.2814102172851562
Validation loss: 2.722767424839799

Epoch: 6| Step: 5
Training loss: 3.220484733581543
Validation loss: 2.721480736168482

Epoch: 6| Step: 6
Training loss: 2.0647969245910645
Validation loss: 2.7225115940135014

Epoch: 6| Step: 7
Training loss: 2.4589195251464844
Validation loss: 2.7193982062801236

Epoch: 6| Step: 8
Training loss: 2.32944655418396
Validation loss: 2.7200443565204577

Epoch: 6| Step: 9
Training loss: 2.586447238922119
Validation loss: 2.722043216869395

Epoch: 6| Step: 10
Training loss: 3.76102352142334
Validation loss: 2.7189192259183494

Epoch: 6| Step: 11
Training loss: 3.318974494934082
Validation loss: 2.717930557907269

Epoch: 6| Step: 12
Training loss: 2.7296676635742188
Validation loss: 2.735199966738301

Epoch: 6| Step: 13
Training loss: 3.143418788909912
Validation loss: 2.7337619848148798

Epoch: 31| Step: 0
Training loss: 2.8273751735687256
Validation loss: 2.713544771235476

Epoch: 6| Step: 1
Training loss: 3.0311999320983887
Validation loss: 2.711060090731549

Epoch: 6| Step: 2
Training loss: 2.4253265857696533
Validation loss: 2.7157042641793527

Epoch: 6| Step: 3
Training loss: 2.938291311264038
Validation loss: 2.7181122379918254

Epoch: 6| Step: 4
Training loss: 2.5013983249664307
Validation loss: 2.724951687679496

Epoch: 6| Step: 5
Training loss: 3.1767289638519287
Validation loss: 2.721619729072817

Epoch: 6| Step: 6
Training loss: 3.275113821029663
Validation loss: 2.7241818366512174

Epoch: 6| Step: 7
Training loss: 2.978950262069702
Validation loss: 2.7191614027946227

Epoch: 6| Step: 8
Training loss: 2.7904038429260254
Validation loss: 2.708494047964773

Epoch: 6| Step: 9
Training loss: 3.490372896194458
Validation loss: 2.7067805413276917

Epoch: 6| Step: 10
Training loss: 2.6096434593200684
Validation loss: 2.7037084128267024

Epoch: 6| Step: 11
Training loss: 2.0592901706695557
Validation loss: 2.7076459084787676

Epoch: 6| Step: 12
Training loss: 3.129739284515381
Validation loss: 2.7135794367841495

Epoch: 6| Step: 13
Training loss: 3.0808231830596924
Validation loss: 2.722959215923022

Epoch: 32| Step: 0
Training loss: 2.8740973472595215
Validation loss: 2.7147603086245957

Epoch: 6| Step: 1
Training loss: 3.0499982833862305
Validation loss: 2.7085171258577736

Epoch: 6| Step: 2
Training loss: 2.8108625411987305
Validation loss: 2.701608411727413

Epoch: 6| Step: 3
Training loss: 2.923008680343628
Validation loss: 2.7032024911654893

Epoch: 6| Step: 4
Training loss: 3.5081589221954346
Validation loss: 2.701580637244768

Epoch: 6| Step: 5
Training loss: 2.5513992309570312
Validation loss: 2.700812880710889

Epoch: 6| Step: 6
Training loss: 3.2084450721740723
Validation loss: 2.702002966275779

Epoch: 6| Step: 7
Training loss: 2.8130295276641846
Validation loss: 2.699152467071369

Epoch: 6| Step: 8
Training loss: 1.6368417739868164
Validation loss: 2.7057764684000323

Epoch: 6| Step: 9
Training loss: 3.5093607902526855
Validation loss: 2.700486013966222

Epoch: 6| Step: 10
Training loss: 1.7929892539978027
Validation loss: 2.6937110142041276

Epoch: 6| Step: 11
Training loss: 2.8202931880950928
Validation loss: 2.6969794150321715

Epoch: 6| Step: 12
Training loss: 3.4199812412261963
Validation loss: 2.6945384779284076

Epoch: 6| Step: 13
Training loss: 3.4586572647094727
Validation loss: 2.700086521845992

Epoch: 33| Step: 0
Training loss: 2.977308750152588
Validation loss: 2.691609654375302

Epoch: 6| Step: 1
Training loss: 2.454554557800293
Validation loss: 2.6923952871753323

Epoch: 6| Step: 2
Training loss: 1.9990811347961426
Validation loss: 2.6946890174701648

Epoch: 6| Step: 3
Training loss: 3.6650338172912598
Validation loss: 2.6906321151282198

Epoch: 6| Step: 4
Training loss: 3.370326042175293
Validation loss: 2.687963711318149

Epoch: 6| Step: 5
Training loss: 2.918982982635498
Validation loss: 2.6906621635601087

Epoch: 6| Step: 6
Training loss: 3.230715036392212
Validation loss: 2.6874835875726517

Epoch: 6| Step: 7
Training loss: 2.420452117919922
Validation loss: 2.6886511695000435

Epoch: 6| Step: 8
Training loss: 2.7909069061279297
Validation loss: 2.686853631850212

Epoch: 6| Step: 9
Training loss: 2.9613752365112305
Validation loss: 2.69932129562542

Epoch: 6| Step: 10
Training loss: 2.3881611824035645
Validation loss: 2.7163914890699488

Epoch: 6| Step: 11
Training loss: 3.617976665496826
Validation loss: 2.7246519211799867

Epoch: 6| Step: 12
Training loss: 2.6114253997802734
Validation loss: 2.691952872019942

Epoch: 6| Step: 13
Training loss: 2.44773530960083
Validation loss: 2.6858283089053248

Epoch: 34| Step: 0
Training loss: 3.068427324295044
Validation loss: 2.6910919553490094

Epoch: 6| Step: 1
Training loss: 2.3102827072143555
Validation loss: 2.6903497301122195

Epoch: 6| Step: 2
Training loss: 3.007784843444824
Validation loss: 2.690518561229911

Epoch: 6| Step: 3
Training loss: 2.5405757427215576
Validation loss: 2.6960264559715026

Epoch: 6| Step: 4
Training loss: 3.26409912109375
Validation loss: 2.6958028808716805

Epoch: 6| Step: 5
Training loss: 3.077876567840576
Validation loss: 2.694142979960288

Epoch: 6| Step: 6
Training loss: 2.4963316917419434
Validation loss: 2.6986241571364866

Epoch: 6| Step: 7
Training loss: 2.830832004547119
Validation loss: 2.692022967082198

Epoch: 6| Step: 8
Training loss: 3.095324993133545
Validation loss: 2.6906233654227307

Epoch: 6| Step: 9
Training loss: 2.8738627433776855
Validation loss: 2.6866943195301998

Epoch: 6| Step: 10
Training loss: 3.737356662750244
Validation loss: 2.6867139236901396

Epoch: 6| Step: 11
Training loss: 2.191290855407715
Validation loss: 2.685989251700781

Epoch: 6| Step: 12
Training loss: 2.6971940994262695
Validation loss: 2.688033857653218

Epoch: 6| Step: 13
Training loss: 2.8954885005950928
Validation loss: 2.687344753614036

Epoch: 35| Step: 0
Training loss: 3.2488348484039307
Validation loss: 2.6953773421625935

Epoch: 6| Step: 1
Training loss: 1.6996160745620728
Validation loss: 2.6922509465166318

Epoch: 6| Step: 2
Training loss: 2.2755024433135986
Validation loss: 2.7030367646166074

Epoch: 6| Step: 3
Training loss: 3.6072988510131836
Validation loss: 2.7074063054976927

Epoch: 6| Step: 4
Training loss: 3.033207893371582
Validation loss: 2.6826494688628824

Epoch: 6| Step: 5
Training loss: 2.509580612182617
Validation loss: 2.6780400404366116

Epoch: 6| Step: 6
Training loss: 2.412546157836914
Validation loss: 2.6781206412981917

Epoch: 6| Step: 7
Training loss: 3.079193592071533
Validation loss: 2.6865428519505326

Epoch: 6| Step: 8
Training loss: 3.0348892211914062
Validation loss: 2.686395393904819

Epoch: 6| Step: 9
Training loss: 3.661850929260254
Validation loss: 2.6888275223393596

Epoch: 6| Step: 10
Training loss: 2.174546718597412
Validation loss: 2.6922312423747075

Epoch: 6| Step: 11
Training loss: 2.6085896492004395
Validation loss: 2.683194616789459

Epoch: 6| Step: 12
Training loss: 3.4614453315734863
Validation loss: 2.6907525421470724

Epoch: 6| Step: 13
Training loss: 3.4702646732330322
Validation loss: 2.686036443197599

Epoch: 36| Step: 0
Training loss: 3.4483909606933594
Validation loss: 2.6774279225257134

Epoch: 6| Step: 1
Training loss: 2.511082172393799
Validation loss: 2.6764256108191704

Epoch: 6| Step: 2
Training loss: 3.07277250289917
Validation loss: 2.6758071068794496

Epoch: 6| Step: 3
Training loss: 3.1700429916381836
Validation loss: 2.672238010232167

Epoch: 6| Step: 4
Training loss: 2.747788190841675
Validation loss: 2.6700935056132655

Epoch: 6| Step: 5
Training loss: 2.8327808380126953
Validation loss: 2.675824983145601

Epoch: 6| Step: 6
Training loss: 2.312321662902832
Validation loss: 2.6706486389201176

Epoch: 6| Step: 7
Training loss: 3.1653780937194824
Validation loss: 2.677643868231004

Epoch: 6| Step: 8
Training loss: 3.4055700302124023
Validation loss: 2.676259858633882

Epoch: 6| Step: 9
Training loss: 2.9628355503082275
Validation loss: 2.6798065913620817

Epoch: 6| Step: 10
Training loss: 2.5806753635406494
Validation loss: 2.6765381161884596

Epoch: 6| Step: 11
Training loss: 2.089876890182495
Validation loss: 2.6675824683199645

Epoch: 6| Step: 12
Training loss: 2.9091873168945312
Validation loss: 2.667377233505249

Epoch: 6| Step: 13
Training loss: 2.43198823928833
Validation loss: 2.665961532182591

Epoch: 37| Step: 0
Training loss: 3.0344207286834717
Validation loss: 2.6663771342205744

Epoch: 6| Step: 1
Training loss: 2.561525821685791
Validation loss: 2.666477641751689

Epoch: 6| Step: 2
Training loss: 3.725287437438965
Validation loss: 2.664479773531678

Epoch: 6| Step: 3
Training loss: 3.127467155456543
Validation loss: 2.667674292800247

Epoch: 6| Step: 4
Training loss: 2.958700180053711
Validation loss: 2.66357099112644

Epoch: 6| Step: 5
Training loss: 3.144437313079834
Validation loss: 2.6636701988917526

Epoch: 6| Step: 6
Training loss: 2.596223831176758
Validation loss: 2.663085142771403

Epoch: 6| Step: 7
Training loss: 2.7777047157287598
Validation loss: 2.6659751681871313

Epoch: 6| Step: 8
Training loss: 2.8022541999816895
Validation loss: 2.658409298107188

Epoch: 6| Step: 9
Training loss: 2.6022934913635254
Validation loss: 2.6571263113329486

Epoch: 6| Step: 10
Training loss: 3.1559691429138184
Validation loss: 2.6604833577268865

Epoch: 6| Step: 11
Training loss: 2.22072434425354
Validation loss: 2.6591668052058064

Epoch: 6| Step: 12
Training loss: 2.239956855773926
Validation loss: 2.6591185985072965

Epoch: 6| Step: 13
Training loss: 2.7945802211761475
Validation loss: 2.6554761830196587

Epoch: 38| Step: 0
Training loss: 2.534909248352051
Validation loss: 2.657796562358897

Epoch: 6| Step: 1
Training loss: 3.3497774600982666
Validation loss: 2.653934835105814

Epoch: 6| Step: 2
Training loss: 2.7414066791534424
Validation loss: 2.6593891420672016

Epoch: 6| Step: 3
Training loss: 3.1220507621765137
Validation loss: 2.6590452630032777

Epoch: 6| Step: 4
Training loss: 2.910407543182373
Validation loss: 2.656403433892035

Epoch: 6| Step: 5
Training loss: 2.5746426582336426
Validation loss: 2.65571266348644

Epoch: 6| Step: 6
Training loss: 2.113849401473999
Validation loss: 2.653925831599902

Epoch: 6| Step: 7
Training loss: 3.220902919769287
Validation loss: 2.6522857578851844

Epoch: 6| Step: 8
Training loss: 2.4136359691619873
Validation loss: 2.6532428213345107

Epoch: 6| Step: 9
Training loss: 3.0609002113342285
Validation loss: 2.653950132349486

Epoch: 6| Step: 10
Training loss: 2.69606351852417
Validation loss: 2.6560386175750406

Epoch: 6| Step: 11
Training loss: 3.5705575942993164
Validation loss: 2.655351628539383

Epoch: 6| Step: 12
Training loss: 2.6922945976257324
Validation loss: 2.6539718130583405

Epoch: 6| Step: 13
Training loss: 2.474114418029785
Validation loss: 2.6504009539081204

Epoch: 39| Step: 0
Training loss: 2.810577392578125
Validation loss: 2.6511299071773404

Epoch: 6| Step: 1
Training loss: 3.0206894874572754
Validation loss: 2.6546752786123626

Epoch: 6| Step: 2
Training loss: 2.2308332920074463
Validation loss: 2.6477922675430134

Epoch: 6| Step: 3
Training loss: 2.935318946838379
Validation loss: 2.649497050111012

Epoch: 6| Step: 4
Training loss: 2.7115297317504883
Validation loss: 2.6478181551861506

Epoch: 6| Step: 5
Training loss: 2.832613468170166
Validation loss: 2.6538761995171987

Epoch: 6| Step: 6
Training loss: 3.110278606414795
Validation loss: 2.657713600384292

Epoch: 6| Step: 7
Training loss: 3.2543811798095703
Validation loss: 2.65301800030534

Epoch: 6| Step: 8
Training loss: 2.5581722259521484
Validation loss: 2.6485322419033257

Epoch: 6| Step: 9
Training loss: 3.251538038253784
Validation loss: 2.646310865238149

Epoch: 6| Step: 10
Training loss: 2.5265026092529297
Validation loss: 2.64760192748039

Epoch: 6| Step: 11
Training loss: 3.093101739883423
Validation loss: 2.646670831147061

Epoch: 6| Step: 12
Training loss: 2.59407377243042
Validation loss: 2.6439707779115245

Epoch: 6| Step: 13
Training loss: 2.5432026386260986
Validation loss: 2.645063397704914

Epoch: 40| Step: 0
Training loss: 3.4751405715942383
Validation loss: 2.646853441833168

Epoch: 6| Step: 1
Training loss: 2.077096939086914
Validation loss: 2.6445774262951267

Epoch: 6| Step: 2
Training loss: 1.9846705198287964
Validation loss: 2.6441268510715936

Epoch: 6| Step: 3
Training loss: 3.581218719482422
Validation loss: 2.6406315167744956

Epoch: 6| Step: 4
Training loss: 2.2541210651397705
Validation loss: 2.6429257700520177

Epoch: 6| Step: 5
Training loss: 2.1036417484283447
Validation loss: 2.644077516371204

Epoch: 6| Step: 6
Training loss: 2.6100852489471436
Validation loss: 2.645339855583765

Epoch: 6| Step: 7
Training loss: 4.101078510284424
Validation loss: 2.6440370313582884

Epoch: 6| Step: 8
Training loss: 2.5384321212768555
Validation loss: 2.6453639204784105

Epoch: 6| Step: 9
Training loss: 2.275083065032959
Validation loss: 2.639621510300585

Epoch: 6| Step: 10
Training loss: 2.879377841949463
Validation loss: 2.643291155497233

Epoch: 6| Step: 11
Training loss: 3.803501605987549
Validation loss: 2.642385636606524

Epoch: 6| Step: 12
Training loss: 2.8837733268737793
Validation loss: 2.6410998323912263

Epoch: 6| Step: 13
Training loss: 3.0361146926879883
Validation loss: 2.6446625084005375

Epoch: 41| Step: 0
Training loss: 2.8738059997558594
Validation loss: 2.63583727036753

Epoch: 6| Step: 1
Training loss: 3.2390336990356445
Validation loss: 2.63990814967822

Epoch: 6| Step: 2
Training loss: 3.497594118118286
Validation loss: 2.6420949556494273

Epoch: 6| Step: 3
Training loss: 2.246263027191162
Validation loss: 2.6351985213577107

Epoch: 6| Step: 4
Training loss: 2.3645451068878174
Validation loss: 2.6413399737368346

Epoch: 6| Step: 5
Training loss: 2.643401622772217
Validation loss: 2.643732965633433

Epoch: 6| Step: 6
Training loss: 3.100356340408325
Validation loss: 2.638384808776199

Epoch: 6| Step: 7
Training loss: 3.496143102645874
Validation loss: 2.6412980864124913

Epoch: 6| Step: 8
Training loss: 2.5977320671081543
Validation loss: 2.637947710611487

Epoch: 6| Step: 9
Training loss: 2.8633532524108887
Validation loss: 2.6549036528474543

Epoch: 6| Step: 10
Training loss: 2.6464784145355225
Validation loss: 2.6435867483897875

Epoch: 6| Step: 11
Training loss: 2.461897850036621
Validation loss: 2.6427784786429456

Epoch: 6| Step: 12
Training loss: 2.789628028869629
Validation loss: 2.6398057117257068

Epoch: 6| Step: 13
Training loss: 2.637737989425659
Validation loss: 2.6349350303731938

Epoch: 42| Step: 0
Training loss: 3.3819055557250977
Validation loss: 2.6362889530838176

Epoch: 6| Step: 1
Training loss: 3.0526862144470215
Validation loss: 2.635159218183128

Epoch: 6| Step: 2
Training loss: 2.243990659713745
Validation loss: 2.6413775900358796

Epoch: 6| Step: 3
Training loss: 2.757706642150879
Validation loss: 2.637704687733804

Epoch: 6| Step: 4
Training loss: 2.547292709350586
Validation loss: 2.638179071487919

Epoch: 6| Step: 5
Training loss: 2.7490334510803223
Validation loss: 2.640649321258709

Epoch: 6| Step: 6
Training loss: 3.8904623985290527
Validation loss: 2.6423449875206075

Epoch: 6| Step: 7
Training loss: 2.9906232357025146
Validation loss: 2.6402938622300343

Epoch: 6| Step: 8
Training loss: 2.9094009399414062
Validation loss: 2.6356686494683705

Epoch: 6| Step: 9
Training loss: 3.3631598949432373
Validation loss: 2.635677263300906

Epoch: 6| Step: 10
Training loss: 2.2862422466278076
Validation loss: 2.638306627991379

Epoch: 6| Step: 11
Training loss: 2.7841477394104004
Validation loss: 2.6446912698848273

Epoch: 6| Step: 12
Training loss: 2.4204294681549072
Validation loss: 2.6395625017022573

Epoch: 6| Step: 13
Training loss: 1.581794261932373
Validation loss: 2.6361602301238687

Epoch: 43| Step: 0
Training loss: 2.8119921684265137
Validation loss: 2.6376365179656656

Epoch: 6| Step: 1
Training loss: 2.697389602661133
Validation loss: 2.63145734161459

Epoch: 6| Step: 2
Training loss: 1.8720464706420898
Validation loss: 2.6369032885438655

Epoch: 6| Step: 3
Training loss: 3.5768918991088867
Validation loss: 2.6371110100899973

Epoch: 6| Step: 4
Training loss: 3.20382022857666
Validation loss: 2.6415752621107202

Epoch: 6| Step: 5
Training loss: 2.5843894481658936
Validation loss: 2.6442499494039886

Epoch: 6| Step: 6
Training loss: 2.5861124992370605
Validation loss: 2.6366682642249653

Epoch: 6| Step: 7
Training loss: 2.8825531005859375
Validation loss: 2.6390509195225214

Epoch: 6| Step: 8
Training loss: 3.21994686126709
Validation loss: 2.6423081813320035

Epoch: 6| Step: 9
Training loss: 2.596245288848877
Validation loss: 2.6423106372997327

Epoch: 6| Step: 10
Training loss: 2.4335412979125977
Validation loss: 2.633123210681382

Epoch: 6| Step: 11
Training loss: 2.622392177581787
Validation loss: 2.6401674568012194

Epoch: 6| Step: 12
Training loss: 2.8114609718322754
Validation loss: 2.638117733822074

Epoch: 6| Step: 13
Training loss: 4.201830863952637
Validation loss: 2.6396449535123763

Epoch: 44| Step: 0
Training loss: 2.324939489364624
Validation loss: 2.6282735511820805

Epoch: 6| Step: 1
Training loss: 2.3996334075927734
Validation loss: 2.63525644681787

Epoch: 6| Step: 2
Training loss: 2.8310728073120117
Validation loss: 2.62875949182818

Epoch: 6| Step: 3
Training loss: 2.9836537837982178
Validation loss: 2.637140732939525

Epoch: 6| Step: 4
Training loss: 2.7545199394226074
Validation loss: 2.6324625374168478

Epoch: 6| Step: 5
Training loss: 3.288778305053711
Validation loss: 2.631785008215135

Epoch: 6| Step: 6
Training loss: 3.445072650909424
Validation loss: 2.6298561403828282

Epoch: 6| Step: 7
Training loss: 2.31559419631958
Validation loss: 2.630597012017363

Epoch: 6| Step: 8
Training loss: 3.071272373199463
Validation loss: 2.6301468597945346

Epoch: 6| Step: 9
Training loss: 3.1758615970611572
Validation loss: 2.631945535700808

Epoch: 6| Step: 10
Training loss: 2.281773090362549
Validation loss: 2.6244296514859764

Epoch: 6| Step: 11
Training loss: 2.3804404735565186
Validation loss: 2.6259682434861378

Epoch: 6| Step: 12
Training loss: 3.042572021484375
Validation loss: 2.62878240564818

Epoch: 6| Step: 13
Training loss: 3.5028438568115234
Validation loss: 2.634658034129809

Epoch: 45| Step: 0
Training loss: 2.580782890319824
Validation loss: 2.6441223288095124

Epoch: 6| Step: 1
Training loss: 2.881082057952881
Validation loss: 2.6558953433908443

Epoch: 6| Step: 2
Training loss: 2.8533709049224854
Validation loss: 2.6457786918968282

Epoch: 6| Step: 3
Training loss: 3.7866125106811523
Validation loss: 2.6566930740110335

Epoch: 6| Step: 4
Training loss: 2.517228603363037
Validation loss: 2.635886130794402

Epoch: 6| Step: 5
Training loss: 3.8428192138671875
Validation loss: 2.6310428239965953

Epoch: 6| Step: 6
Training loss: 3.095332622528076
Validation loss: 2.6203306592920774

Epoch: 6| Step: 7
Training loss: 2.4743614196777344
Validation loss: 2.6206466972187

Epoch: 6| Step: 8
Training loss: 2.3601861000061035
Validation loss: 2.6203166977051766

Epoch: 6| Step: 9
Training loss: 2.632098913192749
Validation loss: 2.621425797862391

Epoch: 6| Step: 10
Training loss: 2.756347417831421
Validation loss: 2.6214462582783034

Epoch: 6| Step: 11
Training loss: 2.8836379051208496
Validation loss: 2.6233091226188083

Epoch: 6| Step: 12
Training loss: 1.8786808252334595
Validation loss: 2.620765603998656

Epoch: 6| Step: 13
Training loss: 2.855877637863159
Validation loss: 2.624093335161927

Epoch: 46| Step: 0
Training loss: 2.6876988410949707
Validation loss: 2.621290191527336

Epoch: 6| Step: 1
Training loss: 3.248532295227051
Validation loss: 2.6234122655724965

Epoch: 6| Step: 2
Training loss: 2.6759212017059326
Validation loss: 2.6267899492735505

Epoch: 6| Step: 3
Training loss: 2.8799028396606445
Validation loss: 2.621813935618247

Epoch: 6| Step: 4
Training loss: 2.6237082481384277
Validation loss: 2.6243982955973637

Epoch: 6| Step: 5
Training loss: 3.7831125259399414
Validation loss: 2.6183932776092202

Epoch: 6| Step: 6
Training loss: 2.9235339164733887
Validation loss: 2.621322760017969

Epoch: 6| Step: 7
Training loss: 2.516569137573242
Validation loss: 2.615770850130307

Epoch: 6| Step: 8
Training loss: 3.104137897491455
Validation loss: 2.617093406697755

Epoch: 6| Step: 9
Training loss: 2.014507293701172
Validation loss: 2.613988414887459

Epoch: 6| Step: 10
Training loss: 2.8572874069213867
Validation loss: 2.6170343096538256

Epoch: 6| Step: 11
Training loss: 2.1714560985565186
Validation loss: 2.613387571868076

Epoch: 6| Step: 12
Training loss: 2.831176280975342
Validation loss: 2.6140955084113666

Epoch: 6| Step: 13
Training loss: 3.0814623832702637
Validation loss: 2.6235043925623738

Epoch: 47| Step: 0
Training loss: 2.72574520111084
Validation loss: 2.6322669418909217

Epoch: 6| Step: 1
Training loss: 2.8151869773864746
Validation loss: 2.624291399473785

Epoch: 6| Step: 2
Training loss: 2.4429244995117188
Validation loss: 2.6260031320715465

Epoch: 6| Step: 3
Training loss: 3.426384449005127
Validation loss: 2.617264298982518

Epoch: 6| Step: 4
Training loss: 3.096558094024658
Validation loss: 2.6148992815325336

Epoch: 6| Step: 5
Training loss: 2.1145448684692383
Validation loss: 2.615149146767073

Epoch: 6| Step: 6
Training loss: 2.8348355293273926
Validation loss: 2.6091368198394775

Epoch: 6| Step: 7
Training loss: 2.833205223083496
Validation loss: 2.6119329801169773

Epoch: 6| Step: 8
Training loss: 2.5661401748657227
Validation loss: 2.6130011671332904

Epoch: 6| Step: 9
Training loss: 2.982825756072998
Validation loss: 2.6121731394080707

Epoch: 6| Step: 10
Training loss: 3.255685806274414
Validation loss: 2.6119209181877876

Epoch: 6| Step: 11
Training loss: 2.815126657485962
Validation loss: 2.6140125618186048

Epoch: 6| Step: 12
Training loss: 2.8967390060424805
Validation loss: 2.6158223639252367

Epoch: 6| Step: 13
Training loss: 2.121029853820801
Validation loss: 2.614038985262635

Epoch: 48| Step: 0
Training loss: 1.6021167039871216
Validation loss: 2.6180164070539576

Epoch: 6| Step: 1
Training loss: 2.0904810428619385
Validation loss: 2.61387207687542

Epoch: 6| Step: 2
Training loss: 2.266467571258545
Validation loss: 2.624373379574027

Epoch: 6| Step: 3
Training loss: 4.352473258972168
Validation loss: 2.63377139388874

Epoch: 6| Step: 4
Training loss: 2.562747001647949
Validation loss: 2.6282272851595314

Epoch: 6| Step: 5
Training loss: 3.3552327156066895
Validation loss: 2.6351426365554973

Epoch: 6| Step: 6
Training loss: 2.8014512062072754
Validation loss: 2.634464586934736

Epoch: 6| Step: 7
Training loss: 2.861388683319092
Validation loss: 2.62333240560306

Epoch: 6| Step: 8
Training loss: 2.280527114868164
Validation loss: 2.6169742384264545

Epoch: 6| Step: 9
Training loss: 3.781500816345215
Validation loss: 2.6153250304601525

Epoch: 6| Step: 10
Training loss: 2.6766855716705322
Validation loss: 2.6137705874699417

Epoch: 6| Step: 11
Training loss: 2.859714984893799
Validation loss: 2.614668100110946

Epoch: 6| Step: 12
Training loss: 3.141711711883545
Validation loss: 2.6190813228648198

Epoch: 6| Step: 13
Training loss: 2.3906211853027344
Validation loss: 2.6132507785674064

Epoch: 49| Step: 0
Training loss: 2.0382156372070312
Validation loss: 2.6153024909316853

Epoch: 6| Step: 1
Training loss: 3.264951467514038
Validation loss: 2.616486241740565

Epoch: 6| Step: 2
Training loss: 2.0395073890686035
Validation loss: 2.6260027167617634

Epoch: 6| Step: 3
Training loss: 3.2923336029052734
Validation loss: 2.6260543331023185

Epoch: 6| Step: 4
Training loss: 2.4061343669891357
Validation loss: 2.632863701030772

Epoch: 6| Step: 5
Training loss: 2.5759763717651367
Validation loss: 2.623133818308512

Epoch: 6| Step: 6
Training loss: 3.609738826751709
Validation loss: 2.6189244947125836

Epoch: 6| Step: 7
Training loss: 3.0159411430358887
Validation loss: 2.622232226915257

Epoch: 6| Step: 8
Training loss: 3.3104991912841797
Validation loss: 2.6191509897990892

Epoch: 6| Step: 9
Training loss: 2.6828227043151855
Validation loss: 2.617734429656818

Epoch: 6| Step: 10
Training loss: 2.9559900760650635
Validation loss: 2.6123266220092773

Epoch: 6| Step: 11
Training loss: 2.22182035446167
Validation loss: 2.6254505572780484

Epoch: 6| Step: 12
Training loss: 2.9488635063171387
Validation loss: 2.6137288334549114

Epoch: 6| Step: 13
Training loss: 2.8070831298828125
Validation loss: 2.612231595541841

Epoch: 50| Step: 0
Training loss: 2.665919780731201
Validation loss: 2.611252789856285

Epoch: 6| Step: 1
Training loss: 2.9614620208740234
Validation loss: 2.6015112605146182

Epoch: 6| Step: 2
Training loss: 2.634165048599243
Validation loss: 2.6035169375840055

Epoch: 6| Step: 3
Training loss: 2.3273401260375977
Validation loss: 2.5992555233740036

Epoch: 6| Step: 4
Training loss: 2.7340946197509766
Validation loss: 2.602881226488339

Epoch: 6| Step: 5
Training loss: 2.907850742340088
Validation loss: 2.6039553867873324

Epoch: 6| Step: 6
Training loss: 3.820950746536255
Validation loss: 2.6126034080341296

Epoch: 6| Step: 7
Training loss: 2.5016565322875977
Validation loss: 2.6164697882949666

Epoch: 6| Step: 8
Training loss: 2.646547794342041
Validation loss: 2.6052136882658927

Epoch: 6| Step: 9
Training loss: 2.431670904159546
Validation loss: 2.605549971262614

Epoch: 6| Step: 10
Training loss: 2.967757225036621
Validation loss: 2.5993665443953646

Epoch: 6| Step: 11
Training loss: 2.229376792907715
Validation loss: 2.6075931313217326

Epoch: 6| Step: 12
Training loss: 3.440504550933838
Validation loss: 2.6063862718561643

Epoch: 6| Step: 13
Training loss: 2.9260141849517822
Validation loss: 2.6101085550041607

Epoch: 51| Step: 0
Training loss: 3.2354960441589355
Validation loss: 2.6133975059755388

Epoch: 6| Step: 1
Training loss: 3.0211963653564453
Validation loss: 2.6208514551962576

Epoch: 6| Step: 2
Training loss: 3.1940622329711914
Validation loss: 2.627054872051362

Epoch: 6| Step: 3
Training loss: 2.4369776248931885
Validation loss: 2.621107655186807

Epoch: 6| Step: 4
Training loss: 3.238840341567993
Validation loss: 2.633059476011543

Epoch: 6| Step: 5
Training loss: 2.339205026626587
Validation loss: 2.6235215356273036

Epoch: 6| Step: 6
Training loss: 2.7343859672546387
Validation loss: 2.609933227621099

Epoch: 6| Step: 7
Training loss: 3.576777696609497
Validation loss: 2.6024391061516217

Epoch: 6| Step: 8
Training loss: 2.788825273513794
Validation loss: 2.599905731857464

Epoch: 6| Step: 9
Training loss: 2.65049409866333
Validation loss: 2.5989985619821856

Epoch: 6| Step: 10
Training loss: 2.3858556747436523
Validation loss: 2.6000587735124814

Epoch: 6| Step: 11
Training loss: 3.2058558464050293
Validation loss: 2.600170889208394

Epoch: 6| Step: 12
Training loss: 2.3031258583068848
Validation loss: 2.6080390330283874

Epoch: 6| Step: 13
Training loss: 1.4446169137954712
Validation loss: 2.6078617803512083

Epoch: 52| Step: 0
Training loss: 2.9247732162475586
Validation loss: 2.6037961513765397

Epoch: 6| Step: 1
Training loss: 2.239536762237549
Validation loss: 2.6068824978284937

Epoch: 6| Step: 2
Training loss: 3.4699244499206543
Validation loss: 2.6040350416655182

Epoch: 6| Step: 3
Training loss: 2.202798366546631
Validation loss: 2.601410481237596

Epoch: 6| Step: 4
Training loss: 3.3918516635894775
Validation loss: 2.599316781566989

Epoch: 6| Step: 5
Training loss: 3.2298026084899902
Validation loss: 2.5993356499620663

Epoch: 6| Step: 6
Training loss: 2.0762746334075928
Validation loss: 2.602898126007408

Epoch: 6| Step: 7
Training loss: 2.507723331451416
Validation loss: 2.600005672823998

Epoch: 6| Step: 8
Training loss: 2.1264472007751465
Validation loss: 2.6046993706815984

Epoch: 6| Step: 9
Training loss: 3.693333148956299
Validation loss: 2.5955319096965175

Epoch: 6| Step: 10
Training loss: 3.0254456996917725
Validation loss: 2.5965691125521095

Epoch: 6| Step: 11
Training loss: 2.5511252880096436
Validation loss: 2.6008639540723575

Epoch: 6| Step: 12
Training loss: 2.6052842140197754
Validation loss: 2.596339774388139

Epoch: 6| Step: 13
Training loss: 3.0483851432800293
Validation loss: 2.5983616741754676

Epoch: 53| Step: 0
Training loss: 3.081808567047119
Validation loss: 2.5974694631432973

Epoch: 6| Step: 1
Training loss: 2.4511160850524902
Validation loss: 2.59938314396848

Epoch: 6| Step: 2
Training loss: 2.4470858573913574
Validation loss: 2.59610261712023

Epoch: 6| Step: 3
Training loss: 3.036712646484375
Validation loss: 2.598162263952276

Epoch: 6| Step: 4
Training loss: 2.614180564880371
Validation loss: 2.5991406056188766

Epoch: 6| Step: 5
Training loss: 3.6046199798583984
Validation loss: 2.5947828959393244

Epoch: 6| Step: 6
Training loss: 2.596520185470581
Validation loss: 2.595508098602295

Epoch: 6| Step: 7
Training loss: 2.446324348449707
Validation loss: 2.594479783888786

Epoch: 6| Step: 8
Training loss: 2.5448641777038574
Validation loss: 2.5902621233335106

Epoch: 6| Step: 9
Training loss: 3.926577568054199
Validation loss: 2.594863489109983

Epoch: 6| Step: 10
Training loss: 1.9985240697860718
Validation loss: 2.5937272348711566

Epoch: 6| Step: 11
Training loss: 2.7987587451934814
Validation loss: 2.6073035834937968

Epoch: 6| Step: 12
Training loss: 3.085196018218994
Validation loss: 2.600971770542924

Epoch: 6| Step: 13
Training loss: 2.0241990089416504
Validation loss: 2.602284659621536

Epoch: 54| Step: 0
Training loss: 2.293309211730957
Validation loss: 2.5957639140467488

Epoch: 6| Step: 1
Training loss: 3.172370195388794
Validation loss: 2.592190052873345

Epoch: 6| Step: 2
Training loss: 2.511380910873413
Validation loss: 2.592787763123871

Epoch: 6| Step: 3
Training loss: 2.516780376434326
Validation loss: 2.589983081304899

Epoch: 6| Step: 4
Training loss: 2.733309268951416
Validation loss: 2.590855303631034

Epoch: 6| Step: 5
Training loss: 2.7729883193969727
Validation loss: 2.587108555660453

Epoch: 6| Step: 6
Training loss: 3.1378040313720703
Validation loss: 2.5882963672760995

Epoch: 6| Step: 7
Training loss: 2.5273585319519043
Validation loss: 2.588394280402891

Epoch: 6| Step: 8
Training loss: 3.2134299278259277
Validation loss: 2.587698177624774

Epoch: 6| Step: 9
Training loss: 2.195794105529785
Validation loss: 2.5872601078402613

Epoch: 6| Step: 10
Training loss: 3.2930984497070312
Validation loss: 2.584767685141615

Epoch: 6| Step: 11
Training loss: 2.9803457260131836
Validation loss: 2.5839853491834415

Epoch: 6| Step: 12
Training loss: 3.207824230194092
Validation loss: 2.5865722164030998

Epoch: 6| Step: 13
Training loss: 2.0569369792938232
Validation loss: 2.5842697338391374

Epoch: 55| Step: 0
Training loss: 2.784820795059204
Validation loss: 2.585150682797996

Epoch: 6| Step: 1
Training loss: 2.5083963871002197
Validation loss: 2.5821103408772457

Epoch: 6| Step: 2
Training loss: 3.208491325378418
Validation loss: 2.577602905611838

Epoch: 6| Step: 3
Training loss: 3.2391841411590576
Validation loss: 2.5819369362246607

Epoch: 6| Step: 4
Training loss: 2.7385499477386475
Validation loss: 2.587672923200874

Epoch: 6| Step: 5
Training loss: 2.901547431945801
Validation loss: 2.584619596440305

Epoch: 6| Step: 6
Training loss: 2.324624538421631
Validation loss: 2.590785398278185

Epoch: 6| Step: 7
Training loss: 2.448147773742676
Validation loss: 2.5850321323640886

Epoch: 6| Step: 8
Training loss: 2.6797332763671875
Validation loss: 2.591114849172613

Epoch: 6| Step: 9
Training loss: 2.9360034465789795
Validation loss: 2.580848261874209

Epoch: 6| Step: 10
Training loss: 2.7334327697753906
Validation loss: 2.5776917549871627

Epoch: 6| Step: 11
Training loss: 2.7586841583251953
Validation loss: 2.573586428037254

Epoch: 6| Step: 12
Training loss: 2.8482308387756348
Validation loss: 2.575855552509267

Epoch: 6| Step: 13
Training loss: 2.6868529319763184
Validation loss: 2.5746012836374264

Epoch: 56| Step: 0
Training loss: 2.6284894943237305
Validation loss: 2.5715254532393588

Epoch: 6| Step: 1
Training loss: 3.542952537536621
Validation loss: 2.572926987883865

Epoch: 6| Step: 2
Training loss: 2.4137516021728516
Validation loss: 2.5719161648904123

Epoch: 6| Step: 3
Training loss: 2.9866645336151123
Validation loss: 2.573626805377263

Epoch: 6| Step: 4
Training loss: 2.9317545890808105
Validation loss: 2.575716416041056

Epoch: 6| Step: 5
Training loss: 2.759819746017456
Validation loss: 2.5776290816645466

Epoch: 6| Step: 6
Training loss: 2.7288246154785156
Validation loss: 2.5844163381925194

Epoch: 6| Step: 7
Training loss: 2.6451706886291504
Validation loss: 2.5908497174580893

Epoch: 6| Step: 8
Training loss: 3.565577507019043
Validation loss: 2.598429513233964

Epoch: 6| Step: 9
Training loss: 3.0593202114105225
Validation loss: 2.601896047592163

Epoch: 6| Step: 10
Training loss: 2.618039608001709
Validation loss: 2.588327464237008

Epoch: 6| Step: 11
Training loss: 2.7367401123046875
Validation loss: 2.576971323259415

Epoch: 6| Step: 12
Training loss: 1.8792239427566528
Validation loss: 2.5741888066773773

Epoch: 6| Step: 13
Training loss: 1.934546947479248
Validation loss: 2.5728409187768095

Epoch: 57| Step: 0
Training loss: 3.108520030975342
Validation loss: 2.5697713334073304

Epoch: 6| Step: 1
Training loss: 3.2084693908691406
Validation loss: 2.570575045001122

Epoch: 6| Step: 2
Training loss: 2.6521263122558594
Validation loss: 2.5734368088424846

Epoch: 6| Step: 3
Training loss: 2.553332805633545
Validation loss: 2.5681435318403345

Epoch: 6| Step: 4
Training loss: 2.2930312156677246
Validation loss: 2.5736384340511855

Epoch: 6| Step: 5
Training loss: 2.834937810897827
Validation loss: 2.571668004476896

Epoch: 6| Step: 6
Training loss: 2.775768280029297
Validation loss: 2.572610314174365

Epoch: 6| Step: 7
Training loss: 2.997027635574341
Validation loss: 2.5693167383952806

Epoch: 6| Step: 8
Training loss: 2.9535117149353027
Validation loss: 2.57499179532451

Epoch: 6| Step: 9
Training loss: 3.1136717796325684
Validation loss: 2.56836707874011

Epoch: 6| Step: 10
Training loss: 2.601334571838379
Validation loss: 2.5763251602008777

Epoch: 6| Step: 11
Training loss: 2.169647693634033
Validation loss: 2.574443873538766

Epoch: 6| Step: 12
Training loss: 2.7388033866882324
Validation loss: 2.5774927908374416

Epoch: 6| Step: 13
Training loss: 2.7278854846954346
Validation loss: 2.5825330954726025

Epoch: 58| Step: 0
Training loss: 3.0973434448242188
Validation loss: 2.5826449214771228

Epoch: 6| Step: 1
Training loss: 2.4807815551757812
Validation loss: 2.5974905055056334

Epoch: 6| Step: 2
Training loss: 3.2664413452148438
Validation loss: 2.627603748793243

Epoch: 6| Step: 3
Training loss: 2.8067593574523926
Validation loss: 2.6256402051577004

Epoch: 6| Step: 4
Training loss: 2.2995896339416504
Validation loss: 2.615581961088283

Epoch: 6| Step: 5
Training loss: 2.7328741550445557
Validation loss: 2.597341368275304

Epoch: 6| Step: 6
Training loss: 2.6716485023498535
Validation loss: 2.577897484584521

Epoch: 6| Step: 7
Training loss: 1.8438143730163574
Validation loss: 2.568398875574912

Epoch: 6| Step: 8
Training loss: 3.0735106468200684
Validation loss: 2.5714458598885486

Epoch: 6| Step: 9
Training loss: 2.8996267318725586
Validation loss: 2.5784766033131588

Epoch: 6| Step: 10
Training loss: 2.9964723587036133
Validation loss: 2.5749178727467856

Epoch: 6| Step: 11
Training loss: 2.629045248031616
Validation loss: 2.578101611906482

Epoch: 6| Step: 12
Training loss: 3.242757797241211
Validation loss: 2.5745538998675603

Epoch: 6| Step: 13
Training loss: 2.933204174041748
Validation loss: 2.5713166293277534

Epoch: 59| Step: 0
Training loss: 2.835362434387207
Validation loss: 2.5742001751417756

Epoch: 6| Step: 1
Training loss: 2.4577393531799316
Validation loss: 2.5695323251908824

Epoch: 6| Step: 2
Training loss: 2.1699066162109375
Validation loss: 2.574966807519236

Epoch: 6| Step: 3
Training loss: 2.616212844848633
Validation loss: 2.5764210301060833

Epoch: 6| Step: 4
Training loss: 2.835394859313965
Validation loss: 2.5737035248869207

Epoch: 6| Step: 5
Training loss: 2.5404839515686035
Validation loss: 2.5736272822144213

Epoch: 6| Step: 6
Training loss: 3.134145736694336
Validation loss: 2.5709468574934107

Epoch: 6| Step: 7
Training loss: 2.7780842781066895
Validation loss: 2.5680544863465014

Epoch: 6| Step: 8
Training loss: 1.8879625797271729
Validation loss: 2.5642862666037773

Epoch: 6| Step: 9
Training loss: 2.4535906314849854
Validation loss: 2.5745344982352307

Epoch: 6| Step: 10
Training loss: 2.7173984050750732
Validation loss: 2.565948893946986

Epoch: 6| Step: 11
Training loss: 3.888730049133301
Validation loss: 2.5665708818743305

Epoch: 6| Step: 12
Training loss: 2.9621851444244385
Validation loss: 2.566237042027135

Epoch: 6| Step: 13
Training loss: 4.008194923400879
Validation loss: 2.563637477095409

Epoch: 60| Step: 0
Training loss: 2.5525107383728027
Validation loss: 2.56542565232964

Epoch: 6| Step: 1
Training loss: 3.217987060546875
Validation loss: 2.5681193310727357

Epoch: 6| Step: 2
Training loss: 3.272904634475708
Validation loss: 2.568101400970131

Epoch: 6| Step: 3
Training loss: 2.9350481033325195
Validation loss: 2.5674598011919247

Epoch: 6| Step: 4
Training loss: 2.4465627670288086
Validation loss: 2.5690750563016502

Epoch: 6| Step: 5
Training loss: 2.4262094497680664
Validation loss: 2.564830046828075

Epoch: 6| Step: 6
Training loss: 2.512192726135254
Validation loss: 2.5605508845339537

Epoch: 6| Step: 7
Training loss: 2.1307196617126465
Validation loss: 2.5574397630588983

Epoch: 6| Step: 8
Training loss: 2.8017618656158447
Validation loss: 2.558439900798182

Epoch: 6| Step: 9
Training loss: 2.770904302597046
Validation loss: 2.557141142506753

Epoch: 6| Step: 10
Training loss: 2.508657217025757
Validation loss: 2.5583308332709858

Epoch: 6| Step: 11
Training loss: 3.4506165981292725
Validation loss: 2.5555477911426174

Epoch: 6| Step: 12
Training loss: 2.948148012161255
Validation loss: 2.556194254147109

Epoch: 6| Step: 13
Training loss: 2.590928077697754
Validation loss: 2.5602950383258123

Epoch: 61| Step: 0
Training loss: 3.7012686729431152
Validation loss: 2.55753989629848

Epoch: 6| Step: 1
Training loss: 2.9872446060180664
Validation loss: 2.5552321146893244

Epoch: 6| Step: 2
Training loss: 2.1611557006835938
Validation loss: 2.561459392629644

Epoch: 6| Step: 3
Training loss: 2.7564969062805176
Validation loss: 2.561495634817308

Epoch: 6| Step: 4
Training loss: 3.2681117057800293
Validation loss: 2.5603027241204375

Epoch: 6| Step: 5
Training loss: 2.6729111671447754
Validation loss: 2.556688424079649

Epoch: 6| Step: 6
Training loss: 2.6054916381835938
Validation loss: 2.5507115035928707

Epoch: 6| Step: 7
Training loss: 3.1221890449523926
Validation loss: 2.552722079779512

Epoch: 6| Step: 8
Training loss: 2.688520908355713
Validation loss: 2.552651728353193

Epoch: 6| Step: 9
Training loss: 2.242659091949463
Validation loss: 2.5560983175872476

Epoch: 6| Step: 10
Training loss: 2.8057191371917725
Validation loss: 2.553347847794974

Epoch: 6| Step: 11
Training loss: 2.9012410640716553
Validation loss: 2.551083903158865

Epoch: 6| Step: 12
Training loss: 1.9385881423950195
Validation loss: 2.5498288857039584

Epoch: 6| Step: 13
Training loss: 2.6660103797912598
Validation loss: 2.55013003400577

Epoch: 62| Step: 0
Training loss: 3.3466691970825195
Validation loss: 2.550275889776086

Epoch: 6| Step: 1
Training loss: 3.2368409633636475
Validation loss: 2.5542595694142003

Epoch: 6| Step: 2
Training loss: 3.185055732727051
Validation loss: 2.5513856128979753

Epoch: 6| Step: 3
Training loss: 1.941611409187317
Validation loss: 2.5462937444768925

Epoch: 6| Step: 4
Training loss: 2.0802876949310303
Validation loss: 2.5462684990257345

Epoch: 6| Step: 5
Training loss: 2.925225019454956
Validation loss: 2.5475675957177275

Epoch: 6| Step: 6
Training loss: 2.998908281326294
Validation loss: 2.547910585198351

Epoch: 6| Step: 7
Training loss: 2.835686206817627
Validation loss: 2.5502509763163905

Epoch: 6| Step: 8
Training loss: 3.063352584838867
Validation loss: 2.5518585123041624

Epoch: 6| Step: 9
Training loss: 3.3466644287109375
Validation loss: 2.557636576314126

Epoch: 6| Step: 10
Training loss: 2.4731850624084473
Validation loss: 2.557981644907305

Epoch: 6| Step: 11
Training loss: 2.0433194637298584
Validation loss: 2.577259732830909

Epoch: 6| Step: 12
Training loss: 2.6238880157470703
Validation loss: 2.577076824762488

Epoch: 6| Step: 13
Training loss: 2.119595527648926
Validation loss: 2.5766164256680395

Epoch: 63| Step: 0
Training loss: 3.730318069458008
Validation loss: 2.616398637012769

Epoch: 6| Step: 1
Training loss: 2.8729381561279297
Validation loss: 2.6256768190732567

Epoch: 6| Step: 2
Training loss: 2.6894021034240723
Validation loss: 2.6123957992881857

Epoch: 6| Step: 3
Training loss: 2.9336977005004883
Validation loss: 2.612142990994197

Epoch: 6| Step: 4
Training loss: 2.7665953636169434
Validation loss: 2.5789113224193616

Epoch: 6| Step: 5
Training loss: 2.6117591857910156
Validation loss: 2.5584748406564035

Epoch: 6| Step: 6
Training loss: 2.483527183532715
Validation loss: 2.5442454071455103

Epoch: 6| Step: 7
Training loss: 3.4934799671173096
Validation loss: 2.541235734057683

Epoch: 6| Step: 8
Training loss: 2.360869884490967
Validation loss: 2.5459199413176505

Epoch: 6| Step: 9
Training loss: 2.632784366607666
Validation loss: 2.5524966229674635

Epoch: 6| Step: 10
Training loss: 2.81807541847229
Validation loss: 2.5562351724152923

Epoch: 6| Step: 11
Training loss: 2.5638222694396973
Validation loss: 2.5487555380790465

Epoch: 6| Step: 12
Training loss: 2.271453380584717
Validation loss: 2.5536589981407247

Epoch: 6| Step: 13
Training loss: 2.4345595836639404
Validation loss: 2.5616951296406407

Epoch: 64| Step: 0
Training loss: 2.8935983180999756
Validation loss: 2.556553804746238

Epoch: 6| Step: 1
Training loss: 3.2666263580322266
Validation loss: 2.573609379030043

Epoch: 6| Step: 2
Training loss: 2.430509090423584
Validation loss: 2.584640832357509

Epoch: 6| Step: 3
Training loss: 2.6624560356140137
Validation loss: 2.5883786191222486

Epoch: 6| Step: 4
Training loss: 3.074279546737671
Validation loss: 2.5817212315015894

Epoch: 6| Step: 5
Training loss: 1.9342182874679565
Validation loss: 2.5591417692040883

Epoch: 6| Step: 6
Training loss: 2.0279688835144043
Validation loss: 2.5475837158900436

Epoch: 6| Step: 7
Training loss: 3.5746538639068604
Validation loss: 2.549129847557314

Epoch: 6| Step: 8
Training loss: 2.6996524333953857
Validation loss: 2.5578100219849618

Epoch: 6| Step: 9
Training loss: 2.8896727561950684
Validation loss: 2.5621818316880094

Epoch: 6| Step: 10
Training loss: 2.539937973022461
Validation loss: 2.5702740325722644

Epoch: 6| Step: 11
Training loss: 3.4490909576416016
Validation loss: 2.5674031703702864

Epoch: 6| Step: 12
Training loss: 2.5898447036743164
Validation loss: 2.557348023178757

Epoch: 6| Step: 13
Training loss: 2.4586117267608643
Validation loss: 2.5520944826064573

Epoch: 65| Step: 0
Training loss: 2.5950896739959717
Validation loss: 2.5464264205707017

Epoch: 6| Step: 1
Training loss: 2.981499433517456
Validation loss: 2.5435169666044173

Epoch: 6| Step: 2
Training loss: 2.628568172454834
Validation loss: 2.54641806438405

Epoch: 6| Step: 3
Training loss: 2.5683109760284424
Validation loss: 2.544974785979076

Epoch: 6| Step: 4
Training loss: 3.3003969192504883
Validation loss: 2.54857127640837

Epoch: 6| Step: 5
Training loss: 2.4960825443267822
Validation loss: 2.5471629763162262

Epoch: 6| Step: 6
Training loss: 2.7373125553131104
Validation loss: 2.547645486811156

Epoch: 6| Step: 7
Training loss: 2.7297768592834473
Validation loss: 2.546971490306239

Epoch: 6| Step: 8
Training loss: 3.1172051429748535
Validation loss: 2.54255683191361

Epoch: 6| Step: 9
Training loss: 2.352206230163574
Validation loss: 2.5541486535021054

Epoch: 6| Step: 10
Training loss: 2.5016543865203857
Validation loss: 2.5539817451148905

Epoch: 6| Step: 11
Training loss: 2.3986496925354004
Validation loss: 2.553600490734141

Epoch: 6| Step: 12
Training loss: 3.4363696575164795
Validation loss: 2.5546356811318347

Epoch: 6| Step: 13
Training loss: 2.4969635009765625
Validation loss: 2.5380985813756145

Epoch: 66| Step: 0
Training loss: 2.002595901489258
Validation loss: 2.5429746309916177

Epoch: 6| Step: 1
Training loss: 2.4999260902404785
Validation loss: 2.5393459668723484

Epoch: 6| Step: 2
Training loss: 3.186461925506592
Validation loss: 2.5445310069668676

Epoch: 6| Step: 3
Training loss: 3.256650924682617
Validation loss: 2.5472696083848194

Epoch: 6| Step: 4
Training loss: 3.0098700523376465
Validation loss: 2.5413533128717893

Epoch: 6| Step: 5
Training loss: 3.33200740814209
Validation loss: 2.5561235386838197

Epoch: 6| Step: 6
Training loss: 2.808095693588257
Validation loss: 2.5631403820489043

Epoch: 6| Step: 7
Training loss: 2.369251251220703
Validation loss: 2.5677745521709485

Epoch: 6| Step: 8
Training loss: 2.9941940307617188
Validation loss: 2.552425479376188

Epoch: 6| Step: 9
Training loss: 2.2439448833465576
Validation loss: 2.553164989717545

Epoch: 6| Step: 10
Training loss: 3.386465549468994
Validation loss: 2.542058621683428

Epoch: 6| Step: 11
Training loss: 2.380110025405884
Validation loss: 2.538122623197494

Epoch: 6| Step: 12
Training loss: 2.4065897464752197
Validation loss: 2.5391679322847756

Epoch: 6| Step: 13
Training loss: 2.387981414794922
Validation loss: 2.541406011068693

Epoch: 67| Step: 0
Training loss: 2.893888235092163
Validation loss: 2.5353498458862305

Epoch: 6| Step: 1
Training loss: 2.6145546436309814
Validation loss: 2.536910387777513

Epoch: 6| Step: 2
Training loss: 2.234038829803467
Validation loss: 2.53677043350794

Epoch: 6| Step: 3
Training loss: 2.7019166946411133
Validation loss: 2.5357939863717682

Epoch: 6| Step: 4
Training loss: 3.506377935409546
Validation loss: 2.5416166397833053

Epoch: 6| Step: 5
Training loss: 2.8300094604492188
Validation loss: 2.5343257945070983

Epoch: 6| Step: 6
Training loss: 2.0519726276397705
Validation loss: 2.5375059240607807

Epoch: 6| Step: 7
Training loss: 2.657987594604492
Validation loss: 2.5332998357793337

Epoch: 6| Step: 8
Training loss: 3.4048991203308105
Validation loss: 2.5366878150611796

Epoch: 6| Step: 9
Training loss: 3.586892604827881
Validation loss: 2.5348408606744584

Epoch: 6| Step: 10
Training loss: 2.5092272758483887
Validation loss: 2.53673541930414

Epoch: 6| Step: 11
Training loss: 2.2122700214385986
Validation loss: 2.5420754327568957

Epoch: 6| Step: 12
Training loss: 2.382983684539795
Validation loss: 2.544448285974482

Epoch: 6| Step: 13
Training loss: 2.7556679248809814
Validation loss: 2.54279141272268

Epoch: 68| Step: 0
Training loss: 2.5100998878479004
Validation loss: 2.5377382411751697

Epoch: 6| Step: 1
Training loss: 2.26578426361084
Validation loss: 2.5412672617102183

Epoch: 6| Step: 2
Training loss: 2.46884822845459
Validation loss: 2.5413537897089475

Epoch: 6| Step: 3
Training loss: 3.2223148345947266
Validation loss: 2.53978273817288

Epoch: 6| Step: 4
Training loss: 2.585016965866089
Validation loss: 2.535636399381904

Epoch: 6| Step: 5
Training loss: 3.142446517944336
Validation loss: 2.5401791475152455

Epoch: 6| Step: 6
Training loss: 2.7746622562408447
Validation loss: 2.541583263745872

Epoch: 6| Step: 7
Training loss: 2.2852983474731445
Validation loss: 2.5428116936837473

Epoch: 6| Step: 8
Training loss: 3.0762417316436768
Validation loss: 2.5354733774738927

Epoch: 6| Step: 9
Training loss: 2.7966904640197754
Validation loss: 2.5357328461062525

Epoch: 6| Step: 10
Training loss: 3.0656139850616455
Validation loss: 2.5374900192342777

Epoch: 6| Step: 11
Training loss: 2.681244373321533
Validation loss: 2.53840123966176

Epoch: 6| Step: 12
Training loss: 2.3566854000091553
Validation loss: 2.5387272527140956

Epoch: 6| Step: 13
Training loss: 3.2679944038391113
Validation loss: 2.535807328839456

Epoch: 69| Step: 0
Training loss: 2.8380367755889893
Validation loss: 2.5313819634017123

Epoch: 6| Step: 1
Training loss: 3.2175416946411133
Validation loss: 2.5381962304474204

Epoch: 6| Step: 2
Training loss: 2.6820805072784424
Validation loss: 2.5324499068721646

Epoch: 6| Step: 3
Training loss: 2.535858392715454
Validation loss: 2.53112546859249

Epoch: 6| Step: 4
Training loss: 2.607572078704834
Validation loss: 2.531696142688874

Epoch: 6| Step: 5
Training loss: 2.3712453842163086
Validation loss: 2.534757278298819

Epoch: 6| Step: 6
Training loss: 2.195098638534546
Validation loss: 2.5352388094830256

Epoch: 6| Step: 7
Training loss: 3.0475473403930664
Validation loss: 2.538496417383994

Epoch: 6| Step: 8
Training loss: 2.6199564933776855
Validation loss: 2.5368287204414286

Epoch: 6| Step: 9
Training loss: 2.119593620300293
Validation loss: 2.5426236121885237

Epoch: 6| Step: 10
Training loss: 2.693021535873413
Validation loss: 2.539123450556109

Epoch: 6| Step: 11
Training loss: 2.7359395027160645
Validation loss: 2.5369330759971374

Epoch: 6| Step: 12
Training loss: 4.251771450042725
Validation loss: 2.541570714724961

Epoch: 6| Step: 13
Training loss: 2.139437437057495
Validation loss: 2.5351266886598323

Epoch: 70| Step: 0
Training loss: 2.8377163410186768
Validation loss: 2.5283521990622244

Epoch: 6| Step: 1
Training loss: 2.1147589683532715
Validation loss: 2.5315596236977527

Epoch: 6| Step: 2
Training loss: 1.4661850929260254
Validation loss: 2.527189277833508

Epoch: 6| Step: 3
Training loss: 3.158611536026001
Validation loss: 2.527351910068143

Epoch: 6| Step: 4
Training loss: 2.4534454345703125
Validation loss: 2.5379985468361967

Epoch: 6| Step: 5
Training loss: 3.083012104034424
Validation loss: 2.541386230017549

Epoch: 6| Step: 6
Training loss: 2.7263143062591553
Validation loss: 2.5488879924179404

Epoch: 6| Step: 7
Training loss: 3.426605463027954
Validation loss: 2.5529753956743466

Epoch: 6| Step: 8
Training loss: 3.3406875133514404
Validation loss: 2.5527642285952004

Epoch: 6| Step: 9
Training loss: 2.3380002975463867
Validation loss: 2.545737456249934

Epoch: 6| Step: 10
Training loss: 2.6217689514160156
Validation loss: 2.541631196134834

Epoch: 6| Step: 11
Training loss: 3.3473281860351562
Validation loss: 2.5384293384449457

Epoch: 6| Step: 12
Training loss: 2.3706276416778564
Validation loss: 2.5315953582845707

Epoch: 6| Step: 13
Training loss: 3.235750913619995
Validation loss: 2.5305581374834945

Epoch: 71| Step: 0
Training loss: 2.0537304878234863
Validation loss: 2.527492615484422

Epoch: 6| Step: 1
Training loss: 3.3891141414642334
Validation loss: 2.5252302487691245

Epoch: 6| Step: 2
Training loss: 3.0040407180786133
Validation loss: 2.527916762136644

Epoch: 6| Step: 3
Training loss: 2.0722310543060303
Validation loss: 2.524721896776589

Epoch: 6| Step: 4
Training loss: 2.929037570953369
Validation loss: 2.523173742396857

Epoch: 6| Step: 5
Training loss: 3.698885679244995
Validation loss: 2.5274366512093493

Epoch: 6| Step: 6
Training loss: 1.8321034908294678
Validation loss: 2.526500568594984

Epoch: 6| Step: 7
Training loss: 2.655092239379883
Validation loss: 2.5243144035339355

Epoch: 6| Step: 8
Training loss: 2.7621283531188965
Validation loss: 2.5257116312621744

Epoch: 6| Step: 9
Training loss: 2.1492581367492676
Validation loss: 2.53381843977077

Epoch: 6| Step: 10
Training loss: 3.0443015098571777
Validation loss: 2.5410536386633433

Epoch: 6| Step: 11
Training loss: 2.815613269805908
Validation loss: 2.5412014556187454

Epoch: 6| Step: 12
Training loss: 3.070146322250366
Validation loss: 2.549645654616817

Epoch: 6| Step: 13
Training loss: 2.8854055404663086
Validation loss: 2.5444439636763705

Epoch: 72| Step: 0
Training loss: 3.342471122741699
Validation loss: 2.53846650995234

Epoch: 6| Step: 1
Training loss: 2.7119648456573486
Validation loss: 2.5347037417914278

Epoch: 6| Step: 2
Training loss: 2.222564697265625
Validation loss: 2.528776817424323

Epoch: 6| Step: 3
Training loss: 2.7445998191833496
Validation loss: 2.5268141787539244

Epoch: 6| Step: 4
Training loss: 3.230680465698242
Validation loss: 2.5337890040489937

Epoch: 6| Step: 5
Training loss: 2.1845972537994385
Validation loss: 2.5270314934433147

Epoch: 6| Step: 6
Training loss: 2.6526055335998535
Validation loss: 2.5305059340692337

Epoch: 6| Step: 7
Training loss: 2.5113308429718018
Validation loss: 2.523713129822926

Epoch: 6| Step: 8
Training loss: 2.5700087547302246
Validation loss: 2.519748226288826

Epoch: 6| Step: 9
Training loss: 2.5542027950286865
Validation loss: 2.522302153289959

Epoch: 6| Step: 10
Training loss: 3.060302734375
Validation loss: 2.5188175606471237

Epoch: 6| Step: 11
Training loss: 3.379035711288452
Validation loss: 2.5218693722960768

Epoch: 6| Step: 12
Training loss: 2.436279058456421
Validation loss: 2.519933413433772

Epoch: 6| Step: 13
Training loss: 2.5173749923706055
Validation loss: 2.519693964271135

Epoch: 73| Step: 0
Training loss: 2.5870120525360107
Validation loss: 2.518989186133108

Epoch: 6| Step: 1
Training loss: 2.162832736968994
Validation loss: 2.521880844587921

Epoch: 6| Step: 2
Training loss: 2.743816375732422
Validation loss: 2.518847716751919

Epoch: 6| Step: 3
Training loss: 2.5844125747680664
Validation loss: 2.5270995375930623

Epoch: 6| Step: 4
Training loss: 2.2458691596984863
Validation loss: 2.527882432424894

Epoch: 6| Step: 5
Training loss: 3.184634208679199
Validation loss: 2.5267727298121296

Epoch: 6| Step: 6
Training loss: 2.614863634109497
Validation loss: 2.526609646376743

Epoch: 6| Step: 7
Training loss: 3.5588219165802
Validation loss: 2.533041020875336

Epoch: 6| Step: 8
Training loss: 2.7973337173461914
Validation loss: 2.5279226456919024

Epoch: 6| Step: 9
Training loss: 2.3635337352752686
Validation loss: 2.525362489044025

Epoch: 6| Step: 10
Training loss: 2.8553967475891113
Validation loss: 2.5269260585948987

Epoch: 6| Step: 11
Training loss: 3.1025285720825195
Validation loss: 2.5232377436853226

Epoch: 6| Step: 12
Training loss: 2.6935949325561523
Validation loss: 2.522349957496889

Epoch: 6| Step: 13
Training loss: 2.7165465354919434
Validation loss: 2.5231615240855882

Epoch: 74| Step: 0
Training loss: 3.507162570953369
Validation loss: 2.5180678290705525

Epoch: 6| Step: 1
Training loss: 2.6710100173950195
Validation loss: 2.516996124739288

Epoch: 6| Step: 2
Training loss: 2.3683629035949707
Validation loss: 2.5187390260798956

Epoch: 6| Step: 3
Training loss: 2.834534168243408
Validation loss: 2.518201945930399

Epoch: 6| Step: 4
Training loss: 2.435590982437134
Validation loss: 2.5178483429775445

Epoch: 6| Step: 5
Training loss: 2.6718740463256836
Validation loss: 2.5212780147470455

Epoch: 6| Step: 6
Training loss: 2.713019371032715
Validation loss: 2.527299424653412

Epoch: 6| Step: 7
Training loss: 3.007047653198242
Validation loss: 2.5297344218018236

Epoch: 6| Step: 8
Training loss: 2.062002420425415
Validation loss: 2.5278596057686755

Epoch: 6| Step: 9
Training loss: 2.8631720542907715
Validation loss: 2.5228315348266275

Epoch: 6| Step: 10
Training loss: 2.2230727672576904
Validation loss: 2.521285846669187

Epoch: 6| Step: 11
Training loss: 3.1534857749938965
Validation loss: 2.5168687835816415

Epoch: 6| Step: 12
Training loss: 3.169713020324707
Validation loss: 2.512601431979928

Epoch: 6| Step: 13
Training loss: 2.3050155639648438
Validation loss: 2.5135466821732058

Epoch: 75| Step: 0
Training loss: 2.973888635635376
Validation loss: 2.5154083723663003

Epoch: 6| Step: 1
Training loss: 2.9668190479278564
Validation loss: 2.5149830208029798

Epoch: 6| Step: 2
Training loss: 1.8566991090774536
Validation loss: 2.5158069979759956

Epoch: 6| Step: 3
Training loss: 3.54773211479187
Validation loss: 2.5166396376907185

Epoch: 6| Step: 4
Training loss: 3.3487067222595215
Validation loss: 2.5161370551714333

Epoch: 6| Step: 5
Training loss: 2.5432775020599365
Validation loss: 2.517435489162322

Epoch: 6| Step: 6
Training loss: 2.753856658935547
Validation loss: 2.519968330219228

Epoch: 6| Step: 7
Training loss: 2.494671583175659
Validation loss: 2.52869011253439

Epoch: 6| Step: 8
Training loss: 3.0843958854675293
Validation loss: 2.536197441880421

Epoch: 6| Step: 9
Training loss: 3.0998611450195312
Validation loss: 2.5439707361241823

Epoch: 6| Step: 10
Training loss: 2.134340763092041
Validation loss: 2.544890183274464

Epoch: 6| Step: 11
Training loss: 2.4562220573425293
Validation loss: 2.5293987284424486

Epoch: 6| Step: 12
Training loss: 2.4496164321899414
Validation loss: 2.521670359437184

Epoch: 6| Step: 13
Training loss: 2.256887912750244
Validation loss: 2.5139864080695697

Epoch: 76| Step: 0
Training loss: 2.024771213531494
Validation loss: 2.5140960934341594

Epoch: 6| Step: 1
Training loss: 2.68976092338562
Validation loss: 2.5112805802335023

Epoch: 6| Step: 2
Training loss: 2.4259188175201416
Validation loss: 2.513636271158854

Epoch: 6| Step: 3
Training loss: 3.3899965286254883
Validation loss: 2.515927355776551

Epoch: 6| Step: 4
Training loss: 2.6638803482055664
Validation loss: 2.509893842922744

Epoch: 6| Step: 5
Training loss: 2.283787727355957
Validation loss: 2.511250526674332

Epoch: 6| Step: 6
Training loss: 2.9459125995635986
Validation loss: 2.5141309640740834

Epoch: 6| Step: 7
Training loss: 2.6928348541259766
Validation loss: 2.5140911635532173

Epoch: 6| Step: 8
Training loss: 3.138601064682007
Validation loss: 2.5204843116062943

Epoch: 6| Step: 9
Training loss: 2.8119471073150635
Validation loss: 2.5238546068950365

Epoch: 6| Step: 10
Training loss: 2.4054670333862305
Validation loss: 2.5230717864087833

Epoch: 6| Step: 11
Training loss: 2.4386415481567383
Validation loss: 2.528176002604987

Epoch: 6| Step: 12
Training loss: 3.26265287399292
Validation loss: 2.5136005852812078

Epoch: 6| Step: 13
Training loss: 3.133650541305542
Validation loss: 2.5147289153068297

Epoch: 77| Step: 0
Training loss: 2.9699692726135254
Validation loss: 2.5098036002087336

Epoch: 6| Step: 1
Training loss: 3.057042360305786
Validation loss: 2.5153792442814

Epoch: 6| Step: 2
Training loss: 2.829833745956421
Validation loss: 2.518081339456702

Epoch: 6| Step: 3
Training loss: 2.022507667541504
Validation loss: 2.509433105427732

Epoch: 6| Step: 4
Training loss: 2.850766181945801
Validation loss: 2.513520607384302

Epoch: 6| Step: 5
Training loss: 3.7498559951782227
Validation loss: 2.509597927011469

Epoch: 6| Step: 6
Training loss: 2.913203716278076
Validation loss: 2.5077692257460726

Epoch: 6| Step: 7
Training loss: 2.5246081352233887
Validation loss: 2.508988736778177

Epoch: 6| Step: 8
Training loss: 2.6966326236724854
Validation loss: 2.5116746835811163

Epoch: 6| Step: 9
Training loss: 2.6838817596435547
Validation loss: 2.5140834418676232

Epoch: 6| Step: 10
Training loss: 2.910855293273926
Validation loss: 2.5129339618067585

Epoch: 6| Step: 11
Training loss: 2.025071620941162
Validation loss: 2.5113096109000583

Epoch: 6| Step: 12
Training loss: 1.9514086246490479
Validation loss: 2.511986304354924

Epoch: 6| Step: 13
Training loss: 3.1059677600860596
Validation loss: 2.5130967632416756

Epoch: 78| Step: 0
Training loss: 1.9719700813293457
Validation loss: 2.511039585195562

Epoch: 6| Step: 1
Training loss: 2.1500167846679688
Validation loss: 2.512548415891586

Epoch: 6| Step: 2
Training loss: 2.7322189807891846
Validation loss: 2.5190494009243545

Epoch: 6| Step: 3
Training loss: 2.26064395904541
Validation loss: 2.5135962552921747

Epoch: 6| Step: 4
Training loss: 3.601531505584717
Validation loss: 2.517136278972831

Epoch: 6| Step: 5
Training loss: 3.278515338897705
Validation loss: 2.517716110393565

Epoch: 6| Step: 6
Training loss: 2.8624401092529297
Validation loss: 2.521558787233086

Epoch: 6| Step: 7
Training loss: 3.2619431018829346
Validation loss: 2.52164093653361

Epoch: 6| Step: 8
Training loss: 2.7596023082733154
Validation loss: 2.5288374398344304

Epoch: 6| Step: 9
Training loss: 2.5537190437316895
Validation loss: 2.5220478119388705

Epoch: 6| Step: 10
Training loss: 2.8661391735076904
Validation loss: 2.517332923027777

Epoch: 6| Step: 11
Training loss: 2.143927574157715
Validation loss: 2.50843112186719

Epoch: 6| Step: 12
Training loss: 3.0373311042785645
Validation loss: 2.502738557836061

Epoch: 6| Step: 13
Training loss: 2.508822441101074
Validation loss: 2.5022797481988066

Epoch: 79| Step: 0
Training loss: 2.1037497520446777
Validation loss: 2.5061102913271998

Epoch: 6| Step: 1
Training loss: 2.8178062438964844
Validation loss: 2.5069099472415064

Epoch: 6| Step: 2
Training loss: 3.181131601333618
Validation loss: 2.505729385601577

Epoch: 6| Step: 3
Training loss: 2.8738603591918945
Validation loss: 2.507753256828554

Epoch: 6| Step: 4
Training loss: 2.8362441062927246
Validation loss: 2.501539707183838

Epoch: 6| Step: 5
Training loss: 3.1425347328186035
Validation loss: 2.5059751695202244

Epoch: 6| Step: 6
Training loss: 3.912308692932129
Validation loss: 2.506197647381854

Epoch: 6| Step: 7
Training loss: 2.4769368171691895
Validation loss: 2.502494460792952

Epoch: 6| Step: 8
Training loss: 2.653770923614502
Validation loss: 2.5011846737195085

Epoch: 6| Step: 9
Training loss: 2.3202033042907715
Validation loss: 2.5022884415042017

Epoch: 6| Step: 10
Training loss: 2.1826956272125244
Validation loss: 2.5042885452188473

Epoch: 6| Step: 11
Training loss: 2.4763052463531494
Validation loss: 2.505569406735

Epoch: 6| Step: 12
Training loss: 2.575029134750366
Validation loss: 2.5074838361432477

Epoch: 6| Step: 13
Training loss: 2.2519328594207764
Validation loss: 2.500094641921341

Epoch: 80| Step: 0
Training loss: 2.8316197395324707
Validation loss: 2.500090801587669

Epoch: 6| Step: 1
Training loss: 3.1480655670166016
Validation loss: 2.5055296395414617

Epoch: 6| Step: 2
Training loss: 2.416243314743042
Validation loss: 2.5080287123239167

Epoch: 6| Step: 3
Training loss: 1.8015714883804321
Validation loss: 2.5021785971938924

Epoch: 6| Step: 4
Training loss: 2.0149784088134766
Validation loss: 2.503189371478173

Epoch: 6| Step: 5
Training loss: 2.073086977005005
Validation loss: 2.5024141752591698

Epoch: 6| Step: 6
Training loss: 3.7120490074157715
Validation loss: 2.505451362620118

Epoch: 6| Step: 7
Training loss: 2.797542095184326
Validation loss: 2.5039365471050306

Epoch: 6| Step: 8
Training loss: 3.0176658630371094
Validation loss: 2.5047979893222934

Epoch: 6| Step: 9
Training loss: 2.347754716873169
Validation loss: 2.502986290121591

Epoch: 6| Step: 10
Training loss: 3.207576274871826
Validation loss: 2.5017132554002988

Epoch: 6| Step: 11
Training loss: 2.7157483100891113
Validation loss: 2.5079608296835296

Epoch: 6| Step: 12
Training loss: 2.9253745079040527
Validation loss: 2.5106632068593013

Epoch: 6| Step: 13
Training loss: 3.0007734298706055
Validation loss: 2.511155289988364

Epoch: 81| Step: 0
Training loss: 2.5025172233581543
Validation loss: 2.5143026844147713

Epoch: 6| Step: 1
Training loss: 2.6468160152435303
Validation loss: 2.5074618811248452

Epoch: 6| Step: 2
Training loss: 1.623882532119751
Validation loss: 2.506312354918449

Epoch: 6| Step: 3
Training loss: 2.563257932662964
Validation loss: 2.501447562248476

Epoch: 6| Step: 4
Training loss: 3.1755170822143555
Validation loss: 2.4961803087624173

Epoch: 6| Step: 5
Training loss: 3.1897168159484863
Validation loss: 2.4993533601043043

Epoch: 6| Step: 6
Training loss: 2.461655616760254
Validation loss: 2.499103407705984

Epoch: 6| Step: 7
Training loss: 1.3032417297363281
Validation loss: 2.4943233484862954

Epoch: 6| Step: 8
Training loss: 3.3560118675231934
Validation loss: 2.499993916480772

Epoch: 6| Step: 9
Training loss: 2.5798380374908447
Validation loss: 2.498573128895093

Epoch: 6| Step: 10
Training loss: 3.907954216003418
Validation loss: 2.501259967844973

Epoch: 6| Step: 11
Training loss: 2.574934959411621
Validation loss: 2.4988301748870523

Epoch: 6| Step: 12
Training loss: 3.0205206871032715
Validation loss: 2.4937669974501415

Epoch: 6| Step: 13
Training loss: 3.343371868133545
Validation loss: 2.4973146966708604

Epoch: 82| Step: 0
Training loss: 2.66171932220459
Validation loss: 2.495711993145686

Epoch: 6| Step: 1
Training loss: 2.550509452819824
Validation loss: 2.4939891317839264

Epoch: 6| Step: 2
Training loss: 3.2528932094573975
Validation loss: 2.497811817353772

Epoch: 6| Step: 3
Training loss: 2.166006088256836
Validation loss: 2.500955681647024

Epoch: 6| Step: 4
Training loss: 2.3973679542541504
Validation loss: 2.500218145308956

Epoch: 6| Step: 5
Training loss: 2.4742279052734375
Validation loss: 2.5025496021393807

Epoch: 6| Step: 6
Training loss: 3.274083137512207
Validation loss: 2.4996789937378256

Epoch: 6| Step: 7
Training loss: 2.7288403511047363
Validation loss: 2.4970411075058805

Epoch: 6| Step: 8
Training loss: 2.2674014568328857
Validation loss: 2.497755273695915

Epoch: 6| Step: 9
Training loss: 2.562100887298584
Validation loss: 2.494652896799067

Epoch: 6| Step: 10
Training loss: 3.006096839904785
Validation loss: 2.499647355848743

Epoch: 6| Step: 11
Training loss: 3.4778685569763184
Validation loss: 2.4996894034006263

Epoch: 6| Step: 12
Training loss: 2.151111125946045
Validation loss: 2.504391562554144

Epoch: 6| Step: 13
Training loss: 3.080348014831543
Validation loss: 2.5109261261519564

Epoch: 83| Step: 0
Training loss: 2.5618884563446045
Validation loss: 2.507283062063238

Epoch: 6| Step: 1
Training loss: 1.9865678548812866
Validation loss: 2.4959458612626597

Epoch: 6| Step: 2
Training loss: 2.767780065536499
Validation loss: 2.4929430113043836

Epoch: 6| Step: 3
Training loss: 2.9977774620056152
Validation loss: 2.497897658296811

Epoch: 6| Step: 4
Training loss: 3.4258947372436523
Validation loss: 2.5009034282417706

Epoch: 6| Step: 5
Training loss: 2.5044641494750977
Validation loss: 2.509588356940977

Epoch: 6| Step: 6
Training loss: 3.212853193283081
Validation loss: 2.5186550130126295

Epoch: 6| Step: 7
Training loss: 3.2177586555480957
Validation loss: 2.511037959847399

Epoch: 6| Step: 8
Training loss: 1.9109888076782227
Validation loss: 2.51383876287809

Epoch: 6| Step: 9
Training loss: 2.1825008392333984
Validation loss: 2.5202847475646646

Epoch: 6| Step: 10
Training loss: 2.7873878479003906
Validation loss: 2.5289728692782822

Epoch: 6| Step: 11
Training loss: 3.053619861602783
Validation loss: 2.5395731285054195

Epoch: 6| Step: 12
Training loss: 2.7739474773406982
Validation loss: 2.5297143843866166

Epoch: 6| Step: 13
Training loss: 2.670349597930908
Validation loss: 2.5321488098431657

Epoch: 84| Step: 0
Training loss: 2.6097970008850098
Validation loss: 2.5247553599778043

Epoch: 6| Step: 1
Training loss: 3.0938825607299805
Validation loss: 2.5123108048592844

Epoch: 6| Step: 2
Training loss: 2.8427481651306152
Validation loss: 2.5101498865312144

Epoch: 6| Step: 3
Training loss: 2.043816089630127
Validation loss: 2.49730561881937

Epoch: 6| Step: 4
Training loss: 3.1805338859558105
Validation loss: 2.502685995512111

Epoch: 6| Step: 5
Training loss: 2.7720465660095215
Validation loss: 2.491963283990019

Epoch: 6| Step: 6
Training loss: 3.1439626216888428
Validation loss: 2.4894548769920104

Epoch: 6| Step: 7
Training loss: 2.303159713745117
Validation loss: 2.4869075821292017

Epoch: 6| Step: 8
Training loss: 3.111495018005371
Validation loss: 2.4891474400797198

Epoch: 6| Step: 9
Training loss: 2.7612037658691406
Validation loss: 2.48820561234669

Epoch: 6| Step: 10
Training loss: 2.7095046043395996
Validation loss: 2.4887366166678806

Epoch: 6| Step: 11
Training loss: 2.720762014389038
Validation loss: 2.4866388049176944

Epoch: 6| Step: 12
Training loss: 2.564162492752075
Validation loss: 2.486599317160986

Epoch: 6| Step: 13
Training loss: 1.5960688591003418
Validation loss: 2.486515701458018

Epoch: 85| Step: 0
Training loss: 1.788077712059021
Validation loss: 2.48791834615892

Epoch: 6| Step: 1
Training loss: 2.8993186950683594
Validation loss: 2.495572582367928

Epoch: 6| Step: 2
Training loss: 2.733682155609131
Validation loss: 2.489594505679223

Epoch: 6| Step: 3
Training loss: 2.4837541580200195
Validation loss: 2.48902436225645

Epoch: 6| Step: 4
Training loss: 3.023629903793335
Validation loss: 2.4889052580761653

Epoch: 6| Step: 5
Training loss: 3.0237913131713867
Validation loss: 2.4890968773954656

Epoch: 6| Step: 6
Training loss: 2.632988452911377
Validation loss: 2.4873578266430925

Epoch: 6| Step: 7
Training loss: 2.77558970451355
Validation loss: 2.4902548713068806

Epoch: 6| Step: 8
Training loss: 3.138751745223999
Validation loss: 2.4924287629383866

Epoch: 6| Step: 9
Training loss: 2.7828924655914307
Validation loss: 2.485608629001084

Epoch: 6| Step: 10
Training loss: 2.873725414276123
Validation loss: 2.496068560948936

Epoch: 6| Step: 11
Training loss: 2.7620954513549805
Validation loss: 2.5012540483987458

Epoch: 6| Step: 12
Training loss: 2.519976854324341
Validation loss: 2.5097771921465473

Epoch: 6| Step: 13
Training loss: 2.07574200630188
Validation loss: 2.5193666463257163

Epoch: 86| Step: 0
Training loss: 3.3155465126037598
Validation loss: 2.5325413775700394

Epoch: 6| Step: 1
Training loss: 2.2861697673797607
Validation loss: 2.539289482178227

Epoch: 6| Step: 2
Training loss: 2.8603880405426025
Validation loss: 2.5262630780537925

Epoch: 6| Step: 3
Training loss: 3.365447998046875
Validation loss: 2.5147934831598753

Epoch: 6| Step: 4
Training loss: 1.9501652717590332
Validation loss: 2.503491393981441

Epoch: 6| Step: 5
Training loss: 2.669816255569458
Validation loss: 2.4995325714029293

Epoch: 6| Step: 6
Training loss: 2.5298171043395996
Validation loss: 2.498569619271063

Epoch: 6| Step: 7
Training loss: 2.9961774349212646
Validation loss: 2.5023273268053607

Epoch: 6| Step: 8
Training loss: 2.9186811447143555
Validation loss: 2.514530711276557

Epoch: 6| Step: 9
Training loss: 2.6045618057250977
Validation loss: 2.51736480446272

Epoch: 6| Step: 10
Training loss: 2.1472554206848145
Validation loss: 2.516949389570503

Epoch: 6| Step: 11
Training loss: 2.9345974922180176
Validation loss: 2.518226282570952

Epoch: 6| Step: 12
Training loss: 2.7024688720703125
Validation loss: 2.5140644632359987

Epoch: 6| Step: 13
Training loss: 2.5905773639678955
Validation loss: 2.5014478173307193

Epoch: 87| Step: 0
Training loss: 2.3208861351013184
Validation loss: 2.4948894439205045

Epoch: 6| Step: 1
Training loss: 3.1621181964874268
Validation loss: 2.4926196721292313

Epoch: 6| Step: 2
Training loss: 3.2570831775665283
Validation loss: 2.496071187398767

Epoch: 6| Step: 3
Training loss: 3.187467575073242
Validation loss: 2.4927665495103404

Epoch: 6| Step: 4
Training loss: 2.6728057861328125
Validation loss: 2.4944444830699632

Epoch: 6| Step: 5
Training loss: 2.292074203491211
Validation loss: 2.485556019249783

Epoch: 6| Step: 6
Training loss: 2.474133014678955
Validation loss: 2.48759784237031

Epoch: 6| Step: 7
Training loss: 2.8852572441101074
Validation loss: 2.490302478113482

Epoch: 6| Step: 8
Training loss: 2.7022886276245117
Validation loss: 2.48482116576164

Epoch: 6| Step: 9
Training loss: 2.4255247116088867
Validation loss: 2.4862238514807915

Epoch: 6| Step: 10
Training loss: 2.6575069427490234
Validation loss: 2.4845304053316832

Epoch: 6| Step: 11
Training loss: 2.594313859939575
Validation loss: 2.4840402449330976

Epoch: 6| Step: 12
Training loss: 2.7689952850341797
Validation loss: 2.4898704251935406

Epoch: 6| Step: 13
Training loss: 2.330953359603882
Validation loss: 2.48125200117788

Epoch: 88| Step: 0
Training loss: 2.4270057678222656
Validation loss: 2.487202964803224

Epoch: 6| Step: 1
Training loss: 2.128108263015747
Validation loss: 2.48918907360364

Epoch: 6| Step: 2
Training loss: 2.7290995121002197
Validation loss: 2.4879084684515513

Epoch: 6| Step: 3
Training loss: 3.2250874042510986
Validation loss: 2.488010004002561

Epoch: 6| Step: 4
Training loss: 2.966343879699707
Validation loss: 2.4919263739739694

Epoch: 6| Step: 5
Training loss: 1.8957982063293457
Validation loss: 2.4963609480088755

Epoch: 6| Step: 6
Training loss: 2.7696330547332764
Validation loss: 2.4974114177047566

Epoch: 6| Step: 7
Training loss: 2.974199056625366
Validation loss: 2.5053581345465874

Epoch: 6| Step: 8
Training loss: 3.298598051071167
Validation loss: 2.501022823395268

Epoch: 6| Step: 9
Training loss: 2.4851632118225098
Validation loss: 2.494560162226359

Epoch: 6| Step: 10
Training loss: 1.8729016780853271
Validation loss: 2.494317739240585

Epoch: 6| Step: 11
Training loss: 2.753002405166626
Validation loss: 2.484766252579228

Epoch: 6| Step: 12
Training loss: 3.000962972640991
Validation loss: 2.485010413713353

Epoch: 6| Step: 13
Training loss: 3.6337764263153076
Validation loss: 2.482081059486635

Epoch: 89| Step: 0
Training loss: 2.6841325759887695
Validation loss: 2.482900668216008

Epoch: 6| Step: 1
Training loss: 2.7864575386047363
Validation loss: 2.4829309499391945

Epoch: 6| Step: 2
Training loss: 2.541722297668457
Validation loss: 2.4843880079125844

Epoch: 6| Step: 3
Training loss: 1.7952568531036377
Validation loss: 2.486515232311782

Epoch: 6| Step: 4
Training loss: 3.8719255924224854
Validation loss: 2.4940967047086327

Epoch: 6| Step: 5
Training loss: 2.733942985534668
Validation loss: 2.500815808132131

Epoch: 6| Step: 6
Training loss: 2.6830286979675293
Validation loss: 2.5085423454161613

Epoch: 6| Step: 7
Training loss: 2.9905571937561035
Validation loss: 2.4998200555001535

Epoch: 6| Step: 8
Training loss: 2.486799478530884
Validation loss: 2.4948875545173563

Epoch: 6| Step: 9
Training loss: 2.893869400024414
Validation loss: 2.4834481029100317

Epoch: 6| Step: 10
Training loss: 2.2899906635284424
Validation loss: 2.4862773700426986

Epoch: 6| Step: 11
Training loss: 2.26078462600708
Validation loss: 2.479740519677439

Epoch: 6| Step: 12
Training loss: 3.132484197616577
Validation loss: 2.482013522937734

Epoch: 6| Step: 13
Training loss: 2.6596460342407227
Validation loss: 2.480034110366657

Epoch: 90| Step: 0
Training loss: 2.355527877807617
Validation loss: 2.479568196881202

Epoch: 6| Step: 1
Training loss: 2.6425938606262207
Validation loss: 2.49064955916456

Epoch: 6| Step: 2
Training loss: 2.53110408782959
Validation loss: 2.4904772107319166

Epoch: 6| Step: 3
Training loss: 2.8704848289489746
Validation loss: 2.491423829909294

Epoch: 6| Step: 4
Training loss: 2.7285947799682617
Validation loss: 2.4975424479412776

Epoch: 6| Step: 5
Training loss: 3.1472983360290527
Validation loss: 2.4932826616430797

Epoch: 6| Step: 6
Training loss: 3.525552988052368
Validation loss: 2.4891473016431256

Epoch: 6| Step: 7
Training loss: 2.630704879760742
Validation loss: 2.4867242946419665

Epoch: 6| Step: 8
Training loss: 2.937587022781372
Validation loss: 2.4857842358209754

Epoch: 6| Step: 9
Training loss: 2.1944949626922607
Validation loss: 2.4856232161163003

Epoch: 6| Step: 10
Training loss: 2.115309000015259
Validation loss: 2.4846339841042795

Epoch: 6| Step: 11
Training loss: 3.391754627227783
Validation loss: 2.4792524512096117

Epoch: 6| Step: 12
Training loss: 2.0364418029785156
Validation loss: 2.487970377809258

Epoch: 6| Step: 13
Training loss: 2.625241279602051
Validation loss: 2.4839187052942093

Epoch: 91| Step: 0
Training loss: 3.3145155906677246
Validation loss: 2.4795407428536365

Epoch: 6| Step: 1
Training loss: 3.216327667236328
Validation loss: 2.4847759226317048

Epoch: 6| Step: 2
Training loss: 2.583904266357422
Validation loss: 2.491077192368046

Epoch: 6| Step: 3
Training loss: 1.9642716646194458
Validation loss: 2.4944961635015344

Epoch: 6| Step: 4
Training loss: 2.4803686141967773
Validation loss: 2.4874574061362975

Epoch: 6| Step: 5
Training loss: 2.253643035888672
Validation loss: 2.492887960967197

Epoch: 6| Step: 6
Training loss: 2.92036509513855
Validation loss: 2.4922971725463867

Epoch: 6| Step: 7
Training loss: 2.3561689853668213
Validation loss: 2.494670832028953

Epoch: 6| Step: 8
Training loss: 2.111546516418457
Validation loss: 2.501210794653944

Epoch: 6| Step: 9
Training loss: 2.823129653930664
Validation loss: 2.505466643200126

Epoch: 6| Step: 10
Training loss: 3.399766683578491
Validation loss: 2.4989879438954015

Epoch: 6| Step: 11
Training loss: 2.6856164932250977
Validation loss: 2.505547361989175

Epoch: 6| Step: 12
Training loss: 2.872065544128418
Validation loss: 2.502073064927132

Epoch: 6| Step: 13
Training loss: 2.844109058380127
Validation loss: 2.5005325963420253

Epoch: 92| Step: 0
Training loss: 2.6222457885742188
Validation loss: 2.501277603128905

Epoch: 6| Step: 1
Training loss: 2.4353907108306885
Validation loss: 2.491183978255077

Epoch: 6| Step: 2
Training loss: 3.257514476776123
Validation loss: 2.4876937430392028

Epoch: 6| Step: 3
Training loss: 2.8294687271118164
Validation loss: 2.483251876728509

Epoch: 6| Step: 4
Training loss: 2.7750113010406494
Validation loss: 2.475990444101313

Epoch: 6| Step: 5
Training loss: 2.333554267883301
Validation loss: 2.475895643234253

Epoch: 6| Step: 6
Training loss: 2.621643304824829
Validation loss: 2.4716240770073346

Epoch: 6| Step: 7
Training loss: 2.6917340755462646
Validation loss: 2.4690470003312632

Epoch: 6| Step: 8
Training loss: 2.8429133892059326
Validation loss: 2.4724557989387104

Epoch: 6| Step: 9
Training loss: 2.6952154636383057
Validation loss: 2.4669050375620523

Epoch: 6| Step: 10
Training loss: 2.8514981269836426
Validation loss: 2.4758957355253157

Epoch: 6| Step: 11
Training loss: 2.1422252655029297
Validation loss: 2.475776885145454

Epoch: 6| Step: 12
Training loss: 2.9476497173309326
Validation loss: 2.4725841399162047

Epoch: 6| Step: 13
Training loss: 2.602069854736328
Validation loss: 2.473848646686923

Epoch: 93| Step: 0
Training loss: 2.8998842239379883
Validation loss: 2.479674611040341

Epoch: 6| Step: 1
Training loss: 3.6324992179870605
Validation loss: 2.4734065301956667

Epoch: 6| Step: 2
Training loss: 2.478125810623169
Validation loss: 2.4706707616006174

Epoch: 6| Step: 3
Training loss: 2.2926127910614014
Validation loss: 2.4707995947971138

Epoch: 6| Step: 4
Training loss: 3.293463706970215
Validation loss: 2.4853237931446364

Epoch: 6| Step: 5
Training loss: 2.4321389198303223
Validation loss: 2.4850504141981884

Epoch: 6| Step: 6
Training loss: 3.047989845275879
Validation loss: 2.494006810649749

Epoch: 6| Step: 7
Training loss: 2.184455633163452
Validation loss: 2.493292418859338

Epoch: 6| Step: 8
Training loss: 2.791872978210449
Validation loss: 2.4852601456385788

Epoch: 6| Step: 9
Training loss: 2.0788626670837402
Validation loss: 2.477117551270352

Epoch: 6| Step: 10
Training loss: 2.81717586517334
Validation loss: 2.4785200036982054

Epoch: 6| Step: 11
Training loss: 2.1609537601470947
Validation loss: 2.478276143791855

Epoch: 6| Step: 12
Training loss: 2.8431358337402344
Validation loss: 2.478895797524401

Epoch: 6| Step: 13
Training loss: 2.603245735168457
Validation loss: 2.4820161891239945

Epoch: 94| Step: 0
Training loss: 2.3374850749969482
Validation loss: 2.480551855538481

Epoch: 6| Step: 1
Training loss: 2.2777438163757324
Validation loss: 2.474035229734195

Epoch: 6| Step: 2
Training loss: 2.5061748027801514
Validation loss: 2.479846680036155

Epoch: 6| Step: 3
Training loss: 3.1490018367767334
Validation loss: 2.465663412565826

Epoch: 6| Step: 4
Training loss: 2.2887635231018066
Validation loss: 2.467177552561606

Epoch: 6| Step: 5
Training loss: 2.054471969604492
Validation loss: 2.466620317069433

Epoch: 6| Step: 6
Training loss: 3.424435615539551
Validation loss: 2.463479979063875

Epoch: 6| Step: 7
Training loss: 2.412900924682617
Validation loss: 2.4661454949327695

Epoch: 6| Step: 8
Training loss: 3.188325881958008
Validation loss: 2.4617901104752735

Epoch: 6| Step: 9
Training loss: 2.6533889770507812
Validation loss: 2.4636673081305718

Epoch: 6| Step: 10
Training loss: 2.3804214000701904
Validation loss: 2.462031715659685

Epoch: 6| Step: 11
Training loss: 2.940908432006836
Validation loss: 2.463421760066863

Epoch: 6| Step: 12
Training loss: 3.2160558700561523
Validation loss: 2.4662659193879817

Epoch: 6| Step: 13
Training loss: 2.673393726348877
Validation loss: 2.471532260217974

Epoch: 95| Step: 0
Training loss: 2.662065029144287
Validation loss: 2.4774933143328597

Epoch: 6| Step: 1
Training loss: 2.6511714458465576
Validation loss: 2.491792389141616

Epoch: 6| Step: 2
Training loss: 2.4886090755462646
Validation loss: 2.4939495491725143

Epoch: 6| Step: 3
Training loss: 1.8327195644378662
Validation loss: 2.5130792510124946

Epoch: 6| Step: 4
Training loss: 3.9156265258789062
Validation loss: 2.5006648289260043

Epoch: 6| Step: 5
Training loss: 3.00260329246521
Validation loss: 2.499799341283819

Epoch: 6| Step: 6
Training loss: 2.525601387023926
Validation loss: 2.504621046845631

Epoch: 6| Step: 7
Training loss: 2.7483973503112793
Validation loss: 2.4980629926086753

Epoch: 6| Step: 8
Training loss: 2.7596535682678223
Validation loss: 2.487558372559086

Epoch: 6| Step: 9
Training loss: 3.2702808380126953
Validation loss: 2.4878750770322737

Epoch: 6| Step: 10
Training loss: 2.4626576900482178
Validation loss: 2.4787476665230206

Epoch: 6| Step: 11
Training loss: 2.1318788528442383
Validation loss: 2.474037736974737

Epoch: 6| Step: 12
Training loss: 3.3419806957244873
Validation loss: 2.46920193395307

Epoch: 6| Step: 13
Training loss: 1.1974444389343262
Validation loss: 2.4653615131173083

Epoch: 96| Step: 0
Training loss: 3.6269140243530273
Validation loss: 2.469590620328021

Epoch: 6| Step: 1
Training loss: 2.3278555870056152
Validation loss: 2.468725840250651

Epoch: 6| Step: 2
Training loss: 2.9355082511901855
Validation loss: 2.4713174476418445

Epoch: 6| Step: 3
Training loss: 2.5467734336853027
Validation loss: 2.475594505187004

Epoch: 6| Step: 4
Training loss: 3.1386311054229736
Validation loss: 2.4711842357471423

Epoch: 6| Step: 5
Training loss: 1.8222352266311646
Validation loss: 2.471223064648208

Epoch: 6| Step: 6
Training loss: 3.1794962882995605
Validation loss: 2.4637879402406755

Epoch: 6| Step: 7
Training loss: 2.1836159229278564
Validation loss: 2.4642927903001026

Epoch: 6| Step: 8
Training loss: 2.6298272609710693
Validation loss: 2.465058790740146

Epoch: 6| Step: 9
Training loss: 2.449629068374634
Validation loss: 2.473925047023322

Epoch: 6| Step: 10
Training loss: 2.391721487045288
Validation loss: 2.466718868542743

Epoch: 6| Step: 11
Training loss: 2.7323129177093506
Validation loss: 2.4730060472283313

Epoch: 6| Step: 12
Training loss: 2.891425132751465
Validation loss: 2.469350927619524

Epoch: 6| Step: 13
Training loss: 2.65054988861084
Validation loss: 2.477488345997308

Epoch: 97| Step: 0
Training loss: 2.6409220695495605
Validation loss: 2.494868355412637

Epoch: 6| Step: 1
Training loss: 2.7454261779785156
Validation loss: 2.49766436699898

Epoch: 6| Step: 2
Training loss: 1.9364826679229736
Validation loss: 2.5093137371924614

Epoch: 6| Step: 3
Training loss: 2.659231185913086
Validation loss: 2.5102680960009174

Epoch: 6| Step: 4
Training loss: 3.7672667503356934
Validation loss: 2.530680710269559

Epoch: 6| Step: 5
Training loss: 2.4389820098876953
Validation loss: 2.539697044639177

Epoch: 6| Step: 6
Training loss: 2.3316712379455566
Validation loss: 2.5211911868023615

Epoch: 6| Step: 7
Training loss: 2.744384288787842
Validation loss: 2.5053026599268757

Epoch: 6| Step: 8
Training loss: 2.750610589981079
Validation loss: 2.5048396177189325

Epoch: 6| Step: 9
Training loss: 2.108370304107666
Validation loss: 2.486754584056075

Epoch: 6| Step: 10
Training loss: 2.3194408416748047
Validation loss: 2.484719343082879

Epoch: 6| Step: 11
Training loss: 3.0875234603881836
Validation loss: 2.4792042111837738

Epoch: 6| Step: 12
Training loss: 3.2250099182128906
Validation loss: 2.4775791450213362

Epoch: 6| Step: 13
Training loss: 3.1162924766540527
Validation loss: 2.4752191599979194

Epoch: 98| Step: 0
Training loss: 3.2571053504943848
Validation loss: 2.4747356830104703

Epoch: 6| Step: 1
Training loss: 2.3013153076171875
Validation loss: 2.476787292829124

Epoch: 6| Step: 2
Training loss: 2.7317378520965576
Validation loss: 2.4763418884687525

Epoch: 6| Step: 3
Training loss: 2.3954596519470215
Validation loss: 2.477870087469778

Epoch: 6| Step: 4
Training loss: 2.666698932647705
Validation loss: 2.481539367347635

Epoch: 6| Step: 5
Training loss: 2.6095924377441406
Validation loss: 2.476822514687815

Epoch: 6| Step: 6
Training loss: 2.3471860885620117
Validation loss: 2.476687685135872

Epoch: 6| Step: 7
Training loss: 2.4416511058807373
Validation loss: 2.4728563318970385

Epoch: 6| Step: 8
Training loss: 3.194504737854004
Validation loss: 2.4773794912522837

Epoch: 6| Step: 9
Training loss: 2.3022475242614746
Validation loss: 2.477029149250318

Epoch: 6| Step: 10
Training loss: 3.0319457054138184
Validation loss: 2.4865303347187657

Epoch: 6| Step: 11
Training loss: 2.336129903793335
Validation loss: 2.493502634827809

Epoch: 6| Step: 12
Training loss: 3.4791016578674316
Validation loss: 2.478881843628422

Epoch: 6| Step: 13
Training loss: 2.297745704650879
Validation loss: 2.46683193022205

Epoch: 99| Step: 0
Training loss: 1.9957568645477295
Validation loss: 2.461529561268386

Epoch: 6| Step: 1
Training loss: 3.3029255867004395
Validation loss: 2.459585443619759

Epoch: 6| Step: 2
Training loss: 1.9223382472991943
Validation loss: 2.4536987120105374

Epoch: 6| Step: 3
Training loss: 3.1640372276306152
Validation loss: 2.4513266394215245

Epoch: 6| Step: 4
Training loss: 2.9165217876434326
Validation loss: 2.456054602899859

Epoch: 6| Step: 5
Training loss: 2.619513511657715
Validation loss: 2.4564574174983527

Epoch: 6| Step: 6
Training loss: 2.9263224601745605
Validation loss: 2.457201603920229

Epoch: 6| Step: 7
Training loss: 3.505589485168457
Validation loss: 2.4558597303205922

Epoch: 6| Step: 8
Training loss: 1.9568458795547485
Validation loss: 2.4540723703240834

Epoch: 6| Step: 9
Training loss: 2.42396879196167
Validation loss: 2.454472916100615

Epoch: 6| Step: 10
Training loss: 2.6721205711364746
Validation loss: 2.4597804187446513

Epoch: 6| Step: 11
Training loss: 1.9167261123657227
Validation loss: 2.4675653467896166

Epoch: 6| Step: 12
Training loss: 3.1294431686401367
Validation loss: 2.473605530236357

Epoch: 6| Step: 13
Training loss: 3.300236463546753
Validation loss: 2.4728183848883516

Epoch: 100| Step: 0
Training loss: 2.5405542850494385
Validation loss: 2.466324396030877

Epoch: 6| Step: 1
Training loss: 2.512906789779663
Validation loss: 2.472186998654437

Epoch: 6| Step: 2
Training loss: 3.8456289768218994
Validation loss: 2.463115474229218

Epoch: 6| Step: 3
Training loss: 2.8725786209106445
Validation loss: 2.466285997821439

Epoch: 6| Step: 4
Training loss: 3.2888708114624023
Validation loss: 2.46089147239603

Epoch: 6| Step: 5
Training loss: 3.155333995819092
Validation loss: 2.4520520856303554

Epoch: 6| Step: 6
Training loss: 2.6761367321014404
Validation loss: 2.450927183192263

Epoch: 6| Step: 7
Training loss: 2.189112663269043
Validation loss: 2.4474920431772866

Epoch: 6| Step: 8
Training loss: 1.8392587900161743
Validation loss: 2.450772157279394

Epoch: 6| Step: 9
Training loss: 2.990687370300293
Validation loss: 2.4418076481870425

Epoch: 6| Step: 10
Training loss: 1.7520389556884766
Validation loss: 2.445972555427141

Epoch: 6| Step: 11
Training loss: 2.635039806365967
Validation loss: 2.460705964796005

Epoch: 6| Step: 12
Training loss: 2.369114637374878
Validation loss: 2.4542081843140306

Epoch: 6| Step: 13
Training loss: 2.8539273738861084
Validation loss: 2.4616496486048542

Epoch: 101| Step: 0
Training loss: 2.517775297164917
Validation loss: 2.4520906068945445

Epoch: 6| Step: 1
Training loss: 2.462198257446289
Validation loss: 2.457967153159521

Epoch: 6| Step: 2
Training loss: 2.4738943576812744
Validation loss: 2.453072022366267

Epoch: 6| Step: 3
Training loss: 2.533031463623047
Validation loss: 2.452888047823342

Epoch: 6| Step: 4
Training loss: 1.7226824760437012
Validation loss: 2.4554512693035986

Epoch: 6| Step: 5
Training loss: 2.5119216442108154
Validation loss: 2.453570783779185

Epoch: 6| Step: 6
Training loss: 3.367985725402832
Validation loss: 2.4532074825738066

Epoch: 6| Step: 7
Training loss: 2.661384105682373
Validation loss: 2.457485621975314

Epoch: 6| Step: 8
Training loss: 2.414163112640381
Validation loss: 2.4541874572794926

Epoch: 6| Step: 9
Training loss: 3.3158459663391113
Validation loss: 2.454303713255031

Epoch: 6| Step: 10
Training loss: 2.6855039596557617
Validation loss: 2.458231891355207

Epoch: 6| Step: 11
Training loss: 2.620441198348999
Validation loss: 2.446426304437781

Epoch: 6| Step: 12
Training loss: 3.140174627304077
Validation loss: 2.4517433079340125

Epoch: 6| Step: 13
Training loss: 3.17757511138916
Validation loss: 2.4511630996581046

Epoch: 102| Step: 0
Training loss: 2.680488109588623
Validation loss: 2.4508179746648318

Epoch: 6| Step: 1
Training loss: 2.118711471557617
Validation loss: 2.4468220356971986

Epoch: 6| Step: 2
Training loss: 3.206185817718506
Validation loss: 2.443014385879681

Epoch: 6| Step: 3
Training loss: 2.821786403656006
Validation loss: 2.4453526235395864

Epoch: 6| Step: 4
Training loss: 2.706033229827881
Validation loss: 2.4545643175801923

Epoch: 6| Step: 5
Training loss: 2.2599024772644043
Validation loss: 2.439140289060531

Epoch: 6| Step: 6
Training loss: 3.2937114238739014
Validation loss: 2.4395390274704143

Epoch: 6| Step: 7
Training loss: 2.33771014213562
Validation loss: 2.44022205568129

Epoch: 6| Step: 8
Training loss: 2.382108211517334
Validation loss: 2.438000766179895

Epoch: 6| Step: 9
Training loss: 2.088353157043457
Validation loss: 2.4410033751559514

Epoch: 6| Step: 10
Training loss: 3.0752267837524414
Validation loss: 2.4435484204241025

Epoch: 6| Step: 11
Training loss: 2.5224170684814453
Validation loss: 2.4471527068845687

Epoch: 6| Step: 12
Training loss: 2.9310355186462402
Validation loss: 2.4458312091007026

Epoch: 6| Step: 13
Training loss: 3.3795204162597656
Validation loss: 2.449626091987856

Epoch: 103| Step: 0
Training loss: 2.833265781402588
Validation loss: 2.4473250758263374

Epoch: 6| Step: 1
Training loss: 2.825758457183838
Validation loss: 2.438837548737885

Epoch: 6| Step: 2
Training loss: 3.5290818214416504
Validation loss: 2.444238534537695

Epoch: 6| Step: 3
Training loss: 2.2871150970458984
Validation loss: 2.454935537871494

Epoch: 6| Step: 4
Training loss: 2.095837116241455
Validation loss: 2.4558810239197104

Epoch: 6| Step: 5
Training loss: 2.5610039234161377
Validation loss: 2.4625366759556595

Epoch: 6| Step: 6
Training loss: 2.6160993576049805
Validation loss: 2.465100198663691

Epoch: 6| Step: 7
Training loss: 1.9795281887054443
Validation loss: 2.4780000307226695

Epoch: 6| Step: 8
Training loss: 2.3065593242645264
Validation loss: 2.470440172380017

Epoch: 6| Step: 9
Training loss: 3.541769504547119
Validation loss: 2.473480196409328

Epoch: 6| Step: 10
Training loss: 3.376084804534912
Validation loss: 2.46598308573487

Epoch: 6| Step: 11
Training loss: 2.536944627761841
Validation loss: 2.459140746824203

Epoch: 6| Step: 12
Training loss: 2.2590720653533936
Validation loss: 2.457046180643061

Epoch: 6| Step: 13
Training loss: 2.926579475402832
Validation loss: 2.4489987716879895

Epoch: 104| Step: 0
Training loss: 3.5465617179870605
Validation loss: 2.4401844368186048

Epoch: 6| Step: 1
Training loss: 2.643674850463867
Validation loss: 2.44064526660468

Epoch: 6| Step: 2
Training loss: 2.7193453311920166
Validation loss: 2.4416880710150606

Epoch: 6| Step: 3
Training loss: 2.403848171234131
Validation loss: 2.443076418292138

Epoch: 6| Step: 4
Training loss: 2.723909854888916
Validation loss: 2.4399146213326404

Epoch: 6| Step: 5
Training loss: 2.371051073074341
Validation loss: 2.4435436366706766

Epoch: 6| Step: 6
Training loss: 2.3884968757629395
Validation loss: 2.4380230621625016

Epoch: 6| Step: 7
Training loss: 2.5443363189697266
Validation loss: 2.4492351521727858

Epoch: 6| Step: 8
Training loss: 2.8211889266967773
Validation loss: 2.4580393811707855

Epoch: 6| Step: 9
Training loss: 2.6370749473571777
Validation loss: 2.4534482494477303

Epoch: 6| Step: 10
Training loss: 2.1593306064605713
Validation loss: 2.4527682540237263

Epoch: 6| Step: 11
Training loss: 3.220215320587158
Validation loss: 2.4478232655473935

Epoch: 6| Step: 12
Training loss: 2.5064122676849365
Validation loss: 2.4328127317531134

Epoch: 6| Step: 13
Training loss: 2.5815908908843994
Validation loss: 2.432658104486363

Epoch: 105| Step: 0
Training loss: 2.1806392669677734
Validation loss: 2.4375311251609557

Epoch: 6| Step: 1
Training loss: 2.0866472721099854
Validation loss: 2.4452252900728615

Epoch: 6| Step: 2
Training loss: 3.3415074348449707
Validation loss: 2.441835872588619

Epoch: 6| Step: 3
Training loss: 2.1349146366119385
Validation loss: 2.4445701799085064

Epoch: 6| Step: 4
Training loss: 3.100614547729492
Validation loss: 2.443540667974821

Epoch: 6| Step: 5
Training loss: 3.3440089225769043
Validation loss: 2.439314644823792

Epoch: 6| Step: 6
Training loss: 2.6561942100524902
Validation loss: 2.441779790386077

Epoch: 6| Step: 7
Training loss: 2.9826953411102295
Validation loss: 2.436876009869319

Epoch: 6| Step: 8
Training loss: 2.6633541584014893
Validation loss: 2.43270811470606

Epoch: 6| Step: 9
Training loss: 2.714278221130371
Validation loss: 2.4322026416819584

Epoch: 6| Step: 10
Training loss: 2.797492027282715
Validation loss: 2.4350840942834013

Epoch: 6| Step: 11
Training loss: 3.0967421531677246
Validation loss: 2.4401005955152613

Epoch: 6| Step: 12
Training loss: 2.266813278198242
Validation loss: 2.4463297602950886

Epoch: 6| Step: 13
Training loss: 1.5702877044677734
Validation loss: 2.4512222223384406

Epoch: 106| Step: 0
Training loss: 3.0169243812561035
Validation loss: 2.463900371264386

Epoch: 6| Step: 1
Training loss: 3.636366128921509
Validation loss: 2.46072357316171

Epoch: 6| Step: 2
Training loss: 2.282301425933838
Validation loss: 2.468444590927452

Epoch: 6| Step: 3
Training loss: 2.1589150428771973
Validation loss: 2.4905993989718858

Epoch: 6| Step: 4
Training loss: 2.181553602218628
Validation loss: 2.4758692787539576

Epoch: 6| Step: 5
Training loss: 2.3701648712158203
Validation loss: 2.4708525647399244

Epoch: 6| Step: 6
Training loss: 2.388030529022217
Validation loss: 2.4543429190112698

Epoch: 6| Step: 7
Training loss: 2.8968234062194824
Validation loss: 2.4529193473118607

Epoch: 6| Step: 8
Training loss: 1.853119969367981
Validation loss: 2.444651752389887

Epoch: 6| Step: 9
Training loss: 2.018859386444092
Validation loss: 2.4342412820426365

Epoch: 6| Step: 10
Training loss: 3.7329862117767334
Validation loss: 2.4382379542114916

Epoch: 6| Step: 11
Training loss: 2.595977783203125
Validation loss: 2.4361718316232004

Epoch: 6| Step: 12
Training loss: 2.847689628601074
Validation loss: 2.438766405146609

Epoch: 6| Step: 13
Training loss: 3.9947526454925537
Validation loss: 2.4389167190879903

Epoch: 107| Step: 0
Training loss: 3.2917559146881104
Validation loss: 2.4472512647669804

Epoch: 6| Step: 1
Training loss: 1.967972755432129
Validation loss: 2.447514703196864

Epoch: 6| Step: 2
Training loss: 2.5059256553649902
Validation loss: 2.453235582638812

Epoch: 6| Step: 3
Training loss: 2.8427321910858154
Validation loss: 2.4515138415880102

Epoch: 6| Step: 4
Training loss: 2.8199610710144043
Validation loss: 2.4535660615531345

Epoch: 6| Step: 5
Training loss: 2.973538875579834
Validation loss: 2.4432866957879837

Epoch: 6| Step: 6
Training loss: 2.587721824645996
Validation loss: 2.435843485657887

Epoch: 6| Step: 7
Training loss: 2.3500986099243164
Validation loss: 2.427993469340827

Epoch: 6| Step: 8
Training loss: 2.596440315246582
Validation loss: 2.425291743329776

Epoch: 6| Step: 9
Training loss: 2.3457016944885254
Validation loss: 2.4273099745473554

Epoch: 6| Step: 10
Training loss: 2.2230947017669678
Validation loss: 2.4250964374952417

Epoch: 6| Step: 11
Training loss: 2.4470479488372803
Validation loss: 2.425193380284053

Epoch: 6| Step: 12
Training loss: 3.3384275436401367
Validation loss: 2.423729237689767

Epoch: 6| Step: 13
Training loss: 3.0361344814300537
Validation loss: 2.4233628601156254

Epoch: 108| Step: 0
Training loss: 2.5023539066314697
Validation loss: 2.426670241099532

Epoch: 6| Step: 1
Training loss: 2.1161019802093506
Validation loss: 2.429505576369583

Epoch: 6| Step: 2
Training loss: 3.2264223098754883
Validation loss: 2.4407468124102523

Epoch: 6| Step: 3
Training loss: 3.964195489883423
Validation loss: 2.451029803163262

Epoch: 6| Step: 4
Training loss: 2.728440523147583
Validation loss: 2.4537423400468725

Epoch: 6| Step: 5
Training loss: 2.2366414070129395
Validation loss: 2.4417951914571945

Epoch: 6| Step: 6
Training loss: 2.927095413208008
Validation loss: 2.448912866653935

Epoch: 6| Step: 7
Training loss: 2.210153341293335
Validation loss: 2.439341418204769

Epoch: 6| Step: 8
Training loss: 2.7019362449645996
Validation loss: 2.4317174829462522

Epoch: 6| Step: 9
Training loss: 2.8795082569122314
Validation loss: 2.4225401801447712

Epoch: 6| Step: 10
Training loss: 2.5468201637268066
Validation loss: 2.428788815775225

Epoch: 6| Step: 11
Training loss: 2.211874008178711
Validation loss: 2.426328189911381

Epoch: 6| Step: 12
Training loss: 2.3701822757720947
Validation loss: 2.432421935501919

Epoch: 6| Step: 13
Training loss: 2.709939479827881
Validation loss: 2.437032148402224

Epoch: 109| Step: 0
Training loss: 2.5271098613739014
Validation loss: 2.4321418731443343

Epoch: 6| Step: 1
Training loss: 2.428448438644409
Validation loss: 2.4354766876466813

Epoch: 6| Step: 2
Training loss: 2.211949110031128
Validation loss: 2.4349383551587342

Epoch: 6| Step: 3
Training loss: 2.5856728553771973
Validation loss: 2.4360455492491364

Epoch: 6| Step: 4
Training loss: 3.77587890625
Validation loss: 2.442066723300565

Epoch: 6| Step: 5
Training loss: 1.515758752822876
Validation loss: 2.45017764388874

Epoch: 6| Step: 6
Training loss: 3.258199691772461
Validation loss: 2.450943923765613

Epoch: 6| Step: 7
Training loss: 2.567124366760254
Validation loss: 2.454655385786487

Epoch: 6| Step: 8
Training loss: 2.508046865463257
Validation loss: 2.452665259761195

Epoch: 6| Step: 9
Training loss: 1.8344130516052246
Validation loss: 2.455825844118672

Epoch: 6| Step: 10
Training loss: 2.8038368225097656
Validation loss: 2.4535487313424387

Epoch: 6| Step: 11
Training loss: 3.1502573490142822
Validation loss: 2.4434827502055834

Epoch: 6| Step: 12
Training loss: 2.9527640342712402
Validation loss: 2.432613188220609

Epoch: 6| Step: 13
Training loss: 3.537856101989746
Validation loss: 2.4240311935383785

Epoch: 110| Step: 0
Training loss: 2.474801540374756
Validation loss: 2.4262683160843386

Epoch: 6| Step: 1
Training loss: 3.332301378250122
Validation loss: 2.4339629245060745

Epoch: 6| Step: 2
Training loss: 1.6450706720352173
Validation loss: 2.4391200850086827

Epoch: 6| Step: 3
Training loss: 3.1926870346069336
Validation loss: 2.4345451401126

Epoch: 6| Step: 4
Training loss: 2.166609764099121
Validation loss: 2.441146186603013

Epoch: 6| Step: 5
Training loss: 3.1744699478149414
Validation loss: 2.445709469497845

Epoch: 6| Step: 6
Training loss: 2.485409736633301
Validation loss: 2.4506570267420944

Epoch: 6| Step: 7
Training loss: 1.5255839824676514
Validation loss: 2.4496339521100445

Epoch: 6| Step: 8
Training loss: 3.0723342895507812
Validation loss: 2.4476350686883412

Epoch: 6| Step: 9
Training loss: 3.2260942459106445
Validation loss: 2.4368218106608235

Epoch: 6| Step: 10
Training loss: 2.9019277095794678
Validation loss: 2.435319810785273

Epoch: 6| Step: 11
Training loss: 2.705634832382202
Validation loss: 2.433117538370112

Epoch: 6| Step: 12
Training loss: 2.5891013145446777
Validation loss: 2.4262703875059723

Epoch: 6| Step: 13
Training loss: 2.821293354034424
Validation loss: 2.4190777232570033

Epoch: 111| Step: 0
Training loss: 2.0114991664886475
Validation loss: 2.41757716414749

Epoch: 6| Step: 1
Training loss: 1.9280178546905518
Validation loss: 2.418564240137736

Epoch: 6| Step: 2
Training loss: 3.1696457862854004
Validation loss: 2.415656215401106

Epoch: 6| Step: 3
Training loss: 2.1466779708862305
Validation loss: 2.4178699190898607

Epoch: 6| Step: 4
Training loss: 2.4128518104553223
Validation loss: 2.4195304968023814

Epoch: 6| Step: 5
Training loss: 2.6626181602478027
Validation loss: 2.42600590695617

Epoch: 6| Step: 6
Training loss: 2.6869285106658936
Validation loss: 2.4241548110080022

Epoch: 6| Step: 7
Training loss: 2.3470187187194824
Validation loss: 2.426434019560455

Epoch: 6| Step: 8
Training loss: 2.6073267459869385
Validation loss: 2.4342262360357467

Epoch: 6| Step: 9
Training loss: 2.882551670074463
Validation loss: 2.4315503771587084

Epoch: 6| Step: 10
Training loss: 3.4447035789489746
Validation loss: 2.434390342363747

Epoch: 6| Step: 11
Training loss: 3.0031650066375732
Validation loss: 2.4352662063414052

Epoch: 6| Step: 12
Training loss: 2.4265711307525635
Validation loss: 2.434688689888165

Epoch: 6| Step: 13
Training loss: 3.9200363159179688
Validation loss: 2.438213356079594

Epoch: 112| Step: 0
Training loss: 2.545083999633789
Validation loss: 2.4374836362818235

Epoch: 6| Step: 1
Training loss: 2.85624361038208
Validation loss: 2.4385048625289754

Epoch: 6| Step: 2
Training loss: 1.9597779512405396
Validation loss: 2.4433353331781205

Epoch: 6| Step: 3
Training loss: 2.8927087783813477
Validation loss: 2.4544064485898582

Epoch: 6| Step: 4
Training loss: 2.769702911376953
Validation loss: 2.455095843602252

Epoch: 6| Step: 5
Training loss: 2.514763355255127
Validation loss: 2.4567520080074186

Epoch: 6| Step: 6
Training loss: 2.1557700634002686
Validation loss: 2.4482727717327815

Epoch: 6| Step: 7
Training loss: 2.9332265853881836
Validation loss: 2.446594612572783

Epoch: 6| Step: 8
Training loss: 3.5355823040008545
Validation loss: 2.439751422533425

Epoch: 6| Step: 9
Training loss: 3.0918819904327393
Validation loss: 2.435063405703473

Epoch: 6| Step: 10
Training loss: 2.545989513397217
Validation loss: 2.429419171425604

Epoch: 6| Step: 11
Training loss: 2.414515495300293
Validation loss: 2.42225541094298

Epoch: 6| Step: 12
Training loss: 2.8978240489959717
Validation loss: 2.4199489572996735

Epoch: 6| Step: 13
Training loss: 1.8887609243392944
Validation loss: 2.4181241322589178

Epoch: 113| Step: 0
Training loss: 2.095533847808838
Validation loss: 2.4226659472270677

Epoch: 6| Step: 1
Training loss: 2.5971107482910156
Validation loss: 2.4145391730852026

Epoch: 6| Step: 2
Training loss: 2.7599401473999023
Validation loss: 2.4206659665671726

Epoch: 6| Step: 3
Training loss: 2.2910351753234863
Validation loss: 2.4231414846194688

Epoch: 6| Step: 4
Training loss: 2.9179201126098633
Validation loss: 2.421514008634834

Epoch: 6| Step: 5
Training loss: 3.1895742416381836
Validation loss: 2.42046852906545

Epoch: 6| Step: 6
Training loss: 2.712164878845215
Validation loss: 2.423577916237616

Epoch: 6| Step: 7
Training loss: 2.675290584564209
Validation loss: 2.423554366634738

Epoch: 6| Step: 8
Training loss: 2.4658236503601074
Validation loss: 2.4247574267848844

Epoch: 6| Step: 9
Training loss: 2.89815616607666
Validation loss: 2.4271446915083033

Epoch: 6| Step: 10
Training loss: 2.64412522315979
Validation loss: 2.4422961229919107

Epoch: 6| Step: 11
Training loss: 2.714710235595703
Validation loss: 2.435658565131567

Epoch: 6| Step: 12
Training loss: 2.2327287197113037
Validation loss: 2.4360040746709353

Epoch: 6| Step: 13
Training loss: 3.081848382949829
Validation loss: 2.4432432087518836

Epoch: 114| Step: 0
Training loss: 3.197216510772705
Validation loss: 2.4523279436172976

Epoch: 6| Step: 1
Training loss: 2.8650989532470703
Validation loss: 2.44799369124956

Epoch: 6| Step: 2
Training loss: 2.77954363822937
Validation loss: 2.447876512363393

Epoch: 6| Step: 3
Training loss: 3.145359992980957
Validation loss: 2.444687904850129

Epoch: 6| Step: 4
Training loss: 2.623137950897217
Validation loss: 2.4461022192432034

Epoch: 6| Step: 5
Training loss: 2.497316598892212
Validation loss: 2.4280391841806392

Epoch: 6| Step: 6
Training loss: 2.6383888721466064
Validation loss: 2.4331636608287854

Epoch: 6| Step: 7
Training loss: 3.5934228897094727
Validation loss: 2.428797565480714

Epoch: 6| Step: 8
Training loss: 2.7388129234313965
Validation loss: 2.4192302303929485

Epoch: 6| Step: 9
Training loss: 1.7148174047470093
Validation loss: 2.4251999816586896

Epoch: 6| Step: 10
Training loss: 2.687757968902588
Validation loss: 2.418901556281633

Epoch: 6| Step: 11
Training loss: 2.323523998260498
Validation loss: 2.4180607282987205

Epoch: 6| Step: 12
Training loss: 1.9267463684082031
Validation loss: 2.4117607711463847

Epoch: 6| Step: 13
Training loss: 2.028761863708496
Validation loss: 2.4179777817059587

Epoch: 115| Step: 0
Training loss: 2.643562078475952
Validation loss: 2.4175396427031486

Epoch: 6| Step: 1
Training loss: 3.296952247619629
Validation loss: 2.428306628299016

Epoch: 6| Step: 2
Training loss: 1.87890625
Validation loss: 2.4311805719970376

Epoch: 6| Step: 3
Training loss: 2.809974193572998
Validation loss: 2.4376270668480986

Epoch: 6| Step: 4
Training loss: 2.943722724914551
Validation loss: 2.4407951549817155

Epoch: 6| Step: 5
Training loss: 2.989751100540161
Validation loss: 2.4355376433300715

Epoch: 6| Step: 6
Training loss: 2.6209633350372314
Validation loss: 2.4348660053745395

Epoch: 6| Step: 7
Training loss: 2.234278917312622
Validation loss: 2.4333719079212477

Epoch: 6| Step: 8
Training loss: 2.71389102935791
Validation loss: 2.4234322578676286

Epoch: 6| Step: 9
Training loss: 2.5270795822143555
Validation loss: 2.4145111704385407

Epoch: 6| Step: 10
Training loss: 2.4664344787597656
Validation loss: 2.4123117487917662

Epoch: 6| Step: 11
Training loss: 3.0352623462677
Validation loss: 2.412566784889467

Epoch: 6| Step: 12
Training loss: 2.608304262161255
Validation loss: 2.4095476878586637

Epoch: 6| Step: 13
Training loss: 1.9699066877365112
Validation loss: 2.4113686674384662

Epoch: 116| Step: 0
Training loss: 3.065589427947998
Validation loss: 2.408933870254024

Epoch: 6| Step: 1
Training loss: 2.8679239749908447
Validation loss: 2.407721104160432

Epoch: 6| Step: 2
Training loss: 2.502598762512207
Validation loss: 2.413271701464089

Epoch: 6| Step: 3
Training loss: 2.882415771484375
Validation loss: 2.415401984286565

Epoch: 6| Step: 4
Training loss: 3.1246304512023926
Validation loss: 2.418993144906977

Epoch: 6| Step: 5
Training loss: 2.8911499977111816
Validation loss: 2.420161188289683

Epoch: 6| Step: 6
Training loss: 2.25193452835083
Validation loss: 2.421089554345736

Epoch: 6| Step: 7
Training loss: 2.072093963623047
Validation loss: 2.4264450021969375

Epoch: 6| Step: 8
Training loss: 1.572929859161377
Validation loss: 2.424126540460894

Epoch: 6| Step: 9
Training loss: 2.994755506515503
Validation loss: 2.436440465270832

Epoch: 6| Step: 10
Training loss: 2.96024227142334
Validation loss: 2.4350163116249988

Epoch: 6| Step: 11
Training loss: 1.8221471309661865
Validation loss: 2.4466416041056314

Epoch: 6| Step: 12
Training loss: 2.8812899589538574
Validation loss: 2.453637435872068

Epoch: 6| Step: 13
Training loss: 3.4543800354003906
Validation loss: 2.448575263382286

Epoch: 117| Step: 0
Training loss: 3.2383604049682617
Validation loss: 2.4578296740849814

Epoch: 6| Step: 1
Training loss: 2.47052001953125
Validation loss: 2.476467793987643

Epoch: 6| Step: 2
Training loss: 2.8886048793792725
Validation loss: 2.4785347856501097

Epoch: 6| Step: 3
Training loss: 2.8162755966186523
Validation loss: 2.4719431605390323

Epoch: 6| Step: 4
Training loss: 2.1519882678985596
Validation loss: 2.4657560112655803

Epoch: 6| Step: 5
Training loss: 2.197045087814331
Validation loss: 2.4509424804359354

Epoch: 6| Step: 6
Training loss: 3.027881622314453
Validation loss: 2.4403489289745206

Epoch: 6| Step: 7
Training loss: 3.3988447189331055
Validation loss: 2.4248401247045046

Epoch: 6| Step: 8
Training loss: 3.1629178524017334
Validation loss: 2.419833888289749

Epoch: 6| Step: 9
Training loss: 2.7338809967041016
Validation loss: 2.4095657512705815

Epoch: 6| Step: 10
Training loss: 2.45198655128479
Validation loss: 2.4057314934269076

Epoch: 6| Step: 11
Training loss: 1.925898551940918
Validation loss: 2.407041677864649

Epoch: 6| Step: 12
Training loss: 2.902031898498535
Validation loss: 2.407942489911151

Epoch: 6| Step: 13
Training loss: 1.3187416791915894
Validation loss: 2.408375104268392

Epoch: 118| Step: 0
Training loss: 3.1407878398895264
Validation loss: 2.410822453037385

Epoch: 6| Step: 1
Training loss: 2.1550865173339844
Validation loss: 2.4172245174325924

Epoch: 6| Step: 2
Training loss: 2.549272298812866
Validation loss: 2.416786486102689

Epoch: 6| Step: 3
Training loss: 2.5640969276428223
Validation loss: 2.417263454006564

Epoch: 6| Step: 4
Training loss: 2.6238489151000977
Validation loss: 2.4161243925812426

Epoch: 6| Step: 5
Training loss: 2.7472798824310303
Validation loss: 2.4223903289405246

Epoch: 6| Step: 6
Training loss: 2.1269774436950684
Validation loss: 2.4214768819911505

Epoch: 6| Step: 7
Training loss: 2.546916961669922
Validation loss: 2.417067030424713

Epoch: 6| Step: 8
Training loss: 3.7161483764648438
Validation loss: 2.414720940333541

Epoch: 6| Step: 9
Training loss: 1.8850510120391846
Validation loss: 2.415454283837349

Epoch: 6| Step: 10
Training loss: 3.0807113647460938
Validation loss: 2.4209382405845066

Epoch: 6| Step: 11
Training loss: 3.153430461883545
Validation loss: 2.4169215258731636

Epoch: 6| Step: 12
Training loss: 2.108748197555542
Validation loss: 2.426932114426808

Epoch: 6| Step: 13
Training loss: 2.766583204269409
Validation loss: 2.4248348718048423

Epoch: 119| Step: 0
Training loss: 2.0402626991271973
Validation loss: 2.425284465154012

Epoch: 6| Step: 1
Training loss: 1.7962818145751953
Validation loss: 2.4158365521379697

Epoch: 6| Step: 2
Training loss: 2.9421334266662598
Validation loss: 2.424498524717105

Epoch: 6| Step: 3
Training loss: 2.9826245307922363
Validation loss: 2.420828104019165

Epoch: 6| Step: 4
Training loss: 2.370684862136841
Validation loss: 2.417177615627166

Epoch: 6| Step: 5
Training loss: 2.752868413925171
Validation loss: 2.4104387888344387

Epoch: 6| Step: 6
Training loss: 2.408482789993286
Validation loss: 2.408573140380203

Epoch: 6| Step: 7
Training loss: 3.504624366760254
Validation loss: 2.4056361170225244

Epoch: 6| Step: 8
Training loss: 2.8394393920898438
Validation loss: 2.410628452095934

Epoch: 6| Step: 9
Training loss: 2.1130895614624023
Validation loss: 2.4103336295773907

Epoch: 6| Step: 10
Training loss: 2.5534534454345703
Validation loss: 2.404191258133099

Epoch: 6| Step: 11
Training loss: 2.45180082321167
Validation loss: 2.411580890737554

Epoch: 6| Step: 12
Training loss: 3.3461594581604004
Validation loss: 2.4074101524968303

Epoch: 6| Step: 13
Training loss: 3.1645402908325195
Validation loss: 2.408184330950501

Epoch: 120| Step: 0
Training loss: 2.268899440765381
Validation loss: 2.4105922804083875

Epoch: 6| Step: 1
Training loss: 2.210749864578247
Validation loss: 2.409831852041265

Epoch: 6| Step: 2
Training loss: 2.2889785766601562
Validation loss: 2.412758957955145

Epoch: 6| Step: 3
Training loss: 3.253333568572998
Validation loss: 2.4076195122093282

Epoch: 6| Step: 4
Training loss: 2.192694902420044
Validation loss: 2.4064165994685185

Epoch: 6| Step: 5
Training loss: 3.470327377319336
Validation loss: 2.4033080108704103

Epoch: 6| Step: 6
Training loss: 2.3627965450286865
Validation loss: 2.4069982446650022

Epoch: 6| Step: 7
Training loss: 2.6589195728302
Validation loss: 2.414317712988905

Epoch: 6| Step: 8
Training loss: 3.2548024654388428
Validation loss: 2.408707695622598

Epoch: 6| Step: 9
Training loss: 3.0214569568634033
Validation loss: 2.410020507791991

Epoch: 6| Step: 10
Training loss: 2.4014134407043457
Validation loss: 2.4123960643686275

Epoch: 6| Step: 11
Training loss: 2.8118889331817627
Validation loss: 2.4085073676160587

Epoch: 6| Step: 12
Training loss: 2.1950159072875977
Validation loss: 2.4104217713879

Epoch: 6| Step: 13
Training loss: 2.4754040241241455
Validation loss: 2.4036712928484847

Epoch: 121| Step: 0
Training loss: 3.558258056640625
Validation loss: 2.4121105722201768

Epoch: 6| Step: 1
Training loss: 2.602412223815918
Validation loss: 2.4086816823610695

Epoch: 6| Step: 2
Training loss: 2.231009006500244
Validation loss: 2.4079383650133686

Epoch: 6| Step: 3
Training loss: 2.481184482574463
Validation loss: 2.4067283548334593

Epoch: 6| Step: 4
Training loss: 1.9940859079360962
Validation loss: 2.4179854931369906

Epoch: 6| Step: 5
Training loss: 2.4517476558685303
Validation loss: 2.4145599539561937

Epoch: 6| Step: 6
Training loss: 2.9105777740478516
Validation loss: 2.422206419770436

Epoch: 6| Step: 7
Training loss: 3.0415825843811035
Validation loss: 2.427905482630576

Epoch: 6| Step: 8
Training loss: 2.2620849609375
Validation loss: 2.4274840406192246

Epoch: 6| Step: 9
Training loss: 2.2270963191986084
Validation loss: 2.431477765883169

Epoch: 6| Step: 10
Training loss: 3.2334368228912354
Validation loss: 2.4268063037626204

Epoch: 6| Step: 11
Training loss: 2.218412399291992
Validation loss: 2.4344293404650945

Epoch: 6| Step: 12
Training loss: 2.796091079711914
Validation loss: 2.434483571719098

Epoch: 6| Step: 13
Training loss: 3.065239667892456
Validation loss: 2.433469710811492

Epoch: 122| Step: 0
Training loss: 2.220215320587158
Validation loss: 2.4356568449287006

Epoch: 6| Step: 1
Training loss: 1.9488447904586792
Validation loss: 2.418458495088803

Epoch: 6| Step: 2
Training loss: 3.0354883670806885
Validation loss: 2.4166045932359594

Epoch: 6| Step: 3
Training loss: 2.4340622425079346
Validation loss: 2.424358585829376

Epoch: 6| Step: 4
Training loss: 2.6447134017944336
Validation loss: 2.4196173401289087

Epoch: 6| Step: 5
Training loss: 2.7828094959259033
Validation loss: 2.4240018295985397

Epoch: 6| Step: 6
Training loss: 2.1369264125823975
Validation loss: 2.4236067751402497

Epoch: 6| Step: 7
Training loss: 2.8777003288269043
Validation loss: 2.4169525177248063

Epoch: 6| Step: 8
Training loss: 3.0988142490386963
Validation loss: 2.423848203433457

Epoch: 6| Step: 9
Training loss: 3.518918037414551
Validation loss: 2.422346597076744

Epoch: 6| Step: 10
Training loss: 2.523145914077759
Validation loss: 2.4254261780810613

Epoch: 6| Step: 11
Training loss: 2.737988233566284
Validation loss: 2.4215668439865112

Epoch: 6| Step: 12
Training loss: 2.6125946044921875
Validation loss: 2.410783172935568

Epoch: 6| Step: 13
Training loss: 2.1023898124694824
Validation loss: 2.417253899317916

Epoch: 123| Step: 0
Training loss: 2.4613747596740723
Validation loss: 2.41626561585293

Epoch: 6| Step: 1
Training loss: 2.227809190750122
Validation loss: 2.417731423531809

Epoch: 6| Step: 2
Training loss: 2.210230827331543
Validation loss: 2.4159627242754866

Epoch: 6| Step: 3
Training loss: 2.521265745162964
Validation loss: 2.418894819034043

Epoch: 6| Step: 4
Training loss: 2.2115447521209717
Validation loss: 2.4154891993409846

Epoch: 6| Step: 5
Training loss: 2.694287061691284
Validation loss: 2.4094132018345658

Epoch: 6| Step: 6
Training loss: 2.915513277053833
Validation loss: 2.4188647911112797

Epoch: 6| Step: 7
Training loss: 2.4794540405273438
Validation loss: 2.4121627474343903

Epoch: 6| Step: 8
Training loss: 3.180907726287842
Validation loss: 2.4191300099895847

Epoch: 6| Step: 9
Training loss: 3.4639813899993896
Validation loss: 2.4145349738418416

Epoch: 6| Step: 10
Training loss: 3.009918451309204
Validation loss: 2.4082801060010026

Epoch: 6| Step: 11
Training loss: 2.4667534828186035
Validation loss: 2.4143982471958285

Epoch: 6| Step: 12
Training loss: 3.058598518371582
Validation loss: 2.4067238505168627

Epoch: 6| Step: 13
Training loss: 1.4408948421478271
Validation loss: 2.410065838085708

Epoch: 124| Step: 0
Training loss: 2.5014212131500244
Validation loss: 2.4084843768868396

Epoch: 6| Step: 1
Training loss: 2.4615983963012695
Validation loss: 2.4089453092185398

Epoch: 6| Step: 2
Training loss: 1.441811442375183
Validation loss: 2.4126675436573644

Epoch: 6| Step: 3
Training loss: 2.8319475650787354
Validation loss: 2.412751399060731

Epoch: 6| Step: 4
Training loss: 2.3292150497436523
Validation loss: 2.4131931374149937

Epoch: 6| Step: 5
Training loss: 3.243222951889038
Validation loss: 2.4168548942894064

Epoch: 6| Step: 6
Training loss: 2.489851713180542
Validation loss: 2.4136939356403966

Epoch: 6| Step: 7
Training loss: 2.6409988403320312
Validation loss: 2.415650854828537

Epoch: 6| Step: 8
Training loss: 2.8662941455841064
Validation loss: 2.4132903006768998

Epoch: 6| Step: 9
Training loss: 3.4372398853302
Validation loss: 2.4188905274996193

Epoch: 6| Step: 10
Training loss: 2.095979690551758
Validation loss: 2.413839945229151

Epoch: 6| Step: 11
Training loss: 2.675518751144409
Validation loss: 2.4204408327738443

Epoch: 6| Step: 12
Training loss: 2.93479585647583
Validation loss: 2.4077664934178835

Epoch: 6| Step: 13
Training loss: 3.1024322509765625
Validation loss: 2.4133083692160984

Epoch: 125| Step: 0
Training loss: 3.5914082527160645
Validation loss: 2.405136546780986

Epoch: 6| Step: 1
Training loss: 2.4643373489379883
Validation loss: 2.413471669279119

Epoch: 6| Step: 2
Training loss: 2.6837596893310547
Validation loss: 2.4137423602483605

Epoch: 6| Step: 3
Training loss: 2.5746207237243652
Validation loss: 2.4220159233257337

Epoch: 6| Step: 4
Training loss: 2.86942720413208
Validation loss: 2.422131884482599

Epoch: 6| Step: 5
Training loss: 2.8342723846435547
Validation loss: 2.4182695342648413

Epoch: 6| Step: 6
Training loss: 2.1633195877075195
Validation loss: 2.417849374073808

Epoch: 6| Step: 7
Training loss: 2.327005386352539
Validation loss: 2.415937690324681

Epoch: 6| Step: 8
Training loss: 2.6937906742095947
Validation loss: 2.417931831011208

Epoch: 6| Step: 9
Training loss: 2.7009670734405518
Validation loss: 2.410233853965677

Epoch: 6| Step: 10
Training loss: 2.7263176441192627
Validation loss: 2.412197389910298

Epoch: 6| Step: 11
Training loss: 2.510927438735962
Validation loss: 2.4134674636266564

Epoch: 6| Step: 12
Training loss: 2.2834911346435547
Validation loss: 2.402389016202701

Epoch: 6| Step: 13
Training loss: 2.176913261413574
Validation loss: 2.4028515251733924

Epoch: 126| Step: 0
Training loss: 2.717027187347412
Validation loss: 2.3972777602493123

Epoch: 6| Step: 1
Training loss: 1.9370882511138916
Validation loss: 2.394712471192883

Epoch: 6| Step: 2
Training loss: 2.635880470275879
Validation loss: 2.39483154460948

Epoch: 6| Step: 3
Training loss: 2.2620978355407715
Validation loss: 2.3958261397577103

Epoch: 6| Step: 4
Training loss: 2.781428337097168
Validation loss: 2.4013109066153087

Epoch: 6| Step: 5
Training loss: 2.7758097648620605
Validation loss: 2.4000747126917683

Epoch: 6| Step: 6
Training loss: 3.1206772327423096
Validation loss: 2.395289041662729

Epoch: 6| Step: 7
Training loss: 3.155653715133667
Validation loss: 2.405543388858918

Epoch: 6| Step: 8
Training loss: 2.836967945098877
Validation loss: 2.406134113188713

Epoch: 6| Step: 9
Training loss: 2.9705755710601807
Validation loss: 2.4029837013572775

Epoch: 6| Step: 10
Training loss: 3.0440385341644287
Validation loss: 2.406523137964228

Epoch: 6| Step: 11
Training loss: 1.9045073986053467
Validation loss: 2.418254893313172

Epoch: 6| Step: 12
Training loss: 1.9242545366287231
Validation loss: 2.4135546120264197

Epoch: 6| Step: 13
Training loss: 2.7918460369110107
Validation loss: 2.4144961833953857

Epoch: 127| Step: 0
Training loss: 1.604928970336914
Validation loss: 2.4128006478791595

Epoch: 6| Step: 1
Training loss: 3.1736624240875244
Validation loss: 2.4178385708921697

Epoch: 6| Step: 2
Training loss: 3.14357590675354
Validation loss: 2.4038877025727303

Epoch: 6| Step: 3
Training loss: 2.8724875450134277
Validation loss: 2.402939301665111

Epoch: 6| Step: 4
Training loss: 2.337681770324707
Validation loss: 2.4114610572015085

Epoch: 6| Step: 5
Training loss: 2.717111110687256
Validation loss: 2.4006216731122745

Epoch: 6| Step: 6
Training loss: 2.3485782146453857
Validation loss: 2.4003725513335197

Epoch: 6| Step: 7
Training loss: 1.626802682876587
Validation loss: 2.398397050878053

Epoch: 6| Step: 8
Training loss: 3.655026912689209
Validation loss: 2.3969823365570395

Epoch: 6| Step: 9
Training loss: 2.6425704956054688
Validation loss: 2.3949004091242307

Epoch: 6| Step: 10
Training loss: 2.849510908126831
Validation loss: 2.393584851295717

Epoch: 6| Step: 11
Training loss: 2.0430824756622314
Validation loss: 2.395867340026363

Epoch: 6| Step: 12
Training loss: 3.0236144065856934
Validation loss: 2.3930777119052027

Epoch: 6| Step: 13
Training loss: 2.826878070831299
Validation loss: 2.3861856614389727

Epoch: 128| Step: 0
Training loss: 2.690847635269165
Validation loss: 2.3885161799769246

Epoch: 6| Step: 1
Training loss: 2.451188564300537
Validation loss: 2.3834236155274096

Epoch: 6| Step: 2
Training loss: 2.7703709602355957
Validation loss: 2.389394744749992

Epoch: 6| Step: 3
Training loss: 2.9213409423828125
Validation loss: 2.3861195630924676

Epoch: 6| Step: 4
Training loss: 2.516664505004883
Validation loss: 2.3898858665138163

Epoch: 6| Step: 5
Training loss: 2.5615668296813965
Validation loss: 2.385234079053325

Epoch: 6| Step: 6
Training loss: 3.174767017364502
Validation loss: 2.3871925979532223

Epoch: 6| Step: 7
Training loss: 2.316065788269043
Validation loss: 2.387532582847021

Epoch: 6| Step: 8
Training loss: 2.468416690826416
Validation loss: 2.390954335530599

Epoch: 6| Step: 9
Training loss: 2.7281689643859863
Validation loss: 2.3906256204010337

Epoch: 6| Step: 10
Training loss: 2.27272367477417
Validation loss: 2.3983455447740454

Epoch: 6| Step: 11
Training loss: 2.826153516769409
Validation loss: 2.394763961915047

Epoch: 6| Step: 12
Training loss: 2.2919557094573975
Validation loss: 2.399522363498647

Epoch: 6| Step: 13
Training loss: 2.9472062587738037
Validation loss: 2.4003932552952922

Epoch: 129| Step: 0
Training loss: 2.2058911323547363
Validation loss: 2.404780669878888

Epoch: 6| Step: 1
Training loss: 1.5232794284820557
Validation loss: 2.4088899089444067

Epoch: 6| Step: 2
Training loss: 2.830949306488037
Validation loss: 2.4071647095423874

Epoch: 6| Step: 3
Training loss: 2.413175344467163
Validation loss: 2.4188122544237363

Epoch: 6| Step: 4
Training loss: 2.7959389686584473
Validation loss: 2.408830306863272

Epoch: 6| Step: 5
Training loss: 2.5018906593322754
Validation loss: 2.4345468577518257

Epoch: 6| Step: 6
Training loss: 3.167450428009033
Validation loss: 2.427629401606898

Epoch: 6| Step: 7
Training loss: 2.813559055328369
Validation loss: 2.428563348708614

Epoch: 6| Step: 8
Training loss: 2.870368003845215
Validation loss: 2.44108171104103

Epoch: 6| Step: 9
Training loss: 1.9126991033554077
Validation loss: 2.4300422796639065

Epoch: 6| Step: 10
Training loss: 3.279937982559204
Validation loss: 2.4282475133096018

Epoch: 6| Step: 11
Training loss: 2.877579689025879
Validation loss: 2.4309499699582338

Epoch: 6| Step: 12
Training loss: 2.5249016284942627
Validation loss: 2.4205476237881567

Epoch: 6| Step: 13
Training loss: 3.487260103225708
Validation loss: 2.4211720599923083

Epoch: 130| Step: 0
Training loss: 2.4372634887695312
Validation loss: 2.418734045438869

Epoch: 6| Step: 1
Training loss: 2.8359627723693848
Validation loss: 2.414526390772994

Epoch: 6| Step: 2
Training loss: 2.3035430908203125
Validation loss: 2.4021485364565285

Epoch: 6| Step: 3
Training loss: 2.6063313484191895
Validation loss: 2.397475327214887

Epoch: 6| Step: 4
Training loss: 3.3533332347869873
Validation loss: 2.394900321960449

Epoch: 6| Step: 5
Training loss: 2.944507122039795
Validation loss: 2.390434331791375

Epoch: 6| Step: 6
Training loss: 2.5144689083099365
Validation loss: 2.386938500147994

Epoch: 6| Step: 7
Training loss: 1.7346949577331543
Validation loss: 2.3844100454802155

Epoch: 6| Step: 8
Training loss: 2.4505062103271484
Validation loss: 2.3859415849049888

Epoch: 6| Step: 9
Training loss: 2.544198989868164
Validation loss: 2.3902014301669214

Epoch: 6| Step: 10
Training loss: 2.622246265411377
Validation loss: 2.397982335859729

Epoch: 6| Step: 11
Training loss: 3.1927688121795654
Validation loss: 2.39440825164959

Epoch: 6| Step: 12
Training loss: 2.8848156929016113
Validation loss: 2.402733382358346

Epoch: 6| Step: 13
Training loss: 2.186068058013916
Validation loss: 2.4030722213047806

Epoch: 131| Step: 0
Training loss: 2.8658957481384277
Validation loss: 2.407804987763846

Epoch: 6| Step: 1
Training loss: 2.7257742881774902
Validation loss: 2.421500967394921

Epoch: 6| Step: 2
Training loss: 2.4154138565063477
Validation loss: 2.4371873101880475

Epoch: 6| Step: 3
Training loss: 2.2941956520080566
Validation loss: 2.45474491324476

Epoch: 6| Step: 4
Training loss: 3.593655824661255
Validation loss: 2.468593874285298

Epoch: 6| Step: 5
Training loss: 3.1282904148101807
Validation loss: 2.468511163547475

Epoch: 6| Step: 6
Training loss: 2.085707664489746
Validation loss: 2.46046462879386

Epoch: 6| Step: 7
Training loss: 2.532771587371826
Validation loss: 2.451604193256747

Epoch: 6| Step: 8
Training loss: 2.343301773071289
Validation loss: 2.4454896039860223

Epoch: 6| Step: 9
Training loss: 2.6502785682678223
Validation loss: 2.4380131037004533

Epoch: 6| Step: 10
Training loss: 3.1526217460632324
Validation loss: 2.426609669962237

Epoch: 6| Step: 11
Training loss: 2.328031063079834
Validation loss: 2.4080661586535874

Epoch: 6| Step: 12
Training loss: 2.2968242168426514
Validation loss: 2.394803665017569

Epoch: 6| Step: 13
Training loss: 2.8098292350769043
Validation loss: 2.3887317129360732

Epoch: 132| Step: 0
Training loss: 1.8496952056884766
Validation loss: 2.3835427017622095

Epoch: 6| Step: 1
Training loss: 2.856433868408203
Validation loss: 2.3811135292053223

Epoch: 6| Step: 2
Training loss: 2.9263267517089844
Validation loss: 2.3843391915803314

Epoch: 6| Step: 3
Training loss: 2.8370378017425537
Validation loss: 2.383138938616681

Epoch: 6| Step: 4
Training loss: 2.866274118423462
Validation loss: 2.389971246001541

Epoch: 6| Step: 5
Training loss: 2.7121353149414062
Validation loss: 2.390823397585141

Epoch: 6| Step: 6
Training loss: 2.5189414024353027
Validation loss: 2.388096514568534

Epoch: 6| Step: 7
Training loss: 2.979586124420166
Validation loss: 2.387982814542709

Epoch: 6| Step: 8
Training loss: 2.4813852310180664
Validation loss: 2.38576679588646

Epoch: 6| Step: 9
Training loss: 1.793548822402954
Validation loss: 2.3904055626161638

Epoch: 6| Step: 10
Training loss: 2.216611385345459
Validation loss: 2.3862412898771224

Epoch: 6| Step: 11
Training loss: 3.016148090362549
Validation loss: 2.3826704114995976

Epoch: 6| Step: 12
Training loss: 2.747246742248535
Validation loss: 2.376737363876835

Epoch: 6| Step: 13
Training loss: 3.2759933471679688
Validation loss: 2.3778478432727117

Epoch: 133| Step: 0
Training loss: 2.1397552490234375
Validation loss: 2.378109703781784

Epoch: 6| Step: 1
Training loss: 2.997667074203491
Validation loss: 2.386345286523142

Epoch: 6| Step: 2
Training loss: 2.559947967529297
Validation loss: 2.3876155730216735

Epoch: 6| Step: 3
Training loss: 2.9356651306152344
Validation loss: 2.385071628837175

Epoch: 6| Step: 4
Training loss: 2.0988216400146484
Validation loss: 2.3836527614183325

Epoch: 6| Step: 5
Training loss: 2.5953099727630615
Validation loss: 2.3757834613964124

Epoch: 6| Step: 6
Training loss: 2.3423619270324707
Validation loss: 2.38291738622932

Epoch: 6| Step: 7
Training loss: 3.338857650756836
Validation loss: 2.3843847320925806

Epoch: 6| Step: 8
Training loss: 2.3594298362731934
Validation loss: 2.3803870549765964

Epoch: 6| Step: 9
Training loss: 2.5529425144195557
Validation loss: 2.391034164736348

Epoch: 6| Step: 10
Training loss: 2.4151268005371094
Validation loss: 2.3887415650070354

Epoch: 6| Step: 11
Training loss: 2.7359778881073
Validation loss: 2.3973563768530406

Epoch: 6| Step: 12
Training loss: 2.8102145195007324
Validation loss: 2.4005182199580695

Epoch: 6| Step: 13
Training loss: 2.9452130794525146
Validation loss: 2.401719738078374

Epoch: 134| Step: 0
Training loss: 3.140089988708496
Validation loss: 2.4085674926798832

Epoch: 6| Step: 1
Training loss: 2.613065719604492
Validation loss: 2.403251063439154

Epoch: 6| Step: 2
Training loss: 2.493152618408203
Validation loss: 2.409736784555579

Epoch: 6| Step: 3
Training loss: 2.8774430751800537
Validation loss: 2.4045803905815206

Epoch: 6| Step: 4
Training loss: 2.813079357147217
Validation loss: 2.399305582046509

Epoch: 6| Step: 5
Training loss: 1.7540173530578613
Validation loss: 2.396787626768953

Epoch: 6| Step: 6
Training loss: 2.6127395629882812
Validation loss: 2.3957998368047897

Epoch: 6| Step: 7
Training loss: 2.3972060680389404
Validation loss: 2.385976017162364

Epoch: 6| Step: 8
Training loss: 2.6538662910461426
Validation loss: 2.3846029414925525

Epoch: 6| Step: 9
Training loss: 2.190556526184082
Validation loss: 2.3787913860813266

Epoch: 6| Step: 10
Training loss: 2.6634905338287354
Validation loss: 2.3832346982853387

Epoch: 6| Step: 11
Training loss: 3.4877660274505615
Validation loss: 2.376432567514399

Epoch: 6| Step: 12
Training loss: 2.5499069690704346
Validation loss: 2.376018447260703

Epoch: 6| Step: 13
Training loss: 2.315397024154663
Validation loss: 2.3761607190614105

Epoch: 135| Step: 0
Training loss: 2.607051372528076
Validation loss: 2.372568248420633

Epoch: 6| Step: 1
Training loss: 3.090855360031128
Validation loss: 2.374236335036575

Epoch: 6| Step: 2
Training loss: 2.7894845008850098
Validation loss: 2.376429145054151

Epoch: 6| Step: 3
Training loss: 1.6507720947265625
Validation loss: 2.378544863834176

Epoch: 6| Step: 4
Training loss: 2.219078540802002
Validation loss: 2.378339439310053

Epoch: 6| Step: 5
Training loss: 3.2455086708068848
Validation loss: 2.379062109096076

Epoch: 6| Step: 6
Training loss: 2.703338146209717
Validation loss: 2.3830999610244588

Epoch: 6| Step: 7
Training loss: 2.605929374694824
Validation loss: 2.382581482651413

Epoch: 6| Step: 8
Training loss: 2.1714048385620117
Validation loss: 2.381553242283483

Epoch: 6| Step: 9
Training loss: 2.6173810958862305
Validation loss: 2.378018376647785

Epoch: 6| Step: 10
Training loss: 2.3612220287323
Validation loss: 2.3814755614085863

Epoch: 6| Step: 11
Training loss: 2.631772041320801
Validation loss: 2.3783905916316535

Epoch: 6| Step: 12
Training loss: 3.19510555267334
Validation loss: 2.3773610514979207

Epoch: 6| Step: 13
Training loss: 2.9674763679504395
Validation loss: 2.382575317095685

Epoch: 136| Step: 0
Training loss: 2.4168272018432617
Validation loss: 2.3881223458115772

Epoch: 6| Step: 1
Training loss: 2.4880177974700928
Validation loss: 2.3940824641976306

Epoch: 6| Step: 2
Training loss: 2.3775758743286133
Validation loss: 2.403399472595543

Epoch: 6| Step: 3
Training loss: 2.2317018508911133
Validation loss: 2.426591024603895

Epoch: 6| Step: 4
Training loss: 2.6557517051696777
Validation loss: 2.437518737649405

Epoch: 6| Step: 5
Training loss: 3.065208673477173
Validation loss: 2.4478973573254

Epoch: 6| Step: 6
Training loss: 2.4996867179870605
Validation loss: 2.450564076823573

Epoch: 6| Step: 7
Training loss: 3.234097957611084
Validation loss: 2.4439764804737543

Epoch: 6| Step: 8
Training loss: 2.1514925956726074
Validation loss: 2.439653491461149

Epoch: 6| Step: 9
Training loss: 3.2628068923950195
Validation loss: 2.430501819938742

Epoch: 6| Step: 10
Training loss: 2.823399543762207
Validation loss: 2.418573446171258

Epoch: 6| Step: 11
Training loss: 2.0965993404388428
Validation loss: 2.409915239580216

Epoch: 6| Step: 12
Training loss: 2.824000358581543
Validation loss: 2.4025059002701954

Epoch: 6| Step: 13
Training loss: 3.268962860107422
Validation loss: 2.40649849625044

Epoch: 137| Step: 0
Training loss: 2.243417978286743
Validation loss: 2.4076731025531726

Epoch: 6| Step: 1
Training loss: 2.382467269897461
Validation loss: 2.414322437778596

Epoch: 6| Step: 2
Training loss: 2.7040488719940186
Validation loss: 2.41549156301765

Epoch: 6| Step: 3
Training loss: 2.785194158554077
Validation loss: 2.417374277627596

Epoch: 6| Step: 4
Training loss: 2.3487329483032227
Validation loss: 2.419867636055075

Epoch: 6| Step: 5
Training loss: 2.7285194396972656
Validation loss: 2.4120284511196997

Epoch: 6| Step: 6
Training loss: 2.790544033050537
Validation loss: 2.4106018261242936

Epoch: 6| Step: 7
Training loss: 2.5514471530914307
Validation loss: 2.402256040162938

Epoch: 6| Step: 8
Training loss: 2.6137356758117676
Validation loss: 2.396516692253851

Epoch: 6| Step: 9
Training loss: 3.427408218383789
Validation loss: 2.3948217758568386

Epoch: 6| Step: 10
Training loss: 2.538081407546997
Validation loss: 2.3833417610455583

Epoch: 6| Step: 11
Training loss: 2.212480068206787
Validation loss: 2.376387357711792

Epoch: 6| Step: 12
Training loss: 2.6184000968933105
Validation loss: 2.375137713647658

Epoch: 6| Step: 13
Training loss: 2.8106489181518555
Validation loss: 2.3709184046714538

Epoch: 138| Step: 0
Training loss: 1.7939502000808716
Validation loss: 2.3683125972747803

Epoch: 6| Step: 1
Training loss: 1.8925734758377075
Validation loss: 2.3686158041800223

Epoch: 6| Step: 2
Training loss: 2.898059606552124
Validation loss: 2.3745400162153345

Epoch: 6| Step: 3
Training loss: 2.583125352859497
Validation loss: 2.374265032429849

Epoch: 6| Step: 4
Training loss: 1.9195964336395264
Validation loss: 2.371397977234215

Epoch: 6| Step: 5
Training loss: 3.0841472148895264
Validation loss: 2.3739590798654864

Epoch: 6| Step: 6
Training loss: 2.765070676803589
Validation loss: 2.372629750159479

Epoch: 6| Step: 7
Training loss: 3.2182059288024902
Validation loss: 2.3737087839393207

Epoch: 6| Step: 8
Training loss: 2.6856448650360107
Validation loss: 2.3724706121670303

Epoch: 6| Step: 9
Training loss: 3.2521162033081055
Validation loss: 2.3678491679571008

Epoch: 6| Step: 10
Training loss: 2.961099624633789
Validation loss: 2.372397973973264

Epoch: 6| Step: 11
Training loss: 3.1911730766296387
Validation loss: 2.3707708902256464

Epoch: 6| Step: 12
Training loss: 2.0142903327941895
Validation loss: 2.370276097328432

Epoch: 6| Step: 13
Training loss: 2.295499324798584
Validation loss: 2.370215267263433

Epoch: 139| Step: 0
Training loss: 2.6706347465515137
Validation loss: 2.3690486467012795

Epoch: 6| Step: 1
Training loss: 2.255836248397827
Validation loss: 2.368860052477929

Epoch: 6| Step: 2
Training loss: 2.6492061614990234
Validation loss: 2.3606311198203795

Epoch: 6| Step: 3
Training loss: 2.657310962677002
Validation loss: 2.3744992799656366

Epoch: 6| Step: 4
Training loss: 2.6565611362457275
Validation loss: 2.3770913001029723

Epoch: 6| Step: 5
Training loss: 2.366973638534546
Validation loss: 2.3756475576790432

Epoch: 6| Step: 6
Training loss: 3.1645760536193848
Validation loss: 2.380057386172715

Epoch: 6| Step: 7
Training loss: 2.8833107948303223
Validation loss: 2.380805648783202

Epoch: 6| Step: 8
Training loss: 2.8098397254943848
Validation loss: 2.396919652979861

Epoch: 6| Step: 9
Training loss: 2.29388427734375
Validation loss: 2.39732648223959

Epoch: 6| Step: 10
Training loss: 2.3596115112304688
Validation loss: 2.4020279504919566

Epoch: 6| Step: 11
Training loss: 2.7200939655303955
Validation loss: 2.3984253355251846

Epoch: 6| Step: 12
Training loss: 2.3377792835235596
Validation loss: 2.4061449266249135

Epoch: 6| Step: 13
Training loss: 3.0890095233917236
Validation loss: 2.3912543917214997

Epoch: 140| Step: 0
Training loss: 2.4546632766723633
Validation loss: 2.383635631171606

Epoch: 6| Step: 1
Training loss: 1.7476682662963867
Validation loss: 2.379871987527417

Epoch: 6| Step: 2
Training loss: 3.234245538711548
Validation loss: 2.370039511752385

Epoch: 6| Step: 3
Training loss: 2.725836753845215
Validation loss: 2.373527567873719

Epoch: 6| Step: 4
Training loss: 2.9687535762786865
Validation loss: 2.3724878398321008

Epoch: 6| Step: 5
Training loss: 2.66390061378479
Validation loss: 2.363171077543689

Epoch: 6| Step: 6
Training loss: 2.6370885372161865
Validation loss: 2.3650566198492564

Epoch: 6| Step: 7
Training loss: 1.8588509559631348
Validation loss: 2.363268070323493

Epoch: 6| Step: 8
Training loss: 2.681511640548706
Validation loss: 2.3625535375328472

Epoch: 6| Step: 9
Training loss: 2.3151907920837402
Validation loss: 2.3562408493411158

Epoch: 6| Step: 10
Training loss: 2.225337505340576
Validation loss: 2.357001239253629

Epoch: 6| Step: 11
Training loss: 2.795144557952881
Validation loss: 2.363364901593936

Epoch: 6| Step: 12
Training loss: 3.0933027267456055
Validation loss: 2.361154769056587

Epoch: 6| Step: 13
Training loss: 3.6132524013519287
Validation loss: 2.371192847528765

Epoch: 141| Step: 0
Training loss: 2.84614896774292
Validation loss: 2.3689270711714223

Epoch: 6| Step: 1
Training loss: 2.5885281562805176
Validation loss: 2.364795861705657

Epoch: 6| Step: 2
Training loss: 2.502817153930664
Validation loss: 2.365293630989649

Epoch: 6| Step: 3
Training loss: 3.100522041320801
Validation loss: 2.3656281130288237

Epoch: 6| Step: 4
Training loss: 3.4348814487457275
Validation loss: 2.3622086304490284

Epoch: 6| Step: 5
Training loss: 2.9028964042663574
Validation loss: 2.3617834788496777

Epoch: 6| Step: 6
Training loss: 2.4329919815063477
Validation loss: 2.3562328853914813

Epoch: 6| Step: 7
Training loss: 1.882087230682373
Validation loss: 2.364425115687873

Epoch: 6| Step: 8
Training loss: 2.621123790740967
Validation loss: 2.368476706166421

Epoch: 6| Step: 9
Training loss: 2.0632758140563965
Validation loss: 2.3653003631099576

Epoch: 6| Step: 10
Training loss: 2.281522274017334
Validation loss: 2.362363871707711

Epoch: 6| Step: 11
Training loss: 2.6311378479003906
Validation loss: 2.3677815724444646

Epoch: 6| Step: 12
Training loss: 2.896425247192383
Validation loss: 2.3686209724795435

Epoch: 6| Step: 13
Training loss: 2.1456713676452637
Validation loss: 2.3770791817736883

Epoch: 142| Step: 0
Training loss: 2.8356499671936035
Validation loss: 2.3859657702907437

Epoch: 6| Step: 1
Training loss: 3.172647476196289
Validation loss: 2.3777664681916595

Epoch: 6| Step: 2
Training loss: 2.668945789337158
Validation loss: 2.383135721247683

Epoch: 6| Step: 3
Training loss: 3.0075507164001465
Validation loss: 2.374083549745621

Epoch: 6| Step: 4
Training loss: 2.0882654190063477
Validation loss: 2.368738620511947

Epoch: 6| Step: 5
Training loss: 2.283768653869629
Validation loss: 2.373506986966697

Epoch: 6| Step: 6
Training loss: 2.0579917430877686
Validation loss: 2.3703483202124156

Epoch: 6| Step: 7
Training loss: 2.962343454360962
Validation loss: 2.368685286532166

Epoch: 6| Step: 8
Training loss: 2.767364978790283
Validation loss: 2.3681437789752917

Epoch: 6| Step: 9
Training loss: 3.102499008178711
Validation loss: 2.3682150174212713

Epoch: 6| Step: 10
Training loss: 2.893350124359131
Validation loss: 2.374247266400245

Epoch: 6| Step: 11
Training loss: 1.7316086292266846
Validation loss: 2.377876732939033

Epoch: 6| Step: 12
Training loss: 2.592134952545166
Validation loss: 2.3783906762317946

Epoch: 6| Step: 13
Training loss: 2.21372652053833
Validation loss: 2.37414223917069

Epoch: 143| Step: 0
Training loss: 2.918801784515381
Validation loss: 2.3749289999726

Epoch: 6| Step: 1
Training loss: 2.3844523429870605
Validation loss: 2.384180412497572

Epoch: 6| Step: 2
Training loss: 1.6891086101531982
Validation loss: 2.3833609191320275

Epoch: 6| Step: 3
Training loss: 2.261873245239258
Validation loss: 2.3887549907930437

Epoch: 6| Step: 4
Training loss: 3.0579705238342285
Validation loss: 2.3831784545734362

Epoch: 6| Step: 5
Training loss: 2.485212564468384
Validation loss: 2.38559789042319

Epoch: 6| Step: 6
Training loss: 2.1669681072235107
Validation loss: 2.388392238206761

Epoch: 6| Step: 7
Training loss: 1.853464126586914
Validation loss: 2.386120334748299

Epoch: 6| Step: 8
Training loss: 2.6893067359924316
Validation loss: 2.3874251945044405

Epoch: 6| Step: 9
Training loss: 3.3408284187316895
Validation loss: 2.3773846011007986

Epoch: 6| Step: 10
Training loss: 3.35078501701355
Validation loss: 2.385514824621139

Epoch: 6| Step: 11
Training loss: 3.248490810394287
Validation loss: 2.3737076867011284

Epoch: 6| Step: 12
Training loss: 2.3201005458831787
Validation loss: 2.37802815950045

Epoch: 6| Step: 13
Training loss: 2.7246551513671875
Validation loss: 2.3645881786141345

Epoch: 144| Step: 0
Training loss: 2.3239293098449707
Validation loss: 2.364802875826436

Epoch: 6| Step: 1
Training loss: 2.83811354637146
Validation loss: 2.3608584737264984

Epoch: 6| Step: 2
Training loss: 3.244269609451294
Validation loss: 2.3596231450316725

Epoch: 6| Step: 3
Training loss: 2.7063612937927246
Validation loss: 2.3574797620055494

Epoch: 6| Step: 4
Training loss: 2.6388816833496094
Validation loss: 2.3538112819835706

Epoch: 6| Step: 5
Training loss: 2.3713693618774414
Validation loss: 2.356683128623552

Epoch: 6| Step: 6
Training loss: 2.240429401397705
Validation loss: 2.3501217006355204

Epoch: 6| Step: 7
Training loss: 2.859283685684204
Validation loss: 2.351403065907058

Epoch: 6| Step: 8
Training loss: 2.765650987625122
Validation loss: 2.3596916352548907

Epoch: 6| Step: 9
Training loss: 1.91594660282135
Validation loss: 2.374446015204153

Epoch: 6| Step: 10
Training loss: 2.6544909477233887
Validation loss: 2.36912110031292

Epoch: 6| Step: 11
Training loss: 2.309159278869629
Validation loss: 2.374911085251839

Epoch: 6| Step: 12
Training loss: 2.545470714569092
Validation loss: 2.3755376595322804

Epoch: 6| Step: 13
Training loss: 3.251335382461548
Validation loss: 2.377730172167542

Epoch: 145| Step: 0
Training loss: 2.260343074798584
Validation loss: 2.3787803649902344

Epoch: 6| Step: 1
Training loss: 2.5700173377990723
Validation loss: 2.377720945624895

Epoch: 6| Step: 2
Training loss: 2.109450340270996
Validation loss: 2.3676209475404475

Epoch: 6| Step: 3
Training loss: 2.2397499084472656
Validation loss: 2.385438431975662

Epoch: 6| Step: 4
Training loss: 3.3589911460876465
Validation loss: 2.3742839008249264

Epoch: 6| Step: 5
Training loss: 2.4490649700164795
Validation loss: 2.372543127306046

Epoch: 6| Step: 6
Training loss: 2.749871253967285
Validation loss: 2.364077465508574

Epoch: 6| Step: 7
Training loss: 3.3551487922668457
Validation loss: 2.3596006465214554

Epoch: 6| Step: 8
Training loss: 2.438369035720825
Validation loss: 2.365567981555898

Epoch: 6| Step: 9
Training loss: 2.4382948875427246
Validation loss: 2.360907821245091

Epoch: 6| Step: 10
Training loss: 2.462958574295044
Validation loss: 2.3604873867445093

Epoch: 6| Step: 11
Training loss: 3.5294227600097656
Validation loss: 2.3569972181832917

Epoch: 6| Step: 12
Training loss: 2.467900514602661
Validation loss: 2.3489529137970298

Epoch: 6| Step: 13
Training loss: 1.5254219770431519
Validation loss: 2.3548543889035463

Epoch: 146| Step: 0
Training loss: 2.2715907096862793
Validation loss: 2.3554805196741575

Epoch: 6| Step: 1
Training loss: 2.3923141956329346
Validation loss: 2.3477024698770173

Epoch: 6| Step: 2
Training loss: 2.0020205974578857
Validation loss: 2.3453763608009583

Epoch: 6| Step: 3
Training loss: 3.7124805450439453
Validation loss: 2.343960428750643

Epoch: 6| Step: 4
Training loss: 2.2310357093811035
Validation loss: 2.347287972768148

Epoch: 6| Step: 5
Training loss: 2.1959381103515625
Validation loss: 2.3445501391605665

Epoch: 6| Step: 6
Training loss: 2.620837688446045
Validation loss: 2.341335755522533

Epoch: 6| Step: 7
Training loss: 2.65797758102417
Validation loss: 2.3530011894882366

Epoch: 6| Step: 8
Training loss: 2.78908371925354
Validation loss: 2.356957633008239

Epoch: 6| Step: 9
Training loss: 3.6570658683776855
Validation loss: 2.3667234297721618

Epoch: 6| Step: 10
Training loss: 2.7412619590759277
Validation loss: 2.376094728387812

Epoch: 6| Step: 11
Training loss: 2.154935836791992
Validation loss: 2.3810096376685688

Epoch: 6| Step: 12
Training loss: 2.642674446105957
Validation loss: 2.3826304738239577

Epoch: 6| Step: 13
Training loss: 2.079318046569824
Validation loss: 2.4001330765344764

Epoch: 147| Step: 0
Training loss: 3.1146647930145264
Validation loss: 2.4065430266882784

Epoch: 6| Step: 1
Training loss: 2.6801834106445312
Validation loss: 2.402810804305538

Epoch: 6| Step: 2
Training loss: 2.974924087524414
Validation loss: 2.394872832041915

Epoch: 6| Step: 3
Training loss: 1.89121413230896
Validation loss: 2.3896823749747327

Epoch: 6| Step: 4
Training loss: 3.472109317779541
Validation loss: 2.3862557847012758

Epoch: 6| Step: 5
Training loss: 2.98286771774292
Validation loss: 2.3871137301127114

Epoch: 6| Step: 6
Training loss: 3.356159210205078
Validation loss: 2.390600173704086

Epoch: 6| Step: 7
Training loss: 1.9978188276290894
Validation loss: 2.38119198173605

Epoch: 6| Step: 8
Training loss: 2.3395535945892334
Validation loss: 2.3746894559552594

Epoch: 6| Step: 9
Training loss: 2.440558433532715
Validation loss: 2.3579748240850305

Epoch: 6| Step: 10
Training loss: 2.242122173309326
Validation loss: 2.3589203921697472

Epoch: 6| Step: 11
Training loss: 2.4619810581207275
Validation loss: 2.3580533996705086

Epoch: 6| Step: 12
Training loss: 2.5074033737182617
Validation loss: 2.353760104025564

Epoch: 6| Step: 13
Training loss: 1.3535656929016113
Validation loss: 2.3478192513988865

Epoch: 148| Step: 0
Training loss: 2.2017974853515625
Validation loss: 2.3501134790400022

Epoch: 6| Step: 1
Training loss: 3.0312259197235107
Validation loss: 2.3548970427564395

Epoch: 6| Step: 2
Training loss: 2.376262903213501
Validation loss: 2.3649300580383628

Epoch: 6| Step: 3
Training loss: 2.913269519805908
Validation loss: 2.369761881007943

Epoch: 6| Step: 4
Training loss: 2.403169870376587
Validation loss: 2.369251146111437

Epoch: 6| Step: 5
Training loss: 2.3821678161621094
Validation loss: 2.3757467885171213

Epoch: 6| Step: 6
Training loss: 3.6348636150360107
Validation loss: 2.373834245948381

Epoch: 6| Step: 7
Training loss: 2.4169955253601074
Validation loss: 2.370915489812051

Epoch: 6| Step: 8
Training loss: 2.1389951705932617
Validation loss: 2.369215364097267

Epoch: 6| Step: 9
Training loss: 3.2068309783935547
Validation loss: 2.3809458132713073

Epoch: 6| Step: 10
Training loss: 2.275693893432617
Validation loss: 2.3733907515002834

Epoch: 6| Step: 11
Training loss: 1.8745617866516113
Validation loss: 2.3703144083740892

Epoch: 6| Step: 12
Training loss: 2.4979970455169678
Validation loss: 2.3680240274757467

Epoch: 6| Step: 13
Training loss: 3.273440361022949
Validation loss: 2.3736901411446194

Epoch: 149| Step: 0
Training loss: 2.1997525691986084
Validation loss: 2.3738685474600842

Epoch: 6| Step: 1
Training loss: 2.248173236846924
Validation loss: 2.367874099362281

Epoch: 6| Step: 2
Training loss: 2.951422929763794
Validation loss: 2.3725117073264173

Epoch: 6| Step: 3
Training loss: 3.0466384887695312
Validation loss: 2.3700592774216847

Epoch: 6| Step: 4
Training loss: 2.665177345275879
Validation loss: 2.370900897569554

Epoch: 6| Step: 5
Training loss: 2.909208297729492
Validation loss: 2.3642417384732153

Epoch: 6| Step: 6
Training loss: 2.59840726852417
Validation loss: 2.3628667631456928

Epoch: 6| Step: 7
Training loss: 2.0572993755340576
Validation loss: 2.3641433485092653

Epoch: 6| Step: 8
Training loss: 2.7602195739746094
Validation loss: 2.3655459034827446

Epoch: 6| Step: 9
Training loss: 3.3182783126831055
Validation loss: 2.365249428697812

Epoch: 6| Step: 10
Training loss: 2.5299506187438965
Validation loss: 2.3650488468908493

Epoch: 6| Step: 11
Training loss: 2.281207323074341
Validation loss: 2.3624798021008893

Epoch: 6| Step: 12
Training loss: 2.1985421180725098
Validation loss: 2.3644273819461947

Epoch: 6| Step: 13
Training loss: 2.450228452682495
Validation loss: 2.3629782533132904

Epoch: 150| Step: 0
Training loss: 2.094602108001709
Validation loss: 2.364111364528697

Epoch: 6| Step: 1
Training loss: 2.4768295288085938
Validation loss: 2.3625306903675036

Epoch: 6| Step: 2
Training loss: 2.543316125869751
Validation loss: 2.374241013680735

Epoch: 6| Step: 3
Training loss: 2.733276844024658
Validation loss: 2.3734675274100354

Epoch: 6| Step: 4
Training loss: 2.9037623405456543
Validation loss: 2.3603469428195747

Epoch: 6| Step: 5
Training loss: 2.427553653717041
Validation loss: 2.363447799477526

Epoch: 6| Step: 6
Training loss: 2.635826587677002
Validation loss: 2.3636778631517963

Epoch: 6| Step: 7
Training loss: 2.806459426879883
Validation loss: 2.3548762747036514

Epoch: 6| Step: 8
Training loss: 2.503479480743408
Validation loss: 2.357252187626336

Epoch: 6| Step: 9
Training loss: 2.1582231521606445
Validation loss: 2.3536675694168254

Epoch: 6| Step: 10
Training loss: 2.2982544898986816
Validation loss: 2.3578295476974978

Epoch: 6| Step: 11
Training loss: 2.969360589981079
Validation loss: 2.354736961344237

Epoch: 6| Step: 12
Training loss: 3.218564987182617
Validation loss: 2.3459473758615474

Epoch: 6| Step: 13
Training loss: 2.3122057914733887
Validation loss: 2.3492332504641626

Epoch: 151| Step: 0
Training loss: 2.6893084049224854
Validation loss: 2.3499103938379595

Epoch: 6| Step: 1
Training loss: 3.3598015308380127
Validation loss: 2.3528000180439284

Epoch: 6| Step: 2
Training loss: 2.7953743934631348
Validation loss: 2.3624864060391664

Epoch: 6| Step: 3
Training loss: 1.6334443092346191
Validation loss: 2.376083250968687

Epoch: 6| Step: 4
Training loss: 2.138288974761963
Validation loss: 2.373061982534265

Epoch: 6| Step: 5
Training loss: 2.2702600955963135
Validation loss: 2.3646940108268493

Epoch: 6| Step: 6
Training loss: 2.610724925994873
Validation loss: 2.374189756249869

Epoch: 6| Step: 7
Training loss: 2.470346212387085
Validation loss: 2.371659145560316

Epoch: 6| Step: 8
Training loss: 3.0848419666290283
Validation loss: 2.379629350477649

Epoch: 6| Step: 9
Training loss: 2.9634807109832764
Validation loss: 2.3688708043867543

Epoch: 6| Step: 10
Training loss: 2.588596820831299
Validation loss: 2.360228956386607

Epoch: 6| Step: 11
Training loss: 2.0502662658691406
Validation loss: 2.3527657344777095

Epoch: 6| Step: 12
Training loss: 3.0774588584899902
Validation loss: 2.3457525737823977

Epoch: 6| Step: 13
Training loss: 2.6951723098754883
Validation loss: 2.335707854199153

Epoch: 152| Step: 0
Training loss: 3.0137956142425537
Validation loss: 2.33050004641215

Epoch: 6| Step: 1
Training loss: 3.130763053894043
Validation loss: 2.3387951261253765

Epoch: 6| Step: 2
Training loss: 2.441746711730957
Validation loss: 2.3284042368653

Epoch: 6| Step: 3
Training loss: 1.9788411855697632
Validation loss: 2.337746863724083

Epoch: 6| Step: 4
Training loss: 2.877016305923462
Validation loss: 2.331824820528748

Epoch: 6| Step: 5
Training loss: 2.7087512016296387
Validation loss: 2.333365589059809

Epoch: 6| Step: 6
Training loss: 2.3899338245391846
Validation loss: 2.330242347973649

Epoch: 6| Step: 7
Training loss: 2.0402603149414062
Validation loss: 2.3299770303951797

Epoch: 6| Step: 8
Training loss: 2.7987565994262695
Validation loss: 2.330254472712035

Epoch: 6| Step: 9
Training loss: 2.329164505004883
Validation loss: 2.3324504667712795

Epoch: 6| Step: 10
Training loss: 2.4595413208007812
Validation loss: 2.333978129971412

Epoch: 6| Step: 11
Training loss: 2.187260389328003
Validation loss: 2.348107478951895

Epoch: 6| Step: 12
Training loss: 3.3014917373657227
Validation loss: 2.354502078025572

Epoch: 6| Step: 13
Training loss: 2.780703067779541
Validation loss: 2.360798958809145

Epoch: 153| Step: 0
Training loss: 2.2425220012664795
Validation loss: 2.364779354423605

Epoch: 6| Step: 1
Training loss: 3.1834094524383545
Validation loss: 2.3817022333862963

Epoch: 6| Step: 2
Training loss: 3.3476080894470215
Validation loss: 2.3821201221917265

Epoch: 6| Step: 3
Training loss: 2.4375884532928467
Validation loss: 2.3864946596084105

Epoch: 6| Step: 4
Training loss: 1.9462778568267822
Validation loss: 2.3923793479960453

Epoch: 6| Step: 5
Training loss: 2.2510769367218018
Validation loss: 2.3880171057998494

Epoch: 6| Step: 6
Training loss: 2.7762069702148438
Validation loss: 2.38779523552105

Epoch: 6| Step: 7
Training loss: 3.4390649795532227
Validation loss: 2.400471087424986

Epoch: 6| Step: 8
Training loss: 3.2880022525787354
Validation loss: 2.3881581252621067

Epoch: 6| Step: 9
Training loss: 2.7189879417419434
Validation loss: 2.3876969532300065

Epoch: 6| Step: 10
Training loss: 2.5334551334381104
Validation loss: 2.3895600406072472

Epoch: 6| Step: 11
Training loss: 1.891547679901123
Validation loss: 2.385104569055701

Epoch: 6| Step: 12
Training loss: 1.8336079120635986
Validation loss: 2.3827316402107157

Epoch: 6| Step: 13
Training loss: 2.7414302825927734
Validation loss: 2.388645400283157

Epoch: 154| Step: 0
Training loss: 2.1755447387695312
Validation loss: 2.37441958150556

Epoch: 6| Step: 1
Training loss: 2.9926748275756836
Validation loss: 2.3770533325851604

Epoch: 6| Step: 2
Training loss: 2.374122142791748
Validation loss: 2.3664581903847317

Epoch: 6| Step: 3
Training loss: 2.1067962646484375
Validation loss: 2.3663849471717753

Epoch: 6| Step: 4
Training loss: 2.566331148147583
Validation loss: 2.362752286336755

Epoch: 6| Step: 5
Training loss: 2.3896584510803223
Validation loss: 2.3542307756280385

Epoch: 6| Step: 6
Training loss: 3.4343862533569336
Validation loss: 2.3516612950191704

Epoch: 6| Step: 7
Training loss: 1.9433987140655518
Validation loss: 2.3475137577261975

Epoch: 6| Step: 8
Training loss: 2.0819263458251953
Validation loss: 2.3509695555574153

Epoch: 6| Step: 9
Training loss: 2.4927656650543213
Validation loss: 2.3596872616839666

Epoch: 6| Step: 10
Training loss: 2.8589649200439453
Validation loss: 2.3621279860055573

Epoch: 6| Step: 11
Training loss: 2.429798126220703
Validation loss: 2.3694279514333254

Epoch: 6| Step: 12
Training loss: 3.268270969390869
Validation loss: 2.3696248813342025

Epoch: 6| Step: 13
Training loss: 3.4784066677093506
Validation loss: 2.370963478601107

Epoch: 155| Step: 0
Training loss: 2.4006876945495605
Validation loss: 2.3701571905484764

Epoch: 6| Step: 1
Training loss: 1.9880194664001465
Validation loss: 2.372447867547312

Epoch: 6| Step: 2
Training loss: 2.0253336429595947
Validation loss: 2.3798543855708134

Epoch: 6| Step: 3
Training loss: 2.919503688812256
Validation loss: 2.3749703912324804

Epoch: 6| Step: 4
Training loss: 2.647975444793701
Validation loss: 2.3705859132992324

Epoch: 6| Step: 5
Training loss: 3.074038505554199
Validation loss: 2.3627600182769117

Epoch: 6| Step: 6
Training loss: 3.2762303352355957
Validation loss: 2.3539813385214856

Epoch: 6| Step: 7
Training loss: 3.545929431915283
Validation loss: 2.3566696887375205

Epoch: 6| Step: 8
Training loss: 1.6687085628509521
Validation loss: 2.3427466346371557

Epoch: 6| Step: 9
Training loss: 2.57608962059021
Validation loss: 2.345086047726293

Epoch: 6| Step: 10
Training loss: 2.0762763023376465
Validation loss: 2.3426245989338046

Epoch: 6| Step: 11
Training loss: 2.4878783226013184
Validation loss: 2.3428046780247844

Epoch: 6| Step: 12
Training loss: 3.184901237487793
Validation loss: 2.3407440262456096

Epoch: 6| Step: 13
Training loss: 2.0560994148254395
Validation loss: 2.3438891595409763

Epoch: 156| Step: 0
Training loss: 2.509211778640747
Validation loss: 2.3455375368877123

Epoch: 6| Step: 1
Training loss: 2.3223345279693604
Validation loss: 2.3507199774506273

Epoch: 6| Step: 2
Training loss: 2.9434432983398438
Validation loss: 2.3480254078424103

Epoch: 6| Step: 3
Training loss: 2.483579635620117
Validation loss: 2.345784394971786

Epoch: 6| Step: 4
Training loss: 2.415194511413574
Validation loss: 2.351363141049621

Epoch: 6| Step: 5
Training loss: 2.066361427307129
Validation loss: 2.3503227618432816

Epoch: 6| Step: 6
Training loss: 2.348686933517456
Validation loss: 2.3553121705209055

Epoch: 6| Step: 7
Training loss: 2.8285584449768066
Validation loss: 2.3582977735868065

Epoch: 6| Step: 8
Training loss: 2.3507444858551025
Validation loss: 2.3563524612816433

Epoch: 6| Step: 9
Training loss: 1.5632307529449463
Validation loss: 2.3482850136295443

Epoch: 6| Step: 10
Training loss: 3.1079812049865723
Validation loss: 2.3575746218363443

Epoch: 6| Step: 11
Training loss: 2.789790630340576
Validation loss: 2.358709696800478

Epoch: 6| Step: 12
Training loss: 3.386796474456787
Validation loss: 2.3639346425251295

Epoch: 6| Step: 13
Training loss: 3.422793388366699
Validation loss: 2.3660068640144925

Epoch: 157| Step: 0
Training loss: 2.5401554107666016
Validation loss: 2.3681693897452405

Epoch: 6| Step: 1
Training loss: 2.6276049613952637
Validation loss: 2.373396676073792

Epoch: 6| Step: 2
Training loss: 2.1561079025268555
Validation loss: 2.3701616564104633

Epoch: 6| Step: 3
Training loss: 2.758615016937256
Validation loss: 2.3655674765186925

Epoch: 6| Step: 4
Training loss: 2.371713638305664
Validation loss: 2.3715246133906867

Epoch: 6| Step: 5
Training loss: 2.575284004211426
Validation loss: 2.3778617920414096

Epoch: 6| Step: 6
Training loss: 3.258047103881836
Validation loss: 2.3851459974883706

Epoch: 6| Step: 7
Training loss: 2.669037342071533
Validation loss: 2.3846961323932936

Epoch: 6| Step: 8
Training loss: 2.1849021911621094
Validation loss: 2.378111554730323

Epoch: 6| Step: 9
Training loss: 2.224290370941162
Validation loss: 2.3758811950683594

Epoch: 6| Step: 10
Training loss: 2.4657907485961914
Validation loss: 2.3697975604764876

Epoch: 6| Step: 11
Training loss: 2.484839916229248
Validation loss: 2.377284311479138

Epoch: 6| Step: 12
Training loss: 3.0059807300567627
Validation loss: 2.3647569558953725

Epoch: 6| Step: 13
Training loss: 3.002101182937622
Validation loss: 2.3753487563902334

Epoch: 158| Step: 0
Training loss: 2.580592393875122
Validation loss: 2.3558027026473836

Epoch: 6| Step: 1
Training loss: 1.9454749822616577
Validation loss: 2.351491766591226

Epoch: 6| Step: 2
Training loss: 2.4372055530548096
Validation loss: 2.351531869621687

Epoch: 6| Step: 3
Training loss: 2.659722089767456
Validation loss: 2.345173911381793

Epoch: 6| Step: 4
Training loss: 2.4883108139038086
Validation loss: 2.339886814035395

Epoch: 6| Step: 5
Training loss: 3.059640407562256
Validation loss: 2.3481122242507113

Epoch: 6| Step: 6
Training loss: 1.9924393892288208
Validation loss: 2.3458174044086086

Epoch: 6| Step: 7
Training loss: 3.1246042251586914
Validation loss: 2.346499866054904

Epoch: 6| Step: 8
Training loss: 3.0757274627685547
Validation loss: 2.351712408886161

Epoch: 6| Step: 9
Training loss: 2.170607805252075
Validation loss: 2.3469694301646244

Epoch: 6| Step: 10
Training loss: 2.843013048171997
Validation loss: 2.3504673639933267

Epoch: 6| Step: 11
Training loss: 2.988738775253296
Validation loss: 2.3530969132659254

Epoch: 6| Step: 12
Training loss: 2.5746493339538574
Validation loss: 2.3634841621563

Epoch: 6| Step: 13
Training loss: 1.959073781967163
Validation loss: 2.3640966902496996

Epoch: 159| Step: 0
Training loss: 1.8951530456542969
Validation loss: 2.3753864072984263

Epoch: 6| Step: 1
Training loss: 2.388428211212158
Validation loss: 2.3690672997505433

Epoch: 6| Step: 2
Training loss: 2.9574122428894043
Validation loss: 2.3759714980279245

Epoch: 6| Step: 3
Training loss: 2.903777599334717
Validation loss: 2.3773636202658377

Epoch: 6| Step: 4
Training loss: 3.057814121246338
Validation loss: 2.392538450097525

Epoch: 6| Step: 5
Training loss: 2.437954902648926
Validation loss: 2.3926680164952434

Epoch: 6| Step: 6
Training loss: 2.150733470916748
Validation loss: 2.3889233886554675

Epoch: 6| Step: 7
Training loss: 2.360121488571167
Validation loss: 2.3915484848842827

Epoch: 6| Step: 8
Training loss: 3.2319588661193848
Validation loss: 2.381987025660853

Epoch: 6| Step: 9
Training loss: 2.626403331756592
Validation loss: 2.380601854734523

Epoch: 6| Step: 10
Training loss: 3.2843337059020996
Validation loss: 2.357410564217516

Epoch: 6| Step: 11
Training loss: 2.5158824920654297
Validation loss: 2.3667908022480626

Epoch: 6| Step: 12
Training loss: 1.9167627096176147
Validation loss: 2.3524891355986237

Epoch: 6| Step: 13
Training loss: 2.475290536880493
Validation loss: 2.3549118029173983

Epoch: 160| Step: 0
Training loss: 2.7679076194763184
Validation loss: 2.348367101402693

Epoch: 6| Step: 1
Training loss: 2.3673601150512695
Validation loss: 2.3381434050939416

Epoch: 6| Step: 2
Training loss: 2.22409725189209
Validation loss: 2.342877722555591

Epoch: 6| Step: 3
Training loss: 3.084610939025879
Validation loss: 2.3484640993097776

Epoch: 6| Step: 4
Training loss: 1.989310383796692
Validation loss: 2.3485404958007154

Epoch: 6| Step: 5
Training loss: 2.9728264808654785
Validation loss: 2.342212374492358

Epoch: 6| Step: 6
Training loss: 2.917511463165283
Validation loss: 2.3437912694869505

Epoch: 6| Step: 7
Training loss: 2.1140847206115723
Validation loss: 2.334314433477258

Epoch: 6| Step: 8
Training loss: 2.6088273525238037
Validation loss: 2.3332846062157744

Epoch: 6| Step: 9
Training loss: 3.204252243041992
Validation loss: 2.33901325989795

Epoch: 6| Step: 10
Training loss: 2.0472724437713623
Validation loss: 2.3281738629905124

Epoch: 6| Step: 11
Training loss: 2.9157848358154297
Validation loss: 2.3288508512640513

Epoch: 6| Step: 12
Training loss: 2.3918116092681885
Validation loss: 2.3353855327893327

Epoch: 6| Step: 13
Training loss: 2.3702502250671387
Validation loss: 2.331019386168449

Epoch: 161| Step: 0
Training loss: 2.252167224884033
Validation loss: 2.3407504135562527

Epoch: 6| Step: 1
Training loss: 2.5514869689941406
Validation loss: 2.335762195689704

Epoch: 6| Step: 2
Training loss: 2.7523789405822754
Validation loss: 2.3425884451917423

Epoch: 6| Step: 3
Training loss: 2.2801766395568848
Validation loss: 2.3391028219653713

Epoch: 6| Step: 4
Training loss: 2.3176867961883545
Validation loss: 2.34107643429951

Epoch: 6| Step: 5
Training loss: 2.5458521842956543
Validation loss: 2.351781286219115

Epoch: 6| Step: 6
Training loss: 3.086989402770996
Validation loss: 2.3520852135073755

Epoch: 6| Step: 7
Training loss: 3.2415316104888916
Validation loss: 2.3659183568851923

Epoch: 6| Step: 8
Training loss: 1.9163095951080322
Validation loss: 2.3582929436878493

Epoch: 6| Step: 9
Training loss: 2.7758092880249023
Validation loss: 2.3645905038361907

Epoch: 6| Step: 10
Training loss: 2.655390739440918
Validation loss: 2.369959350555174

Epoch: 6| Step: 11
Training loss: 2.3503172397613525
Validation loss: 2.3700318926124164

Epoch: 6| Step: 12
Training loss: 2.8845081329345703
Validation loss: 2.365100270958357

Epoch: 6| Step: 13
Training loss: 2.175488233566284
Validation loss: 2.361253837103485

Epoch: 162| Step: 0
Training loss: 3.3440563678741455
Validation loss: 2.3607594992524836

Epoch: 6| Step: 1
Training loss: 2.976919651031494
Validation loss: 2.364888950060773

Epoch: 6| Step: 2
Training loss: 2.7726502418518066
Validation loss: 2.364150257520778

Epoch: 6| Step: 3
Training loss: 2.3380126953125
Validation loss: 2.369714096028318

Epoch: 6| Step: 4
Training loss: 2.6019082069396973
Validation loss: 2.376271432445895

Epoch: 6| Step: 5
Training loss: 2.9036669731140137
Validation loss: 2.357543768421296

Epoch: 6| Step: 6
Training loss: 2.7297017574310303
Validation loss: 2.3647884732933453

Epoch: 6| Step: 7
Training loss: 3.0584864616394043
Validation loss: 2.3653888625483357

Epoch: 6| Step: 8
Training loss: 2.7854719161987305
Validation loss: 2.359527216162733

Epoch: 6| Step: 9
Training loss: 1.7742102146148682
Validation loss: 2.366327767731041

Epoch: 6| Step: 10
Training loss: 2.3066928386688232
Validation loss: 2.3621640461747364

Epoch: 6| Step: 11
Training loss: 2.273233413696289
Validation loss: 2.3580447704561296

Epoch: 6| Step: 12
Training loss: 2.1191866397857666
Validation loss: 2.3611910138078915

Epoch: 6| Step: 13
Training loss: 1.6125609874725342
Validation loss: 2.3386892285398257

Epoch: 163| Step: 0
Training loss: 2.6940841674804688
Validation loss: 2.3314062446676274

Epoch: 6| Step: 1
Training loss: 1.5690643787384033
Validation loss: 2.3362115352384505

Epoch: 6| Step: 2
Training loss: 3.255326747894287
Validation loss: 2.344373156947474

Epoch: 6| Step: 3
Training loss: 2.8644626140594482
Validation loss: 2.3493792754347607

Epoch: 6| Step: 4
Training loss: 3.404123067855835
Validation loss: 2.3548776949605634

Epoch: 6| Step: 5
Training loss: 3.1107442378997803
Validation loss: 2.3548591547114874

Epoch: 6| Step: 6
Training loss: 2.675222396850586
Validation loss: 2.3500521618832826

Epoch: 6| Step: 7
Training loss: 2.353853940963745
Validation loss: 2.3462099567536385

Epoch: 6| Step: 8
Training loss: 2.5934677124023438
Validation loss: 2.348692532508604

Epoch: 6| Step: 9
Training loss: 1.535284161567688
Validation loss: 2.3416788167850946

Epoch: 6| Step: 10
Training loss: 2.4715402126312256
Validation loss: 2.3409355378920034

Epoch: 6| Step: 11
Training loss: 2.252106189727783
Validation loss: 2.3318865427406887

Epoch: 6| Step: 12
Training loss: 2.8834218978881836
Validation loss: 2.333845733314432

Epoch: 6| Step: 13
Training loss: 2.424887180328369
Validation loss: 2.3332098837821715

Epoch: 164| Step: 0
Training loss: 2.7763447761535645
Validation loss: 2.3390910471639326

Epoch: 6| Step: 1
Training loss: 2.120512008666992
Validation loss: 2.341011804919089

Epoch: 6| Step: 2
Training loss: 2.187716007232666
Validation loss: 2.3472607289591143

Epoch: 6| Step: 3
Training loss: 2.52303409576416
Validation loss: 2.3410850083956154

Epoch: 6| Step: 4
Training loss: 2.322251081466675
Validation loss: 2.3518717878608295

Epoch: 6| Step: 5
Training loss: 2.7741358280181885
Validation loss: 2.34767884080128

Epoch: 6| Step: 6
Training loss: 3.5159013271331787
Validation loss: 2.352015831137216

Epoch: 6| Step: 7
Training loss: 1.8985753059387207
Validation loss: 2.341517097206526

Epoch: 6| Step: 8
Training loss: 2.9148521423339844
Validation loss: 2.3405398297053512

Epoch: 6| Step: 9
Training loss: 2.3816721439361572
Validation loss: 2.3325917618249052

Epoch: 6| Step: 10
Training loss: 2.8704190254211426
Validation loss: 2.3364561680824525

Epoch: 6| Step: 11
Training loss: 2.1822569370269775
Validation loss: 2.32169605839637

Epoch: 6| Step: 12
Training loss: 2.578270673751831
Validation loss: 2.3270104059609036

Epoch: 6| Step: 13
Training loss: 3.257430076599121
Validation loss: 2.33525171074816

Epoch: 165| Step: 0
Training loss: 1.8777217864990234
Validation loss: 2.3366302649180093

Epoch: 6| Step: 1
Training loss: 2.528486728668213
Validation loss: 2.3615196315191125

Epoch: 6| Step: 2
Training loss: 2.731564521789551
Validation loss: 2.3563193069991244

Epoch: 6| Step: 3
Training loss: 2.8172640800476074
Validation loss: 2.3643868918059976

Epoch: 6| Step: 4
Training loss: 3.1816158294677734
Validation loss: 2.3604852845591884

Epoch: 6| Step: 5
Training loss: 1.8655128479003906
Validation loss: 2.3529778065220004

Epoch: 6| Step: 6
Training loss: 2.4618825912475586
Validation loss: 2.3466935670504006

Epoch: 6| Step: 7
Training loss: 2.9826316833496094
Validation loss: 2.3359665511756815

Epoch: 6| Step: 8
Training loss: 3.116783857345581
Validation loss: 2.329751927365539

Epoch: 6| Step: 9
Training loss: 2.7172341346740723
Validation loss: 2.334169808254447

Epoch: 6| Step: 10
Training loss: 2.6175379753112793
Validation loss: 2.3222646508165585

Epoch: 6| Step: 11
Training loss: 2.201303005218506
Validation loss: 2.3277093582255866

Epoch: 6| Step: 12
Training loss: 2.2568235397338867
Validation loss: 2.319198223852342

Epoch: 6| Step: 13
Training loss: 2.537388324737549
Validation loss: 2.3295880338197112

Epoch: 166| Step: 0
Training loss: 1.7389402389526367
Validation loss: 2.3269110110498246

Epoch: 6| Step: 1
Training loss: 2.5973501205444336
Validation loss: 2.3254401965807845

Epoch: 6| Step: 2
Training loss: 3.0185117721557617
Validation loss: 2.3291628694021576

Epoch: 6| Step: 3
Training loss: 2.5198986530303955
Validation loss: 2.3304961317329

Epoch: 6| Step: 4
Training loss: 2.730670213699341
Validation loss: 2.3357845147450766

Epoch: 6| Step: 5
Training loss: 2.3846912384033203
Validation loss: 2.329386467574745

Epoch: 6| Step: 6
Training loss: 3.2092947959899902
Validation loss: 2.3292409963505243

Epoch: 6| Step: 7
Training loss: 2.812790632247925
Validation loss: 2.332064067163775

Epoch: 6| Step: 8
Training loss: 2.187081813812256
Validation loss: 2.319898109282217

Epoch: 6| Step: 9
Training loss: 3.2707111835479736
Validation loss: 2.31900954246521

Epoch: 6| Step: 10
Training loss: 3.064060688018799
Validation loss: 2.3202651290483374

Epoch: 6| Step: 11
Training loss: 2.563673734664917
Validation loss: 2.3161677750208045

Epoch: 6| Step: 12
Training loss: 1.266723394393921
Validation loss: 2.3166148201111825

Epoch: 6| Step: 13
Training loss: 2.608745574951172
Validation loss: 2.3161729228112007

Epoch: 167| Step: 0
Training loss: 2.454497814178467
Validation loss: 2.3206783904824206

Epoch: 6| Step: 1
Training loss: 2.86698579788208
Validation loss: 2.319787827871179

Epoch: 6| Step: 2
Training loss: 2.380441665649414
Validation loss: 2.3190759689577165

Epoch: 6| Step: 3
Training loss: 2.491487503051758
Validation loss: 2.3257291368258897

Epoch: 6| Step: 4
Training loss: 2.886651039123535
Validation loss: 2.334137321800314

Epoch: 6| Step: 5
Training loss: 2.421144485473633
Validation loss: 2.339558893634427

Epoch: 6| Step: 6
Training loss: 2.9832282066345215
Validation loss: 2.339062388225268

Epoch: 6| Step: 7
Training loss: 2.6312427520751953
Validation loss: 2.3405071484145297

Epoch: 6| Step: 8
Training loss: 2.5208957195281982
Validation loss: 2.35892217902727

Epoch: 6| Step: 9
Training loss: 2.132805109024048
Validation loss: 2.3703128881351923

Epoch: 6| Step: 10
Training loss: 2.6197011470794678
Validation loss: 2.374146451232254

Epoch: 6| Step: 11
Training loss: 2.81510066986084
Validation loss: 2.381212265260758

Epoch: 6| Step: 12
Training loss: 2.476311683654785
Validation loss: 2.371410910801221

Epoch: 6| Step: 13
Training loss: 2.2552990913391113
Validation loss: 2.3642000754674277

Epoch: 168| Step: 0
Training loss: 2.9966421127319336
Validation loss: 2.3454855924011557

Epoch: 6| Step: 1
Training loss: 1.9238885641098022
Validation loss: 2.3400789217282365

Epoch: 6| Step: 2
Training loss: 2.1806769371032715
Validation loss: 2.3407720596559587

Epoch: 6| Step: 3
Training loss: 2.3583011627197266
Validation loss: 2.3218682466014737

Epoch: 6| Step: 4
Training loss: 3.6632513999938965
Validation loss: 2.3239257181844404

Epoch: 6| Step: 5
Training loss: 2.315131664276123
Validation loss: 2.322010483793033

Epoch: 6| Step: 6
Training loss: 3.1546425819396973
Validation loss: 2.3186957118331746

Epoch: 6| Step: 7
Training loss: 1.9390233755111694
Validation loss: 2.320538361867269

Epoch: 6| Step: 8
Training loss: 2.7170588970184326
Validation loss: 2.3145918487220682

Epoch: 6| Step: 9
Training loss: 2.869476795196533
Validation loss: 2.3191456461465485

Epoch: 6| Step: 10
Training loss: 2.2267074584960938
Validation loss: 2.3261587094235163

Epoch: 6| Step: 11
Training loss: 2.0762710571289062
Validation loss: 2.3295822899828673

Epoch: 6| Step: 12
Training loss: 3.347905158996582
Validation loss: 2.324306644419188

Epoch: 6| Step: 13
Training loss: 1.6276240348815918
Validation loss: 2.31428163795061

Epoch: 169| Step: 0
Training loss: 3.2629451751708984
Validation loss: 2.319853427589581

Epoch: 6| Step: 1
Training loss: 2.1757071018218994
Validation loss: 2.32434558099316

Epoch: 6| Step: 2
Training loss: 2.9229297637939453
Validation loss: 2.3335020131962274

Epoch: 6| Step: 3
Training loss: 2.174027442932129
Validation loss: 2.3324580090020293

Epoch: 6| Step: 4
Training loss: 2.4111266136169434
Validation loss: 2.334629386983892

Epoch: 6| Step: 5
Training loss: 2.8549246788024902
Validation loss: 2.3358730449471423

Epoch: 6| Step: 6
Training loss: 2.324221134185791
Validation loss: 2.3440086918492473

Epoch: 6| Step: 7
Training loss: 2.653029441833496
Validation loss: 2.350967432862969

Epoch: 6| Step: 8
Training loss: 2.8019793033599854
Validation loss: 2.3551600799765637

Epoch: 6| Step: 9
Training loss: 2.0352962017059326
Validation loss: 2.354232008739184

Epoch: 6| Step: 10
Training loss: 2.438889980316162
Validation loss: 2.351206592334214

Epoch: 6| Step: 11
Training loss: 2.9857468605041504
Validation loss: 2.3474524636422434

Epoch: 6| Step: 12
Training loss: 2.170638084411621
Validation loss: 2.3590323540472213

Epoch: 6| Step: 13
Training loss: 2.8355586528778076
Validation loss: 2.349695828653151

Epoch: 170| Step: 0
Training loss: 1.9259439706802368
Validation loss: 2.351922268508583

Epoch: 6| Step: 1
Training loss: 2.413120985031128
Validation loss: 2.356741759084886

Epoch: 6| Step: 2
Training loss: 2.584441900253296
Validation loss: 2.3575211596745316

Epoch: 6| Step: 3
Training loss: 3.357766628265381
Validation loss: 2.351827065149943

Epoch: 6| Step: 4
Training loss: 2.8103041648864746
Validation loss: 2.348471244176229

Epoch: 6| Step: 5
Training loss: 2.994401216506958
Validation loss: 2.3409644711402153

Epoch: 6| Step: 6
Training loss: 3.672956943511963
Validation loss: 2.3332795250800347

Epoch: 6| Step: 7
Training loss: 2.2138895988464355
Validation loss: 2.3316478267792733

Epoch: 6| Step: 8
Training loss: 2.1670331954956055
Validation loss: 2.32671707676303

Epoch: 6| Step: 9
Training loss: 2.2297301292419434
Validation loss: 2.31955712585039

Epoch: 6| Step: 10
Training loss: 2.5488452911376953
Validation loss: 2.316591256408281

Epoch: 6| Step: 11
Training loss: 1.8909791707992554
Validation loss: 2.3132386117853145

Epoch: 6| Step: 12
Training loss: 2.9820070266723633
Validation loss: 2.318036135806832

Epoch: 6| Step: 13
Training loss: 1.951576828956604
Validation loss: 2.3166296815359466

Epoch: 171| Step: 0
Training loss: 2.8022313117980957
Validation loss: 2.315409614193824

Epoch: 6| Step: 1
Training loss: 2.5788557529449463
Validation loss: 2.328452297436294

Epoch: 6| Step: 2
Training loss: 3.3871800899505615
Validation loss: 2.329948058692358

Epoch: 6| Step: 3
Training loss: 2.1319398880004883
Validation loss: 2.3280453092308453

Epoch: 6| Step: 4
Training loss: 2.0654966831207275
Validation loss: 2.327644532726657

Epoch: 6| Step: 5
Training loss: 2.3792874813079834
Validation loss: 2.328302970496557

Epoch: 6| Step: 6
Training loss: 1.7993173599243164
Validation loss: 2.334680708505774

Epoch: 6| Step: 7
Training loss: 3.2816519737243652
Validation loss: 2.334121737428891

Epoch: 6| Step: 8
Training loss: 2.0210745334625244
Validation loss: 2.328954678709789

Epoch: 6| Step: 9
Training loss: 3.4054927825927734
Validation loss: 2.3274740736971617

Epoch: 6| Step: 10
Training loss: 2.5198755264282227
Validation loss: 2.3241842459606867

Epoch: 6| Step: 11
Training loss: 1.9094313383102417
Validation loss: 2.319049912114297

Epoch: 6| Step: 12
Training loss: 2.750610828399658
Validation loss: 2.3150542525834936

Epoch: 6| Step: 13
Training loss: 2.8443896770477295
Validation loss: 2.3125333991101993

Epoch: 172| Step: 0
Training loss: 2.4101099967956543
Validation loss: 2.316652754301666

Epoch: 6| Step: 1
Training loss: 3.3506953716278076
Validation loss: 2.3221993113076813

Epoch: 6| Step: 2
Training loss: 2.2951712608337402
Validation loss: 2.3388474218307005

Epoch: 6| Step: 3
Training loss: 2.1843271255493164
Validation loss: 2.329739514217582

Epoch: 6| Step: 4
Training loss: 2.1561293601989746
Validation loss: 2.3377553775746334

Epoch: 6| Step: 5
Training loss: 2.195798873901367
Validation loss: 2.316709505614414

Epoch: 6| Step: 6
Training loss: 2.1491520404815674
Validation loss: 2.3217137757168023

Epoch: 6| Step: 7
Training loss: 2.8333849906921387
Validation loss: 2.317817344460436

Epoch: 6| Step: 8
Training loss: 2.957465171813965
Validation loss: 2.320932972815729

Epoch: 6| Step: 9
Training loss: 2.3080801963806152
Validation loss: 2.3232137285253054

Epoch: 6| Step: 10
Training loss: 2.315326690673828
Validation loss: 2.321727183557326

Epoch: 6| Step: 11
Training loss: 3.2460508346557617
Validation loss: 2.322086934120424

Epoch: 6| Step: 12
Training loss: 2.1720633506774902
Validation loss: 2.3152539268616708

Epoch: 6| Step: 13
Training loss: 3.7040159702301025
Validation loss: 2.3171223901933238

Epoch: 173| Step: 0
Training loss: 2.827712297439575
Validation loss: 2.320733565156178

Epoch: 6| Step: 1
Training loss: 2.4860422611236572
Validation loss: 2.3130187731917187

Epoch: 6| Step: 2
Training loss: 2.415619373321533
Validation loss: 2.31822540426767

Epoch: 6| Step: 3
Training loss: 2.181509494781494
Validation loss: 2.328521554188062

Epoch: 6| Step: 4
Training loss: 2.9035000801086426
Validation loss: 2.334608272839618

Epoch: 6| Step: 5
Training loss: 2.5155224800109863
Validation loss: 2.322502830977081

Epoch: 6| Step: 6
Training loss: 2.0348100662231445
Validation loss: 2.3177068092489757

Epoch: 6| Step: 7
Training loss: 2.3331527709960938
Validation loss: 2.3327952636185514

Epoch: 6| Step: 8
Training loss: 3.3919882774353027
Validation loss: 2.322290325677523

Epoch: 6| Step: 9
Training loss: 2.858401298522949
Validation loss: 2.3156970906001266

Epoch: 6| Step: 10
Training loss: 3.150275707244873
Validation loss: 2.3148790098005727

Epoch: 6| Step: 11
Training loss: 2.0644338130950928
Validation loss: 2.319434815837491

Epoch: 6| Step: 12
Training loss: 2.0477774143218994
Validation loss: 2.3061920122433732

Epoch: 6| Step: 13
Training loss: 2.852818489074707
Validation loss: 2.310440509550033

Epoch: 174| Step: 0
Training loss: 3.287810802459717
Validation loss: 2.314857393182734

Epoch: 6| Step: 1
Training loss: 2.005936622619629
Validation loss: 2.3163759452040478

Epoch: 6| Step: 2
Training loss: 2.97723388671875
Validation loss: 2.3171797798525904

Epoch: 6| Step: 3
Training loss: 2.1992061138153076
Validation loss: 2.317334723728959

Epoch: 6| Step: 4
Training loss: 2.0430455207824707
Validation loss: 2.311615087652719

Epoch: 6| Step: 5
Training loss: 2.5904009342193604
Validation loss: 2.315626649446385

Epoch: 6| Step: 6
Training loss: 2.9753565788269043
Validation loss: 2.312270284980856

Epoch: 6| Step: 7
Training loss: 2.8060848712921143
Validation loss: 2.3121703311961186

Epoch: 6| Step: 8
Training loss: 3.0215845108032227
Validation loss: 2.3230235115174325

Epoch: 6| Step: 9
Training loss: 2.6456122398376465
Validation loss: 2.3175367052837084

Epoch: 6| Step: 10
Training loss: 2.505601406097412
Validation loss: 2.3195771555746756

Epoch: 6| Step: 11
Training loss: 1.8046399354934692
Validation loss: 2.3277049603000766

Epoch: 6| Step: 12
Training loss: 2.6571545600891113
Validation loss: 2.33058992508919

Epoch: 6| Step: 13
Training loss: 2.350276470184326
Validation loss: 2.344816275822219

Epoch: 175| Step: 0
Training loss: 2.3259437084198
Validation loss: 2.3397689045116468

Epoch: 6| Step: 1
Training loss: 3.083425283432007
Validation loss: 2.3380636707428963

Epoch: 6| Step: 2
Training loss: 1.9195127487182617
Validation loss: 2.3257532196660198

Epoch: 6| Step: 3
Training loss: 2.3848977088928223
Validation loss: 2.316313656427527

Epoch: 6| Step: 4
Training loss: 2.1416475772857666
Validation loss: 2.3184578047003797

Epoch: 6| Step: 5
Training loss: 2.1901144981384277
Validation loss: 2.299622569032895

Epoch: 6| Step: 6
Training loss: 1.925755500793457
Validation loss: 2.2990785888446275

Epoch: 6| Step: 7
Training loss: 2.263962745666504
Validation loss: 2.298804545915255

Epoch: 6| Step: 8
Training loss: 2.941037654876709
Validation loss: 2.295299285201616

Epoch: 6| Step: 9
Training loss: 2.928750514984131
Validation loss: 2.2944264783654162

Epoch: 6| Step: 10
Training loss: 3.720566987991333
Validation loss: 2.2996772860967987

Epoch: 6| Step: 11
Training loss: 3.0398619174957275
Validation loss: 2.3072374072126163

Epoch: 6| Step: 12
Training loss: 2.2459769248962402
Validation loss: 2.30152952542869

Epoch: 6| Step: 13
Training loss: 3.170701026916504
Validation loss: 2.3022097900349605

Epoch: 176| Step: 0
Training loss: 2.5156779289245605
Validation loss: 2.293277768678563

Epoch: 6| Step: 1
Training loss: 2.4851419925689697
Validation loss: 2.2971532344818115

Epoch: 6| Step: 2
Training loss: 2.314218521118164
Validation loss: 2.3022399628034202

Epoch: 6| Step: 3
Training loss: 3.172085762023926
Validation loss: 2.2928583314341884

Epoch: 6| Step: 4
Training loss: 2.4392380714416504
Validation loss: 2.305328663959298

Epoch: 6| Step: 5
Training loss: 3.1836585998535156
Validation loss: 2.309572660794822

Epoch: 6| Step: 6
Training loss: 1.2688498497009277
Validation loss: 2.319061335696969

Epoch: 6| Step: 7
Training loss: 2.7039365768432617
Validation loss: 2.327095603430143

Epoch: 6| Step: 8
Training loss: 1.7353183031082153
Validation loss: 2.32586649797296

Epoch: 6| Step: 9
Training loss: 3.001735210418701
Validation loss: 2.3392363261151057

Epoch: 6| Step: 10
Training loss: 2.869358539581299
Validation loss: 2.3479432905873945

Epoch: 6| Step: 11
Training loss: 2.5052685737609863
Validation loss: 2.3400698400312856

Epoch: 6| Step: 12
Training loss: 2.913799285888672
Validation loss: 2.3418888930351502

Epoch: 6| Step: 13
Training loss: 2.634812355041504
Validation loss: 2.3427841048086844

Epoch: 177| Step: 0
Training loss: 2.320708751678467
Validation loss: 2.3504410277130785

Epoch: 6| Step: 1
Training loss: 2.463188886642456
Validation loss: 2.3566447663050827

Epoch: 6| Step: 2
Training loss: 3.2676405906677246
Validation loss: 2.3569298277619066

Epoch: 6| Step: 3
Training loss: 2.8143773078918457
Validation loss: 2.3575418533817416

Epoch: 6| Step: 4
Training loss: 2.272603750228882
Validation loss: 2.352849906490695

Epoch: 6| Step: 5
Training loss: 2.0908846855163574
Validation loss: 2.363266396266158

Epoch: 6| Step: 6
Training loss: 3.4106948375701904
Validation loss: 2.3668638326788463

Epoch: 6| Step: 7
Training loss: 2.209256172180176
Validation loss: 2.3720265972998833

Epoch: 6| Step: 8
Training loss: 2.1300883293151855
Validation loss: 2.3599223013847106

Epoch: 6| Step: 9
Training loss: 2.563321590423584
Validation loss: 2.358013173585297

Epoch: 6| Step: 10
Training loss: 2.966550350189209
Validation loss: 2.339078676316046

Epoch: 6| Step: 11
Training loss: 1.8866913318634033
Validation loss: 2.3269160383491108

Epoch: 6| Step: 12
Training loss: 2.207169532775879
Validation loss: 2.329748135741039

Epoch: 6| Step: 13
Training loss: 3.5847880840301514
Validation loss: 2.309850400493991

Epoch: 178| Step: 0
Training loss: 2.877730369567871
Validation loss: 2.3059057997119043

Epoch: 6| Step: 1
Training loss: 3.317780017852783
Validation loss: 2.303426191370974

Epoch: 6| Step: 2
Training loss: 2.776533842086792
Validation loss: 2.3006151389050227

Epoch: 6| Step: 3
Training loss: 2.2849345207214355
Validation loss: 2.296863871236001

Epoch: 6| Step: 4
Training loss: 2.7334182262420654
Validation loss: 2.2952477598703034

Epoch: 6| Step: 5
Training loss: 3.004563808441162
Validation loss: 2.298609613090433

Epoch: 6| Step: 6
Training loss: 1.9630132913589478
Validation loss: 2.3012498142898723

Epoch: 6| Step: 7
Training loss: 2.590481996536255
Validation loss: 2.3036739108383015

Epoch: 6| Step: 8
Training loss: 2.459890365600586
Validation loss: 2.297464883455666

Epoch: 6| Step: 9
Training loss: 2.512704849243164
Validation loss: 2.304636178478118

Epoch: 6| Step: 10
Training loss: 1.8224502801895142
Validation loss: 2.2932425134925434

Epoch: 6| Step: 11
Training loss: 2.840412139892578
Validation loss: 2.298898281589631

Epoch: 6| Step: 12
Training loss: 2.2537214756011963
Validation loss: 2.2972280184427896

Epoch: 6| Step: 13
Training loss: 2.245438575744629
Validation loss: 2.2883006398395827

Epoch: 179| Step: 0
Training loss: 2.430300712585449
Validation loss: 2.289121248388803

Epoch: 6| Step: 1
Training loss: 2.2260451316833496
Validation loss: 2.2946378261812272

Epoch: 6| Step: 2
Training loss: 2.531771183013916
Validation loss: 2.293065232615317

Epoch: 6| Step: 3
Training loss: 2.9033846855163574
Validation loss: 2.2981862342485817

Epoch: 6| Step: 4
Training loss: 2.7093849182128906
Validation loss: 2.306916562459802

Epoch: 6| Step: 5
Training loss: 3.0970101356506348
Validation loss: 2.299379607682587

Epoch: 6| Step: 6
Training loss: 2.019753932952881
Validation loss: 2.3008274339860484

Epoch: 6| Step: 7
Training loss: 2.6764652729034424
Validation loss: 2.302427737943588

Epoch: 6| Step: 8
Training loss: 2.424208164215088
Validation loss: 2.301779447063323

Epoch: 6| Step: 9
Training loss: 2.1506290435791016
Validation loss: 2.302378672425465

Epoch: 6| Step: 10
Training loss: 2.7923169136047363
Validation loss: 2.3130230570352204

Epoch: 6| Step: 11
Training loss: 2.9563846588134766
Validation loss: 2.310026753333307

Epoch: 6| Step: 12
Training loss: 2.523642063140869
Validation loss: 2.3178296319900022

Epoch: 6| Step: 13
Training loss: 2.110175132751465
Validation loss: 2.310705933519589

Epoch: 180| Step: 0
Training loss: 2.9965639114379883
Validation loss: 2.3171221543383855

Epoch: 6| Step: 1
Training loss: 2.6180567741394043
Validation loss: 2.3255553091725996

Epoch: 6| Step: 2
Training loss: 2.323011875152588
Validation loss: 2.320661473017867

Epoch: 6| Step: 3
Training loss: 2.5381808280944824
Validation loss: 2.33899268796367

Epoch: 6| Step: 4
Training loss: 3.456169605255127
Validation loss: 2.3451711618772118

Epoch: 6| Step: 5
Training loss: 2.8331427574157715
Validation loss: 2.3339627019820677

Epoch: 6| Step: 6
Training loss: 2.6521902084350586
Validation loss: 2.333521742974558

Epoch: 6| Step: 7
Training loss: 2.811751365661621
Validation loss: 2.3279730709650184

Epoch: 6| Step: 8
Training loss: 1.9615979194641113
Validation loss: 2.3219634281691683

Epoch: 6| Step: 9
Training loss: 2.1152501106262207
Validation loss: 2.331513815028693

Epoch: 6| Step: 10
Training loss: 1.9306151866912842
Validation loss: 2.329255570647537

Epoch: 6| Step: 11
Training loss: 1.997694969177246
Validation loss: 2.309841143187656

Epoch: 6| Step: 12
Training loss: 2.6562209129333496
Validation loss: 2.3190877206863894

Epoch: 6| Step: 13
Training loss: 2.8945446014404297
Validation loss: 2.322922747622254

Epoch: 181| Step: 0
Training loss: 2.9250311851501465
Validation loss: 2.321556960382769

Epoch: 6| Step: 1
Training loss: 2.334671974182129
Validation loss: 2.31576991978512

Epoch: 6| Step: 2
Training loss: 1.9475257396697998
Validation loss: 2.3141345003599763

Epoch: 6| Step: 3
Training loss: 2.700932025909424
Validation loss: 2.313794856430382

Epoch: 6| Step: 4
Training loss: 3.3683886528015137
Validation loss: 2.3058200677235923

Epoch: 6| Step: 5
Training loss: 2.4535248279571533
Validation loss: 2.301329046167353

Epoch: 6| Step: 6
Training loss: 2.7957684993743896
Validation loss: 2.3030471417211715

Epoch: 6| Step: 7
Training loss: 2.943004608154297
Validation loss: 2.3040137675500687

Epoch: 6| Step: 8
Training loss: 2.7520275115966797
Validation loss: 2.296415623798165

Epoch: 6| Step: 9
Training loss: 2.504215717315674
Validation loss: 2.2977482529096704

Epoch: 6| Step: 10
Training loss: 1.9459786415100098
Validation loss: 2.302054279594011

Epoch: 6| Step: 11
Training loss: 2.1842730045318604
Validation loss: 2.3230859143759615

Epoch: 6| Step: 12
Training loss: 2.259566307067871
Validation loss: 2.3475354102350052

Epoch: 6| Step: 13
Training loss: 2.450982093811035
Validation loss: 2.3569934368133545

Epoch: 182| Step: 0
Training loss: 2.3688974380493164
Validation loss: 2.349270356598721

Epoch: 6| Step: 1
Training loss: 2.1429033279418945
Validation loss: 2.3443451748099378

Epoch: 6| Step: 2
Training loss: 2.2714853286743164
Validation loss: 2.3444869031188307

Epoch: 6| Step: 3
Training loss: 2.717350482940674
Validation loss: 2.3182415539218533

Epoch: 6| Step: 4
Training loss: 1.7497670650482178
Validation loss: 2.3096688050095753

Epoch: 6| Step: 5
Training loss: 2.731611490249634
Validation loss: 2.2940385328826083

Epoch: 6| Step: 6
Training loss: 3.031752347946167
Validation loss: 2.294037188253095

Epoch: 6| Step: 7
Training loss: 2.599579334259033
Validation loss: 2.2947374236199165

Epoch: 6| Step: 8
Training loss: 2.5386548042297363
Validation loss: 2.2950931108126076

Epoch: 6| Step: 9
Training loss: 2.0707101821899414
Validation loss: 2.2918826687720513

Epoch: 6| Step: 10
Training loss: 3.004838228225708
Validation loss: 2.2948325987785094

Epoch: 6| Step: 11
Training loss: 3.8172037601470947
Validation loss: 2.283726361490065

Epoch: 6| Step: 12
Training loss: 2.208434820175171
Validation loss: 2.3008411084451983

Epoch: 6| Step: 13
Training loss: 2.3549017906188965
Validation loss: 2.287182133684876

Epoch: 183| Step: 0
Training loss: 3.120509147644043
Validation loss: 2.2942113953251995

Epoch: 6| Step: 1
Training loss: 2.0034196376800537
Validation loss: 2.2991149502415813

Epoch: 6| Step: 2
Training loss: 2.3583667278289795
Validation loss: 2.2954190085011144

Epoch: 6| Step: 3
Training loss: 2.6038918495178223
Validation loss: 2.2841167578133206

Epoch: 6| Step: 4
Training loss: 2.0969185829162598
Validation loss: 2.293105976555937

Epoch: 6| Step: 5
Training loss: 2.6109113693237305
Validation loss: 2.2896353647273076

Epoch: 6| Step: 6
Training loss: 2.4953317642211914
Validation loss: 2.2900904737493044

Epoch: 6| Step: 7
Training loss: 2.391584873199463
Validation loss: 2.2925324901457755

Epoch: 6| Step: 8
Training loss: 2.8324079513549805
Validation loss: 2.2944664442411034

Epoch: 6| Step: 9
Training loss: 3.091801643371582
Validation loss: 2.290039365009595

Epoch: 6| Step: 10
Training loss: 2.8631739616394043
Validation loss: 2.285511460355533

Epoch: 6| Step: 11
Training loss: 2.271740198135376
Validation loss: 2.2926085379815873

Epoch: 6| Step: 12
Training loss: 2.7872183322906494
Validation loss: 2.299901682843444

Epoch: 6| Step: 13
Training loss: 1.5842013359069824
Validation loss: 2.2891677938481814

Epoch: 184| Step: 0
Training loss: 2.5271968841552734
Validation loss: 2.2820414932825233

Epoch: 6| Step: 1
Training loss: 2.4612011909484863
Validation loss: 2.2886443497032247

Epoch: 6| Step: 2
Training loss: 2.3588647842407227
Validation loss: 2.2911239977805846

Epoch: 6| Step: 3
Training loss: 2.9073643684387207
Validation loss: 2.295485947721748

Epoch: 6| Step: 4
Training loss: 2.5394554138183594
Validation loss: 2.2852287164298435

Epoch: 6| Step: 5
Training loss: 2.1406188011169434
Validation loss: 2.291765801368221

Epoch: 6| Step: 6
Training loss: 2.5070526599884033
Validation loss: 2.293226331792852

Epoch: 6| Step: 7
Training loss: 2.334850311279297
Validation loss: 2.294719103843935

Epoch: 6| Step: 8
Training loss: 2.5656991004943848
Validation loss: 2.3074886798858643

Epoch: 6| Step: 9
Training loss: 2.8677663803100586
Validation loss: 2.3056800724357687

Epoch: 6| Step: 10
Training loss: 2.334653377532959
Validation loss: 2.303697855241837

Epoch: 6| Step: 11
Training loss: 2.614386558532715
Validation loss: 2.2981710946688088

Epoch: 6| Step: 12
Training loss: 2.6265671253204346
Validation loss: 2.302676787940405

Epoch: 6| Step: 13
Training loss: 2.7985634803771973
Validation loss: 2.296337894214097

Epoch: 185| Step: 0
Training loss: 2.7607738971710205
Validation loss: 2.2935789861986713

Epoch: 6| Step: 1
Training loss: 2.760619640350342
Validation loss: 2.3002181873526624

Epoch: 6| Step: 2
Training loss: 2.2717535495758057
Validation loss: 2.280133503739552

Epoch: 6| Step: 3
Training loss: 2.3145039081573486
Validation loss: 2.288041426289466

Epoch: 6| Step: 4
Training loss: 2.756229877471924
Validation loss: 2.2877411047617593

Epoch: 6| Step: 5
Training loss: 3.52703595161438
Validation loss: 2.290578878054055

Epoch: 6| Step: 6
Training loss: 2.127748727798462
Validation loss: 2.2933660425165647

Epoch: 6| Step: 7
Training loss: 2.5122203826904297
Validation loss: 2.295715690940939

Epoch: 6| Step: 8
Training loss: 2.1838035583496094
Validation loss: 2.295067684624785

Epoch: 6| Step: 9
Training loss: 2.4825193881988525
Validation loss: 2.295968778671757

Epoch: 6| Step: 10
Training loss: 2.3501906394958496
Validation loss: 2.2924131834378807

Epoch: 6| Step: 11
Training loss: 2.3502838611602783
Validation loss: 2.288623907232797

Epoch: 6| Step: 12
Training loss: 2.724155902862549
Validation loss: 2.293295462926229

Epoch: 6| Step: 13
Training loss: 2.122169017791748
Validation loss: 2.2958944305296867

Epoch: 186| Step: 0
Training loss: 3.193783760070801
Validation loss: 2.2979068474103044

Epoch: 6| Step: 1
Training loss: 2.6903655529022217
Validation loss: 2.3049127594117196

Epoch: 6| Step: 2
Training loss: 2.1577553749084473
Validation loss: 2.3210104806448824

Epoch: 6| Step: 3
Training loss: 2.2917885780334473
Validation loss: 2.319188587127193

Epoch: 6| Step: 4
Training loss: 2.261096954345703
Validation loss: 2.324479805525913

Epoch: 6| Step: 5
Training loss: 2.576737880706787
Validation loss: 2.331500199533278

Epoch: 6| Step: 6
Training loss: 2.197526454925537
Validation loss: 2.3312363240026657

Epoch: 6| Step: 7
Training loss: 2.8940720558166504
Validation loss: 2.3297480049953667

Epoch: 6| Step: 8
Training loss: 2.6535885334014893
Validation loss: 2.316249742302843

Epoch: 6| Step: 9
Training loss: 2.0405449867248535
Validation loss: 2.308735373199627

Epoch: 6| Step: 10
Training loss: 2.4744887351989746
Validation loss: 2.30508376449667

Epoch: 6| Step: 11
Training loss: 2.4877285957336426
Validation loss: 2.287371084254275

Epoch: 6| Step: 12
Training loss: 3.1773862838745117
Validation loss: 2.282886084689889

Epoch: 6| Step: 13
Training loss: 2.407541513442993
Validation loss: 2.2905883045606714

Epoch: 187| Step: 0
Training loss: 3.384317636489868
Validation loss: 2.2858540473445768

Epoch: 6| Step: 1
Training loss: 2.3694190979003906
Validation loss: 2.301642105143557

Epoch: 6| Step: 2
Training loss: 2.446810245513916
Validation loss: 2.296847636981677

Epoch: 6| Step: 3
Training loss: 2.2237000465393066
Validation loss: 2.300411585838564

Epoch: 6| Step: 4
Training loss: 1.8982433080673218
Validation loss: 2.3071364907808203

Epoch: 6| Step: 5
Training loss: 2.711146593093872
Validation loss: 2.3110463003958426

Epoch: 6| Step: 6
Training loss: 3.132707118988037
Validation loss: 2.309086081802204

Epoch: 6| Step: 7
Training loss: 2.570861339569092
Validation loss: 2.310104913609002

Epoch: 6| Step: 8
Training loss: 2.6009793281555176
Validation loss: 2.308228764482724

Epoch: 6| Step: 9
Training loss: 2.4016075134277344
Validation loss: 2.3145141293925624

Epoch: 6| Step: 10
Training loss: 2.2258787155151367
Validation loss: 2.309811281901534

Epoch: 6| Step: 11
Training loss: 2.4614293575286865
Validation loss: 2.309581628409765

Epoch: 6| Step: 12
Training loss: 2.7212085723876953
Validation loss: 2.3011652987490416

Epoch: 6| Step: 13
Training loss: 2.565721035003662
Validation loss: 2.3014296562440935

Epoch: 188| Step: 0
Training loss: 2.4542040824890137
Validation loss: 2.3098708506553405

Epoch: 6| Step: 1
Training loss: 2.1467413902282715
Validation loss: 2.3102208696385866

Epoch: 6| Step: 2
Training loss: 2.831761360168457
Validation loss: 2.297582882706837

Epoch: 6| Step: 3
Training loss: 2.102123498916626
Validation loss: 2.294940810049734

Epoch: 6| Step: 4
Training loss: 2.9785051345825195
Validation loss: 2.2846486222359443

Epoch: 6| Step: 5
Training loss: 3.0992674827575684
Validation loss: 2.2778340654988445

Epoch: 6| Step: 6
Training loss: 3.4127373695373535
Validation loss: 2.2700655178357194

Epoch: 6| Step: 7
Training loss: 1.931584358215332
Validation loss: 2.2734500849118797

Epoch: 6| Step: 8
Training loss: 2.259902000427246
Validation loss: 2.275225488088464

Epoch: 6| Step: 9
Training loss: 2.435851573944092
Validation loss: 2.2724490063164824

Epoch: 6| Step: 10
Training loss: 3.5347447395324707
Validation loss: 2.2723957364277174

Epoch: 6| Step: 11
Training loss: 1.5243115425109863
Validation loss: 2.263093871455039

Epoch: 6| Step: 12
Training loss: 2.4211390018463135
Validation loss: 2.2637362454527166

Epoch: 6| Step: 13
Training loss: 2.270911693572998
Validation loss: 2.264086720763996

Epoch: 189| Step: 0
Training loss: 2.748229503631592
Validation loss: 2.2573798446245092

Epoch: 6| Step: 1
Training loss: 2.985106945037842
Validation loss: 2.271394383522772

Epoch: 6| Step: 2
Training loss: 2.3517086505889893
Validation loss: 2.2749235296762116

Epoch: 6| Step: 3
Training loss: 2.370063304901123
Validation loss: 2.277202490837343

Epoch: 6| Step: 4
Training loss: 2.260530471801758
Validation loss: 2.275577909202986

Epoch: 6| Step: 5
Training loss: 2.618603229522705
Validation loss: 2.277718710642989

Epoch: 6| Step: 6
Training loss: 2.219223976135254
Validation loss: 2.2835987819138395

Epoch: 6| Step: 7
Training loss: 1.6898431777954102
Validation loss: 2.2935365374370287

Epoch: 6| Step: 8
Training loss: 2.417332649230957
Validation loss: 2.299405171025184

Epoch: 6| Step: 9
Training loss: 3.0162363052368164
Validation loss: 2.298668066660563

Epoch: 6| Step: 10
Training loss: 2.3595235347747803
Validation loss: 2.294619462823355

Epoch: 6| Step: 11
Training loss: 2.5324180126190186
Validation loss: 2.2965575777074343

Epoch: 6| Step: 12
Training loss: 2.888430595397949
Validation loss: 2.293320227694768

Epoch: 6| Step: 13
Training loss: 3.2679169178009033
Validation loss: 2.2962785126060568

Epoch: 190| Step: 0
Training loss: 2.053217887878418
Validation loss: 2.2914895396078787

Epoch: 6| Step: 1
Training loss: 2.7307040691375732
Validation loss: 2.29173441087046

Epoch: 6| Step: 2
Training loss: 2.4348936080932617
Validation loss: 2.293567531852312

Epoch: 6| Step: 3
Training loss: 2.6204404830932617
Validation loss: 2.2953596550931215

Epoch: 6| Step: 4
Training loss: 2.0550036430358887
Validation loss: 2.2826817779130835

Epoch: 6| Step: 5
Training loss: 3.174072742462158
Validation loss: 2.281747853884133

Epoch: 6| Step: 6
Training loss: 2.599991798400879
Validation loss: 2.2794528238234983

Epoch: 6| Step: 7
Training loss: 2.614935874938965
Validation loss: 2.2751027896840084

Epoch: 6| Step: 8
Training loss: 2.9511823654174805
Validation loss: 2.2844378076573855

Epoch: 6| Step: 9
Training loss: 2.6494991779327393
Validation loss: 2.2824741178943264

Epoch: 6| Step: 10
Training loss: 2.271470546722412
Validation loss: 2.299753342905352

Epoch: 6| Step: 11
Training loss: 2.156808614730835
Validation loss: 2.2912989111356836

Epoch: 6| Step: 12
Training loss: 2.237743854522705
Validation loss: 2.3036904027385097

Epoch: 6| Step: 13
Training loss: 2.9423866271972656
Validation loss: 2.309421472651984

Epoch: 191| Step: 0
Training loss: 2.155618667602539
Validation loss: 2.2984390925335627

Epoch: 6| Step: 1
Training loss: 2.9224061965942383
Validation loss: 2.309360311877343

Epoch: 6| Step: 2
Training loss: 2.0542750358581543
Validation loss: 2.308203202421947

Epoch: 6| Step: 3
Training loss: 2.3437113761901855
Validation loss: 2.3155986006541918

Epoch: 6| Step: 4
Training loss: 2.8116395473480225
Validation loss: 2.3122929014185423

Epoch: 6| Step: 5
Training loss: 2.351073980331421
Validation loss: 2.3158838659204464

Epoch: 6| Step: 6
Training loss: 3.177401304244995
Validation loss: 2.3153733694425194

Epoch: 6| Step: 7
Training loss: 2.2008533477783203
Validation loss: 2.3043615266840947

Epoch: 6| Step: 8
Training loss: 2.385751247406006
Validation loss: 2.3008083502451577

Epoch: 6| Step: 9
Training loss: 2.2849884033203125
Validation loss: 2.298169659030053

Epoch: 6| Step: 10
Training loss: 2.20623779296875
Validation loss: 2.2900467893128753

Epoch: 6| Step: 11
Training loss: 2.7987232208251953
Validation loss: 2.3010305076517086

Epoch: 6| Step: 12
Training loss: 2.6262083053588867
Validation loss: 2.300056901029361

Epoch: 6| Step: 13
Training loss: 3.273289442062378
Validation loss: 2.29212648253287

Epoch: 192| Step: 0
Training loss: 2.7146811485290527
Validation loss: 2.3032652255027526

Epoch: 6| Step: 1
Training loss: 2.387838363647461
Validation loss: 2.30127747853597

Epoch: 6| Step: 2
Training loss: 2.7509660720825195
Validation loss: 2.3021237311824674

Epoch: 6| Step: 3
Training loss: 1.9552193880081177
Validation loss: 2.31471791959578

Epoch: 6| Step: 4
Training loss: 1.8975334167480469
Validation loss: 2.310179018205212

Epoch: 6| Step: 5
Training loss: 2.6210875511169434
Validation loss: 2.31202430622552

Epoch: 6| Step: 6
Training loss: 2.5187923908233643
Validation loss: 2.325710740140689

Epoch: 6| Step: 7
Training loss: 3.4552416801452637
Validation loss: 2.3007428517905613

Epoch: 6| Step: 8
Training loss: 2.360682487487793
Validation loss: 2.315400372269333

Epoch: 6| Step: 9
Training loss: 2.172499179840088
Validation loss: 2.3033811840959775

Epoch: 6| Step: 10
Training loss: 2.7616236209869385
Validation loss: 2.296693604479554

Epoch: 6| Step: 11
Training loss: 2.523308038711548
Validation loss: 2.3024907189030803

Epoch: 6| Step: 12
Training loss: 2.596344470977783
Validation loss: 2.3000716599085

Epoch: 6| Step: 13
Training loss: 2.822165012359619
Validation loss: 2.3072310263110745

Epoch: 193| Step: 0
Training loss: 2.4925084114074707
Validation loss: 2.2989234796134372

Epoch: 6| Step: 1
Training loss: 2.1936426162719727
Validation loss: 2.292860507965088

Epoch: 6| Step: 2
Training loss: 1.9540431499481201
Validation loss: 2.2989955153516544

Epoch: 6| Step: 3
Training loss: 2.5956106185913086
Validation loss: 2.296218410614998

Epoch: 6| Step: 4
Training loss: 2.1055641174316406
Validation loss: 2.2976710693810576

Epoch: 6| Step: 5
Training loss: 3.1042466163635254
Validation loss: 2.295723363917361

Epoch: 6| Step: 6
Training loss: 2.6589345932006836
Validation loss: 2.3049621453849216

Epoch: 6| Step: 7
Training loss: 2.584779739379883
Validation loss: 2.2928693012524675

Epoch: 6| Step: 8
Training loss: 3.085852861404419
Validation loss: 2.277512019680392

Epoch: 6| Step: 9
Training loss: 2.2645273208618164
Validation loss: 2.2681968776128625

Epoch: 6| Step: 10
Training loss: 2.955364465713501
Validation loss: 2.2679863488802345

Epoch: 6| Step: 11
Training loss: 2.7537026405334473
Validation loss: 2.2672332768799155

Epoch: 6| Step: 12
Training loss: 2.0585529804229736
Validation loss: 2.2554389148630123

Epoch: 6| Step: 13
Training loss: 2.5997581481933594
Validation loss: 2.262473931876562

Epoch: 194| Step: 0
Training loss: 2.3993115425109863
Validation loss: 2.2530808653882755

Epoch: 6| Step: 1
Training loss: 2.4832046031951904
Validation loss: 2.2538446482791694

Epoch: 6| Step: 2
Training loss: 2.4293336868286133
Validation loss: 2.2636658735172723

Epoch: 6| Step: 3
Training loss: 2.222402572631836
Validation loss: 2.268283313320529

Epoch: 6| Step: 4
Training loss: 2.662419557571411
Validation loss: 2.283369723186698

Epoch: 6| Step: 5
Training loss: 2.4874210357666016
Validation loss: 2.2824814152973953

Epoch: 6| Step: 6
Training loss: 2.2092697620391846
Validation loss: 2.283491112852609

Epoch: 6| Step: 7
Training loss: 2.605165958404541
Validation loss: 2.276981794705955

Epoch: 6| Step: 8
Training loss: 1.8795026540756226
Validation loss: 2.2785190356675016

Epoch: 6| Step: 9
Training loss: 3.286374568939209
Validation loss: 2.2838883553781817

Epoch: 6| Step: 10
Training loss: 2.163623332977295
Validation loss: 2.2871073317784134

Epoch: 6| Step: 11
Training loss: 2.361314296722412
Validation loss: 2.2822339816759993

Epoch: 6| Step: 12
Training loss: 2.6202149391174316
Validation loss: 2.2913659362382788

Epoch: 6| Step: 13
Training loss: 4.157936096191406
Validation loss: 2.2948098823588383

Epoch: 195| Step: 0
Training loss: 2.1344974040985107
Validation loss: 2.2884748212752806

Epoch: 6| Step: 1
Training loss: 3.248962163925171
Validation loss: 2.2855206228071645

Epoch: 6| Step: 2
Training loss: 2.424233913421631
Validation loss: 2.2905752915208057

Epoch: 6| Step: 3
Training loss: 3.136110305786133
Validation loss: 2.2910257821441977

Epoch: 6| Step: 4
Training loss: 2.185532331466675
Validation loss: 2.288185563138736

Epoch: 6| Step: 5
Training loss: 2.7217729091644287
Validation loss: 2.2845553403259604

Epoch: 6| Step: 6
Training loss: 1.697733998298645
Validation loss: 2.2874560356140137

Epoch: 6| Step: 7
Training loss: 2.5355491638183594
Validation loss: 2.28759019349211

Epoch: 6| Step: 8
Training loss: 3.148897171020508
Validation loss: 2.284782003330928

Epoch: 6| Step: 9
Training loss: 2.6254730224609375
Validation loss: 2.2928839960405902

Epoch: 6| Step: 10
Training loss: 2.589585304260254
Validation loss: 2.2879453218111427

Epoch: 6| Step: 11
Training loss: 2.501800060272217
Validation loss: 2.2910516313327256

Epoch: 6| Step: 12
Training loss: 2.0572152137756348
Validation loss: 2.291526679069765

Epoch: 6| Step: 13
Training loss: 2.0316708087921143
Validation loss: 2.286616368960309

Epoch: 196| Step: 0
Training loss: 2.976203441619873
Validation loss: 2.291917970103602

Epoch: 6| Step: 1
Training loss: 3.1242620944976807
Validation loss: 2.2870713921003443

Epoch: 6| Step: 2
Training loss: 2.594416618347168
Validation loss: 2.286052965348767

Epoch: 6| Step: 3
Training loss: 2.285081386566162
Validation loss: 2.2667140781238513

Epoch: 6| Step: 4
Training loss: 2.8784098625183105
Validation loss: 2.27543778316949

Epoch: 6| Step: 5
Training loss: 2.342230796813965
Validation loss: 2.2749486725817443

Epoch: 6| Step: 6
Training loss: 2.2955117225646973
Validation loss: 2.265307216234105

Epoch: 6| Step: 7
Training loss: 1.9628119468688965
Validation loss: 2.273960558317041

Epoch: 6| Step: 8
Training loss: 2.068620204925537
Validation loss: 2.2675032026024273

Epoch: 6| Step: 9
Training loss: 1.9087713956832886
Validation loss: 2.268330209998674

Epoch: 6| Step: 10
Training loss: 3.0967836380004883
Validation loss: 2.2730064366453435

Epoch: 6| Step: 11
Training loss: 2.6054484844207764
Validation loss: 2.2866358833928264

Epoch: 6| Step: 12
Training loss: 2.09431791305542
Validation loss: 2.2731458935686337

Epoch: 6| Step: 13
Training loss: 3.331010580062866
Validation loss: 2.2973192648221086

Epoch: 197| Step: 0
Training loss: 2.8268730640411377
Validation loss: 2.2791023305667344

Epoch: 6| Step: 1
Training loss: 2.1787657737731934
Validation loss: 2.2805286786889516

Epoch: 6| Step: 2
Training loss: 2.001023292541504
Validation loss: 2.279309618857599

Epoch: 6| Step: 3
Training loss: 2.934579610824585
Validation loss: 2.273797291581349

Epoch: 6| Step: 4
Training loss: 3.1984896659851074
Validation loss: 2.2693073518814577

Epoch: 6| Step: 5
Training loss: 3.3034260272979736
Validation loss: 2.292267830141129

Epoch: 6| Step: 6
Training loss: 2.8695812225341797
Validation loss: 2.291621110772574

Epoch: 6| Step: 7
Training loss: 2.3933887481689453
Validation loss: 2.305727651042323

Epoch: 6| Step: 8
Training loss: 2.5267210006713867
Validation loss: 2.3031792730413456

Epoch: 6| Step: 9
Training loss: 3.0905609130859375
Validation loss: 2.3023202380826397

Epoch: 6| Step: 10
Training loss: 1.6989768743515015
Validation loss: 2.296699693126063

Epoch: 6| Step: 11
Training loss: 2.8387932777404785
Validation loss: 2.2841621650162565

Epoch: 6| Step: 12
Training loss: 1.596410870552063
Validation loss: 2.271890717168008

Epoch: 6| Step: 13
Training loss: 1.2160987854003906
Validation loss: 2.2711930608236663

Epoch: 198| Step: 0
Training loss: 2.340264081954956
Validation loss: 2.272249360238352

Epoch: 6| Step: 1
Training loss: 2.9929685592651367
Validation loss: 2.2757300151291715

Epoch: 6| Step: 2
Training loss: 2.754338026046753
Validation loss: 2.269948092840051

Epoch: 6| Step: 3
Training loss: 3.139840602874756
Validation loss: 2.285700677543558

Epoch: 6| Step: 4
Training loss: 2.814462661743164
Validation loss: 2.2842071492184877

Epoch: 6| Step: 5
Training loss: 2.663430690765381
Validation loss: 2.2907940162125455

Epoch: 6| Step: 6
Training loss: 2.2987561225891113
Validation loss: 2.2876005018911054

Epoch: 6| Step: 7
Training loss: 2.4516043663024902
Validation loss: 2.2904310969896216

Epoch: 6| Step: 8
Training loss: 2.4086978435516357
Validation loss: 2.2820151646931968

Epoch: 6| Step: 9
Training loss: 2.321791172027588
Validation loss: 2.2995622798960698

Epoch: 6| Step: 10
Training loss: 2.5548009872436523
Validation loss: 2.2940185172583467

Epoch: 6| Step: 11
Training loss: 2.3907899856567383
Validation loss: 2.291328901885658

Epoch: 6| Step: 12
Training loss: 1.552138328552246
Validation loss: 2.2878587143395537

Epoch: 6| Step: 13
Training loss: 2.4966938495635986
Validation loss: 2.2934197277151127

Epoch: 199| Step: 0
Training loss: 2.42935848236084
Validation loss: 2.2909256514682563

Epoch: 6| Step: 1
Training loss: 2.160306453704834
Validation loss: 2.2701919232645342

Epoch: 6| Step: 2
Training loss: 2.366356134414673
Validation loss: 2.264942092280234

Epoch: 6| Step: 3
Training loss: 3.100637912750244
Validation loss: 2.2629882315153718

Epoch: 6| Step: 4
Training loss: 1.7285467386245728
Validation loss: 2.2515899186493247

Epoch: 6| Step: 5
Training loss: 2.9342894554138184
Validation loss: 2.247118349998228

Epoch: 6| Step: 6
Training loss: 2.2402706146240234
Validation loss: 2.2512011528015137

Epoch: 6| Step: 7
Training loss: 2.2036290168762207
Validation loss: 2.254267613093058

Epoch: 6| Step: 8
Training loss: 2.7670679092407227
Validation loss: 2.249432906027763

Epoch: 6| Step: 9
Training loss: 3.131484031677246
Validation loss: 2.259333082424697

Epoch: 6| Step: 10
Training loss: 2.719036102294922
Validation loss: 2.254872096482144

Epoch: 6| Step: 11
Training loss: 2.590549945831299
Validation loss: 2.2561340844759377

Epoch: 6| Step: 12
Training loss: 2.3852686882019043
Validation loss: 2.2573860665803314

Epoch: 6| Step: 13
Training loss: 2.1792354583740234
Validation loss: 2.2556112709865777

Epoch: 200| Step: 0
Training loss: 2.0905439853668213
Validation loss: 2.255670767958446

Epoch: 6| Step: 1
Training loss: 2.379991292953491
Validation loss: 2.266767571049352

Epoch: 6| Step: 2
Training loss: 2.053837776184082
Validation loss: 2.2642540444609938

Epoch: 6| Step: 3
Training loss: 1.9143728017807007
Validation loss: 2.2641826393783733

Epoch: 6| Step: 4
Training loss: 2.8430075645446777
Validation loss: 2.2657671564368793

Epoch: 6| Step: 5
Training loss: 3.1831042766571045
Validation loss: 2.263873391253974

Epoch: 6| Step: 6
Training loss: 1.9129315614700317
Validation loss: 2.2589536610470025

Epoch: 6| Step: 7
Training loss: 2.546504497528076
Validation loss: 2.2601549753578762

Epoch: 6| Step: 8
Training loss: 2.9755797386169434
Validation loss: 2.267107709761589

Epoch: 6| Step: 9
Training loss: 2.9271085262298584
Validation loss: 2.2617611705615954

Epoch: 6| Step: 10
Training loss: 2.402810573577881
Validation loss: 2.2493744101575626

Epoch: 6| Step: 11
Training loss: 3.0799026489257812
Validation loss: 2.2527859236604426

Epoch: 6| Step: 12
Training loss: 2.697458505630493
Validation loss: 2.258111898617078

Epoch: 6| Step: 13
Training loss: 1.6795306205749512
Validation loss: 2.274166709633284

Epoch: 201| Step: 0
Training loss: 2.0971851348876953
Validation loss: 2.267715800193048

Epoch: 6| Step: 1
Training loss: 2.421147108078003
Validation loss: 2.272600486714353

Epoch: 6| Step: 2
Training loss: 2.6117782592773438
Validation loss: 2.2859528039091375

Epoch: 6| Step: 3
Training loss: 2.746509552001953
Validation loss: 2.2942514855374574

Epoch: 6| Step: 4
Training loss: 2.105886936187744
Validation loss: 2.2966817963507866

Epoch: 6| Step: 5
Training loss: 2.349224328994751
Validation loss: 2.2962102556741364

Epoch: 6| Step: 6
Training loss: 2.732340097427368
Validation loss: 2.29596209526062

Epoch: 6| Step: 7
Training loss: 2.7488579750061035
Validation loss: 2.2986341420040337

Epoch: 6| Step: 8
Training loss: 1.717297077178955
Validation loss: 2.2998970964903473

Epoch: 6| Step: 9
Training loss: 2.536513328552246
Validation loss: 2.2958075000393774

Epoch: 6| Step: 10
Training loss: 3.0373833179473877
Validation loss: 2.293838982941002

Epoch: 6| Step: 11
Training loss: 2.374732494354248
Validation loss: 2.2911626600450083

Epoch: 6| Step: 12
Training loss: 2.97648286819458
Validation loss: 2.2934651784999396

Epoch: 6| Step: 13
Training loss: 2.9287590980529785
Validation loss: 2.2809431757978214

Epoch: 202| Step: 0
Training loss: 2.242980480194092
Validation loss: 2.2757336760079987

Epoch: 6| Step: 1
Training loss: 2.6710214614868164
Validation loss: 2.2798967002540507

Epoch: 6| Step: 2
Training loss: 2.6791911125183105
Validation loss: 2.282528018438688

Epoch: 6| Step: 3
Training loss: 2.983150005340576
Validation loss: 2.277410335438226

Epoch: 6| Step: 4
Training loss: 2.8619422912597656
Validation loss: 2.277959913335821

Epoch: 6| Step: 5
Training loss: 2.0849575996398926
Validation loss: 2.263293356023809

Epoch: 6| Step: 6
Training loss: 2.6482338905334473
Validation loss: 2.2643900173966602

Epoch: 6| Step: 7
Training loss: 2.204702377319336
Validation loss: 2.265236211079423

Epoch: 6| Step: 8
Training loss: 2.2709102630615234
Validation loss: 2.274604376926217

Epoch: 6| Step: 9
Training loss: 2.615147829055786
Validation loss: 2.2697754085704847

Epoch: 6| Step: 10
Training loss: 2.4117183685302734
Validation loss: 2.2713588540272047

Epoch: 6| Step: 11
Training loss: 3.0443482398986816
Validation loss: 2.2702552887701217

Epoch: 6| Step: 12
Training loss: 2.39727783203125
Validation loss: 2.279195713740523

Epoch: 6| Step: 13
Training loss: 1.679931640625
Validation loss: 2.2940922296175392

Epoch: 203| Step: 0
Training loss: 2.2290217876434326
Validation loss: 2.2977187915514876

Epoch: 6| Step: 1
Training loss: 2.7085318565368652
Validation loss: 2.2845060235710553

Epoch: 6| Step: 2
Training loss: 2.7405805587768555
Validation loss: 2.301336088488179

Epoch: 6| Step: 3
Training loss: 3.3673524856567383
Validation loss: 2.3025286402753604

Epoch: 6| Step: 4
Training loss: 2.434539318084717
Validation loss: 2.291769835256761

Epoch: 6| Step: 5
Training loss: 2.2138471603393555
Validation loss: 2.294439820833104

Epoch: 6| Step: 6
Training loss: 2.0639936923980713
Validation loss: 2.2942625117558304

Epoch: 6| Step: 7
Training loss: 3.5781469345092773
Validation loss: 2.2833134538383892

Epoch: 6| Step: 8
Training loss: 2.73091983795166
Validation loss: 2.2862650758476666

Epoch: 6| Step: 9
Training loss: 1.846022605895996
Validation loss: 2.2786503120135237

Epoch: 6| Step: 10
Training loss: 1.8694241046905518
Validation loss: 2.2779380941903717

Epoch: 6| Step: 11
Training loss: 2.175321102142334
Validation loss: 2.2701046043826687

Epoch: 6| Step: 12
Training loss: 2.5768117904663086
Validation loss: 2.2863789604556177

Epoch: 6| Step: 13
Training loss: 2.4681482315063477
Validation loss: 2.293806552886963

Epoch: 204| Step: 0
Training loss: 2.965512275695801
Validation loss: 2.293814548882105

Epoch: 6| Step: 1
Training loss: 2.59413480758667
Validation loss: 2.2934450487936697

Epoch: 6| Step: 2
Training loss: 2.1430482864379883
Validation loss: 2.2906623937750377

Epoch: 6| Step: 3
Training loss: 1.916017770767212
Validation loss: 2.29129925979081

Epoch: 6| Step: 4
Training loss: 2.090449810028076
Validation loss: 2.282830153742144

Epoch: 6| Step: 5
Training loss: 2.406006336212158
Validation loss: 2.2910718302572928

Epoch: 6| Step: 6
Training loss: 2.524606943130493
Validation loss: 2.2810242714420443

Epoch: 6| Step: 7
Training loss: 2.4631123542785645
Validation loss: 2.285945507787889

Epoch: 6| Step: 8
Training loss: 2.5006868839263916
Validation loss: 2.2853842063616683

Epoch: 6| Step: 9
Training loss: 2.6711061000823975
Validation loss: 2.289265791575114

Epoch: 6| Step: 10
Training loss: 2.7837743759155273
Validation loss: 2.2788986800819315

Epoch: 6| Step: 11
Training loss: 2.366239547729492
Validation loss: 2.2792657395844818

Epoch: 6| Step: 12
Training loss: 2.578228235244751
Validation loss: 2.255083078979164

Epoch: 6| Step: 13
Training loss: 3.304635763168335
Validation loss: 2.263506597088229

Epoch: 205| Step: 0
Training loss: 2.6988775730133057
Validation loss: 2.268735562601397

Epoch: 6| Step: 1
Training loss: 1.9578193426132202
Validation loss: 2.2470305991429154

Epoch: 6| Step: 2
Training loss: 2.868252754211426
Validation loss: 2.2518259632971978

Epoch: 6| Step: 3
Training loss: 1.97897207736969
Validation loss: 2.256213814981522

Epoch: 6| Step: 4
Training loss: 2.525662422180176
Validation loss: 2.2540459632873535

Epoch: 6| Step: 5
Training loss: 2.0527963638305664
Validation loss: 2.259278643515802

Epoch: 6| Step: 6
Training loss: 2.8649673461914062
Validation loss: 2.255707061418923

Epoch: 6| Step: 7
Training loss: 2.0288405418395996
Validation loss: 2.270852811874882

Epoch: 6| Step: 8
Training loss: 2.0683891773223877
Validation loss: 2.2573564321764055

Epoch: 6| Step: 9
Training loss: 2.568507432937622
Validation loss: 2.2620287890075357

Epoch: 6| Step: 10
Training loss: 3.2766990661621094
Validation loss: 2.2733693276682208

Epoch: 6| Step: 11
Training loss: 3.3744571208953857
Validation loss: 2.2660862989323114

Epoch: 6| Step: 12
Training loss: 2.151508331298828
Validation loss: 2.276818533097544

Epoch: 6| Step: 13
Training loss: 2.5120420455932617
Validation loss: 2.278062420506631

Epoch: 206| Step: 0
Training loss: 2.7339117527008057
Validation loss: 2.279782965619077

Epoch: 6| Step: 1
Training loss: 2.7617855072021484
Validation loss: 2.288705564314319

Epoch: 6| Step: 2
Training loss: 2.217845916748047
Validation loss: 2.2905757299033542

Epoch: 6| Step: 3
Training loss: 2.567692279815674
Validation loss: 2.2976553260639148

Epoch: 6| Step: 4
Training loss: 2.2222492694854736
Validation loss: 2.319831484107561

Epoch: 6| Step: 5
Training loss: 2.5967769622802734
Validation loss: 2.314118246878347

Epoch: 6| Step: 6
Training loss: 2.2870309352874756
Validation loss: 2.299036318256009

Epoch: 6| Step: 7
Training loss: 2.9552600383758545
Validation loss: 2.3106993039449057

Epoch: 6| Step: 8
Training loss: 2.2771060466766357
Validation loss: 2.294008663905564

Epoch: 6| Step: 9
Training loss: 2.6247739791870117
Validation loss: 2.2954712285790393

Epoch: 6| Step: 10
Training loss: 2.4092822074890137
Validation loss: 2.2962621065878097

Epoch: 6| Step: 11
Training loss: 3.1218318939208984
Validation loss: 2.2846490593366724

Epoch: 6| Step: 12
Training loss: 1.9978525638580322
Validation loss: 2.2799805082300657

Epoch: 6| Step: 13
Training loss: 2.166551351547241
Validation loss: 2.278862384057814

Epoch: 207| Step: 0
Training loss: 2.40716552734375
Validation loss: 2.2833218984706427

Epoch: 6| Step: 1
Training loss: 2.3082985877990723
Validation loss: 2.2793885905255555

Epoch: 6| Step: 2
Training loss: 2.4192333221435547
Validation loss: 2.2759826080773466

Epoch: 6| Step: 3
Training loss: 2.919407844543457
Validation loss: 2.281703552892131

Epoch: 6| Step: 4
Training loss: 2.5549657344818115
Validation loss: 2.281502260956713

Epoch: 6| Step: 5
Training loss: 2.3362903594970703
Validation loss: 2.2754512192100607

Epoch: 6| Step: 6
Training loss: 2.5082170963287354
Validation loss: 2.2710545806474585

Epoch: 6| Step: 7
Training loss: 2.8243629932403564
Validation loss: 2.274453406692833

Epoch: 6| Step: 8
Training loss: 2.4631049633026123
Validation loss: 2.2740084253331667

Epoch: 6| Step: 9
Training loss: 2.6200339794158936
Validation loss: 2.2790575360739105

Epoch: 6| Step: 10
Training loss: 1.990813970565796
Validation loss: 2.287312302538144

Epoch: 6| Step: 11
Training loss: 2.9326462745666504
Validation loss: 2.284795832890336

Epoch: 6| Step: 12
Training loss: 1.846084713935852
Validation loss: 2.2996458597080682

Epoch: 6| Step: 13
Training loss: 3.188490867614746
Validation loss: 2.3040034950420423

Epoch: 208| Step: 0
Training loss: 2.3500425815582275
Validation loss: 2.3203897732560352

Epoch: 6| Step: 1
Training loss: 2.467586040496826
Validation loss: 2.3113092555794665

Epoch: 6| Step: 2
Training loss: 3.1568100452423096
Validation loss: 2.3174822381747666

Epoch: 6| Step: 3
Training loss: 1.8328373432159424
Validation loss: 2.3052625310036445

Epoch: 6| Step: 4
Training loss: 2.4144539833068848
Validation loss: 2.302855894129763

Epoch: 6| Step: 5
Training loss: 3.2938008308410645
Validation loss: 2.2914242436808925

Epoch: 6| Step: 6
Training loss: 2.874638795852661
Validation loss: 2.3099447270875335

Epoch: 6| Step: 7
Training loss: 2.5822806358337402
Validation loss: 2.295918007050791

Epoch: 6| Step: 8
Training loss: 2.6959280967712402
Validation loss: 2.2922681634144118

Epoch: 6| Step: 9
Training loss: 2.244286298751831
Validation loss: 2.279535585834134

Epoch: 6| Step: 10
Training loss: 2.1421570777893066
Validation loss: 2.2622893138598372

Epoch: 6| Step: 11
Training loss: 2.1047091484069824
Validation loss: 2.2563495943623204

Epoch: 6| Step: 12
Training loss: 2.0835800170898438
Validation loss: 2.2433490624991794

Epoch: 6| Step: 13
Training loss: 3.0969953536987305
Validation loss: 2.2413267243293022

Epoch: 209| Step: 0
Training loss: 2.6777241230010986
Validation loss: 2.2515259737609536

Epoch: 6| Step: 1
Training loss: 2.2961339950561523
Validation loss: 2.236020065123035

Epoch: 6| Step: 2
Training loss: 2.430133104324341
Validation loss: 2.2418246628135763

Epoch: 6| Step: 3
Training loss: 2.0587496757507324
Validation loss: 2.2487372390685545

Epoch: 6| Step: 4
Training loss: 2.804504632949829
Validation loss: 2.241354403957244

Epoch: 6| Step: 5
Training loss: 2.7535364627838135
Validation loss: 2.23991782306343

Epoch: 6| Step: 6
Training loss: 2.4263393878936768
Validation loss: 2.236466507757864

Epoch: 6| Step: 7
Training loss: 2.746901750564575
Validation loss: 2.2438363054747223

Epoch: 6| Step: 8
Training loss: 2.6039459705352783
Validation loss: 2.2349250521711124

Epoch: 6| Step: 9
Training loss: 2.238316774368286
Validation loss: 2.244233023735785

Epoch: 6| Step: 10
Training loss: 2.548564910888672
Validation loss: 2.2435981804324734

Epoch: 6| Step: 11
Training loss: 3.184177875518799
Validation loss: 2.250516435151459

Epoch: 6| Step: 12
Training loss: 1.9456336498260498
Validation loss: 2.2369504795279553

Epoch: 6| Step: 13
Training loss: 1.9148709774017334
Validation loss: 2.2583564455791185

Epoch: 210| Step: 0
Training loss: 1.8912749290466309
Validation loss: 2.2573471940973753

Epoch: 6| Step: 1
Training loss: 2.810077667236328
Validation loss: 2.2429744838386454

Epoch: 6| Step: 2
Training loss: 1.719619631767273
Validation loss: 2.264378066985838

Epoch: 6| Step: 3
Training loss: 2.903977394104004
Validation loss: 2.256059979879728

Epoch: 6| Step: 4
Training loss: 2.230034351348877
Validation loss: 2.253956015392016

Epoch: 6| Step: 5
Training loss: 2.8499274253845215
Validation loss: 2.255920017919233

Epoch: 6| Step: 6
Training loss: 2.442646026611328
Validation loss: 2.2560819759163806

Epoch: 6| Step: 7
Training loss: 2.509913921356201
Validation loss: 2.246482972175844

Epoch: 6| Step: 8
Training loss: 2.3086981773376465
Validation loss: 2.234720908185487

Epoch: 6| Step: 9
Training loss: 2.1809751987457275
Validation loss: 2.2432300736827235

Epoch: 6| Step: 10
Training loss: 2.794177293777466
Validation loss: 2.2420836417905745

Epoch: 6| Step: 11
Training loss: 3.0593960285186768
Validation loss: 2.2424521189863964

Epoch: 6| Step: 12
Training loss: 2.529564619064331
Validation loss: 2.240824407146823

Epoch: 6| Step: 13
Training loss: 2.7272887229919434
Validation loss: 2.2447357613553285

Epoch: 211| Step: 0
Training loss: 2.5932042598724365
Validation loss: 2.2381372887601136

Epoch: 6| Step: 1
Training loss: 2.784916639328003
Validation loss: 2.246467600586594

Epoch: 6| Step: 2
Training loss: 1.4844655990600586
Validation loss: 2.251617664931923

Epoch: 6| Step: 3
Training loss: 2.836406707763672
Validation loss: 2.2430526364234185

Epoch: 6| Step: 4
Training loss: 2.3898608684539795
Validation loss: 2.242099056961716

Epoch: 6| Step: 5
Training loss: 2.6164157390594482
Validation loss: 2.2441025780093287

Epoch: 6| Step: 6
Training loss: 2.502840518951416
Validation loss: 2.240693658910772

Epoch: 6| Step: 7
Training loss: 2.1695151329040527
Validation loss: 2.2543569803237915

Epoch: 6| Step: 8
Training loss: 1.8172733783721924
Validation loss: 2.2594498011373703

Epoch: 6| Step: 9
Training loss: 2.24341082572937
Validation loss: 2.2676991416561987

Epoch: 6| Step: 10
Training loss: 3.154439926147461
Validation loss: 2.2588298679679952

Epoch: 6| Step: 11
Training loss: 2.272210121154785
Validation loss: 2.2703012112648255

Epoch: 6| Step: 12
Training loss: 3.079491138458252
Validation loss: 2.2863303935655983

Epoch: 6| Step: 13
Training loss: 2.8926286697387695
Validation loss: 2.2791045583704466

Epoch: 212| Step: 0
Training loss: 2.684331178665161
Validation loss: 2.2730589021918592

Epoch: 6| Step: 1
Training loss: 2.735501766204834
Validation loss: 2.2746523605879916

Epoch: 6| Step: 2
Training loss: 1.8714933395385742
Validation loss: 2.2687858176487747

Epoch: 6| Step: 3
Training loss: 2.5464720726013184
Validation loss: 2.2801007865577616

Epoch: 6| Step: 4
Training loss: 3.225560188293457
Validation loss: 2.2564955501146216

Epoch: 6| Step: 5
Training loss: 2.791551113128662
Validation loss: 2.273522061686362

Epoch: 6| Step: 6
Training loss: 2.2323741912841797
Validation loss: 2.251527314545006

Epoch: 6| Step: 7
Training loss: 2.615912675857544
Validation loss: 2.2547800361469226

Epoch: 6| Step: 8
Training loss: 2.3708558082580566
Validation loss: 2.254833149653609

Epoch: 6| Step: 9
Training loss: 2.3535213470458984
Validation loss: 2.2462654241951565

Epoch: 6| Step: 10
Training loss: 2.493457794189453
Validation loss: 2.2494778812572522

Epoch: 6| Step: 11
Training loss: 2.1626179218292236
Validation loss: 2.2419320101379068

Epoch: 6| Step: 12
Training loss: 2.1880452632904053
Validation loss: 2.24656036976845

Epoch: 6| Step: 13
Training loss: 2.3675451278686523
Validation loss: 2.244013153096681

Epoch: 213| Step: 0
Training loss: 2.750196933746338
Validation loss: 2.263250263788367

Epoch: 6| Step: 1
Training loss: 2.4694809913635254
Validation loss: 2.2633572701484925

Epoch: 6| Step: 2
Training loss: 3.0594096183776855
Validation loss: 2.2737824583566315

Epoch: 6| Step: 3
Training loss: 2.0938773155212402
Validation loss: 2.2676585130794074

Epoch: 6| Step: 4
Training loss: 3.1919941902160645
Validation loss: 2.291042959818276

Epoch: 6| Step: 5
Training loss: 2.2710962295532227
Validation loss: 2.286613078527553

Epoch: 6| Step: 6
Training loss: 1.9299099445343018
Validation loss: 2.2808714887147308

Epoch: 6| Step: 7
Training loss: 2.8463220596313477
Validation loss: 2.291697238081245

Epoch: 6| Step: 8
Training loss: 2.3007729053497314
Validation loss: 2.285832412781254

Epoch: 6| Step: 9
Training loss: 1.6776677370071411
Validation loss: 2.275244359047182

Epoch: 6| Step: 10
Training loss: 2.291393756866455
Validation loss: 2.2661525510972544

Epoch: 6| Step: 11
Training loss: 2.874691963195801
Validation loss: 2.2689174670045094

Epoch: 6| Step: 12
Training loss: 2.383871078491211
Validation loss: 2.2581164990701983

Epoch: 6| Step: 13
Training loss: 2.3335723876953125
Validation loss: 2.2705180055351666

Epoch: 214| Step: 0
Training loss: 2.309570789337158
Validation loss: 2.2632855728108394

Epoch: 6| Step: 1
Training loss: 1.8858920335769653
Validation loss: 2.255254650628695

Epoch: 6| Step: 2
Training loss: 2.7413759231567383
Validation loss: 2.2624023934846282

Epoch: 6| Step: 3
Training loss: 3.183506488800049
Validation loss: 2.258218265348865

Epoch: 6| Step: 4
Training loss: 2.4296793937683105
Validation loss: 2.248235530750726

Epoch: 6| Step: 5
Training loss: 2.080644369125366
Validation loss: 2.2508107410964144

Epoch: 6| Step: 6
Training loss: 1.7327446937561035
Validation loss: 2.2407260351283576

Epoch: 6| Step: 7
Training loss: 2.186912775039673
Validation loss: 2.239918085836595

Epoch: 6| Step: 8
Training loss: 2.783975839614868
Validation loss: 2.237808354439274

Epoch: 6| Step: 9
Training loss: 2.5152034759521484
Validation loss: 2.2288294915230042

Epoch: 6| Step: 10
Training loss: 3.2965445518493652
Validation loss: 2.2357971770789034

Epoch: 6| Step: 11
Training loss: 2.0417394638061523
Validation loss: 2.2342907100595455

Epoch: 6| Step: 12
Training loss: 2.5167198181152344
Validation loss: 2.24528573148994

Epoch: 6| Step: 13
Training loss: 3.1082136631011963
Validation loss: 2.2470197703248713

Epoch: 215| Step: 0
Training loss: 2.2959911823272705
Validation loss: 2.2583481637380456

Epoch: 6| Step: 1
Training loss: 2.4404053688049316
Validation loss: 2.234023315932161

Epoch: 6| Step: 2
Training loss: 3.237248420715332
Validation loss: 2.2410930613035798

Epoch: 6| Step: 3
Training loss: 2.6548492908477783
Validation loss: 2.2393909090308735

Epoch: 6| Step: 4
Training loss: 1.9902610778808594
Validation loss: 2.242889186387421

Epoch: 6| Step: 5
Training loss: 2.528520107269287
Validation loss: 2.2631316851544123

Epoch: 6| Step: 6
Training loss: 2.0449533462524414
Validation loss: 2.2601599924026

Epoch: 6| Step: 7
Training loss: 2.6767687797546387
Validation loss: 2.2652033708428823

Epoch: 6| Step: 8
Training loss: 1.837380290031433
Validation loss: 2.2719257467536518

Epoch: 6| Step: 9
Training loss: 3.260741710662842
Validation loss: 2.2616806184091875

Epoch: 6| Step: 10
Training loss: 1.9524791240692139
Validation loss: 2.2593747159486175

Epoch: 6| Step: 11
Training loss: 2.797976016998291
Validation loss: 2.258239056474419

Epoch: 6| Step: 12
Training loss: 2.2505834102630615
Validation loss: 2.245910447130921

Epoch: 6| Step: 13
Training loss: 2.404665231704712
Validation loss: 2.2381350622382215

Epoch: 216| Step: 0
Training loss: 2.4046428203582764
Validation loss: 2.251448690250356

Epoch: 6| Step: 1
Training loss: 2.6740198135375977
Validation loss: 2.2494359375328146

Epoch: 6| Step: 2
Training loss: 1.931905746459961
Validation loss: 2.2547933875873523

Epoch: 6| Step: 3
Training loss: 2.0214765071868896
Validation loss: 2.253751516342163

Epoch: 6| Step: 4
Training loss: 2.915365219116211
Validation loss: 2.2632812402581655

Epoch: 6| Step: 5
Training loss: 2.8879222869873047
Validation loss: 2.2643524446795062

Epoch: 6| Step: 6
Training loss: 2.7231414318084717
Validation loss: 2.258089914116808

Epoch: 6| Step: 7
Training loss: 2.5893025398254395
Validation loss: 2.244515857388896

Epoch: 6| Step: 8
Training loss: 2.424398422241211
Validation loss: 2.245328195633427

Epoch: 6| Step: 9
Training loss: 3.0163934230804443
Validation loss: 2.2476889292399087

Epoch: 6| Step: 10
Training loss: 2.0520710945129395
Validation loss: 2.2566981007975917

Epoch: 6| Step: 11
Training loss: 2.2112722396850586
Validation loss: 2.2631159726009575

Epoch: 6| Step: 12
Training loss: 2.4621448516845703
Validation loss: 2.2547362286557435

Epoch: 6| Step: 13
Training loss: 2.0619754791259766
Validation loss: 2.2710834087864047

Epoch: 217| Step: 0
Training loss: 2.12130069732666
Validation loss: 2.273352530694777

Epoch: 6| Step: 1
Training loss: 2.2176382541656494
Validation loss: 2.2737985862198697

Epoch: 6| Step: 2
Training loss: 2.6346147060394287
Validation loss: 2.26368018632294

Epoch: 6| Step: 3
Training loss: 2.8336119651794434
Validation loss: 2.2660477827954035

Epoch: 6| Step: 4
Training loss: 2.390510082244873
Validation loss: 2.284115993848411

Epoch: 6| Step: 5
Training loss: 2.096942901611328
Validation loss: 2.2924996499092347

Epoch: 6| Step: 6
Training loss: 2.352748394012451
Validation loss: 2.275989552979828

Epoch: 6| Step: 7
Training loss: 2.3914437294006348
Validation loss: 2.275810872354815

Epoch: 6| Step: 8
Training loss: 2.4073023796081543
Validation loss: 2.2729001173409085

Epoch: 6| Step: 9
Training loss: 2.4170265197753906
Validation loss: 2.277681243035101

Epoch: 6| Step: 10
Training loss: 2.4470739364624023
Validation loss: 2.2754059312164143

Epoch: 6| Step: 11
Training loss: 2.7661631107330322
Validation loss: 2.278514177568497

Epoch: 6| Step: 12
Training loss: 3.1655173301696777
Validation loss: 2.2846108610912035

Epoch: 6| Step: 13
Training loss: 2.178138256072998
Validation loss: 2.283362906466248

Epoch: 218| Step: 0
Training loss: 2.3595681190490723
Validation loss: 2.2831466377422376

Epoch: 6| Step: 1
Training loss: 1.9658762216567993
Validation loss: 2.2753692544916624

Epoch: 6| Step: 2
Training loss: 2.760136842727661
Validation loss: 2.2681052274601434

Epoch: 6| Step: 3
Training loss: 2.4148471355438232
Validation loss: 2.2597343037205357

Epoch: 6| Step: 4
Training loss: 2.8629608154296875
Validation loss: 2.253047086859262

Epoch: 6| Step: 5
Training loss: 2.0576298236846924
Validation loss: 2.251631929028419

Epoch: 6| Step: 6
Training loss: 2.400296449661255
Validation loss: 2.24625636172551

Epoch: 6| Step: 7
Training loss: 2.5085787773132324
Validation loss: 2.2336690630964053

Epoch: 6| Step: 8
Training loss: 2.5274622440338135
Validation loss: 2.2281732328476442

Epoch: 6| Step: 9
Training loss: 2.1099390983581543
Validation loss: 2.2372890954376548

Epoch: 6| Step: 10
Training loss: 2.2380905151367188
Validation loss: 2.238628231069093

Epoch: 6| Step: 11
Training loss: 3.0555739402770996
Validation loss: 2.2492454487790345

Epoch: 6| Step: 12
Training loss: 2.4305260181427
Validation loss: 2.2357632190950456

Epoch: 6| Step: 13
Training loss: 3.1899945735931396
Validation loss: 2.2406813585630028

Epoch: 219| Step: 0
Training loss: 2.510924816131592
Validation loss: 2.2475595448606756

Epoch: 6| Step: 1
Training loss: 2.2535901069641113
Validation loss: 2.2471163452312513

Epoch: 6| Step: 2
Training loss: 1.9858880043029785
Validation loss: 2.2547769059417067

Epoch: 6| Step: 3
Training loss: 2.6383795738220215
Validation loss: 2.2465550668777956

Epoch: 6| Step: 4
Training loss: 2.0086004734039307
Validation loss: 2.237194609898393

Epoch: 6| Step: 5
Training loss: 2.6937692165374756
Validation loss: 2.253624157239032

Epoch: 6| Step: 6
Training loss: 3.0276787281036377
Validation loss: 2.2400861247893302

Epoch: 6| Step: 7
Training loss: 2.5665252208709717
Validation loss: 2.239997504859842

Epoch: 6| Step: 8
Training loss: 2.543666362762451
Validation loss: 2.2531114957665883

Epoch: 6| Step: 9
Training loss: 2.1045122146606445
Validation loss: 2.2418244141404347

Epoch: 6| Step: 10
Training loss: 2.694505214691162
Validation loss: 2.253990852704612

Epoch: 6| Step: 11
Training loss: 2.2735161781311035
Validation loss: 2.258874054877989

Epoch: 6| Step: 12
Training loss: 2.508474826812744
Validation loss: 2.256304766542168

Epoch: 6| Step: 13
Training loss: 2.767475128173828
Validation loss: 2.268868443786457

Epoch: 220| Step: 0
Training loss: 2.452239990234375
Validation loss: 2.2506302531047533

Epoch: 6| Step: 1
Training loss: 2.653235912322998
Validation loss: 2.2461271132192304

Epoch: 6| Step: 2
Training loss: 2.433074951171875
Validation loss: 2.242264655328566

Epoch: 6| Step: 3
Training loss: 2.5201900005340576
Validation loss: 2.2581026502834853

Epoch: 6| Step: 4
Training loss: 2.1054587364196777
Validation loss: 2.253669559314687

Epoch: 6| Step: 5
Training loss: 1.9681364297866821
Validation loss: 2.258604790574761

Epoch: 6| Step: 6
Training loss: 2.5577027797698975
Validation loss: 2.2636246373576503

Epoch: 6| Step: 7
Training loss: 2.4681472778320312
Validation loss: 2.2676739231232674

Epoch: 6| Step: 8
Training loss: 2.3425698280334473
Validation loss: 2.262359401231171

Epoch: 6| Step: 9
Training loss: 2.647397756576538
Validation loss: 2.2555361434977543

Epoch: 6| Step: 10
Training loss: 2.320894956588745
Validation loss: 2.250159607138685

Epoch: 6| Step: 11
Training loss: 3.222062110900879
Validation loss: 2.2371799484375985

Epoch: 6| Step: 12
Training loss: 2.12166166305542
Validation loss: 2.2292375205665507

Epoch: 6| Step: 13
Training loss: 3.1344451904296875
Validation loss: 2.226955831691783

Epoch: 221| Step: 0
Training loss: 2.2286412715911865
Validation loss: 2.215837423519422

Epoch: 6| Step: 1
Training loss: 2.7009425163269043
Validation loss: 2.21632017115111

Epoch: 6| Step: 2
Training loss: 2.2846381664276123
Validation loss: 2.2137283945596344

Epoch: 6| Step: 3
Training loss: 2.5256927013397217
Validation loss: 2.2196439261077554

Epoch: 6| Step: 4
Training loss: 2.992314100265503
Validation loss: 2.222282276358656

Epoch: 6| Step: 5
Training loss: 2.3735578060150146
Validation loss: 2.229423362721679

Epoch: 6| Step: 6
Training loss: 2.23154354095459
Validation loss: 2.226296850430068

Epoch: 6| Step: 7
Training loss: 2.3906497955322266
Validation loss: 2.2454674884837162

Epoch: 6| Step: 8
Training loss: 2.376662492752075
Validation loss: 2.2497780938302316

Epoch: 6| Step: 9
Training loss: 2.6872425079345703
Validation loss: 2.2507162645298946

Epoch: 6| Step: 10
Training loss: 2.686668872833252
Validation loss: 2.261321501065326

Epoch: 6| Step: 11
Training loss: 2.1952805519104004
Validation loss: 2.2522149496181036

Epoch: 6| Step: 12
Training loss: 2.5746896266937256
Validation loss: 2.244789000480406

Epoch: 6| Step: 13
Training loss: 2.440699815750122
Validation loss: 2.2393252157395884

Epoch: 222| Step: 0
Training loss: 2.454024076461792
Validation loss: 2.2310771698592813

Epoch: 6| Step: 1
Training loss: 2.4421393871307373
Validation loss: 2.241060923504573

Epoch: 6| Step: 2
Training loss: 2.95174241065979
Validation loss: 2.2407159907843477

Epoch: 6| Step: 3
Training loss: 2.3075544834136963
Validation loss: 2.2361074416868147

Epoch: 6| Step: 4
Training loss: 2.197781562805176
Validation loss: 2.2390947136827695

Epoch: 6| Step: 5
Training loss: 2.534287214279175
Validation loss: 2.236191277862877

Epoch: 6| Step: 6
Training loss: 1.8067166805267334
Validation loss: 2.246902060765092

Epoch: 6| Step: 7
Training loss: 2.417621612548828
Validation loss: 2.239640881938319

Epoch: 6| Step: 8
Training loss: 3.573002576828003
Validation loss: 2.247791756865799

Epoch: 6| Step: 9
Training loss: 3.5148630142211914
Validation loss: 2.2435458142270326

Epoch: 6| Step: 10
Training loss: 2.6248786449432373
Validation loss: 2.2417986892884776

Epoch: 6| Step: 11
Training loss: 2.1013028621673584
Validation loss: 2.2322122204688286

Epoch: 6| Step: 12
Training loss: 1.6886909008026123
Validation loss: 2.2443802689993255

Epoch: 6| Step: 13
Training loss: 1.5249042510986328
Validation loss: 2.2467642471354496

Epoch: 223| Step: 0
Training loss: 2.2711310386657715
Validation loss: 2.25739376519316

Epoch: 6| Step: 1
Training loss: 2.231419324874878
Validation loss: 2.2559071561341644

Epoch: 6| Step: 2
Training loss: 3.0085740089416504
Validation loss: 2.267193986523536

Epoch: 6| Step: 3
Training loss: 3.25040340423584
Validation loss: 2.251502949704406

Epoch: 6| Step: 4
Training loss: 2.910229206085205
Validation loss: 2.2427283717739965

Epoch: 6| Step: 5
Training loss: 2.2799787521362305
Validation loss: 2.233195779144123

Epoch: 6| Step: 6
Training loss: 1.7722339630126953
Validation loss: 2.221497192177721

Epoch: 6| Step: 7
Training loss: 2.0633389949798584
Validation loss: 2.2181944975288967

Epoch: 6| Step: 8
Training loss: 2.7932825088500977
Validation loss: 2.220669830999067

Epoch: 6| Step: 9
Training loss: 2.8365421295166016
Validation loss: 2.230980416779877

Epoch: 6| Step: 10
Training loss: 1.2819263935089111
Validation loss: 2.2276020934504848

Epoch: 6| Step: 11
Training loss: 2.764195442199707
Validation loss: 2.2277789372269825

Epoch: 6| Step: 12
Training loss: 2.951183319091797
Validation loss: 2.2425607712038103

Epoch: 6| Step: 13
Training loss: 2.104172706604004
Validation loss: 2.237705164058234

Epoch: 224| Step: 0
Training loss: 2.319719076156616
Validation loss: 2.254227661317395

Epoch: 6| Step: 1
Training loss: 1.8311288356781006
Validation loss: 2.2543103028369207

Epoch: 6| Step: 2
Training loss: 2.2408995628356934
Validation loss: 2.262250454195084

Epoch: 6| Step: 3
Training loss: 1.821260929107666
Validation loss: 2.2627144270045783

Epoch: 6| Step: 4
Training loss: 1.9837284088134766
Validation loss: 2.262875562073082

Epoch: 6| Step: 5
Training loss: 2.564814567565918
Validation loss: 2.261681295210315

Epoch: 6| Step: 6
Training loss: 2.7843685150146484
Validation loss: 2.263579571118919

Epoch: 6| Step: 7
Training loss: 2.6889400482177734
Validation loss: 2.271114436529016

Epoch: 6| Step: 8
Training loss: 3.185307025909424
Validation loss: 2.265360293849822

Epoch: 6| Step: 9
Training loss: 3.0811548233032227
Validation loss: 2.261759629813574

Epoch: 6| Step: 10
Training loss: 2.694108486175537
Validation loss: 2.257110969994658

Epoch: 6| Step: 11
Training loss: 2.1701204776763916
Validation loss: 2.2519872034749677

Epoch: 6| Step: 12
Training loss: 2.5468332767486572
Validation loss: 2.249306422407909

Epoch: 6| Step: 13
Training loss: 2.755345344543457
Validation loss: 2.2365139722824097

Epoch: 225| Step: 0
Training loss: 2.230276107788086
Validation loss: 2.2355085521615963

Epoch: 6| Step: 1
Training loss: 3.1277499198913574
Validation loss: 2.239218152979369

Epoch: 6| Step: 2
Training loss: 1.8442046642303467
Validation loss: 2.229830870064356

Epoch: 6| Step: 3
Training loss: 2.268266439437866
Validation loss: 2.240055080383055

Epoch: 6| Step: 4
Training loss: 2.3327577114105225
Validation loss: 2.255775723406064

Epoch: 6| Step: 5
Training loss: 2.5612311363220215
Validation loss: 2.2545248205943773

Epoch: 6| Step: 6
Training loss: 2.8990113735198975
Validation loss: 2.2510105384293424

Epoch: 6| Step: 7
Training loss: 3.246755599975586
Validation loss: 2.2484868136785363

Epoch: 6| Step: 8
Training loss: 2.4789860248565674
Validation loss: 2.2349501527765745

Epoch: 6| Step: 9
Training loss: 2.0661001205444336
Validation loss: 2.2298626156263452

Epoch: 6| Step: 10
Training loss: 2.0278148651123047
Validation loss: 2.2300724675578456

Epoch: 6| Step: 11
Training loss: 1.8199857473373413
Validation loss: 2.2362686767373035

Epoch: 6| Step: 12
Training loss: 2.608731746673584
Validation loss: 2.231484243946691

Epoch: 6| Step: 13
Training loss: 3.1511473655700684
Validation loss: 2.224672363650414

Epoch: 226| Step: 0
Training loss: 3.295898914337158
Validation loss: 2.234135071436564

Epoch: 6| Step: 1
Training loss: 2.409822463989258
Validation loss: 2.2494927247365317

Epoch: 6| Step: 2
Training loss: 2.794285297393799
Validation loss: 2.250682105300247

Epoch: 6| Step: 3
Training loss: 2.520392656326294
Validation loss: 2.235514348553073

Epoch: 6| Step: 4
Training loss: 1.715652585029602
Validation loss: 2.2329950704369494

Epoch: 6| Step: 5
Training loss: 2.855313777923584
Validation loss: 2.2269090401229037

Epoch: 6| Step: 6
Training loss: 2.4042720794677734
Validation loss: 2.2315159997632428

Epoch: 6| Step: 7
Training loss: 1.992340326309204
Validation loss: 2.2270775200218282

Epoch: 6| Step: 8
Training loss: 2.153714895248413
Validation loss: 2.2372764259256344

Epoch: 6| Step: 9
Training loss: 2.4080920219421387
Validation loss: 2.232152338950865

Epoch: 6| Step: 10
Training loss: 3.0167393684387207
Validation loss: 2.2401377129298385

Epoch: 6| Step: 11
Training loss: 2.7364091873168945
Validation loss: 2.2356370649030133

Epoch: 6| Step: 12
Training loss: 1.9999656677246094
Validation loss: 2.2514622967730284

Epoch: 6| Step: 13
Training loss: 1.502540111541748
Validation loss: 2.2420922453685472

Epoch: 227| Step: 0
Training loss: 3.020658254623413
Validation loss: 2.261389213223611

Epoch: 6| Step: 1
Training loss: 2.528501510620117
Validation loss: 2.2508643288766184

Epoch: 6| Step: 2
Training loss: 1.9116190671920776
Validation loss: 2.2552796127975627

Epoch: 6| Step: 3
Training loss: 2.404783248901367
Validation loss: 2.250938594982188

Epoch: 6| Step: 4
Training loss: 2.34556245803833
Validation loss: 2.25287272725054

Epoch: 6| Step: 5
Training loss: 2.3615798950195312
Validation loss: 2.2437731245512604

Epoch: 6| Step: 6
Training loss: 2.434675693511963
Validation loss: 2.238510811200706

Epoch: 6| Step: 7
Training loss: 2.284254789352417
Validation loss: 2.234035353506765

Epoch: 6| Step: 8
Training loss: 1.8363566398620605
Validation loss: 2.227647437844225

Epoch: 6| Step: 9
Training loss: 2.6352787017822266
Validation loss: 2.2276600996653237

Epoch: 6| Step: 10
Training loss: 2.726593017578125
Validation loss: 2.2314989797530638

Epoch: 6| Step: 11
Training loss: 2.481311321258545
Validation loss: 2.2349407570336455

Epoch: 6| Step: 12
Training loss: 2.8631591796875
Validation loss: 2.2422301435983307

Epoch: 6| Step: 13
Training loss: 2.2039308547973633
Validation loss: 2.2511279672704716

Epoch: 228| Step: 0
Training loss: 1.3914765119552612
Validation loss: 2.264155957006639

Epoch: 6| Step: 1
Training loss: 3.4808149337768555
Validation loss: 2.252322373851653

Epoch: 6| Step: 2
Training loss: 1.6967593431472778
Validation loss: 2.2623175651796403

Epoch: 6| Step: 3
Training loss: 2.2689990997314453
Validation loss: 2.2602489122780423

Epoch: 6| Step: 4
Training loss: 2.176699638366699
Validation loss: 2.2623943949258454

Epoch: 6| Step: 5
Training loss: 2.805222272872925
Validation loss: 2.2552172125026746

Epoch: 6| Step: 6
Training loss: 2.524473190307617
Validation loss: 2.2512879128097207

Epoch: 6| Step: 7
Training loss: 2.8679747581481934
Validation loss: 2.251048472619826

Epoch: 6| Step: 8
Training loss: 2.322937488555908
Validation loss: 2.240792541093724

Epoch: 6| Step: 9
Training loss: 2.633472442626953
Validation loss: 2.2419046022558726

Epoch: 6| Step: 10
Training loss: 2.2225558757781982
Validation loss: 2.2267510250050533

Epoch: 6| Step: 11
Training loss: 2.529466152191162
Validation loss: 2.2272535062605336

Epoch: 6| Step: 12
Training loss: 2.373204231262207
Validation loss: 2.2446184196779804

Epoch: 6| Step: 13
Training loss: 3.0361573696136475
Validation loss: 2.237454827113818

Epoch: 229| Step: 0
Training loss: 2.57197904586792
Validation loss: 2.2304530630829515

Epoch: 6| Step: 1
Training loss: 2.846468448638916
Validation loss: 2.229440173795146

Epoch: 6| Step: 2
Training loss: 2.1737470626831055
Validation loss: 2.2194815681826685

Epoch: 6| Step: 3
Training loss: 1.8121092319488525
Validation loss: 2.2156035464297057

Epoch: 6| Step: 4
Training loss: 3.4370622634887695
Validation loss: 2.216995252076016

Epoch: 6| Step: 5
Training loss: 2.8097100257873535
Validation loss: 2.2156996726989746

Epoch: 6| Step: 6
Training loss: 2.836355686187744
Validation loss: 2.2168521906739924

Epoch: 6| Step: 7
Training loss: 2.210160255432129
Validation loss: 2.213923177411479

Epoch: 6| Step: 8
Training loss: 1.8531761169433594
Validation loss: 2.2148587793432255

Epoch: 6| Step: 9
Training loss: 2.4879939556121826
Validation loss: 2.2211753527323403

Epoch: 6| Step: 10
Training loss: 1.9053703546524048
Validation loss: 2.216675832707395

Epoch: 6| Step: 11
Training loss: 2.19394588470459
Validation loss: 2.226959511797915

Epoch: 6| Step: 12
Training loss: 2.9713828563690186
Validation loss: 2.2205098034233175

Epoch: 6| Step: 13
Training loss: 1.5795559883117676
Validation loss: 2.225593105439217

Epoch: 230| Step: 0
Training loss: 2.7999539375305176
Validation loss: 2.2325202239457

Epoch: 6| Step: 1
Training loss: 2.903090000152588
Validation loss: 2.2482980220548567

Epoch: 6| Step: 2
Training loss: 1.982241153717041
Validation loss: 2.237308309924218

Epoch: 6| Step: 3
Training loss: 2.2452564239501953
Validation loss: 2.245124593857796

Epoch: 6| Step: 4
Training loss: 2.6146748065948486
Validation loss: 2.2450424881391626

Epoch: 6| Step: 5
Training loss: 1.8257516622543335
Validation loss: 2.251770132331438

Epoch: 6| Step: 6
Training loss: 2.842512607574463
Validation loss: 2.2464187299051592

Epoch: 6| Step: 7
Training loss: 2.545635461807251
Validation loss: 2.257460940268732

Epoch: 6| Step: 8
Training loss: 2.0678787231445312
Validation loss: 2.2385468905971897

Epoch: 6| Step: 9
Training loss: 2.735161542892456
Validation loss: 2.237624240177934

Epoch: 6| Step: 10
Training loss: 1.9538644552230835
Validation loss: 2.232075204131424

Epoch: 6| Step: 11
Training loss: 2.98868989944458
Validation loss: 2.2203409825601885

Epoch: 6| Step: 12
Training loss: 2.2791078090667725
Validation loss: 2.211527306546447

Epoch: 6| Step: 13
Training loss: 2.0144920349121094
Validation loss: 2.2173637369627595

Epoch: 231| Step: 0
Training loss: 1.6391501426696777
Validation loss: 2.214635938726446

Epoch: 6| Step: 1
Training loss: 1.7461366653442383
Validation loss: 2.217374958017821

Epoch: 6| Step: 2
Training loss: 2.692417860031128
Validation loss: 2.2266376685070735

Epoch: 6| Step: 3
Training loss: 2.8494486808776855
Validation loss: 2.217795048990557

Epoch: 6| Step: 4
Training loss: 3.0777387619018555
Validation loss: 2.222113460622808

Epoch: 6| Step: 5
Training loss: 2.044002056121826
Validation loss: 2.2289896139534573

Epoch: 6| Step: 6
Training loss: 2.2863662242889404
Validation loss: 2.2338971937856367

Epoch: 6| Step: 7
Training loss: 1.8877642154693604
Validation loss: 2.2300030621149207

Epoch: 6| Step: 8
Training loss: 2.596505641937256
Validation loss: 2.241334193496294

Epoch: 6| Step: 9
Training loss: 2.3139538764953613
Validation loss: 2.2408409477562032

Epoch: 6| Step: 10
Training loss: 2.3820061683654785
Validation loss: 2.2368099176755516

Epoch: 6| Step: 11
Training loss: 3.5803921222686768
Validation loss: 2.242754982363793

Epoch: 6| Step: 12
Training loss: 2.7249393463134766
Validation loss: 2.256405894474317

Epoch: 6| Step: 13
Training loss: 2.011932134628296
Validation loss: 2.2592432524568293

Epoch: 232| Step: 0
Training loss: 1.7405686378479004
Validation loss: 2.2401185830434165

Epoch: 6| Step: 1
Training loss: 2.1931471824645996
Validation loss: 2.2369630106033815

Epoch: 6| Step: 2
Training loss: 2.7312135696411133
Validation loss: 2.234349931440046

Epoch: 6| Step: 3
Training loss: 2.052276849746704
Validation loss: 2.241475999996226

Epoch: 6| Step: 4
Training loss: 2.6250743865966797
Validation loss: 2.2377870762219993

Epoch: 6| Step: 5
Training loss: 2.0159435272216797
Validation loss: 2.239501968506844

Epoch: 6| Step: 6
Training loss: 2.3240151405334473
Validation loss: 2.251574718823997

Epoch: 6| Step: 7
Training loss: 2.698831558227539
Validation loss: 2.2452250270433325

Epoch: 6| Step: 8
Training loss: 2.7587859630584717
Validation loss: 2.2502568819189586

Epoch: 6| Step: 9
Training loss: 2.3514511585235596
Validation loss: 2.239259865976149

Epoch: 6| Step: 10
Training loss: 2.609053611755371
Validation loss: 2.2419531550458682

Epoch: 6| Step: 11
Training loss: 2.1470041275024414
Validation loss: 2.2461341504127748

Epoch: 6| Step: 12
Training loss: 2.895022392272949
Validation loss: 2.252652697665717

Epoch: 6| Step: 13
Training loss: 2.8204329013824463
Validation loss: 2.241570959809006

Epoch: 233| Step: 0
Training loss: 2.4890494346618652
Validation loss: 2.2338066882984613

Epoch: 6| Step: 1
Training loss: 2.506244421005249
Validation loss: 2.2398602834311863

Epoch: 6| Step: 2
Training loss: 2.5285372734069824
Validation loss: 2.2381757766969743

Epoch: 6| Step: 3
Training loss: 2.4925479888916016
Validation loss: 2.237959390045494

Epoch: 6| Step: 4
Training loss: 2.1091675758361816
Validation loss: 2.2367348606868456

Epoch: 6| Step: 5
Training loss: 2.880131959915161
Validation loss: 2.2412243632860083

Epoch: 6| Step: 6
Training loss: 2.8963115215301514
Validation loss: 2.2499506934996574

Epoch: 6| Step: 7
Training loss: 2.8873064517974854
Validation loss: 2.2505332628885903

Epoch: 6| Step: 8
Training loss: 2.1299736499786377
Validation loss: 2.2353587458210606

Epoch: 6| Step: 9
Training loss: 1.6178462505340576
Validation loss: 2.2209181965038343

Epoch: 6| Step: 10
Training loss: 2.1720328330993652
Validation loss: 2.2286696382748183

Epoch: 6| Step: 11
Training loss: 2.2004635334014893
Validation loss: 2.240147234291159

Epoch: 6| Step: 12
Training loss: 2.945281744003296
Validation loss: 2.2481564270552767

Epoch: 6| Step: 13
Training loss: 2.1469552516937256
Validation loss: 2.244836466286772

Epoch: 234| Step: 0
Training loss: 2.5073604583740234
Validation loss: 2.251589923776606

Epoch: 6| Step: 1
Training loss: 2.249088764190674
Validation loss: 2.254743170994584

Epoch: 6| Step: 2
Training loss: 1.847100019454956
Validation loss: 2.261297792516729

Epoch: 6| Step: 3
Training loss: 2.1728429794311523
Validation loss: 2.2583167296583935

Epoch: 6| Step: 4
Training loss: 3.131718158721924
Validation loss: 2.2555141628429456

Epoch: 6| Step: 5
Training loss: 2.9308371543884277
Validation loss: 2.2388236855947845

Epoch: 6| Step: 6
Training loss: 2.194579601287842
Validation loss: 2.2398405921074653

Epoch: 6| Step: 7
Training loss: 3.1349921226501465
Validation loss: 2.224729730236915

Epoch: 6| Step: 8
Training loss: 2.8037118911743164
Validation loss: 2.2190452275737638

Epoch: 6| Step: 9
Training loss: 1.857519268989563
Validation loss: 2.215640265454528

Epoch: 6| Step: 10
Training loss: 2.3754565715789795
Validation loss: 2.226920579069404

Epoch: 6| Step: 11
Training loss: 2.501204490661621
Validation loss: 2.2193329911078177

Epoch: 6| Step: 12
Training loss: 2.004568576812744
Validation loss: 2.2158844163340907

Epoch: 6| Step: 13
Training loss: 2.05745005607605
Validation loss: 2.232824420416227

Epoch: 235| Step: 0
Training loss: 2.5437347888946533
Validation loss: 2.2305073340733848

Epoch: 6| Step: 1
Training loss: 2.3941233158111572
Validation loss: 2.2516003577939925

Epoch: 6| Step: 2
Training loss: 2.702136278152466
Validation loss: 2.2479319905722015

Epoch: 6| Step: 3
Training loss: 2.037169933319092
Validation loss: 2.247031539999029

Epoch: 6| Step: 4
Training loss: 2.295586585998535
Validation loss: 2.2433210906162055

Epoch: 6| Step: 5
Training loss: 3.046736001968384
Validation loss: 2.2473190933145504

Epoch: 6| Step: 6
Training loss: 2.2390923500061035
Validation loss: 2.2465313173109487

Epoch: 6| Step: 7
Training loss: 3.0553231239318848
Validation loss: 2.247435559508621

Epoch: 6| Step: 8
Training loss: 2.1250457763671875
Validation loss: 2.229086752860777

Epoch: 6| Step: 9
Training loss: 2.7981436252593994
Validation loss: 2.231458858777118

Epoch: 6| Step: 10
Training loss: 2.139376163482666
Validation loss: 2.23268707336918

Epoch: 6| Step: 11
Training loss: 2.358126163482666
Validation loss: 2.233083076374505

Epoch: 6| Step: 12
Training loss: 1.9222460985183716
Validation loss: 2.2405710194700506

Epoch: 6| Step: 13
Training loss: 1.8945822715759277
Validation loss: 2.240488859914964

Epoch: 236| Step: 0
Training loss: 2.499948263168335
Validation loss: 2.2229148008490123

Epoch: 6| Step: 1
Training loss: 2.415192127227783
Validation loss: 2.2300589776808217

Epoch: 6| Step: 2
Training loss: 1.610888957977295
Validation loss: 2.2249647007193616

Epoch: 6| Step: 3
Training loss: 2.563917636871338
Validation loss: 2.23087485631307

Epoch: 6| Step: 4
Training loss: 2.2876527309417725
Validation loss: 2.236516229567989

Epoch: 6| Step: 5
Training loss: 1.8529778718948364
Validation loss: 2.2407057310945246

Epoch: 6| Step: 6
Training loss: 2.6585521697998047
Validation loss: 2.24951534886514

Epoch: 6| Step: 7
Training loss: 2.5582633018493652
Validation loss: 2.2439252253501647

Epoch: 6| Step: 8
Training loss: 2.377983331680298
Validation loss: 2.2365036062015

Epoch: 6| Step: 9
Training loss: 2.413027048110962
Validation loss: 2.2400418725065006

Epoch: 6| Step: 10
Training loss: 2.598726272583008
Validation loss: 2.2401229207233717

Epoch: 6| Step: 11
Training loss: 2.259030818939209
Validation loss: 2.228286148399435

Epoch: 6| Step: 12
Training loss: 2.6942193508148193
Validation loss: 2.2354105223891554

Epoch: 6| Step: 13
Training loss: 3.47013521194458
Validation loss: 2.2499086497932352

Epoch: 237| Step: 0
Training loss: 1.7003366947174072
Validation loss: 2.243650985020463

Epoch: 6| Step: 1
Training loss: 2.7152419090270996
Validation loss: 2.2569553775172078

Epoch: 6| Step: 2
Training loss: 2.323948383331299
Validation loss: 2.2373461748964045

Epoch: 6| Step: 3
Training loss: 3.1441240310668945
Validation loss: 2.260561550817182

Epoch: 6| Step: 4
Training loss: 1.918358564376831
Validation loss: 2.2533449549828806

Epoch: 6| Step: 5
Training loss: 2.5437779426574707
Validation loss: 2.245620726257242

Epoch: 6| Step: 6
Training loss: 2.7885079383850098
Validation loss: 2.2414668631810013

Epoch: 6| Step: 7
Training loss: 2.162245750427246
Validation loss: 2.243688210364311

Epoch: 6| Step: 8
Training loss: 1.8922876119613647
Validation loss: 2.2260051209439515

Epoch: 6| Step: 9
Training loss: 2.1093337535858154
Validation loss: 2.228413793348497

Epoch: 6| Step: 10
Training loss: 2.9292640686035156
Validation loss: 2.214452839666797

Epoch: 6| Step: 11
Training loss: 2.8882131576538086
Validation loss: 2.2179943028316704

Epoch: 6| Step: 12
Training loss: 2.1403825283050537
Validation loss: 2.220272268018415

Epoch: 6| Step: 13
Training loss: 2.4796247482299805
Validation loss: 2.2262092995387253

Epoch: 238| Step: 0
Training loss: 2.781719207763672
Validation loss: 2.2282191604696293

Epoch: 6| Step: 1
Training loss: 1.6505951881408691
Validation loss: 2.2170397645683697

Epoch: 6| Step: 2
Training loss: 2.866711378097534
Validation loss: 2.2026385440621326

Epoch: 6| Step: 3
Training loss: 2.422954559326172
Validation loss: 2.2150213372322822

Epoch: 6| Step: 4
Training loss: 2.6816673278808594
Validation loss: 2.200044080775271

Epoch: 6| Step: 5
Training loss: 2.8953723907470703
Validation loss: 2.218874539098432

Epoch: 6| Step: 6
Training loss: 2.089898109436035
Validation loss: 2.207682560848933

Epoch: 6| Step: 7
Training loss: 1.6348185539245605
Validation loss: 2.2148738625229045

Epoch: 6| Step: 8
Training loss: 2.121419668197632
Validation loss: 2.2129776580359346

Epoch: 6| Step: 9
Training loss: 2.853848457336426
Validation loss: 2.2208340167999268

Epoch: 6| Step: 10
Training loss: 2.4321494102478027
Validation loss: 2.223490407389979

Epoch: 6| Step: 11
Training loss: 1.9539625644683838
Validation loss: 2.2318838078488588

Epoch: 6| Step: 12
Training loss: 3.072509288787842
Validation loss: 2.2296172444538405

Epoch: 6| Step: 13
Training loss: 2.2493271827697754
Validation loss: 2.225282075584576

Epoch: 239| Step: 0
Training loss: 2.149336099624634
Validation loss: 2.2345976957710842

Epoch: 6| Step: 1
Training loss: 2.7881064414978027
Validation loss: 2.241451355718797

Epoch: 6| Step: 2
Training loss: 1.7442333698272705
Validation loss: 2.232213727889522

Epoch: 6| Step: 3
Training loss: 2.610670804977417
Validation loss: 2.2268954605184574

Epoch: 6| Step: 4
Training loss: 2.532191276550293
Validation loss: 2.235713756212624

Epoch: 6| Step: 5
Training loss: 2.673977851867676
Validation loss: 2.2409511381579983

Epoch: 6| Step: 6
Training loss: 2.3401389122009277
Validation loss: 2.244437915022655

Epoch: 6| Step: 7
Training loss: 1.8880889415740967
Validation loss: 2.233343590972244

Epoch: 6| Step: 8
Training loss: 2.511699676513672
Validation loss: 2.2350588460122385

Epoch: 6| Step: 9
Training loss: 2.650658130645752
Validation loss: 2.2522157571649037

Epoch: 6| Step: 10
Training loss: 3.175581455230713
Validation loss: 2.234444664370629

Epoch: 6| Step: 11
Training loss: 1.8070406913757324
Validation loss: 2.232962603210121

Epoch: 6| Step: 12
Training loss: 3.0855114459991455
Validation loss: 2.2339567240848335

Epoch: 6| Step: 13
Training loss: 1.5404505729675293
Validation loss: 2.237393581739036

Epoch: 240| Step: 0
Training loss: 2.187638759613037
Validation loss: 2.228212715477072

Epoch: 6| Step: 1
Training loss: 3.09859037399292
Validation loss: 2.2431710304752475

Epoch: 6| Step: 2
Training loss: 1.8603880405426025
Validation loss: 2.2320198141118532

Epoch: 6| Step: 3
Training loss: 2.7027602195739746
Validation loss: 2.232720721152521

Epoch: 6| Step: 4
Training loss: 2.732388734817505
Validation loss: 2.235327079731931

Epoch: 6| Step: 5
Training loss: 2.3346972465515137
Validation loss: 2.24625842032894

Epoch: 6| Step: 6
Training loss: 2.711805582046509
Validation loss: 2.22652498368294

Epoch: 6| Step: 7
Training loss: 2.560037136077881
Validation loss: 2.233139004758609

Epoch: 6| Step: 8
Training loss: 2.078533172607422
Validation loss: 2.219085242158623

Epoch: 6| Step: 9
Training loss: 2.2011895179748535
Validation loss: 2.2221119019293014

Epoch: 6| Step: 10
Training loss: 2.43941593170166
Validation loss: 2.2105386744263353

Epoch: 6| Step: 11
Training loss: 2.2575950622558594
Validation loss: 2.207116816633491

Epoch: 6| Step: 12
Training loss: 2.3399720191955566
Validation loss: 2.200209161286713

Epoch: 6| Step: 13
Training loss: 2.2340261936187744
Validation loss: 2.183428810488793

Epoch: 241| Step: 0
Training loss: 1.9618728160858154
Validation loss: 2.1871683956474386

Epoch: 6| Step: 1
Training loss: 2.8508005142211914
Validation loss: 2.1889423554943455

Epoch: 6| Step: 2
Training loss: 2.7600317001342773
Validation loss: 2.1946859769923712

Epoch: 6| Step: 3
Training loss: 2.411916732788086
Validation loss: 2.1908118827368623

Epoch: 6| Step: 4
Training loss: 2.705688953399658
Validation loss: 2.1951458556677705

Epoch: 6| Step: 5
Training loss: 1.8030505180358887
Validation loss: 2.2034715593502088

Epoch: 6| Step: 6
Training loss: 1.8459012508392334
Validation loss: 2.2158270548748713

Epoch: 6| Step: 7
Training loss: 2.841230869293213
Validation loss: 2.206268569474579

Epoch: 6| Step: 8
Training loss: 2.637690544128418
Validation loss: 2.2168155870129986

Epoch: 6| Step: 9
Training loss: 2.250771999359131
Validation loss: 2.207239907274964

Epoch: 6| Step: 10
Training loss: 2.2163963317871094
Validation loss: 2.20857629083818

Epoch: 6| Step: 11
Training loss: 2.5712027549743652
Validation loss: 2.2093810637791953

Epoch: 6| Step: 12
Training loss: 2.8560004234313965
Validation loss: 2.211320084910239

Epoch: 6| Step: 13
Training loss: 1.5872912406921387
Validation loss: 2.2216304989271265

Epoch: 242| Step: 0
Training loss: 1.744035243988037
Validation loss: 2.20996190655616

Epoch: 6| Step: 1
Training loss: 2.175394058227539
Validation loss: 2.2374864060391664

Epoch: 6| Step: 2
Training loss: 2.301403522491455
Validation loss: 2.2418075556396158

Epoch: 6| Step: 3
Training loss: 2.7483582496643066
Validation loss: 2.275438224115679

Epoch: 6| Step: 4
Training loss: 2.6001758575439453
Validation loss: 2.2909636369315525

Epoch: 6| Step: 5
Training loss: 2.736480474472046
Validation loss: 2.2757946329732097

Epoch: 6| Step: 6
Training loss: 2.748680830001831
Validation loss: 2.24808007414623

Epoch: 6| Step: 7
Training loss: 2.908837080001831
Validation loss: 2.2439639119691748

Epoch: 6| Step: 8
Training loss: 2.3062570095062256
Validation loss: 2.2104398127525084

Epoch: 6| Step: 9
Training loss: 2.12575626373291
Validation loss: 2.2062047886592087

Epoch: 6| Step: 10
Training loss: 2.288248062133789
Validation loss: 2.1994932031118744

Epoch: 6| Step: 11
Training loss: 2.7721500396728516
Validation loss: 2.207867371138706

Epoch: 6| Step: 12
Training loss: 2.1031389236450195
Validation loss: 2.221134835673917

Epoch: 6| Step: 13
Training loss: 2.3623900413513184
Validation loss: 2.238105397070608

Epoch: 243| Step: 0
Training loss: 1.9044978618621826
Validation loss: 2.2343913765363794

Epoch: 6| Step: 1
Training loss: 2.0837044715881348
Validation loss: 2.2408959583569596

Epoch: 6| Step: 2
Training loss: 2.8655998706817627
Validation loss: 2.235385548683905

Epoch: 6| Step: 3
Training loss: 2.032043933868408
Validation loss: 2.2434365890359365

Epoch: 6| Step: 4
Training loss: 2.6175150871276855
Validation loss: 2.241487790179509

Epoch: 6| Step: 5
Training loss: 2.2057557106018066
Validation loss: 2.248995251553033

Epoch: 6| Step: 6
Training loss: 2.2913858890533447
Validation loss: 2.225655209633612

Epoch: 6| Step: 7
Training loss: 2.711620569229126
Validation loss: 2.219711124256093

Epoch: 6| Step: 8
Training loss: 2.413245677947998
Validation loss: 2.211654963031892

Epoch: 6| Step: 9
Training loss: 2.4914121627807617
Validation loss: 2.216749398939071

Epoch: 6| Step: 10
Training loss: 2.9022903442382812
Validation loss: 2.218144755209646

Epoch: 6| Step: 11
Training loss: 2.054905414581299
Validation loss: 2.229398190334279

Epoch: 6| Step: 12
Training loss: 3.319608211517334
Validation loss: 2.2420145670572915

Epoch: 6| Step: 13
Training loss: 1.7013533115386963
Validation loss: 2.2542341960373746

Epoch: 244| Step: 0
Training loss: 2.6242127418518066
Validation loss: 2.257494561133846

Epoch: 6| Step: 1
Training loss: 2.8282957077026367
Validation loss: 2.2399352032651185

Epoch: 6| Step: 2
Training loss: 2.3219175338745117
Validation loss: 2.250553705359018

Epoch: 6| Step: 3
Training loss: 2.4560561180114746
Validation loss: 2.221616659113156

Epoch: 6| Step: 4
Training loss: 1.915604829788208
Validation loss: 2.2173716150304323

Epoch: 6| Step: 5
Training loss: 2.292661190032959
Validation loss: 2.2058699541194464

Epoch: 6| Step: 6
Training loss: 2.3561599254608154
Validation loss: 2.201003284864528

Epoch: 6| Step: 7
Training loss: 2.218357801437378
Validation loss: 2.198867113359513

Epoch: 6| Step: 8
Training loss: 2.2750284671783447
Validation loss: 2.1976971639099943

Epoch: 6| Step: 9
Training loss: 2.3836073875427246
Validation loss: 2.195938471824892

Epoch: 6| Step: 10
Training loss: 2.105206251144409
Validation loss: 2.2106146889348186

Epoch: 6| Step: 11
Training loss: 2.6966617107391357
Validation loss: 2.2089274698688137

Epoch: 6| Step: 12
Training loss: 2.8870201110839844
Validation loss: 2.196382914820025

Epoch: 6| Step: 13
Training loss: 2.4479384422302246
Validation loss: 2.193625347588652

Epoch: 245| Step: 0
Training loss: 2.4778947830200195
Validation loss: 2.188739276701404

Epoch: 6| Step: 1
Training loss: 2.520123243331909
Validation loss: 2.2067203752456175

Epoch: 6| Step: 2
Training loss: 1.7726750373840332
Validation loss: 2.2033997120395785

Epoch: 6| Step: 3
Training loss: 2.483917236328125
Validation loss: 2.208795347521382

Epoch: 6| Step: 4
Training loss: 2.6898000240325928
Validation loss: 2.211354599204115

Epoch: 6| Step: 5
Training loss: 3.142813205718994
Validation loss: 2.2139956502504248

Epoch: 6| Step: 6
Training loss: 2.815871238708496
Validation loss: 2.2141397255723194

Epoch: 6| Step: 7
Training loss: 2.657876491546631
Validation loss: 2.2195042410204486

Epoch: 6| Step: 8
Training loss: 2.249220132827759
Validation loss: 2.2026876634167087

Epoch: 6| Step: 9
Training loss: 2.6973814964294434
Validation loss: 2.2034548700496717

Epoch: 6| Step: 10
Training loss: 1.7387621402740479
Validation loss: 2.205006153352799

Epoch: 6| Step: 11
Training loss: 2.2515058517456055
Validation loss: 2.203437791075758

Epoch: 6| Step: 12
Training loss: 2.0673296451568604
Validation loss: 2.204009038145824

Epoch: 6| Step: 13
Training loss: 1.7755920886993408
Validation loss: 2.202812381969985

Epoch: 246| Step: 0
Training loss: 2.8993592262268066
Validation loss: 2.198986486722064

Epoch: 6| Step: 1
Training loss: 2.406404495239258
Validation loss: 2.2026162608977287

Epoch: 6| Step: 2
Training loss: 2.5871667861938477
Validation loss: 2.2015809064270346

Epoch: 6| Step: 3
Training loss: 1.4257653951644897
Validation loss: 2.206781659075009

Epoch: 6| Step: 4
Training loss: 2.3257038593292236
Validation loss: 2.211548843691426

Epoch: 6| Step: 5
Training loss: 2.347655773162842
Validation loss: 2.217318273359729

Epoch: 6| Step: 6
Training loss: 2.3936049938201904
Validation loss: 2.2217111408069568

Epoch: 6| Step: 7
Training loss: 2.5734028816223145
Validation loss: 2.2302195205483386

Epoch: 6| Step: 8
Training loss: 1.9689029455184937
Validation loss: 2.230372828821982

Epoch: 6| Step: 9
Training loss: 2.3657939434051514
Validation loss: 2.2537050734284105

Epoch: 6| Step: 10
Training loss: 2.24981951713562
Validation loss: 2.261777226642896

Epoch: 6| Step: 11
Training loss: 2.1942784786224365
Validation loss: 2.2580359123086415

Epoch: 6| Step: 12
Training loss: 3.586297035217285
Validation loss: 2.249803453363398

Epoch: 6| Step: 13
Training loss: 2.4602346420288086
Validation loss: 2.2247782548268638

Epoch: 247| Step: 0
Training loss: 2.7754106521606445
Validation loss: 2.2295761031489216

Epoch: 6| Step: 1
Training loss: 2.74276065826416
Validation loss: 2.2161732694154144

Epoch: 6| Step: 2
Training loss: 2.531947612762451
Validation loss: 2.2126118777900614

Epoch: 6| Step: 3
Training loss: 2.6294002532958984
Validation loss: 2.2102210624243623

Epoch: 6| Step: 4
Training loss: 2.1820223331451416
Validation loss: 2.2076411106253184

Epoch: 6| Step: 5
Training loss: 2.4020743370056152
Validation loss: 2.204403405548424

Epoch: 6| Step: 6
Training loss: 1.953324317932129
Validation loss: 2.203926358171689

Epoch: 6| Step: 7
Training loss: 2.0575337409973145
Validation loss: 2.2017007156084945

Epoch: 6| Step: 8
Training loss: 3.0203731060028076
Validation loss: 2.201831397189889

Epoch: 6| Step: 9
Training loss: 1.6551483869552612
Validation loss: 2.208193261136291

Epoch: 6| Step: 10
Training loss: 2.202207565307617
Validation loss: 2.2041255222853793

Epoch: 6| Step: 11
Training loss: 2.882706642150879
Validation loss: 2.2025955018176826

Epoch: 6| Step: 12
Training loss: 2.2797675132751465
Validation loss: 2.197230041667979

Epoch: 6| Step: 13
Training loss: 2.3944709300994873
Validation loss: 2.192065458143911

Epoch: 248| Step: 0
Training loss: 2.912315845489502
Validation loss: 2.1951038029886063

Epoch: 6| Step: 1
Training loss: 2.1405534744262695
Validation loss: 2.193314507443418

Epoch: 6| Step: 2
Training loss: 2.564723491668701
Validation loss: 2.1962476263764086

Epoch: 6| Step: 3
Training loss: 2.875786542892456
Validation loss: 2.197442049621254

Epoch: 6| Step: 4
Training loss: 1.8665624856948853
Validation loss: 2.1985955392160723

Epoch: 6| Step: 5
Training loss: 1.6628830432891846
Validation loss: 2.204899590502503

Epoch: 6| Step: 6
Training loss: 2.689749240875244
Validation loss: 2.2095650447312223

Epoch: 6| Step: 7
Training loss: 1.9318761825561523
Validation loss: 2.2022564398345126

Epoch: 6| Step: 8
Training loss: 2.558566093444824
Validation loss: 2.2028532874199653

Epoch: 6| Step: 9
Training loss: 3.0051498413085938
Validation loss: 2.2091719040306668

Epoch: 6| Step: 10
Training loss: 2.0955188274383545
Validation loss: 2.2115386429653374

Epoch: 6| Step: 11
Training loss: 2.4935483932495117
Validation loss: 2.2022183710528958

Epoch: 6| Step: 12
Training loss: 2.5385823249816895
Validation loss: 2.2083729133811048

Epoch: 6| Step: 13
Training loss: 2.1049113273620605
Validation loss: 2.195147083651635

Epoch: 249| Step: 0
Training loss: 2.1533594131469727
Validation loss: 2.2093868486342894

Epoch: 6| Step: 1
Training loss: 2.3063948154449463
Validation loss: 2.2141875246519684

Epoch: 6| Step: 2
Training loss: 2.2607157230377197
Validation loss: 2.202904603814566

Epoch: 6| Step: 3
Training loss: 2.510725498199463
Validation loss: 2.2158700022646176

Epoch: 6| Step: 4
Training loss: 2.562756061553955
Validation loss: 2.212894728106837

Epoch: 6| Step: 5
Training loss: 2.4407553672790527
Validation loss: 2.2139167119097967

Epoch: 6| Step: 6
Training loss: 2.2984423637390137
Validation loss: 2.20951759687034

Epoch: 6| Step: 7
Training loss: 2.8394415378570557
Validation loss: 2.2154586789428548

Epoch: 6| Step: 8
Training loss: 2.7055091857910156
Validation loss: 2.2119600003765476

Epoch: 6| Step: 9
Training loss: 2.42099666595459
Validation loss: 2.2060764117907454

Epoch: 6| Step: 10
Training loss: 2.3735768795013428
Validation loss: 2.1959420481035785

Epoch: 6| Step: 11
Training loss: 1.9496761560440063
Validation loss: 2.2052875821308424

Epoch: 6| Step: 12
Training loss: 2.600921154022217
Validation loss: 2.196033976411307

Epoch: 6| Step: 13
Training loss: 2.0405006408691406
Validation loss: 2.20158367003164

Epoch: 250| Step: 0
Training loss: 2.5263988971710205
Validation loss: 2.2005989807908253

Epoch: 6| Step: 1
Training loss: 1.9778525829315186
Validation loss: 2.2015062224480415

Epoch: 6| Step: 2
Training loss: 2.953510284423828
Validation loss: 2.209515044766088

Epoch: 6| Step: 3
Training loss: 1.7158281803131104
Validation loss: 2.217102894219019

Epoch: 6| Step: 4
Training loss: 2.4587364196777344
Validation loss: 2.214381428175075

Epoch: 6| Step: 5
Training loss: 2.2811689376831055
Validation loss: 2.220023367994575

Epoch: 6| Step: 6
Training loss: 2.5191879272460938
Validation loss: 2.213408026643979

Epoch: 6| Step: 7
Training loss: 1.8227894306182861
Validation loss: 2.2191680554420716

Epoch: 6| Step: 8
Training loss: 2.8318514823913574
Validation loss: 2.213117480278015

Epoch: 6| Step: 9
Training loss: 2.1304519176483154
Validation loss: 2.2316440689948296

Epoch: 6| Step: 10
Training loss: 2.6006412506103516
Validation loss: 2.225093815916328

Epoch: 6| Step: 11
Training loss: 2.23976469039917
Validation loss: 2.2374458800080004

Epoch: 6| Step: 12
Training loss: 2.906123638153076
Validation loss: 2.2142157118807555

Epoch: 6| Step: 13
Training loss: 2.733767509460449
Validation loss: 2.2129966469221216

Epoch: 251| Step: 0
Training loss: 2.9256465435028076
Validation loss: 2.21776948436614

Epoch: 6| Step: 1
Training loss: 2.351022243499756
Validation loss: 2.236167129649911

Epoch: 6| Step: 2
Training loss: 2.432532548904419
Validation loss: 2.2100039579535045

Epoch: 6| Step: 3
Training loss: 2.658369779586792
Validation loss: 2.2202893636559926

Epoch: 6| Step: 4
Training loss: 2.024883985519409
Validation loss: 2.2101755936940513

Epoch: 6| Step: 5
Training loss: 2.5038561820983887
Validation loss: 2.194504363562471

Epoch: 6| Step: 6
Training loss: 2.4500341415405273
Validation loss: 2.191179629295103

Epoch: 6| Step: 7
Training loss: 1.9076048135757446
Validation loss: 2.1934611874241985

Epoch: 6| Step: 8
Training loss: 2.0832574367523193
Validation loss: 2.183566875355218

Epoch: 6| Step: 9
Training loss: 2.7588510513305664
Validation loss: 2.1828610820154988

Epoch: 6| Step: 10
Training loss: 2.112483024597168
Validation loss: 2.183163595455949

Epoch: 6| Step: 11
Training loss: 2.229454755783081
Validation loss: 2.1753971192144577

Epoch: 6| Step: 12
Training loss: 3.070436954498291
Validation loss: 2.1711458160031225

Epoch: 6| Step: 13
Training loss: 2.063594341278076
Validation loss: 2.1858898362805768

Epoch: 252| Step: 0
Training loss: 2.594627857208252
Validation loss: 2.2009732697599675

Epoch: 6| Step: 1
Training loss: 2.1850461959838867
Validation loss: 2.1984226421643327

Epoch: 6| Step: 2
Training loss: 2.5002245903015137
Validation loss: 2.189064480925119

Epoch: 6| Step: 3
Training loss: 1.9874273538589478
Validation loss: 2.1978199815237396

Epoch: 6| Step: 4
Training loss: 2.2095274925231934
Validation loss: 2.19193003254552

Epoch: 6| Step: 5
Training loss: 2.1153578758239746
Validation loss: 2.205182898429132

Epoch: 6| Step: 6
Training loss: 1.9808731079101562
Validation loss: 2.221613209734681

Epoch: 6| Step: 7
Training loss: 2.470211982727051
Validation loss: 2.2135780088363157

Epoch: 6| Step: 8
Training loss: 3.643916368484497
Validation loss: 2.2251391923555763

Epoch: 6| Step: 9
Training loss: 1.99239182472229
Validation loss: 2.2292327393767652

Epoch: 6| Step: 10
Training loss: 3.0720205307006836
Validation loss: 2.2090465573854345

Epoch: 6| Step: 11
Training loss: 2.3429489135742188
Validation loss: 2.2229057999067408

Epoch: 6| Step: 12
Training loss: 2.2301433086395264
Validation loss: 2.2193329180440595

Epoch: 6| Step: 13
Training loss: 1.7343907356262207
Validation loss: 2.2182690379440144

Epoch: 253| Step: 0
Training loss: 2.226252317428589
Validation loss: 2.214823179347541

Epoch: 6| Step: 1
Training loss: 2.714310884475708
Validation loss: 2.2106734911600747

Epoch: 6| Step: 2
Training loss: 1.7965184450149536
Validation loss: 2.2063455209937146

Epoch: 6| Step: 3
Training loss: 2.594444990158081
Validation loss: 2.2082500355218047

Epoch: 6| Step: 4
Training loss: 2.8348817825317383
Validation loss: 2.2087438952538276

Epoch: 6| Step: 5
Training loss: 1.9879605770111084
Validation loss: 2.213080054970198

Epoch: 6| Step: 6
Training loss: 2.122622013092041
Validation loss: 2.1941772853174517

Epoch: 6| Step: 7
Training loss: 2.2641448974609375
Validation loss: 2.2057598867724018

Epoch: 6| Step: 8
Training loss: 1.9241750240325928
Validation loss: 2.2026488216974403

Epoch: 6| Step: 9
Training loss: 2.740710496902466
Validation loss: 2.2018670907584568

Epoch: 6| Step: 10
Training loss: 2.511809825897217
Validation loss: 2.1882372863831057

Epoch: 6| Step: 11
Training loss: 2.767890453338623
Validation loss: 2.2046105041298816

Epoch: 6| Step: 12
Training loss: 2.296250343322754
Validation loss: 2.2040094432010444

Epoch: 6| Step: 13
Training loss: 2.5568418502807617
Validation loss: 2.204172016471945

Epoch: 254| Step: 0
Training loss: 1.5675971508026123
Validation loss: 2.214129981174264

Epoch: 6| Step: 1
Training loss: 2.502089500427246
Validation loss: 2.219611014089277

Epoch: 6| Step: 2
Training loss: 2.4120945930480957
Validation loss: 2.2167987720940703

Epoch: 6| Step: 3
Training loss: 2.615586280822754
Validation loss: 2.2249960566079743

Epoch: 6| Step: 4
Training loss: 2.158210039138794
Validation loss: 2.230401760788374

Epoch: 6| Step: 5
Training loss: 2.480363368988037
Validation loss: 2.22907179914495

Epoch: 6| Step: 6
Training loss: 1.9287199974060059
Validation loss: 2.217263966478327

Epoch: 6| Step: 7
Training loss: 2.7011327743530273
Validation loss: 2.2201569695626535

Epoch: 6| Step: 8
Training loss: 2.721454620361328
Validation loss: 2.211558852144467

Epoch: 6| Step: 9
Training loss: 2.555445432662964
Validation loss: 2.218352198600769

Epoch: 6| Step: 10
Training loss: 2.1082773208618164
Validation loss: 2.1965117557074434

Epoch: 6| Step: 11
Training loss: 2.6756439208984375
Validation loss: 2.194127800644085

Epoch: 6| Step: 12
Training loss: 2.4029793739318848
Validation loss: 2.2028759769214097

Epoch: 6| Step: 13
Training loss: 2.6421093940734863
Validation loss: 2.2023796548125563

Epoch: 255| Step: 0
Training loss: 2.701350688934326
Validation loss: 2.205452770315191

Epoch: 6| Step: 1
Training loss: 2.4262373447418213
Validation loss: 2.198746286412721

Epoch: 6| Step: 2
Training loss: 2.7230019569396973
Validation loss: 2.2045950094858804

Epoch: 6| Step: 3
Training loss: 2.5306966304779053
Validation loss: 2.2046284291052047

Epoch: 6| Step: 4
Training loss: 2.3614048957824707
Validation loss: 2.205498177518127

Epoch: 6| Step: 5
Training loss: 2.322929620742798
Validation loss: 2.2006611439489547

Epoch: 6| Step: 6
Training loss: 2.756631374359131
Validation loss: 2.190832009879492

Epoch: 6| Step: 7
Training loss: 2.0009663105010986
Validation loss: 2.201979983237482

Epoch: 6| Step: 8
Training loss: 2.5875983238220215
Validation loss: 2.1974906793204685

Epoch: 6| Step: 9
Training loss: 2.2661421298980713
Validation loss: 2.188701081019576

Epoch: 6| Step: 10
Training loss: 2.2917914390563965
Validation loss: 2.1956551767164663

Epoch: 6| Step: 11
Training loss: 1.7906967401504517
Validation loss: 2.208766971865008

Epoch: 6| Step: 12
Training loss: 2.5075926780700684
Validation loss: 2.1790684794866912

Epoch: 6| Step: 13
Training loss: 2.0509209632873535
Validation loss: 2.1943503169603247

Epoch: 256| Step: 0
Training loss: 2.3244729042053223
Validation loss: 2.1859937739628617

Epoch: 6| Step: 1
Training loss: 2.3159842491149902
Validation loss: 2.188438759055189

Epoch: 6| Step: 2
Training loss: 2.129438877105713
Validation loss: 2.183065765647478

Epoch: 6| Step: 3
Training loss: 2.874194383621216
Validation loss: 2.1826457028747885

Epoch: 6| Step: 4
Training loss: 1.7997584342956543
Validation loss: 2.193528172790363

Epoch: 6| Step: 5
Training loss: 2.432215690612793
Validation loss: 2.1917701164881387

Epoch: 6| Step: 6
Training loss: 1.7528510093688965
Validation loss: 2.1993884117372575

Epoch: 6| Step: 7
Training loss: 2.911196708679199
Validation loss: 2.2098189335997387

Epoch: 6| Step: 8
Training loss: 2.886382579803467
Validation loss: 2.2034864579477618

Epoch: 6| Step: 9
Training loss: 2.5327329635620117
Validation loss: 2.2038253853397984

Epoch: 6| Step: 10
Training loss: 2.5297353267669678
Validation loss: 2.190043516056512

Epoch: 6| Step: 11
Training loss: 2.214848518371582
Validation loss: 2.1933348294227355

Epoch: 6| Step: 12
Training loss: 2.137064218521118
Validation loss: 2.1913688477649482

Epoch: 6| Step: 13
Training loss: 2.494811534881592
Validation loss: 2.179729853906939

Epoch: 257| Step: 0
Training loss: 2.5577783584594727
Validation loss: 2.1958425647468975

Epoch: 6| Step: 1
Training loss: 2.0759148597717285
Validation loss: 2.202975494887239

Epoch: 6| Step: 2
Training loss: 2.383530378341675
Validation loss: 2.1954896860225226

Epoch: 6| Step: 3
Training loss: 2.157932758331299
Validation loss: 2.2024244851963495

Epoch: 6| Step: 4
Training loss: 2.1683902740478516
Validation loss: 2.1960351364586943

Epoch: 6| Step: 5
Training loss: 2.6832146644592285
Validation loss: 2.1984415182503323

Epoch: 6| Step: 6
Training loss: 2.4329018592834473
Validation loss: 2.2109906468340146

Epoch: 6| Step: 7
Training loss: 2.6873221397399902
Validation loss: 2.2182337366124636

Epoch: 6| Step: 8
Training loss: 2.249238967895508
Validation loss: 2.2008529939959125

Epoch: 6| Step: 9
Training loss: 2.4110918045043945
Validation loss: 2.194956435952135

Epoch: 6| Step: 10
Training loss: 2.5969085693359375
Validation loss: 2.1919278226872927

Epoch: 6| Step: 11
Training loss: 1.738422155380249
Validation loss: 2.1993136457217637

Epoch: 6| Step: 12
Training loss: 2.738860607147217
Validation loss: 2.1970892952334498

Epoch: 6| Step: 13
Training loss: 2.2248148918151855
Validation loss: 2.197332530893305

Epoch: 258| Step: 0
Training loss: 2.657973289489746
Validation loss: 2.191988165660571

Epoch: 6| Step: 1
Training loss: 2.516697645187378
Validation loss: 2.1743464341727634

Epoch: 6| Step: 2
Training loss: 1.7594367265701294
Validation loss: 2.1881785238942792

Epoch: 6| Step: 3
Training loss: 1.5258208513259888
Validation loss: 2.1883963666936403

Epoch: 6| Step: 4
Training loss: 2.58132266998291
Validation loss: 2.1891254648085563

Epoch: 6| Step: 5
Training loss: 2.758309841156006
Validation loss: 2.1930981836011334

Epoch: 6| Step: 6
Training loss: 2.6585745811462402
Validation loss: 2.199665948908816

Epoch: 6| Step: 7
Training loss: 2.912804126739502
Validation loss: 2.19735816473602

Epoch: 6| Step: 8
Training loss: 2.0055603981018066
Validation loss: 2.2147450780355804

Epoch: 6| Step: 9
Training loss: 1.614814281463623
Validation loss: 2.2086496994059575

Epoch: 6| Step: 10
Training loss: 2.9804866313934326
Validation loss: 2.225418677894018

Epoch: 6| Step: 11
Training loss: 2.20815372467041
Validation loss: 2.21650299461939

Epoch: 6| Step: 12
Training loss: 2.6178131103515625
Validation loss: 2.2399001839340373

Epoch: 6| Step: 13
Training loss: 2.7101025581359863
Validation loss: 2.2167263377097344

Epoch: 259| Step: 0
Training loss: 2.028796672821045
Validation loss: 2.2140598553483204

Epoch: 6| Step: 1
Training loss: 2.7014694213867188
Validation loss: 2.2161833419594714

Epoch: 6| Step: 2
Training loss: 2.3627254962921143
Validation loss: 2.1927507359494447

Epoch: 6| Step: 3
Training loss: 2.647939443588257
Validation loss: 2.197084370479789

Epoch: 6| Step: 4
Training loss: 2.3135528564453125
Validation loss: 2.1912946047321444

Epoch: 6| Step: 5
Training loss: 2.593129873275757
Validation loss: 2.184504416681105

Epoch: 6| Step: 6
Training loss: 2.4193787574768066
Validation loss: 2.1900083659797587

Epoch: 6| Step: 7
Training loss: 2.4164366722106934
Validation loss: 2.1884369337430565

Epoch: 6| Step: 8
Training loss: 2.5257692337036133
Validation loss: 2.191773665848599

Epoch: 6| Step: 9
Training loss: 2.348456382751465
Validation loss: 2.1991729761964534

Epoch: 6| Step: 10
Training loss: 2.509692430496216
Validation loss: 2.1957336689836238

Epoch: 6| Step: 11
Training loss: 2.0887205600738525
Validation loss: 2.1936163466463805

Epoch: 6| Step: 12
Training loss: 2.085940361022949
Validation loss: 2.196032239544776

Epoch: 6| Step: 13
Training loss: 1.7627809047698975
Validation loss: 2.1839338220575804

Epoch: 260| Step: 0
Training loss: 3.0842063426971436
Validation loss: 2.184653538529591

Epoch: 6| Step: 1
Training loss: 1.399010419845581
Validation loss: 2.1736034052346342

Epoch: 6| Step: 2
Training loss: 2.7067110538482666
Validation loss: 2.16465861053877

Epoch: 6| Step: 3
Training loss: 2.6718993186950684
Validation loss: 2.1659881094450593

Epoch: 6| Step: 4
Training loss: 1.9065382480621338
Validation loss: 2.1528653226872927

Epoch: 6| Step: 5
Training loss: 2.382336139678955
Validation loss: 2.1718717787855413

Epoch: 6| Step: 6
Training loss: 2.4815330505371094
Validation loss: 2.173806603236865

Epoch: 6| Step: 7
Training loss: 2.44146728515625
Validation loss: 2.158653895060221

Epoch: 6| Step: 8
Training loss: 2.721312999725342
Validation loss: 2.163135964383361

Epoch: 6| Step: 9
Training loss: 2.466923236846924
Validation loss: 2.1677978115697063

Epoch: 6| Step: 10
Training loss: 2.3387954235076904
Validation loss: 2.166052267115603

Epoch: 6| Step: 11
Training loss: 2.359495162963867
Validation loss: 2.176063868307298

Epoch: 6| Step: 12
Training loss: 2.35699462890625
Validation loss: 2.176538141824866

Epoch: 6| Step: 13
Training loss: 1.2558228969573975
Validation loss: 2.1790729645759828

Epoch: 261| Step: 0
Training loss: 2.7887840270996094
Validation loss: 2.2023782473738476

Epoch: 6| Step: 1
Training loss: 2.491973638534546
Validation loss: 2.1780418888215096

Epoch: 6| Step: 2
Training loss: 2.508807897567749
Validation loss: 2.1902374554705877

Epoch: 6| Step: 3
Training loss: 2.9978771209716797
Validation loss: 2.17973389035912

Epoch: 6| Step: 4
Training loss: 2.422903537750244
Validation loss: 2.1986409797463367

Epoch: 6| Step: 5
Training loss: 2.1440351009368896
Validation loss: 2.1959773545624106

Epoch: 6| Step: 6
Training loss: 2.794288158416748
Validation loss: 2.1955630817720966

Epoch: 6| Step: 7
Training loss: 2.461928367614746
Validation loss: 2.1862372275321715

Epoch: 6| Step: 8
Training loss: 1.5239075422286987
Validation loss: 2.194585572006882

Epoch: 6| Step: 9
Training loss: 1.7088361978530884
Validation loss: 2.1922202494836625

Epoch: 6| Step: 10
Training loss: 2.1208183765411377
Validation loss: 2.19444267980514

Epoch: 6| Step: 11
Training loss: 3.128775119781494
Validation loss: 2.1870595934570476

Epoch: 6| Step: 12
Training loss: 1.8014429807662964
Validation loss: 2.180163291192824

Epoch: 6| Step: 13
Training loss: 2.1672379970550537
Validation loss: 2.1837519125271867

Epoch: 262| Step: 0
Training loss: 2.1411640644073486
Validation loss: 2.201706963200723

Epoch: 6| Step: 1
Training loss: 2.254755973815918
Validation loss: 2.2108553327539915

Epoch: 6| Step: 2
Training loss: 2.2220795154571533
Validation loss: 2.2121291237492717

Epoch: 6| Step: 3
Training loss: 3.062358856201172
Validation loss: 2.238932635194512

Epoch: 6| Step: 4
Training loss: 2.0077638626098633
Validation loss: 2.2290405996384157

Epoch: 6| Step: 5
Training loss: 2.8530383110046387
Validation loss: 2.2306215250363914

Epoch: 6| Step: 6
Training loss: 2.310976266860962
Validation loss: 2.2174781471170406

Epoch: 6| Step: 7
Training loss: 2.4018402099609375
Validation loss: 2.207952482725984

Epoch: 6| Step: 8
Training loss: 2.1085875034332275
Validation loss: 2.1974720852349394

Epoch: 6| Step: 9
Training loss: 2.05062198638916
Validation loss: 2.1865612511993735

Epoch: 6| Step: 10
Training loss: 2.09175181388855
Validation loss: 2.1850525602217643

Epoch: 6| Step: 11
Training loss: 3.128087282180786
Validation loss: 2.175102182613906

Epoch: 6| Step: 12
Training loss: 2.378568649291992
Validation loss: 2.191222404920927

Epoch: 6| Step: 13
Training loss: 1.9967929124832153
Validation loss: 2.1909381458836217

Epoch: 263| Step: 0
Training loss: 2.1035006046295166
Validation loss: 2.2119671003792876

Epoch: 6| Step: 1
Training loss: 2.052696704864502
Validation loss: 2.2339072406932874

Epoch: 6| Step: 2
Training loss: 2.1788244247436523
Validation loss: 2.225842765582505

Epoch: 6| Step: 3
Training loss: 3.02388334274292
Validation loss: 2.2135958235750914

Epoch: 6| Step: 4
Training loss: 2.456695318222046
Validation loss: 2.190860971327751

Epoch: 6| Step: 5
Training loss: 3.5215983390808105
Validation loss: 2.189229375572615

Epoch: 6| Step: 6
Training loss: 2.4337310791015625
Validation loss: 2.1629606023911507

Epoch: 6| Step: 7
Training loss: 3.0861728191375732
Validation loss: 2.1669412364241896

Epoch: 6| Step: 8
Training loss: 1.937849521636963
Validation loss: 2.1665984097347466

Epoch: 6| Step: 9
Training loss: 1.878551959991455
Validation loss: 2.165225972411453

Epoch: 6| Step: 10
Training loss: 2.2392163276672363
Validation loss: 2.1716903640377905

Epoch: 6| Step: 11
Training loss: 2.0827765464782715
Validation loss: 2.166468060144814

Epoch: 6| Step: 12
Training loss: 1.4339780807495117
Validation loss: 2.180015730601485

Epoch: 6| Step: 13
Training loss: 3.1466174125671387
Validation loss: 2.177012053869104

Epoch: 264| Step: 0
Training loss: 2.6801319122314453
Validation loss: 2.1784987885464906

Epoch: 6| Step: 1
Training loss: 2.0523338317871094
Validation loss: 2.1994291633687992

Epoch: 6| Step: 2
Training loss: 2.525155544281006
Validation loss: 2.1959894190552416

Epoch: 6| Step: 3
Training loss: 2.7385125160217285
Validation loss: 2.188967958573372

Epoch: 6| Step: 4
Training loss: 2.601840019226074
Validation loss: 2.1803833823050223

Epoch: 6| Step: 5
Training loss: 2.5910966396331787
Validation loss: 2.1944320278783

Epoch: 6| Step: 6
Training loss: 2.013639450073242
Validation loss: 2.202339659455002

Epoch: 6| Step: 7
Training loss: 2.0707945823669434
Validation loss: 2.206561270580497

Epoch: 6| Step: 8
Training loss: 2.6585869789123535
Validation loss: 2.2090911044869372

Epoch: 6| Step: 9
Training loss: 3.0237808227539062
Validation loss: 2.1816202197023618

Epoch: 6| Step: 10
Training loss: 2.0537350177764893
Validation loss: 2.185815485574866

Epoch: 6| Step: 11
Training loss: 1.7201859951019287
Validation loss: 2.1798900404284076

Epoch: 6| Step: 12
Training loss: 2.2462992668151855
Validation loss: 2.186260913008003

Epoch: 6| Step: 13
Training loss: 2.1695749759674072
Validation loss: 2.1824890413591937

Epoch: 265| Step: 0
Training loss: 2.549663543701172
Validation loss: 2.1856750531863143

Epoch: 6| Step: 1
Training loss: 1.933927297592163
Validation loss: 2.1911253531773887

Epoch: 6| Step: 2
Training loss: 2.013259172439575
Validation loss: 2.1931961877371675

Epoch: 6| Step: 3
Training loss: 2.1151208877563477
Validation loss: 2.1886073722634265

Epoch: 6| Step: 4
Training loss: 3.6922640800476074
Validation loss: 2.174495691894203

Epoch: 6| Step: 5
Training loss: 1.9144755601882935
Validation loss: 2.1721614330045638

Epoch: 6| Step: 6
Training loss: 2.0016722679138184
Validation loss: 2.1753292135013047

Epoch: 6| Step: 7
Training loss: 1.7722147703170776
Validation loss: 2.17700776233468

Epoch: 6| Step: 8
Training loss: 2.7721481323242188
Validation loss: 2.180990772862588

Epoch: 6| Step: 9
Training loss: 2.587958812713623
Validation loss: 2.1864159081571843

Epoch: 6| Step: 10
Training loss: 2.7623491287231445
Validation loss: 2.185122802693357

Epoch: 6| Step: 11
Training loss: 2.428713083267212
Validation loss: 2.1969304225778066

Epoch: 6| Step: 12
Training loss: 1.9453771114349365
Validation loss: 2.2000107406288065

Epoch: 6| Step: 13
Training loss: 2.58500599861145
Validation loss: 2.205674050956644

Epoch: 266| Step: 0
Training loss: 2.6983304023742676
Validation loss: 2.206913491731049

Epoch: 6| Step: 1
Training loss: 2.1620821952819824
Validation loss: 2.2038150461771155

Epoch: 6| Step: 2
Training loss: 1.798638105392456
Validation loss: 2.189856594608676

Epoch: 6| Step: 3
Training loss: 2.2031121253967285
Validation loss: 2.1823297880029164

Epoch: 6| Step: 4
Training loss: 2.4530234336853027
Validation loss: 2.1884494238002326

Epoch: 6| Step: 5
Training loss: 2.33651065826416
Validation loss: 2.1816377793588946

Epoch: 6| Step: 6
Training loss: 2.3314437866210938
Validation loss: 2.174137282115157

Epoch: 6| Step: 7
Training loss: 3.1386539936065674
Validation loss: 2.1889013423714587

Epoch: 6| Step: 8
Training loss: 1.8227815628051758
Validation loss: 2.1933308750070553

Epoch: 6| Step: 9
Training loss: 2.238586187362671
Validation loss: 2.1995599962049917

Epoch: 6| Step: 10
Training loss: 3.07625675201416
Validation loss: 2.191430043148738

Epoch: 6| Step: 11
Training loss: 2.2683701515197754
Validation loss: 2.1811686023589103

Epoch: 6| Step: 12
Training loss: 2.199113130569458
Validation loss: 2.1883376234321186

Epoch: 6| Step: 13
Training loss: 2.3248462677001953
Validation loss: 2.1901784071358303

Epoch: 267| Step: 0
Training loss: 1.961663007736206
Validation loss: 2.1700823281400945

Epoch: 6| Step: 1
Training loss: 1.9869085550308228
Validation loss: 2.1754759024548274

Epoch: 6| Step: 2
Training loss: 2.105842113494873
Validation loss: 2.1752224160778906

Epoch: 6| Step: 3
Training loss: 2.3561065196990967
Validation loss: 2.1849542484488538

Epoch: 6| Step: 4
Training loss: 2.3380961418151855
Validation loss: 2.198818511860345

Epoch: 6| Step: 5
Training loss: 2.412821054458618
Validation loss: 2.201417737109687

Epoch: 6| Step: 6
Training loss: 2.0058236122131348
Validation loss: 2.189157332143476

Epoch: 6| Step: 7
Training loss: 2.8375139236450195
Validation loss: 2.170972216513849

Epoch: 6| Step: 8
Training loss: 2.980792999267578
Validation loss: 2.1781128145033315

Epoch: 6| Step: 9
Training loss: 2.419943332672119
Validation loss: 2.170626868483841

Epoch: 6| Step: 10
Training loss: 3.397428274154663
Validation loss: 2.1640482077034573

Epoch: 6| Step: 11
Training loss: 2.676748275756836
Validation loss: 2.1661946183891705

Epoch: 6| Step: 12
Training loss: 1.4021075963974
Validation loss: 2.1644506890286683

Epoch: 6| Step: 13
Training loss: 1.8540772199630737
Validation loss: 2.168926890178393

Epoch: 268| Step: 0
Training loss: 2.672365665435791
Validation loss: 2.168115723517633

Epoch: 6| Step: 1
Training loss: 2.3301212787628174
Validation loss: 2.1709642589733167

Epoch: 6| Step: 2
Training loss: 2.149643898010254
Validation loss: 2.162215225158199

Epoch: 6| Step: 3
Training loss: 3.0419116020202637
Validation loss: 2.182887079895184

Epoch: 6| Step: 4
Training loss: 2.2193665504455566
Validation loss: 2.166186568557575

Epoch: 6| Step: 5
Training loss: 2.147897720336914
Validation loss: 2.1681807246259464

Epoch: 6| Step: 6
Training loss: 2.346273422241211
Validation loss: 2.171238801812613

Epoch: 6| Step: 7
Training loss: 2.5629496574401855
Validation loss: 2.1571066123183056

Epoch: 6| Step: 8
Training loss: 2.216057538986206
Validation loss: 2.154607565172257

Epoch: 6| Step: 9
Training loss: 2.346000909805298
Validation loss: 2.17353622118632

Epoch: 6| Step: 10
Training loss: 2.2267065048217773
Validation loss: 2.169211228688558

Epoch: 6| Step: 11
Training loss: 2.2468643188476562
Validation loss: 2.1611789554677983

Epoch: 6| Step: 12
Training loss: 1.9382216930389404
Validation loss: 2.1590884244570168

Epoch: 6| Step: 13
Training loss: 2.532252073287964
Validation loss: 2.1632392483372844

Epoch: 269| Step: 0
Training loss: 2.266814708709717
Validation loss: 2.164751648902893

Epoch: 6| Step: 1
Training loss: 2.417262315750122
Validation loss: 2.170397720029277

Epoch: 6| Step: 2
Training loss: 2.254072904586792
Validation loss: 2.163448820831955

Epoch: 6| Step: 3
Training loss: 2.5785789489746094
Validation loss: 2.1696446659744426

Epoch: 6| Step: 4
Training loss: 2.9801864624023438
Validation loss: 2.183022113256557

Epoch: 6| Step: 5
Training loss: 2.079779624938965
Validation loss: 2.1848012196120394

Epoch: 6| Step: 6
Training loss: 2.213198661804199
Validation loss: 2.1619625860644924

Epoch: 6| Step: 7
Training loss: 1.651259183883667
Validation loss: 2.177361580633348

Epoch: 6| Step: 8
Training loss: 2.3492536544799805
Validation loss: 2.171950932471983

Epoch: 6| Step: 9
Training loss: 2.671748638153076
Validation loss: 2.1703420992820495

Epoch: 6| Step: 10
Training loss: 2.0627710819244385
Validation loss: 2.1764929704768683

Epoch: 6| Step: 11
Training loss: 3.196709632873535
Validation loss: 2.1819565501264346

Epoch: 6| Step: 12
Training loss: 1.8262531757354736
Validation loss: 2.180004891528878

Epoch: 6| Step: 13
Training loss: 2.0735385417938232
Validation loss: 2.1825556229519587

Epoch: 270| Step: 0
Training loss: 2.715517997741699
Validation loss: 2.1858695373740247

Epoch: 6| Step: 1
Training loss: 1.8580260276794434
Validation loss: 2.1785753619286323

Epoch: 6| Step: 2
Training loss: 2.317875385284424
Validation loss: 2.1765231393998667

Epoch: 6| Step: 3
Training loss: 2.4175355434417725
Validation loss: 2.1570948400805072

Epoch: 6| Step: 4
Training loss: 2.6941094398498535
Validation loss: 2.155835226017942

Epoch: 6| Step: 5
Training loss: 2.4986562728881836
Validation loss: 2.1625422252121793

Epoch: 6| Step: 6
Training loss: 2.2754130363464355
Validation loss: 2.1756636558040494

Epoch: 6| Step: 7
Training loss: 2.8871042728424072
Validation loss: 2.1652803985021447

Epoch: 6| Step: 8
Training loss: 2.220384120941162
Validation loss: 2.167153840423912

Epoch: 6| Step: 9
Training loss: 2.8639097213745117
Validation loss: 2.1587998687580066

Epoch: 6| Step: 10
Training loss: 1.8269200325012207
Validation loss: 2.1607996879085416

Epoch: 6| Step: 11
Training loss: 1.8023202419281006
Validation loss: 2.1501161270244147

Epoch: 6| Step: 12
Training loss: 2.042778253555298
Validation loss: 2.156808396821381

Epoch: 6| Step: 13
Training loss: 2.5332753658294678
Validation loss: 2.1624705817109797

Epoch: 271| Step: 0
Training loss: 1.374318242073059
Validation loss: 2.1725669266075216

Epoch: 6| Step: 1
Training loss: 2.451789379119873
Validation loss: 2.1686531497586157

Epoch: 6| Step: 2
Training loss: 2.60720157623291
Validation loss: 2.170071856949919

Epoch: 6| Step: 3
Training loss: 2.183763027191162
Validation loss: 2.1714782253388436

Epoch: 6| Step: 4
Training loss: 2.4059903621673584
Validation loss: 2.1677295251559188

Epoch: 6| Step: 5
Training loss: 2.7453877925872803
Validation loss: 2.1762697671049382

Epoch: 6| Step: 6
Training loss: 1.336674690246582
Validation loss: 2.1677192616206344

Epoch: 6| Step: 7
Training loss: 2.684394359588623
Validation loss: 2.168700425855575

Epoch: 6| Step: 8
Training loss: 2.41971492767334
Validation loss: 2.1628740961833666

Epoch: 6| Step: 9
Training loss: 2.491624116897583
Validation loss: 2.15098233889508

Epoch: 6| Step: 10
Training loss: 2.015951633453369
Validation loss: 2.1493076073226107

Epoch: 6| Step: 11
Training loss: 2.985582113265991
Validation loss: 2.151057177974332

Epoch: 6| Step: 12
Training loss: 2.5367727279663086
Validation loss: 2.16719574569374

Epoch: 6| Step: 13
Training loss: 2.572991132736206
Validation loss: 2.1794695303004277

Epoch: 272| Step: 0
Training loss: 1.9529156684875488
Validation loss: 2.168583652024628

Epoch: 6| Step: 1
Training loss: 2.7599754333496094
Validation loss: 2.168565191248412

Epoch: 6| Step: 2
Training loss: 2.655482530593872
Validation loss: 2.1789085916293565

Epoch: 6| Step: 3
Training loss: 2.0329833030700684
Validation loss: 2.1912062603940248

Epoch: 6| Step: 4
Training loss: 2.194915294647217
Validation loss: 2.1827768677024433

Epoch: 6| Step: 5
Training loss: 3.2319180965423584
Validation loss: 2.1806182271690777

Epoch: 6| Step: 6
Training loss: 3.141369342803955
Validation loss: 2.172848812995418

Epoch: 6| Step: 7
Training loss: 1.7215473651885986
Validation loss: 2.15669051806132

Epoch: 6| Step: 8
Training loss: 2.7577648162841797
Validation loss: 2.1494102478027344

Epoch: 6| Step: 9
Training loss: 1.587914228439331
Validation loss: 2.166422205586587

Epoch: 6| Step: 10
Training loss: 2.542991876602173
Validation loss: 2.135562199418263

Epoch: 6| Step: 11
Training loss: 2.2139925956726074
Validation loss: 2.1609553726770545

Epoch: 6| Step: 12
Training loss: 2.241518020629883
Validation loss: 2.1643049204221336

Epoch: 6| Step: 13
Training loss: 1.391876220703125
Validation loss: 2.1653844002754457

Epoch: 273| Step: 0
Training loss: 2.7410073280334473
Validation loss: 2.1676426882384927

Epoch: 6| Step: 1
Training loss: 2.5238547325134277
Validation loss: 2.1678033080152286

Epoch: 6| Step: 2
Training loss: 1.8158619403839111
Validation loss: 2.148920259168071

Epoch: 6| Step: 3
Training loss: 2.339313507080078
Validation loss: 2.179466479568071

Epoch: 6| Step: 4
Training loss: 1.8477951288223267
Validation loss: 2.170035212270675

Epoch: 6| Step: 5
Training loss: 2.884324789047241
Validation loss: 2.18117461153256

Epoch: 6| Step: 6
Training loss: 2.3960232734680176
Validation loss: 2.1815394086222493

Epoch: 6| Step: 7
Training loss: 2.3093605041503906
Validation loss: 2.1801101289769655

Epoch: 6| Step: 8
Training loss: 1.7726150751113892
Validation loss: 2.1823715035633375

Epoch: 6| Step: 9
Training loss: 2.3112130165100098
Validation loss: 2.167883662767308

Epoch: 6| Step: 10
Training loss: 3.148137331008911
Validation loss: 2.178400179391266

Epoch: 6| Step: 11
Training loss: 2.5518476963043213
Validation loss: 2.189276360696362

Epoch: 6| Step: 12
Training loss: 2.208617687225342
Validation loss: 2.186160343949513

Epoch: 6| Step: 13
Training loss: 1.4748234748840332
Validation loss: 2.176284482402186

Epoch: 274| Step: 0
Training loss: 2.868856191635132
Validation loss: 2.1532633727596653

Epoch: 6| Step: 1
Training loss: 2.860565185546875
Validation loss: 2.1709818250389508

Epoch: 6| Step: 2
Training loss: 2.455404281616211
Validation loss: 2.167141683640019

Epoch: 6| Step: 3
Training loss: 2.1909210681915283
Validation loss: 2.1817527817141626

Epoch: 6| Step: 4
Training loss: 1.5172243118286133
Validation loss: 2.1832225681633077

Epoch: 6| Step: 5
Training loss: 2.5984363555908203
Validation loss: 2.1907992132248415

Epoch: 6| Step: 6
Training loss: 2.4431984424591064
Validation loss: 2.1819966916115052

Epoch: 6| Step: 7
Training loss: 2.114030361175537
Validation loss: 2.189674159531952

Epoch: 6| Step: 8
Training loss: 1.9990954399108887
Validation loss: 2.1915482333911362

Epoch: 6| Step: 9
Training loss: 2.543148994445801
Validation loss: 2.164531333472139

Epoch: 6| Step: 10
Training loss: 2.1264054775238037
Validation loss: 2.1754769843111754

Epoch: 6| Step: 11
Training loss: 2.765651226043701
Validation loss: 2.1694628192532446

Epoch: 6| Step: 12
Training loss: 2.209986686706543
Validation loss: 2.1678417472429174

Epoch: 6| Step: 13
Training loss: 1.6743403673171997
Validation loss: 2.1690202682249007

Epoch: 275| Step: 0
Training loss: 2.126868724822998
Validation loss: 2.182958351668491

Epoch: 6| Step: 1
Training loss: 1.989019751548767
Validation loss: 2.1792347738819737

Epoch: 6| Step: 2
Training loss: 2.3897151947021484
Validation loss: 2.1920051510616014

Epoch: 6| Step: 3
Training loss: 1.841914176940918
Validation loss: 2.1903357890344437

Epoch: 6| Step: 4
Training loss: 2.3057897090911865
Validation loss: 2.204388185213971

Epoch: 6| Step: 5
Training loss: 3.2732481956481934
Validation loss: 2.192345621765301

Epoch: 6| Step: 6
Training loss: 2.845996379852295
Validation loss: 2.1986515111820673

Epoch: 6| Step: 7
Training loss: 2.0583271980285645
Validation loss: 2.1954092030884116

Epoch: 6| Step: 8
Training loss: 2.58960223197937
Validation loss: 2.1955401435975106

Epoch: 6| Step: 9
Training loss: 2.5789260864257812
Validation loss: 2.1937038565194733

Epoch: 6| Step: 10
Training loss: 2.9196691513061523
Validation loss: 2.180103962139417

Epoch: 6| Step: 11
Training loss: 1.5642304420471191
Validation loss: 2.168336024848364

Epoch: 6| Step: 12
Training loss: 1.9240243434906006
Validation loss: 2.1644620664658083

Epoch: 6| Step: 13
Training loss: 2.3686697483062744
Validation loss: 2.1597309907277427

Epoch: 276| Step: 0
Training loss: 2.5510005950927734
Validation loss: 2.1518326062028126

Epoch: 6| Step: 1
Training loss: 2.601299285888672
Validation loss: 2.1607092759942494

Epoch: 6| Step: 2
Training loss: 2.142996311187744
Validation loss: 2.152835443455686

Epoch: 6| Step: 3
Training loss: 1.5857794284820557
Validation loss: 2.154112728693152

Epoch: 6| Step: 4
Training loss: 2.87544584274292
Validation loss: 2.1675398349761963

Epoch: 6| Step: 5
Training loss: 2.2773985862731934
Validation loss: 2.161271749004241

Epoch: 6| Step: 6
Training loss: 2.367176055908203
Validation loss: 2.1559438500353085

Epoch: 6| Step: 7
Training loss: 2.6752419471740723
Validation loss: 2.1608977984356623

Epoch: 6| Step: 8
Training loss: 2.5842843055725098
Validation loss: 2.160615498019803

Epoch: 6| Step: 9
Training loss: 1.8889901638031006
Validation loss: 2.1642644713001866

Epoch: 6| Step: 10
Training loss: 1.9679083824157715
Validation loss: 2.156012776077435

Epoch: 6| Step: 11
Training loss: 2.083293914794922
Validation loss: 2.1745987194840626

Epoch: 6| Step: 12
Training loss: 2.482365608215332
Validation loss: 2.186470034301922

Epoch: 6| Step: 13
Training loss: 2.6802680492401123
Validation loss: 2.172036153013988

Epoch: 277| Step: 0
Training loss: 1.7453659772872925
Validation loss: 2.195664982641897

Epoch: 6| Step: 1
Training loss: 2.391096591949463
Validation loss: 2.17797593403888

Epoch: 6| Step: 2
Training loss: 2.352564811706543
Validation loss: 2.182051435593636

Epoch: 6| Step: 3
Training loss: 1.738476037979126
Validation loss: 2.1848634596793883

Epoch: 6| Step: 4
Training loss: 2.781909704208374
Validation loss: 2.185019540530379

Epoch: 6| Step: 5
Training loss: 2.7988529205322266
Validation loss: 2.1966461263677126

Epoch: 6| Step: 6
Training loss: 1.8102614879608154
Validation loss: 2.1939727696039344

Epoch: 6| Step: 7
Training loss: 1.7418975830078125
Validation loss: 2.1915182631502867

Epoch: 6| Step: 8
Training loss: 2.8741559982299805
Validation loss: 2.1968805123400945

Epoch: 6| Step: 9
Training loss: 2.9725451469421387
Validation loss: 2.1967659278582503

Epoch: 6| Step: 10
Training loss: 2.7061944007873535
Validation loss: 2.1982785681242585

Epoch: 6| Step: 11
Training loss: 2.399265766143799
Validation loss: 2.200600201083768

Epoch: 6| Step: 12
Training loss: 2.0851211547851562
Validation loss: 2.2121676591134842

Epoch: 6| Step: 13
Training loss: 2.3612749576568604
Validation loss: 2.203451923144761

Epoch: 278| Step: 0
Training loss: 2.0784850120544434
Validation loss: 2.2235398343814317

Epoch: 6| Step: 1
Training loss: 3.001626491546631
Validation loss: 2.2051292619397564

Epoch: 6| Step: 2
Training loss: 2.097102642059326
Validation loss: 2.2075199542507047

Epoch: 6| Step: 3
Training loss: 1.987074851989746
Validation loss: 2.1783600776426253

Epoch: 6| Step: 4
Training loss: 1.3837761878967285
Validation loss: 2.1752744387554865

Epoch: 6| Step: 5
Training loss: 2.636229991912842
Validation loss: 2.163344911349717

Epoch: 6| Step: 6
Training loss: 2.672499179840088
Validation loss: 2.1604647021139822

Epoch: 6| Step: 7
Training loss: 2.685911178588867
Validation loss: 2.158755199883574

Epoch: 6| Step: 8
Training loss: 2.9366278648376465
Validation loss: 2.155577254551713

Epoch: 6| Step: 9
Training loss: 2.051978349685669
Validation loss: 2.1391596512127946

Epoch: 6| Step: 10
Training loss: 3.08133602142334
Validation loss: 2.1326569049589095

Epoch: 6| Step: 11
Training loss: 1.649132251739502
Validation loss: 2.125459446701952

Epoch: 6| Step: 12
Training loss: 2.713700771331787
Validation loss: 2.120941895310597

Epoch: 6| Step: 13
Training loss: 1.7848173379898071
Validation loss: 2.1386177847462315

Epoch: 279| Step: 0
Training loss: 2.4689650535583496
Validation loss: 2.1390203070896927

Epoch: 6| Step: 1
Training loss: 2.358212947845459
Validation loss: 2.1376944241985196

Epoch: 6| Step: 2
Training loss: 2.901963710784912
Validation loss: 2.1564425704299763

Epoch: 6| Step: 3
Training loss: 1.6722557544708252
Validation loss: 2.1401260334958314

Epoch: 6| Step: 4
Training loss: 1.5872859954833984
Validation loss: 2.157496504886176

Epoch: 6| Step: 5
Training loss: 1.9025464057922363
Validation loss: 2.161075465140804

Epoch: 6| Step: 6
Training loss: 2.2684261798858643
Validation loss: 2.1620781139660905

Epoch: 6| Step: 7
Training loss: 2.9478933811187744
Validation loss: 2.1530939199591197

Epoch: 6| Step: 8
Training loss: 2.074765205383301
Validation loss: 2.159806546344552

Epoch: 6| Step: 9
Training loss: 3.099081516265869
Validation loss: 2.1401656084163214

Epoch: 6| Step: 10
Training loss: 2.0022006034851074
Validation loss: 2.1403088851641585

Epoch: 6| Step: 11
Training loss: 1.8390151262283325
Validation loss: 2.1502621994223645

Epoch: 6| Step: 12
Training loss: 2.678147792816162
Validation loss: 2.1492926843704714

Epoch: 6| Step: 13
Training loss: 3.3108606338500977
Validation loss: 2.1590558200754146

Epoch: 280| Step: 0
Training loss: 2.5417819023132324
Validation loss: 2.1454968093543925

Epoch: 6| Step: 1
Training loss: 2.870729446411133
Validation loss: 2.1665572479207027

Epoch: 6| Step: 2
Training loss: 1.7567671537399292
Validation loss: 2.1694275948309127

Epoch: 6| Step: 3
Training loss: 3.0033631324768066
Validation loss: 2.166233321671845

Epoch: 6| Step: 4
Training loss: 2.544187545776367
Validation loss: 2.167021087420884

Epoch: 6| Step: 5
Training loss: 2.5245001316070557
Validation loss: 2.178922350688647

Epoch: 6| Step: 6
Training loss: 2.1294355392456055
Validation loss: 2.1767578458273285

Epoch: 6| Step: 7
Training loss: 1.9141615629196167
Validation loss: 2.1774833574089953

Epoch: 6| Step: 8
Training loss: 2.1349265575408936
Validation loss: 2.1725391944249473

Epoch: 6| Step: 9
Training loss: 2.2202770709991455
Validation loss: 2.1736051318466023

Epoch: 6| Step: 10
Training loss: 2.823533535003662
Validation loss: 2.18550818838099

Epoch: 6| Step: 11
Training loss: 2.3119592666625977
Validation loss: 2.196461110986689

Epoch: 6| Step: 12
Training loss: 1.722337245941162
Validation loss: 2.1901058612331266

Epoch: 6| Step: 13
Training loss: 2.0058400630950928
Validation loss: 2.180784304936727

Epoch: 281| Step: 0
Training loss: 2.828692674636841
Validation loss: 2.17620256639296

Epoch: 6| Step: 1
Training loss: 3.043428897857666
Validation loss: 2.172967923584805

Epoch: 6| Step: 2
Training loss: 1.7932149171829224
Validation loss: 2.1750253400494977

Epoch: 6| Step: 3
Training loss: 2.1572647094726562
Validation loss: 2.1450295781576507

Epoch: 6| Step: 4
Training loss: 2.207719326019287
Validation loss: 2.1444342905475247

Epoch: 6| Step: 5
Training loss: 2.8097007274627686
Validation loss: 2.133946608471614

Epoch: 6| Step: 6
Training loss: 2.590864419937134
Validation loss: 2.1374447666188723

Epoch: 6| Step: 7
Training loss: 1.812286615371704
Validation loss: 2.1486041597140733

Epoch: 6| Step: 8
Training loss: 2.0910754203796387
Validation loss: 2.154718570811774

Epoch: 6| Step: 9
Training loss: 2.642879009246826
Validation loss: 2.159659747154482

Epoch: 6| Step: 10
Training loss: 2.565474271774292
Validation loss: 2.1665013631184897

Epoch: 6| Step: 11
Training loss: 2.5479211807250977
Validation loss: 2.1641326104440997

Epoch: 6| Step: 12
Training loss: 1.8890585899353027
Validation loss: 2.1714038336148827

Epoch: 6| Step: 13
Training loss: 1.6235811710357666
Validation loss: 2.1623440378455707

Epoch: 282| Step: 0
Training loss: 2.0584733486175537
Validation loss: 2.152555757953275

Epoch: 6| Step: 1
Training loss: 1.7752578258514404
Validation loss: 2.16665316653508

Epoch: 6| Step: 2
Training loss: 2.1808712482452393
Validation loss: 2.171986975977498

Epoch: 6| Step: 3
Training loss: 2.808420181274414
Validation loss: 2.1804072126265495

Epoch: 6| Step: 4
Training loss: 1.615349531173706
Validation loss: 2.1846087594186105

Epoch: 6| Step: 5
Training loss: 2.7050833702087402
Validation loss: 2.1757752485172723

Epoch: 6| Step: 6
Training loss: 2.06947922706604
Validation loss: 2.1723628197946856

Epoch: 6| Step: 7
Training loss: 2.393558979034424
Validation loss: 2.167884524150561

Epoch: 6| Step: 8
Training loss: 2.979525089263916
Validation loss: 2.1757182972405547

Epoch: 6| Step: 9
Training loss: 2.649526596069336
Validation loss: 2.17764800594699

Epoch: 6| Step: 10
Training loss: 2.2960691452026367
Validation loss: 2.1731731225085515

Epoch: 6| Step: 11
Training loss: 2.798483371734619
Validation loss: 2.1863521722055252

Epoch: 6| Step: 12
Training loss: 2.31942081451416
Validation loss: 2.177698894213605

Epoch: 6| Step: 13
Training loss: 1.736038327217102
Validation loss: 2.179975394279726

Epoch: 283| Step: 0
Training loss: 2.2395098209381104
Validation loss: 2.1853295705651723

Epoch: 6| Step: 1
Training loss: 2.3538832664489746
Validation loss: 2.1759273980253484

Epoch: 6| Step: 2
Training loss: 2.4452576637268066
Validation loss: 2.1757298951507895

Epoch: 6| Step: 3
Training loss: 1.8988590240478516
Validation loss: 2.1762136695205525

Epoch: 6| Step: 4
Training loss: 2.770137310028076
Validation loss: 2.1617413387503674

Epoch: 6| Step: 5
Training loss: 2.524118185043335
Validation loss: 2.1524191159074024

Epoch: 6| Step: 6
Training loss: 2.499192714691162
Validation loss: 2.163365667866122

Epoch: 6| Step: 7
Training loss: 1.8637900352478027
Validation loss: 2.146541186558303

Epoch: 6| Step: 8
Training loss: 2.5742673873901367
Validation loss: 2.1463199764169674

Epoch: 6| Step: 9
Training loss: 1.993698239326477
Validation loss: 2.147994977171703

Epoch: 6| Step: 10
Training loss: 1.9915142059326172
Validation loss: 2.150813243722403

Epoch: 6| Step: 11
Training loss: 2.5215682983398438
Validation loss: 2.1585302609269337

Epoch: 6| Step: 12
Training loss: 2.3932340145111084
Validation loss: 2.147180052213771

Epoch: 6| Step: 13
Training loss: 2.4584741592407227
Validation loss: 2.1523627568316717

Epoch: 284| Step: 0
Training loss: 3.1401708126068115
Validation loss: 2.1633602137206704

Epoch: 6| Step: 1
Training loss: 2.052564859390259
Validation loss: 2.1451735906703497

Epoch: 6| Step: 2
Training loss: 2.4027247428894043
Validation loss: 2.1373150451208955

Epoch: 6| Step: 3
Training loss: 1.9340708255767822
Validation loss: 2.161195719113914

Epoch: 6| Step: 4
Training loss: 1.95283842086792
Validation loss: 2.1517111127094557

Epoch: 6| Step: 5
Training loss: 2.393188953399658
Validation loss: 2.158514686810073

Epoch: 6| Step: 6
Training loss: 2.922614097595215
Validation loss: 2.171462038511871

Epoch: 6| Step: 7
Training loss: 2.0226848125457764
Validation loss: 2.1637665712705223

Epoch: 6| Step: 8
Training loss: 1.9983879327774048
Validation loss: 2.155427996830274

Epoch: 6| Step: 9
Training loss: 2.960674285888672
Validation loss: 2.1425208276317966

Epoch: 6| Step: 10
Training loss: 1.5431302785873413
Validation loss: 2.1425556751989547

Epoch: 6| Step: 11
Training loss: 1.9915099143981934
Validation loss: 2.145641653768478

Epoch: 6| Step: 12
Training loss: 2.426501750946045
Validation loss: 2.1503017845974175

Epoch: 6| Step: 13
Training loss: 3.0335965156555176
Validation loss: 2.1572845981967066

Epoch: 285| Step: 0
Training loss: 2.4586944580078125
Validation loss: 2.16516472190939

Epoch: 6| Step: 1
Training loss: 2.7316815853118896
Validation loss: 2.167005977322978

Epoch: 6| Step: 2
Training loss: 2.1622061729431152
Validation loss: 2.17030244745234

Epoch: 6| Step: 3
Training loss: 1.6309800148010254
Validation loss: 2.1541587742426063

Epoch: 6| Step: 4
Training loss: 2.2376017570495605
Validation loss: 2.152014399087557

Epoch: 6| Step: 5
Training loss: 2.4778363704681396
Validation loss: 2.160767739818942

Epoch: 6| Step: 6
Training loss: 1.5223370790481567
Validation loss: 2.1653845438393216

Epoch: 6| Step: 7
Training loss: 2.514059543609619
Validation loss: 2.1604924778784476

Epoch: 6| Step: 8
Training loss: 2.973867416381836
Validation loss: 2.1656470426949124

Epoch: 6| Step: 9
Training loss: 2.3025827407836914
Validation loss: 2.175723155339559

Epoch: 6| Step: 10
Training loss: 2.227430820465088
Validation loss: 2.1625191806465067

Epoch: 6| Step: 11
Training loss: 2.553417682647705
Validation loss: 2.1731713459055912

Epoch: 6| Step: 12
Training loss: 2.2075657844543457
Validation loss: 2.1701575697109265

Epoch: 6| Step: 13
Training loss: 2.24465274810791
Validation loss: 2.1728599661140033

Epoch: 286| Step: 0
Training loss: 2.4754204750061035
Validation loss: 2.175557444172521

Epoch: 6| Step: 1
Training loss: 2.185610055923462
Validation loss: 2.1818652383742796

Epoch: 6| Step: 2
Training loss: 1.2991280555725098
Validation loss: 2.1651369064084944

Epoch: 6| Step: 3
Training loss: 2.990417957305908
Validation loss: 2.170662997871317

Epoch: 6| Step: 4
Training loss: 2.656277656555176
Validation loss: 2.1769687219332625

Epoch: 6| Step: 5
Training loss: 2.040299654006958
Validation loss: 2.18566236957427

Epoch: 6| Step: 6
Training loss: 2.023636817932129
Validation loss: 2.1713690116841304

Epoch: 6| Step: 7
Training loss: 2.8512344360351562
Validation loss: 2.1804913064484954

Epoch: 6| Step: 8
Training loss: 2.965851068496704
Validation loss: 2.175064504787486

Epoch: 6| Step: 9
Training loss: 2.2345223426818848
Validation loss: 2.176334427249047

Epoch: 6| Step: 10
Training loss: 2.4413723945617676
Validation loss: 2.178171860274448

Epoch: 6| Step: 11
Training loss: 2.135134220123291
Validation loss: 2.1796725065477434

Epoch: 6| Step: 12
Training loss: 1.1296257972717285
Validation loss: 2.1833321971278035

Epoch: 6| Step: 13
Training loss: 3.139216661453247
Validation loss: 2.184670497012395

Epoch: 287| Step: 0
Training loss: 2.9550609588623047
Validation loss: 2.1631911749480874

Epoch: 6| Step: 1
Training loss: 2.3927764892578125
Validation loss: 2.158655297371649

Epoch: 6| Step: 2
Training loss: 2.2106552124023438
Validation loss: 2.141669036239706

Epoch: 6| Step: 3
Training loss: 1.8247404098510742
Validation loss: 2.135617943220241

Epoch: 6| Step: 4
Training loss: 2.278041362762451
Validation loss: 2.1391560646795456

Epoch: 6| Step: 5
Training loss: 2.278118133544922
Validation loss: 2.150399390087333

Epoch: 6| Step: 6
Training loss: 2.0440268516540527
Validation loss: 2.14443866924573

Epoch: 6| Step: 7
Training loss: 2.3995227813720703
Validation loss: 2.142002679968393

Epoch: 6| Step: 8
Training loss: 2.0447258949279785
Validation loss: 2.1422319386595037

Epoch: 6| Step: 9
Training loss: 2.6349658966064453
Validation loss: 2.142160943759385

Epoch: 6| Step: 10
Training loss: 2.498744010925293
Validation loss: 2.126297499543877

Epoch: 6| Step: 11
Training loss: 1.9840244054794312
Validation loss: 2.125679671123464

Epoch: 6| Step: 12
Training loss: 2.5507774353027344
Validation loss: 2.124161337011604

Epoch: 6| Step: 13
Training loss: 2.280961751937866
Validation loss: 2.138611706354285

Epoch: 288| Step: 0
Training loss: 1.5461304187774658
Validation loss: 2.1508305764967397

Epoch: 6| Step: 1
Training loss: 2.321194648742676
Validation loss: 2.1632462316943752

Epoch: 6| Step: 2
Training loss: 2.379765748977661
Validation loss: 2.176305591419179

Epoch: 6| Step: 3
Training loss: 2.719423294067383
Validation loss: 2.1692649574689966

Epoch: 6| Step: 4
Training loss: 2.4089319705963135
Validation loss: 2.167660695250316

Epoch: 6| Step: 5
Training loss: 2.747819662094116
Validation loss: 2.1887903418592227

Epoch: 6| Step: 6
Training loss: 2.740401029586792
Validation loss: 2.17452480459726

Epoch: 6| Step: 7
Training loss: 1.6134921312332153
Validation loss: 2.161705078617219

Epoch: 6| Step: 8
Training loss: 2.3571600914001465
Validation loss: 2.1597946843793316

Epoch: 6| Step: 9
Training loss: 2.5240910053253174
Validation loss: 2.1631798116109704

Epoch: 6| Step: 10
Training loss: 2.5340709686279297
Validation loss: 2.168338765380203

Epoch: 6| Step: 11
Training loss: 2.5119762420654297
Validation loss: 2.17828433744369

Epoch: 6| Step: 12
Training loss: 1.9921951293945312
Validation loss: 2.176586021659195

Epoch: 6| Step: 13
Training loss: 1.9010980129241943
Validation loss: 2.1724109880385862

Epoch: 289| Step: 0
Training loss: 2.1283726692199707
Validation loss: 2.1743955842910276

Epoch: 6| Step: 1
Training loss: 2.3079113960266113
Validation loss: 2.1780720269808205

Epoch: 6| Step: 2
Training loss: 2.3581016063690186
Validation loss: 2.1886652567053355

Epoch: 6| Step: 3
Training loss: 2.2830278873443604
Validation loss: 2.1940790273809947

Epoch: 6| Step: 4
Training loss: 2.472947120666504
Validation loss: 2.1840644523661625

Epoch: 6| Step: 5
Training loss: 2.426227569580078
Validation loss: 2.172070674998786

Epoch: 6| Step: 6
Training loss: 2.4551444053649902
Validation loss: 2.1629791490493284

Epoch: 6| Step: 7
Training loss: 2.041522264480591
Validation loss: 2.1643562419440157

Epoch: 6| Step: 8
Training loss: 2.5811853408813477
Validation loss: 2.1660085032063146

Epoch: 6| Step: 9
Training loss: 2.0755867958068848
Validation loss: 2.1773329473310903

Epoch: 6| Step: 10
Training loss: 1.6032465696334839
Validation loss: 2.187251126894387

Epoch: 6| Step: 11
Training loss: 2.6162314414978027
Validation loss: 2.185875795220816

Epoch: 6| Step: 12
Training loss: 2.481255054473877
Validation loss: 2.1850098615051596

Epoch: 6| Step: 13
Training loss: 2.9731035232543945
Validation loss: 2.1721128340690368

Epoch: 290| Step: 0
Training loss: 1.4307688474655151
Validation loss: 2.1614400725210867

Epoch: 6| Step: 1
Training loss: 2.0129146575927734
Validation loss: 2.151129214994369

Epoch: 6| Step: 2
Training loss: 2.66959810256958
Validation loss: 2.16119457316655

Epoch: 6| Step: 3
Training loss: 1.6492290496826172
Validation loss: 2.1802488398808304

Epoch: 6| Step: 4
Training loss: 2.0978145599365234
Validation loss: 2.1720448437557427

Epoch: 6| Step: 5
Training loss: 2.2612719535827637
Validation loss: 2.1868387370981197

Epoch: 6| Step: 6
Training loss: 2.927058696746826
Validation loss: 2.181494423138198

Epoch: 6| Step: 7
Training loss: 2.704392433166504
Validation loss: 2.1837018817983647

Epoch: 6| Step: 8
Training loss: 2.563941478729248
Validation loss: 2.1840164379407

Epoch: 6| Step: 9
Training loss: 2.195173740386963
Validation loss: 2.1817191211126183

Epoch: 6| Step: 10
Training loss: 2.4172825813293457
Validation loss: 2.175059139087636

Epoch: 6| Step: 11
Training loss: 2.4042105674743652
Validation loss: 2.184103132576071

Epoch: 6| Step: 12
Training loss: 2.3921687602996826
Validation loss: 2.165879184199918

Epoch: 6| Step: 13
Training loss: 2.929020643234253
Validation loss: 2.1524856334091513

Epoch: 291| Step: 0
Training loss: 2.028064250946045
Validation loss: 2.1398011484453754

Epoch: 6| Step: 1
Training loss: 2.3751072883605957
Validation loss: 2.138571786624129

Epoch: 6| Step: 2
Training loss: 2.2403669357299805
Validation loss: 2.1391228475878314

Epoch: 6| Step: 3
Training loss: 2.6323931217193604
Validation loss: 2.1478939979307112

Epoch: 6| Step: 4
Training loss: 3.004420757293701
Validation loss: 2.14935722402347

Epoch: 6| Step: 5
Training loss: 1.7187844514846802
Validation loss: 2.13226294261153

Epoch: 6| Step: 6
Training loss: 2.825432777404785
Validation loss: 2.1528169878067507

Epoch: 6| Step: 7
Training loss: 2.4460597038269043
Validation loss: 2.1531065381983274

Epoch: 6| Step: 8
Training loss: 1.8862510919570923
Validation loss: 2.1326684387781287

Epoch: 6| Step: 9
Training loss: 1.8689284324645996
Validation loss: 2.135443211883627

Epoch: 6| Step: 10
Training loss: 2.322622537612915
Validation loss: 2.1452342258986605

Epoch: 6| Step: 11
Training loss: 2.161693572998047
Validation loss: 2.147284701306333

Epoch: 6| Step: 12
Training loss: 2.628316879272461
Validation loss: 2.1485377242488246

Epoch: 6| Step: 13
Training loss: 1.9154142141342163
Validation loss: 2.1650331866356636

Epoch: 292| Step: 0
Training loss: 3.099869728088379
Validation loss: 2.146238351380953

Epoch: 6| Step: 1
Training loss: 1.8685762882232666
Validation loss: 2.1391183201984694

Epoch: 6| Step: 2
Training loss: 2.4065003395080566
Validation loss: 2.1326374623083297

Epoch: 6| Step: 3
Training loss: 2.381505012512207
Validation loss: 2.129977456984981

Epoch: 6| Step: 4
Training loss: 1.8293323516845703
Validation loss: 2.1344608952922206

Epoch: 6| Step: 5
Training loss: 2.084623098373413
Validation loss: 2.125159058519589

Epoch: 6| Step: 6
Training loss: 2.8122615814208984
Validation loss: 2.1440732222731396

Epoch: 6| Step: 7
Training loss: 2.061769962310791
Validation loss: 2.137198402035621

Epoch: 6| Step: 8
Training loss: 2.047633409500122
Validation loss: 2.1383841601751183

Epoch: 6| Step: 9
Training loss: 1.585959792137146
Validation loss: 2.1599844988956245

Epoch: 6| Step: 10
Training loss: 2.504240036010742
Validation loss: 2.1496205227349394

Epoch: 6| Step: 11
Training loss: 2.539555072784424
Validation loss: 2.1559042353783884

Epoch: 6| Step: 12
Training loss: 2.892929792404175
Validation loss: 2.157211016583186

Epoch: 6| Step: 13
Training loss: 1.6399320363998413
Validation loss: 2.1617696285247803

Epoch: 293| Step: 0
Training loss: 2.201265335083008
Validation loss: 2.1649447974338325

Epoch: 6| Step: 1
Training loss: 1.7523115873336792
Validation loss: 2.158887591413272

Epoch: 6| Step: 2
Training loss: 2.1426820755004883
Validation loss: 2.1827634816528647

Epoch: 6| Step: 3
Training loss: 2.2405529022216797
Validation loss: 2.170189719046316

Epoch: 6| Step: 4
Training loss: 2.487095832824707
Validation loss: 2.1662242002384637

Epoch: 6| Step: 5
Training loss: 2.455862283706665
Validation loss: 2.149657667324107

Epoch: 6| Step: 6
Training loss: 1.9826154708862305
Validation loss: 2.1592820844342633

Epoch: 6| Step: 7
Training loss: 1.9440815448760986
Validation loss: 2.1606868223477433

Epoch: 6| Step: 8
Training loss: 2.6273133754730225
Validation loss: 2.154029812864078

Epoch: 6| Step: 9
Training loss: 2.176846742630005
Validation loss: 2.1712971400189143

Epoch: 6| Step: 10
Training loss: 2.3934173583984375
Validation loss: 2.1638687426044094

Epoch: 6| Step: 11
Training loss: 2.9242818355560303
Validation loss: 2.1657317505087903

Epoch: 6| Step: 12
Training loss: 2.2030632495880127
Validation loss: 2.165968031011602

Epoch: 6| Step: 13
Training loss: 2.925140142440796
Validation loss: 2.14481177765836

Epoch: 294| Step: 0
Training loss: 2.5550615787506104
Validation loss: 2.1292343575467347

Epoch: 6| Step: 1
Training loss: 2.679271936416626
Validation loss: 2.124335055710167

Epoch: 6| Step: 2
Training loss: 2.5041725635528564
Validation loss: 2.1422927405244563

Epoch: 6| Step: 3
Training loss: 1.8279774188995361
Validation loss: 2.1411814023089666

Epoch: 6| Step: 4
Training loss: 2.2597174644470215
Validation loss: 2.149622103219391

Epoch: 6| Step: 5
Training loss: 2.1534509658813477
Validation loss: 2.1363784369601997

Epoch: 6| Step: 6
Training loss: 2.322397232055664
Validation loss: 2.117764344779394

Epoch: 6| Step: 7
Training loss: 2.7024288177490234
Validation loss: 2.123946289862356

Epoch: 6| Step: 8
Training loss: 2.0514745712280273
Validation loss: 2.112726561484798

Epoch: 6| Step: 9
Training loss: 2.4013328552246094
Validation loss: 2.1090470936990555

Epoch: 6| Step: 10
Training loss: 2.025494337081909
Validation loss: 2.1148501878143637

Epoch: 6| Step: 11
Training loss: 2.784287452697754
Validation loss: 2.116612411314441

Epoch: 6| Step: 12
Training loss: 1.9404640197753906
Validation loss: 2.119564917779738

Epoch: 6| Step: 13
Training loss: 1.6887907981872559
Validation loss: 2.1299596550644084

Epoch: 295| Step: 0
Training loss: 2.5310025215148926
Validation loss: 2.119581878826182

Epoch: 6| Step: 1
Training loss: 1.9542577266693115
Validation loss: 2.1484158667184974

Epoch: 6| Step: 2
Training loss: 2.8063173294067383
Validation loss: 2.151653628195486

Epoch: 6| Step: 3
Training loss: 3.255528450012207
Validation loss: 2.152849110223914

Epoch: 6| Step: 4
Training loss: 2.3108484745025635
Validation loss: 2.1605738542413198

Epoch: 6| Step: 5
Training loss: 2.9498250484466553
Validation loss: 2.169825953821982

Epoch: 6| Step: 6
Training loss: 2.003203868865967
Validation loss: 2.1676299495081746

Epoch: 6| Step: 7
Training loss: 1.8300197124481201
Validation loss: 2.147961175569924

Epoch: 6| Step: 8
Training loss: 2.414104461669922
Validation loss: 2.153507794103315

Epoch: 6| Step: 9
Training loss: 1.7980278730392456
Validation loss: 2.167673918508714

Epoch: 6| Step: 10
Training loss: 1.6949044466018677
Validation loss: 2.16994502980222

Epoch: 6| Step: 11
Training loss: 2.1940736770629883
Validation loss: 2.1726497245091263

Epoch: 6| Step: 12
Training loss: 2.1129016876220703
Validation loss: 2.1869998772939048

Epoch: 6| Step: 13
Training loss: 2.3742544651031494
Validation loss: 2.184610591139845

Epoch: 296| Step: 0
Training loss: 1.9810616970062256
Validation loss: 2.1943181689067552

Epoch: 6| Step: 1
Training loss: 2.61510968208313
Validation loss: 2.178990341001941

Epoch: 6| Step: 2
Training loss: 2.6125648021698
Validation loss: 2.1792013183716805

Epoch: 6| Step: 3
Training loss: 2.817841053009033
Validation loss: 2.148348210960306

Epoch: 6| Step: 4
Training loss: 2.4932258129119873
Validation loss: 2.1550416510592223

Epoch: 6| Step: 5
Training loss: 2.130988121032715
Validation loss: 2.15331857691529

Epoch: 6| Step: 6
Training loss: 1.2818150520324707
Validation loss: 2.143346422462053

Epoch: 6| Step: 7
Training loss: 1.7653017044067383
Validation loss: 2.1435342937387447

Epoch: 6| Step: 8
Training loss: 2.361949920654297
Validation loss: 2.1463764098382767

Epoch: 6| Step: 9
Training loss: 2.7068018913269043
Validation loss: 2.144232378211073

Epoch: 6| Step: 10
Training loss: 2.009113073348999
Validation loss: 2.125247319539388

Epoch: 6| Step: 11
Training loss: 2.4381065368652344
Validation loss: 2.126566452364768

Epoch: 6| Step: 12
Training loss: 2.5787558555603027
Validation loss: 2.1329813593177387

Epoch: 6| Step: 13
Training loss: 2.2458364963531494
Validation loss: 2.1303389713328373

Epoch: 297| Step: 0
Training loss: 2.771277666091919
Validation loss: 2.1259035525783414

Epoch: 6| Step: 1
Training loss: 2.226797580718994
Validation loss: 2.1196460980241016

Epoch: 6| Step: 2
Training loss: 2.8186488151550293
Validation loss: 2.123287727755885

Epoch: 6| Step: 3
Training loss: 2.8790535926818848
Validation loss: 2.1365439455996276

Epoch: 6| Step: 4
Training loss: 1.446906566619873
Validation loss: 2.1383490652166386

Epoch: 6| Step: 5
Training loss: 2.103233814239502
Validation loss: 2.1263640747275403

Epoch: 6| Step: 6
Training loss: 1.6590206623077393
Validation loss: 2.1302967738079768

Epoch: 6| Step: 7
Training loss: 1.9118618965148926
Validation loss: 2.131625231876168

Epoch: 6| Step: 8
Training loss: 1.7194987535476685
Validation loss: 2.139153854821318

Epoch: 6| Step: 9
Training loss: 2.89371657371521
Validation loss: 2.1457418216172086

Epoch: 6| Step: 10
Training loss: 2.2891907691955566
Validation loss: 2.1287784614870624

Epoch: 6| Step: 11
Training loss: 2.7649729251861572
Validation loss: 2.1423758024810464

Epoch: 6| Step: 12
Training loss: 2.567579984664917
Validation loss: 2.152727355239212

Epoch: 6| Step: 13
Training loss: 1.622437596321106
Validation loss: 2.1372826765942317

Epoch: 298| Step: 0
Training loss: 2.179811477661133
Validation loss: 2.1433293101608113

Epoch: 6| Step: 1
Training loss: 1.967766284942627
Validation loss: 2.142148907466601

Epoch: 6| Step: 2
Training loss: 2.4038164615631104
Validation loss: 2.1336084437626663

Epoch: 6| Step: 3
Training loss: 1.9165359735488892
Validation loss: 2.1219644136326288

Epoch: 6| Step: 4
Training loss: 2.60406494140625
Validation loss: 2.132201810036936

Epoch: 6| Step: 5
Training loss: 3.62591552734375
Validation loss: 2.1336274121397283

Epoch: 6| Step: 6
Training loss: 2.3719799518585205
Validation loss: 2.132390852897398

Epoch: 6| Step: 7
Training loss: 2.4620041847229004
Validation loss: 2.1198124988104707

Epoch: 6| Step: 8
Training loss: 1.8500229120254517
Validation loss: 2.112973864360522

Epoch: 6| Step: 9
Training loss: 1.2742233276367188
Validation loss: 2.1239708187759563

Epoch: 6| Step: 10
Training loss: 2.5299668312072754
Validation loss: 2.123307389597739

Epoch: 6| Step: 11
Training loss: 3.183284044265747
Validation loss: 2.1252606581616145

Epoch: 6| Step: 12
Training loss: 1.2603428363800049
Validation loss: 2.164184667730844

Epoch: 6| Step: 13
Training loss: 2.509597063064575
Validation loss: 2.1697013711416595

Epoch: 299| Step: 0
Training loss: 2.278904438018799
Validation loss: 2.1667608932782243

Epoch: 6| Step: 1
Training loss: 2.5709524154663086
Validation loss: 2.1774927698155886

Epoch: 6| Step: 2
Training loss: 2.461827278137207
Validation loss: 2.1768428805053874

Epoch: 6| Step: 3
Training loss: 1.1814345121383667
Validation loss: 2.1469326685833674

Epoch: 6| Step: 4
Training loss: 1.8845082521438599
Validation loss: 2.135022263373098

Epoch: 6| Step: 5
Training loss: 2.297177314758301
Validation loss: 2.1530615668142996

Epoch: 6| Step: 6
Training loss: 2.350127696990967
Validation loss: 2.164971077313987

Epoch: 6| Step: 7
Training loss: 2.3731980323791504
Validation loss: 2.1463572286790416

Epoch: 6| Step: 8
Training loss: 2.113302230834961
Validation loss: 2.147936587692589

Epoch: 6| Step: 9
Training loss: 2.328947067260742
Validation loss: 2.1364860803850236

Epoch: 6| Step: 10
Training loss: 2.710526704788208
Validation loss: 2.1460073327505462

Epoch: 6| Step: 11
Training loss: 2.270752429962158
Validation loss: 2.131453303880589

Epoch: 6| Step: 12
Training loss: 2.83237624168396
Validation loss: 2.132065858892215

Epoch: 6| Step: 13
Training loss: 2.4344677925109863
Validation loss: 2.126700520515442

Epoch: 300| Step: 0
Training loss: 2.4976682662963867
Validation loss: 2.141416288191272

Epoch: 6| Step: 1
Training loss: 2.301222324371338
Validation loss: 2.1370918571308093

Epoch: 6| Step: 2
Training loss: 2.0639662742614746
Validation loss: 2.1408521103602585

Epoch: 6| Step: 3
Training loss: 2.528616428375244
Validation loss: 2.1347425330069756

Epoch: 6| Step: 4
Training loss: 2.507596254348755
Validation loss: 2.1408171551201933

Epoch: 6| Step: 5
Training loss: 2.340089797973633
Validation loss: 2.1210313817506194

Epoch: 6| Step: 6
Training loss: 2.6579155921936035
Validation loss: 2.1346289829541276

Epoch: 6| Step: 7
Training loss: 2.537186622619629
Validation loss: 2.127884826352519

Epoch: 6| Step: 8
Training loss: 2.7943880558013916
Validation loss: 2.1251259029552503

Epoch: 6| Step: 9
Training loss: 1.9693517684936523
Validation loss: 2.1207031178218063

Epoch: 6| Step: 10
Training loss: 1.5006437301635742
Validation loss: 2.1385902486821657

Epoch: 6| Step: 11
Training loss: 2.2274169921875
Validation loss: 2.1384305184887302

Epoch: 6| Step: 12
Training loss: 2.0667927265167236
Validation loss: 2.1460270368924705

Epoch: 6| Step: 13
Training loss: 1.7684296369552612
Validation loss: 2.161131097424415

Epoch: 301| Step: 0
Training loss: 2.6512997150421143
Validation loss: 2.1586484255329257

Epoch: 6| Step: 1
Training loss: 2.7205705642700195
Validation loss: 2.170375516337733

Epoch: 6| Step: 2
Training loss: 1.9016237258911133
Validation loss: 2.164136061104395

Epoch: 6| Step: 3
Training loss: 2.1257169246673584
Validation loss: 2.144859396001344

Epoch: 6| Step: 4
Training loss: 1.8467203378677368
Validation loss: 2.143061250768682

Epoch: 6| Step: 5
Training loss: 1.7642104625701904
Validation loss: 2.1355920325043383

Epoch: 6| Step: 6
Training loss: 2.910294771194458
Validation loss: 2.119519764377225

Epoch: 6| Step: 7
Training loss: 2.430654525756836
Validation loss: 2.131692747915945

Epoch: 6| Step: 8
Training loss: 2.7009878158569336
Validation loss: 2.130751648256856

Epoch: 6| Step: 9
Training loss: 1.6107022762298584
Validation loss: 2.1262293297757386

Epoch: 6| Step: 10
Training loss: 2.305432081222534
Validation loss: 2.123342647347399

Epoch: 6| Step: 11
Training loss: 2.6786882877349854
Validation loss: 2.119327450311312

Epoch: 6| Step: 12
Training loss: 1.8208078145980835
Validation loss: 2.111625268895139

Epoch: 6| Step: 13
Training loss: 2.4489126205444336
Validation loss: 2.1223177268940914

Epoch: 302| Step: 0
Training loss: 2.1974120140075684
Validation loss: 2.1290969848632812

Epoch: 6| Step: 1
Training loss: 2.4964027404785156
Validation loss: 2.1337162422877487

Epoch: 6| Step: 2
Training loss: 2.1591551303863525
Validation loss: 2.122310939655509

Epoch: 6| Step: 3
Training loss: 2.4764585494995117
Validation loss: 2.1289183503837994

Epoch: 6| Step: 4
Training loss: 2.193279266357422
Validation loss: 2.12907475297169

Epoch: 6| Step: 5
Training loss: 1.973925232887268
Validation loss: 2.1280704211163264

Epoch: 6| Step: 6
Training loss: 1.5639443397521973
Validation loss: 2.1337399328908613

Epoch: 6| Step: 7
Training loss: 2.8975296020507812
Validation loss: 2.131965676943461

Epoch: 6| Step: 8
Training loss: 2.3690977096557617
Validation loss: 2.144346688383369

Epoch: 6| Step: 9
Training loss: 2.3546836376190186
Validation loss: 2.1491404964077856

Epoch: 6| Step: 10
Training loss: 2.9954562187194824
Validation loss: 2.148024700021231

Epoch: 6| Step: 11
Training loss: 1.9053895473480225
Validation loss: 2.142299444444718

Epoch: 6| Step: 12
Training loss: 1.8215430974960327
Validation loss: 2.1472200552622476

Epoch: 6| Step: 13
Training loss: 2.7219436168670654
Validation loss: 2.1400793213998117

Epoch: 303| Step: 0
Training loss: 2.70222806930542
Validation loss: 2.139698023437172

Epoch: 6| Step: 1
Training loss: 2.1003384590148926
Validation loss: 2.1405222672288136

Epoch: 6| Step: 2
Training loss: 2.4409337043762207
Validation loss: 2.1216480142326763

Epoch: 6| Step: 3
Training loss: 2.8052711486816406
Validation loss: 2.1440531130759948

Epoch: 6| Step: 4
Training loss: 2.6713132858276367
Validation loss: 2.1547942379469514

Epoch: 6| Step: 5
Training loss: 1.7595503330230713
Validation loss: 2.1396660035656345

Epoch: 6| Step: 6
Training loss: 3.193272113800049
Validation loss: 2.1262911596605854

Epoch: 6| Step: 7
Training loss: 1.8911364078521729
Validation loss: 2.113250768312844

Epoch: 6| Step: 8
Training loss: 2.0753824710845947
Validation loss: 2.109019458934825

Epoch: 6| Step: 9
Training loss: 2.248919725418091
Validation loss: 2.121301676637383

Epoch: 6| Step: 10
Training loss: 2.2433018684387207
Validation loss: 2.1166546895939815

Epoch: 6| Step: 11
Training loss: 1.9129316806793213
Validation loss: 2.1134412263029363

Epoch: 6| Step: 12
Training loss: 2.100475788116455
Validation loss: 2.1324844257805937

Epoch: 6| Step: 13
Training loss: 1.9377977848052979
Validation loss: 2.1440307683842157

Epoch: 304| Step: 0
Training loss: 1.8361659049987793
Validation loss: 2.1416470004666235

Epoch: 6| Step: 1
Training loss: 2.076327323913574
Validation loss: 2.15008976638958

Epoch: 6| Step: 2
Training loss: 2.287318706512451
Validation loss: 2.154344256206225

Epoch: 6| Step: 3
Training loss: 2.57431960105896
Validation loss: 2.146991099080732

Epoch: 6| Step: 4
Training loss: 2.1978378295898438
Validation loss: 2.140257035532305

Epoch: 6| Step: 5
Training loss: 2.4879770278930664
Validation loss: 2.1457825040304535

Epoch: 6| Step: 6
Training loss: 2.2724363803863525
Validation loss: 2.1418390145865818

Epoch: 6| Step: 7
Training loss: 2.187173843383789
Validation loss: 2.1224941412607827

Epoch: 6| Step: 8
Training loss: 2.0089893341064453
Validation loss: 2.11604049897963

Epoch: 6| Step: 9
Training loss: 2.428865432739258
Validation loss: 2.1247083243503364

Epoch: 6| Step: 10
Training loss: 2.7673778533935547
Validation loss: 2.121981874588997

Epoch: 6| Step: 11
Training loss: 2.6059916019439697
Validation loss: 2.121300688353918

Epoch: 6| Step: 12
Training loss: 2.229191780090332
Validation loss: 2.119784434636434

Epoch: 6| Step: 13
Training loss: 1.694649338722229
Validation loss: 2.1261696430944625

Epoch: 305| Step: 0
Training loss: 2.34293270111084
Validation loss: 2.117855912895613

Epoch: 6| Step: 1
Training loss: 2.1620898246765137
Validation loss: 2.1167970293311664

Epoch: 6| Step: 2
Training loss: 2.2209582328796387
Validation loss: 2.1222388975081907

Epoch: 6| Step: 3
Training loss: 2.3467671871185303
Validation loss: 2.1362301341948973

Epoch: 6| Step: 4
Training loss: 2.21051287651062
Validation loss: 2.1182951875912246

Epoch: 6| Step: 5
Training loss: 1.9060559272766113
Validation loss: 2.1156483580989223

Epoch: 6| Step: 6
Training loss: 1.8373980522155762
Validation loss: 2.1201171208453435

Epoch: 6| Step: 7
Training loss: 2.3620805740356445
Validation loss: 2.1249318584319083

Epoch: 6| Step: 8
Training loss: 1.6448934078216553
Validation loss: 2.1164918035589237

Epoch: 6| Step: 9
Training loss: 2.714824676513672
Validation loss: 2.1159198771240892

Epoch: 6| Step: 10
Training loss: 2.419860363006592
Validation loss: 2.1216213241700204

Epoch: 6| Step: 11
Training loss: 2.477893829345703
Validation loss: 2.125601568529683

Epoch: 6| Step: 12
Training loss: 2.6772634983062744
Validation loss: 2.1418404758617444

Epoch: 6| Step: 13
Training loss: 2.352325201034546
Validation loss: 2.1348968936551

Epoch: 306| Step: 0
Training loss: 2.140380382537842
Validation loss: 2.1479424840660504

Epoch: 6| Step: 1
Training loss: 2.2962260246276855
Validation loss: 2.1485515935446626

Epoch: 6| Step: 2
Training loss: 1.6491389274597168
Validation loss: 2.142445016932744

Epoch: 6| Step: 3
Training loss: 2.470673084259033
Validation loss: 2.1499229079933575

Epoch: 6| Step: 4
Training loss: 2.7072787284851074
Validation loss: 2.1400755041389057

Epoch: 6| Step: 5
Training loss: 2.691117763519287
Validation loss: 2.1649445513243317

Epoch: 6| Step: 6
Training loss: 2.490335464477539
Validation loss: 2.145661518137942

Epoch: 6| Step: 7
Training loss: 1.850299596786499
Validation loss: 2.160716972043437

Epoch: 6| Step: 8
Training loss: 2.1275863647460938
Validation loss: 2.1439428457649807

Epoch: 6| Step: 9
Training loss: 2.0266547203063965
Validation loss: 2.146827356789702

Epoch: 6| Step: 10
Training loss: 2.167415142059326
Validation loss: 2.1284674034323743

Epoch: 6| Step: 11
Training loss: 3.2524194717407227
Validation loss: 2.120450391564318

Epoch: 6| Step: 12
Training loss: 2.057382583618164
Validation loss: 2.1241709852731354

Epoch: 6| Step: 13
Training loss: 1.7294474840164185
Validation loss: 2.122977561848138

Epoch: 307| Step: 0
Training loss: 2.5530238151550293
Validation loss: 2.1340013575810257

Epoch: 6| Step: 1
Training loss: 2.126314163208008
Validation loss: 2.144730962732787

Epoch: 6| Step: 2
Training loss: 2.6489782333374023
Validation loss: 2.1440787328186857

Epoch: 6| Step: 3
Training loss: 1.678788185119629
Validation loss: 2.1593361170061174

Epoch: 6| Step: 4
Training loss: 2.8808465003967285
Validation loss: 2.1471628271123415

Epoch: 6| Step: 5
Training loss: 2.018342971801758
Validation loss: 2.148454193145998

Epoch: 6| Step: 6
Training loss: 2.4855246543884277
Validation loss: 2.146991193935435

Epoch: 6| Step: 7
Training loss: 2.058976411819458
Validation loss: 2.148253822839388

Epoch: 6| Step: 8
Training loss: 1.9928526878356934
Validation loss: 2.1279147055841263

Epoch: 6| Step: 9
Training loss: 2.385915517807007
Validation loss: 2.124266332195651

Epoch: 6| Step: 10
Training loss: 2.1888279914855957
Validation loss: 2.117283005868235

Epoch: 6| Step: 11
Training loss: 1.9704669713974
Validation loss: 2.1229400839856876

Epoch: 6| Step: 12
Training loss: 2.8550586700439453
Validation loss: 2.121858234046608

Epoch: 6| Step: 13
Training loss: 2.1133322715759277
Validation loss: 2.137056055889335

Epoch: 308| Step: 0
Training loss: 2.7657651901245117
Validation loss: 2.131974071584722

Epoch: 6| Step: 1
Training loss: 2.2005114555358887
Validation loss: 2.122997424935782

Epoch: 6| Step: 2
Training loss: 2.341763973236084
Validation loss: 2.123272811212847

Epoch: 6| Step: 3
Training loss: 2.531473159790039
Validation loss: 2.1076964024574525

Epoch: 6| Step: 4
Training loss: 2.237969160079956
Validation loss: 2.101135428233813

Epoch: 6| Step: 5
Training loss: 2.527939796447754
Validation loss: 2.0991413131836922

Epoch: 6| Step: 6
Training loss: 1.8599131107330322
Validation loss: 2.105065986674319

Epoch: 6| Step: 7
Training loss: 2.4884800910949707
Validation loss: 2.116165602079002

Epoch: 6| Step: 8
Training loss: 1.9177838563919067
Validation loss: 2.1371866169796196

Epoch: 6| Step: 9
Training loss: 2.826906204223633
Validation loss: 2.1242755228473293

Epoch: 6| Step: 10
Training loss: 1.9776155948638916
Validation loss: 2.148484706878662

Epoch: 6| Step: 11
Training loss: 2.574655055999756
Validation loss: 2.172312189173955

Epoch: 6| Step: 12
Training loss: 1.6194590330123901
Validation loss: 2.1559450728918916

Epoch: 6| Step: 13
Training loss: 1.8135706186294556
Validation loss: 2.1703336559316164

Epoch: 309| Step: 0
Training loss: 2.558720588684082
Validation loss: 2.157986028220064

Epoch: 6| Step: 1
Training loss: 2.268167018890381
Validation loss: 2.166965647410321

Epoch: 6| Step: 2
Training loss: 2.935683250427246
Validation loss: 2.176476591376848

Epoch: 6| Step: 3
Training loss: 3.1819145679473877
Validation loss: 2.1884349981943765

Epoch: 6| Step: 4
Training loss: 2.2098326683044434
Validation loss: 2.176483369642688

Epoch: 6| Step: 5
Training loss: 2.0484509468078613
Validation loss: 2.1668760161246023

Epoch: 6| Step: 6
Training loss: 1.4541248083114624
Validation loss: 2.1833540778006277

Epoch: 6| Step: 7
Training loss: 1.3479814529418945
Validation loss: 2.1666404662593717

Epoch: 6| Step: 8
Training loss: 2.031402349472046
Validation loss: 2.1591603102222567

Epoch: 6| Step: 9
Training loss: 2.1204781532287598
Validation loss: 2.155941337667486

Epoch: 6| Step: 10
Training loss: 2.5867700576782227
Validation loss: 2.1431837146000197

Epoch: 6| Step: 11
Training loss: 2.2142393589019775
Validation loss: 2.1397909067010366

Epoch: 6| Step: 12
Training loss: 2.4642794132232666
Validation loss: 2.1408390614294235

Epoch: 6| Step: 13
Training loss: 2.5659291744232178
Validation loss: 2.1252473374848724

Epoch: 310| Step: 0
Training loss: 2.348386764526367
Validation loss: 2.1272078739699496

Epoch: 6| Step: 1
Training loss: 2.6916065216064453
Validation loss: 2.1005349825787287

Epoch: 6| Step: 2
Training loss: 2.5616455078125
Validation loss: 2.130313350308326

Epoch: 6| Step: 3
Training loss: 1.6607719659805298
Validation loss: 2.107142049779174

Epoch: 6| Step: 4
Training loss: 1.9890116453170776
Validation loss: 2.1125939533274662

Epoch: 6| Step: 5
Training loss: 2.0978426933288574
Validation loss: 2.123413860156972

Epoch: 6| Step: 6
Training loss: 2.1366286277770996
Validation loss: 2.12455581080529

Epoch: 6| Step: 7
Training loss: 2.8366031646728516
Validation loss: 2.126823784202658

Epoch: 6| Step: 8
Training loss: 2.5366733074188232
Validation loss: 2.1246034996483916

Epoch: 6| Step: 9
Training loss: 2.154510498046875
Validation loss: 2.1274229403465026

Epoch: 6| Step: 10
Training loss: 2.324462890625
Validation loss: 2.123898449764457

Epoch: 6| Step: 11
Training loss: 1.9782814979553223
Validation loss: 2.117951777673537

Epoch: 6| Step: 12
Training loss: 1.8362603187561035
Validation loss: 2.121621956107437

Epoch: 6| Step: 13
Training loss: 2.452049970626831
Validation loss: 2.1144285202026367

Epoch: 311| Step: 0
Training loss: 2.524909019470215
Validation loss: 2.096015425138576

Epoch: 6| Step: 1
Training loss: 1.8297159671783447
Validation loss: 2.109403548702117

Epoch: 6| Step: 2
Training loss: 2.735126495361328
Validation loss: 2.1154179624331895

Epoch: 6| Step: 3
Training loss: 2.8973288536071777
Validation loss: 2.1056324743455455

Epoch: 6| Step: 4
Training loss: 1.7067402601242065
Validation loss: 2.1103047606765584

Epoch: 6| Step: 5
Training loss: 1.9055856466293335
Validation loss: 2.116520086924235

Epoch: 6| Step: 6
Training loss: 1.8473758697509766
Validation loss: 2.136479926365678

Epoch: 6| Step: 7
Training loss: 2.139376163482666
Validation loss: 2.1443059931519213

Epoch: 6| Step: 8
Training loss: 2.869722604751587
Validation loss: 2.1360773309584586

Epoch: 6| Step: 9
Training loss: 2.9515204429626465
Validation loss: 2.149449145922097

Epoch: 6| Step: 10
Training loss: 2.3453588485717773
Validation loss: 2.143323572733069

Epoch: 6| Step: 11
Training loss: 1.8018839359283447
Validation loss: 2.1398182171647266

Epoch: 6| Step: 12
Training loss: 2.4130618572235107
Validation loss: 2.1332577928420036

Epoch: 6| Step: 13
Training loss: 1.4122567176818848
Validation loss: 2.118570477731766

Epoch: 312| Step: 0
Training loss: 2.068944215774536
Validation loss: 2.1181798699081584

Epoch: 6| Step: 1
Training loss: 2.349759101867676
Validation loss: 2.1106981205683883

Epoch: 6| Step: 2
Training loss: 2.366452217102051
Validation loss: 2.1170479764220533

Epoch: 6| Step: 3
Training loss: 2.3570656776428223
Validation loss: 2.1052968681499524

Epoch: 6| Step: 4
Training loss: 1.7950849533081055
Validation loss: 2.095213104319829

Epoch: 6| Step: 5
Training loss: 2.564772844314575
Validation loss: 2.105643695400607

Epoch: 6| Step: 6
Training loss: 2.093921661376953
Validation loss: 2.08738394834662

Epoch: 6| Step: 7
Training loss: 2.3931379318237305
Validation loss: 2.101271093532603

Epoch: 6| Step: 8
Training loss: 2.434678554534912
Validation loss: 2.0941900386605212

Epoch: 6| Step: 9
Training loss: 2.0425238609313965
Validation loss: 2.0998996483382357

Epoch: 6| Step: 10
Training loss: 1.9735270738601685
Validation loss: 2.0964873657431653

Epoch: 6| Step: 11
Training loss: 2.0978665351867676
Validation loss: 2.090802538779474

Epoch: 6| Step: 12
Training loss: 2.4847567081451416
Validation loss: 2.1103321070312173

Epoch: 6| Step: 13
Training loss: 2.7613770961761475
Validation loss: 2.1041905521064677

Epoch: 313| Step: 0
Training loss: 2.1786022186279297
Validation loss: 2.096401910628042

Epoch: 6| Step: 1
Training loss: 2.3655331134796143
Validation loss: 2.0977750055251585

Epoch: 6| Step: 2
Training loss: 2.450758934020996
Validation loss: 2.1062412800327426

Epoch: 6| Step: 3
Training loss: 3.165480136871338
Validation loss: 2.11491088585187

Epoch: 6| Step: 4
Training loss: 2.2190370559692383
Validation loss: 2.1015461234636206

Epoch: 6| Step: 5
Training loss: 2.2740609645843506
Validation loss: 2.1244803397886214

Epoch: 6| Step: 6
Training loss: 2.534501075744629
Validation loss: 2.128103412607665

Epoch: 6| Step: 7
Training loss: 1.9815006256103516
Validation loss: 2.127693940234441

Epoch: 6| Step: 8
Training loss: 2.0679917335510254
Validation loss: 2.132033109664917

Epoch: 6| Step: 9
Training loss: 1.7947877645492554
Validation loss: 2.142384672677645

Epoch: 6| Step: 10
Training loss: 2.1258928775787354
Validation loss: 2.145801918480986

Epoch: 6| Step: 11
Training loss: 2.550224542617798
Validation loss: 2.143196690467096

Epoch: 6| Step: 12
Training loss: 2.1019527912139893
Validation loss: 2.1419288035362

Epoch: 6| Step: 13
Training loss: 1.6324665546417236
Validation loss: 2.1293472833530878

Epoch: 314| Step: 0
Training loss: 2.3064262866973877
Validation loss: 2.1279173051157305

Epoch: 6| Step: 1
Training loss: 1.7048566341400146
Validation loss: 2.1205681036877375

Epoch: 6| Step: 2
Training loss: 2.672682285308838
Validation loss: 2.123179466493668

Epoch: 6| Step: 3
Training loss: 2.218317985534668
Validation loss: 2.1121841117899907

Epoch: 6| Step: 4
Training loss: 2.259561061859131
Validation loss: 2.1314258062711327

Epoch: 6| Step: 5
Training loss: 2.1274847984313965
Validation loss: 2.107918832891731

Epoch: 6| Step: 6
Training loss: 2.136721611022949
Validation loss: 2.120262263923563

Epoch: 6| Step: 7
Training loss: 2.28181791305542
Validation loss: 2.107488721929571

Epoch: 6| Step: 8
Training loss: 2.345337152481079
Validation loss: 2.1027901685366066

Epoch: 6| Step: 9
Training loss: 1.7873153686523438
Validation loss: 2.119398356765829

Epoch: 6| Step: 10
Training loss: 2.533475160598755
Validation loss: 2.1179134666278796

Epoch: 6| Step: 11
Training loss: 2.298340320587158
Validation loss: 2.1018372069122973

Epoch: 6| Step: 12
Training loss: 2.7023096084594727
Validation loss: 2.1035727300951557

Epoch: 6| Step: 13
Training loss: 1.6742377281188965
Validation loss: 2.1058520911842264

Epoch: 315| Step: 0
Training loss: 1.9903030395507812
Validation loss: 2.122900175791915

Epoch: 6| Step: 1
Training loss: 2.294609546661377
Validation loss: 2.1257046550832768

Epoch: 6| Step: 2
Training loss: 2.3115739822387695
Validation loss: 2.101056028437871

Epoch: 6| Step: 3
Training loss: 1.9098378419876099
Validation loss: 2.119549469281268

Epoch: 6| Step: 4
Training loss: 2.049853801727295
Validation loss: 2.111607228555987

Epoch: 6| Step: 5
Training loss: 2.1719107627868652
Validation loss: 2.1059201866067867

Epoch: 6| Step: 6
Training loss: 2.219630241394043
Validation loss: 2.1284037302899104

Epoch: 6| Step: 7
Training loss: 2.2270190715789795
Validation loss: 2.1404872350795294

Epoch: 6| Step: 8
Training loss: 2.8073244094848633
Validation loss: 2.141216581867587

Epoch: 6| Step: 9
Training loss: 1.939645528793335
Validation loss: 2.1537259381304503

Epoch: 6| Step: 10
Training loss: 2.0022058486938477
Validation loss: 2.160532751391011

Epoch: 6| Step: 11
Training loss: 2.6313421726226807
Validation loss: 2.1393131094594158

Epoch: 6| Step: 12
Training loss: 2.6031055450439453
Validation loss: 2.1411250099059074

Epoch: 6| Step: 13
Training loss: 2.435190439224243
Validation loss: 2.135374706278565

Epoch: 316| Step: 0
Training loss: 2.1620912551879883
Validation loss: 2.132221024523499

Epoch: 6| Step: 1
Training loss: 1.7383849620819092
Validation loss: 2.1199834680044525

Epoch: 6| Step: 2
Training loss: 1.8133721351623535
Validation loss: 2.1255368160945114

Epoch: 6| Step: 3
Training loss: 2.762336492538452
Validation loss: 2.1110239874932075

Epoch: 6| Step: 4
Training loss: 2.7686309814453125
Validation loss: 2.0956089650430987

Epoch: 6| Step: 5
Training loss: 2.1168336868286133
Validation loss: 2.116389680934209

Epoch: 6| Step: 6
Training loss: 1.8279613256454468
Validation loss: 2.088527871716407

Epoch: 6| Step: 7
Training loss: 2.4334182739257812
Validation loss: 2.1063313920010804

Epoch: 6| Step: 8
Training loss: 2.1629257202148438
Validation loss: 2.0943843639025124

Epoch: 6| Step: 9
Training loss: 1.633034586906433
Validation loss: 2.098488735896285

Epoch: 6| Step: 10
Training loss: 2.9970905780792236
Validation loss: 2.0944668605763423

Epoch: 6| Step: 11
Training loss: 2.4375109672546387
Validation loss: 2.097366817535893

Epoch: 6| Step: 12
Training loss: 2.421383857727051
Validation loss: 2.106399266950546

Epoch: 6| Step: 13
Training loss: 1.945845127105713
Validation loss: 2.1167820525425736

Epoch: 317| Step: 0
Training loss: 2.578252077102661
Validation loss: 2.1067989551892845

Epoch: 6| Step: 1
Training loss: 2.9789319038391113
Validation loss: 2.097576520776236

Epoch: 6| Step: 2
Training loss: 2.3136861324310303
Validation loss: 2.0892261740981892

Epoch: 6| Step: 3
Training loss: 1.909348487854004
Validation loss: 2.0991945766633555

Epoch: 6| Step: 4
Training loss: 1.71279776096344
Validation loss: 2.0982078352282123

Epoch: 6| Step: 5
Training loss: 2.4336776733398438
Validation loss: 2.1012759400952246

Epoch: 6| Step: 6
Training loss: 1.9431475400924683
Validation loss: 2.10799676756705

Epoch: 6| Step: 7
Training loss: 2.6896181106567383
Validation loss: 2.1063514806891

Epoch: 6| Step: 8
Training loss: 2.3504910469055176
Validation loss: 2.118663967296641

Epoch: 6| Step: 9
Training loss: 2.310276985168457
Validation loss: 2.1110163350259104

Epoch: 6| Step: 10
Training loss: 2.1136555671691895
Validation loss: 2.115350431011569

Epoch: 6| Step: 11
Training loss: 1.4211746454238892
Validation loss: 2.120377314988003

Epoch: 6| Step: 12
Training loss: 2.0808498859405518
Validation loss: 2.130803754252772

Epoch: 6| Step: 13
Training loss: 3.083782434463501
Validation loss: 2.1484619391861783

Epoch: 318| Step: 0
Training loss: 3.2656607627868652
Validation loss: 2.1389442797630065

Epoch: 6| Step: 1
Training loss: 1.8112518787384033
Validation loss: 2.1514513723311888

Epoch: 6| Step: 2
Training loss: 2.044912576675415
Validation loss: 2.1489332939988826

Epoch: 6| Step: 3
Training loss: 2.1419692039489746
Validation loss: 2.1538872667538222

Epoch: 6| Step: 4
Training loss: 2.4071826934814453
Validation loss: 2.1241215787908083

Epoch: 6| Step: 5
Training loss: 2.1506996154785156
Validation loss: 2.118510336004278

Epoch: 6| Step: 6
Training loss: 2.736032724380493
Validation loss: 2.106301017986831

Epoch: 6| Step: 7
Training loss: 2.2714059352874756
Validation loss: 2.1155217129697084

Epoch: 6| Step: 8
Training loss: 2.2279751300811768
Validation loss: 2.108107518124324

Epoch: 6| Step: 9
Training loss: 1.5370819568634033
Validation loss: 2.101807253335112

Epoch: 6| Step: 10
Training loss: 2.362532138824463
Validation loss: 2.094263909965433

Epoch: 6| Step: 11
Training loss: 1.860163927078247
Validation loss: 2.0892880937104583

Epoch: 6| Step: 12
Training loss: 2.2596564292907715
Validation loss: 2.085829327183385

Epoch: 6| Step: 13
Training loss: 2.237201690673828
Validation loss: 2.1026433565283336

Epoch: 319| Step: 0
Training loss: 2.9627344608306885
Validation loss: 2.094893293996011

Epoch: 6| Step: 1
Training loss: 2.0642855167388916
Validation loss: 2.0762824473842496

Epoch: 6| Step: 2
Training loss: 1.591958999633789
Validation loss: 2.1005327675932195

Epoch: 6| Step: 3
Training loss: 2.254763126373291
Validation loss: 2.093770352743005

Epoch: 6| Step: 4
Training loss: 2.0731823444366455
Validation loss: 2.1132608280386975

Epoch: 6| Step: 5
Training loss: 2.5842015743255615
Validation loss: 2.1318044226656676

Epoch: 6| Step: 6
Training loss: 2.3042616844177246
Validation loss: 2.1297956051365023

Epoch: 6| Step: 7
Training loss: 2.5761055946350098
Validation loss: 2.12681947728639

Epoch: 6| Step: 8
Training loss: 2.2298269271850586
Validation loss: 2.124652760003203

Epoch: 6| Step: 9
Training loss: 2.774944305419922
Validation loss: 2.120934340261644

Epoch: 6| Step: 10
Training loss: 2.7667393684387207
Validation loss: 2.1235520391054052

Epoch: 6| Step: 11
Training loss: 1.7145432233810425
Validation loss: 2.1050644510535785

Epoch: 6| Step: 12
Training loss: 1.610237717628479
Validation loss: 2.117294183341406

Epoch: 6| Step: 13
Training loss: 1.5712916851043701
Validation loss: 2.102834096518896

Epoch: 320| Step: 0
Training loss: 2.5606870651245117
Validation loss: 2.1066808828743557

Epoch: 6| Step: 1
Training loss: 1.6665868759155273
Validation loss: 2.0984792504259335

Epoch: 6| Step: 2
Training loss: 1.9217662811279297
Validation loss: 2.103252416015953

Epoch: 6| Step: 3
Training loss: 3.243276596069336
Validation loss: 2.1134322586879937

Epoch: 6| Step: 4
Training loss: 2.363999605178833
Validation loss: 2.1244887100752963

Epoch: 6| Step: 5
Training loss: 1.568893313407898
Validation loss: 2.09092483469235

Epoch: 6| Step: 6
Training loss: 2.3620872497558594
Validation loss: 2.0990587613915883

Epoch: 6| Step: 7
Training loss: 1.9038243293762207
Validation loss: 2.094885295437228

Epoch: 6| Step: 8
Training loss: 1.7457573413848877
Validation loss: 2.1241510042580227

Epoch: 6| Step: 9
Training loss: 2.5042290687561035
Validation loss: 2.1120212411367767

Epoch: 6| Step: 10
Training loss: 2.5435261726379395
Validation loss: 2.1319627210658085

Epoch: 6| Step: 11
Training loss: 2.498361110687256
Validation loss: 2.100117063009611

Epoch: 6| Step: 12
Training loss: 2.2639644145965576
Validation loss: 2.1213939728275424

Epoch: 6| Step: 13
Training loss: 2.0386335849761963
Validation loss: 2.099135342464652

Epoch: 321| Step: 0
Training loss: 2.863029956817627
Validation loss: 2.101002367593909

Epoch: 6| Step: 1
Training loss: 2.2416155338287354
Validation loss: 2.1170940745261406

Epoch: 6| Step: 2
Training loss: 1.680481195449829
Validation loss: 2.1056353174230105

Epoch: 6| Step: 3
Training loss: 2.5719351768493652
Validation loss: 2.1053947787131033

Epoch: 6| Step: 4
Training loss: 1.8597044944763184
Validation loss: 2.0856625777418896

Epoch: 6| Step: 5
Training loss: 2.4070987701416016
Validation loss: 2.109482355015252

Epoch: 6| Step: 6
Training loss: 2.507220506668091
Validation loss: 2.093176867372246

Epoch: 6| Step: 7
Training loss: 1.5086166858673096
Validation loss: 2.097466534183871

Epoch: 6| Step: 8
Training loss: 2.8992440700531006
Validation loss: 2.0989203132608885

Epoch: 6| Step: 9
Training loss: 1.6524219512939453
Validation loss: 2.084582690269716

Epoch: 6| Step: 10
Training loss: 1.9658089876174927
Validation loss: 2.0879743983668666

Epoch: 6| Step: 11
Training loss: 2.7353827953338623
Validation loss: 2.075616011055567

Epoch: 6| Step: 12
Training loss: 2.238424777984619
Validation loss: 2.079363397372666

Epoch: 6| Step: 13
Training loss: 1.824484944343567
Validation loss: 2.0888804005038355

Epoch: 322| Step: 0
Training loss: 2.2029364109039307
Validation loss: 2.0852237132287796

Epoch: 6| Step: 1
Training loss: 1.5637948513031006
Validation loss: 2.0818758446683168

Epoch: 6| Step: 2
Training loss: 1.9340312480926514
Validation loss: 2.0831683528038765

Epoch: 6| Step: 3
Training loss: 1.7201447486877441
Validation loss: 2.085783707198276

Epoch: 6| Step: 4
Training loss: 2.2219667434692383
Validation loss: 2.098335401986235

Epoch: 6| Step: 5
Training loss: 2.3254690170288086
Validation loss: 2.092586576297719

Epoch: 6| Step: 6
Training loss: 2.1330888271331787
Validation loss: 2.0921015918895765

Epoch: 6| Step: 7
Training loss: 1.7229875326156616
Validation loss: 2.0908081518706454

Epoch: 6| Step: 8
Training loss: 2.656597137451172
Validation loss: 2.0985074607274865

Epoch: 6| Step: 9
Training loss: 2.8172223567962646
Validation loss: 2.0903076151365876

Epoch: 6| Step: 10
Training loss: 2.6556148529052734
Validation loss: 2.100205918794037

Epoch: 6| Step: 11
Training loss: 2.5234975814819336
Validation loss: 2.108560480097289

Epoch: 6| Step: 12
Training loss: 2.2417099475860596
Validation loss: 2.095596562149704

Epoch: 6| Step: 13
Training loss: 2.4352052211761475
Validation loss: 2.0980684026595084

Epoch: 323| Step: 0
Training loss: 2.253387451171875
Validation loss: 2.110807188095585

Epoch: 6| Step: 1
Training loss: 2.3227651119232178
Validation loss: 2.1063708900123514

Epoch: 6| Step: 2
Training loss: 2.0051181316375732
Validation loss: 2.093602062553488

Epoch: 6| Step: 3
Training loss: 2.1893508434295654
Validation loss: 2.099437616204703

Epoch: 6| Step: 4
Training loss: 2.3408029079437256
Validation loss: 2.113393211877474

Epoch: 6| Step: 5
Training loss: 2.1664681434631348
Validation loss: 2.0967504465451805

Epoch: 6| Step: 6
Training loss: 1.4330534934997559
Validation loss: 2.1174138002498175

Epoch: 6| Step: 7
Training loss: 1.9036226272583008
Validation loss: 2.0892214287993727

Epoch: 6| Step: 8
Training loss: 2.8634164333343506
Validation loss: 2.101590685946967

Epoch: 6| Step: 9
Training loss: 2.5586555004119873
Validation loss: 2.0852292955562635

Epoch: 6| Step: 10
Training loss: 1.45106840133667
Validation loss: 2.0801085554143435

Epoch: 6| Step: 11
Training loss: 2.4595608711242676
Validation loss: 2.0905471232629593

Epoch: 6| Step: 12
Training loss: 2.975397825241089
Validation loss: 2.075692724156123

Epoch: 6| Step: 13
Training loss: 2.128300428390503
Validation loss: 2.0818945489903933

Epoch: 324| Step: 0
Training loss: 2.704228639602661
Validation loss: 2.0762499276027886

Epoch: 6| Step: 1
Training loss: 2.609584331512451
Validation loss: 2.0639606047702093

Epoch: 6| Step: 2
Training loss: 2.165534734725952
Validation loss: 2.073328866753527

Epoch: 6| Step: 3
Training loss: 2.114384889602661
Validation loss: 2.096187483879828

Epoch: 6| Step: 4
Training loss: 2.373225212097168
Validation loss: 2.0903845602466213

Epoch: 6| Step: 5
Training loss: 2.2789459228515625
Validation loss: 2.1119771413905646

Epoch: 6| Step: 6
Training loss: 2.0790414810180664
Validation loss: 2.1053918151445288

Epoch: 6| Step: 7
Training loss: 2.481644868850708
Validation loss: 2.101766110748373

Epoch: 6| Step: 8
Training loss: 2.448153495788574
Validation loss: 2.094097480979017

Epoch: 6| Step: 9
Training loss: 2.165584087371826
Validation loss: 2.090080544512759

Epoch: 6| Step: 10
Training loss: 1.9451086521148682
Validation loss: 2.078632157335999

Epoch: 6| Step: 11
Training loss: 2.1900835037231445
Validation loss: 2.093735715394379

Epoch: 6| Step: 12
Training loss: 1.1712321043014526
Validation loss: 2.0987646554106023

Epoch: 6| Step: 13
Training loss: 2.6260859966278076
Validation loss: 2.0979798801483645

Epoch: 325| Step: 0
Training loss: 1.7801499366760254
Validation loss: 2.1288219933868735

Epoch: 6| Step: 1
Training loss: 2.657648801803589
Validation loss: 2.135222013278674

Epoch: 6| Step: 2
Training loss: 2.4440274238586426
Validation loss: 2.1656093341048046

Epoch: 6| Step: 3
Training loss: 2.3063104152679443
Validation loss: 2.1952612451327744

Epoch: 6| Step: 4
Training loss: 2.4613051414489746
Validation loss: 2.1693310968337522

Epoch: 6| Step: 5
Training loss: 2.4312281608581543
Validation loss: 2.1506913810647945

Epoch: 6| Step: 6
Training loss: 2.2658493518829346
Validation loss: 2.146188400124991

Epoch: 6| Step: 7
Training loss: 1.9366579055786133
Validation loss: 2.1292365366412747

Epoch: 6| Step: 8
Training loss: 1.6616783142089844
Validation loss: 2.1129501250482376

Epoch: 6| Step: 9
Training loss: 2.0197386741638184
Validation loss: 2.114370951088526

Epoch: 6| Step: 10
Training loss: 1.8342163562774658
Validation loss: 2.1044057274377472

Epoch: 6| Step: 11
Training loss: 2.89066219329834
Validation loss: 2.1102612018585205

Epoch: 6| Step: 12
Training loss: 2.384638786315918
Validation loss: 2.104021236460696

Epoch: 6| Step: 13
Training loss: 2.142226457595825
Validation loss: 2.092201914838565

Epoch: 326| Step: 0
Training loss: 2.278331756591797
Validation loss: 2.097082794353526

Epoch: 6| Step: 1
Training loss: 2.1375575065612793
Validation loss: 2.083925957320839

Epoch: 6| Step: 2
Training loss: 1.603444218635559
Validation loss: 2.0865589662264754

Epoch: 6| Step: 3
Training loss: 1.818965196609497
Validation loss: 2.079670811212191

Epoch: 6| Step: 4
Training loss: 2.2661073207855225
Validation loss: 2.0729390113584456

Epoch: 6| Step: 5
Training loss: 1.694596767425537
Validation loss: 2.082096817672894

Epoch: 6| Step: 6
Training loss: 2.026972770690918
Validation loss: 2.083007776609031

Epoch: 6| Step: 7
Training loss: 2.6402578353881836
Validation loss: 2.0766005285324587

Epoch: 6| Step: 8
Training loss: 2.201836109161377
Validation loss: 2.083511165393296

Epoch: 6| Step: 9
Training loss: 2.8094279766082764
Validation loss: 2.101499572876961

Epoch: 6| Step: 10
Training loss: 3.2276973724365234
Validation loss: 2.0969720809690413

Epoch: 6| Step: 11
Training loss: 2.6722912788391113
Validation loss: 2.080514161817489

Epoch: 6| Step: 12
Training loss: 1.6345049142837524
Validation loss: 2.0940177338097685

Epoch: 6| Step: 13
Training loss: 2.2721569538116455
Validation loss: 2.094565300531285

Epoch: 327| Step: 0
Training loss: 2.3942480087280273
Validation loss: 2.0664657482536892

Epoch: 6| Step: 1
Training loss: 1.9614335298538208
Validation loss: 2.0935098791635163

Epoch: 6| Step: 2
Training loss: 2.3597464561462402
Validation loss: 2.099171030905939

Epoch: 6| Step: 3
Training loss: 2.249570846557617
Validation loss: 2.0972773977505264

Epoch: 6| Step: 4
Training loss: 2.7827272415161133
Validation loss: 2.0907962040234636

Epoch: 6| Step: 5
Training loss: 1.8801298141479492
Validation loss: 2.0919915527425785

Epoch: 6| Step: 6
Training loss: 2.321742057800293
Validation loss: 2.092330313497974

Epoch: 6| Step: 7
Training loss: 2.231370449066162
Validation loss: 2.076125785868655

Epoch: 6| Step: 8
Training loss: 2.0501441955566406
Validation loss: 2.094865278531146

Epoch: 6| Step: 9
Training loss: 2.3865585327148438
Validation loss: 2.0880111520008375

Epoch: 6| Step: 10
Training loss: 2.0469963550567627
Validation loss: 2.0913014283744236

Epoch: 6| Step: 11
Training loss: 2.2263436317443848
Validation loss: 2.099001398650549

Epoch: 6| Step: 12
Training loss: 1.9922592639923096
Validation loss: 2.0986082758954776

Epoch: 6| Step: 13
Training loss: 2.680905818939209
Validation loss: 2.0846274527170325

Epoch: 328| Step: 0
Training loss: 2.02990984916687
Validation loss: 2.0825167907181608

Epoch: 6| Step: 1
Training loss: 2.483920097351074
Validation loss: 2.0929171731395106

Epoch: 6| Step: 2
Training loss: 1.6384845972061157
Validation loss: 2.092519444804038

Epoch: 6| Step: 3
Training loss: 2.0886576175689697
Validation loss: 2.1039272739041235

Epoch: 6| Step: 4
Training loss: 2.17893123626709
Validation loss: 2.134476189972252

Epoch: 6| Step: 5
Training loss: 2.8269009590148926
Validation loss: 2.1269298420157483

Epoch: 6| Step: 6
Training loss: 1.4671518802642822
Validation loss: 2.125376048908439

Epoch: 6| Step: 7
Training loss: 1.9836657047271729
Validation loss: 2.121615679033341

Epoch: 6| Step: 8
Training loss: 2.3250315189361572
Validation loss: 2.121450226794007

Epoch: 6| Step: 9
Training loss: 2.476459264755249
Validation loss: 2.096140569256198

Epoch: 6| Step: 10
Training loss: 2.4717116355895996
Validation loss: 2.0871018773765972

Epoch: 6| Step: 11
Training loss: 2.0254580974578857
Validation loss: 2.094313730475723

Epoch: 6| Step: 12
Training loss: 2.7807562351226807
Validation loss: 2.105565736370702

Epoch: 6| Step: 13
Training loss: 2.342534303665161
Validation loss: 2.1259733425673617

Epoch: 329| Step: 0
Training loss: 2.4791834354400635
Validation loss: 2.1469390571758313

Epoch: 6| Step: 1
Training loss: 2.3269734382629395
Validation loss: 2.142084308849868

Epoch: 6| Step: 2
Training loss: 2.090043067932129
Validation loss: 2.1383370942966913

Epoch: 6| Step: 3
Training loss: 1.8215909004211426
Validation loss: 2.1420850933239026

Epoch: 6| Step: 4
Training loss: 2.217926263809204
Validation loss: 2.125958101723784

Epoch: 6| Step: 5
Training loss: 1.5779123306274414
Validation loss: 2.1158645306864092

Epoch: 6| Step: 6
Training loss: 2.6141576766967773
Validation loss: 2.115624704668599

Epoch: 6| Step: 7
Training loss: 2.7426376342773438
Validation loss: 2.1027898711542927

Epoch: 6| Step: 8
Training loss: 1.9240719079971313
Validation loss: 2.111837294793898

Epoch: 6| Step: 9
Training loss: 2.750885009765625
Validation loss: 2.111890718501101

Epoch: 6| Step: 10
Training loss: 2.6755919456481934
Validation loss: 2.1020865517277874

Epoch: 6| Step: 11
Training loss: 2.334352731704712
Validation loss: 2.1079409609558764

Epoch: 6| Step: 12
Training loss: 1.5535130500793457
Validation loss: 2.0989506654841925

Epoch: 6| Step: 13
Training loss: 1.9833009243011475
Validation loss: 2.1158605621707056

Epoch: 330| Step: 0
Training loss: 2.929741144180298
Validation loss: 2.106273171722248

Epoch: 6| Step: 1
Training loss: 2.239473819732666
Validation loss: 2.1112965717110583

Epoch: 6| Step: 2
Training loss: 2.0444815158843994
Validation loss: 2.115098491791756

Epoch: 6| Step: 3
Training loss: 1.3146827220916748
Validation loss: 2.094952006493845

Epoch: 6| Step: 4
Training loss: 1.8314157724380493
Validation loss: 2.082257186212847

Epoch: 6| Step: 5
Training loss: 2.542206048965454
Validation loss: 2.089041148462603

Epoch: 6| Step: 6
Training loss: 1.9742754697799683
Validation loss: 2.085552264285344

Epoch: 6| Step: 7
Training loss: 2.0649218559265137
Validation loss: 2.091405334011201

Epoch: 6| Step: 8
Training loss: 2.752969264984131
Validation loss: 2.095707014042844

Epoch: 6| Step: 9
Training loss: 1.5360713005065918
Validation loss: 2.088590661684672

Epoch: 6| Step: 10
Training loss: 2.4671897888183594
Validation loss: 2.087723321812127

Epoch: 6| Step: 11
Training loss: 1.6622883081436157
Validation loss: 2.0913180266657183

Epoch: 6| Step: 12
Training loss: 3.1105566024780273
Validation loss: 2.094507735262635

Epoch: 6| Step: 13
Training loss: 2.800963878631592
Validation loss: 2.0952803037499868

Epoch: 331| Step: 0
Training loss: 1.9628280401229858
Validation loss: 2.0866297778262886

Epoch: 6| Step: 1
Training loss: 2.7801079750061035
Validation loss: 2.1095664860099874

Epoch: 6| Step: 2
Training loss: 1.5000669956207275
Validation loss: 2.101167501941804

Epoch: 6| Step: 3
Training loss: 1.7859413623809814
Validation loss: 2.0919052298351

Epoch: 6| Step: 4
Training loss: 2.300011157989502
Validation loss: 2.1020222658752115

Epoch: 6| Step: 5
Training loss: 2.5031657218933105
Validation loss: 2.0974706013997397

Epoch: 6| Step: 6
Training loss: 2.3817200660705566
Validation loss: 2.0882639103038336

Epoch: 6| Step: 7
Training loss: 2.1808454990386963
Validation loss: 2.1002241616607993

Epoch: 6| Step: 8
Training loss: 1.8677284717559814
Validation loss: 2.0933203299840293

Epoch: 6| Step: 9
Training loss: 2.074963331222534
Validation loss: 2.097425655652118

Epoch: 6| Step: 10
Training loss: 2.4075844287872314
Validation loss: 2.105472687752016

Epoch: 6| Step: 11
Training loss: 2.2686543464660645
Validation loss: 2.096444852890507

Epoch: 6| Step: 12
Training loss: 2.2356648445129395
Validation loss: 2.088871903316949

Epoch: 6| Step: 13
Training loss: 3.0892648696899414
Validation loss: 2.1097651579046763

Epoch: 332| Step: 0
Training loss: 1.7624849081039429
Validation loss: 2.0862320289816907

Epoch: 6| Step: 1
Training loss: 2.2015366554260254
Validation loss: 2.1017397142225698

Epoch: 6| Step: 2
Training loss: 2.4158999919891357
Validation loss: 2.1038131252411874

Epoch: 6| Step: 3
Training loss: 2.3072519302368164
Validation loss: 2.1138914759441088

Epoch: 6| Step: 4
Training loss: 1.7981679439544678
Validation loss: 2.122429185016181

Epoch: 6| Step: 5
Training loss: 1.5117809772491455
Validation loss: 2.1271616156383226

Epoch: 6| Step: 6
Training loss: 2.110222339630127
Validation loss: 2.110075419948947

Epoch: 6| Step: 7
Training loss: 3.157517433166504
Validation loss: 2.100808205143098

Epoch: 6| Step: 8
Training loss: 2.113797187805176
Validation loss: 2.0896773876682406

Epoch: 6| Step: 9
Training loss: 2.7753753662109375
Validation loss: 2.0796061279953166

Epoch: 6| Step: 10
Training loss: 2.080652952194214
Validation loss: 2.097638791607272

Epoch: 6| Step: 11
Training loss: 2.1789391040802
Validation loss: 2.0725961269870883

Epoch: 6| Step: 12
Training loss: 2.4270858764648438
Validation loss: 2.094261298897446

Epoch: 6| Step: 13
Training loss: 1.8919336795806885
Validation loss: 2.099452584020553

Epoch: 333| Step: 0
Training loss: 2.3448312282562256
Validation loss: 2.098219957402957

Epoch: 6| Step: 1
Training loss: 2.7018518447875977
Validation loss: 2.0852017479558147

Epoch: 6| Step: 2
Training loss: 2.1461825370788574
Validation loss: 2.0778745066735054

Epoch: 6| Step: 3
Training loss: 2.006227493286133
Validation loss: 2.0933803332749235

Epoch: 6| Step: 4
Training loss: 2.559603691101074
Validation loss: 2.0908546088844218

Epoch: 6| Step: 5
Training loss: 1.9233450889587402
Validation loss: 2.0927518016548565

Epoch: 6| Step: 6
Training loss: 1.8005154132843018
Validation loss: 2.0834466859858525

Epoch: 6| Step: 7
Training loss: 1.946000576019287
Validation loss: 2.067738030546455

Epoch: 6| Step: 8
Training loss: 2.231489658355713
Validation loss: 2.08762966176515

Epoch: 6| Step: 9
Training loss: 2.039780616760254
Validation loss: 2.113482718826622

Epoch: 6| Step: 10
Training loss: 2.459920883178711
Validation loss: 2.1014853062168246

Epoch: 6| Step: 11
Training loss: 2.0923361778259277
Validation loss: 2.107882741958864

Epoch: 6| Step: 12
Training loss: 2.6112184524536133
Validation loss: 2.0925268434709117

Epoch: 6| Step: 13
Training loss: 2.220641613006592
Validation loss: 2.0991231908080397

Epoch: 334| Step: 0
Training loss: 2.2867074012756348
Validation loss: 2.089907197542088

Epoch: 6| Step: 1
Training loss: 2.495771884918213
Validation loss: 2.0884973477291804

Epoch: 6| Step: 2
Training loss: 2.8044707775115967
Validation loss: 2.0780316091352895

Epoch: 6| Step: 3
Training loss: 1.5613086223602295
Validation loss: 2.0810547618455786

Epoch: 6| Step: 4
Training loss: 1.944032907485962
Validation loss: 2.0882049068327873

Epoch: 6| Step: 5
Training loss: 1.2838554382324219
Validation loss: 2.1058215261787496

Epoch: 6| Step: 6
Training loss: 1.9804530143737793
Validation loss: 2.1094036435568206

Epoch: 6| Step: 7
Training loss: 2.4097485542297363
Validation loss: 2.11000164862602

Epoch: 6| Step: 8
Training loss: 2.1281802654266357
Validation loss: 2.1030774090879705

Epoch: 6| Step: 9
Training loss: 2.53835391998291
Validation loss: 2.0971421054614487

Epoch: 6| Step: 10
Training loss: 3.00103759765625
Validation loss: 2.103155341199649

Epoch: 6| Step: 11
Training loss: 2.113164186477661
Validation loss: 2.0959174709935344

Epoch: 6| Step: 12
Training loss: 2.18034029006958
Validation loss: 2.107869571255099

Epoch: 6| Step: 13
Training loss: 2.048708915710449
Validation loss: 2.1132506567944764

Epoch: 335| Step: 0
Training loss: 2.1456193923950195
Validation loss: 2.111649105625768

Epoch: 6| Step: 1
Training loss: 1.6277360916137695
Validation loss: 2.125953435897827

Epoch: 6| Step: 2
Training loss: 2.094818353652954
Validation loss: 2.1214651471825055

Epoch: 6| Step: 3
Training loss: 2.070603847503662
Validation loss: 2.130247313489196

Epoch: 6| Step: 4
Training loss: 1.6276261806488037
Validation loss: 2.1156093048793014

Epoch: 6| Step: 5
Training loss: 2.2710611820220947
Validation loss: 2.102331156371742

Epoch: 6| Step: 6
Training loss: 3.322819709777832
Validation loss: 2.085668211342186

Epoch: 6| Step: 7
Training loss: 2.4471826553344727
Validation loss: 2.088733788459532

Epoch: 6| Step: 8
Training loss: 1.7660118341445923
Validation loss: 2.085555730327483

Epoch: 6| Step: 9
Training loss: 2.479440212249756
Validation loss: 2.0969163628034693

Epoch: 6| Step: 10
Training loss: 2.9627695083618164
Validation loss: 2.1049724266093266

Epoch: 6| Step: 11
Training loss: 2.136180877685547
Validation loss: 2.1043180675916773

Epoch: 6| Step: 12
Training loss: 2.218045949935913
Validation loss: 2.11240622433283

Epoch: 6| Step: 13
Training loss: 1.8964593410491943
Validation loss: 2.107758505370027

Epoch: 336| Step: 0
Training loss: 2.4580435752868652
Validation loss: 2.103397354002922

Epoch: 6| Step: 1
Training loss: 2.0075817108154297
Validation loss: 2.0897533406493483

Epoch: 6| Step: 2
Training loss: 2.8499531745910645
Validation loss: 2.0857459498989965

Epoch: 6| Step: 3
Training loss: 1.4106413125991821
Validation loss: 2.076622692487573

Epoch: 6| Step: 4
Training loss: 2.299880027770996
Validation loss: 2.0865730982954784

Epoch: 6| Step: 5
Training loss: 1.5708460807800293
Validation loss: 2.084643393434504

Epoch: 6| Step: 6
Training loss: 2.448671817779541
Validation loss: 2.0652866671162267

Epoch: 6| Step: 7
Training loss: 2.590909481048584
Validation loss: 2.071021477381388

Epoch: 6| Step: 8
Training loss: 1.898493766784668
Validation loss: 2.0636258509851273

Epoch: 6| Step: 9
Training loss: 2.084803342819214
Validation loss: 2.0747397779136576

Epoch: 6| Step: 10
Training loss: 2.4448111057281494
Validation loss: 2.064113260597311

Epoch: 6| Step: 11
Training loss: 2.21130633354187
Validation loss: 2.067622338571856

Epoch: 6| Step: 12
Training loss: 2.1341843605041504
Validation loss: 2.072486392913326

Epoch: 6| Step: 13
Training loss: 2.481348991394043
Validation loss: 2.0774648907364055

Epoch: 337| Step: 0
Training loss: 2.2063345909118652
Validation loss: 2.0626661521132275

Epoch: 6| Step: 1
Training loss: 2.1980395317077637
Validation loss: 2.072629996525344

Epoch: 6| Step: 2
Training loss: 2.656435966491699
Validation loss: 2.0804710644547657

Epoch: 6| Step: 3
Training loss: 1.8660939931869507
Validation loss: 2.0707137482140654

Epoch: 6| Step: 4
Training loss: 2.4154977798461914
Validation loss: 2.070209692883235

Epoch: 6| Step: 5
Training loss: 1.7907112836837769
Validation loss: 2.086342857730004

Epoch: 6| Step: 6
Training loss: 2.5985305309295654
Validation loss: 2.082625321162644

Epoch: 6| Step: 7
Training loss: 2.1505603790283203
Validation loss: 2.0973141411299348

Epoch: 6| Step: 8
Training loss: 1.896289348602295
Validation loss: 2.1003315961489113

Epoch: 6| Step: 9
Training loss: 1.971343994140625
Validation loss: 2.096065890404486

Epoch: 6| Step: 10
Training loss: 1.808347225189209
Validation loss: 2.093236287434896

Epoch: 6| Step: 11
Training loss: 1.9570832252502441
Validation loss: 2.0922361445683304

Epoch: 6| Step: 12
Training loss: 2.3035507202148438
Validation loss: 2.093374506119759

Epoch: 6| Step: 13
Training loss: 3.3951542377471924
Validation loss: 2.0869112245498167

Epoch: 338| Step: 0
Training loss: 2.1386706829071045
Validation loss: 2.0843075526657926

Epoch: 6| Step: 1
Training loss: 1.4987291097640991
Validation loss: 2.0842975647218767

Epoch: 6| Step: 2
Training loss: 2.1382386684417725
Validation loss: 2.08650710762188

Epoch: 6| Step: 3
Training loss: 1.923751950263977
Validation loss: 2.073539544177312

Epoch: 6| Step: 4
Training loss: 2.4515538215637207
Validation loss: 2.0768807626539663

Epoch: 6| Step: 5
Training loss: 2.211550712585449
Validation loss: 2.0770518113208074

Epoch: 6| Step: 6
Training loss: 2.2815890312194824
Validation loss: 2.069922613841231

Epoch: 6| Step: 7
Training loss: 2.6559572219848633
Validation loss: 2.0751738240641933

Epoch: 6| Step: 8
Training loss: 1.9670742750167847
Validation loss: 2.0752146782413607

Epoch: 6| Step: 9
Training loss: 2.1576156616210938
Validation loss: 2.0880620851311633

Epoch: 6| Step: 10
Training loss: 2.444187879562378
Validation loss: 2.0921647933221634

Epoch: 6| Step: 11
Training loss: 2.5672998428344727
Validation loss: 2.0893697405374176

Epoch: 6| Step: 12
Training loss: 2.1485249996185303
Validation loss: 2.0900895134095223

Epoch: 6| Step: 13
Training loss: 2.034736156463623
Validation loss: 2.0908917047644175

Epoch: 339| Step: 0
Training loss: 2.365933656692505
Validation loss: 2.083823024585683

Epoch: 6| Step: 1
Training loss: 2.3475046157836914
Validation loss: 2.0797521401477117

Epoch: 6| Step: 2
Training loss: 2.465252161026001
Validation loss: 2.0786915491986018

Epoch: 6| Step: 3
Training loss: 2.6845433712005615
Validation loss: 2.0712198595846854

Epoch: 6| Step: 4
Training loss: 2.04404878616333
Validation loss: 2.0731809318706556

Epoch: 6| Step: 5
Training loss: 2.786989688873291
Validation loss: 2.0850124051493983

Epoch: 6| Step: 6
Training loss: 2.155029773712158
Validation loss: 2.0814257783274495

Epoch: 6| Step: 7
Training loss: 1.8596376180648804
Validation loss: 2.0815962976024998

Epoch: 6| Step: 8
Training loss: 1.6340649127960205
Validation loss: 2.0829173518765356

Epoch: 6| Step: 9
Training loss: 2.619264841079712
Validation loss: 2.0743825384365615

Epoch: 6| Step: 10
Training loss: 1.4547804594039917
Validation loss: 2.079270624345349

Epoch: 6| Step: 11
Training loss: 2.025161027908325
Validation loss: 2.080271695249824

Epoch: 6| Step: 12
Training loss: 2.3594465255737305
Validation loss: 2.0594497906264437

Epoch: 6| Step: 13
Training loss: 1.776400089263916
Validation loss: 2.06907315920758

Epoch: 340| Step: 0
Training loss: 2.677748441696167
Validation loss: 2.0697910119128484

Epoch: 6| Step: 1
Training loss: 1.7737280130386353
Validation loss: 2.077992687943161

Epoch: 6| Step: 2
Training loss: 2.0642166137695312
Validation loss: 2.065431712776102

Epoch: 6| Step: 3
Training loss: 2.106809139251709
Validation loss: 2.083888743513374

Epoch: 6| Step: 4
Training loss: 2.6210904121398926
Validation loss: 2.0645071767991587

Epoch: 6| Step: 5
Training loss: 2.475198745727539
Validation loss: 2.067050072454637

Epoch: 6| Step: 6
Training loss: 2.249480724334717
Validation loss: 2.067343332434213

Epoch: 6| Step: 7
Training loss: 2.0761005878448486
Validation loss: 2.0722440212003645

Epoch: 6| Step: 8
Training loss: 2.1420509815216064
Validation loss: 2.0683763193827804

Epoch: 6| Step: 9
Training loss: 1.9685016870498657
Validation loss: 2.0862631182516775

Epoch: 6| Step: 10
Training loss: 1.3584387302398682
Validation loss: 2.095060771511447

Epoch: 6| Step: 11
Training loss: 2.7112107276916504
Validation loss: 2.1006219874146166

Epoch: 6| Step: 12
Training loss: 2.255157470703125
Validation loss: 2.0955480247415523

Epoch: 6| Step: 13
Training loss: 2.147745370864868
Validation loss: 2.0848036889106996

Epoch: 341| Step: 0
Training loss: 2.2700929641723633
Validation loss: 2.0661314559239212

Epoch: 6| Step: 1
Training loss: 2.4587531089782715
Validation loss: 2.0550636796541113

Epoch: 6| Step: 2
Training loss: 2.753643274307251
Validation loss: 2.0583751509266515

Epoch: 6| Step: 3
Training loss: 1.975469946861267
Validation loss: 2.066853875754982

Epoch: 6| Step: 4
Training loss: 1.950508713722229
Validation loss: 2.063820540264089

Epoch: 6| Step: 5
Training loss: 2.2701680660247803
Validation loss: 2.0769727512072493

Epoch: 6| Step: 6
Training loss: 1.903741717338562
Validation loss: 2.0659055889293714

Epoch: 6| Step: 7
Training loss: 2.7042746543884277
Validation loss: 2.0696027586537022

Epoch: 6| Step: 8
Training loss: 2.3321526050567627
Validation loss: 2.0616500685291905

Epoch: 6| Step: 9
Training loss: 2.2660293579101562
Validation loss: 2.066136965187647

Epoch: 6| Step: 10
Training loss: 1.722965121269226
Validation loss: 2.069454088005968

Epoch: 6| Step: 11
Training loss: 2.3419506549835205
Validation loss: 2.0803704261779785

Epoch: 6| Step: 12
Training loss: 1.2647068500518799
Validation loss: 2.09094008450867

Epoch: 6| Step: 13
Training loss: 2.546306610107422
Validation loss: 2.1007357963951687

Epoch: 342| Step: 0
Training loss: 2.0659472942352295
Validation loss: 2.0935035444075063

Epoch: 6| Step: 1
Training loss: 1.9319801330566406
Validation loss: 2.1140565641464724

Epoch: 6| Step: 2
Training loss: 1.8130674362182617
Validation loss: 2.0940842769479238

Epoch: 6| Step: 3
Training loss: 1.8886692523956299
Validation loss: 2.110748506361438

Epoch: 6| Step: 4
Training loss: 1.7117223739624023
Validation loss: 2.1022749536780903

Epoch: 6| Step: 5
Training loss: 1.6402432918548584
Validation loss: 2.102262317493398

Epoch: 6| Step: 6
Training loss: 2.567694664001465
Validation loss: 2.0824874883056967

Epoch: 6| Step: 7
Training loss: 3.1130917072296143
Validation loss: 2.0780654145825292

Epoch: 6| Step: 8
Training loss: 2.441556453704834
Validation loss: 2.0768088345886557

Epoch: 6| Step: 9
Training loss: 1.8782118558883667
Validation loss: 2.071081845991073

Epoch: 6| Step: 10
Training loss: 1.9658830165863037
Validation loss: 2.0645546887510564

Epoch: 6| Step: 11
Training loss: 3.2158751487731934
Validation loss: 2.072253869425866

Epoch: 6| Step: 12
Training loss: 2.021202564239502
Validation loss: 2.0615535372047016

Epoch: 6| Step: 13
Training loss: 2.2852635383605957
Validation loss: 2.052288759139276

Epoch: 343| Step: 0
Training loss: 2.5393948554992676
Validation loss: 2.0481807416485203

Epoch: 6| Step: 1
Training loss: 1.924591302871704
Validation loss: 2.063827999176518

Epoch: 6| Step: 2
Training loss: 2.7746806144714355
Validation loss: 2.0535421012550272

Epoch: 6| Step: 3
Training loss: 1.8948051929473877
Validation loss: 2.061064197171119

Epoch: 6| Step: 4
Training loss: 2.0132839679718018
Validation loss: 2.058451262853479

Epoch: 6| Step: 5
Training loss: 1.982175588607788
Validation loss: 2.0884405028435493

Epoch: 6| Step: 6
Training loss: 2.2020654678344727
Validation loss: 2.091266006551763

Epoch: 6| Step: 7
Training loss: 1.4738752841949463
Validation loss: 2.1051738492904173

Epoch: 6| Step: 8
Training loss: 3.0880627632141113
Validation loss: 2.0992286410383

Epoch: 6| Step: 9
Training loss: 2.67659330368042
Validation loss: 2.1071226827559935

Epoch: 6| Step: 10
Training loss: 2.398374080657959
Validation loss: 2.090819684408044

Epoch: 6| Step: 11
Training loss: 2.318023204803467
Validation loss: 2.080979262628863

Epoch: 6| Step: 12
Training loss: 1.6070462465286255
Validation loss: 2.082002883316368

Epoch: 6| Step: 13
Training loss: 1.1562076807022095
Validation loss: 2.075933797385103

Epoch: 344| Step: 0
Training loss: 2.207876443862915
Validation loss: 2.070233839814381

Epoch: 6| Step: 1
Training loss: 2.3326992988586426
Validation loss: 2.0687550934412147

Epoch: 6| Step: 2
Training loss: 2.2482619285583496
Validation loss: 2.0496033648008942

Epoch: 6| Step: 3
Training loss: 1.6637763977050781
Validation loss: 2.0609196001483547

Epoch: 6| Step: 4
Training loss: 2.1000986099243164
Validation loss: 2.0535053617210797

Epoch: 6| Step: 5
Training loss: 2.711228609085083
Validation loss: 2.0750421016447005

Epoch: 6| Step: 6
Training loss: 2.1981377601623535
Validation loss: 2.076461345918717

Epoch: 6| Step: 7
Training loss: 1.820462942123413
Validation loss: 2.085895762648634

Epoch: 6| Step: 8
Training loss: 2.5787885189056396
Validation loss: 2.1075463115528064

Epoch: 6| Step: 9
Training loss: 1.792176365852356
Validation loss: 2.0800202867036224

Epoch: 6| Step: 10
Training loss: 2.1574130058288574
Validation loss: 2.081810553868612

Epoch: 6| Step: 11
Training loss: 2.508572578430176
Validation loss: 2.0602269813578618

Epoch: 6| Step: 12
Training loss: 2.496821403503418
Validation loss: 2.0708937670594905

Epoch: 6| Step: 13
Training loss: 1.1182643175125122
Validation loss: 2.06293462809696

Epoch: 345| Step: 0
Training loss: 3.0404982566833496
Validation loss: 2.0731938128830283

Epoch: 6| Step: 1
Training loss: 1.9278826713562012
Validation loss: 2.069124085928804

Epoch: 6| Step: 2
Training loss: 1.86545991897583
Validation loss: 2.079535548404981

Epoch: 6| Step: 3
Training loss: 1.9200389385223389
Validation loss: 2.0962151199258785

Epoch: 6| Step: 4
Training loss: 2.0122737884521484
Validation loss: 2.085722064459196

Epoch: 6| Step: 5
Training loss: 1.7424473762512207
Validation loss: 2.075984754870015

Epoch: 6| Step: 6
Training loss: 1.9047282934188843
Validation loss: 2.0778319117843465

Epoch: 6| Step: 7
Training loss: 2.168466091156006
Validation loss: 2.0715881650165846

Epoch: 6| Step: 8
Training loss: 2.4587037563323975
Validation loss: 2.0595707085824784

Epoch: 6| Step: 9
Training loss: 2.511518955230713
Validation loss: 2.071788999342149

Epoch: 6| Step: 10
Training loss: 1.5556061267852783
Validation loss: 2.0542241745097662

Epoch: 6| Step: 11
Training loss: 2.3702244758605957
Validation loss: 2.0612713649708736

Epoch: 6| Step: 12
Training loss: 2.496612548828125
Validation loss: 2.0690647940481863

Epoch: 6| Step: 13
Training loss: 2.5741021633148193
Validation loss: 2.067992171933574

Epoch: 346| Step: 0
Training loss: 2.0228376388549805
Validation loss: 2.0927495982057307

Epoch: 6| Step: 1
Training loss: 2.045178174972534
Validation loss: 2.0823319624829035

Epoch: 6| Step: 2
Training loss: 1.8973037004470825
Validation loss: 2.0921376059132237

Epoch: 6| Step: 3
Training loss: 2.279618740081787
Validation loss: 2.0932339109400266

Epoch: 6| Step: 4
Training loss: 1.751192569732666
Validation loss: 2.0803226911893455

Epoch: 6| Step: 5
Training loss: 2.030379295349121
Validation loss: 2.07630084406945

Epoch: 6| Step: 6
Training loss: 2.2236671447753906
Validation loss: 2.0881564027519635

Epoch: 6| Step: 7
Training loss: 2.190781593322754
Validation loss: 2.0694558517907256

Epoch: 6| Step: 8
Training loss: 2.288846492767334
Validation loss: 2.0771209424541843

Epoch: 6| Step: 9
Training loss: 2.6083598136901855
Validation loss: 2.0519574431962866

Epoch: 6| Step: 10
Training loss: 2.2286338806152344
Validation loss: 2.0528470521332114

Epoch: 6| Step: 11
Training loss: 2.9048774242401123
Validation loss: 2.0594125922008226

Epoch: 6| Step: 12
Training loss: 1.8254170417785645
Validation loss: 2.053421030762375

Epoch: 6| Step: 13
Training loss: 1.9498850107192993
Validation loss: 2.0567418606050554

Epoch: 347| Step: 0
Training loss: 2.5081686973571777
Validation loss: 2.0646836655114287

Epoch: 6| Step: 1
Training loss: 2.110823154449463
Validation loss: 2.0664284677915674

Epoch: 6| Step: 2
Training loss: 1.675788164138794
Validation loss: 2.062367880216209

Epoch: 6| Step: 3
Training loss: 2.3523430824279785
Validation loss: 2.068745154206471

Epoch: 6| Step: 4
Training loss: 2.8217530250549316
Validation loss: 2.0637880525281354

Epoch: 6| Step: 5
Training loss: 2.2360715866088867
Validation loss: 2.060975838732976

Epoch: 6| Step: 6
Training loss: 2.1723434925079346
Validation loss: 2.0642645679494387

Epoch: 6| Step: 7
Training loss: 1.8213887214660645
Validation loss: 2.061859115477531

Epoch: 6| Step: 8
Training loss: 2.232895612716675
Validation loss: 2.062380879156051

Epoch: 6| Step: 9
Training loss: 2.078409194946289
Validation loss: 2.0615800772943804

Epoch: 6| Step: 10
Training loss: 1.3969552516937256
Validation loss: 2.0771419014981998

Epoch: 6| Step: 11
Training loss: 2.8267970085144043
Validation loss: 2.0762894256140596

Epoch: 6| Step: 12
Training loss: 1.85372793674469
Validation loss: 2.069737611278411

Epoch: 6| Step: 13
Training loss: 2.247399091720581
Validation loss: 2.0786861629896265

Epoch: 348| Step: 0
Training loss: 2.700068950653076
Validation loss: 2.0730702595044206

Epoch: 6| Step: 1
Training loss: 1.7394410371780396
Validation loss: 2.06865220813341

Epoch: 6| Step: 2
Training loss: 2.0627493858337402
Validation loss: 2.059836502998106

Epoch: 6| Step: 3
Training loss: 2.9778835773468018
Validation loss: 2.070990063810861

Epoch: 6| Step: 4
Training loss: 2.199800491333008
Validation loss: 2.0661062386728104

Epoch: 6| Step: 5
Training loss: 2.4708263874053955
Validation loss: 2.0560036269567346

Epoch: 6| Step: 6
Training loss: 2.1377596855163574
Validation loss: 2.064225007128972

Epoch: 6| Step: 7
Training loss: 2.565216302871704
Validation loss: 2.0624046120592343

Epoch: 6| Step: 8
Training loss: 1.336342215538025
Validation loss: 2.0626102762837566

Epoch: 6| Step: 9
Training loss: 2.1572837829589844
Validation loss: 2.0703537617960284

Epoch: 6| Step: 10
Training loss: 1.7890857458114624
Validation loss: 2.0672131353808987

Epoch: 6| Step: 11
Training loss: 1.821528434753418
Validation loss: 2.0802194482536724

Epoch: 6| Step: 12
Training loss: 2.040938377380371
Validation loss: 2.09810991953778

Epoch: 6| Step: 13
Training loss: 2.2433993816375732
Validation loss: 2.1146483921235606

Epoch: 349| Step: 0
Training loss: 2.3491947650909424
Validation loss: 2.1010090343413816

Epoch: 6| Step: 1
Training loss: 1.9252667427062988
Validation loss: 2.0853396359310357

Epoch: 6| Step: 2
Training loss: 2.157176971435547
Validation loss: 2.076260515438613

Epoch: 6| Step: 3
Training loss: 2.9560770988464355
Validation loss: 2.093244227029944

Epoch: 6| Step: 4
Training loss: 1.9288570880889893
Validation loss: 2.078630106423491

Epoch: 6| Step: 5
Training loss: 2.211289644241333
Validation loss: 2.0762720697669574

Epoch: 6| Step: 6
Training loss: 2.074460983276367
Validation loss: 2.0855607935177383

Epoch: 6| Step: 7
Training loss: 2.2648301124572754
Validation loss: 2.0905933610854612

Epoch: 6| Step: 8
Training loss: 2.411376953125
Validation loss: 2.0876878551257554

Epoch: 6| Step: 9
Training loss: 1.9437199831008911
Validation loss: 2.068527965135472

Epoch: 6| Step: 10
Training loss: 1.242118000984192
Validation loss: 2.0753597264648764

Epoch: 6| Step: 11
Training loss: 2.6885297298431396
Validation loss: 2.0708623457980413

Epoch: 6| Step: 12
Training loss: 2.2017853260040283
Validation loss: 2.0888300403471916

Epoch: 6| Step: 13
Training loss: 1.79322350025177
Validation loss: 2.1084376355653167

Epoch: 350| Step: 0
Training loss: 2.731536865234375
Validation loss: 2.0991092522939048

Epoch: 6| Step: 1
Training loss: 1.4369404315948486
Validation loss: 2.074480405417822

Epoch: 6| Step: 2
Training loss: 2.337674617767334
Validation loss: 2.0601709017189602

Epoch: 6| Step: 3
Training loss: 3.064911365509033
Validation loss: 2.065496201156288

Epoch: 6| Step: 4
Training loss: 2.032349109649658
Validation loss: 2.053936286639142

Epoch: 6| Step: 5
Training loss: 1.6628844738006592
Validation loss: 2.0536202435852378

Epoch: 6| Step: 6
Training loss: 1.9572583436965942
Validation loss: 2.054282634488998

Epoch: 6| Step: 7
Training loss: 2.3416411876678467
Validation loss: 2.0501796289156844

Epoch: 6| Step: 8
Training loss: 2.4564638137817383
Validation loss: 2.0558313900424587

Epoch: 6| Step: 9
Training loss: 1.5499590635299683
Validation loss: 2.0581204045203423

Epoch: 6| Step: 10
Training loss: 1.726351022720337
Validation loss: 2.063707602921353

Epoch: 6| Step: 11
Training loss: 2.240060329437256
Validation loss: 2.0526092411369405

Epoch: 6| Step: 12
Training loss: 2.523074150085449
Validation loss: 2.0503499674540695

Epoch: 6| Step: 13
Training loss: 1.9063506126403809
Validation loss: 2.058904060753443

Epoch: 351| Step: 0
Training loss: 1.3551857471466064
Validation loss: 2.0547251368081696

Epoch: 6| Step: 1
Training loss: 1.9236414432525635
Validation loss: 2.0582324176706295

Epoch: 6| Step: 2
Training loss: 1.0938373804092407
Validation loss: 2.059261482249024

Epoch: 6| Step: 3
Training loss: 2.0621719360351562
Validation loss: 2.071208401392865

Epoch: 6| Step: 4
Training loss: 1.808998942375183
Validation loss: 2.0693638786192863

Epoch: 6| Step: 5
Training loss: 2.930697441101074
Validation loss: 2.067577838897705

Epoch: 6| Step: 6
Training loss: 1.9086880683898926
Validation loss: 2.0739586814757316

Epoch: 6| Step: 7
Training loss: 2.259153366088867
Validation loss: 2.0702601222581762

Epoch: 6| Step: 8
Training loss: 2.0725343227386475
Validation loss: 2.0779117743174234

Epoch: 6| Step: 9
Training loss: 2.690546989440918
Validation loss: 2.0744988328667096

Epoch: 6| Step: 10
Training loss: 2.7435107231140137
Validation loss: 2.0727586694943008

Epoch: 6| Step: 11
Training loss: 2.57016658782959
Validation loss: 2.069734109345303

Epoch: 6| Step: 12
Training loss: 2.634037733078003
Validation loss: 2.084497591500641

Epoch: 6| Step: 13
Training loss: 1.8086405992507935
Validation loss: 2.0790397685061217

Epoch: 352| Step: 0
Training loss: 2.7373650074005127
Validation loss: 2.0732417644992953

Epoch: 6| Step: 1
Training loss: 1.6705513000488281
Validation loss: 2.0850778061856508

Epoch: 6| Step: 2
Training loss: 1.100479245185852
Validation loss: 2.083723561738127

Epoch: 6| Step: 3
Training loss: 2.1547160148620605
Validation loss: 2.0764495608627156

Epoch: 6| Step: 4
Training loss: 2.028686761856079
Validation loss: 2.071005335418127

Epoch: 6| Step: 5
Training loss: 2.077122688293457
Validation loss: 2.0776793726028933

Epoch: 6| Step: 6
Training loss: 1.9511849880218506
Validation loss: 2.0584943089433896

Epoch: 6| Step: 7
Training loss: 2.082895517349243
Validation loss: 2.060275972530406

Epoch: 6| Step: 8
Training loss: 2.62198805809021
Validation loss: 2.059719120302508

Epoch: 6| Step: 9
Training loss: 2.4021387100219727
Validation loss: 2.0688338177178496

Epoch: 6| Step: 10
Training loss: 2.265383243560791
Validation loss: 2.061064621453644

Epoch: 6| Step: 11
Training loss: 2.4656710624694824
Validation loss: 2.068143046030434

Epoch: 6| Step: 12
Training loss: 2.4027650356292725
Validation loss: 2.076175623042609

Epoch: 6| Step: 13
Training loss: 1.7462164163589478
Validation loss: 2.056972570316766

Epoch: 353| Step: 0
Training loss: 1.9668500423431396
Validation loss: 2.059260678547685

Epoch: 6| Step: 1
Training loss: 2.200990676879883
Validation loss: 2.0510336288841824

Epoch: 6| Step: 2
Training loss: 1.8558597564697266
Validation loss: 2.0548017999177337

Epoch: 6| Step: 3
Training loss: 2.1652636528015137
Validation loss: 2.0730667755167973

Epoch: 6| Step: 4
Training loss: 2.0229194164276123
Validation loss: 2.069995580180999

Epoch: 6| Step: 5
Training loss: 2.103734016418457
Validation loss: 2.085336723635274

Epoch: 6| Step: 6
Training loss: 2.1164984703063965
Validation loss: 2.087443346618324

Epoch: 6| Step: 7
Training loss: 2.32143235206604
Validation loss: 2.0977555577472975

Epoch: 6| Step: 8
Training loss: 1.8528954982757568
Validation loss: 2.059680493929053

Epoch: 6| Step: 9
Training loss: 2.3738913536071777
Validation loss: 2.0542567622277046

Epoch: 6| Step: 10
Training loss: 1.926971673965454
Validation loss: 2.048775734439973

Epoch: 6| Step: 11
Training loss: 2.2055742740631104
Validation loss: 2.0579569698661886

Epoch: 6| Step: 12
Training loss: 2.7781903743743896
Validation loss: 2.0588058092260875

Epoch: 6| Step: 13
Training loss: 2.02333402633667
Validation loss: 2.0552929678270893

Epoch: 354| Step: 0
Training loss: 2.0270919799804688
Validation loss: 2.068559285133116

Epoch: 6| Step: 1
Training loss: 1.9584953784942627
Validation loss: 2.0656409853248188

Epoch: 6| Step: 2
Training loss: 2.049774169921875
Validation loss: 2.059285686862084

Epoch: 6| Step: 3
Training loss: 1.2372462749481201
Validation loss: 2.0635099821193243

Epoch: 6| Step: 4
Training loss: 3.434999942779541
Validation loss: 2.0559068982319166

Epoch: 6| Step: 5
Training loss: 1.9795513153076172
Validation loss: 2.0549301178224626

Epoch: 6| Step: 6
Training loss: 2.040114641189575
Validation loss: 2.0580934991118727

Epoch: 6| Step: 7
Training loss: 2.5216639041900635
Validation loss: 2.0462162981751146

Epoch: 6| Step: 8
Training loss: 2.023146390914917
Validation loss: 2.0542426596405687

Epoch: 6| Step: 9
Training loss: 2.437001943588257
Validation loss: 2.067997024905297

Epoch: 6| Step: 10
Training loss: 2.2512035369873047
Validation loss: 2.071193789923063

Epoch: 6| Step: 11
Training loss: 1.4865986108779907
Validation loss: 2.097158593516196

Epoch: 6| Step: 12
Training loss: 2.261898994445801
Validation loss: 2.0984909983091455

Epoch: 6| Step: 13
Training loss: 2.33164119720459
Validation loss: 2.103335037026354

Epoch: 355| Step: 0
Training loss: 2.5633175373077393
Validation loss: 2.0992236944936935

Epoch: 6| Step: 1
Training loss: 2.706117868423462
Validation loss: 2.094516586231929

Epoch: 6| Step: 2
Training loss: 1.6326375007629395
Validation loss: 2.0937749724234305

Epoch: 6| Step: 3
Training loss: 2.2115700244903564
Validation loss: 2.098602462840337

Epoch: 6| Step: 4
Training loss: 2.408510208129883
Validation loss: 2.07661541943909

Epoch: 6| Step: 5
Training loss: 2.076615333557129
Validation loss: 2.076701069390902

Epoch: 6| Step: 6
Training loss: 1.9847850799560547
Validation loss: 2.0679552580720637

Epoch: 6| Step: 7
Training loss: 1.621788501739502
Validation loss: 2.0583216785102763

Epoch: 6| Step: 8
Training loss: 2.287914991378784
Validation loss: 2.0663537338215816

Epoch: 6| Step: 9
Training loss: 1.804941177368164
Validation loss: 2.0640294462121944

Epoch: 6| Step: 10
Training loss: 1.8967068195343018
Validation loss: 2.0598277917472263

Epoch: 6| Step: 11
Training loss: 2.130197525024414
Validation loss: 2.074684735267393

Epoch: 6| Step: 12
Training loss: 2.35819411277771
Validation loss: 2.0681694374289563

Epoch: 6| Step: 13
Training loss: 2.2563982009887695
Validation loss: 2.071343735982013

Epoch: 356| Step: 0
Training loss: 2.1832196712493896
Validation loss: 2.0800171923893753

Epoch: 6| Step: 1
Training loss: 2.1182899475097656
Validation loss: 2.078727747804375

Epoch: 6| Step: 2
Training loss: 2.2494888305664062
Validation loss: 2.067857949964462

Epoch: 6| Step: 3
Training loss: 1.8895593881607056
Validation loss: 2.092220962688487

Epoch: 6| Step: 4
Training loss: 2.439967155456543
Validation loss: 2.077007791047455

Epoch: 6| Step: 5
Training loss: 2.4415974617004395
Validation loss: 2.0735093470542663

Epoch: 6| Step: 6
Training loss: 2.490358829498291
Validation loss: 2.097555511741228

Epoch: 6| Step: 7
Training loss: 1.9907993078231812
Validation loss: 2.1109604040781655

Epoch: 6| Step: 8
Training loss: 2.289966106414795
Validation loss: 2.097228885978781

Epoch: 6| Step: 9
Training loss: 2.1022114753723145
Validation loss: 2.086587808465445

Epoch: 6| Step: 10
Training loss: 1.922600269317627
Validation loss: 2.100677497925297

Epoch: 6| Step: 11
Training loss: 1.829902172088623
Validation loss: 2.0916125543655886

Epoch: 6| Step: 12
Training loss: 1.8923423290252686
Validation loss: 2.093027046931687

Epoch: 6| Step: 13
Training loss: 2.0178678035736084
Validation loss: 2.1228237164917814

Epoch: 357| Step: 0
Training loss: 1.4986541271209717
Validation loss: 2.1370666642342844

Epoch: 6| Step: 1
Training loss: 2.4117846488952637
Validation loss: 2.1309381172221196

Epoch: 6| Step: 2
Training loss: 2.723780632019043
Validation loss: 2.1210799499224593

Epoch: 6| Step: 3
Training loss: 2.181227684020996
Validation loss: 2.106788727544969

Epoch: 6| Step: 4
Training loss: 2.105638027191162
Validation loss: 2.095643171700098

Epoch: 6| Step: 5
Training loss: 3.12239670753479
Validation loss: 2.078536448940154

Epoch: 6| Step: 6
Training loss: 1.9879978895187378
Validation loss: 2.0709628469200543

Epoch: 6| Step: 7
Training loss: 1.615082025527954
Validation loss: 2.0584828802334365

Epoch: 6| Step: 8
Training loss: 2.111560821533203
Validation loss: 2.062027060857383

Epoch: 6| Step: 9
Training loss: 2.566695213317871
Validation loss: 2.0507822075197772

Epoch: 6| Step: 10
Training loss: 1.8097476959228516
Validation loss: 2.045745162553685

Epoch: 6| Step: 11
Training loss: 1.8452943563461304
Validation loss: 2.043745053711758

Epoch: 6| Step: 12
Training loss: 1.785144329071045
Validation loss: 2.0554577176288893

Epoch: 6| Step: 13
Training loss: 2.298713207244873
Validation loss: 2.0430688601668163

Epoch: 358| Step: 0
Training loss: 2.757301092147827
Validation loss: 2.05269746242031

Epoch: 6| Step: 1
Training loss: 1.8409957885742188
Validation loss: 2.0584837121348225

Epoch: 6| Step: 2
Training loss: 2.03254771232605
Validation loss: 2.073843107428602

Epoch: 6| Step: 3
Training loss: 1.6898529529571533
Validation loss: 2.085963185115527

Epoch: 6| Step: 4
Training loss: 2.3868489265441895
Validation loss: 2.1076115946615896

Epoch: 6| Step: 5
Training loss: 2.050950050354004
Validation loss: 2.1151762495758715

Epoch: 6| Step: 6
Training loss: 1.9231655597686768
Validation loss: 2.1006687456561672

Epoch: 6| Step: 7
Training loss: 2.2795701026916504
Validation loss: 2.0919895300301175

Epoch: 6| Step: 8
Training loss: 2.445340633392334
Validation loss: 2.0600337187449136

Epoch: 6| Step: 9
Training loss: 2.2053422927856445
Validation loss: 2.057001062618789

Epoch: 6| Step: 10
Training loss: 1.6613590717315674
Validation loss: 2.0502380324948217

Epoch: 6| Step: 11
Training loss: 2.4477508068084717
Validation loss: 2.0427980679337696

Epoch: 6| Step: 12
Training loss: 1.7738996744155884
Validation loss: 2.035834591875794

Epoch: 6| Step: 13
Training loss: 2.3270373344421387
Validation loss: 2.0425074715768137

Epoch: 359| Step: 0
Training loss: 1.8574570417404175
Validation loss: 2.0549580179234987

Epoch: 6| Step: 1
Training loss: 2.2375316619873047
Validation loss: 2.0540661504191737

Epoch: 6| Step: 2
Training loss: 1.2327048778533936
Validation loss: 2.060938665943761

Epoch: 6| Step: 3
Training loss: 1.7522509098052979
Validation loss: 2.062460319970244

Epoch: 6| Step: 4
Training loss: 2.1772942543029785
Validation loss: 2.060827221921695

Epoch: 6| Step: 5
Training loss: 1.5704787969589233
Validation loss: 2.070046071083315

Epoch: 6| Step: 6
Training loss: 2.679863452911377
Validation loss: 2.0919181531475437

Epoch: 6| Step: 7
Training loss: 2.4760961532592773
Validation loss: 2.085357312233217

Epoch: 6| Step: 8
Training loss: 2.6386513710021973
Validation loss: 2.092970791683402

Epoch: 6| Step: 9
Training loss: 2.668710947036743
Validation loss: 2.099204622289186

Epoch: 6| Step: 10
Training loss: 2.391753673553467
Validation loss: 2.0905569471338743

Epoch: 6| Step: 11
Training loss: 2.1593127250671387
Validation loss: 2.1046959533486316

Epoch: 6| Step: 12
Training loss: 1.7622325420379639
Validation loss: 2.0963078262985393

Epoch: 6| Step: 13
Training loss: 2.456833839416504
Validation loss: 2.07958984375

Epoch: 360| Step: 0
Training loss: 2.013941764831543
Validation loss: 2.0792516226409585

Epoch: 6| Step: 1
Training loss: 1.8388571739196777
Validation loss: 2.06761069707973

Epoch: 6| Step: 2
Training loss: 2.4873404502868652
Validation loss: 2.087974307357624

Epoch: 6| Step: 3
Training loss: 3.1305999755859375
Validation loss: 2.061792545421149

Epoch: 6| Step: 4
Training loss: 1.8102096319198608
Validation loss: 2.0653702161645375

Epoch: 6| Step: 5
Training loss: 2.6062092781066895
Validation loss: 2.0653784082781885

Epoch: 6| Step: 6
Training loss: 1.7801034450531006
Validation loss: 2.075187039631669

Epoch: 6| Step: 7
Training loss: 1.5778188705444336
Validation loss: 2.072322840331703

Epoch: 6| Step: 8
Training loss: 2.102288246154785
Validation loss: 2.0523480112834642

Epoch: 6| Step: 9
Training loss: 2.463460922241211
Validation loss: 2.0677178495673725

Epoch: 6| Step: 10
Training loss: 2.513376235961914
Validation loss: 2.0719777243111723

Epoch: 6| Step: 11
Training loss: 1.713151216506958
Validation loss: 2.073300343687816

Epoch: 6| Step: 12
Training loss: 1.8282948732376099
Validation loss: 2.087851929408248

Epoch: 6| Step: 13
Training loss: 1.6952974796295166
Validation loss: 2.093416570335306

Epoch: 361| Step: 0
Training loss: 1.7296741008758545
Validation loss: 2.112367637695805

Epoch: 6| Step: 1
Training loss: 2.059549570083618
Validation loss: 2.1227935462869625

Epoch: 6| Step: 2
Training loss: 2.084993362426758
Validation loss: 2.1018899512547318

Epoch: 6| Step: 3
Training loss: 1.751326560974121
Validation loss: 2.1171629813409623

Epoch: 6| Step: 4
Training loss: 2.3454785346984863
Validation loss: 2.1042076990168583

Epoch: 6| Step: 5
Training loss: 1.981981635093689
Validation loss: 2.0738353908702893

Epoch: 6| Step: 6
Training loss: 2.5238592624664307
Validation loss: 2.098037124961935

Epoch: 6| Step: 7
Training loss: 2.3095295429229736
Validation loss: 2.071947561797275

Epoch: 6| Step: 8
Training loss: 3.034745931625366
Validation loss: 2.0609755234051774

Epoch: 6| Step: 9
Training loss: 1.9405251741409302
Validation loss: 2.0623744662090013

Epoch: 6| Step: 10
Training loss: 2.2484073638916016
Validation loss: 2.066738272225985

Epoch: 6| Step: 11
Training loss: 1.4579708576202393
Validation loss: 2.060504774893484

Epoch: 6| Step: 12
Training loss: 2.109941005706787
Validation loss: 2.0561936696370444

Epoch: 6| Step: 13
Training loss: 2.2419652938842773
Validation loss: 2.0515752364230413

Epoch: 362| Step: 0
Training loss: 1.3968666791915894
Validation loss: 2.0624900466652325

Epoch: 6| Step: 1
Training loss: 1.5435545444488525
Validation loss: 2.0644226407492035

Epoch: 6| Step: 2
Training loss: 2.409775972366333
Validation loss: 2.06257301504894

Epoch: 6| Step: 3
Training loss: 0.6685665845870972
Validation loss: 2.053502631443803

Epoch: 6| Step: 4
Training loss: 2.4700088500976562
Validation loss: 2.0515782910008586

Epoch: 6| Step: 5
Training loss: 2.5880486965179443
Validation loss: 2.0643469056775494

Epoch: 6| Step: 6
Training loss: 3.187318801879883
Validation loss: 2.0563009041611866

Epoch: 6| Step: 7
Training loss: 2.149071455001831
Validation loss: 2.0577028028426634

Epoch: 6| Step: 8
Training loss: 2.1652884483337402
Validation loss: 2.056226340673303

Epoch: 6| Step: 9
Training loss: 2.0862932205200195
Validation loss: 2.0569564680899344

Epoch: 6| Step: 10
Training loss: 2.3116164207458496
Validation loss: 2.0594246131117626

Epoch: 6| Step: 11
Training loss: 1.8516154289245605
Validation loss: 2.0663103711220527

Epoch: 6| Step: 12
Training loss: 2.5149998664855957
Validation loss: 2.0660838260445544

Epoch: 6| Step: 13
Training loss: 2.3094468116760254
Validation loss: 2.0566970404758247

Epoch: 363| Step: 0
Training loss: 2.03627347946167
Validation loss: 2.060570172084275

Epoch: 6| Step: 1
Training loss: 1.4500577449798584
Validation loss: 2.0649283419373217

Epoch: 6| Step: 2
Training loss: 2.7192516326904297
Validation loss: 2.0692747395525695

Epoch: 6| Step: 3
Training loss: 1.76797616481781
Validation loss: 2.0881049248480026

Epoch: 6| Step: 4
Training loss: 2.8105688095092773
Validation loss: 2.0972508256153395

Epoch: 6| Step: 5
Training loss: 1.8604822158813477
Validation loss: 2.097317857127036

Epoch: 6| Step: 6
Training loss: 2.0607590675354004
Validation loss: 2.109476791915073

Epoch: 6| Step: 7
Training loss: 2.3903212547302246
Validation loss: 2.1104853050683134

Epoch: 6| Step: 8
Training loss: 2.399726390838623
Validation loss: 2.1139697400472497

Epoch: 6| Step: 9
Training loss: 2.666884183883667
Validation loss: 2.0908861532006213

Epoch: 6| Step: 10
Training loss: 2.238626480102539
Validation loss: 2.0867088071761595

Epoch: 6| Step: 11
Training loss: 1.6411001682281494
Validation loss: 2.081029227984849

Epoch: 6| Step: 12
Training loss: 1.6644145250320435
Validation loss: 2.0583532625629055

Epoch: 6| Step: 13
Training loss: 1.8424440622329712
Validation loss: 2.0607143307244904

Epoch: 364| Step: 0
Training loss: 2.1048951148986816
Validation loss: 2.05822927464721

Epoch: 6| Step: 1
Training loss: 1.662158727645874
Validation loss: 2.0613603976465042

Epoch: 6| Step: 2
Training loss: 2.3908753395080566
Validation loss: 2.071320056915283

Epoch: 6| Step: 3
Training loss: 2.334359884262085
Validation loss: 2.079418379773376

Epoch: 6| Step: 4
Training loss: 1.8738337755203247
Validation loss: 2.0926081083154164

Epoch: 6| Step: 5
Training loss: 2.3077917098999023
Validation loss: 2.0954663035690144

Epoch: 6| Step: 6
Training loss: 1.824154019355774
Validation loss: 2.0843197889225458

Epoch: 6| Step: 7
Training loss: 2.30142879486084
Validation loss: 2.0706951566921767

Epoch: 6| Step: 8
Training loss: 2.075267791748047
Validation loss: 2.085122195623254

Epoch: 6| Step: 9
Training loss: 1.910609483718872
Validation loss: 2.0591445917724283

Epoch: 6| Step: 10
Training loss: 1.7306840419769287
Validation loss: 2.076856033776396

Epoch: 6| Step: 11
Training loss: 2.86091947555542
Validation loss: 2.0794173863626297

Epoch: 6| Step: 12
Training loss: 2.225804090499878
Validation loss: 2.0541754999468402

Epoch: 6| Step: 13
Training loss: 1.8203186988830566
Validation loss: 2.071843921497304

Epoch: 365| Step: 0
Training loss: 2.253439426422119
Validation loss: 2.0554467247378443

Epoch: 6| Step: 1
Training loss: 2.5517311096191406
Validation loss: 2.0571080676970945

Epoch: 6| Step: 2
Training loss: 1.4829100370407104
Validation loss: 2.080652115165546

Epoch: 6| Step: 3
Training loss: 2.5622689723968506
Validation loss: 2.071597486413935

Epoch: 6| Step: 4
Training loss: 1.9500584602355957
Validation loss: 2.057649564999406

Epoch: 6| Step: 5
Training loss: 2.242474317550659
Validation loss: 2.082570170843473

Epoch: 6| Step: 6
Training loss: 2.2815701961517334
Validation loss: 2.0726897639612996

Epoch: 6| Step: 7
Training loss: 2.1683757305145264
Validation loss: 2.0745636596474597

Epoch: 6| Step: 8
Training loss: 2.0816640853881836
Validation loss: 2.066548089827261

Epoch: 6| Step: 9
Training loss: 1.7471997737884521
Validation loss: 2.065296329477782

Epoch: 6| Step: 10
Training loss: 1.6217856407165527
Validation loss: 2.0451712736519436

Epoch: 6| Step: 11
Training loss: 2.0465164184570312
Validation loss: 2.0524118869535384

Epoch: 6| Step: 12
Training loss: 2.2034478187561035
Validation loss: 2.047040024111348

Epoch: 6| Step: 13
Training loss: 2.3844199180603027
Validation loss: 2.040529929181581

Epoch: 366| Step: 0
Training loss: 1.845829725265503
Validation loss: 2.0466179873353694

Epoch: 6| Step: 1
Training loss: 1.7999930381774902
Validation loss: 2.048517886028495

Epoch: 6| Step: 2
Training loss: 2.081075668334961
Validation loss: 2.038057234979445

Epoch: 6| Step: 3
Training loss: 2.03537917137146
Validation loss: 2.04810090731549

Epoch: 6| Step: 4
Training loss: 2.030712127685547
Validation loss: 2.044927866228165

Epoch: 6| Step: 5
Training loss: 1.477175235748291
Validation loss: 2.048307740560142

Epoch: 6| Step: 6
Training loss: 3.090823173522949
Validation loss: 2.0583395111945366

Epoch: 6| Step: 7
Training loss: 1.6032856702804565
Validation loss: 2.067810804613175

Epoch: 6| Step: 8
Training loss: 2.179816722869873
Validation loss: 2.0818600462329004

Epoch: 6| Step: 9
Training loss: 2.561765670776367
Validation loss: 2.0735508908507643

Epoch: 6| Step: 10
Training loss: 2.128124237060547
Validation loss: 2.067408915488951

Epoch: 6| Step: 11
Training loss: 2.544440984725952
Validation loss: 2.0593416921554075

Epoch: 6| Step: 12
Training loss: 2.267293691635132
Validation loss: 2.059433211562454

Epoch: 6| Step: 13
Training loss: 1.59367036819458
Validation loss: 2.035043761294375

Epoch: 367| Step: 0
Training loss: 2.643678903579712
Validation loss: 2.0447138355624292

Epoch: 6| Step: 1
Training loss: 1.9365671873092651
Validation loss: 2.0471335854581607

Epoch: 6| Step: 2
Training loss: 2.974264144897461
Validation loss: 2.0479581150957333

Epoch: 6| Step: 3
Training loss: 2.546142578125
Validation loss: 2.0486325448559177

Epoch: 6| Step: 4
Training loss: 1.356680154800415
Validation loss: 2.050970805588589

Epoch: 6| Step: 5
Training loss: 1.7977880239486694
Validation loss: 2.0264395565114994

Epoch: 6| Step: 6
Training loss: 2.251467704772949
Validation loss: 2.0375017363538026

Epoch: 6| Step: 7
Training loss: 1.6133098602294922
Validation loss: 2.0384521586920625

Epoch: 6| Step: 8
Training loss: 2.26627254486084
Validation loss: 2.028796640775537

Epoch: 6| Step: 9
Training loss: 1.5038580894470215
Validation loss: 2.035660734740637

Epoch: 6| Step: 10
Training loss: 1.5541183948516846
Validation loss: 2.0486604347023913

Epoch: 6| Step: 11
Training loss: 2.2969582080841064
Validation loss: 2.050080804414647

Epoch: 6| Step: 12
Training loss: 2.483842372894287
Validation loss: 2.067033972791446

Epoch: 6| Step: 13
Training loss: 2.2285642623901367
Validation loss: 2.053669697494917

Epoch: 368| Step: 0
Training loss: 2.389676570892334
Validation loss: 2.0579144980317805

Epoch: 6| Step: 1
Training loss: 2.031639575958252
Validation loss: 2.0692905854153376

Epoch: 6| Step: 2
Training loss: 2.194031238555908
Validation loss: 2.061498116421443

Epoch: 6| Step: 3
Training loss: 2.312751054763794
Validation loss: 2.0597329626801195

Epoch: 6| Step: 4
Training loss: 1.9422531127929688
Validation loss: 2.054751019324026

Epoch: 6| Step: 5
Training loss: 2.0468153953552246
Validation loss: 2.0498983513924385

Epoch: 6| Step: 6
Training loss: 1.9650307893753052
Validation loss: 2.0467296749032955

Epoch: 6| Step: 7
Training loss: 2.2057929039001465
Validation loss: 2.05162218821946

Epoch: 6| Step: 8
Training loss: 2.0351662635803223
Validation loss: 2.044116202221122

Epoch: 6| Step: 9
Training loss: 1.3418986797332764
Validation loss: 2.04413842257633

Epoch: 6| Step: 10
Training loss: 2.481179714202881
Validation loss: 2.035685381581706

Epoch: 6| Step: 11
Training loss: 1.9889230728149414
Validation loss: 2.051137367884318

Epoch: 6| Step: 12
Training loss: 2.552177667617798
Validation loss: 2.051749998523343

Epoch: 6| Step: 13
Training loss: 1.709972620010376
Validation loss: 2.043331038567328

Epoch: 369| Step: 0
Training loss: 1.7543891668319702
Validation loss: 2.0578455117440995

Epoch: 6| Step: 1
Training loss: 2.2227864265441895
Validation loss: 2.0456683763893704

Epoch: 6| Step: 2
Training loss: 1.5785558223724365
Validation loss: 2.048638456611223

Epoch: 6| Step: 3
Training loss: 2.486377239227295
Validation loss: 2.062950354750438

Epoch: 6| Step: 4
Training loss: 2.467881202697754
Validation loss: 2.0384771823883057

Epoch: 6| Step: 5
Training loss: 2.191298723220825
Validation loss: 2.0344867244843514

Epoch: 6| Step: 6
Training loss: 1.896470069885254
Validation loss: 2.028380791346232

Epoch: 6| Step: 7
Training loss: 2.682316541671753
Validation loss: 2.038117334406863

Epoch: 6| Step: 8
Training loss: 1.7110235691070557
Validation loss: 2.035793762053213

Epoch: 6| Step: 9
Training loss: 1.924120306968689
Validation loss: 2.0402511960716656

Epoch: 6| Step: 10
Training loss: 1.7565745115280151
Validation loss: 2.0388009984006166

Epoch: 6| Step: 11
Training loss: 1.596055507659912
Validation loss: 2.0567149885239138

Epoch: 6| Step: 12
Training loss: 2.5570154190063477
Validation loss: 2.0649282855372273

Epoch: 6| Step: 13
Training loss: 2.512498617172241
Validation loss: 2.068472486670299

Epoch: 370| Step: 0
Training loss: 2.0954859256744385
Validation loss: 2.06017872851382

Epoch: 6| Step: 1
Training loss: 1.661293625831604
Validation loss: 2.038665376683717

Epoch: 6| Step: 2
Training loss: 2.0918145179748535
Validation loss: 2.0519410666599067

Epoch: 6| Step: 3
Training loss: 2.0355753898620605
Validation loss: 2.059774442385602

Epoch: 6| Step: 4
Training loss: 2.056811809539795
Validation loss: 2.067862496581129

Epoch: 6| Step: 5
Training loss: 1.9730713367462158
Validation loss: 2.064923035201206

Epoch: 6| Step: 6
Training loss: 2.1201367378234863
Validation loss: 2.0835760460104993

Epoch: 6| Step: 7
Training loss: 1.937766432762146
Validation loss: 2.088187566367529

Epoch: 6| Step: 8
Training loss: 2.2007689476013184
Validation loss: 2.1152108856426772

Epoch: 6| Step: 9
Training loss: 2.180332660675049
Validation loss: 2.1084215025747977

Epoch: 6| Step: 10
Training loss: 2.2680299282073975
Validation loss: 2.112482555450932

Epoch: 6| Step: 11
Training loss: 2.2896907329559326
Validation loss: 2.086454645279915

Epoch: 6| Step: 12
Training loss: 2.016751289367676
Validation loss: 2.0845742917829946

Epoch: 6| Step: 13
Training loss: 2.782348871231079
Validation loss: 2.0572421525114324

Epoch: 371| Step: 0
Training loss: 1.9947799444198608
Validation loss: 2.055299174401068

Epoch: 6| Step: 1
Training loss: 2.1653990745544434
Validation loss: 2.0406204833779285

Epoch: 6| Step: 2
Training loss: 2.569004774093628
Validation loss: 2.053818307897096

Epoch: 6| Step: 3
Training loss: 2.0526623725891113
Validation loss: 2.050096499022617

Epoch: 6| Step: 4
Training loss: 1.4196374416351318
Validation loss: 2.057733110202256

Epoch: 6| Step: 5
Training loss: 1.6866590976715088
Validation loss: 2.030012874193089

Epoch: 6| Step: 6
Training loss: 2.571287155151367
Validation loss: 2.013603183530992

Epoch: 6| Step: 7
Training loss: 2.0639216899871826
Validation loss: 2.017180158245948

Epoch: 6| Step: 8
Training loss: 1.2669811248779297
Validation loss: 2.020484019351262

Epoch: 6| Step: 9
Training loss: 1.7627441883087158
Validation loss: 2.0490240819992556

Epoch: 6| Step: 10
Training loss: 3.132045269012451
Validation loss: 2.0797439262431157

Epoch: 6| Step: 11
Training loss: 2.4041261672973633
Validation loss: 2.093335142699621

Epoch: 6| Step: 12
Training loss: 2.401191234588623
Validation loss: 2.1154808075197282

Epoch: 6| Step: 13
Training loss: 2.789637565612793
Validation loss: 2.1098662114912465

Epoch: 372| Step: 0
Training loss: 1.9624226093292236
Validation loss: 2.1231585548770044

Epoch: 6| Step: 1
Training loss: 2.071610927581787
Validation loss: 2.175402513114355

Epoch: 6| Step: 2
Training loss: 2.5569138526916504
Validation loss: 2.1602033120329662

Epoch: 6| Step: 3
Training loss: 1.7695715427398682
Validation loss: 2.164228126566897

Epoch: 6| Step: 4
Training loss: 1.7749664783477783
Validation loss: 2.163715584303743

Epoch: 6| Step: 5
Training loss: 1.916771650314331
Validation loss: 2.143516860982423

Epoch: 6| Step: 6
Training loss: 2.420691728591919
Validation loss: 2.1449164472600466

Epoch: 6| Step: 7
Training loss: 2.3867456912994385
Validation loss: 2.1398934036172848

Epoch: 6| Step: 8
Training loss: 2.7492380142211914
Validation loss: 2.1101495399270007

Epoch: 6| Step: 9
Training loss: 2.0124990940093994
Validation loss: 2.1073367313672136

Epoch: 6| Step: 10
Training loss: 1.8456922769546509
Validation loss: 2.100526912238008

Epoch: 6| Step: 11
Training loss: 1.99251389503479
Validation loss: 2.0894822112975584

Epoch: 6| Step: 12
Training loss: 2.9852402210235596
Validation loss: 2.0785085232027116

Epoch: 6| Step: 13
Training loss: 1.5415507555007935
Validation loss: 2.055103471202235

Epoch: 373| Step: 0
Training loss: 2.5383567810058594
Validation loss: 2.064316148399025

Epoch: 6| Step: 1
Training loss: 2.2716753482818604
Validation loss: 2.053760205545733

Epoch: 6| Step: 2
Training loss: 1.9893780946731567
Validation loss: 2.040629316401738

Epoch: 6| Step: 3
Training loss: 2.440495491027832
Validation loss: 2.0439047287869196

Epoch: 6| Step: 4
Training loss: 1.9632238149642944
Validation loss: 2.0396190394637403

Epoch: 6| Step: 5
Training loss: 2.4052577018737793
Validation loss: 2.0280133344793834

Epoch: 6| Step: 6
Training loss: 1.891904354095459
Validation loss: 2.0323351416536557

Epoch: 6| Step: 7
Training loss: 1.9315751791000366
Validation loss: 2.0235260660930345

Epoch: 6| Step: 8
Training loss: 2.2505228519439697
Validation loss: 2.0395361684983775

Epoch: 6| Step: 9
Training loss: 1.9518496990203857
Validation loss: 2.029261983850951

Epoch: 6| Step: 10
Training loss: 2.37107515335083
Validation loss: 2.0542407420373734

Epoch: 6| Step: 11
Training loss: 2.306452512741089
Validation loss: 2.048154938605524

Epoch: 6| Step: 12
Training loss: 1.723141074180603
Validation loss: 2.052027461349323

Epoch: 6| Step: 13
Training loss: 1.1661688089370728
Validation loss: 2.0401721385217484

Epoch: 374| Step: 0
Training loss: 1.7442538738250732
Validation loss: 2.0391684962857153

Epoch: 6| Step: 1
Training loss: 2.4882078170776367
Validation loss: 2.0618334572802306

Epoch: 6| Step: 2
Training loss: 2.400796413421631
Validation loss: 2.057297806585989

Epoch: 6| Step: 3
Training loss: 1.8326448202133179
Validation loss: 2.0439893943007275

Epoch: 6| Step: 4
Training loss: 2.240583896636963
Validation loss: 2.0445243594467

Epoch: 6| Step: 5
Training loss: 1.8257447481155396
Validation loss: 2.031331974972961

Epoch: 6| Step: 6
Training loss: 1.5725228786468506
Validation loss: 2.019948702986522

Epoch: 6| Step: 7
Training loss: 2.164566993713379
Validation loss: 2.0245845715204873

Epoch: 6| Step: 8
Training loss: 2.4580814838409424
Validation loss: 2.0280018621875393

Epoch: 6| Step: 9
Training loss: 1.6733447313308716
Validation loss: 2.029064584803838

Epoch: 6| Step: 10
Training loss: 2.38456392288208
Validation loss: 2.0328936705025296

Epoch: 6| Step: 11
Training loss: 2.0266835689544678
Validation loss: 2.025934286015008

Epoch: 6| Step: 12
Training loss: 2.209054470062256
Validation loss: 2.0351743044391757

Epoch: 6| Step: 13
Training loss: 2.2012434005737305
Validation loss: 2.033848367711549

Epoch: 375| Step: 0
Training loss: 2.000192165374756
Validation loss: 2.032372938689365

Epoch: 6| Step: 1
Training loss: 1.8319975137710571
Validation loss: 2.031013822042814

Epoch: 6| Step: 2
Training loss: 1.7305974960327148
Validation loss: 2.051801114953974

Epoch: 6| Step: 3
Training loss: 1.9979794025421143
Validation loss: 2.066275922201013

Epoch: 6| Step: 4
Training loss: 1.7363128662109375
Validation loss: 2.0502407063720045

Epoch: 6| Step: 5
Training loss: 1.3513559103012085
Validation loss: 2.0361169794554352

Epoch: 6| Step: 6
Training loss: 2.538928985595703
Validation loss: 2.032655692869617

Epoch: 6| Step: 7
Training loss: 2.18780517578125
Validation loss: 2.0361413045596053

Epoch: 6| Step: 8
Training loss: 2.463473320007324
Validation loss: 2.020104177536503

Epoch: 6| Step: 9
Training loss: 2.012248992919922
Validation loss: 2.0198391663130892

Epoch: 6| Step: 10
Training loss: 2.1372718811035156
Validation loss: 2.0298874557659192

Epoch: 6| Step: 11
Training loss: 2.764864921569824
Validation loss: 2.0410835050767466

Epoch: 6| Step: 12
Training loss: 2.0393199920654297
Validation loss: 2.0398460152328655

Epoch: 6| Step: 13
Training loss: 2.24013090133667
Validation loss: 2.020902309366452

Epoch: 376| Step: 0
Training loss: 2.320385694503784
Validation loss: 2.034879812630274

Epoch: 6| Step: 1
Training loss: 2.0043535232543945
Validation loss: 2.0364177906385033

Epoch: 6| Step: 2
Training loss: 1.6994898319244385
Validation loss: 2.0428237492038357

Epoch: 6| Step: 3
Training loss: 2.776022434234619
Validation loss: 2.0353404001523088

Epoch: 6| Step: 4
Training loss: 2.266538143157959
Validation loss: 2.0351403900372085

Epoch: 6| Step: 5
Training loss: 2.0671544075012207
Validation loss: 2.0257400530640797

Epoch: 6| Step: 6
Training loss: 2.203019857406616
Validation loss: 2.030499437803863

Epoch: 6| Step: 7
Training loss: 1.9500187635421753
Validation loss: 2.0475575513737176

Epoch: 6| Step: 8
Training loss: 1.7894749641418457
Validation loss: 2.047111003629623

Epoch: 6| Step: 9
Training loss: 2.5882437229156494
Validation loss: 2.0560532385303127

Epoch: 6| Step: 10
Training loss: 1.7168779373168945
Validation loss: 2.0562384692571496

Epoch: 6| Step: 11
Training loss: 1.5865224599838257
Validation loss: 2.0444331040946384

Epoch: 6| Step: 12
Training loss: 1.5805023908615112
Validation loss: 2.0486758832008607

Epoch: 6| Step: 13
Training loss: 2.78633975982666
Validation loss: 2.0266803221036027

Epoch: 377| Step: 0
Training loss: 2.1298818588256836
Validation loss: 2.0215330713538715

Epoch: 6| Step: 1
Training loss: 2.1017093658447266
Validation loss: 2.0244048333937124

Epoch: 6| Step: 2
Training loss: 2.354360580444336
Validation loss: 2.0204684618980653

Epoch: 6| Step: 3
Training loss: 2.194124698638916
Validation loss: 2.0290854720659155

Epoch: 6| Step: 4
Training loss: 1.8825932741165161
Validation loss: 2.026730397696136

Epoch: 6| Step: 5
Training loss: 1.5054945945739746
Validation loss: 2.034713932262954

Epoch: 6| Step: 6
Training loss: 1.6966016292572021
Validation loss: 2.033692944434381

Epoch: 6| Step: 7
Training loss: 2.2773072719573975
Validation loss: 2.0408874557864283

Epoch: 6| Step: 8
Training loss: 2.165464401245117
Validation loss: 2.055041563126349

Epoch: 6| Step: 9
Training loss: 1.8999550342559814
Validation loss: 2.046483726911647

Epoch: 6| Step: 10
Training loss: 2.0480616092681885
Validation loss: 2.033160359628739

Epoch: 6| Step: 11
Training loss: 2.7229995727539062
Validation loss: 2.0299003021691435

Epoch: 6| Step: 12
Training loss: 1.891526222229004
Validation loss: 2.0379660552547825

Epoch: 6| Step: 13
Training loss: 2.001622438430786
Validation loss: 2.031245614892693

Epoch: 378| Step: 0
Training loss: 2.172498941421509
Validation loss: 2.0183203425458682

Epoch: 6| Step: 1
Training loss: 1.969649076461792
Validation loss: 2.011895369457942

Epoch: 6| Step: 2
Training loss: 2.0929298400878906
Validation loss: 2.0100416124507947

Epoch: 6| Step: 3
Training loss: 1.7782565355300903
Validation loss: 2.007450025568726

Epoch: 6| Step: 4
Training loss: 2.1360228061676025
Validation loss: 2.0071641706651255

Epoch: 6| Step: 5
Training loss: 1.986914873123169
Validation loss: 2.019304392158344

Epoch: 6| Step: 6
Training loss: 1.8330445289611816
Validation loss: 2.0130435266802387

Epoch: 6| Step: 7
Training loss: 2.095341205596924
Validation loss: 2.0171338255687425

Epoch: 6| Step: 8
Training loss: 2.210618019104004
Validation loss: 2.01065150127616

Epoch: 6| Step: 9
Training loss: 2.3660690784454346
Validation loss: 2.0118209059520433

Epoch: 6| Step: 10
Training loss: 1.6899882555007935
Validation loss: 2.0125095946814424

Epoch: 6| Step: 11
Training loss: 2.4189672470092773
Validation loss: 2.0085708582273094

Epoch: 6| Step: 12
Training loss: 1.8154356479644775
Validation loss: 2.039406062454306

Epoch: 6| Step: 13
Training loss: 2.2413854598999023
Validation loss: 2.016079828303347

Epoch: 379| Step: 0
Training loss: 1.7622780799865723
Validation loss: 2.017462500961878

Epoch: 6| Step: 1
Training loss: 1.952639102935791
Validation loss: 2.025858226642814

Epoch: 6| Step: 2
Training loss: 2.3279612064361572
Validation loss: 2.023479184796733

Epoch: 6| Step: 3
Training loss: 2.111722946166992
Validation loss: 2.0273775439108572

Epoch: 6| Step: 4
Training loss: 2.189483165740967
Validation loss: 2.0332140717455136

Epoch: 6| Step: 5
Training loss: 1.1003190279006958
Validation loss: 2.037385462432779

Epoch: 6| Step: 6
Training loss: 2.603105068206787
Validation loss: 2.0236360142307896

Epoch: 6| Step: 7
Training loss: 2.2763919830322266
Validation loss: 2.037303488741639

Epoch: 6| Step: 8
Training loss: 2.5696895122528076
Validation loss: 2.030865655150465

Epoch: 6| Step: 9
Training loss: 2.5645198822021484
Validation loss: 2.0376023297668784

Epoch: 6| Step: 10
Training loss: 1.8729066848754883
Validation loss: 2.0248984893163047

Epoch: 6| Step: 11
Training loss: 2.0988619327545166
Validation loss: 2.029982192541963

Epoch: 6| Step: 12
Training loss: 1.7275028228759766
Validation loss: 2.015988798551662

Epoch: 6| Step: 13
Training loss: 1.4789843559265137
Validation loss: 2.0218968775964554

Epoch: 380| Step: 0
Training loss: 1.6509718894958496
Validation loss: 2.023079461948846

Epoch: 6| Step: 1
Training loss: 2.528289794921875
Validation loss: 2.0203957083404704

Epoch: 6| Step: 2
Training loss: 1.445735216140747
Validation loss: 2.023767461058914

Epoch: 6| Step: 3
Training loss: 1.68611478805542
Validation loss: 2.0158636454612977

Epoch: 6| Step: 4
Training loss: 1.9847118854522705
Validation loss: 2.0200687762229674

Epoch: 6| Step: 5
Training loss: 2.371333122253418
Validation loss: 2.026792881309345

Epoch: 6| Step: 6
Training loss: 2.7876977920532227
Validation loss: 2.0281782996269966

Epoch: 6| Step: 7
Training loss: 1.8142046928405762
Validation loss: 2.03213914491797

Epoch: 6| Step: 8
Training loss: 1.2549090385437012
Validation loss: 2.0353023134252077

Epoch: 6| Step: 9
Training loss: 2.4797682762145996
Validation loss: 2.0429138163084626

Epoch: 6| Step: 10
Training loss: 1.7891764640808105
Validation loss: 2.046223493032558

Epoch: 6| Step: 11
Training loss: 2.173877477645874
Validation loss: 2.042685108800088

Epoch: 6| Step: 12
Training loss: 2.3912980556488037
Validation loss: 2.040110929037935

Epoch: 6| Step: 13
Training loss: 2.5186643600463867
Validation loss: 2.051561709373228

Epoch: 381| Step: 0
Training loss: 1.9731581211090088
Validation loss: 2.047365201416836

Epoch: 6| Step: 1
Training loss: 2.1359128952026367
Validation loss: 2.0334238057495444

Epoch: 6| Step: 2
Training loss: 1.3024520874023438
Validation loss: 2.0347745008366083

Epoch: 6| Step: 3
Training loss: 2.6759262084960938
Validation loss: 2.0338371184564408

Epoch: 6| Step: 4
Training loss: 1.6896624565124512
Validation loss: 2.0283642815005396

Epoch: 6| Step: 5
Training loss: 2.2724874019622803
Validation loss: 2.029196108541181

Epoch: 6| Step: 6
Training loss: 2.1720786094665527
Validation loss: 2.032552492234015

Epoch: 6| Step: 7
Training loss: 1.9527525901794434
Validation loss: 2.0379292734207644

Epoch: 6| Step: 8
Training loss: 1.7557792663574219
Validation loss: 2.0231058264291413

Epoch: 6| Step: 9
Training loss: 2.1893787384033203
Validation loss: 2.040767429977335

Epoch: 6| Step: 10
Training loss: 2.187638282775879
Validation loss: 2.026593949205132

Epoch: 6| Step: 11
Training loss: 2.1444931030273438
Validation loss: 2.033018142946305

Epoch: 6| Step: 12
Training loss: 2.099891185760498
Validation loss: 2.0115103619073027

Epoch: 6| Step: 13
Training loss: 2.043433904647827
Validation loss: 2.0197323163350425

Epoch: 382| Step: 0
Training loss: 2.2456789016723633
Validation loss: 2.0222133180146575

Epoch: 6| Step: 1
Training loss: 2.4555068016052246
Validation loss: 2.014856048809585

Epoch: 6| Step: 2
Training loss: 1.7390310764312744
Validation loss: 2.037495856644005

Epoch: 6| Step: 3
Training loss: 2.4552831649780273
Validation loss: 2.033991212485939

Epoch: 6| Step: 4
Training loss: 2.1725125312805176
Validation loss: 2.0295616965140066

Epoch: 6| Step: 5
Training loss: 2.153346061706543
Validation loss: 2.030364155769348

Epoch: 6| Step: 6
Training loss: 1.5246628522872925
Validation loss: 2.003102256405738

Epoch: 6| Step: 7
Training loss: 2.0312886238098145
Validation loss: 2.0126098176484466

Epoch: 6| Step: 8
Training loss: 2.5066962242126465
Validation loss: 2.019643942515055

Epoch: 6| Step: 9
Training loss: 2.166624069213867
Validation loss: 2.0298716945032917

Epoch: 6| Step: 10
Training loss: 1.579751968383789
Validation loss: 2.0302060906605055

Epoch: 6| Step: 11
Training loss: 1.6482517719268799
Validation loss: 2.0270180676573064

Epoch: 6| Step: 12
Training loss: 2.0261318683624268
Validation loss: 2.0163087280847694

Epoch: 6| Step: 13
Training loss: 1.9518852233886719
Validation loss: 2.015689315334443

Epoch: 383| Step: 0
Training loss: 2.941394805908203
Validation loss: 2.013361225845993

Epoch: 6| Step: 1
Training loss: 1.6390275955200195
Validation loss: 2.035335866353845

Epoch: 6| Step: 2
Training loss: 1.9633538722991943
Validation loss: 2.0293419886660833

Epoch: 6| Step: 3
Training loss: 1.6705093383789062
Validation loss: 2.0526943668242423

Epoch: 6| Step: 4
Training loss: 2.2828495502471924
Validation loss: 2.054815928141276

Epoch: 6| Step: 5
Training loss: 2.862405300140381
Validation loss: 2.0562756881918958

Epoch: 6| Step: 6
Training loss: 1.9918725490570068
Validation loss: 2.046623450453563

Epoch: 6| Step: 7
Training loss: 1.3719992637634277
Validation loss: 2.0387611748069845

Epoch: 6| Step: 8
Training loss: 2.3823862075805664
Validation loss: 2.0134050320553523

Epoch: 6| Step: 9
Training loss: 2.3561136722564697
Validation loss: 2.0107275952575026

Epoch: 6| Step: 10
Training loss: 1.330712080001831
Validation loss: 2.013413971470248

Epoch: 6| Step: 11
Training loss: 1.8173997402191162
Validation loss: 2.0185882122285905

Epoch: 6| Step: 12
Training loss: 2.3703789710998535
Validation loss: 2.0252992183931413

Epoch: 6| Step: 13
Training loss: 1.6335700750350952
Validation loss: 2.0171180809697797

Epoch: 384| Step: 0
Training loss: 2.284841537475586
Validation loss: 2.0210232709043767

Epoch: 6| Step: 1
Training loss: 2.134275197982788
Validation loss: 2.0254939474085325

Epoch: 6| Step: 2
Training loss: 2.1299729347229004
Validation loss: 2.0171944210606236

Epoch: 6| Step: 3
Training loss: 2.479653835296631
Validation loss: 2.0255404954315512

Epoch: 6| Step: 4
Training loss: 1.630415678024292
Validation loss: 2.0222042811814176

Epoch: 6| Step: 5
Training loss: 1.9529025554656982
Validation loss: 2.040163519561932

Epoch: 6| Step: 6
Training loss: 1.5254582166671753
Validation loss: 2.048036503535445

Epoch: 6| Step: 7
Training loss: 1.572595477104187
Validation loss: 2.03527360193191

Epoch: 6| Step: 8
Training loss: 1.6146481037139893
Validation loss: 2.032009099119453

Epoch: 6| Step: 9
Training loss: 2.6673367023468018
Validation loss: 2.0232277275413595

Epoch: 6| Step: 10
Training loss: 2.606369972229004
Validation loss: 2.024764835193593

Epoch: 6| Step: 11
Training loss: 2.4725122451782227
Validation loss: 2.0183004128035678

Epoch: 6| Step: 12
Training loss: 2.19014835357666
Validation loss: 2.0165501948325866

Epoch: 6| Step: 13
Training loss: 0.8745318651199341
Validation loss: 2.014390309651693

Epoch: 385| Step: 0
Training loss: 2.3308629989624023
Validation loss: 2.0117926687322636

Epoch: 6| Step: 1
Training loss: 1.946704387664795
Validation loss: 2.005733855309025

Epoch: 6| Step: 2
Training loss: 1.7576192617416382
Validation loss: 2.0431466256418536

Epoch: 6| Step: 3
Training loss: 2.138339042663574
Validation loss: 2.054652621669154

Epoch: 6| Step: 4
Training loss: 2.250920534133911
Validation loss: 2.0551067757350143

Epoch: 6| Step: 5
Training loss: 1.7064287662506104
Validation loss: 2.053511409349339

Epoch: 6| Step: 6
Training loss: 1.8775758743286133
Validation loss: 2.0460536813223236

Epoch: 6| Step: 7
Training loss: 1.6925880908966064
Validation loss: 2.058746422490766

Epoch: 6| Step: 8
Training loss: 2.147538661956787
Validation loss: 2.039796419041131

Epoch: 6| Step: 9
Training loss: 1.9520193338394165
Validation loss: 2.0226290405437513

Epoch: 6| Step: 10
Training loss: 2.3409423828125
Validation loss: 2.02908072933074

Epoch: 6| Step: 11
Training loss: 2.189699649810791
Validation loss: 2.0469046408130276

Epoch: 6| Step: 12
Training loss: 2.2972660064697266
Validation loss: 2.0453878987220024

Epoch: 6| Step: 13
Training loss: 2.6991517543792725
Validation loss: 2.06968290575089

Epoch: 386| Step: 0
Training loss: 1.8220651149749756
Validation loss: 2.036525764772969

Epoch: 6| Step: 1
Training loss: 2.151388645172119
Validation loss: 2.027098303200096

Epoch: 6| Step: 2
Training loss: 2.059676170349121
Validation loss: 2.0131123142857708

Epoch: 6| Step: 3
Training loss: 1.9375501871109009
Validation loss: 2.006258726119995

Epoch: 6| Step: 4
Training loss: 1.665204405784607
Validation loss: 2.0194548432544996

Epoch: 6| Step: 5
Training loss: 2.180421829223633
Validation loss: 2.0279468669686267

Epoch: 6| Step: 6
Training loss: 2.909761905670166
Validation loss: 2.0316949095777286

Epoch: 6| Step: 7
Training loss: 2.2441651821136475
Validation loss: 2.0036093599052838

Epoch: 6| Step: 8
Training loss: 2.8207807540893555
Validation loss: 2.016272767897575

Epoch: 6| Step: 9
Training loss: 1.084662675857544
Validation loss: 2.012151848885321

Epoch: 6| Step: 10
Training loss: 1.4874632358551025
Validation loss: 2.0105539239862913

Epoch: 6| Step: 11
Training loss: 1.501286268234253
Validation loss: 2.033162655368928

Epoch: 6| Step: 12
Training loss: 2.383450746536255
Validation loss: 2.0285116985280025

Epoch: 6| Step: 13
Training loss: 2.6312851905822754
Validation loss: 2.033669182049331

Epoch: 387| Step: 0
Training loss: 1.327218770980835
Validation loss: 2.017301820939587

Epoch: 6| Step: 1
Training loss: 2.0052266120910645
Validation loss: 2.01563677992872

Epoch: 6| Step: 2
Training loss: 2.077026844024658
Validation loss: 2.0244471808915496

Epoch: 6| Step: 3
Training loss: 1.900834083557129
Validation loss: 2.0189175349409862

Epoch: 6| Step: 4
Training loss: 2.3984217643737793
Validation loss: 2.0266627188651793

Epoch: 6| Step: 5
Training loss: 1.915945053100586
Validation loss: 2.0178692148577784

Epoch: 6| Step: 6
Training loss: 2.31418514251709
Validation loss: 2.022562725569612

Epoch: 6| Step: 7
Training loss: 1.8034908771514893
Validation loss: 2.031159626540317

Epoch: 6| Step: 8
Training loss: 2.0880179405212402
Validation loss: 2.031928457239623

Epoch: 6| Step: 9
Training loss: 2.1624433994293213
Validation loss: 2.0387619823537846

Epoch: 6| Step: 10
Training loss: 2.128389358520508
Validation loss: 2.037443148192539

Epoch: 6| Step: 11
Training loss: 2.0379769802093506
Validation loss: 2.0330704258334253

Epoch: 6| Step: 12
Training loss: 2.234919786453247
Validation loss: 2.0292212117102837

Epoch: 6| Step: 13
Training loss: 2.061086893081665
Validation loss: 2.032825384088742

Epoch: 388| Step: 0
Training loss: 1.553062915802002
Validation loss: 2.0119258203814105

Epoch: 6| Step: 1
Training loss: 1.8975944519042969
Validation loss: 2.017042249761602

Epoch: 6| Step: 2
Training loss: 2.690760612487793
Validation loss: 2.0088567759401057

Epoch: 6| Step: 3
Training loss: 2.667546272277832
Validation loss: 2.0008618370179208

Epoch: 6| Step: 4
Training loss: 2.6488895416259766
Validation loss: 2.016290130153779

Epoch: 6| Step: 5
Training loss: 1.437134027481079
Validation loss: 1.9918759881809194

Epoch: 6| Step: 6
Training loss: 1.7873239517211914
Validation loss: 2.021712544143841

Epoch: 6| Step: 7
Training loss: 1.477037787437439
Validation loss: 2.009035723183745

Epoch: 6| Step: 8
Training loss: 2.2345871925354004
Validation loss: 2.0203721728376163

Epoch: 6| Step: 9
Training loss: 2.0350446701049805
Validation loss: 2.024933995739106

Epoch: 6| Step: 10
Training loss: 2.018982172012329
Validation loss: 2.0165231791875695

Epoch: 6| Step: 11
Training loss: 1.7236242294311523
Validation loss: 2.0223285177702546

Epoch: 6| Step: 12
Training loss: 2.036207437515259
Validation loss: 2.033771450801562

Epoch: 6| Step: 13
Training loss: 2.4567692279815674
Validation loss: 2.0377419199994815

Epoch: 389| Step: 0
Training loss: 2.1148264408111572
Validation loss: 2.019646998374693

Epoch: 6| Step: 1
Training loss: 1.8381267786026
Validation loss: 2.0285664271282893

Epoch: 6| Step: 2
Training loss: 2.1079025268554688
Validation loss: 2.0149114824110463

Epoch: 6| Step: 3
Training loss: 1.7153266668319702
Validation loss: 2.007035732269287

Epoch: 6| Step: 4
Training loss: 2.5157630443573
Validation loss: 2.0058260297262542

Epoch: 6| Step: 5
Training loss: 2.556628942489624
Validation loss: 2.0028899049246185

Epoch: 6| Step: 6
Training loss: 2.4330992698669434
Validation loss: 2.021378086459252

Epoch: 6| Step: 7
Training loss: 1.4725000858306885
Validation loss: 2.0170111361370293

Epoch: 6| Step: 8
Training loss: 1.9203578233718872
Validation loss: 2.01727694337086

Epoch: 6| Step: 9
Training loss: 1.5089695453643799
Validation loss: 2.0133459221932197

Epoch: 6| Step: 10
Training loss: 2.7331323623657227
Validation loss: 2.0220288358708864

Epoch: 6| Step: 11
Training loss: 1.6568119525909424
Validation loss: 2.026199067792585

Epoch: 6| Step: 12
Training loss: 2.06815505027771
Validation loss: 2.020515262439687

Epoch: 6| Step: 13
Training loss: 1.5990736484527588
Validation loss: 2.020405997512161

Epoch: 390| Step: 0
Training loss: 1.933510661125183
Validation loss: 2.013916446316627

Epoch: 6| Step: 1
Training loss: 1.6966960430145264
Validation loss: 2.0046477343446467

Epoch: 6| Step: 2
Training loss: 1.7487010955810547
Validation loss: 1.9958056275562575

Epoch: 6| Step: 3
Training loss: 2.774773120880127
Validation loss: 2.0080156249384724

Epoch: 6| Step: 4
Training loss: 1.9955594539642334
Validation loss: 2.0171164863853046

Epoch: 6| Step: 5
Training loss: 1.4803255796432495
Validation loss: 2.0122213645647933

Epoch: 6| Step: 6
Training loss: 1.395470380783081
Validation loss: 2.0201910323994134

Epoch: 6| Step: 7
Training loss: 2.258166551589966
Validation loss: 2.041703180600238

Epoch: 6| Step: 8
Training loss: 2.2027406692504883
Validation loss: 2.02893280213879

Epoch: 6| Step: 9
Training loss: 1.6453194618225098
Validation loss: 2.0283132842791978

Epoch: 6| Step: 10
Training loss: 2.2137396335601807
Validation loss: 2.0231187625597884

Epoch: 6| Step: 11
Training loss: 1.869777798652649
Validation loss: 2.032898538856096

Epoch: 6| Step: 12
Training loss: 2.5158917903900146
Validation loss: 2.0287761701050626

Epoch: 6| Step: 13
Training loss: 2.778411626815796
Validation loss: 2.030300853072956

Epoch: 391| Step: 0
Training loss: 1.5876206159591675
Validation loss: 2.009936216056988

Epoch: 6| Step: 1
Training loss: 2.031992197036743
Validation loss: 2.03104636105158

Epoch: 6| Step: 2
Training loss: 2.157453775405884
Validation loss: 2.0228695689990954

Epoch: 6| Step: 3
Training loss: 2.508021593093872
Validation loss: 2.0187234417084725

Epoch: 6| Step: 4
Training loss: 1.8773212432861328
Validation loss: 2.0079941800845567

Epoch: 6| Step: 5
Training loss: 1.8697755336761475
Validation loss: 2.0184398517813733

Epoch: 6| Step: 6
Training loss: 2.2622323036193848
Validation loss: 1.9903420504703317

Epoch: 6| Step: 7
Training loss: 2.103677272796631
Validation loss: 2.0201731868969497

Epoch: 6| Step: 8
Training loss: 1.999507188796997
Validation loss: 2.021152195110116

Epoch: 6| Step: 9
Training loss: 2.0758986473083496
Validation loss: 2.019039720617315

Epoch: 6| Step: 10
Training loss: 1.4544744491577148
Validation loss: 2.0358251653691775

Epoch: 6| Step: 11
Training loss: 2.473296642303467
Validation loss: 2.0339054881885485

Epoch: 6| Step: 12
Training loss: 1.8424382209777832
Validation loss: 2.035101353481252

Epoch: 6| Step: 13
Training loss: 2.287900686264038
Validation loss: 2.0333213088332966

Epoch: 392| Step: 0
Training loss: 1.7688181400299072
Validation loss: 2.0412088337764946

Epoch: 6| Step: 1
Training loss: 2.7596726417541504
Validation loss: 2.022162118265706

Epoch: 6| Step: 2
Training loss: 1.8804428577423096
Validation loss: 2.027272839700022

Epoch: 6| Step: 3
Training loss: 1.6018600463867188
Validation loss: 2.0174710891580068

Epoch: 6| Step: 4
Training loss: 1.8597443103790283
Validation loss: 2.019567249923624

Epoch: 6| Step: 5
Training loss: 2.3472394943237305
Validation loss: 2.0230965396409393

Epoch: 6| Step: 6
Training loss: 2.0096306800842285
Validation loss: 2.0152797570792575

Epoch: 6| Step: 7
Training loss: 1.3260023593902588
Validation loss: 2.0085577349508963

Epoch: 6| Step: 8
Training loss: 1.3047058582305908
Validation loss: 2.0119894037964525

Epoch: 6| Step: 9
Training loss: 2.3427374362945557
Validation loss: 2.0223339065428703

Epoch: 6| Step: 10
Training loss: 3.1065616607666016
Validation loss: 2.049648657921822

Epoch: 6| Step: 11
Training loss: 2.1724514961242676
Validation loss: 2.034791454192131

Epoch: 6| Step: 12
Training loss: 1.548093557357788
Validation loss: 2.035639186059275

Epoch: 6| Step: 13
Training loss: 2.4639034271240234
Validation loss: 2.0102408457827825

Epoch: 393| Step: 0
Training loss: 2.0132570266723633
Validation loss: 2.0190262666312595

Epoch: 6| Step: 1
Training loss: 2.415360927581787
Validation loss: 2.0092531981006747

Epoch: 6| Step: 2
Training loss: 2.427762746810913
Validation loss: 2.0050599575042725

Epoch: 6| Step: 3
Training loss: 2.0476796627044678
Validation loss: 2.0023339409982004

Epoch: 6| Step: 4
Training loss: 1.7901824712753296
Validation loss: 2.017215564686765

Epoch: 6| Step: 5
Training loss: 2.3774032592773438
Validation loss: 2.0098053716844126

Epoch: 6| Step: 6
Training loss: 2.312530517578125
Validation loss: 2.0148966338044856

Epoch: 6| Step: 7
Training loss: 1.6237379312515259
Validation loss: 2.001732167377267

Epoch: 6| Step: 8
Training loss: 1.8302040100097656
Validation loss: 2.0205668121255855

Epoch: 6| Step: 9
Training loss: 1.6757254600524902
Validation loss: 2.0294766515813847

Epoch: 6| Step: 10
Training loss: 1.785658836364746
Validation loss: 2.0337871120822046

Epoch: 6| Step: 11
Training loss: 2.029770851135254
Validation loss: 2.048349622757204

Epoch: 6| Step: 12
Training loss: 1.8539714813232422
Validation loss: 2.0388460928393948

Epoch: 6| Step: 13
Training loss: 1.9293702840805054
Validation loss: 2.0290457740906747

Epoch: 394| Step: 0
Training loss: 1.6711528301239014
Validation loss: 2.019045200399173

Epoch: 6| Step: 1
Training loss: 2.0701496601104736
Validation loss: 2.0237599829191804

Epoch: 6| Step: 2
Training loss: 1.6037588119506836
Validation loss: 2.032848427372594

Epoch: 6| Step: 3
Training loss: 2.419351577758789
Validation loss: 2.0272225385071128

Epoch: 6| Step: 4
Training loss: 1.791914463043213
Validation loss: 2.0301512800237185

Epoch: 6| Step: 5
Training loss: 1.2194933891296387
Validation loss: 2.023291216101698

Epoch: 6| Step: 6
Training loss: 2.261746883392334
Validation loss: 2.0251355286567443

Epoch: 6| Step: 7
Training loss: 2.179581880569458
Validation loss: 2.0391011853371896

Epoch: 6| Step: 8
Training loss: 2.2023110389709473
Validation loss: 2.040048699225149

Epoch: 6| Step: 9
Training loss: 2.0562005043029785
Validation loss: 2.02836004892985

Epoch: 6| Step: 10
Training loss: 2.3362443447113037
Validation loss: 2.0188692756878432

Epoch: 6| Step: 11
Training loss: 1.6830142736434937
Validation loss: 2.0265669797056463

Epoch: 6| Step: 12
Training loss: 2.1214351654052734
Validation loss: 2.0171350638071694

Epoch: 6| Step: 13
Training loss: 3.011644124984741
Validation loss: 2.000942172542695

Epoch: 395| Step: 0
Training loss: 2.582658290863037
Validation loss: 1.9961260326447026

Epoch: 6| Step: 1
Training loss: 2.0028860569000244
Validation loss: 1.9994972675077376

Epoch: 6| Step: 2
Training loss: 2.628392457962036
Validation loss: 1.99296094781609

Epoch: 6| Step: 3
Training loss: 1.592632532119751
Validation loss: 1.9868883330334899

Epoch: 6| Step: 4
Training loss: 1.554044246673584
Validation loss: 1.9890747121585313

Epoch: 6| Step: 5
Training loss: 1.8045804500579834
Validation loss: 2.001752879029961

Epoch: 6| Step: 6
Training loss: 2.1948654651641846
Validation loss: 2.0050490581861107

Epoch: 6| Step: 7
Training loss: 1.555443525314331
Validation loss: 2.023846596799871

Epoch: 6| Step: 8
Training loss: 2.2522428035736084
Validation loss: 2.020314537068849

Epoch: 6| Step: 9
Training loss: 1.9715036153793335
Validation loss: 2.028276011507998

Epoch: 6| Step: 10
Training loss: 2.160186290740967
Validation loss: 2.0282326103538595

Epoch: 6| Step: 11
Training loss: 1.579774022102356
Validation loss: 2.0153235940523047

Epoch: 6| Step: 12
Training loss: 2.1076886653900146
Validation loss: 2.0136013774461645

Epoch: 6| Step: 13
Training loss: 2.116975784301758
Validation loss: 2.0034245829428396

Epoch: 396| Step: 0
Training loss: 2.71225643157959
Validation loss: 2.0063301696572253

Epoch: 6| Step: 1
Training loss: 2.1416878700256348
Validation loss: 2.0142841364747737

Epoch: 6| Step: 2
Training loss: 1.4104583263397217
Validation loss: 2.0032201556749243

Epoch: 6| Step: 3
Training loss: 1.580571174621582
Validation loss: 2.020630946723364

Epoch: 6| Step: 4
Training loss: 2.1759557723999023
Validation loss: 2.011148391231414

Epoch: 6| Step: 5
Training loss: 1.7476788759231567
Validation loss: 2.013624773230604

Epoch: 6| Step: 6
Training loss: 1.902077317237854
Validation loss: 2.0212361094772175

Epoch: 6| Step: 7
Training loss: 1.6890592575073242
Validation loss: 2.021122428678697

Epoch: 6| Step: 8
Training loss: 2.1365504264831543
Validation loss: 2.0056313353200115

Epoch: 6| Step: 9
Training loss: 2.149977684020996
Validation loss: 2.0212288441196566

Epoch: 6| Step: 10
Training loss: 2.026808261871338
Validation loss: 2.0270255611788843

Epoch: 6| Step: 11
Training loss: 1.9071708917617798
Validation loss: 2.034223105317803

Epoch: 6| Step: 12
Training loss: 2.117703676223755
Validation loss: 2.024235784366567

Epoch: 6| Step: 13
Training loss: 2.572589635848999
Validation loss: 2.030223584944202

Epoch: 397| Step: 0
Training loss: 1.4594128131866455
Validation loss: 2.0180717578498264

Epoch: 6| Step: 1
Training loss: 1.9727002382278442
Validation loss: 2.0064003057377313

Epoch: 6| Step: 2
Training loss: 2.9647529125213623
Validation loss: 1.9903750957981232

Epoch: 6| Step: 3
Training loss: 1.5720796585083008
Validation loss: 1.990144355322725

Epoch: 6| Step: 4
Training loss: 2.253079652786255
Validation loss: 1.983242029784828

Epoch: 6| Step: 5
Training loss: 1.3114264011383057
Validation loss: 1.991264397098172

Epoch: 6| Step: 6
Training loss: 2.8287296295166016
Validation loss: 1.9887997899004208

Epoch: 6| Step: 7
Training loss: 2.1318860054016113
Validation loss: 1.9856168070147115

Epoch: 6| Step: 8
Training loss: 2.287370204925537
Validation loss: 1.9881733091928626

Epoch: 6| Step: 9
Training loss: 1.7573788166046143
Validation loss: 1.9778358077490201

Epoch: 6| Step: 10
Training loss: 1.6532630920410156
Validation loss: 2.000896126993241

Epoch: 6| Step: 11
Training loss: 2.015287160873413
Validation loss: 1.9975332290895524

Epoch: 6| Step: 12
Training loss: 2.2280404567718506
Validation loss: 2.0034547685295023

Epoch: 6| Step: 13
Training loss: 1.1826823949813843
Validation loss: 2.0131366124717136

Epoch: 398| Step: 0
Training loss: 2.314868450164795
Validation loss: 2.021353265290619

Epoch: 6| Step: 1
Training loss: 1.743013620376587
Validation loss: 2.04087237645221

Epoch: 6| Step: 2
Training loss: 1.6282589435577393
Validation loss: 2.024251200819528

Epoch: 6| Step: 3
Training loss: 2.2164549827575684
Validation loss: 2.052296825634536

Epoch: 6| Step: 4
Training loss: 2.3372340202331543
Validation loss: 2.0150914512654787

Epoch: 6| Step: 5
Training loss: 1.992564082145691
Validation loss: 2.0132072343621203

Epoch: 6| Step: 6
Training loss: 1.735230803489685
Validation loss: 2.002084803837602

Epoch: 6| Step: 7
Training loss: 1.5507395267486572
Validation loss: 2.0062588337929017

Epoch: 6| Step: 8
Training loss: 1.9221439361572266
Validation loss: 2.005257891070458

Epoch: 6| Step: 9
Training loss: 2.2583022117614746
Validation loss: 2.012890563216261

Epoch: 6| Step: 10
Training loss: 2.3907203674316406
Validation loss: 2.016521721757868

Epoch: 6| Step: 11
Training loss: 1.4603168964385986
Validation loss: 2.008356381488103

Epoch: 6| Step: 12
Training loss: 1.999631404876709
Validation loss: 1.994494217698292

Epoch: 6| Step: 13
Training loss: 2.8192193508148193
Validation loss: 2.0092103276201474

Epoch: 399| Step: 0
Training loss: 1.7285795211791992
Validation loss: 2.0110164637206704

Epoch: 6| Step: 1
Training loss: 1.0526609420776367
Validation loss: 2.0052783848136984

Epoch: 6| Step: 2
Training loss: 1.9066071510314941
Validation loss: 2.0220881764606764

Epoch: 6| Step: 3
Training loss: 2.103813409805298
Validation loss: 2.009234937288428

Epoch: 6| Step: 4
Training loss: 2.178840160369873
Validation loss: 2.0148201001587736

Epoch: 6| Step: 5
Training loss: 1.694225788116455
Validation loss: 2.024766460541756

Epoch: 6| Step: 6
Training loss: 2.3463664054870605
Validation loss: 2.0137594797277965

Epoch: 6| Step: 7
Training loss: 2.3696107864379883
Validation loss: 2.0182812982989895

Epoch: 6| Step: 8
Training loss: 1.931768536567688
Validation loss: 2.021583728892829

Epoch: 6| Step: 9
Training loss: 1.7682358026504517
Validation loss: 2.000884791856171

Epoch: 6| Step: 10
Training loss: 2.197357177734375
Validation loss: 1.9982801791160338

Epoch: 6| Step: 11
Training loss: 2.0801591873168945
Validation loss: 1.990263710739792

Epoch: 6| Step: 12
Training loss: 2.1221327781677246
Validation loss: 1.9882011003391717

Epoch: 6| Step: 13
Training loss: 2.6366000175476074
Validation loss: 2.008390034398725

Epoch: 400| Step: 0
Training loss: 1.6536245346069336
Validation loss: 1.9897104014632523

Epoch: 6| Step: 1
Training loss: 2.384913444519043
Validation loss: 2.0039164097078386

Epoch: 6| Step: 2
Training loss: 2.087719440460205
Validation loss: 2.0030055712628108

Epoch: 6| Step: 3
Training loss: 2.0903031826019287
Validation loss: 1.9893924625970985

Epoch: 6| Step: 4
Training loss: 2.482590436935425
Validation loss: 1.9981984156434254

Epoch: 6| Step: 5
Training loss: 2.0201611518859863
Validation loss: 1.9888671418671966

Epoch: 6| Step: 6
Training loss: 1.5597360134124756
Validation loss: 2.000420698555567

Epoch: 6| Step: 7
Training loss: 2.0852723121643066
Validation loss: 1.9978480339050293

Epoch: 6| Step: 8
Training loss: 2.1658685207366943
Validation loss: 1.9978775080814157

Epoch: 6| Step: 9
Training loss: 2.429685115814209
Validation loss: 2.019233993304673

Epoch: 6| Step: 10
Training loss: 2.0105459690093994
Validation loss: 2.005075693130493

Epoch: 6| Step: 11
Training loss: 1.3273215293884277
Validation loss: 2.0096650059505174

Epoch: 6| Step: 12
Training loss: 2.077160596847534
Validation loss: 2.0062596682579286

Epoch: 6| Step: 13
Training loss: 1.1954727172851562
Validation loss: 1.991537353043915

Epoch: 401| Step: 0
Training loss: 2.591599702835083
Validation loss: 2.0015894174575806

Epoch: 6| Step: 1
Training loss: 1.7232686281204224
Validation loss: 1.9922994400865288

Epoch: 6| Step: 2
Training loss: 2.011265754699707
Validation loss: 1.9918998261933685

Epoch: 6| Step: 3
Training loss: 1.252953290939331
Validation loss: 2.0050437245317685

Epoch: 6| Step: 4
Training loss: 1.7133077383041382
Validation loss: 1.9808228477354972

Epoch: 6| Step: 5
Training loss: 1.5539453029632568
Validation loss: 1.9774345223621657

Epoch: 6| Step: 6
Training loss: 2.4516592025756836
Validation loss: 1.9869282271272393

Epoch: 6| Step: 7
Training loss: 2.7942824363708496
Validation loss: 1.989666510653752

Epoch: 6| Step: 8
Training loss: 2.514042854309082
Validation loss: 1.9851234241198468

Epoch: 6| Step: 9
Training loss: 2.221404552459717
Validation loss: 1.9883498017505934

Epoch: 6| Step: 10
Training loss: 1.9648816585540771
Validation loss: 1.9914528285303423

Epoch: 6| Step: 11
Training loss: 1.8351455926895142
Validation loss: 1.992156901667195

Epoch: 6| Step: 12
Training loss: 1.4175106287002563
Validation loss: 1.9813653281939927

Epoch: 6| Step: 13
Training loss: 1.3484952449798584
Validation loss: 2.002077248788649

Epoch: 402| Step: 0
Training loss: 2.0534210205078125
Validation loss: 2.0130639576142833

Epoch: 6| Step: 1
Training loss: 2.3380210399627686
Validation loss: 2.0175187792829288

Epoch: 6| Step: 2
Training loss: 1.8108210563659668
Validation loss: 1.9973853685522591

Epoch: 6| Step: 3
Training loss: 2.2026376724243164
Validation loss: 1.9907175943415651

Epoch: 6| Step: 4
Training loss: 2.2859079837799072
Validation loss: 1.9896200805582025

Epoch: 6| Step: 5
Training loss: 2.3670592308044434
Validation loss: 1.995718398401814

Epoch: 6| Step: 6
Training loss: 2.213829517364502
Validation loss: 1.9932323014864357

Epoch: 6| Step: 7
Training loss: 1.8090898990631104
Validation loss: 1.989425072105982

Epoch: 6| Step: 8
Training loss: 1.7106201648712158
Validation loss: 1.9734530807823263

Epoch: 6| Step: 9
Training loss: 1.6503136157989502
Validation loss: 1.9936029116312664

Epoch: 6| Step: 10
Training loss: 1.7444719076156616
Validation loss: 1.9882975265543947

Epoch: 6| Step: 11
Training loss: 1.8090906143188477
Validation loss: 1.9736338687199417

Epoch: 6| Step: 12
Training loss: 1.667391061782837
Validation loss: 1.969174882417084

Epoch: 6| Step: 13
Training loss: 2.1207590103149414
Validation loss: 1.9884034625945552

Epoch: 403| Step: 0
Training loss: 2.1269805431365967
Validation loss: 1.9953418265106857

Epoch: 6| Step: 1
Training loss: 2.1641416549682617
Validation loss: 2.0198866808286278

Epoch: 6| Step: 2
Training loss: 1.5227867364883423
Validation loss: 2.0330650588517547

Epoch: 6| Step: 3
Training loss: 1.847562313079834
Validation loss: 2.028864065806071

Epoch: 6| Step: 4
Training loss: 2.2187368869781494
Validation loss: 2.0545381666511617

Epoch: 6| Step: 5
Training loss: 2.1122384071350098
Validation loss: 2.0462759258926555

Epoch: 6| Step: 6
Training loss: 1.9987671375274658
Validation loss: 2.0499430292396137

Epoch: 6| Step: 7
Training loss: 2.0832576751708984
Validation loss: 2.049591438744658

Epoch: 6| Step: 8
Training loss: 1.4880220890045166
Validation loss: 2.011465989133363

Epoch: 6| Step: 9
Training loss: 1.835953950881958
Validation loss: 2.025222552719937

Epoch: 6| Step: 10
Training loss: 2.1201601028442383
Validation loss: 2.007449419267716

Epoch: 6| Step: 11
Training loss: 2.3386037349700928
Validation loss: 2.003016733354138

Epoch: 6| Step: 12
Training loss: 2.441681385040283
Validation loss: 1.994763316646699

Epoch: 6| Step: 13
Training loss: 1.3404650688171387
Validation loss: 1.9964653343282721

Epoch: 404| Step: 0
Training loss: 2.898416042327881
Validation loss: 1.9988226070198962

Epoch: 6| Step: 1
Training loss: 1.9818443059921265
Validation loss: 2.0083161656574537

Epoch: 6| Step: 2
Training loss: 0.7448403239250183
Validation loss: 2.0003221522095385

Epoch: 6| Step: 3
Training loss: 1.6477621793746948
Validation loss: 1.9920876513245285

Epoch: 6| Step: 4
Training loss: 1.5338966846466064
Validation loss: 2.000296213293588

Epoch: 6| Step: 5
Training loss: 2.252955913543701
Validation loss: 2.0066125751823507

Epoch: 6| Step: 6
Training loss: 1.3932210206985474
Validation loss: 1.991425355275472

Epoch: 6| Step: 7
Training loss: 1.9240837097167969
Validation loss: 2.0134467655612576

Epoch: 6| Step: 8
Training loss: 2.3170228004455566
Validation loss: 1.9767277625299269

Epoch: 6| Step: 9
Training loss: 2.5108799934387207
Validation loss: 1.9911603363611365

Epoch: 6| Step: 10
Training loss: 2.5887255668640137
Validation loss: 1.989971371107204

Epoch: 6| Step: 11
Training loss: 1.8028531074523926
Validation loss: 1.9989321565115323

Epoch: 6| Step: 12
Training loss: 2.377056837081909
Validation loss: 1.9931170722489715

Epoch: 6| Step: 13
Training loss: 1.5961577892303467
Validation loss: 2.002716866872644

Epoch: 405| Step: 0
Training loss: 1.5378057956695557
Validation loss: 2.013901592582785

Epoch: 6| Step: 1
Training loss: 2.356577157974243
Validation loss: 1.99634039145644

Epoch: 6| Step: 2
Training loss: 2.062058925628662
Validation loss: 1.9861571558060185

Epoch: 6| Step: 3
Training loss: 1.9658282995224
Validation loss: 2.0013779478688396

Epoch: 6| Step: 4
Training loss: 2.256584644317627
Validation loss: 1.9986862303108297

Epoch: 6| Step: 5
Training loss: 2.0660548210144043
Validation loss: 1.9928697283549974

Epoch: 6| Step: 6
Training loss: 1.9153032302856445
Validation loss: 1.999264741456637

Epoch: 6| Step: 7
Training loss: 2.180851936340332
Validation loss: 1.9963521624124179

Epoch: 6| Step: 8
Training loss: 1.7801084518432617
Validation loss: 1.995806719667168

Epoch: 6| Step: 9
Training loss: 1.6798919439315796
Validation loss: 1.9894984793919388

Epoch: 6| Step: 10
Training loss: 1.3870971202850342
Validation loss: 2.001989474860571

Epoch: 6| Step: 11
Training loss: 2.2004027366638184
Validation loss: 1.997229746592942

Epoch: 6| Step: 12
Training loss: 1.9056847095489502
Validation loss: 1.996476145200832

Epoch: 6| Step: 13
Training loss: 2.3194494247436523
Validation loss: 2.011590178294848

Epoch: 406| Step: 0
Training loss: 2.263673782348633
Validation loss: 1.9977180060519968

Epoch: 6| Step: 1
Training loss: 2.241334915161133
Validation loss: 2.0183101905289518

Epoch: 6| Step: 2
Training loss: 1.3431792259216309
Validation loss: 2.037925209409447

Epoch: 6| Step: 3
Training loss: 1.465858817100525
Validation loss: 2.0164814533725863

Epoch: 6| Step: 4
Training loss: 2.309023857116699
Validation loss: 2.0233822304715394

Epoch: 6| Step: 5
Training loss: 2.709510564804077
Validation loss: 2.0052904518701697

Epoch: 6| Step: 6
Training loss: 2.1583125591278076
Validation loss: 1.9798369689654278

Epoch: 6| Step: 7
Training loss: 1.6874926090240479
Validation loss: 1.984737644913376

Epoch: 6| Step: 8
Training loss: 1.8436404466629028
Validation loss: 1.9817326889243176

Epoch: 6| Step: 9
Training loss: 1.8660881519317627
Validation loss: 1.987174480192123

Epoch: 6| Step: 10
Training loss: 1.486267328262329
Validation loss: 1.978095766036741

Epoch: 6| Step: 11
Training loss: 1.838613510131836
Validation loss: 1.9846791323795114

Epoch: 6| Step: 12
Training loss: 2.21966814994812
Validation loss: 1.9812920439627864

Epoch: 6| Step: 13
Training loss: 2.419890880584717
Validation loss: 1.9878017453737156

Epoch: 407| Step: 0
Training loss: 1.7987022399902344
Validation loss: 1.9937841738423994

Epoch: 6| Step: 1
Training loss: 1.514889121055603
Validation loss: 1.9877412780638664

Epoch: 6| Step: 2
Training loss: 2.396275520324707
Validation loss: 2.0011865297953286

Epoch: 6| Step: 3
Training loss: 2.2812278270721436
Validation loss: 2.0013248471803564

Epoch: 6| Step: 4
Training loss: 2.225464344024658
Validation loss: 1.9900297118771462

Epoch: 6| Step: 5
Training loss: 2.637158155441284
Validation loss: 1.9963731637565039

Epoch: 6| Step: 6
Training loss: 1.6516706943511963
Validation loss: 2.000781165656223

Epoch: 6| Step: 7
Training loss: 2.329028844833374
Validation loss: 1.995318023107385

Epoch: 6| Step: 8
Training loss: 1.8230818510055542
Validation loss: 2.0050711119046776

Epoch: 6| Step: 9
Training loss: 1.6350457668304443
Validation loss: 1.9997780169210126

Epoch: 6| Step: 10
Training loss: 1.6779582500457764
Validation loss: 1.9851177687286048

Epoch: 6| Step: 11
Training loss: 2.222750425338745
Validation loss: 1.9833970915886663

Epoch: 6| Step: 12
Training loss: 1.9181535243988037
Validation loss: 1.9865090706015145

Epoch: 6| Step: 13
Training loss: 1.0839051008224487
Validation loss: 1.9876399245313419

Epoch: 408| Step: 0
Training loss: 2.260378360748291
Validation loss: 1.992785902433498

Epoch: 6| Step: 1
Training loss: 2.1519999504089355
Validation loss: 1.9906527765335575

Epoch: 6| Step: 2
Training loss: 2.273115873336792
Validation loss: 1.9910053719756424

Epoch: 6| Step: 3
Training loss: 2.3386945724487305
Validation loss: 1.996832114393993

Epoch: 6| Step: 4
Training loss: 1.9388129711151123
Validation loss: 1.994186742331392

Epoch: 6| Step: 5
Training loss: 2.2947378158569336
Validation loss: 1.9830519178862214

Epoch: 6| Step: 6
Training loss: 1.806343674659729
Validation loss: 1.9871736444452757

Epoch: 6| Step: 7
Training loss: 1.860818862915039
Validation loss: 1.9915946068302277

Epoch: 6| Step: 8
Training loss: 0.48131924867630005
Validation loss: 1.978691803511753

Epoch: 6| Step: 9
Training loss: 2.0900285243988037
Validation loss: 1.994373902197807

Epoch: 6| Step: 10
Training loss: 1.5437572002410889
Validation loss: 1.985804678291403

Epoch: 6| Step: 11
Training loss: 2.357639789581299
Validation loss: 1.9853503588707215

Epoch: 6| Step: 12
Training loss: 2.122152328491211
Validation loss: 1.9793483967422156

Epoch: 6| Step: 13
Training loss: 2.0925416946411133
Validation loss: 1.9831847836894374

Epoch: 409| Step: 0
Training loss: 1.7510777711868286
Validation loss: 1.9915635765239756

Epoch: 6| Step: 1
Training loss: 1.4823132753372192
Validation loss: 1.9993909764033493

Epoch: 6| Step: 2
Training loss: 1.848990797996521
Validation loss: 2.001983415695929

Epoch: 6| Step: 3
Training loss: 2.4238674640655518
Validation loss: 1.9972599642251128

Epoch: 6| Step: 4
Training loss: 1.982933759689331
Validation loss: 1.9834051209111367

Epoch: 6| Step: 5
Training loss: 1.520202398300171
Validation loss: 2.011016276574904

Epoch: 6| Step: 6
Training loss: 2.0915002822875977
Validation loss: 1.9767880183394237

Epoch: 6| Step: 7
Training loss: 2.1736948490142822
Validation loss: 1.987925853780521

Epoch: 6| Step: 8
Training loss: 2.022521734237671
Validation loss: 1.9976732551410634

Epoch: 6| Step: 9
Training loss: 2.607095718383789
Validation loss: 1.9978672163460844

Epoch: 6| Step: 10
Training loss: 1.471426248550415
Validation loss: 1.9951269626617432

Epoch: 6| Step: 11
Training loss: 1.4971954822540283
Validation loss: 1.9914658864339192

Epoch: 6| Step: 12
Training loss: 2.071653366088867
Validation loss: 1.990687636918919

Epoch: 6| Step: 13
Training loss: 2.7052013874053955
Validation loss: 1.9950990266697382

Epoch: 410| Step: 0
Training loss: 2.160823345184326
Validation loss: 1.9973946156040314

Epoch: 6| Step: 1
Training loss: 2.2915759086608887
Validation loss: 1.9984122655724967

Epoch: 6| Step: 2
Training loss: 1.6043363809585571
Validation loss: 1.9985530863526046

Epoch: 6| Step: 3
Training loss: 1.1240594387054443
Validation loss: 2.0083165168762207

Epoch: 6| Step: 4
Training loss: 2.5377182960510254
Validation loss: 2.006352943758811

Epoch: 6| Step: 5
Training loss: 2.9152650833129883
Validation loss: 2.003683464501494

Epoch: 6| Step: 6
Training loss: 1.8194597959518433
Validation loss: 1.9976932207743328

Epoch: 6| Step: 7
Training loss: 1.3227565288543701
Validation loss: 1.9950770678058747

Epoch: 6| Step: 8
Training loss: 1.6547870635986328
Validation loss: 1.999782290509952

Epoch: 6| Step: 9
Training loss: 1.8533886671066284
Validation loss: 1.9747640535395632

Epoch: 6| Step: 10
Training loss: 1.7509698867797852
Validation loss: 1.9709104581545758

Epoch: 6| Step: 11
Training loss: 2.325294256210327
Validation loss: 1.9925737227163007

Epoch: 6| Step: 12
Training loss: 1.9169559478759766
Validation loss: 1.9804508583520049

Epoch: 6| Step: 13
Training loss: 2.162425994873047
Validation loss: 1.99036415033443

Epoch: 411| Step: 0
Training loss: 2.112226963043213
Validation loss: 2.001120323775917

Epoch: 6| Step: 1
Training loss: 2.4793295860290527
Validation loss: 1.9873948302320255

Epoch: 6| Step: 2
Training loss: 1.647119164466858
Validation loss: 1.9874228508241716

Epoch: 6| Step: 3
Training loss: 2.2529733180999756
Validation loss: 2.0066686432848693

Epoch: 6| Step: 4
Training loss: 2.8243961334228516
Validation loss: 2.0056494410319994

Epoch: 6| Step: 5
Training loss: 1.8428709506988525
Validation loss: 1.9891432562182028

Epoch: 6| Step: 6
Training loss: 1.4436678886413574
Validation loss: 1.9888808804173623

Epoch: 6| Step: 7
Training loss: 2.1645851135253906
Validation loss: 1.9960177072914698

Epoch: 6| Step: 8
Training loss: 1.8739955425262451
Validation loss: 1.9882946411768596

Epoch: 6| Step: 9
Training loss: 2.2706503868103027
Validation loss: 1.9987653173426145

Epoch: 6| Step: 10
Training loss: 1.6963390111923218
Validation loss: 1.9976487980094007

Epoch: 6| Step: 11
Training loss: 1.2785882949829102
Validation loss: 1.9671113080875848

Epoch: 6| Step: 12
Training loss: 1.1684882640838623
Validation loss: 1.9937875219570693

Epoch: 6| Step: 13
Training loss: 2.8880863189697266
Validation loss: 1.980413338189484

Epoch: 412| Step: 0
Training loss: 1.9758524894714355
Validation loss: 1.9918781352299515

Epoch: 6| Step: 1
Training loss: 1.8836454153060913
Validation loss: 2.001044104176183

Epoch: 6| Step: 2
Training loss: 1.9190912246704102
Validation loss: 2.0024152789064633

Epoch: 6| Step: 3
Training loss: 1.9618573188781738
Validation loss: 2.0029797989835023

Epoch: 6| Step: 4
Training loss: 1.5257835388183594
Validation loss: 2.004826440606066

Epoch: 6| Step: 5
Training loss: 2.11953067779541
Validation loss: 1.9921697352522163

Epoch: 6| Step: 6
Training loss: 2.0267276763916016
Validation loss: 1.986851316626354

Epoch: 6| Step: 7
Training loss: 1.9306213855743408
Validation loss: 1.9902523038207844

Epoch: 6| Step: 8
Training loss: 1.991093397140503
Validation loss: 1.9641576710567679

Epoch: 6| Step: 9
Training loss: 1.2169064283370972
Validation loss: 1.9629568464012557

Epoch: 6| Step: 10
Training loss: 2.475836992263794
Validation loss: 1.9679336829852032

Epoch: 6| Step: 11
Training loss: 1.6586709022521973
Validation loss: 1.9540155010838662

Epoch: 6| Step: 12
Training loss: 2.788581371307373
Validation loss: 1.968243937338552

Epoch: 6| Step: 13
Training loss: 1.9875212907791138
Validation loss: 1.9780236546711256

Epoch: 413| Step: 0
Training loss: 2.0062522888183594
Validation loss: 1.985441815468573

Epoch: 6| Step: 1
Training loss: 1.791452169418335
Validation loss: 1.9769378246799592

Epoch: 6| Step: 2
Training loss: 2.329866886138916
Validation loss: 2.0058631204789683

Epoch: 6| Step: 3
Training loss: 2.0690083503723145
Validation loss: 2.0029234475986932

Epoch: 6| Step: 4
Training loss: 1.7056461572647095
Validation loss: 1.9981411810844176

Epoch: 6| Step: 5
Training loss: 1.6880223751068115
Validation loss: 1.993407964706421

Epoch: 6| Step: 6
Training loss: 2.2496137619018555
Validation loss: 1.987453600411774

Epoch: 6| Step: 7
Training loss: 2.281395196914673
Validation loss: 1.973403944764086

Epoch: 6| Step: 8
Training loss: 1.9916331768035889
Validation loss: 1.987671991830231

Epoch: 6| Step: 9
Training loss: 1.8569602966308594
Validation loss: 1.9737122597232941

Epoch: 6| Step: 10
Training loss: 1.4383161067962646
Validation loss: 1.9975463805660125

Epoch: 6| Step: 11
Training loss: 2.2752599716186523
Validation loss: 1.9779484759094894

Epoch: 6| Step: 12
Training loss: 1.9922831058502197
Validation loss: 1.9797052311640915

Epoch: 6| Step: 13
Training loss: 1.3920903205871582
Validation loss: 1.9960186122566141

Epoch: 414| Step: 0
Training loss: 1.603804588317871
Validation loss: 2.0124622596207487

Epoch: 6| Step: 1
Training loss: 2.323367118835449
Validation loss: 2.0467160030077864

Epoch: 6| Step: 2
Training loss: 1.940259337425232
Validation loss: 2.0360372681771555

Epoch: 6| Step: 3
Training loss: 2.504779577255249
Validation loss: 2.035826272861932

Epoch: 6| Step: 4
Training loss: 2.064140796661377
Validation loss: 2.023220862111738

Epoch: 6| Step: 5
Training loss: 1.7224624156951904
Validation loss: 2.0136095298233854

Epoch: 6| Step: 6
Training loss: 2.2679672241210938
Validation loss: 2.024220969087334

Epoch: 6| Step: 7
Training loss: 1.4197887182235718
Validation loss: 2.0023663877159037

Epoch: 6| Step: 8
Training loss: 2.013578414916992
Validation loss: 2.012613711818572

Epoch: 6| Step: 9
Training loss: 2.1896491050720215
Validation loss: 1.994761952789881

Epoch: 6| Step: 10
Training loss: 1.5621446371078491
Validation loss: 1.9909792228411602

Epoch: 6| Step: 11
Training loss: 2.3806233406066895
Validation loss: 1.9863665949913762

Epoch: 6| Step: 12
Training loss: 1.6759650707244873
Validation loss: 1.9777062195603565

Epoch: 6| Step: 13
Training loss: 1.536711573600769
Validation loss: 1.9991974061535251

Epoch: 415| Step: 0
Training loss: 1.8712520599365234
Validation loss: 1.9856308737108785

Epoch: 6| Step: 1
Training loss: 2.0867857933044434
Validation loss: 1.981098618558658

Epoch: 6| Step: 2
Training loss: 2.2011256217956543
Validation loss: 1.982070538305467

Epoch: 6| Step: 3
Training loss: 1.9560827016830444
Validation loss: 1.9848426695792907

Epoch: 6| Step: 4
Training loss: 2.058563232421875
Validation loss: 1.9841207124853646

Epoch: 6| Step: 5
Training loss: 1.5301880836486816
Validation loss: 1.9950770178148824

Epoch: 6| Step: 6
Training loss: 2.0908708572387695
Validation loss: 1.9846050867470362

Epoch: 6| Step: 7
Training loss: 2.304201126098633
Validation loss: 1.9758630055253223

Epoch: 6| Step: 8
Training loss: 1.5085655450820923
Validation loss: 1.985225026325513

Epoch: 6| Step: 9
Training loss: 1.909452199935913
Validation loss: 1.983452316253416

Epoch: 6| Step: 10
Training loss: 1.95448637008667
Validation loss: 1.989856194424373

Epoch: 6| Step: 11
Training loss: 2.0248522758483887
Validation loss: 1.9814106136239984

Epoch: 6| Step: 12
Training loss: 1.7633757591247559
Validation loss: 1.9745936393737793

Epoch: 6| Step: 13
Training loss: 2.0384926795959473
Validation loss: 1.9795149346833587

Epoch: 416| Step: 0
Training loss: 2.4594507217407227
Validation loss: 1.9616494063408143

Epoch: 6| Step: 1
Training loss: 2.032802104949951
Validation loss: 1.9825096463644376

Epoch: 6| Step: 2
Training loss: 1.7368988990783691
Validation loss: 1.9632790934654973

Epoch: 6| Step: 3
Training loss: 1.6432650089263916
Validation loss: 1.9757067106103385

Epoch: 6| Step: 4
Training loss: 2.215543508529663
Validation loss: 1.9641135200377433

Epoch: 6| Step: 5
Training loss: 2.0384771823883057
Validation loss: 1.9951520068671114

Epoch: 6| Step: 6
Training loss: 1.82813560962677
Validation loss: 2.0016286091137956

Epoch: 6| Step: 7
Training loss: 1.5902844667434692
Validation loss: 1.9882011593029063

Epoch: 6| Step: 8
Training loss: 1.3143134117126465
Validation loss: 2.011614740535777

Epoch: 6| Step: 9
Training loss: 2.524944543838501
Validation loss: 1.992059382059241

Epoch: 6| Step: 10
Training loss: 1.709639310836792
Validation loss: 2.010474581872263

Epoch: 6| Step: 11
Training loss: 1.6499965190887451
Validation loss: 1.9924113558184715

Epoch: 6| Step: 12
Training loss: 2.105616569519043
Validation loss: 2.0054852552311395

Epoch: 6| Step: 13
Training loss: 2.924677610397339
Validation loss: 1.9709401489585958

Epoch: 417| Step: 0
Training loss: 1.8880932331085205
Validation loss: 1.986145104131391

Epoch: 6| Step: 1
Training loss: 1.788804531097412
Validation loss: 1.9800109709462812

Epoch: 6| Step: 2
Training loss: 2.627934694290161
Validation loss: 1.9751025963855047

Epoch: 6| Step: 3
Training loss: 1.8451545238494873
Validation loss: 1.9844032051742717

Epoch: 6| Step: 4
Training loss: 1.7374684810638428
Validation loss: 1.9864015681769258

Epoch: 6| Step: 5
Training loss: 1.3969318866729736
Validation loss: 1.96833546187288

Epoch: 6| Step: 6
Training loss: 1.9010891914367676
Validation loss: 1.9862381360864128

Epoch: 6| Step: 7
Training loss: 1.2471081018447876
Validation loss: 1.9873340129852295

Epoch: 6| Step: 8
Training loss: 1.8769278526306152
Validation loss: 1.9922291745421707

Epoch: 6| Step: 9
Training loss: 2.6521403789520264
Validation loss: 1.9970205701807493

Epoch: 6| Step: 10
Training loss: 2.0305380821228027
Validation loss: 1.9944761709500385

Epoch: 6| Step: 11
Training loss: 2.0917675495147705
Validation loss: 1.9990096476770216

Epoch: 6| Step: 12
Training loss: 2.6046156883239746
Validation loss: 1.9894684027600031

Epoch: 6| Step: 13
Training loss: 1.3208177089691162
Validation loss: 1.9717861298591859

Epoch: 418| Step: 0
Training loss: 2.2416369915008545
Validation loss: 1.9768694857115388

Epoch: 6| Step: 1
Training loss: 1.835541844367981
Validation loss: 1.9658454105418215

Epoch: 6| Step: 2
Training loss: 1.859217882156372
Validation loss: 1.9711835230550458

Epoch: 6| Step: 3
Training loss: 3.090941905975342
Validation loss: 1.968035359536448

Epoch: 6| Step: 4
Training loss: 2.658952236175537
Validation loss: 1.9956794849006079

Epoch: 6| Step: 5
Training loss: 1.5401279926300049
Validation loss: 1.9741072218905213

Epoch: 6| Step: 6
Training loss: 1.5811454057693481
Validation loss: 1.9926653908145042

Epoch: 6| Step: 7
Training loss: 2.003784418106079
Validation loss: 1.9908348847461004

Epoch: 6| Step: 8
Training loss: 1.127785325050354
Validation loss: 1.9731644738105036

Epoch: 6| Step: 9
Training loss: 1.8784030675888062
Validation loss: 1.99946298778698

Epoch: 6| Step: 10
Training loss: 1.458944320678711
Validation loss: 1.9860078609117897

Epoch: 6| Step: 11
Training loss: 1.7913283109664917
Validation loss: 1.998059767548756

Epoch: 6| Step: 12
Training loss: 2.057753562927246
Validation loss: 1.9904617314697595

Epoch: 6| Step: 13
Training loss: 2.2231991291046143
Validation loss: 2.006777455729823

Epoch: 419| Step: 0
Training loss: 2.017606019973755
Validation loss: 1.9981500320537116

Epoch: 6| Step: 1
Training loss: 1.860875129699707
Validation loss: 1.9840489023475236

Epoch: 6| Step: 2
Training loss: 1.533520221710205
Validation loss: 1.9955209365455053

Epoch: 6| Step: 3
Training loss: 2.4556691646575928
Validation loss: 1.9813931372857863

Epoch: 6| Step: 4
Training loss: 1.8521314859390259
Validation loss: 1.9833672995208411

Epoch: 6| Step: 5
Training loss: 1.613771677017212
Validation loss: 1.9970234106945735

Epoch: 6| Step: 6
Training loss: 2.6136555671691895
Validation loss: 1.9951613180098995

Epoch: 6| Step: 7
Training loss: 1.5030120611190796
Validation loss: 2.0113290394506147

Epoch: 6| Step: 8
Training loss: 1.8476829528808594
Validation loss: 2.021961769750041

Epoch: 6| Step: 9
Training loss: 1.8007526397705078
Validation loss: 2.0092723959235737

Epoch: 6| Step: 10
Training loss: 2.814183235168457
Validation loss: 1.9931149251999394

Epoch: 6| Step: 11
Training loss: 2.025702953338623
Validation loss: 1.9889442266956452

Epoch: 6| Step: 12
Training loss: 1.756925344467163
Validation loss: 1.9633411104961107

Epoch: 6| Step: 13
Training loss: 1.4234799146652222
Validation loss: 1.9683770210512224

Epoch: 420| Step: 0
Training loss: 2.141643524169922
Validation loss: 1.9730444133922618

Epoch: 6| Step: 1
Training loss: 2.2539119720458984
Validation loss: 1.9701214093033985

Epoch: 6| Step: 2
Training loss: 2.562406539916992
Validation loss: 1.9670630552435433

Epoch: 6| Step: 3
Training loss: 1.8846783638000488
Validation loss: 1.9861581530622257

Epoch: 6| Step: 4
Training loss: 1.7238446474075317
Validation loss: 1.9819547207124772

Epoch: 6| Step: 5
Training loss: 1.5537002086639404
Validation loss: 1.976479225261237

Epoch: 6| Step: 6
Training loss: 2.0723776817321777
Validation loss: 1.989782464119696

Epoch: 6| Step: 7
Training loss: 1.4109575748443604
Validation loss: 1.990030683496947

Epoch: 6| Step: 8
Training loss: 1.657395362854004
Validation loss: 1.9836877597275602

Epoch: 6| Step: 9
Training loss: 1.7169833183288574
Validation loss: 1.9947967734388126

Epoch: 6| Step: 10
Training loss: 1.7990543842315674
Validation loss: 2.0045101693881455

Epoch: 6| Step: 11
Training loss: 2.390688896179199
Validation loss: 2.010001601711396

Epoch: 6| Step: 12
Training loss: 1.6472277641296387
Validation loss: 2.007751162334155

Epoch: 6| Step: 13
Training loss: 2.5737314224243164
Validation loss: 2.00983771457467

Epoch: 421| Step: 0
Training loss: 1.5848040580749512
Validation loss: 1.9784181643557806

Epoch: 6| Step: 1
Training loss: 2.3508315086364746
Validation loss: 1.9826962050571237

Epoch: 6| Step: 2
Training loss: 1.7125828266143799
Validation loss: 1.9798280449323757

Epoch: 6| Step: 3
Training loss: 2.011420249938965
Validation loss: 1.9875930919442126

Epoch: 6| Step: 4
Training loss: 1.637069582939148
Validation loss: 1.9585524246256838

Epoch: 6| Step: 5
Training loss: 2.113391876220703
Validation loss: 1.9549050741298224

Epoch: 6| Step: 6
Training loss: 1.9269330501556396
Validation loss: 1.958048947395817

Epoch: 6| Step: 7
Training loss: 1.8694686889648438
Validation loss: 1.9682467393977667

Epoch: 6| Step: 8
Training loss: 2.158924102783203
Validation loss: 1.9571764828056417

Epoch: 6| Step: 9
Training loss: 1.8179895877838135
Validation loss: 1.9559396261809974

Epoch: 6| Step: 10
Training loss: 2.3290867805480957
Validation loss: 1.9630956444689023

Epoch: 6| Step: 11
Training loss: 2.1872105598449707
Validation loss: 1.9785431444004018

Epoch: 6| Step: 12
Training loss: 2.0090928077697754
Validation loss: 1.972594791843045

Epoch: 6| Step: 13
Training loss: 0.6917222738265991
Validation loss: 1.9892453403883084

Epoch: 422| Step: 0
Training loss: 2.0946285724639893
Validation loss: 1.978787729817052

Epoch: 6| Step: 1
Training loss: 2.1626131534576416
Validation loss: 2.0018322416531142

Epoch: 6| Step: 2
Training loss: 2.169389247894287
Validation loss: 2.0067842468138664

Epoch: 6| Step: 3
Training loss: 1.769942045211792
Validation loss: 2.0163545993066605

Epoch: 6| Step: 4
Training loss: 2.4061474800109863
Validation loss: 1.9996313792403027

Epoch: 6| Step: 5
Training loss: 2.2537317276000977
Validation loss: 1.9926114877065022

Epoch: 6| Step: 6
Training loss: 1.4752119779586792
Validation loss: 1.9761886737679923

Epoch: 6| Step: 7
Training loss: 2.163939952850342
Validation loss: 1.9638081481379848

Epoch: 6| Step: 8
Training loss: 1.6365551948547363
Validation loss: 1.9858215906286751

Epoch: 6| Step: 9
Training loss: 2.4048261642456055
Validation loss: 1.9854235085107947

Epoch: 6| Step: 10
Training loss: 1.430802583694458
Validation loss: 1.9871515074083883

Epoch: 6| Step: 11
Training loss: 1.757629632949829
Validation loss: 1.9846777736499746

Epoch: 6| Step: 12
Training loss: 1.7503907680511475
Validation loss: 1.9759440498967324

Epoch: 6| Step: 13
Training loss: 1.7619671821594238
Validation loss: 1.9774134274451964

Epoch: 423| Step: 0
Training loss: 1.8055975437164307
Validation loss: 1.972449798737803

Epoch: 6| Step: 1
Training loss: 1.4444109201431274
Validation loss: 1.9787983561074862

Epoch: 6| Step: 2
Training loss: 2.202361822128296
Validation loss: 1.992513322061108

Epoch: 6| Step: 3
Training loss: 2.2162985801696777
Validation loss: 2.0025788686608754

Epoch: 6| Step: 4
Training loss: 2.0355300903320312
Validation loss: 2.0111516342368176

Epoch: 6| Step: 5
Training loss: 2.1675331592559814
Validation loss: 2.0105265494315856

Epoch: 6| Step: 6
Training loss: 1.9151244163513184
Validation loss: 2.013258813529886

Epoch: 6| Step: 7
Training loss: 1.8631887435913086
Validation loss: 2.0194390973737164

Epoch: 6| Step: 8
Training loss: 1.8986531496047974
Validation loss: 1.977621897574394

Epoch: 6| Step: 9
Training loss: 1.7814921140670776
Validation loss: 1.9752627700887702

Epoch: 6| Step: 10
Training loss: 2.4068336486816406
Validation loss: 1.9777546903138519

Epoch: 6| Step: 11
Training loss: 1.6679856777191162
Validation loss: 1.9797418232887023

Epoch: 6| Step: 12
Training loss: 1.9691526889801025
Validation loss: 1.9760419322598366

Epoch: 6| Step: 13
Training loss: 1.4880082607269287
Validation loss: 1.9809166013553579

Epoch: 424| Step: 0
Training loss: 1.7824347019195557
Validation loss: 1.9684950331205964

Epoch: 6| Step: 1
Training loss: 1.741853952407837
Validation loss: 1.9743999563237673

Epoch: 6| Step: 2
Training loss: 2.0685276985168457
Validation loss: 1.9916591105922576

Epoch: 6| Step: 3
Training loss: 2.064643621444702
Validation loss: 1.9833763748086908

Epoch: 6| Step: 4
Training loss: 1.908541202545166
Validation loss: 1.991378645743093

Epoch: 6| Step: 5
Training loss: 1.3780004978179932
Validation loss: 2.0072412516481135

Epoch: 6| Step: 6
Training loss: 2.1279983520507812
Validation loss: 2.007520224458428

Epoch: 6| Step: 7
Training loss: 1.8972443342208862
Validation loss: 2.0083517618076776

Epoch: 6| Step: 8
Training loss: 1.8750362396240234
Validation loss: 1.9913104016293761

Epoch: 6| Step: 9
Training loss: 1.6337525844573975
Validation loss: 2.0042014109191073

Epoch: 6| Step: 10
Training loss: 1.9618926048278809
Validation loss: 1.9821668376204788

Epoch: 6| Step: 11
Training loss: 1.9328677654266357
Validation loss: 1.9678465922673543

Epoch: 6| Step: 12
Training loss: 2.3771533966064453
Validation loss: 1.9743462249796877

Epoch: 6| Step: 13
Training loss: 2.7485814094543457
Validation loss: 1.9782324798645512

Epoch: 425| Step: 0
Training loss: 2.1026265621185303
Validation loss: 1.9803553358201058

Epoch: 6| Step: 1
Training loss: 1.7663183212280273
Validation loss: 1.9730637970791067

Epoch: 6| Step: 2
Training loss: 1.528796672821045
Validation loss: 1.9630759198178527

Epoch: 6| Step: 3
Training loss: 1.5920169353485107
Validation loss: 1.9905052261967813

Epoch: 6| Step: 4
Training loss: 1.930907964706421
Validation loss: 1.9889044877021544

Epoch: 6| Step: 5
Training loss: 2.670499563217163
Validation loss: 1.9862958051825081

Epoch: 6| Step: 6
Training loss: 2.3782191276550293
Validation loss: 1.9818725175754999

Epoch: 6| Step: 7
Training loss: 2.4804024696350098
Validation loss: 1.9786482113663868

Epoch: 6| Step: 8
Training loss: 1.544442892074585
Validation loss: 1.9799309238310783

Epoch: 6| Step: 9
Training loss: 1.4371144771575928
Validation loss: 1.9744166071696947

Epoch: 6| Step: 10
Training loss: 1.81077241897583
Validation loss: 1.9813884881234938

Epoch: 6| Step: 11
Training loss: 2.379409074783325
Validation loss: 1.9799777243726997

Epoch: 6| Step: 12
Training loss: 1.5425496101379395
Validation loss: 1.9924166625545872

Epoch: 6| Step: 13
Training loss: 1.8872854709625244
Validation loss: 1.982757459404648

Epoch: 426| Step: 0
Training loss: 2.381586790084839
Validation loss: 1.9707273026948333

Epoch: 6| Step: 1
Training loss: 1.665508508682251
Validation loss: 1.9748603387545514

Epoch: 6| Step: 2
Training loss: 2.018756151199341
Validation loss: 1.9838136191009192

Epoch: 6| Step: 3
Training loss: 2.376420021057129
Validation loss: 2.0017964122115925

Epoch: 6| Step: 4
Training loss: 1.9561831951141357
Validation loss: 2.0088349773037817

Epoch: 6| Step: 5
Training loss: 1.7415730953216553
Validation loss: 1.9982608479838218

Epoch: 6| Step: 6
Training loss: 1.353992223739624
Validation loss: 1.9701514461989045

Epoch: 6| Step: 7
Training loss: 2.3872525691986084
Validation loss: 1.9753327369689941

Epoch: 6| Step: 8
Training loss: 2.092360496520996
Validation loss: 1.9696349097836403

Epoch: 6| Step: 9
Training loss: 1.7749197483062744
Validation loss: 1.9721700440170944

Epoch: 6| Step: 10
Training loss: 1.8035590648651123
Validation loss: 1.9656956734195832

Epoch: 6| Step: 11
Training loss: 1.865570306777954
Validation loss: 1.9848514885030768

Epoch: 6| Step: 12
Training loss: 2.001008987426758
Validation loss: 1.9838542963868828

Epoch: 6| Step: 13
Training loss: 1.29533851146698
Validation loss: 1.9853333145059564

Epoch: 427| Step: 0
Training loss: 1.5732722282409668
Validation loss: 2.00695373165992

Epoch: 6| Step: 1
Training loss: 2.3571982383728027
Validation loss: 2.0204704307740733

Epoch: 6| Step: 2
Training loss: 1.3731435537338257
Validation loss: 2.0148100878602717

Epoch: 6| Step: 3
Training loss: 1.8898429870605469
Validation loss: 2.0204495870938866

Epoch: 6| Step: 4
Training loss: 1.6782011985778809
Validation loss: 2.0474886458407164

Epoch: 6| Step: 5
Training loss: 2.4346981048583984
Validation loss: 2.0170215073452202

Epoch: 6| Step: 6
Training loss: 1.964287519454956
Validation loss: 2.0183396185598066

Epoch: 6| Step: 7
Training loss: 1.5933668613433838
Validation loss: 2.0162723936060423

Epoch: 6| Step: 8
Training loss: 1.104307770729065
Validation loss: 2.0032678816908147

Epoch: 6| Step: 9
Training loss: 1.9506266117095947
Validation loss: 1.9732157876414638

Epoch: 6| Step: 10
Training loss: 2.845226287841797
Validation loss: 1.9928062974765737

Epoch: 6| Step: 11
Training loss: 2.044570207595825
Validation loss: 1.9746710446573073

Epoch: 6| Step: 12
Training loss: 2.120283842086792
Validation loss: 1.9678415918862948

Epoch: 6| Step: 13
Training loss: 2.231154441833496
Validation loss: 1.962831412592242

Epoch: 428| Step: 0
Training loss: 2.1227967739105225
Validation loss: 1.9720404494193293

Epoch: 6| Step: 1
Training loss: 2.19389009475708
Validation loss: 1.9688537825820267

Epoch: 6| Step: 2
Training loss: 2.0360021591186523
Validation loss: 1.9677978484861312

Epoch: 6| Step: 3
Training loss: 2.4573428630828857
Validation loss: 1.9616062384779736

Epoch: 6| Step: 4
Training loss: 1.6009624004364014
Validation loss: 1.9660092015420236

Epoch: 6| Step: 5
Training loss: 1.150728702545166
Validation loss: 1.98810673657284

Epoch: 6| Step: 6
Training loss: 1.6592210531234741
Validation loss: 1.9718090488064675

Epoch: 6| Step: 7
Training loss: 1.8338217735290527
Validation loss: 1.9735366016305902

Epoch: 6| Step: 8
Training loss: 1.85993492603302
Validation loss: 1.9776307998165008

Epoch: 6| Step: 9
Training loss: 1.7525404691696167
Validation loss: 1.9699032768126457

Epoch: 6| Step: 10
Training loss: 1.9015109539031982
Validation loss: 1.9742129284848449

Epoch: 6| Step: 11
Training loss: 1.6940457820892334
Validation loss: 1.9705809470145934

Epoch: 6| Step: 12
Training loss: 2.428649425506592
Validation loss: 1.976332567071402

Epoch: 6| Step: 13
Training loss: 2.4099557399749756
Validation loss: 1.971486714578444

Epoch: 429| Step: 0
Training loss: 1.9024848937988281
Validation loss: 1.9812341761845413

Epoch: 6| Step: 1
Training loss: 2.3555445671081543
Validation loss: 1.9688761388101885

Epoch: 6| Step: 2
Training loss: 2.2512989044189453
Validation loss: 1.9648309971696587

Epoch: 6| Step: 3
Training loss: 1.7613284587860107
Validation loss: 1.9607462165176228

Epoch: 6| Step: 4
Training loss: 1.521553874015808
Validation loss: 1.9660421853424401

Epoch: 6| Step: 5
Training loss: 1.816832423210144
Validation loss: 1.9522099469297676

Epoch: 6| Step: 6
Training loss: 1.7077950239181519
Validation loss: 1.9661827651403283

Epoch: 6| Step: 7
Training loss: 1.758142113685608
Validation loss: 1.9597915269995247

Epoch: 6| Step: 8
Training loss: 2.627941131591797
Validation loss: 1.9662181843993485

Epoch: 6| Step: 9
Training loss: 1.3631714582443237
Validation loss: 1.952762988305861

Epoch: 6| Step: 10
Training loss: 2.280848503112793
Validation loss: 1.9730315426344514

Epoch: 6| Step: 11
Training loss: 1.822434902191162
Validation loss: 1.9637182784336868

Epoch: 6| Step: 12
Training loss: 1.5679666996002197
Validation loss: 1.9630721743388841

Epoch: 6| Step: 13
Training loss: 1.8676084280014038
Validation loss: 1.952184982197259

Epoch: 430| Step: 0
Training loss: 1.7701239585876465
Validation loss: 1.9708984923619095

Epoch: 6| Step: 1
Training loss: 2.4612488746643066
Validation loss: 1.9775948806475567

Epoch: 6| Step: 2
Training loss: 2.110983371734619
Validation loss: 1.9667792243342246

Epoch: 6| Step: 3
Training loss: 1.5477216243743896
Validation loss: 1.9683578629647531

Epoch: 6| Step: 4
Training loss: 1.9804545640945435
Validation loss: 1.96154966662007

Epoch: 6| Step: 5
Training loss: 2.0974063873291016
Validation loss: 1.9637970603922361

Epoch: 6| Step: 6
Training loss: 2.3150081634521484
Validation loss: 1.9628706055302774

Epoch: 6| Step: 7
Training loss: 1.598859429359436
Validation loss: 1.9715206802532237

Epoch: 6| Step: 8
Training loss: 1.9877328872680664
Validation loss: 1.969286617412362

Epoch: 6| Step: 9
Training loss: 1.9131641387939453
Validation loss: 1.9614828530178274

Epoch: 6| Step: 10
Training loss: 1.326974868774414
Validation loss: 1.9536443320653771

Epoch: 6| Step: 11
Training loss: 2.2706031799316406
Validation loss: 1.968739499327957

Epoch: 6| Step: 12
Training loss: 1.190485954284668
Validation loss: 1.960987473046908

Epoch: 6| Step: 13
Training loss: 2.3660247325897217
Validation loss: 1.9632759017329062

Epoch: 431| Step: 0
Training loss: 2.409153461456299
Validation loss: 1.970455410659954

Epoch: 6| Step: 1
Training loss: 1.6710054874420166
Validation loss: 1.971367791134824

Epoch: 6| Step: 2
Training loss: 1.3119934797286987
Validation loss: 1.9877670631613782

Epoch: 6| Step: 3
Training loss: 2.1394314765930176
Validation loss: 1.9990648402962634

Epoch: 6| Step: 4
Training loss: 1.9281928539276123
Validation loss: 2.0122143978713662

Epoch: 6| Step: 5
Training loss: 1.7308529615402222
Validation loss: 2.0056877033684843

Epoch: 6| Step: 6
Training loss: 2.2367732524871826
Validation loss: 1.9908637667215

Epoch: 6| Step: 7
Training loss: 1.5734940767288208
Validation loss: 1.9784221879897579

Epoch: 6| Step: 8
Training loss: 1.9019006490707397
Validation loss: 1.9937052931836856

Epoch: 6| Step: 9
Training loss: 1.3585747480392456
Validation loss: 1.9871409964817826

Epoch: 6| Step: 10
Training loss: 1.752638339996338
Validation loss: 1.9717821741616854

Epoch: 6| Step: 11
Training loss: 1.8798046112060547
Validation loss: 1.962982916062878

Epoch: 6| Step: 12
Training loss: 2.681468963623047
Validation loss: 1.9645340622112315

Epoch: 6| Step: 13
Training loss: 2.4457638263702393
Validation loss: 1.9562778883082892

Epoch: 432| Step: 0
Training loss: 2.005498170852661
Validation loss: 1.9599736057302004

Epoch: 6| Step: 1
Training loss: 2.1844072341918945
Validation loss: 1.9416520236640848

Epoch: 6| Step: 2
Training loss: 2.031643867492676
Validation loss: 1.9476400780421432

Epoch: 6| Step: 3
Training loss: 2.567626476287842
Validation loss: 1.950385243661942

Epoch: 6| Step: 4
Training loss: 1.6770603656768799
Validation loss: 1.959273599809216

Epoch: 6| Step: 5
Training loss: 1.7094112634658813
Validation loss: 1.950762071917134

Epoch: 6| Step: 6
Training loss: 1.5736737251281738
Validation loss: 1.9490352202487249

Epoch: 6| Step: 7
Training loss: 1.79799485206604
Validation loss: 1.956713504688714

Epoch: 6| Step: 8
Training loss: 1.315758466720581
Validation loss: 1.9450592917780722

Epoch: 6| Step: 9
Training loss: 2.038060188293457
Validation loss: 1.9630259006254134

Epoch: 6| Step: 10
Training loss: 0.8847132921218872
Validation loss: 1.9772930247809297

Epoch: 6| Step: 11
Training loss: 2.987730026245117
Validation loss: 1.9810051174574002

Epoch: 6| Step: 12
Training loss: 1.8354634046554565
Validation loss: 1.985009278020551

Epoch: 6| Step: 13
Training loss: 2.51568603515625
Validation loss: 1.9812120609385993

Epoch: 433| Step: 0
Training loss: 1.9099851846694946
Validation loss: 1.9670348487874514

Epoch: 6| Step: 1
Training loss: 2.0803616046905518
Validation loss: 1.9673700614642071

Epoch: 6| Step: 2
Training loss: 1.549496054649353
Validation loss: 1.9504428525124826

Epoch: 6| Step: 3
Training loss: 1.9811670780181885
Validation loss: 1.946127971013387

Epoch: 6| Step: 4
Training loss: 2.42753267288208
Validation loss: 1.9522550682867728

Epoch: 6| Step: 5
Training loss: 1.6929078102111816
Validation loss: 1.9678722927647252

Epoch: 6| Step: 6
Training loss: 1.9422194957733154
Validation loss: 1.9534129647798435

Epoch: 6| Step: 7
Training loss: 1.8613245487213135
Validation loss: 1.9570666538771762

Epoch: 6| Step: 8
Training loss: 1.787071943283081
Validation loss: 1.9630048018629833

Epoch: 6| Step: 9
Training loss: 1.759257197380066
Validation loss: 1.9630575615872619

Epoch: 6| Step: 10
Training loss: 2.423434257507324
Validation loss: 1.9483877484516432

Epoch: 6| Step: 11
Training loss: 1.6031208038330078
Validation loss: 1.9692033170371928

Epoch: 6| Step: 12
Training loss: 1.4267864227294922
Validation loss: 1.968894527804467

Epoch: 6| Step: 13
Training loss: 2.4016032218933105
Validation loss: 1.9573925964293941

Epoch: 434| Step: 0
Training loss: 2.2093417644500732
Validation loss: 1.970307570631786

Epoch: 6| Step: 1
Training loss: 1.8752717971801758
Validation loss: 1.9632328607702767

Epoch: 6| Step: 2
Training loss: 2.1564078330993652
Validation loss: 1.9815009409381497

Epoch: 6| Step: 3
Training loss: 2.165757179260254
Validation loss: 1.9660939401195896

Epoch: 6| Step: 4
Training loss: 2.248012065887451
Validation loss: 1.9579699116368448

Epoch: 6| Step: 5
Training loss: 1.5409190654754639
Validation loss: 1.9493652441168343

Epoch: 6| Step: 6
Training loss: 1.4646716117858887
Validation loss: 1.9652611465864285

Epoch: 6| Step: 7
Training loss: 1.9862861633300781
Validation loss: 1.9653197719204811

Epoch: 6| Step: 8
Training loss: 1.5286751985549927
Validation loss: 1.9686267863037765

Epoch: 6| Step: 9
Training loss: 2.373147964477539
Validation loss: 1.9776615058222125

Epoch: 6| Step: 10
Training loss: 1.4666649103164673
Validation loss: 1.995907227198283

Epoch: 6| Step: 11
Training loss: 1.9013922214508057
Validation loss: 1.9974958794091338

Epoch: 6| Step: 12
Training loss: 1.7554696798324585
Validation loss: 1.9983902080084688

Epoch: 6| Step: 13
Training loss: 2.0421175956726074
Validation loss: 1.9965398132160146

Epoch: 435| Step: 0
Training loss: 1.2207298278808594
Validation loss: 1.9960977287702664

Epoch: 6| Step: 1
Training loss: 1.6931495666503906
Validation loss: 1.9881525488309963

Epoch: 6| Step: 2
Training loss: 1.328180193901062
Validation loss: 2.0045688972678235

Epoch: 6| Step: 3
Training loss: 2.053483247756958
Validation loss: 1.9902467445660663

Epoch: 6| Step: 4
Training loss: 1.9566543102264404
Validation loss: 1.9791325228188628

Epoch: 6| Step: 5
Training loss: 1.8427857160568237
Validation loss: 1.9983213627210228

Epoch: 6| Step: 6
Training loss: 2.5635390281677246
Validation loss: 1.9577404017089515

Epoch: 6| Step: 7
Training loss: 2.3213329315185547
Validation loss: 1.9620084788209649

Epoch: 6| Step: 8
Training loss: 2.338430881500244
Validation loss: 1.952394990510838

Epoch: 6| Step: 9
Training loss: 1.8558131456375122
Validation loss: 1.963164488474528

Epoch: 6| Step: 10
Training loss: 1.6953885555267334
Validation loss: 1.9791273045283493

Epoch: 6| Step: 11
Training loss: 1.8033761978149414
Validation loss: 1.9885024614231561

Epoch: 6| Step: 12
Training loss: 1.6922730207443237
Validation loss: 1.988143636334327

Epoch: 6| Step: 13
Training loss: 2.996891975402832
Validation loss: 2.0100360942143265

Epoch: 436| Step: 0
Training loss: 1.274841070175171
Validation loss: 2.010836147492932

Epoch: 6| Step: 1
Training loss: 1.589212417602539
Validation loss: 1.9935322320589455

Epoch: 6| Step: 2
Training loss: 1.8779205083847046
Validation loss: 2.011241853878062

Epoch: 6| Step: 3
Training loss: 2.0345582962036133
Validation loss: 1.9832929167696225

Epoch: 6| Step: 4
Training loss: 1.8139203786849976
Validation loss: 1.9926521803743096

Epoch: 6| Step: 5
Training loss: 2.505545139312744
Validation loss: 1.9728026518257715

Epoch: 6| Step: 6
Training loss: 2.143160820007324
Validation loss: 1.9634555206503919

Epoch: 6| Step: 7
Training loss: 2.431060791015625
Validation loss: 1.9635824029163649

Epoch: 6| Step: 8
Training loss: 1.6873068809509277
Validation loss: 1.957413322182112

Epoch: 6| Step: 9
Training loss: 1.905590295791626
Validation loss: 1.9543383236854308

Epoch: 6| Step: 10
Training loss: 1.982724905014038
Validation loss: 1.9557877381642659

Epoch: 6| Step: 11
Training loss: 2.1667675971984863
Validation loss: 1.9508378044251473

Epoch: 6| Step: 12
Training loss: 1.340210199356079
Validation loss: 1.9651280846647037

Epoch: 6| Step: 13
Training loss: 1.9437421560287476
Validation loss: 1.969100272783669

Epoch: 437| Step: 0
Training loss: 1.7821961641311646
Validation loss: 1.964746316274007

Epoch: 6| Step: 1
Training loss: 2.660702705383301
Validation loss: 1.9684987080994474

Epoch: 6| Step: 2
Training loss: 1.9596374034881592
Validation loss: 1.9663099806795838

Epoch: 6| Step: 3
Training loss: 2.1211047172546387
Validation loss: 1.9797085715878395

Epoch: 6| Step: 4
Training loss: 2.306751251220703
Validation loss: 1.9649071078146658

Epoch: 6| Step: 5
Training loss: 1.7565585374832153
Validation loss: 1.9884087078032955

Epoch: 6| Step: 6
Training loss: 2.193891763687134
Validation loss: 1.965722712137366

Epoch: 6| Step: 7
Training loss: 1.683502197265625
Validation loss: 1.9734022027702742

Epoch: 6| Step: 8
Training loss: 1.9523282051086426
Validation loss: 1.9550570134193666

Epoch: 6| Step: 9
Training loss: 1.6380189657211304
Validation loss: 1.9619125038064935

Epoch: 6| Step: 10
Training loss: 1.5018254518508911
Validation loss: 1.960230460730932

Epoch: 6| Step: 11
Training loss: 1.355745553970337
Validation loss: 1.9592486543040122

Epoch: 6| Step: 12
Training loss: 1.971031904220581
Validation loss: 1.9539526252336399

Epoch: 6| Step: 13
Training loss: 1.3110262155532837
Validation loss: 1.9538846246657833

Epoch: 438| Step: 0
Training loss: 2.4495654106140137
Validation loss: 1.983010740690334

Epoch: 6| Step: 1
Training loss: 1.4483284950256348
Validation loss: 1.9750612333256712

Epoch: 6| Step: 2
Training loss: 2.587657928466797
Validation loss: 1.9973020502316055

Epoch: 6| Step: 3
Training loss: 1.3902617692947388
Validation loss: 1.9969052947977537

Epoch: 6| Step: 4
Training loss: 1.4708378314971924
Validation loss: 1.9981136693749377

Epoch: 6| Step: 5
Training loss: 2.826113700866699
Validation loss: 1.9837238634786298

Epoch: 6| Step: 6
Training loss: 2.074122905731201
Validation loss: 1.9969903833122664

Epoch: 6| Step: 7
Training loss: 1.7968865633010864
Validation loss: 1.9847127083809144

Epoch: 6| Step: 8
Training loss: 2.349783420562744
Validation loss: 1.9846156668919388

Epoch: 6| Step: 9
Training loss: 1.365858793258667
Validation loss: 1.9840076815697454

Epoch: 6| Step: 10
Training loss: 1.3529248237609863
Validation loss: 1.9892006792047972

Epoch: 6| Step: 11
Training loss: 1.7544169425964355
Validation loss: 1.9548682692230388

Epoch: 6| Step: 12
Training loss: 1.384036898612976
Validation loss: 1.9585381541200864

Epoch: 6| Step: 13
Training loss: 2.3583450317382812
Validation loss: 1.9606817025010304

Epoch: 439| Step: 0
Training loss: 1.8262944221496582
Validation loss: 1.948968413055584

Epoch: 6| Step: 1
Training loss: 2.4850902557373047
Validation loss: 1.9517490351071922

Epoch: 6| Step: 2
Training loss: 1.259610652923584
Validation loss: 1.9603030322700419

Epoch: 6| Step: 3
Training loss: 1.5984411239624023
Validation loss: 1.9597116875392135

Epoch: 6| Step: 4
Training loss: 1.8678553104400635
Validation loss: 1.9446735330807265

Epoch: 6| Step: 5
Training loss: 2.3645408153533936
Validation loss: 1.959128684895013

Epoch: 6| Step: 6
Training loss: 2.3545594215393066
Validation loss: 1.9646022704339796

Epoch: 6| Step: 7
Training loss: 1.2673993110656738
Validation loss: 1.9522467223546838

Epoch: 6| Step: 8
Training loss: 1.7074549198150635
Validation loss: 1.9538430577965193

Epoch: 6| Step: 9
Training loss: 1.9782328605651855
Validation loss: 1.9585522990072928

Epoch: 6| Step: 10
Training loss: 2.5045313835144043
Validation loss: 1.9834778206322783

Epoch: 6| Step: 11
Training loss: 1.0351332426071167
Validation loss: 1.9709309852251442

Epoch: 6| Step: 12
Training loss: 2.48858642578125
Validation loss: 1.9686167765689153

Epoch: 6| Step: 13
Training loss: 1.462821364402771
Validation loss: 1.9776840440688594

Epoch: 440| Step: 0
Training loss: 2.5037949085235596
Validation loss: 1.9770009261305614

Epoch: 6| Step: 1
Training loss: 1.827606439590454
Validation loss: 1.9839324130806872

Epoch: 6| Step: 2
Training loss: 1.873491883277893
Validation loss: 1.9784107977344143

Epoch: 6| Step: 3
Training loss: 2.050189971923828
Validation loss: 1.9815137001775927

Epoch: 6| Step: 4
Training loss: 1.9336109161376953
Validation loss: 1.9742770477007794

Epoch: 6| Step: 5
Training loss: 2.049593448638916
Validation loss: 1.9842471807233748

Epoch: 6| Step: 6
Training loss: 1.6352601051330566
Validation loss: 1.9696651171612483

Epoch: 6| Step: 7
Training loss: 2.2940757274627686
Validation loss: 1.9496394344555434

Epoch: 6| Step: 8
Training loss: 2.1969194412231445
Validation loss: 1.9629322572421002

Epoch: 6| Step: 9
Training loss: 1.503140926361084
Validation loss: 1.962614647803768

Epoch: 6| Step: 10
Training loss: 1.6175960302352905
Validation loss: 1.9765818965050481

Epoch: 6| Step: 11
Training loss: 1.8536587953567505
Validation loss: 1.9611851041034987

Epoch: 6| Step: 12
Training loss: 1.515930414199829
Validation loss: 1.9711146329038887

Epoch: 6| Step: 13
Training loss: 1.4477791786193848
Validation loss: 1.9688604890659291

Epoch: 441| Step: 0
Training loss: 1.8921964168548584
Validation loss: 1.973476243275468

Epoch: 6| Step: 1
Training loss: 2.0363807678222656
Validation loss: 1.9704720961150302

Epoch: 6| Step: 2
Training loss: 2.0455987453460693
Validation loss: 1.984833667355199

Epoch: 6| Step: 3
Training loss: 2.0908946990966797
Validation loss: 1.9804069995880127

Epoch: 6| Step: 4
Training loss: 1.6553857326507568
Validation loss: 1.9704183570800289

Epoch: 6| Step: 5
Training loss: 2.0132241249084473
Validation loss: 1.972853583674277

Epoch: 6| Step: 6
Training loss: 1.7242798805236816
Validation loss: 1.97050735258287

Epoch: 6| Step: 7
Training loss: 1.3014028072357178
Validation loss: 1.9726015290906351

Epoch: 6| Step: 8
Training loss: 1.9019958972930908
Validation loss: 1.9711782932281494

Epoch: 6| Step: 9
Training loss: 1.7352008819580078
Validation loss: 1.9802545244975756

Epoch: 6| Step: 10
Training loss: 2.2955162525177
Validation loss: 1.9896615551364036

Epoch: 6| Step: 11
Training loss: 2.201864242553711
Validation loss: 1.9778196375857118

Epoch: 6| Step: 12
Training loss: 1.861926555633545
Validation loss: 1.9553673677547003

Epoch: 6| Step: 13
Training loss: 1.640596866607666
Validation loss: 1.9631575153719993

Epoch: 442| Step: 0
Training loss: 1.0641735792160034
Validation loss: 1.9663451435745403

Epoch: 6| Step: 1
Training loss: 2.4477033615112305
Validation loss: 1.9765197166832544

Epoch: 6| Step: 2
Training loss: 1.6004925966262817
Validation loss: 1.9930984807270828

Epoch: 6| Step: 3
Training loss: 1.8450902700424194
Validation loss: 1.98250582397625

Epoch: 6| Step: 4
Training loss: 1.4919202327728271
Validation loss: 1.9896844074290285

Epoch: 6| Step: 5
Training loss: 2.010979175567627
Validation loss: 1.973233404979911

Epoch: 6| Step: 6
Training loss: 2.0295028686523438
Validation loss: 1.9712334525200628

Epoch: 6| Step: 7
Training loss: 2.0156314373016357
Validation loss: 1.949391193287347

Epoch: 6| Step: 8
Training loss: 2.8675103187561035
Validation loss: 1.9468221895156368

Epoch: 6| Step: 9
Training loss: 1.3519601821899414
Validation loss: 1.9617014879821448

Epoch: 6| Step: 10
Training loss: 1.7411766052246094
Validation loss: 1.9575621338300808

Epoch: 6| Step: 11
Training loss: 1.8440536260604858
Validation loss: 1.956443279020248

Epoch: 6| Step: 12
Training loss: 2.5170836448669434
Validation loss: 1.974249529582198

Epoch: 6| Step: 13
Training loss: 1.5515694618225098
Validation loss: 1.9856439777599868

Epoch: 443| Step: 0
Training loss: 2.2439651489257812
Validation loss: 1.9770669962770195

Epoch: 6| Step: 1
Training loss: 2.3495824337005615
Validation loss: 1.9716079209440498

Epoch: 6| Step: 2
Training loss: 2.201885938644409
Validation loss: 1.9747396053806427

Epoch: 6| Step: 3
Training loss: 1.732679009437561
Validation loss: 1.9708789958748767

Epoch: 6| Step: 4
Training loss: 1.7745169401168823
Validation loss: 1.9583423791393157

Epoch: 6| Step: 5
Training loss: 1.701735019683838
Validation loss: 1.9554254316514539

Epoch: 6| Step: 6
Training loss: 1.882630467414856
Validation loss: 1.9487431997893958

Epoch: 6| Step: 7
Training loss: 1.8543678522109985
Validation loss: 1.9634716433863486

Epoch: 6| Step: 8
Training loss: 1.3162469863891602
Validation loss: 1.952037142169091

Epoch: 6| Step: 9
Training loss: 1.757590413093567
Validation loss: 1.95494447728639

Epoch: 6| Step: 10
Training loss: 1.6545634269714355
Validation loss: 1.9598106620132283

Epoch: 6| Step: 11
Training loss: 2.0433082580566406
Validation loss: 1.962624224283362

Epoch: 6| Step: 12
Training loss: 1.7464015483856201
Validation loss: 1.9635011355082195

Epoch: 6| Step: 13
Training loss: 1.996329665184021
Validation loss: 1.9404761970684092

Epoch: 444| Step: 0
Training loss: 2.132072925567627
Validation loss: 1.9485998640778244

Epoch: 6| Step: 1
Training loss: 1.4385288953781128
Validation loss: 1.9386975406318583

Epoch: 6| Step: 2
Training loss: 1.3485074043273926
Validation loss: 1.9570216581385622

Epoch: 6| Step: 3
Training loss: 1.7396260499954224
Validation loss: 1.9792676817986272

Epoch: 6| Step: 4
Training loss: 2.220522165298462
Validation loss: 1.9773754150636735

Epoch: 6| Step: 5
Training loss: 2.2113218307495117
Validation loss: 1.9707294176983576

Epoch: 6| Step: 6
Training loss: 2.0657198429107666
Validation loss: 1.9731381477848176

Epoch: 6| Step: 7
Training loss: 1.9605062007904053
Validation loss: 1.9709207280989616

Epoch: 6| Step: 8
Training loss: 1.8076711893081665
Validation loss: 1.948527511729989

Epoch: 6| Step: 9
Training loss: 2.0023088455200195
Validation loss: 1.9507983602503294

Epoch: 6| Step: 10
Training loss: 1.7058305740356445
Validation loss: 1.9457081812684254

Epoch: 6| Step: 11
Training loss: 1.8398070335388184
Validation loss: 1.9516010963788597

Epoch: 6| Step: 12
Training loss: 2.1443891525268555
Validation loss: 1.9406226655488372

Epoch: 6| Step: 13
Training loss: 1.1175918579101562
Validation loss: 1.937316656112671

Epoch: 445| Step: 0
Training loss: 2.1145617961883545
Validation loss: 1.950150748734833

Epoch: 6| Step: 1
Training loss: 1.8555183410644531
Validation loss: 1.9239748549717728

Epoch: 6| Step: 2
Training loss: 2.243894577026367
Validation loss: 1.942426630245742

Epoch: 6| Step: 3
Training loss: 2.3058621883392334
Validation loss: 1.9380853919572727

Epoch: 6| Step: 4
Training loss: 1.4553837776184082
Validation loss: 1.956014101223279

Epoch: 6| Step: 5
Training loss: 2.065575122833252
Validation loss: 1.9732772586166218

Epoch: 6| Step: 6
Training loss: 1.4297327995300293
Validation loss: 1.9583056037143995

Epoch: 6| Step: 7
Training loss: 1.8307852745056152
Validation loss: 1.9449023969711796

Epoch: 6| Step: 8
Training loss: 2.2592382431030273
Validation loss: 1.9717761419152702

Epoch: 6| Step: 9
Training loss: 1.8082859516143799
Validation loss: 1.9621209713720507

Epoch: 6| Step: 10
Training loss: 1.9902194738388062
Validation loss: 1.9725501357868154

Epoch: 6| Step: 11
Training loss: 1.8628344535827637
Validation loss: 1.9702536341964558

Epoch: 6| Step: 12
Training loss: 1.4374332427978516
Validation loss: 1.9544686963481288

Epoch: 6| Step: 13
Training loss: 1.1148428916931152
Validation loss: 1.9553021654005973

Epoch: 446| Step: 0
Training loss: 1.7997655868530273
Validation loss: 1.946258920495228

Epoch: 6| Step: 1
Training loss: 1.9911525249481201
Validation loss: 1.9544217945427023

Epoch: 6| Step: 2
Training loss: 1.7357354164123535
Validation loss: 1.951232260273349

Epoch: 6| Step: 3
Training loss: 1.9145234823226929
Validation loss: 1.9490451376925233

Epoch: 6| Step: 4
Training loss: 2.249279022216797
Validation loss: 1.9650248763381795

Epoch: 6| Step: 5
Training loss: 2.0468811988830566
Validation loss: 1.9605533794690204

Epoch: 6| Step: 6
Training loss: 1.6376945972442627
Validation loss: 1.9629148398676226

Epoch: 6| Step: 7
Training loss: 1.9747084379196167
Validation loss: 1.956135598562097

Epoch: 6| Step: 8
Training loss: 1.8697714805603027
Validation loss: 1.9570304065622308

Epoch: 6| Step: 9
Training loss: 1.8629688024520874
Validation loss: 1.9564179605053318

Epoch: 6| Step: 10
Training loss: 1.764336347579956
Validation loss: 1.9466498769739622

Epoch: 6| Step: 11
Training loss: 1.5617682933807373
Validation loss: 1.9472104682717273

Epoch: 6| Step: 12
Training loss: 1.808013677597046
Validation loss: 1.9475610525377336

Epoch: 6| Step: 13
Training loss: 1.7732195854187012
Validation loss: 1.956056103911451

Epoch: 447| Step: 0
Training loss: 1.5023072957992554
Validation loss: 1.9472138958592569

Epoch: 6| Step: 1
Training loss: 1.5729111433029175
Validation loss: 1.9429697759689823

Epoch: 6| Step: 2
Training loss: 1.219223976135254
Validation loss: 1.9636717816834808

Epoch: 6| Step: 3
Training loss: 1.8595129251480103
Validation loss: 1.951761548237134

Epoch: 6| Step: 4
Training loss: 1.9905202388763428
Validation loss: 1.9650487105051677

Epoch: 6| Step: 5
Training loss: 2.3928680419921875
Validation loss: 1.9543335668502315

Epoch: 6| Step: 6
Training loss: 1.9603850841522217
Validation loss: 1.9479416365264564

Epoch: 6| Step: 7
Training loss: 2.1014480590820312
Validation loss: 1.9520211412060646

Epoch: 6| Step: 8
Training loss: 1.6008641719818115
Validation loss: 1.9594169842299594

Epoch: 6| Step: 9
Training loss: 2.0144524574279785
Validation loss: 1.9459873707063737

Epoch: 6| Step: 10
Training loss: 2.2702980041503906
Validation loss: 1.9446062452049666

Epoch: 6| Step: 11
Training loss: 1.7275846004486084
Validation loss: 1.9416362739378406

Epoch: 6| Step: 12
Training loss: 1.8086650371551514
Validation loss: 1.9749538488285516

Epoch: 6| Step: 13
Training loss: 2.1582117080688477
Validation loss: 1.9511293826564666

Epoch: 448| Step: 0
Training loss: 2.2762155532836914
Validation loss: 1.9671910680750364

Epoch: 6| Step: 1
Training loss: 1.7912185192108154
Validation loss: 1.97438015989078

Epoch: 6| Step: 2
Training loss: 1.296010971069336
Validation loss: 1.9913958439262964

Epoch: 6| Step: 3
Training loss: 1.6141681671142578
Validation loss: 1.9953406113450245

Epoch: 6| Step: 4
Training loss: 1.5840768814086914
Validation loss: 1.978419884558647

Epoch: 6| Step: 5
Training loss: 1.1239062547683716
Validation loss: 1.9707510073979695

Epoch: 6| Step: 6
Training loss: 1.389833688735962
Validation loss: 1.9647152423858643

Epoch: 6| Step: 7
Training loss: 2.6869301795959473
Validation loss: 1.9579641819000244

Epoch: 6| Step: 8
Training loss: 2.0169734954833984
Validation loss: 1.987143926723029

Epoch: 6| Step: 9
Training loss: 1.9801826477050781
Validation loss: 1.9631817981760988

Epoch: 6| Step: 10
Training loss: 1.714620590209961
Validation loss: 1.9766416498409805

Epoch: 6| Step: 11
Training loss: 1.9519957304000854
Validation loss: 1.9801245479173557

Epoch: 6| Step: 12
Training loss: 2.2426984310150146
Validation loss: 1.97564979650641

Epoch: 6| Step: 13
Training loss: 3.105698585510254
Validation loss: 1.9722682609353015

Epoch: 449| Step: 0
Training loss: 1.9670871496200562
Validation loss: 1.9499841954118462

Epoch: 6| Step: 1
Training loss: 1.4687727689743042
Validation loss: 1.9657965090966993

Epoch: 6| Step: 2
Training loss: 1.4756555557250977
Validation loss: 1.96472748889718

Epoch: 6| Step: 3
Training loss: 2.3885457515716553
Validation loss: 1.9858051141103108

Epoch: 6| Step: 4
Training loss: 1.6727445125579834
Validation loss: 1.9874643612933416

Epoch: 6| Step: 5
Training loss: 1.736438512802124
Validation loss: 1.9988703189357635

Epoch: 6| Step: 6
Training loss: 1.2750591039657593
Validation loss: 1.9871881546512726

Epoch: 6| Step: 7
Training loss: 1.549187421798706
Validation loss: 1.9872401042651104

Epoch: 6| Step: 8
Training loss: 2.205873489379883
Validation loss: 1.987933951039468

Epoch: 6| Step: 9
Training loss: 1.9823212623596191
Validation loss: 1.9750679949278473

Epoch: 6| Step: 10
Training loss: 2.298542022705078
Validation loss: 1.9848083911403533

Epoch: 6| Step: 11
Training loss: 1.9072198867797852
Validation loss: 1.9845473151053152

Epoch: 6| Step: 12
Training loss: 2.31618070602417
Validation loss: 1.985067093244163

Epoch: 6| Step: 13
Training loss: 1.6202716827392578
Validation loss: 1.9510275625413465

Epoch: 450| Step: 0
Training loss: 1.9376846551895142
Validation loss: 1.9501152423120314

Epoch: 6| Step: 1
Training loss: 1.5684672594070435
Validation loss: 1.9384035833420292

Epoch: 6| Step: 2
Training loss: 1.554005742073059
Validation loss: 1.9479651989475373

Epoch: 6| Step: 3
Training loss: 1.6316684484481812
Validation loss: 1.9751901575314101

Epoch: 6| Step: 4
Training loss: 2.3618319034576416
Validation loss: 1.9802967450952018

Epoch: 6| Step: 5
Training loss: 1.1850714683532715
Validation loss: 1.987883005090939

Epoch: 6| Step: 6
Training loss: 2.084872245788574
Validation loss: 1.9892957389995616

Epoch: 6| Step: 7
Training loss: 2.908283233642578
Validation loss: 1.9731729850974133

Epoch: 6| Step: 8
Training loss: 1.7541736364364624
Validation loss: 1.9698081606177873

Epoch: 6| Step: 9
Training loss: 2.2241692543029785
Validation loss: 1.9814504449085524

Epoch: 6| Step: 10
Training loss: 2.0793395042419434
Validation loss: 1.9530076442226287

Epoch: 6| Step: 11
Training loss: 1.3994985818862915
Validation loss: 1.9582635279624694

Epoch: 6| Step: 12
Training loss: 1.2735786437988281
Validation loss: 1.938860336939494

Epoch: 6| Step: 13
Training loss: 2.1089940071105957
Validation loss: 1.9560029378501318

Epoch: 451| Step: 0
Training loss: 2.12117862701416
Validation loss: 1.9588296105784755

Epoch: 6| Step: 1
Training loss: 2.1345510482788086
Validation loss: 1.9474219173513434

Epoch: 6| Step: 2
Training loss: 1.8007605075836182
Validation loss: 1.9546039527462375

Epoch: 6| Step: 3
Training loss: 1.6464464664459229
Validation loss: 1.934406525345259

Epoch: 6| Step: 4
Training loss: 1.7638386487960815
Validation loss: 1.9348077261319725

Epoch: 6| Step: 5
Training loss: 2.1163558959960938
Validation loss: 1.9381568829218547

Epoch: 6| Step: 6
Training loss: 1.70871901512146
Validation loss: 1.9339318608724942

Epoch: 6| Step: 7
Training loss: 1.6107070446014404
Validation loss: 1.9381268075717393

Epoch: 6| Step: 8
Training loss: 2.1380910873413086
Validation loss: 1.941143069216

Epoch: 6| Step: 9
Training loss: 1.6256935596466064
Validation loss: 1.9483402723907142

Epoch: 6| Step: 10
Training loss: 1.9877829551696777
Validation loss: 1.9535387715985697

Epoch: 6| Step: 11
Training loss: 2.4484333992004395
Validation loss: 1.9720819893703665

Epoch: 6| Step: 12
Training loss: 1.5680347681045532
Validation loss: 1.953242786468998

Epoch: 6| Step: 13
Training loss: 0.5430947542190552
Validation loss: 1.978697605030511

Epoch: 452| Step: 0
Training loss: 2.3213558197021484
Validation loss: 1.9779783089955647

Epoch: 6| Step: 1
Training loss: 0.9540007710456848
Validation loss: 2.0027102654980076

Epoch: 6| Step: 2
Training loss: 1.5899930000305176
Validation loss: 1.9780705590401926

Epoch: 6| Step: 3
Training loss: 1.9186575412750244
Validation loss: 1.9999207565861363

Epoch: 6| Step: 4
Training loss: 2.1602821350097656
Validation loss: 1.9810105523755472

Epoch: 6| Step: 5
Training loss: 1.8091121912002563
Validation loss: 1.9758290577960271

Epoch: 6| Step: 6
Training loss: 2.2387917041778564
Validation loss: 1.969078420310892

Epoch: 6| Step: 7
Training loss: 1.7801107168197632
Validation loss: 1.9549812501476658

Epoch: 6| Step: 8
Training loss: 1.6628024578094482
Validation loss: 1.951748389069752

Epoch: 6| Step: 9
Training loss: 1.5772545337677002
Validation loss: 1.9562843897009408

Epoch: 6| Step: 10
Training loss: 1.6324920654296875
Validation loss: 1.9760158882346204

Epoch: 6| Step: 11
Training loss: 2.00870418548584
Validation loss: 1.9758580371897707

Epoch: 6| Step: 12
Training loss: 2.286365509033203
Validation loss: 1.9839266628347418

Epoch: 6| Step: 13
Training loss: 2.3617475032806396
Validation loss: 1.992842758855512

Epoch: 453| Step: 0
Training loss: 1.8803844451904297
Validation loss: 1.986131775763727

Epoch: 6| Step: 1
Training loss: 1.538354516029358
Validation loss: 1.9758078577697917

Epoch: 6| Step: 2
Training loss: 1.9467947483062744
Validation loss: 1.9791156040724887

Epoch: 6| Step: 3
Training loss: 2.1082353591918945
Validation loss: 1.9618358227514452

Epoch: 6| Step: 4
Training loss: 2.114211320877075
Validation loss: 1.9850973185672556

Epoch: 6| Step: 5
Training loss: 1.2794075012207031
Validation loss: 1.9684057620263868

Epoch: 6| Step: 6
Training loss: 1.6398183107376099
Validation loss: 1.9939114893636396

Epoch: 6| Step: 7
Training loss: 1.5364868640899658
Validation loss: 1.9714872683248212

Epoch: 6| Step: 8
Training loss: 1.0472500324249268
Validation loss: 1.9635108901608376

Epoch: 6| Step: 9
Training loss: 2.344862461090088
Validation loss: 1.9633226445926133

Epoch: 6| Step: 10
Training loss: 1.8436968326568604
Validation loss: 1.963377752611714

Epoch: 6| Step: 11
Training loss: 2.0197057723999023
Validation loss: 1.9552649797931794

Epoch: 6| Step: 12
Training loss: 2.276815891265869
Validation loss: 1.9589897048088811

Epoch: 6| Step: 13
Training loss: 2.7734804153442383
Validation loss: 1.9367002543582712

Epoch: 454| Step: 0
Training loss: 1.8577293157577515
Validation loss: 1.9395624565821823

Epoch: 6| Step: 1
Training loss: 1.4562751054763794
Validation loss: 1.9489644509489819

Epoch: 6| Step: 2
Training loss: 2.6870574951171875
Validation loss: 1.933808986858655

Epoch: 6| Step: 3
Training loss: 1.7686258554458618
Validation loss: 1.9445292590766825

Epoch: 6| Step: 4
Training loss: 2.2886500358581543
Validation loss: 1.9526297200110652

Epoch: 6| Step: 5
Training loss: 1.866708517074585
Validation loss: 1.9534300527264994

Epoch: 6| Step: 6
Training loss: 1.2954181432724
Validation loss: 1.966660770036841

Epoch: 6| Step: 7
Training loss: 2.18837308883667
Validation loss: 1.9533435106277466

Epoch: 6| Step: 8
Training loss: 2.2125051021575928
Validation loss: 1.9465048774596183

Epoch: 6| Step: 9
Training loss: 1.9803379774093628
Validation loss: 1.9382051857568885

Epoch: 6| Step: 10
Training loss: 2.0154552459716797
Validation loss: 1.9547463437562347

Epoch: 6| Step: 11
Training loss: 0.8087148666381836
Validation loss: 1.9492998469260432

Epoch: 6| Step: 12
Training loss: 1.6860431432724
Validation loss: 1.9601903884641585

Epoch: 6| Step: 13
Training loss: 1.464248538017273
Validation loss: 1.961520533407888

Epoch: 455| Step: 0
Training loss: 1.7801668643951416
Validation loss: 1.9505190798031387

Epoch: 6| Step: 1
Training loss: 1.9818083047866821
Validation loss: 1.9537101035477014

Epoch: 6| Step: 2
Training loss: 1.1270445585250854
Validation loss: 1.9505496691632014

Epoch: 6| Step: 3
Training loss: 1.9302270412445068
Validation loss: 1.959150803986416

Epoch: 6| Step: 4
Training loss: 2.2976646423339844
Validation loss: 1.959586097348121

Epoch: 6| Step: 5
Training loss: 1.5373709201812744
Validation loss: 1.9644953640558387

Epoch: 6| Step: 6
Training loss: 1.7183347940444946
Validation loss: 1.9702548519257577

Epoch: 6| Step: 7
Training loss: 2.054011344909668
Validation loss: 1.9788468883883568

Epoch: 6| Step: 8
Training loss: 2.426825761795044
Validation loss: 1.9816776193598264

Epoch: 6| Step: 9
Training loss: 2.010607957839966
Validation loss: 1.9777519626002158

Epoch: 6| Step: 10
Training loss: 1.6664354801177979
Validation loss: 1.9540761183666926

Epoch: 6| Step: 11
Training loss: 1.7670645713806152
Validation loss: 1.9597166046019523

Epoch: 6| Step: 12
Training loss: 1.6887319087982178
Validation loss: 1.955438393418507

Epoch: 6| Step: 13
Training loss: 1.7792898416519165
Validation loss: 1.9611966763773272

Epoch: 456| Step: 0
Training loss: 1.9494227170944214
Validation loss: 1.956694196629268

Epoch: 6| Step: 1
Training loss: 1.8762143850326538
Validation loss: 1.9583099452398156

Epoch: 6| Step: 2
Training loss: 1.260621190071106
Validation loss: 1.9499699146516862

Epoch: 6| Step: 3
Training loss: 2.458554744720459
Validation loss: 1.9613615441065964

Epoch: 6| Step: 4
Training loss: 2.038320302963257
Validation loss: 1.9462858989674559

Epoch: 6| Step: 5
Training loss: 1.9402742385864258
Validation loss: 1.9368045612048077

Epoch: 6| Step: 6
Training loss: 1.9768567085266113
Validation loss: 1.9581368418150051

Epoch: 6| Step: 7
Training loss: 2.032832622528076
Validation loss: 1.961843503418789

Epoch: 6| Step: 8
Training loss: 1.2183482646942139
Validation loss: 1.9597356703973585

Epoch: 6| Step: 9
Training loss: 1.5461914539337158
Validation loss: 1.9623832446272655

Epoch: 6| Step: 10
Training loss: 1.629166841506958
Validation loss: 1.9567915880551903

Epoch: 6| Step: 11
Training loss: 1.5092017650604248
Validation loss: 1.9764642561635664

Epoch: 6| Step: 12
Training loss: 1.919691562652588
Validation loss: 1.9582046052461028

Epoch: 6| Step: 13
Training loss: 2.686877489089966
Validation loss: 1.9659640750577372

Epoch: 457| Step: 0
Training loss: 1.260591745376587
Validation loss: 1.9693015057553527

Epoch: 6| Step: 1
Training loss: 2.4449801445007324
Validation loss: 1.977401625725531

Epoch: 6| Step: 2
Training loss: 2.340240001678467
Validation loss: 1.9857009213457826

Epoch: 6| Step: 3
Training loss: 1.8787686824798584
Validation loss: 1.9697937401392127

Epoch: 6| Step: 4
Training loss: 1.3525137901306152
Validation loss: 1.9548172156016033

Epoch: 6| Step: 5
Training loss: 2.2552390098571777
Validation loss: 1.9427812099456787

Epoch: 6| Step: 6
Training loss: 2.2673115730285645
Validation loss: 1.958686843995125

Epoch: 6| Step: 7
Training loss: 1.7016403675079346
Validation loss: 1.960161555197931

Epoch: 6| Step: 8
Training loss: 1.0265381336212158
Validation loss: 1.9826222414611487

Epoch: 6| Step: 9
Training loss: 2.110365867614746
Validation loss: 1.9768355456731652

Epoch: 6| Step: 10
Training loss: 1.9711205959320068
Validation loss: 1.9975287798912293

Epoch: 6| Step: 11
Training loss: 1.6890747547149658
Validation loss: 1.9925503038590955

Epoch: 6| Step: 12
Training loss: 1.8897260427474976
Validation loss: 1.9812771453652331

Epoch: 6| Step: 13
Training loss: 1.5342061519622803
Validation loss: 1.97441311805479

Epoch: 458| Step: 0
Training loss: 1.2294085025787354
Validation loss: 1.983699555038124

Epoch: 6| Step: 1
Training loss: 1.7210975885391235
Validation loss: 1.9889848744997414

Epoch: 6| Step: 2
Training loss: 1.9927537441253662
Validation loss: 1.9781195604672996

Epoch: 6| Step: 3
Training loss: 2.4358181953430176
Validation loss: 1.9782226944482455

Epoch: 6| Step: 4
Training loss: 2.1896934509277344
Validation loss: 1.9622807105382283

Epoch: 6| Step: 5
Training loss: 2.2486095428466797
Validation loss: 1.9596692580048756

Epoch: 6| Step: 6
Training loss: 1.6407687664031982
Validation loss: 1.9454209740443895

Epoch: 6| Step: 7
Training loss: 1.343346118927002
Validation loss: 1.9781153894239856

Epoch: 6| Step: 8
Training loss: 1.3770678043365479
Validation loss: 1.9765962234107397

Epoch: 6| Step: 9
Training loss: 2.0290451049804688
Validation loss: 1.9772973778427287

Epoch: 6| Step: 10
Training loss: 1.9285600185394287
Validation loss: 1.9676411177522393

Epoch: 6| Step: 11
Training loss: 2.039788246154785
Validation loss: 1.9635478783679265

Epoch: 6| Step: 12
Training loss: 1.7629096508026123
Validation loss: 1.959962297511357

Epoch: 6| Step: 13
Training loss: 1.7543222904205322
Validation loss: 1.9741859718035626

Epoch: 459| Step: 0
Training loss: 1.140344262123108
Validation loss: 1.9730093632974932

Epoch: 6| Step: 1
Training loss: 1.9490927457809448
Validation loss: 1.9628590050564017

Epoch: 6| Step: 2
Training loss: 1.8995269536972046
Validation loss: 1.943172134378905

Epoch: 6| Step: 3
Training loss: 2.494110345840454
Validation loss: 1.9474267062320505

Epoch: 6| Step: 4
Training loss: 2.380554676055908
Validation loss: 1.9572416813142839

Epoch: 6| Step: 5
Training loss: 1.7515732049942017
Validation loss: 1.9552322228749592

Epoch: 6| Step: 6
Training loss: 1.743847370147705
Validation loss: 1.9641141917115899

Epoch: 6| Step: 7
Training loss: 1.9672727584838867
Validation loss: 1.97261780564503

Epoch: 6| Step: 8
Training loss: 1.432873010635376
Validation loss: 1.9673047360553537

Epoch: 6| Step: 9
Training loss: 1.915004014968872
Validation loss: 1.9662163667781378

Epoch: 6| Step: 10
Training loss: 1.8945051431655884
Validation loss: 1.9680526077106435

Epoch: 6| Step: 11
Training loss: 1.843610405921936
Validation loss: 1.9620380619520783

Epoch: 6| Step: 12
Training loss: 1.793555498123169
Validation loss: 1.9719510001520957

Epoch: 6| Step: 13
Training loss: 1.4066071510314941
Validation loss: 1.9543915794741722

Epoch: 460| Step: 0
Training loss: 2.112377166748047
Validation loss: 1.9612652230006393

Epoch: 6| Step: 1
Training loss: 1.5488531589508057
Validation loss: 1.9597460082782212

Epoch: 6| Step: 2
Training loss: 1.601546287536621
Validation loss: 1.955641577320714

Epoch: 6| Step: 3
Training loss: 1.8592593669891357
Validation loss: 1.9373854873000935

Epoch: 6| Step: 4
Training loss: 1.651450753211975
Validation loss: 1.9352663383688977

Epoch: 6| Step: 5
Training loss: 2.363161563873291
Validation loss: 1.9453270653242707

Epoch: 6| Step: 6
Training loss: 1.9698317050933838
Validation loss: 1.9302287999019827

Epoch: 6| Step: 7
Training loss: 1.9831080436706543
Validation loss: 1.924447492886615

Epoch: 6| Step: 8
Training loss: 1.6187001466751099
Validation loss: 1.944350750215592

Epoch: 6| Step: 9
Training loss: 1.3766168355941772
Validation loss: 1.9322172864790885

Epoch: 6| Step: 10
Training loss: 1.6442984342575073
Validation loss: 1.9488863047733103

Epoch: 6| Step: 11
Training loss: 2.6031198501586914
Validation loss: 1.929794898597143

Epoch: 6| Step: 12
Training loss: 1.6503980159759521
Validation loss: 1.9535978455697336

Epoch: 6| Step: 13
Training loss: 1.476615071296692
Validation loss: 1.96851529869982

Epoch: 461| Step: 0
Training loss: 2.1571431159973145
Validation loss: 1.976529973809437

Epoch: 6| Step: 1
Training loss: 2.0721921920776367
Validation loss: 2.003833806642922

Epoch: 6| Step: 2
Training loss: 1.8191136121749878
Validation loss: 1.9764766539296796

Epoch: 6| Step: 3
Training loss: 2.423720121383667
Validation loss: 1.9913784573155064

Epoch: 6| Step: 4
Training loss: 1.6816797256469727
Validation loss: 1.9647670612540296

Epoch: 6| Step: 5
Training loss: 1.0992586612701416
Validation loss: 1.9652596071202268

Epoch: 6| Step: 6
Training loss: 1.4189071655273438
Validation loss: 1.9545391939019645

Epoch: 6| Step: 7
Training loss: 2.203653335571289
Validation loss: 1.9385436132390013

Epoch: 6| Step: 8
Training loss: 1.7755358219146729
Validation loss: 1.9465110981336204

Epoch: 6| Step: 9
Training loss: 1.7800297737121582
Validation loss: 1.9385346712604645

Epoch: 6| Step: 10
Training loss: 1.8774763345718384
Validation loss: 1.956827114987117

Epoch: 6| Step: 11
Training loss: 1.7898668050765991
Validation loss: 1.937305332511984

Epoch: 6| Step: 12
Training loss: 1.8581056594848633
Validation loss: 1.9495257998025546

Epoch: 6| Step: 13
Training loss: 1.6626591682434082
Validation loss: 1.937931711955737

Epoch: 462| Step: 0
Training loss: 2.3307127952575684
Validation loss: 1.9440796747002551

Epoch: 6| Step: 1
Training loss: 2.68654727935791
Validation loss: 1.9505443149997341

Epoch: 6| Step: 2
Training loss: 1.5689077377319336
Validation loss: 1.9573034009625834

Epoch: 6| Step: 3
Training loss: 2.157397508621216
Validation loss: 1.972889587443362

Epoch: 6| Step: 4
Training loss: 1.334721565246582
Validation loss: 1.9525126769978514

Epoch: 6| Step: 5
Training loss: 2.4230401515960693
Validation loss: 1.9520796678399528

Epoch: 6| Step: 6
Training loss: 1.7449175119400024
Validation loss: 1.9644848249291862

Epoch: 6| Step: 7
Training loss: 2.0946569442749023
Validation loss: 1.9628767146859118

Epoch: 6| Step: 8
Training loss: 1.0034006834030151
Validation loss: 1.953854694161364

Epoch: 6| Step: 9
Training loss: 1.9687728881835938
Validation loss: 1.9644238231002644

Epoch: 6| Step: 10
Training loss: 1.4530662298202515
Validation loss: 1.9463311100518832

Epoch: 6| Step: 11
Training loss: 1.8408998250961304
Validation loss: 1.9377282281075754

Epoch: 6| Step: 12
Training loss: 1.3476698398590088
Validation loss: 1.9428550620232858

Epoch: 6| Step: 13
Training loss: 1.483717679977417
Validation loss: 1.9744994563441123

Epoch: 463| Step: 0
Training loss: 1.958613395690918
Validation loss: 1.9389373371678014

Epoch: 6| Step: 1
Training loss: 1.8635183572769165
Validation loss: 1.9641397922269759

Epoch: 6| Step: 2
Training loss: 1.1841601133346558
Validation loss: 1.9590309281503

Epoch: 6| Step: 3
Training loss: 2.3717098236083984
Validation loss: 1.9762171801700388

Epoch: 6| Step: 4
Training loss: 2.0076966285705566
Validation loss: 1.9700474636529082

Epoch: 6| Step: 5
Training loss: 1.9832432270050049
Validation loss: 1.9652252530538907

Epoch: 6| Step: 6
Training loss: 1.3691781759262085
Validation loss: 1.9570256369088286

Epoch: 6| Step: 7
Training loss: 1.724600076675415
Validation loss: 1.9415855894806564

Epoch: 6| Step: 8
Training loss: 1.726548194885254
Validation loss: 1.9398983704146517

Epoch: 6| Step: 9
Training loss: 1.3859871625900269
Validation loss: 1.9411489886622275

Epoch: 6| Step: 10
Training loss: 2.161409854888916
Validation loss: 1.9359081176019484

Epoch: 6| Step: 11
Training loss: 1.8466770648956299
Validation loss: 1.9222435335959158

Epoch: 6| Step: 12
Training loss: 1.5154316425323486
Validation loss: 1.9249907129554338

Epoch: 6| Step: 13
Training loss: 2.807431697845459
Validation loss: 1.9425844133541148

Epoch: 464| Step: 0
Training loss: 2.280735969543457
Validation loss: 1.947130915939167

Epoch: 6| Step: 1
Training loss: 1.1879615783691406
Validation loss: 1.9726405759011545

Epoch: 6| Step: 2
Training loss: 1.6887428760528564
Validation loss: 1.9719895726890975

Epoch: 6| Step: 3
Training loss: 1.6989485025405884
Validation loss: 1.9714866171600998

Epoch: 6| Step: 4
Training loss: 2.301969289779663
Validation loss: 1.981548536208368

Epoch: 6| Step: 5
Training loss: 2.316822052001953
Validation loss: 1.9672125731745074

Epoch: 6| Step: 6
Training loss: 1.266412377357483
Validation loss: 1.9857142894498763

Epoch: 6| Step: 7
Training loss: 1.7490168809890747
Validation loss: 1.9587927966989496

Epoch: 6| Step: 8
Training loss: 1.9071862697601318
Validation loss: 1.9641549253976474

Epoch: 6| Step: 9
Training loss: 2.298250198364258
Validation loss: 1.962351426001518

Epoch: 6| Step: 10
Training loss: 1.891435146331787
Validation loss: 1.954922822213942

Epoch: 6| Step: 11
Training loss: 1.970398187637329
Validation loss: 1.9516779556069324

Epoch: 6| Step: 12
Training loss: 1.5724282264709473
Validation loss: 1.9452957248175016

Epoch: 6| Step: 13
Training loss: 0.9882614612579346
Validation loss: 1.9369475174975652

Epoch: 465| Step: 0
Training loss: 2.7149038314819336
Validation loss: 1.9534315973199823

Epoch: 6| Step: 1
Training loss: 1.824295997619629
Validation loss: 1.9299596483989427

Epoch: 6| Step: 2
Training loss: 2.239567279815674
Validation loss: 1.9462002118428547

Epoch: 6| Step: 3
Training loss: 1.7279781103134155
Validation loss: 1.9468186696370442

Epoch: 6| Step: 4
Training loss: 2.040133476257324
Validation loss: 1.9462393124898274

Epoch: 6| Step: 5
Training loss: 1.4207065105438232
Validation loss: 1.9318288603136617

Epoch: 6| Step: 6
Training loss: 1.3558515310287476
Validation loss: 1.9401176475709485

Epoch: 6| Step: 7
Training loss: 1.6968779563903809
Validation loss: 1.9517188610569123

Epoch: 6| Step: 8
Training loss: 1.6848387718200684
Validation loss: 1.9455186628526258

Epoch: 6| Step: 9
Training loss: 1.7153676748275757
Validation loss: 1.936010519663493

Epoch: 6| Step: 10
Training loss: 1.600895643234253
Validation loss: 1.965299944723806

Epoch: 6| Step: 11
Training loss: 1.993647575378418
Validation loss: 1.9681615342376053

Epoch: 6| Step: 12
Training loss: 1.678999662399292
Validation loss: 1.9850776118616904

Epoch: 6| Step: 13
Training loss: 1.7307347059249878
Validation loss: 1.9570224695308234

Epoch: 466| Step: 0
Training loss: 1.1014965772628784
Validation loss: 1.9626581053580008

Epoch: 6| Step: 1
Training loss: 2.1067376136779785
Validation loss: 1.959250078406385

Epoch: 6| Step: 2
Training loss: 1.5800080299377441
Validation loss: 1.9508731724113546

Epoch: 6| Step: 3
Training loss: 1.3760424852371216
Validation loss: 1.9415856612625944

Epoch: 6| Step: 4
Training loss: 2.2323689460754395
Validation loss: 1.94144852699772

Epoch: 6| Step: 5
Training loss: 1.358368158340454
Validation loss: 1.9446980325124597

Epoch: 6| Step: 6
Training loss: 1.6264511346817017
Validation loss: 1.9462071054725236

Epoch: 6| Step: 7
Training loss: 2.1783928871154785
Validation loss: 1.9368141902390348

Epoch: 6| Step: 8
Training loss: 2.251323699951172
Validation loss: 1.9315238665508967

Epoch: 6| Step: 9
Training loss: 1.4152863025665283
Validation loss: 1.9462888112632177

Epoch: 6| Step: 10
Training loss: 1.8710185289382935
Validation loss: 1.937785138366043

Epoch: 6| Step: 11
Training loss: 2.0035080909729004
Validation loss: 1.9546175990053403

Epoch: 6| Step: 12
Training loss: 2.4146595001220703
Validation loss: 1.9357965530887726

Epoch: 6| Step: 13
Training loss: 1.596032738685608
Validation loss: 1.9252174413332375

Epoch: 467| Step: 0
Training loss: 1.5735886096954346
Validation loss: 1.9524217472281507

Epoch: 6| Step: 1
Training loss: 1.8945773839950562
Validation loss: 1.955861917106054

Epoch: 6| Step: 2
Training loss: 2.5976829528808594
Validation loss: 1.9483142616928264

Epoch: 6| Step: 3
Training loss: 1.2054134607315063
Validation loss: 1.947901254059166

Epoch: 6| Step: 4
Training loss: 1.9280803203582764
Validation loss: 1.9461346262244767

Epoch: 6| Step: 5
Training loss: 2.113015651702881
Validation loss: 1.9350385717166367

Epoch: 6| Step: 6
Training loss: 1.293630599975586
Validation loss: 1.957153034466569

Epoch: 6| Step: 7
Training loss: 1.5238618850708008
Validation loss: 1.9733650786902315

Epoch: 6| Step: 8
Training loss: 1.5695724487304688
Validation loss: 1.9756228564887919

Epoch: 6| Step: 9
Training loss: 2.1020045280456543
Validation loss: 1.9681231591009325

Epoch: 6| Step: 10
Training loss: 2.093080997467041
Validation loss: 1.9585805887817054

Epoch: 6| Step: 11
Training loss: 2.3964381217956543
Validation loss: 1.9487552309548983

Epoch: 6| Step: 12
Training loss: 1.8474972248077393
Validation loss: 1.9603516004418815

Epoch: 6| Step: 13
Training loss: 0.9379457831382751
Validation loss: 1.9393746981056788

Epoch: 468| Step: 0
Training loss: 1.7222799062728882
Validation loss: 1.948381454713883

Epoch: 6| Step: 1
Training loss: 1.780339002609253
Validation loss: 1.9454345357033513

Epoch: 6| Step: 2
Training loss: 1.5163851976394653
Validation loss: 1.9370235730242986

Epoch: 6| Step: 3
Training loss: 1.0260629653930664
Validation loss: 1.9569231464016823

Epoch: 6| Step: 4
Training loss: 1.3237780332565308
Validation loss: 1.9440367990924465

Epoch: 6| Step: 5
Training loss: 1.975914716720581
Validation loss: 1.951518645850561

Epoch: 6| Step: 6
Training loss: 2.1936209201812744
Validation loss: 1.9516622558716805

Epoch: 6| Step: 7
Training loss: 1.808470606803894
Validation loss: 1.9642611293382541

Epoch: 6| Step: 8
Training loss: 1.658919095993042
Validation loss: 1.977411231686992

Epoch: 6| Step: 9
Training loss: 2.1102418899536133
Validation loss: 1.9698169667233703

Epoch: 6| Step: 10
Training loss: 2.1629550457000732
Validation loss: 1.980769480428388

Epoch: 6| Step: 11
Training loss: 2.1897902488708496
Validation loss: 1.9664178714957288

Epoch: 6| Step: 12
Training loss: 2.0885963439941406
Validation loss: 1.947050840623917

Epoch: 6| Step: 13
Training loss: 1.9238379001617432
Validation loss: 1.9541701462961012

Epoch: 469| Step: 0
Training loss: 2.32302188873291
Validation loss: 1.9414998895378524

Epoch: 6| Step: 1
Training loss: 1.8221964836120605
Validation loss: 1.9281941921480241

Epoch: 6| Step: 2
Training loss: 1.623993158340454
Validation loss: 1.9394613414682367

Epoch: 6| Step: 3
Training loss: 1.089529275894165
Validation loss: 1.9422772956150833

Epoch: 6| Step: 4
Training loss: 1.945857048034668
Validation loss: 1.9277829354809177

Epoch: 6| Step: 5
Training loss: 1.7914468050003052
Validation loss: 1.9357002730010657

Epoch: 6| Step: 6
Training loss: 1.2961137294769287
Validation loss: 1.9239129443322458

Epoch: 6| Step: 7
Training loss: 1.7585031986236572
Validation loss: 1.9416553179423015

Epoch: 6| Step: 8
Training loss: 2.004204034805298
Validation loss: 1.946819769438877

Epoch: 6| Step: 9
Training loss: 1.9764516353607178
Validation loss: 1.9514877526990828

Epoch: 6| Step: 10
Training loss: 1.7243409156799316
Validation loss: 1.94228151793121

Epoch: 6| Step: 11
Training loss: 1.9308604001998901
Validation loss: 1.9591809677821335

Epoch: 6| Step: 12
Training loss: 1.9816782474517822
Validation loss: 1.9539820955645653

Epoch: 6| Step: 13
Training loss: 1.9527677297592163
Validation loss: 1.9646621404155609

Epoch: 470| Step: 0
Training loss: 2.072303295135498
Validation loss: 2.0045043371056996

Epoch: 6| Step: 1
Training loss: 1.5058815479278564
Validation loss: 1.9983778999697777

Epoch: 6| Step: 2
Training loss: 2.3244495391845703
Validation loss: 1.9734433748388802

Epoch: 6| Step: 3
Training loss: 1.366628646850586
Validation loss: 1.9418551678298621

Epoch: 6| Step: 4
Training loss: 2.4347190856933594
Validation loss: 1.9395224727610105

Epoch: 6| Step: 5
Training loss: 2.2511069774627686
Validation loss: 1.944421786133961

Epoch: 6| Step: 6
Training loss: 2.085873603820801
Validation loss: 1.9432910411588606

Epoch: 6| Step: 7
Training loss: 1.6798720359802246
Validation loss: 1.9255091541556901

Epoch: 6| Step: 8
Training loss: 1.8033860921859741
Validation loss: 1.9343150546473842

Epoch: 6| Step: 9
Training loss: 1.6849288940429688
Validation loss: 1.9266136730870893

Epoch: 6| Step: 10
Training loss: 1.579186201095581
Validation loss: 1.945251641734954

Epoch: 6| Step: 11
Training loss: 1.994936227798462
Validation loss: 1.9731894129066057

Epoch: 6| Step: 12
Training loss: 1.1406404972076416
Validation loss: 1.980252637658068

Epoch: 6| Step: 13
Training loss: 1.1236860752105713
Validation loss: 1.9981273297340638

Epoch: 471| Step: 0
Training loss: 1.6869300603866577
Validation loss: 2.018776794915558

Epoch: 6| Step: 1
Training loss: 2.116713285446167
Validation loss: 2.0417635876645326

Epoch: 6| Step: 2
Training loss: 2.48451828956604
Validation loss: 2.0204343103593394

Epoch: 6| Step: 3
Training loss: 1.9264870882034302
Validation loss: 1.9690651688524472

Epoch: 6| Step: 4
Training loss: 1.8348114490509033
Validation loss: 1.9642980162815382

Epoch: 6| Step: 5
Training loss: 1.4059745073318481
Validation loss: 1.9504507754438667

Epoch: 6| Step: 6
Training loss: 1.7687095403671265
Validation loss: 1.9486775449527207

Epoch: 6| Step: 7
Training loss: 1.67827570438385
Validation loss: 1.930581638889928

Epoch: 6| Step: 8
Training loss: 1.1367812156677246
Validation loss: 1.9412912502083728

Epoch: 6| Step: 9
Training loss: 1.8754528760910034
Validation loss: 1.9191303919720393

Epoch: 6| Step: 10
Training loss: 1.7936153411865234
Validation loss: 1.942786616663779

Epoch: 6| Step: 11
Training loss: 1.4244201183319092
Validation loss: 1.9415880582665885

Epoch: 6| Step: 12
Training loss: 2.1647140979766846
Validation loss: 1.9482014820139895

Epoch: 6| Step: 13
Training loss: 1.8589401245117188
Validation loss: 1.9811427849595264

Epoch: 472| Step: 0
Training loss: 1.1409004926681519
Validation loss: 1.9698365401196223

Epoch: 6| Step: 1
Training loss: 1.317591667175293
Validation loss: 1.9842858622151036

Epoch: 6| Step: 2
Training loss: 2.047239303588867
Validation loss: 1.967399904804845

Epoch: 6| Step: 3
Training loss: 1.8748438358306885
Validation loss: 1.9717253843943279

Epoch: 6| Step: 4
Training loss: 1.691732406616211
Validation loss: 1.9653363509844708

Epoch: 6| Step: 5
Training loss: 1.9500151872634888
Validation loss: 1.941844558203092

Epoch: 6| Step: 6
Training loss: 2.199016809463501
Validation loss: 1.9556023690008348

Epoch: 6| Step: 7
Training loss: 1.631066083908081
Validation loss: 1.9295104344685872

Epoch: 6| Step: 8
Training loss: 1.867213249206543
Validation loss: 1.9432527621587117

Epoch: 6| Step: 9
Training loss: 1.6953709125518799
Validation loss: 1.9475603180546914

Epoch: 6| Step: 10
Training loss: 1.7930341958999634
Validation loss: 1.9382716148130354

Epoch: 6| Step: 11
Training loss: 1.9692867994308472
Validation loss: 1.9468880468799221

Epoch: 6| Step: 12
Training loss: 2.581914186477661
Validation loss: 1.9389295719003166

Epoch: 6| Step: 13
Training loss: 1.433503270149231
Validation loss: 1.962878155451949

Epoch: 473| Step: 0
Training loss: 1.7100476026535034
Validation loss: 1.9751908189506941

Epoch: 6| Step: 1
Training loss: 2.1880645751953125
Validation loss: 1.9686164086864841

Epoch: 6| Step: 2
Training loss: 1.8146177530288696
Validation loss: 1.957260072872203

Epoch: 6| Step: 3
Training loss: 1.5132851600646973
Validation loss: 1.9623635917581537

Epoch: 6| Step: 4
Training loss: 1.8108172416687012
Validation loss: 1.961775436196276

Epoch: 6| Step: 5
Training loss: 1.593521237373352
Validation loss: 1.9800582239704747

Epoch: 6| Step: 6
Training loss: 1.8848010301589966
Validation loss: 1.9684636157046083

Epoch: 6| Step: 7
Training loss: 1.8331657648086548
Validation loss: 1.9456767805161015

Epoch: 6| Step: 8
Training loss: 2.099602699279785
Validation loss: 1.9358150036104265

Epoch: 6| Step: 9
Training loss: 1.6043140888214111
Validation loss: 1.9494705943651096

Epoch: 6| Step: 10
Training loss: 2.129944324493408
Validation loss: 1.9439402344406291

Epoch: 6| Step: 11
Training loss: 1.6993281841278076
Validation loss: 1.9596779179829422

Epoch: 6| Step: 12
Training loss: 1.6230430603027344
Validation loss: 1.939125955745738

Epoch: 6| Step: 13
Training loss: 1.2423012256622314
Validation loss: 1.9561041093641711

Epoch: 474| Step: 0
Training loss: 2.3127400875091553
Validation loss: 1.9528084954907816

Epoch: 6| Step: 1
Training loss: 1.7008628845214844
Validation loss: 1.9506437848973017

Epoch: 6| Step: 2
Training loss: 1.5604629516601562
Validation loss: 1.959127741475259

Epoch: 6| Step: 3
Training loss: 1.8752893209457397
Validation loss: 1.9712282996023855

Epoch: 6| Step: 4
Training loss: 1.112696647644043
Validation loss: 1.966228283861632

Epoch: 6| Step: 5
Training loss: 1.974446177482605
Validation loss: 1.9475364479967343

Epoch: 6| Step: 6
Training loss: 1.6695640087127686
Validation loss: 1.9620738619117326

Epoch: 6| Step: 7
Training loss: 1.969690203666687
Validation loss: 1.9623825011714813

Epoch: 6| Step: 8
Training loss: 1.4407739639282227
Validation loss: 1.9572061466914352

Epoch: 6| Step: 9
Training loss: 1.6487302780151367
Validation loss: 1.9532301720752512

Epoch: 6| Step: 10
Training loss: 1.548219919204712
Validation loss: 1.9470134473616076

Epoch: 6| Step: 11
Training loss: 1.59891676902771
Validation loss: 1.9357520047054495

Epoch: 6| Step: 12
Training loss: 2.6066014766693115
Validation loss: 1.9414541990526262

Epoch: 6| Step: 13
Training loss: 2.139242649078369
Validation loss: 1.9323171646364274

Epoch: 475| Step: 0
Training loss: 1.124273419380188
Validation loss: 1.9471796520294682

Epoch: 6| Step: 1
Training loss: 2.2696995735168457
Validation loss: 1.9514237116741877

Epoch: 6| Step: 2
Training loss: 1.5944206714630127
Validation loss: 1.9801561781155166

Epoch: 6| Step: 3
Training loss: 2.0074117183685303
Validation loss: 1.9963209975150324

Epoch: 6| Step: 4
Training loss: 1.6615301370620728
Validation loss: 1.9763837693839945

Epoch: 6| Step: 5
Training loss: 2.3398118019104004
Validation loss: 1.9922589281553864

Epoch: 6| Step: 6
Training loss: 1.9664705991744995
Validation loss: 1.959561986307944

Epoch: 6| Step: 7
Training loss: 2.1320343017578125
Validation loss: 1.9679814436102425

Epoch: 6| Step: 8
Training loss: 2.27028489112854
Validation loss: 1.9779702078911565

Epoch: 6| Step: 9
Training loss: 1.9860657453536987
Validation loss: 1.949939791874219

Epoch: 6| Step: 10
Training loss: 0.9176741242408752
Validation loss: 1.9418571033785421

Epoch: 6| Step: 11
Training loss: 1.439805030822754
Validation loss: 1.9427339492305633

Epoch: 6| Step: 12
Training loss: 1.869231939315796
Validation loss: 1.9282919553018385

Epoch: 6| Step: 13
Training loss: 1.4123884439468384
Validation loss: 1.933534388901085

Epoch: 476| Step: 0
Training loss: 1.1456713676452637
Validation loss: 1.9338381546799854

Epoch: 6| Step: 1
Training loss: 1.5049329996109009
Validation loss: 1.9437254731373121

Epoch: 6| Step: 2
Training loss: 1.7060084342956543
Validation loss: 1.9287938828109412

Epoch: 6| Step: 3
Training loss: 2.1796061992645264
Validation loss: 1.9574964546388196

Epoch: 6| Step: 4
Training loss: 2.1732616424560547
Validation loss: 1.9576769567305041

Epoch: 6| Step: 5
Training loss: 2.0454394817352295
Validation loss: 1.974249812864488

Epoch: 6| Step: 6
Training loss: 1.7339162826538086
Validation loss: 1.9579493948208389

Epoch: 6| Step: 7
Training loss: 1.4740443229675293
Validation loss: 1.9544993972265592

Epoch: 6| Step: 8
Training loss: 1.6916730403900146
Validation loss: 1.9304833591625254

Epoch: 6| Step: 9
Training loss: 1.451646327972412
Validation loss: 1.9541492154521327

Epoch: 6| Step: 10
Training loss: 2.212040901184082
Validation loss: 1.9709881505658549

Epoch: 6| Step: 11
Training loss: 1.8810027837753296
Validation loss: 1.9742044300161383

Epoch: 6| Step: 12
Training loss: 2.090226411819458
Validation loss: 1.9654808172615625

Epoch: 6| Step: 13
Training loss: 1.7224059104919434
Validation loss: 1.957711983752507

Epoch: 477| Step: 0
Training loss: 1.2218565940856934
Validation loss: 1.957087839803388

Epoch: 6| Step: 1
Training loss: 2.179187536239624
Validation loss: 1.9667231254680182

Epoch: 6| Step: 2
Training loss: 1.0429836511611938
Validation loss: 1.9452265731749996

Epoch: 6| Step: 3
Training loss: 1.4667370319366455
Validation loss: 1.9323689271044988

Epoch: 6| Step: 4
Training loss: 1.1299750804901123
Validation loss: 1.9463244868863014

Epoch: 6| Step: 5
Training loss: 2.173107862472534
Validation loss: 1.9517917120328514

Epoch: 6| Step: 6
Training loss: 1.8230479955673218
Validation loss: 1.939731615845875

Epoch: 6| Step: 7
Training loss: 2.2079503536224365
Validation loss: 1.9404885025434597

Epoch: 6| Step: 8
Training loss: 1.7378867864608765
Validation loss: 1.928693599598382

Epoch: 6| Step: 9
Training loss: 2.667475700378418
Validation loss: 1.9422422403930335

Epoch: 6| Step: 10
Training loss: 1.5521502494812012
Validation loss: 1.9437846932359921

Epoch: 6| Step: 11
Training loss: 1.6309666633605957
Validation loss: 1.9481144797417425

Epoch: 6| Step: 12
Training loss: 2.6046180725097656
Validation loss: 1.9467553105405582

Epoch: 6| Step: 13
Training loss: 1.3887760639190674
Validation loss: 1.9663814216531732

Epoch: 478| Step: 0
Training loss: 1.1272133588790894
Validation loss: 1.9685108648833407

Epoch: 6| Step: 1
Training loss: 1.9124464988708496
Validation loss: 1.9626809935415945

Epoch: 6| Step: 2
Training loss: 1.8596513271331787
Validation loss: 1.974419875811505

Epoch: 6| Step: 3
Training loss: 1.9720271825790405
Validation loss: 1.9540942676605717

Epoch: 6| Step: 4
Training loss: 1.2610337734222412
Validation loss: 1.9777215885859665

Epoch: 6| Step: 5
Training loss: 1.866923213005066
Validation loss: 1.9635710024064588

Epoch: 6| Step: 6
Training loss: 1.504798412322998
Validation loss: 1.9536509539491387

Epoch: 6| Step: 7
Training loss: 2.365769386291504
Validation loss: 1.9507608208605038

Epoch: 6| Step: 8
Training loss: 2.137813091278076
Validation loss: 1.9452119001778223

Epoch: 6| Step: 9
Training loss: 1.329673171043396
Validation loss: 1.9425080694178098

Epoch: 6| Step: 10
Training loss: 1.689316987991333
Validation loss: 1.9427079500690583

Epoch: 6| Step: 11
Training loss: 1.7704315185546875
Validation loss: 1.9322166058324999

Epoch: 6| Step: 12
Training loss: 2.4750845432281494
Validation loss: 1.9228859819391722

Epoch: 6| Step: 13
Training loss: 1.3605268001556396
Validation loss: 1.9248925562827819

Epoch: 479| Step: 0
Training loss: 1.5655488967895508
Validation loss: 1.9468564423181678

Epoch: 6| Step: 1
Training loss: 1.2816591262817383
Validation loss: 1.9305966566967707

Epoch: 6| Step: 2
Training loss: 1.853257656097412
Validation loss: 1.9306877402849094

Epoch: 6| Step: 3
Training loss: 1.575058937072754
Validation loss: 1.9712556472388647

Epoch: 6| Step: 4
Training loss: 1.595611810684204
Validation loss: 1.9860031335584578

Epoch: 6| Step: 5
Training loss: 2.6035032272338867
Validation loss: 1.9764776370858634

Epoch: 6| Step: 6
Training loss: 2.388347864151001
Validation loss: 1.9750944440082838

Epoch: 6| Step: 7
Training loss: 1.7660014629364014
Validation loss: 1.96558347312353

Epoch: 6| Step: 8
Training loss: 2.1017189025878906
Validation loss: 1.969007153664866

Epoch: 6| Step: 9
Training loss: 1.8345361948013306
Validation loss: 1.9631372831201042

Epoch: 6| Step: 10
Training loss: 2.0294628143310547
Validation loss: 1.944979457445042

Epoch: 6| Step: 11
Training loss: 1.3445045948028564
Validation loss: 1.9660096681246193

Epoch: 6| Step: 12
Training loss: 1.2939215898513794
Validation loss: 1.935322364171346

Epoch: 6| Step: 13
Training loss: 1.6126757860183716
Validation loss: 1.9286935919074601

Epoch: 480| Step: 0
Training loss: 1.7753574848175049
Validation loss: 1.9429591317330637

Epoch: 6| Step: 1
Training loss: 1.7181572914123535
Validation loss: 1.9439533269533547

Epoch: 6| Step: 2
Training loss: 1.825238823890686
Validation loss: 1.9474228953802457

Epoch: 6| Step: 3
Training loss: 1.5991489887237549
Validation loss: 1.9422493032229844

Epoch: 6| Step: 4
Training loss: 1.5461796522140503
Validation loss: 1.942891957939312

Epoch: 6| Step: 5
Training loss: 2.3234810829162598
Validation loss: 1.9579701090371737

Epoch: 6| Step: 6
Training loss: 1.9429124593734741
Validation loss: 1.9576948163329915

Epoch: 6| Step: 7
Training loss: 1.72768235206604
Validation loss: 1.9680091104199808

Epoch: 6| Step: 8
Training loss: 1.6188530921936035
Validation loss: 1.9638935622348581

Epoch: 6| Step: 9
Training loss: 2.0669970512390137
Validation loss: 1.9571172703978836

Epoch: 6| Step: 10
Training loss: 2.142843246459961
Validation loss: 1.9371318996593516

Epoch: 6| Step: 11
Training loss: 1.0375711917877197
Validation loss: 1.9278511667764315

Epoch: 6| Step: 12
Training loss: 1.8118579387664795
Validation loss: 1.9381626882860739

Epoch: 6| Step: 13
Training loss: 1.5884591341018677
Validation loss: 1.93146470028867

Epoch: 481| Step: 0
Training loss: 1.9639673233032227
Validation loss: 1.9385666565228534

Epoch: 6| Step: 1
Training loss: 1.9419136047363281
Validation loss: 1.9259733923019902

Epoch: 6| Step: 2
Training loss: 1.7009005546569824
Validation loss: 1.9274479766045847

Epoch: 6| Step: 3
Training loss: 1.8015360832214355
Validation loss: 1.9261009539327314

Epoch: 6| Step: 4
Training loss: 1.505277395248413
Validation loss: 1.9455090748366488

Epoch: 6| Step: 5
Training loss: 1.9131525754928589
Validation loss: 1.9588146491717267

Epoch: 6| Step: 6
Training loss: 2.2762064933776855
Validation loss: 1.9406402700690812

Epoch: 6| Step: 7
Training loss: 2.013369083404541
Validation loss: 1.9325799621561521

Epoch: 6| Step: 8
Training loss: 1.2555301189422607
Validation loss: 1.935551986899427

Epoch: 6| Step: 9
Training loss: 1.9397555589675903
Validation loss: 1.9408342607559697

Epoch: 6| Step: 10
Training loss: 1.8399536609649658
Validation loss: 1.9354926206732308

Epoch: 6| Step: 11
Training loss: 1.1669470071792603
Validation loss: 1.9417956016396964

Epoch: 6| Step: 12
Training loss: 1.587341070175171
Validation loss: 1.942660976481694

Epoch: 6| Step: 13
Training loss: 1.7564319372177124
Validation loss: 1.9345428097632624

Epoch: 482| Step: 0
Training loss: 1.2627780437469482
Validation loss: 1.9430616132674678

Epoch: 6| Step: 1
Training loss: 2.2371437549591064
Validation loss: 1.9281901569776638

Epoch: 6| Step: 2
Training loss: 1.3843644857406616
Validation loss: 1.9410825801152054

Epoch: 6| Step: 3
Training loss: 1.830495834350586
Validation loss: 1.952999876391503

Epoch: 6| Step: 4
Training loss: 2.11722731590271
Validation loss: 1.9565003584789973

Epoch: 6| Step: 5
Training loss: 0.8901685476303101
Validation loss: 1.9472687244415283

Epoch: 6| Step: 6
Training loss: 2.4064693450927734
Validation loss: 1.963969233215496

Epoch: 6| Step: 7
Training loss: 1.5340979099273682
Validation loss: 1.9631370882834158

Epoch: 6| Step: 8
Training loss: 2.02085018157959
Validation loss: 1.9594498577938284

Epoch: 6| Step: 9
Training loss: 1.052420735359192
Validation loss: 1.9519679213082919

Epoch: 6| Step: 10
Training loss: 1.7928860187530518
Validation loss: 1.9733015106570335

Epoch: 6| Step: 11
Training loss: 2.0846805572509766
Validation loss: 2.0005343191085325

Epoch: 6| Step: 12
Training loss: 2.2549123764038086
Validation loss: 2.000256722973239

Epoch: 6| Step: 13
Training loss: 2.433291435241699
Validation loss: 2.01425229349444

Epoch: 483| Step: 0
Training loss: 2.156353712081909
Validation loss: 2.0082609320199616

Epoch: 6| Step: 1
Training loss: 2.365462303161621
Validation loss: 1.9600623961417907

Epoch: 6| Step: 2
Training loss: 1.6664128303527832
Validation loss: 1.9640212264112247

Epoch: 6| Step: 3
Training loss: 1.1760444641113281
Validation loss: 1.9423874578168314

Epoch: 6| Step: 4
Training loss: 1.8202271461486816
Validation loss: 1.946716143238929

Epoch: 6| Step: 5
Training loss: 2.005850315093994
Validation loss: 1.94154360986525

Epoch: 6| Step: 6
Training loss: 1.7116072177886963
Validation loss: 1.959463466880142

Epoch: 6| Step: 7
Training loss: 1.4947582483291626
Validation loss: 1.9536334007017073

Epoch: 6| Step: 8
Training loss: 2.429203510284424
Validation loss: 1.9689110684138473

Epoch: 6| Step: 9
Training loss: 1.9294512271881104
Validation loss: 1.9553627467924548

Epoch: 6| Step: 10
Training loss: 1.7984802722930908
Validation loss: 1.9615352512687765

Epoch: 6| Step: 11
Training loss: 1.366191029548645
Validation loss: 1.9755552814852806

Epoch: 6| Step: 12
Training loss: 1.7271385192871094
Validation loss: 1.956807203190301

Epoch: 6| Step: 13
Training loss: 1.3480453491210938
Validation loss: 1.9689667865794191

Epoch: 484| Step: 0
Training loss: 1.8180067539215088
Validation loss: 1.9608504438912997

Epoch: 6| Step: 1
Training loss: 1.6671913862228394
Validation loss: 1.960965794901694

Epoch: 6| Step: 2
Training loss: 1.9112162590026855
Validation loss: 1.9346090619282057

Epoch: 6| Step: 3
Training loss: 1.7431926727294922
Validation loss: 1.9378009380832795

Epoch: 6| Step: 4
Training loss: 1.6050572395324707
Validation loss: 1.9408399456290788

Epoch: 6| Step: 5
Training loss: 1.3865346908569336
Validation loss: 1.9612307317795292

Epoch: 6| Step: 6
Training loss: 1.5678751468658447
Validation loss: 1.935852986510082

Epoch: 6| Step: 7
Training loss: 2.0481743812561035
Validation loss: 1.932189735033179

Epoch: 6| Step: 8
Training loss: 1.3847308158874512
Validation loss: 1.9512112320110362

Epoch: 6| Step: 9
Training loss: 1.8490828275680542
Validation loss: 1.9412660675664102

Epoch: 6| Step: 10
Training loss: 2.1211915016174316
Validation loss: 1.9545363944063905

Epoch: 6| Step: 11
Training loss: 2.276272773742676
Validation loss: 1.9481331968820224

Epoch: 6| Step: 12
Training loss: 1.4009002447128296
Validation loss: 1.9587960550861974

Epoch: 6| Step: 13
Training loss: 1.9789597988128662
Validation loss: 1.9425621917170863

Epoch: 485| Step: 0
Training loss: 1.8499417304992676
Validation loss: 1.9433578752702283

Epoch: 6| Step: 1
Training loss: 2.1258139610290527
Validation loss: 1.9484318917797459

Epoch: 6| Step: 2
Training loss: 1.7128887176513672
Validation loss: 1.9522116261143838

Epoch: 6| Step: 3
Training loss: 1.6500611305236816
Validation loss: 1.959056254356138

Epoch: 6| Step: 4
Training loss: 2.538902759552002
Validation loss: 1.9440000992949291

Epoch: 6| Step: 5
Training loss: 2.084986925125122
Validation loss: 1.939093800001247

Epoch: 6| Step: 6
Training loss: 1.5000380277633667
Validation loss: 1.9492269139136038

Epoch: 6| Step: 7
Training loss: 1.4041630029678345
Validation loss: 1.935737713690727

Epoch: 6| Step: 8
Training loss: 1.5850715637207031
Validation loss: 1.9499526844229749

Epoch: 6| Step: 9
Training loss: 1.6320569515228271
Validation loss: 1.9497575606069257

Epoch: 6| Step: 10
Training loss: 1.892380952835083
Validation loss: 1.9677434698227914

Epoch: 6| Step: 11
Training loss: 1.3748623132705688
Validation loss: 1.9723790050834737

Epoch: 6| Step: 12
Training loss: 1.7842974662780762
Validation loss: 1.97364293759869

Epoch: 6| Step: 13
Training loss: 1.217509150505066
Validation loss: 1.9801739620906051

Epoch: 486| Step: 0
Training loss: 1.8577632904052734
Validation loss: 1.9866708760620446

Epoch: 6| Step: 1
Training loss: 1.4161624908447266
Validation loss: 1.9971305298548874

Epoch: 6| Step: 2
Training loss: 1.4947082996368408
Validation loss: 1.969231693975387

Epoch: 6| Step: 3
Training loss: 1.3320965766906738
Validation loss: 1.977476542995822

Epoch: 6| Step: 4
Training loss: 1.6026535034179688
Validation loss: 1.9518763275556668

Epoch: 6| Step: 5
Training loss: 1.9877638816833496
Validation loss: 1.9448683556690012

Epoch: 6| Step: 6
Training loss: 1.2174959182739258
Validation loss: 1.9638770318800403

Epoch: 6| Step: 7
Training loss: 1.6823947429656982
Validation loss: 1.9570504106501097

Epoch: 6| Step: 8
Training loss: 1.9484615325927734
Validation loss: 1.9609259995081092

Epoch: 6| Step: 9
Training loss: 1.5728912353515625
Validation loss: 1.9439317808356336

Epoch: 6| Step: 10
Training loss: 2.49938702583313
Validation loss: 1.961237011417266

Epoch: 6| Step: 11
Training loss: 2.197054862976074
Validation loss: 1.9346250616094118

Epoch: 6| Step: 12
Training loss: 2.1599857807159424
Validation loss: 1.9302065603194698

Epoch: 6| Step: 13
Training loss: 1.664842963218689
Validation loss: 1.9651101378984348

Epoch: 487| Step: 0
Training loss: 2.2437145709991455
Validation loss: 1.974713861301381

Epoch: 6| Step: 1
Training loss: 1.7932015657424927
Validation loss: 1.9595412528643044

Epoch: 6| Step: 2
Training loss: 1.572248101234436
Validation loss: 1.9688934972209315

Epoch: 6| Step: 3
Training loss: 1.7375624179840088
Validation loss: 1.9673016532774894

Epoch: 6| Step: 4
Training loss: 1.9428958892822266
Validation loss: 1.9566096285338044

Epoch: 6| Step: 5
Training loss: 1.817882776260376
Validation loss: 1.9543267860207507

Epoch: 6| Step: 6
Training loss: 1.9211997985839844
Validation loss: 1.9493895217936525

Epoch: 6| Step: 7
Training loss: 1.5144778490066528
Validation loss: 1.9388782439693328

Epoch: 6| Step: 8
Training loss: 0.9930820465087891
Validation loss: 1.9383650082413868

Epoch: 6| Step: 9
Training loss: 1.3614869117736816
Validation loss: 1.925721336436528

Epoch: 6| Step: 10
Training loss: 2.396976947784424
Validation loss: 1.9216236657993768

Epoch: 6| Step: 11
Training loss: 1.8323194980621338
Validation loss: 1.9362132856922765

Epoch: 6| Step: 12
Training loss: 1.3452337980270386
Validation loss: 1.938700052999681

Epoch: 6| Step: 13
Training loss: 2.29067325592041
Validation loss: 1.929699287619642

Epoch: 488| Step: 0
Training loss: 2.250859498977661
Validation loss: 1.9301487758595457

Epoch: 6| Step: 1
Training loss: 1.811090350151062
Validation loss: 1.950811247671804

Epoch: 6| Step: 2
Training loss: 1.7430715560913086
Validation loss: 1.9537569169075257

Epoch: 6| Step: 3
Training loss: 1.8197709321975708
Validation loss: 1.9775221219626806

Epoch: 6| Step: 4
Training loss: 2.2792673110961914
Validation loss: 1.9786191242997364

Epoch: 6| Step: 5
Training loss: 2.077789783477783
Validation loss: 1.98986893059105

Epoch: 6| Step: 6
Training loss: 1.338962197303772
Validation loss: 2.000317176183065

Epoch: 6| Step: 7
Training loss: 2.3795998096466064
Validation loss: 2.021565084816307

Epoch: 6| Step: 8
Training loss: 1.5639325380325317
Validation loss: 2.005764510041924

Epoch: 6| Step: 9
Training loss: 1.4407291412353516
Validation loss: 2.0046760702645905

Epoch: 6| Step: 10
Training loss: 1.6652477979660034
Validation loss: 1.9953725799437492

Epoch: 6| Step: 11
Training loss: 1.5666086673736572
Validation loss: 1.9750999019991966

Epoch: 6| Step: 12
Training loss: 0.9762178659439087
Validation loss: 1.9748432149169266

Epoch: 6| Step: 13
Training loss: 1.9682104587554932
Validation loss: 1.9661042664640693

Epoch: 489| Step: 0
Training loss: 1.8981423377990723
Validation loss: 1.9667417221171881

Epoch: 6| Step: 1
Training loss: 2.2331182956695557
Validation loss: 1.9358242134894095

Epoch: 6| Step: 2
Training loss: 0.9516626000404358
Validation loss: 1.9422427159483715

Epoch: 6| Step: 3
Training loss: 1.610933780670166
Validation loss: 1.9310032501015613

Epoch: 6| Step: 4
Training loss: 1.96523118019104
Validation loss: 1.944395294753454

Epoch: 6| Step: 5
Training loss: 2.004303455352783
Validation loss: 1.927684469889569

Epoch: 6| Step: 6
Training loss: 1.3762152194976807
Validation loss: 1.9327230299672773

Epoch: 6| Step: 7
Training loss: 1.382519245147705
Validation loss: 1.9457764830640567

Epoch: 6| Step: 8
Training loss: 2.058652877807617
Validation loss: 1.9522413002547396

Epoch: 6| Step: 9
Training loss: 2.2593600749969482
Validation loss: 1.9744173172981507

Epoch: 6| Step: 10
Training loss: 1.2860348224639893
Validation loss: 1.9843475664815595

Epoch: 6| Step: 11
Training loss: 1.7015708684921265
Validation loss: 1.9975595525515977

Epoch: 6| Step: 12
Training loss: 2.2274208068847656
Validation loss: 1.9824556112289429

Epoch: 6| Step: 13
Training loss: 1.9245270490646362
Validation loss: 1.9640896217797392

Epoch: 490| Step: 0
Training loss: 1.5940544605255127
Validation loss: 1.9594808227272444

Epoch: 6| Step: 1
Training loss: 1.6791267395019531
Validation loss: 1.9247054694801249

Epoch: 6| Step: 2
Training loss: 1.6286649703979492
Validation loss: 1.9315455113687823

Epoch: 6| Step: 3
Training loss: 1.6843818426132202
Validation loss: 1.9208887392474758

Epoch: 6| Step: 4
Training loss: 1.66031014919281
Validation loss: 1.9511427135877712

Epoch: 6| Step: 5
Training loss: 1.6304563283920288
Validation loss: 1.9425443808237712

Epoch: 6| Step: 6
Training loss: 1.912940502166748
Validation loss: 1.941075184011972

Epoch: 6| Step: 7
Training loss: 1.9503165483474731
Validation loss: 1.9389236998814408

Epoch: 6| Step: 8
Training loss: 1.7068718671798706
Validation loss: 1.9302315609429472

Epoch: 6| Step: 9
Training loss: 2.299009084701538
Validation loss: 1.930501458465412

Epoch: 6| Step: 10
Training loss: 2.3470489978790283
Validation loss: 1.943586294369031

Epoch: 6| Step: 11
Training loss: 1.8034220933914185
Validation loss: 1.9453007623713503

Epoch: 6| Step: 12
Training loss: 1.4960873126983643
Validation loss: 1.9688924897101618

Epoch: 6| Step: 13
Training loss: 0.8340080380439758
Validation loss: 1.9839123320835892

Epoch: 491| Step: 0
Training loss: 1.7043027877807617
Validation loss: 1.9554168280734812

Epoch: 6| Step: 1
Training loss: 1.8160533905029297
Validation loss: 1.9502651358163485

Epoch: 6| Step: 2
Training loss: 1.808371901512146
Validation loss: 1.948564451227906

Epoch: 6| Step: 3
Training loss: 1.1809883117675781
Validation loss: 1.947793863152945

Epoch: 6| Step: 4
Training loss: 2.2589759826660156
Validation loss: 1.9351215080548358

Epoch: 6| Step: 5
Training loss: 2.062345266342163
Validation loss: 1.954638458067371

Epoch: 6| Step: 6
Training loss: 1.8589380979537964
Validation loss: 1.9495516541183635

Epoch: 6| Step: 7
Training loss: 1.7151732444763184
Validation loss: 1.963261970909693

Epoch: 6| Step: 8
Training loss: 1.10939359664917
Validation loss: 1.9422792875638573

Epoch: 6| Step: 9
Training loss: 2.009199380874634
Validation loss: 1.9417703946431477

Epoch: 6| Step: 10
Training loss: 2.149895668029785
Validation loss: 1.9369423466344033

Epoch: 6| Step: 11
Training loss: 1.8790287971496582
Validation loss: 1.93346893659202

Epoch: 6| Step: 12
Training loss: 1.6041951179504395
Validation loss: 1.9412890864956764

Epoch: 6| Step: 13
Training loss: 0.7933322787284851
Validation loss: 1.957481271477156

Epoch: 492| Step: 0
Training loss: 1.6864848136901855
Validation loss: 1.963570366623581

Epoch: 6| Step: 1
Training loss: 1.465709924697876
Validation loss: 1.978623354306785

Epoch: 6| Step: 2
Training loss: 2.0667858123779297
Validation loss: 1.996574181382374

Epoch: 6| Step: 3
Training loss: 1.5221813917160034
Validation loss: 1.9814800985397831

Epoch: 6| Step: 4
Training loss: 2.353837013244629
Validation loss: 1.9621955451144968

Epoch: 6| Step: 5
Training loss: 2.1437435150146484
Validation loss: 1.961265783156118

Epoch: 6| Step: 6
Training loss: 1.4302253723144531
Validation loss: 1.9546015390785791

Epoch: 6| Step: 7
Training loss: 1.156339168548584
Validation loss: 1.9338618465649184

Epoch: 6| Step: 8
Training loss: 1.5628538131713867
Validation loss: 1.9387087027231853

Epoch: 6| Step: 9
Training loss: 2.4673588275909424
Validation loss: 1.9332433990252915

Epoch: 6| Step: 10
Training loss: 1.3428468704223633
Validation loss: 1.9315341441862044

Epoch: 6| Step: 11
Training loss: 1.258738398551941
Validation loss: 1.9339641704354236

Epoch: 6| Step: 12
Training loss: 1.9820353984832764
Validation loss: 1.9436896975322435

Epoch: 6| Step: 13
Training loss: 1.763464331626892
Validation loss: 1.9335665138818885

Epoch: 493| Step: 0
Training loss: 1.0468014478683472
Validation loss: 1.9388337340406192

Epoch: 6| Step: 1
Training loss: 1.3551816940307617
Validation loss: 1.934815772118107

Epoch: 6| Step: 2
Training loss: 1.6947332620620728
Validation loss: 1.9493920059614285

Epoch: 6| Step: 3
Training loss: 0.9199713468551636
Validation loss: 1.9326561010012062

Epoch: 6| Step: 4
Training loss: 1.963184118270874
Validation loss: 1.9386532845035676

Epoch: 6| Step: 5
Training loss: 1.3821120262145996
Validation loss: 1.938349921216247

Epoch: 6| Step: 6
Training loss: 1.5423312187194824
Validation loss: 1.9540055374945364

Epoch: 6| Step: 7
Training loss: 2.024590492248535
Validation loss: 1.9191545940214587

Epoch: 6| Step: 8
Training loss: 2.284517765045166
Validation loss: 1.9325169158238236

Epoch: 6| Step: 9
Training loss: 2.1597094535827637
Validation loss: 1.92261335157579

Epoch: 6| Step: 10
Training loss: 2.3754801750183105
Validation loss: 1.9364973075928227

Epoch: 6| Step: 11
Training loss: 1.6373395919799805
Validation loss: 1.9153633707313127

Epoch: 6| Step: 12
Training loss: 1.974965214729309
Validation loss: 1.9408000605080717

Epoch: 6| Step: 13
Training loss: 2.0505778789520264
Validation loss: 1.9467620311244842

Epoch: 494| Step: 0
Training loss: 2.1542911529541016
Validation loss: 1.9516818779771046

Epoch: 6| Step: 1
Training loss: 2.15228009223938
Validation loss: 1.9681861631331905

Epoch: 6| Step: 2
Training loss: 1.126395344734192
Validation loss: 1.947936668190905

Epoch: 6| Step: 3
Training loss: 1.1977837085723877
Validation loss: 1.9325543949680943

Epoch: 6| Step: 4
Training loss: 1.9529869556427002
Validation loss: 1.9526509033736361

Epoch: 6| Step: 5
Training loss: 1.9475059509277344
Validation loss: 1.9468616106176888

Epoch: 6| Step: 6
Training loss: 2.2479968070983887
Validation loss: 1.9496583810416601

Epoch: 6| Step: 7
Training loss: 1.4510217905044556
Validation loss: 1.9570403611788185

Epoch: 6| Step: 8
Training loss: 1.5588183403015137
Validation loss: 1.95852768036627

Epoch: 6| Step: 9
Training loss: 1.4195420742034912
Validation loss: 1.9664721809407717

Epoch: 6| Step: 10
Training loss: 1.5240223407745361
Validation loss: 1.9436123319851455

Epoch: 6| Step: 11
Training loss: 2.248082160949707
Validation loss: 1.9199316757981495

Epoch: 6| Step: 12
Training loss: 1.8181898593902588
Validation loss: 1.9404403637814265

Epoch: 6| Step: 13
Training loss: 0.9296293258666992
Validation loss: 1.915618137646747

Epoch: 495| Step: 0
Training loss: 1.5041390657424927
Validation loss: 1.9190678378587127

Epoch: 6| Step: 1
Training loss: 1.0417742729187012
Validation loss: 1.928391125894362

Epoch: 6| Step: 2
Training loss: 2.1413984298706055
Validation loss: 1.9405294720844557

Epoch: 6| Step: 3
Training loss: 2.2616753578186035
Validation loss: 1.9242997259222052

Epoch: 6| Step: 4
Training loss: 1.1564557552337646
Validation loss: 1.9188038097914828

Epoch: 6| Step: 5
Training loss: 1.381800889968872
Validation loss: 1.9504377534312587

Epoch: 6| Step: 6
Training loss: 1.7607550621032715
Validation loss: 1.943093648520849

Epoch: 6| Step: 7
Training loss: 1.5916171073913574
Validation loss: 1.9481729089572866

Epoch: 6| Step: 8
Training loss: 2.4321775436401367
Validation loss: 1.934329980163164

Epoch: 6| Step: 9
Training loss: 2.2679710388183594
Validation loss: 1.9328753538029169

Epoch: 6| Step: 10
Training loss: 1.5828737020492554
Validation loss: 1.9340833271703413

Epoch: 6| Step: 11
Training loss: 1.7828679084777832
Validation loss: 1.9453059306708715

Epoch: 6| Step: 12
Training loss: 1.7188475131988525
Validation loss: 1.9248308058707946

Epoch: 6| Step: 13
Training loss: 1.3275401592254639
Validation loss: 1.961615970057826

Epoch: 496| Step: 0
Training loss: 1.2246366739273071
Validation loss: 1.9493350816029373

Epoch: 6| Step: 1
Training loss: 1.5260815620422363
Validation loss: 1.9799578882032824

Epoch: 6| Step: 2
Training loss: 1.5976848602294922
Validation loss: 1.9635108491425872

Epoch: 6| Step: 3
Training loss: 1.2070374488830566
Validation loss: 1.985915623685365

Epoch: 6| Step: 4
Training loss: 1.957948923110962
Validation loss: 1.9605803169229978

Epoch: 6| Step: 5
Training loss: 1.680859923362732
Validation loss: 1.948369429957482

Epoch: 6| Step: 6
Training loss: 1.7277247905731201
Validation loss: 1.9509695934992966

Epoch: 6| Step: 7
Training loss: 1.710248589515686
Validation loss: 1.925550712052212

Epoch: 6| Step: 8
Training loss: 1.7868986129760742
Validation loss: 1.940980403654037

Epoch: 6| Step: 9
Training loss: 2.529015064239502
Validation loss: 1.9313361490926435

Epoch: 6| Step: 10
Training loss: 1.4898059368133545
Validation loss: 1.9241410916851414

Epoch: 6| Step: 11
Training loss: 1.5709033012390137
Validation loss: 1.9163059419201267

Epoch: 6| Step: 12
Training loss: 2.070125102996826
Validation loss: 1.931113104666433

Epoch: 6| Step: 13
Training loss: 2.3150312900543213
Validation loss: 1.9168999118189658

Epoch: 497| Step: 0
Training loss: 1.4992717504501343
Validation loss: 1.9207553081614996

Epoch: 6| Step: 1
Training loss: 2.2907137870788574
Validation loss: 1.9270712957587293

Epoch: 6| Step: 2
Training loss: 1.3442187309265137
Validation loss: 1.9269220290645477

Epoch: 6| Step: 3
Training loss: 1.6526316404342651
Validation loss: 1.935700132000831

Epoch: 6| Step: 4
Training loss: 1.1259410381317139
Validation loss: 1.9029271256539129

Epoch: 6| Step: 5
Training loss: 1.4595558643341064
Validation loss: 1.938319936875374

Epoch: 6| Step: 6
Training loss: 2.194861650466919
Validation loss: 1.9370582898457844

Epoch: 6| Step: 7
Training loss: 1.9870387315750122
Validation loss: 1.928526924502465

Epoch: 6| Step: 8
Training loss: 1.8506938219070435
Validation loss: 1.9428835453525666

Epoch: 6| Step: 9
Training loss: 1.613053321838379
Validation loss: 1.9580814210317468

Epoch: 6| Step: 10
Training loss: 1.890690565109253
Validation loss: 1.9387857734516103

Epoch: 6| Step: 11
Training loss: 1.4996858835220337
Validation loss: 1.92803587964786

Epoch: 6| Step: 12
Training loss: 1.7332905530929565
Validation loss: 1.930736575075375

Epoch: 6| Step: 13
Training loss: 1.9739603996276855
Validation loss: 1.9349248024725145

Epoch: 498| Step: 0
Training loss: 1.7118440866470337
Validation loss: 1.9227718563490017

Epoch: 6| Step: 1
Training loss: 1.2934070825576782
Validation loss: 1.9214857201422415

Epoch: 6| Step: 2
Training loss: 1.8669111728668213
Validation loss: 1.924340630090365

Epoch: 6| Step: 3
Training loss: 1.9104129076004028
Validation loss: 1.9311842021121775

Epoch: 6| Step: 4
Training loss: 1.8746089935302734
Validation loss: 1.9302064167555941

Epoch: 6| Step: 5
Training loss: 2.288231134414673
Validation loss: 1.9267482911386797

Epoch: 6| Step: 6
Training loss: 1.4573302268981934
Validation loss: 1.9305410346677225

Epoch: 6| Step: 7
Training loss: 1.7416104078292847
Validation loss: 1.9340346128709855

Epoch: 6| Step: 8
Training loss: 1.4717962741851807
Validation loss: 1.9336908260981243

Epoch: 6| Step: 9
Training loss: 2.0543832778930664
Validation loss: 1.9305108824083883

Epoch: 6| Step: 10
Training loss: 1.7099529504776
Validation loss: 1.9175900079870736

Epoch: 6| Step: 11
Training loss: 1.6020746231079102
Validation loss: 1.9478387832641602

Epoch: 6| Step: 12
Training loss: 1.4329798221588135
Validation loss: 1.9594882239577591

Epoch: 6| Step: 13
Training loss: 1.3459148406982422
Validation loss: 1.9445741586787726

Epoch: 499| Step: 0
Training loss: 1.774581789970398
Validation loss: 1.9632727984459168

Epoch: 6| Step: 1
Training loss: 1.6661171913146973
Validation loss: 1.9339641319808138

Epoch: 6| Step: 2
Training loss: 1.5586748123168945
Validation loss: 1.9278632440874655

Epoch: 6| Step: 3
Training loss: 1.2208174467086792
Validation loss: 1.9200800759817964

Epoch: 6| Step: 4
Training loss: 1.0716830492019653
Validation loss: 1.9224961214168097

Epoch: 6| Step: 5
Training loss: 2.0986292362213135
Validation loss: 1.9164263022843229

Epoch: 6| Step: 6
Training loss: 1.4039160013198853
Validation loss: 1.9292855403756584

Epoch: 6| Step: 7
Training loss: 1.1955368518829346
Validation loss: 1.9262155922510291

Epoch: 6| Step: 8
Training loss: 1.9571914672851562
Validation loss: 1.9281163702728927

Epoch: 6| Step: 9
Training loss: 2.0558626651763916
Validation loss: 1.9372023818313435

Epoch: 6| Step: 10
Training loss: 1.8092269897460938
Validation loss: 1.9486222651696974

Epoch: 6| Step: 11
Training loss: 2.2738237380981445
Validation loss: 1.9445691647068146

Epoch: 6| Step: 12
Training loss: 2.29231595993042
Validation loss: 1.9443405046257922

Epoch: 6| Step: 13
Training loss: 1.5971044301986694
Validation loss: 1.9450334669441305

Epoch: 500| Step: 0
Training loss: 1.9458152055740356
Validation loss: 1.9522224036596154

Epoch: 6| Step: 1
Training loss: 1.6191167831420898
Validation loss: 1.9537680213169386

Epoch: 6| Step: 2
Training loss: 1.4774775505065918
Validation loss: 1.9252485100940993

Epoch: 6| Step: 3
Training loss: 1.9818751811981201
Validation loss: 1.9526097851414834

Epoch: 6| Step: 4
Training loss: 2.003408908843994
Validation loss: 1.923740884309174

Epoch: 6| Step: 5
Training loss: 1.438782811164856
Validation loss: 1.9212980065294492

Epoch: 6| Step: 6
Training loss: 1.346496343612671
Validation loss: 1.9134909388839558

Epoch: 6| Step: 7
Training loss: 1.2847185134887695
Validation loss: 1.9208294037849671

Epoch: 6| Step: 8
Training loss: 1.7469978332519531
Validation loss: 1.9382229415319299

Epoch: 6| Step: 9
Training loss: 1.8534514904022217
Validation loss: 1.943814044357628

Epoch: 6| Step: 10
Training loss: 1.7395660877227783
Validation loss: 1.9485451700866863

Epoch: 6| Step: 11
Training loss: 1.8332486152648926
Validation loss: 1.9548843804226126

Epoch: 6| Step: 12
Training loss: 1.7281945943832397
Validation loss: 1.9493589631972774

Epoch: 6| Step: 13
Training loss: 1.7766814231872559
Validation loss: 1.967681223346341

Testing loss: 2.261614926656087
