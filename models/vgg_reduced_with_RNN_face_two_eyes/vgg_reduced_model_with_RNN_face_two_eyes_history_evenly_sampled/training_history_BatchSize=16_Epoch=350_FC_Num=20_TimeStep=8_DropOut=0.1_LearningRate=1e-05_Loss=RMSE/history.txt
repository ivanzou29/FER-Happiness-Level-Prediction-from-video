Epoch: 1| Step: 0
Training loss: 5.638664094967789
Validation loss: 5.7830434281774545

Epoch: 6| Step: 1
Training loss: 5.28481736545187
Validation loss: 5.7747463229377365

Epoch: 6| Step: 2
Training loss: 5.174249478524941
Validation loss: 5.767203857952728

Epoch: 6| Step: 3
Training loss: 4.920028873141786
Validation loss: 5.7595696019980425

Epoch: 6| Step: 4
Training loss: 6.933286469863578
Validation loss: 5.752185178040066

Epoch: 6| Step: 5
Training loss: 6.023614190623472
Validation loss: 5.7442598122823885

Epoch: 6| Step: 6
Training loss: 6.346892982957045
Validation loss: 5.736289672461238

Epoch: 6| Step: 7
Training loss: 5.483593833478771
Validation loss: 5.727026548585948

Epoch: 6| Step: 8
Training loss: 5.786472250723962
Validation loss: 5.717512479532338

Epoch: 6| Step: 9
Training loss: 6.455857850505811
Validation loss: 5.7072806355122045

Epoch: 6| Step: 10
Training loss: 5.1087030091351835
Validation loss: 5.695550693905736

Epoch: 6| Step: 11
Training loss: 5.411181367230496
Validation loss: 5.683895666974268

Epoch: 6| Step: 12
Training loss: 6.122198904600392
Validation loss: 5.670540060679955

Epoch: 6| Step: 13
Training loss: 5.577257104882726
Validation loss: 5.657376900652411

Epoch: 2| Step: 0
Training loss: 6.393969865973147
Validation loss: 5.6423289984164455

Epoch: 6| Step: 1
Training loss: 4.313637403788963
Validation loss: 5.626776571708475

Epoch: 6| Step: 2
Training loss: 4.687758375040641
Validation loss: 5.610243431952834

Epoch: 6| Step: 3
Training loss: 6.206283572318404
Validation loss: 5.591605534297372

Epoch: 6| Step: 4
Training loss: 6.244289383296048
Validation loss: 5.572928013146479

Epoch: 6| Step: 5
Training loss: 6.097028114668218
Validation loss: 5.551578294282767

Epoch: 6| Step: 6
Training loss: 5.2573798853294775
Validation loss: 5.5289778397266

Epoch: 6| Step: 7
Training loss: 5.5377810439183
Validation loss: 5.506083574124522

Epoch: 6| Step: 8
Training loss: 4.3542787576998165
Validation loss: 5.480629979347806

Epoch: 6| Step: 9
Training loss: 5.223650612963922
Validation loss: 5.454173503380012

Epoch: 6| Step: 10
Training loss: 5.90184930817008
Validation loss: 5.424933169403967

Epoch: 6| Step: 11
Training loss: 4.565420600759674
Validation loss: 5.395200236673323

Epoch: 6| Step: 12
Training loss: 6.012128651149171
Validation loss: 5.36300654293676

Epoch: 6| Step: 13
Training loss: 6.70119236826508
Validation loss: 5.328586276326256

Epoch: 3| Step: 0
Training loss: 5.061005548371245
Validation loss: 5.292761774219943

Epoch: 6| Step: 1
Training loss: 5.293775163430823
Validation loss: 5.252988651204897

Epoch: 6| Step: 2
Training loss: 4.9102859904796565
Validation loss: 5.2135953951344

Epoch: 6| Step: 3
Training loss: 3.9031211834683477
Validation loss: 5.1704017695392

Epoch: 6| Step: 4
Training loss: 5.055475329832683
Validation loss: 5.127892601055974

Epoch: 6| Step: 5
Training loss: 5.251407979447185
Validation loss: 5.08375429998885

Epoch: 6| Step: 6
Training loss: 6.237376778709929
Validation loss: 5.038865343990461

Epoch: 6| Step: 7
Training loss: 4.984835516723113
Validation loss: 4.990706734931206

Epoch: 6| Step: 8
Training loss: 5.131047100557987
Validation loss: 4.9422561710298085

Epoch: 6| Step: 9
Training loss: 4.034318569270327
Validation loss: 4.8957575254346475

Epoch: 6| Step: 10
Training loss: 5.65694090274923
Validation loss: 4.8484737315824225

Epoch: 6| Step: 11
Training loss: 4.5900373961809775
Validation loss: 4.8046159924524074

Epoch: 6| Step: 12
Training loss: 5.819404029351798
Validation loss: 4.762255295283206

Epoch: 6| Step: 13
Training loss: 4.25946875040122
Validation loss: 4.722107147577665

Epoch: 4| Step: 0
Training loss: 5.11419730144291
Validation loss: 4.684517166364427

Epoch: 6| Step: 1
Training loss: 4.1051065882274
Validation loss: 4.650136857715303

Epoch: 6| Step: 2
Training loss: 4.1293811073910485
Validation loss: 4.617013042962953

Epoch: 6| Step: 3
Training loss: 4.678356968614222
Validation loss: 4.586714622523969

Epoch: 6| Step: 4
Training loss: 5.9386801099026965
Validation loss: 4.5579430578057645

Epoch: 6| Step: 5
Training loss: 5.229845142296504
Validation loss: 4.530351521852529

Epoch: 6| Step: 6
Training loss: 4.969217914165849
Validation loss: 4.504251470269566

Epoch: 6| Step: 7
Training loss: 5.13625903955269
Validation loss: 4.479383575079107

Epoch: 6| Step: 8
Training loss: 4.692958247917748
Validation loss: 4.452718520237446

Epoch: 6| Step: 9
Training loss: 3.1587161259104803
Validation loss: 4.428833205544859

Epoch: 6| Step: 10
Training loss: 3.5891633328068853
Validation loss: 4.4063849788120315

Epoch: 6| Step: 11
Training loss: 4.402925143230865
Validation loss: 4.385226788393983

Epoch: 6| Step: 12
Training loss: 3.837293583291818
Validation loss: 4.364774792536232

Epoch: 6| Step: 13
Training loss: 4.992005823975614
Validation loss: 4.343916728019563

Epoch: 5| Step: 0
Training loss: 4.4316169533027985
Validation loss: 4.324032266564561

Epoch: 6| Step: 1
Training loss: 4.693051725377669
Validation loss: 4.3028638368532475

Epoch: 6| Step: 2
Training loss: 3.8059318121346006
Validation loss: 4.285496323790907

Epoch: 6| Step: 3
Training loss: 4.264782497499323
Validation loss: 4.2672035661710055

Epoch: 6| Step: 4
Training loss: 4.8749428770190955
Validation loss: 4.250852276195481

Epoch: 6| Step: 5
Training loss: 3.8110025936008776
Validation loss: 4.233420350783455

Epoch: 6| Step: 6
Training loss: 4.551241636114023
Validation loss: 4.217114823265472

Epoch: 6| Step: 7
Training loss: 4.076628779570308
Validation loss: 4.19820205930388

Epoch: 6| Step: 8
Training loss: 4.369017734427856
Validation loss: 4.183186454108083

Epoch: 6| Step: 9
Training loss: 4.356428127943298
Validation loss: 4.168869087845414

Epoch: 6| Step: 10
Training loss: 4.001140431909304
Validation loss: 4.153558837316985

Epoch: 6| Step: 11
Training loss: 4.1785903203628
Validation loss: 4.135497611310027

Epoch: 6| Step: 12
Training loss: 4.8677137650630184
Validation loss: 4.1259086281846855

Epoch: 6| Step: 13
Training loss: 4.364276932891937
Validation loss: 4.116569517963095

Epoch: 6| Step: 0
Training loss: 4.259753311608177
Validation loss: 4.10101562104322

Epoch: 6| Step: 1
Training loss: 4.925257123247733
Validation loss: 4.0830112796541735

Epoch: 6| Step: 2
Training loss: 3.033235194815976
Validation loss: 4.068612971180915

Epoch: 6| Step: 3
Training loss: 4.071967961618109
Validation loss: 4.0557459924517785

Epoch: 6| Step: 4
Training loss: 3.883192446749351
Validation loss: 4.04829701348464

Epoch: 6| Step: 5
Training loss: 4.012659543867413
Validation loss: 4.049496342910389

Epoch: 6| Step: 6
Training loss: 2.7969737115414937
Validation loss: 4.031981485541124

Epoch: 6| Step: 7
Training loss: 4.506538938446593
Validation loss: 4.021128226310688

Epoch: 6| Step: 8
Training loss: 4.277864997492041
Validation loss: 4.007346549089148

Epoch: 6| Step: 9
Training loss: 4.62898289097945
Validation loss: 3.998017111870557

Epoch: 6| Step: 10
Training loss: 4.242548525009531
Validation loss: 3.9833451653475267

Epoch: 6| Step: 11
Training loss: 4.653837462245539
Validation loss: 3.9800025518558306

Epoch: 6| Step: 12
Training loss: 4.215175894871652
Validation loss: 3.9725090391048385

Epoch: 6| Step: 13
Training loss: 4.482405279789542
Validation loss: 3.9629963056872066

Epoch: 7| Step: 0
Training loss: 4.180765686724732
Validation loss: 3.9556054595225656

Epoch: 6| Step: 1
Training loss: 4.884507518295889
Validation loss: 3.945677455550169

Epoch: 6| Step: 2
Training loss: 4.286543865748755
Validation loss: 3.9313911883073094

Epoch: 6| Step: 3
Training loss: 3.2044527604883895
Validation loss: 3.9235110457291245

Epoch: 6| Step: 4
Training loss: 4.110440308312267
Validation loss: 3.914898183588278

Epoch: 6| Step: 5
Training loss: 4.233117624228819
Validation loss: 3.906827084808716

Epoch: 6| Step: 6
Training loss: 4.112505398546751
Validation loss: 3.8997674770680293

Epoch: 6| Step: 7
Training loss: 4.518148278236975
Validation loss: 3.886322342607332

Epoch: 6| Step: 8
Training loss: 3.775233250163445
Validation loss: 3.879476509308899

Epoch: 6| Step: 9
Training loss: 3.6419539093167956
Validation loss: 3.875019151505994

Epoch: 6| Step: 10
Training loss: 4.414795725191146
Validation loss: 3.862463220498925

Epoch: 6| Step: 11
Training loss: 3.200732272525039
Validation loss: 3.8487873445986653

Epoch: 6| Step: 12
Training loss: 3.723921569785024
Validation loss: 3.8436892004679435

Epoch: 6| Step: 13
Training loss: 4.342808244006851
Validation loss: 3.838133455378558

Epoch: 8| Step: 0
Training loss: 3.763894724323274
Validation loss: 3.8351989760959984

Epoch: 6| Step: 1
Training loss: 3.3699014086691603
Validation loss: 3.83255955741144

Epoch: 6| Step: 2
Training loss: 3.7251467784663417
Validation loss: 3.818487303806691

Epoch: 6| Step: 3
Training loss: 4.6542886789164095
Validation loss: 3.814350360318434

Epoch: 6| Step: 4
Training loss: 4.316806136029791
Validation loss: 3.802875155287102

Epoch: 6| Step: 5
Training loss: 4.068041264792635
Validation loss: 3.794539517513629

Epoch: 6| Step: 6
Training loss: 3.6633458849964082
Validation loss: 3.784140057078729

Epoch: 6| Step: 7
Training loss: 3.4164865647895786
Validation loss: 3.777575759404352

Epoch: 6| Step: 8
Training loss: 3.6687209847909674
Validation loss: 3.7694992146529986

Epoch: 6| Step: 9
Training loss: 4.568243096198134
Validation loss: 3.7633104345395822

Epoch: 6| Step: 10
Training loss: 2.933792534200063
Validation loss: 3.7550556572304177

Epoch: 6| Step: 11
Training loss: 4.234856497214746
Validation loss: 3.7485616721654735

Epoch: 6| Step: 12
Training loss: 4.059322111917306
Validation loss: 3.7389386657958887

Epoch: 6| Step: 13
Training loss: 4.980925224179458
Validation loss: 3.7323642389981853

Epoch: 9| Step: 0
Training loss: 3.8228572802734027
Validation loss: 3.7241660806730517

Epoch: 6| Step: 1
Training loss: 4.411656735164895
Validation loss: 3.7158935846667758

Epoch: 6| Step: 2
Training loss: 3.382611204858226
Validation loss: 3.713134775549858

Epoch: 6| Step: 3
Training loss: 4.174407990107231
Validation loss: 3.706728305957777

Epoch: 6| Step: 4
Training loss: 4.380770991501436
Validation loss: 3.6977418175620715

Epoch: 6| Step: 5
Training loss: 4.1186481469025
Validation loss: 3.690505271280251

Epoch: 6| Step: 6
Training loss: 3.879760033570481
Validation loss: 3.679616692239304

Epoch: 6| Step: 7
Training loss: 3.553244362791417
Validation loss: 3.6695841348776397

Epoch: 6| Step: 8
Training loss: 4.057524465885543
Validation loss: 3.663767219671178

Epoch: 6| Step: 9
Training loss: 3.6138250488173154
Validation loss: 3.6615606513744576

Epoch: 6| Step: 10
Training loss: 4.001017441097307
Validation loss: 3.6577728917081327

Epoch: 6| Step: 11
Training loss: 3.057333188313834
Validation loss: 3.6476071736466835

Epoch: 6| Step: 12
Training loss: 3.1716846728419315
Validation loss: 3.6385869076200255

Epoch: 6| Step: 13
Training loss: 4.511952738453505
Validation loss: 3.631071230751196

Epoch: 10| Step: 0
Training loss: 4.154447006719502
Validation loss: 3.628921116502277

Epoch: 6| Step: 1
Training loss: 3.6930458908142687
Validation loss: 3.620130338101946

Epoch: 6| Step: 2
Training loss: 4.052359734189847
Validation loss: 3.614679965365058

Epoch: 6| Step: 3
Training loss: 3.017765214669481
Validation loss: 3.6119008617121398

Epoch: 6| Step: 4
Training loss: 4.194262154655173
Validation loss: 3.604649442373175

Epoch: 6| Step: 5
Training loss: 3.5338066096000125
Validation loss: 3.601269387494695

Epoch: 6| Step: 6
Training loss: 3.5120110819735157
Validation loss: 3.5910771399868526

Epoch: 6| Step: 7
Training loss: 4.178267592491282
Validation loss: 3.5853619901092233

Epoch: 6| Step: 8
Training loss: 3.164542305441608
Validation loss: 3.5813803266830253

Epoch: 6| Step: 9
Training loss: 3.9651055611296
Validation loss: 3.5739217780835304

Epoch: 6| Step: 10
Training loss: 3.2421422013025274
Validation loss: 3.569776033611387

Epoch: 6| Step: 11
Training loss: 4.205142306393043
Validation loss: 3.562754499796706

Epoch: 6| Step: 12
Training loss: 3.7598992975425727
Validation loss: 3.5557521851473384

Epoch: 6| Step: 13
Training loss: 4.336575517881597
Validation loss: 3.5498544317381406

Epoch: 11| Step: 0
Training loss: 3.6073519499093982
Validation loss: 3.545052436736893

Epoch: 6| Step: 1
Training loss: 3.926220192733853
Validation loss: 3.5411530056449307

Epoch: 6| Step: 2
Training loss: 3.6226550443020824
Validation loss: 3.5352432783246184

Epoch: 6| Step: 3
Training loss: 3.7753766055174904
Validation loss: 3.534238340186837

Epoch: 6| Step: 4
Training loss: 4.210730722761133
Validation loss: 3.5276917943492894

Epoch: 6| Step: 5
Training loss: 2.8181538867125613
Validation loss: 3.5212831019992232

Epoch: 6| Step: 6
Training loss: 3.5357817881472204
Validation loss: 3.5158476655330095

Epoch: 6| Step: 7
Training loss: 4.426514688510324
Validation loss: 3.505032854207526

Epoch: 6| Step: 8
Training loss: 3.081179115455009
Validation loss: 3.501719650030379

Epoch: 6| Step: 9
Training loss: 3.0687845325275083
Validation loss: 3.4980209207719635

Epoch: 6| Step: 10
Training loss: 4.627086271960365
Validation loss: 3.4968651475123984

Epoch: 6| Step: 11
Training loss: 3.7442394516169664
Validation loss: 3.4865948039274213

Epoch: 6| Step: 12
Training loss: 3.2526691919957975
Validation loss: 3.4811158335375225

Epoch: 6| Step: 13
Training loss: 4.161120321832051
Validation loss: 3.479158472340477

Epoch: 12| Step: 0
Training loss: 3.2741305179854563
Validation loss: 3.4649382148060095

Epoch: 6| Step: 1
Training loss: 3.0949615264128223
Validation loss: 3.458720677123775

Epoch: 6| Step: 2
Training loss: 3.797428797141607
Validation loss: 3.4567258983287807

Epoch: 6| Step: 3
Training loss: 3.3146769729580883
Validation loss: 3.4438533089359296

Epoch: 6| Step: 4
Training loss: 3.802434046347004
Validation loss: 3.4402015697521247

Epoch: 6| Step: 5
Training loss: 3.7010118595851647
Validation loss: 3.433223644081012

Epoch: 6| Step: 6
Training loss: 3.3123069562982383
Validation loss: 3.4259331920733587

Epoch: 6| Step: 7
Training loss: 3.1157774066284403
Validation loss: 3.408172957248078

Epoch: 6| Step: 8
Training loss: 3.875025964465369
Validation loss: 3.4061369367735215

Epoch: 6| Step: 9
Training loss: 4.895755502068619
Validation loss: 3.408669061224982

Epoch: 6| Step: 10
Training loss: 3.4090251292037976
Validation loss: 3.3938727991372653

Epoch: 6| Step: 11
Training loss: 4.186082970290397
Validation loss: 3.3896196157403145

Epoch: 6| Step: 12
Training loss: 3.629709407429919
Validation loss: 3.3826576448880523

Epoch: 6| Step: 13
Training loss: 2.834653285117277
Validation loss: 3.376497034648098

Epoch: 13| Step: 0
Training loss: 3.6741385767286814
Validation loss: 3.380440404982968

Epoch: 6| Step: 1
Training loss: 3.0564730759790066
Validation loss: 3.3639588668787326

Epoch: 6| Step: 2
Training loss: 3.2230299854309927
Validation loss: 3.351827215404572

Epoch: 6| Step: 3
Training loss: 3.4845795849324532
Validation loss: 3.3459397342288235

Epoch: 6| Step: 4
Training loss: 2.8105512013246323
Validation loss: 3.3502574486848844

Epoch: 6| Step: 5
Training loss: 3.1901099795333945
Validation loss: 3.344545978257764

Epoch: 6| Step: 6
Training loss: 3.2458146362027347
Validation loss: 3.348305488809208

Epoch: 6| Step: 7
Training loss: 4.631349895599419
Validation loss: 3.3264430223768344

Epoch: 6| Step: 8
Training loss: 3.6349206857541794
Validation loss: 3.3168322520033393

Epoch: 6| Step: 9
Training loss: 3.657829660720037
Validation loss: 3.310297931566718

Epoch: 6| Step: 10
Training loss: 3.3539585183205154
Validation loss: 3.313907244657431

Epoch: 6| Step: 11
Training loss: 4.055851117051932
Validation loss: 3.3100770078253596

Epoch: 6| Step: 12
Training loss: 3.5223898672914196
Validation loss: 3.296281826628714

Epoch: 6| Step: 13
Training loss: 4.273369211491632
Validation loss: 3.291569504420822

Epoch: 14| Step: 0
Training loss: 3.707852978973692
Validation loss: 3.2903954496896364

Epoch: 6| Step: 1
Training loss: 3.3974647269758256
Validation loss: 3.2908199639317655

Epoch: 6| Step: 2
Training loss: 3.5877631699003567
Validation loss: 3.280012742252145

Epoch: 6| Step: 3
Training loss: 3.0036798796166457
Validation loss: 3.2728795149603123

Epoch: 6| Step: 4
Training loss: 4.261129280813096
Validation loss: 3.2635823117105622

Epoch: 6| Step: 5
Training loss: 2.7382502533686073
Validation loss: 3.2553825043710374

Epoch: 6| Step: 6
Training loss: 4.244500585143694
Validation loss: 3.245416969735963

Epoch: 6| Step: 7
Training loss: 3.617658349653053
Validation loss: 3.242666630504626

Epoch: 6| Step: 8
Training loss: 2.6009084434953325
Validation loss: 3.2378945917597672

Epoch: 6| Step: 9
Training loss: 2.8261541591423835
Validation loss: 3.23367815049194

Epoch: 6| Step: 10
Training loss: 3.689434255427527
Validation loss: 3.232970574198806

Epoch: 6| Step: 11
Training loss: 3.111606276555614
Validation loss: 3.2197331266076796

Epoch: 6| Step: 12
Training loss: 3.880974378643274
Validation loss: 3.2165618062853145

Epoch: 6| Step: 13
Training loss: 4.0202031144028885
Validation loss: 3.209579686475159

Epoch: 15| Step: 0
Training loss: 3.5658379694251865
Validation loss: 3.206302142615282

Epoch: 6| Step: 1
Training loss: 2.916322051988272
Validation loss: 3.2030309023517916

Epoch: 6| Step: 2
Training loss: 2.995423004388483
Validation loss: 3.1984945880458784

Epoch: 6| Step: 3
Training loss: 3.821559959770754
Validation loss: 3.195253497360042

Epoch: 6| Step: 4
Training loss: 3.170472083815426
Validation loss: 3.1900333356329016

Epoch: 6| Step: 5
Training loss: 3.509843200267828
Validation loss: 3.1881707274175484

Epoch: 6| Step: 6
Training loss: 3.851599888494365
Validation loss: 3.1846462361873322

Epoch: 6| Step: 7
Training loss: 3.644118699645627
Validation loss: 3.1740672744499756

Epoch: 6| Step: 8
Training loss: 3.2431268641065296
Validation loss: 3.171762721969366

Epoch: 6| Step: 9
Training loss: 3.391054469038695
Validation loss: 3.171170222505103

Epoch: 6| Step: 10
Training loss: 4.073147480205917
Validation loss: 3.1662977054415156

Epoch: 6| Step: 11
Training loss: 3.4635537207066247
Validation loss: 3.161383820337297

Epoch: 6| Step: 12
Training loss: 2.9613642322154035
Validation loss: 3.16473443277223

Epoch: 6| Step: 13
Training loss: 3.3169836253882456
Validation loss: 3.1646632758616393

Epoch: 16| Step: 0
Training loss: 3.332859307598448
Validation loss: 3.1625547457902248

Epoch: 6| Step: 1
Training loss: 4.16983496689294
Validation loss: 3.1552710357669165

Epoch: 6| Step: 2
Training loss: 2.959548664737614
Validation loss: 3.1515891450823683

Epoch: 6| Step: 3
Training loss: 3.809939666030036
Validation loss: 3.1503179258863674

Epoch: 6| Step: 4
Training loss: 2.1985835891043144
Validation loss: 3.143654722832584

Epoch: 6| Step: 5
Training loss: 4.101517624382482
Validation loss: 3.1529490322115215

Epoch: 6| Step: 6
Training loss: 2.89545363171273
Validation loss: 3.1436445062710017

Epoch: 6| Step: 7
Training loss: 3.3341465593790183
Validation loss: 3.1385141600261295

Epoch: 6| Step: 8
Training loss: 3.4153667551262314
Validation loss: 3.1310064857626316

Epoch: 6| Step: 9
Training loss: 3.8440796005232114
Validation loss: 3.128673045439136

Epoch: 6| Step: 10
Training loss: 3.3069582953855696
Validation loss: 3.1310360161476876

Epoch: 6| Step: 11
Training loss: 3.2163094462220863
Validation loss: 3.127692875759278

Epoch: 6| Step: 12
Training loss: 3.304299911243285
Validation loss: 3.1292566460651714

Epoch: 6| Step: 13
Training loss: 3.3114475521661326
Validation loss: 3.1200307472024438

Epoch: 17| Step: 0
Training loss: 3.2069970522879796
Validation loss: 3.1170115462733103

Epoch: 6| Step: 1
Training loss: 3.4702126108604925
Validation loss: 3.117547586130504

Epoch: 6| Step: 2
Training loss: 3.745599198935976
Validation loss: 3.1155238138955657

Epoch: 6| Step: 3
Training loss: 3.1765213933218592
Validation loss: 3.1100985906934127

Epoch: 6| Step: 4
Training loss: 2.830988661807689
Validation loss: 3.108232169113481

Epoch: 6| Step: 5
Training loss: 3.3801985369727956
Validation loss: 3.1070573875730556

Epoch: 6| Step: 6
Training loss: 3.0986497399474606
Validation loss: 3.1050258608303163

Epoch: 6| Step: 7
Training loss: 3.2550974264960866
Validation loss: 3.1129201185849964

Epoch: 6| Step: 8
Training loss: 3.4829695394510902
Validation loss: 3.123261235021416

Epoch: 6| Step: 9
Training loss: 3.7054824729116804
Validation loss: 3.106733760590715

Epoch: 6| Step: 10
Training loss: 3.8437044714735653
Validation loss: 3.0968549404461307

Epoch: 6| Step: 11
Training loss: 3.822541318062618
Validation loss: 3.098788662315152

Epoch: 6| Step: 12
Training loss: 2.528120484601528
Validation loss: 3.0961135432265903

Epoch: 6| Step: 13
Training loss: 3.7033695188506175
Validation loss: 3.100181445072305

Epoch: 18| Step: 0
Training loss: 3.198628912687676
Validation loss: 3.0960318647055263

Epoch: 6| Step: 1
Training loss: 3.3158250351084795
Validation loss: 3.093409738632225

Epoch: 6| Step: 2
Training loss: 2.3816961956751856
Validation loss: 3.087798144973553

Epoch: 6| Step: 3
Training loss: 2.740764890121435
Validation loss: 3.0839486016829016

Epoch: 6| Step: 4
Training loss: 3.0295801970989804
Validation loss: 3.083397405391586

Epoch: 6| Step: 5
Training loss: 3.2699436670519813
Validation loss: 3.08937058780533

Epoch: 6| Step: 6
Training loss: 3.6420756711938522
Validation loss: 3.1011133521484004

Epoch: 6| Step: 7
Training loss: 3.637954846026948
Validation loss: 3.0801485892300584

Epoch: 6| Step: 8
Training loss: 3.847706069236482
Validation loss: 3.078103373936541

Epoch: 6| Step: 9
Training loss: 4.068799343483797
Validation loss: 3.0819047136388913

Epoch: 6| Step: 10
Training loss: 3.834623838276592
Validation loss: 3.0835024934997364

Epoch: 6| Step: 11
Training loss: 3.1304874306319657
Validation loss: 3.0799076058793085

Epoch: 6| Step: 12
Training loss: 2.922338275595294
Validation loss: 3.077811165653918

Epoch: 6| Step: 13
Training loss: 3.8326211488889226
Validation loss: 3.0707071349156374

Epoch: 19| Step: 0
Training loss: 4.055610566368526
Validation loss: 3.069734080255764

Epoch: 6| Step: 1
Training loss: 2.7648798051753807
Validation loss: 3.0690801170373727

Epoch: 6| Step: 2
Training loss: 3.242439278627425
Validation loss: 3.0745085405465087

Epoch: 6| Step: 3
Training loss: 3.4885337199981263
Validation loss: 3.077800319886672

Epoch: 6| Step: 4
Training loss: 3.625542172631871
Validation loss: 3.0617359791321443

Epoch: 6| Step: 5
Training loss: 3.9589667900910643
Validation loss: 3.0819733210808766

Epoch: 6| Step: 6
Training loss: 2.97612929508358
Validation loss: 3.066140168481305

Epoch: 6| Step: 7
Training loss: 2.8905966267610874
Validation loss: 3.0594895772540758

Epoch: 6| Step: 8
Training loss: 3.2863651187854535
Validation loss: 3.0621465295252457

Epoch: 6| Step: 9
Training loss: 2.3678177098527424
Validation loss: 3.061800167943981

Epoch: 6| Step: 10
Training loss: 3.6430624468569324
Validation loss: 3.0632212369064566

Epoch: 6| Step: 11
Training loss: 3.3095508618766734
Validation loss: 3.0630238955293563

Epoch: 6| Step: 12
Training loss: 3.829822895546853
Validation loss: 3.0644422637454802

Epoch: 6| Step: 13
Training loss: 2.7037623541589846
Validation loss: 3.064917483544661

Epoch: 20| Step: 0
Training loss: 4.168068738916034
Validation loss: 3.064803431055433

Epoch: 6| Step: 1
Training loss: 3.5315878377352656
Validation loss: 3.064877426678749

Epoch: 6| Step: 2
Training loss: 3.066309214228993
Validation loss: 3.0635390487276837

Epoch: 6| Step: 3
Training loss: 2.9151149618469065
Validation loss: 3.0567498971330034

Epoch: 6| Step: 4
Training loss: 3.0092690644281084
Validation loss: 3.0535290793845946

Epoch: 6| Step: 5
Training loss: 3.1481677524313616
Validation loss: 3.053495122090265

Epoch: 6| Step: 6
Training loss: 3.6095361714894914
Validation loss: 3.0537684975649664

Epoch: 6| Step: 7
Training loss: 3.846484444421524
Validation loss: 3.047826054272433

Epoch: 6| Step: 8
Training loss: 3.058885582341938
Validation loss: 3.047498891442386

Epoch: 6| Step: 9
Training loss: 3.375517770116109
Validation loss: 3.0482698153379637

Epoch: 6| Step: 10
Training loss: 3.0679708389030322
Validation loss: 3.04425179238451

Epoch: 6| Step: 11
Training loss: 3.712035713319969
Validation loss: 3.0430583894054806

Epoch: 6| Step: 12
Training loss: 2.6072767581632847
Validation loss: 3.043267952209817

Epoch: 6| Step: 13
Training loss: 3.2029877423907314
Validation loss: 3.044482574738583

Epoch: 21| Step: 0
Training loss: 2.7910562863334456
Validation loss: 3.0505956002677856

Epoch: 6| Step: 1
Training loss: 2.3967995284829993
Validation loss: 3.0584484470195297

Epoch: 6| Step: 2
Training loss: 2.593819674739537
Validation loss: 3.051353687119778

Epoch: 6| Step: 3
Training loss: 3.3986864020741243
Validation loss: 3.0426870924954708

Epoch: 6| Step: 4
Training loss: 2.5136641922413188
Validation loss: 3.0387156087897034

Epoch: 6| Step: 5
Training loss: 3.608393151636859
Validation loss: 3.032703597054601

Epoch: 6| Step: 6
Training loss: 2.553583028883218
Validation loss: 3.0340929923480435

Epoch: 6| Step: 7
Training loss: 3.6029614030103114
Validation loss: 3.03402243695969

Epoch: 6| Step: 8
Training loss: 3.589913086330535
Validation loss: 3.028955463747442

Epoch: 6| Step: 9
Training loss: 3.8318085056471958
Validation loss: 3.029332848558744

Epoch: 6| Step: 10
Training loss: 4.173826297086638
Validation loss: 3.026849644589589

Epoch: 6| Step: 11
Training loss: 2.994182668491507
Validation loss: 3.0296259272703527

Epoch: 6| Step: 12
Training loss: 4.200180213331672
Validation loss: 3.026957625826712

Epoch: 6| Step: 13
Training loss: 3.6688878671973435
Validation loss: 3.0273817621941497

Epoch: 22| Step: 0
Training loss: 2.8521473742015924
Validation loss: 3.0247863099459362

Epoch: 6| Step: 1
Training loss: 2.9404694178547186
Validation loss: 3.0239380584317774

Epoch: 6| Step: 2
Training loss: 3.202698023180697
Validation loss: 3.024122812489827

Epoch: 6| Step: 3
Training loss: 3.966554049220888
Validation loss: 3.027564274711145

Epoch: 6| Step: 4
Training loss: 3.360892871115246
Validation loss: 3.023521650047955

Epoch: 6| Step: 5
Training loss: 3.2016616083595344
Validation loss: 3.01889630520697

Epoch: 6| Step: 6
Training loss: 4.100395109165643
Validation loss: 3.018520885406234

Epoch: 6| Step: 7
Training loss: 3.5266518151800432
Validation loss: 3.0185289656698093

Epoch: 6| Step: 8
Training loss: 3.5836500131412126
Validation loss: 3.0180212582040564

Epoch: 6| Step: 9
Training loss: 2.1919802969513436
Validation loss: 3.0178114229034585

Epoch: 6| Step: 10
Training loss: 2.9963658891847835
Validation loss: 3.014073891901178

Epoch: 6| Step: 11
Training loss: 3.4699089245016124
Validation loss: 3.013605943941309

Epoch: 6| Step: 12
Training loss: 2.996393260880911
Validation loss: 3.0139524027432514

Epoch: 6| Step: 13
Training loss: 3.64373751028024
Validation loss: 3.0143454743164533

Epoch: 23| Step: 0
Training loss: 3.274087700192939
Validation loss: 3.0123193803029724

Epoch: 6| Step: 1
Training loss: 2.811803265207914
Validation loss: 3.0129145779546995

Epoch: 6| Step: 2
Training loss: 2.297568806810274
Validation loss: 3.0094784765239013

Epoch: 6| Step: 3
Training loss: 4.122971469437179
Validation loss: 3.0083720826270253

Epoch: 6| Step: 4
Training loss: 3.820200038885028
Validation loss: 3.005756210438134

Epoch: 6| Step: 5
Training loss: 3.538953901565719
Validation loss: 3.0073675198578735

Epoch: 6| Step: 6
Training loss: 3.325634521516627
Validation loss: 3.006892135521193

Epoch: 6| Step: 7
Training loss: 2.70488668377178
Validation loss: 3.005316322137918

Epoch: 6| Step: 8
Training loss: 3.673790225249752
Validation loss: 3.0078435637595002

Epoch: 6| Step: 9
Training loss: 3.6706187595059117
Validation loss: 3.0052606167164644

Epoch: 6| Step: 10
Training loss: 3.1330605881935947
Validation loss: 3.002878206446882

Epoch: 6| Step: 11
Training loss: 3.380831307879236
Validation loss: 3.002096890924615

Epoch: 6| Step: 12
Training loss: 2.956315512062329
Validation loss: 3.0019570542095355

Epoch: 6| Step: 13
Training loss: 2.759604760494348
Validation loss: 3.0033544617177927

Epoch: 24| Step: 0
Training loss: 2.942027073323918
Validation loss: 2.996958262178604

Epoch: 6| Step: 1
Training loss: 3.573702682176527
Validation loss: 2.998574670304102

Epoch: 6| Step: 2
Training loss: 3.009641254882924
Validation loss: 2.998601293424675

Epoch: 6| Step: 3
Training loss: 2.8229661962989883
Validation loss: 2.9977554671885005

Epoch: 6| Step: 4
Training loss: 3.5580917657572866
Validation loss: 2.995655726496032

Epoch: 6| Step: 5
Training loss: 3.59427963997949
Validation loss: 2.9963086706492437

Epoch: 6| Step: 6
Training loss: 3.122312687309518
Validation loss: 2.9956027100758424

Epoch: 6| Step: 7
Training loss: 3.3925249955360557
Validation loss: 2.9942753257965555

Epoch: 6| Step: 8
Training loss: 2.3991692138248486
Validation loss: 2.9919667010011985

Epoch: 6| Step: 9
Training loss: 3.397565216718506
Validation loss: 2.992499421215643

Epoch: 6| Step: 10
Training loss: 3.4791414789137063
Validation loss: 2.9996677850519897

Epoch: 6| Step: 11
Training loss: 3.0614407322859942
Validation loss: 2.990356755736431

Epoch: 6| Step: 12
Training loss: 3.641634166814018
Validation loss: 2.99189756767594

Epoch: 6| Step: 13
Training loss: 4.096101740557007
Validation loss: 2.9967062773585744

Epoch: 25| Step: 0
Training loss: 3.2048778668965894
Validation loss: 2.9955390480537125

Epoch: 6| Step: 1
Training loss: 3.0586720111914416
Validation loss: 2.9889430364811784

Epoch: 6| Step: 2
Training loss: 2.939418734225729
Validation loss: 2.9901944690935403

Epoch: 6| Step: 3
Training loss: 3.1456898704978116
Validation loss: 2.9955062896728046

Epoch: 6| Step: 4
Training loss: 3.217672815905888
Validation loss: 2.998555461156881

Epoch: 6| Step: 5
Training loss: 4.06089281422305
Validation loss: 2.9980269031341096

Epoch: 6| Step: 6
Training loss: 3.3630134218908303
Validation loss: 2.9928014795699034

Epoch: 6| Step: 7
Training loss: 3.536527218192255
Validation loss: 2.990236406889638

Epoch: 6| Step: 8
Training loss: 2.9234503920580246
Validation loss: 2.990901722492742

Epoch: 6| Step: 9
Training loss: 3.195339361325054
Validation loss: 2.989702963596279

Epoch: 6| Step: 10
Training loss: 3.698152833659463
Validation loss: 2.989528894902441

Epoch: 6| Step: 11
Training loss: 3.1448624146270046
Validation loss: 2.9865689070690404

Epoch: 6| Step: 12
Training loss: 3.464801224680904
Validation loss: 2.9871779902059523

Epoch: 6| Step: 13
Training loss: 2.4075923989886596
Validation loss: 2.9907423541600875

Epoch: 26| Step: 0
Training loss: 3.0442374526457066
Validation loss: 3.0045130565490137

Epoch: 6| Step: 1
Training loss: 3.1336460288914583
Validation loss: 3.012795068934732

Epoch: 6| Step: 2
Training loss: 3.4409769680291142
Validation loss: 2.989256305665189

Epoch: 6| Step: 3
Training loss: 3.357705770565225
Validation loss: 2.97895624536477

Epoch: 6| Step: 4
Training loss: 3.306454017272123
Validation loss: 2.978183306669547

Epoch: 6| Step: 5
Training loss: 3.363352705033629
Validation loss: 2.9794565448877024

Epoch: 6| Step: 6
Training loss: 2.4348646736531183
Validation loss: 2.9781793262959435

Epoch: 6| Step: 7
Training loss: 3.6397487912110855
Validation loss: 2.9736140336526553

Epoch: 6| Step: 8
Training loss: 3.725412763218011
Validation loss: 2.97326647338657

Epoch: 6| Step: 9
Training loss: 3.37315120215397
Validation loss: 2.9716651269695253

Epoch: 6| Step: 10
Training loss: 3.9590650718681215
Validation loss: 2.969576381136622

Epoch: 6| Step: 11
Training loss: 2.6279420260533457
Validation loss: 2.964054558025816

Epoch: 6| Step: 12
Training loss: 3.085942753654547
Validation loss: 2.9657090869641776

Epoch: 6| Step: 13
Training loss: 2.9581604669775223
Validation loss: 2.9632290247879

Epoch: 27| Step: 0
Training loss: 3.113165610354302
Validation loss: 2.960172744863636

Epoch: 6| Step: 1
Training loss: 3.5038695062350187
Validation loss: 2.9584011975386946

Epoch: 6| Step: 2
Training loss: 3.5256285357309625
Validation loss: 2.95850710175785

Epoch: 6| Step: 3
Training loss: 2.9722673961339843
Validation loss: 2.9547137333776634

Epoch: 6| Step: 4
Training loss: 3.0951770612267464
Validation loss: 2.9531911527984396

Epoch: 6| Step: 5
Training loss: 3.7254821362915096
Validation loss: 2.9539973037398273

Epoch: 6| Step: 6
Training loss: 3.0438914240698334
Validation loss: 2.9499219538906116

Epoch: 6| Step: 7
Training loss: 2.5037976983831403
Validation loss: 2.9514282095258495

Epoch: 6| Step: 8
Training loss: 3.168739309800755
Validation loss: 2.9495171695647957

Epoch: 6| Step: 9
Training loss: 3.4917742934896014
Validation loss: 2.95299734150136

Epoch: 6| Step: 10
Training loss: 3.428919121732647
Validation loss: 2.9538032953790756

Epoch: 6| Step: 11
Training loss: 2.471967700710204
Validation loss: 2.9556210858297147

Epoch: 6| Step: 12
Training loss: 3.2149440151815947
Validation loss: 2.968110809857818

Epoch: 6| Step: 13
Training loss: 4.431128642541641
Validation loss: 2.9463294047129183

Epoch: 28| Step: 0
Training loss: 3.5988487893126884
Validation loss: 2.9411543102382636

Epoch: 6| Step: 1
Training loss: 3.6643759912616054
Validation loss: 2.948550228221528

Epoch: 6| Step: 2
Training loss: 2.7760091544723173
Validation loss: 2.9571595960828776

Epoch: 6| Step: 3
Training loss: 3.6657073471042745
Validation loss: 2.9669213613463628

Epoch: 6| Step: 4
Training loss: 2.8751230628170985
Validation loss: 2.962935268094352

Epoch: 6| Step: 5
Training loss: 3.835904185350496
Validation loss: 2.9498591779965486

Epoch: 6| Step: 6
Training loss: 2.803672925797054
Validation loss: 2.947468738853717

Epoch: 6| Step: 7
Training loss: 3.2963565943136373
Validation loss: 2.946404844317348

Epoch: 6| Step: 8
Training loss: 2.999493715162985
Validation loss: 2.9420496090173476

Epoch: 6| Step: 9
Training loss: 3.0313676634299362
Validation loss: 2.940782342112092

Epoch: 6| Step: 10
Training loss: 3.712875598955326
Validation loss: 2.9393738412403967

Epoch: 6| Step: 11
Training loss: 2.2898700838842614
Validation loss: 2.9407442461878146

Epoch: 6| Step: 12
Training loss: 3.2685010009222553
Validation loss: 2.954177707879603

Epoch: 6| Step: 13
Training loss: 3.4398741412980782
Validation loss: 2.9534722170887524

Epoch: 29| Step: 0
Training loss: 3.6184313223661126
Validation loss: 2.9448536883007437

Epoch: 6| Step: 1
Training loss: 2.992226065046025
Validation loss: 2.9259953624696524

Epoch: 6| Step: 2
Training loss: 2.8121644561667853
Validation loss: 2.928832887539254

Epoch: 6| Step: 3
Training loss: 3.1523797507044367
Validation loss: 2.9257781621839283

Epoch: 6| Step: 4
Training loss: 2.973438936875638
Validation loss: 2.927415461887786

Epoch: 6| Step: 5
Training loss: 2.840122802121051
Validation loss: 2.9296604107660573

Epoch: 6| Step: 6
Training loss: 3.4369593802064298
Validation loss: 2.927210320745709

Epoch: 6| Step: 7
Training loss: 2.6836430574243413
Validation loss: 2.9276223706510627

Epoch: 6| Step: 8
Training loss: 3.767762396673018
Validation loss: 2.9239480227503534

Epoch: 6| Step: 9
Training loss: 3.4463796887435914
Validation loss: 2.921715630758514

Epoch: 6| Step: 10
Training loss: 3.853501023556346
Validation loss: 2.9202438485915594

Epoch: 6| Step: 11
Training loss: 2.702079085496452
Validation loss: 2.917412579577603

Epoch: 6| Step: 12
Training loss: 3.746464524998569
Validation loss: 2.915061008294289

Epoch: 6| Step: 13
Training loss: 2.648365571162117
Validation loss: 2.9129895377643207

Epoch: 30| Step: 0
Training loss: 3.748839643881438
Validation loss: 2.9120086889986996

Epoch: 6| Step: 1
Training loss: 3.474830178701254
Validation loss: 2.910662293467465

Epoch: 6| Step: 2
Training loss: 3.5387612187225583
Validation loss: 2.9073471237290365

Epoch: 6| Step: 3
Training loss: 3.2556461294143597
Validation loss: 2.9107721866585075

Epoch: 6| Step: 4
Training loss: 2.180450634008069
Validation loss: 2.9115205770921437

Epoch: 6| Step: 5
Training loss: 2.801850650774303
Validation loss: 2.9154739636727083

Epoch: 6| Step: 6
Training loss: 3.614252667138664
Validation loss: 2.9089027168872077

Epoch: 6| Step: 7
Training loss: 3.112151933074768
Validation loss: 2.906842800569716

Epoch: 6| Step: 8
Training loss: 3.551389266562629
Validation loss: 2.906904254776465

Epoch: 6| Step: 9
Training loss: 3.2691879183347266
Validation loss: 2.902349024180333

Epoch: 6| Step: 10
Training loss: 3.4762906428995737
Validation loss: 2.9053467365606616

Epoch: 6| Step: 11
Training loss: 2.9374597424934237
Validation loss: 2.906903990202142

Epoch: 6| Step: 12
Training loss: 2.296959388895376
Validation loss: 2.9049870338776795

Epoch: 6| Step: 13
Training loss: 3.3640461936799992
Validation loss: 2.9031232778158036

Epoch: 31| Step: 0
Training loss: 3.098547096641815
Validation loss: 2.9018823073577007

Epoch: 6| Step: 1
Training loss: 2.7918634962088715
Validation loss: 2.9034407604449717

Epoch: 6| Step: 2
Training loss: 3.0379622559001493
Validation loss: 2.904561387029438

Epoch: 6| Step: 3
Training loss: 3.2057710464597027
Validation loss: 2.903532038310669

Epoch: 6| Step: 4
Training loss: 3.10956147367981
Validation loss: 2.9011756031108504

Epoch: 6| Step: 5
Training loss: 2.047782172763354
Validation loss: 2.902051170347629

Epoch: 6| Step: 6
Training loss: 3.1560693065928667
Validation loss: 2.902414793843907

Epoch: 6| Step: 7
Training loss: 3.7201777690537607
Validation loss: 2.9004919688569837

Epoch: 6| Step: 8
Training loss: 3.399035732188087
Validation loss: 2.8980174762952973

Epoch: 6| Step: 9
Training loss: 3.6452107506461098
Validation loss: 2.8976093729249723

Epoch: 6| Step: 10
Training loss: 2.7950708121676877
Validation loss: 2.8960199078342623

Epoch: 6| Step: 11
Training loss: 3.740940212649967
Validation loss: 2.8974802045942156

Epoch: 6| Step: 12
Training loss: 3.420691716696889
Validation loss: 2.8962274016056506

Epoch: 6| Step: 13
Training loss: 3.6193041283307554
Validation loss: 2.895620786371378

Epoch: 32| Step: 0
Training loss: 2.3739171822298135
Validation loss: 2.89173540662107

Epoch: 6| Step: 1
Training loss: 3.9545995804242557
Validation loss: 2.8895743924410935

Epoch: 6| Step: 2
Training loss: 3.362904526438845
Validation loss: 2.888793908123082

Epoch: 6| Step: 3
Training loss: 3.3924583716990453
Validation loss: 2.8918868344170017

Epoch: 6| Step: 4
Training loss: 2.6736102799143193
Validation loss: 2.887587873924688

Epoch: 6| Step: 5
Training loss: 3.728672925489486
Validation loss: 2.8926958262052014

Epoch: 6| Step: 6
Training loss: 3.2533017039976304
Validation loss: 2.889898577948355

Epoch: 6| Step: 7
Training loss: 2.795568406069273
Validation loss: 2.8909864648087464

Epoch: 6| Step: 8
Training loss: 3.7590311021545606
Validation loss: 2.887170723079019

Epoch: 6| Step: 9
Training loss: 2.66689179384117
Validation loss: 2.886634567556116

Epoch: 6| Step: 10
Training loss: 3.1774371007520887
Validation loss: 2.8868137216168357

Epoch: 6| Step: 11
Training loss: 3.382267368434185
Validation loss: 2.888324607764603

Epoch: 6| Step: 12
Training loss: 2.5551714424199976
Validation loss: 2.8861607057657372

Epoch: 6| Step: 13
Training loss: 3.4082855302090125
Validation loss: 2.8858073593361366

Epoch: 33| Step: 0
Training loss: 2.497559787007902
Validation loss: 2.888199210239783

Epoch: 6| Step: 1
Training loss: 3.4861235059000237
Validation loss: 2.883102932820403

Epoch: 6| Step: 2
Training loss: 3.7511587260098347
Validation loss: 2.88358750869364

Epoch: 6| Step: 3
Training loss: 2.9902075847918126
Validation loss: 2.8825823475266823

Epoch: 6| Step: 4
Training loss: 3.2762031616449048
Validation loss: 2.8836757415581618

Epoch: 6| Step: 5
Training loss: 3.1852753299538024
Validation loss: 2.882655884731803

Epoch: 6| Step: 6
Training loss: 2.853058388675117
Validation loss: 2.8822569450883844

Epoch: 6| Step: 7
Training loss: 3.3430627134364737
Validation loss: 2.8802128864296774

Epoch: 6| Step: 8
Training loss: 3.306733924914901
Validation loss: 2.8778921278439777

Epoch: 6| Step: 9
Training loss: 2.5204957993526675
Validation loss: 2.8796913335546517

Epoch: 6| Step: 10
Training loss: 3.2503617892265866
Validation loss: 2.8788915532959845

Epoch: 6| Step: 11
Training loss: 3.903810517559329
Validation loss: 2.8782071339859705

Epoch: 6| Step: 12
Training loss: 2.830574787121563
Validation loss: 2.87717592238416

Epoch: 6| Step: 13
Training loss: 3.1982657441880558
Validation loss: 2.877250623312877

Epoch: 34| Step: 0
Training loss: 2.6327699380484986
Validation loss: 2.883567898060269

Epoch: 6| Step: 1
Training loss: 3.550942126701394
Validation loss: 2.8827997262883303

Epoch: 6| Step: 2
Training loss: 3.691597165615272
Validation loss: 2.8852556553248565

Epoch: 6| Step: 3
Training loss: 3.428283264902301
Validation loss: 2.882121217138384

Epoch: 6| Step: 4
Training loss: 2.934043311404629
Validation loss: 2.8839227625055748

Epoch: 6| Step: 5
Training loss: 3.0215853752511515
Validation loss: 2.88907075762526

Epoch: 6| Step: 6
Training loss: 3.104459932201105
Validation loss: 2.886138360789123

Epoch: 6| Step: 7
Training loss: 3.2036596828891692
Validation loss: 2.874855647803529

Epoch: 6| Step: 8
Training loss: 3.296029077272022
Validation loss: 2.8749319071149464

Epoch: 6| Step: 9
Training loss: 2.974724309633206
Validation loss: 2.8700050641072687

Epoch: 6| Step: 10
Training loss: 3.530697939769775
Validation loss: 2.872958836830508

Epoch: 6| Step: 11
Training loss: 3.0406516659107408
Validation loss: 2.868898718704643

Epoch: 6| Step: 12
Training loss: 3.2504060931686385
Validation loss: 2.8708569018587777

Epoch: 6| Step: 13
Training loss: 2.664369269017448
Validation loss: 2.872401543008581

Epoch: 35| Step: 0
Training loss: 2.8962468096798255
Validation loss: 2.8692149489949466

Epoch: 6| Step: 1
Training loss: 4.048576556945807
Validation loss: 2.86943453405013

Epoch: 6| Step: 2
Training loss: 3.256935934793561
Validation loss: 2.8705112982894576

Epoch: 6| Step: 3
Training loss: 3.6492146679204716
Validation loss: 2.8709189317039914

Epoch: 6| Step: 4
Training loss: 3.0491610827259756
Validation loss: 2.8689031545190526

Epoch: 6| Step: 5
Training loss: 2.9724756253641154
Validation loss: 2.8675023794809364

Epoch: 6| Step: 6
Training loss: 2.6339563437560973
Validation loss: 2.8685939491418435

Epoch: 6| Step: 7
Training loss: 1.9144756883226772
Validation loss: 2.8690217876700537

Epoch: 6| Step: 8
Training loss: 3.4214507933047726
Validation loss: 2.8681119877036974

Epoch: 6| Step: 9
Training loss: 3.1490208390661767
Validation loss: 2.8728816506335804

Epoch: 6| Step: 10
Training loss: 3.750583348995683
Validation loss: 2.876766214272984

Epoch: 6| Step: 11
Training loss: 3.572516030555247
Validation loss: 2.872116817139941

Epoch: 6| Step: 12
Training loss: 2.5448083274026305
Validation loss: 2.865312624338307

Epoch: 6| Step: 13
Training loss: 3.0650916519276867
Validation loss: 2.8646345579577153

Epoch: 36| Step: 0
Training loss: 3.2990040345434686
Validation loss: 2.866359112105626

Epoch: 6| Step: 1
Training loss: 3.732906292151777
Validation loss: 2.8648872949566435

Epoch: 6| Step: 2
Training loss: 3.097109271291194
Validation loss: 2.8630134237786775

Epoch: 6| Step: 3
Training loss: 3.8816886518834988
Validation loss: 2.8631681703561744

Epoch: 6| Step: 4
Training loss: 2.72460114946115
Validation loss: 2.8623200246738585

Epoch: 6| Step: 5
Training loss: 3.4740043915417225
Validation loss: 2.859491089601976

Epoch: 6| Step: 6
Training loss: 3.3586129677136856
Validation loss: 2.860609457274028

Epoch: 6| Step: 7
Training loss: 2.948084005362354
Validation loss: 2.863093432408435

Epoch: 6| Step: 8
Training loss: 3.2567133890455686
Validation loss: 2.862380529757569

Epoch: 6| Step: 9
Training loss: 3.5005846897577
Validation loss: 2.864366270251963

Epoch: 6| Step: 10
Training loss: 3.007708342098743
Validation loss: 2.8626467127534583

Epoch: 6| Step: 11
Training loss: 2.7182441328496387
Validation loss: 2.863693806796399

Epoch: 6| Step: 12
Training loss: 2.270694716769548
Validation loss: 2.8640880173643715

Epoch: 6| Step: 13
Training loss: 2.58415552611924
Validation loss: 2.8597232206024055

Epoch: 37| Step: 0
Training loss: 3.2320602906240787
Validation loss: 2.8598299265859928

Epoch: 6| Step: 1
Training loss: 2.703039178974302
Validation loss: 2.860437654884392

Epoch: 6| Step: 2
Training loss: 3.0433324319838837
Validation loss: 2.862859439847207

Epoch: 6| Step: 3
Training loss: 2.8621767419587267
Validation loss: 2.8664169843162237

Epoch: 6| Step: 4
Training loss: 3.464982744974877
Validation loss: 2.8728415798837457

Epoch: 6| Step: 5
Training loss: 3.1826176369764183
Validation loss: 2.8768594577300832

Epoch: 6| Step: 6
Training loss: 3.3807674155243355
Validation loss: 2.8951072877501187

Epoch: 6| Step: 7
Training loss: 2.2614471852294122
Validation loss: 2.887702821340773

Epoch: 6| Step: 8
Training loss: 2.9092519699290627
Validation loss: 2.8677173755353116

Epoch: 6| Step: 9
Training loss: 3.318228321058367
Validation loss: 2.861276963333134

Epoch: 6| Step: 10
Training loss: 3.087307319343156
Validation loss: 2.8542234718868156

Epoch: 6| Step: 11
Training loss: 3.3094494286255354
Validation loss: 2.8531589500061467

Epoch: 6| Step: 12
Training loss: 3.9455991735267237
Validation loss: 2.8623538066500336

Epoch: 6| Step: 13
Training loss: 3.5355027508450494
Validation loss: 2.877616649254091

Epoch: 38| Step: 0
Training loss: 3.0045908134246373
Validation loss: 2.86072824258501

Epoch: 6| Step: 1
Training loss: 2.760402597835365
Validation loss: 2.8679856188180666

Epoch: 6| Step: 2
Training loss: 3.5157698537866384
Validation loss: 2.8852388273770466

Epoch: 6| Step: 3
Training loss: 2.324806459636601
Validation loss: 2.8774059335209925

Epoch: 6| Step: 4
Training loss: 3.348391155112664
Validation loss: 2.8883022315986437

Epoch: 6| Step: 5
Training loss: 3.3500569125223336
Validation loss: 2.902074715224224

Epoch: 6| Step: 6
Training loss: 2.9662535762001725
Validation loss: 2.9129524037681156

Epoch: 6| Step: 7
Training loss: 3.5120446178061204
Validation loss: 2.926432173694709

Epoch: 6| Step: 8
Training loss: 3.255708229845061
Validation loss: 2.9441828431250343

Epoch: 6| Step: 9
Training loss: 3.3639228731583035
Validation loss: 2.8755411483222644

Epoch: 6| Step: 10
Training loss: 3.2388289739593525
Validation loss: 2.856415032709305

Epoch: 6| Step: 11
Training loss: 3.7705864728909666
Validation loss: 2.8634515818072157

Epoch: 6| Step: 12
Training loss: 2.7489236112258966
Validation loss: 2.870923380470416

Epoch: 6| Step: 13
Training loss: 3.212681057944925
Validation loss: 2.858734778237854

Epoch: 39| Step: 0
Training loss: 2.8204741286355977
Validation loss: 2.8545148439661614

Epoch: 6| Step: 1
Training loss: 2.710829850843577
Validation loss: 2.8549705872000195

Epoch: 6| Step: 2
Training loss: 2.5344020856169585
Validation loss: 2.8514296454231993

Epoch: 6| Step: 3
Training loss: 2.8769547824375743
Validation loss: 2.8528590786825947

Epoch: 6| Step: 4
Training loss: 3.6570819658080773
Validation loss: 2.8516366546379306

Epoch: 6| Step: 5
Training loss: 3.635567225678711
Validation loss: 2.8540030497579303

Epoch: 6| Step: 6
Training loss: 2.9303876116591523
Validation loss: 2.8554090259053697

Epoch: 6| Step: 7
Training loss: 3.121390126924683
Validation loss: 2.8516558519637094

Epoch: 6| Step: 8
Training loss: 3.610370977471803
Validation loss: 2.8543219246046627

Epoch: 6| Step: 9
Training loss: 3.7360501542410915
Validation loss: 2.8551897090176594

Epoch: 6| Step: 10
Training loss: 3.180083678961954
Validation loss: 2.8571946875533913

Epoch: 6| Step: 11
Training loss: 3.690110527182055
Validation loss: 2.851111236570739

Epoch: 6| Step: 12
Training loss: 2.7156612345535542
Validation loss: 2.853173145800475

Epoch: 6| Step: 13
Training loss: 2.4563348265310445
Validation loss: 2.855149058643938

Epoch: 40| Step: 0
Training loss: 3.3757908212481476
Validation loss: 2.8549846599464073

Epoch: 6| Step: 1
Training loss: 2.6037201969164365
Validation loss: 2.85431533029898

Epoch: 6| Step: 2
Training loss: 3.752037003714928
Validation loss: 2.857297087973216

Epoch: 6| Step: 3
Training loss: 2.8191940330043868
Validation loss: 2.8538386425352615

Epoch: 6| Step: 4
Training loss: 3.300468475149633
Validation loss: 2.8466987237318606

Epoch: 6| Step: 5
Training loss: 2.8947378231576235
Validation loss: 2.8461316743814766

Epoch: 6| Step: 6
Training loss: 3.4489599456983044
Validation loss: 2.8423941371921204

Epoch: 6| Step: 7
Training loss: 1.9487409292698763
Validation loss: 2.8435279518800147

Epoch: 6| Step: 8
Training loss: 3.373352496377948
Validation loss: 2.8442565099977144

Epoch: 6| Step: 9
Training loss: 3.2929444227304243
Validation loss: 2.844843116490527

Epoch: 6| Step: 10
Training loss: 3.801126493826575
Validation loss: 2.846703017628236

Epoch: 6| Step: 11
Training loss: 3.4441552673146276
Validation loss: 2.842873593425386

Epoch: 6| Step: 12
Training loss: 2.159091569818277
Validation loss: 2.8434511821240624

Epoch: 6| Step: 13
Training loss: 3.6004132404509015
Validation loss: 2.839868394695916

Epoch: 41| Step: 0
Training loss: 2.9709143529030175
Validation loss: 2.841682012105946

Epoch: 6| Step: 1
Training loss: 3.151363404717671
Validation loss: 2.837220792055847

Epoch: 6| Step: 2
Training loss: 2.4303116073498847
Validation loss: 2.837982432126468

Epoch: 6| Step: 3
Training loss: 2.656360758547909
Validation loss: 2.8366046345576663

Epoch: 6| Step: 4
Training loss: 3.534559471382294
Validation loss: 2.8380662510744177

Epoch: 6| Step: 5
Training loss: 3.2940851493442564
Validation loss: 2.836462138396365

Epoch: 6| Step: 6
Training loss: 2.892936153779366
Validation loss: 2.8356681281548464

Epoch: 6| Step: 7
Training loss: 3.053697508564972
Validation loss: 2.8336981159134713

Epoch: 6| Step: 8
Training loss: 3.4267078568868685
Validation loss: 2.8339215692852293

Epoch: 6| Step: 9
Training loss: 3.4132788695023457
Validation loss: 2.8338224928557643

Epoch: 6| Step: 10
Training loss: 3.4219898222031166
Validation loss: 2.832298669576084

Epoch: 6| Step: 11
Training loss: 3.34059179305584
Validation loss: 2.837223988900972

Epoch: 6| Step: 12
Training loss: 2.9886921120226333
Validation loss: 2.8391766216843815

Epoch: 6| Step: 13
Training loss: 3.5349602576453845
Validation loss: 2.8363111441867357

Epoch: 42| Step: 0
Training loss: 2.79149378530667
Validation loss: 2.837980734764941

Epoch: 6| Step: 1
Training loss: 3.245294098303706
Validation loss: 2.843866713908877

Epoch: 6| Step: 2
Training loss: 2.7857878451713516
Validation loss: 2.8473785529215934

Epoch: 6| Step: 3
Training loss: 3.032084084816894
Validation loss: 2.8467251930503794

Epoch: 6| Step: 4
Training loss: 3.006818334584313
Validation loss: 2.835617055009306

Epoch: 6| Step: 5
Training loss: 3.4315268205108427
Validation loss: 2.840484755781453

Epoch: 6| Step: 6
Training loss: 3.603301780579005
Validation loss: 2.8314869406187118

Epoch: 6| Step: 7
Training loss: 2.2684409695588394
Validation loss: 2.827474735668263

Epoch: 6| Step: 8
Training loss: 3.034127982994043
Validation loss: 2.8293161457624865

Epoch: 6| Step: 9
Training loss: 3.5499034169987684
Validation loss: 2.830504759641815

Epoch: 6| Step: 10
Training loss: 3.179922634119323
Validation loss: 2.8316345919236383

Epoch: 6| Step: 11
Training loss: 3.848657715878259
Validation loss: 2.827690006302602

Epoch: 6| Step: 12
Training loss: 3.0540749016091064
Validation loss: 2.8306588652675533

Epoch: 6| Step: 13
Training loss: 2.8963959693921737
Validation loss: 2.8285197765038457

Epoch: 43| Step: 0
Training loss: 2.609097677330202
Validation loss: 2.8286940041277875

Epoch: 6| Step: 1
Training loss: 3.0043119595577616
Validation loss: 2.826907419573992

Epoch: 6| Step: 2
Training loss: 3.6967032720773125
Validation loss: 2.828193316090325

Epoch: 6| Step: 3
Training loss: 2.850244170320209
Validation loss: 2.8281679623248754

Epoch: 6| Step: 4
Training loss: 3.1118254087549246
Validation loss: 2.830867046515149

Epoch: 6| Step: 5
Training loss: 3.354141203663216
Validation loss: 2.8274835831270453

Epoch: 6| Step: 6
Training loss: 2.664740333574669
Validation loss: 2.8245077179232267

Epoch: 6| Step: 7
Training loss: 2.607514409055608
Validation loss: 2.8256913866822737

Epoch: 6| Step: 8
Training loss: 3.6938130278139747
Validation loss: 2.825357122296879

Epoch: 6| Step: 9
Training loss: 3.311246526823602
Validation loss: 2.8265407713907

Epoch: 6| Step: 10
Training loss: 3.059024941169693
Validation loss: 2.8300177319035402

Epoch: 6| Step: 11
Training loss: 2.889801072926797
Validation loss: 2.8374303589565617

Epoch: 6| Step: 12
Training loss: 3.804434076599104
Validation loss: 2.8570510311503488

Epoch: 6| Step: 13
Training loss: 3.0146848171598246
Validation loss: 2.849336330051178

Epoch: 44| Step: 0
Training loss: 3.3047665706039875
Validation loss: 2.8375511757143914

Epoch: 6| Step: 1
Training loss: 2.6755080480395703
Validation loss: 2.831015705433576

Epoch: 6| Step: 2
Training loss: 4.1681602598487295
Validation loss: 2.821440270487957

Epoch: 6| Step: 3
Training loss: 2.308397933478348
Validation loss: 2.820975978622617

Epoch: 6| Step: 4
Training loss: 2.876487015661557
Validation loss: 2.820654477392502

Epoch: 6| Step: 5
Training loss: 3.309926310753336
Validation loss: 2.8183984575317735

Epoch: 6| Step: 6
Training loss: 3.6920164219582996
Validation loss: 2.8181286181970564

Epoch: 6| Step: 7
Training loss: 2.2072874747562494
Validation loss: 2.815823587211735

Epoch: 6| Step: 8
Training loss: 3.300900428922781
Validation loss: 2.818680988850587

Epoch: 6| Step: 9
Training loss: 3.7057041892065308
Validation loss: 2.8173806059021076

Epoch: 6| Step: 10
Training loss: 2.8636277888115984
Validation loss: 2.8211822763863177

Epoch: 6| Step: 11
Training loss: 3.004878051873057
Validation loss: 2.8191978777433757

Epoch: 6| Step: 12
Training loss: 3.1830640855402597
Validation loss: 2.8306216773390127

Epoch: 6| Step: 13
Training loss: 2.3452290255173174
Validation loss: 2.842344147280497

Epoch: 45| Step: 0
Training loss: 2.5449048244464314
Validation loss: 2.8490907644624164

Epoch: 6| Step: 1
Training loss: 2.602474476655217
Validation loss: 2.8562304588746765

Epoch: 6| Step: 2
Training loss: 3.2657448778553984
Validation loss: 2.835873147398242

Epoch: 6| Step: 3
Training loss: 2.685915457661154
Validation loss: 2.8158118434115678

Epoch: 6| Step: 4
Training loss: 3.4009022861835443
Validation loss: 2.812388205727616

Epoch: 6| Step: 5
Training loss: 2.8042503590066223
Validation loss: 2.814953840821473

Epoch: 6| Step: 6
Training loss: 3.413370232481988
Validation loss: 2.8167516687053062

Epoch: 6| Step: 7
Training loss: 3.203428375019775
Validation loss: 2.81441725597687

Epoch: 6| Step: 8
Training loss: 3.1629700081507157
Validation loss: 2.8153074811370233

Epoch: 6| Step: 9
Training loss: 3.0767729447490986
Validation loss: 2.8174029666207283

Epoch: 6| Step: 10
Training loss: 4.088034797236683
Validation loss: 2.8159949078363513

Epoch: 6| Step: 11
Training loss: 3.2142340822462874
Validation loss: 2.814277266040901

Epoch: 6| Step: 12
Training loss: 2.982504053488804
Validation loss: 2.815721961067039

Epoch: 6| Step: 13
Training loss: 3.1754449007001857
Validation loss: 2.814252847249674

Epoch: 46| Step: 0
Training loss: 3.366593806419461
Validation loss: 2.815978170351129

Epoch: 6| Step: 1
Training loss: 3.1667059511123776
Validation loss: 2.8130024259532367

Epoch: 6| Step: 2
Training loss: 2.9816946405840254
Validation loss: 2.8110372561100267

Epoch: 6| Step: 3
Training loss: 2.8946594127538954
Validation loss: 2.8135883098832872

Epoch: 6| Step: 4
Training loss: 3.543014778418624
Validation loss: 2.8101931838714895

Epoch: 6| Step: 5
Training loss: 3.414593478535509
Validation loss: 2.808562968002099

Epoch: 6| Step: 6
Training loss: 2.7756637879074937
Validation loss: 2.807387414262447

Epoch: 6| Step: 7
Training loss: 2.781821374387037
Validation loss: 2.809436047961913

Epoch: 6| Step: 8
Training loss: 3.2156230959872736
Validation loss: 2.8076231701373846

Epoch: 6| Step: 9
Training loss: 2.720645112502922
Validation loss: 2.805395492125551

Epoch: 6| Step: 10
Training loss: 2.3175030792446316
Validation loss: 2.8089370874808943

Epoch: 6| Step: 11
Training loss: 3.3886593513367282
Validation loss: 2.8062321560360854

Epoch: 6| Step: 12
Training loss: 3.5555893644738794
Validation loss: 2.812874783391608

Epoch: 6| Step: 13
Training loss: 3.6792108506472565
Validation loss: 2.822927124333424

Epoch: 47| Step: 0
Training loss: 2.8154708430589785
Validation loss: 2.8076595149333916

Epoch: 6| Step: 1
Training loss: 3.861098425925905
Validation loss: 2.808485095516843

Epoch: 6| Step: 2
Training loss: 3.0543962032424403
Validation loss: 2.8054023805302126

Epoch: 6| Step: 3
Training loss: 3.103759141494495
Validation loss: 2.80996769760513

Epoch: 6| Step: 4
Training loss: 3.275178796677751
Validation loss: 2.8099899138627715

Epoch: 6| Step: 5
Training loss: 3.0805691537498645
Validation loss: 2.817845779483699

Epoch: 6| Step: 6
Training loss: 2.217891150793654
Validation loss: 2.817299555681511

Epoch: 6| Step: 7
Training loss: 4.021503820830838
Validation loss: 2.8212036546508776

Epoch: 6| Step: 8
Training loss: 3.5384747351843684
Validation loss: 2.8203457716267013

Epoch: 6| Step: 9
Training loss: 2.575676049677933
Validation loss: 2.812740991036844

Epoch: 6| Step: 10
Training loss: 2.1210024763108133
Validation loss: 2.8084993738069253

Epoch: 6| Step: 11
Training loss: 3.6064205876403346
Validation loss: 2.814204277766163

Epoch: 6| Step: 12
Training loss: 2.479273518629153
Validation loss: 2.8113395931344978

Epoch: 6| Step: 13
Training loss: 3.560299913438868
Validation loss: 2.8062433890561675

Epoch: 48| Step: 0
Training loss: 3.488615867909238
Validation loss: 2.799942524198478

Epoch: 6| Step: 1
Training loss: 3.1415595187290015
Validation loss: 2.8024971668544905

Epoch: 6| Step: 2
Training loss: 2.572198332512442
Validation loss: 2.805517599338525

Epoch: 6| Step: 3
Training loss: 2.657561842162054
Validation loss: 2.812581530338377

Epoch: 6| Step: 4
Training loss: 3.6880054450749977
Validation loss: 2.8196823492835708

Epoch: 6| Step: 5
Training loss: 3.2574524165884435
Validation loss: 2.8171430070730707

Epoch: 6| Step: 6
Training loss: 3.574249434209137
Validation loss: 2.8092097954951543

Epoch: 6| Step: 7
Training loss: 2.4257711265954724
Validation loss: 2.8065334130637125

Epoch: 6| Step: 8
Training loss: 3.13410158343512
Validation loss: 2.802914393545174

Epoch: 6| Step: 9
Training loss: 3.256377784725763
Validation loss: 2.8039899192709483

Epoch: 6| Step: 10
Training loss: 3.073013631724031
Validation loss: 2.801369301873175

Epoch: 6| Step: 11
Training loss: 3.107473894471485
Validation loss: 2.8040027969190406

Epoch: 6| Step: 12
Training loss: 3.121517835315282
Validation loss: 2.8093726651617525

Epoch: 6| Step: 13
Training loss: 3.125623106823374
Validation loss: 2.8128156149915466

Epoch: 49| Step: 0
Training loss: 3.3557351909186495
Validation loss: 2.8150775269136195

Epoch: 6| Step: 1
Training loss: 2.953280813153455
Validation loss: 2.812012983698705

Epoch: 6| Step: 2
Training loss: 2.6250657572911464
Validation loss: 2.811360511879969

Epoch: 6| Step: 3
Training loss: 3.0982996307340325
Validation loss: 2.816790182870508

Epoch: 6| Step: 4
Training loss: 3.4864933434240535
Validation loss: 2.8181678094522633

Epoch: 6| Step: 5
Training loss: 3.2687625687833464
Validation loss: 2.814122376296863

Epoch: 6| Step: 6
Training loss: 3.2920343378809265
Validation loss: 2.8015663425449473

Epoch: 6| Step: 7
Training loss: 2.898483892928073
Validation loss: 2.7959411303098283

Epoch: 6| Step: 8
Training loss: 3.1765535173415786
Validation loss: 2.794600167920084

Epoch: 6| Step: 9
Training loss: 3.281929163808214
Validation loss: 2.7939249588862562

Epoch: 6| Step: 10
Training loss: 2.9371733788245105
Validation loss: 2.793727368258564

Epoch: 6| Step: 11
Training loss: 2.7713487953535934
Validation loss: 2.79300465582593

Epoch: 6| Step: 12
Training loss: 3.2414538185305086
Validation loss: 2.796249821161157

Epoch: 6| Step: 13
Training loss: 3.3618740988264064
Validation loss: 2.794113378757407

Epoch: 50| Step: 0
Training loss: 3.5662662608153344
Validation loss: 2.796944465262656

Epoch: 6| Step: 1
Training loss: 3.5493797835022076
Validation loss: 2.7936978374760466

Epoch: 6| Step: 2
Training loss: 2.335635468722619
Validation loss: 2.795395136580271

Epoch: 6| Step: 3
Training loss: 3.332489447265767
Validation loss: 2.793304884372638

Epoch: 6| Step: 4
Training loss: 3.593700640795543
Validation loss: 2.7994638069496505

Epoch: 6| Step: 5
Training loss: 3.3472391623195414
Validation loss: 2.795520573909067

Epoch: 6| Step: 6
Training loss: 2.705589273683479
Validation loss: 2.789655182683042

Epoch: 6| Step: 7
Training loss: 3.506902971851302
Validation loss: 2.7914442118534333

Epoch: 6| Step: 8
Training loss: 3.2136277115656195
Validation loss: 2.795838874985134

Epoch: 6| Step: 9
Training loss: 2.4872551303894586
Validation loss: 2.798620245375355

Epoch: 6| Step: 10
Training loss: 2.66917729407688
Validation loss: 2.797532274371859

Epoch: 6| Step: 11
Training loss: 3.3170241644056464
Validation loss: 2.7951449044848053

Epoch: 6| Step: 12
Training loss: 2.8523819255546683
Validation loss: 2.794655305002704

Epoch: 6| Step: 13
Training loss: 2.539381834636394
Validation loss: 2.8001644067210205

Epoch: 51| Step: 0
Training loss: 3.2498722051290585
Validation loss: 2.8029843832043397

Epoch: 6| Step: 1
Training loss: 3.264121845850817
Validation loss: 2.7986900987627576

Epoch: 6| Step: 2
Training loss: 3.629551365139033
Validation loss: 2.7954771208472478

Epoch: 6| Step: 3
Training loss: 2.5905380584153535
Validation loss: 2.793834677966933

Epoch: 6| Step: 4
Training loss: 2.8476860557639396
Validation loss: 2.795310430643416

Epoch: 6| Step: 5
Training loss: 3.0767377641700655
Validation loss: 2.7930832490370623

Epoch: 6| Step: 6
Training loss: 2.9886862087741166
Validation loss: 2.792412278271762

Epoch: 6| Step: 7
Training loss: 2.7467665302615614
Validation loss: 2.787345659539405

Epoch: 6| Step: 8
Training loss: 2.761498427606619
Validation loss: 2.7870580706136567

Epoch: 6| Step: 9
Training loss: 3.0001171407082077
Validation loss: 2.7834294485727193

Epoch: 6| Step: 10
Training loss: 3.215234113982191
Validation loss: 2.788224405927231

Epoch: 6| Step: 11
Training loss: 4.026337224944603
Validation loss: 2.7822441084079106

Epoch: 6| Step: 12
Training loss: 2.7295093952107403
Validation loss: 2.784013461798013

Epoch: 6| Step: 13
Training loss: 3.218978873698746
Validation loss: 2.7846507120029376

Epoch: 52| Step: 0
Training loss: 3.472255550648424
Validation loss: 2.7838265206124855

Epoch: 6| Step: 1
Training loss: 2.721817741273546
Validation loss: 2.785518199594805

Epoch: 6| Step: 2
Training loss: 3.641342681742396
Validation loss: 2.7851312555638073

Epoch: 6| Step: 3
Training loss: 3.4827373402402193
Validation loss: 2.786570572952548

Epoch: 6| Step: 4
Training loss: 2.343827309922861
Validation loss: 2.787822703017114

Epoch: 6| Step: 5
Training loss: 3.4930933517794234
Validation loss: 2.7895338589052474

Epoch: 6| Step: 6
Training loss: 3.1180843889073393
Validation loss: 2.788987198208333

Epoch: 6| Step: 7
Training loss: 2.640356648369841
Validation loss: 2.7951355364304735

Epoch: 6| Step: 8
Training loss: 2.9334167345790636
Validation loss: 2.8156241107642583

Epoch: 6| Step: 9
Training loss: 3.5517764737360324
Validation loss: 2.802563318588866

Epoch: 6| Step: 10
Training loss: 2.9749729187317824
Validation loss: 2.7825545527959687

Epoch: 6| Step: 11
Training loss: 2.401187078633541
Validation loss: 2.7821091821185915

Epoch: 6| Step: 12
Training loss: 3.2473236214634733
Validation loss: 2.781670363817769

Epoch: 6| Step: 13
Training loss: 3.177238552283293
Validation loss: 2.7806723071785338

Epoch: 53| Step: 0
Training loss: 3.073325040589548
Validation loss: 2.780038362992175

Epoch: 6| Step: 1
Training loss: 3.141361131322735
Validation loss: 2.783768649400138

Epoch: 6| Step: 2
Training loss: 2.725397161536342
Validation loss: 2.780784513596571

Epoch: 6| Step: 3
Training loss: 2.645549268316753
Validation loss: 2.778789392731554

Epoch: 6| Step: 4
Training loss: 3.8519571655363656
Validation loss: 2.779081745870133

Epoch: 6| Step: 5
Training loss: 2.887821632076075
Validation loss: 2.7782445054718563

Epoch: 6| Step: 6
Training loss: 2.9052914915405426
Validation loss: 2.7757988381635776

Epoch: 6| Step: 7
Training loss: 2.3093458780354696
Validation loss: 2.7755316978696407

Epoch: 6| Step: 8
Training loss: 3.6086172654384407
Validation loss: 2.7751371951168813

Epoch: 6| Step: 9
Training loss: 3.121641108674209
Validation loss: 2.7748290759741736

Epoch: 6| Step: 10
Training loss: 3.3597200438262984
Validation loss: 2.7751454214438764

Epoch: 6| Step: 11
Training loss: 2.688730002754081
Validation loss: 2.772608891682985

Epoch: 6| Step: 12
Training loss: 3.4263493796475473
Validation loss: 2.776213821004233

Epoch: 6| Step: 13
Training loss: 3.5493392114435363
Validation loss: 2.774207876120273

Epoch: 54| Step: 0
Training loss: 3.3132147827533416
Validation loss: 2.773817712886116

Epoch: 6| Step: 1
Training loss: 3.1532078046861565
Validation loss: 2.773369780930833

Epoch: 6| Step: 2
Training loss: 2.7815623590177685
Validation loss: 2.7753810771126606

Epoch: 6| Step: 3
Training loss: 3.7927605584598396
Validation loss: 2.776797353006102

Epoch: 6| Step: 4
Training loss: 3.574269845732796
Validation loss: 2.783292686922608

Epoch: 6| Step: 5
Training loss: 2.56204554552009
Validation loss: 2.798731028738154

Epoch: 6| Step: 6
Training loss: 4.0216292678942684
Validation loss: 2.802068458155038

Epoch: 6| Step: 7
Training loss: 2.5214636674026245
Validation loss: 2.7818293745169376

Epoch: 6| Step: 8
Training loss: 2.5127311789973223
Validation loss: 2.772026634672312

Epoch: 6| Step: 9
Training loss: 2.9148974002429093
Validation loss: 2.766752406861306

Epoch: 6| Step: 10
Training loss: 2.573159817674787
Validation loss: 2.7703911219259525

Epoch: 6| Step: 11
Training loss: 3.5151870115624466
Validation loss: 2.769055170592909

Epoch: 6| Step: 12
Training loss: 2.648619788994187
Validation loss: 2.772345925200074

Epoch: 6| Step: 13
Training loss: 3.147565318574403
Validation loss: 2.7742293945886005

Epoch: 55| Step: 0
Training loss: 2.6662489345314127
Validation loss: 2.772362507209547

Epoch: 6| Step: 1
Training loss: 3.7384104611698383
Validation loss: 2.7726318464816755

Epoch: 6| Step: 2
Training loss: 2.9346322203848474
Validation loss: 2.7705472813469307

Epoch: 6| Step: 3
Training loss: 3.186031826207551
Validation loss: 2.7716121394816375

Epoch: 6| Step: 4
Training loss: 3.447578359796342
Validation loss: 2.778912402421665

Epoch: 6| Step: 5
Training loss: 2.4643266864000535
Validation loss: 2.7969021012452937

Epoch: 6| Step: 6
Training loss: 3.2687882430281086
Validation loss: 2.8340616888522048

Epoch: 6| Step: 7
Training loss: 3.6571004807622667
Validation loss: 2.842330830018161

Epoch: 6| Step: 8
Training loss: 3.0112871189767074
Validation loss: 2.811265386869802

Epoch: 6| Step: 9
Training loss: 3.0126240874886947
Validation loss: 2.7760942711121284

Epoch: 6| Step: 10
Training loss: 2.757558059842015
Validation loss: 2.766595561579959

Epoch: 6| Step: 11
Training loss: 3.22673274369272
Validation loss: 2.7651838846852947

Epoch: 6| Step: 12
Training loss: 2.806310667473922
Validation loss: 2.7684172641833604

Epoch: 6| Step: 13
Training loss: 3.0237748305336893
Validation loss: 2.778110962919513

Epoch: 56| Step: 0
Training loss: 2.4701941406926706
Validation loss: 2.7868762422358198

Epoch: 6| Step: 1
Training loss: 2.994518198989545
Validation loss: 2.79963655815862

Epoch: 6| Step: 2
Training loss: 3.05377355303369
Validation loss: 2.804372010551037

Epoch: 6| Step: 3
Training loss: 3.2915560224906297
Validation loss: 2.799745013965833

Epoch: 6| Step: 4
Training loss: 3.496263962336931
Validation loss: 2.765696216035031

Epoch: 6| Step: 5
Training loss: 3.353925676553918
Validation loss: 2.7652494280855158

Epoch: 6| Step: 6
Training loss: 3.434309987779654
Validation loss: 2.7621197589288893

Epoch: 6| Step: 7
Training loss: 3.498169556579845
Validation loss: 2.7636882966294074

Epoch: 6| Step: 8
Training loss: 2.6183971740917196
Validation loss: 2.7658941231718366

Epoch: 6| Step: 9
Training loss: 2.8867549248727116
Validation loss: 2.7713152342783562

Epoch: 6| Step: 10
Training loss: 3.3023973831070284
Validation loss: 2.7922767397428316

Epoch: 6| Step: 11
Training loss: 2.61593652690796
Validation loss: 2.8010826063702656

Epoch: 6| Step: 12
Training loss: 3.091489948935645
Validation loss: 2.8072088935093666

Epoch: 6| Step: 13
Training loss: 3.096816883638911
Validation loss: 2.819350720057834

Epoch: 57| Step: 0
Training loss: 2.9903544495915355
Validation loss: 2.7878091860007648

Epoch: 6| Step: 1
Training loss: 2.5084099459010996
Validation loss: 2.7729140789963265

Epoch: 6| Step: 2
Training loss: 3.3299400860319546
Validation loss: 2.7680194126115625

Epoch: 6| Step: 3
Training loss: 2.6860456745584593
Validation loss: 2.7624344880292817

Epoch: 6| Step: 4
Training loss: 2.533118041410378
Validation loss: 2.7608183200369867

Epoch: 6| Step: 5
Training loss: 2.9755609384205854
Validation loss: 2.7621102937158364

Epoch: 6| Step: 6
Training loss: 3.7620798731857095
Validation loss: 2.7604589129740624

Epoch: 6| Step: 7
Training loss: 3.1129116475537937
Validation loss: 2.7591163834125574

Epoch: 6| Step: 8
Training loss: 3.35128818625379
Validation loss: 2.7623297830863796

Epoch: 6| Step: 9
Training loss: 2.9289984541264107
Validation loss: 2.7616666508772396

Epoch: 6| Step: 10
Training loss: 3.8785473983128624
Validation loss: 2.7632124453972935

Epoch: 6| Step: 11
Training loss: 2.6666321652882594
Validation loss: 2.7588137547662694

Epoch: 6| Step: 12
Training loss: 3.0132228000026906
Validation loss: 2.763053846912511

Epoch: 6| Step: 13
Training loss: 3.2823705303984383
Validation loss: 2.7558860665595195

Epoch: 58| Step: 0
Training loss: 2.721275997712304
Validation loss: 2.7568924594009316

Epoch: 6| Step: 1
Training loss: 3.526911948843841
Validation loss: 2.7601021963474355

Epoch: 6| Step: 2
Training loss: 2.264366694958182
Validation loss: 2.7539563781509364

Epoch: 6| Step: 3
Training loss: 3.4290873843205922
Validation loss: 2.7565883664378807

Epoch: 6| Step: 4
Training loss: 3.52435534378905
Validation loss: 2.7546179825743637

Epoch: 6| Step: 5
Training loss: 3.002089567440495
Validation loss: 2.754922531256935

Epoch: 6| Step: 6
Training loss: 3.19400467725016
Validation loss: 2.756761439563025

Epoch: 6| Step: 7
Training loss: 3.1476443974320776
Validation loss: 2.767968482370666

Epoch: 6| Step: 8
Training loss: 2.980660728581207
Validation loss: 2.7759482924752956

Epoch: 6| Step: 9
Training loss: 2.7860726538205967
Validation loss: 2.785418027330969

Epoch: 6| Step: 10
Training loss: 2.468246794975284
Validation loss: 2.7763284523817826

Epoch: 6| Step: 11
Training loss: 3.5219015423401587
Validation loss: 2.7753330591424668

Epoch: 6| Step: 12
Training loss: 3.0566357889837943
Validation loss: 2.781306091200173

Epoch: 6| Step: 13
Training loss: 3.445543069541779
Validation loss: 2.761435589577718

Epoch: 59| Step: 0
Training loss: 3.3389805799332506
Validation loss: 2.7625538731971093

Epoch: 6| Step: 1
Training loss: 3.1694040680554516
Validation loss: 2.7558184762161515

Epoch: 6| Step: 2
Training loss: 2.35439213936129
Validation loss: 2.750519553333723

Epoch: 6| Step: 3
Training loss: 3.4500705103648617
Validation loss: 2.751570367890082

Epoch: 6| Step: 4
Training loss: 2.400815102127203
Validation loss: 2.749583323692335

Epoch: 6| Step: 5
Training loss: 3.288009221196296
Validation loss: 2.7480959411350607

Epoch: 6| Step: 6
Training loss: 2.3958145362006045
Validation loss: 2.7491669050166334

Epoch: 6| Step: 7
Training loss: 3.4674798512990725
Validation loss: 2.7520791786192733

Epoch: 6| Step: 8
Training loss: 2.686309550793718
Validation loss: 2.751863539916382

Epoch: 6| Step: 9
Training loss: 2.936428117996946
Validation loss: 2.7558612624784087

Epoch: 6| Step: 10
Training loss: 2.7680956478461867
Validation loss: 2.7514793727470885

Epoch: 6| Step: 11
Training loss: 3.963092044921308
Validation loss: 2.7465706050949605

Epoch: 6| Step: 12
Training loss: 3.281133885826848
Validation loss: 2.7442515141537185

Epoch: 6| Step: 13
Training loss: 3.271430007710561
Validation loss: 2.744918136327839

Epoch: 60| Step: 0
Training loss: 3.6021219675446003
Validation loss: 2.7464698533132648

Epoch: 6| Step: 1
Training loss: 2.227645664097625
Validation loss: 2.7467116396204223

Epoch: 6| Step: 2
Training loss: 4.212712693999853
Validation loss: 2.7494602018509804

Epoch: 6| Step: 3
Training loss: 3.640728470146457
Validation loss: 2.7489874253678854

Epoch: 6| Step: 4
Training loss: 2.827963134180014
Validation loss: 2.7503525199432626

Epoch: 6| Step: 5
Training loss: 2.936044860143722
Validation loss: 2.74753537488759

Epoch: 6| Step: 6
Training loss: 2.4940430241952254
Validation loss: 2.7515917727036987

Epoch: 6| Step: 7
Training loss: 3.3279089342642565
Validation loss: 2.7478124582086862

Epoch: 6| Step: 8
Training loss: 2.7355434863832
Validation loss: 2.749088526907635

Epoch: 6| Step: 9
Training loss: 3.36875578078303
Validation loss: 2.7466632077124338

Epoch: 6| Step: 10
Training loss: 2.9709896273025844
Validation loss: 2.7479893697851963

Epoch: 6| Step: 11
Training loss: 2.3438454163520244
Validation loss: 2.748862166320582

Epoch: 6| Step: 12
Training loss: 2.564091072179033
Validation loss: 2.748739246274868

Epoch: 6| Step: 13
Training loss: 3.342444048964617
Validation loss: 2.7480761603003154

Epoch: 61| Step: 0
Training loss: 3.24992928061204
Validation loss: 2.7473831665574426

Epoch: 6| Step: 1
Training loss: 2.2858409931621466
Validation loss: 2.750989335119534

Epoch: 6| Step: 2
Training loss: 2.4029720818290428
Validation loss: 2.7536987133395763

Epoch: 6| Step: 3
Training loss: 2.7452252291082995
Validation loss: 2.760180214343647

Epoch: 6| Step: 4
Training loss: 2.9952845071152177
Validation loss: 2.7635075884015445

Epoch: 6| Step: 5
Training loss: 3.6808789828884514
Validation loss: 2.7751027154098336

Epoch: 6| Step: 6
Training loss: 3.092155276723841
Validation loss: 2.7562680783298714

Epoch: 6| Step: 7
Training loss: 3.668593218441175
Validation loss: 2.753520749677729

Epoch: 6| Step: 8
Training loss: 2.9877852682758466
Validation loss: 2.7432325029257187

Epoch: 6| Step: 9
Training loss: 3.236047284793432
Validation loss: 2.741804318831631

Epoch: 6| Step: 10
Training loss: 3.6651570651550336
Validation loss: 2.742900220893858

Epoch: 6| Step: 11
Training loss: 2.719433051936084
Validation loss: 2.743213642120769

Epoch: 6| Step: 12
Training loss: 2.9252751604078413
Validation loss: 2.742999265408291

Epoch: 6| Step: 13
Training loss: 2.9685002272086805
Validation loss: 2.7431695146947153

Epoch: 62| Step: 0
Training loss: 3.1773961314490613
Validation loss: 2.741594961364302

Epoch: 6| Step: 1
Training loss: 3.2461107898544936
Validation loss: 2.7427708422782024

Epoch: 6| Step: 2
Training loss: 2.7520284974042153
Validation loss: 2.7412828280037456

Epoch: 6| Step: 3
Training loss: 2.490434753733524
Validation loss: 2.74139623611412

Epoch: 6| Step: 4
Training loss: 3.5257094136076588
Validation loss: 2.740772519022403

Epoch: 6| Step: 5
Training loss: 3.108076428253061
Validation loss: 2.7425782837589097

Epoch: 6| Step: 6
Training loss: 2.9905765669038886
Validation loss: 2.73942481769666

Epoch: 6| Step: 7
Training loss: 3.4073784035294445
Validation loss: 2.737657914172621

Epoch: 6| Step: 8
Training loss: 2.8095920364340885
Validation loss: 2.740592042493735

Epoch: 6| Step: 9
Training loss: 2.7756503880900234
Validation loss: 2.739811458296941

Epoch: 6| Step: 10
Training loss: 3.6651692945403767
Validation loss: 2.7406402430690013

Epoch: 6| Step: 11
Training loss: 2.8880803635529833
Validation loss: 2.7374726200499797

Epoch: 6| Step: 12
Training loss: 3.0108551093302185
Validation loss: 2.738395622174655

Epoch: 6| Step: 13
Training loss: 2.878017997616501
Validation loss: 2.741739704946929

Epoch: 63| Step: 0
Training loss: 2.9247601793879774
Validation loss: 2.734867645277825

Epoch: 6| Step: 1
Training loss: 3.2122985479816077
Validation loss: 2.73898018948805

Epoch: 6| Step: 2
Training loss: 3.275342873832007
Validation loss: 2.7390807815461216

Epoch: 6| Step: 3
Training loss: 2.19302694462941
Validation loss: 2.739750875752998

Epoch: 6| Step: 4
Training loss: 3.048455400673433
Validation loss: 2.7342114274516485

Epoch: 6| Step: 5
Training loss: 3.7750773845092502
Validation loss: 2.7367892725100758

Epoch: 6| Step: 6
Training loss: 3.4872304395186826
Validation loss: 2.7349279938520685

Epoch: 6| Step: 7
Training loss: 3.2472026230092155
Validation loss: 2.738396317758863

Epoch: 6| Step: 8
Training loss: 2.880295230780185
Validation loss: 2.7402691053971804

Epoch: 6| Step: 9
Training loss: 2.8985268304019645
Validation loss: 2.73901950426252

Epoch: 6| Step: 10
Training loss: 2.881408183954261
Validation loss: 2.755415353736488

Epoch: 6| Step: 11
Training loss: 2.886265286768184
Validation loss: 2.7461551793646435

Epoch: 6| Step: 12
Training loss: 3.241432340989986
Validation loss: 2.7464438935356315

Epoch: 6| Step: 13
Training loss: 2.354430822445345
Validation loss: 2.740477754501572

Epoch: 64| Step: 0
Training loss: 3.778671520451686
Validation loss: 2.7395375765472836

Epoch: 6| Step: 1
Training loss: 2.649540944195017
Validation loss: 2.7306115512744245

Epoch: 6| Step: 2
Training loss: 3.335073175957202
Validation loss: 2.7308760525577087

Epoch: 6| Step: 3
Training loss: 2.745877730879409
Validation loss: 2.727587806725454

Epoch: 6| Step: 4
Training loss: 3.018461642501998
Validation loss: 2.7308862850362385

Epoch: 6| Step: 5
Training loss: 3.118025664649051
Validation loss: 2.728821716138822

Epoch: 6| Step: 6
Training loss: 3.05760861020635
Validation loss: 2.7310209972042583

Epoch: 6| Step: 7
Training loss: 2.8271826760124505
Validation loss: 2.7299096784465338

Epoch: 6| Step: 8
Training loss: 2.803257994968094
Validation loss: 2.7275934423179486

Epoch: 6| Step: 9
Training loss: 2.9976428626395095
Validation loss: 2.7303607216359977

Epoch: 6| Step: 10
Training loss: 2.6279888394494746
Validation loss: 2.727618585227259

Epoch: 6| Step: 11
Training loss: 2.4857341958957044
Validation loss: 2.7252497974462817

Epoch: 6| Step: 12
Training loss: 3.5243335607926634
Validation loss: 2.731345084993915

Epoch: 6| Step: 13
Training loss: 3.9995413755710523
Validation loss: 2.7304246832511954

Epoch: 65| Step: 0
Training loss: 2.5501113642889948
Validation loss: 2.7536807621092483

Epoch: 6| Step: 1
Training loss: 3.1190545554519007
Validation loss: 2.78622112274608

Epoch: 6| Step: 2
Training loss: 2.689189645885557
Validation loss: 2.796891728063172

Epoch: 6| Step: 3
Training loss: 3.1686077860984976
Validation loss: 2.7867607853421297

Epoch: 6| Step: 4
Training loss: 3.1194289330398495
Validation loss: 2.8256961860908394

Epoch: 6| Step: 5
Training loss: 3.094050229079735
Validation loss: 2.782473305373112

Epoch: 6| Step: 6
Training loss: 3.3813754017927558
Validation loss: 2.7732711970910144

Epoch: 6| Step: 7
Training loss: 3.321246852679443
Validation loss: 2.7332966083467505

Epoch: 6| Step: 8
Training loss: 2.9041405682551846
Validation loss: 2.7225298228149732

Epoch: 6| Step: 9
Training loss: 2.983497210926295
Validation loss: 2.7274297243636267

Epoch: 6| Step: 10
Training loss: 2.9189926863418965
Validation loss: 2.735709174918159

Epoch: 6| Step: 11
Training loss: 3.047070932201799
Validation loss: 2.738623281289898

Epoch: 6| Step: 12
Training loss: 3.495711423970831
Validation loss: 2.7523970667725637

Epoch: 6| Step: 13
Training loss: 3.366795775956283
Validation loss: 2.741827742373788

Epoch: 66| Step: 0
Training loss: 2.5017130704570723
Validation loss: 2.7484346560416433

Epoch: 6| Step: 1
Training loss: 3.3571639480624
Validation loss: 2.734167084414197

Epoch: 6| Step: 2
Training loss: 3.151148535227188
Validation loss: 2.728590524882307

Epoch: 6| Step: 3
Training loss: 3.3224458909059824
Validation loss: 2.726151160054925

Epoch: 6| Step: 4
Training loss: 3.5554509611110143
Validation loss: 2.725543999389429

Epoch: 6| Step: 5
Training loss: 3.0609782583766245
Validation loss: 2.729785977768844

Epoch: 6| Step: 6
Training loss: 2.6262055308205228
Validation loss: 2.7337984082471896

Epoch: 6| Step: 7
Training loss: 2.4384385282814236
Validation loss: 2.7414505757793193

Epoch: 6| Step: 8
Training loss: 3.1822385559811277
Validation loss: 2.7527098127501133

Epoch: 6| Step: 9
Training loss: 3.169335462067429
Validation loss: 2.774368670100028

Epoch: 6| Step: 10
Training loss: 3.3579334093481084
Validation loss: 2.780680046015467

Epoch: 6| Step: 11
Training loss: 2.113591028661408
Validation loss: 2.798112606558479

Epoch: 6| Step: 12
Training loss: 3.718737433917188
Validation loss: 2.8091565548250554

Epoch: 6| Step: 13
Training loss: 2.964247813286159
Validation loss: 2.75963584055311

Epoch: 67| Step: 0
Training loss: 3.2616251857837777
Validation loss: 2.734295349367347

Epoch: 6| Step: 1
Training loss: 3.4219325509304936
Validation loss: 2.722862643657919

Epoch: 6| Step: 2
Training loss: 2.696879144446591
Validation loss: 2.7209007356846606

Epoch: 6| Step: 3
Training loss: 2.8744167897337913
Validation loss: 2.726105633596747

Epoch: 6| Step: 4
Training loss: 2.1243193041062214
Validation loss: 2.7314882562318985

Epoch: 6| Step: 5
Training loss: 2.970754167769084
Validation loss: 2.732527859177288

Epoch: 6| Step: 6
Training loss: 3.3417035551881074
Validation loss: 2.736084209600211

Epoch: 6| Step: 7
Training loss: 3.029299393535381
Validation loss: 2.73759970096416

Epoch: 6| Step: 8
Training loss: 4.240987309360204
Validation loss: 2.7412366831041313

Epoch: 6| Step: 9
Training loss: 2.9312731711441753
Validation loss: 2.7379240081767735

Epoch: 6| Step: 10
Training loss: 3.0758782721989735
Validation loss: 2.731025636312223

Epoch: 6| Step: 11
Training loss: 2.5256575983931966
Validation loss: 2.73248241269276

Epoch: 6| Step: 12
Training loss: 2.845650509444091
Validation loss: 2.733752949124696

Epoch: 6| Step: 13
Training loss: 3.399376469825894
Validation loss: 2.728852353896714

Epoch: 68| Step: 0
Training loss: 2.7767849345243354
Validation loss: 2.726787323395621

Epoch: 6| Step: 1
Training loss: 4.1156890284859005
Validation loss: 2.723810200875127

Epoch: 6| Step: 2
Training loss: 3.2039441061585614
Validation loss: 2.722226810960695

Epoch: 6| Step: 3
Training loss: 3.1412629196077395
Validation loss: 2.7186898524356997

Epoch: 6| Step: 4
Training loss: 2.2706201669109727
Validation loss: 2.7157678633833227

Epoch: 6| Step: 5
Training loss: 2.7928325913325396
Validation loss: 2.713935658272835

Epoch: 6| Step: 6
Training loss: 3.4111252639123464
Validation loss: 2.715560262101865

Epoch: 6| Step: 7
Training loss: 3.2576667149260543
Validation loss: 2.712569706161359

Epoch: 6| Step: 8
Training loss: 2.9763600037747975
Validation loss: 2.7144619085131096

Epoch: 6| Step: 9
Training loss: 3.0285390155528105
Validation loss: 2.7280618231193285

Epoch: 6| Step: 10
Training loss: 2.7633893303284105
Validation loss: 2.738506426604939

Epoch: 6| Step: 11
Training loss: 2.6092259712834323
Validation loss: 2.7414144557512037

Epoch: 6| Step: 12
Training loss: 3.116011854391601
Validation loss: 2.750974677261553

Epoch: 6| Step: 13
Training loss: 2.9420708339936903
Validation loss: 2.713689731109598

Epoch: 69| Step: 0
Training loss: 3.208805165130559
Validation loss: 2.7119030815805365

Epoch: 6| Step: 1
Training loss: 2.782615412180507
Validation loss: 2.711296014099673

Epoch: 6| Step: 2
Training loss: 3.324102989180423
Validation loss: 2.714246230000541

Epoch: 6| Step: 3
Training loss: 2.1871130464812234
Validation loss: 2.7150277737064274

Epoch: 6| Step: 4
Training loss: 3.3000701318860197
Validation loss: 2.7155381352299806

Epoch: 6| Step: 5
Training loss: 3.3968420734231
Validation loss: 2.7188552969953244

Epoch: 6| Step: 6
Training loss: 3.405754123255419
Validation loss: 2.7240141288758686

Epoch: 6| Step: 7
Training loss: 2.429428822770329
Validation loss: 2.7244421466657287

Epoch: 6| Step: 8
Training loss: 3.0284821763215586
Validation loss: 2.7237690185108185

Epoch: 6| Step: 9
Training loss: 3.0308478963727734
Validation loss: 2.725177789724705

Epoch: 6| Step: 10
Training loss: 2.8187844318731368
Validation loss: 2.731650919145436

Epoch: 6| Step: 11
Training loss: 3.2097709374385572
Validation loss: 2.7243654069317413

Epoch: 6| Step: 12
Training loss: 3.2615944844404887
Validation loss: 2.7209757302352724

Epoch: 6| Step: 13
Training loss: 3.4127936547776123
Validation loss: 2.714977096761361

Epoch: 70| Step: 0
Training loss: 3.2655903937591457
Validation loss: 2.7129512725070426

Epoch: 6| Step: 1
Training loss: 3.7857707088820756
Validation loss: 2.7125700303295024

Epoch: 6| Step: 2
Training loss: 3.0777584574154586
Validation loss: 2.7091225609253002

Epoch: 6| Step: 3
Training loss: 2.3243516900005887
Validation loss: 2.7078819293125966

Epoch: 6| Step: 4
Training loss: 2.322958724891346
Validation loss: 2.7086489251390184

Epoch: 6| Step: 5
Training loss: 3.162157931317279
Validation loss: 2.7077317534451644

Epoch: 6| Step: 6
Training loss: 3.5499509673694845
Validation loss: 2.714162797058356

Epoch: 6| Step: 7
Training loss: 3.0628054719503144
Validation loss: 2.7288975865184595

Epoch: 6| Step: 8
Training loss: 2.9702608781289004
Validation loss: 2.7262319067104452

Epoch: 6| Step: 9
Training loss: 2.460994271728595
Validation loss: 2.7244889505187913

Epoch: 6| Step: 10
Training loss: 3.058329642672135
Validation loss: 2.7218877417739193

Epoch: 6| Step: 11
Training loss: 3.118083777202016
Validation loss: 2.710631242099997

Epoch: 6| Step: 12
Training loss: 3.05106914104587
Validation loss: 2.7097995553395497

Epoch: 6| Step: 13
Training loss: 3.1934909245171097
Validation loss: 2.7113271515205075

Epoch: 71| Step: 0
Training loss: 2.8365272770428636
Validation loss: 2.7065458761823944

Epoch: 6| Step: 1
Training loss: 3.062185777386717
Validation loss: 2.705775439910434

Epoch: 6| Step: 2
Training loss: 3.083188302693055
Validation loss: 2.704595991726301

Epoch: 6| Step: 3
Training loss: 3.044808493920174
Validation loss: 2.7087827415332493

Epoch: 6| Step: 4
Training loss: 2.724489402180525
Validation loss: 2.705456149315817

Epoch: 6| Step: 5
Training loss: 3.307368208032026
Validation loss: 2.7080960594976236

Epoch: 6| Step: 6
Training loss: 2.322727988296776
Validation loss: 2.7127599436726886

Epoch: 6| Step: 7
Training loss: 3.244263060462415
Validation loss: 2.7116400820805002

Epoch: 6| Step: 8
Training loss: 3.552024296393938
Validation loss: 2.710334464178398

Epoch: 6| Step: 9
Training loss: 2.086980894497552
Validation loss: 2.712572093474533

Epoch: 6| Step: 10
Training loss: 3.536900952842718
Validation loss: 2.7044942653764625

Epoch: 6| Step: 11
Training loss: 3.090804422105677
Validation loss: 2.7036086761789138

Epoch: 6| Step: 12
Training loss: 3.1350331795380093
Validation loss: 2.70275318690595

Epoch: 6| Step: 13
Training loss: 3.4815117400307125
Validation loss: 2.703818793703637

Epoch: 72| Step: 0
Training loss: 3.3893230417226894
Validation loss: 2.7016826221480024

Epoch: 6| Step: 1
Training loss: 3.4167337333485692
Validation loss: 2.7050055442909273

Epoch: 6| Step: 2
Training loss: 3.1142959377076016
Validation loss: 2.7026264338581063

Epoch: 6| Step: 3
Training loss: 2.545068205273609
Validation loss: 2.69750616121393

Epoch: 6| Step: 4
Training loss: 2.754168645383862
Validation loss: 2.6977579710998483

Epoch: 6| Step: 5
Training loss: 3.0511185267908503
Validation loss: 2.695610616044951

Epoch: 6| Step: 6
Training loss: 2.74303021211358
Validation loss: 2.6965007106222507

Epoch: 6| Step: 7
Training loss: 2.4555943203604547
Validation loss: 2.697891100931295

Epoch: 6| Step: 8
Training loss: 3.2306095632286507
Validation loss: 2.697529240956023

Epoch: 6| Step: 9
Training loss: 3.138136755779396
Validation loss: 2.698165682197734

Epoch: 6| Step: 10
Training loss: 3.4085046148438205
Validation loss: 2.694736947505361

Epoch: 6| Step: 11
Training loss: 2.538024878125197
Validation loss: 2.695993813341743

Epoch: 6| Step: 12
Training loss: 3.2531123297570113
Validation loss: 2.6952336524962

Epoch: 6| Step: 13
Training loss: 3.564232789636943
Validation loss: 2.699023779594381

Epoch: 73| Step: 0
Training loss: 2.920125672235767
Validation loss: 2.703887755017518

Epoch: 6| Step: 1
Training loss: 3.044663942581249
Validation loss: 2.707124586750922

Epoch: 6| Step: 2
Training loss: 2.6394772715788624
Validation loss: 2.714133612444112

Epoch: 6| Step: 3
Training loss: 2.8601586774009777
Validation loss: 2.717555774717438

Epoch: 6| Step: 4
Training loss: 3.1342847603827386
Validation loss: 2.7095588530203845

Epoch: 6| Step: 5
Training loss: 3.3869093827006913
Validation loss: 2.710508933925356

Epoch: 6| Step: 6
Training loss: 3.321386545035517
Validation loss: 2.7218475913447957

Epoch: 6| Step: 7
Training loss: 2.9615294335348685
Validation loss: 2.7181652431745738

Epoch: 6| Step: 8
Training loss: 3.0864300684815382
Validation loss: 2.701354704266766

Epoch: 6| Step: 9
Training loss: 2.8626633376783404
Validation loss: 2.6963598203558288

Epoch: 6| Step: 10
Training loss: 3.2586926339400466
Validation loss: 2.697306559061543

Epoch: 6| Step: 11
Training loss: 2.7851442655115575
Validation loss: 2.694175282704191

Epoch: 6| Step: 12
Training loss: 2.8417639871378744
Validation loss: 2.695149418868604

Epoch: 6| Step: 13
Training loss: 3.5774760761434057
Validation loss: 2.6941206556075032

Epoch: 74| Step: 0
Training loss: 2.921907149357305
Validation loss: 2.6943127818772252

Epoch: 6| Step: 1
Training loss: 2.3153777903030455
Validation loss: 2.6948860314961474

Epoch: 6| Step: 2
Training loss: 2.83939556378881
Validation loss: 2.6937743794245192

Epoch: 6| Step: 3
Training loss: 3.1158303578612436
Validation loss: 2.693319343269932

Epoch: 6| Step: 4
Training loss: 2.6283934321171523
Validation loss: 2.692910106367676

Epoch: 6| Step: 5
Training loss: 2.923603546140845
Validation loss: 2.6934708937880183

Epoch: 6| Step: 6
Training loss: 3.2615440458919847
Validation loss: 2.7066927602057658

Epoch: 6| Step: 7
Training loss: 3.6461684300057646
Validation loss: 2.707217237522017

Epoch: 6| Step: 8
Training loss: 3.1899098281313356
Validation loss: 2.7106113250025885

Epoch: 6| Step: 9
Training loss: 3.356278948952055
Validation loss: 2.7123480936734023

Epoch: 6| Step: 10
Training loss: 2.6356384324764326
Validation loss: 2.702205960988487

Epoch: 6| Step: 11
Training loss: 2.794473053558436
Validation loss: 2.696905350330459

Epoch: 6| Step: 12
Training loss: 3.2039415760785657
Validation loss: 2.6915537906854805

Epoch: 6| Step: 13
Training loss: 3.751904703251765
Validation loss: 2.691266640020431

Epoch: 75| Step: 0
Training loss: 3.097427802302826
Validation loss: 2.686726694728325

Epoch: 6| Step: 1
Training loss: 3.184615980918712
Validation loss: 2.689301743676738

Epoch: 6| Step: 2
Training loss: 3.049660998406248
Validation loss: 2.688245669392363

Epoch: 6| Step: 3
Training loss: 2.5448690366492905
Validation loss: 2.6857041236877377

Epoch: 6| Step: 4
Training loss: 2.827940708288837
Validation loss: 2.6896982229283135

Epoch: 6| Step: 5
Training loss: 2.934025434283663
Validation loss: 2.6861797341672164

Epoch: 6| Step: 6
Training loss: 3.2958195881771957
Validation loss: 2.686720745363586

Epoch: 6| Step: 7
Training loss: 2.923109640293577
Validation loss: 2.685640933599974

Epoch: 6| Step: 8
Training loss: 3.4018367910823737
Validation loss: 2.6853455409317832

Epoch: 6| Step: 9
Training loss: 2.9079553666395355
Validation loss: 2.6863390634577113

Epoch: 6| Step: 10
Training loss: 3.05045925497453
Validation loss: 2.6883335504518486

Epoch: 6| Step: 11
Training loss: 3.2452015299000347
Validation loss: 2.6869084975273356

Epoch: 6| Step: 12
Training loss: 2.8111762428361073
Validation loss: 2.689025899783596

Epoch: 6| Step: 13
Training loss: 3.095686335473004
Validation loss: 2.6877470091363755

Epoch: 76| Step: 0
Training loss: 2.350652068554575
Validation loss: 2.682101075883736

Epoch: 6| Step: 1
Training loss: 2.904165196977095
Validation loss: 2.6868217949904136

Epoch: 6| Step: 2
Training loss: 2.54168556289736
Validation loss: 2.686903227901992

Epoch: 6| Step: 3
Training loss: 2.897859664857329
Validation loss: 2.6892514389528683

Epoch: 6| Step: 4
Training loss: 2.830074418238601
Validation loss: 2.690836595409262

Epoch: 6| Step: 5
Training loss: 3.50652563198267
Validation loss: 2.6897307464953695

Epoch: 6| Step: 6
Training loss: 2.8897608109592157
Validation loss: 2.6904170542661703

Epoch: 6| Step: 7
Training loss: 3.2865488046968507
Validation loss: 2.68886582966597

Epoch: 6| Step: 8
Training loss: 3.333153306550093
Validation loss: 2.6888940567145028

Epoch: 6| Step: 9
Training loss: 3.0035776422383527
Validation loss: 2.6947837269297086

Epoch: 6| Step: 10
Training loss: 2.957804852056112
Validation loss: 2.7013426459870575

Epoch: 6| Step: 11
Training loss: 3.255694023011402
Validation loss: 2.6983039157717132

Epoch: 6| Step: 12
Training loss: 3.2830087943492345
Validation loss: 2.6923633145819723

Epoch: 6| Step: 13
Training loss: 3.3991664762341807
Validation loss: 2.682111561350914

Epoch: 77| Step: 0
Training loss: 1.8791815859363787
Validation loss: 2.6837602548088904

Epoch: 6| Step: 1
Training loss: 2.798471943245558
Validation loss: 2.686260804324321

Epoch: 6| Step: 2
Training loss: 3.1247288395538813
Validation loss: 2.685730562701695

Epoch: 6| Step: 3
Training loss: 3.4214742068720927
Validation loss: 2.693748172583992

Epoch: 6| Step: 4
Training loss: 3.10451200130316
Validation loss: 2.703610487296039

Epoch: 6| Step: 5
Training loss: 2.5276354189552785
Validation loss: 2.730475801139594

Epoch: 6| Step: 6
Training loss: 2.7250080213516186
Validation loss: 2.736672772302834

Epoch: 6| Step: 7
Training loss: 3.773711705956465
Validation loss: 2.7261690866180115

Epoch: 6| Step: 8
Training loss: 3.449355333330588
Validation loss: 2.6887681014946208

Epoch: 6| Step: 9
Training loss: 2.6927534698500804
Validation loss: 2.680168892865331

Epoch: 6| Step: 10
Training loss: 3.361038009296974
Validation loss: 2.6879782054500256

Epoch: 6| Step: 11
Training loss: 3.4086463268421
Validation loss: 2.691678943134264

Epoch: 6| Step: 12
Training loss: 2.5803994982831138
Validation loss: 2.6951409807124413

Epoch: 6| Step: 13
Training loss: 3.4240879932933135
Validation loss: 2.699443687323303

Epoch: 78| Step: 0
Training loss: 3.052641278370923
Validation loss: 2.710776063436875

Epoch: 6| Step: 1
Training loss: 3.1267554883670075
Validation loss: 2.737630040085343

Epoch: 6| Step: 2
Training loss: 3.3402669002772654
Validation loss: 2.7466950978258113

Epoch: 6| Step: 3
Training loss: 2.833593655763198
Validation loss: 2.6919298857882463

Epoch: 6| Step: 4
Training loss: 3.256741500926566
Validation loss: 2.6909666699155825

Epoch: 6| Step: 5
Training loss: 2.508114330155933
Validation loss: 2.684446251584567

Epoch: 6| Step: 6
Training loss: 3.3571665047041703
Validation loss: 2.6852502986440676

Epoch: 6| Step: 7
Training loss: 3.3558518498562466
Validation loss: 2.6794052365215815

Epoch: 6| Step: 8
Training loss: 1.9374684977277694
Validation loss: 2.680442635973838

Epoch: 6| Step: 9
Training loss: 2.7780534183647525
Validation loss: 2.6809808503961916

Epoch: 6| Step: 10
Training loss: 3.317950245388195
Validation loss: 2.67957912926593

Epoch: 6| Step: 11
Training loss: 3.101911011148054
Validation loss: 2.6890711492740285

Epoch: 6| Step: 12
Training loss: 3.049128554874791
Validation loss: 2.689182921204134

Epoch: 6| Step: 13
Training loss: 3.355218205185281
Validation loss: 2.699055253307745

Epoch: 79| Step: 0
Training loss: 3.0217968335934873
Validation loss: 2.7055872099513785

Epoch: 6| Step: 1
Training loss: 3.1537057423065993
Validation loss: 2.685149643382695

Epoch: 6| Step: 2
Training loss: 3.0010904873327595
Validation loss: 2.680788592987435

Epoch: 6| Step: 3
Training loss: 3.3360135429345275
Validation loss: 2.6830722213524947

Epoch: 6| Step: 4
Training loss: 2.970632819372697
Validation loss: 2.6888327216662495

Epoch: 6| Step: 5
Training loss: 2.781727610522912
Validation loss: 2.686754070224042

Epoch: 6| Step: 6
Training loss: 2.835901853899597
Validation loss: 2.70505804191631

Epoch: 6| Step: 7
Training loss: 3.5740559858773264
Validation loss: 2.714409128089353

Epoch: 6| Step: 8
Training loss: 2.5918868393509173
Validation loss: 2.7422028508326513

Epoch: 6| Step: 9
Training loss: 2.7558035733354345
Validation loss: 2.7584447992540855

Epoch: 6| Step: 10
Training loss: 2.883911419580839
Validation loss: 2.7397553962142567

Epoch: 6| Step: 11
Training loss: 3.333830049381153
Validation loss: 2.7212421083093536

Epoch: 6| Step: 12
Training loss: 3.247783051475373
Validation loss: 2.6920921211039506

Epoch: 6| Step: 13
Training loss: 3.2974745941918675
Validation loss: 2.688118291399497

Epoch: 80| Step: 0
Training loss: 3.2186845198702136
Validation loss: 2.6818786290338408

Epoch: 6| Step: 1
Training loss: 2.250038358573309
Validation loss: 2.6811149280320574

Epoch: 6| Step: 2
Training loss: 3.2710619480071292
Validation loss: 2.677685172274284

Epoch: 6| Step: 3
Training loss: 3.069073686795889
Validation loss: 2.677584646242436

Epoch: 6| Step: 4
Training loss: 3.075292067884839
Validation loss: 2.6836067114969264

Epoch: 6| Step: 5
Training loss: 3.6923030026418298
Validation loss: 2.69993010576311

Epoch: 6| Step: 6
Training loss: 3.203162216342485
Validation loss: 2.718656382954465

Epoch: 6| Step: 7
Training loss: 2.9174461049885214
Validation loss: 2.7186337546227213

Epoch: 6| Step: 8
Training loss: 3.154324841449165
Validation loss: 2.707281727927986

Epoch: 6| Step: 9
Training loss: 2.71514039099905
Validation loss: 2.689870362804513

Epoch: 6| Step: 10
Training loss: 3.1700219063949584
Validation loss: 2.684683481690118

Epoch: 6| Step: 11
Training loss: 2.9701743473551385
Validation loss: 2.6833020090032598

Epoch: 6| Step: 12
Training loss: 2.800275387164184
Validation loss: 2.680215616647008

Epoch: 6| Step: 13
Training loss: 2.5122457992483667
Validation loss: 2.676539394590533

Epoch: 81| Step: 0
Training loss: 2.694345494274461
Validation loss: 2.68030041333286

Epoch: 6| Step: 1
Training loss: 2.6601819724745273
Validation loss: 2.6770783568732983

Epoch: 6| Step: 2
Training loss: 2.2084833010248826
Validation loss: 2.677463255712737

Epoch: 6| Step: 3
Training loss: 2.916820703707742
Validation loss: 2.6760458950461703

Epoch: 6| Step: 4
Training loss: 3.045799965595233
Validation loss: 2.6777355142958674

Epoch: 6| Step: 5
Training loss: 2.8207268661474054
Validation loss: 2.6761456330006457

Epoch: 6| Step: 6
Training loss: 2.6991413729186133
Validation loss: 2.675191279049069

Epoch: 6| Step: 7
Training loss: 3.4498535125150602
Validation loss: 2.676119465235666

Epoch: 6| Step: 8
Training loss: 3.4234038817488717
Validation loss: 2.675460659456979

Epoch: 6| Step: 9
Training loss: 3.0572706456845387
Validation loss: 2.673735304811554

Epoch: 6| Step: 10
Training loss: 3.460533790206242
Validation loss: 2.67353892092833

Epoch: 6| Step: 11
Training loss: 3.2865225437539642
Validation loss: 2.6722560328544898

Epoch: 6| Step: 12
Training loss: 2.9333050581985374
Validation loss: 2.6723402772349236

Epoch: 6| Step: 13
Training loss: 3.655036790195566
Validation loss: 2.673678002978746

Epoch: 82| Step: 0
Training loss: 2.926980357321517
Validation loss: 2.676397608700478

Epoch: 6| Step: 1
Training loss: 3.10306510752247
Validation loss: 2.6716425636932035

Epoch: 6| Step: 2
Training loss: 3.156241841825007
Validation loss: 2.6751031253300566

Epoch: 6| Step: 3
Training loss: 2.7766365621002587
Validation loss: 2.673575544677854

Epoch: 6| Step: 4
Training loss: 2.88742366541247
Validation loss: 2.6708937966596493

Epoch: 6| Step: 5
Training loss: 3.8271454472589745
Validation loss: 2.6707342927464035

Epoch: 6| Step: 6
Training loss: 2.78911618306617
Validation loss: 2.6706719838829045

Epoch: 6| Step: 7
Training loss: 2.941722999732184
Validation loss: 2.6662312416193807

Epoch: 6| Step: 8
Training loss: 2.7156368277306435
Validation loss: 2.6699269246508828

Epoch: 6| Step: 9
Training loss: 2.835888738712168
Validation loss: 2.666028036342361

Epoch: 6| Step: 10
Training loss: 2.1327506814458563
Validation loss: 2.667438496966461

Epoch: 6| Step: 11
Training loss: 3.4518642972261877
Validation loss: 2.671343462866863

Epoch: 6| Step: 12
Training loss: 3.3246424547283615
Validation loss: 2.670675334013606

Epoch: 6| Step: 13
Training loss: 3.0803312343984763
Validation loss: 2.6688239804896345

Epoch: 83| Step: 0
Training loss: 2.4055551293509527
Validation loss: 2.678113176609271

Epoch: 6| Step: 1
Training loss: 2.927863201541513
Validation loss: 2.677027933543353

Epoch: 6| Step: 2
Training loss: 3.452956804002566
Validation loss: 2.6915869899873868

Epoch: 6| Step: 3
Training loss: 2.7199473758824046
Validation loss: 2.686384734202947

Epoch: 6| Step: 4
Training loss: 3.1192824893380555
Validation loss: 2.6941740751878442

Epoch: 6| Step: 5
Training loss: 2.834061603821514
Validation loss: 2.707433528054437

Epoch: 6| Step: 6
Training loss: 2.3353912837622532
Validation loss: 2.7059882948507465

Epoch: 6| Step: 7
Training loss: 2.7176755338546235
Validation loss: 2.6847122292086425

Epoch: 6| Step: 8
Training loss: 2.9478604656204586
Validation loss: 2.6749053601756976

Epoch: 6| Step: 9
Training loss: 3.27799404817312
Validation loss: 2.6707657379595817

Epoch: 6| Step: 10
Training loss: 3.784966526059848
Validation loss: 2.666894482551398

Epoch: 6| Step: 11
Training loss: 3.402739229221799
Validation loss: 2.664917526666651

Epoch: 6| Step: 12
Training loss: 3.1667869611947017
Validation loss: 2.664527557768601

Epoch: 6| Step: 13
Training loss: 2.5597188790761147
Validation loss: 2.6629356623666016

Epoch: 84| Step: 0
Training loss: 2.843648384710082
Validation loss: 2.661896752938378

Epoch: 6| Step: 1
Training loss: 3.110432200681542
Validation loss: 2.66432066044786

Epoch: 6| Step: 2
Training loss: 3.341286152573788
Validation loss: 2.664856452673639

Epoch: 6| Step: 3
Training loss: 2.2983756839574627
Validation loss: 2.6619400173858945

Epoch: 6| Step: 4
Training loss: 2.9630507524606653
Validation loss: 2.6656607844467155

Epoch: 6| Step: 5
Training loss: 3.2953512277222123
Validation loss: 2.6602874646882353

Epoch: 6| Step: 6
Training loss: 2.804428726201948
Validation loss: 2.6613707991085342

Epoch: 6| Step: 7
Training loss: 3.3497037557311944
Validation loss: 2.6625019887488963

Epoch: 6| Step: 8
Training loss: 3.390899787702264
Validation loss: 2.6590470963385884

Epoch: 6| Step: 9
Training loss: 3.0208325265466773
Validation loss: 2.6594917045890356

Epoch: 6| Step: 10
Training loss: 2.8228844409712623
Validation loss: 2.6676150841418766

Epoch: 6| Step: 11
Training loss: 2.71349387880348
Validation loss: 2.669844534164164

Epoch: 6| Step: 12
Training loss: 3.2051611406639244
Validation loss: 2.68526856413159

Epoch: 6| Step: 13
Training loss: 2.673422827978579
Validation loss: 2.6792217906982154

Epoch: 85| Step: 0
Training loss: 3.261309386736503
Validation loss: 2.6776883585304754

Epoch: 6| Step: 1
Training loss: 2.9530948052048434
Validation loss: 2.665909921908891

Epoch: 6| Step: 2
Training loss: 2.757320716819208
Validation loss: 2.6638478242026964

Epoch: 6| Step: 3
Training loss: 3.18508760005428
Validation loss: 2.6619264640352274

Epoch: 6| Step: 4
Training loss: 3.7640013934060903
Validation loss: 2.6581767603512865

Epoch: 6| Step: 5
Training loss: 2.682748364330117
Validation loss: 2.6574437855505257

Epoch: 6| Step: 6
Training loss: 2.7270439182014132
Validation loss: 2.6600081802354643

Epoch: 6| Step: 7
Training loss: 2.752757510578863
Validation loss: 2.6561321698088203

Epoch: 6| Step: 8
Training loss: 3.015232040813564
Validation loss: 2.6549985848869864

Epoch: 6| Step: 9
Training loss: 3.2063427649569225
Validation loss: 2.6605682692431363

Epoch: 6| Step: 10
Training loss: 3.437960507151074
Validation loss: 2.6564768665966088

Epoch: 6| Step: 11
Training loss: 2.085673912053232
Validation loss: 2.653940499489012

Epoch: 6| Step: 12
Training loss: 2.792941433432849
Validation loss: 2.6555342180950303

Epoch: 6| Step: 13
Training loss: 3.154389994755511
Validation loss: 2.6540347306262846

Epoch: 86| Step: 0
Training loss: 2.6020248964424884
Validation loss: 2.660455081223684

Epoch: 6| Step: 1
Training loss: 3.2491699038973154
Validation loss: 2.6657801288548395

Epoch: 6| Step: 2
Training loss: 3.509180019054014
Validation loss: 2.675575745106251

Epoch: 6| Step: 3
Training loss: 3.261568022574625
Validation loss: 2.68515498232692

Epoch: 6| Step: 4
Training loss: 3.2720486920005127
Validation loss: 2.679296405615785

Epoch: 6| Step: 5
Training loss: 2.761899604972635
Validation loss: 2.681823718004295

Epoch: 6| Step: 6
Training loss: 2.6526953754864038
Validation loss: 2.6708815595840396

Epoch: 6| Step: 7
Training loss: 3.3761341873637702
Validation loss: 2.6655019772641415

Epoch: 6| Step: 8
Training loss: 3.204467194497449
Validation loss: 2.6661530552535715

Epoch: 6| Step: 9
Training loss: 2.812725142898287
Validation loss: 2.6535791084007485

Epoch: 6| Step: 10
Training loss: 2.0972327119117224
Validation loss: 2.6520895160040747

Epoch: 6| Step: 11
Training loss: 2.8486999357342886
Validation loss: 2.652421411694263

Epoch: 6| Step: 12
Training loss: 2.9921345917727704
Validation loss: 2.654266243999749

Epoch: 6| Step: 13
Training loss: 3.231912901299618
Validation loss: 2.6531956068424085

Epoch: 87| Step: 0
Training loss: 3.048396586461816
Validation loss: 2.653997239298218

Epoch: 6| Step: 1
Training loss: 2.2960756948201846
Validation loss: 2.6582335158234645

Epoch: 6| Step: 2
Training loss: 2.84958829081045
Validation loss: 2.6551964675010664

Epoch: 6| Step: 3
Training loss: 3.0446822663702386
Validation loss: 2.6601079547581765

Epoch: 6| Step: 4
Training loss: 3.491845577150852
Validation loss: 2.656874824593567

Epoch: 6| Step: 5
Training loss: 2.4391253016693613
Validation loss: 2.653036082500248

Epoch: 6| Step: 6
Training loss: 3.309197849218665
Validation loss: 2.656561349842033

Epoch: 6| Step: 7
Training loss: 2.982693982654781
Validation loss: 2.654902931797921

Epoch: 6| Step: 8
Training loss: 2.7218803712286
Validation loss: 2.6554270773126887

Epoch: 6| Step: 9
Training loss: 2.3947564621226975
Validation loss: 2.6532817569367295

Epoch: 6| Step: 10
Training loss: 3.461616397860615
Validation loss: 2.6476633146283124

Epoch: 6| Step: 11
Training loss: 3.764334176450357
Validation loss: 2.6473546136396964

Epoch: 6| Step: 12
Training loss: 2.520096684372245
Validation loss: 2.648988453068044

Epoch: 6| Step: 13
Training loss: 3.670115207454165
Validation loss: 2.6494421786452795

Epoch: 88| Step: 0
Training loss: 3.314382773772749
Validation loss: 2.650083661824208

Epoch: 6| Step: 1
Training loss: 2.6340653243136294
Validation loss: 2.651119278829114

Epoch: 6| Step: 2
Training loss: 2.964864657884942
Validation loss: 2.653379910970726

Epoch: 6| Step: 3
Training loss: 3.1332687844736262
Validation loss: 2.6523386059802276

Epoch: 6| Step: 4
Training loss: 3.0595991448031037
Validation loss: 2.652268250214654

Epoch: 6| Step: 5
Training loss: 3.1384202800530154
Validation loss: 2.653289074555949

Epoch: 6| Step: 6
Training loss: 2.823387181858064
Validation loss: 2.653490903322533

Epoch: 6| Step: 7
Training loss: 3.076269684704946
Validation loss: 2.648931686298761

Epoch: 6| Step: 8
Training loss: 2.9810683221060956
Validation loss: 2.6536523653306827

Epoch: 6| Step: 9
Training loss: 3.4356028089800743
Validation loss: 2.648775656581775

Epoch: 6| Step: 10
Training loss: 2.614965241239475
Validation loss: 2.648934947788541

Epoch: 6| Step: 11
Training loss: 2.6002437697355107
Validation loss: 2.6485354318631043

Epoch: 6| Step: 12
Training loss: 2.799429126854134
Validation loss: 2.646878709790612

Epoch: 6| Step: 13
Training loss: 3.5450154946315444
Validation loss: 2.6465119768993444

Epoch: 89| Step: 0
Training loss: 2.6370308698366958
Validation loss: 2.6505319430994807

Epoch: 6| Step: 1
Training loss: 2.893249310212468
Validation loss: 2.646401550137558

Epoch: 6| Step: 2
Training loss: 3.3356268780570617
Validation loss: 2.6438646059590254

Epoch: 6| Step: 3
Training loss: 3.410999871040639
Validation loss: 2.6497693536678453

Epoch: 6| Step: 4
Training loss: 1.6757643194165868
Validation loss: 2.6489217043730395

Epoch: 6| Step: 5
Training loss: 2.820640481491762
Validation loss: 2.651323469148243

Epoch: 6| Step: 6
Training loss: 3.701658062971394
Validation loss: 2.6548812263905113

Epoch: 6| Step: 7
Training loss: 2.1114862119932254
Validation loss: 2.663362364800637

Epoch: 6| Step: 8
Training loss: 3.4741818624450684
Validation loss: 2.665033254225276

Epoch: 6| Step: 9
Training loss: 3.1645514969838913
Validation loss: 2.665710443771564

Epoch: 6| Step: 10
Training loss: 3.0570507225393273
Validation loss: 2.667625032638018

Epoch: 6| Step: 11
Training loss: 2.8289925103572164
Validation loss: 2.66764928098092

Epoch: 6| Step: 12
Training loss: 2.9476618212928565
Validation loss: 2.6485266448300844

Epoch: 6| Step: 13
Training loss: 3.3424613109281114
Validation loss: 2.6494153083175522

Epoch: 90| Step: 0
Training loss: 2.359698443947533
Validation loss: 2.6464940435439313

Epoch: 6| Step: 1
Training loss: 3.259188062037916
Validation loss: 2.6417334241639785

Epoch: 6| Step: 2
Training loss: 3.531825736044342
Validation loss: 2.6426609154485683

Epoch: 6| Step: 3
Training loss: 2.1017694194137504
Validation loss: 2.643196655118754

Epoch: 6| Step: 4
Training loss: 3.3295572986682096
Validation loss: 2.641768500441831

Epoch: 6| Step: 5
Training loss: 2.6856079538508797
Validation loss: 2.641418277683383

Epoch: 6| Step: 6
Training loss: 2.5940744587749323
Validation loss: 2.645325051273729

Epoch: 6| Step: 7
Training loss: 2.7909194363782706
Validation loss: 2.640855621229963

Epoch: 6| Step: 8
Training loss: 2.873391074406596
Validation loss: 2.6422820872553725

Epoch: 6| Step: 9
Training loss: 2.765348258962543
Validation loss: 2.638491881629382

Epoch: 6| Step: 10
Training loss: 3.608120787059889
Validation loss: 2.641154364882632

Epoch: 6| Step: 11
Training loss: 2.9364654667228525
Validation loss: 2.638024186380817

Epoch: 6| Step: 12
Training loss: 3.281104238996476
Validation loss: 2.637371598048628

Epoch: 6| Step: 13
Training loss: 3.511490896129254
Validation loss: 2.638654009806516

Epoch: 91| Step: 0
Training loss: 2.6771778332449023
Validation loss: 2.636596229590076

Epoch: 6| Step: 1
Training loss: 3.1140702419309183
Validation loss: 2.638602720056528

Epoch: 6| Step: 2
Training loss: 2.4465626211503775
Validation loss: 2.6356414769723906

Epoch: 6| Step: 3
Training loss: 3.4186927246651915
Validation loss: 2.635250966857905

Epoch: 6| Step: 4
Training loss: 3.2988337623453163
Validation loss: 2.6346858130402167

Epoch: 6| Step: 5
Training loss: 3.793184598365578
Validation loss: 2.6329874320351085

Epoch: 6| Step: 6
Training loss: 2.4658020381439174
Validation loss: 2.637240434976893

Epoch: 6| Step: 7
Training loss: 3.3749013815706004
Validation loss: 2.6334666873234647

Epoch: 6| Step: 8
Training loss: 2.5490560729308323
Validation loss: 2.6365893863252614

Epoch: 6| Step: 9
Training loss: 2.8778609263396553
Validation loss: 2.6412154152489493

Epoch: 6| Step: 10
Training loss: 3.102908824755193
Validation loss: 2.634120017282768

Epoch: 6| Step: 11
Training loss: 2.4690612403625973
Validation loss: 2.6411596151317647

Epoch: 6| Step: 12
Training loss: 2.8886693989276915
Validation loss: 2.6524878287616267

Epoch: 6| Step: 13
Training loss: 2.9026611483160343
Validation loss: 2.6607877274450336

Epoch: 92| Step: 0
Training loss: 2.5696176441917014
Validation loss: 2.634310926709354

Epoch: 6| Step: 1
Training loss: 3.0837716143360496
Validation loss: 2.635091019682576

Epoch: 6| Step: 2
Training loss: 3.0659070428640525
Validation loss: 2.632157565705616

Epoch: 6| Step: 3
Training loss: 3.3126727365044206
Validation loss: 2.635780204016079

Epoch: 6| Step: 4
Training loss: 2.686947521820229
Validation loss: 2.6267961635647725

Epoch: 6| Step: 5
Training loss: 2.948583916049423
Validation loss: 2.6301101862821077

Epoch: 6| Step: 6
Training loss: 3.241148412181268
Validation loss: 2.6296945652293373

Epoch: 6| Step: 7
Training loss: 2.9913253936639537
Validation loss: 2.6292788823777618

Epoch: 6| Step: 8
Training loss: 3.258149712763557
Validation loss: 2.6287014828211337

Epoch: 6| Step: 9
Training loss: 3.0982408392857024
Validation loss: 2.6288537168596875

Epoch: 6| Step: 10
Training loss: 3.006741261145463
Validation loss: 2.6293931443224308

Epoch: 6| Step: 11
Training loss: 2.4750650493666204
Validation loss: 2.632501804328712

Epoch: 6| Step: 12
Training loss: 2.8951296786185705
Validation loss: 2.6255365400555704

Epoch: 6| Step: 13
Training loss: 2.9786830767478607
Validation loss: 2.628292696531624

Epoch: 93| Step: 0
Training loss: 3.0272133288438856
Validation loss: 2.6316687883780534

Epoch: 6| Step: 1
Training loss: 2.313428125482281
Validation loss: 2.6297041010156383

Epoch: 6| Step: 2
Training loss: 2.9900219603277476
Validation loss: 2.6383951989249805

Epoch: 6| Step: 3
Training loss: 2.4115328574697568
Validation loss: 2.6338836875459535

Epoch: 6| Step: 4
Training loss: 2.756962112852718
Validation loss: 2.647200185729108

Epoch: 6| Step: 5
Training loss: 3.2304070500267152
Validation loss: 2.6637356792542413

Epoch: 6| Step: 6
Training loss: 3.274370374652634
Validation loss: 2.6935971811178354

Epoch: 6| Step: 7
Training loss: 3.1210164429372944
Validation loss: 2.703299025586742

Epoch: 6| Step: 8
Training loss: 3.004216251325627
Validation loss: 2.728297994214656

Epoch: 6| Step: 9
Training loss: 2.765302994942708
Validation loss: 2.733917111734472

Epoch: 6| Step: 10
Training loss: 3.616711579027836
Validation loss: 2.728888903243495

Epoch: 6| Step: 11
Training loss: 3.1684136507495135
Validation loss: 2.678732275638114

Epoch: 6| Step: 12
Training loss: 2.986644101937521
Validation loss: 2.6452910164867305

Epoch: 6| Step: 13
Training loss: 3.2050038851567137
Validation loss: 2.632803332344268

Epoch: 94| Step: 0
Training loss: 2.678825662445963
Validation loss: 2.6290194554951114

Epoch: 6| Step: 1
Training loss: 2.9919975359901443
Validation loss: 2.631821635896491

Epoch: 6| Step: 2
Training loss: 2.8903597323385575
Validation loss: 2.6453745477077515

Epoch: 6| Step: 3
Training loss: 2.6899818670803244
Validation loss: 2.648517853896099

Epoch: 6| Step: 4
Training loss: 2.825169910958871
Validation loss: 2.650840108700411

Epoch: 6| Step: 5
Training loss: 2.694200369233446
Validation loss: 2.6484396402080113

Epoch: 6| Step: 6
Training loss: 2.866391105123182
Validation loss: 2.645524623600019

Epoch: 6| Step: 7
Training loss: 3.0225387144172973
Validation loss: 2.649405367402892

Epoch: 6| Step: 8
Training loss: 2.7688593513474
Validation loss: 2.6407289814013124

Epoch: 6| Step: 9
Training loss: 3.4689784619126516
Validation loss: 2.6416701595301033

Epoch: 6| Step: 10
Training loss: 3.071992603740133
Validation loss: 2.637164286985798

Epoch: 6| Step: 11
Training loss: 3.300648920239433
Validation loss: 2.640552271941934

Epoch: 6| Step: 12
Training loss: 3.4423422260461995
Validation loss: 2.634411284250933

Epoch: 6| Step: 13
Training loss: 3.39505769885645
Validation loss: 2.6323383437813823

Epoch: 95| Step: 0
Training loss: 3.3693908421577925
Validation loss: 2.630206419364227

Epoch: 6| Step: 1
Training loss: 3.0150033576908677
Validation loss: 2.6304195709510583

Epoch: 6| Step: 2
Training loss: 2.840779859898043
Validation loss: 2.626183528681828

Epoch: 6| Step: 3
Training loss: 2.7291893315041458
Validation loss: 2.6282016178139904

Epoch: 6| Step: 4
Training loss: 3.164794234446644
Validation loss: 2.625308081717589

Epoch: 6| Step: 5
Training loss: 2.123150300960808
Validation loss: 2.626528267219064

Epoch: 6| Step: 6
Training loss: 2.983740614327738
Validation loss: 2.628180654650339

Epoch: 6| Step: 7
Training loss: 3.0731849337791295
Validation loss: 2.6398010094482247

Epoch: 6| Step: 8
Training loss: 2.8511992758821707
Validation loss: 2.6419360653646997

Epoch: 6| Step: 9
Training loss: 3.432852360142814
Validation loss: 2.6697760964199815

Epoch: 6| Step: 10
Training loss: 2.5668112610881284
Validation loss: 2.6627221261657223

Epoch: 6| Step: 11
Training loss: 2.755167267943441
Validation loss: 2.6825414130146124

Epoch: 6| Step: 12
Training loss: 3.4391508819856247
Validation loss: 2.690697786219614

Epoch: 6| Step: 13
Training loss: 3.388506812217274
Validation loss: 2.675053230195344

Epoch: 96| Step: 0
Training loss: 2.981875026609332
Validation loss: 2.6432160113738896

Epoch: 6| Step: 1
Training loss: 2.954079609939094
Validation loss: 2.628375854046281

Epoch: 6| Step: 2
Training loss: 2.97685308364659
Validation loss: 2.6211560451617095

Epoch: 6| Step: 3
Training loss: 3.284933438722675
Validation loss: 2.6193978935119335

Epoch: 6| Step: 4
Training loss: 2.742039081436878
Validation loss: 2.616772670987916

Epoch: 6| Step: 5
Training loss: 3.021235331829987
Validation loss: 2.6180303850622573

Epoch: 6| Step: 6
Training loss: 3.4372448913238824
Validation loss: 2.617995576322063

Epoch: 6| Step: 7
Training loss: 2.6394208160044355
Validation loss: 2.617250461154703

Epoch: 6| Step: 8
Training loss: 2.6665225486753332
Validation loss: 2.618301302020837

Epoch: 6| Step: 9
Training loss: 2.991617890565139
Validation loss: 2.6170675113987416

Epoch: 6| Step: 10
Training loss: 3.050099236796908
Validation loss: 2.616733774824678

Epoch: 6| Step: 11
Training loss: 3.527671688884279
Validation loss: 2.6160334930546894

Epoch: 6| Step: 12
Training loss: 2.6778691742716187
Validation loss: 2.620273990365123

Epoch: 6| Step: 13
Training loss: 2.208934294304096
Validation loss: 2.6203115435041284

Epoch: 97| Step: 0
Training loss: 3.085688404701324
Validation loss: 2.6170341230033594

Epoch: 6| Step: 1
Training loss: 2.3123271980675337
Validation loss: 2.61804864852283

Epoch: 6| Step: 2
Training loss: 2.799895121108822
Validation loss: 2.6140491400888615

Epoch: 6| Step: 3
Training loss: 3.085752380226773
Validation loss: 2.615584241988826

Epoch: 6| Step: 4
Training loss: 3.336606532598854
Validation loss: 2.620945658563135

Epoch: 6| Step: 5
Training loss: 2.482404395161216
Validation loss: 2.61596604656439

Epoch: 6| Step: 6
Training loss: 3.3799464394202476
Validation loss: 2.6143968779836646

Epoch: 6| Step: 7
Training loss: 2.9265186312636557
Validation loss: 2.6182649469086234

Epoch: 6| Step: 8
Training loss: 3.1505949518170437
Validation loss: 2.6204104971608135

Epoch: 6| Step: 9
Training loss: 3.3804651445934235
Validation loss: 2.6155100403628584

Epoch: 6| Step: 10
Training loss: 3.0512410499975955
Validation loss: 2.6162358593290462

Epoch: 6| Step: 11
Training loss: 3.0312750117263048
Validation loss: 2.6164598286288347

Epoch: 6| Step: 12
Training loss: 2.5681539359079095
Validation loss: 2.613780925915753

Epoch: 6| Step: 13
Training loss: 2.6270086686739513
Validation loss: 2.614826375596827

Epoch: 98| Step: 0
Training loss: 2.3924269523351223
Validation loss: 2.619374956766314

Epoch: 6| Step: 1
Training loss: 3.4008404534460186
Validation loss: 2.6165902453109795

Epoch: 6| Step: 2
Training loss: 2.7725720411869874
Validation loss: 2.618954139424126

Epoch: 6| Step: 3
Training loss: 2.458695616670964
Validation loss: 2.6145379471444024

Epoch: 6| Step: 4
Training loss: 3.185315748819532
Validation loss: 2.6150211463973103

Epoch: 6| Step: 5
Training loss: 2.9634023587827323
Validation loss: 2.6160420315403257

Epoch: 6| Step: 6
Training loss: 2.740030771904112
Validation loss: 2.6133414545329594

Epoch: 6| Step: 7
Training loss: 3.039239010428796
Validation loss: 2.616017404798235

Epoch: 6| Step: 8
Training loss: 3.2928639097708676
Validation loss: 2.616982043152469

Epoch: 6| Step: 9
Training loss: 2.843955231691118
Validation loss: 2.622792200815278

Epoch: 6| Step: 10
Training loss: 3.4466754872881276
Validation loss: 2.627716658822056

Epoch: 6| Step: 11
Training loss: 3.267537848115487
Validation loss: 2.622367079504526

Epoch: 6| Step: 12
Training loss: 2.6765746784990925
Validation loss: 2.6154534364879147

Epoch: 6| Step: 13
Training loss: 2.8270170454679278
Validation loss: 2.6135238568446972

Epoch: 99| Step: 0
Training loss: 3.484203796286201
Validation loss: 2.609723387233408

Epoch: 6| Step: 1
Training loss: 3.444518951580945
Validation loss: 2.615805638567424

Epoch: 6| Step: 2
Training loss: 2.4582697865521883
Validation loss: 2.6148575735083854

Epoch: 6| Step: 3
Training loss: 2.43217159739999
Validation loss: 2.6173659211025284

Epoch: 6| Step: 4
Training loss: 2.9137941293144483
Validation loss: 2.6114314587574454

Epoch: 6| Step: 5
Training loss: 2.9378684604144962
Validation loss: 2.610607385501589

Epoch: 6| Step: 6
Training loss: 2.5359153610269085
Validation loss: 2.611120005874419

Epoch: 6| Step: 7
Training loss: 3.186663050257122
Validation loss: 2.6046585885036158

Epoch: 6| Step: 8
Training loss: 2.939445987325221
Validation loss: 2.6078370019510797

Epoch: 6| Step: 9
Training loss: 2.748084875303628
Validation loss: 2.6059754752403608

Epoch: 6| Step: 10
Training loss: 3.161262082958849
Validation loss: 2.6065781235362597

Epoch: 6| Step: 11
Training loss: 3.013964259957761
Validation loss: 2.6101827556941632

Epoch: 6| Step: 12
Training loss: 3.098961342347979
Validation loss: 2.608511984601996

Epoch: 6| Step: 13
Training loss: 2.9004784156536747
Validation loss: 2.611857541410674

Epoch: 100| Step: 0
Training loss: 2.909356046916061
Validation loss: 2.621633581141483

Epoch: 6| Step: 1
Training loss: 2.6156168765508188
Validation loss: 2.6236029284865467

Epoch: 6| Step: 2
Training loss: 2.931853203433271
Validation loss: 2.6301564786062266

Epoch: 6| Step: 3
Training loss: 3.269669214252396
Validation loss: 2.628077430260932

Epoch: 6| Step: 4
Training loss: 3.694456876448618
Validation loss: 2.626253078004565

Epoch: 6| Step: 5
Training loss: 2.6643145042099947
Validation loss: 2.636295839436668

Epoch: 6| Step: 6
Training loss: 2.7744234293719474
Validation loss: 2.6332138844672484

Epoch: 6| Step: 7
Training loss: 2.987515858883443
Validation loss: 2.6376552475249526

Epoch: 6| Step: 8
Training loss: 2.5785677442988533
Validation loss: 2.628798635412428

Epoch: 6| Step: 9
Training loss: 2.9100002579836386
Validation loss: 2.631317422071371

Epoch: 6| Step: 10
Training loss: 2.8159921794100016
Validation loss: 2.6233555163949895

Epoch: 6| Step: 11
Training loss: 3.227038627759778
Validation loss: 2.625491856494979

Epoch: 6| Step: 12
Training loss: 3.126213601017533
Validation loss: 2.607651144341303

Epoch: 6| Step: 13
Training loss: 2.7493080655826003
Validation loss: 2.6036278401443296

Epoch: 101| Step: 0
Training loss: 2.600935668578002
Validation loss: 2.607639361590953

Epoch: 6| Step: 1
Training loss: 3.257897977370843
Validation loss: 2.607837660596159

Epoch: 6| Step: 2
Training loss: 3.6820130986980986
Validation loss: 2.615603407590347

Epoch: 6| Step: 3
Training loss: 2.7160969208909127
Validation loss: 2.6114530432924394

Epoch: 6| Step: 4
Training loss: 2.825409992815634
Validation loss: 2.6140703578001903

Epoch: 6| Step: 5
Training loss: 3.182379255738693
Validation loss: 2.615538494500553

Epoch: 6| Step: 6
Training loss: 2.7319825087080924
Validation loss: 2.6170082105564325

Epoch: 6| Step: 7
Training loss: 2.984558099851903
Validation loss: 2.6107785431234296

Epoch: 6| Step: 8
Training loss: 2.39322027814264
Validation loss: 2.6150752426293433

Epoch: 6| Step: 9
Training loss: 2.8312855968805963
Validation loss: 2.6109003269792996

Epoch: 6| Step: 10
Training loss: 3.459030693859835
Validation loss: 2.6093221296417126

Epoch: 6| Step: 11
Training loss: 3.0650925853492086
Validation loss: 2.6078367473404747

Epoch: 6| Step: 12
Training loss: 3.0107759219546177
Validation loss: 2.60428832395497

Epoch: 6| Step: 13
Training loss: 2.424095563251204
Validation loss: 2.6049309128812244

Epoch: 102| Step: 0
Training loss: 3.0014628976145676
Validation loss: 2.605881222948869

Epoch: 6| Step: 1
Training loss: 2.8423579235687098
Validation loss: 2.6084205523090636

Epoch: 6| Step: 2
Training loss: 2.710959486638596
Validation loss: 2.6103333993776285

Epoch: 6| Step: 3
Training loss: 3.53279174636623
Validation loss: 2.6134381530336115

Epoch: 6| Step: 4
Training loss: 2.582126540648972
Validation loss: 2.619615987847103

Epoch: 6| Step: 5
Training loss: 3.110455809183173
Validation loss: 2.6333671095948197

Epoch: 6| Step: 6
Training loss: 2.82429042107905
Validation loss: 2.6291937165098798

Epoch: 6| Step: 7
Training loss: 2.733253118066798
Validation loss: 2.6354443128222727

Epoch: 6| Step: 8
Training loss: 2.898006108921897
Validation loss: 2.6265870388424655

Epoch: 6| Step: 9
Training loss: 2.938471532014222
Validation loss: 2.6271428768062854

Epoch: 6| Step: 10
Training loss: 3.5517570069768127
Validation loss: 2.639966781353771

Epoch: 6| Step: 11
Training loss: 3.1253330816142966
Validation loss: 2.6284259134922308

Epoch: 6| Step: 12
Training loss: 2.7894985168037363
Validation loss: 2.6393624777945566

Epoch: 6| Step: 13
Training loss: 2.436487623421657
Validation loss: 2.634990283294114

Epoch: 103| Step: 0
Training loss: 2.2433561144045715
Validation loss: 2.600448979578399

Epoch: 6| Step: 1
Training loss: 3.3771304717746204
Validation loss: 2.602216888638791

Epoch: 6| Step: 2
Training loss: 2.929760090246532
Validation loss: 2.606145678921217

Epoch: 6| Step: 3
Training loss: 3.0182839170048106
Validation loss: 2.613669979432622

Epoch: 6| Step: 4
Training loss: 3.3199330550648614
Validation loss: 2.6206460638928237

Epoch: 6| Step: 5
Training loss: 2.6305733506127713
Validation loss: 2.623776535036558

Epoch: 6| Step: 6
Training loss: 3.122463722965074
Validation loss: 2.622719379017793

Epoch: 6| Step: 7
Training loss: 2.856315435081542
Validation loss: 2.6311808117663587

Epoch: 6| Step: 8
Training loss: 3.0092170903655724
Validation loss: 2.6266973304234003

Epoch: 6| Step: 9
Training loss: 2.8587849326057313
Validation loss: 2.626718190258716

Epoch: 6| Step: 10
Training loss: 2.769319727988962
Validation loss: 2.6303425510453784

Epoch: 6| Step: 11
Training loss: 3.14564727502459
Validation loss: 2.6222653713601884

Epoch: 6| Step: 12
Training loss: 3.295429654161925
Validation loss: 2.619785633144225

Epoch: 6| Step: 13
Training loss: 3.2277690857423527
Validation loss: 2.6173728048334386

Epoch: 104| Step: 0
Training loss: 3.2777195420632528
Validation loss: 2.6205107433261667

Epoch: 6| Step: 1
Training loss: 2.4569775889348433
Validation loss: 2.61670033906311

Epoch: 6| Step: 2
Training loss: 2.8241903005515137
Validation loss: 2.614935122054736

Epoch: 6| Step: 3
Training loss: 3.3277722382185364
Validation loss: 2.611166456180425

Epoch: 6| Step: 4
Training loss: 2.752088447313854
Validation loss: 2.611745960592409

Epoch: 6| Step: 5
Training loss: 3.1917576497176676
Validation loss: 2.6104311555360273

Epoch: 6| Step: 6
Training loss: 3.05705197037485
Validation loss: 2.6169582922255477

Epoch: 6| Step: 7
Training loss: 3.03303711112008
Validation loss: 2.6151131370689202

Epoch: 6| Step: 8
Training loss: 2.792418440376511
Validation loss: 2.63163789789441

Epoch: 6| Step: 9
Training loss: 3.362317025690766
Validation loss: 2.624637668602782

Epoch: 6| Step: 10
Training loss: 3.2234496833397213
Validation loss: 2.606462504392219

Epoch: 6| Step: 11
Training loss: 2.74457396211516
Validation loss: 2.6030599274406634

Epoch: 6| Step: 12
Training loss: 2.5540871570983414
Validation loss: 2.6005798817636627

Epoch: 6| Step: 13
Training loss: 3.111387588689455
Validation loss: 2.598503268426893

Epoch: 105| Step: 0
Training loss: 3.1400659167909186
Validation loss: 2.600503435135817

Epoch: 6| Step: 1
Training loss: 3.013298441704588
Validation loss: 2.599710439045408

Epoch: 6| Step: 2
Training loss: 2.815957974169071
Validation loss: 2.5989222899606346

Epoch: 6| Step: 3
Training loss: 3.3484764563234197
Validation loss: 2.5959855838330923

Epoch: 6| Step: 4
Training loss: 2.6972277926609998
Validation loss: 2.599978788390297

Epoch: 6| Step: 5
Training loss: 3.6232045429810227
Validation loss: 2.6029931641434083

Epoch: 6| Step: 6
Training loss: 3.0888204121794276
Validation loss: 2.6046530707806066

Epoch: 6| Step: 7
Training loss: 2.3268422939103504
Validation loss: 2.601885543130731

Epoch: 6| Step: 8
Training loss: 3.0646093461216126
Validation loss: 2.598133741940015

Epoch: 6| Step: 9
Training loss: 3.1465030151042375
Validation loss: 2.604839340126578

Epoch: 6| Step: 10
Training loss: 2.673993971413412
Validation loss: 2.6029657448892265

Epoch: 6| Step: 11
Training loss: 3.007638108783735
Validation loss: 2.607880352239091

Epoch: 6| Step: 12
Training loss: 2.6253471145009857
Validation loss: 2.6087632287691997

Epoch: 6| Step: 13
Training loss: 2.3526801308109433
Validation loss: 2.612933248840896

Epoch: 106| Step: 0
Training loss: 2.4290849238972445
Validation loss: 2.609728397172298

Epoch: 6| Step: 1
Training loss: 3.3273950770320657
Validation loss: 2.6194064533280725

Epoch: 6| Step: 2
Training loss: 3.1326258882037505
Validation loss: 2.610855394890658

Epoch: 6| Step: 3
Training loss: 2.8669759480026653
Validation loss: 2.609372809084161

Epoch: 6| Step: 4
Training loss: 3.717226373470022
Validation loss: 2.5975606733749137

Epoch: 6| Step: 5
Training loss: 2.526800129602359
Validation loss: 2.589774051445371

Epoch: 6| Step: 6
Training loss: 2.7868279232780777
Validation loss: 2.5936962348949004

Epoch: 6| Step: 7
Training loss: 2.7381508179862144
Validation loss: 2.589104986003416

Epoch: 6| Step: 8
Training loss: 2.927851964053696
Validation loss: 2.585072685719784

Epoch: 6| Step: 9
Training loss: 2.755150133947259
Validation loss: 2.587489077867154

Epoch: 6| Step: 10
Training loss: 3.0604879815448816
Validation loss: 2.5922411243567636

Epoch: 6| Step: 11
Training loss: 2.670983952298759
Validation loss: 2.5812900573972084

Epoch: 6| Step: 12
Training loss: 2.8712470396472516
Validation loss: 2.586721905749726

Epoch: 6| Step: 13
Training loss: 3.568877150747342
Validation loss: 2.588959562850453

Epoch: 107| Step: 0
Training loss: 3.0299741281846386
Validation loss: 2.5861553658879775

Epoch: 6| Step: 1
Training loss: 3.1713905904157467
Validation loss: 2.5903864763159707

Epoch: 6| Step: 2
Training loss: 3.3901912569991097
Validation loss: 2.591939484762987

Epoch: 6| Step: 3
Training loss: 2.731579643276889
Validation loss: 2.6017083701113313

Epoch: 6| Step: 4
Training loss: 2.297864220840081
Validation loss: 2.6115001336160475

Epoch: 6| Step: 5
Training loss: 2.4365048455578244
Validation loss: 2.6241709888966755

Epoch: 6| Step: 6
Training loss: 3.4687315794309597
Validation loss: 2.634632825904546

Epoch: 6| Step: 7
Training loss: 3.226982181770585
Validation loss: 2.6277675327661894

Epoch: 6| Step: 8
Training loss: 3.2962585162102314
Validation loss: 2.5984917007087676

Epoch: 6| Step: 9
Training loss: 2.74550504058114
Validation loss: 2.588883892070465

Epoch: 6| Step: 10
Training loss: 2.8649574359175287
Validation loss: 2.5810467811930113

Epoch: 6| Step: 11
Training loss: 3.2231512995710823
Validation loss: 2.5760359090049194

Epoch: 6| Step: 12
Training loss: 2.3791884582198533
Validation loss: 2.5786263245390026

Epoch: 6| Step: 13
Training loss: 2.564459354018282
Validation loss: 2.5772307813086943

Epoch: 108| Step: 0
Training loss: 3.304192255665875
Validation loss: 2.579927365205175

Epoch: 6| Step: 1
Training loss: 2.8735981716354093
Validation loss: 2.5886237484134846

Epoch: 6| Step: 2
Training loss: 3.016993869156973
Validation loss: 2.5934065240360957

Epoch: 6| Step: 3
Training loss: 2.2124631760113656
Validation loss: 2.588751645345869

Epoch: 6| Step: 4
Training loss: 3.1469020080922694
Validation loss: 2.5871607739155538

Epoch: 6| Step: 5
Training loss: 3.1366888023457524
Validation loss: 2.5875215852588203

Epoch: 6| Step: 6
Training loss: 2.947540007522759
Validation loss: 2.5800634460759486

Epoch: 6| Step: 7
Training loss: 2.832647427579827
Validation loss: 2.581940115148014

Epoch: 6| Step: 8
Training loss: 2.803090270304644
Validation loss: 2.5782338725669094

Epoch: 6| Step: 9
Training loss: 2.3411753436567055
Validation loss: 2.5802174469133514

Epoch: 6| Step: 10
Training loss: 3.445004680835218
Validation loss: 2.582875939351846

Epoch: 6| Step: 11
Training loss: 2.9855639900296915
Validation loss: 2.588012649838562

Epoch: 6| Step: 12
Training loss: 2.9600123266014977
Validation loss: 2.590261515951645

Epoch: 6| Step: 13
Training loss: 3.3283689884064596
Validation loss: 2.5933616012316723

Epoch: 109| Step: 0
Training loss: 3.3391709391756446
Validation loss: 2.5986602182808296

Epoch: 6| Step: 1
Training loss: 2.676107612253674
Validation loss: 2.5922969321464353

Epoch: 6| Step: 2
Training loss: 2.8034207769568487
Validation loss: 2.597323740334243

Epoch: 6| Step: 3
Training loss: 2.2134290479546865
Validation loss: 2.600629069549805

Epoch: 6| Step: 4
Training loss: 3.261985831832756
Validation loss: 2.5927417523689544

Epoch: 6| Step: 5
Training loss: 3.4130455615011663
Validation loss: 2.5985908824770934

Epoch: 6| Step: 6
Training loss: 2.8928967595961885
Validation loss: 2.6014576951511694

Epoch: 6| Step: 7
Training loss: 2.516097504210797
Validation loss: 2.5982320306078273

Epoch: 6| Step: 8
Training loss: 3.2086509118051665
Validation loss: 2.593803172944666

Epoch: 6| Step: 9
Training loss: 3.0372352892910106
Validation loss: 2.592714723049262

Epoch: 6| Step: 10
Training loss: 3.166847039824472
Validation loss: 2.5772327926455834

Epoch: 6| Step: 11
Training loss: 2.8873531485862407
Validation loss: 2.5742937011403613

Epoch: 6| Step: 12
Training loss: 2.685547762783944
Validation loss: 2.5735013676962315

Epoch: 6| Step: 13
Training loss: 2.736913842977271
Validation loss: 2.5721249284917596

Epoch: 110| Step: 0
Training loss: 2.7432097787330663
Validation loss: 2.575638228954289

Epoch: 6| Step: 1
Training loss: 3.390315450434456
Validation loss: 2.572860576338255

Epoch: 6| Step: 2
Training loss: 2.6914059842445894
Validation loss: 2.572410584207892

Epoch: 6| Step: 3
Training loss: 2.823277486753988
Validation loss: 2.5713940770462242

Epoch: 6| Step: 4
Training loss: 2.9323386442081354
Validation loss: 2.571822368451261

Epoch: 6| Step: 5
Training loss: 3.170355973338115
Validation loss: 2.569937444645147

Epoch: 6| Step: 6
Training loss: 2.3761401200512537
Validation loss: 2.569523567800292

Epoch: 6| Step: 7
Training loss: 2.5932814393167276
Validation loss: 2.5715298986711472

Epoch: 6| Step: 8
Training loss: 3.2383746052021474
Validation loss: 2.5794533095361776

Epoch: 6| Step: 9
Training loss: 3.4788714681480446
Validation loss: 2.5974830127418667

Epoch: 6| Step: 10
Training loss: 2.5245772583854764
Validation loss: 2.622520500433079

Epoch: 6| Step: 11
Training loss: 3.2281023466011476
Validation loss: 2.6332605428073403

Epoch: 6| Step: 12
Training loss: 2.954800892171574
Validation loss: 2.645180771356033

Epoch: 6| Step: 13
Training loss: 2.943364235127872
Validation loss: 2.645828888178599

Epoch: 111| Step: 0
Training loss: 2.750961569087425
Validation loss: 2.646559149577997

Epoch: 6| Step: 1
Training loss: 2.41039681741053
Validation loss: 2.6388451255432233

Epoch: 6| Step: 2
Training loss: 2.9928296548001803
Validation loss: 2.6529769681654813

Epoch: 6| Step: 3
Training loss: 2.9099945228236717
Validation loss: 2.6350508830045243

Epoch: 6| Step: 4
Training loss: 2.943321627733651
Validation loss: 2.6216612021684838

Epoch: 6| Step: 5
Training loss: 3.2975567298156583
Validation loss: 2.61874491905757

Epoch: 6| Step: 6
Training loss: 3.296969010156247
Validation loss: 2.6113392853762805

Epoch: 6| Step: 7
Training loss: 2.9753502006534154
Validation loss: 2.6034440847424087

Epoch: 6| Step: 8
Training loss: 2.946873097100559
Validation loss: 2.60114214155981

Epoch: 6| Step: 9
Training loss: 2.7619271422326594
Validation loss: 2.6029087810562737

Epoch: 6| Step: 10
Training loss: 2.6294360144272924
Validation loss: 2.6026017022936268

Epoch: 6| Step: 11
Training loss: 3.7495858281617536
Validation loss: 2.604579343194589

Epoch: 6| Step: 12
Training loss: 2.7978996232783118
Validation loss: 2.6015833603449026

Epoch: 6| Step: 13
Training loss: 3.034325995476783
Validation loss: 2.600390041129759

Epoch: 112| Step: 0
Training loss: 3.42573281126673
Validation loss: 2.599864836067328

Epoch: 6| Step: 1
Training loss: 2.592923044030031
Validation loss: 2.6034392192796587

Epoch: 6| Step: 2
Training loss: 3.0630993937706568
Validation loss: 2.596372769549011

Epoch: 6| Step: 3
Training loss: 2.496429659548705
Validation loss: 2.595642261474744

Epoch: 6| Step: 4
Training loss: 3.2569409126166793
Validation loss: 2.602197193918451

Epoch: 6| Step: 5
Training loss: 2.594227666418501
Validation loss: 2.6020201081312893

Epoch: 6| Step: 6
Training loss: 2.85449101816389
Validation loss: 2.601636868843108

Epoch: 6| Step: 7
Training loss: 2.7817390954805066
Validation loss: 2.604219356537068

Epoch: 6| Step: 8
Training loss: 2.6257070769820783
Validation loss: 2.6062427437532425

Epoch: 6| Step: 9
Training loss: 3.3817184828812907
Validation loss: 2.6088919430403816

Epoch: 6| Step: 10
Training loss: 3.0080756530581945
Validation loss: 2.6042341798624253

Epoch: 6| Step: 11
Training loss: 3.511767088967918
Validation loss: 2.609825550756172

Epoch: 6| Step: 12
Training loss: 2.742510915089449
Validation loss: 2.5959133264716687

Epoch: 6| Step: 13
Training loss: 2.5997650994046597
Validation loss: 2.59357333678149

Epoch: 113| Step: 0
Training loss: 3.2614067613700612
Validation loss: 2.590330845099357

Epoch: 6| Step: 1
Training loss: 3.384740548720584
Validation loss: 2.587168377148368

Epoch: 6| Step: 2
Training loss: 2.360970671223168
Validation loss: 2.5813039124742856

Epoch: 6| Step: 3
Training loss: 2.208832726302937
Validation loss: 2.576009420938614

Epoch: 6| Step: 4
Training loss: 3.228978174102161
Validation loss: 2.582479193483834

Epoch: 6| Step: 5
Training loss: 2.5168097886910665
Validation loss: 2.5686399332414918

Epoch: 6| Step: 6
Training loss: 3.083088701870823
Validation loss: 2.5710475087772244

Epoch: 6| Step: 7
Training loss: 2.9012776158443057
Validation loss: 2.5630258240283914

Epoch: 6| Step: 8
Training loss: 3.2160511739085003
Validation loss: 2.5622119876768745

Epoch: 6| Step: 9
Training loss: 3.0995819917465597
Validation loss: 2.561143153234733

Epoch: 6| Step: 10
Training loss: 3.0640815232390093
Validation loss: 2.5628020325909326

Epoch: 6| Step: 11
Training loss: 2.9430985363645195
Validation loss: 2.561847078352096

Epoch: 6| Step: 12
Training loss: 2.9963779836859974
Validation loss: 2.559720074905168

Epoch: 6| Step: 13
Training loss: 2.2032322417867753
Validation loss: 2.56478650966382

Epoch: 114| Step: 0
Training loss: 2.7830225407423983
Validation loss: 2.567480299343732

Epoch: 6| Step: 1
Training loss: 3.259378985130968
Validation loss: 2.5766163757168328

Epoch: 6| Step: 2
Training loss: 3.0189494254698808
Validation loss: 2.5799909772903553

Epoch: 6| Step: 3
Training loss: 3.0555165914497993
Validation loss: 2.582736102748916

Epoch: 6| Step: 4
Training loss: 2.4677883158311875
Validation loss: 2.580426503603475

Epoch: 6| Step: 5
Training loss: 2.4567094601234314
Validation loss: 2.581705554729195

Epoch: 6| Step: 6
Training loss: 2.9194209763196364
Validation loss: 2.577583305301935

Epoch: 6| Step: 7
Training loss: 2.8056576041954906
Validation loss: 2.6050281509107482

Epoch: 6| Step: 8
Training loss: 2.4246652588412365
Validation loss: 2.5949702085441886

Epoch: 6| Step: 9
Training loss: 2.9963813255790406
Validation loss: 2.5913472576799883

Epoch: 6| Step: 10
Training loss: 3.0935634980677458
Validation loss: 2.579890900604325

Epoch: 6| Step: 11
Training loss: 3.2200442184350138
Validation loss: 2.5720594663011624

Epoch: 6| Step: 12
Training loss: 3.3321875192326855
Validation loss: 2.5710656283620668

Epoch: 6| Step: 13
Training loss: 3.0391906868149543
Validation loss: 2.5579889039244064

Epoch: 115| Step: 0
Training loss: 2.9858696674844354
Validation loss: 2.5572572625658787

Epoch: 6| Step: 1
Training loss: 2.54802485995539
Validation loss: 2.560349899726172

Epoch: 6| Step: 2
Training loss: 3.0693482105326533
Validation loss: 2.556514059288587

Epoch: 6| Step: 3
Training loss: 2.5424773273188532
Validation loss: 2.557718443407993

Epoch: 6| Step: 4
Training loss: 2.68554882812429
Validation loss: 2.5613963854249797

Epoch: 6| Step: 5
Training loss: 2.7152678892492697
Validation loss: 2.56536886722234

Epoch: 6| Step: 6
Training loss: 2.9881625282789015
Validation loss: 2.56558383429346

Epoch: 6| Step: 7
Training loss: 2.8563989045375404
Validation loss: 2.5650176489313448

Epoch: 6| Step: 8
Training loss: 3.2606430381376863
Validation loss: 2.5662284396526256

Epoch: 6| Step: 9
Training loss: 2.4422041664848373
Validation loss: 2.5757711056604053

Epoch: 6| Step: 10
Training loss: 2.8305973606019417
Validation loss: 2.5719638844041377

Epoch: 6| Step: 11
Training loss: 3.608405441256735
Validation loss: 2.5790653327401722

Epoch: 6| Step: 12
Training loss: 3.3948001030794384
Validation loss: 2.5824792599950843

Epoch: 6| Step: 13
Training loss: 2.6016847507288987
Validation loss: 2.5635986754069475

Epoch: 116| Step: 0
Training loss: 3.2785438640918647
Validation loss: 2.571437896145817

Epoch: 6| Step: 1
Training loss: 2.750783461895145
Validation loss: 2.5621749767845414

Epoch: 6| Step: 2
Training loss: 2.2998880359100458
Validation loss: 2.5652924256144076

Epoch: 6| Step: 3
Training loss: 3.52292211446824
Validation loss: 2.568420002689356

Epoch: 6| Step: 4
Training loss: 2.921109838816351
Validation loss: 2.5758761534498

Epoch: 6| Step: 5
Training loss: 2.724604387176214
Validation loss: 2.570538184722572

Epoch: 6| Step: 6
Training loss: 3.0793657464766557
Validation loss: 2.5777469222302845

Epoch: 6| Step: 7
Training loss: 2.6215052274586013
Validation loss: 2.568862260046575

Epoch: 6| Step: 8
Training loss: 2.5555605082072304
Validation loss: 2.5651016464375096

Epoch: 6| Step: 9
Training loss: 2.807842637008071
Validation loss: 2.559589322111309

Epoch: 6| Step: 10
Training loss: 2.6737165741260056
Validation loss: 2.561946944274501

Epoch: 6| Step: 11
Training loss: 3.249533106205443
Validation loss: 2.566102973231418

Epoch: 6| Step: 12
Training loss: 3.4339797982280955
Validation loss: 2.57484093423774

Epoch: 6| Step: 13
Training loss: 2.4529716297970827
Validation loss: 2.5695192038108727

Epoch: 117| Step: 0
Training loss: 2.864664823355587
Validation loss: 2.5600938863195433

Epoch: 6| Step: 1
Training loss: 2.364761065778925
Validation loss: 2.556612222289174

Epoch: 6| Step: 2
Training loss: 3.275970862532676
Validation loss: 2.557417515581418

Epoch: 6| Step: 3
Training loss: 2.8183389875767717
Validation loss: 2.5561070565679493

Epoch: 6| Step: 4
Training loss: 2.602025812723257
Validation loss: 2.5593603255011375

Epoch: 6| Step: 5
Training loss: 2.6517604810166473
Validation loss: 2.551698472765502

Epoch: 6| Step: 6
Training loss: 2.270053823059846
Validation loss: 2.5501435459212733

Epoch: 6| Step: 7
Training loss: 3.2545184490309786
Validation loss: 2.551757503065711

Epoch: 6| Step: 8
Training loss: 3.430975530934616
Validation loss: 2.554591213926968

Epoch: 6| Step: 9
Training loss: 2.9036763598743347
Validation loss: 2.5617856246216855

Epoch: 6| Step: 10
Training loss: 2.434779091278639
Validation loss: 2.55992057268496

Epoch: 6| Step: 11
Training loss: 2.890473727830242
Validation loss: 2.56768418087531

Epoch: 6| Step: 12
Training loss: 3.880529826455247
Validation loss: 2.570249431360101

Epoch: 6| Step: 13
Training loss: 2.7401569379984134
Validation loss: 2.5743534327332007

Epoch: 118| Step: 0
Training loss: 2.8832499681302597
Validation loss: 2.5812382619604257

Epoch: 6| Step: 1
Training loss: 2.9101603463163284
Validation loss: 2.5671026072058454

Epoch: 6| Step: 2
Training loss: 2.6912269477193593
Validation loss: 2.559376296116277

Epoch: 6| Step: 3
Training loss: 3.243657305207048
Validation loss: 2.5530705742165924

Epoch: 6| Step: 4
Training loss: 2.95859485240399
Validation loss: 2.552077134714809

Epoch: 6| Step: 5
Training loss: 3.418577094299675
Validation loss: 2.558167856191861

Epoch: 6| Step: 6
Training loss: 2.8410855061635365
Validation loss: 2.5476000793185496

Epoch: 6| Step: 7
Training loss: 2.0998496410492464
Validation loss: 2.552874329575667

Epoch: 6| Step: 8
Training loss: 2.781149358750132
Validation loss: 2.554143345871613

Epoch: 6| Step: 9
Training loss: 3.1641648264221462
Validation loss: 2.550288605529055

Epoch: 6| Step: 10
Training loss: 2.476326531080159
Validation loss: 2.550580874070754

Epoch: 6| Step: 11
Training loss: 3.180652218996602
Validation loss: 2.5531378115589116

Epoch: 6| Step: 12
Training loss: 3.2168569090197203
Validation loss: 2.553467865490591

Epoch: 6| Step: 13
Training loss: 2.7839904314074015
Validation loss: 2.5531375856333205

Epoch: 119| Step: 0
Training loss: 2.5250306193695278
Validation loss: 2.5587335934873363

Epoch: 6| Step: 1
Training loss: 2.0689760897081277
Validation loss: 2.5578576371767054

Epoch: 6| Step: 2
Training loss: 2.256624641909925
Validation loss: 2.563020216677506

Epoch: 6| Step: 3
Training loss: 2.445137968324705
Validation loss: 2.567111677940567

Epoch: 6| Step: 4
Training loss: 3.08671587048635
Validation loss: 2.5711041883918555

Epoch: 6| Step: 5
Training loss: 2.3193747940824063
Validation loss: 2.5764035779504426

Epoch: 6| Step: 6
Training loss: 3.0246581144469125
Validation loss: 2.594614307215765

Epoch: 6| Step: 7
Training loss: 3.478023881976113
Validation loss: 2.593050630536963

Epoch: 6| Step: 8
Training loss: 3.5971354584967887
Validation loss: 2.578896664023333

Epoch: 6| Step: 9
Training loss: 3.438321102217349
Validation loss: 2.5781988168778125

Epoch: 6| Step: 10
Training loss: 2.816864357355401
Validation loss: 2.55951599167868

Epoch: 6| Step: 11
Training loss: 3.350923632929522
Validation loss: 2.553986945699158

Epoch: 6| Step: 12
Training loss: 3.363196182504333
Validation loss: 2.5448762988143394

Epoch: 6| Step: 13
Training loss: 1.952370948189902
Validation loss: 2.5481328172773146

Epoch: 120| Step: 0
Training loss: 2.973696152086094
Validation loss: 2.552650130220987

Epoch: 6| Step: 1
Training loss: 2.9305662744535983
Validation loss: 2.5555639340024228

Epoch: 6| Step: 2
Training loss: 2.9413932810139056
Validation loss: 2.5569309152009336

Epoch: 6| Step: 3
Training loss: 3.114302062195433
Validation loss: 2.5540656719432806

Epoch: 6| Step: 4
Training loss: 3.131529585792204
Validation loss: 2.5529829815698677

Epoch: 6| Step: 5
Training loss: 3.1613079372540582
Validation loss: 2.551603126844215

Epoch: 6| Step: 6
Training loss: 2.6039331763815574
Validation loss: 2.5486380829081083

Epoch: 6| Step: 7
Training loss: 2.7055371056914814
Validation loss: 2.5468884277795043

Epoch: 6| Step: 8
Training loss: 3.149809810406946
Validation loss: 2.5494110804900094

Epoch: 6| Step: 9
Training loss: 2.3021346096582467
Validation loss: 2.556116566496426

Epoch: 6| Step: 10
Training loss: 3.544491946208692
Validation loss: 2.5607691846407734

Epoch: 6| Step: 11
Training loss: 2.622131687916462
Validation loss: 2.5553996040171056

Epoch: 6| Step: 12
Training loss: 2.887278501263753
Validation loss: 2.5534137009884996

Epoch: 6| Step: 13
Training loss: 2.449319499740755
Validation loss: 2.5504966003764693

Epoch: 121| Step: 0
Training loss: 2.346883586354809
Validation loss: 2.553206600453074

Epoch: 6| Step: 1
Training loss: 2.91099308962118
Validation loss: 2.5478282206347362

Epoch: 6| Step: 2
Training loss: 2.8328908312951513
Validation loss: 2.5514325040111996

Epoch: 6| Step: 3
Training loss: 2.9915815491818494
Validation loss: 2.5500459180699346

Epoch: 6| Step: 4
Training loss: 3.4020914713444332
Validation loss: 2.5470631153303405

Epoch: 6| Step: 5
Training loss: 2.6286102173591064
Validation loss: 2.547453371176106

Epoch: 6| Step: 6
Training loss: 2.5791058148511894
Validation loss: 2.5526259373904914

Epoch: 6| Step: 7
Training loss: 3.155537742092853
Validation loss: 2.5513214397139636

Epoch: 6| Step: 8
Training loss: 2.896053186939852
Validation loss: 2.5566644479377474

Epoch: 6| Step: 9
Training loss: 2.5091541539892375
Validation loss: 2.5661199998210966

Epoch: 6| Step: 10
Training loss: 3.1746379675926453
Validation loss: 2.5696227522773487

Epoch: 6| Step: 11
Training loss: 3.0091321552093135
Validation loss: 2.572119464568629

Epoch: 6| Step: 12
Training loss: 3.111952283841566
Validation loss: 2.5764734780039653

Epoch: 6| Step: 13
Training loss: 3.2603875464620766
Validation loss: 2.564882868783128

Epoch: 122| Step: 0
Training loss: 2.8367908549514764
Validation loss: 2.5535087574275606

Epoch: 6| Step: 1
Training loss: 3.0305999373432004
Validation loss: 2.555689897754252

Epoch: 6| Step: 2
Training loss: 2.6108114891303247
Validation loss: 2.545563787645325

Epoch: 6| Step: 3
Training loss: 2.6094837280280676
Validation loss: 2.545000699334476

Epoch: 6| Step: 4
Training loss: 2.750670438017165
Validation loss: 2.543865436604283

Epoch: 6| Step: 5
Training loss: 2.8848869489340276
Validation loss: 2.541159902236407

Epoch: 6| Step: 6
Training loss: 2.9731821805512624
Validation loss: 2.540873364555512

Epoch: 6| Step: 7
Training loss: 3.25283865570802
Validation loss: 2.5435852610997425

Epoch: 6| Step: 8
Training loss: 3.14755047213057
Validation loss: 2.542022533575279

Epoch: 6| Step: 9
Training loss: 2.8267706056894575
Validation loss: 2.540756877405808

Epoch: 6| Step: 10
Training loss: 3.3195799973253513
Validation loss: 2.5448271072894575

Epoch: 6| Step: 11
Training loss: 2.777848381628691
Validation loss: 2.5460499888625905

Epoch: 6| Step: 12
Training loss: 2.759091175382703
Validation loss: 2.549502723016296

Epoch: 6| Step: 13
Training loss: 2.854131508121063
Validation loss: 2.547986808894484

Epoch: 123| Step: 0
Training loss: 3.257842066056635
Validation loss: 2.5483875716642386

Epoch: 6| Step: 1
Training loss: 2.642363658697165
Validation loss: 2.556763413332511

Epoch: 6| Step: 2
Training loss: 2.6518556935158024
Validation loss: 2.5540854647913536

Epoch: 6| Step: 3
Training loss: 2.7719202323930165
Validation loss: 2.5638339504617416

Epoch: 6| Step: 4
Training loss: 2.854256807189346
Validation loss: 2.5583493131385886

Epoch: 6| Step: 5
Training loss: 2.8150579899833312
Validation loss: 2.563194705966985

Epoch: 6| Step: 6
Training loss: 2.850721930369918
Validation loss: 2.5491962596206212

Epoch: 6| Step: 7
Training loss: 3.0488595612669034
Validation loss: 2.5456115076867007

Epoch: 6| Step: 8
Training loss: 2.8200752813693346
Validation loss: 2.541152780777978

Epoch: 6| Step: 9
Training loss: 2.831052161035006
Validation loss: 2.5407580024479954

Epoch: 6| Step: 10
Training loss: 3.0952773514378675
Validation loss: 2.537790747008537

Epoch: 6| Step: 11
Training loss: 3.1098479098208
Validation loss: 2.5475986463521587

Epoch: 6| Step: 12
Training loss: 3.0092842761790384
Validation loss: 2.546158950194826

Epoch: 6| Step: 13
Training loss: 2.8962542184561086
Validation loss: 2.552695874923575

Epoch: 124| Step: 0
Training loss: 2.2541459351136854
Validation loss: 2.572609097428906

Epoch: 6| Step: 1
Training loss: 2.951839429587322
Validation loss: 2.603551328418694

Epoch: 6| Step: 2
Training loss: 2.9817698027540978
Validation loss: 2.635724311202673

Epoch: 6| Step: 3
Training loss: 2.940423363026659
Validation loss: 2.650448932299996

Epoch: 6| Step: 4
Training loss: 3.653598704434026
Validation loss: 2.655669919299943

Epoch: 6| Step: 5
Training loss: 2.8545940849500027
Validation loss: 2.6436347039701715

Epoch: 6| Step: 6
Training loss: 2.7836275546719
Validation loss: 2.628875584504184

Epoch: 6| Step: 7
Training loss: 2.942971834971505
Validation loss: 2.618497667689571

Epoch: 6| Step: 8
Training loss: 2.7998522038281326
Validation loss: 2.6035667099138213

Epoch: 6| Step: 9
Training loss: 2.8378261025872233
Validation loss: 2.6007330768139947

Epoch: 6| Step: 10
Training loss: 3.550746334227397
Validation loss: 2.595681511224255

Epoch: 6| Step: 11
Training loss: 2.6431597219781198
Validation loss: 2.5993022062782973

Epoch: 6| Step: 12
Training loss: 3.4178006376067773
Validation loss: 2.5939443203875236

Epoch: 6| Step: 13
Training loss: 1.9676802620232556
Validation loss: 2.596888679584953

Epoch: 125| Step: 0
Training loss: 3.4896438517470707
Validation loss: 2.596786428645767

Epoch: 6| Step: 1
Training loss: 3.082121911788367
Validation loss: 2.6014611373715955

Epoch: 6| Step: 2
Training loss: 2.9821080090760312
Validation loss: 2.590455203381934

Epoch: 6| Step: 3
Training loss: 3.0793592428056265
Validation loss: 2.600987216161819

Epoch: 6| Step: 4
Training loss: 3.0529549214558354
Validation loss: 2.59226069099278

Epoch: 6| Step: 5
Training loss: 2.7559349866155514
Validation loss: 2.5985651254940016

Epoch: 6| Step: 6
Training loss: 2.9720342840114338
Validation loss: 2.6004031275051225

Epoch: 6| Step: 7
Training loss: 2.687883571487439
Validation loss: 2.6011097216011914

Epoch: 6| Step: 8
Training loss: 2.426284320162088
Validation loss: 2.5907690752049644

Epoch: 6| Step: 9
Training loss: 2.871693575735392
Validation loss: 2.604800285452931

Epoch: 6| Step: 10
Training loss: 2.14327482512467
Validation loss: 2.597212787715083

Epoch: 6| Step: 11
Training loss: 3.364193038427594
Validation loss: 2.5959986647602413

Epoch: 6| Step: 12
Training loss: 3.0052584021951994
Validation loss: 2.5734827387824004

Epoch: 6| Step: 13
Training loss: 3.230442771207513
Validation loss: 2.5655327724889783

Epoch: 126| Step: 0
Training loss: 3.028347867749917
Validation loss: 2.575156650463527

Epoch: 6| Step: 1
Training loss: 2.655793633245568
Validation loss: 2.5553713058943055

Epoch: 6| Step: 2
Training loss: 2.831103363618708
Validation loss: 2.5450413294292566

Epoch: 6| Step: 3
Training loss: 2.45959300295259
Validation loss: 2.5472776113738003

Epoch: 6| Step: 4
Training loss: 2.8696868563492113
Validation loss: 2.5387152311436294

Epoch: 6| Step: 5
Training loss: 3.325647856044676
Validation loss: 2.5398428415269767

Epoch: 6| Step: 6
Training loss: 2.9203970532042827
Validation loss: 2.5418944714830256

Epoch: 6| Step: 7
Training loss: 2.7447950349867902
Validation loss: 2.542639241838834

Epoch: 6| Step: 8
Training loss: 3.144341694111989
Validation loss: 2.53971185425037

Epoch: 6| Step: 9
Training loss: 2.677900335621087
Validation loss: 2.542010245929287

Epoch: 6| Step: 10
Training loss: 2.7093443132926445
Validation loss: 2.5439690799849553

Epoch: 6| Step: 11
Training loss: 3.2867443768313978
Validation loss: 2.5491702529588127

Epoch: 6| Step: 12
Training loss: 3.37571426180353
Validation loss: 2.5688407702269807

Epoch: 6| Step: 13
Training loss: 2.092662130111309
Validation loss: 2.574685093354833

Epoch: 127| Step: 0
Training loss: 2.8386851049923054
Validation loss: 2.5790727491072714

Epoch: 6| Step: 1
Training loss: 2.4426821861141943
Validation loss: 2.583571800779386

Epoch: 6| Step: 2
Training loss: 2.7860082149891117
Validation loss: 2.601459917369572

Epoch: 6| Step: 3
Training loss: 2.9472250155108997
Validation loss: 2.6350543864145917

Epoch: 6| Step: 4
Training loss: 3.2399376842016214
Validation loss: 2.6456847839925635

Epoch: 6| Step: 5
Training loss: 3.017271867043691
Validation loss: 2.6662107399633594

Epoch: 6| Step: 6
Training loss: 3.2031547731085803
Validation loss: 2.6507952743021037

Epoch: 6| Step: 7
Training loss: 2.5463746872468636
Validation loss: 2.6476636709499357

Epoch: 6| Step: 8
Training loss: 2.966042337908978
Validation loss: 2.618611971262385

Epoch: 6| Step: 9
Training loss: 3.135854561644578
Validation loss: 2.553967920988787

Epoch: 6| Step: 10
Training loss: 2.784216509588582
Validation loss: 2.5412429541790726

Epoch: 6| Step: 11
Training loss: 2.9776500407224904
Validation loss: 2.542916155364281

Epoch: 6| Step: 12
Training loss: 2.8170694319050043
Validation loss: 2.5473621717049117

Epoch: 6| Step: 13
Training loss: 3.3977398035613438
Validation loss: 2.554051359447464

Epoch: 128| Step: 0
Training loss: 3.2191650715573084
Validation loss: 2.55752539518438

Epoch: 6| Step: 1
Training loss: 3.220703125
Validation loss: 2.5641729984753625

Epoch: 6| Step: 2
Training loss: 2.734613375491228
Validation loss: 2.5577192051675985

Epoch: 6| Step: 3
Training loss: 3.434285828645023
Validation loss: 2.5540232421206497

Epoch: 6| Step: 4
Training loss: 2.5950148841857357
Validation loss: 2.5555587105406836

Epoch: 6| Step: 5
Training loss: 2.6352840787281635
Validation loss: 2.553209307469219

Epoch: 6| Step: 6
Training loss: 3.121150277667856
Validation loss: 2.5531140541184127

Epoch: 6| Step: 7
Training loss: 2.3048875624898093
Validation loss: 2.5506509812538964

Epoch: 6| Step: 8
Training loss: 2.8050835204992235
Validation loss: 2.5490004700025475

Epoch: 6| Step: 9
Training loss: 3.5943577791510206
Validation loss: 2.5405959417990642

Epoch: 6| Step: 10
Training loss: 3.0225718439365195
Validation loss: 2.545910289496765

Epoch: 6| Step: 11
Training loss: 2.2669133173688745
Validation loss: 2.5486010318155294

Epoch: 6| Step: 12
Training loss: 2.8378785271593476
Validation loss: 2.5533635685086766

Epoch: 6| Step: 13
Training loss: 3.1469901949302774
Validation loss: 2.550178558014327

Epoch: 129| Step: 0
Training loss: 2.649148581139996
Validation loss: 2.5548683672720007

Epoch: 6| Step: 1
Training loss: 2.8620272983232806
Validation loss: 2.5669984547389224

Epoch: 6| Step: 2
Training loss: 3.016076405000102
Validation loss: 2.581369745047901

Epoch: 6| Step: 3
Training loss: 2.904312308192855
Validation loss: 2.600344628707827

Epoch: 6| Step: 4
Training loss: 3.0821307302841667
Validation loss: 2.631874412733143

Epoch: 6| Step: 5
Training loss: 2.698668317526035
Validation loss: 2.6672421809817197

Epoch: 6| Step: 6
Training loss: 2.294254806641549
Validation loss: 2.707020323142266

Epoch: 6| Step: 7
Training loss: 2.593216622904478
Validation loss: 2.753906678218862

Epoch: 6| Step: 8
Training loss: 2.9584589828528394
Validation loss: 2.8074338078188346

Epoch: 6| Step: 9
Training loss: 3.9931012505759322
Validation loss: 2.7806721356958417

Epoch: 6| Step: 10
Training loss: 3.340062898283466
Validation loss: 2.7007776956743283

Epoch: 6| Step: 11
Training loss: 2.479429108221841
Validation loss: 2.6326075526736648

Epoch: 6| Step: 12
Training loss: 3.1045964773395873
Validation loss: 2.6031130372583693

Epoch: 6| Step: 13
Training loss: 3.179147435468017
Validation loss: 2.5743925250782542

Epoch: 130| Step: 0
Training loss: 3.046130906235778
Validation loss: 2.5626325495483586

Epoch: 6| Step: 1
Training loss: 2.9138235858411705
Validation loss: 2.5645133412086016

Epoch: 6| Step: 2
Training loss: 2.7520981500666175
Validation loss: 2.569805762700149

Epoch: 6| Step: 3
Training loss: 3.198567045762873
Validation loss: 2.5716018671874297

Epoch: 6| Step: 4
Training loss: 2.338135058787474
Validation loss: 2.5637646797493354

Epoch: 6| Step: 5
Training loss: 3.2123245250706094
Validation loss: 2.571679240740906

Epoch: 6| Step: 6
Training loss: 3.083275218793986
Validation loss: 2.578350336960948

Epoch: 6| Step: 7
Training loss: 2.5919148030937635
Validation loss: 2.5748501051544856

Epoch: 6| Step: 8
Training loss: 3.0325486065899367
Validation loss: 2.5792605358269998

Epoch: 6| Step: 9
Training loss: 3.14855669046839
Validation loss: 2.5913893261782803

Epoch: 6| Step: 10
Training loss: 2.8513695220446467
Validation loss: 2.6029881609389727

Epoch: 6| Step: 11
Training loss: 3.2461704286408355
Validation loss: 2.6067963463142236

Epoch: 6| Step: 12
Training loss: 2.8038856826584846
Validation loss: 2.6005794480134896

Epoch: 6| Step: 13
Training loss: 2.869493269363914
Validation loss: 2.604601503225876

Epoch: 131| Step: 0
Training loss: 2.750413516772456
Validation loss: 2.6074430414372847

Epoch: 6| Step: 1
Training loss: 2.8884023007983712
Validation loss: 2.6064298230774923

Epoch: 6| Step: 2
Training loss: 2.8335037928149105
Validation loss: 2.5960383939937732

Epoch: 6| Step: 3
Training loss: 3.1783510440945744
Validation loss: 2.588356684090064

Epoch: 6| Step: 4
Training loss: 3.245201382963962
Validation loss: 2.5813974433479463

Epoch: 6| Step: 5
Training loss: 3.0222850249191566
Validation loss: 2.57613645787652

Epoch: 6| Step: 6
Training loss: 2.674603948062535
Validation loss: 2.564231625630544

Epoch: 6| Step: 7
Training loss: 3.610521274877462
Validation loss: 2.55675670332346

Epoch: 6| Step: 8
Training loss: 3.186897669709862
Validation loss: 2.557640911130515

Epoch: 6| Step: 9
Training loss: 3.220495546960617
Validation loss: 2.5533722653576647

Epoch: 6| Step: 10
Training loss: 2.2729171734281044
Validation loss: 2.5547876588333502

Epoch: 6| Step: 11
Training loss: 2.3931415750761915
Validation loss: 2.5523165494342517

Epoch: 6| Step: 12
Training loss: 2.5885969702315563
Validation loss: 2.542907390494055

Epoch: 6| Step: 13
Training loss: 2.9513046870967257
Validation loss: 2.538179528720895

Epoch: 132| Step: 0
Training loss: 2.7661027226326507
Validation loss: 2.554012537942013

Epoch: 6| Step: 1
Training loss: 2.8481362857892174
Validation loss: 2.5529582104709387

Epoch: 6| Step: 2
Training loss: 2.426862736665332
Validation loss: 2.5505624622104848

Epoch: 6| Step: 3
Training loss: 2.8100939313454663
Validation loss: 2.548753579196486

Epoch: 6| Step: 4
Training loss: 2.587440722242615
Validation loss: 2.549617530583987

Epoch: 6| Step: 5
Training loss: 3.0837159477861866
Validation loss: 2.551686090053424

Epoch: 6| Step: 6
Training loss: 2.8042228972723744
Validation loss: 2.5545509063278833

Epoch: 6| Step: 7
Training loss: 2.907876164776081
Validation loss: 2.567638752126062

Epoch: 6| Step: 8
Training loss: 3.2510842202060157
Validation loss: 2.590458016951672

Epoch: 6| Step: 9
Training loss: 2.958435128479891
Validation loss: 2.57471712416234

Epoch: 6| Step: 10
Training loss: 2.963980608157251
Validation loss: 2.582814456924638

Epoch: 6| Step: 11
Training loss: 2.685018502709767
Validation loss: 2.581805305883257

Epoch: 6| Step: 12
Training loss: 3.387477415790794
Validation loss: 2.6093611618302854

Epoch: 6| Step: 13
Training loss: 3.24316538575515
Validation loss: 2.6007135532198724

Epoch: 133| Step: 0
Training loss: 2.725164541473907
Validation loss: 2.6102102611926052

Epoch: 6| Step: 1
Training loss: 3.164127151393886
Validation loss: 2.595751773114743

Epoch: 6| Step: 2
Training loss: 2.5227662129564
Validation loss: 2.5896063613715796

Epoch: 6| Step: 3
Training loss: 2.5259077423355207
Validation loss: 2.584615982084678

Epoch: 6| Step: 4
Training loss: 3.1081609608272616
Validation loss: 2.5731245553665136

Epoch: 6| Step: 5
Training loss: 3.4616363715320215
Validation loss: 2.5766994678037665

Epoch: 6| Step: 6
Training loss: 2.574316182123321
Validation loss: 2.5714731157840807

Epoch: 6| Step: 7
Training loss: 3.0629156959382353
Validation loss: 2.557229964449213

Epoch: 6| Step: 8
Training loss: 3.477565252156717
Validation loss: 2.5546727263626896

Epoch: 6| Step: 9
Training loss: 2.7380601736552257
Validation loss: 2.5483697576128956

Epoch: 6| Step: 10
Training loss: 2.9306944883979584
Validation loss: 2.5483761838843115

Epoch: 6| Step: 11
Training loss: 2.97986553682439
Validation loss: 2.5480017188929542

Epoch: 6| Step: 12
Training loss: 3.11734046656323
Validation loss: 2.5492829827799524

Epoch: 6| Step: 13
Training loss: 1.2689276096447255
Validation loss: 2.55178581815706

Epoch: 134| Step: 0
Training loss: 2.8237562631889683
Validation loss: 2.5489075496791056

Epoch: 6| Step: 1
Training loss: 2.661378733619743
Validation loss: 2.5461521588752403

Epoch: 6| Step: 2
Training loss: 2.762616347542618
Validation loss: 2.556636299184729

Epoch: 6| Step: 3
Training loss: 3.4626748436806887
Validation loss: 2.5523615759293947

Epoch: 6| Step: 4
Training loss: 2.875348774859739
Validation loss: 2.55911688148297

Epoch: 6| Step: 5
Training loss: 2.804447004372822
Validation loss: 2.560754644313389

Epoch: 6| Step: 6
Training loss: 2.8437615698275116
Validation loss: 2.565017545486906

Epoch: 6| Step: 7
Training loss: 2.8276726798325225
Validation loss: 2.57459739367505

Epoch: 6| Step: 8
Training loss: 2.9509909048583394
Validation loss: 2.594493513785179

Epoch: 6| Step: 9
Training loss: 2.8214010320081666
Validation loss: 2.6170359695443923

Epoch: 6| Step: 10
Training loss: 3.439326685282412
Validation loss: 2.600531091316149

Epoch: 6| Step: 11
Training loss: 3.0615531859100944
Validation loss: 2.6033585567357194

Epoch: 6| Step: 12
Training loss: 2.4977966135513228
Validation loss: 2.5997722131543775

Epoch: 6| Step: 13
Training loss: 2.5990470203462936
Validation loss: 2.5704434299120105

Epoch: 135| Step: 0
Training loss: 2.863320885106814
Validation loss: 2.563377102205185

Epoch: 6| Step: 1
Training loss: 2.8353272509204315
Validation loss: 2.5570277397878316

Epoch: 6| Step: 2
Training loss: 3.0121275232278135
Validation loss: 2.5518319500657127

Epoch: 6| Step: 3
Training loss: 2.5293408953396628
Validation loss: 2.5521444117905303

Epoch: 6| Step: 4
Training loss: 3.200419255448344
Validation loss: 2.5575983160908833

Epoch: 6| Step: 5
Training loss: 2.9231628191061123
Validation loss: 2.5513813589467342

Epoch: 6| Step: 6
Training loss: 2.6337947654450216
Validation loss: 2.5455153274830256

Epoch: 6| Step: 7
Training loss: 2.57353940112315
Validation loss: 2.5508520300602218

Epoch: 6| Step: 8
Training loss: 2.2281794515967666
Validation loss: 2.5448713364882383

Epoch: 6| Step: 9
Training loss: 3.302851173505796
Validation loss: 2.5497484674644717

Epoch: 6| Step: 10
Training loss: 2.6949805898445116
Validation loss: 2.550999149738709

Epoch: 6| Step: 11
Training loss: 3.5863278909908973
Validation loss: 2.544592401131403

Epoch: 6| Step: 12
Training loss: 3.180871241717319
Validation loss: 2.545864639370358

Epoch: 6| Step: 13
Training loss: 2.995857716878062
Validation loss: 2.541536321446399

Epoch: 136| Step: 0
Training loss: 2.9041366276402965
Validation loss: 2.5405116517256965

Epoch: 6| Step: 1
Training loss: 3.0030756125621654
Validation loss: 2.5425689056787775

Epoch: 6| Step: 2
Training loss: 2.739651368508716
Validation loss: 2.546169973338892

Epoch: 6| Step: 3
Training loss: 2.0472022806844348
Validation loss: 2.5474262115416737

Epoch: 6| Step: 4
Training loss: 3.0234445971028623
Validation loss: 2.551767497874734

Epoch: 6| Step: 5
Training loss: 3.500159123754456
Validation loss: 2.5595502986456413

Epoch: 6| Step: 6
Training loss: 2.3590609107730356
Validation loss: 2.5562362760389084

Epoch: 6| Step: 7
Training loss: 3.10939585616435
Validation loss: 2.5542724649559343

Epoch: 6| Step: 8
Training loss: 3.1675538944997523
Validation loss: 2.5509559443258154

Epoch: 6| Step: 9
Training loss: 3.334399974554285
Validation loss: 2.53991752470909

Epoch: 6| Step: 10
Training loss: 3.242232798064584
Validation loss: 2.538734122750681

Epoch: 6| Step: 11
Training loss: 1.7528649448350386
Validation loss: 2.5387151119850886

Epoch: 6| Step: 12
Training loss: 2.645035350541696
Validation loss: 2.5344727738479755

Epoch: 6| Step: 13
Training loss: 3.3199636478042494
Validation loss: 2.5384755536370482

Epoch: 137| Step: 0
Training loss: 2.7002719530262675
Validation loss: 2.551482881414889

Epoch: 6| Step: 1
Training loss: 2.491390471529587
Validation loss: 2.5592051467147354

Epoch: 6| Step: 2
Training loss: 2.6038002264971936
Validation loss: 2.570839874266703

Epoch: 6| Step: 3
Training loss: 3.1923774352776677
Validation loss: 2.590696671359862

Epoch: 6| Step: 4
Training loss: 2.8239655651608273
Validation loss: 2.5936489033631824

Epoch: 6| Step: 5
Training loss: 2.6806565025792763
Validation loss: 2.5785760399828046

Epoch: 6| Step: 6
Training loss: 2.6432318826796135
Validation loss: 2.5590776339270147

Epoch: 6| Step: 7
Training loss: 2.749376399687428
Validation loss: 2.529695459646062

Epoch: 6| Step: 8
Training loss: 3.5739407123756504
Validation loss: 2.5221212933045414

Epoch: 6| Step: 9
Training loss: 2.9905029016840077
Validation loss: 2.5205687296978634

Epoch: 6| Step: 10
Training loss: 3.1353169844656237
Validation loss: 2.5136975411386473

Epoch: 6| Step: 11
Training loss: 2.8107719198741434
Validation loss: 2.511377838795578

Epoch: 6| Step: 12
Training loss: 3.1623099288816885
Validation loss: 2.5150876004646414

Epoch: 6| Step: 13
Training loss: 2.7584082632653537
Validation loss: 2.517359129825124

Epoch: 138| Step: 0
Training loss: 2.4151444957778074
Validation loss: 2.513769573410151

Epoch: 6| Step: 1
Training loss: 2.5821663363809493
Validation loss: 2.514874327394326

Epoch: 6| Step: 2
Training loss: 3.2167135666770124
Validation loss: 2.518814786587067

Epoch: 6| Step: 3
Training loss: 2.9763776266201702
Validation loss: 2.5162019347653626

Epoch: 6| Step: 4
Training loss: 2.6690520604738635
Validation loss: 2.5210756086977684

Epoch: 6| Step: 5
Training loss: 3.0852340475915225
Validation loss: 2.5226280442859994

Epoch: 6| Step: 6
Training loss: 3.132097652622984
Validation loss: 2.5258233548917333

Epoch: 6| Step: 7
Training loss: 3.1498408443873323
Validation loss: 2.5343683890835385

Epoch: 6| Step: 8
Training loss: 3.1882867777074724
Validation loss: 2.552173953595674

Epoch: 6| Step: 9
Training loss: 2.7425686389328185
Validation loss: 2.558794486318592

Epoch: 6| Step: 10
Training loss: 2.6735937825311566
Validation loss: 2.553549776713541

Epoch: 6| Step: 11
Training loss: 2.6089475361530226
Validation loss: 2.565496492009661

Epoch: 6| Step: 12
Training loss: 2.854055323598534
Validation loss: 2.568393266394122

Epoch: 6| Step: 13
Training loss: 3.049452410460296
Validation loss: 2.5774276630564894

Epoch: 139| Step: 0
Training loss: 2.8318460338140765
Validation loss: 2.5721451734118577

Epoch: 6| Step: 1
Training loss: 2.7379325176641878
Validation loss: 2.5529717860028303

Epoch: 6| Step: 2
Training loss: 2.7135790177384282
Validation loss: 2.5561032323270867

Epoch: 6| Step: 3
Training loss: 2.7148770337157115
Validation loss: 2.5484052175926672

Epoch: 6| Step: 4
Training loss: 3.0777717813677468
Validation loss: 2.53835472976455

Epoch: 6| Step: 5
Training loss: 3.1115413001260546
Validation loss: 2.5385211467807745

Epoch: 6| Step: 6
Training loss: 3.1551289597648116
Validation loss: 2.5212122436548667

Epoch: 6| Step: 7
Training loss: 3.3452615619114954
Validation loss: 2.521415745545218

Epoch: 6| Step: 8
Training loss: 2.6879930265767604
Validation loss: 2.5147518435454166

Epoch: 6| Step: 9
Training loss: 2.891914698565519
Validation loss: 2.5146271037140506

Epoch: 6| Step: 10
Training loss: 2.734743627495982
Validation loss: 2.516206543034602

Epoch: 6| Step: 11
Training loss: 2.7070768718535705
Validation loss: 2.5114942564618103

Epoch: 6| Step: 12
Training loss: 2.568574729564515
Validation loss: 2.514323429872686

Epoch: 6| Step: 13
Training loss: 3.055208361773399
Validation loss: 2.5150668983007938

Epoch: 140| Step: 0
Training loss: 2.7489912610517013
Validation loss: 2.5184082133198764

Epoch: 6| Step: 1
Training loss: 2.9643118359831355
Validation loss: 2.5228126306145433

Epoch: 6| Step: 2
Training loss: 2.4651023862053068
Validation loss: 2.5269062047486495

Epoch: 6| Step: 3
Training loss: 2.5451709686889754
Validation loss: 2.5246823048752196

Epoch: 6| Step: 4
Training loss: 3.179955623485017
Validation loss: 2.5341011194040712

Epoch: 6| Step: 5
Training loss: 2.875458058894602
Validation loss: 2.5405780085333194

Epoch: 6| Step: 6
Training loss: 2.7150318547131143
Validation loss: 2.5374866365422033

Epoch: 6| Step: 7
Training loss: 3.072448608614257
Validation loss: 2.5363447265760906

Epoch: 6| Step: 8
Training loss: 2.333681580123395
Validation loss: 2.546054279298203

Epoch: 6| Step: 9
Training loss: 3.105548133075407
Validation loss: 2.5474434676242605

Epoch: 6| Step: 10
Training loss: 2.9048253330896294
Validation loss: 2.566635069940949

Epoch: 6| Step: 11
Training loss: 3.137934960843109
Validation loss: 2.57566357023427

Epoch: 6| Step: 12
Training loss: 3.207968422750945
Validation loss: 2.5657247066439846

Epoch: 6| Step: 13
Training loss: 3.0049865922930237
Validation loss: 2.5575422112418047

Epoch: 141| Step: 0
Training loss: 3.0408710501720413
Validation loss: 2.5359232220300756

Epoch: 6| Step: 1
Training loss: 3.385116955132682
Validation loss: 2.5222876480997707

Epoch: 6| Step: 2
Training loss: 2.609929008833831
Validation loss: 2.532280603127847

Epoch: 6| Step: 3
Training loss: 2.9911326648161687
Validation loss: 2.5287097584754763

Epoch: 6| Step: 4
Training loss: 3.3021937852230927
Validation loss: 2.5326512331109297

Epoch: 6| Step: 5
Training loss: 2.4411449078872214
Validation loss: 2.5343703767787353

Epoch: 6| Step: 6
Training loss: 2.9338216274052287
Validation loss: 2.528375715207047

Epoch: 6| Step: 7
Training loss: 2.9053005185187426
Validation loss: 2.5326928609724044

Epoch: 6| Step: 8
Training loss: 3.173088405383838
Validation loss: 2.5346519410650035

Epoch: 6| Step: 9
Training loss: 2.8446544843683585
Validation loss: 2.531661827709906

Epoch: 6| Step: 10
Training loss: 2.3859508421599163
Validation loss: 2.533532802992422

Epoch: 6| Step: 11
Training loss: 2.7414897672248983
Validation loss: 2.5346913170111565

Epoch: 6| Step: 12
Training loss: 3.0369167254514338
Validation loss: 2.533339717087315

Epoch: 6| Step: 13
Training loss: 2.731420173843025
Validation loss: 2.5337123199853084

Epoch: 142| Step: 0
Training loss: 3.1455592021279455
Validation loss: 2.5282393234008564

Epoch: 6| Step: 1
Training loss: 3.066251986565551
Validation loss: 2.533119338857398

Epoch: 6| Step: 2
Training loss: 3.0434804934143975
Validation loss: 2.5310130057118787

Epoch: 6| Step: 3
Training loss: 2.5757113168679826
Validation loss: 2.5325112147389093

Epoch: 6| Step: 4
Training loss: 2.968524803856016
Validation loss: 2.5316935254105

Epoch: 6| Step: 5
Training loss: 2.5726417260754806
Validation loss: 2.534015678488439

Epoch: 6| Step: 6
Training loss: 2.731489741018946
Validation loss: 2.542755520760984

Epoch: 6| Step: 7
Training loss: 2.6887361212052543
Validation loss: 2.5575932180701404

Epoch: 6| Step: 8
Training loss: 2.5213310969279092
Validation loss: 2.573382364664898

Epoch: 6| Step: 9
Training loss: 3.102017232388334
Validation loss: 2.582775588333532

Epoch: 6| Step: 10
Training loss: 2.563653267719214
Validation loss: 2.591570205470768

Epoch: 6| Step: 11
Training loss: 2.960051955205288
Validation loss: 2.5656380726079275

Epoch: 6| Step: 12
Training loss: 3.284811938518786
Validation loss: 2.5717656981852675

Epoch: 6| Step: 13
Training loss: 3.438051214239456
Validation loss: 2.5692844144442266

Epoch: 143| Step: 0
Training loss: 3.0157826436794903
Validation loss: 2.5602839882737376

Epoch: 6| Step: 1
Training loss: 2.372822616718358
Validation loss: 2.565873921999219

Epoch: 6| Step: 2
Training loss: 2.7626060776172725
Validation loss: 2.552182965890129

Epoch: 6| Step: 3
Training loss: 3.079874383916189
Validation loss: 2.5632256481624593

Epoch: 6| Step: 4
Training loss: 2.7411258740030355
Validation loss: 2.5541631832847482

Epoch: 6| Step: 5
Training loss: 2.5123715420048214
Validation loss: 2.5502064181609256

Epoch: 6| Step: 6
Training loss: 3.337110540976327
Validation loss: 2.5434939269653523

Epoch: 6| Step: 7
Training loss: 2.762903631075354
Validation loss: 2.5425389825523417

Epoch: 6| Step: 8
Training loss: 3.1670510577418467
Validation loss: 2.5345363271387904

Epoch: 6| Step: 9
Training loss: 3.013052836616085
Validation loss: 2.5306118740999715

Epoch: 6| Step: 10
Training loss: 3.0635349315546363
Validation loss: 2.5214135229363883

Epoch: 6| Step: 11
Training loss: 2.7231224241106635
Validation loss: 2.520245492590893

Epoch: 6| Step: 12
Training loss: 2.623881146995719
Validation loss: 2.5165636628158317

Epoch: 6| Step: 13
Training loss: 3.295451213870861
Validation loss: 2.5207767420896148

Epoch: 144| Step: 0
Training loss: 2.56037498380183
Validation loss: 2.5205345298761457

Epoch: 6| Step: 1
Training loss: 2.8226517462674683
Validation loss: 2.5163273443300582

Epoch: 6| Step: 2
Training loss: 2.434262007905543
Validation loss: 2.5207659089371695

Epoch: 6| Step: 3
Training loss: 3.080211726008226
Validation loss: 2.5165938744234615

Epoch: 6| Step: 4
Training loss: 3.188405226278945
Validation loss: 2.5157023892925015

Epoch: 6| Step: 5
Training loss: 2.9809046835212243
Validation loss: 2.512998381245591

Epoch: 6| Step: 6
Training loss: 2.4787168548876455
Validation loss: 2.516519522879734

Epoch: 6| Step: 7
Training loss: 2.6775176491320414
Validation loss: 2.5150407466679514

Epoch: 6| Step: 8
Training loss: 3.3997508350401864
Validation loss: 2.519744105504172

Epoch: 6| Step: 9
Training loss: 2.525570372566781
Validation loss: 2.5168636123399324

Epoch: 6| Step: 10
Training loss: 2.958457693432192
Validation loss: 2.5286427384178656

Epoch: 6| Step: 11
Training loss: 2.7802938467924068
Validation loss: 2.535970131776835

Epoch: 6| Step: 12
Training loss: 3.0404057610913773
Validation loss: 2.5409079161698824

Epoch: 6| Step: 13
Training loss: 3.474124079024104
Validation loss: 2.5428080380637996

Epoch: 145| Step: 0
Training loss: 2.39530576342925
Validation loss: 2.5751489161946224

Epoch: 6| Step: 1
Training loss: 3.073211466123855
Validation loss: 2.58099398908778

Epoch: 6| Step: 2
Training loss: 2.926864199507452
Validation loss: 2.5959758259280847

Epoch: 6| Step: 3
Training loss: 3.05416967193192
Validation loss: 2.5961396414891103

Epoch: 6| Step: 4
Training loss: 2.871491655037704
Validation loss: 2.6196706282291746

Epoch: 6| Step: 5
Training loss: 2.8430773599775465
Validation loss: 2.6262465509091553

Epoch: 6| Step: 6
Training loss: 3.437539117763931
Validation loss: 2.6344717055764266

Epoch: 6| Step: 7
Training loss: 2.560750689858654
Validation loss: 2.5996567705858897

Epoch: 6| Step: 8
Training loss: 2.1886818009518585
Validation loss: 2.5626764734440215

Epoch: 6| Step: 9
Training loss: 3.178695486473585
Validation loss: 2.5526511465779786

Epoch: 6| Step: 10
Training loss: 3.10810036148379
Validation loss: 2.5304881855702925

Epoch: 6| Step: 11
Training loss: 3.0535675883766955
Validation loss: 2.5208806187964385

Epoch: 6| Step: 12
Training loss: 2.859606123791796
Validation loss: 2.5197615989805846

Epoch: 6| Step: 13
Training loss: 2.7006153076675963
Validation loss: 2.511208344861549

Epoch: 146| Step: 0
Training loss: 2.589192442318055
Validation loss: 2.5120479889964953

Epoch: 6| Step: 1
Training loss: 2.7796558569167957
Validation loss: 2.5160320484881886

Epoch: 6| Step: 2
Training loss: 2.2860840047117956
Validation loss: 2.520987760620107

Epoch: 6| Step: 3
Training loss: 3.460199626169261
Validation loss: 2.5297005470027236

Epoch: 6| Step: 4
Training loss: 2.2189184850201378
Validation loss: 2.53923804497457

Epoch: 6| Step: 5
Training loss: 3.5749905779521
Validation loss: 2.5380580059222972

Epoch: 6| Step: 6
Training loss: 2.6010259584791013
Validation loss: 2.5607278149701527

Epoch: 6| Step: 7
Training loss: 3.0796405914465654
Validation loss: 2.5801163317422238

Epoch: 6| Step: 8
Training loss: 3.1656996271011435
Validation loss: 2.602258447940436

Epoch: 6| Step: 9
Training loss: 2.850396071903628
Validation loss: 2.5989532585734842

Epoch: 6| Step: 10
Training loss: 3.1089718044471177
Validation loss: 2.5950830796910775

Epoch: 6| Step: 11
Training loss: 2.894329110319062
Validation loss: 2.5869455266666534

Epoch: 6| Step: 12
Training loss: 2.8467723170499726
Validation loss: 2.594078475092753

Epoch: 6| Step: 13
Training loss: 2.493586228425833
Validation loss: 2.582233570642665

Epoch: 147| Step: 0
Training loss: 2.7956718542213777
Validation loss: 2.5907268734366307

Epoch: 6| Step: 1
Training loss: 2.8379228856562753
Validation loss: 2.566841427601701

Epoch: 6| Step: 2
Training loss: 3.236174446835956
Validation loss: 2.5504287556321312

Epoch: 6| Step: 3
Training loss: 2.941049582044303
Validation loss: 2.555662642080078

Epoch: 6| Step: 4
Training loss: 2.8140220762036194
Validation loss: 2.560722366774097

Epoch: 6| Step: 5
Training loss: 2.8126998830339227
Validation loss: 2.5419057067620208

Epoch: 6| Step: 6
Training loss: 2.651206760224752
Validation loss: 2.5439358225755213

Epoch: 6| Step: 7
Training loss: 2.5571976674835866
Validation loss: 2.528415203090237

Epoch: 6| Step: 8
Training loss: 2.8869618892869564
Validation loss: 2.513172702874929

Epoch: 6| Step: 9
Training loss: 2.8907249639598613
Validation loss: 2.5110074594261698

Epoch: 6| Step: 10
Training loss: 3.2402318732566444
Validation loss: 2.5067686588691283

Epoch: 6| Step: 11
Training loss: 2.791288112955882
Validation loss: 2.5077362493638615

Epoch: 6| Step: 12
Training loss: 2.5945354329540393
Validation loss: 2.504652232306268

Epoch: 6| Step: 13
Training loss: 3.2658799359409167
Validation loss: 2.5040338591958773

Epoch: 148| Step: 0
Training loss: 3.254308632177027
Validation loss: 2.5029109962954283

Epoch: 6| Step: 1
Training loss: 2.4925751100661517
Validation loss: 2.4999364649995193

Epoch: 6| Step: 2
Training loss: 2.640220746579294
Validation loss: 2.5007921230392727

Epoch: 6| Step: 3
Training loss: 2.8420540919354114
Validation loss: 2.50268740646435

Epoch: 6| Step: 4
Training loss: 3.330716981882928
Validation loss: 2.500791537176585

Epoch: 6| Step: 5
Training loss: 3.4687783179974443
Validation loss: 2.5065494137454984

Epoch: 6| Step: 6
Training loss: 2.12602680306392
Validation loss: 2.5054794052985487

Epoch: 6| Step: 7
Training loss: 2.3787713474552614
Validation loss: 2.5048371208549365

Epoch: 6| Step: 8
Training loss: 3.3380286208857677
Validation loss: 2.5080822685274735

Epoch: 6| Step: 9
Training loss: 2.730143209760393
Validation loss: 2.5064269250463793

Epoch: 6| Step: 10
Training loss: 2.5557274058053263
Validation loss: 2.512020830290257

Epoch: 6| Step: 11
Training loss: 2.8966917965599674
Validation loss: 2.513524261568426

Epoch: 6| Step: 12
Training loss: 2.9721326329245996
Validation loss: 2.5187032366843445

Epoch: 6| Step: 13
Training loss: 2.8448241165044306
Validation loss: 2.515245913889535

Epoch: 149| Step: 0
Training loss: 2.9421017902225546
Validation loss: 2.514304546541172

Epoch: 6| Step: 1
Training loss: 2.6323548776705334
Validation loss: 2.5119290169523443

Epoch: 6| Step: 2
Training loss: 3.205551791248576
Validation loss: 2.5166492347735634

Epoch: 6| Step: 3
Training loss: 2.7248290052047266
Validation loss: 2.5086450777638003

Epoch: 6| Step: 4
Training loss: 1.8281963367074492
Validation loss: 2.5143521848764845

Epoch: 6| Step: 5
Training loss: 2.5240213291578866
Validation loss: 2.5100542440952123

Epoch: 6| Step: 6
Training loss: 2.5816134808822278
Validation loss: 2.50730792118369

Epoch: 6| Step: 7
Training loss: 2.8157008288944536
Validation loss: 2.506648331699241

Epoch: 6| Step: 8
Training loss: 2.7698519888214292
Validation loss: 2.503674649096653

Epoch: 6| Step: 9
Training loss: 3.074951394790211
Validation loss: 2.5059679887168094

Epoch: 6| Step: 10
Training loss: 3.4039286131405477
Validation loss: 2.5027917061770903

Epoch: 6| Step: 11
Training loss: 3.114543969831643
Validation loss: 2.514026134001597

Epoch: 6| Step: 12
Training loss: 2.982485507568552
Validation loss: 2.507191638381066

Epoch: 6| Step: 13
Training loss: 3.456991938997889
Validation loss: 2.5128087216879433

Epoch: 150| Step: 0
Training loss: 2.855895212788919
Validation loss: 2.5149739617311693

Epoch: 6| Step: 1
Training loss: 2.940549525590612
Validation loss: 2.519957738584802

Epoch: 6| Step: 2
Training loss: 2.770021553919696
Validation loss: 2.5141959003936702

Epoch: 6| Step: 3
Training loss: 2.1247397992766377
Validation loss: 2.5258345743701627

Epoch: 6| Step: 4
Training loss: 2.2404962734130978
Validation loss: 2.542789849193295

Epoch: 6| Step: 5
Training loss: 3.1232734488246163
Validation loss: 2.5517050634583405

Epoch: 6| Step: 6
Training loss: 2.911909110579162
Validation loss: 2.540848812394236

Epoch: 6| Step: 7
Training loss: 2.526053380775164
Validation loss: 2.5571804601802666

Epoch: 6| Step: 8
Training loss: 2.8610254746082604
Validation loss: 2.5238584447160988

Epoch: 6| Step: 9
Training loss: 3.0139585644177895
Validation loss: 2.523789366845405

Epoch: 6| Step: 10
Training loss: 3.52582369440093
Validation loss: 2.517644629056755

Epoch: 6| Step: 11
Training loss: 2.593983099700768
Validation loss: 2.5127051326293155

Epoch: 6| Step: 12
Training loss: 3.1832045990110407
Validation loss: 2.509193978083565

Epoch: 6| Step: 13
Training loss: 3.344782161946644
Validation loss: 2.5142907030929798

Epoch: 151| Step: 0
Training loss: 3.3923549194348848
Validation loss: 2.5115983915325013

Epoch: 6| Step: 1
Training loss: 2.5715920646100026
Validation loss: 2.5158697060359407

Epoch: 6| Step: 2
Training loss: 3.1859095476317147
Validation loss: 2.5148013134626184

Epoch: 6| Step: 3
Training loss: 3.188326111496362
Validation loss: 2.516586676316997

Epoch: 6| Step: 4
Training loss: 3.1533455657184066
Validation loss: 2.5119648770413154

Epoch: 6| Step: 5
Training loss: 2.6351339819357733
Validation loss: 2.5085046305238965

Epoch: 6| Step: 6
Training loss: 2.785489740509274
Validation loss: 2.5000458364489107

Epoch: 6| Step: 7
Training loss: 3.244375938043549
Validation loss: 2.5089021475703928

Epoch: 6| Step: 8
Training loss: 2.265295807172684
Validation loss: 2.51114698416112

Epoch: 6| Step: 9
Training loss: 3.0973027954873245
Validation loss: 2.522784041399266

Epoch: 6| Step: 10
Training loss: 2.2311681395829055
Validation loss: 2.5176676672978666

Epoch: 6| Step: 11
Training loss: 3.0629754767810833
Validation loss: 2.517675528253888

Epoch: 6| Step: 12
Training loss: 1.9612748057326603
Validation loss: 2.5224992602916467

Epoch: 6| Step: 13
Training loss: 3.123693727228372
Validation loss: 2.521488438821876

Epoch: 152| Step: 0
Training loss: 3.3004626961206345
Validation loss: 2.525691282233493

Epoch: 6| Step: 1
Training loss: 2.715260864708127
Validation loss: 2.529337980337288

Epoch: 6| Step: 2
Training loss: 2.630157943595414
Validation loss: 2.529616474587838

Epoch: 6| Step: 3
Training loss: 2.7608212924199202
Validation loss: 2.523084521270415

Epoch: 6| Step: 4
Training loss: 2.6526445041308135
Validation loss: 2.509100421417884

Epoch: 6| Step: 5
Training loss: 2.4317461228369663
Validation loss: 2.508118331825618

Epoch: 6| Step: 6
Training loss: 3.111443986190209
Validation loss: 2.5110179262963173

Epoch: 6| Step: 7
Training loss: 2.9149963682489033
Validation loss: 2.5166731388220973

Epoch: 6| Step: 8
Training loss: 3.138276090040801
Validation loss: 2.505091328131665

Epoch: 6| Step: 9
Training loss: 2.9972107954713887
Validation loss: 2.5089754946167813

Epoch: 6| Step: 10
Training loss: 2.5826110650522036
Validation loss: 2.5092190289929475

Epoch: 6| Step: 11
Training loss: 2.740503386318799
Validation loss: 2.5136356037689502

Epoch: 6| Step: 12
Training loss: 3.609373811003254
Validation loss: 2.530839973682027

Epoch: 6| Step: 13
Training loss: 1.6977428823205871
Validation loss: 2.5284428721243533

Epoch: 153| Step: 0
Training loss: 2.5983391115207137
Validation loss: 2.5164065855422533

Epoch: 6| Step: 1
Training loss: 2.5798199255148595
Validation loss: 2.5034065172156046

Epoch: 6| Step: 2
Training loss: 3.3838991177539177
Validation loss: 2.5108651967352067

Epoch: 6| Step: 3
Training loss: 2.7971714651163646
Validation loss: 2.510780465037231

Epoch: 6| Step: 4
Training loss: 2.5295524085143315
Validation loss: 2.5061790726522224

Epoch: 6| Step: 5
Training loss: 2.733606372159788
Validation loss: 2.5027254548213604

Epoch: 6| Step: 6
Training loss: 3.3456880176067263
Validation loss: 2.4963249081405605

Epoch: 6| Step: 7
Training loss: 2.6554176372783886
Validation loss: 2.505067114006792

Epoch: 6| Step: 8
Training loss: 3.175162580037118
Validation loss: 2.5014165572051628

Epoch: 6| Step: 9
Training loss: 3.1625511798562185
Validation loss: 2.4984487478920148

Epoch: 6| Step: 10
Training loss: 2.6560311619987256
Validation loss: 2.4974361912014804

Epoch: 6| Step: 11
Training loss: 2.829791679128629
Validation loss: 2.5050228789519386

Epoch: 6| Step: 12
Training loss: 2.3034851041146176
Validation loss: 2.4990734434240127

Epoch: 6| Step: 13
Training loss: 3.24951432340476
Validation loss: 2.503296368854199

Epoch: 154| Step: 0
Training loss: 2.908905129027521
Validation loss: 2.5096494448366693

Epoch: 6| Step: 1
Training loss: 2.8434991411503288
Validation loss: 2.509014314079848

Epoch: 6| Step: 2
Training loss: 2.8610583077242158
Validation loss: 2.5216399708819295

Epoch: 6| Step: 3
Training loss: 2.717789140355058
Validation loss: 2.5230209558950016

Epoch: 6| Step: 4
Training loss: 2.918755809443245
Validation loss: 2.529505770959696

Epoch: 6| Step: 5
Training loss: 2.874513667893109
Validation loss: 2.540342041907287

Epoch: 6| Step: 6
Training loss: 2.6035980417609634
Validation loss: 2.5516002493313126

Epoch: 6| Step: 7
Training loss: 3.0287137776978525
Validation loss: 2.5670942025418295

Epoch: 6| Step: 8
Training loss: 2.5182657538316695
Validation loss: 2.5408543808944533

Epoch: 6| Step: 9
Training loss: 2.2937002233774315
Validation loss: 2.514775684074998

Epoch: 6| Step: 10
Training loss: 3.0441726046536566
Validation loss: 2.4997034337919133

Epoch: 6| Step: 11
Training loss: 3.3074723001647985
Validation loss: 2.4952730128128016

Epoch: 6| Step: 12
Training loss: 2.9282857974917667
Validation loss: 2.493950242687705

Epoch: 6| Step: 13
Training loss: 3.31678063533888
Validation loss: 2.4982964977383837

Epoch: 155| Step: 0
Training loss: 3.2760126368333644
Validation loss: 2.5008894589131434

Epoch: 6| Step: 1
Training loss: 2.791515137464834
Validation loss: 2.5021906330263906

Epoch: 6| Step: 2
Training loss: 2.9889269561265728
Validation loss: 2.501083309537265

Epoch: 6| Step: 3
Training loss: 3.092479714748799
Validation loss: 2.502689218547885

Epoch: 6| Step: 4
Training loss: 3.195314887682482
Validation loss: 2.496793359882856

Epoch: 6| Step: 5
Training loss: 2.8388236836084433
Validation loss: 2.4987579818818313

Epoch: 6| Step: 6
Training loss: 2.792450543326823
Validation loss: 2.489561197109788

Epoch: 6| Step: 7
Training loss: 2.603894720501215
Validation loss: 2.4956532025899287

Epoch: 6| Step: 8
Training loss: 3.0294004480400014
Validation loss: 2.4900838139746466

Epoch: 6| Step: 9
Training loss: 3.137574189665369
Validation loss: 2.4940349150352565

Epoch: 6| Step: 10
Training loss: 2.6074141941600355
Validation loss: 2.497077814802081

Epoch: 6| Step: 11
Training loss: 2.5479683430739732
Validation loss: 2.503277589241415

Epoch: 6| Step: 12
Training loss: 2.7024971116974226
Validation loss: 2.519402279724305

Epoch: 6| Step: 13
Training loss: 2.058662775319297
Validation loss: 2.5180445826964832

Epoch: 156| Step: 0
Training loss: 2.7336512016370915
Validation loss: 2.538876593940808

Epoch: 6| Step: 1
Training loss: 2.6704590374965997
Validation loss: 2.528548489026692

Epoch: 6| Step: 2
Training loss: 3.1457270084290623
Validation loss: 2.564757188601821

Epoch: 6| Step: 3
Training loss: 2.898590330634219
Validation loss: 2.536528478456328

Epoch: 6| Step: 4
Training loss: 2.9380895144833805
Validation loss: 2.521488307665355

Epoch: 6| Step: 5
Training loss: 2.897731314535603
Validation loss: 2.4984286476764472

Epoch: 6| Step: 6
Training loss: 2.9512176005205983
Validation loss: 2.503920499993918

Epoch: 6| Step: 7
Training loss: 3.0989471862763454
Validation loss: 2.4952471479125826

Epoch: 6| Step: 8
Training loss: 3.010462636277658
Validation loss: 2.5047028658653243

Epoch: 6| Step: 9
Training loss: 3.0307862231795952
Validation loss: 2.497426185798573

Epoch: 6| Step: 10
Training loss: 2.8664383494216574
Validation loss: 2.502317474249717

Epoch: 6| Step: 11
Training loss: 2.7499793658782874
Validation loss: 2.499214009839837

Epoch: 6| Step: 12
Training loss: 2.6548776110585037
Validation loss: 2.498133409629798

Epoch: 6| Step: 13
Training loss: 1.8803149234501884
Validation loss: 2.493732791232358

Epoch: 157| Step: 0
Training loss: 2.925100412846016
Validation loss: 2.4961810383913035

Epoch: 6| Step: 1
Training loss: 2.689776144250067
Validation loss: 2.493427409600671

Epoch: 6| Step: 2
Training loss: 3.291350015467271
Validation loss: 2.4965842056254517

Epoch: 6| Step: 3
Training loss: 3.0116628599609006
Validation loss: 2.5012846179106902

Epoch: 6| Step: 4
Training loss: 2.9627618730265457
Validation loss: 2.504848184605883

Epoch: 6| Step: 5
Training loss: 2.798590703931374
Validation loss: 2.4959327920211556

Epoch: 6| Step: 6
Training loss: 2.767925103403587
Validation loss: 2.4962179288610877

Epoch: 6| Step: 7
Training loss: 3.0646709610275025
Validation loss: 2.4984088930980315

Epoch: 6| Step: 8
Training loss: 2.875570986894844
Validation loss: 2.5028144478581726

Epoch: 6| Step: 9
Training loss: 2.2407370737476078
Validation loss: 2.521192182564235

Epoch: 6| Step: 10
Training loss: 2.3841710954625226
Validation loss: 2.5260040033440085

Epoch: 6| Step: 11
Training loss: 3.0586935248732527
Validation loss: 2.555205707388088

Epoch: 6| Step: 12
Training loss: 2.8552429694424926
Validation loss: 2.570416293775971

Epoch: 6| Step: 13
Training loss: 3.0477105975591923
Validation loss: 2.5811018258696348

Epoch: 158| Step: 0
Training loss: 2.9664273461954784
Validation loss: 2.5943693362286178

Epoch: 6| Step: 1
Training loss: 2.5719192260054426
Validation loss: 2.55732890394933

Epoch: 6| Step: 2
Training loss: 2.861702393931043
Validation loss: 2.5273781467702774

Epoch: 6| Step: 3
Training loss: 2.90162734050128
Validation loss: 2.5137749581551176

Epoch: 6| Step: 4
Training loss: 2.467941924526279
Validation loss: 2.50917449216718

Epoch: 6| Step: 5
Training loss: 3.071250558681538
Validation loss: 2.506278904340632

Epoch: 6| Step: 6
Training loss: 2.4619989921450003
Validation loss: 2.501090716263675

Epoch: 6| Step: 7
Training loss: 2.863555353843604
Validation loss: 2.5027706672236603

Epoch: 6| Step: 8
Training loss: 3.1160286874295284
Validation loss: 2.490465011581058

Epoch: 6| Step: 9
Training loss: 3.1167983192204325
Validation loss: 2.4941873102056147

Epoch: 6| Step: 10
Training loss: 2.705628046539417
Validation loss: 2.495672408866054

Epoch: 6| Step: 11
Training loss: 2.4112882506093825
Validation loss: 2.4931561448244106

Epoch: 6| Step: 12
Training loss: 3.2547801150633986
Validation loss: 2.494738711286775

Epoch: 6| Step: 13
Training loss: 3.480893161640959
Validation loss: 2.496227035341651

Epoch: 159| Step: 0
Training loss: 3.0300875922405925
Validation loss: 2.4970021352271137

Epoch: 6| Step: 1
Training loss: 3.155047499212974
Validation loss: 2.504939432589073

Epoch: 6| Step: 2
Training loss: 2.8180592166264153
Validation loss: 2.49384055970259

Epoch: 6| Step: 3
Training loss: 2.8635871588482864
Validation loss: 2.5098129981101036

Epoch: 6| Step: 4
Training loss: 3.18564626607669
Validation loss: 2.5234978730623774

Epoch: 6| Step: 5
Training loss: 2.6047616711212345
Validation loss: 2.535902118780389

Epoch: 6| Step: 6
Training loss: 2.862452950569856
Validation loss: 2.563770930439269

Epoch: 6| Step: 7
Training loss: 2.1939203049504505
Validation loss: 2.567572886999681

Epoch: 6| Step: 8
Training loss: 2.919373772763203
Validation loss: 2.5447115446168094

Epoch: 6| Step: 9
Training loss: 2.4708762368331163
Validation loss: 2.539692096759671

Epoch: 6| Step: 10
Training loss: 2.903977192444996
Validation loss: 2.548178566613192

Epoch: 6| Step: 11
Training loss: 2.618041124200101
Validation loss: 2.545937990932471

Epoch: 6| Step: 12
Training loss: 3.430854060218757
Validation loss: 2.5335723511476504

Epoch: 6| Step: 13
Training loss: 2.930784787999927
Validation loss: 2.4988920217655464

Epoch: 160| Step: 0
Training loss: 2.625273826485912
Validation loss: 2.4902090950184785

Epoch: 6| Step: 1
Training loss: 3.246837691385521
Validation loss: 2.497956740210902

Epoch: 6| Step: 2
Training loss: 2.8120419447145926
Validation loss: 2.4974678392988015

Epoch: 6| Step: 3
Training loss: 3.378331412220882
Validation loss: 2.5018028834148285

Epoch: 6| Step: 4
Training loss: 2.93039737493474
Validation loss: 2.499748763924739

Epoch: 6| Step: 5
Training loss: 2.5970764889915836
Validation loss: 2.506895046546418

Epoch: 6| Step: 6
Training loss: 2.7846508878437866
Validation loss: 2.499746873818203

Epoch: 6| Step: 7
Training loss: 3.172754024980087
Validation loss: 2.496904300267924

Epoch: 6| Step: 8
Training loss: 2.7764609606481807
Validation loss: 2.4995579318440386

Epoch: 6| Step: 9
Training loss: 2.4494554809835414
Validation loss: 2.505926533795775

Epoch: 6| Step: 10
Training loss: 2.8904225871382145
Validation loss: 2.5067800106731815

Epoch: 6| Step: 11
Training loss: 2.6732454410415287
Validation loss: 2.515220445487282

Epoch: 6| Step: 12
Training loss: 2.9083920040242623
Validation loss: 2.5200337394676566

Epoch: 6| Step: 13
Training loss: 2.6771149590154284
Validation loss: 2.5284168192970458

Epoch: 161| Step: 0
Training loss: 2.8580469267872024
Validation loss: 2.5401027863672696

Epoch: 6| Step: 1
Training loss: 2.2334505316126085
Validation loss: 2.564626406226128

Epoch: 6| Step: 2
Training loss: 2.9302466914250447
Validation loss: 2.582621250660499

Epoch: 6| Step: 3
Training loss: 2.847721219466335
Validation loss: 2.5823392043524733

Epoch: 6| Step: 4
Training loss: 2.0186836633323657
Validation loss: 2.586889061345374

Epoch: 6| Step: 5
Training loss: 3.365907359343773
Validation loss: 2.585760759084163

Epoch: 6| Step: 6
Training loss: 3.0017934842372616
Validation loss: 2.5673078038936383

Epoch: 6| Step: 7
Training loss: 2.627969606139587
Validation loss: 2.5439962523423043

Epoch: 6| Step: 8
Training loss: 2.7290107643695136
Validation loss: 2.5325825661419246

Epoch: 6| Step: 9
Training loss: 3.0508171987918806
Validation loss: 2.531090303318488

Epoch: 6| Step: 10
Training loss: 3.0993924560793777
Validation loss: 2.523425562772026

Epoch: 6| Step: 11
Training loss: 3.2623771322798745
Validation loss: 2.5222582725876865

Epoch: 6| Step: 12
Training loss: 2.823442830015808
Validation loss: 2.530404226454212

Epoch: 6| Step: 13
Training loss: 3.0726458586423258
Validation loss: 2.522864618028105

Epoch: 162| Step: 0
Training loss: 2.82657804384697
Validation loss: 2.5260558235897426

Epoch: 6| Step: 1
Training loss: 2.121435878974105
Validation loss: 2.5212613865006213

Epoch: 6| Step: 2
Training loss: 3.2687253699459697
Validation loss: 2.509839053041666

Epoch: 6| Step: 3
Training loss: 3.0194240220389257
Validation loss: 2.5115257641584434

Epoch: 6| Step: 4
Training loss: 2.5228737594101713
Validation loss: 2.510325530289728

Epoch: 6| Step: 5
Training loss: 2.50635198447476
Validation loss: 2.5074484932198677

Epoch: 6| Step: 6
Training loss: 2.509960169989086
Validation loss: 2.523765872523324

Epoch: 6| Step: 7
Training loss: 3.053964202401256
Validation loss: 2.5140817716613917

Epoch: 6| Step: 8
Training loss: 2.686890466454326
Validation loss: 2.5082614156856873

Epoch: 6| Step: 9
Training loss: 3.0644730420799537
Validation loss: 2.524056797044379

Epoch: 6| Step: 10
Training loss: 2.832249452800834
Validation loss: 2.524001557524623

Epoch: 6| Step: 11
Training loss: 3.5662589068858113
Validation loss: 2.526574547982607

Epoch: 6| Step: 12
Training loss: 2.807223138108431
Validation loss: 2.521420787586073

Epoch: 6| Step: 13
Training loss: 3.011516875985945
Validation loss: 2.51586477362047

Epoch: 163| Step: 0
Training loss: 3.2074573526498185
Validation loss: 2.5155716237350805

Epoch: 6| Step: 1
Training loss: 2.3895038643626325
Validation loss: 2.5057966198082053

Epoch: 6| Step: 2
Training loss: 3.317721587932625
Validation loss: 2.5007410612334104

Epoch: 6| Step: 3
Training loss: 3.2521695451633947
Validation loss: 2.5018143438265925

Epoch: 6| Step: 4
Training loss: 3.125746981035593
Validation loss: 2.4955578264523868

Epoch: 6| Step: 5
Training loss: 2.904633103015726
Validation loss: 2.4980307811699145

Epoch: 6| Step: 6
Training loss: 2.265102668271096
Validation loss: 2.496113390410942

Epoch: 6| Step: 7
Training loss: 2.664172754774952
Validation loss: 2.4882945056207464

Epoch: 6| Step: 8
Training loss: 3.1399801171031676
Validation loss: 2.4908156135621615

Epoch: 6| Step: 9
Training loss: 2.267536698520706
Validation loss: 2.4887009056205267

Epoch: 6| Step: 10
Training loss: 2.655395998832192
Validation loss: 2.493342784483438

Epoch: 6| Step: 11
Training loss: 3.1676490330730322
Validation loss: 2.512139802068238

Epoch: 6| Step: 12
Training loss: 2.3841587953549794
Validation loss: 2.512609291628031

Epoch: 6| Step: 13
Training loss: 2.853391128946997
Validation loss: 2.540119840895245

Epoch: 164| Step: 0
Training loss: 3.176495423666577
Validation loss: 2.5519753998129975

Epoch: 6| Step: 1
Training loss: 3.3211686051645533
Validation loss: 2.539812269550781

Epoch: 6| Step: 2
Training loss: 2.2747509495160605
Validation loss: 2.5313506031085016

Epoch: 6| Step: 3
Training loss: 2.59615168775159
Validation loss: 2.5385720823602083

Epoch: 6| Step: 4
Training loss: 3.0264114617909392
Validation loss: 2.5453365764558047

Epoch: 6| Step: 5
Training loss: 2.8728500288403516
Validation loss: 2.5264526394848117

Epoch: 6| Step: 6
Training loss: 3.0088354971972686
Validation loss: 2.5117105866532388

Epoch: 6| Step: 7
Training loss: 3.1931486754361975
Validation loss: 2.498033140551185

Epoch: 6| Step: 8
Training loss: 2.7372003399996037
Validation loss: 2.505809205756979

Epoch: 6| Step: 9
Training loss: 2.9530959354968553
Validation loss: 2.5047181655576356

Epoch: 6| Step: 10
Training loss: 2.893698877661613
Validation loss: 2.500016321108466

Epoch: 6| Step: 11
Training loss: 2.5396226470466217
Validation loss: 2.4973924076441305

Epoch: 6| Step: 12
Training loss: 2.5583276042397767
Validation loss: 2.4989677256640057

Epoch: 6| Step: 13
Training loss: 2.590442340885791
Validation loss: 2.4985331939143376

Epoch: 165| Step: 0
Training loss: 2.59957158887358
Validation loss: 2.495395081249334

Epoch: 6| Step: 1
Training loss: 2.617622726463488
Validation loss: 2.501277012921519

Epoch: 6| Step: 2
Training loss: 2.7189181922539403
Validation loss: 2.5030117003791212

Epoch: 6| Step: 3
Training loss: 3.1391540422853237
Validation loss: 2.5018106466608656

Epoch: 6| Step: 4
Training loss: 3.284894971402363
Validation loss: 2.5094018555620616

Epoch: 6| Step: 5
Training loss: 2.9684963720298523
Validation loss: 2.505426294321419

Epoch: 6| Step: 6
Training loss: 3.033232679548546
Validation loss: 2.4983916097660197

Epoch: 6| Step: 7
Training loss: 1.9416811957518358
Validation loss: 2.4884660640310536

Epoch: 6| Step: 8
Training loss: 2.7806150590303482
Validation loss: 2.506855213542693

Epoch: 6| Step: 9
Training loss: 2.988591595659563
Validation loss: 2.5050357451048075

Epoch: 6| Step: 10
Training loss: 2.6981190098671055
Validation loss: 2.510435280373226

Epoch: 6| Step: 11
Training loss: 3.005732146328683
Validation loss: 2.521996477821812

Epoch: 6| Step: 12
Training loss: 3.050601812304636
Validation loss: 2.547421186756163

Epoch: 6| Step: 13
Training loss: 2.763500194811137
Validation loss: 2.5524545030899133

Epoch: 166| Step: 0
Training loss: 2.5104051539577874
Validation loss: 2.567688150610904

Epoch: 6| Step: 1
Training loss: 3.141990099244815
Validation loss: 2.5633436865523955

Epoch: 6| Step: 2
Training loss: 2.6884125335750824
Validation loss: 2.5796267464014915

Epoch: 6| Step: 3
Training loss: 2.8506152108059277
Validation loss: 2.5600749480488467

Epoch: 6| Step: 4
Training loss: 2.794649314785856
Validation loss: 2.542810728928833

Epoch: 6| Step: 5
Training loss: 2.6162729971467744
Validation loss: 2.538564542621809

Epoch: 6| Step: 6
Training loss: 3.076134207358666
Validation loss: 2.5288095228737846

Epoch: 6| Step: 7
Training loss: 2.554223067971361
Validation loss: 2.521347074568193

Epoch: 6| Step: 8
Training loss: 2.5625987150205263
Validation loss: 2.524211307097408

Epoch: 6| Step: 9
Training loss: 3.3993381753684906
Validation loss: 2.507433257218442

Epoch: 6| Step: 10
Training loss: 2.767283141918952
Validation loss: 2.49873515916479

Epoch: 6| Step: 11
Training loss: 3.275625731117474
Validation loss: 2.493121183358824

Epoch: 6| Step: 12
Training loss: 3.048198705849374
Validation loss: 2.4851045213966363

Epoch: 6| Step: 13
Training loss: 2.1926147610111215
Validation loss: 2.492809408233361

Epoch: 167| Step: 0
Training loss: 2.7612911254804304
Validation loss: 2.488122138919664

Epoch: 6| Step: 1
Training loss: 2.9051724969334396
Validation loss: 2.4969016092133547

Epoch: 6| Step: 2
Training loss: 3.1005863988680757
Validation loss: 2.5055615848869834

Epoch: 6| Step: 3
Training loss: 2.610361244078099
Validation loss: 2.518845231746943

Epoch: 6| Step: 4
Training loss: 2.699007106052244
Validation loss: 2.535518147467203

Epoch: 6| Step: 5
Training loss: 2.920348232616044
Validation loss: 2.5301655429220595

Epoch: 6| Step: 6
Training loss: 3.225897695112332
Validation loss: 2.518439322007313

Epoch: 6| Step: 7
Training loss: 2.996845653338537
Validation loss: 2.523945084718631

Epoch: 6| Step: 8
Training loss: 2.64934584982913
Validation loss: 2.5114678767427576

Epoch: 6| Step: 9
Training loss: 3.2916004962949974
Validation loss: 2.506568822906042

Epoch: 6| Step: 10
Training loss: 2.8704408071847203
Validation loss: 2.497899066894828

Epoch: 6| Step: 11
Training loss: 2.6772392811358925
Validation loss: 2.499245457967049

Epoch: 6| Step: 12
Training loss: 2.502990459964996
Validation loss: 2.495405618741644

Epoch: 6| Step: 13
Training loss: 2.0432688855477297
Validation loss: 2.495062777602641

Epoch: 168| Step: 0
Training loss: 2.106025919328174
Validation loss: 2.4925573867035493

Epoch: 6| Step: 1
Training loss: 3.3780421921764128
Validation loss: 2.4894108502502594

Epoch: 6| Step: 2
Training loss: 2.8203684624273793
Validation loss: 2.491600145110538

Epoch: 6| Step: 3
Training loss: 2.8678400196269367
Validation loss: 2.497918324665525

Epoch: 6| Step: 4
Training loss: 3.6197390033358077
Validation loss: 2.4970066875549053

Epoch: 6| Step: 5
Training loss: 2.7589848865787787
Validation loss: 2.495795607187121

Epoch: 6| Step: 6
Training loss: 2.746289263910365
Validation loss: 2.4997413480943163

Epoch: 6| Step: 7
Training loss: 2.751925228023524
Validation loss: 2.505283150868867

Epoch: 6| Step: 8
Training loss: 3.2080589441320866
Validation loss: 2.505730513381314

Epoch: 6| Step: 9
Training loss: 2.5282050762532644
Validation loss: 2.515228588778952

Epoch: 6| Step: 10
Training loss: 2.740490597568718
Validation loss: 2.522694786139552

Epoch: 6| Step: 11
Training loss: 1.6326972884274744
Validation loss: 2.5323148872835253

Epoch: 6| Step: 12
Training loss: 3.187136461058913
Validation loss: 2.5425172057119

Epoch: 6| Step: 13
Training loss: 2.7926793515386357
Validation loss: 2.5778776898537425

Epoch: 169| Step: 0
Training loss: 2.7711469620961404
Validation loss: 2.550699506666991

Epoch: 6| Step: 1
Training loss: 2.4125777434635376
Validation loss: 2.554505102515186

Epoch: 6| Step: 2
Training loss: 3.361124266361382
Validation loss: 2.5448343725963296

Epoch: 6| Step: 3
Training loss: 2.6207272405534043
Validation loss: 2.5477437613022866

Epoch: 6| Step: 4
Training loss: 2.6542090260365785
Validation loss: 2.5491966196491123

Epoch: 6| Step: 5
Training loss: 2.6267147821127868
Validation loss: 2.5267775936530117

Epoch: 6| Step: 6
Training loss: 3.0834555386906475
Validation loss: 2.519384750173258

Epoch: 6| Step: 7
Training loss: 2.501552099984237
Validation loss: 2.503200935724773

Epoch: 6| Step: 8
Training loss: 2.699950984227348
Validation loss: 2.4889149897373732

Epoch: 6| Step: 9
Training loss: 3.1045574650556893
Validation loss: 2.4923375332994753

Epoch: 6| Step: 10
Training loss: 3.5909245537884775
Validation loss: 2.4940390492813442

Epoch: 6| Step: 11
Training loss: 2.2113824942461116
Validation loss: 2.4891691896170727

Epoch: 6| Step: 12
Training loss: 3.410806390721313
Validation loss: 2.491693303240929

Epoch: 6| Step: 13
Training loss: 2.2028124431989458
Validation loss: 2.496056463297615

Epoch: 170| Step: 0
Training loss: 2.5352232091022486
Validation loss: 2.4913256570675384

Epoch: 6| Step: 1
Training loss: 2.501095341100262
Validation loss: 2.4868088802071715

Epoch: 6| Step: 2
Training loss: 3.1449500521770575
Validation loss: 2.486694207939454

Epoch: 6| Step: 3
Training loss: 2.9991713015078973
Validation loss: 2.4906149921856144

Epoch: 6| Step: 4
Training loss: 3.2323661130953147
Validation loss: 2.485960709404641

Epoch: 6| Step: 5
Training loss: 3.024661740393267
Validation loss: 2.4951336063050054

Epoch: 6| Step: 6
Training loss: 2.256338938812012
Validation loss: 2.511968053058897

Epoch: 6| Step: 7
Training loss: 2.858092306964881
Validation loss: 2.531436325380055

Epoch: 6| Step: 8
Training loss: 2.534723794550531
Validation loss: 2.5615545309901844

Epoch: 6| Step: 9
Training loss: 2.8895519017437796
Validation loss: 2.5786966624160064

Epoch: 6| Step: 10
Training loss: 3.23526121520585
Validation loss: 2.5612854198825166

Epoch: 6| Step: 11
Training loss: 2.456732072188138
Validation loss: 2.521113256501048

Epoch: 6| Step: 12
Training loss: 3.2326522883324063
Validation loss: 2.507046405370617

Epoch: 6| Step: 13
Training loss: 2.859806215883731
Validation loss: 2.4905110214573254

Epoch: 171| Step: 0
Training loss: 2.7128688297810597
Validation loss: 2.4831100744923784

Epoch: 6| Step: 1
Training loss: 2.9718200871060403
Validation loss: 2.4824723020857613

Epoch: 6| Step: 2
Training loss: 3.1696026559655865
Validation loss: 2.4913865510367468

Epoch: 6| Step: 3
Training loss: 3.0941941684192806
Validation loss: 2.4906577703709862

Epoch: 6| Step: 4
Training loss: 2.4918394413715155
Validation loss: 2.4950058501507897

Epoch: 6| Step: 5
Training loss: 2.5929630418549703
Validation loss: 2.488984271235863

Epoch: 6| Step: 6
Training loss: 2.1855191662815683
Validation loss: 2.4898380944327663

Epoch: 6| Step: 7
Training loss: 2.5360092820439917
Validation loss: 2.488605415497694

Epoch: 6| Step: 8
Training loss: 3.3360752908091365
Validation loss: 2.4853720397576264

Epoch: 6| Step: 9
Training loss: 3.034806672023781
Validation loss: 2.4887849510384243

Epoch: 6| Step: 10
Training loss: 3.1562416907474935
Validation loss: 2.4913282852003604

Epoch: 6| Step: 11
Training loss: 3.1897464390733403
Validation loss: 2.501644038996654

Epoch: 6| Step: 12
Training loss: 2.631160228946657
Validation loss: 2.5247753054706434

Epoch: 6| Step: 13
Training loss: 2.3713152560443294
Validation loss: 2.5566915044211656

Epoch: 172| Step: 0
Training loss: 3.0475794833601078
Validation loss: 2.585329326356731

Epoch: 6| Step: 1
Training loss: 2.5717743308109604
Validation loss: 2.63417516555809

Epoch: 6| Step: 2
Training loss: 3.329290194998725
Validation loss: 2.681761733712652

Epoch: 6| Step: 3
Training loss: 3.562964425850745
Validation loss: 2.7016846138992414

Epoch: 6| Step: 4
Training loss: 3.1105395106087474
Validation loss: 2.668650654023911

Epoch: 6| Step: 5
Training loss: 2.2529539215279297
Validation loss: 2.6002285687273154

Epoch: 6| Step: 6
Training loss: 3.4244737206864175
Validation loss: 2.548795822153221

Epoch: 6| Step: 7
Training loss: 2.729021248085779
Validation loss: 2.5049867240127077

Epoch: 6| Step: 8
Training loss: 2.309753333294021
Validation loss: 2.482657691048131

Epoch: 6| Step: 9
Training loss: 2.0310081924881795
Validation loss: 2.4795250804612263

Epoch: 6| Step: 10
Training loss: 3.0537413866106653
Validation loss: 2.486774876910213

Epoch: 6| Step: 11
Training loss: 2.7762389742148392
Validation loss: 2.4897669451883973

Epoch: 6| Step: 12
Training loss: 2.6501893857543446
Validation loss: 2.4927491917968365

Epoch: 6| Step: 13
Training loss: 2.998565012738613
Validation loss: 2.495382297918

Epoch: 173| Step: 0
Training loss: 2.704073171855747
Validation loss: 2.490430781295745

Epoch: 6| Step: 1
Training loss: 2.6453518967643688
Validation loss: 2.4896440704951006

Epoch: 6| Step: 2
Training loss: 3.070263267685354
Validation loss: 2.4949850275967007

Epoch: 6| Step: 3
Training loss: 2.522885477727443
Validation loss: 2.487253138024754

Epoch: 6| Step: 4
Training loss: 3.085404825713734
Validation loss: 2.4956306473279457

Epoch: 6| Step: 5
Training loss: 2.9834238503929926
Validation loss: 2.5155222963577706

Epoch: 6| Step: 6
Training loss: 3.367410532917629
Validation loss: 2.540860259134929

Epoch: 6| Step: 7
Training loss: 2.82931089038319
Validation loss: 2.5568472057446545

Epoch: 6| Step: 8
Training loss: 2.8966651289057483
Validation loss: 2.572510394823159

Epoch: 6| Step: 9
Training loss: 3.3905130534875014
Validation loss: 2.6175259700195563

Epoch: 6| Step: 10
Training loss: 2.909703817337164
Validation loss: 2.6452824628989817

Epoch: 6| Step: 11
Training loss: 2.068393955535998
Validation loss: 2.6003194441548096

Epoch: 6| Step: 12
Training loss: 2.284463369849382
Validation loss: 2.5610589678396116

Epoch: 6| Step: 13
Training loss: 2.9519369975244247
Validation loss: 2.523400833735675

Epoch: 174| Step: 0
Training loss: 2.8276125617519527
Validation loss: 2.4926687696503587

Epoch: 6| Step: 1
Training loss: 2.898192690975436
Validation loss: 2.484568659475254

Epoch: 6| Step: 2
Training loss: 3.129949998060104
Validation loss: 2.4833954148902424

Epoch: 6| Step: 3
Training loss: 2.3667299942713558
Validation loss: 2.4887063466660955

Epoch: 6| Step: 4
Training loss: 2.9539926051703933
Validation loss: 2.485107543990829

Epoch: 6| Step: 5
Training loss: 2.6091553372876595
Validation loss: 2.4832351906606625

Epoch: 6| Step: 6
Training loss: 2.6511723174531365
Validation loss: 2.485639320987891

Epoch: 6| Step: 7
Training loss: 2.6566669810002557
Validation loss: 2.477691018541052

Epoch: 6| Step: 8
Training loss: 3.175190212529351
Validation loss: 2.4766748693408718

Epoch: 6| Step: 9
Training loss: 3.061957174967182
Validation loss: 2.4756500839696236

Epoch: 6| Step: 10
Training loss: 2.3502134591410697
Validation loss: 2.486076314711701

Epoch: 6| Step: 11
Training loss: 3.3805722049110543
Validation loss: 2.4837412671789565

Epoch: 6| Step: 12
Training loss: 2.983879327803909
Validation loss: 2.4917403481004614

Epoch: 6| Step: 13
Training loss: 2.6870463675958605
Validation loss: 2.501713685309435

Epoch: 175| Step: 0
Training loss: 2.661847130333309
Validation loss: 2.508053427328368

Epoch: 6| Step: 1
Training loss: 2.917878544037415
Validation loss: 2.5109826091129603

Epoch: 6| Step: 2
Training loss: 2.7613171146468494
Validation loss: 2.497245759342924

Epoch: 6| Step: 3
Training loss: 2.6322244502488834
Validation loss: 2.506871647507348

Epoch: 6| Step: 4
Training loss: 2.965358684387977
Validation loss: 2.505865073429148

Epoch: 6| Step: 5
Training loss: 3.0093980449614137
Validation loss: 2.495514909339975

Epoch: 6| Step: 6
Training loss: 2.738676861579043
Validation loss: 2.4974236646811865

Epoch: 6| Step: 7
Training loss: 2.8119662308164286
Validation loss: 2.486434026517768

Epoch: 6| Step: 8
Training loss: 2.142080104815307
Validation loss: 2.497435777518334

Epoch: 6| Step: 9
Training loss: 3.0712525770388495
Validation loss: 2.51198919102734

Epoch: 6| Step: 10
Training loss: 3.1663318925546315
Validation loss: 2.496361104319376

Epoch: 6| Step: 11
Training loss: 3.058754323590726
Validation loss: 2.5104273732581306

Epoch: 6| Step: 12
Training loss: 2.5585141701006773
Validation loss: 2.515124782386988

Epoch: 6| Step: 13
Training loss: 3.1989027526326557
Validation loss: 2.517617728270459

Epoch: 176| Step: 0
Training loss: 3.279274045809086
Validation loss: 2.4997345937314908

Epoch: 6| Step: 1
Training loss: 2.990019727660966
Validation loss: 2.4905990109069616

Epoch: 6| Step: 2
Training loss: 2.3414478439592554
Validation loss: 2.479851473456882

Epoch: 6| Step: 3
Training loss: 3.0593263959287134
Validation loss: 2.4701840716492183

Epoch: 6| Step: 4
Training loss: 2.9402195131005584
Validation loss: 2.474836400179962

Epoch: 6| Step: 5
Training loss: 1.7536143716365922
Validation loss: 2.478480099126601

Epoch: 6| Step: 6
Training loss: 2.8683299769001955
Validation loss: 2.4798443713233174

Epoch: 6| Step: 7
Training loss: 2.9433434985263585
Validation loss: 2.478208721479303

Epoch: 6| Step: 8
Training loss: 2.3770533268667555
Validation loss: 2.4783152394181407

Epoch: 6| Step: 9
Training loss: 3.3464417363248233
Validation loss: 2.49164782604201

Epoch: 6| Step: 10
Training loss: 2.3607354694320417
Validation loss: 2.494335738068624

Epoch: 6| Step: 11
Training loss: 2.3227423586827998
Validation loss: 2.496282853531412

Epoch: 6| Step: 12
Training loss: 3.6474234174358715
Validation loss: 2.4994982687662803

Epoch: 6| Step: 13
Training loss: 2.995554968820974
Validation loss: 2.4921939909046147

Epoch: 177| Step: 0
Training loss: 2.538267228219004
Validation loss: 2.505585970218524

Epoch: 6| Step: 1
Training loss: 2.8682412022525785
Validation loss: 2.4977113502482053

Epoch: 6| Step: 2
Training loss: 2.7515639279658064
Validation loss: 2.4854372601222

Epoch: 6| Step: 3
Training loss: 2.2973162168897256
Validation loss: 2.5019624155363624

Epoch: 6| Step: 4
Training loss: 3.1149274621052165
Validation loss: 2.488052978698141

Epoch: 6| Step: 5
Training loss: 2.9986963618555094
Validation loss: 2.4876717582607077

Epoch: 6| Step: 6
Training loss: 2.890930489558506
Validation loss: 2.494175707852142

Epoch: 6| Step: 7
Training loss: 3.2106479040824856
Validation loss: 2.4991707852008673

Epoch: 6| Step: 8
Training loss: 3.23119577624278
Validation loss: 2.495284004928937

Epoch: 6| Step: 9
Training loss: 2.4723483552319077
Validation loss: 2.4956874362333528

Epoch: 6| Step: 10
Training loss: 2.331290940648801
Validation loss: 2.500488510394707

Epoch: 6| Step: 11
Training loss: 2.323309507352726
Validation loss: 2.4932348669955955

Epoch: 6| Step: 12
Training loss: 3.1301047783519826
Validation loss: 2.4833249389342487

Epoch: 6| Step: 13
Training loss: 3.232398419712862
Validation loss: 2.483063144882822

Epoch: 178| Step: 0
Training loss: 2.6999378267829894
Validation loss: 2.4850114990048877

Epoch: 6| Step: 1
Training loss: 2.8540157268922233
Validation loss: 2.4873386335663614

Epoch: 6| Step: 2
Training loss: 2.875407977803908
Validation loss: 2.4781319639270007

Epoch: 6| Step: 3
Training loss: 2.6968588111365026
Validation loss: 2.4781844903766204

Epoch: 6| Step: 4
Training loss: 2.796397333539636
Validation loss: 2.481667924200501

Epoch: 6| Step: 5
Training loss: 2.587748466761749
Validation loss: 2.479949614176412

Epoch: 6| Step: 6
Training loss: 2.7544143099887055
Validation loss: 2.4864800264388345

Epoch: 6| Step: 7
Training loss: 2.623544471109348
Validation loss: 2.4821036423109333

Epoch: 6| Step: 8
Training loss: 2.393599411333746
Validation loss: 2.4850625709171026

Epoch: 6| Step: 9
Training loss: 3.026015018383004
Validation loss: 2.495123047114711

Epoch: 6| Step: 10
Training loss: 3.049300416854096
Validation loss: 2.5058819046921466

Epoch: 6| Step: 11
Training loss: 2.9879758192562336
Validation loss: 2.494222959764087

Epoch: 6| Step: 12
Training loss: 3.2756829401462584
Validation loss: 2.516723594708919

Epoch: 6| Step: 13
Training loss: 2.5498682698650437
Validation loss: 2.5233366098506065

Epoch: 179| Step: 0
Training loss: 2.811600604891417
Validation loss: 2.5246680745853145

Epoch: 6| Step: 1
Training loss: 2.845968198768799
Validation loss: 2.519746874922685

Epoch: 6| Step: 2
Training loss: 2.9757606046946448
Validation loss: 2.5271729206490043

Epoch: 6| Step: 3
Training loss: 2.9540542674416517
Validation loss: 2.526168451319078

Epoch: 6| Step: 4
Training loss: 2.6824309871502705
Validation loss: 2.5435784639163295

Epoch: 6| Step: 5
Training loss: 2.3018900817493027
Validation loss: 2.5279517927661743

Epoch: 6| Step: 6
Training loss: 2.954096235790652
Validation loss: 2.5471683416057567

Epoch: 6| Step: 7
Training loss: 3.1482109196540353
Validation loss: 2.5359161101281837

Epoch: 6| Step: 8
Training loss: 3.163873059288335
Validation loss: 2.514671325802441

Epoch: 6| Step: 9
Training loss: 2.5628854415182967
Validation loss: 2.5109501552953954

Epoch: 6| Step: 10
Training loss: 2.8937967580885884
Validation loss: 2.5060546733419744

Epoch: 6| Step: 11
Training loss: 2.49416547865945
Validation loss: 2.4999785873562557

Epoch: 6| Step: 12
Training loss: 3.008412328582891
Validation loss: 2.500711281404785

Epoch: 6| Step: 13
Training loss: 2.156135334891329
Validation loss: 2.494145316172879

Epoch: 180| Step: 0
Training loss: 2.5980043565215833
Validation loss: 2.4987783420933893

Epoch: 6| Step: 1
Training loss: 2.719819571036454
Validation loss: 2.487693970380689

Epoch: 6| Step: 2
Training loss: 2.842100566354481
Validation loss: 2.484146028155758

Epoch: 6| Step: 3
Training loss: 2.944127823542555
Validation loss: 2.49037722739839

Epoch: 6| Step: 4
Training loss: 2.704504994846724
Validation loss: 2.496917985483006

Epoch: 6| Step: 5
Training loss: 3.2551204252452965
Validation loss: 2.4982631592637117

Epoch: 6| Step: 6
Training loss: 1.9171606408610682
Validation loss: 2.507620511906368

Epoch: 6| Step: 7
Training loss: 2.475234773848522
Validation loss: 2.5108615670106564

Epoch: 6| Step: 8
Training loss: 2.645448331280375
Validation loss: 2.5305275158797094

Epoch: 6| Step: 9
Training loss: 2.526187685387164
Validation loss: 2.546755087997979

Epoch: 6| Step: 10
Training loss: 3.2339434497067012
Validation loss: 2.573464869821068

Epoch: 6| Step: 11
Training loss: 2.7469406449911675
Validation loss: 2.5810630387587685

Epoch: 6| Step: 12
Training loss: 2.934913957884549
Validation loss: 2.571844770358798

Epoch: 6| Step: 13
Training loss: 4.22355209008844
Validation loss: 2.5641675516006686

Epoch: 181| Step: 0
Training loss: 2.9926953395229923
Validation loss: 2.524218100573488

Epoch: 6| Step: 1
Training loss: 2.983502485143497
Validation loss: 2.509099400702454

Epoch: 6| Step: 2
Training loss: 2.5466993774523545
Validation loss: 2.5184686570660997

Epoch: 6| Step: 3
Training loss: 2.929911775269736
Validation loss: 2.4980391185298556

Epoch: 6| Step: 4
Training loss: 2.51614582996425
Validation loss: 2.494812744477695

Epoch: 6| Step: 5
Training loss: 3.0040470482180726
Validation loss: 2.495271049452818

Epoch: 6| Step: 6
Training loss: 3.0111129289960203
Validation loss: 2.4928212154290232

Epoch: 6| Step: 7
Training loss: 2.730590468328251
Validation loss: 2.497364934038726

Epoch: 6| Step: 8
Training loss: 2.7499758979434747
Validation loss: 2.490202918082204

Epoch: 6| Step: 9
Training loss: 2.4013794987484336
Validation loss: 2.5107788252251235

Epoch: 6| Step: 10
Training loss: 2.8608503027335908
Validation loss: 2.516777230737736

Epoch: 6| Step: 11
Training loss: 2.5728083496356815
Validation loss: 2.5284337752112247

Epoch: 6| Step: 12
Training loss: 3.11128889060322
Validation loss: 2.535103798681446

Epoch: 6| Step: 13
Training loss: 3.507487870383684
Validation loss: 2.5373825939996233

Epoch: 182| Step: 0
Training loss: 2.7259398353301645
Validation loss: 2.5272508368202717

Epoch: 6| Step: 1
Training loss: 3.372313949396025
Validation loss: 2.546853720750159

Epoch: 6| Step: 2
Training loss: 2.8235178984028626
Validation loss: 2.5444351408404837

Epoch: 6| Step: 3
Training loss: 2.9633812796708447
Validation loss: 2.519764237133611

Epoch: 6| Step: 4
Training loss: 2.9083229793448075
Validation loss: 2.505086695321772

Epoch: 6| Step: 5
Training loss: 3.005443402930385
Validation loss: 2.5023867960127677

Epoch: 6| Step: 6
Training loss: 2.11238143859059
Validation loss: 2.5022784709814965

Epoch: 6| Step: 7
Training loss: 2.7194409424193497
Validation loss: 2.4962398831561177

Epoch: 6| Step: 8
Training loss: 2.5659579694045522
Validation loss: 2.506572135652317

Epoch: 6| Step: 9
Training loss: 2.7782825541151297
Validation loss: 2.503250745543737

Epoch: 6| Step: 10
Training loss: 3.0206527305196795
Validation loss: 2.5188971097040183

Epoch: 6| Step: 11
Training loss: 3.269761964959394
Validation loss: 2.5210004293665755

Epoch: 6| Step: 12
Training loss: 2.4144295718913176
Validation loss: 2.5291426158290666

Epoch: 6| Step: 13
Training loss: 2.458726743695768
Validation loss: 2.5194929446410113

Epoch: 183| Step: 0
Training loss: 2.5709311253904614
Validation loss: 2.5251008684009766

Epoch: 6| Step: 1
Training loss: 2.709889585913156
Validation loss: 2.5116725213049245

Epoch: 6| Step: 2
Training loss: 2.9279079882021444
Validation loss: 2.50116572837659

Epoch: 6| Step: 3
Training loss: 3.1232334484412005
Validation loss: 2.4845671860283844

Epoch: 6| Step: 4
Training loss: 2.7961407768598767
Validation loss: 2.475800984822751

Epoch: 6| Step: 5
Training loss: 2.595793321361337
Validation loss: 2.476590452291701

Epoch: 6| Step: 6
Training loss: 2.3336057730978985
Validation loss: 2.4810705701392757

Epoch: 6| Step: 7
Training loss: 2.9720520929466354
Validation loss: 2.4728382653175203

Epoch: 6| Step: 8
Training loss: 2.8822255764741316
Validation loss: 2.4709651495659877

Epoch: 6| Step: 9
Training loss: 2.8561363013945176
Validation loss: 2.482832857400588

Epoch: 6| Step: 10
Training loss: 3.4071262177560584
Validation loss: 2.4893564422998185

Epoch: 6| Step: 11
Training loss: 2.8327268811609696
Validation loss: 2.5058293020160867

Epoch: 6| Step: 12
Training loss: 2.3747543408685194
Validation loss: 2.4987966327985727

Epoch: 6| Step: 13
Training loss: 2.9311048004041322
Validation loss: 2.497456613513805

Epoch: 184| Step: 0
Training loss: 2.6539124918570347
Validation loss: 2.503410263227434

Epoch: 6| Step: 1
Training loss: 2.969265220506082
Validation loss: 2.482187490752587

Epoch: 6| Step: 2
Training loss: 3.089281342028446
Validation loss: 2.4961387574629983

Epoch: 6| Step: 3
Training loss: 3.1217616277352747
Validation loss: 2.476515896618358

Epoch: 6| Step: 4
Training loss: 2.4618958559917825
Validation loss: 2.475102704087149

Epoch: 6| Step: 5
Training loss: 2.7375551749465186
Validation loss: 2.4655686903037815

Epoch: 6| Step: 6
Training loss: 3.3175767106915917
Validation loss: 2.4767843136580407

Epoch: 6| Step: 7
Training loss: 2.1393004168772376
Validation loss: 2.468780619155043

Epoch: 6| Step: 8
Training loss: 2.7834439999932874
Validation loss: 2.477639810716088

Epoch: 6| Step: 9
Training loss: 2.676145119534003
Validation loss: 2.477760572490384

Epoch: 6| Step: 10
Training loss: 2.578427198789605
Validation loss: 2.471503633687753

Epoch: 6| Step: 11
Training loss: 2.9006901544619312
Validation loss: 2.4822885579116787

Epoch: 6| Step: 12
Training loss: 2.9785029776883127
Validation loss: 2.4806356471929636

Epoch: 6| Step: 13
Training loss: 2.5810849855155125
Validation loss: 2.5077013822931264

Epoch: 185| Step: 0
Training loss: 2.9604623861270136
Validation loss: 2.5157182498240345

Epoch: 6| Step: 1
Training loss: 3.334495214781743
Validation loss: 2.539467812269804

Epoch: 6| Step: 2
Training loss: 2.479632379295406
Validation loss: 2.5860791094627027

Epoch: 6| Step: 3
Training loss: 2.31689077523734
Validation loss: 2.607871154936745

Epoch: 6| Step: 4
Training loss: 2.8873221008192687
Validation loss: 2.5858013564721074

Epoch: 6| Step: 5
Training loss: 2.8236738552517924
Validation loss: 2.5550029632995552

Epoch: 6| Step: 6
Training loss: 3.3058748028744636
Validation loss: 2.501987611600626

Epoch: 6| Step: 7
Training loss: 2.554339277233742
Validation loss: 2.469243214920526

Epoch: 6| Step: 8
Training loss: 3.252567304285753
Validation loss: 2.473113805968352

Epoch: 6| Step: 9
Training loss: 1.9033443631433258
Validation loss: 2.474873578772825

Epoch: 6| Step: 10
Training loss: 2.841623202650606
Validation loss: 2.477877347714331

Epoch: 6| Step: 11
Training loss: 3.1672338345887674
Validation loss: 2.485721295843749

Epoch: 6| Step: 12
Training loss: 2.806813743736625
Validation loss: 2.481593466319722

Epoch: 6| Step: 13
Training loss: 2.717577188022019
Validation loss: 2.4830750355907023

Epoch: 186| Step: 0
Training loss: 2.8698973777580106
Validation loss: 2.4757455094339744

Epoch: 6| Step: 1
Training loss: 2.9255450857519
Validation loss: 2.4838829923194075

Epoch: 6| Step: 2
Training loss: 3.0780376286378544
Validation loss: 2.47781358895448

Epoch: 6| Step: 3
Training loss: 2.840972214430994
Validation loss: 2.487791978966143

Epoch: 6| Step: 4
Training loss: 2.670520104317411
Validation loss: 2.4762343395030912

Epoch: 6| Step: 5
Training loss: 2.5929720527740527
Validation loss: 2.4811567152651515

Epoch: 6| Step: 6
Training loss: 3.3071176237834456
Validation loss: 2.489591772437847

Epoch: 6| Step: 7
Training loss: 2.8025170218693467
Validation loss: 2.501261757776495

Epoch: 6| Step: 8
Training loss: 3.0574486002808574
Validation loss: 2.5296927943535272

Epoch: 6| Step: 9
Training loss: 2.254538092153727
Validation loss: 2.5412665961219036

Epoch: 6| Step: 10
Training loss: 2.727806354104551
Validation loss: 2.558021228983548

Epoch: 6| Step: 11
Training loss: 2.676742492431533
Validation loss: 2.5714547787421558

Epoch: 6| Step: 12
Training loss: 2.4437596079449673
Validation loss: 2.556434634267362

Epoch: 6| Step: 13
Training loss: 3.4100180966073266
Validation loss: 2.548514111423328

Epoch: 187| Step: 0
Training loss: 2.185746934613065
Validation loss: 2.4928235344910195

Epoch: 6| Step: 1
Training loss: 3.1962190941490127
Validation loss: 2.4817629282043754

Epoch: 6| Step: 2
Training loss: 2.918753358892105
Validation loss: 2.484284925385455

Epoch: 6| Step: 3
Training loss: 2.702194847643098
Validation loss: 2.4808608012954076

Epoch: 6| Step: 4
Training loss: 3.181738489564943
Validation loss: 2.486938493410324

Epoch: 6| Step: 5
Training loss: 2.6485763108327083
Validation loss: 2.487366912067459

Epoch: 6| Step: 6
Training loss: 2.5396973740526683
Validation loss: 2.490082215613442

Epoch: 6| Step: 7
Training loss: 3.3512514765905865
Validation loss: 2.4899116221060362

Epoch: 6| Step: 8
Training loss: 2.956619052553749
Validation loss: 2.483840479342033

Epoch: 6| Step: 9
Training loss: 2.963419415053597
Validation loss: 2.4867316484240005

Epoch: 6| Step: 10
Training loss: 2.8154532292308336
Validation loss: 2.4876081217164083

Epoch: 6| Step: 11
Training loss: 2.312512165759278
Validation loss: 2.4876821491551078

Epoch: 6| Step: 12
Training loss: 3.258384306786179
Validation loss: 2.4889612795877296

Epoch: 6| Step: 13
Training loss: 2.15256749701923
Validation loss: 2.4873444543031735

Epoch: 188| Step: 0
Training loss: 2.531394106683519
Validation loss: 2.4775216661738098

Epoch: 6| Step: 1
Training loss: 2.6208617879498424
Validation loss: 2.4857925526336064

Epoch: 6| Step: 2
Training loss: 3.22897935549651
Validation loss: 2.4910947945196034

Epoch: 6| Step: 3
Training loss: 2.863543364430786
Validation loss: 2.5094760512416108

Epoch: 6| Step: 4
Training loss: 2.344903890759059
Validation loss: 2.5100610105212198

Epoch: 6| Step: 5
Training loss: 2.7073921524505606
Validation loss: 2.517142054770218

Epoch: 6| Step: 6
Training loss: 2.8159697428508297
Validation loss: 2.5246761635411628

Epoch: 6| Step: 7
Training loss: 2.418095747119276
Validation loss: 2.542274461599785

Epoch: 6| Step: 8
Training loss: 2.5598909074665435
Validation loss: 2.559658927663817

Epoch: 6| Step: 9
Training loss: 3.1807616572857174
Validation loss: 2.5720069821185976

Epoch: 6| Step: 10
Training loss: 3.205258435855836
Validation loss: 2.600789611213703

Epoch: 6| Step: 11
Training loss: 3.0347640914608687
Validation loss: 2.611241457674869

Epoch: 6| Step: 12
Training loss: 2.928553165817471
Validation loss: 2.6062423734075524

Epoch: 6| Step: 13
Training loss: 3.0723837352634558
Validation loss: 2.5780679795269865

Epoch: 189| Step: 0
Training loss: 2.9885963822297024
Validation loss: 2.5528114758436318

Epoch: 6| Step: 1
Training loss: 2.652378447225646
Validation loss: 2.5135384626446196

Epoch: 6| Step: 2
Training loss: 2.3069628846515213
Validation loss: 2.4897024303206856

Epoch: 6| Step: 3
Training loss: 3.369712926936201
Validation loss: 2.4763923411362447

Epoch: 6| Step: 4
Training loss: 2.6246917180280542
Validation loss: 2.476716561308471

Epoch: 6| Step: 5
Training loss: 2.848180819364768
Validation loss: 2.4706797095317645

Epoch: 6| Step: 6
Training loss: 3.0635764896437543
Validation loss: 2.4725215628749275

Epoch: 6| Step: 7
Training loss: 2.2630335226167784
Validation loss: 2.4703206758655143

Epoch: 6| Step: 8
Training loss: 3.239977273979075
Validation loss: 2.4745294873823025

Epoch: 6| Step: 9
Training loss: 2.5450023483235555
Validation loss: 2.480203744770249

Epoch: 6| Step: 10
Training loss: 2.6792189296847604
Validation loss: 2.470297054922675

Epoch: 6| Step: 11
Training loss: 2.3269601250261926
Validation loss: 2.470471085568254

Epoch: 6| Step: 12
Training loss: 3.622136267387847
Validation loss: 2.468200816697405

Epoch: 6| Step: 13
Training loss: 2.464945118507887
Validation loss: 2.4629525915091253

Epoch: 190| Step: 0
Training loss: 2.7241225378508225
Validation loss: 2.4681639447548656

Epoch: 6| Step: 1
Training loss: 2.4322331576011726
Validation loss: 2.4670433956809257

Epoch: 6| Step: 2
Training loss: 3.0439041130011812
Validation loss: 2.4781936351927114

Epoch: 6| Step: 3
Training loss: 3.3509930747156123
Validation loss: 2.49466812931219

Epoch: 6| Step: 4
Training loss: 2.6267424658506355
Validation loss: 2.490313124677246

Epoch: 6| Step: 5
Training loss: 3.0496211270007807
Validation loss: 2.4921774303207003

Epoch: 6| Step: 6
Training loss: 2.5562936009650215
Validation loss: 2.5005337114689374

Epoch: 6| Step: 7
Training loss: 2.5468783700370725
Validation loss: 2.498184697649868

Epoch: 6| Step: 8
Training loss: 2.7171462140887033
Validation loss: 2.4906870270975876

Epoch: 6| Step: 9
Training loss: 2.8438512763130053
Validation loss: 2.492735921812325

Epoch: 6| Step: 10
Training loss: 2.7973378400532964
Validation loss: 2.4927981799816537

Epoch: 6| Step: 11
Training loss: 3.3826519441275456
Validation loss: 2.503284029371534

Epoch: 6| Step: 12
Training loss: 2.5824787715840714
Validation loss: 2.5010461884488757

Epoch: 6| Step: 13
Training loss: 1.8086721184973285
Validation loss: 2.503003547555589

Epoch: 191| Step: 0
Training loss: 2.727477349205615
Validation loss: 2.516672311667984

Epoch: 6| Step: 1
Training loss: 3.103454474008151
Validation loss: 2.5084735023641844

Epoch: 6| Step: 2
Training loss: 3.186534510975243
Validation loss: 2.50389756972973

Epoch: 6| Step: 3
Training loss: 3.037458844946086
Validation loss: 2.5071273479592735

Epoch: 6| Step: 4
Training loss: 3.028369124485683
Validation loss: 2.5081880411137525

Epoch: 6| Step: 5
Training loss: 2.4638172557366196
Validation loss: 2.5048743249541143

Epoch: 6| Step: 6
Training loss: 3.3025694929459553
Validation loss: 2.501484698714129

Epoch: 6| Step: 7
Training loss: 2.2793916422699496
Validation loss: 2.482962221794446

Epoch: 6| Step: 8
Training loss: 2.456499342359458
Validation loss: 2.4820382878696248

Epoch: 6| Step: 9
Training loss: 2.09955078043239
Validation loss: 2.4773018878611923

Epoch: 6| Step: 10
Training loss: 2.605720748038871
Validation loss: 2.476374348220826

Epoch: 6| Step: 11
Training loss: 3.2466846575489843
Validation loss: 2.47887120839252

Epoch: 6| Step: 12
Training loss: 2.651489120124422
Validation loss: 2.4893460069019113

Epoch: 6| Step: 13
Training loss: 2.4852957308930295
Validation loss: 2.5034384943358465

Epoch: 192| Step: 0
Training loss: 3.316648656390442
Validation loss: 2.5140790092586824

Epoch: 6| Step: 1
Training loss: 2.6312895312024067
Validation loss: 2.55800773537053

Epoch: 6| Step: 2
Training loss: 2.871543132879821
Validation loss: 2.585652938139333

Epoch: 6| Step: 3
Training loss: 3.1974323581105484
Validation loss: 2.5768671640971577

Epoch: 6| Step: 4
Training loss: 2.7881560575683313
Validation loss: 2.552949195892274

Epoch: 6| Step: 5
Training loss: 2.9226347399636152
Validation loss: 2.4998900912336

Epoch: 6| Step: 6
Training loss: 2.5634585192817387
Validation loss: 2.490775106050264

Epoch: 6| Step: 7
Training loss: 3.0368746455212574
Validation loss: 2.4794070412622586

Epoch: 6| Step: 8
Training loss: 2.0522531222927167
Validation loss: 2.4879621881775735

Epoch: 6| Step: 9
Training loss: 2.548324827583776
Validation loss: 2.4762625294738116

Epoch: 6| Step: 10
Training loss: 3.0137006717475447
Validation loss: 2.4738707078183255

Epoch: 6| Step: 11
Training loss: 2.698264631025461
Validation loss: 2.4712926673989135

Epoch: 6| Step: 12
Training loss: 2.8964812471008905
Validation loss: 2.4729358892299027

Epoch: 6| Step: 13
Training loss: 2.227632713774155
Validation loss: 2.4786957051904115

Epoch: 193| Step: 0
Training loss: 2.2714290595761004
Validation loss: 2.479145875841712

Epoch: 6| Step: 1
Training loss: 2.384540069185824
Validation loss: 2.4775389921368043

Epoch: 6| Step: 2
Training loss: 2.7111091669350134
Validation loss: 2.4772762544463114

Epoch: 6| Step: 3
Training loss: 3.260422500426382
Validation loss: 2.4979071563260775

Epoch: 6| Step: 4
Training loss: 3.1004850500318804
Validation loss: 2.496564835903897

Epoch: 6| Step: 5
Training loss: 3.0202981584408763
Validation loss: 2.4949600248894854

Epoch: 6| Step: 6
Training loss: 2.900484991625626
Validation loss: 2.507499917875164

Epoch: 6| Step: 7
Training loss: 2.574831436713913
Validation loss: 2.5023207629135724

Epoch: 6| Step: 8
Training loss: 2.5136794628867603
Validation loss: 2.494395994314596

Epoch: 6| Step: 9
Training loss: 3.314527934482797
Validation loss: 2.495029413900376

Epoch: 6| Step: 10
Training loss: 2.3459616843344295
Validation loss: 2.4962161511062417

Epoch: 6| Step: 11
Training loss: 2.7728563156457993
Validation loss: 2.5065658844892726

Epoch: 6| Step: 12
Training loss: 2.2904611942690476
Validation loss: 2.4975280866992193

Epoch: 6| Step: 13
Training loss: 3.326578990058647
Validation loss: 2.4941786022784718

Epoch: 194| Step: 0
Training loss: 2.9264492194252254
Validation loss: 2.4845340497522406

Epoch: 6| Step: 1
Training loss: 2.5256981894714414
Validation loss: 2.493970149767466

Epoch: 6| Step: 2
Training loss: 3.1571712848934506
Validation loss: 2.489439266891866

Epoch: 6| Step: 3
Training loss: 2.7476448898362595
Validation loss: 2.49139386825606

Epoch: 6| Step: 4
Training loss: 2.9024868463945968
Validation loss: 2.4848674467469385

Epoch: 6| Step: 5
Training loss: 3.2899052860807156
Validation loss: 2.480918960596776

Epoch: 6| Step: 6
Training loss: 2.722540307004949
Validation loss: 2.4834528933964197

Epoch: 6| Step: 7
Training loss: 2.481671763974863
Validation loss: 2.485380154489599

Epoch: 6| Step: 8
Training loss: 2.2849922316938778
Validation loss: 2.488793739641583

Epoch: 6| Step: 9
Training loss: 2.984393853732167
Validation loss: 2.4952754523701897

Epoch: 6| Step: 10
Training loss: 3.166608977210603
Validation loss: 2.5073231456771987

Epoch: 6| Step: 11
Training loss: 2.291368384167079
Validation loss: 2.5039717861955273

Epoch: 6| Step: 12
Training loss: 2.546706866934015
Validation loss: 2.5018270266620704

Epoch: 6| Step: 13
Training loss: 2.3334449559714985
Validation loss: 2.5087165172987635

Epoch: 195| Step: 0
Training loss: 2.8860734726825092
Validation loss: 2.5249985481565873

Epoch: 6| Step: 1
Training loss: 2.638564349735999
Validation loss: 2.545067604924276

Epoch: 6| Step: 2
Training loss: 2.4082270835309636
Validation loss: 2.5576316965489396

Epoch: 6| Step: 3
Training loss: 1.8141481206831145
Validation loss: 2.570473289503665

Epoch: 6| Step: 4
Training loss: 3.335926636582136
Validation loss: 2.6185921727198243

Epoch: 6| Step: 5
Training loss: 2.9954217308795092
Validation loss: 2.578155839573384

Epoch: 6| Step: 6
Training loss: 3.0628974812307685
Validation loss: 2.5231688540047914

Epoch: 6| Step: 7
Training loss: 3.093166874347557
Validation loss: 2.4972441691587806

Epoch: 6| Step: 8
Training loss: 2.1921357217384996
Validation loss: 2.48706996970793

Epoch: 6| Step: 9
Training loss: 2.637616130568261
Validation loss: 2.482104275447875

Epoch: 6| Step: 10
Training loss: 3.2549005388337435
Validation loss: 2.4845985223816753

Epoch: 6| Step: 11
Training loss: 3.0546712655418986
Validation loss: 2.489873515392947

Epoch: 6| Step: 12
Training loss: 3.0300377063482378
Validation loss: 2.4910866942866083

Epoch: 6| Step: 13
Training loss: 2.427666513564069
Validation loss: 2.490888206678022

Epoch: 196| Step: 0
Training loss: 2.655347334130559
Validation loss: 2.4903652686138167

Epoch: 6| Step: 1
Training loss: 3.5215282469188938
Validation loss: 2.4921197991657547

Epoch: 6| Step: 2
Training loss: 3.136539363838465
Validation loss: 2.4906579319714965

Epoch: 6| Step: 3
Training loss: 2.82502770874478
Validation loss: 2.481437335220434

Epoch: 6| Step: 4
Training loss: 2.6998448397946992
Validation loss: 2.485744898102581

Epoch: 6| Step: 5
Training loss: 2.8828614600347873
Validation loss: 2.4855912055771703

Epoch: 6| Step: 6
Training loss: 2.273204988210811
Validation loss: 2.483682913853609

Epoch: 6| Step: 7
Training loss: 3.002776133015061
Validation loss: 2.4795581001570746

Epoch: 6| Step: 8
Training loss: 2.8278931580666096
Validation loss: 2.4842015357614913

Epoch: 6| Step: 9
Training loss: 2.4786660680060497
Validation loss: 2.481596418809998

Epoch: 6| Step: 10
Training loss: 2.6231473106760665
Validation loss: 2.4930086010234924

Epoch: 6| Step: 11
Training loss: 2.2800366035668675
Validation loss: 2.500192844992608

Epoch: 6| Step: 12
Training loss: 2.9021528342953267
Validation loss: 2.5077292343810655

Epoch: 6| Step: 13
Training loss: 3.4236265951188627
Validation loss: 2.5159221971184094

Epoch: 197| Step: 0
Training loss: 3.0293535415396255
Validation loss: 2.5464472338166897

Epoch: 6| Step: 1
Training loss: 2.554683393655912
Validation loss: 2.5721370822404777

Epoch: 6| Step: 2
Training loss: 2.944423713451156
Validation loss: 2.6079325715790813

Epoch: 6| Step: 3
Training loss: 2.43888698144296
Validation loss: 2.6315881099714122

Epoch: 6| Step: 4
Training loss: 3.2734823656307825
Validation loss: 2.677863064498461

Epoch: 6| Step: 5
Training loss: 2.9906824375484504
Validation loss: 2.702832119517562

Epoch: 6| Step: 6
Training loss: 2.6439051372921836
Validation loss: 2.643545290409776

Epoch: 6| Step: 7
Training loss: 2.6435970758168836
Validation loss: 2.5699977218836807

Epoch: 6| Step: 8
Training loss: 2.9815072066638835
Validation loss: 2.55024715129069

Epoch: 6| Step: 9
Training loss: 2.197658276548512
Validation loss: 2.5241809510351065

Epoch: 6| Step: 10
Training loss: 2.687111227614658
Validation loss: 2.5027894557616865

Epoch: 6| Step: 11
Training loss: 3.2283825486317537
Validation loss: 2.5014260408729596

Epoch: 6| Step: 12
Training loss: 2.686120144779444
Validation loss: 2.4911050352922883

Epoch: 6| Step: 13
Training loss: 2.1983133352824313
Validation loss: 2.4788684491539605

Epoch: 198| Step: 0
Training loss: 2.522446003573195
Validation loss: 2.470754678403891

Epoch: 6| Step: 1
Training loss: 2.56805738406967
Validation loss: 2.478349586353693

Epoch: 6| Step: 2
Training loss: 3.0512632411746057
Validation loss: 2.4753899669058774

Epoch: 6| Step: 3
Training loss: 3.4063199937261035
Validation loss: 2.4710184207637553

Epoch: 6| Step: 4
Training loss: 3.0528046641979936
Validation loss: 2.478269972400864

Epoch: 6| Step: 5
Training loss: 2.2826092994483798
Validation loss: 2.4810029265742726

Epoch: 6| Step: 6
Training loss: 2.5100448987372235
Validation loss: 2.4903202515154526

Epoch: 6| Step: 7
Training loss: 2.99582604277833
Validation loss: 2.5032538322533386

Epoch: 6| Step: 8
Training loss: 2.660731047653403
Validation loss: 2.5096512335060637

Epoch: 6| Step: 9
Training loss: 3.258587422589982
Validation loss: 2.509394332383621

Epoch: 6| Step: 10
Training loss: 2.456116911022179
Validation loss: 2.524556280652232

Epoch: 6| Step: 11
Training loss: 2.9062951197249416
Validation loss: 2.5387790740717175

Epoch: 6| Step: 12
Training loss: 2.329122342510813
Validation loss: 2.536093724791529

Epoch: 6| Step: 13
Training loss: 2.7457172683783546
Validation loss: 2.5617693648047686

Epoch: 199| Step: 0
Training loss: 2.7686986707489023
Validation loss: 2.5444622447459118

Epoch: 6| Step: 1
Training loss: 3.110234434117219
Validation loss: 2.5516395797487252

Epoch: 6| Step: 2
Training loss: 2.3112954791614566
Validation loss: 2.5493332638858734

Epoch: 6| Step: 3
Training loss: 2.0964774970191815
Validation loss: 2.550946955333232

Epoch: 6| Step: 4
Training loss: 3.6765980314717535
Validation loss: 2.551851171531901

Epoch: 6| Step: 5
Training loss: 2.564984954284205
Validation loss: 2.5434429407766426

Epoch: 6| Step: 6
Training loss: 2.6485847724770055
Validation loss: 2.535238667407764

Epoch: 6| Step: 7
Training loss: 3.300159138396983
Validation loss: 2.5264597374374014

Epoch: 6| Step: 8
Training loss: 2.279633040428049
Validation loss: 2.5107900874249265

Epoch: 6| Step: 9
Training loss: 2.7348044793853745
Validation loss: 2.5034185027952396

Epoch: 6| Step: 10
Training loss: 2.413686284745939
Validation loss: 2.494428580262959

Epoch: 6| Step: 11
Training loss: 2.7229507265147306
Validation loss: 2.4932478916614778

Epoch: 6| Step: 12
Training loss: 3.021994865115213
Validation loss: 2.488177309514959

Epoch: 6| Step: 13
Training loss: 2.6037418069770095
Validation loss: 2.481467374764328

Epoch: 200| Step: 0
Training loss: 2.862032296564305
Validation loss: 2.472785982980344

Epoch: 6| Step: 1
Training loss: 3.110658313710029
Validation loss: 2.4795847092464887

Epoch: 6| Step: 2
Training loss: 3.2153902759649595
Validation loss: 2.4785960802322764

Epoch: 6| Step: 3
Training loss: 2.774843702983786
Validation loss: 2.477724868173578

Epoch: 6| Step: 4
Training loss: 2.821086153977805
Validation loss: 2.4726609819333873

Epoch: 6| Step: 5
Training loss: 3.0571750356511154
Validation loss: 2.4756631007034016

Epoch: 6| Step: 6
Training loss: 2.3549832528525165
Validation loss: 2.4793784382943778

Epoch: 6| Step: 7
Training loss: 2.5258005138527486
Validation loss: 2.489516389962528

Epoch: 6| Step: 8
Training loss: 2.801567701429569
Validation loss: 2.487637280337654

Epoch: 6| Step: 9
Training loss: 2.568439763772823
Validation loss: 2.5015831180190227

Epoch: 6| Step: 10
Training loss: 2.880478324905262
Validation loss: 2.5197930816415943

Epoch: 6| Step: 11
Training loss: 2.207827372139787
Validation loss: 2.5240794029913514

Epoch: 6| Step: 12
Training loss: 2.955739312287562
Validation loss: 2.5284440178545156

Epoch: 6| Step: 13
Training loss: 2.1827761188989574
Validation loss: 2.5033575113274615

Epoch: 201| Step: 0
Training loss: 2.657088652217575
Validation loss: 2.499276524118429

Epoch: 6| Step: 1
Training loss: 2.6044416562167805
Validation loss: 2.496805240647878

Epoch: 6| Step: 2
Training loss: 2.4373168876532745
Validation loss: 2.4999670600771946

Epoch: 6| Step: 3
Training loss: 3.0757365763440383
Validation loss: 2.490079111546723

Epoch: 6| Step: 4
Training loss: 2.650223211568504
Validation loss: 2.491889400104512

Epoch: 6| Step: 5
Training loss: 2.4747702674979934
Validation loss: 2.481728447733154

Epoch: 6| Step: 6
Training loss: 2.215204118748366
Validation loss: 2.488772871293776

Epoch: 6| Step: 7
Training loss: 3.409961323448844
Validation loss: 2.487556733117084

Epoch: 6| Step: 8
Training loss: 2.797259512102096
Validation loss: 2.4899629919625648

Epoch: 6| Step: 9
Training loss: 2.5142630924408556
Validation loss: 2.4841089274507135

Epoch: 6| Step: 10
Training loss: 2.9686484871624716
Validation loss: 2.48882427495497

Epoch: 6| Step: 11
Training loss: 2.8170453112407503
Validation loss: 2.4866808149194854

Epoch: 6| Step: 12
Training loss: 3.051431857592557
Validation loss: 2.4742300661309424

Epoch: 6| Step: 13
Training loss: 2.826608831005894
Validation loss: 2.470848322615386

Epoch: 202| Step: 0
Training loss: 2.681411055416142
Validation loss: 2.474292843304449

Epoch: 6| Step: 1
Training loss: 2.5564635283212946
Validation loss: 2.4857473145239504

Epoch: 6| Step: 2
Training loss: 2.526227324174965
Validation loss: 2.4874883620852057

Epoch: 6| Step: 3
Training loss: 3.184624964792846
Validation loss: 2.4947087210767087

Epoch: 6| Step: 4
Training loss: 2.5736107346965116
Validation loss: 2.520725783560078

Epoch: 6| Step: 5
Training loss: 2.6747009324071773
Validation loss: 2.5497665011240342

Epoch: 6| Step: 6
Training loss: 2.684820125386871
Validation loss: 2.558926637723418

Epoch: 6| Step: 7
Training loss: 2.57433887253519
Validation loss: 2.548977162796292

Epoch: 6| Step: 8
Training loss: 2.8196450074951342
Validation loss: 2.559119354846229

Epoch: 6| Step: 9
Training loss: 2.6855740410557805
Validation loss: 2.542996769784069

Epoch: 6| Step: 10
Training loss: 2.4302418557831023
Validation loss: 2.522351873284175

Epoch: 6| Step: 11
Training loss: 2.9844323597134164
Validation loss: 2.5082677883384563

Epoch: 6| Step: 12
Training loss: 2.801851076240523
Validation loss: 2.5076602714142653

Epoch: 6| Step: 13
Training loss: 3.532982730265048
Validation loss: 2.4971079269627205

Epoch: 203| Step: 0
Training loss: 1.9638489770258378
Validation loss: 2.485839593660322

Epoch: 6| Step: 1
Training loss: 2.848674157921157
Validation loss: 2.4741136534313717

Epoch: 6| Step: 2
Training loss: 2.516202303590229
Validation loss: 2.4782701860143015

Epoch: 6| Step: 3
Training loss: 2.7890863497700082
Validation loss: 2.472840120008723

Epoch: 6| Step: 4
Training loss: 2.6530444381218747
Validation loss: 2.4656038539979996

Epoch: 6| Step: 5
Training loss: 2.8507587292932386
Validation loss: 2.4682005019810513

Epoch: 6| Step: 6
Training loss: 2.88709534290833
Validation loss: 2.462383686402563

Epoch: 6| Step: 7
Training loss: 2.8284682597712147
Validation loss: 2.4677305805069185

Epoch: 6| Step: 8
Training loss: 2.9657463539304993
Validation loss: 2.478553680334897

Epoch: 6| Step: 9
Training loss: 2.8053810728432578
Validation loss: 2.4843862271082626

Epoch: 6| Step: 10
Training loss: 3.0716981357639717
Validation loss: 2.490886047914514

Epoch: 6| Step: 11
Training loss: 3.0757582807276718
Validation loss: 2.5164903963528302

Epoch: 6| Step: 12
Training loss: 2.86665958876808
Validation loss: 2.575189900885172

Epoch: 6| Step: 13
Training loss: 2.095957716580853
Validation loss: 2.587992947073066

Epoch: 204| Step: 0
Training loss: 2.738570651054201
Validation loss: 2.604956475046741

Epoch: 6| Step: 1
Training loss: 2.71314670570758
Validation loss: 2.5986928641275

Epoch: 6| Step: 2
Training loss: 3.0085597311477446
Validation loss: 2.600266122490026

Epoch: 6| Step: 3
Training loss: 2.509440621436066
Validation loss: 2.5482706121142056

Epoch: 6| Step: 4
Training loss: 3.044461590501282
Validation loss: 2.5416844856717504

Epoch: 6| Step: 5
Training loss: 2.707063660971197
Validation loss: 2.521394012495108

Epoch: 6| Step: 6
Training loss: 2.692781625681139
Validation loss: 2.5259492560176966

Epoch: 6| Step: 7
Training loss: 2.753612486409676
Validation loss: 2.490910263010077

Epoch: 6| Step: 8
Training loss: 3.0278891582787137
Validation loss: 2.4904849269610505

Epoch: 6| Step: 9
Training loss: 3.1175767851476417
Validation loss: 2.4865036163405727

Epoch: 6| Step: 10
Training loss: 2.642381614263532
Validation loss: 2.4982823870345636

Epoch: 6| Step: 11
Training loss: 1.997727354572234
Validation loss: 2.4958749127283806

Epoch: 6| Step: 12
Training loss: 3.0163437377174676
Validation loss: 2.5053965926941992

Epoch: 6| Step: 13
Training loss: 2.0869381679629693
Validation loss: 2.509870849129846

Epoch: 205| Step: 0
Training loss: 2.8570163358195293
Validation loss: 2.537336311534558

Epoch: 6| Step: 1
Training loss: 2.579492472179747
Validation loss: 2.548170257484936

Epoch: 6| Step: 2
Training loss: 2.669136115915718
Validation loss: 2.595400612560929

Epoch: 6| Step: 3
Training loss: 2.4278551656269016
Validation loss: 2.5949968582269607

Epoch: 6| Step: 4
Training loss: 2.6340607986327034
Validation loss: 2.573252728001203

Epoch: 6| Step: 5
Training loss: 2.5930862496681004
Validation loss: 2.57404488450942

Epoch: 6| Step: 6
Training loss: 2.7291484473011
Validation loss: 2.5616308549609395

Epoch: 6| Step: 7
Training loss: 2.958391932233968
Validation loss: 2.541425936303186

Epoch: 6| Step: 8
Training loss: 2.8839623450520677
Validation loss: 2.5379578474823568

Epoch: 6| Step: 9
Training loss: 2.9767126010484657
Validation loss: 2.513873498990722

Epoch: 6| Step: 10
Training loss: 2.682375080083221
Validation loss: 2.5061920310700643

Epoch: 6| Step: 11
Training loss: 2.3007090222043063
Validation loss: 2.496196439612521

Epoch: 6| Step: 12
Training loss: 2.6733958059924547
Validation loss: 2.500194437402828

Epoch: 6| Step: 13
Training loss: 3.5702813812836274
Validation loss: 2.494039415216272

Epoch: 206| Step: 0
Training loss: 2.704278600538157
Validation loss: 2.4915966457738

Epoch: 6| Step: 1
Training loss: 3.200221238833032
Validation loss: 2.482148596698135

Epoch: 6| Step: 2
Training loss: 2.957700867720162
Validation loss: 2.4960010847790572

Epoch: 6| Step: 3
Training loss: 2.765951536050528
Validation loss: 2.4924345714051754

Epoch: 6| Step: 4
Training loss: 2.343499539026305
Validation loss: 2.4938639514823278

Epoch: 6| Step: 5
Training loss: 2.899029036461699
Validation loss: 2.489406957534367

Epoch: 6| Step: 6
Training loss: 2.712714676338477
Validation loss: 2.4788809298232417

Epoch: 6| Step: 7
Training loss: 2.9456955233168394
Validation loss: 2.487819977176888

Epoch: 6| Step: 8
Training loss: 1.9952863937976237
Validation loss: 2.4953083314532756

Epoch: 6| Step: 9
Training loss: 2.5057705085202095
Validation loss: 2.4988436772971947

Epoch: 6| Step: 10
Training loss: 2.6982409504498612
Validation loss: 2.506004721815577

Epoch: 6| Step: 11
Training loss: 2.7697350947549455
Validation loss: 2.4902996533222734

Epoch: 6| Step: 12
Training loss: 3.040002515691419
Validation loss: 2.502873471604901

Epoch: 6| Step: 13
Training loss: 2.447126891518574
Validation loss: 2.5050758516272134

Epoch: 207| Step: 0
Training loss: 2.390353418020694
Validation loss: 2.5010830922346923

Epoch: 6| Step: 1
Training loss: 2.3068394845746796
Validation loss: 2.4942668806680643

Epoch: 6| Step: 2
Training loss: 2.9986292568511943
Validation loss: 2.5004499471466124

Epoch: 6| Step: 3
Training loss: 2.2725560947457093
Validation loss: 2.479212259928287

Epoch: 6| Step: 4
Training loss: 2.3705004180669667
Validation loss: 2.491675842144247

Epoch: 6| Step: 5
Training loss: 3.411695135308702
Validation loss: 2.480927788431676

Epoch: 6| Step: 6
Training loss: 2.8299293452632575
Validation loss: 2.4774922829509842

Epoch: 6| Step: 7
Training loss: 2.275472772122295
Validation loss: 2.478826153200103

Epoch: 6| Step: 8
Training loss: 2.6371280606782728
Validation loss: 2.4770458439835004

Epoch: 6| Step: 9
Training loss: 3.178020668380296
Validation loss: 2.4833472353566832

Epoch: 6| Step: 10
Training loss: 2.891049740490424
Validation loss: 2.4873030450945794

Epoch: 6| Step: 11
Training loss: 3.121975770532499
Validation loss: 2.489083762616512

Epoch: 6| Step: 12
Training loss: 2.6135456310701817
Validation loss: 2.510311973314379

Epoch: 6| Step: 13
Training loss: 2.7300839132470567
Validation loss: 2.5284258427614326

Epoch: 208| Step: 0
Training loss: 2.3855116268619003
Validation loss: 2.597009965746762

Epoch: 6| Step: 1
Training loss: 2.8635700075022106
Validation loss: 2.6696484316015057

Epoch: 6| Step: 2
Training loss: 3.009546825221479
Validation loss: 2.732513710240292

Epoch: 6| Step: 3
Training loss: 3.1471320160024208
Validation loss: 2.7034553773107675

Epoch: 6| Step: 4
Training loss: 2.4968728534560354
Validation loss: 2.621778627888748

Epoch: 6| Step: 5
Training loss: 2.593374569850236
Validation loss: 2.5849516447654044

Epoch: 6| Step: 6
Training loss: 2.915555760582604
Validation loss: 2.5212815212670643

Epoch: 6| Step: 7
Training loss: 2.563014188211487
Validation loss: 2.509226072504706

Epoch: 6| Step: 8
Training loss: 2.740236115132199
Validation loss: 2.5000492634585303

Epoch: 6| Step: 9
Training loss: 1.996731829697053
Validation loss: 2.4860164054241056

Epoch: 6| Step: 10
Training loss: 2.9056159527613774
Validation loss: 2.4998272877172174

Epoch: 6| Step: 11
Training loss: 3.0806265798058914
Validation loss: 2.483290437824926

Epoch: 6| Step: 12
Training loss: 3.0930705239475675
Validation loss: 2.4909956006138105

Epoch: 6| Step: 13
Training loss: 2.931477968505645
Validation loss: 2.4954225544542794

Epoch: 209| Step: 0
Training loss: 3.1295166944115484
Validation loss: 2.4971862863826613

Epoch: 6| Step: 1
Training loss: 3.0471857939445344
Validation loss: 2.508656566189281

Epoch: 6| Step: 2
Training loss: 2.5672470410919
Validation loss: 2.502131121863853

Epoch: 6| Step: 3
Training loss: 2.8383983517552767
Validation loss: 2.538227977437376

Epoch: 6| Step: 4
Training loss: 2.7093664888558466
Validation loss: 2.524230606859127

Epoch: 6| Step: 5
Training loss: 2.518375291237076
Validation loss: 2.514376777576783

Epoch: 6| Step: 6
Training loss: 2.308266863456942
Validation loss: 2.519566410725894

Epoch: 6| Step: 7
Training loss: 2.8145678230119935
Validation loss: 2.5257304385622508

Epoch: 6| Step: 8
Training loss: 2.893987895505276
Validation loss: 2.504397568949882

Epoch: 6| Step: 9
Training loss: 2.8584796775374373
Validation loss: 2.4988616484619937

Epoch: 6| Step: 10
Training loss: 2.1177914592029246
Validation loss: 2.492793266191549

Epoch: 6| Step: 11
Training loss: 2.748084875303628
Validation loss: 2.5024381295259492

Epoch: 6| Step: 12
Training loss: 2.8330588114269544
Validation loss: 2.5022711691988695

Epoch: 6| Step: 13
Training loss: 2.52042882737173
Validation loss: 2.4962400490167598

Epoch: 210| Step: 0
Training loss: 2.6235492875602344
Validation loss: 2.5016767395874413

Epoch: 6| Step: 1
Training loss: 2.760820860630658
Validation loss: 2.496461173557904

Epoch: 6| Step: 2
Training loss: 2.0727443016377887
Validation loss: 2.4757332656222766

Epoch: 6| Step: 3
Training loss: 2.133939228840703
Validation loss: 2.467273054886764

Epoch: 6| Step: 4
Training loss: 2.631373343215804
Validation loss: 2.476996188227812

Epoch: 6| Step: 5
Training loss: 2.6546238128764355
Validation loss: 2.4794230160980004

Epoch: 6| Step: 6
Training loss: 2.7051117051446862
Validation loss: 2.467572665791477

Epoch: 6| Step: 7
Training loss: 2.4862790278930915
Validation loss: 2.471921542736938

Epoch: 6| Step: 8
Training loss: 2.9190510041190505
Validation loss: 2.483609600216749

Epoch: 6| Step: 9
Training loss: 3.1747597791252438
Validation loss: 2.4953346919407386

Epoch: 6| Step: 10
Training loss: 2.9173591518317328
Validation loss: 2.505386342803683

Epoch: 6| Step: 11
Training loss: 2.8372833169219107
Validation loss: 2.5024441021040094

Epoch: 6| Step: 12
Training loss: 3.2865746301708434
Validation loss: 2.5068364069008586

Epoch: 6| Step: 13
Training loss: 2.7856036625370795
Validation loss: 2.5571495761689276

Epoch: 211| Step: 0
Training loss: 2.3893792390898017
Validation loss: 2.554802009349579

Epoch: 6| Step: 1
Training loss: 2.597101183794811
Validation loss: 2.574572157408261

Epoch: 6| Step: 2
Training loss: 2.815163516754953
Validation loss: 2.5586984960674237

Epoch: 6| Step: 3
Training loss: 2.981175170215231
Validation loss: 2.5430840329909645

Epoch: 6| Step: 4
Training loss: 2.7802391358307266
Validation loss: 2.56896778793538

Epoch: 6| Step: 5
Training loss: 2.269778948872688
Validation loss: 2.5616160603199076

Epoch: 6| Step: 6
Training loss: 3.172230968325959
Validation loss: 2.5666653643768464

Epoch: 6| Step: 7
Training loss: 3.0706557065056166
Validation loss: 2.5374442962411528

Epoch: 6| Step: 8
Training loss: 2.522763944792017
Validation loss: 2.531560725063692

Epoch: 6| Step: 9
Training loss: 2.6586652658121492
Validation loss: 2.5121338933617543

Epoch: 6| Step: 10
Training loss: 2.651632716474858
Validation loss: 2.503779716571534

Epoch: 6| Step: 11
Training loss: 3.0478431141744493
Validation loss: 2.4837401957873473

Epoch: 6| Step: 12
Training loss: 2.7318801397390025
Validation loss: 2.4795516185649924

Epoch: 6| Step: 13
Training loss: 2.04568213728314
Validation loss: 2.4857359311270377

Epoch: 212| Step: 0
Training loss: 2.7043800747856626
Validation loss: 2.4756977878418676

Epoch: 6| Step: 1
Training loss: 3.00361431474169
Validation loss: 2.474763635589749

Epoch: 6| Step: 2
Training loss: 2.6526935779286287
Validation loss: 2.4724286409828236

Epoch: 6| Step: 3
Training loss: 2.2636412255596023
Validation loss: 2.463964643504328

Epoch: 6| Step: 4
Training loss: 2.8328325913690446
Validation loss: 2.467961270628221

Epoch: 6| Step: 5
Training loss: 2.5832316368348924
Validation loss: 2.4717617280841115

Epoch: 6| Step: 6
Training loss: 2.680323667054888
Validation loss: 2.4785819887312117

Epoch: 6| Step: 7
Training loss: 2.912571420735256
Validation loss: 2.4741971820412028

Epoch: 6| Step: 8
Training loss: 1.998185168837869
Validation loss: 2.4842035037422225

Epoch: 6| Step: 9
Training loss: 2.6889917536134202
Validation loss: 2.480566356787167

Epoch: 6| Step: 10
Training loss: 2.6161765807922803
Validation loss: 2.486211994176198

Epoch: 6| Step: 11
Training loss: 2.896273151909397
Validation loss: 2.5063299837387154

Epoch: 6| Step: 12
Training loss: 3.163372199969063
Validation loss: 2.514342225376191

Epoch: 6| Step: 13
Training loss: 3.044391735189885
Validation loss: 2.535225360954179

Epoch: 213| Step: 0
Training loss: 2.91626923896078
Validation loss: 2.565915940051331

Epoch: 6| Step: 1
Training loss: 2.535320353082649
Validation loss: 2.6210978999921952

Epoch: 6| Step: 2
Training loss: 1.7544121299432167
Validation loss: 2.5963920670886282

Epoch: 6| Step: 3
Training loss: 3.0542354005275913
Validation loss: 2.5836618133911524

Epoch: 6| Step: 4
Training loss: 2.5380442294091354
Validation loss: 2.577037980119463

Epoch: 6| Step: 5
Training loss: 2.5671510123819234
Validation loss: 2.5416055009953813

Epoch: 6| Step: 6
Training loss: 3.064992552059017
Validation loss: 2.5149412954043604

Epoch: 6| Step: 7
Training loss: 3.0760918888410584
Validation loss: 2.4894072335260646

Epoch: 6| Step: 8
Training loss: 2.662787078997525
Validation loss: 2.473531217551699

Epoch: 6| Step: 9
Training loss: 2.6797784283839463
Validation loss: 2.4725255449044803

Epoch: 6| Step: 10
Training loss: 2.204286742470177
Validation loss: 2.46959141818427

Epoch: 6| Step: 11
Training loss: 2.720134689418276
Validation loss: 2.4723959610524266

Epoch: 6| Step: 12
Training loss: 3.2416784415403033
Validation loss: 2.465501029292273

Epoch: 6| Step: 13
Training loss: 2.601241174964288
Validation loss: 2.4746863314220464

Epoch: 214| Step: 0
Training loss: 3.0215457646175445
Validation loss: 2.4724135971944197

Epoch: 6| Step: 1
Training loss: 2.920627919446032
Validation loss: 2.47295649832199

Epoch: 6| Step: 2
Training loss: 2.312473812470493
Validation loss: 2.4704106058607005

Epoch: 6| Step: 3
Training loss: 2.413169522846684
Validation loss: 2.478106028743571

Epoch: 6| Step: 4
Training loss: 2.9459519236073857
Validation loss: 2.477348664796427

Epoch: 6| Step: 5
Training loss: 2.23181528576114
Validation loss: 2.4924416937202087

Epoch: 6| Step: 6
Training loss: 3.1091032436598707
Validation loss: 2.501940790163773

Epoch: 6| Step: 7
Training loss: 2.715565361886945
Validation loss: 2.522263130499642

Epoch: 6| Step: 8
Training loss: 3.1047879990398592
Validation loss: 2.5404474951064544

Epoch: 6| Step: 9
Training loss: 2.9134975836897508
Validation loss: 2.5664384700390652

Epoch: 6| Step: 10
Training loss: 2.74045971292617
Validation loss: 2.5944449270558794

Epoch: 6| Step: 11
Training loss: 2.216044536087958
Validation loss: 2.565353844305749

Epoch: 6| Step: 12
Training loss: 2.348769243048854
Validation loss: 2.5614164379007986

Epoch: 6| Step: 13
Training loss: 3.0319562266267406
Validation loss: 2.5491448202787605

Epoch: 215| Step: 0
Training loss: 2.6651573280716514
Validation loss: 2.5225547446050114

Epoch: 6| Step: 1
Training loss: 2.4622931727577893
Validation loss: 2.5222517955265924

Epoch: 6| Step: 2
Training loss: 2.644543871715633
Validation loss: 2.5159442128140017

Epoch: 6| Step: 3
Training loss: 2.4527024798165575
Validation loss: 2.4991279619334383

Epoch: 6| Step: 4
Training loss: 2.6402560546273883
Validation loss: 2.4977760800919184

Epoch: 6| Step: 5
Training loss: 2.6469131629111273
Validation loss: 2.489304432740371

Epoch: 6| Step: 6
Training loss: 2.577518553643923
Validation loss: 2.4819043459110106

Epoch: 6| Step: 7
Training loss: 2.8421482144283607
Validation loss: 2.486034859115241

Epoch: 6| Step: 8
Training loss: 2.6285336642780828
Validation loss: 2.4753241421105354

Epoch: 6| Step: 9
Training loss: 2.7981069398339344
Validation loss: 2.4822728968922916

Epoch: 6| Step: 10
Training loss: 3.086862314448809
Validation loss: 2.4912488904925145

Epoch: 6| Step: 11
Training loss: 2.431154256077903
Validation loss: 2.503361961979135

Epoch: 6| Step: 12
Training loss: 3.0491305878756565
Validation loss: 2.515519677195987

Epoch: 6| Step: 13
Training loss: 2.89848010913551
Validation loss: 2.5130005725313977

Epoch: 216| Step: 0
Training loss: 3.4872772036248962
Validation loss: 2.5208385355268668

Epoch: 6| Step: 1
Training loss: 2.379505501673639
Validation loss: 2.5464085088097277

Epoch: 6| Step: 2
Training loss: 2.9938389774869516
Validation loss: 2.5721450687590273

Epoch: 6| Step: 3
Training loss: 2.8699738063347984
Validation loss: 2.5788889857049173

Epoch: 6| Step: 4
Training loss: 3.2844738336532133
Validation loss: 2.5598974885840167

Epoch: 6| Step: 5
Training loss: 3.0862301458351293
Validation loss: 2.549260063317198

Epoch: 6| Step: 6
Training loss: 2.341472892843811
Validation loss: 2.529532693289037

Epoch: 6| Step: 7
Training loss: 2.373763415000899
Validation loss: 2.5302282621194547

Epoch: 6| Step: 8
Training loss: 1.8465221707014756
Validation loss: 2.4965162574228845

Epoch: 6| Step: 9
Training loss: 2.456987389687024
Validation loss: 2.4916969115025025

Epoch: 6| Step: 10
Training loss: 2.711536000610167
Validation loss: 2.468055023425454

Epoch: 6| Step: 11
Training loss: 2.52249543642325
Validation loss: 2.484282850147056

Epoch: 6| Step: 12
Training loss: 2.4657090205392254
Validation loss: 2.4748418271643726

Epoch: 6| Step: 13
Training loss: 2.5147311121118188
Validation loss: 2.477403119147888

Epoch: 217| Step: 0
Training loss: 3.6044436368563755
Validation loss: 2.4782642560363644

Epoch: 6| Step: 1
Training loss: 2.5739602406298
Validation loss: 2.4943808687235873

Epoch: 6| Step: 2
Training loss: 2.8231405941218135
Validation loss: 2.498347515615493

Epoch: 6| Step: 3
Training loss: 2.549741851605111
Validation loss: 2.5132140352117833

Epoch: 6| Step: 4
Training loss: 2.3753846509545005
Validation loss: 2.520455608647433

Epoch: 6| Step: 5
Training loss: 3.0485306374122616
Validation loss: 2.5180540327546312

Epoch: 6| Step: 6
Training loss: 2.5726150356481763
Validation loss: 2.514185769989344

Epoch: 6| Step: 7
Training loss: 2.2313519280924634
Validation loss: 2.512633389196397

Epoch: 6| Step: 8
Training loss: 2.4199220720465013
Validation loss: 2.5346485375773726

Epoch: 6| Step: 9
Training loss: 2.313675246718483
Validation loss: 2.542106827000438

Epoch: 6| Step: 10
Training loss: 2.760662562136565
Validation loss: 2.5539974281506295

Epoch: 6| Step: 11
Training loss: 2.4513109631230483
Validation loss: 2.5437216519580215

Epoch: 6| Step: 12
Training loss: 2.6726379197648145
Validation loss: 2.548585321603397

Epoch: 6| Step: 13
Training loss: 3.050088918671749
Validation loss: 2.581829205431655

Epoch: 218| Step: 0
Training loss: 1.7765815190326366
Validation loss: 2.5812636366550534

Epoch: 6| Step: 1
Training loss: 2.808285416402768
Validation loss: 2.604705393206535

Epoch: 6| Step: 2
Training loss: 2.4313678389285873
Validation loss: 2.579148093456597

Epoch: 6| Step: 3
Training loss: 2.620801929312009
Validation loss: 2.5319379081669684

Epoch: 6| Step: 4
Training loss: 2.6458590849176398
Validation loss: 2.5044051480845924

Epoch: 6| Step: 5
Training loss: 2.7692499919167126
Validation loss: 2.484251122827985

Epoch: 6| Step: 6
Training loss: 3.065523795694265
Validation loss: 2.472148206024606

Epoch: 6| Step: 7
Training loss: 2.7624294979713433
Validation loss: 2.4676770700327273

Epoch: 6| Step: 8
Training loss: 2.9815702190405204
Validation loss: 2.4735637757326243

Epoch: 6| Step: 9
Training loss: 2.6198151564003203
Validation loss: 2.4674983498539453

Epoch: 6| Step: 10
Training loss: 2.753590667173938
Validation loss: 2.464056824919575

Epoch: 6| Step: 11
Training loss: 3.240895356218855
Validation loss: 2.4795822904381413

Epoch: 6| Step: 12
Training loss: 2.0901653291936113
Validation loss: 2.489305823054005

Epoch: 6| Step: 13
Training loss: 3.3387460789859187
Validation loss: 2.5197285246703927

Epoch: 219| Step: 0
Training loss: 3.1210983333625606
Validation loss: 2.5640920959989413

Epoch: 6| Step: 1
Training loss: 2.25592680330775
Validation loss: 2.5474847611858076

Epoch: 6| Step: 2
Training loss: 2.67671853238121
Validation loss: 2.505367593182454

Epoch: 6| Step: 3
Training loss: 3.7033529090764548
Validation loss: 2.495483922719825

Epoch: 6| Step: 4
Training loss: 2.433676630999875
Validation loss: 2.4723847925195184

Epoch: 6| Step: 5
Training loss: 2.3324303469218943
Validation loss: 2.485141615491147

Epoch: 6| Step: 6
Training loss: 2.3089849201963912
Validation loss: 2.489416087900185

Epoch: 6| Step: 7
Training loss: 2.2352732740085877
Validation loss: 2.5009301967443767

Epoch: 6| Step: 8
Training loss: 2.6807161809027287
Validation loss: 2.4949112312301027

Epoch: 6| Step: 9
Training loss: 2.9281954208260053
Validation loss: 2.4973243248818227

Epoch: 6| Step: 10
Training loss: 2.4704489354791486
Validation loss: 2.517307566430569

Epoch: 6| Step: 11
Training loss: 2.249241807136399
Validation loss: 2.511062931707297

Epoch: 6| Step: 12
Training loss: 2.805542201985053
Validation loss: 2.529370806353872

Epoch: 6| Step: 13
Training loss: 3.22779257466931
Validation loss: 2.5477082679660263

Epoch: 220| Step: 0
Training loss: 2.843571416256857
Validation loss: 2.588322918402551

Epoch: 6| Step: 1
Training loss: 2.636018606406782
Validation loss: 2.6142800297408386

Epoch: 6| Step: 2
Training loss: 2.5440939480930402
Validation loss: 2.600444543270365

Epoch: 6| Step: 3
Training loss: 2.448978491380665
Validation loss: 2.596442535835455

Epoch: 6| Step: 4
Training loss: 2.7648586784794067
Validation loss: 2.601165419932899

Epoch: 6| Step: 5
Training loss: 2.7850288693696976
Validation loss: 2.584019514906859

Epoch: 6| Step: 6
Training loss: 2.5078528094988606
Validation loss: 2.5564401958942105

Epoch: 6| Step: 7
Training loss: 3.167738448684244
Validation loss: 2.554834340613731

Epoch: 6| Step: 8
Training loss: 2.584763459205729
Validation loss: 2.5578998771125434

Epoch: 6| Step: 9
Training loss: 2.9071640710133675
Validation loss: 2.5752703671199493

Epoch: 6| Step: 10
Training loss: 1.6781394744760274
Validation loss: 2.5303837063383248

Epoch: 6| Step: 11
Training loss: 2.1894901486889715
Validation loss: 2.506807646476375

Epoch: 6| Step: 12
Training loss: 3.071514020726033
Validation loss: 2.4901155313230507

Epoch: 6| Step: 13
Training loss: 3.17799546119361
Validation loss: 2.473540176431767

Epoch: 221| Step: 0
Training loss: 2.8515919304988113
Validation loss: 2.47979932347409

Epoch: 6| Step: 1
Training loss: 2.442681014851043
Validation loss: 2.4817836292727504

Epoch: 6| Step: 2
Training loss: 2.972000430696233
Validation loss: 2.4656546203638263

Epoch: 6| Step: 3
Training loss: 2.680823082715059
Validation loss: 2.4719009208676166

Epoch: 6| Step: 4
Training loss: 2.769232256289841
Validation loss: 2.4799752830169446

Epoch: 6| Step: 5
Training loss: 2.355871770235071
Validation loss: 2.4824235304456796

Epoch: 6| Step: 6
Training loss: 3.082713159274356
Validation loss: 2.4803492229105673

Epoch: 6| Step: 7
Training loss: 2.884339297849618
Validation loss: 2.4888704603982026

Epoch: 6| Step: 8
Training loss: 2.388539919635607
Validation loss: 2.5245900106661536

Epoch: 6| Step: 9
Training loss: 2.7238027164702534
Validation loss: 2.5927571099912035

Epoch: 6| Step: 10
Training loss: 1.8579086804979357
Validation loss: 2.655825396289808

Epoch: 6| Step: 11
Training loss: 2.75017200278853
Validation loss: 2.73556492569765

Epoch: 6| Step: 12
Training loss: 3.0197411152105516
Validation loss: 2.7156819500665286

Epoch: 6| Step: 13
Training loss: 2.4543727932835804
Validation loss: 2.7186318233813846

Epoch: 222| Step: 0
Training loss: 2.098943844375266
Validation loss: 2.6502650560028322

Epoch: 6| Step: 1
Training loss: 2.751162716678193
Validation loss: 2.5955612267411152

Epoch: 6| Step: 2
Training loss: 2.8797010051971537
Validation loss: 2.5423664526310334

Epoch: 6| Step: 3
Training loss: 2.346582354345898
Validation loss: 2.5226150331027712

Epoch: 6| Step: 4
Training loss: 2.3639350932419942
Validation loss: 2.501311425825571

Epoch: 6| Step: 5
Training loss: 2.9324033635730156
Validation loss: 2.4880485975174857

Epoch: 6| Step: 6
Training loss: 3.2128784550491396
Validation loss: 2.500526092918347

Epoch: 6| Step: 7
Training loss: 2.0857445559759236
Validation loss: 2.4830714571306407

Epoch: 6| Step: 8
Training loss: 2.098798898805446
Validation loss: 2.4835871719594107

Epoch: 6| Step: 9
Training loss: 3.0865406847209225
Validation loss: 2.485122851878134

Epoch: 6| Step: 10
Training loss: 2.9517355581896147
Validation loss: 2.475446328474849

Epoch: 6| Step: 11
Training loss: 2.998317564632504
Validation loss: 2.473958179277416

Epoch: 6| Step: 12
Training loss: 2.4652225064333617
Validation loss: 2.4947208065047226

Epoch: 6| Step: 13
Training loss: 2.4158233837472394
Validation loss: 2.5052475389693383

Epoch: 223| Step: 0
Training loss: 3.0290327319759744
Validation loss: 2.5356760244767043

Epoch: 6| Step: 1
Training loss: 2.46793709420977
Validation loss: 2.528952065579072

Epoch: 6| Step: 2
Training loss: 2.497030974709699
Validation loss: 2.5281157834612507

Epoch: 6| Step: 3
Training loss: 2.389070691231257
Validation loss: 2.5294492132704227

Epoch: 6| Step: 4
Training loss: 3.1346658375862138
Validation loss: 2.532492884090514

Epoch: 6| Step: 5
Training loss: 2.5049793247123473
Validation loss: 2.5242178974499354

Epoch: 6| Step: 6
Training loss: 2.3032335770788634
Validation loss: 2.5077327490309758

Epoch: 6| Step: 7
Training loss: 2.707340371453478
Validation loss: 2.503925175915478

Epoch: 6| Step: 8
Training loss: 3.0705324050542573
Validation loss: 2.516808261798373

Epoch: 6| Step: 9
Training loss: 2.856316269788176
Validation loss: 2.5070512012383976

Epoch: 6| Step: 10
Training loss: 2.1931300056076433
Validation loss: 2.5139827066786213

Epoch: 6| Step: 11
Training loss: 2.656795670054789
Validation loss: 2.520082130124104

Epoch: 6| Step: 12
Training loss: 2.2034393519154505
Validation loss: 2.5138879127601013

Epoch: 6| Step: 13
Training loss: 2.723296649768284
Validation loss: 2.5284876941206567

Epoch: 224| Step: 0
Training loss: 2.505005212957322
Validation loss: 2.541637244139144

Epoch: 6| Step: 1
Training loss: 2.4251224526232247
Validation loss: 2.536873092813753

Epoch: 6| Step: 2
Training loss: 3.072576333720301
Validation loss: 2.5578932131813468

Epoch: 6| Step: 3
Training loss: 2.7372742024145302
Validation loss: 2.5443471320123505

Epoch: 6| Step: 4
Training loss: 2.5466851473765195
Validation loss: 2.521816529397473

Epoch: 6| Step: 5
Training loss: 2.0262911789208533
Validation loss: 2.5213150856324007

Epoch: 6| Step: 6
Training loss: 2.7341875284506116
Validation loss: 2.503010470287724

Epoch: 6| Step: 7
Training loss: 2.559910372863852
Validation loss: 2.500490105692402

Epoch: 6| Step: 8
Training loss: 2.7103333253433153
Validation loss: 2.500237330584873

Epoch: 6| Step: 9
Training loss: 2.3465109267176496
Validation loss: 2.5096548098195175

Epoch: 6| Step: 10
Training loss: 2.736025589984994
Validation loss: 2.5123246212279735

Epoch: 6| Step: 11
Training loss: 2.7823345341457237
Validation loss: 2.534284848840423

Epoch: 6| Step: 12
Training loss: 3.018913571050867
Validation loss: 2.5546487503798345

Epoch: 6| Step: 13
Training loss: 2.321510185651517
Validation loss: 2.5623284459307514

Epoch: 225| Step: 0
Training loss: 2.984483327447403
Validation loss: 2.570129626904025

Epoch: 6| Step: 1
Training loss: 2.1509771699141633
Validation loss: 2.6068790419027854

Epoch: 6| Step: 2
Training loss: 3.4191579962321486
Validation loss: 2.574999043597593

Epoch: 6| Step: 3
Training loss: 2.3252363269429743
Validation loss: 2.5715151639728773

Epoch: 6| Step: 4
Training loss: 2.880922933620907
Validation loss: 2.560392117570145

Epoch: 6| Step: 5
Training loss: 2.564067826158012
Validation loss: 2.571222637812465

Epoch: 6| Step: 6
Training loss: 2.6831064906304922
Validation loss: 2.559533589932124

Epoch: 6| Step: 7
Training loss: 2.506632970150576
Validation loss: 2.5373467400151353

Epoch: 6| Step: 8
Training loss: 2.212902907415715
Validation loss: 2.544124836417512

Epoch: 6| Step: 9
Training loss: 2.4676511226241606
Validation loss: 2.515744739868165

Epoch: 6| Step: 10
Training loss: 2.3829933973341766
Validation loss: 2.5163998208974627

Epoch: 6| Step: 11
Training loss: 3.2633089312328463
Validation loss: 2.502645546867034

Epoch: 6| Step: 12
Training loss: 2.0476514202761025
Validation loss: 2.5113292855208087

Epoch: 6| Step: 13
Training loss: 2.130166896675101
Validation loss: 2.5075254539581966

Epoch: 226| Step: 0
Training loss: 2.624359961092095
Validation loss: 2.5212457214963746

Epoch: 6| Step: 1
Training loss: 2.671771666553076
Validation loss: 2.5371173141504193

Epoch: 6| Step: 2
Training loss: 2.5892143577928395
Validation loss: 2.585544202475258

Epoch: 6| Step: 3
Training loss: 2.872530996555455
Validation loss: 2.578553855132586

Epoch: 6| Step: 4
Training loss: 1.5959435121965673
Validation loss: 2.5661669619726255

Epoch: 6| Step: 5
Training loss: 3.4110703264656865
Validation loss: 2.5409778170530712

Epoch: 6| Step: 6
Training loss: 2.8052146649965
Validation loss: 2.5165292455696386

Epoch: 6| Step: 7
Training loss: 2.7502937160041636
Validation loss: 2.531111467956778

Epoch: 6| Step: 8
Training loss: 2.7612012407963484
Validation loss: 2.50040857298904

Epoch: 6| Step: 9
Training loss: 2.4097452910751556
Validation loss: 2.5089775361480426

Epoch: 6| Step: 10
Training loss: 2.2702601931506643
Validation loss: 2.4963394982029175

Epoch: 6| Step: 11
Training loss: 2.3842844934647305
Validation loss: 2.4915794546062093

Epoch: 6| Step: 12
Training loss: 2.450301470990166
Validation loss: 2.5069944140982985

Epoch: 6| Step: 13
Training loss: 2.61302395909709
Validation loss: 2.504834973601403

Epoch: 227| Step: 0
Training loss: 2.4983952139973185
Validation loss: 2.5284156025793436

Epoch: 6| Step: 1
Training loss: 2.4005259017134897
Validation loss: 2.591893200258518

Epoch: 6| Step: 2
Training loss: 2.6615517158822817
Validation loss: 2.6238285298550443

Epoch: 6| Step: 3
Training loss: 3.131324014912022
Validation loss: 2.6307603534361994

Epoch: 6| Step: 4
Training loss: 2.2976025317935225
Validation loss: 2.5797239911673024

Epoch: 6| Step: 5
Training loss: 2.4950180959714205
Validation loss: 2.5333601656978586

Epoch: 6| Step: 6
Training loss: 2.8890997084289323
Validation loss: 2.518001968419053

Epoch: 6| Step: 7
Training loss: 2.5153508955140786
Validation loss: 2.4930435877191948

Epoch: 6| Step: 8
Training loss: 2.5840891891062623
Validation loss: 2.4846608503175927

Epoch: 6| Step: 9
Training loss: 2.603001285466197
Validation loss: 2.4940525569729624

Epoch: 6| Step: 10
Training loss: 3.2091377207730853
Validation loss: 2.500571651115667

Epoch: 6| Step: 11
Training loss: 2.065640803520472
Validation loss: 2.501363206227741

Epoch: 6| Step: 12
Training loss: 2.6778440668634063
Validation loss: 2.509378701590414

Epoch: 6| Step: 13
Training loss: 2.384410384929269
Validation loss: 2.5175516471188644

Epoch: 228| Step: 0
Training loss: 2.8851986652379114
Validation loss: 2.5429919872681195

Epoch: 6| Step: 1
Training loss: 2.39124983058197
Validation loss: 2.542167620930291

Epoch: 6| Step: 2
Training loss: 2.6223854486486498
Validation loss: 2.575566568317674

Epoch: 6| Step: 3
Training loss: 2.5037688457143514
Validation loss: 2.587216897395971

Epoch: 6| Step: 4
Training loss: 2.6610382007263813
Validation loss: 2.578984837791687

Epoch: 6| Step: 5
Training loss: 2.2330478381351133
Validation loss: 2.5660156006625465

Epoch: 6| Step: 6
Training loss: 2.7993862875974656
Validation loss: 2.5761500018241716

Epoch: 6| Step: 7
Training loss: 2.073391104483102
Validation loss: 2.5606447292213597

Epoch: 6| Step: 8
Training loss: 2.9037987000236067
Validation loss: 2.5422547038565066

Epoch: 6| Step: 9
Training loss: 2.400200310930897
Validation loss: 2.539569646956649

Epoch: 6| Step: 10
Training loss: 2.8865127593220516
Validation loss: 2.5254874416955295

Epoch: 6| Step: 11
Training loss: 2.696652109918651
Validation loss: 2.521742255593417

Epoch: 6| Step: 12
Training loss: 2.5132317383703304
Validation loss: 2.5200590651257726

Epoch: 6| Step: 13
Training loss: 2.3685050294165175
Validation loss: 2.5258270026993968

Epoch: 229| Step: 0
Training loss: 2.6161229032290905
Validation loss: 2.549538807761749

Epoch: 6| Step: 1
Training loss: 2.652587340100754
Validation loss: 2.6095899081139766

Epoch: 6| Step: 2
Training loss: 2.909589591957589
Validation loss: 2.6500152032547244

Epoch: 6| Step: 3
Training loss: 3.1522051888305485
Validation loss: 2.61441983633982

Epoch: 6| Step: 4
Training loss: 2.0639616670893166
Validation loss: 2.58643301048773

Epoch: 6| Step: 5
Training loss: 2.5535497902668887
Validation loss: 2.556554777155424

Epoch: 6| Step: 6
Training loss: 2.3929290638670646
Validation loss: 2.5502759209333825

Epoch: 6| Step: 7
Training loss: 2.124214475963427
Validation loss: 2.5572520586029164

Epoch: 6| Step: 8
Training loss: 2.568850208564713
Validation loss: 2.5539004354751063

Epoch: 6| Step: 9
Training loss: 2.281512728677121
Validation loss: 2.529470353126739

Epoch: 6| Step: 10
Training loss: 2.9237774046306284
Validation loss: 2.5461876577936704

Epoch: 6| Step: 11
Training loss: 2.720334172477479
Validation loss: 2.5401331378572327

Epoch: 6| Step: 12
Training loss: 2.1675030732270555
Validation loss: 2.5003640453299534

Epoch: 6| Step: 13
Training loss: 2.678502479755734
Validation loss: 2.5076221036891693

Epoch: 230| Step: 0
Training loss: 2.5342392401781524
Validation loss: 2.5097497963105937

Epoch: 6| Step: 1
Training loss: 2.5481780293728815
Validation loss: 2.4943627861374846

Epoch: 6| Step: 2
Training loss: 2.0378332415518043
Validation loss: 2.490883386380386

Epoch: 6| Step: 3
Training loss: 2.7299678490390886
Validation loss: 2.524306837596531

Epoch: 6| Step: 4
Training loss: 2.641280956168144
Validation loss: 2.5759965092013

Epoch: 6| Step: 5
Training loss: 2.236913666008598
Validation loss: 2.5987840793345316

Epoch: 6| Step: 6
Training loss: 2.6382729252036357
Validation loss: 2.638843700350895

Epoch: 6| Step: 7
Training loss: 2.857043039758112
Validation loss: 2.665050922384349

Epoch: 6| Step: 8
Training loss: 2.9705252710155805
Validation loss: 2.660463424144403

Epoch: 6| Step: 9
Training loss: 2.5843414267558353
Validation loss: 2.523686313836224

Epoch: 6| Step: 10
Training loss: 2.4942430969552634
Validation loss: 2.492016968312638

Epoch: 6| Step: 11
Training loss: 3.041053257233434
Validation loss: 2.4719937096282196

Epoch: 6| Step: 12
Training loss: 2.090181754755748
Validation loss: 2.4704536394711116

Epoch: 6| Step: 13
Training loss: 2.8292638688016782
Validation loss: 2.459017462528446

Epoch: 231| Step: 0
Training loss: 3.08624188817234
Validation loss: 2.482159920634119

Epoch: 6| Step: 1
Training loss: 2.7270610539337627
Validation loss: 2.4894138140653146

Epoch: 6| Step: 2
Training loss: 1.5924127990227455
Validation loss: 2.512831584918551

Epoch: 6| Step: 3
Training loss: 2.371235323203459
Validation loss: 2.5140277212187443

Epoch: 6| Step: 4
Training loss: 2.4622252954922135
Validation loss: 2.535140488830584

Epoch: 6| Step: 5
Training loss: 2.495331792691151
Validation loss: 2.606673515083077

Epoch: 6| Step: 6
Training loss: 2.6252984376832007
Validation loss: 2.599594330041674

Epoch: 6| Step: 7
Training loss: 2.9274672576610885
Validation loss: 2.619125760751478

Epoch: 6| Step: 8
Training loss: 2.548368238563903
Validation loss: 2.604463344943202

Epoch: 6| Step: 9
Training loss: 2.735846249002519
Validation loss: 2.6107203317997643

Epoch: 6| Step: 10
Training loss: 2.1523071950587944
Validation loss: 2.5665031850953395

Epoch: 6| Step: 11
Training loss: 2.8263149475706575
Validation loss: 2.5514053013269002

Epoch: 6| Step: 12
Training loss: 2.431899949305859
Validation loss: 2.5444706838643927

Epoch: 6| Step: 13
Training loss: 2.5535804146256997
Validation loss: 2.5253570406957513

Epoch: 232| Step: 0
Training loss: 2.872714585538532
Validation loss: 2.5193518937656587

Epoch: 6| Step: 1
Training loss: 2.836406910617314
Validation loss: 2.4919740992675403

Epoch: 6| Step: 2
Training loss: 2.4140413647562866
Validation loss: 2.5055136003525518

Epoch: 6| Step: 3
Training loss: 2.009565604796945
Validation loss: 2.5189962429720807

Epoch: 6| Step: 4
Training loss: 2.7289093323348075
Validation loss: 2.5343783568787703

Epoch: 6| Step: 5
Training loss: 1.7868384651006255
Validation loss: 2.5688811040957495

Epoch: 6| Step: 6
Training loss: 2.682913037273118
Validation loss: 2.612425459120059

Epoch: 6| Step: 7
Training loss: 2.7757676342996085
Validation loss: 2.665442149699533

Epoch: 6| Step: 8
Training loss: 2.2519798045633386
Validation loss: 2.632990527305785

Epoch: 6| Step: 9
Training loss: 1.79978084289685
Validation loss: 2.6656479780458024

Epoch: 6| Step: 10
Training loss: 3.193241110195376
Validation loss: 2.6810718171494323

Epoch: 6| Step: 11
Training loss: 2.9482738876028463
Validation loss: 2.6381495742101677

Epoch: 6| Step: 12
Training loss: 2.7558029677297764
Validation loss: 2.559874651638297

Epoch: 6| Step: 13
Training loss: 2.997041037756178
Validation loss: 2.4972633960494544

Epoch: 233| Step: 0
Training loss: 2.433822204741339
Validation loss: 2.4787748235150486

Epoch: 6| Step: 1
Training loss: 2.2308262740564877
Validation loss: 2.46804001218585

Epoch: 6| Step: 2
Training loss: 2.652548690766065
Validation loss: 2.4710610308778063

Epoch: 6| Step: 3
Training loss: 3.0241343560117246
Validation loss: 2.466666666971532

Epoch: 6| Step: 4
Training loss: 2.716639785009522
Validation loss: 2.4650693325126705

Epoch: 6| Step: 5
Training loss: 2.6070866401419313
Validation loss: 2.4520845126234243

Epoch: 6| Step: 6
Training loss: 2.549915207593768
Validation loss: 2.4537704420215873

Epoch: 6| Step: 7
Training loss: 3.0088643402320288
Validation loss: 2.4888923548706274

Epoch: 6| Step: 8
Training loss: 2.5018785094809046
Validation loss: 2.4941132939115644

Epoch: 6| Step: 9
Training loss: 2.2269727897746043
Validation loss: 2.52342654315075

Epoch: 6| Step: 10
Training loss: 2.3170852566551985
Validation loss: 2.5751710248526805

Epoch: 6| Step: 11
Training loss: 2.3160706867242458
Validation loss: 2.6487802316460267

Epoch: 6| Step: 12
Training loss: 2.8147338473050256
Validation loss: 2.750711179414339

Epoch: 6| Step: 13
Training loss: 2.4652169937974158
Validation loss: 2.849921593651694

Epoch: 234| Step: 0
Training loss: 3.04186192412708
Validation loss: 2.8693119232681594

Epoch: 6| Step: 1
Training loss: 3.131227315793893
Validation loss: 2.7865208116315414

Epoch: 6| Step: 2
Training loss: 2.3588320884308684
Validation loss: 2.636770554751066

Epoch: 6| Step: 3
Training loss: 2.718048531374797
Validation loss: 2.5586944983575948

Epoch: 6| Step: 4
Training loss: 2.6875642280887986
Validation loss: 2.5404003895115057

Epoch: 6| Step: 5
Training loss: 2.953967746194369
Validation loss: 2.496585795203096

Epoch: 6| Step: 6
Training loss: 1.889243322510306
Validation loss: 2.4875922190246826

Epoch: 6| Step: 7
Training loss: 2.2420432014420615
Validation loss: 2.4888728047722597

Epoch: 6| Step: 8
Training loss: 2.5037478011488723
Validation loss: 2.47495239873301

Epoch: 6| Step: 9
Training loss: 2.5469917317418367
Validation loss: 2.474634492156833

Epoch: 6| Step: 10
Training loss: 2.3823533913494894
Validation loss: 2.4700952169442325

Epoch: 6| Step: 11
Training loss: 2.1554867043046406
Validation loss: 2.457733578221867

Epoch: 6| Step: 12
Training loss: 3.1912523510360575
Validation loss: 2.466978665862861

Epoch: 6| Step: 13
Training loss: 1.7542716752227665
Validation loss: 2.469906124107784

Epoch: 235| Step: 0
Training loss: 1.905614903449226
Validation loss: 2.493231350416683

Epoch: 6| Step: 1
Training loss: 2.7092142482002726
Validation loss: 2.4943603888540227

Epoch: 6| Step: 2
Training loss: 2.431988672066959
Validation loss: 2.512194996267262

Epoch: 6| Step: 3
Training loss: 2.503251440924235
Validation loss: 2.531049401667338

Epoch: 6| Step: 4
Training loss: 2.3307129473983204
Validation loss: 2.5687663715590245

Epoch: 6| Step: 5
Training loss: 3.161691186783348
Validation loss: 2.5825388871383104

Epoch: 6| Step: 6
Training loss: 2.8151649564989625
Validation loss: 2.5725813533367816

Epoch: 6| Step: 7
Training loss: 3.0603108269394648
Validation loss: 2.561816474758748

Epoch: 6| Step: 8
Training loss: 2.743110262382935
Validation loss: 2.5465168351626857

Epoch: 6| Step: 9
Training loss: 2.2043077256677384
Validation loss: 2.5125183803535185

Epoch: 6| Step: 10
Training loss: 2.1450933890475716
Validation loss: 2.5129942761500925

Epoch: 6| Step: 11
Training loss: 1.829222651199113
Validation loss: 2.527223907427449

Epoch: 6| Step: 12
Training loss: 2.3810698593766486
Validation loss: 2.5317182797703617

Epoch: 6| Step: 13
Training loss: 2.992668571345227
Validation loss: 2.5405216105541966

Epoch: 236| Step: 0
Training loss: 2.6293669207725143
Validation loss: 2.557616981014841

Epoch: 6| Step: 1
Training loss: 1.9994009432073918
Validation loss: 2.5685225514577708

Epoch: 6| Step: 2
Training loss: 2.7552545804407167
Validation loss: 2.5857124058394274

Epoch: 6| Step: 3
Training loss: 2.559783332864748
Validation loss: 2.6035108482926845

Epoch: 6| Step: 4
Training loss: 2.412019822160995
Validation loss: 2.5699458619567443

Epoch: 6| Step: 5
Training loss: 2.739145618663849
Validation loss: 2.5869085683713076

Epoch: 6| Step: 6
Training loss: 2.4883770647270813
Validation loss: 2.5903443455102577

Epoch: 6| Step: 7
Training loss: 2.8880830052353748
Validation loss: 2.5795368225630546

Epoch: 6| Step: 8
Training loss: 2.4260177128484037
Validation loss: 2.5371480893648104

Epoch: 6| Step: 9
Training loss: 2.607099260238163
Validation loss: 2.551911072298916

Epoch: 6| Step: 10
Training loss: 2.232085114958366
Validation loss: 2.51034788305463

Epoch: 6| Step: 11
Training loss: 2.861990977509657
Validation loss: 2.5117076593551393

Epoch: 6| Step: 12
Training loss: 1.6082797721812272
Validation loss: 2.509975772648082

Epoch: 6| Step: 13
Training loss: 2.6065158369943195
Validation loss: 2.478889084419503

Epoch: 237| Step: 0
Training loss: 2.5708606448544096
Validation loss: 2.498242172476757

Epoch: 6| Step: 1
Training loss: 2.658025350238821
Validation loss: 2.5008353991012218

Epoch: 6| Step: 2
Training loss: 2.5940501027970786
Validation loss: 2.515822842858248

Epoch: 6| Step: 3
Training loss: 2.566156709055807
Validation loss: 2.5338326094399135

Epoch: 6| Step: 4
Training loss: 2.0260457199827573
Validation loss: 2.547408192512226

Epoch: 6| Step: 5
Training loss: 2.443798144712617
Validation loss: 2.576119054645129

Epoch: 6| Step: 6
Training loss: 2.38733861088145
Validation loss: 2.5585583300261368

Epoch: 6| Step: 7
Training loss: 2.370202187553119
Validation loss: 2.5814540794379663

Epoch: 6| Step: 8
Training loss: 2.730873176191703
Validation loss: 2.5734091806251014

Epoch: 6| Step: 9
Training loss: 2.608798757187946
Validation loss: 2.5892066724468634

Epoch: 6| Step: 10
Training loss: 2.2659957056299445
Validation loss: 2.5527895958261517

Epoch: 6| Step: 11
Training loss: 2.6354580500272373
Validation loss: 2.5115546410179515

Epoch: 6| Step: 12
Training loss: 2.551196591735458
Validation loss: 2.483300700458128

Epoch: 6| Step: 13
Training loss: 2.6505215977218963
Validation loss: 2.4955339882690173

Epoch: 238| Step: 0
Training loss: 2.406492840291605
Validation loss: 2.461117273689622

Epoch: 6| Step: 1
Training loss: 3.007770329960066
Validation loss: 2.475256213080023

Epoch: 6| Step: 2
Training loss: 2.1127710202414667
Validation loss: 2.498715384437986

Epoch: 6| Step: 3
Training loss: 2.3673054379332856
Validation loss: 2.4979184539806862

Epoch: 6| Step: 4
Training loss: 2.390631283022534
Validation loss: 2.5141288513471944

Epoch: 6| Step: 5
Training loss: 2.7418838724132364
Validation loss: 2.5519303444031745

Epoch: 6| Step: 6
Training loss: 2.4182706530400977
Validation loss: 2.5799445211565426

Epoch: 6| Step: 7
Training loss: 2.3498240790566958
Validation loss: 2.5852878647910074

Epoch: 6| Step: 8
Training loss: 2.4424696902656153
Validation loss: 2.596772256836589

Epoch: 6| Step: 9
Training loss: 2.296671436657356
Validation loss: 2.6263176872231617

Epoch: 6| Step: 10
Training loss: 2.6787033720671056
Validation loss: 2.5864416268682175

Epoch: 6| Step: 11
Training loss: 1.9022511297155669
Validation loss: 2.5283088424467373

Epoch: 6| Step: 12
Training loss: 2.764826082688944
Validation loss: 2.486778336641155

Epoch: 6| Step: 13
Training loss: 2.9251437746887072
Validation loss: 2.4791309074565975

Epoch: 239| Step: 0
Training loss: 2.0109105532959277
Validation loss: 2.4701446471402986

Epoch: 6| Step: 1
Training loss: 2.1002853653796265
Validation loss: 2.4635312970924494

Epoch: 6| Step: 2
Training loss: 2.7129697190818907
Validation loss: 2.503758385400698

Epoch: 6| Step: 3
Training loss: 2.516205146188903
Validation loss: 2.5252225183041555

Epoch: 6| Step: 4
Training loss: 2.4024889398135665
Validation loss: 2.539607199274486

Epoch: 6| Step: 5
Training loss: 2.368713088741932
Validation loss: 2.5426257896025604

Epoch: 6| Step: 6
Training loss: 2.538911034394484
Validation loss: 2.585335016213582

Epoch: 6| Step: 7
Training loss: 2.372612807523349
Validation loss: 2.560354329408366

Epoch: 6| Step: 8
Training loss: 2.6275257493344433
Validation loss: 2.561216936051727

Epoch: 6| Step: 9
Training loss: 2.4858114060719925
Validation loss: 2.532000889235591

Epoch: 6| Step: 10
Training loss: 2.731140054196413
Validation loss: 2.5130857822790564

Epoch: 6| Step: 11
Training loss: 2.5138391825876782
Validation loss: 2.533806016095185

Epoch: 6| Step: 12
Training loss: 2.5209170766324465
Validation loss: 2.5461582786151786

Epoch: 6| Step: 13
Training loss: 2.9389797298411215
Validation loss: 2.562801118291689

Epoch: 240| Step: 0
Training loss: 2.2277199397053353
Validation loss: 2.5328112180237365

Epoch: 6| Step: 1
Training loss: 2.382156031497189
Validation loss: 2.530905246994574

Epoch: 6| Step: 2
Training loss: 2.3597706848201425
Validation loss: 2.4957296128416457

Epoch: 6| Step: 3
Training loss: 2.8424746829124174
Validation loss: 2.4891670865232327

Epoch: 6| Step: 4
Training loss: 2.0679828708168015
Validation loss: 2.487933962811868

Epoch: 6| Step: 5
Training loss: 2.9881636453063227
Validation loss: 2.4736925667376095

Epoch: 6| Step: 6
Training loss: 2.6435661414313647
Validation loss: 2.486613645635218

Epoch: 6| Step: 7
Training loss: 2.1434659274761
Validation loss: 2.4917685941378713

Epoch: 6| Step: 8
Training loss: 2.6620816112478307
Validation loss: 2.518897190107305

Epoch: 6| Step: 9
Training loss: 2.265569225808638
Validation loss: 2.5810672958243797

Epoch: 6| Step: 10
Training loss: 2.435992434936202
Validation loss: 2.6016983774734515

Epoch: 6| Step: 11
Training loss: 2.808507671283923
Validation loss: 2.6410075594589184

Epoch: 6| Step: 12
Training loss: 2.3809825436634307
Validation loss: 2.6425328836352677

Epoch: 6| Step: 13
Training loss: 1.9927616264474055
Validation loss: 2.5709687062424558

Epoch: 241| Step: 0
Training loss: 2.6138254006819666
Validation loss: 2.5143637532637264

Epoch: 6| Step: 1
Training loss: 2.001628570299985
Validation loss: 2.4649011951624393

Epoch: 6| Step: 2
Training loss: 1.9110847821873973
Validation loss: 2.476897720377156

Epoch: 6| Step: 3
Training loss: 2.5626350925470662
Validation loss: 2.4507250746102254

Epoch: 6| Step: 4
Training loss: 2.72757175424599
Validation loss: 2.447283631323596

Epoch: 6| Step: 5
Training loss: 2.978271314263075
Validation loss: 2.452676667701494

Epoch: 6| Step: 6
Training loss: 2.295255440352665
Validation loss: 2.438042026411565

Epoch: 6| Step: 7
Training loss: 2.6810061043737767
Validation loss: 2.4567585220603587

Epoch: 6| Step: 8
Training loss: 2.2863303273951465
Validation loss: 2.4585729648712213

Epoch: 6| Step: 9
Training loss: 2.7015574766854775
Validation loss: 2.487577471508607

Epoch: 6| Step: 10
Training loss: 2.1950672596421796
Validation loss: 2.5360123996441186

Epoch: 6| Step: 11
Training loss: 2.7158664012236784
Validation loss: 2.630976267412281

Epoch: 6| Step: 12
Training loss: 2.0451864018630377
Validation loss: 2.7540534779607317

Epoch: 6| Step: 13
Training loss: 2.4710892809026337
Validation loss: 2.7982567289910456

Epoch: 242| Step: 0
Training loss: 3.0412473694413267
Validation loss: 2.8501536657302475

Epoch: 6| Step: 1
Training loss: 2.4095193030539415
Validation loss: 2.819624698467951

Epoch: 6| Step: 2
Training loss: 2.885641720438092
Validation loss: 2.7891553417128976

Epoch: 6| Step: 3
Training loss: 2.5483219272548707
Validation loss: 2.704634278820468

Epoch: 6| Step: 4
Training loss: 2.040518405344296
Validation loss: 2.6193845996098495

Epoch: 6| Step: 5
Training loss: 2.6253017070499824
Validation loss: 2.521349554479229

Epoch: 6| Step: 6
Training loss: 2.7558838581644114
Validation loss: 2.4825432318364724

Epoch: 6| Step: 7
Training loss: 2.536696614085741
Validation loss: 2.4491910955620395

Epoch: 6| Step: 8
Training loss: 2.2649874086008968
Validation loss: 2.453954157970976

Epoch: 6| Step: 9
Training loss: 2.5087704358981555
Validation loss: 2.4633547873683055

Epoch: 6| Step: 10
Training loss: 2.128617517332603
Validation loss: 2.4616002896299913

Epoch: 6| Step: 11
Training loss: 2.852182148535197
Validation loss: 2.464010215986606

Epoch: 6| Step: 12
Training loss: 2.382461672111346
Validation loss: 2.4638846511003742

Epoch: 6| Step: 13
Training loss: 2.412080908232833
Validation loss: 2.487221060011809

Epoch: 243| Step: 0
Training loss: 2.2679491421347646
Validation loss: 2.5060544820449437

Epoch: 6| Step: 1
Training loss: 2.5838005709855008
Validation loss: 2.544463775194619

Epoch: 6| Step: 2
Training loss: 2.1237732207144155
Validation loss: 2.584583750595566

Epoch: 6| Step: 3
Training loss: 2.3413115977724472
Validation loss: 2.5975713145572343

Epoch: 6| Step: 4
Training loss: 2.2129980399583773
Validation loss: 2.5926018318555943

Epoch: 6| Step: 5
Training loss: 3.033679421212544
Validation loss: 2.6091959980763266

Epoch: 6| Step: 6
Training loss: 2.7069658984378018
Validation loss: 2.58541021773033

Epoch: 6| Step: 7
Training loss: 2.131861100723286
Validation loss: 2.5574732863557785

Epoch: 6| Step: 8
Training loss: 2.5033392539464403
Validation loss: 2.547244587881091

Epoch: 6| Step: 9
Training loss: 2.2374394882799846
Validation loss: 2.5369130254482752

Epoch: 6| Step: 10
Training loss: 2.56846686888883
Validation loss: 2.535876020262342

Epoch: 6| Step: 11
Training loss: 2.730146440903058
Validation loss: 2.5217028701014743

Epoch: 6| Step: 12
Training loss: 2.377963275398055
Validation loss: 2.512307993336002

Epoch: 6| Step: 13
Training loss: 1.995457915621005
Validation loss: 2.5090762628420427

Epoch: 244| Step: 0
Training loss: 2.383957284557491
Validation loss: 2.486446041327664

Epoch: 6| Step: 1
Training loss: 2.5026795332585845
Validation loss: 2.4703790469881945

Epoch: 6| Step: 2
Training loss: 2.1520105232066564
Validation loss: 2.446875160343111

Epoch: 6| Step: 3
Training loss: 2.8804760073308358
Validation loss: 2.4479898840209775

Epoch: 6| Step: 4
Training loss: 2.564399480440203
Validation loss: 2.469396336015649

Epoch: 6| Step: 5
Training loss: 2.5088497880629923
Validation loss: 2.464759395792705

Epoch: 6| Step: 6
Training loss: 2.5358960875151815
Validation loss: 2.50093421708469

Epoch: 6| Step: 7
Training loss: 1.9590384113621617
Validation loss: 2.528408437114131

Epoch: 6| Step: 8
Training loss: 1.9521834278262677
Validation loss: 2.539968949057808

Epoch: 6| Step: 9
Training loss: 2.5840886355217982
Validation loss: 2.5451345369588787

Epoch: 6| Step: 10
Training loss: 2.203040696282926
Validation loss: 2.541680798086995

Epoch: 6| Step: 11
Training loss: 2.664838303174861
Validation loss: 2.5340885161522855

Epoch: 6| Step: 12
Training loss: 2.013306696549266
Validation loss: 2.5147606484402067

Epoch: 6| Step: 13
Training loss: 3.3105146108309795
Validation loss: 2.5292941271875122

Epoch: 245| Step: 0
Training loss: 2.1041862814212497
Validation loss: 2.540328603744854

Epoch: 6| Step: 1
Training loss: 2.8746622965301154
Validation loss: 2.5470242154933938

Epoch: 6| Step: 2
Training loss: 2.6412137972096845
Validation loss: 2.544177523961771

Epoch: 6| Step: 3
Training loss: 2.8538531574414057
Validation loss: 2.5620327615340552

Epoch: 6| Step: 4
Training loss: 2.5339162465430123
Validation loss: 2.5764581775479583

Epoch: 6| Step: 5
Training loss: 1.9719566388769714
Validation loss: 2.575258542732978

Epoch: 6| Step: 6
Training loss: 2.3249111650784835
Validation loss: 2.578432986401292

Epoch: 6| Step: 7
Training loss: 1.9745404300293667
Validation loss: 2.5607056311688323

Epoch: 6| Step: 8
Training loss: 1.910640226184295
Validation loss: 2.5469591680585695

Epoch: 6| Step: 9
Training loss: 2.2998256285538106
Validation loss: 2.5443003454782875

Epoch: 6| Step: 10
Training loss: 2.8842358060667577
Validation loss: 2.5231201577828943

Epoch: 6| Step: 11
Training loss: 2.0446441374338655
Validation loss: 2.4952939706340262

Epoch: 6| Step: 12
Training loss: 2.1488649255222274
Validation loss: 2.477197040654202

Epoch: 6| Step: 13
Training loss: 2.6706674981569063
Validation loss: 2.501025528938206

Epoch: 246| Step: 0
Training loss: 1.9465752605094082
Validation loss: 2.4802385131137044

Epoch: 6| Step: 1
Training loss: 2.9322184705435204
Validation loss: 2.4452657036259757

Epoch: 6| Step: 2
Training loss: 2.5031849600364797
Validation loss: 2.469866507290138

Epoch: 6| Step: 3
Training loss: 1.9606388670139392
Validation loss: 2.453025676346052

Epoch: 6| Step: 4
Training loss: 2.625773633760293
Validation loss: 2.4739107869387653

Epoch: 6| Step: 5
Training loss: 2.346235965936765
Validation loss: 2.4871077173751015

Epoch: 6| Step: 6
Training loss: 2.6376817541187076
Validation loss: 2.4794637954061423

Epoch: 6| Step: 7
Training loss: 2.638615492550837
Validation loss: 2.490527275050743

Epoch: 6| Step: 8
Training loss: 2.2467918836901033
Validation loss: 2.4996452459260876

Epoch: 6| Step: 9
Training loss: 2.2841517139693677
Validation loss: 2.5339190682581187

Epoch: 6| Step: 10
Training loss: 2.1207430217627663
Validation loss: 2.52326207192632

Epoch: 6| Step: 11
Training loss: 2.238358581165765
Validation loss: 2.5667039605483533

Epoch: 6| Step: 12
Training loss: 2.4375692504435658
Validation loss: 2.6025829285400186

Epoch: 6| Step: 13
Training loss: 2.37532553198589
Validation loss: 2.5816436263648774

Epoch: 247| Step: 0
Training loss: 2.02497728594062
Validation loss: 2.5784301955034112

Epoch: 6| Step: 1
Training loss: 1.9002991641579914
Validation loss: 2.5657275373412514

Epoch: 6| Step: 2
Training loss: 2.23414664001861
Validation loss: 2.5179489729303786

Epoch: 6| Step: 3
Training loss: 2.0624299470969016
Validation loss: 2.495509616688542

Epoch: 6| Step: 4
Training loss: 3.123925596555158
Validation loss: 2.480205088503372

Epoch: 6| Step: 5
Training loss: 2.734805002461649
Validation loss: 2.443369338447084

Epoch: 6| Step: 6
Training loss: 2.4968424884460325
Validation loss: 2.4657129828991513

Epoch: 6| Step: 7
Training loss: 2.494427860840195
Validation loss: 2.459766963389247

Epoch: 6| Step: 8
Training loss: 2.355451542679167
Validation loss: 2.4876303426490445

Epoch: 6| Step: 9
Training loss: 2.136326616139872
Validation loss: 2.530149768902081

Epoch: 6| Step: 10
Training loss: 2.0088517286348337
Validation loss: 2.5670778495193827

Epoch: 6| Step: 11
Training loss: 2.340651231117097
Validation loss: 2.577362329581511

Epoch: 6| Step: 12
Training loss: 2.9624914756684455
Validation loss: 2.5851209453150594

Epoch: 6| Step: 13
Training loss: 1.6738694318305996
Validation loss: 2.611993999281843

Epoch: 248| Step: 0
Training loss: 2.317314908929297
Validation loss: 2.604539829877173

Epoch: 6| Step: 1
Training loss: 2.073616472007236
Validation loss: 2.6248757752432277

Epoch: 6| Step: 2
Training loss: 2.409236095496407
Validation loss: 2.665350687027312

Epoch: 6| Step: 3
Training loss: 2.941147507917629
Validation loss: 2.711453704894957

Epoch: 6| Step: 4
Training loss: 2.3688986859925163
Validation loss: 2.656415936319576

Epoch: 6| Step: 5
Training loss: 2.020774827352753
Validation loss: 2.6143096847953338

Epoch: 6| Step: 6
Training loss: 2.4685637005396126
Validation loss: 2.534926178370586

Epoch: 6| Step: 7
Training loss: 2.1955383836192235
Validation loss: 2.462559462044316

Epoch: 6| Step: 8
Training loss: 2.618791777430034
Validation loss: 2.4391027702241344

Epoch: 6| Step: 9
Training loss: 2.251933856229901
Validation loss: 2.448926482697472

Epoch: 6| Step: 10
Training loss: 2.5787593176817167
Validation loss: 2.432291937369536

Epoch: 6| Step: 11
Training loss: 2.101978586975267
Validation loss: 2.4482134298564002

Epoch: 6| Step: 12
Training loss: 2.2943213143714423
Validation loss: 2.4337233979271042

Epoch: 6| Step: 13
Training loss: 2.800579494727229
Validation loss: 2.4335234519997067

Epoch: 249| Step: 0
Training loss: 2.929759276464499
Validation loss: 2.4747655727469158

Epoch: 6| Step: 1
Training loss: 2.743880920067327
Validation loss: 2.531025507796278

Epoch: 6| Step: 2
Training loss: 2.6473886218971217
Validation loss: 2.55145856297229

Epoch: 6| Step: 3
Training loss: 1.767389816454102
Validation loss: 2.5031760898446085

Epoch: 6| Step: 4
Training loss: 2.081111167882369
Validation loss: 2.494879343134338

Epoch: 6| Step: 5
Training loss: 2.2504486060623186
Validation loss: 2.5068849653823766

Epoch: 6| Step: 6
Training loss: 2.213345244425394
Validation loss: 2.5009103891446944

Epoch: 6| Step: 7
Training loss: 1.9444800744501014
Validation loss: 2.5192998766039345

Epoch: 6| Step: 8
Training loss: 2.2972845633598094
Validation loss: 2.5279910266469554

Epoch: 6| Step: 9
Training loss: 2.0179408763772537
Validation loss: 2.5494034948746283

Epoch: 6| Step: 10
Training loss: 2.4382281071800525
Validation loss: 2.5560494957721462

Epoch: 6| Step: 11
Training loss: 2.2612350552783598
Validation loss: 2.5940762327152873

Epoch: 6| Step: 12
Training loss: 2.4343349742414633
Validation loss: 2.6007187293622294

Epoch: 6| Step: 13
Training loss: 2.9315192841102635
Validation loss: 2.6086920034159533

Epoch: 250| Step: 0
Training loss: 2.320329556900164
Validation loss: 2.5977541787637612

Epoch: 6| Step: 1
Training loss: 2.259253863494396
Validation loss: 2.547445722872

Epoch: 6| Step: 2
Training loss: 2.712214891770308
Validation loss: 2.5187268204699937

Epoch: 6| Step: 3
Training loss: 2.402583114980551
Validation loss: 2.480588729678766

Epoch: 6| Step: 4
Training loss: 2.120709407260968
Validation loss: 2.4790706933060793

Epoch: 6| Step: 5
Training loss: 2.0633337474241236
Validation loss: 2.4760164918180165

Epoch: 6| Step: 6
Training loss: 2.3075701772943824
Validation loss: 2.4692288618779594

Epoch: 6| Step: 7
Training loss: 2.1935443749201093
Validation loss: 2.4825299790683064

Epoch: 6| Step: 8
Training loss: 2.2952362234842494
Validation loss: 2.496816989930638

Epoch: 6| Step: 9
Training loss: 2.6898069017441855
Validation loss: 2.508173541949913

Epoch: 6| Step: 10
Training loss: 2.6159549372871918
Validation loss: 2.5095347824413072

Epoch: 6| Step: 11
Training loss: 2.2414719772408174
Validation loss: 2.5186559707359426

Epoch: 6| Step: 12
Training loss: 2.441704083395771
Validation loss: 2.5547168433092335

Epoch: 6| Step: 13
Training loss: 1.9411441618394696
Validation loss: 2.5602276899425753

Epoch: 251| Step: 0
Training loss: 2.2254353129563933
Validation loss: 2.5621608286568764

Epoch: 6| Step: 1
Training loss: 1.9806682177734123
Validation loss: 2.5776218931468597

Epoch: 6| Step: 2
Training loss: 1.7835479770556637
Validation loss: 2.5711820834318355

Epoch: 6| Step: 3
Training loss: 2.62973431133599
Validation loss: 2.564381836602114

Epoch: 6| Step: 4
Training loss: 2.4516359900503093
Validation loss: 2.5783706771718444

Epoch: 6| Step: 5
Training loss: 2.143685040170929
Validation loss: 2.5960151437115164

Epoch: 6| Step: 6
Training loss: 2.541321392266772
Validation loss: 2.5591314341209883

Epoch: 6| Step: 7
Training loss: 1.9865991338136737
Validation loss: 2.5432330223355786

Epoch: 6| Step: 8
Training loss: 2.3473364283700113
Validation loss: 2.55148982634095

Epoch: 6| Step: 9
Training loss: 2.346898012010338
Validation loss: 2.5106425057169663

Epoch: 6| Step: 10
Training loss: 2.2939201603692396
Validation loss: 2.495721957540751

Epoch: 6| Step: 11
Training loss: 2.3526062534185925
Validation loss: 2.464864333145014

Epoch: 6| Step: 12
Training loss: 2.433062793985959
Validation loss: 2.474703757003122

Epoch: 6| Step: 13
Training loss: 3.2970447948537887
Validation loss: 2.452273043563539

Epoch: 252| Step: 0
Training loss: 2.5747349500815395
Validation loss: 2.4730286396765093

Epoch: 6| Step: 1
Training loss: 2.7185414552178147
Validation loss: 2.4801065237469984

Epoch: 6| Step: 2
Training loss: 1.7403650716388692
Validation loss: 2.4853657780793608

Epoch: 6| Step: 3
Training loss: 2.214441764184674
Validation loss: 2.5303387193481037

Epoch: 6| Step: 4
Training loss: 2.5300053491648944
Validation loss: 2.580870323202817

Epoch: 6| Step: 5
Training loss: 2.6804703439225808
Validation loss: 2.6197757549622636

Epoch: 6| Step: 6
Training loss: 2.351527622509212
Validation loss: 2.5905133406323317

Epoch: 6| Step: 7
Training loss: 2.596055626165963
Validation loss: 2.55332730989954

Epoch: 6| Step: 8
Training loss: 2.37909636340737
Validation loss: 2.5100176315413933

Epoch: 6| Step: 9
Training loss: 1.6694738668274065
Validation loss: 2.488217097402464

Epoch: 6| Step: 10
Training loss: 2.5322244911170664
Validation loss: 2.471150855085519

Epoch: 6| Step: 11
Training loss: 2.4687359000660445
Validation loss: 2.456532438312875

Epoch: 6| Step: 12
Training loss: 2.097520081488741
Validation loss: 2.4378195322600416

Epoch: 6| Step: 13
Training loss: 2.256874391169586
Validation loss: 2.441901112271196

Epoch: 253| Step: 0
Training loss: 2.504273862231702
Validation loss: 2.449190173393153

Epoch: 6| Step: 1
Training loss: 2.1453164474995545
Validation loss: 2.468062448769436

Epoch: 6| Step: 2
Training loss: 2.0501895305199143
Validation loss: 2.4892823328284934

Epoch: 6| Step: 3
Training loss: 2.637100305147527
Validation loss: 2.4984516496811806

Epoch: 6| Step: 4
Training loss: 2.5096949467188114
Validation loss: 2.527262700188334

Epoch: 6| Step: 5
Training loss: 2.163611630181092
Validation loss: 2.5283433193718245

Epoch: 6| Step: 6
Training loss: 2.7178515122521625
Validation loss: 2.5329512744662184

Epoch: 6| Step: 7
Training loss: 2.3059008491685606
Validation loss: 2.522790954310618

Epoch: 6| Step: 8
Training loss: 1.8873263500241184
Validation loss: 2.5336075517650105

Epoch: 6| Step: 9
Training loss: 1.6224791707963369
Validation loss: 2.556696903049269

Epoch: 6| Step: 10
Training loss: 2.071964741830309
Validation loss: 2.545741075615367

Epoch: 6| Step: 11
Training loss: 3.097675645726636
Validation loss: 2.5546662216000313

Epoch: 6| Step: 12
Training loss: 2.3824866900717705
Validation loss: 2.522486624988823

Epoch: 6| Step: 13
Training loss: 1.7378682192324633
Validation loss: 2.5088085197324865

Epoch: 254| Step: 0
Training loss: 2.507723132291031
Validation loss: 2.4820952028796026

Epoch: 6| Step: 1
Training loss: 1.780437484942076
Validation loss: 2.4696359816432616

Epoch: 6| Step: 2
Training loss: 1.9286470272243539
Validation loss: 2.488302096713902

Epoch: 6| Step: 3
Training loss: 2.3694848724867614
Validation loss: 2.4904627417920224

Epoch: 6| Step: 4
Training loss: 2.249427086687353
Validation loss: 2.5167438676425613

Epoch: 6| Step: 5
Training loss: 2.925742135085665
Validation loss: 2.5196980830611446

Epoch: 6| Step: 6
Training loss: 1.732061131365422
Validation loss: 2.5585225999438213

Epoch: 6| Step: 7
Training loss: 2.4777594240171226
Validation loss: 2.591572009812738

Epoch: 6| Step: 8
Training loss: 2.389199823158982
Validation loss: 2.6219748573071104

Epoch: 6| Step: 9
Training loss: 2.2851413302464336
Validation loss: 2.638902559084873

Epoch: 6| Step: 10
Training loss: 2.4286006937748055
Validation loss: 2.6532744194898665

Epoch: 6| Step: 11
Training loss: 1.9169352868409923
Validation loss: 2.596403792268424

Epoch: 6| Step: 12
Training loss: 2.661870597267854
Validation loss: 2.5770889661641845

Epoch: 6| Step: 13
Training loss: 2.2166871703306263
Validation loss: 2.5121430788941157

Epoch: 255| Step: 0
Training loss: 2.1161984318749667
Validation loss: 2.4750627312738374

Epoch: 6| Step: 1
Training loss: 2.037570217303417
Validation loss: 2.4084089502413497

Epoch: 6| Step: 2
Training loss: 2.351477535905388
Validation loss: 2.405049771952431

Epoch: 6| Step: 3
Training loss: 2.4752825489021277
Validation loss: 2.395818852777222

Epoch: 6| Step: 4
Training loss: 2.056848354300309
Validation loss: 2.4031092742875204

Epoch: 6| Step: 5
Training loss: 2.522916568805452
Validation loss: 2.401522595833728

Epoch: 6| Step: 6
Training loss: 2.3835011972208697
Validation loss: 2.40561416827425

Epoch: 6| Step: 7
Training loss: 1.7174990870266504
Validation loss: 2.4490436927679267

Epoch: 6| Step: 8
Training loss: 2.042201640307061
Validation loss: 2.5227117479940855

Epoch: 6| Step: 9
Training loss: 2.630935951030369
Validation loss: 2.591829202248849

Epoch: 6| Step: 10
Training loss: 2.6752116467181297
Validation loss: 2.656689707236851

Epoch: 6| Step: 11
Training loss: 2.2400698347786077
Validation loss: 2.6504144013321413

Epoch: 6| Step: 12
Training loss: 2.155573863293658
Validation loss: 2.5655223851344915

Epoch: 6| Step: 13
Training loss: 3.2527144906865657
Validation loss: 2.480076186038324

Epoch: 256| Step: 0
Training loss: 2.284094095767044
Validation loss: 2.4705911709804584

Epoch: 6| Step: 1
Training loss: 2.457998403804748
Validation loss: 2.485520709367552

Epoch: 6| Step: 2
Training loss: 2.2223975059467818
Validation loss: 2.4626485147348487

Epoch: 6| Step: 3
Training loss: 1.5757323908571643
Validation loss: 2.476253194279781

Epoch: 6| Step: 4
Training loss: 2.225115389457123
Validation loss: 2.489531761359873

Epoch: 6| Step: 5
Training loss: 2.120622614177033
Validation loss: 2.5067382347580685

Epoch: 6| Step: 6
Training loss: 1.9240742327512228
Validation loss: 2.5126057552307386

Epoch: 6| Step: 7
Training loss: 2.4869955385211826
Validation loss: 2.534001855717793

Epoch: 6| Step: 8
Training loss: 1.8092045257322833
Validation loss: 2.5669261828808394

Epoch: 6| Step: 9
Training loss: 2.314325282433076
Validation loss: 2.5882582115719726

Epoch: 6| Step: 10
Training loss: 2.7106681931818644
Validation loss: 2.5783517548251105

Epoch: 6| Step: 11
Training loss: 2.674548055670996
Validation loss: 2.5740644918601974

Epoch: 6| Step: 12
Training loss: 2.496445799642804
Validation loss: 2.561170340576306

Epoch: 6| Step: 13
Training loss: 2.1880988255068203
Validation loss: 2.558452319673404

Epoch: 257| Step: 0
Training loss: 2.6187586381355517
Validation loss: 2.553118676092564

Epoch: 6| Step: 1
Training loss: 2.147272411361388
Validation loss: 2.5370243294481822

Epoch: 6| Step: 2
Training loss: 2.655497006666924
Validation loss: 2.58513679893128

Epoch: 6| Step: 3
Training loss: 2.4598696374854607
Validation loss: 2.548011727931317

Epoch: 6| Step: 4
Training loss: 2.0894650695539245
Validation loss: 2.5376489018206607

Epoch: 6| Step: 5
Training loss: 2.0994333592645127
Validation loss: 2.4985679052243466

Epoch: 6| Step: 6
Training loss: 1.7736937888058255
Validation loss: 2.4731494389876563

Epoch: 6| Step: 7
Training loss: 2.4841629033751733
Validation loss: 2.4869828790088158

Epoch: 6| Step: 8
Training loss: 2.45797202046721
Validation loss: 2.4802883799303252

Epoch: 6| Step: 9
Training loss: 1.9310306708469727
Validation loss: 2.4798156844926904

Epoch: 6| Step: 10
Training loss: 2.1096366437484537
Validation loss: 2.477329251264756

Epoch: 6| Step: 11
Training loss: 2.39709723485528
Validation loss: 2.4923890969315825

Epoch: 6| Step: 12
Training loss: 2.071483583142645
Validation loss: 2.4819317257121742

Epoch: 6| Step: 13
Training loss: 2.208909145595371
Validation loss: 2.4700145138765857

Epoch: 258| Step: 0
Training loss: 1.8728810098695878
Validation loss: 2.468942459473815

Epoch: 6| Step: 1
Training loss: 2.331741902916969
Validation loss: 2.503024726405631

Epoch: 6| Step: 2
Training loss: 2.2101475682767364
Validation loss: 2.5148519995708267

Epoch: 6| Step: 3
Training loss: 2.016274162852457
Validation loss: 2.5383522866664245

Epoch: 6| Step: 4
Training loss: 1.9946448634803868
Validation loss: 2.578221837049492

Epoch: 6| Step: 5
Training loss: 2.5143268149905587
Validation loss: 2.6231774235262093

Epoch: 6| Step: 6
Training loss: 3.125239248654113
Validation loss: 2.6598372440475537

Epoch: 6| Step: 7
Training loss: 1.6950128527803847
Validation loss: 2.593120578146212

Epoch: 6| Step: 8
Training loss: 2.0881897843149657
Validation loss: 2.5598687048956448

Epoch: 6| Step: 9
Training loss: 2.2337329715705163
Validation loss: 2.516888142813594

Epoch: 6| Step: 10
Training loss: 2.5106439975573407
Validation loss: 2.5082453536670597

Epoch: 6| Step: 11
Training loss: 1.9105493807966343
Validation loss: 2.4985604335606864

Epoch: 6| Step: 12
Training loss: 2.4888107718496704
Validation loss: 2.4804369955991206

Epoch: 6| Step: 13
Training loss: 1.7564762716365585
Validation loss: 2.478514264835744

Epoch: 259| Step: 0
Training loss: 2.52216999356515
Validation loss: 2.4617409473575327

Epoch: 6| Step: 1
Training loss: 2.255580022780451
Validation loss: 2.456422574895598

Epoch: 6| Step: 2
Training loss: 2.4629318633170274
Validation loss: 2.4446058523778755

Epoch: 6| Step: 3
Training loss: 1.9301108695091618
Validation loss: 2.4495789587380004

Epoch: 6| Step: 4
Training loss: 1.7741922125433762
Validation loss: 2.470950334976483

Epoch: 6| Step: 5
Training loss: 2.183964406118186
Validation loss: 2.461045893091866

Epoch: 6| Step: 6
Training loss: 2.4636395833488036
Validation loss: 2.5158593434177687

Epoch: 6| Step: 7
Training loss: 2.167119370141137
Validation loss: 2.515612846339548

Epoch: 6| Step: 8
Training loss: 2.5328350990976873
Validation loss: 2.5740497776465006

Epoch: 6| Step: 9
Training loss: 2.514590411951889
Validation loss: 2.6228875402502307

Epoch: 6| Step: 10
Training loss: 2.1742957367119113
Validation loss: 2.5969823135295003

Epoch: 6| Step: 11
Training loss: 1.7674464729977282
Validation loss: 2.5831394000369685

Epoch: 6| Step: 12
Training loss: 2.100003823776397
Validation loss: 2.5775159845500744

Epoch: 6| Step: 13
Training loss: 2.3789287998276993
Validation loss: 2.5618163866960857

Epoch: 260| Step: 0
Training loss: 2.406353341397727
Validation loss: 2.5298057151689775

Epoch: 6| Step: 1
Training loss: 1.6270738719448559
Validation loss: 2.51177585287916

Epoch: 6| Step: 2
Training loss: 2.7085395343240943
Validation loss: 2.500854901813368

Epoch: 6| Step: 3
Training loss: 2.0522347667090157
Validation loss: 2.5068272683968815

Epoch: 6| Step: 4
Training loss: 2.408182136338991
Validation loss: 2.5157920187321112

Epoch: 6| Step: 5
Training loss: 2.2110505092032717
Validation loss: 2.49448576240381

Epoch: 6| Step: 6
Training loss: 2.2152714930185784
Validation loss: 2.5009011910583396

Epoch: 6| Step: 7
Training loss: 2.1757233918474177
Validation loss: 2.4829573308711996

Epoch: 6| Step: 8
Training loss: 2.0986747329238606
Validation loss: 2.4905644304286603

Epoch: 6| Step: 9
Training loss: 2.1998087496424916
Validation loss: 2.5162733533301758

Epoch: 6| Step: 10
Training loss: 2.5214503350239097
Validation loss: 2.537307330004747

Epoch: 6| Step: 11
Training loss: 2.078240183456146
Validation loss: 2.5995623177964946

Epoch: 6| Step: 12
Training loss: 2.1161560699292914
Validation loss: 2.6335165458389054

Epoch: 6| Step: 13
Training loss: 2.3236044192048357
Validation loss: 2.7066815364699344

Epoch: 261| Step: 0
Training loss: 2.0339030619339353
Validation loss: 2.706844764785888

Epoch: 6| Step: 1
Training loss: 1.967626947672322
Validation loss: 2.621304957970273

Epoch: 6| Step: 2
Training loss: 2.2349101672797826
Validation loss: 2.5361742164291514

Epoch: 6| Step: 3
Training loss: 1.7850451946146957
Validation loss: 2.4731889835227245

Epoch: 6| Step: 4
Training loss: 2.1520392173044063
Validation loss: 2.4693607796495147

Epoch: 6| Step: 5
Training loss: 2.3666047741851712
Validation loss: 2.4291265435142413

Epoch: 6| Step: 6
Training loss: 2.30070404804023
Validation loss: 2.4146748956851156

Epoch: 6| Step: 7
Training loss: 1.7250039501421386
Validation loss: 2.414783077536961

Epoch: 6| Step: 8
Training loss: 3.011766247801526
Validation loss: 2.4362985191374746

Epoch: 6| Step: 9
Training loss: 2.1565228718023013
Validation loss: 2.472526720693258

Epoch: 6| Step: 10
Training loss: 2.1616563330966816
Validation loss: 2.5055952053347834

Epoch: 6| Step: 11
Training loss: 2.148110326650814
Validation loss: 2.5369051675121717

Epoch: 6| Step: 12
Training loss: 2.4992836879677935
Validation loss: 2.60068337445861

Epoch: 6| Step: 13
Training loss: 2.959880066323472
Validation loss: 2.6249106060379854

Epoch: 262| Step: 0
Training loss: 2.043649709498141
Validation loss: 2.6425626591644886

Epoch: 6| Step: 1
Training loss: 2.1294465385581747
Validation loss: 2.6461592003568404

Epoch: 6| Step: 2
Training loss: 2.3192351951805072
Validation loss: 2.6508104919124573

Epoch: 6| Step: 3
Training loss: 2.1403110023256025
Validation loss: 2.64778942818611

Epoch: 6| Step: 4
Training loss: 2.4669052184800515
Validation loss: 2.6088279458678305

Epoch: 6| Step: 5
Training loss: 2.660070387116947
Validation loss: 2.547180179641976

Epoch: 6| Step: 6
Training loss: 2.0124798270215534
Validation loss: 2.4954995511686837

Epoch: 6| Step: 7
Training loss: 2.200819175103649
Validation loss: 2.464468817537816

Epoch: 6| Step: 8
Training loss: 2.4465825984069363
Validation loss: 2.4506319298571304

Epoch: 6| Step: 9
Training loss: 2.2347006393769693
Validation loss: 2.4432295841696354

Epoch: 6| Step: 10
Training loss: 2.1090486627266967
Validation loss: 2.431556389384931

Epoch: 6| Step: 11
Training loss: 2.2318252206686777
Validation loss: 2.4558651806354956

Epoch: 6| Step: 12
Training loss: 2.4334296451303192
Validation loss: 2.465334659536239

Epoch: 6| Step: 13
Training loss: 2.2046488368525834
Validation loss: 2.4826914099748802

Epoch: 263| Step: 0
Training loss: 2.4477585328882316
Validation loss: 2.542319216207879

Epoch: 6| Step: 1
Training loss: 2.0664271333789386
Validation loss: 2.6359943608059306

Epoch: 6| Step: 2
Training loss: 1.751629343382298
Validation loss: 2.703083954883043

Epoch: 6| Step: 3
Training loss: 2.410017556724071
Validation loss: 2.795396837789474

Epoch: 6| Step: 4
Training loss: 2.584552958956374
Validation loss: 2.8128234112194574

Epoch: 6| Step: 5
Training loss: 2.1226099822863964
Validation loss: 2.722536110132238

Epoch: 6| Step: 6
Training loss: 2.5549457197899526
Validation loss: 2.6438244298738844

Epoch: 6| Step: 7
Training loss: 2.512890389702014
Validation loss: 2.58049565687809

Epoch: 6| Step: 8
Training loss: 1.8949963814693316
Validation loss: 2.5024774110026224

Epoch: 6| Step: 9
Training loss: 2.017824732137974
Validation loss: 2.4674855196607592

Epoch: 6| Step: 10
Training loss: 2.231584206563554
Validation loss: 2.46213674810734

Epoch: 6| Step: 11
Training loss: 2.030508052596728
Validation loss: 2.4645865798476816

Epoch: 6| Step: 12
Training loss: 2.4366474127715443
Validation loss: 2.457139999038752

Epoch: 6| Step: 13
Training loss: 2.6559257758236714
Validation loss: 2.459828183163006

Epoch: 264| Step: 0
Training loss: 2.231494674303596
Validation loss: 2.4653640472771285

Epoch: 6| Step: 1
Training loss: 2.4032795393801103
Validation loss: 2.483708173557356

Epoch: 6| Step: 2
Training loss: 2.022651431305215
Validation loss: 2.512011128931636

Epoch: 6| Step: 3
Training loss: 2.231127105662314
Validation loss: 2.5382033310056658

Epoch: 6| Step: 4
Training loss: 2.6354129072521872
Validation loss: 2.580989864007244

Epoch: 6| Step: 5
Training loss: 2.2758189309873984
Validation loss: 2.5845966958097177

Epoch: 6| Step: 6
Training loss: 2.66647748474767
Validation loss: 2.5921861312807115

Epoch: 6| Step: 7
Training loss: 2.597797590727133
Validation loss: 2.584287762520163

Epoch: 6| Step: 8
Training loss: 1.8348762854051794
Validation loss: 2.538226400808204

Epoch: 6| Step: 9
Training loss: 1.5457425065961012
Validation loss: 2.522904658580918

Epoch: 6| Step: 10
Training loss: 1.8557005406207008
Validation loss: 2.491741415023334

Epoch: 6| Step: 11
Training loss: 1.7351500008241671
Validation loss: 2.4754550909047905

Epoch: 6| Step: 12
Training loss: 2.3060869526279912
Validation loss: 2.473071267504645

Epoch: 6| Step: 13
Training loss: 2.2292484613070815
Validation loss: 2.4880667996651575

Epoch: 265| Step: 0
Training loss: 2.145584709307002
Validation loss: 2.4955773621900987

Epoch: 6| Step: 1
Training loss: 2.2459353714541797
Validation loss: 2.511988638903254

Epoch: 6| Step: 2
Training loss: 1.769548293951616
Validation loss: 2.5170685708873988

Epoch: 6| Step: 3
Training loss: 2.6214092763990267
Validation loss: 2.5326081307250266

Epoch: 6| Step: 4
Training loss: 1.2382676277253717
Validation loss: 2.5297819093695892

Epoch: 6| Step: 5
Training loss: 1.9626861921294587
Validation loss: 2.5206818110922953

Epoch: 6| Step: 6
Training loss: 2.1848238242418665
Validation loss: 2.513350475347261

Epoch: 6| Step: 7
Training loss: 2.66963414146579
Validation loss: 2.4787953183878186

Epoch: 6| Step: 8
Training loss: 2.0321138159122714
Validation loss: 2.500115817473893

Epoch: 6| Step: 9
Training loss: 2.7529134922424032
Validation loss: 2.5292760225659787

Epoch: 6| Step: 10
Training loss: 1.8090201548755198
Validation loss: 2.516743317580192

Epoch: 6| Step: 11
Training loss: 2.211557901099257
Validation loss: 2.5036247197148365

Epoch: 6| Step: 12
Training loss: 2.0861804834924014
Validation loss: 2.496863484430834

Epoch: 6| Step: 13
Training loss: 2.0758186104383936
Validation loss: 2.488628962589591

Epoch: 266| Step: 0
Training loss: 1.8994065939160685
Validation loss: 2.538497714071424

Epoch: 6| Step: 1
Training loss: 2.0048440445441975
Validation loss: 2.5657349862667185

Epoch: 6| Step: 2
Training loss: 2.335369844900264
Validation loss: 2.5465624046383297

Epoch: 6| Step: 3
Training loss: 2.3554997228607295
Validation loss: 2.574564127635134

Epoch: 6| Step: 4
Training loss: 2.146738052997728
Validation loss: 2.5784861739543765

Epoch: 6| Step: 5
Training loss: 2.4749744991953917
Validation loss: 2.5724303076601363

Epoch: 6| Step: 6
Training loss: 2.2353063389647767
Validation loss: 2.5529642968249204

Epoch: 6| Step: 7
Training loss: 2.517813920845312
Validation loss: 2.529562534639433

Epoch: 6| Step: 8
Training loss: 1.9541481084965888
Validation loss: 2.5201369031813163

Epoch: 6| Step: 9
Training loss: 1.7201948162020708
Validation loss: 2.526583684059184

Epoch: 6| Step: 10
Training loss: 1.9022439856091364
Validation loss: 2.522160733757476

Epoch: 6| Step: 11
Training loss: 1.8782743473940033
Validation loss: 2.5299664596344114

Epoch: 6| Step: 12
Training loss: 2.292453168517558
Validation loss: 2.5560508422588444

Epoch: 6| Step: 13
Training loss: 2.07762059565204
Validation loss: 2.5579261578282226

Epoch: 267| Step: 0
Training loss: 2.1929469277030322
Validation loss: 2.6260426311632132

Epoch: 6| Step: 1
Training loss: 2.184986523340072
Validation loss: 2.6787696533376413

Epoch: 6| Step: 2
Training loss: 2.2511790683041633
Validation loss: 2.6955076494470265

Epoch: 6| Step: 3
Training loss: 2.2315271542021184
Validation loss: 2.674298424004358

Epoch: 6| Step: 4
Training loss: 2.1539886337093725
Validation loss: 2.6201309385303424

Epoch: 6| Step: 5
Training loss: 2.4435570604106855
Validation loss: 2.5570499158950537

Epoch: 6| Step: 6
Training loss: 2.406945363425067
Validation loss: 2.5201087645276496

Epoch: 6| Step: 7
Training loss: 2.0621393061736653
Validation loss: 2.469332243034737

Epoch: 6| Step: 8
Training loss: 2.0681039221972894
Validation loss: 2.4802856005625764

Epoch: 6| Step: 9
Training loss: 2.2488910273318536
Validation loss: 2.4849692828503187

Epoch: 6| Step: 10
Training loss: 2.0139138698855477
Validation loss: 2.51396431945057

Epoch: 6| Step: 11
Training loss: 1.736048672718905
Validation loss: 2.527053994164679

Epoch: 6| Step: 12
Training loss: 1.996083298747254
Validation loss: 2.5074014803184554

Epoch: 6| Step: 13
Training loss: 2.4791166690518525
Validation loss: 2.5021857643197496

Epoch: 268| Step: 0
Training loss: 1.3960704696925783
Validation loss: 2.49344077666419

Epoch: 6| Step: 1
Training loss: 2.562260686352796
Validation loss: 2.453514219253683

Epoch: 6| Step: 2
Training loss: 1.7754999343240394
Validation loss: 2.4520400332288426

Epoch: 6| Step: 3
Training loss: 2.2413668842123
Validation loss: 2.4833105759184586

Epoch: 6| Step: 4
Training loss: 1.9071258033900267
Validation loss: 2.470815164215326

Epoch: 6| Step: 5
Training loss: 2.321899077135321
Validation loss: 2.5082979015867273

Epoch: 6| Step: 6
Training loss: 2.232279828909921
Validation loss: 2.528830395374752

Epoch: 6| Step: 7
Training loss: 1.5339713534897015
Validation loss: 2.5632677566329143

Epoch: 6| Step: 8
Training loss: 2.1497239578822147
Validation loss: 2.5863919502105577

Epoch: 6| Step: 9
Training loss: 1.8707529924412862
Validation loss: 2.6094167665603734

Epoch: 6| Step: 10
Training loss: 2.7240646856976864
Validation loss: 2.6118957907327887

Epoch: 6| Step: 11
Training loss: 2.560269757601619
Validation loss: 2.5716697125998382

Epoch: 6| Step: 12
Training loss: 2.424463279554609
Validation loss: 2.5338468545312156

Epoch: 6| Step: 13
Training loss: 1.8048110853542951
Validation loss: 2.517816255579107

Epoch: 269| Step: 0
Training loss: 2.2487693175948715
Validation loss: 2.4662127173828114

Epoch: 6| Step: 1
Training loss: 2.187906282025302
Validation loss: 2.44356380009563

Epoch: 6| Step: 2
Training loss: 1.9932724335892562
Validation loss: 2.431675846276204

Epoch: 6| Step: 3
Training loss: 2.137197046951633
Validation loss: 2.4205067591280702

Epoch: 6| Step: 4
Training loss: 2.5051670084272435
Validation loss: 2.4250152748733904

Epoch: 6| Step: 5
Training loss: 1.9855014277241476
Validation loss: 2.42500422589097

Epoch: 6| Step: 6
Training loss: 2.062390989254902
Validation loss: 2.4236147429669033

Epoch: 6| Step: 7
Training loss: 2.074954259896845
Validation loss: 2.449671607708255

Epoch: 6| Step: 8
Training loss: 2.028148572223436
Validation loss: 2.519499548353062

Epoch: 6| Step: 9
Training loss: 1.6979757037362213
Validation loss: 2.530249640660552

Epoch: 6| Step: 10
Training loss: 1.973719425556503
Validation loss: 2.6027358569607

Epoch: 6| Step: 11
Training loss: 2.4753399548033204
Validation loss: 2.6226510692958027

Epoch: 6| Step: 12
Training loss: 2.3547398592387014
Validation loss: 2.6360265792997257

Epoch: 6| Step: 13
Training loss: 1.9469924474960578
Validation loss: 2.5869905945786216

Epoch: 270| Step: 0
Training loss: 2.205091315906626
Validation loss: 2.560790453374968

Epoch: 6| Step: 1
Training loss: 2.3253019485470063
Validation loss: 2.5615302200924726

Epoch: 6| Step: 2
Training loss: 2.5333543672023064
Validation loss: 2.5601259925368542

Epoch: 6| Step: 3
Training loss: 1.7650865392028925
Validation loss: 2.5597295043081574

Epoch: 6| Step: 4
Training loss: 1.9106245656460663
Validation loss: 2.567303857535682

Epoch: 6| Step: 5
Training loss: 2.2768926942626266
Validation loss: 2.5540215296959863

Epoch: 6| Step: 6
Training loss: 2.4042256745270763
Validation loss: 2.5586605466283086

Epoch: 6| Step: 7
Training loss: 2.0981106115080204
Validation loss: 2.545056273807708

Epoch: 6| Step: 8
Training loss: 1.8819282956464718
Validation loss: 2.554797527895017

Epoch: 6| Step: 9
Training loss: 2.045714070973914
Validation loss: 2.5698765534827634

Epoch: 6| Step: 10
Training loss: 2.243094124739621
Validation loss: 2.571503802844765

Epoch: 6| Step: 11
Training loss: 1.6538050617442723
Validation loss: 2.554194294108722

Epoch: 6| Step: 12
Training loss: 2.3423508600495158
Validation loss: 2.5575153201318197

Epoch: 6| Step: 13
Training loss: 1.533668321146104
Validation loss: 2.5400320055218266

Epoch: 271| Step: 0
Training loss: 1.7539531472102219
Validation loss: 2.5288159593149375

Epoch: 6| Step: 1
Training loss: 2.140669773496743
Validation loss: 2.5111774242787273

Epoch: 6| Step: 2
Training loss: 2.4583523205384887
Validation loss: 2.546573198521327

Epoch: 6| Step: 3
Training loss: 2.5709500435212154
Validation loss: 2.561186272878984

Epoch: 6| Step: 4
Training loss: 1.8245223975026033
Validation loss: 2.557211760864478

Epoch: 6| Step: 5
Training loss: 1.5968821545942646
Validation loss: 2.5458747675782063

Epoch: 6| Step: 6
Training loss: 1.965738202884986
Validation loss: 2.5090535835367604

Epoch: 6| Step: 7
Training loss: 2.0150305292736954
Validation loss: 2.5326523921208315

Epoch: 6| Step: 8
Training loss: 2.0953088906845196
Validation loss: 2.536311669392462

Epoch: 6| Step: 9
Training loss: 2.416650465110753
Validation loss: 2.497420770936228

Epoch: 6| Step: 10
Training loss: 2.4035923140089483
Validation loss: 2.5334110653949016

Epoch: 6| Step: 11
Training loss: 2.0316817778394896
Validation loss: 2.494722186092608

Epoch: 6| Step: 12
Training loss: 1.8147281894027447
Validation loss: 2.508755504269535

Epoch: 6| Step: 13
Training loss: 1.9156127257210571
Validation loss: 2.499447688753864

Epoch: 272| Step: 0
Training loss: 1.9440276410684807
Validation loss: 2.484860299110999

Epoch: 6| Step: 1
Training loss: 1.311463718943588
Validation loss: 2.5152269844827595

Epoch: 6| Step: 2
Training loss: 2.3070718102227366
Validation loss: 2.5201016293590706

Epoch: 6| Step: 3
Training loss: 2.225022382302166
Validation loss: 2.5466620238370323

Epoch: 6| Step: 4
Training loss: 1.7432400385009763
Validation loss: 2.553216348107563

Epoch: 6| Step: 5
Training loss: 2.3524575795353213
Validation loss: 2.550239231904416

Epoch: 6| Step: 6
Training loss: 2.094416384195598
Validation loss: 2.5261415185064706

Epoch: 6| Step: 7
Training loss: 2.3699883236174926
Validation loss: 2.513188126457805

Epoch: 6| Step: 8
Training loss: 1.8521491944052946
Validation loss: 2.4990069539756896

Epoch: 6| Step: 9
Training loss: 2.152525850820879
Validation loss: 2.47957073347473

Epoch: 6| Step: 10
Training loss: 2.4705349227885884
Validation loss: 2.480452095630182

Epoch: 6| Step: 11
Training loss: 1.8698733496998792
Validation loss: 2.501830461478874

Epoch: 6| Step: 12
Training loss: 2.0527105647628963
Validation loss: 2.5013324468179796

Epoch: 6| Step: 13
Training loss: 2.373205611331902
Validation loss: 2.5109077136411875

Epoch: 273| Step: 0
Training loss: 1.780774571733503
Validation loss: 2.5470776271283264

Epoch: 6| Step: 1
Training loss: 1.7526154727958436
Validation loss: 2.537336477234725

Epoch: 6| Step: 2
Training loss: 2.3703947089466753
Validation loss: 2.568705741066505

Epoch: 6| Step: 3
Training loss: 1.910750782188965
Validation loss: 2.574068816273329

Epoch: 6| Step: 4
Training loss: 2.071598560423939
Validation loss: 2.6047320303899837

Epoch: 6| Step: 5
Training loss: 2.0779210040705864
Validation loss: 2.610490149621337

Epoch: 6| Step: 6
Training loss: 1.9093965919385099
Validation loss: 2.562827455781157

Epoch: 6| Step: 7
Training loss: 1.8983272316387783
Validation loss: 2.521683007091998

Epoch: 6| Step: 8
Training loss: 2.0747717858253316
Validation loss: 2.479169577926646

Epoch: 6| Step: 9
Training loss: 1.9349677858455763
Validation loss: 2.4836570810198384

Epoch: 6| Step: 10
Training loss: 2.5316384099907374
Validation loss: 2.4596217526222683

Epoch: 6| Step: 11
Training loss: 2.185701775537302
Validation loss: 2.4728117697251277

Epoch: 6| Step: 12
Training loss: 2.2266238555485525
Validation loss: 2.456116175158625

Epoch: 6| Step: 13
Training loss: 2.058562942650766
Validation loss: 2.50372604477514

Epoch: 274| Step: 0
Training loss: 2.5675103122166076
Validation loss: 2.54491140049764

Epoch: 6| Step: 1
Training loss: 1.4581479454279032
Validation loss: 2.584913917109918

Epoch: 6| Step: 2
Training loss: 1.9835205040562591
Validation loss: 2.6143377999592934

Epoch: 6| Step: 3
Training loss: 1.7721293325737848
Validation loss: 2.6656963296768925

Epoch: 6| Step: 4
Training loss: 2.2110005831396333
Validation loss: 2.636817126335986

Epoch: 6| Step: 5
Training loss: 1.9123417807561967
Validation loss: 2.6119055235151105

Epoch: 6| Step: 6
Training loss: 1.6913997658832123
Validation loss: 2.6306677892263304

Epoch: 6| Step: 7
Training loss: 2.0776857758052345
Validation loss: 2.6255256411723407

Epoch: 6| Step: 8
Training loss: 2.3288614017297804
Validation loss: 2.6039737316566662

Epoch: 6| Step: 9
Training loss: 2.4490310621367275
Validation loss: 2.5561754295788375

Epoch: 6| Step: 10
Training loss: 1.7892194121068645
Validation loss: 2.517431677504748

Epoch: 6| Step: 11
Training loss: 2.3639175441194027
Validation loss: 2.4823293583070587

Epoch: 6| Step: 12
Training loss: 1.8152652561359393
Validation loss: 2.462915707613575

Epoch: 6| Step: 13
Training loss: 2.133698220141501
Validation loss: 2.4765869669418783

Epoch: 275| Step: 0
Training loss: 2.183929144635664
Validation loss: 2.468641341302509

Epoch: 6| Step: 1
Training loss: 1.9572108142578188
Validation loss: 2.487755762189691

Epoch: 6| Step: 2
Training loss: 2.060419825393009
Validation loss: 2.530834697165878

Epoch: 6| Step: 3
Training loss: 1.9771935582629607
Validation loss: 2.5828178133195014

Epoch: 6| Step: 4
Training loss: 1.9301839954250652
Validation loss: 2.619031445295215

Epoch: 6| Step: 5
Training loss: 2.7903977731975806
Validation loss: 2.6213000875174144

Epoch: 6| Step: 6
Training loss: 2.205267655612771
Validation loss: 2.5979375787587653

Epoch: 6| Step: 7
Training loss: 2.032884732252482
Validation loss: 2.5693505130779277

Epoch: 6| Step: 8
Training loss: 1.8901717848642745
Validation loss: 2.571304209266029

Epoch: 6| Step: 9
Training loss: 1.397252694428174
Validation loss: 2.558730680910745

Epoch: 6| Step: 10
Training loss: 1.9707538155878457
Validation loss: 2.550763056676569

Epoch: 6| Step: 11
Training loss: 1.9124114097072935
Validation loss: 2.5591429633739287

Epoch: 6| Step: 12
Training loss: 1.9893118654827942
Validation loss: 2.5346329451964125

Epoch: 6| Step: 13
Training loss: 1.9757285790231283
Validation loss: 2.5211835587577816

Epoch: 276| Step: 0
Training loss: 1.8453996681342897
Validation loss: 2.539685420382849

Epoch: 6| Step: 1
Training loss: 1.920741111157857
Validation loss: 2.5345406613401247

Epoch: 6| Step: 2
Training loss: 2.424915595404596
Validation loss: 2.566896496255168

Epoch: 6| Step: 3
Training loss: 2.2764226971326105
Validation loss: 2.531687651201624

Epoch: 6| Step: 4
Training loss: 2.3290940898399515
Validation loss: 2.5392444408471446

Epoch: 6| Step: 5
Training loss: 1.5368137099496983
Validation loss: 2.5448510831263738

Epoch: 6| Step: 6
Training loss: 1.9140146677696857
Validation loss: 2.5307378631893434

Epoch: 6| Step: 7
Training loss: 2.2163910481708466
Validation loss: 2.5134250338546744

Epoch: 6| Step: 8
Training loss: 1.932781256852627
Validation loss: 2.4913461932688774

Epoch: 6| Step: 9
Training loss: 2.293349486264556
Validation loss: 2.4993661066597066

Epoch: 6| Step: 10
Training loss: 2.2029264103550297
Validation loss: 2.5253558357009283

Epoch: 6| Step: 11
Training loss: 1.0540719956016387
Validation loss: 2.52973266197228

Epoch: 6| Step: 12
Training loss: 1.8842621600272536
Validation loss: 2.5764701277720667

Epoch: 6| Step: 13
Training loss: 2.12132124269222
Validation loss: 2.557584538581247

Epoch: 277| Step: 0
Training loss: 2.2501004514523295
Validation loss: 2.615028184333268

Epoch: 6| Step: 1
Training loss: 1.7543384724596758
Validation loss: 2.652427500816223

Epoch: 6| Step: 2
Training loss: 2.1383226919566005
Validation loss: 2.660967898670743

Epoch: 6| Step: 3
Training loss: 1.6153203533127087
Validation loss: 2.639346871701717

Epoch: 6| Step: 4
Training loss: 2.0262168148271984
Validation loss: 2.6785915399393105

Epoch: 6| Step: 5
Training loss: 2.2819891999212287
Validation loss: 2.664416300654441

Epoch: 6| Step: 6
Training loss: 1.7794032646054068
Validation loss: 2.598229157374963

Epoch: 6| Step: 7
Training loss: 1.8062863224165748
Validation loss: 2.56016839631996

Epoch: 6| Step: 8
Training loss: 2.0089829888618103
Validation loss: 2.50931102117558

Epoch: 6| Step: 9
Training loss: 1.9059670660449892
Validation loss: 2.467678521878586

Epoch: 6| Step: 10
Training loss: 2.4974590740344578
Validation loss: 2.4454619245268097

Epoch: 6| Step: 11
Training loss: 2.0294456096991245
Validation loss: 2.4303366506729547

Epoch: 6| Step: 12
Training loss: 1.9394758670698982
Validation loss: 2.4098409853142044

Epoch: 6| Step: 13
Training loss: 2.265110983582115
Validation loss: 2.4640899078001586

Epoch: 278| Step: 0
Training loss: 1.995551227815283
Validation loss: 2.4432127766877634

Epoch: 6| Step: 1
Training loss: 2.4172436146057548
Validation loss: 2.4463486410366673

Epoch: 6| Step: 2
Training loss: 1.9293396053150749
Validation loss: 2.4674660046313535

Epoch: 6| Step: 3
Training loss: 1.8912004588131421
Validation loss: 2.4566582746311334

Epoch: 6| Step: 4
Training loss: 2.1851519380376208
Validation loss: 2.465980653588641

Epoch: 6| Step: 5
Training loss: 2.585147886934238
Validation loss: 2.483572671107904

Epoch: 6| Step: 6
Training loss: 2.1727743139358298
Validation loss: 2.499716378602838

Epoch: 6| Step: 7
Training loss: 1.889660171354073
Validation loss: 2.539165394404346

Epoch: 6| Step: 8
Training loss: 1.8974536497061538
Validation loss: 2.570029443028178

Epoch: 6| Step: 9
Training loss: 1.7050188366696826
Validation loss: 2.607825779399806

Epoch: 6| Step: 10
Training loss: 1.8788157736710813
Validation loss: 2.5750528735347475

Epoch: 6| Step: 11
Training loss: 1.7076356284925849
Validation loss: 2.5833459914020067

Epoch: 6| Step: 12
Training loss: 2.118264350258122
Validation loss: 2.5602112239687327

Epoch: 6| Step: 13
Training loss: 1.2988250044017964
Validation loss: 2.5531954560711396

Epoch: 279| Step: 0
Training loss: 2.104214834536924
Validation loss: 2.606775112668384

Epoch: 6| Step: 1
Training loss: 2.0937304140000426
Validation loss: 2.6252654391152803

Epoch: 6| Step: 2
Training loss: 1.7751190682892244
Validation loss: 2.623392924768815

Epoch: 6| Step: 3
Training loss: 1.9551958016298985
Validation loss: 2.624235115984112

Epoch: 6| Step: 4
Training loss: 1.9987783873488296
Validation loss: 2.5996349421567104

Epoch: 6| Step: 5
Training loss: 1.426346507439005
Validation loss: 2.582682207624231

Epoch: 6| Step: 6
Training loss: 2.407773514022929
Validation loss: 2.5854447244782905

Epoch: 6| Step: 7
Training loss: 2.3235225372042327
Validation loss: 2.596174808440123

Epoch: 6| Step: 8
Training loss: 1.9415555777580609
Validation loss: 2.5715154490970686

Epoch: 6| Step: 9
Training loss: 1.8706363764046372
Validation loss: 2.5758316434965884

Epoch: 6| Step: 10
Training loss: 1.9817499534786907
Validation loss: 2.5891272621403036

Epoch: 6| Step: 11
Training loss: 1.932985028867573
Validation loss: 2.6123021575237724

Epoch: 6| Step: 12
Training loss: 2.095726560548717
Validation loss: 2.639026538372636

Epoch: 6| Step: 13
Training loss: 1.9194605477788207
Validation loss: 2.6063723929877933

Epoch: 280| Step: 0
Training loss: 2.3371666573682686
Validation loss: 2.530208484275086

Epoch: 6| Step: 1
Training loss: 2.172212862589196
Validation loss: 2.49330296323156

Epoch: 6| Step: 2
Training loss: 1.8891410994289537
Validation loss: 2.471245527897097

Epoch: 6| Step: 3
Training loss: 1.7392595260071921
Validation loss: 2.474667661538422

Epoch: 6| Step: 4
Training loss: 2.039335619879134
Validation loss: 2.486892845246206

Epoch: 6| Step: 5
Training loss: 1.6689499553082363
Validation loss: 2.524626627165031

Epoch: 6| Step: 6
Training loss: 2.184962081056396
Validation loss: 2.5197152472089077

Epoch: 6| Step: 7
Training loss: 1.6724909423217924
Validation loss: 2.519815521343687

Epoch: 6| Step: 8
Training loss: 1.909432428123813
Validation loss: 2.5631949460087275

Epoch: 6| Step: 9
Training loss: 1.7443043118310344
Validation loss: 2.5911546817174376

Epoch: 6| Step: 10
Training loss: 1.4393353562852484
Validation loss: 2.6141500401201467

Epoch: 6| Step: 11
Training loss: 2.150422666832409
Validation loss: 2.639267670353669

Epoch: 6| Step: 12
Training loss: 2.622086042928839
Validation loss: 2.6044369343620035

Epoch: 6| Step: 13
Training loss: 2.4615123259092218
Validation loss: 2.5718131633124823

Epoch: 281| Step: 0
Training loss: 1.8626252305089752
Validation loss: 2.5424645124982073

Epoch: 6| Step: 1
Training loss: 1.9219071920536521
Validation loss: 2.5284399459474414

Epoch: 6| Step: 2
Training loss: 2.164384177637649
Validation loss: 2.5012532507686243

Epoch: 6| Step: 3
Training loss: 1.6499882495346125
Validation loss: 2.4837695417383685

Epoch: 6| Step: 4
Training loss: 2.154746374442103
Validation loss: 2.499114399095859

Epoch: 6| Step: 5
Training loss: 1.839280092757228
Validation loss: 2.5291099054481756

Epoch: 6| Step: 6
Training loss: 1.840498109339308
Validation loss: 2.5380786245935827

Epoch: 6| Step: 7
Training loss: 2.118413816354245
Validation loss: 2.58800340768519

Epoch: 6| Step: 8
Training loss: 2.2627557936592013
Validation loss: 2.625700142849938

Epoch: 6| Step: 9
Training loss: 1.9831536807376628
Validation loss: 2.6160067808304768

Epoch: 6| Step: 10
Training loss: 1.7757086642090516
Validation loss: 2.5864208168676703

Epoch: 6| Step: 11
Training loss: 2.1501943722179795
Validation loss: 2.542382997877149

Epoch: 6| Step: 12
Training loss: 2.228030286490633
Validation loss: 2.5265947479619792

Epoch: 6| Step: 13
Training loss: 1.2926938320743127
Validation loss: 2.5108644549649197

Epoch: 282| Step: 0
Training loss: 1.823165556855734
Validation loss: 2.5146359763318062

Epoch: 6| Step: 1
Training loss: 1.993878951730687
Validation loss: 2.5344336362607156

Epoch: 6| Step: 2
Training loss: 2.3975735080496414
Validation loss: 2.579514924749771

Epoch: 6| Step: 3
Training loss: 1.748259769027824
Validation loss: 2.600306877913162

Epoch: 6| Step: 4
Training loss: 1.8751302673863965
Validation loss: 2.607864214667884

Epoch: 6| Step: 5
Training loss: 2.069202514206815
Validation loss: 2.578931050163443

Epoch: 6| Step: 6
Training loss: 1.4162440043471476
Validation loss: 2.5906472979592055

Epoch: 6| Step: 7
Training loss: 1.9057809221305417
Validation loss: 2.551150677454012

Epoch: 6| Step: 8
Training loss: 1.9449324025859258
Validation loss: 2.5241166728563513

Epoch: 6| Step: 9
Training loss: 2.51850243196565
Validation loss: 2.4989158227857513

Epoch: 6| Step: 10
Training loss: 2.31595044854214
Validation loss: 2.453512802388976

Epoch: 6| Step: 11
Training loss: 1.826561283473384
Validation loss: 2.471742942763865

Epoch: 6| Step: 12
Training loss: 1.7967254576444631
Validation loss: 2.4842806490096545

Epoch: 6| Step: 13
Training loss: 1.6464241351672806
Validation loss: 2.526264925648365

Epoch: 283| Step: 0
Training loss: 1.982225831208605
Validation loss: 2.5158943037726393

Epoch: 6| Step: 1
Training loss: 2.0164880605164925
Validation loss: 2.552998778191452

Epoch: 6| Step: 2
Training loss: 1.3538948177464718
Validation loss: 2.5611191817698122

Epoch: 6| Step: 3
Training loss: 2.2425347567685416
Validation loss: 2.5852146588920575

Epoch: 6| Step: 4
Training loss: 2.0206173129161167
Validation loss: 2.6033827502960443

Epoch: 6| Step: 5
Training loss: 1.7234978036714332
Validation loss: 2.5422834081474694

Epoch: 6| Step: 6
Training loss: 1.5725013319291872
Validation loss: 2.539248843742328

Epoch: 6| Step: 7
Training loss: 1.9146845838183046
Validation loss: 2.5149324371155415

Epoch: 6| Step: 8
Training loss: 2.142201309660425
Validation loss: 2.5206927513951727

Epoch: 6| Step: 9
Training loss: 1.7768954539589341
Validation loss: 2.4880902163615017

Epoch: 6| Step: 10
Training loss: 2.161522652155478
Validation loss: 2.5263686101843894

Epoch: 6| Step: 11
Training loss: 1.9941978334296702
Validation loss: 2.510436796845379

Epoch: 6| Step: 12
Training loss: 2.248658310026551
Validation loss: 2.527193296412688

Epoch: 6| Step: 13
Training loss: 2.198741691708116
Validation loss: 2.5815294724613254

Epoch: 284| Step: 0
Training loss: 1.8878279874684465
Validation loss: 2.6174866678139885

Epoch: 6| Step: 1
Training loss: 2.1822068615977264
Validation loss: 2.6286771326709664

Epoch: 6| Step: 2
Training loss: 1.983110280143096
Validation loss: 2.6573153140795185

Epoch: 6| Step: 3
Training loss: 2.1549261700934133
Validation loss: 2.6327494182875952

Epoch: 6| Step: 4
Training loss: 1.6912132664065411
Validation loss: 2.617633957939834

Epoch: 6| Step: 5
Training loss: 1.8005782072904966
Validation loss: 2.613338133907157

Epoch: 6| Step: 6
Training loss: 1.8150432764363813
Validation loss: 2.57426314742256

Epoch: 6| Step: 7
Training loss: 2.138789148468461
Validation loss: 2.533654204882397

Epoch: 6| Step: 8
Training loss: 1.6191105857059662
Validation loss: 2.4911087390846447

Epoch: 6| Step: 9
Training loss: 2.0845684459316574
Validation loss: 2.4807464441583065

Epoch: 6| Step: 10
Training loss: 1.9304641828556293
Validation loss: 2.462278991079489

Epoch: 6| Step: 11
Training loss: 2.3885518977304754
Validation loss: 2.462223879475461

Epoch: 6| Step: 12
Training loss: 1.8221272603091807
Validation loss: 2.5048271578081622

Epoch: 6| Step: 13
Training loss: 1.4583923691198912
Validation loss: 2.53990283674933

Epoch: 285| Step: 0
Training loss: 2.0856630523383695
Validation loss: 2.574161162969278

Epoch: 6| Step: 1
Training loss: 2.2742172948845076
Validation loss: 2.59149404407935

Epoch: 6| Step: 2
Training loss: 1.4805653724241576
Validation loss: 2.594628677554372

Epoch: 6| Step: 3
Training loss: 1.9121689753064481
Validation loss: 2.63247712218931

Epoch: 6| Step: 4
Training loss: 2.2325382819743442
Validation loss: 2.6565773411765123

Epoch: 6| Step: 5
Training loss: 1.8945932279850939
Validation loss: 2.6357761111830906

Epoch: 6| Step: 6
Training loss: 2.304747913667922
Validation loss: 2.6295592243069765

Epoch: 6| Step: 7
Training loss: 1.9582626519400186
Validation loss: 2.6163736977533594

Epoch: 6| Step: 8
Training loss: 1.7653412717533161
Validation loss: 2.5818657201065496

Epoch: 6| Step: 9
Training loss: 2.2829844530790147
Validation loss: 2.526568823205215

Epoch: 6| Step: 10
Training loss: 1.5837943342908856
Validation loss: 2.51672623910245

Epoch: 6| Step: 11
Training loss: 2.1063102781460015
Validation loss: 2.4793933390104654

Epoch: 6| Step: 12
Training loss: 1.4859499957885969
Validation loss: 2.4982279126694675

Epoch: 6| Step: 13
Training loss: 1.7743721402243653
Validation loss: 2.4756743227919773

Epoch: 286| Step: 0
Training loss: 2.174617435528779
Validation loss: 2.4876408099772105

Epoch: 6| Step: 1
Training loss: 1.7680109158088333
Validation loss: 2.4996146787034776

Epoch: 6| Step: 2
Training loss: 1.5427962967313629
Validation loss: 2.5300877236044417

Epoch: 6| Step: 3
Training loss: 2.017251711177254
Validation loss: 2.575235110814666

Epoch: 6| Step: 4
Training loss: 1.9066089229687464
Validation loss: 2.5981522449205356

Epoch: 6| Step: 5
Training loss: 2.472709088717627
Validation loss: 2.6360793798991295

Epoch: 6| Step: 6
Training loss: 2.5470579116761614
Validation loss: 2.6229910382744834

Epoch: 6| Step: 7
Training loss: 1.5897216750007799
Validation loss: 2.6148844102186226

Epoch: 6| Step: 8
Training loss: 1.4816506532047593
Validation loss: 2.6125394484253

Epoch: 6| Step: 9
Training loss: 2.065246949104371
Validation loss: 2.585164480670053

Epoch: 6| Step: 10
Training loss: 1.3253449009103324
Validation loss: 2.5660690535863235

Epoch: 6| Step: 11
Training loss: 1.8095597062518032
Validation loss: 2.552130493839996

Epoch: 6| Step: 12
Training loss: 1.923408082912169
Validation loss: 2.534708544490597

Epoch: 6| Step: 13
Training loss: 2.0519976396305424
Validation loss: 2.5297780509068786

Epoch: 287| Step: 0
Training loss: 1.8896305842381746
Validation loss: 2.525642770661853

Epoch: 6| Step: 1
Training loss: 1.8992767362792815
Validation loss: 2.548939877259908

Epoch: 6| Step: 2
Training loss: 2.0730611728414514
Validation loss: 2.5666420198138002

Epoch: 6| Step: 3
Training loss: 2.004782680235118
Validation loss: 2.6120615591311482

Epoch: 6| Step: 4
Training loss: 1.7998705234584513
Validation loss: 2.6128129991319597

Epoch: 6| Step: 5
Training loss: 1.9502043592523015
Validation loss: 2.6544978366562124

Epoch: 6| Step: 6
Training loss: 2.1679335582729324
Validation loss: 2.6658393376972778

Epoch: 6| Step: 7
Training loss: 1.3459921472498917
Validation loss: 2.679050336919517

Epoch: 6| Step: 8
Training loss: 1.592116622170791
Validation loss: 2.633561943066719

Epoch: 6| Step: 9
Training loss: 2.180815811446393
Validation loss: 2.6300773796751997

Epoch: 6| Step: 10
Training loss: 1.9365053392450433
Validation loss: 2.5675390636566413

Epoch: 6| Step: 11
Training loss: 1.804626331696399
Validation loss: 2.551679397838134

Epoch: 6| Step: 12
Training loss: 2.104928649816685
Validation loss: 2.511030869952301

Epoch: 6| Step: 13
Training loss: 1.683102777322333
Validation loss: 2.54537744140047

Epoch: 288| Step: 0
Training loss: 2.052632976317863
Validation loss: 2.5017492081481256

Epoch: 6| Step: 1
Training loss: 1.9210261509479074
Validation loss: 2.4960854790637654

Epoch: 6| Step: 2
Training loss: 1.670507352934397
Validation loss: 2.501882236774548

Epoch: 6| Step: 3
Training loss: 2.0103452864181763
Validation loss: 2.514681943595938

Epoch: 6| Step: 4
Training loss: 1.836085147196373
Validation loss: 2.53260122613667

Epoch: 6| Step: 5
Training loss: 1.9715821618517466
Validation loss: 2.5814119021596182

Epoch: 6| Step: 6
Training loss: 1.8404817224251522
Validation loss: 2.638036888791297

Epoch: 6| Step: 7
Training loss: 1.5275722635160904
Validation loss: 2.599932204270548

Epoch: 6| Step: 8
Training loss: 1.8354642217438502
Validation loss: 2.625323916762421

Epoch: 6| Step: 9
Training loss: 1.862045486087193
Validation loss: 2.574467994449431

Epoch: 6| Step: 10
Training loss: 1.9739172804563592
Validation loss: 2.5638540678658273

Epoch: 6| Step: 11
Training loss: 2.300969114551385
Validation loss: 2.4963340850912594

Epoch: 6| Step: 12
Training loss: 1.9329760248677745
Validation loss: 2.4869438888314677

Epoch: 6| Step: 13
Training loss: 1.9197954541764246
Validation loss: 2.5017098476034656

Epoch: 289| Step: 0
Training loss: 1.9085745474387694
Validation loss: 2.5258803956885925

Epoch: 6| Step: 1
Training loss: 2.1512026106974975
Validation loss: 2.518145255248058

Epoch: 6| Step: 2
Training loss: 1.720244711390048
Validation loss: 2.5694384916178015

Epoch: 6| Step: 3
Training loss: 1.5509472813356429
Validation loss: 2.6116022796607616

Epoch: 6| Step: 4
Training loss: 2.077923528327064
Validation loss: 2.6209779456470863

Epoch: 6| Step: 5
Training loss: 1.735180367100801
Validation loss: 2.636411818882057

Epoch: 6| Step: 6
Training loss: 1.4395241790998632
Validation loss: 2.6322399602700126

Epoch: 6| Step: 7
Training loss: 2.0359867912643446
Validation loss: 2.623274427906711

Epoch: 6| Step: 8
Training loss: 1.4114108013112212
Validation loss: 2.5869962520434826

Epoch: 6| Step: 9
Training loss: 2.069140984504759
Validation loss: 2.5871359218009884

Epoch: 6| Step: 10
Training loss: 1.950199530247849
Validation loss: 2.5955659805457842

Epoch: 6| Step: 11
Training loss: 2.1951246079374536
Validation loss: 2.5760182612714577

Epoch: 6| Step: 12
Training loss: 1.987934314609736
Validation loss: 2.5615025741850115

Epoch: 6| Step: 13
Training loss: 2.135446787055739
Validation loss: 2.551499854853168

Epoch: 290| Step: 0
Training loss: 2.0863818434738506
Validation loss: 2.5738626625607237

Epoch: 6| Step: 1
Training loss: 2.0766448292367317
Validation loss: 2.576313693857686

Epoch: 6| Step: 2
Training loss: 2.0101812616861157
Validation loss: 2.5613559196812856

Epoch: 6| Step: 3
Training loss: 1.1937332691398264
Validation loss: 2.549511435046417

Epoch: 6| Step: 4
Training loss: 1.9869953786472743
Validation loss: 2.563051204989605

Epoch: 6| Step: 5
Training loss: 1.9406521904310554
Validation loss: 2.5528952382990093

Epoch: 6| Step: 6
Training loss: 1.8072981014375344
Validation loss: 2.5756963562650417

Epoch: 6| Step: 7
Training loss: 1.8152328146428494
Validation loss: 2.5926198185980343

Epoch: 6| Step: 8
Training loss: 1.812075598127086
Validation loss: 2.6045787019347695

Epoch: 6| Step: 9
Training loss: 1.5256366213895438
Validation loss: 2.5871749409013023

Epoch: 6| Step: 10
Training loss: 1.9514287678304165
Validation loss: 2.6147839228582166

Epoch: 6| Step: 11
Training loss: 2.104809603020145
Validation loss: 2.5854795064175327

Epoch: 6| Step: 12
Training loss: 1.58524920180222
Validation loss: 2.5821632754980572

Epoch: 6| Step: 13
Training loss: 2.099522050327939
Validation loss: 2.578060977920214

Epoch: 291| Step: 0
Training loss: 2.0199439329921116
Validation loss: 2.5691439927327133

Epoch: 6| Step: 1
Training loss: 1.7567830780202727
Validation loss: 2.59477397119818

Epoch: 6| Step: 2
Training loss: 1.5053543847140716
Validation loss: 2.55501853271028

Epoch: 6| Step: 3
Training loss: 2.107913719105311
Validation loss: 2.525737588279735

Epoch: 6| Step: 4
Training loss: 2.0328806274163536
Validation loss: 2.5331202942313773

Epoch: 6| Step: 5
Training loss: 1.8167368598232867
Validation loss: 2.5053252201690404

Epoch: 6| Step: 6
Training loss: 1.9000650344560193
Validation loss: 2.5105403559400394

Epoch: 6| Step: 7
Training loss: 1.7319400637742133
Validation loss: 2.5084174423934464

Epoch: 6| Step: 8
Training loss: 2.148743097938872
Validation loss: 2.5091853886465185

Epoch: 6| Step: 9
Training loss: 1.6634854314571457
Validation loss: 2.5260675342496763

Epoch: 6| Step: 10
Training loss: 1.8668971135171044
Validation loss: 2.541399275137721

Epoch: 6| Step: 11
Training loss: 2.1489207331193545
Validation loss: 2.5932564303483456

Epoch: 6| Step: 12
Training loss: 1.45106664098903
Validation loss: 2.607849337264441

Epoch: 6| Step: 13
Training loss: 1.55282987864706
Validation loss: 2.666821654748213

Epoch: 292| Step: 0
Training loss: 1.9628994310475665
Validation loss: 2.651173521347672

Epoch: 6| Step: 1
Training loss: 1.8041715999239223
Validation loss: 2.666554184401258

Epoch: 6| Step: 2
Training loss: 1.9585637775405655
Validation loss: 2.690426081822175

Epoch: 6| Step: 3
Training loss: 2.055307389076517
Validation loss: 2.6580142074548214

Epoch: 6| Step: 4
Training loss: 1.683876668785797
Validation loss: 2.62409527545561

Epoch: 6| Step: 5
Training loss: 2.19196082728948
Validation loss: 2.5670909639026642

Epoch: 6| Step: 6
Training loss: 1.7231791215269332
Validation loss: 2.530841300659784

Epoch: 6| Step: 7
Training loss: 2.108707350574909
Validation loss: 2.4868508950382866

Epoch: 6| Step: 8
Training loss: 1.7266231198262987
Validation loss: 2.4728325156622786

Epoch: 6| Step: 9
Training loss: 2.07796529285279
Validation loss: 2.4939040269351587

Epoch: 6| Step: 10
Training loss: 1.5939056470077237
Validation loss: 2.4660807164563043

Epoch: 6| Step: 11
Training loss: 1.6155122197408345
Validation loss: 2.4932066828129003

Epoch: 6| Step: 12
Training loss: 1.8384388218572942
Validation loss: 2.5124492284438245

Epoch: 6| Step: 13
Training loss: 1.7836307877693907
Validation loss: 2.5724232010160537

Epoch: 293| Step: 0
Training loss: 1.5376527787882524
Validation loss: 2.600609576719972

Epoch: 6| Step: 1
Training loss: 2.085429040323972
Validation loss: 2.6810254104536786

Epoch: 6| Step: 2
Training loss: 2.0835542815982633
Validation loss: 2.7051806571912174

Epoch: 6| Step: 3
Training loss: 1.7804492689927414
Validation loss: 2.6748481217453475

Epoch: 6| Step: 4
Training loss: 1.547884833041484
Validation loss: 2.6456582393624917

Epoch: 6| Step: 5
Training loss: 1.3167098060413693
Validation loss: 2.625801918098384

Epoch: 6| Step: 6
Training loss: 1.6814145457922136
Validation loss: 2.611387435059517

Epoch: 6| Step: 7
Training loss: 2.1160308944379382
Validation loss: 2.6025020330843396

Epoch: 6| Step: 8
Training loss: 2.119302179181763
Validation loss: 2.5992874978381346

Epoch: 6| Step: 9
Training loss: 2.092220146032757
Validation loss: 2.612856256069656

Epoch: 6| Step: 10
Training loss: 2.327803109465396
Validation loss: 2.6134926008324495

Epoch: 6| Step: 11
Training loss: 1.8357208773466536
Validation loss: 2.6021729021459663

Epoch: 6| Step: 12
Training loss: 1.5037328843104307
Validation loss: 2.612435124180482

Epoch: 6| Step: 13
Training loss: 1.7392322467722017
Validation loss: 2.6257711792472733

Epoch: 294| Step: 0
Training loss: 1.9233307945966356
Validation loss: 2.6216509491942994

Epoch: 6| Step: 1
Training loss: 1.5418610665040087
Validation loss: 2.6444916220746033

Epoch: 6| Step: 2
Training loss: 2.1824085383351677
Validation loss: 2.649078937108539

Epoch: 6| Step: 3
Training loss: 1.5891876741543405
Validation loss: 2.633670856231211

Epoch: 6| Step: 4
Training loss: 2.1756906267945655
Validation loss: 2.6367647532373644

Epoch: 6| Step: 5
Training loss: 1.6440767579873437
Validation loss: 2.565872720046005

Epoch: 6| Step: 6
Training loss: 2.1369970164869487
Validation loss: 2.4922226525210633

Epoch: 6| Step: 7
Training loss: 1.5745256375660135
Validation loss: 2.454124847305954

Epoch: 6| Step: 8
Training loss: 1.7041207298796688
Validation loss: 2.428115063152832

Epoch: 6| Step: 9
Training loss: 1.7917650624543338
Validation loss: 2.467576801776998

Epoch: 6| Step: 10
Training loss: 1.9201745675121464
Validation loss: 2.484947345043158

Epoch: 6| Step: 11
Training loss: 2.0433134586846666
Validation loss: 2.5383373189779626

Epoch: 6| Step: 12
Training loss: 1.3937313232539001
Validation loss: 2.5879906122507434

Epoch: 6| Step: 13
Training loss: 2.2445998556113076
Validation loss: 2.6309486379681037

Epoch: 295| Step: 0
Training loss: 1.6282690617824755
Validation loss: 2.6528031001269112

Epoch: 6| Step: 1
Training loss: 1.54605018897467
Validation loss: 2.690442246350681

Epoch: 6| Step: 2
Training loss: 1.7782818341268893
Validation loss: 2.734174049130617

Epoch: 6| Step: 3
Training loss: 1.8635617091076817
Validation loss: 2.7146304391645515

Epoch: 6| Step: 4
Training loss: 1.6076636242685802
Validation loss: 2.6738303724036636

Epoch: 6| Step: 5
Training loss: 1.6525090993841345
Validation loss: 2.6385527973348273

Epoch: 6| Step: 6
Training loss: 2.2466982882092084
Validation loss: 2.6081376423755707

Epoch: 6| Step: 7
Training loss: 1.3453287121441668
Validation loss: 2.5989657524473677

Epoch: 6| Step: 8
Training loss: 2.011997122161506
Validation loss: 2.6085490063438947

Epoch: 6| Step: 9
Training loss: 2.0136600349736784
Validation loss: 2.620424184038829

Epoch: 6| Step: 10
Training loss: 1.8070248087080871
Validation loss: 2.6340827320538507

Epoch: 6| Step: 11
Training loss: 1.8180727297395334
Validation loss: 2.6141863798885767

Epoch: 6| Step: 12
Training loss: 2.2683980873763097
Validation loss: 2.5944018759890635

Epoch: 6| Step: 13
Training loss: 1.8674456046888106
Validation loss: 2.5989715347646887

Epoch: 296| Step: 0
Training loss: 2.0293215473867092
Validation loss: 2.5628361105118045

Epoch: 6| Step: 1
Training loss: 1.9650334594634549
Validation loss: 2.5677044588113964

Epoch: 6| Step: 2
Training loss: 1.4402279056230989
Validation loss: 2.57780914410288

Epoch: 6| Step: 3
Training loss: 1.763560886206975
Validation loss: 2.5659130975725364

Epoch: 6| Step: 4
Training loss: 1.9687656825818525
Validation loss: 2.564589963979881

Epoch: 6| Step: 5
Training loss: 1.595668610254404
Validation loss: 2.5756579993544704

Epoch: 6| Step: 6
Training loss: 2.0655268797315505
Validation loss: 2.5706014247933284

Epoch: 6| Step: 7
Training loss: 2.071371246822521
Validation loss: 2.5564705489665123

Epoch: 6| Step: 8
Training loss: 2.12479612831056
Validation loss: 2.534813583764558

Epoch: 6| Step: 9
Training loss: 2.193544157538055
Validation loss: 2.5529337494276065

Epoch: 6| Step: 10
Training loss: 1.0413937910612454
Validation loss: 2.568155082888389

Epoch: 6| Step: 11
Training loss: 1.1199034642441617
Validation loss: 2.600349266306498

Epoch: 6| Step: 12
Training loss: 1.6712504138246993
Validation loss: 2.6373241356403185

Epoch: 6| Step: 13
Training loss: 2.0513624548437503
Validation loss: 2.624884075958833

Epoch: 297| Step: 0
Training loss: 1.7211187512369317
Validation loss: 2.6306095979931525

Epoch: 6| Step: 1
Training loss: 2.049332984710015
Validation loss: 2.6294083151740386

Epoch: 6| Step: 2
Training loss: 1.8275225698222823
Validation loss: 2.6263675799378925

Epoch: 6| Step: 3
Training loss: 1.5193697100680243
Validation loss: 2.6151273035957727

Epoch: 6| Step: 4
Training loss: 1.6807579001031514
Validation loss: 2.587988091195001

Epoch: 6| Step: 5
Training loss: 1.3854685130731637
Validation loss: 2.583248435407395

Epoch: 6| Step: 6
Training loss: 1.476217724142847
Validation loss: 2.5983177347626745

Epoch: 6| Step: 7
Training loss: 2.1079376975304376
Validation loss: 2.573951998793004

Epoch: 6| Step: 8
Training loss: 2.0365838079668017
Validation loss: 2.5705385786626342

Epoch: 6| Step: 9
Training loss: 2.0755706232305906
Validation loss: 2.5736558707632358

Epoch: 6| Step: 10
Training loss: 1.9058635507558592
Validation loss: 2.5862303780095686

Epoch: 6| Step: 11
Training loss: 1.9978395356321508
Validation loss: 2.6016904797051863

Epoch: 6| Step: 12
Training loss: 1.1275545891955323
Validation loss: 2.574618435657249

Epoch: 6| Step: 13
Training loss: 2.0439148675990473
Validation loss: 2.5396079069082633

Epoch: 298| Step: 0
Training loss: 1.6258233258779977
Validation loss: 2.559738492004176

Epoch: 6| Step: 1
Training loss: 1.6483900596698462
Validation loss: 2.558001995752863

Epoch: 6| Step: 2
Training loss: 1.800139935670109
Validation loss: 2.5679806251640276

Epoch: 6| Step: 3
Training loss: 1.4519915518449231
Validation loss: 2.581388488358173

Epoch: 6| Step: 4
Training loss: 2.419980495626493
Validation loss: 2.6241468067495113

Epoch: 6| Step: 5
Training loss: 1.9856423963841927
Validation loss: 2.6534369265285696

Epoch: 6| Step: 6
Training loss: 1.4717432728518558
Validation loss: 2.6325842446001992

Epoch: 6| Step: 7
Training loss: 1.7611889772152094
Validation loss: 2.665953376058618

Epoch: 6| Step: 8
Training loss: 1.5104995266340033
Validation loss: 2.663191770003277

Epoch: 6| Step: 9
Training loss: 1.5101299759206803
Validation loss: 2.7039558461063513

Epoch: 6| Step: 10
Training loss: 1.7518528938327695
Validation loss: 2.6819128877541685

Epoch: 6| Step: 11
Training loss: 1.667992978065219
Validation loss: 2.62860985357827

Epoch: 6| Step: 12
Training loss: 2.031116657281969
Validation loss: 2.578096709681939

Epoch: 6| Step: 13
Training loss: 2.2667669115151954
Validation loss: 2.542843125954086

Epoch: 299| Step: 0
Training loss: 1.0678446364820935
Validation loss: 2.5199469761772493

Epoch: 6| Step: 1
Training loss: 2.1556012933123743
Validation loss: 2.481902164355782

Epoch: 6| Step: 2
Training loss: 1.5225302317707468
Validation loss: 2.4990323285866256

Epoch: 6| Step: 3
Training loss: 2.071946215664265
Validation loss: 2.4812368637517923

Epoch: 6| Step: 4
Training loss: 2.061763053785185
Validation loss: 2.5645627169248026

Epoch: 6| Step: 5
Training loss: 1.6526500517202447
Validation loss: 2.5904391591474543

Epoch: 6| Step: 6
Training loss: 1.8799631552433764
Validation loss: 2.660597187713488

Epoch: 6| Step: 7
Training loss: 1.5298810795462865
Validation loss: 2.673790871899766

Epoch: 6| Step: 8
Training loss: 1.8848425972988851
Validation loss: 2.674213730348878

Epoch: 6| Step: 9
Training loss: 1.938304918506772
Validation loss: 2.6290810792060055

Epoch: 6| Step: 10
Training loss: 1.7845335694520008
Validation loss: 2.6182939571147386

Epoch: 6| Step: 11
Training loss: 2.0002069366209687
Validation loss: 2.5832132969204826

Epoch: 6| Step: 12
Training loss: 1.5364414882275297
Validation loss: 2.5687975879549936

Epoch: 6| Step: 13
Training loss: 1.5518958556686175
Validation loss: 2.5291074118597954

Epoch: 300| Step: 0
Training loss: 1.7212182095652384
Validation loss: 2.552809260484703

Epoch: 6| Step: 1
Training loss: 1.9274193410658453
Validation loss: 2.506852617027781

Epoch: 6| Step: 2
Training loss: 1.9040056367838791
Validation loss: 2.543628125570375

Epoch: 6| Step: 3
Training loss: 2.091732362523519
Validation loss: 2.560398231309882

Epoch: 6| Step: 4
Training loss: 1.5048971503464041
Validation loss: 2.6157941473648547

Epoch: 6| Step: 5
Training loss: 2.048328145917879
Validation loss: 2.619259994992356

Epoch: 6| Step: 6
Training loss: 1.8465620676202505
Validation loss: 2.6354867751649413

Epoch: 6| Step: 7
Training loss: 1.4673412140913806
Validation loss: 2.6391286904732314

Epoch: 6| Step: 8
Training loss: 1.156732407019962
Validation loss: 2.6722720108545808

Epoch: 6| Step: 9
Training loss: 1.8360920293178422
Validation loss: 2.6692371176394394

Epoch: 6| Step: 10
Training loss: 2.0590212991436365
Validation loss: 2.6316118350453936

Epoch: 6| Step: 11
Training loss: 1.5868132479996189
Validation loss: 2.6077775600223005

Epoch: 6| Step: 12
Training loss: 1.821077898071894
Validation loss: 2.5775412606222385

Epoch: 6| Step: 13
Training loss: 1.7111456060785786
Validation loss: 2.5362163535327746

Epoch: 301| Step: 0
Training loss: 1.813432913785424
Validation loss: 2.5253263095950524

Epoch: 6| Step: 1
Training loss: 1.278112944007479
Validation loss: 2.5233071718753397

Epoch: 6| Step: 2
Training loss: 1.008235517333969
Validation loss: 2.5489289525909875

Epoch: 6| Step: 3
Training loss: 1.7693866055888496
Validation loss: 2.571881402866121

Epoch: 6| Step: 4
Training loss: 1.7383241798157443
Validation loss: 2.595021236437976

Epoch: 6| Step: 5
Training loss: 2.385498134326865
Validation loss: 2.6007483123312247

Epoch: 6| Step: 6
Training loss: 1.86775626613754
Validation loss: 2.624999257764892

Epoch: 6| Step: 7
Training loss: 2.2251723919209248
Validation loss: 2.649817601275041

Epoch: 6| Step: 8
Training loss: 1.6362679891857819
Validation loss: 2.6639447362863953

Epoch: 6| Step: 9
Training loss: 1.7826464349164042
Validation loss: 2.6291928994034137

Epoch: 6| Step: 10
Training loss: 1.4638072504824333
Validation loss: 2.601081722668836

Epoch: 6| Step: 11
Training loss: 1.812583526791375
Validation loss: 2.600197910099787

Epoch: 6| Step: 12
Training loss: 1.7033359501937404
Validation loss: 2.5975932600076055

Epoch: 6| Step: 13
Training loss: 1.7254138422469005
Validation loss: 2.5781251978819753

Epoch: 302| Step: 0
Training loss: 2.076841488618632
Validation loss: 2.5693637745070634

Epoch: 6| Step: 1
Training loss: 1.4890056459154597
Validation loss: 2.585695931621953

Epoch: 6| Step: 2
Training loss: 1.6233482769559644
Validation loss: 2.61307550367739

Epoch: 6| Step: 3
Training loss: 1.5756761038276819
Validation loss: 2.614356254937249

Epoch: 6| Step: 4
Training loss: 1.6253154155086749
Validation loss: 2.6260973277023276

Epoch: 6| Step: 5
Training loss: 1.9452433746189763
Validation loss: 2.6099651726156994

Epoch: 6| Step: 6
Training loss: 1.4309065160918757
Validation loss: 2.583457955349144

Epoch: 6| Step: 7
Training loss: 2.0661108602671985
Validation loss: 2.5601323151971576

Epoch: 6| Step: 8
Training loss: 1.4543022391327678
Validation loss: 2.5767690608617215

Epoch: 6| Step: 9
Training loss: 1.6630003498877584
Validation loss: 2.562146166151328

Epoch: 6| Step: 10
Training loss: 2.001980754382511
Validation loss: 2.5590168820754915

Epoch: 6| Step: 11
Training loss: 1.67974825017321
Validation loss: 2.592561571358342

Epoch: 6| Step: 12
Training loss: 1.9552634777272306
Validation loss: 2.6181212467465382

Epoch: 6| Step: 13
Training loss: 1.3487867837862495
Validation loss: 2.619645607941346

Epoch: 303| Step: 0
Training loss: 1.5552114246062592
Validation loss: 2.6372649646352766

Epoch: 6| Step: 1
Training loss: 1.7400406409592684
Validation loss: 2.616800989915292

Epoch: 6| Step: 2
Training loss: 1.9040244196119218
Validation loss: 2.644921517184652

Epoch: 6| Step: 3
Training loss: 1.794131830494142
Validation loss: 2.6665192519737255

Epoch: 6| Step: 4
Training loss: 1.4266211139382365
Validation loss: 2.6599782250782433

Epoch: 6| Step: 5
Training loss: 1.968478895625087
Validation loss: 2.653826374796224

Epoch: 6| Step: 6
Training loss: 2.022438185493402
Validation loss: 2.637047097237866

Epoch: 6| Step: 7
Training loss: 1.6021085971118492
Validation loss: 2.629622118348426

Epoch: 6| Step: 8
Training loss: 1.652113300964075
Validation loss: 2.589883814188626

Epoch: 6| Step: 9
Training loss: 1.4887935527641416
Validation loss: 2.5724369767857653

Epoch: 6| Step: 10
Training loss: 1.8528217910325189
Validation loss: 2.580959708902103

Epoch: 6| Step: 11
Training loss: 1.7595705862063071
Validation loss: 2.5757414438407027

Epoch: 6| Step: 12
Training loss: 1.6581888905915103
Validation loss: 2.58055634217568

Epoch: 6| Step: 13
Training loss: 1.5288250464471214
Validation loss: 2.5855596544084505

Epoch: 304| Step: 0
Training loss: 1.598614319150821
Validation loss: 2.5714345832198733

Epoch: 6| Step: 1
Training loss: 2.1608860100757883
Validation loss: 2.581995410846387

Epoch: 6| Step: 2
Training loss: 1.8606647538207521
Validation loss: 2.557477843314402

Epoch: 6| Step: 3
Training loss: 1.6609199472757694
Validation loss: 2.585648495283377

Epoch: 6| Step: 4
Training loss: 1.4538828196577256
Validation loss: 2.576475017298242

Epoch: 6| Step: 5
Training loss: 1.1057928034971345
Validation loss: 2.5744732651834323

Epoch: 6| Step: 6
Training loss: 1.5063467857321229
Validation loss: 2.6015189399781327

Epoch: 6| Step: 7
Training loss: 1.6963811925137378
Validation loss: 2.659984720964797

Epoch: 6| Step: 8
Training loss: 2.0431851040881908
Validation loss: 2.6616821105082824

Epoch: 6| Step: 9
Training loss: 1.9852011455216678
Validation loss: 2.6655697245601693

Epoch: 6| Step: 10
Training loss: 1.8188926824334526
Validation loss: 2.6690456452462867

Epoch: 6| Step: 11
Training loss: 1.2264724018025936
Validation loss: 2.607236006480075

Epoch: 6| Step: 12
Training loss: 1.6700078217100522
Validation loss: 2.5634148088039934

Epoch: 6| Step: 13
Training loss: 2.284367456175824
Validation loss: 2.5821417122049923

Epoch: 305| Step: 0
Training loss: 1.7663300043494525
Validation loss: 2.5798765515193636

Epoch: 6| Step: 1
Training loss: 2.0475381257509735
Validation loss: 2.5632027093466307

Epoch: 6| Step: 2
Training loss: 1.7336325216062092
Validation loss: 2.5961170873069217

Epoch: 6| Step: 3
Training loss: 1.496392521519903
Validation loss: 2.60872568726173

Epoch: 6| Step: 4
Training loss: 1.5381288746487
Validation loss: 2.631824812413833

Epoch: 6| Step: 5
Training loss: 1.5319290990782377
Validation loss: 2.6337638463605697

Epoch: 6| Step: 6
Training loss: 1.8283622131338668
Validation loss: 2.6445742857313173

Epoch: 6| Step: 7
Training loss: 2.070699288566704
Validation loss: 2.6533855920986853

Epoch: 6| Step: 8
Training loss: 1.8420384108093328
Validation loss: 2.6564903010637004

Epoch: 6| Step: 9
Training loss: 1.576798816583887
Validation loss: 2.6508253999601625

Epoch: 6| Step: 10
Training loss: 1.2503458021591913
Validation loss: 2.61014063110721

Epoch: 6| Step: 11
Training loss: 1.244343116846122
Validation loss: 2.6108628711882305

Epoch: 6| Step: 12
Training loss: 2.0265766081543184
Validation loss: 2.5702913449685996

Epoch: 6| Step: 13
Training loss: 2.174015335288615
Validation loss: 2.588076162252121

Epoch: 306| Step: 0
Training loss: 1.64109969764815
Validation loss: 2.5886406268744566

Epoch: 6| Step: 1
Training loss: 1.7752109348525924
Validation loss: 2.5767574607397994

Epoch: 6| Step: 2
Training loss: 1.2514304559323928
Validation loss: 2.61647601802441

Epoch: 6| Step: 3
Training loss: 2.0856066952257346
Validation loss: 2.6214408076845084

Epoch: 6| Step: 4
Training loss: 1.750711228393066
Validation loss: 2.617796142019971

Epoch: 6| Step: 5
Training loss: 1.3819932827820782
Validation loss: 2.618698523880869

Epoch: 6| Step: 6
Training loss: 1.889769683812084
Validation loss: 2.610711610938233

Epoch: 6| Step: 7
Training loss: 1.9853115124657215
Validation loss: 2.590771699434035

Epoch: 6| Step: 8
Training loss: 1.1742109287024323
Validation loss: 2.6105817068150707

Epoch: 6| Step: 9
Training loss: 1.8717832310364515
Validation loss: 2.6175066950881725

Epoch: 6| Step: 10
Training loss: 1.647291752529114
Validation loss: 2.6045942619145466

Epoch: 6| Step: 11
Training loss: 1.6748555078386467
Validation loss: 2.6117381211826918

Epoch: 6| Step: 12
Training loss: 2.0409548809740685
Validation loss: 2.643934335951049

Epoch: 6| Step: 13
Training loss: 1.202750209544292
Validation loss: 2.678817247517052

Epoch: 307| Step: 0
Training loss: 1.5973477613713478
Validation loss: 2.6189337473260617

Epoch: 6| Step: 1
Training loss: 2.0525390067442184
Validation loss: 2.6027528340065134

Epoch: 6| Step: 2
Training loss: 1.4240595206990656
Validation loss: 2.602916044785008

Epoch: 6| Step: 3
Training loss: 1.483225487778313
Validation loss: 2.5716045573319364

Epoch: 6| Step: 4
Training loss: 1.5473549608781507
Validation loss: 2.5798504809952956

Epoch: 6| Step: 5
Training loss: 1.9495750208682425
Validation loss: 2.5584636515819636

Epoch: 6| Step: 6
Training loss: 1.5775581323761103
Validation loss: 2.5745005826084695

Epoch: 6| Step: 7
Training loss: 1.7735977436552033
Validation loss: 2.550353172998189

Epoch: 6| Step: 8
Training loss: 1.7981284372285589
Validation loss: 2.5793499226473955

Epoch: 6| Step: 9
Training loss: 1.6380502023980132
Validation loss: 2.591146756759102

Epoch: 6| Step: 10
Training loss: 1.6479871957429657
Validation loss: 2.6371557789762115

Epoch: 6| Step: 11
Training loss: 1.6215609325402094
Validation loss: 2.595143364602135

Epoch: 6| Step: 12
Training loss: 1.9610669218721621
Validation loss: 2.6210352787185833

Epoch: 6| Step: 13
Training loss: 1.4042537083046256
Validation loss: 2.6400058188114817

Epoch: 308| Step: 0
Training loss: 1.659989005247726
Validation loss: 2.6162567437820248

Epoch: 6| Step: 1
Training loss: 1.3075086051409759
Validation loss: 2.5920690680774117

Epoch: 6| Step: 2
Training loss: 2.034146752276281
Validation loss: 2.5929489312108482

Epoch: 6| Step: 3
Training loss: 1.164011755739737
Validation loss: 2.559984459594311

Epoch: 6| Step: 4
Training loss: 1.7720872217071852
Validation loss: 2.5167655542649774

Epoch: 6| Step: 5
Training loss: 1.8162789248889075
Validation loss: 2.5292196249574643

Epoch: 6| Step: 6
Training loss: 1.5302455488145514
Validation loss: 2.5764628103808027

Epoch: 6| Step: 7
Training loss: 2.0107469303914436
Validation loss: 2.6139725057928214

Epoch: 6| Step: 8
Training loss: 1.4973277289341445
Validation loss: 2.6217271722776885

Epoch: 6| Step: 9
Training loss: 1.8363001688419873
Validation loss: 2.6661181276667145

Epoch: 6| Step: 10
Training loss: 1.5004497489611957
Validation loss: 2.6810599908428383

Epoch: 6| Step: 11
Training loss: 1.8678460017405776
Validation loss: 2.684122010202764

Epoch: 6| Step: 12
Training loss: 1.776226119888284
Validation loss: 2.6955569605383545

Epoch: 6| Step: 13
Training loss: 1.2806561652320083
Validation loss: 2.7006101692089928

Epoch: 309| Step: 0
Training loss: 1.1177898997004923
Validation loss: 2.6888603870153114

Epoch: 6| Step: 1
Training loss: 1.8869927564723523
Validation loss: 2.6314864211447646

Epoch: 6| Step: 2
Training loss: 1.880564570471854
Validation loss: 2.6188420925168288

Epoch: 6| Step: 3
Training loss: 1.2334542039117558
Validation loss: 2.568543520440983

Epoch: 6| Step: 4
Training loss: 1.3906209709880626
Validation loss: 2.581745086857775

Epoch: 6| Step: 5
Training loss: 2.240096655872002
Validation loss: 2.5626138701351064

Epoch: 6| Step: 6
Training loss: 1.9333203054953794
Validation loss: 2.5700021728427274

Epoch: 6| Step: 7
Training loss: 1.219100706063555
Validation loss: 2.5835393399424404

Epoch: 6| Step: 8
Training loss: 1.863655292706666
Validation loss: 2.5579715556201137

Epoch: 6| Step: 9
Training loss: 1.9535175386788268
Validation loss: 2.5625826404370633

Epoch: 6| Step: 10
Training loss: 1.38018635666343
Validation loss: 2.5616216757484107

Epoch: 6| Step: 11
Training loss: 1.4645921821742938
Validation loss: 2.575775328674739

Epoch: 6| Step: 12
Training loss: 1.5650592444177944
Validation loss: 2.5416887602777996

Epoch: 6| Step: 13
Training loss: 2.0004067007445734
Validation loss: 2.547662224906782

Epoch: 310| Step: 0
Training loss: 1.4639305421684805
Validation loss: 2.536116575222855

Epoch: 6| Step: 1
Training loss: 1.3303159705545338
Validation loss: 2.497766713428312

Epoch: 6| Step: 2
Training loss: 1.8368271640339047
Validation loss: 2.5170570312276066

Epoch: 6| Step: 3
Training loss: 1.5857005576542256
Validation loss: 2.500729764028732

Epoch: 6| Step: 4
Training loss: 2.4937448448950086
Validation loss: 2.5680577204900485

Epoch: 6| Step: 5
Training loss: 1.5740656245800615
Validation loss: 2.554590055838759

Epoch: 6| Step: 6
Training loss: 1.893291390160379
Validation loss: 2.592639618702814

Epoch: 6| Step: 7
Training loss: 1.3185393938147552
Validation loss: 2.653632556751207

Epoch: 6| Step: 8
Training loss: 1.4213462936539303
Validation loss: 2.6736075241248765

Epoch: 6| Step: 9
Training loss: 1.6657653119675784
Validation loss: 2.7043586641055803

Epoch: 6| Step: 10
Training loss: 1.1819759176934714
Validation loss: 2.6888845749534016

Epoch: 6| Step: 11
Training loss: 2.1144935952173247
Validation loss: 2.650663071323156

Epoch: 6| Step: 12
Training loss: 1.4572365132988976
Validation loss: 2.6229621279103323

Epoch: 6| Step: 13
Training loss: 1.4011233659296225
Validation loss: 2.578057227016106

Epoch: 311| Step: 0
Training loss: 1.7021008133039306
Validation loss: 2.572380689300964

Epoch: 6| Step: 1
Training loss: 1.6394786644583055
Validation loss: 2.5536096873303213

Epoch: 6| Step: 2
Training loss: 1.7013008077575706
Validation loss: 2.5429071545861572

Epoch: 6| Step: 3
Training loss: 1.5912174972486994
Validation loss: 2.529299523478927

Epoch: 6| Step: 4
Training loss: 1.7040097799423453
Validation loss: 2.571919214542459

Epoch: 6| Step: 5
Training loss: 1.5914135430402507
Validation loss: 2.593448642659688

Epoch: 6| Step: 6
Training loss: 1.6027827382722575
Validation loss: 2.5983843567345417

Epoch: 6| Step: 7
Training loss: 0.895621755291957
Validation loss: 2.616298331891191

Epoch: 6| Step: 8
Training loss: 1.6513224301851583
Validation loss: 2.634533233867102

Epoch: 6| Step: 9
Training loss: 1.495755548323106
Validation loss: 2.6419059305272095

Epoch: 6| Step: 10
Training loss: 1.9202992251801005
Validation loss: 2.668865872369769

Epoch: 6| Step: 11
Training loss: 1.8086218285904214
Validation loss: 2.7048748061522203

Epoch: 6| Step: 12
Training loss: 2.097224754124251
Validation loss: 2.696441209560342

Epoch: 6| Step: 13
Training loss: 1.429100958571307
Validation loss: 2.6839165574684944

Epoch: 312| Step: 0
Training loss: 1.4853075009644516
Validation loss: 2.6519885552898264

Epoch: 6| Step: 1
Training loss: 1.550732205862152
Validation loss: 2.6529090712988728

Epoch: 6| Step: 2
Training loss: 1.721167372948344
Validation loss: 2.640375344817281

Epoch: 6| Step: 3
Training loss: 1.8903477993616067
Validation loss: 2.637993340191622

Epoch: 6| Step: 4
Training loss: 1.6986141839376072
Validation loss: 2.6208986411123973

Epoch: 6| Step: 5
Training loss: 1.6559029701435262
Validation loss: 2.6009927564461295

Epoch: 6| Step: 6
Training loss: 1.6143991508848379
Validation loss: 2.580029073040901

Epoch: 6| Step: 7
Training loss: 1.8216318743641546
Validation loss: 2.5789350165037876

Epoch: 6| Step: 8
Training loss: 1.7496803536723087
Validation loss: 2.5962579479999675

Epoch: 6| Step: 9
Training loss: 1.2709842759006864
Validation loss: 2.5784808398376473

Epoch: 6| Step: 10
Training loss: 1.1888480816479867
Validation loss: 2.593243308896937

Epoch: 6| Step: 11
Training loss: 1.6585288295177973
Validation loss: 2.614866078578249

Epoch: 6| Step: 12
Training loss: 1.8698518649499187
Validation loss: 2.6352954197666723

Epoch: 6| Step: 13
Training loss: 1.327461570643282
Validation loss: 2.614157977719551

Epoch: 313| Step: 0
Training loss: 1.6315328886205116
Validation loss: 2.6792948277968307

Epoch: 6| Step: 1
Training loss: 1.2049386362620225
Validation loss: 2.704963911669245

Epoch: 6| Step: 2
Training loss: 1.5363669244331932
Validation loss: 2.678355962170677

Epoch: 6| Step: 3
Training loss: 1.5532367013717778
Validation loss: 2.693538081333811

Epoch: 6| Step: 4
Training loss: 1.3990854648173425
Validation loss: 2.690051665335436

Epoch: 6| Step: 5
Training loss: 1.5829110418977719
Validation loss: 2.677608576521467

Epoch: 6| Step: 6
Training loss: 1.205146379562705
Validation loss: 2.6332368968435973

Epoch: 6| Step: 7
Training loss: 1.9732165456806994
Validation loss: 2.625614170587847

Epoch: 6| Step: 8
Training loss: 1.4039275594971679
Validation loss: 2.6039045107566943

Epoch: 6| Step: 9
Training loss: 1.2631826500286385
Validation loss: 2.594279924391228

Epoch: 6| Step: 10
Training loss: 1.708044105174737
Validation loss: 2.6134023306169833

Epoch: 6| Step: 11
Training loss: 2.0359260143035094
Validation loss: 2.593456377216645

Epoch: 6| Step: 12
Training loss: 2.087077540062573
Validation loss: 2.6057535425336873

Epoch: 6| Step: 13
Training loss: 1.7635191115146005
Validation loss: 2.5931376161651682

Epoch: 314| Step: 0
Training loss: 1.9675199511048433
Validation loss: 2.6483505253617867

Epoch: 6| Step: 1
Training loss: 1.058849289797341
Validation loss: 2.685575343125627

Epoch: 6| Step: 2
Training loss: 1.5036389398191083
Validation loss: 2.693059354318109

Epoch: 6| Step: 3
Training loss: 1.6567081321628625
Validation loss: 2.6384734409792556

Epoch: 6| Step: 4
Training loss: 1.749452641581217
Validation loss: 2.653878323768627

Epoch: 6| Step: 5
Training loss: 1.5133888816861658
Validation loss: 2.630258027814155

Epoch: 6| Step: 6
Training loss: 1.6589542839783007
Validation loss: 2.5848377748136384

Epoch: 6| Step: 7
Training loss: 1.5305283071896731
Validation loss: 2.568905896795843

Epoch: 6| Step: 8
Training loss: 1.6481552243924165
Validation loss: 2.57695327637394

Epoch: 6| Step: 9
Training loss: 1.4104359103777173
Validation loss: 2.5847141658785557

Epoch: 6| Step: 10
Training loss: 1.9538788218138405
Validation loss: 2.6264342156352116

Epoch: 6| Step: 11
Training loss: 1.6838128816888716
Validation loss: 2.660496077687504

Epoch: 6| Step: 12
Training loss: 1.5374865523579841
Validation loss: 2.6831013387054288

Epoch: 6| Step: 13
Training loss: 1.7552279311839603
Validation loss: 2.654454843985757

Epoch: 315| Step: 0
Training loss: 1.8841714347341485
Validation loss: 2.658725151377367

Epoch: 6| Step: 1
Training loss: 1.401740196641414
Validation loss: 2.6718791114167657

Epoch: 6| Step: 2
Training loss: 1.3069870835872168
Validation loss: 2.6555318132938903

Epoch: 6| Step: 3
Training loss: 1.6029874091935978
Validation loss: 2.613360284412473

Epoch: 6| Step: 4
Training loss: 1.2812707480634762
Validation loss: 2.600833146979833

Epoch: 6| Step: 5
Training loss: 1.2877873442649885
Validation loss: 2.6061537668116097

Epoch: 6| Step: 6
Training loss: 1.749300340024893
Validation loss: 2.61252867489666

Epoch: 6| Step: 7
Training loss: 1.1352877704122617
Validation loss: 2.6141193623565555

Epoch: 6| Step: 8
Training loss: 1.5010672587168272
Validation loss: 2.610548206006587

Epoch: 6| Step: 9
Training loss: 2.0309820145111632
Validation loss: 2.5991130367452535

Epoch: 6| Step: 10
Training loss: 1.0735882382562998
Validation loss: 2.60984222628622

Epoch: 6| Step: 11
Training loss: 2.0463903887203134
Validation loss: 2.5915152960926715

Epoch: 6| Step: 12
Training loss: 1.7854325562715565
Validation loss: 2.578532169192395

Epoch: 6| Step: 13
Training loss: 2.087127346194913
Validation loss: 2.585066860412765

Epoch: 316| Step: 0
Training loss: 1.2761835084308435
Validation loss: 2.6143133983952365

Epoch: 6| Step: 1
Training loss: 2.2080219577098323
Validation loss: 2.635946836155411

Epoch: 6| Step: 2
Training loss: 1.279545883521734
Validation loss: 2.6604573399241374

Epoch: 6| Step: 3
Training loss: 1.830764625462767
Validation loss: 2.6494579420182975

Epoch: 6| Step: 4
Training loss: 1.7280076826949111
Validation loss: 2.6993020284663456

Epoch: 6| Step: 5
Training loss: 1.4019782990124328
Validation loss: 2.67206066469752

Epoch: 6| Step: 6
Training loss: 1.5231221190477378
Validation loss: 2.618486529990938

Epoch: 6| Step: 7
Training loss: 1.336942328299852
Validation loss: 2.6086474902679297

Epoch: 6| Step: 8
Training loss: 1.3602589769479085
Validation loss: 2.5965684111645517

Epoch: 6| Step: 9
Training loss: 1.500890785203536
Validation loss: 2.6207710291052666

Epoch: 6| Step: 10
Training loss: 1.6424707112248442
Validation loss: 2.580343949809134

Epoch: 6| Step: 11
Training loss: 1.7806715444290686
Validation loss: 2.6114696446206143

Epoch: 6| Step: 12
Training loss: 1.485196177564449
Validation loss: 2.572213200837323

Epoch: 6| Step: 13
Training loss: 1.7323445299638307
Validation loss: 2.6045751481812114

Epoch: 317| Step: 0
Training loss: 1.5615736695035765
Validation loss: 2.632167024878364

Epoch: 6| Step: 1
Training loss: 1.648530062567104
Validation loss: 2.6787108068636742

Epoch: 6| Step: 2
Training loss: 1.3829612867408037
Validation loss: 2.6764438657526104

Epoch: 6| Step: 3
Training loss: 1.4172028293642747
Validation loss: 2.646709949657847

Epoch: 6| Step: 4
Training loss: 1.4342538420925108
Validation loss: 2.7168668085945917

Epoch: 6| Step: 5
Training loss: 1.6063996746224383
Validation loss: 2.655475575466673

Epoch: 6| Step: 6
Training loss: 1.5942237000433876
Validation loss: 2.6053928650091103

Epoch: 6| Step: 7
Training loss: 1.7268873228502555
Validation loss: 2.5737021465624332

Epoch: 6| Step: 8
Training loss: 1.1355560753774065
Validation loss: 2.564726051973802

Epoch: 6| Step: 9
Training loss: 1.2658252322197445
Validation loss: 2.553619788835333

Epoch: 6| Step: 10
Training loss: 2.1192175785278873
Validation loss: 2.5587863409080667

Epoch: 6| Step: 11
Training loss: 1.812607794877631
Validation loss: 2.5527841161265465

Epoch: 6| Step: 12
Training loss: 1.6720894649243316
Validation loss: 2.577623046854655

Epoch: 6| Step: 13
Training loss: 1.607844541654881
Validation loss: 2.579316864008525

Epoch: 318| Step: 0
Training loss: 1.7941863801862121
Validation loss: 2.6355994519178916

Epoch: 6| Step: 1
Training loss: 1.5625773601454773
Validation loss: 2.662900385469993

Epoch: 6| Step: 2
Training loss: 1.5079149596826624
Validation loss: 2.7109493340348645

Epoch: 6| Step: 3
Training loss: 1.6739514015052648
Validation loss: 2.697817699691693

Epoch: 6| Step: 4
Training loss: 1.4989439107569085
Validation loss: 2.667855888449884

Epoch: 6| Step: 5
Training loss: 2.0801262648478724
Validation loss: 2.6879264395916933

Epoch: 6| Step: 6
Training loss: 1.889361503166728
Validation loss: 2.653590099774253

Epoch: 6| Step: 7
Training loss: 1.4440875661986317
Validation loss: 2.625125269676842

Epoch: 6| Step: 8
Training loss: 1.177844799931825
Validation loss: 2.619272676822859

Epoch: 6| Step: 9
Training loss: 1.182023823293083
Validation loss: 2.6170601419688087

Epoch: 6| Step: 10
Training loss: 1.5865846262619885
Validation loss: 2.5861570927217765

Epoch: 6| Step: 11
Training loss: 1.6066745211909186
Validation loss: 2.5816151730186543

Epoch: 6| Step: 12
Training loss: 1.4967195880145634
Validation loss: 2.5814054687482293

Epoch: 6| Step: 13
Training loss: 1.131352081751163
Validation loss: 2.5722364808854015

Epoch: 319| Step: 0
Training loss: 1.4858250010811807
Validation loss: 2.5651353979804314

Epoch: 6| Step: 1
Training loss: 1.8215409091959784
Validation loss: 2.598704384091086

Epoch: 6| Step: 2
Training loss: 0.9804764705521165
Validation loss: 2.5980859011784196

Epoch: 6| Step: 3
Training loss: 1.671129149444996
Validation loss: 2.6076656807507708

Epoch: 6| Step: 4
Training loss: 1.8112437399893573
Validation loss: 2.612636377765249

Epoch: 6| Step: 5
Training loss: 1.7443236525169934
Validation loss: 2.6286122049864864

Epoch: 6| Step: 6
Training loss: 1.2230053485556902
Validation loss: 2.6289200925563914

Epoch: 6| Step: 7
Training loss: 1.5864384804191245
Validation loss: 2.63675331448559

Epoch: 6| Step: 8
Training loss: 1.4788464033831217
Validation loss: 2.647788397032432

Epoch: 6| Step: 9
Training loss: 1.448184896456157
Validation loss: 2.6398494887710764

Epoch: 6| Step: 10
Training loss: 1.787740693859897
Validation loss: 2.656391843112699

Epoch: 6| Step: 11
Training loss: 1.4144241966359226
Validation loss: 2.6907609013785763

Epoch: 6| Step: 12
Training loss: 1.7626893611395378
Validation loss: 2.6600681608554257

Epoch: 6| Step: 13
Training loss: 1.2985829975305871
Validation loss: 2.640223099298664

Epoch: 320| Step: 0
Training loss: 1.6800691392840528
Validation loss: 2.6604062262391657

Epoch: 6| Step: 1
Training loss: 1.629903145235293
Validation loss: 2.6462456153705696

Epoch: 6| Step: 2
Training loss: 1.110840487637176
Validation loss: 2.6052959810598177

Epoch: 6| Step: 3
Training loss: 1.9528454389768575
Validation loss: 2.639195911233228

Epoch: 6| Step: 4
Training loss: 1.6327048818358614
Validation loss: 2.6349475298255

Epoch: 6| Step: 5
Training loss: 1.3941168503298629
Validation loss: 2.6139193547543886

Epoch: 6| Step: 6
Training loss: 1.425543862006881
Validation loss: 2.6014689560139517

Epoch: 6| Step: 7
Training loss: 1.3351988060755617
Validation loss: 2.59320574734957

Epoch: 6| Step: 8
Training loss: 1.5999184706896799
Validation loss: 2.598218263333721

Epoch: 6| Step: 9
Training loss: 1.4976021356412543
Validation loss: 2.5944419616855745

Epoch: 6| Step: 10
Training loss: 1.815480970753102
Validation loss: 2.626578091515236

Epoch: 6| Step: 11
Training loss: 1.1302817653351187
Validation loss: 2.5907191915879717

Epoch: 6| Step: 12
Training loss: 1.7031888337378038
Validation loss: 2.6115131093449393

Epoch: 6| Step: 13
Training loss: 1.875958642670464
Validation loss: 2.6557714389489004

Epoch: 321| Step: 0
Training loss: 1.3615117434955863
Validation loss: 2.645151164860608

Epoch: 6| Step: 1
Training loss: 1.7386611351927623
Validation loss: 2.6413227685321568

Epoch: 6| Step: 2
Training loss: 1.5007638575803597
Validation loss: 2.6619910751361058

Epoch: 6| Step: 3
Training loss: 1.5667534726355334
Validation loss: 2.687089137431471

Epoch: 6| Step: 4
Training loss: 1.0686268027166907
Validation loss: 2.6458975645496197

Epoch: 6| Step: 5
Training loss: 1.7095971976020277
Validation loss: 2.668740976699776

Epoch: 6| Step: 6
Training loss: 1.7688354741124908
Validation loss: 2.6514813020162573

Epoch: 6| Step: 7
Training loss: 1.376390577615283
Validation loss: 2.6428394007018965

Epoch: 6| Step: 8
Training loss: 1.7093436424824275
Validation loss: 2.623602933372272

Epoch: 6| Step: 9
Training loss: 1.312285224053717
Validation loss: 2.5968761500507855

Epoch: 6| Step: 10
Training loss: 1.778069316615621
Validation loss: 2.623212654105675

Epoch: 6| Step: 11
Training loss: 1.5497685351899473
Validation loss: 2.5729738604176378

Epoch: 6| Step: 12
Training loss: 1.6278109080936105
Validation loss: 2.603865080731227

Epoch: 6| Step: 13
Training loss: 1.2139020011003572
Validation loss: 2.6224936157600562

Epoch: 322| Step: 0
Training loss: 1.444617604407643
Validation loss: 2.6192321969332886

Epoch: 6| Step: 1
Training loss: 1.1704362811442104
Validation loss: 2.642372301290079

Epoch: 6| Step: 2
Training loss: 1.496876643743389
Validation loss: 2.641254650699076

Epoch: 6| Step: 3
Training loss: 1.3307314261201413
Validation loss: 2.68122273471496

Epoch: 6| Step: 4
Training loss: 1.9360389738297796
Validation loss: 2.6567585805096523

Epoch: 6| Step: 5
Training loss: 1.9592699354315282
Validation loss: 2.6679984828408227

Epoch: 6| Step: 6
Training loss: 1.6012723334226793
Validation loss: 2.6510374633000167

Epoch: 6| Step: 7
Training loss: 1.586939828516786
Validation loss: 2.6560006262872022

Epoch: 6| Step: 8
Training loss: 1.269348272195296
Validation loss: 2.603772365785594

Epoch: 6| Step: 9
Training loss: 1.3416242863297685
Validation loss: 2.6149052672298003

Epoch: 6| Step: 10
Training loss: 1.7339818010442147
Validation loss: 2.6446453260185896

Epoch: 6| Step: 11
Training loss: 1.6807091732942117
Validation loss: 2.6165150708669294

Epoch: 6| Step: 12
Training loss: 1.2166438366215517
Validation loss: 2.625489124408718

Epoch: 6| Step: 13
Training loss: 1.3751013458356331
Validation loss: 2.6122683372571425

Epoch: 323| Step: 0
Training loss: 1.4577773896432633
Validation loss: 2.611952723461469

Epoch: 6| Step: 1
Training loss: 1.3867714885300466
Validation loss: 2.6378482753703993

Epoch: 6| Step: 2
Training loss: 2.03186213733048
Validation loss: 2.624566476497254

Epoch: 6| Step: 3
Training loss: 1.7981312879678506
Validation loss: 2.6151481194575967

Epoch: 6| Step: 4
Training loss: 1.0368556630065795
Validation loss: 2.637456700079857

Epoch: 6| Step: 5
Training loss: 1.3282393911129367
Validation loss: 2.6487206574386035

Epoch: 6| Step: 6
Training loss: 1.69045056132404
Validation loss: 2.649558398298227

Epoch: 6| Step: 7
Training loss: 1.530115135199091
Validation loss: 2.6761584399380647

Epoch: 6| Step: 8
Training loss: 1.306817742675587
Validation loss: 2.665193654343193

Epoch: 6| Step: 9
Training loss: 1.3526421793386187
Validation loss: 2.6566093915895275

Epoch: 6| Step: 10
Training loss: 1.1771805759648581
Validation loss: 2.61943305307671

Epoch: 6| Step: 11
Training loss: 1.5731503479362403
Validation loss: 2.6184770027956965

Epoch: 6| Step: 12
Training loss: 1.8883082168919914
Validation loss: 2.6048592746928216

Epoch: 6| Step: 13
Training loss: 1.3776398373500447
Validation loss: 2.599496442986684

Epoch: 324| Step: 0
Training loss: 1.8164578338189512
Validation loss: 2.579408200872001

Epoch: 6| Step: 1
Training loss: 1.7249450011400387
Validation loss: 2.5536457672490243

Epoch: 6| Step: 2
Training loss: 1.3937927342179905
Validation loss: 2.5317353533126066

Epoch: 6| Step: 3
Training loss: 1.7374438379665371
Validation loss: 2.5907083213819093

Epoch: 6| Step: 4
Training loss: 1.6385908322759823
Validation loss: 2.5503634301408926

Epoch: 6| Step: 5
Training loss: 1.3319063100083792
Validation loss: 2.5990951048019824

Epoch: 6| Step: 6
Training loss: 1.3813742793171664
Validation loss: 2.61388488161782

Epoch: 6| Step: 7
Training loss: 1.8119886268865113
Validation loss: 2.6557892546359643

Epoch: 6| Step: 8
Training loss: 1.4865943780495852
Validation loss: 2.6734038841363783

Epoch: 6| Step: 9
Training loss: 1.5204530876371432
Validation loss: 2.710157308088555

Epoch: 6| Step: 10
Training loss: 1.279130904518918
Validation loss: 2.725852139204694

Epoch: 6| Step: 11
Training loss: 1.5777492264655206
Validation loss: 2.7165876178374813

Epoch: 6| Step: 12
Training loss: 1.0554045888513646
Validation loss: 2.7225927132249765

Epoch: 6| Step: 13
Training loss: 1.1416230734045876
Validation loss: 2.716217596625867

Epoch: 325| Step: 0
Training loss: 1.3538663775719162
Validation loss: 2.695837050738072

Epoch: 6| Step: 1
Training loss: 1.564241125861101
Validation loss: 2.662216710043222

Epoch: 6| Step: 2
Training loss: 1.1745854884345852
Validation loss: 2.625738476596526

Epoch: 6| Step: 3
Training loss: 1.4953224843488098
Validation loss: 2.6166917321853234

Epoch: 6| Step: 4
Training loss: 1.153355816739578
Validation loss: 2.5760766178532957

Epoch: 6| Step: 5
Training loss: 1.4159594715428405
Validation loss: 2.5756604100529072

Epoch: 6| Step: 6
Training loss: 1.2236349557917183
Validation loss: 2.595422674153255

Epoch: 6| Step: 7
Training loss: 1.8682472062939297
Validation loss: 2.599247411417638

Epoch: 6| Step: 8
Training loss: 1.4551331784887154
Validation loss: 2.579769274674988

Epoch: 6| Step: 9
Training loss: 1.6753886725569325
Validation loss: 2.6272042556957675

Epoch: 6| Step: 10
Training loss: 1.6085138331640492
Validation loss: 2.630679374304801

Epoch: 6| Step: 11
Training loss: 2.059783996812625
Validation loss: 2.6566473724567934

Epoch: 6| Step: 12
Training loss: 1.550436524480403
Validation loss: 2.6622385713479493

Epoch: 6| Step: 13
Training loss: 1.4060946908594336
Validation loss: 2.654548998919614

Epoch: 326| Step: 0
Training loss: 1.491702415350503
Validation loss: 2.6371854616226664

Epoch: 6| Step: 1
Training loss: 1.2919357183662912
Validation loss: 2.6154992565264434

Epoch: 6| Step: 2
Training loss: 1.208159724731611
Validation loss: 2.6077683938159257

Epoch: 6| Step: 3
Training loss: 1.9806692409419473
Validation loss: 2.577646319815427

Epoch: 6| Step: 4
Training loss: 1.3115193472746625
Validation loss: 2.550169993023917

Epoch: 6| Step: 5
Training loss: 1.6176518312679617
Validation loss: 2.5761689821388583

Epoch: 6| Step: 6
Training loss: 1.4788018255753377
Validation loss: 2.5725218421916587

Epoch: 6| Step: 7
Training loss: 1.431725472177713
Validation loss: 2.5557649283521613

Epoch: 6| Step: 8
Training loss: 1.4500478341992944
Validation loss: 2.5503235874844514

Epoch: 6| Step: 9
Training loss: 1.6254001271530032
Validation loss: 2.6148865229863287

Epoch: 6| Step: 10
Training loss: 1.6946659525282761
Validation loss: 2.6539418914588726

Epoch: 6| Step: 11
Training loss: 1.54163103663881
Validation loss: 2.6878899884891982

Epoch: 6| Step: 12
Training loss: 1.648854424421195
Validation loss: 2.7542337118622053

Epoch: 6| Step: 13
Training loss: 0.7864760508446815
Validation loss: 2.705359469621701

Epoch: 327| Step: 0
Training loss: 2.0061314295256225
Validation loss: 2.687265420698316

Epoch: 6| Step: 1
Training loss: 1.3086693585316793
Validation loss: 2.6518383077038843

Epoch: 6| Step: 2
Training loss: 1.1092814553808659
Validation loss: 2.6693074535355987

Epoch: 6| Step: 3
Training loss: 1.5710405019180735
Validation loss: 2.621166234542185

Epoch: 6| Step: 4
Training loss: 1.6377080508551625
Validation loss: 2.6306281717315048

Epoch: 6| Step: 5
Training loss: 1.6480452807649983
Validation loss: 2.639163624577927

Epoch: 6| Step: 6
Training loss: 1.4082075693004807
Validation loss: 2.6335887459001395

Epoch: 6| Step: 7
Training loss: 1.6989964833080051
Validation loss: 2.647679505911921

Epoch: 6| Step: 8
Training loss: 1.088433231385913
Validation loss: 2.624999115177597

Epoch: 6| Step: 9
Training loss: 1.5208147997140535
Validation loss: 2.645507450073679

Epoch: 6| Step: 10
Training loss: 1.7918895390602294
Validation loss: 2.6572407350892084

Epoch: 6| Step: 11
Training loss: 1.1351011111893474
Validation loss: 2.62152827513986

Epoch: 6| Step: 12
Training loss: 1.2295363996220712
Validation loss: 2.629133434237414

Epoch: 6| Step: 13
Training loss: 1.565731521607043
Validation loss: 2.5900115860444584

Epoch: 328| Step: 0
Training loss: 1.0477479170621766
Validation loss: 2.6605910469490386

Epoch: 6| Step: 1
Training loss: 1.6790010690873123
Validation loss: 2.6570572564419552

Epoch: 6| Step: 2
Training loss: 1.388785957125014
Validation loss: 2.6540143173192257

Epoch: 6| Step: 3
Training loss: 1.4353378455118735
Validation loss: 2.649496483558983

Epoch: 6| Step: 4
Training loss: 1.4955526224900824
Validation loss: 2.677749853106699

Epoch: 6| Step: 5
Training loss: 1.5897609679768636
Validation loss: 2.660867461738418

Epoch: 6| Step: 6
Training loss: 1.9906690607629285
Validation loss: 2.5968956274679322

Epoch: 6| Step: 7
Training loss: 1.6317326383466302
Validation loss: 2.616354768059697

Epoch: 6| Step: 8
Training loss: 1.3822113282066364
Validation loss: 2.5951920696384447

Epoch: 6| Step: 9
Training loss: 1.7614668773922906
Validation loss: 2.571975202632804

Epoch: 6| Step: 10
Training loss: 1.0334129192611547
Validation loss: 2.593064669444669

Epoch: 6| Step: 11
Training loss: 1.4727744300433623
Validation loss: 2.5346423870135415

Epoch: 6| Step: 12
Training loss: 1.5870929135992935
Validation loss: 2.538469058875263

Epoch: 6| Step: 13
Training loss: 1.2830321315598177
Validation loss: 2.559301779082248

Epoch: 329| Step: 0
Training loss: 1.9582683741840876
Validation loss: 2.6174521363707584

Epoch: 6| Step: 1
Training loss: 1.9940694857918717
Validation loss: 2.6681387948355932

Epoch: 6| Step: 2
Training loss: 1.3215268661879866
Validation loss: 2.7106265690337747

Epoch: 6| Step: 3
Training loss: 1.427055395739263
Validation loss: 2.7633664388400496

Epoch: 6| Step: 4
Training loss: 1.5526486930958863
Validation loss: 2.6942348537902516

Epoch: 6| Step: 5
Training loss: 1.4547444825121056
Validation loss: 2.683261924679588

Epoch: 6| Step: 6
Training loss: 1.3567308162515965
Validation loss: 2.5887414506829183

Epoch: 6| Step: 7
Training loss: 1.2940707394250786
Validation loss: 2.6041514691965615

Epoch: 6| Step: 8
Training loss: 1.7490550623536754
Validation loss: 2.5511168253041427

Epoch: 6| Step: 9
Training loss: 1.4265430662203977
Validation loss: 2.5368496559976075

Epoch: 6| Step: 10
Training loss: 1.5330312839110463
Validation loss: 2.5073567547740914

Epoch: 6| Step: 11
Training loss: 1.3894242235148015
Validation loss: 2.483503858004388

Epoch: 6| Step: 12
Training loss: 0.9371714334106066
Validation loss: 2.5340984911183355

Epoch: 6| Step: 13
Training loss: 1.4171209822314534
Validation loss: 2.542605461890291

Epoch: 330| Step: 0
Training loss: 1.4637873795164518
Validation loss: 2.6182930940147084

Epoch: 6| Step: 1
Training loss: 1.416691817266071
Validation loss: 2.6391994479957925

Epoch: 6| Step: 2
Training loss: 1.4336535365971224
Validation loss: 2.7006407890757522

Epoch: 6| Step: 3
Training loss: 1.5666020525465587
Validation loss: 2.7386844944242705

Epoch: 6| Step: 4
Training loss: 1.385893799308934
Validation loss: 2.6987624982695033

Epoch: 6| Step: 5
Training loss: 1.586322981866701
Validation loss: 2.710429420910008

Epoch: 6| Step: 6
Training loss: 1.4932070140262068
Validation loss: 2.663641848090524

Epoch: 6| Step: 7
Training loss: 1.3672620916454428
Validation loss: 2.639182297421528

Epoch: 6| Step: 8
Training loss: 1.7966389376612533
Validation loss: 2.5959735713639036

Epoch: 6| Step: 9
Training loss: 1.6597469767804256
Validation loss: 2.5547352774103316

Epoch: 6| Step: 10
Training loss: 1.5443708399211409
Validation loss: 2.5458665969432004

Epoch: 6| Step: 11
Training loss: 1.5209464810578273
Validation loss: 2.529479430095879

Epoch: 6| Step: 12
Training loss: 1.1484505788875796
Validation loss: 2.4995372036218946

Epoch: 6| Step: 13
Training loss: 1.5711166827834304
Validation loss: 2.5245350496337498

Epoch: 331| Step: 0
Training loss: 1.3908680478413624
Validation loss: 2.544486206389068

Epoch: 6| Step: 1
Training loss: 1.1980984701881865
Validation loss: 2.5685209784527463

Epoch: 6| Step: 2
Training loss: 1.6333840569904603
Validation loss: 2.5773782219694374

Epoch: 6| Step: 3
Training loss: 1.5014245897805216
Validation loss: 2.6044395950204384

Epoch: 6| Step: 4
Training loss: 1.583525980556496
Validation loss: 2.6512220924760825

Epoch: 6| Step: 5
Training loss: 1.4295152237285988
Validation loss: 2.638397106063017

Epoch: 6| Step: 6
Training loss: 0.9767549859127893
Validation loss: 2.703658205528171

Epoch: 6| Step: 7
Training loss: 1.2799944890171862
Validation loss: 2.6815013163534758

Epoch: 6| Step: 8
Training loss: 1.8292115723724975
Validation loss: 2.674288776417663

Epoch: 6| Step: 9
Training loss: 1.7140510829938251
Validation loss: 2.6173985290424007

Epoch: 6| Step: 10
Training loss: 1.6113340435497363
Validation loss: 2.5962822511744146

Epoch: 6| Step: 11
Training loss: 1.585392599971667
Validation loss: 2.5518377829265004

Epoch: 6| Step: 12
Training loss: 1.2318866613446733
Validation loss: 2.5478385895688653

Epoch: 6| Step: 13
Training loss: 1.1723168620905813
Validation loss: 2.544250506001213

Epoch: 332| Step: 0
Training loss: 1.5152832904501332
Validation loss: 2.551986995550412

Epoch: 6| Step: 1
Training loss: 1.259966930303601
Validation loss: 2.605449381934338

Epoch: 6| Step: 2
Training loss: 1.7970351438063061
Validation loss: 2.6136019471766634

Epoch: 6| Step: 3
Training loss: 1.7036760471160137
Validation loss: 2.6460042938145993

Epoch: 6| Step: 4
Training loss: 1.3295561764839787
Validation loss: 2.6712822085320447

Epoch: 6| Step: 5
Training loss: 1.9052261354488254
Validation loss: 2.677490609108312

Epoch: 6| Step: 6
Training loss: 1.706075020785206
Validation loss: 2.705980205977449

Epoch: 6| Step: 7
Training loss: 1.4487949790258836
Validation loss: 2.6769892927943792

Epoch: 6| Step: 8
Training loss: 0.6943486852320685
Validation loss: 2.6429496222489566

Epoch: 6| Step: 9
Training loss: 1.5500357346876212
Validation loss: 2.658085522201297

Epoch: 6| Step: 10
Training loss: 1.2393249541627482
Validation loss: 2.612497347118791

Epoch: 6| Step: 11
Training loss: 1.0926259395541646
Validation loss: 2.5796143248286825

Epoch: 6| Step: 12
Training loss: 1.3718304950559772
Validation loss: 2.592279690811573

Epoch: 6| Step: 13
Training loss: 1.1337930579037052
Validation loss: 2.5772507190390264

Epoch: 333| Step: 0
Training loss: 1.0105935102568824
Validation loss: 2.541305620911687

Epoch: 6| Step: 1
Training loss: 1.5945985068715778
Validation loss: 2.5394702780184075

Epoch: 6| Step: 2
Training loss: 0.9414811480473738
Validation loss: 2.551997877996067

Epoch: 6| Step: 3
Training loss: 1.7814351705039322
Validation loss: 2.618780484351144

Epoch: 6| Step: 4
Training loss: 0.8987184831507512
Validation loss: 2.5979091894005975

Epoch: 6| Step: 5
Training loss: 1.3656230586057783
Validation loss: 2.6173207013574875

Epoch: 6| Step: 6
Training loss: 2.0599239329765693
Validation loss: 2.659862619738807

Epoch: 6| Step: 7
Training loss: 1.2123877915835288
Validation loss: 2.666517215688806

Epoch: 6| Step: 8
Training loss: 1.3395817892600614
Validation loss: 2.717049773915822

Epoch: 6| Step: 9
Training loss: 1.2279218199878188
Validation loss: 2.7105395526289144

Epoch: 6| Step: 10
Training loss: 1.5089210822853882
Validation loss: 2.6859249680387034

Epoch: 6| Step: 11
Training loss: 1.7328391620865355
Validation loss: 2.7265922247883623

Epoch: 6| Step: 12
Training loss: 1.609770050450041
Validation loss: 2.7099380998610867

Epoch: 6| Step: 13
Training loss: 1.7076667632719051
Validation loss: 2.691533777183432

Epoch: 334| Step: 0
Training loss: 1.8821980593665555
Validation loss: 2.6532342399899247

Epoch: 6| Step: 1
Training loss: 1.4931742017263256
Validation loss: 2.555797307619357

Epoch: 6| Step: 2
Training loss: 1.1662904041810365
Validation loss: 2.6277062275223235

Epoch: 6| Step: 3
Training loss: 1.1979116467356887
Validation loss: 2.5832358297894613

Epoch: 6| Step: 4
Training loss: 1.0524070103357102
Validation loss: 2.5743629250496696

Epoch: 6| Step: 5
Training loss: 1.6082358170958302
Validation loss: 2.598541216100305

Epoch: 6| Step: 6
Training loss: 1.5101395276007663
Validation loss: 2.5848299524796863

Epoch: 6| Step: 7
Training loss: 1.4379117624749505
Validation loss: 2.6188514529467755

Epoch: 6| Step: 8
Training loss: 1.2076950470147099
Validation loss: 2.619984820113004

Epoch: 6| Step: 9
Training loss: 1.5362892531989634
Validation loss: 2.6363896665983124

Epoch: 6| Step: 10
Training loss: 1.4896243785547316
Validation loss: 2.6264849689848977

Epoch: 6| Step: 11
Training loss: 1.743182868749219
Validation loss: 2.6361506238264782

Epoch: 6| Step: 12
Training loss: 1.465954331606533
Validation loss: 2.6641250077118697

Epoch: 6| Step: 13
Training loss: 0.9001443985495057
Validation loss: 2.680180685799703

Epoch: 335| Step: 0
Training loss: 1.4025970485245522
Validation loss: 2.674223528714145

Epoch: 6| Step: 1
Training loss: 1.2164187999707594
Validation loss: 2.674375168243264

Epoch: 6| Step: 2
Training loss: 1.3883021810882543
Validation loss: 2.6586419721170285

Epoch: 6| Step: 3
Training loss: 1.2036630492531497
Validation loss: 2.6909111869383384

Epoch: 6| Step: 4
Training loss: 1.6283642349642833
Validation loss: 2.702846547137149

Epoch: 6| Step: 5
Training loss: 1.3039550095590111
Validation loss: 2.704714631377199

Epoch: 6| Step: 6
Training loss: 1.554714336834563
Validation loss: 2.621488060872554

Epoch: 6| Step: 7
Training loss: 1.557577695913945
Validation loss: 2.653408750298694

Epoch: 6| Step: 8
Training loss: 1.5545779242311122
Validation loss: 2.656765986494749

Epoch: 6| Step: 9
Training loss: 1.772079149222291
Validation loss: 2.617249159376634

Epoch: 6| Step: 10
Training loss: 1.2696200765198984
Validation loss: 2.583433189671856

Epoch: 6| Step: 11
Training loss: 1.4902993284296517
Validation loss: 2.5882558878843267

Epoch: 6| Step: 12
Training loss: 1.1752348989698411
Validation loss: 2.535468467003734

Epoch: 6| Step: 13
Training loss: 1.5226440711045695
Validation loss: 2.555418124485761

Epoch: 336| Step: 0
Training loss: 1.611999519807162
Validation loss: 2.574872869516677

Epoch: 6| Step: 1
Training loss: 1.795387846823931
Validation loss: 2.566737329458273

Epoch: 6| Step: 2
Training loss: 1.4587830349696402
Validation loss: 2.585206840673457

Epoch: 6| Step: 3
Training loss: 1.3141237387522753
Validation loss: 2.611208672214691

Epoch: 6| Step: 4
Training loss: 1.0803894918613615
Validation loss: 2.5965645482771333

Epoch: 6| Step: 5
Training loss: 1.7040474169854303
Validation loss: 2.6431028077147793

Epoch: 6| Step: 6
Training loss: 1.4123737515093646
Validation loss: 2.625032674739399

Epoch: 6| Step: 7
Training loss: 1.2942615971788964
Validation loss: 2.585793076036792

Epoch: 6| Step: 8
Training loss: 1.361261396264046
Validation loss: 2.598349731755495

Epoch: 6| Step: 9
Training loss: 1.0910837099634116
Validation loss: 2.567602461466168

Epoch: 6| Step: 10
Training loss: 1.4704730701231068
Validation loss: 2.5580363718815033

Epoch: 6| Step: 11
Training loss: 1.6052496173491628
Validation loss: 2.5814190724448665

Epoch: 6| Step: 12
Training loss: 1.3231041642730181
Validation loss: 2.643444090650021

Epoch: 6| Step: 13
Training loss: 1.4031698614820334
Validation loss: 2.6573070722213554

Epoch: 337| Step: 0
Training loss: 1.3890495376926133
Validation loss: 2.6811053585201354

Epoch: 6| Step: 1
Training loss: 1.33325322725144
Validation loss: 2.735775388861213

Epoch: 6| Step: 2
Training loss: 1.6843941682138905
Validation loss: 2.7227086737615

Epoch: 6| Step: 3
Training loss: 1.1390813546000396
Validation loss: 2.6953857573614624

Epoch: 6| Step: 4
Training loss: 1.1417736905928821
Validation loss: 2.6863677875335368

Epoch: 6| Step: 5
Training loss: 1.7992327935966455
Validation loss: 2.6971585964305325

Epoch: 6| Step: 6
Training loss: 1.7273875202929052
Validation loss: 2.676164215445405

Epoch: 6| Step: 7
Training loss: 1.4055003393248124
Validation loss: 2.6697661146487537

Epoch: 6| Step: 8
Training loss: 1.6564320878035197
Validation loss: 2.6491509588330633

Epoch: 6| Step: 9
Training loss: 1.4559171369888577
Validation loss: 2.5968718596685103

Epoch: 6| Step: 10
Training loss: 1.3058719398197582
Validation loss: 2.5406029053856343

Epoch: 6| Step: 11
Training loss: 0.7646737319835504
Validation loss: 2.5466442284188537

Epoch: 6| Step: 12
Training loss: 1.209995617188642
Validation loss: 2.5449906386647627

Epoch: 6| Step: 13
Training loss: 1.5069110132231005
Validation loss: 2.4935841043830593

Epoch: 338| Step: 0
Training loss: 1.648212435576217
Validation loss: 2.5009886427539203

Epoch: 6| Step: 1
Training loss: 1.5072217189092594
Validation loss: 2.5124278841467955

Epoch: 6| Step: 2
Training loss: 1.1909056565515157
Validation loss: 2.5328114710667275

Epoch: 6| Step: 3
Training loss: 1.3033745835419661
Validation loss: 2.577470064673772

Epoch: 6| Step: 4
Training loss: 0.6926738089847063
Validation loss: 2.6051434213881333

Epoch: 6| Step: 5
Training loss: 1.1701108751172895
Validation loss: 2.6239340727971845

Epoch: 6| Step: 6
Training loss: 1.6681261904023699
Validation loss: 2.6484813879540625

Epoch: 6| Step: 7
Training loss: 0.9825186710185175
Validation loss: 2.6819969970356454

Epoch: 6| Step: 8
Training loss: 1.5825735410744537
Validation loss: 2.740932335687165

Epoch: 6| Step: 9
Training loss: 1.5131183621285775
Validation loss: 2.7207515554323463

Epoch: 6| Step: 10
Training loss: 1.2038355624013544
Validation loss: 2.7512346052519097

Epoch: 6| Step: 11
Training loss: 1.4490777535753498
Validation loss: 2.7166487820467737

Epoch: 6| Step: 12
Training loss: 1.7047333428838558
Validation loss: 2.684846800361607

Epoch: 6| Step: 13
Training loss: 1.7758885053742839
Validation loss: 2.647247561132884

Epoch: 339| Step: 0
Training loss: 1.7399300631356627
Validation loss: 2.5820775732753543

Epoch: 6| Step: 1
Training loss: 1.0858233275187932
Validation loss: 2.602831656242856

Epoch: 6| Step: 2
Training loss: 1.1356658778708983
Validation loss: 2.588361769060839

Epoch: 6| Step: 3
Training loss: 1.187275965789224
Validation loss: 2.612656902420344

Epoch: 6| Step: 4
Training loss: 1.2864229864085635
Validation loss: 2.6254345680152236

Epoch: 6| Step: 5
Training loss: 1.0014105623544929
Validation loss: 2.6223699047830706

Epoch: 6| Step: 6
Training loss: 1.4842889861232489
Validation loss: 2.675539596204915

Epoch: 6| Step: 7
Training loss: 0.8979135727146832
Validation loss: 2.6885265804011693

Epoch: 6| Step: 8
Training loss: 1.6053389522310524
Validation loss: 2.7237600242862

Epoch: 6| Step: 9
Training loss: 1.8593131944658345
Validation loss: 2.7335633088354103

Epoch: 6| Step: 10
Training loss: 1.2421603409779127
Validation loss: 2.681451415984777

Epoch: 6| Step: 11
Training loss: 1.7856881916319447
Validation loss: 2.6432476733897614

Epoch: 6| Step: 12
Training loss: 1.5498854502527046
Validation loss: 2.6362271968910433

Epoch: 6| Step: 13
Training loss: 1.2384531762177517
Validation loss: 2.5751257630255298

Epoch: 340| Step: 0
Training loss: 1.231649068845193
Validation loss: 2.5585396920093326

Epoch: 6| Step: 1
Training loss: 0.9654128523679768
Validation loss: 2.5243413184017554

Epoch: 6| Step: 2
Training loss: 1.525429855799538
Validation loss: 2.545769477764287

Epoch: 6| Step: 3
Training loss: 1.7683186197103193
Validation loss: 2.55150239689038

Epoch: 6| Step: 4
Training loss: 1.3100645084368439
Validation loss: 2.593875627456573

Epoch: 6| Step: 5
Training loss: 1.4813613012805622
Validation loss: 2.589893217908472

Epoch: 6| Step: 6
Training loss: 1.4158521255284837
Validation loss: 2.6332509191360107

Epoch: 6| Step: 7
Training loss: 0.9557716020661852
Validation loss: 2.6851008390973856

Epoch: 6| Step: 8
Training loss: 1.2339108234159903
Validation loss: 2.702049499017031

Epoch: 6| Step: 9
Training loss: 1.4147844526481177
Validation loss: 2.6962170648085304

Epoch: 6| Step: 10
Training loss: 1.6523407198830815
Validation loss: 2.70778930412515

Epoch: 6| Step: 11
Training loss: 1.3741206044623266
Validation loss: 2.671011690701902

Epoch: 6| Step: 12
Training loss: 1.3661840625707304
Validation loss: 2.691458020368035

Epoch: 6| Step: 13
Training loss: 1.464435408579945
Validation loss: 2.675563903129888

Epoch: 341| Step: 0
Training loss: 1.588116731768526
Validation loss: 2.6340734666266576

Epoch: 6| Step: 1
Training loss: 0.8766610183703082
Validation loss: 2.6031335966231746

Epoch: 6| Step: 2
Training loss: 0.9538166788273492
Validation loss: 2.6305892855271353

Epoch: 6| Step: 3
Training loss: 1.825255007760086
Validation loss: 2.5701684159292455

Epoch: 6| Step: 4
Training loss: 1.5847880891482318
Validation loss: 2.5434134220427542

Epoch: 6| Step: 5
Training loss: 1.0571917156210981
Validation loss: 2.5443761431810956

Epoch: 6| Step: 6
Training loss: 1.057561448478548
Validation loss: 2.5589651692853193

Epoch: 6| Step: 7
Training loss: 1.6327746811278878
Validation loss: 2.613135602090895

Epoch: 6| Step: 8
Training loss: 1.427870966982679
Validation loss: 2.597489033258527

Epoch: 6| Step: 9
Training loss: 1.6201817900301685
Validation loss: 2.6329696256385016

Epoch: 6| Step: 10
Training loss: 1.1428407546554349
Validation loss: 2.6602739703755556

Epoch: 6| Step: 11
Training loss: 1.497854765071472
Validation loss: 2.60488427560215

Epoch: 6| Step: 12
Training loss: 1.4466056193964747
Validation loss: 2.6557969075450343

Epoch: 6| Step: 13
Training loss: 1.1946899188927966
Validation loss: 2.6424327831260843

Epoch: 342| Step: 0
Training loss: 0.884141748354654
Validation loss: 2.615111473469942

Epoch: 6| Step: 1
Training loss: 1.9320336415499313
Validation loss: 2.6221261639433853

Epoch: 6| Step: 2
Training loss: 1.1889596300578706
Validation loss: 2.6146964739270753

Epoch: 6| Step: 3
Training loss: 1.2036780535309781
Validation loss: 2.5833632050321036

Epoch: 6| Step: 4
Training loss: 1.2262423152080055
Validation loss: 2.589228622455317

Epoch: 6| Step: 5
Training loss: 1.449551690613262
Validation loss: 2.584754230230205

Epoch: 6| Step: 6
Training loss: 1.250813982104601
Validation loss: 2.5558308399906373

Epoch: 6| Step: 7
Training loss: 1.391683325791537
Validation loss: 2.547704532749897

Epoch: 6| Step: 8
Training loss: 1.355073195025399
Validation loss: 2.568354907219682

Epoch: 6| Step: 9
Training loss: 1.6712459913960376
Validation loss: 2.582407089317321

Epoch: 6| Step: 10
Training loss: 1.5887159241534314
Validation loss: 2.5737693778186

Epoch: 6| Step: 11
Training loss: 1.2179833470632715
Validation loss: 2.646764809455965

Epoch: 6| Step: 12
Training loss: 0.9586042594799913
Validation loss: 2.659818820303554

Epoch: 6| Step: 13
Training loss: 1.7086953578157
Validation loss: 2.6899538277596275

Epoch: 343| Step: 0
Training loss: 1.295952342334507
Validation loss: 2.7257580860856865

Epoch: 6| Step: 1
Training loss: 1.6709520163047311
Validation loss: 2.7357985936769604

Epoch: 6| Step: 2
Training loss: 1.267154852167863
Validation loss: 2.6824383939344862

Epoch: 6| Step: 3
Training loss: 1.2927109383498674
Validation loss: 2.667304357074742

Epoch: 6| Step: 4
Training loss: 1.0999082765484416
Validation loss: 2.6162605535868373

Epoch: 6| Step: 5
Training loss: 1.1458036361082649
Validation loss: 2.608659232103303

Epoch: 6| Step: 6
Training loss: 1.2242540638010802
Validation loss: 2.5834295775566

Epoch: 6| Step: 7
Training loss: 1.5352536236115046
Validation loss: 2.52931156069455

Epoch: 6| Step: 8
Training loss: 1.0803123068485192
Validation loss: 2.5187737853429653

Epoch: 6| Step: 9
Training loss: 1.4385791542569857
Validation loss: 2.5703572441630267

Epoch: 6| Step: 10
Training loss: 1.5988993763279626
Validation loss: 2.543610371414897

Epoch: 6| Step: 11
Training loss: 1.7575526744822505
Validation loss: 2.6058540544546833

Epoch: 6| Step: 12
Training loss: 1.069313139650672
Validation loss: 2.576838501813552

Epoch: 6| Step: 13
Training loss: 1.316223312933363
Validation loss: 2.5979091726248416

Epoch: 344| Step: 0
Training loss: 1.0432755951144694
Validation loss: 2.6405696747812755

Epoch: 6| Step: 1
Training loss: 0.9875704957449921
Validation loss: 2.6787988365978035

Epoch: 6| Step: 2
Training loss: 1.6686398587686573
Validation loss: 2.736052588408212

Epoch: 6| Step: 3
Training loss: 1.3268978508281215
Validation loss: 2.7475311014273283

Epoch: 6| Step: 4
Training loss: 1.1664682401216084
Validation loss: 2.707219989401622

Epoch: 6| Step: 5
Training loss: 1.2265905875130505
Validation loss: 2.655247998158081

Epoch: 6| Step: 6
Training loss: 1.3694980824050764
Validation loss: 2.6406117848090314

Epoch: 6| Step: 7
Training loss: 1.3361628827493528
Validation loss: 2.645489474053481

Epoch: 6| Step: 8
Training loss: 1.7284458986863513
Validation loss: 2.605477066298582

Epoch: 6| Step: 9
Training loss: 1.5947383733009513
Validation loss: 2.643935140259823

Epoch: 6| Step: 10
Training loss: 1.2738697277997233
Validation loss: 2.5947600561474182

Epoch: 6| Step: 11
Training loss: 1.1833561321981485
Validation loss: 2.5829880814832205

Epoch: 6| Step: 12
Training loss: 1.738261704924353
Validation loss: 2.6067066024697456

Epoch: 6| Step: 13
Training loss: 0.7641499771561457
Validation loss: 2.5939472675487143

Epoch: 345| Step: 0
Training loss: 1.5635040109239544
Validation loss: 2.6089405574767968

Epoch: 6| Step: 1
Training loss: 1.732970897978309
Validation loss: 2.6228230254059484

Epoch: 6| Step: 2
Training loss: 1.123694828363671
Validation loss: 2.6465426724616763

Epoch: 6| Step: 3
Training loss: 1.0057044048741237
Validation loss: 2.6413633121786315

Epoch: 6| Step: 4
Training loss: 1.0059617073817695
Validation loss: 2.650461592574913

Epoch: 6| Step: 5
Training loss: 0.967796748830384
Validation loss: 2.6571630338324583

Epoch: 6| Step: 6
Training loss: 0.9155950495798147
Validation loss: 2.675463457415048

Epoch: 6| Step: 7
Training loss: 1.522614320243258
Validation loss: 2.6812269102016857

Epoch: 6| Step: 8
Training loss: 1.7330648611690211
Validation loss: 2.717201090607233

Epoch: 6| Step: 9
Training loss: 0.9602162825810658
Validation loss: 2.687659850998283

Epoch: 6| Step: 10
Training loss: 1.303855219368681
Validation loss: 2.7022087578177416

Epoch: 6| Step: 11
Training loss: 1.8725459251323413
Validation loss: 2.672103828859974

Epoch: 6| Step: 12
Training loss: 1.2900837869565542
Validation loss: 2.652785779474236

Epoch: 6| Step: 13
Training loss: 1.0206701122249033
Validation loss: 2.6712341384378

Epoch: 346| Step: 0
Training loss: 1.2511446956715842
Validation loss: 2.6342190468577624

Epoch: 6| Step: 1
Training loss: 1.8688265577473728
Validation loss: 2.658096337732761

Epoch: 6| Step: 2
Training loss: 1.3810444104914565
Validation loss: 2.647734603172954

Epoch: 6| Step: 3
Training loss: 1.2037861976449569
Validation loss: 2.6407567191798047

Epoch: 6| Step: 4
Training loss: 1.5982558936862648
Validation loss: 2.6334908997340767

Epoch: 6| Step: 5
Training loss: 1.0395678101771342
Validation loss: 2.668572677842738

Epoch: 6| Step: 6
Training loss: 0.9325175446810642
Validation loss: 2.6408476075826495

Epoch: 6| Step: 7
Training loss: 1.4447997137210937
Validation loss: 2.659279952952285

Epoch: 6| Step: 8
Training loss: 1.1520113190717396
Validation loss: 2.6613910683325184

Epoch: 6| Step: 9
Training loss: 1.354512077686062
Validation loss: 2.628414751539529

Epoch: 6| Step: 10
Training loss: 1.187436754650607
Validation loss: 2.6112039419792636

Epoch: 6| Step: 11
Training loss: 1.3545940996155028
Validation loss: 2.6123594179995515

Epoch: 6| Step: 12
Training loss: 0.8428665763867403
Validation loss: 2.600139248931395

Epoch: 6| Step: 13
Training loss: 1.969708890367551
Validation loss: 2.574737921222022

Epoch: 347| Step: 0
Training loss: 0.9756543629032008
Validation loss: 2.584787529766099

Epoch: 6| Step: 1
Training loss: 1.0760173929042498
Validation loss: 2.59026545702446

Epoch: 6| Step: 2
Training loss: 1.5988195236873142
Validation loss: 2.578917016824585

Epoch: 6| Step: 3
Training loss: 1.324532215747614
Validation loss: 2.5808321445094724

Epoch: 6| Step: 4
Training loss: 1.255597693913977
Validation loss: 2.6502552928764858

Epoch: 6| Step: 5
Training loss: 1.1359058632833066
Validation loss: 2.6483802722678456

Epoch: 6| Step: 6
Training loss: 1.6769233137600341
Validation loss: 2.674790790079393

Epoch: 6| Step: 7
Training loss: 1.5772041429065196
Validation loss: 2.7028544348229815

Epoch: 6| Step: 8
Training loss: 1.7486509163894108
Validation loss: 2.6540944917495852

Epoch: 6| Step: 9
Training loss: 0.7693653992984311
Validation loss: 2.6623064970183927

Epoch: 6| Step: 10
Training loss: 1.3463688547696995
Validation loss: 2.6144014401554414

Epoch: 6| Step: 11
Training loss: 1.0437372926406765
Validation loss: 2.5781590911609964

Epoch: 6| Step: 12
Training loss: 1.2688707247269246
Validation loss: 2.555907721045912

Epoch: 6| Step: 13
Training loss: 1.7035154542527073
Validation loss: 2.5721510618709127

Epoch: 348| Step: 0
Training loss: 1.1966473973050156
Validation loss: 2.5886800322996186

Epoch: 6| Step: 1
Training loss: 1.3268294354529153
Validation loss: 2.569993173159165

Epoch: 6| Step: 2
Training loss: 1.42245873845601
Validation loss: 2.567245423367127

Epoch: 6| Step: 3
Training loss: 1.41518580884832
Validation loss: 2.6122850364487986

Epoch: 6| Step: 4
Training loss: 1.3819143104569174
Validation loss: 2.6126908246108047

Epoch: 6| Step: 5
Training loss: 1.4480157264835478
Validation loss: 2.592696377044507

Epoch: 6| Step: 6
Training loss: 1.1279305330083411
Validation loss: 2.6188668904369843

Epoch: 6| Step: 7
Training loss: 1.3717063122315911
Validation loss: 2.6409397431586727

Epoch: 6| Step: 8
Training loss: 1.6940762983251725
Validation loss: 2.6730967143263875

Epoch: 6| Step: 9
Training loss: 1.1840098943071378
Validation loss: 2.679737487745757

Epoch: 6| Step: 10
Training loss: 0.7035534506991252
Validation loss: 2.6679992486663306

Epoch: 6| Step: 11
Training loss: 1.5305840737481635
Validation loss: 2.6832401620470754

Epoch: 6| Step: 12
Training loss: 1.2054151066966576
Validation loss: 2.6506872833353325

Epoch: 6| Step: 13
Training loss: 1.3936372343555032
Validation loss: 2.6087550187602746

Epoch: 349| Step: 0
Training loss: 1.3402734184304048
Validation loss: 2.591527082906646

Epoch: 6| Step: 1
Training loss: 1.515051507105732
Validation loss: 2.580372041623948

Epoch: 6| Step: 2
Training loss: 1.2079023162491145
Validation loss: 2.5617482633153763

Epoch: 6| Step: 3
Training loss: 1.2114779343116806
Validation loss: 2.5525687229297547

Epoch: 6| Step: 4
Training loss: 1.4468601497934424
Validation loss: 2.5920479214865697

Epoch: 6| Step: 5
Training loss: 1.1617469543029646
Validation loss: 2.5842519318439607

Epoch: 6| Step: 6
Training loss: 1.0471490529742637
Validation loss: 2.627990632444106

Epoch: 6| Step: 7
Training loss: 1.3601492945686606
Validation loss: 2.6576866284700063

Epoch: 6| Step: 8
Training loss: 1.350815318413231
Validation loss: 2.718027336832956

Epoch: 6| Step: 9
Training loss: 1.3906458306627614
Validation loss: 2.7172715473260847

Epoch: 6| Step: 10
Training loss: 1.5324134299390515
Validation loss: 2.7276242075978354

Epoch: 6| Step: 11
Training loss: 1.255095538800058
Validation loss: 2.6934881817183816

Epoch: 6| Step: 12
Training loss: 1.3048142240278744
Validation loss: 2.6879122370923256

Epoch: 6| Step: 13
Training loss: 1.3840133711328837
Validation loss: 2.6205904949288876

Epoch: 350| Step: 0
Training loss: 1.33260268318505
Validation loss: 2.578067102462672

Epoch: 6| Step: 1
Training loss: 0.986329937923767
Validation loss: 2.5735542905884965

Epoch: 6| Step: 2
Training loss: 1.0032175871049716
Validation loss: 2.601451645385997

Epoch: 6| Step: 3
Training loss: 1.2013529819324027
Validation loss: 2.5733471746440135

Epoch: 6| Step: 4
Training loss: 1.0826323454303448
Validation loss: 2.5927736392078167

Epoch: 6| Step: 5
Training loss: 1.4687413966150118
Validation loss: 2.6248947743597837

Epoch: 6| Step: 6
Training loss: 1.6718205951145433
Validation loss: 2.5988205195381964

Epoch: 6| Step: 7
Training loss: 1.1544706726909062
Validation loss: 2.652059062024435

Epoch: 6| Step: 8
Training loss: 1.4312220608178963
Validation loss: 2.625963754890064

Epoch: 6| Step: 9
Training loss: 1.653988139450188
Validation loss: 2.6447115961889045

Epoch: 6| Step: 10
Training loss: 1.295664532615436
Validation loss: 2.603355048584338

Epoch: 6| Step: 11
Training loss: 1.3566520868372438
Validation loss: 2.5851926272025416

Epoch: 6| Step: 12
Training loss: 1.4043723816925753
Validation loss: 2.5705898576742396

Epoch: 6| Step: 13
Training loss: 0.864513363745385
Validation loss: 2.5992366917818006

Testing loss: 2.2207832917664403
