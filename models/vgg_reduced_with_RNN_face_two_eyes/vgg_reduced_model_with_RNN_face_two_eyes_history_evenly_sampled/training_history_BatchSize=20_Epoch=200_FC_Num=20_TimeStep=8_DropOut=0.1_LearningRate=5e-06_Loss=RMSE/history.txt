Epoch: 1| Step: 0
Training loss: 5.022511920525554
Validation loss: 5.714742700773507

Epoch: 5| Step: 1
Training loss: 6.09409491712155
Validation loss: 5.7088598438621

Epoch: 5| Step: 2
Training loss: 5.564584405809207
Validation loss: 5.703098129723856

Epoch: 5| Step: 3
Training loss: 6.3891223735807285
Validation loss: 5.696673152180676

Epoch: 5| Step: 4
Training loss: 5.318385913907343
Validation loss: 5.690530583701333

Epoch: 5| Step: 5
Training loss: 5.129978645979253
Validation loss: 5.684331585414675

Epoch: 5| Step: 6
Training loss: 6.466238520236161
Validation loss: 5.67826088325399

Epoch: 5| Step: 7
Training loss: 5.248468084720352
Validation loss: 5.671783474550653

Epoch: 5| Step: 8
Training loss: 6.471773924284653
Validation loss: 5.665042204012028

Epoch: 5| Step: 9
Training loss: 5.587508486201522
Validation loss: 5.6582933586540545

Epoch: 5| Step: 10
Training loss: 5.34272372557868
Validation loss: 5.651539770949182

Epoch: 2| Step: 0
Training loss: 5.107755165093378
Validation loss: 5.644804133706097

Epoch: 5| Step: 1
Training loss: 5.771014085640422
Validation loss: 5.637595949947378

Epoch: 5| Step: 2
Training loss: 4.558559649682333
Validation loss: 5.630022234744462

Epoch: 5| Step: 3
Training loss: 5.574349116489724
Validation loss: 5.622272449082986

Epoch: 5| Step: 4
Training loss: 5.70966388574953
Validation loss: 5.613569868567758

Epoch: 5| Step: 5
Training loss: 5.843475498545331
Validation loss: 5.6055096732014205

Epoch: 5| Step: 6
Training loss: 6.013095869012204
Validation loss: 5.596834627526004

Epoch: 5| Step: 7
Training loss: 5.612721244682281
Validation loss: 5.587636180692892

Epoch: 5| Step: 8
Training loss: 5.779985609201646
Validation loss: 5.577925542492467

Epoch: 5| Step: 9
Training loss: 6.131221491973894
Validation loss: 5.567085557817465

Epoch: 5| Step: 10
Training loss: 5.841994730852018
Validation loss: 5.557667388825651

Epoch: 3| Step: 0
Training loss: 5.536688248701173
Validation loss: 5.5466385837927445

Epoch: 5| Step: 1
Training loss: 6.4577871112153655
Validation loss: 5.534577019074362

Epoch: 5| Step: 2
Training loss: 5.6271131149157325
Validation loss: 5.522371643928078

Epoch: 5| Step: 3
Training loss: 6.147130107385796
Validation loss: 5.510245149091976

Epoch: 5| Step: 4
Training loss: 4.415968113963791
Validation loss: 5.497653372946422

Epoch: 5| Step: 5
Training loss: 5.097337828297337
Validation loss: 5.4842862147529745

Epoch: 5| Step: 6
Training loss: 5.779352980041963
Validation loss: 5.470754917698284

Epoch: 5| Step: 7
Training loss: 4.192032823186602
Validation loss: 5.456611533949027

Epoch: 5| Step: 8
Training loss: 5.584861641094692
Validation loss: 5.4417176222005095

Epoch: 5| Step: 9
Training loss: 6.042933714850766
Validation loss: 5.427364891044832

Epoch: 5| Step: 10
Training loss: 5.464602221699788
Validation loss: 5.411364859869101

Epoch: 4| Step: 0
Training loss: 4.916077702478536
Validation loss: 5.394681523092995

Epoch: 5| Step: 1
Training loss: 5.265991198203862
Validation loss: 5.378569977771833

Epoch: 5| Step: 2
Training loss: 4.496080599052227
Validation loss: 5.361369540332158

Epoch: 5| Step: 3
Training loss: 4.417210143617899
Validation loss: 5.3442311555151045

Epoch: 5| Step: 4
Training loss: 5.439397195908605
Validation loss: 5.32720995414331

Epoch: 5| Step: 5
Training loss: 5.724623701896948
Validation loss: 5.309898620722863

Epoch: 5| Step: 6
Training loss: 6.418346168718536
Validation loss: 5.290800447938768

Epoch: 5| Step: 7
Training loss: 5.914446275320484
Validation loss: 5.272559030057563

Epoch: 5| Step: 8
Training loss: 5.170947403716456
Validation loss: 5.253751185185461

Epoch: 5| Step: 9
Training loss: 4.83998837997681
Validation loss: 5.234298669744923

Epoch: 5| Step: 10
Training loss: 5.987017892051609
Validation loss: 5.214078011911404

Epoch: 5| Step: 0
Training loss: 5.263534176074577
Validation loss: 5.1944671823973705

Epoch: 5| Step: 1
Training loss: 4.953997899103932
Validation loss: 5.174288675314853

Epoch: 5| Step: 2
Training loss: 5.6813404978310285
Validation loss: 5.154940547094015

Epoch: 5| Step: 3
Training loss: 4.70749782924835
Validation loss: 5.135404342872539

Epoch: 5| Step: 4
Training loss: 4.536230047228848
Validation loss: 5.115447399089308

Epoch: 5| Step: 5
Training loss: 5.34245168518583
Validation loss: 5.095339023627102

Epoch: 5| Step: 6
Training loss: 5.398670329525993
Validation loss: 5.0756807599819895

Epoch: 5| Step: 7
Training loss: 4.447095784800396
Validation loss: 5.05664971218987

Epoch: 5| Step: 8
Training loss: 5.721832278564571
Validation loss: 5.038341155986001

Epoch: 5| Step: 9
Training loss: 5.599018705767047
Validation loss: 5.016822301720552

Epoch: 5| Step: 10
Training loss: 4.77715989240189
Validation loss: 4.999471899056451

Epoch: 6| Step: 0
Training loss: 4.148865758482573
Validation loss: 4.982337084747722

Epoch: 5| Step: 1
Training loss: 5.673855690552659
Validation loss: 4.962279174235858

Epoch: 5| Step: 2
Training loss: 5.562786309235399
Validation loss: 4.943967683697051

Epoch: 5| Step: 3
Training loss: 3.899246040238037
Validation loss: 4.926050852164827

Epoch: 5| Step: 4
Training loss: 4.415202467910345
Validation loss: 4.908194097255148

Epoch: 5| Step: 5
Training loss: 5.082503558531499
Validation loss: 4.89195481277098

Epoch: 5| Step: 6
Training loss: 5.512168081934819
Validation loss: 4.875462687043544

Epoch: 5| Step: 7
Training loss: 5.351800932758706
Validation loss: 4.859038483592199

Epoch: 5| Step: 8
Training loss: 5.08310452972947
Validation loss: 4.840603711433685

Epoch: 5| Step: 9
Training loss: 4.370903931451538
Validation loss: 4.824065544037546

Epoch: 5| Step: 10
Training loss: 5.151208991202446
Validation loss: 4.807712472209182

Epoch: 7| Step: 0
Training loss: 4.848939736477776
Validation loss: 4.791398608113989

Epoch: 5| Step: 1
Training loss: 4.169598933630666
Validation loss: 4.7760677500873046

Epoch: 5| Step: 2
Training loss: 5.298592708095169
Validation loss: 4.758798351049696

Epoch: 5| Step: 3
Training loss: 5.519805275067066
Validation loss: 4.743554140913334

Epoch: 5| Step: 4
Training loss: 4.555498577681675
Validation loss: 4.7265823926568915

Epoch: 5| Step: 5
Training loss: 4.300128828381055
Validation loss: 4.710335642876062

Epoch: 5| Step: 6
Training loss: 4.75076127226107
Validation loss: 4.695764070519008

Epoch: 5| Step: 7
Training loss: 4.812163898571905
Validation loss: 4.678654027281218

Epoch: 5| Step: 8
Training loss: 4.457382790077634
Validation loss: 4.660527187100454

Epoch: 5| Step: 9
Training loss: 5.145257317843423
Validation loss: 4.64387703590154

Epoch: 5| Step: 10
Training loss: 4.707210553185039
Validation loss: 4.627503553091208

Epoch: 8| Step: 0
Training loss: 4.413870856251794
Validation loss: 4.608815315796335

Epoch: 5| Step: 1
Training loss: 3.137077795550648
Validation loss: 4.590923320010955

Epoch: 5| Step: 2
Training loss: 5.168142948689204
Validation loss: 4.570796972637501

Epoch: 5| Step: 3
Training loss: 5.987574745301006
Validation loss: 4.552838830937412

Epoch: 5| Step: 4
Training loss: 4.01408813991057
Validation loss: 4.5340146308028615

Epoch: 5| Step: 5
Training loss: 4.548361833389208
Validation loss: 4.513668312676274

Epoch: 5| Step: 6
Training loss: 3.941102574788543
Validation loss: 4.496379685793793

Epoch: 5| Step: 7
Training loss: 4.729838700235878
Validation loss: 4.479426052465251

Epoch: 5| Step: 8
Training loss: 5.333049031468387
Validation loss: 4.464308633818733

Epoch: 5| Step: 9
Training loss: 4.163291530557067
Validation loss: 4.446909588621678

Epoch: 5| Step: 10
Training loss: 4.693557893806643
Validation loss: 4.432518350759985

Epoch: 9| Step: 0
Training loss: 5.254997236575953
Validation loss: 4.418929740149966

Epoch: 5| Step: 1
Training loss: 4.712422555949879
Validation loss: 4.405239669248432

Epoch: 5| Step: 2
Training loss: 4.251956713652596
Validation loss: 4.390072811166762

Epoch: 5| Step: 3
Training loss: 4.431789753784912
Validation loss: 4.377127242452921

Epoch: 5| Step: 4
Training loss: 4.772402287437601
Validation loss: 4.363647615945564

Epoch: 5| Step: 5
Training loss: 4.609197270474482
Validation loss: 4.350377691579184

Epoch: 5| Step: 6
Training loss: 4.486122774332722
Validation loss: 4.333615752136494

Epoch: 5| Step: 7
Training loss: 4.211624570715937
Validation loss: 4.321370367786163

Epoch: 5| Step: 8
Training loss: 2.7748472257607726
Validation loss: 4.306492717756141

Epoch: 5| Step: 9
Training loss: 4.092936893695221
Validation loss: 4.287338051532273

Epoch: 5| Step: 10
Training loss: 5.159557044955166
Validation loss: 4.269803758001125

Epoch: 10| Step: 0
Training loss: 4.773098248352713
Validation loss: 4.25117138856114

Epoch: 5| Step: 1
Training loss: 3.9042107714289322
Validation loss: 4.236370684218184

Epoch: 5| Step: 2
Training loss: 4.01746703176496
Validation loss: 4.219557098760857

Epoch: 5| Step: 3
Training loss: 3.6350560633390736
Validation loss: 4.206678107425043

Epoch: 5| Step: 4
Training loss: 4.081514667148633
Validation loss: 4.194161993133472

Epoch: 5| Step: 5
Training loss: 4.496330672583135
Validation loss: 4.182657776580668

Epoch: 5| Step: 6
Training loss: 4.816925986062086
Validation loss: 4.172171343413388

Epoch: 5| Step: 7
Training loss: 4.904983259788824
Validation loss: 4.162512367439811

Epoch: 5| Step: 8
Training loss: 3.8311690703116326
Validation loss: 4.152694240824637

Epoch: 5| Step: 9
Training loss: 4.0380709406840625
Validation loss: 4.144915625061789

Epoch: 5| Step: 10
Training loss: 4.768890162816687
Validation loss: 4.1325377389960485

Epoch: 11| Step: 0
Training loss: 3.807065749173538
Validation loss: 4.1223584726120315

Epoch: 5| Step: 1
Training loss: 4.633097596426466
Validation loss: 4.114570533957874

Epoch: 5| Step: 2
Training loss: 4.4104581177135636
Validation loss: 4.106047160404794

Epoch: 5| Step: 3
Training loss: 3.837117497271384
Validation loss: 4.094647919399495

Epoch: 5| Step: 4
Training loss: 3.922782762497256
Validation loss: 4.087472217278869

Epoch: 5| Step: 5
Training loss: 3.236963682784685
Validation loss: 4.078529172865922

Epoch: 5| Step: 6
Training loss: 4.908309018517951
Validation loss: 4.069157350337673

Epoch: 5| Step: 7
Training loss: 3.7273318218359366
Validation loss: 4.062881843032444

Epoch: 5| Step: 8
Training loss: 4.572836884633205
Validation loss: 4.056279961186685

Epoch: 5| Step: 9
Training loss: 5.038329646321288
Validation loss: 4.048974799965048

Epoch: 5| Step: 10
Training loss: 3.886008223567631
Validation loss: 4.0414415877634235

Epoch: 12| Step: 0
Training loss: 4.622269520354566
Validation loss: 4.034628028064976

Epoch: 5| Step: 1
Training loss: 3.997327507835081
Validation loss: 4.0297708254727445

Epoch: 5| Step: 2
Training loss: 3.64292383266493
Validation loss: 4.021890519873586

Epoch: 5| Step: 3
Training loss: 4.611957615335846
Validation loss: 4.018194095085632

Epoch: 5| Step: 4
Training loss: 4.197121114892465
Validation loss: 4.011633938539308

Epoch: 5| Step: 5
Training loss: 4.67952976374918
Validation loss: 4.004024506309957

Epoch: 5| Step: 6
Training loss: 4.823166161737585
Validation loss: 3.998474601894659

Epoch: 5| Step: 7
Training loss: 4.0218519327232825
Validation loss: 3.991818767592686

Epoch: 5| Step: 8
Training loss: 3.4206797284585853
Validation loss: 3.9849387818592996

Epoch: 5| Step: 9
Training loss: 3.825839111438981
Validation loss: 3.979771749376569

Epoch: 5| Step: 10
Training loss: 3.457793519200263
Validation loss: 3.9747401978045716

Epoch: 13| Step: 0
Training loss: 3.361203569834206
Validation loss: 3.9718253864932525

Epoch: 5| Step: 1
Training loss: 4.307792637515983
Validation loss: 3.963170756364607

Epoch: 5| Step: 2
Training loss: 4.633601669847598
Validation loss: 3.9574146847642675

Epoch: 5| Step: 3
Training loss: 3.4458613574830776
Validation loss: 3.9550910032106477

Epoch: 5| Step: 4
Training loss: 4.7442537987607345
Validation loss: 3.950809521613811

Epoch: 5| Step: 5
Training loss: 4.321537885668206
Validation loss: 3.946412624709758

Epoch: 5| Step: 6
Training loss: 2.981663615646493
Validation loss: 3.9369535052271223

Epoch: 5| Step: 7
Training loss: 4.906373235041664
Validation loss: 3.933404561296958

Epoch: 5| Step: 8
Training loss: 3.6621977853911347
Validation loss: 3.9255083549533554

Epoch: 5| Step: 9
Training loss: 4.713372406282748
Validation loss: 3.9242738372719472

Epoch: 5| Step: 10
Training loss: 3.322263902667102
Validation loss: 3.9204682590367392

Epoch: 14| Step: 0
Training loss: 3.6604956079755513
Validation loss: 3.9138096844877874

Epoch: 5| Step: 1
Training loss: 5.064129790765609
Validation loss: 3.9097681241675404

Epoch: 5| Step: 2
Training loss: 4.462052668528648
Validation loss: 3.903780427352312

Epoch: 5| Step: 3
Training loss: 4.041208431314469
Validation loss: 3.898685581005289

Epoch: 5| Step: 4
Training loss: 3.6233078525867355
Validation loss: 3.8948634525548567

Epoch: 5| Step: 5
Training loss: 4.148401177601109
Validation loss: 3.893520867656679

Epoch: 5| Step: 6
Training loss: 3.96613123242535
Validation loss: 3.8865346540843846

Epoch: 5| Step: 7
Training loss: 4.220981939975301
Validation loss: 3.88272113898481

Epoch: 5| Step: 8
Training loss: 3.4855548588790524
Validation loss: 3.8768771623413576

Epoch: 5| Step: 9
Training loss: 3.35196226354584
Validation loss: 3.8743062240149984

Epoch: 5| Step: 10
Training loss: 4.277285557181201
Validation loss: 3.8694524389294602

Epoch: 15| Step: 0
Training loss: 4.715635572943643
Validation loss: 3.8683294279811125

Epoch: 5| Step: 1
Training loss: 4.043215949568332
Validation loss: 3.861116076775316

Epoch: 5| Step: 2
Training loss: 3.2860495206754785
Validation loss: 3.855775007437543

Epoch: 5| Step: 3
Training loss: 4.912643834306434
Validation loss: 3.8532990272505847

Epoch: 5| Step: 4
Training loss: 3.526719689742797
Validation loss: 3.847822639411857

Epoch: 5| Step: 5
Training loss: 4.139819948639472
Validation loss: 3.842367061352899

Epoch: 5| Step: 6
Training loss: 4.194470425848812
Validation loss: 3.8415008588863353

Epoch: 5| Step: 7
Training loss: 2.980623293728379
Validation loss: 3.8341804404822515

Epoch: 5| Step: 8
Training loss: 4.190968685294387
Validation loss: 3.83359394997713

Epoch: 5| Step: 9
Training loss: 3.781886527971089
Validation loss: 3.8310494318069845

Epoch: 5| Step: 10
Training loss: 3.9573082784551903
Validation loss: 3.825127137948035

Epoch: 16| Step: 0
Training loss: 3.3687792774973557
Validation loss: 3.822434259819411

Epoch: 5| Step: 1
Training loss: 4.188946374509421
Validation loss: 3.821183779266874

Epoch: 5| Step: 2
Training loss: 3.5515123879840815
Validation loss: 3.814569275826649

Epoch: 5| Step: 3
Training loss: 3.7909479543000737
Validation loss: 3.808278086717009

Epoch: 5| Step: 4
Training loss: 3.721437653053777
Validation loss: 3.8056578434671855

Epoch: 5| Step: 5
Training loss: 4.100360454438517
Validation loss: 3.8032833379619255

Epoch: 5| Step: 6
Training loss: 3.3373948784321223
Validation loss: 3.8001449806651624

Epoch: 5| Step: 7
Training loss: 4.2659391070963615
Validation loss: 3.7979740476646233

Epoch: 5| Step: 8
Training loss: 4.7532201191891845
Validation loss: 3.7929003679474382

Epoch: 5| Step: 9
Training loss: 4.944825930410055
Validation loss: 3.7890234511012166

Epoch: 5| Step: 10
Training loss: 3.1462715972050006
Validation loss: 3.7857390344258177

Epoch: 17| Step: 0
Training loss: 3.9432273264480804
Validation loss: 3.779923203111345

Epoch: 5| Step: 1
Training loss: 4.576553022766198
Validation loss: 3.777345304196874

Epoch: 5| Step: 2
Training loss: 4.251319680364934
Validation loss: 3.7760905578412762

Epoch: 5| Step: 3
Training loss: 3.11551187170219
Validation loss: 3.7708077632399912

Epoch: 5| Step: 4
Training loss: 3.851558909695018
Validation loss: 3.7660712657342788

Epoch: 5| Step: 5
Training loss: 3.8079022058463567
Validation loss: 3.7688983504725333

Epoch: 5| Step: 6
Training loss: 2.856297405358708
Validation loss: 3.7723444442956033

Epoch: 5| Step: 7
Training loss: 4.15246432569821
Validation loss: 3.7668495261973107

Epoch: 5| Step: 8
Training loss: 4.9185539545836425
Validation loss: 3.7553355744546852

Epoch: 5| Step: 9
Training loss: 3.573621022424463
Validation loss: 3.748880097440831

Epoch: 5| Step: 10
Training loss: 3.846764227777534
Validation loss: 3.7468407561798633

Epoch: 18| Step: 0
Training loss: 4.226205525157187
Validation loss: 3.744136980985667

Epoch: 5| Step: 1
Training loss: 4.197449209281984
Validation loss: 3.7406210374635975

Epoch: 5| Step: 2
Training loss: 3.213744484278346
Validation loss: 3.7368177313541717

Epoch: 5| Step: 3
Training loss: 4.186994835288482
Validation loss: 3.733831188155052

Epoch: 5| Step: 4
Training loss: 3.4869294660396064
Validation loss: 3.730644203994644

Epoch: 5| Step: 5
Training loss: 4.812636732660865
Validation loss: 3.7286069326985065

Epoch: 5| Step: 6
Training loss: 3.6427916272466883
Validation loss: 3.725750543939951

Epoch: 5| Step: 7
Training loss: 4.444256434172711
Validation loss: 3.719686391492152

Epoch: 5| Step: 8
Training loss: 3.167528001861724
Validation loss: 3.723560239288185

Epoch: 5| Step: 9
Training loss: 3.451179474162191
Validation loss: 3.7197147840299727

Epoch: 5| Step: 10
Training loss: 3.8094007057780908
Validation loss: 3.712914186533131

Epoch: 19| Step: 0
Training loss: 3.632557062172117
Validation loss: 3.709239393218105

Epoch: 5| Step: 1
Training loss: 3.8395504223383643
Validation loss: 3.706397263355405

Epoch: 5| Step: 2
Training loss: 3.5603651375982355
Validation loss: 3.7105112007325443

Epoch: 5| Step: 3
Training loss: 4.073046097646061
Validation loss: 3.7144822873576624

Epoch: 5| Step: 4
Training loss: 3.6444659620776645
Validation loss: 3.703231053330595

Epoch: 5| Step: 5
Training loss: 4.2164508347188825
Validation loss: 3.699577066693644

Epoch: 5| Step: 6
Training loss: 3.7863898535635427
Validation loss: 3.6948777066380813

Epoch: 5| Step: 7
Training loss: 4.131100622757412
Validation loss: 3.690679249943009

Epoch: 5| Step: 8
Training loss: 3.8520916000835923
Validation loss: 3.688056589553586

Epoch: 5| Step: 9
Training loss: 3.8839158883224383
Validation loss: 3.685606105659835

Epoch: 5| Step: 10
Training loss: 4.031856993879098
Validation loss: 3.6838122978011727

Epoch: 20| Step: 0
Training loss: 3.8204590314913354
Validation loss: 3.6808341881219935

Epoch: 5| Step: 1
Training loss: 3.865510950896275
Validation loss: 3.6787773333721225

Epoch: 5| Step: 2
Training loss: 3.8078380911009795
Validation loss: 3.675926303711682

Epoch: 5| Step: 3
Training loss: 4.87978753956301
Validation loss: 3.6735550275952273

Epoch: 5| Step: 4
Training loss: 3.971692653885276
Validation loss: 3.6710296069593267

Epoch: 5| Step: 5
Training loss: 3.513144469954582
Validation loss: 3.667195099333405

Epoch: 5| Step: 6
Training loss: 3.4058549284400095
Validation loss: 3.664875708077378

Epoch: 5| Step: 7
Training loss: 3.401620641306982
Validation loss: 3.6634065187033995

Epoch: 5| Step: 8
Training loss: 3.494106098514088
Validation loss: 3.659115730085608

Epoch: 5| Step: 9
Training loss: 4.730180651257442
Validation loss: 3.6584877813695504

Epoch: 5| Step: 10
Training loss: 3.0140371935599264
Validation loss: 3.65777644794485

Epoch: 21| Step: 0
Training loss: 3.5373690092279446
Validation loss: 3.654293363081941

Epoch: 5| Step: 1
Training loss: 4.836154618573622
Validation loss: 3.6548070550308096

Epoch: 5| Step: 2
Training loss: 4.109998996483896
Validation loss: 3.649086134286109

Epoch: 5| Step: 3
Training loss: 2.582736151386634
Validation loss: 3.6468633918799953

Epoch: 5| Step: 4
Training loss: 3.472705956565658
Validation loss: 3.6423831619968534

Epoch: 5| Step: 5
Training loss: 3.1455964931907006
Validation loss: 3.642875200264021

Epoch: 5| Step: 6
Training loss: 3.9226542758689766
Validation loss: 3.640537723384318

Epoch: 5| Step: 7
Training loss: 3.4864880095078337
Validation loss: 3.6397218625748047

Epoch: 5| Step: 8
Training loss: 4.082765007691751
Validation loss: 3.638796993175405

Epoch: 5| Step: 9
Training loss: 4.576588447682182
Validation loss: 3.6361108896229988

Epoch: 5| Step: 10
Training loss: 3.9130058765908307
Validation loss: 3.63413231046369

Epoch: 22| Step: 0
Training loss: 4.806088027903568
Validation loss: 3.6333932677653626

Epoch: 5| Step: 1
Training loss: 4.249994390147378
Validation loss: 3.6271509925250416

Epoch: 5| Step: 2
Training loss: 3.7923499249793933
Validation loss: 3.6267611886151947

Epoch: 5| Step: 3
Training loss: 3.426639114546189
Validation loss: 3.6225850905470374

Epoch: 5| Step: 4
Training loss: 3.969493646111372
Validation loss: 3.623956586000258

Epoch: 5| Step: 5
Training loss: 4.344260645428624
Validation loss: 3.619157122577879

Epoch: 5| Step: 6
Training loss: 2.6992616774241154
Validation loss: 3.6172349058011015

Epoch: 5| Step: 7
Training loss: 2.8856341191693646
Validation loss: 3.6127692605560258

Epoch: 5| Step: 8
Training loss: 3.9077401942687184
Validation loss: 3.612042169676277

Epoch: 5| Step: 9
Training loss: 3.395187191641159
Validation loss: 3.615702659894686

Epoch: 5| Step: 10
Training loss: 4.025272165894063
Validation loss: 3.6190816439502496

Epoch: 23| Step: 0
Training loss: 4.32195428760367
Validation loss: 3.6111522415591173

Epoch: 5| Step: 1
Training loss: 3.8732256364759707
Validation loss: 3.603997701657754

Epoch: 5| Step: 2
Training loss: 3.6955953413161744
Validation loss: 3.603546278863995

Epoch: 5| Step: 3
Training loss: 3.744039885389993
Validation loss: 3.601146882311469

Epoch: 5| Step: 4
Training loss: 3.5225760005118874
Validation loss: 3.598283855541859

Epoch: 5| Step: 5
Training loss: 3.213450838080042
Validation loss: 3.597851189809064

Epoch: 5| Step: 6
Training loss: 4.814406574635503
Validation loss: 3.594583063288221

Epoch: 5| Step: 7
Training loss: 3.642239715974308
Validation loss: 3.5963349877767494

Epoch: 5| Step: 8
Training loss: 3.159780057906446
Validation loss: 3.5937527378779857

Epoch: 5| Step: 9
Training loss: 3.2889763827614065
Validation loss: 3.5906172356973665

Epoch: 5| Step: 10
Training loss: 4.226554151375188
Validation loss: 3.596917544233836

Epoch: 24| Step: 0
Training loss: 3.304204810853569
Validation loss: 3.5930559698203033

Epoch: 5| Step: 1
Training loss: 3.751785234848244
Validation loss: 3.5845873203672056

Epoch: 5| Step: 2
Training loss: 4.051845017251184
Validation loss: 3.581485801905055

Epoch: 5| Step: 3
Training loss: 3.666551212458255
Validation loss: 3.5794876197305303

Epoch: 5| Step: 4
Training loss: 3.8007013326242847
Validation loss: 3.5786450005463477

Epoch: 5| Step: 5
Training loss: 3.1836642953744496
Validation loss: 3.5771084427020217

Epoch: 5| Step: 6
Training loss: 3.917633802980801
Validation loss: 3.577030168966819

Epoch: 5| Step: 7
Training loss: 4.124085296015178
Validation loss: 3.571993421019564

Epoch: 5| Step: 8
Training loss: 4.084449745200611
Validation loss: 3.5775220862490427

Epoch: 5| Step: 9
Training loss: 3.923674030230826
Validation loss: 3.5729064357676505

Epoch: 5| Step: 10
Training loss: 3.5910047577646127
Validation loss: 3.5725371997183895

Epoch: 25| Step: 0
Training loss: 4.608180004326058
Validation loss: 3.571519383595831

Epoch: 5| Step: 1
Training loss: 3.887450857557157
Validation loss: 3.575217066694157

Epoch: 5| Step: 2
Training loss: 2.833871977224938
Validation loss: 3.5693189539513095

Epoch: 5| Step: 3
Training loss: 3.613936543197298
Validation loss: 3.5741577882015476

Epoch: 5| Step: 4
Training loss: 2.784026913447024
Validation loss: 3.5623076652703407

Epoch: 5| Step: 5
Training loss: 3.963397644607746
Validation loss: 3.56275293617723

Epoch: 5| Step: 6
Training loss: 4.76975878923355
Validation loss: 3.567217413738799

Epoch: 5| Step: 7
Training loss: 3.263802489812287
Validation loss: 3.561445996001281

Epoch: 5| Step: 8
Training loss: 3.289191236717503
Validation loss: 3.5584718317664126

Epoch: 5| Step: 9
Training loss: 4.1223121902870785
Validation loss: 3.5582339973490993

Epoch: 5| Step: 10
Training loss: 3.765884073929569
Validation loss: 3.556185128461765

Epoch: 26| Step: 0
Training loss: 3.492767900201113
Validation loss: 3.555736022090017

Epoch: 5| Step: 1
Training loss: 4.069761623365736
Validation loss: 3.5540534653803624

Epoch: 5| Step: 2
Training loss: 4.045992368380731
Validation loss: 3.5619897136924905

Epoch: 5| Step: 3
Training loss: 3.2860364607902737
Validation loss: 3.5527814083475335

Epoch: 5| Step: 4
Training loss: 4.159703934844585
Validation loss: 3.5475161075429424

Epoch: 5| Step: 5
Training loss: 4.449371790744777
Validation loss: 3.5496463303669064

Epoch: 5| Step: 6
Training loss: 3.6702043344434356
Validation loss: 3.546361074564594

Epoch: 5| Step: 7
Training loss: 3.207223493828841
Validation loss: 3.545813079109434

Epoch: 5| Step: 8
Training loss: 3.7826584643988905
Validation loss: 3.544558196087087

Epoch: 5| Step: 9
Training loss: 3.4273959000886993
Validation loss: 3.5451439587034885

Epoch: 5| Step: 10
Training loss: 3.4414807938329814
Validation loss: 3.549490980866065

Epoch: 27| Step: 0
Training loss: 4.278443021914919
Validation loss: 3.5483068514445275

Epoch: 5| Step: 1
Training loss: 2.9665012877869943
Validation loss: 3.548235077878397

Epoch: 5| Step: 2
Training loss: 4.650034807956813
Validation loss: 3.539885307596735

Epoch: 5| Step: 3
Training loss: 3.5614348040451835
Validation loss: 3.5362196138002706

Epoch: 5| Step: 4
Training loss: 3.5128017363813084
Validation loss: 3.533964633344821

Epoch: 5| Step: 5
Training loss: 4.178159858826395
Validation loss: 3.5344488704925965

Epoch: 5| Step: 6
Training loss: 2.695603506991846
Validation loss: 3.53518016360429

Epoch: 5| Step: 7
Training loss: 4.280111119619333
Validation loss: 3.5325126920467897

Epoch: 5| Step: 8
Training loss: 2.8706730333226047
Validation loss: 3.5331286907623194

Epoch: 5| Step: 9
Training loss: 3.661626139992272
Validation loss: 3.530131422857692

Epoch: 5| Step: 10
Training loss: 4.020567231275464
Validation loss: 3.5282425520304685

Epoch: 28| Step: 0
Training loss: 3.374724341543868
Validation loss: 3.5290353625485364

Epoch: 5| Step: 1
Training loss: 3.966775598285812
Validation loss: 3.5309754864879226

Epoch: 5| Step: 2
Training loss: 4.434765040077474
Validation loss: 3.528554988757713

Epoch: 5| Step: 3
Training loss: 3.5525139839385718
Validation loss: 3.530500500331948

Epoch: 5| Step: 4
Training loss: 3.2229465423231662
Validation loss: 3.5330694551273716

Epoch: 5| Step: 5
Training loss: 3.9208165902494088
Validation loss: 3.5371198234721555

Epoch: 5| Step: 6
Training loss: 3.889347464151206
Validation loss: 3.529334594700056

Epoch: 5| Step: 7
Training loss: 3.467140442922979
Validation loss: 3.520271521972475

Epoch: 5| Step: 8
Training loss: 4.035175157264513
Validation loss: 3.524463642838971

Epoch: 5| Step: 9
Training loss: 3.271568183394788
Validation loss: 3.526189356417787

Epoch: 5| Step: 10
Training loss: 3.787365846177975
Validation loss: 3.5225918106474747

Epoch: 29| Step: 0
Training loss: 3.4763279524989
Validation loss: 3.5237086647644342

Epoch: 5| Step: 1
Training loss: 3.097233362182594
Validation loss: 3.522168638714765

Epoch: 5| Step: 2
Training loss: 3.233483970384105
Validation loss: 3.5199162239651707

Epoch: 5| Step: 3
Training loss: 3.813855164864929
Validation loss: 3.5190840179498744

Epoch: 5| Step: 4
Training loss: 4.033788547101175
Validation loss: 3.5182618834724213

Epoch: 5| Step: 5
Training loss: 3.552522037445804
Validation loss: 3.5163167905900647

Epoch: 5| Step: 6
Training loss: 3.784633919310855
Validation loss: 3.516173465655356

Epoch: 5| Step: 7
Training loss: 4.394860664736844
Validation loss: 3.5176169527843006

Epoch: 5| Step: 8
Training loss: 4.029694012935799
Validation loss: 3.5163042855613695

Epoch: 5| Step: 9
Training loss: 3.874454952177485
Validation loss: 3.5157797298312725

Epoch: 5| Step: 10
Training loss: 3.489699601850742
Validation loss: 3.5179053214514164

Epoch: 30| Step: 0
Training loss: 3.8480782059635206
Validation loss: 3.512180909764008

Epoch: 5| Step: 1
Training loss: 3.7405442868912573
Validation loss: 3.509518802319715

Epoch: 5| Step: 2
Training loss: 3.099853044533737
Validation loss: 3.508399694797856

Epoch: 5| Step: 3
Training loss: 4.182733584469307
Validation loss: 3.5070869899032164

Epoch: 5| Step: 4
Training loss: 3.4971260805644766
Validation loss: 3.5075619497529353

Epoch: 5| Step: 5
Training loss: 3.2209078768205024
Validation loss: 3.5059985763405304

Epoch: 5| Step: 6
Training loss: 3.583116938836282
Validation loss: 3.5089583974592533

Epoch: 5| Step: 7
Training loss: 3.4002069185908965
Validation loss: 3.5025930760461867

Epoch: 5| Step: 8
Training loss: 3.9312066541262225
Validation loss: 3.5039658220771375

Epoch: 5| Step: 9
Training loss: 4.4488862862094
Validation loss: 3.504233859749495

Epoch: 5| Step: 10
Training loss: 3.7320523880105796
Validation loss: 3.504272456433737

Epoch: 31| Step: 0
Training loss: 3.3863643474007885
Validation loss: 3.501705696004142

Epoch: 5| Step: 1
Training loss: 4.156308510734179
Validation loss: 3.5039379977074327

Epoch: 5| Step: 2
Training loss: 4.236611989466582
Validation loss: 3.505680367608904

Epoch: 5| Step: 3
Training loss: 3.1489053004766006
Validation loss: 3.505599039341748

Epoch: 5| Step: 4
Training loss: 3.2322131317134395
Validation loss: 3.5073368475286855

Epoch: 5| Step: 5
Training loss: 3.9239631352379627
Validation loss: 3.5012302573066902

Epoch: 5| Step: 6
Training loss: 2.881319646758984
Validation loss: 3.5024248182084756

Epoch: 5| Step: 7
Training loss: 3.600427543895354
Validation loss: 3.503024467444053

Epoch: 5| Step: 8
Training loss: 4.162276180080747
Validation loss: 3.50076014530796

Epoch: 5| Step: 9
Training loss: 4.290663790267002
Validation loss: 3.4991562085496675

Epoch: 5| Step: 10
Training loss: 3.492885033498636
Validation loss: 3.498036243859567

Epoch: 32| Step: 0
Training loss: 4.000906364750612
Validation loss: 3.4989776202152703

Epoch: 5| Step: 1
Training loss: 3.9054507238922485
Validation loss: 3.4941271675029686

Epoch: 5| Step: 2
Training loss: 2.8480671401735815
Validation loss: 3.4960553812724187

Epoch: 5| Step: 3
Training loss: 2.0591601292953965
Validation loss: 3.493670330232196

Epoch: 5| Step: 4
Training loss: 4.081359515977149
Validation loss: 3.493187161260076

Epoch: 5| Step: 5
Training loss: 3.519972084541602
Validation loss: 3.4922730510926967

Epoch: 5| Step: 6
Training loss: 4.6555121944555795
Validation loss: 3.4933317932785246

Epoch: 5| Step: 7
Training loss: 4.107902930400827
Validation loss: 3.4912983783649

Epoch: 5| Step: 8
Training loss: 4.033676008899994
Validation loss: 3.4883013076370006

Epoch: 5| Step: 9
Training loss: 3.0815339551469547
Validation loss: 3.4873464855700784

Epoch: 5| Step: 10
Training loss: 3.774041737578866
Validation loss: 3.4867491294671122

Epoch: 33| Step: 0
Training loss: 3.845123913855421
Validation loss: 3.4871942537327834

Epoch: 5| Step: 1
Training loss: 4.324109800597917
Validation loss: 3.4874301669501833

Epoch: 5| Step: 2
Training loss: 3.661468433494619
Validation loss: 3.4856663154207945

Epoch: 5| Step: 3
Training loss: 3.793688029202591
Validation loss: 3.486930560773625

Epoch: 5| Step: 4
Training loss: 3.2980652599551967
Validation loss: 3.483794205276427

Epoch: 5| Step: 5
Training loss: 4.30000108230932
Validation loss: 3.482769685766937

Epoch: 5| Step: 6
Training loss: 2.9721802820433494
Validation loss: 3.482238320417581

Epoch: 5| Step: 7
Training loss: 4.1758045449245
Validation loss: 3.481015042597617

Epoch: 5| Step: 8
Training loss: 4.053211097714591
Validation loss: 3.4808544309251586

Epoch: 5| Step: 9
Training loss: 3.3102060688331245
Validation loss: 3.478873017147904

Epoch: 5| Step: 10
Training loss: 2.2122150948920214
Validation loss: 3.4802984855699908

Epoch: 34| Step: 0
Training loss: 3.6952745625199794
Validation loss: 3.4788643996299395

Epoch: 5| Step: 1
Training loss: 3.0645492859554087
Validation loss: 3.4775677261792843

Epoch: 5| Step: 2
Training loss: 3.832138386666508
Validation loss: 3.4806063270035184

Epoch: 5| Step: 3
Training loss: 4.00712285047743
Validation loss: 3.4779615716682706

Epoch: 5| Step: 4
Training loss: 3.646693333511437
Validation loss: 3.475760023306956

Epoch: 5| Step: 5
Training loss: 3.3928548626425976
Validation loss: 3.474856379921341

Epoch: 5| Step: 6
Training loss: 3.6456382190628833
Validation loss: 3.475176447651836

Epoch: 5| Step: 7
Training loss: 3.280605434505457
Validation loss: 3.473145480119118

Epoch: 5| Step: 8
Training loss: 4.197261762373165
Validation loss: 3.4733095025150487

Epoch: 5| Step: 9
Training loss: 3.8544706619933535
Validation loss: 3.470546858245444

Epoch: 5| Step: 10
Training loss: 3.8853419946989844
Validation loss: 3.4713084415711646

Epoch: 35| Step: 0
Training loss: 4.03854042087969
Validation loss: 3.471042074219998

Epoch: 5| Step: 1
Training loss: 3.293474948118889
Validation loss: 3.472587206509071

Epoch: 5| Step: 2
Training loss: 4.584858704098508
Validation loss: 3.473143872466738

Epoch: 5| Step: 3
Training loss: 3.334708422907182
Validation loss: 3.470383350918407

Epoch: 5| Step: 4
Training loss: 3.864045070511704
Validation loss: 3.4689199961570107

Epoch: 5| Step: 5
Training loss: 2.90192214142078
Validation loss: 3.4674408140174404

Epoch: 5| Step: 6
Training loss: 3.3500626059987786
Validation loss: 3.4697339023230893

Epoch: 5| Step: 7
Training loss: 4.0395323371258645
Validation loss: 3.468484703028447

Epoch: 5| Step: 8
Training loss: 3.4498119081832943
Validation loss: 3.470795322276007

Epoch: 5| Step: 9
Training loss: 3.833511237839865
Validation loss: 3.4686330657142777

Epoch: 5| Step: 10
Training loss: 3.5750384615449775
Validation loss: 3.4661811703603154

Epoch: 36| Step: 0
Training loss: 3.2693921131349035
Validation loss: 3.464719866195658

Epoch: 5| Step: 1
Training loss: 3.7854696642045993
Validation loss: 3.4679041818570466

Epoch: 5| Step: 2
Training loss: 4.225106882402457
Validation loss: 3.4616854646528523

Epoch: 5| Step: 3
Training loss: 4.38958901777776
Validation loss: 3.461078748045444

Epoch: 5| Step: 4
Training loss: 3.532665677839022
Validation loss: 3.459893247069638

Epoch: 5| Step: 5
Training loss: 3.890306084365819
Validation loss: 3.4614295373601265

Epoch: 5| Step: 6
Training loss: 3.603595284095818
Validation loss: 3.4577441276357663

Epoch: 5| Step: 7
Training loss: 3.649436928154551
Validation loss: 3.465615305151024

Epoch: 5| Step: 8
Training loss: 3.630136336821742
Validation loss: 3.457815165321496

Epoch: 5| Step: 9
Training loss: 3.115576306175872
Validation loss: 3.462436254564705

Epoch: 5| Step: 10
Training loss: 3.0961975280479814
Validation loss: 3.4628853302408444

Epoch: 37| Step: 0
Training loss: 3.581146430470238
Validation loss: 3.4597566988837385

Epoch: 5| Step: 1
Training loss: 4.006190754516348
Validation loss: 3.459642473589284

Epoch: 5| Step: 2
Training loss: 4.04027900601074
Validation loss: 3.457719112034629

Epoch: 5| Step: 3
Training loss: 3.5683148761849797
Validation loss: 3.4579056155196586

Epoch: 5| Step: 4
Training loss: 2.8939857535179647
Validation loss: 3.4590904310511252

Epoch: 5| Step: 5
Training loss: 3.5274512189037575
Validation loss: 3.4590671357295957

Epoch: 5| Step: 6
Training loss: 3.3806283432218804
Validation loss: 3.4606290008613594

Epoch: 5| Step: 7
Training loss: 3.746987340673111
Validation loss: 3.4609463740046413

Epoch: 5| Step: 8
Training loss: 3.907960807002468
Validation loss: 3.45708724423188

Epoch: 5| Step: 9
Training loss: 3.6899885412105466
Validation loss: 3.455200735533174

Epoch: 5| Step: 10
Training loss: 4.015227658098891
Validation loss: 3.453558530864263

Epoch: 38| Step: 0
Training loss: 3.317996377383066
Validation loss: 3.453272537823586

Epoch: 5| Step: 1
Training loss: 3.8237402892324566
Validation loss: 3.451768038236908

Epoch: 5| Step: 2
Training loss: 4.7295584271313755
Validation loss: 3.451905722345206

Epoch: 5| Step: 3
Training loss: 3.6021615479719933
Validation loss: 3.4502757978898217

Epoch: 5| Step: 4
Training loss: 3.866573523901345
Validation loss: 3.451038939696051

Epoch: 5| Step: 5
Training loss: 4.28753001032967
Validation loss: 3.449645427872025

Epoch: 5| Step: 6
Training loss: 3.633144568576477
Validation loss: 3.4482927797890475

Epoch: 5| Step: 7
Training loss: 3.075739987043038
Validation loss: 3.450177555232362

Epoch: 5| Step: 8
Training loss: 3.400495795957583
Validation loss: 3.447883175784322

Epoch: 5| Step: 9
Training loss: 3.1594486458153477
Validation loss: 3.4461422552765955

Epoch: 5| Step: 10
Training loss: 3.0298496433130118
Validation loss: 3.4455578224433303

Epoch: 39| Step: 0
Training loss: 3.0049427957532755
Validation loss: 3.4457016576911785

Epoch: 5| Step: 1
Training loss: 3.282451300742792
Validation loss: 3.4458188731744763

Epoch: 5| Step: 2
Training loss: 3.6544393637038612
Validation loss: 3.4463677318395995

Epoch: 5| Step: 3
Training loss: 3.8704669648980583
Validation loss: 3.4439476348788935

Epoch: 5| Step: 4
Training loss: 4.341475295951979
Validation loss: 3.444913211726301

Epoch: 5| Step: 5
Training loss: 3.9878955322020206
Validation loss: 3.443592155356873

Epoch: 5| Step: 6
Training loss: 3.470317589465398
Validation loss: 3.443264358390826

Epoch: 5| Step: 7
Training loss: 3.7063859834217845
Validation loss: 3.443311071867613

Epoch: 5| Step: 8
Training loss: 3.840351369994617
Validation loss: 3.442540870051127

Epoch: 5| Step: 9
Training loss: 3.46735237076847
Validation loss: 3.443115099142454

Epoch: 5| Step: 10
Training loss: 3.5104058753205254
Validation loss: 3.4417700772664306

Epoch: 40| Step: 0
Training loss: 3.095248851477969
Validation loss: 3.4424628266910493

Epoch: 5| Step: 1
Training loss: 4.011089925689497
Validation loss: 3.440167233713085

Epoch: 5| Step: 2
Training loss: 3.3545264451944314
Validation loss: 3.442526755086031

Epoch: 5| Step: 3
Training loss: 3.419685255369063
Validation loss: 3.442625313627972

Epoch: 5| Step: 4
Training loss: 3.4765068135462913
Validation loss: 3.442239696535981

Epoch: 5| Step: 5
Training loss: 3.683560610932588
Validation loss: 3.4410547761378245

Epoch: 5| Step: 6
Training loss: 3.514857500858715
Validation loss: 3.44002340106345

Epoch: 5| Step: 7
Training loss: 3.786227772377638
Validation loss: 3.439432865977663

Epoch: 5| Step: 8
Training loss: 4.5890827992879695
Validation loss: 3.437953731837129

Epoch: 5| Step: 9
Training loss: 3.5373167064614846
Validation loss: 3.4384210130190165

Epoch: 5| Step: 10
Training loss: 3.597760425761665
Validation loss: 3.4373954600437933

Epoch: 41| Step: 0
Training loss: 3.9024297725753905
Validation loss: 3.4374574884226554

Epoch: 5| Step: 1
Training loss: 4.356854766505409
Validation loss: 3.4374598630349937

Epoch: 5| Step: 2
Training loss: 3.6678820387530893
Validation loss: 3.436975980998548

Epoch: 5| Step: 3
Training loss: 4.123310552321844
Validation loss: 3.4364730956741223

Epoch: 5| Step: 4
Training loss: 3.689370149857714
Validation loss: 3.4370211016895977

Epoch: 5| Step: 5
Training loss: 3.684018965093483
Validation loss: 3.435410475487298

Epoch: 5| Step: 6
Training loss: 2.7182584296251657
Validation loss: 3.4364887304999217

Epoch: 5| Step: 7
Training loss: 3.674393070473045
Validation loss: 3.4364066263552284

Epoch: 5| Step: 8
Training loss: 3.0550641464266732
Validation loss: 3.437678858782738

Epoch: 5| Step: 9
Training loss: 3.1141523150149997
Validation loss: 3.4353795183285962

Epoch: 5| Step: 10
Training loss: 4.013007710027145
Validation loss: 3.4347693806033686

Epoch: 42| Step: 0
Training loss: 3.35033431591257
Validation loss: 3.4353903836633943

Epoch: 5| Step: 1
Training loss: 3.6549380304220733
Validation loss: 3.434114966069948

Epoch: 5| Step: 2
Training loss: 3.3127327603309067
Validation loss: 3.4348329342095627

Epoch: 5| Step: 3
Training loss: 3.448444214690308
Validation loss: 3.4340523174147095

Epoch: 5| Step: 4
Training loss: 3.7095363822867125
Validation loss: 3.432499110415912

Epoch: 5| Step: 5
Training loss: 3.745341395464384
Validation loss: 3.431442693277924

Epoch: 5| Step: 6
Training loss: 3.676098411571047
Validation loss: 3.4321539122940816

Epoch: 5| Step: 7
Training loss: 3.896074025815761
Validation loss: 3.430807483497631

Epoch: 5| Step: 8
Training loss: 3.6352121610787296
Validation loss: 3.431987289538173

Epoch: 5| Step: 9
Training loss: 3.6907764684747004
Validation loss: 3.431066452572181

Epoch: 5| Step: 10
Training loss: 4.10455689616343
Validation loss: 3.4308534400169406

Epoch: 43| Step: 0
Training loss: 3.400280402345547
Validation loss: 3.430259599878632

Epoch: 5| Step: 1
Training loss: 3.4720086265140373
Validation loss: 3.430733677692311

Epoch: 5| Step: 2
Training loss: 3.37455195525905
Validation loss: 3.429062478150315

Epoch: 5| Step: 3
Training loss: 3.3792873983456446
Validation loss: 3.4280154150130686

Epoch: 5| Step: 4
Training loss: 3.288062009166349
Validation loss: 3.4275449986745357

Epoch: 5| Step: 5
Training loss: 4.09006036951705
Validation loss: 3.4273288949396976

Epoch: 5| Step: 6
Training loss: 3.8622383893251024
Validation loss: 3.4275207200524354

Epoch: 5| Step: 7
Training loss: 3.7934132560082845
Validation loss: 3.427232449506542

Epoch: 5| Step: 8
Training loss: 4.009227123789191
Validation loss: 3.4276345603210587

Epoch: 5| Step: 9
Training loss: 4.058749301488573
Validation loss: 3.431010549245822

Epoch: 5| Step: 10
Training loss: 3.2490762718314605
Validation loss: 3.4281184043487674

Epoch: 44| Step: 0
Training loss: 4.067898962786016
Validation loss: 3.42840074091359

Epoch: 5| Step: 1
Training loss: 3.7401883513405334
Validation loss: 3.425369900090557

Epoch: 5| Step: 2
Training loss: 4.063103264253362
Validation loss: 3.425250492407505

Epoch: 5| Step: 3
Training loss: 3.054847654549222
Validation loss: 3.4250205957104702

Epoch: 5| Step: 4
Training loss: 3.391429331080753
Validation loss: 3.4251991047033092

Epoch: 5| Step: 5
Training loss: 3.443380008490718
Validation loss: 3.424072222480527

Epoch: 5| Step: 6
Training loss: 3.526921277605341
Validation loss: 3.424836906476342

Epoch: 5| Step: 7
Training loss: 3.6267298813060243
Validation loss: 3.4227109719417497

Epoch: 5| Step: 8
Training loss: 2.7052868263354517
Validation loss: 3.424058203586531

Epoch: 5| Step: 9
Training loss: 4.158749624653034
Validation loss: 3.4236794890438556

Epoch: 5| Step: 10
Training loss: 4.141894566938866
Validation loss: 3.4225586883240604

Epoch: 45| Step: 0
Training loss: 3.4565746630861685
Validation loss: 3.4221792901925125

Epoch: 5| Step: 1
Training loss: 3.6884981517851756
Validation loss: 3.4220379812928647

Epoch: 5| Step: 2
Training loss: 3.08857957753442
Validation loss: 3.421162693207334

Epoch: 5| Step: 3
Training loss: 3.4327929086868414
Validation loss: 3.420028855294953

Epoch: 5| Step: 4
Training loss: 3.640754926597899
Validation loss: 3.420029743566335

Epoch: 5| Step: 5
Training loss: 3.482563317593431
Validation loss: 3.419861374162218

Epoch: 5| Step: 6
Training loss: 4.127156705298791
Validation loss: 3.4193657364384293

Epoch: 5| Step: 7
Training loss: 3.1024929543906232
Validation loss: 3.4191600026619

Epoch: 5| Step: 8
Training loss: 3.9473156366667252
Validation loss: 3.4194579639041325

Epoch: 5| Step: 9
Training loss: 4.643199887043421
Validation loss: 3.4173607430132087

Epoch: 5| Step: 10
Training loss: 3.0981394137196703
Validation loss: 3.4172874014869765

Epoch: 46| Step: 0
Training loss: 3.6481307429676426
Validation loss: 3.418039315287801

Epoch: 5| Step: 1
Training loss: 3.580281769516654
Validation loss: 3.418425765697236

Epoch: 5| Step: 2
Training loss: 3.576045202306653
Validation loss: 3.418595333672221

Epoch: 5| Step: 3
Training loss: 3.7973499393510797
Validation loss: 3.4189327632590802

Epoch: 5| Step: 4
Training loss: 4.000645585414641
Validation loss: 3.416845605597964

Epoch: 5| Step: 5
Training loss: 3.361917642414073
Validation loss: 3.414971444048643

Epoch: 5| Step: 6
Training loss: 3.7133076055880774
Validation loss: 3.4145500661140664

Epoch: 5| Step: 7
Training loss: 3.395613977255327
Validation loss: 3.4148622355530858

Epoch: 5| Step: 8
Training loss: 3.8249558390143745
Validation loss: 3.4143576834771583

Epoch: 5| Step: 9
Training loss: 3.581416985311912
Validation loss: 3.413965532605911

Epoch: 5| Step: 10
Training loss: 3.5323611511457917
Validation loss: 3.4134798777474717

Epoch: 47| Step: 0
Training loss: 4.110152370477878
Validation loss: 3.4137627220874243

Epoch: 5| Step: 1
Training loss: 3.5599873030361104
Validation loss: 3.413789943216374

Epoch: 5| Step: 2
Training loss: 3.6835536206224795
Validation loss: 3.4133929624399424

Epoch: 5| Step: 3
Training loss: 3.4637332413927746
Validation loss: 3.4125142985414025

Epoch: 5| Step: 4
Training loss: 3.2824945905049616
Validation loss: 3.4126431244279796

Epoch: 5| Step: 5
Training loss: 3.2224801680115176
Validation loss: 3.4135701418702813

Epoch: 5| Step: 6
Training loss: 3.5869181835754302
Validation loss: 3.4117208302661757

Epoch: 5| Step: 7
Training loss: 3.7692903906210415
Validation loss: 3.413608174534157

Epoch: 5| Step: 8
Training loss: 3.3650014202233955
Validation loss: 3.411489652846696

Epoch: 5| Step: 9
Training loss: 4.030234985316022
Validation loss: 3.4126236527890117

Epoch: 5| Step: 10
Training loss: 3.88603656858789
Validation loss: 3.411408802466026

Epoch: 48| Step: 0
Training loss: 4.026885989912905
Validation loss: 3.4112778272157267

Epoch: 5| Step: 1
Training loss: 3.4187546529511583
Validation loss: 3.409747738263029

Epoch: 5| Step: 2
Training loss: 3.4364131249611525
Validation loss: 3.4096935124450716

Epoch: 5| Step: 3
Training loss: 3.0942439445984347
Validation loss: 3.409104402775813

Epoch: 5| Step: 4
Training loss: 3.8654359492190076
Validation loss: 3.409164165059025

Epoch: 5| Step: 5
Training loss: 3.4332105750448947
Validation loss: 3.4078630697973176

Epoch: 5| Step: 6
Training loss: 3.8426251510064655
Validation loss: 3.4071269837346887

Epoch: 5| Step: 7
Training loss: 3.3918108997716208
Validation loss: 3.407440584093403

Epoch: 5| Step: 8
Training loss: 3.967230318130613
Validation loss: 3.407957147659599

Epoch: 5| Step: 9
Training loss: 3.918893965368826
Validation loss: 3.4065830308374685

Epoch: 5| Step: 10
Training loss: 3.4484402046832536
Validation loss: 3.406406293257894

Epoch: 49| Step: 0
Training loss: 4.137024433199382
Validation loss: 3.406414333961752

Epoch: 5| Step: 1
Training loss: 3.6225051186935455
Validation loss: 3.4055279759311934

Epoch: 5| Step: 2
Training loss: 4.208194894055814
Validation loss: 3.404469708481542

Epoch: 5| Step: 3
Training loss: 3.6025639463595733
Validation loss: 3.4038926549525517

Epoch: 5| Step: 4
Training loss: 3.7253847320340436
Validation loss: 3.404887471511217

Epoch: 5| Step: 5
Training loss: 2.606528002505294
Validation loss: 3.4045690517203377

Epoch: 5| Step: 6
Training loss: 3.6208037720158677
Validation loss: 3.4040974166328515

Epoch: 5| Step: 7
Training loss: 3.5004856590104736
Validation loss: 3.403393790799701

Epoch: 5| Step: 8
Training loss: 3.5032957091581154
Validation loss: 3.4041573654720296

Epoch: 5| Step: 9
Training loss: 3.7814151948515904
Validation loss: 3.4033031980187456

Epoch: 5| Step: 10
Training loss: 3.3827356765868966
Validation loss: 3.4030027849347757

Epoch: 50| Step: 0
Training loss: 3.964183072070971
Validation loss: 3.4028801612499726

Epoch: 5| Step: 1
Training loss: 3.23815652678427
Validation loss: 3.4014980077410644

Epoch: 5| Step: 2
Training loss: 4.019838252822795
Validation loss: 3.402508307284361

Epoch: 5| Step: 3
Training loss: 3.978667356044447
Validation loss: 3.403231265033496

Epoch: 5| Step: 4
Training loss: 3.24359320994805
Validation loss: 3.4015632230365513

Epoch: 5| Step: 5
Training loss: 2.560095705836165
Validation loss: 3.4012662975485832

Epoch: 5| Step: 6
Training loss: 3.7651516312135787
Validation loss: 3.401236393884245

Epoch: 5| Step: 7
Training loss: 3.833471807107264
Validation loss: 3.4007909870496187

Epoch: 5| Step: 8
Training loss: 3.6977739906546363
Validation loss: 3.400644376998138

Epoch: 5| Step: 9
Training loss: 4.016800882674506
Validation loss: 3.400251438487732

Epoch: 5| Step: 10
Training loss: 3.267885001046689
Validation loss: 3.398801613927981

Epoch: 51| Step: 0
Training loss: 4.04110860740657
Validation loss: 3.398936448971734

Epoch: 5| Step: 1
Training loss: 3.5262741545641303
Validation loss: 3.399017814751422

Epoch: 5| Step: 2
Training loss: 3.132714020282339
Validation loss: 3.39979727018202

Epoch: 5| Step: 3
Training loss: 4.0716686369216735
Validation loss: 3.4005421123664035

Epoch: 5| Step: 4
Training loss: 3.745868950583601
Validation loss: 3.397913006780517

Epoch: 5| Step: 5
Training loss: 2.770596620778781
Validation loss: 3.3976406137655575

Epoch: 5| Step: 6
Training loss: 3.2777444187629157
Validation loss: 3.398272276357837

Epoch: 5| Step: 7
Training loss: 4.308341190963063
Validation loss: 3.3972933285745324

Epoch: 5| Step: 8
Training loss: 3.2109318568419085
Validation loss: 3.397264118901206

Epoch: 5| Step: 9
Training loss: 4.245419670720668
Validation loss: 3.398336586439911

Epoch: 5| Step: 10
Training loss: 3.1257115889044718
Validation loss: 3.396343754262568

Epoch: 52| Step: 0
Training loss: 3.939299399346339
Validation loss: 3.3975571792179404

Epoch: 5| Step: 1
Training loss: 3.631226552339314
Validation loss: 3.396076761128676

Epoch: 5| Step: 2
Training loss: 3.219178847104646
Validation loss: 3.3943543622352568

Epoch: 5| Step: 3
Training loss: 3.5114257147100174
Validation loss: 3.3950911062506766

Epoch: 5| Step: 4
Training loss: 3.3340813433284233
Validation loss: 3.395217399268964

Epoch: 5| Step: 5
Training loss: 2.9444212842626225
Validation loss: 3.3954910316175195

Epoch: 5| Step: 6
Training loss: 3.5975052825698084
Validation loss: 3.394464031137216

Epoch: 5| Step: 7
Training loss: 4.310777845533788
Validation loss: 3.3944429130043443

Epoch: 5| Step: 8
Training loss: 3.852276161419419
Validation loss: 3.394571693659332

Epoch: 5| Step: 9
Training loss: 3.791384019202868
Validation loss: 3.3942191684292533

Epoch: 5| Step: 10
Training loss: 3.5449427244135494
Validation loss: 3.394248152794864

Epoch: 53| Step: 0
Training loss: 3.5273110355452766
Validation loss: 3.392674606486923

Epoch: 5| Step: 1
Training loss: 3.476097367278327
Validation loss: 3.3932475523628076

Epoch: 5| Step: 2
Training loss: 3.048891310003498
Validation loss: 3.392617355695007

Epoch: 5| Step: 3
Training loss: 3.5080737588015993
Validation loss: 3.3923796658638556

Epoch: 5| Step: 4
Training loss: 3.730137419841049
Validation loss: 3.391893060783735

Epoch: 5| Step: 5
Training loss: 4.043911235253969
Validation loss: 3.3931187410961217

Epoch: 5| Step: 6
Training loss: 3.0597133803926484
Validation loss: 3.391274815008941

Epoch: 5| Step: 7
Training loss: 3.899803885395195
Validation loss: 3.39092148282773

Epoch: 5| Step: 8
Training loss: 3.483259629803757
Validation loss: 3.3905559056602934

Epoch: 5| Step: 9
Training loss: 4.060807095437731
Validation loss: 3.390670546963943

Epoch: 5| Step: 10
Training loss: 3.8829097620489255
Validation loss: 3.391285978888206

Epoch: 54| Step: 0
Training loss: 4.52452693595039
Validation loss: 3.3900772331989777

Epoch: 5| Step: 1
Training loss: 3.582682143783312
Validation loss: 3.389467494988563

Epoch: 5| Step: 2
Training loss: 3.1384805978294117
Validation loss: 3.390285804068011

Epoch: 5| Step: 3
Training loss: 3.426276037485361
Validation loss: 3.3892509345619097

Epoch: 5| Step: 4
Training loss: 3.2821194904526823
Validation loss: 3.388924685136234

Epoch: 5| Step: 5
Training loss: 3.4934956193554982
Validation loss: 3.388926226834239

Epoch: 5| Step: 6
Training loss: 3.3395322063210684
Validation loss: 3.388990806556881

Epoch: 5| Step: 7
Training loss: 3.9142454793650194
Validation loss: 3.3882741682129875

Epoch: 5| Step: 8
Training loss: 3.003465240607603
Validation loss: 3.3873469198825323

Epoch: 5| Step: 9
Training loss: 3.857077590450745
Validation loss: 3.386936960439595

Epoch: 5| Step: 10
Training loss: 4.051226423148453
Validation loss: 3.385819690780007

Epoch: 55| Step: 0
Training loss: 4.044914566099746
Validation loss: 3.387400852564635

Epoch: 5| Step: 1
Training loss: 3.886030433319652
Validation loss: 3.386949793238523

Epoch: 5| Step: 2
Training loss: 3.8522759138581573
Validation loss: 3.387975310777994

Epoch: 5| Step: 3
Training loss: 3.0839115494191973
Validation loss: 3.3869938425068504

Epoch: 5| Step: 4
Training loss: 3.7356704316512683
Validation loss: 3.3861977987834377

Epoch: 5| Step: 5
Training loss: 3.759223910852647
Validation loss: 3.387117048135486

Epoch: 5| Step: 6
Training loss: 3.753231690579326
Validation loss: 3.3873114925559156

Epoch: 5| Step: 7
Training loss: 3.1813930276970948
Validation loss: 3.384885818599449

Epoch: 5| Step: 8
Training loss: 3.8916135704018004
Validation loss: 3.3849194505937334

Epoch: 5| Step: 9
Training loss: 2.861124639468837
Validation loss: 3.384718697334928

Epoch: 5| Step: 10
Training loss: 3.523300269725732
Validation loss: 3.384720448480635

Epoch: 56| Step: 0
Training loss: 3.4719074072642977
Validation loss: 3.3834688920144798

Epoch: 5| Step: 1
Training loss: 3.73400315225036
Validation loss: 3.3836723378650144

Epoch: 5| Step: 2
Training loss: 3.97273762937481
Validation loss: 3.3831593014750445

Epoch: 5| Step: 3
Training loss: 3.9645627979275266
Validation loss: 3.3827269642151605

Epoch: 5| Step: 4
Training loss: 3.2805686606600215
Validation loss: 3.3827588594500626

Epoch: 5| Step: 5
Training loss: 3.3721418641047634
Validation loss: 3.382980574025358

Epoch: 5| Step: 6
Training loss: 3.967870659919819
Validation loss: 3.382353755645658

Epoch: 5| Step: 7
Training loss: 3.62065785242154
Validation loss: 3.3811622650250293

Epoch: 5| Step: 8
Training loss: 3.0575668150493804
Validation loss: 3.3815758789490697

Epoch: 5| Step: 9
Training loss: 3.6937943096052823
Validation loss: 3.380860435076344

Epoch: 5| Step: 10
Training loss: 3.4834103467784225
Validation loss: 3.3805216623437038

Epoch: 57| Step: 0
Training loss: 3.8771993486831073
Validation loss: 3.381018259901646

Epoch: 5| Step: 1
Training loss: 3.6683063453283546
Validation loss: 3.380947671092487

Epoch: 5| Step: 2
Training loss: 4.349474311722059
Validation loss: 3.3799549086596232

Epoch: 5| Step: 3
Training loss: 3.397058106148656
Validation loss: 3.3799273573861606

Epoch: 5| Step: 4
Training loss: 3.6148817981690478
Validation loss: 3.381813679216202

Epoch: 5| Step: 5
Training loss: 3.527794421566393
Validation loss: 3.382530842001316

Epoch: 5| Step: 6
Training loss: 2.9767622592808465
Validation loss: 3.3805797367869865

Epoch: 5| Step: 7
Training loss: 2.813656209012076
Validation loss: 3.3785482157770486

Epoch: 5| Step: 8
Training loss: 3.792675694499204
Validation loss: 3.3777744704008867

Epoch: 5| Step: 9
Training loss: 3.6129275587027196
Validation loss: 3.3775594115060326

Epoch: 5| Step: 10
Training loss: 3.896643950366486
Validation loss: 3.377669206753751

Epoch: 58| Step: 0
Training loss: 3.472672452770834
Validation loss: 3.3766336000622887

Epoch: 5| Step: 1
Training loss: 3.7062569423565486
Validation loss: 3.376904641791973

Epoch: 5| Step: 2
Training loss: 3.8920852800849075
Validation loss: 3.3766600074876925

Epoch: 5| Step: 3
Training loss: 3.32692729191494
Validation loss: 3.376258032261036

Epoch: 5| Step: 4
Training loss: 3.236783664944623
Validation loss: 3.376381423118157

Epoch: 5| Step: 5
Training loss: 3.9429589833954357
Validation loss: 3.375475867786251

Epoch: 5| Step: 6
Training loss: 3.9889136699401444
Validation loss: 3.37568705867837

Epoch: 5| Step: 7
Training loss: 3.6270164932031634
Validation loss: 3.376460811656567

Epoch: 5| Step: 8
Training loss: 4.234563731812203
Validation loss: 3.3742891510261375

Epoch: 5| Step: 9
Training loss: 2.8543294781286823
Validation loss: 3.3749011628002

Epoch: 5| Step: 10
Training loss: 3.1082375137518903
Validation loss: 3.374742953144703

Epoch: 59| Step: 0
Training loss: 3.8409979667866754
Validation loss: 3.3735884324153145

Epoch: 5| Step: 1
Training loss: 2.969864164386517
Validation loss: 3.372886053404202

Epoch: 5| Step: 2
Training loss: 3.224968098327407
Validation loss: 3.3740058081780573

Epoch: 5| Step: 3
Training loss: 3.095449578043545
Validation loss: 3.3719227524776603

Epoch: 5| Step: 4
Training loss: 3.5645046282666097
Validation loss: 3.3734612673533237

Epoch: 5| Step: 5
Training loss: 4.291855422131265
Validation loss: 3.375743393662099

Epoch: 5| Step: 6
Training loss: 3.275153609306101
Validation loss: 3.3727500370646633

Epoch: 5| Step: 7
Training loss: 3.5450464316099595
Validation loss: 3.3739857062924794

Epoch: 5| Step: 8
Training loss: 4.342572608389048
Validation loss: 3.3743135551004144

Epoch: 5| Step: 9
Training loss: 3.9742444069995724
Validation loss: 3.3721409761431125

Epoch: 5| Step: 10
Training loss: 3.181517877898104
Validation loss: 3.3738650757470934

Epoch: 60| Step: 0
Training loss: 3.411314812279002
Validation loss: 3.3743645507721705

Epoch: 5| Step: 1
Training loss: 3.84739177588829
Validation loss: 3.375839938611025

Epoch: 5| Step: 2
Training loss: 2.7944350015149126
Validation loss: 3.376767870208362

Epoch: 5| Step: 3
Training loss: 3.1394818251378833
Validation loss: 3.3723551703506343

Epoch: 5| Step: 4
Training loss: 3.4952862195871655
Validation loss: 3.3723481096710954

Epoch: 5| Step: 5
Training loss: 4.415965738398563
Validation loss: 3.372277284642429

Epoch: 5| Step: 6
Training loss: 4.395735512077435
Validation loss: 3.372599571130865

Epoch: 5| Step: 7
Training loss: 3.321954155281201
Validation loss: 3.371655534772896

Epoch: 5| Step: 8
Training loss: 3.702558643152252
Validation loss: 3.3722463971479417

Epoch: 5| Step: 9
Training loss: 3.438480445450094
Validation loss: 3.375224087414939

Epoch: 5| Step: 10
Training loss: 3.351524655143997
Validation loss: 3.3739639417784586

Epoch: 61| Step: 0
Training loss: 3.1312585339458465
Validation loss: 3.372902522632273

Epoch: 5| Step: 1
Training loss: 2.85478367134546
Validation loss: 3.3712884007404167

Epoch: 5| Step: 2
Training loss: 3.994707659551362
Validation loss: 3.3709073982258393

Epoch: 5| Step: 3
Training loss: 3.6569205427292184
Validation loss: 3.3700336572852896

Epoch: 5| Step: 4
Training loss: 3.716408385010949
Validation loss: 3.369945020461179

Epoch: 5| Step: 5
Training loss: 3.612065621102067
Validation loss: 3.369257670457934

Epoch: 5| Step: 6
Training loss: 3.1707277525184687
Validation loss: 3.3685361246936085

Epoch: 5| Step: 7
Training loss: 4.247503557209324
Validation loss: 3.3686532976991623

Epoch: 5| Step: 8
Training loss: 3.7795527408541925
Validation loss: 3.3679264653782215

Epoch: 5| Step: 9
Training loss: 4.288054912457509
Validation loss: 3.367510667951139

Epoch: 5| Step: 10
Training loss: 2.6556693844981423
Validation loss: 3.3673905393559345

Epoch: 62| Step: 0
Training loss: 2.985786463711825
Validation loss: 3.366252342854405

Epoch: 5| Step: 1
Training loss: 4.28677123524116
Validation loss: 3.366469131568698

Epoch: 5| Step: 2
Training loss: 3.096740202371107
Validation loss: 3.366182343076802

Epoch: 5| Step: 3
Training loss: 4.090631826233323
Validation loss: 3.3660279262522126

Epoch: 5| Step: 4
Training loss: 3.672996057671836
Validation loss: 3.3663455426403743

Epoch: 5| Step: 5
Training loss: 3.054493617468413
Validation loss: 3.3651497926387592

Epoch: 5| Step: 6
Training loss: 3.4527457879131718
Validation loss: 3.3650690432509176

Epoch: 5| Step: 7
Training loss: 3.3647432240069937
Validation loss: 3.364638681863529

Epoch: 5| Step: 8
Training loss: 3.535958181228875
Validation loss: 3.3646028051356103

Epoch: 5| Step: 9
Training loss: 4.278456841828335
Validation loss: 3.3633446254101824

Epoch: 5| Step: 10
Training loss: 3.460066364952836
Validation loss: 3.3640559679830644

Epoch: 63| Step: 0
Training loss: 4.099489338404646
Validation loss: 3.3633074497454745

Epoch: 5| Step: 1
Training loss: 2.5428418012067433
Validation loss: 3.3623058075613317

Epoch: 5| Step: 2
Training loss: 2.6883723595236817
Validation loss: 3.3624958054314757

Epoch: 5| Step: 3
Training loss: 4.084591704079869
Validation loss: 3.3624358579458096

Epoch: 5| Step: 4
Training loss: 3.9983452712136947
Validation loss: 3.362454969863447

Epoch: 5| Step: 5
Training loss: 3.6262236535878265
Validation loss: 3.361224377399784

Epoch: 5| Step: 6
Training loss: 4.086901344999628
Validation loss: 3.362548414422283

Epoch: 5| Step: 7
Training loss: 2.507004652301259
Validation loss: 3.3626272665174395

Epoch: 5| Step: 8
Training loss: 3.903234920374116
Validation loss: 3.360993590865866

Epoch: 5| Step: 9
Training loss: 3.97766433769543
Validation loss: 3.3610243087060194

Epoch: 5| Step: 10
Training loss: 3.433106267389414
Validation loss: 3.3604825604841038

Epoch: 64| Step: 0
Training loss: 3.9290069536830607
Validation loss: 3.3617926972960883

Epoch: 5| Step: 1
Training loss: 2.7677830611480156
Validation loss: 3.3587036179265413

Epoch: 5| Step: 2
Training loss: 3.632047708055177
Validation loss: 3.3614004040521666

Epoch: 5| Step: 3
Training loss: 3.8018005823355177
Validation loss: 3.3611864254810087

Epoch: 5| Step: 4
Training loss: 3.573700413875277
Validation loss: 3.3618823527976613

Epoch: 5| Step: 5
Training loss: 2.9394339830149154
Validation loss: 3.3637629338369734

Epoch: 5| Step: 6
Training loss: 3.598498847362296
Validation loss: 3.364313089168528

Epoch: 5| Step: 7
Training loss: 3.778959605226948
Validation loss: 3.3600705074763617

Epoch: 5| Step: 8
Training loss: 3.6936040239486934
Validation loss: 3.358677669264907

Epoch: 5| Step: 9
Training loss: 3.214257670083396
Validation loss: 3.3577142775785633

Epoch: 5| Step: 10
Training loss: 4.453276193294075
Validation loss: 3.360694959042394

Epoch: 65| Step: 0
Training loss: 3.5580992705813483
Validation loss: 3.3609361924805694

Epoch: 5| Step: 1
Training loss: 3.2810465431714055
Validation loss: 3.359199902835522

Epoch: 5| Step: 2
Training loss: 3.8721891483577062
Validation loss: 3.358307411103778

Epoch: 5| Step: 3
Training loss: 4.007554311782892
Validation loss: 3.357666866470992

Epoch: 5| Step: 4
Training loss: 2.407339468701063
Validation loss: 3.3573092810457577

Epoch: 5| Step: 5
Training loss: 4.66630094094193
Validation loss: 3.35661908999921

Epoch: 5| Step: 6
Training loss: 3.283280534529514
Validation loss: 3.3571428656207933

Epoch: 5| Step: 7
Training loss: 3.910331120043901
Validation loss: 3.357242331003716

Epoch: 5| Step: 8
Training loss: 3.9892006766104213
Validation loss: 3.356089294256197

Epoch: 5| Step: 9
Training loss: 3.4416780916506196
Validation loss: 3.357888197069602

Epoch: 5| Step: 10
Training loss: 2.2640411102148024
Validation loss: 3.356745998011587

Epoch: 66| Step: 0
Training loss: 3.577254943345176
Validation loss: 3.3580403238108927

Epoch: 5| Step: 1
Training loss: 3.700208585891012
Validation loss: 3.356181720616494

Epoch: 5| Step: 2
Training loss: 3.3806091603863475
Validation loss: 3.3563614298104842

Epoch: 5| Step: 3
Training loss: 4.002448762926705
Validation loss: 3.355284582839416

Epoch: 5| Step: 4
Training loss: 3.532114783878998
Validation loss: 3.3541145348680654

Epoch: 5| Step: 5
Training loss: 3.171414797616748
Validation loss: 3.3548949336415856

Epoch: 5| Step: 6
Training loss: 3.5602909400010576
Validation loss: 3.352443469234232

Epoch: 5| Step: 7
Training loss: 3.5643770058225086
Validation loss: 3.3517466177406003

Epoch: 5| Step: 8
Training loss: 3.9273560662851437
Validation loss: 3.3516085563899223

Epoch: 5| Step: 9
Training loss: 4.110412698709332
Validation loss: 3.352571506452643

Epoch: 5| Step: 10
Training loss: 2.6151580685458047
Validation loss: 3.352542606054364

Epoch: 67| Step: 0
Training loss: 3.765401113352148
Validation loss: 3.351867697071273

Epoch: 5| Step: 1
Training loss: 2.67366619190985
Validation loss: 3.351563881425539

Epoch: 5| Step: 2
Training loss: 3.657975661766715
Validation loss: 3.3520506432040174

Epoch: 5| Step: 3
Training loss: 3.621186453775587
Validation loss: 3.350813704209197

Epoch: 5| Step: 4
Training loss: 3.4551773531451335
Validation loss: 3.3512762434942625

Epoch: 5| Step: 5
Training loss: 3.327283152816441
Validation loss: 3.3514787964824313

Epoch: 5| Step: 6
Training loss: 3.4269009960022725
Validation loss: 3.3500379127704325

Epoch: 5| Step: 7
Training loss: 4.391768662910809
Validation loss: 3.3506301235836453

Epoch: 5| Step: 8
Training loss: 3.454145323929386
Validation loss: 3.3492058799773448

Epoch: 5| Step: 9
Training loss: 3.7098901174061125
Validation loss: 3.3498845930428343

Epoch: 5| Step: 10
Training loss: 3.7806013827816765
Validation loss: 3.349424022295166

Epoch: 68| Step: 0
Training loss: 3.553375605700927
Validation loss: 3.34916240381878

Epoch: 5| Step: 1
Training loss: 3.799156727834661
Validation loss: 3.3481901733342756

Epoch: 5| Step: 2
Training loss: 3.106923119052062
Validation loss: 3.347545479555416

Epoch: 5| Step: 3
Training loss: 4.036266428989917
Validation loss: 3.3472632864582224

Epoch: 5| Step: 4
Training loss: 3.498237983769667
Validation loss: 3.3474783755914497

Epoch: 5| Step: 5
Training loss: 3.2665811261505726
Validation loss: 3.347004811060267

Epoch: 5| Step: 6
Training loss: 2.9181965403265133
Validation loss: 3.3473676635935643

Epoch: 5| Step: 7
Training loss: 3.9275153586064873
Validation loss: 3.3466024176563445

Epoch: 5| Step: 8
Training loss: 4.206015121454546
Validation loss: 3.3461279216307664

Epoch: 5| Step: 9
Training loss: 3.137670541209019
Validation loss: 3.3459407348786963

Epoch: 5| Step: 10
Training loss: 3.7741447086134863
Validation loss: 3.345743502997297

Epoch: 69| Step: 0
Training loss: 3.0093996294544767
Validation loss: 3.3451846302326675

Epoch: 5| Step: 1
Training loss: 4.153235468030349
Validation loss: 3.346793614941616

Epoch: 5| Step: 2
Training loss: 3.4625042195759206
Validation loss: 3.344911297177952

Epoch: 5| Step: 3
Training loss: 3.366554572502313
Validation loss: 3.343341402595715

Epoch: 5| Step: 4
Training loss: 3.5638995182245217
Validation loss: 3.3445895864763813

Epoch: 5| Step: 5
Training loss: 3.003760047797369
Validation loss: 3.343372333226228

Epoch: 5| Step: 6
Training loss: 4.003234985651204
Validation loss: 3.3430734969184375

Epoch: 5| Step: 7
Training loss: 4.0928455547586235
Validation loss: 3.343953487264113

Epoch: 5| Step: 8
Training loss: 3.771804108542135
Validation loss: 3.343970778234704

Epoch: 5| Step: 9
Training loss: 3.3686868467055517
Validation loss: 3.3432672631523843

Epoch: 5| Step: 10
Training loss: 3.363487387973622
Validation loss: 3.3434416788163333

Epoch: 70| Step: 0
Training loss: 3.705515158561901
Validation loss: 3.3431519448975835

Epoch: 5| Step: 1
Training loss: 3.9842876349949967
Validation loss: 3.3422845683196982

Epoch: 5| Step: 2
Training loss: 3.404424895846575
Validation loss: 3.3433646653887283

Epoch: 5| Step: 3
Training loss: 3.680474523136127
Validation loss: 3.3408413590525394

Epoch: 5| Step: 4
Training loss: 3.339453673309699
Validation loss: 3.3415055607107673

Epoch: 5| Step: 5
Training loss: 4.261634609045645
Validation loss: 3.341239622435953

Epoch: 5| Step: 6
Training loss: 2.90027027843756
Validation loss: 3.341498127959976

Epoch: 5| Step: 7
Training loss: 3.359693787109124
Validation loss: 3.340283663877278

Epoch: 5| Step: 8
Training loss: 3.852132697001444
Validation loss: 3.3406473784386543

Epoch: 5| Step: 9
Training loss: 3.799355156042352
Validation loss: 3.3416617812156075

Epoch: 5| Step: 10
Training loss: 2.676915906922665
Validation loss: 3.342189800120119

Epoch: 71| Step: 0
Training loss: 3.89015691308341
Validation loss: 3.3430070102397744

Epoch: 5| Step: 1
Training loss: 4.238537758654861
Validation loss: 3.339522787063216

Epoch: 5| Step: 2
Training loss: 3.493988050836701
Validation loss: 3.339492457947167

Epoch: 5| Step: 3
Training loss: 3.100186366970336
Validation loss: 3.3393899734668455

Epoch: 5| Step: 4
Training loss: 2.94838402663735
Validation loss: 3.3388146468711537

Epoch: 5| Step: 5
Training loss: 3.524181481961145
Validation loss: 3.3388964012921933

Epoch: 5| Step: 6
Training loss: 4.107823764441692
Validation loss: 3.338130561955198

Epoch: 5| Step: 7
Training loss: 4.1215708958078014
Validation loss: 3.3378945235795907

Epoch: 5| Step: 8
Training loss: 3.7021763870202555
Validation loss: 3.33766327294565

Epoch: 5| Step: 9
Training loss: 2.7301513312738717
Validation loss: 3.3374138072840234

Epoch: 5| Step: 10
Training loss: 3.0537251471227598
Validation loss: 3.3378611474127724

Epoch: 72| Step: 0
Training loss: 2.8664919141984404
Validation loss: 3.337207825614238

Epoch: 5| Step: 1
Training loss: 4.742621865403474
Validation loss: 3.3367978908392497

Epoch: 5| Step: 2
Training loss: 4.0021642551981715
Validation loss: 3.3367051165545374

Epoch: 5| Step: 3
Training loss: 3.5529499208768462
Validation loss: 3.33709705404942

Epoch: 5| Step: 4
Training loss: 3.019889859597386
Validation loss: 3.336202619138224

Epoch: 5| Step: 5
Training loss: 3.260527067580156
Validation loss: 3.335676568383091

Epoch: 5| Step: 6
Training loss: 4.099674509665991
Validation loss: 3.3351226977366006

Epoch: 5| Step: 7
Training loss: 3.4283478016811526
Validation loss: 3.3347972213934023

Epoch: 5| Step: 8
Training loss: 3.780325784520347
Validation loss: 3.334478944884206

Epoch: 5| Step: 9
Training loss: 2.7389953813963075
Validation loss: 3.3343043563987425

Epoch: 5| Step: 10
Training loss: 3.311083508774008
Validation loss: 3.333870938745386

Epoch: 73| Step: 0
Training loss: 3.8848806357488144
Validation loss: 3.334277898000785

Epoch: 5| Step: 1
Training loss: 3.943814134756403
Validation loss: 3.3337923569619567

Epoch: 5| Step: 2
Training loss: 3.8685788512697026
Validation loss: 3.3341127766152456

Epoch: 5| Step: 3
Training loss: 3.2146761399768597
Validation loss: 3.3330951610712067

Epoch: 5| Step: 4
Training loss: 3.355666557760917
Validation loss: 3.3335129125480023

Epoch: 5| Step: 5
Training loss: 3.759537457565282
Validation loss: 3.332796207857357

Epoch: 5| Step: 6
Training loss: 3.5772884007221055
Validation loss: 3.332002409957922

Epoch: 5| Step: 7
Training loss: 3.351327456611118
Validation loss: 3.3328690041394227

Epoch: 5| Step: 8
Training loss: 3.5846347811146746
Validation loss: 3.3319461140674775

Epoch: 5| Step: 9
Training loss: 2.9278728103736995
Validation loss: 3.331583484122438

Epoch: 5| Step: 10
Training loss: 3.7258248868735744
Validation loss: 3.3307399187545697

Epoch: 74| Step: 0
Training loss: 3.4603973724972596
Validation loss: 3.3320044180897357

Epoch: 5| Step: 1
Training loss: 3.519061634093086
Validation loss: 3.330866973847543

Epoch: 5| Step: 2
Training loss: 2.1551434538638436
Validation loss: 3.3331283465288304

Epoch: 5| Step: 3
Training loss: 3.8825845632291127
Validation loss: 3.3377647635627365

Epoch: 5| Step: 4
Training loss: 3.8909881299773343
Validation loss: 3.3398286606230023

Epoch: 5| Step: 5
Training loss: 4.117291733292774
Validation loss: 3.33264184567975

Epoch: 5| Step: 6
Training loss: 3.2359659456175196
Validation loss: 3.3301003303060552

Epoch: 5| Step: 7
Training loss: 3.20440945807111
Validation loss: 3.330221603892486

Epoch: 5| Step: 8
Training loss: 3.599467895178115
Validation loss: 3.3308398978096285

Epoch: 5| Step: 9
Training loss: 4.03656318118196
Validation loss: 3.329825843726554

Epoch: 5| Step: 10
Training loss: 3.8049559449541586
Validation loss: 3.3321262101757423

Epoch: 75| Step: 0
Training loss: 3.8064617430070884
Validation loss: 3.331569480802229

Epoch: 5| Step: 1
Training loss: 3.4848958126568492
Validation loss: 3.3328801928942293

Epoch: 5| Step: 2
Training loss: 3.292228135780153
Validation loss: 3.331764150761813

Epoch: 5| Step: 3
Training loss: 2.6340655053407045
Validation loss: 3.330514399345183

Epoch: 5| Step: 4
Training loss: 4.196543933708884
Validation loss: 3.3305589517805525

Epoch: 5| Step: 5
Training loss: 3.096932979776215
Validation loss: 3.330202126082068

Epoch: 5| Step: 6
Training loss: 3.599087011279152
Validation loss: 3.3295428417849804

Epoch: 5| Step: 7
Training loss: 4.0560215866597895
Validation loss: 3.3294840126487126

Epoch: 5| Step: 8
Training loss: 3.112190543727802
Validation loss: 3.3288844465559455

Epoch: 5| Step: 9
Training loss: 4.185513836707568
Validation loss: 3.328430212625692

Epoch: 5| Step: 10
Training loss: 3.450727225794705
Validation loss: 3.327499196010149

Epoch: 76| Step: 0
Training loss: 2.966397608296604
Validation loss: 3.328064868627777

Epoch: 5| Step: 1
Training loss: 3.32927300796986
Validation loss: 3.3277129217090327

Epoch: 5| Step: 2
Training loss: 3.3532457370831925
Validation loss: 3.3273113880978396

Epoch: 5| Step: 3
Training loss: 3.931608727709966
Validation loss: 3.3262746665435743

Epoch: 5| Step: 4
Training loss: 4.26125863980497
Validation loss: 3.3253905868852613

Epoch: 5| Step: 5
Training loss: 3.6141409186379203
Validation loss: 3.3256464453531174

Epoch: 5| Step: 6
Training loss: 4.336808400712693
Validation loss: 3.325843577145261

Epoch: 5| Step: 7
Training loss: 3.0329740674840533
Validation loss: 3.326286799263006

Epoch: 5| Step: 8
Training loss: 3.644165282360773
Validation loss: 3.325988689338925

Epoch: 5| Step: 9
Training loss: 3.704930633842814
Validation loss: 3.3239123254030174

Epoch: 5| Step: 10
Training loss: 2.502040793009341
Validation loss: 3.3246369151222477

Epoch: 77| Step: 0
Training loss: 3.7156998122297895
Validation loss: 3.3239744538701856

Epoch: 5| Step: 1
Training loss: 3.26172284337318
Validation loss: 3.3242873846330014

Epoch: 5| Step: 2
Training loss: 3.2440474357288287
Validation loss: 3.3235871180644265

Epoch: 5| Step: 3
Training loss: 3.0114565486544205
Validation loss: 3.323034432476495

Epoch: 5| Step: 4
Training loss: 4.515996053161788
Validation loss: 3.3231419081175826

Epoch: 5| Step: 5
Training loss: 3.600067424142779
Validation loss: 3.323328956539985

Epoch: 5| Step: 6
Training loss: 4.051868318607836
Validation loss: 3.323209415552506

Epoch: 5| Step: 7
Training loss: 3.533865576069498
Validation loss: 3.3217474171629306

Epoch: 5| Step: 8
Training loss: 3.7484425171424585
Validation loss: 3.3212848171506066

Epoch: 5| Step: 9
Training loss: 3.068262711816833
Validation loss: 3.3213619072189045

Epoch: 5| Step: 10
Training loss: 3.101445193438509
Validation loss: 3.3214348939038056

Epoch: 78| Step: 0
Training loss: 3.8841594608624432
Validation loss: 3.320921403618707

Epoch: 5| Step: 1
Training loss: 3.6246919172187555
Validation loss: 3.320434281627005

Epoch: 5| Step: 2
Training loss: 4.074205173605137
Validation loss: 3.3216792703009324

Epoch: 5| Step: 3
Training loss: 3.6835730381178053
Validation loss: 3.3200626356003697

Epoch: 5| Step: 4
Training loss: 3.2147344336574477
Validation loss: 3.3199697666271737

Epoch: 5| Step: 5
Training loss: 3.2339348977353466
Validation loss: 3.3196615443115745

Epoch: 5| Step: 6
Training loss: 2.6207824613145005
Validation loss: 3.3187629063093844

Epoch: 5| Step: 7
Training loss: 4.270098118961277
Validation loss: 3.319394844542617

Epoch: 5| Step: 8
Training loss: 3.6865732353838614
Validation loss: 3.319852268430072

Epoch: 5| Step: 9
Training loss: 3.001636853307425
Validation loss: 3.318681175019305

Epoch: 5| Step: 10
Training loss: 3.577748507886091
Validation loss: 3.3207408194935435

Epoch: 79| Step: 0
Training loss: 3.9994670989777705
Validation loss: 3.3195230181202846

Epoch: 5| Step: 1
Training loss: 3.5506268122526894
Validation loss: 3.3188253258322433

Epoch: 5| Step: 2
Training loss: 3.3070890750060564
Validation loss: 3.320214817605646

Epoch: 5| Step: 3
Training loss: 4.086537537725698
Validation loss: 3.3182022536614224

Epoch: 5| Step: 4
Training loss: 3.1739953381432646
Validation loss: 3.31802626942358

Epoch: 5| Step: 5
Training loss: 3.2916714792980954
Validation loss: 3.3175648413079917

Epoch: 5| Step: 6
Training loss: 2.908424466371254
Validation loss: 3.3181490551397097

Epoch: 5| Step: 7
Training loss: 3.6028417603330847
Validation loss: 3.3176709162358997

Epoch: 5| Step: 8
Training loss: 3.4054337669723296
Validation loss: 3.319544016669784

Epoch: 5| Step: 9
Training loss: 3.582393582155068
Validation loss: 3.316300494858315

Epoch: 5| Step: 10
Training loss: 4.1339827324774685
Validation loss: 3.316709661017008

Epoch: 80| Step: 0
Training loss: 4.125683121037044
Validation loss: 3.3169090977508913

Epoch: 5| Step: 1
Training loss: 3.4776131060461912
Validation loss: 3.316539965447105

Epoch: 5| Step: 2
Training loss: 3.4639139917016903
Validation loss: 3.3135504702520393

Epoch: 5| Step: 3
Training loss: 3.277064533183758
Validation loss: 3.3140257163773694

Epoch: 5| Step: 4
Training loss: 4.595558692747415
Validation loss: 3.315205919751699

Epoch: 5| Step: 5
Training loss: 2.777586849856561
Validation loss: 3.3142321781125004

Epoch: 5| Step: 6
Training loss: 3.0823852181082914
Validation loss: 3.315267843295067

Epoch: 5| Step: 7
Training loss: 3.9588694694566895
Validation loss: 3.3138973642158285

Epoch: 5| Step: 8
Training loss: 3.1652948687507987
Validation loss: 3.3134469605616728

Epoch: 5| Step: 9
Training loss: 3.643640145531915
Validation loss: 3.3135153610645465

Epoch: 5| Step: 10
Training loss: 3.1085473880920125
Validation loss: 3.3151104169012258

Epoch: 81| Step: 0
Training loss: 4.0744057719389195
Validation loss: 3.3135909089151276

Epoch: 5| Step: 1
Training loss: 3.7959810939354184
Validation loss: 3.311948819003338

Epoch: 5| Step: 2
Training loss: 3.367258588921125
Validation loss: 3.3149250090597193

Epoch: 5| Step: 3
Training loss: 3.7481430542310505
Validation loss: 3.314299238936249

Epoch: 5| Step: 4
Training loss: 3.288389014655435
Validation loss: 3.31430342825891

Epoch: 5| Step: 5
Training loss: 2.8786881052337634
Validation loss: 3.309824797610781

Epoch: 5| Step: 6
Training loss: 3.593391466914935
Validation loss: 3.311836538432216

Epoch: 5| Step: 7
Training loss: 3.613739413520035
Validation loss: 3.3108498488902995

Epoch: 5| Step: 8
Training loss: 3.339495795790883
Validation loss: 3.313112734316798

Epoch: 5| Step: 9
Training loss: 3.63733154116537
Validation loss: 3.311804859655223

Epoch: 5| Step: 10
Training loss: 3.65096520503904
Validation loss: 3.312560905350147

Epoch: 82| Step: 0
Training loss: 3.5868455987799788
Validation loss: 3.3093599360501376

Epoch: 5| Step: 1
Training loss: 3.4398864785026486
Validation loss: 3.312767276518059

Epoch: 5| Step: 2
Training loss: 4.0008334245279835
Validation loss: 3.3111654051484103

Epoch: 5| Step: 3
Training loss: 3.4921590987379765
Validation loss: 3.31065513856581

Epoch: 5| Step: 4
Training loss: 2.986892836414314
Validation loss: 3.3135909135571744

Epoch: 5| Step: 5
Training loss: 3.492583864661918
Validation loss: 3.3105703961120643

Epoch: 5| Step: 6
Training loss: 3.2594610566786777
Validation loss: 3.3094970207777212

Epoch: 5| Step: 7
Training loss: 3.8949335592574967
Validation loss: 3.30858130134929

Epoch: 5| Step: 8
Training loss: 3.433114878793906
Validation loss: 3.3093726482551684

Epoch: 5| Step: 9
Training loss: 4.013242497181864
Validation loss: 3.310589600688843

Epoch: 5| Step: 10
Training loss: 3.312070422838235
Validation loss: 3.30924719423939

Epoch: 83| Step: 0
Training loss: 3.514557672183445
Validation loss: 3.3086480102591613

Epoch: 5| Step: 1
Training loss: 3.2593124193454384
Validation loss: 3.3093986937917164

Epoch: 5| Step: 2
Training loss: 3.0551938469004996
Validation loss: 3.3112670095832915

Epoch: 5| Step: 3
Training loss: 4.225236667121556
Validation loss: 3.3079058488264494

Epoch: 5| Step: 4
Training loss: 3.7279857420832863
Validation loss: 3.3079965540641347

Epoch: 5| Step: 5
Training loss: 4.2157113894241975
Validation loss: 3.3084240085430157

Epoch: 5| Step: 6
Training loss: 3.3710480617287057
Validation loss: 3.308221892805718

Epoch: 5| Step: 7
Training loss: 2.9292494789742305
Validation loss: 3.307700970144708

Epoch: 5| Step: 8
Training loss: 3.7002512408349104
Validation loss: 3.307753522910996

Epoch: 5| Step: 9
Training loss: 2.7952749267918744
Validation loss: 3.3072678659190045

Epoch: 5| Step: 10
Training loss: 3.9890107357313886
Validation loss: 3.3073769755169176

Epoch: 84| Step: 0
Training loss: 3.7287373784075744
Validation loss: 3.3075289289025243

Epoch: 5| Step: 1
Training loss: 4.014332129011824
Validation loss: 3.3065773490070876

Epoch: 5| Step: 2
Training loss: 3.397403954502013
Validation loss: 3.308298382169326

Epoch: 5| Step: 3
Training loss: 4.02632111849857
Validation loss: 3.311046071526517

Epoch: 5| Step: 4
Training loss: 4.104312229318381
Validation loss: 3.3075619182220213

Epoch: 5| Step: 5
Training loss: 3.505787968240418
Validation loss: 3.312890257148351

Epoch: 5| Step: 6
Training loss: 3.513130354063674
Validation loss: 3.307795024481959

Epoch: 5| Step: 7
Training loss: 3.339408123316871
Validation loss: 3.306322489882654

Epoch: 5| Step: 8
Training loss: 3.6201090209309017
Validation loss: 3.3039008039358024

Epoch: 5| Step: 9
Training loss: 2.8526746279516324
Validation loss: 3.304377486008841

Epoch: 5| Step: 10
Training loss: 2.429099548442067
Validation loss: 3.302680121599651

Epoch: 85| Step: 0
Training loss: 3.144331685243491
Validation loss: 3.3034954354500092

Epoch: 5| Step: 1
Training loss: 3.6383117399275355
Validation loss: 3.300724932675639

Epoch: 5| Step: 2
Training loss: 3.2841208841468448
Validation loss: 3.3011827830815874

Epoch: 5| Step: 3
Training loss: 2.901958619719862
Validation loss: 3.3016690633913495

Epoch: 5| Step: 4
Training loss: 3.9528146252523513
Validation loss: 3.3029823967150373

Epoch: 5| Step: 5
Training loss: 3.32027415533925
Validation loss: 3.3016804588172133

Epoch: 5| Step: 6
Training loss: 4.242401960652945
Validation loss: 3.3025740456864794

Epoch: 5| Step: 7
Training loss: 2.8925830704507014
Validation loss: 3.303214090003292

Epoch: 5| Step: 8
Training loss: 4.1780804262943505
Validation loss: 3.302317026867727

Epoch: 5| Step: 9
Training loss: 3.646194323878714
Validation loss: 3.2999655366902187

Epoch: 5| Step: 10
Training loss: 3.5163340213852226
Validation loss: 3.30074506597703

Epoch: 86| Step: 0
Training loss: 3.80733214781706
Validation loss: 3.301204145242687

Epoch: 5| Step: 1
Training loss: 3.2684051506818896
Validation loss: 3.302011916811415

Epoch: 5| Step: 2
Training loss: 3.0815577850444993
Validation loss: 3.2987271376394522

Epoch: 5| Step: 3
Training loss: 3.8228646395241386
Validation loss: 3.3010815959430344

Epoch: 5| Step: 4
Training loss: 4.1483662342336745
Validation loss: 3.3001528290318065

Epoch: 5| Step: 5
Training loss: 3.9563106923924427
Validation loss: 3.300035754793485

Epoch: 5| Step: 6
Training loss: 3.387405061975028
Validation loss: 3.3011436236789526

Epoch: 5| Step: 7
Training loss: 3.370934474891019
Validation loss: 3.300328865270724

Epoch: 5| Step: 8
Training loss: 3.3406801481485604
Validation loss: 3.3013775178142684

Epoch: 5| Step: 9
Training loss: 2.777145958146882
Validation loss: 3.3022665139461482

Epoch: 5| Step: 10
Training loss: 3.8379568467966827
Validation loss: 3.303576013680106

Epoch: 87| Step: 0
Training loss: 3.4492390719513883
Validation loss: 3.301639944157037

Epoch: 5| Step: 1
Training loss: 4.615712093081706
Validation loss: 3.2969796566957807

Epoch: 5| Step: 2
Training loss: 3.1304092892815807
Validation loss: 3.29908091013477

Epoch: 5| Step: 3
Training loss: 3.504181952033042
Validation loss: 3.298288530351792

Epoch: 5| Step: 4
Training loss: 3.100656679803216
Validation loss: 3.295675082971048

Epoch: 5| Step: 5
Training loss: 3.407822412251675
Validation loss: 3.2953532504090663

Epoch: 5| Step: 6
Training loss: 3.631969198155135
Validation loss: 3.2969706648354045

Epoch: 5| Step: 7
Training loss: 3.2186679274085903
Validation loss: 3.295744985662629

Epoch: 5| Step: 8
Training loss: 3.332192813940962
Validation loss: 3.29608089212725

Epoch: 5| Step: 9
Training loss: 3.955657871282742
Validation loss: 3.296679876436193

Epoch: 5| Step: 10
Training loss: 3.333828905142285
Validation loss: 3.2964728519885673

Epoch: 88| Step: 0
Training loss: 3.8001231675515483
Validation loss: 3.2937622679053273

Epoch: 5| Step: 1
Training loss: 3.511431553928164
Validation loss: 3.297353200014091

Epoch: 5| Step: 2
Training loss: 3.3541481696777846
Validation loss: 3.2952154263547304

Epoch: 5| Step: 3
Training loss: 3.220519236999492
Validation loss: 3.2965545366356706

Epoch: 5| Step: 4
Training loss: 3.406329932718595
Validation loss: 3.296371325842529

Epoch: 5| Step: 5
Training loss: 4.384535724415614
Validation loss: 3.2959539863648266

Epoch: 5| Step: 6
Training loss: 3.091062052404708
Validation loss: 3.294697162603551

Epoch: 5| Step: 7
Training loss: 3.3292879034000027
Validation loss: 3.294579426056281

Epoch: 5| Step: 8
Training loss: 4.141726710743283
Validation loss: 3.2940271127468623

Epoch: 5| Step: 9
Training loss: 2.481079026488506
Validation loss: 3.2928427909087503

Epoch: 5| Step: 10
Training loss: 3.884589358589049
Validation loss: 3.293631219092965

Epoch: 89| Step: 0
Training loss: 3.302372114548386
Validation loss: 3.294221921835963

Epoch: 5| Step: 1
Training loss: 3.2711486826371035
Validation loss: 3.2956738119144355

Epoch: 5| Step: 2
Training loss: 3.122684078364554
Validation loss: 3.293996391195737

Epoch: 5| Step: 3
Training loss: 3.981438126603155
Validation loss: 3.2932461933469495

Epoch: 5| Step: 4
Training loss: 3.5607548504896607
Validation loss: 3.2921343546830575

Epoch: 5| Step: 5
Training loss: 3.3846625011339064
Validation loss: 3.295413737507778

Epoch: 5| Step: 6
Training loss: 3.7617068344989115
Validation loss: 3.2923290483959065

Epoch: 5| Step: 7
Training loss: 3.846666423680801
Validation loss: 3.2927180104391605

Epoch: 5| Step: 8
Training loss: 3.668210412657753
Validation loss: 3.2922539190397546

Epoch: 5| Step: 9
Training loss: 2.8350626959755765
Validation loss: 3.2926012448971425

Epoch: 5| Step: 10
Training loss: 4.069766778660717
Validation loss: 3.29156008810451

Epoch: 90| Step: 0
Training loss: 3.7523348850873837
Validation loss: 3.2906103348638687

Epoch: 5| Step: 1
Training loss: 2.9563603515675
Validation loss: 3.293291187680135

Epoch: 5| Step: 2
Training loss: 3.6360077618808804
Validation loss: 3.291524796539382

Epoch: 5| Step: 3
Training loss: 3.0565598157249423
Validation loss: 3.294747543359828

Epoch: 5| Step: 4
Training loss: 3.3883817081278766
Validation loss: 3.2994674134764037

Epoch: 5| Step: 5
Training loss: 3.5988418994550107
Validation loss: 3.301023997660584

Epoch: 5| Step: 6
Training loss: 3.7846950253939484
Validation loss: 3.2944089874256823

Epoch: 5| Step: 7
Training loss: 3.2491995485971623
Validation loss: 3.2966286172983965

Epoch: 5| Step: 8
Training loss: 3.136515951667308
Validation loss: 3.2923601000853506

Epoch: 5| Step: 9
Training loss: 3.937916930392436
Validation loss: 3.290854270584536

Epoch: 5| Step: 10
Training loss: 4.287340495976776
Validation loss: 3.2897303503879876

Epoch: 91| Step: 0
Training loss: 3.5355688370682232
Validation loss: 3.288863876035731

Epoch: 5| Step: 1
Training loss: 2.727116044919034
Validation loss: 3.288479249441075

Epoch: 5| Step: 2
Training loss: 4.01689964874478
Validation loss: 3.28931716573345

Epoch: 5| Step: 3
Training loss: 3.0894806042031657
Validation loss: 3.2872899544582412

Epoch: 5| Step: 4
Training loss: 3.3793710730677837
Validation loss: 3.2940786353373737

Epoch: 5| Step: 5
Training loss: 3.321231777613523
Validation loss: 3.2902304471878048

Epoch: 5| Step: 6
Training loss: 4.243262167126812
Validation loss: 3.2868167750698225

Epoch: 5| Step: 7
Training loss: 4.005064142787453
Validation loss: 3.2878987616696436

Epoch: 5| Step: 8
Training loss: 2.926234130034173
Validation loss: 3.2904186481568134

Epoch: 5| Step: 9
Training loss: 3.6706283725727578
Validation loss: 3.2892677695737

Epoch: 5| Step: 10
Training loss: 3.690874010902495
Validation loss: 3.295090066637784

Epoch: 92| Step: 0
Training loss: 3.2514693533274217
Validation loss: 3.293140528199617

Epoch: 5| Step: 1
Training loss: 4.210094926719846
Validation loss: 3.292172235927085

Epoch: 5| Step: 2
Training loss: 3.4518365311710877
Validation loss: 3.2900659093891704

Epoch: 5| Step: 3
Training loss: 3.1841014621038193
Validation loss: 3.290552517452839

Epoch: 5| Step: 4
Training loss: 3.1344084444096816
Validation loss: 3.2879831403328943

Epoch: 5| Step: 5
Training loss: 2.883902656340883
Validation loss: 3.2875690295903133

Epoch: 5| Step: 6
Training loss: 4.225350422970788
Validation loss: 3.2881806277477543

Epoch: 5| Step: 7
Training loss: 4.066309155451056
Validation loss: 3.2869963629280394

Epoch: 5| Step: 8
Training loss: 3.1937505733243126
Validation loss: 3.286269649166547

Epoch: 5| Step: 9
Training loss: 3.61167405134032
Validation loss: 3.287885774626595

Epoch: 5| Step: 10
Training loss: 3.2909989625412757
Validation loss: 3.2865061167122054

Epoch: 93| Step: 0
Training loss: 4.018684379552101
Validation loss: 3.286029057044962

Epoch: 5| Step: 1
Training loss: 2.950281621130758
Validation loss: 3.2873954013613638

Epoch: 5| Step: 2
Training loss: 3.7767747610256057
Validation loss: 3.2853851217173493

Epoch: 5| Step: 3
Training loss: 3.786163164656195
Validation loss: 3.2860961598012444

Epoch: 5| Step: 4
Training loss: 3.6959446049869746
Validation loss: 3.2858671066702576

Epoch: 5| Step: 5
Training loss: 4.073856853384178
Validation loss: 3.2875367270681592

Epoch: 5| Step: 6
Training loss: 3.5129571583234287
Validation loss: 3.2862980745678216

Epoch: 5| Step: 7
Training loss: 3.437348518501795
Validation loss: 3.2915628810692965

Epoch: 5| Step: 8
Training loss: 2.8453968016753612
Validation loss: 3.2888793223981994

Epoch: 5| Step: 9
Training loss: 3.3748026189660307
Validation loss: 3.28726510320313

Epoch: 5| Step: 10
Training loss: 3.0184864442504185
Validation loss: 3.2838241628994136

Epoch: 94| Step: 0
Training loss: 3.4573931660837784
Validation loss: 3.289235432293713

Epoch: 5| Step: 1
Training loss: 3.2657886810897137
Validation loss: 3.2858203121517127

Epoch: 5| Step: 2
Training loss: 3.8615086638212532
Validation loss: 3.2900758941256956

Epoch: 5| Step: 3
Training loss: 4.083957987644906
Validation loss: 3.281916293748008

Epoch: 5| Step: 4
Training loss: 3.887913996494859
Validation loss: 3.2812642711948237

Epoch: 5| Step: 5
Training loss: 3.1169887852251312
Validation loss: 3.2809751896549546

Epoch: 5| Step: 6
Training loss: 3.453756973640617
Validation loss: 3.2823520167332565

Epoch: 5| Step: 7
Training loss: 3.877967928426723
Validation loss: 3.2807781608795676

Epoch: 5| Step: 8
Training loss: 2.962347897516085
Validation loss: 3.279036236586219

Epoch: 5| Step: 9
Training loss: 3.194850748363887
Validation loss: 3.2796689929510436

Epoch: 5| Step: 10
Training loss: 3.4262125750685852
Validation loss: 3.280487507925281

Epoch: 95| Step: 0
Training loss: 3.8003219217165274
Validation loss: 3.281262803919471

Epoch: 5| Step: 1
Training loss: 4.005968885631351
Validation loss: 3.28049593541206

Epoch: 5| Step: 2
Training loss: 3.5104694456817227
Validation loss: 3.2786594663508564

Epoch: 5| Step: 3
Training loss: 4.1054487726975895
Validation loss: 3.2791356678974966

Epoch: 5| Step: 4
Training loss: 3.657776342813739
Validation loss: 3.277908264257087

Epoch: 5| Step: 5
Training loss: 2.911338043912561
Validation loss: 3.278263978428506

Epoch: 5| Step: 6
Training loss: 3.8869458309527842
Validation loss: 3.2805458668893164

Epoch: 5| Step: 7
Training loss: 2.679181198468307
Validation loss: 3.280203183218999

Epoch: 5| Step: 8
Training loss: 3.217727943295615
Validation loss: 3.2784578490251484

Epoch: 5| Step: 9
Training loss: 3.8006343362295523
Validation loss: 3.278849558234236

Epoch: 5| Step: 10
Training loss: 2.7013630499389905
Validation loss: 3.2772614206933284

Epoch: 96| Step: 0
Training loss: 3.4165204799981197
Validation loss: 3.278641798099402

Epoch: 5| Step: 1
Training loss: 4.284426659203738
Validation loss: 3.276990337648339

Epoch: 5| Step: 2
Training loss: 2.801075003527132
Validation loss: 3.2773361467036164

Epoch: 5| Step: 3
Training loss: 3.141329102800993
Validation loss: 3.2757227834868354

Epoch: 5| Step: 4
Training loss: 3.923858019656528
Validation loss: 3.2765859932290757

Epoch: 5| Step: 5
Training loss: 3.4914339690560268
Validation loss: 3.276434413020401

Epoch: 5| Step: 6
Training loss: 3.440599466033346
Validation loss: 3.2742420777699386

Epoch: 5| Step: 7
Training loss: 3.046265996077799
Validation loss: 3.2770149366874817

Epoch: 5| Step: 8
Training loss: 4.450749349186843
Validation loss: 3.275461467766075

Epoch: 5| Step: 9
Training loss: 3.102474203563481
Validation loss: 3.2784702165667428

Epoch: 5| Step: 10
Training loss: 3.187832534498224
Validation loss: 3.282968633371121

Epoch: 97| Step: 0
Training loss: 3.830328606833639
Validation loss: 3.2936516121401045

Epoch: 5| Step: 1
Training loss: 4.022654988756721
Validation loss: 3.298793804907413

Epoch: 5| Step: 2
Training loss: 3.5043116306312765
Validation loss: 3.309647687822302

Epoch: 5| Step: 3
Training loss: 3.4551211840165945
Validation loss: 3.2869828981177096

Epoch: 5| Step: 4
Training loss: 3.9996267382988795
Validation loss: 3.274197628134479

Epoch: 5| Step: 5
Training loss: 2.865837090983307
Validation loss: 3.271897550353698

Epoch: 5| Step: 6
Training loss: 3.2421402893305964
Validation loss: 3.2725944148962336

Epoch: 5| Step: 7
Training loss: 3.5874554780862407
Validation loss: 3.2731019170949964

Epoch: 5| Step: 8
Training loss: 3.52166067180373
Validation loss: 3.277906143210647

Epoch: 5| Step: 9
Training loss: 2.9911007812621415
Validation loss: 3.2784928026926363

Epoch: 5| Step: 10
Training loss: 3.5518664222035095
Validation loss: 3.2771829584261556

Epoch: 98| Step: 0
Training loss: 2.422690174365934
Validation loss: 3.280920387350498

Epoch: 5| Step: 1
Training loss: 4.174193006175878
Validation loss: 3.2719445134346867

Epoch: 5| Step: 2
Training loss: 3.352241785174078
Validation loss: 3.271801255830104

Epoch: 5| Step: 3
Training loss: 3.241750811847024
Validation loss: 3.271420299114966

Epoch: 5| Step: 4
Training loss: 3.9770877993308655
Validation loss: 3.2719637989893093

Epoch: 5| Step: 5
Training loss: 3.041203154341479
Validation loss: 3.273548873520962

Epoch: 5| Step: 6
Training loss: 4.023965567591273
Validation loss: 3.272325966141259

Epoch: 5| Step: 7
Training loss: 4.059149901365178
Validation loss: 3.276225851039547

Epoch: 5| Step: 8
Training loss: 3.6977287280541358
Validation loss: 3.276004517094173

Epoch: 5| Step: 9
Training loss: 2.896454742136011
Validation loss: 3.2757917173476785

Epoch: 5| Step: 10
Training loss: 3.397320302852432
Validation loss: 3.275922678452693

Epoch: 99| Step: 0
Training loss: 4.082420688286236
Validation loss: 3.2738424619379574

Epoch: 5| Step: 1
Training loss: 2.6853288263752204
Validation loss: 3.2731207932445097

Epoch: 5| Step: 2
Training loss: 3.357287232793251
Validation loss: 3.2732757082755377

Epoch: 5| Step: 3
Training loss: 3.3795312204263515
Validation loss: 3.2725929625345316

Epoch: 5| Step: 4
Training loss: 3.221435611633786
Validation loss: 3.274325743548015

Epoch: 5| Step: 5
Training loss: 3.6365788450281067
Validation loss: 3.2756552725703205

Epoch: 5| Step: 6
Training loss: 3.425263281956617
Validation loss: 3.2769126136725557

Epoch: 5| Step: 7
Training loss: 3.448902845766835
Validation loss: 3.2725844958953414

Epoch: 5| Step: 8
Training loss: 3.8897789950706922
Validation loss: 3.2839485693492243

Epoch: 5| Step: 9
Training loss: 3.8605810589827114
Validation loss: 3.2896796200401783

Epoch: 5| Step: 10
Training loss: 3.5114310107454907
Validation loss: 3.270506001768503

Epoch: 100| Step: 0
Training loss: 3.5288578809624456
Validation loss: 3.2701093976264652

Epoch: 5| Step: 1
Training loss: 3.9910437929507836
Validation loss: 3.268233348629844

Epoch: 5| Step: 2
Training loss: 3.783334961161214
Validation loss: 3.2683941930074085

Epoch: 5| Step: 3
Training loss: 2.8677538902210435
Validation loss: 3.27433503248007

Epoch: 5| Step: 4
Training loss: 2.7951868172927
Validation loss: 3.277951909644728

Epoch: 5| Step: 5
Training loss: 3.4996311810854426
Validation loss: 3.2730862161285303

Epoch: 5| Step: 6
Training loss: 3.0948496704075747
Validation loss: 3.269627133090877

Epoch: 5| Step: 7
Training loss: 3.7839712644215813
Validation loss: 3.2674674628011777

Epoch: 5| Step: 8
Training loss: 3.6135447802969627
Validation loss: 3.265561992219745

Epoch: 5| Step: 9
Training loss: 3.5128237266283078
Validation loss: 3.2645831225408792

Epoch: 5| Step: 10
Training loss: 4.088576680740132
Validation loss: 3.2649619380254573

Epoch: 101| Step: 0
Training loss: 3.1051554971725803
Validation loss: 3.266575709397811

Epoch: 5| Step: 1
Training loss: 3.093520647275073
Validation loss: 3.265118604765676

Epoch: 5| Step: 2
Training loss: 4.450172060951162
Validation loss: 3.2634149503296808

Epoch: 5| Step: 3
Training loss: 3.387286674285769
Validation loss: 3.266755418051076

Epoch: 5| Step: 4
Training loss: 4.071467903731194
Validation loss: 3.2649885294228027

Epoch: 5| Step: 5
Training loss: 3.224053615133724
Validation loss: 3.2688211715831494

Epoch: 5| Step: 6
Training loss: 2.580236599002083
Validation loss: 3.2673690738146286

Epoch: 5| Step: 7
Training loss: 3.9049091937146536
Validation loss: 3.268312692483901

Epoch: 5| Step: 8
Training loss: 2.9375754813378205
Validation loss: 3.2673174383991372

Epoch: 5| Step: 9
Training loss: 3.749514993456784
Validation loss: 3.268692071804069

Epoch: 5| Step: 10
Training loss: 3.726200238100001
Validation loss: 3.2719632771666656

Epoch: 102| Step: 0
Training loss: 4.014587743361142
Validation loss: 3.2673350093928053

Epoch: 5| Step: 1
Training loss: 4.219663167952693
Validation loss: 3.2645214406623286

Epoch: 5| Step: 2
Training loss: 3.740856722456012
Validation loss: 3.2625376021719

Epoch: 5| Step: 3
Training loss: 3.9609336476805725
Validation loss: 3.260687735447235

Epoch: 5| Step: 4
Training loss: 2.186950069511617
Validation loss: 3.264323473742559

Epoch: 5| Step: 5
Training loss: 3.876212022798923
Validation loss: 3.2644027233641113

Epoch: 5| Step: 6
Training loss: 3.390682096923488
Validation loss: 3.263429326227631

Epoch: 5| Step: 7
Training loss: 3.18384746640461
Validation loss: 3.263971787057914

Epoch: 5| Step: 8
Training loss: 3.0485182805701223
Validation loss: 3.265185648892676

Epoch: 5| Step: 9
Training loss: 2.3621759020806654
Validation loss: 3.264539791586677

Epoch: 5| Step: 10
Training loss: 4.019782975065442
Validation loss: 3.266499748343501

Epoch: 103| Step: 0
Training loss: 2.6841759640109153
Validation loss: 3.2657216069519417

Epoch: 5| Step: 1
Training loss: 4.136759785708883
Validation loss: 3.268849934584157

Epoch: 5| Step: 2
Training loss: 3.133361311713223
Validation loss: 3.267364745067421

Epoch: 5| Step: 3
Training loss: 3.9850870132040552
Validation loss: 3.265552762333551

Epoch: 5| Step: 4
Training loss: 3.92324622754092
Validation loss: 3.2635295103376754

Epoch: 5| Step: 5
Training loss: 3.6922638719354826
Validation loss: 3.263868814000974

Epoch: 5| Step: 6
Training loss: 3.6863056123560876
Validation loss: 3.262223038016485

Epoch: 5| Step: 7
Training loss: 2.223524410133542
Validation loss: 3.2605190099191854

Epoch: 5| Step: 8
Training loss: 3.5278160480282397
Validation loss: 3.2619605268726466

Epoch: 5| Step: 9
Training loss: 3.772428199888691
Validation loss: 3.261055896890211

Epoch: 5| Step: 10
Training loss: 3.2680215756977606
Validation loss: 3.2611598289940793

Epoch: 104| Step: 0
Training loss: 3.5018936211742635
Validation loss: 3.2624887875084645

Epoch: 5| Step: 1
Training loss: 3.736696423546227
Validation loss: 3.2623425277344205

Epoch: 5| Step: 2
Training loss: 3.418797053653139
Validation loss: 3.2627619648428428

Epoch: 5| Step: 3
Training loss: 2.9772314085995335
Validation loss: 3.258838259838275

Epoch: 5| Step: 4
Training loss: 3.108428044107746
Validation loss: 3.259178855790285

Epoch: 5| Step: 5
Training loss: 3.740470093951117
Validation loss: 3.2585826305913126

Epoch: 5| Step: 6
Training loss: 3.3793885697123582
Validation loss: 3.258820990743016

Epoch: 5| Step: 7
Training loss: 3.3750426678256313
Validation loss: 3.258214805764997

Epoch: 5| Step: 8
Training loss: 3.559500251153786
Validation loss: 3.259010546149165

Epoch: 5| Step: 9
Training loss: 3.9099338098567524
Validation loss: 3.2589449891866717

Epoch: 5| Step: 10
Training loss: 3.754834809511107
Validation loss: 3.2584353198081897

Epoch: 105| Step: 0
Training loss: 2.96347701946917
Validation loss: 3.2618134323052805

Epoch: 5| Step: 1
Training loss: 4.05754702951531
Validation loss: 3.26049172631741

Epoch: 5| Step: 2
Training loss: 3.9120246622833283
Validation loss: 3.258731110043834

Epoch: 5| Step: 3
Training loss: 3.629382805386429
Validation loss: 3.2636474793843133

Epoch: 5| Step: 4
Training loss: 3.8422894688091347
Validation loss: 3.26064268118573

Epoch: 5| Step: 5
Training loss: 3.0843767685967256
Validation loss: 3.264908036898562

Epoch: 5| Step: 6
Training loss: 4.017204478705368
Validation loss: 3.2622230592346226

Epoch: 5| Step: 7
Training loss: 3.4549548793998692
Validation loss: 3.2604921233858737

Epoch: 5| Step: 8
Training loss: 2.7032460973879555
Validation loss: 3.2571059872161183

Epoch: 5| Step: 9
Training loss: 3.3393849911077114
Validation loss: 3.2579763170672753

Epoch: 5| Step: 10
Training loss: 3.1565989688541207
Validation loss: 3.2561419785280963

Epoch: 106| Step: 0
Training loss: 3.3974092879266022
Validation loss: 3.2555298438335427

Epoch: 5| Step: 1
Training loss: 3.2502516135605006
Validation loss: 3.257426794659986

Epoch: 5| Step: 2
Training loss: 3.4295401226521407
Validation loss: 3.2554361348172947

Epoch: 5| Step: 3
Training loss: 2.993508468154646
Validation loss: 3.2554884965332676

Epoch: 5| Step: 4
Training loss: 4.010312614907609
Validation loss: 3.2543619904263146

Epoch: 5| Step: 5
Training loss: 3.396514839794727
Validation loss: 3.2563859801708857

Epoch: 5| Step: 6
Training loss: 3.4340742206850785
Validation loss: 3.25619213386725

Epoch: 5| Step: 7
Training loss: 2.896214869405097
Validation loss: 3.254932775372686

Epoch: 5| Step: 8
Training loss: 3.56818044095877
Validation loss: 3.2541635724710885

Epoch: 5| Step: 9
Training loss: 3.638862805519744
Validation loss: 3.2544164191301124

Epoch: 5| Step: 10
Training loss: 4.373976233453986
Validation loss: 3.252725418426398

Epoch: 107| Step: 0
Training loss: 3.886303197988018
Validation loss: 3.2547347301224527

Epoch: 5| Step: 1
Training loss: 3.2771951962290884
Validation loss: 3.2549826177624985

Epoch: 5| Step: 2
Training loss: 3.691950036418577
Validation loss: 3.2540906021648124

Epoch: 5| Step: 3
Training loss: 3.5980576944607847
Validation loss: 3.2526189019388387

Epoch: 5| Step: 4
Training loss: 3.3866158264078714
Validation loss: 3.2523588497573015

Epoch: 5| Step: 5
Training loss: 3.166647977941143
Validation loss: 3.250950496819228

Epoch: 5| Step: 6
Training loss: 3.467957552182586
Validation loss: 3.2509325423375377

Epoch: 5| Step: 7
Training loss: 2.794077065117029
Validation loss: 3.252646057688836

Epoch: 5| Step: 8
Training loss: 4.308299354601235
Validation loss: 3.253354443634261

Epoch: 5| Step: 9
Training loss: 3.4439680802375787
Validation loss: 3.2550446331906553

Epoch: 5| Step: 10
Training loss: 3.088424723289098
Validation loss: 3.2520051226193694

Epoch: 108| Step: 0
Training loss: 3.8004098771546997
Validation loss: 3.2565541294618052

Epoch: 5| Step: 1
Training loss: 2.7093373613922083
Validation loss: 3.2502458288523033

Epoch: 5| Step: 2
Training loss: 3.5690696773552077
Validation loss: 3.249587487986401

Epoch: 5| Step: 3
Training loss: 3.2590622368740303
Validation loss: 3.249115019617939

Epoch: 5| Step: 4
Training loss: 3.375993088032666
Validation loss: 3.25186627098426

Epoch: 5| Step: 5
Training loss: 2.8990964731650055
Validation loss: 3.248518597486082

Epoch: 5| Step: 6
Training loss: 4.286815283904861
Validation loss: 3.2571611492739625

Epoch: 5| Step: 7
Training loss: 3.439336944818742
Validation loss: 3.2504364585139554

Epoch: 5| Step: 8
Training loss: 3.146618338822623
Validation loss: 3.2502660066648805

Epoch: 5| Step: 9
Training loss: 3.6995524625495904
Validation loss: 3.2459437549856087

Epoch: 5| Step: 10
Training loss: 4.072501445135395
Validation loss: 3.2456585636913973

Epoch: 109| Step: 0
Training loss: 3.842266633908605
Validation loss: 3.246567343462953

Epoch: 5| Step: 1
Training loss: 3.6482566118835917
Validation loss: 3.2456475584470588

Epoch: 5| Step: 2
Training loss: 3.3061260582348417
Validation loss: 3.2469197088426696

Epoch: 5| Step: 3
Training loss: 3.797609988058137
Validation loss: 3.24531405253941

Epoch: 5| Step: 4
Training loss: 3.7162864923979018
Validation loss: 3.2454628823049996

Epoch: 5| Step: 5
Training loss: 3.289543207337373
Validation loss: 3.243981864040335

Epoch: 5| Step: 6
Training loss: 3.8611675840741086
Validation loss: 3.2466416057111243

Epoch: 5| Step: 7
Training loss: 2.9525775704784425
Validation loss: 3.245065811457243

Epoch: 5| Step: 8
Training loss: 3.8484754590707504
Validation loss: 3.2458358872897084

Epoch: 5| Step: 9
Training loss: 2.7846975497206894
Validation loss: 3.246359366015597

Epoch: 5| Step: 10
Training loss: 3.0187919471622195
Validation loss: 3.248950384888893

Epoch: 110| Step: 0
Training loss: 3.8019706535190045
Validation loss: 3.245565083090993

Epoch: 5| Step: 1
Training loss: 3.6541032275989713
Validation loss: 3.2458680708979837

Epoch: 5| Step: 2
Training loss: 3.348894813769738
Validation loss: 3.2466365931457433

Epoch: 5| Step: 3
Training loss: 3.5840622064522316
Validation loss: 3.244881898188385

Epoch: 5| Step: 4
Training loss: 3.4990491937982404
Validation loss: 3.2452492316334958

Epoch: 5| Step: 5
Training loss: 3.453120304984789
Validation loss: 3.2450972636539346

Epoch: 5| Step: 6
Training loss: 4.3635113961936565
Validation loss: 3.244481447468842

Epoch: 5| Step: 7
Training loss: 3.1155512059692745
Validation loss: 3.2417512578693444

Epoch: 5| Step: 8
Training loss: 2.0277019323973504
Validation loss: 3.241756554775116

Epoch: 5| Step: 9
Training loss: 3.4173294603035846
Validation loss: 3.242010584152032

Epoch: 5| Step: 10
Training loss: 3.6026420382070357
Validation loss: 3.240680942429692

Epoch: 111| Step: 0
Training loss: 3.6239418590083843
Validation loss: 3.2400770604803664

Epoch: 5| Step: 1
Training loss: 3.196249826705027
Validation loss: 3.241672296727677

Epoch: 5| Step: 2
Training loss: 3.7405201934689543
Validation loss: 3.2402944020199262

Epoch: 5| Step: 3
Training loss: 3.532184848428349
Validation loss: 3.239534727793061

Epoch: 5| Step: 4
Training loss: 3.2980855012154606
Validation loss: 3.239956090493618

Epoch: 5| Step: 5
Training loss: 4.088969460559671
Validation loss: 3.2395551337571202

Epoch: 5| Step: 6
Training loss: 3.337848482262122
Validation loss: 3.236889054355646

Epoch: 5| Step: 7
Training loss: 3.3958286839240763
Validation loss: 3.237826574764245

Epoch: 5| Step: 8
Training loss: 3.6054594922179355
Validation loss: 3.2410321348189677

Epoch: 5| Step: 9
Training loss: 3.249197347267361
Validation loss: 3.240406854549658

Epoch: 5| Step: 10
Training loss: 3.0247870693456047
Validation loss: 3.2422576481583767

Epoch: 112| Step: 0
Training loss: 3.0961564078140413
Validation loss: 3.2391689671119916

Epoch: 5| Step: 1
Training loss: 3.6385489508054207
Validation loss: 3.2409211531380624

Epoch: 5| Step: 2
Training loss: 2.3883051368484676
Validation loss: 3.2416825839440953

Epoch: 5| Step: 3
Training loss: 3.666855778296731
Validation loss: 3.240371510621723

Epoch: 5| Step: 4
Training loss: 3.7321443798925142
Validation loss: 3.2390333366328727

Epoch: 5| Step: 5
Training loss: 3.837803031562436
Validation loss: 3.239854762013521

Epoch: 5| Step: 6
Training loss: 4.154464911975306
Validation loss: 3.2365714152225333

Epoch: 5| Step: 7
Training loss: 2.7363200218195063
Validation loss: 3.2382500930008264

Epoch: 5| Step: 8
Training loss: 4.083826515361341
Validation loss: 3.237477863182398

Epoch: 5| Step: 9
Training loss: 2.870835148589765
Validation loss: 3.2383373913754228

Epoch: 5| Step: 10
Training loss: 3.6367778834729876
Validation loss: 3.2345705643487275

Epoch: 113| Step: 0
Training loss: 2.9224268754176017
Validation loss: 3.234542180518654

Epoch: 5| Step: 1
Training loss: 3.207829588609043
Validation loss: 3.2353262821838418

Epoch: 5| Step: 2
Training loss: 3.7378574876555235
Validation loss: 3.2349593910865866

Epoch: 5| Step: 3
Training loss: 3.6034818818288037
Validation loss: 3.2354474918325513

Epoch: 5| Step: 4
Training loss: 3.782241565173253
Validation loss: 3.236935804640903

Epoch: 5| Step: 5
Training loss: 3.8070968111883814
Validation loss: 3.2361364297763786

Epoch: 5| Step: 6
Training loss: 2.789456892578589
Validation loss: 3.234449794230057

Epoch: 5| Step: 7
Training loss: 3.942676592774249
Validation loss: 3.233783387426253

Epoch: 5| Step: 8
Training loss: 3.2085110668807717
Validation loss: 3.234051328806407

Epoch: 5| Step: 9
Training loss: 3.409394798605939
Validation loss: 3.2353054834606763

Epoch: 5| Step: 10
Training loss: 3.6448672222553036
Validation loss: 3.2312764111704517

Epoch: 114| Step: 0
Training loss: 3.83744406395321
Validation loss: 3.236443040996483

Epoch: 5| Step: 1
Training loss: 3.4575415627938972
Validation loss: 3.2327870683786823

Epoch: 5| Step: 2
Training loss: 3.1076621700577443
Validation loss: 3.2321951826035566

Epoch: 5| Step: 3
Training loss: 3.245775999085993
Validation loss: 3.2320210004699113

Epoch: 5| Step: 4
Training loss: 3.2767682667138174
Validation loss: 3.2328591587574955

Epoch: 5| Step: 5
Training loss: 3.257138262532753
Validation loss: 3.2332374966618973

Epoch: 5| Step: 6
Training loss: 3.901251684968897
Validation loss: 3.2309721970444727

Epoch: 5| Step: 7
Training loss: 3.6371658329007364
Validation loss: 3.2318266636805038

Epoch: 5| Step: 8
Training loss: 2.5089027197882423
Validation loss: 3.2267543349648684

Epoch: 5| Step: 9
Training loss: 4.187578342900546
Validation loss: 3.2306543197648643

Epoch: 5| Step: 10
Training loss: 3.5446817616252564
Validation loss: 3.230566474924477

Epoch: 115| Step: 0
Training loss: 4.020637204356137
Validation loss: 3.2295833867875587

Epoch: 5| Step: 1
Training loss: 3.333515511938554
Validation loss: 3.228289500068792

Epoch: 5| Step: 2
Training loss: 3.2820297041437385
Validation loss: 3.230994213841166

Epoch: 5| Step: 3
Training loss: 3.3434730486393245
Validation loss: 3.230702089487765

Epoch: 5| Step: 4
Training loss: 3.512411182950429
Validation loss: 3.231303548731142

Epoch: 5| Step: 5
Training loss: 3.049959939162015
Validation loss: 3.230923606900032

Epoch: 5| Step: 6
Training loss: 3.3575756843313576
Validation loss: 3.2299014670928896

Epoch: 5| Step: 7
Training loss: 3.0433327453490153
Validation loss: 3.2330690005860383

Epoch: 5| Step: 8
Training loss: 3.6635551833459394
Validation loss: 3.232482483295655

Epoch: 5| Step: 9
Training loss: 3.448893997266707
Validation loss: 3.2317924871949897

Epoch: 5| Step: 10
Training loss: 4.097229388961702
Validation loss: 3.232194570285721

Epoch: 116| Step: 0
Training loss: 3.2652337967029785
Validation loss: 3.230510979376501

Epoch: 5| Step: 1
Training loss: 3.375493613986186
Validation loss: 3.2288112120568786

Epoch: 5| Step: 2
Training loss: 3.6014841199442955
Validation loss: 3.227113673053098

Epoch: 5| Step: 3
Training loss: 3.785812525746955
Validation loss: 3.2287274689494243

Epoch: 5| Step: 4
Training loss: 3.16595116278453
Validation loss: 3.2280478919479565

Epoch: 5| Step: 5
Training loss: 3.8642446090168034
Validation loss: 3.227740732646786

Epoch: 5| Step: 6
Training loss: 3.6270864335860677
Validation loss: 3.2266678109006377

Epoch: 5| Step: 7
Training loss: 3.49891182468338
Validation loss: 3.2281796940100014

Epoch: 5| Step: 8
Training loss: 3.4750255830769867
Validation loss: 3.226286495955366

Epoch: 5| Step: 9
Training loss: 3.1733582885412757
Validation loss: 3.225091667045839

Epoch: 5| Step: 10
Training loss: 3.2303217308973147
Validation loss: 3.225025593887475

Epoch: 117| Step: 0
Training loss: 3.6843699732674176
Validation loss: 3.2244471463484317

Epoch: 5| Step: 1
Training loss: 3.5926278394067577
Validation loss: 3.22475738115166

Epoch: 5| Step: 2
Training loss: 2.965520768901498
Validation loss: 3.2230461982977303

Epoch: 5| Step: 3
Training loss: 3.144819201441224
Validation loss: 3.2244580784547376

Epoch: 5| Step: 4
Training loss: 3.3625043620822224
Validation loss: 3.2240326482689783

Epoch: 5| Step: 5
Training loss: 3.3536131660792656
Validation loss: 3.2240000319914865

Epoch: 5| Step: 6
Training loss: 3.1619511848074096
Validation loss: 3.2244090450843044

Epoch: 5| Step: 7
Training loss: 3.7680935821008
Validation loss: 3.2251609358903357

Epoch: 5| Step: 8
Training loss: 3.643250922282851
Validation loss: 3.22327070506882

Epoch: 5| Step: 9
Training loss: 3.194028115900606
Validation loss: 3.2230131433076212

Epoch: 5| Step: 10
Training loss: 4.2163130892148155
Validation loss: 3.2250703539896723

Epoch: 118| Step: 0
Training loss: 2.759889852288518
Validation loss: 3.2217733677928946

Epoch: 5| Step: 1
Training loss: 3.896532835694887
Validation loss: 3.2210649130083806

Epoch: 5| Step: 2
Training loss: 3.842415554729479
Validation loss: 3.2219328841163852

Epoch: 5| Step: 3
Training loss: 3.5054412507452977
Validation loss: 3.222909326942244

Epoch: 5| Step: 4
Training loss: 3.9881829708293823
Validation loss: 3.2215227361890797

Epoch: 5| Step: 5
Training loss: 3.365406388432422
Validation loss: 3.2220161354639294

Epoch: 5| Step: 6
Training loss: 2.933629671935943
Validation loss: 3.2221454313710884

Epoch: 5| Step: 7
Training loss: 3.4981271637648663
Validation loss: 3.2203290335484582

Epoch: 5| Step: 8
Training loss: 3.0171599755792373
Validation loss: 3.2217544112172565

Epoch: 5| Step: 9
Training loss: 3.4607096095435272
Validation loss: 3.220353708760176

Epoch: 5| Step: 10
Training loss: 3.6497586000645463
Validation loss: 3.2195100142891566

Epoch: 119| Step: 0
Training loss: 3.3192223049375174
Validation loss: 3.219485925050016

Epoch: 5| Step: 1
Training loss: 3.192286319855569
Validation loss: 3.220446938053306

Epoch: 5| Step: 2
Training loss: 2.8988943228380903
Validation loss: 3.218345166625148

Epoch: 5| Step: 3
Training loss: 3.855658962268991
Validation loss: 3.2187272312065067

Epoch: 5| Step: 4
Training loss: 3.674645729894839
Validation loss: 3.219249488663223

Epoch: 5| Step: 5
Training loss: 3.36541630656653
Validation loss: 3.2237519838589077

Epoch: 5| Step: 6
Training loss: 3.778944337158822
Validation loss: 3.2195084233156135

Epoch: 5| Step: 7
Training loss: 3.143462763683941
Validation loss: 3.2205319591789587

Epoch: 5| Step: 8
Training loss: 3.585478310698825
Validation loss: 3.219544980472138

Epoch: 5| Step: 9
Training loss: 3.6638321468601984
Validation loss: 3.218418668584224

Epoch: 5| Step: 10
Training loss: 3.5164007390675547
Validation loss: 3.217867170965368

Epoch: 120| Step: 0
Training loss: 3.2167150490503675
Validation loss: 3.2180391811676947

Epoch: 5| Step: 1
Training loss: 3.4592597976703514
Validation loss: 3.22103909714216

Epoch: 5| Step: 2
Training loss: 4.15971195911011
Validation loss: 3.221927611909496

Epoch: 5| Step: 3
Training loss: 3.4547493682801123
Validation loss: 3.2215059315457695

Epoch: 5| Step: 4
Training loss: 2.808034276084696
Validation loss: 3.2204534115351224

Epoch: 5| Step: 5
Training loss: 3.3094672949351103
Validation loss: 3.2270771285504205

Epoch: 5| Step: 6
Training loss: 3.2327182230562834
Validation loss: 3.2212669940457417

Epoch: 5| Step: 7
Training loss: 3.451504978928449
Validation loss: 3.2178561224579316

Epoch: 5| Step: 8
Training loss: 3.3886209357662707
Validation loss: 3.218375472825178

Epoch: 5| Step: 9
Training loss: 3.186761209476729
Validation loss: 3.2148311297112744

Epoch: 5| Step: 10
Training loss: 4.291232979104843
Validation loss: 3.2149955165349953

Epoch: 121| Step: 0
Training loss: 3.3675998514915078
Validation loss: 3.214317425322217

Epoch: 5| Step: 1
Training loss: 3.955901606980245
Validation loss: 3.2155416802590793

Epoch: 5| Step: 2
Training loss: 3.8119102397089764
Validation loss: 3.2160995869995936

Epoch: 5| Step: 3
Training loss: 4.200291923187034
Validation loss: 3.213050899877217

Epoch: 5| Step: 4
Training loss: 3.4221266562534516
Validation loss: 3.217080002928924

Epoch: 5| Step: 5
Training loss: 3.326218179681726
Validation loss: 3.2130412390880028

Epoch: 5| Step: 6
Training loss: 2.4569844785765964
Validation loss: 3.2141978124386053

Epoch: 5| Step: 7
Training loss: 4.10374941697757
Validation loss: 3.215344253706047

Epoch: 5| Step: 8
Training loss: 2.8482832774285294
Validation loss: 3.214302393500016

Epoch: 5| Step: 9
Training loss: 3.1220338095594395
Validation loss: 3.2131069890093276

Epoch: 5| Step: 10
Training loss: 2.9090975685476894
Validation loss: 3.2150485225320207

Epoch: 122| Step: 0
Training loss: 3.2922773800653613
Validation loss: 3.216001666396898

Epoch: 5| Step: 1
Training loss: 3.3565899326931974
Validation loss: 3.2139316913228164

Epoch: 5| Step: 2
Training loss: 3.2256271817015727
Validation loss: 3.214707940140828

Epoch: 5| Step: 3
Training loss: 3.284877987574198
Validation loss: 3.2142754019229836

Epoch: 5| Step: 4
Training loss: 3.511129531396225
Validation loss: 3.214140370447834

Epoch: 5| Step: 5
Training loss: 4.32007872792315
Validation loss: 3.2158536861602904

Epoch: 5| Step: 6
Training loss: 3.0178511708991325
Validation loss: 3.2143724148567228

Epoch: 5| Step: 7
Training loss: 3.2694918722427087
Validation loss: 3.2145076997666804

Epoch: 5| Step: 8
Training loss: 3.2690372435652817
Validation loss: 3.2158207892234603

Epoch: 5| Step: 9
Training loss: 3.8346432368960297
Validation loss: 3.213882287564935

Epoch: 5| Step: 10
Training loss: 3.4412844546498826
Validation loss: 3.2128907718179036

Epoch: 123| Step: 0
Training loss: 3.2698162141534532
Validation loss: 3.2126473975678613

Epoch: 5| Step: 1
Training loss: 3.545776869387428
Validation loss: 3.212167572369287

Epoch: 5| Step: 2
Training loss: 3.8486626717552053
Validation loss: 3.214977215332586

Epoch: 5| Step: 3
Training loss: 2.8282351814852262
Validation loss: 3.210590947943415

Epoch: 5| Step: 4
Training loss: 3.8382711673218246
Validation loss: 3.2099237488686203

Epoch: 5| Step: 5
Training loss: 3.3175889277666903
Validation loss: 3.213238524707664

Epoch: 5| Step: 6
Training loss: 3.32771907712875
Validation loss: 3.2096115722782277

Epoch: 5| Step: 7
Training loss: 3.9416711905347954
Validation loss: 3.211168866531653

Epoch: 5| Step: 8
Training loss: 3.399368334043195
Validation loss: 3.208794226034663

Epoch: 5| Step: 9
Training loss: 3.048800598450369
Validation loss: 3.210635943616638

Epoch: 5| Step: 10
Training loss: 3.449772376692232
Validation loss: 3.2093484761718227

Epoch: 124| Step: 0
Training loss: 3.3180916573233667
Validation loss: 3.208546910383921

Epoch: 5| Step: 1
Training loss: 3.675223653825662
Validation loss: 3.2094675141436233

Epoch: 5| Step: 2
Training loss: 3.058116344546464
Validation loss: 3.207860058088788

Epoch: 5| Step: 3
Training loss: 4.197977196546524
Validation loss: 3.2094822075659226

Epoch: 5| Step: 4
Training loss: 2.952333051465797
Validation loss: 3.209601687074162

Epoch: 5| Step: 5
Training loss: 3.127056818236986
Validation loss: 3.207689819768006

Epoch: 5| Step: 6
Training loss: 4.068636206751071
Validation loss: 3.2101239301794062

Epoch: 5| Step: 7
Training loss: 3.7834849412652947
Validation loss: 3.2112383758264667

Epoch: 5| Step: 8
Training loss: 3.3481732640251187
Validation loss: 3.209076614057335

Epoch: 5| Step: 9
Training loss: 2.204042284315854
Validation loss: 3.208531059710713

Epoch: 5| Step: 10
Training loss: 3.8182053947133676
Validation loss: 3.207735971028099

Epoch: 125| Step: 0
Training loss: 3.743592191754992
Validation loss: 3.2067593241446333

Epoch: 5| Step: 1
Training loss: 2.7063874419024443
Validation loss: 3.206822417640399

Epoch: 5| Step: 2
Training loss: 2.837774013110858
Validation loss: 3.205513404609394

Epoch: 5| Step: 3
Training loss: 3.210592803645126
Validation loss: 3.2069057079156655

Epoch: 5| Step: 4
Training loss: 3.427312702206149
Validation loss: 3.2082441759979083

Epoch: 5| Step: 5
Training loss: 3.4767569841142065
Validation loss: 3.2048247486778605

Epoch: 5| Step: 6
Training loss: 3.8032227502828495
Validation loss: 3.2044696209598316

Epoch: 5| Step: 7
Training loss: 3.7006150121156223
Validation loss: 3.20402639588116

Epoch: 5| Step: 8
Training loss: 3.299920578203168
Validation loss: 3.2052349689519657

Epoch: 5| Step: 9
Training loss: 4.062986374130141
Validation loss: 3.2045345675468364

Epoch: 5| Step: 10
Training loss: 3.4823436888744697
Validation loss: 3.205594742344218

Epoch: 126| Step: 0
Training loss: 3.816160976997165
Validation loss: 3.203632039082832

Epoch: 5| Step: 1
Training loss: 3.4819554708176317
Validation loss: 3.2051427697102413

Epoch: 5| Step: 2
Training loss: 3.180970029371353
Validation loss: 3.202889521777388

Epoch: 5| Step: 3
Training loss: 3.421097619228087
Validation loss: 3.209766541396598

Epoch: 5| Step: 4
Training loss: 2.691491113218957
Validation loss: 3.2176691118710603

Epoch: 5| Step: 5
Training loss: 4.108676401377971
Validation loss: 3.2212045519599104

Epoch: 5| Step: 6
Training loss: 3.3303344269952655
Validation loss: 3.2069329166054312

Epoch: 5| Step: 7
Training loss: 3.509932864815955
Validation loss: 3.205264655276404

Epoch: 5| Step: 8
Training loss: 2.6964068416416422
Validation loss: 3.2029652049185993

Epoch: 5| Step: 9
Training loss: 3.7289087359062267
Validation loss: 3.2015210193221417

Epoch: 5| Step: 10
Training loss: 3.7895179081589423
Validation loss: 3.20218473970907

Epoch: 127| Step: 0
Training loss: 3.583793048793017
Validation loss: 3.2035385669208303

Epoch: 5| Step: 1
Training loss: 3.7978799376993475
Validation loss: 3.205449402395788

Epoch: 5| Step: 2
Training loss: 3.0316345914710126
Validation loss: 3.20053815213288

Epoch: 5| Step: 3
Training loss: 3.0033625196195297
Validation loss: 3.202003821822783

Epoch: 5| Step: 4
Training loss: 2.9752758379090682
Validation loss: 3.20044931566316

Epoch: 5| Step: 5
Training loss: 2.560084250971111
Validation loss: 3.2018314305694933

Epoch: 5| Step: 6
Training loss: 3.6591886790572072
Validation loss: 3.1981603052572196

Epoch: 5| Step: 7
Training loss: 3.010592199221716
Validation loss: 3.1995028517225546

Epoch: 5| Step: 8
Training loss: 3.7379210167995836
Validation loss: 3.2001764684325824

Epoch: 5| Step: 9
Training loss: 3.830528158917165
Validation loss: 3.2011723779302566

Epoch: 5| Step: 10
Training loss: 4.5027690421151805
Validation loss: 3.200559120720513

Epoch: 128| Step: 0
Training loss: 3.9840469524496984
Validation loss: 3.201241225773922

Epoch: 5| Step: 1
Training loss: 3.1978021822803657
Validation loss: 3.1977211033066983

Epoch: 5| Step: 2
Training loss: 3.0802668366710075
Validation loss: 3.2008501868616124

Epoch: 5| Step: 3
Training loss: 3.7486969273274284
Validation loss: 3.203072187266945

Epoch: 5| Step: 4
Training loss: 3.999058851148141
Validation loss: 3.198698030068451

Epoch: 5| Step: 5
Training loss: 2.662648650841787
Validation loss: 3.201549857657878

Epoch: 5| Step: 6
Training loss: 2.523571565922738
Validation loss: 3.2030059015966157

Epoch: 5| Step: 7
Training loss: 3.3949432298635838
Validation loss: 3.2157630716888606

Epoch: 5| Step: 8
Training loss: 3.6559311165278245
Validation loss: 3.2363078412755777

Epoch: 5| Step: 9
Training loss: 3.483670971825756
Validation loss: 3.2700158108552317

Epoch: 5| Step: 10
Training loss: 4.000764296945872
Validation loss: 3.230940023750582

Epoch: 129| Step: 0
Training loss: 3.8645595059684226
Validation loss: 3.200039533786216

Epoch: 5| Step: 1
Training loss: 3.1108490023630093
Validation loss: 3.196712701090846

Epoch: 5| Step: 2
Training loss: 3.5335880067800995
Validation loss: 3.1949791015132036

Epoch: 5| Step: 3
Training loss: 3.0363036825711966
Validation loss: 3.1945521088787587

Epoch: 5| Step: 4
Training loss: 3.3810891217160806
Validation loss: 3.197653261200247

Epoch: 5| Step: 5
Training loss: 3.5232986456668156
Validation loss: 3.1980437843738105

Epoch: 5| Step: 6
Training loss: 3.6481413302399996
Validation loss: 3.198791529070225

Epoch: 5| Step: 7
Training loss: 3.3898635220132354
Validation loss: 3.1989375786244554

Epoch: 5| Step: 8
Training loss: 3.7220113862205304
Validation loss: 3.19432446250164

Epoch: 5| Step: 9
Training loss: 3.9119131312330384
Validation loss: 3.193752600957354

Epoch: 5| Step: 10
Training loss: 2.5263046180222943
Validation loss: 3.189578931244186

Epoch: 130| Step: 0
Training loss: 3.1235738933451693
Validation loss: 3.1919892700170815

Epoch: 5| Step: 1
Training loss: 3.9063933079181186
Validation loss: 3.193622274353032

Epoch: 5| Step: 2
Training loss: 3.9399364139053916
Validation loss: 3.189681961351064

Epoch: 5| Step: 3
Training loss: 3.4308537822488003
Validation loss: 3.1959380792002605

Epoch: 5| Step: 4
Training loss: 3.278997029267385
Validation loss: 3.2008222248491536

Epoch: 5| Step: 5
Training loss: 3.8730290230220823
Validation loss: 3.2100218133469873

Epoch: 5| Step: 6
Training loss: 3.849856975920844
Validation loss: 3.206847853908335

Epoch: 5| Step: 7
Training loss: 2.700317512492545
Validation loss: 3.2043330505902596

Epoch: 5| Step: 8
Training loss: 3.4404159662567
Validation loss: 3.19486239961056

Epoch: 5| Step: 9
Training loss: 3.239219244381489
Validation loss: 3.1913369570223424

Epoch: 5| Step: 10
Training loss: 2.812353511810104
Validation loss: 3.1908378922875835

Epoch: 131| Step: 0
Training loss: 3.121103222275207
Validation loss: 3.189645164807086

Epoch: 5| Step: 1
Training loss: 2.704977029501925
Validation loss: 3.18998307233273

Epoch: 5| Step: 2
Training loss: 4.199735842072508
Validation loss: 3.1906370184130477

Epoch: 5| Step: 3
Training loss: 2.8893736734125226
Validation loss: 3.192232865227888

Epoch: 5| Step: 4
Training loss: 4.100361384770588
Validation loss: 3.1887741694963427

Epoch: 5| Step: 5
Training loss: 3.4871142102226473
Validation loss: 3.1911638127914594

Epoch: 5| Step: 6
Training loss: 3.8587775752568554
Validation loss: 3.1873286179263367

Epoch: 5| Step: 7
Training loss: 2.8597116741150366
Validation loss: 3.190935794535018

Epoch: 5| Step: 8
Training loss: 2.463353209649794
Validation loss: 3.189851600772914

Epoch: 5| Step: 9
Training loss: 4.078863435150462
Validation loss: 3.1908260801192254

Epoch: 5| Step: 10
Training loss: 3.592593993972849
Validation loss: 3.1895833165295144

Epoch: 132| Step: 0
Training loss: 2.9530815646090587
Validation loss: 3.190054148251959

Epoch: 5| Step: 1
Training loss: 3.4665425467890527
Validation loss: 3.188012495508341

Epoch: 5| Step: 2
Training loss: 3.3390238508416283
Validation loss: 3.187231455876595

Epoch: 5| Step: 3
Training loss: 3.1370449632870376
Validation loss: 3.191036271048905

Epoch: 5| Step: 4
Training loss: 3.3281106724676928
Validation loss: 3.1877616310076937

Epoch: 5| Step: 5
Training loss: 3.242142789601356
Validation loss: 3.1867109090466355

Epoch: 5| Step: 6
Training loss: 3.041282490197296
Validation loss: 3.1882581241543484

Epoch: 5| Step: 7
Training loss: 4.396405199406461
Validation loss: 3.1901542217989474

Epoch: 5| Step: 8
Training loss: 3.268589845895088
Validation loss: 3.19092292221926

Epoch: 5| Step: 9
Training loss: 3.2503025207571725
Validation loss: 3.187351624688699

Epoch: 5| Step: 10
Training loss: 4.2468712453706265
Validation loss: 3.1874119655766497

Epoch: 133| Step: 0
Training loss: 3.346706616237954
Validation loss: 3.191209118535525

Epoch: 5| Step: 1
Training loss: 3.1868159738248756
Validation loss: 3.1911711353731107

Epoch: 5| Step: 2
Training loss: 4.3497828023772
Validation loss: 3.190634014971055

Epoch: 5| Step: 3
Training loss: 3.3298924011167594
Validation loss: 3.1904426582303

Epoch: 5| Step: 4
Training loss: 2.279132016585138
Validation loss: 3.1882281548433693

Epoch: 5| Step: 5
Training loss: 3.668400715670247
Validation loss: 3.1895487758142336

Epoch: 5| Step: 6
Training loss: 2.852193684157982
Validation loss: 3.1895392246866527

Epoch: 5| Step: 7
Training loss: 3.8228227290254657
Validation loss: 3.1888249712003014

Epoch: 5| Step: 8
Training loss: 3.7567705704525736
Validation loss: 3.188536554059961

Epoch: 5| Step: 9
Training loss: 2.8174365483122896
Validation loss: 3.189138492820864

Epoch: 5| Step: 10
Training loss: 3.9518580159153114
Validation loss: 3.188644975645694

Epoch: 134| Step: 0
Training loss: 3.5620286863993575
Validation loss: 3.187051590728369

Epoch: 5| Step: 1
Training loss: 3.589859955162689
Validation loss: 3.1906135998468663

Epoch: 5| Step: 2
Training loss: 3.482142669901301
Validation loss: 3.185022944308187

Epoch: 5| Step: 3
Training loss: 3.8356952163413056
Validation loss: 3.188599635076585

Epoch: 5| Step: 4
Training loss: 3.537388555166391
Validation loss: 3.1865842574685423

Epoch: 5| Step: 5
Training loss: 3.7453079115386343
Validation loss: 3.185976285559102

Epoch: 5| Step: 6
Training loss: 4.173597344608351
Validation loss: 3.185383614659878

Epoch: 5| Step: 7
Training loss: 3.582524289609846
Validation loss: 3.1864310090060446

Epoch: 5| Step: 8
Training loss: 2.4398843889519473
Validation loss: 3.1866022462735386

Epoch: 5| Step: 9
Training loss: 2.4518192971247235
Validation loss: 3.1842210582559747

Epoch: 5| Step: 10
Training loss: 2.8092580972520698
Validation loss: 3.184579885775394

Epoch: 135| Step: 0
Training loss: 3.544614903633888
Validation loss: 3.185817307331572

Epoch: 5| Step: 1
Training loss: 2.858173055205191
Validation loss: 3.1840546880814595

Epoch: 5| Step: 2
Training loss: 3.5096474247104035
Validation loss: 3.185420635878737

Epoch: 5| Step: 3
Training loss: 3.552722429671713
Validation loss: 3.1898309089934402

Epoch: 5| Step: 4
Training loss: 3.224062932813001
Validation loss: 3.192930827305552

Epoch: 5| Step: 5
Training loss: 3.350939855114928
Validation loss: 3.1979557804688343

Epoch: 5| Step: 6
Training loss: 3.605243117855268
Validation loss: 3.1897184231230367

Epoch: 5| Step: 7
Training loss: 3.5603066100195124
Validation loss: 3.186982420260227

Epoch: 5| Step: 8
Training loss: 3.7089659904839913
Validation loss: 3.1827918518331946

Epoch: 5| Step: 9
Training loss: 3.644367308368917
Validation loss: 3.182089058794005

Epoch: 5| Step: 10
Training loss: 3.0231935072434197
Validation loss: 3.1818089938900074

Epoch: 136| Step: 0
Training loss: 3.3991893418972516
Validation loss: 3.18107850092609

Epoch: 5| Step: 1
Training loss: 3.0869525254148367
Validation loss: 3.180276382884586

Epoch: 5| Step: 2
Training loss: 3.192470639182678
Validation loss: 3.181544138540573

Epoch: 5| Step: 3
Training loss: 3.946947782423803
Validation loss: 3.181922670605599

Epoch: 5| Step: 4
Training loss: 4.283443585076522
Validation loss: 3.1820962354897566

Epoch: 5| Step: 5
Training loss: 3.6860910083714793
Validation loss: 3.182444972946864

Epoch: 5| Step: 6
Training loss: 2.943693571096546
Validation loss: 3.1814440068940417

Epoch: 5| Step: 7
Training loss: 3.3558922035264263
Validation loss: 3.178594519853041

Epoch: 5| Step: 8
Training loss: 3.2708517345388706
Validation loss: 3.179164377729213

Epoch: 5| Step: 9
Training loss: 2.5948904816260168
Validation loss: 3.179834381852735

Epoch: 5| Step: 10
Training loss: 3.689627470114713
Validation loss: 3.178779429855326

Epoch: 137| Step: 0
Training loss: 4.483614016306131
Validation loss: 3.177252950163432

Epoch: 5| Step: 1
Training loss: 3.50118371837434
Validation loss: 3.180205589846708

Epoch: 5| Step: 2
Training loss: 3.4985319873611784
Validation loss: 3.1791515625821325

Epoch: 5| Step: 3
Training loss: 3.0453869438173604
Validation loss: 3.1797944673471585

Epoch: 5| Step: 4
Training loss: 3.6077258813768336
Validation loss: 3.1779485214717673

Epoch: 5| Step: 5
Training loss: 3.7062844749249653
Validation loss: 3.177316097055668

Epoch: 5| Step: 6
Training loss: 3.3678453692279686
Validation loss: 3.1788610919507456

Epoch: 5| Step: 7
Training loss: 2.76954519593853
Validation loss: 3.1779561382930304

Epoch: 5| Step: 8
Training loss: 2.318049705025119
Validation loss: 3.183795345246673

Epoch: 5| Step: 9
Training loss: 3.19609437064587
Validation loss: 3.188746956204482

Epoch: 5| Step: 10
Training loss: 3.8254756556942784
Validation loss: 3.1874257448423697

Epoch: 138| Step: 0
Training loss: 2.8098362494165308
Validation loss: 3.18305660336307

Epoch: 5| Step: 1
Training loss: 3.008244154040663
Validation loss: 3.180930794822791

Epoch: 5| Step: 2
Training loss: 3.925478795485171
Validation loss: 3.179316602436151

Epoch: 5| Step: 3
Training loss: 2.822212403531487
Validation loss: 3.1782074250766272

Epoch: 5| Step: 4
Training loss: 2.9338091124864105
Validation loss: 3.1791081292356003

Epoch: 5| Step: 5
Training loss: 4.091105065323742
Validation loss: 3.1775350399184155

Epoch: 5| Step: 6
Training loss: 3.6887391158292067
Validation loss: 3.1755446047284206

Epoch: 5| Step: 7
Training loss: 3.329418522009834
Validation loss: 3.176060853603529

Epoch: 5| Step: 8
Training loss: 3.7387465423598605
Validation loss: 3.1752066624033786

Epoch: 5| Step: 9
Training loss: 3.6267267258196356
Validation loss: 3.174861544367065

Epoch: 5| Step: 10
Training loss: 3.3521306905647306
Validation loss: 3.174219884126652

Epoch: 139| Step: 0
Training loss: 3.6107860630819943
Validation loss: 3.1749564494300913

Epoch: 5| Step: 1
Training loss: 3.395220196062184
Validation loss: 3.173438847676438

Epoch: 5| Step: 2
Training loss: 3.779573936065227
Validation loss: 3.1746287681069925

Epoch: 5| Step: 3
Training loss: 3.592182912404639
Validation loss: 3.1726853766904024

Epoch: 5| Step: 4
Training loss: 3.3436744182279927
Validation loss: 3.174782149411896

Epoch: 5| Step: 5
Training loss: 2.8049109749767758
Validation loss: 3.1740864277902636

Epoch: 5| Step: 6
Training loss: 3.9209035452955523
Validation loss: 3.1710537171963105

Epoch: 5| Step: 7
Training loss: 3.418547663027334
Validation loss: 3.1713899485740016

Epoch: 5| Step: 8
Training loss: 3.259413657320342
Validation loss: 3.172186952901595

Epoch: 5| Step: 9
Training loss: 3.0085159866240465
Validation loss: 3.169692042347497

Epoch: 5| Step: 10
Training loss: 3.3708446494636726
Validation loss: 3.1716046576004473

Epoch: 140| Step: 0
Training loss: 3.7090726965441796
Validation loss: 3.172537990926258

Epoch: 5| Step: 1
Training loss: 3.689234051074282
Validation loss: 3.170709600882157

Epoch: 5| Step: 2
Training loss: 3.6799184155750093
Validation loss: 3.1702862105606258

Epoch: 5| Step: 3
Training loss: 3.7748462266739
Validation loss: 3.1721017634118125

Epoch: 5| Step: 4
Training loss: 2.9018215772487674
Validation loss: 3.170730008327036

Epoch: 5| Step: 5
Training loss: 3.843917967064908
Validation loss: 3.1738111074037154

Epoch: 5| Step: 6
Training loss: 3.3482467504471476
Validation loss: 3.1723878119501543

Epoch: 5| Step: 7
Training loss: 2.6522265311450615
Validation loss: 3.1729224436685293

Epoch: 5| Step: 8
Training loss: 3.7778105422699713
Validation loss: 3.174675978176385

Epoch: 5| Step: 9
Training loss: 2.8417027408700335
Validation loss: 3.1716049494004435

Epoch: 5| Step: 10
Training loss: 3.064723861726014
Validation loss: 3.170436028179887

Epoch: 141| Step: 0
Training loss: 3.3590329018219607
Validation loss: 3.170305768422925

Epoch: 5| Step: 1
Training loss: 3.7543005125944817
Validation loss: 3.1679279681894457

Epoch: 5| Step: 2
Training loss: 4.050510732212971
Validation loss: 3.16967899640865

Epoch: 5| Step: 3
Training loss: 3.311712927249614
Validation loss: 3.1692694147823888

Epoch: 5| Step: 4
Training loss: 3.935560687398218
Validation loss: 3.1682951700739483

Epoch: 5| Step: 5
Training loss: 3.56845478500321
Validation loss: 3.165008017164305

Epoch: 5| Step: 6
Training loss: 3.005891102009298
Validation loss: 3.1667200390560617

Epoch: 5| Step: 7
Training loss: 3.2142917905477586
Validation loss: 3.1653986811772845

Epoch: 5| Step: 8
Training loss: 2.8363406732825647
Validation loss: 3.1665246367108995

Epoch: 5| Step: 9
Training loss: 3.0585365338777533
Validation loss: 3.166298298116287

Epoch: 5| Step: 10
Training loss: 3.3009288867685305
Validation loss: 3.1647609023458596

Epoch: 142| Step: 0
Training loss: 3.590600931138393
Validation loss: 3.165827751487622

Epoch: 5| Step: 1
Training loss: 3.5322696260248168
Validation loss: 3.1679189134961723

Epoch: 5| Step: 2
Training loss: 3.9731962273984878
Validation loss: 3.1706227707487677

Epoch: 5| Step: 3
Training loss: 2.9832581032870147
Validation loss: 3.1667057681516577

Epoch: 5| Step: 4
Training loss: 3.1058274163948143
Validation loss: 3.1655070351777987

Epoch: 5| Step: 5
Training loss: 3.4202934337797304
Validation loss: 3.169403673326133

Epoch: 5| Step: 6
Training loss: 3.00935653094589
Validation loss: 3.1659514381007727

Epoch: 5| Step: 7
Training loss: 3.9373876162037154
Validation loss: 3.165338806691803

Epoch: 5| Step: 8
Training loss: 3.1187061253215513
Validation loss: 3.1647191711106095

Epoch: 5| Step: 9
Training loss: 3.297487319563286
Validation loss: 3.1653205302022616

Epoch: 5| Step: 10
Training loss: 3.494053557554824
Validation loss: 3.165576799617717

Epoch: 143| Step: 0
Training loss: 3.817856699448901
Validation loss: 3.1651420539169504

Epoch: 5| Step: 1
Training loss: 3.617243657180843
Validation loss: 3.163172121912756

Epoch: 5| Step: 2
Training loss: 3.2324776359427636
Validation loss: 3.163714419225897

Epoch: 5| Step: 3
Training loss: 3.058994544651321
Validation loss: 3.1621914578631154

Epoch: 5| Step: 4
Training loss: 3.8286989365677475
Validation loss: 3.1621584631528648

Epoch: 5| Step: 5
Training loss: 3.5080310778921318
Validation loss: 3.1633406212254638

Epoch: 5| Step: 6
Training loss: 3.0281178130860757
Validation loss: 3.161184315492508

Epoch: 5| Step: 7
Training loss: 2.7473392619354673
Validation loss: 3.160829074808595

Epoch: 5| Step: 8
Training loss: 3.6029696084465725
Validation loss: 3.1643486619719843

Epoch: 5| Step: 9
Training loss: 3.576977408338043
Validation loss: 3.160797665315016

Epoch: 5| Step: 10
Training loss: 3.4078892954097064
Validation loss: 3.1627874161180127

Epoch: 144| Step: 0
Training loss: 3.343313028179463
Validation loss: 3.162534738732718

Epoch: 5| Step: 1
Training loss: 3.3144771505371864
Validation loss: 3.161048255331924

Epoch: 5| Step: 2
Training loss: 3.59580656169121
Validation loss: 3.159413219008261

Epoch: 5| Step: 3
Training loss: 3.6336948430743945
Validation loss: 3.1628180682459432

Epoch: 5| Step: 4
Training loss: 3.2511054873148053
Validation loss: 3.160806033964914

Epoch: 5| Step: 5
Training loss: 3.708652925471248
Validation loss: 3.1657347713889297

Epoch: 5| Step: 6
Training loss: 3.0196920058477263
Validation loss: 3.16283556485577

Epoch: 5| Step: 7
Training loss: 3.5607271300539374
Validation loss: 3.1638756003428123

Epoch: 5| Step: 8
Training loss: 3.3041239950175423
Validation loss: 3.163201805058065

Epoch: 5| Step: 9
Training loss: 3.6849393844277465
Validation loss: 3.1618183392753374

Epoch: 5| Step: 10
Training loss: 3.010102903565137
Validation loss: 3.161304425868791

Epoch: 145| Step: 0
Training loss: 3.0661285080227736
Validation loss: 3.1601886766617318

Epoch: 5| Step: 1
Training loss: 3.1972888906071657
Validation loss: 3.1596081394240567

Epoch: 5| Step: 2
Training loss: 3.2978209092260626
Validation loss: 3.1581181525096365

Epoch: 5| Step: 3
Training loss: 3.7592655156429227
Validation loss: 3.1602135456382805

Epoch: 5| Step: 4
Training loss: 3.8861742414597615
Validation loss: 3.1588398418303423

Epoch: 5| Step: 5
Training loss: 4.422947190847675
Validation loss: 3.155654898234278

Epoch: 5| Step: 6
Training loss: 2.914990642918639
Validation loss: 3.159022024171111

Epoch: 5| Step: 7
Training loss: 3.18071758259201
Validation loss: 3.1564869823690964

Epoch: 5| Step: 8
Training loss: 3.5638647309737657
Validation loss: 3.1601256142381655

Epoch: 5| Step: 9
Training loss: 2.885569838074496
Validation loss: 3.1606613086773443

Epoch: 5| Step: 10
Training loss: 2.9267762227795173
Validation loss: 3.1607114096682114

Epoch: 146| Step: 0
Training loss: 3.9913430711245024
Validation loss: 3.160048694160132

Epoch: 5| Step: 1
Training loss: 3.3544549442983485
Validation loss: 3.1606757261058234

Epoch: 5| Step: 2
Training loss: 3.5145291803450815
Validation loss: 3.1596159432605115

Epoch: 5| Step: 3
Training loss: 3.239025513602972
Validation loss: 3.1590608053210247

Epoch: 5| Step: 4
Training loss: 3.0404418325582894
Validation loss: 3.1578500258458195

Epoch: 5| Step: 5
Training loss: 3.3439629032413616
Validation loss: 3.155133710631005

Epoch: 5| Step: 6
Training loss: 3.374676441648211
Validation loss: 3.1558419224422822

Epoch: 5| Step: 7
Training loss: 3.475025445858668
Validation loss: 3.1562663357804457

Epoch: 5| Step: 8
Training loss: 3.41300881753001
Validation loss: 3.1574652513244983

Epoch: 5| Step: 9
Training loss: 3.4175914970377894
Validation loss: 3.155629304414704

Epoch: 5| Step: 10
Training loss: 3.2424082485561834
Validation loss: 3.1546847534541547

Epoch: 147| Step: 0
Training loss: 3.247764258553595
Validation loss: 3.1539649509611163

Epoch: 5| Step: 1
Training loss: 3.664063801389028
Validation loss: 3.1521773076769812

Epoch: 5| Step: 2
Training loss: 3.458505158962512
Validation loss: 3.1511708477771547

Epoch: 5| Step: 3
Training loss: 3.5581142801819845
Validation loss: 3.1497002318841463

Epoch: 5| Step: 4
Training loss: 2.9645124207569555
Validation loss: 3.148627174075039

Epoch: 5| Step: 5
Training loss: 2.842128081536853
Validation loss: 3.1495743670521104

Epoch: 5| Step: 6
Training loss: 4.154122173615648
Validation loss: 3.1486923817715504

Epoch: 5| Step: 7
Training loss: 3.2852685934083015
Validation loss: 3.1476434428810225

Epoch: 5| Step: 8
Training loss: 3.927045476243604
Validation loss: 3.1466869121704595

Epoch: 5| Step: 9
Training loss: 2.777165446077434
Validation loss: 3.146927250087828

Epoch: 5| Step: 10
Training loss: 3.268901003090392
Validation loss: 3.143271973795877

Epoch: 148| Step: 0
Training loss: 3.256297831998589
Validation loss: 3.145548017004928

Epoch: 5| Step: 1
Training loss: 3.0888685768551256
Validation loss: 3.1450592574004634

Epoch: 5| Step: 2
Training loss: 3.9541471464092663
Validation loss: 3.1473302155909475

Epoch: 5| Step: 3
Training loss: 2.942075534175067
Validation loss: 3.1442553058306166

Epoch: 5| Step: 4
Training loss: 3.423615034993992
Validation loss: 3.1475258793977656

Epoch: 5| Step: 5
Training loss: 3.8905726662911584
Validation loss: 3.1491249176992677

Epoch: 5| Step: 6
Training loss: 3.1559177639283034
Validation loss: 3.1476422448050143

Epoch: 5| Step: 7
Training loss: 3.6354117990076804
Validation loss: 3.145667043125216

Epoch: 5| Step: 8
Training loss: 3.141484840318846
Validation loss: 3.1487939375780463

Epoch: 5| Step: 9
Training loss: 3.6144229879002023
Validation loss: 3.146455558312424

Epoch: 5| Step: 10
Training loss: 3.0287554987008516
Validation loss: 3.1467119025183363

Epoch: 149| Step: 0
Training loss: 3.741739329855228
Validation loss: 3.1461672400258647

Epoch: 5| Step: 1
Training loss: 3.354418837898939
Validation loss: 3.1470161913767183

Epoch: 5| Step: 2
Training loss: 3.5883565484935036
Validation loss: 3.1518859412926825

Epoch: 5| Step: 3
Training loss: 2.960609276930918
Validation loss: 3.1467078452868544

Epoch: 5| Step: 4
Training loss: 3.8435270663484884
Validation loss: 3.14944767586724

Epoch: 5| Step: 5
Training loss: 3.1285877232335637
Validation loss: 3.14506915635636

Epoch: 5| Step: 6
Training loss: 3.704647990401799
Validation loss: 3.1488144968281175

Epoch: 5| Step: 7
Training loss: 3.083989941215686
Validation loss: 3.14565253001333

Epoch: 5| Step: 8
Training loss: 3.1451153135764924
Validation loss: 3.1445319014003177

Epoch: 5| Step: 9
Training loss: 3.4204663029050706
Validation loss: 3.140459979040074

Epoch: 5| Step: 10
Training loss: 3.2647686433243006
Validation loss: 3.140862878883961

Epoch: 150| Step: 0
Training loss: 3.012489546761639
Validation loss: 3.141691862248844

Epoch: 5| Step: 1
Training loss: 2.9428913070822533
Validation loss: 3.138103792447654

Epoch: 5| Step: 2
Training loss: 2.704215122096374
Validation loss: 3.1394445235045376

Epoch: 5| Step: 3
Training loss: 3.438709809079855
Validation loss: 3.140714667471819

Epoch: 5| Step: 4
Training loss: 4.3320559061516555
Validation loss: 3.1397996549673386

Epoch: 5| Step: 5
Training loss: 3.6744345976111186
Validation loss: 3.1382744709553845

Epoch: 5| Step: 6
Training loss: 3.247898596190727
Validation loss: 3.1391869684557774

Epoch: 5| Step: 7
Training loss: 2.9662301060218033
Validation loss: 3.1407559063029704

Epoch: 5| Step: 8
Training loss: 3.341406170084901
Validation loss: 3.139930017622984

Epoch: 5| Step: 9
Training loss: 3.42654991443304
Validation loss: 3.1389436440848524

Epoch: 5| Step: 10
Training loss: 3.9846649662793046
Validation loss: 3.144411588978112

Epoch: 151| Step: 0
Training loss: 2.53004756671685
Validation loss: 3.1390463352478797

Epoch: 5| Step: 1
Training loss: 2.844742151251057
Validation loss: 3.1400840430935557

Epoch: 5| Step: 2
Training loss: 2.9035523723163976
Validation loss: 3.1391690297055006

Epoch: 5| Step: 3
Training loss: 2.837913644359926
Validation loss: 3.141159478235794

Epoch: 5| Step: 4
Training loss: 3.6954887622305743
Validation loss: 3.1387805325313938

Epoch: 5| Step: 5
Training loss: 3.76796361712083
Validation loss: 3.1393675058249486

Epoch: 5| Step: 6
Training loss: 3.7751469817189296
Validation loss: 3.1389115974296216

Epoch: 5| Step: 7
Training loss: 3.5863020967121324
Validation loss: 3.138781288854086

Epoch: 5| Step: 8
Training loss: 3.8229177753886905
Validation loss: 3.13894765663169

Epoch: 5| Step: 9
Training loss: 3.771939377128679
Validation loss: 3.1390039861061214

Epoch: 5| Step: 10
Training loss: 3.3883245724403563
Validation loss: 3.137917764930313

Epoch: 152| Step: 0
Training loss: 3.075262452377191
Validation loss: 3.1392310986845007

Epoch: 5| Step: 1
Training loss: 2.4992802537539083
Validation loss: 3.1377426754679028

Epoch: 5| Step: 2
Training loss: 3.5614435068234513
Validation loss: 3.1373110781097995

Epoch: 5| Step: 3
Training loss: 3.743251322807252
Validation loss: 3.1348854841180156

Epoch: 5| Step: 4
Training loss: 3.7717114404393937
Validation loss: 3.1357020739240715

Epoch: 5| Step: 5
Training loss: 3.217877167808313
Validation loss: 3.1369373897794492

Epoch: 5| Step: 6
Training loss: 3.4402691871091933
Validation loss: 3.1382361322063845

Epoch: 5| Step: 7
Training loss: 2.955374209338662
Validation loss: 3.138353435114401

Epoch: 5| Step: 8
Training loss: 3.0802864966969223
Validation loss: 3.1385514923205786

Epoch: 5| Step: 9
Training loss: 4.268319979856179
Validation loss: 3.140692132077146

Epoch: 5| Step: 10
Training loss: 3.29273299960526
Validation loss: 3.139347223603122

Epoch: 153| Step: 0
Training loss: 3.4798806803625535
Validation loss: 3.1319903004509113

Epoch: 5| Step: 1
Training loss: 3.1484167510075447
Validation loss: 3.134535794155859

Epoch: 5| Step: 2
Training loss: 3.632505867435471
Validation loss: 3.133680925636352

Epoch: 5| Step: 3
Training loss: 3.0880033507452462
Validation loss: 3.134589352688102

Epoch: 5| Step: 4
Training loss: 3.305967114755193
Validation loss: 3.1331826251887134

Epoch: 5| Step: 5
Training loss: 3.501940461799121
Validation loss: 3.132121824648093

Epoch: 5| Step: 6
Training loss: 3.1897255103185223
Validation loss: 3.1312951012798806

Epoch: 5| Step: 7
Training loss: 3.791706979278782
Validation loss: 3.1334526171743033

Epoch: 5| Step: 8
Training loss: 3.621843081474366
Validation loss: 3.1345971803717716

Epoch: 5| Step: 9
Training loss: 2.7852899591523994
Validation loss: 3.1334051492699935

Epoch: 5| Step: 10
Training loss: 3.636733697354486
Validation loss: 3.13189740528353

Epoch: 154| Step: 0
Training loss: 3.415584827127517
Validation loss: 3.132282457634462

Epoch: 5| Step: 1
Training loss: 3.8620722067753577
Validation loss: 3.1328610848711236

Epoch: 5| Step: 2
Training loss: 3.7088730380044197
Validation loss: 3.1314600927193568

Epoch: 5| Step: 3
Training loss: 3.1999911725399333
Validation loss: 3.133106056624585

Epoch: 5| Step: 4
Training loss: 2.72122211531378
Validation loss: 3.1314718848575587

Epoch: 5| Step: 5
Training loss: 3.484945755130018
Validation loss: 3.1303964891071137

Epoch: 5| Step: 6
Training loss: 2.908910374566522
Validation loss: 3.131272935291053

Epoch: 5| Step: 7
Training loss: 2.7322820882645105
Validation loss: 3.1324182024470537

Epoch: 5| Step: 8
Training loss: 4.037989933298004
Validation loss: 3.1304976409969734

Epoch: 5| Step: 9
Training loss: 3.2438938292734156
Validation loss: 3.130761744412923

Epoch: 5| Step: 10
Training loss: 3.6562374799465127
Validation loss: 3.128910404055237

Epoch: 155| Step: 0
Training loss: 2.311357679979147
Validation loss: 3.1309145177815547

Epoch: 5| Step: 1
Training loss: 3.367919559070862
Validation loss: 3.135794544898381

Epoch: 5| Step: 2
Training loss: 3.1288064281146917
Validation loss: 3.13819926343554

Epoch: 5| Step: 3
Training loss: 3.6757113280826363
Validation loss: 3.137270846494509

Epoch: 5| Step: 4
Training loss: 3.7911113430165733
Validation loss: 3.134139794442459

Epoch: 5| Step: 5
Training loss: 3.52820192292036
Validation loss: 3.132051644064344

Epoch: 5| Step: 6
Training loss: 3.4183473562631534
Validation loss: 3.135152037364616

Epoch: 5| Step: 7
Training loss: 3.9180444499011706
Validation loss: 3.130162858300821

Epoch: 5| Step: 8
Training loss: 3.4578501965191295
Validation loss: 3.1290748166411357

Epoch: 5| Step: 9
Training loss: 3.014162964281152
Validation loss: 3.128416273678515

Epoch: 5| Step: 10
Training loss: 3.297591145190659
Validation loss: 3.1285376461782812

Epoch: 156| Step: 0
Training loss: 3.763713937394693
Validation loss: 3.1266424739793854

Epoch: 5| Step: 1
Training loss: 3.818324907932674
Validation loss: 3.1278900122146367

Epoch: 5| Step: 2
Training loss: 3.1251135233286176
Validation loss: 3.1268207209217618

Epoch: 5| Step: 3
Training loss: 3.63653282075398
Validation loss: 3.1254346442723526

Epoch: 5| Step: 4
Training loss: 3.4590447548195624
Validation loss: 3.124468773430247

Epoch: 5| Step: 5
Training loss: 3.5103217922411343
Validation loss: 3.126361496192237

Epoch: 5| Step: 6
Training loss: 2.429594277313798
Validation loss: 3.1254540800574184

Epoch: 5| Step: 7
Training loss: 3.620022480510227
Validation loss: 3.1264257956182084

Epoch: 5| Step: 8
Training loss: 2.699039436710848
Validation loss: 3.1246208092119323

Epoch: 5| Step: 9
Training loss: 3.457139801217702
Validation loss: 3.125851893647354

Epoch: 5| Step: 10
Training loss: 3.427732705661987
Validation loss: 3.1246681348902485

Epoch: 157| Step: 0
Training loss: 3.4214392258284523
Validation loss: 3.1258870766964684

Epoch: 5| Step: 1
Training loss: 3.896542625661081
Validation loss: 3.1235445140140268

Epoch: 5| Step: 2
Training loss: 3.2770256824761685
Validation loss: 3.1259225349108934

Epoch: 5| Step: 3
Training loss: 3.3410008617812195
Validation loss: 3.1243073194121447

Epoch: 5| Step: 4
Training loss: 3.3094961113602173
Validation loss: 3.123376788164507

Epoch: 5| Step: 5
Training loss: 3.6721180936818074
Validation loss: 3.123445841397837

Epoch: 5| Step: 6
Training loss: 3.038681830171538
Validation loss: 3.1257534070527515

Epoch: 5| Step: 7
Training loss: 3.4992506042379654
Validation loss: 3.1214992365496013

Epoch: 5| Step: 8
Training loss: 3.142058695273444
Validation loss: 3.1232722225215324

Epoch: 5| Step: 9
Training loss: 3.303046790923093
Validation loss: 3.123579231430649

Epoch: 5| Step: 10
Training loss: 3.178362146042594
Validation loss: 3.1231702538176527

Epoch: 158| Step: 0
Training loss: 4.07693966999193
Validation loss: 3.122457066035715

Epoch: 5| Step: 1
Training loss: 3.706432555464622
Validation loss: 3.1233051864315846

Epoch: 5| Step: 2
Training loss: 3.8497313814459253
Validation loss: 3.122692271668563

Epoch: 5| Step: 3
Training loss: 3.6127888441932297
Validation loss: 3.12265549850698

Epoch: 5| Step: 4
Training loss: 3.289247629931243
Validation loss: 3.120980315381707

Epoch: 5| Step: 5
Training loss: 2.9717292693756385
Validation loss: 3.122432026067527

Epoch: 5| Step: 6
Training loss: 3.35929465974063
Validation loss: 3.123258557499842

Epoch: 5| Step: 7
Training loss: 3.3716699631568483
Validation loss: 3.1208691307023666

Epoch: 5| Step: 8
Training loss: 3.211104859680051
Validation loss: 3.1225495392676286

Epoch: 5| Step: 9
Training loss: 2.4502083514624164
Validation loss: 3.122591104203268

Epoch: 5| Step: 10
Training loss: 2.8608541362956896
Validation loss: 3.122630704784268

Epoch: 159| Step: 0
Training loss: 3.8638180011749537
Validation loss: 3.125352061139155

Epoch: 5| Step: 1
Training loss: 3.097336818777951
Validation loss: 3.1274060066529468

Epoch: 5| Step: 2
Training loss: 3.249022997210295
Validation loss: 3.125105700602334

Epoch: 5| Step: 3
Training loss: 3.171169258867112
Validation loss: 3.120892788397504

Epoch: 5| Step: 4
Training loss: 2.8929503289608967
Validation loss: 3.11952768258332

Epoch: 5| Step: 5
Training loss: 3.799066860669975
Validation loss: 3.1189038873400046

Epoch: 5| Step: 6
Training loss: 3.366397915553401
Validation loss: 3.1187770254351865

Epoch: 5| Step: 7
Training loss: 3.535438686490351
Validation loss: 3.118984233722388

Epoch: 5| Step: 8
Training loss: 3.609315417569972
Validation loss: 3.120761043969222

Epoch: 5| Step: 9
Training loss: 3.270363759797819
Validation loss: 3.120411034723618

Epoch: 5| Step: 10
Training loss: 3.118517599066267
Validation loss: 3.1174244198112917

Epoch: 160| Step: 0
Training loss: 3.3708353131401996
Validation loss: 3.118590223197437

Epoch: 5| Step: 1
Training loss: 3.5769755420355214
Validation loss: 3.1192960501420806

Epoch: 5| Step: 2
Training loss: 2.9556304153325015
Validation loss: 3.1184073854445566

Epoch: 5| Step: 3
Training loss: 3.7459782969451494
Validation loss: 3.11907103425803

Epoch: 5| Step: 4
Training loss: 3.0517393749443036
Validation loss: 3.1176651847629016

Epoch: 5| Step: 5
Training loss: 3.509664271891487
Validation loss: 3.117709970740884

Epoch: 5| Step: 6
Training loss: 2.7435002241515187
Validation loss: 3.117450894710133

Epoch: 5| Step: 7
Training loss: 3.0176100448352217
Validation loss: 3.119807714553545

Epoch: 5| Step: 8
Training loss: 3.408472018851834
Validation loss: 3.1190744789413514

Epoch: 5| Step: 9
Training loss: 3.5006850798289766
Validation loss: 3.1185182928935062

Epoch: 5| Step: 10
Training loss: 4.147416213593627
Validation loss: 3.1168382870381377

Epoch: 161| Step: 0
Training loss: 3.097227203942946
Validation loss: 3.1196105176930677

Epoch: 5| Step: 1
Training loss: 3.657007383494008
Validation loss: 3.1154078567429186

Epoch: 5| Step: 2
Training loss: 3.9323231407404866
Validation loss: 3.1167520223049014

Epoch: 5| Step: 3
Training loss: 2.9961547049597166
Validation loss: 3.116839779076727

Epoch: 5| Step: 4
Training loss: 3.5733382677879235
Validation loss: 3.1184291627798806

Epoch: 5| Step: 5
Training loss: 3.154135118240214
Validation loss: 3.118536209037735

Epoch: 5| Step: 6
Training loss: 3.514454829126657
Validation loss: 3.117023557565264

Epoch: 5| Step: 7
Training loss: 3.308785425103883
Validation loss: 3.1147912513331386

Epoch: 5| Step: 8
Training loss: 2.910368595440812
Validation loss: 3.11821900062449

Epoch: 5| Step: 9
Training loss: 2.53860122011811
Validation loss: 3.1143085307610345

Epoch: 5| Step: 10
Training loss: 4.193630456712978
Validation loss: 3.1167921321906586

Epoch: 162| Step: 0
Training loss: 3.678836278600353
Validation loss: 3.1169432157484707

Epoch: 5| Step: 1
Training loss: 2.9588514241480772
Validation loss: 3.115220659907092

Epoch: 5| Step: 2
Training loss: 3.1581339737134098
Validation loss: 3.113972275962489

Epoch: 5| Step: 3
Training loss: 3.602380092936387
Validation loss: 3.1134481956691635

Epoch: 5| Step: 4
Training loss: 3.819768012626956
Validation loss: 3.11509495077052

Epoch: 5| Step: 5
Training loss: 3.8056145699806523
Validation loss: 3.113862344396336

Epoch: 5| Step: 6
Training loss: 3.0161771120638607
Validation loss: 3.110598718224087

Epoch: 5| Step: 7
Training loss: 3.0109434799823855
Validation loss: 3.1122118241940258

Epoch: 5| Step: 8
Training loss: 3.8540773673494964
Validation loss: 3.1118614992493923

Epoch: 5| Step: 9
Training loss: 3.277873745463472
Validation loss: 3.1126996270826117

Epoch: 5| Step: 10
Training loss: 2.4908831301072283
Validation loss: 3.111381562283155

Epoch: 163| Step: 0
Training loss: 3.5072228970577273
Validation loss: 3.111661173923977

Epoch: 5| Step: 1
Training loss: 3.610875069818454
Validation loss: 3.113413867567141

Epoch: 5| Step: 2
Training loss: 2.8860666986531527
Validation loss: 3.1140431307309906

Epoch: 5| Step: 3
Training loss: 3.226359880564854
Validation loss: 3.11270689458069

Epoch: 5| Step: 4
Training loss: 3.369232477235244
Validation loss: 3.1129231821838386

Epoch: 5| Step: 5
Training loss: 3.2406820088065027
Validation loss: 3.11220635293531

Epoch: 5| Step: 6
Training loss: 3.4548849048572583
Validation loss: 3.114412896880274

Epoch: 5| Step: 7
Training loss: 2.851079863372666
Validation loss: 3.112963982115162

Epoch: 5| Step: 8
Training loss: 4.1317333406149555
Validation loss: 3.1137266641884014

Epoch: 5| Step: 9
Training loss: 3.350401492755561
Validation loss: 3.11090557938863

Epoch: 5| Step: 10
Training loss: 3.2075438746055416
Validation loss: 3.1097495354912694

Epoch: 164| Step: 0
Training loss: 2.7904884262241385
Validation loss: 3.109294880225221

Epoch: 5| Step: 1
Training loss: 2.851075849419918
Validation loss: 3.110840266100813

Epoch: 5| Step: 2
Training loss: 3.2984350770971234
Validation loss: 3.10838926300674

Epoch: 5| Step: 3
Training loss: 3.7815539025118414
Validation loss: 3.110390915868576

Epoch: 5| Step: 4
Training loss: 3.5432591766128776
Validation loss: 3.109767005875659

Epoch: 5| Step: 5
Training loss: 3.8809932998564007
Validation loss: 3.109998151123586

Epoch: 5| Step: 6
Training loss: 3.1855595984283767
Validation loss: 3.1099807331459255

Epoch: 5| Step: 7
Training loss: 2.70013173806262
Validation loss: 3.1108244656088146

Epoch: 5| Step: 8
Training loss: 4.00838402433852
Validation loss: 3.1094011291339365

Epoch: 5| Step: 9
Training loss: 3.6542955701327173
Validation loss: 3.107461120271431

Epoch: 5| Step: 10
Training loss: 2.9439603499562046
Validation loss: 3.1088886363960895

Epoch: 165| Step: 0
Training loss: 3.0310546182804137
Validation loss: 3.1091294958745985

Epoch: 5| Step: 1
Training loss: 3.307541068377889
Validation loss: 3.1073467424762446

Epoch: 5| Step: 2
Training loss: 3.917730930827474
Validation loss: 3.109310832778351

Epoch: 5| Step: 3
Training loss: 3.2382383999445574
Validation loss: 3.1087499789997115

Epoch: 5| Step: 4
Training loss: 3.2175228409152785
Validation loss: 3.10875006641295

Epoch: 5| Step: 5
Training loss: 3.8966769904616374
Validation loss: 3.107702399737425

Epoch: 5| Step: 6
Training loss: 3.7898751242806936
Validation loss: 3.1111596185981996

Epoch: 5| Step: 7
Training loss: 3.3230867890404423
Validation loss: 3.1101002516486367

Epoch: 5| Step: 8
Training loss: 2.863671581937988
Validation loss: 3.1080421703202927

Epoch: 5| Step: 9
Training loss: 3.0330948082619775
Validation loss: 3.1117966714982295

Epoch: 5| Step: 10
Training loss: 3.1556110301835236
Validation loss: 3.111975879163735

Epoch: 166| Step: 0
Training loss: 3.7434220159210243
Validation loss: 3.1072358009523158

Epoch: 5| Step: 1
Training loss: 3.7200535645268897
Validation loss: 3.1089896667589714

Epoch: 5| Step: 2
Training loss: 3.763321928058255
Validation loss: 3.1073983391493947

Epoch: 5| Step: 3
Training loss: 3.260560265122035
Validation loss: 3.1058387255796753

Epoch: 5| Step: 4
Training loss: 2.8952569914024298
Validation loss: 3.106833837826972

Epoch: 5| Step: 5
Training loss: 2.664231460001352
Validation loss: 3.1056919340945774

Epoch: 5| Step: 6
Training loss: 2.978607516512835
Validation loss: 3.1068897197577177

Epoch: 5| Step: 7
Training loss: 3.491302173195982
Validation loss: 3.107238807451518

Epoch: 5| Step: 8
Training loss: 3.281823825615185
Validation loss: 3.1056405302997976

Epoch: 5| Step: 9
Training loss: 3.5867805902712506
Validation loss: 3.1080321658076095

Epoch: 5| Step: 10
Training loss: 3.379849940473273
Validation loss: 3.1128201456059843

Epoch: 167| Step: 0
Training loss: 3.49336881520061
Validation loss: 3.11713683351666

Epoch: 5| Step: 1
Training loss: 3.4107034949828865
Validation loss: 3.117679713037918

Epoch: 5| Step: 2
Training loss: 3.7919101986211037
Validation loss: 3.1083734789221547

Epoch: 5| Step: 3
Training loss: 3.4830559256546243
Validation loss: 3.1033183660188453

Epoch: 5| Step: 4
Training loss: 3.1989644640051527
Validation loss: 3.102140702178196

Epoch: 5| Step: 5
Training loss: 3.951304623480587
Validation loss: 3.104144527744239

Epoch: 5| Step: 6
Training loss: 2.5823063090715728
Validation loss: 3.105584228828611

Epoch: 5| Step: 7
Training loss: 3.2552937163281332
Validation loss: 3.1150383650667353

Epoch: 5| Step: 8
Training loss: 2.793353031638284
Validation loss: 3.1244982523762466

Epoch: 5| Step: 9
Training loss: 3.716896172067585
Validation loss: 3.1240233111242945

Epoch: 5| Step: 10
Training loss: 3.08448343907655
Validation loss: 3.1218902028785367

Epoch: 168| Step: 0
Training loss: 3.224206392094911
Validation loss: 3.107277441202431

Epoch: 5| Step: 1
Training loss: 3.848706407092597
Validation loss: 3.1027164963083482

Epoch: 5| Step: 2
Training loss: 3.0978508175023536
Validation loss: 3.1028639085890695

Epoch: 5| Step: 3
Training loss: 3.0905742336381326
Validation loss: 3.099939810955514

Epoch: 5| Step: 4
Training loss: 3.6063601630721047
Validation loss: 3.100283366129035

Epoch: 5| Step: 5
Training loss: 3.2286556372770843
Validation loss: 3.1013217786219007

Epoch: 5| Step: 6
Training loss: 4.094608595404517
Validation loss: 3.1034708993483413

Epoch: 5| Step: 7
Training loss: 2.811830313743586
Validation loss: 3.1040607628957386

Epoch: 5| Step: 8
Training loss: 3.0916502020741063
Validation loss: 3.101467230396207

Epoch: 5| Step: 9
Training loss: 3.0995764535310593
Validation loss: 3.111222508397183

Epoch: 5| Step: 10
Training loss: 3.5685833305815753
Validation loss: 3.109469587058464

Epoch: 169| Step: 0
Training loss: 2.9900608722525015
Validation loss: 3.1109309791338418

Epoch: 5| Step: 1
Training loss: 3.407827169674481
Validation loss: 3.112973635599464

Epoch: 5| Step: 2
Training loss: 3.946450973772652
Validation loss: 3.1062829373647136

Epoch: 5| Step: 3
Training loss: 3.0460512270311138
Validation loss: 3.1017029681046395

Epoch: 5| Step: 4
Training loss: 2.48494066240476
Validation loss: 3.0971773763809987

Epoch: 5| Step: 5
Training loss: 3.466417507852324
Validation loss: 3.1004357511013274

Epoch: 5| Step: 6
Training loss: 4.075019677237528
Validation loss: 3.097973106139326

Epoch: 5| Step: 7
Training loss: 3.4657662420496926
Validation loss: 3.1009038922955776

Epoch: 5| Step: 8
Training loss: 2.693501978384693
Validation loss: 3.098873666647856

Epoch: 5| Step: 9
Training loss: 3.9174815338030617
Validation loss: 3.101088343204701

Epoch: 5| Step: 10
Training loss: 2.9564829309165277
Validation loss: 3.0982968075255384

Epoch: 170| Step: 0
Training loss: 2.9469785961335613
Validation loss: 3.0986223018819823

Epoch: 5| Step: 1
Training loss: 3.3364474690705364
Validation loss: 3.0987529473903628

Epoch: 5| Step: 2
Training loss: 3.397492797035514
Validation loss: 3.0996736537309393

Epoch: 5| Step: 3
Training loss: 3.784853518636057
Validation loss: 3.100573121692674

Epoch: 5| Step: 4
Training loss: 3.5557555218599877
Validation loss: 3.1023037800225315

Epoch: 5| Step: 5
Training loss: 3.826668847733606
Validation loss: 3.0986253829264108

Epoch: 5| Step: 6
Training loss: 3.188446502777523
Validation loss: 3.097148789609616

Epoch: 5| Step: 7
Training loss: 3.5505043316282734
Validation loss: 3.0981993787783266

Epoch: 5| Step: 8
Training loss: 2.873052517945682
Validation loss: 3.0956301577194227

Epoch: 5| Step: 9
Training loss: 2.8438806189417445
Validation loss: 3.0950557032910173

Epoch: 5| Step: 10
Training loss: 3.468046512234654
Validation loss: 3.098061257484625

Epoch: 171| Step: 0
Training loss: 2.87068864728158
Validation loss: 3.0957233875869634

Epoch: 5| Step: 1
Training loss: 3.5361734012359176
Validation loss: 3.0984618831211654

Epoch: 5| Step: 2
Training loss: 2.851673866083037
Validation loss: 3.095671381007533

Epoch: 5| Step: 3
Training loss: 3.9825801621467463
Validation loss: 3.0965374110532347

Epoch: 5| Step: 4
Training loss: 3.433565975072531
Validation loss: 3.0959211810003056

Epoch: 5| Step: 5
Training loss: 2.8156986273517983
Validation loss: 3.0973697408764997

Epoch: 5| Step: 6
Training loss: 3.2640686707098205
Validation loss: 3.0966170123247716

Epoch: 5| Step: 7
Training loss: 3.5742626416789323
Validation loss: 3.097910725254324

Epoch: 5| Step: 8
Training loss: 3.4405133997585966
Validation loss: 3.0971892709032414

Epoch: 5| Step: 9
Training loss: 3.4851883422222274
Validation loss: 3.0970654547185585

Epoch: 5| Step: 10
Training loss: 3.480738088887559
Validation loss: 3.0954155538862285

Epoch: 172| Step: 0
Training loss: 2.957063984658227
Validation loss: 3.094619542598125

Epoch: 5| Step: 1
Training loss: 3.33680331498802
Validation loss: 3.094803873519213

Epoch: 5| Step: 2
Training loss: 2.695039597116004
Validation loss: 3.093407809318695

Epoch: 5| Step: 3
Training loss: 3.3295793534558493
Validation loss: 3.0950040673458092

Epoch: 5| Step: 4
Training loss: 3.1762064406325394
Validation loss: 3.0939327072928666

Epoch: 5| Step: 5
Training loss: 3.7397293586520877
Validation loss: 3.093558936891462

Epoch: 5| Step: 6
Training loss: 3.5085553102802027
Validation loss: 3.0909839229064446

Epoch: 5| Step: 7
Training loss: 3.3669243729665754
Validation loss: 3.0949564918363586

Epoch: 5| Step: 8
Training loss: 3.8641567491759634
Validation loss: 3.0936668221570245

Epoch: 5| Step: 9
Training loss: 3.0455258243350842
Validation loss: 3.09427646546467

Epoch: 5| Step: 10
Training loss: 3.730007922084874
Validation loss: 3.0951304823148704

Epoch: 173| Step: 0
Training loss: 3.525114417417368
Validation loss: 3.0914856815745884

Epoch: 5| Step: 1
Training loss: 3.16430135696614
Validation loss: 3.089586919239063

Epoch: 5| Step: 2
Training loss: 4.077164694016992
Validation loss: 3.091985327464567

Epoch: 5| Step: 3
Training loss: 3.9073139420215663
Validation loss: 3.091313350230664

Epoch: 5| Step: 4
Training loss: 3.585600660539708
Validation loss: 3.091013145603625

Epoch: 5| Step: 5
Training loss: 3.063349703252788
Validation loss: 3.0898394704089833

Epoch: 5| Step: 6
Training loss: 3.428175190894615
Validation loss: 3.092388948751598

Epoch: 5| Step: 7
Training loss: 2.804440458250899
Validation loss: 3.0902113943577136

Epoch: 5| Step: 8
Training loss: 3.75850146157938
Validation loss: 3.0918720023161708

Epoch: 5| Step: 9
Training loss: 2.3768192150100655
Validation loss: 3.0908043590681427

Epoch: 5| Step: 10
Training loss: 2.6050618781942956
Validation loss: 3.0901159672676957

Epoch: 174| Step: 0
Training loss: 3.0230105391863487
Validation loss: 3.0896373206012524

Epoch: 5| Step: 1
Training loss: 2.850790175269496
Validation loss: 3.090225434483134

Epoch: 5| Step: 2
Training loss: 2.749502397080074
Validation loss: 3.088898217112218

Epoch: 5| Step: 3
Training loss: 3.2061861623019374
Validation loss: 3.090925177266666

Epoch: 5| Step: 4
Training loss: 3.9485605296934265
Validation loss: 3.0886732791840217

Epoch: 5| Step: 5
Training loss: 3.6624538900447745
Validation loss: 3.0901410799455156

Epoch: 5| Step: 6
Training loss: 3.8958878674829664
Validation loss: 3.090273709993695

Epoch: 5| Step: 7
Training loss: 2.890224779620678
Validation loss: 3.088937006386469

Epoch: 5| Step: 8
Training loss: 3.1988429779218457
Validation loss: 3.0895904482407324

Epoch: 5| Step: 9
Training loss: 3.461686236332796
Validation loss: 3.087253908789893

Epoch: 5| Step: 10
Training loss: 3.733441607290301
Validation loss: 3.0916336442781254

Epoch: 175| Step: 0
Training loss: 2.9572186227995094
Validation loss: 3.0913367862921457

Epoch: 5| Step: 1
Training loss: 3.4242567717808363
Validation loss: 3.0952072838035476

Epoch: 5| Step: 2
Training loss: 2.96290414363264
Validation loss: 3.0980662125408918

Epoch: 5| Step: 3
Training loss: 3.366688844085266
Validation loss: 3.0958674578119956

Epoch: 5| Step: 4
Training loss: 3.476428905877707
Validation loss: 3.092126416353324

Epoch: 5| Step: 5
Training loss: 3.4065436840316345
Validation loss: 3.0903155456154785

Epoch: 5| Step: 6
Training loss: 3.5037203498100205
Validation loss: 3.0883477788638385

Epoch: 5| Step: 7
Training loss: 3.7695062033656233
Validation loss: 3.08784134915719

Epoch: 5| Step: 8
Training loss: 2.9568954698639835
Validation loss: 3.084555310325644

Epoch: 5| Step: 9
Training loss: 3.5117440058359057
Validation loss: 3.0840869626650216

Epoch: 5| Step: 10
Training loss: 3.3611943485962907
Validation loss: 3.0857410879832674

Epoch: 176| Step: 0
Training loss: 3.5310408268644937
Validation loss: 3.086402715318825

Epoch: 5| Step: 1
Training loss: 3.031558306244522
Validation loss: 3.084327391731947

Epoch: 5| Step: 2
Training loss: 3.6811185026403264
Validation loss: 3.083843661786926

Epoch: 5| Step: 3
Training loss: 3.1838384803366
Validation loss: 3.0817808839791994

Epoch: 5| Step: 4
Training loss: 3.4837800617104953
Validation loss: 3.0834531092861064

Epoch: 5| Step: 5
Training loss: 3.851140801981222
Validation loss: 3.085897472574235

Epoch: 5| Step: 6
Training loss: 2.690015192520747
Validation loss: 3.0833084556642447

Epoch: 5| Step: 7
Training loss: 3.6310139459517092
Validation loss: 3.0828568046807407

Epoch: 5| Step: 8
Training loss: 3.364366947613015
Validation loss: 3.0844169703526947

Epoch: 5| Step: 9
Training loss: 2.6277935059417024
Validation loss: 3.080442549007431

Epoch: 5| Step: 10
Training loss: 3.488489569822413
Validation loss: 3.084161311069685

Epoch: 177| Step: 0
Training loss: 3.0322260907306395
Validation loss: 3.0827230438734627

Epoch: 5| Step: 1
Training loss: 3.0568892795226885
Validation loss: 3.0814739220228877

Epoch: 5| Step: 2
Training loss: 3.0790125153136367
Validation loss: 3.08562968785286

Epoch: 5| Step: 3
Training loss: 3.4889544171728386
Validation loss: 3.081846591015304

Epoch: 5| Step: 4
Training loss: 3.338618681798449
Validation loss: 3.0832193171188274

Epoch: 5| Step: 5
Training loss: 3.773574605468872
Validation loss: 3.0812504921856823

Epoch: 5| Step: 6
Training loss: 3.45275849343525
Validation loss: 3.080407641700976

Epoch: 5| Step: 7
Training loss: 3.2600989791260524
Validation loss: 3.080514261541816

Epoch: 5| Step: 8
Training loss: 3.5329071477656875
Validation loss: 3.0822555747534865

Epoch: 5| Step: 9
Training loss: 3.229224780800575
Validation loss: 3.0792525579954058

Epoch: 5| Step: 10
Training loss: 3.442121000682196
Validation loss: 3.0799333727975737

Epoch: 178| Step: 0
Training loss: 2.7827053762697562
Validation loss: 3.0793975428364737

Epoch: 5| Step: 1
Training loss: 2.6612833242986254
Validation loss: 3.0828497661835015

Epoch: 5| Step: 2
Training loss: 3.5849399217921194
Validation loss: 3.0794027368850543

Epoch: 5| Step: 3
Training loss: 3.2775851173318107
Validation loss: 3.081802636467425

Epoch: 5| Step: 4
Training loss: 4.009318702641458
Validation loss: 3.0861408291788472

Epoch: 5| Step: 5
Training loss: 3.077315945486379
Validation loss: 3.085464376056475

Epoch: 5| Step: 6
Training loss: 4.225364416534347
Validation loss: 3.08088979757471

Epoch: 5| Step: 7
Training loss: 2.6413118270519687
Validation loss: 3.0790910001979053

Epoch: 5| Step: 8
Training loss: 3.9092121337336967
Validation loss: 3.079310145140753

Epoch: 5| Step: 9
Training loss: 2.980389235249535
Validation loss: 3.079147359809779

Epoch: 5| Step: 10
Training loss: 3.05133059509679
Validation loss: 3.0793122814307914

Epoch: 179| Step: 0
Training loss: 2.690913671588045
Validation loss: 3.0790586611443262

Epoch: 5| Step: 1
Training loss: 3.6092439437786865
Validation loss: 3.0778747926634282

Epoch: 5| Step: 2
Training loss: 3.8004135157809045
Validation loss: 3.07617173665781

Epoch: 5| Step: 3
Training loss: 3.1632005058944213
Validation loss: 3.0744146798588696

Epoch: 5| Step: 4
Training loss: 3.8314624173644547
Validation loss: 3.077129363941541

Epoch: 5| Step: 5
Training loss: 3.4045897471105637
Validation loss: 3.0740170224026464

Epoch: 5| Step: 6
Training loss: 3.520074089094206
Validation loss: 3.0761954580855915

Epoch: 5| Step: 7
Training loss: 2.8574941317013267
Validation loss: 3.077752535085065

Epoch: 5| Step: 8
Training loss: 3.296185896029173
Validation loss: 3.076023825295719

Epoch: 5| Step: 9
Training loss: 3.163553229896901
Validation loss: 3.0776650531911915

Epoch: 5| Step: 10
Training loss: 3.1400104889421154
Validation loss: 3.0756204169472245

Epoch: 180| Step: 0
Training loss: 3.0946829573983057
Validation loss: 3.0774676225474056

Epoch: 5| Step: 1
Training loss: 2.7559777226980287
Validation loss: 3.075196511290366

Epoch: 5| Step: 2
Training loss: 3.453049464715779
Validation loss: 3.075570147641528

Epoch: 5| Step: 3
Training loss: 3.8200980596289233
Validation loss: 3.081409360150956

Epoch: 5| Step: 4
Training loss: 3.7329200879221216
Validation loss: 3.076346686221192

Epoch: 5| Step: 5
Training loss: 3.351491789527612
Validation loss: 3.0801538702369373

Epoch: 5| Step: 6
Training loss: 2.6599812947239405
Validation loss: 3.0800505206603614

Epoch: 5| Step: 7
Training loss: 3.2506826124053143
Validation loss: 3.0754865639746893

Epoch: 5| Step: 8
Training loss: 3.395241683874499
Validation loss: 3.074440853873031

Epoch: 5| Step: 9
Training loss: 3.327371574692153
Validation loss: 3.0757186092660476

Epoch: 5| Step: 10
Training loss: 3.6764418751212453
Validation loss: 3.072925392557015

Epoch: 181| Step: 0
Training loss: 3.3943727936980723
Validation loss: 3.072533053394869

Epoch: 5| Step: 1
Training loss: 3.2596465512441815
Validation loss: 3.074315492757107

Epoch: 5| Step: 2
Training loss: 3.2706732903138853
Validation loss: 3.0761012179998724

Epoch: 5| Step: 3
Training loss: 4.066271161300801
Validation loss: 3.075319842480258

Epoch: 5| Step: 4
Training loss: 3.6887067986042665
Validation loss: 3.0745182830888798

Epoch: 5| Step: 5
Training loss: 2.4257447858886287
Validation loss: 3.0717703704178714

Epoch: 5| Step: 6
Training loss: 3.2037658050421114
Validation loss: 3.0729576151215454

Epoch: 5| Step: 7
Training loss: 3.4956597255903294
Validation loss: 3.0739193712030266

Epoch: 5| Step: 8
Training loss: 3.016458662951543
Validation loss: 3.071693575503747

Epoch: 5| Step: 9
Training loss: 3.2657682396534806
Validation loss: 3.0722908869229553

Epoch: 5| Step: 10
Training loss: 3.3232538098074023
Validation loss: 3.0704250495106464

Epoch: 182| Step: 0
Training loss: 2.6704535021309503
Validation loss: 3.0698549034577236

Epoch: 5| Step: 1
Training loss: 3.968686321078085
Validation loss: 3.0728303463705258

Epoch: 5| Step: 2
Training loss: 3.682930911996458
Validation loss: 3.06976111343838

Epoch: 5| Step: 3
Training loss: 3.653493249507153
Validation loss: 3.0705003732848364

Epoch: 5| Step: 4
Training loss: 2.807786849493298
Validation loss: 3.0742081825965033

Epoch: 5| Step: 5
Training loss: 3.2363798405550415
Validation loss: 3.0709318218821657

Epoch: 5| Step: 6
Training loss: 2.8310427288791065
Validation loss: 3.0690271861762835

Epoch: 5| Step: 7
Training loss: 3.9570586042597835
Validation loss: 3.0694999764660675

Epoch: 5| Step: 8
Training loss: 2.751887020835986
Validation loss: 3.071001606088653

Epoch: 5| Step: 9
Training loss: 2.895215487720545
Validation loss: 3.068827339429015

Epoch: 5| Step: 10
Training loss: 3.8594044054895704
Validation loss: 3.068049066455327

Epoch: 183| Step: 0
Training loss: 2.9982684224431972
Validation loss: 3.0687565417272533

Epoch: 5| Step: 1
Training loss: 3.6213929218376646
Validation loss: 3.067493762914321

Epoch: 5| Step: 2
Training loss: 3.6540311944107104
Validation loss: 3.0677625432423286

Epoch: 5| Step: 3
Training loss: 3.112909043485321
Validation loss: 3.067269238658885

Epoch: 5| Step: 4
Training loss: 3.568654148932393
Validation loss: 3.0697214312835577

Epoch: 5| Step: 5
Training loss: 3.5813042122297665
Validation loss: 3.068487085679787

Epoch: 5| Step: 6
Training loss: 3.243776083898317
Validation loss: 3.0664311965189937

Epoch: 5| Step: 7
Training loss: 3.4513548029123196
Validation loss: 3.067703764913614

Epoch: 5| Step: 8
Training loss: 3.142304080752384
Validation loss: 3.070738278740527

Epoch: 5| Step: 9
Training loss: 3.040675973023894
Validation loss: 3.0700935495070922

Epoch: 5| Step: 10
Training loss: 3.0946106917602947
Validation loss: 3.0664771772063677

Epoch: 184| Step: 0
Training loss: 2.488615148350162
Validation loss: 3.0739623884857745

Epoch: 5| Step: 1
Training loss: 3.1637734363521326
Validation loss: 3.0711403299841677

Epoch: 5| Step: 2
Training loss: 3.7346289640124
Validation loss: 3.067436198809383

Epoch: 5| Step: 3
Training loss: 3.345279664578243
Validation loss: 3.073486551146454

Epoch: 5| Step: 4
Training loss: 2.4764949175641755
Validation loss: 3.065845133373937

Epoch: 5| Step: 5
Training loss: 3.625472202458033
Validation loss: 3.0709489871709055

Epoch: 5| Step: 6
Training loss: 3.6941383222242217
Validation loss: 3.0653056673376162

Epoch: 5| Step: 7
Training loss: 3.7054385913294756
Validation loss: 3.0640726946309087

Epoch: 5| Step: 8
Training loss: 2.9226030880748763
Validation loss: 3.065365083767792

Epoch: 5| Step: 9
Training loss: 3.5066666462635965
Validation loss: 3.064051195290832

Epoch: 5| Step: 10
Training loss: 3.6163764192575028
Validation loss: 3.0648975208386533

Epoch: 185| Step: 0
Training loss: 3.99138739344917
Validation loss: 3.0640283152623673

Epoch: 5| Step: 1
Training loss: 2.963773390968462
Validation loss: 3.0633910579862693

Epoch: 5| Step: 2
Training loss: 3.4037450976832035
Validation loss: 3.0649226879126665

Epoch: 5| Step: 3
Training loss: 3.9013077866253885
Validation loss: 3.0627647923304555

Epoch: 5| Step: 4
Training loss: 3.227589293765698
Validation loss: 3.0648919433695223

Epoch: 5| Step: 5
Training loss: 2.7499808397492584
Validation loss: 3.0619318244387292

Epoch: 5| Step: 6
Training loss: 3.2326008081611803
Validation loss: 3.0646511489622457

Epoch: 5| Step: 7
Training loss: 3.397404796622242
Validation loss: 3.0634118221768896

Epoch: 5| Step: 8
Training loss: 3.726970274425681
Validation loss: 3.0634120330650934

Epoch: 5| Step: 9
Training loss: 2.751420954410935
Validation loss: 3.062823384204187

Epoch: 5| Step: 10
Training loss: 2.8937796210138598
Validation loss: 3.0679953924985353

Epoch: 186| Step: 0
Training loss: 3.1705787152100893
Validation loss: 3.080086548165486

Epoch: 5| Step: 1
Training loss: 3.451874795775897
Validation loss: 3.0681861624948157

Epoch: 5| Step: 2
Training loss: 3.267804308426217
Validation loss: 3.0632690257713016

Epoch: 5| Step: 3
Training loss: 4.145181013510221
Validation loss: 3.062264964778579

Epoch: 5| Step: 4
Training loss: 3.448495099892052
Validation loss: 3.0617405131951263

Epoch: 5| Step: 5
Training loss: 3.0847989456717086
Validation loss: 3.0616745530115104

Epoch: 5| Step: 6
Training loss: 3.751934569758256
Validation loss: 3.061399460069705

Epoch: 5| Step: 7
Training loss: 3.2759918225271334
Validation loss: 3.0594609534030837

Epoch: 5| Step: 8
Training loss: 2.8909103665095506
Validation loss: 3.0571157787046053

Epoch: 5| Step: 9
Training loss: 2.599102793458376
Validation loss: 3.0618884941242306

Epoch: 5| Step: 10
Training loss: 3.192484231191479
Validation loss: 3.060323609468094

Epoch: 187| Step: 0
Training loss: 3.698832796903402
Validation loss: 3.0594487647229425

Epoch: 5| Step: 1
Training loss: 3.4605514276588463
Validation loss: 3.061207932151972

Epoch: 5| Step: 2
Training loss: 3.083222791047679
Validation loss: 3.0610542877982705

Epoch: 5| Step: 3
Training loss: 3.3399953707360264
Validation loss: 3.0597620116298816

Epoch: 5| Step: 4
Training loss: 3.2516749540842858
Validation loss: 3.0593839006205337

Epoch: 5| Step: 5
Training loss: 3.9473914985651395
Validation loss: 3.0588822400121365

Epoch: 5| Step: 6
Training loss: 3.5327385659729615
Validation loss: 3.06062531910773

Epoch: 5| Step: 7
Training loss: 3.412784153771934
Validation loss: 3.0591898078972943

Epoch: 5| Step: 8
Training loss: 3.1057798217825425
Validation loss: 3.0592344485207392

Epoch: 5| Step: 9
Training loss: 2.881823527749882
Validation loss: 3.058332311654611

Epoch: 5| Step: 10
Training loss: 2.4995660405218696
Validation loss: 3.0574086962726605

Epoch: 188| Step: 0
Training loss: 3.5636808880942143
Validation loss: 3.0575228141462283

Epoch: 5| Step: 1
Training loss: 3.0268543266174848
Validation loss: 3.0594262357312174

Epoch: 5| Step: 2
Training loss: 3.565585222615823
Validation loss: 3.0591956421377984

Epoch: 5| Step: 3
Training loss: 3.2626932664240815
Validation loss: 3.057078809617088

Epoch: 5| Step: 4
Training loss: 3.1477984591560704
Validation loss: 3.0565993424865074

Epoch: 5| Step: 5
Training loss: 3.128834317603238
Validation loss: 3.0583143010072145

Epoch: 5| Step: 6
Training loss: 3.968732338212731
Validation loss: 3.056385013528879

Epoch: 5| Step: 7
Training loss: 2.469387020544302
Validation loss: 3.058276022790175

Epoch: 5| Step: 8
Training loss: 3.373596606051733
Validation loss: 3.059726989039416

Epoch: 5| Step: 9
Training loss: 3.3412406275625246
Validation loss: 3.0583214890168344

Epoch: 5| Step: 10
Training loss: 3.5173659697525563
Validation loss: 3.058462445195853

Epoch: 189| Step: 0
Training loss: 3.658840989420592
Validation loss: 3.057880393911525

Epoch: 5| Step: 1
Training loss: 3.714838872318696
Validation loss: 3.0570146742967244

Epoch: 5| Step: 2
Training loss: 3.4246838333217466
Validation loss: 3.057785341195016

Epoch: 5| Step: 3
Training loss: 2.7715790875564643
Validation loss: 3.0579390282334464

Epoch: 5| Step: 4
Training loss: 3.407771899205785
Validation loss: 3.0580283998375832

Epoch: 5| Step: 5
Training loss: 3.333420529814513
Validation loss: 3.057708776068593

Epoch: 5| Step: 6
Training loss: 2.6259082857663456
Validation loss: 3.0599573331406904

Epoch: 5| Step: 7
Training loss: 2.756187414033976
Validation loss: 3.058131549722791

Epoch: 5| Step: 8
Training loss: 3.315905565764703
Validation loss: 3.0580703630565

Epoch: 5| Step: 9
Training loss: 3.6763429121399436
Validation loss: 3.0590111751963387

Epoch: 5| Step: 10
Training loss: 3.6788922724171718
Validation loss: 3.056514891963122

Epoch: 190| Step: 0
Training loss: 3.8705432242476046
Validation loss: 3.0582259126744495

Epoch: 5| Step: 1
Training loss: 2.7421589820009267
Validation loss: 3.057293089936726

Epoch: 5| Step: 2
Training loss: 3.0137525684878947
Validation loss: 3.059204076710295

Epoch: 5| Step: 3
Training loss: 3.879643396133793
Validation loss: 3.0593910467331225

Epoch: 5| Step: 4
Training loss: 3.17864793284334
Validation loss: 3.0558208453578173

Epoch: 5| Step: 5
Training loss: 2.8453911038831934
Validation loss: 3.0569265804852286

Epoch: 5| Step: 6
Training loss: 3.564597466041526
Validation loss: 3.060622307025133

Epoch: 5| Step: 7
Training loss: 3.0332086271984062
Validation loss: 3.0569528916553015

Epoch: 5| Step: 8
Training loss: 2.9937988404688087
Validation loss: 3.0577709441933574

Epoch: 5| Step: 9
Training loss: 3.3973450055672925
Validation loss: 3.0588243269475024

Epoch: 5| Step: 10
Training loss: 3.8035882070620324
Validation loss: 3.0570778242717895

Epoch: 191| Step: 0
Training loss: 3.2441356275360365
Validation loss: 3.0575332530777968

Epoch: 5| Step: 1
Training loss: 4.085891285738884
Validation loss: 3.0540828097410073

Epoch: 5| Step: 2
Training loss: 3.4769238916361083
Validation loss: 3.0558507986113894

Epoch: 5| Step: 3
Training loss: 3.4522194343830934
Validation loss: 3.0511636241103206

Epoch: 5| Step: 4
Training loss: 2.783390207528093
Validation loss: 3.055297929885413

Epoch: 5| Step: 5
Training loss: 3.2452247457160066
Validation loss: 3.0532019617281234

Epoch: 5| Step: 6
Training loss: 3.3229752937016053
Validation loss: 3.052569534184216

Epoch: 5| Step: 7
Training loss: 3.1382139449894693
Validation loss: 3.0511960302814645

Epoch: 5| Step: 8
Training loss: 3.0541752924847194
Validation loss: 3.0511113613029086

Epoch: 5| Step: 9
Training loss: 3.5056134576007274
Validation loss: 3.053930276807749

Epoch: 5| Step: 10
Training loss: 2.928364935848974
Validation loss: 3.050699730889624

Epoch: 192| Step: 0
Training loss: 3.2412924392811147
Validation loss: 3.054573964409097

Epoch: 5| Step: 1
Training loss: 3.3275144491591306
Validation loss: 3.050395144360037

Epoch: 5| Step: 2
Training loss: 3.4049748825065493
Validation loss: 3.0525041392512797

Epoch: 5| Step: 3
Training loss: 3.291024753093795
Validation loss: 3.052876782424174

Epoch: 5| Step: 4
Training loss: 3.2128524824388647
Validation loss: 3.0524783289219557

Epoch: 5| Step: 5
Training loss: 2.872780316173709
Validation loss: 3.0500314522285996

Epoch: 5| Step: 6
Training loss: 3.0636297205299075
Validation loss: 3.0484643838355003

Epoch: 5| Step: 7
Training loss: 3.77348602453272
Validation loss: 3.0461952496659004

Epoch: 5| Step: 8
Training loss: 2.823648862205372
Validation loss: 3.048066393093629

Epoch: 5| Step: 9
Training loss: 3.3581997967115935
Validation loss: 3.048184998636343

Epoch: 5| Step: 10
Training loss: 4.044232658341976
Validation loss: 3.0481171210354407

Epoch: 193| Step: 0
Training loss: 3.8473974770215005
Validation loss: 3.0499899894796183

Epoch: 5| Step: 1
Training loss: 2.997552827269356
Validation loss: 3.047091807604759

Epoch: 5| Step: 2
Training loss: 3.210697062973707
Validation loss: 3.0494036089228347

Epoch: 5| Step: 3
Training loss: 2.964721516337343
Validation loss: 3.0472003335016073

Epoch: 5| Step: 4
Training loss: 3.6352201625469656
Validation loss: 3.0481319236049735

Epoch: 5| Step: 5
Training loss: 3.4971762574272254
Validation loss: 3.0483606965870242

Epoch: 5| Step: 6
Training loss: 3.3589575219791703
Validation loss: 3.0471931318780285

Epoch: 5| Step: 7
Training loss: 3.2943449753370273
Validation loss: 3.0481523762643006

Epoch: 5| Step: 8
Training loss: 3.1812233554646103
Validation loss: 3.0528299427203347

Epoch: 5| Step: 9
Training loss: 3.71601857121388
Validation loss: 3.0653875272961675

Epoch: 5| Step: 10
Training loss: 2.321361779729764
Validation loss: 3.0512815370955724

Epoch: 194| Step: 0
Training loss: 3.429925932014988
Validation loss: 3.05710583814373

Epoch: 5| Step: 1
Training loss: 3.512532548312414
Validation loss: 3.0487310006452013

Epoch: 5| Step: 2
Training loss: 3.4688214818789005
Validation loss: 3.044756325788349

Epoch: 5| Step: 3
Training loss: 3.23195067137664
Validation loss: 3.046415331221803

Epoch: 5| Step: 4
Training loss: 3.4507626008559065
Validation loss: 3.04712297741469

Epoch: 5| Step: 5
Training loss: 2.5905094355632423
Validation loss: 3.047244702194423

Epoch: 5| Step: 6
Training loss: 3.3434540804822572
Validation loss: 3.046791362850332

Epoch: 5| Step: 7
Training loss: 3.3041925442914155
Validation loss: 3.0468035626194427

Epoch: 5| Step: 8
Training loss: 3.4737319224334375
Validation loss: 3.047566093021477

Epoch: 5| Step: 9
Training loss: 3.3333309809358562
Validation loss: 3.049415184530868

Epoch: 5| Step: 10
Training loss: 3.2555238291120685
Validation loss: 3.048038528279834

Epoch: 195| Step: 0
Training loss: 3.8616575834726965
Validation loss: 3.0470599677623045

Epoch: 5| Step: 1
Training loss: 3.7406961101251817
Validation loss: 3.047064569937462

Epoch: 5| Step: 2
Training loss: 3.369106374373006
Validation loss: 3.045506896174303

Epoch: 5| Step: 3
Training loss: 3.173000042212937
Validation loss: 3.0459497873397856

Epoch: 5| Step: 4
Training loss: 2.860158844118002
Validation loss: 3.0444275943825834

Epoch: 5| Step: 5
Training loss: 2.9968462897905437
Validation loss: 3.043856985305766

Epoch: 5| Step: 6
Training loss: 3.2532518697399238
Validation loss: 3.0410848750308546

Epoch: 5| Step: 7
Training loss: 2.53930738001819
Validation loss: 3.0435984522047477

Epoch: 5| Step: 8
Training loss: 3.0466103463285155
Validation loss: 3.0416195475701344

Epoch: 5| Step: 9
Training loss: 3.3520508879392734
Validation loss: 3.0403117894533627

Epoch: 5| Step: 10
Training loss: 4.066467226067806
Validation loss: 3.0452759708845725

Epoch: 196| Step: 0
Training loss: 3.1026750774305065
Validation loss: 3.0470135754292818

Epoch: 5| Step: 1
Training loss: 3.474655760036789
Validation loss: 3.051782394054225

Epoch: 5| Step: 2
Training loss: 3.59814396802691
Validation loss: 3.054377791685219

Epoch: 5| Step: 3
Training loss: 2.9470916959634126
Validation loss: 3.0515723414742006

Epoch: 5| Step: 4
Training loss: 3.3830798882578095
Validation loss: 3.046745576468278

Epoch: 5| Step: 5
Training loss: 3.2252431023812775
Validation loss: 3.0423557367974174

Epoch: 5| Step: 6
Training loss: 2.8297384307002016
Validation loss: 3.0417913534107095

Epoch: 5| Step: 7
Training loss: 2.791933009029837
Validation loss: 3.04077801693681

Epoch: 5| Step: 8
Training loss: 3.4153160744277575
Validation loss: 3.039409982532254

Epoch: 5| Step: 9
Training loss: 3.557182224688338
Validation loss: 3.0423407409635526

Epoch: 5| Step: 10
Training loss: 3.9703861978860155
Validation loss: 3.040773454146152

Epoch: 197| Step: 0
Training loss: 2.934310480125512
Validation loss: 3.039403847150416

Epoch: 5| Step: 1
Training loss: 2.7946348116196083
Validation loss: 3.039470623797995

Epoch: 5| Step: 2
Training loss: 3.2956919784872842
Validation loss: 3.0409581017475222

Epoch: 5| Step: 3
Training loss: 3.3845933274904203
Validation loss: 3.040322607899993

Epoch: 5| Step: 4
Training loss: 2.6895545380752646
Validation loss: 3.0395576733097847

Epoch: 5| Step: 5
Training loss: 3.2250273888186394
Validation loss: 3.0395794420455595

Epoch: 5| Step: 6
Training loss: 3.5207417192145702
Validation loss: 3.040083228754628

Epoch: 5| Step: 7
Training loss: 3.5682372357825645
Validation loss: 3.039806152348727

Epoch: 5| Step: 8
Training loss: 4.032723091136454
Validation loss: 3.039671870985499

Epoch: 5| Step: 9
Training loss: 3.446959916951078
Validation loss: 3.0405402090274527

Epoch: 5| Step: 10
Training loss: 3.2863646834985882
Validation loss: 3.040203344836324

Epoch: 198| Step: 0
Training loss: 3.677451975267047
Validation loss: 3.0387626829258214

Epoch: 5| Step: 1
Training loss: 3.415053723472605
Validation loss: 3.040621215560297

Epoch: 5| Step: 2
Training loss: 3.122726987066656
Validation loss: 3.0406224920596805

Epoch: 5| Step: 3
Training loss: 2.5152494730750266
Validation loss: 3.0450208198308015

Epoch: 5| Step: 4
Training loss: 3.013983245013267
Validation loss: 3.046656165876899

Epoch: 5| Step: 5
Training loss: 3.229730930045592
Validation loss: 3.0483258087613083

Epoch: 5| Step: 6
Training loss: 3.2593883481214125
Validation loss: 3.0454180620487405

Epoch: 5| Step: 7
Training loss: 3.4251656930759444
Validation loss: 3.0422067560250685

Epoch: 5| Step: 8
Training loss: 3.6540366752466857
Validation loss: 3.051484705521532

Epoch: 5| Step: 9
Training loss: 3.6449126180004487
Validation loss: 3.0442335923239323

Epoch: 5| Step: 10
Training loss: 3.220129957952933
Validation loss: 3.0397082952619017

Epoch: 199| Step: 0
Training loss: 3.3934650392834986
Validation loss: 3.037170048695109

Epoch: 5| Step: 1
Training loss: 3.3878024258343724
Validation loss: 3.0361649510062687

Epoch: 5| Step: 2
Training loss: 3.364186660169208
Validation loss: 3.0369685175420833

Epoch: 5| Step: 3
Training loss: 3.286979541265766
Validation loss: 3.035244279695242

Epoch: 5| Step: 4
Training loss: 3.6473091553509733
Validation loss: 3.0369184314963267

Epoch: 5| Step: 5
Training loss: 4.141845292985999
Validation loss: 3.037246765251518

Epoch: 5| Step: 6
Training loss: 3.03012063922492
Validation loss: 3.037557079177757

Epoch: 5| Step: 7
Training loss: 3.3694301845678236
Validation loss: 3.0369879328062854

Epoch: 5| Step: 8
Training loss: 2.3831362645052834
Validation loss: 3.0374578371999457

Epoch: 5| Step: 9
Training loss: 3.1079757839324844
Validation loss: 3.0374281667755656

Epoch: 5| Step: 10
Training loss: 2.829669004029143
Validation loss: 3.0407210557545277

Epoch: 200| Step: 0
Training loss: 3.2418184736805338
Validation loss: 3.038164338806034

Epoch: 5| Step: 1
Training loss: 3.5576535101854927
Validation loss: 3.040493716371757

Epoch: 5| Step: 2
Training loss: 2.7267622997453858
Validation loss: 3.0448566795426637

Epoch: 5| Step: 3
Training loss: 3.673391864838759
Validation loss: 3.0553488079414497

Epoch: 5| Step: 4
Training loss: 2.88597599121597
Validation loss: 3.0620838147854115

Epoch: 5| Step: 5
Training loss: 3.7433262249230013
Validation loss: 3.0635328143882927

Epoch: 5| Step: 6
Training loss: 3.6929777161013435
Validation loss: 3.0520589485161693

Epoch: 5| Step: 7
Training loss: 3.5549834075840976
Validation loss: 3.0313268410090193

Epoch: 5| Step: 8
Training loss: 2.7533554067334958
Validation loss: 3.0343042498834585

Epoch: 5| Step: 9
Training loss: 2.490043938030808
Validation loss: 3.0322530135944152

Epoch: 5| Step: 10
Training loss: 3.7634237986645207
Validation loss: 3.0326124520157993

Testing loss: 3.2151752773248248
