Epoch: 1| Step: 0
Training loss: 5.747618804141817
Validation loss: 5.807788715660743

Epoch: 5| Step: 1
Training loss: 6.425017170567705
Validation loss: 5.8032737578967035

Epoch: 5| Step: 2
Training loss: 5.424313922867433
Validation loss: 5.799120048006185

Epoch: 5| Step: 3
Training loss: 5.959838925943667
Validation loss: 5.794705855126407

Epoch: 5| Step: 4
Training loss: 6.6319497561697025
Validation loss: 5.7904547149744126

Epoch: 5| Step: 5
Training loss: 5.6318168871329
Validation loss: 5.786314730017314

Epoch: 5| Step: 6
Training loss: 5.843090326131042
Validation loss: 5.782551879987733

Epoch: 5| Step: 7
Training loss: 5.259243411924299
Validation loss: 5.778787821946013

Epoch: 5| Step: 8
Training loss: 6.153449181443955
Validation loss: 5.774598826442702

Epoch: 5| Step: 9
Training loss: 5.538286464116691
Validation loss: 5.770441942575855

Epoch: 5| Step: 10
Training loss: 5.14310142905721
Validation loss: 5.766313574600351

Epoch: 2| Step: 0
Training loss: 5.05992682724467
Validation loss: 5.761858049519509

Epoch: 5| Step: 1
Training loss: 5.3579217035796125
Validation loss: 5.757161189968306

Epoch: 5| Step: 2
Training loss: 5.406524122046936
Validation loss: 5.752361531376723

Epoch: 5| Step: 3
Training loss: 5.863195043815801
Validation loss: 5.747460694957201

Epoch: 5| Step: 4
Training loss: 6.368609947034808
Validation loss: 5.742330082355176

Epoch: 5| Step: 5
Training loss: 6.014428591964643
Validation loss: 5.736760112888966

Epoch: 5| Step: 6
Training loss: 6.134289606153916
Validation loss: 5.730630040772732

Epoch: 5| Step: 7
Training loss: 4.8590217290197355
Validation loss: 5.724913911467287

Epoch: 5| Step: 8
Training loss: 5.92959389593857
Validation loss: 5.719353156130628

Epoch: 5| Step: 9
Training loss: 6.065287470282671
Validation loss: 5.712897887511467

Epoch: 5| Step: 10
Training loss: 6.276580441301841
Validation loss: 5.706039232998627

Epoch: 3| Step: 0
Training loss: 5.177669540569183
Validation loss: 5.698903138128891

Epoch: 5| Step: 1
Training loss: 6.4386352723167875
Validation loss: 5.6915258857748015

Epoch: 5| Step: 2
Training loss: 6.293802500925358
Validation loss: 5.683650915226781

Epoch: 5| Step: 3
Training loss: 4.427864466549407
Validation loss: 5.676470200062115

Epoch: 5| Step: 4
Training loss: 5.672880057409284
Validation loss: 5.667727587636655

Epoch: 5| Step: 5
Training loss: 6.309900938486723
Validation loss: 5.6584317664428445

Epoch: 5| Step: 6
Training loss: 5.08864707668403
Validation loss: 5.649721028646826

Epoch: 5| Step: 7
Training loss: 5.567525929055304
Validation loss: 5.639347883892748

Epoch: 5| Step: 8
Training loss: 5.2730578928763885
Validation loss: 5.630587199598421

Epoch: 5| Step: 9
Training loss: 6.483616354811329
Validation loss: 5.619948837583986

Epoch: 5| Step: 10
Training loss: 5.490778909261919
Validation loss: 5.609086862129288

Epoch: 4| Step: 0
Training loss: 5.893648459408309
Validation loss: 5.597979194971543

Epoch: 5| Step: 1
Training loss: 5.4849769718378765
Validation loss: 5.585646603616368

Epoch: 5| Step: 2
Training loss: 5.018870411873736
Validation loss: 5.574058656603766

Epoch: 5| Step: 3
Training loss: 5.831923323473904
Validation loss: 5.561145558117256

Epoch: 5| Step: 4
Training loss: 5.492338392808492
Validation loss: 5.548551469193858

Epoch: 5| Step: 5
Training loss: 5.151363022065851
Validation loss: 5.534331604216576

Epoch: 5| Step: 6
Training loss: 5.275876172235814
Validation loss: 5.520372397122269

Epoch: 5| Step: 7
Training loss: 6.287362384238117
Validation loss: 5.506742645715204

Epoch: 5| Step: 8
Training loss: 5.134159370115437
Validation loss: 5.49104318842925

Epoch: 5| Step: 9
Training loss: 6.298153125169786
Validation loss: 5.476074451656118

Epoch: 5| Step: 10
Training loss: 5.1848569824152895
Validation loss: 5.4602178260504

Epoch: 5| Step: 0
Training loss: 4.737153600745974
Validation loss: 5.444030506291324

Epoch: 5| Step: 1
Training loss: 5.54084832977975
Validation loss: 5.42756174974609

Epoch: 5| Step: 2
Training loss: 5.368952698261727
Validation loss: 5.409803086087946

Epoch: 5| Step: 3
Training loss: 5.834413955141611
Validation loss: 5.393401617546796

Epoch: 5| Step: 4
Training loss: 5.299428498746829
Validation loss: 5.377345991404061

Epoch: 5| Step: 5
Training loss: 6.301024326429462
Validation loss: 5.360313583755195

Epoch: 5| Step: 6
Training loss: 4.6389142617593295
Validation loss: 5.3435781945761285

Epoch: 5| Step: 7
Training loss: 5.413307654753667
Validation loss: 5.3256848479673735

Epoch: 5| Step: 8
Training loss: 5.021110031080166
Validation loss: 5.308386390516053

Epoch: 5| Step: 9
Training loss: 5.315526481670818
Validation loss: 5.292507845362107

Epoch: 5| Step: 10
Training loss: 5.873136184160496
Validation loss: 5.276177387791636

Epoch: 6| Step: 0
Training loss: 5.523356349408286
Validation loss: 5.2603257122561

Epoch: 5| Step: 1
Training loss: 4.645987036290764
Validation loss: 5.243762553935773

Epoch: 5| Step: 2
Training loss: 4.966567225815525
Validation loss: 5.227907794139435

Epoch: 5| Step: 3
Training loss: 5.044191006993992
Validation loss: 5.212532208886324

Epoch: 5| Step: 4
Training loss: 5.4175640634393725
Validation loss: 5.197294558000044

Epoch: 5| Step: 5
Training loss: 5.156136621326872
Validation loss: 5.1810704977820405

Epoch: 5| Step: 6
Training loss: 5.5950864761664985
Validation loss: 5.166372659331811

Epoch: 5| Step: 7
Training loss: 4.58791058025673
Validation loss: 5.150787851260053

Epoch: 5| Step: 8
Training loss: 5.101679708586087
Validation loss: 5.135447861741585

Epoch: 5| Step: 9
Training loss: 5.561438298431947
Validation loss: 5.120396661377644

Epoch: 5| Step: 10
Training loss: 5.958566656635008
Validation loss: 5.103483618545834

Epoch: 7| Step: 0
Training loss: 3.954929829395755
Validation loss: 5.08671770178736

Epoch: 5| Step: 1
Training loss: 5.587553374784393
Validation loss: 5.068333380206092

Epoch: 5| Step: 2
Training loss: 5.867516154139825
Validation loss: 5.050145401593021

Epoch: 5| Step: 3
Training loss: 4.517744260009915
Validation loss: 5.031993252862553

Epoch: 5| Step: 4
Training loss: 4.530074605095856
Validation loss: 5.0129199304055705

Epoch: 5| Step: 5
Training loss: 4.427676651035286
Validation loss: 4.994139475141372

Epoch: 5| Step: 6
Training loss: 5.569402976237107
Validation loss: 4.9741694384050525

Epoch: 5| Step: 7
Training loss: 5.201175542150416
Validation loss: 4.955827341183981

Epoch: 5| Step: 8
Training loss: 5.460957408426694
Validation loss: 4.93719710156551

Epoch: 5| Step: 9
Training loss: 5.557048912669193
Validation loss: 4.916701627300781

Epoch: 5| Step: 10
Training loss: 4.5187882164569775
Validation loss: 4.898253475196528

Epoch: 8| Step: 0
Training loss: 5.167912281791838
Validation loss: 4.8775888851655145

Epoch: 5| Step: 1
Training loss: 4.273634548630595
Validation loss: 4.861760983171916

Epoch: 5| Step: 2
Training loss: 3.181690981415496
Validation loss: 4.844253536095549

Epoch: 5| Step: 3
Training loss: 5.403560608953939
Validation loss: 4.828676005341855

Epoch: 5| Step: 4
Training loss: 5.496383865388509
Validation loss: 4.813820516990644

Epoch: 5| Step: 5
Training loss: 4.355839214906042
Validation loss: 4.799027234039959

Epoch: 5| Step: 6
Training loss: 6.343492624859008
Validation loss: 4.783942989980808

Epoch: 5| Step: 7
Training loss: 4.304311967867063
Validation loss: 4.7688305151671155

Epoch: 5| Step: 8
Training loss: 4.647489358070013
Validation loss: 4.755288697155467

Epoch: 5| Step: 9
Training loss: 5.011117972016601
Validation loss: 4.740957537940698

Epoch: 5| Step: 10
Training loss: 4.769244711076979
Validation loss: 4.7274779506231255

Epoch: 9| Step: 0
Training loss: 4.232010184537174
Validation loss: 4.71478312497632

Epoch: 5| Step: 1
Training loss: 5.2345426162528454
Validation loss: 4.701360222396588

Epoch: 5| Step: 2
Training loss: 5.027816643514923
Validation loss: 4.68872325946794

Epoch: 5| Step: 3
Training loss: 4.558006896070258
Validation loss: 4.678760285576507

Epoch: 5| Step: 4
Training loss: 5.056107240601884
Validation loss: 4.66735614057619

Epoch: 5| Step: 5
Training loss: 3.2872480520732497
Validation loss: 4.65701339221743

Epoch: 5| Step: 6
Training loss: 4.980540555548551
Validation loss: 4.646513952460868

Epoch: 5| Step: 7
Training loss: 5.360806021082904
Validation loss: 4.638046271303737

Epoch: 5| Step: 8
Training loss: 5.3632006989922445
Validation loss: 4.629815875492154

Epoch: 5| Step: 9
Training loss: 4.289551865084169
Validation loss: 4.620100179087829

Epoch: 5| Step: 10
Training loss: 4.416854542509026
Validation loss: 4.610938605221398

Epoch: 10| Step: 0
Training loss: 4.835211531421233
Validation loss: 4.602922283199149

Epoch: 5| Step: 1
Training loss: 4.105687564786034
Validation loss: 4.594985100519151

Epoch: 5| Step: 2
Training loss: 4.937902313452763
Validation loss: 4.585794077270859

Epoch: 5| Step: 3
Training loss: 4.380980409607561
Validation loss: 4.578373064936624

Epoch: 5| Step: 4
Training loss: 4.800394065893571
Validation loss: 4.570111225955976

Epoch: 5| Step: 5
Training loss: 4.89448663032086
Validation loss: 4.562165953122488

Epoch: 5| Step: 6
Training loss: 5.043490287589128
Validation loss: 4.555127043587193

Epoch: 5| Step: 7
Training loss: 4.626416169969882
Validation loss: 4.54557258128283

Epoch: 5| Step: 8
Training loss: 4.794635660054984
Validation loss: 4.537871214352774

Epoch: 5| Step: 9
Training loss: 4.052006005707307
Validation loss: 4.528893233187377

Epoch: 5| Step: 10
Training loss: 4.710997016492825
Validation loss: 4.522230209333522

Epoch: 11| Step: 0
Training loss: 3.0185393644972613
Validation loss: 4.511708431145975

Epoch: 5| Step: 1
Training loss: 4.278230590854751
Validation loss: 4.502186598313827

Epoch: 5| Step: 2
Training loss: 5.057816399309684
Validation loss: 4.495415769200494

Epoch: 5| Step: 3
Training loss: 4.5483890909588975
Validation loss: 4.485061314579458

Epoch: 5| Step: 4
Training loss: 4.604504303901078
Validation loss: 4.47926563211798

Epoch: 5| Step: 5
Training loss: 4.756861098302632
Validation loss: 4.470457953504335

Epoch: 5| Step: 6
Training loss: 5.289534712522037
Validation loss: 4.460895044256822

Epoch: 5| Step: 7
Training loss: 4.548250075645616
Validation loss: 4.451480371658218

Epoch: 5| Step: 8
Training loss: 4.6485969067336805
Validation loss: 4.447672683807282

Epoch: 5| Step: 9
Training loss: 5.137257502046592
Validation loss: 4.43962047659514

Epoch: 5| Step: 10
Training loss: 3.917571849249323
Validation loss: 4.430725484178076

Epoch: 12| Step: 0
Training loss: 4.368750113513165
Validation loss: 4.427808425657334

Epoch: 5| Step: 1
Training loss: 5.025875656733199
Validation loss: 4.418975959272255

Epoch: 5| Step: 2
Training loss: 3.7798813794208774
Validation loss: 4.415775579893548

Epoch: 5| Step: 3
Training loss: 3.493661454226853
Validation loss: 4.409102952851536

Epoch: 5| Step: 4
Training loss: 3.5121817448020125
Validation loss: 4.400165446705004

Epoch: 5| Step: 5
Training loss: 3.9764951089420983
Validation loss: 4.396519172624665

Epoch: 5| Step: 6
Training loss: 5.353896652518119
Validation loss: 4.390336074872256

Epoch: 5| Step: 7
Training loss: 5.216528505358405
Validation loss: 4.386105546906179

Epoch: 5| Step: 8
Training loss: 5.074897937969841
Validation loss: 4.382003939181447

Epoch: 5| Step: 9
Training loss: 4.995372920048268
Validation loss: 4.376422780817357

Epoch: 5| Step: 10
Training loss: 4.217807918901366
Validation loss: 4.369595187275673

Epoch: 13| Step: 0
Training loss: 4.7068438354157465
Validation loss: 4.3663374486845985

Epoch: 5| Step: 1
Training loss: 3.470767834714358
Validation loss: 4.3620134692495505

Epoch: 5| Step: 2
Training loss: 4.402157012038823
Validation loss: 4.355995792988297

Epoch: 5| Step: 3
Training loss: 4.264458465363171
Validation loss: 4.3532428415939295

Epoch: 5| Step: 4
Training loss: 4.931113833250517
Validation loss: 4.349282955467489

Epoch: 5| Step: 5
Training loss: 4.613191324337881
Validation loss: 4.346228914934617

Epoch: 5| Step: 6
Training loss: 4.995039386460335
Validation loss: 4.340809672435918

Epoch: 5| Step: 7
Training loss: 4.5732566805570585
Validation loss: 4.33543536142416

Epoch: 5| Step: 8
Training loss: 4.099424200796518
Validation loss: 4.333349305179464

Epoch: 5| Step: 9
Training loss: 4.298158100328549
Validation loss: 4.327869130957873

Epoch: 5| Step: 10
Training loss: 4.577920225595783
Validation loss: 4.323882838761726

Epoch: 14| Step: 0
Training loss: 4.450871054446595
Validation loss: 4.318760694792065

Epoch: 5| Step: 1
Training loss: 4.74987592033149
Validation loss: 4.31836063356069

Epoch: 5| Step: 2
Training loss: 3.825231712154489
Validation loss: 4.313165015066633

Epoch: 5| Step: 3
Training loss: 3.6749515711908565
Validation loss: 4.309674962216652

Epoch: 5| Step: 4
Training loss: 4.409086572417939
Validation loss: 4.304994917160265

Epoch: 5| Step: 5
Training loss: 4.801663571407155
Validation loss: 4.296362099860424

Epoch: 5| Step: 6
Training loss: 5.119457690605367
Validation loss: 4.29320252810326

Epoch: 5| Step: 7
Training loss: 4.347084796156567
Validation loss: 4.290397993346049

Epoch: 5| Step: 8
Training loss: 4.16955318920474
Validation loss: 4.282590494102199

Epoch: 5| Step: 9
Training loss: 4.603440838846818
Validation loss: 4.276801341513179

Epoch: 5| Step: 10
Training loss: 4.267123339969299
Validation loss: 4.270210862236323

Epoch: 15| Step: 0
Training loss: 5.314140874233686
Validation loss: 4.265176255370148

Epoch: 5| Step: 1
Training loss: 4.626693209444656
Validation loss: 4.262725059489024

Epoch: 5| Step: 2
Training loss: 3.9549452620430583
Validation loss: 4.258010867765309

Epoch: 5| Step: 3
Training loss: 3.9571054796221277
Validation loss: 4.250434387611371

Epoch: 5| Step: 4
Training loss: 3.81487162882758
Validation loss: 4.248059273016762

Epoch: 5| Step: 5
Training loss: 3.7492560602403544
Validation loss: 4.241709484604101

Epoch: 5| Step: 6
Training loss: 3.9920907503412244
Validation loss: 4.239466351298073

Epoch: 5| Step: 7
Training loss: 4.772162284272365
Validation loss: 4.233699665266474

Epoch: 5| Step: 8
Training loss: 4.43681974972808
Validation loss: 4.230982204612524

Epoch: 5| Step: 9
Training loss: 4.382353787548226
Validation loss: 4.223671718221193

Epoch: 5| Step: 10
Training loss: 4.86909675195838
Validation loss: 4.220346631322591

Epoch: 16| Step: 0
Training loss: 3.9890370339381263
Validation loss: 4.217203760058947

Epoch: 5| Step: 1
Training loss: 3.8721748636184388
Validation loss: 4.209887389527008

Epoch: 5| Step: 2
Training loss: 4.941282151665513
Validation loss: 4.211874578278561

Epoch: 5| Step: 3
Training loss: 4.40241263741023
Validation loss: 4.2049476784635935

Epoch: 5| Step: 4
Training loss: 4.170698478619684
Validation loss: 4.196932462198507

Epoch: 5| Step: 5
Training loss: 4.469744164913723
Validation loss: 4.19611758426817

Epoch: 5| Step: 6
Training loss: 4.8617173219556395
Validation loss: 4.187899388512241

Epoch: 5| Step: 7
Training loss: 4.3137941491855925
Validation loss: 4.1837496198173

Epoch: 5| Step: 8
Training loss: 3.758605873280243
Validation loss: 4.178822277741766

Epoch: 5| Step: 9
Training loss: 4.579794517471894
Validation loss: 4.180500263769721

Epoch: 5| Step: 10
Training loss: 3.9974193593015297
Validation loss: 4.171503030539356

Epoch: 17| Step: 0
Training loss: 3.874224923666058
Validation loss: 4.172009240280076

Epoch: 5| Step: 1
Training loss: 4.447773391357651
Validation loss: 4.163338129499652

Epoch: 5| Step: 2
Training loss: 4.395983484002866
Validation loss: 4.161684093301279

Epoch: 5| Step: 3
Training loss: 3.8832705436727486
Validation loss: 4.154084950530989

Epoch: 5| Step: 4
Training loss: 3.8047172028245724
Validation loss: 4.152346259096795

Epoch: 5| Step: 5
Training loss: 5.20328280922706
Validation loss: 4.139906723927878

Epoch: 5| Step: 6
Training loss: 4.834587833229624
Validation loss: 4.135347528123268

Epoch: 5| Step: 7
Training loss: 4.376452831459095
Validation loss: 4.125692779845591

Epoch: 5| Step: 8
Training loss: 4.152441129502545
Validation loss: 4.11678307225745

Epoch: 5| Step: 9
Training loss: 3.7094191486716928
Validation loss: 4.110528443500151

Epoch: 5| Step: 10
Training loss: 4.081144070382443
Validation loss: 4.104479974173411

Epoch: 18| Step: 0
Training loss: 4.083328143265728
Validation loss: 4.101639779217892

Epoch: 5| Step: 1
Training loss: 3.7691136578522153
Validation loss: 4.099450953867962

Epoch: 5| Step: 2
Training loss: 4.247670376634708
Validation loss: 4.097077138056287

Epoch: 5| Step: 3
Training loss: 4.658965477449726
Validation loss: 4.091611289582402

Epoch: 5| Step: 4
Training loss: 3.6551369823247537
Validation loss: 4.089315655963415

Epoch: 5| Step: 5
Training loss: 4.707248033778725
Validation loss: 4.084233769645337

Epoch: 5| Step: 6
Training loss: 3.2868740747816427
Validation loss: 4.0786276032087425

Epoch: 5| Step: 7
Training loss: 5.05447052338111
Validation loss: 4.072915592428976

Epoch: 5| Step: 8
Training loss: 4.621760703137962
Validation loss: 4.067228641307996

Epoch: 5| Step: 9
Training loss: 3.486718454602413
Validation loss: 4.066034697359494

Epoch: 5| Step: 10
Training loss: 4.575429493906658
Validation loss: 4.061192155433009

Epoch: 19| Step: 0
Training loss: 4.211274482110122
Validation loss: 4.062468259322974

Epoch: 5| Step: 1
Training loss: 3.4451991471308467
Validation loss: 4.051260556563595

Epoch: 5| Step: 2
Training loss: 4.790490290769009
Validation loss: 4.047340573118793

Epoch: 5| Step: 3
Training loss: 4.486120648500259
Validation loss: 4.041732730881615

Epoch: 5| Step: 4
Training loss: 4.127042091519167
Validation loss: 4.039366394925276

Epoch: 5| Step: 5
Training loss: 4.693135243881045
Validation loss: 4.034661494940067

Epoch: 5| Step: 6
Training loss: 4.066936476673548
Validation loss: 4.033583498357597

Epoch: 5| Step: 7
Training loss: 3.877053731770826
Validation loss: 4.027873474575951

Epoch: 5| Step: 8
Training loss: 4.144660566579391
Validation loss: 4.02294773362919

Epoch: 5| Step: 9
Training loss: 4.642865702862237
Validation loss: 4.019508475518735

Epoch: 5| Step: 10
Training loss: 3.0835876016335653
Validation loss: 4.018083662011084

Epoch: 20| Step: 0
Training loss: 3.5724633080298025
Validation loss: 4.012433166632223

Epoch: 5| Step: 1
Training loss: 4.315127249705661
Validation loss: 4.007578134215748

Epoch: 5| Step: 2
Training loss: 3.812560409317448
Validation loss: 4.008283651584393

Epoch: 5| Step: 3
Training loss: 4.849296101880748
Validation loss: 4.001563466525036

Epoch: 5| Step: 4
Training loss: 4.391901556944175
Validation loss: 3.9991090664225215

Epoch: 5| Step: 5
Training loss: 4.492779767342463
Validation loss: 3.995800659644224

Epoch: 5| Step: 6
Training loss: 3.6321785978779078
Validation loss: 3.9933425891941585

Epoch: 5| Step: 7
Training loss: 3.124745473033001
Validation loss: 3.9890872802545667

Epoch: 5| Step: 8
Training loss: 4.575212926026661
Validation loss: 3.9839008921867367

Epoch: 5| Step: 9
Training loss: 3.712516753804329
Validation loss: 3.9834540258009685

Epoch: 5| Step: 10
Training loss: 4.83620036801969
Validation loss: 3.980979965421876

Epoch: 21| Step: 0
Training loss: 4.9587589797142275
Validation loss: 3.9747830063987197

Epoch: 5| Step: 1
Training loss: 3.758667783101234
Validation loss: 3.975462343107376

Epoch: 5| Step: 2
Training loss: 4.513587571218877
Validation loss: 3.969419650735958

Epoch: 5| Step: 3
Training loss: 4.222571782370951
Validation loss: 3.9708497649779306

Epoch: 5| Step: 4
Training loss: 3.92269037897017
Validation loss: 3.9642032296857916

Epoch: 5| Step: 5
Training loss: 4.472337256637672
Validation loss: 3.9621147012689786

Epoch: 5| Step: 6
Training loss: 2.8214784362553016
Validation loss: 3.959247990335081

Epoch: 5| Step: 7
Training loss: 4.791809588526075
Validation loss: 3.9615986777789933

Epoch: 5| Step: 8
Training loss: 3.9432628784162866
Validation loss: 3.954788710703979

Epoch: 5| Step: 9
Training loss: 3.6069663461881896
Validation loss: 3.952658665353078

Epoch: 5| Step: 10
Training loss: 3.787259961066221
Validation loss: 3.9451399551100588

Epoch: 22| Step: 0
Training loss: 3.884540871648579
Validation loss: 3.941783753976888

Epoch: 5| Step: 1
Training loss: 4.24392153318819
Validation loss: 3.942213941065511

Epoch: 5| Step: 2
Training loss: 4.068042436946649
Validation loss: 3.9373056272941485

Epoch: 5| Step: 3
Training loss: 4.254793044906
Validation loss: 3.935561757003717

Epoch: 5| Step: 4
Training loss: 4.834135098660319
Validation loss: 3.932680322707594

Epoch: 5| Step: 5
Training loss: 4.305504030855945
Validation loss: 3.9280395275050486

Epoch: 5| Step: 6
Training loss: 3.067710958500221
Validation loss: 3.927058165672963

Epoch: 5| Step: 7
Training loss: 3.5948389145118953
Validation loss: 3.9296805417329046

Epoch: 5| Step: 8
Training loss: 4.257884397687117
Validation loss: 3.920682155613444

Epoch: 5| Step: 9
Training loss: 4.0269241188389335
Validation loss: 3.9201312903203163

Epoch: 5| Step: 10
Training loss: 4.193619995831
Validation loss: 3.915624087476408

Epoch: 23| Step: 0
Training loss: 4.81316182923799
Validation loss: 3.9156911172208133

Epoch: 5| Step: 1
Training loss: 5.055890324912029
Validation loss: 3.909198792223361

Epoch: 5| Step: 2
Training loss: 4.739256705742453
Validation loss: 3.9021956840362586

Epoch: 5| Step: 3
Training loss: 3.4826357482172523
Validation loss: 3.9009415065904314

Epoch: 5| Step: 4
Training loss: 3.6377312288495376
Validation loss: 3.8993601005588845

Epoch: 5| Step: 5
Training loss: 3.1930381683352613
Validation loss: 3.891558401468251

Epoch: 5| Step: 6
Training loss: 3.119225010599275
Validation loss: 3.88937759087713

Epoch: 5| Step: 7
Training loss: 3.2690586856068227
Validation loss: 3.8891637985247147

Epoch: 5| Step: 8
Training loss: 4.455926596100298
Validation loss: 3.8836038388492393

Epoch: 5| Step: 9
Training loss: 3.9461116774504297
Validation loss: 3.8820406582230467

Epoch: 5| Step: 10
Training loss: 4.358614291197227
Validation loss: 3.876875648045713

Epoch: 24| Step: 0
Training loss: 3.770981141173984
Validation loss: 3.8738170303999038

Epoch: 5| Step: 1
Training loss: 4.071737263385375
Validation loss: 3.869689380042139

Epoch: 5| Step: 2
Training loss: 4.624651509120503
Validation loss: 3.8637965528362446

Epoch: 5| Step: 3
Training loss: 4.293423240699582
Validation loss: 3.8655494539509507

Epoch: 5| Step: 4
Training loss: 4.126707012819461
Validation loss: 3.8660152749775825

Epoch: 5| Step: 5
Training loss: 4.370995350838944
Validation loss: 3.8612895918029264

Epoch: 5| Step: 6
Training loss: 3.675786049785987
Validation loss: 3.8590050647442378

Epoch: 5| Step: 7
Training loss: 3.252529333804807
Validation loss: 3.8521861159503543

Epoch: 5| Step: 8
Training loss: 3.7939944545160365
Validation loss: 3.851519867408299

Epoch: 5| Step: 9
Training loss: 3.5118026638507325
Validation loss: 3.8457603529701796

Epoch: 5| Step: 10
Training loss: 4.615731308215802
Validation loss: 3.8442342156218428

Epoch: 25| Step: 0
Training loss: 3.628883386381823
Validation loss: 3.8457053048621033

Epoch: 5| Step: 1
Training loss: 3.544658758313785
Validation loss: 3.840505263398188

Epoch: 5| Step: 2
Training loss: 3.5098592313703474
Validation loss: 3.8365216944083587

Epoch: 5| Step: 3
Training loss: 4.258316654140309
Validation loss: 3.842661871243503

Epoch: 5| Step: 4
Training loss: 4.231100582938716
Validation loss: 3.830933851580063

Epoch: 5| Step: 5
Training loss: 4.120379316405174
Validation loss: 3.8372095919855265

Epoch: 5| Step: 6
Training loss: 4.36403262260964
Validation loss: 3.8418572040101795

Epoch: 5| Step: 7
Training loss: 4.610316707299138
Validation loss: 3.8454073869190877

Epoch: 5| Step: 8
Training loss: 4.047890554132167
Validation loss: 3.837974465137091

Epoch: 5| Step: 9
Training loss: 3.799267176186719
Validation loss: 3.834646784206713

Epoch: 5| Step: 10
Training loss: 3.770758331283554
Validation loss: 3.8282957472986894

Epoch: 26| Step: 0
Training loss: 3.254560498686699
Validation loss: 3.8230381860514857

Epoch: 5| Step: 1
Training loss: 4.267972977657274
Validation loss: 3.818131506302987

Epoch: 5| Step: 2
Training loss: 4.200694235690998
Validation loss: 3.8185643461080847

Epoch: 5| Step: 3
Training loss: 3.558957664398724
Validation loss: 3.8148390710370177

Epoch: 5| Step: 4
Training loss: 3.881481287848112
Validation loss: 3.8131504724394816

Epoch: 5| Step: 5
Training loss: 3.8927400653877218
Validation loss: 3.814493307467572

Epoch: 5| Step: 6
Training loss: 3.8516199444245616
Validation loss: 3.810863802081537

Epoch: 5| Step: 7
Training loss: 3.8811908612990234
Validation loss: 3.810474190387972

Epoch: 5| Step: 8
Training loss: 5.185587151150084
Validation loss: 3.8073109468788036

Epoch: 5| Step: 9
Training loss: 3.2865202223345538
Validation loss: 3.806968160219951

Epoch: 5| Step: 10
Training loss: 4.259931292629016
Validation loss: 3.802855221145385

Epoch: 27| Step: 0
Training loss: 3.748645029051565
Validation loss: 3.799459052320626

Epoch: 5| Step: 1
Training loss: 3.3895000226349583
Validation loss: 3.799673136711203

Epoch: 5| Step: 2
Training loss: 4.666320560881378
Validation loss: 3.7944934850109373

Epoch: 5| Step: 3
Training loss: 3.905430333924758
Validation loss: 3.7949049079729407

Epoch: 5| Step: 4
Training loss: 4.044162621885508
Validation loss: 3.79563122556808

Epoch: 5| Step: 5
Training loss: 3.4227548800539465
Validation loss: 3.7920199020877328

Epoch: 5| Step: 6
Training loss: 3.6620713539692944
Validation loss: 3.7891478521816944

Epoch: 5| Step: 7
Training loss: 4.538413232797434
Validation loss: 3.7885330423988903

Epoch: 5| Step: 8
Training loss: 4.688138587686844
Validation loss: 3.7855410220979304

Epoch: 5| Step: 9
Training loss: 3.5599875709231
Validation loss: 3.7835827862894593

Epoch: 5| Step: 10
Training loss: 3.6446972775436484
Validation loss: 3.782026612001502

Epoch: 28| Step: 0
Training loss: 4.030177957093796
Validation loss: 3.7843832162141737

Epoch: 5| Step: 1
Training loss: 4.121043764507285
Validation loss: 3.7825424031833457

Epoch: 5| Step: 2
Training loss: 3.4925786765759126
Validation loss: 3.7767099624041305

Epoch: 5| Step: 3
Training loss: 3.561021196721662
Validation loss: 3.77972773615592

Epoch: 5| Step: 4
Training loss: 3.585261661445406
Validation loss: 3.7760899766908724

Epoch: 5| Step: 5
Training loss: 3.640105902210687
Validation loss: 3.7744660343558594

Epoch: 5| Step: 6
Training loss: 3.9587664852395323
Validation loss: 3.7727017724979945

Epoch: 5| Step: 7
Training loss: 4.278795192879919
Validation loss: 3.774024993227254

Epoch: 5| Step: 8
Training loss: 3.78651918609848
Validation loss: 3.773583174989721

Epoch: 5| Step: 9
Training loss: 4.724105120491406
Validation loss: 3.7674817750666914

Epoch: 5| Step: 10
Training loss: 4.162923861164475
Validation loss: 3.769149366644261

Epoch: 29| Step: 0
Training loss: 4.417502893901367
Validation loss: 3.7686220337842387

Epoch: 5| Step: 1
Training loss: 3.1096649801477527
Validation loss: 3.7678684418823565

Epoch: 5| Step: 2
Training loss: 3.7444749184439674
Validation loss: 3.766708473451256

Epoch: 5| Step: 3
Training loss: 3.557970480244806
Validation loss: 3.7665406012086375

Epoch: 5| Step: 4
Training loss: 3.5749800408079615
Validation loss: 3.7665239841408384

Epoch: 5| Step: 5
Training loss: 4.639010267262363
Validation loss: 3.7620319879254205

Epoch: 5| Step: 6
Training loss: 3.9689053482529806
Validation loss: 3.762598902940576

Epoch: 5| Step: 7
Training loss: 3.0154360380908254
Validation loss: 3.7612010601418246

Epoch: 5| Step: 8
Training loss: 4.976870253312874
Validation loss: 3.7592366280226908

Epoch: 5| Step: 9
Training loss: 3.639570353586205
Validation loss: 3.7582237174370565

Epoch: 5| Step: 10
Training loss: 4.270327257395375
Validation loss: 3.7553234120541172

Epoch: 30| Step: 0
Training loss: 3.467453172913465
Validation loss: 3.75379676305341

Epoch: 5| Step: 1
Training loss: 4.590219399521355
Validation loss: 3.7586758791563595

Epoch: 5| Step: 2
Training loss: 3.74197648315543
Validation loss: 3.7543791001194995

Epoch: 5| Step: 3
Training loss: 4.012114775517249
Validation loss: 3.748284027282057

Epoch: 5| Step: 4
Training loss: 3.6567156894519277
Validation loss: 3.7490391392404616

Epoch: 5| Step: 5
Training loss: 3.8579397892028147
Validation loss: 3.7495464324108094

Epoch: 5| Step: 6
Training loss: 4.019027040700502
Validation loss: 3.7537301274168136

Epoch: 5| Step: 7
Training loss: 3.4965751785319843
Validation loss: 3.7487116278786106

Epoch: 5| Step: 8
Training loss: 4.064137524913636
Validation loss: 3.75190341046602

Epoch: 5| Step: 9
Training loss: 3.7482244738733255
Validation loss: 3.7432089044569024

Epoch: 5| Step: 10
Training loss: 4.504306004592474
Validation loss: 3.746136577769898

Epoch: 31| Step: 0
Training loss: 3.9165401573581775
Validation loss: 3.7451107406020587

Epoch: 5| Step: 1
Training loss: 3.9916838983364253
Validation loss: 3.745508801020662

Epoch: 5| Step: 2
Training loss: 4.13779246054381
Validation loss: 3.7418740519511684

Epoch: 5| Step: 3
Training loss: 3.6311922787725632
Validation loss: 3.743496472224406

Epoch: 5| Step: 4
Training loss: 3.9615910158382097
Validation loss: 3.7377569627940894

Epoch: 5| Step: 5
Training loss: 3.9363655999351153
Validation loss: 3.7383415255112253

Epoch: 5| Step: 6
Training loss: 4.492651130966026
Validation loss: 3.7381200414577047

Epoch: 5| Step: 7
Training loss: 3.1394110463810962
Validation loss: 3.735953084528269

Epoch: 5| Step: 8
Training loss: 4.300469687780913
Validation loss: 3.740262211273244

Epoch: 5| Step: 9
Training loss: 4.1205952564324955
Validation loss: 3.7411556187503328

Epoch: 5| Step: 10
Training loss: 3.197277854378719
Validation loss: 3.73707531197957

Epoch: 32| Step: 0
Training loss: 4.376846577727602
Validation loss: 3.7335591261860035

Epoch: 5| Step: 1
Training loss: 3.5685517959203024
Validation loss: 3.733898509844978

Epoch: 5| Step: 2
Training loss: 3.8256708491830635
Validation loss: 3.7312818367321388

Epoch: 5| Step: 3
Training loss: 4.298189163383635
Validation loss: 3.731777128327031

Epoch: 5| Step: 4
Training loss: 3.47737629827429
Validation loss: 3.7351605153876797

Epoch: 5| Step: 5
Training loss: 3.581665286606324
Validation loss: 3.7348958631872518

Epoch: 5| Step: 6
Training loss: 3.122420047075412
Validation loss: 3.7321591291565706

Epoch: 5| Step: 7
Training loss: 4.5679491502299925
Validation loss: 3.7323187378534524

Epoch: 5| Step: 8
Training loss: 3.989579575074553
Validation loss: 3.729886574253753

Epoch: 5| Step: 9
Training loss: 4.0198906829546095
Validation loss: 3.7264050746501574

Epoch: 5| Step: 10
Training loss: 4.0078562832647435
Validation loss: 3.723771991308523

Epoch: 33| Step: 0
Training loss: 3.850995685583891
Validation loss: 3.7245242343356812

Epoch: 5| Step: 1
Training loss: 4.359064125270214
Validation loss: 3.7230486905548466

Epoch: 5| Step: 2
Training loss: 3.6323748581314335
Validation loss: 3.732294065181458

Epoch: 5| Step: 3
Training loss: 3.7397062800323084
Validation loss: 3.7267621491357996

Epoch: 5| Step: 4
Training loss: 3.2540195257612767
Validation loss: 3.718352831130745

Epoch: 5| Step: 5
Training loss: 4.243501744150968
Validation loss: 3.7192114425410456

Epoch: 5| Step: 6
Training loss: 3.461472308513032
Validation loss: 3.726115388353731

Epoch: 5| Step: 7
Training loss: 3.3279285641577716
Validation loss: 3.7207824221434507

Epoch: 5| Step: 8
Training loss: 4.292429563003303
Validation loss: 3.717430460407783

Epoch: 5| Step: 9
Training loss: 4.437469912144916
Validation loss: 3.7202978899907047

Epoch: 5| Step: 10
Training loss: 4.164217088989646
Validation loss: 3.7173116785246925

Epoch: 34| Step: 0
Training loss: 3.5647504959432488
Validation loss: 3.7180922627928545

Epoch: 5| Step: 1
Training loss: 4.171594045943981
Validation loss: 3.7136058253290725

Epoch: 5| Step: 2
Training loss: 4.304272307988699
Validation loss: 3.713391187735628

Epoch: 5| Step: 3
Training loss: 3.1889682454932284
Validation loss: 3.7131030517719075

Epoch: 5| Step: 4
Training loss: 4.156270650941413
Validation loss: 3.711153285300027

Epoch: 5| Step: 5
Training loss: 3.9130276893905327
Validation loss: 3.7089267839792472

Epoch: 5| Step: 6
Training loss: 3.428821358767376
Validation loss: 3.70969271427085

Epoch: 5| Step: 7
Training loss: 4.0552834603874235
Validation loss: 3.7074633318993944

Epoch: 5| Step: 8
Training loss: 4.368003045706334
Validation loss: 3.710631188281239

Epoch: 5| Step: 9
Training loss: 3.9753789133336253
Validation loss: 3.707040370303777

Epoch: 5| Step: 10
Training loss: 3.4638415825808644
Validation loss: 3.705870071679481

Epoch: 35| Step: 0
Training loss: 3.963012994237172
Validation loss: 3.705423640228672

Epoch: 5| Step: 1
Training loss: 4.036164356314252
Validation loss: 3.7069756507929075

Epoch: 5| Step: 2
Training loss: 4.015077071156805
Validation loss: 3.7030687176870254

Epoch: 5| Step: 3
Training loss: 3.686860368502048
Validation loss: 3.704544849543373

Epoch: 5| Step: 4
Training loss: 4.234644356919462
Validation loss: 3.704373465388117

Epoch: 5| Step: 5
Training loss: 4.15336703936359
Validation loss: 3.7072789162317417

Epoch: 5| Step: 6
Training loss: 3.0294923700821137
Validation loss: 3.7007265740021853

Epoch: 5| Step: 7
Training loss: 4.1682037315878
Validation loss: 3.7036692559156807

Epoch: 5| Step: 8
Training loss: 3.510971991348784
Validation loss: 3.7012368442210875

Epoch: 5| Step: 9
Training loss: 3.8726413070085672
Validation loss: 3.7007423282574834

Epoch: 5| Step: 10
Training loss: 3.956620310828121
Validation loss: 3.6961355969165934

Epoch: 36| Step: 0
Training loss: 4.333772465878976
Validation loss: 3.6983051563359237

Epoch: 5| Step: 1
Training loss: 3.6498121657442653
Validation loss: 3.694401783316109

Epoch: 5| Step: 2
Training loss: 3.193780135219709
Validation loss: 3.6934419440098507

Epoch: 5| Step: 3
Training loss: 3.1884264628050967
Validation loss: 3.6965980897700117

Epoch: 5| Step: 4
Training loss: 4.373523572025031
Validation loss: 3.696945145077554

Epoch: 5| Step: 5
Training loss: 3.6194819841628165
Validation loss: 3.6952954016806348

Epoch: 5| Step: 6
Training loss: 4.273846315568865
Validation loss: 3.694383562168069

Epoch: 5| Step: 7
Training loss: 3.4960526959443596
Validation loss: 3.6928286711661524

Epoch: 5| Step: 8
Training loss: 4.354678231931966
Validation loss: 3.6921831124228937

Epoch: 5| Step: 9
Training loss: 4.574365940869437
Validation loss: 3.693393168851151

Epoch: 5| Step: 10
Training loss: 3.1567519893481366
Validation loss: 3.6947705323384894

Epoch: 37| Step: 0
Training loss: 4.034791795163942
Validation loss: 3.693074250757653

Epoch: 5| Step: 1
Training loss: 3.6014706151002627
Validation loss: 3.6917294926469713

Epoch: 5| Step: 2
Training loss: 4.541823894800616
Validation loss: 3.688679396155673

Epoch: 5| Step: 3
Training loss: 3.6418050400714943
Validation loss: 3.691235343439208

Epoch: 5| Step: 4
Training loss: 3.8867596034677687
Validation loss: 3.6874967477379847

Epoch: 5| Step: 5
Training loss: 3.5774646132962946
Validation loss: 3.6887405961598256

Epoch: 5| Step: 6
Training loss: 4.03577281750312
Validation loss: 3.6860880761831005

Epoch: 5| Step: 7
Training loss: 3.8777761051887274
Validation loss: 3.686242029610984

Epoch: 5| Step: 8
Training loss: 4.033070471108428
Validation loss: 3.6864235323352172

Epoch: 5| Step: 9
Training loss: 3.316987075536675
Validation loss: 3.685378587732736

Epoch: 5| Step: 10
Training loss: 3.9701325418942273
Validation loss: 3.6844339390036285

Epoch: 38| Step: 0
Training loss: 4.186377531462911
Validation loss: 3.6851959719672114

Epoch: 5| Step: 1
Training loss: 4.715950849333576
Validation loss: 3.6878321077306087

Epoch: 5| Step: 2
Training loss: 3.9894049515780896
Validation loss: 3.6873137780038463

Epoch: 5| Step: 3
Training loss: 3.761296867567962
Validation loss: 3.684966607368766

Epoch: 5| Step: 4
Training loss: 3.4265916620449532
Validation loss: 3.6835898080701037

Epoch: 5| Step: 5
Training loss: 3.923169169484979
Validation loss: 3.6810680375979876

Epoch: 5| Step: 6
Training loss: 3.7675485090690572
Validation loss: 3.6820593147939076

Epoch: 5| Step: 7
Training loss: 4.106399212917518
Validation loss: 3.6815874973438483

Epoch: 5| Step: 8
Training loss: 3.2054002078131423
Validation loss: 3.6819438020139033

Epoch: 5| Step: 9
Training loss: 3.5841513446715987
Validation loss: 3.679786692113347

Epoch: 5| Step: 10
Training loss: 3.708621810379413
Validation loss: 3.680657717235688

Epoch: 39| Step: 0
Training loss: 4.018509952857021
Validation loss: 3.6811004943144177

Epoch: 5| Step: 1
Training loss: 3.5054741692974045
Validation loss: 3.680083653313783

Epoch: 5| Step: 2
Training loss: 3.584976100655756
Validation loss: 3.6795047703927146

Epoch: 5| Step: 3
Training loss: 4.349913471282113
Validation loss: 3.6779228552816594

Epoch: 5| Step: 4
Training loss: 4.17029395844335
Validation loss: 3.6788542575920133

Epoch: 5| Step: 5
Training loss: 4.642536219310241
Validation loss: 3.676870972582658

Epoch: 5| Step: 6
Training loss: 3.638797415893214
Validation loss: 3.6783688260320555

Epoch: 5| Step: 7
Training loss: 3.702592642460277
Validation loss: 3.6754154630398825

Epoch: 5| Step: 8
Training loss: 3.517478623748874
Validation loss: 3.67532107611099

Epoch: 5| Step: 9
Training loss: 4.303594931745767
Validation loss: 3.6762264498601134

Epoch: 5| Step: 10
Training loss: 2.511378334909387
Validation loss: 3.676264475819377

Epoch: 40| Step: 0
Training loss: 3.2561650124147166
Validation loss: 3.675192711912809

Epoch: 5| Step: 1
Training loss: 4.077796191994797
Validation loss: 3.676352380535182

Epoch: 5| Step: 2
Training loss: 4.435398947610338
Validation loss: 3.6763062265851163

Epoch: 5| Step: 3
Training loss: 3.7233700303125117
Validation loss: 3.6768903988739883

Epoch: 5| Step: 4
Training loss: 2.935137833798194
Validation loss: 3.6726419967787085

Epoch: 5| Step: 5
Training loss: 4.564052369949816
Validation loss: 3.6729624377045553

Epoch: 5| Step: 6
Training loss: 4.12739816947845
Validation loss: 3.675281129840521

Epoch: 5| Step: 7
Training loss: 3.7589100842754246
Validation loss: 3.6716565292529992

Epoch: 5| Step: 8
Training loss: 3.672853120429741
Validation loss: 3.6714234433365784

Epoch: 5| Step: 9
Training loss: 4.26099812737625
Validation loss: 3.6711197340992276

Epoch: 5| Step: 10
Training loss: 3.2633545205893246
Validation loss: 3.6723397565837175

Epoch: 41| Step: 0
Training loss: 4.407099865056504
Validation loss: 3.669450133144503

Epoch: 5| Step: 1
Training loss: 3.341745221236536
Validation loss: 3.6703996915338126

Epoch: 5| Step: 2
Training loss: 3.6985842393226913
Validation loss: 3.6693490938062565

Epoch: 5| Step: 3
Training loss: 3.7910717228429296
Validation loss: 3.6693698678108353

Epoch: 5| Step: 4
Training loss: 4.494323116677261
Validation loss: 3.6692425237029465

Epoch: 5| Step: 5
Training loss: 3.598629764881681
Validation loss: 3.670620472036083

Epoch: 5| Step: 6
Training loss: 3.3543189035938186
Validation loss: 3.6691042389792328

Epoch: 5| Step: 7
Training loss: 4.181235566848454
Validation loss: 3.6696483108409437

Epoch: 5| Step: 8
Training loss: 3.3237767715781867
Validation loss: 3.667553171307747

Epoch: 5| Step: 9
Training loss: 4.301009640705698
Validation loss: 3.668225479092091

Epoch: 5| Step: 10
Training loss: 3.706252053374418
Validation loss: 3.666298567192958

Epoch: 42| Step: 0
Training loss: 3.9218944533880085
Validation loss: 3.666868387939923

Epoch: 5| Step: 1
Training loss: 3.8066274721986084
Validation loss: 3.6658786759443793

Epoch: 5| Step: 2
Training loss: 3.7254611453133233
Validation loss: 3.665860413725624

Epoch: 5| Step: 3
Training loss: 3.955218217040519
Validation loss: 3.665355908611581

Epoch: 5| Step: 4
Training loss: 4.027051054773692
Validation loss: 3.6665645517092957

Epoch: 5| Step: 5
Training loss: 3.687483189431359
Validation loss: 3.6636595859238845

Epoch: 5| Step: 6
Training loss: 3.5260544085965
Validation loss: 3.6653457445570394

Epoch: 5| Step: 7
Training loss: 3.4027738419767357
Validation loss: 3.6639306598994086

Epoch: 5| Step: 8
Training loss: 4.080851728509396
Validation loss: 3.6627473416641565

Epoch: 5| Step: 9
Training loss: 3.727081710505181
Validation loss: 3.6634339156507685

Epoch: 5| Step: 10
Training loss: 4.558484335193453
Validation loss: 3.6628951805889276

Epoch: 43| Step: 0
Training loss: 4.49255475740597
Validation loss: 3.6622157130618453

Epoch: 5| Step: 1
Training loss: 3.723005920831694
Validation loss: 3.6608999010817835

Epoch: 5| Step: 2
Training loss: 4.033486625553691
Validation loss: 3.661664937188964

Epoch: 5| Step: 3
Training loss: 3.324920114116847
Validation loss: 3.664316206148255

Epoch: 5| Step: 4
Training loss: 4.316942221390305
Validation loss: 3.6626103963946326

Epoch: 5| Step: 5
Training loss: 3.5978887195013467
Validation loss: 3.661007173402417

Epoch: 5| Step: 6
Training loss: 3.0778399495234985
Validation loss: 3.6609974398371667

Epoch: 5| Step: 7
Training loss: 4.221578822275565
Validation loss: 3.661705335854178

Epoch: 5| Step: 8
Training loss: 4.0542810489923795
Validation loss: 3.659906525525782

Epoch: 5| Step: 9
Training loss: 4.016160506228803
Validation loss: 3.6602828694408625

Epoch: 5| Step: 10
Training loss: 3.147510628776996
Validation loss: 3.6608609907348395

Epoch: 44| Step: 0
Training loss: 3.610314449236144
Validation loss: 3.6606035014333838

Epoch: 5| Step: 1
Training loss: 3.867291073423622
Validation loss: 3.6595608501700583

Epoch: 5| Step: 2
Training loss: 4.128130331909525
Validation loss: 3.659598408316883

Epoch: 5| Step: 3
Training loss: 3.6395149339531185
Validation loss: 3.658602966833874

Epoch: 5| Step: 4
Training loss: 4.010675489652682
Validation loss: 3.6595579835907013

Epoch: 5| Step: 5
Training loss: 3.577867390383745
Validation loss: 3.6570632741054485

Epoch: 5| Step: 6
Training loss: 3.4602389007295535
Validation loss: 3.6573605873135593

Epoch: 5| Step: 7
Training loss: 3.9734064854751416
Validation loss: 3.6580212985136433

Epoch: 5| Step: 8
Training loss: 4.201686910913147
Validation loss: 3.656503589166855

Epoch: 5| Step: 9
Training loss: 4.105898238491625
Validation loss: 3.655666521071332

Epoch: 5| Step: 10
Training loss: 3.6928183786255517
Validation loss: 3.6556466467822837

Epoch: 45| Step: 0
Training loss: 4.253051111390917
Validation loss: 3.654517710761538

Epoch: 5| Step: 1
Training loss: 3.715614856548917
Validation loss: 3.654748260967013

Epoch: 5| Step: 2
Training loss: 4.456092675469513
Validation loss: 3.653568265624779

Epoch: 5| Step: 3
Training loss: 3.8120449607575346
Validation loss: 3.6538866747370853

Epoch: 5| Step: 4
Training loss: 3.3402901691322366
Validation loss: 3.6527682135986113

Epoch: 5| Step: 5
Training loss: 4.354771305916197
Validation loss: 3.652368867296547

Epoch: 5| Step: 6
Training loss: 4.196774815707863
Validation loss: 3.6524477023662225

Epoch: 5| Step: 7
Training loss: 3.3992476977389416
Validation loss: 3.6513686857902874

Epoch: 5| Step: 8
Training loss: 2.3753429968258435
Validation loss: 3.6511046767087656

Epoch: 5| Step: 9
Training loss: 4.260063822093579
Validation loss: 3.6504730282201927

Epoch: 5| Step: 10
Training loss: 3.6353283773957785
Validation loss: 3.6497725541894863

Epoch: 46| Step: 0
Training loss: 4.318482161302769
Validation loss: 3.6516189590418238

Epoch: 5| Step: 1
Training loss: 4.014499372954752
Validation loss: 3.6492778048150276

Epoch: 5| Step: 2
Training loss: 3.6329423122388245
Validation loss: 3.6495644126166273

Epoch: 5| Step: 3
Training loss: 4.051956344745901
Validation loss: 3.6474142633307087

Epoch: 5| Step: 4
Training loss: 3.6846781132769135
Validation loss: 3.647127560367291

Epoch: 5| Step: 5
Training loss: 3.157472883456899
Validation loss: 3.647330453421629

Epoch: 5| Step: 6
Training loss: 3.8807161071472955
Validation loss: 3.646455911430934

Epoch: 5| Step: 7
Training loss: 3.3430521584429136
Validation loss: 3.6444626109173766

Epoch: 5| Step: 8
Training loss: 3.908383816607878
Validation loss: 3.644337383361046

Epoch: 5| Step: 9
Training loss: 3.99755808680107
Validation loss: 3.6426836763386983

Epoch: 5| Step: 10
Training loss: 4.1632328888927415
Validation loss: 3.644846848777298

Epoch: 47| Step: 0
Training loss: 3.143988634763564
Validation loss: 3.6382985155261296

Epoch: 5| Step: 1
Training loss: 4.119401311244868
Validation loss: 3.6382122076517027

Epoch: 5| Step: 2
Training loss: 4.230695751859238
Validation loss: 3.6385440243944527

Epoch: 5| Step: 3
Training loss: 2.9412618046891277
Validation loss: 3.634691308428164

Epoch: 5| Step: 4
Training loss: 4.095463052170577
Validation loss: 3.6348803928251368

Epoch: 5| Step: 5
Training loss: 3.71990038605083
Validation loss: 3.6322064082343894

Epoch: 5| Step: 6
Training loss: 3.797648912213583
Validation loss: 3.6283840455987915

Epoch: 5| Step: 7
Training loss: 4.153284377232561
Validation loss: 3.627388927599278

Epoch: 5| Step: 8
Training loss: 3.6648415589270122
Validation loss: 3.6283925482310573

Epoch: 5| Step: 9
Training loss: 4.082668068597986
Validation loss: 3.6319847142085493

Epoch: 5| Step: 10
Training loss: 3.949717021414999
Validation loss: 3.6324343996750303

Epoch: 48| Step: 0
Training loss: 4.081043353844336
Validation loss: 3.631789724649027

Epoch: 5| Step: 1
Training loss: 3.783253414861607
Validation loss: 3.627117459339134

Epoch: 5| Step: 2
Training loss: 3.176690866378828
Validation loss: 3.6342815010572207

Epoch: 5| Step: 3
Training loss: 3.4753478939537534
Validation loss: 3.6373360576079343

Epoch: 5| Step: 4
Training loss: 4.062275102699196
Validation loss: 3.642789028974382

Epoch: 5| Step: 5
Training loss: 2.9647203904775536
Validation loss: 3.632722932679746

Epoch: 5| Step: 6
Training loss: 4.114832050516166
Validation loss: 3.634359343085043

Epoch: 5| Step: 7
Training loss: 3.261281460441768
Validation loss: 3.6254748470824967

Epoch: 5| Step: 8
Training loss: 4.365113122267329
Validation loss: 3.6268458619045822

Epoch: 5| Step: 9
Training loss: 4.257388032526172
Validation loss: 3.630141640459215

Epoch: 5| Step: 10
Training loss: 4.304904163813538
Validation loss: 3.627819864071588

Epoch: 49| Step: 0
Training loss: 3.4275273708861653
Validation loss: 3.626265035283792

Epoch: 5| Step: 1
Training loss: 4.260344090422607
Validation loss: 3.628760797517899

Epoch: 5| Step: 2
Training loss: 4.604318101328649
Validation loss: 3.6267953033076186

Epoch: 5| Step: 3
Training loss: 3.273833257746021
Validation loss: 3.6246766684170293

Epoch: 5| Step: 4
Training loss: 4.339668606881602
Validation loss: 3.624143942804755

Epoch: 5| Step: 5
Training loss: 3.0428203502505577
Validation loss: 3.6243114163972656

Epoch: 5| Step: 6
Training loss: 4.227446909547993
Validation loss: 3.6195174664534706

Epoch: 5| Step: 7
Training loss: 2.9997719042213786
Validation loss: 3.6189530842584094

Epoch: 5| Step: 8
Training loss: 4.333157804797708
Validation loss: 3.6221161482521453

Epoch: 5| Step: 9
Training loss: 3.9015893827527375
Validation loss: 3.6200848737824525

Epoch: 5| Step: 10
Training loss: 2.973649489382628
Validation loss: 3.622994849598754

Epoch: 50| Step: 0
Training loss: 3.357763711282869
Validation loss: 3.6234292816526104

Epoch: 5| Step: 1
Training loss: 4.051707089305002
Validation loss: 3.616469595560286

Epoch: 5| Step: 2
Training loss: 3.560794087259238
Validation loss: 3.6170521482275264

Epoch: 5| Step: 3
Training loss: 4.542097065448197
Validation loss: 3.616400586914399

Epoch: 5| Step: 4
Training loss: 3.700771694642113
Validation loss: 3.6130045126379233

Epoch: 5| Step: 5
Training loss: 3.9620759370045926
Validation loss: 3.6160222168115688

Epoch: 5| Step: 6
Training loss: 3.904912612855515
Validation loss: 3.61770164485561

Epoch: 5| Step: 7
Training loss: 3.311030511778283
Validation loss: 3.6112506156922595

Epoch: 5| Step: 8
Training loss: 4.049765007830991
Validation loss: 3.611097662253587

Epoch: 5| Step: 9
Training loss: 3.3260589060748287
Validation loss: 3.6095939938781387

Epoch: 5| Step: 10
Training loss: 4.0001254062067675
Validation loss: 3.6124430771206457

Epoch: 51| Step: 0
Training loss: 4.085881949461052
Validation loss: 3.625813687422988

Epoch: 5| Step: 1
Training loss: 3.2940983220743676
Validation loss: 3.6073288970878807

Epoch: 5| Step: 2
Training loss: 4.155665306323837
Validation loss: 3.6075020433575222

Epoch: 5| Step: 3
Training loss: 4.337727714959294
Validation loss: 3.6085202503442604

Epoch: 5| Step: 4
Training loss: 3.989992975596887
Validation loss: 3.609163498733475

Epoch: 5| Step: 5
Training loss: 3.4832054193790105
Validation loss: 3.607904049327395

Epoch: 5| Step: 6
Training loss: 2.9884864487349545
Validation loss: 3.6097762235498827

Epoch: 5| Step: 7
Training loss: 4.596890991100139
Validation loss: 3.608892311834648

Epoch: 5| Step: 8
Training loss: 3.0591477712035373
Validation loss: 3.6069741331242984

Epoch: 5| Step: 9
Training loss: 3.373972418436626
Validation loss: 3.6102594794925102

Epoch: 5| Step: 10
Training loss: 4.196336219954073
Validation loss: 3.607130446838157

Epoch: 52| Step: 0
Training loss: 3.0559344856269965
Validation loss: 3.6074798826451606

Epoch: 5| Step: 1
Training loss: 3.292977583071264
Validation loss: 3.605846482788512

Epoch: 5| Step: 2
Training loss: 3.764926576544358
Validation loss: 3.6062100206761856

Epoch: 5| Step: 3
Training loss: 4.086805204083386
Validation loss: 3.60647460649793

Epoch: 5| Step: 4
Training loss: 3.9136710513694988
Validation loss: 3.604140370790086

Epoch: 5| Step: 5
Training loss: 3.0898656639354067
Validation loss: 3.6046684471129056

Epoch: 5| Step: 6
Training loss: 4.072046419459917
Validation loss: 3.601071617074078

Epoch: 5| Step: 7
Training loss: 4.32350435360367
Validation loss: 3.6029776402498856

Epoch: 5| Step: 8
Training loss: 3.708904408119645
Validation loss: 3.6036512404772565

Epoch: 5| Step: 9
Training loss: 3.8835062984426774
Validation loss: 3.622099511271798

Epoch: 5| Step: 10
Training loss: 4.474432260312366
Validation loss: 3.5999675836436733

Epoch: 53| Step: 0
Training loss: 3.65360810126001
Validation loss: 3.600362665271381

Epoch: 5| Step: 1
Training loss: 4.169976534697379
Validation loss: 3.598851218426032

Epoch: 5| Step: 2
Training loss: 3.8129816220108483
Validation loss: 3.6001560379038278

Epoch: 5| Step: 3
Training loss: 3.676592713964249
Validation loss: 3.6016389394118034

Epoch: 5| Step: 4
Training loss: 4.1445372327065675
Validation loss: 3.598534097704934

Epoch: 5| Step: 5
Training loss: 4.241774733889861
Validation loss: 3.5980350893984974

Epoch: 5| Step: 6
Training loss: 3.792271967490602
Validation loss: 3.602722127914335

Epoch: 5| Step: 7
Training loss: 3.24212690549551
Validation loss: 3.5963074161314674

Epoch: 5| Step: 8
Training loss: 3.2814679754607705
Validation loss: 3.599122787234053

Epoch: 5| Step: 9
Training loss: 3.9911240805557027
Validation loss: 3.5972165972801258

Epoch: 5| Step: 10
Training loss: 3.6176546590206193
Validation loss: 3.596441437236807

Epoch: 54| Step: 0
Training loss: 3.901260851961374
Validation loss: 3.5940022669383227

Epoch: 5| Step: 1
Training loss: 4.125596205656102
Validation loss: 3.5925985366865523

Epoch: 5| Step: 2
Training loss: 4.105075922646069
Validation loss: 3.593077154960191

Epoch: 5| Step: 3
Training loss: 3.6755443662877756
Validation loss: 3.600659603788197

Epoch: 5| Step: 4
Training loss: 2.9927219481290734
Validation loss: 3.5999230824392123

Epoch: 5| Step: 5
Training loss: 4.181218688573905
Validation loss: 3.5948571438727455

Epoch: 5| Step: 6
Training loss: 3.258724240580577
Validation loss: 3.5915418991833543

Epoch: 5| Step: 7
Training loss: 4.192295118863587
Validation loss: 3.5922662854636873

Epoch: 5| Step: 8
Training loss: 3.773413995705136
Validation loss: 3.593930521421855

Epoch: 5| Step: 9
Training loss: 3.7903626403838557
Validation loss: 3.5956069550116023

Epoch: 5| Step: 10
Training loss: 3.5028696557530243
Validation loss: 3.5932274679744207

Epoch: 55| Step: 0
Training loss: 3.8825003116605084
Validation loss: 3.591541652208736

Epoch: 5| Step: 1
Training loss: 3.6535801717341667
Validation loss: 3.5925139068280223

Epoch: 5| Step: 2
Training loss: 4.152991372650392
Validation loss: 3.5884154172967406

Epoch: 5| Step: 3
Training loss: 3.826207019124585
Validation loss: 3.585664982621084

Epoch: 5| Step: 4
Training loss: 4.006609462852273
Validation loss: 3.5856244407687017

Epoch: 5| Step: 5
Training loss: 3.4827552759903995
Validation loss: 3.585795510773327

Epoch: 5| Step: 6
Training loss: 3.9955889699055214
Validation loss: 3.58522975292112

Epoch: 5| Step: 7
Training loss: 3.572726779410906
Validation loss: 3.586812177660697

Epoch: 5| Step: 8
Training loss: 2.428533445590177
Validation loss: 3.585253293922877

Epoch: 5| Step: 9
Training loss: 3.62216312292626
Validation loss: 3.587934728123139

Epoch: 5| Step: 10
Training loss: 4.815817346017712
Validation loss: 3.5872611939752805

Epoch: 56| Step: 0
Training loss: 3.9323897124271436
Validation loss: 3.5823459900953414

Epoch: 5| Step: 1
Training loss: 3.38794739643861
Validation loss: 3.5824069571103694

Epoch: 5| Step: 2
Training loss: 2.6702188635000876
Validation loss: 3.581485541352514

Epoch: 5| Step: 3
Training loss: 3.853249201818631
Validation loss: 3.5811598916924594

Epoch: 5| Step: 4
Training loss: 4.472428948236236
Validation loss: 3.5806547232875916

Epoch: 5| Step: 5
Training loss: 4.735986617842661
Validation loss: 3.580577629693791

Epoch: 5| Step: 6
Training loss: 3.3865645746427306
Validation loss: 3.5809676757610482

Epoch: 5| Step: 7
Training loss: 4.19309009527808
Validation loss: 3.5808232342696518

Epoch: 5| Step: 8
Training loss: 3.2874141377306967
Validation loss: 3.580156892063358

Epoch: 5| Step: 9
Training loss: 3.4084613866153526
Validation loss: 3.5797188599638545

Epoch: 5| Step: 10
Training loss: 3.8480975367582335
Validation loss: 3.5796723008637152

Epoch: 57| Step: 0
Training loss: 3.8363424736106526
Validation loss: 3.5785724771881617

Epoch: 5| Step: 1
Training loss: 3.376332761618039
Validation loss: 3.580501907728991

Epoch: 5| Step: 2
Training loss: 4.6508114178584385
Validation loss: 3.578911564055866

Epoch: 5| Step: 3
Training loss: 2.866833574034415
Validation loss: 3.577701190819281

Epoch: 5| Step: 4
Training loss: 4.560219808935809
Validation loss: 3.577262161439173

Epoch: 5| Step: 5
Training loss: 3.588328775514318
Validation loss: 3.5776879874445457

Epoch: 5| Step: 6
Training loss: 3.0951225241718996
Validation loss: 3.5788458512568173

Epoch: 5| Step: 7
Training loss: 4.225161731039699
Validation loss: 3.5766593989830247

Epoch: 5| Step: 8
Training loss: 3.9303230393601982
Validation loss: 3.576087346745293

Epoch: 5| Step: 9
Training loss: 3.2104690841234254
Validation loss: 3.5754005114269956

Epoch: 5| Step: 10
Training loss: 3.807044957522008
Validation loss: 3.5764684163651164

Epoch: 58| Step: 0
Training loss: 3.425610597855461
Validation loss: 3.5743104001824424

Epoch: 5| Step: 1
Training loss: 3.9001238583190525
Validation loss: 3.574981588322977

Epoch: 5| Step: 2
Training loss: 4.276599223516169
Validation loss: 3.5753814543669042

Epoch: 5| Step: 3
Training loss: 3.488255960985809
Validation loss: 3.5738305698572415

Epoch: 5| Step: 4
Training loss: 4.001354703382377
Validation loss: 3.5748789818942766

Epoch: 5| Step: 5
Training loss: 4.075790029132054
Validation loss: 3.574403724880108

Epoch: 5| Step: 6
Training loss: 4.477638421573428
Validation loss: 3.5730737236492605

Epoch: 5| Step: 7
Training loss: 3.1921524800280943
Validation loss: 3.5729602294569895

Epoch: 5| Step: 8
Training loss: 3.451310315294186
Validation loss: 3.572279939241726

Epoch: 5| Step: 9
Training loss: 2.881871677281771
Validation loss: 3.57292843924383

Epoch: 5| Step: 10
Training loss: 4.118762531174625
Validation loss: 3.5723179155527536

Epoch: 59| Step: 0
Training loss: 3.5482062307671307
Validation loss: 3.5719627691058777

Epoch: 5| Step: 1
Training loss: 4.554630966228262
Validation loss: 3.5729530658133664

Epoch: 5| Step: 2
Training loss: 3.8513422471649235
Validation loss: 3.571393145987613

Epoch: 5| Step: 3
Training loss: 4.27858567693782
Validation loss: 3.5716004468282567

Epoch: 5| Step: 4
Training loss: 3.9579099863774205
Validation loss: 3.571218900839777

Epoch: 5| Step: 5
Training loss: 2.9977233513347583
Validation loss: 3.572608678803084

Epoch: 5| Step: 6
Training loss: 3.5260178956320374
Validation loss: 3.5697750296352053

Epoch: 5| Step: 7
Training loss: 3.614599237031423
Validation loss: 3.5704289432587744

Epoch: 5| Step: 8
Training loss: 3.995449577310306
Validation loss: 3.569994424036762

Epoch: 5| Step: 9
Training loss: 3.182955026033812
Validation loss: 3.5696250390284723

Epoch: 5| Step: 10
Training loss: 3.7547442625202465
Validation loss: 3.5685453849303856

Epoch: 60| Step: 0
Training loss: 4.040059009158821
Validation loss: 3.568875034539013

Epoch: 5| Step: 1
Training loss: 3.381979753926572
Validation loss: 3.5691401427183624

Epoch: 5| Step: 2
Training loss: 3.8425410160414604
Validation loss: 3.5681238952634664

Epoch: 5| Step: 3
Training loss: 3.7600670790268804
Validation loss: 3.5675994695957574

Epoch: 5| Step: 4
Training loss: 3.4022617614888135
Validation loss: 3.5678472652499673

Epoch: 5| Step: 5
Training loss: 3.3964856385222637
Validation loss: 3.567373237414997

Epoch: 5| Step: 6
Training loss: 3.3494194666463923
Validation loss: 3.567999300743335

Epoch: 5| Step: 7
Training loss: 3.8561150377295674
Validation loss: 3.566951288691715

Epoch: 5| Step: 8
Training loss: 3.8154259382180196
Validation loss: 3.56641663708174

Epoch: 5| Step: 9
Training loss: 4.655688360763511
Validation loss: 3.566536903627585

Epoch: 5| Step: 10
Training loss: 3.817715438829222
Validation loss: 3.56643251595999

Epoch: 61| Step: 0
Training loss: 3.6038203578383072
Validation loss: 3.566284867698906

Epoch: 5| Step: 1
Training loss: 3.2789185006360673
Validation loss: 3.565634555449206

Epoch: 5| Step: 2
Training loss: 3.877088414673479
Validation loss: 3.5656454811407783

Epoch: 5| Step: 3
Training loss: 4.342953835393305
Validation loss: 3.5659806584188476

Epoch: 5| Step: 4
Training loss: 3.8977724169258456
Validation loss: 3.565567581292362

Epoch: 5| Step: 5
Training loss: 4.115507821954462
Validation loss: 3.5642272426333848

Epoch: 5| Step: 6
Training loss: 3.9617870856762916
Validation loss: 3.5648275492304164

Epoch: 5| Step: 7
Training loss: 3.7511770308559536
Validation loss: 3.5657447311319728

Epoch: 5| Step: 8
Training loss: 3.7008254238823803
Validation loss: 3.5632047735054386

Epoch: 5| Step: 9
Training loss: 3.723863435972177
Validation loss: 3.563144716891203

Epoch: 5| Step: 10
Training loss: 2.902689403626537
Validation loss: 3.563468566843655

Epoch: 62| Step: 0
Training loss: 4.116000907490059
Validation loss: 3.5630457067421952

Epoch: 5| Step: 1
Training loss: 4.317664109000872
Validation loss: 3.5659240807167856

Epoch: 5| Step: 2
Training loss: 3.1549705707126634
Validation loss: 3.564710816561533

Epoch: 5| Step: 3
Training loss: 3.690363144205242
Validation loss: 3.5664175313038333

Epoch: 5| Step: 4
Training loss: 3.5646651531544684
Validation loss: 3.5627421620792328

Epoch: 5| Step: 5
Training loss: 3.338231461624828
Validation loss: 3.562487775101238

Epoch: 5| Step: 6
Training loss: 3.5308175961579873
Validation loss: 3.5617498281914375

Epoch: 5| Step: 7
Training loss: 4.103336205025688
Validation loss: 3.562837444760615

Epoch: 5| Step: 8
Training loss: 3.550258954771477
Validation loss: 3.560825499114244

Epoch: 5| Step: 9
Training loss: 3.0621507406573407
Validation loss: 3.560718701996493

Epoch: 5| Step: 10
Training loss: 4.825260435991666
Validation loss: 3.5610191867120946

Epoch: 63| Step: 0
Training loss: 4.23640646538906
Validation loss: 3.5603901966873934

Epoch: 5| Step: 1
Training loss: 3.7985635150451325
Validation loss: 3.560157608122375

Epoch: 5| Step: 2
Training loss: 2.8718219274820127
Validation loss: 3.5590416068905486

Epoch: 5| Step: 3
Training loss: 4.2036139335015905
Validation loss: 3.561229645544095

Epoch: 5| Step: 4
Training loss: 3.5525107625305665
Validation loss: 3.5600782869563115

Epoch: 5| Step: 5
Training loss: 4.173393973091765
Validation loss: 3.5588930238587233

Epoch: 5| Step: 6
Training loss: 4.39187875678305
Validation loss: 3.5617251990167915

Epoch: 5| Step: 7
Training loss: 3.1240345798781446
Validation loss: 3.5578520353639735

Epoch: 5| Step: 8
Training loss: 4.020237748436662
Validation loss: 3.5585869111570054

Epoch: 5| Step: 9
Training loss: 3.327286162351648
Validation loss: 3.5583950399814146

Epoch: 5| Step: 10
Training loss: 3.3131973684136278
Validation loss: 3.559471786312328

Epoch: 64| Step: 0
Training loss: 3.831025064408796
Validation loss: 3.56042052340735

Epoch: 5| Step: 1
Training loss: 4.292492216144274
Validation loss: 3.5599439814120135

Epoch: 5| Step: 2
Training loss: 3.5991517975071603
Validation loss: 3.560510558790624

Epoch: 5| Step: 3
Training loss: 4.404091597211718
Validation loss: 3.5617565796275374

Epoch: 5| Step: 4
Training loss: 4.071582442318309
Validation loss: 3.5605879731144423

Epoch: 5| Step: 5
Training loss: 2.9140230641496294
Validation loss: 3.56052421035336

Epoch: 5| Step: 6
Training loss: 3.8044412208134473
Validation loss: 3.559406877094942

Epoch: 5| Step: 7
Training loss: 3.268917778187723
Validation loss: 3.559270430058979

Epoch: 5| Step: 8
Training loss: 3.643268722235827
Validation loss: 3.5578368776624303

Epoch: 5| Step: 9
Training loss: 3.748200302601617
Validation loss: 3.557565594611789

Epoch: 5| Step: 10
Training loss: 3.573810624965693
Validation loss: 3.556298275658524

Epoch: 65| Step: 0
Training loss: 3.9436535661759398
Validation loss: 3.5579901637530167

Epoch: 5| Step: 1
Training loss: 4.260795346369335
Validation loss: 3.5558858862430687

Epoch: 5| Step: 2
Training loss: 4.292922098671681
Validation loss: 3.555386814914631

Epoch: 5| Step: 3
Training loss: 3.056168219285436
Validation loss: 3.554412172678572

Epoch: 5| Step: 4
Training loss: 3.5420679800013963
Validation loss: 3.5557710936249376

Epoch: 5| Step: 5
Training loss: 3.4169967926072857
Validation loss: 3.554579840518038

Epoch: 5| Step: 6
Training loss: 3.7002326840617377
Validation loss: 3.553157977394533

Epoch: 5| Step: 7
Training loss: 4.087730349894932
Validation loss: 3.5530414385574054

Epoch: 5| Step: 8
Training loss: 3.3296952102980004
Validation loss: 3.553506309897836

Epoch: 5| Step: 9
Training loss: 3.769456615598578
Validation loss: 3.5529583716921076

Epoch: 5| Step: 10
Training loss: 3.7822260582074283
Validation loss: 3.5530709895860246

Epoch: 66| Step: 0
Training loss: 4.076257036724176
Validation loss: 3.5523298408546333

Epoch: 5| Step: 1
Training loss: 4.207217354939497
Validation loss: 3.551478064099504

Epoch: 5| Step: 2
Training loss: 4.273555551742952
Validation loss: 3.5511371763524893

Epoch: 5| Step: 3
Training loss: 3.063853062266238
Validation loss: 3.550721748581189

Epoch: 5| Step: 4
Training loss: 3.3449992760627545
Validation loss: 3.550807244555306

Epoch: 5| Step: 5
Training loss: 3.942515977864614
Validation loss: 3.5510320168894096

Epoch: 5| Step: 6
Training loss: 3.8516687219917713
Validation loss: 3.5498489705943754

Epoch: 5| Step: 7
Training loss: 3.645423575490065
Validation loss: 3.5499958754681193

Epoch: 5| Step: 8
Training loss: 3.8900550516739107
Validation loss: 3.5490888616430136

Epoch: 5| Step: 9
Training loss: 4.055801738310012
Validation loss: 3.54900148009978

Epoch: 5| Step: 10
Training loss: 2.392080723966464
Validation loss: 3.5497445933929406

Epoch: 67| Step: 0
Training loss: 2.644986495216089
Validation loss: 3.5479134011789046

Epoch: 5| Step: 1
Training loss: 4.05579868151099
Validation loss: 3.548323963019414

Epoch: 5| Step: 2
Training loss: 4.016029664070637
Validation loss: 3.547195433828886

Epoch: 5| Step: 3
Training loss: 3.527698452542438
Validation loss: 3.5464468665028925

Epoch: 5| Step: 4
Training loss: 3.8544392394862204
Validation loss: 3.5475860630311407

Epoch: 5| Step: 5
Training loss: 3.44145987184211
Validation loss: 3.546044748375982

Epoch: 5| Step: 6
Training loss: 3.946382947681456
Validation loss: 3.5454441842079

Epoch: 5| Step: 7
Training loss: 4.873356077364664
Validation loss: 3.545735413060229

Epoch: 5| Step: 8
Training loss: 3.2388911023867593
Validation loss: 3.5431317772868303

Epoch: 5| Step: 9
Training loss: 3.557779631464953
Validation loss: 3.5447889146170386

Epoch: 5| Step: 10
Training loss: 3.714805241815396
Validation loss: 3.5425932963486706

Epoch: 68| Step: 0
Training loss: 3.782070732895604
Validation loss: 3.5406307947118836

Epoch: 5| Step: 1
Training loss: 3.5401100477796765
Validation loss: 3.5384171713898493

Epoch: 5| Step: 2
Training loss: 3.88250104856262
Validation loss: 3.539807589704768

Epoch: 5| Step: 3
Training loss: 4.711443568640962
Validation loss: 3.536077890165769

Epoch: 5| Step: 4
Training loss: 3.681034303314123
Validation loss: 3.532983518299871

Epoch: 5| Step: 5
Training loss: 4.062081652888864
Validation loss: 3.5303208906330314

Epoch: 5| Step: 6
Training loss: 3.8104806774026407
Validation loss: 3.5237133704930104

Epoch: 5| Step: 7
Training loss: 2.8111665743690994
Validation loss: 3.520474287379242

Epoch: 5| Step: 8
Training loss: 3.587103228276613
Validation loss: 3.520562696652757

Epoch: 5| Step: 9
Training loss: 3.6293498282448953
Validation loss: 3.5208856824252592

Epoch: 5| Step: 10
Training loss: 3.2838844985629967
Validation loss: 3.51733017562897

Epoch: 69| Step: 0
Training loss: 3.839078716388217
Validation loss: 3.51795496437219

Epoch: 5| Step: 1
Training loss: 3.739675295804998
Validation loss: 3.516804371839685

Epoch: 5| Step: 2
Training loss: 3.9751885519353043
Validation loss: 3.5172995852493396

Epoch: 5| Step: 3
Training loss: 4.546075809677395
Validation loss: 3.51706946155558

Epoch: 5| Step: 4
Training loss: 3.6300350605766365
Validation loss: 3.5141549062748156

Epoch: 5| Step: 5
Training loss: 3.0442969737414014
Validation loss: 3.513558359092086

Epoch: 5| Step: 6
Training loss: 3.991633247973582
Validation loss: 3.511174388419755

Epoch: 5| Step: 7
Training loss: 3.298058030903568
Validation loss: 3.5114295914613334

Epoch: 5| Step: 8
Training loss: 3.754522267109843
Validation loss: 3.514525190302172

Epoch: 5| Step: 9
Training loss: 3.3761939303485318
Validation loss: 3.5102293565160525

Epoch: 5| Step: 10
Training loss: 3.5459518239491854
Validation loss: 3.5097669485402165

Epoch: 70| Step: 0
Training loss: 3.6275440365348444
Validation loss: 3.5084979570656567

Epoch: 5| Step: 1
Training loss: 3.6541154939786673
Validation loss: 3.509240315426533

Epoch: 5| Step: 2
Training loss: 4.330777123469189
Validation loss: 3.510228611575064

Epoch: 5| Step: 3
Training loss: 3.6211249587803582
Validation loss: 3.509079519875143

Epoch: 5| Step: 4
Training loss: 4.2411001930121826
Validation loss: 3.509343480777566

Epoch: 5| Step: 5
Training loss: 3.5236472598142794
Validation loss: 3.5066528069632326

Epoch: 5| Step: 6
Training loss: 3.3555963600771017
Validation loss: 3.506754753001954

Epoch: 5| Step: 7
Training loss: 4.145926597479093
Validation loss: 3.5050463707677313

Epoch: 5| Step: 8
Training loss: 3.4171201513532092
Validation loss: 3.506765148629356

Epoch: 5| Step: 9
Training loss: 3.357916226921679
Validation loss: 3.5048024795364774

Epoch: 5| Step: 10
Training loss: 3.452854335758293
Validation loss: 3.505788815038777

Epoch: 71| Step: 0
Training loss: 3.691497188033307
Validation loss: 3.504041270881167

Epoch: 5| Step: 1
Training loss: 3.0384249373908667
Validation loss: 3.504409602249716

Epoch: 5| Step: 2
Training loss: 4.1173331942467675
Validation loss: 3.504736031155531

Epoch: 5| Step: 3
Training loss: 3.7569975098070385
Validation loss: 3.503599680179624

Epoch: 5| Step: 4
Training loss: 4.066381155737291
Validation loss: 3.5035430990360603

Epoch: 5| Step: 5
Training loss: 2.9951140034014703
Validation loss: 3.5032285223572854

Epoch: 5| Step: 6
Training loss: 3.1395386292519847
Validation loss: 3.502509027919605

Epoch: 5| Step: 7
Training loss: 3.434162808806201
Validation loss: 3.50235922943908

Epoch: 5| Step: 8
Training loss: 4.473439350454232
Validation loss: 3.5016885103657205

Epoch: 5| Step: 9
Training loss: 3.589246764578347
Validation loss: 3.502198795798407

Epoch: 5| Step: 10
Training loss: 4.328967291334995
Validation loss: 3.501260814550832

Epoch: 72| Step: 0
Training loss: 3.546912911502371
Validation loss: 3.5008456502097283

Epoch: 5| Step: 1
Training loss: 3.8957358499390073
Validation loss: 3.500199718021634

Epoch: 5| Step: 2
Training loss: 3.769860129759355
Validation loss: 3.5018695856816695

Epoch: 5| Step: 3
Training loss: 4.268222562898465
Validation loss: 3.5009540409025

Epoch: 5| Step: 4
Training loss: 2.5722303105669533
Validation loss: 3.500873472794609

Epoch: 5| Step: 5
Training loss: 4.29024612965589
Validation loss: 3.5011175469271394

Epoch: 5| Step: 6
Training loss: 3.769281282191254
Validation loss: 3.499851967864392

Epoch: 5| Step: 7
Training loss: 4.004720286913434
Validation loss: 3.4996836866548193

Epoch: 5| Step: 8
Training loss: 4.106976987913135
Validation loss: 3.4982364638639725

Epoch: 5| Step: 9
Training loss: 3.124617743954835
Validation loss: 3.497512915235138

Epoch: 5| Step: 10
Training loss: 2.9879354438906325
Validation loss: 3.499037295253121

Epoch: 73| Step: 0
Training loss: 3.4806109569538206
Validation loss: 3.4983594597670313

Epoch: 5| Step: 1
Training loss: 3.7419768654430814
Validation loss: 3.49661132149164

Epoch: 5| Step: 2
Training loss: 3.9751574838979087
Validation loss: 3.496313905203288

Epoch: 5| Step: 3
Training loss: 3.0682655091864657
Validation loss: 3.49645330766588

Epoch: 5| Step: 4
Training loss: 3.6266692691915186
Validation loss: 3.497584603816471

Epoch: 5| Step: 5
Training loss: 3.4593232051896896
Validation loss: 3.4960131784122512

Epoch: 5| Step: 6
Training loss: 3.838947304040294
Validation loss: 3.4952737332002455

Epoch: 5| Step: 7
Training loss: 3.8775476264119275
Validation loss: 3.4956844520822514

Epoch: 5| Step: 8
Training loss: 3.8608366017142863
Validation loss: 3.4947138888413387

Epoch: 5| Step: 9
Training loss: 3.975874985654138
Validation loss: 3.493258363250726

Epoch: 5| Step: 10
Training loss: 3.8365698019394627
Validation loss: 3.4955995821935595

Epoch: 74| Step: 0
Training loss: 3.352594390154804
Validation loss: 3.491351054774813

Epoch: 5| Step: 1
Training loss: 4.123501823475771
Validation loss: 3.4919564144361037

Epoch: 5| Step: 2
Training loss: 2.612776589239796
Validation loss: 3.491340457582717

Epoch: 5| Step: 3
Training loss: 3.3411584240900885
Validation loss: 3.491839154544695

Epoch: 5| Step: 4
Training loss: 3.236382492612511
Validation loss: 3.4911257635274335

Epoch: 5| Step: 5
Training loss: 3.1948365694134075
Validation loss: 3.4929280506752587

Epoch: 5| Step: 6
Training loss: 4.172450565253281
Validation loss: 3.4885539687200064

Epoch: 5| Step: 7
Training loss: 3.7652706755142713
Validation loss: 3.4960324525228677

Epoch: 5| Step: 8
Training loss: 4.136283930907074
Validation loss: 3.4867244660736687

Epoch: 5| Step: 9
Training loss: 4.23087044708181
Validation loss: 3.4854694716663435

Epoch: 5| Step: 10
Training loss: 4.269878125562054
Validation loss: 3.484383912904879

Epoch: 75| Step: 0
Training loss: 3.3608776901222432
Validation loss: 3.481650490763847

Epoch: 5| Step: 1
Training loss: 4.280603735936814
Validation loss: 3.483626317002712

Epoch: 5| Step: 2
Training loss: 3.610896198691822
Validation loss: 3.482250114398823

Epoch: 5| Step: 3
Training loss: 3.079564256684274
Validation loss: 3.4844702655150512

Epoch: 5| Step: 4
Training loss: 4.629503892392019
Validation loss: 3.4826227998281962

Epoch: 5| Step: 5
Training loss: 4.098630834710328
Validation loss: 3.495963776835719

Epoch: 5| Step: 6
Training loss: 3.4745956514976313
Validation loss: 3.4762359093349464

Epoch: 5| Step: 7
Training loss: 3.308568672886813
Validation loss: 3.481738020051185

Epoch: 5| Step: 8
Training loss: 3.2684725525141074
Validation loss: 3.4789647245217443

Epoch: 5| Step: 9
Training loss: 3.806438317361703
Validation loss: 3.478409338710429

Epoch: 5| Step: 10
Training loss: 3.3927470655439134
Validation loss: 3.477492139424686

Epoch: 76| Step: 0
Training loss: 4.718692198140393
Validation loss: 3.483470918466336

Epoch: 5| Step: 1
Training loss: 4.130560854683437
Validation loss: 3.4761479317569064

Epoch: 5| Step: 2
Training loss: 3.8503487862474013
Validation loss: 3.477167249241171

Epoch: 5| Step: 3
Training loss: 3.452226616865813
Validation loss: 3.474110474624773

Epoch: 5| Step: 4
Training loss: 3.810189594547616
Validation loss: 3.4757096788869375

Epoch: 5| Step: 5
Training loss: 4.16152825453944
Validation loss: 3.472577947353921

Epoch: 5| Step: 6
Training loss: 2.0018247386424024
Validation loss: 3.4744552864689187

Epoch: 5| Step: 7
Training loss: 3.196204175325959
Validation loss: 3.477850499194896

Epoch: 5| Step: 8
Training loss: 3.3207020968579313
Validation loss: 3.5076791152499402

Epoch: 5| Step: 9
Training loss: 3.3118956392404226
Validation loss: 3.4792610928358245

Epoch: 5| Step: 10
Training loss: 4.047640341480994
Validation loss: 3.472344097883472

Epoch: 77| Step: 0
Training loss: 2.9743400546989123
Validation loss: 3.474005501417953

Epoch: 5| Step: 1
Training loss: 2.8494112443972117
Validation loss: 3.4761390523095184

Epoch: 5| Step: 2
Training loss: 3.741643495778227
Validation loss: 3.476890795679791

Epoch: 5| Step: 3
Training loss: 3.9616960931459952
Validation loss: 3.4818535055094118

Epoch: 5| Step: 4
Training loss: 4.623214376982438
Validation loss: 3.479330572715945

Epoch: 5| Step: 5
Training loss: 2.959879260822553
Validation loss: 3.479545175261845

Epoch: 5| Step: 6
Training loss: 3.5709863606931957
Validation loss: 3.475365074116616

Epoch: 5| Step: 7
Training loss: 4.374014825252462
Validation loss: 3.4796811178417513

Epoch: 5| Step: 8
Training loss: 3.6241283026376827
Validation loss: 3.472164278155351

Epoch: 5| Step: 9
Training loss: 3.457581557100139
Validation loss: 3.46839202893243

Epoch: 5| Step: 10
Training loss: 4.081267684267296
Validation loss: 3.471084170043819

Epoch: 78| Step: 0
Training loss: 3.888547779442579
Validation loss: 3.4671365033406945

Epoch: 5| Step: 1
Training loss: 3.2260922142324833
Validation loss: 3.463596920091136

Epoch: 5| Step: 2
Training loss: 3.267683484647031
Validation loss: 3.4657107608579802

Epoch: 5| Step: 3
Training loss: 3.3710729569625975
Validation loss: 3.4673450406913946

Epoch: 5| Step: 4
Training loss: 3.3507478875535868
Validation loss: 3.465004372819715

Epoch: 5| Step: 5
Training loss: 3.970431955125074
Validation loss: 3.4707515019148705

Epoch: 5| Step: 6
Training loss: 3.811755123226806
Validation loss: 3.47014225692913

Epoch: 5| Step: 7
Training loss: 4.101544596315091
Validation loss: 3.4641619353664512

Epoch: 5| Step: 8
Training loss: 4.17129478277368
Validation loss: 3.46400608252495

Epoch: 5| Step: 9
Training loss: 3.6477320640530335
Validation loss: 3.4621329153580707

Epoch: 5| Step: 10
Training loss: 3.5006184712699677
Validation loss: 3.4587161453588315

Epoch: 79| Step: 0
Training loss: 4.7830521920730416
Validation loss: 3.4588415160691763

Epoch: 5| Step: 1
Training loss: 3.7811006879094577
Validation loss: 3.4585858645840406

Epoch: 5| Step: 2
Training loss: 4.037568101810521
Validation loss: 3.4585503664397415

Epoch: 5| Step: 3
Training loss: 2.8070993068565793
Validation loss: 3.4573759707659995

Epoch: 5| Step: 4
Training loss: 4.166729786712659
Validation loss: 3.459594823150267

Epoch: 5| Step: 5
Training loss: 3.773873819276527
Validation loss: 3.4574067146585743

Epoch: 5| Step: 6
Training loss: 3.160918305395796
Validation loss: 3.456194360825139

Epoch: 5| Step: 7
Training loss: 3.682469314685606
Validation loss: 3.4575885230614944

Epoch: 5| Step: 8
Training loss: 2.2961912629615755
Validation loss: 3.4556456756218084

Epoch: 5| Step: 9
Training loss: 3.933119259412896
Validation loss: 3.456803044176698

Epoch: 5| Step: 10
Training loss: 3.3313668808463297
Validation loss: 3.457741027015955

Epoch: 80| Step: 0
Training loss: 3.5128990625419907
Validation loss: 3.456837470091107

Epoch: 5| Step: 1
Training loss: 4.166371805566181
Validation loss: 3.4567092485067907

Epoch: 5| Step: 2
Training loss: 3.9985526565837723
Validation loss: 3.4560644968168996

Epoch: 5| Step: 3
Training loss: 3.271905581560011
Validation loss: 3.453201164668105

Epoch: 5| Step: 4
Training loss: 3.9766768943056086
Validation loss: 3.4580380273771594

Epoch: 5| Step: 5
Training loss: 3.269037389429985
Validation loss: 3.4550091605990083

Epoch: 5| Step: 6
Training loss: 3.126756403380203
Validation loss: 3.454777898988898

Epoch: 5| Step: 7
Training loss: 2.941563170200046
Validation loss: 3.4564448044660923

Epoch: 5| Step: 8
Training loss: 3.8893929487865844
Validation loss: 3.4632006489425895

Epoch: 5| Step: 9
Training loss: 4.229437282278985
Validation loss: 3.4626302438515317

Epoch: 5| Step: 10
Training loss: 3.794143133517072
Validation loss: 3.451711384339444

Epoch: 81| Step: 0
Training loss: 3.763020988209159
Validation loss: 3.4502178310627247

Epoch: 5| Step: 1
Training loss: 3.667039910017364
Validation loss: 3.4509178364466524

Epoch: 5| Step: 2
Training loss: 3.539805218569603
Validation loss: 3.4534061874022766

Epoch: 5| Step: 3
Training loss: 4.067956634380364
Validation loss: 3.452790182787524

Epoch: 5| Step: 4
Training loss: 3.4332207139689106
Validation loss: 3.4518210193361156

Epoch: 5| Step: 5
Training loss: 4.667208072500797
Validation loss: 3.449030563725941

Epoch: 5| Step: 6
Training loss: 3.466117065830017
Validation loss: 3.452164748406357

Epoch: 5| Step: 7
Training loss: 4.260360431377729
Validation loss: 3.45190293137518

Epoch: 5| Step: 8
Training loss: 2.8235406127408322
Validation loss: 3.451167627484459

Epoch: 5| Step: 9
Training loss: 2.942927763643118
Validation loss: 3.453823028143089

Epoch: 5| Step: 10
Training loss: 3.2909075348532815
Validation loss: 3.4486029994901255

Epoch: 82| Step: 0
Training loss: 3.3852533076071336
Validation loss: 3.449419128040452

Epoch: 5| Step: 1
Training loss: 3.9655539792602443
Validation loss: 3.448315673578151

Epoch: 5| Step: 2
Training loss: 3.974596178187551
Validation loss: 3.448350060813526

Epoch: 5| Step: 3
Training loss: 3.754312324591364
Validation loss: 3.447322816004545

Epoch: 5| Step: 4
Training loss: 3.8572940544487078
Validation loss: 3.448720654554905

Epoch: 5| Step: 5
Training loss: 3.8946634803906077
Validation loss: 3.448223441771838

Epoch: 5| Step: 6
Training loss: 4.140676821978188
Validation loss: 3.448216103743887

Epoch: 5| Step: 7
Training loss: 3.597519730122152
Validation loss: 3.4469811848634464

Epoch: 5| Step: 8
Training loss: 2.203189713630128
Validation loss: 3.447546414326083

Epoch: 5| Step: 9
Training loss: 3.5957930355237755
Validation loss: 3.446868685667842

Epoch: 5| Step: 10
Training loss: 3.614925723757163
Validation loss: 3.4484142190703153

Epoch: 83| Step: 0
Training loss: 3.736577106959968
Validation loss: 3.4473892778633597

Epoch: 5| Step: 1
Training loss: 2.667082833558878
Validation loss: 3.447879006006912

Epoch: 5| Step: 2
Training loss: 3.803946107540787
Validation loss: 3.44704536264872

Epoch: 5| Step: 3
Training loss: 3.926058783139212
Validation loss: 3.446983426480081

Epoch: 5| Step: 4
Training loss: 4.161571108070174
Validation loss: 3.4478224971442337

Epoch: 5| Step: 5
Training loss: 3.568658023858206
Validation loss: 3.4470012656506124

Epoch: 5| Step: 6
Training loss: 2.8801735478669546
Validation loss: 3.4480502958357935

Epoch: 5| Step: 7
Training loss: 4.187721815924305
Validation loss: 3.445769094206711

Epoch: 5| Step: 8
Training loss: 3.8123001296385866
Validation loss: 3.445267160490438

Epoch: 5| Step: 9
Training loss: 3.498244935461067
Validation loss: 3.4449667626098632

Epoch: 5| Step: 10
Training loss: 3.805156952958118
Validation loss: 3.4459317220829737

Epoch: 84| Step: 0
Training loss: 3.046151882339947
Validation loss: 3.4436460915668263

Epoch: 5| Step: 1
Training loss: 3.950207987271075
Validation loss: 3.4452958709194204

Epoch: 5| Step: 2
Training loss: 3.632939162148409
Validation loss: 3.444584793246526

Epoch: 5| Step: 3
Training loss: 3.000723751503446
Validation loss: 3.442783981821821

Epoch: 5| Step: 4
Training loss: 4.245096856439985
Validation loss: 3.4422129267972545

Epoch: 5| Step: 5
Training loss: 4.086318164255736
Validation loss: 3.4431433584409628

Epoch: 5| Step: 6
Training loss: 3.4734956737319496
Validation loss: 3.443758341687559

Epoch: 5| Step: 7
Training loss: 3.5977100612662665
Validation loss: 3.4415642183177972

Epoch: 5| Step: 8
Training loss: 2.9825986998375194
Validation loss: 3.4438422782431655

Epoch: 5| Step: 9
Training loss: 4.254434628069469
Validation loss: 3.4422267883405264

Epoch: 5| Step: 10
Training loss: 3.742130541915503
Validation loss: 3.4417475481239537

Epoch: 85| Step: 0
Training loss: 4.056872651871263
Validation loss: 3.440832230447082

Epoch: 5| Step: 1
Training loss: 3.05652019031907
Validation loss: 3.4388525620312524

Epoch: 5| Step: 2
Training loss: 4.358362223795047
Validation loss: 3.4423060688606695

Epoch: 5| Step: 3
Training loss: 3.7707684477954424
Validation loss: 3.4408727512656796

Epoch: 5| Step: 4
Training loss: 3.002286516488292
Validation loss: 3.4416388883400533

Epoch: 5| Step: 5
Training loss: 4.59424697367555
Validation loss: 3.4395692103257782

Epoch: 5| Step: 6
Training loss: 4.055411625112385
Validation loss: 3.4404972705683208

Epoch: 5| Step: 7
Training loss: 2.3589669184158084
Validation loss: 3.441372581534109

Epoch: 5| Step: 8
Training loss: 3.0445232999138407
Validation loss: 3.4394153334043946

Epoch: 5| Step: 9
Training loss: 3.58159605687691
Validation loss: 3.440067189555615

Epoch: 5| Step: 10
Training loss: 3.793351410441129
Validation loss: 3.4406311228234023

Epoch: 86| Step: 0
Training loss: 4.407274275964578
Validation loss: 3.4408684493134274

Epoch: 5| Step: 1
Training loss: 4.198962337738351
Validation loss: 3.439800813240054

Epoch: 5| Step: 2
Training loss: 3.5263034980661594
Validation loss: 3.440618756994307

Epoch: 5| Step: 3
Training loss: 4.137810668345664
Validation loss: 3.43819506228589

Epoch: 5| Step: 4
Training loss: 3.772630309021461
Validation loss: 3.4388341512859615

Epoch: 5| Step: 5
Training loss: 3.3859710395957974
Validation loss: 3.43805584035315

Epoch: 5| Step: 6
Training loss: 3.401516346230651
Validation loss: 3.437932460277151

Epoch: 5| Step: 7
Training loss: 3.7751583495623096
Validation loss: 3.4376150937916234

Epoch: 5| Step: 8
Training loss: 3.704494046196547
Validation loss: 3.438217223995746

Epoch: 5| Step: 9
Training loss: 2.764312432667992
Validation loss: 3.4355262825174706

Epoch: 5| Step: 10
Training loss: 2.6278119239801963
Validation loss: 3.4365572907360202

Epoch: 87| Step: 0
Training loss: 3.5088513031983193
Validation loss: 3.43718010541001

Epoch: 5| Step: 1
Training loss: 3.4470999097031676
Validation loss: 3.4357771806278232

Epoch: 5| Step: 2
Training loss: 3.1697956654731
Validation loss: 3.4364023419387

Epoch: 5| Step: 3
Training loss: 3.6339302558399607
Validation loss: 3.4374486507335535

Epoch: 5| Step: 4
Training loss: 3.748760399977303
Validation loss: 3.436310064918673

Epoch: 5| Step: 5
Training loss: 3.303884710826648
Validation loss: 3.4339326815858078

Epoch: 5| Step: 6
Training loss: 3.2269934119413524
Validation loss: 3.435295992904844

Epoch: 5| Step: 7
Training loss: 4.321730313806431
Validation loss: 3.4345938232361366

Epoch: 5| Step: 8
Training loss: 4.124789608300542
Validation loss: 3.4338632492063996

Epoch: 5| Step: 9
Training loss: 3.991112730471484
Validation loss: 3.434608151434906

Epoch: 5| Step: 10
Training loss: 3.551582472644773
Validation loss: 3.433160265287909

Epoch: 88| Step: 0
Training loss: 3.6456978618339004
Validation loss: 3.433973545112243

Epoch: 5| Step: 1
Training loss: 4.077342692790029
Validation loss: 3.4337367664136815

Epoch: 5| Step: 2
Training loss: 3.664860685232535
Validation loss: 3.4324775249737636

Epoch: 5| Step: 3
Training loss: 3.2672842090802683
Validation loss: 3.4326133083732997

Epoch: 5| Step: 4
Training loss: 3.2357581677885254
Validation loss: 3.4335032088820037

Epoch: 5| Step: 5
Training loss: 4.004196111840078
Validation loss: 3.4322883632954673

Epoch: 5| Step: 6
Training loss: 3.9356406529614927
Validation loss: 3.435054287128393

Epoch: 5| Step: 7
Training loss: 3.8373294953978085
Validation loss: 3.431984758754419

Epoch: 5| Step: 8
Training loss: 2.8709319815183507
Validation loss: 3.432608056533631

Epoch: 5| Step: 9
Training loss: 3.7971016773015327
Validation loss: 3.434513424182756

Epoch: 5| Step: 10
Training loss: 3.68069165695911
Validation loss: 3.4306104295919266

Epoch: 89| Step: 0
Training loss: 3.5048150592503937
Validation loss: 3.430630128691592

Epoch: 5| Step: 1
Training loss: 4.327873360379937
Validation loss: 3.433021984703935

Epoch: 5| Step: 2
Training loss: 2.9390960577874714
Validation loss: 3.4344939794989378

Epoch: 5| Step: 3
Training loss: 4.218153169588484
Validation loss: 3.430788862196867

Epoch: 5| Step: 4
Training loss: 4.271815018138582
Validation loss: 3.432025735110975

Epoch: 5| Step: 5
Training loss: 3.2722579542482015
Validation loss: 3.4314792323898526

Epoch: 5| Step: 6
Training loss: 3.1735270289869812
Validation loss: 3.4293632539988494

Epoch: 5| Step: 7
Training loss: 3.6938962904204993
Validation loss: 3.4302059718571756

Epoch: 5| Step: 8
Training loss: 3.374534574841656
Validation loss: 3.4288878278384827

Epoch: 5| Step: 9
Training loss: 3.8360859207061617
Validation loss: 3.4303993429884008

Epoch: 5| Step: 10
Training loss: 3.169879906001052
Validation loss: 3.428752851703607

Epoch: 90| Step: 0
Training loss: 3.9927586335436436
Validation loss: 3.427635109303759

Epoch: 5| Step: 1
Training loss: 3.91294799287367
Validation loss: 3.4287838761687324

Epoch: 5| Step: 2
Training loss: 3.9468499237979504
Validation loss: 3.4276885935591466

Epoch: 5| Step: 3
Training loss: 3.6146876222075037
Validation loss: 3.4278285686231507

Epoch: 5| Step: 4
Training loss: 3.929188751665644
Validation loss: 3.4295394962325707

Epoch: 5| Step: 5
Training loss: 3.6398767840312516
Validation loss: 3.428356380171515

Epoch: 5| Step: 6
Training loss: 3.68631945317275
Validation loss: 3.4267699635126063

Epoch: 5| Step: 7
Training loss: 3.112539856437208
Validation loss: 3.4270689342764933

Epoch: 5| Step: 8
Training loss: 2.6320734543217656
Validation loss: 3.427641827229351

Epoch: 5| Step: 9
Training loss: 3.258488353999353
Validation loss: 3.4276147430338173

Epoch: 5| Step: 10
Training loss: 4.233470411909788
Validation loss: 3.427266265857135

Epoch: 91| Step: 0
Training loss: 3.5126954482468005
Validation loss: 3.4267357756810877

Epoch: 5| Step: 1
Training loss: 4.058018251651575
Validation loss: 3.4260829783729014

Epoch: 5| Step: 2
Training loss: 3.7577828071039723
Validation loss: 3.4263654302845397

Epoch: 5| Step: 3
Training loss: 3.1590391620117697
Validation loss: 3.42507588873049

Epoch: 5| Step: 4
Training loss: 3.500208439750996
Validation loss: 3.4248896784118528

Epoch: 5| Step: 5
Training loss: 3.542163021236961
Validation loss: 3.4242679479184637

Epoch: 5| Step: 6
Training loss: 3.1659397160856795
Validation loss: 3.423997519771474

Epoch: 5| Step: 7
Training loss: 3.848058751155412
Validation loss: 3.424226729740797

Epoch: 5| Step: 8
Training loss: 3.5290015159856623
Validation loss: 3.422184934096874

Epoch: 5| Step: 9
Training loss: 3.4320114708288605
Validation loss: 3.4208241720922383

Epoch: 5| Step: 10
Training loss: 4.539751798256212
Validation loss: 3.4212246097546006

Epoch: 92| Step: 0
Training loss: 4.046696368071285
Validation loss: 3.4235104634369065

Epoch: 5| Step: 1
Training loss: 3.516065781829646
Validation loss: 3.4215026104431714

Epoch: 5| Step: 2
Training loss: 4.1180796516203815
Validation loss: 3.4196255465100944

Epoch: 5| Step: 3
Training loss: 2.673521817079971
Validation loss: 3.4182632901605254

Epoch: 5| Step: 4
Training loss: 2.832847572273668
Validation loss: 3.417860345343125

Epoch: 5| Step: 5
Training loss: 4.273142691142235
Validation loss: 3.4148746541115393

Epoch: 5| Step: 6
Training loss: 3.43520569964195
Validation loss: 3.4131504687023937

Epoch: 5| Step: 7
Training loss: 3.50777579715278
Validation loss: 3.4148976608319077

Epoch: 5| Step: 8
Training loss: 3.027563153591815
Validation loss: 3.4107689747216363

Epoch: 5| Step: 9
Training loss: 4.2097956820311655
Validation loss: 3.40892723941044

Epoch: 5| Step: 10
Training loss: 3.990858719089773
Validation loss: 3.408683928593052

Epoch: 93| Step: 0
Training loss: 4.303719247247764
Validation loss: 3.4091533830796963

Epoch: 5| Step: 1
Training loss: 3.7076710027355944
Validation loss: 3.4087816027609916

Epoch: 5| Step: 2
Training loss: 3.9182036339893345
Validation loss: 3.408389380470291

Epoch: 5| Step: 3
Training loss: 3.0065354051153155
Validation loss: 3.4072023256949775

Epoch: 5| Step: 4
Training loss: 2.903635140757125
Validation loss: 3.406688231867981

Epoch: 5| Step: 5
Training loss: 3.9914207244688247
Validation loss: 3.406316391718485

Epoch: 5| Step: 6
Training loss: 4.050696494412257
Validation loss: 3.405498662992631

Epoch: 5| Step: 7
Training loss: 3.784833738840329
Validation loss: 3.407385048536055

Epoch: 5| Step: 8
Training loss: 2.945825830546262
Validation loss: 3.407131414067435

Epoch: 5| Step: 9
Training loss: 3.614847369632265
Validation loss: 3.4057658478827295

Epoch: 5| Step: 10
Training loss: 3.3520137598670283
Validation loss: 3.4078398124707423

Epoch: 94| Step: 0
Training loss: 2.8151049947722724
Validation loss: 3.4045744823523023

Epoch: 5| Step: 1
Training loss: 2.7224725253537736
Validation loss: 3.404092806124785

Epoch: 5| Step: 2
Training loss: 3.4048635478413734
Validation loss: 3.4046651467234135

Epoch: 5| Step: 3
Training loss: 4.431297588227368
Validation loss: 3.403640048217351

Epoch: 5| Step: 4
Training loss: 4.005513682670495
Validation loss: 3.4026951547458095

Epoch: 5| Step: 5
Training loss: 3.7821739896375237
Validation loss: 3.405751520286331

Epoch: 5| Step: 6
Training loss: 3.8496441812940065
Validation loss: 3.4027916070387683

Epoch: 5| Step: 7
Training loss: 3.240342095293528
Validation loss: 3.4021170165397923

Epoch: 5| Step: 8
Training loss: 4.060219931823323
Validation loss: 3.4025045460294363

Epoch: 5| Step: 9
Training loss: 3.4236756207568133
Validation loss: 3.401558061931718

Epoch: 5| Step: 10
Training loss: 3.807524389137508
Validation loss: 3.4015982562403533

Epoch: 95| Step: 0
Training loss: 3.657534772977497
Validation loss: 3.4006569763886705

Epoch: 5| Step: 1
Training loss: 3.7132778136407807
Validation loss: 3.3996692379560502

Epoch: 5| Step: 2
Training loss: 4.255917636705382
Validation loss: 3.399482426285586

Epoch: 5| Step: 3
Training loss: 3.7593101641739306
Validation loss: 3.4003307447070825

Epoch: 5| Step: 4
Training loss: 3.861144243337574
Validation loss: 3.4021518827844868

Epoch: 5| Step: 5
Training loss: 4.000276317589252
Validation loss: 3.400517699756207

Epoch: 5| Step: 6
Training loss: 3.558212243073796
Validation loss: 3.3990024389872895

Epoch: 5| Step: 7
Training loss: 3.015796241444317
Validation loss: 3.3982283038800603

Epoch: 5| Step: 8
Training loss: 3.3969208237856896
Validation loss: 3.398756898536749

Epoch: 5| Step: 9
Training loss: 2.426323134485985
Validation loss: 3.400263450496608

Epoch: 5| Step: 10
Training loss: 3.912887061720013
Validation loss: 3.402124363573738

Epoch: 96| Step: 0
Training loss: 4.180326780112458
Validation loss: 3.407378972328072

Epoch: 5| Step: 1
Training loss: 3.5706290140234582
Validation loss: 3.405117158497903

Epoch: 5| Step: 2
Training loss: 3.6795944558466047
Validation loss: 3.401690095724932

Epoch: 5| Step: 3
Training loss: 3.9349864626970303
Validation loss: 3.398502298788016

Epoch: 5| Step: 4
Training loss: 3.5064118101484647
Validation loss: 3.3951630168884392

Epoch: 5| Step: 5
Training loss: 3.9748740218250793
Validation loss: 3.3953432088904716

Epoch: 5| Step: 6
Training loss: 3.713206928391441
Validation loss: 3.395286382135626

Epoch: 5| Step: 7
Training loss: 3.8452125806044926
Validation loss: 3.39242472980659

Epoch: 5| Step: 8
Training loss: 3.0668685273062715
Validation loss: 3.393782787670355

Epoch: 5| Step: 9
Training loss: 2.8357234485226983
Validation loss: 3.395858695602803

Epoch: 5| Step: 10
Training loss: 3.22706758919297
Validation loss: 3.3956422694786457

Epoch: 97| Step: 0
Training loss: 3.7969541188226565
Validation loss: 3.3928338463231955

Epoch: 5| Step: 1
Training loss: 4.050560410897977
Validation loss: 3.39017069149796

Epoch: 5| Step: 2
Training loss: 3.672341045266164
Validation loss: 3.388783006298893

Epoch: 5| Step: 3
Training loss: 2.764116986019648
Validation loss: 3.3884382179130426

Epoch: 5| Step: 4
Training loss: 3.4795548152078495
Validation loss: 3.3887493143018825

Epoch: 5| Step: 5
Training loss: 4.2066497204696685
Validation loss: 3.390218877610841

Epoch: 5| Step: 6
Training loss: 3.1543404118512464
Validation loss: 3.3913444057148148

Epoch: 5| Step: 7
Training loss: 3.4358032200323505
Validation loss: 3.3908628733117356

Epoch: 5| Step: 8
Training loss: 3.5662978156862413
Validation loss: 3.3927915004696736

Epoch: 5| Step: 9
Training loss: 3.934051093114433
Validation loss: 3.391538371932824

Epoch: 5| Step: 10
Training loss: 3.4657936213398823
Validation loss: 3.3906208006358987

Epoch: 98| Step: 0
Training loss: 3.595293459951689
Validation loss: 3.3900312986365

Epoch: 5| Step: 1
Training loss: 3.7617499329412367
Validation loss: 3.3900343553135226

Epoch: 5| Step: 2
Training loss: 4.2172356042029975
Validation loss: 3.3878391995267285

Epoch: 5| Step: 3
Training loss: 2.8724728963318578
Validation loss: 3.386705978397292

Epoch: 5| Step: 4
Training loss: 4.308298026456112
Validation loss: 3.385255685517451

Epoch: 5| Step: 5
Training loss: 2.7371245592713365
Validation loss: 3.3854150956042157

Epoch: 5| Step: 6
Training loss: 3.658703754994258
Validation loss: 3.385902808838793

Epoch: 5| Step: 7
Training loss: 3.1513119584271836
Validation loss: 3.3846010019065043

Epoch: 5| Step: 8
Training loss: 3.634921079300977
Validation loss: 3.387545197087772

Epoch: 5| Step: 9
Training loss: 4.103808443859982
Validation loss: 3.3898375577681272

Epoch: 5| Step: 10
Training loss: 3.2617320534440526
Validation loss: 3.3901512208533697

Epoch: 99| Step: 0
Training loss: 3.1128788667682468
Validation loss: 3.384842614409544

Epoch: 5| Step: 1
Training loss: 4.282781173997871
Validation loss: 3.384070812742233

Epoch: 5| Step: 2
Training loss: 3.5923861361983755
Validation loss: 3.384185090429921

Epoch: 5| Step: 3
Training loss: 3.86172994202619
Validation loss: 3.3826073760055926

Epoch: 5| Step: 4
Training loss: 3.791613414236744
Validation loss: 3.3832607010733997

Epoch: 5| Step: 5
Training loss: 3.4520835168930923
Validation loss: 3.3843514381260933

Epoch: 5| Step: 6
Training loss: 3.663920515680853
Validation loss: 3.385090065371666

Epoch: 5| Step: 7
Training loss: 3.6976238869113796
Validation loss: 3.3844492994382587

Epoch: 5| Step: 8
Training loss: 3.003469050901254
Validation loss: 3.3833358016207913

Epoch: 5| Step: 9
Training loss: 3.741724037347955
Validation loss: 3.383618048749105

Epoch: 5| Step: 10
Training loss: 3.27756824111021
Validation loss: 3.3832780275704826

Epoch: 100| Step: 0
Training loss: 3.892236582639135
Validation loss: 3.3827387246991276

Epoch: 5| Step: 1
Training loss: 3.2175512952057614
Validation loss: 3.383751217442054

Epoch: 5| Step: 2
Training loss: 3.0511904160035495
Validation loss: 3.3807792700292048

Epoch: 5| Step: 3
Training loss: 3.2165251514620237
Validation loss: 3.3841189357156667

Epoch: 5| Step: 4
Training loss: 3.2910202614952504
Validation loss: 3.381036522944561

Epoch: 5| Step: 5
Training loss: 4.029398884963551
Validation loss: 3.3812049817082537

Epoch: 5| Step: 6
Training loss: 3.6014335427190756
Validation loss: 3.381958948983189

Epoch: 5| Step: 7
Training loss: 3.328714237973632
Validation loss: 3.3819393537416693

Epoch: 5| Step: 8
Training loss: 4.093259126775468
Validation loss: 3.3799288819504394

Epoch: 5| Step: 9
Training loss: 3.890552075786512
Validation loss: 3.3822576179570407

Epoch: 5| Step: 10
Training loss: 3.9107955730074897
Validation loss: 3.3798769280529743

Epoch: 101| Step: 0
Training loss: 3.321655289138727
Validation loss: 3.381367954329312

Epoch: 5| Step: 1
Training loss: 3.249098139122819
Validation loss: 3.379832333957459

Epoch: 5| Step: 2
Training loss: 3.882862359384982
Validation loss: 3.3789762744930143

Epoch: 5| Step: 3
Training loss: 2.489897629651918
Validation loss: 3.3793746127622066

Epoch: 5| Step: 4
Training loss: 4.1089723338989605
Validation loss: 3.3794574857655606

Epoch: 5| Step: 5
Training loss: 3.5380786597703233
Validation loss: 3.37940012030052

Epoch: 5| Step: 6
Training loss: 3.101988948071859
Validation loss: 3.3799556170833056

Epoch: 5| Step: 7
Training loss: 4.230851512722359
Validation loss: 3.3799172603540333

Epoch: 5| Step: 8
Training loss: 3.7486407041628103
Validation loss: 3.3785412226737868

Epoch: 5| Step: 9
Training loss: 3.551562602038535
Validation loss: 3.3788081704787154

Epoch: 5| Step: 10
Training loss: 4.172597301118895
Validation loss: 3.3783276832388793

Epoch: 102| Step: 0
Training loss: 3.6915126886109686
Validation loss: 3.3776676067877958

Epoch: 5| Step: 1
Training loss: 3.0862460597813834
Validation loss: 3.377618294372444

Epoch: 5| Step: 2
Training loss: 3.2653726726678918
Validation loss: 3.3758567776871384

Epoch: 5| Step: 3
Training loss: 3.5716456755998696
Validation loss: 3.3757381733365888

Epoch: 5| Step: 4
Training loss: 3.916412561709456
Validation loss: 3.3772140420446846

Epoch: 5| Step: 5
Training loss: 3.4296199296625387
Validation loss: 3.3779986075131276

Epoch: 5| Step: 6
Training loss: 3.548283368773174
Validation loss: 3.3773957078267713

Epoch: 5| Step: 7
Training loss: 3.391462231472567
Validation loss: 3.374914778192131

Epoch: 5| Step: 8
Training loss: 4.16644367892901
Validation loss: 3.3766218836086814

Epoch: 5| Step: 9
Training loss: 3.608110346669386
Validation loss: 3.3789585298923575

Epoch: 5| Step: 10
Training loss: 3.881227350092111
Validation loss: 3.378484076883235

Epoch: 103| Step: 0
Training loss: 3.158181685243399
Validation loss: 3.3775645394522433

Epoch: 5| Step: 1
Training loss: 3.707732605585781
Validation loss: 3.379325032426885

Epoch: 5| Step: 2
Training loss: 4.175549207187077
Validation loss: 3.377474992065821

Epoch: 5| Step: 3
Training loss: 3.6688443277375336
Validation loss: 3.3770844780181357

Epoch: 5| Step: 4
Training loss: 3.0535315158055236
Validation loss: 3.3744831122363705

Epoch: 5| Step: 5
Training loss: 3.593232225353294
Validation loss: 3.373753801836153

Epoch: 5| Step: 6
Training loss: 3.1301856693371923
Validation loss: 3.37332745533271

Epoch: 5| Step: 7
Training loss: 4.4247948809135975
Validation loss: 3.372084737588705

Epoch: 5| Step: 8
Training loss: 3.3030164745912027
Validation loss: 3.3730797084412596

Epoch: 5| Step: 9
Training loss: 3.6831730170480372
Validation loss: 3.374270552877238

Epoch: 5| Step: 10
Training loss: 3.442081242331243
Validation loss: 3.372325415506995

Epoch: 104| Step: 0
Training loss: 2.8880131649446397
Validation loss: 3.371898436781113

Epoch: 5| Step: 1
Training loss: 3.8054311288012825
Validation loss: 3.371448084951726

Epoch: 5| Step: 2
Training loss: 3.7136907703628768
Validation loss: 3.372302894516857

Epoch: 5| Step: 3
Training loss: 3.7120056542485025
Validation loss: 3.3724362074661554

Epoch: 5| Step: 4
Training loss: 3.2082734205588608
Validation loss: 3.3739704778339017

Epoch: 5| Step: 5
Training loss: 3.9763008436293967
Validation loss: 3.3745201830164477

Epoch: 5| Step: 6
Training loss: 3.8189829753727005
Validation loss: 3.3716473077683187

Epoch: 5| Step: 7
Training loss: 3.6149077842421122
Validation loss: 3.3720829981272904

Epoch: 5| Step: 8
Training loss: 3.490769749221171
Validation loss: 3.3732806314992216

Epoch: 5| Step: 9
Training loss: 4.060362737828252
Validation loss: 3.3752915489274726

Epoch: 5| Step: 10
Training loss: 3.026417606570169
Validation loss: 3.37312744708666

Epoch: 105| Step: 0
Training loss: 4.131969690468363
Validation loss: 3.37163167184218

Epoch: 5| Step: 1
Training loss: 3.4352780183227365
Validation loss: 3.370965436767914

Epoch: 5| Step: 2
Training loss: 3.3173072049449956
Validation loss: 3.3693492425453

Epoch: 5| Step: 3
Training loss: 3.376982777577302
Validation loss: 3.3681639483291654

Epoch: 5| Step: 4
Training loss: 3.308973198291905
Validation loss: 3.3681921141567543

Epoch: 5| Step: 5
Training loss: 3.748596310163289
Validation loss: 3.367805042316194

Epoch: 5| Step: 6
Training loss: 3.743943728113742
Validation loss: 3.368594955239149

Epoch: 5| Step: 7
Training loss: 3.6018234456291562
Validation loss: 3.3689160735808548

Epoch: 5| Step: 8
Training loss: 3.4129159080055267
Validation loss: 3.368025594790254

Epoch: 5| Step: 9
Training loss: 3.8577457340314045
Validation loss: 3.367607622490013

Epoch: 5| Step: 10
Training loss: 3.5268920744435817
Validation loss: 3.368278660665384

Epoch: 106| Step: 0
Training loss: 2.600344260972714
Validation loss: 3.3684328236175882

Epoch: 5| Step: 1
Training loss: 2.598751531309674
Validation loss: 3.3673990173349053

Epoch: 5| Step: 2
Training loss: 3.648684899643597
Validation loss: 3.3663165761978315

Epoch: 5| Step: 3
Training loss: 3.6719926531184215
Validation loss: 3.3693919210595906

Epoch: 5| Step: 4
Training loss: 3.2617637768224443
Validation loss: 3.3662400145182096

Epoch: 5| Step: 5
Training loss: 3.999375890680146
Validation loss: 3.3670806673671225

Epoch: 5| Step: 6
Training loss: 3.553692286422271
Validation loss: 3.36656939283662

Epoch: 5| Step: 7
Training loss: 3.943281258900003
Validation loss: 3.366135116737059

Epoch: 5| Step: 8
Training loss: 3.889259313168244
Validation loss: 3.3669203343970744

Epoch: 5| Step: 9
Training loss: 4.0882872030519914
Validation loss: 3.3690193354891744

Epoch: 5| Step: 10
Training loss: 3.9344234254506545
Validation loss: 3.3678464242661237

Epoch: 107| Step: 0
Training loss: 3.5392864232243366
Validation loss: 3.3667547275556493

Epoch: 5| Step: 1
Training loss: 4.059989975414209
Validation loss: 3.370655402095232

Epoch: 5| Step: 2
Training loss: 3.885984909326738
Validation loss: 3.367952759150874

Epoch: 5| Step: 3
Training loss: 3.65401449085989
Validation loss: 3.369706405446309

Epoch: 5| Step: 4
Training loss: 2.9057854722106127
Validation loss: 3.3663209475299274

Epoch: 5| Step: 5
Training loss: 3.345778375905049
Validation loss: 3.363444626915055

Epoch: 5| Step: 6
Training loss: 3.82301132265131
Validation loss: 3.3640554833075487

Epoch: 5| Step: 7
Training loss: 3.5410051214164406
Validation loss: 3.3645049151765214

Epoch: 5| Step: 8
Training loss: 4.304563434010687
Validation loss: 3.3636440821573674

Epoch: 5| Step: 9
Training loss: 2.88508545297776
Validation loss: 3.3628647234661626

Epoch: 5| Step: 10
Training loss: 3.2721396265434186
Validation loss: 3.363480593741009

Epoch: 108| Step: 0
Training loss: 4.690836418414235
Validation loss: 3.3634035056024993

Epoch: 5| Step: 1
Training loss: 3.440441745517118
Validation loss: 3.3650668415356586

Epoch: 5| Step: 2
Training loss: 3.834893171869125
Validation loss: 3.363526089075486

Epoch: 5| Step: 3
Training loss: 3.7854699161348404
Validation loss: 3.3637365265262322

Epoch: 5| Step: 4
Training loss: 3.0656560089378453
Validation loss: 3.3611751341704683

Epoch: 5| Step: 5
Training loss: 3.9653289948982495
Validation loss: 3.3621743628811207

Epoch: 5| Step: 6
Training loss: 2.9995514216427597
Validation loss: 3.362354797870707

Epoch: 5| Step: 7
Training loss: 3.750593392789289
Validation loss: 3.360624393428439

Epoch: 5| Step: 8
Training loss: 2.9864549029866905
Validation loss: 3.361181219157314

Epoch: 5| Step: 9
Training loss: 3.0352981121830154
Validation loss: 3.362303940283928

Epoch: 5| Step: 10
Training loss: 3.559603936098055
Validation loss: 3.3621087953096604

Epoch: 109| Step: 0
Training loss: 3.404994488234127
Validation loss: 3.3640798678862684

Epoch: 5| Step: 1
Training loss: 3.3474635243440614
Validation loss: 3.360653166350441

Epoch: 5| Step: 2
Training loss: 3.3358045636385825
Validation loss: 3.363112914892213

Epoch: 5| Step: 3
Training loss: 3.3414716712838786
Validation loss: 3.359794848782822

Epoch: 5| Step: 4
Training loss: 3.9283333297511542
Validation loss: 3.3669800687926235

Epoch: 5| Step: 5
Training loss: 3.766149967053997
Validation loss: 3.363720471993294

Epoch: 5| Step: 6
Training loss: 3.811347537095371
Validation loss: 3.3644827190139566

Epoch: 5| Step: 7
Training loss: 3.7664302740495996
Validation loss: 3.361457991276446

Epoch: 5| Step: 8
Training loss: 3.7722164729553165
Validation loss: 3.359051114204044

Epoch: 5| Step: 9
Training loss: 3.633599571366077
Validation loss: 3.3590937060494936

Epoch: 5| Step: 10
Training loss: 3.244489546539261
Validation loss: 3.3592677861223326

Epoch: 110| Step: 0
Training loss: 3.332201829235696
Validation loss: 3.3581460470048143

Epoch: 5| Step: 1
Training loss: 3.5561258948045844
Validation loss: 3.3585991366279333

Epoch: 5| Step: 2
Training loss: 3.2510144044433193
Validation loss: 3.359437617304779

Epoch: 5| Step: 3
Training loss: 4.7539229004818315
Validation loss: 3.3581268120836585

Epoch: 5| Step: 4
Training loss: 3.772453985521358
Validation loss: 3.358763796128392

Epoch: 5| Step: 5
Training loss: 3.0174286345455124
Validation loss: 3.3579815984620938

Epoch: 5| Step: 6
Training loss: 3.1396279341768314
Validation loss: 3.356764707766003

Epoch: 5| Step: 7
Training loss: 4.137068693148105
Validation loss: 3.355358912884141

Epoch: 5| Step: 8
Training loss: 3.678159359987794
Validation loss: 3.3573011609158545

Epoch: 5| Step: 9
Training loss: 2.4055362980605013
Validation loss: 3.3564816827569293

Epoch: 5| Step: 10
Training loss: 3.9217170592341293
Validation loss: 3.355587114262533

Epoch: 111| Step: 0
Training loss: 3.2045534995867784
Validation loss: 3.356193395376261

Epoch: 5| Step: 1
Training loss: 4.1948889832930405
Validation loss: 3.356460200385185

Epoch: 5| Step: 2
Training loss: 3.6723303979152853
Validation loss: 3.3565994002913064

Epoch: 5| Step: 3
Training loss: 3.5064770847704834
Validation loss: 3.3576718186480723

Epoch: 5| Step: 4
Training loss: 2.5089646779474575
Validation loss: 3.3617033307172903

Epoch: 5| Step: 5
Training loss: 3.302185554406351
Validation loss: 3.360593156243817

Epoch: 5| Step: 6
Training loss: 4.053781397130666
Validation loss: 3.356371473968308

Epoch: 5| Step: 7
Training loss: 3.850161407852418
Validation loss: 3.356779902777593

Epoch: 5| Step: 8
Training loss: 3.83111007459803
Validation loss: 3.3549070362164657

Epoch: 5| Step: 9
Training loss: 3.6196979025719522
Validation loss: 3.35634811342593

Epoch: 5| Step: 10
Training loss: 3.361807009393639
Validation loss: 3.3548563117850487

Epoch: 112| Step: 0
Training loss: 3.5550043321199487
Validation loss: 3.3541826403071964

Epoch: 5| Step: 1
Training loss: 3.108596781048252
Validation loss: 3.3542407274843513

Epoch: 5| Step: 2
Training loss: 3.4177174851840393
Validation loss: 3.352531270337717

Epoch: 5| Step: 3
Training loss: 3.7656762843775016
Validation loss: 3.352896910464883

Epoch: 5| Step: 4
Training loss: 3.457946725094079
Validation loss: 3.3545426316155393

Epoch: 5| Step: 5
Training loss: 4.309757632280384
Validation loss: 3.352504865554999

Epoch: 5| Step: 6
Training loss: 3.2616940434599457
Validation loss: 3.3534383536577543

Epoch: 5| Step: 7
Training loss: 2.906599454481808
Validation loss: 3.352206887733532

Epoch: 5| Step: 8
Training loss: 3.4616214946015123
Validation loss: 3.3538396761669835

Epoch: 5| Step: 9
Training loss: 4.2104858835688335
Validation loss: 3.352321759144442

Epoch: 5| Step: 10
Training loss: 3.7210131258242227
Validation loss: 3.3525619051308366

Epoch: 113| Step: 0
Training loss: 3.047276553567283
Validation loss: 3.351672611444754

Epoch: 5| Step: 1
Training loss: 2.898012855043194
Validation loss: 3.3508836356192284

Epoch: 5| Step: 2
Training loss: 3.7908287100527187
Validation loss: 3.351175202618356

Epoch: 5| Step: 3
Training loss: 3.307439285147796
Validation loss: 3.35199009515255

Epoch: 5| Step: 4
Training loss: 3.43577310360536
Validation loss: 3.35154656996535

Epoch: 5| Step: 5
Training loss: 3.356892648898023
Validation loss: 3.3514235253748237

Epoch: 5| Step: 6
Training loss: 4.0469817512012165
Validation loss: 3.351135913646694

Epoch: 5| Step: 7
Training loss: 3.8413018594723765
Validation loss: 3.350784927130614

Epoch: 5| Step: 8
Training loss: 3.8203448272772706
Validation loss: 3.3508441733826984

Epoch: 5| Step: 9
Training loss: 3.51270888715406
Validation loss: 3.3489719113034937

Epoch: 5| Step: 10
Training loss: 4.194437230477996
Validation loss: 3.349375076300833

Epoch: 114| Step: 0
Training loss: 3.131810510839643
Validation loss: 3.349156982846165

Epoch: 5| Step: 1
Training loss: 3.6030363100092564
Validation loss: 3.3487743373772654

Epoch: 5| Step: 2
Training loss: 3.789894374492779
Validation loss: 3.3479504213053812

Epoch: 5| Step: 3
Training loss: 3.4699579833287455
Validation loss: 3.3484720923204665

Epoch: 5| Step: 4
Training loss: 4.015231695841357
Validation loss: 3.34932222288613

Epoch: 5| Step: 5
Training loss: 3.918473672326424
Validation loss: 3.349962783567569

Epoch: 5| Step: 6
Training loss: 3.3854610655391886
Validation loss: 3.3475714731537547

Epoch: 5| Step: 7
Training loss: 2.862674331353914
Validation loss: 3.348288139063941

Epoch: 5| Step: 8
Training loss: 3.668659636702247
Validation loss: 3.346796156525406

Epoch: 5| Step: 9
Training loss: 3.4356336208580243
Validation loss: 3.349261388225474

Epoch: 5| Step: 10
Training loss: 3.9524687572887593
Validation loss: 3.3497636333615763

Epoch: 115| Step: 0
Training loss: 2.72962809925486
Validation loss: 3.349663857125435

Epoch: 5| Step: 1
Training loss: 3.320084292479256
Validation loss: 3.350435431118198

Epoch: 5| Step: 2
Training loss: 4.372427701881269
Validation loss: 3.3517401056559883

Epoch: 5| Step: 3
Training loss: 3.91040952854931
Validation loss: 3.3485775449460187

Epoch: 5| Step: 4
Training loss: 3.472046531470916
Validation loss: 3.3483624054491163

Epoch: 5| Step: 5
Training loss: 3.834712872157399
Validation loss: 3.3466143127475667

Epoch: 5| Step: 6
Training loss: 3.329501158549538
Validation loss: 3.3457405200258186

Epoch: 5| Step: 7
Training loss: 3.29753431624805
Validation loss: 3.3449714751937014

Epoch: 5| Step: 8
Training loss: 3.829808079266013
Validation loss: 3.344650578927316

Epoch: 5| Step: 9
Training loss: 3.6374434948494603
Validation loss: 3.343567712227545

Epoch: 5| Step: 10
Training loss: 3.3123268226123708
Validation loss: 3.343376501455315

Epoch: 116| Step: 0
Training loss: 3.6687130563880714
Validation loss: 3.345933034617372

Epoch: 5| Step: 1
Training loss: 3.6516112546722472
Validation loss: 3.3515381880411765

Epoch: 5| Step: 2
Training loss: 3.855062074866528
Validation loss: 3.3621166705008236

Epoch: 5| Step: 3
Training loss: 3.5449550994913417
Validation loss: 3.3449196696496757

Epoch: 5| Step: 4
Training loss: 3.497594551733438
Validation loss: 3.3437039565055025

Epoch: 5| Step: 5
Training loss: 3.065250640627641
Validation loss: 3.3449355362078608

Epoch: 5| Step: 6
Training loss: 3.547643771440493
Validation loss: 3.344145479180816

Epoch: 5| Step: 7
Training loss: 3.132793474020702
Validation loss: 3.343735814555618

Epoch: 5| Step: 8
Training loss: 3.1597592324871204
Validation loss: 3.345338729384127

Epoch: 5| Step: 9
Training loss: 4.2144660957286035
Validation loss: 3.343380272486645

Epoch: 5| Step: 10
Training loss: 3.87890625
Validation loss: 3.345166539313579

Epoch: 117| Step: 0
Training loss: 3.3396979763051946
Validation loss: 3.3448383996857673

Epoch: 5| Step: 1
Training loss: 3.696816652406666
Validation loss: 3.344943510079133

Epoch: 5| Step: 2
Training loss: 3.2619979647519552
Validation loss: 3.3469085327379258

Epoch: 5| Step: 3
Training loss: 3.591305241171532
Validation loss: 3.345520222568327

Epoch: 5| Step: 4
Training loss: 3.2766383142754902
Validation loss: 3.3443839471135117

Epoch: 5| Step: 5
Training loss: 3.7584219139018904
Validation loss: 3.3444758338446805

Epoch: 5| Step: 6
Training loss: 2.935146931442321
Validation loss: 3.3455639927999923

Epoch: 5| Step: 7
Training loss: 3.330732300344051
Validation loss: 3.343295385679681

Epoch: 5| Step: 8
Training loss: 4.242019790509725
Validation loss: 3.345286101875802

Epoch: 5| Step: 9
Training loss: 4.449248329714008
Validation loss: 3.343110718145123

Epoch: 5| Step: 10
Training loss: 3.046589842926105
Validation loss: 3.3428631582958133

Epoch: 118| Step: 0
Training loss: 4.152212605598939
Validation loss: 3.3412489033488963

Epoch: 5| Step: 1
Training loss: 3.4155784052317046
Validation loss: 3.341732699689238

Epoch: 5| Step: 2
Training loss: 3.9265841597700826
Validation loss: 3.3427098484696907

Epoch: 5| Step: 3
Training loss: 3.8409717722965127
Validation loss: 3.340100220602494

Epoch: 5| Step: 4
Training loss: 3.46482819873025
Validation loss: 3.3405609042136732

Epoch: 5| Step: 5
Training loss: 3.571824169047559
Validation loss: 3.3422239123792474

Epoch: 5| Step: 6
Training loss: 3.394564822681721
Validation loss: 3.3391220056529933

Epoch: 5| Step: 7
Training loss: 3.235386639562341
Validation loss: 3.339934764562956

Epoch: 5| Step: 8
Training loss: 3.7108123436953897
Validation loss: 3.338802016050733

Epoch: 5| Step: 9
Training loss: 3.2583294282257276
Validation loss: 3.3378263884100545

Epoch: 5| Step: 10
Training loss: 3.0975888258149236
Validation loss: 3.338522626977302

Epoch: 119| Step: 0
Training loss: 3.4202645749376233
Validation loss: 3.339495058824756

Epoch: 5| Step: 1
Training loss: 3.65714755004769
Validation loss: 3.3406709132345065

Epoch: 5| Step: 2
Training loss: 3.178951693791518
Validation loss: 3.3395490488397908

Epoch: 5| Step: 3
Training loss: 3.9775878543610017
Validation loss: 3.3372744186086543

Epoch: 5| Step: 4
Training loss: 2.9325835295583507
Validation loss: 3.336346672201505

Epoch: 5| Step: 5
Training loss: 3.935014454913219
Validation loss: 3.338479758098765

Epoch: 5| Step: 6
Training loss: 3.214003832128171
Validation loss: 3.3370044478771357

Epoch: 5| Step: 7
Training loss: 3.8941793483661242
Validation loss: 3.3378751642760554

Epoch: 5| Step: 8
Training loss: 3.899198102428239
Validation loss: 3.3355534210355473

Epoch: 5| Step: 9
Training loss: 3.5213187671212296
Validation loss: 3.3367162478838805

Epoch: 5| Step: 10
Training loss: 3.4366953514917267
Validation loss: 3.333808010410244

Epoch: 120| Step: 0
Training loss: 3.6107852707273067
Validation loss: 3.3379156722960666

Epoch: 5| Step: 1
Training loss: 3.294825056696613
Validation loss: 3.334462816372314

Epoch: 5| Step: 2
Training loss: 3.7785874758139357
Validation loss: 3.3349901240132893

Epoch: 5| Step: 3
Training loss: 3.383387985790299
Validation loss: 3.335865739000256

Epoch: 5| Step: 4
Training loss: 4.096253539553275
Validation loss: 3.3368187084590892

Epoch: 5| Step: 5
Training loss: 3.2948868528629243
Validation loss: 3.336715958998387

Epoch: 5| Step: 6
Training loss: 4.042838775462099
Validation loss: 3.337912626262434

Epoch: 5| Step: 7
Training loss: 3.491067933041457
Validation loss: 3.3346475492055387

Epoch: 5| Step: 8
Training loss: 3.0942816999897733
Validation loss: 3.3368462269159407

Epoch: 5| Step: 9
Training loss: 3.853510922846219
Validation loss: 3.3376409620315948

Epoch: 5| Step: 10
Training loss: 3.0438124695306725
Validation loss: 3.3379651672649207

Epoch: 121| Step: 0
Training loss: 4.181187212690716
Validation loss: 3.334338772300122

Epoch: 5| Step: 1
Training loss: 3.2505997324502243
Validation loss: 3.3336264917196674

Epoch: 5| Step: 2
Training loss: 3.6925606350578866
Validation loss: 3.3337507114800062

Epoch: 5| Step: 3
Training loss: 3.0930120956031457
Validation loss: 3.334617500180005

Epoch: 5| Step: 4
Training loss: 3.315112828884909
Validation loss: 3.33578007073876

Epoch: 5| Step: 5
Training loss: 3.589857829899619
Validation loss: 3.3391824154477687

Epoch: 5| Step: 6
Training loss: 3.2535080683273843
Validation loss: 3.335485978969927

Epoch: 5| Step: 7
Training loss: 3.555893913368666
Validation loss: 3.3355669572442532

Epoch: 5| Step: 8
Training loss: 4.005459635787246
Validation loss: 3.3321623550202752

Epoch: 5| Step: 9
Training loss: 3.6346661832346867
Validation loss: 3.3338585660245688

Epoch: 5| Step: 10
Training loss: 3.502142114427745
Validation loss: 3.3308337924132108

Epoch: 122| Step: 0
Training loss: 4.165735420429096
Validation loss: 3.332694472854751

Epoch: 5| Step: 1
Training loss: 3.7755227339631863
Validation loss: 3.3356720708142156

Epoch: 5| Step: 2
Training loss: 3.118227983411534
Validation loss: 3.332022580471387

Epoch: 5| Step: 3
Training loss: 3.0194001755388347
Validation loss: 3.3341765634394203

Epoch: 5| Step: 4
Training loss: 3.9449889399732454
Validation loss: 3.3392566709194615

Epoch: 5| Step: 5
Training loss: 3.612465068291859
Validation loss: 3.3357014017403332

Epoch: 5| Step: 6
Training loss: 3.479136133726232
Validation loss: 3.334045541468713

Epoch: 5| Step: 7
Training loss: 3.76141045595453
Validation loss: 3.3331271251350967

Epoch: 5| Step: 8
Training loss: 4.02154887788241
Validation loss: 3.329063728754843

Epoch: 5| Step: 9
Training loss: 3.301205074029164
Validation loss: 3.328889618678141

Epoch: 5| Step: 10
Training loss: 2.5190009926812555
Validation loss: 3.333945375571207

Epoch: 123| Step: 0
Training loss: 3.496065926041515
Validation loss: 3.3290852747134276

Epoch: 5| Step: 1
Training loss: 3.886523187212603
Validation loss: 3.330083678649923

Epoch: 5| Step: 2
Training loss: 3.438743782439967
Validation loss: 3.330838236096162

Epoch: 5| Step: 3
Training loss: 2.548799501455657
Validation loss: 3.326786016668932

Epoch: 5| Step: 4
Training loss: 4.067917483427797
Validation loss: 3.327790029267424

Epoch: 5| Step: 5
Training loss: 3.7631864764265752
Validation loss: 3.3291776707104535

Epoch: 5| Step: 6
Training loss: 3.375594757797812
Validation loss: 3.32867263832264

Epoch: 5| Step: 7
Training loss: 3.661867570141952
Validation loss: 3.3310392743187087

Epoch: 5| Step: 8
Training loss: 3.938029662338764
Validation loss: 3.326960856368178

Epoch: 5| Step: 9
Training loss: 3.398233201474196
Validation loss: 3.328290654146747

Epoch: 5| Step: 10
Training loss: 3.3006330287541705
Validation loss: 3.3255094065350113

Epoch: 124| Step: 0
Training loss: 3.475904904011817
Validation loss: 3.3265103395125633

Epoch: 5| Step: 1
Training loss: 3.7827702768483347
Validation loss: 3.329162199555477

Epoch: 5| Step: 2
Training loss: 3.0265819353967474
Validation loss: 3.326102107692265

Epoch: 5| Step: 3
Training loss: 3.5406945783170607
Validation loss: 3.326560594502326

Epoch: 5| Step: 4
Training loss: 3.920955109335146
Validation loss: 3.32621512756036

Epoch: 5| Step: 5
Training loss: 3.1647184469089136
Validation loss: 3.3285127658731755

Epoch: 5| Step: 6
Training loss: 2.978660184760399
Validation loss: 3.3264720000167323

Epoch: 5| Step: 7
Training loss: 3.2689999019871343
Validation loss: 3.327169322429735

Epoch: 5| Step: 8
Training loss: 4.178367791436352
Validation loss: 3.326481109424784

Epoch: 5| Step: 9
Training loss: 4.319150357935357
Validation loss: 3.325537097206419

Epoch: 5| Step: 10
Training loss: 3.1114445992009054
Validation loss: 3.3276708295807236

Epoch: 125| Step: 0
Training loss: 3.591812673080741
Validation loss: 3.3259988807159013

Epoch: 5| Step: 1
Training loss: 3.3213249547825385
Validation loss: 3.326365678586811

Epoch: 5| Step: 2
Training loss: 3.355432796618718
Validation loss: 3.32450449851609

Epoch: 5| Step: 3
Training loss: 3.7531792197650606
Validation loss: 3.3284685180122944

Epoch: 5| Step: 4
Training loss: 3.4357461790185586
Validation loss: 3.325785723204348

Epoch: 5| Step: 5
Training loss: 3.64432530776995
Validation loss: 3.325648967638368

Epoch: 5| Step: 6
Training loss: 3.4006198935040084
Validation loss: 3.326642705560748

Epoch: 5| Step: 7
Training loss: 3.660514496458685
Validation loss: 3.3253364995960473

Epoch: 5| Step: 8
Training loss: 4.092727882970947
Validation loss: 3.3254519414889065

Epoch: 5| Step: 9
Training loss: 3.3043045290984465
Validation loss: 3.3232860150967922

Epoch: 5| Step: 10
Training loss: 3.462012268309119
Validation loss: 3.325784947741647

Epoch: 126| Step: 0
Training loss: 3.4802370690022713
Validation loss: 3.322265885819151

Epoch: 5| Step: 1
Training loss: 3.9806237607053485
Validation loss: 3.3225127165023465

Epoch: 5| Step: 2
Training loss: 3.40565037480403
Validation loss: 3.3213935550475604

Epoch: 5| Step: 3
Training loss: 3.36905245015958
Validation loss: 3.3226636667548974

Epoch: 5| Step: 4
Training loss: 3.97392716235147
Validation loss: 3.324280821841997

Epoch: 5| Step: 5
Training loss: 3.1567408113993145
Validation loss: 3.325090106745809

Epoch: 5| Step: 6
Training loss: 3.1967201769675655
Validation loss: 3.323299957665514

Epoch: 5| Step: 7
Training loss: 3.6318985640523374
Validation loss: 3.3228468505569357

Epoch: 5| Step: 8
Training loss: 3.6308189254403667
Validation loss: 3.3226644722654055

Epoch: 5| Step: 9
Training loss: 3.5971330724115846
Validation loss: 3.3234971268179305

Epoch: 5| Step: 10
Training loss: 3.56857517970007
Validation loss: 3.320094284231568

Epoch: 127| Step: 0
Training loss: 3.3598423832300415
Validation loss: 3.3229959587558024

Epoch: 5| Step: 1
Training loss: 3.5101719590800693
Validation loss: 3.322308487034598

Epoch: 5| Step: 2
Training loss: 2.7693544231830662
Validation loss: 3.322940786338899

Epoch: 5| Step: 3
Training loss: 3.8251620289511257
Validation loss: 3.322653546162264

Epoch: 5| Step: 4
Training loss: 3.5836719678214437
Validation loss: 3.3234634178482385

Epoch: 5| Step: 5
Training loss: 3.3575583580552375
Validation loss: 3.321144081518398

Epoch: 5| Step: 6
Training loss: 3.673545554781402
Validation loss: 3.321822917480819

Epoch: 5| Step: 7
Training loss: 3.9755481557941272
Validation loss: 3.3211956859449723

Epoch: 5| Step: 8
Training loss: 3.8310183431713467
Validation loss: 3.322998746900442

Epoch: 5| Step: 9
Training loss: 3.6370158499245697
Validation loss: 3.3213734265015256

Epoch: 5| Step: 10
Training loss: 3.3621522291077683
Validation loss: 3.323477262479728

Epoch: 128| Step: 0
Training loss: 3.4235832792693643
Validation loss: 3.3251925184874103

Epoch: 5| Step: 1
Training loss: 2.878788649332287
Validation loss: 3.323628983458001

Epoch: 5| Step: 2
Training loss: 4.087070052839967
Validation loss: 3.3218896105219478

Epoch: 5| Step: 3
Training loss: 3.148573955295529
Validation loss: 3.318336785190139

Epoch: 5| Step: 4
Training loss: 3.543933741197698
Validation loss: 3.321510605088627

Epoch: 5| Step: 5
Training loss: 2.894880636650095
Validation loss: 3.319234945387266

Epoch: 5| Step: 6
Training loss: 3.86201479435146
Validation loss: 3.32093174486811

Epoch: 5| Step: 7
Training loss: 3.5734586313921413
Validation loss: 3.321788679069527

Epoch: 5| Step: 8
Training loss: 3.623247841250777
Validation loss: 3.3187924113946234

Epoch: 5| Step: 9
Training loss: 3.6948884555359096
Validation loss: 3.320924691423125

Epoch: 5| Step: 10
Training loss: 4.151491352199556
Validation loss: 3.3195758888005886

Epoch: 129| Step: 0
Training loss: 3.3454693803345235
Validation loss: 3.3191432156879186

Epoch: 5| Step: 1
Training loss: 2.9916065737782014
Validation loss: 3.3180835787463154

Epoch: 5| Step: 2
Training loss: 4.239479282361372
Validation loss: 3.317090382014894

Epoch: 5| Step: 3
Training loss: 3.410118076595836
Validation loss: 3.3167146434293424

Epoch: 5| Step: 4
Training loss: 3.7407580614126115
Validation loss: 3.318609807968887

Epoch: 5| Step: 5
Training loss: 3.387575245827401
Validation loss: 3.3179112460216156

Epoch: 5| Step: 6
Training loss: 3.3906719714308373
Validation loss: 3.316721298485957

Epoch: 5| Step: 7
Training loss: 3.2895497303253665
Validation loss: 3.3169856364295

Epoch: 5| Step: 8
Training loss: 4.237225575971268
Validation loss: 3.3179129103459855

Epoch: 5| Step: 9
Training loss: 3.5581111978584485
Validation loss: 3.3163260190714827

Epoch: 5| Step: 10
Training loss: 3.14346716273968
Validation loss: 3.319341719197739

Epoch: 130| Step: 0
Training loss: 3.793869021715255
Validation loss: 3.3181216674887097

Epoch: 5| Step: 1
Training loss: 3.664782097598161
Validation loss: 3.315892676043057

Epoch: 5| Step: 2
Training loss: 3.692999666430378
Validation loss: 3.3161749736009907

Epoch: 5| Step: 3
Training loss: 3.6587315150798476
Validation loss: 3.316337588313652

Epoch: 5| Step: 4
Training loss: 3.6253338364094194
Validation loss: 3.3160161144087157

Epoch: 5| Step: 5
Training loss: 3.219719009459976
Validation loss: 3.315376193954167

Epoch: 5| Step: 6
Training loss: 3.6362170601694
Validation loss: 3.3142057884368747

Epoch: 5| Step: 7
Training loss: 3.161700839064276
Validation loss: 3.313616314739436

Epoch: 5| Step: 8
Training loss: 3.4407029921780956
Validation loss: 3.3148063397835945

Epoch: 5| Step: 9
Training loss: 3.0231611731768298
Validation loss: 3.313427419733169

Epoch: 5| Step: 10
Training loss: 4.025399153921096
Validation loss: 3.314128344710983

Epoch: 131| Step: 0
Training loss: 3.5575949379965794
Validation loss: 3.314397030702558

Epoch: 5| Step: 1
Training loss: 3.4847974307324874
Validation loss: 3.316107075574922

Epoch: 5| Step: 2
Training loss: 4.252618992490167
Validation loss: 3.3127945985468874

Epoch: 5| Step: 3
Training loss: 4.137629739162077
Validation loss: 3.3137283354058633

Epoch: 5| Step: 4
Training loss: 3.4629966517362565
Validation loss: 3.3120710869555885

Epoch: 5| Step: 5
Training loss: 3.1416713812376984
Validation loss: 3.312172311435085

Epoch: 5| Step: 6
Training loss: 3.950160667918226
Validation loss: 3.31316493661209

Epoch: 5| Step: 7
Training loss: 2.984712591599996
Validation loss: 3.312764095923954

Epoch: 5| Step: 8
Training loss: 4.0225869474147755
Validation loss: 3.3122373474093476

Epoch: 5| Step: 9
Training loss: 2.85998095152587
Validation loss: 3.313726122787953

Epoch: 5| Step: 10
Training loss: 2.524537027046293
Validation loss: 3.3148962320943753

Epoch: 132| Step: 0
Training loss: 3.345291067782598
Validation loss: 3.317547350890207

Epoch: 5| Step: 1
Training loss: 3.7133127421065573
Validation loss: 3.320706566837127

Epoch: 5| Step: 2
Training loss: 4.1206336754444735
Validation loss: 3.3191183063316902

Epoch: 5| Step: 3
Training loss: 4.0152682728528255
Validation loss: 3.3205281134901647

Epoch: 5| Step: 4
Training loss: 2.7795708548745552
Validation loss: 3.315423066966583

Epoch: 5| Step: 5
Training loss: 3.6344170421159636
Validation loss: 3.311694529624603

Epoch: 5| Step: 6
Training loss: 3.2027569815262042
Validation loss: 3.310501395006989

Epoch: 5| Step: 7
Training loss: 3.4501805244429047
Validation loss: 3.311081687713193

Epoch: 5| Step: 8
Training loss: 3.406568739790591
Validation loss: 3.310105109510531

Epoch: 5| Step: 9
Training loss: 3.4069819232717524
Validation loss: 3.3101326595254603

Epoch: 5| Step: 10
Training loss: 3.7262625583563747
Validation loss: 3.3101749599538626

Epoch: 133| Step: 0
Training loss: 3.7045923858750505
Validation loss: 3.3110500388789674

Epoch: 5| Step: 1
Training loss: 3.06502195565106
Validation loss: 3.310806256218555

Epoch: 5| Step: 2
Training loss: 3.901337976071804
Validation loss: 3.310523231366984

Epoch: 5| Step: 3
Training loss: 2.8957731025707565
Validation loss: 3.3104863778763405

Epoch: 5| Step: 4
Training loss: 3.1330701764840705
Validation loss: 3.310069794163913

Epoch: 5| Step: 5
Training loss: 2.4740964723803263
Validation loss: 3.3095648421689843

Epoch: 5| Step: 6
Training loss: 4.058918474587733
Validation loss: 3.3104195913982624

Epoch: 5| Step: 7
Training loss: 3.995402316388151
Validation loss: 3.310300301364754

Epoch: 5| Step: 8
Training loss: 3.4896170695178172
Validation loss: 3.30922598315982

Epoch: 5| Step: 9
Training loss: 4.071969601051163
Validation loss: 3.30899992720127

Epoch: 5| Step: 10
Training loss: 3.76677638768993
Validation loss: 3.3079862824253405

Epoch: 134| Step: 0
Training loss: 3.4761027171384993
Validation loss: 3.3079725791074495

Epoch: 5| Step: 1
Training loss: 2.9542938018544773
Validation loss: 3.3079320438617223

Epoch: 5| Step: 2
Training loss: 3.736564473216005
Validation loss: 3.3086477468168587

Epoch: 5| Step: 3
Training loss: 3.2079351268877483
Validation loss: 3.307386257662182

Epoch: 5| Step: 4
Training loss: 3.8738929643865907
Validation loss: 3.308075525425057

Epoch: 5| Step: 5
Training loss: 3.1350798737543095
Validation loss: 3.3080373334109563

Epoch: 5| Step: 6
Training loss: 4.349340779131096
Validation loss: 3.306845600386512

Epoch: 5| Step: 7
Training loss: 4.120655662067282
Validation loss: 3.305631277595182

Epoch: 5| Step: 8
Training loss: 2.8085369587171582
Validation loss: 3.3053835244443412

Epoch: 5| Step: 9
Training loss: 3.799640919634915
Validation loss: 3.3057703587683482

Epoch: 5| Step: 10
Training loss: 2.995386390789501
Validation loss: 3.305499437488364

Epoch: 135| Step: 0
Training loss: 3.548095761921682
Validation loss: 3.305926477372878

Epoch: 5| Step: 1
Training loss: 3.4464564770543644
Validation loss: 3.3054184043417885

Epoch: 5| Step: 2
Training loss: 3.183459844288945
Validation loss: 3.305922314657316

Epoch: 5| Step: 3
Training loss: 3.169075919400222
Validation loss: 3.305707878086213

Epoch: 5| Step: 4
Training loss: 3.3941690934363993
Validation loss: 3.3046410099955246

Epoch: 5| Step: 5
Training loss: 3.9745697844312002
Validation loss: 3.3052018036247874

Epoch: 5| Step: 6
Training loss: 3.5262895700749026
Validation loss: 3.308537553260897

Epoch: 5| Step: 7
Training loss: 3.758886108572815
Validation loss: 3.304269548995227

Epoch: 5| Step: 8
Training loss: 3.4543551502102647
Validation loss: 3.303268324544462

Epoch: 5| Step: 9
Training loss: 4.041197575878967
Validation loss: 3.3030955851967545

Epoch: 5| Step: 10
Training loss: 3.2155006080642288
Validation loss: 3.3031071200614335

Epoch: 136| Step: 0
Training loss: 4.37932917435239
Validation loss: 3.3021430165476753

Epoch: 5| Step: 1
Training loss: 3.3014064219348955
Validation loss: 3.3031357622399606

Epoch: 5| Step: 2
Training loss: 2.2313152784527537
Validation loss: 3.3039411155110243

Epoch: 5| Step: 3
Training loss: 3.6637072035060965
Validation loss: 3.301525850842263

Epoch: 5| Step: 4
Training loss: 3.852441157461604
Validation loss: 3.3021752134530127

Epoch: 5| Step: 5
Training loss: 3.57988725601912
Validation loss: 3.3040642710307755

Epoch: 5| Step: 6
Training loss: 3.9082189861778343
Validation loss: 3.3023920670220255

Epoch: 5| Step: 7
Training loss: 3.016750303622953
Validation loss: 3.302385682740408

Epoch: 5| Step: 8
Training loss: 3.4219296246353506
Validation loss: 3.3015108154044386

Epoch: 5| Step: 9
Training loss: 3.6902716613675453
Validation loss: 3.301100622741595

Epoch: 5| Step: 10
Training loss: 3.3520629793682826
Validation loss: 3.3006971053026395

Epoch: 137| Step: 0
Training loss: 3.630499515686297
Validation loss: 3.301289216651

Epoch: 5| Step: 1
Training loss: 3.2327499361469645
Validation loss: 3.301160344431826

Epoch: 5| Step: 2
Training loss: 2.850455123968333
Validation loss: 3.300436500835958

Epoch: 5| Step: 3
Training loss: 3.051053199906896
Validation loss: 3.2999038426226286

Epoch: 5| Step: 4
Training loss: 3.859785421069946
Validation loss: 3.30049124162913

Epoch: 5| Step: 5
Training loss: 3.6177282073425787
Validation loss: 3.2991605378311104

Epoch: 5| Step: 6
Training loss: 4.036139310309614
Validation loss: 3.2986698961587897

Epoch: 5| Step: 7
Training loss: 4.006409278595634
Validation loss: 3.2994418831651915

Epoch: 5| Step: 8
Training loss: 3.6161426328615316
Validation loss: 3.2996370788128404

Epoch: 5| Step: 9
Training loss: 3.4897907404207302
Validation loss: 3.299087653604028

Epoch: 5| Step: 10
Training loss: 3.1839663796494904
Validation loss: 3.298903943146326

Epoch: 138| Step: 0
Training loss: 3.3970534740121257
Validation loss: 3.2994589614097345

Epoch: 5| Step: 1
Training loss: 3.7803523992334545
Validation loss: 3.298632167251702

Epoch: 5| Step: 2
Training loss: 3.4604761922739655
Validation loss: 3.2986013067272846

Epoch: 5| Step: 3
Training loss: 3.1464043576883247
Validation loss: 3.2995574167758526

Epoch: 5| Step: 4
Training loss: 2.6981512628036617
Validation loss: 3.298308129780284

Epoch: 5| Step: 5
Training loss: 2.7355068806872174
Validation loss: 3.2970081468282113

Epoch: 5| Step: 6
Training loss: 3.644588425035512
Validation loss: 3.2977734968375096

Epoch: 5| Step: 7
Training loss: 4.300496964236145
Validation loss: 3.2963968208289884

Epoch: 5| Step: 8
Training loss: 3.661801158904721
Validation loss: 3.2970059914152285

Epoch: 5| Step: 9
Training loss: 3.4595979117343196
Validation loss: 3.2960710889168072

Epoch: 5| Step: 10
Training loss: 4.2661143710386185
Validation loss: 3.2967566646957343

Epoch: 139| Step: 0
Training loss: 4.016704251019875
Validation loss: 3.296047336777458

Epoch: 5| Step: 1
Training loss: 3.1467092612449417
Validation loss: 3.2956138912291166

Epoch: 5| Step: 2
Training loss: 3.3799856589650745
Validation loss: 3.2964096763495387

Epoch: 5| Step: 3
Training loss: 3.9104557437126375
Validation loss: 3.296586584373964

Epoch: 5| Step: 4
Training loss: 2.9481749045196013
Validation loss: 3.295669393549815

Epoch: 5| Step: 5
Training loss: 3.082733731778884
Validation loss: 3.2942043603995583

Epoch: 5| Step: 6
Training loss: 3.7015137849164845
Validation loss: 3.294805399200658

Epoch: 5| Step: 7
Training loss: 3.350966891916089
Validation loss: 3.295726203310401

Epoch: 5| Step: 8
Training loss: 4.559589032175376
Validation loss: 3.2953067500804027

Epoch: 5| Step: 9
Training loss: 3.5028576765057795
Validation loss: 3.29456654160605

Epoch: 5| Step: 10
Training loss: 2.6632941695840198
Validation loss: 3.2934272980230963

Epoch: 140| Step: 0
Training loss: 3.2766310379507644
Validation loss: 3.2940384754610847

Epoch: 5| Step: 1
Training loss: 3.2937248330358195
Validation loss: 3.2946824578260085

Epoch: 5| Step: 2
Training loss: 3.7092129524912303
Validation loss: 3.294549459788332

Epoch: 5| Step: 3
Training loss: 3.6534634918731834
Validation loss: 3.2938878275900723

Epoch: 5| Step: 4
Training loss: 3.8379823164142377
Validation loss: 3.293394619381145

Epoch: 5| Step: 5
Training loss: 3.290997948301934
Validation loss: 3.292509953580057

Epoch: 5| Step: 6
Training loss: 3.767538130781762
Validation loss: 3.2920031569615813

Epoch: 5| Step: 7
Training loss: 3.206486570914584
Validation loss: 3.292383285488059

Epoch: 5| Step: 8
Training loss: 2.8456870388186384
Validation loss: 3.292123985272582

Epoch: 5| Step: 9
Training loss: 4.097868267498183
Validation loss: 3.2928098363066898

Epoch: 5| Step: 10
Training loss: 3.6303521469432454
Validation loss: 3.290963481116195

Epoch: 141| Step: 0
Training loss: 3.778437048912258
Validation loss: 3.292647510147209

Epoch: 5| Step: 1
Training loss: 3.9679956395063742
Validation loss: 3.293219766284902

Epoch: 5| Step: 2
Training loss: 3.896901900405849
Validation loss: 3.2927711238820487

Epoch: 5| Step: 3
Training loss: 3.1978835975022335
Validation loss: 3.2928864205256385

Epoch: 5| Step: 4
Training loss: 3.621948009739221
Validation loss: 3.292326813609829

Epoch: 5| Step: 5
Training loss: 3.619135091317275
Validation loss: 3.292517324065017

Epoch: 5| Step: 6
Training loss: 3.9140612817332188
Validation loss: 3.294320838772754

Epoch: 5| Step: 7
Training loss: 2.641083807277419
Validation loss: 3.2942018654010425

Epoch: 5| Step: 8
Training loss: 3.3376447610499764
Validation loss: 3.2946161228856505

Epoch: 5| Step: 9
Training loss: 3.090243577708377
Validation loss: 3.294215493704279

Epoch: 5| Step: 10
Training loss: 3.432315453932691
Validation loss: 3.293405260350395

Epoch: 142| Step: 0
Training loss: 3.237126898162871
Validation loss: 3.2930996212112844

Epoch: 5| Step: 1
Training loss: 3.575840916468138
Validation loss: 3.293059054697039

Epoch: 5| Step: 2
Training loss: 3.506816901142289
Validation loss: 3.2954015097933

Epoch: 5| Step: 3
Training loss: 2.6344292541202545
Validation loss: 3.293192037414568

Epoch: 5| Step: 4
Training loss: 3.2689788971619764
Validation loss: 3.294168388968687

Epoch: 5| Step: 5
Training loss: 3.7020528665783416
Validation loss: 3.294573298206207

Epoch: 5| Step: 6
Training loss: 3.578548889371988
Validation loss: 3.29286786088114

Epoch: 5| Step: 7
Training loss: 4.196266676727874
Validation loss: 3.290157363581196

Epoch: 5| Step: 8
Training loss: 3.6078692841883213
Validation loss: 3.290363255166345

Epoch: 5| Step: 9
Training loss: 3.249533693166215
Validation loss: 3.2889516518158395

Epoch: 5| Step: 10
Training loss: 4.021793362871556
Validation loss: 3.2899981925334267

Epoch: 143| Step: 0
Training loss: 3.7672280346190004
Validation loss: 3.2881958137982314

Epoch: 5| Step: 1
Training loss: 3.1847447473596624
Validation loss: 3.287604655260961

Epoch: 5| Step: 2
Training loss: 2.954551069881198
Validation loss: 3.2892744084582257

Epoch: 5| Step: 3
Training loss: 3.612585052228185
Validation loss: 3.289535161521702

Epoch: 5| Step: 4
Training loss: 3.8897997122541716
Validation loss: 3.2984375844381364

Epoch: 5| Step: 5
Training loss: 3.529430764745545
Validation loss: 3.2899885737967547

Epoch: 5| Step: 6
Training loss: 3.1463466166596343
Validation loss: 3.287813181600438

Epoch: 5| Step: 7
Training loss: 4.095064374443332
Validation loss: 3.288422369056086

Epoch: 5| Step: 8
Training loss: 3.1579822281379077
Validation loss: 3.287118381357296

Epoch: 5| Step: 9
Training loss: 4.059024909049004
Validation loss: 3.2911886758878137

Epoch: 5| Step: 10
Training loss: 3.0299826263332514
Validation loss: 3.2898232789247874

Epoch: 144| Step: 0
Training loss: 3.9608065190375052
Validation loss: 3.2950129578899667

Epoch: 5| Step: 1
Training loss: 3.55423312794006
Validation loss: 3.294325257389664

Epoch: 5| Step: 2
Training loss: 3.5312383870971935
Validation loss: 3.293568792233026

Epoch: 5| Step: 3
Training loss: 3.518713107686403
Validation loss: 3.2895982681196516

Epoch: 5| Step: 4
Training loss: 2.8490628090251904
Validation loss: 3.2899295173787904

Epoch: 5| Step: 5
Training loss: 3.4067483239984733
Validation loss: 3.292900462225841

Epoch: 5| Step: 6
Training loss: 3.511567346960438
Validation loss: 3.290153939841366

Epoch: 5| Step: 7
Training loss: 4.09893935836155
Validation loss: 3.2904145951568076

Epoch: 5| Step: 8
Training loss: 3.6065393183067043
Validation loss: 3.292587219050301

Epoch: 5| Step: 9
Training loss: 3.3682321578630376
Validation loss: 3.290308758823045

Epoch: 5| Step: 10
Training loss: 3.078175036028523
Validation loss: 3.287859011300451

Epoch: 145| Step: 0
Training loss: 3.6323848349580747
Validation loss: 3.289112100336079

Epoch: 5| Step: 1
Training loss: 3.893636495488065
Validation loss: 3.2880289177638544

Epoch: 5| Step: 2
Training loss: 2.6013711394993067
Validation loss: 3.286265402263484

Epoch: 5| Step: 3
Training loss: 3.2026310237433164
Validation loss: 3.2863312208432944

Epoch: 5| Step: 4
Training loss: 3.7737400099529546
Validation loss: 3.287085826394284

Epoch: 5| Step: 5
Training loss: 3.3864195448407157
Validation loss: 3.286154509656518

Epoch: 5| Step: 6
Training loss: 3.472169307729404
Validation loss: 3.286240331069609

Epoch: 5| Step: 7
Training loss: 2.4936950333352725
Validation loss: 3.2835754182282213

Epoch: 5| Step: 8
Training loss: 4.214639653451676
Validation loss: 3.285890223979132

Epoch: 5| Step: 9
Training loss: 3.9087905556697793
Validation loss: 3.2839142787687057

Epoch: 5| Step: 10
Training loss: 3.7079455712283447
Validation loss: 3.28512227247138

Epoch: 146| Step: 0
Training loss: 3.1873496525031597
Validation loss: 3.283804069501815

Epoch: 5| Step: 1
Training loss: 4.059721010892164
Validation loss: 3.283596946857218

Epoch: 5| Step: 2
Training loss: 2.3387641262849095
Validation loss: 3.2852070548800922

Epoch: 5| Step: 3
Training loss: 2.512861261918208
Validation loss: 3.283421315905514

Epoch: 5| Step: 4
Training loss: 3.7648400719302693
Validation loss: 3.28238573239508

Epoch: 5| Step: 5
Training loss: 3.552480427461916
Validation loss: 3.283389476968431

Epoch: 5| Step: 6
Training loss: 3.5918969725890437
Validation loss: 3.2821598586540572

Epoch: 5| Step: 7
Training loss: 3.803130722355044
Validation loss: 3.2827434166836875

Epoch: 5| Step: 8
Training loss: 3.3541312521887363
Validation loss: 3.281190051865731

Epoch: 5| Step: 9
Training loss: 3.834511548185947
Validation loss: 3.28154199007147

Epoch: 5| Step: 10
Training loss: 4.268402871892744
Validation loss: 3.2811825840553666

Epoch: 147| Step: 0
Training loss: 3.3659623255941735
Validation loss: 3.2808705826885656

Epoch: 5| Step: 1
Training loss: 3.4974788031982125
Validation loss: 3.2822678416600524

Epoch: 5| Step: 2
Training loss: 3.0872586669503668
Validation loss: 3.283242261789652

Epoch: 5| Step: 3
Training loss: 3.1524813975330597
Validation loss: 3.2820422456924474

Epoch: 5| Step: 4
Training loss: 3.8059704006084463
Validation loss: 3.2812517329229496

Epoch: 5| Step: 5
Training loss: 4.109101144926744
Validation loss: 3.2812719841458438

Epoch: 5| Step: 6
Training loss: 3.6021901409198724
Validation loss: 3.2805832599056823

Epoch: 5| Step: 7
Training loss: 4.014324764416674
Validation loss: 3.2809580495778063

Epoch: 5| Step: 8
Training loss: 3.972787560437408
Validation loss: 3.2808552666204305

Epoch: 5| Step: 9
Training loss: 2.394297652183917
Validation loss: 3.280237821302898

Epoch: 5| Step: 10
Training loss: 3.219963659709319
Validation loss: 3.280289182218018

Epoch: 148| Step: 0
Training loss: 3.39063132852412
Validation loss: 3.2802221263572227

Epoch: 5| Step: 1
Training loss: 2.9719046445826116
Validation loss: 3.2788861316564284

Epoch: 5| Step: 2
Training loss: 4.486468208726664
Validation loss: 3.2797633696671795

Epoch: 5| Step: 3
Training loss: 2.863335040369143
Validation loss: 3.279113894590147

Epoch: 5| Step: 4
Training loss: 2.5162366988185356
Validation loss: 3.280529493537192

Epoch: 5| Step: 5
Training loss: 3.475500326021322
Validation loss: 3.279426676748087

Epoch: 5| Step: 6
Training loss: 4.465431528458539
Validation loss: 3.2794718012739628

Epoch: 5| Step: 7
Training loss: 3.706384310934223
Validation loss: 3.280071103410556

Epoch: 5| Step: 8
Training loss: 2.7603202850981736
Validation loss: 3.2811847264232923

Epoch: 5| Step: 9
Training loss: 3.443864790704663
Validation loss: 3.2797438767181615

Epoch: 5| Step: 10
Training loss: 3.9834125627967256
Validation loss: 3.276132785648909

Epoch: 149| Step: 0
Training loss: 3.078156911616784
Validation loss: 3.2768015672821407

Epoch: 5| Step: 1
Training loss: 3.3537630268743928
Validation loss: 3.2766391694381842

Epoch: 5| Step: 2
Training loss: 3.553515297582636
Validation loss: 3.2750891848609336

Epoch: 5| Step: 3
Training loss: 3.648556300971641
Validation loss: 3.276400290271033

Epoch: 5| Step: 4
Training loss: 3.5814320303306633
Validation loss: 3.2770660289369618

Epoch: 5| Step: 5
Training loss: 4.251372396248876
Validation loss: 3.2759638147983194

Epoch: 5| Step: 6
Training loss: 3.0537991610117223
Validation loss: 3.275032214385402

Epoch: 5| Step: 7
Training loss: 3.498285418565926
Validation loss: 3.276575499500746

Epoch: 5| Step: 8
Training loss: 3.567172817311959
Validation loss: 3.274096106568409

Epoch: 5| Step: 9
Training loss: 3.3492137441737873
Validation loss: 3.274835022195906

Epoch: 5| Step: 10
Training loss: 3.5046562829500263
Validation loss: 3.27473674731561

Epoch: 150| Step: 0
Training loss: 3.825793245128097
Validation loss: 3.275227575623069

Epoch: 5| Step: 1
Training loss: 3.849285079170876
Validation loss: 3.2734093701701226

Epoch: 5| Step: 2
Training loss: 3.3050104078166482
Validation loss: 3.274706561893443

Epoch: 5| Step: 3
Training loss: 3.434841029279716
Validation loss: 3.2732472355756137

Epoch: 5| Step: 4
Training loss: 3.1063911267771047
Validation loss: 3.27402701798729

Epoch: 5| Step: 5
Training loss: 3.095352374402034
Validation loss: 3.274526033044063

Epoch: 5| Step: 6
Training loss: 3.128664843215373
Validation loss: 3.2730579751903375

Epoch: 5| Step: 7
Training loss: 3.6537799806046722
Validation loss: 3.2723210540270578

Epoch: 5| Step: 8
Training loss: 4.316750463509442
Validation loss: 3.2725287454120786

Epoch: 5| Step: 9
Training loss: 3.3705444595670975
Validation loss: 3.272417431964522

Epoch: 5| Step: 10
Training loss: 3.215365065142095
Validation loss: 3.273965210213893

Epoch: 151| Step: 0
Training loss: 3.8342640755797897
Validation loss: 3.27442668958859

Epoch: 5| Step: 1
Training loss: 3.3747284391434915
Validation loss: 3.2756148649048655

Epoch: 5| Step: 2
Training loss: 3.8301091248825143
Validation loss: 3.273552234747687

Epoch: 5| Step: 3
Training loss: 3.66079442537957
Validation loss: 3.273888850546163

Epoch: 5| Step: 4
Training loss: 3.104236132636028
Validation loss: 3.2726818875573387

Epoch: 5| Step: 5
Training loss: 3.090803805001337
Validation loss: 3.271833190296676

Epoch: 5| Step: 6
Training loss: 4.167201020626852
Validation loss: 3.2732546165402554

Epoch: 5| Step: 7
Training loss: 3.4284455781500203
Validation loss: 3.2718296000745735

Epoch: 5| Step: 8
Training loss: 2.689798215225289
Validation loss: 3.2717856222765462

Epoch: 5| Step: 9
Training loss: 3.9414258489508995
Validation loss: 3.2720334607815915

Epoch: 5| Step: 10
Training loss: 3.049732140207425
Validation loss: 3.2688192995284764

Epoch: 152| Step: 0
Training loss: 2.6846530828000463
Validation loss: 3.2692887524815757

Epoch: 5| Step: 1
Training loss: 3.956146171376492
Validation loss: 3.2693099513543245

Epoch: 5| Step: 2
Training loss: 3.763745103805636
Validation loss: 3.2684178982466614

Epoch: 5| Step: 3
Training loss: 4.182963176830595
Validation loss: 3.26932438366648

Epoch: 5| Step: 4
Training loss: 3.0300616265000593
Validation loss: 3.2686653207334007

Epoch: 5| Step: 5
Training loss: 3.6218018729304746
Validation loss: 3.268158714137432

Epoch: 5| Step: 6
Training loss: 3.267569661058225
Validation loss: 3.267621638478416

Epoch: 5| Step: 7
Training loss: 2.7873045780122254
Validation loss: 3.2682874255284013

Epoch: 5| Step: 8
Training loss: 3.9897335147064124
Validation loss: 3.26772372207884

Epoch: 5| Step: 9
Training loss: 3.2140597642470583
Validation loss: 3.267701449080302

Epoch: 5| Step: 10
Training loss: 3.671006120186705
Validation loss: 3.267454968876757

Epoch: 153| Step: 0
Training loss: 3.3788847994261313
Validation loss: 3.2671802944645445

Epoch: 5| Step: 1
Training loss: 4.020342834808919
Validation loss: 3.2681410330450222

Epoch: 5| Step: 2
Training loss: 2.4732842634668173
Validation loss: 3.266690562723574

Epoch: 5| Step: 3
Training loss: 3.4322683577645723
Validation loss: 3.266675917085162

Epoch: 5| Step: 4
Training loss: 3.699841165999628
Validation loss: 3.2664353996576674

Epoch: 5| Step: 5
Training loss: 3.2620371406166875
Validation loss: 3.2661558955060253

Epoch: 5| Step: 6
Training loss: 3.160313926507097
Validation loss: 3.2655547791408845

Epoch: 5| Step: 7
Training loss: 3.9010694406876296
Validation loss: 3.2650895081754823

Epoch: 5| Step: 8
Training loss: 3.9795186684318318
Validation loss: 3.2657612892220125

Epoch: 5| Step: 9
Training loss: 3.2562442362143087
Validation loss: 3.266012299220333

Epoch: 5| Step: 10
Training loss: 3.6735093395716203
Validation loss: 3.2653115694156187

Epoch: 154| Step: 0
Training loss: 3.827065831232449
Validation loss: 3.2665257621505392

Epoch: 5| Step: 1
Training loss: 3.296988679634447
Validation loss: 3.264156937325124

Epoch: 5| Step: 2
Training loss: 3.735947026679745
Validation loss: 3.264360953632129

Epoch: 5| Step: 3
Training loss: 3.076972552048453
Validation loss: 3.2640380803168383

Epoch: 5| Step: 4
Training loss: 3.3762529661129546
Validation loss: 3.264555679722351

Epoch: 5| Step: 5
Training loss: 4.130929788480845
Validation loss: 3.2640639519475565

Epoch: 5| Step: 6
Training loss: 3.589902991469154
Validation loss: 3.2644030728369304

Epoch: 5| Step: 7
Training loss: 3.2522198358627
Validation loss: 3.262594160639183

Epoch: 5| Step: 8
Training loss: 3.3521507476103443
Validation loss: 3.2648799136719897

Epoch: 5| Step: 9
Training loss: 3.4427286783253015
Validation loss: 3.26387186708523

Epoch: 5| Step: 10
Training loss: 3.203832185415186
Validation loss: 3.262856687589272

Epoch: 155| Step: 0
Training loss: 3.3376586190581334
Validation loss: 3.2629235896272935

Epoch: 5| Step: 1
Training loss: 3.628374699321888
Validation loss: 3.2622679345007515

Epoch: 5| Step: 2
Training loss: 3.671382270381083
Validation loss: 3.261908682449426

Epoch: 5| Step: 3
Training loss: 3.6073071389780322
Validation loss: 3.262225058454069

Epoch: 5| Step: 4
Training loss: 3.943629383594372
Validation loss: 3.264071143187724

Epoch: 5| Step: 5
Training loss: 3.0254706907175
Validation loss: 3.264483241698211

Epoch: 5| Step: 6
Training loss: 3.5516874627862443
Validation loss: 3.2632941588626427

Epoch: 5| Step: 7
Training loss: 3.4309677480428684
Validation loss: 3.261123824812925

Epoch: 5| Step: 8
Training loss: 2.942713392585299
Validation loss: 3.2614244066542954

Epoch: 5| Step: 9
Training loss: 3.4332715470269752
Validation loss: 3.2609918841723053

Epoch: 5| Step: 10
Training loss: 3.8034375152449984
Validation loss: 3.260417225982567

Epoch: 156| Step: 0
Training loss: 3.8495081748414806
Validation loss: 3.2611117122252433

Epoch: 5| Step: 1
Training loss: 2.942532712483939
Validation loss: 3.2608230580251334

Epoch: 5| Step: 2
Training loss: 3.655015264184392
Validation loss: 3.260700047738326

Epoch: 5| Step: 3
Training loss: 3.2574127464290035
Validation loss: 3.2616206395508645

Epoch: 5| Step: 4
Training loss: 3.3806203033702382
Validation loss: 3.2607362374282327

Epoch: 5| Step: 5
Training loss: 3.7216416344239978
Validation loss: 3.2606732232375446

Epoch: 5| Step: 6
Training loss: 3.9090368476823145
Validation loss: 3.260705472679416

Epoch: 5| Step: 7
Training loss: 3.475290815959603
Validation loss: 3.260952395435941

Epoch: 5| Step: 8
Training loss: 3.6901994296717233
Validation loss: 3.259778599029506

Epoch: 5| Step: 9
Training loss: 2.2435665342506828
Validation loss: 3.259232093798338

Epoch: 5| Step: 10
Training loss: 4.029119830695958
Validation loss: 3.2588689808542397

Epoch: 157| Step: 0
Training loss: 3.2151133909741487
Validation loss: 3.259083009845279

Epoch: 5| Step: 1
Training loss: 3.1908532250628583
Validation loss: 3.2583219394925758

Epoch: 5| Step: 2
Training loss: 3.475525707849512
Validation loss: 3.2580272184470935

Epoch: 5| Step: 3
Training loss: 3.180286547868021
Validation loss: 3.2580186950708825

Epoch: 5| Step: 4
Training loss: 3.0061299956354484
Validation loss: 3.2581572616922228

Epoch: 5| Step: 5
Training loss: 4.281273612075626
Validation loss: 3.258734656481176

Epoch: 5| Step: 6
Training loss: 4.194470880578095
Validation loss: 3.257542386083839

Epoch: 5| Step: 7
Training loss: 3.5216998025394703
Validation loss: 3.256902081616318

Epoch: 5| Step: 8
Training loss: 3.7811457091522316
Validation loss: 3.257318466671647

Epoch: 5| Step: 9
Training loss: 3.0956869516040446
Validation loss: 3.2564481105786727

Epoch: 5| Step: 10
Training loss: 3.1326508516003226
Validation loss: 3.2574825210737615

Epoch: 158| Step: 0
Training loss: 2.591648031415106
Validation loss: 3.2582386212577723

Epoch: 5| Step: 1
Training loss: 3.086070847346397
Validation loss: 3.258670567483425

Epoch: 5| Step: 2
Training loss: 3.7512534272007603
Validation loss: 3.2615220451026667

Epoch: 5| Step: 3
Training loss: 3.6127579593624883
Validation loss: 3.2629369792985097

Epoch: 5| Step: 4
Training loss: 4.071044621732091
Validation loss: 3.2608462090077124

Epoch: 5| Step: 5
Training loss: 3.508080826927572
Validation loss: 3.257255830260721

Epoch: 5| Step: 6
Training loss: 3.817526333761165
Validation loss: 3.2563258498443584

Epoch: 5| Step: 7
Training loss: 3.6917418312245354
Validation loss: 3.2547862477318055

Epoch: 5| Step: 8
Training loss: 3.208166852983116
Validation loss: 3.2534441813193133

Epoch: 5| Step: 9
Training loss: 3.626011148375654
Validation loss: 3.254949653175252

Epoch: 5| Step: 10
Training loss: 3.109596896281066
Validation loss: 3.2556274984242024

Epoch: 159| Step: 0
Training loss: 3.9308495443426463
Validation loss: 3.2532012860844506

Epoch: 5| Step: 1
Training loss: 4.339719370545507
Validation loss: 3.2547899142522856

Epoch: 5| Step: 2
Training loss: 3.573477179303231
Validation loss: 3.2537259656106

Epoch: 5| Step: 3
Training loss: 3.708771211867556
Validation loss: 3.2543911403898083

Epoch: 5| Step: 4
Training loss: 3.601689863952563
Validation loss: 3.252019617539745

Epoch: 5| Step: 5
Training loss: 3.3900430065566587
Validation loss: 3.2526863219329556

Epoch: 5| Step: 6
Training loss: 3.2297073075748735
Validation loss: 3.2521450735120205

Epoch: 5| Step: 7
Training loss: 2.8006506640691335
Validation loss: 3.2535260732086395

Epoch: 5| Step: 8
Training loss: 3.3385009921845006
Validation loss: 3.252313960733314

Epoch: 5| Step: 9
Training loss: 2.827800331658648
Validation loss: 3.252464940455166

Epoch: 5| Step: 10
Training loss: 3.3098359821629835
Validation loss: 3.252241349368041

Epoch: 160| Step: 0
Training loss: 3.3770679213877983
Validation loss: 3.2514069148944724

Epoch: 5| Step: 1
Training loss: 3.8242506701936474
Validation loss: 3.249729728188603

Epoch: 5| Step: 2
Training loss: 4.003672344539653
Validation loss: 3.2513072458793015

Epoch: 5| Step: 3
Training loss: 3.7887590739092127
Validation loss: 3.2529182757619415

Epoch: 5| Step: 4
Training loss: 3.605365855028918
Validation loss: 3.253083806666955

Epoch: 5| Step: 5
Training loss: 3.708253809615561
Validation loss: 3.251480293924962

Epoch: 5| Step: 6
Training loss: 3.0380079307829333
Validation loss: 3.2504556603077313

Epoch: 5| Step: 7
Training loss: 3.5345318153191685
Validation loss: 3.2512989540516575

Epoch: 5| Step: 8
Training loss: 2.8691708723516234
Validation loss: 3.2523144344722974

Epoch: 5| Step: 9
Training loss: 3.0997942825478293
Validation loss: 3.2507292211006065

Epoch: 5| Step: 10
Training loss: 3.2785419733485646
Validation loss: 3.24910301848968

Epoch: 161| Step: 0
Training loss: 3.4999900545251412
Validation loss: 3.2507573815769426

Epoch: 5| Step: 1
Training loss: 2.7276563663573326
Validation loss: 3.250327050450148

Epoch: 5| Step: 2
Training loss: 3.3765790565575546
Validation loss: 3.250000145141497

Epoch: 5| Step: 3
Training loss: 3.678001195595211
Validation loss: 3.2511659302490887

Epoch: 5| Step: 4
Training loss: 2.5768911472492837
Validation loss: 3.250045411618547

Epoch: 5| Step: 5
Training loss: 3.7438507525048657
Validation loss: 3.2501835246681376

Epoch: 5| Step: 6
Training loss: 3.2542941261822955
Validation loss: 3.249760832714618

Epoch: 5| Step: 7
Training loss: 4.057563012010479
Validation loss: 3.2495125964356553

Epoch: 5| Step: 8
Training loss: 4.234920452501283
Validation loss: 3.249607228098456

Epoch: 5| Step: 9
Training loss: 3.5435413709582777
Validation loss: 3.2492608996110293

Epoch: 5| Step: 10
Training loss: 3.2699602909768535
Validation loss: 3.248233949535231

Epoch: 162| Step: 0
Training loss: 3.7210030021870657
Validation loss: 3.2506843679327506

Epoch: 5| Step: 1
Training loss: 3.4768704052993664
Validation loss: 3.2540143370552617

Epoch: 5| Step: 2
Training loss: 3.0925571184118246
Validation loss: 3.251254081934359

Epoch: 5| Step: 3
Training loss: 3.3759679465919126
Validation loss: 3.2525794345053978

Epoch: 5| Step: 4
Training loss: 3.7666324518275798
Validation loss: 3.255679157818893

Epoch: 5| Step: 5
Training loss: 3.1954876914649053
Validation loss: 3.255331180477657

Epoch: 5| Step: 6
Training loss: 3.336130319780551
Validation loss: 3.2540629069905136

Epoch: 5| Step: 7
Training loss: 4.339582241361605
Validation loss: 3.247574051457131

Epoch: 5| Step: 8
Training loss: 2.947626717442502
Validation loss: 3.247864989806427

Epoch: 5| Step: 9
Training loss: 3.5927125179583093
Validation loss: 3.2467368540374664

Epoch: 5| Step: 10
Training loss: 3.2224181671050958
Validation loss: 3.2467651565265667

Epoch: 163| Step: 0
Training loss: 3.049735736342321
Validation loss: 3.2447607091304125

Epoch: 5| Step: 1
Training loss: 3.806701503088752
Validation loss: 3.246694173221519

Epoch: 5| Step: 2
Training loss: 3.182764762179585
Validation loss: 3.2457797160664397

Epoch: 5| Step: 3
Training loss: 4.096585987642685
Validation loss: 3.2451406693572484

Epoch: 5| Step: 4
Training loss: 3.5410903611373357
Validation loss: 3.245378861881473

Epoch: 5| Step: 5
Training loss: 3.4196193001322404
Validation loss: 3.2460733156405226

Epoch: 5| Step: 6
Training loss: 3.028677566550131
Validation loss: 3.247241427890289

Epoch: 5| Step: 7
Training loss: 3.8540520040965665
Validation loss: 3.2476982511851404

Epoch: 5| Step: 8
Training loss: 3.899050005114427
Validation loss: 3.2461636052534453

Epoch: 5| Step: 9
Training loss: 3.4297214237003932
Validation loss: 3.247740969324919

Epoch: 5| Step: 10
Training loss: 2.5567174656615363
Validation loss: 3.248247079328244

Epoch: 164| Step: 0
Training loss: 2.8736076300466635
Validation loss: 3.2459432021268

Epoch: 5| Step: 1
Training loss: 2.9908002620670886
Validation loss: 3.245696226731046

Epoch: 5| Step: 2
Training loss: 3.575768506871479
Validation loss: 3.245071981049379

Epoch: 5| Step: 3
Training loss: 3.741636996303807
Validation loss: 3.2442049180622976

Epoch: 5| Step: 4
Training loss: 3.9406283833113327
Validation loss: 3.2432613195246116

Epoch: 5| Step: 5
Training loss: 3.641775317866317
Validation loss: 3.2424651012142363

Epoch: 5| Step: 6
Training loss: 4.588098072284248
Validation loss: 3.2424783239436197

Epoch: 5| Step: 7
Training loss: 3.099419841007358
Validation loss: 3.242605668622687

Epoch: 5| Step: 8
Training loss: 2.564505931720207
Validation loss: 3.242257969971693

Epoch: 5| Step: 9
Training loss: 3.0430168569187552
Validation loss: 3.242519849003836

Epoch: 5| Step: 10
Training loss: 3.7807069498829917
Validation loss: 3.2423202880835724

Epoch: 165| Step: 0
Training loss: 3.479367339843738
Validation loss: 3.2423549806026277

Epoch: 5| Step: 1
Training loss: 3.6422487493509332
Validation loss: 3.242406430039

Epoch: 5| Step: 2
Training loss: 3.1718016366977606
Validation loss: 3.242063219634115

Epoch: 5| Step: 3
Training loss: 3.362367796160211
Validation loss: 3.241223360160369

Epoch: 5| Step: 4
Training loss: 3.794899257684789
Validation loss: 3.240802681157301

Epoch: 5| Step: 5
Training loss: 3.2501100374813934
Validation loss: 3.240522130639815

Epoch: 5| Step: 6
Training loss: 3.5087393235063535
Validation loss: 3.2399018382373295

Epoch: 5| Step: 7
Training loss: 3.470951653181465
Validation loss: 3.238670463975845

Epoch: 5| Step: 8
Training loss: 3.559130363329822
Validation loss: 3.2395200211114794

Epoch: 5| Step: 9
Training loss: 3.5730875194986575
Validation loss: 3.239750682944

Epoch: 5| Step: 10
Training loss: 3.3933042848264265
Validation loss: 3.23992406180074

Epoch: 166| Step: 0
Training loss: 3.7453539996022305
Validation loss: 3.2395655780536883

Epoch: 5| Step: 1
Training loss: 4.015170416724774
Validation loss: 3.2391752607171522

Epoch: 5| Step: 2
Training loss: 3.4802795427229127
Validation loss: 3.238765666515955

Epoch: 5| Step: 3
Training loss: 3.609270631016056
Validation loss: 3.238098208233126

Epoch: 5| Step: 4
Training loss: 3.498166285126886
Validation loss: 3.240206669785644

Epoch: 5| Step: 5
Training loss: 3.0861491842941953
Validation loss: 3.238493720138492

Epoch: 5| Step: 6
Training loss: 3.417625401281405
Validation loss: 3.236557487164676

Epoch: 5| Step: 7
Training loss: 3.5161504056178767
Validation loss: 3.2370769827925967

Epoch: 5| Step: 8
Training loss: 3.5051509555845874
Validation loss: 3.2375257848245815

Epoch: 5| Step: 9
Training loss: 2.9932903916550453
Validation loss: 3.2380439612680454

Epoch: 5| Step: 10
Training loss: 3.1894045357118674
Validation loss: 3.236591610166299

Epoch: 167| Step: 0
Training loss: 3.928251151864094
Validation loss: 3.2361527140293638

Epoch: 5| Step: 1
Training loss: 3.3188780794016246
Validation loss: 3.2395144720599482

Epoch: 5| Step: 2
Training loss: 3.6103437700669896
Validation loss: 3.236663042352883

Epoch: 5| Step: 3
Training loss: 3.0392548566413717
Validation loss: 3.238133069492171

Epoch: 5| Step: 4
Training loss: 3.634319690076834
Validation loss: 3.238517297517774

Epoch: 5| Step: 5
Training loss: 3.158284202200251
Validation loss: 3.2413860731578192

Epoch: 5| Step: 6
Training loss: 3.189647474750712
Validation loss: 3.2348293591464192

Epoch: 5| Step: 7
Training loss: 3.8129269720407986
Validation loss: 3.234367950401651

Epoch: 5| Step: 8
Training loss: 4.21255105550825
Validation loss: 3.240426251852464

Epoch: 5| Step: 9
Training loss: 2.8330349110540407
Validation loss: 3.239066735470906

Epoch: 5| Step: 10
Training loss: 3.1584785072425126
Validation loss: 3.2367041390663203

Epoch: 168| Step: 0
Training loss: 3.4157254077780217
Validation loss: 3.236059907107938

Epoch: 5| Step: 1
Training loss: 3.3213146178449353
Validation loss: 3.23657386276518

Epoch: 5| Step: 2
Training loss: 3.036187466840819
Validation loss: 3.2366089756894425

Epoch: 5| Step: 3
Training loss: 4.310312352025255
Validation loss: 3.237866078715119

Epoch: 5| Step: 4
Training loss: 3.31854473851394
Validation loss: 3.2354435268584223

Epoch: 5| Step: 5
Training loss: 3.9706367153125193
Validation loss: 3.2354261519104957

Epoch: 5| Step: 6
Training loss: 3.7466148356136677
Validation loss: 3.234315593931474

Epoch: 5| Step: 7
Training loss: 3.0075712032879087
Validation loss: 3.2340283403516468

Epoch: 5| Step: 8
Training loss: 3.056602248660848
Validation loss: 3.2334359943895543

Epoch: 5| Step: 9
Training loss: 3.326317381350157
Validation loss: 3.232470962889768

Epoch: 5| Step: 10
Training loss: 3.452866074188476
Validation loss: 3.2323124805737464

Epoch: 169| Step: 0
Training loss: 3.3270902502616653
Validation loss: 3.2328594791273955

Epoch: 5| Step: 1
Training loss: 3.1934852505294464
Validation loss: 3.2338073709536728

Epoch: 5| Step: 2
Training loss: 4.0108210107986695
Validation loss: 3.232104253720899

Epoch: 5| Step: 3
Training loss: 3.2444896935075715
Validation loss: 3.231783039495386

Epoch: 5| Step: 4
Training loss: 2.696501980795505
Validation loss: 3.232584648766547

Epoch: 5| Step: 5
Training loss: 2.7145416311211443
Validation loss: 3.2358983055986066

Epoch: 5| Step: 6
Training loss: 4.167648632051322
Validation loss: 3.2362561118953845

Epoch: 5| Step: 7
Training loss: 3.1565066695895916
Validation loss: 3.248906293084924

Epoch: 5| Step: 8
Training loss: 4.084829614230552
Validation loss: 3.242012929534682

Epoch: 5| Step: 9
Training loss: 3.1545057859417596
Validation loss: 3.2386651667721456

Epoch: 5| Step: 10
Training loss: 4.108120222670706
Validation loss: 3.2325233627193417

Epoch: 170| Step: 0
Training loss: 2.7426785195180607
Validation loss: 3.23120900224482

Epoch: 5| Step: 1
Training loss: 3.8688120502678665
Validation loss: 3.2298794555470014

Epoch: 5| Step: 2
Training loss: 3.593724524366225
Validation loss: 3.2307639441153366

Epoch: 5| Step: 3
Training loss: 3.511419603889931
Validation loss: 3.2301509620669093

Epoch: 5| Step: 4
Training loss: 3.381712419687004
Validation loss: 3.2300174784462845

Epoch: 5| Step: 5
Training loss: 3.3919031221662466
Validation loss: 3.2299364834926143

Epoch: 5| Step: 6
Training loss: 3.1869148764516027
Validation loss: 3.2313630181073716

Epoch: 5| Step: 7
Training loss: 3.1935077971050734
Validation loss: 3.2331053362189373

Epoch: 5| Step: 8
Training loss: 4.066667971584757
Validation loss: 3.234010794501771

Epoch: 5| Step: 9
Training loss: 3.3623597126451594
Validation loss: 3.2321767099069376

Epoch: 5| Step: 10
Training loss: 3.7458086114109346
Validation loss: 3.232834039755317

Epoch: 171| Step: 0
Training loss: 4.375019182435626
Validation loss: 3.2305060481209904

Epoch: 5| Step: 1
Training loss: 2.5509587411628183
Validation loss: 3.2298616363398693

Epoch: 5| Step: 2
Training loss: 4.104468836367373
Validation loss: 3.2292614581868784

Epoch: 5| Step: 3
Training loss: 3.5108890083607487
Validation loss: 3.2287212057955528

Epoch: 5| Step: 4
Training loss: 2.652401818158075
Validation loss: 3.2275044275710667

Epoch: 5| Step: 5
Training loss: 3.585045265114163
Validation loss: 3.228995148664937

Epoch: 5| Step: 6
Training loss: 3.734977003279519
Validation loss: 3.2288503618299065

Epoch: 5| Step: 7
Training loss: 3.3790081383662733
Validation loss: 3.226844858471288

Epoch: 5| Step: 8
Training loss: 3.682282846629988
Validation loss: 3.227022205361357

Epoch: 5| Step: 9
Training loss: 3.182424955599497
Validation loss: 3.227065039110127

Epoch: 5| Step: 10
Training loss: 2.806680040607015
Validation loss: 3.228118603084381

Epoch: 172| Step: 0
Training loss: 3.2812613350808677
Validation loss: 3.22596391967753

Epoch: 5| Step: 1
Training loss: 2.6928442226532168
Validation loss: 3.22580134111943

Epoch: 5| Step: 2
Training loss: 3.3859507604039196
Validation loss: 3.2266930065077433

Epoch: 5| Step: 3
Training loss: 3.5524347901449818
Validation loss: 3.2267082253155035

Epoch: 5| Step: 4
Training loss: 3.2678734736514694
Validation loss: 3.229824621286002

Epoch: 5| Step: 5
Training loss: 3.691986974823398
Validation loss: 3.238547296207494

Epoch: 5| Step: 6
Training loss: 3.5242801174671845
Validation loss: 3.231188484860377

Epoch: 5| Step: 7
Training loss: 4.083212532799719
Validation loss: 3.233299072848659

Epoch: 5| Step: 8
Training loss: 3.968466801188619
Validation loss: 3.2264328757529883

Epoch: 5| Step: 9
Training loss: 3.1493273062178617
Validation loss: 3.224147332998602

Epoch: 5| Step: 10
Training loss: 3.29214615689513
Validation loss: 3.224750609444124

Epoch: 173| Step: 0
Training loss: 3.1614756617733675
Validation loss: 3.2253227153185944

Epoch: 5| Step: 1
Training loss: 3.0933068468615157
Validation loss: 3.226349910005588

Epoch: 5| Step: 2
Training loss: 3.228665680118431
Validation loss: 3.227404957712372

Epoch: 5| Step: 3
Training loss: 3.4698543680725744
Validation loss: 3.228890527409385

Epoch: 5| Step: 4
Training loss: 3.56659035348507
Validation loss: 3.230931555871725

Epoch: 5| Step: 5
Training loss: 3.7954709317970297
Validation loss: 3.230434770243334

Epoch: 5| Step: 6
Training loss: 3.712079131549035
Validation loss: 3.2291777124655945

Epoch: 5| Step: 7
Training loss: 3.851287770096925
Validation loss: 3.227128167764697

Epoch: 5| Step: 8
Training loss: 3.0319103033038877
Validation loss: 3.225904825207746

Epoch: 5| Step: 9
Training loss: 3.674011647712132
Validation loss: 3.22539577372071

Epoch: 5| Step: 10
Training loss: 3.4461946979854954
Validation loss: 3.225085080458482

Epoch: 174| Step: 0
Training loss: 3.7122431656592605
Validation loss: 3.223127853177632

Epoch: 5| Step: 1
Training loss: 3.708477417507696
Validation loss: 3.2224849365282497

Epoch: 5| Step: 2
Training loss: 3.339973955795258
Validation loss: 3.222586255498914

Epoch: 5| Step: 3
Training loss: 3.4553690389468534
Validation loss: 3.2230502859030765

Epoch: 5| Step: 4
Training loss: 2.71306849556385
Validation loss: 3.221938846967207

Epoch: 5| Step: 5
Training loss: 3.0069604236470893
Validation loss: 3.2215885143397434

Epoch: 5| Step: 6
Training loss: 3.504772746817679
Validation loss: 3.2236265108181916

Epoch: 5| Step: 7
Training loss: 2.966660898895943
Validation loss: 3.222745568115046

Epoch: 5| Step: 8
Training loss: 3.4996006601580434
Validation loss: 3.2373936877871743

Epoch: 5| Step: 9
Training loss: 4.197097256613161
Validation loss: 3.2360378415936664

Epoch: 5| Step: 10
Training loss: 3.7731665598899653
Validation loss: 3.2269003709898016

Epoch: 175| Step: 0
Training loss: 3.1764457354684934
Validation loss: 3.2265289224644707

Epoch: 5| Step: 1
Training loss: 3.7450419392293743
Validation loss: 3.2233348703941185

Epoch: 5| Step: 2
Training loss: 3.4428693971263193
Validation loss: 3.2206249930664588

Epoch: 5| Step: 3
Training loss: 3.2604741263074475
Validation loss: 3.220972862851466

Epoch: 5| Step: 4
Training loss: 3.129105731829661
Validation loss: 3.2203422946274762

Epoch: 5| Step: 5
Training loss: 3.5871287509345477
Validation loss: 3.2207510526653027

Epoch: 5| Step: 6
Training loss: 4.113573837379873
Validation loss: 3.2220472807654432

Epoch: 5| Step: 7
Training loss: 2.599793070114576
Validation loss: 3.2191079316331375

Epoch: 5| Step: 8
Training loss: 3.8178503297191626
Validation loss: 3.2236555426689044

Epoch: 5| Step: 9
Training loss: 3.6832864254917665
Validation loss: 3.22253110342448

Epoch: 5| Step: 10
Training loss: 3.207794656160414
Validation loss: 3.2225960233100266

Epoch: 176| Step: 0
Training loss: 3.403244232246826
Validation loss: 3.219464152847589

Epoch: 5| Step: 1
Training loss: 3.381040747860973
Validation loss: 3.221420438744007

Epoch: 5| Step: 2
Training loss: 3.6237082975263784
Validation loss: 3.2219843405935924

Epoch: 5| Step: 3
Training loss: 4.1080728650785785
Validation loss: 3.2201123936947535

Epoch: 5| Step: 4
Training loss: 3.122344147310345
Validation loss: 3.2230861331606118

Epoch: 5| Step: 5
Training loss: 3.3704670735771005
Validation loss: 3.220501367593844

Epoch: 5| Step: 6
Training loss: 3.503825277117967
Validation loss: 3.217253951699861

Epoch: 5| Step: 7
Training loss: 3.573905756018935
Validation loss: 3.218034756588292

Epoch: 5| Step: 8
Training loss: 3.6892557651769162
Validation loss: 3.216179274824029

Epoch: 5| Step: 9
Training loss: 3.0944815647342256
Validation loss: 3.2158316215093894

Epoch: 5| Step: 10
Training loss: 2.940774269653098
Validation loss: 3.2170186948458754

Epoch: 177| Step: 0
Training loss: 3.551874074430679
Validation loss: 3.2172132997902163

Epoch: 5| Step: 1
Training loss: 2.964846644946709
Validation loss: 3.2162915629922026

Epoch: 5| Step: 2
Training loss: 4.0939004884971
Validation loss: 3.2177034614716336

Epoch: 5| Step: 3
Training loss: 3.1984837098690004
Validation loss: 3.2161855496481824

Epoch: 5| Step: 4
Training loss: 3.883243774778435
Validation loss: 3.215764315337267

Epoch: 5| Step: 5
Training loss: 3.381271046345587
Validation loss: 3.215847224146188

Epoch: 5| Step: 6
Training loss: 3.2537274626377433
Validation loss: 3.215639884336519

Epoch: 5| Step: 7
Training loss: 3.3538235948970954
Validation loss: 3.2160817281109884

Epoch: 5| Step: 8
Training loss: 3.2327944814512657
Validation loss: 3.2157741584785478

Epoch: 5| Step: 9
Training loss: 3.5785834006312385
Validation loss: 3.2158884943977992

Epoch: 5| Step: 10
Training loss: 3.3696123141278393
Validation loss: 3.214713557531022

Epoch: 178| Step: 0
Training loss: 3.610619004455734
Validation loss: 3.215971666256448

Epoch: 5| Step: 1
Training loss: 2.8603122196637063
Validation loss: 3.21464784844408

Epoch: 5| Step: 2
Training loss: 2.766419635989174
Validation loss: 3.2144077320186186

Epoch: 5| Step: 3
Training loss: 3.6026344938142847
Validation loss: 3.213696831836427

Epoch: 5| Step: 4
Training loss: 4.095674251805714
Validation loss: 3.2144376797618595

Epoch: 5| Step: 5
Training loss: 3.3135954287182026
Validation loss: 3.2143805897909576

Epoch: 5| Step: 6
Training loss: 3.7658906581764717
Validation loss: 3.213167454196004

Epoch: 5| Step: 7
Training loss: 3.2167784939896826
Validation loss: 3.2133181470575005

Epoch: 5| Step: 8
Training loss: 3.832029881219493
Validation loss: 3.212816305554258

Epoch: 5| Step: 9
Training loss: 3.5217104991009043
Validation loss: 3.2124186553430474

Epoch: 5| Step: 10
Training loss: 3.1306112646836186
Validation loss: 3.212826204805787

Epoch: 179| Step: 0
Training loss: 3.879768391018249
Validation loss: 3.2122644654029946

Epoch: 5| Step: 1
Training loss: 3.604800806137381
Validation loss: 3.2116086361393967

Epoch: 5| Step: 2
Training loss: 2.6721874745895033
Validation loss: 3.2130675061857774

Epoch: 5| Step: 3
Training loss: 3.525397928922489
Validation loss: 3.2109500701229505

Epoch: 5| Step: 4
Training loss: 4.321670291269952
Validation loss: 3.2119012439282817

Epoch: 5| Step: 5
Training loss: 3.077475852096854
Validation loss: 3.2115450395761687

Epoch: 5| Step: 6
Training loss: 3.1702314356126555
Validation loss: 3.2109891023404855

Epoch: 5| Step: 7
Training loss: 3.410856719028118
Validation loss: 3.2102424307003914

Epoch: 5| Step: 8
Training loss: 3.8046827375002277
Validation loss: 3.21248938490621

Epoch: 5| Step: 9
Training loss: 2.5870147028838106
Validation loss: 3.213187164337139

Epoch: 5| Step: 10
Training loss: 3.539556809824239
Validation loss: 3.2103142575230534

Epoch: 180| Step: 0
Training loss: 2.8455265071521074
Validation loss: 3.211724139667831

Epoch: 5| Step: 1
Training loss: 3.6102622787005796
Validation loss: 3.210757982352429

Epoch: 5| Step: 2
Training loss: 3.280304400112505
Validation loss: 3.2105932108772857

Epoch: 5| Step: 3
Training loss: 2.8270296958008667
Validation loss: 3.2100759253066395

Epoch: 5| Step: 4
Training loss: 4.322130369198126
Validation loss: 3.2093985144665003

Epoch: 5| Step: 5
Training loss: 3.6863728756506062
Validation loss: 3.2086326535140355

Epoch: 5| Step: 6
Training loss: 2.6481326667651253
Validation loss: 3.2079179993304243

Epoch: 5| Step: 7
Training loss: 3.0913586863265894
Validation loss: 3.2076584135781165

Epoch: 5| Step: 8
Training loss: 3.875257914173867
Validation loss: 3.208368312121367

Epoch: 5| Step: 9
Training loss: 2.939701797257558
Validation loss: 3.207979364662801

Epoch: 5| Step: 10
Training loss: 4.451904986386446
Validation loss: 3.2087392503612904

Epoch: 181| Step: 0
Training loss: 3.0686505893990823
Validation loss: 3.2067186503183156

Epoch: 5| Step: 1
Training loss: 3.621181844979169
Validation loss: 3.2075629431386217

Epoch: 5| Step: 2
Training loss: 3.6474601531123656
Validation loss: 3.206981040470918

Epoch: 5| Step: 3
Training loss: 3.931453482451519
Validation loss: 3.207505460654289

Epoch: 5| Step: 4
Training loss: 2.8646951179656943
Validation loss: 3.210544824947227

Epoch: 5| Step: 5
Training loss: 4.008626457382766
Validation loss: 3.209393783220253

Epoch: 5| Step: 6
Training loss: 3.6710637921241203
Validation loss: 3.2077124695013617

Epoch: 5| Step: 7
Training loss: 3.2869506725095134
Validation loss: 3.210080528566616

Epoch: 5| Step: 8
Training loss: 3.6562788220435167
Validation loss: 3.206401467592996

Epoch: 5| Step: 9
Training loss: 2.5344122454708655
Validation loss: 3.2069389920834284

Epoch: 5| Step: 10
Training loss: 3.3314896889174492
Validation loss: 3.2085747803085747

Epoch: 182| Step: 0
Training loss: 2.9807327173613927
Validation loss: 3.208365197430323

Epoch: 5| Step: 1
Training loss: 3.261287016477577
Validation loss: 3.207563908630952

Epoch: 5| Step: 2
Training loss: 3.234545127338021
Validation loss: 3.2049241258412864

Epoch: 5| Step: 3
Training loss: 4.29596625688823
Validation loss: 3.205292914456654

Epoch: 5| Step: 4
Training loss: 3.807347176804243
Validation loss: 3.205038636854746

Epoch: 5| Step: 5
Training loss: 3.609841056558208
Validation loss: 3.2051226213688957

Epoch: 5| Step: 6
Training loss: 3.2685775915596524
Validation loss: 3.206306409080737

Epoch: 5| Step: 7
Training loss: 3.278941768574749
Validation loss: 3.2032957674291946

Epoch: 5| Step: 8
Training loss: 3.376547282130359
Validation loss: 3.2040835327217643

Epoch: 5| Step: 9
Training loss: 3.310073539631492
Validation loss: 3.2062096310392763

Epoch: 5| Step: 10
Training loss: 3.317966772500588
Validation loss: 3.2052419234596257

Epoch: 183| Step: 0
Training loss: 2.824852161421323
Validation loss: 3.204948860464235

Epoch: 5| Step: 1
Training loss: 3.404833297793976
Validation loss: 3.203651397374448

Epoch: 5| Step: 2
Training loss: 4.135032245182759
Validation loss: 3.2034294634008043

Epoch: 5| Step: 3
Training loss: 3.3207506317089823
Validation loss: 3.2036246137453603

Epoch: 5| Step: 4
Training loss: 3.3768270280372246
Validation loss: 3.203053604238696

Epoch: 5| Step: 5
Training loss: 3.550810390978125
Validation loss: 3.2031558743881496

Epoch: 5| Step: 6
Training loss: 3.539284941227908
Validation loss: 3.202799254510549

Epoch: 5| Step: 7
Training loss: 3.3724033115063485
Validation loss: 3.202798422055438

Epoch: 5| Step: 8
Training loss: 2.982308835908316
Validation loss: 3.2030451474764745

Epoch: 5| Step: 9
Training loss: 3.4546560630247907
Validation loss: 3.2023488422711126

Epoch: 5| Step: 10
Training loss: 3.828031079444161
Validation loss: 3.20193327057212

Epoch: 184| Step: 0
Training loss: 3.1135918475476574
Validation loss: 3.201483264203772

Epoch: 5| Step: 1
Training loss: 3.068636915061717
Validation loss: 3.201617441835144

Epoch: 5| Step: 2
Training loss: 3.8870936534012785
Validation loss: 3.2016853272564387

Epoch: 5| Step: 3
Training loss: 4.033821882394144
Validation loss: 3.2008639034721647

Epoch: 5| Step: 4
Training loss: 3.6566975637525596
Validation loss: 3.2010571215478576

Epoch: 5| Step: 5
Training loss: 3.668263058946142
Validation loss: 3.2011458042045695

Epoch: 5| Step: 6
Training loss: 3.606434999477537
Validation loss: 3.200884658483951

Epoch: 5| Step: 7
Training loss: 2.3115078627815495
Validation loss: 3.200616194504887

Epoch: 5| Step: 8
Training loss: 3.5231804933723443
Validation loss: 3.20008223841984

Epoch: 5| Step: 9
Training loss: 3.890739960101907
Validation loss: 3.1997507350113725

Epoch: 5| Step: 10
Training loss: 2.5072245161073874
Validation loss: 3.2002487975481393

Epoch: 185| Step: 0
Training loss: 3.088863328176928
Validation loss: 3.1993227181057162

Epoch: 5| Step: 1
Training loss: 3.6224826095721747
Validation loss: 3.199212413049698

Epoch: 5| Step: 2
Training loss: 2.808876925267255
Validation loss: 3.1993369797411795

Epoch: 5| Step: 3
Training loss: 3.1303418089241055
Validation loss: 3.1998327672365305

Epoch: 5| Step: 4
Training loss: 3.86498714232681
Validation loss: 3.1991469337003036

Epoch: 5| Step: 5
Training loss: 3.114109747528709
Validation loss: 3.199573156898995

Epoch: 5| Step: 6
Training loss: 3.5073365566159334
Validation loss: 3.198502731425516

Epoch: 5| Step: 7
Training loss: 3.694744687480322
Validation loss: 3.1979476950186556

Epoch: 5| Step: 8
Training loss: 3.5019479507944204
Validation loss: 3.19803449108983

Epoch: 5| Step: 9
Training loss: 3.373669114671456
Validation loss: 3.1988475845236275

Epoch: 5| Step: 10
Training loss: 4.0405343950561585
Validation loss: 3.1973679431748785

Epoch: 186| Step: 0
Training loss: 3.3113283208424207
Validation loss: 3.1960474087750397

Epoch: 5| Step: 1
Training loss: 2.7213097284269216
Validation loss: 3.1972185849146437

Epoch: 5| Step: 2
Training loss: 3.6131235449114465
Validation loss: 3.196462482505951

Epoch: 5| Step: 3
Training loss: 3.4671321910900894
Validation loss: 3.197336300092155

Epoch: 5| Step: 4
Training loss: 2.3882686995256694
Validation loss: 3.1978383478390158

Epoch: 5| Step: 5
Training loss: 3.985271397901177
Validation loss: 3.1954455720661215

Epoch: 5| Step: 6
Training loss: 4.010129024874709
Validation loss: 3.1958898869138235

Epoch: 5| Step: 7
Training loss: 4.276334516352989
Validation loss: 3.1963917704479794

Epoch: 5| Step: 8
Training loss: 3.176466151257244
Validation loss: 3.1957271774297777

Epoch: 5| Step: 9
Training loss: 3.5529348894590442
Validation loss: 3.1964006041270054

Epoch: 5| Step: 10
Training loss: 2.7305661949484246
Validation loss: 3.1962637844302826

Epoch: 187| Step: 0
Training loss: 3.2682176729078685
Validation loss: 3.19418720875946

Epoch: 5| Step: 1
Training loss: 4.260459595007721
Validation loss: 3.1964422249115914

Epoch: 5| Step: 2
Training loss: 3.518542897175292
Validation loss: 3.198725614730119

Epoch: 5| Step: 3
Training loss: 3.1846537130197667
Validation loss: 3.2107272161985216

Epoch: 5| Step: 4
Training loss: 2.8130619759185693
Validation loss: 3.210849533311229

Epoch: 5| Step: 5
Training loss: 3.4232740633946257
Validation loss: 3.2129728084640305

Epoch: 5| Step: 6
Training loss: 3.691079293762766
Validation loss: 3.1949857461532316

Epoch: 5| Step: 7
Training loss: 3.134247486871444
Validation loss: 3.1917513308855208

Epoch: 5| Step: 8
Training loss: 3.0676912178809914
Validation loss: 3.193161479368316

Epoch: 5| Step: 9
Training loss: 3.269589294866328
Validation loss: 3.194556334861681

Epoch: 5| Step: 10
Training loss: 4.055451602271226
Validation loss: 3.1951559681163304

Epoch: 188| Step: 0
Training loss: 3.360164389903097
Validation loss: 3.197290149459632

Epoch: 5| Step: 1
Training loss: 3.1405074823512362
Validation loss: 3.200028918825244

Epoch: 5| Step: 2
Training loss: 4.002451145653104
Validation loss: 3.195667779729837

Epoch: 5| Step: 3
Training loss: 4.095787182092255
Validation loss: 3.1949241954435457

Epoch: 5| Step: 4
Training loss: 3.3730911225474327
Validation loss: 3.1923436973373125

Epoch: 5| Step: 5
Training loss: 3.2137686692017935
Validation loss: 3.193350581879263

Epoch: 5| Step: 6
Training loss: 2.6478516597456556
Validation loss: 3.190340279469174

Epoch: 5| Step: 7
Training loss: 3.58587553348897
Validation loss: 3.1911436581321744

Epoch: 5| Step: 8
Training loss: 2.9516407299427936
Validation loss: 3.1903185229163302

Epoch: 5| Step: 9
Training loss: 3.309986816564392
Validation loss: 3.191764441624989

Epoch: 5| Step: 10
Training loss: 3.9552517323008836
Validation loss: 3.1917054416684376

Epoch: 189| Step: 0
Training loss: 3.6605359901312795
Validation loss: 3.191004316126374

Epoch: 5| Step: 1
Training loss: 3.0952570163581656
Validation loss: 3.188795051434134

Epoch: 5| Step: 2
Training loss: 4.103270663648714
Validation loss: 3.189641456355469

Epoch: 5| Step: 3
Training loss: 3.352084317077783
Validation loss: 3.1909032930830556

Epoch: 5| Step: 4
Training loss: 3.817394429304082
Validation loss: 3.1886643581925345

Epoch: 5| Step: 5
Training loss: 2.926540953500335
Validation loss: 3.188663080658957

Epoch: 5| Step: 6
Training loss: 2.816631334598606
Validation loss: 3.1882952414522334

Epoch: 5| Step: 7
Training loss: 3.4200320223374336
Validation loss: 3.190081544067183

Epoch: 5| Step: 8
Training loss: 3.7307186342600454
Validation loss: 3.188098081665236

Epoch: 5| Step: 9
Training loss: 3.197271292278881
Validation loss: 3.1879342587830237

Epoch: 5| Step: 10
Training loss: 3.4560236437659873
Validation loss: 3.18505069569909

Epoch: 190| Step: 0
Training loss: 3.6427284025636264
Validation loss: 3.1861434195579355

Epoch: 5| Step: 1
Training loss: 3.184633349719172
Validation loss: 3.1872657224909795

Epoch: 5| Step: 2
Training loss: 3.5151902671748676
Validation loss: 3.1856755040260296

Epoch: 5| Step: 3
Training loss: 3.16813070351288
Validation loss: 3.1859727836591576

Epoch: 5| Step: 4
Training loss: 4.258492679687744
Validation loss: 3.1879595176581503

Epoch: 5| Step: 5
Training loss: 3.699910245270699
Validation loss: 3.1880114372466055

Epoch: 5| Step: 6
Training loss: 3.4812397215330195
Validation loss: 3.188920304816796

Epoch: 5| Step: 7
Training loss: 3.613621579200508
Validation loss: 3.1854249898677214

Epoch: 5| Step: 8
Training loss: 3.2400180406421386
Validation loss: 3.1863856498063416

Epoch: 5| Step: 9
Training loss: 2.8029359751645386
Validation loss: 3.1858236041358805

Epoch: 5| Step: 10
Training loss: 2.814217699887416
Validation loss: 3.184980615687027

Epoch: 191| Step: 0
Training loss: 2.8748694680477214
Validation loss: 3.1854437465588803

Epoch: 5| Step: 1
Training loss: 3.3768371950441285
Validation loss: 3.1847474118265593

Epoch: 5| Step: 2
Training loss: 3.6281037033468007
Validation loss: 3.182956793142033

Epoch: 5| Step: 3
Training loss: 3.9527795210943415
Validation loss: 3.184516129408536

Epoch: 5| Step: 4
Training loss: 3.8951130301415033
Validation loss: 3.184652664911885

Epoch: 5| Step: 5
Training loss: 3.4240292252336144
Validation loss: 3.1843038222436406

Epoch: 5| Step: 6
Training loss: 3.1250112914835064
Validation loss: 3.1835461922299415

Epoch: 5| Step: 7
Training loss: 2.7736126911547454
Validation loss: 3.1841505316577012

Epoch: 5| Step: 8
Training loss: 3.925440410032959
Validation loss: 3.183683463450075

Epoch: 5| Step: 9
Training loss: 3.5610110199566822
Validation loss: 3.1834669872931096

Epoch: 5| Step: 10
Training loss: 2.8351403999884175
Validation loss: 3.183747056120596

Epoch: 192| Step: 0
Training loss: 3.314481322618711
Validation loss: 3.183223533078964

Epoch: 5| Step: 1
Training loss: 2.579123009069293
Validation loss: 3.184481596524891

Epoch: 5| Step: 2
Training loss: 3.1572712671788628
Validation loss: 3.1877606820357345

Epoch: 5| Step: 3
Training loss: 3.496286738519422
Validation loss: 3.1947439352648135

Epoch: 5| Step: 4
Training loss: 3.62135750181404
Validation loss: 3.1916041283553076

Epoch: 5| Step: 5
Training loss: 3.9721123577180473
Validation loss: 3.190721073467656

Epoch: 5| Step: 6
Training loss: 3.12873114049442
Validation loss: 3.192053316432722

Epoch: 5| Step: 7
Training loss: 3.021555233342129
Validation loss: 3.1947259361316735

Epoch: 5| Step: 8
Training loss: 3.7230218025366284
Validation loss: 3.1956604072849393

Epoch: 5| Step: 9
Training loss: 4.166234693387513
Validation loss: 3.1926496401610844

Epoch: 5| Step: 10
Training loss: 3.2636943750159486
Validation loss: 3.1839988093977096

Epoch: 193| Step: 0
Training loss: 3.586743100166132
Validation loss: 3.1806537455810457

Epoch: 5| Step: 1
Training loss: 2.5989218016804583
Validation loss: 3.182348809745343

Epoch: 5| Step: 2
Training loss: 3.133866358796648
Validation loss: 3.1824966369218806

Epoch: 5| Step: 3
Training loss: 4.269215843507685
Validation loss: 3.18311834650395

Epoch: 5| Step: 4
Training loss: 3.2823565842384874
Validation loss: 3.1857224312911403

Epoch: 5| Step: 5
Training loss: 3.6459521174381004
Validation loss: 3.185407710693387

Epoch: 5| Step: 6
Training loss: 3.2419090794893206
Validation loss: 3.1845180003047235

Epoch: 5| Step: 7
Training loss: 3.5433555316199805
Validation loss: 3.185065380222636

Epoch: 5| Step: 8
Training loss: 2.5823328993319996
Validation loss: 3.184473422120476

Epoch: 5| Step: 9
Training loss: 3.711076914527581
Validation loss: 3.1884363187822395

Epoch: 5| Step: 10
Training loss: 3.8808583920481894
Validation loss: 3.1836153471678625

Epoch: 194| Step: 0
Training loss: 3.427034016324882
Validation loss: 3.1827600743058015

Epoch: 5| Step: 1
Training loss: 3.5513115246662115
Validation loss: 3.1821659375398834

Epoch: 5| Step: 2
Training loss: 3.2809221376378606
Validation loss: 3.1799829708615204

Epoch: 5| Step: 3
Training loss: 3.585362739460366
Validation loss: 3.1804051847679147

Epoch: 5| Step: 4
Training loss: 3.05303223389928
Validation loss: 3.180369986563616

Epoch: 5| Step: 5
Training loss: 3.394103906770689
Validation loss: 3.1798724657642237

Epoch: 5| Step: 6
Training loss: 3.364052146970106
Validation loss: 3.1803840671818078

Epoch: 5| Step: 7
Training loss: 4.227441044175829
Validation loss: 3.182090930714355

Epoch: 5| Step: 8
Training loss: 2.976574674966898
Validation loss: 3.1790650968895577

Epoch: 5| Step: 9
Training loss: 3.439483902385721
Validation loss: 3.180341112556879

Epoch: 5| Step: 10
Training loss: 3.2026692880381016
Validation loss: 3.1807247688301756

Epoch: 195| Step: 0
Training loss: 2.992463340694076
Validation loss: 3.1835434945465253

Epoch: 5| Step: 1
Training loss: 2.9250867194989887
Validation loss: 3.182984042245417

Epoch: 5| Step: 2
Training loss: 3.285111253500553
Validation loss: 3.182035861475196

Epoch: 5| Step: 3
Training loss: 4.101669920468322
Validation loss: 3.1909948352341266

Epoch: 5| Step: 4
Training loss: 2.6131676619267274
Validation loss: 3.189494565571911

Epoch: 5| Step: 5
Training loss: 3.5822165471429837
Validation loss: 3.1827696900779494

Epoch: 5| Step: 6
Training loss: 3.6637453377107376
Validation loss: 3.1780995686154108

Epoch: 5| Step: 7
Training loss: 3.387306241620903
Validation loss: 3.1768433774602345

Epoch: 5| Step: 8
Training loss: 3.17320156074927
Validation loss: 3.1772256890245005

Epoch: 5| Step: 9
Training loss: 3.578634567291125
Validation loss: 3.1775855630520917

Epoch: 5| Step: 10
Training loss: 4.172476392968321
Validation loss: 3.1781990909542017

Epoch: 196| Step: 0
Training loss: 3.3609960149249374
Validation loss: 3.176823317554049

Epoch: 5| Step: 1
Training loss: 3.3757025376024306
Validation loss: 3.177057120815024

Epoch: 5| Step: 2
Training loss: 3.203845729223715
Validation loss: 3.176911926218257

Epoch: 5| Step: 3
Training loss: 2.8936451573669033
Validation loss: 3.1756252052756286

Epoch: 5| Step: 4
Training loss: 2.837110208634395
Validation loss: 3.1771046554896243

Epoch: 5| Step: 5
Training loss: 3.7342404137783505
Validation loss: 3.1759900408630743

Epoch: 5| Step: 6
Training loss: 3.850000525140107
Validation loss: 3.1750985328345998

Epoch: 5| Step: 7
Training loss: 4.041648051949857
Validation loss: 3.1748621580526284

Epoch: 5| Step: 8
Training loss: 2.906600930960904
Validation loss: 3.1765319044427556

Epoch: 5| Step: 9
Training loss: 3.6832250610824664
Validation loss: 3.174317620506068

Epoch: 5| Step: 10
Training loss: 3.539585100203072
Validation loss: 3.175046645934417

Epoch: 197| Step: 0
Training loss: 2.8199352741253385
Validation loss: 3.1742036326661967

Epoch: 5| Step: 1
Training loss: 3.52722992401823
Validation loss: 3.1744834672876396

Epoch: 5| Step: 2
Training loss: 3.4749276078182745
Validation loss: 3.174218190496077

Epoch: 5| Step: 3
Training loss: 3.830056960277448
Validation loss: 3.1754582830195015

Epoch: 5| Step: 4
Training loss: 3.8144128722114474
Validation loss: 3.1748260230755503

Epoch: 5| Step: 5
Training loss: 2.629039744010337
Validation loss: 3.1738023255516747

Epoch: 5| Step: 6
Training loss: 3.6916439242268817
Validation loss: 3.1734298741427387

Epoch: 5| Step: 7
Training loss: 3.6206352001160425
Validation loss: 3.1753304350010896

Epoch: 5| Step: 8
Training loss: 3.2089815517048597
Validation loss: 3.17458256677574

Epoch: 5| Step: 9
Training loss: 3.3951791862651586
Validation loss: 3.1729273836211824

Epoch: 5| Step: 10
Training loss: 3.425033713961435
Validation loss: 3.173199629859326

Epoch: 198| Step: 0
Training loss: 3.180186089642916
Validation loss: 3.172405040016061

Epoch: 5| Step: 1
Training loss: 3.4787741494856896
Validation loss: 3.173204688142163

Epoch: 5| Step: 2
Training loss: 3.0808254731002087
Validation loss: 3.1734082512798603

Epoch: 5| Step: 3
Training loss: 3.2142806643491766
Validation loss: 3.1725220783231167

Epoch: 5| Step: 4
Training loss: 3.614329055211789
Validation loss: 3.172080831387405

Epoch: 5| Step: 5
Training loss: 3.706449151437913
Validation loss: 3.1731062751802845

Epoch: 5| Step: 6
Training loss: 3.8931908170752663
Validation loss: 3.1729302826280885

Epoch: 5| Step: 7
Training loss: 3.347518081217359
Validation loss: 3.1714114542435428

Epoch: 5| Step: 8
Training loss: 3.7983037826997705
Validation loss: 3.1727205906576317

Epoch: 5| Step: 9
Training loss: 3.0793418996157285
Validation loss: 3.1715946555533234

Epoch: 5| Step: 10
Training loss: 3.0328204619171957
Validation loss: 3.1710779399040288

Epoch: 199| Step: 0
Training loss: 3.362762446602173
Validation loss: 3.1706614213267725

Epoch: 5| Step: 1
Training loss: 3.9545799261840853
Validation loss: 3.1719479389049408

Epoch: 5| Step: 2
Training loss: 3.921720585309867
Validation loss: 3.1725269041524893

Epoch: 5| Step: 3
Training loss: 3.068305604537611
Validation loss: 3.1728554578300128

Epoch: 5| Step: 4
Training loss: 4.08550287856366
Validation loss: 3.171084808441373

Epoch: 5| Step: 5
Training loss: 3.344729841467371
Validation loss: 3.1707229756970365

Epoch: 5| Step: 6
Training loss: 3.3378570537095404
Validation loss: 3.1708626130923463

Epoch: 5| Step: 7
Training loss: 3.4617690213357792
Validation loss: 3.174349132045172

Epoch: 5| Step: 8
Training loss: 2.9684788630296675
Validation loss: 3.171450075809441

Epoch: 5| Step: 9
Training loss: 2.256327632508938
Validation loss: 3.171166393820886

Epoch: 5| Step: 10
Training loss: 3.4425957103935
Validation loss: 3.167026363878472

Epoch: 200| Step: 0
Training loss: 3.7926103165235006
Validation loss: 3.167086470345386

Epoch: 5| Step: 1
Training loss: 3.9023392288746956
Validation loss: 3.169548074648714

Epoch: 5| Step: 2
Training loss: 3.278245113125087
Validation loss: 3.167203610486893

Epoch: 5| Step: 3
Training loss: 2.612975691421323
Validation loss: 3.1687357354547423

Epoch: 5| Step: 4
Training loss: 3.275809000281189
Validation loss: 3.168142805025118

Epoch: 5| Step: 5
Training loss: 4.14445163315964
Validation loss: 3.1648715657069775

Epoch: 5| Step: 6
Training loss: 3.548210799964039
Validation loss: 3.166988212913808

Epoch: 5| Step: 7
Training loss: 3.054783343984729
Validation loss: 3.1675402845423597

Epoch: 5| Step: 8
Training loss: 3.617636733038098
Validation loss: 3.167051746602842

Epoch: 5| Step: 9
Training loss: 2.830057232281404
Validation loss: 3.165526685736972

Epoch: 5| Step: 10
Training loss: 3.144608888793098
Validation loss: 3.1663382443021093

Epoch: 201| Step: 0
Training loss: 3.6200289348900125
Validation loss: 3.16646122603347

Epoch: 5| Step: 1
Training loss: 3.2617069084272323
Validation loss: 3.1682166681579913

Epoch: 5| Step: 2
Training loss: 3.251247020046888
Validation loss: 3.1659266141964992

Epoch: 5| Step: 3
Training loss: 2.558446422732347
Validation loss: 3.1671560073462848

Epoch: 5| Step: 4
Training loss: 3.5101180284441145
Validation loss: 3.1745576779242293

Epoch: 5| Step: 5
Training loss: 3.7645344401514547
Validation loss: 3.177000621981163

Epoch: 5| Step: 6
Training loss: 2.876763507838157
Validation loss: 3.1761128353234915

Epoch: 5| Step: 7
Training loss: 3.8631121499107537
Validation loss: 3.1797292218375235

Epoch: 5| Step: 8
Training loss: 3.434985819291741
Validation loss: 3.1783110512719

Epoch: 5| Step: 9
Training loss: 3.494815528814695
Validation loss: 3.181346763433272

Epoch: 5| Step: 10
Training loss: 3.7518932649522747
Validation loss: 3.165513706857585

Epoch: 202| Step: 0
Training loss: 2.9002929671059
Validation loss: 3.164892921263524

Epoch: 5| Step: 1
Training loss: 2.789559199879538
Validation loss: 3.1657916405277615

Epoch: 5| Step: 2
Training loss: 3.5314428226185157
Validation loss: 3.1655048080419403

Epoch: 5| Step: 3
Training loss: 3.435450549832828
Validation loss: 3.165840909660899

Epoch: 5| Step: 4
Training loss: 3.631492719564975
Validation loss: 3.168671961259865

Epoch: 5| Step: 5
Training loss: 3.522708250648846
Validation loss: 3.165658249178483

Epoch: 5| Step: 6
Training loss: 2.717865723370269
Validation loss: 3.1635696470889307

Epoch: 5| Step: 7
Training loss: 3.2915508072820243
Validation loss: 3.1645277460358416

Epoch: 5| Step: 8
Training loss: 3.661261881102159
Validation loss: 3.164385920374166

Epoch: 5| Step: 9
Training loss: 4.396704323824018
Validation loss: 3.16352574049206

Epoch: 5| Step: 10
Training loss: 3.318170695921617
Validation loss: 3.163877512614607

Epoch: 203| Step: 0
Training loss: 3.837061451260523
Validation loss: 3.1631619943245535

Epoch: 5| Step: 1
Training loss: 2.742448147724318
Validation loss: 3.1638384785427536

Epoch: 5| Step: 2
Training loss: 4.18169900852517
Validation loss: 3.163903882400677

Epoch: 5| Step: 3
Training loss: 2.860904805503382
Validation loss: 3.1626364134142517

Epoch: 5| Step: 4
Training loss: 3.654638734176574
Validation loss: 3.163180268697531

Epoch: 5| Step: 5
Training loss: 3.470907279360678
Validation loss: 3.163101391831999

Epoch: 5| Step: 6
Training loss: 4.129456395911261
Validation loss: 3.1641044149049447

Epoch: 5| Step: 7
Training loss: 3.1215537332642156
Validation loss: 3.162912940762235

Epoch: 5| Step: 8
Training loss: 3.081241946567743
Validation loss: 3.162016120165939

Epoch: 5| Step: 9
Training loss: 3.150621589003466
Validation loss: 3.1605375837539587

Epoch: 5| Step: 10
Training loss: 2.808764201842642
Validation loss: 3.161484636801903

Epoch: 204| Step: 0
Training loss: 3.684182177699882
Validation loss: 3.1603008580787733

Epoch: 5| Step: 1
Training loss: 2.647876961503173
Validation loss: 3.161153114707274

Epoch: 5| Step: 2
Training loss: 3.7313245500692136
Validation loss: 3.1603790179942743

Epoch: 5| Step: 3
Training loss: 3.54410232864656
Validation loss: 3.1631146075439527

Epoch: 5| Step: 4
Training loss: 2.931857106795201
Validation loss: 3.1667698329016023

Epoch: 5| Step: 5
Training loss: 3.24550141256252
Validation loss: 3.160326659046741

Epoch: 5| Step: 6
Training loss: 4.39891317990099
Validation loss: 3.160320729206997

Epoch: 5| Step: 7
Training loss: 3.440589487445162
Validation loss: 3.161564760588789

Epoch: 5| Step: 8
Training loss: 2.9494407317639033
Validation loss: 3.16052761481916

Epoch: 5| Step: 9
Training loss: 3.669649009447506
Validation loss: 3.160560441615937

Epoch: 5| Step: 10
Training loss: 2.7526517567389766
Validation loss: 3.158567643528008

Epoch: 205| Step: 0
Training loss: 2.760114103805825
Validation loss: 3.157493214068504

Epoch: 5| Step: 1
Training loss: 3.3766539018043886
Validation loss: 3.1579712656116077

Epoch: 5| Step: 2
Training loss: 3.7015887586790224
Validation loss: 3.1582882900166283

Epoch: 5| Step: 3
Training loss: 3.868772732817336
Validation loss: 3.158357777215343

Epoch: 5| Step: 4
Training loss: 3.3993479945012584
Validation loss: 3.1595024847135864

Epoch: 5| Step: 5
Training loss: 3.5790338819487597
Validation loss: 3.157599460494598

Epoch: 5| Step: 6
Training loss: 3.7312492792330096
Validation loss: 3.157838624470268

Epoch: 5| Step: 7
Training loss: 2.838137443295108
Validation loss: 3.1577728408792933

Epoch: 5| Step: 8
Training loss: 4.169442485617129
Validation loss: 3.1575147242651718

Epoch: 5| Step: 9
Training loss: 2.4129176712187745
Validation loss: 3.157295991868346

Epoch: 5| Step: 10
Training loss: 3.2067274723381383
Validation loss: 3.1575377688280595

Epoch: 206| Step: 0
Training loss: 3.5124565257575666
Validation loss: 3.1558085851450812

Epoch: 5| Step: 1
Training loss: 3.2337266944897745
Validation loss: 3.156688002283735

Epoch: 5| Step: 2
Training loss: 3.6820914480693987
Validation loss: 3.1558213732302987

Epoch: 5| Step: 3
Training loss: 3.0169372865748283
Validation loss: 3.1566060321389666

Epoch: 5| Step: 4
Training loss: 3.6925225401689508
Validation loss: 3.156293443307523

Epoch: 5| Step: 5
Training loss: 3.2644680474298458
Validation loss: 3.1559688118370013

Epoch: 5| Step: 6
Training loss: 3.1134630482816297
Validation loss: 3.1566375474998445

Epoch: 5| Step: 7
Training loss: 3.1061822035699875
Validation loss: 3.1537852394633337

Epoch: 5| Step: 8
Training loss: 3.5756115477025014
Validation loss: 3.1563446475839654

Epoch: 5| Step: 9
Training loss: 3.904689873995752
Validation loss: 3.1552256169926394

Epoch: 5| Step: 10
Training loss: 3.2018391330965574
Validation loss: 3.1547996822003923

Epoch: 207| Step: 0
Training loss: 3.4377507898572377
Validation loss: 3.15519379177357

Epoch: 5| Step: 1
Training loss: 3.336587668317975
Validation loss: 3.1542606442223935

Epoch: 5| Step: 2
Training loss: 3.588960989420412
Validation loss: 3.155941215752999

Epoch: 5| Step: 3
Training loss: 3.3329039456054423
Validation loss: 3.1541531815711137

Epoch: 5| Step: 4
Training loss: 3.881851169388355
Validation loss: 3.153538357318685

Epoch: 5| Step: 5
Training loss: 2.7467391014115528
Validation loss: 3.1530094785883245

Epoch: 5| Step: 6
Training loss: 4.046874293029016
Validation loss: 3.1529934202694934

Epoch: 5| Step: 7
Training loss: 2.378690763087738
Validation loss: 3.1596645281593614

Epoch: 5| Step: 8
Training loss: 2.798905642408293
Validation loss: 3.1545726730094152

Epoch: 5| Step: 9
Training loss: 3.4665484616105307
Validation loss: 3.1551513790452925

Epoch: 5| Step: 10
Training loss: 4.100306029645003
Validation loss: 3.1610527929276526

Epoch: 208| Step: 0
Training loss: 3.5332267427261352
Validation loss: 3.1580222186306472

Epoch: 5| Step: 1
Training loss: 3.803663300006573
Validation loss: 3.1593543541286437

Epoch: 5| Step: 2
Training loss: 3.764985722771838
Validation loss: 3.160908065150409

Epoch: 5| Step: 3
Training loss: 3.5810098138124524
Validation loss: 3.158022143946264

Epoch: 5| Step: 4
Training loss: 2.7777487329448043
Validation loss: 3.1604579838934144

Epoch: 5| Step: 5
Training loss: 3.6963887814735763
Validation loss: 3.156332941873254

Epoch: 5| Step: 6
Training loss: 2.854396801508835
Validation loss: 3.1529325475219228

Epoch: 5| Step: 7
Training loss: 3.263636517518678
Validation loss: 3.150726096449295

Epoch: 5| Step: 8
Training loss: 3.5225846639276925
Validation loss: 3.1509443517044904

Epoch: 5| Step: 9
Training loss: 3.216337021719004
Validation loss: 3.1506167035832804

Epoch: 5| Step: 10
Training loss: 3.186480340365164
Validation loss: 3.1499202372447663

Epoch: 209| Step: 0
Training loss: 3.7642723598227827
Validation loss: 3.1479888851267

Epoch: 5| Step: 1
Training loss: 2.7291828669487024
Validation loss: 3.1500457651616434

Epoch: 5| Step: 2
Training loss: 3.7899793007318108
Validation loss: 3.150252528045363

Epoch: 5| Step: 3
Training loss: 3.523120535996069
Validation loss: 3.1496176908102087

Epoch: 5| Step: 4
Training loss: 3.8789655022066865
Validation loss: 3.151941138347503

Epoch: 5| Step: 5
Training loss: 3.339611451396894
Validation loss: 3.153407202819322

Epoch: 5| Step: 6
Training loss: 2.978251140921201
Validation loss: 3.154939306038835

Epoch: 5| Step: 7
Training loss: 3.0179020482492716
Validation loss: 3.1597947089626652

Epoch: 5| Step: 8
Training loss: 3.5952637511209815
Validation loss: 3.150584704870192

Epoch: 5| Step: 9
Training loss: 3.8116997050821873
Validation loss: 3.1527740156009023

Epoch: 5| Step: 10
Training loss: 2.518002920365704
Validation loss: 3.1508990983771823

Epoch: 210| Step: 0
Training loss: 2.8858388506970347
Validation loss: 3.1494347430579865

Epoch: 5| Step: 1
Training loss: 3.109758669698446
Validation loss: 3.1486707811795887

Epoch: 5| Step: 2
Training loss: 3.7478943317137285
Validation loss: 3.148771298799777

Epoch: 5| Step: 3
Training loss: 3.3844136948279915
Validation loss: 3.1484702655741557

Epoch: 5| Step: 4
Training loss: 3.109621737864607
Validation loss: 3.1468082349735225

Epoch: 5| Step: 5
Training loss: 4.237502178540415
Validation loss: 3.147690459877704

Epoch: 5| Step: 6
Training loss: 2.6101893450577913
Validation loss: 3.147138734781704

Epoch: 5| Step: 7
Training loss: 3.5975474321473917
Validation loss: 3.1474709681833812

Epoch: 5| Step: 8
Training loss: 3.60374083603492
Validation loss: 3.147846194591227

Epoch: 5| Step: 9
Training loss: 3.2805358109475318
Validation loss: 3.148024254824191

Epoch: 5| Step: 10
Training loss: 3.557060640055732
Validation loss: 3.146217251593929

Epoch: 211| Step: 0
Training loss: 3.904410455529621
Validation loss: 3.1473080240613265

Epoch: 5| Step: 1
Training loss: 3.268558772312207
Validation loss: 3.145557563971202

Epoch: 5| Step: 2
Training loss: 3.2343290021638618
Validation loss: 3.1477560176391908

Epoch: 5| Step: 3
Training loss: 3.7310703611341727
Validation loss: 3.1457172191183096

Epoch: 5| Step: 4
Training loss: 3.1350134065332265
Validation loss: 3.147328439883354

Epoch: 5| Step: 5
Training loss: 2.932729215257422
Validation loss: 3.146740320915576

Epoch: 5| Step: 6
Training loss: 3.226883768339064
Validation loss: 3.1500732110613536

Epoch: 5| Step: 7
Training loss: 3.224987024088933
Validation loss: 3.1515781521837467

Epoch: 5| Step: 8
Training loss: 3.079473674440531
Validation loss: 3.155693410432313

Epoch: 5| Step: 9
Training loss: 3.1758347022331317
Validation loss: 3.146616634409477

Epoch: 5| Step: 10
Training loss: 4.358345593835764
Validation loss: 3.1467958974406978

Epoch: 212| Step: 0
Training loss: 3.1847453462611774
Validation loss: 3.146030915027678

Epoch: 5| Step: 1
Training loss: 3.04359000723506
Validation loss: 3.146226948087881

Epoch: 5| Step: 2
Training loss: 3.669751271438716
Validation loss: 3.1443642881430955

Epoch: 5| Step: 3
Training loss: 3.4393903216423305
Validation loss: 3.1447399194751684

Epoch: 5| Step: 4
Training loss: 3.381060633407053
Validation loss: 3.1452290743014615

Epoch: 5| Step: 5
Training loss: 3.3734647296550415
Validation loss: 3.1443514208492376

Epoch: 5| Step: 6
Training loss: 3.5889332211186953
Validation loss: 3.1428668851092807

Epoch: 5| Step: 7
Training loss: 3.7108795482728283
Validation loss: 3.143230306341719

Epoch: 5| Step: 8
Training loss: 3.827665215731797
Validation loss: 3.1436542473978637

Epoch: 5| Step: 9
Training loss: 3.2838686711563017
Validation loss: 3.1441015817351636

Epoch: 5| Step: 10
Training loss: 2.536531096138675
Validation loss: 3.1429091251020687

Epoch: 213| Step: 0
Training loss: 3.5990569362943505
Validation loss: 3.141654399988124

Epoch: 5| Step: 1
Training loss: 3.0646526011598603
Validation loss: 3.142736482761157

Epoch: 5| Step: 2
Training loss: 3.6583332093629113
Validation loss: 3.1432360775715416

Epoch: 5| Step: 3
Training loss: 3.4076346286701877
Validation loss: 3.1430956891551745

Epoch: 5| Step: 4
Training loss: 3.3671770206297196
Validation loss: 3.1464191639124204

Epoch: 5| Step: 5
Training loss: 3.4105762690578474
Validation loss: 3.1458293803667674

Epoch: 5| Step: 6
Training loss: 3.5934493229345845
Validation loss: 3.145386043424165

Epoch: 5| Step: 7
Training loss: 3.3041198098579154
Validation loss: 3.1455859455273867

Epoch: 5| Step: 8
Training loss: 3.476584033685066
Validation loss: 3.1419142120418484

Epoch: 5| Step: 9
Training loss: 3.2967971864891497
Validation loss: 3.1430380292669433

Epoch: 5| Step: 10
Training loss: 3.031509545609591
Validation loss: 3.1413241800781826

Epoch: 214| Step: 0
Training loss: 3.3173521959600576
Validation loss: 3.1406488941622186

Epoch: 5| Step: 1
Training loss: 3.6491434529302182
Validation loss: 3.140073146260712

Epoch: 5| Step: 2
Training loss: 3.786117825246001
Validation loss: 3.1405480120862994

Epoch: 5| Step: 3
Training loss: 3.5286043772309164
Validation loss: 3.1414975332930015

Epoch: 5| Step: 4
Training loss: 3.531189099352129
Validation loss: 3.1404198808274586

Epoch: 5| Step: 5
Training loss: 2.932437836621505
Validation loss: 3.1403671107340982

Epoch: 5| Step: 6
Training loss: 2.952031170140312
Validation loss: 3.1390845219985417

Epoch: 5| Step: 7
Training loss: 2.815564499352165
Validation loss: 3.1406611856428803

Epoch: 5| Step: 8
Training loss: 3.6307051914714763
Validation loss: 3.1405355405751973

Epoch: 5| Step: 9
Training loss: 3.9503251967985404
Validation loss: 3.139682834769623

Epoch: 5| Step: 10
Training loss: 2.9173329999994415
Validation loss: 3.1395146335505433

Epoch: 215| Step: 0
Training loss: 3.6222263116429914
Validation loss: 3.1389358280568476

Epoch: 5| Step: 1
Training loss: 3.8721029465443833
Validation loss: 3.1401767434286194

Epoch: 5| Step: 2
Training loss: 3.435799750411359
Validation loss: 3.1391754502970244

Epoch: 5| Step: 3
Training loss: 3.042211788572308
Validation loss: 3.1403703026633973

Epoch: 5| Step: 4
Training loss: 3.4202787952670635
Validation loss: 3.1421585954749074

Epoch: 5| Step: 5
Training loss: 2.986122777950551
Validation loss: 3.144554514446349

Epoch: 5| Step: 6
Training loss: 2.9630298317763497
Validation loss: 3.147760668055911

Epoch: 5| Step: 7
Training loss: 3.7578548817613924
Validation loss: 3.1438255240152597

Epoch: 5| Step: 8
Training loss: 3.2381226577853397
Validation loss: 3.139111008587781

Epoch: 5| Step: 9
Training loss: 3.6229153920296255
Validation loss: 3.144633328245839

Epoch: 5| Step: 10
Training loss: 3.128688618952873
Validation loss: 3.1423343518087576

Epoch: 216| Step: 0
Training loss: 3.097226896030642
Validation loss: 3.1371008586701423

Epoch: 5| Step: 1
Training loss: 3.372627130576675
Validation loss: 3.137401410645507

Epoch: 5| Step: 2
Training loss: 3.357635189467694
Validation loss: 3.135366856760538

Epoch: 5| Step: 3
Training loss: 4.168657640981082
Validation loss: 3.134765814731763

Epoch: 5| Step: 4
Training loss: 2.7372353552136404
Validation loss: 3.136673132061647

Epoch: 5| Step: 5
Training loss: 3.61504681315522
Validation loss: 3.1359957434614048

Epoch: 5| Step: 6
Training loss: 3.1660820438070894
Validation loss: 3.133967995845867

Epoch: 5| Step: 7
Training loss: 2.590714390297299
Validation loss: 3.134667671172606

Epoch: 5| Step: 8
Training loss: 3.798132291871253
Validation loss: 3.1362355968764364

Epoch: 5| Step: 9
Training loss: 3.968833982525241
Validation loss: 3.135970332544143

Epoch: 5| Step: 10
Training loss: 2.934071752054406
Validation loss: 3.140559445213653

Epoch: 217| Step: 0
Training loss: 2.8838738862715454
Validation loss: 3.1383934412840286

Epoch: 5| Step: 1
Training loss: 3.213949976144264
Validation loss: 3.1363294237206

Epoch: 5| Step: 2
Training loss: 2.460459732423831
Validation loss: 3.1348279447241785

Epoch: 5| Step: 3
Training loss: 3.1996268174007234
Validation loss: 3.1392198191491754

Epoch: 5| Step: 4
Training loss: 3.0809372191850275
Validation loss: 3.1356742528772585

Epoch: 5| Step: 5
Training loss: 2.9116230180507854
Validation loss: 3.137556521136168

Epoch: 5| Step: 6
Training loss: 3.0047031729493243
Validation loss: 3.136929846615983

Epoch: 5| Step: 7
Training loss: 4.0066299329735715
Validation loss: 3.137532303552348

Epoch: 5| Step: 8
Training loss: 3.867426207910477
Validation loss: 3.138456246061495

Epoch: 5| Step: 9
Training loss: 3.656203832090327
Validation loss: 3.1331371562324253

Epoch: 5| Step: 10
Training loss: 4.61763610209669
Validation loss: 3.1326202578271745

Epoch: 218| Step: 0
Training loss: 3.5721916745865347
Validation loss: 3.1333414741581413

Epoch: 5| Step: 1
Training loss: 3.3797130878271715
Validation loss: 3.1349554524298093

Epoch: 5| Step: 2
Training loss: 2.466993262174673
Validation loss: 3.1348926691080017

Epoch: 5| Step: 3
Training loss: 3.05913686010571
Validation loss: 3.1357392487984

Epoch: 5| Step: 4
Training loss: 4.00731752547761
Validation loss: 3.132199553321928

Epoch: 5| Step: 5
Training loss: 3.063039926695259
Validation loss: 3.1311405796052245

Epoch: 5| Step: 6
Training loss: 3.530744128156378
Validation loss: 3.1293545251377606

Epoch: 5| Step: 7
Training loss: 3.571831912016947
Validation loss: 3.132557761604349

Epoch: 5| Step: 8
Training loss: 3.3451308491977403
Validation loss: 3.130117671450018

Epoch: 5| Step: 9
Training loss: 3.2481469960703833
Validation loss: 3.1301334703778045

Epoch: 5| Step: 10
Training loss: 3.7925521040312673
Validation loss: 3.128992311147927

Epoch: 219| Step: 0
Training loss: 3.353213883756854
Validation loss: 3.1317548517473273

Epoch: 5| Step: 1
Training loss: 3.3891414086180975
Validation loss: 3.1307452133198495

Epoch: 5| Step: 2
Training loss: 3.4820836491843488
Validation loss: 3.1305828554635178

Epoch: 5| Step: 3
Training loss: 3.43324432504577
Validation loss: 3.130225210693903

Epoch: 5| Step: 4
Training loss: 3.6163627063159485
Validation loss: 3.130516798853772

Epoch: 5| Step: 5
Training loss: 3.041512489766043
Validation loss: 3.130795074918878

Epoch: 5| Step: 6
Training loss: 3.258468598454909
Validation loss: 3.1288922851237753

Epoch: 5| Step: 7
Training loss: 3.3107348363399893
Validation loss: 3.1285747205826113

Epoch: 5| Step: 8
Training loss: 3.946149740990617
Validation loss: 3.1315150980308624

Epoch: 5| Step: 9
Training loss: 3.2925890503400126
Validation loss: 3.1316652666416553

Epoch: 5| Step: 10
Training loss: 2.92417564187059
Validation loss: 3.1362934717407183

Epoch: 220| Step: 0
Training loss: 2.919261069143926
Validation loss: 3.1343973945268564

Epoch: 5| Step: 1
Training loss: 3.2051093677065
Validation loss: 3.135125919644649

Epoch: 5| Step: 2
Training loss: 3.5295962622047754
Validation loss: 3.12878416911247

Epoch: 5| Step: 3
Training loss: 3.7732977357495003
Validation loss: 3.1304342400534297

Epoch: 5| Step: 4
Training loss: 2.9860466075307985
Validation loss: 3.126751544624275

Epoch: 5| Step: 5
Training loss: 3.6503475180540654
Validation loss: 3.127908446761578

Epoch: 5| Step: 6
Training loss: 4.184008380990907
Validation loss: 3.127546762447816

Epoch: 5| Step: 7
Training loss: 3.4421856936027093
Validation loss: 3.1264613862997304

Epoch: 5| Step: 8
Training loss: 2.6235581934272614
Validation loss: 3.1292274904930086

Epoch: 5| Step: 9
Training loss: 3.0304633624114263
Validation loss: 3.1280770819246424

Epoch: 5| Step: 10
Training loss: 3.56755911336361
Validation loss: 3.1284482160133114

Epoch: 221| Step: 0
Training loss: 3.3516327821702894
Validation loss: 3.1284974820176092

Epoch: 5| Step: 1
Training loss: 3.687713746163742
Validation loss: 3.1274803162850935

Epoch: 5| Step: 2
Training loss: 3.3435738775626356
Validation loss: 3.1277773453642777

Epoch: 5| Step: 3
Training loss: 3.6096241522332684
Validation loss: 3.1298578581513423

Epoch: 5| Step: 4
Training loss: 3.2532668200973895
Validation loss: 3.131977097469215

Epoch: 5| Step: 5
Training loss: 2.8393156250563205
Validation loss: 3.125815497199172

Epoch: 5| Step: 6
Training loss: 3.668275797934489
Validation loss: 3.1244082105868975

Epoch: 5| Step: 7
Training loss: 3.6521377260575445
Validation loss: 3.127211423649312

Epoch: 5| Step: 8
Training loss: 3.5369393757032226
Validation loss: 3.124743663159868

Epoch: 5| Step: 9
Training loss: 2.703543129042339
Validation loss: 3.129411566328053

Epoch: 5| Step: 10
Training loss: 3.375754095531986
Validation loss: 3.12745351314895

Epoch: 222| Step: 0
Training loss: 2.8720140292746805
Validation loss: 3.125895619181759

Epoch: 5| Step: 1
Training loss: 3.134439783006829
Validation loss: 3.1262940219469537

Epoch: 5| Step: 2
Training loss: 3.5421404054234493
Validation loss: 3.1233207481326755

Epoch: 5| Step: 3
Training loss: 3.2610132973548116
Validation loss: 3.1235612703453652

Epoch: 5| Step: 4
Training loss: 4.038288448103713
Validation loss: 3.1238493583253506

Epoch: 5| Step: 5
Training loss: 3.8936018375233283
Validation loss: 3.1258407577472096

Epoch: 5| Step: 6
Training loss: 2.7874775291187186
Validation loss: 3.1240183512841275

Epoch: 5| Step: 7
Training loss: 3.365701086234469
Validation loss: 3.125447655885577

Epoch: 5| Step: 8
Training loss: 3.8271094395898397
Validation loss: 3.126184128406088

Epoch: 5| Step: 9
Training loss: 2.6324084959583125
Validation loss: 3.126190165639776

Epoch: 5| Step: 10
Training loss: 3.4881124252696902
Validation loss: 3.1214233899543915

Epoch: 223| Step: 0
Training loss: 3.432665667998682
Validation loss: 3.122640200310736

Epoch: 5| Step: 1
Training loss: 3.8935608109119144
Validation loss: 3.125206492174943

Epoch: 5| Step: 2
Training loss: 3.3390404164535
Validation loss: 3.126139805798838

Epoch: 5| Step: 3
Training loss: 3.1727429034083316
Validation loss: 3.1246509373457676

Epoch: 5| Step: 4
Training loss: 4.386882884215093
Validation loss: 3.123516828444388

Epoch: 5| Step: 5
Training loss: 3.1756078243410526
Validation loss: 3.1260860992220865

Epoch: 5| Step: 6
Training loss: 3.578240538484986
Validation loss: 3.1245411427285417

Epoch: 5| Step: 7
Training loss: 3.2202922496501367
Validation loss: 3.122930778521828

Epoch: 5| Step: 8
Training loss: 2.7881445990435614
Validation loss: 3.1222291364622317

Epoch: 5| Step: 9
Training loss: 3.0592169778320817
Validation loss: 3.1227003771073774

Epoch: 5| Step: 10
Training loss: 2.6311493553068477
Validation loss: 3.120638641151277

Epoch: 224| Step: 0
Training loss: 3.629702313409761
Validation loss: 3.1225764797340205

Epoch: 5| Step: 1
Training loss: 4.021270938969371
Validation loss: 3.1226950153533366

Epoch: 5| Step: 2
Training loss: 3.3014802271660892
Validation loss: 3.121614155207756

Epoch: 5| Step: 3
Training loss: 3.1520868927069263
Validation loss: 3.123500557763897

Epoch: 5| Step: 4
Training loss: 3.2658695695181983
Validation loss: 3.1218203736911887

Epoch: 5| Step: 5
Training loss: 3.263187794880301
Validation loss: 3.1225507001738495

Epoch: 5| Step: 6
Training loss: 3.6969225482994634
Validation loss: 3.1209385786712818

Epoch: 5| Step: 7
Training loss: 3.469621153716553
Validation loss: 3.1209193932329224

Epoch: 5| Step: 8
Training loss: 2.841767678651566
Validation loss: 3.1193134769214934

Epoch: 5| Step: 9
Training loss: 2.9929622115360255
Validation loss: 3.119682652907372

Epoch: 5| Step: 10
Training loss: 3.3240271041260847
Validation loss: 3.119596762670986

Epoch: 225| Step: 0
Training loss: 3.7815715558490806
Validation loss: 3.120328936472781

Epoch: 5| Step: 1
Training loss: 2.8453150205061597
Validation loss: 3.120099647713133

Epoch: 5| Step: 2
Training loss: 3.593639338904242
Validation loss: 3.120373677645921

Epoch: 5| Step: 3
Training loss: 2.661714027698427
Validation loss: 3.120034298465049

Epoch: 5| Step: 4
Training loss: 3.7297143942379085
Validation loss: 3.1196154253729675

Epoch: 5| Step: 5
Training loss: 3.5909824495537332
Validation loss: 3.120222670636992

Epoch: 5| Step: 6
Training loss: 3.5589650334148866
Validation loss: 3.119356323504232

Epoch: 5| Step: 7
Training loss: 3.038617805169573
Validation loss: 3.1192012358747747

Epoch: 5| Step: 8
Training loss: 3.057320399152056
Validation loss: 3.1184291644240676

Epoch: 5| Step: 9
Training loss: 3.1908182562007514
Validation loss: 3.1187915863428235

Epoch: 5| Step: 10
Training loss: 3.9137966652021987
Validation loss: 3.1186345939139013

Epoch: 226| Step: 0
Training loss: 3.1288266975490826
Validation loss: 3.117010643203885

Epoch: 5| Step: 1
Training loss: 3.6961799232566386
Validation loss: 3.116491132588806

Epoch: 5| Step: 2
Training loss: 2.8112632575428522
Validation loss: 3.117460456177166

Epoch: 5| Step: 3
Training loss: 3.5197528934441125
Validation loss: 3.117328845479895

Epoch: 5| Step: 4
Training loss: 3.2135141990802576
Validation loss: 3.1167829873400588

Epoch: 5| Step: 5
Training loss: 3.072765816471932
Validation loss: 3.1166664872611705

Epoch: 5| Step: 6
Training loss: 3.503641686291275
Validation loss: 3.1159985623155815

Epoch: 5| Step: 7
Training loss: 3.083227430707202
Validation loss: 3.1152615795219987

Epoch: 5| Step: 8
Training loss: 3.1068024848206073
Validation loss: 3.117688003366913

Epoch: 5| Step: 9
Training loss: 4.084372926578711
Validation loss: 3.1139310726620058

Epoch: 5| Step: 10
Training loss: 3.7097068271835636
Validation loss: 3.115809322615354

Epoch: 227| Step: 0
Training loss: 3.9443760733133764
Validation loss: 3.1191073680370995

Epoch: 5| Step: 1
Training loss: 2.6805785007406167
Validation loss: 3.1228257390412426

Epoch: 5| Step: 2
Training loss: 3.34015811979894
Validation loss: 3.118409536055674

Epoch: 5| Step: 3
Training loss: 3.912428341535334
Validation loss: 3.1182781273757545

Epoch: 5| Step: 4
Training loss: 2.1896262598109772
Validation loss: 3.1202455083321974

Epoch: 5| Step: 5
Training loss: 3.3185339618489405
Validation loss: 3.118429169356629

Epoch: 5| Step: 6
Training loss: 3.1929316896323043
Validation loss: 3.1193332705477603

Epoch: 5| Step: 7
Training loss: 3.166432940909203
Validation loss: 3.112773137241144

Epoch: 5| Step: 8
Training loss: 3.977998545420569
Validation loss: 3.114759552079516

Epoch: 5| Step: 9
Training loss: 3.359910505329093
Validation loss: 3.117431088309667

Epoch: 5| Step: 10
Training loss: 3.6043075063599708
Validation loss: 3.1121463084926613

Epoch: 228| Step: 0
Training loss: 3.369638918088028
Validation loss: 3.110432621027189

Epoch: 5| Step: 1
Training loss: 3.0458600823671174
Validation loss: 3.1118953485365695

Epoch: 5| Step: 2
Training loss: 3.618273973533014
Validation loss: 3.1128518571971586

Epoch: 5| Step: 3
Training loss: 3.526131895968458
Validation loss: 3.113689949810577

Epoch: 5| Step: 4
Training loss: 3.023319843378502
Validation loss: 3.11315498739852

Epoch: 5| Step: 5
Training loss: 3.673213503752924
Validation loss: 3.111932102210805

Epoch: 5| Step: 6
Training loss: 2.787799795134849
Validation loss: 3.112066225466363

Epoch: 5| Step: 7
Training loss: 2.8986437947769685
Validation loss: 3.11047578775006

Epoch: 5| Step: 8
Training loss: 3.2162720854942743
Validation loss: 3.1142189179522677

Epoch: 5| Step: 9
Training loss: 4.3995808661843805
Validation loss: 3.1160748091584454

Epoch: 5| Step: 10
Training loss: 3.176485966456136
Validation loss: 3.1151327324324174

Epoch: 229| Step: 0
Training loss: 3.0512122949929608
Validation loss: 3.118873630534108

Epoch: 5| Step: 1
Training loss: 3.026037079396713
Validation loss: 3.1200787817540347

Epoch: 5| Step: 2
Training loss: 3.163790618141386
Validation loss: 3.1191932955843504

Epoch: 5| Step: 3
Training loss: 3.4634339432946355
Validation loss: 3.1164354178887543

Epoch: 5| Step: 4
Training loss: 3.1649319431406284
Validation loss: 3.114678069508841

Epoch: 5| Step: 5
Training loss: 3.644894826075487
Validation loss: 3.1178646984042993

Epoch: 5| Step: 6
Training loss: 3.9889463043921425
Validation loss: 3.1144897719059284

Epoch: 5| Step: 7
Training loss: 3.3932514477825566
Validation loss: 3.1138620644745676

Epoch: 5| Step: 8
Training loss: 3.1723298747303135
Validation loss: 3.1122797240042988

Epoch: 5| Step: 9
Training loss: 3.7722128071306202
Validation loss: 3.112075794415634

Epoch: 5| Step: 10
Training loss: 2.9955968332826837
Validation loss: 3.110684442366139

Epoch: 230| Step: 0
Training loss: 3.4672540411595887
Validation loss: 3.110522245663908

Epoch: 5| Step: 1
Training loss: 3.694735653394152
Validation loss: 3.10876475839933

Epoch: 5| Step: 2
Training loss: 3.633446029058577
Validation loss: 3.1078335470053826

Epoch: 5| Step: 3
Training loss: 3.1735943423513797
Validation loss: 3.10840500412445

Epoch: 5| Step: 4
Training loss: 3.3214561736663675
Validation loss: 3.109334054035127

Epoch: 5| Step: 5
Training loss: 3.080054748098114
Validation loss: 3.108591270439088

Epoch: 5| Step: 6
Training loss: 3.741962848203657
Validation loss: 3.1068683013440137

Epoch: 5| Step: 7
Training loss: 3.3842230624456717
Validation loss: 3.1071480897605155

Epoch: 5| Step: 8
Training loss: 3.041344734469323
Validation loss: 3.1073085188047296

Epoch: 5| Step: 9
Training loss: 3.1586010929298767
Validation loss: 3.108372733345271

Epoch: 5| Step: 10
Training loss: 3.1979004469138155
Validation loss: 3.1067867091778543

Epoch: 231| Step: 0
Training loss: 2.631975442731208
Validation loss: 3.106214581290089

Epoch: 5| Step: 1
Training loss: 2.7935087095513693
Validation loss: 3.10863482146854

Epoch: 5| Step: 2
Training loss: 3.5818910727325846
Validation loss: 3.1092018808507196

Epoch: 5| Step: 3
Training loss: 3.106896721121861
Validation loss: 3.104935228754366

Epoch: 5| Step: 4
Training loss: 3.722045079724383
Validation loss: 3.1071965775869663

Epoch: 5| Step: 5
Training loss: 3.7505916128784587
Validation loss: 3.110722524011376

Epoch: 5| Step: 6
Training loss: 3.6264561326495115
Validation loss: 3.111177206313961

Epoch: 5| Step: 7
Training loss: 3.4921752110207436
Validation loss: 3.106550766374687

Epoch: 5| Step: 8
Training loss: 3.432279888744532
Validation loss: 3.107845534376425

Epoch: 5| Step: 9
Training loss: 3.5371047914623808
Validation loss: 3.1059509427196397

Epoch: 5| Step: 10
Training loss: 3.0384106562141824
Validation loss: 3.105340128963328

Epoch: 232| Step: 0
Training loss: 3.0609567607528745
Validation loss: 3.1063527939625684

Epoch: 5| Step: 1
Training loss: 3.5625313205346054
Validation loss: 3.1046460173781405

Epoch: 5| Step: 2
Training loss: 3.06037876078842
Validation loss: 3.1044010542682834

Epoch: 5| Step: 3
Training loss: 3.825992161345441
Validation loss: 3.105457115035455

Epoch: 5| Step: 4
Training loss: 3.6748475075567946
Validation loss: 3.106064879170258

Epoch: 5| Step: 5
Training loss: 3.3890914613252234
Validation loss: 3.106358135232228

Epoch: 5| Step: 6
Training loss: 3.360615346056491
Validation loss: 3.105728204823977

Epoch: 5| Step: 7
Training loss: 3.011352200101988
Validation loss: 3.1063687550223067

Epoch: 5| Step: 8
Training loss: 3.856419470230267
Validation loss: 3.1060427188369615

Epoch: 5| Step: 9
Training loss: 2.6040739933054637
Validation loss: 3.1044954311786914

Epoch: 5| Step: 10
Training loss: 3.387027783577524
Validation loss: 3.106107758293575

Epoch: 233| Step: 0
Training loss: 2.718119931930059
Validation loss: 3.1044129888291216

Epoch: 5| Step: 1
Training loss: 3.717553338884812
Validation loss: 3.104079428156696

Epoch: 5| Step: 2
Training loss: 3.502817246243871
Validation loss: 3.103079588491013

Epoch: 5| Step: 3
Training loss: 3.7514730739143256
Validation loss: 3.1035097584295674

Epoch: 5| Step: 4
Training loss: 2.9195361236621418
Validation loss: 3.103037412729771

Epoch: 5| Step: 5
Training loss: 3.266101565106901
Validation loss: 3.1025617461162365

Epoch: 5| Step: 6
Training loss: 3.6005720319859638
Validation loss: 3.1034070478699505

Epoch: 5| Step: 7
Training loss: 3.3019867089672377
Validation loss: 3.1026586296992806

Epoch: 5| Step: 8
Training loss: 3.6678499277712233
Validation loss: 3.1034914647694016

Epoch: 5| Step: 9
Training loss: 3.4320699632711578
Validation loss: 3.1035815293992304

Epoch: 5| Step: 10
Training loss: 2.839692123541978
Validation loss: 3.1042817210014633

Epoch: 234| Step: 0
Training loss: 3.350576402411017
Validation loss: 3.1034169161218

Epoch: 5| Step: 1
Training loss: 3.18103733513564
Validation loss: 3.1043194269842913

Epoch: 5| Step: 2
Training loss: 3.852430636544571
Validation loss: 3.1047852164109595

Epoch: 5| Step: 3
Training loss: 3.650888277424194
Validation loss: 3.102063754999044

Epoch: 5| Step: 4
Training loss: 3.1376047367684627
Validation loss: 3.1022955725372947

Epoch: 5| Step: 5
Training loss: 3.5391802568191957
Validation loss: 3.101548207018313

Epoch: 5| Step: 6
Training loss: 3.4490719307123094
Validation loss: 3.100553297601462

Epoch: 5| Step: 7
Training loss: 3.2203261581049825
Validation loss: 3.10036163668569

Epoch: 5| Step: 8
Training loss: 3.2146007867826745
Validation loss: 3.0993552170526786

Epoch: 5| Step: 9
Training loss: 3.144830270138361
Validation loss: 3.1003243720898963

Epoch: 5| Step: 10
Training loss: 3.065992893616366
Validation loss: 3.0992421307817644

Epoch: 235| Step: 0
Training loss: 3.837056356128033
Validation loss: 3.0995066261729716

Epoch: 5| Step: 1
Training loss: 3.7803220004226996
Validation loss: 3.0999946717908826

Epoch: 5| Step: 2
Training loss: 3.307323802081
Validation loss: 3.098778177872269

Epoch: 5| Step: 3
Training loss: 3.4199579869863115
Validation loss: 3.099484600089168

Epoch: 5| Step: 4
Training loss: 3.0796887448568167
Validation loss: 3.0995737208117604

Epoch: 5| Step: 5
Training loss: 3.2664037624624287
Validation loss: 3.098246857326649

Epoch: 5| Step: 6
Training loss: 2.8492944345968203
Validation loss: 3.097849831057136

Epoch: 5| Step: 7
Training loss: 2.7586524267878527
Validation loss: 3.0990667878252762

Epoch: 5| Step: 8
Training loss: 3.4700992468896565
Validation loss: 3.099078603954303

Epoch: 5| Step: 9
Training loss: 3.2142627140009417
Validation loss: 3.0993183597277483

Epoch: 5| Step: 10
Training loss: 3.836951469458467
Validation loss: 3.0991917615406663

Epoch: 236| Step: 0
Training loss: 3.2106070615309257
Validation loss: 3.0958285533178214

Epoch: 5| Step: 1
Training loss: 3.6694611102282497
Validation loss: 3.0970567234469932

Epoch: 5| Step: 2
Training loss: 2.8743977123142037
Validation loss: 3.0986934240829402

Epoch: 5| Step: 3
Training loss: 3.2424067779293226
Validation loss: 3.0976824196365147

Epoch: 5| Step: 4
Training loss: 3.6581204838336263
Validation loss: 3.096743667755025

Epoch: 5| Step: 5
Training loss: 3.4502518382275205
Validation loss: 3.095350684827572

Epoch: 5| Step: 6
Training loss: 2.9697141988911495
Validation loss: 3.0974924242595967

Epoch: 5| Step: 7
Training loss: 3.6552551741962924
Validation loss: 3.0976423892143097

Epoch: 5| Step: 8
Training loss: 3.5470911707941455
Validation loss: 3.1012624806939213

Epoch: 5| Step: 9
Training loss: 2.9466912156660388
Validation loss: 3.1024899069344496

Epoch: 5| Step: 10
Training loss: 3.605992569486777
Validation loss: 3.0945573227592806

Epoch: 237| Step: 0
Training loss: 3.1208567809856826
Validation loss: 3.0962577459899405

Epoch: 5| Step: 1
Training loss: 3.2626182914715485
Validation loss: 3.095841050076631

Epoch: 5| Step: 2
Training loss: 2.890191617902834
Validation loss: 3.0968988477449857

Epoch: 5| Step: 3
Training loss: 3.5798989775059225
Validation loss: 3.09553590142182

Epoch: 5| Step: 4
Training loss: 3.3725558720422093
Validation loss: 3.0965374764577756

Epoch: 5| Step: 5
Training loss: 3.2583190377808817
Validation loss: 3.0945736544903992

Epoch: 5| Step: 6
Training loss: 3.059137951217244
Validation loss: 3.0947472423596594

Epoch: 5| Step: 7
Training loss: 3.6194263886861515
Validation loss: 3.095373613268231

Epoch: 5| Step: 8
Training loss: 3.8559281868717434
Validation loss: 3.0960767922161074

Epoch: 5| Step: 9
Training loss: 3.1779510480448767
Validation loss: 3.094359726338737

Epoch: 5| Step: 10
Training loss: 3.6273133361448413
Validation loss: 3.0939905763561297

Epoch: 238| Step: 0
Training loss: 3.6070220015161243
Validation loss: 3.0941074977277774

Epoch: 5| Step: 1
Training loss: 3.060680238000551
Validation loss: 3.096026326763847

Epoch: 5| Step: 2
Training loss: 3.463421001579174
Validation loss: 3.091890807490755

Epoch: 5| Step: 3
Training loss: 3.1349400932270712
Validation loss: 3.096163616438688

Epoch: 5| Step: 4
Training loss: 3.3377713382448313
Validation loss: 3.093705292270236

Epoch: 5| Step: 5
Training loss: 3.655980809401348
Validation loss: 3.0939452407101635

Epoch: 5| Step: 6
Training loss: 3.4361589069857663
Validation loss: 3.091752474848132

Epoch: 5| Step: 7
Training loss: 1.8764010598953236
Validation loss: 3.094281994939009

Epoch: 5| Step: 8
Training loss: 3.7345748273304387
Validation loss: 3.092691238062023

Epoch: 5| Step: 9
Training loss: 3.669178463612714
Validation loss: 3.0929165825184133

Epoch: 5| Step: 10
Training loss: 3.5155403635645492
Validation loss: 3.0940690508438418

Epoch: 239| Step: 0
Training loss: 3.4861008000991807
Validation loss: 3.0922332605581366

Epoch: 5| Step: 1
Training loss: 3.4064224619471104
Validation loss: 3.093719026508492

Epoch: 5| Step: 2
Training loss: 3.1132847727297355
Validation loss: 3.09213809650355

Epoch: 5| Step: 3
Training loss: 3.2995556965748896
Validation loss: 3.0960445386717406

Epoch: 5| Step: 4
Training loss: 3.7452660243811504
Validation loss: 3.095497810177972

Epoch: 5| Step: 5
Training loss: 3.3581344798039643
Validation loss: 3.0958435765837287

Epoch: 5| Step: 6
Training loss: 3.2747159295968964
Validation loss: 3.0959969824631863

Epoch: 5| Step: 7
Training loss: 3.5651355832120286
Validation loss: 3.0980724684122345

Epoch: 5| Step: 8
Training loss: 2.8747152104510683
Validation loss: 3.098489389625308

Epoch: 5| Step: 9
Training loss: 3.583325201217532
Validation loss: 3.099098551635285

Epoch: 5| Step: 10
Training loss: 3.0490780421872827
Validation loss: 3.0929369462476353

Epoch: 240| Step: 0
Training loss: 2.3855021321229795
Validation loss: 3.0931646498267926

Epoch: 5| Step: 1
Training loss: 4.004200160706499
Validation loss: 3.0891635674478453

Epoch: 5| Step: 2
Training loss: 3.4836883552607847
Validation loss: 3.0904572449551404

Epoch: 5| Step: 3
Training loss: 3.272535832662801
Validation loss: 3.0879835447528836

Epoch: 5| Step: 4
Training loss: 3.5087546801561347
Validation loss: 3.0894312068438707

Epoch: 5| Step: 5
Training loss: 2.99364163196634
Validation loss: 3.0890116140119868

Epoch: 5| Step: 6
Training loss: 3.015763828066582
Validation loss: 3.090019971408188

Epoch: 5| Step: 7
Training loss: 3.0432940445112138
Validation loss: 3.089818357783843

Epoch: 5| Step: 8
Training loss: 4.101790358254113
Validation loss: 3.089212224694603

Epoch: 5| Step: 9
Training loss: 3.755189229816974
Validation loss: 3.0893675888120105

Epoch: 5| Step: 10
Training loss: 2.7919379619657696
Validation loss: 3.0874739091606163

Epoch: 241| Step: 0
Training loss: 2.3270829704191036
Validation loss: 3.0876248223557967

Epoch: 5| Step: 1
Training loss: 3.4413656520289084
Validation loss: 3.088516680710076

Epoch: 5| Step: 2
Training loss: 3.423146608182425
Validation loss: 3.088607309003519

Epoch: 5| Step: 3
Training loss: 3.413124636538475
Validation loss: 3.0889193683944276

Epoch: 5| Step: 4
Training loss: 4.004846497831272
Validation loss: 3.093171088832025

Epoch: 5| Step: 5
Training loss: 3.769377172612099
Validation loss: 3.087959019748895

Epoch: 5| Step: 6
Training loss: 3.1285685191479993
Validation loss: 3.0890707304949228

Epoch: 5| Step: 7
Training loss: 2.763033843781343
Validation loss: 3.0881922206561674

Epoch: 5| Step: 8
Training loss: 3.1142304049338816
Validation loss: 3.0891198165991836

Epoch: 5| Step: 9
Training loss: 4.035701216376323
Validation loss: 3.087257321712024

Epoch: 5| Step: 10
Training loss: 2.9410156963387393
Validation loss: 3.088391197822479

Epoch: 242| Step: 0
Training loss: 3.0579025637345665
Validation loss: 3.086171843837967

Epoch: 5| Step: 1
Training loss: 2.970379673229873
Validation loss: 3.084685118819307

Epoch: 5| Step: 2
Training loss: 3.1541890884737978
Validation loss: 3.087445450094504

Epoch: 5| Step: 3
Training loss: 3.9205126580918344
Validation loss: 3.0887361138897442

Epoch: 5| Step: 4
Training loss: 3.1516844711190815
Validation loss: 3.090887741672416

Epoch: 5| Step: 5
Training loss: 3.1553962988208477
Validation loss: 3.091630771862986

Epoch: 5| Step: 6
Training loss: 2.858007552225694
Validation loss: 3.091791127153643

Epoch: 5| Step: 7
Training loss: 2.8987114049423868
Validation loss: 3.090665096062392

Epoch: 5| Step: 8
Training loss: 3.6236561882347815
Validation loss: 3.0892303589329355

Epoch: 5| Step: 9
Training loss: 3.6722084705623033
Validation loss: 3.085957845815762

Epoch: 5| Step: 10
Training loss: 4.200491040907147
Validation loss: 3.087169463092602

Epoch: 243| Step: 0
Training loss: 3.1877472725492244
Validation loss: 3.08392074685474

Epoch: 5| Step: 1
Training loss: 3.6792844644756983
Validation loss: 3.08650342602341

Epoch: 5| Step: 2
Training loss: 3.0868298749295873
Validation loss: 3.084501380033897

Epoch: 5| Step: 3
Training loss: 3.2294675297195194
Validation loss: 3.083570485084042

Epoch: 5| Step: 4
Training loss: 3.558452917467438
Validation loss: 3.0856933522092196

Epoch: 5| Step: 5
Training loss: 3.366894348553469
Validation loss: 3.0859201705194734

Epoch: 5| Step: 6
Training loss: 2.8412816999742208
Validation loss: 3.0851973996496223

Epoch: 5| Step: 7
Training loss: 3.3299082961643642
Validation loss: 3.083635399103317

Epoch: 5| Step: 8
Training loss: 2.861880012902699
Validation loss: 3.0866097273255058

Epoch: 5| Step: 9
Training loss: 3.496277873555849
Validation loss: 3.084352169199017

Epoch: 5| Step: 10
Training loss: 4.108102579709996
Validation loss: 3.0854283415519683

Epoch: 244| Step: 0
Training loss: 3.6026423029222836
Validation loss: 3.087899081649191

Epoch: 5| Step: 1
Training loss: 4.413171836994544
Validation loss: 3.088186919359493

Epoch: 5| Step: 2
Training loss: 3.217394052463976
Validation loss: 3.0903418711554465

Epoch: 5| Step: 3
Training loss: 3.5539572835575908
Validation loss: 3.088748675033544

Epoch: 5| Step: 4
Training loss: 2.8589290417047657
Validation loss: 3.085964160293635

Epoch: 5| Step: 5
Training loss: 3.1495601649735296
Validation loss: 3.0866732983794893

Epoch: 5| Step: 6
Training loss: 3.378165844186042
Validation loss: 3.082728801974638

Epoch: 5| Step: 7
Training loss: 3.2581661041611563
Validation loss: 3.080768048255158

Epoch: 5| Step: 8
Training loss: 3.1107456885791342
Validation loss: 3.0833325229456356

Epoch: 5| Step: 9
Training loss: 2.831270776129276
Validation loss: 3.083857462390209

Epoch: 5| Step: 10
Training loss: 3.118016335954136
Validation loss: 3.0812120121736197

Epoch: 245| Step: 0
Training loss: 3.13655411037605
Validation loss: 3.0800212888390766

Epoch: 5| Step: 1
Training loss: 3.573230310729442
Validation loss: 3.0789876432541723

Epoch: 5| Step: 2
Training loss: 2.9965181808543924
Validation loss: 3.078483621034355

Epoch: 5| Step: 3
Training loss: 3.115489985105078
Validation loss: 3.0805013056396673

Epoch: 5| Step: 4
Training loss: 3.7748363737303237
Validation loss: 3.078186717480976

Epoch: 5| Step: 5
Training loss: 2.935279169014223
Validation loss: 3.0787789072008103

Epoch: 5| Step: 6
Training loss: 2.7964264920315167
Validation loss: 3.0811935844632377

Epoch: 5| Step: 7
Training loss: 3.4206129559904817
Validation loss: 3.0920923606038295

Epoch: 5| Step: 8
Training loss: 4.065317673323228
Validation loss: 3.1007608555721364

Epoch: 5| Step: 9
Training loss: 3.0823827429479675
Validation loss: 3.1035799335155927

Epoch: 5| Step: 10
Training loss: 3.665221724315067
Validation loss: 3.0934593235660457

Epoch: 246| Step: 0
Training loss: 3.572862645103213
Validation loss: 3.089694815418817

Epoch: 5| Step: 1
Training loss: 3.1667158892637386
Validation loss: 3.0817666032362085

Epoch: 5| Step: 2
Training loss: 3.0902532988494333
Validation loss: 3.082407659138511

Epoch: 5| Step: 3
Training loss: 3.1076508155371307
Validation loss: 3.077911864291723

Epoch: 5| Step: 4
Training loss: 3.1624258824283973
Validation loss: 3.0759363925832233

Epoch: 5| Step: 5
Training loss: 3.7094473005028012
Validation loss: 3.0777487301275426

Epoch: 5| Step: 6
Training loss: 2.672797417501682
Validation loss: 3.0762531774623576

Epoch: 5| Step: 7
Training loss: 3.4834522342618377
Validation loss: 3.0781781925069276

Epoch: 5| Step: 8
Training loss: 3.34462648116691
Validation loss: 3.075398719196251

Epoch: 5| Step: 9
Training loss: 3.3759806585797394
Validation loss: 3.077201253660889

Epoch: 5| Step: 10
Training loss: 3.9689455960351876
Validation loss: 3.0750600162508213

Epoch: 247| Step: 0
Training loss: 3.3890175942611194
Validation loss: 3.074955074816833

Epoch: 5| Step: 1
Training loss: 3.166049964149063
Validation loss: 3.075300030661417

Epoch: 5| Step: 2
Training loss: 2.678285905061614
Validation loss: 3.0757792598192792

Epoch: 5| Step: 3
Training loss: 2.4300891997994505
Validation loss: 3.0755553937760953

Epoch: 5| Step: 4
Training loss: 3.6630448024049977
Validation loss: 3.076169142323895

Epoch: 5| Step: 5
Training loss: 3.705387888795599
Validation loss: 3.0761050916676504

Epoch: 5| Step: 6
Training loss: 3.416684189418116
Validation loss: 3.0825385643870296

Epoch: 5| Step: 7
Training loss: 3.5490296662983285
Validation loss: 3.075659552885016

Epoch: 5| Step: 8
Training loss: 3.923936886986614
Validation loss: 3.0816357708478894

Epoch: 5| Step: 9
Training loss: 2.516653383822051
Validation loss: 3.0751546175414872

Epoch: 5| Step: 10
Training loss: 3.9411187875225586
Validation loss: 3.081895210724787

Epoch: 248| Step: 0
Training loss: 3.635415340448846
Validation loss: 3.077544333357033

Epoch: 5| Step: 1
Training loss: 3.4506090759893815
Validation loss: 3.0791897820345753

Epoch: 5| Step: 2
Training loss: 3.522570315133686
Validation loss: 3.0738360428955187

Epoch: 5| Step: 3
Training loss: 3.5971924589505853
Validation loss: 3.075470000013446

Epoch: 5| Step: 4
Training loss: 3.553542134971399
Validation loss: 3.074547156988106

Epoch: 5| Step: 5
Training loss: 3.1798305619881857
Validation loss: 3.0737604088642825

Epoch: 5| Step: 6
Training loss: 2.5802540628885238
Validation loss: 3.073194069053276

Epoch: 5| Step: 7
Training loss: 3.1827533759504556
Validation loss: 3.0743720816726117

Epoch: 5| Step: 8
Training loss: 3.420752911816873
Validation loss: 3.075763678460742

Epoch: 5| Step: 9
Training loss: 3.5621517078064926
Validation loss: 3.0755780630194836

Epoch: 5| Step: 10
Training loss: 2.7869291294040033
Validation loss: 3.074824761340369

Epoch: 249| Step: 0
Training loss: 3.4284368159344125
Validation loss: 3.074662554820771

Epoch: 5| Step: 1
Training loss: 3.870813138243215
Validation loss: 3.074153603780831

Epoch: 5| Step: 2
Training loss: 3.1046033889135685
Validation loss: 3.0748084806261478

Epoch: 5| Step: 3
Training loss: 3.1244755114057963
Validation loss: 3.0749945893879094

Epoch: 5| Step: 4
Training loss: 2.8477019632069016
Validation loss: 3.073608966733827

Epoch: 5| Step: 5
Training loss: 3.188757704393148
Validation loss: 3.0722532467988812

Epoch: 5| Step: 6
Training loss: 3.7834357887768957
Validation loss: 3.0725835008806848

Epoch: 5| Step: 7
Training loss: 3.14676911707225
Validation loss: 3.0727229726629424

Epoch: 5| Step: 8
Training loss: 3.66005749808418
Validation loss: 3.072379301183165

Epoch: 5| Step: 9
Training loss: 3.405730041575355
Validation loss: 3.071974519628856

Epoch: 5| Step: 10
Training loss: 2.938021836700205
Validation loss: 3.073105425466086

Epoch: 250| Step: 0
Training loss: 2.96034254875706
Validation loss: 3.0714085708442282

Epoch: 5| Step: 1
Training loss: 2.9929019881698458
Validation loss: 3.0715407177400946

Epoch: 5| Step: 2
Training loss: 3.1517466531492038
Validation loss: 3.0710480951774537

Epoch: 5| Step: 3
Training loss: 2.7589248272733284
Validation loss: 3.070692396088909

Epoch: 5| Step: 4
Training loss: 3.302638218865626
Validation loss: 3.06921421014658

Epoch: 5| Step: 5
Training loss: 3.9515104954843348
Validation loss: 3.0706559369335307

Epoch: 5| Step: 6
Training loss: 3.578639897109458
Validation loss: 3.0698310628856604

Epoch: 5| Step: 7
Training loss: 2.4667808308687467
Validation loss: 3.070396037487694

Epoch: 5| Step: 8
Training loss: 4.147147400108603
Validation loss: 3.071731424457001

Epoch: 5| Step: 9
Training loss: 3.3788852227940382
Validation loss: 3.068865524465656

Epoch: 5| Step: 10
Training loss: 3.665242800092563
Validation loss: 3.07056523883658

Epoch: 251| Step: 0
Training loss: 3.3761259955718588
Validation loss: 3.067590132755056

Epoch: 5| Step: 1
Training loss: 3.990393308218184
Validation loss: 3.0702359750648363

Epoch: 5| Step: 2
Training loss: 2.6712924255229433
Validation loss: 3.0694415679996365

Epoch: 5| Step: 3
Training loss: 3.265295568760535
Validation loss: 3.0706893688350103

Epoch: 5| Step: 4
Training loss: 2.890312714075078
Validation loss: 3.068489335609967

Epoch: 5| Step: 5
Training loss: 3.020873567159779
Validation loss: 3.0700414477881943

Epoch: 5| Step: 6
Training loss: 3.47100124678044
Validation loss: 3.0701341754414337

Epoch: 5| Step: 7
Training loss: 3.823768098207849
Validation loss: 3.0679863244701546

Epoch: 5| Step: 8
Training loss: 2.915855040475337
Validation loss: 3.068055219756757

Epoch: 5| Step: 9
Training loss: 3.0115851188333553
Validation loss: 3.0702177720563433

Epoch: 5| Step: 10
Training loss: 4.000234120193145
Validation loss: 3.068136337900008

Epoch: 252| Step: 0
Training loss: 3.4425371197684838
Validation loss: 3.065791544590911

Epoch: 5| Step: 1
Training loss: 3.519604139176562
Validation loss: 3.0679483323820205

Epoch: 5| Step: 2
Training loss: 3.2131687403374625
Validation loss: 3.068034201218036

Epoch: 5| Step: 3
Training loss: 3.0214767998450616
Validation loss: 3.0674932347238353

Epoch: 5| Step: 4
Training loss: 3.6441962935572727
Validation loss: 3.06709673524502

Epoch: 5| Step: 5
Training loss: 3.545129825598307
Validation loss: 3.0674014819761437

Epoch: 5| Step: 6
Training loss: 3.6494570498120473
Validation loss: 3.066356535268781

Epoch: 5| Step: 7
Training loss: 3.615163809625003
Validation loss: 3.0670682041212833

Epoch: 5| Step: 8
Training loss: 2.6498460652968667
Validation loss: 3.06618267953224

Epoch: 5| Step: 9
Training loss: 3.0858205266101804
Validation loss: 3.0673626719376275

Epoch: 5| Step: 10
Training loss: 3.065281286229454
Validation loss: 3.0649500178094344

Epoch: 253| Step: 0
Training loss: 3.1296952642229265
Validation loss: 3.0641822321626497

Epoch: 5| Step: 1
Training loss: 3.1555176442365807
Validation loss: 3.067452472685937

Epoch: 5| Step: 2
Training loss: 3.423321283301293
Validation loss: 3.0646246462348996

Epoch: 5| Step: 3
Training loss: 2.94208525866442
Validation loss: 3.067392255066869

Epoch: 5| Step: 4
Training loss: 3.02579550253429
Validation loss: 3.0644551026593927

Epoch: 5| Step: 5
Training loss: 4.148617957836442
Validation loss: 3.0633639819799394

Epoch: 5| Step: 6
Training loss: 3.2899736968035445
Validation loss: 3.0662332398590504

Epoch: 5| Step: 7
Training loss: 3.0798005321861672
Validation loss: 3.0673343422050325

Epoch: 5| Step: 8
Training loss: 3.0339063822737455
Validation loss: 3.06779504817063

Epoch: 5| Step: 9
Training loss: 3.7197387406682374
Validation loss: 3.0716710461832277

Epoch: 5| Step: 10
Training loss: 3.5114896739887738
Validation loss: 3.0774750190631908

Epoch: 254| Step: 0
Training loss: 3.42866768588321
Validation loss: 3.076005618200374

Epoch: 5| Step: 1
Training loss: 3.3269978078520204
Validation loss: 3.0700235692980304

Epoch: 5| Step: 2
Training loss: 2.886516889191351
Validation loss: 3.0685833800461815

Epoch: 5| Step: 3
Training loss: 3.0673946269869576
Validation loss: 3.0635514136027457

Epoch: 5| Step: 4
Training loss: 3.561430921260327
Validation loss: 3.0633765894163814

Epoch: 5| Step: 5
Training loss: 2.913489073104885
Validation loss: 3.064622556590251

Epoch: 5| Step: 6
Training loss: 2.9687920818357925
Validation loss: 3.063503202358176

Epoch: 5| Step: 7
Training loss: 3.807675420135301
Validation loss: 3.05994814578206

Epoch: 5| Step: 8
Training loss: 3.2169732680652303
Validation loss: 3.0608909034491623

Epoch: 5| Step: 9
Training loss: 3.539895471225752
Validation loss: 3.0611190729565187

Epoch: 5| Step: 10
Training loss: 3.7956382715303185
Validation loss: 3.062218553319023

Epoch: 255| Step: 0
Training loss: 3.1709024977356974
Validation loss: 3.0606142943349144

Epoch: 5| Step: 1
Training loss: 3.5030920811517814
Validation loss: 3.062110680249733

Epoch: 5| Step: 2
Training loss: 3.000350772695804
Validation loss: 3.0578908215619722

Epoch: 5| Step: 3
Training loss: 3.480830831991814
Validation loss: 3.060738251638402

Epoch: 5| Step: 4
Training loss: 3.4174662018941557
Validation loss: 3.0595612848581633

Epoch: 5| Step: 5
Training loss: 2.808831004598931
Validation loss: 3.0626097595221387

Epoch: 5| Step: 6
Training loss: 3.464174294119605
Validation loss: 3.063748312659676

Epoch: 5| Step: 7
Training loss: 3.8114770236012743
Validation loss: 3.059252636434052

Epoch: 5| Step: 8
Training loss: 2.9369667056115234
Validation loss: 3.0575467104430136

Epoch: 5| Step: 9
Training loss: 3.505712343495877
Validation loss: 3.0578862625083687

Epoch: 5| Step: 10
Training loss: 3.383635458274095
Validation loss: 3.0599437942184733

Epoch: 256| Step: 0
Training loss: 3.7931310459854988
Validation loss: 3.0595976315538467

Epoch: 5| Step: 1
Training loss: 3.2534237947029667
Validation loss: 3.057146520946626

Epoch: 5| Step: 2
Training loss: 3.787235409398736
Validation loss: 3.0587956432314374

Epoch: 5| Step: 3
Training loss: 3.104428444562256
Validation loss: 3.059247590019625

Epoch: 5| Step: 4
Training loss: 3.2648244360183383
Validation loss: 3.057495266095847

Epoch: 5| Step: 5
Training loss: 3.4250448516359278
Validation loss: 3.0592626906902565

Epoch: 5| Step: 6
Training loss: 2.7141814158055193
Validation loss: 3.0579530480237938

Epoch: 5| Step: 7
Training loss: 3.3380961882192968
Validation loss: 3.060795767495783

Epoch: 5| Step: 8
Training loss: 2.9536238960407086
Validation loss: 3.0581804307759266

Epoch: 5| Step: 9
Training loss: 3.2506544481266366
Validation loss: 3.059282218378168

Epoch: 5| Step: 10
Training loss: 3.5414502844438602
Validation loss: 3.0582830440757465

Epoch: 257| Step: 0
Training loss: 3.499909263524595
Validation loss: 3.057538094382236

Epoch: 5| Step: 1
Training loss: 3.039900401893157
Validation loss: 3.0550082068560225

Epoch: 5| Step: 2
Training loss: 3.482663405638371
Validation loss: 3.056425176661949

Epoch: 5| Step: 3
Training loss: 3.319900594854731
Validation loss: 3.056042256254756

Epoch: 5| Step: 4
Training loss: 3.6814822216006187
Validation loss: 3.0567721439266

Epoch: 5| Step: 5
Training loss: 3.140365969475725
Validation loss: 3.0558285660836577

Epoch: 5| Step: 6
Training loss: 3.2130013397527444
Validation loss: 3.0585105229952276

Epoch: 5| Step: 7
Training loss: 3.14606744429847
Validation loss: 3.0559251435596555

Epoch: 5| Step: 8
Training loss: 3.5889478360411173
Validation loss: 3.055641894893487

Epoch: 5| Step: 9
Training loss: 3.0485523790762055
Validation loss: 3.0546951908597717

Epoch: 5| Step: 10
Training loss: 3.2927147528635983
Validation loss: 3.0539104252835507

Epoch: 258| Step: 0
Training loss: 3.5572162730026746
Validation loss: 3.0562647751238528

Epoch: 5| Step: 1
Training loss: 3.394733945284245
Validation loss: 3.0535685689778105

Epoch: 5| Step: 2
Training loss: 3.3721195220670865
Validation loss: 3.0533732199661974

Epoch: 5| Step: 3
Training loss: 2.5599193138579848
Validation loss: 3.0551894751395126

Epoch: 5| Step: 4
Training loss: 3.44214039483309
Validation loss: 3.0548496384270383

Epoch: 5| Step: 5
Training loss: 3.430583584800085
Validation loss: 3.0581941753401716

Epoch: 5| Step: 6
Training loss: 3.0123371127716507
Validation loss: 3.055530994039383

Epoch: 5| Step: 7
Training loss: 3.962163310382919
Validation loss: 3.056555310042582

Epoch: 5| Step: 8
Training loss: 2.9036847350019257
Validation loss: 3.061277783932874

Epoch: 5| Step: 9
Training loss: 3.360364049762471
Validation loss: 3.0602478509078446

Epoch: 5| Step: 10
Training loss: 3.306191248813424
Validation loss: 3.055924867558848

Epoch: 259| Step: 0
Training loss: 3.2444860192978093
Validation loss: 3.056519817916324

Epoch: 5| Step: 1
Training loss: 3.319729096264183
Validation loss: 3.0523440935496104

Epoch: 5| Step: 2
Training loss: 3.167567442888789
Validation loss: 3.0505215086517907

Epoch: 5| Step: 3
Training loss: 3.1620630799286333
Validation loss: 3.0497884169628375

Epoch: 5| Step: 4
Training loss: 2.893169705763922
Validation loss: 3.0499726364680786

Epoch: 5| Step: 5
Training loss: 3.672991254239948
Validation loss: 3.049424242209641

Epoch: 5| Step: 6
Training loss: 3.6072481833354297
Validation loss: 3.0530217980513

Epoch: 5| Step: 7
Training loss: 2.9669887739328495
Validation loss: 3.0514268520134884

Epoch: 5| Step: 8
Training loss: 4.106940531041653
Validation loss: 3.0524023193754433

Epoch: 5| Step: 9
Training loss: 2.700545916292148
Validation loss: 3.0511291624008146

Epoch: 5| Step: 10
Training loss: 3.4299777870459898
Validation loss: 3.0543505619167033

Epoch: 260| Step: 0
Training loss: 3.3177330858553846
Validation loss: 3.048575469438198

Epoch: 5| Step: 1
Training loss: 2.9730583650805267
Validation loss: 3.0473950880587672

Epoch: 5| Step: 2
Training loss: 2.875814902873761
Validation loss: 3.048132964828465

Epoch: 5| Step: 3
Training loss: 3.719042341778513
Validation loss: 3.0471073488001164

Epoch: 5| Step: 4
Training loss: 3.1300200766995077
Validation loss: 3.047516728783395

Epoch: 5| Step: 5
Training loss: 3.299935606125919
Validation loss: 3.0450820228759556

Epoch: 5| Step: 6
Training loss: 3.916604197118934
Validation loss: 3.043236778296526

Epoch: 5| Step: 7
Training loss: 3.6135785614590454
Validation loss: 3.045658439376782

Epoch: 5| Step: 8
Training loss: 3.3177639863253563
Validation loss: 3.0437166136228124

Epoch: 5| Step: 9
Training loss: 3.2560080235169173
Validation loss: 3.0456261704109733

Epoch: 5| Step: 10
Training loss: 2.7625477368126954
Validation loss: 3.0419194707411057

Epoch: 261| Step: 0
Training loss: 2.9351355593827564
Validation loss: 3.043767791390813

Epoch: 5| Step: 1
Training loss: 3.5189680015017557
Validation loss: 3.0442150334049702

Epoch: 5| Step: 2
Training loss: 3.7919984749175275
Validation loss: 3.0454666892255786

Epoch: 5| Step: 3
Training loss: 3.104206639657601
Validation loss: 3.0464105420881036

Epoch: 5| Step: 4
Training loss: 3.584753701276549
Validation loss: 3.0462537680670985

Epoch: 5| Step: 5
Training loss: 3.826824605741731
Validation loss: 3.044479886878061

Epoch: 5| Step: 6
Training loss: 3.6680411594706515
Validation loss: 3.0418523433132996

Epoch: 5| Step: 7
Training loss: 3.049212532320557
Validation loss: 3.045171707833376

Epoch: 5| Step: 8
Training loss: 2.528019480159405
Validation loss: 3.04216281442167

Epoch: 5| Step: 9
Training loss: 3.031078373091135
Validation loss: 3.043949986760915

Epoch: 5| Step: 10
Training loss: 3.073464210134317
Validation loss: 3.0506623386639484

Epoch: 262| Step: 0
Training loss: 3.4580164997861083
Validation loss: 3.0439826036380104

Epoch: 5| Step: 1
Training loss: 2.2189566287684004
Validation loss: 3.0456418655480144

Epoch: 5| Step: 2
Training loss: 3.0656742072555163
Validation loss: 3.042867052526998

Epoch: 5| Step: 3
Training loss: 3.6876082323645543
Validation loss: 3.0429748461799413

Epoch: 5| Step: 4
Training loss: 3.811948642572888
Validation loss: 3.0415951653972857

Epoch: 5| Step: 5
Training loss: 2.912405898248028
Validation loss: 3.043488002010061

Epoch: 5| Step: 6
Training loss: 3.411178942394927
Validation loss: 3.042977907744974

Epoch: 5| Step: 7
Training loss: 3.5882766839880187
Validation loss: 3.0443329856287615

Epoch: 5| Step: 8
Training loss: 3.606513668582833
Validation loss: 3.044201697322734

Epoch: 5| Step: 9
Training loss: 3.0855130060589735
Validation loss: 3.0418655379941093

Epoch: 5| Step: 10
Training loss: 3.2561415817164807
Validation loss: 3.043307425005422

Epoch: 263| Step: 0
Training loss: 3.8224554935755903
Validation loss: 3.0431269097349944

Epoch: 5| Step: 1
Training loss: 3.209422104293898
Validation loss: 3.0440658998190737

Epoch: 5| Step: 2
Training loss: 2.958632727145386
Validation loss: 3.041657498512043

Epoch: 5| Step: 3
Training loss: 3.2174508148678433
Validation loss: 3.0414382274532112

Epoch: 5| Step: 4
Training loss: 3.308264850000529
Validation loss: 3.0471853017756962

Epoch: 5| Step: 5
Training loss: 3.623572495986108
Validation loss: 3.0484512345359245

Epoch: 5| Step: 6
Training loss: 4.147623848011621
Validation loss: 3.0413838486973486

Epoch: 5| Step: 7
Training loss: 3.074647749907417
Validation loss: 3.052864750521799

Epoch: 5| Step: 8
Training loss: 2.738669897080658
Validation loss: 3.050296749544294

Epoch: 5| Step: 9
Training loss: 2.9632411239003185
Validation loss: 3.0544879085352536

Epoch: 5| Step: 10
Training loss: 3.0366216826081796
Validation loss: 3.0551325443388113

Epoch: 264| Step: 0
Training loss: 3.6167892335670304
Validation loss: 3.045229096771835

Epoch: 5| Step: 1
Training loss: 3.683228815474422
Validation loss: 3.042581206377443

Epoch: 5| Step: 2
Training loss: 2.599035095018992
Validation loss: 3.0433248606681604

Epoch: 5| Step: 3
Training loss: 3.168682126253173
Validation loss: 3.042065159553459

Epoch: 5| Step: 4
Training loss: 3.2245996152752063
Validation loss: 3.0381288259112935

Epoch: 5| Step: 5
Training loss: 3.626748551210979
Validation loss: 3.03775299124666

Epoch: 5| Step: 6
Training loss: 2.711730753026635
Validation loss: 3.0392948800646495

Epoch: 5| Step: 7
Training loss: 3.226083937062042
Validation loss: 3.0418776083462915

Epoch: 5| Step: 8
Training loss: 3.5279794586950364
Validation loss: 3.0373499836420166

Epoch: 5| Step: 9
Training loss: 3.615075172286427
Validation loss: 3.0360248367188816

Epoch: 5| Step: 10
Training loss: 3.1110186809100315
Validation loss: 3.0371351049139372

Epoch: 265| Step: 0
Training loss: 3.1859328961678206
Validation loss: 3.034655780596329

Epoch: 5| Step: 1
Training loss: 3.9285635886176022
Validation loss: 3.0371269990269663

Epoch: 5| Step: 2
Training loss: 3.110114848233367
Validation loss: 3.0345098526411753

Epoch: 5| Step: 3
Training loss: 2.8218839288276687
Validation loss: 3.0342944914365413

Epoch: 5| Step: 4
Training loss: 3.4772254568911345
Validation loss: 3.0381896935741746

Epoch: 5| Step: 5
Training loss: 3.0536570652527386
Validation loss: 3.0358601382651895

Epoch: 5| Step: 6
Training loss: 3.0825532149697135
Validation loss: 3.035006169116931

Epoch: 5| Step: 7
Training loss: 3.4672081072118845
Validation loss: 3.0333254371070613

Epoch: 5| Step: 8
Training loss: 3.5842524539981415
Validation loss: 3.0394473124453407

Epoch: 5| Step: 9
Training loss: 3.3223744172185765
Validation loss: 3.036992813615354

Epoch: 5| Step: 10
Training loss: 3.1519806947068516
Validation loss: 3.0435812051022775

Epoch: 266| Step: 0
Training loss: 3.8602767076286706
Validation loss: 3.0380812761566327

Epoch: 5| Step: 1
Training loss: 3.008639293832118
Validation loss: 3.0350470974705708

Epoch: 5| Step: 2
Training loss: 3.255602775581359
Validation loss: 3.037503519667664

Epoch: 5| Step: 3
Training loss: 2.9549875995614623
Validation loss: 3.042790663028934

Epoch: 5| Step: 4
Training loss: 3.0030009836556686
Validation loss: 3.0375058085837887

Epoch: 5| Step: 5
Training loss: 2.9449631056231325
Validation loss: 3.034807346130972

Epoch: 5| Step: 6
Training loss: 3.7061578748810042
Validation loss: 3.0364043942070658

Epoch: 5| Step: 7
Training loss: 3.5155764428070295
Validation loss: 3.0348898884955657

Epoch: 5| Step: 8
Training loss: 3.2607375079518683
Validation loss: 3.041908998454223

Epoch: 5| Step: 9
Training loss: 3.408264964070079
Validation loss: 3.0375141700337474

Epoch: 5| Step: 10
Training loss: 3.2662151478755828
Validation loss: 3.033425721951398

Epoch: 267| Step: 0
Training loss: 3.2239021620943826
Validation loss: 3.0326652846870776

Epoch: 5| Step: 1
Training loss: 3.0407612816123746
Validation loss: 3.0355473478072144

Epoch: 5| Step: 2
Training loss: 3.238574411630143
Validation loss: 3.036167200401882

Epoch: 5| Step: 3
Training loss: 3.363187959199035
Validation loss: 3.034850666073811

Epoch: 5| Step: 4
Training loss: 3.450450154666261
Validation loss: 3.0361632791570976

Epoch: 5| Step: 5
Training loss: 3.826438563478855
Validation loss: 3.0347564227398767

Epoch: 5| Step: 6
Training loss: 3.3772446973695356
Validation loss: 3.0349502517853986

Epoch: 5| Step: 7
Training loss: 3.34600725367205
Validation loss: 3.0328133157495483

Epoch: 5| Step: 8
Training loss: 2.808054313797338
Validation loss: 3.029713252869966

Epoch: 5| Step: 9
Training loss: 3.668639230436891
Validation loss: 3.0321017727187343

Epoch: 5| Step: 10
Training loss: 2.8006910152610316
Validation loss: 3.031745759312384

Epoch: 268| Step: 0
Training loss: 3.3000221598488038
Validation loss: 3.0307153624200014

Epoch: 5| Step: 1
Training loss: 3.034582606716262
Validation loss: 3.031876900397004

Epoch: 5| Step: 2
Training loss: 2.628371480480698
Validation loss: 3.0327056647353543

Epoch: 5| Step: 3
Training loss: 3.871302655816216
Validation loss: 3.0330708925909065

Epoch: 5| Step: 4
Training loss: 3.3435001458198945
Validation loss: 3.0309711391882534

Epoch: 5| Step: 5
Training loss: 3.544825159019838
Validation loss: 3.0355382664568578

Epoch: 5| Step: 6
Training loss: 3.730887216794214
Validation loss: 3.035332729137277

Epoch: 5| Step: 7
Training loss: 2.9977939759987144
Validation loss: 3.0374135686245807

Epoch: 5| Step: 8
Training loss: 3.252051512916666
Validation loss: 3.0338194443959714

Epoch: 5| Step: 9
Training loss: 2.9701806084790303
Validation loss: 3.030490860107597

Epoch: 5| Step: 10
Training loss: 3.4662225811737435
Validation loss: 3.028667478477265

Epoch: 269| Step: 0
Training loss: 3.4842378734753403
Validation loss: 3.031588237072024

Epoch: 5| Step: 1
Training loss: 3.651007912879295
Validation loss: 3.0286633045886577

Epoch: 5| Step: 2
Training loss: 2.983157403827076
Validation loss: 3.0278217164092434

Epoch: 5| Step: 3
Training loss: 3.7507164588612865
Validation loss: 3.0291348075847284

Epoch: 5| Step: 4
Training loss: 2.5275661836405203
Validation loss: 3.0292817078888232

Epoch: 5| Step: 5
Training loss: 3.2091846740212158
Validation loss: 3.02962910725253

Epoch: 5| Step: 6
Training loss: 3.7123992289728647
Validation loss: 3.0291854632581616

Epoch: 5| Step: 7
Training loss: 2.9929966243440638
Validation loss: 3.0294775128243594

Epoch: 5| Step: 8
Training loss: 3.3631476930690254
Validation loss: 3.0300130245335337

Epoch: 5| Step: 9
Training loss: 2.8818097942307905
Validation loss: 3.0298700239297327

Epoch: 5| Step: 10
Training loss: 3.5818312993709407
Validation loss: 3.030287371247255

Epoch: 270| Step: 0
Training loss: 3.338678239160455
Validation loss: 3.028908409855026

Epoch: 5| Step: 1
Training loss: 3.841128315858714
Validation loss: 3.028772442562684

Epoch: 5| Step: 2
Training loss: 2.5141925405912233
Validation loss: 3.0271277163694017

Epoch: 5| Step: 3
Training loss: 3.017710700718341
Validation loss: 3.0262873081487043

Epoch: 5| Step: 4
Training loss: 3.697025732609678
Validation loss: 3.026268795891124

Epoch: 5| Step: 5
Training loss: 3.0515037394236155
Validation loss: 3.0280144924979218

Epoch: 5| Step: 6
Training loss: 2.8953579482717857
Validation loss: 3.0259672265931292

Epoch: 5| Step: 7
Training loss: 3.844705354391278
Validation loss: 3.0272305023679604

Epoch: 5| Step: 8
Training loss: 2.923152868542987
Validation loss: 3.027968377315255

Epoch: 5| Step: 9
Training loss: 2.9102340790242898
Validation loss: 3.024404645108328

Epoch: 5| Step: 10
Training loss: 4.0134984185451055
Validation loss: 3.02749866143499

Epoch: 271| Step: 0
Training loss: 3.3306831951214826
Validation loss: 3.0257189091073613

Epoch: 5| Step: 1
Training loss: 3.452923660967859
Validation loss: 3.0239614605190246

Epoch: 5| Step: 2
Training loss: 3.7404117074067877
Validation loss: 3.031581534500121

Epoch: 5| Step: 3
Training loss: 3.519157974144506
Validation loss: 3.0348896545073454

Epoch: 5| Step: 4
Training loss: 3.391208440270779
Validation loss: 3.0282619250175236

Epoch: 5| Step: 5
Training loss: 2.6609539790827625
Validation loss: 3.0352454258500043

Epoch: 5| Step: 6
Training loss: 3.4849499967865447
Validation loss: 3.030569661767886

Epoch: 5| Step: 7
Training loss: 2.307527918951518
Validation loss: 3.0262049547148075

Epoch: 5| Step: 8
Training loss: 2.6768163307916226
Validation loss: 3.0264723143771723

Epoch: 5| Step: 9
Training loss: 3.510865240367814
Validation loss: 3.0228115005118266

Epoch: 5| Step: 10
Training loss: 3.9100611291189895
Validation loss: 3.0233373078191703

Epoch: 272| Step: 0
Training loss: 3.8960178487944583
Validation loss: 3.023547044512914

Epoch: 5| Step: 1
Training loss: 3.7995126612517947
Validation loss: 3.024006916207624

Epoch: 5| Step: 2
Training loss: 3.665585329535444
Validation loss: 3.022236725416296

Epoch: 5| Step: 3
Training loss: 3.140650051643323
Validation loss: 3.022046125703709

Epoch: 5| Step: 4
Training loss: 3.3737065697807704
Validation loss: 3.0232756459198034

Epoch: 5| Step: 5
Training loss: 2.7793145464015683
Validation loss: 3.0233979102400177

Epoch: 5| Step: 6
Training loss: 3.060065411136594
Validation loss: 3.0238243076689253

Epoch: 5| Step: 7
Training loss: 3.257221708084243
Validation loss: 3.023491247632686

Epoch: 5| Step: 8
Training loss: 2.6770939412383057
Validation loss: 3.019543353596428

Epoch: 5| Step: 9
Training loss: 2.8716381153791373
Validation loss: 3.0242264788075532

Epoch: 5| Step: 10
Training loss: 3.5251855679629434
Validation loss: 3.0210813670157046

Epoch: 273| Step: 0
Training loss: 2.8657718666571546
Validation loss: 3.0246774926132622

Epoch: 5| Step: 1
Training loss: 2.784116061208486
Validation loss: 3.0220243324673848

Epoch: 5| Step: 2
Training loss: 3.111064049576744
Validation loss: 3.0219218215583803

Epoch: 5| Step: 3
Training loss: 3.7790049043387866
Validation loss: 3.022945166295228

Epoch: 5| Step: 4
Training loss: 3.5354311335636135
Validation loss: 3.019495020426456

Epoch: 5| Step: 5
Training loss: 2.6657866774404777
Validation loss: 3.0249187977244083

Epoch: 5| Step: 6
Training loss: 3.8120073093932647
Validation loss: 3.022027050480213

Epoch: 5| Step: 7
Training loss: 3.610828982034458
Validation loss: 3.0269935077690695

Epoch: 5| Step: 8
Training loss: 3.353572358421894
Validation loss: 3.0258673071112114

Epoch: 5| Step: 9
Training loss: 3.3316605821267373
Validation loss: 3.028464060952047

Epoch: 5| Step: 10
Training loss: 3.12740218341183
Validation loss: 3.0241166638954793

Epoch: 274| Step: 0
Training loss: 3.5870185502409866
Validation loss: 3.022877432633869

Epoch: 5| Step: 1
Training loss: 3.791054616862203
Validation loss: 3.0190321016472725

Epoch: 5| Step: 2
Training loss: 3.306784106778853
Validation loss: 3.021012120088763

Epoch: 5| Step: 3
Training loss: 3.0006970549443603
Validation loss: 3.0211179662122922

Epoch: 5| Step: 4
Training loss: 3.0660383064479877
Validation loss: 3.0181951208315323

Epoch: 5| Step: 5
Training loss: 3.307330145824793
Validation loss: 3.02113570134631

Epoch: 5| Step: 6
Training loss: 3.2933463788514183
Validation loss: 3.0193446959946684

Epoch: 5| Step: 7
Training loss: 3.0610603529854066
Validation loss: 3.018555436577288

Epoch: 5| Step: 8
Training loss: 3.6080338269358667
Validation loss: 3.017171668094952

Epoch: 5| Step: 9
Training loss: 3.1573813648544076
Validation loss: 3.0189344458439806

Epoch: 5| Step: 10
Training loss: 2.8021803677194694
Validation loss: 3.018849622734837

Epoch: 275| Step: 0
Training loss: 3.4085737229116706
Validation loss: 3.0165715594594222

Epoch: 5| Step: 1
Training loss: 2.9503739071542445
Validation loss: 3.018751343631889

Epoch: 5| Step: 2
Training loss: 3.832791345400306
Validation loss: 3.0183290386139388

Epoch: 5| Step: 3
Training loss: 3.189039270072486
Validation loss: 3.0146988909871246

Epoch: 5| Step: 4
Training loss: 3.1937368374010195
Validation loss: 3.016690284905319

Epoch: 5| Step: 5
Training loss: 4.0798338601936015
Validation loss: 3.0163322604217693

Epoch: 5| Step: 6
Training loss: 2.9712600537083076
Validation loss: 3.019736334710736

Epoch: 5| Step: 7
Training loss: 2.2132729640257556
Validation loss: 3.0189372770329395

Epoch: 5| Step: 8
Training loss: 3.462391016377695
Validation loss: 3.0153126415370632

Epoch: 5| Step: 9
Training loss: 3.1891523080354216
Validation loss: 3.0165246387424847

Epoch: 5| Step: 10
Training loss: 3.341548301775778
Validation loss: 3.0145653400501695

Epoch: 276| Step: 0
Training loss: 2.877720085099243
Validation loss: 3.016180507666371

Epoch: 5| Step: 1
Training loss: 3.1430633341045455
Validation loss: 3.0230416367354165

Epoch: 5| Step: 2
Training loss: 3.6612670906373896
Validation loss: 3.021227403905396

Epoch: 5| Step: 3
Training loss: 3.593475065909934
Validation loss: 3.030928878596579

Epoch: 5| Step: 4
Training loss: 3.328128868423148
Validation loss: 3.0239302384793376

Epoch: 5| Step: 5
Training loss: 3.3211016984879005
Validation loss: 3.033756547153301

Epoch: 5| Step: 6
Training loss: 3.3726841080438246
Validation loss: 3.042904182482129

Epoch: 5| Step: 7
Training loss: 2.9926881694988534
Validation loss: 3.0355324399535606

Epoch: 5| Step: 8
Training loss: 3.748287572879635
Validation loss: 3.030605393512789

Epoch: 5| Step: 9
Training loss: 2.7808401255819493
Validation loss: 3.018678058533128

Epoch: 5| Step: 10
Training loss: 3.2196730984433564
Validation loss: 3.0163731021933105

Epoch: 277| Step: 0
Training loss: 3.1308890738122757
Validation loss: 3.0182978755236056

Epoch: 5| Step: 1
Training loss: 3.45008336394944
Validation loss: 3.011706654114026

Epoch: 5| Step: 2
Training loss: 3.4436701105893412
Validation loss: 3.012019684430187

Epoch: 5| Step: 3
Training loss: 3.456837863146746
Validation loss: 3.0163201303414064

Epoch: 5| Step: 4
Training loss: 3.5030795581875114
Validation loss: 3.014838072924274

Epoch: 5| Step: 5
Training loss: 2.8395515721859175
Validation loss: 3.012764823764367

Epoch: 5| Step: 6
Training loss: 3.3828860796883795
Validation loss: 3.0167230775415597

Epoch: 5| Step: 7
Training loss: 3.3611167473303527
Validation loss: 3.0143764562943205

Epoch: 5| Step: 8
Training loss: 3.086295037139906
Validation loss: 3.0107164278754777

Epoch: 5| Step: 9
Training loss: 3.0157233503837526
Validation loss: 3.0117827475793537

Epoch: 5| Step: 10
Training loss: 3.4576976758781903
Validation loss: 3.013895205062716

Epoch: 278| Step: 0
Training loss: 2.9314345376950692
Validation loss: 3.0130368764252045

Epoch: 5| Step: 1
Training loss: 3.370328425129709
Validation loss: 3.012066915340231

Epoch: 5| Step: 2
Training loss: 3.772748738172453
Validation loss: 3.0136831208380914

Epoch: 5| Step: 3
Training loss: 3.29381154996341
Validation loss: 3.009629063762462

Epoch: 5| Step: 4
Training loss: 3.0022368039557383
Validation loss: 3.0117592508606057

Epoch: 5| Step: 5
Training loss: 3.2514243305991766
Validation loss: 3.012864406016156

Epoch: 5| Step: 6
Training loss: 3.1280917323093624
Validation loss: 3.0119153400667407

Epoch: 5| Step: 7
Training loss: 3.854875049273039
Validation loss: 3.0229440095403732

Epoch: 5| Step: 8
Training loss: 2.674015726846399
Validation loss: 3.0200344592299375

Epoch: 5| Step: 9
Training loss: 3.308557143115817
Validation loss: 3.0250648968199125

Epoch: 5| Step: 10
Training loss: 3.370037103329847
Validation loss: 3.016888749348668

Epoch: 279| Step: 0
Training loss: 3.3540462369603627
Validation loss: 3.0109843011915047

Epoch: 5| Step: 1
Training loss: 2.592126545065801
Validation loss: 3.0118809697781264

Epoch: 5| Step: 2
Training loss: 3.2985981420072394
Validation loss: 3.0147240417308296

Epoch: 5| Step: 3
Training loss: 3.6932807482293706
Validation loss: 3.0101338636313226

Epoch: 5| Step: 4
Training loss: 2.930173787766465
Validation loss: 3.008725517596612

Epoch: 5| Step: 5
Training loss: 2.5516816634076536
Validation loss: 3.0111632884741026

Epoch: 5| Step: 6
Training loss: 3.4379220876780825
Validation loss: 3.011399707090231

Epoch: 5| Step: 7
Training loss: 3.5895160446605456
Validation loss: 3.0103512343241743

Epoch: 5| Step: 8
Training loss: 3.1422561281393184
Validation loss: 3.009312829525166

Epoch: 5| Step: 9
Training loss: 3.7570638882462153
Validation loss: 3.0115420626680796

Epoch: 5| Step: 10
Training loss: 3.5454562538427403
Validation loss: 3.0155143821644392

Epoch: 280| Step: 0
Training loss: 2.912584026909121
Validation loss: 3.0083851650930167

Epoch: 5| Step: 1
Training loss: 3.4529540420951577
Validation loss: 3.0096587186280574

Epoch: 5| Step: 2
Training loss: 3.2503744056424435
Validation loss: 3.0120656318458696

Epoch: 5| Step: 3
Training loss: 3.0795314306063326
Validation loss: 3.007373195487185

Epoch: 5| Step: 4
Training loss: 2.9507326800303386
Validation loss: 3.0095370393124323

Epoch: 5| Step: 5
Training loss: 3.539323068756818
Validation loss: 3.009007588511537

Epoch: 5| Step: 6
Training loss: 3.4245352659477355
Validation loss: 3.0074244103540764

Epoch: 5| Step: 7
Training loss: 3.2319862279598546
Validation loss: 3.0126790287558136

Epoch: 5| Step: 8
Training loss: 3.6745595655109855
Validation loss: 3.013710002644558

Epoch: 5| Step: 9
Training loss: 3.217316539783284
Validation loss: 3.0222068376976967

Epoch: 5| Step: 10
Training loss: 3.2662783612532045
Validation loss: 3.031344771819799

Epoch: 281| Step: 0
Training loss: 3.2449850858513143
Validation loss: 3.025398490325307

Epoch: 5| Step: 1
Training loss: 3.0584481352031356
Validation loss: 3.0108743489935748

Epoch: 5| Step: 2
Training loss: 4.019945484759645
Validation loss: 3.0100666720819858

Epoch: 5| Step: 3
Training loss: 3.434522553069277
Validation loss: 3.007208408633494

Epoch: 5| Step: 4
Training loss: 3.3174628741350896
Validation loss: 3.0065528766687537

Epoch: 5| Step: 5
Training loss: 3.540168774563238
Validation loss: 3.006672341343864

Epoch: 5| Step: 6
Training loss: 3.9189574799680287
Validation loss: 3.005358352594806

Epoch: 5| Step: 7
Training loss: 2.692434172750964
Validation loss: 3.0064881998638797

Epoch: 5| Step: 8
Training loss: 3.028667490327681
Validation loss: 3.0062339728563092

Epoch: 5| Step: 9
Training loss: 2.4449764910544807
Validation loss: 3.005891202648203

Epoch: 5| Step: 10
Training loss: 3.0999930227877948
Validation loss: 3.0074451313277017

Epoch: 282| Step: 0
Training loss: 3.1134143451494727
Validation loss: 3.0055950657626656

Epoch: 5| Step: 1
Training loss: 3.5469142558744484
Validation loss: 3.005738389676077

Epoch: 5| Step: 2
Training loss: 3.2498207042828304
Validation loss: 3.0075166648144114

Epoch: 5| Step: 3
Training loss: 3.5900166898461663
Validation loss: 3.00623625658641

Epoch: 5| Step: 4
Training loss: 2.815820895037049
Validation loss: 3.0042414420402572

Epoch: 5| Step: 5
Training loss: 2.7569702418412487
Validation loss: 3.0045924576199567

Epoch: 5| Step: 6
Training loss: 4.047386343328025
Validation loss: 3.0028184030720024

Epoch: 5| Step: 7
Training loss: 3.2982589926364674
Validation loss: 3.0081908234327766

Epoch: 5| Step: 8
Training loss: 3.3815255833715194
Validation loss: 3.0114440567123646

Epoch: 5| Step: 9
Training loss: 3.531485085553224
Validation loss: 3.0169841821799914

Epoch: 5| Step: 10
Training loss: 2.2963383884685307
Validation loss: 3.018976286708143

Epoch: 283| Step: 0
Training loss: 3.2325567027205744
Validation loss: 3.0215080158436107

Epoch: 5| Step: 1
Training loss: 2.5901707231377626
Validation loss: 3.021198347115987

Epoch: 5| Step: 2
Training loss: 3.7677766976004508
Validation loss: 3.0313233591955724

Epoch: 5| Step: 3
Training loss: 3.8813314088401447
Validation loss: 3.024422510155104

Epoch: 5| Step: 4
Training loss: 3.307044232741983
Validation loss: 3.0136164958659344

Epoch: 5| Step: 5
Training loss: 3.8206799414297645
Validation loss: 3.013567785205718

Epoch: 5| Step: 6
Training loss: 2.7499583848058613
Validation loss: 3.002830139479009

Epoch: 5| Step: 7
Training loss: 3.5350005900640142
Validation loss: 3.0014069874276297

Epoch: 5| Step: 8
Training loss: 3.3271141845444787
Validation loss: 3.0015680212862725

Epoch: 5| Step: 9
Training loss: 3.099140134121536
Validation loss: 3.002691107876011

Epoch: 5| Step: 10
Training loss: 2.179173672180391
Validation loss: 3.0039290520067317

Epoch: 284| Step: 0
Training loss: 3.239295791343532
Validation loss: 3.000853340239037

Epoch: 5| Step: 1
Training loss: 3.3378806250764486
Validation loss: 3.001990066710829

Epoch: 5| Step: 2
Training loss: 2.9382920516286433
Validation loss: 3.0011140094931843

Epoch: 5| Step: 3
Training loss: 3.014095570811475
Validation loss: 3.003646752540301

Epoch: 5| Step: 4
Training loss: 2.9173575173490827
Validation loss: 3.0018788798214575

Epoch: 5| Step: 5
Training loss: 3.2726808096737505
Validation loss: 3.0029074652638506

Epoch: 5| Step: 6
Training loss: 3.675246358905076
Validation loss: 3.006435147643999

Epoch: 5| Step: 7
Training loss: 3.9072398648158337
Validation loss: 3.003107619957966

Epoch: 5| Step: 8
Training loss: 3.1828028158603288
Validation loss: 3.0004410470781986

Epoch: 5| Step: 9
Training loss: 3.4645100016736534
Validation loss: 3.0037172686563736

Epoch: 5| Step: 10
Training loss: 2.8827777643359545
Validation loss: 3.0095615176546975

Epoch: 285| Step: 0
Training loss: 3.378300783451894
Validation loss: 3.003678480729897

Epoch: 5| Step: 1
Training loss: 3.2001617867579415
Validation loss: 3.0110678150428636

Epoch: 5| Step: 2
Training loss: 2.5629408852513014
Validation loss: 3.010420079269601

Epoch: 5| Step: 3
Training loss: 3.1968178782202763
Validation loss: 3.0087914005260377

Epoch: 5| Step: 4
Training loss: 3.6780454045242155
Validation loss: 3.0108066639332205

Epoch: 5| Step: 5
Training loss: 2.931532784752477
Validation loss: 3.0088423935807844

Epoch: 5| Step: 6
Training loss: 3.3775169029914087
Validation loss: 3.005875557522338

Epoch: 5| Step: 7
Training loss: 3.9858721145656286
Validation loss: 3.0017055906575103

Epoch: 5| Step: 8
Training loss: 3.57659652913755
Validation loss: 3.0015531428193385

Epoch: 5| Step: 9
Training loss: 2.930508999407009
Validation loss: 2.997062542197907

Epoch: 5| Step: 10
Training loss: 2.8921221181114287
Validation loss: 2.9970537385684195

Epoch: 286| Step: 0
Training loss: 3.614542247234559
Validation loss: 3.002045236752724

Epoch: 5| Step: 1
Training loss: 2.8229744730493547
Validation loss: 3.0009257262418942

Epoch: 5| Step: 2
Training loss: 3.3088181384672244
Validation loss: 2.9994649495407995

Epoch: 5| Step: 3
Training loss: 2.8306054465809725
Validation loss: 2.9964127012041546

Epoch: 5| Step: 4
Training loss: 3.2915810843500535
Validation loss: 2.998050830706582

Epoch: 5| Step: 5
Training loss: 3.372121925964323
Validation loss: 2.995427281936839

Epoch: 5| Step: 6
Training loss: 3.1071501013008946
Validation loss: 2.9981878423529507

Epoch: 5| Step: 7
Training loss: 3.517177120483213
Validation loss: 2.996560362092962

Epoch: 5| Step: 8
Training loss: 2.943670568994127
Validation loss: 2.9968138391204104

Epoch: 5| Step: 9
Training loss: 3.4496418919119827
Validation loss: 2.996700987455463

Epoch: 5| Step: 10
Training loss: 3.681438183467685
Validation loss: 2.9967095025395234

Epoch: 287| Step: 0
Training loss: 3.193528253131988
Validation loss: 2.996997842787393

Epoch: 5| Step: 1
Training loss: 3.5120939026793963
Validation loss: 2.997694217235413

Epoch: 5| Step: 2
Training loss: 3.405777084698759
Validation loss: 2.9971460522163866

Epoch: 5| Step: 3
Training loss: 3.1110763112649873
Validation loss: 2.997508571459614

Epoch: 5| Step: 4
Training loss: 3.4026601931092837
Validation loss: 2.9990922689401907

Epoch: 5| Step: 5
Training loss: 3.2402246623385174
Validation loss: 2.996494754371373

Epoch: 5| Step: 6
Training loss: 3.153464117046522
Validation loss: 2.998598310518396

Epoch: 5| Step: 7
Training loss: 2.8547049986955986
Validation loss: 2.999346350828658

Epoch: 5| Step: 8
Training loss: 2.6970174068897674
Validation loss: 2.9943410181058923

Epoch: 5| Step: 9
Training loss: 4.076780134001137
Validation loss: 2.995421308943957

Epoch: 5| Step: 10
Training loss: 3.088515506181147
Validation loss: 2.9962661282216705

Epoch: 288| Step: 0
Training loss: 2.7554555876947204
Validation loss: 3.002826108109053

Epoch: 5| Step: 1
Training loss: 2.948129293549035
Validation loss: 2.9931563651377657

Epoch: 5| Step: 2
Training loss: 3.825001715366752
Validation loss: 2.9950024867745526

Epoch: 5| Step: 3
Training loss: 3.2942384419212045
Validation loss: 2.9927153957967727

Epoch: 5| Step: 4
Training loss: 3.4709339311972403
Validation loss: 2.997246312487136

Epoch: 5| Step: 5
Training loss: 3.2535693302180677
Validation loss: 2.9944876339506985

Epoch: 5| Step: 6
Training loss: 3.0017504353742552
Validation loss: 2.996382922088841

Epoch: 5| Step: 7
Training loss: 3.8247880365819324
Validation loss: 2.993111976657882

Epoch: 5| Step: 8
Training loss: 3.1134331832437705
Validation loss: 2.996525293804043

Epoch: 5| Step: 9
Training loss: 3.1938552331477355
Validation loss: 2.995017985833762

Epoch: 5| Step: 10
Training loss: 3.1257036561304505
Validation loss: 2.993517897103735

Epoch: 289| Step: 0
Training loss: 2.9895937362294958
Validation loss: 2.996144396147738

Epoch: 5| Step: 1
Training loss: 3.280010897688091
Validation loss: 2.9932467220322767

Epoch: 5| Step: 2
Training loss: 3.2916332355845754
Validation loss: 2.992354078723601

Epoch: 5| Step: 3
Training loss: 3.0380438737645736
Validation loss: 2.993857925754006

Epoch: 5| Step: 4
Training loss: 3.221209873102003
Validation loss: 2.9929267156325006

Epoch: 5| Step: 5
Training loss: 3.073811408349035
Validation loss: 2.9951814268207295

Epoch: 5| Step: 6
Training loss: 2.7873553011847494
Validation loss: 2.9993217292856222

Epoch: 5| Step: 7
Training loss: 3.4019129028115094
Validation loss: 3.0047533327043108

Epoch: 5| Step: 8
Training loss: 3.546477442571909
Validation loss: 3.0125935427606474

Epoch: 5| Step: 9
Training loss: 3.5847237720771075
Validation loss: 3.001170732370036

Epoch: 5| Step: 10
Training loss: 3.728554886800552
Validation loss: 2.9929139099365596

Epoch: 290| Step: 0
Training loss: 2.8992221315200233
Validation loss: 2.996693977153852

Epoch: 5| Step: 1
Training loss: 2.9459851050948846
Validation loss: 2.9937131750100234

Epoch: 5| Step: 2
Training loss: 3.2552302896394942
Validation loss: 2.992494020644791

Epoch: 5| Step: 3
Training loss: 2.586177019626317
Validation loss: 2.992906916889907

Epoch: 5| Step: 4
Training loss: 3.7593909614458796
Validation loss: 2.9933774155332236

Epoch: 5| Step: 5
Training loss: 3.80169785866546
Validation loss: 2.99217396287585

Epoch: 5| Step: 6
Training loss: 3.284421133194673
Validation loss: 2.993397510058566

Epoch: 5| Step: 7
Training loss: 3.4738190874200723
Validation loss: 2.991339253440091

Epoch: 5| Step: 8
Training loss: 2.9818868600629065
Validation loss: 2.992146734221665

Epoch: 5| Step: 9
Training loss: 3.386205508931533
Validation loss: 2.9939563729499814

Epoch: 5| Step: 10
Training loss: 3.435935340592702
Validation loss: 2.9915217882072263

Epoch: 291| Step: 0
Training loss: 2.935137833798194
Validation loss: 2.990872558801543

Epoch: 5| Step: 1
Training loss: 3.302291253861414
Validation loss: 2.9932440780931455

Epoch: 5| Step: 2
Training loss: 3.291211076586698
Validation loss: 2.992167302245576

Epoch: 5| Step: 3
Training loss: 3.416333314093969
Validation loss: 2.9991241718222366

Epoch: 5| Step: 4
Training loss: 3.2660948492925304
Validation loss: 3.0021084644866356

Epoch: 5| Step: 5
Training loss: 3.269811693421658
Validation loss: 3.0100056164343356

Epoch: 5| Step: 6
Training loss: 3.2190551613154748
Validation loss: 2.998120826866507

Epoch: 5| Step: 7
Training loss: 3.682607476245151
Validation loss: 2.9985710008432584

Epoch: 5| Step: 8
Training loss: 2.793052746770142
Validation loss: 2.994240121153073

Epoch: 5| Step: 9
Training loss: 3.4248562023855897
Validation loss: 2.990633145896216

Epoch: 5| Step: 10
Training loss: 3.253762048500431
Validation loss: 2.9919832808344013

Epoch: 292| Step: 0
Training loss: 3.2546891350268186
Validation loss: 2.9891146117723864

Epoch: 5| Step: 1
Training loss: 2.973479027991828
Validation loss: 2.9902121132866406

Epoch: 5| Step: 2
Training loss: 3.4377378901615865
Validation loss: 2.9905993968215565

Epoch: 5| Step: 3
Training loss: 2.413406925010214
Validation loss: 2.9903972510080714

Epoch: 5| Step: 4
Training loss: 3.6331667491509703
Validation loss: 2.9874095078730534

Epoch: 5| Step: 5
Training loss: 2.8209925964864127
Validation loss: 2.9862713914727608

Epoch: 5| Step: 6
Training loss: 3.6349747324489057
Validation loss: 2.988775029044115

Epoch: 5| Step: 7
Training loss: 3.643895460729238
Validation loss: 2.9863143793208216

Epoch: 5| Step: 8
Training loss: 3.3249013269454086
Validation loss: 2.987469530458649

Epoch: 5| Step: 9
Training loss: 3.606165660486776
Validation loss: 2.9884248861330494

Epoch: 5| Step: 10
Training loss: 2.8392890902736503
Validation loss: 2.986797169118231

Epoch: 293| Step: 0
Training loss: 3.4269249289098513
Validation loss: 2.984108421868192

Epoch: 5| Step: 1
Training loss: 2.9623929676406138
Validation loss: 2.9856945647487674

Epoch: 5| Step: 2
Training loss: 3.2214079317598348
Validation loss: 2.985204626761985

Epoch: 5| Step: 3
Training loss: 3.091814456776447
Validation loss: 2.9852401337601955

Epoch: 5| Step: 4
Training loss: 3.454524658450816
Validation loss: 2.9882611287915637

Epoch: 5| Step: 5
Training loss: 3.0624638769393826
Validation loss: 2.99013883604812

Epoch: 5| Step: 6
Training loss: 3.0854921430018853
Validation loss: 2.9918652158534043

Epoch: 5| Step: 7
Training loss: 3.105841541107144
Validation loss: 2.986904268047838

Epoch: 5| Step: 8
Training loss: 3.5278620038194752
Validation loss: 2.9867028223360172

Epoch: 5| Step: 9
Training loss: 3.6010236026633424
Validation loss: 2.9919057935311746

Epoch: 5| Step: 10
Training loss: 3.2819173951571745
Validation loss: 2.9894129292329117

Epoch: 294| Step: 0
Training loss: 3.9718319197988854
Validation loss: 2.9887280081889247

Epoch: 5| Step: 1
Training loss: 3.828946021651226
Validation loss: 2.985497663221674

Epoch: 5| Step: 2
Training loss: 3.2667148359471128
Validation loss: 2.984893376697716

Epoch: 5| Step: 3
Training loss: 2.5167118354769165
Validation loss: 2.9839639894474654

Epoch: 5| Step: 4
Training loss: 2.931002309131266
Validation loss: 2.9835252042130005

Epoch: 5| Step: 5
Training loss: 3.1442817920752706
Validation loss: 2.983545420946021

Epoch: 5| Step: 6
Training loss: 3.6373959084001015
Validation loss: 2.985573806430098

Epoch: 5| Step: 7
Training loss: 2.9272996453738984
Validation loss: 2.9831712293647157

Epoch: 5| Step: 8
Training loss: 2.8285488422257172
Validation loss: 2.9856824767722028

Epoch: 5| Step: 9
Training loss: 3.3695711341795263
Validation loss: 2.9827720143814327

Epoch: 5| Step: 10
Training loss: 3.1310905613919404
Validation loss: 2.983003910961166

Epoch: 295| Step: 0
Training loss: 2.8530373299740726
Validation loss: 2.987257174928062

Epoch: 5| Step: 1
Training loss: 3.2506409526566262
Validation loss: 2.9848968267835922

Epoch: 5| Step: 2
Training loss: 2.519282554949882
Validation loss: 2.987127609134089

Epoch: 5| Step: 3
Training loss: 3.0842257230708734
Validation loss: 2.9830029552906647

Epoch: 5| Step: 4
Training loss: 4.1553903708943505
Validation loss: 2.981880846191432

Epoch: 5| Step: 5
Training loss: 3.6509410428897953
Validation loss: 2.983157673669734

Epoch: 5| Step: 6
Training loss: 2.787115534111975
Validation loss: 2.9818879656854205

Epoch: 5| Step: 7
Training loss: 2.5720906237926284
Validation loss: 2.988238622458014

Epoch: 5| Step: 8
Training loss: 3.8497651957460897
Validation loss: 2.9865374597888774

Epoch: 5| Step: 9
Training loss: 3.7459711685252417
Validation loss: 2.987038260971416

Epoch: 5| Step: 10
Training loss: 2.847459323180573
Validation loss: 2.9870779429877596

Epoch: 296| Step: 0
Training loss: 3.7166801269926144
Validation loss: 2.9846049081004313

Epoch: 5| Step: 1
Training loss: 3.4323857496658614
Validation loss: 2.9892455674083216

Epoch: 5| Step: 2
Training loss: 3.16067813670967
Validation loss: 2.986021390385658

Epoch: 5| Step: 3
Training loss: 3.098544326610437
Validation loss: 2.9835104712082967

Epoch: 5| Step: 4
Training loss: 3.354963662054487
Validation loss: 2.9789494501895883

Epoch: 5| Step: 5
Training loss: 2.7641848677767284
Validation loss: 2.981283389494183

Epoch: 5| Step: 6
Training loss: 3.4773916563026437
Validation loss: 2.9792786919989775

Epoch: 5| Step: 7
Training loss: 2.6921104096873103
Validation loss: 2.9798549591600065

Epoch: 5| Step: 8
Training loss: 2.9947551338068363
Validation loss: 2.980035256100648

Epoch: 5| Step: 9
Training loss: 3.6969105529365427
Validation loss: 2.9793242270806033

Epoch: 5| Step: 10
Training loss: 3.275397612917412
Validation loss: 2.979532130054096

Epoch: 297| Step: 0
Training loss: 3.24025159282835
Validation loss: 2.980192537184837

Epoch: 5| Step: 1
Training loss: 3.4494240376780914
Validation loss: 2.9787824764368436

Epoch: 5| Step: 2
Training loss: 2.5346831598857285
Validation loss: 2.982362676615965

Epoch: 5| Step: 3
Training loss: 3.6578317464903063
Validation loss: 2.9840934168303095

Epoch: 5| Step: 4
Training loss: 3.0092009275167997
Validation loss: 2.9834135577419847

Epoch: 5| Step: 5
Training loss: 3.1871258385157413
Validation loss: 2.979493944494919

Epoch: 5| Step: 6
Training loss: 3.0230829390777503
Validation loss: 2.9805912461483297

Epoch: 5| Step: 7
Training loss: 3.5927548564856564
Validation loss: 2.9852431875518604

Epoch: 5| Step: 8
Training loss: 3.33654093589006
Validation loss: 2.9761355298972068

Epoch: 5| Step: 9
Training loss: 3.0196648453426485
Validation loss: 2.9771036057752314

Epoch: 5| Step: 10
Training loss: 3.6600218008257177
Validation loss: 2.977823707855345

Epoch: 298| Step: 0
Training loss: 3.1355781048922835
Validation loss: 2.9798172053242573

Epoch: 5| Step: 1
Training loss: 4.225830014653233
Validation loss: 2.9818814901362196

Epoch: 5| Step: 2
Training loss: 2.84394014163006
Validation loss: 2.978503614616958

Epoch: 5| Step: 3
Training loss: 3.05464878691901
Validation loss: 2.976202106693355

Epoch: 5| Step: 4
Training loss: 3.134760605282196
Validation loss: 2.976819684729654

Epoch: 5| Step: 5
Training loss: 3.458088892988305
Validation loss: 2.976580793437404

Epoch: 5| Step: 6
Training loss: 2.664116017092134
Validation loss: 2.9748757616054964

Epoch: 5| Step: 7
Training loss: 3.249792532534439
Validation loss: 2.978160856741894

Epoch: 5| Step: 8
Training loss: 3.8292959485456137
Validation loss: 2.979026345951902

Epoch: 5| Step: 9
Training loss: 3.3938302215030873
Validation loss: 2.981128511064327

Epoch: 5| Step: 10
Training loss: 2.2798851842581147
Validation loss: 2.9791851035959653

Epoch: 299| Step: 0
Training loss: 3.272444763416834
Validation loss: 2.978089678678336

Epoch: 5| Step: 1
Training loss: 2.733053792832366
Validation loss: 2.9767904519731476

Epoch: 5| Step: 2
Training loss: 3.130820080753884
Validation loss: 2.9835720252292695

Epoch: 5| Step: 3
Training loss: 3.1106360863780647
Validation loss: 2.976840691936

Epoch: 5| Step: 4
Training loss: 2.7426293172053415
Validation loss: 2.9755072313891433

Epoch: 5| Step: 5
Training loss: 3.566485935754078
Validation loss: 2.9785924407290123

Epoch: 5| Step: 6
Training loss: 3.0731062663579687
Validation loss: 2.9777799396887636

Epoch: 5| Step: 7
Training loss: 3.1097579030196334
Validation loss: 2.9778127777115766

Epoch: 5| Step: 8
Training loss: 3.5429791131756514
Validation loss: 2.9778269973937523

Epoch: 5| Step: 9
Training loss: 4.052102736922667
Validation loss: 2.977904504100143

Epoch: 5| Step: 10
Training loss: 3.2257466242995103
Validation loss: 2.9771625005691464

Epoch: 300| Step: 0
Training loss: 3.6874476283605513
Validation loss: 2.973565412595031

Epoch: 5| Step: 1
Training loss: 3.38985705138984
Validation loss: 2.9795702325249027

Epoch: 5| Step: 2
Training loss: 2.5879137491596587
Validation loss: 2.974897962285091

Epoch: 5| Step: 3
Training loss: 2.6214813991820205
Validation loss: 2.9765015899667793

Epoch: 5| Step: 4
Training loss: 3.336733149178352
Validation loss: 2.974434257521945

Epoch: 5| Step: 5
Training loss: 3.507655218799614
Validation loss: 2.976671864488359

Epoch: 5| Step: 6
Training loss: 2.630655825981055
Validation loss: 2.975457597014218

Epoch: 5| Step: 7
Training loss: 3.350407897257128
Validation loss: 2.971826502627259

Epoch: 5| Step: 8
Training loss: 2.883139987115217
Validation loss: 2.973272464157108

Epoch: 5| Step: 9
Training loss: 3.5524421726918827
Validation loss: 2.9754041431542664

Epoch: 5| Step: 10
Training loss: 3.9959696492215753
Validation loss: 2.977613404883516

Epoch: 301| Step: 0
Training loss: 3.452443603673759
Validation loss: 2.972089792745789

Epoch: 5| Step: 1
Training loss: 3.2298967254001307
Validation loss: 2.9738646070943444

Epoch: 5| Step: 2
Training loss: 3.291773894933583
Validation loss: 2.9739303994146002

Epoch: 5| Step: 3
Training loss: 2.712906531883936
Validation loss: 2.9767467719609124

Epoch: 5| Step: 4
Training loss: 3.3456344285672124
Validation loss: 2.974316736246969

Epoch: 5| Step: 5
Training loss: 3.506454646756222
Validation loss: 2.982340161873037

Epoch: 5| Step: 6
Training loss: 3.6663251775609305
Validation loss: 2.9734762293908155

Epoch: 5| Step: 7
Training loss: 2.870462070445065
Validation loss: 2.97292612640867

Epoch: 5| Step: 8
Training loss: 3.160672102085545
Validation loss: 2.9762492599776147

Epoch: 5| Step: 9
Training loss: 3.191173306838691
Validation loss: 2.9703993200524503

Epoch: 5| Step: 10
Training loss: 3.224060122722087
Validation loss: 2.9741694156710556

Epoch: 302| Step: 0
Training loss: 2.86362828835674
Validation loss: 2.96930395030389

Epoch: 5| Step: 1
Training loss: 2.8758245198031767
Validation loss: 2.9714267081922854

Epoch: 5| Step: 2
Training loss: 3.4373209126378526
Validation loss: 2.972034534161897

Epoch: 5| Step: 3
Training loss: 3.3587410262072797
Validation loss: 2.9701632112568435

Epoch: 5| Step: 4
Training loss: 3.117748697573803
Validation loss: 2.9692138240462795

Epoch: 5| Step: 5
Training loss: 3.5824695847278996
Validation loss: 2.9712063207044817

Epoch: 5| Step: 6
Training loss: 3.0512727739546097
Validation loss: 2.9712318723892657

Epoch: 5| Step: 7
Training loss: 3.003020673164297
Validation loss: 2.971007825621056

Epoch: 5| Step: 8
Training loss: 3.480223641718232
Validation loss: 2.973598142837668

Epoch: 5| Step: 9
Training loss: 3.234189825239637
Validation loss: 2.972656538044045

Epoch: 5| Step: 10
Training loss: 3.6885969179215543
Validation loss: 2.9719479635926613

Epoch: 303| Step: 0
Training loss: 2.7980697040832796
Validation loss: 2.97817842761224

Epoch: 5| Step: 1
Training loss: 3.2232655082228368
Validation loss: 2.9700174308558966

Epoch: 5| Step: 2
Training loss: 3.7318211206249923
Validation loss: 2.978833422074711

Epoch: 5| Step: 3
Training loss: 3.357072759899432
Validation loss: 2.9768046618983024

Epoch: 5| Step: 4
Training loss: 3.2875455497806145
Validation loss: 2.975881745716789

Epoch: 5| Step: 5
Training loss: 3.339149518947556
Validation loss: 2.980755921976391

Epoch: 5| Step: 6
Training loss: 3.0116760013381474
Validation loss: 2.968660107791469

Epoch: 5| Step: 7
Training loss: 3.328079724787406
Validation loss: 2.971440223362999

Epoch: 5| Step: 8
Training loss: 3.6978741853808064
Validation loss: 2.9676129964391693

Epoch: 5| Step: 9
Training loss: 2.699561178787011
Validation loss: 2.96803213441595

Epoch: 5| Step: 10
Training loss: 3.1036145702839626
Validation loss: 2.975659742834371

Epoch: 304| Step: 0
Training loss: 3.0990450464934054
Validation loss: 2.9672181232078736

Epoch: 5| Step: 1
Training loss: 3.117646377173888
Validation loss: 2.9692922583752703

Epoch: 5| Step: 2
Training loss: 2.934747908259614
Validation loss: 2.9675861091352322

Epoch: 5| Step: 3
Training loss: 2.715191496388523
Validation loss: 2.966788120682569

Epoch: 5| Step: 4
Training loss: 3.0488461109635234
Validation loss: 2.9643105646754084

Epoch: 5| Step: 5
Training loss: 3.447555676758266
Validation loss: 2.967336635793074

Epoch: 5| Step: 6
Training loss: 3.372366266108722
Validation loss: 2.9671796953680043

Epoch: 5| Step: 7
Training loss: 3.9397327208508908
Validation loss: 2.9649435341043677

Epoch: 5| Step: 8
Training loss: 3.498028881339818
Validation loss: 2.9674152113162995

Epoch: 5| Step: 9
Training loss: 3.4418443450754044
Validation loss: 2.966021014800738

Epoch: 5| Step: 10
Training loss: 2.862661172252417
Validation loss: 2.968509186334766

Epoch: 305| Step: 0
Training loss: 2.6776935955478893
Validation loss: 2.9701368303966738

Epoch: 5| Step: 1
Training loss: 3.0339263427182193
Validation loss: 2.9693513357289945

Epoch: 5| Step: 2
Training loss: 2.5908157112779535
Validation loss: 2.9681065620401066

Epoch: 5| Step: 3
Training loss: 3.390464251526824
Validation loss: 2.965604423687476

Epoch: 5| Step: 4
Training loss: 3.150015537284195
Validation loss: 2.970348324696429

Epoch: 5| Step: 5
Training loss: 2.512522045437332
Validation loss: 2.973569361210476

Epoch: 5| Step: 6
Training loss: 3.990385899441913
Validation loss: 2.966632312669307

Epoch: 5| Step: 7
Training loss: 3.2689171947075217
Validation loss: 2.9705548398662995

Epoch: 5| Step: 8
Training loss: 3.641428584529768
Validation loss: 2.9697465641238

Epoch: 5| Step: 9
Training loss: 3.6817920279296423
Validation loss: 2.9639621738116864

Epoch: 5| Step: 10
Training loss: 3.428810372427784
Validation loss: 2.9675783808476126

Epoch: 306| Step: 0
Training loss: 3.2346211952458046
Validation loss: 2.965552275661202

Epoch: 5| Step: 1
Training loss: 3.4123533671528414
Validation loss: 2.962937766897182

Epoch: 5| Step: 2
Training loss: 3.330812470580168
Validation loss: 2.963881701572937

Epoch: 5| Step: 3
Training loss: 2.560737562026274
Validation loss: 2.962977688620605

Epoch: 5| Step: 4
Training loss: 3.1975140810038307
Validation loss: 2.9621523935854968

Epoch: 5| Step: 5
Training loss: 3.171906720082695
Validation loss: 2.962017973361324

Epoch: 5| Step: 6
Training loss: 3.569122316410166
Validation loss: 2.9622930257908284

Epoch: 5| Step: 7
Training loss: 2.8334045027227943
Validation loss: 2.9608121118055477

Epoch: 5| Step: 8
Training loss: 3.560641021237145
Validation loss: 2.9628567260478955

Epoch: 5| Step: 9
Training loss: 3.2413867375211085
Validation loss: 2.962720776779864

Epoch: 5| Step: 10
Training loss: 3.4715799695594494
Validation loss: 2.9653000427590093

Epoch: 307| Step: 0
Training loss: 3.735675920353528
Validation loss: 2.9635831350344852

Epoch: 5| Step: 1
Training loss: 2.8831260944780333
Validation loss: 2.9680098452384724

Epoch: 5| Step: 2
Training loss: 3.463668262586929
Validation loss: 2.971625120945175

Epoch: 5| Step: 3
Training loss: 3.1906205404252317
Validation loss: 2.973604707120169

Epoch: 5| Step: 4
Training loss: 2.9715522791451727
Validation loss: 2.966751272076574

Epoch: 5| Step: 5
Training loss: 3.6247029676090086
Validation loss: 2.965583856430084

Epoch: 5| Step: 6
Training loss: 3.4385183039837166
Validation loss: 2.961728515387309

Epoch: 5| Step: 7
Training loss: 3.4938336957757152
Validation loss: 2.961009003795378

Epoch: 5| Step: 8
Training loss: 2.1757078312483884
Validation loss: 2.960775488414903

Epoch: 5| Step: 9
Training loss: 2.610928101810911
Validation loss: 2.9585802378751653

Epoch: 5| Step: 10
Training loss: 3.785479363506773
Validation loss: 2.961979777524782

Epoch: 308| Step: 0
Training loss: 3.546368129996116
Validation loss: 2.9635315353578227

Epoch: 5| Step: 1
Training loss: 2.6342277006009334
Validation loss: 2.9589800430364153

Epoch: 5| Step: 2
Training loss: 2.9588285398836778
Validation loss: 2.959582343447469

Epoch: 5| Step: 3
Training loss: 3.118875835074134
Validation loss: 2.9611807535565937

Epoch: 5| Step: 4
Training loss: 3.2310533651881777
Validation loss: 2.9614088446477203

Epoch: 5| Step: 5
Training loss: 3.4407774126629014
Validation loss: 2.9606049785179356

Epoch: 5| Step: 6
Training loss: 3.4200268636172684
Validation loss: 2.9646943053452506

Epoch: 5| Step: 7
Training loss: 3.6208809437198775
Validation loss: 2.967705682513695

Epoch: 5| Step: 8
Training loss: 3.344832200658431
Validation loss: 2.9712983709691527

Epoch: 5| Step: 9
Training loss: 3.2051995235235675
Validation loss: 2.96645300645263

Epoch: 5| Step: 10
Training loss: 2.9925337708112503
Validation loss: 2.96194415007893

Epoch: 309| Step: 0
Training loss: 3.2100011940832087
Validation loss: 2.958038640079917

Epoch: 5| Step: 1
Training loss: 2.9929928007182656
Validation loss: 2.9597696742764446

Epoch: 5| Step: 2
Training loss: 3.402750720134948
Validation loss: 2.9578999056397546

Epoch: 5| Step: 3
Training loss: 2.827967686782823
Validation loss: 2.9598025414850904

Epoch: 5| Step: 4
Training loss: 2.9661477981752893
Validation loss: 2.959075727703824

Epoch: 5| Step: 5
Training loss: 2.7200290696610256
Validation loss: 2.9574476063195774

Epoch: 5| Step: 6
Training loss: 3.190523695575127
Validation loss: 2.9590975071818417

Epoch: 5| Step: 7
Training loss: 3.582111919330872
Validation loss: 2.9589670904274663

Epoch: 5| Step: 8
Training loss: 3.7460332871570654
Validation loss: 2.9570994940441846

Epoch: 5| Step: 9
Training loss: 3.9536128892741718
Validation loss: 2.959422930966149

Epoch: 5| Step: 10
Training loss: 2.7146029358685717
Validation loss: 2.9552133189275507

Epoch: 310| Step: 0
Training loss: 3.935245292221151
Validation loss: 2.960067355792805

Epoch: 5| Step: 1
Training loss: 3.337839767934682
Validation loss: 2.9626944179110004

Epoch: 5| Step: 2
Training loss: 2.480197585295025
Validation loss: 2.9570561248361162

Epoch: 5| Step: 3
Training loss: 3.183683316895742
Validation loss: 2.959831165957451

Epoch: 5| Step: 4
Training loss: 3.3374530288877082
Validation loss: 2.9563463659605205

Epoch: 5| Step: 5
Training loss: 3.1491113892833735
Validation loss: 2.95743166678072

Epoch: 5| Step: 6
Training loss: 3.239292700058961
Validation loss: 2.9542064180937584

Epoch: 5| Step: 7
Training loss: 2.8151547088932185
Validation loss: 2.9560622048199154

Epoch: 5| Step: 8
Training loss: 3.66337660366209
Validation loss: 2.9617116259599205

Epoch: 5| Step: 9
Training loss: 3.385317115298118
Validation loss: 2.9564280621978742

Epoch: 5| Step: 10
Training loss: 2.7900961448483383
Validation loss: 2.9578638381610567

Epoch: 311| Step: 0
Training loss: 3.402015223447186
Validation loss: 2.9545464277247926

Epoch: 5| Step: 1
Training loss: 3.187232511179921
Validation loss: 2.9548524994189624

Epoch: 5| Step: 2
Training loss: 3.1863916003316453
Validation loss: 2.9556300510348787

Epoch: 5| Step: 3
Training loss: 2.7142342960535464
Validation loss: 2.957357685668846

Epoch: 5| Step: 4
Training loss: 3.7845448412532443
Validation loss: 2.9526585687321845

Epoch: 5| Step: 5
Training loss: 2.9318307590013224
Validation loss: 2.9536482701187268

Epoch: 5| Step: 6
Training loss: 2.929149364639197
Validation loss: 2.9544035168897564

Epoch: 5| Step: 7
Training loss: 3.837471649363415
Validation loss: 2.95620614202502

Epoch: 5| Step: 8
Training loss: 2.297927719002017
Validation loss: 2.9598839725667587

Epoch: 5| Step: 9
Training loss: 3.7544277753783235
Validation loss: 2.955346062172997

Epoch: 5| Step: 10
Training loss: 3.230924968494096
Validation loss: 2.9547319772787946

Epoch: 312| Step: 0
Training loss: 3.4041049747799037
Validation loss: 2.955180503911419

Epoch: 5| Step: 1
Training loss: 2.9354796259138425
Validation loss: 2.957342761620681

Epoch: 5| Step: 2
Training loss: 3.678302479937061
Validation loss: 2.956516752071511

Epoch: 5| Step: 3
Training loss: 3.474246095618784
Validation loss: 2.956575061525722

Epoch: 5| Step: 4
Training loss: 2.773740080325322
Validation loss: 2.9551290264478824

Epoch: 5| Step: 5
Training loss: 3.192636875931495
Validation loss: 2.9545973209791216

Epoch: 5| Step: 6
Training loss: 3.6831032354597664
Validation loss: 2.952079600502314

Epoch: 5| Step: 7
Training loss: 2.467357580834537
Validation loss: 2.9535744251227825

Epoch: 5| Step: 8
Training loss: 3.5301131047183874
Validation loss: 2.9551993799422953

Epoch: 5| Step: 9
Training loss: 3.2712585917889503
Validation loss: 2.952490131581569

Epoch: 5| Step: 10
Training loss: 2.90799193323163
Validation loss: 2.9565216027099996

Epoch: 313| Step: 0
Training loss: 2.783093730717444
Validation loss: 2.9546208297674608

Epoch: 5| Step: 1
Training loss: 3.2432688920407298
Validation loss: 2.9551054184664176

Epoch: 5| Step: 2
Training loss: 3.1989860776101624
Validation loss: 2.951830777685331

Epoch: 5| Step: 3
Training loss: 2.4507541741336873
Validation loss: 2.953189298554053

Epoch: 5| Step: 4
Training loss: 3.1475530475391125
Validation loss: 2.956526000707843

Epoch: 5| Step: 5
Training loss: 3.2909075348532815
Validation loss: 2.9535602023843133

Epoch: 5| Step: 6
Training loss: 3.3888874436116567
Validation loss: 2.961187231086961

Epoch: 5| Step: 7
Training loss: 3.4172894135162126
Validation loss: 2.959527544318222

Epoch: 5| Step: 8
Training loss: 3.484382389898974
Validation loss: 2.962572242676683

Epoch: 5| Step: 9
Training loss: 3.373250861259186
Validation loss: 2.9551650336133926

Epoch: 5| Step: 10
Training loss: 3.710160151929605
Validation loss: 2.957383593658412

Epoch: 314| Step: 0
Training loss: 3.6939111354942895
Validation loss: 2.9514611348802853

Epoch: 5| Step: 1
Training loss: 2.9817982679323785
Validation loss: 2.951034339746935

Epoch: 5| Step: 2
Training loss: 3.6364061526500655
Validation loss: 2.94844686697968

Epoch: 5| Step: 3
Training loss: 3.0394148830689267
Validation loss: 2.947949556742427

Epoch: 5| Step: 4
Training loss: 3.2225782720206064
Validation loss: 2.951431419907388

Epoch: 5| Step: 5
Training loss: 3.4300080933767316
Validation loss: 2.955837660440781

Epoch: 5| Step: 6
Training loss: 3.2348769530961086
Validation loss: 2.95071447135065

Epoch: 5| Step: 7
Training loss: 2.74124720610247
Validation loss: 2.9498395438518346

Epoch: 5| Step: 8
Training loss: 3.3194722627106366
Validation loss: 2.949492726580898

Epoch: 5| Step: 9
Training loss: 3.5451982879062958
Validation loss: 2.9497482197224976

Epoch: 5| Step: 10
Training loss: 2.33980543713416
Validation loss: 2.9472762787440963

Epoch: 315| Step: 0
Training loss: 3.402121325294547
Validation loss: 2.94882884852946

Epoch: 5| Step: 1
Training loss: 4.07216281532392
Validation loss: 2.948613716231903

Epoch: 5| Step: 2
Training loss: 3.4769107258449425
Validation loss: 2.9530434242080705

Epoch: 5| Step: 3
Training loss: 3.504367827735883
Validation loss: 2.949941942058358

Epoch: 5| Step: 4
Training loss: 2.2612728015262475
Validation loss: 2.9554495724713266

Epoch: 5| Step: 5
Training loss: 2.8530573858833534
Validation loss: 2.955384943150819

Epoch: 5| Step: 6
Training loss: 2.381925223828746
Validation loss: 2.9603523621915024

Epoch: 5| Step: 7
Training loss: 3.2042423439431453
Validation loss: 2.9678763848007352

Epoch: 5| Step: 8
Training loss: 3.577582039095674
Validation loss: 2.9671616895717827

Epoch: 5| Step: 9
Training loss: 2.860194688052625
Validation loss: 2.9790328414763363

Epoch: 5| Step: 10
Training loss: 3.552695049217134
Validation loss: 2.966369672894464

Epoch: 316| Step: 0
Training loss: 3.36051403518695
Validation loss: 2.9593947902563094

Epoch: 5| Step: 1
Training loss: 3.2839016327337944
Validation loss: 2.946819627573693

Epoch: 5| Step: 2
Training loss: 3.367702931475395
Validation loss: 2.947775834170309

Epoch: 5| Step: 3
Training loss: 2.9385624039783798
Validation loss: 2.950448330133023

Epoch: 5| Step: 4
Training loss: 3.2799310849090912
Validation loss: 2.9500869721470573

Epoch: 5| Step: 5
Training loss: 3.1826432570273195
Validation loss: 2.9511821975734334

Epoch: 5| Step: 6
Training loss: 3.6799261902580422
Validation loss: 2.9564813263010454

Epoch: 5| Step: 7
Training loss: 3.220789883325856
Validation loss: 2.95222998070943

Epoch: 5| Step: 8
Training loss: 3.056666520956598
Validation loss: 2.9479636891498187

Epoch: 5| Step: 9
Training loss: 3.540714240569835
Validation loss: 2.946286286799006

Epoch: 5| Step: 10
Training loss: 2.4346243695111727
Validation loss: 2.9471862182519066

Epoch: 317| Step: 0
Training loss: 3.7209156045792504
Validation loss: 2.9471278378615935

Epoch: 5| Step: 1
Training loss: 3.2101203268440552
Validation loss: 2.9509264767396393

Epoch: 5| Step: 2
Training loss: 3.2679770728326063
Validation loss: 2.948373470803121

Epoch: 5| Step: 3
Training loss: 2.925720458678775
Validation loss: 2.951013118428778

Epoch: 5| Step: 4
Training loss: 3.0581953975605685
Validation loss: 2.9512317806912467

Epoch: 5| Step: 5
Training loss: 3.130464734807211
Validation loss: 2.953266351149919

Epoch: 5| Step: 6
Training loss: 3.0308500989636054
Validation loss: 2.954788004534662

Epoch: 5| Step: 7
Training loss: 3.3526613794865248
Validation loss: 2.9555122708258437

Epoch: 5| Step: 8
Training loss: 3.011116729612219
Validation loss: 2.9505139303845733

Epoch: 5| Step: 9
Training loss: 3.204511240143808
Validation loss: 2.9426754105222046

Epoch: 5| Step: 10
Training loss: 3.5661126273913775
Validation loss: 2.9431884344944397

Epoch: 318| Step: 0
Training loss: 3.3310320698807043
Validation loss: 2.9467757964881827

Epoch: 5| Step: 1
Training loss: 2.62339706526058
Validation loss: 2.9457522916088674

Epoch: 5| Step: 2
Training loss: 3.2083622984796563
Validation loss: 2.9408037976588854

Epoch: 5| Step: 3
Training loss: 3.2598846944064133
Validation loss: 2.9411544566745165

Epoch: 5| Step: 4
Training loss: 3.42146709919895
Validation loss: 2.941297645177891

Epoch: 5| Step: 5
Training loss: 3.2661354359602353
Validation loss: 2.9449213866678705

Epoch: 5| Step: 6
Training loss: 3.123227952165279
Validation loss: 2.9448904809710887

Epoch: 5| Step: 7
Training loss: 3.1044840469085626
Validation loss: 2.946963419440473

Epoch: 5| Step: 8
Training loss: 3.277602866367672
Validation loss: 2.946402587300167

Epoch: 5| Step: 9
Training loss: 3.3915772397360646
Validation loss: 2.9441347879051034

Epoch: 5| Step: 10
Training loss: 3.471757015005548
Validation loss: 2.953903418587269

Epoch: 319| Step: 0
Training loss: 3.3911384158648255
Validation loss: 2.9484426082219453

Epoch: 5| Step: 1
Training loss: 3.5312537809368587
Validation loss: 2.9471059734057756

Epoch: 5| Step: 2
Training loss: 2.8738951840755664
Validation loss: 2.945096514564491

Epoch: 5| Step: 3
Training loss: 3.3307961503671
Validation loss: 2.9444551586369725

Epoch: 5| Step: 4
Training loss: 3.3175850470535933
Validation loss: 2.949778575662295

Epoch: 5| Step: 5
Training loss: 3.3075502950314446
Validation loss: 2.943515577061785

Epoch: 5| Step: 6
Training loss: 3.2639655318403706
Validation loss: 2.9433161682846207

Epoch: 5| Step: 7
Training loss: 3.243034233841838
Validation loss: 2.941572607038444

Epoch: 5| Step: 8
Training loss: 2.4062841834080153
Validation loss: 2.9446159264358562

Epoch: 5| Step: 9
Training loss: 3.339749947284704
Validation loss: 2.9408062612184764

Epoch: 5| Step: 10
Training loss: 3.344399077261606
Validation loss: 2.95039561184182

Epoch: 320| Step: 0
Training loss: 2.9439758991623273
Validation loss: 2.94609577087745

Epoch: 5| Step: 1
Training loss: 3.340875834226959
Validation loss: 2.945275099822527

Epoch: 5| Step: 2
Training loss: 3.268660453313806
Validation loss: 2.9448618749359987

Epoch: 5| Step: 3
Training loss: 2.980231319384624
Validation loss: 2.9404590794699996

Epoch: 5| Step: 4
Training loss: 2.503267632277091
Validation loss: 2.939195487918941

Epoch: 5| Step: 5
Training loss: 3.5539242773967787
Validation loss: 2.942244549241215

Epoch: 5| Step: 6
Training loss: 3.295724532449067
Validation loss: 2.940960044797048

Epoch: 5| Step: 7
Training loss: 3.637054788407031
Validation loss: 2.944837375900754

Epoch: 5| Step: 8
Training loss: 3.4829365451058516
Validation loss: 2.940306505166469

Epoch: 5| Step: 9
Training loss: 3.1451520034615066
Validation loss: 2.9430862734356333

Epoch: 5| Step: 10
Training loss: 3.141076202624406
Validation loss: 2.9398697323163963

Epoch: 321| Step: 0
Training loss: 3.545236620841253
Validation loss: 2.946240984204751

Epoch: 5| Step: 1
Training loss: 3.7385468104637023
Validation loss: 2.9402296238849956

Epoch: 5| Step: 2
Training loss: 2.4904069908004756
Validation loss: 2.9404512947068326

Epoch: 5| Step: 3
Training loss: 3.6825389788002654
Validation loss: 2.9409152346164142

Epoch: 5| Step: 4
Training loss: 2.884951906381843
Validation loss: 2.9372336642822234

Epoch: 5| Step: 5
Training loss: 2.979592210659252
Validation loss: 2.937403033001618

Epoch: 5| Step: 6
Training loss: 2.694524766002274
Validation loss: 2.93637269817756

Epoch: 5| Step: 7
Training loss: 3.21918536454736
Validation loss: 2.9388371489483194

Epoch: 5| Step: 8
Training loss: 2.817145685699113
Validation loss: 2.939108658353259

Epoch: 5| Step: 9
Training loss: 3.7022705379990324
Validation loss: 2.9357552846332666

Epoch: 5| Step: 10
Training loss: 3.4346436163808045
Validation loss: 2.9346755147683172

Epoch: 322| Step: 0
Training loss: 2.3430142074199796
Validation loss: 2.936046861428652

Epoch: 5| Step: 1
Training loss: 3.6025333709547747
Validation loss: 2.9358033774660166

Epoch: 5| Step: 2
Training loss: 2.8646867953025272
Validation loss: 2.9373621510085894

Epoch: 5| Step: 3
Training loss: 3.5943677288387157
Validation loss: 2.935900800718191

Epoch: 5| Step: 4
Training loss: 3.5136679394346357
Validation loss: 2.9360171179330385

Epoch: 5| Step: 5
Training loss: 2.9500929995603
Validation loss: 2.937167747347201

Epoch: 5| Step: 6
Training loss: 3.0076048147656897
Validation loss: 2.9345147981890807

Epoch: 5| Step: 7
Training loss: 3.0965705113697584
Validation loss: 2.936438552639717

Epoch: 5| Step: 8
Training loss: 2.808064417504995
Validation loss: 2.9350584850048915

Epoch: 5| Step: 9
Training loss: 3.826234436302597
Validation loss: 2.9357449907750044

Epoch: 5| Step: 10
Training loss: 3.6026441559284765
Validation loss: 2.938784419516848

Epoch: 323| Step: 0
Training loss: 3.662203384210022
Validation loss: 2.9350736000995963

Epoch: 5| Step: 1
Training loss: 3.2104944819171406
Validation loss: 2.935596536191413

Epoch: 5| Step: 2
Training loss: 3.42701286699536
Validation loss: 2.936190462286

Epoch: 5| Step: 3
Training loss: 3.773910840281671
Validation loss: 2.938174005253008

Epoch: 5| Step: 4
Training loss: 2.7917616149545945
Validation loss: 2.9410450196916056

Epoch: 5| Step: 5
Training loss: 2.328344757153997
Validation loss: 2.943373711483153

Epoch: 5| Step: 6
Training loss: 3.3129336954903477
Validation loss: 2.938061625792285

Epoch: 5| Step: 7
Training loss: 2.933087707841702
Validation loss: 2.93692287849124

Epoch: 5| Step: 8
Training loss: 3.7581450697837027
Validation loss: 2.935191699546062

Epoch: 5| Step: 9
Training loss: 2.4905994102857787
Validation loss: 2.93692937722621

Epoch: 5| Step: 10
Training loss: 3.3934365143543093
Validation loss: 2.9346838040498793

Epoch: 324| Step: 0
Training loss: 3.6658535547053566
Validation loss: 2.9358118268571727

Epoch: 5| Step: 1
Training loss: 3.4878272501224568
Validation loss: 2.941745748650556

Epoch: 5| Step: 2
Training loss: 2.98991941541185
Validation loss: 2.9332954322020153

Epoch: 5| Step: 3
Training loss: 3.7624775882699804
Validation loss: 2.9334424021888386

Epoch: 5| Step: 4
Training loss: 2.385436467473058
Validation loss: 2.9366052303802053

Epoch: 5| Step: 5
Training loss: 3.2906038202109524
Validation loss: 2.9363751558510613

Epoch: 5| Step: 6
Training loss: 3.0909852283708563
Validation loss: 2.933583677517165

Epoch: 5| Step: 7
Training loss: 3.560839617439675
Validation loss: 2.9324838324019664

Epoch: 5| Step: 8
Training loss: 2.6595560480656792
Validation loss: 2.9350157046287024

Epoch: 5| Step: 9
Training loss: 3.2367377013384364
Validation loss: 2.9302853805115614

Epoch: 5| Step: 10
Training loss: 2.951125340880643
Validation loss: 2.933379299842169

Epoch: 325| Step: 0
Training loss: 3.1946465654053884
Validation loss: 2.9308800198811134

Epoch: 5| Step: 1
Training loss: 3.883734303894837
Validation loss: 2.9311702222135136

Epoch: 5| Step: 2
Training loss: 3.3734498879371753
Validation loss: 2.932437221159798

Epoch: 5| Step: 3
Training loss: 3.519154857700295
Validation loss: 2.933885295201336

Epoch: 5| Step: 4
Training loss: 2.1431023956913418
Validation loss: 2.9333445756683743

Epoch: 5| Step: 5
Training loss: 3.423298021658759
Validation loss: 2.933065643452885

Epoch: 5| Step: 6
Training loss: 3.624753088599016
Validation loss: 2.9313027266409897

Epoch: 5| Step: 7
Training loss: 2.8424448225022285
Validation loss: 2.9310041774118316

Epoch: 5| Step: 8
Training loss: 3.4239171174882723
Validation loss: 2.937109911485277

Epoch: 5| Step: 9
Training loss: 3.011479349677689
Validation loss: 2.9443498512929325

Epoch: 5| Step: 10
Training loss: 2.415057622249751
Validation loss: 2.9442994557103104

Epoch: 326| Step: 0
Training loss: 2.7941722064404666
Validation loss: 2.9457436749159

Epoch: 5| Step: 1
Training loss: 3.042013035392044
Validation loss: 2.9542552570988656

Epoch: 5| Step: 2
Training loss: 3.157556546657069
Validation loss: 2.9477258998314286

Epoch: 5| Step: 3
Training loss: 3.054297849189319
Validation loss: 2.9423409802854303

Epoch: 5| Step: 4
Training loss: 3.286994193150585
Validation loss: 2.9434584189890307

Epoch: 5| Step: 5
Training loss: 3.2611985574147107
Validation loss: 2.9349468501301836

Epoch: 5| Step: 6
Training loss: 3.1498982185995503
Validation loss: 2.9308079034809915

Epoch: 5| Step: 7
Training loss: 3.2272878944441086
Validation loss: 2.9279271057246627

Epoch: 5| Step: 8
Training loss: 3.523043794479402
Validation loss: 2.9278415215746647

Epoch: 5| Step: 9
Training loss: 3.5892220540965813
Validation loss: 2.9284050496242635

Epoch: 5| Step: 10
Training loss: 3.248925104651125
Validation loss: 2.9301503706858547

Epoch: 327| Step: 0
Training loss: 3.384483999256481
Validation loss: 2.930715330244433

Epoch: 5| Step: 1
Training loss: 3.087935098114275
Validation loss: 2.9320468997507882

Epoch: 5| Step: 2
Training loss: 3.381091378205546
Validation loss: 2.93382812165012

Epoch: 5| Step: 3
Training loss: 3.1876922250268427
Validation loss: 2.9337279477214664

Epoch: 5| Step: 4
Training loss: 3.2520126566435326
Validation loss: 2.9315614071676226

Epoch: 5| Step: 5
Training loss: 2.869644982846429
Validation loss: 2.9286357642934053

Epoch: 5| Step: 6
Training loss: 3.143171350452543
Validation loss: 2.9286614081527507

Epoch: 5| Step: 7
Training loss: 2.8969006846913707
Validation loss: 2.9283145602019722

Epoch: 5| Step: 8
Training loss: 3.991316668643275
Validation loss: 2.9251946080847984

Epoch: 5| Step: 9
Training loss: 3.006051318290864
Validation loss: 2.928667646855285

Epoch: 5| Step: 10
Training loss: 3.051060232772593
Validation loss: 2.9263244481280966

Epoch: 328| Step: 0
Training loss: 3.1243593703701444
Validation loss: 2.927810060820302

Epoch: 5| Step: 1
Training loss: 3.062162575330766
Validation loss: 2.9317988233948946

Epoch: 5| Step: 2
Training loss: 2.8915710550674536
Validation loss: 2.9290724163208095

Epoch: 5| Step: 3
Training loss: 3.3185897127514257
Validation loss: 2.936362193455418

Epoch: 5| Step: 4
Training loss: 2.8927189021912803
Validation loss: 2.9331548649322676

Epoch: 5| Step: 5
Training loss: 3.64887243124931
Validation loss: 2.9429236493446513

Epoch: 5| Step: 6
Training loss: 2.384809813843772
Validation loss: 2.945005887743994

Epoch: 5| Step: 7
Training loss: 3.3905745120178983
Validation loss: 2.9377717254851894

Epoch: 5| Step: 8
Training loss: 3.0353722612060485
Validation loss: 2.937752413721364

Epoch: 5| Step: 9
Training loss: 3.6747437004971193
Validation loss: 2.937175626350025

Epoch: 5| Step: 10
Training loss: 3.7561057927890604
Validation loss: 2.935036901859839

Epoch: 329| Step: 0
Training loss: 2.9871257467757832
Validation loss: 2.9298367667507663

Epoch: 5| Step: 1
Training loss: 3.415154254160698
Validation loss: 2.933220169349351

Epoch: 5| Step: 2
Training loss: 2.736928913345939
Validation loss: 2.9283511754744764

Epoch: 5| Step: 3
Training loss: 2.9943294975694723
Validation loss: 2.9299512650081025

Epoch: 5| Step: 4
Training loss: 3.2003772394027714
Validation loss: 2.930945191301136

Epoch: 5| Step: 5
Training loss: 3.655616379308816
Validation loss: 2.9232647924472155

Epoch: 5| Step: 6
Training loss: 2.5760695152972954
Validation loss: 2.9244682522122463

Epoch: 5| Step: 7
Training loss: 3.0280645878201233
Validation loss: 2.9261217064212484

Epoch: 5| Step: 8
Training loss: 3.9071607824927073
Validation loss: 2.928715620606912

Epoch: 5| Step: 9
Training loss: 3.1732259044040436
Validation loss: 2.92854659159406

Epoch: 5| Step: 10
Training loss: 3.4705030805461154
Validation loss: 2.9251545563293395

Epoch: 330| Step: 0
Training loss: 2.9627398236899603
Validation loss: 2.929734315122149

Epoch: 5| Step: 1
Training loss: 3.2242707248544313
Validation loss: 2.9281552577767047

Epoch: 5| Step: 2
Training loss: 3.154493088421254
Validation loss: 2.92800762840307

Epoch: 5| Step: 3
Training loss: 2.9190196400811845
Validation loss: 2.9321681995714473

Epoch: 5| Step: 4
Training loss: 3.5752829379711826
Validation loss: 2.9347276270456364

Epoch: 5| Step: 5
Training loss: 3.189676925179716
Validation loss: 2.9288205920150707

Epoch: 5| Step: 6
Training loss: 2.8440244772779217
Validation loss: 2.9239881673107457

Epoch: 5| Step: 7
Training loss: 3.1054007276846565
Validation loss: 2.92404324145071

Epoch: 5| Step: 8
Training loss: 3.6055339505632937
Validation loss: 2.929523362897591

Epoch: 5| Step: 9
Training loss: 2.447917586522572
Validation loss: 2.92427702408134

Epoch: 5| Step: 10
Training loss: 4.146403415660419
Validation loss: 2.92338919272116

Epoch: 331| Step: 0
Training loss: 3.629812663264862
Validation loss: 2.922293719391246

Epoch: 5| Step: 1
Training loss: 3.050422051417223
Validation loss: 2.922468283890897

Epoch: 5| Step: 2
Training loss: 3.0358480600325697
Validation loss: 2.9250169932156904

Epoch: 5| Step: 3
Training loss: 2.9251974055523493
Validation loss: 2.919130868829395

Epoch: 5| Step: 4
Training loss: 2.381438412558947
Validation loss: 2.926071899317688

Epoch: 5| Step: 5
Training loss: 3.1032392067844086
Validation loss: 2.923988648652842

Epoch: 5| Step: 6
Training loss: 3.0208898254023167
Validation loss: 2.9246356472142203

Epoch: 5| Step: 7
Training loss: 3.2818714824854536
Validation loss: 2.9256757533206543

Epoch: 5| Step: 8
Training loss: 3.561073151331736
Validation loss: 2.9273394733620828

Epoch: 5| Step: 9
Training loss: 3.76363728719674
Validation loss: 2.9361007978139497

Epoch: 5| Step: 10
Training loss: 3.339463811311347
Validation loss: 2.9422233429445948

Epoch: 332| Step: 0
Training loss: 3.2678673451463163
Validation loss: 2.934068961300541

Epoch: 5| Step: 1
Training loss: 3.2552327798561205
Validation loss: 2.9490586938572148

Epoch: 5| Step: 2
Training loss: 3.2268914523786774
Validation loss: 2.9485483658418667

Epoch: 5| Step: 3
Training loss: 3.2379416735216107
Validation loss: 2.957120561583267

Epoch: 5| Step: 4
Training loss: 3.1422324550605327
Validation loss: 2.942186597084268

Epoch: 5| Step: 5
Training loss: 3.601131785821644
Validation loss: 2.938403217409062

Epoch: 5| Step: 6
Training loss: 2.926524171104701
Validation loss: 2.922496874027308

Epoch: 5| Step: 7
Training loss: 2.879312349453058
Validation loss: 2.9203738588301524

Epoch: 5| Step: 8
Training loss: 3.550422004009548
Validation loss: 2.9195878607742998

Epoch: 5| Step: 9
Training loss: 3.016728490824707
Validation loss: 2.9188367484980002

Epoch: 5| Step: 10
Training loss: 3.135118354132964
Validation loss: 2.918958402301373

Epoch: 333| Step: 0
Training loss: 2.720385005013167
Validation loss: 2.9201545311233668

Epoch: 5| Step: 1
Training loss: 3.682288673899656
Validation loss: 2.9200348323020533

Epoch: 5| Step: 2
Training loss: 3.1747841108318884
Validation loss: 2.9202449775524926

Epoch: 5| Step: 3
Training loss: 3.3482305152136425
Validation loss: 2.9229508742604153

Epoch: 5| Step: 4
Training loss: 3.073298198915622
Validation loss: 2.9217101800738843

Epoch: 5| Step: 5
Training loss: 2.8529163229966117
Validation loss: 2.919953269733474

Epoch: 5| Step: 6
Training loss: 3.3103524210037087
Validation loss: 2.915322285461252

Epoch: 5| Step: 7
Training loss: 3.882662795191536
Validation loss: 2.9188117280017924

Epoch: 5| Step: 8
Training loss: 3.1953241399352477
Validation loss: 2.9168345905488375

Epoch: 5| Step: 9
Training loss: 2.499461020544028
Validation loss: 2.9227734730144816

Epoch: 5| Step: 10
Training loss: 3.3640731251465104
Validation loss: 2.918117185945586

Epoch: 334| Step: 0
Training loss: 3.284070936768055
Validation loss: 2.9192821506893654

Epoch: 5| Step: 1
Training loss: 3.42005000808472
Validation loss: 2.920481424675791

Epoch: 5| Step: 2
Training loss: 3.02353023416408
Validation loss: 2.923794067762278

Epoch: 5| Step: 3
Training loss: 3.305841339181127
Validation loss: 2.945563050140337

Epoch: 5| Step: 4
Training loss: 3.6968829505557603
Validation loss: 2.941783634655954

Epoch: 5| Step: 5
Training loss: 3.261820790413602
Validation loss: 2.9366645122290778

Epoch: 5| Step: 6
Training loss: 2.597298641973176
Validation loss: 2.943265060800641

Epoch: 5| Step: 7
Training loss: 3.4668505167504935
Validation loss: 2.9192592526252317

Epoch: 5| Step: 8
Training loss: 2.629732044769736
Validation loss: 2.9162403258009935

Epoch: 5| Step: 9
Training loss: 3.6335562652183224
Validation loss: 2.914828139109196

Epoch: 5| Step: 10
Training loss: 2.635784249183884
Validation loss: 2.9167866138692333

Epoch: 335| Step: 0
Training loss: 3.1169381484111147
Validation loss: 2.914854602773343

Epoch: 5| Step: 1
Training loss: 3.495379258781474
Validation loss: 2.9154241936180596

Epoch: 5| Step: 2
Training loss: 2.9324310070874855
Validation loss: 2.9165122757465176

Epoch: 5| Step: 3
Training loss: 3.512653502235884
Validation loss: 2.920142693325049

Epoch: 5| Step: 4
Training loss: 3.350474503347699
Validation loss: 2.9189505891795426

Epoch: 5| Step: 5
Training loss: 3.2801660109586286
Validation loss: 2.920128926688351

Epoch: 5| Step: 6
Training loss: 3.327550130992406
Validation loss: 2.9204537136994957

Epoch: 5| Step: 7
Training loss: 3.0121914780787677
Validation loss: 2.9201740821728825

Epoch: 5| Step: 8
Training loss: 2.81465117520771
Validation loss: 2.9181830306960266

Epoch: 5| Step: 9
Training loss: 3.472342203398513
Validation loss: 2.9143961763477853

Epoch: 5| Step: 10
Training loss: 2.8600851542460366
Validation loss: 2.9160944756817013

Epoch: 336| Step: 0
Training loss: 3.1640490873076055
Validation loss: 2.913307365482342

Epoch: 5| Step: 1
Training loss: 3.870898013743102
Validation loss: 2.9134419318281854

Epoch: 5| Step: 2
Training loss: 2.846657241549586
Validation loss: 2.915296139100278

Epoch: 5| Step: 3
Training loss: 3.140377964913174
Validation loss: 2.914987515529187

Epoch: 5| Step: 4
Training loss: 2.955586371424492
Validation loss: 2.9145360421851656

Epoch: 5| Step: 5
Training loss: 2.8040867749226996
Validation loss: 2.9193610325721924

Epoch: 5| Step: 6
Training loss: 3.4552026082542415
Validation loss: 2.9264812607146964

Epoch: 5| Step: 7
Training loss: 3.4140422480002166
Validation loss: 2.926288397968988

Epoch: 5| Step: 8
Training loss: 3.4999062661834692
Validation loss: 2.9322539004906805

Epoch: 5| Step: 9
Training loss: 2.2539644283408897
Validation loss: 2.9153793822554115

Epoch: 5| Step: 10
Training loss: 3.583950847084319
Validation loss: 2.917908982008565

Epoch: 337| Step: 0
Training loss: 3.7266689581229913
Validation loss: 2.9180003133453405

Epoch: 5| Step: 1
Training loss: 3.283579843887845
Validation loss: 2.927460390259449

Epoch: 5| Step: 2
Training loss: 2.6399551535178487
Validation loss: 2.9189622877759365

Epoch: 5| Step: 3
Training loss: 3.2326248520108067
Validation loss: 2.9130465711544056

Epoch: 5| Step: 4
Training loss: 3.1399172464630705
Validation loss: 2.9121453585947323

Epoch: 5| Step: 5
Training loss: 3.3523864444671165
Validation loss: 2.9154214272222525

Epoch: 5| Step: 6
Training loss: 2.5967636984282674
Validation loss: 2.9150127069252627

Epoch: 5| Step: 7
Training loss: 3.5357007360818016
Validation loss: 2.92217053492671

Epoch: 5| Step: 8
Training loss: 2.983530454321322
Validation loss: 2.9180936396076054

Epoch: 5| Step: 9
Training loss: 3.1867591146469096
Validation loss: 2.9134964081183004

Epoch: 5| Step: 10
Training loss: 3.3710844143664187
Validation loss: 2.9114549937561023

Epoch: 338| Step: 0
Training loss: 3.1001819065005773
Validation loss: 2.913104472904874

Epoch: 5| Step: 1
Training loss: 3.943108091996832
Validation loss: 2.9116493338700304

Epoch: 5| Step: 2
Training loss: 2.861042474542749
Validation loss: 2.914380756970028

Epoch: 5| Step: 3
Training loss: 3.0210421435217634
Validation loss: 2.921007872744793

Epoch: 5| Step: 4
Training loss: 3.403984506340941
Validation loss: 2.9226887308878755

Epoch: 5| Step: 5
Training loss: 2.6205942328894354
Validation loss: 2.9251680267511864

Epoch: 5| Step: 6
Training loss: 3.1922344874631654
Validation loss: 2.919751163850439

Epoch: 5| Step: 7
Training loss: 3.3631519465562363
Validation loss: 2.910277804192377

Epoch: 5| Step: 8
Training loss: 2.877759024249242
Validation loss: 2.910067634254649

Epoch: 5| Step: 9
Training loss: 3.2782212584175316
Validation loss: 2.906322966581563

Epoch: 5| Step: 10
Training loss: 3.3891660302521673
Validation loss: 2.907417774613765

Epoch: 339| Step: 0
Training loss: 2.8302174620094447
Validation loss: 2.9109096690700853

Epoch: 5| Step: 1
Training loss: 3.164278300896959
Validation loss: 2.9115439159573637

Epoch: 5| Step: 2
Training loss: 2.2991096888090263
Validation loss: 2.9111998842856677

Epoch: 5| Step: 3
Training loss: 2.7705597897838428
Validation loss: 2.9106771864657706

Epoch: 5| Step: 4
Training loss: 3.3678173352359275
Validation loss: 2.911214255855317

Epoch: 5| Step: 5
Training loss: 3.3965054336430263
Validation loss: 2.9106141313726392

Epoch: 5| Step: 6
Training loss: 3.2842210670062655
Validation loss: 2.9087581117225882

Epoch: 5| Step: 7
Training loss: 3.593958309604712
Validation loss: 2.9129985602488686

Epoch: 5| Step: 8
Training loss: 3.1609184562497887
Validation loss: 2.9091794196077165

Epoch: 5| Step: 9
Training loss: 3.8646906643312655
Validation loss: 2.907419166910266

Epoch: 5| Step: 10
Training loss: 3.2660421442698766
Validation loss: 2.911243007587777

Epoch: 340| Step: 0
Training loss: 3.4135022434770925
Validation loss: 2.9095418870271237

Epoch: 5| Step: 1
Training loss: 3.0143757342441084
Validation loss: 2.9094827653805813

Epoch: 5| Step: 2
Training loss: 2.6070277455517537
Validation loss: 2.913422242327574

Epoch: 5| Step: 3
Training loss: 2.3026278327968783
Validation loss: 2.919392760883773

Epoch: 5| Step: 4
Training loss: 3.132395728492479
Validation loss: 2.933439497224458

Epoch: 5| Step: 5
Training loss: 3.5783555402156986
Validation loss: 2.9301069875669437

Epoch: 5| Step: 6
Training loss: 3.373309383106274
Validation loss: 2.919668917252321

Epoch: 5| Step: 7
Training loss: 4.164539989699422
Validation loss: 2.9137189231986915

Epoch: 5| Step: 8
Training loss: 3.0237112783828306
Validation loss: 2.9132412098935907

Epoch: 5| Step: 9
Training loss: 2.9955435077256425
Validation loss: 2.9078947386785976

Epoch: 5| Step: 10
Training loss: 3.234942989878819
Validation loss: 2.9076225293866482

Epoch: 341| Step: 0
Training loss: 3.5095573452651534
Validation loss: 2.9077567372503155

Epoch: 5| Step: 1
Training loss: 2.9417009547957607
Validation loss: 2.908454493807784

Epoch: 5| Step: 2
Training loss: 2.8500969452013205
Validation loss: 2.904257757614713

Epoch: 5| Step: 3
Training loss: 2.944884737152255
Validation loss: 2.9066894565955894

Epoch: 5| Step: 4
Training loss: 3.5506967800991602
Validation loss: 2.906693393749598

Epoch: 5| Step: 5
Training loss: 3.575774241018229
Validation loss: 2.9043062952244707

Epoch: 5| Step: 6
Training loss: 2.617526906338828
Validation loss: 2.9062720395074093

Epoch: 5| Step: 7
Training loss: 3.2028641757375
Validation loss: 2.90622558654065

Epoch: 5| Step: 8
Training loss: 2.962645508617088
Validation loss: 2.9075904707248226

Epoch: 5| Step: 9
Training loss: 3.6128494252097307
Validation loss: 2.9083018589076697

Epoch: 5| Step: 10
Training loss: 3.2654727005922113
Validation loss: 2.9071666671360754

Epoch: 342| Step: 0
Training loss: 4.042252068875725
Validation loss: 2.9046992057686176

Epoch: 5| Step: 1
Training loss: 2.8329855948585885
Validation loss: 2.908748350729551

Epoch: 5| Step: 2
Training loss: 3.403305180651439
Validation loss: 2.904999770037984

Epoch: 5| Step: 3
Training loss: 2.5065043712724715
Validation loss: 2.9076632105790132

Epoch: 5| Step: 4
Training loss: 3.338088331622876
Validation loss: 2.9060272403116674

Epoch: 5| Step: 5
Training loss: 3.3413017079997185
Validation loss: 2.9072793228719136

Epoch: 5| Step: 6
Training loss: 2.797948194502731
Validation loss: 2.9068298555280965

Epoch: 5| Step: 7
Training loss: 3.9423569287916713
Validation loss: 2.917353234297192

Epoch: 5| Step: 8
Training loss: 2.3396992583073
Validation loss: 2.922347231494535

Epoch: 5| Step: 9
Training loss: 3.08758207513237
Validation loss: 2.919014435543421

Epoch: 5| Step: 10
Training loss: 3.05193608854278
Validation loss: 2.917831601955493

Epoch: 343| Step: 0
Training loss: 3.423233946855988
Validation loss: 2.921067459726268

Epoch: 5| Step: 1
Training loss: 2.8597648646657574
Validation loss: 2.9074976943516053

Epoch: 5| Step: 2
Training loss: 2.616964211119727
Validation loss: 2.9162902085142908

Epoch: 5| Step: 3
Training loss: 3.0840380267162617
Validation loss: 2.9052961859256676

Epoch: 5| Step: 4
Training loss: 4.0336438545515305
Validation loss: 2.9080226756840664

Epoch: 5| Step: 5
Training loss: 2.681905645845691
Validation loss: 2.9047391680082923

Epoch: 5| Step: 6
Training loss: 3.257687060825071
Validation loss: 2.910007048539381

Epoch: 5| Step: 7
Training loss: 2.946191793068294
Validation loss: 2.9077459501714125

Epoch: 5| Step: 8
Training loss: 3.3427159501976913
Validation loss: 2.9079926913942074

Epoch: 5| Step: 9
Training loss: 3.161734621815471
Validation loss: 2.9029219236475123

Epoch: 5| Step: 10
Training loss: 3.529271339446567
Validation loss: 2.9051933648013817

Epoch: 344| Step: 0
Training loss: 3.0046911119587136
Validation loss: 2.9060756186889476

Epoch: 5| Step: 1
Training loss: 3.0794300082020114
Validation loss: 2.913246479304922

Epoch: 5| Step: 2
Training loss: 3.5523193519615197
Validation loss: 2.9072319433398985

Epoch: 5| Step: 3
Training loss: 3.656965919241943
Validation loss: 2.919604363420643

Epoch: 5| Step: 4
Training loss: 2.9493178597274863
Validation loss: 2.922914676365766

Epoch: 5| Step: 5
Training loss: 3.013211722606612
Validation loss: 2.920455878409532

Epoch: 5| Step: 6
Training loss: 3.44832861399585
Validation loss: 2.924990694241392

Epoch: 5| Step: 7
Training loss: 4.065853905886042
Validation loss: 2.915292327004048

Epoch: 5| Step: 8
Training loss: 2.839086880366647
Validation loss: 2.907902998508186

Epoch: 5| Step: 9
Training loss: 2.4050348359438103
Validation loss: 2.903918197632727

Epoch: 5| Step: 10
Training loss: 2.669803731183851
Validation loss: 2.8989347639357863

Epoch: 345| Step: 0
Training loss: 3.6549706462302387
Validation loss: 2.8991857425864667

Epoch: 5| Step: 1
Training loss: 3.163578099976879
Validation loss: 2.900262908206262

Epoch: 5| Step: 2
Training loss: 3.0378898966904746
Validation loss: 2.8969442571290998

Epoch: 5| Step: 3
Training loss: 3.28457240882485
Validation loss: 2.9002271546284426

Epoch: 5| Step: 4
Training loss: 2.962739984634618
Validation loss: 2.902929188218188

Epoch: 5| Step: 5
Training loss: 3.639488730523079
Validation loss: 2.900985967914008

Epoch: 5| Step: 6
Training loss: 2.90812409385144
Validation loss: 2.9032047869150417

Epoch: 5| Step: 7
Training loss: 3.5031967550478287
Validation loss: 2.898711392560689

Epoch: 5| Step: 8
Training loss: 3.038028178191706
Validation loss: 2.899075969071342

Epoch: 5| Step: 9
Training loss: 2.530256665143658
Validation loss: 2.9010759815806684

Epoch: 5| Step: 10
Training loss: 3.2585891785791925
Validation loss: 2.9136521188104045

Epoch: 346| Step: 0
Training loss: 2.826495802531558
Validation loss: 2.9219850356355903

Epoch: 5| Step: 1
Training loss: 3.3636631765398213
Validation loss: 2.9222796760192096

Epoch: 5| Step: 2
Training loss: 3.525618797801269
Validation loss: 2.9161435573741388

Epoch: 5| Step: 3
Training loss: 2.849997062012346
Validation loss: 2.9134683702466755

Epoch: 5| Step: 4
Training loss: 2.405627777105935
Validation loss: 2.9137796340952766

Epoch: 5| Step: 5
Training loss: 3.62450773908789
Validation loss: 2.904070807811529

Epoch: 5| Step: 6
Training loss: 3.364646147307951
Validation loss: 2.9047079097975983

Epoch: 5| Step: 7
Training loss: 3.343164125257419
Validation loss: 2.8951292039899195

Epoch: 5| Step: 8
Training loss: 3.0739033984441195
Validation loss: 2.894376172282398

Epoch: 5| Step: 9
Training loss: 2.9721157870937818
Validation loss: 2.900378895690255

Epoch: 5| Step: 10
Training loss: 3.6111629400853946
Validation loss: 2.8985109710469597

Epoch: 347| Step: 0
Training loss: 3.3510156999047767
Validation loss: 2.894183479372378

Epoch: 5| Step: 1
Training loss: 2.873468737616536
Validation loss: 2.8966689876416494

Epoch: 5| Step: 2
Training loss: 2.994182987000553
Validation loss: 2.8989336284444804

Epoch: 5| Step: 3
Training loss: 3.066658155457116
Validation loss: 2.900208766750972

Epoch: 5| Step: 4
Training loss: 2.9880000761305303
Validation loss: 2.899429609217879

Epoch: 5| Step: 5
Training loss: 2.887152488241043
Validation loss: 2.901318660806072

Epoch: 5| Step: 6
Training loss: 3.5853966531558856
Validation loss: 2.9057358908815827

Epoch: 5| Step: 7
Training loss: 3.433351822837252
Validation loss: 2.9018024176083386

Epoch: 5| Step: 8
Training loss: 2.99379565496813
Validation loss: 2.907237816221636

Epoch: 5| Step: 9
Training loss: 3.1604162234207744
Validation loss: 2.902401628547749

Epoch: 5| Step: 10
Training loss: 3.7084138982929407
Validation loss: 2.9014864512647747

Epoch: 348| Step: 0
Training loss: 3.5814249738253134
Validation loss: 2.8987784298358283

Epoch: 5| Step: 1
Training loss: 3.4483948497960752
Validation loss: 2.9044817166072376

Epoch: 5| Step: 2
Training loss: 3.0558314998369114
Validation loss: 2.9041101996059417

Epoch: 5| Step: 3
Training loss: 3.2394964241235367
Validation loss: 2.9054987025961423

Epoch: 5| Step: 4
Training loss: 2.3067001606414985
Validation loss: 2.902677642978699

Epoch: 5| Step: 5
Training loss: 3.5880782774484805
Validation loss: 2.8977533259403323

Epoch: 5| Step: 6
Training loss: 3.359625944478999
Validation loss: 2.899507682844254

Epoch: 5| Step: 7
Training loss: 2.968431154495912
Validation loss: 2.9032305732810975

Epoch: 5| Step: 8
Training loss: 2.697151772805319
Validation loss: 2.897766484929364

Epoch: 5| Step: 9
Training loss: 3.071468223113054
Validation loss: 2.9021732592328022

Epoch: 5| Step: 10
Training loss: 3.545169504307237
Validation loss: 2.8951815543526878

Epoch: 349| Step: 0
Training loss: 3.794524544546397
Validation loss: 2.895980447600162

Epoch: 5| Step: 1
Training loss: 3.2185974084924167
Validation loss: 2.896523625686776

Epoch: 5| Step: 2
Training loss: 3.284908035825814
Validation loss: 2.895433116874121

Epoch: 5| Step: 3
Training loss: 3.3188012128136477
Validation loss: 2.890842754805892

Epoch: 5| Step: 4
Training loss: 2.79301655334965
Validation loss: 2.8866669362138695

Epoch: 5| Step: 5
Training loss: 3.262249529932441
Validation loss: 2.8915991332654944

Epoch: 5| Step: 6
Training loss: 3.0573949498542925
Validation loss: 2.8933532008335843

Epoch: 5| Step: 7
Training loss: 3.05500374252165
Validation loss: 2.894338785307217

Epoch: 5| Step: 8
Training loss: 3.264545755143701
Validation loss: 2.891905248613956

Epoch: 5| Step: 9
Training loss: 3.3915568534700733
Validation loss: 2.8974622399086427

Epoch: 5| Step: 10
Training loss: 2.198962127185936
Validation loss: 2.907135090225311

Epoch: 350| Step: 0
Training loss: 3.636297051947214
Validation loss: 2.899643796714438

Epoch: 5| Step: 1
Training loss: 2.641297655375246
Validation loss: 2.8897242106193364

Epoch: 5| Step: 2
Training loss: 2.448056762149433
Validation loss: 2.8927154883962007

Epoch: 5| Step: 3
Training loss: 3.3825208436897483
Validation loss: 2.8900228550004354

Epoch: 5| Step: 4
Training loss: 2.653889134228045
Validation loss: 2.893375630085392

Epoch: 5| Step: 5
Training loss: 3.145776878675625
Validation loss: 2.894938404939009

Epoch: 5| Step: 6
Training loss: 3.467280721077381
Validation loss: 2.895975993949252

Epoch: 5| Step: 7
Training loss: 3.88415688280566
Validation loss: 2.8902014256007855

Epoch: 5| Step: 8
Training loss: 2.9877943652069177
Validation loss: 2.892757069599386

Epoch: 5| Step: 9
Training loss: 3.1424133371377003
Validation loss: 2.8905702168362715

Epoch: 5| Step: 10
Training loss: 3.3504225564035233
Validation loss: 2.8882372003815933

Epoch: 351| Step: 0
Training loss: 2.790479967677999
Validation loss: 2.8907668336384567

Epoch: 5| Step: 1
Training loss: 3.6516589170368188
Validation loss: 2.890269051419988

Epoch: 5| Step: 2
Training loss: 3.4763228773195807
Validation loss: 2.8941715867228153

Epoch: 5| Step: 3
Training loss: 3.857326442648619
Validation loss: 2.890114962017193

Epoch: 5| Step: 4
Training loss: 2.612176270938254
Validation loss: 2.8873775404892856

Epoch: 5| Step: 5
Training loss: 3.079502630079967
Validation loss: 2.8931202041929014

Epoch: 5| Step: 6
Training loss: 2.9583047319202693
Validation loss: 2.888931350288151

Epoch: 5| Step: 7
Training loss: 3.3976258459636424
Validation loss: 2.8856526034726495

Epoch: 5| Step: 8
Training loss: 2.8926407667508163
Validation loss: 2.889148487383466

Epoch: 5| Step: 9
Training loss: 2.829254093607764
Validation loss: 2.8882003179967857

Epoch: 5| Step: 10
Training loss: 3.2236912400510134
Validation loss: 2.8843709110063975

Epoch: 352| Step: 0
Training loss: 2.7490361865545845
Validation loss: 2.8907600821361488

Epoch: 5| Step: 1
Training loss: 3.1406702446406705
Validation loss: 2.8914099073582102

Epoch: 5| Step: 2
Training loss: 3.723387063053407
Validation loss: 2.8941624435398197

Epoch: 5| Step: 3
Training loss: 2.5491067668274123
Validation loss: 2.8968909713563784

Epoch: 5| Step: 4
Training loss: 2.781119268538072
Validation loss: 2.8874544839086527

Epoch: 5| Step: 5
Training loss: 3.277984156460321
Validation loss: 2.8912045931803627

Epoch: 5| Step: 6
Training loss: 3.6666441974529422
Validation loss: 2.8875006990503365

Epoch: 5| Step: 7
Training loss: 3.4958423715928504
Validation loss: 2.882289802293943

Epoch: 5| Step: 8
Training loss: 2.896912700650544
Validation loss: 2.884408388075785

Epoch: 5| Step: 9
Training loss: 3.170499305993332
Validation loss: 2.8865164389026625

Epoch: 5| Step: 10
Training loss: 3.3096250617889607
Validation loss: 2.8861550706837975

Epoch: 353| Step: 0
Training loss: 3.5598486688145665
Validation loss: 2.889785315610648

Epoch: 5| Step: 1
Training loss: 3.7007933410485667
Validation loss: 2.887925919463378

Epoch: 5| Step: 2
Training loss: 2.7454713466068195
Validation loss: 2.890579118616719

Epoch: 5| Step: 3
Training loss: 3.4751652685151035
Validation loss: 2.8859497433198666

Epoch: 5| Step: 4
Training loss: 2.827865504378179
Validation loss: 2.8856954031621203

Epoch: 5| Step: 5
Training loss: 3.6312752701475897
Validation loss: 2.8865360694703335

Epoch: 5| Step: 6
Training loss: 3.0633070524608286
Validation loss: 2.8855256407704792

Epoch: 5| Step: 7
Training loss: 3.221227192618497
Validation loss: 2.887085420766425

Epoch: 5| Step: 8
Training loss: 2.6454809559937096
Validation loss: 2.887392420407863

Epoch: 5| Step: 9
Training loss: 3.2922721659994405
Validation loss: 2.887934953229773

Epoch: 5| Step: 10
Training loss: 2.478736572998739
Validation loss: 2.886998775061179

Epoch: 354| Step: 0
Training loss: 3.432598989772176
Validation loss: 2.8868687261442787

Epoch: 5| Step: 1
Training loss: 2.556450844781383
Validation loss: 2.884722860393975

Epoch: 5| Step: 2
Training loss: 3.475046165763415
Validation loss: 2.8926001286456153

Epoch: 5| Step: 3
Training loss: 2.955218183850417
Validation loss: 2.895951728469147

Epoch: 5| Step: 4
Training loss: 2.369219521563467
Validation loss: 2.899502639567773

Epoch: 5| Step: 5
Training loss: 3.1706230812360214
Validation loss: 2.8930420352838175

Epoch: 5| Step: 6
Training loss: 3.422374253453395
Validation loss: 2.8978541710704384

Epoch: 5| Step: 7
Training loss: 3.84020572170898
Validation loss: 2.9041345531657043

Epoch: 5| Step: 8
Training loss: 2.66263951755386
Validation loss: 2.89393991035736

Epoch: 5| Step: 9
Training loss: 3.0060062682390374
Validation loss: 2.897509963225943

Epoch: 5| Step: 10
Training loss: 3.7906688313414834
Validation loss: 2.8927168833378754

Epoch: 355| Step: 0
Training loss: 2.8361286697898604
Validation loss: 2.894115153990671

Epoch: 5| Step: 1
Training loss: 3.3631846982275726
Validation loss: 2.904942696037067

Epoch: 5| Step: 2
Training loss: 3.188200480964729
Validation loss: 2.907620692812239

Epoch: 5| Step: 3
Training loss: 2.3934357519027594
Validation loss: 2.907215135898074

Epoch: 5| Step: 4
Training loss: 3.4142409917407144
Validation loss: 2.901218094714088

Epoch: 5| Step: 5
Training loss: 3.920467534502347
Validation loss: 2.899314821669896

Epoch: 5| Step: 6
Training loss: 2.5565700302693903
Validation loss: 2.8890754002796473

Epoch: 5| Step: 7
Training loss: 3.090788840183368
Validation loss: 2.885900540752049

Epoch: 5| Step: 8
Training loss: 3.5733708277438545
Validation loss: 2.8881349489549155

Epoch: 5| Step: 9
Training loss: 3.1032974425745663
Validation loss: 2.886626196246515

Epoch: 5| Step: 10
Training loss: 3.231160506110391
Validation loss: 2.880579593254754

Epoch: 356| Step: 0
Training loss: 3.515179415121738
Validation loss: 2.8828201620655562

Epoch: 5| Step: 1
Training loss: 2.7995122484721695
Validation loss: 2.8784868257048077

Epoch: 5| Step: 2
Training loss: 3.4804695720222094
Validation loss: 2.8818156637658725

Epoch: 5| Step: 3
Training loss: 2.875239818356292
Validation loss: 2.88299638395309

Epoch: 5| Step: 4
Training loss: 2.9994774999192733
Validation loss: 2.87937536794944

Epoch: 5| Step: 5
Training loss: 2.9151223226698275
Validation loss: 2.883096284301921

Epoch: 5| Step: 6
Training loss: 3.1421760031529167
Validation loss: 2.88417934425664

Epoch: 5| Step: 7
Training loss: 3.638808423447669
Validation loss: 2.8805756462178334

Epoch: 5| Step: 8
Training loss: 2.5857901632049423
Validation loss: 2.8834429089221647

Epoch: 5| Step: 9
Training loss: 3.212951474062846
Validation loss: 2.8972682586259637

Epoch: 5| Step: 10
Training loss: 3.6601729255223123
Validation loss: 2.8907997191621906

Epoch: 357| Step: 0
Training loss: 3.4446283123887627
Validation loss: 2.8964617343863233

Epoch: 5| Step: 1
Training loss: 2.9781763702797517
Validation loss: 2.887458116120797

Epoch: 5| Step: 2
Training loss: 2.7526629299410383
Validation loss: 2.8849406012713503

Epoch: 5| Step: 3
Training loss: 3.1079196303493655
Validation loss: 2.883299904119217

Epoch: 5| Step: 4
Training loss: 2.937242374891773
Validation loss: 2.879852586856597

Epoch: 5| Step: 5
Training loss: 3.274472457679043
Validation loss: 2.8820119313601538

Epoch: 5| Step: 6
Training loss: 3.343152714798247
Validation loss: 2.8906207039448333

Epoch: 5| Step: 7
Training loss: 2.8263491118243693
Validation loss: 2.887885864823984

Epoch: 5| Step: 8
Training loss: 3.3018954411108052
Validation loss: 2.8895964145234925

Epoch: 5| Step: 9
Training loss: 3.791784193851451
Validation loss: 2.882307890007517

Epoch: 5| Step: 10
Training loss: 3.001136246717617
Validation loss: 2.8930596632156513

Epoch: 358| Step: 0
Training loss: 3.225675521008506
Validation loss: 2.8876798437648183

Epoch: 5| Step: 1
Training loss: 2.964146307130963
Validation loss: 2.880827095041382

Epoch: 5| Step: 2
Training loss: 3.5679001953809215
Validation loss: 2.8886572315307757

Epoch: 5| Step: 3
Training loss: 3.2400281954350882
Validation loss: 2.880539925955236

Epoch: 5| Step: 4
Training loss: 3.6739881562782895
Validation loss: 2.8885989577751197

Epoch: 5| Step: 5
Training loss: 2.3796230294905305
Validation loss: 2.8895819797958224

Epoch: 5| Step: 6
Training loss: 3.3680731721572457
Validation loss: 2.889345305631118

Epoch: 5| Step: 7
Training loss: 3.374615400087948
Validation loss: 2.884429148417045

Epoch: 5| Step: 8
Training loss: 3.5474291129150455
Validation loss: 2.8948996286789974

Epoch: 5| Step: 9
Training loss: 2.541345127800187
Validation loss: 2.8862637732396776

Epoch: 5| Step: 10
Training loss: 2.665832736830204
Validation loss: 2.890087261474316

Epoch: 359| Step: 0
Training loss: 3.387464887711534
Validation loss: 2.890159694090079

Epoch: 5| Step: 1
Training loss: 3.6684121543346
Validation loss: 2.887085383471752

Epoch: 5| Step: 2
Training loss: 3.0195543058830316
Validation loss: 2.8784009650033977

Epoch: 5| Step: 3
Training loss: 3.6034010292584884
Validation loss: 2.8769194984151407

Epoch: 5| Step: 4
Training loss: 3.1728874808004637
Validation loss: 2.876174512075074

Epoch: 5| Step: 5
Training loss: 2.6209534836374173
Validation loss: 2.879721651694957

Epoch: 5| Step: 6
Training loss: 3.470240092477533
Validation loss: 2.8748752786299705

Epoch: 5| Step: 7
Training loss: 3.2400920668813833
Validation loss: 2.879599132611631

Epoch: 5| Step: 8
Training loss: 2.5742889533650803
Validation loss: 2.8813929590601632

Epoch: 5| Step: 9
Training loss: 2.76410508282057
Validation loss: 2.8813139879732708

Epoch: 5| Step: 10
Training loss: 3.2251713965950013
Validation loss: 2.8759224184572356

Epoch: 360| Step: 0
Training loss: 2.6719199728945355
Validation loss: 2.8759463849434272

Epoch: 5| Step: 1
Training loss: 3.212971212657639
Validation loss: 2.878621232406882

Epoch: 5| Step: 2
Training loss: 3.7881667503947587
Validation loss: 2.8789572479784153

Epoch: 5| Step: 3
Training loss: 3.0768840631432477
Validation loss: 2.8760872239050723

Epoch: 5| Step: 4
Training loss: 2.7679084790650546
Validation loss: 2.880977047755074

Epoch: 5| Step: 5
Training loss: 3.0366556006466188
Validation loss: 2.877183680543383

Epoch: 5| Step: 6
Training loss: 3.2852755603148647
Validation loss: 2.880145308436176

Epoch: 5| Step: 7
Training loss: 3.410700978472135
Validation loss: 2.8845941610636214

Epoch: 5| Step: 8
Training loss: 3.4500208923149533
Validation loss: 2.8754476187192544

Epoch: 5| Step: 9
Training loss: 2.91650942423982
Validation loss: 2.885682020331749

Epoch: 5| Step: 10
Training loss: 3.0901318595430185
Validation loss: 2.878022180650688

Epoch: 361| Step: 0
Training loss: 2.8276612128078082
Validation loss: 2.8758139338691713

Epoch: 5| Step: 1
Training loss: 3.2253841437503006
Validation loss: 2.8808508000316615

Epoch: 5| Step: 2
Training loss: 3.729498452428294
Validation loss: 2.8853027408922727

Epoch: 5| Step: 3
Training loss: 3.239954462084589
Validation loss: 2.880893948700183

Epoch: 5| Step: 4
Training loss: 3.61846611213919
Validation loss: 2.8800786706133295

Epoch: 5| Step: 5
Training loss: 3.3655900108622587
Validation loss: 2.8891886549546646

Epoch: 5| Step: 6
Training loss: 2.9979624186495824
Validation loss: 2.880652911930897

Epoch: 5| Step: 7
Training loss: 3.0387260819580093
Validation loss: 2.8854533548148713

Epoch: 5| Step: 8
Training loss: 3.1098072767493083
Validation loss: 2.876171137471378

Epoch: 5| Step: 9
Training loss: 2.4431726032107495
Validation loss: 2.8726394739351413

Epoch: 5| Step: 10
Training loss: 3.0374469140205833
Validation loss: 2.8752074039759634

Epoch: 362| Step: 0
Training loss: 2.961310129195254
Validation loss: 2.873384873607199

Epoch: 5| Step: 1
Training loss: 2.9596289005143475
Validation loss: 2.873565822598724

Epoch: 5| Step: 2
Training loss: 3.457284760743627
Validation loss: 2.872376139001928

Epoch: 5| Step: 3
Training loss: 3.4143721311341744
Validation loss: 2.874074918162467

Epoch: 5| Step: 4
Training loss: 3.0141272111257402
Validation loss: 2.874378873795541

Epoch: 5| Step: 5
Training loss: 3.222126199307329
Validation loss: 2.8754975136778125

Epoch: 5| Step: 6
Training loss: 3.2928920026458304
Validation loss: 2.8767561878860946

Epoch: 5| Step: 7
Training loss: 2.819685340533
Validation loss: 2.882065850702202

Epoch: 5| Step: 8
Training loss: 3.2398960334674665
Validation loss: 2.8810748905627177

Epoch: 5| Step: 9
Training loss: 3.0597182115445887
Validation loss: 2.8777561851210636

Epoch: 5| Step: 10
Training loss: 3.36498951699153
Validation loss: 2.8749350780773786

Epoch: 363| Step: 0
Training loss: 3.601049423908283
Validation loss: 2.8781047088191736

Epoch: 5| Step: 1
Training loss: 3.2632547199832067
Validation loss: 2.8723178352721055

Epoch: 5| Step: 2
Training loss: 2.507986282554481
Validation loss: 2.873539059874411

Epoch: 5| Step: 3
Training loss: 3.2375941082447643
Validation loss: 2.8714270082385207

Epoch: 5| Step: 4
Training loss: 2.885535466104595
Validation loss: 2.870294835937497

Epoch: 5| Step: 5
Training loss: 3.3655939779029613
Validation loss: 2.8704285178629654

Epoch: 5| Step: 6
Training loss: 3.2847950994262707
Validation loss: 2.8734985539929627

Epoch: 5| Step: 7
Training loss: 2.7626185050851073
Validation loss: 2.8688934750699

Epoch: 5| Step: 8
Training loss: 3.3167025699940558
Validation loss: 2.872636434303923

Epoch: 5| Step: 9
Training loss: 3.165618287933253
Validation loss: 2.8702097448404946

Epoch: 5| Step: 10
Training loss: 3.320900683196691
Validation loss: 2.872234609755986

Epoch: 364| Step: 0
Training loss: 3.1025923933585235
Validation loss: 2.867903409102775

Epoch: 5| Step: 1
Training loss: 3.204928006986781
Validation loss: 2.8716927812075563

Epoch: 5| Step: 2
Training loss: 2.6065419973461856
Validation loss: 2.8702812991298465

Epoch: 5| Step: 3
Training loss: 2.8955295504032246
Validation loss: 2.874434144813509

Epoch: 5| Step: 4
Training loss: 3.0347309379151803
Validation loss: 2.870810750084291

Epoch: 5| Step: 5
Training loss: 3.5052552959287047
Validation loss: 2.8772874197438583

Epoch: 5| Step: 6
Training loss: 3.2199950541582685
Validation loss: 2.8731139810774184

Epoch: 5| Step: 7
Training loss: 3.270551843537584
Validation loss: 2.8722731886014072

Epoch: 5| Step: 8
Training loss: 2.696490663302551
Validation loss: 2.876852290404873

Epoch: 5| Step: 9
Training loss: 3.622601998461577
Validation loss: 2.881411548865653

Epoch: 5| Step: 10
Training loss: 3.5748022384897773
Validation loss: 2.8751919670271673

Epoch: 365| Step: 0
Training loss: 3.510525815872353
Validation loss: 2.8810735789664212

Epoch: 5| Step: 1
Training loss: 2.9658915360747375
Validation loss: 2.873304688481935

Epoch: 5| Step: 2
Training loss: 2.7240224117135714
Validation loss: 2.87859279517709

Epoch: 5| Step: 3
Training loss: 2.935175523854572
Validation loss: 2.8722018303168464

Epoch: 5| Step: 4
Training loss: 3.120632018118266
Validation loss: 2.8725675874910213

Epoch: 5| Step: 5
Training loss: 3.1229071666394046
Validation loss: 2.8768074431999304

Epoch: 5| Step: 6
Training loss: 2.692248562802769
Validation loss: 2.867201895469643

Epoch: 5| Step: 7
Training loss: 3.233492376079924
Validation loss: 2.872300531667993

Epoch: 5| Step: 8
Training loss: 3.138409644556602
Validation loss: 2.871477148940085

Epoch: 5| Step: 9
Training loss: 3.4230233273147324
Validation loss: 2.867294142784797

Epoch: 5| Step: 10
Training loss: 3.8708633985607634
Validation loss: 2.8711101045715437

Epoch: 366| Step: 0
Training loss: 3.6337559941219078
Validation loss: 2.871390334020934

Epoch: 5| Step: 1
Training loss: 2.890466964113218
Validation loss: 2.8719836797564455

Epoch: 5| Step: 2
Training loss: 3.3973482337497143
Validation loss: 2.8687290579531686

Epoch: 5| Step: 3
Training loss: 3.613232685484444
Validation loss: 2.8705618095386054

Epoch: 5| Step: 4
Training loss: 3.0714547165679873
Validation loss: 2.868283981993901

Epoch: 5| Step: 5
Training loss: 2.983563857167284
Validation loss: 2.873898688021825

Epoch: 5| Step: 6
Training loss: 3.220855320653511
Validation loss: 2.8706484834064003

Epoch: 5| Step: 7
Training loss: 3.400906772869051
Validation loss: 2.8704572163838398

Epoch: 5| Step: 8
Training loss: 2.7903012214951355
Validation loss: 2.8721156728313497

Epoch: 5| Step: 9
Training loss: 2.7013782303792437
Validation loss: 2.8763815639800137

Epoch: 5| Step: 10
Training loss: 2.8813856775606355
Validation loss: 2.875429947900564

Epoch: 367| Step: 0
Training loss: 3.184149683055362
Validation loss: 2.8738228491104025

Epoch: 5| Step: 1
Training loss: 3.479190955772056
Validation loss: 2.8765374558451944

Epoch: 5| Step: 2
Training loss: 3.3162003488055376
Validation loss: 2.8776243946435596

Epoch: 5| Step: 3
Training loss: 2.943687901580951
Validation loss: 2.8747857162422696

Epoch: 5| Step: 4
Training loss: 3.6838447428656074
Validation loss: 2.8660878211843688

Epoch: 5| Step: 5
Training loss: 3.2856639419868934
Validation loss: 2.864028596535007

Epoch: 5| Step: 6
Training loss: 2.955470531199899
Validation loss: 2.8651704808834815

Epoch: 5| Step: 7
Training loss: 2.3607210273390837
Validation loss: 2.8643098275882006

Epoch: 5| Step: 8
Training loss: 2.9031526200835613
Validation loss: 2.8653860992517246

Epoch: 5| Step: 9
Training loss: 3.586155172153348
Validation loss: 2.8640475317770635

Epoch: 5| Step: 10
Training loss: 2.815192734945104
Validation loss: 2.8639101539969904

Epoch: 368| Step: 0
Training loss: 2.6819466279456283
Validation loss: 2.8673335507570976

Epoch: 5| Step: 1
Training loss: 2.674415406851019
Validation loss: 2.8627162942803768

Epoch: 5| Step: 2
Training loss: 3.881374161802896
Validation loss: 2.8626329741020244

Epoch: 5| Step: 3
Training loss: 3.6906542461118277
Validation loss: 2.863102067723205

Epoch: 5| Step: 4
Training loss: 2.6512421018203147
Validation loss: 2.86092721494315

Epoch: 5| Step: 5
Training loss: 3.052206841965357
Validation loss: 2.862716736670836

Epoch: 5| Step: 6
Training loss: 2.983089789425129
Validation loss: 2.862684550347656

Epoch: 5| Step: 7
Training loss: 3.571687596328464
Validation loss: 2.8607683503779335

Epoch: 5| Step: 8
Training loss: 2.800280240203744
Validation loss: 2.865286483305916

Epoch: 5| Step: 9
Training loss: 3.590638779363927
Validation loss: 2.860368014342071

Epoch: 5| Step: 10
Training loss: 2.8126302053193912
Validation loss: 2.8684622605427315

Epoch: 369| Step: 0
Training loss: 2.4913583171320943
Validation loss: 2.871265799606489

Epoch: 5| Step: 1
Training loss: 2.9474073493509194
Validation loss: 2.8725357052102694

Epoch: 5| Step: 2
Training loss: 3.4180498037264457
Validation loss: 2.870457604887662

Epoch: 5| Step: 3
Training loss: 2.9931954461548007
Validation loss: 2.8705453687863276

Epoch: 5| Step: 4
Training loss: 3.2870086999028927
Validation loss: 2.8692690141089563

Epoch: 5| Step: 5
Training loss: 2.8935070619709538
Validation loss: 2.8795890475370642

Epoch: 5| Step: 6
Training loss: 3.8437844871896707
Validation loss: 2.8840162750417435

Epoch: 5| Step: 7
Training loss: 3.432016194721062
Validation loss: 2.8681406727565166

Epoch: 5| Step: 8
Training loss: 3.0681233063330047
Validation loss: 2.8627033780607802

Epoch: 5| Step: 9
Training loss: 2.810017740729861
Validation loss: 2.8600565873920165

Epoch: 5| Step: 10
Training loss: 3.482317535155204
Validation loss: 2.861608047397632

Epoch: 370| Step: 0
Training loss: 2.3534643650408413
Validation loss: 2.859139775091598

Epoch: 5| Step: 1
Training loss: 2.7451563574168705
Validation loss: 2.8618134263401096

Epoch: 5| Step: 2
Training loss: 3.510694241892705
Validation loss: 2.86040540437737

Epoch: 5| Step: 3
Training loss: 3.359800799686526
Validation loss: 2.862281038498804

Epoch: 5| Step: 4
Training loss: 2.88607512488238
Validation loss: 2.863735278533303

Epoch: 5| Step: 5
Training loss: 3.178983643256026
Validation loss: 2.860451295635265

Epoch: 5| Step: 6
Training loss: 3.211550020700507
Validation loss: 2.8595497637850538

Epoch: 5| Step: 7
Training loss: 3.334647078706586
Validation loss: 2.859449680033861

Epoch: 5| Step: 8
Training loss: 3.325803421588211
Validation loss: 2.8626370873757434

Epoch: 5| Step: 9
Training loss: 2.339254416502868
Validation loss: 2.8625742332576034

Epoch: 5| Step: 10
Training loss: 4.272293635117217
Validation loss: 2.8625195867385367

Epoch: 371| Step: 0
Training loss: 2.761666433656261
Validation loss: 2.8706362574876785

Epoch: 5| Step: 1
Training loss: 3.2780468519585337
Validation loss: 2.873476829643959

Epoch: 5| Step: 2
Training loss: 3.261692142949113
Validation loss: 2.880086606989737

Epoch: 5| Step: 3
Training loss: 3.3103198668481584
Validation loss: 2.8799230309681425

Epoch: 5| Step: 4
Training loss: 2.729471048945427
Validation loss: 2.878636170946192

Epoch: 5| Step: 5
Training loss: 3.0096629606111396
Validation loss: 2.8705675832934103

Epoch: 5| Step: 6
Training loss: 3.107656492802623
Validation loss: 2.8641366977728877

Epoch: 5| Step: 7
Training loss: 3.4589765172747424
Validation loss: 2.860393450159204

Epoch: 5| Step: 8
Training loss: 2.742922605573481
Validation loss: 2.8662296508171465

Epoch: 5| Step: 9
Training loss: 3.380992514348424
Validation loss: 2.871528059234713

Epoch: 5| Step: 10
Training loss: 3.621694175544351
Validation loss: 2.8632496600652484

Epoch: 372| Step: 0
Training loss: 3.0785782378680593
Validation loss: 2.864256222003972

Epoch: 5| Step: 1
Training loss: 3.426441089933642
Validation loss: 2.8616081907374906

Epoch: 5| Step: 2
Training loss: 2.8770179300979306
Validation loss: 2.865797827032835

Epoch: 5| Step: 3
Training loss: 3.332378552707132
Validation loss: 2.8580429226192843

Epoch: 5| Step: 4
Training loss: 3.260407144128383
Validation loss: 2.8686018323917475

Epoch: 5| Step: 5
Training loss: 2.985892823592215
Validation loss: 2.862453589139503

Epoch: 5| Step: 6
Training loss: 3.2549009783283953
Validation loss: 2.863842517152225

Epoch: 5| Step: 7
Training loss: 3.383693659594855
Validation loss: 2.8647503485146286

Epoch: 5| Step: 8
Training loss: 3.325677822692192
Validation loss: 2.8696624185998343

Epoch: 5| Step: 9
Training loss: 2.7742032565492893
Validation loss: 2.8653311932110004

Epoch: 5| Step: 10
Training loss: 2.953844416752329
Validation loss: 2.8811293461969876

Epoch: 373| Step: 0
Training loss: 3.3071069540672022
Validation loss: 2.8602026258234554

Epoch: 5| Step: 1
Training loss: 3.7321982963027036
Validation loss: 2.861039196785463

Epoch: 5| Step: 2
Training loss: 3.4731845861447668
Validation loss: 2.8583413962542834

Epoch: 5| Step: 3
Training loss: 3.0428925922153067
Validation loss: 2.8544006132015842

Epoch: 5| Step: 4
Training loss: 3.1603619068877737
Validation loss: 2.853136529869874

Epoch: 5| Step: 5
Training loss: 3.408593447831897
Validation loss: 2.8537225125431798

Epoch: 5| Step: 6
Training loss: 2.534954139399978
Validation loss: 2.854495158437824

Epoch: 5| Step: 7
Training loss: 2.6389215155029015
Validation loss: 2.854826668014701

Epoch: 5| Step: 8
Training loss: 3.5122360510431343
Validation loss: 2.85722527581028

Epoch: 5| Step: 9
Training loss: 2.7016809387896883
Validation loss: 2.8543139614981246

Epoch: 5| Step: 10
Training loss: 2.952084958639799
Validation loss: 2.856956367698378

Epoch: 374| Step: 0
Training loss: 3.618543729025818
Validation loss: 2.854257313763662

Epoch: 5| Step: 1
Training loss: 3.1656685979614387
Validation loss: 2.853902948452272

Epoch: 5| Step: 2
Training loss: 1.9678908395886356
Validation loss: 2.860963617363339

Epoch: 5| Step: 3
Training loss: 3.0596776919694255
Validation loss: 2.8604948989973504

Epoch: 5| Step: 4
Training loss: 3.5889358783817444
Validation loss: 2.8621939428555505

Epoch: 5| Step: 5
Training loss: 1.830844323853518
Validation loss: 2.856893137340777

Epoch: 5| Step: 6
Training loss: 3.0359763825695385
Validation loss: 2.8578317387639167

Epoch: 5| Step: 7
Training loss: 2.9979236092839407
Validation loss: 2.8595159666128467

Epoch: 5| Step: 8
Training loss: 3.4936042659711637
Validation loss: 2.8616075618338095

Epoch: 5| Step: 9
Training loss: 3.811539951203658
Validation loss: 2.86215562494883

Epoch: 5| Step: 10
Training loss: 3.5178393362810403
Validation loss: 2.858942292411351

Epoch: 375| Step: 0
Training loss: 2.498479285257551
Validation loss: 2.8517643215284223

Epoch: 5| Step: 1
Training loss: 2.9237754475569453
Validation loss: 2.8547772702821783

Epoch: 5| Step: 2
Training loss: 3.122877544610158
Validation loss: 2.8526228087136962

Epoch: 5| Step: 3
Training loss: 3.0414025875748565
Validation loss: 2.850583588427828

Epoch: 5| Step: 4
Training loss: 3.9433852521284427
Validation loss: 2.8521018275244794

Epoch: 5| Step: 5
Training loss: 3.2921370319106464
Validation loss: 2.851036499075823

Epoch: 5| Step: 6
Training loss: 3.0688159197468967
Validation loss: 2.8528495640618003

Epoch: 5| Step: 7
Training loss: 3.169629885610522
Validation loss: 2.8525696179978346

Epoch: 5| Step: 8
Training loss: 2.9122886679275726
Validation loss: 2.8532306533647374

Epoch: 5| Step: 9
Training loss: 3.009431319140549
Validation loss: 2.8552498507196256

Epoch: 5| Step: 10
Training loss: 3.553587221328246
Validation loss: 2.85492291426836

Epoch: 376| Step: 0
Training loss: 2.9698601504194295
Validation loss: 2.8531796079679035

Epoch: 5| Step: 1
Training loss: 3.0923457185689727
Validation loss: 2.8588505396257813

Epoch: 5| Step: 2
Training loss: 3.441717023381028
Validation loss: 2.8582627542603154

Epoch: 5| Step: 3
Training loss: 3.422986411840832
Validation loss: 2.8544385358542876

Epoch: 5| Step: 4
Training loss: 2.8844082352034657
Validation loss: 2.8512821758156806

Epoch: 5| Step: 5
Training loss: 3.512920102013059
Validation loss: 2.8502833786993005

Epoch: 5| Step: 6
Training loss: 2.8772612262360653
Validation loss: 2.8509400442853425

Epoch: 5| Step: 7
Training loss: 2.685570845063481
Validation loss: 2.8503615474014454

Epoch: 5| Step: 8
Training loss: 2.3381657514204854
Validation loss: 2.8510344507065835

Epoch: 5| Step: 9
Training loss: 3.79144853795897
Validation loss: 2.8530642814174425

Epoch: 5| Step: 10
Training loss: 3.4174373191772474
Validation loss: 2.856851792415481

Epoch: 377| Step: 0
Training loss: 3.0808403315390267
Validation loss: 2.850445646292399

Epoch: 5| Step: 1
Training loss: 2.5758258162007954
Validation loss: 2.8518673861770263

Epoch: 5| Step: 2
Training loss: 3.649636963857713
Validation loss: 2.85594338474221

Epoch: 5| Step: 3
Training loss: 3.3073656128954476
Validation loss: 2.849940306882671

Epoch: 5| Step: 4
Training loss: 2.9137358699735816
Validation loss: 2.849872444635971

Epoch: 5| Step: 5
Training loss: 3.3173914368264406
Validation loss: 2.8572462121263387

Epoch: 5| Step: 6
Training loss: 3.042393445144963
Validation loss: 2.857974822201918

Epoch: 5| Step: 7
Training loss: 2.9471858616091136
Validation loss: 2.8620416409226768

Epoch: 5| Step: 8
Training loss: 3.3764646672202594
Validation loss: 2.861012968319564

Epoch: 5| Step: 9
Training loss: 3.383843879200651
Validation loss: 2.860834860899877

Epoch: 5| Step: 10
Training loss: 2.873430901955958
Validation loss: 2.873263661797307

Epoch: 378| Step: 0
Training loss: 3.414659391203546
Validation loss: 2.86223074834315

Epoch: 5| Step: 1
Training loss: 3.3706402346484063
Validation loss: 2.8485358695245018

Epoch: 5| Step: 2
Training loss: 3.272549237841827
Validation loss: 2.855121378921678

Epoch: 5| Step: 3
Training loss: 3.246971186221903
Validation loss: 2.846796997222068

Epoch: 5| Step: 4
Training loss: 3.283800278457694
Validation loss: 2.850237291349121

Epoch: 5| Step: 5
Training loss: 2.5412522483624347
Validation loss: 2.849145141267255

Epoch: 5| Step: 6
Training loss: 3.185659138790522
Validation loss: 2.8515597300867914

Epoch: 5| Step: 7
Training loss: 3.2114413346442774
Validation loss: 2.852108743345978

Epoch: 5| Step: 8
Training loss: 2.9500758662409257
Validation loss: 2.8469660226436058

Epoch: 5| Step: 9
Training loss: 3.063698358991579
Validation loss: 2.8488458103272785

Epoch: 5| Step: 10
Training loss: 2.9673812119989265
Validation loss: 2.84572625773514

Epoch: 379| Step: 0
Training loss: 2.966463513508558
Validation loss: 2.8466006629922873

Epoch: 5| Step: 1
Training loss: 3.3596791684154987
Validation loss: 2.8447696273658374

Epoch: 5| Step: 2
Training loss: 3.4406698696942257
Validation loss: 2.8526546709028415

Epoch: 5| Step: 3
Training loss: 3.5819958401160097
Validation loss: 2.848162754349241

Epoch: 5| Step: 4
Training loss: 2.7566259495389263
Validation loss: 2.8499122824174385

Epoch: 5| Step: 5
Training loss: 3.2384454296721374
Validation loss: 2.8525686069458316

Epoch: 5| Step: 6
Training loss: 2.9882793351709553
Validation loss: 2.852587409758312

Epoch: 5| Step: 7
Training loss: 2.819851232622227
Validation loss: 2.860649643803373

Epoch: 5| Step: 8
Training loss: 2.670178862163511
Validation loss: 2.8509011812526475

Epoch: 5| Step: 9
Training loss: 3.158702388596324
Validation loss: 2.8564675908902264

Epoch: 5| Step: 10
Training loss: 3.566395420087267
Validation loss: 2.8530374881215788

Epoch: 380| Step: 0
Training loss: 3.246563488406307
Validation loss: 2.8535616333488067

Epoch: 5| Step: 1
Training loss: 3.271474317848347
Validation loss: 2.8500212806924696

Epoch: 5| Step: 2
Training loss: 3.3269149658049972
Validation loss: 2.8471858235282017

Epoch: 5| Step: 3
Training loss: 3.766721193937301
Validation loss: 2.849130595177725

Epoch: 5| Step: 4
Training loss: 2.5486242921669118
Validation loss: 2.847144588856379

Epoch: 5| Step: 5
Training loss: 3.148617571279252
Validation loss: 2.8442424296884403

Epoch: 5| Step: 6
Training loss: 3.418541525668472
Validation loss: 2.844726974344042

Epoch: 5| Step: 7
Training loss: 3.0986669750716844
Validation loss: 2.8465625035318296

Epoch: 5| Step: 8
Training loss: 3.3912974451094753
Validation loss: 2.845671763348535

Epoch: 5| Step: 9
Training loss: 2.452277650698824
Validation loss: 2.848004852054703

Epoch: 5| Step: 10
Training loss: 2.587290522255186
Validation loss: 2.8479993053053825

Epoch: 381| Step: 0
Training loss: 3.212453962062962
Validation loss: 2.8437101642388236

Epoch: 5| Step: 1
Training loss: 2.718107476439996
Validation loss: 2.8484243843539376

Epoch: 5| Step: 2
Training loss: 3.3757224545945865
Validation loss: 2.85037059364213

Epoch: 5| Step: 3
Training loss: 2.987775373336917
Validation loss: 2.8484724630488545

Epoch: 5| Step: 4
Training loss: 3.6343645615563096
Validation loss: 2.846307094589184

Epoch: 5| Step: 5
Training loss: 2.5847094060010805
Validation loss: 2.8479432278011796

Epoch: 5| Step: 6
Training loss: 2.9908783840195854
Validation loss: 2.8479106170594606

Epoch: 5| Step: 7
Training loss: 2.9766158452097264
Validation loss: 2.8530942103941475

Epoch: 5| Step: 8
Training loss: 3.4881297865703025
Validation loss: 2.850595843692324

Epoch: 5| Step: 9
Training loss: 3.4243422718994063
Validation loss: 2.8597410440560567

Epoch: 5| Step: 10
Training loss: 2.9939052342443544
Validation loss: 2.853682610267572

Epoch: 382| Step: 0
Training loss: 3.383446473232796
Validation loss: 2.854461243040855

Epoch: 5| Step: 1
Training loss: 3.421537896539159
Validation loss: 2.8509316949557224

Epoch: 5| Step: 2
Training loss: 2.6518036372472187
Validation loss: 2.8470907627320807

Epoch: 5| Step: 3
Training loss: 3.571138449192809
Validation loss: 2.8453266758719447

Epoch: 5| Step: 4
Training loss: 3.1010881729064295
Validation loss: 2.8450423302467676

Epoch: 5| Step: 5
Training loss: 3.1977224052812643
Validation loss: 2.843102923434347

Epoch: 5| Step: 6
Training loss: 2.750187087197415
Validation loss: 2.8471100834545497

Epoch: 5| Step: 7
Training loss: 2.3463732471318277
Validation loss: 2.8505304388035433

Epoch: 5| Step: 8
Training loss: 3.613140173555037
Validation loss: 2.849047936779173

Epoch: 5| Step: 9
Training loss: 2.945294205586005
Validation loss: 2.8446364735622742

Epoch: 5| Step: 10
Training loss: 3.3556101439486956
Validation loss: 2.841566042089382

Epoch: 383| Step: 0
Training loss: 3.459513696441906
Validation loss: 2.8425959612236698

Epoch: 5| Step: 1
Training loss: 3.159598509959869
Validation loss: 2.8442218555375933

Epoch: 5| Step: 2
Training loss: 3.0581882251820423
Validation loss: 2.84295273505937

Epoch: 5| Step: 3
Training loss: 2.976568427292737
Validation loss: 2.8396316649759688

Epoch: 5| Step: 4
Training loss: 3.0215683316955566
Validation loss: 2.839327678851797

Epoch: 5| Step: 5
Training loss: 2.8380163050714775
Validation loss: 2.8384023529272766

Epoch: 5| Step: 6
Training loss: 3.6319702484660015
Validation loss: 2.844670145611076

Epoch: 5| Step: 7
Training loss: 2.8615007680424993
Validation loss: 2.841775740965749

Epoch: 5| Step: 8
Training loss: 2.6917667673431422
Validation loss: 2.8400967487761055

Epoch: 5| Step: 9
Training loss: 3.037712209062585
Validation loss: 2.844018140337474

Epoch: 5| Step: 10
Training loss: 3.7658902783163866
Validation loss: 2.8369806605589267

Epoch: 384| Step: 0
Training loss: 3.342701257254597
Validation loss: 2.8391490986664856

Epoch: 5| Step: 1
Training loss: 2.587840506590162
Validation loss: 2.844293572384293

Epoch: 5| Step: 2
Training loss: 3.48444096113645
Validation loss: 2.8402925929828524

Epoch: 5| Step: 3
Training loss: 3.3061302408548014
Validation loss: 2.85275611636235

Epoch: 5| Step: 4
Training loss: 2.611302834319144
Validation loss: 2.849261375945695

Epoch: 5| Step: 5
Training loss: 3.404687925761504
Validation loss: 2.855227574500167

Epoch: 5| Step: 6
Training loss: 2.8030063191511747
Validation loss: 2.8397096159129114

Epoch: 5| Step: 7
Training loss: 2.812440574865912
Validation loss: 2.852191427191978

Epoch: 5| Step: 8
Training loss: 3.5093559828503684
Validation loss: 2.8432559242593896

Epoch: 5| Step: 9
Training loss: 2.9584554369447065
Validation loss: 2.8476141209633203

Epoch: 5| Step: 10
Training loss: 3.5705016104867227
Validation loss: 2.8445938122352876

Epoch: 385| Step: 0
Training loss: 3.1485161026071418
Validation loss: 2.8436028903258412

Epoch: 5| Step: 1
Training loss: 3.711192810913083
Validation loss: 2.8445352855891146

Epoch: 5| Step: 2
Training loss: 3.397088986897444
Validation loss: 2.8406248629656488

Epoch: 5| Step: 3
Training loss: 3.4731727790944094
Validation loss: 2.8381401540453894

Epoch: 5| Step: 4
Training loss: 3.4290093726928097
Validation loss: 2.8397978931443943

Epoch: 5| Step: 5
Training loss: 2.998841220856435
Validation loss: 2.83657550496922

Epoch: 5| Step: 6
Training loss: 3.2078188859417986
Validation loss: 2.8357592225273005

Epoch: 5| Step: 7
Training loss: 2.5289414793146836
Validation loss: 2.839357800476089

Epoch: 5| Step: 8
Training loss: 2.6480413720163356
Validation loss: 2.8352949878560607

Epoch: 5| Step: 9
Training loss: 3.0451464322464434
Validation loss: 2.8383598833147388

Epoch: 5| Step: 10
Training loss: 2.658921188919577
Validation loss: 2.8362379103408673

Epoch: 386| Step: 0
Training loss: 3.74777537163129
Validation loss: 2.8380972649933542

Epoch: 5| Step: 1
Training loss: 2.72258146558206
Validation loss: 2.8394417855805676

Epoch: 5| Step: 2
Training loss: 2.9048770409724654
Validation loss: 2.8369763248377358

Epoch: 5| Step: 3
Training loss: 2.9045966583049916
Validation loss: 2.8387165149320177

Epoch: 5| Step: 4
Training loss: 2.9580066840848787
Validation loss: 2.840397101907468

Epoch: 5| Step: 5
Training loss: 3.5292252668959896
Validation loss: 2.838134644923724

Epoch: 5| Step: 6
Training loss: 3.4208032331795755
Validation loss: 2.840500173767425

Epoch: 5| Step: 7
Training loss: 2.5765328779767525
Validation loss: 2.838148851733493

Epoch: 5| Step: 8
Training loss: 3.2860416847505842
Validation loss: 2.8414046117416687

Epoch: 5| Step: 9
Training loss: 2.8840028533074897
Validation loss: 2.845728365779386

Epoch: 5| Step: 10
Training loss: 3.3923044571993346
Validation loss: 2.8406135141086386

Epoch: 387| Step: 0
Training loss: 2.4417689183754936
Validation loss: 2.845265023346725

Epoch: 5| Step: 1
Training loss: 2.7688835473499784
Validation loss: 2.8575085311459563

Epoch: 5| Step: 2
Training loss: 3.0191986571963447
Validation loss: 2.8476441648387674

Epoch: 5| Step: 3
Training loss: 3.828614869206803
Validation loss: 2.857210442462221

Epoch: 5| Step: 4
Training loss: 3.1970228174067716
Validation loss: 2.8529887225631496

Epoch: 5| Step: 5
Training loss: 3.491569583851153
Validation loss: 2.8368784883134737

Epoch: 5| Step: 6
Training loss: 2.8778019395531547
Validation loss: 2.836191833385862

Epoch: 5| Step: 7
Training loss: 3.0435102615095717
Validation loss: 2.836936327090583

Epoch: 5| Step: 8
Training loss: 2.712009009298478
Validation loss: 2.8329448439646816

Epoch: 5| Step: 9
Training loss: 3.454054763386313
Validation loss: 2.8316950836211077

Epoch: 5| Step: 10
Training loss: 3.4829323009972613
Validation loss: 2.8353089195555965

Epoch: 388| Step: 0
Training loss: 3.2626486908802392
Validation loss: 2.830330809239851

Epoch: 5| Step: 1
Training loss: 3.308117252342943
Validation loss: 2.8322132624382026

Epoch: 5| Step: 2
Training loss: 3.318916009174102
Validation loss: 2.8323003884456868

Epoch: 5| Step: 3
Training loss: 3.4193556059153294
Validation loss: 2.8339898686698404

Epoch: 5| Step: 4
Training loss: 2.611005992892754
Validation loss: 2.8333633977415715

Epoch: 5| Step: 5
Training loss: 2.782290574767083
Validation loss: 2.8334338702968345

Epoch: 5| Step: 6
Training loss: 3.2016231830853745
Validation loss: 2.8346388943790686

Epoch: 5| Step: 7
Training loss: 3.6384064950779336
Validation loss: 2.8387678213005283

Epoch: 5| Step: 8
Training loss: 3.1451492744765286
Validation loss: 2.8318979109568465

Epoch: 5| Step: 9
Training loss: 2.3743813361444603
Validation loss: 2.8362390618935964

Epoch: 5| Step: 10
Training loss: 3.250689946812839
Validation loss: 2.836669789362643

Epoch: 389| Step: 0
Training loss: 3.3244514070133095
Validation loss: 2.838759032491138

Epoch: 5| Step: 1
Training loss: 3.2987124850216776
Validation loss: 2.840537016665831

Epoch: 5| Step: 2
Training loss: 1.9222942608299403
Validation loss: 2.8396818281263014

Epoch: 5| Step: 3
Training loss: 2.8730566671633775
Validation loss: 2.838354655519014

Epoch: 5| Step: 4
Training loss: 3.4364904134886674
Validation loss: 2.8321583251958122

Epoch: 5| Step: 5
Training loss: 3.183575476845564
Validation loss: 2.8304150540447823

Epoch: 5| Step: 6
Training loss: 3.5275815290063277
Validation loss: 2.8364009950184648

Epoch: 5| Step: 7
Training loss: 2.882364212371294
Validation loss: 2.8323524075177358

Epoch: 5| Step: 8
Training loss: 3.141670318790273
Validation loss: 2.8313679498768214

Epoch: 5| Step: 9
Training loss: 3.103733484821112
Validation loss: 2.8325861109008668

Epoch: 5| Step: 10
Training loss: 3.524196230106709
Validation loss: 2.8327363638194627

Epoch: 390| Step: 0
Training loss: 2.8902099311373424
Validation loss: 2.8330836345903614

Epoch: 5| Step: 1
Training loss: 3.1581078528552684
Validation loss: 2.8334652208279065

Epoch: 5| Step: 2
Training loss: 3.2323913388380157
Validation loss: 2.835050865485739

Epoch: 5| Step: 3
Training loss: 3.177121938668925
Validation loss: 2.832620312648296

Epoch: 5| Step: 4
Training loss: 2.457592825703282
Validation loss: 2.8330612338486207

Epoch: 5| Step: 5
Training loss: 3.625873986480021
Validation loss: 2.838478514115666

Epoch: 5| Step: 6
Training loss: 2.8759400862500084
Validation loss: 2.8401054639413084

Epoch: 5| Step: 7
Training loss: 3.09928168311529
Validation loss: 2.839435573843122

Epoch: 5| Step: 8
Training loss: 3.413689285235669
Validation loss: 2.845731664775411

Epoch: 5| Step: 9
Training loss: 2.8332850134226093
Validation loss: 2.8427936199292434

Epoch: 5| Step: 10
Training loss: 3.6077903803051883
Validation loss: 2.839729384979056

Epoch: 391| Step: 0
Training loss: 2.757403464957711
Validation loss: 2.836316717409074

Epoch: 5| Step: 1
Training loss: 2.244598156110748
Validation loss: 2.8319651438770332

Epoch: 5| Step: 2
Training loss: 3.516171832471893
Validation loss: 2.8293320640655915

Epoch: 5| Step: 3
Training loss: 3.522023663772205
Validation loss: 2.831223204868796

Epoch: 5| Step: 4
Training loss: 3.2253075623047116
Validation loss: 2.829544707261426

Epoch: 5| Step: 5
Training loss: 3.1596163181167998
Validation loss: 2.8303187596999675

Epoch: 5| Step: 6
Training loss: 2.821133818932117
Validation loss: 2.8297261738891497

Epoch: 5| Step: 7
Training loss: 3.1921239487142534
Validation loss: 2.8283148405938525

Epoch: 5| Step: 8
Training loss: 3.435919936041113
Validation loss: 2.8281080655307242

Epoch: 5| Step: 9
Training loss: 3.2848983100932987
Validation loss: 2.8304178908437296

Epoch: 5| Step: 10
Training loss: 3.0776306375004374
Validation loss: 2.828895006704235

Epoch: 392| Step: 0
Training loss: 3.4635509672494176
Validation loss: 2.8309647493910006

Epoch: 5| Step: 1
Training loss: 2.5670940807059557
Validation loss: 2.8308808197920046

Epoch: 5| Step: 2
Training loss: 3.651939133043912
Validation loss: 2.8343356915267504

Epoch: 5| Step: 3
Training loss: 3.118209633044705
Validation loss: 2.8414019983903405

Epoch: 5| Step: 4
Training loss: 3.625574263763663
Validation loss: 2.8410218774625755

Epoch: 5| Step: 5
Training loss: 2.9398202052251925
Validation loss: 2.8402496434646824

Epoch: 5| Step: 6
Training loss: 2.9515017937899204
Validation loss: 2.8418738806892225

Epoch: 5| Step: 7
Training loss: 2.815592527890279
Validation loss: 2.8489688915763347

Epoch: 5| Step: 8
Training loss: 3.1903983010393704
Validation loss: 2.847797766086156

Epoch: 5| Step: 9
Training loss: 3.1869609601371005
Validation loss: 2.8504124687821033

Epoch: 5| Step: 10
Training loss: 2.7255989711317263
Validation loss: 2.848563679836957

Epoch: 393| Step: 0
Training loss: 3.106919896060977
Validation loss: 2.840934735574881

Epoch: 5| Step: 1
Training loss: 3.2990608381690127
Validation loss: 2.8403100013250544

Epoch: 5| Step: 2
Training loss: 3.2837726886431575
Validation loss: 2.8329916469932295

Epoch: 5| Step: 3
Training loss: 3.342932342666247
Validation loss: 2.82929962752882

Epoch: 5| Step: 4
Training loss: 2.869642490356758
Validation loss: 2.8367175250418284

Epoch: 5| Step: 5
Training loss: 3.5676439859569324
Validation loss: 2.8337925132304975

Epoch: 5| Step: 6
Training loss: 2.8505324083917207
Validation loss: 2.831532686710116

Epoch: 5| Step: 7
Training loss: 3.046230619710917
Validation loss: 2.828862191783356

Epoch: 5| Step: 8
Training loss: 3.1487879404263497
Validation loss: 2.83075904953058

Epoch: 5| Step: 9
Training loss: 3.2217491029104814
Validation loss: 2.8250110274990887

Epoch: 5| Step: 10
Training loss: 2.474894349896952
Validation loss: 2.827377781282926

Epoch: 394| Step: 0
Training loss: 2.9328163630643513
Validation loss: 2.8349255323261238

Epoch: 5| Step: 1
Training loss: 3.469046227805541
Validation loss: 2.84063224624144

Epoch: 5| Step: 2
Training loss: 3.145507054534603
Validation loss: 2.834915825487133

Epoch: 5| Step: 3
Training loss: 2.8146460081210023
Validation loss: 2.848291145787571

Epoch: 5| Step: 4
Training loss: 2.912367422336259
Validation loss: 2.863754378641683

Epoch: 5| Step: 5
Training loss: 3.5584119128470357
Validation loss: 2.860195372838601

Epoch: 5| Step: 6
Training loss: 2.902233013848958
Validation loss: 2.8652804161759255

Epoch: 5| Step: 7
Training loss: 2.973121716904687
Validation loss: 2.891068040308518

Epoch: 5| Step: 8
Training loss: 3.560169461535312
Validation loss: 2.8937102513239013

Epoch: 5| Step: 9
Training loss: 3.037350836964924
Validation loss: 2.8547967985091836

Epoch: 5| Step: 10
Training loss: 3.0878555710870073
Validation loss: 2.8407032541264097

Epoch: 395| Step: 0
Training loss: 2.8469063146818154
Validation loss: 2.8244636924254882

Epoch: 5| Step: 1
Training loss: 3.18711252288345
Validation loss: 2.823503807740176

Epoch: 5| Step: 2
Training loss: 2.820326532978852
Validation loss: 2.826326059048548

Epoch: 5| Step: 3
Training loss: 2.4978771733674137
Validation loss: 2.8389835233152976

Epoch: 5| Step: 4
Training loss: 3.1704755430001677
Validation loss: 2.829368711703716

Epoch: 5| Step: 5
Training loss: 3.51016964972473
Validation loss: 2.8307187891435577

Epoch: 5| Step: 6
Training loss: 2.8548882307899084
Validation loss: 2.8273269224343744

Epoch: 5| Step: 7
Training loss: 2.9923415978494528
Validation loss: 2.8241732367360037

Epoch: 5| Step: 8
Training loss: 3.4921965118906373
Validation loss: 2.825960046663233

Epoch: 5| Step: 9
Training loss: 3.384910162180124
Validation loss: 2.824207760037709

Epoch: 5| Step: 10
Training loss: 3.658626468763852
Validation loss: 2.824530378011907

Epoch: 396| Step: 0
Training loss: 2.7572139274111485
Validation loss: 2.8279695070966704

Epoch: 5| Step: 1
Training loss: 2.7867153346300384
Validation loss: 2.830723286598173

Epoch: 5| Step: 2
Training loss: 3.4409018589647893
Validation loss: 2.839512081096582

Epoch: 5| Step: 3
Training loss: 3.1036028936754874
Validation loss: 2.847939082503056

Epoch: 5| Step: 4
Training loss: 2.782320138168382
Validation loss: 2.8443780147220794

Epoch: 5| Step: 5
Training loss: 3.323258831779506
Validation loss: 2.850418018930067

Epoch: 5| Step: 6
Training loss: 3.385550221474203
Validation loss: 2.8352386093448803

Epoch: 5| Step: 7
Training loss: 2.501341364543984
Validation loss: 2.8277287459147

Epoch: 5| Step: 8
Training loss: 3.8326615836861304
Validation loss: 2.8285368041279937

Epoch: 5| Step: 9
Training loss: 3.1615159324330206
Validation loss: 2.8296331937980517

Epoch: 5| Step: 10
Training loss: 3.150230332687884
Validation loss: 2.8306011807951825

Epoch: 397| Step: 0
Training loss: 2.8822886086573964
Validation loss: 2.83714150046978

Epoch: 5| Step: 1
Training loss: 3.0007072250901135
Validation loss: 2.834290783930717

Epoch: 5| Step: 2
Training loss: 2.8979590501755093
Validation loss: 2.8358463932740077

Epoch: 5| Step: 3
Training loss: 3.563947015653193
Validation loss: 2.8448283411376183

Epoch: 5| Step: 4
Training loss: 3.476007241473101
Validation loss: 2.846902092231715

Epoch: 5| Step: 5
Training loss: 3.455082403323736
Validation loss: 2.8375838901524917

Epoch: 5| Step: 6
Training loss: 3.531574335648056
Validation loss: 2.8325660458041786

Epoch: 5| Step: 7
Training loss: 3.2704105630416636
Validation loss: 2.8379240862095747

Epoch: 5| Step: 8
Training loss: 2.936498268255538
Validation loss: 2.8326080855031393

Epoch: 5| Step: 9
Training loss: 2.5995196779111267
Validation loss: 2.841317948066738

Epoch: 5| Step: 10
Training loss: 2.658686698299895
Validation loss: 2.844008892705869

Epoch: 398| Step: 0
Training loss: 2.708301768974845
Validation loss: 2.845075633455893

Epoch: 5| Step: 1
Training loss: 2.370383946669076
Validation loss: 2.856262786140831

Epoch: 5| Step: 2
Training loss: 3.3706913041479916
Validation loss: 2.875644435055589

Epoch: 5| Step: 3
Training loss: 2.9750605921625484
Validation loss: 2.871780256509327

Epoch: 5| Step: 4
Training loss: 3.2494882033920933
Validation loss: 2.862936415386762

Epoch: 5| Step: 5
Training loss: 3.7652519326187015
Validation loss: 2.854264351903901

Epoch: 5| Step: 6
Training loss: 2.8374621283738843
Validation loss: 2.8269700265407116

Epoch: 5| Step: 7
Training loss: 2.827477734087658
Validation loss: 2.828330127322846

Epoch: 5| Step: 8
Training loss: 3.1429431767268383
Validation loss: 2.825109590798103

Epoch: 5| Step: 9
Training loss: 3.400944909456877
Validation loss: 2.8227555205848227

Epoch: 5| Step: 10
Training loss: 3.6308983795057337
Validation loss: 2.826191588183221

Epoch: 399| Step: 0
Training loss: 2.642209542586896
Validation loss: 2.8276569761257013

Epoch: 5| Step: 1
Training loss: 3.0648570429707904
Validation loss: 2.8287042579684423

Epoch: 5| Step: 2
Training loss: 3.180407243479206
Validation loss: 2.8303546038281673

Epoch: 5| Step: 3
Training loss: 2.774559889938443
Validation loss: 2.8316930257875095

Epoch: 5| Step: 4
Training loss: 3.153958385717911
Validation loss: 2.83599246527854

Epoch: 5| Step: 5
Training loss: 3.120366437863183
Validation loss: 2.838613724205546

Epoch: 5| Step: 6
Training loss: 3.3194466931820057
Validation loss: 2.8340664559943027

Epoch: 5| Step: 7
Training loss: 3.3444255966325716
Validation loss: 2.8333293678309026

Epoch: 5| Step: 8
Training loss: 3.5895528416031337
Validation loss: 2.829820219931787

Epoch: 5| Step: 9
Training loss: 2.9858027533085703
Validation loss: 2.827075163078546

Epoch: 5| Step: 10
Training loss: 3.3160978247980517
Validation loss: 2.825011596488909

Epoch: 400| Step: 0
Training loss: 3.1704907332884864
Validation loss: 2.8257929201069487

Epoch: 5| Step: 1
Training loss: 2.869418655957464
Validation loss: 2.822323498006736

Epoch: 5| Step: 2
Training loss: 3.0832101092760276
Validation loss: 2.8227198705894216

Epoch: 5| Step: 3
Training loss: 2.8796657352380506
Validation loss: 2.818904167506603

Epoch: 5| Step: 4
Training loss: 3.4168978512092143
Validation loss: 2.8231041062790645

Epoch: 5| Step: 5
Training loss: 3.3325964749015693
Validation loss: 2.818560597951069

Epoch: 5| Step: 6
Training loss: 3.4305538395419615
Validation loss: 2.81728899007191

Epoch: 5| Step: 7
Training loss: 3.5332510350797453
Validation loss: 2.8220766792474423

Epoch: 5| Step: 8
Training loss: 3.0642906714827065
Validation loss: 2.8227516062186226

Epoch: 5| Step: 9
Training loss: 2.5523179757340917
Validation loss: 2.8287848536380826

Epoch: 5| Step: 10
Training loss: 2.9636417812248963
Validation loss: 2.8379905494571265

Epoch: 401| Step: 0
Training loss: 3.1278350177388448
Validation loss: 2.845561908357563

Epoch: 5| Step: 1
Training loss: 3.3848973428550946
Validation loss: 2.8671711480894135

Epoch: 5| Step: 2
Training loss: 2.9313136762848178
Validation loss: 2.8431208799346113

Epoch: 5| Step: 3
Training loss: 3.1517115529813005
Validation loss: 2.848970675075679

Epoch: 5| Step: 4
Training loss: 3.1406939294946663
Validation loss: 2.8459060250559918

Epoch: 5| Step: 5
Training loss: 2.585186806132454
Validation loss: 2.8217720747844033

Epoch: 5| Step: 6
Training loss: 3.2659199412637383
Validation loss: 2.8280344991481323

Epoch: 5| Step: 7
Training loss: 3.114969712258624
Validation loss: 2.8220944797488228

Epoch: 5| Step: 8
Training loss: 2.9491846347881987
Validation loss: 2.817326439524023

Epoch: 5| Step: 9
Training loss: 3.3241590770202225
Validation loss: 2.817704529627301

Epoch: 5| Step: 10
Training loss: 3.3656872020134125
Validation loss: 2.8224912605254615

Epoch: 402| Step: 0
Training loss: 2.7983541999146446
Validation loss: 2.822806072638041

Epoch: 5| Step: 1
Training loss: 3.513141483905466
Validation loss: 2.827595904821962

Epoch: 5| Step: 2
Training loss: 2.5689617654428276
Validation loss: 2.829555944677672

Epoch: 5| Step: 3
Training loss: 3.2673332455498914
Validation loss: 2.8323305268760683

Epoch: 5| Step: 4
Training loss: 2.961876873684685
Validation loss: 2.8396250672514256

Epoch: 5| Step: 5
Training loss: 2.599516742984762
Validation loss: 2.820901148857573

Epoch: 5| Step: 6
Training loss: 3.449941557237173
Validation loss: 2.821805950622726

Epoch: 5| Step: 7
Training loss: 3.6949425284287054
Validation loss: 2.8185108602239843

Epoch: 5| Step: 8
Training loss: 2.9743544831903956
Validation loss: 2.816952909121295

Epoch: 5| Step: 9
Training loss: 3.061398366414561
Validation loss: 2.812956969989204

Epoch: 5| Step: 10
Training loss: 3.2533704447062712
Validation loss: 2.8145605034360477

Epoch: 403| Step: 0
Training loss: 2.97869220147704
Validation loss: 2.8184159456203757

Epoch: 5| Step: 1
Training loss: 3.4341433696022943
Validation loss: 2.818911089290304

Epoch: 5| Step: 2
Training loss: 3.2782256220965205
Validation loss: 2.8220633317501145

Epoch: 5| Step: 3
Training loss: 2.965790407735305
Validation loss: 2.8188460042080496

Epoch: 5| Step: 4
Training loss: 3.2208929243081643
Validation loss: 2.8234237205219563

Epoch: 5| Step: 5
Training loss: 2.3011658740479386
Validation loss: 2.829701275068122

Epoch: 5| Step: 6
Training loss: 2.777488479384351
Validation loss: 2.825559891510697

Epoch: 5| Step: 7
Training loss: 3.7516248361793836
Validation loss: 2.830273652498915

Epoch: 5| Step: 8
Training loss: 3.304833952271642
Validation loss: 2.821040052189817

Epoch: 5| Step: 9
Training loss: 2.8497899229022643
Validation loss: 2.81612430886399

Epoch: 5| Step: 10
Training loss: 3.212214083880262
Validation loss: 2.8157589023823584

Epoch: 404| Step: 0
Training loss: 3.327987166581719
Validation loss: 2.817323621391588

Epoch: 5| Step: 1
Training loss: 2.907489799291375
Validation loss: 2.814522164614484

Epoch: 5| Step: 2
Training loss: 2.668190361861182
Validation loss: 2.8180971880212606

Epoch: 5| Step: 3
Training loss: 3.4145436242529206
Validation loss: 2.821194389483934

Epoch: 5| Step: 4
Training loss: 3.2220245297029204
Validation loss: 2.8253246369494036

Epoch: 5| Step: 5
Training loss: 2.7528779835901553
Validation loss: 2.8289050586331124

Epoch: 5| Step: 6
Training loss: 3.319783965286277
Validation loss: 2.830585730626769

Epoch: 5| Step: 7
Training loss: 2.805635339926508
Validation loss: 2.8369520779313073

Epoch: 5| Step: 8
Training loss: 3.2806378474740696
Validation loss: 2.8443146110980813

Epoch: 5| Step: 9
Training loss: 3.473849011273374
Validation loss: 2.845294045953293

Epoch: 5| Step: 10
Training loss: 3.0438273519913164
Validation loss: 2.8602017062047924

Epoch: 405| Step: 0
Training loss: 2.8723938781418057
Validation loss: 2.872212451877919

Epoch: 5| Step: 1
Training loss: 3.1567652819925116
Validation loss: 2.8781922903074686

Epoch: 5| Step: 2
Training loss: 3.665108407409189
Validation loss: 2.8724273238717237

Epoch: 5| Step: 3
Training loss: 3.3733785054294687
Validation loss: 2.8691794196814557

Epoch: 5| Step: 4
Training loss: 3.4202907849106525
Validation loss: 2.864246988696135

Epoch: 5| Step: 5
Training loss: 2.965218943702849
Validation loss: 2.8612630846033698

Epoch: 5| Step: 6
Training loss: 3.620006805539979
Validation loss: 2.863332902311236

Epoch: 5| Step: 7
Training loss: 2.8149251866266236
Validation loss: 2.8658507078232756

Epoch: 5| Step: 8
Training loss: 2.8298614397939374
Validation loss: 2.8540513389813813

Epoch: 5| Step: 9
Training loss: 3.1469501929594905
Validation loss: 2.8496503194099265

Epoch: 5| Step: 10
Training loss: 2.5353527022364264
Validation loss: 2.8412186576526057

Epoch: 406| Step: 0
Training loss: 2.816861818162991
Validation loss: 2.8339228737563857

Epoch: 5| Step: 1
Training loss: 3.604943663941287
Validation loss: 2.8245929650565036

Epoch: 5| Step: 2
Training loss: 2.9451416937479324
Validation loss: 2.8174654226418543

Epoch: 5| Step: 3
Training loss: 3.4372061863958425
Validation loss: 2.8143906576961313

Epoch: 5| Step: 4
Training loss: 2.9113997906762825
Validation loss: 2.8151999873109794

Epoch: 5| Step: 5
Training loss: 2.983272648483613
Validation loss: 2.813953190129961

Epoch: 5| Step: 6
Training loss: 2.8954269526546823
Validation loss: 2.814124125399365

Epoch: 5| Step: 7
Training loss: 3.772805865953462
Validation loss: 2.8144711057949334

Epoch: 5| Step: 8
Training loss: 3.0441691585864388
Validation loss: 2.812955005077831

Epoch: 5| Step: 9
Training loss: 2.7440233307338726
Validation loss: 2.813888983434672

Epoch: 5| Step: 10
Training loss: 3.015128139221093
Validation loss: 2.814498404684971

Epoch: 407| Step: 0
Training loss: 3.280784065226116
Validation loss: 2.810866861846033

Epoch: 5| Step: 1
Training loss: 3.226066348004342
Validation loss: 2.8105705214799244

Epoch: 5| Step: 2
Training loss: 3.2784151456160027
Validation loss: 2.807629178328766

Epoch: 5| Step: 3
Training loss: 2.8693975511452843
Validation loss: 2.8112398111299024

Epoch: 5| Step: 4
Training loss: 3.7168166319922875
Validation loss: 2.8182011382376837

Epoch: 5| Step: 5
Training loss: 2.8048783346299384
Validation loss: 2.8120851436358136

Epoch: 5| Step: 6
Training loss: 2.0952591652450674
Validation loss: 2.8096796385378378

Epoch: 5| Step: 7
Training loss: 3.1102511451117487
Validation loss: 2.816215309887889

Epoch: 5| Step: 8
Training loss: 3.0956167118755613
Validation loss: 2.8239025338966965

Epoch: 5| Step: 9
Training loss: 3.1749551784926053
Validation loss: 2.8367635871320926

Epoch: 5| Step: 10
Training loss: 3.342047427230705
Validation loss: 2.8447797466630975

Epoch: 408| Step: 0
Training loss: 3.2608930993267498
Validation loss: 2.846243470930465

Epoch: 5| Step: 1
Training loss: 2.872836252423682
Validation loss: 2.82296971986915

Epoch: 5| Step: 2
Training loss: 3.012231370020916
Validation loss: 2.8219243688615

Epoch: 5| Step: 3
Training loss: 2.92356880582242
Validation loss: 2.810635366761767

Epoch: 5| Step: 4
Training loss: 3.299290933435872
Validation loss: 2.806722358425051

Epoch: 5| Step: 5
Training loss: 2.988164283607519
Validation loss: 2.8112443525141

Epoch: 5| Step: 6
Training loss: 3.0588204213381207
Validation loss: 2.8057984993138705

Epoch: 5| Step: 7
Training loss: 3.4402391097780236
Validation loss: 2.8066750086444414

Epoch: 5| Step: 8
Training loss: 3.0913784300598586
Validation loss: 2.8070438214798763

Epoch: 5| Step: 9
Training loss: 2.980421393381967
Validation loss: 2.8069473034995918

Epoch: 5| Step: 10
Training loss: 3.3523207298098274
Validation loss: 2.8115439336137404

Epoch: 409| Step: 0
Training loss: 2.911980506506848
Validation loss: 2.8101359614723367

Epoch: 5| Step: 1
Training loss: 3.518063797112582
Validation loss: 2.8079441648660066

Epoch: 5| Step: 2
Training loss: 3.61234996444489
Validation loss: 2.8084402894024763

Epoch: 5| Step: 3
Training loss: 2.8270010216316073
Validation loss: 2.808692433041823

Epoch: 5| Step: 4
Training loss: 2.8385483674603154
Validation loss: 2.8080885806204665

Epoch: 5| Step: 5
Training loss: 3.1684739995235462
Validation loss: 2.807538890658198

Epoch: 5| Step: 6
Training loss: 3.382750900447738
Validation loss: 2.8053120705392076

Epoch: 5| Step: 7
Training loss: 2.2280857162971714
Validation loss: 2.8086535942477906

Epoch: 5| Step: 8
Training loss: 3.2594435014411456
Validation loss: 2.806786355491386

Epoch: 5| Step: 9
Training loss: 3.4265950018319336
Validation loss: 2.813888272802532

Epoch: 5| Step: 10
Training loss: 2.8034080200890505
Validation loss: 2.8168294837592702

Epoch: 410| Step: 0
Training loss: 3.0962006081933318
Validation loss: 2.8102415243733643

Epoch: 5| Step: 1
Training loss: 3.291664960514705
Validation loss: 2.809157239276137

Epoch: 5| Step: 2
Training loss: 3.6514228190132196
Validation loss: 2.814299053844152

Epoch: 5| Step: 3
Training loss: 2.7098610799451173
Validation loss: 2.8060865319758657

Epoch: 5| Step: 4
Training loss: 2.8601823511211726
Validation loss: 2.8039502967036807

Epoch: 5| Step: 5
Training loss: 3.4118859098350516
Validation loss: 2.8058660643279816

Epoch: 5| Step: 6
Training loss: 2.839857014831039
Validation loss: 2.8068696629336647

Epoch: 5| Step: 7
Training loss: 3.115252130631218
Validation loss: 2.8112238605996818

Epoch: 5| Step: 8
Training loss: 2.9406542785678784
Validation loss: 2.803884679652443

Epoch: 5| Step: 9
Training loss: 3.278870219136529
Validation loss: 2.8108656096062257

Epoch: 5| Step: 10
Training loss: 2.8253844244356388
Validation loss: 2.811649158261653

Epoch: 411| Step: 0
Training loss: 2.534499825485684
Validation loss: 2.808781921508206

Epoch: 5| Step: 1
Training loss: 2.706629427417215
Validation loss: 2.805339010773002

Epoch: 5| Step: 2
Training loss: 3.493935917529224
Validation loss: 2.8053918139773715

Epoch: 5| Step: 3
Training loss: 3.5139734076252016
Validation loss: 2.8141329674602726

Epoch: 5| Step: 4
Training loss: 2.8463200284697034
Validation loss: 2.8047640611756974

Epoch: 5| Step: 5
Training loss: 2.6148377759515897
Validation loss: 2.822538419457471

Epoch: 5| Step: 6
Training loss: 2.748551680907756
Validation loss: 2.813108579359944

Epoch: 5| Step: 7
Training loss: 3.6884530339135715
Validation loss: 2.8115535360436037

Epoch: 5| Step: 8
Training loss: 3.480490670525808
Validation loss: 2.8104863531887028

Epoch: 5| Step: 9
Training loss: 3.0583045403756195
Validation loss: 2.8143201473523227

Epoch: 5| Step: 10
Training loss: 3.2593690369241504
Validation loss: 2.8035166957698716

Epoch: 412| Step: 0
Training loss: 2.76934228421918
Validation loss: 2.80556023075225

Epoch: 5| Step: 1
Training loss: 3.5013715236592495
Validation loss: 2.7975008492264735

Epoch: 5| Step: 2
Training loss: 2.936506062625269
Validation loss: 2.800068369410126

Epoch: 5| Step: 3
Training loss: 2.9173846496425058
Validation loss: 2.7989073726258433

Epoch: 5| Step: 4
Training loss: 3.1380680740198446
Validation loss: 2.803225939880107

Epoch: 5| Step: 5
Training loss: 2.9616480958521305
Validation loss: 2.8012899811289147

Epoch: 5| Step: 6
Training loss: 3.422828854908629
Validation loss: 2.8034328058527067

Epoch: 5| Step: 7
Training loss: 3.4665107716451193
Validation loss: 2.8002188409890065

Epoch: 5| Step: 8
Training loss: 3.2950019035275973
Validation loss: 2.816927011885661

Epoch: 5| Step: 9
Training loss: 3.108745875522652
Validation loss: 2.8305364378761677

Epoch: 5| Step: 10
Training loss: 2.4016150881408316
Validation loss: 2.836980441875357

Epoch: 413| Step: 0
Training loss: 3.761803171511807
Validation loss: 2.8412505096786913

Epoch: 5| Step: 1
Training loss: 2.7982148951476673
Validation loss: 2.828182058756452

Epoch: 5| Step: 2
Training loss: 3.251623041853258
Validation loss: 2.828019298753047

Epoch: 5| Step: 3
Training loss: 2.737143722412309
Validation loss: 2.814812937659546

Epoch: 5| Step: 4
Training loss: 3.091288656755821
Validation loss: 2.811009190359355

Epoch: 5| Step: 5
Training loss: 2.9309126670005834
Validation loss: 2.8056253681887076

Epoch: 5| Step: 6
Training loss: 2.658438644794573
Validation loss: 2.8107001731514587

Epoch: 5| Step: 7
Training loss: 3.3007277986611516
Validation loss: 2.8085598142955703

Epoch: 5| Step: 8
Training loss: 3.629193478356414
Validation loss: 2.803900079458633

Epoch: 5| Step: 9
Training loss: 2.4170166507600377
Validation loss: 2.809269163949281

Epoch: 5| Step: 10
Training loss: 3.398208645536085
Validation loss: 2.8137509680174175

Epoch: 414| Step: 0
Training loss: 2.880525172617064
Validation loss: 2.8088146260182127

Epoch: 5| Step: 1
Training loss: 3.2771845745947714
Validation loss: 2.8091685144429537

Epoch: 5| Step: 2
Training loss: 3.324012902382829
Validation loss: 2.80616450756546

Epoch: 5| Step: 3
Training loss: 3.0124029626690167
Validation loss: 2.802207165151808

Epoch: 5| Step: 4
Training loss: 2.8522961652511896
Validation loss: 2.8065855141990927

Epoch: 5| Step: 5
Training loss: 2.6999431250904427
Validation loss: 2.8025785491102653

Epoch: 5| Step: 6
Training loss: 3.3535988052529837
Validation loss: 2.808373446315143

Epoch: 5| Step: 7
Training loss: 2.8604625863994304
Validation loss: 2.803817149182444

Epoch: 5| Step: 8
Training loss: 3.3199741325749508
Validation loss: 2.8137883925811553

Epoch: 5| Step: 9
Training loss: 3.323962550258721
Validation loss: 2.828965759127195

Epoch: 5| Step: 10
Training loss: 3.164455511857204
Validation loss: 2.8359359867312595

Epoch: 415| Step: 0
Training loss: 3.2776053395863514
Validation loss: 2.831490848341254

Epoch: 5| Step: 1
Training loss: 3.7365648560573588
Validation loss: 2.8649903581952354

Epoch: 5| Step: 2
Training loss: 2.692099427981656
Validation loss: 2.869356663368719

Epoch: 5| Step: 3
Training loss: 3.331323367343317
Validation loss: 2.8510375133687385

Epoch: 5| Step: 4
Training loss: 2.8860204365641824
Validation loss: 2.8658050318452357

Epoch: 5| Step: 5
Training loss: 3.1841639095941057
Validation loss: 2.8605334130149926

Epoch: 5| Step: 6
Training loss: 3.4299041054002095
Validation loss: 2.8468878867793976

Epoch: 5| Step: 7
Training loss: 2.4715296874241854
Validation loss: 2.8256859793993416

Epoch: 5| Step: 8
Training loss: 3.2500375598791162
Validation loss: 2.8028348357267143

Epoch: 5| Step: 9
Training loss: 2.9878960255172466
Validation loss: 2.8025622272936745

Epoch: 5| Step: 10
Training loss: 2.798065869710106
Validation loss: 2.797826861988152

Epoch: 416| Step: 0
Training loss: 2.8405112802972803
Validation loss: 2.800035450127906

Epoch: 5| Step: 1
Training loss: 3.3033352152501148
Validation loss: 2.7999628093479214

Epoch: 5| Step: 2
Training loss: 3.2265223022617073
Validation loss: 2.7976952502240544

Epoch: 5| Step: 3
Training loss: 3.131477204567686
Validation loss: 2.7978865755165305

Epoch: 5| Step: 4
Training loss: 3.3372019888310347
Validation loss: 2.802192284836688

Epoch: 5| Step: 5
Training loss: 3.266509743898282
Validation loss: 2.803024269110712

Epoch: 5| Step: 6
Training loss: 3.1592041392021275
Validation loss: 2.7979354236784557

Epoch: 5| Step: 7
Training loss: 3.629289916814716
Validation loss: 2.79877013071896

Epoch: 5| Step: 8
Training loss: 2.6771794362512793
Validation loss: 2.803902371638905

Epoch: 5| Step: 9
Training loss: 2.860605110764407
Validation loss: 2.8037544741698706

Epoch: 5| Step: 10
Training loss: 2.5177533167928092
Validation loss: 2.799985571939824

Epoch: 417| Step: 0
Training loss: 3.2358502695362636
Validation loss: 2.804602393723387

Epoch: 5| Step: 1
Training loss: 2.454955274714468
Validation loss: 2.8081153755350527

Epoch: 5| Step: 2
Training loss: 3.1880423888448046
Validation loss: 2.8054411245214026

Epoch: 5| Step: 3
Training loss: 3.3612979087380253
Validation loss: 2.8202568673416795

Epoch: 5| Step: 4
Training loss: 2.6934002713424308
Validation loss: 2.814308031084198

Epoch: 5| Step: 5
Training loss: 3.9180450584153506
Validation loss: 2.8205920447233384

Epoch: 5| Step: 6
Training loss: 3.0988650182357276
Validation loss: 2.804411873979364

Epoch: 5| Step: 7
Training loss: 2.1547718233534088
Validation loss: 2.80491597354474

Epoch: 5| Step: 8
Training loss: 3.171804944096272
Validation loss: 2.8052911414178223

Epoch: 5| Step: 9
Training loss: 3.229772268953611
Validation loss: 2.80554782901971

Epoch: 5| Step: 10
Training loss: 3.3288090678928763
Validation loss: 2.7986515974936204

Epoch: 418| Step: 0
Training loss: 2.3100560651308557
Validation loss: 2.8061085204143423

Epoch: 5| Step: 1
Training loss: 2.7762593272884213
Validation loss: 2.81026307617852

Epoch: 5| Step: 2
Training loss: 3.0950781543336037
Validation loss: 2.8030869311836626

Epoch: 5| Step: 3
Training loss: 3.0491432550043585
Validation loss: 2.8033047431052784

Epoch: 5| Step: 4
Training loss: 3.4942878704913243
Validation loss: 2.8060284921952867

Epoch: 5| Step: 5
Training loss: 3.1043608602590016
Validation loss: 2.805317120481975

Epoch: 5| Step: 6
Training loss: 2.556709445991692
Validation loss: 2.802093956582537

Epoch: 5| Step: 7
Training loss: 3.3209780755242564
Validation loss: 2.8017351768539265

Epoch: 5| Step: 8
Training loss: 3.070309859801266
Validation loss: 2.8032023512495288

Epoch: 5| Step: 9
Training loss: 3.438578211141306
Validation loss: 2.7963579526829734

Epoch: 5| Step: 10
Training loss: 3.7426422416244254
Validation loss: 2.8009186725263957

Epoch: 419| Step: 0
Training loss: 3.248170484437613
Validation loss: 2.793829909162301

Epoch: 5| Step: 1
Training loss: 3.0244954153370807
Validation loss: 2.794997301241451

Epoch: 5| Step: 2
Training loss: 3.1789210940033437
Validation loss: 2.796573039423207

Epoch: 5| Step: 3
Training loss: 2.696448045441925
Validation loss: 2.794020646740986

Epoch: 5| Step: 4
Training loss: 2.777782979536484
Validation loss: 2.798431350269677

Epoch: 5| Step: 5
Training loss: 3.909925638842987
Validation loss: 2.792843056697422

Epoch: 5| Step: 6
Training loss: 2.8640725160081275
Validation loss: 2.796225096415252

Epoch: 5| Step: 7
Training loss: 2.8593429813781084
Validation loss: 2.796985499608217

Epoch: 5| Step: 8
Training loss: 3.0704288217965967
Validation loss: 2.7949069155382023

Epoch: 5| Step: 9
Training loss: 3.337728336824232
Validation loss: 2.7959925045907785

Epoch: 5| Step: 10
Training loss: 2.9615519749107317
Validation loss: 2.802415183043486

Epoch: 420| Step: 0
Training loss: 3.230791843775327
Validation loss: 2.8042625333576483

Epoch: 5| Step: 1
Training loss: 3.527172063322433
Validation loss: 2.8084055165900823

Epoch: 5| Step: 2
Training loss: 2.7804067812190847
Validation loss: 2.8127116234212663

Epoch: 5| Step: 3
Training loss: 3.099451071837771
Validation loss: 2.8045302780104975

Epoch: 5| Step: 4
Training loss: 3.0559706858681976
Validation loss: 2.8166232267062563

Epoch: 5| Step: 5
Training loss: 2.9421993569384854
Validation loss: 2.8101130429931045

Epoch: 5| Step: 6
Training loss: 3.474499173746026
Validation loss: 2.807592679737589

Epoch: 5| Step: 7
Training loss: 2.7297892454910477
Validation loss: 2.8041991396704122

Epoch: 5| Step: 8
Training loss: 3.1498172283129926
Validation loss: 2.806990090380907

Epoch: 5| Step: 9
Training loss: 3.0393930760418137
Validation loss: 2.8044953333120755

Epoch: 5| Step: 10
Training loss: 2.963048982254636
Validation loss: 2.809694390694067

Epoch: 421| Step: 0
Training loss: 2.763987428153522
Validation loss: 2.8060294140365953

Epoch: 5| Step: 1
Training loss: 3.6939008084927507
Validation loss: 2.8036310548128

Epoch: 5| Step: 2
Training loss: 3.0660322410744647
Validation loss: 2.8148398233929197

Epoch: 5| Step: 3
Training loss: 2.1059108970536586
Validation loss: 2.822670118961764

Epoch: 5| Step: 4
Training loss: 3.6755682369701725
Validation loss: 2.8150508064641264

Epoch: 5| Step: 5
Training loss: 3.6132035200676422
Validation loss: 2.8145797131835124

Epoch: 5| Step: 6
Training loss: 3.145028893560917
Validation loss: 2.821701931509164

Epoch: 5| Step: 7
Training loss: 2.9425884571245993
Validation loss: 2.816506823815852

Epoch: 5| Step: 8
Training loss: 2.7124022119008746
Validation loss: 2.811999860113118

Epoch: 5| Step: 9
Training loss: 2.758301688835817
Validation loss: 2.806656355868748

Epoch: 5| Step: 10
Training loss: 3.266938305933461
Validation loss: 2.8058852166504242

Epoch: 422| Step: 0
Training loss: 3.392498571048399
Validation loss: 2.804338336404715

Epoch: 5| Step: 1
Training loss: 2.540069474298909
Validation loss: 2.8009988046377856

Epoch: 5| Step: 2
Training loss: 2.8845629662861803
Validation loss: 2.7909663617903053

Epoch: 5| Step: 3
Training loss: 3.0541943398367306
Validation loss: 2.7886857390444617

Epoch: 5| Step: 4
Training loss: 3.1603321832786806
Validation loss: 2.7907841615583444

Epoch: 5| Step: 5
Training loss: 3.241114721568291
Validation loss: 2.7917725811259815

Epoch: 5| Step: 6
Training loss: 2.8389721651879425
Validation loss: 2.794254734866167

Epoch: 5| Step: 7
Training loss: 3.03599161756562
Validation loss: 2.793716297807576

Epoch: 5| Step: 8
Training loss: 3.399206175415937
Validation loss: 2.7890862881857106

Epoch: 5| Step: 9
Training loss: 3.132709910551405
Validation loss: 2.7937160527962694

Epoch: 5| Step: 10
Training loss: 3.330177784432497
Validation loss: 2.791856169448269

Epoch: 423| Step: 0
Training loss: 2.896027665970308
Validation loss: 2.7936927729535697

Epoch: 5| Step: 1
Training loss: 2.7354611228783807
Validation loss: 2.7896348326893774

Epoch: 5| Step: 2
Training loss: 3.63603713780606
Validation loss: 2.8000360965233217

Epoch: 5| Step: 3
Training loss: 3.2106170123095414
Validation loss: 2.7963816228849105

Epoch: 5| Step: 4
Training loss: 2.7978092956013323
Validation loss: 2.79534932459886

Epoch: 5| Step: 5
Training loss: 3.0821862707567824
Validation loss: 2.794326433190303

Epoch: 5| Step: 6
Training loss: 3.2335451692488024
Validation loss: 2.793765662100464

Epoch: 5| Step: 7
Training loss: 3.418235620161935
Validation loss: 2.796063934636551

Epoch: 5| Step: 8
Training loss: 2.915419847930907
Validation loss: 2.7930056985364073

Epoch: 5| Step: 9
Training loss: 2.758469976015969
Validation loss: 2.79360053261893

Epoch: 5| Step: 10
Training loss: 3.292232770567808
Validation loss: 2.797153763551579

Epoch: 424| Step: 0
Training loss: 3.3379371956778994
Validation loss: 2.7952591236176545

Epoch: 5| Step: 1
Training loss: 3.9750190542472144
Validation loss: 2.798286533230286

Epoch: 5| Step: 2
Training loss: 1.7065555424697731
Validation loss: 2.7911779967466543

Epoch: 5| Step: 3
Training loss: 3.380177235668457
Validation loss: 2.795652449444784

Epoch: 5| Step: 4
Training loss: 3.315132966057561
Validation loss: 2.794786016043072

Epoch: 5| Step: 5
Training loss: 2.806467835397478
Validation loss: 2.7963708489753194

Epoch: 5| Step: 6
Training loss: 2.6824582736422093
Validation loss: 2.796142163136173

Epoch: 5| Step: 7
Training loss: 3.150308587838404
Validation loss: 2.797226808133509

Epoch: 5| Step: 8
Training loss: 2.9967395230758775
Validation loss: 2.791108318161602

Epoch: 5| Step: 9
Training loss: 2.9059571149356653
Validation loss: 2.7911051167184686

Epoch: 5| Step: 10
Training loss: 3.2961267282048228
Validation loss: 2.7897424440960004

Epoch: 425| Step: 0
Training loss: 3.487231259947003
Validation loss: 2.80090588778742

Epoch: 5| Step: 1
Training loss: 3.384015228507765
Validation loss: 2.7943286690027174

Epoch: 5| Step: 2
Training loss: 2.6271574146575953
Validation loss: 2.7925753335222163

Epoch: 5| Step: 3
Training loss: 2.9983810188893663
Validation loss: 2.7909471107643973

Epoch: 5| Step: 4
Training loss: 2.7269684672419277
Validation loss: 2.7905606567724415

Epoch: 5| Step: 5
Training loss: 3.083596261301074
Validation loss: 2.791460721741476

Epoch: 5| Step: 6
Training loss: 2.794065033561975
Validation loss: 2.7941741111606313

Epoch: 5| Step: 7
Training loss: 3.082713468636343
Validation loss: 2.799241586817054

Epoch: 5| Step: 8
Training loss: 3.143857592339877
Validation loss: 2.7931060016094733

Epoch: 5| Step: 9
Training loss: 3.3598849597038063
Validation loss: 2.7999157133322368

Epoch: 5| Step: 10
Training loss: 3.221005436558415
Validation loss: 2.80089678338482

Epoch: 426| Step: 0
Training loss: 2.0541670107373715
Validation loss: 2.790972391142427

Epoch: 5| Step: 1
Training loss: 3.5386097599485486
Validation loss: 2.8003779125886457

Epoch: 5| Step: 2
Training loss: 3.1723352859339813
Validation loss: 2.799464876558653

Epoch: 5| Step: 3
Training loss: 3.2479954920206593
Validation loss: 2.792996749204061

Epoch: 5| Step: 4
Training loss: 3.17826297726814
Validation loss: 2.7969477118090116

Epoch: 5| Step: 5
Training loss: 3.3130472558885993
Validation loss: 2.792946763672426

Epoch: 5| Step: 6
Training loss: 2.4962512520303197
Validation loss: 2.7971842046012805

Epoch: 5| Step: 7
Training loss: 3.2379060350700977
Validation loss: 2.7928699896169125

Epoch: 5| Step: 8
Training loss: 3.589048544524865
Validation loss: 2.789005497607617

Epoch: 5| Step: 9
Training loss: 3.0989698051860057
Validation loss: 2.7912390630457526

Epoch: 5| Step: 10
Training loss: 2.6627558303209025
Validation loss: 2.7879360276411727

Epoch: 427| Step: 0
Training loss: 3.2829633326787824
Validation loss: 2.785182019236898

Epoch: 5| Step: 1
Training loss: 3.2647744855359075
Validation loss: 2.7855677892385473

Epoch: 5| Step: 2
Training loss: 2.818822239798047
Validation loss: 2.7870378580302906

Epoch: 5| Step: 3
Training loss: 3.6199962677067017
Validation loss: 2.784044614679376

Epoch: 5| Step: 4
Training loss: 2.5490668291001612
Validation loss: 2.7885130154877813

Epoch: 5| Step: 5
Training loss: 2.6796616088684058
Validation loss: 2.7834220093494637

Epoch: 5| Step: 6
Training loss: 2.8245548032527834
Validation loss: 2.783231298897381

Epoch: 5| Step: 7
Training loss: 2.9991647829256736
Validation loss: 2.7854633924491266

Epoch: 5| Step: 8
Training loss: 3.3036581109063516
Validation loss: 2.7864761592711496

Epoch: 5| Step: 9
Training loss: 2.811318806458825
Validation loss: 2.7850061621921527

Epoch: 5| Step: 10
Training loss: 3.71606245617894
Validation loss: 2.781829548692992

Epoch: 428| Step: 0
Training loss: 2.713141608935427
Validation loss: 2.782636152546801

Epoch: 5| Step: 1
Training loss: 2.927178287436628
Validation loss: 2.7844847132882915

Epoch: 5| Step: 2
Training loss: 3.3626631856694105
Validation loss: 2.782204084926417

Epoch: 5| Step: 3
Training loss: 2.857553704558932
Validation loss: 2.7890997135304767

Epoch: 5| Step: 4
Training loss: 2.9739461298401015
Validation loss: 2.7904046416641437

Epoch: 5| Step: 5
Training loss: 2.764558403249609
Validation loss: 2.7936362678968685

Epoch: 5| Step: 6
Training loss: 3.2539206111815435
Validation loss: 2.797519679430048

Epoch: 5| Step: 7
Training loss: 2.872138216162178
Validation loss: 2.785015893862342

Epoch: 5| Step: 8
Training loss: 3.071600025245457
Validation loss: 2.7861343822635347

Epoch: 5| Step: 9
Training loss: 3.5951409343317153
Validation loss: 2.7791525183722787

Epoch: 5| Step: 10
Training loss: 3.544326202535606
Validation loss: 2.7838984258125548

Epoch: 429| Step: 0
Training loss: 3.1035694000021787
Validation loss: 2.7829258133060204

Epoch: 5| Step: 1
Training loss: 3.1207499786232713
Validation loss: 2.781400654569906

Epoch: 5| Step: 2
Training loss: 2.7496401811497915
Validation loss: 2.7852024813838616

Epoch: 5| Step: 3
Training loss: 2.7546731084057114
Validation loss: 2.7870247299828126

Epoch: 5| Step: 4
Training loss: 3.259126320529621
Validation loss: 2.780615803981128

Epoch: 5| Step: 5
Training loss: 3.4066489449753634
Validation loss: 2.7790999564406023

Epoch: 5| Step: 6
Training loss: 3.125547132279184
Validation loss: 2.7795104167426574

Epoch: 5| Step: 7
Training loss: 3.0991996778012387
Validation loss: 2.779704008184994

Epoch: 5| Step: 8
Training loss: 2.897463076918236
Validation loss: 2.780782486309745

Epoch: 5| Step: 9
Training loss: 3.1093115105209397
Validation loss: 2.7804020926520336

Epoch: 5| Step: 10
Training loss: 3.375959471906769
Validation loss: 2.78017206193522

Epoch: 430| Step: 0
Training loss: 3.106266941200894
Validation loss: 2.7810044253382906

Epoch: 5| Step: 1
Training loss: 3.2714823344210053
Validation loss: 2.7792684481407255

Epoch: 5| Step: 2
Training loss: 3.2524956144732875
Validation loss: 2.781425111997522

Epoch: 5| Step: 3
Training loss: 2.777860998390559
Validation loss: 2.7797473167755604

Epoch: 5| Step: 4
Training loss: 3.392363634285346
Validation loss: 2.780824917050245

Epoch: 5| Step: 5
Training loss: 3.514127827906825
Validation loss: 2.78182100575937

Epoch: 5| Step: 6
Training loss: 2.955804487212572
Validation loss: 2.7886048945727295

Epoch: 5| Step: 7
Training loss: 2.6509432571422367
Validation loss: 2.7867660823266527

Epoch: 5| Step: 8
Training loss: 2.9065761588234733
Validation loss: 2.782650820513702

Epoch: 5| Step: 9
Training loss: 2.5957432636863187
Validation loss: 2.7856821304885093

Epoch: 5| Step: 10
Training loss: 3.455252841911585
Validation loss: 2.78752524086143

Epoch: 431| Step: 0
Training loss: 2.9902048738645157
Validation loss: 2.7864267845234707

Epoch: 5| Step: 1
Training loss: 2.418674840424734
Validation loss: 2.781214201437437

Epoch: 5| Step: 2
Training loss: 3.5641665659641277
Validation loss: 2.781804439581608

Epoch: 5| Step: 3
Training loss: 2.7701592641277526
Validation loss: 2.7817500707499523

Epoch: 5| Step: 4
Training loss: 3.0849283234169507
Validation loss: 2.7814295822408646

Epoch: 5| Step: 5
Training loss: 3.624505371022412
Validation loss: 2.7755385883459467

Epoch: 5| Step: 6
Training loss: 2.6830872081242805
Validation loss: 2.780859779376883

Epoch: 5| Step: 7
Training loss: 2.690569167493815
Validation loss: 2.776035790815351

Epoch: 5| Step: 8
Training loss: 2.978581742350177
Validation loss: 2.777396653462164

Epoch: 5| Step: 9
Training loss: 3.3532616636328934
Validation loss: 2.7828200543860575

Epoch: 5| Step: 10
Training loss: 3.618500374467574
Validation loss: 2.77575546334915

Epoch: 432| Step: 0
Training loss: 3.1685587266605735
Validation loss: 2.7751688448641856

Epoch: 5| Step: 1
Training loss: 3.0971409873021685
Validation loss: 2.776803702557787

Epoch: 5| Step: 2
Training loss: 2.73564719986182
Validation loss: 2.778092624978542

Epoch: 5| Step: 3
Training loss: 3.220993445308332
Validation loss: 2.781418545796129

Epoch: 5| Step: 4
Training loss: 2.8187885763907716
Validation loss: 2.780599041618339

Epoch: 5| Step: 5
Training loss: 2.7762461021014677
Validation loss: 2.7756970414899134

Epoch: 5| Step: 6
Training loss: 3.1184419101370824
Validation loss: 2.7776344776790776

Epoch: 5| Step: 7
Training loss: 2.9249013639594073
Validation loss: 2.7779118127855424

Epoch: 5| Step: 8
Training loss: 2.672700364084148
Validation loss: 2.7813229119796747

Epoch: 5| Step: 9
Training loss: 3.0530088060928624
Validation loss: 2.7831897670077717

Epoch: 5| Step: 10
Training loss: 4.2443311695031545
Validation loss: 2.7850481097560564

Epoch: 433| Step: 0
Training loss: 3.445065444081065
Validation loss: 2.789733981450113

Epoch: 5| Step: 1
Training loss: 2.5947122282724124
Validation loss: 2.7803912070320473

Epoch: 5| Step: 2
Training loss: 3.023361796532855
Validation loss: 2.7959115651430926

Epoch: 5| Step: 3
Training loss: 2.917795199093408
Validation loss: 2.780271083423158

Epoch: 5| Step: 4
Training loss: 3.215917878302833
Validation loss: 2.7890019283701357

Epoch: 5| Step: 5
Training loss: 3.1210764859405975
Validation loss: 2.780453322540371

Epoch: 5| Step: 6
Training loss: 3.053039886943754
Validation loss: 2.777086865799405

Epoch: 5| Step: 7
Training loss: 3.5311639825927723
Validation loss: 2.781938536529564

Epoch: 5| Step: 8
Training loss: 3.306894994461501
Validation loss: 2.7776838878091157

Epoch: 5| Step: 9
Training loss: 2.70366456043624
Validation loss: 2.775146902734417

Epoch: 5| Step: 10
Training loss: 2.812868899417906
Validation loss: 2.7825005901924857

Epoch: 434| Step: 0
Training loss: 3.3848784659584283
Validation loss: 2.7751244394119343

Epoch: 5| Step: 1
Training loss: 2.6674024838299504
Validation loss: 2.7774871428702443

Epoch: 5| Step: 2
Training loss: 3.1526592715972472
Validation loss: 2.774534002641859

Epoch: 5| Step: 3
Training loss: 3.3240101767888
Validation loss: 2.7816891979626575

Epoch: 5| Step: 4
Training loss: 3.3525996526348276
Validation loss: 2.7899155344464273

Epoch: 5| Step: 5
Training loss: 3.678338777589651
Validation loss: 2.780595054076974

Epoch: 5| Step: 6
Training loss: 3.382040803560513
Validation loss: 2.7966018830306014

Epoch: 5| Step: 7
Training loss: 2.5832943964659267
Validation loss: 2.7963246395069663

Epoch: 5| Step: 8
Training loss: 2.7369377987267307
Validation loss: 2.7883444590483544

Epoch: 5| Step: 9
Training loss: 2.725563631475591
Validation loss: 2.7896774899432244

Epoch: 5| Step: 10
Training loss: 2.640166745121815
Validation loss: 2.775908745268461

Epoch: 435| Step: 0
Training loss: 2.7982154063704994
Validation loss: 2.7747384887945077

Epoch: 5| Step: 1
Training loss: 3.0817932887976003
Validation loss: 2.7756518076905126

Epoch: 5| Step: 2
Training loss: 3.618733613235715
Validation loss: 2.774321646915382

Epoch: 5| Step: 3
Training loss: 2.784469455611061
Validation loss: 2.776215118423842

Epoch: 5| Step: 4
Training loss: 2.7841649585282093
Validation loss: 2.7707150255387014

Epoch: 5| Step: 5
Training loss: 3.0535344828296256
Validation loss: 2.7692007145882256

Epoch: 5| Step: 6
Training loss: 3.385031872913407
Validation loss: 2.7746944718996716

Epoch: 5| Step: 7
Training loss: 3.025865629572394
Validation loss: 2.77441404032329

Epoch: 5| Step: 8
Training loss: 3.204035485355688
Validation loss: 2.7725232158832402

Epoch: 5| Step: 9
Training loss: 2.472614306053462
Validation loss: 2.768287581595137

Epoch: 5| Step: 10
Training loss: 3.565827538958896
Validation loss: 2.7739833592142418

Epoch: 436| Step: 0
Training loss: 3.0282719721129676
Validation loss: 2.774812934621107

Epoch: 5| Step: 1
Training loss: 2.953849259628595
Validation loss: 2.779541336940012

Epoch: 5| Step: 2
Training loss: 2.5911298639517844
Validation loss: 2.7839373815912647

Epoch: 5| Step: 3
Training loss: 2.912720726719325
Validation loss: 2.784609256982702

Epoch: 5| Step: 4
Training loss: 3.1900542254009627
Validation loss: 2.779795957091535

Epoch: 5| Step: 5
Training loss: 2.9634964888648274
Validation loss: 2.7828598967394873

Epoch: 5| Step: 6
Training loss: 2.9145774079581384
Validation loss: 2.7766239490075892

Epoch: 5| Step: 7
Training loss: 3.3694201367298042
Validation loss: 2.7768924281184435

Epoch: 5| Step: 8
Training loss: 3.1668372526567343
Validation loss: 2.7730102468786257

Epoch: 5| Step: 9
Training loss: 3.35808620127308
Validation loss: 2.7785185272983184

Epoch: 5| Step: 10
Training loss: 3.3681729815136334
Validation loss: 2.779265763909968

Epoch: 437| Step: 0
Training loss: 2.623946205425112
Validation loss: 2.780546686819312

Epoch: 5| Step: 1
Training loss: 2.508713319792547
Validation loss: 2.7736204145659458

Epoch: 5| Step: 2
Training loss: 2.6631013361307647
Validation loss: 2.7758367882613295

Epoch: 5| Step: 3
Training loss: 3.5501555341578244
Validation loss: 2.7791561002592413

Epoch: 5| Step: 4
Training loss: 3.485917370104152
Validation loss: 2.7749539407789436

Epoch: 5| Step: 5
Training loss: 2.8928420354055078
Validation loss: 2.791445068713239

Epoch: 5| Step: 6
Training loss: 3.392334678405493
Validation loss: 2.7817865950731546

Epoch: 5| Step: 7
Training loss: 3.3612098118885902
Validation loss: 2.7776956516007014

Epoch: 5| Step: 8
Training loss: 3.259646258674314
Validation loss: 2.7800608737528245

Epoch: 5| Step: 9
Training loss: 2.979019872787998
Validation loss: 2.7839096909334917

Epoch: 5| Step: 10
Training loss: 2.883636274207666
Validation loss: 2.7837161953511127

Epoch: 438| Step: 0
Training loss: 3.611029439801385
Validation loss: 2.7722595403147667

Epoch: 5| Step: 1
Training loss: 3.2735683078167748
Validation loss: 2.7782830662374187

Epoch: 5| Step: 2
Training loss: 2.901142677909077
Validation loss: 2.770108836887756

Epoch: 5| Step: 3
Training loss: 2.51690546464919
Validation loss: 2.770523974308509

Epoch: 5| Step: 4
Training loss: 2.836816236480274
Validation loss: 2.7755991508326754

Epoch: 5| Step: 5
Training loss: 2.5923883011977606
Validation loss: 2.7716673037680732

Epoch: 5| Step: 6
Training loss: 3.1366441083604317
Validation loss: 2.7757088090840027

Epoch: 5| Step: 7
Training loss: 3.1380580451415705
Validation loss: 2.7689524158692547

Epoch: 5| Step: 8
Training loss: 3.419297732702328
Validation loss: 2.773594622946977

Epoch: 5| Step: 9
Training loss: 3.1910038557803375
Validation loss: 2.76976831400065

Epoch: 5| Step: 10
Training loss: 3.0454865250791174
Validation loss: 2.77632999075312

Epoch: 439| Step: 0
Training loss: 2.9457303264329706
Validation loss: 2.7736138298878585

Epoch: 5| Step: 1
Training loss: 2.2831811960960398
Validation loss: 2.7752383786299597

Epoch: 5| Step: 2
Training loss: 2.5264588211481454
Validation loss: 2.773711903371779

Epoch: 5| Step: 3
Training loss: 3.896625227521544
Validation loss: 2.7772224957902787

Epoch: 5| Step: 4
Training loss: 3.31304653625321
Validation loss: 2.7860708641032215

Epoch: 5| Step: 5
Training loss: 3.1522998830397313
Validation loss: 2.796685479180405

Epoch: 5| Step: 6
Training loss: 2.503978900777874
Validation loss: 2.8181507401001813

Epoch: 5| Step: 7
Training loss: 3.344366569358709
Validation loss: 2.841471483485285

Epoch: 5| Step: 8
Training loss: 3.132262374255509
Validation loss: 2.860382156433363

Epoch: 5| Step: 9
Training loss: 3.395340554147359
Validation loss: 2.8258441417790747

Epoch: 5| Step: 10
Training loss: 3.0099436950486766
Validation loss: 2.7886983702068995

Epoch: 440| Step: 0
Training loss: 3.1300273891627817
Validation loss: 2.770743350476091

Epoch: 5| Step: 1
Training loss: 2.7254192064844296
Validation loss: 2.768329693588242

Epoch: 5| Step: 2
Training loss: 3.4875320706550723
Validation loss: 2.7687777483460834

Epoch: 5| Step: 3
Training loss: 3.35843776669869
Validation loss: 2.7692965170789403

Epoch: 5| Step: 4
Training loss: 3.6094123871423367
Validation loss: 2.7684468479425868

Epoch: 5| Step: 5
Training loss: 3.0837280089572654
Validation loss: 2.7713927821331152

Epoch: 5| Step: 6
Training loss: 2.1149379138536353
Validation loss: 2.776339003966862

Epoch: 5| Step: 7
Training loss: 3.4155920866473743
Validation loss: 2.7849409594929075

Epoch: 5| Step: 8
Training loss: 3.0461792762883433
Validation loss: 2.77326859487462

Epoch: 5| Step: 9
Training loss: 3.152566554480988
Validation loss: 2.7675166338783193

Epoch: 5| Step: 10
Training loss: 2.356997371906795
Validation loss: 2.769220309349063

Epoch: 441| Step: 0
Training loss: 2.9597426446951682
Validation loss: 2.768060463611573

Epoch: 5| Step: 1
Training loss: 2.738323565059551
Validation loss: 2.7762039541313497

Epoch: 5| Step: 2
Training loss: 3.114612404848167
Validation loss: 2.773859448870544

Epoch: 5| Step: 3
Training loss: 3.5520812152994203
Validation loss: 2.7765113879368033

Epoch: 5| Step: 4
Training loss: 2.727858708025569
Validation loss: 2.7864135937936827

Epoch: 5| Step: 5
Training loss: 3.20906253471081
Validation loss: 2.7867872315271325

Epoch: 5| Step: 6
Training loss: 2.877637731203902
Validation loss: 2.797300010273789

Epoch: 5| Step: 7
Training loss: 3.1181850127995694
Validation loss: 2.8078783868718826

Epoch: 5| Step: 8
Training loss: 3.633637102943307
Validation loss: 2.8022032687400102

Epoch: 5| Step: 9
Training loss: 2.5422751422726324
Validation loss: 2.8044816946331896

Epoch: 5| Step: 10
Training loss: 3.24708176689709
Validation loss: 2.789229720763043

Epoch: 442| Step: 0
Training loss: 3.704177642451282
Validation loss: 2.7871672237572302

Epoch: 5| Step: 1
Training loss: 3.0959223046916104
Validation loss: 2.790136523720711

Epoch: 5| Step: 2
Training loss: 3.013466650649653
Validation loss: 2.785899301703158

Epoch: 5| Step: 3
Training loss: 3.4041925218425946
Validation loss: 2.7801596631382814

Epoch: 5| Step: 4
Training loss: 3.0065793370535823
Validation loss: 2.7849866287901084

Epoch: 5| Step: 5
Training loss: 3.0908354314401154
Validation loss: 2.7786243613689074

Epoch: 5| Step: 6
Training loss: 2.8058007031424013
Validation loss: 2.775457482845588

Epoch: 5| Step: 7
Training loss: 2.57077717856271
Validation loss: 2.774988892106286

Epoch: 5| Step: 8
Training loss: 2.49268558511478
Validation loss: 2.7673101003381992

Epoch: 5| Step: 9
Training loss: 3.0026740236694747
Validation loss: 2.7711972511072824

Epoch: 5| Step: 10
Training loss: 3.4783282307135153
Validation loss: 2.770592640123548

Epoch: 443| Step: 0
Training loss: 3.0182491605731117
Validation loss: 2.769736072178396

Epoch: 5| Step: 1
Training loss: 3.513056244705854
Validation loss: 2.766308504838847

Epoch: 5| Step: 2
Training loss: 3.267917686098105
Validation loss: 2.7623250174330893

Epoch: 5| Step: 3
Training loss: 3.006937271199665
Validation loss: 2.759738726650615

Epoch: 5| Step: 4
Training loss: 2.85116281713094
Validation loss: 2.7611701263640636

Epoch: 5| Step: 5
Training loss: 2.9396601100297293
Validation loss: 2.7651487959798824

Epoch: 5| Step: 6
Training loss: 3.292145867213472
Validation loss: 2.772646443474864

Epoch: 5| Step: 7
Training loss: 3.0854045166215993
Validation loss: 2.771369005807242

Epoch: 5| Step: 8
Training loss: 2.7926044786762247
Validation loss: 2.77083232792341

Epoch: 5| Step: 9
Training loss: 3.0059853292527254
Validation loss: 2.7695962786100097

Epoch: 5| Step: 10
Training loss: 2.9944038648653275
Validation loss: 2.7734361097698317

Epoch: 444| Step: 0
Training loss: 3.0472602796269292
Validation loss: 2.7743888761116655

Epoch: 5| Step: 1
Training loss: 3.1865536650037343
Validation loss: 2.7663836538537607

Epoch: 5| Step: 2
Training loss: 2.9695610143248197
Validation loss: 2.76281729242845

Epoch: 5| Step: 3
Training loss: 2.9019007800417698
Validation loss: 2.763966968017738

Epoch: 5| Step: 4
Training loss: 2.9754373821938254
Validation loss: 2.7658954773372115

Epoch: 5| Step: 5
Training loss: 3.012610000564781
Validation loss: 2.76611047442728

Epoch: 5| Step: 6
Training loss: 3.136168701285823
Validation loss: 2.7682279065610387

Epoch: 5| Step: 7
Training loss: 3.725042709003338
Validation loss: 2.7680773621023644

Epoch: 5| Step: 8
Training loss: 2.774528439294743
Validation loss: 2.7673877872898838

Epoch: 5| Step: 9
Training loss: 2.8963490491187445
Validation loss: 2.7660819787826885

Epoch: 5| Step: 10
Training loss: 3.0729659944012693
Validation loss: 2.769375360063009

Epoch: 445| Step: 0
Training loss: 3.677626370684096
Validation loss: 2.7684344160792724

Epoch: 5| Step: 1
Training loss: 2.932973742841263
Validation loss: 2.7708347362804973

Epoch: 5| Step: 2
Training loss: 2.7274596041896886
Validation loss: 2.7805472980996626

Epoch: 5| Step: 3
Training loss: 3.4474905313495956
Validation loss: 2.7792311675408916

Epoch: 5| Step: 4
Training loss: 3.079026608170316
Validation loss: 2.7788687800682585

Epoch: 5| Step: 5
Training loss: 2.941388417629378
Validation loss: 2.7755526832884305

Epoch: 5| Step: 6
Training loss: 2.6678749168505727
Validation loss: 2.7823912290997233

Epoch: 5| Step: 7
Training loss: 2.5855413865329266
Validation loss: 2.7865892608185994

Epoch: 5| Step: 8
Training loss: 3.2638130088985893
Validation loss: 2.7881950448875403

Epoch: 5| Step: 9
Training loss: 3.0132742302367514
Validation loss: 2.7761500223018336

Epoch: 5| Step: 10
Training loss: 3.338970012035444
Validation loss: 2.7650110457684316

Epoch: 446| Step: 0
Training loss: 2.683398732480286
Validation loss: 2.7632549668739768

Epoch: 5| Step: 1
Training loss: 3.7541057998064113
Validation loss: 2.7631012065943628

Epoch: 5| Step: 2
Training loss: 2.871503445205601
Validation loss: 2.764692793303355

Epoch: 5| Step: 3
Training loss: 2.6546427632604366
Validation loss: 2.7629624115933775

Epoch: 5| Step: 4
Training loss: 3.3810934936630526
Validation loss: 2.7644774207360046

Epoch: 5| Step: 5
Training loss: 3.1859810893999607
Validation loss: 2.7561186237289603

Epoch: 5| Step: 6
Training loss: 3.344074839562173
Validation loss: 2.7668031769526924

Epoch: 5| Step: 7
Training loss: 2.633661150345672
Validation loss: 2.7632393377652633

Epoch: 5| Step: 8
Training loss: 3.0197464840313706
Validation loss: 2.7681190512733944

Epoch: 5| Step: 9
Training loss: 3.298577325659056
Validation loss: 2.7672629229321686

Epoch: 5| Step: 10
Training loss: 2.7649704325579907
Validation loss: 2.765459845860445

Epoch: 447| Step: 0
Training loss: 2.7691843006522703
Validation loss: 2.7612034783628596

Epoch: 5| Step: 1
Training loss: 2.7791536124026264
Validation loss: 2.7610717299565697

Epoch: 5| Step: 2
Training loss: 3.2146712450395425
Validation loss: 2.760345969491508

Epoch: 5| Step: 3
Training loss: 2.724517842604524
Validation loss: 2.76689670534004

Epoch: 5| Step: 4
Training loss: 3.3935126739755397
Validation loss: 2.75840224080317

Epoch: 5| Step: 5
Training loss: 3.2290351758867937
Validation loss: 2.7614195463273585

Epoch: 5| Step: 6
Training loss: 3.174433536008611
Validation loss: 2.7624944747433755

Epoch: 5| Step: 7
Training loss: 2.932522391439483
Validation loss: 2.7610364265030762

Epoch: 5| Step: 8
Training loss: 3.3087470909714027
Validation loss: 2.7572667903354353

Epoch: 5| Step: 9
Training loss: 3.245958896961975
Validation loss: 2.7705738471342283

Epoch: 5| Step: 10
Training loss: 2.933635035807186
Validation loss: 2.7633649841688492

Epoch: 448| Step: 0
Training loss: 3.1000227096710233
Validation loss: 2.7636630737159904

Epoch: 5| Step: 1
Training loss: 3.671344085620351
Validation loss: 2.7639378455232704

Epoch: 5| Step: 2
Training loss: 2.8986273443765382
Validation loss: 2.765826869164945

Epoch: 5| Step: 3
Training loss: 2.918304709993645
Validation loss: 2.7655776251374835

Epoch: 5| Step: 4
Training loss: 2.4466212856058136
Validation loss: 2.776780991360862

Epoch: 5| Step: 5
Training loss: 3.0182166155514936
Validation loss: 2.778760650692442

Epoch: 5| Step: 6
Training loss: 3.404250091563939
Validation loss: 2.7817207501227954

Epoch: 5| Step: 7
Training loss: 3.1693533659662845
Validation loss: 2.7767735906437063

Epoch: 5| Step: 8
Training loss: 2.910355160463097
Validation loss: 2.7887027276688787

Epoch: 5| Step: 9
Training loss: 2.7960619890274923
Validation loss: 2.766763840011726

Epoch: 5| Step: 10
Training loss: 3.317546383404832
Validation loss: 2.7709112761646333

Epoch: 449| Step: 0
Training loss: 3.2513070045997163
Validation loss: 2.764809630727855

Epoch: 5| Step: 1
Training loss: 3.36277038735022
Validation loss: 2.7625664804663175

Epoch: 5| Step: 2
Training loss: 3.5491808147615673
Validation loss: 2.7679533170365853

Epoch: 5| Step: 3
Training loss: 2.089103211011204
Validation loss: 2.762171127423971

Epoch: 5| Step: 4
Training loss: 3.1353904410413445
Validation loss: 2.7609275253835057

Epoch: 5| Step: 5
Training loss: 3.3218994656484546
Validation loss: 2.7573686937673996

Epoch: 5| Step: 6
Training loss: 2.9729780105716848
Validation loss: 2.7608272520334185

Epoch: 5| Step: 7
Training loss: 2.600289706448995
Validation loss: 2.760599817448387

Epoch: 5| Step: 8
Training loss: 2.9668891294700215
Validation loss: 2.7590972994777774

Epoch: 5| Step: 9
Training loss: 3.4032428311212417
Validation loss: 2.762850190287532

Epoch: 5| Step: 10
Training loss: 2.7665234846576143
Validation loss: 2.759184608398785

Epoch: 450| Step: 0
Training loss: 2.656535593275084
Validation loss: 2.7623812803877184

Epoch: 5| Step: 1
Training loss: 3.3257850695340117
Validation loss: 2.759115904898838

Epoch: 5| Step: 2
Training loss: 2.693846726948929
Validation loss: 2.755902413651593

Epoch: 5| Step: 3
Training loss: 3.473007338876656
Validation loss: 2.753884042106178

Epoch: 5| Step: 4
Training loss: 3.3202539057329874
Validation loss: 2.7639897395206896

Epoch: 5| Step: 5
Training loss: 3.2936415884283616
Validation loss: 2.763013339470567

Epoch: 5| Step: 6
Training loss: 3.019548936720516
Validation loss: 2.754246467515353

Epoch: 5| Step: 7
Training loss: 2.968478541762644
Validation loss: 2.7526594430351357

Epoch: 5| Step: 8
Training loss: 3.098445834996511
Validation loss: 2.750751879201054

Epoch: 5| Step: 9
Training loss: 2.9068986722531402
Validation loss: 2.756024748645924

Epoch: 5| Step: 10
Training loss: 2.8548578321130367
Validation loss: 2.7571395354588204

Epoch: 451| Step: 0
Training loss: 2.441089237230695
Validation loss: 2.7563634755739974

Epoch: 5| Step: 1
Training loss: 3.238229417558643
Validation loss: 2.759395704188367

Epoch: 5| Step: 2
Training loss: 2.4636860348833016
Validation loss: 2.7570110882045045

Epoch: 5| Step: 3
Training loss: 3.4148311491702996
Validation loss: 2.758187115034976

Epoch: 5| Step: 4
Training loss: 3.247741207711986
Validation loss: 2.7644888966796235

Epoch: 5| Step: 5
Training loss: 3.4147748749506515
Validation loss: 2.761146543336854

Epoch: 5| Step: 6
Training loss: 2.5308300658971024
Validation loss: 2.76273801453178

Epoch: 5| Step: 7
Training loss: 3.3930475396677413
Validation loss: 2.7579921564078997

Epoch: 5| Step: 8
Training loss: 3.42223450326849
Validation loss: 2.76325321526035

Epoch: 5| Step: 9
Training loss: 2.896504294699289
Validation loss: 2.7558026774855424

Epoch: 5| Step: 10
Training loss: 2.9679251076948105
Validation loss: 2.7596334763034083

Epoch: 452| Step: 0
Training loss: 3.3674811923288415
Validation loss: 2.752463361732039

Epoch: 5| Step: 1
Training loss: 2.8080019267638026
Validation loss: 2.758635046795458

Epoch: 5| Step: 2
Training loss: 3.720417322110408
Validation loss: 2.7570226407893523

Epoch: 5| Step: 3
Training loss: 2.7559197606446775
Validation loss: 2.7522714580487317

Epoch: 5| Step: 4
Training loss: 2.993243875108412
Validation loss: 2.7648247919789712

Epoch: 5| Step: 5
Training loss: 2.860247036061711
Validation loss: 2.7661311327982703

Epoch: 5| Step: 6
Training loss: 3.0749158832240937
Validation loss: 2.758262913789615

Epoch: 5| Step: 7
Training loss: 2.872213090955467
Validation loss: 2.762571111144399

Epoch: 5| Step: 8
Training loss: 2.9799941898775746
Validation loss: 2.757187548102789

Epoch: 5| Step: 9
Training loss: 3.083859596361482
Validation loss: 2.7565583754773333

Epoch: 5| Step: 10
Training loss: 3.0702882722087987
Validation loss: 2.7601465323286964

Epoch: 453| Step: 0
Training loss: 3.9191590894144177
Validation loss: 2.763286816731071

Epoch: 5| Step: 1
Training loss: 3.3744220945290615
Validation loss: 2.7631590643941006

Epoch: 5| Step: 2
Training loss: 2.903070823402088
Validation loss: 2.760341481821572

Epoch: 5| Step: 3
Training loss: 3.087704541307607
Validation loss: 2.7618578312037854

Epoch: 5| Step: 4
Training loss: 2.2441285135525004
Validation loss: 2.7646434913118347

Epoch: 5| Step: 5
Training loss: 3.2792727371245354
Validation loss: 2.7622189273145294

Epoch: 5| Step: 6
Training loss: 2.791433827573332
Validation loss: 2.7593581671736676

Epoch: 5| Step: 7
Training loss: 3.2769927972476367
Validation loss: 2.7645706707881357

Epoch: 5| Step: 8
Training loss: 2.775425416109567
Validation loss: 2.7677378777026918

Epoch: 5| Step: 9
Training loss: 2.9676910117810866
Validation loss: 2.753500461289162

Epoch: 5| Step: 10
Training loss: 2.71615678608857
Validation loss: 2.7514523561212134

Epoch: 454| Step: 0
Training loss: 3.0451199685502983
Validation loss: 2.752791906965509

Epoch: 5| Step: 1
Training loss: 2.68292414544557
Validation loss: 2.750013314118881

Epoch: 5| Step: 2
Training loss: 3.0718047808269375
Validation loss: 2.754956643779345

Epoch: 5| Step: 3
Training loss: 3.0327333576581283
Validation loss: 2.7486325012031463

Epoch: 5| Step: 4
Training loss: 3.183136290465232
Validation loss: 2.750815984570824

Epoch: 5| Step: 5
Training loss: 3.0659695648454495
Validation loss: 2.7501911607752936

Epoch: 5| Step: 6
Training loss: 3.0148421936742875
Validation loss: 2.7509262244195467

Epoch: 5| Step: 7
Training loss: 3.2021365245470688
Validation loss: 2.7457171488664107

Epoch: 5| Step: 8
Training loss: 2.9223452918854202
Validation loss: 2.748093402770484

Epoch: 5| Step: 9
Training loss: 3.1226678920106035
Validation loss: 2.7499620112445564

Epoch: 5| Step: 10
Training loss: 3.354173048183144
Validation loss: 2.7490577481851557

Epoch: 455| Step: 0
Training loss: 3.093143596365881
Validation loss: 2.747299824533857

Epoch: 5| Step: 1
Training loss: 2.6566846604098835
Validation loss: 2.751801395794518

Epoch: 5| Step: 2
Training loss: 3.080708615171879
Validation loss: 2.7522468775464586

Epoch: 5| Step: 3
Training loss: 3.0656644081748095
Validation loss: 2.7546127484806626

Epoch: 5| Step: 4
Training loss: 3.212623765988167
Validation loss: 2.756263327308824

Epoch: 5| Step: 5
Training loss: 2.666960004726183
Validation loss: 2.7678501203536836

Epoch: 5| Step: 6
Training loss: 3.2512115274431466
Validation loss: 2.769081371113405

Epoch: 5| Step: 7
Training loss: 3.3299609927163853
Validation loss: 2.787947142194121

Epoch: 5| Step: 8
Training loss: 2.9739838090775264
Validation loss: 2.7612741455367695

Epoch: 5| Step: 9
Training loss: 2.6965329268227847
Validation loss: 2.7549208394851874

Epoch: 5| Step: 10
Training loss: 3.611773730071402
Validation loss: 2.7481169690772123

Epoch: 456| Step: 0
Training loss: 3.631161419154087
Validation loss: 2.7511223211622267

Epoch: 5| Step: 1
Training loss: 3.0120651501097813
Validation loss: 2.752330009226798

Epoch: 5| Step: 2
Training loss: 2.0952398209337666
Validation loss: 2.758958382963836

Epoch: 5| Step: 3
Training loss: 3.0949707705299208
Validation loss: 2.753210138752282

Epoch: 5| Step: 4
Training loss: 2.9219308123638403
Validation loss: 2.749516281438333

Epoch: 5| Step: 5
Training loss: 3.030875743296196
Validation loss: 2.7508430885260537

Epoch: 5| Step: 6
Training loss: 3.251487831530561
Validation loss: 2.7487680989099696

Epoch: 5| Step: 7
Training loss: 3.1083938354112965
Validation loss: 2.7510994478119035

Epoch: 5| Step: 8
Training loss: 3.968310955122828
Validation loss: 2.7469726476080094

Epoch: 5| Step: 9
Training loss: 2.7215104394362424
Validation loss: 2.745736381819273

Epoch: 5| Step: 10
Training loss: 2.248853179277883
Validation loss: 2.7470500166006744

Epoch: 457| Step: 0
Training loss: 3.081240553773711
Validation loss: 2.7475782192250855

Epoch: 5| Step: 1
Training loss: 3.1294303007517494
Validation loss: 2.745333311287906

Epoch: 5| Step: 2
Training loss: 2.8641575907286962
Validation loss: 2.7547951699509508

Epoch: 5| Step: 3
Training loss: 3.5040865610395957
Validation loss: 2.7451747314014945

Epoch: 5| Step: 4
Training loss: 2.935096894050658
Validation loss: 2.7553122438607645

Epoch: 5| Step: 5
Training loss: 3.072370387944822
Validation loss: 2.7508360224929733

Epoch: 5| Step: 6
Training loss: 3.3291991027346826
Validation loss: 2.7515353282588837

Epoch: 5| Step: 7
Training loss: 3.2153923521415626
Validation loss: 2.760466381576476

Epoch: 5| Step: 8
Training loss: 2.768831194167173
Validation loss: 2.7593398486129255

Epoch: 5| Step: 9
Training loss: 2.8482328859329193
Validation loss: 2.767152425991495

Epoch: 5| Step: 10
Training loss: 2.784903451968468
Validation loss: 2.75416255407827

Epoch: 458| Step: 0
Training loss: 2.7288248464443483
Validation loss: 2.7628820745031604

Epoch: 5| Step: 1
Training loss: 3.041671613575993
Validation loss: 2.7609437316656695

Epoch: 5| Step: 2
Training loss: 3.009477268592634
Validation loss: 2.7648205294791843

Epoch: 5| Step: 3
Training loss: 3.047053405233604
Validation loss: 2.7614184304170033

Epoch: 5| Step: 4
Training loss: 3.483897770928948
Validation loss: 2.755785956761323

Epoch: 5| Step: 5
Training loss: 3.447186918143634
Validation loss: 2.7509286856167354

Epoch: 5| Step: 6
Training loss: 3.1859285557477746
Validation loss: 2.744016301326859

Epoch: 5| Step: 7
Training loss: 2.6521572221610072
Validation loss: 2.7495500013677954

Epoch: 5| Step: 8
Training loss: 3.024594738508674
Validation loss: 2.741169275851247

Epoch: 5| Step: 9
Training loss: 3.4105494251794384
Validation loss: 2.748079722988054

Epoch: 5| Step: 10
Training loss: 2.3560143593251794
Validation loss: 2.7440141842796972

Epoch: 459| Step: 0
Training loss: 3.678463353594513
Validation loss: 2.7459325233557155

Epoch: 5| Step: 1
Training loss: 3.232034914762924
Validation loss: 2.746927469036543

Epoch: 5| Step: 2
Training loss: 2.64328302538391
Validation loss: 2.7459400333352564

Epoch: 5| Step: 3
Training loss: 2.8992668672113595
Validation loss: 2.742148963609063

Epoch: 5| Step: 4
Training loss: 3.5669027862348863
Validation loss: 2.7444305833103333

Epoch: 5| Step: 5
Training loss: 2.565507565969144
Validation loss: 2.7434875231924054

Epoch: 5| Step: 6
Training loss: 3.2312208635503343
Validation loss: 2.7423621746867446

Epoch: 5| Step: 7
Training loss: 3.0930908734020486
Validation loss: 2.7418663580792986

Epoch: 5| Step: 8
Training loss: 3.4396424986019225
Validation loss: 2.749217458079844

Epoch: 5| Step: 9
Training loss: 2.357169225470951
Validation loss: 2.7459548459721392

Epoch: 5| Step: 10
Training loss: 2.5597482187909644
Validation loss: 2.751456217252705

Epoch: 460| Step: 0
Training loss: 2.8150828899152343
Validation loss: 2.7505869523361177

Epoch: 5| Step: 1
Training loss: 2.4441921604863257
Validation loss: 2.7570162972881147

Epoch: 5| Step: 2
Training loss: 2.797013263374989
Validation loss: 2.764813265504215

Epoch: 5| Step: 3
Training loss: 3.393920703058258
Validation loss: 2.7716111358958346

Epoch: 5| Step: 4
Training loss: 3.5203813040723317
Validation loss: 2.7795519602597736

Epoch: 5| Step: 5
Training loss: 2.819745289412124
Validation loss: 2.788572901798831

Epoch: 5| Step: 6
Training loss: 3.2104041777377557
Validation loss: 2.7812314043832527

Epoch: 5| Step: 7
Training loss: 3.492063242773292
Validation loss: 2.777276284024196

Epoch: 5| Step: 8
Training loss: 3.0676811143653104
Validation loss: 2.758757177443252

Epoch: 5| Step: 9
Training loss: 2.779786828739287
Validation loss: 2.7554848249576693

Epoch: 5| Step: 10
Training loss: 3.1380952733920067
Validation loss: 2.752768103154626

Epoch: 461| Step: 0
Training loss: 2.6957984375697337
Validation loss: 2.74343575813962

Epoch: 5| Step: 1
Training loss: 2.7299350113172336
Validation loss: 2.744187896301509

Epoch: 5| Step: 2
Training loss: 3.210593397724965
Validation loss: 2.7443900326537265

Epoch: 5| Step: 3
Training loss: 2.4371077393081344
Validation loss: 2.7413841781508768

Epoch: 5| Step: 4
Training loss: 3.024359195397538
Validation loss: 2.7426619431165267

Epoch: 5| Step: 5
Training loss: 3.150003729924007
Validation loss: 2.741034406802506

Epoch: 5| Step: 6
Training loss: 3.0263074713271854
Validation loss: 2.74560982784199

Epoch: 5| Step: 7
Training loss: 3.1769164661715967
Validation loss: 2.74517422150757

Epoch: 5| Step: 8
Training loss: 3.813578093638799
Validation loss: 2.748828848310727

Epoch: 5| Step: 9
Training loss: 2.7446325112417393
Validation loss: 2.74731220273012

Epoch: 5| Step: 10
Training loss: 3.400336776210614
Validation loss: 2.7507902522015706

Epoch: 462| Step: 0
Training loss: 3.15490694081074
Validation loss: 2.7446487394837864

Epoch: 5| Step: 1
Training loss: 2.886750795343953
Validation loss: 2.7571087517704194

Epoch: 5| Step: 2
Training loss: 3.0607571995176968
Validation loss: 2.75672670119287

Epoch: 5| Step: 3
Training loss: 2.9711082327743252
Validation loss: 2.760393243753373

Epoch: 5| Step: 4
Training loss: 3.119812130529235
Validation loss: 2.759477668247393

Epoch: 5| Step: 5
Training loss: 3.309268598854253
Validation loss: 2.7553088514904327

Epoch: 5| Step: 6
Training loss: 2.8306959068967084
Validation loss: 2.750424550864887

Epoch: 5| Step: 7
Training loss: 3.432907226811273
Validation loss: 2.749173848517965

Epoch: 5| Step: 8
Training loss: 3.3468245872027538
Validation loss: 2.7551987488481053

Epoch: 5| Step: 9
Training loss: 2.6508506201434554
Validation loss: 2.74274824605299

Epoch: 5| Step: 10
Training loss: 2.664731833759189
Validation loss: 2.743882867172666

Epoch: 463| Step: 0
Training loss: 3.0644168693581073
Validation loss: 2.7458768467293084

Epoch: 5| Step: 1
Training loss: 3.122220290814304
Validation loss: 2.7455076364305344

Epoch: 5| Step: 2
Training loss: 3.0598901020835068
Validation loss: 2.7407672453925387

Epoch: 5| Step: 3
Training loss: 2.885271052646737
Validation loss: 2.7418784083120933

Epoch: 5| Step: 4
Training loss: 3.556581633914955
Validation loss: 2.747979948259973

Epoch: 5| Step: 5
Training loss: 2.863927666736339
Validation loss: 2.74292651142433

Epoch: 5| Step: 6
Training loss: 3.005778786890788
Validation loss: 2.746890001495073

Epoch: 5| Step: 7
Training loss: 3.4000290925520322
Validation loss: 2.746314581979269

Epoch: 5| Step: 8
Training loss: 3.1159500304538192
Validation loss: 2.740271640718582

Epoch: 5| Step: 9
Training loss: 2.5250512977148225
Validation loss: 2.7442720325326375

Epoch: 5| Step: 10
Training loss: 2.8050757009317526
Validation loss: 2.7445868542016685

Epoch: 464| Step: 0
Training loss: 2.6827252577658385
Validation loss: 2.7547716393701585

Epoch: 5| Step: 1
Training loss: 2.603004674431747
Validation loss: 2.7509219357245986

Epoch: 5| Step: 2
Training loss: 3.463634946709509
Validation loss: 2.77179753670593

Epoch: 5| Step: 3
Training loss: 3.2322765674949374
Validation loss: 2.755216314279153

Epoch: 5| Step: 4
Training loss: 2.6403009339967687
Validation loss: 2.756329387903373

Epoch: 5| Step: 5
Training loss: 2.990138056703157
Validation loss: 2.760418397171924

Epoch: 5| Step: 6
Training loss: 3.596228101741242
Validation loss: 2.7644433848936

Epoch: 5| Step: 7
Training loss: 3.323866721317072
Validation loss: 2.7726756751396646

Epoch: 5| Step: 8
Training loss: 3.2667459270696835
Validation loss: 2.7662765414926795

Epoch: 5| Step: 9
Training loss: 2.2128413869122188
Validation loss: 2.769027969931612

Epoch: 5| Step: 10
Training loss: 3.2728506941594153
Validation loss: 2.7520437150946107

Epoch: 465| Step: 0
Training loss: 3.5000580374129213
Validation loss: 2.742341315760241

Epoch: 5| Step: 1
Training loss: 3.0012353896580226
Validation loss: 2.736710304784758

Epoch: 5| Step: 2
Training loss: 3.6941254142616686
Validation loss: 2.738850760484843

Epoch: 5| Step: 3
Training loss: 2.9108874330499597
Validation loss: 2.741085972632818

Epoch: 5| Step: 4
Training loss: 2.848586444653912
Validation loss: 2.7506045127331773

Epoch: 5| Step: 5
Training loss: 3.051447171689815
Validation loss: 2.7500643009487886

Epoch: 5| Step: 6
Training loss: 3.5996391804331003
Validation loss: 2.759185959353179

Epoch: 5| Step: 7
Training loss: 2.5623082345059394
Validation loss: 2.76030118441047

Epoch: 5| Step: 8
Training loss: 2.4898567422001787
Validation loss: 2.746667914670539

Epoch: 5| Step: 9
Training loss: 3.12054033588977
Validation loss: 2.744462729158382

Epoch: 5| Step: 10
Training loss: 2.575375287013044
Validation loss: 2.738358491015292

Epoch: 466| Step: 0
Training loss: 3.4476125223830167
Validation loss: 2.739490887555093

Epoch: 5| Step: 1
Training loss: 3.532964779567862
Validation loss: 2.7376963339873863

Epoch: 5| Step: 2
Training loss: 2.0466376014078755
Validation loss: 2.7353326707847825

Epoch: 5| Step: 3
Training loss: 2.868309196564193
Validation loss: 2.7387242271869487

Epoch: 5| Step: 4
Training loss: 3.256681909307485
Validation loss: 2.742225168284549

Epoch: 5| Step: 5
Training loss: 2.291823560950447
Validation loss: 2.7462526744916675

Epoch: 5| Step: 6
Training loss: 3.319301316612993
Validation loss: 2.748741811090162

Epoch: 5| Step: 7
Training loss: 2.722349918596922
Validation loss: 2.7473745295768754

Epoch: 5| Step: 8
Training loss: 3.3332049504034464
Validation loss: 2.7444285095525216

Epoch: 5| Step: 9
Training loss: 2.8751356673365556
Validation loss: 2.7513659274116122

Epoch: 5| Step: 10
Training loss: 3.540558824989763
Validation loss: 2.753639844932287

Epoch: 467| Step: 0
Training loss: 2.3392851963687438
Validation loss: 2.760026232612739

Epoch: 5| Step: 1
Training loss: 3.5676391743363394
Validation loss: 2.753332030515932

Epoch: 5| Step: 2
Training loss: 2.950402352001552
Validation loss: 2.751465041744031

Epoch: 5| Step: 3
Training loss: 3.140117091771678
Validation loss: 2.753829260751906

Epoch: 5| Step: 4
Training loss: 2.3696247307524256
Validation loss: 2.7497735195924244

Epoch: 5| Step: 5
Training loss: 2.9728073502785404
Validation loss: 2.7543214849000686

Epoch: 5| Step: 6
Training loss: 3.0405837617843647
Validation loss: 2.746976496370968

Epoch: 5| Step: 7
Training loss: 2.67458941793594
Validation loss: 2.757384692716025

Epoch: 5| Step: 8
Training loss: 2.952180095658073
Validation loss: 2.7522113109249915

Epoch: 5| Step: 9
Training loss: 4.127709394812389
Validation loss: 2.743537778166438

Epoch: 5| Step: 10
Training loss: 2.964533652673221
Validation loss: 2.7470968869481687

Epoch: 468| Step: 0
Training loss: 3.1438266509705235
Validation loss: 2.738652156251526

Epoch: 5| Step: 1
Training loss: 3.1872610862803032
Validation loss: 2.7337548387373243

Epoch: 5| Step: 2
Training loss: 3.326338597507926
Validation loss: 2.7422788604951283

Epoch: 5| Step: 3
Training loss: 2.979275965964226
Validation loss: 2.7418115432506522

Epoch: 5| Step: 4
Training loss: 2.4186426064949904
Validation loss: 2.7342234335993565

Epoch: 5| Step: 5
Training loss: 3.474421770028412
Validation loss: 2.737433846839795

Epoch: 5| Step: 6
Training loss: 2.891888151746944
Validation loss: 2.739178020268665

Epoch: 5| Step: 7
Training loss: 3.33030092271552
Validation loss: 2.7338832355591487

Epoch: 5| Step: 8
Training loss: 3.1478532954329164
Validation loss: 2.737381263975224

Epoch: 5| Step: 9
Training loss: 2.952992754200366
Validation loss: 2.737488735278999

Epoch: 5| Step: 10
Training loss: 2.398872162141841
Validation loss: 2.7351846010302223

Epoch: 469| Step: 0
Training loss: 2.588808246806416
Validation loss: 2.748176932485051

Epoch: 5| Step: 1
Training loss: 2.706113188987809
Validation loss: 2.746885154924021

Epoch: 5| Step: 2
Training loss: 3.7634753664400766
Validation loss: 2.744748354166096

Epoch: 5| Step: 3
Training loss: 2.7341121874257786
Validation loss: 2.742726031001417

Epoch: 5| Step: 4
Training loss: 3.1211773189199197
Validation loss: 2.741039409622321

Epoch: 5| Step: 5
Training loss: 3.3810140925838343
Validation loss: 2.7426572797587125

Epoch: 5| Step: 6
Training loss: 2.574177534731465
Validation loss: 2.747405163861327

Epoch: 5| Step: 7
Training loss: 3.321298394530774
Validation loss: 2.744801185374872

Epoch: 5| Step: 8
Training loss: 2.9144635371978427
Validation loss: 2.7555019531512217

Epoch: 5| Step: 9
Training loss: 3.19304458979849
Validation loss: 2.7502243727941473

Epoch: 5| Step: 10
Training loss: 2.966933005589402
Validation loss: 2.7475642177713224

Epoch: 470| Step: 0
Training loss: 2.706007286270606
Validation loss: 2.7429619759964363

Epoch: 5| Step: 1
Training loss: 3.485213790312521
Validation loss: 2.747783366024744

Epoch: 5| Step: 2
Training loss: 3.25736473171525
Validation loss: 2.746117658342849

Epoch: 5| Step: 3
Training loss: 2.9823217868560805
Validation loss: 2.741764046776418

Epoch: 5| Step: 4
Training loss: 3.33341838410274
Validation loss: 2.7442757524299255

Epoch: 5| Step: 5
Training loss: 2.6066754476426985
Validation loss: 2.7377532210674485

Epoch: 5| Step: 6
Training loss: 3.0375465986029058
Validation loss: 2.74066948778049

Epoch: 5| Step: 7
Training loss: 3.14438324574053
Validation loss: 2.7357116582393624

Epoch: 5| Step: 8
Training loss: 2.654619681495138
Validation loss: 2.74222204953627

Epoch: 5| Step: 9
Training loss: 3.0733036293309977
Validation loss: 2.738151482735803

Epoch: 5| Step: 10
Training loss: 3.0939463543473247
Validation loss: 2.7440532251321086

Epoch: 471| Step: 0
Training loss: 3.3709177831029122
Validation loss: 2.7339929851174305

Epoch: 5| Step: 1
Training loss: 3.2137728236488536
Validation loss: 2.7319597031380667

Epoch: 5| Step: 2
Training loss: 3.029507165492679
Validation loss: 2.732918678065834

Epoch: 5| Step: 3
Training loss: 3.0806623351113367
Validation loss: 2.734994126411231

Epoch: 5| Step: 4
Training loss: 2.9219908665821746
Validation loss: 2.7428132133205967

Epoch: 5| Step: 5
Training loss: 2.937153572595207
Validation loss: 2.7326080304122917

Epoch: 5| Step: 6
Training loss: 2.5624371962875916
Validation loss: 2.7355718165689558

Epoch: 5| Step: 7
Training loss: 3.737885935578428
Validation loss: 2.732811913539805

Epoch: 5| Step: 8
Training loss: 2.7379757088976207
Validation loss: 2.7361982004581322

Epoch: 5| Step: 9
Training loss: 2.859362659531943
Validation loss: 2.732728467665376

Epoch: 5| Step: 10
Training loss: 2.8303375862343314
Validation loss: 2.7282660441052915

Epoch: 472| Step: 0
Training loss: 3.1047423850796316
Validation loss: 2.7337691266047286

Epoch: 5| Step: 1
Training loss: 2.4041212499638176
Validation loss: 2.7277952252308078

Epoch: 5| Step: 2
Training loss: 3.2312252907020365
Validation loss: 2.7266889150813847

Epoch: 5| Step: 3
Training loss: 3.676097503581068
Validation loss: 2.728687069204959

Epoch: 5| Step: 4
Training loss: 3.243133186393223
Validation loss: 2.7326057478528463

Epoch: 5| Step: 5
Training loss: 2.71317394691364
Validation loss: 2.726458619596386

Epoch: 5| Step: 6
Training loss: 3.1983057007052302
Validation loss: 2.732189197146721

Epoch: 5| Step: 7
Training loss: 3.173340407238083
Validation loss: 2.7249636988325965

Epoch: 5| Step: 8
Training loss: 3.0338564020020375
Validation loss: 2.7319644832868946

Epoch: 5| Step: 9
Training loss: 2.3748510213605454
Validation loss: 2.732345406294813

Epoch: 5| Step: 10
Training loss: 3.095622411211188
Validation loss: 2.7281813043111556

Epoch: 473| Step: 0
Training loss: 2.675141596388868
Validation loss: 2.7243661860835164

Epoch: 5| Step: 1
Training loss: 3.3012408957884865
Validation loss: 2.7269033847762114

Epoch: 5| Step: 2
Training loss: 3.28950174982245
Validation loss: 2.735036372348788

Epoch: 5| Step: 3
Training loss: 3.195589757702971
Validation loss: 2.7354047345222643

Epoch: 5| Step: 4
Training loss: 2.961344265739715
Validation loss: 2.7450721866523993

Epoch: 5| Step: 5
Training loss: 3.3652954450258914
Validation loss: 2.7496818813411097

Epoch: 5| Step: 6
Training loss: 3.1652819132186196
Validation loss: 2.7536385238419703

Epoch: 5| Step: 7
Training loss: 2.744549030579724
Validation loss: 2.76472305951323

Epoch: 5| Step: 8
Training loss: 2.592884884610443
Validation loss: 2.749360650656355

Epoch: 5| Step: 9
Training loss: 2.8655650358259783
Validation loss: 2.7528421308410964

Epoch: 5| Step: 10
Training loss: 3.2588911946461914
Validation loss: 2.74696504059242

Epoch: 474| Step: 0
Training loss: 2.7621836830731668
Validation loss: 2.734209112476535

Epoch: 5| Step: 1
Training loss: 2.9228868007606854
Validation loss: 2.7291421207343975

Epoch: 5| Step: 2
Training loss: 2.7183383323051227
Validation loss: 2.7299052496776484

Epoch: 5| Step: 3
Training loss: 3.1921850442526805
Validation loss: 2.7242990210647813

Epoch: 5| Step: 4
Training loss: 3.294748352582962
Validation loss: 2.7222163048448915

Epoch: 5| Step: 5
Training loss: 2.7461580836003034
Validation loss: 2.726258881286399

Epoch: 5| Step: 6
Training loss: 3.4968228224610653
Validation loss: 2.729039931734393

Epoch: 5| Step: 7
Training loss: 2.6044812025218285
Validation loss: 2.726535967997368

Epoch: 5| Step: 8
Training loss: 3.606329884297192
Validation loss: 2.724830220775669

Epoch: 5| Step: 9
Training loss: 2.939086972367462
Validation loss: 2.7244330549193028

Epoch: 5| Step: 10
Training loss: 2.9611500686395322
Validation loss: 2.72820376465356

Epoch: 475| Step: 0
Training loss: 3.0029519181087707
Validation loss: 2.7254142455400787

Epoch: 5| Step: 1
Training loss: 2.912069748954911
Validation loss: 2.7299739342289966

Epoch: 5| Step: 2
Training loss: 3.262457520657806
Validation loss: 2.7271534137521343

Epoch: 5| Step: 3
Training loss: 2.7475359888470554
Validation loss: 2.728551645186733

Epoch: 5| Step: 4
Training loss: 3.267454082280204
Validation loss: 2.731933906705668

Epoch: 5| Step: 5
Training loss: 2.8979787951971128
Validation loss: 2.7357765405323957

Epoch: 5| Step: 6
Training loss: 2.848796182001175
Validation loss: 2.7297067365382897

Epoch: 5| Step: 7
Training loss: 3.163357879923966
Validation loss: 2.739015733235985

Epoch: 5| Step: 8
Training loss: 2.7293650916574625
Validation loss: 2.747410956623347

Epoch: 5| Step: 9
Training loss: 2.920970103444204
Validation loss: 2.7593180412191

Epoch: 5| Step: 10
Training loss: 3.6356161476356683
Validation loss: 2.753353223310441

Epoch: 476| Step: 0
Training loss: 2.7537616664727658
Validation loss: 2.754962999467512

Epoch: 5| Step: 1
Training loss: 2.7000798178283625
Validation loss: 2.745729412818857

Epoch: 5| Step: 2
Training loss: 2.732429291699414
Validation loss: 2.739901491709815

Epoch: 5| Step: 3
Training loss: 2.84618466295146
Validation loss: 2.740698564743901

Epoch: 5| Step: 4
Training loss: 2.7894784312695564
Validation loss: 2.740396278342912

Epoch: 5| Step: 5
Training loss: 3.4062239619668504
Validation loss: 2.738881324432248

Epoch: 5| Step: 6
Training loss: 3.272213217552531
Validation loss: 2.745627259472154

Epoch: 5| Step: 7
Training loss: 3.4615884345270262
Validation loss: 2.7367595498127892

Epoch: 5| Step: 8
Training loss: 3.4669848925688
Validation loss: 2.736305283507056

Epoch: 5| Step: 9
Training loss: 3.236373505075622
Validation loss: 2.742891390344526

Epoch: 5| Step: 10
Training loss: 2.419115524863982
Validation loss: 2.7222654090046783

Epoch: 477| Step: 0
Training loss: 2.952470979475252
Validation loss: 2.7296080005052925

Epoch: 5| Step: 1
Training loss: 3.358239128236617
Validation loss: 2.7291338280721202

Epoch: 5| Step: 2
Training loss: 2.423106218983006
Validation loss: 2.7297333288201813

Epoch: 5| Step: 3
Training loss: 3.2973756816760202
Validation loss: 2.7281265499913707

Epoch: 5| Step: 4
Training loss: 4.132114632714178
Validation loss: 2.7343035635574773

Epoch: 5| Step: 5
Training loss: 3.046438019545711
Validation loss: 2.7321111258185775

Epoch: 5| Step: 6
Training loss: 2.867238722507371
Validation loss: 2.7306819210947486

Epoch: 5| Step: 7
Training loss: 2.9119541426181383
Validation loss: 2.7438446517077355

Epoch: 5| Step: 8
Training loss: 2.6215552479453463
Validation loss: 2.7435452844224906

Epoch: 5| Step: 9
Training loss: 2.421557596388521
Validation loss: 2.7474399351798695

Epoch: 5| Step: 10
Training loss: 2.93522767179831
Validation loss: 2.7721318352644064

Epoch: 478| Step: 0
Training loss: 3.323715656012699
Validation loss: 2.754742559259031

Epoch: 5| Step: 1
Training loss: 2.3921163058759083
Validation loss: 2.752469827493813

Epoch: 5| Step: 2
Training loss: 3.187198849083796
Validation loss: 2.7599256692171377

Epoch: 5| Step: 3
Training loss: 3.119229443837568
Validation loss: 2.734877031358968

Epoch: 5| Step: 4
Training loss: 2.7625358268520452
Validation loss: 2.7346999408651933

Epoch: 5| Step: 5
Training loss: 3.095291524293201
Validation loss: 2.7225391186606736

Epoch: 5| Step: 6
Training loss: 2.817180892081823
Validation loss: 2.7198568553750904

Epoch: 5| Step: 7
Training loss: 2.951692263899501
Validation loss: 2.7189187457302837

Epoch: 5| Step: 8
Training loss: 3.539885503134978
Validation loss: 2.7215239654635086

Epoch: 5| Step: 9
Training loss: 3.300787750779471
Validation loss: 2.7194431200755744

Epoch: 5| Step: 10
Training loss: 2.744097878336987
Validation loss: 2.714736937555737

Epoch: 479| Step: 0
Training loss: 3.0121457283360162
Validation loss: 2.7191289723177188

Epoch: 5| Step: 1
Training loss: 2.7792355389237255
Validation loss: 2.7161029965711236

Epoch: 5| Step: 2
Training loss: 3.5280850160696575
Validation loss: 2.722849417096086

Epoch: 5| Step: 3
Training loss: 3.71999780572806
Validation loss: 2.725079664782036

Epoch: 5| Step: 4
Training loss: 2.351386789239721
Validation loss: 2.725409762433946

Epoch: 5| Step: 5
Training loss: 2.6212257317914487
Validation loss: 2.7339713290578533

Epoch: 5| Step: 6
Training loss: 2.7515459916910108
Validation loss: 2.7374031740150975

Epoch: 5| Step: 7
Training loss: 3.293021892874489
Validation loss: 2.7336014579595793

Epoch: 5| Step: 8
Training loss: 3.18830801502258
Validation loss: 2.7394548240405516

Epoch: 5| Step: 9
Training loss: 2.5416768391723514
Validation loss: 2.736109573377429

Epoch: 5| Step: 10
Training loss: 3.3292131391264848
Validation loss: 2.7407388575997733

Epoch: 480| Step: 0
Training loss: 3.1928047468470817
Validation loss: 2.7318951355890477

Epoch: 5| Step: 1
Training loss: 3.6620882811892495
Validation loss: 2.737403393161437

Epoch: 5| Step: 2
Training loss: 2.5176350399949943
Validation loss: 2.7390790200890445

Epoch: 5| Step: 3
Training loss: 3.3259370444298466
Validation loss: 2.7294269454249713

Epoch: 5| Step: 4
Training loss: 2.3633049577516947
Validation loss: 2.7443694030595687

Epoch: 5| Step: 5
Training loss: 2.6140827039084926
Validation loss: 2.739602383203027

Epoch: 5| Step: 6
Training loss: 3.1909802454830376
Validation loss: 2.7260797102968954

Epoch: 5| Step: 7
Training loss: 2.8555809656473037
Validation loss: 2.7384552245809526

Epoch: 5| Step: 8
Training loss: 2.815915471038319
Validation loss: 2.721103877416562

Epoch: 5| Step: 9
Training loss: 3.3778828212092855
Validation loss: 2.7250631864141854

Epoch: 5| Step: 10
Training loss: 3.2228681275046234
Validation loss: 2.7173451721641326

Epoch: 481| Step: 0
Training loss: 3.1893039161554504
Validation loss: 2.7123436296133825

Epoch: 5| Step: 1
Training loss: 3.147902223127661
Validation loss: 2.713627709466971

Epoch: 5| Step: 2
Training loss: 3.2948357661855097
Validation loss: 2.716092799954204

Epoch: 5| Step: 3
Training loss: 2.7320214306003385
Validation loss: 2.7181296418155174

Epoch: 5| Step: 4
Training loss: 2.520871868837339
Validation loss: 2.7175553596378377

Epoch: 5| Step: 5
Training loss: 3.0477966479653187
Validation loss: 2.7181351932701423

Epoch: 5| Step: 6
Training loss: 2.7391778237262905
Validation loss: 2.7249096334525706

Epoch: 5| Step: 7
Training loss: 2.8251685607044443
Validation loss: 2.7257623607634764

Epoch: 5| Step: 8
Training loss: 3.8443748152374186
Validation loss: 2.7217285489076146

Epoch: 5| Step: 9
Training loss: 2.57685339808286
Validation loss: 2.729248685965608

Epoch: 5| Step: 10
Training loss: 3.2672855225667257
Validation loss: 2.7332604546614245

Epoch: 482| Step: 0
Training loss: 2.9639288052182264
Validation loss: 2.7394310063448253

Epoch: 5| Step: 1
Training loss: 3.1228134134811003
Validation loss: 2.7346471826238794

Epoch: 5| Step: 2
Training loss: 3.2437540337274715
Validation loss: 2.731761076524888

Epoch: 5| Step: 3
Training loss: 2.9166078470747765
Validation loss: 2.726005659295403

Epoch: 5| Step: 4
Training loss: 2.4658032951145463
Validation loss: 2.731952252320114

Epoch: 5| Step: 5
Training loss: 2.906155164258288
Validation loss: 2.7322606344499443

Epoch: 5| Step: 6
Training loss: 3.229708488702513
Validation loss: 2.7444579306113597

Epoch: 5| Step: 7
Training loss: 2.341804612554982
Validation loss: 2.7372445954990146

Epoch: 5| Step: 8
Training loss: 3.273632398825745
Validation loss: 2.7338516695551016

Epoch: 5| Step: 9
Training loss: 3.3022470684351846
Validation loss: 2.7232679932518558

Epoch: 5| Step: 10
Training loss: 3.4482027762987792
Validation loss: 2.723881562400364

Epoch: 483| Step: 0
Training loss: 2.818248215225996
Validation loss: 2.7191139763028245

Epoch: 5| Step: 1
Training loss: 2.683735628555971
Validation loss: 2.715411195363086

Epoch: 5| Step: 2
Training loss: 3.068665351399431
Validation loss: 2.714598202587731

Epoch: 5| Step: 3
Training loss: 3.1636950620947735
Validation loss: 2.722490672944686

Epoch: 5| Step: 4
Training loss: 2.856392060133953
Validation loss: 2.7205018031598103

Epoch: 5| Step: 5
Training loss: 2.4612482752680123
Validation loss: 2.7249868141435574

Epoch: 5| Step: 6
Training loss: 3.3223833156329348
Validation loss: 2.7242198343214032

Epoch: 5| Step: 7
Training loss: 3.538212217203729
Validation loss: 2.7317856302066583

Epoch: 5| Step: 8
Training loss: 3.5375500409256717
Validation loss: 2.7244580388000013

Epoch: 5| Step: 9
Training loss: 2.619762463466914
Validation loss: 2.7304600275930713

Epoch: 5| Step: 10
Training loss: 3.007865608043725
Validation loss: 2.73416213043474

Epoch: 484| Step: 0
Training loss: 3.211794847808493
Validation loss: 2.730822775459162

Epoch: 5| Step: 1
Training loss: 3.3699080591083286
Validation loss: 2.7299173771247944

Epoch: 5| Step: 2
Training loss: 2.860669286083811
Validation loss: 2.7296278475518085

Epoch: 5| Step: 3
Training loss: 2.2865945577049036
Validation loss: 2.731924710392224

Epoch: 5| Step: 4
Training loss: 2.2132696246357897
Validation loss: 2.73647348817794

Epoch: 5| Step: 5
Training loss: 3.541608219038442
Validation loss: 2.7454620714470264

Epoch: 5| Step: 6
Training loss: 2.9328282318750114
Validation loss: 2.7288451924032824

Epoch: 5| Step: 7
Training loss: 3.3081909078565443
Validation loss: 2.722382091633959

Epoch: 5| Step: 8
Training loss: 3.379720142222739
Validation loss: 2.7157984671629123

Epoch: 5| Step: 9
Training loss: 3.4073392193954324
Validation loss: 2.718207286640735

Epoch: 5| Step: 10
Training loss: 2.2532795211566334
Validation loss: 2.7104624031998235

Epoch: 485| Step: 0
Training loss: 2.945082435425643
Validation loss: 2.715234446983458

Epoch: 5| Step: 1
Training loss: 2.8713531584553107
Validation loss: 2.7114220801056845

Epoch: 5| Step: 2
Training loss: 3.0237144323672265
Validation loss: 2.712605150835836

Epoch: 5| Step: 3
Training loss: 3.27474184838805
Validation loss: 2.7137579560188847

Epoch: 5| Step: 4
Training loss: 2.634713231068429
Validation loss: 2.7147340270915348

Epoch: 5| Step: 5
Training loss: 2.8169479801465207
Validation loss: 2.7156455901961345

Epoch: 5| Step: 6
Training loss: 2.691218620149242
Validation loss: 2.713811053289118

Epoch: 5| Step: 7
Training loss: 3.0367110306995246
Validation loss: 2.7221477579420235

Epoch: 5| Step: 8
Training loss: 3.332246762245718
Validation loss: 2.7148330075646134

Epoch: 5| Step: 9
Training loss: 3.383762851630087
Validation loss: 2.716815120894394

Epoch: 5| Step: 10
Training loss: 3.2286736552937176
Validation loss: 2.715453728970355

Epoch: 486| Step: 0
Training loss: 3.1910431560776793
Validation loss: 2.717761824667651

Epoch: 5| Step: 1
Training loss: 2.6384082947727285
Validation loss: 2.720324471403242

Epoch: 5| Step: 2
Training loss: 3.681470434975491
Validation loss: 2.7272043776904633

Epoch: 5| Step: 3
Training loss: 2.8080957472581027
Validation loss: 2.7136877292755464

Epoch: 5| Step: 4
Training loss: 3.13791110320445
Validation loss: 2.724650214404443

Epoch: 5| Step: 5
Training loss: 2.909355555222514
Validation loss: 2.7137356633011183

Epoch: 5| Step: 6
Training loss: 3.169841998040518
Validation loss: 2.7167531328566548

Epoch: 5| Step: 7
Training loss: 3.248714045890363
Validation loss: 2.722338211340374

Epoch: 5| Step: 8
Training loss: 2.688594861239019
Validation loss: 2.7298795577930854

Epoch: 5| Step: 9
Training loss: 2.970182213893287
Validation loss: 2.7239818028867706

Epoch: 5| Step: 10
Training loss: 2.624470066893323
Validation loss: 2.722983389555697

Epoch: 487| Step: 0
Training loss: 3.214218653630261
Validation loss: 2.7277415604246267

Epoch: 5| Step: 1
Training loss: 2.943747673924655
Validation loss: 2.720527960538046

Epoch: 5| Step: 2
Training loss: 2.754759224895344
Validation loss: 2.7171650926116957

Epoch: 5| Step: 3
Training loss: 2.811907048768776
Validation loss: 2.7169615893914347

Epoch: 5| Step: 4
Training loss: 3.1713244331475012
Validation loss: 2.718777837576598

Epoch: 5| Step: 5
Training loss: 3.3164482338700014
Validation loss: 2.716640843819103

Epoch: 5| Step: 6
Training loss: 2.6939831980157942
Validation loss: 2.723014836294802

Epoch: 5| Step: 7
Training loss: 2.540425565617572
Validation loss: 2.720185440861175

Epoch: 5| Step: 8
Training loss: 3.1637259598703733
Validation loss: 2.7248303336769677

Epoch: 5| Step: 9
Training loss: 3.25901600222128
Validation loss: 2.7198107626357837

Epoch: 5| Step: 10
Training loss: 3.3463049423614923
Validation loss: 2.726205681342173

Epoch: 488| Step: 0
Training loss: 2.7284147862428423
Validation loss: 2.723028489949791

Epoch: 5| Step: 1
Training loss: 3.1597421796864764
Validation loss: 2.7228021086384064

Epoch: 5| Step: 2
Training loss: 3.2771310293934657
Validation loss: 2.7147096837032167

Epoch: 5| Step: 3
Training loss: 2.800451368326814
Validation loss: 2.7157089090724877

Epoch: 5| Step: 4
Training loss: 3.1120981531526213
Validation loss: 2.722950513737173

Epoch: 5| Step: 5
Training loss: 2.672789121713112
Validation loss: 2.717744862353533

Epoch: 5| Step: 6
Training loss: 3.030593329020461
Validation loss: 2.7122275652547865

Epoch: 5| Step: 7
Training loss: 3.404431058654277
Validation loss: 2.7099510952306014

Epoch: 5| Step: 8
Training loss: 3.0404731987034013
Validation loss: 2.710995103669055

Epoch: 5| Step: 9
Training loss: 3.094484030217161
Validation loss: 2.711268247210329

Epoch: 5| Step: 10
Training loss: 2.876759529721889
Validation loss: 2.708740794071646

Epoch: 489| Step: 0
Training loss: 2.831318943287415
Validation loss: 2.7175112419749836

Epoch: 5| Step: 1
Training loss: 2.9347097252658267
Validation loss: 2.7106828562000125

Epoch: 5| Step: 2
Training loss: 2.9928658217035378
Validation loss: 2.7129566020974147

Epoch: 5| Step: 3
Training loss: 3.247705236326565
Validation loss: 2.7100710050119208

Epoch: 5| Step: 4
Training loss: 3.355348951268382
Validation loss: 2.7189915075592315

Epoch: 5| Step: 5
Training loss: 3.4263472921314304
Validation loss: 2.72398155630881

Epoch: 5| Step: 6
Training loss: 2.395405197589424
Validation loss: 2.7304877176180082

Epoch: 5| Step: 7
Training loss: 2.745123527679667
Validation loss: 2.7312476312278777

Epoch: 5| Step: 8
Training loss: 3.627021620457495
Validation loss: 2.746031049592182

Epoch: 5| Step: 9
Training loss: 2.2336289020452798
Validation loss: 2.7515006739154417

Epoch: 5| Step: 10
Training loss: 3.213135795167019
Validation loss: 2.7673985517538977

Epoch: 490| Step: 0
Training loss: 3.116597437642191
Validation loss: 2.764988822295065

Epoch: 5| Step: 1
Training loss: 3.0098380266376856
Validation loss: 2.7546198020338384

Epoch: 5| Step: 2
Training loss: 3.211411786842798
Validation loss: 2.739319374571773

Epoch: 5| Step: 3
Training loss: 2.7443720709781396
Validation loss: 2.723661882150836

Epoch: 5| Step: 4
Training loss: 3.069148884194452
Validation loss: 2.7261475696500583

Epoch: 5| Step: 5
Training loss: 2.632062312707443
Validation loss: 2.7092115986507603

Epoch: 5| Step: 6
Training loss: 3.725672201655295
Validation loss: 2.7161021319885954

Epoch: 5| Step: 7
Training loss: 3.278227949389606
Validation loss: 2.713146248378026

Epoch: 5| Step: 8
Training loss: 2.9220163239761354
Validation loss: 2.714201784636629

Epoch: 5| Step: 9
Training loss: 2.6854696366733752
Validation loss: 2.713647361631935

Epoch: 5| Step: 10
Training loss: 2.6336063806801833
Validation loss: 2.719615481219455

Epoch: 491| Step: 0
Training loss: 2.9195816913562194
Validation loss: 2.7074481157962302

Epoch: 5| Step: 1
Training loss: 2.649688605240705
Validation loss: 2.709039150933162

Epoch: 5| Step: 2
Training loss: 2.217846861228164
Validation loss: 2.7101736803330594

Epoch: 5| Step: 3
Training loss: 3.0802755056742788
Validation loss: 2.711502729774959

Epoch: 5| Step: 4
Training loss: 2.6172418844920884
Validation loss: 2.7131247311243647

Epoch: 5| Step: 5
Training loss: 3.1894154496779707
Validation loss: 2.7093392964200502

Epoch: 5| Step: 6
Training loss: 3.3043857734321285
Validation loss: 2.7119136106345287

Epoch: 5| Step: 7
Training loss: 3.3314352989549483
Validation loss: 2.7070201839282455

Epoch: 5| Step: 8
Training loss: 3.4051800368517995
Validation loss: 2.7113344112886386

Epoch: 5| Step: 9
Training loss: 3.183477069612185
Validation loss: 2.7105169421310933

Epoch: 5| Step: 10
Training loss: 3.1242133104029444
Validation loss: 2.71645363005659

Epoch: 492| Step: 0
Training loss: 2.8404120672844457
Validation loss: 2.7166333547613672

Epoch: 5| Step: 1
Training loss: 3.05866172198578
Validation loss: 2.719105576688135

Epoch: 5| Step: 2
Training loss: 2.450763610640169
Validation loss: 2.722301601354489

Epoch: 5| Step: 3
Training loss: 2.8920551782939543
Validation loss: 2.717019675819584

Epoch: 5| Step: 4
Training loss: 3.1772958819889756
Validation loss: 2.706541238686531

Epoch: 5| Step: 5
Training loss: 3.3701585022641445
Validation loss: 2.7076933667096377

Epoch: 5| Step: 6
Training loss: 3.508965589466024
Validation loss: 2.7079703688061665

Epoch: 5| Step: 7
Training loss: 2.6229616152724904
Validation loss: 2.7059580874561906

Epoch: 5| Step: 8
Training loss: 3.190888641853086
Validation loss: 2.7047381481691555

Epoch: 5| Step: 9
Training loss: 3.218430142111349
Validation loss: 2.7074216777052276

Epoch: 5| Step: 10
Training loss: 2.649854073015412
Validation loss: 2.7206560468309666

Epoch: 493| Step: 0
Training loss: 2.6612269729614253
Validation loss: 2.7141241971323304

Epoch: 5| Step: 1
Training loss: 3.1813350223953525
Validation loss: 2.7192256569390474

Epoch: 5| Step: 2
Training loss: 2.923367858416063
Validation loss: 2.717875750153216

Epoch: 5| Step: 3
Training loss: 2.895939411077489
Validation loss: 2.7082903180993614

Epoch: 5| Step: 4
Training loss: 2.670691869582835
Validation loss: 2.7142318733661703

Epoch: 5| Step: 5
Training loss: 2.688987675035291
Validation loss: 2.7174977771057764

Epoch: 5| Step: 6
Training loss: 3.4706423984382075
Validation loss: 2.7102958825629058

Epoch: 5| Step: 7
Training loss: 3.053089396992468
Validation loss: 2.7053320274845167

Epoch: 5| Step: 8
Training loss: 2.9382946481680703
Validation loss: 2.714792433146216

Epoch: 5| Step: 9
Training loss: 3.69022113809385
Validation loss: 2.7236980625330354

Epoch: 5| Step: 10
Training loss: 2.8285201834568294
Validation loss: 2.715805229777616

Epoch: 494| Step: 0
Training loss: 3.0632700049406263
Validation loss: 2.7222297812194993

Epoch: 5| Step: 1
Training loss: 3.4914478995194234
Validation loss: 2.722194317775192

Epoch: 5| Step: 2
Training loss: 2.9985084004490425
Validation loss: 2.722365407656917

Epoch: 5| Step: 3
Training loss: 2.7574733277013976
Validation loss: 2.7244438959436192

Epoch: 5| Step: 4
Training loss: 3.218706593637465
Validation loss: 2.7364968163569405

Epoch: 5| Step: 5
Training loss: 3.49120451813221
Validation loss: 2.7443258976852913

Epoch: 5| Step: 6
Training loss: 3.162904579308016
Validation loss: 2.728061194440107

Epoch: 5| Step: 7
Training loss: 2.704950939727785
Validation loss: 2.7196631684311106

Epoch: 5| Step: 8
Training loss: 2.586408773852073
Validation loss: 2.7300463300449778

Epoch: 5| Step: 9
Training loss: 2.9595269137004787
Validation loss: 2.7195933072154723

Epoch: 5| Step: 10
Training loss: 2.5474575757208706
Validation loss: 2.7150826061738838

Epoch: 495| Step: 0
Training loss: 2.3237715603473066
Validation loss: 2.7110874273698076

Epoch: 5| Step: 1
Training loss: 3.713732114868855
Validation loss: 2.7102253807119414

Epoch: 5| Step: 2
Training loss: 2.8486845360298196
Validation loss: 2.7104502842341227

Epoch: 5| Step: 3
Training loss: 2.855645587836074
Validation loss: 2.7037374435831936

Epoch: 5| Step: 4
Training loss: 3.5663898045640137
Validation loss: 2.706941971980771

Epoch: 5| Step: 5
Training loss: 2.8867620276483583
Validation loss: 2.7079403695508675

Epoch: 5| Step: 6
Training loss: 3.175788757390419
Validation loss: 2.70410742906628

Epoch: 5| Step: 7
Training loss: 2.8923595276322343
Validation loss: 2.703659965408714

Epoch: 5| Step: 8
Training loss: 2.7922794371733697
Validation loss: 2.70629260953651

Epoch: 5| Step: 9
Training loss: 2.4596485455985353
Validation loss: 2.7052872395068834

Epoch: 5| Step: 10
Training loss: 3.47037158900301
Validation loss: 2.7043420262994347

Epoch: 496| Step: 0
Training loss: 2.745641722720475
Validation loss: 2.7102051475319726

Epoch: 5| Step: 1
Training loss: 3.3944716892789675
Validation loss: 2.7051918843111156

Epoch: 5| Step: 2
Training loss: 3.061359115157516
Validation loss: 2.7025878911324943

Epoch: 5| Step: 3
Training loss: 2.801382343480231
Validation loss: 2.6979713359967774

Epoch: 5| Step: 4
Training loss: 2.8545985950809416
Validation loss: 2.7048130572337534

Epoch: 5| Step: 5
Training loss: 3.18589009038758
Validation loss: 2.7038408761548434

Epoch: 5| Step: 6
Training loss: 3.3117886625210002
Validation loss: 2.704028250205389

Epoch: 5| Step: 7
Training loss: 2.8913616169760004
Validation loss: 2.7029826833160806

Epoch: 5| Step: 8
Training loss: 2.7617444761553713
Validation loss: 2.710528327797301

Epoch: 5| Step: 9
Training loss: 2.790362741550129
Validation loss: 2.708752112435653

Epoch: 5| Step: 10
Training loss: 3.3647666070268802
Validation loss: 2.7195323195238554

Epoch: 497| Step: 0
Training loss: 2.564579747742647
Validation loss: 2.7267830174186636

Epoch: 5| Step: 1
Training loss: 3.450158964171326
Validation loss: 2.738750705702522

Epoch: 5| Step: 2
Training loss: 2.9813477506146806
Validation loss: 2.7500416854130254

Epoch: 5| Step: 3
Training loss: 2.711485705614265
Validation loss: 2.7490922421526296

Epoch: 5| Step: 4
Training loss: 2.766964517975934
Validation loss: 2.750545374915941

Epoch: 5| Step: 5
Training loss: 3.297067067124536
Validation loss: 2.7542064029867213

Epoch: 5| Step: 6
Training loss: 3.4221908911252004
Validation loss: 2.748347726667784

Epoch: 5| Step: 7
Training loss: 2.2986366626539683
Validation loss: 2.7267891031347657

Epoch: 5| Step: 8
Training loss: 2.815622419044929
Validation loss: 2.71631319899769

Epoch: 5| Step: 9
Training loss: 3.571674379336571
Validation loss: 2.7045707073023086

Epoch: 5| Step: 10
Training loss: 3.030373672760113
Validation loss: 2.7037540244262916

Epoch: 498| Step: 0
Training loss: 3.228206631273658
Validation loss: 2.695677124489386

Epoch: 5| Step: 1
Training loss: 2.6514274351465206
Validation loss: 2.701445073219742

Epoch: 5| Step: 2
Training loss: 3.1289355101628114
Validation loss: 2.6984396673968183

Epoch: 5| Step: 3
Training loss: 2.934807050299108
Validation loss: 2.699422128274401

Epoch: 5| Step: 4
Training loss: 2.587541434283382
Validation loss: 2.7010434157171908

Epoch: 5| Step: 5
Training loss: 3.412968021478843
Validation loss: 2.702136933034853

Epoch: 5| Step: 6
Training loss: 2.994142058310567
Validation loss: 2.69702938755208

Epoch: 5| Step: 7
Training loss: 2.9453422888911347
Validation loss: 2.7005226582295245

Epoch: 5| Step: 8
Training loss: 2.924048283607534
Validation loss: 2.701454421690475

Epoch: 5| Step: 9
Training loss: 2.972049205018447
Validation loss: 2.704451908246449

Epoch: 5| Step: 10
Training loss: 3.3882209939592562
Validation loss: 2.7062066047684943

Epoch: 499| Step: 0
Training loss: 2.96170444671228
Validation loss: 2.7096445233730693

Epoch: 5| Step: 1
Training loss: 2.8484148603199815
Validation loss: 2.710239506957584

Epoch: 5| Step: 2
Training loss: 3.0233840346229566
Validation loss: 2.7087514688640866

Epoch: 5| Step: 3
Training loss: 2.6418576946643855
Validation loss: 2.709496244812337

Epoch: 5| Step: 4
Training loss: 2.965793462536924
Validation loss: 2.7008948381831734

Epoch: 5| Step: 5
Training loss: 3.0803360332136895
Validation loss: 2.70936724582698

Epoch: 5| Step: 6
Training loss: 3.6900870090140474
Validation loss: 2.7097488667111724

Epoch: 5| Step: 7
Training loss: 2.904128418008772
Validation loss: 2.7058277065795995

Epoch: 5| Step: 8
Training loss: 3.08014376515345
Validation loss: 2.7200125145126632

Epoch: 5| Step: 9
Training loss: 2.9334333149892413
Validation loss: 2.742561407627895

Epoch: 5| Step: 10
Training loss: 2.977526891476437
Validation loss: 2.7487613306551273

Epoch: 500| Step: 0
Training loss: 3.1431440432994333
Validation loss: 2.7500464043006816

Epoch: 5| Step: 1
Training loss: 2.9895701302869293
Validation loss: 2.7407837275567513

Epoch: 5| Step: 2
Training loss: 3.2503126434188236
Validation loss: 2.742244934297652

Epoch: 5| Step: 3
Training loss: 3.085969021793122
Validation loss: 2.7149979393027617

Epoch: 5| Step: 4
Training loss: 2.8956548695265956
Validation loss: 2.715420586386202

Epoch: 5| Step: 5
Training loss: 2.9635764568590792
Validation loss: 2.704690904905979

Epoch: 5| Step: 6
Training loss: 3.1393305449971263
Validation loss: 2.7029703231032847

Epoch: 5| Step: 7
Training loss: 3.1723461083136275
Validation loss: 2.7021960316520213

Epoch: 5| Step: 8
Training loss: 2.85634197863305
Validation loss: 2.7096533165698156

Epoch: 5| Step: 9
Training loss: 2.660134201966725
Validation loss: 2.7073628001592325

Epoch: 5| Step: 10
Training loss: 2.9700889378855635
Validation loss: 2.7038405461994075

Epoch: 501| Step: 0
Training loss: 3.6365249532983976
Validation loss: 2.7163607997847503

Epoch: 5| Step: 1
Training loss: 2.462962646399371
Validation loss: 2.7235724188473034

Epoch: 5| Step: 2
Training loss: 3.5233701035509566
Validation loss: 2.733482820483413

Epoch: 5| Step: 3
Training loss: 3.157194392863096
Validation loss: 2.721114438702367

Epoch: 5| Step: 4
Training loss: 3.224983771231575
Validation loss: 2.704212221164237

Epoch: 5| Step: 5
Training loss: 2.8062919766487457
Validation loss: 2.6967493042621844

Epoch: 5| Step: 6
Training loss: 2.5800361716521905
Validation loss: 2.6945048259445987

Epoch: 5| Step: 7
Training loss: 2.7467651414656125
Validation loss: 2.6908458554521513

Epoch: 5| Step: 8
Training loss: 2.9822779772505696
Validation loss: 2.6917047681987807

Epoch: 5| Step: 9
Training loss: 3.3916215267192436
Validation loss: 2.6940232208329427

Epoch: 5| Step: 10
Training loss: 2.3284492010924076
Validation loss: 2.6933768873265502

Epoch: 502| Step: 0
Training loss: 3.535068843878013
Validation loss: 2.693446032705394

Epoch: 5| Step: 1
Training loss: 2.813223682122831
Validation loss: 2.694818519860492

Epoch: 5| Step: 2
Training loss: 2.889574674571806
Validation loss: 2.6993827211435653

Epoch: 5| Step: 3
Training loss: 2.8778576125072988
Validation loss: 2.7008817470339612

Epoch: 5| Step: 4
Training loss: 2.908186728672718
Validation loss: 2.6959383862778146

Epoch: 5| Step: 5
Training loss: 3.2403100150340975
Validation loss: 2.707639925074845

Epoch: 5| Step: 6
Training loss: 3.1488647171088235
Validation loss: 2.702396311439093

Epoch: 5| Step: 7
Training loss: 2.1842629596316576
Validation loss: 2.7147916163067936

Epoch: 5| Step: 8
Training loss: 2.758819569106772
Validation loss: 2.7089778451942665

Epoch: 5| Step: 9
Training loss: 3.629484362589437
Validation loss: 2.718837377841172

Epoch: 5| Step: 10
Training loss: 2.9311449825125164
Validation loss: 2.716001873472047

Epoch: 503| Step: 0
Training loss: 3.0100785079805714
Validation loss: 2.704741603018992

Epoch: 5| Step: 1
Training loss: 3.4459103435381375
Validation loss: 2.7015170483029007

Epoch: 5| Step: 2
Training loss: 2.8789065812627013
Validation loss: 2.7046138151860704

Epoch: 5| Step: 3
Training loss: 3.1011907321074563
Validation loss: 2.700054903660941

Epoch: 5| Step: 4
Training loss: 3.1664332420917285
Validation loss: 2.701498146785013

Epoch: 5| Step: 5
Training loss: 3.0845270337759607
Validation loss: 2.6970529057682113

Epoch: 5| Step: 6
Training loss: 2.609706377927947
Validation loss: 2.6978944490954113

Epoch: 5| Step: 7
Training loss: 3.1972765121321207
Validation loss: 2.6956060396238843

Epoch: 5| Step: 8
Training loss: 2.3406372762645873
Validation loss: 2.6976918275582307

Epoch: 5| Step: 9
Training loss: 3.2002347979235557
Validation loss: 2.693205706911242

Epoch: 5| Step: 10
Training loss: 2.921755048768196
Validation loss: 2.6892243529440454

Epoch: 504| Step: 0
Training loss: 3.2914311449479836
Validation loss: 2.6894483036086783

Epoch: 5| Step: 1
Training loss: 3.0641216733394123
Validation loss: 2.693617232586651

Epoch: 5| Step: 2
Training loss: 2.613893263332676
Validation loss: 2.694040389599939

Epoch: 5| Step: 3
Training loss: 2.6373128490128197
Validation loss: 2.695505513322816

Epoch: 5| Step: 4
Training loss: 3.4570789743351305
Validation loss: 2.690811003531806

Epoch: 5| Step: 5
Training loss: 3.1457589921735614
Validation loss: 2.6923338584322534

Epoch: 5| Step: 6
Training loss: 3.380481789239571
Validation loss: 2.6951108957264784

Epoch: 5| Step: 7
Training loss: 3.0255621017414502
Validation loss: 2.6982630623980293

Epoch: 5| Step: 8
Training loss: 2.3961382353999845
Validation loss: 2.697702169750497

Epoch: 5| Step: 9
Training loss: 2.907088292133013
Validation loss: 2.6970403596400363

Epoch: 5| Step: 10
Training loss: 2.993039958428391
Validation loss: 2.701276465894634

Epoch: 505| Step: 0
Training loss: 3.125462917373357
Validation loss: 2.701516864204007

Epoch: 5| Step: 1
Training loss: 2.790595736462301
Validation loss: 2.7073045983911745

Epoch: 5| Step: 2
Training loss: 2.9052985489986183
Validation loss: 2.7089515384348606

Epoch: 5| Step: 3
Training loss: 3.5577325878123323
Validation loss: 2.7093094580424535

Epoch: 5| Step: 4
Training loss: 3.0127257013256656
Validation loss: 2.72560401357006

Epoch: 5| Step: 5
Training loss: 3.1701554772308715
Validation loss: 2.726279426000603

Epoch: 5| Step: 6
Training loss: 3.106258037717924
Validation loss: 2.7293704831247894

Epoch: 5| Step: 7
Training loss: 2.7844526731743797
Validation loss: 2.736163627327763

Epoch: 5| Step: 8
Training loss: 2.9164757439023057
Validation loss: 2.757179398369415

Epoch: 5| Step: 9
Training loss: 2.865179455314663
Validation loss: 2.772056368574212

Epoch: 5| Step: 10
Training loss: 2.7170474103512503
Validation loss: 2.7734754260236016

Epoch: 506| Step: 0
Training loss: 3.0394795188056882
Validation loss: 2.7544181530070784

Epoch: 5| Step: 1
Training loss: 2.4931145262289003
Validation loss: 2.73447275388401

Epoch: 5| Step: 2
Training loss: 3.2212807789088154
Validation loss: 2.7192776207744385

Epoch: 5| Step: 3
Training loss: 3.179072290088785
Validation loss: 2.7022017780725758

Epoch: 5| Step: 4
Training loss: 2.9978526695548156
Validation loss: 2.7010402831126665

Epoch: 5| Step: 5
Training loss: 3.043373169180409
Validation loss: 2.7125901145023894

Epoch: 5| Step: 6
Training loss: 3.3659110426772716
Validation loss: 2.705501008407393

Epoch: 5| Step: 7
Training loss: 3.3275701928992985
Validation loss: 2.7024407213896544

Epoch: 5| Step: 8
Training loss: 2.60480908417301
Validation loss: 2.7067670118598732

Epoch: 5| Step: 9
Training loss: 2.912580261434331
Validation loss: 2.6954716917646198

Epoch: 5| Step: 10
Training loss: 2.7938205513803904
Validation loss: 2.6928261780121634

Epoch: 507| Step: 0
Training loss: 2.743129992112202
Validation loss: 2.6914336674351027

Epoch: 5| Step: 1
Training loss: 3.5591311671842285
Validation loss: 2.6906502907146916

Epoch: 5| Step: 2
Training loss: 3.3945047006567486
Validation loss: 2.690797426013793

Epoch: 5| Step: 3
Training loss: 2.8558157359073526
Validation loss: 2.6915022421857633

Epoch: 5| Step: 4
Training loss: 2.7520434850040565
Validation loss: 2.7027055447040227

Epoch: 5| Step: 5
Training loss: 3.2586105430387984
Validation loss: 2.6978277781791293

Epoch: 5| Step: 6
Training loss: 2.620782006453017
Validation loss: 2.688962338708358

Epoch: 5| Step: 7
Training loss: 3.0456261838788934
Validation loss: 2.694342061299245

Epoch: 5| Step: 8
Training loss: 2.932232943681443
Validation loss: 2.691275899059926

Epoch: 5| Step: 9
Training loss: 2.9864191374497935
Validation loss: 2.6925023744887078

Epoch: 5| Step: 10
Training loss: 2.856071690308754
Validation loss: 2.6848859615631215

Epoch: 508| Step: 0
Training loss: 2.6211966254203425
Validation loss: 2.6914711068708885

Epoch: 5| Step: 1
Training loss: 2.9499210153124493
Validation loss: 2.686643999762849

Epoch: 5| Step: 2
Training loss: 2.9904595308357553
Validation loss: 2.6878892273771267

Epoch: 5| Step: 3
Training loss: 3.3362775356832923
Validation loss: 2.683342382211573

Epoch: 5| Step: 4
Training loss: 3.2974826921611795
Validation loss: 2.685336710144643

Epoch: 5| Step: 5
Training loss: 2.731469752639139
Validation loss: 2.689003315271469

Epoch: 5| Step: 6
Training loss: 2.9371425329995944
Validation loss: 2.686319779342402

Epoch: 5| Step: 7
Training loss: 3.5832943285807906
Validation loss: 2.687071620857559

Epoch: 5| Step: 8
Training loss: 2.8063909516481185
Validation loss: 2.6887954123472677

Epoch: 5| Step: 9
Training loss: 2.8264295016366794
Validation loss: 2.6890429994003173

Epoch: 5| Step: 10
Training loss: 2.8490079123433
Validation loss: 2.7031462819863674

Epoch: 509| Step: 0
Training loss: 2.501793122963736
Validation loss: 2.6924171689409926

Epoch: 5| Step: 1
Training loss: 3.3908466319412995
Validation loss: 2.6929485934017365

Epoch: 5| Step: 2
Training loss: 2.951809383182382
Validation loss: 2.688077846866123

Epoch: 5| Step: 3
Training loss: 3.164480525530211
Validation loss: 2.683646873780256

Epoch: 5| Step: 4
Training loss: 3.2661926652246325
Validation loss: 2.683633805485159

Epoch: 5| Step: 5
Training loss: 2.8229204203638174
Validation loss: 2.6896559721086164

Epoch: 5| Step: 6
Training loss: 2.9213166544879337
Validation loss: 2.6810569214258244

Epoch: 5| Step: 7
Training loss: 3.32901447570532
Validation loss: 2.683689589848248

Epoch: 5| Step: 8
Training loss: 2.8019641628710077
Validation loss: 2.6800675407424612

Epoch: 5| Step: 9
Training loss: 2.8054621484732447
Validation loss: 2.688391666105878

Epoch: 5| Step: 10
Training loss: 3.0256252998173814
Validation loss: 2.682742516037374

Epoch: 510| Step: 0
Training loss: 2.687342439512879
Validation loss: 2.6907376749740624

Epoch: 5| Step: 1
Training loss: 3.2219756916343907
Validation loss: 2.684515709596022

Epoch: 5| Step: 2
Training loss: 2.50405573882201
Validation loss: 2.6844076216400183

Epoch: 5| Step: 3
Training loss: 2.971530936909254
Validation loss: 2.685195931065142

Epoch: 5| Step: 4
Training loss: 2.6060511268466175
Validation loss: 2.682264175218403

Epoch: 5| Step: 5
Training loss: 3.3494048031098322
Validation loss: 2.6841505220936157

Epoch: 5| Step: 6
Training loss: 3.115149422088134
Validation loss: 2.6829880894028397

Epoch: 5| Step: 7
Training loss: 3.3564159046845976
Validation loss: 2.6839147674485555

Epoch: 5| Step: 8
Training loss: 2.9228386743263295
Validation loss: 2.6807368107043423

Epoch: 5| Step: 9
Training loss: 3.1111357797674026
Validation loss: 2.688436484763454

Epoch: 5| Step: 10
Training loss: 3.0916862925877364
Validation loss: 2.684195998945149

Epoch: 511| Step: 0
Training loss: 2.6456602044920765
Validation loss: 2.682385518604197

Epoch: 5| Step: 1
Training loss: 3.47344158548174
Validation loss: 2.688618433210849

Epoch: 5| Step: 2
Training loss: 3.1222170836141285
Validation loss: 2.680737030657797

Epoch: 5| Step: 3
Training loss: 2.6087672273864895
Validation loss: 2.678101286502722

Epoch: 5| Step: 4
Training loss: 2.5280948330620103
Validation loss: 2.684714102728313

Epoch: 5| Step: 5
Training loss: 3.0362207615317347
Validation loss: 2.691322673868807

Epoch: 5| Step: 6
Training loss: 3.1335331190278546
Validation loss: 2.6898414311895453

Epoch: 5| Step: 7
Training loss: 2.995129127839339
Validation loss: 2.695461181230235

Epoch: 5| Step: 8
Training loss: 3.3021868540103583
Validation loss: 2.720841356466111

Epoch: 5| Step: 9
Training loss: 2.8547369023032703
Validation loss: 2.7090522802613135

Epoch: 5| Step: 10
Training loss: 3.210838891810076
Validation loss: 2.711277287602137

Epoch: 512| Step: 0
Training loss: 3.913478053881285
Validation loss: 2.7074706723846513

Epoch: 5| Step: 1
Training loss: 2.5708829020745383
Validation loss: 2.709295849271366

Epoch: 5| Step: 2
Training loss: 2.6944058427525324
Validation loss: 2.706858479641826

Epoch: 5| Step: 3
Training loss: 2.9208130564146795
Validation loss: 2.709520919834431

Epoch: 5| Step: 4
Training loss: 2.737454146606469
Validation loss: 2.694453236854122

Epoch: 5| Step: 5
Training loss: 2.8890894754985563
Validation loss: 2.6891059798898183

Epoch: 5| Step: 6
Training loss: 3.31946019621605
Validation loss: 2.691554106907524

Epoch: 5| Step: 7
Training loss: 3.4023485150834887
Validation loss: 2.6858332206977

Epoch: 5| Step: 8
Training loss: 2.7656443104904938
Validation loss: 2.682569212531771

Epoch: 5| Step: 9
Training loss: 2.937390426864707
Validation loss: 2.6839043816796404

Epoch: 5| Step: 10
Training loss: 2.48403438896295
Validation loss: 2.687265908190261

Epoch: 513| Step: 0
Training loss: 3.255174771962407
Validation loss: 2.680994991122983

Epoch: 5| Step: 1
Training loss: 3.008222438075096
Validation loss: 2.6904402053032173

Epoch: 5| Step: 2
Training loss: 3.0482558031548606
Validation loss: 2.6814991394341283

Epoch: 5| Step: 3
Training loss: 3.0537793304621266
Validation loss: 2.691653863583124

Epoch: 5| Step: 4
Training loss: 2.359909805417014
Validation loss: 2.6834791515181102

Epoch: 5| Step: 5
Training loss: 2.2424595897014714
Validation loss: 2.6767271454583277

Epoch: 5| Step: 6
Training loss: 3.3907640841739384
Validation loss: 2.686862336670175

Epoch: 5| Step: 7
Training loss: 3.1621828123710656
Validation loss: 2.689034987305307

Epoch: 5| Step: 8
Training loss: 3.129687646264974
Validation loss: 2.6840478923872237

Epoch: 5| Step: 9
Training loss: 3.255484867811297
Validation loss: 2.6908752221390566

Epoch: 5| Step: 10
Training loss: 2.850976000526594
Validation loss: 2.687613274757165

Epoch: 514| Step: 0
Training loss: 2.8530291404372443
Validation loss: 2.689047348649892

Epoch: 5| Step: 1
Training loss: 3.3138433647457353
Validation loss: 2.69812558495572

Epoch: 5| Step: 2
Training loss: 2.940954409238477
Validation loss: 2.695991596775537

Epoch: 5| Step: 3
Training loss: 2.8341812286257095
Validation loss: 2.6874162814013562

Epoch: 5| Step: 4
Training loss: 3.099426610278101
Validation loss: 2.6927940307570717

Epoch: 5| Step: 5
Training loss: 2.945294367483972
Validation loss: 2.7003974988833717

Epoch: 5| Step: 6
Training loss: 2.6190989332415326
Validation loss: 2.7089528027701735

Epoch: 5| Step: 7
Training loss: 3.1756729914569974
Validation loss: 2.69337650231073

Epoch: 5| Step: 8
Training loss: 3.2436899403798276
Validation loss: 2.7110105951912793

Epoch: 5| Step: 9
Training loss: 2.9100472858690205
Validation loss: 2.711074368417121

Epoch: 5| Step: 10
Training loss: 2.9188165824533057
Validation loss: 2.7003059632007007

Epoch: 515| Step: 0
Training loss: 2.900344098164276
Validation loss: 2.699515869613882

Epoch: 5| Step: 1
Training loss: 2.853461148200899
Validation loss: 2.7001547782724735

Epoch: 5| Step: 2
Training loss: 2.9457500749950762
Validation loss: 2.6861907076249656

Epoch: 5| Step: 3
Training loss: 3.2943397645435617
Validation loss: 2.6803742416734138

Epoch: 5| Step: 4
Training loss: 2.655653493885025
Validation loss: 2.6733843158838684

Epoch: 5| Step: 5
Training loss: 2.8748905326901006
Validation loss: 2.6833992894613705

Epoch: 5| Step: 6
Training loss: 3.097603603844083
Validation loss: 2.6748851416034642

Epoch: 5| Step: 7
Training loss: 3.3611876809161925
Validation loss: 2.6743961191969388

Epoch: 5| Step: 8
Training loss: 3.1038172139000464
Validation loss: 2.67109646189162

Epoch: 5| Step: 9
Training loss: 2.9712415980893088
Validation loss: 2.6712910301180743

Epoch: 5| Step: 10
Training loss: 2.8783664067821344
Validation loss: 2.6735282503337485

Epoch: 516| Step: 0
Training loss: 2.6520319040430596
Validation loss: 2.6701475790186526

Epoch: 5| Step: 1
Training loss: 3.1518272912784817
Validation loss: 2.6764047965463473

Epoch: 5| Step: 2
Training loss: 2.744441570464091
Validation loss: 2.6748016751204076

Epoch: 5| Step: 3
Training loss: 3.2172400627270292
Validation loss: 2.676576955204184

Epoch: 5| Step: 4
Training loss: 3.1706006727106866
Validation loss: 2.681286356877128

Epoch: 5| Step: 5
Training loss: 2.9748477351868594
Validation loss: 2.6865449158880006

Epoch: 5| Step: 6
Training loss: 2.679597547261399
Validation loss: 2.680523697929459

Epoch: 5| Step: 7
Training loss: 2.795858955171146
Validation loss: 2.682109378236058

Epoch: 5| Step: 8
Training loss: 3.219452420227452
Validation loss: 2.6829865151881784

Epoch: 5| Step: 9
Training loss: 3.2222570183581567
Validation loss: 2.698186937741504

Epoch: 5| Step: 10
Training loss: 3.1358816281574518
Validation loss: 2.6844305895726914

Epoch: 517| Step: 0
Training loss: 2.9985112628938335
Validation loss: 2.682120307174133

Epoch: 5| Step: 1
Training loss: 3.065232128668971
Validation loss: 2.683659827378384

Epoch: 5| Step: 2
Training loss: 2.962119638997943
Validation loss: 2.6841405202347284

Epoch: 5| Step: 3
Training loss: 2.9787840875427265
Validation loss: 2.6779096839552192

Epoch: 5| Step: 4
Training loss: 2.7232799280907467
Validation loss: 2.6968764618653243

Epoch: 5| Step: 5
Training loss: 3.6310038340345274
Validation loss: 2.685025108924107

Epoch: 5| Step: 6
Training loss: 2.9944431975705537
Validation loss: 2.6857971325386965

Epoch: 5| Step: 7
Training loss: 3.0443746626839463
Validation loss: 2.6851383047742328

Epoch: 5| Step: 8
Training loss: 2.8839537473083316
Validation loss: 2.6974933757976447

Epoch: 5| Step: 9
Training loss: 2.7761166808756763
Validation loss: 2.69565383773328

Epoch: 5| Step: 10
Training loss: 2.766234594716763
Validation loss: 2.6977835241594437

Epoch: 518| Step: 0
Training loss: 2.9739628049657623
Validation loss: 2.700173936047298

Epoch: 5| Step: 1
Training loss: 2.9551842992533834
Validation loss: 2.6975584636082646

Epoch: 5| Step: 2
Training loss: 2.992064789728427
Validation loss: 2.6928380011975657

Epoch: 5| Step: 3
Training loss: 3.0899807867051585
Validation loss: 2.688338120180736

Epoch: 5| Step: 4
Training loss: 3.2005107352850426
Validation loss: 2.691056927580451

Epoch: 5| Step: 5
Training loss: 3.4991712951508416
Validation loss: 2.6804318077935627

Epoch: 5| Step: 6
Training loss: 2.505089918947853
Validation loss: 2.681616837774891

Epoch: 5| Step: 7
Training loss: 2.447924209474887
Validation loss: 2.681252095888344

Epoch: 5| Step: 8
Training loss: 3.261588928928444
Validation loss: 2.6745499756104563

Epoch: 5| Step: 9
Training loss: 3.25629900348129
Validation loss: 2.683680969503206

Epoch: 5| Step: 10
Training loss: 2.4827479186640384
Validation loss: 2.6776930766336413

Epoch: 519| Step: 0
Training loss: 2.48225456292237
Validation loss: 2.684801402329642

Epoch: 5| Step: 1
Training loss: 2.899107164205618
Validation loss: 2.6802407927066616

Epoch: 5| Step: 2
Training loss: 2.892304463548622
Validation loss: 2.695428526124174

Epoch: 5| Step: 3
Training loss: 2.9832406809252165
Validation loss: 2.7086337589459513

Epoch: 5| Step: 4
Training loss: 2.5397134269291235
Validation loss: 2.718473777557933

Epoch: 5| Step: 5
Training loss: 3.467324178648265
Validation loss: 2.713255765266289

Epoch: 5| Step: 6
Training loss: 2.8789569327501034
Validation loss: 2.724634378904881

Epoch: 5| Step: 7
Training loss: 3.4967708677821627
Validation loss: 2.7225001459541547

Epoch: 5| Step: 8
Training loss: 2.6945448514794705
Validation loss: 2.706651981356758

Epoch: 5| Step: 9
Training loss: 2.622513638034557
Validation loss: 2.705911281884403

Epoch: 5| Step: 10
Training loss: 3.813842161972358
Validation loss: 2.7069422523109727

Epoch: 520| Step: 0
Training loss: 3.367380229629686
Validation loss: 2.690160785392079

Epoch: 5| Step: 1
Training loss: 2.76323083384528
Validation loss: 2.683788524093099

Epoch: 5| Step: 2
Training loss: 2.7617581161002684
Validation loss: 2.6822261857664764

Epoch: 5| Step: 3
Training loss: 3.2658453324014682
Validation loss: 2.675580882777242

Epoch: 5| Step: 4
Training loss: 3.0147833563811988
Validation loss: 2.6755856247180834

Epoch: 5| Step: 5
Training loss: 2.992065108462924
Validation loss: 2.6728541843097324

Epoch: 5| Step: 6
Training loss: 2.826108434844291
Validation loss: 2.6731607312869627

Epoch: 5| Step: 7
Training loss: 2.9240393145066914
Validation loss: 2.6715683712252556

Epoch: 5| Step: 8
Training loss: 2.7350119584570067
Validation loss: 2.6737525233111605

Epoch: 5| Step: 9
Training loss: 2.5913807722511977
Validation loss: 2.6799584870604476

Epoch: 5| Step: 10
Training loss: 3.595844885555967
Validation loss: 2.6790762550106337

Epoch: 521| Step: 0
Training loss: 3.1182478628537362
Validation loss: 2.6846596755897547

Epoch: 5| Step: 1
Training loss: 2.6307168198374256
Validation loss: 2.69216046958496

Epoch: 5| Step: 2
Training loss: 3.6777201129071577
Validation loss: 2.689222033561377

Epoch: 5| Step: 3
Training loss: 2.5951925655352577
Validation loss: 2.7069781779013544

Epoch: 5| Step: 4
Training loss: 2.9001265794161024
Validation loss: 2.696762041871757

Epoch: 5| Step: 5
Training loss: 2.9200548020537336
Validation loss: 2.7143867226615317

Epoch: 5| Step: 6
Training loss: 3.028758647432471
Validation loss: 2.7170098336442985

Epoch: 5| Step: 7
Training loss: 3.152817928004406
Validation loss: 2.7230999463344547

Epoch: 5| Step: 8
Training loss: 3.034782003652385
Validation loss: 2.7282302747988623

Epoch: 5| Step: 9
Training loss: 2.5978198007136637
Validation loss: 2.74974846551864

Epoch: 5| Step: 10
Training loss: 3.2017389043164615
Validation loss: 2.7381144943253166

Epoch: 522| Step: 0
Training loss: 3.2508433788241815
Validation loss: 2.737485781576643

Epoch: 5| Step: 1
Training loss: 3.036086638238464
Validation loss: 2.7403011026652337

Epoch: 5| Step: 2
Training loss: 2.8604735885331647
Validation loss: 2.720816119835147

Epoch: 5| Step: 3
Training loss: 2.81273014398547
Validation loss: 2.7113269113559264

Epoch: 5| Step: 4
Training loss: 3.285671923938885
Validation loss: 2.695291534717993

Epoch: 5| Step: 5
Training loss: 2.6378204078768186
Validation loss: 2.690999378213313

Epoch: 5| Step: 6
Training loss: 3.0471674852102177
Validation loss: 2.6838612057553277

Epoch: 5| Step: 7
Training loss: 3.1127495784353285
Validation loss: 2.682343464172144

Epoch: 5| Step: 8
Training loss: 3.2728200981192535
Validation loss: 2.681841860572995

Epoch: 5| Step: 9
Training loss: 2.7087916255440683
Validation loss: 2.6800541087182803

Epoch: 5| Step: 10
Training loss: 2.8743925696837795
Validation loss: 2.676542850399725

Epoch: 523| Step: 0
Training loss: 3.1957808993007406
Validation loss: 2.6764386301212566

Epoch: 5| Step: 1
Training loss: 3.047471051724067
Validation loss: 2.677850038821464

Epoch: 5| Step: 2
Training loss: 3.1702849814178093
Validation loss: 2.678230413047874

Epoch: 5| Step: 3
Training loss: 3.1698800564285636
Validation loss: 2.682110716397739

Epoch: 5| Step: 4
Training loss: 3.1255935105337707
Validation loss: 2.7005072384982367

Epoch: 5| Step: 5
Training loss: 2.594496837779449
Validation loss: 2.6927657017830975

Epoch: 5| Step: 6
Training loss: 3.445163853351598
Validation loss: 2.700499537618124

Epoch: 5| Step: 7
Training loss: 2.7487845769340717
Validation loss: 2.7030142124150753

Epoch: 5| Step: 8
Training loss: 2.5375561750235494
Validation loss: 2.697738055890374

Epoch: 5| Step: 9
Training loss: 2.947239253164403
Validation loss: 2.7094677971537995

Epoch: 5| Step: 10
Training loss: 2.78761138351356
Validation loss: 2.7088023696974104

Epoch: 524| Step: 0
Training loss: 2.8546560568662085
Validation loss: 2.709778785396586

Epoch: 5| Step: 1
Training loss: 3.2039892007786253
Validation loss: 2.6890648618874855

Epoch: 5| Step: 2
Training loss: 3.4487331994737347
Validation loss: 2.6821746921729215

Epoch: 5| Step: 3
Training loss: 2.2277436988149835
Validation loss: 2.6703388955959517

Epoch: 5| Step: 4
Training loss: 3.126372074274231
Validation loss: 2.6703290196135328

Epoch: 5| Step: 5
Training loss: 2.7620925326637016
Validation loss: 2.6666646663853104

Epoch: 5| Step: 6
Training loss: 2.4556590798746973
Validation loss: 2.6703378923506436

Epoch: 5| Step: 7
Training loss: 2.7787048181042917
Validation loss: 2.6680756533092627

Epoch: 5| Step: 8
Training loss: 3.5407449457872793
Validation loss: 2.6662908582163105

Epoch: 5| Step: 9
Training loss: 3.4116730522937084
Validation loss: 2.691286090634575

Epoch: 5| Step: 10
Training loss: 2.731833012069911
Validation loss: 2.698305793155541

Epoch: 525| Step: 0
Training loss: 2.8806327704839836
Validation loss: 2.7225936840323293

Epoch: 5| Step: 1
Training loss: 2.5875097375953735
Validation loss: 2.7532777875411085

Epoch: 5| Step: 2
Training loss: 3.3829748806292885
Validation loss: 2.8081786251265046

Epoch: 5| Step: 3
Training loss: 3.6228705103637475
Validation loss: 2.83843931518041

Epoch: 5| Step: 4
Training loss: 2.668661672662615
Validation loss: 2.856133845586022

Epoch: 5| Step: 5
Training loss: 3.220177935547114
Validation loss: 2.8455665337077574

Epoch: 5| Step: 6
Training loss: 3.2257918575941176
Validation loss: 2.791890322879098

Epoch: 5| Step: 7
Training loss: 3.124890439973987
Validation loss: 2.731393390556972

Epoch: 5| Step: 8
Training loss: 2.6309828017748167
Validation loss: 2.6975043745095806

Epoch: 5| Step: 9
Training loss: 2.858936547187987
Validation loss: 2.6803088896018914

Epoch: 5| Step: 10
Training loss: 2.9258669750250084
Validation loss: 2.6696643848761465

Epoch: 526| Step: 0
Training loss: 3.337927767310904
Validation loss: 2.668685413015269

Epoch: 5| Step: 1
Training loss: 3.320091186328271
Validation loss: 2.6790792434456305

Epoch: 5| Step: 2
Training loss: 2.8124857584274845
Validation loss: 2.692242494232277

Epoch: 5| Step: 3
Training loss: 2.8455673949914586
Validation loss: 2.6916063420883494

Epoch: 5| Step: 4
Training loss: 2.8478027640956665
Validation loss: 2.6826130514476123

Epoch: 5| Step: 5
Training loss: 3.1058099139447695
Validation loss: 2.6796068753236355

Epoch: 5| Step: 6
Training loss: 3.4617793521040316
Validation loss: 2.6739602794800166

Epoch: 5| Step: 7
Training loss: 2.3488829291196
Validation loss: 2.6747686901565895

Epoch: 5| Step: 8
Training loss: 2.858023569061927
Validation loss: 2.6637020192575753

Epoch: 5| Step: 9
Training loss: 3.3553844792150027
Validation loss: 2.66325038711701

Epoch: 5| Step: 10
Training loss: 2.5123248518441734
Validation loss: 2.660265446652811

Epoch: 527| Step: 0
Training loss: 2.9913660420833645
Validation loss: 2.668992889764159

Epoch: 5| Step: 1
Training loss: 2.9876232744265163
Validation loss: 2.6744456661689693

Epoch: 5| Step: 2
Training loss: 3.1502235212191816
Validation loss: 2.6757125386984177

Epoch: 5| Step: 3
Training loss: 2.888626975225765
Validation loss: 2.684564013617311

Epoch: 5| Step: 4
Training loss: 2.7882606358085433
Validation loss: 2.6930401868653724

Epoch: 5| Step: 5
Training loss: 3.623886463534135
Validation loss: 2.692739678393208

Epoch: 5| Step: 6
Training loss: 2.613441086059285
Validation loss: 2.710493038507963

Epoch: 5| Step: 7
Training loss: 3.089872454137373
Validation loss: 2.7312770337652874

Epoch: 5| Step: 8
Training loss: 2.756016219209026
Validation loss: 2.7423642051353303

Epoch: 5| Step: 9
Training loss: 2.7500711778619267
Validation loss: 2.7499148858137334

Epoch: 5| Step: 10
Training loss: 3.09247817282348
Validation loss: 2.741901284721774

Epoch: 528| Step: 0
Training loss: 2.9208094648038068
Validation loss: 2.736485245039164

Epoch: 5| Step: 1
Training loss: 3.068424178033463
Validation loss: 2.7327877518257204

Epoch: 5| Step: 2
Training loss: 3.309997332937774
Validation loss: 2.728688461564858

Epoch: 5| Step: 3
Training loss: 2.73382833193312
Validation loss: 2.6948426005713038

Epoch: 5| Step: 4
Training loss: 2.9017965999860205
Validation loss: 2.6674166263795556

Epoch: 5| Step: 5
Training loss: 3.075694872491326
Validation loss: 2.670857460568647

Epoch: 5| Step: 6
Training loss: 2.953223494244553
Validation loss: 2.6637481252801383

Epoch: 5| Step: 7
Training loss: 2.4782843635952716
Validation loss: 2.665828450681512

Epoch: 5| Step: 8
Training loss: 3.550375400090444
Validation loss: 2.6667816870504932

Epoch: 5| Step: 9
Training loss: 2.153824367910809
Validation loss: 2.6671838707450477

Epoch: 5| Step: 10
Training loss: 3.539102111998928
Validation loss: 2.671605206229025

Epoch: 529| Step: 0
Training loss: 2.723727000657167
Validation loss: 2.663784949084562

Epoch: 5| Step: 1
Training loss: 3.21784367810286
Validation loss: 2.674082963169238

Epoch: 5| Step: 2
Training loss: 3.108063694471856
Validation loss: 2.665954010729364

Epoch: 5| Step: 3
Training loss: 3.2225210080523707
Validation loss: 2.6649756787047667

Epoch: 5| Step: 4
Training loss: 2.8739149285071726
Validation loss: 2.6752172661512374

Epoch: 5| Step: 5
Training loss: 2.6120530508183224
Validation loss: 2.67257529173092

Epoch: 5| Step: 6
Training loss: 2.8704188792825174
Validation loss: 2.6747208830417204

Epoch: 5| Step: 7
Training loss: 3.007355890666251
Validation loss: 2.6789712069622915

Epoch: 5| Step: 8
Training loss: 3.1840247862919786
Validation loss: 2.6794289075170323

Epoch: 5| Step: 9
Training loss: 3.3045411855353555
Validation loss: 2.688060677210931

Epoch: 5| Step: 10
Training loss: 2.503571343601708
Validation loss: 2.6886616185561922

Epoch: 530| Step: 0
Training loss: 3.0503943829312394
Validation loss: 2.6996405181027834

Epoch: 5| Step: 1
Training loss: 3.4751429027566734
Validation loss: 2.6946783236689518

Epoch: 5| Step: 2
Training loss: 2.541811350055314
Validation loss: 2.703568586648455

Epoch: 5| Step: 3
Training loss: 2.6143583122375604
Validation loss: 2.7012093237206565

Epoch: 5| Step: 4
Training loss: 3.2624749135189273
Validation loss: 2.6967509022893443

Epoch: 5| Step: 5
Training loss: 3.0438088663976806
Validation loss: 2.686486629548644

Epoch: 5| Step: 6
Training loss: 3.237303214554718
Validation loss: 2.684128278604044

Epoch: 5| Step: 7
Training loss: 2.868744056047253
Validation loss: 2.688527244070882

Epoch: 5| Step: 8
Training loss: 3.1767591634161745
Validation loss: 2.6964528229427573

Epoch: 5| Step: 9
Training loss: 2.7129604915578227
Validation loss: 2.69735433559096

Epoch: 5| Step: 10
Training loss: 2.5090369922074447
Validation loss: 2.697922822564601

Epoch: 531| Step: 0
Training loss: 2.993073733088462
Validation loss: 2.715244390954875

Epoch: 5| Step: 1
Training loss: 2.411786534253021
Validation loss: 2.7078708686107285

Epoch: 5| Step: 2
Training loss: 2.6784370552145402
Validation loss: 2.731177609206761

Epoch: 5| Step: 3
Training loss: 2.772337187517551
Validation loss: 2.735650356093618

Epoch: 5| Step: 4
Training loss: 3.142524410568756
Validation loss: 2.745815934917468

Epoch: 5| Step: 5
Training loss: 2.7623324865584857
Validation loss: 2.7325599452161122

Epoch: 5| Step: 6
Training loss: 2.3388700417519117
Validation loss: 2.72155207892514

Epoch: 5| Step: 7
Training loss: 3.6158641264630615
Validation loss: 2.698589846420528

Epoch: 5| Step: 8
Training loss: 3.9226382299395643
Validation loss: 2.6870131198251297

Epoch: 5| Step: 9
Training loss: 2.9531991131883117
Validation loss: 2.685739222286046

Epoch: 5| Step: 10
Training loss: 2.860051309618823
Validation loss: 2.6741022559581133

Epoch: 532| Step: 0
Training loss: 2.955101683750275
Validation loss: 2.6624633793476717

Epoch: 5| Step: 1
Training loss: 2.8923069365089913
Validation loss: 2.659214901924172

Epoch: 5| Step: 2
Training loss: 3.3621821540444676
Validation loss: 2.665418489144922

Epoch: 5| Step: 3
Training loss: 2.3167638904652796
Validation loss: 2.6627353086455416

Epoch: 5| Step: 4
Training loss: 3.427710030406783
Validation loss: 2.6572997188762475

Epoch: 5| Step: 5
Training loss: 2.6104745889393928
Validation loss: 2.6655403416421346

Epoch: 5| Step: 6
Training loss: 2.8890683493340936
Validation loss: 2.667031136980432

Epoch: 5| Step: 7
Training loss: 2.967664339420772
Validation loss: 2.6702821353200306

Epoch: 5| Step: 8
Training loss: 3.6603452782281574
Validation loss: 2.667299835409428

Epoch: 5| Step: 9
Training loss: 2.616146598044715
Validation loss: 2.670863939594037

Epoch: 5| Step: 10
Training loss: 2.860861803404476
Validation loss: 2.6702872860561877

Epoch: 533| Step: 0
Training loss: 3.5106507778868212
Validation loss: 2.677377765932714

Epoch: 5| Step: 1
Training loss: 3.1145940331793023
Validation loss: 2.672660748080789

Epoch: 5| Step: 2
Training loss: 2.948386614289133
Validation loss: 2.663637450621044

Epoch: 5| Step: 3
Training loss: 2.7200314362897164
Validation loss: 2.6649923198625993

Epoch: 5| Step: 4
Training loss: 3.371559367286697
Validation loss: 2.6714997837974086

Epoch: 5| Step: 5
Training loss: 2.7816681279688478
Validation loss: 2.665197089273632

Epoch: 5| Step: 6
Training loss: 3.073190829875531
Validation loss: 2.666648918203028

Epoch: 5| Step: 7
Training loss: 2.5681306338254246
Validation loss: 2.6679623504246264

Epoch: 5| Step: 8
Training loss: 2.9312721951097838
Validation loss: 2.6685131112626816

Epoch: 5| Step: 9
Training loss: 2.3324619323633287
Validation loss: 2.6793904683552294

Epoch: 5| Step: 10
Training loss: 3.232944042982896
Validation loss: 2.6740046737049847

Epoch: 534| Step: 0
Training loss: 3.311879657742806
Validation loss: 2.6716909450119557

Epoch: 5| Step: 1
Training loss: 2.8592127352673735
Validation loss: 2.690684477768127

Epoch: 5| Step: 2
Training loss: 3.20709756278503
Validation loss: 2.680754930983213

Epoch: 5| Step: 3
Training loss: 2.6543425948336608
Validation loss: 2.6842585936605228

Epoch: 5| Step: 4
Training loss: 2.893524695043683
Validation loss: 2.6899698121429076

Epoch: 5| Step: 5
Training loss: 3.106947061166887
Validation loss: 2.681967426076391

Epoch: 5| Step: 6
Training loss: 2.6566319808067718
Validation loss: 2.6771287773383112

Epoch: 5| Step: 7
Training loss: 2.775820372005433
Validation loss: 2.678406907989924

Epoch: 5| Step: 8
Training loss: 3.0244676673284725
Validation loss: 2.6648058567656374

Epoch: 5| Step: 9
Training loss: 2.777326151903415
Validation loss: 2.6598215383318813

Epoch: 5| Step: 10
Training loss: 3.413406972562656
Validation loss: 2.6693748276584213

Epoch: 535| Step: 0
Training loss: 2.6398277207717977
Validation loss: 2.6542482297467114

Epoch: 5| Step: 1
Training loss: 2.796054996926456
Validation loss: 2.655503978841367

Epoch: 5| Step: 2
Training loss: 3.1372750858985268
Validation loss: 2.661732692595245

Epoch: 5| Step: 3
Training loss: 2.489693377202862
Validation loss: 2.6561149152636507

Epoch: 5| Step: 4
Training loss: 3.126191026694975
Validation loss: 2.653816189096439

Epoch: 5| Step: 5
Training loss: 2.9540200466542466
Validation loss: 2.6487644158466663

Epoch: 5| Step: 6
Training loss: 3.554380298796357
Validation loss: 2.6542731015729264

Epoch: 5| Step: 7
Training loss: 3.071061292975111
Validation loss: 2.660288610492251

Epoch: 5| Step: 8
Training loss: 3.08536866172384
Validation loss: 2.653384185344324

Epoch: 5| Step: 9
Training loss: 2.821755755873794
Validation loss: 2.6587056698656593

Epoch: 5| Step: 10
Training loss: 2.868956308696334
Validation loss: 2.661678316596297

Epoch: 536| Step: 0
Training loss: 2.103451018549984
Validation loss: 2.657086962798527

Epoch: 5| Step: 1
Training loss: 3.2892643012617104
Validation loss: 2.6640951700540656

Epoch: 5| Step: 2
Training loss: 2.628529401185524
Validation loss: 2.6694104905389024

Epoch: 5| Step: 3
Training loss: 3.340455187771755
Validation loss: 2.682538993241711

Epoch: 5| Step: 4
Training loss: 2.8347067776506956
Validation loss: 2.6753126471363546

Epoch: 5| Step: 5
Training loss: 3.3464596901173884
Validation loss: 2.67519902211646

Epoch: 5| Step: 6
Training loss: 2.663928344570496
Validation loss: 2.680825107177326

Epoch: 5| Step: 7
Training loss: 2.995897189659268
Validation loss: 2.6692200621011546

Epoch: 5| Step: 8
Training loss: 3.3222628979724993
Validation loss: 2.6754970767604958

Epoch: 5| Step: 9
Training loss: 3.171887327273613
Validation loss: 2.6823764811908504

Epoch: 5| Step: 10
Training loss: 2.66432058924419
Validation loss: 2.684788856242254

Epoch: 537| Step: 0
Training loss: 3.298042126934208
Validation loss: 2.6720115858426987

Epoch: 5| Step: 1
Training loss: 2.8614102817236824
Validation loss: 2.678702614087072

Epoch: 5| Step: 2
Training loss: 3.3931319993052838
Validation loss: 2.6787639600096136

Epoch: 5| Step: 3
Training loss: 2.9651239034099808
Validation loss: 2.695640651706258

Epoch: 5| Step: 4
Training loss: 3.277487786893691
Validation loss: 2.6766927868444617

Epoch: 5| Step: 5
Training loss: 2.4220453017870436
Validation loss: 2.6720918937845535

Epoch: 5| Step: 6
Training loss: 3.2310878986007
Validation loss: 2.678951371235919

Epoch: 5| Step: 7
Training loss: 3.068533267818755
Validation loss: 2.656938866717038

Epoch: 5| Step: 8
Training loss: 2.3913481372849685
Validation loss: 2.6477389747696765

Epoch: 5| Step: 9
Training loss: 2.677193239877585
Validation loss: 2.6615552422019446

Epoch: 5| Step: 10
Training loss: 2.9339974807489213
Validation loss: 2.6513046826248505

Epoch: 538| Step: 0
Training loss: 2.5815567757958986
Validation loss: 2.6516260019300244

Epoch: 5| Step: 1
Training loss: 2.863083066235599
Validation loss: 2.658163982511632

Epoch: 5| Step: 2
Training loss: 2.9735774894792133
Validation loss: 2.661352129747074

Epoch: 5| Step: 3
Training loss: 2.647903073383759
Validation loss: 2.653219841157045

Epoch: 5| Step: 4
Training loss: 2.802288081028556
Validation loss: 2.6671526533967675

Epoch: 5| Step: 5
Training loss: 3.666017185834777
Validation loss: 2.661825053928672

Epoch: 5| Step: 6
Training loss: 2.995791025795901
Validation loss: 2.658869539025014

Epoch: 5| Step: 7
Training loss: 2.820478608795344
Validation loss: 2.6619823970441177

Epoch: 5| Step: 8
Training loss: 3.0307298980955
Validation loss: 2.664538636753489

Epoch: 5| Step: 9
Training loss: 3.095495482981077
Validation loss: 2.6725702509209244

Epoch: 5| Step: 10
Training loss: 3.050469102899044
Validation loss: 2.6747777302719835

Epoch: 539| Step: 0
Training loss: 3.2925047632413222
Validation loss: 2.695592859069342

Epoch: 5| Step: 1
Training loss: 3.3636884099509397
Validation loss: 2.6882921459891254

Epoch: 5| Step: 2
Training loss: 2.72428593510321
Validation loss: 2.6806518422911476

Epoch: 5| Step: 3
Training loss: 3.213132827117059
Validation loss: 2.681530545411654

Epoch: 5| Step: 4
Training loss: 2.477545317573154
Validation loss: 2.6956969607743586

Epoch: 5| Step: 5
Training loss: 2.63728392018711
Validation loss: 2.687865957082227

Epoch: 5| Step: 6
Training loss: 2.9889579056717146
Validation loss: 2.6738374837363437

Epoch: 5| Step: 7
Training loss: 3.400293444143699
Validation loss: 2.689507788754536

Epoch: 5| Step: 8
Training loss: 2.8616877307090687
Validation loss: 2.6742677690223373

Epoch: 5| Step: 9
Training loss: 2.9092232866403984
Validation loss: 2.6900446797780586

Epoch: 5| Step: 10
Training loss: 2.6413517239755357
Validation loss: 2.6826815057343416

Epoch: 540| Step: 0
Training loss: 3.317107828470929
Validation loss: 2.6747598857909174

Epoch: 5| Step: 1
Training loss: 3.2246875996057773
Validation loss: 2.678645444356194

Epoch: 5| Step: 2
Training loss: 2.451188896697621
Validation loss: 2.682921740350971

Epoch: 5| Step: 3
Training loss: 2.349709017980151
Validation loss: 2.68120947580434

Epoch: 5| Step: 4
Training loss: 2.9560124243344825
Validation loss: 2.6889317240984436

Epoch: 5| Step: 5
Training loss: 2.885831249947548
Validation loss: 2.694595134445428

Epoch: 5| Step: 6
Training loss: 3.3839034860704214
Validation loss: 2.68539868351823

Epoch: 5| Step: 7
Training loss: 2.7195309799794734
Validation loss: 2.6903908242511365

Epoch: 5| Step: 8
Training loss: 3.413637182773353
Validation loss: 2.7015888250383315

Epoch: 5| Step: 9
Training loss: 3.025392989175561
Validation loss: 2.6885745949563544

Epoch: 5| Step: 10
Training loss: 2.553538959613054
Validation loss: 2.702994927762131

Epoch: 541| Step: 0
Training loss: 2.888467839523393
Validation loss: 2.7092970642416097

Epoch: 5| Step: 1
Training loss: 3.0953987429223955
Validation loss: 2.7185882889902317

Epoch: 5| Step: 2
Training loss: 3.463743703967911
Validation loss: 2.6994681132963807

Epoch: 5| Step: 3
Training loss: 3.0101562880182646
Validation loss: 2.7026399249153528

Epoch: 5| Step: 4
Training loss: 2.9365554264864726
Validation loss: 2.6821197570961473

Epoch: 5| Step: 5
Training loss: 3.0627758913914467
Validation loss: 2.6702637231571504

Epoch: 5| Step: 6
Training loss: 2.7962534123188014
Validation loss: 2.676610158290266

Epoch: 5| Step: 7
Training loss: 2.781535273291083
Validation loss: 2.6713048459377413

Epoch: 5| Step: 8
Training loss: 3.427510537340701
Validation loss: 2.6599996103636037

Epoch: 5| Step: 9
Training loss: 2.825185270057549
Validation loss: 2.6612097764962956

Epoch: 5| Step: 10
Training loss: 2.0429021120600046
Validation loss: 2.6619690875638624

Epoch: 542| Step: 0
Training loss: 3.2429482176555053
Validation loss: 2.6607717055324103

Epoch: 5| Step: 1
Training loss: 3.034876747959491
Validation loss: 2.6551593140990306

Epoch: 5| Step: 2
Training loss: 3.167418106333161
Validation loss: 2.6558152810008226

Epoch: 5| Step: 3
Training loss: 3.317358520526676
Validation loss: 2.6562571786666465

Epoch: 5| Step: 4
Training loss: 2.4346009645395412
Validation loss: 2.6605244448085665

Epoch: 5| Step: 5
Training loss: 2.5401181887365487
Validation loss: 2.657048251555614

Epoch: 5| Step: 6
Training loss: 3.1004692091708637
Validation loss: 2.6623350123991956

Epoch: 5| Step: 7
Training loss: 3.096923125631202
Validation loss: 2.6656838485080185

Epoch: 5| Step: 8
Training loss: 2.2603429849689816
Validation loss: 2.6800411778682647

Epoch: 5| Step: 9
Training loss: 3.257296075300489
Validation loss: 2.679167207010292

Epoch: 5| Step: 10
Training loss: 3.023558779312148
Validation loss: 2.676138144616367

Epoch: 543| Step: 0
Training loss: 2.8974459615281156
Validation loss: 2.6862481261940605

Epoch: 5| Step: 1
Training loss: 2.8121481781359705
Validation loss: 2.6660102900378404

Epoch: 5| Step: 2
Training loss: 3.013476619464563
Validation loss: 2.653107102029588

Epoch: 5| Step: 3
Training loss: 3.050381564677526
Validation loss: 2.6599088077332387

Epoch: 5| Step: 4
Training loss: 3.051637653884463
Validation loss: 2.659925020857242

Epoch: 5| Step: 5
Training loss: 2.7410948225596696
Validation loss: 2.657478706076908

Epoch: 5| Step: 6
Training loss: 3.011979978639239
Validation loss: 2.65698089436593

Epoch: 5| Step: 7
Training loss: 3.330092730448176
Validation loss: 2.6561716202060404

Epoch: 5| Step: 8
Training loss: 3.2023119383006873
Validation loss: 2.6545486985701823

Epoch: 5| Step: 9
Training loss: 2.765058039078503
Validation loss: 2.653292824906482

Epoch: 5| Step: 10
Training loss: 2.624415105416506
Validation loss: 2.659017247014116

Epoch: 544| Step: 0
Training loss: 3.1312807671716194
Validation loss: 2.6632247683992345

Epoch: 5| Step: 1
Training loss: 2.6223561733142273
Validation loss: 2.669278639034901

Epoch: 5| Step: 2
Training loss: 2.720370105920074
Validation loss: 2.6656686263653557

Epoch: 5| Step: 3
Training loss: 2.8096738391162694
Validation loss: 2.6701097052134157

Epoch: 5| Step: 4
Training loss: 3.2013543422009088
Validation loss: 2.6679298718625155

Epoch: 5| Step: 5
Training loss: 3.3381784671000516
Validation loss: 2.667377837266643

Epoch: 5| Step: 6
Training loss: 2.9416803685662565
Validation loss: 2.6720394958701092

Epoch: 5| Step: 7
Training loss: 3.411701704279249
Validation loss: 2.6658911247020693

Epoch: 5| Step: 8
Training loss: 3.2621792222681822
Validation loss: 2.653759115996185

Epoch: 5| Step: 9
Training loss: 2.8287556824941027
Validation loss: 2.650915200436192

Epoch: 5| Step: 10
Training loss: 1.8977380413773646
Validation loss: 2.6524906905790284

Epoch: 545| Step: 0
Training loss: 2.927722322669489
Validation loss: 2.660499571680567

Epoch: 5| Step: 1
Training loss: 2.89246619070434
Validation loss: 2.663019101250716

Epoch: 5| Step: 2
Training loss: 3.1096470392734776
Validation loss: 2.655999826114798

Epoch: 5| Step: 3
Training loss: 2.769613030736759
Validation loss: 2.657709487784515

Epoch: 5| Step: 4
Training loss: 3.023353910646015
Validation loss: 2.6690426446165065

Epoch: 5| Step: 5
Training loss: 3.001069514048186
Validation loss: 2.657483024503977

Epoch: 5| Step: 6
Training loss: 3.3196404708235776
Validation loss: 2.6762804586511844

Epoch: 5| Step: 7
Training loss: 3.6113753947521556
Validation loss: 2.6881308190866244

Epoch: 5| Step: 8
Training loss: 2.4668652063662933
Validation loss: 2.6799066820413904

Epoch: 5| Step: 9
Training loss: 2.7985484481960707
Validation loss: 2.6860652756010364

Epoch: 5| Step: 10
Training loss: 2.3376708473151138
Validation loss: 2.6936598476485405

Epoch: 546| Step: 0
Training loss: 3.003801956648138
Validation loss: 2.68614542106475

Epoch: 5| Step: 1
Training loss: 2.8978407417697483
Validation loss: 2.684237575469324

Epoch: 5| Step: 2
Training loss: 3.5148267051553126
Validation loss: 2.683022569966463

Epoch: 5| Step: 3
Training loss: 3.288028944273287
Validation loss: 2.6828638081658687

Epoch: 5| Step: 4
Training loss: 3.043743852613065
Validation loss: 2.6874227834656454

Epoch: 5| Step: 5
Training loss: 2.979799447959717
Validation loss: 2.672714411456965

Epoch: 5| Step: 6
Training loss: 2.542756665083135
Validation loss: 2.6926104278927783

Epoch: 5| Step: 7
Training loss: 3.265533007918564
Validation loss: 2.690341998789311

Epoch: 5| Step: 8
Training loss: 3.039916558375372
Validation loss: 2.6815671059039503

Epoch: 5| Step: 9
Training loss: 2.272421593483272
Validation loss: 2.702440223354139

Epoch: 5| Step: 10
Training loss: 2.312706706113466
Validation loss: 2.702821100751818

Epoch: 547| Step: 0
Training loss: 3.0066553044862188
Validation loss: 2.6924740510154153

Epoch: 5| Step: 1
Training loss: 2.903473707266284
Validation loss: 2.686493882965039

Epoch: 5| Step: 2
Training loss: 2.7676465248803233
Validation loss: 2.6770817468682457

Epoch: 5| Step: 3
Training loss: 3.062827423654066
Validation loss: 2.684707862432184

Epoch: 5| Step: 4
Training loss: 3.2524127807182164
Validation loss: 2.671156527517808

Epoch: 5| Step: 5
Training loss: 2.800625465561586
Validation loss: 2.680808411294737

Epoch: 5| Step: 6
Training loss: 2.393816842921282
Validation loss: 2.6703135311347665

Epoch: 5| Step: 7
Training loss: 3.242144260347961
Validation loss: 2.684046633512835

Epoch: 5| Step: 8
Training loss: 2.567287346075966
Validation loss: 2.680500126503861

Epoch: 5| Step: 9
Training loss: 3.1423834437542095
Validation loss: 2.6764568015304

Epoch: 5| Step: 10
Training loss: 3.296222929628189
Validation loss: 2.6716469940459615

Epoch: 548| Step: 0
Training loss: 2.423632666908842
Validation loss: 2.671643922450646

Epoch: 5| Step: 1
Training loss: 3.1310467012541623
Validation loss: 2.676906454560833

Epoch: 5| Step: 2
Training loss: 2.7739988806570333
Validation loss: 2.678805862008211

Epoch: 5| Step: 3
Training loss: 2.9649355827654555
Validation loss: 2.6781981911039447

Epoch: 5| Step: 4
Training loss: 2.9568348344402295
Validation loss: 2.6725083244417633

Epoch: 5| Step: 5
Training loss: 3.261608519376136
Validation loss: 2.675236540218809

Epoch: 5| Step: 6
Training loss: 3.2716688963820455
Validation loss: 2.675355950479929

Epoch: 5| Step: 7
Training loss: 2.471100858858432
Validation loss: 2.683120396574685

Epoch: 5| Step: 8
Training loss: 2.909212632775438
Validation loss: 2.6905954272131267

Epoch: 5| Step: 9
Training loss: 3.348569302583798
Validation loss: 2.69908464560248

Epoch: 5| Step: 10
Training loss: 2.8641808984303183
Validation loss: 2.7034134230510345

Epoch: 549| Step: 0
Training loss: 2.448344925017039
Validation loss: 2.6943620387178537

Epoch: 5| Step: 1
Training loss: 3.138374395225097
Validation loss: 2.6863471981120397

Epoch: 5| Step: 2
Training loss: 3.2104937392944453
Validation loss: 2.668941092824849

Epoch: 5| Step: 3
Training loss: 2.9250927511002214
Validation loss: 2.6842657470856137

Epoch: 5| Step: 4
Training loss: 2.7201739561328675
Validation loss: 2.6672100569721695

Epoch: 5| Step: 5
Training loss: 3.5372665597839554
Validation loss: 2.6710995273980918

Epoch: 5| Step: 6
Training loss: 3.084018235990091
Validation loss: 2.65382722392478

Epoch: 5| Step: 7
Training loss: 2.808212063337771
Validation loss: 2.6542875690625007

Epoch: 5| Step: 8
Training loss: 2.649544723556571
Validation loss: 2.6527983106970217

Epoch: 5| Step: 9
Training loss: 2.813140372382833
Validation loss: 2.6475844298436857

Epoch: 5| Step: 10
Training loss: 3.10534683084182
Validation loss: 2.650087324326218

Epoch: 550| Step: 0
Training loss: 3.0957510285627245
Validation loss: 2.6521725798495135

Epoch: 5| Step: 1
Training loss: 3.1227355381966166
Validation loss: 2.64140699399161

Epoch: 5| Step: 2
Training loss: 2.872091895745152
Validation loss: 2.645914417742954

Epoch: 5| Step: 3
Training loss: 3.1682660096260014
Validation loss: 2.6416302674159144

Epoch: 5| Step: 4
Training loss: 2.74649405241037
Validation loss: 2.6466656148495202

Epoch: 5| Step: 5
Training loss: 2.873599499133604
Validation loss: 2.6513453989994398

Epoch: 5| Step: 6
Training loss: 2.891340507413399
Validation loss: 2.6497127274704857

Epoch: 5| Step: 7
Training loss: 2.4494641438133753
Validation loss: 2.648067502606182

Epoch: 5| Step: 8
Training loss: 3.0549065006513976
Validation loss: 2.648882715079187

Epoch: 5| Step: 9
Training loss: 2.927805059290997
Validation loss: 2.650906827465351

Epoch: 5| Step: 10
Training loss: 3.301488315310289
Validation loss: 2.655339677029383

Testing loss: 2.8641858281698926
