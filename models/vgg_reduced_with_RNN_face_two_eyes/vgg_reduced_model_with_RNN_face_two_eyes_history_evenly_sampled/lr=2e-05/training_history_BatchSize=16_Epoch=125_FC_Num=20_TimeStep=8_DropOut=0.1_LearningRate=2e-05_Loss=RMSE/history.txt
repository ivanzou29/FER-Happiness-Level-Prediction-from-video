Epoch: 1| Step: 0
Training loss: 5.307527795791613
Validation loss: 5.764195797715661

Epoch: 6| Step: 1
Training loss: 6.4163509472877
Validation loss: 5.743716801383813

Epoch: 6| Step: 2
Training loss: 5.231015166158391
Validation loss: 5.723986501866176

Epoch: 6| Step: 3
Training loss: 4.022850571571284
Validation loss: 5.702359633053583

Epoch: 6| Step: 4
Training loss: 6.663612556249402
Validation loss: 5.677960965733985

Epoch: 6| Step: 5
Training loss: 4.5437663879518775
Validation loss: 5.650137704863954

Epoch: 6| Step: 6
Training loss: 6.094600989758495
Validation loss: 5.618731746365384

Epoch: 6| Step: 7
Training loss: 6.1372197539760425
Validation loss: 5.582237346684548

Epoch: 6| Step: 8
Training loss: 5.544232493910514
Validation loss: 5.541335695634575

Epoch: 6| Step: 9
Training loss: 6.262801830457206
Validation loss: 5.49544856263215

Epoch: 6| Step: 10
Training loss: 5.283752931765954
Validation loss: 5.446003862089555

Epoch: 6| Step: 11
Training loss: 4.94863100483573
Validation loss: 5.392625733414485

Epoch: 6| Step: 12
Training loss: 5.904183485410538
Validation loss: 5.335409086706475

Epoch: 6| Step: 13
Training loss: 5.589330365739524
Validation loss: 5.277299605798444

Epoch: 2| Step: 0
Training loss: 4.321508755891407
Validation loss: 5.217855707838257

Epoch: 6| Step: 1
Training loss: 5.049442169804135
Validation loss: 5.157869573747447

Epoch: 6| Step: 2
Training loss: 5.311344514734402
Validation loss: 5.096061881978548

Epoch: 6| Step: 3
Training loss: 5.637610816289325
Validation loss: 5.030788742136029

Epoch: 6| Step: 4
Training loss: 4.953865068183583
Validation loss: 4.964943055126423

Epoch: 6| Step: 5
Training loss: 4.381655181564034
Validation loss: 4.899196818097582

Epoch: 6| Step: 6
Training loss: 4.925355873224317
Validation loss: 4.837312589305435

Epoch: 6| Step: 7
Training loss: 5.452433107744981
Validation loss: 4.777686874826653

Epoch: 6| Step: 8
Training loss: 4.391517195549688
Validation loss: 4.721598460248117

Epoch: 6| Step: 9
Training loss: 5.179355892653888
Validation loss: 4.668053723388788

Epoch: 6| Step: 10
Training loss: 4.390948192064059
Validation loss: 4.615124389926017

Epoch: 6| Step: 11
Training loss: 4.98132613637215
Validation loss: 4.569301736689894

Epoch: 6| Step: 12
Training loss: 4.869296136079613
Validation loss: 4.534186855678706

Epoch: 6| Step: 13
Training loss: 4.565844002757817
Validation loss: 4.50081658331949

Epoch: 3| Step: 0
Training loss: 3.9431310684899907
Validation loss: 4.4714433335766435

Epoch: 6| Step: 1
Training loss: 5.262396210215553
Validation loss: 4.4444901834889405

Epoch: 6| Step: 2
Training loss: 4.407420334379993
Validation loss: 4.417124876344979

Epoch: 6| Step: 3
Training loss: 3.9113082484452013
Validation loss: 4.380505109292212

Epoch: 6| Step: 4
Training loss: 4.7411106652952295
Validation loss: 4.339471014482346

Epoch: 6| Step: 5
Training loss: 4.107232176952687
Validation loss: 4.303999119713038

Epoch: 6| Step: 6
Training loss: 5.022656796838515
Validation loss: 4.274739128346834

Epoch: 6| Step: 7
Training loss: 4.619283494090755
Validation loss: 4.24339050484002

Epoch: 6| Step: 8
Training loss: 4.3314700644598165
Validation loss: 4.210366355722584

Epoch: 6| Step: 9
Training loss: 4.403991120207355
Validation loss: 4.184392085221197

Epoch: 6| Step: 10
Training loss: 4.292455113153485
Validation loss: 4.157860963614056

Epoch: 6| Step: 11
Training loss: 4.958467027587445
Validation loss: 4.134736275591878

Epoch: 6| Step: 12
Training loss: 3.6210292246644493
Validation loss: 4.110954236684173

Epoch: 6| Step: 13
Training loss: 2.9693429455144065
Validation loss: 4.0829439603299065

Epoch: 4| Step: 0
Training loss: 3.3710825755264535
Validation loss: 4.059389772454356

Epoch: 6| Step: 1
Training loss: 3.2253523582358925
Validation loss: 4.032027664082993

Epoch: 6| Step: 2
Training loss: 3.657605563848207
Validation loss: 4.009875438123078

Epoch: 6| Step: 3
Training loss: 3.947177921851627
Validation loss: 3.9948355986288733

Epoch: 6| Step: 4
Training loss: 4.2311636934254295
Validation loss: 3.978957409675167

Epoch: 6| Step: 5
Training loss: 3.8260934849917083
Validation loss: 3.9632734928874385

Epoch: 6| Step: 6
Training loss: 3.7641897671705506
Validation loss: 3.95085290356285

Epoch: 6| Step: 7
Training loss: 4.3652221406428104
Validation loss: 3.931546177806128

Epoch: 6| Step: 8
Training loss: 5.5604448272270215
Validation loss: 3.9143100727609155

Epoch: 6| Step: 9
Training loss: 3.6448049493623778
Validation loss: 3.896766678894146

Epoch: 6| Step: 10
Training loss: 4.2516018709703145
Validation loss: 3.877937267491688

Epoch: 6| Step: 11
Training loss: 4.262488473110331
Validation loss: 3.8625955345444676

Epoch: 6| Step: 12
Training loss: 4.549461232240814
Validation loss: 3.850534540322057

Epoch: 6| Step: 13
Training loss: 4.072978429821956
Validation loss: 3.8375445147243257

Epoch: 5| Step: 0
Training loss: 3.675472753310402
Validation loss: 3.8297731007274693

Epoch: 6| Step: 1
Training loss: 3.9139964693937523
Validation loss: 3.824483056939881

Epoch: 6| Step: 2
Training loss: 3.169418812130933
Validation loss: 3.8104436241689976

Epoch: 6| Step: 3
Training loss: 3.96282853650844
Validation loss: 3.7934392017589964

Epoch: 6| Step: 4
Training loss: 4.413536161926933
Validation loss: 3.783770641860045

Epoch: 6| Step: 5
Training loss: 4.107767813386171
Validation loss: 3.770395590166867

Epoch: 6| Step: 6
Training loss: 4.897629471956824
Validation loss: 3.7566347597635423

Epoch: 6| Step: 7
Training loss: 4.300700090770333
Validation loss: 3.747720008861877

Epoch: 6| Step: 8
Training loss: 4.0306391290129255
Validation loss: 3.736346129245331

Epoch: 6| Step: 9
Training loss: 3.3130213489161253
Validation loss: 3.7254901049048925

Epoch: 6| Step: 10
Training loss: 4.437491833316649
Validation loss: 3.7139470102494427

Epoch: 6| Step: 11
Training loss: 3.2148390036416967
Validation loss: 3.700139197635985

Epoch: 6| Step: 12
Training loss: 3.542496587715309
Validation loss: 3.695290373319449

Epoch: 6| Step: 13
Training loss: 3.5420161504910386
Validation loss: 3.689973724820375

Epoch: 6| Step: 0
Training loss: 3.635760942278044
Validation loss: 3.6775872037146287

Epoch: 6| Step: 1
Training loss: 4.215869739800302
Validation loss: 3.667275062736692

Epoch: 6| Step: 2
Training loss: 2.891247161718708
Validation loss: 3.6562198931815884

Epoch: 6| Step: 3
Training loss: 3.952714861073237
Validation loss: 3.6540890907627865

Epoch: 6| Step: 4
Training loss: 3.9362330744825553
Validation loss: 3.636333537653049

Epoch: 6| Step: 5
Training loss: 3.6895284730841595
Validation loss: 3.63307297507482

Epoch: 6| Step: 6
Training loss: 3.351951594319587
Validation loss: 3.6306029947799328

Epoch: 6| Step: 7
Training loss: 3.5495490526506113
Validation loss: 3.6187268249970006

Epoch: 6| Step: 8
Training loss: 2.7508060834479284
Validation loss: 3.6074177986675102

Epoch: 6| Step: 9
Training loss: 4.859767100715152
Validation loss: 3.5979559769748115

Epoch: 6| Step: 10
Training loss: 4.338226099280276
Validation loss: 3.587986940364145

Epoch: 6| Step: 11
Training loss: 3.9288001452166905
Validation loss: 3.576395392970353

Epoch: 6| Step: 12
Training loss: 3.6592125261236648
Validation loss: 3.5684966167766157

Epoch: 6| Step: 13
Training loss: 4.404856792984219
Validation loss: 3.549507836833135

Epoch: 7| Step: 0
Training loss: 2.6617733245799338
Validation loss: 3.538477905614352

Epoch: 6| Step: 1
Training loss: 3.73810343384242
Validation loss: 3.530646097283944

Epoch: 6| Step: 2
Training loss: 3.1146569556951462
Validation loss: 3.518139898163013

Epoch: 6| Step: 3
Training loss: 4.314310771757493
Validation loss: 3.5033116136217184

Epoch: 6| Step: 4
Training loss: 2.5625700592140164
Validation loss: 3.5124782670916863

Epoch: 6| Step: 5
Training loss: 3.6553010931861887
Validation loss: 3.522197589898337

Epoch: 6| Step: 6
Training loss: 3.3351998507486167
Validation loss: 3.487241732888695

Epoch: 6| Step: 7
Training loss: 4.718925422287714
Validation loss: 3.469282043503849

Epoch: 6| Step: 8
Training loss: 4.070216904467631
Validation loss: 3.4674256706869633

Epoch: 6| Step: 9
Training loss: 3.7893506756555033
Validation loss: 3.4522728154969458

Epoch: 6| Step: 10
Training loss: 3.6820527268529433
Validation loss: 3.4400365604738607

Epoch: 6| Step: 11
Training loss: 4.006623030269937
Validation loss: 3.4309820390803476

Epoch: 6| Step: 12
Training loss: 3.786865100586376
Validation loss: 3.4256578918226572

Epoch: 6| Step: 13
Training loss: 3.6553874506330524
Validation loss: 3.422886702871038

Epoch: 8| Step: 0
Training loss: 3.5227087920926303
Validation loss: 3.4106390963774373

Epoch: 6| Step: 1
Training loss: 3.3226328920951116
Validation loss: 3.401529824942384

Epoch: 6| Step: 2
Training loss: 3.651585921545821
Validation loss: 3.3935889270725688

Epoch: 6| Step: 3
Training loss: 3.3785031822452685
Validation loss: 3.3843074074904895

Epoch: 6| Step: 4
Training loss: 3.666908574071705
Validation loss: 3.377375982118116

Epoch: 6| Step: 5
Training loss: 2.965131944161855
Validation loss: 3.371364751961759

Epoch: 6| Step: 6
Training loss: 4.070268919962236
Validation loss: 3.3680980878576703

Epoch: 6| Step: 7
Training loss: 3.6804698590232623
Validation loss: 3.361654694680193

Epoch: 6| Step: 8
Training loss: 3.2145438257156007
Validation loss: 3.354971900933407

Epoch: 6| Step: 9
Training loss: 4.256613130245239
Validation loss: 3.3466991490770526

Epoch: 6| Step: 10
Training loss: 3.4515131299695994
Validation loss: 3.3437622962520863

Epoch: 6| Step: 11
Training loss: 3.8996611912595958
Validation loss: 3.3328889094204803

Epoch: 6| Step: 12
Training loss: 3.0435912605893134
Validation loss: 3.335175788473628

Epoch: 6| Step: 13
Training loss: 4.23536135738578
Validation loss: 3.3203684526683777

Epoch: 9| Step: 0
Training loss: 3.4224613331852907
Validation loss: 3.3148941532757012

Epoch: 6| Step: 1
Training loss: 3.8505825939546097
Validation loss: 3.3136799839524094

Epoch: 6| Step: 2
Training loss: 3.7440136493450358
Validation loss: 3.3075645659102952

Epoch: 6| Step: 3
Training loss: 4.141059823866802
Validation loss: 3.3015505489413783

Epoch: 6| Step: 4
Training loss: 3.861286631984953
Validation loss: 3.2930606560675026

Epoch: 6| Step: 5
Training loss: 3.2834154522174543
Validation loss: 3.282443551512086

Epoch: 6| Step: 6
Training loss: 3.3145380048611517
Validation loss: 3.2760733730337086

Epoch: 6| Step: 7
Training loss: 3.05094676722696
Validation loss: 3.2713346649036943

Epoch: 6| Step: 8
Training loss: 3.290496875844347
Validation loss: 3.2707930239018568

Epoch: 6| Step: 9
Training loss: 3.37476008940054
Validation loss: 3.265681352701723

Epoch: 6| Step: 10
Training loss: 3.337383876880602
Validation loss: 3.25796362936851

Epoch: 6| Step: 11
Training loss: 3.595968076112321
Validation loss: 3.2521918378230126

Epoch: 6| Step: 12
Training loss: 3.8419623210832685
Validation loss: 3.245525033821868

Epoch: 6| Step: 13
Training loss: 2.687205986086239
Validation loss: 3.241861359448765

Epoch: 10| Step: 0
Training loss: 3.5399500258199597
Validation loss: 3.2392817847776048

Epoch: 6| Step: 1
Training loss: 2.9022057399051295
Validation loss: 3.234874816514861

Epoch: 6| Step: 2
Training loss: 3.629600236806847
Validation loss: 3.2324804609225413

Epoch: 6| Step: 3
Training loss: 3.421320761470437
Validation loss: 3.2277052611422943

Epoch: 6| Step: 4
Training loss: 3.227215052051459
Validation loss: 3.2222697010568715

Epoch: 6| Step: 5
Training loss: 4.03154049795126
Validation loss: 3.2176715411256156

Epoch: 6| Step: 6
Training loss: 3.3571974683221413
Validation loss: 3.214059609506222

Epoch: 6| Step: 7
Training loss: 2.9464097951315544
Validation loss: 3.2110396483890735

Epoch: 6| Step: 8
Training loss: 4.128815706788691
Validation loss: 3.2102808358584523

Epoch: 6| Step: 9
Training loss: 3.6540867853658527
Validation loss: 3.200555923135921

Epoch: 6| Step: 10
Training loss: 3.5525197556206085
Validation loss: 3.1971002447600068

Epoch: 6| Step: 11
Training loss: 2.907210324683827
Validation loss: 3.1971143334851866

Epoch: 6| Step: 12
Training loss: 3.09622001303858
Validation loss: 3.194381495196313

Epoch: 6| Step: 13
Training loss: 4.186642231556075
Validation loss: 3.1855658241177616

Epoch: 11| Step: 0
Training loss: 4.410608178931409
Validation loss: 3.178555922993107

Epoch: 6| Step: 1
Training loss: 3.3015894154409713
Validation loss: 3.1774189745349615

Epoch: 6| Step: 2
Training loss: 3.533851138146194
Validation loss: 3.1722958055929498

Epoch: 6| Step: 3
Training loss: 3.618180272610449
Validation loss: 3.1677921531656086

Epoch: 6| Step: 4
Training loss: 3.4918521318972195
Validation loss: 3.1657703282845655

Epoch: 6| Step: 5
Training loss: 3.267840496321602
Validation loss: 3.169462590986201

Epoch: 6| Step: 6
Training loss: 3.032569362164752
Validation loss: 3.1647231720384674

Epoch: 6| Step: 7
Training loss: 3.530325709545582
Validation loss: 3.157520224999671

Epoch: 6| Step: 8
Training loss: 3.888839618431295
Validation loss: 3.153257185886291

Epoch: 6| Step: 9
Training loss: 3.484018624046817
Validation loss: 3.1492821346656834

Epoch: 6| Step: 10
Training loss: 3.115648697712268
Validation loss: 3.146720238564676

Epoch: 6| Step: 11
Training loss: 2.7537280735245955
Validation loss: 3.1429971335955535

Epoch: 6| Step: 12
Training loss: 2.833877361651154
Validation loss: 3.140953344336429

Epoch: 6| Step: 13
Training loss: 3.411221297476381
Validation loss: 3.1404588557746385

Epoch: 12| Step: 0
Training loss: 3.4606431960787876
Validation loss: 3.139439506368375

Epoch: 6| Step: 1
Training loss: 4.4119840066296545
Validation loss: 3.1344718557523628

Epoch: 6| Step: 2
Training loss: 2.6051714268545862
Validation loss: 3.131363666336324

Epoch: 6| Step: 3
Training loss: 3.1412302828867085
Validation loss: 3.131270980183378

Epoch: 6| Step: 4
Training loss: 3.849068040880181
Validation loss: 3.1293956728230867

Epoch: 6| Step: 5
Training loss: 3.342070826366082
Validation loss: 3.1276118989900294

Epoch: 6| Step: 6
Training loss: 3.606401812499978
Validation loss: 3.127892880837918

Epoch: 6| Step: 7
Training loss: 3.0593259283383363
Validation loss: 3.1291621794853537

Epoch: 6| Step: 8
Training loss: 3.0366738157331254
Validation loss: 3.1255846571828414

Epoch: 6| Step: 9
Training loss: 3.9571646454178304
Validation loss: 3.1399840066744287

Epoch: 6| Step: 10
Training loss: 3.829048512448119
Validation loss: 3.123223984268317

Epoch: 6| Step: 11
Training loss: 3.7315403862037497
Validation loss: 3.138448159259258

Epoch: 6| Step: 12
Training loss: 2.387506682701145
Validation loss: 3.1346481371250476

Epoch: 6| Step: 13
Training loss: 1.7690608934194025
Validation loss: 3.1385706859656737

Epoch: 13| Step: 0
Training loss: 3.7350178568258685
Validation loss: 3.144035204130261

Epoch: 6| Step: 1
Training loss: 3.535614152621615
Validation loss: 3.1386747125325285

Epoch: 6| Step: 2
Training loss: 3.1700897454394923
Validation loss: 3.1291430059615273

Epoch: 6| Step: 3
Training loss: 3.65076471966218
Validation loss: 3.127876965682763

Epoch: 6| Step: 4
Training loss: 3.4139407068521774
Validation loss: 3.129365887746495

Epoch: 6| Step: 5
Training loss: 3.9523418389561007
Validation loss: 3.125470768734256

Epoch: 6| Step: 6
Training loss: 2.750824111218861
Validation loss: 3.1218961252388775

Epoch: 6| Step: 7
Training loss: 3.423138110999546
Validation loss: 3.117763213947894

Epoch: 6| Step: 8
Training loss: 3.2642850180050105
Validation loss: 3.1114376484435105

Epoch: 6| Step: 9
Training loss: 3.9390974891376658
Validation loss: 3.108180738046126

Epoch: 6| Step: 10
Training loss: 3.1274264261570393
Validation loss: 3.106409761530283

Epoch: 6| Step: 11
Training loss: 3.3232314260680154
Validation loss: 3.1043274573464634

Epoch: 6| Step: 12
Training loss: 2.986826264454162
Validation loss: 3.105265782382422

Epoch: 6| Step: 13
Training loss: 2.6926677609799
Validation loss: 3.10907964467724

Epoch: 14| Step: 0
Training loss: 4.002843323087909
Validation loss: 3.1005474783434157

Epoch: 6| Step: 1
Training loss: 3.277026555530836
Validation loss: 3.1003992712733206

Epoch: 6| Step: 2
Training loss: 2.960317098798616
Validation loss: 3.0976562483447867

Epoch: 6| Step: 3
Training loss: 3.9411848476746227
Validation loss: 3.0990162842025857

Epoch: 6| Step: 4
Training loss: 3.1002117453830373
Validation loss: 3.096200156107674

Epoch: 6| Step: 5
Training loss: 3.3977556618895997
Validation loss: 3.0922966994234016

Epoch: 6| Step: 6
Training loss: 3.6041258587300202
Validation loss: 3.0919439489028666

Epoch: 6| Step: 7
Training loss: 3.6707559381842376
Validation loss: 3.0865579716802007

Epoch: 6| Step: 8
Training loss: 3.067365557049125
Validation loss: 3.0851998343282268

Epoch: 6| Step: 9
Training loss: 2.857942649751744
Validation loss: 3.0815441854533616

Epoch: 6| Step: 10
Training loss: 3.345977611605936
Validation loss: 3.0772195686501815

Epoch: 6| Step: 11
Training loss: 3.3209696040957866
Validation loss: 3.0805688891111838

Epoch: 6| Step: 12
Training loss: 3.045463352371794
Validation loss: 3.075942221730295

Epoch: 6| Step: 13
Training loss: 3.3931388852728936
Validation loss: 3.067391215366294

Epoch: 15| Step: 0
Training loss: 3.6165111725132393
Validation loss: 3.06871959591938

Epoch: 6| Step: 1
Training loss: 3.518986023597898
Validation loss: 3.0658314866610517

Epoch: 6| Step: 2
Training loss: 3.396778622605001
Validation loss: 3.064393259207198

Epoch: 6| Step: 3
Training loss: 2.7892756020052323
Validation loss: 3.062869985706222

Epoch: 6| Step: 4
Training loss: 3.206377861938651
Validation loss: 3.0619941764153467

Epoch: 6| Step: 5
Training loss: 2.772323685621664
Validation loss: 3.0591903861261667

Epoch: 6| Step: 6
Training loss: 3.153832142138534
Validation loss: 3.056750032999459

Epoch: 6| Step: 7
Training loss: 3.2339105687276386
Validation loss: 3.0537898997195136

Epoch: 6| Step: 8
Training loss: 2.7709384028273134
Validation loss: 3.0536513765834625

Epoch: 6| Step: 9
Training loss: 4.089429599374733
Validation loss: 3.051524482007459

Epoch: 6| Step: 10
Training loss: 3.2127344899371986
Validation loss: 3.0506125354337192

Epoch: 6| Step: 11
Training loss: 3.680120033711457
Validation loss: 3.0458175065098056

Epoch: 6| Step: 12
Training loss: 3.367656206049477
Validation loss: 3.045182267398427

Epoch: 6| Step: 13
Training loss: 3.9488935780060572
Validation loss: 3.0430498645884687

Epoch: 16| Step: 0
Training loss: 3.425469448467292
Validation loss: 3.0392457981783236

Epoch: 6| Step: 1
Training loss: 3.944258324316863
Validation loss: 3.042311140069367

Epoch: 6| Step: 2
Training loss: 3.0078667177540397
Validation loss: 3.0359538263258727

Epoch: 6| Step: 3
Training loss: 2.9634699396572177
Validation loss: 3.037001972497399

Epoch: 6| Step: 4
Training loss: 3.6048227642791586
Validation loss: 3.031976444269173

Epoch: 6| Step: 5
Training loss: 2.9753928301816694
Validation loss: 3.034656148923853

Epoch: 6| Step: 6
Training loss: 2.963262043092908
Validation loss: 3.033803269809081

Epoch: 6| Step: 7
Training loss: 3.651893302353241
Validation loss: 3.036819718212901

Epoch: 6| Step: 8
Training loss: 3.846302208606552
Validation loss: 3.028882232562922

Epoch: 6| Step: 9
Training loss: 2.7546328620879805
Validation loss: 3.0340301514739134

Epoch: 6| Step: 10
Training loss: 2.9935286979669593
Validation loss: 3.0290762902310218

Epoch: 6| Step: 11
Training loss: 3.6349229158521386
Validation loss: 3.040446795513444

Epoch: 6| Step: 12
Training loss: 3.0742019982469255
Validation loss: 3.0349507450936524

Epoch: 6| Step: 13
Training loss: 3.4633367415684613
Validation loss: 3.0325643415131136

Epoch: 17| Step: 0
Training loss: 2.965488449184811
Validation loss: 3.027717047893224

Epoch: 6| Step: 1
Training loss: 3.33086314862685
Validation loss: 3.0222021018150618

Epoch: 6| Step: 2
Training loss: 3.40846082702304
Validation loss: 3.0237164994122048

Epoch: 6| Step: 3
Training loss: 3.0624367843642974
Validation loss: 3.0233486737274324

Epoch: 6| Step: 4
Training loss: 3.16536431552515
Validation loss: 3.021343527295881

Epoch: 6| Step: 5
Training loss: 3.0259056564116316
Validation loss: 3.021311551870363

Epoch: 6| Step: 6
Training loss: 3.007319739465835
Validation loss: 3.0189719779886857

Epoch: 6| Step: 7
Training loss: 3.7364336667905245
Validation loss: 3.0179830941340033

Epoch: 6| Step: 8
Training loss: 3.1834752721915063
Validation loss: 3.0136748310772403

Epoch: 6| Step: 9
Training loss: 4.085354648542782
Validation loss: 3.0139431125745846

Epoch: 6| Step: 10
Training loss: 4.016657002755301
Validation loss: 3.01157083125894

Epoch: 6| Step: 11
Training loss: 3.0134533588451404
Validation loss: 3.0114586785960276

Epoch: 6| Step: 12
Training loss: 3.2655892256095957
Validation loss: 3.0121039032338657

Epoch: 6| Step: 13
Training loss: 2.2547015765326353
Validation loss: 3.0305700627372474

Epoch: 18| Step: 0
Training loss: 3.053078620425619
Validation loss: 3.059293715546757

Epoch: 6| Step: 1
Training loss: 2.752675055845446
Validation loss: 3.1057419057052535

Epoch: 6| Step: 2
Training loss: 3.2024889803003713
Validation loss: 3.057666507729202

Epoch: 6| Step: 3
Training loss: 2.675699096309542
Validation loss: 3.003223838749113

Epoch: 6| Step: 4
Training loss: 3.3103515567382296
Validation loss: 3.0018603323311837

Epoch: 6| Step: 5
Training loss: 2.875332025346194
Validation loss: 3.002617350536566

Epoch: 6| Step: 6
Training loss: 2.58734157279961
Validation loss: 3.00119011441237

Epoch: 6| Step: 7
Training loss: 3.2850096462346183
Validation loss: 3.0009219058846894

Epoch: 6| Step: 8
Training loss: 3.7318844969805416
Validation loss: 3.0041135696712247

Epoch: 6| Step: 9
Training loss: 3.4776033707810576
Validation loss: 3.0058511685669007

Epoch: 6| Step: 10
Training loss: 4.026108175750706
Validation loss: 2.999113269728752

Epoch: 6| Step: 11
Training loss: 4.0199080013546915
Validation loss: 2.997065626712576

Epoch: 6| Step: 12
Training loss: 3.3986466968209585
Validation loss: 2.9956028307438203

Epoch: 6| Step: 13
Training loss: 3.5319103872524207
Validation loss: 2.9927142076549695

Epoch: 19| Step: 0
Training loss: 3.203788725774822
Validation loss: 2.992437371461729

Epoch: 6| Step: 1
Training loss: 3.185978694722408
Validation loss: 2.9913054814789075

Epoch: 6| Step: 2
Training loss: 2.817380358399061
Validation loss: 2.990281864272297

Epoch: 6| Step: 3
Training loss: 2.5595775780252663
Validation loss: 2.99222009680095

Epoch: 6| Step: 4
Training loss: 3.7493177429090325
Validation loss: 2.992502913077015

Epoch: 6| Step: 5
Training loss: 2.643117056036607
Validation loss: 2.988624346626036

Epoch: 6| Step: 6
Training loss: 3.3065408329965376
Validation loss: 2.9886971411831613

Epoch: 6| Step: 7
Training loss: 3.0089419931821486
Validation loss: 2.9892114613303478

Epoch: 6| Step: 8
Training loss: 3.9574497374417077
Validation loss: 2.9924869974893737

Epoch: 6| Step: 9
Training loss: 3.532977466536227
Validation loss: 2.9869898292469994

Epoch: 6| Step: 10
Training loss: 3.253675876261136
Validation loss: 2.986519338931956

Epoch: 6| Step: 11
Training loss: 3.6068017547420395
Validation loss: 2.9865471716988665

Epoch: 6| Step: 12
Training loss: 3.142250665136967
Validation loss: 2.9858903543028092

Epoch: 6| Step: 13
Training loss: 3.978520658824135
Validation loss: 2.9821977129864274

Epoch: 20| Step: 0
Training loss: 3.5511521417440672
Validation loss: 2.9858174784368248

Epoch: 6| Step: 1
Training loss: 3.0061471267197404
Validation loss: 2.9949193569673684

Epoch: 6| Step: 2
Training loss: 2.8477508571068557
Validation loss: 2.9957287558272516

Epoch: 6| Step: 3
Training loss: 3.0405483193054588
Validation loss: 3.0011688607876152

Epoch: 6| Step: 4
Training loss: 2.698585005253422
Validation loss: 3.0001226198438458

Epoch: 6| Step: 5
Training loss: 3.163200958129861
Validation loss: 2.9954433530713325

Epoch: 6| Step: 6
Training loss: 3.8915773015241255
Validation loss: 2.981320987178827

Epoch: 6| Step: 7
Training loss: 3.3439420840983773
Validation loss: 2.9789964197140857

Epoch: 6| Step: 8
Training loss: 3.5050799425180568
Validation loss: 2.974045049103764

Epoch: 6| Step: 9
Training loss: 2.4732900473139194
Validation loss: 2.974285861900919

Epoch: 6| Step: 10
Training loss: 3.664776893059565
Validation loss: 2.9746918554977504

Epoch: 6| Step: 11
Training loss: 3.2956702756674505
Validation loss: 2.969537119637812

Epoch: 6| Step: 12
Training loss: 3.488973824330414
Validation loss: 2.9698000524828654

Epoch: 6| Step: 13
Training loss: 3.7323047214329073
Validation loss: 2.9683711122656837

Epoch: 21| Step: 0
Training loss: 2.7680944420132754
Validation loss: 2.9675851795993555

Epoch: 6| Step: 1
Training loss: 3.0781578410763926
Validation loss: 2.9669190819173616

Epoch: 6| Step: 2
Training loss: 4.164299305092344
Validation loss: 2.974819886030889

Epoch: 6| Step: 3
Training loss: 3.282788597139746
Validation loss: 2.9675511390347658

Epoch: 6| Step: 4
Training loss: 2.9313748396132118
Validation loss: 2.967974527713453

Epoch: 6| Step: 5
Training loss: 3.832111882752589
Validation loss: 2.9701714455173946

Epoch: 6| Step: 6
Training loss: 2.8457277567889867
Validation loss: 2.9619854596313093

Epoch: 6| Step: 7
Training loss: 2.8682470208997675
Validation loss: 2.9614856383712715

Epoch: 6| Step: 8
Training loss: 3.16541523214869
Validation loss: 2.962152485324836

Epoch: 6| Step: 9
Training loss: 3.2822036084067934
Validation loss: 2.96225870891871

Epoch: 6| Step: 10
Training loss: 2.9031069587664327
Validation loss: 2.961874983331651

Epoch: 6| Step: 11
Training loss: 3.7436781683703155
Validation loss: 2.9592614766663305

Epoch: 6| Step: 12
Training loss: 3.421198669204623
Validation loss: 2.959216581493163

Epoch: 6| Step: 13
Training loss: 2.9731640576244365
Validation loss: 2.9577967064450683

Epoch: 22| Step: 0
Training loss: 3.5616016259068894
Validation loss: 2.959596344946465

Epoch: 6| Step: 1
Training loss: 3.0288395687120184
Validation loss: 2.956759893317312

Epoch: 6| Step: 2
Training loss: 3.331395937244031
Validation loss: 2.9573522278588515

Epoch: 6| Step: 3
Training loss: 3.2699293762419934
Validation loss: 2.956397235166799

Epoch: 6| Step: 4
Training loss: 2.92533221192224
Validation loss: 2.956922929491833

Epoch: 6| Step: 5
Training loss: 3.0860424168774947
Validation loss: 2.957520370766215

Epoch: 6| Step: 6
Training loss: 2.9324168601449894
Validation loss: 2.9539076981120282

Epoch: 6| Step: 7
Training loss: 3.2576350980250637
Validation loss: 2.951953479989947

Epoch: 6| Step: 8
Training loss: 3.154619003240015
Validation loss: 2.948214139198526

Epoch: 6| Step: 9
Training loss: 3.5049898817321745
Validation loss: 2.945733814554572

Epoch: 6| Step: 10
Training loss: 3.5576242912278104
Validation loss: 2.945682724648141

Epoch: 6| Step: 11
Training loss: 3.543631124773276
Validation loss: 2.9458413907918906

Epoch: 6| Step: 12
Training loss: 3.092262295690112
Validation loss: 2.9444687514624914

Epoch: 6| Step: 13
Training loss: 3.1463651060282447
Validation loss: 2.943569252922395

Epoch: 23| Step: 0
Training loss: 3.5225701797674263
Validation loss: 2.9449508382711205

Epoch: 6| Step: 1
Training loss: 2.7155353351359786
Validation loss: 2.942944717314544

Epoch: 6| Step: 2
Training loss: 2.199645629432288
Validation loss: 2.9379788202461823

Epoch: 6| Step: 3
Training loss: 3.786669921560187
Validation loss: 2.9331023986959086

Epoch: 6| Step: 4
Training loss: 3.1500129638889516
Validation loss: 2.929364401006406

Epoch: 6| Step: 5
Training loss: 2.835580682506995
Validation loss: 2.923079437145839

Epoch: 6| Step: 6
Training loss: 2.925005699217371
Validation loss: 2.9244758884190687

Epoch: 6| Step: 7
Training loss: 3.496904230208695
Validation loss: 2.9272298141599213

Epoch: 6| Step: 8
Training loss: 3.604638232360336
Validation loss: 2.91677828866689

Epoch: 6| Step: 9
Training loss: 3.8123158895094527
Validation loss: 2.9220344991703673

Epoch: 6| Step: 10
Training loss: 3.379832446217113
Validation loss: 2.939951836707219

Epoch: 6| Step: 11
Training loss: 3.360733680095802
Validation loss: 2.943725095494242

Epoch: 6| Step: 12
Training loss: 2.9641923151058567
Validation loss: 2.9606653566206447

Epoch: 6| Step: 13
Training loss: 2.9450479484760925
Validation loss: 2.9505038444158025

Epoch: 24| Step: 0
Training loss: 3.58600664591559
Validation loss: 2.950020619385164

Epoch: 6| Step: 1
Training loss: 2.714639296483009
Validation loss: 2.933969221999002

Epoch: 6| Step: 2
Training loss: 3.243293885961137
Validation loss: 2.9399802847268104

Epoch: 6| Step: 3
Training loss: 3.1714546413651146
Validation loss: 2.9182446677670435

Epoch: 6| Step: 4
Training loss: 3.119153466434117
Validation loss: 2.905853805502579

Epoch: 6| Step: 5
Training loss: 2.842499678183129
Validation loss: 2.902956469936429

Epoch: 6| Step: 6
Training loss: 3.584603520685753
Validation loss: 2.9031706767163166

Epoch: 6| Step: 7
Training loss: 3.4077766566991095
Validation loss: 2.9048934683362355

Epoch: 6| Step: 8
Training loss: 2.8914800255718958
Validation loss: 2.920333147526544

Epoch: 6| Step: 9
Training loss: 3.166244395025558
Validation loss: 2.9075668409018105

Epoch: 6| Step: 10
Training loss: 3.4544412857302436
Validation loss: 2.9138571701414904

Epoch: 6| Step: 11
Training loss: 3.615247828429182
Validation loss: 2.93123392660914

Epoch: 6| Step: 12
Training loss: 3.2765441573852487
Validation loss: 2.991921881867665

Epoch: 6| Step: 13
Training loss: 2.5660126963514647
Validation loss: 2.9496588587411803

Epoch: 25| Step: 0
Training loss: 3.101051115449386
Validation loss: 2.9888070214676787

Epoch: 6| Step: 1
Training loss: 3.246446574255777
Validation loss: 2.998167202762001

Epoch: 6| Step: 2
Training loss: 3.4108030354744554
Validation loss: 2.9892592275689944

Epoch: 6| Step: 3
Training loss: 3.88377715318296
Validation loss: 2.976717705567126

Epoch: 6| Step: 4
Training loss: 3.068759671135792
Validation loss: 2.94810368250405

Epoch: 6| Step: 5
Training loss: 3.6388440667288524
Validation loss: 2.9005301338564204

Epoch: 6| Step: 6
Training loss: 3.342356453825461
Validation loss: 2.9013630248694477

Epoch: 6| Step: 7
Training loss: 3.6074682706731567
Validation loss: 2.957016736981393

Epoch: 6| Step: 8
Training loss: 2.1617677275662106
Validation loss: 2.977404071217266

Epoch: 6| Step: 9
Training loss: 3.4989065096985428
Validation loss: 2.95970851393105

Epoch: 6| Step: 10
Training loss: 2.9526208517873034
Validation loss: 2.894892388237277

Epoch: 6| Step: 11
Training loss: 2.9092721300141466
Validation loss: 2.8863478385979255

Epoch: 6| Step: 12
Training loss: 3.178550873226119
Validation loss: 2.9130841510123378

Epoch: 6| Step: 13
Training loss: 3.1104746651953725
Validation loss: 2.941776103507004

Epoch: 26| Step: 0
Training loss: 3.228548265535621
Validation loss: 2.996124334591409

Epoch: 6| Step: 1
Training loss: 3.9096091513641955
Validation loss: 3.007110918735617

Epoch: 6| Step: 2
Training loss: 2.5587637109580137
Validation loss: 2.9678480676953893

Epoch: 6| Step: 3
Training loss: 3.89744894761373
Validation loss: 2.980834458539063

Epoch: 6| Step: 4
Training loss: 3.8213176380144827
Validation loss: 2.9402098975344306

Epoch: 6| Step: 5
Training loss: 3.33267431102328
Validation loss: 2.9128343382066784

Epoch: 6| Step: 6
Training loss: 3.5212839654564725
Validation loss: 2.9091165153491882

Epoch: 6| Step: 7
Training loss: 3.2226855467418334
Validation loss: 2.9232044995473854

Epoch: 6| Step: 8
Training loss: 2.1261695560440574
Validation loss: 2.962235980792888

Epoch: 6| Step: 9
Training loss: 3.2293876490300013
Validation loss: 2.9958502480709712

Epoch: 6| Step: 10
Training loss: 3.1610617642907792
Validation loss: 2.927365887852335

Epoch: 6| Step: 11
Training loss: 2.9365080112144692
Validation loss: 2.901073436563469

Epoch: 6| Step: 12
Training loss: 2.9052207518857323
Validation loss: 2.8949057426582465

Epoch: 6| Step: 13
Training loss: 2.869178018657361
Validation loss: 2.8934719514406173

Epoch: 27| Step: 0
Training loss: 3.2602114546832768
Validation loss: 2.894229366506906

Epoch: 6| Step: 1
Training loss: 2.9461777122022768
Validation loss: 2.8853655245998957

Epoch: 6| Step: 2
Training loss: 3.663802603347564
Validation loss: 2.886095129749944

Epoch: 6| Step: 3
Training loss: 3.3536276690295344
Validation loss: 2.885365290924991

Epoch: 6| Step: 4
Training loss: 3.319502572402383
Validation loss: 2.88481791193652

Epoch: 6| Step: 5
Training loss: 3.4585483131844996
Validation loss: 2.8833036944959414

Epoch: 6| Step: 6
Training loss: 2.505874788351369
Validation loss: 2.88942049224191

Epoch: 6| Step: 7
Training loss: 3.4096436000512016
Validation loss: 2.9029620233916336

Epoch: 6| Step: 8
Training loss: 3.300287153292794
Validation loss: 2.891455872200865

Epoch: 6| Step: 9
Training loss: 3.099183830370298
Validation loss: 2.8868208508893116

Epoch: 6| Step: 10
Training loss: 3.5731800008253627
Validation loss: 2.878257982245673

Epoch: 6| Step: 11
Training loss: 2.715201330992283
Validation loss: 2.876218202406826

Epoch: 6| Step: 12
Training loss: 3.0533516150625495
Validation loss: 2.872436497861886

Epoch: 6| Step: 13
Training loss: 2.34703088641394
Validation loss: 2.877749930477062

Epoch: 28| Step: 0
Training loss: 2.963904512223794
Validation loss: 2.8697737281610434

Epoch: 6| Step: 1
Training loss: 2.8394566918892683
Validation loss: 2.869172768384963

Epoch: 6| Step: 2
Training loss: 3.310500495158154
Validation loss: 2.869489052454671

Epoch: 6| Step: 3
Training loss: 3.1412784029567984
Validation loss: 2.8618510415961076

Epoch: 6| Step: 4
Training loss: 2.8533677331092675
Validation loss: 2.8594703884790533

Epoch: 6| Step: 5
Training loss: 3.4053220272289755
Validation loss: 2.856396138416796

Epoch: 6| Step: 6
Training loss: 2.806835743831973
Validation loss: 2.8580328996170175

Epoch: 6| Step: 7
Training loss: 3.4222744921893886
Validation loss: 2.8570288470406475

Epoch: 6| Step: 8
Training loss: 3.5009915445983473
Validation loss: 2.863010857462609

Epoch: 6| Step: 9
Training loss: 3.6296378097384334
Validation loss: 2.874501617164228

Epoch: 6| Step: 10
Training loss: 3.5922828664975883
Validation loss: 2.88222816837586

Epoch: 6| Step: 11
Training loss: 2.868732088319797
Validation loss: 2.857148193960142

Epoch: 6| Step: 12
Training loss: 2.9094040685854825
Validation loss: 2.8605372783691045

Epoch: 6| Step: 13
Training loss: 2.9053963668845695
Validation loss: 2.8598883867460514

Epoch: 29| Step: 0
Training loss: 3.8183081738095295
Validation loss: 2.8605832974596823

Epoch: 6| Step: 1
Training loss: 2.5240997295838477
Validation loss: 2.8604339901538376

Epoch: 6| Step: 2
Training loss: 3.3699809300819807
Validation loss: 2.857592590156597

Epoch: 6| Step: 3
Training loss: 2.897021335827415
Validation loss: 2.8556836061724664

Epoch: 6| Step: 4
Training loss: 2.7418483078759297
Validation loss: 2.8523536806100562

Epoch: 6| Step: 5
Training loss: 2.4494688158886584
Validation loss: 2.8515928169332434

Epoch: 6| Step: 6
Training loss: 3.0734500917720737
Validation loss: 2.8529246755040556

Epoch: 6| Step: 7
Training loss: 3.70373118143132
Validation loss: 2.8541292302318952

Epoch: 6| Step: 8
Training loss: 3.3973479530383215
Validation loss: 2.8532811542628047

Epoch: 6| Step: 9
Training loss: 3.1323004325504695
Validation loss: 2.8520499978792637

Epoch: 6| Step: 10
Training loss: 2.556040834109656
Validation loss: 2.8562923557952633

Epoch: 6| Step: 11
Training loss: 3.793113823580528
Validation loss: 2.866448580038654

Epoch: 6| Step: 12
Training loss: 2.922413169543367
Validation loss: 2.860736976446242

Epoch: 6| Step: 13
Training loss: 3.896048324011111
Validation loss: 2.855888270230002

Epoch: 30| Step: 0
Training loss: 2.8550686118838637
Validation loss: 2.850496960992502

Epoch: 6| Step: 1
Training loss: 3.2333053810510677
Validation loss: 2.846790362071675

Epoch: 6| Step: 2
Training loss: 3.413575021958942
Validation loss: 2.846035699218364

Epoch: 6| Step: 3
Training loss: 3.9768141871096248
Validation loss: 2.847413829362593

Epoch: 6| Step: 4
Training loss: 3.1165516905222774
Validation loss: 2.8478047364705645

Epoch: 6| Step: 5
Training loss: 3.2373494647167242
Validation loss: 2.84694311069654

Epoch: 6| Step: 6
Training loss: 4.043857465728113
Validation loss: 2.8432078168630555

Epoch: 6| Step: 7
Training loss: 2.224022416941783
Validation loss: 2.843392998013673

Epoch: 6| Step: 8
Training loss: 2.2506119637613637
Validation loss: 2.841426785206921

Epoch: 6| Step: 9
Training loss: 3.154559900991787
Validation loss: 2.8443027361684416

Epoch: 6| Step: 10
Training loss: 3.04327148185236
Validation loss: 2.8542909064459727

Epoch: 6| Step: 11
Training loss: 3.0382053764994295
Validation loss: 2.8672286386626946

Epoch: 6| Step: 12
Training loss: 3.29805904297175
Validation loss: 2.874293668136181

Epoch: 6| Step: 13
Training loss: 2.613369653686187
Validation loss: 2.8611809809975326

Epoch: 31| Step: 0
Training loss: 3.781809741749382
Validation loss: 2.8397770872827124

Epoch: 6| Step: 1
Training loss: 3.0878316353671265
Validation loss: 2.836151747742376

Epoch: 6| Step: 2
Training loss: 3.7674434592314534
Validation loss: 2.83752259521971

Epoch: 6| Step: 3
Training loss: 3.2314419185820045
Validation loss: 2.835803888094943

Epoch: 6| Step: 4
Training loss: 3.04228404498794
Validation loss: 2.8358953867131556

Epoch: 6| Step: 5
Training loss: 3.4611285912521517
Validation loss: 2.8377459181834896

Epoch: 6| Step: 6
Training loss: 3.304328917038977
Validation loss: 2.837565827239695

Epoch: 6| Step: 7
Training loss: 2.821261851125696
Validation loss: 2.837243672279551

Epoch: 6| Step: 8
Training loss: 2.3354640723347693
Validation loss: 2.8487582778286646

Epoch: 6| Step: 9
Training loss: 2.897342773332006
Validation loss: 2.8480691573720347

Epoch: 6| Step: 10
Training loss: 2.221823913587826
Validation loss: 2.845180038774004

Epoch: 6| Step: 11
Training loss: 2.9634552972651975
Validation loss: 2.8438948745722827

Epoch: 6| Step: 12
Training loss: 3.4484240263315735
Validation loss: 2.833498433012137

Epoch: 6| Step: 13
Training loss: 3.494430879634964
Validation loss: 2.8299965742217945

Epoch: 32| Step: 0
Training loss: 2.9438673769476504
Validation loss: 2.827781519056079

Epoch: 6| Step: 1
Training loss: 2.666069460594262
Validation loss: 2.8281102932194244

Epoch: 6| Step: 2
Training loss: 3.164654108946578
Validation loss: 2.8292164821740475

Epoch: 6| Step: 3
Training loss: 2.9917616578502395
Validation loss: 2.829337854906031

Epoch: 6| Step: 4
Training loss: 2.660788932769936
Validation loss: 2.8292266027325925

Epoch: 6| Step: 5
Training loss: 3.0045884328807793
Validation loss: 2.829246645300519

Epoch: 6| Step: 6
Training loss: 2.831913049796276
Validation loss: 2.829648681783145

Epoch: 6| Step: 7
Training loss: 3.3968535842852114
Validation loss: 2.8273755847523128

Epoch: 6| Step: 8
Training loss: 3.346666151809146
Validation loss: 2.8290923395094696

Epoch: 6| Step: 9
Training loss: 3.3799585721338095
Validation loss: 2.8266373867143493

Epoch: 6| Step: 10
Training loss: 3.7312345827125997
Validation loss: 2.8269631902360755

Epoch: 6| Step: 11
Training loss: 2.8310546875
Validation loss: 2.82479011738972

Epoch: 6| Step: 12
Training loss: 3.523856195241402
Validation loss: 2.824038353803592

Epoch: 6| Step: 13
Training loss: 3.534153107845961
Validation loss: 2.826026221591678

Epoch: 33| Step: 0
Training loss: 3.447072243602142
Validation loss: 2.8226858413301508

Epoch: 6| Step: 1
Training loss: 3.7380552153777624
Validation loss: 2.83167881646455

Epoch: 6| Step: 2
Training loss: 2.627791419160727
Validation loss: 2.822637442385056

Epoch: 6| Step: 3
Training loss: 2.398785196257815
Validation loss: 2.8250602460559584

Epoch: 6| Step: 4
Training loss: 3.5988836358908047
Validation loss: 2.820748196058966

Epoch: 6| Step: 5
Training loss: 3.0236321122968475
Validation loss: 2.8198397719752433

Epoch: 6| Step: 6
Training loss: 2.9998359635329175
Validation loss: 2.819848251549329

Epoch: 6| Step: 7
Training loss: 3.13594427559448
Validation loss: 2.821372754958762

Epoch: 6| Step: 8
Training loss: 3.3714931777416655
Validation loss: 2.8170698878340774

Epoch: 6| Step: 9
Training loss: 3.101193499775026
Validation loss: 2.8179408279211406

Epoch: 6| Step: 10
Training loss: 2.957177505000595
Validation loss: 2.8145696046281463

Epoch: 6| Step: 11
Training loss: 3.2979066509224064
Validation loss: 2.8185470364282614

Epoch: 6| Step: 12
Training loss: 3.3697647180123336
Validation loss: 2.8129172941890754

Epoch: 6| Step: 13
Training loss: 1.8854126763345493
Validation loss: 2.818115793272145

Epoch: 34| Step: 0
Training loss: 3.22573864188756
Validation loss: 2.816737676165792

Epoch: 6| Step: 1
Training loss: 2.3592983006016692
Validation loss: 2.8140696257697653

Epoch: 6| Step: 2
Training loss: 3.720764383928121
Validation loss: 2.817497141934229

Epoch: 6| Step: 3
Training loss: 3.3245809247934526
Validation loss: 2.812076120098322

Epoch: 6| Step: 4
Training loss: 2.9494218162706005
Validation loss: 2.813850903320879

Epoch: 6| Step: 5
Training loss: 2.5506781517796524
Validation loss: 2.822081081464052

Epoch: 6| Step: 6
Training loss: 3.377638597785947
Validation loss: 2.8327507072077442

Epoch: 6| Step: 7
Training loss: 3.5994878987488965
Validation loss: 2.832245213025375

Epoch: 6| Step: 8
Training loss: 2.927660431542052
Validation loss: 2.8078092920925277

Epoch: 6| Step: 9
Training loss: 3.309644800126281
Validation loss: 2.8070756293089887

Epoch: 6| Step: 10
Training loss: 3.4499396222124847
Validation loss: 2.8111340321914966

Epoch: 6| Step: 11
Training loss: 2.661331611697087
Validation loss: 2.813592528569867

Epoch: 6| Step: 12
Training loss: 3.185937086912599
Validation loss: 2.819533162829586

Epoch: 6| Step: 13
Training loss: 2.724566234397486
Validation loss: 2.8285232686842265

Epoch: 35| Step: 0
Training loss: 3.0187807322452223
Validation loss: 2.8286372892226956

Epoch: 6| Step: 1
Training loss: 1.9666707397138585
Validation loss: 2.824541963032277

Epoch: 6| Step: 2
Training loss: 2.525511937130011
Validation loss: 2.815868465211693

Epoch: 6| Step: 3
Training loss: 2.977184801305671
Validation loss: 2.8089481308007502

Epoch: 6| Step: 4
Training loss: 3.300798874305759
Validation loss: 2.8070889905354712

Epoch: 6| Step: 5
Training loss: 2.8693962217030995
Validation loss: 2.804927776673897

Epoch: 6| Step: 6
Training loss: 4.064748288627765
Validation loss: 2.80740966098386

Epoch: 6| Step: 7
Training loss: 2.9281170921259614
Validation loss: 2.807648722210702

Epoch: 6| Step: 8
Training loss: 3.2062637953433573
Validation loss: 2.8574293270222366

Epoch: 6| Step: 9
Training loss: 3.9515606947683946
Validation loss: 2.8264354489896744

Epoch: 6| Step: 10
Training loss: 3.265132301068587
Validation loss: 2.8022904102060555

Epoch: 6| Step: 11
Training loss: 2.9990213705320947
Validation loss: 2.7977089723849526

Epoch: 6| Step: 12
Training loss: 3.2484552673764044
Validation loss: 2.800632175299671

Epoch: 6| Step: 13
Training loss: 2.761508183633122
Validation loss: 2.7993300934478325

Epoch: 36| Step: 0
Training loss: 2.422311066778138
Validation loss: 2.8003837340078848

Epoch: 6| Step: 1
Training loss: 3.865408563375469
Validation loss: 2.799487227447115

Epoch: 6| Step: 2
Training loss: 3.0509206664287087
Validation loss: 2.799038516156261

Epoch: 6| Step: 3
Training loss: 3.9912258714471647
Validation loss: 2.7969360601547812

Epoch: 6| Step: 4
Training loss: 2.9145414148078888
Validation loss: 2.7939868404958115

Epoch: 6| Step: 5
Training loss: 2.8166811064250328
Validation loss: 2.7932614445680155

Epoch: 6| Step: 6
Training loss: 3.0121731149437028
Validation loss: 2.7959131596748543

Epoch: 6| Step: 7
Training loss: 2.998064688464994
Validation loss: 2.7946926247735555

Epoch: 6| Step: 8
Training loss: 3.484112237850196
Validation loss: 2.792970918057495

Epoch: 6| Step: 9
Training loss: 2.994099854989875
Validation loss: 2.7948193778292243

Epoch: 6| Step: 10
Training loss: 2.7563730432981672
Validation loss: 2.7912498448235286

Epoch: 6| Step: 11
Training loss: 2.852596064294816
Validation loss: 2.793185602488608

Epoch: 6| Step: 12
Training loss: 3.044455638765915
Validation loss: 2.805750646935191

Epoch: 6| Step: 13
Training loss: 3.015770626999078
Validation loss: 2.814294250485181

Epoch: 37| Step: 0
Training loss: 3.369931972281152
Validation loss: 2.821565960974724

Epoch: 6| Step: 1
Training loss: 3.1155245750411833
Validation loss: 2.790226475927

Epoch: 6| Step: 2
Training loss: 3.3142255211517684
Validation loss: 2.781005091828405

Epoch: 6| Step: 3
Training loss: 2.925897287835792
Validation loss: 2.780944211030817

Epoch: 6| Step: 4
Training loss: 2.513212385766806
Validation loss: 2.784413278060016

Epoch: 6| Step: 5
Training loss: 2.9264459606130067
Validation loss: 2.7825713503660077

Epoch: 6| Step: 6
Training loss: 3.170787906864378
Validation loss: 2.7834347417655216

Epoch: 6| Step: 7
Training loss: 3.387773712473829
Validation loss: 2.7857228641497374

Epoch: 6| Step: 8
Training loss: 3.3038978444856424
Validation loss: 2.7845760587340336

Epoch: 6| Step: 9
Training loss: 3.128051945979415
Validation loss: 2.782663909312549

Epoch: 6| Step: 10
Training loss: 3.2955458434083207
Validation loss: 2.7845476793241635

Epoch: 6| Step: 11
Training loss: 2.9425673909601113
Validation loss: 2.782088502327396

Epoch: 6| Step: 12
Training loss: 2.988206570758033
Validation loss: 2.7814640600185894

Epoch: 6| Step: 13
Training loss: 2.9906232843822633
Validation loss: 2.7829843339771565

Epoch: 38| Step: 0
Training loss: 2.7849257963694796
Validation loss: 2.7842431014817532

Epoch: 6| Step: 1
Training loss: 3.531108482023231
Validation loss: 2.786140646586583

Epoch: 6| Step: 2
Training loss: 3.153285078629805
Validation loss: 2.7818154486913773

Epoch: 6| Step: 3
Training loss: 3.0959147576516877
Validation loss: 2.7767852124197474

Epoch: 6| Step: 4
Training loss: 3.505358544919818
Validation loss: 2.779881738897744

Epoch: 6| Step: 5
Training loss: 3.2028338044085443
Validation loss: 2.7731538286944377

Epoch: 6| Step: 6
Training loss: 3.572213299234049
Validation loss: 2.773700736397851

Epoch: 6| Step: 7
Training loss: 2.8486550754936517
Validation loss: 2.7845151105452137

Epoch: 6| Step: 8
Training loss: 2.763725533655326
Validation loss: 2.7995155469853783

Epoch: 6| Step: 9
Training loss: 2.5823165574335403
Validation loss: 2.81097744436895

Epoch: 6| Step: 10
Training loss: 2.1269197207403296
Validation loss: 2.8391049805569177

Epoch: 6| Step: 11
Training loss: 3.3736571006803864
Validation loss: 2.846306705491032

Epoch: 6| Step: 12
Training loss: 3.4665655182485113
Validation loss: 2.826352264729239

Epoch: 6| Step: 13
Training loss: 3.2140320208508637
Validation loss: 2.8090896147035513

Epoch: 39| Step: 0
Training loss: 3.1604729530252587
Validation loss: 2.791446867842458

Epoch: 6| Step: 1
Training loss: 2.771691086784439
Validation loss: 2.78252465836157

Epoch: 6| Step: 2
Training loss: 3.236190802193703
Validation loss: 2.780792900224007

Epoch: 6| Step: 3
Training loss: 3.7280225792475283
Validation loss: 2.7803399040784935

Epoch: 6| Step: 4
Training loss: 2.832501476317759
Validation loss: 2.77960215531154

Epoch: 6| Step: 5
Training loss: 2.9045615264843008
Validation loss: 2.7764799917157146

Epoch: 6| Step: 6
Training loss: 3.2990401692785105
Validation loss: 2.7704282975460526

Epoch: 6| Step: 7
Training loss: 3.177194128553932
Validation loss: 2.770208891801889

Epoch: 6| Step: 8
Training loss: 3.1345584408753164
Validation loss: 2.7692611546201777

Epoch: 6| Step: 9
Training loss: 3.580464626828441
Validation loss: 2.7669567843247975

Epoch: 6| Step: 10
Training loss: 2.9361306103127345
Validation loss: 2.767249288813103

Epoch: 6| Step: 11
Training loss: 2.6654868694977365
Validation loss: 2.7653015913522467

Epoch: 6| Step: 12
Training loss: 2.9587776137023534
Validation loss: 2.7633041600438806

Epoch: 6| Step: 13
Training loss: 2.4446007420923617
Validation loss: 2.7660794281922376

Epoch: 40| Step: 0
Training loss: 3.226516390787366
Validation loss: 2.7673009910158086

Epoch: 6| Step: 1
Training loss: 2.843715793278128
Validation loss: 2.7718973521648294

Epoch: 6| Step: 2
Training loss: 3.222764853757144
Validation loss: 2.771251343154395

Epoch: 6| Step: 3
Training loss: 3.2212772262541747
Validation loss: 2.7868863196952915

Epoch: 6| Step: 4
Training loss: 3.0848828795225103
Validation loss: 2.7942336091571596

Epoch: 6| Step: 5
Training loss: 2.071570248292251
Validation loss: 2.8061544353873487

Epoch: 6| Step: 6
Training loss: 2.996474578805604
Validation loss: 2.809810793877

Epoch: 6| Step: 7
Training loss: 3.421143893518823
Validation loss: 2.81477712240363

Epoch: 6| Step: 8
Training loss: 3.331551950021329
Validation loss: 2.805102446942742

Epoch: 6| Step: 9
Training loss: 3.4313478382941187
Validation loss: 2.789253735462755

Epoch: 6| Step: 10
Training loss: 2.8021712637982166
Validation loss: 2.777834940205963

Epoch: 6| Step: 11
Training loss: 3.5472812503957423
Validation loss: 2.761800185632586

Epoch: 6| Step: 12
Training loss: 2.907491767327157
Validation loss: 2.758556799230301

Epoch: 6| Step: 13
Training loss: 2.8827076301005015
Validation loss: 2.755496789584256

Epoch: 41| Step: 0
Training loss: 3.2026707769119267
Validation loss: 2.755577272211769

Epoch: 6| Step: 1
Training loss: 3.8739521701835864
Validation loss: 2.7558574186816847

Epoch: 6| Step: 2
Training loss: 3.4053123653496207
Validation loss: 2.7573132303986787

Epoch: 6| Step: 3
Training loss: 3.1739574793351344
Validation loss: 2.754705875519173

Epoch: 6| Step: 4
Training loss: 2.3810123835677808
Validation loss: 2.7579460865820318

Epoch: 6| Step: 5
Training loss: 3.4345068645067154
Validation loss: 2.757199492323375

Epoch: 6| Step: 6
Training loss: 3.116332890662486
Validation loss: 2.7530347853383716

Epoch: 6| Step: 7
Training loss: 2.740467368870009
Validation loss: 2.753689482649457

Epoch: 6| Step: 8
Training loss: 3.14912168579872
Validation loss: 2.7497937431809394

Epoch: 6| Step: 9
Training loss: 3.1254665789381866
Validation loss: 2.7481368606291547

Epoch: 6| Step: 10
Training loss: 3.108048966177925
Validation loss: 2.751995701206758

Epoch: 6| Step: 11
Training loss: 2.697647366038215
Validation loss: 2.7500471146501173

Epoch: 6| Step: 12
Training loss: 2.4971647397635404
Validation loss: 2.750302364324262

Epoch: 6| Step: 13
Training loss: 2.868501034905837
Validation loss: 2.748167413653116

Epoch: 42| Step: 0
Training loss: 3.338230033212012
Validation loss: 2.7484149009639554

Epoch: 6| Step: 1
Training loss: 3.6098746081948123
Validation loss: 2.7468337021606333

Epoch: 6| Step: 2
Training loss: 2.554080436043332
Validation loss: 2.7470140131280023

Epoch: 6| Step: 3
Training loss: 3.183721659144416
Validation loss: 2.744344003522841

Epoch: 6| Step: 4
Training loss: 2.5583542573385882
Validation loss: 2.7451899777464033

Epoch: 6| Step: 5
Training loss: 2.8079757753343424
Validation loss: 2.7441601632805424

Epoch: 6| Step: 6
Training loss: 2.746363142319487
Validation loss: 2.742401825186769

Epoch: 6| Step: 7
Training loss: 2.9816548198580457
Validation loss: 2.7440175663224853

Epoch: 6| Step: 8
Training loss: 2.611403447778901
Validation loss: 2.7426601895677956

Epoch: 6| Step: 9
Training loss: 3.5848722184524004
Validation loss: 2.743211845935871

Epoch: 6| Step: 10
Training loss: 3.106020243876574
Validation loss: 2.7444943590050594

Epoch: 6| Step: 11
Training loss: 3.0953010755286705
Validation loss: 2.7452112903622674

Epoch: 6| Step: 12
Training loss: 3.032211308586833
Validation loss: 2.743906329496502

Epoch: 6| Step: 13
Training loss: 3.9148672041897448
Validation loss: 2.745897535020157

Epoch: 43| Step: 0
Training loss: 3.127511807914173
Validation loss: 2.7401104625842554

Epoch: 6| Step: 1
Training loss: 3.0650700275828635
Validation loss: 2.740175393220513

Epoch: 6| Step: 2
Training loss: 2.47770553829487
Validation loss: 2.7395076628185318

Epoch: 6| Step: 3
Training loss: 2.7818378298763133
Validation loss: 2.73854235189135

Epoch: 6| Step: 4
Training loss: 3.3473269145908846
Validation loss: 2.7398871647100447

Epoch: 6| Step: 5
Training loss: 3.250679238572296
Validation loss: 2.7392323711814255

Epoch: 6| Step: 6
Training loss: 3.0673543642723295
Validation loss: 2.74061944212904

Epoch: 6| Step: 7
Training loss: 3.466722325342812
Validation loss: 2.7412564225773415

Epoch: 6| Step: 8
Training loss: 3.334086492010376
Validation loss: 2.740745690564339

Epoch: 6| Step: 9
Training loss: 2.986480130205998
Validation loss: 2.740173769061171

Epoch: 6| Step: 10
Training loss: 2.994053351019317
Validation loss: 2.7386873906687805

Epoch: 6| Step: 11
Training loss: 2.977320937402354
Validation loss: 2.736781081705074

Epoch: 6| Step: 12
Training loss: 2.853758752636514
Validation loss: 2.7363755462536257

Epoch: 6| Step: 13
Training loss: 3.2541153601307027
Validation loss: 2.734220316975373

Epoch: 44| Step: 0
Training loss: 3.1854730781132456
Validation loss: 2.734819920404889

Epoch: 6| Step: 1
Training loss: 2.5413352771116484
Validation loss: 2.7383164189739846

Epoch: 6| Step: 2
Training loss: 3.1259811387033047
Validation loss: 2.739402444676399

Epoch: 6| Step: 3
Training loss: 3.387420546384645
Validation loss: 2.750894593040286

Epoch: 6| Step: 4
Training loss: 3.2790341115784414
Validation loss: 2.75511507377797

Epoch: 6| Step: 5
Training loss: 3.1437098597244795
Validation loss: 2.77065780944778

Epoch: 6| Step: 6
Training loss: 3.259434431198041
Validation loss: 2.771961457760986

Epoch: 6| Step: 7
Training loss: 2.7539019212621123
Validation loss: 2.756007545099498

Epoch: 6| Step: 8
Training loss: 3.5208568384112002
Validation loss: 2.757579529738595

Epoch: 6| Step: 9
Training loss: 2.6051208172273075
Validation loss: 2.743032071970286

Epoch: 6| Step: 10
Training loss: 3.04779539634046
Validation loss: 2.7370539738782

Epoch: 6| Step: 11
Training loss: 3.107205654944117
Validation loss: 2.7369913220917432

Epoch: 6| Step: 12
Training loss: 3.066971297959093
Validation loss: 2.730073196974121

Epoch: 6| Step: 13
Training loss: 2.3440727520286093
Validation loss: 2.7283198475281876

Epoch: 45| Step: 0
Training loss: 3.3817689620768316
Validation loss: 2.7275307358265644

Epoch: 6| Step: 1
Training loss: 2.736249009049865
Validation loss: 2.7273031001623105

Epoch: 6| Step: 2
Training loss: 3.310455843143705
Validation loss: 2.727814581256103

Epoch: 6| Step: 3
Training loss: 3.2818858665877753
Validation loss: 2.7280012690865623

Epoch: 6| Step: 4
Training loss: 2.7105113637235974
Validation loss: 2.7267367145743124

Epoch: 6| Step: 5
Training loss: 3.050931294325605
Validation loss: 2.724176511569972

Epoch: 6| Step: 6
Training loss: 3.3022630965502873
Validation loss: 2.7258546846436196

Epoch: 6| Step: 7
Training loss: 2.1041303071257813
Validation loss: 2.7242215498640876

Epoch: 6| Step: 8
Training loss: 3.342367011016014
Validation loss: 2.7245038713127383

Epoch: 6| Step: 9
Training loss: 2.753193128524423
Validation loss: 2.7209093426947795

Epoch: 6| Step: 10
Training loss: 3.4466068665010106
Validation loss: 2.723463774295787

Epoch: 6| Step: 11
Training loss: 3.1718868762766426
Validation loss: 2.7256486435866103

Epoch: 6| Step: 12
Training loss: 2.797032868602368
Validation loss: 2.7289685256698895

Epoch: 6| Step: 13
Training loss: 3.1220496937366535
Validation loss: 2.725248687420856

Epoch: 46| Step: 0
Training loss: 3.2415082472767343
Validation loss: 2.7270957725452596

Epoch: 6| Step: 1
Training loss: 3.075116076255706
Validation loss: 2.7260018806109465

Epoch: 6| Step: 2
Training loss: 3.3086884360067725
Validation loss: 2.7350477590498663

Epoch: 6| Step: 3
Training loss: 2.913785292298363
Validation loss: 2.7499978204384794

Epoch: 6| Step: 4
Training loss: 3.023765684152575
Validation loss: 2.741614244742046

Epoch: 6| Step: 5
Training loss: 3.3261532382588572
Validation loss: 2.74089233001608

Epoch: 6| Step: 6
Training loss: 2.7002590620300113
Validation loss: 2.7442311404212543

Epoch: 6| Step: 7
Training loss: 2.975675195319878
Validation loss: 2.7285422354673745

Epoch: 6| Step: 8
Training loss: 3.0490264339333333
Validation loss: 2.72590299345434

Epoch: 6| Step: 9
Training loss: 2.77815297030088
Validation loss: 2.720017308117366

Epoch: 6| Step: 10
Training loss: 2.761928868697496
Validation loss: 2.718745387093102

Epoch: 6| Step: 11
Training loss: 2.8889719592483485
Validation loss: 2.721153265442841

Epoch: 6| Step: 12
Training loss: 3.251942714181909
Validation loss: 2.7187776027848702

Epoch: 6| Step: 13
Training loss: 3.5401427786530744
Validation loss: 2.7230134810463604

Epoch: 47| Step: 0
Training loss: 2.9422476528863997
Validation loss: 2.723054954450014

Epoch: 6| Step: 1
Training loss: 3.1179013307336905
Validation loss: 2.725771903287334

Epoch: 6| Step: 2
Training loss: 3.000429122751327
Validation loss: 2.734373299265624

Epoch: 6| Step: 3
Training loss: 2.964420896589455
Validation loss: 2.7444705747693616

Epoch: 6| Step: 4
Training loss: 3.10150238670689
Validation loss: 2.7668664703196524

Epoch: 6| Step: 5
Training loss: 3.2532693118169544
Validation loss: 2.7461320583278614

Epoch: 6| Step: 6
Training loss: 2.8133897857365615
Validation loss: 2.733896474380174

Epoch: 6| Step: 7
Training loss: 2.9405894164832
Validation loss: 2.721432605305182

Epoch: 6| Step: 8
Training loss: 3.1331305972585213
Validation loss: 2.7199823690864853

Epoch: 6| Step: 9
Training loss: 2.603399138194892
Validation loss: 2.713221417581321

Epoch: 6| Step: 10
Training loss: 2.9315807684595616
Validation loss: 2.714440001243769

Epoch: 6| Step: 11
Training loss: 3.249812194092914
Validation loss: 2.7160405618672936

Epoch: 6| Step: 12
Training loss: 3.3989408975228614
Validation loss: 2.7117605033123255

Epoch: 6| Step: 13
Training loss: 3.3091857452598306
Validation loss: 2.7135834627607522

Epoch: 48| Step: 0
Training loss: 3.107999411093166
Validation loss: 2.7100800162887646

Epoch: 6| Step: 1
Training loss: 2.9949619587566407
Validation loss: 2.7367867330259226

Epoch: 6| Step: 2
Training loss: 3.222368299162021
Validation loss: 2.7818889771104773

Epoch: 6| Step: 3
Training loss: 3.0355502428883647
Validation loss: 2.8529861112864077

Epoch: 6| Step: 4
Training loss: 3.129538940011896
Validation loss: 2.9139242988701595

Epoch: 6| Step: 5
Training loss: 3.2525914937432425
Validation loss: 2.8518229910755917

Epoch: 6| Step: 6
Training loss: 3.4398903598612285
Validation loss: 2.7892952882725046

Epoch: 6| Step: 7
Training loss: 3.1682359086545597
Validation loss: 2.7227665217720807

Epoch: 6| Step: 8
Training loss: 2.875563690652924
Validation loss: 2.7121465878718762

Epoch: 6| Step: 9
Training loss: 2.6953832644696027
Validation loss: 2.7214945065395653

Epoch: 6| Step: 10
Training loss: 3.1546823366452608
Validation loss: 2.7363439303020844

Epoch: 6| Step: 11
Training loss: 2.8753719918458724
Validation loss: 2.734136322433483

Epoch: 6| Step: 12
Training loss: 2.608872051079978
Validation loss: 2.7352819913826885

Epoch: 6| Step: 13
Training loss: 3.724143980862952
Validation loss: 2.740541410771585

Epoch: 49| Step: 0
Training loss: 3.3298604675935866
Validation loss: 2.7374491025836485

Epoch: 6| Step: 1
Training loss: 3.329977603413182
Validation loss: 2.7224079908173366

Epoch: 6| Step: 2
Training loss: 3.2538756223704883
Validation loss: 2.708444643849049

Epoch: 6| Step: 3
Training loss: 2.8789844269405847
Validation loss: 2.7077377598444805

Epoch: 6| Step: 4
Training loss: 2.4500062397468674
Validation loss: 2.709429693324667

Epoch: 6| Step: 5
Training loss: 2.9860408587410188
Validation loss: 2.7096225904009663

Epoch: 6| Step: 6
Training loss: 2.696080283676028
Validation loss: 2.7140480431748637

Epoch: 6| Step: 7
Training loss: 2.4060530148418366
Validation loss: 2.71693614687873

Epoch: 6| Step: 8
Training loss: 3.441031843725968
Validation loss: 2.7251690165169014

Epoch: 6| Step: 9
Training loss: 2.9810782393073936
Validation loss: 2.731553786943556

Epoch: 6| Step: 10
Training loss: 3.009398678758739
Validation loss: 2.7318466849958982

Epoch: 6| Step: 11
Training loss: 2.890867810747968
Validation loss: 2.730890255978589

Epoch: 6| Step: 12
Training loss: 3.4624458281207664
Validation loss: 2.722716259097526

Epoch: 6| Step: 13
Training loss: 3.3535365268986785
Validation loss: 2.712759329402854

Epoch: 50| Step: 0
Training loss: 2.5012661588605356
Validation loss: 2.708605434736177

Epoch: 6| Step: 1
Training loss: 3.346318622009465
Validation loss: 2.7116079744583836

Epoch: 6| Step: 2
Training loss: 3.10460384968462
Validation loss: 2.704306425923009

Epoch: 6| Step: 3
Training loss: 3.303578147734065
Validation loss: 2.7010006376264823

Epoch: 6| Step: 4
Training loss: 2.9550697341668712
Validation loss: 2.7005355887877593

Epoch: 6| Step: 5
Training loss: 2.872461608152077
Validation loss: 2.6924547775150973

Epoch: 6| Step: 6
Training loss: 2.5454481375601232
Validation loss: 2.6872229226995885

Epoch: 6| Step: 7
Training loss: 2.8516609906471375
Validation loss: 2.692601353390274

Epoch: 6| Step: 8
Training loss: 2.8439676390146733
Validation loss: 2.6912806962205362

Epoch: 6| Step: 9
Training loss: 3.4815572113416042
Validation loss: 2.697938638580956

Epoch: 6| Step: 10
Training loss: 3.087527558362033
Validation loss: 2.691778813280628

Epoch: 6| Step: 11
Training loss: 3.0297536401085448
Validation loss: 2.692395177517594

Epoch: 6| Step: 12
Training loss: 3.339909139071148
Validation loss: 2.688815305121598

Epoch: 6| Step: 13
Training loss: 2.878052956407379
Validation loss: 2.686088103376937

Epoch: 51| Step: 0
Training loss: 3.3062385544461623
Validation loss: 2.688534913449076

Epoch: 6| Step: 1
Training loss: 3.6189216428117814
Validation loss: 2.6921313502245625

Epoch: 6| Step: 2
Training loss: 2.536844922526741
Validation loss: 2.701716114497644

Epoch: 6| Step: 3
Training loss: 3.383450137472647
Validation loss: 2.7071381732921846

Epoch: 6| Step: 4
Training loss: 3.7240270790566057
Validation loss: 2.714499039778626

Epoch: 6| Step: 5
Training loss: 3.6491463276906884
Validation loss: 2.707659995636028

Epoch: 6| Step: 6
Training loss: 2.168069263224577
Validation loss: 2.6981498670371904

Epoch: 6| Step: 7
Training loss: 2.930308527928016
Validation loss: 2.6900982508199074

Epoch: 6| Step: 8
Training loss: 2.657276269461121
Validation loss: 2.694418334545471

Epoch: 6| Step: 9
Training loss: 3.045860865129759
Validation loss: 2.68672463368285

Epoch: 6| Step: 10
Training loss: 2.64795655691462
Validation loss: 2.6810115491039963

Epoch: 6| Step: 11
Training loss: 2.5941000093285607
Validation loss: 2.684566019024258

Epoch: 6| Step: 12
Training loss: 2.8339492091094383
Validation loss: 2.6823389931858417

Epoch: 6| Step: 13
Training loss: 2.5387296957371372
Validation loss: 2.6871640156813577

Epoch: 52| Step: 0
Training loss: 3.185232215931702
Validation loss: 2.686242628135757

Epoch: 6| Step: 1
Training loss: 2.5011165033085843
Validation loss: 2.6919346341663535

Epoch: 6| Step: 2
Training loss: 3.648381561569298
Validation loss: 2.702158307240853

Epoch: 6| Step: 3
Training loss: 3.3104100381934076
Validation loss: 2.702561865565159

Epoch: 6| Step: 4
Training loss: 2.799711014957249
Validation loss: 2.6799611368332275

Epoch: 6| Step: 5
Training loss: 2.9136419325155734
Validation loss: 2.680296657252467

Epoch: 6| Step: 6
Training loss: 2.779466292792956
Validation loss: 2.6822336389939507

Epoch: 6| Step: 7
Training loss: 3.032978784010903
Validation loss: 2.697488260853858

Epoch: 6| Step: 8
Training loss: 2.836051329122669
Validation loss: 2.734741362655403

Epoch: 6| Step: 9
Training loss: 2.913331131777888
Validation loss: 2.7501004779615803

Epoch: 6| Step: 10
Training loss: 3.4128005010741305
Validation loss: 2.743105378292758

Epoch: 6| Step: 11
Training loss: 3.315597381620585
Validation loss: 2.697262803085481

Epoch: 6| Step: 12
Training loss: 2.8213768638715213
Validation loss: 2.6802854540203773

Epoch: 6| Step: 13
Training loss: 2.5423606696347423
Validation loss: 2.6745730857072005

Epoch: 53| Step: 0
Training loss: 3.115650381216357
Validation loss: 2.6783178330522657

Epoch: 6| Step: 1
Training loss: 2.9879794897169623
Validation loss: 2.6725790519483597

Epoch: 6| Step: 2
Training loss: 3.2172593303737504
Validation loss: 2.671577688938187

Epoch: 6| Step: 3
Training loss: 3.12983207959078
Validation loss: 2.6691754394260863

Epoch: 6| Step: 4
Training loss: 2.81456714534175
Validation loss: 2.670907830497799

Epoch: 6| Step: 5
Training loss: 2.5761490156361178
Validation loss: 2.6714262082592795

Epoch: 6| Step: 6
Training loss: 2.756109127674578
Validation loss: 2.668484881903581

Epoch: 6| Step: 7
Training loss: 3.3695646245883673
Validation loss: 2.674981538810275

Epoch: 6| Step: 8
Training loss: 3.3683489502386372
Validation loss: 2.6700494393707497

Epoch: 6| Step: 9
Training loss: 3.246973682772722
Validation loss: 2.6753501646035143

Epoch: 6| Step: 10
Training loss: 2.9373824725076103
Validation loss: 2.6955987384472575

Epoch: 6| Step: 11
Training loss: 2.8159340133196666
Validation loss: 2.6921570481073918

Epoch: 6| Step: 12
Training loss: 2.8561478210469757
Validation loss: 2.7245345698576786

Epoch: 6| Step: 13
Training loss: 2.6925852370517562
Validation loss: 2.790627116265308

Epoch: 54| Step: 0
Training loss: 3.8828212192982456
Validation loss: 2.8544124883342534

Epoch: 6| Step: 1
Training loss: 2.54185853035935
Validation loss: 2.7960320657197077

Epoch: 6| Step: 2
Training loss: 3.0928608551053456
Validation loss: 2.754030276155642

Epoch: 6| Step: 3
Training loss: 2.576921586738094
Validation loss: 2.7442853436134595

Epoch: 6| Step: 4
Training loss: 2.735264747819052
Validation loss: 2.738040448591355

Epoch: 6| Step: 5
Training loss: 3.3540138225600424
Validation loss: 2.7403790286046794

Epoch: 6| Step: 6
Training loss: 3.089815971548647
Validation loss: 2.708268531295412

Epoch: 6| Step: 7
Training loss: 2.9013923328071423
Validation loss: 2.695901280850438

Epoch: 6| Step: 8
Training loss: 3.3205928190493146
Validation loss: 2.6804492778545845

Epoch: 6| Step: 9
Training loss: 2.354504541327503
Validation loss: 2.6829806306270454

Epoch: 6| Step: 10
Training loss: 2.89478361648661
Validation loss: 2.6804625835643003

Epoch: 6| Step: 11
Training loss: 3.4564939609399232
Validation loss: 2.674253414417182

Epoch: 6| Step: 12
Training loss: 2.80753761775834
Validation loss: 2.6870959112393495

Epoch: 6| Step: 13
Training loss: 3.3435968381795345
Validation loss: 2.682240344778247

Epoch: 55| Step: 0
Training loss: 2.801157991191102
Validation loss: 2.681028887254484

Epoch: 6| Step: 1
Training loss: 2.7494357137009793
Validation loss: 2.6788195031761273

Epoch: 6| Step: 2
Training loss: 3.4359635127020947
Validation loss: 2.6772689320876206

Epoch: 6| Step: 3
Training loss: 2.398371493645887
Validation loss: 2.6720184516021575

Epoch: 6| Step: 4
Training loss: 3.2656743534136936
Validation loss: 2.672835141961309

Epoch: 6| Step: 5
Training loss: 2.982394375077866
Validation loss: 2.6665870984060898

Epoch: 6| Step: 6
Training loss: 3.4682204383564206
Validation loss: 2.6660911903038014

Epoch: 6| Step: 7
Training loss: 2.385525119320622
Validation loss: 2.669808039277475

Epoch: 6| Step: 8
Training loss: 3.636028088997258
Validation loss: 2.6683197633763927

Epoch: 6| Step: 9
Training loss: 3.030288071739961
Validation loss: 2.6654893018654526

Epoch: 6| Step: 10
Training loss: 2.6862912675715114
Validation loss: 2.6762837212967914

Epoch: 6| Step: 11
Training loss: 2.687569373366521
Validation loss: 2.696509816686436

Epoch: 6| Step: 12
Training loss: 2.664854765293032
Validation loss: 2.704934881805411

Epoch: 6| Step: 13
Training loss: 3.9492977145759083
Validation loss: 2.7050006634280352

Epoch: 56| Step: 0
Training loss: 2.798949085291775
Validation loss: 2.7197988521622882

Epoch: 6| Step: 1
Training loss: 3.057901939990419
Validation loss: 2.722430101403952

Epoch: 6| Step: 2
Training loss: 3.12907814953829
Validation loss: 2.7286099292895627

Epoch: 6| Step: 3
Training loss: 2.846530602871414
Validation loss: 2.711260092771863

Epoch: 6| Step: 4
Training loss: 2.5453327400615806
Validation loss: 2.6787890013750846

Epoch: 6| Step: 5
Training loss: 3.0157163932273012
Validation loss: 2.677745915374549

Epoch: 6| Step: 6
Training loss: 3.4374239826466866
Validation loss: 2.6696846458680605

Epoch: 6| Step: 7
Training loss: 3.474993748281879
Validation loss: 2.6538856131780526

Epoch: 6| Step: 8
Training loss: 2.925160891028615
Validation loss: 2.651620842015552

Epoch: 6| Step: 9
Training loss: 3.0747510359548573
Validation loss: 2.6559911033512504

Epoch: 6| Step: 10
Training loss: 2.940080523783001
Validation loss: 2.6548012253969837

Epoch: 6| Step: 11
Training loss: 2.8268862377063986
Validation loss: 2.6588718868130874

Epoch: 6| Step: 12
Training loss: 2.752844293250321
Validation loss: 2.665986444126581

Epoch: 6| Step: 13
Training loss: 3.3189391403755946
Validation loss: 2.659490792683782

Epoch: 57| Step: 0
Training loss: 3.355749542602335
Validation loss: 2.6564514537377164

Epoch: 6| Step: 1
Training loss: 2.9144201800635945
Validation loss: 2.6518377614952016

Epoch: 6| Step: 2
Training loss: 3.1535161330592305
Validation loss: 2.6577993247799965

Epoch: 6| Step: 3
Training loss: 2.696372622556391
Validation loss: 2.6593058622477685

Epoch: 6| Step: 4
Training loss: 3.6174565456182104
Validation loss: 2.6728477585454002

Epoch: 6| Step: 5
Training loss: 2.724202093495197
Validation loss: 2.6864334836721877

Epoch: 6| Step: 6
Training loss: 2.493700100583547
Validation loss: 2.691750269807133

Epoch: 6| Step: 7
Training loss: 3.4102138588704993
Validation loss: 2.6896576772901306

Epoch: 6| Step: 8
Training loss: 3.4373191092319906
Validation loss: 2.705147953567813

Epoch: 6| Step: 9
Training loss: 2.762127922857927
Validation loss: 2.6928736998765466

Epoch: 6| Step: 10
Training loss: 2.551872078592355
Validation loss: 2.691920201870835

Epoch: 6| Step: 11
Training loss: 2.7726736816821367
Validation loss: 2.6794052786205467

Epoch: 6| Step: 12
Training loss: 2.8340740544584904
Validation loss: 2.6607168088663915

Epoch: 6| Step: 13
Training loss: 2.8688682182736804
Validation loss: 2.648548391667258

Epoch: 58| Step: 0
Training loss: 2.640104344068772
Validation loss: 2.6423096214762185

Epoch: 6| Step: 1
Training loss: 3.603822871810133
Validation loss: 2.6483172409560054

Epoch: 6| Step: 2
Training loss: 3.3569861146459603
Validation loss: 2.6478072530420955

Epoch: 6| Step: 3
Training loss: 2.5530923418736804
Validation loss: 2.6519545315854507

Epoch: 6| Step: 4
Training loss: 3.1689942154836057
Validation loss: 2.6528030160510374

Epoch: 6| Step: 5
Training loss: 2.9800508338637632
Validation loss: 2.6481908427508154

Epoch: 6| Step: 6
Training loss: 2.8624589475661417
Validation loss: 2.648249106519221

Epoch: 6| Step: 7
Training loss: 2.6356000773622217
Validation loss: 2.6491776281387183

Epoch: 6| Step: 8
Training loss: 3.235634084168935
Validation loss: 2.6489109771966595

Epoch: 6| Step: 9
Training loss: 3.1285526680679356
Validation loss: 2.650473590230929

Epoch: 6| Step: 10
Training loss: 3.2778479969096685
Validation loss: 2.648077210871225

Epoch: 6| Step: 11
Training loss: 2.7519247948384296
Validation loss: 2.644908465944341

Epoch: 6| Step: 12
Training loss: 2.900661386509465
Validation loss: 2.647582766313735

Epoch: 6| Step: 13
Training loss: 2.3878346033949183
Validation loss: 2.647719778419895

Epoch: 59| Step: 0
Training loss: 2.5228017472655
Validation loss: 2.650073606846812

Epoch: 6| Step: 1
Training loss: 3.1733005871672657
Validation loss: 2.64746458232685

Epoch: 6| Step: 2
Training loss: 2.4728627774013128
Validation loss: 2.644714693247596

Epoch: 6| Step: 3
Training loss: 3.4013063445606218
Validation loss: 2.645061447828904

Epoch: 6| Step: 4
Training loss: 3.4240618123865616
Validation loss: 2.644973786441647

Epoch: 6| Step: 5
Training loss: 2.82037471797715
Validation loss: 2.651381675680479

Epoch: 6| Step: 6
Training loss: 3.1219374336361345
Validation loss: 2.651776991451428

Epoch: 6| Step: 7
Training loss: 3.0824127541328434
Validation loss: 2.657879872130812

Epoch: 6| Step: 8
Training loss: 2.689933828085963
Validation loss: 2.659207061219003

Epoch: 6| Step: 9
Training loss: 3.0020439814243645
Validation loss: 2.660944493142424

Epoch: 6| Step: 10
Training loss: 3.2549075707410466
Validation loss: 2.663284204910268

Epoch: 6| Step: 11
Training loss: 2.8464064713977586
Validation loss: 2.655417036775992

Epoch: 6| Step: 12
Training loss: 2.9888677682173683
Validation loss: 2.646003131167416

Epoch: 6| Step: 13
Training loss: 2.7203621304896517
Validation loss: 2.646857971066117

Epoch: 60| Step: 0
Training loss: 3.208440176105433
Validation loss: 2.645205970731207

Epoch: 6| Step: 1
Training loss: 3.1353992617980553
Validation loss: 2.643785452679548

Epoch: 6| Step: 2
Training loss: 3.1572356243103794
Validation loss: 2.648247127821898

Epoch: 6| Step: 3
Training loss: 2.6624449352605732
Validation loss: 2.652194170165543

Epoch: 6| Step: 4
Training loss: 2.911744533022418
Validation loss: 2.6458286391618624

Epoch: 6| Step: 5
Training loss: 3.7064364149999256
Validation loss: 2.650687786258862

Epoch: 6| Step: 6
Training loss: 3.2352087448198135
Validation loss: 2.652561884179405

Epoch: 6| Step: 7
Training loss: 3.0159298441288436
Validation loss: 2.6608593484253666

Epoch: 6| Step: 8
Training loss: 2.459746057227482
Validation loss: 2.663747373631137

Epoch: 6| Step: 9
Training loss: 2.968962169895732
Validation loss: 2.6587777509388064

Epoch: 6| Step: 10
Training loss: 3.1871786516554668
Validation loss: 2.658213398047618

Epoch: 6| Step: 11
Training loss: 2.8186737117889815
Validation loss: 2.655628650432931

Epoch: 6| Step: 12
Training loss: 2.1722027647941604
Validation loss: 2.6639381018542663

Epoch: 6| Step: 13
Training loss: 2.793995659116897
Validation loss: 2.6618517590161668

Epoch: 61| Step: 0
Training loss: 3.123921780543583
Validation loss: 2.656122179231384

Epoch: 6| Step: 1
Training loss: 2.9443558573642084
Validation loss: 2.6430556897424933

Epoch: 6| Step: 2
Training loss: 2.439259896364161
Validation loss: 2.6408458427325234

Epoch: 6| Step: 3
Training loss: 3.1607502495764757
Validation loss: 2.637012036904439

Epoch: 6| Step: 4
Training loss: 3.4596504246514583
Validation loss: 2.642147515796089

Epoch: 6| Step: 5
Training loss: 3.060071644162474
Validation loss: 2.6388008567865735

Epoch: 6| Step: 6
Training loss: 2.880851099034723
Validation loss: 2.6431290152562914

Epoch: 6| Step: 7
Training loss: 2.589465359624231
Validation loss: 2.6384730775866783

Epoch: 6| Step: 8
Training loss: 3.1536960655556787
Validation loss: 2.647709703814652

Epoch: 6| Step: 9
Training loss: 3.7453047286403782
Validation loss: 2.6498387792871543

Epoch: 6| Step: 10
Training loss: 3.175452709212856
Validation loss: 2.656402654924091

Epoch: 6| Step: 11
Training loss: 2.4757043934307554
Validation loss: 2.646573588523402

Epoch: 6| Step: 12
Training loss: 2.3163333772000643
Validation loss: 2.6589607097783143

Epoch: 6| Step: 13
Training loss: 3.2757726092853483
Validation loss: 2.667409651704422

Epoch: 62| Step: 0
Training loss: 2.976896812908467
Validation loss: 2.667839381428171

Epoch: 6| Step: 1
Training loss: 3.4145158340147295
Validation loss: 2.6761482520621724

Epoch: 6| Step: 2
Training loss: 3.01882622348126
Validation loss: 2.672282175134552

Epoch: 6| Step: 3
Training loss: 2.4942417587292476
Validation loss: 2.6257149835497193

Epoch: 6| Step: 4
Training loss: 2.5625666167741423
Validation loss: 2.628900689552813

Epoch: 6| Step: 5
Training loss: 2.2592956529035777
Validation loss: 2.6316005326860834

Epoch: 6| Step: 6
Training loss: 2.908110976440539
Validation loss: 2.6371720571309925

Epoch: 6| Step: 7
Training loss: 3.058020916884086
Validation loss: 2.6455665772362207

Epoch: 6| Step: 8
Training loss: 3.40314012704505
Validation loss: 2.645566890233778

Epoch: 6| Step: 9
Training loss: 3.140737958556302
Validation loss: 2.6353255397248203

Epoch: 6| Step: 10
Training loss: 2.957396632086663
Validation loss: 2.629047436754971

Epoch: 6| Step: 11
Training loss: 2.6093561777132708
Validation loss: 2.6289366801239478

Epoch: 6| Step: 12
Training loss: 3.855407281480299
Validation loss: 2.629210545141353

Epoch: 6| Step: 13
Training loss: 2.421066247587521
Validation loss: 2.625275300058914

Epoch: 63| Step: 0
Training loss: 2.9170667283119043
Validation loss: 2.6304932155632548

Epoch: 6| Step: 1
Training loss: 3.8825694570328144
Validation loss: 2.6297135222196104

Epoch: 6| Step: 2
Training loss: 2.9579283387825757
Validation loss: 2.6307380609869546

Epoch: 6| Step: 3
Training loss: 3.273533057226979
Validation loss: 2.6369517622564462

Epoch: 6| Step: 4
Training loss: 2.9827705584175592
Validation loss: 2.642127399735322

Epoch: 6| Step: 5
Training loss: 2.8160042866110686
Validation loss: 2.659937237017541

Epoch: 6| Step: 6
Training loss: 2.198405411844658
Validation loss: 2.6612381090366424

Epoch: 6| Step: 7
Training loss: 3.1544726815847914
Validation loss: 2.6792229944280472

Epoch: 6| Step: 8
Training loss: 2.4901020568400414
Validation loss: 2.680837534109898

Epoch: 6| Step: 9
Training loss: 2.893885737422071
Validation loss: 2.6524357501043907

Epoch: 6| Step: 10
Training loss: 3.1538611710496838
Validation loss: 2.6371784915676915

Epoch: 6| Step: 11
Training loss: 2.6140649187860054
Validation loss: 2.634840527821076

Epoch: 6| Step: 12
Training loss: 3.14130876224323
Validation loss: 2.6273484640965368

Epoch: 6| Step: 13
Training loss: 2.507643364167203
Validation loss: 2.632917557205638

Epoch: 64| Step: 0
Training loss: 2.857925631378421
Validation loss: 2.627882025293904

Epoch: 6| Step: 1
Training loss: 2.9021958817900795
Validation loss: 2.6316784665423394

Epoch: 6| Step: 2
Training loss: 2.748809990464597
Validation loss: 2.6317580385045396

Epoch: 6| Step: 3
Training loss: 2.9709525520904
Validation loss: 2.663489653310777

Epoch: 6| Step: 4
Training loss: 3.210916115348498
Validation loss: 2.8210472786183134

Epoch: 6| Step: 5
Training loss: 3.119909641962605
Validation loss: 2.7570353974871002

Epoch: 6| Step: 6
Training loss: 3.1196736529429963
Validation loss: 2.7455842950519957

Epoch: 6| Step: 7
Training loss: 2.659079267866118
Validation loss: 2.701285560604918

Epoch: 6| Step: 8
Training loss: 3.6429594356803108
Validation loss: 2.682852146471295

Epoch: 6| Step: 9
Training loss: 3.153308063860153
Validation loss: 2.67569564324308

Epoch: 6| Step: 10
Training loss: 2.702232786901775
Validation loss: 2.6687755289451585

Epoch: 6| Step: 11
Training loss: 3.675915252480722
Validation loss: 2.7290095760245823

Epoch: 6| Step: 12
Training loss: 2.6050845753711003
Validation loss: 2.711205711571299

Epoch: 6| Step: 13
Training loss: 2.331197567265746
Validation loss: 2.671942513747561

Epoch: 65| Step: 0
Training loss: 2.932268069202249
Validation loss: 2.6276330550638676

Epoch: 6| Step: 1
Training loss: 3.2158570853690103
Validation loss: 2.613429443203189

Epoch: 6| Step: 2
Training loss: 3.307091958732134
Validation loss: 2.6135988907399708

Epoch: 6| Step: 3
Training loss: 2.6364528945832593
Validation loss: 2.6094963738636965

Epoch: 6| Step: 4
Training loss: 2.921614854624861
Validation loss: 2.6106359844007168

Epoch: 6| Step: 5
Training loss: 2.885063471104198
Validation loss: 2.6110706033475832

Epoch: 6| Step: 6
Training loss: 2.98362362974777
Validation loss: 2.614548604535437

Epoch: 6| Step: 7
Training loss: 2.9074087806621027
Validation loss: 2.610792880461324

Epoch: 6| Step: 8
Training loss: 3.0143230572804143
Validation loss: 2.612056061953542

Epoch: 6| Step: 9
Training loss: 2.4310598147027056
Validation loss: 2.610238698459796

Epoch: 6| Step: 10
Training loss: 3.134585822822474
Validation loss: 2.6091534763263646

Epoch: 6| Step: 11
Training loss: 3.18364377596815
Validation loss: 2.6086111097010605

Epoch: 6| Step: 12
Training loss: 3.0265696464930794
Validation loss: 2.6094831896552093

Epoch: 6| Step: 13
Training loss: 2.759388935058245
Validation loss: 2.6072344017681144

Epoch: 66| Step: 0
Training loss: 2.692617644818693
Validation loss: 2.611583356611124

Epoch: 6| Step: 1
Training loss: 2.5867064102141204
Validation loss: 2.6081532661467968

Epoch: 6| Step: 2
Training loss: 3.485661153812748
Validation loss: 2.6124666577983824

Epoch: 6| Step: 3
Training loss: 2.615429005634526
Validation loss: 2.6218649752573846

Epoch: 6| Step: 4
Training loss: 2.8369256602065
Validation loss: 2.6043375224188643

Epoch: 6| Step: 5
Training loss: 2.5071952274055556
Validation loss: 2.606541321653507

Epoch: 6| Step: 6
Training loss: 2.6429135489612054
Validation loss: 2.6032706063234863

Epoch: 6| Step: 7
Training loss: 3.1419171004987145
Validation loss: 2.5992497908680035

Epoch: 6| Step: 8
Training loss: 2.2862490918140472
Validation loss: 2.60135282399322

Epoch: 6| Step: 9
Training loss: 3.3107806367966743
Validation loss: 2.602554389889855

Epoch: 6| Step: 10
Training loss: 3.235246623807513
Validation loss: 2.59687272347131

Epoch: 6| Step: 11
Training loss: 3.259531861843664
Validation loss: 2.599551074315277

Epoch: 6| Step: 12
Training loss: 2.9845755145233115
Validation loss: 2.5956542517732117

Epoch: 6| Step: 13
Training loss: 3.8544242704065192
Validation loss: 2.5958705713430974

Epoch: 67| Step: 0
Training loss: 2.6449506193285583
Validation loss: 2.591931475164744

Epoch: 6| Step: 1
Training loss: 3.5131260107012143
Validation loss: 2.601550012684358

Epoch: 6| Step: 2
Training loss: 2.256792834805835
Validation loss: 2.60296403117625

Epoch: 6| Step: 3
Training loss: 2.596117983948027
Validation loss: 2.6135671285012694

Epoch: 6| Step: 4
Training loss: 2.9819706523635703
Validation loss: 2.6337221622074853

Epoch: 6| Step: 5
Training loss: 2.880122720964748
Validation loss: 2.6509808632230216

Epoch: 6| Step: 6
Training loss: 2.740399160616803
Validation loss: 2.606155514823542

Epoch: 6| Step: 7
Training loss: 3.1825619014164763
Validation loss: 2.597518405283963

Epoch: 6| Step: 8
Training loss: 3.488900705251371
Validation loss: 2.5945870227193626

Epoch: 6| Step: 9
Training loss: 2.7526993074940145
Validation loss: 2.5972893844977425

Epoch: 6| Step: 10
Training loss: 2.8806327704839836
Validation loss: 2.605639093040026

Epoch: 6| Step: 11
Training loss: 3.032303145419774
Validation loss: 2.6030006531739667

Epoch: 6| Step: 12
Training loss: 3.424598480969612
Validation loss: 2.6023614571747915

Epoch: 6| Step: 13
Training loss: 2.8346512665113455
Validation loss: 2.5990129960296056

Epoch: 68| Step: 0
Training loss: 3.607202974544203
Validation loss: 2.5963727379524304

Epoch: 6| Step: 1
Training loss: 2.98055322209915
Validation loss: 2.5969805149208494

Epoch: 6| Step: 2
Training loss: 2.977267284507462
Validation loss: 2.6249960974035833

Epoch: 6| Step: 3
Training loss: 3.062562280138408
Validation loss: 2.666871806747596

Epoch: 6| Step: 4
Training loss: 2.348757265088842
Validation loss: 2.7025923381062453

Epoch: 6| Step: 5
Training loss: 3.114300684186721
Validation loss: 2.7065070776393294

Epoch: 6| Step: 6
Training loss: 2.744696444766447
Validation loss: 2.6399632563011886

Epoch: 6| Step: 7
Training loss: 2.536068415714724
Validation loss: 2.612049017972397

Epoch: 6| Step: 8
Training loss: 3.308226942246225
Validation loss: 2.5989846835209445

Epoch: 6| Step: 9
Training loss: 2.891244522927354
Validation loss: 2.5940091443124365

Epoch: 6| Step: 10
Training loss: 2.8148044046642626
Validation loss: 2.591313444889737

Epoch: 6| Step: 11
Training loss: 2.9035159140404136
Validation loss: 2.591104388986408

Epoch: 6| Step: 12
Training loss: 2.8688226761265856
Validation loss: 2.5940857348876807

Epoch: 6| Step: 13
Training loss: 3.222799328026495
Validation loss: 2.5943433406885297

Epoch: 69| Step: 0
Training loss: 2.9406511976512206
Validation loss: 2.603563265061549

Epoch: 6| Step: 1
Training loss: 2.7789372461460116
Validation loss: 2.596608606573719

Epoch: 6| Step: 2
Training loss: 3.112368269128154
Validation loss: 2.606995959305817

Epoch: 6| Step: 3
Training loss: 2.619751178486731
Validation loss: 2.5971019310416623

Epoch: 6| Step: 4
Training loss: 2.932711655311214
Validation loss: 2.6016015205042486

Epoch: 6| Step: 5
Training loss: 3.816476467896125
Validation loss: 2.5985463442817602

Epoch: 6| Step: 6
Training loss: 2.9283537002865505
Validation loss: 2.5935952646609275

Epoch: 6| Step: 7
Training loss: 2.898992192331875
Validation loss: 2.5919874102872114

Epoch: 6| Step: 8
Training loss: 2.2600197743926382
Validation loss: 2.5888404603591657

Epoch: 6| Step: 9
Training loss: 2.6043219151315142
Validation loss: 2.585587323687965

Epoch: 6| Step: 10
Training loss: 2.9980847284866
Validation loss: 2.58782550812654

Epoch: 6| Step: 11
Training loss: 2.7765464872414776
Validation loss: 2.599301436979527

Epoch: 6| Step: 12
Training loss: 3.321150514651029
Validation loss: 2.6282624511079224

Epoch: 6| Step: 13
Training loss: 3.1399233209759894
Validation loss: 2.699720946171436

Epoch: 70| Step: 0
Training loss: 3.4846426685655865
Validation loss: 2.71852983717901

Epoch: 6| Step: 1
Training loss: 3.011492016838243
Validation loss: 2.712752100853998

Epoch: 6| Step: 2
Training loss: 2.510046988423571
Validation loss: 2.6775852101776145

Epoch: 6| Step: 3
Training loss: 2.3893159760557117
Validation loss: 2.620896806096178

Epoch: 6| Step: 4
Training loss: 2.3761683150312907
Validation loss: 2.595858972141324

Epoch: 6| Step: 5
Training loss: 3.337740765863188
Validation loss: 2.586641143604826

Epoch: 6| Step: 6
Training loss: 3.5944226506191757
Validation loss: 2.5772706327420454

Epoch: 6| Step: 7
Training loss: 2.553960574258766
Validation loss: 2.5795170481009135

Epoch: 6| Step: 8
Training loss: 2.8789135377706265
Validation loss: 2.5802342472254463

Epoch: 6| Step: 9
Training loss: 2.9064796931241355
Validation loss: 2.581054218684482

Epoch: 6| Step: 10
Training loss: 3.190777010383627
Validation loss: 2.5820136789877606

Epoch: 6| Step: 11
Training loss: 2.784490005395768
Validation loss: 2.5763530490080164

Epoch: 6| Step: 12
Training loss: 2.99981625312122
Validation loss: 2.5816092644388644

Epoch: 6| Step: 13
Training loss: 2.9342004628624485
Validation loss: 2.573593315381731

Epoch: 71| Step: 0
Training loss: 2.550404542735133
Validation loss: 2.579892426928888

Epoch: 6| Step: 1
Training loss: 2.5306619031631503
Validation loss: 2.578583741105595

Epoch: 6| Step: 2
Training loss: 3.183836383583748
Validation loss: 2.5797294469339866

Epoch: 6| Step: 3
Training loss: 3.0938091850399405
Validation loss: 2.578381363747166

Epoch: 6| Step: 4
Training loss: 2.8972073229606465
Validation loss: 2.5778138351723885

Epoch: 6| Step: 5
Training loss: 3.2258907477839642
Validation loss: 2.5736359783984772

Epoch: 6| Step: 6
Training loss: 2.841339598894782
Validation loss: 2.572752935201714

Epoch: 6| Step: 7
Training loss: 2.7646370540210716
Validation loss: 2.57581239893896

Epoch: 6| Step: 8
Training loss: 2.736380490136212
Validation loss: 2.577292483476073

Epoch: 6| Step: 9
Training loss: 2.552552804129837
Validation loss: 2.5993937807937524

Epoch: 6| Step: 10
Training loss: 3.1603294674019824
Validation loss: 2.5925738943110637

Epoch: 6| Step: 11
Training loss: 3.332254775712504
Validation loss: 2.584568231329921

Epoch: 6| Step: 12
Training loss: 3.1056007980966696
Validation loss: 2.5869716738412394

Epoch: 6| Step: 13
Training loss: 3.0277597055469396
Validation loss: 2.580491835996176

Epoch: 72| Step: 0
Training loss: 3.2713228738121467
Validation loss: 2.570529119097868

Epoch: 6| Step: 1
Training loss: 2.839720837479356
Validation loss: 2.569403382778539

Epoch: 6| Step: 2
Training loss: 3.3308338012644083
Validation loss: 2.566825940890607

Epoch: 6| Step: 3
Training loss: 3.1035246899942344
Validation loss: 2.567282307238626

Epoch: 6| Step: 4
Training loss: 2.709588058524656
Validation loss: 2.5752582759420073

Epoch: 6| Step: 5
Training loss: 2.3036952064691807
Validation loss: 2.5687318184116363

Epoch: 6| Step: 6
Training loss: 2.1350251622023815
Validation loss: 2.571453584382364

Epoch: 6| Step: 7
Training loss: 3.0965072213286895
Validation loss: 2.570279270264892

Epoch: 6| Step: 8
Training loss: 3.0660686331356226
Validation loss: 2.570246227617012

Epoch: 6| Step: 9
Training loss: 2.9207464476399467
Validation loss: 2.568582841938253

Epoch: 6| Step: 10
Training loss: 3.3624687675528757
Validation loss: 2.5732202953985763

Epoch: 6| Step: 11
Training loss: 2.4386836381463852
Validation loss: 2.5701551955580975

Epoch: 6| Step: 12
Training loss: 2.9104410121794215
Validation loss: 2.5712409864803654

Epoch: 6| Step: 13
Training loss: 3.6900341571994733
Validation loss: 2.571510839253123

Epoch: 73| Step: 0
Training loss: 2.982460406441093
Validation loss: 2.572141204574876

Epoch: 6| Step: 1
Training loss: 2.8744211028719753
Validation loss: 2.5743923776963684

Epoch: 6| Step: 2
Training loss: 3.0650045313342704
Validation loss: 2.578882728912235

Epoch: 6| Step: 3
Training loss: 3.0387521305806433
Validation loss: 2.590230214792237

Epoch: 6| Step: 4
Training loss: 3.1384719376657846
Validation loss: 2.592554895659526

Epoch: 6| Step: 5
Training loss: 3.168578290331171
Validation loss: 2.5884670650315718

Epoch: 6| Step: 6
Training loss: 2.6034582980255525
Validation loss: 2.5904282630248185

Epoch: 6| Step: 7
Training loss: 2.5863378854442676
Validation loss: 2.5728937199255886

Epoch: 6| Step: 8
Training loss: 2.4635399031414362
Validation loss: 2.576375092604898

Epoch: 6| Step: 9
Training loss: 2.7986350036139704
Validation loss: 2.5741441681553305

Epoch: 6| Step: 10
Training loss: 3.4318037520810907
Validation loss: 2.56699894409792

Epoch: 6| Step: 11
Training loss: 3.428151127620921
Validation loss: 2.5671229506530886

Epoch: 6| Step: 12
Training loss: 2.6982363556872375
Validation loss: 2.5639046701535984

Epoch: 6| Step: 13
Training loss: 2.2175245527523084
Validation loss: 2.562076868817999

Epoch: 74| Step: 0
Training loss: 3.497543290192769
Validation loss: 2.5597664934725723

Epoch: 6| Step: 1
Training loss: 3.0300532859422478
Validation loss: 2.554932123640817

Epoch: 6| Step: 2
Training loss: 2.8260337727304385
Validation loss: 2.560188605612119

Epoch: 6| Step: 3
Training loss: 2.7570538652572925
Validation loss: 2.5607260349470637

Epoch: 6| Step: 4
Training loss: 3.143541490681759
Validation loss: 2.564425592577952

Epoch: 6| Step: 5
Training loss: 3.0019022950316048
Validation loss: 2.571504730997778

Epoch: 6| Step: 6
Training loss: 2.5630384670292563
Validation loss: 2.568850874211965

Epoch: 6| Step: 7
Training loss: 2.377839950340909
Validation loss: 2.567394605258845

Epoch: 6| Step: 8
Training loss: 2.942097090083124
Validation loss: 2.5666119208754647

Epoch: 6| Step: 9
Training loss: 3.545074678180553
Validation loss: 2.5735916767428044

Epoch: 6| Step: 10
Training loss: 2.904099027337652
Validation loss: 2.567466824490129

Epoch: 6| Step: 11
Training loss: 2.642026991793651
Validation loss: 2.5679932807082073

Epoch: 6| Step: 12
Training loss: 2.5297125397468467
Validation loss: 2.565439786432508

Epoch: 6| Step: 13
Training loss: 2.8355941354418386
Validation loss: 2.5672462162521126

Epoch: 75| Step: 0
Training loss: 2.4705112789894845
Validation loss: 2.567083157397324

Epoch: 6| Step: 1
Training loss: 3.4982687891990767
Validation loss: 2.5780051284621033

Epoch: 6| Step: 2
Training loss: 2.7957029817289856
Validation loss: 2.5789773406534744

Epoch: 6| Step: 3
Training loss: 2.3300174471811794
Validation loss: 2.561582925938679

Epoch: 6| Step: 4
Training loss: 2.4577222377065486
Validation loss: 2.5584378353189376

Epoch: 6| Step: 5
Training loss: 2.4242245997691163
Validation loss: 2.559253208418286

Epoch: 6| Step: 6
Training loss: 2.731707508867204
Validation loss: 2.5571731156621307

Epoch: 6| Step: 7
Training loss: 3.1846285583354033
Validation loss: 2.5532423597442384

Epoch: 6| Step: 8
Training loss: 2.9587245915252223
Validation loss: 2.55372622265813

Epoch: 6| Step: 9
Training loss: 3.5436879093711733
Validation loss: 2.5513364623590467

Epoch: 6| Step: 10
Training loss: 3.228526259056897
Validation loss: 2.5520904597839413

Epoch: 6| Step: 11
Training loss: 2.724684278764296
Validation loss: 2.5546505506937445

Epoch: 6| Step: 12
Training loss: 3.0455663756253686
Validation loss: 2.5564574848951396

Epoch: 6| Step: 13
Training loss: 3.2998292532009534
Validation loss: 2.554614970676088

Epoch: 76| Step: 0
Training loss: 2.842583385576416
Validation loss: 2.5609577879515992

Epoch: 6| Step: 1
Training loss: 3.744221749618329
Validation loss: 2.5697198309115437

Epoch: 6| Step: 2
Training loss: 2.340574529330321
Validation loss: 2.5674128914169874

Epoch: 6| Step: 3
Training loss: 3.117123557751921
Validation loss: 2.573221167140953

Epoch: 6| Step: 4
Training loss: 2.6665545579073817
Validation loss: 2.5863992623081047

Epoch: 6| Step: 5
Training loss: 2.9730774509620406
Validation loss: 2.6230145694014233

Epoch: 6| Step: 6
Training loss: 2.681683922714688
Validation loss: 2.610202313552558

Epoch: 6| Step: 7
Training loss: 2.933800498290491
Validation loss: 2.5956223262463567

Epoch: 6| Step: 8
Training loss: 3.7065356036783794
Validation loss: 2.5757025680461294

Epoch: 6| Step: 9
Training loss: 2.479946964681268
Validation loss: 2.5528999902120586

Epoch: 6| Step: 10
Training loss: 2.550552614956727
Validation loss: 2.550711896178684

Epoch: 6| Step: 11
Training loss: 2.3329479262536763
Validation loss: 2.5465284391450553

Epoch: 6| Step: 12
Training loss: 3.311692049351257
Validation loss: 2.5459292858063987

Epoch: 6| Step: 13
Training loss: 2.5328270979407073
Validation loss: 2.544312481000823

Epoch: 77| Step: 0
Training loss: 3.1840676171488838
Validation loss: 2.5440063426412793

Epoch: 6| Step: 1
Training loss: 3.2302265191737467
Validation loss: 2.544478854951724

Epoch: 6| Step: 2
Training loss: 3.213802498114532
Validation loss: 2.544451175916991

Epoch: 6| Step: 3
Training loss: 3.0881256458040145
Validation loss: 2.544475623798625

Epoch: 6| Step: 4
Training loss: 2.5773013562118035
Validation loss: 2.544567579583416

Epoch: 6| Step: 5
Training loss: 2.745106417846181
Validation loss: 2.5464571231215722

Epoch: 6| Step: 6
Training loss: 2.405639372792845
Validation loss: 2.5434984202726634

Epoch: 6| Step: 7
Training loss: 2.81878290939574
Validation loss: 2.542871409750081

Epoch: 6| Step: 8
Training loss: 2.87213091119979
Validation loss: 2.5480832298364238

Epoch: 6| Step: 9
Training loss: 2.621201991931817
Validation loss: 2.5584173516663986

Epoch: 6| Step: 10
Training loss: 3.2045725459140986
Validation loss: 2.56054275001872

Epoch: 6| Step: 11
Training loss: 3.2586111283644876
Validation loss: 2.5523468822405526

Epoch: 6| Step: 12
Training loss: 2.780029371916027
Validation loss: 2.545890852998692

Epoch: 6| Step: 13
Training loss: 2.3967694872295398
Validation loss: 2.5450087649660675

Epoch: 78| Step: 0
Training loss: 2.7402482960266488
Validation loss: 2.5436124960139566

Epoch: 6| Step: 1
Training loss: 2.8117321237732007
Validation loss: 2.542185278771284

Epoch: 6| Step: 2
Training loss: 3.003098794781121
Validation loss: 2.540412571920103

Epoch: 6| Step: 3
Training loss: 2.7296876676981916
Validation loss: 2.5488945439027146

Epoch: 6| Step: 4
Training loss: 3.0247927444960196
Validation loss: 2.551434009178408

Epoch: 6| Step: 5
Training loss: 2.8748583551427
Validation loss: 2.5683210422701714

Epoch: 6| Step: 6
Training loss: 2.6350321935319325
Validation loss: 2.5822055794970726

Epoch: 6| Step: 7
Training loss: 2.937842166532944
Validation loss: 2.584743399407659

Epoch: 6| Step: 8
Training loss: 3.1435087259279797
Validation loss: 2.5881201674358425

Epoch: 6| Step: 9
Training loss: 2.8183885600587386
Validation loss: 2.5588502381021274

Epoch: 6| Step: 10
Training loss: 2.847758894379933
Validation loss: 2.5620901538871887

Epoch: 6| Step: 11
Training loss: 3.3385692640920506
Validation loss: 2.558761961629594

Epoch: 6| Step: 12
Training loss: 2.779440644889168
Validation loss: 2.5582030340470863

Epoch: 6| Step: 13
Training loss: 2.980438032279452
Validation loss: 2.5538299798203816

Epoch: 79| Step: 0
Training loss: 2.955617831425757
Validation loss: 2.543694343128334

Epoch: 6| Step: 1
Training loss: 2.6278973892478237
Validation loss: 2.5462544456076355

Epoch: 6| Step: 2
Training loss: 3.2436992016528325
Validation loss: 2.546337832769516

Epoch: 6| Step: 3
Training loss: 2.4569997133496266
Validation loss: 2.5425252908173634

Epoch: 6| Step: 4
Training loss: 2.764290784139057
Validation loss: 2.540562011574041

Epoch: 6| Step: 5
Training loss: 2.785345854866049
Validation loss: 2.539046091637234

Epoch: 6| Step: 6
Training loss: 2.8018912399607605
Validation loss: 2.543221380636527

Epoch: 6| Step: 7
Training loss: 2.35225598828136
Validation loss: 2.5471327657716496

Epoch: 6| Step: 8
Training loss: 3.089044093693187
Validation loss: 2.544372845397763

Epoch: 6| Step: 9
Training loss: 3.0013629678217555
Validation loss: 2.5479560166895108

Epoch: 6| Step: 10
Training loss: 3.019102947065646
Validation loss: 2.5514103423810814

Epoch: 6| Step: 11
Training loss: 2.878404674547862
Validation loss: 2.554984162886403

Epoch: 6| Step: 12
Training loss: 3.3587728271162973
Validation loss: 2.5580682736721325

Epoch: 6| Step: 13
Training loss: 3.292510845887692
Validation loss: 2.5608761732427605

Epoch: 80| Step: 0
Training loss: 3.2072822203109372
Validation loss: 2.564422952384989

Epoch: 6| Step: 1
Training loss: 2.8730989888415985
Validation loss: 2.5748125650231364

Epoch: 6| Step: 2
Training loss: 3.3165238610071666
Validation loss: 2.5886610932101033

Epoch: 6| Step: 3
Training loss: 2.9045914049756463
Validation loss: 2.5979461332999754

Epoch: 6| Step: 4
Training loss: 3.501542977410994
Validation loss: 2.629719553761179

Epoch: 6| Step: 5
Training loss: 2.7062466627985793
Validation loss: 2.596018394655452

Epoch: 6| Step: 6
Training loss: 3.101084328792467
Validation loss: 2.602624737117168

Epoch: 6| Step: 7
Training loss: 2.6683619196939263
Validation loss: 2.5833729619517194

Epoch: 6| Step: 8
Training loss: 2.754865070922799
Validation loss: 2.578641905414089

Epoch: 6| Step: 9
Training loss: 2.42842476466041
Validation loss: 2.559790246257449

Epoch: 6| Step: 10
Training loss: 3.394023826609899
Validation loss: 2.5437684214209337

Epoch: 6| Step: 11
Training loss: 2.577720194160636
Validation loss: 2.546181718351736

Epoch: 6| Step: 12
Training loss: 2.4052722480204123
Validation loss: 2.5354410111407906

Epoch: 6| Step: 13
Training loss: 1.6724552324173905
Validation loss: 2.542175422262258

Epoch: 81| Step: 0
Training loss: 2.3339534230753634
Validation loss: 2.5392838879311914

Epoch: 6| Step: 1
Training loss: 2.9677546388533447
Validation loss: 2.543990882186844

Epoch: 6| Step: 2
Training loss: 3.1326653120134433
Validation loss: 2.5372264307440697

Epoch: 6| Step: 3
Training loss: 3.3164695131627973
Validation loss: 2.5373674518618405

Epoch: 6| Step: 4
Training loss: 2.8401677971283186
Validation loss: 2.5444738384512795

Epoch: 6| Step: 5
Training loss: 3.5168825062206777
Validation loss: 2.5509605008671725

Epoch: 6| Step: 6
Training loss: 2.113251014253433
Validation loss: 2.5462399532821003

Epoch: 6| Step: 7
Training loss: 3.218841551432369
Validation loss: 2.5614666069362304

Epoch: 6| Step: 8
Training loss: 2.6778643664882686
Validation loss: 2.5638631600927435

Epoch: 6| Step: 9
Training loss: 2.4899375589040806
Validation loss: 2.5787527364848803

Epoch: 6| Step: 10
Training loss: 2.6581734369036947
Validation loss: 2.5710365833197875

Epoch: 6| Step: 11
Training loss: 2.438573649730496
Validation loss: 2.590090785137739

Epoch: 6| Step: 12
Training loss: 3.3611585983270573
Validation loss: 2.621651950535653

Epoch: 6| Step: 13
Training loss: 2.9528115726840505
Validation loss: 2.6143429491269794

Epoch: 82| Step: 0
Training loss: 2.762484561652633
Validation loss: 2.5698316752538304

Epoch: 6| Step: 1
Training loss: 3.5474408072331176
Validation loss: 2.562690590714529

Epoch: 6| Step: 2
Training loss: 2.6292727981482864
Validation loss: 2.541028762912937

Epoch: 6| Step: 3
Training loss: 3.2178580520456825
Validation loss: 2.529750647798584

Epoch: 6| Step: 4
Training loss: 3.7101962664324404
Validation loss: 2.534079680282424

Epoch: 6| Step: 5
Training loss: 2.0918308401333294
Validation loss: 2.52949205124504

Epoch: 6| Step: 6
Training loss: 2.4374330951605194
Validation loss: 2.536191263006671

Epoch: 6| Step: 7
Training loss: 2.824343012480679
Validation loss: 2.538645471949648

Epoch: 6| Step: 8
Training loss: 2.771653410129955
Validation loss: 2.53347401085338

Epoch: 6| Step: 9
Training loss: 2.491558509784232
Validation loss: 2.5267839064175974

Epoch: 6| Step: 10
Training loss: 2.945162579593741
Validation loss: 2.529010580677894

Epoch: 6| Step: 11
Training loss: 3.0050016670412845
Validation loss: 2.5319588449923596

Epoch: 6| Step: 12
Training loss: 2.6846511290240884
Validation loss: 2.547368715246379

Epoch: 6| Step: 13
Training loss: 3.081278623250673
Validation loss: 2.5705426372390807

Epoch: 83| Step: 0
Training loss: 2.367691439629729
Validation loss: 2.6344112754927083

Epoch: 6| Step: 1
Training loss: 3.2381828854557
Validation loss: 2.7024765000209445

Epoch: 6| Step: 2
Training loss: 2.5281931939847557
Validation loss: 2.779147333252945

Epoch: 6| Step: 3
Training loss: 2.724766530525877
Validation loss: 2.872819102753997

Epoch: 6| Step: 4
Training loss: 2.4764592964498036
Validation loss: 2.8729375866952487

Epoch: 6| Step: 5
Training loss: 3.197895675408042
Validation loss: 2.850624107852829

Epoch: 6| Step: 6
Training loss: 2.6460210978848338
Validation loss: 2.7636202190028136

Epoch: 6| Step: 7
Training loss: 3.444080504465631
Validation loss: 2.649519874107168

Epoch: 6| Step: 8
Training loss: 3.364864813935985
Validation loss: 2.554305880848005

Epoch: 6| Step: 9
Training loss: 3.2465586415465357
Validation loss: 2.5238239364903774

Epoch: 6| Step: 10
Training loss: 2.6785226853794852
Validation loss: 2.525852989877891

Epoch: 6| Step: 11
Training loss: 3.3112134054313977
Validation loss: 2.567597781693972

Epoch: 6| Step: 12
Training loss: 2.5926163735383905
Validation loss: 2.598812835965484

Epoch: 6| Step: 13
Training loss: 3.12338199690204
Validation loss: 2.585111966035196

Epoch: 84| Step: 0
Training loss: 3.2753923719807507
Validation loss: 2.546103989826229

Epoch: 6| Step: 1
Training loss: 2.5267118109072944
Validation loss: 2.5366649374668198

Epoch: 6| Step: 2
Training loss: 2.6054535597968926
Validation loss: 2.5326295235933927

Epoch: 6| Step: 3
Training loss: 3.0735991846094435
Validation loss: 2.5449007829065287

Epoch: 6| Step: 4
Training loss: 3.015825017907248
Validation loss: 2.572743997953025

Epoch: 6| Step: 5
Training loss: 2.6932147279754517
Validation loss: 2.60198748432465

Epoch: 6| Step: 6
Training loss: 3.2037853025589245
Validation loss: 2.677116383943498

Epoch: 6| Step: 7
Training loss: 2.8477249032576495
Validation loss: 2.6761671625874475

Epoch: 6| Step: 8
Training loss: 2.955264976226652
Validation loss: 2.6075206826820008

Epoch: 6| Step: 9
Training loss: 2.6546491398995156
Validation loss: 2.578408084963056

Epoch: 6| Step: 10
Training loss: 3.174515099931002
Validation loss: 2.5526855126638064

Epoch: 6| Step: 11
Training loss: 2.822223385821459
Validation loss: 2.5298532095598416

Epoch: 6| Step: 12
Training loss: 3.117417558866333
Validation loss: 2.5197499632989255

Epoch: 6| Step: 13
Training loss: 2.713421389988742
Validation loss: 2.522339702234211

Epoch: 85| Step: 0
Training loss: 2.9384408620920395
Validation loss: 2.5213455311044966

Epoch: 6| Step: 1
Training loss: 3.049863318210445
Validation loss: 2.5303747526708853

Epoch: 6| Step: 2
Training loss: 2.9468413819289667
Validation loss: 2.5285005473331954

Epoch: 6| Step: 3
Training loss: 3.285883946510668
Validation loss: 2.5383169195530173

Epoch: 6| Step: 4
Training loss: 2.417432882803344
Validation loss: 2.5396318926492576

Epoch: 6| Step: 5
Training loss: 2.521149817742575
Validation loss: 2.5800533462560074

Epoch: 6| Step: 6
Training loss: 3.026116655288354
Validation loss: 2.5376861986874677

Epoch: 6| Step: 7
Training loss: 2.9175232492287084
Validation loss: 2.5222317000147134

Epoch: 6| Step: 8
Training loss: 2.1055929681657637
Validation loss: 2.5224456285469454

Epoch: 6| Step: 9
Training loss: 2.9893511284336243
Validation loss: 2.5213033722178846

Epoch: 6| Step: 10
Training loss: 3.2878305479318826
Validation loss: 2.518908231795074

Epoch: 6| Step: 11
Training loss: 3.1164399974083072
Validation loss: 2.5279785876418055

Epoch: 6| Step: 12
Training loss: 3.0820451743387927
Validation loss: 2.5346609610436985

Epoch: 6| Step: 13
Training loss: 2.693313786353888
Validation loss: 2.5499805837765077

Epoch: 86| Step: 0
Training loss: 2.3572143362197426
Validation loss: 2.548487303103149

Epoch: 6| Step: 1
Training loss: 2.488165979994149
Validation loss: 2.559905414644528

Epoch: 6| Step: 2
Training loss: 2.1121258917914623
Validation loss: 2.5665318194624196

Epoch: 6| Step: 3
Training loss: 3.221404527266934
Validation loss: 2.5712106781554183

Epoch: 6| Step: 4
Training loss: 2.7528650791128193
Validation loss: 2.5518630199922656

Epoch: 6| Step: 5
Training loss: 2.880937995484402
Validation loss: 2.541023794081943

Epoch: 6| Step: 6
Training loss: 2.611416868700551
Validation loss: 2.533283870399805

Epoch: 6| Step: 7
Training loss: 3.215464720888235
Validation loss: 2.530024144695713

Epoch: 6| Step: 8
Training loss: 3.363060495395662
Validation loss: 2.5405909408403184

Epoch: 6| Step: 9
Training loss: 3.383452251455371
Validation loss: 2.5402736057903357

Epoch: 6| Step: 10
Training loss: 2.6725815402117874
Validation loss: 2.537279617193406

Epoch: 6| Step: 11
Training loss: 3.0997570557918954
Validation loss: 2.5417211241984514

Epoch: 6| Step: 12
Training loss: 2.9119023966518784
Validation loss: 2.548570704722186

Epoch: 6| Step: 13
Training loss: 3.0686019519902383
Validation loss: 2.5404098734691605

Epoch: 87| Step: 0
Training loss: 2.870428680411024
Validation loss: 2.539043804696216

Epoch: 6| Step: 1
Training loss: 3.062974542714387
Validation loss: 2.5355998094781387

Epoch: 6| Step: 2
Training loss: 2.3623293133792913
Validation loss: 2.5419789083307793

Epoch: 6| Step: 3
Training loss: 2.8020884763157574
Validation loss: 2.554889515549971

Epoch: 6| Step: 4
Training loss: 2.892051550968951
Validation loss: 2.5587744173028004

Epoch: 6| Step: 5
Training loss: 3.006965339554763
Validation loss: 2.569514790926061

Epoch: 6| Step: 6
Training loss: 2.380635251769017
Validation loss: 2.5954467564859622

Epoch: 6| Step: 7
Training loss: 3.3098940405351818
Validation loss: 2.599378591581146

Epoch: 6| Step: 8
Training loss: 3.3333691754003603
Validation loss: 2.597724033716992

Epoch: 6| Step: 9
Training loss: 3.0368254991930024
Validation loss: 2.5687316028397356

Epoch: 6| Step: 10
Training loss: 2.7733402718707856
Validation loss: 2.5330148284840677

Epoch: 6| Step: 11
Training loss: 2.914833273724389
Validation loss: 2.5252594667384654

Epoch: 6| Step: 12
Training loss: 2.5492486482597765
Validation loss: 2.5188570481926655

Epoch: 6| Step: 13
Training loss: 2.850801047467826
Validation loss: 2.5194761310439344

Epoch: 88| Step: 0
Training loss: 2.504316703968984
Validation loss: 2.5182469082062817

Epoch: 6| Step: 1
Training loss: 3.0344073968605585
Validation loss: 2.5226926225828334

Epoch: 6| Step: 2
Training loss: 2.9078830519802787
Validation loss: 2.529510863765324

Epoch: 6| Step: 3
Training loss: 2.9561054992845555
Validation loss: 2.5238407998449124

Epoch: 6| Step: 4
Training loss: 2.6924102637905043
Validation loss: 2.526085596915176

Epoch: 6| Step: 5
Training loss: 2.865091748058425
Validation loss: 2.5286814936980315

Epoch: 6| Step: 6
Training loss: 2.978858842930211
Validation loss: 2.525889820490562

Epoch: 6| Step: 7
Training loss: 2.8292352172756603
Validation loss: 2.5142129053097504

Epoch: 6| Step: 8
Training loss: 3.066573256300081
Validation loss: 2.5232561354165846

Epoch: 6| Step: 9
Training loss: 2.907605255137318
Validation loss: 2.529321358880905

Epoch: 6| Step: 10
Training loss: 2.6712235219782934
Validation loss: 2.552077831859238

Epoch: 6| Step: 11
Training loss: 2.982446017164484
Validation loss: 2.573497390989068

Epoch: 6| Step: 12
Training loss: 2.9883394921305464
Validation loss: 2.592107884346588

Epoch: 6| Step: 13
Training loss: 3.076381906272325
Validation loss: 2.605071770345786

Epoch: 89| Step: 0
Training loss: 3.1540392696666935
Validation loss: 2.590658108057475

Epoch: 6| Step: 1
Training loss: 2.481769659169504
Validation loss: 2.5717459666453992

Epoch: 6| Step: 2
Training loss: 3.046266778736138
Validation loss: 2.5572217117992526

Epoch: 6| Step: 3
Training loss: 2.5687905301425893
Validation loss: 2.5432975602712196

Epoch: 6| Step: 4
Training loss: 2.77244683423676
Validation loss: 2.5309214376840106

Epoch: 6| Step: 5
Training loss: 2.908726611139667
Validation loss: 2.527016021968536

Epoch: 6| Step: 6
Training loss: 2.421848518472913
Validation loss: 2.5268850261934537

Epoch: 6| Step: 7
Training loss: 3.0638150875379213
Validation loss: 2.5142040689265066

Epoch: 6| Step: 8
Training loss: 3.0475635239674967
Validation loss: 2.510577442846968

Epoch: 6| Step: 9
Training loss: 2.949153106161005
Validation loss: 2.5108929346004416

Epoch: 6| Step: 10
Training loss: 3.1020802562963947
Validation loss: 2.5113303869962924

Epoch: 6| Step: 11
Training loss: 2.9585524643524868
Validation loss: 2.5099353654837357

Epoch: 6| Step: 12
Training loss: 2.980568580405423
Validation loss: 2.510414102769422

Epoch: 6| Step: 13
Training loss: 2.201558523397868
Validation loss: 2.510950435045072

Epoch: 90| Step: 0
Training loss: 3.095446497150877
Validation loss: 2.512300471717052

Epoch: 6| Step: 1
Training loss: 2.456880937839379
Validation loss: 2.5169162655264388

Epoch: 6| Step: 2
Training loss: 2.7297864506238434
Validation loss: 2.511560284675038

Epoch: 6| Step: 3
Training loss: 2.643799718655341
Validation loss: 2.5149143310431037

Epoch: 6| Step: 4
Training loss: 3.289017991877076
Validation loss: 2.5229711898930827

Epoch: 6| Step: 5
Training loss: 2.8143742568158876
Validation loss: 2.5297827246369256

Epoch: 6| Step: 6
Training loss: 2.9418559142304663
Validation loss: 2.547736775977483

Epoch: 6| Step: 7
Training loss: 3.1423316986974292
Validation loss: 2.5546008770186033

Epoch: 6| Step: 8
Training loss: 3.4845033630538786
Validation loss: 2.5536411412093054

Epoch: 6| Step: 9
Training loss: 3.0343148379740867
Validation loss: 2.571740977414739

Epoch: 6| Step: 10
Training loss: 2.882123332363503
Validation loss: 2.5747682238712093

Epoch: 6| Step: 11
Training loss: 2.278119382079514
Validation loss: 2.590394004762461

Epoch: 6| Step: 12
Training loss: 2.235510050970087
Validation loss: 2.616926781382829

Epoch: 6| Step: 13
Training loss: 1.9738771796005203
Validation loss: 2.600600550861342

Epoch: 91| Step: 0
Training loss: 2.7181865941461236
Validation loss: 2.6012190720492048

Epoch: 6| Step: 1
Training loss: 3.384521616457136
Validation loss: 2.623865688200389

Epoch: 6| Step: 2
Training loss: 3.158660874371782
Validation loss: 2.6001753664707

Epoch: 6| Step: 3
Training loss: 3.316844753934694
Validation loss: 2.561374916540897

Epoch: 6| Step: 4
Training loss: 2.6142030923251474
Validation loss: 2.5453084101976744

Epoch: 6| Step: 5
Training loss: 2.6001267695699903
Validation loss: 2.5398053325639265

Epoch: 6| Step: 6
Training loss: 2.743111479198538
Validation loss: 2.5257539937801377

Epoch: 6| Step: 7
Training loss: 2.9521477914116065
Validation loss: 2.51896348734152

Epoch: 6| Step: 8
Training loss: 2.189168130530236
Validation loss: 2.5125429573319225

Epoch: 6| Step: 9
Training loss: 3.0096639112233956
Validation loss: 2.5111742033627884

Epoch: 6| Step: 10
Training loss: 3.353251851749613
Validation loss: 2.5141831841040556

Epoch: 6| Step: 11
Training loss: 2.630328628256734
Validation loss: 2.5097366310265317

Epoch: 6| Step: 12
Training loss: 2.526789939141244
Validation loss: 2.5076453290859155

Epoch: 6| Step: 13
Training loss: 1.875959786494485
Validation loss: 2.5114963051324946

Epoch: 92| Step: 0
Training loss: 2.3727112834980297
Validation loss: 2.5120441527909176

Epoch: 6| Step: 1
Training loss: 3.5195244758362945
Validation loss: 2.5148114026495203

Epoch: 6| Step: 2
Training loss: 2.922533583240065
Validation loss: 2.5135502933287373

Epoch: 6| Step: 3
Training loss: 2.528916401764649
Validation loss: 2.5136374732330564

Epoch: 6| Step: 4
Training loss: 2.8484531956678096
Validation loss: 2.5053027468678866

Epoch: 6| Step: 5
Training loss: 2.6605135639879416
Validation loss: 2.510524317692202

Epoch: 6| Step: 6
Training loss: 3.352893342817595
Validation loss: 2.510339705037636

Epoch: 6| Step: 7
Training loss: 2.7683595403555756
Validation loss: 2.5122421796822048

Epoch: 6| Step: 8
Training loss: 2.899276406350371
Validation loss: 2.5063252335428228

Epoch: 6| Step: 9
Training loss: 3.0584359743389853
Validation loss: 2.5083516503271905

Epoch: 6| Step: 10
Training loss: 2.392771835270564
Validation loss: 2.5096595465627387

Epoch: 6| Step: 11
Training loss: 2.827443920763246
Validation loss: 2.524977696776233

Epoch: 6| Step: 12
Training loss: 2.556798966460801
Validation loss: 2.561843123582236

Epoch: 6| Step: 13
Training loss: 3.0667108663884344
Validation loss: 2.6762311017904836

Epoch: 93| Step: 0
Training loss: 2.804634540025971
Validation loss: 2.825550607057799

Epoch: 6| Step: 1
Training loss: 2.5075786160651217
Validation loss: 2.945457474294835

Epoch: 6| Step: 2
Training loss: 3.124392488556197
Validation loss: 2.8883795240524313

Epoch: 6| Step: 3
Training loss: 3.825622238709105
Validation loss: 2.828161086765108

Epoch: 6| Step: 4
Training loss: 3.3577584568962666
Validation loss: 2.735610166345079

Epoch: 6| Step: 5
Training loss: 2.695413515713483
Validation loss: 2.631074268479522

Epoch: 6| Step: 6
Training loss: 2.678100649924399
Validation loss: 2.5646861755468993

Epoch: 6| Step: 7
Training loss: 3.1426168170299094
Validation loss: 2.545270499825756

Epoch: 6| Step: 8
Training loss: 2.620310454575361
Validation loss: 2.5296331275487454

Epoch: 6| Step: 9
Training loss: 2.5855107718859123
Validation loss: 2.5112795134331036

Epoch: 6| Step: 10
Training loss: 2.984429963090078
Validation loss: 2.5117008044833398

Epoch: 6| Step: 11
Training loss: 2.878228406674204
Validation loss: 2.5063906737567154

Epoch: 6| Step: 12
Training loss: 2.7727106565725173
Validation loss: 2.523116888100757

Epoch: 6| Step: 13
Training loss: 3.187544728881558
Validation loss: 2.514756288303384

Epoch: 94| Step: 0
Training loss: 3.0667477168554136
Validation loss: 2.5210632942063613

Epoch: 6| Step: 1
Training loss: 3.2880375005713627
Validation loss: 2.5145996904611314

Epoch: 6| Step: 2
Training loss: 3.3872379666153467
Validation loss: 2.5189174262099163

Epoch: 6| Step: 3
Training loss: 2.997145884565705
Validation loss: 2.518004153314254

Epoch: 6| Step: 4
Training loss: 1.6005828838773113
Validation loss: 2.523296208364236

Epoch: 6| Step: 5
Training loss: 2.983241000602496
Validation loss: 2.53408464755448

Epoch: 6| Step: 6
Training loss: 2.9286979122959775
Validation loss: 2.525779440720242

Epoch: 6| Step: 7
Training loss: 2.9106308927634044
Validation loss: 2.534396197455187

Epoch: 6| Step: 8
Training loss: 2.814340116626493
Validation loss: 2.5371916733896653

Epoch: 6| Step: 9
Training loss: 3.3030584842910327
Validation loss: 2.528498200666112

Epoch: 6| Step: 10
Training loss: 2.80146804539711
Validation loss: 2.5309451968065195

Epoch: 6| Step: 11
Training loss: 2.6818977338280283
Validation loss: 2.535461107114423

Epoch: 6| Step: 12
Training loss: 2.3234416784622187
Validation loss: 2.538006237804361

Epoch: 6| Step: 13
Training loss: 1.9996666034334536
Validation loss: 2.52655242603973

Epoch: 95| Step: 0
Training loss: 3.1683146220910046
Validation loss: 2.54327341556374

Epoch: 6| Step: 1
Training loss: 2.8059502524372792
Validation loss: 2.543518236892868

Epoch: 6| Step: 2
Training loss: 2.268556158859295
Validation loss: 2.5469568560131757

Epoch: 6| Step: 3
Training loss: 2.4976650778405927
Validation loss: 2.5567709695917955

Epoch: 6| Step: 4
Training loss: 2.877032680926503
Validation loss: 2.5644927241440896

Epoch: 6| Step: 5
Training loss: 2.5895525508246915
Validation loss: 2.590559013471668

Epoch: 6| Step: 6
Training loss: 3.3146927971130897
Validation loss: 2.573249123513305

Epoch: 6| Step: 7
Training loss: 2.9894453984959113
Validation loss: 2.5338781040118548

Epoch: 6| Step: 8
Training loss: 2.369461025325614
Validation loss: 2.5053961854416875

Epoch: 6| Step: 9
Training loss: 3.0840828646104326
Validation loss: 2.5069756228171496

Epoch: 6| Step: 10
Training loss: 3.015714495818211
Validation loss: 2.516580478553582

Epoch: 6| Step: 11
Training loss: 3.2030072446438087
Validation loss: 2.5184311264934647

Epoch: 6| Step: 12
Training loss: 2.875905764992346
Validation loss: 2.527877909156215

Epoch: 6| Step: 13
Training loss: 2.6926510261817453
Validation loss: 2.5106015435796616

Epoch: 96| Step: 0
Training loss: 2.6209343806337255
Validation loss: 2.5132352738867962

Epoch: 6| Step: 1
Training loss: 2.3486979834383193
Validation loss: 2.514967845619134

Epoch: 6| Step: 2
Training loss: 3.086987435115431
Validation loss: 2.5192253418667305

Epoch: 6| Step: 3
Training loss: 3.4003412636423005
Validation loss: 2.5187591165796808

Epoch: 6| Step: 4
Training loss: 2.139393584527022
Validation loss: 2.5244921338909547

Epoch: 6| Step: 5
Training loss: 3.021015152995176
Validation loss: 2.548445401083551

Epoch: 6| Step: 6
Training loss: 2.0225532396474146
Validation loss: 2.5505444050298705

Epoch: 6| Step: 7
Training loss: 3.15261949280957
Validation loss: 2.5680757333910145

Epoch: 6| Step: 8
Training loss: 3.0328207763684727
Validation loss: 2.597423048621257

Epoch: 6| Step: 9
Training loss: 3.0717145907023
Validation loss: 2.635297302152541

Epoch: 6| Step: 10
Training loss: 2.7106968665716584
Validation loss: 2.6295495617411797

Epoch: 6| Step: 11
Training loss: 2.7930617096909702
Validation loss: 2.611631007055875

Epoch: 6| Step: 12
Training loss: 2.9898916654831633
Validation loss: 2.5555405291590674

Epoch: 6| Step: 13
Training loss: 3.2806597950871215
Validation loss: 2.5265755646822337

Epoch: 97| Step: 0
Training loss: 2.4781362064295793
Validation loss: 2.509747488802942

Epoch: 6| Step: 1
Training loss: 2.9762392043711374
Validation loss: 2.5094839092535985

Epoch: 6| Step: 2
Training loss: 2.9784166863690515
Validation loss: 2.5056146218868807

Epoch: 6| Step: 3
Training loss: 3.3792302500006612
Validation loss: 2.508330394830503

Epoch: 6| Step: 4
Training loss: 3.0495376298981047
Validation loss: 2.5101230207743157

Epoch: 6| Step: 5
Training loss: 2.1366470018018506
Validation loss: 2.515130863461632

Epoch: 6| Step: 6
Training loss: 2.9723083051850083
Validation loss: 2.510726324124248

Epoch: 6| Step: 7
Training loss: 3.0031230882843
Validation loss: 2.5086047953026407

Epoch: 6| Step: 8
Training loss: 3.189641943421532
Validation loss: 2.5184736480027725

Epoch: 6| Step: 9
Training loss: 2.5325015706154415
Validation loss: 2.516573100098372

Epoch: 6| Step: 10
Training loss: 3.0340061831829357
Validation loss: 2.520696049647662

Epoch: 6| Step: 11
Training loss: 2.8375574114532833
Validation loss: 2.533352392877319

Epoch: 6| Step: 12
Training loss: 2.353211087986282
Validation loss: 2.5356558745993616

Epoch: 6| Step: 13
Training loss: 2.9451211315689982
Validation loss: 2.5542774702415874

Epoch: 98| Step: 0
Training loss: 2.5913701917171195
Validation loss: 2.549737134024395

Epoch: 6| Step: 1
Training loss: 2.902198017717849
Validation loss: 2.551705595937354

Epoch: 6| Step: 2
Training loss: 2.7680012467662674
Validation loss: 2.5421926030584903

Epoch: 6| Step: 3
Training loss: 2.2505538046947304
Validation loss: 2.5254852734254927

Epoch: 6| Step: 4
Training loss: 2.554916884830329
Validation loss: 2.521564710775048

Epoch: 6| Step: 5
Training loss: 2.647396637048824
Validation loss: 2.5221896870606413

Epoch: 6| Step: 6
Training loss: 2.658676654645141
Validation loss: 2.5328149903860293

Epoch: 6| Step: 7
Training loss: 3.4918936450051485
Validation loss: 2.5505987239398564

Epoch: 6| Step: 8
Training loss: 3.174763984618735
Validation loss: 2.5192936112303017

Epoch: 6| Step: 9
Training loss: 2.8036480946076696
Validation loss: 2.537798919399965

Epoch: 6| Step: 10
Training loss: 2.6199767778546823
Validation loss: 2.5098971108076387

Epoch: 6| Step: 11
Training loss: 3.3556696839394013
Validation loss: 2.494437395230464

Epoch: 6| Step: 12
Training loss: 2.6827445428736065
Validation loss: 2.4921952006180907

Epoch: 6| Step: 13
Training loss: 3.2850020981408883
Validation loss: 2.4960009399580705

Epoch: 99| Step: 0
Training loss: 3.0942949527934167
Validation loss: 2.4919828056392492

Epoch: 6| Step: 1
Training loss: 2.8767742818754245
Validation loss: 2.5010356388455977

Epoch: 6| Step: 2
Training loss: 3.030234255154753
Validation loss: 2.502068032379496

Epoch: 6| Step: 3
Training loss: 1.9595574617986322
Validation loss: 2.501678904410903

Epoch: 6| Step: 4
Training loss: 2.5934600668032326
Validation loss: 2.507165069214907

Epoch: 6| Step: 5
Training loss: 3.108562114024432
Validation loss: 2.5064039583881508

Epoch: 6| Step: 6
Training loss: 2.5737835946097576
Validation loss: 2.506583730741183

Epoch: 6| Step: 7
Training loss: 2.825285777263172
Validation loss: 2.504446195190525

Epoch: 6| Step: 8
Training loss: 2.8622900273635143
Validation loss: 2.5059177561740533

Epoch: 6| Step: 9
Training loss: 2.385558500334986
Validation loss: 2.5114499763894176

Epoch: 6| Step: 10
Training loss: 3.1183582679109114
Validation loss: 2.5189463028051016

Epoch: 6| Step: 11
Training loss: 2.7154917869773794
Validation loss: 2.5069544896157745

Epoch: 6| Step: 12
Training loss: 3.286905990718519
Validation loss: 2.51152395538829

Epoch: 6| Step: 13
Training loss: 3.1217915658426665
Validation loss: 2.5225337459870847

Epoch: 100| Step: 0
Training loss: 2.6736270447183292
Validation loss: 2.527633384379744

Epoch: 6| Step: 1
Training loss: 3.003295995188752
Validation loss: 2.519074634926326

Epoch: 6| Step: 2
Training loss: 3.1995460426676767
Validation loss: 2.531155901372271

Epoch: 6| Step: 3
Training loss: 2.790450063521445
Validation loss: 2.5232314199599766

Epoch: 6| Step: 4
Training loss: 2.949137584251492
Validation loss: 2.5166175559058224

Epoch: 6| Step: 5
Training loss: 2.8985181113495373
Validation loss: 2.5138117128108006

Epoch: 6| Step: 6
Training loss: 2.6815070822652642
Validation loss: 2.5119855460876224

Epoch: 6| Step: 7
Training loss: 2.2707827034535275
Validation loss: 2.512083459588171

Epoch: 6| Step: 8
Training loss: 2.8514053092376797
Validation loss: 2.5163374498119464

Epoch: 6| Step: 9
Training loss: 3.1607538702628126
Validation loss: 2.5177750558134315

Epoch: 6| Step: 10
Training loss: 2.510934283023618
Validation loss: 2.513566629464415

Epoch: 6| Step: 11
Training loss: 2.9387324568185496
Validation loss: 2.5071066690263017

Epoch: 6| Step: 12
Training loss: 2.5771667549202197
Validation loss: 2.5122539435082767

Epoch: 6| Step: 13
Training loss: 2.8493494931079466
Validation loss: 2.5107473438923926

Epoch: 101| Step: 0
Training loss: 2.7751516283554256
Validation loss: 2.4981303473800733

Epoch: 6| Step: 1
Training loss: 2.8664177217251363
Validation loss: 2.4984785536621157

Epoch: 6| Step: 2
Training loss: 2.64237349367074
Validation loss: 2.492061262430721

Epoch: 6| Step: 3
Training loss: 2.2016401765872384
Validation loss: 2.4889037243461485

Epoch: 6| Step: 4
Training loss: 3.2233527893089367
Validation loss: 2.488012629710991

Epoch: 6| Step: 5
Training loss: 2.54459096143383
Validation loss: 2.4833865669222956

Epoch: 6| Step: 6
Training loss: 3.2669242938949496
Validation loss: 2.483063785002262

Epoch: 6| Step: 7
Training loss: 2.7211273147479935
Validation loss: 2.4888350967515236

Epoch: 6| Step: 8
Training loss: 3.253580908292683
Validation loss: 2.4907991616622907

Epoch: 6| Step: 9
Training loss: 2.7063143222556296
Validation loss: 2.485383592437839

Epoch: 6| Step: 10
Training loss: 3.290463255758982
Validation loss: 2.489196212463956

Epoch: 6| Step: 11
Training loss: 2.373081536687445
Validation loss: 2.4964706139225497

Epoch: 6| Step: 12
Training loss: 2.837773677046616
Validation loss: 2.4995133603128137

Epoch: 6| Step: 13
Training loss: 2.5593362211426585
Validation loss: 2.510095212099878

Epoch: 102| Step: 0
Training loss: 3.1343179258282747
Validation loss: 2.5182583701340753

Epoch: 6| Step: 1
Training loss: 2.9900283393665092
Validation loss: 2.5298272847535412

Epoch: 6| Step: 2
Training loss: 2.9790061071563128
Validation loss: 2.539024246975207

Epoch: 6| Step: 3
Training loss: 2.8701070530294874
Validation loss: 2.529648837396738

Epoch: 6| Step: 4
Training loss: 2.5724053022714077
Validation loss: 2.5319607029525906

Epoch: 6| Step: 5
Training loss: 2.617132658882047
Validation loss: 2.5183731372031146

Epoch: 6| Step: 6
Training loss: 3.0840924505583986
Validation loss: 2.5091000934402987

Epoch: 6| Step: 7
Training loss: 2.932271809394955
Validation loss: 2.501140577332224

Epoch: 6| Step: 8
Training loss: 2.3335896305830732
Validation loss: 2.4984383874100606

Epoch: 6| Step: 9
Training loss: 2.2858380726945815
Validation loss: 2.4982030316968133

Epoch: 6| Step: 10
Training loss: 2.6751071052856474
Validation loss: 2.4982747667493257

Epoch: 6| Step: 11
Training loss: 3.3673138163299368
Validation loss: 2.4973472467219993

Epoch: 6| Step: 12
Training loss: 2.5671010463132187
Validation loss: 2.502796990599299

Epoch: 6| Step: 13
Training loss: 2.7337140837700966
Validation loss: 2.4993076365548457

Epoch: 103| Step: 0
Training loss: 3.07941963350821
Validation loss: 2.501921030527002

Epoch: 6| Step: 1
Training loss: 2.8165776680724472
Validation loss: 2.5088137751315633

Epoch: 6| Step: 2
Training loss: 2.883829242492266
Validation loss: 2.51613967288896

Epoch: 6| Step: 3
Training loss: 2.8826753743957974
Validation loss: 2.517009071305037

Epoch: 6| Step: 4
Training loss: 2.702327897399477
Validation loss: 2.504834351327394

Epoch: 6| Step: 5
Training loss: 3.0682650429583704
Validation loss: 2.512921764612847

Epoch: 6| Step: 6
Training loss: 2.2254319918167385
Validation loss: 2.5057830352609365

Epoch: 6| Step: 7
Training loss: 2.5357561856344546
Validation loss: 2.506483894828962

Epoch: 6| Step: 8
Training loss: 2.6445162841734025
Validation loss: 2.50951952641621

Epoch: 6| Step: 9
Training loss: 3.0238896310334122
Validation loss: 2.5162542584512217

Epoch: 6| Step: 10
Training loss: 2.7824544120406047
Validation loss: 2.5316382013867007

Epoch: 6| Step: 11
Training loss: 2.573218375571752
Validation loss: 2.5293955854724954

Epoch: 6| Step: 12
Training loss: 3.03843733528103
Validation loss: 2.525409755357226

Epoch: 6| Step: 13
Training loss: 3.0257775371439104
Validation loss: 2.53798865795941

Epoch: 104| Step: 0
Training loss: 2.961128007301028
Validation loss: 2.5359095178271818

Epoch: 6| Step: 1
Training loss: 2.6532953322227657
Validation loss: 2.522857863586351

Epoch: 6| Step: 2
Training loss: 2.1694434296880614
Validation loss: 2.5328617805720817

Epoch: 6| Step: 3
Training loss: 1.8147658950061212
Validation loss: 2.5142739372975753

Epoch: 6| Step: 4
Training loss: 2.8559060655527926
Validation loss: 2.5104957843483073

Epoch: 6| Step: 5
Training loss: 3.20395556590764
Validation loss: 2.5046320385766405

Epoch: 6| Step: 6
Training loss: 2.6631061705662447
Validation loss: 2.5000696849340125

Epoch: 6| Step: 7
Training loss: 3.3883696055749843
Validation loss: 2.4975342249894124

Epoch: 6| Step: 8
Training loss: 3.0338340835015716
Validation loss: 2.496465255521326

Epoch: 6| Step: 9
Training loss: 2.7752343602923193
Validation loss: 2.497309212920751

Epoch: 6| Step: 10
Training loss: 2.9681945281119746
Validation loss: 2.4945117389975784

Epoch: 6| Step: 11
Training loss: 3.1896435878717497
Validation loss: 2.4920868960175744

Epoch: 6| Step: 12
Training loss: 2.8568442563289014
Validation loss: 2.4939761323453267

Epoch: 6| Step: 13
Training loss: 1.9220697567891178
Validation loss: 2.4869843788566963

Epoch: 105| Step: 0
Training loss: 3.097272004856905
Validation loss: 2.496230645265825

Epoch: 6| Step: 1
Training loss: 3.02009433169543
Validation loss: 2.4946251629806113

Epoch: 6| Step: 2
Training loss: 2.606024870079739
Validation loss: 2.495967815788213

Epoch: 6| Step: 3
Training loss: 2.480067519530108
Validation loss: 2.497408818163455

Epoch: 6| Step: 4
Training loss: 3.1882641942101535
Validation loss: 2.5040182788935503

Epoch: 6| Step: 5
Training loss: 2.7725399660440906
Validation loss: 2.5154483095930713

Epoch: 6| Step: 6
Training loss: 2.799327095100494
Validation loss: 2.5368640463415613

Epoch: 6| Step: 7
Training loss: 3.2966620932438997
Validation loss: 2.5530377135191418

Epoch: 6| Step: 8
Training loss: 2.836667473953915
Validation loss: 2.541069671408446

Epoch: 6| Step: 9
Training loss: 2.634269152921117
Validation loss: 2.5232960590138807

Epoch: 6| Step: 10
Training loss: 2.8926308760382415
Validation loss: 2.5233036260874133

Epoch: 6| Step: 11
Training loss: 2.7358377086624945
Validation loss: 2.5079985109938345

Epoch: 6| Step: 12
Training loss: 2.167326081018078
Validation loss: 2.5063753321086724

Epoch: 6| Step: 13
Training loss: 2.32568446513145
Validation loss: 2.5059250381239435

Epoch: 106| Step: 0
Training loss: 2.223597751185211
Validation loss: 2.4946794652711763

Epoch: 6| Step: 1
Training loss: 2.820457306840196
Validation loss: 2.4971126197476043

Epoch: 6| Step: 2
Training loss: 2.467147886744603
Validation loss: 2.497256746368707

Epoch: 6| Step: 3
Training loss: 3.1097646497866984
Validation loss: 2.4889370218400013

Epoch: 6| Step: 4
Training loss: 2.446295884783401
Validation loss: 2.4924296399268018

Epoch: 6| Step: 5
Training loss: 2.565686082751713
Validation loss: 2.50204198566655

Epoch: 6| Step: 6
Training loss: 2.453116641668185
Validation loss: 2.5020629892504678

Epoch: 6| Step: 7
Training loss: 3.129238458682692
Validation loss: 2.5111670744555448

Epoch: 6| Step: 8
Training loss: 2.712018767531057
Validation loss: 2.520620715589377

Epoch: 6| Step: 9
Training loss: 2.844801320679211
Validation loss: 2.531354873897157

Epoch: 6| Step: 10
Training loss: 2.6622896532237723
Validation loss: 2.527546555364698

Epoch: 6| Step: 11
Training loss: 3.1707587321491366
Validation loss: 2.512013827272468

Epoch: 6| Step: 12
Training loss: 2.9695131625994793
Validation loss: 2.5088359604991237

Epoch: 6| Step: 13
Training loss: 3.6256392342837604
Validation loss: 2.4943860383827983

Epoch: 107| Step: 0
Training loss: 2.704759225054078
Validation loss: 2.490224005050027

Epoch: 6| Step: 1
Training loss: 3.0270703001500943
Validation loss: 2.4891917241251478

Epoch: 6| Step: 2
Training loss: 2.2490284199562156
Validation loss: 2.488871695418027

Epoch: 6| Step: 3
Training loss: 2.647791060603225
Validation loss: 2.490780817375041

Epoch: 6| Step: 4
Training loss: 3.009430368454822
Validation loss: 2.489517695716323

Epoch: 6| Step: 5
Training loss: 3.0044024272227827
Validation loss: 2.495128688894514

Epoch: 6| Step: 6
Training loss: 2.8897971127581386
Validation loss: 2.5074632005458564

Epoch: 6| Step: 7
Training loss: 2.7309129869308357
Validation loss: 2.534485325625292

Epoch: 6| Step: 8
Training loss: 2.8523494940861602
Validation loss: 2.5551765573123535

Epoch: 6| Step: 9
Training loss: 2.5604730358286942
Validation loss: 2.5545072983390638

Epoch: 6| Step: 10
Training loss: 3.105118181126478
Validation loss: 2.5284077983352926

Epoch: 6| Step: 11
Training loss: 2.9991822717728254
Validation loss: 2.5228858293167664

Epoch: 6| Step: 12
Training loss: 2.57206559616376
Validation loss: 2.5070499056392004

Epoch: 6| Step: 13
Training loss: 2.791348415472798
Validation loss: 2.500363296855767

Epoch: 108| Step: 0
Training loss: 3.1453427233241165
Validation loss: 2.4887533418887156

Epoch: 6| Step: 1
Training loss: 3.0020787666351367
Validation loss: 2.4834857571255755

Epoch: 6| Step: 2
Training loss: 1.9891018775943736
Validation loss: 2.482100749296523

Epoch: 6| Step: 3
Training loss: 3.0902637914753037
Validation loss: 2.488701348568642

Epoch: 6| Step: 4
Training loss: 2.799350516741745
Validation loss: 2.4901587762201163

Epoch: 6| Step: 5
Training loss: 2.7365315679579543
Validation loss: 2.497069343333366

Epoch: 6| Step: 6
Training loss: 2.512618074442014
Validation loss: 2.4994567742360605

Epoch: 6| Step: 7
Training loss: 2.662949584111256
Validation loss: 2.5081852788636665

Epoch: 6| Step: 8
Training loss: 2.819653885886324
Validation loss: 2.4949370996127547

Epoch: 6| Step: 9
Training loss: 2.5560145299973107
Validation loss: 2.4961318731875046

Epoch: 6| Step: 10
Training loss: 2.030061814442847
Validation loss: 2.48884302714347

Epoch: 6| Step: 11
Training loss: 3.048312742964287
Validation loss: 2.4797281353490175

Epoch: 6| Step: 12
Training loss: 3.2091441100212807
Validation loss: 2.483256391511693

Epoch: 6| Step: 13
Training loss: 3.200618004726996
Validation loss: 2.476674270009839

Epoch: 109| Step: 0
Training loss: 2.8284841067113926
Validation loss: 2.47189605161718

Epoch: 6| Step: 1
Training loss: 3.5474939016406686
Validation loss: 2.4754060888358955

Epoch: 6| Step: 2
Training loss: 2.0945522991689316
Validation loss: 2.4722115255189485

Epoch: 6| Step: 3
Training loss: 3.3869682316919114
Validation loss: 2.4735171085971586

Epoch: 6| Step: 4
Training loss: 2.8436353052505834
Validation loss: 2.4817472246140766

Epoch: 6| Step: 5
Training loss: 3.3330474413022806
Validation loss: 2.4799684593138083

Epoch: 6| Step: 6
Training loss: 1.9390415703860453
Validation loss: 2.488743051265508

Epoch: 6| Step: 7
Training loss: 2.1643592823767612
Validation loss: 2.49015303258331

Epoch: 6| Step: 8
Training loss: 2.6339814169249203
Validation loss: 2.4918980728220688

Epoch: 6| Step: 9
Training loss: 2.7918903963387347
Validation loss: 2.4929095058930626

Epoch: 6| Step: 10
Training loss: 2.8089132538408053
Validation loss: 2.4902145039430934

Epoch: 6| Step: 11
Training loss: 2.6366362834326016
Validation loss: 2.4982124942125616

Epoch: 6| Step: 12
Training loss: 2.5631831119240553
Validation loss: 2.4987107285207437

Epoch: 6| Step: 13
Training loss: 2.71666216430603
Validation loss: 2.484601914979948

Epoch: 110| Step: 0
Training loss: 3.1246285790016493
Validation loss: 2.4745533745807116

Epoch: 6| Step: 1
Training loss: 2.092942039259498
Validation loss: 2.472104407549608

Epoch: 6| Step: 2
Training loss: 2.5363198829374785
Validation loss: 2.474821690599479

Epoch: 6| Step: 3
Training loss: 2.565686175677569
Validation loss: 2.4698207885599155

Epoch: 6| Step: 4
Training loss: 3.095812023666241
Validation loss: 2.469101768220731

Epoch: 6| Step: 5
Training loss: 2.969448930883473
Validation loss: 2.4694406662977477

Epoch: 6| Step: 6
Training loss: 2.887564693898683
Validation loss: 2.4683581490765616

Epoch: 6| Step: 7
Training loss: 2.5819059448308495
Validation loss: 2.4675766386649145

Epoch: 6| Step: 8
Training loss: 2.992379364157092
Validation loss: 2.470016768205412

Epoch: 6| Step: 9
Training loss: 2.8894829220825713
Validation loss: 2.477514081370464

Epoch: 6| Step: 10
Training loss: 2.4794930529057666
Validation loss: 2.4824099026765785

Epoch: 6| Step: 11
Training loss: 2.7462442934708826
Validation loss: 2.486433115068394

Epoch: 6| Step: 12
Training loss: 3.0075968875642123
Validation loss: 2.4954145792221807

Epoch: 6| Step: 13
Training loss: 2.929994612809264
Validation loss: 2.502574913355282

Epoch: 111| Step: 0
Training loss: 2.7367337761416635
Validation loss: 2.520455240444964

Epoch: 6| Step: 1
Training loss: 3.2984307401543562
Validation loss: 2.525944632030339

Epoch: 6| Step: 2
Training loss: 3.486071528547347
Validation loss: 2.55005780306728

Epoch: 6| Step: 3
Training loss: 2.6266894580446096
Validation loss: 2.547863660984177

Epoch: 6| Step: 4
Training loss: 2.313832388904627
Validation loss: 2.5327520579028566

Epoch: 6| Step: 5
Training loss: 2.8578442087390523
Validation loss: 2.5167208464110025

Epoch: 6| Step: 6
Training loss: 2.146542688051462
Validation loss: 2.5180762822990013

Epoch: 6| Step: 7
Training loss: 3.036408429965319
Validation loss: 2.52249838067539

Epoch: 6| Step: 8
Training loss: 2.702869381146734
Validation loss: 2.4898989238800033

Epoch: 6| Step: 9
Training loss: 2.6175015844651814
Validation loss: 2.4671206961758765

Epoch: 6| Step: 10
Training loss: 2.6040578794009206
Validation loss: 2.4660448731818927

Epoch: 6| Step: 11
Training loss: 3.2632148281111215
Validation loss: 2.4650463107277734

Epoch: 6| Step: 12
Training loss: 2.7035553870703355
Validation loss: 2.46646047305166

Epoch: 6| Step: 13
Training loss: 2.1298098265234295
Validation loss: 2.4659543275839146

Epoch: 112| Step: 0
Training loss: 2.8891277662779005
Validation loss: 2.472141969442919

Epoch: 6| Step: 1
Training loss: 3.2598841093093984
Validation loss: 2.467107208328905

Epoch: 6| Step: 2
Training loss: 2.779184924918331
Validation loss: 2.473038718389262

Epoch: 6| Step: 3
Training loss: 2.881633238222537
Validation loss: 2.4836654697271277

Epoch: 6| Step: 4
Training loss: 2.975381131161416
Validation loss: 2.4891788584702965

Epoch: 6| Step: 5
Training loss: 2.8761455078242713
Validation loss: 2.49755375193983

Epoch: 6| Step: 6
Training loss: 2.7014017069386362
Validation loss: 2.5105368156072467

Epoch: 6| Step: 7
Training loss: 1.8326042922085741
Validation loss: 2.5097658895597195

Epoch: 6| Step: 8
Training loss: 3.033453071941752
Validation loss: 2.5051968949289845

Epoch: 6| Step: 9
Training loss: 2.708075427955901
Validation loss: 2.514890000484436

Epoch: 6| Step: 10
Training loss: 2.7852797728295355
Validation loss: 2.510900494639441

Epoch: 6| Step: 11
Training loss: 2.881118731704613
Validation loss: 2.5075525304897286

Epoch: 6| Step: 12
Training loss: 2.358265091500693
Validation loss: 2.497676948300631

Epoch: 6| Step: 13
Training loss: 2.036357737314362
Validation loss: 2.4931929278700724

Epoch: 113| Step: 0
Training loss: 2.9766733544400203
Validation loss: 2.489386525825208

Epoch: 6| Step: 1
Training loss: 2.858357232738114
Validation loss: 2.4845315908772423

Epoch: 6| Step: 2
Training loss: 3.1440203328627807
Validation loss: 2.471284191048122

Epoch: 6| Step: 3
Training loss: 2.496868843004181
Validation loss: 2.478716612870516

Epoch: 6| Step: 4
Training loss: 2.589712378390563
Validation loss: 2.4811192319843656

Epoch: 6| Step: 5
Training loss: 2.595365733428082
Validation loss: 2.474054373586259

Epoch: 6| Step: 6
Training loss: 3.30123685141577
Validation loss: 2.4824660253480637

Epoch: 6| Step: 7
Training loss: 2.7640350426689695
Validation loss: 2.482564951827857

Epoch: 6| Step: 8
Training loss: 3.0644501685474106
Validation loss: 2.498980532715235

Epoch: 6| Step: 9
Training loss: 2.1221603044439337
Validation loss: 2.5043515475296867

Epoch: 6| Step: 10
Training loss: 2.2095815861442265
Validation loss: 2.4847583894139844

Epoch: 6| Step: 11
Training loss: 2.9138569695448067
Validation loss: 2.4851076595301924

Epoch: 6| Step: 12
Training loss: 3.1354226823075253
Validation loss: 2.4728244976389413

Epoch: 6| Step: 13
Training loss: 1.5644396377725043
Validation loss: 2.4714333071956758

Epoch: 114| Step: 0
Training loss: 3.2357390102956423
Validation loss: 2.469487834023406

Epoch: 6| Step: 1
Training loss: 2.8889957269654802
Validation loss: 2.46920801194809

Epoch: 6| Step: 2
Training loss: 2.49419071442949
Validation loss: 2.4665282566340703

Epoch: 6| Step: 3
Training loss: 2.7846683540323904
Validation loss: 2.4681560362076587

Epoch: 6| Step: 4
Training loss: 3.236401204289566
Validation loss: 2.462920748670747

Epoch: 6| Step: 5
Training loss: 2.4367883083423707
Validation loss: 2.4723449987023343

Epoch: 6| Step: 6
Training loss: 2.8167084466969325
Validation loss: 2.470909933928734

Epoch: 6| Step: 7
Training loss: 2.897935355972003
Validation loss: 2.486684471692238

Epoch: 6| Step: 8
Training loss: 2.2762493559633756
Validation loss: 2.4878312423231734

Epoch: 6| Step: 9
Training loss: 2.615086318391177
Validation loss: 2.5048089715250565

Epoch: 6| Step: 10
Training loss: 2.5225465695758147
Validation loss: 2.5027224053606987

Epoch: 6| Step: 11
Training loss: 2.2794871377517216
Validation loss: 2.517815204796437

Epoch: 6| Step: 12
Training loss: 3.186351344762995
Validation loss: 2.5277360148065484

Epoch: 6| Step: 13
Training loss: 2.5791689521972523
Validation loss: 2.5322613120752195

Epoch: 115| Step: 0
Training loss: 2.984522471354344
Validation loss: 2.5515181403837968

Epoch: 6| Step: 1
Training loss: 2.917980515789532
Validation loss: 2.5436966268960703

Epoch: 6| Step: 2
Training loss: 2.2728903200444814
Validation loss: 2.5194367849160106

Epoch: 6| Step: 3
Training loss: 2.5973371037208457
Validation loss: 2.5041906836992935

Epoch: 6| Step: 4
Training loss: 2.725986627575323
Validation loss: 2.5016556661500786

Epoch: 6| Step: 5
Training loss: 3.3143460869575554
Validation loss: 2.5030722004647523

Epoch: 6| Step: 6
Training loss: 3.0552181943900556
Validation loss: 2.4935910285913416

Epoch: 6| Step: 7
Training loss: 2.258820094428536
Validation loss: 2.482559111107162

Epoch: 6| Step: 8
Training loss: 2.973470207992645
Validation loss: 2.4865117026351906

Epoch: 6| Step: 9
Training loss: 3.1253306404672854
Validation loss: 2.482283334140278

Epoch: 6| Step: 10
Training loss: 2.369542728525816
Validation loss: 2.486299066509344

Epoch: 6| Step: 11
Training loss: 2.4124117148260233
Validation loss: 2.4864057899909406

Epoch: 6| Step: 12
Training loss: 3.062766238726203
Validation loss: 2.4822813357194855

Epoch: 6| Step: 13
Training loss: 1.8202067987098554
Validation loss: 2.4856176856189935

Epoch: 116| Step: 0
Training loss: 2.3158874445364823
Validation loss: 2.4796208608191606

Epoch: 6| Step: 1
Training loss: 2.8508182756356537
Validation loss: 2.4752433143491785

Epoch: 6| Step: 2
Training loss: 3.1582837492607796
Validation loss: 2.471454180362956

Epoch: 6| Step: 3
Training loss: 2.6793422643407134
Validation loss: 2.4663049259962033

Epoch: 6| Step: 4
Training loss: 2.5744135179483623
Validation loss: 2.457493153724877

Epoch: 6| Step: 5
Training loss: 2.910810932022625
Validation loss: 2.453606490283593

Epoch: 6| Step: 6
Training loss: 2.9445280047221933
Validation loss: 2.458907509963552

Epoch: 6| Step: 7
Training loss: 2.456334341217316
Validation loss: 2.4575917157902714

Epoch: 6| Step: 8
Training loss: 3.0580421232886277
Validation loss: 2.4606957611980973

Epoch: 6| Step: 9
Training loss: 2.457933511925791
Validation loss: 2.4661221685914754

Epoch: 6| Step: 10
Training loss: 2.242418018148096
Validation loss: 2.4790934617969667

Epoch: 6| Step: 11
Training loss: 3.231072107727098
Validation loss: 2.4931013178299892

Epoch: 6| Step: 12
Training loss: 2.967753674816973
Validation loss: 2.4853390369615003

Epoch: 6| Step: 13
Training loss: 2.182044938615092
Validation loss: 2.507190673126879

Epoch: 117| Step: 0
Training loss: 2.662125674874438
Validation loss: 2.5167433583255567

Epoch: 6| Step: 1
Training loss: 3.322966253375038
Validation loss: 2.527205996944994

Epoch: 6| Step: 2
Training loss: 3.2383003924532225
Validation loss: 2.536577047646835

Epoch: 6| Step: 3
Training loss: 2.300210930647442
Validation loss: 2.544843200087524

Epoch: 6| Step: 4
Training loss: 2.6244682500033942
Validation loss: 2.5413612307943705

Epoch: 6| Step: 5
Training loss: 2.4757499444871596
Validation loss: 2.5303710095979186

Epoch: 6| Step: 6
Training loss: 2.3155483052967383
Validation loss: 2.528135225803735

Epoch: 6| Step: 7
Training loss: 2.1813520959608366
Validation loss: 2.5206727115962524

Epoch: 6| Step: 8
Training loss: 3.13028026800707
Validation loss: 2.5225117552811307

Epoch: 6| Step: 9
Training loss: 3.0586271125854445
Validation loss: 2.5206978060695975

Epoch: 6| Step: 10
Training loss: 3.3368290373185125
Validation loss: 2.505969874131122

Epoch: 6| Step: 11
Training loss: 2.2805399377525326
Validation loss: 2.4896017125308076

Epoch: 6| Step: 12
Training loss: 2.3476915912221346
Validation loss: 2.4764288850743843

Epoch: 6| Step: 13
Training loss: 3.144471351574312
Validation loss: 2.464475251417815

Epoch: 118| Step: 0
Training loss: 2.406778549999774
Validation loss: 2.462337896411436

Epoch: 6| Step: 1
Training loss: 2.279107224028072
Validation loss: 2.4628821702165875

Epoch: 6| Step: 2
Training loss: 2.5695005485205984
Validation loss: 2.4603277562768104

Epoch: 6| Step: 3
Training loss: 3.0598346244155046
Validation loss: 2.471596000166295

Epoch: 6| Step: 4
Training loss: 2.5753262211346493
Validation loss: 2.475683693305697

Epoch: 6| Step: 5
Training loss: 2.4504582190681066
Validation loss: 2.4780490603895395

Epoch: 6| Step: 6
Training loss: 2.606256414538204
Validation loss: 2.4871805346714453

Epoch: 6| Step: 7
Training loss: 2.383336544257004
Validation loss: 2.5010067727633074

Epoch: 6| Step: 8
Training loss: 2.949305087208938
Validation loss: 2.50546075153333

Epoch: 6| Step: 9
Training loss: 2.947943122304728
Validation loss: 2.4954084223625514

Epoch: 6| Step: 10
Training loss: 2.866901435405834
Validation loss: 2.509135848875105

Epoch: 6| Step: 11
Training loss: 3.2386860151606798
Validation loss: 2.507717501466682

Epoch: 6| Step: 12
Training loss: 3.202134588688031
Validation loss: 2.50095817293059

Epoch: 6| Step: 13
Training loss: 2.741969521056103
Validation loss: 2.469578349723992

Epoch: 119| Step: 0
Training loss: 2.912398858012806
Validation loss: 2.454212426074595

Epoch: 6| Step: 1
Training loss: 2.5457116026632565
Validation loss: 2.456193404140716

Epoch: 6| Step: 2
Training loss: 3.4035762827430753
Validation loss: 2.4561591800115727

Epoch: 6| Step: 3
Training loss: 2.697792570777792
Validation loss: 2.46361414857737

Epoch: 6| Step: 4
Training loss: 3.0747116449886973
Validation loss: 2.4698325271213464

Epoch: 6| Step: 5
Training loss: 2.4763207543252554
Validation loss: 2.466491359688184

Epoch: 6| Step: 6
Training loss: 2.593043403435826
Validation loss: 2.465221918877014

Epoch: 6| Step: 7
Training loss: 2.451472703931524
Validation loss: 2.462930795363869

Epoch: 6| Step: 8
Training loss: 2.5129624012427674
Validation loss: 2.465516404322991

Epoch: 6| Step: 9
Training loss: 3.1621968361514763
Validation loss: 2.46696177805303

Epoch: 6| Step: 10
Training loss: 2.4777586542293415
Validation loss: 2.4701974264590487

Epoch: 6| Step: 11
Training loss: 2.6627209997018872
Validation loss: 2.4786447989319713

Epoch: 6| Step: 12
Training loss: 2.3980749396735463
Validation loss: 2.50030357199469

Epoch: 6| Step: 13
Training loss: 3.3132717744979163
Validation loss: 2.5161660321567667

Epoch: 120| Step: 0
Training loss: 2.71372064645742
Validation loss: 2.5381645973850464

Epoch: 6| Step: 1
Training loss: 2.79320178360219
Validation loss: 2.5507582042976984

Epoch: 6| Step: 2
Training loss: 2.9637804700555366
Validation loss: 2.537656001794644

Epoch: 6| Step: 3
Training loss: 2.985130973255652
Validation loss: 2.5184364432483144

Epoch: 6| Step: 4
Training loss: 2.7893948397057997
Validation loss: 2.5012473757916

Epoch: 6| Step: 5
Training loss: 2.589655758578157
Validation loss: 2.503978358149626

Epoch: 6| Step: 6
Training loss: 3.0853777800347606
Validation loss: 2.476895164909507

Epoch: 6| Step: 7
Training loss: 2.206534054546748
Validation loss: 2.470935730914348

Epoch: 6| Step: 8
Training loss: 2.572302143877537
Validation loss: 2.4653707429453218

Epoch: 6| Step: 9
Training loss: 2.4116291510197705
Validation loss: 2.458632773872188

Epoch: 6| Step: 10
Training loss: 3.116527210182295
Validation loss: 2.4557607512991386

Epoch: 6| Step: 11
Training loss: 2.1310429760570297
Validation loss: 2.4556590318519604

Epoch: 6| Step: 12
Training loss: 2.7389726622973094
Validation loss: 2.4472408376735637

Epoch: 6| Step: 13
Training loss: 3.597728219073513
Validation loss: 2.4672365234033276

Epoch: 121| Step: 0
Training loss: 2.074346448627694
Validation loss: 2.4773059217107245

Epoch: 6| Step: 1
Training loss: 2.855089822615505
Validation loss: 2.47415383430551

Epoch: 6| Step: 2
Training loss: 2.642538156369257
Validation loss: 2.4843867771114354

Epoch: 6| Step: 3
Training loss: 2.360489739827016
Validation loss: 2.4784315964780084

Epoch: 6| Step: 4
Training loss: 2.7333911106547033
Validation loss: 2.492997982444171

Epoch: 6| Step: 5
Training loss: 3.172474170336174
Validation loss: 2.4992240665545173

Epoch: 6| Step: 6
Training loss: 3.094121120811838
Validation loss: 2.495437071715246

Epoch: 6| Step: 7
Training loss: 3.1027851145251657
Validation loss: 2.4809654544032034

Epoch: 6| Step: 8
Training loss: 2.310892319511649
Validation loss: 2.466080898379423

Epoch: 6| Step: 9
Training loss: 2.3619976498610704
Validation loss: 2.461480262387212

Epoch: 6| Step: 10
Training loss: 3.0395438394122536
Validation loss: 2.455371304511004

Epoch: 6| Step: 11
Training loss: 2.6522587129110167
Validation loss: 2.456208013402022

Epoch: 6| Step: 12
Training loss: 2.8503055676398024
Validation loss: 2.4588035445264707

Epoch: 6| Step: 13
Training loss: 3.0019548722648626
Validation loss: 2.466937620936967

Epoch: 122| Step: 0
Training loss: 2.2675873775112696
Validation loss: 2.471357329867614

Epoch: 6| Step: 1
Training loss: 2.9824807111910974
Validation loss: 2.485101208918028

Epoch: 6| Step: 2
Training loss: 1.4074570879314905
Validation loss: 2.4860061344084277

Epoch: 6| Step: 3
Training loss: 3.6361344438631056
Validation loss: 2.487431868330562

Epoch: 6| Step: 4
Training loss: 2.6066716061258304
Validation loss: 2.4861821238400315

Epoch: 6| Step: 5
Training loss: 2.3006129567588376
Validation loss: 2.479065359859624

Epoch: 6| Step: 6
Training loss: 2.477348708259387
Validation loss: 2.4786602180980157

Epoch: 6| Step: 7
Training loss: 3.0544937735784616
Validation loss: 2.4670649279190218

Epoch: 6| Step: 8
Training loss: 3.0665972024541484
Validation loss: 2.4673244648795163

Epoch: 6| Step: 9
Training loss: 2.622168239704164
Validation loss: 2.4534067567292985

Epoch: 6| Step: 10
Training loss: 3.1251025373802737
Validation loss: 2.4718316583782665

Epoch: 6| Step: 11
Training loss: 3.0459463415998913
Validation loss: 2.4735460425943336

Epoch: 6| Step: 12
Training loss: 2.4087136277450294
Validation loss: 2.4762307221689883

Epoch: 6| Step: 13
Training loss: 2.4540794119573373
Validation loss: 2.47793560290463

Epoch: 123| Step: 0
Training loss: 1.7189946780740977
Validation loss: 2.4836954012956522

Epoch: 6| Step: 1
Training loss: 2.9939445735003
Validation loss: 2.4977317949440345

Epoch: 6| Step: 2
Training loss: 2.7739527264055024
Validation loss: 2.4899219078996455

Epoch: 6| Step: 3
Training loss: 2.3779964617806333
Validation loss: 2.4755560342221647

Epoch: 6| Step: 4
Training loss: 2.6374023455579803
Validation loss: 2.4822209826535753

Epoch: 6| Step: 5
Training loss: 2.520582538666115
Validation loss: 2.4802928223643876

Epoch: 6| Step: 6
Training loss: 2.768698154075989
Validation loss: 2.468119230592417

Epoch: 6| Step: 7
Training loss: 2.2768581389547125
Validation loss: 2.455734752101956

Epoch: 6| Step: 8
Training loss: 3.3559518805999504
Validation loss: 2.4462137352618907

Epoch: 6| Step: 9
Training loss: 3.1807025910603968
Validation loss: 2.444725569268939

Epoch: 6| Step: 10
Training loss: 2.871077972161154
Validation loss: 2.436318906757914

Epoch: 6| Step: 11
Training loss: 2.66936191806611
Validation loss: 2.440485247146102

Epoch: 6| Step: 12
Training loss: 2.8420613064257467
Validation loss: 2.4484382651433774

Epoch: 6| Step: 13
Training loss: 3.1027347069550055
Validation loss: 2.4465693357901364

Epoch: 124| Step: 0
Training loss: 2.883047037482551
Validation loss: 2.452321860776414

Epoch: 6| Step: 1
Training loss: 2.6847977470786333
Validation loss: 2.4523095533312045

Epoch: 6| Step: 2
Training loss: 2.550941357107914
Validation loss: 2.4496121471440357

Epoch: 6| Step: 3
Training loss: 2.7990665480650554
Validation loss: 2.4484861740805863

Epoch: 6| Step: 4
Training loss: 3.011168987598504
Validation loss: 2.4493152408178926

Epoch: 6| Step: 5
Training loss: 3.3663646285537654
Validation loss: 2.4584541756900484

Epoch: 6| Step: 6
Training loss: 2.128819567114276
Validation loss: 2.4742385209921656

Epoch: 6| Step: 7
Training loss: 2.789794398426512
Validation loss: 2.48315652211105

Epoch: 6| Step: 8
Training loss: 1.7949325677430756
Validation loss: 2.486653926598112

Epoch: 6| Step: 9
Training loss: 2.7968589739633383
Validation loss: 2.493550508077687

Epoch: 6| Step: 10
Training loss: 3.3633814851044272
Validation loss: 2.5096180627260947

Epoch: 6| Step: 11
Training loss: 2.5829290771022126
Validation loss: 2.4844513753237902

Epoch: 6| Step: 12
Training loss: 2.1784596693689084
Validation loss: 2.475253932451759

Epoch: 6| Step: 13
Training loss: 3.2689937755937386
Validation loss: 2.4762403110951654

Epoch: 125| Step: 0
Training loss: 2.7140493863699815
Validation loss: 2.46606147203324

Epoch: 6| Step: 1
Training loss: 2.6328740777758113
Validation loss: 2.459323901090853

Epoch: 6| Step: 2
Training loss: 3.2826381108673774
Validation loss: 2.460777322036097

Epoch: 6| Step: 3
Training loss: 2.4086367177332275
Validation loss: 2.454937453106742

Epoch: 6| Step: 4
Training loss: 3.00286220071524
Validation loss: 2.4521267439607026

Epoch: 6| Step: 5
Training loss: 2.509059512780013
Validation loss: 2.452976663072023

Epoch: 6| Step: 6
Training loss: 2.236006987722871
Validation loss: 2.4594340966752926

Epoch: 6| Step: 7
Training loss: 2.8632356189875234
Validation loss: 2.4630649395635804

Epoch: 6| Step: 8
Training loss: 3.07313652329673
Validation loss: 2.5017936968075833

Epoch: 6| Step: 9
Training loss: 2.473697003398764
Validation loss: 2.5084164305982415

Epoch: 6| Step: 10
Training loss: 3.009819807571186
Validation loss: 2.501282715640635

Epoch: 6| Step: 11
Training loss: 2.4752663671324013
Validation loss: 2.4863327638923263

Epoch: 6| Step: 12
Training loss: 2.8117524743078155
Validation loss: 2.4835283948846834

Epoch: 6| Step: 13
Training loss: 2.254165396510793
Validation loss: 2.472909849790389

Testing loss: 2.682922534022872
