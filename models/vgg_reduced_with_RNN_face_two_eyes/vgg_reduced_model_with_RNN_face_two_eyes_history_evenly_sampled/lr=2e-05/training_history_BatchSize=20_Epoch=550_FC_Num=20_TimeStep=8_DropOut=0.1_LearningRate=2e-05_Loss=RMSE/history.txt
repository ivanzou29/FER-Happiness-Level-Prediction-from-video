Epoch: 1| Step: 0
Training loss: 5.51974100306951
Validation loss: 5.784953702600152

Epoch: 5| Step: 1
Training loss: 6.470669816262745
Validation loss: 5.761096208052699

Epoch: 5| Step: 2
Training loss: 5.455085642393227
Validation loss: 5.740247049750917

Epoch: 5| Step: 3
Training loss: 6.227872818331199
Validation loss: 5.721938580828861

Epoch: 5| Step: 4
Training loss: 5.546468886431645
Validation loss: 5.701670743016466

Epoch: 5| Step: 5
Training loss: 6.327864577974745
Validation loss: 5.680446796245429

Epoch: 5| Step: 6
Training loss: 6.079609118495317
Validation loss: 5.656408686279538

Epoch: 5| Step: 7
Training loss: 4.583082828033786
Validation loss: 5.62853544783484

Epoch: 5| Step: 8
Training loss: 5.098831544052424
Validation loss: 5.598083813635345

Epoch: 5| Step: 9
Training loss: 5.204052724983126
Validation loss: 5.562774186879263

Epoch: 5| Step: 10
Training loss: 6.092873847771141
Validation loss: 5.525199386227703

Epoch: 2| Step: 0
Training loss: 5.339158254852663
Validation loss: 5.482820452106189

Epoch: 5| Step: 1
Training loss: 5.890740593299694
Validation loss: 5.4351725620156115

Epoch: 5| Step: 2
Training loss: 5.67279902726255
Validation loss: 5.385316415543374

Epoch: 5| Step: 3
Training loss: 5.253625979978019
Validation loss: 5.332293391102792

Epoch: 5| Step: 4
Training loss: 5.434263120950678
Validation loss: 5.276343604177833

Epoch: 5| Step: 5
Training loss: 5.123741553644653
Validation loss: 5.218356840736585

Epoch: 5| Step: 6
Training loss: 4.351675145114065
Validation loss: 5.161523147556359

Epoch: 5| Step: 7
Training loss: 6.283179750597648
Validation loss: 5.1050522371500655

Epoch: 5| Step: 8
Training loss: 4.9129140509524385
Validation loss: 5.0507554733425275

Epoch: 5| Step: 9
Training loss: 4.445437786569261
Validation loss: 4.9996254934522755

Epoch: 5| Step: 10
Training loss: 5.0253020010767875
Validation loss: 4.949106620697254

Epoch: 3| Step: 0
Training loss: 4.152524727065056
Validation loss: 4.903587292294911

Epoch: 5| Step: 1
Training loss: 5.260206201957237
Validation loss: 4.859722415061529

Epoch: 5| Step: 2
Training loss: 4.469561523164279
Validation loss: 4.821903695484929

Epoch: 5| Step: 3
Training loss: 4.09093862195386
Validation loss: 4.791507078761682

Epoch: 5| Step: 4
Training loss: 5.377631496948054
Validation loss: 4.764433069853652

Epoch: 5| Step: 5
Training loss: 5.4434084306634185
Validation loss: 4.739914255941209

Epoch: 5| Step: 6
Training loss: 4.914366404925993
Validation loss: 4.71339746296673

Epoch: 5| Step: 7
Training loss: 5.807510038868853
Validation loss: 4.684307555200537

Epoch: 5| Step: 8
Training loss: 4.692163411071303
Validation loss: 4.644645415806845

Epoch: 5| Step: 9
Training loss: 4.744106853265963
Validation loss: 4.605348785607276

Epoch: 5| Step: 10
Training loss: 3.5061143872695673
Validation loss: 4.567538971684978

Epoch: 4| Step: 0
Training loss: 5.145336461757141
Validation loss: 4.533916352263474

Epoch: 5| Step: 1
Training loss: 4.5522433441229095
Validation loss: 4.503269844275888

Epoch: 5| Step: 2
Training loss: 5.243489542916046
Validation loss: 4.475678487033204

Epoch: 5| Step: 3
Training loss: 3.5531808867207033
Validation loss: 4.45193037104417

Epoch: 5| Step: 4
Training loss: 4.678508629164219
Validation loss: 4.433184896502749

Epoch: 5| Step: 5
Training loss: 5.033781374427887
Validation loss: 4.408134728200132

Epoch: 5| Step: 6
Training loss: 4.384915478021172
Validation loss: 4.386247124785477

Epoch: 5| Step: 7
Training loss: 5.183950473725428
Validation loss: 4.3768375598533895

Epoch: 5| Step: 8
Training loss: 3.8135552118570195
Validation loss: 4.366402766073278

Epoch: 5| Step: 9
Training loss: 4.319449312644142
Validation loss: 4.3526645798856265

Epoch: 5| Step: 10
Training loss: 3.4068574976117216
Validation loss: 4.338112953657995

Epoch: 5| Step: 0
Training loss: 4.411015956395774
Validation loss: 4.325224394925056

Epoch: 5| Step: 1
Training loss: 4.37728821996502
Validation loss: 4.316473144939416

Epoch: 5| Step: 2
Training loss: 5.130078846286499
Validation loss: 4.300127724259934

Epoch: 5| Step: 3
Training loss: 5.394539382121858
Validation loss: 4.282550592358965

Epoch: 5| Step: 4
Training loss: 3.7696328263111565
Validation loss: 4.2676895219799444

Epoch: 5| Step: 5
Training loss: 3.821648549368151
Validation loss: 4.257273834435332

Epoch: 5| Step: 6
Training loss: 4.267114176726093
Validation loss: 4.25109266293503

Epoch: 5| Step: 7
Training loss: 4.088081687111103
Validation loss: 4.237314554102921

Epoch: 5| Step: 8
Training loss: 4.213710685643898
Validation loss: 4.223602258468716

Epoch: 5| Step: 9
Training loss: 3.966237632138277
Validation loss: 4.2114800760705515

Epoch: 5| Step: 10
Training loss: 4.625068664041079
Validation loss: 4.20374151306446

Epoch: 6| Step: 0
Training loss: 5.677304698116344
Validation loss: 4.191504861453612

Epoch: 5| Step: 1
Training loss: 4.1659771666649625
Validation loss: 4.175561800816036

Epoch: 5| Step: 2
Training loss: 3.420239340678072
Validation loss: 4.160978925891356

Epoch: 5| Step: 3
Training loss: 3.9329524346100695
Validation loss: 4.149193341103417

Epoch: 5| Step: 4
Training loss: 4.24681106305923
Validation loss: 4.139864949056759

Epoch: 5| Step: 5
Training loss: 3.721105775046836
Validation loss: 4.132155039136993

Epoch: 5| Step: 6
Training loss: 4.774437532700801
Validation loss: 4.12185326180011

Epoch: 5| Step: 7
Training loss: 3.6398313254795056
Validation loss: 4.105533142293608

Epoch: 5| Step: 8
Training loss: 4.39380332512871
Validation loss: 4.093189956743651

Epoch: 5| Step: 9
Training loss: 4.441176060437673
Validation loss: 4.083898593501545

Epoch: 5| Step: 10
Training loss: 4.1225638854360955
Validation loss: 4.076369579193261

Epoch: 7| Step: 0
Training loss: 3.9539152418515617
Validation loss: 4.066028142661486

Epoch: 5| Step: 1
Training loss: 3.8848676250985146
Validation loss: 4.057797290878169

Epoch: 5| Step: 2
Training loss: 4.38436258413524
Validation loss: 4.046307130742061

Epoch: 5| Step: 3
Training loss: 3.439572628442814
Validation loss: 4.038688455901889

Epoch: 5| Step: 4
Training loss: 4.185485583064412
Validation loss: 4.028120325100537

Epoch: 5| Step: 5
Training loss: 4.6700754431567155
Validation loss: 4.02349561264422

Epoch: 5| Step: 6
Training loss: 3.897404046385395
Validation loss: 4.0122499471022675

Epoch: 5| Step: 7
Training loss: 4.492103642220011
Validation loss: 4.002556675951267

Epoch: 5| Step: 8
Training loss: 4.366289677738613
Validation loss: 3.9959116982782983

Epoch: 5| Step: 9
Training loss: 4.059569960119963
Validation loss: 3.9876543795213224

Epoch: 5| Step: 10
Training loss: 4.476311109051686
Validation loss: 3.9801225038760926

Epoch: 8| Step: 0
Training loss: 3.737181817739508
Validation loss: 3.974734661264962

Epoch: 5| Step: 1
Training loss: 4.967112913288702
Validation loss: 3.963240322317159

Epoch: 5| Step: 2
Training loss: 3.772835187841401
Validation loss: 3.9535651606581155

Epoch: 5| Step: 3
Training loss: 3.906765224810617
Validation loss: 3.949346907272615

Epoch: 5| Step: 4
Training loss: 5.0948601197572225
Validation loss: 3.9432374191723896

Epoch: 5| Step: 5
Training loss: 4.561516224604927
Validation loss: 3.9315244351466614

Epoch: 5| Step: 6
Training loss: 4.218405702458243
Validation loss: 3.9224899549172694

Epoch: 5| Step: 7
Training loss: 3.985052552301474
Validation loss: 3.915007659890367

Epoch: 5| Step: 8
Training loss: 3.162209502738391
Validation loss: 3.909456770295447

Epoch: 5| Step: 9
Training loss: 3.636316590655047
Validation loss: 3.9024496040627894

Epoch: 5| Step: 10
Training loss: 3.4889795644549255
Validation loss: 3.8936367549047772

Epoch: 9| Step: 0
Training loss: 3.9011339788715227
Validation loss: 3.8857393683627848

Epoch: 5| Step: 1
Training loss: 3.840631475978572
Validation loss: 3.879560414201215

Epoch: 5| Step: 2
Training loss: 5.556623462187906
Validation loss: 3.8682828487001606

Epoch: 5| Step: 3
Training loss: 3.4976118659670647
Validation loss: 3.861483873860403

Epoch: 5| Step: 4
Training loss: 2.8337562095866846
Validation loss: 3.8558871649800115

Epoch: 5| Step: 5
Training loss: 4.298239751307132
Validation loss: 3.851645372946832

Epoch: 5| Step: 6
Training loss: 4.341131724803984
Validation loss: 3.842358718631656

Epoch: 5| Step: 7
Training loss: 3.8883227541752765
Validation loss: 3.836270577121968

Epoch: 5| Step: 8
Training loss: 3.795631990142069
Validation loss: 3.834217367295014

Epoch: 5| Step: 9
Training loss: 3.6809130529007525
Validation loss: 3.830080333835272

Epoch: 5| Step: 10
Training loss: 4.068410945424468
Validation loss: 3.8169216509493196

Epoch: 10| Step: 0
Training loss: 4.682761683934534
Validation loss: 3.81266576661108

Epoch: 5| Step: 1
Training loss: 3.2048763790481014
Validation loss: 3.8102930527625882

Epoch: 5| Step: 2
Training loss: 4.622897520823614
Validation loss: 3.806098991003847

Epoch: 5| Step: 3
Training loss: 3.8352963908225584
Validation loss: 3.789771118140464

Epoch: 5| Step: 4
Training loss: 4.392737264027564
Validation loss: 3.782910244119293

Epoch: 5| Step: 5
Training loss: 2.8775692944837425
Validation loss: 3.7783203973141632

Epoch: 5| Step: 6
Training loss: 4.08158826842796
Validation loss: 3.769157612946554

Epoch: 5| Step: 7
Training loss: 3.730254257986127
Validation loss: 3.7627226255945394

Epoch: 5| Step: 8
Training loss: 4.489363922398626
Validation loss: 3.754944185627254

Epoch: 5| Step: 9
Training loss: 4.354604428323295
Validation loss: 3.748408876258049

Epoch: 5| Step: 10
Training loss: 2.2506720281050465
Validation loss: 3.739778826459585

Epoch: 11| Step: 0
Training loss: 4.231655021452133
Validation loss: 3.734128519893877

Epoch: 5| Step: 1
Training loss: 4.17338391851251
Validation loss: 3.7313126309482203

Epoch: 5| Step: 2
Training loss: 4.418010627150112
Validation loss: 3.7217693816112463

Epoch: 5| Step: 3
Training loss: 3.3987413993970748
Validation loss: 3.7143823639423497

Epoch: 5| Step: 4
Training loss: 3.728211875600376
Validation loss: 3.7101046507450515

Epoch: 5| Step: 5
Training loss: 3.927884182949274
Validation loss: 3.7024319073990712

Epoch: 5| Step: 6
Training loss: 4.00912222180615
Validation loss: 3.6987788727192705

Epoch: 5| Step: 7
Training loss: 4.015572514172437
Validation loss: 3.690704877374389

Epoch: 5| Step: 8
Training loss: 2.96324192848738
Validation loss: 3.6858296366224734

Epoch: 5| Step: 9
Training loss: 3.9333258407866243
Validation loss: 3.683975470851354

Epoch: 5| Step: 10
Training loss: 3.81204983914629
Validation loss: 3.6758963873403765

Epoch: 12| Step: 0
Training loss: 3.277123754162735
Validation loss: 3.681192115927375

Epoch: 5| Step: 1
Training loss: 3.548853519833809
Validation loss: 3.677192688918555

Epoch: 5| Step: 2
Training loss: 3.2739789055276964
Validation loss: 3.6688664727637494

Epoch: 5| Step: 3
Training loss: 3.437466014347266
Validation loss: 3.661192809246465

Epoch: 5| Step: 4
Training loss: 3.3334216741935605
Validation loss: 3.650905773307981

Epoch: 5| Step: 5
Training loss: 3.7444648582387523
Validation loss: 3.6458129324393513

Epoch: 5| Step: 6
Training loss: 4.7697134022214644
Validation loss: 3.65019242926682

Epoch: 5| Step: 7
Training loss: 4.457748850125029
Validation loss: 3.636411324474537

Epoch: 5| Step: 8
Training loss: 4.083787049498224
Validation loss: 3.633876951300196

Epoch: 5| Step: 9
Training loss: 4.337096683099168
Validation loss: 3.6368098599529883

Epoch: 5| Step: 10
Training loss: 3.6077339438059384
Validation loss: 3.629274814480077

Epoch: 13| Step: 0
Training loss: 3.923069623793634
Validation loss: 3.6234640956051676

Epoch: 5| Step: 1
Training loss: 3.599142126017522
Validation loss: 3.6138514631591594

Epoch: 5| Step: 2
Training loss: 3.925440774453574
Validation loss: 3.6134157923222103

Epoch: 5| Step: 3
Training loss: 3.8454421125793496
Validation loss: 3.612604523321925

Epoch: 5| Step: 4
Training loss: 4.3228721279316416
Validation loss: 3.604461221621972

Epoch: 5| Step: 5
Training loss: 3.709427889902396
Validation loss: 3.5959699567970445

Epoch: 5| Step: 6
Training loss: 3.9688737504543905
Validation loss: 3.600887442546111

Epoch: 5| Step: 7
Training loss: 4.071812915109118
Validation loss: 3.5976693587141

Epoch: 5| Step: 8
Training loss: 3.5278706542544063
Validation loss: 3.5905898272029857

Epoch: 5| Step: 9
Training loss: 2.730196304809046
Validation loss: 3.5850381299094938

Epoch: 5| Step: 10
Training loss: 4.018513749981336
Validation loss: 3.580827413902188

Epoch: 14| Step: 0
Training loss: 3.1381344765415786
Validation loss: 3.5778062499966508

Epoch: 5| Step: 1
Training loss: 3.3335509864955464
Validation loss: 3.5792211621534995

Epoch: 5| Step: 2
Training loss: 3.9470670216922423
Validation loss: 3.576083356565425

Epoch: 5| Step: 3
Training loss: 4.305110626748739
Validation loss: 3.5682498224852166

Epoch: 5| Step: 4
Training loss: 4.253475787448902
Validation loss: 3.561715778589573

Epoch: 5| Step: 5
Training loss: 3.9738561267966777
Validation loss: 3.561225594084588

Epoch: 5| Step: 6
Training loss: 3.5416094307855985
Validation loss: 3.561400418865113

Epoch: 5| Step: 7
Training loss: 3.625677242813427
Validation loss: 3.557841954735846

Epoch: 5| Step: 8
Training loss: 3.8497469880829076
Validation loss: 3.551555341819089

Epoch: 5| Step: 9
Training loss: 3.974880139924979
Validation loss: 3.551457411861051

Epoch: 5| Step: 10
Training loss: 3.2158360299874023
Validation loss: 3.558542264924747

Epoch: 15| Step: 0
Training loss: 3.9291630237571895
Validation loss: 3.56035393072363

Epoch: 5| Step: 1
Training loss: 3.559062838911502
Validation loss: 3.5523015148543373

Epoch: 5| Step: 2
Training loss: 3.557630992844817
Validation loss: 3.552123104213588

Epoch: 5| Step: 3
Training loss: 4.00052949261888
Validation loss: 3.5673350747974517

Epoch: 5| Step: 4
Training loss: 3.192314999088555
Validation loss: 3.572529484111151

Epoch: 5| Step: 5
Training loss: 4.076601876726268
Validation loss: 3.5758592914300573

Epoch: 5| Step: 6
Training loss: 4.0200837907551605
Validation loss: 3.5457838016235192

Epoch: 5| Step: 7
Training loss: 3.5990375927792533
Validation loss: 3.539759540955125

Epoch: 5| Step: 8
Training loss: 3.5004716282928787
Validation loss: 3.554585605960802

Epoch: 5| Step: 9
Training loss: 4.338007802123479
Validation loss: 3.5624483180691446

Epoch: 5| Step: 10
Training loss: 3.433635828587087
Validation loss: 3.5433071207481848

Epoch: 16| Step: 0
Training loss: 3.703475227373018
Validation loss: 3.527259551745998

Epoch: 5| Step: 1
Training loss: 3.8707389784455644
Validation loss: 3.5330285970821427

Epoch: 5| Step: 2
Training loss: 4.121578994314202
Validation loss: 3.532531038383412

Epoch: 5| Step: 3
Training loss: 3.341286866127021
Validation loss: 3.5368515990408733

Epoch: 5| Step: 4
Training loss: 3.9632257176048
Validation loss: 3.529830875420975

Epoch: 5| Step: 5
Training loss: 3.5800311079751563
Validation loss: 3.514561566633628

Epoch: 5| Step: 6
Training loss: 3.4188331775205603
Validation loss: 3.5027643133806268

Epoch: 5| Step: 7
Training loss: 3.7238535761826275
Validation loss: 3.500708729465874

Epoch: 5| Step: 8
Training loss: 4.497962914435675
Validation loss: 3.504304132055979

Epoch: 5| Step: 9
Training loss: 3.3752342425403015
Validation loss: 3.4914812348956277

Epoch: 5| Step: 10
Training loss: 3.0792299407803636
Validation loss: 3.4818829980639454

Epoch: 17| Step: 0
Training loss: 3.4937841533158482
Validation loss: 3.4826094656608055

Epoch: 5| Step: 1
Training loss: 3.4616380245203535
Validation loss: 3.4776830862163526

Epoch: 5| Step: 2
Training loss: 2.9392722444866304
Validation loss: 3.4755749308073662

Epoch: 5| Step: 3
Training loss: 2.8837194489248468
Validation loss: 3.4715486688367823

Epoch: 5| Step: 4
Training loss: 4.290996733785794
Validation loss: 3.4702648951888198

Epoch: 5| Step: 5
Training loss: 3.5190383278054074
Validation loss: 3.466891227430745

Epoch: 5| Step: 6
Training loss: 4.354579242829332
Validation loss: 3.4654472818660538

Epoch: 5| Step: 7
Training loss: 4.071769819562616
Validation loss: 3.462626935859911

Epoch: 5| Step: 8
Training loss: 3.2584428428985848
Validation loss: 3.456968895023236

Epoch: 5| Step: 9
Training loss: 4.004561446011027
Validation loss: 3.4553029383209664

Epoch: 5| Step: 10
Training loss: 3.938646422113533
Validation loss: 3.452178247694993

Epoch: 18| Step: 0
Training loss: 4.415558634027762
Validation loss: 3.450041965249007

Epoch: 5| Step: 1
Training loss: 3.965008511431916
Validation loss: 3.4472776219225665

Epoch: 5| Step: 2
Training loss: 3.5564558723808712
Validation loss: 3.445592682135039

Epoch: 5| Step: 3
Training loss: 4.069524472736846
Validation loss: 3.4446594722152883

Epoch: 5| Step: 4
Training loss: 3.367288043651879
Validation loss: 3.441616684602519

Epoch: 5| Step: 5
Training loss: 3.8492259894787435
Validation loss: 3.438921172798336

Epoch: 5| Step: 6
Training loss: 3.781420112755634
Validation loss: 3.4368347553444187

Epoch: 5| Step: 7
Training loss: 3.167822292343227
Validation loss: 3.435448472324337

Epoch: 5| Step: 8
Training loss: 3.3437209083503743
Validation loss: 3.4346022995418166

Epoch: 5| Step: 9
Training loss: 3.4067256490400206
Validation loss: 3.431554356442331

Epoch: 5| Step: 10
Training loss: 3.0615591044074706
Validation loss: 3.431045153256707

Epoch: 19| Step: 0
Training loss: 3.338620538518825
Validation loss: 3.428737378993468

Epoch: 5| Step: 1
Training loss: 2.5957942398417684
Validation loss: 3.426392688960246

Epoch: 5| Step: 2
Training loss: 3.985015219320721
Validation loss: 3.4226988050211884

Epoch: 5| Step: 3
Training loss: 3.1309705537223387
Validation loss: 3.419895645707898

Epoch: 5| Step: 4
Training loss: 3.4874672618136042
Validation loss: 3.418634903222195

Epoch: 5| Step: 5
Training loss: 3.477482568956316
Validation loss: 3.4171824599917957

Epoch: 5| Step: 6
Training loss: 3.6924174220640613
Validation loss: 3.412607651706235

Epoch: 5| Step: 7
Training loss: 3.7520284888399895
Validation loss: 3.410132427945453

Epoch: 5| Step: 8
Training loss: 4.425923034605544
Validation loss: 3.4061076238070527

Epoch: 5| Step: 9
Training loss: 3.640021802187172
Validation loss: 3.3999058918532974

Epoch: 5| Step: 10
Training loss: 4.253533857595348
Validation loss: 3.3982439328537972

Epoch: 20| Step: 0
Training loss: 2.858808951293373
Validation loss: 3.394171008895128

Epoch: 5| Step: 1
Training loss: 3.610627852813983
Validation loss: 3.3908957081322213

Epoch: 5| Step: 2
Training loss: 3.498204724505938
Validation loss: 3.3890068873745767

Epoch: 5| Step: 3
Training loss: 4.016963750423545
Validation loss: 3.3873835471558387

Epoch: 5| Step: 4
Training loss: 2.6236855076700714
Validation loss: 3.3835152187423603

Epoch: 5| Step: 5
Training loss: 4.12776068582215
Validation loss: 3.3805371858659763

Epoch: 5| Step: 6
Training loss: 3.437551463348787
Validation loss: 3.3775285252568183

Epoch: 5| Step: 7
Training loss: 4.491579867192516
Validation loss: 3.3771741556983246

Epoch: 5| Step: 8
Training loss: 2.8587739239731205
Validation loss: 3.375362548436412

Epoch: 5| Step: 9
Training loss: 3.9173241462504573
Validation loss: 3.374253309287661

Epoch: 5| Step: 10
Training loss: 3.8602681844572166
Validation loss: 3.369745345522486

Epoch: 21| Step: 0
Training loss: 3.322633322630602
Validation loss: 3.3669696710088943

Epoch: 5| Step: 1
Training loss: 3.7039875040111307
Validation loss: 3.3640349668374743

Epoch: 5| Step: 2
Training loss: 3.0299657873859718
Validation loss: 3.361452083727441

Epoch: 5| Step: 3
Training loss: 4.5686420224394055
Validation loss: 3.360680138738649

Epoch: 5| Step: 4
Training loss: 3.8891353589624558
Validation loss: 3.3566913207571005

Epoch: 5| Step: 5
Training loss: 3.0214550211688223
Validation loss: 3.3549809039219065

Epoch: 5| Step: 6
Training loss: 3.8861614805430365
Validation loss: 3.352248225926886

Epoch: 5| Step: 7
Training loss: 3.069689971478568
Validation loss: 3.3539599476783746

Epoch: 5| Step: 8
Training loss: 3.4825185440347477
Validation loss: 3.352188054650209

Epoch: 5| Step: 9
Training loss: 3.5608572937057863
Validation loss: 3.349217053958554

Epoch: 5| Step: 10
Training loss: 3.6874103858532927
Validation loss: 3.3434577502133354

Epoch: 22| Step: 0
Training loss: 3.5098687413118164
Validation loss: 3.3431120179435445

Epoch: 5| Step: 1
Training loss: 4.125697452652727
Validation loss: 3.338492138265993

Epoch: 5| Step: 2
Training loss: 4.420889700848723
Validation loss: 3.3413106772342935

Epoch: 5| Step: 3
Training loss: 3.9370145952662967
Validation loss: 3.3359409074909294

Epoch: 5| Step: 4
Training loss: 3.618959853654539
Validation loss: 3.3330622583321308

Epoch: 5| Step: 5
Training loss: 3.1368473544425526
Validation loss: 3.3311026543846136

Epoch: 5| Step: 6
Training loss: 2.4466827745799558
Validation loss: 3.3308132525691283

Epoch: 5| Step: 7
Training loss: 2.9517665746040467
Validation loss: 3.328570868169284

Epoch: 5| Step: 8
Training loss: 3.3688289597693535
Validation loss: 3.3282310865249074

Epoch: 5| Step: 9
Training loss: 3.561629339536344
Validation loss: 3.3251621843337267

Epoch: 5| Step: 10
Training loss: 3.817247780172827
Validation loss: 3.3237843642811047

Epoch: 23| Step: 0
Training loss: 3.5527035049682754
Validation loss: 3.322549365611535

Epoch: 5| Step: 1
Training loss: 3.388243511289718
Validation loss: 3.3203393198434523

Epoch: 5| Step: 2
Training loss: 3.524857397779748
Validation loss: 3.3186167674536122

Epoch: 5| Step: 3
Training loss: 3.570889682985426
Validation loss: 3.3172435612998736

Epoch: 5| Step: 4
Training loss: 4.146048279881859
Validation loss: 3.3165636017442193

Epoch: 5| Step: 5
Training loss: 3.499540571304336
Validation loss: 3.3156229205248384

Epoch: 5| Step: 6
Training loss: 2.8940722555909093
Validation loss: 3.3127742103573956

Epoch: 5| Step: 7
Training loss: 3.7507923560682275
Validation loss: 3.312147249805926

Epoch: 5| Step: 8
Training loss: 2.4741237437849684
Validation loss: 3.309923640169266

Epoch: 5| Step: 9
Training loss: 3.7510382168764655
Validation loss: 3.310404223859059

Epoch: 5| Step: 10
Training loss: 4.328472247464492
Validation loss: 3.310206724805399

Epoch: 24| Step: 0
Training loss: 4.488962199826339
Validation loss: 3.307003875269735

Epoch: 5| Step: 1
Training loss: 2.9118598201672907
Validation loss: 3.306170272462918

Epoch: 5| Step: 2
Training loss: 3.5538243178447204
Validation loss: 3.3057134028818997

Epoch: 5| Step: 3
Training loss: 4.159558807599305
Validation loss: 3.3038274857647925

Epoch: 5| Step: 4
Training loss: 2.820165318587515
Validation loss: 3.3031217811252054

Epoch: 5| Step: 5
Training loss: 3.26614682349582
Validation loss: 3.3018239853266538

Epoch: 5| Step: 6
Training loss: 2.790773865764911
Validation loss: 3.3000447569466047

Epoch: 5| Step: 7
Training loss: 3.399247557461677
Validation loss: 3.3000952766861733

Epoch: 5| Step: 8
Training loss: 4.132135173481011
Validation loss: 3.2992138358409626

Epoch: 5| Step: 9
Training loss: 3.383625734469153
Validation loss: 3.2976878309744473

Epoch: 5| Step: 10
Training loss: 3.674183091694858
Validation loss: 3.296088106848395

Epoch: 25| Step: 0
Training loss: 3.509133546833423
Validation loss: 3.2955793011811028

Epoch: 5| Step: 1
Training loss: 3.233799390205544
Validation loss: 3.2934653644451326

Epoch: 5| Step: 2
Training loss: 3.727758187780879
Validation loss: 3.2941016903499665

Epoch: 5| Step: 3
Training loss: 4.233187012634281
Validation loss: 3.2923130061801156

Epoch: 5| Step: 4
Training loss: 3.1400132223932116
Validation loss: 3.2915354856118113

Epoch: 5| Step: 5
Training loss: 3.187920935268999
Validation loss: 3.291857710891897

Epoch: 5| Step: 6
Training loss: 4.124088533444627
Validation loss: 3.2895072316961733

Epoch: 5| Step: 7
Training loss: 3.460720907972912
Validation loss: 3.2876405612668402

Epoch: 5| Step: 8
Training loss: 3.206595871025553
Validation loss: 3.2882098536987177

Epoch: 5| Step: 9
Training loss: 3.469142307400926
Validation loss: 3.286894609587138

Epoch: 5| Step: 10
Training loss: 3.4068052906664894
Validation loss: 3.2862257273113635

Epoch: 26| Step: 0
Training loss: 3.4214990139293238
Validation loss: 3.283942612923484

Epoch: 5| Step: 1
Training loss: 3.685839262878584
Validation loss: 3.2836952001523283

Epoch: 5| Step: 2
Training loss: 3.3645377298734798
Validation loss: 3.283156277675894

Epoch: 5| Step: 3
Training loss: 3.00403879416416
Validation loss: 3.28142380652068

Epoch: 5| Step: 4
Training loss: 3.701479904522182
Validation loss: 3.280919346554177

Epoch: 5| Step: 5
Training loss: 3.4403235196860456
Validation loss: 3.280598165416843

Epoch: 5| Step: 6
Training loss: 3.446626788805756
Validation loss: 3.2796944411169724

Epoch: 5| Step: 7
Training loss: 3.641218276247432
Validation loss: 3.2792022174865143

Epoch: 5| Step: 8
Training loss: 3.786483043955576
Validation loss: 3.2788471711781755

Epoch: 5| Step: 9
Training loss: 3.5422771750441644
Validation loss: 3.2767658319817974

Epoch: 5| Step: 10
Training loss: 3.742557770124561
Validation loss: 3.2764352345910446

Epoch: 27| Step: 0
Training loss: 2.538574641382322
Validation loss: 3.274818352561478

Epoch: 5| Step: 1
Training loss: 3.7072785981346223
Validation loss: 3.274158707390958

Epoch: 5| Step: 2
Training loss: 3.484907443159737
Validation loss: 3.273337925361647

Epoch: 5| Step: 3
Training loss: 3.539601131317375
Validation loss: 3.2728403513825515

Epoch: 5| Step: 4
Training loss: 3.2027455174884687
Validation loss: 3.2715579149248297

Epoch: 5| Step: 5
Training loss: 3.0746759755682107
Validation loss: 3.2709197772388423

Epoch: 5| Step: 6
Training loss: 3.502431025237735
Validation loss: 3.269420540995592

Epoch: 5| Step: 7
Training loss: 4.079925490428262
Validation loss: 3.269422767915266

Epoch: 5| Step: 8
Training loss: 3.994206763281876
Validation loss: 3.268974968153039

Epoch: 5| Step: 9
Training loss: 3.4429778408608285
Validation loss: 3.2676046652937303

Epoch: 5| Step: 10
Training loss: 3.940199395957929
Validation loss: 3.2682103950926558

Epoch: 28| Step: 0
Training loss: 4.24397007142641
Validation loss: 3.2667727472218027

Epoch: 5| Step: 1
Training loss: 3.01440752980371
Validation loss: 3.2649349286829272

Epoch: 5| Step: 2
Training loss: 3.933762244637933
Validation loss: 3.264675015745532

Epoch: 5| Step: 3
Training loss: 3.7422636976030246
Validation loss: 3.2641426070430297

Epoch: 5| Step: 4
Training loss: 2.9878698527067518
Validation loss: 3.2623022899410175

Epoch: 5| Step: 5
Training loss: 2.990043330054029
Validation loss: 3.2628402710416515

Epoch: 5| Step: 6
Training loss: 3.857372304863459
Validation loss: 3.2627295094360718

Epoch: 5| Step: 7
Training loss: 2.661993481806478
Validation loss: 3.2643239198220586

Epoch: 5| Step: 8
Training loss: 3.874685336227053
Validation loss: 3.2575548015531717

Epoch: 5| Step: 9
Training loss: 3.443291934473216
Validation loss: 3.2604944090839934

Epoch: 5| Step: 10
Training loss: 3.534533164400439
Validation loss: 3.256960675853259

Epoch: 29| Step: 0
Training loss: 3.1523476828700683
Validation loss: 3.2543463896846063

Epoch: 5| Step: 1
Training loss: 2.91283057305547
Validation loss: 3.2536353642456377

Epoch: 5| Step: 2
Training loss: 3.7789054727070472
Validation loss: 3.2535793276759692

Epoch: 5| Step: 3
Training loss: 3.5819712127346675
Validation loss: 3.2532428405481055

Epoch: 5| Step: 4
Training loss: 3.4509418197144672
Validation loss: 3.251033850431904

Epoch: 5| Step: 5
Training loss: 4.024689770228512
Validation loss: 3.2505845695037303

Epoch: 5| Step: 6
Training loss: 4.310163002914662
Validation loss: 3.251739995366994

Epoch: 5| Step: 7
Training loss: 3.0559720901792593
Validation loss: 3.24810716332603

Epoch: 5| Step: 8
Training loss: 3.2322714041639173
Validation loss: 3.247808721066808

Epoch: 5| Step: 9
Training loss: 3.3565463199905623
Validation loss: 3.249223302349955

Epoch: 5| Step: 10
Training loss: 3.42673206944769
Validation loss: 3.2595128039664987

Epoch: 30| Step: 0
Training loss: 3.417283134360649
Validation loss: 3.301337907995246

Epoch: 5| Step: 1
Training loss: 3.980750136682256
Validation loss: 3.2858114340928326

Epoch: 5| Step: 2
Training loss: 2.611267682605
Validation loss: 3.242998390484141

Epoch: 5| Step: 3
Training loss: 3.556611665862334
Validation loss: 3.330943144852688

Epoch: 5| Step: 4
Training loss: 3.0654424428294673
Validation loss: 3.354121082087614

Epoch: 5| Step: 5
Training loss: 3.5743739026690453
Validation loss: 3.365806620590242

Epoch: 5| Step: 6
Training loss: 4.380084543675066
Validation loss: 3.3828884289496384

Epoch: 5| Step: 7
Training loss: 3.9996009866064126
Validation loss: 3.360783392819404

Epoch: 5| Step: 8
Training loss: 3.6546759192196405
Validation loss: 3.3351143083573715

Epoch: 5| Step: 9
Training loss: 3.791288433842303
Validation loss: 3.328967003941147

Epoch: 5| Step: 10
Training loss: 2.7595676963977884
Validation loss: 3.326601716560654

Epoch: 31| Step: 0
Training loss: 3.873093659103469
Validation loss: 3.332188464002521

Epoch: 5| Step: 1
Training loss: 3.5219000530282667
Validation loss: 3.3404371387754477

Epoch: 5| Step: 2
Training loss: 3.394883395455254
Validation loss: 3.3211978449567274

Epoch: 5| Step: 3
Training loss: 3.3936367458604058
Validation loss: 3.286363340193599

Epoch: 5| Step: 4
Training loss: 3.383041409330677
Validation loss: 3.2646541951173744

Epoch: 5| Step: 5
Training loss: 3.4911848502084784
Validation loss: 3.2526071233947857

Epoch: 5| Step: 6
Training loss: 3.7219908881221953
Validation loss: 3.237030009625934

Epoch: 5| Step: 7
Training loss: 4.160949115686824
Validation loss: 3.2523861337960094

Epoch: 5| Step: 8
Training loss: 3.591185342941575
Validation loss: 3.2665972382293536

Epoch: 5| Step: 9
Training loss: 3.1969903024592607
Validation loss: 3.265703386701626

Epoch: 5| Step: 10
Training loss: 2.7307959975793703
Validation loss: 3.253947325899024

Epoch: 32| Step: 0
Training loss: 2.778012738357241
Validation loss: 3.2451567156693044

Epoch: 5| Step: 1
Training loss: 3.700181523587068
Validation loss: 3.2388376792296976

Epoch: 5| Step: 2
Training loss: 4.082761503909178
Validation loss: 3.2398260043030795

Epoch: 5| Step: 3
Training loss: 3.264680132539458
Validation loss: 3.236373924906475

Epoch: 5| Step: 4
Training loss: 3.48004045002547
Validation loss: 3.2325637768886555

Epoch: 5| Step: 5
Training loss: 3.089063080405073
Validation loss: 3.227805500098439

Epoch: 5| Step: 6
Training loss: 3.427785428528274
Validation loss: 3.223099114051966

Epoch: 5| Step: 7
Training loss: 4.085127274247616
Validation loss: 3.220127015456747

Epoch: 5| Step: 8
Training loss: 3.7643595108405186
Validation loss: 3.2181400079878113

Epoch: 5| Step: 9
Training loss: 3.5482750368742115
Validation loss: 3.2215898114431365

Epoch: 5| Step: 10
Training loss: 2.7274124875526806
Validation loss: 3.2206371655853325

Epoch: 33| Step: 0
Training loss: 3.4496615202345593
Validation loss: 3.221916510488212

Epoch: 5| Step: 1
Training loss: 3.930648413206425
Validation loss: 3.22338217674986

Epoch: 5| Step: 2
Training loss: 4.193519706486011
Validation loss: 3.2238399340674864

Epoch: 5| Step: 3
Training loss: 2.703693484466532
Validation loss: 3.2190350259882887

Epoch: 5| Step: 4
Training loss: 3.0559379184268938
Validation loss: 3.2216657825940245

Epoch: 5| Step: 5
Training loss: 3.685204130649767
Validation loss: 3.2211955682349154

Epoch: 5| Step: 6
Training loss: 3.2435072085854837
Validation loss: 3.217549224406093

Epoch: 5| Step: 7
Training loss: 3.11343134538593
Validation loss: 3.214391540182483

Epoch: 5| Step: 8
Training loss: 3.4540801647538375
Validation loss: 3.212924503053425

Epoch: 5| Step: 9
Training loss: 3.112314186524569
Validation loss: 3.2112011492983332

Epoch: 5| Step: 10
Training loss: 4.01705705215018
Validation loss: 3.2100118431532447

Epoch: 34| Step: 0
Training loss: 3.630352672332634
Validation loss: 3.2127044688635853

Epoch: 5| Step: 1
Training loss: 4.019992931606474
Validation loss: 3.2134645264339503

Epoch: 5| Step: 2
Training loss: 3.798263233224784
Validation loss: 3.2062670424059867

Epoch: 5| Step: 3
Training loss: 2.688365264706095
Validation loss: 3.2036557185843355

Epoch: 5| Step: 4
Training loss: 3.0885666089822505
Validation loss: 3.2037143680292455

Epoch: 5| Step: 5
Training loss: 3.6757872173005497
Validation loss: 3.203744068443777

Epoch: 5| Step: 6
Training loss: 2.5626125776171134
Validation loss: 3.202707332549562

Epoch: 5| Step: 7
Training loss: 3.896713578980853
Validation loss: 3.2042001492039462

Epoch: 5| Step: 8
Training loss: 3.1080983670549345
Validation loss: 3.202941999752827

Epoch: 5| Step: 9
Training loss: 3.9715985265711597
Validation loss: 3.201807744782333

Epoch: 5| Step: 10
Training loss: 3.2463737210980703
Validation loss: 3.2042437072740815

Epoch: 35| Step: 0
Training loss: 3.685153667294582
Validation loss: 3.2060734394448622

Epoch: 5| Step: 1
Training loss: 2.7783889627942053
Validation loss: 3.208491289660978

Epoch: 5| Step: 2
Training loss: 3.65799026155088
Validation loss: 3.215505477820778

Epoch: 5| Step: 3
Training loss: 3.9555749350393334
Validation loss: 3.2185080254415577

Epoch: 5| Step: 4
Training loss: 3.5487722288525916
Validation loss: 3.218734632854215

Epoch: 5| Step: 5
Training loss: 3.4499421101011705
Validation loss: 3.203996875714458

Epoch: 5| Step: 6
Training loss: 4.0077563425037335
Validation loss: 3.1964911948475017

Epoch: 5| Step: 7
Training loss: 3.5190316881952017
Validation loss: 3.1947837015143876

Epoch: 5| Step: 8
Training loss: 3.1248049865909446
Validation loss: 3.194343103534508

Epoch: 5| Step: 9
Training loss: 3.1887177777727804
Validation loss: 3.193645384281784

Epoch: 5| Step: 10
Training loss: 2.736747714974824
Validation loss: 3.193897412047138

Epoch: 36| Step: 0
Training loss: 4.02016587062267
Validation loss: 3.1959846777019827

Epoch: 5| Step: 1
Training loss: 3.166632317473853
Validation loss: 3.196184883419913

Epoch: 5| Step: 2
Training loss: 3.446214761038438
Validation loss: 3.1923576882021796

Epoch: 5| Step: 3
Training loss: 3.5025589988471677
Validation loss: 3.19230822120168

Epoch: 5| Step: 4
Training loss: 4.0947045531023685
Validation loss: 3.1902906574370933

Epoch: 5| Step: 5
Training loss: 2.8476540731623197
Validation loss: 3.1893697888931993

Epoch: 5| Step: 6
Training loss: 3.6113895227423396
Validation loss: 3.188565000088275

Epoch: 5| Step: 7
Training loss: 2.8388209960874864
Validation loss: 3.188725654279275

Epoch: 5| Step: 8
Training loss: 3.615373918920199
Validation loss: 3.188366929096454

Epoch: 5| Step: 9
Training loss: 2.8125425547453355
Validation loss: 3.1878562887369237

Epoch: 5| Step: 10
Training loss: 3.739363781674527
Validation loss: 3.186076245798695

Epoch: 37| Step: 0
Training loss: 3.9439208947348043
Validation loss: 3.1832852520431163

Epoch: 5| Step: 1
Training loss: 3.341305846587081
Validation loss: 3.1841464005563282

Epoch: 5| Step: 2
Training loss: 3.747585918314472
Validation loss: 3.1827566043081834

Epoch: 5| Step: 3
Training loss: 3.6968077523700633
Validation loss: 3.1799399350365802

Epoch: 5| Step: 4
Training loss: 2.750868746777918
Validation loss: 3.182303962719345

Epoch: 5| Step: 5
Training loss: 3.4626226520504892
Validation loss: 3.180416177980581

Epoch: 5| Step: 6
Training loss: 3.2255208918093423
Validation loss: 3.179353931364879

Epoch: 5| Step: 7
Training loss: 3.2292005639706916
Validation loss: 3.178573485408861

Epoch: 5| Step: 8
Training loss: 3.5821320198220055
Validation loss: 3.178183384155358

Epoch: 5| Step: 9
Training loss: 3.0406908708359133
Validation loss: 3.179067204853439

Epoch: 5| Step: 10
Training loss: 3.6256633020149067
Validation loss: 3.184338588917621

Epoch: 38| Step: 0
Training loss: 3.7673971351194253
Validation loss: 3.1757860547319128

Epoch: 5| Step: 1
Training loss: 2.7961007010753742
Validation loss: 3.173851326553946

Epoch: 5| Step: 2
Training loss: 3.2571463143896815
Validation loss: 3.172765746059652

Epoch: 5| Step: 3
Training loss: 2.8030374502673556
Validation loss: 3.173768062203076

Epoch: 5| Step: 4
Training loss: 3.0458542899173158
Validation loss: 3.1744366290766304

Epoch: 5| Step: 5
Training loss: 3.3199751379621825
Validation loss: 3.173887800565943

Epoch: 5| Step: 6
Training loss: 3.8037816404693348
Validation loss: 3.1746688557689566

Epoch: 5| Step: 7
Training loss: 3.9135215522520643
Validation loss: 3.171410455111021

Epoch: 5| Step: 8
Training loss: 2.942276662487429
Validation loss: 3.1742726228621274

Epoch: 5| Step: 9
Training loss: 3.8548792549747355
Validation loss: 3.1765996270577275

Epoch: 5| Step: 10
Training loss: 3.990604333069771
Validation loss: 3.1771966476580746

Epoch: 39| Step: 0
Training loss: 3.381992302324681
Validation loss: 3.174029618423067

Epoch: 5| Step: 1
Training loss: 3.4520973298904276
Validation loss: 3.170531327695264

Epoch: 5| Step: 2
Training loss: 3.0483582627612082
Validation loss: 3.171177761830484

Epoch: 5| Step: 3
Training loss: 3.567859566631937
Validation loss: 3.1692937910670587

Epoch: 5| Step: 4
Training loss: 2.9404399039282
Validation loss: 3.1670340102057923

Epoch: 5| Step: 5
Training loss: 3.912282817041112
Validation loss: 3.1714426745511877

Epoch: 5| Step: 6
Training loss: 3.3494673006494806
Validation loss: 3.1680984714294205

Epoch: 5| Step: 7
Training loss: 3.393299507042464
Validation loss: 3.1667345527621746

Epoch: 5| Step: 8
Training loss: 3.2102914424752598
Validation loss: 3.163450378006072

Epoch: 5| Step: 9
Training loss: 3.5830048846744647
Validation loss: 3.163224265187099

Epoch: 5| Step: 10
Training loss: 3.719712845989084
Validation loss: 3.162214010292923

Epoch: 40| Step: 0
Training loss: 3.3843263405976507
Validation loss: 3.1605707559895206

Epoch: 5| Step: 1
Training loss: 2.87235802043098
Validation loss: 3.1582259883934913

Epoch: 5| Step: 2
Training loss: 3.0173774331522862
Validation loss: 3.1574310331628452

Epoch: 5| Step: 3
Training loss: 3.949673438757583
Validation loss: 3.158144307376316

Epoch: 5| Step: 4
Training loss: 3.601467437482542
Validation loss: 3.1575060375506876

Epoch: 5| Step: 5
Training loss: 3.3478257482432663
Validation loss: 3.157284923026371

Epoch: 5| Step: 6
Training loss: 3.9339887918798433
Validation loss: 3.158444780571843

Epoch: 5| Step: 7
Training loss: 2.927924925524361
Validation loss: 3.159574583843608

Epoch: 5| Step: 8
Training loss: 4.016200874092277
Validation loss: 3.1551543317612136

Epoch: 5| Step: 9
Training loss: 3.1530827408861355
Validation loss: 3.1546856896217292

Epoch: 5| Step: 10
Training loss: 3.0319941285713132
Validation loss: 3.1555406424520345

Epoch: 41| Step: 0
Training loss: 3.6543617263169255
Validation loss: 3.155759939256839

Epoch: 5| Step: 1
Training loss: 3.2647546219737893
Validation loss: 3.14933669845902

Epoch: 5| Step: 2
Training loss: 2.912710249356105
Validation loss: 3.1512466601279683

Epoch: 5| Step: 3
Training loss: 3.5641901122998774
Validation loss: 3.1484145085252484

Epoch: 5| Step: 4
Training loss: 3.174964640262777
Validation loss: 3.14946901146764

Epoch: 5| Step: 5
Training loss: 4.055646073769702
Validation loss: 3.1476234167892456

Epoch: 5| Step: 6
Training loss: 3.433417097631541
Validation loss: 3.1486083902169932

Epoch: 5| Step: 7
Training loss: 3.349329633681366
Validation loss: 3.1461160314501706

Epoch: 5| Step: 8
Training loss: 2.96869314038888
Validation loss: 3.1476027927461976

Epoch: 5| Step: 9
Training loss: 3.7587605190605635
Validation loss: 3.1458682752555394

Epoch: 5| Step: 10
Training loss: 3.078997028583556
Validation loss: 3.1443502679919266

Epoch: 42| Step: 0
Training loss: 3.3071732787722503
Validation loss: 3.1436271214038274

Epoch: 5| Step: 1
Training loss: 3.539269717046849
Validation loss: 3.1449255467115447

Epoch: 5| Step: 2
Training loss: 3.175857223972083
Validation loss: 3.1432103940493876

Epoch: 5| Step: 3
Training loss: 3.0259173176746454
Validation loss: 3.141016786785991

Epoch: 5| Step: 4
Training loss: 3.93567881777119
Validation loss: 3.140230702113826

Epoch: 5| Step: 5
Training loss: 3.4869410897593536
Validation loss: 3.1393929406908123

Epoch: 5| Step: 6
Training loss: 3.3525471696941738
Validation loss: 3.1387301076126684

Epoch: 5| Step: 7
Training loss: 2.9848763409276913
Validation loss: 3.138557082651318

Epoch: 5| Step: 8
Training loss: 3.251537692824564
Validation loss: 3.1372861436231423

Epoch: 5| Step: 9
Training loss: 4.04230066943918
Validation loss: 3.1431534752234622

Epoch: 5| Step: 10
Training loss: 3.0282685079513674
Validation loss: 3.1382469218684363

Epoch: 43| Step: 0
Training loss: 3.5721297366000777
Validation loss: 3.1365360078104163

Epoch: 5| Step: 1
Training loss: 3.5244860389401578
Validation loss: 3.1361141969511857

Epoch: 5| Step: 2
Training loss: 2.914375513360201
Validation loss: 3.132137500514274

Epoch: 5| Step: 3
Training loss: 3.919877231193522
Validation loss: 3.1294140722859294

Epoch: 5| Step: 4
Training loss: 3.2567072395392533
Validation loss: 3.1320460879592584

Epoch: 5| Step: 5
Training loss: 3.022208030361937
Validation loss: 3.1314645954155247

Epoch: 5| Step: 6
Training loss: 3.355654053017855
Validation loss: 3.1307348760197478

Epoch: 5| Step: 7
Training loss: 4.0987611341078
Validation loss: 3.129233013916909

Epoch: 5| Step: 8
Training loss: 3.4621555088141136
Validation loss: 3.1284161212572488

Epoch: 5| Step: 9
Training loss: 3.0814784029170226
Validation loss: 3.1277483743565755

Epoch: 5| Step: 10
Training loss: 2.7423892042092204
Validation loss: 3.125853041025001

Epoch: 44| Step: 0
Training loss: 2.995850236090743
Validation loss: 3.128066603038346

Epoch: 5| Step: 1
Training loss: 3.046380731644321
Validation loss: 3.1279913746517893

Epoch: 5| Step: 2
Training loss: 3.606398903666671
Validation loss: 3.1268252057021417

Epoch: 5| Step: 3
Training loss: 3.085151205206055
Validation loss: 3.1275111390338903

Epoch: 5| Step: 4
Training loss: 3.6100604574789092
Validation loss: 3.1252608930730474

Epoch: 5| Step: 5
Training loss: 3.5507235044981336
Validation loss: 3.1237538993227534

Epoch: 5| Step: 6
Training loss: 3.2868872764112966
Validation loss: 3.1230480981080584

Epoch: 5| Step: 7
Training loss: 2.984767708230362
Validation loss: 3.1224600086169945

Epoch: 5| Step: 8
Training loss: 3.478526317273713
Validation loss: 3.1228091905658633

Epoch: 5| Step: 9
Training loss: 3.8842364334838853
Validation loss: 3.122707554832298

Epoch: 5| Step: 10
Training loss: 3.570358042353476
Validation loss: 3.12099079506085

Epoch: 45| Step: 0
Training loss: 2.9015694942194914
Validation loss: 3.1202666977121094

Epoch: 5| Step: 1
Training loss: 3.4391364623890097
Validation loss: 3.121544336270664

Epoch: 5| Step: 2
Training loss: 3.679149418261581
Validation loss: 3.120132749490025

Epoch: 5| Step: 3
Training loss: 3.1695742225507675
Validation loss: 3.1198154396308513

Epoch: 5| Step: 4
Training loss: 2.7755072808765484
Validation loss: 3.121828887886972

Epoch: 5| Step: 5
Training loss: 3.1604649566267033
Validation loss: 3.1226457140408503

Epoch: 5| Step: 6
Training loss: 3.555759679047728
Validation loss: 3.124927496940662

Epoch: 5| Step: 7
Training loss: 3.4744656872429482
Validation loss: 3.1144701368192957

Epoch: 5| Step: 8
Training loss: 3.4689137188190253
Validation loss: 3.1160308413278193

Epoch: 5| Step: 9
Training loss: 4.057558311283141
Validation loss: 3.114822581539809

Epoch: 5| Step: 10
Training loss: 3.2212827032617763
Validation loss: 3.116174107598401

Epoch: 46| Step: 0
Training loss: 3.773118663136101
Validation loss: 3.1163136768694257

Epoch: 5| Step: 1
Training loss: 3.249232715118988
Validation loss: 3.1241198393377787

Epoch: 5| Step: 2
Training loss: 3.4353846196672633
Validation loss: 3.110730773544575

Epoch: 5| Step: 3
Training loss: 3.4854554010957224
Validation loss: 3.1086387857208195

Epoch: 5| Step: 4
Training loss: 3.404140974404645
Validation loss: 3.1089274162154945

Epoch: 5| Step: 5
Training loss: 3.1624572449459043
Validation loss: 3.107757469180882

Epoch: 5| Step: 6
Training loss: 2.608107755939036
Validation loss: 3.1104851571921777

Epoch: 5| Step: 7
Training loss: 3.520834356605035
Validation loss: 3.121912446982468

Epoch: 5| Step: 8
Training loss: 3.5453240452826833
Validation loss: 3.12569494908401

Epoch: 5| Step: 9
Training loss: 3.5614785854987
Validation loss: 3.1108414124224373

Epoch: 5| Step: 10
Training loss: 3.1511246263076393
Validation loss: 3.1046106472883173

Epoch: 47| Step: 0
Training loss: 3.5666506496557036
Validation loss: 3.1015496741762445

Epoch: 5| Step: 1
Training loss: 3.5447971794959168
Validation loss: 3.1007456543958902

Epoch: 5| Step: 2
Training loss: 2.54833614819082
Validation loss: 3.101716876866482

Epoch: 5| Step: 3
Training loss: 3.601052204646695
Validation loss: 3.1003038055059764

Epoch: 5| Step: 4
Training loss: 3.6823604133084227
Validation loss: 3.099316211585394

Epoch: 5| Step: 5
Training loss: 3.5387304962925086
Validation loss: 3.0975771761494992

Epoch: 5| Step: 6
Training loss: 3.769139592671379
Validation loss: 3.098342566023291

Epoch: 5| Step: 7
Training loss: 2.6505926585096424
Validation loss: 3.0968840663527986

Epoch: 5| Step: 8
Training loss: 3.8563109060760765
Validation loss: 3.0995903966478937

Epoch: 5| Step: 9
Training loss: 3.300308825752056
Validation loss: 3.097838789800723

Epoch: 5| Step: 10
Training loss: 2.3645059738164385
Validation loss: 3.0959899539658924

Epoch: 48| Step: 0
Training loss: 3.018180910415346
Validation loss: 3.093141050248306

Epoch: 5| Step: 1
Training loss: 2.7470842856747804
Validation loss: 3.092738929652203

Epoch: 5| Step: 2
Training loss: 3.270947658865261
Validation loss: 3.092943613665498

Epoch: 5| Step: 3
Training loss: 3.4051811571146335
Validation loss: 3.092307024282326

Epoch: 5| Step: 4
Training loss: 3.952611595860941
Validation loss: 3.091687068723187

Epoch: 5| Step: 5
Training loss: 3.8215740593793024
Validation loss: 3.091297729408203

Epoch: 5| Step: 6
Training loss: 2.9995724055419744
Validation loss: 3.089133517281549

Epoch: 5| Step: 7
Training loss: 3.2150731984017944
Validation loss: 3.0905218633512637

Epoch: 5| Step: 8
Training loss: 3.107638233452319
Validation loss: 3.0867241027866847

Epoch: 5| Step: 9
Training loss: 3.083265011692024
Validation loss: 3.0874728944898973

Epoch: 5| Step: 10
Training loss: 4.10305613614682
Validation loss: 3.0913394972674104

Epoch: 49| Step: 0
Training loss: 3.337525036892938
Validation loss: 3.0903056355271126

Epoch: 5| Step: 1
Training loss: 3.3229445851906045
Validation loss: 3.0838051850363457

Epoch: 5| Step: 2
Training loss: 3.3655166197658155
Validation loss: 3.0835562999252

Epoch: 5| Step: 3
Training loss: 3.6985429833361354
Validation loss: 3.0854678582589994

Epoch: 5| Step: 4
Training loss: 3.361818072859518
Validation loss: 3.084689728853535

Epoch: 5| Step: 5
Training loss: 3.667548564857177
Validation loss: 3.0865294983546394

Epoch: 5| Step: 6
Training loss: 3.402494547641262
Validation loss: 3.090487109708765

Epoch: 5| Step: 7
Training loss: 3.229882700298949
Validation loss: 3.0900263929064584

Epoch: 5| Step: 8
Training loss: 3.626348441995903
Validation loss: 3.087438324077323

Epoch: 5| Step: 9
Training loss: 2.946383415635785
Validation loss: 3.0843762840247293

Epoch: 5| Step: 10
Training loss: 2.715322943461123
Validation loss: 3.0842512793613315

Epoch: 50| Step: 0
Training loss: 3.5552912272772246
Validation loss: 3.0815368427972634

Epoch: 5| Step: 1
Training loss: 3.5978113196934407
Validation loss: 3.0803815341993426

Epoch: 5| Step: 2
Training loss: 3.781681382974566
Validation loss: 3.078383243401652

Epoch: 5| Step: 3
Training loss: 2.7052140294718763
Validation loss: 3.078406769572855

Epoch: 5| Step: 4
Training loss: 3.2516723144993174
Validation loss: 3.078106373910209

Epoch: 5| Step: 5
Training loss: 3.3842244714457586
Validation loss: 3.079064177982264

Epoch: 5| Step: 6
Training loss: 3.252848184114796
Validation loss: 3.079660113955064

Epoch: 5| Step: 7
Training loss: 3.359994946430584
Validation loss: 3.077993312359317

Epoch: 5| Step: 8
Training loss: 2.932619789063948
Validation loss: 3.076167443046496

Epoch: 5| Step: 9
Training loss: 3.5232076971727047
Validation loss: 3.0753494749410413

Epoch: 5| Step: 10
Training loss: 3.2178770196245434
Validation loss: 3.0775598057390066

Epoch: 51| Step: 0
Training loss: 3.9289450579243885
Validation loss: 3.0933909277739855

Epoch: 5| Step: 1
Training loss: 3.2632447835918104
Validation loss: 3.0734682656273034

Epoch: 5| Step: 2
Training loss: 3.8555247757849895
Validation loss: 3.068458768834855

Epoch: 5| Step: 3
Training loss: 3.1811756897287045
Validation loss: 3.0679739106200574

Epoch: 5| Step: 4
Training loss: 3.8080746340930927
Validation loss: 3.0680253572450504

Epoch: 5| Step: 5
Training loss: 2.3626760669475324
Validation loss: 3.0677223304832983

Epoch: 5| Step: 6
Training loss: 3.4441158093465614
Validation loss: 3.0679751623689313

Epoch: 5| Step: 7
Training loss: 3.2543177167064576
Validation loss: 3.0680032630775567

Epoch: 5| Step: 8
Training loss: 3.2951334471010583
Validation loss: 3.0652183320267197

Epoch: 5| Step: 9
Training loss: 3.229777141004345
Validation loss: 3.0624741701129663

Epoch: 5| Step: 10
Training loss: 2.683423521370405
Validation loss: 3.0622167240712526

Epoch: 52| Step: 0
Training loss: 3.234389447903268
Validation loss: 3.0625083007432132

Epoch: 5| Step: 1
Training loss: 3.116694743664048
Validation loss: 3.0621531635207764

Epoch: 5| Step: 2
Training loss: 3.1189004498659965
Validation loss: 3.0613129462188238

Epoch: 5| Step: 3
Training loss: 3.552214917442658
Validation loss: 3.06483769551209

Epoch: 5| Step: 4
Training loss: 3.5938994003422344
Validation loss: 3.063384319552713

Epoch: 5| Step: 5
Training loss: 3.373394478280195
Validation loss: 3.064648005320121

Epoch: 5| Step: 6
Training loss: 3.3366494055678473
Validation loss: 3.0606368614880153

Epoch: 5| Step: 7
Training loss: 2.727492996192842
Validation loss: 3.056729496129108

Epoch: 5| Step: 8
Training loss: 3.707598981404162
Validation loss: 3.0569301195159952

Epoch: 5| Step: 9
Training loss: 3.7859855821982844
Validation loss: 3.0582349291692457

Epoch: 5| Step: 10
Training loss: 2.7838020188978816
Validation loss: 3.0551841132206627

Epoch: 53| Step: 0
Training loss: 3.1616750493103556
Validation loss: 3.0557796331473592

Epoch: 5| Step: 1
Training loss: 3.1148654635600397
Validation loss: 3.053641945256889

Epoch: 5| Step: 2
Training loss: 3.499331819240974
Validation loss: 3.056714860159555

Epoch: 5| Step: 3
Training loss: 3.3695433975733096
Validation loss: 3.0531369657516376

Epoch: 5| Step: 4
Training loss: 3.317604881761729
Validation loss: 3.050688199652076

Epoch: 5| Step: 5
Training loss: 2.91383913222133
Validation loss: 3.050401308060323

Epoch: 5| Step: 6
Training loss: 3.6566487934390923
Validation loss: 3.0500976969811626

Epoch: 5| Step: 7
Training loss: 3.291765203489949
Validation loss: 3.047644608794382

Epoch: 5| Step: 8
Training loss: 2.7593755426114717
Validation loss: 3.0477036789337237

Epoch: 5| Step: 9
Training loss: 4.06118588834618
Validation loss: 3.047552154153154

Epoch: 5| Step: 10
Training loss: 3.145996965274693
Validation loss: 3.046865143824418

Epoch: 54| Step: 0
Training loss: 3.1975419677175374
Validation loss: 3.0487775905174175

Epoch: 5| Step: 1
Training loss: 3.539143879272692
Validation loss: 3.047399433986255

Epoch: 5| Step: 2
Training loss: 3.2327956614509814
Validation loss: 3.045749842127589

Epoch: 5| Step: 3
Training loss: 2.855260337811543
Validation loss: 3.042548063863528

Epoch: 5| Step: 4
Training loss: 3.191635889314973
Validation loss: 3.0423144601566716

Epoch: 5| Step: 5
Training loss: 3.477028256195909
Validation loss: 3.041762323655163

Epoch: 5| Step: 6
Training loss: 2.6937679564547974
Validation loss: 3.0403462784932334

Epoch: 5| Step: 7
Training loss: 3.3877312049932704
Validation loss: 3.0418007169732664

Epoch: 5| Step: 8
Training loss: 3.705121624761117
Validation loss: 3.0399525749283143

Epoch: 5| Step: 9
Training loss: 3.546155411242377
Validation loss: 3.040105987103428

Epoch: 5| Step: 10
Training loss: 3.5173757305303797
Validation loss: 3.0389744982352287

Epoch: 55| Step: 0
Training loss: 2.615207389937328
Validation loss: 3.037984722971873

Epoch: 5| Step: 1
Training loss: 3.9160011348313586
Validation loss: 3.0366595634671927

Epoch: 5| Step: 2
Training loss: 3.7703812189396464
Validation loss: 3.035795558049378

Epoch: 5| Step: 3
Training loss: 3.023411950291755
Validation loss: 3.0356723388175615

Epoch: 5| Step: 4
Training loss: 2.786411938622719
Validation loss: 3.035835692946722

Epoch: 5| Step: 5
Training loss: 3.5633600100406957
Validation loss: 3.0335960667453783

Epoch: 5| Step: 6
Training loss: 3.258237376511536
Validation loss: 3.033355751098999

Epoch: 5| Step: 7
Training loss: 2.6461487729726825
Validation loss: 3.0339996887456064

Epoch: 5| Step: 8
Training loss: 3.4624580848993767
Validation loss: 3.032301799473607

Epoch: 5| Step: 9
Training loss: 2.7536520549794554
Validation loss: 3.032403191848621

Epoch: 5| Step: 10
Training loss: 4.2516996687492155
Validation loss: 3.0318589211537

Epoch: 56| Step: 0
Training loss: 2.888408574090817
Validation loss: 3.031884500300928

Epoch: 5| Step: 1
Training loss: 3.284050899524693
Validation loss: 3.0334576237702375

Epoch: 5| Step: 2
Training loss: 3.153512201646383
Validation loss: 3.03329475770005

Epoch: 5| Step: 3
Training loss: 3.4807941186212132
Validation loss: 3.0479127120674065

Epoch: 5| Step: 4
Training loss: 3.6682305613265105
Validation loss: 3.0506271536199003

Epoch: 5| Step: 5
Training loss: 3.7444249991853122
Validation loss: 3.0367844006427966

Epoch: 5| Step: 6
Training loss: 2.710066069892011
Validation loss: 3.030296472563784

Epoch: 5| Step: 7
Training loss: 3.330007387903398
Validation loss: 3.0285340550928823

Epoch: 5| Step: 8
Training loss: 2.9792010609879944
Validation loss: 3.0256022207170195

Epoch: 5| Step: 9
Training loss: 3.5098235009314114
Validation loss: 3.0245897690371604

Epoch: 5| Step: 10
Training loss: 3.3983375973103334
Validation loss: 3.0266188797352465

Epoch: 57| Step: 0
Training loss: 3.3345026508411713
Validation loss: 3.0247594121579215

Epoch: 5| Step: 1
Training loss: 3.3723986455053834
Validation loss: 3.022355294482374

Epoch: 5| Step: 2
Training loss: 3.1566234405469014
Validation loss: 3.0235151856599463

Epoch: 5| Step: 3
Training loss: 2.7959135310291594
Validation loss: 3.0243133635491355

Epoch: 5| Step: 4
Training loss: 3.320936148921325
Validation loss: 3.023516465989729

Epoch: 5| Step: 5
Training loss: 3.4070372065557883
Validation loss: 3.019757189384049

Epoch: 5| Step: 6
Training loss: 4.197660048650105
Validation loss: 3.0191767381154553

Epoch: 5| Step: 7
Training loss: 2.8362840172790107
Validation loss: 3.0189150809158574

Epoch: 5| Step: 8
Training loss: 3.560002840448168
Validation loss: 3.0176866316927295

Epoch: 5| Step: 9
Training loss: 2.7755163863572307
Validation loss: 3.0182119048352427

Epoch: 5| Step: 10
Training loss: 3.207550713011111
Validation loss: 3.0163903892792705

Epoch: 58| Step: 0
Training loss: 2.940217729148609
Validation loss: 3.017055077386317

Epoch: 5| Step: 1
Training loss: 3.6075319811380857
Validation loss: 3.0156740106723796

Epoch: 5| Step: 2
Training loss: 3.3090448173376883
Validation loss: 3.0145345683681066

Epoch: 5| Step: 3
Training loss: 3.014882525026385
Validation loss: 3.0127306095279405

Epoch: 5| Step: 4
Training loss: 2.970028732366329
Validation loss: 3.015642667124932

Epoch: 5| Step: 5
Training loss: 3.062717196489318
Validation loss: 3.0142795784033054

Epoch: 5| Step: 6
Training loss: 3.5267582235247863
Validation loss: 3.01717816051871

Epoch: 5| Step: 7
Training loss: 2.6343500645227795
Validation loss: 3.020602094705757

Epoch: 5| Step: 8
Training loss: 3.611577274523013
Validation loss: 3.0248901255704808

Epoch: 5| Step: 9
Training loss: 3.3692838511223115
Validation loss: 3.022671436412912

Epoch: 5| Step: 10
Training loss: 3.9735197706027092
Validation loss: 3.0073940191071884

Epoch: 59| Step: 0
Training loss: 3.410879646121679
Validation loss: 3.0044950065635803

Epoch: 5| Step: 1
Training loss: 3.42134835706382
Validation loss: 3.0027840242790806

Epoch: 5| Step: 2
Training loss: 3.2663352960426946
Validation loss: 3.0022581140631073

Epoch: 5| Step: 3
Training loss: 3.18659960427473
Validation loss: 3.003222198072656

Epoch: 5| Step: 4
Training loss: 2.6012092785853533
Validation loss: 2.997557429336597

Epoch: 5| Step: 5
Training loss: 3.7160620712253594
Validation loss: 2.9986669114825415

Epoch: 5| Step: 6
Training loss: 3.1962325210302223
Validation loss: 2.9995121832717984

Epoch: 5| Step: 7
Training loss: 2.9590525402111365
Validation loss: 3.004816231290613

Epoch: 5| Step: 8
Training loss: 3.057633250367022
Validation loss: 3.0426920408351297

Epoch: 5| Step: 9
Training loss: 3.408979809424581
Validation loss: 2.9978757339589803

Epoch: 5| Step: 10
Training loss: 3.756462378059751
Validation loss: 2.9988195804198723

Epoch: 60| Step: 0
Training loss: 3.468570738963155
Validation loss: 3.002277145818276

Epoch: 5| Step: 1
Training loss: 2.015263369744107
Validation loss: 3.007143045158707

Epoch: 5| Step: 2
Training loss: 3.444474375673364
Validation loss: 3.020060059582397

Epoch: 5| Step: 3
Training loss: 2.9832552262067593
Validation loss: 3.007191858182214

Epoch: 5| Step: 4
Training loss: 3.9324166318055713
Validation loss: 2.999916146415643

Epoch: 5| Step: 5
Training loss: 3.2101423109600935
Validation loss: 3.0063828448927055

Epoch: 5| Step: 6
Training loss: 3.05603309907015
Validation loss: 3.0170711208356082

Epoch: 5| Step: 7
Training loss: 3.259648306662834
Validation loss: 3.0179702622404636

Epoch: 5| Step: 8
Training loss: 3.1055188061020838
Validation loss: 3.012838965756989

Epoch: 5| Step: 9
Training loss: 3.625038541391623
Validation loss: 2.9899365159070532

Epoch: 5| Step: 10
Training loss: 3.6894833678121257
Validation loss: 2.9891759431860403

Epoch: 61| Step: 0
Training loss: 3.484154116895279
Validation loss: 2.989896326501418

Epoch: 5| Step: 1
Training loss: 2.8911114257641612
Validation loss: 2.991113290455101

Epoch: 5| Step: 2
Training loss: 3.488167242940292
Validation loss: 3.0184732357013218

Epoch: 5| Step: 3
Training loss: 3.0075039792054348
Validation loss: 2.995632502937671

Epoch: 5| Step: 4
Training loss: 4.050106216733246
Validation loss: 2.986712107967342

Epoch: 5| Step: 5
Training loss: 2.9363932046279255
Validation loss: 2.9849240666046346

Epoch: 5| Step: 6
Training loss: 2.8561267851248338
Validation loss: 2.984496101456878

Epoch: 5| Step: 7
Training loss: 3.492704826798439
Validation loss: 2.9831913238891246

Epoch: 5| Step: 8
Training loss: 2.3314512927820803
Validation loss: 2.9856372258500556

Epoch: 5| Step: 9
Training loss: 3.908631720197402
Validation loss: 2.988330359112031

Epoch: 5| Step: 10
Training loss: 3.112402587346736
Validation loss: 2.991241253194524

Epoch: 62| Step: 0
Training loss: 3.347519648111812
Validation loss: 2.9942795698810976

Epoch: 5| Step: 1
Training loss: 3.225360785123715
Validation loss: 2.9957516132304827

Epoch: 5| Step: 2
Training loss: 3.0421878072134056
Validation loss: 2.986357132193027

Epoch: 5| Step: 3
Training loss: 3.4942740878123506
Validation loss: 2.981447892094047

Epoch: 5| Step: 4
Training loss: 3.367620665973253
Validation loss: 2.981870593780718

Epoch: 5| Step: 5
Training loss: 3.117873649322507
Validation loss: 2.9812469745886436

Epoch: 5| Step: 6
Training loss: 3.4874848997821477
Validation loss: 2.9841296475191945

Epoch: 5| Step: 7
Training loss: 2.6939823130116918
Validation loss: 2.98302180394406

Epoch: 5| Step: 8
Training loss: 3.0197256403206665
Validation loss: 2.9900111416526713

Epoch: 5| Step: 9
Training loss: 3.7113807815013877
Validation loss: 2.9914631435480903

Epoch: 5| Step: 10
Training loss: 3.2119054518735295
Validation loss: 2.986761668613569

Epoch: 63| Step: 0
Training loss: 2.7116759775756467
Validation loss: 2.975819642369285

Epoch: 5| Step: 1
Training loss: 2.543429518997751
Validation loss: 2.9726182900351734

Epoch: 5| Step: 2
Training loss: 3.2196117840001848
Validation loss: 2.9716883135324816

Epoch: 5| Step: 3
Training loss: 3.5588713787832593
Validation loss: 2.9703547805086834

Epoch: 5| Step: 4
Training loss: 3.3950953393507595
Validation loss: 2.973429659800556

Epoch: 5| Step: 5
Training loss: 2.8624516179023085
Validation loss: 2.97005122477322

Epoch: 5| Step: 6
Training loss: 3.995720242732055
Validation loss: 2.970687682896622

Epoch: 5| Step: 7
Training loss: 3.1926182064675483
Validation loss: 2.9744301497425663

Epoch: 5| Step: 8
Training loss: 3.502496782474279
Validation loss: 2.9719171267469235

Epoch: 5| Step: 9
Training loss: 3.5463963660395597
Validation loss: 2.9721361073114188

Epoch: 5| Step: 10
Training loss: 2.8959907836556655
Validation loss: 2.97040820958419

Epoch: 64| Step: 0
Training loss: 3.4085141277784277
Validation loss: 2.968485918804718

Epoch: 5| Step: 1
Training loss: 2.398717509770775
Validation loss: 2.964109270866973

Epoch: 5| Step: 2
Training loss: 3.7509492308542765
Validation loss: 2.9644578563176083

Epoch: 5| Step: 3
Training loss: 3.207686586133889
Validation loss: 2.9630810127838503

Epoch: 5| Step: 4
Training loss: 3.5631350570293217
Validation loss: 2.964591819146805

Epoch: 5| Step: 5
Training loss: 2.9963195795248616
Validation loss: 2.9605765269191173

Epoch: 5| Step: 6
Training loss: 3.3758073476900696
Validation loss: 2.961520218702589

Epoch: 5| Step: 7
Training loss: 3.635995696699997
Validation loss: 2.9640112421480933

Epoch: 5| Step: 8
Training loss: 3.469256664767004
Validation loss: 2.9639894788829704

Epoch: 5| Step: 9
Training loss: 2.8781864917660003
Validation loss: 2.961790826777349

Epoch: 5| Step: 10
Training loss: 2.6446560220288604
Validation loss: 2.9605216266921413

Epoch: 65| Step: 0
Training loss: 3.5318273561822005
Validation loss: 2.9602090890542403

Epoch: 5| Step: 1
Training loss: 2.9439639133231945
Validation loss: 2.9663299195443695

Epoch: 5| Step: 2
Training loss: 3.2794645265456954
Validation loss: 2.9805735424219364

Epoch: 5| Step: 3
Training loss: 2.935418385671451
Validation loss: 2.9746941737851422

Epoch: 5| Step: 4
Training loss: 2.9227582443130165
Validation loss: 2.9576072448869803

Epoch: 5| Step: 5
Training loss: 3.6352583332431907
Validation loss: 2.9591974807178074

Epoch: 5| Step: 6
Training loss: 3.5647692229276124
Validation loss: 2.9572454171139992

Epoch: 5| Step: 7
Training loss: 3.367603391378435
Validation loss: 2.9552389412273263

Epoch: 5| Step: 8
Training loss: 3.724918794706892
Validation loss: 2.956616392335145

Epoch: 5| Step: 9
Training loss: 2.8278628064428775
Validation loss: 2.9578234625869966

Epoch: 5| Step: 10
Training loss: 2.592712838422009
Validation loss: 2.9566803912590047

Epoch: 66| Step: 0
Training loss: 4.0326270775067
Validation loss: 2.958821149160749

Epoch: 5| Step: 1
Training loss: 3.6209764183812556
Validation loss: 2.9581791515344156

Epoch: 5| Step: 2
Training loss: 3.1592353827683293
Validation loss: 2.960411380670935

Epoch: 5| Step: 3
Training loss: 3.4677955757794474
Validation loss: 2.965711116639367

Epoch: 5| Step: 4
Training loss: 3.343387334532656
Validation loss: 2.9639201747668276

Epoch: 5| Step: 5
Training loss: 3.5246869428424343
Validation loss: 2.958162623160612

Epoch: 5| Step: 6
Training loss: 2.8022273332732572
Validation loss: 2.9483942937584726

Epoch: 5| Step: 7
Training loss: 2.7274387121264083
Validation loss: 2.945749927046707

Epoch: 5| Step: 8
Training loss: 2.728868094460656
Validation loss: 2.9473790739143575

Epoch: 5| Step: 9
Training loss: 2.9694632225604614
Validation loss: 2.945817681400489

Epoch: 5| Step: 10
Training loss: 2.931557183345751
Validation loss: 2.9504243875329736

Epoch: 67| Step: 0
Training loss: 2.9248759316761186
Validation loss: 2.9501021779591756

Epoch: 5| Step: 1
Training loss: 3.1760216278281432
Validation loss: 2.953511735540737

Epoch: 5| Step: 2
Training loss: 2.692317459591765
Validation loss: 2.9509150299635865

Epoch: 5| Step: 3
Training loss: 2.6424012840404156
Validation loss: 2.952620700710174

Epoch: 5| Step: 4
Training loss: 3.652974544458384
Validation loss: 2.9516743182266127

Epoch: 5| Step: 5
Training loss: 4.066667033544639
Validation loss: 2.9480788016981863

Epoch: 5| Step: 6
Training loss: 3.1664199900334906
Validation loss: 2.943901965681168

Epoch: 5| Step: 7
Training loss: 3.2643655054727425
Validation loss: 2.942247492563427

Epoch: 5| Step: 8
Training loss: 3.092436848938528
Validation loss: 2.9435413020564667

Epoch: 5| Step: 9
Training loss: 3.2518949119695817
Validation loss: 2.940545791567526

Epoch: 5| Step: 10
Training loss: 3.408355062426358
Validation loss: 2.943062693416713

Epoch: 68| Step: 0
Training loss: 2.8665767507719737
Validation loss: 2.9443657423661196

Epoch: 5| Step: 1
Training loss: 3.0632164564725266
Validation loss: 2.9442420098412727

Epoch: 5| Step: 2
Training loss: 3.4902167509260544
Validation loss: 2.943310400489402

Epoch: 5| Step: 3
Training loss: 3.6610214529859877
Validation loss: 2.9419713607448386

Epoch: 5| Step: 4
Training loss: 3.4927343158038027
Validation loss: 2.9380916819057683

Epoch: 5| Step: 5
Training loss: 3.7423846167014596
Validation loss: 2.9385758993072097

Epoch: 5| Step: 6
Training loss: 2.950547642710881
Validation loss: 2.936650048710188

Epoch: 5| Step: 7
Training loss: 2.5700759546952754
Validation loss: 2.9367590750693267

Epoch: 5| Step: 8
Training loss: 2.8596301355820652
Validation loss: 2.9352752483682347

Epoch: 5| Step: 9
Training loss: 3.0851581603426124
Validation loss: 2.934559677274285

Epoch: 5| Step: 10
Training loss: 3.5007362953641876
Validation loss: 2.9319964142402397

Epoch: 69| Step: 0
Training loss: 3.7543950075289887
Validation loss: 2.931800785605813

Epoch: 5| Step: 1
Training loss: 2.8164292756513687
Validation loss: 2.930939533862136

Epoch: 5| Step: 2
Training loss: 3.2710314810114665
Validation loss: 2.9324598585257107

Epoch: 5| Step: 3
Training loss: 3.104309249436611
Validation loss: 2.9341828121175357

Epoch: 5| Step: 4
Training loss: 3.1924207515335095
Validation loss: 2.9317895649595305

Epoch: 5| Step: 5
Training loss: 2.971450220149689
Validation loss: 2.9334949025444885

Epoch: 5| Step: 6
Training loss: 3.323876619943486
Validation loss: 2.933828738567684

Epoch: 5| Step: 7
Training loss: 3.804097656649109
Validation loss: 2.928938809674926

Epoch: 5| Step: 8
Training loss: 2.90353857734689
Validation loss: 2.929489667659668

Epoch: 5| Step: 9
Training loss: 2.5207396455699844
Validation loss: 2.9308367717719173

Epoch: 5| Step: 10
Training loss: 3.5566817841093865
Validation loss: 2.9306376173776414

Epoch: 70| Step: 0
Training loss: 3.5716010842211325
Validation loss: 2.9289419598048143

Epoch: 5| Step: 1
Training loss: 2.9912697602259786
Validation loss: 2.929092900360501

Epoch: 5| Step: 2
Training loss: 3.157534498447597
Validation loss: 2.9264068580874687

Epoch: 5| Step: 3
Training loss: 3.002176448975998
Validation loss: 2.923251585996799

Epoch: 5| Step: 4
Training loss: 3.1178338855393473
Validation loss: 2.921234887249471

Epoch: 5| Step: 5
Training loss: 3.2575011619161787
Validation loss: 2.9206177741585297

Epoch: 5| Step: 6
Training loss: 3.191524881611655
Validation loss: 2.923142663611584

Epoch: 5| Step: 7
Training loss: 3.323184649305378
Validation loss: 2.9215436713240113

Epoch: 5| Step: 8
Training loss: 2.9220607106966603
Validation loss: 2.920640527712343

Epoch: 5| Step: 9
Training loss: 3.914456589402905
Validation loss: 2.9223054765402465

Epoch: 5| Step: 10
Training loss: 2.610536876284299
Validation loss: 2.9215006965565515

Epoch: 71| Step: 0
Training loss: 2.9849028594857834
Validation loss: 2.9213709093425906

Epoch: 5| Step: 1
Training loss: 4.048650050353156
Validation loss: 2.931027227312797

Epoch: 5| Step: 2
Training loss: 3.254782166113815
Validation loss: 2.929264362364055

Epoch: 5| Step: 3
Training loss: 3.0817456324603554
Validation loss: 2.92474303878962

Epoch: 5| Step: 4
Training loss: 2.827867359207205
Validation loss: 2.924701281224438

Epoch: 5| Step: 5
Training loss: 2.9398617279857384
Validation loss: 2.9253366217564123

Epoch: 5| Step: 6
Training loss: 3.114340033751163
Validation loss: 2.9238008280353993

Epoch: 5| Step: 7
Training loss: 3.110306030131797
Validation loss: 2.937804767243438

Epoch: 5| Step: 8
Training loss: 3.5421134816476614
Validation loss: 2.942734248622275

Epoch: 5| Step: 9
Training loss: 3.0990562786791096
Validation loss: 2.919311759966061

Epoch: 5| Step: 10
Training loss: 3.066378414732341
Validation loss: 2.916007564861492

Epoch: 72| Step: 0
Training loss: 3.7103790184194323
Validation loss: 2.9157884696659178

Epoch: 5| Step: 1
Training loss: 2.240308658928065
Validation loss: 2.9186892178389137

Epoch: 5| Step: 2
Training loss: 2.5543923863733253
Validation loss: 2.916452677446126

Epoch: 5| Step: 3
Training loss: 3.718850142468921
Validation loss: 2.916992922230559

Epoch: 5| Step: 4
Training loss: 3.1477634664469694
Validation loss: 2.9140144345720063

Epoch: 5| Step: 5
Training loss: 3.3438067565094025
Validation loss: 2.917349193775919

Epoch: 5| Step: 6
Training loss: 2.939723694980879
Validation loss: 2.920688175126723

Epoch: 5| Step: 7
Training loss: 3.313210896916876
Validation loss: 2.924416256047699

Epoch: 5| Step: 8
Training loss: 3.7800735030520984
Validation loss: 2.9193042964228

Epoch: 5| Step: 9
Training loss: 2.7754685392993346
Validation loss: 2.91254489671661

Epoch: 5| Step: 10
Training loss: 3.369284558746141
Validation loss: 2.908071059654147

Epoch: 73| Step: 0
Training loss: 3.537572416501144
Validation loss: 2.9073991676841824

Epoch: 5| Step: 1
Training loss: 2.307077700737977
Validation loss: 2.9064064032310006

Epoch: 5| Step: 2
Training loss: 3.0797788562898316
Validation loss: 2.9072344829658894

Epoch: 5| Step: 3
Training loss: 3.796446348255577
Validation loss: 2.904688609447474

Epoch: 5| Step: 4
Training loss: 2.86006181316668
Validation loss: 2.9028486825833215

Epoch: 5| Step: 5
Training loss: 2.9527466546762287
Validation loss: 2.905822983640837

Epoch: 5| Step: 6
Training loss: 3.461103654924515
Validation loss: 2.9061396914518105

Epoch: 5| Step: 7
Training loss: 2.6234498669512893
Validation loss: 2.904659902278282

Epoch: 5| Step: 8
Training loss: 3.4323139257485895
Validation loss: 2.90604977464362

Epoch: 5| Step: 9
Training loss: 3.0947341124375405
Validation loss: 2.904848281830596

Epoch: 5| Step: 10
Training loss: 3.746882859731644
Validation loss: 2.905908750465399

Epoch: 74| Step: 0
Training loss: 2.994267868453689
Validation loss: 2.9036055287785048

Epoch: 5| Step: 1
Training loss: 2.7854353883884944
Validation loss: 2.9033930056974744

Epoch: 5| Step: 2
Training loss: 3.481258075917052
Validation loss: 2.9011257857040036

Epoch: 5| Step: 3
Training loss: 2.9056591130562133
Validation loss: 2.9007550876753876

Epoch: 5| Step: 4
Training loss: 3.36067493925897
Validation loss: 2.901792421185571

Epoch: 5| Step: 5
Training loss: 3.588506970655398
Validation loss: 2.9011918234512897

Epoch: 5| Step: 6
Training loss: 3.4127395825245563
Validation loss: 2.9055581170670277

Epoch: 5| Step: 7
Training loss: 2.8002300917227063
Validation loss: 2.907520984389862

Epoch: 5| Step: 8
Training loss: 2.7292855991530796
Validation loss: 2.901169012798442

Epoch: 5| Step: 9
Training loss: 3.6668862074815145
Validation loss: 2.897837316314973

Epoch: 5| Step: 10
Training loss: 3.2074992759507537
Validation loss: 2.892890832787333

Epoch: 75| Step: 0
Training loss: 3.088174747760411
Validation loss: 2.893027447608275

Epoch: 5| Step: 1
Training loss: 3.582580324644758
Validation loss: 2.895353947004846

Epoch: 5| Step: 2
Training loss: 2.932522716645615
Validation loss: 2.8973755125481246

Epoch: 5| Step: 3
Training loss: 3.1154019780051025
Validation loss: 2.8955511411714654

Epoch: 5| Step: 4
Training loss: 2.5782158113149403
Validation loss: 2.8948656933798316

Epoch: 5| Step: 5
Training loss: 3.738214538042738
Validation loss: 2.8957938513753727

Epoch: 5| Step: 6
Training loss: 3.215412075752427
Validation loss: 2.9001959246914493

Epoch: 5| Step: 7
Training loss: 2.848746803887831
Validation loss: 2.9168479886510887

Epoch: 5| Step: 8
Training loss: 3.0202984741958834
Validation loss: 2.926508681598711

Epoch: 5| Step: 9
Training loss: 3.1561865469720116
Validation loss: 2.8945613825914913

Epoch: 5| Step: 10
Training loss: 3.6807066848404397
Validation loss: 2.8926538408738196

Epoch: 76| Step: 0
Training loss: 3.2448075703842965
Validation loss: 2.8981381269369333

Epoch: 5| Step: 1
Training loss: 3.5258913144277755
Validation loss: 2.896468777069986

Epoch: 5| Step: 2
Training loss: 3.3499757794315945
Validation loss: 2.891219933106649

Epoch: 5| Step: 3
Training loss: 3.0742907194561764
Validation loss: 2.890540502056525

Epoch: 5| Step: 4
Training loss: 3.0033250501929856
Validation loss: 2.886273965559806

Epoch: 5| Step: 5
Training loss: 3.285442906776644
Validation loss: 2.8911248043002673

Epoch: 5| Step: 6
Training loss: 3.0740774429980315
Validation loss: 2.8964424950361503

Epoch: 5| Step: 7
Training loss: 2.596573545216891
Validation loss: 2.9199079431386714

Epoch: 5| Step: 8
Training loss: 3.0821250060002927
Validation loss: 2.92263114532839

Epoch: 5| Step: 9
Training loss: 3.062084403351663
Validation loss: 2.8947689924212723

Epoch: 5| Step: 10
Training loss: 3.7536237374182
Validation loss: 2.8819207529305877

Epoch: 77| Step: 0
Training loss: 2.6915323922725403
Validation loss: 2.8829597546473793

Epoch: 5| Step: 1
Training loss: 3.3744153116767817
Validation loss: 2.8853914472923763

Epoch: 5| Step: 2
Training loss: 3.3210909301200244
Validation loss: 2.883913643722105

Epoch: 5| Step: 3
Training loss: 3.2692230699198235
Validation loss: 2.891015814092963

Epoch: 5| Step: 4
Training loss: 2.7253083675787546
Validation loss: 2.8831754368668663

Epoch: 5| Step: 5
Training loss: 3.919544150453095
Validation loss: 2.8826225407816057

Epoch: 5| Step: 6
Training loss: 3.1563731254507714
Validation loss: 2.882292559574686

Epoch: 5| Step: 7
Training loss: 2.968007526912553
Validation loss: 2.880430410187776

Epoch: 5| Step: 8
Training loss: 2.6610464435525456
Validation loss: 2.8789598917986936

Epoch: 5| Step: 9
Training loss: 3.7102021783816275
Validation loss: 2.8820964605278054

Epoch: 5| Step: 10
Training loss: 2.875824353994321
Validation loss: 2.8815000520980028

Epoch: 78| Step: 0
Training loss: 2.591106032380539
Validation loss: 2.883156476087731

Epoch: 5| Step: 1
Training loss: 3.082344377708787
Validation loss: 2.879752587335395

Epoch: 5| Step: 2
Training loss: 3.2306863141860345
Validation loss: 2.8813702274460136

Epoch: 5| Step: 3
Training loss: 2.7906628032656977
Validation loss: 2.8782528171195874

Epoch: 5| Step: 4
Training loss: 3.7340876895719903
Validation loss: 2.8777184690819513

Epoch: 5| Step: 5
Training loss: 3.5824536123420385
Validation loss: 2.880651795931824

Epoch: 5| Step: 6
Training loss: 3.5320032717299727
Validation loss: 2.884973678502917

Epoch: 5| Step: 7
Training loss: 2.907069921197871
Validation loss: 2.876573977993062

Epoch: 5| Step: 8
Training loss: 3.2697822355969057
Validation loss: 2.876846523025408

Epoch: 5| Step: 9
Training loss: 3.157426822445632
Validation loss: 2.874136095407426

Epoch: 5| Step: 10
Training loss: 2.718997198683547
Validation loss: 2.872852557811335

Epoch: 79| Step: 0
Training loss: 2.7322850550984707
Validation loss: 2.874748113725532

Epoch: 5| Step: 1
Training loss: 3.1316850493255135
Validation loss: 2.8722849202235357

Epoch: 5| Step: 2
Training loss: 3.270117630782237
Validation loss: 2.873484765518621

Epoch: 5| Step: 3
Training loss: 2.883911419580839
Validation loss: 2.87422880696609

Epoch: 5| Step: 4
Training loss: 2.9840276226370848
Validation loss: 2.872696331223929

Epoch: 5| Step: 5
Training loss: 3.726093254695592
Validation loss: 2.87031762936221

Epoch: 5| Step: 6
Training loss: 3.2943604629245073
Validation loss: 2.8693775549474885

Epoch: 5| Step: 7
Training loss: 3.353012233803966
Validation loss: 2.8691981940531193

Epoch: 5| Step: 8
Training loss: 3.4149967547690303
Validation loss: 2.871016185059599

Epoch: 5| Step: 9
Training loss: 2.8635463617886967
Validation loss: 2.8856825427110504

Epoch: 5| Step: 10
Training loss: 3.000806858913848
Validation loss: 2.8983494069385047

Epoch: 80| Step: 0
Training loss: 3.0272312857134236
Validation loss: 2.9339324120809818

Epoch: 5| Step: 1
Training loss: 3.3786386725699384
Validation loss: 2.8852374625843265

Epoch: 5| Step: 2
Training loss: 3.0902526816350373
Validation loss: 2.868820250837744

Epoch: 5| Step: 3
Training loss: 3.1708668577115464
Validation loss: 2.86669714624819

Epoch: 5| Step: 4
Training loss: 2.9104292159104634
Validation loss: 2.867489171012741

Epoch: 5| Step: 5
Training loss: 3.557544675051915
Validation loss: 2.8628785046069494

Epoch: 5| Step: 6
Training loss: 2.9767431970250904
Validation loss: 2.8676431933117597

Epoch: 5| Step: 7
Training loss: 2.9796178160482114
Validation loss: 2.8678737830642818

Epoch: 5| Step: 8
Training loss: 2.9382307077172243
Validation loss: 2.867919383186987

Epoch: 5| Step: 9
Training loss: 3.5678131904878705
Validation loss: 2.8717245800038804

Epoch: 5| Step: 10
Training loss: 3.1590346336965873
Validation loss: 2.8706192920414506

Epoch: 81| Step: 0
Training loss: 2.933931171299
Validation loss: 2.872490249769034

Epoch: 5| Step: 1
Training loss: 2.7294491240733065
Validation loss: 2.872282733489934

Epoch: 5| Step: 2
Training loss: 2.8942894055933794
Validation loss: 2.871327971508416

Epoch: 5| Step: 3
Training loss: 3.2255707110127294
Validation loss: 2.8703028726053175

Epoch: 5| Step: 4
Training loss: 3.5664542488469766
Validation loss: 2.8651132890274686

Epoch: 5| Step: 5
Training loss: 3.4694559564561507
Validation loss: 2.864111164515764

Epoch: 5| Step: 6
Training loss: 3.802984651657457
Validation loss: 2.8637955451368975

Epoch: 5| Step: 7
Training loss: 2.839263730850869
Validation loss: 2.8638986512449653

Epoch: 5| Step: 8
Training loss: 2.6720237467447263
Validation loss: 2.857686975064471

Epoch: 5| Step: 9
Training loss: 3.1748907475935724
Validation loss: 2.8673809726466275

Epoch: 5| Step: 10
Training loss: 3.2988217649065392
Validation loss: 2.886416532582742

Epoch: 82| Step: 0
Training loss: 3.475908196416728
Validation loss: 2.8829681205970132

Epoch: 5| Step: 1
Training loss: 3.607706848685836
Validation loss: 2.867987703350064

Epoch: 5| Step: 2
Training loss: 3.7675626842445387
Validation loss: 2.8544567731082315

Epoch: 5| Step: 3
Training loss: 2.9546732401390265
Validation loss: 2.8515797451440124

Epoch: 5| Step: 4
Training loss: 3.0278105738863337
Validation loss: 2.8539527206289232

Epoch: 5| Step: 5
Training loss: 2.7330028469825987
Validation loss: 2.8544391214312763

Epoch: 5| Step: 6
Training loss: 2.929333149143237
Validation loss: 2.855586732883817

Epoch: 5| Step: 7
Training loss: 2.9148813687455384
Validation loss: 2.863294315821751

Epoch: 5| Step: 8
Training loss: 3.0760368583961126
Validation loss: 2.8539898219306195

Epoch: 5| Step: 9
Training loss: 3.340568383560519
Validation loss: 2.8491664248895656

Epoch: 5| Step: 10
Training loss: 2.5578485466544088
Validation loss: 2.8526765223677053

Epoch: 83| Step: 0
Training loss: 3.54517528794637
Validation loss: 2.9042079374654954

Epoch: 5| Step: 1
Training loss: 3.8678017484871927
Validation loss: 2.8666229769727347

Epoch: 5| Step: 2
Training loss: 3.3404444817924306
Validation loss: 2.8484721966472395

Epoch: 5| Step: 3
Training loss: 2.8604995934083193
Validation loss: 2.8441861672441675

Epoch: 5| Step: 4
Training loss: 3.187970594186749
Validation loss: 2.8440197917292895

Epoch: 5| Step: 5
Training loss: 2.565118149979071
Validation loss: 2.8475962819246905

Epoch: 5| Step: 6
Training loss: 2.5757228873631908
Validation loss: 2.847897084576732

Epoch: 5| Step: 7
Training loss: 3.0895995997289853
Validation loss: 2.8470425310381895

Epoch: 5| Step: 8
Training loss: 2.882764035362857
Validation loss: 2.8528100647465715

Epoch: 5| Step: 9
Training loss: 3.3555054135256874
Validation loss: 2.850181445865793

Epoch: 5| Step: 10
Training loss: 3.2271362976758287
Validation loss: 2.8558508803013183

Epoch: 84| Step: 0
Training loss: 3.344345467568402
Validation loss: 2.8543501662394455

Epoch: 5| Step: 1
Training loss: 2.638234969872112
Validation loss: 2.8512619275945132

Epoch: 5| Step: 2
Training loss: 3.0874094096496125
Validation loss: 2.8516116819187465

Epoch: 5| Step: 3
Training loss: 3.0947452061898977
Validation loss: 2.8491402274938635

Epoch: 5| Step: 4
Training loss: 2.8908524707268137
Validation loss: 2.8462496218740374

Epoch: 5| Step: 5
Training loss: 3.3365769499290514
Validation loss: 2.8434383848594935

Epoch: 5| Step: 6
Training loss: 3.7276773444598734
Validation loss: 2.844554790399161

Epoch: 5| Step: 7
Training loss: 2.9221112976810373
Validation loss: 2.8431976793476483

Epoch: 5| Step: 8
Training loss: 3.3246576577536167
Validation loss: 2.843601345976025

Epoch: 5| Step: 9
Training loss: 3.3650357126321913
Validation loss: 2.8420975734399416

Epoch: 5| Step: 10
Training loss: 2.625125427882538
Validation loss: 2.840345806917733

Epoch: 85| Step: 0
Training loss: 3.5358509708863397
Validation loss: 2.840789295821729

Epoch: 5| Step: 1
Training loss: 2.793033796499984
Validation loss: 2.842794783255248

Epoch: 5| Step: 2
Training loss: 3.1229436593716153
Validation loss: 2.8566797559609176

Epoch: 5| Step: 3
Training loss: 2.8353006788116883
Validation loss: 2.8616993552245478

Epoch: 5| Step: 4
Training loss: 3.4570592501955755
Validation loss: 2.8635143647414547

Epoch: 5| Step: 5
Training loss: 2.7161298381350294
Validation loss: 2.8526582953009227

Epoch: 5| Step: 6
Training loss: 3.653832834814098
Validation loss: 2.8456211156957254

Epoch: 5| Step: 7
Training loss: 2.9412099258539666
Validation loss: 2.8432390542132637

Epoch: 5| Step: 8
Training loss: 3.352820242678082
Validation loss: 2.8449581229938103

Epoch: 5| Step: 9
Training loss: 2.8749528963957203
Validation loss: 2.8301639009289956

Epoch: 5| Step: 10
Training loss: 3.0831021574493835
Validation loss: 2.8299453579540854

Epoch: 86| Step: 0
Training loss: 3.5519342176772564
Validation loss: 2.8342601959953955

Epoch: 5| Step: 1
Training loss: 3.053432509242832
Validation loss: 2.843932782266576

Epoch: 5| Step: 2
Training loss: 2.6622357411944413
Validation loss: 2.9276160815589294

Epoch: 5| Step: 3
Training loss: 3.2989006870164874
Validation loss: 3.0353631700413577

Epoch: 5| Step: 4
Training loss: 3.211569322484346
Validation loss: 2.835513189037461

Epoch: 5| Step: 5
Training loss: 3.182325314074922
Validation loss: 2.829817137930277

Epoch: 5| Step: 6
Training loss: 3.3159297245801955
Validation loss: 2.8455723554759866

Epoch: 5| Step: 7
Training loss: 3.253669134799222
Validation loss: 2.961155540227757

Epoch: 5| Step: 8
Training loss: 3.569794531714287
Validation loss: 3.053103092262913

Epoch: 5| Step: 9
Training loss: 2.5577883319027537
Validation loss: 2.8822003057548673

Epoch: 5| Step: 10
Training loss: 3.1808796365386094
Validation loss: 2.8492541005076393

Epoch: 87| Step: 0
Training loss: 2.3853906910466227
Validation loss: 2.825063682620257

Epoch: 5| Step: 1
Training loss: 2.9337663663221525
Validation loss: 2.824340246734165

Epoch: 5| Step: 2
Training loss: 3.3165692939713876
Validation loss: 2.82889393372306

Epoch: 5| Step: 3
Training loss: 3.180746366134639
Validation loss: 2.854267097636141

Epoch: 5| Step: 4
Training loss: 2.1330331541508074
Validation loss: 2.8868676969114633

Epoch: 5| Step: 5
Training loss: 3.248239186936787
Validation loss: 2.914134890923925

Epoch: 5| Step: 6
Training loss: 3.450127452762813
Validation loss: 2.867007977952086

Epoch: 5| Step: 7
Training loss: 3.1390452800789195
Validation loss: 2.825678850116869

Epoch: 5| Step: 8
Training loss: 3.6897373201074957
Validation loss: 2.8198732791903813

Epoch: 5| Step: 9
Training loss: 3.327171798100042
Validation loss: 2.822330607606325

Epoch: 5| Step: 10
Training loss: 3.458894354727465
Validation loss: 2.8195616920011255

Epoch: 88| Step: 0
Training loss: 3.2339630601763156
Validation loss: 2.8199860167362125

Epoch: 5| Step: 1
Training loss: 3.083951441351622
Validation loss: 2.820557364460508

Epoch: 5| Step: 2
Training loss: 2.961601565333715
Validation loss: 2.8228884096430007

Epoch: 5| Step: 3
Training loss: 2.8799737118474913
Validation loss: 2.840910680373298

Epoch: 5| Step: 4
Training loss: 3.4942964675803805
Validation loss: 2.859283301446887

Epoch: 5| Step: 5
Training loss: 2.934877239304915
Validation loss: 2.855612254381544

Epoch: 5| Step: 6
Training loss: 3.8372058519585805
Validation loss: 2.8459746241491026

Epoch: 5| Step: 7
Training loss: 2.7109696883783396
Validation loss: 2.822905504837071

Epoch: 5| Step: 8
Training loss: 3.3030851912107124
Validation loss: 2.819983525809519

Epoch: 5| Step: 9
Training loss: 3.4393379153138373
Validation loss: 2.815074001661111

Epoch: 5| Step: 10
Training loss: 2.0683914196496684
Validation loss: 2.8173303541482557

Epoch: 89| Step: 0
Training loss: 3.030455809701039
Validation loss: 2.827593962776383

Epoch: 5| Step: 1
Training loss: 3.3574863536384125
Validation loss: 2.8154941590852394

Epoch: 5| Step: 2
Training loss: 2.7351939691526743
Validation loss: 2.8139904270643803

Epoch: 5| Step: 3
Training loss: 3.3464222150283653
Validation loss: 2.8131098114636055

Epoch: 5| Step: 4
Training loss: 3.0195953638689774
Validation loss: 2.81071279476788

Epoch: 5| Step: 5
Training loss: 2.615753145166603
Validation loss: 2.808417834501675

Epoch: 5| Step: 6
Training loss: 3.2506531279200863
Validation loss: 2.81373663073161

Epoch: 5| Step: 7
Training loss: 3.240042470959763
Validation loss: 2.8099986941216644

Epoch: 5| Step: 8
Training loss: 3.049587509528376
Validation loss: 2.8119334945839944

Epoch: 5| Step: 9
Training loss: 3.456527207693354
Validation loss: 2.8092518571012794

Epoch: 5| Step: 10
Training loss: 3.1150791619836573
Validation loss: 2.807221766436503

Epoch: 90| Step: 0
Training loss: 3.5459736086169356
Validation loss: 2.807137234719007

Epoch: 5| Step: 1
Training loss: 2.992291879451852
Validation loss: 2.808179936078401

Epoch: 5| Step: 2
Training loss: 2.851716003466809
Validation loss: 2.808567766558322

Epoch: 5| Step: 3
Training loss: 3.5535923203445026
Validation loss: 2.80665521592721

Epoch: 5| Step: 4
Training loss: 2.722849068730477
Validation loss: 2.8060041971365965

Epoch: 5| Step: 5
Training loss: 2.8213840467309566
Validation loss: 2.8067475588255792

Epoch: 5| Step: 6
Training loss: 3.152183708278644
Validation loss: 2.8066775168628912

Epoch: 5| Step: 7
Training loss: 3.1125917903739673
Validation loss: 2.8060850775243

Epoch: 5| Step: 8
Training loss: 3.301816301750134
Validation loss: 2.806300570241549

Epoch: 5| Step: 9
Training loss: 3.2849525996349085
Validation loss: 2.8053720962794335

Epoch: 5| Step: 10
Training loss: 2.7207070684027865
Validation loss: 2.803872082158587

Epoch: 91| Step: 0
Training loss: 2.719900567397106
Validation loss: 2.8051964338665036

Epoch: 5| Step: 1
Training loss: 2.8994208053453927
Validation loss: 2.8055861707741823

Epoch: 5| Step: 2
Training loss: 3.196853228930252
Validation loss: 2.8055258243076144

Epoch: 5| Step: 3
Training loss: 2.9388650198121202
Validation loss: 2.8075615169504085

Epoch: 5| Step: 4
Training loss: 3.353846485343868
Validation loss: 2.80794602372441

Epoch: 5| Step: 5
Training loss: 3.087332031376031
Validation loss: 2.807497568600712

Epoch: 5| Step: 6
Training loss: 3.2899883353539625
Validation loss: 2.8010013765156696

Epoch: 5| Step: 7
Training loss: 2.9813731809874997
Validation loss: 2.807129769737901

Epoch: 5| Step: 8
Training loss: 3.237300857840872
Validation loss: 2.813287087511741

Epoch: 5| Step: 9
Training loss: 3.4040080400454897
Validation loss: 2.811205691238714

Epoch: 5| Step: 10
Training loss: 3.039784951132777
Validation loss: 2.79835170347447

Epoch: 92| Step: 0
Training loss: 3.866445265931719
Validation loss: 2.7964627412437357

Epoch: 5| Step: 1
Training loss: 3.1379714307681934
Validation loss: 2.797884468077389

Epoch: 5| Step: 2
Training loss: 3.0829069684766255
Validation loss: 2.796099441305644

Epoch: 5| Step: 3
Training loss: 3.0604862676972076
Validation loss: 2.793616852651575

Epoch: 5| Step: 4
Training loss: 3.1469029172475365
Validation loss: 2.7958869754043016

Epoch: 5| Step: 5
Training loss: 2.798060501578836
Validation loss: 2.794123687935717

Epoch: 5| Step: 6
Training loss: 3.0800287391510786
Validation loss: 2.7929784860519433

Epoch: 5| Step: 7
Training loss: 3.313710549320096
Validation loss: 2.792289942254123

Epoch: 5| Step: 8
Training loss: 2.9260925208878645
Validation loss: 2.791484597858983

Epoch: 5| Step: 9
Training loss: 2.335493881305772
Validation loss: 2.7921921742494926

Epoch: 5| Step: 10
Training loss: 3.1988413382008214
Validation loss: 2.7914932710161153

Epoch: 93| Step: 0
Training loss: 3.186554862126692
Validation loss: 2.7907716647677394

Epoch: 5| Step: 1
Training loss: 3.5724153899203337
Validation loss: 2.789687083094646

Epoch: 5| Step: 2
Training loss: 2.605586791331397
Validation loss: 2.790213102862415

Epoch: 5| Step: 3
Training loss: 3.6471031084936953
Validation loss: 2.7895456030518955

Epoch: 5| Step: 4
Training loss: 3.0014085641812622
Validation loss: 2.789231499262322

Epoch: 5| Step: 5
Training loss: 2.965553570641859
Validation loss: 2.789968732471279

Epoch: 5| Step: 6
Training loss: 2.951028069275081
Validation loss: 2.790187174278392

Epoch: 5| Step: 7
Training loss: 2.9646245299904
Validation loss: 2.7904386070668865

Epoch: 5| Step: 8
Training loss: 3.55302923739445
Validation loss: 2.7876855904042377

Epoch: 5| Step: 9
Training loss: 2.745420804869991
Validation loss: 2.7862674565338104

Epoch: 5| Step: 10
Training loss: 2.6540093339872333
Validation loss: 2.789426006930423

Epoch: 94| Step: 0
Training loss: 3.23536467959724
Validation loss: 2.7878061807799788

Epoch: 5| Step: 1
Training loss: 2.9826564134510503
Validation loss: 2.7908674855382225

Epoch: 5| Step: 2
Training loss: 3.1058625745271065
Validation loss: 2.7909271321044002

Epoch: 5| Step: 3
Training loss: 2.7539034796085358
Validation loss: 2.7960188322831856

Epoch: 5| Step: 4
Training loss: 3.524840217377865
Validation loss: 2.7926130446204054

Epoch: 5| Step: 5
Training loss: 2.3607006264698076
Validation loss: 2.7914716486860485

Epoch: 5| Step: 6
Training loss: 3.7716770527879695
Validation loss: 2.7918385333543685

Epoch: 5| Step: 7
Training loss: 2.336509506973592
Validation loss: 2.790419573813819

Epoch: 5| Step: 8
Training loss: 3.0506721506380705
Validation loss: 2.7875126407108044

Epoch: 5| Step: 9
Training loss: 3.373457096779723
Validation loss: 2.7861577813888663

Epoch: 5| Step: 10
Training loss: 3.364255969928741
Validation loss: 2.787997931836049

Epoch: 95| Step: 0
Training loss: 3.1483261808115897
Validation loss: 2.792074930027038

Epoch: 5| Step: 1
Training loss: 3.0468216328960094
Validation loss: 2.7872709101336

Epoch: 5| Step: 2
Training loss: 3.060207988427271
Validation loss: 2.798510848226404

Epoch: 5| Step: 3
Training loss: 3.1071174131958332
Validation loss: 2.7931454677825553

Epoch: 5| Step: 4
Training loss: 2.92619420640007
Validation loss: 2.7887667972019505

Epoch: 5| Step: 5
Training loss: 3.303765928220654
Validation loss: 2.787741348881823

Epoch: 5| Step: 6
Training loss: 3.2578116217961948
Validation loss: 2.7786153620267866

Epoch: 5| Step: 7
Training loss: 3.433718456655291
Validation loss: 2.7794961306541395

Epoch: 5| Step: 8
Training loss: 3.050685123975756
Validation loss: 2.7791081405961147

Epoch: 5| Step: 9
Training loss: 3.019646527654775
Validation loss: 2.778985377577689

Epoch: 5| Step: 10
Training loss: 2.5728798888096605
Validation loss: 2.778516164353319

Epoch: 96| Step: 0
Training loss: 2.798474413928088
Validation loss: 2.7805628280790677

Epoch: 5| Step: 1
Training loss: 2.6744406355942676
Validation loss: 2.7782384983265

Epoch: 5| Step: 2
Training loss: 2.7539426977031796
Validation loss: 2.776259559989094

Epoch: 5| Step: 3
Training loss: 3.155818494250318
Validation loss: 2.7779720439113293

Epoch: 5| Step: 4
Training loss: 3.434545322183039
Validation loss: 2.7779717679803353

Epoch: 5| Step: 5
Training loss: 3.001087309571791
Validation loss: 2.7817910592061317

Epoch: 5| Step: 6
Training loss: 3.5023395348548414
Validation loss: 2.7825819538259524

Epoch: 5| Step: 7
Training loss: 3.5810449671346807
Validation loss: 2.7933134096223005

Epoch: 5| Step: 8
Training loss: 2.7509780358367104
Validation loss: 2.794140058128069

Epoch: 5| Step: 9
Training loss: 3.330335715614678
Validation loss: 2.801922939760436

Epoch: 5| Step: 10
Training loss: 2.7786865422068225
Validation loss: 2.7958282007657167

Epoch: 97| Step: 0
Training loss: 3.097937322230038
Validation loss: 2.794333550719051

Epoch: 5| Step: 1
Training loss: 3.230249694998982
Validation loss: 2.787038135823228

Epoch: 5| Step: 2
Training loss: 3.5813243172542255
Validation loss: 2.801042603121246

Epoch: 5| Step: 3
Training loss: 2.971630104797084
Validation loss: 2.7739236422062743

Epoch: 5| Step: 4
Training loss: 2.774823597292943
Validation loss: 2.7748764970651876

Epoch: 5| Step: 5
Training loss: 2.959212230810345
Validation loss: 2.7789827585717553

Epoch: 5| Step: 6
Training loss: 3.0674540096401324
Validation loss: 2.7858123809541966

Epoch: 5| Step: 7
Training loss: 3.41939493125053
Validation loss: 2.786697623683484

Epoch: 5| Step: 8
Training loss: 3.308118117192148
Validation loss: 2.7823282677031442

Epoch: 5| Step: 9
Training loss: 2.56421315682159
Validation loss: 2.78254110784908

Epoch: 5| Step: 10
Training loss: 2.9739830073965945
Validation loss: 2.7797645942792095

Epoch: 98| Step: 0
Training loss: 2.516153978921419
Validation loss: 2.783972709571685

Epoch: 5| Step: 1
Training loss: 3.5889283051768683
Validation loss: 2.783636442950158

Epoch: 5| Step: 2
Training loss: 2.700350092337159
Validation loss: 2.7786764396221795

Epoch: 5| Step: 3
Training loss: 3.267284500966193
Validation loss: 2.7795208464909114

Epoch: 5| Step: 4
Training loss: 3.113831053926571
Validation loss: 2.7800132340141075

Epoch: 5| Step: 5
Training loss: 3.338754362491227
Validation loss: 2.7797340131905774

Epoch: 5| Step: 6
Training loss: 3.045782900982838
Validation loss: 2.778901760051299

Epoch: 5| Step: 7
Training loss: 2.8666988444925026
Validation loss: 2.7767084983816526

Epoch: 5| Step: 8
Training loss: 2.8848302545972015
Validation loss: 2.7729665399972805

Epoch: 5| Step: 9
Training loss: 3.482687229181471
Validation loss: 2.774311027593502

Epoch: 5| Step: 10
Training loss: 3.016344211970897
Validation loss: 2.773586623096705

Epoch: 99| Step: 0
Training loss: 2.913939772570625
Validation loss: 2.778718185663012

Epoch: 5| Step: 1
Training loss: 2.808168339245229
Validation loss: 2.781028417959945

Epoch: 5| Step: 2
Training loss: 3.0517948435253266
Validation loss: 2.8056732894067116

Epoch: 5| Step: 3
Training loss: 3.3042167887467877
Validation loss: 2.820849815617745

Epoch: 5| Step: 4
Training loss: 2.508244462408544
Validation loss: 2.8341279143214804

Epoch: 5| Step: 5
Training loss: 2.960581896522308
Validation loss: 2.806439670054779

Epoch: 5| Step: 6
Training loss: 3.1792224290856206
Validation loss: 2.7841646878149455

Epoch: 5| Step: 7
Training loss: 3.588084922185298
Validation loss: 2.771826005038301

Epoch: 5| Step: 8
Training loss: 2.7576275728377198
Validation loss: 2.777750650772482

Epoch: 5| Step: 9
Training loss: 3.565045702027387
Validation loss: 2.7846893911985564

Epoch: 5| Step: 10
Training loss: 3.208205199882517
Validation loss: 2.78216274687317

Epoch: 100| Step: 0
Training loss: 3.091956032700707
Validation loss: 2.78362618426651

Epoch: 5| Step: 1
Training loss: 2.7299126534933538
Validation loss: 2.776745078864124

Epoch: 5| Step: 2
Training loss: 3.2814001139862308
Validation loss: 2.7677194543605244

Epoch: 5| Step: 3
Training loss: 3.222487270664498
Validation loss: 2.766698626222339

Epoch: 5| Step: 4
Training loss: 2.7317909455748453
Validation loss: 2.764630759519441

Epoch: 5| Step: 5
Training loss: 3.5249761702361084
Validation loss: 2.763875441397312

Epoch: 5| Step: 6
Training loss: 2.8293660007044656
Validation loss: 2.7656109267647797

Epoch: 5| Step: 7
Training loss: 3.436686332811634
Validation loss: 2.7602372343162696

Epoch: 5| Step: 8
Training loss: 2.945958721796241
Validation loss: 2.7569915052351934

Epoch: 5| Step: 9
Training loss: 3.205191787480314
Validation loss: 2.7581769819800446

Epoch: 5| Step: 10
Training loss: 2.7248657543467028
Validation loss: 2.7568976594096823

Epoch: 101| Step: 0
Training loss: 2.952761511659682
Validation loss: 2.7546153348166134

Epoch: 5| Step: 1
Training loss: 3.256571947462396
Validation loss: 2.7743158770765493

Epoch: 5| Step: 2
Training loss: 2.8281449796698
Validation loss: 2.7941261542055593

Epoch: 5| Step: 3
Training loss: 3.2115048837685487
Validation loss: 2.80908856518656

Epoch: 5| Step: 4
Training loss: 2.9050923985085344
Validation loss: 2.8451950934256716

Epoch: 5| Step: 5
Training loss: 3.274288531183074
Validation loss: 2.8781517448080973

Epoch: 5| Step: 6
Training loss: 3.4746096494694947
Validation loss: 2.863745038081538

Epoch: 5| Step: 7
Training loss: 3.470909202695941
Validation loss: 2.8481927582339197

Epoch: 5| Step: 8
Training loss: 2.4873231872901047
Validation loss: 2.827252713235188

Epoch: 5| Step: 9
Training loss: 2.2662527332825966
Validation loss: 2.8073440435155974

Epoch: 5| Step: 10
Training loss: 3.905006271728481
Validation loss: 2.8036911631762087

Epoch: 102| Step: 0
Training loss: 3.0450441777574637
Validation loss: 2.784492375240219

Epoch: 5| Step: 1
Training loss: 2.5482334188563494
Validation loss: 2.782670568389227

Epoch: 5| Step: 2
Training loss: 3.1698490682104055
Validation loss: 2.7638690793047616

Epoch: 5| Step: 3
Training loss: 2.992981329811562
Validation loss: 2.7656598416555376

Epoch: 5| Step: 4
Training loss: 3.099053047506571
Validation loss: 2.7651542650892393

Epoch: 5| Step: 5
Training loss: 3.1790386915801254
Validation loss: 2.762554078748351

Epoch: 5| Step: 6
Training loss: 3.2843237149692586
Validation loss: 2.7627854408702754

Epoch: 5| Step: 7
Training loss: 2.2965042956922717
Validation loss: 2.760667504313648

Epoch: 5| Step: 8
Training loss: 3.89437917950032
Validation loss: 2.7574576332827823

Epoch: 5| Step: 9
Training loss: 2.7791468351267565
Validation loss: 2.756830011104777

Epoch: 5| Step: 10
Training loss: 3.3966786711246395
Validation loss: 2.755598540772438

Epoch: 103| Step: 0
Training loss: 3.0358954944541603
Validation loss: 2.752177057252909

Epoch: 5| Step: 1
Training loss: 3.2221966409946656
Validation loss: 2.7514390498975523

Epoch: 5| Step: 2
Training loss: 3.1751634811004403
Validation loss: 2.750713747050922

Epoch: 5| Step: 3
Training loss: 3.504224543749321
Validation loss: 2.7497185295494853

Epoch: 5| Step: 4
Training loss: 3.2722506681831094
Validation loss: 2.7480337528601986

Epoch: 5| Step: 5
Training loss: 2.674541815618599
Validation loss: 2.74468998871374

Epoch: 5| Step: 6
Training loss: 3.0289341840422623
Validation loss: 2.743518123321255

Epoch: 5| Step: 7
Training loss: 2.783214261216756
Validation loss: 2.752416365749584

Epoch: 5| Step: 8
Training loss: 2.904833704904536
Validation loss: 2.7553306692155934

Epoch: 5| Step: 9
Training loss: 2.941737750295922
Validation loss: 2.7546741833079738

Epoch: 5| Step: 10
Training loss: 3.2320567498182036
Validation loss: 2.7501241808808183

Epoch: 104| Step: 0
Training loss: 3.1605541228693466
Validation loss: 2.743123135180556

Epoch: 5| Step: 1
Training loss: 2.82687552655131
Validation loss: 2.7453494737558017

Epoch: 5| Step: 2
Training loss: 3.503136455643067
Validation loss: 2.7411741250464625

Epoch: 5| Step: 3
Training loss: 2.9180399976659874
Validation loss: 2.7443033899318126

Epoch: 5| Step: 4
Training loss: 3.1750858385392173
Validation loss: 2.747085475533104

Epoch: 5| Step: 5
Training loss: 3.239061286951805
Validation loss: 2.743377613334312

Epoch: 5| Step: 6
Training loss: 3.275414645903645
Validation loss: 2.7431362555776495

Epoch: 5| Step: 7
Training loss: 3.0605312948311156
Validation loss: 2.742567403181182

Epoch: 5| Step: 8
Training loss: 2.740662849191011
Validation loss: 2.73997675401171

Epoch: 5| Step: 9
Training loss: 2.416799333372911
Validation loss: 2.7454256689666776

Epoch: 5| Step: 10
Training loss: 3.2221432179232945
Validation loss: 2.7375143248465648

Epoch: 105| Step: 0
Training loss: 2.7435571450687988
Validation loss: 2.740520608146015

Epoch: 5| Step: 1
Training loss: 2.8413088874403742
Validation loss: 2.7491501038342876

Epoch: 5| Step: 2
Training loss: 3.461267459890097
Validation loss: 2.75480857908148

Epoch: 5| Step: 3
Training loss: 3.191604215909031
Validation loss: 2.762710155933967

Epoch: 5| Step: 4
Training loss: 3.2505847698260686
Validation loss: 2.7528050157368527

Epoch: 5| Step: 5
Training loss: 3.483496037627291
Validation loss: 2.7347775623827055

Epoch: 5| Step: 6
Training loss: 3.201494648681248
Validation loss: 2.7368449625896516

Epoch: 5| Step: 7
Training loss: 2.983312127945479
Validation loss: 2.7397305939394423

Epoch: 5| Step: 8
Training loss: 2.5943020152773593
Validation loss: 2.7427850495302764

Epoch: 5| Step: 9
Training loss: 2.7390005171052154
Validation loss: 2.7488754076109325

Epoch: 5| Step: 10
Training loss: 3.1128359754994754
Validation loss: 2.7560402507682737

Epoch: 106| Step: 0
Training loss: 3.4651220095953095
Validation loss: 2.745804171791928

Epoch: 5| Step: 1
Training loss: 2.7985439329285597
Validation loss: 2.745522588662015

Epoch: 5| Step: 2
Training loss: 2.622218793078334
Validation loss: 2.7430304139875346

Epoch: 5| Step: 3
Training loss: 3.3570342669563327
Validation loss: 2.741276714611377

Epoch: 5| Step: 4
Training loss: 3.1387469241766404
Validation loss: 2.741277058764774

Epoch: 5| Step: 5
Training loss: 2.977639631685487
Validation loss: 2.7397768933336635

Epoch: 5| Step: 6
Training loss: 3.0697306695648385
Validation loss: 2.7397423887563206

Epoch: 5| Step: 7
Training loss: 2.888736912405953
Validation loss: 2.7369245371494784

Epoch: 5| Step: 8
Training loss: 3.1075389559476054
Validation loss: 2.7367722154869893

Epoch: 5| Step: 9
Training loss: 3.2466323717826944
Validation loss: 2.7354117907451356

Epoch: 5| Step: 10
Training loss: 2.9644434159788795
Validation loss: 2.737933828542381

Epoch: 107| Step: 0
Training loss: 3.137508535183547
Validation loss: 2.736687270697167

Epoch: 5| Step: 1
Training loss: 3.0882315691757176
Validation loss: 2.7424418789480915

Epoch: 5| Step: 2
Training loss: 3.083436208160059
Validation loss: 2.7394280612874766

Epoch: 5| Step: 3
Training loss: 2.7533928142277335
Validation loss: 2.735886903804025

Epoch: 5| Step: 4
Training loss: 2.9878698527067518
Validation loss: 2.731038176508172

Epoch: 5| Step: 5
Training loss: 2.6938290259149364
Validation loss: 2.730264585792453

Epoch: 5| Step: 6
Training loss: 3.7298684481006457
Validation loss: 2.7287528607221274

Epoch: 5| Step: 7
Training loss: 2.990915371660825
Validation loss: 2.7306535073176237

Epoch: 5| Step: 8
Training loss: 2.4343639642859514
Validation loss: 2.7333373235807947

Epoch: 5| Step: 9
Training loss: 3.619386338334924
Validation loss: 2.741573218543327

Epoch: 5| Step: 10
Training loss: 2.743478411395418
Validation loss: 2.746222421294606

Epoch: 108| Step: 0
Training loss: 2.706710466146386
Validation loss: 2.753654122722075

Epoch: 5| Step: 1
Training loss: 3.1078083941632473
Validation loss: 2.7578963609441223

Epoch: 5| Step: 2
Training loss: 2.9112209343841267
Validation loss: 2.7794825657657363

Epoch: 5| Step: 3
Training loss: 3.197699441065884
Validation loss: 2.781330416729952

Epoch: 5| Step: 4
Training loss: 3.339635010381146
Validation loss: 2.7861921684531006

Epoch: 5| Step: 5
Training loss: 2.985170747611436
Validation loss: 2.753167342949052

Epoch: 5| Step: 6
Training loss: 3.2881788937985217
Validation loss: 2.7243903086251473

Epoch: 5| Step: 7
Training loss: 2.6492590966129246
Validation loss: 2.718756745843624

Epoch: 5| Step: 8
Training loss: 2.8120059957046943
Validation loss: 2.7190847137771468

Epoch: 5| Step: 9
Training loss: 3.211028977179302
Validation loss: 2.720954452969845

Epoch: 5| Step: 10
Training loss: 3.2868592772875758
Validation loss: 2.72162457065882

Epoch: 109| Step: 0
Training loss: 2.7902544824355555
Validation loss: 2.7209394740822117

Epoch: 5| Step: 1
Training loss: 3.405913590083823
Validation loss: 2.722812185034053

Epoch: 5| Step: 2
Training loss: 2.9357284723230124
Validation loss: 2.719482790821965

Epoch: 5| Step: 3
Training loss: 2.876712454928341
Validation loss: 2.7210704277356004

Epoch: 5| Step: 4
Training loss: 2.6667736945926603
Validation loss: 2.717441325436643

Epoch: 5| Step: 5
Training loss: 3.436675094115626
Validation loss: 2.7191819038980034

Epoch: 5| Step: 6
Training loss: 2.749850355758462
Validation loss: 2.7208776205220815

Epoch: 5| Step: 7
Training loss: 2.7203507369770596
Validation loss: 2.719431988557377

Epoch: 5| Step: 8
Training loss: 3.3950933730666115
Validation loss: 2.7191393296125916

Epoch: 5| Step: 9
Training loss: 3.514425115334852
Validation loss: 2.720582959191041

Epoch: 5| Step: 10
Training loss: 2.901472040347025
Validation loss: 2.718354638301002

Epoch: 110| Step: 0
Training loss: 3.4487290515380953
Validation loss: 2.7168421120620714

Epoch: 5| Step: 1
Training loss: 2.577580619905383
Validation loss: 2.7166985266129804

Epoch: 5| Step: 2
Training loss: 3.446756419323528
Validation loss: 2.7126368128664495

Epoch: 5| Step: 3
Training loss: 2.397015078354359
Validation loss: 2.7136087487056515

Epoch: 5| Step: 4
Training loss: 3.0150155355834523
Validation loss: 2.7131884565474134

Epoch: 5| Step: 5
Training loss: 3.6279207499048725
Validation loss: 2.7156919981284684

Epoch: 5| Step: 6
Training loss: 3.287055701340612
Validation loss: 2.7164685449680497

Epoch: 5| Step: 7
Training loss: 2.553540453499073
Validation loss: 2.7128424397927873

Epoch: 5| Step: 8
Training loss: 2.95063523387528
Validation loss: 2.7153260553394776

Epoch: 5| Step: 9
Training loss: 2.7608599804637093
Validation loss: 2.72292567513824

Epoch: 5| Step: 10
Training loss: 3.1163683893060865
Validation loss: 2.7247525473370557

Epoch: 111| Step: 0
Training loss: 3.0408581917742348
Validation loss: 2.731564316272685

Epoch: 5| Step: 1
Training loss: 3.32466655005692
Validation loss: 2.7340613494386377

Epoch: 5| Step: 2
Training loss: 2.8779537120964482
Validation loss: 2.7369141783123765

Epoch: 5| Step: 3
Training loss: 2.752812681116918
Validation loss: 2.7458499626417847

Epoch: 5| Step: 4
Training loss: 3.1783786488666337
Validation loss: 2.7486460933594605

Epoch: 5| Step: 5
Training loss: 3.2148048889852032
Validation loss: 2.745483092483028

Epoch: 5| Step: 6
Training loss: 3.2429811540374227
Validation loss: 2.7251037960599698

Epoch: 5| Step: 7
Training loss: 2.3936421422339067
Validation loss: 2.7090769527029535

Epoch: 5| Step: 8
Training loss: 3.0772429620915047
Validation loss: 2.7023027810169284

Epoch: 5| Step: 9
Training loss: 3.1214041812139612
Validation loss: 2.702925861152254

Epoch: 5| Step: 10
Training loss: 3.200224218857853
Validation loss: 2.7069946924892445

Epoch: 112| Step: 0
Training loss: 2.9011272278546674
Validation loss: 2.70818732714494

Epoch: 5| Step: 1
Training loss: 3.2846551574212213
Validation loss: 2.7083236189321713

Epoch: 5| Step: 2
Training loss: 3.3464329018835985
Validation loss: 2.7082805133019985

Epoch: 5| Step: 3
Training loss: 2.984815475153419
Validation loss: 2.7078347106026097

Epoch: 5| Step: 4
Training loss: 3.466541996572588
Validation loss: 2.708585187562209

Epoch: 5| Step: 5
Training loss: 3.294807545160044
Validation loss: 2.705679657541065

Epoch: 5| Step: 6
Training loss: 2.7979795523190143
Validation loss: 2.7049898932753424

Epoch: 5| Step: 7
Training loss: 2.4165091846937954
Validation loss: 2.7042779141902136

Epoch: 5| Step: 8
Training loss: 3.0878988093364814
Validation loss: 2.7125208394971283

Epoch: 5| Step: 9
Training loss: 3.205463281673757
Validation loss: 2.722156874272952

Epoch: 5| Step: 10
Training loss: 2.311780250507332
Validation loss: 2.7406743144748758

Epoch: 113| Step: 0
Training loss: 2.487291843005214
Validation loss: 2.733452360301316

Epoch: 5| Step: 1
Training loss: 3.581738775162619
Validation loss: 2.7140268551757396

Epoch: 5| Step: 2
Training loss: 2.426473079686917
Validation loss: 2.6997859641359385

Epoch: 5| Step: 3
Training loss: 3.145721248288862
Validation loss: 2.7012044056279527

Epoch: 5| Step: 4
Training loss: 3.1698863743776124
Validation loss: 2.6964293432273907

Epoch: 5| Step: 5
Training loss: 3.6011385388853228
Validation loss: 2.698632249011247

Epoch: 5| Step: 6
Training loss: 2.9910983899818886
Validation loss: 2.6974944981948257

Epoch: 5| Step: 7
Training loss: 2.6449370981391587
Validation loss: 2.696321742363417

Epoch: 5| Step: 8
Training loss: 3.011398436932495
Validation loss: 2.695185055542679

Epoch: 5| Step: 9
Training loss: 3.139403148223432
Validation loss: 2.6943192806195175

Epoch: 5| Step: 10
Training loss: 2.8508000438820247
Validation loss: 2.692538476559115

Epoch: 114| Step: 0
Training loss: 3.0473799849451075
Validation loss: 2.6920933209835742

Epoch: 5| Step: 1
Training loss: 3.0153447945029983
Validation loss: 2.693871381630783

Epoch: 5| Step: 2
Training loss: 2.8429525745473647
Validation loss: 2.6968603853337263

Epoch: 5| Step: 3
Training loss: 2.7649461160827906
Validation loss: 2.705330362506637

Epoch: 5| Step: 4
Training loss: 3.550824625654689
Validation loss: 2.719590382152689

Epoch: 5| Step: 5
Training loss: 2.762469889619115
Validation loss: 2.719425055845934

Epoch: 5| Step: 6
Training loss: 2.735460164135152
Validation loss: 2.7400694391313904

Epoch: 5| Step: 7
Training loss: 2.730113867316824
Validation loss: 2.7315527442383734

Epoch: 5| Step: 8
Training loss: 3.3614696980463457
Validation loss: 2.7042386043638587

Epoch: 5| Step: 9
Training loss: 3.1348810762910597
Validation loss: 2.6881900272588166

Epoch: 5| Step: 10
Training loss: 3.2367427102246453
Validation loss: 2.6880641286990548

Epoch: 115| Step: 0
Training loss: 2.5294663538175826
Validation loss: 2.697015665487896

Epoch: 5| Step: 1
Training loss: 3.1402827593571603
Validation loss: 2.6998036859364016

Epoch: 5| Step: 2
Training loss: 2.6647599277828546
Validation loss: 2.702133032738709

Epoch: 5| Step: 3
Training loss: 2.800346904790621
Validation loss: 2.706261741008145

Epoch: 5| Step: 4
Training loss: 3.201230414590203
Validation loss: 2.7082324240338393

Epoch: 5| Step: 5
Training loss: 3.260194488527846
Validation loss: 2.709036377243256

Epoch: 5| Step: 6
Training loss: 2.9323671013912596
Validation loss: 2.704640600155501

Epoch: 5| Step: 7
Training loss: 3.530306259572525
Validation loss: 2.701005123280952

Epoch: 5| Step: 8
Training loss: 3.0363834605247315
Validation loss: 2.6981586587386603

Epoch: 5| Step: 9
Training loss: 2.8216061993192576
Validation loss: 2.699032981628215

Epoch: 5| Step: 10
Training loss: 3.430112773275849
Validation loss: 2.6942161390671946

Epoch: 116| Step: 0
Training loss: 3.112790479472044
Validation loss: 2.6934893376695768

Epoch: 5| Step: 1
Training loss: 2.847744494249582
Validation loss: 2.6943887695586652

Epoch: 5| Step: 2
Training loss: 2.5986362989101943
Validation loss: 2.691056441251585

Epoch: 5| Step: 3
Training loss: 3.307252289945626
Validation loss: 2.6907213302411344

Epoch: 5| Step: 4
Training loss: 3.0539671690049897
Validation loss: 2.688442385513177

Epoch: 5| Step: 5
Training loss: 3.5789961774645227
Validation loss: 2.6878058919318404

Epoch: 5| Step: 6
Training loss: 2.9478790676203888
Validation loss: 2.684962256137208

Epoch: 5| Step: 7
Training loss: 2.6167263250981034
Validation loss: 2.6878142539205383

Epoch: 5| Step: 8
Training loss: 3.2897578793282114
Validation loss: 2.687726991133865

Epoch: 5| Step: 9
Training loss: 2.905712118928993
Validation loss: 2.6965657301746657

Epoch: 5| Step: 10
Training loss: 2.9032262022777
Validation loss: 2.706755419999626

Epoch: 117| Step: 0
Training loss: 3.419708541586463
Validation loss: 2.716963110424181

Epoch: 5| Step: 1
Training loss: 3.0368942724269172
Validation loss: 2.69405069347208

Epoch: 5| Step: 2
Training loss: 2.969185405725243
Validation loss: 2.6848420012537595

Epoch: 5| Step: 3
Training loss: 2.7051794811223617
Validation loss: 2.684626692380635

Epoch: 5| Step: 4
Training loss: 3.178001763009026
Validation loss: 2.6842235349164705

Epoch: 5| Step: 5
Training loss: 3.0120325382699105
Validation loss: 2.6859523898841964

Epoch: 5| Step: 6
Training loss: 2.7354573750620297
Validation loss: 2.682536354616404

Epoch: 5| Step: 7
Training loss: 2.8605382668879935
Validation loss: 2.693001198503288

Epoch: 5| Step: 8
Training loss: 3.167195894957578
Validation loss: 2.6987597083180184

Epoch: 5| Step: 9
Training loss: 3.1266325691603387
Validation loss: 2.683635696952862

Epoch: 5| Step: 10
Training loss: 2.9144478305369246
Validation loss: 2.6840000098529995

Epoch: 118| Step: 0
Training loss: 2.620411086118723
Validation loss: 2.688708998540162

Epoch: 5| Step: 1
Training loss: 3.0899335652835984
Validation loss: 2.6797694701914403

Epoch: 5| Step: 2
Training loss: 2.8475763757123596
Validation loss: 2.679928729071269

Epoch: 5| Step: 3
Training loss: 3.6147091245429017
Validation loss: 2.6777323357549263

Epoch: 5| Step: 4
Training loss: 3.247011718221325
Validation loss: 2.6768044253473664

Epoch: 5| Step: 5
Training loss: 2.2608716890554756
Validation loss: 2.6789846262340253

Epoch: 5| Step: 6
Training loss: 3.3788531878059
Validation loss: 2.675976586987006

Epoch: 5| Step: 7
Training loss: 2.957373414091629
Validation loss: 2.677916098051927

Epoch: 5| Step: 8
Training loss: 3.5237507818301697
Validation loss: 2.6765516603942126

Epoch: 5| Step: 9
Training loss: 2.8690669996190787
Validation loss: 2.682793360400522

Epoch: 5| Step: 10
Training loss: 2.288222748023884
Validation loss: 2.681261614201548

Epoch: 119| Step: 0
Training loss: 2.8995998961581395
Validation loss: 2.692422712472874

Epoch: 5| Step: 1
Training loss: 2.089623783692425
Validation loss: 2.716711453785122

Epoch: 5| Step: 2
Training loss: 3.345193711674696
Validation loss: 2.755015873013593

Epoch: 5| Step: 3
Training loss: 2.8022588133668678
Validation loss: 2.761762490076772

Epoch: 5| Step: 4
Training loss: 2.3381504561387816
Validation loss: 2.7089456227383697

Epoch: 5| Step: 5
Training loss: 2.790873476523594
Validation loss: 2.7074281724415936

Epoch: 5| Step: 6
Training loss: 3.8958181017137625
Validation loss: 2.6829114224037887

Epoch: 5| Step: 7
Training loss: 2.950307642525924
Validation loss: 2.673125388889427

Epoch: 5| Step: 8
Training loss: 3.6850476919993276
Validation loss: 2.6748684153539672

Epoch: 5| Step: 9
Training loss: 2.939275326848692
Validation loss: 2.6780352730035286

Epoch: 5| Step: 10
Training loss: 2.9158014013114215
Validation loss: 2.6782582467826703

Epoch: 120| Step: 0
Training loss: 3.134003144224302
Validation loss: 2.678191995930847

Epoch: 5| Step: 1
Training loss: 3.237669368128391
Validation loss: 2.676653806513783

Epoch: 5| Step: 2
Training loss: 3.1465051367351187
Validation loss: 2.6768281930857176

Epoch: 5| Step: 3
Training loss: 3.1577447052501184
Validation loss: 2.67435649476225

Epoch: 5| Step: 4
Training loss: 3.216380311807151
Validation loss: 2.6738702404937538

Epoch: 5| Step: 5
Training loss: 3.0677201292958607
Validation loss: 2.6740784457757822

Epoch: 5| Step: 6
Training loss: 2.649595114528833
Validation loss: 2.6739081329410923

Epoch: 5| Step: 7
Training loss: 2.8843788089086444
Validation loss: 2.675503278173724

Epoch: 5| Step: 8
Training loss: 2.750339400414859
Validation loss: 2.6844229266135895

Epoch: 5| Step: 9
Training loss: 2.6454482411563003
Validation loss: 2.6987741881063654

Epoch: 5| Step: 10
Training loss: 3.253717350599959
Validation loss: 2.7582148854748025

Epoch: 121| Step: 0
Training loss: 3.0862832950049106
Validation loss: 2.718236631232876

Epoch: 5| Step: 1
Training loss: 3.1653390075495618
Validation loss: 2.700329613325197

Epoch: 5| Step: 2
Training loss: 3.578548889371988
Validation loss: 2.6761212183191465

Epoch: 5| Step: 3
Training loss: 2.7549276419274356
Validation loss: 2.674433607344103

Epoch: 5| Step: 4
Training loss: 2.9500112113093038
Validation loss: 2.6703264025248723

Epoch: 5| Step: 5
Training loss: 3.0144151227235594
Validation loss: 2.66960825174345

Epoch: 5| Step: 6
Training loss: 2.8415535629301405
Validation loss: 2.669457409348506

Epoch: 5| Step: 7
Training loss: 2.85982005506911
Validation loss: 2.6681219162774936

Epoch: 5| Step: 8
Training loss: 2.3622118335151328
Validation loss: 2.6639736132921983

Epoch: 5| Step: 9
Training loss: 3.1779309418883117
Validation loss: 2.669432837459493

Epoch: 5| Step: 10
Training loss: 3.1312230518270283
Validation loss: 2.6797964853074054

Epoch: 122| Step: 0
Training loss: 3.341538883597751
Validation loss: 2.693946986836319

Epoch: 5| Step: 1
Training loss: 3.480548622250956
Validation loss: 2.727860370530628

Epoch: 5| Step: 2
Training loss: 3.2459910682936104
Validation loss: 2.7311573679191445

Epoch: 5| Step: 3
Training loss: 3.0088432626569035
Validation loss: 2.721459926538852

Epoch: 5| Step: 4
Training loss: 3.2509891765300494
Validation loss: 2.694067169784184

Epoch: 5| Step: 5
Training loss: 2.4319441640367048
Validation loss: 2.6908272352975136

Epoch: 5| Step: 6
Training loss: 3.009824718808665
Validation loss: 2.664687226360009

Epoch: 5| Step: 7
Training loss: 2.900262057861748
Validation loss: 2.6585592309379873

Epoch: 5| Step: 8
Training loss: 2.694336468432804
Validation loss: 2.6591802640149838

Epoch: 5| Step: 9
Training loss: 2.9879604990236377
Validation loss: 2.6575419749381184

Epoch: 5| Step: 10
Training loss: 2.475014476541124
Validation loss: 2.655983545594483

Epoch: 123| Step: 0
Training loss: 2.9646613626583487
Validation loss: 2.6549497371601904

Epoch: 5| Step: 1
Training loss: 3.2015874382302583
Validation loss: 2.6579937012537447

Epoch: 5| Step: 2
Training loss: 2.9296279290818563
Validation loss: 2.6794739928176146

Epoch: 5| Step: 3
Training loss: 2.529142090763387
Validation loss: 2.7065534689280746

Epoch: 5| Step: 4
Training loss: 3.0206923528637293
Validation loss: 2.7244151724514474

Epoch: 5| Step: 5
Training loss: 3.44998122500411
Validation loss: 2.7246499951732592

Epoch: 5| Step: 6
Training loss: 2.6992686552742295
Validation loss: 2.726225391415351

Epoch: 5| Step: 7
Training loss: 2.700773153163259
Validation loss: 2.6659059349542176

Epoch: 5| Step: 8
Training loss: 2.75607305464789
Validation loss: 2.6500683974751342

Epoch: 5| Step: 9
Training loss: 2.774772473192103
Validation loss: 2.653588365619289

Epoch: 5| Step: 10
Training loss: 3.923297396170888
Validation loss: 2.659015788283696

Epoch: 124| Step: 0
Training loss: 2.885560584122876
Validation loss: 2.661909621688201

Epoch: 5| Step: 1
Training loss: 2.8632089728045074
Validation loss: 2.6664402049052174

Epoch: 5| Step: 2
Training loss: 2.813708067098118
Validation loss: 2.6593650720803663

Epoch: 5| Step: 3
Training loss: 3.3549016932995372
Validation loss: 2.6619784629535896

Epoch: 5| Step: 4
Training loss: 2.849654387549305
Validation loss: 2.6581462820787225

Epoch: 5| Step: 5
Training loss: 3.2827184388576365
Validation loss: 2.653300161336239

Epoch: 5| Step: 6
Training loss: 2.8108040676710173
Validation loss: 2.6563793201562738

Epoch: 5| Step: 7
Training loss: 3.26469386209237
Validation loss: 2.673336014118599

Epoch: 5| Step: 8
Training loss: 3.15956802457689
Validation loss: 2.71770493890043

Epoch: 5| Step: 9
Training loss: 2.900887905865206
Validation loss: 2.72426984999328

Epoch: 5| Step: 10
Training loss: 2.890560829893728
Validation loss: 2.727566635553886

Epoch: 125| Step: 0
Training loss: 3.1616011476808077
Validation loss: 2.722507104734345

Epoch: 5| Step: 1
Training loss: 3.054625839820856
Validation loss: 2.668285498267717

Epoch: 5| Step: 2
Training loss: 2.8624299619677003
Validation loss: 2.6565464257320386

Epoch: 5| Step: 3
Training loss: 3.016267540031367
Validation loss: 2.6509457695819867

Epoch: 5| Step: 4
Training loss: 3.28404175204686
Validation loss: 2.649170375128327

Epoch: 5| Step: 5
Training loss: 3.26762963782804
Validation loss: 2.654708983761181

Epoch: 5| Step: 6
Training loss: 2.4752778292302184
Validation loss: 2.656601429806051

Epoch: 5| Step: 7
Training loss: 3.4392465489320214
Validation loss: 2.6541231735971773

Epoch: 5| Step: 8
Training loss: 2.6518872504453705
Validation loss: 2.665641022786362

Epoch: 5| Step: 9
Training loss: 2.823898613857738
Validation loss: 2.6677048979589735

Epoch: 5| Step: 10
Training loss: 2.9159536489248628
Validation loss: 2.6636866953199445

Epoch: 126| Step: 0
Training loss: 3.0246860183568733
Validation loss: 2.6592444463188065

Epoch: 5| Step: 1
Training loss: 3.13146015002644
Validation loss: 2.6520802429205443

Epoch: 5| Step: 2
Training loss: 2.647361334176241
Validation loss: 2.6483260654686944

Epoch: 5| Step: 3
Training loss: 2.8319588487512504
Validation loss: 2.6512719492385597

Epoch: 5| Step: 4
Training loss: 2.916199419651506
Validation loss: 2.6533232053041

Epoch: 5| Step: 5
Training loss: 3.173684191447835
Validation loss: 2.664660573741644

Epoch: 5| Step: 6
Training loss: 2.757321149156583
Validation loss: 2.6574030806136957

Epoch: 5| Step: 7
Training loss: 2.825056909308646
Validation loss: 2.6484891432884186

Epoch: 5| Step: 8
Training loss: 3.5164383011081664
Validation loss: 2.647562152205404

Epoch: 5| Step: 9
Training loss: 3.0658281886963237
Validation loss: 2.6473981070232697

Epoch: 5| Step: 10
Training loss: 2.9187375119450625
Validation loss: 2.6494980946048505

Epoch: 127| Step: 0
Training loss: 2.9565730880097743
Validation loss: 2.650429721723793

Epoch: 5| Step: 1
Training loss: 2.641926100674154
Validation loss: 2.654629385112649

Epoch: 5| Step: 2
Training loss: 3.742773850282749
Validation loss: 2.6614074226960294

Epoch: 5| Step: 3
Training loss: 2.838277392669585
Validation loss: 2.6702377233693984

Epoch: 5| Step: 4
Training loss: 3.4167645758269587
Validation loss: 2.6849993122285025

Epoch: 5| Step: 5
Training loss: 2.5415092065116442
Validation loss: 2.6761102035712017

Epoch: 5| Step: 6
Training loss: 3.195080886318402
Validation loss: 2.6671340956355976

Epoch: 5| Step: 7
Training loss: 3.235549050247141
Validation loss: 2.6605742106018644

Epoch: 5| Step: 8
Training loss: 2.8598167203317697
Validation loss: 2.661300098361459

Epoch: 5| Step: 9
Training loss: 2.8563262862487586
Validation loss: 2.6598787791705054

Epoch: 5| Step: 10
Training loss: 2.276771434236938
Validation loss: 2.662505608171019

Epoch: 128| Step: 0
Training loss: 3.211354769211174
Validation loss: 2.6598509150288923

Epoch: 5| Step: 1
Training loss: 2.4370115720014733
Validation loss: 2.6611496289359655

Epoch: 5| Step: 2
Training loss: 2.882785703953208
Validation loss: 2.661984729567017

Epoch: 5| Step: 3
Training loss: 3.1046242771325234
Validation loss: 2.667723142312415

Epoch: 5| Step: 4
Training loss: 3.1856028577047395
Validation loss: 2.678060129727592

Epoch: 5| Step: 5
Training loss: 3.092653793174405
Validation loss: 2.6841381878631165

Epoch: 5| Step: 6
Training loss: 3.0147621620211913
Validation loss: 2.6843503642590507

Epoch: 5| Step: 7
Training loss: 2.6996907374966117
Validation loss: 2.663591814295544

Epoch: 5| Step: 8
Training loss: 2.419398955588956
Validation loss: 2.657336886730403

Epoch: 5| Step: 9
Training loss: 2.9782706738416236
Validation loss: 2.6555548543078586

Epoch: 5| Step: 10
Training loss: 3.7974093339856463
Validation loss: 2.650155044875652

Epoch: 129| Step: 0
Training loss: 3.1930804302863
Validation loss: 2.648315483019733

Epoch: 5| Step: 1
Training loss: 2.1447951635622773
Validation loss: 2.644772880441695

Epoch: 5| Step: 2
Training loss: 3.2114076293413754
Validation loss: 2.64372221775682

Epoch: 5| Step: 3
Training loss: 3.3683737238583107
Validation loss: 2.639735958159924

Epoch: 5| Step: 4
Training loss: 2.809922966223601
Validation loss: 2.6395626097183205

Epoch: 5| Step: 5
Training loss: 2.8111611464432222
Validation loss: 2.6376951142273994

Epoch: 5| Step: 6
Training loss: 2.8214117639465246
Validation loss: 2.6493534265211176

Epoch: 5| Step: 7
Training loss: 3.1239472714124723
Validation loss: 2.6519343410423986

Epoch: 5| Step: 8
Training loss: 3.209183188169459
Validation loss: 2.6627037541550305

Epoch: 5| Step: 9
Training loss: 2.903722669100872
Validation loss: 2.654092872868634

Epoch: 5| Step: 10
Training loss: 3.1868657995862884
Validation loss: 2.657595662887252

Epoch: 130| Step: 0
Training loss: 2.7708699981634672
Validation loss: 2.6515076056139844

Epoch: 5| Step: 1
Training loss: 2.912067784013024
Validation loss: 2.636278252792997

Epoch: 5| Step: 2
Training loss: 2.8556808205064512
Validation loss: 2.633969274069968

Epoch: 5| Step: 3
Training loss: 2.7428831429895424
Validation loss: 2.6362590926019425

Epoch: 5| Step: 4
Training loss: 3.0249918409505474
Validation loss: 2.6344846421188306

Epoch: 5| Step: 5
Training loss: 3.100465518084826
Validation loss: 2.632637065550036

Epoch: 5| Step: 6
Training loss: 2.9222966670169876
Validation loss: 2.632659312218765

Epoch: 5| Step: 7
Training loss: 3.4915989458774526
Validation loss: 2.628969161613156

Epoch: 5| Step: 8
Training loss: 2.5390976184470375
Validation loss: 2.6314468042839847

Epoch: 5| Step: 9
Training loss: 2.7809482367895892
Validation loss: 2.6295509597979985

Epoch: 5| Step: 10
Training loss: 3.5108800444508836
Validation loss: 2.628926886548068

Epoch: 131| Step: 0
Training loss: 3.386492060518103
Validation loss: 2.6291006866247653

Epoch: 5| Step: 1
Training loss: 3.4796797931724543
Validation loss: 2.628671865292644

Epoch: 5| Step: 2
Training loss: 2.841747543064081
Validation loss: 2.628060630466667

Epoch: 5| Step: 3
Training loss: 2.4105938432265925
Validation loss: 2.628736047397843

Epoch: 5| Step: 4
Training loss: 2.913919644778838
Validation loss: 2.6297786674006627

Epoch: 5| Step: 5
Training loss: 2.707116327971775
Validation loss: 2.6272756866223292

Epoch: 5| Step: 6
Training loss: 3.124908903701531
Validation loss: 2.628794140648306

Epoch: 5| Step: 7
Training loss: 2.806208206239362
Validation loss: 2.6296370685259123

Epoch: 5| Step: 8
Training loss: 2.86723024092164
Validation loss: 2.6317087418704337

Epoch: 5| Step: 9
Training loss: 3.2483986063688945
Validation loss: 2.6486843143073022

Epoch: 5| Step: 10
Training loss: 2.6960995616866783
Validation loss: 2.6590368756822316

Epoch: 132| Step: 0
Training loss: 2.9100838261751516
Validation loss: 2.691402373207003

Epoch: 5| Step: 1
Training loss: 3.3461360796010684
Validation loss: 2.691641924712726

Epoch: 5| Step: 2
Training loss: 2.6773100780443424
Validation loss: 2.6674002877154535

Epoch: 5| Step: 3
Training loss: 2.935738055411735
Validation loss: 2.6350281335888925

Epoch: 5| Step: 4
Training loss: 2.5290172761121137
Validation loss: 2.628946637490039

Epoch: 5| Step: 5
Training loss: 2.771760847457011
Validation loss: 2.62350729648824

Epoch: 5| Step: 6
Training loss: 3.0169502469247704
Validation loss: 2.6243988809865963

Epoch: 5| Step: 7
Training loss: 3.306369218317415
Validation loss: 2.6239091195432738

Epoch: 5| Step: 8
Training loss: 2.758341795187088
Validation loss: 2.624369678909087

Epoch: 5| Step: 9
Training loss: 3.4532490013263066
Validation loss: 2.625578116897453

Epoch: 5| Step: 10
Training loss: 2.9034852033356
Validation loss: 2.6224627951180435

Epoch: 133| Step: 0
Training loss: 2.90225864455051
Validation loss: 2.618045428851722

Epoch: 5| Step: 1
Training loss: 3.338979865887155
Validation loss: 2.619748820103705

Epoch: 5| Step: 2
Training loss: 2.9485237565839024
Validation loss: 2.6194964393205833

Epoch: 5| Step: 3
Training loss: 3.3124523519291973
Validation loss: 2.6217158781531773

Epoch: 5| Step: 4
Training loss: 3.097999505630956
Validation loss: 2.6479707578198086

Epoch: 5| Step: 5
Training loss: 2.773429075416342
Validation loss: 2.6566637917268365

Epoch: 5| Step: 6
Training loss: 1.613213415313035
Validation loss: 2.6570305002716705

Epoch: 5| Step: 7
Training loss: 2.7982592007797518
Validation loss: 2.66739750340489

Epoch: 5| Step: 8
Training loss: 3.2044163031657016
Validation loss: 2.666544057414126

Epoch: 5| Step: 9
Training loss: 3.398685840872364
Validation loss: 2.6377552562328717

Epoch: 5| Step: 10
Training loss: 2.950001028028406
Validation loss: 2.627447689375513

Epoch: 134| Step: 0
Training loss: 2.561186383985352
Validation loss: 2.6173992357236524

Epoch: 5| Step: 1
Training loss: 2.666051843418131
Validation loss: 2.6184557796712595

Epoch: 5| Step: 2
Training loss: 2.839172367873615
Validation loss: 2.6177535641016374

Epoch: 5| Step: 3
Training loss: 2.8921207991152107
Validation loss: 2.619675886305195

Epoch: 5| Step: 4
Training loss: 3.150920031172908
Validation loss: 2.6204026391582294

Epoch: 5| Step: 5
Training loss: 3.0950490362815426
Validation loss: 2.6208520023484367

Epoch: 5| Step: 6
Training loss: 2.87547265189599
Validation loss: 2.623334639593323

Epoch: 5| Step: 7
Training loss: 2.9393656872896443
Validation loss: 2.623176320150258

Epoch: 5| Step: 8
Training loss: 3.0301204818591816
Validation loss: 2.6239675746588036

Epoch: 5| Step: 9
Training loss: 3.2463396440598644
Validation loss: 2.620714831838012

Epoch: 5| Step: 10
Training loss: 3.3757980250917528
Validation loss: 2.6235027877727233

Epoch: 135| Step: 0
Training loss: 3.242159261925222
Validation loss: 2.626609701299198

Epoch: 5| Step: 1
Training loss: 3.1350578195694343
Validation loss: 2.640509860960558

Epoch: 5| Step: 2
Training loss: 2.5727957466735605
Validation loss: 2.6543829323687596

Epoch: 5| Step: 3
Training loss: 2.9688113557598883
Validation loss: 2.6636153091701016

Epoch: 5| Step: 4
Training loss: 3.0290173045558566
Validation loss: 2.6790090368298873

Epoch: 5| Step: 5
Training loss: 3.074767009313073
Validation loss: 2.7104086718731772

Epoch: 5| Step: 6
Training loss: 2.876223428231271
Validation loss: 2.6890456526150004

Epoch: 5| Step: 7
Training loss: 2.91679274876876
Validation loss: 2.667263163935188

Epoch: 5| Step: 8
Training loss: 2.7698973506540634
Validation loss: 2.6580577222063457

Epoch: 5| Step: 9
Training loss: 2.9715384789199115
Validation loss: 2.661698141388181

Epoch: 5| Step: 10
Training loss: 3.114335593552824
Validation loss: 2.6580996448808674

Epoch: 136| Step: 0
Training loss: 2.8883592128162907
Validation loss: 2.6560684431594366

Epoch: 5| Step: 1
Training loss: 3.0264851983182814
Validation loss: 2.665381989923007

Epoch: 5| Step: 2
Training loss: 2.9072091765519774
Validation loss: 2.665386088271533

Epoch: 5| Step: 3
Training loss: 2.7930012734393515
Validation loss: 2.664426302467739

Epoch: 5| Step: 4
Training loss: 3.1943207113287375
Validation loss: 2.6460904309856788

Epoch: 5| Step: 5
Training loss: 2.923149932304773
Validation loss: 2.629771944824106

Epoch: 5| Step: 6
Training loss: 2.950280651384887
Validation loss: 2.627672660153884

Epoch: 5| Step: 7
Training loss: 3.071195752010602
Validation loss: 2.627745125171746

Epoch: 5| Step: 8
Training loss: 2.7812536003861
Validation loss: 2.6365615055256826

Epoch: 5| Step: 9
Training loss: 3.1555897239244053
Validation loss: 2.6389227988182395

Epoch: 5| Step: 10
Training loss: 2.8747596640268083
Validation loss: 2.6383087111589494

Epoch: 137| Step: 0
Training loss: 2.8905372400106994
Validation loss: 2.6462734493597146

Epoch: 5| Step: 1
Training loss: 3.153820349067057
Validation loss: 2.659039604151078

Epoch: 5| Step: 2
Training loss: 2.894825126360318
Validation loss: 2.651122906055366

Epoch: 5| Step: 3
Training loss: 2.9992434819347733
Validation loss: 2.631372194563532

Epoch: 5| Step: 4
Training loss: 2.6632394721910706
Validation loss: 2.6549640503285996

Epoch: 5| Step: 5
Training loss: 3.4644480654578147
Validation loss: 2.6597606509400435

Epoch: 5| Step: 6
Training loss: 2.8489535167218674
Validation loss: 2.667020368255754

Epoch: 5| Step: 7
Training loss: 3.0914472236453387
Validation loss: 2.660347094988759

Epoch: 5| Step: 8
Training loss: 2.319319901260351
Validation loss: 2.6321761626095435

Epoch: 5| Step: 9
Training loss: 2.586066020987242
Validation loss: 2.6287193551884918

Epoch: 5| Step: 10
Training loss: 3.5674845307408405
Validation loss: 2.6270826118804393

Epoch: 138| Step: 0
Training loss: 3.164277095346236
Validation loss: 2.6306968994651276

Epoch: 5| Step: 1
Training loss: 2.951246198807643
Validation loss: 2.627147589077413

Epoch: 5| Step: 2
Training loss: 2.9116516776991945
Validation loss: 2.6403194648048305

Epoch: 5| Step: 3
Training loss: 2.3519491593841133
Validation loss: 2.640099133475768

Epoch: 5| Step: 4
Training loss: 3.422496164457681
Validation loss: 2.6503986658948304

Epoch: 5| Step: 5
Training loss: 2.7865948700059464
Validation loss: 2.653033936337144

Epoch: 5| Step: 6
Training loss: 2.727299544173669
Validation loss: 2.654251734861877

Epoch: 5| Step: 7
Training loss: 3.310997244209011
Validation loss: 2.655586898236482

Epoch: 5| Step: 8
Training loss: 2.824988971114784
Validation loss: 2.662062578031705

Epoch: 5| Step: 9
Training loss: 2.9542574855544648
Validation loss: 2.681124214480196

Epoch: 5| Step: 10
Training loss: 3.1804735116681684
Validation loss: 2.6872493477245545

Epoch: 139| Step: 0
Training loss: 2.8673962093549856
Validation loss: 2.6927593906533636

Epoch: 5| Step: 1
Training loss: 2.8401098743192255
Validation loss: 2.6935466215921107

Epoch: 5| Step: 2
Training loss: 2.9174521523861197
Validation loss: 2.6997517926286485

Epoch: 5| Step: 3
Training loss: 3.151445717035576
Validation loss: 2.7014550233471115

Epoch: 5| Step: 4
Training loss: 2.695796226548747
Validation loss: 2.7159256626684627

Epoch: 5| Step: 5
Training loss: 2.9433180635890692
Validation loss: 2.7314129974948975

Epoch: 5| Step: 6
Training loss: 2.8815180655870765
Validation loss: 2.7201759013586013

Epoch: 5| Step: 7
Training loss: 3.1397336387642336
Validation loss: 2.67816685517403

Epoch: 5| Step: 8
Training loss: 2.972204988693077
Validation loss: 2.6480022865002746

Epoch: 5| Step: 9
Training loss: 3.4195841606705892
Validation loss: 2.634851032065579

Epoch: 5| Step: 10
Training loss: 2.7396967082381773
Validation loss: 2.627131516187465

Epoch: 140| Step: 0
Training loss: 2.6589935495356447
Validation loss: 2.6267995433023907

Epoch: 5| Step: 1
Training loss: 2.5966013666674272
Validation loss: 2.624216449127934

Epoch: 5| Step: 2
Training loss: 2.8075635185087844
Validation loss: 2.6239266366741787

Epoch: 5| Step: 3
Training loss: 3.7500488278071127
Validation loss: 2.6273796304077393

Epoch: 5| Step: 4
Training loss: 2.461020138276442
Validation loss: 2.616190575955257

Epoch: 5| Step: 5
Training loss: 3.0494811820597167
Validation loss: 2.6169371312366905

Epoch: 5| Step: 6
Training loss: 2.559986370318608
Validation loss: 2.6200269586381175

Epoch: 5| Step: 7
Training loss: 3.586736585888048
Validation loss: 2.6182000949106228

Epoch: 5| Step: 8
Training loss: 2.4908079915327863
Validation loss: 2.6414623521407474

Epoch: 5| Step: 9
Training loss: 3.477069397737078
Validation loss: 2.663286130081982

Epoch: 5| Step: 10
Training loss: 2.830762781658928
Validation loss: 2.6629861388139915

Epoch: 141| Step: 0
Training loss: 2.603879246427216
Validation loss: 2.6624671278484193

Epoch: 5| Step: 1
Training loss: 2.9165398343075206
Validation loss: 2.696236744038845

Epoch: 5| Step: 2
Training loss: 2.826292424244188
Validation loss: 2.74168597786616

Epoch: 5| Step: 3
Training loss: 2.553088232963967
Validation loss: 2.731155343218933

Epoch: 5| Step: 4
Training loss: 3.43487476326026
Validation loss: 2.7210683211004243

Epoch: 5| Step: 5
Training loss: 2.915684307513264
Validation loss: 2.6688354258726563

Epoch: 5| Step: 6
Training loss: 3.0657585091639605
Validation loss: 2.606270001641758

Epoch: 5| Step: 7
Training loss: 2.659007537234306
Validation loss: 2.6043184648797126

Epoch: 5| Step: 8
Training loss: 2.6394989501985724
Validation loss: 2.6111067277546733

Epoch: 5| Step: 9
Training loss: 3.4593033560042556
Validation loss: 2.6148857376840073

Epoch: 5| Step: 10
Training loss: 3.3494257306618587
Validation loss: 2.6198316558119426

Epoch: 142| Step: 0
Training loss: 2.6515271554815545
Validation loss: 2.625335652367349

Epoch: 5| Step: 1
Training loss: 2.646481311979316
Validation loss: 2.6315598469080417

Epoch: 5| Step: 2
Training loss: 2.884833395128975
Validation loss: 2.635896966713022

Epoch: 5| Step: 3
Training loss: 3.3559226105488733
Validation loss: 2.631367115741328

Epoch: 5| Step: 4
Training loss: 2.671153456318249
Validation loss: 2.614468151876629

Epoch: 5| Step: 5
Training loss: 2.750423918908431
Validation loss: 2.6047277371999216

Epoch: 5| Step: 6
Training loss: 2.8078114742559515
Validation loss: 2.600934029423381

Epoch: 5| Step: 7
Training loss: 3.2116696898903614
Validation loss: 2.6080698894648036

Epoch: 5| Step: 8
Training loss: 3.8523139143256273
Validation loss: 2.639428283264376

Epoch: 5| Step: 9
Training loss: 2.8951163376276328
Validation loss: 2.6669921375151087

Epoch: 5| Step: 10
Training loss: 2.8770320179695386
Validation loss: 2.672177422197087

Epoch: 143| Step: 0
Training loss: 2.5185225959144364
Validation loss: 2.6214908646060064

Epoch: 5| Step: 1
Training loss: 3.1014630280117053
Validation loss: 2.6018173564466243

Epoch: 5| Step: 2
Training loss: 2.739695315858421
Validation loss: 2.599842700743532

Epoch: 5| Step: 3
Training loss: 2.5232992695365724
Validation loss: 2.6332396812525314

Epoch: 5| Step: 4
Training loss: 2.8660114589336967
Validation loss: 2.736082196978636

Epoch: 5| Step: 5
Training loss: 3.4936550393617307
Validation loss: 2.7764920376095366

Epoch: 5| Step: 6
Training loss: 2.4554504257911756
Validation loss: 2.6176201722458874

Epoch: 5| Step: 7
Training loss: 3.4344117597395063
Validation loss: 2.617818249907609

Epoch: 5| Step: 8
Training loss: 3.28373740238464
Validation loss: 2.6177598259204897

Epoch: 5| Step: 9
Training loss: 3.0042211717236817
Validation loss: 2.625729136812631

Epoch: 5| Step: 10
Training loss: 3.2114301985701146
Validation loss: 2.6467512006746334

Epoch: 144| Step: 0
Training loss: 2.820900810783205
Validation loss: 2.6467981734361863

Epoch: 5| Step: 1
Training loss: 3.083100765495704
Validation loss: 2.643496209708382

Epoch: 5| Step: 2
Training loss: 2.8754620388114165
Validation loss: 2.634938425055768

Epoch: 5| Step: 3
Training loss: 2.8895750046114723
Validation loss: 2.623650463231559

Epoch: 5| Step: 4
Training loss: 3.09937968662013
Validation loss: 2.6132271980557094

Epoch: 5| Step: 5
Training loss: 3.040330166455138
Validation loss: 2.6109421300161837

Epoch: 5| Step: 6
Training loss: 3.14062257073911
Validation loss: 2.611100698382089

Epoch: 5| Step: 7
Training loss: 2.724762155494698
Validation loss: 2.608154152752461

Epoch: 5| Step: 8
Training loss: 3.441648996475586
Validation loss: 2.602143537339398

Epoch: 5| Step: 9
Training loss: 2.441005533520757
Validation loss: 2.6062679350058735

Epoch: 5| Step: 10
Training loss: 3.157501274827472
Validation loss: 2.599810964702818

Epoch: 145| Step: 0
Training loss: 2.895265061493706
Validation loss: 2.610410843679261

Epoch: 5| Step: 1
Training loss: 2.013877169987867
Validation loss: 2.6309895641311245

Epoch: 5| Step: 2
Training loss: 3.0476971421851284
Validation loss: 2.6530030916940883

Epoch: 5| Step: 3
Training loss: 3.3091962641789556
Validation loss: 2.6647522419292966

Epoch: 5| Step: 4
Training loss: 2.8307738992244285
Validation loss: 2.6316194920204126

Epoch: 5| Step: 5
Training loss: 3.1294235963821295
Validation loss: 2.6028737326646922

Epoch: 5| Step: 6
Training loss: 2.8483956087498297
Validation loss: 2.6064190616712772

Epoch: 5| Step: 7
Training loss: 3.165450180363032
Validation loss: 2.6037374373245896

Epoch: 5| Step: 8
Training loss: 2.9560845294475695
Validation loss: 2.597914606977344

Epoch: 5| Step: 9
Training loss: 3.2239774457932993
Validation loss: 2.5921414335886497

Epoch: 5| Step: 10
Training loss: 2.9339344217971624
Validation loss: 2.586193367860567

Epoch: 146| Step: 0
Training loss: 3.1869213102529126
Validation loss: 2.5893530495152155

Epoch: 5| Step: 1
Training loss: 3.3047948508716325
Validation loss: 2.5903750683075724

Epoch: 5| Step: 2
Training loss: 3.7200184429901046
Validation loss: 2.59770424966801

Epoch: 5| Step: 3
Training loss: 2.7957816091226086
Validation loss: 2.6172588418864997

Epoch: 5| Step: 4
Training loss: 2.6059069400838544
Validation loss: 2.624115663590555

Epoch: 5| Step: 5
Training loss: 2.8264492402336163
Validation loss: 2.6112178312534917

Epoch: 5| Step: 6
Training loss: 2.7856618628267804
Validation loss: 2.604346257241765

Epoch: 5| Step: 7
Training loss: 3.0974943063358813
Validation loss: 2.625550401354333

Epoch: 5| Step: 8
Training loss: 2.75851007992049
Validation loss: 2.5915396907318304

Epoch: 5| Step: 9
Training loss: 2.7072339002711954
Validation loss: 2.5842605604566535

Epoch: 5| Step: 10
Training loss: 2.2176527076961134
Validation loss: 2.583273275301118

Epoch: 147| Step: 0
Training loss: 3.0805919075982247
Validation loss: 2.5872695545985422

Epoch: 5| Step: 1
Training loss: 2.138140496557703
Validation loss: 2.5915534628188333

Epoch: 5| Step: 2
Training loss: 3.241236241521443
Validation loss: 2.591751310031118

Epoch: 5| Step: 3
Training loss: 3.1413716050338722
Validation loss: 2.589713651443538

Epoch: 5| Step: 4
Training loss: 2.694366377478465
Validation loss: 2.592536038274943

Epoch: 5| Step: 5
Training loss: 3.0652293285310344
Validation loss: 2.592933306786265

Epoch: 5| Step: 6
Training loss: 3.29979558369379
Validation loss: 2.5928571804902973

Epoch: 5| Step: 7
Training loss: 2.9908669050034344
Validation loss: 2.5924810643101406

Epoch: 5| Step: 8
Training loss: 2.945261663913904
Validation loss: 2.6121335758983975

Epoch: 5| Step: 9
Training loss: 2.5715796411128196
Validation loss: 2.6240831952961283

Epoch: 5| Step: 10
Training loss: 3.1025737968231937
Validation loss: 2.643332159506101

Epoch: 148| Step: 0
Training loss: 3.2299005638382607
Validation loss: 2.6576485307832693

Epoch: 5| Step: 1
Training loss: 2.7773476129818864
Validation loss: 2.64991468979884

Epoch: 5| Step: 2
Training loss: 2.851203624142485
Validation loss: 2.651352092982699

Epoch: 5| Step: 3
Training loss: 2.6708038145944464
Validation loss: 2.636889512621808

Epoch: 5| Step: 4
Training loss: 2.477981305375906
Validation loss: 2.6406724603587652

Epoch: 5| Step: 5
Training loss: 3.0916161162021614
Validation loss: 2.6304494426643723

Epoch: 5| Step: 6
Training loss: 3.081440490653117
Validation loss: 2.6253495283976864

Epoch: 5| Step: 7
Training loss: 3.267227728663067
Validation loss: 2.6024992571621417

Epoch: 5| Step: 8
Training loss: 3.268919820367607
Validation loss: 2.5963844000266394

Epoch: 5| Step: 9
Training loss: 2.407326989854927
Validation loss: 2.592539435976391

Epoch: 5| Step: 10
Training loss: 3.2937934539650193
Validation loss: 2.5911681056115365

Epoch: 149| Step: 0
Training loss: 2.9487865409187908
Validation loss: 2.5918524361744284

Epoch: 5| Step: 1
Training loss: 2.9514046961541816
Validation loss: 2.592139918432667

Epoch: 5| Step: 2
Training loss: 3.199243044731853
Validation loss: 2.592437723518753

Epoch: 5| Step: 3
Training loss: 2.5635894692397367
Validation loss: 2.592049239877356

Epoch: 5| Step: 4
Training loss: 2.708144538363439
Validation loss: 2.5901722028246503

Epoch: 5| Step: 5
Training loss: 3.2862832838413785
Validation loss: 2.590928888084191

Epoch: 5| Step: 6
Training loss: 3.0193925951549856
Validation loss: 2.5889448273383913

Epoch: 5| Step: 7
Training loss: 2.9532727401350036
Validation loss: 2.5877146862030607

Epoch: 5| Step: 8
Training loss: 2.645864491517036
Validation loss: 2.5875733366593163

Epoch: 5| Step: 9
Training loss: 3.0959198403540666
Validation loss: 2.5875946317717284

Epoch: 5| Step: 10
Training loss: 3.16579256207376
Validation loss: 2.584995659502247

Epoch: 150| Step: 0
Training loss: 3.16796739533533
Validation loss: 2.5815842228338712

Epoch: 5| Step: 1
Training loss: 2.7821792593162
Validation loss: 2.5816467464523782

Epoch: 5| Step: 2
Training loss: 3.0704591051194505
Validation loss: 2.5849813992499175

Epoch: 5| Step: 3
Training loss: 2.4721843154610896
Validation loss: 2.579574171702792

Epoch: 5| Step: 4
Training loss: 3.496630136270562
Validation loss: 2.5831481117617603

Epoch: 5| Step: 5
Training loss: 2.687679373499355
Validation loss: 2.5879766339810653

Epoch: 5| Step: 6
Training loss: 2.921674752130834
Validation loss: 2.591154003001605

Epoch: 5| Step: 7
Training loss: 2.3014255003804207
Validation loss: 2.607836866289834

Epoch: 5| Step: 8
Training loss: 2.814340116626493
Validation loss: 2.619089289835658

Epoch: 5| Step: 9
Training loss: 2.796976183547473
Validation loss: 2.6649601235196334

Epoch: 5| Step: 10
Training loss: 3.658708186195756
Validation loss: 2.675773468377523

Epoch: 151| Step: 0
Training loss: 2.4195647018430875
Validation loss: 2.6698679452083263

Epoch: 5| Step: 1
Training loss: 3.2891115017319184
Validation loss: 2.6669832872908574

Epoch: 5| Step: 2
Training loss: 3.640500046055095
Validation loss: 2.669696074117441

Epoch: 5| Step: 3
Training loss: 2.701335866146777
Validation loss: 2.604570341919898

Epoch: 5| Step: 4
Training loss: 2.943106313254444
Validation loss: 2.5811446110985092

Epoch: 5| Step: 5
Training loss: 3.3403071567215368
Validation loss: 2.5869924774286965

Epoch: 5| Step: 6
Training loss: 2.6683014289462412
Validation loss: 2.588647686025636

Epoch: 5| Step: 7
Training loss: 2.9321950531802994
Validation loss: 2.5900849434027

Epoch: 5| Step: 8
Training loss: 2.7771990130733037
Validation loss: 2.5938703813229074

Epoch: 5| Step: 9
Training loss: 2.6944273448895273
Validation loss: 2.6001012811977797

Epoch: 5| Step: 10
Training loss: 2.714043939908023
Validation loss: 2.600424273189743

Epoch: 152| Step: 0
Training loss: 3.3757420889611933
Validation loss: 2.6051853423862217

Epoch: 5| Step: 1
Training loss: 2.9821599759148136
Validation loss: 2.602794823056462

Epoch: 5| Step: 2
Training loss: 3.023104390564441
Validation loss: 2.60577373574049

Epoch: 5| Step: 3
Training loss: 3.1764913705798357
Validation loss: 2.592745595738143

Epoch: 5| Step: 4
Training loss: 2.8990214702946737
Validation loss: 2.5895997998215643

Epoch: 5| Step: 5
Training loss: 2.854690132494852
Validation loss: 2.5923297649323125

Epoch: 5| Step: 6
Training loss: 3.317980281557398
Validation loss: 2.587264613138911

Epoch: 5| Step: 7
Training loss: 2.7577718672312064
Validation loss: 2.5871744335586744

Epoch: 5| Step: 8
Training loss: 3.026277061319349
Validation loss: 2.5868394507599275

Epoch: 5| Step: 9
Training loss: 2.9374964287918783
Validation loss: 2.586438385693144

Epoch: 5| Step: 10
Training loss: 1.9349178828082239
Validation loss: 2.586489787079467

Epoch: 153| Step: 0
Training loss: 3.2884126505990876
Validation loss: 2.5852471334008746

Epoch: 5| Step: 1
Training loss: 2.8751719879454365
Validation loss: 2.586229536425125

Epoch: 5| Step: 2
Training loss: 3.326049300671968
Validation loss: 2.5841062261557917

Epoch: 5| Step: 3
Training loss: 2.907056142920329
Validation loss: 2.5866014880801314

Epoch: 5| Step: 4
Training loss: 2.6473716008765074
Validation loss: 2.5843559712710595

Epoch: 5| Step: 5
Training loss: 2.933207845893624
Validation loss: 2.5799623864769097

Epoch: 5| Step: 6
Training loss: 2.9940673659905923
Validation loss: 2.581825581142772

Epoch: 5| Step: 7
Training loss: 2.546071774252402
Validation loss: 2.591553247166835

Epoch: 5| Step: 8
Training loss: 2.9677877372454935
Validation loss: 2.602816638282219

Epoch: 5| Step: 9
Training loss: 2.792768820696058
Validation loss: 2.6045083528544977

Epoch: 5| Step: 10
Training loss: 3.222841791533807
Validation loss: 2.5785925417925064

Epoch: 154| Step: 0
Training loss: 2.922685480162823
Validation loss: 2.577329918852629

Epoch: 5| Step: 1
Training loss: 2.8502453413986224
Validation loss: 2.5772290942514187

Epoch: 5| Step: 2
Training loss: 3.391871069545096
Validation loss: 2.5778635886254504

Epoch: 5| Step: 3
Training loss: 2.835388634903071
Validation loss: 2.5754709951380086

Epoch: 5| Step: 4
Training loss: 2.816434693424333
Validation loss: 2.5758747182989596

Epoch: 5| Step: 5
Training loss: 2.6208465959934064
Validation loss: 2.5747575282735826

Epoch: 5| Step: 6
Training loss: 2.6858124868649353
Validation loss: 2.576169192112721

Epoch: 5| Step: 7
Training loss: 2.634816841549557
Validation loss: 2.5733330485896193

Epoch: 5| Step: 8
Training loss: 3.737480117591869
Validation loss: 2.5861625775427237

Epoch: 5| Step: 9
Training loss: 2.877089528918012
Validation loss: 2.6177968167662367

Epoch: 5| Step: 10
Training loss: 2.629062052810252
Validation loss: 2.7220243821639443

Epoch: 155| Step: 0
Training loss: 2.781282231862039
Validation loss: 2.7564739325420717

Epoch: 5| Step: 1
Training loss: 3.069883204919318
Validation loss: 2.757456247082283

Epoch: 5| Step: 2
Training loss: 3.31271692681322
Validation loss: 2.6881875324623374

Epoch: 5| Step: 3
Training loss: 2.6887039326756392
Validation loss: 2.6036630585717364

Epoch: 5| Step: 4
Training loss: 2.63867711561517
Validation loss: 2.5660271809084136

Epoch: 5| Step: 5
Training loss: 2.346037295358055
Validation loss: 2.5596083466050685

Epoch: 5| Step: 6
Training loss: 3.0502685428653247
Validation loss: 2.5708813793756993

Epoch: 5| Step: 7
Training loss: 3.256881324646262
Validation loss: 2.577559343509062

Epoch: 5| Step: 8
Training loss: 3.0799874030512044
Validation loss: 2.583020675294975

Epoch: 5| Step: 9
Training loss: 2.991123578037898
Validation loss: 2.594153602017769

Epoch: 5| Step: 10
Training loss: 3.2927503773604556
Validation loss: 2.6032152405952753

Epoch: 156| Step: 0
Training loss: 3.04848934346533
Validation loss: 2.617290124425455

Epoch: 5| Step: 1
Training loss: 2.784221561883673
Validation loss: 2.6292229498379975

Epoch: 5| Step: 2
Training loss: 2.664537404260791
Validation loss: 2.5935624103338446

Epoch: 5| Step: 3
Training loss: 2.3189386995347046
Validation loss: 2.5828124320680197

Epoch: 5| Step: 4
Training loss: 3.034122168146463
Validation loss: 2.5769010987941083

Epoch: 5| Step: 5
Training loss: 2.6141554848412865
Validation loss: 2.5744782003253053

Epoch: 5| Step: 6
Training loss: 3.6022851843655452
Validation loss: 2.5704801507078976

Epoch: 5| Step: 7
Training loss: 2.7322738858244433
Validation loss: 2.5650374667099824

Epoch: 5| Step: 8
Training loss: 3.0094927961799125
Validation loss: 2.5618138268732755

Epoch: 5| Step: 9
Training loss: 3.3679528307024174
Validation loss: 2.560049412404943

Epoch: 5| Step: 10
Training loss: 3.0681125825718873
Validation loss: 2.572675581981881

Epoch: 157| Step: 0
Training loss: 2.9131265318366664
Validation loss: 2.597207863199342

Epoch: 5| Step: 1
Training loss: 3.2265574753101007
Validation loss: 2.6551772922394656

Epoch: 5| Step: 2
Training loss: 3.429800531353899
Validation loss: 2.649361208332146

Epoch: 5| Step: 3
Training loss: 2.7371263013806053
Validation loss: 2.590194208984585

Epoch: 5| Step: 4
Training loss: 2.4180932821765526
Validation loss: 2.5675026367907576

Epoch: 5| Step: 5
Training loss: 2.9510178895031256
Validation loss: 2.565671089670373

Epoch: 5| Step: 6
Training loss: 3.120757007217272
Validation loss: 2.556044932756641

Epoch: 5| Step: 7
Training loss: 2.5701029497893404
Validation loss: 2.555083807412852

Epoch: 5| Step: 8
Training loss: 3.295060367986346
Validation loss: 2.5537935561739777

Epoch: 5| Step: 9
Training loss: 2.8624211329627305
Validation loss: 2.5533790163892625

Epoch: 5| Step: 10
Training loss: 2.427171097070486
Validation loss: 2.5514653517225216

Epoch: 158| Step: 0
Training loss: 2.9577061879377133
Validation loss: 2.551198300027024

Epoch: 5| Step: 1
Training loss: 2.8728181604026486
Validation loss: 2.556052922917901

Epoch: 5| Step: 2
Training loss: 2.5747130965608673
Validation loss: 2.5571313840424748

Epoch: 5| Step: 3
Training loss: 3.0693081288014024
Validation loss: 2.553569158429501

Epoch: 5| Step: 4
Training loss: 2.8938854078740315
Validation loss: 2.5574560668730464

Epoch: 5| Step: 5
Training loss: 2.4543764846132827
Validation loss: 2.5555849832312068

Epoch: 5| Step: 6
Training loss: 3.3917708328584633
Validation loss: 2.552958832060965

Epoch: 5| Step: 7
Training loss: 2.810012480277044
Validation loss: 2.564811085561299

Epoch: 5| Step: 8
Training loss: 3.334166009533115
Validation loss: 2.55849292452826

Epoch: 5| Step: 9
Training loss: 2.800568512694023
Validation loss: 2.5661677931534075

Epoch: 5| Step: 10
Training loss: 2.702740592304328
Validation loss: 2.5709083620239386

Epoch: 159| Step: 0
Training loss: 2.543932379105799
Validation loss: 2.5721836624406813

Epoch: 5| Step: 1
Training loss: 3.112638668050668
Validation loss: 2.5775179280305194

Epoch: 5| Step: 2
Training loss: 3.1874190675521197
Validation loss: 2.5672307869059745

Epoch: 5| Step: 3
Training loss: 3.2896258308962443
Validation loss: 2.5784867128337754

Epoch: 5| Step: 4
Training loss: 2.5785719975303683
Validation loss: 2.5594994369903756

Epoch: 5| Step: 5
Training loss: 2.4704012599684906
Validation loss: 2.5570525456544053

Epoch: 5| Step: 6
Training loss: 2.8224964931793997
Validation loss: 2.5474445726053303

Epoch: 5| Step: 7
Training loss: 2.792655703200348
Validation loss: 2.546851707566891

Epoch: 5| Step: 8
Training loss: 3.3193222903054993
Validation loss: 2.5491724905880586

Epoch: 5| Step: 9
Training loss: 3.0585655318282448
Validation loss: 2.5514158034281387

Epoch: 5| Step: 10
Training loss: 2.6740570081855255
Validation loss: 2.553386482262434

Epoch: 160| Step: 0
Training loss: 2.5565178057003703
Validation loss: 2.5537548828359404

Epoch: 5| Step: 1
Training loss: 3.3609176996943337
Validation loss: 2.5505314337338354

Epoch: 5| Step: 2
Training loss: 2.6067755994775412
Validation loss: 2.5514582133107218

Epoch: 5| Step: 3
Training loss: 2.9218544372814215
Validation loss: 2.550505278857196

Epoch: 5| Step: 4
Training loss: 2.4755242996517937
Validation loss: 2.556344573538528

Epoch: 5| Step: 5
Training loss: 3.249387536660304
Validation loss: 2.5681149173033995

Epoch: 5| Step: 6
Training loss: 3.00803412079228
Validation loss: 2.566890848421777

Epoch: 5| Step: 7
Training loss: 3.0863693514582153
Validation loss: 2.576755223187224

Epoch: 5| Step: 8
Training loss: 3.187237597865748
Validation loss: 2.6052212777884085

Epoch: 5| Step: 9
Training loss: 2.687675470345876
Validation loss: 2.6070149785883316

Epoch: 5| Step: 10
Training loss: 2.58386368588616
Validation loss: 2.6545014737524215

Epoch: 161| Step: 0
Training loss: 3.1118644831553057
Validation loss: 2.6215586745337895

Epoch: 5| Step: 1
Training loss: 3.13041035555095
Validation loss: 2.616238230677755

Epoch: 5| Step: 2
Training loss: 2.553153507815904
Validation loss: 2.5937527931930737

Epoch: 5| Step: 3
Training loss: 3.359509700469887
Validation loss: 2.5805105658138117

Epoch: 5| Step: 4
Training loss: 3.1726790287615696
Validation loss: 2.5783380752868696

Epoch: 5| Step: 5
Training loss: 2.8169911447859124
Validation loss: 2.5762687108313798

Epoch: 5| Step: 6
Training loss: 2.703705212719911
Validation loss: 2.562905282286188

Epoch: 5| Step: 7
Training loss: 2.8942389913393916
Validation loss: 2.5554067660299746

Epoch: 5| Step: 8
Training loss: 2.7487077277638043
Validation loss: 2.5554280508037905

Epoch: 5| Step: 9
Training loss: 2.594686959409146
Validation loss: 2.5490938958264358

Epoch: 5| Step: 10
Training loss: 2.5475436777969485
Validation loss: 2.547538601920778

Epoch: 162| Step: 0
Training loss: 2.8339049566749406
Validation loss: 2.5427423776548452

Epoch: 5| Step: 1
Training loss: 2.492200032265463
Validation loss: 2.5435147908419835

Epoch: 5| Step: 2
Training loss: 3.074809811300755
Validation loss: 2.5424222732465793

Epoch: 5| Step: 3
Training loss: 3.077710118871767
Validation loss: 2.5429472979317516

Epoch: 5| Step: 4
Training loss: 3.258047850087078
Validation loss: 2.542811758292336

Epoch: 5| Step: 5
Training loss: 3.3659121760098447
Validation loss: 2.542886775690545

Epoch: 5| Step: 6
Training loss: 3.09820174697217
Validation loss: 2.5435313386974117

Epoch: 5| Step: 7
Training loss: 2.813005359599801
Validation loss: 2.5477380609486375

Epoch: 5| Step: 8
Training loss: 2.248219951525974
Validation loss: 2.5495405201806864

Epoch: 5| Step: 9
Training loss: 2.66790699922247
Validation loss: 2.557847065307141

Epoch: 5| Step: 10
Training loss: 2.6752712682633075
Validation loss: 2.5562855328301826

Epoch: 163| Step: 0
Training loss: 2.8208129100726995
Validation loss: 2.58689541174875

Epoch: 5| Step: 1
Training loss: 2.6689517442979582
Validation loss: 2.625605654443268

Epoch: 5| Step: 2
Training loss: 3.0309544055395277
Validation loss: 2.698548920424978

Epoch: 5| Step: 3
Training loss: 2.7233321939354718
Validation loss: 2.735792527065217

Epoch: 5| Step: 4
Training loss: 2.6731165628074867
Validation loss: 2.7344268034497374

Epoch: 5| Step: 5
Training loss: 3.298590769565615
Validation loss: 2.683955731287873

Epoch: 5| Step: 6
Training loss: 2.520816634782282
Validation loss: 2.617250181992418

Epoch: 5| Step: 7
Training loss: 3.073484999692525
Validation loss: 2.5735388641962835

Epoch: 5| Step: 8
Training loss: 3.001717393761731
Validation loss: 2.5539233925947356

Epoch: 5| Step: 9
Training loss: 3.1487927863472596
Validation loss: 2.546416533738656

Epoch: 5| Step: 10
Training loss: 2.9647900321426444
Validation loss: 2.5416331989163354

Epoch: 164| Step: 0
Training loss: 2.572325408171307
Validation loss: 2.5455719229967397

Epoch: 5| Step: 1
Training loss: 3.0730353553394103
Validation loss: 2.5501832848312236

Epoch: 5| Step: 2
Training loss: 2.425284072125443
Validation loss: 2.54946633508665

Epoch: 5| Step: 3
Training loss: 2.952442877569776
Validation loss: 2.5509946500464724

Epoch: 5| Step: 4
Training loss: 3.64802800561796
Validation loss: 2.554005745422794

Epoch: 5| Step: 5
Training loss: 2.4089296951137817
Validation loss: 2.5553258839780932

Epoch: 5| Step: 6
Training loss: 3.028181902623417
Validation loss: 2.5557584825420183

Epoch: 5| Step: 7
Training loss: 3.0409820691990985
Validation loss: 2.5563686248752546

Epoch: 5| Step: 8
Training loss: 2.4908395787255753
Validation loss: 2.5470046254442416

Epoch: 5| Step: 9
Training loss: 3.496655228350331
Validation loss: 2.5446836963429336

Epoch: 5| Step: 10
Training loss: 2.7696970471683833
Validation loss: 2.549810627551529

Epoch: 165| Step: 0
Training loss: 2.8139951334615025
Validation loss: 2.5520534457544604

Epoch: 5| Step: 1
Training loss: 3.041585389884683
Validation loss: 2.574051514593392

Epoch: 5| Step: 2
Training loss: 2.6406397170158953
Validation loss: 2.589316604784004

Epoch: 5| Step: 3
Training loss: 2.7093107856083836
Validation loss: 2.6129305673971754

Epoch: 5| Step: 4
Training loss: 3.311190076251941
Validation loss: 2.6229963786351513

Epoch: 5| Step: 5
Training loss: 2.63102448645535
Validation loss: 2.6063769942874155

Epoch: 5| Step: 6
Training loss: 3.1582843531800604
Validation loss: 2.5528462886612426

Epoch: 5| Step: 7
Training loss: 2.9243705006919667
Validation loss: 2.545346939425106

Epoch: 5| Step: 8
Training loss: 2.946544925654684
Validation loss: 2.5367492062936385

Epoch: 5| Step: 9
Training loss: 2.406971513650129
Validation loss: 2.5401182785607204

Epoch: 5| Step: 10
Training loss: 3.1967116745799125
Validation loss: 2.5378244612366174

Epoch: 166| Step: 0
Training loss: 2.8529868553118205
Validation loss: 2.5400916581705224

Epoch: 5| Step: 1
Training loss: 2.8565402962306092
Validation loss: 2.5376966535113534

Epoch: 5| Step: 2
Training loss: 3.0693606388701395
Validation loss: 2.538190984469451

Epoch: 5| Step: 3
Training loss: 2.792142305611438
Validation loss: 2.534196170871274

Epoch: 5| Step: 4
Training loss: 2.7997374990575725
Validation loss: 2.539899407998832

Epoch: 5| Step: 5
Training loss: 3.0376509891862975
Validation loss: 2.5402469438841875

Epoch: 5| Step: 6
Training loss: 2.778037541217508
Validation loss: 2.540867405628334

Epoch: 5| Step: 7
Training loss: 2.362191546452177
Validation loss: 2.5601035636897396

Epoch: 5| Step: 8
Training loss: 3.1738781546537633
Validation loss: 2.584025047917904

Epoch: 5| Step: 9
Training loss: 3.007695500463892
Validation loss: 2.596681230612592

Epoch: 5| Step: 10
Training loss: 3.0204445073486546
Validation loss: 2.6211107587643765

Epoch: 167| Step: 0
Training loss: 2.469514945584919
Validation loss: 2.6488112609614767

Epoch: 5| Step: 1
Training loss: 3.5081353325745166
Validation loss: 2.6793712710524895

Epoch: 5| Step: 2
Training loss: 3.3871632144640533
Validation loss: 2.6816654463935863

Epoch: 5| Step: 3
Training loss: 3.0082852078830182
Validation loss: 2.620657859575438

Epoch: 5| Step: 4
Training loss: 2.912230214733787
Validation loss: 2.568389592202925

Epoch: 5| Step: 5
Training loss: 2.945839103754229
Validation loss: 2.536876697448008

Epoch: 5| Step: 6
Training loss: 2.446632979349054
Validation loss: 2.5315847354026966

Epoch: 5| Step: 7
Training loss: 2.459130777450241
Validation loss: 2.542251538448669

Epoch: 5| Step: 8
Training loss: 2.9212771533361916
Validation loss: 2.5799258508255347

Epoch: 5| Step: 9
Training loss: 2.6294077243314558
Validation loss: 2.5990719134276343

Epoch: 5| Step: 10
Training loss: 3.4191645508648913
Validation loss: 2.5632445011449487

Epoch: 168| Step: 0
Training loss: 2.889371528004535
Validation loss: 2.5546915511448227

Epoch: 5| Step: 1
Training loss: 3.1205135947323908
Validation loss: 2.543642775389181

Epoch: 5| Step: 2
Training loss: 2.8583225335305453
Validation loss: 2.544415707179701

Epoch: 5| Step: 3
Training loss: 2.855471087870965
Validation loss: 2.5405118051095097

Epoch: 5| Step: 4
Training loss: 2.9077108669814327
Validation loss: 2.5313298638051713

Epoch: 5| Step: 5
Training loss: 2.970843410251928
Validation loss: 2.528749921400678

Epoch: 5| Step: 6
Training loss: 3.254077407713379
Validation loss: 2.5215858923312626

Epoch: 5| Step: 7
Training loss: 2.921256912869659
Validation loss: 2.524879467472372

Epoch: 5| Step: 8
Training loss: 2.412276215130833
Validation loss: 2.5486115404428777

Epoch: 5| Step: 9
Training loss: 3.0298066783205173
Validation loss: 2.5946389493730417

Epoch: 5| Step: 10
Training loss: 2.5585020558474034
Validation loss: 2.6419200378077226

Epoch: 169| Step: 0
Training loss: 2.7110833999992896
Validation loss: 2.7141164224857923

Epoch: 5| Step: 1
Training loss: 2.8542678332440357
Validation loss: 2.7351405643324624

Epoch: 5| Step: 2
Training loss: 2.815565007424825
Validation loss: 2.712769734170045

Epoch: 5| Step: 3
Training loss: 2.824769785455146
Validation loss: 2.638542169858367

Epoch: 5| Step: 4
Training loss: 2.7317512349073305
Validation loss: 2.609953833486697

Epoch: 5| Step: 5
Training loss: 3.0429508859993932
Validation loss: 2.606543003508322

Epoch: 5| Step: 6
Training loss: 3.374277532038557
Validation loss: 2.5522440024540223

Epoch: 5| Step: 7
Training loss: 2.691221543660835
Validation loss: 2.527518361258422

Epoch: 5| Step: 8
Training loss: 3.2929279148379997
Validation loss: 2.526953627835888

Epoch: 5| Step: 9
Training loss: 2.6843544049966197
Validation loss: 2.534939138499777

Epoch: 5| Step: 10
Training loss: 2.865373167331181
Validation loss: 2.536812430709508

Epoch: 170| Step: 0
Training loss: 2.8756679919883803
Validation loss: 2.538357681880396

Epoch: 5| Step: 1
Training loss: 3.2830347929129613
Validation loss: 2.5427605829963085

Epoch: 5| Step: 2
Training loss: 2.5944989513395833
Validation loss: 2.5426563136344718

Epoch: 5| Step: 3
Training loss: 3.154468902526515
Validation loss: 2.536605890974971

Epoch: 5| Step: 4
Training loss: 2.4184521513900648
Validation loss: 2.53052604285302

Epoch: 5| Step: 5
Training loss: 2.5446308757146165
Validation loss: 2.5305084262383604

Epoch: 5| Step: 6
Training loss: 2.8967732795378436
Validation loss: 2.53894333275008

Epoch: 5| Step: 7
Training loss: 2.90608657869666
Validation loss: 2.5505906176884157

Epoch: 5| Step: 8
Training loss: 3.1569497116573766
Validation loss: 2.5663439984002174

Epoch: 5| Step: 9
Training loss: 2.6190833669344853
Validation loss: 2.6042539605717367

Epoch: 5| Step: 10
Training loss: 3.3471632319555287
Validation loss: 2.6490757106350036

Epoch: 171| Step: 0
Training loss: 3.558346384874718
Validation loss: 2.658677594793005

Epoch: 5| Step: 1
Training loss: 2.970336650688001
Validation loss: 2.6207899601593247

Epoch: 5| Step: 2
Training loss: 3.3029389501341058
Validation loss: 2.5815341945069976

Epoch: 5| Step: 3
Training loss: 2.8674863404910638
Validation loss: 2.5537493359403434

Epoch: 5| Step: 4
Training loss: 3.1593048118092213
Validation loss: 2.5247559469178302

Epoch: 5| Step: 5
Training loss: 2.858358567314608
Validation loss: 2.517984580821074

Epoch: 5| Step: 6
Training loss: 2.3741890376027754
Validation loss: 2.518652368524762

Epoch: 5| Step: 7
Training loss: 2.485274050240207
Validation loss: 2.5168711977342895

Epoch: 5| Step: 8
Training loss: 2.386754811415633
Validation loss: 2.5177045351728746

Epoch: 5| Step: 9
Training loss: 2.393459858255119
Validation loss: 2.5177371177911825

Epoch: 5| Step: 10
Training loss: 3.2047531827968414
Validation loss: 2.518281980991177

Epoch: 172| Step: 0
Training loss: 3.004417981038117
Validation loss: 2.5213984902813156

Epoch: 5| Step: 1
Training loss: 2.949114462922299
Validation loss: 2.526786830453965

Epoch: 5| Step: 2
Training loss: 2.90948470387205
Validation loss: 2.529608333528286

Epoch: 5| Step: 3
Training loss: 2.9840306587689653
Validation loss: 2.553033292229385

Epoch: 5| Step: 4
Training loss: 2.1712402953181917
Validation loss: 2.589008126765434

Epoch: 5| Step: 5
Training loss: 2.503654669681322
Validation loss: 2.635795236952667

Epoch: 5| Step: 6
Training loss: 3.0070354300093545
Validation loss: 2.6034352833785284

Epoch: 5| Step: 7
Training loss: 3.0335937562874227
Validation loss: 2.5754394186586267

Epoch: 5| Step: 8
Training loss: 3.3385824041316168
Validation loss: 2.543554164643401

Epoch: 5| Step: 9
Training loss: 2.6780330789074305
Validation loss: 2.557484743893569

Epoch: 5| Step: 10
Training loss: 2.7868274099662957
Validation loss: 2.5261161026148473

Epoch: 173| Step: 0
Training loss: 2.694304435299709
Validation loss: 2.5159195131590075

Epoch: 5| Step: 1
Training loss: 3.321211103126135
Validation loss: 2.519077471230709

Epoch: 5| Step: 2
Training loss: 2.956603247282398
Validation loss: 2.5247443459305794

Epoch: 5| Step: 3
Training loss: 2.58223096851342
Validation loss: 2.5330386216115164

Epoch: 5| Step: 4
Training loss: 2.657900039693404
Validation loss: 2.535995745104826

Epoch: 5| Step: 5
Training loss: 3.3488790088393348
Validation loss: 2.5352832893756507

Epoch: 5| Step: 6
Training loss: 2.606575657832257
Validation loss: 2.5337108710700504

Epoch: 5| Step: 7
Training loss: 2.932765635551414
Validation loss: 2.545023880779287

Epoch: 5| Step: 8
Training loss: 2.3791316384466543
Validation loss: 2.5340316742829794

Epoch: 5| Step: 9
Training loss: 3.220025263622051
Validation loss: 2.5367574436869296

Epoch: 5| Step: 10
Training loss: 3.275699534944758
Validation loss: 2.533819970452408

Epoch: 174| Step: 0
Training loss: 3.1007392617110217
Validation loss: 2.5323257727728556

Epoch: 5| Step: 1
Training loss: 2.3827447600194502
Validation loss: 2.531170868988164

Epoch: 5| Step: 2
Training loss: 2.6395032859011485
Validation loss: 2.526526109178411

Epoch: 5| Step: 3
Training loss: 2.9263108796537463
Validation loss: 2.516733740363895

Epoch: 5| Step: 4
Training loss: 3.185141345230871
Validation loss: 2.518013239037058

Epoch: 5| Step: 5
Training loss: 2.8725300005615217
Validation loss: 2.5323787599636445

Epoch: 5| Step: 6
Training loss: 2.928780295735909
Validation loss: 2.573323064317935

Epoch: 5| Step: 7
Training loss: 2.9982374099674494
Validation loss: 2.645041423713375

Epoch: 5| Step: 8
Training loss: 2.8748187132360483
Validation loss: 2.7309120688345896

Epoch: 5| Step: 9
Training loss: 3.587505986544303
Validation loss: 2.7157934150143053

Epoch: 5| Step: 10
Training loss: 2.302223362410978
Validation loss: 2.6171718870605485

Epoch: 175| Step: 0
Training loss: 3.044720009895765
Validation loss: 2.5669731517555325

Epoch: 5| Step: 1
Training loss: 2.8906462797464196
Validation loss: 2.5457272168145653

Epoch: 5| Step: 2
Training loss: 2.707381408855719
Validation loss: 2.5355526476938013

Epoch: 5| Step: 3
Training loss: 2.5365866459553406
Validation loss: 2.527301335125077

Epoch: 5| Step: 4
Training loss: 3.028728891787968
Validation loss: 2.520369847550541

Epoch: 5| Step: 5
Training loss: 2.7572000920435022
Validation loss: 2.5190656670135936

Epoch: 5| Step: 6
Training loss: 3.01257707805877
Validation loss: 2.5162150697877754

Epoch: 5| Step: 7
Training loss: 2.4447390337884447
Validation loss: 2.514293359221931

Epoch: 5| Step: 8
Training loss: 3.4265621604519185
Validation loss: 2.509472535968532

Epoch: 5| Step: 9
Training loss: 2.4065716020753523
Validation loss: 2.517036200632756

Epoch: 5| Step: 10
Training loss: 3.002799317546059
Validation loss: 2.519637517205558

Epoch: 176| Step: 0
Training loss: 2.44475395478033
Validation loss: 2.526573499827773

Epoch: 5| Step: 1
Training loss: 3.143092007345344
Validation loss: 2.5407698471444378

Epoch: 5| Step: 2
Training loss: 2.6230439663982383
Validation loss: 2.561339827289243

Epoch: 5| Step: 3
Training loss: 2.9245808358097314
Validation loss: 2.580676738932926

Epoch: 5| Step: 4
Training loss: 2.6956346402260127
Validation loss: 2.5999378670997983

Epoch: 5| Step: 5
Training loss: 3.2716228398869154
Validation loss: 2.589685227862554

Epoch: 5| Step: 6
Training loss: 2.821852160727843
Validation loss: 2.5726590412225234

Epoch: 5| Step: 7
Training loss: 2.9177259065824503
Validation loss: 2.553345875520354

Epoch: 5| Step: 8
Training loss: 2.6879130201345047
Validation loss: 2.5470546234041027

Epoch: 5| Step: 9
Training loss: 2.6263109294318103
Validation loss: 2.5385647748937523

Epoch: 5| Step: 10
Training loss: 3.2500176062473827
Validation loss: 2.5347383355256765

Epoch: 177| Step: 0
Training loss: 2.8627709406265973
Validation loss: 2.5381920146964645

Epoch: 5| Step: 1
Training loss: 2.69871867470453
Validation loss: 2.5336149595364477

Epoch: 5| Step: 2
Training loss: 2.4586815560476865
Validation loss: 2.533986687307793

Epoch: 5| Step: 3
Training loss: 2.8584316344267195
Validation loss: 2.535041264831234

Epoch: 5| Step: 4
Training loss: 2.478644136985481
Validation loss: 2.545434768654799

Epoch: 5| Step: 5
Training loss: 2.3723408720236074
Validation loss: 2.5657593622370287

Epoch: 5| Step: 6
Training loss: 3.361021268360203
Validation loss: 2.5815762506210658

Epoch: 5| Step: 7
Training loss: 3.157227921773215
Validation loss: 2.6098599527607664

Epoch: 5| Step: 8
Training loss: 2.710359275341227
Validation loss: 2.6142119162759623

Epoch: 5| Step: 9
Training loss: 3.5719237583733956
Validation loss: 2.598328799077285

Epoch: 5| Step: 10
Training loss: 2.644070786658258
Validation loss: 2.5832025310918927

Epoch: 178| Step: 0
Training loss: 2.58057171867062
Validation loss: 2.549534093827459

Epoch: 5| Step: 1
Training loss: 3.02490845218562
Validation loss: 2.5419355223698226

Epoch: 5| Step: 2
Training loss: 2.2198506164122374
Validation loss: 2.5273528944539425

Epoch: 5| Step: 3
Training loss: 2.8129654393247874
Validation loss: 2.526189092950265

Epoch: 5| Step: 4
Training loss: 3.2590920842128575
Validation loss: 2.528942022668986

Epoch: 5| Step: 5
Training loss: 2.4732083010195347
Validation loss: 2.5300475423981865

Epoch: 5| Step: 6
Training loss: 2.8170957528152614
Validation loss: 2.529802479462087

Epoch: 5| Step: 7
Training loss: 3.217817152823309
Validation loss: 2.5284896418270963

Epoch: 5| Step: 8
Training loss: 2.6477141616264483
Validation loss: 2.526617824323062

Epoch: 5| Step: 9
Training loss: 3.099237988246157
Validation loss: 2.533159958126299

Epoch: 5| Step: 10
Training loss: 2.983601255125249
Validation loss: 2.544657704513592

Epoch: 179| Step: 0
Training loss: 2.6856728486079158
Validation loss: 2.540873430137938

Epoch: 5| Step: 1
Training loss: 2.9214220970953466
Validation loss: 2.5539939385219164

Epoch: 5| Step: 2
Training loss: 2.6236365274042224
Validation loss: 2.5630693681013135

Epoch: 5| Step: 3
Training loss: 2.910780462102831
Validation loss: 2.5761934663690833

Epoch: 5| Step: 4
Training loss: 2.0329080710203615
Validation loss: 2.5728121271243993

Epoch: 5| Step: 5
Training loss: 2.796695383793642
Validation loss: 2.5840212560654585

Epoch: 5| Step: 6
Training loss: 3.6976723746974374
Validation loss: 2.5921981761359723

Epoch: 5| Step: 7
Training loss: 2.4077700483081403
Validation loss: 2.6042795431633774

Epoch: 5| Step: 8
Training loss: 2.9007896071852244
Validation loss: 2.6249381154271547

Epoch: 5| Step: 9
Training loss: 3.061494467566284
Validation loss: 2.6369818078809453

Epoch: 5| Step: 10
Training loss: 2.9690073002191966
Validation loss: 2.664519367083461

Epoch: 180| Step: 0
Training loss: 2.7334542604383727
Validation loss: 2.6397021251847437

Epoch: 5| Step: 1
Training loss: 2.940310979731861
Validation loss: 2.603619487415088

Epoch: 5| Step: 2
Training loss: 3.1678933394519526
Validation loss: 2.5848131274884563

Epoch: 5| Step: 3
Training loss: 2.2025637080735163
Validation loss: 2.561325161084712

Epoch: 5| Step: 4
Training loss: 2.699718291103418
Validation loss: 2.560973887749469

Epoch: 5| Step: 5
Training loss: 2.8371888649713783
Validation loss: 2.5482345204767376

Epoch: 5| Step: 6
Training loss: 3.37518620860376
Validation loss: 2.532013063457577

Epoch: 5| Step: 7
Training loss: 2.898688868395799
Validation loss: 2.5347128328838813

Epoch: 5| Step: 8
Training loss: 2.810482827650406
Validation loss: 2.5334881704314975

Epoch: 5| Step: 9
Training loss: 2.5393541373978596
Validation loss: 2.5356660840253644

Epoch: 5| Step: 10
Training loss: 2.812475077200772
Validation loss: 2.5348074305670774

Epoch: 181| Step: 0
Training loss: 1.856952660116914
Validation loss: 2.5424104070063724

Epoch: 5| Step: 1
Training loss: 2.607315987140668
Validation loss: 2.546785545426432

Epoch: 5| Step: 2
Training loss: 2.9710957144229964
Validation loss: 2.548685084533094

Epoch: 5| Step: 3
Training loss: 2.7935046128753327
Validation loss: 2.5622369154472553

Epoch: 5| Step: 4
Training loss: 3.0359220385587213
Validation loss: 2.5679500836858

Epoch: 5| Step: 5
Training loss: 2.516969309750436
Validation loss: 2.5693962697578625

Epoch: 5| Step: 6
Training loss: 2.480126545046313
Validation loss: 2.580744900077087

Epoch: 5| Step: 7
Training loss: 3.1587671496971503
Validation loss: 2.5703219409126787

Epoch: 5| Step: 8
Training loss: 3.320849996706048
Validation loss: 2.5746496348688384

Epoch: 5| Step: 9
Training loss: 3.073456452800453
Validation loss: 2.568951798111789

Epoch: 5| Step: 10
Training loss: 3.0470127172401886
Validation loss: 2.57121643714353

Epoch: 182| Step: 0
Training loss: 2.623447685835367
Validation loss: 2.564890452097355

Epoch: 5| Step: 1
Training loss: 3.276277098006944
Validation loss: 2.561318326902985

Epoch: 5| Step: 2
Training loss: 3.1815799264755626
Validation loss: 2.5526161141661263

Epoch: 5| Step: 3
Training loss: 2.860032636549609
Validation loss: 2.5415887731608717

Epoch: 5| Step: 4
Training loss: 3.143141464278268
Validation loss: 2.533794803583966

Epoch: 5| Step: 5
Training loss: 1.7799317015714144
Validation loss: 2.5351850943244827

Epoch: 5| Step: 6
Training loss: 2.791956236515435
Validation loss: 2.5266815183692604

Epoch: 5| Step: 7
Training loss: 3.070556630919163
Validation loss: 2.519326339164113

Epoch: 5| Step: 8
Training loss: 2.787744632814646
Validation loss: 2.524170680936668

Epoch: 5| Step: 9
Training loss: 2.6070063456350927
Validation loss: 2.5184788822153523

Epoch: 5| Step: 10
Training loss: 2.6021925704501685
Validation loss: 2.5201619256787886

Epoch: 183| Step: 0
Training loss: 2.8150713716067646
Validation loss: 2.517296833428922

Epoch: 5| Step: 1
Training loss: 2.4845937956426
Validation loss: 2.5213834066986407

Epoch: 5| Step: 2
Training loss: 3.269128991178218
Validation loss: 2.512775094711085

Epoch: 5| Step: 3
Training loss: 3.145261615733847
Validation loss: 2.5217382257289147

Epoch: 5| Step: 4
Training loss: 2.8635233819645367
Validation loss: 2.5249113878970415

Epoch: 5| Step: 5
Training loss: 2.612637975234271
Validation loss: 2.520009548877543

Epoch: 5| Step: 6
Training loss: 2.7746153143854495
Validation loss: 2.5200116791318607

Epoch: 5| Step: 7
Training loss: 2.517940237728347
Validation loss: 2.5263517733431646

Epoch: 5| Step: 8
Training loss: 2.835397548083208
Validation loss: 2.534819921016435

Epoch: 5| Step: 9
Training loss: 2.6357097136117797
Validation loss: 2.5395398873598443

Epoch: 5| Step: 10
Training loss: 2.9334003166295832
Validation loss: 2.5455801409039336

Epoch: 184| Step: 0
Training loss: 2.0058283520224505
Validation loss: 2.5520653023165485

Epoch: 5| Step: 1
Training loss: 3.4303903750156484
Validation loss: 2.556096463416763

Epoch: 5| Step: 2
Training loss: 2.7772306051693927
Validation loss: 2.5625573668822796

Epoch: 5| Step: 3
Training loss: 2.421406460631736
Validation loss: 2.5571360278291473

Epoch: 5| Step: 4
Training loss: 2.3790824336313325
Validation loss: 2.553330487681539

Epoch: 5| Step: 5
Training loss: 3.46547537533112
Validation loss: 2.53851671737602

Epoch: 5| Step: 6
Training loss: 3.0028950709386883
Validation loss: 2.533832188546051

Epoch: 5| Step: 7
Training loss: 3.0108253351213183
Validation loss: 2.523322924663752

Epoch: 5| Step: 8
Training loss: 2.7861810754232015
Validation loss: 2.514835403680784

Epoch: 5| Step: 9
Training loss: 2.4605811451440447
Validation loss: 2.5228235723469363

Epoch: 5| Step: 10
Training loss: 2.955471176561917
Validation loss: 2.514848652877738

Epoch: 185| Step: 0
Training loss: 2.8909270257649777
Validation loss: 2.525430429583006

Epoch: 5| Step: 1
Training loss: 2.5994762956932957
Validation loss: 2.5286286125375255

Epoch: 5| Step: 2
Training loss: 3.0169586237066963
Validation loss: 2.5266585805805057

Epoch: 5| Step: 3
Training loss: 2.739150580008952
Validation loss: 2.544492457587736

Epoch: 5| Step: 4
Training loss: 2.7490436451577445
Validation loss: 2.5622863460364025

Epoch: 5| Step: 5
Training loss: 3.1923686225881482
Validation loss: 2.555485359250001

Epoch: 5| Step: 6
Training loss: 3.1658011475008307
Validation loss: 2.5445347874053907

Epoch: 5| Step: 7
Training loss: 2.9410275320601706
Validation loss: 2.5544119338155555

Epoch: 5| Step: 8
Training loss: 2.213084011263889
Validation loss: 2.544432206858904

Epoch: 5| Step: 9
Training loss: 2.48277000549326
Validation loss: 2.535562558257647

Epoch: 5| Step: 10
Training loss: 2.7791343957799395
Validation loss: 2.549506712011622

Epoch: 186| Step: 0
Training loss: 2.523250230389109
Validation loss: 2.5229011447440155

Epoch: 5| Step: 1
Training loss: 2.6852482966122944
Validation loss: 2.514941573690719

Epoch: 5| Step: 2
Training loss: 2.9219944567409106
Validation loss: 2.5179220473962842

Epoch: 5| Step: 3
Training loss: 3.126806423694131
Validation loss: 2.516931571952415

Epoch: 5| Step: 4
Training loss: 2.0492273456307406
Validation loss: 2.51286158838468

Epoch: 5| Step: 5
Training loss: 2.357876535485223
Validation loss: 2.511629217110486

Epoch: 5| Step: 6
Training loss: 3.171307893614796
Validation loss: 2.5086645299815475

Epoch: 5| Step: 7
Training loss: 2.956953523891787
Validation loss: 2.514191147724917

Epoch: 5| Step: 8
Training loss: 3.419346959858998
Validation loss: 2.5159865042963605

Epoch: 5| Step: 9
Training loss: 2.917301944394105
Validation loss: 2.5243378471874416

Epoch: 5| Step: 10
Training loss: 2.417893909288306
Validation loss: 2.531744399883958

Epoch: 187| Step: 0
Training loss: 2.6007453620339054
Validation loss: 2.53336618174946

Epoch: 5| Step: 1
Training loss: 2.730859032763085
Validation loss: 2.523025097513655

Epoch: 5| Step: 2
Training loss: 2.525218701097551
Validation loss: 2.5242767741585737

Epoch: 5| Step: 3
Training loss: 2.4103194665282643
Validation loss: 2.5190843497898627

Epoch: 5| Step: 4
Training loss: 2.8707094103933435
Validation loss: 2.5201180868075697

Epoch: 5| Step: 5
Training loss: 3.3067221003418417
Validation loss: 2.5353460680240736

Epoch: 5| Step: 6
Training loss: 2.6111133746775383
Validation loss: 2.540870005724082

Epoch: 5| Step: 7
Training loss: 3.1288542820571186
Validation loss: 2.5487889986324044

Epoch: 5| Step: 8
Training loss: 2.386119911000973
Validation loss: 2.543409525294312

Epoch: 5| Step: 9
Training loss: 3.1315254745068497
Validation loss: 2.5432503179573596

Epoch: 5| Step: 10
Training loss: 3.0268012366718695
Validation loss: 2.5475230501943864

Epoch: 188| Step: 0
Training loss: 2.6418755634235964
Validation loss: 2.5412286975842724

Epoch: 5| Step: 1
Training loss: 3.1970541388324936
Validation loss: 2.5292982291403567

Epoch: 5| Step: 2
Training loss: 2.7882189075942834
Validation loss: 2.531977275695029

Epoch: 5| Step: 3
Training loss: 2.4678392299611622
Validation loss: 2.527701974839754

Epoch: 5| Step: 4
Training loss: 2.5740034045157634
Validation loss: 2.5147043840504955

Epoch: 5| Step: 5
Training loss: 3.192539494807123
Validation loss: 2.5183820739888807

Epoch: 5| Step: 6
Training loss: 2.80659713127399
Validation loss: 2.5271044507523297

Epoch: 5| Step: 7
Training loss: 2.7653248079819006
Validation loss: 2.5189591594140914

Epoch: 5| Step: 8
Training loss: 2.743189354274426
Validation loss: 2.527845919704535

Epoch: 5| Step: 9
Training loss: 3.067748107825016
Validation loss: 2.5267813699502764

Epoch: 5| Step: 10
Training loss: 2.334236367640053
Validation loss: 2.522682104561076

Epoch: 189| Step: 0
Training loss: 3.0767934019933487
Validation loss: 2.5251098321391305

Epoch: 5| Step: 1
Training loss: 2.627587178795716
Validation loss: 2.5226831899010023

Epoch: 5| Step: 2
Training loss: 2.1589170906151978
Validation loss: 2.528544854270102

Epoch: 5| Step: 3
Training loss: 2.6046543936178694
Validation loss: 2.5361184362022455

Epoch: 5| Step: 4
Training loss: 2.1449512285854553
Validation loss: 2.5389383547891464

Epoch: 5| Step: 5
Training loss: 3.147518203597873
Validation loss: 2.551832954693048

Epoch: 5| Step: 6
Training loss: 2.7262233752770038
Validation loss: 2.5579264194112903

Epoch: 5| Step: 7
Training loss: 3.1626259639215792
Validation loss: 2.5569147087331285

Epoch: 5| Step: 8
Training loss: 2.6424472096925538
Validation loss: 2.55284485964389

Epoch: 5| Step: 9
Training loss: 3.0876599104393248
Validation loss: 2.5409210627112633

Epoch: 5| Step: 10
Training loss: 3.229690033533794
Validation loss: 2.5349283941882397

Epoch: 190| Step: 0
Training loss: 3.3314709387938284
Validation loss: 2.511698603898134

Epoch: 5| Step: 1
Training loss: 2.716470925079854
Validation loss: 2.505494141066068

Epoch: 5| Step: 2
Training loss: 2.8819994102863924
Validation loss: 2.4956587897547613

Epoch: 5| Step: 3
Training loss: 2.634537853126131
Validation loss: 2.495782941979622

Epoch: 5| Step: 4
Training loss: 2.688220703720288
Validation loss: 2.4951827439166467

Epoch: 5| Step: 5
Training loss: 3.11491950186723
Validation loss: 2.49450650588057

Epoch: 5| Step: 6
Training loss: 3.1892254217267832
Validation loss: 2.493885504004179

Epoch: 5| Step: 7
Training loss: 2.9000636060908316
Validation loss: 2.4990161272324714

Epoch: 5| Step: 8
Training loss: 2.632038942338817
Validation loss: 2.5107229709107224

Epoch: 5| Step: 9
Training loss: 2.3428765258751527
Validation loss: 2.5257226067360548

Epoch: 5| Step: 10
Training loss: 2.1464820424449904
Validation loss: 2.5637223084493597

Epoch: 191| Step: 0
Training loss: 2.945353621542347
Validation loss: 2.534603312732713

Epoch: 5| Step: 1
Training loss: 2.560192837306748
Validation loss: 2.510924225223758

Epoch: 5| Step: 2
Training loss: 3.0878662262832726
Validation loss: 2.5017946170069068

Epoch: 5| Step: 3
Training loss: 2.7605565929336255
Validation loss: 2.4883979992387055

Epoch: 5| Step: 4
Training loss: 2.806786986631507
Validation loss: 2.4961265818442486

Epoch: 5| Step: 5
Training loss: 2.7291761403004307
Validation loss: 2.4935620598787698

Epoch: 5| Step: 6
Training loss: 2.269365577100366
Validation loss: 2.4881251351803226

Epoch: 5| Step: 7
Training loss: 3.0154766777602857
Validation loss: 2.494804687657838

Epoch: 5| Step: 8
Training loss: 3.5690886488807387
Validation loss: 2.506291657665916

Epoch: 5| Step: 9
Training loss: 2.380835842050689
Validation loss: 2.504970840563736

Epoch: 5| Step: 10
Training loss: 2.5046598874364956
Validation loss: 2.5021986245697847

Epoch: 192| Step: 0
Training loss: 2.923342902132712
Validation loss: 2.5115512164377907

Epoch: 5| Step: 1
Training loss: 2.678586327647598
Validation loss: 2.5163893906760793

Epoch: 5| Step: 2
Training loss: 2.4740519509253813
Validation loss: 2.5145636212239952

Epoch: 5| Step: 3
Training loss: 2.8796062886485907
Validation loss: 2.534952184524668

Epoch: 5| Step: 4
Training loss: 2.234191566887237
Validation loss: 2.5414370753016806

Epoch: 5| Step: 5
Training loss: 2.7962077959309286
Validation loss: 2.542114762645179

Epoch: 5| Step: 6
Training loss: 3.2262077967866354
Validation loss: 2.53394600844765

Epoch: 5| Step: 7
Training loss: 2.7721064422560087
Validation loss: 2.524218570804449

Epoch: 5| Step: 8
Training loss: 2.816093353371359
Validation loss: 2.4924080773871524

Epoch: 5| Step: 9
Training loss: 3.1587801319492104
Validation loss: 2.4905887526136445

Epoch: 5| Step: 10
Training loss: 2.6174901075640764
Validation loss: 2.4854659377679926

Epoch: 193| Step: 0
Training loss: 2.2967000881729045
Validation loss: 2.487821858826715

Epoch: 5| Step: 1
Training loss: 2.992651841112537
Validation loss: 2.4856288802982713

Epoch: 5| Step: 2
Training loss: 3.0829423879956295
Validation loss: 2.4900081977539616

Epoch: 5| Step: 3
Training loss: 2.0007215628756945
Validation loss: 2.4926717038799353

Epoch: 5| Step: 4
Training loss: 2.8435474365527615
Validation loss: 2.4996818114392174

Epoch: 5| Step: 5
Training loss: 2.7849380386281135
Validation loss: 2.506194665094547

Epoch: 5| Step: 6
Training loss: 2.8826083806250553
Validation loss: 2.524257829194868

Epoch: 5| Step: 7
Training loss: 3.437034991630345
Validation loss: 2.555635682039262

Epoch: 5| Step: 8
Training loss: 2.7173207351809316
Validation loss: 2.5492667357370116

Epoch: 5| Step: 9
Training loss: 2.745488975206817
Validation loss: 2.5248085725913287

Epoch: 5| Step: 10
Training loss: 2.7085507134472624
Validation loss: 2.5248634949244075

Epoch: 194| Step: 0
Training loss: 2.8604572520163263
Validation loss: 2.520217453820951

Epoch: 5| Step: 1
Training loss: 3.011180864287087
Validation loss: 2.5109736429288954

Epoch: 5| Step: 2
Training loss: 2.5600815502231025
Validation loss: 2.510752798425057

Epoch: 5| Step: 3
Training loss: 2.6896880358215345
Validation loss: 2.5051545318201525

Epoch: 5| Step: 4
Training loss: 3.135000325861523
Validation loss: 2.4990421152082285

Epoch: 5| Step: 5
Training loss: 2.6711664877775823
Validation loss: 2.501404031657436

Epoch: 5| Step: 6
Training loss: 2.354136936596416
Validation loss: 2.497969104983052

Epoch: 5| Step: 7
Training loss: 2.4079832299938047
Validation loss: 2.498768798617552

Epoch: 5| Step: 8
Training loss: 3.0933893166880253
Validation loss: 2.499008436348363

Epoch: 5| Step: 9
Training loss: 2.9709531940893528
Validation loss: 2.494812964895397

Epoch: 5| Step: 10
Training loss: 2.802005346033087
Validation loss: 2.499746570252397

Epoch: 195| Step: 0
Training loss: 2.5254540667785275
Validation loss: 2.5121000869253245

Epoch: 5| Step: 1
Training loss: 2.9059976447687235
Validation loss: 2.513596327363077

Epoch: 5| Step: 2
Training loss: 2.9165465375593635
Validation loss: 2.5178374859788266

Epoch: 5| Step: 3
Training loss: 2.735496247512288
Validation loss: 2.5219359295517405

Epoch: 5| Step: 4
Training loss: 3.057621398162623
Validation loss: 2.5222218824182208

Epoch: 5| Step: 5
Training loss: 2.9717952168021116
Validation loss: 2.515189949825908

Epoch: 5| Step: 6
Training loss: 2.7894565506932647
Validation loss: 2.5257480575448934

Epoch: 5| Step: 7
Training loss: 2.923944077266181
Validation loss: 2.528376455388729

Epoch: 5| Step: 8
Training loss: 2.841203660431837
Validation loss: 2.5202850997209745

Epoch: 5| Step: 9
Training loss: 2.081700168072289
Validation loss: 2.5123064147264844

Epoch: 5| Step: 10
Training loss: 2.8303128205069963
Validation loss: 2.5161705508315535

Epoch: 196| Step: 0
Training loss: 2.6836513196608793
Validation loss: 2.5156749846997446

Epoch: 5| Step: 1
Training loss: 2.944175116099213
Validation loss: 2.521836225653232

Epoch: 5| Step: 2
Training loss: 2.72553231525876
Validation loss: 2.5245579196391206

Epoch: 5| Step: 3
Training loss: 2.845696757564084
Validation loss: 2.535205208506167

Epoch: 5| Step: 4
Training loss: 2.6594421952003047
Validation loss: 2.5255551900604227

Epoch: 5| Step: 5
Training loss: 2.530778723278175
Validation loss: 2.524851577638102

Epoch: 5| Step: 6
Training loss: 3.056637816991522
Validation loss: 2.5194170230945017

Epoch: 5| Step: 7
Training loss: 2.7162374527944677
Validation loss: 2.5195720171048825

Epoch: 5| Step: 8
Training loss: 2.810656982131333
Validation loss: 2.5062774988932115

Epoch: 5| Step: 9
Training loss: 2.800318553378656
Validation loss: 2.506707536190867

Epoch: 5| Step: 10
Training loss: 2.8031238670729577
Validation loss: 2.5019609451604006

Epoch: 197| Step: 0
Training loss: 2.8549976299429707
Validation loss: 2.504483337537947

Epoch: 5| Step: 1
Training loss: 2.3286687228833256
Validation loss: 2.5035971102160754

Epoch: 5| Step: 2
Training loss: 2.705076274113762
Validation loss: 2.5002412700107195

Epoch: 5| Step: 3
Training loss: 2.9826225208272006
Validation loss: 2.505644415059061

Epoch: 5| Step: 4
Training loss: 2.855819075316639
Validation loss: 2.52856283435114

Epoch: 5| Step: 5
Training loss: 3.176464950332126
Validation loss: 2.5284006034437705

Epoch: 5| Step: 6
Training loss: 2.94089458012294
Validation loss: 2.530371609381535

Epoch: 5| Step: 7
Training loss: 2.5979186420285307
Validation loss: 2.5087229715686314

Epoch: 5| Step: 8
Training loss: 2.4559280029144315
Validation loss: 2.4909478871285833

Epoch: 5| Step: 9
Training loss: 2.6318311362143123
Validation loss: 2.483274852292304

Epoch: 5| Step: 10
Training loss: 3.0681840736046926
Validation loss: 2.4822448330154847

Epoch: 198| Step: 0
Training loss: 2.6122944655173836
Validation loss: 2.4857447712481298

Epoch: 5| Step: 1
Training loss: 2.5279671373343895
Validation loss: 2.4871597568939308

Epoch: 5| Step: 2
Training loss: 2.8678396870859424
Validation loss: 2.4923594199441217

Epoch: 5| Step: 3
Training loss: 3.2330375522989514
Validation loss: 2.525778923075338

Epoch: 5| Step: 4
Training loss: 2.7033858862432063
Validation loss: 2.5653365837823645

Epoch: 5| Step: 5
Training loss: 2.6791035096440305
Validation loss: 2.5941022813331935

Epoch: 5| Step: 6
Training loss: 3.0113715183161447
Validation loss: 2.566911691911429

Epoch: 5| Step: 7
Training loss: 2.3665310292485584
Validation loss: 2.5369095411195293

Epoch: 5| Step: 8
Training loss: 2.8608188006591884
Validation loss: 2.519171997618059

Epoch: 5| Step: 9
Training loss: 2.7316390818827867
Validation loss: 2.504965576078788

Epoch: 5| Step: 10
Training loss: 3.0575685305334845
Validation loss: 2.4903573029217094

Epoch: 199| Step: 0
Training loss: 2.708451596147795
Validation loss: 2.4918542974091125

Epoch: 5| Step: 1
Training loss: 2.2317884719727297
Validation loss: 2.487571915660696

Epoch: 5| Step: 2
Training loss: 3.4008180195218176
Validation loss: 2.488685924141748

Epoch: 5| Step: 3
Training loss: 2.6480295772975104
Validation loss: 2.496824378510094

Epoch: 5| Step: 4
Training loss: 2.7275144123147665
Validation loss: 2.518461056124369

Epoch: 5| Step: 5
Training loss: 2.6685374869933014
Validation loss: 2.528182669440349

Epoch: 5| Step: 6
Training loss: 2.849859194037889
Validation loss: 2.549112344442126

Epoch: 5| Step: 7
Training loss: 2.6347129595945677
Validation loss: 2.5403123842038977

Epoch: 5| Step: 8
Training loss: 2.7690083127046834
Validation loss: 2.5183561573245865

Epoch: 5| Step: 9
Training loss: 3.0146447995098717
Validation loss: 2.5199511208134098

Epoch: 5| Step: 10
Training loss: 2.9048059629155856
Validation loss: 2.503549548830438

Epoch: 200| Step: 0
Training loss: 2.919615335863891
Validation loss: 2.4948780833442714

Epoch: 5| Step: 1
Training loss: 2.9056852058512685
Validation loss: 2.4887794833826367

Epoch: 5| Step: 2
Training loss: 2.8769063848672656
Validation loss: 2.4909830756679763

Epoch: 5| Step: 3
Training loss: 3.098934568853646
Validation loss: 2.4823465815197707

Epoch: 5| Step: 4
Training loss: 2.5206798685402925
Validation loss: 2.4865436310244298

Epoch: 5| Step: 5
Training loss: 2.5933330154745633
Validation loss: 2.501901207204199

Epoch: 5| Step: 6
Training loss: 2.7371899747135053
Validation loss: 2.5084794483084116

Epoch: 5| Step: 7
Training loss: 2.69547003686463
Validation loss: 2.5238737684618897

Epoch: 5| Step: 8
Training loss: 2.4927141834854063
Validation loss: 2.5148419390901133

Epoch: 5| Step: 9
Training loss: 2.726817996233434
Validation loss: 2.525365195460263

Epoch: 5| Step: 10
Training loss: 2.937406822512398
Validation loss: 2.5160366040847326

Epoch: 201| Step: 0
Training loss: 1.993659638656137
Validation loss: 2.4971043562926627

Epoch: 5| Step: 1
Training loss: 2.7630643035220785
Validation loss: 2.4937259126512967

Epoch: 5| Step: 2
Training loss: 3.116629567324984
Validation loss: 2.488780763771081

Epoch: 5| Step: 3
Training loss: 3.0958497599340933
Validation loss: 2.4869050526712075

Epoch: 5| Step: 4
Training loss: 2.6801776048539754
Validation loss: 2.485167035736437

Epoch: 5| Step: 5
Training loss: 2.891851051747507
Validation loss: 2.5046694391720075

Epoch: 5| Step: 6
Training loss: 2.6985797042794792
Validation loss: 2.531780927086914

Epoch: 5| Step: 7
Training loss: 2.80370013780683
Validation loss: 2.5506597838404157

Epoch: 5| Step: 8
Training loss: 2.7368196730717567
Validation loss: 2.5605098810894256

Epoch: 5| Step: 9
Training loss: 2.856943733224722
Validation loss: 2.5863054692369425

Epoch: 5| Step: 10
Training loss: 2.816330907398536
Validation loss: 2.5465915667419483

Epoch: 202| Step: 0
Training loss: 2.33281057042159
Validation loss: 2.5160534783663406

Epoch: 5| Step: 1
Training loss: 2.6327975581166787
Validation loss: 2.487001808981296

Epoch: 5| Step: 2
Training loss: 2.76323954836823
Validation loss: 2.482420743141308

Epoch: 5| Step: 3
Training loss: 2.5888434271943415
Validation loss: 2.4741724635115125

Epoch: 5| Step: 4
Training loss: 2.9826581720200798
Validation loss: 2.479033918403733

Epoch: 5| Step: 5
Training loss: 3.085345015808953
Validation loss: 2.4742517114504983

Epoch: 5| Step: 6
Training loss: 3.016762632526109
Validation loss: 2.4916011050865023

Epoch: 5| Step: 7
Training loss: 3.016950404977475
Validation loss: 2.482472556129105

Epoch: 5| Step: 8
Training loss: 3.1299428377629477
Validation loss: 2.479052034207727

Epoch: 5| Step: 9
Training loss: 2.4059427238553317
Validation loss: 2.475136774517652

Epoch: 5| Step: 10
Training loss: 2.5322736389280025
Validation loss: 2.4949275640494877

Epoch: 203| Step: 0
Training loss: 2.9210476443418614
Validation loss: 2.528220906008946

Epoch: 5| Step: 1
Training loss: 2.665095154314208
Validation loss: 2.5441587604408067

Epoch: 5| Step: 2
Training loss: 2.809709733109859
Validation loss: 2.5543772883632934

Epoch: 5| Step: 3
Training loss: 2.8968364889965628
Validation loss: 2.552326059926255

Epoch: 5| Step: 4
Training loss: 2.787323139550067
Validation loss: 2.5355334988217084

Epoch: 5| Step: 5
Training loss: 2.9218934410451647
Validation loss: 2.5363001970693353

Epoch: 5| Step: 6
Training loss: 2.9558004541524903
Validation loss: 2.527162083467501

Epoch: 5| Step: 7
Training loss: 2.4868920968410686
Validation loss: 2.5394573389948567

Epoch: 5| Step: 8
Training loss: 2.506664357928302
Validation loss: 2.5255032326546885

Epoch: 5| Step: 9
Training loss: 2.9477642186154926
Validation loss: 2.5318128769454935

Epoch: 5| Step: 10
Training loss: 2.5448177898959194
Validation loss: 2.5136320953328317

Epoch: 204| Step: 0
Training loss: 2.8942959956270427
Validation loss: 2.4933181035872645

Epoch: 5| Step: 1
Training loss: 2.802767976034429
Validation loss: 2.478234205079607

Epoch: 5| Step: 2
Training loss: 2.6566831347801885
Validation loss: 2.476508201075551

Epoch: 5| Step: 3
Training loss: 2.6887208693880194
Validation loss: 2.480772750631568

Epoch: 5| Step: 4
Training loss: 3.016731810173745
Validation loss: 2.4657984190214317

Epoch: 5| Step: 5
Training loss: 2.566310840151206
Validation loss: 2.4654067447183907

Epoch: 5| Step: 6
Training loss: 2.7538976790923804
Validation loss: 2.47247740551665

Epoch: 5| Step: 7
Training loss: 2.0676837858829673
Validation loss: 2.47234056894734

Epoch: 5| Step: 8
Training loss: 2.8694660165851267
Validation loss: 2.4942131316210348

Epoch: 5| Step: 9
Training loss: 3.0852541396259565
Validation loss: 2.518094091770209

Epoch: 5| Step: 10
Training loss: 2.9679681651934966
Validation loss: 2.557362898418968

Epoch: 205| Step: 0
Training loss: 2.5419224990747633
Validation loss: 2.5564256179079012

Epoch: 5| Step: 1
Training loss: 2.793293967352759
Validation loss: 2.5456235070456317

Epoch: 5| Step: 2
Training loss: 2.492961034042578
Validation loss: 2.538457433705035

Epoch: 5| Step: 3
Training loss: 2.7671374479621185
Validation loss: 2.5331650324530233

Epoch: 5| Step: 4
Training loss: 2.6260739808828824
Validation loss: 2.519375447566359

Epoch: 5| Step: 5
Training loss: 2.773826980107099
Validation loss: 2.501601194529639

Epoch: 5| Step: 6
Training loss: 2.9962672216933433
Validation loss: 2.4884032761089716

Epoch: 5| Step: 7
Training loss: 2.8080031154593548
Validation loss: 2.480796921834805

Epoch: 5| Step: 8
Training loss: 3.092191669756221
Validation loss: 2.4682749016801666

Epoch: 5| Step: 9
Training loss: 2.8271018859509405
Validation loss: 2.4774083563139513

Epoch: 5| Step: 10
Training loss: 2.640620756428034
Validation loss: 2.4750648567101985

Epoch: 206| Step: 0
Training loss: 3.151816549733088
Validation loss: 2.47516928568562

Epoch: 5| Step: 1
Training loss: 3.027559531120328
Validation loss: 2.485069673611722

Epoch: 5| Step: 2
Training loss: 2.7019750541535026
Validation loss: 2.4937719703060357

Epoch: 5| Step: 3
Training loss: 2.8211345795365617
Validation loss: 2.523664438820934

Epoch: 5| Step: 4
Training loss: 2.856815881411619
Validation loss: 2.5621215987120713

Epoch: 5| Step: 5
Training loss: 2.8578216836238446
Validation loss: 2.5751999316765817

Epoch: 5| Step: 6
Training loss: 2.278208128533586
Validation loss: 2.5966982808103207

Epoch: 5| Step: 7
Training loss: 2.545289089968696
Validation loss: 2.6034704216958398

Epoch: 5| Step: 8
Training loss: 2.6347549472193754
Validation loss: 2.581063340706724

Epoch: 5| Step: 9
Training loss: 2.9256948705331296
Validation loss: 2.5598024074938373

Epoch: 5| Step: 10
Training loss: 2.414305443251833
Validation loss: 2.5012173006538294

Epoch: 207| Step: 0
Training loss: 2.956643727961527
Validation loss: 2.485207229769476

Epoch: 5| Step: 1
Training loss: 2.897375359475166
Validation loss: 2.4817585793052883

Epoch: 5| Step: 2
Training loss: 2.9856109456543454
Validation loss: 2.4784110308450247

Epoch: 5| Step: 3
Training loss: 2.615215868382288
Validation loss: 2.4744835108434806

Epoch: 5| Step: 4
Training loss: 2.869786552706187
Validation loss: 2.485517050882635

Epoch: 5| Step: 5
Training loss: 2.990732661016429
Validation loss: 2.4795245888302873

Epoch: 5| Step: 6
Training loss: 2.681218635713537
Validation loss: 2.487114430267748

Epoch: 5| Step: 7
Training loss: 2.6736799245018243
Validation loss: 2.505775063845414

Epoch: 5| Step: 8
Training loss: 2.7948504744712372
Validation loss: 2.51398543757485

Epoch: 5| Step: 9
Training loss: 2.3104097353043276
Validation loss: 2.5254872539006796

Epoch: 5| Step: 10
Training loss: 2.5462579272169745
Validation loss: 2.5474432824543443

Epoch: 208| Step: 0
Training loss: 2.818869097238416
Validation loss: 2.58764244655682

Epoch: 5| Step: 1
Training loss: 2.3792917725316225
Validation loss: 2.577529982748551

Epoch: 5| Step: 2
Training loss: 2.428219857934367
Validation loss: 2.5605005426682044

Epoch: 5| Step: 3
Training loss: 2.5843418880311053
Validation loss: 2.517649426119608

Epoch: 5| Step: 4
Training loss: 2.9225233042157392
Validation loss: 2.5044247396935

Epoch: 5| Step: 5
Training loss: 2.760236760640739
Validation loss: 2.492533849981946

Epoch: 5| Step: 6
Training loss: 2.9238154042183195
Validation loss: 2.4837226111710615

Epoch: 5| Step: 7
Training loss: 2.4529477195098224
Validation loss: 2.48229530707415

Epoch: 5| Step: 8
Training loss: 2.7938200393533728
Validation loss: 2.4875123330235818

Epoch: 5| Step: 9
Training loss: 3.2555526836094724
Validation loss: 2.5135788511539814

Epoch: 5| Step: 10
Training loss: 2.8295894645842066
Validation loss: 2.526961434541955

Epoch: 209| Step: 0
Training loss: 2.4934329565140447
Validation loss: 2.559292499359904

Epoch: 5| Step: 1
Training loss: 2.73230154714617
Validation loss: 2.547134892465034

Epoch: 5| Step: 2
Training loss: 2.9623807343888995
Validation loss: 2.517610887453843

Epoch: 5| Step: 3
Training loss: 2.7151027199156945
Validation loss: 2.5038604217646343

Epoch: 5| Step: 4
Training loss: 2.724232987415074
Validation loss: 2.5046505792699945

Epoch: 5| Step: 5
Training loss: 2.7800741388877386
Validation loss: 2.499160068681893

Epoch: 5| Step: 6
Training loss: 2.8296996733026045
Validation loss: 2.4965976061029647

Epoch: 5| Step: 7
Training loss: 2.216758478983285
Validation loss: 2.4870423289875307

Epoch: 5| Step: 8
Training loss: 2.754812710967801
Validation loss: 2.4994706824062907

Epoch: 5| Step: 9
Training loss: 3.3146647451502087
Validation loss: 2.499598829834982

Epoch: 5| Step: 10
Training loss: 2.669152730174328
Validation loss: 2.5052413059906433

Epoch: 210| Step: 0
Training loss: 2.4854060498693267
Validation loss: 2.499416626781342

Epoch: 5| Step: 1
Training loss: 2.8285662059267827
Validation loss: 2.4990265227629616

Epoch: 5| Step: 2
Training loss: 3.141125843100659
Validation loss: 2.508491386143911

Epoch: 5| Step: 3
Training loss: 2.8654836638528614
Validation loss: 2.4965544727382305

Epoch: 5| Step: 4
Training loss: 2.72323536563192
Validation loss: 2.4919521485413374

Epoch: 5| Step: 5
Training loss: 3.0016662420865243
Validation loss: 2.4992632098077627

Epoch: 5| Step: 6
Training loss: 2.4403706788084043
Validation loss: 2.5120965947140075

Epoch: 5| Step: 7
Training loss: 2.9592206098974763
Validation loss: 2.5057946247934506

Epoch: 5| Step: 8
Training loss: 2.9000414089008872
Validation loss: 2.5270608256501736

Epoch: 5| Step: 9
Training loss: 2.5532102834402113
Validation loss: 2.5396180913617137

Epoch: 5| Step: 10
Training loss: 2.109349455502157
Validation loss: 2.5135842699646975

Epoch: 211| Step: 0
Training loss: 2.7347602790787895
Validation loss: 2.53016177471541

Epoch: 5| Step: 1
Training loss: 2.8107527497727767
Validation loss: 2.5279245503758476

Epoch: 5| Step: 2
Training loss: 2.7496527539275566
Validation loss: 2.5464226719717016

Epoch: 5| Step: 3
Training loss: 2.539852641479361
Validation loss: 2.544336933237901

Epoch: 5| Step: 4
Training loss: 2.698046726543267
Validation loss: 2.5308945118945108

Epoch: 5| Step: 5
Training loss: 2.545251153121161
Validation loss: 2.562444071505778

Epoch: 5| Step: 6
Training loss: 3.0662865099033767
Validation loss: 2.5846439381992576

Epoch: 5| Step: 7
Training loss: 2.024193346400803
Validation loss: 2.56464132544598

Epoch: 5| Step: 8
Training loss: 3.2301596478669605
Validation loss: 2.5512463889701604

Epoch: 5| Step: 9
Training loss: 2.7566056244844326
Validation loss: 2.527831446583385

Epoch: 5| Step: 10
Training loss: 2.734604046628981
Validation loss: 2.487503934615852

Epoch: 212| Step: 0
Training loss: 2.6866158206409985
Validation loss: 2.483863553482388

Epoch: 5| Step: 1
Training loss: 3.1852856592682763
Validation loss: 2.481046906880812

Epoch: 5| Step: 2
Training loss: 2.5918959459976687
Validation loss: 2.482297700001564

Epoch: 5| Step: 3
Training loss: 2.61924230277214
Validation loss: 2.4764849222752963

Epoch: 5| Step: 4
Training loss: 3.081638557741891
Validation loss: 2.478946984901186

Epoch: 5| Step: 5
Training loss: 2.652675512405351
Validation loss: 2.491604385258818

Epoch: 5| Step: 6
Training loss: 2.6047024493597974
Validation loss: 2.4959193345633808

Epoch: 5| Step: 7
Training loss: 2.381639736050863
Validation loss: 2.5466092180684137

Epoch: 5| Step: 8
Training loss: 3.300261579607812
Validation loss: 2.597123013777691

Epoch: 5| Step: 9
Training loss: 2.592414512144441
Validation loss: 2.5841597761062634

Epoch: 5| Step: 10
Training loss: 2.4954235150144575
Validation loss: 2.509087245063458

Epoch: 213| Step: 0
Training loss: 2.587548344846945
Validation loss: 2.4770811839553932

Epoch: 5| Step: 1
Training loss: 2.88161735261546
Validation loss: 2.474548458749425

Epoch: 5| Step: 2
Training loss: 2.55847344734469
Validation loss: 2.474586187633901

Epoch: 5| Step: 3
Training loss: 2.6762941634602386
Validation loss: 2.468464584747345

Epoch: 5| Step: 4
Training loss: 2.65799045763104
Validation loss: 2.479546994901776

Epoch: 5| Step: 5
Training loss: 2.968703741415919
Validation loss: 2.47395071515312

Epoch: 5| Step: 6
Training loss: 2.714724838616587
Validation loss: 2.488840154323537

Epoch: 5| Step: 7
Training loss: 2.5526867419164376
Validation loss: 2.4944017477089084

Epoch: 5| Step: 8
Training loss: 2.8968973926390635
Validation loss: 2.5050494974468105

Epoch: 5| Step: 9
Training loss: 2.857516325656181
Validation loss: 2.499911222624877

Epoch: 5| Step: 10
Training loss: 2.9267247388751056
Validation loss: 2.5229002373238005

Epoch: 214| Step: 0
Training loss: 2.9778878372723363
Validation loss: 2.5520579460912147

Epoch: 5| Step: 1
Training loss: 2.5368505614598584
Validation loss: 2.6137718356884543

Epoch: 5| Step: 2
Training loss: 3.740696620016508
Validation loss: 2.6389646407737852

Epoch: 5| Step: 3
Training loss: 2.631706571495878
Validation loss: 2.568574859813828

Epoch: 5| Step: 4
Training loss: 2.352980176868908
Validation loss: 2.5264434187123332

Epoch: 5| Step: 5
Training loss: 2.364592990491419
Validation loss: 2.498382955998268

Epoch: 5| Step: 6
Training loss: 2.792281913335188
Validation loss: 2.484873351165681

Epoch: 5| Step: 7
Training loss: 2.833069919982348
Validation loss: 2.4818338637672177

Epoch: 5| Step: 8
Training loss: 2.656951273180259
Validation loss: 2.4912915168145764

Epoch: 5| Step: 9
Training loss: 2.6894881413104903
Validation loss: 2.5245989812954606

Epoch: 5| Step: 10
Training loss: 2.3206552579855577
Validation loss: 2.5145708179849744

Epoch: 215| Step: 0
Training loss: 2.8332691933346914
Validation loss: 2.5113652807545446

Epoch: 5| Step: 1
Training loss: 2.555748768657368
Validation loss: 2.511261289656494

Epoch: 5| Step: 2
Training loss: 2.6700885890879875
Validation loss: 2.496079925720159

Epoch: 5| Step: 3
Training loss: 3.0204555582187935
Validation loss: 2.5180889575486773

Epoch: 5| Step: 4
Training loss: 2.8508998989379912
Validation loss: 2.498234057449601

Epoch: 5| Step: 5
Training loss: 2.7120414486927538
Validation loss: 2.4931050227698086

Epoch: 5| Step: 6
Training loss: 2.5158703607355424
Validation loss: 2.4756569889567333

Epoch: 5| Step: 7
Training loss: 2.5358909165480883
Validation loss: 2.499517753193191

Epoch: 5| Step: 8
Training loss: 3.3638446260692483
Validation loss: 2.535153315392151

Epoch: 5| Step: 9
Training loss: 2.234106727980845
Validation loss: 2.59379937561932

Epoch: 5| Step: 10
Training loss: 2.9442795781297493
Validation loss: 2.6680515914059946

Epoch: 216| Step: 0
Training loss: 3.151568424973902
Validation loss: 2.681221475470263

Epoch: 5| Step: 1
Training loss: 2.7890719031594817
Validation loss: 2.694101051319764

Epoch: 5| Step: 2
Training loss: 2.790564979172608
Validation loss: 2.69534704166326

Epoch: 5| Step: 3
Training loss: 2.404841518612978
Validation loss: 2.6550486715098067

Epoch: 5| Step: 4
Training loss: 3.112406570686883
Validation loss: 2.596836045657915

Epoch: 5| Step: 5
Training loss: 2.7842375750295703
Validation loss: 2.5370131281290424

Epoch: 5| Step: 6
Training loss: 3.0142597804313054
Validation loss: 2.495337890152269

Epoch: 5| Step: 7
Training loss: 2.2937618619107987
Validation loss: 2.4604464846977327

Epoch: 5| Step: 8
Training loss: 3.0462504994012787
Validation loss: 2.462776647185619

Epoch: 5| Step: 9
Training loss: 2.4636074538583745
Validation loss: 2.4750741746348104

Epoch: 5| Step: 10
Training loss: 2.5976398209360636
Validation loss: 2.4817810271868677

Epoch: 217| Step: 0
Training loss: 3.07669731375604
Validation loss: 2.4778501631455465

Epoch: 5| Step: 1
Training loss: 2.8351420818699102
Validation loss: 2.4774359130832107

Epoch: 5| Step: 2
Training loss: 2.550512606390897
Validation loss: 2.478631185553112

Epoch: 5| Step: 3
Training loss: 2.784346239346016
Validation loss: 2.4652467427506903

Epoch: 5| Step: 4
Training loss: 2.3829743877512035
Validation loss: 2.461708770175719

Epoch: 5| Step: 5
Training loss: 3.0425960914903163
Validation loss: 2.4811487964694288

Epoch: 5| Step: 6
Training loss: 3.1519168531614477
Validation loss: 2.48534460244265

Epoch: 5| Step: 7
Training loss: 2.574352116234175
Validation loss: 2.494435709731333

Epoch: 5| Step: 8
Training loss: 2.697450447794073
Validation loss: 2.4929543353508183

Epoch: 5| Step: 9
Training loss: 2.606353106391717
Validation loss: 2.5042133164450417

Epoch: 5| Step: 10
Training loss: 2.633116843181284
Validation loss: 2.555114667229909

Epoch: 218| Step: 0
Training loss: 2.793079806167268
Validation loss: 2.6189208827593213

Epoch: 5| Step: 1
Training loss: 2.3930438401972407
Validation loss: 2.6572543904858916

Epoch: 5| Step: 2
Training loss: 2.4075858631449734
Validation loss: 2.5846350187586133

Epoch: 5| Step: 3
Training loss: 3.1093156511786564
Validation loss: 2.53489704691364

Epoch: 5| Step: 4
Training loss: 2.746057892696861
Validation loss: 2.49287292434304

Epoch: 5| Step: 5
Training loss: 3.0030028890976297
Validation loss: 2.4783766651073504

Epoch: 5| Step: 6
Training loss: 2.8251330319029613
Validation loss: 2.471251193066869

Epoch: 5| Step: 7
Training loss: 2.6406408907620973
Validation loss: 2.480311184271861

Epoch: 5| Step: 8
Training loss: 3.4556148062638607
Validation loss: 2.492250767597599

Epoch: 5| Step: 9
Training loss: 2.8049552598400904
Validation loss: 2.4900277368788273

Epoch: 5| Step: 10
Training loss: 2.299475203640649
Validation loss: 2.504095392149754

Epoch: 219| Step: 0
Training loss: 2.6745787208597784
Validation loss: 2.5006200267648397

Epoch: 5| Step: 1
Training loss: 2.655989780021446
Validation loss: 2.5062506724946325

Epoch: 5| Step: 2
Training loss: 2.708470345968409
Validation loss: 2.4950278099736662

Epoch: 5| Step: 3
Training loss: 3.326522512988443
Validation loss: 2.5196264115607923

Epoch: 5| Step: 4
Training loss: 2.912932066733248
Validation loss: 2.537064100047191

Epoch: 5| Step: 5
Training loss: 2.5712943477264805
Validation loss: 2.569217843134649

Epoch: 5| Step: 6
Training loss: 2.6711410495958345
Validation loss: 2.6466185380272953

Epoch: 5| Step: 7
Training loss: 2.3716429022614616
Validation loss: 2.7237355243797214

Epoch: 5| Step: 8
Training loss: 2.885599747965151
Validation loss: 2.7656670264699734

Epoch: 5| Step: 9
Training loss: 2.8926920330690495
Validation loss: 2.707772493310381

Epoch: 5| Step: 10
Training loss: 2.840366236753056
Validation loss: 2.659409322423533

Epoch: 220| Step: 0
Training loss: 2.5152615112793524
Validation loss: 2.6141034496326925

Epoch: 5| Step: 1
Training loss: 2.604291155064871
Validation loss: 2.5303432755292468

Epoch: 5| Step: 2
Training loss: 2.53976299306522
Validation loss: 2.4964610431403464

Epoch: 5| Step: 3
Training loss: 2.638354527317435
Validation loss: 2.473358411776506

Epoch: 5| Step: 4
Training loss: 2.8494569294491265
Validation loss: 2.4687695879540104

Epoch: 5| Step: 5
Training loss: 2.9441496883463887
Validation loss: 2.4608026793453557

Epoch: 5| Step: 6
Training loss: 2.5496259938641286
Validation loss: 2.465951547654519

Epoch: 5| Step: 7
Training loss: 3.2354878892856123
Validation loss: 2.464035944750991

Epoch: 5| Step: 8
Training loss: 3.0274202989313914
Validation loss: 2.4806837874143937

Epoch: 5| Step: 9
Training loss: 2.4828557581461066
Validation loss: 2.4883059643710803

Epoch: 5| Step: 10
Training loss: 2.6785901550364972
Validation loss: 2.495709466073153

Epoch: 221| Step: 0
Training loss: 2.795476212033413
Validation loss: 2.5111064151402145

Epoch: 5| Step: 1
Training loss: 2.8501355925311675
Validation loss: 2.5280418934891253

Epoch: 5| Step: 2
Training loss: 2.7485460425842545
Validation loss: 2.5409309261039428

Epoch: 5| Step: 3
Training loss: 3.2316685654501986
Validation loss: 2.5435291031608007

Epoch: 5| Step: 4
Training loss: 2.546331429544173
Validation loss: 2.565956655591801

Epoch: 5| Step: 5
Training loss: 2.636352694497676
Validation loss: 2.5705664864198168

Epoch: 5| Step: 6
Training loss: 2.7735890521697986
Validation loss: 2.563732095118894

Epoch: 5| Step: 7
Training loss: 2.575013658802139
Validation loss: 2.5407881110152917

Epoch: 5| Step: 8
Training loss: 2.814204653083577
Validation loss: 2.5213016863764897

Epoch: 5| Step: 9
Training loss: 2.1121937320965514
Validation loss: 2.5128712548336454

Epoch: 5| Step: 10
Training loss: 2.9642561781391685
Validation loss: 2.4831460317503784

Epoch: 222| Step: 0
Training loss: 3.0720815439726503
Validation loss: 2.488627322603359

Epoch: 5| Step: 1
Training loss: 3.0134348451625828
Validation loss: 2.4844737813335427

Epoch: 5| Step: 2
Training loss: 2.6286633678315288
Validation loss: 2.4828523951705583

Epoch: 5| Step: 3
Training loss: 3.4002219239904408
Validation loss: 2.4889002067978914

Epoch: 5| Step: 4
Training loss: 2.287821566799931
Validation loss: 2.4924294213554727

Epoch: 5| Step: 5
Training loss: 2.647859583453727
Validation loss: 2.511334854143069

Epoch: 5| Step: 6
Training loss: 1.9140271241947748
Validation loss: 2.5297150266582755

Epoch: 5| Step: 7
Training loss: 2.7319616512327096
Validation loss: 2.5471119929263777

Epoch: 5| Step: 8
Training loss: 2.336528690507292
Validation loss: 2.5728464510996996

Epoch: 5| Step: 9
Training loss: 3.088804820248494
Validation loss: 2.578267886719509

Epoch: 5| Step: 10
Training loss: 2.3301301040671274
Validation loss: 2.572811237307588

Epoch: 223| Step: 0
Training loss: 2.6776052676182958
Validation loss: 2.560406013140262

Epoch: 5| Step: 1
Training loss: 2.6758888835560177
Validation loss: 2.569359259582325

Epoch: 5| Step: 2
Training loss: 2.7500873898579057
Validation loss: 2.5545844209393307

Epoch: 5| Step: 3
Training loss: 2.920331414632432
Validation loss: 2.564153381973854

Epoch: 5| Step: 4
Training loss: 2.5721404929344485
Validation loss: 2.545904428958107

Epoch: 5| Step: 5
Training loss: 2.574250425106242
Validation loss: 2.5168470653650306

Epoch: 5| Step: 6
Training loss: 3.0665463555273615
Validation loss: 2.5145823863858996

Epoch: 5| Step: 7
Training loss: 2.278276883728017
Validation loss: 2.5187049731213147

Epoch: 5| Step: 8
Training loss: 2.9081960745905975
Validation loss: 2.5139201512108853

Epoch: 5| Step: 9
Training loss: 2.9487545229111833
Validation loss: 2.523824640423282

Epoch: 5| Step: 10
Training loss: 2.473116718824981
Validation loss: 2.5485274048253492

Epoch: 224| Step: 0
Training loss: 2.921189498046317
Validation loss: 2.574598751869894

Epoch: 5| Step: 1
Training loss: 2.419033919041018
Validation loss: 2.5915838656140124

Epoch: 5| Step: 2
Training loss: 3.0037967180737684
Validation loss: 2.584612326987562

Epoch: 5| Step: 3
Training loss: 2.3160158185336295
Validation loss: 2.5698820760434833

Epoch: 5| Step: 4
Training loss: 3.2848906165829996
Validation loss: 2.5422844831025

Epoch: 5| Step: 5
Training loss: 2.766751420971092
Validation loss: 2.497848139413224

Epoch: 5| Step: 6
Training loss: 2.6921171403879884
Validation loss: 2.4868354483097916

Epoch: 5| Step: 7
Training loss: 2.2238240852902225
Validation loss: 2.4851788988412173

Epoch: 5| Step: 8
Training loss: 3.0508628375174007
Validation loss: 2.4727155094510307

Epoch: 5| Step: 9
Training loss: 2.7743833836245986
Validation loss: 2.476059661992698

Epoch: 5| Step: 10
Training loss: 2.6071400465082295
Validation loss: 2.4762269422873238

Epoch: 225| Step: 0
Training loss: 2.8847672779489173
Validation loss: 2.4864443854669847

Epoch: 5| Step: 1
Training loss: 2.599667061983207
Validation loss: 2.4989978976341285

Epoch: 5| Step: 2
Training loss: 3.027439672119455
Validation loss: 2.5138276260638324

Epoch: 5| Step: 3
Training loss: 2.0484538504663057
Validation loss: 2.5392534677331784

Epoch: 5| Step: 4
Training loss: 2.665904999278752
Validation loss: 2.551675375065836

Epoch: 5| Step: 5
Training loss: 2.7078278485549387
Validation loss: 2.5248058696477873

Epoch: 5| Step: 6
Training loss: 3.285039112665285
Validation loss: 2.506991061006158

Epoch: 5| Step: 7
Training loss: 2.582940246044463
Validation loss: 2.5010786980036115

Epoch: 5| Step: 8
Training loss: 2.8896923313242806
Validation loss: 2.491416869354092

Epoch: 5| Step: 9
Training loss: 2.561071416345429
Validation loss: 2.4993643578127487

Epoch: 5| Step: 10
Training loss: 2.197706769951782
Validation loss: 2.5075479410770627

Epoch: 226| Step: 0
Training loss: 2.9195480464608323
Validation loss: 2.528252880576034

Epoch: 5| Step: 1
Training loss: 2.74186587281509
Validation loss: 2.5717307726384866

Epoch: 5| Step: 2
Training loss: 2.2107210626240787
Validation loss: 2.620056022230459

Epoch: 5| Step: 3
Training loss: 2.3095278842891953
Validation loss: 2.6053640776865556

Epoch: 5| Step: 4
Training loss: 3.0315888205654704
Validation loss: 2.596849082812611

Epoch: 5| Step: 5
Training loss: 2.8696793789828123
Validation loss: 2.545525890140775

Epoch: 5| Step: 6
Training loss: 2.214737824021252
Validation loss: 2.5221867729412213

Epoch: 5| Step: 7
Training loss: 2.7196480155847955
Validation loss: 2.5107740650670993

Epoch: 5| Step: 8
Training loss: 2.843804998180392
Validation loss: 2.522346523111283

Epoch: 5| Step: 9
Training loss: 2.611687737456792
Validation loss: 2.5056242989002953

Epoch: 5| Step: 10
Training loss: 3.0946213236977735
Validation loss: 2.5118988768134507

Epoch: 227| Step: 0
Training loss: 2.4506453111892106
Validation loss: 2.5100947586284157

Epoch: 5| Step: 1
Training loss: 2.874751536372148
Validation loss: 2.5029131825851345

Epoch: 5| Step: 2
Training loss: 3.198051193008872
Validation loss: 2.5196989845124778

Epoch: 5| Step: 3
Training loss: 2.7139842038014677
Validation loss: 2.525886850758134

Epoch: 5| Step: 4
Training loss: 2.1227766635340206
Validation loss: 2.564990256498353

Epoch: 5| Step: 5
Training loss: 2.6821059276875
Validation loss: 2.567844416133956

Epoch: 5| Step: 6
Training loss: 2.816471432422292
Validation loss: 2.5916727077114463

Epoch: 5| Step: 7
Training loss: 2.672906865978831
Validation loss: 2.6092885153933896

Epoch: 5| Step: 8
Training loss: 2.802404723236564
Validation loss: 2.5707786803815766

Epoch: 5| Step: 9
Training loss: 2.528433563301021
Validation loss: 2.5340288375179782

Epoch: 5| Step: 10
Training loss: 2.736218337934069
Validation loss: 2.49937563246913

Epoch: 228| Step: 0
Training loss: 2.899550396497887
Validation loss: 2.4920961924739893

Epoch: 5| Step: 1
Training loss: 2.7352414747404628
Validation loss: 2.490143114251888

Epoch: 5| Step: 2
Training loss: 2.640825794418262
Validation loss: 2.4853788929790457

Epoch: 5| Step: 3
Training loss: 2.618409102290784
Validation loss: 2.4936661331689045

Epoch: 5| Step: 4
Training loss: 2.806066572485837
Validation loss: 2.495788557615241

Epoch: 5| Step: 5
Training loss: 3.0910458547250936
Validation loss: 2.5007637610794

Epoch: 5| Step: 6
Training loss: 2.804218901270055
Validation loss: 2.5009580750370355

Epoch: 5| Step: 7
Training loss: 2.1759445156568873
Validation loss: 2.518379800857976

Epoch: 5| Step: 8
Training loss: 2.4831965308516644
Validation loss: 2.5347498907726576

Epoch: 5| Step: 9
Training loss: 2.7707327535247925
Validation loss: 2.557641692960123

Epoch: 5| Step: 10
Training loss: 2.4536632749104528
Validation loss: 2.5268615423922838

Epoch: 229| Step: 0
Training loss: 1.9261131387519024
Validation loss: 2.5143460402324442

Epoch: 5| Step: 1
Training loss: 2.9294085153624323
Validation loss: 2.5199094208238404

Epoch: 5| Step: 2
Training loss: 2.468332182862269
Validation loss: 2.5254544768872464

Epoch: 5| Step: 3
Training loss: 2.610077906063383
Validation loss: 2.5315450336625878

Epoch: 5| Step: 4
Training loss: 2.5759069900899445
Validation loss: 2.5358482372172206

Epoch: 5| Step: 5
Training loss: 2.799653021566818
Validation loss: 2.5300523027721216

Epoch: 5| Step: 6
Training loss: 2.010768984689698
Validation loss: 2.534125795616652

Epoch: 5| Step: 7
Training loss: 2.7322373235846324
Validation loss: 2.5479611898341257

Epoch: 5| Step: 8
Training loss: 3.293258056964371
Validation loss: 2.5531807350502236

Epoch: 5| Step: 9
Training loss: 3.0989564185043106
Validation loss: 2.5250477127494326

Epoch: 5| Step: 10
Training loss: 2.828244454405979
Validation loss: 2.4887540073269494

Epoch: 230| Step: 0
Training loss: 2.734661239900727
Validation loss: 2.486731917496126

Epoch: 5| Step: 1
Training loss: 3.013588014772145
Validation loss: 2.4638296909088497

Epoch: 5| Step: 2
Training loss: 2.3751411396050623
Validation loss: 2.4584845163929137

Epoch: 5| Step: 3
Training loss: 2.3874223986092415
Validation loss: 2.457707618670348

Epoch: 5| Step: 4
Training loss: 2.510992108209955
Validation loss: 2.478587476813597

Epoch: 5| Step: 5
Training loss: 2.7687223514872783
Validation loss: 2.5350867832195476

Epoch: 5| Step: 6
Training loss: 3.089646671920919
Validation loss: 2.5798248852091334

Epoch: 5| Step: 7
Training loss: 3.077730569886752
Validation loss: 2.5807376593758433

Epoch: 5| Step: 8
Training loss: 2.7099244261335453
Validation loss: 2.521610639166457

Epoch: 5| Step: 9
Training loss: 2.462167680653084
Validation loss: 2.4932383722589377

Epoch: 5| Step: 10
Training loss: 2.4951777680390252
Validation loss: 2.4847263658614582

Epoch: 231| Step: 0
Training loss: 1.6612748270927968
Validation loss: 2.469283380051375

Epoch: 5| Step: 1
Training loss: 2.782459467535253
Validation loss: 2.487066014573149

Epoch: 5| Step: 2
Training loss: 2.698236885852555
Validation loss: 2.4750829021299827

Epoch: 5| Step: 3
Training loss: 2.7136100325999495
Validation loss: 2.493271549142188

Epoch: 5| Step: 4
Training loss: 2.78387233251218
Validation loss: 2.535649736589353

Epoch: 5| Step: 5
Training loss: 2.840619218776347
Validation loss: 2.5230608781332378

Epoch: 5| Step: 6
Training loss: 2.1236370427996354
Validation loss: 2.5418175669846517

Epoch: 5| Step: 7
Training loss: 3.0847633928916673
Validation loss: 2.562816759365969

Epoch: 5| Step: 8
Training loss: 2.874877097778537
Validation loss: 2.5822209848905833

Epoch: 5| Step: 9
Training loss: 2.771576162784805
Validation loss: 2.6261219629087718

Epoch: 5| Step: 10
Training loss: 2.6575909091045276
Validation loss: 2.6362338504932494

Epoch: 232| Step: 0
Training loss: 2.994063862253924
Validation loss: 2.6754653671155713

Epoch: 5| Step: 1
Training loss: 3.104113704221047
Validation loss: 2.6772556009301267

Epoch: 5| Step: 2
Training loss: 2.909585330952798
Validation loss: 2.5739763188585427

Epoch: 5| Step: 3
Training loss: 2.050908431696217
Validation loss: 2.5047327128703993

Epoch: 5| Step: 4
Training loss: 1.9283407971570972
Validation loss: 2.475744480144287

Epoch: 5| Step: 5
Training loss: 2.811208216389312
Validation loss: 2.464850371155749

Epoch: 5| Step: 6
Training loss: 2.41771374961666
Validation loss: 2.456565395023291

Epoch: 5| Step: 7
Training loss: 2.707021649936756
Validation loss: 2.456835205983959

Epoch: 5| Step: 8
Training loss: 3.045896245791132
Validation loss: 2.4656870408148794

Epoch: 5| Step: 9
Training loss: 3.0631247681137213
Validation loss: 2.4768744095292288

Epoch: 5| Step: 10
Training loss: 2.737031441917354
Validation loss: 2.5239902506728535

Epoch: 233| Step: 0
Training loss: 2.8657933309487706
Validation loss: 2.5841761142849426

Epoch: 5| Step: 1
Training loss: 2.740589078104493
Validation loss: 2.676609960505837

Epoch: 5| Step: 2
Training loss: 3.034334167142872
Validation loss: 2.7000653820712563

Epoch: 5| Step: 3
Training loss: 2.619438638025588
Validation loss: 2.597791375528499

Epoch: 5| Step: 4
Training loss: 1.827765861512324
Validation loss: 2.5276508983093344

Epoch: 5| Step: 5
Training loss: 2.2902355117964195
Validation loss: 2.4838163129858017

Epoch: 5| Step: 6
Training loss: 2.5803550554268013
Validation loss: 2.4715016104728007

Epoch: 5| Step: 7
Training loss: 2.6131224077928557
Validation loss: 2.4818193676494666

Epoch: 5| Step: 8
Training loss: 3.0170539277200525
Validation loss: 2.479364503236541

Epoch: 5| Step: 9
Training loss: 3.038050936745909
Validation loss: 2.497058571595835

Epoch: 5| Step: 10
Training loss: 2.555783844393954
Validation loss: 2.4922027469127084

Epoch: 234| Step: 0
Training loss: 2.7733805905802975
Validation loss: 2.5004416034713777

Epoch: 5| Step: 1
Training loss: 2.86860592548881
Validation loss: 2.4956837443722946

Epoch: 5| Step: 2
Training loss: 2.236809318113224
Validation loss: 2.5212092582444234

Epoch: 5| Step: 3
Training loss: 2.549509195703567
Validation loss: 2.5489057060834113

Epoch: 5| Step: 4
Training loss: 2.700508306480986
Validation loss: 2.604691105036641

Epoch: 5| Step: 5
Training loss: 2.9886391419161433
Validation loss: 2.601356862580786

Epoch: 5| Step: 6
Training loss: 2.5733027818411207
Validation loss: 2.5774028891685172

Epoch: 5| Step: 7
Training loss: 3.035485994746838
Validation loss: 2.6757707243969016

Epoch: 5| Step: 8
Training loss: 2.193192622570965
Validation loss: 2.6331345010807445

Epoch: 5| Step: 9
Training loss: 2.5456631825761113
Validation loss: 2.6333475203136483

Epoch: 5| Step: 10
Training loss: 2.835961712190031
Validation loss: 2.5905916010926067

Epoch: 235| Step: 0
Training loss: 2.404243524425854
Validation loss: 2.5456629308106007

Epoch: 5| Step: 1
Training loss: 2.420957920810169
Validation loss: 2.5114937909937987

Epoch: 5| Step: 2
Training loss: 3.0898985345471113
Validation loss: 2.4914210017706218

Epoch: 5| Step: 3
Training loss: 1.9598260290437597
Validation loss: 2.483256755938452

Epoch: 5| Step: 4
Training loss: 2.8808489472798566
Validation loss: 2.4814738306902266

Epoch: 5| Step: 5
Training loss: 3.037193213774496
Validation loss: 2.4949610914630513

Epoch: 5| Step: 6
Training loss: 2.3433758246239824
Validation loss: 2.511237373396872

Epoch: 5| Step: 7
Training loss: 2.889085679402265
Validation loss: 2.55832526138324

Epoch: 5| Step: 8
Training loss: 2.3679482021466
Validation loss: 2.5946747368976557

Epoch: 5| Step: 9
Training loss: 3.0550243455381914
Validation loss: 2.6241000483977555

Epoch: 5| Step: 10
Training loss: 2.5345520333995446
Validation loss: 2.6548681082352696

Epoch: 236| Step: 0
Training loss: 2.5283959393261526
Validation loss: 2.6964845234666903

Epoch: 5| Step: 1
Training loss: 2.4557435462398516
Validation loss: 2.7035917293739127

Epoch: 5| Step: 2
Training loss: 3.3075021431498604
Validation loss: 2.67027966123503

Epoch: 5| Step: 3
Training loss: 2.5565259192301966
Validation loss: 2.5517132304685775

Epoch: 5| Step: 4
Training loss: 2.4208417103327546
Validation loss: 2.507113974109186

Epoch: 5| Step: 5
Training loss: 2.5267381369951174
Validation loss: 2.490728891080552

Epoch: 5| Step: 6
Training loss: 2.5375681074050482
Validation loss: 2.485652129672865

Epoch: 5| Step: 7
Training loss: 2.014777071715915
Validation loss: 2.5041203753075623

Epoch: 5| Step: 8
Training loss: 3.3162140088477443
Validation loss: 2.508639939532637

Epoch: 5| Step: 9
Training loss: 2.9961602751944563
Validation loss: 2.512391999544308

Epoch: 5| Step: 10
Training loss: 2.260937386112698
Validation loss: 2.5198293680133688

Epoch: 237| Step: 0
Training loss: 2.7411964125294284
Validation loss: 2.5439761411576494

Epoch: 5| Step: 1
Training loss: 2.6271002405657673
Validation loss: 2.5917593627196265

Epoch: 5| Step: 2
Training loss: 2.54688604621598
Validation loss: 2.653303131458887

Epoch: 5| Step: 3
Training loss: 3.1768798429432334
Validation loss: 2.706668785870701

Epoch: 5| Step: 4
Training loss: 2.513521819834023
Validation loss: 2.6189877970021143

Epoch: 5| Step: 5
Training loss: 2.5442620664124695
Validation loss: 2.5714402709218844

Epoch: 5| Step: 6
Training loss: 2.7255125456181672
Validation loss: 2.5274538778618565

Epoch: 5| Step: 7
Training loss: 2.7736428628028515
Validation loss: 2.485933827732093

Epoch: 5| Step: 8
Training loss: 1.7540499961756684
Validation loss: 2.48057074291504

Epoch: 5| Step: 9
Training loss: 2.9629749545101944
Validation loss: 2.459563709900701

Epoch: 5| Step: 10
Training loss: 2.7203903511384424
Validation loss: 2.470512345741143

Epoch: 238| Step: 0
Training loss: 2.6090077581498643
Validation loss: 2.4641479916410605

Epoch: 5| Step: 1
Training loss: 2.8095710762349064
Validation loss: 2.4809569470338233

Epoch: 5| Step: 2
Training loss: 3.3783744614037152
Validation loss: 2.4958015494379118

Epoch: 5| Step: 3
Training loss: 2.6580962104233903
Validation loss: 2.5150586194261737

Epoch: 5| Step: 4
Training loss: 2.4258437586300112
Validation loss: 2.5323534593143746

Epoch: 5| Step: 5
Training loss: 2.3374337090052717
Validation loss: 2.562614949567203

Epoch: 5| Step: 6
Training loss: 2.6529011877978492
Validation loss: 2.613422038009746

Epoch: 5| Step: 7
Training loss: 2.4418973138950104
Validation loss: 2.6526543058193734

Epoch: 5| Step: 8
Training loss: 1.6971800050550665
Validation loss: 2.590412608551509

Epoch: 5| Step: 9
Training loss: 3.032922342424986
Validation loss: 2.571098738253106

Epoch: 5| Step: 10
Training loss: 2.552242870923568
Validation loss: 2.5286000330640874

Epoch: 239| Step: 0
Training loss: 2.2862088379405523
Validation loss: 2.505904174329547

Epoch: 5| Step: 1
Training loss: 2.3509976034862095
Validation loss: 2.492285487201569

Epoch: 5| Step: 2
Training loss: 1.9400401537957517
Validation loss: 2.4964659990027505

Epoch: 5| Step: 3
Training loss: 2.4583444648964794
Validation loss: 2.5016121701124114

Epoch: 5| Step: 4
Training loss: 3.1531627399465765
Validation loss: 2.4913208175502377

Epoch: 5| Step: 5
Training loss: 2.7219252186466365
Validation loss: 2.512342313816849

Epoch: 5| Step: 6
Training loss: 2.6466304949859825
Validation loss: 2.543958204511234

Epoch: 5| Step: 7
Training loss: 2.493039741808349
Validation loss: 2.5599587558075996

Epoch: 5| Step: 8
Training loss: 2.990711136776284
Validation loss: 2.604522935349366

Epoch: 5| Step: 9
Training loss: 2.2959921041744984
Validation loss: 2.6277563543584677

Epoch: 5| Step: 10
Training loss: 2.956950459957698
Validation loss: 2.6187519401331456

Epoch: 240| Step: 0
Training loss: 2.6455177259065827
Validation loss: 2.6478429120760807

Epoch: 5| Step: 1
Training loss: 2.514024118494407
Validation loss: 2.626458046805922

Epoch: 5| Step: 2
Training loss: 2.4552985602982456
Validation loss: 2.619966280512848

Epoch: 5| Step: 3
Training loss: 2.5126071622399513
Validation loss: 2.6450061475600655

Epoch: 5| Step: 4
Training loss: 2.6918106993255337
Validation loss: 2.6448645332418144

Epoch: 5| Step: 5
Training loss: 2.5562017310325658
Validation loss: 2.6123519587425457

Epoch: 5| Step: 6
Training loss: 2.8689867241952163
Validation loss: 2.5918698445434507

Epoch: 5| Step: 7
Training loss: 2.564570451131323
Validation loss: 2.5739911310980923

Epoch: 5| Step: 8
Training loss: 2.401734115038211
Validation loss: 2.5315187049034313

Epoch: 5| Step: 9
Training loss: 2.4526796361869425
Validation loss: 2.487216314549922

Epoch: 5| Step: 10
Training loss: 2.8881005063201894
Validation loss: 2.458389752593798

Epoch: 241| Step: 0
Training loss: 2.4527386403612477
Validation loss: 2.4683962976558353

Epoch: 5| Step: 1
Training loss: 2.705273959235745
Validation loss: 2.466578319561592

Epoch: 5| Step: 2
Training loss: 2.808094728409842
Validation loss: 2.4549913237576106

Epoch: 5| Step: 3
Training loss: 2.631928790830721
Validation loss: 2.479719187452909

Epoch: 5| Step: 4
Training loss: 2.016315903647844
Validation loss: 2.52027585129768

Epoch: 5| Step: 5
Training loss: 2.96715526914844
Validation loss: 2.5471666779154205

Epoch: 5| Step: 6
Training loss: 2.112155014851584
Validation loss: 2.553903437880575

Epoch: 5| Step: 7
Training loss: 1.8886649320015223
Validation loss: 2.583609730611228

Epoch: 5| Step: 8
Training loss: 2.907817458897236
Validation loss: 2.5984043092505678

Epoch: 5| Step: 9
Training loss: 2.8245604586675017
Validation loss: 2.6484686369037664

Epoch: 5| Step: 10
Training loss: 2.794002571039239
Validation loss: 2.651969364566723

Epoch: 242| Step: 0
Training loss: 2.0199918535276007
Validation loss: 2.6701757591161965

Epoch: 5| Step: 1
Training loss: 2.342209169619675
Validation loss: 2.6277528714620724

Epoch: 5| Step: 2
Training loss: 2.5369343921205996
Validation loss: 2.6030595669831387

Epoch: 5| Step: 3
Training loss: 2.4640723228863535
Validation loss: 2.5729981100195185

Epoch: 5| Step: 4
Training loss: 2.3503566958219797
Validation loss: 2.5418776093943625

Epoch: 5| Step: 5
Training loss: 2.8480418589119694
Validation loss: 2.569095544279021

Epoch: 5| Step: 6
Training loss: 3.089775229368243
Validation loss: 2.591691447730624

Epoch: 5| Step: 7
Training loss: 2.6139163398810172
Validation loss: 2.6421941366911774

Epoch: 5| Step: 8
Training loss: 2.625777084133903
Validation loss: 2.680003306131676

Epoch: 5| Step: 9
Training loss: 2.5641481635122725
Validation loss: 2.714500163644091

Epoch: 5| Step: 10
Training loss: 3.5334409145555656
Validation loss: 2.714199910691661

Epoch: 243| Step: 0
Training loss: 2.5216607136308387
Validation loss: 2.6247336217807224

Epoch: 5| Step: 1
Training loss: 2.4697894069146984
Validation loss: 2.564599197544019

Epoch: 5| Step: 2
Training loss: 2.8255144579181146
Validation loss: 2.545359831387504

Epoch: 5| Step: 3
Training loss: 3.0102511737746114
Validation loss: 2.550859778702262

Epoch: 5| Step: 4
Training loss: 2.994726791784867
Validation loss: 2.5463114837967513

Epoch: 5| Step: 5
Training loss: 2.2883101649360618
Validation loss: 2.5149620597634574

Epoch: 5| Step: 6
Training loss: 2.2621633458339967
Validation loss: 2.562473756189066

Epoch: 5| Step: 7
Training loss: 2.2020564091773895
Validation loss: 2.660504565018453

Epoch: 5| Step: 8
Training loss: 2.977052983600239
Validation loss: 2.7290108554915937

Epoch: 5| Step: 9
Training loss: 3.0873159685771623
Validation loss: 2.740223298003539

Epoch: 5| Step: 10
Training loss: 2.5686770166577504
Validation loss: 2.6463613680052522

Epoch: 244| Step: 0
Training loss: 2.83792036530571
Validation loss: 2.5659925449177905

Epoch: 5| Step: 1
Training loss: 3.135783092763018
Validation loss: 2.527833132126668

Epoch: 5| Step: 2
Training loss: 2.155208170100913
Validation loss: 2.516783552288014

Epoch: 5| Step: 3
Training loss: 2.806533928252015
Validation loss: 2.521198899778256

Epoch: 5| Step: 4
Training loss: 2.3843011927149194
Validation loss: 2.526763977832565

Epoch: 5| Step: 5
Training loss: 2.6540976387122366
Validation loss: 2.4999265311325893

Epoch: 5| Step: 6
Training loss: 2.6859440402339114
Validation loss: 2.530017844069154

Epoch: 5| Step: 7
Training loss: 2.1577298158884544
Validation loss: 2.5338338215329044

Epoch: 5| Step: 8
Training loss: 2.3307918149459725
Validation loss: 2.5592162829579452

Epoch: 5| Step: 9
Training loss: 2.4688067852201443
Validation loss: 2.6025772360046253

Epoch: 5| Step: 10
Training loss: 2.8790824763736307
Validation loss: 2.6532621871459288

Epoch: 245| Step: 0
Training loss: 2.7712923592309835
Validation loss: 2.6150340674018486

Epoch: 5| Step: 1
Training loss: 2.683290689338826
Validation loss: 2.5914401273066123

Epoch: 5| Step: 2
Training loss: 2.0700054588798746
Validation loss: 2.5529052723366403

Epoch: 5| Step: 3
Training loss: 3.1956125878627
Validation loss: 2.5268433503366685

Epoch: 5| Step: 4
Training loss: 1.9010621439906512
Validation loss: 2.510368091057296

Epoch: 5| Step: 5
Training loss: 2.5318774163943933
Validation loss: 2.5106279048313533

Epoch: 5| Step: 6
Training loss: 2.3002313497537887
Validation loss: 2.5048230347153697

Epoch: 5| Step: 7
Training loss: 2.6906858678793615
Validation loss: 2.539502702515993

Epoch: 5| Step: 8
Training loss: 2.508363657247392
Validation loss: 2.5808536104710837

Epoch: 5| Step: 9
Training loss: 2.889093766731836
Validation loss: 2.6249463553936385

Epoch: 5| Step: 10
Training loss: 2.4648800226072645
Validation loss: 2.618409892410891

Epoch: 246| Step: 0
Training loss: 2.225727446720227
Validation loss: 2.5917691651847083

Epoch: 5| Step: 1
Training loss: 2.6341482334121555
Validation loss: 2.5486912394316352

Epoch: 5| Step: 2
Training loss: 2.7065339395398955
Validation loss: 2.530709696532659

Epoch: 5| Step: 3
Training loss: 2.2229543261449862
Validation loss: 2.5065877849697076

Epoch: 5| Step: 4
Training loss: 2.9060476909486312
Validation loss: 2.508488148493258

Epoch: 5| Step: 5
Training loss: 2.3249074732919794
Validation loss: 2.497742642809724

Epoch: 5| Step: 6
Training loss: 2.348906782194996
Validation loss: 2.5096143259804258

Epoch: 5| Step: 7
Training loss: 2.802430160972599
Validation loss: 2.4800139925236486

Epoch: 5| Step: 8
Training loss: 2.744730495709841
Validation loss: 2.516567958698941

Epoch: 5| Step: 9
Training loss: 2.6611682014562046
Validation loss: 2.5280099811554866

Epoch: 5| Step: 10
Training loss: 2.5588527868634543
Validation loss: 2.5376887868892566

Epoch: 247| Step: 0
Training loss: 3.014997505958753
Validation loss: 2.541887477143777

Epoch: 5| Step: 1
Training loss: 2.786002738047594
Validation loss: 2.5511783772567336

Epoch: 5| Step: 2
Training loss: 2.9782685924709553
Validation loss: 2.608456937499305

Epoch: 5| Step: 3
Training loss: 2.4285830228993595
Validation loss: 2.584089964917981

Epoch: 5| Step: 4
Training loss: 2.2949088887598
Validation loss: 2.5673713581943987

Epoch: 5| Step: 5
Training loss: 2.255589958715708
Validation loss: 2.5500280834326885

Epoch: 5| Step: 6
Training loss: 2.3641497064555135
Validation loss: 2.5068020821147865

Epoch: 5| Step: 7
Training loss: 2.232173128195271
Validation loss: 2.4982648467983437

Epoch: 5| Step: 8
Training loss: 2.3769881309370224
Validation loss: 2.5094206118183564

Epoch: 5| Step: 9
Training loss: 2.879706303933028
Validation loss: 2.514344266118536

Epoch: 5| Step: 10
Training loss: 2.080207526968193
Validation loss: 2.5068908251022584

Epoch: 248| Step: 0
Training loss: 2.677535368955573
Validation loss: 2.5135271071957526

Epoch: 5| Step: 1
Training loss: 2.4894410309497044
Validation loss: 2.495344486900079

Epoch: 5| Step: 2
Training loss: 2.6028486858503905
Validation loss: 2.529630765717211

Epoch: 5| Step: 3
Training loss: 2.1783769283976757
Validation loss: 2.5299098549908137

Epoch: 5| Step: 4
Training loss: 2.4236729008893447
Validation loss: 2.5448429197822207

Epoch: 5| Step: 5
Training loss: 2.2747909869081715
Validation loss: 2.586361237589171

Epoch: 5| Step: 6
Training loss: 2.457380551979301
Validation loss: 2.5927507502142975

Epoch: 5| Step: 7
Training loss: 3.002719917724075
Validation loss: 2.6243285498683337

Epoch: 5| Step: 8
Training loss: 2.8974400369464415
Validation loss: 2.635146048404583

Epoch: 5| Step: 9
Training loss: 2.2097854038841604
Validation loss: 2.6171185002715336

Epoch: 5| Step: 10
Training loss: 2.7131054918791304
Validation loss: 2.5857895237298454

Epoch: 249| Step: 0
Training loss: 2.2224538271798884
Validation loss: 2.571979605315607

Epoch: 5| Step: 1
Training loss: 2.567832608468618
Validation loss: 2.533559654196926

Epoch: 5| Step: 2
Training loss: 2.1798561605193587
Validation loss: 2.521546095177714

Epoch: 5| Step: 3
Training loss: 2.866603365650196
Validation loss: 2.5002684069697265

Epoch: 5| Step: 4
Training loss: 2.8078535905908355
Validation loss: 2.482458475272858

Epoch: 5| Step: 5
Training loss: 2.1576907002673065
Validation loss: 2.488564982752479

Epoch: 5| Step: 6
Training loss: 2.8112944668399056
Validation loss: 2.4861390459102144

Epoch: 5| Step: 7
Training loss: 2.6719992090098414
Validation loss: 2.4890606421120403

Epoch: 5| Step: 8
Training loss: 2.383945383387149
Validation loss: 2.4794031928107167

Epoch: 5| Step: 9
Training loss: 2.8740070120899137
Validation loss: 2.4789079438243404

Epoch: 5| Step: 10
Training loss: 2.2846716733814003
Validation loss: 2.524993204607003

Epoch: 250| Step: 0
Training loss: 2.3644509187389033
Validation loss: 2.590636280993714

Epoch: 5| Step: 1
Training loss: 2.7634733634259967
Validation loss: 2.6499955977319924

Epoch: 5| Step: 2
Training loss: 2.585861066627923
Validation loss: 2.729770304011425

Epoch: 5| Step: 3
Training loss: 3.33001469079062
Validation loss: 2.7586833475142156

Epoch: 5| Step: 4
Training loss: 2.911513126155686
Validation loss: 2.6896180880151275

Epoch: 5| Step: 5
Training loss: 2.3615484269002858
Validation loss: 2.63125397617561

Epoch: 5| Step: 6
Training loss: 2.124251065388965
Validation loss: 2.543992917788484

Epoch: 5| Step: 7
Training loss: 2.46821173099419
Validation loss: 2.4919508430343997

Epoch: 5| Step: 8
Training loss: 2.0869958600020095
Validation loss: 2.457470202319735

Epoch: 5| Step: 9
Training loss: 2.456195634623682
Validation loss: 2.4698885100226624

Epoch: 5| Step: 10
Training loss: 2.8907012104607386
Validation loss: 2.4680085601149617

Epoch: 251| Step: 0
Training loss: 2.9406573594813086
Validation loss: 2.46680005928725

Epoch: 5| Step: 1
Training loss: 2.892230273754304
Validation loss: 2.5022856129177655

Epoch: 5| Step: 2
Training loss: 2.535391257374769
Validation loss: 2.508507701059817

Epoch: 5| Step: 3
Training loss: 2.3324133785146075
Validation loss: 2.576883822099811

Epoch: 5| Step: 4
Training loss: 2.224494696684758
Validation loss: 2.666839114953079

Epoch: 5| Step: 5
Training loss: 2.8352283610520628
Validation loss: 2.7412996512185597

Epoch: 5| Step: 6
Training loss: 2.9854002784195783
Validation loss: 2.776957107098954

Epoch: 5| Step: 7
Training loss: 3.061787113595505
Validation loss: 2.680739763817043

Epoch: 5| Step: 8
Training loss: 2.2126521817903932
Validation loss: 2.5866501428494777

Epoch: 5| Step: 9
Training loss: 2.376725724312677
Validation loss: 2.491672994197008

Epoch: 5| Step: 10
Training loss: 1.4936245694030146
Validation loss: 2.4652039390651095

Epoch: 252| Step: 0
Training loss: 2.599584704023382
Validation loss: 2.457618753086864

Epoch: 5| Step: 1
Training loss: 2.2827989727979814
Validation loss: 2.458878275472032

Epoch: 5| Step: 2
Training loss: 3.0746159569572065
Validation loss: 2.462825109428133

Epoch: 5| Step: 3
Training loss: 2.1869200891478315
Validation loss: 2.47508554233104

Epoch: 5| Step: 4
Training loss: 2.488348703952269
Validation loss: 2.527624522901796

Epoch: 5| Step: 5
Training loss: 2.3209675593116232
Validation loss: 2.5805403734923376

Epoch: 5| Step: 6
Training loss: 2.3228676852092764
Validation loss: 2.6593849440006108

Epoch: 5| Step: 7
Training loss: 2.589596007222234
Validation loss: 2.7113574536903986

Epoch: 5| Step: 8
Training loss: 2.896771468829903
Validation loss: 2.7111337639222977

Epoch: 5| Step: 9
Training loss: 2.7466093314615443
Validation loss: 2.6953642533588607

Epoch: 5| Step: 10
Training loss: 2.4800548298219818
Validation loss: 2.6176268496392483

Epoch: 253| Step: 0
Training loss: 2.4994129445314273
Validation loss: 2.564581011279477

Epoch: 5| Step: 1
Training loss: 3.0723315872706696
Validation loss: 2.5112374305654517

Epoch: 5| Step: 2
Training loss: 2.3591776380033425
Validation loss: 2.5161428854108445

Epoch: 5| Step: 3
Training loss: 2.974981413711062
Validation loss: 2.5016892396878143

Epoch: 5| Step: 4
Training loss: 2.6896603794620884
Validation loss: 2.5051952545320586

Epoch: 5| Step: 5
Training loss: 2.5112061162810324
Validation loss: 2.5118420022884735

Epoch: 5| Step: 6
Training loss: 2.3593275052778586
Validation loss: 2.5130591122079853

Epoch: 5| Step: 7
Training loss: 2.8651470022785093
Validation loss: 2.565537360098913

Epoch: 5| Step: 8
Training loss: 2.0192841428472725
Validation loss: 2.5687995599873465

Epoch: 5| Step: 9
Training loss: 2.3120056861226734
Validation loss: 2.571325727849521

Epoch: 5| Step: 10
Training loss: 1.6401303226747121
Validation loss: 2.6327233542701616

Epoch: 254| Step: 0
Training loss: 2.7001995507426053
Validation loss: 2.6423103792235443

Epoch: 5| Step: 1
Training loss: 2.090051715521285
Validation loss: 2.6443087877059184

Epoch: 5| Step: 2
Training loss: 2.470172037936462
Validation loss: 2.621028436884062

Epoch: 5| Step: 3
Training loss: 2.755911801580969
Validation loss: 2.6478831327213253

Epoch: 5| Step: 4
Training loss: 2.44731628414247
Validation loss: 2.641871031714306

Epoch: 5| Step: 5
Training loss: 2.739530052759623
Validation loss: 2.640714141589601

Epoch: 5| Step: 6
Training loss: 2.7371637564616953
Validation loss: 2.573233474119243

Epoch: 5| Step: 7
Training loss: 2.6475837704352565
Validation loss: 2.473319659777264

Epoch: 5| Step: 8
Training loss: 2.38406039221007
Validation loss: 2.4498775330397993

Epoch: 5| Step: 9
Training loss: 2.5716439830532005
Validation loss: 2.442624335958348

Epoch: 5| Step: 10
Training loss: 1.894635573198897
Validation loss: 2.4646726598659128

Epoch: 255| Step: 0
Training loss: 2.6108077450190423
Validation loss: 2.506690601040647

Epoch: 5| Step: 1
Training loss: 2.41059443665352
Validation loss: 2.529978792601912

Epoch: 5| Step: 2
Training loss: 2.925138558260441
Validation loss: 2.5664040713493677

Epoch: 5| Step: 3
Training loss: 2.2867994350929757
Validation loss: 2.5897317859459164

Epoch: 5| Step: 4
Training loss: 2.4895562419188777
Validation loss: 2.575017487812723

Epoch: 5| Step: 5
Training loss: 2.525742272531423
Validation loss: 2.5699445072881684

Epoch: 5| Step: 6
Training loss: 2.5709733200499083
Validation loss: 2.572308363855194

Epoch: 5| Step: 7
Training loss: 1.895512780836965
Validation loss: 2.5578010048012456

Epoch: 5| Step: 8
Training loss: 1.9473802232452497
Validation loss: 2.5465056156978836

Epoch: 5| Step: 9
Training loss: 2.7753660562006313
Validation loss: 2.568027789884969

Epoch: 5| Step: 10
Training loss: 2.5013233497002862
Validation loss: 2.57234617772674

Epoch: 256| Step: 0
Training loss: 2.422852940157307
Validation loss: 2.580449764692057

Epoch: 5| Step: 1
Training loss: 1.9988911654379458
Validation loss: 2.554527271418216

Epoch: 5| Step: 2
Training loss: 2.563228782667939
Validation loss: 2.5152379801085596

Epoch: 5| Step: 3
Training loss: 3.027764115220099
Validation loss: 2.492475996672564

Epoch: 5| Step: 4
Training loss: 2.4165291144150176
Validation loss: 2.479533045282422

Epoch: 5| Step: 5
Training loss: 2.522875743967731
Validation loss: 2.475258664597707

Epoch: 5| Step: 6
Training loss: 2.5849078107734815
Validation loss: 2.4981343732525105

Epoch: 5| Step: 7
Training loss: 1.9758109974761764
Validation loss: 2.497743664060619

Epoch: 5| Step: 8
Training loss: 2.5081328665721427
Validation loss: 2.5387303672622705

Epoch: 5| Step: 9
Training loss: 2.8388478711825638
Validation loss: 2.5571099796058534

Epoch: 5| Step: 10
Training loss: 2.0642610603138776
Validation loss: 2.553004397511496

Epoch: 257| Step: 0
Training loss: 2.41240934290556
Validation loss: 2.535368768465381

Epoch: 5| Step: 1
Training loss: 2.2419751428932746
Validation loss: 2.4992946768050683

Epoch: 5| Step: 2
Training loss: 2.834316157999332
Validation loss: 2.4953251558420644

Epoch: 5| Step: 3
Training loss: 2.4025515582757717
Validation loss: 2.4949546652990375

Epoch: 5| Step: 4
Training loss: 1.835911332613553
Validation loss: 2.496363883247347

Epoch: 5| Step: 5
Training loss: 2.7139300009317253
Validation loss: 2.5237462258647065

Epoch: 5| Step: 6
Training loss: 2.113750863912576
Validation loss: 2.543821545666281

Epoch: 5| Step: 7
Training loss: 2.320891028827957
Validation loss: 2.54766431040422

Epoch: 5| Step: 8
Training loss: 2.098282193183616
Validation loss: 2.563739529842875

Epoch: 5| Step: 9
Training loss: 3.1929626031699305
Validation loss: 2.5466313731589088

Epoch: 5| Step: 10
Training loss: 2.643871681533411
Validation loss: 2.533928301284583

Epoch: 258| Step: 0
Training loss: 1.8739724840609202
Validation loss: 2.5522205676678564

Epoch: 5| Step: 1
Training loss: 2.2442400638869873
Validation loss: 2.5472976592556145

Epoch: 5| Step: 2
Training loss: 2.421788564800837
Validation loss: 2.5636239136958006

Epoch: 5| Step: 3
Training loss: 2.4474603647017226
Validation loss: 2.595747264582846

Epoch: 5| Step: 4
Training loss: 2.674308427203612
Validation loss: 2.593327362936674

Epoch: 5| Step: 5
Training loss: 2.6143632368078022
Validation loss: 2.58001596778462

Epoch: 5| Step: 6
Training loss: 2.3703868635528784
Validation loss: 2.564962047193856

Epoch: 5| Step: 7
Training loss: 1.990214548957463
Validation loss: 2.5336349839870835

Epoch: 5| Step: 8
Training loss: 2.580151033490353
Validation loss: 2.5287051050662406

Epoch: 5| Step: 9
Training loss: 2.9941888794117952
Validation loss: 2.5253446953087546

Epoch: 5| Step: 10
Training loss: 2.67804714521485
Validation loss: 2.5529446870847203

Epoch: 259| Step: 0
Training loss: 2.5135104372814436
Validation loss: 2.5419900464189267

Epoch: 5| Step: 1
Training loss: 2.7592165563419013
Validation loss: 2.5671690965555953

Epoch: 5| Step: 2
Training loss: 2.331993115495102
Validation loss: 2.5739657026373735

Epoch: 5| Step: 3
Training loss: 2.3934940251072025
Validation loss: 2.588002022845218

Epoch: 5| Step: 4
Training loss: 2.840692070734676
Validation loss: 2.588663194699261

Epoch: 5| Step: 5
Training loss: 2.371677182358112
Validation loss: 2.60209265601284

Epoch: 5| Step: 6
Training loss: 2.1094631600500633
Validation loss: 2.575739464184245

Epoch: 5| Step: 7
Training loss: 2.3800555179435734
Validation loss: 2.5426954698431117

Epoch: 5| Step: 8
Training loss: 2.574715689361154
Validation loss: 2.541450433461214

Epoch: 5| Step: 9
Training loss: 2.393158411772587
Validation loss: 2.564385807450985

Epoch: 5| Step: 10
Training loss: 1.9201972275008188
Validation loss: 2.5506046380195073

Epoch: 260| Step: 0
Training loss: 2.757229665057447
Validation loss: 2.543145251138954

Epoch: 5| Step: 1
Training loss: 2.6465187886946078
Validation loss: 2.5136419974732243

Epoch: 5| Step: 2
Training loss: 2.4571075185027844
Validation loss: 2.4874655967456807

Epoch: 5| Step: 3
Training loss: 2.646085792171382
Validation loss: 2.492948801769487

Epoch: 5| Step: 4
Training loss: 2.4528069745586096
Validation loss: 2.4995542344177024

Epoch: 5| Step: 5
Training loss: 2.646155170080369
Validation loss: 2.5390913140844624

Epoch: 5| Step: 6
Training loss: 1.6074453099559909
Validation loss: 2.5708669361285055

Epoch: 5| Step: 7
Training loss: 2.285188071526568
Validation loss: 2.6189426101554716

Epoch: 5| Step: 8
Training loss: 2.443129665148778
Validation loss: 2.6291311105979003

Epoch: 5| Step: 9
Training loss: 2.566464218808784
Validation loss: 2.6444464609488234

Epoch: 5| Step: 10
Training loss: 2.087833186074097
Validation loss: 2.6322563418697005

Epoch: 261| Step: 0
Training loss: 1.9070479177006785
Validation loss: 2.6519808246893297

Epoch: 5| Step: 1
Training loss: 2.253592801570263
Validation loss: 2.6283602353898377

Epoch: 5| Step: 2
Training loss: 2.8591762119253588
Validation loss: 2.5910610746381773

Epoch: 5| Step: 3
Training loss: 2.582669131712885
Validation loss: 2.5595929343171218

Epoch: 5| Step: 4
Training loss: 2.490164961501937
Validation loss: 2.542627356445914

Epoch: 5| Step: 5
Training loss: 2.147409421988963
Validation loss: 2.524042366184377

Epoch: 5| Step: 6
Training loss: 2.3465086913940554
Validation loss: 2.541124399666206

Epoch: 5| Step: 7
Training loss: 2.2329492888784737
Validation loss: 2.545536174791732

Epoch: 5| Step: 8
Training loss: 2.3763271438461664
Validation loss: 2.548929468551824

Epoch: 5| Step: 9
Training loss: 2.647531900330767
Validation loss: 2.565599143643505

Epoch: 5| Step: 10
Training loss: 2.8535457037685754
Validation loss: 2.5999297421241554

Epoch: 262| Step: 0
Training loss: 2.3773726607917465
Validation loss: 2.665214388905009

Epoch: 5| Step: 1
Training loss: 2.1248123983710854
Validation loss: 2.705614180474848

Epoch: 5| Step: 2
Training loss: 2.9443443589224505
Validation loss: 2.7793974578851155

Epoch: 5| Step: 3
Training loss: 2.588897209899948
Validation loss: 2.7025757738507585

Epoch: 5| Step: 4
Training loss: 2.2123447428394685
Validation loss: 2.666294552299598

Epoch: 5| Step: 5
Training loss: 1.5347469648128311
Validation loss: 2.5915842464627996

Epoch: 5| Step: 6
Training loss: 2.701450954095827
Validation loss: 2.5575049794038276

Epoch: 5| Step: 7
Training loss: 2.198185679769878
Validation loss: 2.5225556694263878

Epoch: 5| Step: 8
Training loss: 2.9404493094973825
Validation loss: 2.4842204260418232

Epoch: 5| Step: 9
Training loss: 2.7163966725366824
Validation loss: 2.468711536004505

Epoch: 5| Step: 10
Training loss: 2.2622651542048926
Validation loss: 2.477683099015721

Epoch: 263| Step: 0
Training loss: 2.2852816555466906
Validation loss: 2.500179505825567

Epoch: 5| Step: 1
Training loss: 2.2940628586781684
Validation loss: 2.552803578471917

Epoch: 5| Step: 2
Training loss: 2.0344804165156143
Validation loss: 2.5756095281108387

Epoch: 5| Step: 3
Training loss: 2.6166746633452016
Validation loss: 2.615841551557744

Epoch: 5| Step: 4
Training loss: 2.94536204005502
Validation loss: 2.657680191595736

Epoch: 5| Step: 5
Training loss: 2.624964577572105
Validation loss: 2.6606011074659675

Epoch: 5| Step: 6
Training loss: 2.3171043952140593
Validation loss: 2.6478501106308467

Epoch: 5| Step: 7
Training loss: 2.3391667630103075
Validation loss: 2.627358990488506

Epoch: 5| Step: 8
Training loss: 2.3085919943349396
Validation loss: 2.5895638401929078

Epoch: 5| Step: 9
Training loss: 2.2065036919599876
Validation loss: 2.5652845236935495

Epoch: 5| Step: 10
Training loss: 2.5592726876811875
Validation loss: 2.532186452692845

Epoch: 264| Step: 0
Training loss: 2.491516501283058
Validation loss: 2.504012280379641

Epoch: 5| Step: 1
Training loss: 2.185955265128401
Validation loss: 2.4745146501012676

Epoch: 5| Step: 2
Training loss: 2.654786189031549
Validation loss: 2.489819827495869

Epoch: 5| Step: 3
Training loss: 2.0080630372476005
Validation loss: 2.5549668162545127

Epoch: 5| Step: 4
Training loss: 2.4533213154180538
Validation loss: 2.5982445131495675

Epoch: 5| Step: 5
Training loss: 2.570686939178693
Validation loss: 2.6259409882548925

Epoch: 5| Step: 6
Training loss: 2.5777775385827284
Validation loss: 2.650117748242607

Epoch: 5| Step: 7
Training loss: 2.4783926858915954
Validation loss: 2.6210163416115346

Epoch: 5| Step: 8
Training loss: 2.16615893454846
Validation loss: 2.552440389468

Epoch: 5| Step: 9
Training loss: 2.6245788054652524
Validation loss: 2.489503717524587

Epoch: 5| Step: 10
Training loss: 2.7390494364259923
Validation loss: 2.4668360869663393

Epoch: 265| Step: 0
Training loss: 1.8054011531573866
Validation loss: 2.4874014736134793

Epoch: 5| Step: 1
Training loss: 1.7066005975382237
Validation loss: 2.4813288157395395

Epoch: 5| Step: 2
Training loss: 2.771109794266969
Validation loss: 2.523462589329297

Epoch: 5| Step: 3
Training loss: 3.0578752748091382
Validation loss: 2.546847638918648

Epoch: 5| Step: 4
Training loss: 2.7813633242032845
Validation loss: 2.536896900282288

Epoch: 5| Step: 5
Training loss: 2.63473449643398
Validation loss: 2.518804479341781

Epoch: 5| Step: 6
Training loss: 2.247988331394524
Validation loss: 2.4833426992825167

Epoch: 5| Step: 7
Training loss: 2.500569469442669
Validation loss: 2.5021602019176026

Epoch: 5| Step: 8
Training loss: 2.552993072500367
Validation loss: 2.4888487676231343

Epoch: 5| Step: 9
Training loss: 2.4281907945357113
Validation loss: 2.4896260482398973

Epoch: 5| Step: 10
Training loss: 2.38428239355074
Validation loss: 2.5097970195658266

Epoch: 266| Step: 0
Training loss: 2.272037874913511
Validation loss: 2.581331992848985

Epoch: 5| Step: 1
Training loss: 1.7574000574077415
Validation loss: 2.5942673901631097

Epoch: 5| Step: 2
Training loss: 2.6492734956836075
Validation loss: 2.6150489137337036

Epoch: 5| Step: 3
Training loss: 2.4680445182160886
Validation loss: 2.632629636481191

Epoch: 5| Step: 4
Training loss: 2.6351333485978614
Validation loss: 2.660530120316366

Epoch: 5| Step: 5
Training loss: 2.529049800160747
Validation loss: 2.6357627656633165

Epoch: 5| Step: 6
Training loss: 2.3222346195496404
Validation loss: 2.6493155196206204

Epoch: 5| Step: 7
Training loss: 2.4253302752346384
Validation loss: 2.6756927995379414

Epoch: 5| Step: 8
Training loss: 2.2078708908232008
Validation loss: 2.6785773137853672

Epoch: 5| Step: 9
Training loss: 2.5528960406619556
Validation loss: 2.656499256693987

Epoch: 5| Step: 10
Training loss: 2.7897428649761875
Validation loss: 2.603421279715076

Epoch: 267| Step: 0
Training loss: 2.1539891871443926
Validation loss: 2.5552179155264163

Epoch: 5| Step: 1
Training loss: 2.2788129356511293
Validation loss: 2.50060530584609

Epoch: 5| Step: 2
Training loss: 2.2978154547205563
Validation loss: 2.486885020999548

Epoch: 5| Step: 3
Training loss: 2.4858545659951243
Validation loss: 2.49141461792507

Epoch: 5| Step: 4
Training loss: 2.4933816087948544
Validation loss: 2.4762656353307197

Epoch: 5| Step: 5
Training loss: 2.408047289729326
Validation loss: 2.499695951164247

Epoch: 5| Step: 6
Training loss: 2.6219387369513285
Validation loss: 2.545056030040578

Epoch: 5| Step: 7
Training loss: 2.3583079571476344
Validation loss: 2.5968131243529418

Epoch: 5| Step: 8
Training loss: 2.8649174905716226
Validation loss: 2.641527521049083

Epoch: 5| Step: 9
Training loss: 1.9918258637950104
Validation loss: 2.688058547567112

Epoch: 5| Step: 10
Training loss: 2.449219918136683
Validation loss: 2.7110465557587804

Epoch: 268| Step: 0
Training loss: 2.2696381903188034
Validation loss: 2.68893856190957

Epoch: 5| Step: 1
Training loss: 2.3274927496873996
Validation loss: 2.6924016418492513

Epoch: 5| Step: 2
Training loss: 2.162973288192568
Validation loss: 2.702494727816333

Epoch: 5| Step: 3
Training loss: 2.7847650154189085
Validation loss: 2.64730289398876

Epoch: 5| Step: 4
Training loss: 2.1312878647290487
Validation loss: 2.5851264665476434

Epoch: 5| Step: 5
Training loss: 2.442371684113492
Validation loss: 2.5124340044011917

Epoch: 5| Step: 6
Training loss: 2.886812076944104
Validation loss: 2.4777166590464237

Epoch: 5| Step: 7
Training loss: 2.1991972846005057
Validation loss: 2.448015040766647

Epoch: 5| Step: 8
Training loss: 2.737575031802514
Validation loss: 2.4467117775847345

Epoch: 5| Step: 9
Training loss: 1.8343558133371252
Validation loss: 2.445247278801958

Epoch: 5| Step: 10
Training loss: 2.4977024010865088
Validation loss: 2.4462716629712626

Epoch: 269| Step: 0
Training loss: 2.9774967839938715
Validation loss: 2.5050734292892574

Epoch: 5| Step: 1
Training loss: 2.274662382624186
Validation loss: 2.5523433155254165

Epoch: 5| Step: 2
Training loss: 1.8636666145322425
Validation loss: 2.600179058847563

Epoch: 5| Step: 3
Training loss: 2.2302034290395802
Validation loss: 2.6503326510996525

Epoch: 5| Step: 4
Training loss: 2.2102762588168265
Validation loss: 2.687815147632175

Epoch: 5| Step: 5
Training loss: 1.9714326292789943
Validation loss: 2.677677788245023

Epoch: 5| Step: 6
Training loss: 2.335951176734105
Validation loss: 2.664170841791117

Epoch: 5| Step: 7
Training loss: 2.569720724791718
Validation loss: 2.6476514436685576

Epoch: 5| Step: 8
Training loss: 3.0267253022528906
Validation loss: 2.6086746768407614

Epoch: 5| Step: 9
Training loss: 2.3912196199009754
Validation loss: 2.5494999577650543

Epoch: 5| Step: 10
Training loss: 2.321293376297527
Validation loss: 2.498135852551191

Epoch: 270| Step: 0
Training loss: 2.2636900959482915
Validation loss: 2.4724317443976114

Epoch: 5| Step: 1
Training loss: 2.1761132471544116
Validation loss: 2.4770340102352004

Epoch: 5| Step: 2
Training loss: 2.0714757566292525
Validation loss: 2.458640653617973

Epoch: 5| Step: 3
Training loss: 2.6489837893274064
Validation loss: 2.46166559410612

Epoch: 5| Step: 4
Training loss: 2.514249816706388
Validation loss: 2.540482621654087

Epoch: 5| Step: 5
Training loss: 2.6218281611008667
Validation loss: 2.593805062709919

Epoch: 5| Step: 6
Training loss: 1.6339996256927098
Validation loss: 2.6339414988793965

Epoch: 5| Step: 7
Training loss: 2.4359171692181465
Validation loss: 2.6399289688499685

Epoch: 5| Step: 8
Training loss: 2.792752429614497
Validation loss: 2.66638304819806

Epoch: 5| Step: 9
Training loss: 2.3994205212380004
Validation loss: 2.686989123510017

Epoch: 5| Step: 10
Training loss: 2.4354967541955923
Validation loss: 2.7163972048202

Epoch: 271| Step: 0
Training loss: 3.080969565979466
Validation loss: 2.7184315797794776

Epoch: 5| Step: 1
Training loss: 1.9955008684470423
Validation loss: 2.680031857535363

Epoch: 5| Step: 2
Training loss: 1.885417608046604
Validation loss: 2.679357956096062

Epoch: 5| Step: 3
Training loss: 2.2067869878313733
Validation loss: 2.6482109263060076

Epoch: 5| Step: 4
Training loss: 2.5511920125035403
Validation loss: 2.626752267570903

Epoch: 5| Step: 5
Training loss: 2.245555939349008
Validation loss: 2.5576455058795537

Epoch: 5| Step: 6
Training loss: 3.0397669115553767
Validation loss: 2.51365989751493

Epoch: 5| Step: 7
Training loss: 2.4829301771408887
Validation loss: 2.4710285393188074

Epoch: 5| Step: 8
Training loss: 2.383390162752988
Validation loss: 2.45018063495231

Epoch: 5| Step: 9
Training loss: 2.0272174421004157
Validation loss: 2.465173237527296

Epoch: 5| Step: 10
Training loss: 2.141134716522549
Validation loss: 2.468140447549731

Epoch: 272| Step: 0
Training loss: 2.7131955639341325
Validation loss: 2.4752337795608166

Epoch: 5| Step: 1
Training loss: 2.3030124590226544
Validation loss: 2.4995591487627724

Epoch: 5| Step: 2
Training loss: 2.4797946764950605
Validation loss: 2.4829545658484746

Epoch: 5| Step: 3
Training loss: 2.424283214699145
Validation loss: 2.507186415369867

Epoch: 5| Step: 4
Training loss: 1.953739283282761
Validation loss: 2.5152792693346946

Epoch: 5| Step: 5
Training loss: 2.4249358493145783
Validation loss: 2.5444435699734127

Epoch: 5| Step: 6
Training loss: 2.1361284015795183
Validation loss: 2.58925472875249

Epoch: 5| Step: 7
Training loss: 2.2458148816352748
Validation loss: 2.6265460596972345

Epoch: 5| Step: 8
Training loss: 1.58814810791979
Validation loss: 2.6326154239100203

Epoch: 5| Step: 9
Training loss: 2.6888171672013095
Validation loss: 2.668032939005819

Epoch: 5| Step: 10
Training loss: 2.784048665421556
Validation loss: 2.6392601501865034

Epoch: 273| Step: 0
Training loss: 2.2720012519524038
Validation loss: 2.6567932953435927

Epoch: 5| Step: 1
Training loss: 2.2725985837395353
Validation loss: 2.6507526384156503

Epoch: 5| Step: 2
Training loss: 2.3011835909020526
Validation loss: 2.6075023395824086

Epoch: 5| Step: 3
Training loss: 2.102245460914541
Validation loss: 2.520060914565347

Epoch: 5| Step: 4
Training loss: 2.1750128603149452
Validation loss: 2.5014561626942826

Epoch: 5| Step: 5
Training loss: 2.625005540387801
Validation loss: 2.4626451356155132

Epoch: 5| Step: 6
Training loss: 2.5562471534321425
Validation loss: 2.4651725522045007

Epoch: 5| Step: 7
Training loss: 2.525445286984553
Validation loss: 2.4748265292323985

Epoch: 5| Step: 8
Training loss: 2.302231440087909
Validation loss: 2.500306088157537

Epoch: 5| Step: 9
Training loss: 2.699444685449629
Validation loss: 2.548022639428645

Epoch: 5| Step: 10
Training loss: 2.0548268550131548
Validation loss: 2.598724238952785

Epoch: 274| Step: 0
Training loss: 1.6836071323650637
Validation loss: 2.677231075716816

Epoch: 5| Step: 1
Training loss: 2.46850333611238
Validation loss: 2.704649402985657

Epoch: 5| Step: 2
Training loss: 2.9256223424073493
Validation loss: 2.7421415124297526

Epoch: 5| Step: 3
Training loss: 2.4154456660532686
Validation loss: 2.72187940205056

Epoch: 5| Step: 4
Training loss: 2.491095324517414
Validation loss: 2.6260053405879855

Epoch: 5| Step: 5
Training loss: 2.179347295429124
Validation loss: 2.5581798317288897

Epoch: 5| Step: 6
Training loss: 2.094118455948456
Validation loss: 2.505239192852826

Epoch: 5| Step: 7
Training loss: 2.0275691794600594
Validation loss: 2.479139229269425

Epoch: 5| Step: 8
Training loss: 2.5265381839598873
Validation loss: 2.4748202641798764

Epoch: 5| Step: 9
Training loss: 2.7691182634330844
Validation loss: 2.4964819232126376

Epoch: 5| Step: 10
Training loss: 2.189303934967808
Validation loss: 2.49882855297991

Epoch: 275| Step: 0
Training loss: 2.3387500582296914
Validation loss: 2.5181520335291534

Epoch: 5| Step: 1
Training loss: 1.9518852266354607
Validation loss: 2.5790697710323873

Epoch: 5| Step: 2
Training loss: 3.1146039845133893
Validation loss: 2.5766949717023455

Epoch: 5| Step: 3
Training loss: 2.456792240617002
Validation loss: 2.6355512407048693

Epoch: 5| Step: 4
Training loss: 2.5020851975899094
Validation loss: 2.6864836655762496

Epoch: 5| Step: 5
Training loss: 2.1552258699298874
Validation loss: 2.699266146973305

Epoch: 5| Step: 6
Training loss: 2.5694075733552153
Validation loss: 2.6782788064975245

Epoch: 5| Step: 7
Training loss: 2.4361519631653272
Validation loss: 2.650693852282839

Epoch: 5| Step: 8
Training loss: 2.125675767148183
Validation loss: 2.59008884515264

Epoch: 5| Step: 9
Training loss: 1.6941729816269662
Validation loss: 2.558845071442544

Epoch: 5| Step: 10
Training loss: 2.069218414843546
Validation loss: 2.5121032974694932

Epoch: 276| Step: 0
Training loss: 2.1380435943940763
Validation loss: 2.4789815909287936

Epoch: 5| Step: 1
Training loss: 2.5216196793613683
Validation loss: 2.489511339942983

Epoch: 5| Step: 2
Training loss: 2.510456913246878
Validation loss: 2.505544402565436

Epoch: 5| Step: 3
Training loss: 2.673879663320408
Validation loss: 2.5314993999432587

Epoch: 5| Step: 4
Training loss: 2.137075335162329
Validation loss: 2.5218143488218927

Epoch: 5| Step: 5
Training loss: 2.585692056953247
Validation loss: 2.5562385114944224

Epoch: 5| Step: 6
Training loss: 2.20943947445733
Validation loss: 2.5776428308738426

Epoch: 5| Step: 7
Training loss: 1.804120061270964
Validation loss: 2.618174206732713

Epoch: 5| Step: 8
Training loss: 2.0619300285921582
Validation loss: 2.6476230189910357

Epoch: 5| Step: 9
Training loss: 2.5615744431158958
Validation loss: 2.6656810422084956

Epoch: 5| Step: 10
Training loss: 2.382661208055616
Validation loss: 2.6354737705858486

Epoch: 277| Step: 0
Training loss: 2.597708198200022
Validation loss: 2.56004911298549

Epoch: 5| Step: 1
Training loss: 2.346984767251629
Validation loss: 2.5036663970604165

Epoch: 5| Step: 2
Training loss: 1.645957201710689
Validation loss: 2.467991120501747

Epoch: 5| Step: 3
Training loss: 2.2569721070249025
Validation loss: 2.440698167856625

Epoch: 5| Step: 4
Training loss: 2.2967205384925684
Validation loss: 2.460912995184696

Epoch: 5| Step: 5
Training loss: 2.2988950189728232
Validation loss: 2.4448890679810225

Epoch: 5| Step: 6
Training loss: 2.1435606936846376
Validation loss: 2.4810775597520904

Epoch: 5| Step: 7
Training loss: 2.2315436076545243
Validation loss: 2.499670240742316

Epoch: 5| Step: 8
Training loss: 2.5487253219509847
Validation loss: 2.554511502312876

Epoch: 5| Step: 9
Training loss: 3.023967213518536
Validation loss: 2.623445266279919

Epoch: 5| Step: 10
Training loss: 2.209127703130861
Validation loss: 2.6060273451584886

Epoch: 278| Step: 0
Training loss: 1.9613791648485517
Validation loss: 2.6240953096492703

Epoch: 5| Step: 1
Training loss: 1.8644459281317338
Validation loss: 2.637818441766115

Epoch: 5| Step: 2
Training loss: 2.4211146976319307
Validation loss: 2.5813915104348277

Epoch: 5| Step: 3
Training loss: 1.8790925185411453
Validation loss: 2.599222987035075

Epoch: 5| Step: 4
Training loss: 1.9800329086189117
Validation loss: 2.5888742494992965

Epoch: 5| Step: 5
Training loss: 2.1502743168974825
Validation loss: 2.553243274956228

Epoch: 5| Step: 6
Training loss: 2.4174790387196587
Validation loss: 2.5456621040124894

Epoch: 5| Step: 7
Training loss: 2.4962201153643013
Validation loss: 2.4860284036903884

Epoch: 5| Step: 8
Training loss: 2.2108805618772625
Validation loss: 2.4619185047676044

Epoch: 5| Step: 9
Training loss: 2.8277513457409658
Validation loss: 2.4388464024382035

Epoch: 5| Step: 10
Training loss: 2.9225084566723307
Validation loss: 2.442740136700906

Epoch: 279| Step: 0
Training loss: 2.302946409343179
Validation loss: 2.425575532308571

Epoch: 5| Step: 1
Training loss: 2.1989016261906347
Validation loss: 2.419171943861272

Epoch: 5| Step: 2
Training loss: 2.0398785942079165
Validation loss: 2.4769904730636196

Epoch: 5| Step: 3
Training loss: 2.5498043134813972
Validation loss: 2.503657771764284

Epoch: 5| Step: 4
Training loss: 2.0210274147616754
Validation loss: 2.5494271179562253

Epoch: 5| Step: 5
Training loss: 2.2228806420946277
Validation loss: 2.595724927234938

Epoch: 5| Step: 6
Training loss: 2.6263259082193287
Validation loss: 2.6558272506104834

Epoch: 5| Step: 7
Training loss: 1.8728481660677436
Validation loss: 2.649612446363518

Epoch: 5| Step: 8
Training loss: 2.4570198968524966
Validation loss: 2.6534074585307508

Epoch: 5| Step: 9
Training loss: 2.084179083497242
Validation loss: 2.6350609057998216

Epoch: 5| Step: 10
Training loss: 2.7345775420242715
Validation loss: 2.609097999615597

Epoch: 280| Step: 0
Training loss: 1.82956703890578
Validation loss: 2.592930224008844

Epoch: 5| Step: 1
Training loss: 1.4251056063151955
Validation loss: 2.5506149042020287

Epoch: 5| Step: 2
Training loss: 1.8033277004292643
Validation loss: 2.52637624111694

Epoch: 5| Step: 3
Training loss: 1.8216823940639404
Validation loss: 2.558675896400587

Epoch: 5| Step: 4
Training loss: 2.786152665434876
Validation loss: 2.5244066206201015

Epoch: 5| Step: 5
Training loss: 2.448706760462872
Validation loss: 2.5648512439121602

Epoch: 5| Step: 6
Training loss: 2.3078819765494694
Validation loss: 2.598424407632189

Epoch: 5| Step: 7
Training loss: 2.1183315437763537
Validation loss: 2.6302774841581904

Epoch: 5| Step: 8
Training loss: 2.1796319332354908
Validation loss: 2.6536144126041368

Epoch: 5| Step: 9
Training loss: 2.7184758541402307
Validation loss: 2.6013867999677784

Epoch: 5| Step: 10
Training loss: 3.075019935605315
Validation loss: 2.5762266775359444

Epoch: 281| Step: 0
Training loss: 1.7208620446175296
Validation loss: 2.569013983526403

Epoch: 5| Step: 1
Training loss: 2.007672137983504
Validation loss: 2.5168889148937157

Epoch: 5| Step: 2
Training loss: 2.5283282336202686
Validation loss: 2.513330852333455

Epoch: 5| Step: 3
Training loss: 2.4728105204639492
Validation loss: 2.510361683908508

Epoch: 5| Step: 4
Training loss: 2.0351099752191706
Validation loss: 2.534606063133922

Epoch: 5| Step: 5
Training loss: 2.177067977145366
Validation loss: 2.5730359117617145

Epoch: 5| Step: 6
Training loss: 2.340293471689047
Validation loss: 2.6098589557357195

Epoch: 5| Step: 7
Training loss: 2.3167191241063296
Validation loss: 2.6530637544171496

Epoch: 5| Step: 8
Training loss: 2.4054297498246653
Validation loss: 2.6574341423744676

Epoch: 5| Step: 9
Training loss: 2.5529594526466552
Validation loss: 2.6153993985591595

Epoch: 5| Step: 10
Training loss: 2.2311741236332727
Validation loss: 2.5871353847231497

Epoch: 282| Step: 0
Training loss: 2.1086919738347603
Validation loss: 2.53062302676145

Epoch: 5| Step: 1
Training loss: 2.478098203651279
Validation loss: 2.5338413566305427

Epoch: 5| Step: 2
Training loss: 2.331737608449588
Validation loss: 2.51970037026435

Epoch: 5| Step: 3
Training loss: 2.6772076668174005
Validation loss: 2.5096248528016463

Epoch: 5| Step: 4
Training loss: 1.79493024323913
Validation loss: 2.5493357407075226

Epoch: 5| Step: 5
Training loss: 2.714404085632811
Validation loss: 2.5513420436402865

Epoch: 5| Step: 6
Training loss: 2.225690490221891
Validation loss: 2.585868530920083

Epoch: 5| Step: 7
Training loss: 2.224528993622973
Validation loss: 2.593153344152349

Epoch: 5| Step: 8
Training loss: 1.9325008501887455
Validation loss: 2.60024363170626

Epoch: 5| Step: 9
Training loss: 1.9415035108308096
Validation loss: 2.590108794266788

Epoch: 5| Step: 10
Training loss: 2.2670640255872927
Validation loss: 2.569005965319891

Epoch: 283| Step: 0
Training loss: 2.6718455530518215
Validation loss: 2.565989036134382

Epoch: 5| Step: 1
Training loss: 2.4630179194589568
Validation loss: 2.528708949452002

Epoch: 5| Step: 2
Training loss: 2.1995527376346278
Validation loss: 2.4955826187433576

Epoch: 5| Step: 3
Training loss: 2.0278470217699294
Validation loss: 2.504958213559314

Epoch: 5| Step: 4
Training loss: 1.7811184884762905
Validation loss: 2.537333961925233

Epoch: 5| Step: 5
Training loss: 2.12439472329618
Validation loss: 2.55880366064476

Epoch: 5| Step: 6
Training loss: 2.463758420112114
Validation loss: 2.5843929462305995

Epoch: 5| Step: 7
Training loss: 1.8849327843417139
Validation loss: 2.6053324895905616

Epoch: 5| Step: 8
Training loss: 2.0837682524341075
Validation loss: 2.5809906139320797

Epoch: 5| Step: 9
Training loss: 2.1628310903767978
Validation loss: 2.6052992243589808

Epoch: 5| Step: 10
Training loss: 2.5582551921462624
Validation loss: 2.634953094052168

Epoch: 284| Step: 0
Training loss: 2.40454011084944
Validation loss: 2.6359576340825415

Epoch: 5| Step: 1
Training loss: 2.3289070607989824
Validation loss: 2.6183774434407523

Epoch: 5| Step: 2
Training loss: 1.3547558407556408
Validation loss: 2.5752074905827995

Epoch: 5| Step: 3
Training loss: 2.0123675142832944
Validation loss: 2.5601487576457793

Epoch: 5| Step: 4
Training loss: 2.2842385560498766
Validation loss: 2.545704526163403

Epoch: 5| Step: 5
Training loss: 2.340390149546333
Validation loss: 2.5477599003279385

Epoch: 5| Step: 6
Training loss: 2.297237341709447
Validation loss: 2.5695711771064276

Epoch: 5| Step: 7
Training loss: 2.356305076704193
Validation loss: 2.561313639652691

Epoch: 5| Step: 8
Training loss: 2.1598112027345167
Validation loss: 2.5718924064716546

Epoch: 5| Step: 9
Training loss: 2.468718130171566
Validation loss: 2.594435770068407

Epoch: 5| Step: 10
Training loss: 2.422099047726387
Validation loss: 2.634428492159801

Epoch: 285| Step: 0
Training loss: 2.085743527198102
Validation loss: 2.621847506931229

Epoch: 5| Step: 1
Training loss: 1.4261312812789224
Validation loss: 2.6154770868892334

Epoch: 5| Step: 2
Training loss: 2.525532328324536
Validation loss: 2.566196763431715

Epoch: 5| Step: 3
Training loss: 2.5019144357493595
Validation loss: 2.5529617195906757

Epoch: 5| Step: 4
Training loss: 2.0479854454477024
Validation loss: 2.5137859438149492

Epoch: 5| Step: 5
Training loss: 1.9593858393075756
Validation loss: 2.496578926536362

Epoch: 5| Step: 6
Training loss: 1.9567345795984539
Validation loss: 2.4929424264638924

Epoch: 5| Step: 7
Training loss: 2.411992935891506
Validation loss: 2.47509390726487

Epoch: 5| Step: 8
Training loss: 2.670118769743652
Validation loss: 2.506553980439834

Epoch: 5| Step: 9
Training loss: 2.2046946892462294
Validation loss: 2.538266906030148

Epoch: 5| Step: 10
Training loss: 2.511426466670178
Validation loss: 2.61451250513187

Epoch: 286| Step: 0
Training loss: 2.4307886308603472
Validation loss: 2.620309356840781

Epoch: 5| Step: 1
Training loss: 2.073185837743994
Validation loss: 2.5999326164357957

Epoch: 5| Step: 2
Training loss: 2.3021321241176693
Validation loss: 2.5608126839939462

Epoch: 5| Step: 3
Training loss: 2.1225553924557468
Validation loss: 2.5497329563641085

Epoch: 5| Step: 4
Training loss: 2.054071950631024
Validation loss: 2.5292410890577774

Epoch: 5| Step: 5
Training loss: 1.9885017557536875
Validation loss: 2.4926140532981305

Epoch: 5| Step: 6
Training loss: 2.551426664195174
Validation loss: 2.4874122665581546

Epoch: 5| Step: 7
Training loss: 2.232536359706625
Validation loss: 2.5013615253954478

Epoch: 5| Step: 8
Training loss: 2.5028628170324856
Validation loss: 2.5581916127966395

Epoch: 5| Step: 9
Training loss: 2.253436008104257
Validation loss: 2.5862979219504707

Epoch: 5| Step: 10
Training loss: 1.810947674252858
Validation loss: 2.659691552746154

Epoch: 287| Step: 0
Training loss: 2.377648432898583
Validation loss: 2.671080396238334

Epoch: 5| Step: 1
Training loss: 2.396900392718635
Validation loss: 2.6749183139360233

Epoch: 5| Step: 2
Training loss: 1.317324174010009
Validation loss: 2.6369030731322005

Epoch: 5| Step: 3
Training loss: 2.42955620217738
Validation loss: 2.6231737625445177

Epoch: 5| Step: 4
Training loss: 1.9171126993847634
Validation loss: 2.566644687688995

Epoch: 5| Step: 5
Training loss: 2.007423571014133
Validation loss: 2.5237557571695635

Epoch: 5| Step: 6
Training loss: 2.4866704353051694
Validation loss: 2.472541808896103

Epoch: 5| Step: 7
Training loss: 2.4288232376278667
Validation loss: 2.482090864891251

Epoch: 5| Step: 8
Training loss: 1.8493452356849795
Validation loss: 2.4930459250840373

Epoch: 5| Step: 9
Training loss: 2.545181366579156
Validation loss: 2.516263763627439

Epoch: 5| Step: 10
Training loss: 2.2525080371844552
Validation loss: 2.600394510064354

Epoch: 288| Step: 0
Training loss: 2.0846960824164467
Validation loss: 2.66742374808359

Epoch: 5| Step: 1
Training loss: 2.2539229632043902
Validation loss: 2.717573587232746

Epoch: 5| Step: 2
Training loss: 2.435505270889396
Validation loss: 2.7115684343178548

Epoch: 5| Step: 3
Training loss: 1.862489160083742
Validation loss: 2.7107596409241177

Epoch: 5| Step: 4
Training loss: 2.002139615932668
Validation loss: 2.63771772401129

Epoch: 5| Step: 5
Training loss: 2.9662805827509757
Validation loss: 2.5963970405460954

Epoch: 5| Step: 6
Training loss: 1.8699745223405801
Validation loss: 2.553340879452879

Epoch: 5| Step: 7
Training loss: 2.396714476938391
Validation loss: 2.5184537747936013

Epoch: 5| Step: 8
Training loss: 1.73034695095484
Validation loss: 2.5154409767366626

Epoch: 5| Step: 9
Training loss: 1.8453825495616578
Validation loss: 2.5052970921843727

Epoch: 5| Step: 10
Training loss: 2.5095543442196657
Validation loss: 2.5114426359418975

Epoch: 289| Step: 0
Training loss: 1.922971521203383
Validation loss: 2.480942519675594

Epoch: 5| Step: 1
Training loss: 2.2121066719050786
Validation loss: 2.4985527176747353

Epoch: 5| Step: 2
Training loss: 1.9252192236185672
Validation loss: 2.514146871304655

Epoch: 5| Step: 3
Training loss: 2.693903634985146
Validation loss: 2.4984967059899246

Epoch: 5| Step: 4
Training loss: 2.492184534340173
Validation loss: 2.4966116318590554

Epoch: 5| Step: 5
Training loss: 1.7154004142806096
Validation loss: 2.5391858536484198

Epoch: 5| Step: 6
Training loss: 2.2625195497121324
Validation loss: 2.574655634099423

Epoch: 5| Step: 7
Training loss: 2.320361615312982
Validation loss: 2.577471782406972

Epoch: 5| Step: 8
Training loss: 2.084476487921783
Validation loss: 2.6660319918626283

Epoch: 5| Step: 9
Training loss: 2.5325017589024483
Validation loss: 2.7117438154360602

Epoch: 5| Step: 10
Training loss: 1.7854281495955429
Validation loss: 2.7368821704850577

Epoch: 290| Step: 0
Training loss: 2.561850674865742
Validation loss: 2.717737324456576

Epoch: 5| Step: 1
Training loss: 2.789137980831523
Validation loss: 2.634778605830303

Epoch: 5| Step: 2
Training loss: 2.37679243210673
Validation loss: 2.55936508043567

Epoch: 5| Step: 3
Training loss: 2.0963046303024147
Validation loss: 2.5180149973303676

Epoch: 5| Step: 4
Training loss: 1.906701706695473
Validation loss: 2.5103592237796124

Epoch: 5| Step: 5
Training loss: 1.668852239327123
Validation loss: 2.4929503165384648

Epoch: 5| Step: 6
Training loss: 2.8122816212962154
Validation loss: 2.47545866069805

Epoch: 5| Step: 7
Training loss: 1.8465536105783964
Validation loss: 2.463299282498642

Epoch: 5| Step: 8
Training loss: 2.085398515081787
Validation loss: 2.5262633750413586

Epoch: 5| Step: 9
Training loss: 1.9305978087353222
Validation loss: 2.571646859073033

Epoch: 5| Step: 10
Training loss: 1.6282391908984717
Validation loss: 2.6699133811180826

Epoch: 291| Step: 0
Training loss: 2.2324538074255464
Validation loss: 2.7498605651781944

Epoch: 5| Step: 1
Training loss: 2.2850462797390594
Validation loss: 2.7843265751729267

Epoch: 5| Step: 2
Training loss: 1.8152583607254014
Validation loss: 2.7883527659340275

Epoch: 5| Step: 3
Training loss: 1.9451204994158908
Validation loss: 2.677912689009306

Epoch: 5| Step: 4
Training loss: 2.129880573703546
Validation loss: 2.6048444362252208

Epoch: 5| Step: 5
Training loss: 2.0498733109195584
Validation loss: 2.552493593357492

Epoch: 5| Step: 6
Training loss: 2.413086727918729
Validation loss: 2.5207262076593833

Epoch: 5| Step: 7
Training loss: 2.253593436339451
Validation loss: 2.4829942990737894

Epoch: 5| Step: 8
Training loss: 2.122266694491149
Validation loss: 2.474180341429891

Epoch: 5| Step: 9
Training loss: 2.7795126128221916
Validation loss: 2.515178796003637

Epoch: 5| Step: 10
Training loss: 2.182348889410184
Validation loss: 2.5340303307655714

Epoch: 292| Step: 0
Training loss: 2.2674213522800817
Validation loss: 2.5570725449710006

Epoch: 5| Step: 1
Training loss: 2.3804332423777894
Validation loss: 2.6182801567818674

Epoch: 5| Step: 2
Training loss: 2.4167246537541236
Validation loss: 2.6405733504792823

Epoch: 5| Step: 3
Training loss: 2.116120805216013
Validation loss: 2.659312880349546

Epoch: 5| Step: 4
Training loss: 2.6664913437747706
Validation loss: 2.6739411218092464

Epoch: 5| Step: 5
Training loss: 2.3842525945719135
Validation loss: 2.6641406861330577

Epoch: 5| Step: 6
Training loss: 2.153055007749231
Validation loss: 2.6143115930783827

Epoch: 5| Step: 7
Training loss: 2.003136797556303
Validation loss: 2.5544548539620275

Epoch: 5| Step: 8
Training loss: 1.673788953787935
Validation loss: 2.558295076621377

Epoch: 5| Step: 9
Training loss: 1.7777976326363532
Validation loss: 2.511165372621194

Epoch: 5| Step: 10
Training loss: 2.044047841992154
Validation loss: 2.5382319538513807

Epoch: 293| Step: 0
Training loss: 2.3209821460436566
Validation loss: 2.5453369843682134

Epoch: 5| Step: 1
Training loss: 2.1166944316735083
Validation loss: 2.5317903603010645

Epoch: 5| Step: 2
Training loss: 2.730604001953527
Validation loss: 2.550958145214695

Epoch: 5| Step: 3
Training loss: 1.7295665584967772
Validation loss: 2.535698323622449

Epoch: 5| Step: 4
Training loss: 2.156197699313347
Validation loss: 2.533587767920677

Epoch: 5| Step: 5
Training loss: 2.1599700461182727
Validation loss: 2.515997823681304

Epoch: 5| Step: 6
Training loss: 2.293690452530334
Validation loss: 2.4972262961995657

Epoch: 5| Step: 7
Training loss: 1.8767809992372313
Validation loss: 2.509981452539338

Epoch: 5| Step: 8
Training loss: 2.0853801082591277
Validation loss: 2.498414128302267

Epoch: 5| Step: 9
Training loss: 1.9079258540639656
Validation loss: 2.5036580958469994

Epoch: 5| Step: 10
Training loss: 2.1907021110338873
Validation loss: 2.500731464763625

Epoch: 294| Step: 0
Training loss: 2.868432047724776
Validation loss: 2.5298994080147486

Epoch: 5| Step: 1
Training loss: 2.66011089896869
Validation loss: 2.543394765776282

Epoch: 5| Step: 2
Training loss: 1.5312022766150168
Validation loss: 2.581517752217267

Epoch: 5| Step: 3
Training loss: 1.9121371180515772
Validation loss: 2.5758512676019936

Epoch: 5| Step: 4
Training loss: 1.651928572202779
Validation loss: 2.536620311000072

Epoch: 5| Step: 5
Training loss: 1.9769180641464716
Validation loss: 2.5279438684381152

Epoch: 5| Step: 6
Training loss: 1.9969366574506662
Validation loss: 2.5411591778844143

Epoch: 5| Step: 7
Training loss: 2.4224858651865873
Validation loss: 2.551446156990731

Epoch: 5| Step: 8
Training loss: 2.199914852575332
Validation loss: 2.5593045026903964

Epoch: 5| Step: 9
Training loss: 2.126369147441287
Validation loss: 2.578307121558786

Epoch: 5| Step: 10
Training loss: 1.6772645019231824
Validation loss: 2.5590217758972624

Epoch: 295| Step: 0
Training loss: 1.8256499661544316
Validation loss: 2.5521503097320926

Epoch: 5| Step: 1
Training loss: 2.1037000258296183
Validation loss: 2.520059610395227

Epoch: 5| Step: 2
Training loss: 1.862319986233536
Validation loss: 2.536941825546133

Epoch: 5| Step: 3
Training loss: 1.767002884642789
Validation loss: 2.519454549156296

Epoch: 5| Step: 4
Training loss: 2.342635029389002
Validation loss: 2.5404172392041415

Epoch: 5| Step: 5
Training loss: 2.256645455403942
Validation loss: 2.555769560578543

Epoch: 5| Step: 6
Training loss: 2.4368047456283097
Validation loss: 2.5490217524517487

Epoch: 5| Step: 7
Training loss: 2.7543697318867855
Validation loss: 2.5596201451355443

Epoch: 5| Step: 8
Training loss: 2.410846629874725
Validation loss: 2.5502083301797436

Epoch: 5| Step: 9
Training loss: 1.4654164733250266
Validation loss: 2.5537219400925113

Epoch: 5| Step: 10
Training loss: 1.7548980966962748
Validation loss: 2.512451416127089

Epoch: 296| Step: 0
Training loss: 2.0258595467297758
Validation loss: 2.516801931142665

Epoch: 5| Step: 1
Training loss: 1.8150828144526996
Validation loss: 2.500312620531005

Epoch: 5| Step: 2
Training loss: 1.9372663049350165
Validation loss: 2.5027972907221874

Epoch: 5| Step: 3
Training loss: 2.001345182081741
Validation loss: 2.5110470948605026

Epoch: 5| Step: 4
Training loss: 2.2339836791628245
Validation loss: 2.5106976705456656

Epoch: 5| Step: 5
Training loss: 1.841651692336757
Validation loss: 2.548204084391401

Epoch: 5| Step: 6
Training loss: 1.9556503449331026
Validation loss: 2.5507638657404996

Epoch: 5| Step: 7
Training loss: 2.547600016928176
Validation loss: 2.5517719861576498

Epoch: 5| Step: 8
Training loss: 2.1178212923945625
Validation loss: 2.5225392034900187

Epoch: 5| Step: 9
Training loss: 2.7810703176684344
Validation loss: 2.5184043124913806

Epoch: 5| Step: 10
Training loss: 1.752294194630086
Validation loss: 2.520372545079768

Epoch: 297| Step: 0
Training loss: 2.5335315735533857
Validation loss: 2.4884752998394015

Epoch: 5| Step: 1
Training loss: 1.5772804039700115
Validation loss: 2.508071956528523

Epoch: 5| Step: 2
Training loss: 1.6371162314283916
Validation loss: 2.5265042912210363

Epoch: 5| Step: 3
Training loss: 1.825751304136038
Validation loss: 2.5528880104937635

Epoch: 5| Step: 4
Training loss: 1.3798597459424238
Validation loss: 2.549879001494941

Epoch: 5| Step: 5
Training loss: 2.4413521478380416
Validation loss: 2.553224967139823

Epoch: 5| Step: 6
Training loss: 2.725753270599046
Validation loss: 2.5591420748148797

Epoch: 5| Step: 7
Training loss: 2.145457472490627
Validation loss: 2.5256717013038865

Epoch: 5| Step: 8
Training loss: 1.9418710194507929
Validation loss: 2.55601350394489

Epoch: 5| Step: 9
Training loss: 2.223716871627027
Validation loss: 2.5042884540971158

Epoch: 5| Step: 10
Training loss: 2.2336118235061995
Validation loss: 2.4861835932363365

Epoch: 298| Step: 0
Training loss: 1.69392035496827
Validation loss: 2.476797442428059

Epoch: 5| Step: 1
Training loss: 2.4283308062238076
Validation loss: 2.495233538809176

Epoch: 5| Step: 2
Training loss: 2.1521676159357384
Validation loss: 2.4787197290978167

Epoch: 5| Step: 3
Training loss: 2.373777878182268
Validation loss: 2.487852694598449

Epoch: 5| Step: 4
Training loss: 2.5175422328524215
Validation loss: 2.482069092206622

Epoch: 5| Step: 5
Training loss: 2.0478171007770354
Validation loss: 2.522289774397282

Epoch: 5| Step: 6
Training loss: 1.9728141494857683
Validation loss: 2.5664278575990083

Epoch: 5| Step: 7
Training loss: 1.6338295575291906
Validation loss: 2.6186996438281382

Epoch: 5| Step: 8
Training loss: 1.5488018019220415
Validation loss: 2.6134758877762136

Epoch: 5| Step: 9
Training loss: 2.2010988698934875
Validation loss: 2.5771185229450175

Epoch: 5| Step: 10
Training loss: 2.327412438635529
Validation loss: 2.5705117257745966

Epoch: 299| Step: 0
Training loss: 2.006758476303104
Validation loss: 2.5357060943069776

Epoch: 5| Step: 1
Training loss: 1.8049344641076337
Validation loss: 2.5271923073509837

Epoch: 5| Step: 2
Training loss: 2.266220645872239
Validation loss: 2.5231114552168106

Epoch: 5| Step: 3
Training loss: 2.175945392217955
Validation loss: 2.556414990977827

Epoch: 5| Step: 4
Training loss: 2.3664949618990536
Validation loss: 2.5703148199612604

Epoch: 5| Step: 5
Training loss: 2.308740188420818
Validation loss: 2.5937457538663384

Epoch: 5| Step: 6
Training loss: 2.3223831750171597
Validation loss: 2.5911367778070526

Epoch: 5| Step: 7
Training loss: 1.7117551478490562
Validation loss: 2.5876047888465226

Epoch: 5| Step: 8
Training loss: 1.6082971908118813
Validation loss: 2.5256982422526137

Epoch: 5| Step: 9
Training loss: 2.0707878286887125
Validation loss: 2.4795252319310963

Epoch: 5| Step: 10
Training loss: 2.3294763931221283
Validation loss: 2.4448742914688766

Epoch: 300| Step: 0
Training loss: 2.030886573558012
Validation loss: 2.4254937886955115

Epoch: 5| Step: 1
Training loss: 2.171224482973294
Validation loss: 2.3950128438860676

Epoch: 5| Step: 2
Training loss: 2.076415427161329
Validation loss: 2.388586720802218

Epoch: 5| Step: 3
Training loss: 1.9739448191264868
Validation loss: 2.4658020137114796

Epoch: 5| Step: 4
Training loss: 1.6924489531714646
Validation loss: 2.473468979179336

Epoch: 5| Step: 5
Training loss: 1.9457293450657205
Validation loss: 2.487505215660857

Epoch: 5| Step: 6
Training loss: 2.0616840713781928
Validation loss: 2.5207039174320416

Epoch: 5| Step: 7
Training loss: 2.2875753004677373
Validation loss: 2.526398585816131

Epoch: 5| Step: 8
Training loss: 1.943994159634769
Validation loss: 2.5310505988871603

Epoch: 5| Step: 9
Training loss: 2.2571084795950034
Validation loss: 2.5198289366414133

Epoch: 5| Step: 10
Training loss: 2.6805898854149737
Validation loss: 2.5447494320856245

Epoch: 301| Step: 0
Training loss: 2.1040916681300477
Validation loss: 2.5383850233799805

Epoch: 5| Step: 1
Training loss: 2.129992510643629
Validation loss: 2.50966185312974

Epoch: 5| Step: 2
Training loss: 2.267499687421918
Validation loss: 2.5023516863874766

Epoch: 5| Step: 3
Training loss: 1.9591281035649453
Validation loss: 2.510565740602834

Epoch: 5| Step: 4
Training loss: 2.2985706946849285
Validation loss: 2.5031755357766214

Epoch: 5| Step: 5
Training loss: 1.9037397772852045
Validation loss: 2.4958792205963314

Epoch: 5| Step: 6
Training loss: 1.8300666605163851
Validation loss: 2.4917631227406076

Epoch: 5| Step: 7
Training loss: 1.8659699752043863
Validation loss: 2.467712210695959

Epoch: 5| Step: 8
Training loss: 2.2290697403510356
Validation loss: 2.4442426169215765

Epoch: 5| Step: 9
Training loss: 2.317249061142273
Validation loss: 2.4264883993177757

Epoch: 5| Step: 10
Training loss: 1.9913524597972667
Validation loss: 2.4367816488113223

Epoch: 302| Step: 0
Training loss: 2.01591253078019
Validation loss: 2.445378155576991

Epoch: 5| Step: 1
Training loss: 2.207898103062798
Validation loss: 2.4863142093021917

Epoch: 5| Step: 2
Training loss: 2.2114600113442933
Validation loss: 2.51152642968754

Epoch: 5| Step: 3
Training loss: 1.5089506291174313
Validation loss: 2.5364119352879526

Epoch: 5| Step: 4
Training loss: 1.8613771189979285
Validation loss: 2.5881906137941475

Epoch: 5| Step: 5
Training loss: 2.4922802946698646
Validation loss: 2.5792172571525414

Epoch: 5| Step: 6
Training loss: 1.549400502834039
Validation loss: 2.55523157536879

Epoch: 5| Step: 7
Training loss: 2.2831289835722033
Validation loss: 2.5223297539453258

Epoch: 5| Step: 8
Training loss: 2.467078693447594
Validation loss: 2.481674519063541

Epoch: 5| Step: 9
Training loss: 2.203855893798109
Validation loss: 2.46756104634668

Epoch: 5| Step: 10
Training loss: 1.7277186738658525
Validation loss: 2.466498326693701

Epoch: 303| Step: 0
Training loss: 1.888862103228668
Validation loss: 2.4708474557381654

Epoch: 5| Step: 1
Training loss: 2.2003877558148566
Validation loss: 2.466545017491488

Epoch: 5| Step: 2
Training loss: 1.9385430389459568
Validation loss: 2.486491306935066

Epoch: 5| Step: 3
Training loss: 2.1667703701534915
Validation loss: 2.5026708579528236

Epoch: 5| Step: 4
Training loss: 2.1233571377691933
Validation loss: 2.534966435965979

Epoch: 5| Step: 5
Training loss: 1.90563535943348
Validation loss: 2.5235928637134766

Epoch: 5| Step: 6
Training loss: 1.6972151947430962
Validation loss: 2.535950367374742

Epoch: 5| Step: 7
Training loss: 2.189365899069533
Validation loss: 2.5256864872492675

Epoch: 5| Step: 8
Training loss: 2.165538958977446
Validation loss: 2.499216931256024

Epoch: 5| Step: 9
Training loss: 2.265411366881046
Validation loss: 2.496765934618696

Epoch: 5| Step: 10
Training loss: 1.9349635965042735
Validation loss: 2.5148822195082343

Epoch: 304| Step: 0
Training loss: 2.2575142739352687
Validation loss: 2.4786583108760754

Epoch: 5| Step: 1
Training loss: 2.1683748431951995
Validation loss: 2.5027111211971627

Epoch: 5| Step: 2
Training loss: 1.568213279066772
Validation loss: 2.5140877063811993

Epoch: 5| Step: 3
Training loss: 2.1097594864432314
Validation loss: 2.509163892958473

Epoch: 5| Step: 4
Training loss: 1.8047927891786741
Validation loss: 2.532313599548049

Epoch: 5| Step: 5
Training loss: 1.819768603360161
Validation loss: 2.4913558119981594

Epoch: 5| Step: 6
Training loss: 2.279808634205918
Validation loss: 2.5052434713154876

Epoch: 5| Step: 7
Training loss: 1.8987336732264144
Validation loss: 2.457986658790543

Epoch: 5| Step: 8
Training loss: 2.2742757923097376
Validation loss: 2.4898993274895784

Epoch: 5| Step: 9
Training loss: 2.092311535805844
Validation loss: 2.4995774942665347

Epoch: 5| Step: 10
Training loss: 2.3497855230625904
Validation loss: 2.4931492893309626

Epoch: 305| Step: 0
Training loss: 1.7821660279745206
Validation loss: 2.4577864749011615

Epoch: 5| Step: 1
Training loss: 1.7730201532603027
Validation loss: 2.4983433084604076

Epoch: 5| Step: 2
Training loss: 1.9794123313088778
Validation loss: 2.487035766912722

Epoch: 5| Step: 3
Training loss: 1.7367154387778403
Validation loss: 2.5081491306696617

Epoch: 5| Step: 4
Training loss: 2.197841070481155
Validation loss: 2.5304355929138937

Epoch: 5| Step: 5
Training loss: 2.087149849952031
Validation loss: 2.548053339271833

Epoch: 5| Step: 6
Training loss: 2.673859957609316
Validation loss: 2.588697501615122

Epoch: 5| Step: 7
Training loss: 2.48824388125639
Validation loss: 2.5528716744236735

Epoch: 5| Step: 8
Training loss: 1.8263290582421046
Validation loss: 2.5206242224346185

Epoch: 5| Step: 9
Training loss: 1.4217748921125146
Validation loss: 2.477526641295508

Epoch: 5| Step: 10
Training loss: 2.243895727329087
Validation loss: 2.4658086931151235

Epoch: 306| Step: 0
Training loss: 2.071412337761018
Validation loss: 2.419430455731794

Epoch: 5| Step: 1
Training loss: 2.0166080650243225
Validation loss: 2.4080828188271703

Epoch: 5| Step: 2
Training loss: 1.4869212747807565
Validation loss: 2.472302255175765

Epoch: 5| Step: 3
Training loss: 1.518489058569766
Validation loss: 2.5461239422335096

Epoch: 5| Step: 4
Training loss: 2.096069190200997
Validation loss: 2.6106502861877785

Epoch: 5| Step: 5
Training loss: 2.07120664469455
Validation loss: 2.585956319253405

Epoch: 5| Step: 6
Training loss: 2.4670909667019125
Validation loss: 2.629639906953987

Epoch: 5| Step: 7
Training loss: 1.8687190075604008
Validation loss: 2.545121490749285

Epoch: 5| Step: 8
Training loss: 2.077917332419327
Validation loss: 2.490259074105322

Epoch: 5| Step: 9
Training loss: 2.381816518281333
Validation loss: 2.4531601416769147

Epoch: 5| Step: 10
Training loss: 2.571512516104753
Validation loss: 2.416953177718892

Epoch: 307| Step: 0
Training loss: 1.7401166848268377
Validation loss: 2.4046697292398727

Epoch: 5| Step: 1
Training loss: 2.0174962310566733
Validation loss: 2.442900140434312

Epoch: 5| Step: 2
Training loss: 2.0990899157554614
Validation loss: 2.470332552150725

Epoch: 5| Step: 3
Training loss: 1.3088842268847987
Validation loss: 2.4960173652748607

Epoch: 5| Step: 4
Training loss: 2.216092519570844
Validation loss: 2.5154717001920517

Epoch: 5| Step: 5
Training loss: 2.3576365754745536
Validation loss: 2.5625617107140894

Epoch: 5| Step: 6
Training loss: 2.030411767398532
Validation loss: 2.5506586239672

Epoch: 5| Step: 7
Training loss: 2.1552331710669916
Validation loss: 2.5414025555958717

Epoch: 5| Step: 8
Training loss: 2.17918844218221
Validation loss: 2.53224533344473

Epoch: 5| Step: 9
Training loss: 2.1311078647862383
Validation loss: 2.4695417184269766

Epoch: 5| Step: 10
Training loss: 1.9165733217922518
Validation loss: 2.4966865013039277

Epoch: 308| Step: 0
Training loss: 2.3059551308957307
Validation loss: 2.4726294486726488

Epoch: 5| Step: 1
Training loss: 1.8846809328648242
Validation loss: 2.485274375172883

Epoch: 5| Step: 2
Training loss: 2.345128378861653
Validation loss: 2.4759888928484473

Epoch: 5| Step: 3
Training loss: 1.0841194687249958
Validation loss: 2.4732507023752373

Epoch: 5| Step: 4
Training loss: 2.4855282583922884
Validation loss: 2.486248969665887

Epoch: 5| Step: 5
Training loss: 2.0755883129706105
Validation loss: 2.49697410958382

Epoch: 5| Step: 6
Training loss: 2.3184446272565022
Validation loss: 2.4818596102171844

Epoch: 5| Step: 7
Training loss: 1.7570418639517607
Validation loss: 2.463012340478284

Epoch: 5| Step: 8
Training loss: 2.2216973943319105
Validation loss: 2.4341656081079908

Epoch: 5| Step: 9
Training loss: 1.4467754486308462
Validation loss: 2.4668024724421476

Epoch: 5| Step: 10
Training loss: 1.7458200944324198
Validation loss: 2.4997962878917472

Epoch: 309| Step: 0
Training loss: 1.8318573761440062
Validation loss: 2.5106096462017877

Epoch: 5| Step: 1
Training loss: 2.3250099181917356
Validation loss: 2.5636858493516272

Epoch: 5| Step: 2
Training loss: 2.211961920012073
Validation loss: 2.5616658411498303

Epoch: 5| Step: 3
Training loss: 2.1733571216630945
Validation loss: 2.5463616232282855

Epoch: 5| Step: 4
Training loss: 2.338319922273025
Validation loss: 2.507240982416232

Epoch: 5| Step: 5
Training loss: 1.382841034503219
Validation loss: 2.4437984825032935

Epoch: 5| Step: 6
Training loss: 2.1891244578663884
Validation loss: 2.453029275644647

Epoch: 5| Step: 7
Training loss: 2.2506523246345838
Validation loss: 2.437845260867093

Epoch: 5| Step: 8
Training loss: 2.0157777003916477
Validation loss: 2.437542630736004

Epoch: 5| Step: 9
Training loss: 1.5372714547350488
Validation loss: 2.4747753983576417

Epoch: 5| Step: 10
Training loss: 1.7862039575856064
Validation loss: 2.47323937703661

Epoch: 310| Step: 0
Training loss: 2.0851205661960486
Validation loss: 2.4956088212172465

Epoch: 5| Step: 1
Training loss: 2.010692267889018
Validation loss: 2.5317850989291943

Epoch: 5| Step: 2
Training loss: 2.653794982931403
Validation loss: 2.5381468055176017

Epoch: 5| Step: 3
Training loss: 1.8071464531538008
Validation loss: 2.5353483087537354

Epoch: 5| Step: 4
Training loss: 2.1686433309657303
Validation loss: 2.504739608306028

Epoch: 5| Step: 5
Training loss: 1.6411805438462246
Validation loss: 2.531799761077624

Epoch: 5| Step: 6
Training loss: 1.9436431217554613
Validation loss: 2.486269539550923

Epoch: 5| Step: 7
Training loss: 1.6415136927609615
Validation loss: 2.4946413198879283

Epoch: 5| Step: 8
Training loss: 1.5530755969658228
Validation loss: 2.4875633814171687

Epoch: 5| Step: 9
Training loss: 2.073086819462478
Validation loss: 2.5185491755572573

Epoch: 5| Step: 10
Training loss: 2.4359613110330995
Validation loss: 2.5408569557793563

Epoch: 311| Step: 0
Training loss: 1.8170162366226645
Validation loss: 2.5313112227959707

Epoch: 5| Step: 1
Training loss: 2.0384078454751466
Validation loss: 2.4995440446721555

Epoch: 5| Step: 2
Training loss: 1.8976314387578164
Validation loss: 2.4756631296984364

Epoch: 5| Step: 3
Training loss: 1.7054548513743464
Validation loss: 2.475207769473982

Epoch: 5| Step: 4
Training loss: 2.602023338764442
Validation loss: 2.4728500185830784

Epoch: 5| Step: 5
Training loss: 2.1458699368314753
Validation loss: 2.4832358833870836

Epoch: 5| Step: 6
Training loss: 1.5176141800887086
Validation loss: 2.473131728793362

Epoch: 5| Step: 7
Training loss: 2.162931952582014
Validation loss: 2.4733218292087304

Epoch: 5| Step: 8
Training loss: 1.9417502637666277
Validation loss: 2.4746272901010586

Epoch: 5| Step: 9
Training loss: 1.8304317299668562
Validation loss: 2.498487940230772

Epoch: 5| Step: 10
Training loss: 2.0390315144841007
Validation loss: 2.4884479549478273

Epoch: 312| Step: 0
Training loss: 1.8196341105927023
Validation loss: 2.4860971262927607

Epoch: 5| Step: 1
Training loss: 2.161747434347886
Validation loss: 2.443930884460176

Epoch: 5| Step: 2
Training loss: 2.152018610770998
Validation loss: 2.479679051270267

Epoch: 5| Step: 3
Training loss: 1.8682371883966324
Validation loss: 2.4457611633756375

Epoch: 5| Step: 4
Training loss: 1.9849312670936643
Validation loss: 2.4568888764196104

Epoch: 5| Step: 5
Training loss: 2.1203589527773468
Validation loss: 2.4639624720769175

Epoch: 5| Step: 6
Training loss: 1.6624482971412147
Validation loss: 2.48328738204827

Epoch: 5| Step: 7
Training loss: 1.4514833426681026
Validation loss: 2.500980724223255

Epoch: 5| Step: 8
Training loss: 2.088470863670566
Validation loss: 2.524326545142582

Epoch: 5| Step: 9
Training loss: 2.1412634349964925
Validation loss: 2.539786497375643

Epoch: 5| Step: 10
Training loss: 2.250184687346074
Validation loss: 2.517415813511294

Epoch: 313| Step: 0
Training loss: 1.854544704631749
Validation loss: 2.5076004647621026

Epoch: 5| Step: 1
Training loss: 1.6518848404174478
Validation loss: 2.508940808767217

Epoch: 5| Step: 2
Training loss: 2.0266533118778383
Validation loss: 2.484939162355014

Epoch: 5| Step: 3
Training loss: 2.0730586426643347
Validation loss: 2.476408885641441

Epoch: 5| Step: 4
Training loss: 2.0956440799070957
Validation loss: 2.4736987165012567

Epoch: 5| Step: 5
Training loss: 1.349038562328118
Validation loss: 2.4944869401742022

Epoch: 5| Step: 6
Training loss: 2.336875293504156
Validation loss: 2.467491592426316

Epoch: 5| Step: 7
Training loss: 2.1669800849566276
Validation loss: 2.4658453372419347

Epoch: 5| Step: 8
Training loss: 1.9401329362686175
Validation loss: 2.478794916590034

Epoch: 5| Step: 9
Training loss: 2.0267488345421274
Validation loss: 2.4825211502183944

Epoch: 5| Step: 10
Training loss: 2.083574192111234
Validation loss: 2.4875029431710756

Epoch: 314| Step: 0
Training loss: 1.7239361288094752
Validation loss: 2.4827609529115158

Epoch: 5| Step: 1
Training loss: 1.5292579772601462
Validation loss: 2.47887195404829

Epoch: 5| Step: 2
Training loss: 1.7995066072512809
Validation loss: 2.485478458541187

Epoch: 5| Step: 3
Training loss: 2.6381139610148137
Validation loss: 2.501298456471828

Epoch: 5| Step: 4
Training loss: 1.876243687465959
Validation loss: 2.4999586183958304

Epoch: 5| Step: 5
Training loss: 1.7635157316418504
Validation loss: 2.4962858276730833

Epoch: 5| Step: 6
Training loss: 1.752365012854099
Validation loss: 2.511497338143686

Epoch: 5| Step: 7
Training loss: 1.6987120826649436
Validation loss: 2.457328924559721

Epoch: 5| Step: 8
Training loss: 2.404455531422424
Validation loss: 2.464789491423557

Epoch: 5| Step: 9
Training loss: 2.5324137332002197
Validation loss: 2.4773794674258025

Epoch: 5| Step: 10
Training loss: 1.5606305955718545
Validation loss: 2.4680043324042105

Epoch: 315| Step: 0
Training loss: 1.620720289483779
Validation loss: 2.463447355839399

Epoch: 5| Step: 1
Training loss: 2.1287389287027914
Validation loss: 2.475217406899158

Epoch: 5| Step: 2
Training loss: 1.7422221911615792
Validation loss: 2.5043064890707596

Epoch: 5| Step: 3
Training loss: 2.0949112817374465
Validation loss: 2.5092884497339303

Epoch: 5| Step: 4
Training loss: 1.3644860308174278
Validation loss: 2.5216802184503915

Epoch: 5| Step: 5
Training loss: 2.0274144272437598
Validation loss: 2.5358715498431295

Epoch: 5| Step: 6
Training loss: 1.7013424985966605
Validation loss: 2.504914677640794

Epoch: 5| Step: 7
Training loss: 2.14700635927393
Validation loss: 2.4717840593212017

Epoch: 5| Step: 8
Training loss: 2.291898877487863
Validation loss: 2.4191628885519605

Epoch: 5| Step: 9
Training loss: 2.260749569709869
Validation loss: 2.3921611080424614

Epoch: 5| Step: 10
Training loss: 2.2723414344988266
Validation loss: 2.38681410592676

Epoch: 316| Step: 0
Training loss: 1.9780796546017405
Validation loss: 2.434021709565782

Epoch: 5| Step: 1
Training loss: 1.6659434259295323
Validation loss: 2.5087054465931207

Epoch: 5| Step: 2
Training loss: 2.1759962321557356
Validation loss: 2.5418417119053185

Epoch: 5| Step: 3
Training loss: 1.693681697242459
Validation loss: 2.5849341431925845

Epoch: 5| Step: 4
Training loss: 2.2325298453426012
Validation loss: 2.633905981598087

Epoch: 5| Step: 5
Training loss: 2.044161563228805
Validation loss: 2.5953988187827433

Epoch: 5| Step: 6
Training loss: 1.0666386277765374
Validation loss: 2.549973733265227

Epoch: 5| Step: 7
Training loss: 2.4551644564238786
Validation loss: 2.490498564071553

Epoch: 5| Step: 8
Training loss: 1.899776975190956
Validation loss: 2.4368187310159586

Epoch: 5| Step: 9
Training loss: 1.6003685943897223
Validation loss: 2.4013177251528157

Epoch: 5| Step: 10
Training loss: 2.954768939335745
Validation loss: 2.373039377594743

Epoch: 317| Step: 0
Training loss: 1.527854346273598
Validation loss: 2.416121769013061

Epoch: 5| Step: 1
Training loss: 1.6359790231996758
Validation loss: 2.405278670243942

Epoch: 5| Step: 2
Training loss: 2.201891939572855
Validation loss: 2.442494804155207

Epoch: 5| Step: 3
Training loss: 1.903388204679971
Validation loss: 2.4815806015616473

Epoch: 5| Step: 4
Training loss: 2.242275542016021
Validation loss: 2.5234452007519965

Epoch: 5| Step: 5
Training loss: 1.892360930680977
Validation loss: 2.55009965044398

Epoch: 5| Step: 6
Training loss: 1.9873286215350832
Validation loss: 2.5772218745091626

Epoch: 5| Step: 7
Training loss: 2.470132271781006
Validation loss: 2.5695606584180246

Epoch: 5| Step: 8
Training loss: 1.5155317140166304
Validation loss: 2.505204989448304

Epoch: 5| Step: 9
Training loss: 2.435788654235631
Validation loss: 2.4643703796799965

Epoch: 5| Step: 10
Training loss: 1.483016667514802
Validation loss: 2.467366623432878

Epoch: 318| Step: 0
Training loss: 1.697456024341893
Validation loss: 2.412853844913123

Epoch: 5| Step: 1
Training loss: 1.9493867423342026
Validation loss: 2.3890473389627873

Epoch: 5| Step: 2
Training loss: 1.8479888165081875
Validation loss: 2.3975415378922516

Epoch: 5| Step: 3
Training loss: 2.087777344331036
Validation loss: 2.3793893019181955

Epoch: 5| Step: 4
Training loss: 1.7440892262163386
Validation loss: 2.4176915562346752

Epoch: 5| Step: 5
Training loss: 2.619196425376182
Validation loss: 2.4633015367286153

Epoch: 5| Step: 6
Training loss: 1.7179286034417838
Validation loss: 2.5119984852679997

Epoch: 5| Step: 7
Training loss: 1.9976306231857412
Validation loss: 2.5576610622111766

Epoch: 5| Step: 8
Training loss: 1.4675539706701877
Validation loss: 2.59306103416579

Epoch: 5| Step: 9
Training loss: 1.7765236775661406
Validation loss: 2.6349771852959725

Epoch: 5| Step: 10
Training loss: 2.604882307267796
Validation loss: 2.6456236061365064

Epoch: 319| Step: 0
Training loss: 2.062015707783112
Validation loss: 2.536494848578046

Epoch: 5| Step: 1
Training loss: 2.2774168235087067
Validation loss: 2.479844527425744

Epoch: 5| Step: 2
Training loss: 2.3109160488698666
Validation loss: 2.4484908967088197

Epoch: 5| Step: 3
Training loss: 2.298184495144888
Validation loss: 2.4152655498471365

Epoch: 5| Step: 4
Training loss: 1.6400699948283919
Validation loss: 2.4544124627751622

Epoch: 5| Step: 5
Training loss: 1.5593534449003013
Validation loss: 2.4638599789424958

Epoch: 5| Step: 6
Training loss: 1.8371673360705298
Validation loss: 2.485288839275819

Epoch: 5| Step: 7
Training loss: 1.7007489209657425
Validation loss: 2.502683493424768

Epoch: 5| Step: 8
Training loss: 2.0540689327778234
Validation loss: 2.4819073310852753

Epoch: 5| Step: 9
Training loss: 1.8764182131371063
Validation loss: 2.496089287415805

Epoch: 5| Step: 10
Training loss: 1.977227984792147
Validation loss: 2.535448218914986

Epoch: 320| Step: 0
Training loss: 2.197007797373225
Validation loss: 2.539453529052131

Epoch: 5| Step: 1
Training loss: 1.7041692069982173
Validation loss: 2.5165209134385864

Epoch: 5| Step: 2
Training loss: 1.81952607681109
Validation loss: 2.529626135284603

Epoch: 5| Step: 3
Training loss: 2.175421584037986
Validation loss: 2.527861250717262

Epoch: 5| Step: 4
Training loss: 1.530832350468757
Validation loss: 2.5243189646322937

Epoch: 5| Step: 5
Training loss: 1.8286624346698146
Validation loss: 2.547739636722872

Epoch: 5| Step: 6
Training loss: 1.3750017339522091
Validation loss: 2.537338956673736

Epoch: 5| Step: 7
Training loss: 1.9089108016774872
Validation loss: 2.5064114015559373

Epoch: 5| Step: 8
Training loss: 2.188162022277163
Validation loss: 2.5010988015220446

Epoch: 5| Step: 9
Training loss: 2.19239945097389
Validation loss: 2.5185026487831625

Epoch: 5| Step: 10
Training loss: 2.378612381146035
Validation loss: 2.497789572706023

Epoch: 321| Step: 0
Training loss: 1.6797209980307997
Validation loss: 2.4625224056903825

Epoch: 5| Step: 1
Training loss: 1.810190966211085
Validation loss: 2.4438290219444077

Epoch: 5| Step: 2
Training loss: 1.734258286956613
Validation loss: 2.454727977384149

Epoch: 5| Step: 3
Training loss: 1.4967372695536931
Validation loss: 2.4479994243874765

Epoch: 5| Step: 4
Training loss: 2.2491029434627863
Validation loss: 2.4427385036880027

Epoch: 5| Step: 5
Training loss: 2.192742523385896
Validation loss: 2.4208726548029817

Epoch: 5| Step: 6
Training loss: 2.034411039487323
Validation loss: 2.4317557675197

Epoch: 5| Step: 7
Training loss: 1.2560007066238748
Validation loss: 2.439524853666266

Epoch: 5| Step: 8
Training loss: 2.5067103926246994
Validation loss: 2.4731369532361223

Epoch: 5| Step: 9
Training loss: 2.450892799570012
Validation loss: 2.441595410178654

Epoch: 5| Step: 10
Training loss: 1.3933051353016623
Validation loss: 2.4412443562964263

Epoch: 322| Step: 0
Training loss: 1.788236802308285
Validation loss: 2.439744682507689

Epoch: 5| Step: 1
Training loss: 2.2012274395784672
Validation loss: 2.4387624188665655

Epoch: 5| Step: 2
Training loss: 1.9437081335532767
Validation loss: 2.4404406493113924

Epoch: 5| Step: 3
Training loss: 1.5758790756975338
Validation loss: 2.4580031900305666

Epoch: 5| Step: 4
Training loss: 1.5604199869946482
Validation loss: 2.4896508275200184

Epoch: 5| Step: 5
Training loss: 1.638397448434184
Validation loss: 2.5079762650641233

Epoch: 5| Step: 6
Training loss: 1.8575814195658187
Validation loss: 2.500409910990425

Epoch: 5| Step: 7
Training loss: 1.970819263797835
Validation loss: 2.500447421901074

Epoch: 5| Step: 8
Training loss: 2.3741712630086718
Validation loss: 2.4832174006366485

Epoch: 5| Step: 9
Training loss: 2.2481176131559013
Validation loss: 2.448679416421091

Epoch: 5| Step: 10
Training loss: 1.9931999476191455
Validation loss: 2.4651587193547244

Epoch: 323| Step: 0
Training loss: 1.9166504472239774
Validation loss: 2.444438292786784

Epoch: 5| Step: 1
Training loss: 1.7515278005438226
Validation loss: 2.487599076950577

Epoch: 5| Step: 2
Training loss: 1.4155219539501562
Validation loss: 2.4828963447819317

Epoch: 5| Step: 3
Training loss: 1.8583111324039052
Validation loss: 2.5081083286615757

Epoch: 5| Step: 4
Training loss: 1.7793473907569057
Validation loss: 2.5323316146243986

Epoch: 5| Step: 5
Training loss: 1.8326235466458198
Validation loss: 2.5013957055130303

Epoch: 5| Step: 6
Training loss: 2.113402075847849
Validation loss: 2.5209819021422946

Epoch: 5| Step: 7
Training loss: 2.064669537276302
Validation loss: 2.5033349968074345

Epoch: 5| Step: 8
Training loss: 2.0211708599726634
Validation loss: 2.499283046873863

Epoch: 5| Step: 9
Training loss: 2.4221472802463087
Validation loss: 2.5044144530686934

Epoch: 5| Step: 10
Training loss: 1.8239979906489363
Validation loss: 2.466329579932561

Epoch: 324| Step: 0
Training loss: 1.7182666445697012
Validation loss: 2.4575760225680767

Epoch: 5| Step: 1
Training loss: 1.4346795816271543
Validation loss: 2.4401971331755616

Epoch: 5| Step: 2
Training loss: 1.8383141251658879
Validation loss: 2.440927986799084

Epoch: 5| Step: 3
Training loss: 1.6260695972116925
Validation loss: 2.4575253829735937

Epoch: 5| Step: 4
Training loss: 1.4272652206157228
Validation loss: 2.4880715945083685

Epoch: 5| Step: 5
Training loss: 1.4405844395155278
Validation loss: 2.4846773629810377

Epoch: 5| Step: 6
Training loss: 2.237789079969483
Validation loss: 2.490087086879831

Epoch: 5| Step: 7
Training loss: 1.8088582383086291
Validation loss: 2.4970382209751776

Epoch: 5| Step: 8
Training loss: 1.7708024265359712
Validation loss: 2.48663021028207

Epoch: 5| Step: 9
Training loss: 2.6765013679431062
Validation loss: 2.498177385954189

Epoch: 5| Step: 10
Training loss: 2.706749311024786
Validation loss: 2.496560382376717

Epoch: 325| Step: 0
Training loss: 1.8687531359592011
Validation loss: 2.5001596071710765

Epoch: 5| Step: 1
Training loss: 1.4072693838769115
Validation loss: 2.4822086478790335

Epoch: 5| Step: 2
Training loss: 2.341893592599813
Validation loss: 2.474684011938563

Epoch: 5| Step: 3
Training loss: 1.3839645759012578
Validation loss: 2.4834985407881462

Epoch: 5| Step: 4
Training loss: 1.4779166818810028
Validation loss: 2.490562901856476

Epoch: 5| Step: 5
Training loss: 2.14939953159133
Validation loss: 2.5352699265296037

Epoch: 5| Step: 6
Training loss: 2.0804793709610254
Validation loss: 2.512661567692457

Epoch: 5| Step: 7
Training loss: 2.2558105463465457
Validation loss: 2.478188959857977

Epoch: 5| Step: 8
Training loss: 1.8494085990429452
Validation loss: 2.487313536990555

Epoch: 5| Step: 9
Training loss: 1.8136905180354757
Validation loss: 2.4803701275052483

Epoch: 5| Step: 10
Training loss: 2.0736638420652747
Validation loss: 2.478335278291656

Epoch: 326| Step: 0
Training loss: 1.5618679294067415
Validation loss: 2.4977052986107746

Epoch: 5| Step: 1
Training loss: 2.0542566115964775
Validation loss: 2.5000631385951873

Epoch: 5| Step: 2
Training loss: 2.5428799615175985
Validation loss: 2.4915348885139226

Epoch: 5| Step: 3
Training loss: 1.6913777056040813
Validation loss: 2.4973236545413533

Epoch: 5| Step: 4
Training loss: 1.5810798704275324
Validation loss: 2.471766695611663

Epoch: 5| Step: 5
Training loss: 1.6232600066421332
Validation loss: 2.4751102455273486

Epoch: 5| Step: 6
Training loss: 1.957115430411012
Validation loss: 2.463436952219654

Epoch: 5| Step: 7
Training loss: 2.3077556295754977
Validation loss: 2.4457583683555173

Epoch: 5| Step: 8
Training loss: 1.90515486731018
Validation loss: 2.4663267858737346

Epoch: 5| Step: 9
Training loss: 1.7402632825443458
Validation loss: 2.486334987959216

Epoch: 5| Step: 10
Training loss: 1.6365986418070326
Validation loss: 2.494213845966559

Epoch: 327| Step: 0
Training loss: 2.046127648817426
Validation loss: 2.4930230541885035

Epoch: 5| Step: 1
Training loss: 1.1608577880602071
Validation loss: 2.4989109271806313

Epoch: 5| Step: 2
Training loss: 2.110863958358236
Validation loss: 2.4919771299895377

Epoch: 5| Step: 3
Training loss: 2.428146118700641
Validation loss: 2.483889833135495

Epoch: 5| Step: 4
Training loss: 1.9821819291749938
Validation loss: 2.500095485586523

Epoch: 5| Step: 5
Training loss: 1.3484941172289369
Validation loss: 2.4835160511196728

Epoch: 5| Step: 6
Training loss: 1.2038437319000175
Validation loss: 2.5071839766657273

Epoch: 5| Step: 7
Training loss: 1.991274396288336
Validation loss: 2.5199463281321473

Epoch: 5| Step: 8
Training loss: 1.842273379484622
Validation loss: 2.549113870087588

Epoch: 5| Step: 9
Training loss: 1.7558802178050685
Validation loss: 2.590671910559711

Epoch: 5| Step: 10
Training loss: 2.671224593031446
Validation loss: 2.581366765650486

Epoch: 328| Step: 0
Training loss: 2.096593036824397
Validation loss: 2.586706696637079

Epoch: 5| Step: 1
Training loss: 1.9618491679007266
Validation loss: 2.563100634877959

Epoch: 5| Step: 2
Training loss: 2.212918852906346
Validation loss: 2.5449328715189505

Epoch: 5| Step: 3
Training loss: 2.187039899122836
Validation loss: 2.5174604570877315

Epoch: 5| Step: 4
Training loss: 1.8151421855372767
Validation loss: 2.4619915833968147

Epoch: 5| Step: 5
Training loss: 1.5910608380264766
Validation loss: 2.4432243387954897

Epoch: 5| Step: 6
Training loss: 2.053926508278695
Validation loss: 2.4253205653612

Epoch: 5| Step: 7
Training loss: 1.4302390446969298
Validation loss: 2.403508324137698

Epoch: 5| Step: 8
Training loss: 2.056495943985048
Validation loss: 2.4233156659536674

Epoch: 5| Step: 9
Training loss: 1.6743406136610346
Validation loss: 2.4707117558732703

Epoch: 5| Step: 10
Training loss: 1.816566706307524
Validation loss: 2.52904322696108

Epoch: 329| Step: 0
Training loss: 1.9181002010508634
Validation loss: 2.568194650905668

Epoch: 5| Step: 1
Training loss: 2.0236347352743977
Validation loss: 2.6069910871964637

Epoch: 5| Step: 2
Training loss: 2.132166390837965
Validation loss: 2.5539514708690763

Epoch: 5| Step: 3
Training loss: 2.166636124420086
Validation loss: 2.4986930992085457

Epoch: 5| Step: 4
Training loss: 1.7706918846933248
Validation loss: 2.457804034903368

Epoch: 5| Step: 5
Training loss: 2.0999527335524237
Validation loss: 2.4209132184533013

Epoch: 5| Step: 6
Training loss: 1.8956915694111924
Validation loss: 2.408885881680228

Epoch: 5| Step: 7
Training loss: 1.8634521917787217
Validation loss: 2.404743214494415

Epoch: 5| Step: 8
Training loss: 1.9257142711079893
Validation loss: 2.3906435294535404

Epoch: 5| Step: 9
Training loss: 1.43539257647596
Validation loss: 2.3934175648670224

Epoch: 5| Step: 10
Training loss: 1.6623026537106802
Validation loss: 2.406069077145262

Epoch: 330| Step: 0
Training loss: 1.6478595895764991
Validation loss: 2.4531425881446007

Epoch: 5| Step: 1
Training loss: 2.1634506297040264
Validation loss: 2.5049969079932706

Epoch: 5| Step: 2
Training loss: 2.1281526404110847
Validation loss: 2.540304152283022

Epoch: 5| Step: 3
Training loss: 2.3480932048059358
Validation loss: 2.583740943192591

Epoch: 5| Step: 4
Training loss: 1.617906051445043
Validation loss: 2.584126818682564

Epoch: 5| Step: 5
Training loss: 1.5869904578967071
Validation loss: 2.562434462002589

Epoch: 5| Step: 6
Training loss: 1.8009280726225603
Validation loss: 2.53127291441258

Epoch: 5| Step: 7
Training loss: 2.3638778059694996
Validation loss: 2.495941084005835

Epoch: 5| Step: 8
Training loss: 1.5091237903628987
Validation loss: 2.4495266038249848

Epoch: 5| Step: 9
Training loss: 1.8718129091998268
Validation loss: 2.4500492990040357

Epoch: 5| Step: 10
Training loss: 1.7791172443586156
Validation loss: 2.423055385895703

Epoch: 331| Step: 0
Training loss: 1.7048517974923696
Validation loss: 2.449892716259382

Epoch: 5| Step: 1
Training loss: 1.7745356583697967
Validation loss: 2.462332695907267

Epoch: 5| Step: 2
Training loss: 1.8950546957290408
Validation loss: 2.4725770851946955

Epoch: 5| Step: 3
Training loss: 1.922917897178226
Validation loss: 2.513960519566434

Epoch: 5| Step: 4
Training loss: 1.4115327578509136
Validation loss: 2.5255754113887274

Epoch: 5| Step: 5
Training loss: 2.3482957625875036
Validation loss: 2.5718501840283157

Epoch: 5| Step: 6
Training loss: 2.318035614108715
Validation loss: 2.5537264505394095

Epoch: 5| Step: 7
Training loss: 1.8180541080358674
Validation loss: 2.4902411901327257

Epoch: 5| Step: 8
Training loss: 1.557054950325103
Validation loss: 2.434848104292862

Epoch: 5| Step: 9
Training loss: 2.0508199633622755
Validation loss: 2.4207415047622063

Epoch: 5| Step: 10
Training loss: 1.9658722205019605
Validation loss: 2.4292223333103227

Epoch: 332| Step: 0
Training loss: 2.104992757861802
Validation loss: 2.4637445642346805

Epoch: 5| Step: 1
Training loss: 2.411132318087991
Validation loss: 2.5205069260860813

Epoch: 5| Step: 2
Training loss: 1.7581608405936855
Validation loss: 2.5716641739404067

Epoch: 5| Step: 3
Training loss: 1.221707106662978
Validation loss: 2.580061916871652

Epoch: 5| Step: 4
Training loss: 1.8622332490722517
Validation loss: 2.623633836379815

Epoch: 5| Step: 5
Training loss: 1.5422349947618208
Validation loss: 2.6068288991214095

Epoch: 5| Step: 6
Training loss: 1.7451897314157323
Validation loss: 2.606879716524515

Epoch: 5| Step: 7
Training loss: 1.883094291651863
Validation loss: 2.581528080176179

Epoch: 5| Step: 8
Training loss: 1.492104093607302
Validation loss: 2.5527241143284356

Epoch: 5| Step: 9
Training loss: 2.4498440128416052
Validation loss: 2.4959639435697363

Epoch: 5| Step: 10
Training loss: 2.3131374820763093
Validation loss: 2.479770439179297

Epoch: 333| Step: 0
Training loss: 1.9967643074314938
Validation loss: 2.4633037992823863

Epoch: 5| Step: 1
Training loss: 2.1706972290639968
Validation loss: 2.4734520848962784

Epoch: 5| Step: 2
Training loss: 1.9719978064549997
Validation loss: 2.4763944245398006

Epoch: 5| Step: 3
Training loss: 2.1826202460828683
Validation loss: 2.5154000407621773

Epoch: 5| Step: 4
Training loss: 1.6960295817476434
Validation loss: 2.543004576637323

Epoch: 5| Step: 5
Training loss: 2.1852190387148527
Validation loss: 2.542263258202729

Epoch: 5| Step: 6
Training loss: 1.255561757752245
Validation loss: 2.5609234888281533

Epoch: 5| Step: 7
Training loss: 1.909715472893396
Validation loss: 2.577257702455333

Epoch: 5| Step: 8
Training loss: 1.6107981787152885
Validation loss: 2.533799288796763

Epoch: 5| Step: 9
Training loss: 1.385012713556432
Validation loss: 2.495695132215529

Epoch: 5| Step: 10
Training loss: 2.034709156444321
Validation loss: 2.453231059929169

Epoch: 334| Step: 0
Training loss: 1.4183454197160565
Validation loss: 2.3722884551200094

Epoch: 5| Step: 1
Training loss: 1.788491636926957
Validation loss: 2.384730208619031

Epoch: 5| Step: 2
Training loss: 1.6924700133964967
Validation loss: 2.410602056540069

Epoch: 5| Step: 3
Training loss: 2.162862396744975
Validation loss: 2.3894011922436644

Epoch: 5| Step: 4
Training loss: 1.7777661167530572
Validation loss: 2.4326636697076376

Epoch: 5| Step: 5
Training loss: 1.7181378748395042
Validation loss: 2.4816266356621384

Epoch: 5| Step: 6
Training loss: 2.3298699924724837
Validation loss: 2.532213786920095

Epoch: 5| Step: 7
Training loss: 2.1892333656298524
Validation loss: 2.5870628553996387

Epoch: 5| Step: 8
Training loss: 1.987224005483675
Validation loss: 2.546420757110365

Epoch: 5| Step: 9
Training loss: 1.7984158087912887
Validation loss: 2.5378610196233686

Epoch: 5| Step: 10
Training loss: 2.0650763171043067
Validation loss: 2.5077024848509657

Epoch: 335| Step: 0
Training loss: 1.6170784733827108
Validation loss: 2.468446529371659

Epoch: 5| Step: 1
Training loss: 1.2066292695227099
Validation loss: 2.448307683885137

Epoch: 5| Step: 2
Training loss: 1.8632911026092365
Validation loss: 2.4111639655683725

Epoch: 5| Step: 3
Training loss: 2.5630319554915046
Validation loss: 2.3684429044203594

Epoch: 5| Step: 4
Training loss: 1.3842981838157913
Validation loss: 2.363369785929476

Epoch: 5| Step: 5
Training loss: 2.3932777596328885
Validation loss: 2.362084983603251

Epoch: 5| Step: 6
Training loss: 1.6764109746571476
Validation loss: 2.368685329938805

Epoch: 5| Step: 7
Training loss: 2.320156824303386
Validation loss: 2.4137886376011006

Epoch: 5| Step: 8
Training loss: 1.6966259346789856
Validation loss: 2.496497941795269

Epoch: 5| Step: 9
Training loss: 1.3671807861163274
Validation loss: 2.5413062150882175

Epoch: 5| Step: 10
Training loss: 2.3983387880172713
Validation loss: 2.6196652160109255

Epoch: 336| Step: 0
Training loss: 2.2364650101392485
Validation loss: 2.6638767725122103

Epoch: 5| Step: 1
Training loss: 2.089199644279121
Validation loss: 2.585997207012289

Epoch: 5| Step: 2
Training loss: 1.1295899957178726
Validation loss: 2.573100666629093

Epoch: 5| Step: 3
Training loss: 2.2758144262313706
Validation loss: 2.5240397705912523

Epoch: 5| Step: 4
Training loss: 2.161916501919811
Validation loss: 2.4922025224066586

Epoch: 5| Step: 5
Training loss: 0.9844288584189593
Validation loss: 2.4872197571752164

Epoch: 5| Step: 6
Training loss: 2.420365386050161
Validation loss: 2.455011062214533

Epoch: 5| Step: 7
Training loss: 2.0233232031395265
Validation loss: 2.467546465860808

Epoch: 5| Step: 8
Training loss: 1.8606939045862247
Validation loss: 2.4846994739300046

Epoch: 5| Step: 9
Training loss: 1.4312878599531669
Validation loss: 2.504070653428333

Epoch: 5| Step: 10
Training loss: 1.6071556862818612
Validation loss: 2.518901459619929

Epoch: 337| Step: 0
Training loss: 2.3709341683646543
Validation loss: 2.5169420462711902

Epoch: 5| Step: 1
Training loss: 1.7906376596905367
Validation loss: 2.515854353408818

Epoch: 5| Step: 2
Training loss: 1.2860071212073043
Validation loss: 2.519290500416133

Epoch: 5| Step: 3
Training loss: 2.118999198729799
Validation loss: 2.491404169539077

Epoch: 5| Step: 4
Training loss: 1.7608224826134802
Validation loss: 2.4478941149033897

Epoch: 5| Step: 5
Training loss: 2.34629866308231
Validation loss: 2.422639465353252

Epoch: 5| Step: 6
Training loss: 1.8523651829722039
Validation loss: 2.416092614199903

Epoch: 5| Step: 7
Training loss: 1.719753596598628
Validation loss: 2.378181560917922

Epoch: 5| Step: 8
Training loss: 1.3940252246161653
Validation loss: 2.408237014552145

Epoch: 5| Step: 9
Training loss: 2.1056738136093323
Validation loss: 2.4071255020599898

Epoch: 5| Step: 10
Training loss: 1.4564382865238035
Validation loss: 2.45869928691312

Epoch: 338| Step: 0
Training loss: 2.3350245500209286
Validation loss: 2.496131275447039

Epoch: 5| Step: 1
Training loss: 2.0971264161155565
Validation loss: 2.508368819551306

Epoch: 5| Step: 2
Training loss: 1.7031256999443085
Validation loss: 2.527107551440468

Epoch: 5| Step: 3
Training loss: 1.6823457486776825
Validation loss: 2.5222567708460892

Epoch: 5| Step: 4
Training loss: 1.413872974824977
Validation loss: 2.5267090704296975

Epoch: 5| Step: 5
Training loss: 1.6986194474535654
Validation loss: 2.5018434178277396

Epoch: 5| Step: 6
Training loss: 1.7977872440202602
Validation loss: 2.464424302117801

Epoch: 5| Step: 7
Training loss: 2.286890346812349
Validation loss: 2.43468754401562

Epoch: 5| Step: 8
Training loss: 1.985949634962126
Validation loss: 2.449540417676724

Epoch: 5| Step: 9
Training loss: 1.5863755847225565
Validation loss: 2.3994675866961206

Epoch: 5| Step: 10
Training loss: 1.3269886765589822
Validation loss: 2.4077622693307617

Epoch: 339| Step: 0
Training loss: 1.864223793642599
Validation loss: 2.41733510875816

Epoch: 5| Step: 1
Training loss: 2.012993802920949
Validation loss: 2.4523367003495578

Epoch: 5| Step: 2
Training loss: 1.2044218925845354
Validation loss: 2.469545773776131

Epoch: 5| Step: 3
Training loss: 1.9220079825689054
Validation loss: 2.5080352000428445

Epoch: 5| Step: 4
Training loss: 1.7635722422629643
Validation loss: 2.509058563570722

Epoch: 5| Step: 5
Training loss: 2.2344152273544955
Validation loss: 2.5107693559529407

Epoch: 5| Step: 6
Training loss: 1.7100739411769896
Validation loss: 2.492074768497848

Epoch: 5| Step: 7
Training loss: 1.6674382172309925
Validation loss: 2.547813063098959

Epoch: 5| Step: 8
Training loss: 1.5106125364787693
Validation loss: 2.5166718970721624

Epoch: 5| Step: 9
Training loss: 2.164458861702265
Validation loss: 2.5387511117474224

Epoch: 5| Step: 10
Training loss: 1.9941796010362167
Validation loss: 2.5049942573581587

Epoch: 340| Step: 0
Training loss: 1.7274975208314367
Validation loss: 2.4458700665705946

Epoch: 5| Step: 1
Training loss: 1.8256651149731786
Validation loss: 2.4196564896507144

Epoch: 5| Step: 2
Training loss: 1.1178605513126811
Validation loss: 2.3702712323716892

Epoch: 5| Step: 3
Training loss: 1.6563537853040529
Validation loss: 2.3542379516762573

Epoch: 5| Step: 4
Training loss: 1.9960902861622956
Validation loss: 2.354453626830642

Epoch: 5| Step: 5
Training loss: 1.8031243494518567
Validation loss: 2.362649164950672

Epoch: 5| Step: 6
Training loss: 2.1753757722210225
Validation loss: 2.3567229590649323

Epoch: 5| Step: 7
Training loss: 1.4858748237235573
Validation loss: 2.37419028260763

Epoch: 5| Step: 8
Training loss: 2.1709948615703456
Validation loss: 2.435472751295412

Epoch: 5| Step: 9
Training loss: 1.853622964016054
Validation loss: 2.4963465903781175

Epoch: 5| Step: 10
Training loss: 2.059421669600525
Validation loss: 2.529038291854998

Epoch: 341| Step: 0
Training loss: 1.8378891980351129
Validation loss: 2.4948562105745595

Epoch: 5| Step: 1
Training loss: 1.8417625059964335
Validation loss: 2.476709670661508

Epoch: 5| Step: 2
Training loss: 1.9106163297736618
Validation loss: 2.4604842870770836

Epoch: 5| Step: 3
Training loss: 1.6396407308391698
Validation loss: 2.4380667206182074

Epoch: 5| Step: 4
Training loss: 1.7641761709373787
Validation loss: 2.4538066986176323

Epoch: 5| Step: 5
Training loss: 1.7332560048215966
Validation loss: 2.4585548191258595

Epoch: 5| Step: 6
Training loss: 1.734770721105088
Validation loss: 2.440028656721993

Epoch: 5| Step: 7
Training loss: 1.9263661330141975
Validation loss: 2.431458486341418

Epoch: 5| Step: 8
Training loss: 1.9499492002863843
Validation loss: 2.4096096978267867

Epoch: 5| Step: 9
Training loss: 1.6237904375193395
Validation loss: 2.3796691334056677

Epoch: 5| Step: 10
Training loss: 1.9903531474273601
Validation loss: 2.3738560698505062

Epoch: 342| Step: 0
Training loss: 1.2462310237071108
Validation loss: 2.4279243300480027

Epoch: 5| Step: 1
Training loss: 1.8655106424781116
Validation loss: 2.446840428170581

Epoch: 5| Step: 2
Training loss: 1.703362544581297
Validation loss: 2.4297655901074897

Epoch: 5| Step: 3
Training loss: 1.2413104337826126
Validation loss: 2.43619928765361

Epoch: 5| Step: 4
Training loss: 2.160273240079078
Validation loss: 2.4894626876699832

Epoch: 5| Step: 5
Training loss: 1.415808174459109
Validation loss: 2.487212939947928

Epoch: 5| Step: 6
Training loss: 2.102949400963779
Validation loss: 2.450517176821682

Epoch: 5| Step: 7
Training loss: 2.3751852063695758
Validation loss: 2.464329923813527

Epoch: 5| Step: 8
Training loss: 1.49946099769721
Validation loss: 2.4530648105966293

Epoch: 5| Step: 9
Training loss: 2.25536163255417
Validation loss: 2.4569516693931983

Epoch: 5| Step: 10
Training loss: 1.2883474042666074
Validation loss: 2.4910707674907253

Epoch: 343| Step: 0
Training loss: 1.3374621519634005
Validation loss: 2.5077248845093907

Epoch: 5| Step: 1
Training loss: 2.262266735044093
Validation loss: 2.4999857245827277

Epoch: 5| Step: 2
Training loss: 2.0877816838247156
Validation loss: 2.510887011728677

Epoch: 5| Step: 3
Training loss: 1.5924921494893791
Validation loss: 2.5468970007858074

Epoch: 5| Step: 4
Training loss: 1.452437945959201
Validation loss: 2.5543339810126096

Epoch: 5| Step: 5
Training loss: 1.6585087758459722
Validation loss: 2.5177620551889053

Epoch: 5| Step: 6
Training loss: 1.470523331836771
Validation loss: 2.478169856531705

Epoch: 5| Step: 7
Training loss: 1.57747659487523
Validation loss: 2.458599741123273

Epoch: 5| Step: 8
Training loss: 2.4743199348537464
Validation loss: 2.3831932319126925

Epoch: 5| Step: 9
Training loss: 1.5228727418728898
Validation loss: 2.344382375634476

Epoch: 5| Step: 10
Training loss: 1.994159933775734
Validation loss: 2.3381561652925518

Epoch: 344| Step: 0
Training loss: 1.8890717486461976
Validation loss: 2.3548319485747533

Epoch: 5| Step: 1
Training loss: 2.170904038559745
Validation loss: 2.402335130682902

Epoch: 5| Step: 2
Training loss: 1.9311840107825555
Validation loss: 2.4042396665557315

Epoch: 5| Step: 3
Training loss: 1.3486389115821988
Validation loss: 2.4420841664226005

Epoch: 5| Step: 4
Training loss: 1.722164300060772
Validation loss: 2.490333937911236

Epoch: 5| Step: 5
Training loss: 1.550036811391491
Validation loss: 2.5214344393770776

Epoch: 5| Step: 6
Training loss: 1.5751963720063857
Validation loss: 2.5181095340771718

Epoch: 5| Step: 7
Training loss: 1.4832465450028662
Validation loss: 2.5129341740909825

Epoch: 5| Step: 8
Training loss: 2.095853062480592
Validation loss: 2.4967424765891364

Epoch: 5| Step: 9
Training loss: 1.463341840720737
Validation loss: 2.4800013009910464

Epoch: 5| Step: 10
Training loss: 2.2367868277861804
Validation loss: 2.447246413848718

Epoch: 345| Step: 0
Training loss: 1.6879840439182425
Validation loss: 2.445870003681547

Epoch: 5| Step: 1
Training loss: 1.5657843594338918
Validation loss: 2.4545710633087148

Epoch: 5| Step: 2
Training loss: 2.1801681808903077
Validation loss: 2.478581826343365

Epoch: 5| Step: 3
Training loss: 1.2581241766466913
Validation loss: 2.4940288565329607

Epoch: 5| Step: 4
Training loss: 1.6948923741832982
Validation loss: 2.493798979257326

Epoch: 5| Step: 5
Training loss: 1.8546761516426322
Validation loss: 2.502029902301366

Epoch: 5| Step: 6
Training loss: 1.247541202789744
Validation loss: 2.5116257773213646

Epoch: 5| Step: 7
Training loss: 1.642014124290317
Validation loss: 2.5069793420212734

Epoch: 5| Step: 8
Training loss: 2.197409825997393
Validation loss: 2.51906343062775

Epoch: 5| Step: 9
Training loss: 1.9137003653360558
Validation loss: 2.465750528828634

Epoch: 5| Step: 10
Training loss: 1.904168728160229
Validation loss: 2.4381344676524037

Epoch: 346| Step: 0
Training loss: 1.9897997140972956
Validation loss: 2.3802453683066043

Epoch: 5| Step: 1
Training loss: 1.683927852466917
Validation loss: 2.370575657360096

Epoch: 5| Step: 2
Training loss: 2.180866100554402
Validation loss: 2.369431585257048

Epoch: 5| Step: 3
Training loss: 1.9212663508596184
Validation loss: 2.3794301320975584

Epoch: 5| Step: 4
Training loss: 1.4419499227423451
Validation loss: 2.4179311385564217

Epoch: 5| Step: 5
Training loss: 1.6527061696216507
Validation loss: 2.421578995276281

Epoch: 5| Step: 6
Training loss: 1.581743228266597
Validation loss: 2.4619717311738825

Epoch: 5| Step: 7
Training loss: 1.3448621007004817
Validation loss: 2.456253208981905

Epoch: 5| Step: 8
Training loss: 1.4595101467510385
Validation loss: 2.472657413285077

Epoch: 5| Step: 9
Training loss: 2.179221920482386
Validation loss: 2.470552534340395

Epoch: 5| Step: 10
Training loss: 1.8141159877728037
Validation loss: 2.4448058844491447

Epoch: 347| Step: 0
Training loss: 1.741354362498583
Validation loss: 2.3775482625822195

Epoch: 5| Step: 1
Training loss: 2.152749246661172
Validation loss: 2.345764649519196

Epoch: 5| Step: 2
Training loss: 2.158049454547487
Validation loss: 2.3226825421935846

Epoch: 5| Step: 3
Training loss: 2.07826324232534
Validation loss: 2.3267060182819868

Epoch: 5| Step: 4
Training loss: 1.7003721334765125
Validation loss: 2.341616313843867

Epoch: 5| Step: 5
Training loss: 1.1203829010320208
Validation loss: 2.4131189181389363

Epoch: 5| Step: 6
Training loss: 1.5762551438128938
Validation loss: 2.4779653698708266

Epoch: 5| Step: 7
Training loss: 2.2021861138683865
Validation loss: 2.5413307386197688

Epoch: 5| Step: 8
Training loss: 1.7976578707068083
Validation loss: 2.4786099865124998

Epoch: 5| Step: 9
Training loss: 1.357039275554672
Validation loss: 2.457234149580649

Epoch: 5| Step: 10
Training loss: 1.919010353442118
Validation loss: 2.4374329815683984

Epoch: 348| Step: 0
Training loss: 1.707111767020035
Validation loss: 2.4028254851251187

Epoch: 5| Step: 1
Training loss: 1.8567813767770938
Validation loss: 2.3926994496888643

Epoch: 5| Step: 2
Training loss: 1.8658395155065541
Validation loss: 2.4840536417281025

Epoch: 5| Step: 3
Training loss: 1.882019762484724
Validation loss: 2.5372178957908593

Epoch: 5| Step: 4
Training loss: 2.0502403490546177
Validation loss: 2.5672636386894747

Epoch: 5| Step: 5
Training loss: 1.5164115673760052
Validation loss: 2.543590389211862

Epoch: 5| Step: 6
Training loss: 1.7489174491764365
Validation loss: 2.475926001293423

Epoch: 5| Step: 7
Training loss: 1.8080804149881162
Validation loss: 2.4301503253735843

Epoch: 5| Step: 8
Training loss: 1.8898028012491814
Validation loss: 2.362874254249756

Epoch: 5| Step: 9
Training loss: 1.7644413043815501
Validation loss: 2.3607052157576964

Epoch: 5| Step: 10
Training loss: 1.3779435728199445
Validation loss: 2.368650699163656

Epoch: 349| Step: 0
Training loss: 1.9799285693722095
Validation loss: 2.3610302853568643

Epoch: 5| Step: 1
Training loss: 1.7279744308575604
Validation loss: 2.3649727433527135

Epoch: 5| Step: 2
Training loss: 1.1414528024568127
Validation loss: 2.396408626901285

Epoch: 5| Step: 3
Training loss: 2.006021376088007
Validation loss: 2.4317634175597487

Epoch: 5| Step: 4
Training loss: 2.353041073137083
Validation loss: 2.502710653071269

Epoch: 5| Step: 5
Training loss: 1.947555902973966
Validation loss: 2.5292609606221914

Epoch: 5| Step: 6
Training loss: 2.016767429430176
Validation loss: 2.518397151116448

Epoch: 5| Step: 7
Training loss: 1.3249661747195665
Validation loss: 2.4765002327370933

Epoch: 5| Step: 8
Training loss: 1.719079904972653
Validation loss: 2.4510030039432515

Epoch: 5| Step: 9
Training loss: 1.6168609141947956
Validation loss: 2.448285705006082

Epoch: 5| Step: 10
Training loss: 1.4193517072774513
Validation loss: 2.424048537072881

Epoch: 350| Step: 0
Training loss: 1.8429105108291837
Validation loss: 2.4346082281391954

Epoch: 5| Step: 1
Training loss: 1.7297636709697126
Validation loss: 2.454293899445673

Epoch: 5| Step: 2
Training loss: 2.0557176451597368
Validation loss: 2.487834325493727

Epoch: 5| Step: 3
Training loss: 1.509144960173966
Validation loss: 2.531331642218739

Epoch: 5| Step: 4
Training loss: 1.7010212775754825
Validation loss: 2.600618346244181

Epoch: 5| Step: 5
Training loss: 1.6532300371285487
Validation loss: 2.5816055246484324

Epoch: 5| Step: 6
Training loss: 1.6015698688616682
Validation loss: 2.529885207070401

Epoch: 5| Step: 7
Training loss: 1.9496839805212964
Validation loss: 2.421464522313159

Epoch: 5| Step: 8
Training loss: 1.6359414961364382
Validation loss: 2.3732212316057697

Epoch: 5| Step: 9
Training loss: 1.7215034624032228
Validation loss: 2.316062570976234

Epoch: 5| Step: 10
Training loss: 1.635034245123646
Validation loss: 2.312859109069151

Epoch: 351| Step: 0
Training loss: 1.7915289922056328
Validation loss: 2.3283618124667376

Epoch: 5| Step: 1
Training loss: 1.75260200519249
Validation loss: 2.315004438771069

Epoch: 5| Step: 2
Training loss: 1.5788265972629336
Validation loss: 2.325491971739636

Epoch: 5| Step: 3
Training loss: 1.643833329441927
Validation loss: 2.3496090258504463

Epoch: 5| Step: 4
Training loss: 1.3920196226479842
Validation loss: 2.3767986233407155

Epoch: 5| Step: 5
Training loss: 2.0740355214946025
Validation loss: 2.4638366050913447

Epoch: 5| Step: 6
Training loss: 1.5498347625025712
Validation loss: 2.5223564205156643

Epoch: 5| Step: 7
Training loss: 1.5094311974214478
Validation loss: 2.5798054259812835

Epoch: 5| Step: 8
Training loss: 1.9837456854212665
Validation loss: 2.619942323753897

Epoch: 5| Step: 9
Training loss: 1.940056498579844
Validation loss: 2.600832919283176

Epoch: 5| Step: 10
Training loss: 1.6442715038756957
Validation loss: 2.53245340006295

Epoch: 352| Step: 0
Training loss: 1.6768079338069855
Validation loss: 2.489323637537314

Epoch: 5| Step: 1
Training loss: 1.611811081150322
Validation loss: 2.4539380335290177

Epoch: 5| Step: 2
Training loss: 1.8529518162308796
Validation loss: 2.4009456183328695

Epoch: 5| Step: 3
Training loss: 1.7725103029885156
Validation loss: 2.3716341313716445

Epoch: 5| Step: 4
Training loss: 1.7304235585944476
Validation loss: 2.327553766478442

Epoch: 5| Step: 5
Training loss: 1.2645787753798636
Validation loss: 2.326041633484684

Epoch: 5| Step: 6
Training loss: 1.4622853635130464
Validation loss: 2.3559075344793947

Epoch: 5| Step: 7
Training loss: 1.4470481554730004
Validation loss: 2.413874510685952

Epoch: 5| Step: 8
Training loss: 2.0335498407923454
Validation loss: 2.480120950800005

Epoch: 5| Step: 9
Training loss: 2.234832290057815
Validation loss: 2.563124407775215

Epoch: 5| Step: 10
Training loss: 1.5491601268239703
Validation loss: 2.649603649356475

Epoch: 353| Step: 0
Training loss: 1.9541094930889171
Validation loss: 2.6448668634138497

Epoch: 5| Step: 1
Training loss: 1.3995627452717423
Validation loss: 2.5738496902525028

Epoch: 5| Step: 2
Training loss: 1.7492544766006661
Validation loss: 2.553865230476832

Epoch: 5| Step: 3
Training loss: 1.4179000627679783
Validation loss: 2.4638794424155517

Epoch: 5| Step: 4
Training loss: 1.6246330140272707
Validation loss: 2.4592130782178128

Epoch: 5| Step: 5
Training loss: 1.730288528460971
Validation loss: 2.4064229459049478

Epoch: 5| Step: 6
Training loss: 1.7802312514286542
Validation loss: 2.4134710054312256

Epoch: 5| Step: 7
Training loss: 1.78596928819349
Validation loss: 2.4084024953834047

Epoch: 5| Step: 8
Training loss: 1.5314337950970192
Validation loss: 2.4026874703524954

Epoch: 5| Step: 9
Training loss: 1.9678337750519863
Validation loss: 2.406493807585249

Epoch: 5| Step: 10
Training loss: 1.6456645766387847
Validation loss: 2.4384851570977846

Epoch: 354| Step: 0
Training loss: 1.6888240282392226
Validation loss: 2.482409090440176

Epoch: 5| Step: 1
Training loss: 2.156164526973002
Validation loss: 2.494558999959819

Epoch: 5| Step: 2
Training loss: 1.7695856822822897
Validation loss: 2.501411691603822

Epoch: 5| Step: 3
Training loss: 1.9045727965167005
Validation loss: 2.447708699842421

Epoch: 5| Step: 4
Training loss: 1.6205041019819744
Validation loss: 2.4089319172123296

Epoch: 5| Step: 5
Training loss: 1.227793859047577
Validation loss: 2.361544917230004

Epoch: 5| Step: 6
Training loss: 1.406985069588813
Validation loss: 2.3598212917676564

Epoch: 5| Step: 7
Training loss: 1.563543505310699
Validation loss: 2.372801805612579

Epoch: 5| Step: 8
Training loss: 1.3798953823156919
Validation loss: 2.3712972977421853

Epoch: 5| Step: 9
Training loss: 2.007088259685041
Validation loss: 2.3950502597014656

Epoch: 5| Step: 10
Training loss: 1.0832218821979123
Validation loss: 2.441121161110118

Epoch: 355| Step: 0
Training loss: 1.939830854651875
Validation loss: 2.5119395667319844

Epoch: 5| Step: 1
Training loss: 1.7178945319783454
Validation loss: 2.550617392845495

Epoch: 5| Step: 2
Training loss: 1.720359672710378
Validation loss: 2.5374444892130117

Epoch: 5| Step: 3
Training loss: 0.9755783615352739
Validation loss: 2.5021292755648763

Epoch: 5| Step: 4
Training loss: 1.3640894639189345
Validation loss: 2.4451716510668895

Epoch: 5| Step: 5
Training loss: 1.5382830199875148
Validation loss: 2.446088309079617

Epoch: 5| Step: 6
Training loss: 1.4385993734170903
Validation loss: 2.435105183588063

Epoch: 5| Step: 7
Training loss: 1.4747315210949121
Validation loss: 2.4331204858447664

Epoch: 5| Step: 8
Training loss: 2.065555967253713
Validation loss: 2.441808423066194

Epoch: 5| Step: 9
Training loss: 1.602837552778295
Validation loss: 2.4427901382718975

Epoch: 5| Step: 10
Training loss: 1.8223833739087458
Validation loss: 2.4641254195381808

Epoch: 356| Step: 0
Training loss: 1.7242590957850803
Validation loss: 2.4962417194330726

Epoch: 5| Step: 1
Training loss: 1.5199583576170008
Validation loss: 2.508743158937888

Epoch: 5| Step: 2
Training loss: 1.6834671433145432
Validation loss: 2.5423547878047943

Epoch: 5| Step: 3
Training loss: 1.658551614219844
Validation loss: 2.5382292672223317

Epoch: 5| Step: 4
Training loss: 1.5127032718732256
Validation loss: 2.5544386628966875

Epoch: 5| Step: 5
Training loss: 2.1367540095068396
Validation loss: 2.515955949140991

Epoch: 5| Step: 6
Training loss: 1.5848001244569485
Validation loss: 2.457047706284265

Epoch: 5| Step: 7
Training loss: 1.0772596562949381
Validation loss: 2.4553930445585883

Epoch: 5| Step: 8
Training loss: 1.7585727658199748
Validation loss: 2.420418839889834

Epoch: 5| Step: 9
Training loss: 1.1671529108562646
Validation loss: 2.3836808345075235

Epoch: 5| Step: 10
Training loss: 1.765853124414311
Validation loss: 2.3358509589432686

Epoch: 357| Step: 0
Training loss: 1.8095635271434105
Validation loss: 2.373577994004166

Epoch: 5| Step: 1
Training loss: 1.5526874655109475
Validation loss: 2.329515225827084

Epoch: 5| Step: 2
Training loss: 1.4333783645357527
Validation loss: 2.3374137552786793

Epoch: 5| Step: 3
Training loss: 1.6682357395728236
Validation loss: 2.376614634341479

Epoch: 5| Step: 4
Training loss: 1.4554003877090664
Validation loss: 2.429005393412025

Epoch: 5| Step: 5
Training loss: 1.538964592777321
Validation loss: 2.4941951783549037

Epoch: 5| Step: 6
Training loss: 2.162446999313812
Validation loss: 2.5566065998687213

Epoch: 5| Step: 7
Training loss: 1.9474585771378987
Validation loss: 2.5498020512709374

Epoch: 5| Step: 8
Training loss: 1.1986756228701827
Validation loss: 2.602760960019076

Epoch: 5| Step: 9
Training loss: 1.4657273539446838
Validation loss: 2.6088238854347283

Epoch: 5| Step: 10
Training loss: 1.6288272829377006
Validation loss: 2.5399903354423765

Epoch: 358| Step: 0
Training loss: 1.4785206239079132
Validation loss: 2.467398174080065

Epoch: 5| Step: 1
Training loss: 1.0827967831130167
Validation loss: 2.4175350717340183

Epoch: 5| Step: 2
Training loss: 1.960115784903604
Validation loss: 2.392104858174216

Epoch: 5| Step: 3
Training loss: 1.9233188322943129
Validation loss: 2.33430394261389

Epoch: 5| Step: 4
Training loss: 1.3354659112587925
Validation loss: 2.368821899940207

Epoch: 5| Step: 5
Training loss: 1.139457052418267
Validation loss: 2.4007104363085925

Epoch: 5| Step: 6
Training loss: 1.7996763865648882
Validation loss: 2.4353720529564877

Epoch: 5| Step: 7
Training loss: 1.5271691420083802
Validation loss: 2.4849083255058826

Epoch: 5| Step: 8
Training loss: 1.5328679781487504
Validation loss: 2.480102865544896

Epoch: 5| Step: 9
Training loss: 1.39087349032391
Validation loss: 2.5142724496502917

Epoch: 5| Step: 10
Training loss: 2.094588837619842
Validation loss: 2.5095809248658365

Epoch: 359| Step: 0
Training loss: 1.2049538719877055
Validation loss: 2.442564594158921

Epoch: 5| Step: 1
Training loss: 1.9532073957229394
Validation loss: 2.4231532243037606

Epoch: 5| Step: 2
Training loss: 1.0967972947986722
Validation loss: 2.3893465337630824

Epoch: 5| Step: 3
Training loss: 2.095285222887969
Validation loss: 2.395457051936137

Epoch: 5| Step: 4
Training loss: 1.6973731530371408
Validation loss: 2.424464888925139

Epoch: 5| Step: 5
Training loss: 1.4414151819464112
Validation loss: 2.413609593731713

Epoch: 5| Step: 6
Training loss: 1.5581713417160719
Validation loss: 2.421648414113425

Epoch: 5| Step: 7
Training loss: 1.1891749766183524
Validation loss: 2.469596938702993

Epoch: 5| Step: 8
Training loss: 1.4432534887475528
Validation loss: 2.447666224696417

Epoch: 5| Step: 9
Training loss: 1.7263652982333535
Validation loss: 2.500359227407949

Epoch: 5| Step: 10
Training loss: 1.7128312591043278
Validation loss: 2.494435364409419

Epoch: 360| Step: 0
Training loss: 1.5163135341028957
Validation loss: 2.492612832474483

Epoch: 5| Step: 1
Training loss: 1.345111866521302
Validation loss: 2.447817238328996

Epoch: 5| Step: 2
Training loss: 1.773136130114137
Validation loss: 2.4242009040371

Epoch: 5| Step: 3
Training loss: 1.1559608200950886
Validation loss: 2.4143235754079058

Epoch: 5| Step: 4
Training loss: 1.6047617151320366
Validation loss: 2.3947407232494236

Epoch: 5| Step: 5
Training loss: 1.6398189199311566
Validation loss: 2.4066554136708826

Epoch: 5| Step: 6
Training loss: 1.4363964654860408
Validation loss: 2.388334846621762

Epoch: 5| Step: 7
Training loss: 1.530870195892239
Validation loss: 2.4183500913178437

Epoch: 5| Step: 8
Training loss: 1.691575533036011
Validation loss: 2.4730234911981355

Epoch: 5| Step: 9
Training loss: 1.6149289489328371
Validation loss: 2.479294953956977

Epoch: 5| Step: 10
Training loss: 1.7074682867810924
Validation loss: 2.499498043120609

Epoch: 361| Step: 0
Training loss: 1.1214218988558498
Validation loss: 2.472972815459192

Epoch: 5| Step: 1
Training loss: 1.1881886041704428
Validation loss: 2.4733693561756076

Epoch: 5| Step: 2
Training loss: 1.0565088440235604
Validation loss: 2.4774619432384455

Epoch: 5| Step: 3
Training loss: 2.135921015532814
Validation loss: 2.444385389900057

Epoch: 5| Step: 4
Training loss: 1.9633730167508348
Validation loss: 2.42570066953113

Epoch: 5| Step: 5
Training loss: 1.0585792230826931
Validation loss: 2.431700081692837

Epoch: 5| Step: 6
Training loss: 1.496021876588278
Validation loss: 2.449713925118821

Epoch: 5| Step: 7
Training loss: 1.518998942753397
Validation loss: 2.4348649031827665

Epoch: 5| Step: 8
Training loss: 1.4909339152836527
Validation loss: 2.425006042107583

Epoch: 5| Step: 9
Training loss: 1.7281310262454264
Validation loss: 2.4598974089686183

Epoch: 5| Step: 10
Training loss: 1.6769050440192208
Validation loss: 2.4396130947401033

Epoch: 362| Step: 0
Training loss: 1.200564694654953
Validation loss: 2.4560286632313706

Epoch: 5| Step: 1
Training loss: 1.7125071114719614
Validation loss: 2.4652558222090595

Epoch: 5| Step: 2
Training loss: 1.9166723403293835
Validation loss: 2.443503687828216

Epoch: 5| Step: 3
Training loss: 1.649158699680776
Validation loss: 2.459522158696667

Epoch: 5| Step: 4
Training loss: 1.388298789339143
Validation loss: 2.444890707946067

Epoch: 5| Step: 5
Training loss: 1.5714787948930338
Validation loss: 2.4664954652659485

Epoch: 5| Step: 6
Training loss: 1.4763944015487733
Validation loss: 2.4777172415704594

Epoch: 5| Step: 7
Training loss: 1.630406263074366
Validation loss: 2.4661177619637336

Epoch: 5| Step: 8
Training loss: 1.1642301297940365
Validation loss: 2.455987546997095

Epoch: 5| Step: 9
Training loss: 1.465700351754554
Validation loss: 2.4324627234432445

Epoch: 5| Step: 10
Training loss: 1.2129277271241272
Validation loss: 2.4119486732286153

Epoch: 363| Step: 0
Training loss: 1.3035526479573827
Validation loss: 2.412178364916665

Epoch: 5| Step: 1
Training loss: 1.5165378928099256
Validation loss: 2.392622900303821

Epoch: 5| Step: 2
Training loss: 1.3472681343583925
Validation loss: 2.3732690866886528

Epoch: 5| Step: 3
Training loss: 1.9244083981714695
Validation loss: 2.4177645465640403

Epoch: 5| Step: 4
Training loss: 1.2332889269661507
Validation loss: 2.4109455645094466

Epoch: 5| Step: 5
Training loss: 1.8479950092256539
Validation loss: 2.4572149235111835

Epoch: 5| Step: 6
Training loss: 1.554832796754573
Validation loss: 2.4834588703414453

Epoch: 5| Step: 7
Training loss: 1.524071664131463
Validation loss: 2.4857619285117876

Epoch: 5| Step: 8
Training loss: 1.3922830191402726
Validation loss: 2.486716049407458

Epoch: 5| Step: 9
Training loss: 1.567438256539815
Validation loss: 2.4915683741217634

Epoch: 5| Step: 10
Training loss: 1.077170460839849
Validation loss: 2.5072449946822544

Epoch: 364| Step: 0
Training loss: 1.3973122443659487
Validation loss: 2.483252046260469

Epoch: 5| Step: 1
Training loss: 1.4453190159006415
Validation loss: 2.482411598406394

Epoch: 5| Step: 2
Training loss: 1.488476517650652
Validation loss: 2.470310399781676

Epoch: 5| Step: 3
Training loss: 1.7633025161752038
Validation loss: 2.4240852075444796

Epoch: 5| Step: 4
Training loss: 1.1594111043649986
Validation loss: 2.3983845620904964

Epoch: 5| Step: 5
Training loss: 1.3184706803419122
Validation loss: 2.399852978333183

Epoch: 5| Step: 6
Training loss: 1.8180913512524677
Validation loss: 2.43163726288491

Epoch: 5| Step: 7
Training loss: 1.4428318489533865
Validation loss: 2.4735635622309555

Epoch: 5| Step: 8
Training loss: 1.5353928400655596
Validation loss: 2.4920421939490027

Epoch: 5| Step: 9
Training loss: 1.082267762924635
Validation loss: 2.5442718624419767

Epoch: 5| Step: 10
Training loss: 1.8774800746789966
Validation loss: 2.5467302271300825

Epoch: 365| Step: 0
Training loss: 1.339106498716508
Validation loss: 2.501461897800404

Epoch: 5| Step: 1
Training loss: 1.3411846513284609
Validation loss: 2.457590531812964

Epoch: 5| Step: 2
Training loss: 1.1907253133011597
Validation loss: 2.395171402439297

Epoch: 5| Step: 3
Training loss: 1.7129787304966846
Validation loss: 2.388448716708967

Epoch: 5| Step: 4
Training loss: 1.101743534443968
Validation loss: 2.365259240261261

Epoch: 5| Step: 5
Training loss: 1.772837734893435
Validation loss: 2.4055181247129998

Epoch: 5| Step: 6
Training loss: 1.472912510601189
Validation loss: 2.412373951917461

Epoch: 5| Step: 7
Training loss: 1.3152493790126742
Validation loss: 2.441643998840447

Epoch: 5| Step: 8
Training loss: 2.0904844638819227
Validation loss: 2.439901207803857

Epoch: 5| Step: 9
Training loss: 1.3260698911305637
Validation loss: 2.4769966891579096

Epoch: 5| Step: 10
Training loss: 1.3991254680642646
Validation loss: 2.462362640041183

Epoch: 366| Step: 0
Training loss: 1.5502199170780713
Validation loss: 2.466622820012453

Epoch: 5| Step: 1
Training loss: 1.4125578657467264
Validation loss: 2.4428822781049986

Epoch: 5| Step: 2
Training loss: 1.6976410655761476
Validation loss: 2.410722196580866

Epoch: 5| Step: 3
Training loss: 1.080588911522868
Validation loss: 2.3550096796183144

Epoch: 5| Step: 4
Training loss: 2.0541131554907834
Validation loss: 2.3629003334580685

Epoch: 5| Step: 5
Training loss: 1.1627783124286288
Validation loss: 2.350653183155984

Epoch: 5| Step: 6
Training loss: 1.4910719931073584
Validation loss: 2.380266960884842

Epoch: 5| Step: 7
Training loss: 1.763112872006618
Validation loss: 2.446529119978074

Epoch: 5| Step: 8
Training loss: 1.3342280465532683
Validation loss: 2.453980126410406

Epoch: 5| Step: 9
Training loss: 0.9482748731171524
Validation loss: 2.4644767181528606

Epoch: 5| Step: 10
Training loss: 1.2661369136159786
Validation loss: 2.474290729120202

Epoch: 367| Step: 0
Training loss: 1.4829179539379689
Validation loss: 2.454309622010625

Epoch: 5| Step: 1
Training loss: 1.5326712104782
Validation loss: 2.4741984679036335

Epoch: 5| Step: 2
Training loss: 1.242446440572774
Validation loss: 2.4470706078916225

Epoch: 5| Step: 3
Training loss: 1.3660781719493675
Validation loss: 2.3976344018990567

Epoch: 5| Step: 4
Training loss: 1.5434802788851476
Validation loss: 2.404804472078694

Epoch: 5| Step: 5
Training loss: 1.3055879603528528
Validation loss: 2.414953978170128

Epoch: 5| Step: 6
Training loss: 1.5789348677090151
Validation loss: 2.413965916947416

Epoch: 5| Step: 7
Training loss: 1.7445898214468136
Validation loss: 2.457201839306583

Epoch: 5| Step: 8
Training loss: 1.547169743980945
Validation loss: 2.4345223892861827

Epoch: 5| Step: 9
Training loss: 0.7259781651431731
Validation loss: 2.4654897224252865

Epoch: 5| Step: 10
Training loss: 1.7304134316999344
Validation loss: 2.455290181435233

Epoch: 368| Step: 0
Training loss: 1.796737002173793
Validation loss: 2.4411962884346634

Epoch: 5| Step: 1
Training loss: 1.5025469296912768
Validation loss: 2.464255521526443

Epoch: 5| Step: 2
Training loss: 1.6853254930931525
Validation loss: 2.4512484178471414

Epoch: 5| Step: 3
Training loss: 1.422219790060891
Validation loss: 2.441385702198477

Epoch: 5| Step: 4
Training loss: 1.4368757468110045
Validation loss: 2.4478357574420033

Epoch: 5| Step: 5
Training loss: 0.9959006627251168
Validation loss: 2.4308219914426243

Epoch: 5| Step: 6
Training loss: 1.5714360862403625
Validation loss: 2.413020399837765

Epoch: 5| Step: 7
Training loss: 1.35794263771382
Validation loss: 2.425089137320117

Epoch: 5| Step: 8
Training loss: 1.2931989943074764
Validation loss: 2.4045085259860954

Epoch: 5| Step: 9
Training loss: 1.1966827118593963
Validation loss: 2.387535634671771

Epoch: 5| Step: 10
Training loss: 1.3335402099731735
Validation loss: 2.416730757539909

Epoch: 369| Step: 0
Training loss: 1.4306548967816461
Validation loss: 2.4183336134034414

Epoch: 5| Step: 1
Training loss: 1.252044198328548
Validation loss: 2.4036385586489994

Epoch: 5| Step: 2
Training loss: 1.5914884490787313
Validation loss: 2.397658684159927

Epoch: 5| Step: 3
Training loss: 1.376636831331273
Validation loss: 2.3640350303113706

Epoch: 5| Step: 4
Training loss: 1.3723770178917183
Validation loss: 2.3598984347743244

Epoch: 5| Step: 5
Training loss: 1.3889889040010102
Validation loss: 2.4051986888628414

Epoch: 5| Step: 6
Training loss: 1.0277482893439374
Validation loss: 2.4755700668328164

Epoch: 5| Step: 7
Training loss: 1.329140219031662
Validation loss: 2.492739077078161

Epoch: 5| Step: 8
Training loss: 1.1610339919148684
Validation loss: 2.529706937093294

Epoch: 5| Step: 9
Training loss: 2.0085162996177246
Validation loss: 2.5094785439053844

Epoch: 5| Step: 10
Training loss: 1.4428358974133628
Validation loss: 2.543751005360136

Epoch: 370| Step: 0
Training loss: 1.403167737552083
Validation loss: 2.5194373547412203

Epoch: 5| Step: 1
Training loss: 1.4543028129233044
Validation loss: 2.4760474914342563

Epoch: 5| Step: 2
Training loss: 1.4871787645981582
Validation loss: 2.4786040444186708

Epoch: 5| Step: 3
Training loss: 1.7476163024838711
Validation loss: 2.441506897916975

Epoch: 5| Step: 4
Training loss: 0.8505877594430113
Validation loss: 2.400142430194654

Epoch: 5| Step: 5
Training loss: 1.2178831685788827
Validation loss: 2.417299322189045

Epoch: 5| Step: 6
Training loss: 1.7545073908478683
Validation loss: 2.432706433144395

Epoch: 5| Step: 7
Training loss: 1.2892055547693393
Validation loss: 2.4259302649240477

Epoch: 5| Step: 8
Training loss: 1.4974771582592026
Validation loss: 2.4442199816134647

Epoch: 5| Step: 9
Training loss: 1.5418791581535787
Validation loss: 2.411050937552844

Epoch: 5| Step: 10
Training loss: 1.2695733166107424
Validation loss: 2.4044305373331825

Epoch: 371| Step: 0
Training loss: 1.179762376846865
Validation loss: 2.3848162250603435

Epoch: 5| Step: 1
Training loss: 1.4773283894596165
Validation loss: 2.4053345968486295

Epoch: 5| Step: 2
Training loss: 1.2903575056583165
Validation loss: 2.417734951369662

Epoch: 5| Step: 3
Training loss: 1.5553706982688091
Validation loss: 2.4409781504704986

Epoch: 5| Step: 4
Training loss: 1.559356961499539
Validation loss: 2.518075391465801

Epoch: 5| Step: 5
Training loss: 1.3206979313150013
Validation loss: 2.4726680715221594

Epoch: 5| Step: 6
Training loss: 1.3360222237474595
Validation loss: 2.456286721559239

Epoch: 5| Step: 7
Training loss: 1.3464492921655036
Validation loss: 2.395126198469114

Epoch: 5| Step: 8
Training loss: 1.4786646980711684
Validation loss: 2.378548855454329

Epoch: 5| Step: 9
Training loss: 1.4011087744238986
Validation loss: 2.373774616630246

Epoch: 5| Step: 10
Training loss: 1.6142490245951435
Validation loss: 2.3683686294893485

Epoch: 372| Step: 0
Training loss: 1.0417615211532658
Validation loss: 2.3579163812985007

Epoch: 5| Step: 1
Training loss: 1.4257649459951798
Validation loss: 2.376879968617098

Epoch: 5| Step: 2
Training loss: 0.8080317068866212
Validation loss: 2.385124138811284

Epoch: 5| Step: 3
Training loss: 1.6727102457139231
Validation loss: 2.398675829043729

Epoch: 5| Step: 4
Training loss: 1.4790929677449847
Validation loss: 2.383448110418792

Epoch: 5| Step: 5
Training loss: 1.453960629634608
Validation loss: 2.3928062133691905

Epoch: 5| Step: 6
Training loss: 1.4519203689324518
Validation loss: 2.4191962897056216

Epoch: 5| Step: 7
Training loss: 1.42158991711958
Validation loss: 2.4837266836209357

Epoch: 5| Step: 8
Training loss: 1.5731681555313797
Validation loss: 2.570039595706748

Epoch: 5| Step: 9
Training loss: 1.6319335323897795
Validation loss: 2.5538424354559113

Epoch: 5| Step: 10
Training loss: 1.4941523532781116
Validation loss: 2.5541497189735507

Epoch: 373| Step: 0
Training loss: 1.6547662098493048
Validation loss: 2.5493669808344066

Epoch: 5| Step: 1
Training loss: 1.2587500448520506
Validation loss: 2.4918968670795127

Epoch: 5| Step: 2
Training loss: 1.2243939321241097
Validation loss: 2.41930410725034

Epoch: 5| Step: 3
Training loss: 1.6321085457327007
Validation loss: 2.386611905203864

Epoch: 5| Step: 4
Training loss: 1.3901880842338918
Validation loss: 2.397454900140631

Epoch: 5| Step: 5
Training loss: 1.1394472181541757
Validation loss: 2.3775812207760767

Epoch: 5| Step: 6
Training loss: 1.6963610944019873
Validation loss: 2.4273606705725452

Epoch: 5| Step: 7
Training loss: 1.3015330207114917
Validation loss: 2.445620955609349

Epoch: 5| Step: 8
Training loss: 0.9556517955149433
Validation loss: 2.448247025259963

Epoch: 5| Step: 9
Training loss: 1.2002200441473925
Validation loss: 2.474000640317417

Epoch: 5| Step: 10
Training loss: 1.7495806736603001
Validation loss: 2.455870509662247

Epoch: 374| Step: 0
Training loss: 1.2198016202386421
Validation loss: 2.4576345190555413

Epoch: 5| Step: 1
Training loss: 1.3605992296447995
Validation loss: 2.401750444790404

Epoch: 5| Step: 2
Training loss: 1.3560136474834075
Validation loss: 2.4312285789311394

Epoch: 5| Step: 3
Training loss: 1.5526788665638334
Validation loss: 2.407349266008904

Epoch: 5| Step: 4
Training loss: 1.1115078370147915
Validation loss: 2.436224411988342

Epoch: 5| Step: 5
Training loss: 1.6125092587463945
Validation loss: 2.4648103256849474

Epoch: 5| Step: 6
Training loss: 1.1376937931689157
Validation loss: 2.4598734664722577

Epoch: 5| Step: 7
Training loss: 1.1843511090850822
Validation loss: 2.4320538118988635

Epoch: 5| Step: 8
Training loss: 1.7385392244054036
Validation loss: 2.4409620721193925

Epoch: 5| Step: 9
Training loss: 1.5161963890013563
Validation loss: 2.393454357066791

Epoch: 5| Step: 10
Training loss: 1.1970375428745785
Validation loss: 2.384521439623236

Epoch: 375| Step: 0
Training loss: 1.8754280873207776
Validation loss: 2.4450831372044832

Epoch: 5| Step: 1
Training loss: 1.137861378873696
Validation loss: 2.490822875850809

Epoch: 5| Step: 2
Training loss: 1.439754211324238
Validation loss: 2.4914300866831622

Epoch: 5| Step: 3
Training loss: 1.2538346599926957
Validation loss: 2.5561890216222234

Epoch: 5| Step: 4
Training loss: 1.1246168755787669
Validation loss: 2.5697698079132705

Epoch: 5| Step: 5
Training loss: 1.5033627803791476
Validation loss: 2.484640308902228

Epoch: 5| Step: 6
Training loss: 1.226988505837374
Validation loss: 2.4345766305856906

Epoch: 5| Step: 7
Training loss: 1.3827170646192173
Validation loss: 2.384577178436539

Epoch: 5| Step: 8
Training loss: 1.4566014041873439
Validation loss: 2.3181234804844517

Epoch: 5| Step: 9
Training loss: 1.622247418697124
Validation loss: 2.2760139742045835

Epoch: 5| Step: 10
Training loss: 1.133621768618298
Validation loss: 2.3706687482427022

Epoch: 376| Step: 0
Training loss: 0.9092058122694133
Validation loss: 2.395643651728985

Epoch: 5| Step: 1
Training loss: 1.4739180201037547
Validation loss: 2.548655274456261

Epoch: 5| Step: 2
Training loss: 1.3828169828008199
Validation loss: 2.5446096321021927

Epoch: 5| Step: 3
Training loss: 1.1304405899600383
Validation loss: 2.564918184427394

Epoch: 5| Step: 4
Training loss: 0.9744430124795972
Validation loss: 2.5544575767164837

Epoch: 5| Step: 5
Training loss: 1.427387910440588
Validation loss: 2.5068952605329513

Epoch: 5| Step: 6
Training loss: 1.227359682753095
Validation loss: 2.5024389224556582

Epoch: 5| Step: 7
Training loss: 1.6840413996439403
Validation loss: 2.497620403759229

Epoch: 5| Step: 8
Training loss: 1.9302282772553832
Validation loss: 2.43451157984378

Epoch: 5| Step: 9
Training loss: 1.3533207036041341
Validation loss: 2.4778073024846945

Epoch: 5| Step: 10
Training loss: 1.1365910094542437
Validation loss: 2.421958682135837

Epoch: 377| Step: 0
Training loss: 1.6271358538498084
Validation loss: 2.4442819232585564

Epoch: 5| Step: 1
Training loss: 1.659238171009812
Validation loss: 2.459912143698789

Epoch: 5| Step: 2
Training loss: 1.0385252058177965
Validation loss: 2.503305356391635

Epoch: 5| Step: 3
Training loss: 1.4696157622790433
Validation loss: 2.5517148148394146

Epoch: 5| Step: 4
Training loss: 1.032668842707
Validation loss: 2.5280006200332212

Epoch: 5| Step: 5
Training loss: 1.1200212405949497
Validation loss: 2.5561900019715713

Epoch: 5| Step: 6
Training loss: 1.4754990073045255
Validation loss: 2.5900090926911834

Epoch: 5| Step: 7
Training loss: 1.310527681986182
Validation loss: 2.517436171503981

Epoch: 5| Step: 8
Training loss: 1.1912166256947831
Validation loss: 2.483929780524295

Epoch: 5| Step: 9
Training loss: 1.4436613807067658
Validation loss: 2.487633878481768

Epoch: 5| Step: 10
Training loss: 1.3665808067255774
Validation loss: 2.4115539987524404

Epoch: 378| Step: 0
Training loss: 1.202206446768801
Validation loss: 2.4128586452523124

Epoch: 5| Step: 1
Training loss: 1.2015036024086454
Validation loss: 2.416078270097941

Epoch: 5| Step: 2
Training loss: 1.0768284395838126
Validation loss: 2.408228352455665

Epoch: 5| Step: 3
Training loss: 1.2272984914612028
Validation loss: 2.4047524232470483

Epoch: 5| Step: 4
Training loss: 1.5726758338857245
Validation loss: 2.4396977777599442

Epoch: 5| Step: 5
Training loss: 1.4504328574913683
Validation loss: 2.4784842655251147

Epoch: 5| Step: 6
Training loss: 1.476275461544201
Validation loss: 2.4589675631288848

Epoch: 5| Step: 7
Training loss: 1.4545705844594
Validation loss: 2.5079096017354576

Epoch: 5| Step: 8
Training loss: 1.4828540438428817
Validation loss: 2.511309593630132

Epoch: 5| Step: 9
Training loss: 1.2643091402046436
Validation loss: 2.521529524537078

Epoch: 5| Step: 10
Training loss: 1.4475851800130985
Validation loss: 2.5035723440431004

Epoch: 379| Step: 0
Training loss: 1.073068342629439
Validation loss: 2.471819519637519

Epoch: 5| Step: 1
Training loss: 1.2499407277359549
Validation loss: 2.463518534693112

Epoch: 5| Step: 2
Training loss: 1.4341719706007066
Validation loss: 2.392951545295796

Epoch: 5| Step: 3
Training loss: 1.467588086839443
Validation loss: 2.36602127857449

Epoch: 5| Step: 4
Training loss: 1.2200642859609658
Validation loss: 2.297646073947927

Epoch: 5| Step: 5
Training loss: 1.6631756779039577
Validation loss: 2.29260934997328

Epoch: 5| Step: 6
Training loss: 1.7137517210926008
Validation loss: 2.315987722559163

Epoch: 5| Step: 7
Training loss: 1.4139772673995783
Validation loss: 2.4153015735260572

Epoch: 5| Step: 8
Training loss: 1.0103543776880906
Validation loss: 2.489256410830848

Epoch: 5| Step: 9
Training loss: 1.2738110047201487
Validation loss: 2.5425591746767724

Epoch: 5| Step: 10
Training loss: 1.2891778142965344
Validation loss: 2.5681306747537422

Epoch: 380| Step: 0
Training loss: 0.9842272450803707
Validation loss: 2.643554634647522

Epoch: 5| Step: 1
Training loss: 1.1417379305982385
Validation loss: 2.5466852092859775

Epoch: 5| Step: 2
Training loss: 1.233153209334615
Validation loss: 2.5244978938427884

Epoch: 5| Step: 3
Training loss: 1.7643701600978952
Validation loss: 2.452783701281321

Epoch: 5| Step: 4
Training loss: 1.7987072434953761
Validation loss: 2.3916253636190143

Epoch: 5| Step: 5
Training loss: 1.3502733112873355
Validation loss: 2.3680949811434417

Epoch: 5| Step: 6
Training loss: 1.3374709758996273
Validation loss: 2.4095784821060313

Epoch: 5| Step: 7
Training loss: 1.1656992625288911
Validation loss: 2.425784923541504

Epoch: 5| Step: 8
Training loss: 1.2603226723840966
Validation loss: 2.4624349788020505

Epoch: 5| Step: 9
Training loss: 1.293105196019888
Validation loss: 2.4960853958715443

Epoch: 5| Step: 10
Training loss: 1.5901494212686615
Validation loss: 2.504541682206623

Epoch: 381| Step: 0
Training loss: 1.2362394617478167
Validation loss: 2.4724893673524115

Epoch: 5| Step: 1
Training loss: 1.278008804076051
Validation loss: 2.451323481608264

Epoch: 5| Step: 2
Training loss: 1.6997885263966235
Validation loss: 2.4092992898247774

Epoch: 5| Step: 3
Training loss: 1.4036085115565484
Validation loss: 2.3888212881072883

Epoch: 5| Step: 4
Training loss: 1.232189126261548
Validation loss: 2.406286592262554

Epoch: 5| Step: 5
Training loss: 1.2969585529666718
Validation loss: 2.4113060652376404

Epoch: 5| Step: 6
Training loss: 1.3879155541931538
Validation loss: 2.414373923388662

Epoch: 5| Step: 7
Training loss: 1.1737795294478923
Validation loss: 2.49275111292026

Epoch: 5| Step: 8
Training loss: 1.0557035849880825
Validation loss: 2.4862613369829507

Epoch: 5| Step: 9
Training loss: 1.2779809138405578
Validation loss: 2.5261603316223575

Epoch: 5| Step: 10
Training loss: 1.6215033691587684
Validation loss: 2.5386151652844564

Epoch: 382| Step: 0
Training loss: 1.7777149525442457
Validation loss: 2.4934143077320057

Epoch: 5| Step: 1
Training loss: 1.2847085654188688
Validation loss: 2.5277825602683355

Epoch: 5| Step: 2
Training loss: 1.271610283074525
Validation loss: 2.4858820910123494

Epoch: 5| Step: 3
Training loss: 1.0218831846510197
Validation loss: 2.445741223434101

Epoch: 5| Step: 4
Training loss: 1.380808612154805
Validation loss: 2.4284697737086614

Epoch: 5| Step: 5
Training loss: 1.0536157885026707
Validation loss: 2.378954732134717

Epoch: 5| Step: 6
Training loss: 1.2950576089689605
Validation loss: 2.3554472734809586

Epoch: 5| Step: 7
Training loss: 1.559391286149532
Validation loss: 2.360384619617946

Epoch: 5| Step: 8
Training loss: 0.9350591355762954
Validation loss: 2.376684280296528

Epoch: 5| Step: 9
Training loss: 1.3422144610680224
Validation loss: 2.4212654481970852

Epoch: 5| Step: 10
Training loss: 1.4857079393780535
Validation loss: 2.4195141673179124

Epoch: 383| Step: 0
Training loss: 1.0995918665520248
Validation loss: 2.465214690362597

Epoch: 5| Step: 1
Training loss: 1.2859349080426965
Validation loss: 2.506484822511614

Epoch: 5| Step: 2
Training loss: 1.1526719999743384
Validation loss: 2.5173202934157257

Epoch: 5| Step: 3
Training loss: 1.6371543140837912
Validation loss: 2.542718210535676

Epoch: 5| Step: 4
Training loss: 1.3072298600175054
Validation loss: 2.47700644692481

Epoch: 5| Step: 5
Training loss: 1.7330840521458757
Validation loss: 2.4272314004748767

Epoch: 5| Step: 6
Training loss: 1.503946437546453
Validation loss: 2.399624112689835

Epoch: 5| Step: 7
Training loss: 1.2247462827334472
Validation loss: 2.3721900988422835

Epoch: 5| Step: 8
Training loss: 0.9644769751379704
Validation loss: 2.3378395882818768

Epoch: 5| Step: 9
Training loss: 1.1940326196345743
Validation loss: 2.3304115018892997

Epoch: 5| Step: 10
Training loss: 1.1111710207735448
Validation loss: 2.332891112127254

Epoch: 384| Step: 0
Training loss: 1.635803695205524
Validation loss: 2.374484377006202

Epoch: 5| Step: 1
Training loss: 1.1231805075046284
Validation loss: 2.419561424134634

Epoch: 5| Step: 2
Training loss: 1.3144899904429361
Validation loss: 2.4369304949822133

Epoch: 5| Step: 3
Training loss: 1.334495301373794
Validation loss: 2.474059383658008

Epoch: 5| Step: 4
Training loss: 0.8922439717660708
Validation loss: 2.4658215933737226

Epoch: 5| Step: 5
Training loss: 1.1812837424328282
Validation loss: 2.4729252860546453

Epoch: 5| Step: 6
Training loss: 0.9826498203246173
Validation loss: 2.413229139299967

Epoch: 5| Step: 7
Training loss: 1.2155935052944862
Validation loss: 2.432556303074365

Epoch: 5| Step: 8
Training loss: 1.381254104677203
Validation loss: 2.4301003506738086

Epoch: 5| Step: 9
Training loss: 1.2492309588801316
Validation loss: 2.446540221071069

Epoch: 5| Step: 10
Training loss: 1.7408548227350038
Validation loss: 2.412070470121461

Epoch: 385| Step: 0
Training loss: 0.9917897906657002
Validation loss: 2.42126510938043

Epoch: 5| Step: 1
Training loss: 0.8917079498562079
Validation loss: 2.4579985675524405

Epoch: 5| Step: 2
Training loss: 1.7468554992133254
Validation loss: 2.504451825692586

Epoch: 5| Step: 3
Training loss: 1.3477796415148544
Validation loss: 2.508231459401384

Epoch: 5| Step: 4
Training loss: 1.4140583691615682
Validation loss: 2.5364003198932954

Epoch: 5| Step: 5
Training loss: 1.5108244860572946
Validation loss: 2.4625748413865938

Epoch: 5| Step: 6
Training loss: 1.3721599726043172
Validation loss: 2.443637270268483

Epoch: 5| Step: 7
Training loss: 1.267316888301841
Validation loss: 2.37351414779233

Epoch: 5| Step: 8
Training loss: 1.3355972124349975
Validation loss: 2.3892797172409654

Epoch: 5| Step: 9
Training loss: 1.043478280521821
Validation loss: 2.381194541646441

Epoch: 5| Step: 10
Training loss: 0.767260886293147
Validation loss: 2.4049469650963737

Epoch: 386| Step: 0
Training loss: 0.96653287731797
Validation loss: 2.3664309776707824

Epoch: 5| Step: 1
Training loss: 1.0966791439989192
Validation loss: 2.3642556481721404

Epoch: 5| Step: 2
Training loss: 1.6212564042081792
Validation loss: 2.3908056461275127

Epoch: 5| Step: 3
Training loss: 1.1449140097466055
Validation loss: 2.409013036241015

Epoch: 5| Step: 4
Training loss: 1.275767155398308
Validation loss: 2.445618340205359

Epoch: 5| Step: 5
Training loss: 1.4141625637668547
Validation loss: 2.4256833326388265

Epoch: 5| Step: 6
Training loss: 1.4910886223473117
Validation loss: 2.4673674047749916

Epoch: 5| Step: 7
Training loss: 0.8014485997705582
Validation loss: 2.489261958799572

Epoch: 5| Step: 8
Training loss: 1.0913725490732606
Validation loss: 2.481214317957281

Epoch: 5| Step: 9
Training loss: 1.2576302343012582
Validation loss: 2.433452740050461

Epoch: 5| Step: 10
Training loss: 1.5280118685855586
Validation loss: 2.4960674103672016

Epoch: 387| Step: 0
Training loss: 1.361937026860518
Validation loss: 2.4319232495561556

Epoch: 5| Step: 1
Training loss: 1.5137863804976015
Validation loss: 2.393384936681843

Epoch: 5| Step: 2
Training loss: 1.137672993846265
Validation loss: 2.3654438101290935

Epoch: 5| Step: 3
Training loss: 0.9545845675505562
Validation loss: 2.3377324231192604

Epoch: 5| Step: 4
Training loss: 1.5903393022314212
Validation loss: 2.3260314749703244

Epoch: 5| Step: 5
Training loss: 1.2664990644666105
Validation loss: 2.349310862650735

Epoch: 5| Step: 6
Training loss: 1.2389624133100865
Validation loss: 2.3517577790994735

Epoch: 5| Step: 7
Training loss: 1.1165231183054976
Validation loss: 2.386652778315367

Epoch: 5| Step: 8
Training loss: 1.2708703124289211
Validation loss: 2.3952021583762715

Epoch: 5| Step: 9
Training loss: 1.14777079842181
Validation loss: 2.460393107032459

Epoch: 5| Step: 10
Training loss: 1.0095164952737208
Validation loss: 2.4895303433686604

Epoch: 388| Step: 0
Training loss: 1.0250735419337875
Validation loss: 2.4943942656215365

Epoch: 5| Step: 1
Training loss: 1.2838844569142718
Validation loss: 2.46330077907445

Epoch: 5| Step: 2
Training loss: 1.2450220647641441
Validation loss: 2.434429052670776

Epoch: 5| Step: 3
Training loss: 0.9520607932418603
Validation loss: 2.450927230601049

Epoch: 5| Step: 4
Training loss: 1.5104594345176452
Validation loss: 2.4136995846597666

Epoch: 5| Step: 5
Training loss: 1.2771848527261596
Validation loss: 2.339720780217686

Epoch: 5| Step: 6
Training loss: 0.9378109098508041
Validation loss: 2.364260033211095

Epoch: 5| Step: 7
Training loss: 1.6807252738662464
Validation loss: 2.3697980036623196

Epoch: 5| Step: 8
Training loss: 1.074266911207309
Validation loss: 2.3457331492106777

Epoch: 5| Step: 9
Training loss: 1.0886698864828672
Validation loss: 2.4157777830455482

Epoch: 5| Step: 10
Training loss: 1.401958954704113
Validation loss: 2.4441823482847025

Epoch: 389| Step: 0
Training loss: 1.1044776166769323
Validation loss: 2.4828885750552545

Epoch: 5| Step: 1
Training loss: 1.4152739167381747
Validation loss: 2.523795973536553

Epoch: 5| Step: 2
Training loss: 1.268667214610158
Validation loss: 2.5203630386158875

Epoch: 5| Step: 3
Training loss: 0.8154384955198881
Validation loss: 2.4776041507042987

Epoch: 5| Step: 4
Training loss: 0.9879802200155929
Validation loss: 2.4024902405800495

Epoch: 5| Step: 5
Training loss: 0.7986471628722255
Validation loss: 2.4009262191382876

Epoch: 5| Step: 6
Training loss: 1.1383636214405046
Validation loss: 2.3740526024947055

Epoch: 5| Step: 7
Training loss: 1.868194627686284
Validation loss: 2.3602760841829724

Epoch: 5| Step: 8
Training loss: 1.537149547551202
Validation loss: 2.3955494295594493

Epoch: 5| Step: 9
Training loss: 1.1860417396862106
Validation loss: 2.413177104325102

Epoch: 5| Step: 10
Training loss: 0.9882595074942003
Validation loss: 2.4621308401843023

Epoch: 390| Step: 0
Training loss: 1.2751443108064113
Validation loss: 2.42437915197645

Epoch: 5| Step: 1
Training loss: 0.8953163000428941
Validation loss: 2.443287243719439

Epoch: 5| Step: 2
Training loss: 1.3503381994265382
Validation loss: 2.494962574184506

Epoch: 5| Step: 3
Training loss: 1.4053466438487092
Validation loss: 2.476210171386977

Epoch: 5| Step: 4
Training loss: 0.7640965834428528
Validation loss: 2.4554314843589604

Epoch: 5| Step: 5
Training loss: 0.9453988154073629
Validation loss: 2.468463174386833

Epoch: 5| Step: 6
Training loss: 1.3723692435982877
Validation loss: 2.396091536794894

Epoch: 5| Step: 7
Training loss: 0.8750555497656298
Validation loss: 2.3740930396076814

Epoch: 5| Step: 8
Training loss: 0.9557716644290369
Validation loss: 2.3836647654586445

Epoch: 5| Step: 9
Training loss: 1.435293328347996
Validation loss: 2.3579688252254747

Epoch: 5| Step: 10
Training loss: 1.8688663612295167
Validation loss: 2.3523198033501016

Epoch: 391| Step: 0
Training loss: 1.084977967877984
Validation loss: 2.3584247401236604

Epoch: 5| Step: 1
Training loss: 1.2250923530643238
Validation loss: 2.3771138987001894

Epoch: 5| Step: 2
Training loss: 1.2524330302473328
Validation loss: 2.43848601497891

Epoch: 5| Step: 3
Training loss: 1.2654342507622904
Validation loss: 2.447180669065961

Epoch: 5| Step: 4
Training loss: 1.60671436410491
Validation loss: 2.476812004682304

Epoch: 5| Step: 5
Training loss: 0.959667172503915
Validation loss: 2.4572204488827785

Epoch: 5| Step: 6
Training loss: 1.3956660080252121
Validation loss: 2.45245931463275

Epoch: 5| Step: 7
Training loss: 0.8754649289490488
Validation loss: 2.4409198839298316

Epoch: 5| Step: 8
Training loss: 1.0300057736947907
Validation loss: 2.3962679760752224

Epoch: 5| Step: 9
Training loss: 1.0177349767773203
Validation loss: 2.4223872261987065

Epoch: 5| Step: 10
Training loss: 1.2362782737962437
Validation loss: 2.3954033942468826

Epoch: 392| Step: 0
Training loss: 1.3097447130562911
Validation loss: 2.41390922015428

Epoch: 5| Step: 1
Training loss: 0.8992233819784249
Validation loss: 2.398528658723245

Epoch: 5| Step: 2
Training loss: 1.1659449774779174
Validation loss: 2.4550333275715404

Epoch: 5| Step: 3
Training loss: 1.0726343851437963
Validation loss: 2.4608030986659606

Epoch: 5| Step: 4
Training loss: 1.2764054331343166
Validation loss: 2.460065739811475

Epoch: 5| Step: 5
Training loss: 0.8421643864391729
Validation loss: 2.491159969511488

Epoch: 5| Step: 6
Training loss: 1.1766979408070433
Validation loss: 2.4788812917906706

Epoch: 5| Step: 7
Training loss: 1.2125501661639293
Validation loss: 2.4739518239443536

Epoch: 5| Step: 8
Training loss: 1.1373929256305735
Validation loss: 2.437683952022679

Epoch: 5| Step: 9
Training loss: 1.7044873869281831
Validation loss: 2.4174093861510935

Epoch: 5| Step: 10
Training loss: 1.1086136797994661
Validation loss: 2.398589877290915

Epoch: 393| Step: 0
Training loss: 1.1474761572295162
Validation loss: 2.434395159686172

Epoch: 5| Step: 1
Training loss: 1.1262930750256925
Validation loss: 2.4108810245823062

Epoch: 5| Step: 2
Training loss: 1.288801687038461
Validation loss: 2.4437092642788802

Epoch: 5| Step: 3
Training loss: 1.247914147520415
Validation loss: 2.499806244838031

Epoch: 5| Step: 4
Training loss: 1.2134314174534035
Validation loss: 2.5385499579209703

Epoch: 5| Step: 5
Training loss: 1.4183454197160565
Validation loss: 2.5364506431156935

Epoch: 5| Step: 6
Training loss: 0.9673650748037859
Validation loss: 2.4853276872816776

Epoch: 5| Step: 7
Training loss: 1.0961724838288858
Validation loss: 2.4819394586669206

Epoch: 5| Step: 8
Training loss: 1.223087417578739
Validation loss: 2.4179148539366957

Epoch: 5| Step: 9
Training loss: 1.035411357034518
Validation loss: 2.411979103630889

Epoch: 5| Step: 10
Training loss: 1.221389650698338
Validation loss: 2.3668342412572483

Epoch: 394| Step: 0
Training loss: 1.405251805693697
Validation loss: 2.40786937339736

Epoch: 5| Step: 1
Training loss: 1.2412400381066897
Validation loss: 2.354372560204034

Epoch: 5| Step: 2
Training loss: 1.6224754971151378
Validation loss: 2.3850709580733285

Epoch: 5| Step: 3
Training loss: 1.1475524606119614
Validation loss: 2.4433707444062276

Epoch: 5| Step: 4
Training loss: 1.0690598780363747
Validation loss: 2.485742760140103

Epoch: 5| Step: 5
Training loss: 1.1441761286141243
Validation loss: 2.484511247024143

Epoch: 5| Step: 6
Training loss: 1.0274351826292472
Validation loss: 2.535803436137778

Epoch: 5| Step: 7
Training loss: 0.8970686394468022
Validation loss: 2.5367739315309477

Epoch: 5| Step: 8
Training loss: 1.154869595882168
Validation loss: 2.523402922775119

Epoch: 5| Step: 9
Training loss: 1.3891405905366416
Validation loss: 2.497608352377332

Epoch: 5| Step: 10
Training loss: 0.8990595115635821
Validation loss: 2.4456361123183235

Epoch: 395| Step: 0
Training loss: 1.1781801610524525
Validation loss: 2.4074912085521865

Epoch: 5| Step: 1
Training loss: 1.3082147305584049
Validation loss: 2.4054327862083142

Epoch: 5| Step: 2
Training loss: 1.3547246028126685
Validation loss: 2.4033441735693724

Epoch: 5| Step: 3
Training loss: 0.9156643452181538
Validation loss: 2.431734460821575

Epoch: 5| Step: 4
Training loss: 1.3959507916502807
Validation loss: 2.494092070225699

Epoch: 5| Step: 5
Training loss: 1.0946199499616869
Validation loss: 2.469228270083752

Epoch: 5| Step: 6
Training loss: 0.8759480177227127
Validation loss: 2.547245102673451

Epoch: 5| Step: 7
Training loss: 1.0224577312546732
Validation loss: 2.5514441414023827

Epoch: 5| Step: 8
Training loss: 1.2592964659027017
Validation loss: 2.559146960383199

Epoch: 5| Step: 9
Training loss: 0.7321868112376055
Validation loss: 2.486275628303239

Epoch: 5| Step: 10
Training loss: 1.7445949462523551
Validation loss: 2.4677575160695606

Epoch: 396| Step: 0
Training loss: 1.2215688336496795
Validation loss: 2.4099127554944233

Epoch: 5| Step: 1
Training loss: 1.2192264994768907
Validation loss: 2.403412647090898

Epoch: 5| Step: 2
Training loss: 1.0135751431860909
Validation loss: 2.3650829916088547

Epoch: 5| Step: 3
Training loss: 0.874271839155963
Validation loss: 2.4099143038399964

Epoch: 5| Step: 4
Training loss: 1.2719901817710593
Validation loss: 2.392123267655022

Epoch: 5| Step: 5
Training loss: 0.9872364356412477
Validation loss: 2.4405868469098952

Epoch: 5| Step: 6
Training loss: 1.0113736304119578
Validation loss: 2.4217421183947416

Epoch: 5| Step: 7
Training loss: 1.1738352846761944
Validation loss: 2.4702678275719836

Epoch: 5| Step: 8
Training loss: 1.0178813811932161
Validation loss: 2.5184529299013483

Epoch: 5| Step: 9
Training loss: 1.257839415836821
Validation loss: 2.526091141126916

Epoch: 5| Step: 10
Training loss: 1.696129035319104
Validation loss: 2.531549131461875

Epoch: 397| Step: 0
Training loss: 0.8743269238946648
Validation loss: 2.5073442256711718

Epoch: 5| Step: 1
Training loss: 0.8599573416443033
Validation loss: 2.497550724392322

Epoch: 5| Step: 2
Training loss: 0.8752096469950713
Validation loss: 2.43688672262202

Epoch: 5| Step: 3
Training loss: 1.510703680019905
Validation loss: 2.4068026910076656

Epoch: 5| Step: 4
Training loss: 1.1758459840107967
Validation loss: 2.4300685942837394

Epoch: 5| Step: 5
Training loss: 1.0865776864483454
Validation loss: 2.379551814719552

Epoch: 5| Step: 6
Training loss: 1.0182782654823161
Validation loss: 2.3809039862866643

Epoch: 5| Step: 7
Training loss: 1.0664709721302132
Validation loss: 2.375118956422973

Epoch: 5| Step: 8
Training loss: 1.0602932621486436
Validation loss: 2.405849534798229

Epoch: 5| Step: 9
Training loss: 1.260610985817505
Validation loss: 2.4157747320730905

Epoch: 5| Step: 10
Training loss: 1.663077909368468
Validation loss: 2.4668648478318747

Epoch: 398| Step: 0
Training loss: 1.1853834162084165
Validation loss: 2.508615069854541

Epoch: 5| Step: 1
Training loss: 1.3901464946310638
Validation loss: 2.456685738571808

Epoch: 5| Step: 2
Training loss: 1.0165538941566437
Validation loss: 2.4412928957639846

Epoch: 5| Step: 3
Training loss: 1.2080876440438948
Validation loss: 2.444987330773487

Epoch: 5| Step: 4
Training loss: 0.8813260147100572
Validation loss: 2.4488603684588353

Epoch: 5| Step: 5
Training loss: 1.0874711328818707
Validation loss: 2.429518143327539

Epoch: 5| Step: 6
Training loss: 1.0738737904929587
Validation loss: 2.382677853049864

Epoch: 5| Step: 7
Training loss: 1.0593267064072314
Validation loss: 2.378570217154467

Epoch: 5| Step: 8
Training loss: 1.4968072768403002
Validation loss: 2.3631682799201843

Epoch: 5| Step: 9
Training loss: 1.0021497150621912
Validation loss: 2.375262312335967

Epoch: 5| Step: 10
Training loss: 0.941861181227395
Validation loss: 2.4009440401787976

Epoch: 399| Step: 0
Training loss: 1.0525282620873777
Validation loss: 2.3759325357694765

Epoch: 5| Step: 1
Training loss: 1.0459448824560142
Validation loss: 2.384571045026907

Epoch: 5| Step: 2
Training loss: 1.5125732372617349
Validation loss: 2.382678097290349

Epoch: 5| Step: 3
Training loss: 1.159734784259387
Validation loss: 2.412996245602863

Epoch: 5| Step: 4
Training loss: 1.1963966788329692
Validation loss: 2.436603833653722

Epoch: 5| Step: 5
Training loss: 0.993589177103883
Validation loss: 2.445827886522913

Epoch: 5| Step: 6
Training loss: 1.3455073819136931
Validation loss: 2.458712806286258

Epoch: 5| Step: 7
Training loss: 0.961564332540636
Validation loss: 2.432064789852974

Epoch: 5| Step: 8
Training loss: 0.6545614134794885
Validation loss: 2.4188100648746875

Epoch: 5| Step: 9
Training loss: 0.9137021520065945
Validation loss: 2.422122188236485

Epoch: 5| Step: 10
Training loss: 1.3824408511292745
Validation loss: 2.3490405415630744

Epoch: 400| Step: 0
Training loss: 1.098222254016426
Validation loss: 2.338583345222455

Epoch: 5| Step: 1
Training loss: 0.8922113044622909
Validation loss: 2.338490463636506

Epoch: 5| Step: 2
Training loss: 1.0521803833165941
Validation loss: 2.380521238393518

Epoch: 5| Step: 3
Training loss: 1.1332090012754021
Validation loss: 2.365656141847556

Epoch: 5| Step: 4
Training loss: 1.187566353801246
Validation loss: 2.4132979795560274

Epoch: 5| Step: 5
Training loss: 1.133238771411162
Validation loss: 2.447696363964588

Epoch: 5| Step: 6
Training loss: 1.184885308634648
Validation loss: 2.4563198856081963

Epoch: 5| Step: 7
Training loss: 1.6131042678961005
Validation loss: 2.4416327284905903

Epoch: 5| Step: 8
Training loss: 0.978520924445324
Validation loss: 2.475429501539787

Epoch: 5| Step: 9
Training loss: 1.115625049152961
Validation loss: 2.425574130831511

Epoch: 5| Step: 10
Training loss: 0.8442681099347465
Validation loss: 2.3794640381975523

Epoch: 401| Step: 0
Training loss: 1.3982598389024132
Validation loss: 2.4014814196255574

Epoch: 5| Step: 1
Training loss: 1.5421557638657692
Validation loss: 2.4009351825295706

Epoch: 5| Step: 2
Training loss: 0.8831546761722903
Validation loss: 2.3906578020428095

Epoch: 5| Step: 3
Training loss: 1.2623095944790417
Validation loss: 2.365588323483003

Epoch: 5| Step: 4
Training loss: 1.0212865459201759
Validation loss: 2.3775035193184024

Epoch: 5| Step: 5
Training loss: 1.070906982165152
Validation loss: 2.3963384266188075

Epoch: 5| Step: 6
Training loss: 1.0378005316370706
Validation loss: 2.413247236518992

Epoch: 5| Step: 7
Training loss: 1.0290539796941605
Validation loss: 2.4199288860317707

Epoch: 5| Step: 8
Training loss: 0.9807149874242428
Validation loss: 2.4209967209904573

Epoch: 5| Step: 9
Training loss: 0.8935352761083154
Validation loss: 2.4488241736771705

Epoch: 5| Step: 10
Training loss: 0.9363812765314163
Validation loss: 2.4229079040239663

Epoch: 402| Step: 0
Training loss: 1.1270192356651256
Validation loss: 2.45590016410176

Epoch: 5| Step: 1
Training loss: 0.8360294398435535
Validation loss: 2.445101698519319

Epoch: 5| Step: 2
Training loss: 1.6939717981587394
Validation loss: 2.422943738955549

Epoch: 5| Step: 3
Training loss: 1.2829893447956817
Validation loss: 2.4023276851986304

Epoch: 5| Step: 4
Training loss: 1.0055922070094296
Validation loss: 2.384414583454796

Epoch: 5| Step: 5
Training loss: 0.8162758828071363
Validation loss: 2.40266647885652

Epoch: 5| Step: 6
Training loss: 0.9485369144730919
Validation loss: 2.4081189542127674

Epoch: 5| Step: 7
Training loss: 0.9739828599639734
Validation loss: 2.4407855498772237

Epoch: 5| Step: 8
Training loss: 0.8914810216170512
Validation loss: 2.406154036689239

Epoch: 5| Step: 9
Training loss: 1.1849320402656929
Validation loss: 2.432061003521142

Epoch: 5| Step: 10
Training loss: 1.1346971290913124
Validation loss: 2.409842007114532

Epoch: 403| Step: 0
Training loss: 1.1520080594701443
Validation loss: 2.4366058947889018

Epoch: 5| Step: 1
Training loss: 1.3023222538776438
Validation loss: 2.4459756843487144

Epoch: 5| Step: 2
Training loss: 0.8999866564079388
Validation loss: 2.454258847122413

Epoch: 5| Step: 3
Training loss: 1.265429352131602
Validation loss: 2.461797522483596

Epoch: 5| Step: 4
Training loss: 0.8567459813990209
Validation loss: 2.4396514421816833

Epoch: 5| Step: 5
Training loss: 0.7783470388535894
Validation loss: 2.4200358923231184

Epoch: 5| Step: 6
Training loss: 1.0703123886219719
Validation loss: 2.399570470190417

Epoch: 5| Step: 7
Training loss: 1.6795453388468886
Validation loss: 2.3537500538992435

Epoch: 5| Step: 8
Training loss: 1.158463395773174
Validation loss: 2.378096088221119

Epoch: 5| Step: 9
Training loss: 0.7341493706356313
Validation loss: 2.379830542320986

Epoch: 5| Step: 10
Training loss: 0.9268640551753655
Validation loss: 2.405563893790363

Epoch: 404| Step: 0
Training loss: 0.6010007836658872
Validation loss: 2.440539624833009

Epoch: 5| Step: 1
Training loss: 1.0226368575155322
Validation loss: 2.4383807435620177

Epoch: 5| Step: 2
Training loss: 0.7979610372678155
Validation loss: 2.4209687473524335

Epoch: 5| Step: 3
Training loss: 1.2427083968583268
Validation loss: 2.4514748560950395

Epoch: 5| Step: 4
Training loss: 1.694272051659408
Validation loss: 2.45069409073824

Epoch: 5| Step: 5
Training loss: 0.9414545260512294
Validation loss: 2.41936791809539

Epoch: 5| Step: 6
Training loss: 1.0647112892030328
Validation loss: 2.462059018323165

Epoch: 5| Step: 7
Training loss: 1.015046644595383
Validation loss: 2.4295615445926964

Epoch: 5| Step: 8
Training loss: 1.0402949202047096
Validation loss: 2.430423805037296

Epoch: 5| Step: 9
Training loss: 1.1971230351978728
Validation loss: 2.375595691631331

Epoch: 5| Step: 10
Training loss: 1.1427506275863777
Validation loss: 2.3776031232843544

Epoch: 405| Step: 0
Training loss: 1.2249735848829104
Validation loss: 2.3602797130452218

Epoch: 5| Step: 1
Training loss: 1.2662928196858687
Validation loss: 2.367957469545641

Epoch: 5| Step: 2
Training loss: 1.0694707080098724
Validation loss: 2.4219154770002858

Epoch: 5| Step: 3
Training loss: 0.5951327986339456
Validation loss: 2.4200300945487756

Epoch: 5| Step: 4
Training loss: 1.1922400886666003
Validation loss: 2.457201583693886

Epoch: 5| Step: 5
Training loss: 0.9921313292455389
Validation loss: 2.502442726260962

Epoch: 5| Step: 6
Training loss: 0.9698575057241421
Validation loss: 2.495883981428873

Epoch: 5| Step: 7
Training loss: 1.6795723099355884
Validation loss: 2.4987395534132752

Epoch: 5| Step: 8
Training loss: 0.7939808217045801
Validation loss: 2.462974367684931

Epoch: 5| Step: 9
Training loss: 0.9551156627556583
Validation loss: 2.412054010952948

Epoch: 5| Step: 10
Training loss: 0.6722424633373968
Validation loss: 2.360862007991053

Epoch: 406| Step: 0
Training loss: 0.7393933352134168
Validation loss: 2.330472201349742

Epoch: 5| Step: 1
Training loss: 1.2381884422781972
Validation loss: 2.3519012460110753

Epoch: 5| Step: 2
Training loss: 1.1405281652863564
Validation loss: 2.3609804264057157

Epoch: 5| Step: 3
Training loss: 1.262534902109078
Validation loss: 2.3907487432282104

Epoch: 5| Step: 4
Training loss: 1.553496244643933
Validation loss: 2.3803264186254305

Epoch: 5| Step: 5
Training loss: 0.9699686445497128
Validation loss: 2.3841375122233006

Epoch: 5| Step: 6
Training loss: 0.9737401537709572
Validation loss: 2.4170245558700025

Epoch: 5| Step: 7
Training loss: 1.0280494731769072
Validation loss: 2.419422673980076

Epoch: 5| Step: 8
Training loss: 1.0174952965705004
Validation loss: 2.4278621833153045

Epoch: 5| Step: 9
Training loss: 1.0259983550610656
Validation loss: 2.4580731404553458

Epoch: 5| Step: 10
Training loss: 0.5719401244306624
Validation loss: 2.475104506328759

Epoch: 407| Step: 0
Training loss: 0.8302509801066839
Validation loss: 2.4480927064774147

Epoch: 5| Step: 1
Training loss: 1.10081131665961
Validation loss: 2.482133400605451

Epoch: 5| Step: 2
Training loss: 1.1651132436895255
Validation loss: 2.4506088529943097

Epoch: 5| Step: 3
Training loss: 0.9695797719809439
Validation loss: 2.4461462015060484

Epoch: 5| Step: 4
Training loss: 0.9154723616302707
Validation loss: 2.440913588564758

Epoch: 5| Step: 5
Training loss: 0.9950521071606316
Validation loss: 2.4259395657680236

Epoch: 5| Step: 6
Training loss: 1.0581313809125266
Validation loss: 2.419163478817158

Epoch: 5| Step: 7
Training loss: 0.955048917546115
Validation loss: 2.4125188696389666

Epoch: 5| Step: 8
Training loss: 1.4887131592414495
Validation loss: 2.4147038818217825

Epoch: 5| Step: 9
Training loss: 0.9415463545130629
Validation loss: 2.384485672884865

Epoch: 5| Step: 10
Training loss: 1.154022494009273
Validation loss: 2.40313820843766

Epoch: 408| Step: 0
Training loss: 1.0721229777966954
Validation loss: 2.353822782292151

Epoch: 5| Step: 1
Training loss: 0.8786252738267312
Validation loss: 2.373325182665805

Epoch: 5| Step: 2
Training loss: 1.1443944334987446
Validation loss: 2.383603572806061

Epoch: 5| Step: 3
Training loss: 1.1134267611525068
Validation loss: 2.424460613834056

Epoch: 5| Step: 4
Training loss: 0.7347652534674557
Validation loss: 2.436240925687139

Epoch: 5| Step: 5
Training loss: 1.0794444096198157
Validation loss: 2.419324764181002

Epoch: 5| Step: 6
Training loss: 1.3520320010714935
Validation loss: 2.4449943097739513

Epoch: 5| Step: 7
Training loss: 0.6783387844778942
Validation loss: 2.4438278396916115

Epoch: 5| Step: 8
Training loss: 1.2741732198040645
Validation loss: 2.4335002123705944

Epoch: 5| Step: 9
Training loss: 1.2137859682515049
Validation loss: 2.4541975612824336

Epoch: 5| Step: 10
Training loss: 0.8922580003024342
Validation loss: 2.43859870597475

Epoch: 409| Step: 0
Training loss: 0.8119352652227035
Validation loss: 2.419974257022839

Epoch: 5| Step: 1
Training loss: 1.0264511001504462
Validation loss: 2.4089095460777834

Epoch: 5| Step: 2
Training loss: 0.7141972103805777
Validation loss: 2.4453771407627203

Epoch: 5| Step: 3
Training loss: 0.849778081871532
Validation loss: 2.4501536735706013

Epoch: 5| Step: 4
Training loss: 1.0507972460809059
Validation loss: 2.4391630235325534

Epoch: 5| Step: 5
Training loss: 1.144792546464873
Validation loss: 2.434365888307856

Epoch: 5| Step: 6
Training loss: 0.9915421557330601
Validation loss: 2.362975312426604

Epoch: 5| Step: 7
Training loss: 1.6819023965328703
Validation loss: 2.4091228216674128

Epoch: 5| Step: 8
Training loss: 1.0488181229155296
Validation loss: 2.364214972861493

Epoch: 5| Step: 9
Training loss: 1.094675980011014
Validation loss: 2.3960264448226427

Epoch: 5| Step: 10
Training loss: 0.7238261882099358
Validation loss: 2.360627107598203

Epoch: 410| Step: 0
Training loss: 0.9183382629797615
Validation loss: 2.3809976025577675

Epoch: 5| Step: 1
Training loss: 0.9865629917417841
Validation loss: 2.343792155443862

Epoch: 5| Step: 2
Training loss: 1.1155880235373126
Validation loss: 2.357931006917606

Epoch: 5| Step: 3
Training loss: 1.0295532023210878
Validation loss: 2.413510355103515

Epoch: 5| Step: 4
Training loss: 1.1528824403785987
Validation loss: 2.417986998877744

Epoch: 5| Step: 5
Training loss: 1.204674255852437
Validation loss: 2.5037850767253333

Epoch: 5| Step: 6
Training loss: 0.9360003875340369
Validation loss: 2.5245739956678643

Epoch: 5| Step: 7
Training loss: 1.5753546845233173
Validation loss: 2.5390080564607977

Epoch: 5| Step: 8
Training loss: 0.8033523223012402
Validation loss: 2.4809097627922694

Epoch: 5| Step: 9
Training loss: 0.9989610878141029
Validation loss: 2.4532669597950356

Epoch: 5| Step: 10
Training loss: 0.7794942581963616
Validation loss: 2.363470594047927

Epoch: 411| Step: 0
Training loss: 1.2642425710630691
Validation loss: 2.3229057178950208

Epoch: 5| Step: 1
Training loss: 1.0817803047119405
Validation loss: 2.311066911523932

Epoch: 5| Step: 2
Training loss: 1.0493807056265074
Validation loss: 2.2963113021226134

Epoch: 5| Step: 3
Training loss: 0.7867145163186341
Validation loss: 2.3405765392122913

Epoch: 5| Step: 4
Training loss: 1.22532105034022
Validation loss: 2.3382567908142122

Epoch: 5| Step: 5
Training loss: 1.1426430186566217
Validation loss: 2.430217067824352

Epoch: 5| Step: 6
Training loss: 0.7926774264980385
Validation loss: 2.4682192716773286

Epoch: 5| Step: 7
Training loss: 0.973564183792252
Validation loss: 2.4822696229790226

Epoch: 5| Step: 8
Training loss: 0.772849813347978
Validation loss: 2.451259704645265

Epoch: 5| Step: 9
Training loss: 0.7266377235767271
Validation loss: 2.4486611418711552

Epoch: 5| Step: 10
Training loss: 1.6040801565780363
Validation loss: 2.4106792632965925

Epoch: 412| Step: 0
Training loss: 1.4264039234548151
Validation loss: 2.3950807849221585

Epoch: 5| Step: 1
Training loss: 1.0878523814740602
Validation loss: 2.397771321337289

Epoch: 5| Step: 2
Training loss: 0.9876325083810389
Validation loss: 2.366954257926479

Epoch: 5| Step: 3
Training loss: 0.7418420891343263
Validation loss: 2.4191438463286774

Epoch: 5| Step: 4
Training loss: 1.077200562364989
Validation loss: 2.4296165128583938

Epoch: 5| Step: 5
Training loss: 1.1727689258135559
Validation loss: 2.4180914692493336

Epoch: 5| Step: 6
Training loss: 1.145911676445143
Validation loss: 2.4323360364146294

Epoch: 5| Step: 7
Training loss: 0.8062559600728069
Validation loss: 2.4221775835794244

Epoch: 5| Step: 8
Training loss: 0.8596302000340302
Validation loss: 2.3933946229445917

Epoch: 5| Step: 9
Training loss: 0.6549268963109469
Validation loss: 2.4013515528067617

Epoch: 5| Step: 10
Training loss: 1.043940744845012
Validation loss: 2.3741751621792484

Epoch: 413| Step: 0
Training loss: 0.7762340887407766
Validation loss: 2.407840558917537

Epoch: 5| Step: 1
Training loss: 0.9375332508548351
Validation loss: 2.4453386634753986

Epoch: 5| Step: 2
Training loss: 1.0857913790307352
Validation loss: 2.4302124652829447

Epoch: 5| Step: 3
Training loss: 1.3879843940269785
Validation loss: 2.474371326389112

Epoch: 5| Step: 4
Training loss: 0.9418889308068823
Validation loss: 2.463348510831751

Epoch: 5| Step: 5
Training loss: 0.9831103724066266
Validation loss: 2.409748535857375

Epoch: 5| Step: 6
Training loss: 0.7873885272617733
Validation loss: 2.412312290889379

Epoch: 5| Step: 7
Training loss: 0.961866627409488
Validation loss: 2.4147925049197423

Epoch: 5| Step: 8
Training loss: 0.8217013998860206
Validation loss: 2.4176200238708287

Epoch: 5| Step: 9
Training loss: 1.1550376309626538
Validation loss: 2.4224504467953993

Epoch: 5| Step: 10
Training loss: 1.184179280800225
Validation loss: 2.435997134954096

Epoch: 414| Step: 0
Training loss: 1.537825653819909
Validation loss: 2.456807370146682

Epoch: 5| Step: 1
Training loss: 0.9467782251236873
Validation loss: 2.4475922114020294

Epoch: 5| Step: 2
Training loss: 1.0041271515876269
Validation loss: 2.444541674680188

Epoch: 5| Step: 3
Training loss: 0.9984613144113484
Validation loss: 2.4461422645689224

Epoch: 5| Step: 4
Training loss: 1.094381368151251
Validation loss: 2.4776969421307906

Epoch: 5| Step: 5
Training loss: 0.8215735778409975
Validation loss: 2.44539950956185

Epoch: 5| Step: 6
Training loss: 0.7027259117918802
Validation loss: 2.4382541837030907

Epoch: 5| Step: 7
Training loss: 1.2524291753636463
Validation loss: 2.4415287372667405

Epoch: 5| Step: 8
Training loss: 0.9151936240736072
Validation loss: 2.4006223740684955

Epoch: 5| Step: 9
Training loss: 0.7718747467164153
Validation loss: 2.3776074599850983

Epoch: 5| Step: 10
Training loss: 0.6355714114469678
Validation loss: 2.4032495737948008

Epoch: 415| Step: 0
Training loss: 1.278571096231489
Validation loss: 2.3870661599015053

Epoch: 5| Step: 1
Training loss: 0.7818141426290568
Validation loss: 2.3860522933900974

Epoch: 5| Step: 2
Training loss: 1.0953112766841309
Validation loss: 2.4119410055144774

Epoch: 5| Step: 3
Training loss: 0.6829165128490872
Validation loss: 2.4166383287241473

Epoch: 5| Step: 4
Training loss: 1.0909972290717163
Validation loss: 2.483881328557426

Epoch: 5| Step: 5
Training loss: 1.4115391763242768
Validation loss: 2.51487803389782

Epoch: 5| Step: 6
Training loss: 0.946173567362108
Validation loss: 2.489397774614057

Epoch: 5| Step: 7
Training loss: 0.9081063495881543
Validation loss: 2.506225586289125

Epoch: 5| Step: 8
Training loss: 0.838472959811479
Validation loss: 2.46001788391541

Epoch: 5| Step: 9
Training loss: 0.7402988697631321
Validation loss: 2.4450934993906714

Epoch: 5| Step: 10
Training loss: 0.9806980001825757
Validation loss: 2.3970898886057195

Epoch: 416| Step: 0
Training loss: 0.8184574405299098
Validation loss: 2.388190576117763

Epoch: 5| Step: 1
Training loss: 0.6308236126757587
Validation loss: 2.369987528560334

Epoch: 5| Step: 2
Training loss: 1.5181240440167763
Validation loss: 2.3808557118218037

Epoch: 5| Step: 3
Training loss: 1.333817299786785
Validation loss: 2.3860951288256502

Epoch: 5| Step: 4
Training loss: 1.0976896993624499
Validation loss: 2.42097295554349

Epoch: 5| Step: 5
Training loss: 0.7950642151359397
Validation loss: 2.464702467396399

Epoch: 5| Step: 6
Training loss: 0.9829795574127116
Validation loss: 2.4980470622920814

Epoch: 5| Step: 7
Training loss: 0.7763091443515011
Validation loss: 2.533502272252411

Epoch: 5| Step: 8
Training loss: 1.235826242794824
Validation loss: 2.5196565620259874

Epoch: 5| Step: 9
Training loss: 0.6242324407458317
Validation loss: 2.497975405369227

Epoch: 5| Step: 10
Training loss: 0.6694756848703881
Validation loss: 2.4795728664198746

Epoch: 417| Step: 0
Training loss: 0.9314488627453505
Validation loss: 2.4119819978471995

Epoch: 5| Step: 1
Training loss: 1.0805059485882955
Validation loss: 2.407954100141558

Epoch: 5| Step: 2
Training loss: 1.0351826214580095
Validation loss: 2.4163934710930763

Epoch: 5| Step: 3
Training loss: 1.0021228906724182
Validation loss: 2.4290170843613565

Epoch: 5| Step: 4
Training loss: 0.8523779997688224
Validation loss: 2.500046731142928

Epoch: 5| Step: 5
Training loss: 0.5513918312719178
Validation loss: 2.500105162428866

Epoch: 5| Step: 6
Training loss: 1.5867786901394638
Validation loss: 2.518954164859557

Epoch: 5| Step: 7
Training loss: 0.9802866002833398
Validation loss: 2.515123272818577

Epoch: 5| Step: 8
Training loss: 1.0438368252943446
Validation loss: 2.48751717067495

Epoch: 5| Step: 9
Training loss: 0.8424028662654554
Validation loss: 2.4327128719909985

Epoch: 5| Step: 10
Training loss: 0.6432446903924379
Validation loss: 2.4089275060041557

Epoch: 418| Step: 0
Training loss: 0.7234949966552925
Validation loss: 2.4058525802423407

Epoch: 5| Step: 1
Training loss: 1.0425485057203743
Validation loss: 2.411901314022057

Epoch: 5| Step: 2
Training loss: 0.9261197787032248
Validation loss: 2.4375750559317395

Epoch: 5| Step: 3
Training loss: 0.7434137754435043
Validation loss: 2.4368057966261163

Epoch: 5| Step: 4
Training loss: 0.9315076369209537
Validation loss: 2.4529364070346302

Epoch: 5| Step: 5
Training loss: 0.9545933091669035
Validation loss: 2.4693828460639056

Epoch: 5| Step: 6
Training loss: 1.2640041757526714
Validation loss: 2.4570000482819356

Epoch: 5| Step: 7
Training loss: 0.8437322685356551
Validation loss: 2.4625586427400323

Epoch: 5| Step: 8
Training loss: 0.8963984030595723
Validation loss: 2.4599687952749854

Epoch: 5| Step: 9
Training loss: 1.445855281051287
Validation loss: 2.4592506097559736

Epoch: 5| Step: 10
Training loss: 0.7921272661231772
Validation loss: 2.4509818253401368

Epoch: 419| Step: 0
Training loss: 0.9198084475814282
Validation loss: 2.4549305535429835

Epoch: 5| Step: 1
Training loss: 1.1138099352018977
Validation loss: 2.445368479442069

Epoch: 5| Step: 2
Training loss: 1.0046524658739382
Validation loss: 2.4247211310753087

Epoch: 5| Step: 3
Training loss: 1.5171295249225907
Validation loss: 2.4233131640042442

Epoch: 5| Step: 4
Training loss: 0.8459783727257754
Validation loss: 2.451530054574245

Epoch: 5| Step: 5
Training loss: 0.8558888209616938
Validation loss: 2.412977241834953

Epoch: 5| Step: 6
Training loss: 0.8226851890234167
Validation loss: 2.45431940730315

Epoch: 5| Step: 7
Training loss: 1.014437524134288
Validation loss: 2.4757187208396694

Epoch: 5| Step: 8
Training loss: 0.6902427798041734
Validation loss: 2.503068117497538

Epoch: 5| Step: 9
Training loss: 0.6862097249954376
Validation loss: 2.487559475504375

Epoch: 5| Step: 10
Training loss: 1.0380751428913122
Validation loss: 2.448163634343701

Epoch: 420| Step: 0
Training loss: 0.9126166948401159
Validation loss: 2.409688997131728

Epoch: 5| Step: 1
Training loss: 0.8163150207069381
Validation loss: 2.443038447594236

Epoch: 5| Step: 2
Training loss: 0.9159287531476399
Validation loss: 2.4200803799536095

Epoch: 5| Step: 3
Training loss: 1.2217867748673095
Validation loss: 2.4100107774768813

Epoch: 5| Step: 4
Training loss: 1.5639260460230207
Validation loss: 2.418916991890296

Epoch: 5| Step: 5
Training loss: 0.602753933226427
Validation loss: 2.4442617090394823

Epoch: 5| Step: 6
Training loss: 1.0352803857614294
Validation loss: 2.4570496991440764

Epoch: 5| Step: 7
Training loss: 0.6492478466284658
Validation loss: 2.466099560501408

Epoch: 5| Step: 8
Training loss: 0.857133682235932
Validation loss: 2.5249339405029505

Epoch: 5| Step: 9
Training loss: 0.7803110583883649
Validation loss: 2.505471960896845

Epoch: 5| Step: 10
Training loss: 0.954054988477908
Validation loss: 2.500199136698937

Epoch: 421| Step: 0
Training loss: 0.9242981245406308
Validation loss: 2.4478224670535926

Epoch: 5| Step: 1
Training loss: 0.9684145869756937
Validation loss: 2.445759982056816

Epoch: 5| Step: 2
Training loss: 0.7685516628802063
Validation loss: 2.396494207057739

Epoch: 5| Step: 3
Training loss: 0.7350581218159978
Validation loss: 2.3954332064819863

Epoch: 5| Step: 4
Training loss: 0.7256134561939666
Validation loss: 2.3936431414961485

Epoch: 5| Step: 5
Training loss: 0.909333344124862
Validation loss: 2.4055119887460195

Epoch: 5| Step: 6
Training loss: 0.8527472068251039
Validation loss: 2.4444494841294655

Epoch: 5| Step: 7
Training loss: 1.1146389362096696
Validation loss: 2.474005157770228

Epoch: 5| Step: 8
Training loss: 0.7151664880841092
Validation loss: 2.4804761790076393

Epoch: 5| Step: 9
Training loss: 1.6639620611835926
Validation loss: 2.4840038928142323

Epoch: 5| Step: 10
Training loss: 0.8252279963594875
Validation loss: 2.474440546281516

Epoch: 422| Step: 0
Training loss: 0.7711364734258023
Validation loss: 2.472747711359965

Epoch: 5| Step: 1
Training loss: 0.8747698617464467
Validation loss: 2.4533136354186085

Epoch: 5| Step: 2
Training loss: 0.7296479861814932
Validation loss: 2.4057894573503473

Epoch: 5| Step: 3
Training loss: 1.3140542500675787
Validation loss: 2.415484187024541

Epoch: 5| Step: 4
Training loss: 1.0300009706177815
Validation loss: 2.413102680723115

Epoch: 5| Step: 5
Training loss: 0.7876195650311247
Validation loss: 2.4315017000923262

Epoch: 5| Step: 6
Training loss: 0.761217979734886
Validation loss: 2.4364532555948535

Epoch: 5| Step: 7
Training loss: 1.02096999804124
Validation loss: 2.4005998026870943

Epoch: 5| Step: 8
Training loss: 1.114380090073938
Validation loss: 2.4737281054033096

Epoch: 5| Step: 9
Training loss: 0.6958983878222118
Validation loss: 2.460837589494413

Epoch: 5| Step: 10
Training loss: 1.141145456796593
Validation loss: 2.3921940953183

Epoch: 423| Step: 0
Training loss: 1.032491052787383
Validation loss: 2.4442716085003497

Epoch: 5| Step: 1
Training loss: 0.7692975304132906
Validation loss: 2.433657574613752

Epoch: 5| Step: 2
Training loss: 0.9037579110565687
Validation loss: 2.404530120846551

Epoch: 5| Step: 3
Training loss: 0.9720286907094288
Validation loss: 2.4621519676597803

Epoch: 5| Step: 4
Training loss: 0.9162018999326101
Validation loss: 2.4413863080922784

Epoch: 5| Step: 5
Training loss: 0.7622105502451197
Validation loss: 2.4706247972534117

Epoch: 5| Step: 6
Training loss: 0.6487872547779282
Validation loss: 2.440205999067471

Epoch: 5| Step: 7
Training loss: 0.9302495331449088
Validation loss: 2.460943474333439

Epoch: 5| Step: 8
Training loss: 0.7404268764320732
Validation loss: 2.4546991547323995

Epoch: 5| Step: 9
Training loss: 0.9571042402810239
Validation loss: 2.450408909626631

Epoch: 5| Step: 10
Training loss: 1.47657880824534
Validation loss: 2.4517708024150844

Epoch: 424| Step: 0
Training loss: 0.8157745545760409
Validation loss: 2.4494205938657627

Epoch: 5| Step: 1
Training loss: 0.9631898426702931
Validation loss: 2.4462808369597373

Epoch: 5| Step: 2
Training loss: 0.943097854284265
Validation loss: 2.459827534912573

Epoch: 5| Step: 3
Training loss: 0.8569438183818435
Validation loss: 2.480139079337296

Epoch: 5| Step: 4
Training loss: 0.7235709510132421
Validation loss: 2.5008858249609816

Epoch: 5| Step: 5
Training loss: 1.4087678197700042
Validation loss: 2.483680964039873

Epoch: 5| Step: 6
Training loss: 0.5212793983201102
Validation loss: 2.4948891080271167

Epoch: 5| Step: 7
Training loss: 0.8468562627317199
Validation loss: 2.448039696681811

Epoch: 5| Step: 8
Training loss: 0.9654325163759478
Validation loss: 2.430567014777559

Epoch: 5| Step: 9
Training loss: 1.1325694908733435
Validation loss: 2.407090959434324

Epoch: 5| Step: 10
Training loss: 0.8662506060027058
Validation loss: 2.384285805238021

Epoch: 425| Step: 0
Training loss: 1.0629961314018816
Validation loss: 2.410624169495253

Epoch: 5| Step: 1
Training loss: 0.9469621309787324
Validation loss: 2.359547467017442

Epoch: 5| Step: 2
Training loss: 0.817680897019576
Validation loss: 2.381959715422264

Epoch: 5| Step: 3
Training loss: 1.1463567347528838
Validation loss: 2.4458986610050713

Epoch: 5| Step: 4
Training loss: 0.7748800754051676
Validation loss: 2.450668913373183

Epoch: 5| Step: 5
Training loss: 0.7523499073636192
Validation loss: 2.4327802775774696

Epoch: 5| Step: 6
Training loss: 1.349120740307138
Validation loss: 2.504728119826263

Epoch: 5| Step: 7
Training loss: 0.7943646026459122
Validation loss: 2.5432249530884183

Epoch: 5| Step: 8
Training loss: 0.9496907446085016
Validation loss: 2.502694779761576

Epoch: 5| Step: 9
Training loss: 0.6028983901056311
Validation loss: 2.479467030632376

Epoch: 5| Step: 10
Training loss: 0.8192325931523947
Validation loss: 2.423737653379635

Epoch: 426| Step: 0
Training loss: 0.9247243457606962
Validation loss: 2.4214344440352678

Epoch: 5| Step: 1
Training loss: 0.7130261854068876
Validation loss: 2.3940859888865176

Epoch: 5| Step: 2
Training loss: 0.8232192718465976
Validation loss: 2.387005624202515

Epoch: 5| Step: 3
Training loss: 0.8953918914479752
Validation loss: 2.425025344346605

Epoch: 5| Step: 4
Training loss: 0.9807303638150443
Validation loss: 2.4757641484086017

Epoch: 5| Step: 5
Training loss: 0.6518007862714886
Validation loss: 2.492046129355687

Epoch: 5| Step: 6
Training loss: 0.8581523173541358
Validation loss: 2.5262391659645678

Epoch: 5| Step: 7
Training loss: 0.890898277786822
Validation loss: 2.5300448349188494

Epoch: 5| Step: 8
Training loss: 1.4248012571443884
Validation loss: 2.476368602634726

Epoch: 5| Step: 9
Training loss: 0.7045117161103492
Validation loss: 2.4712524410415444

Epoch: 5| Step: 10
Training loss: 1.1878216960242898
Validation loss: 2.420558888075552

Epoch: 427| Step: 0
Training loss: 0.8717967733203136
Validation loss: 2.3957125604336498

Epoch: 5| Step: 1
Training loss: 0.9006021048543055
Validation loss: 2.3934902230126585

Epoch: 5| Step: 2
Training loss: 0.47370803078424706
Validation loss: 2.380894673449461

Epoch: 5| Step: 3
Training loss: 1.0092719695709906
Validation loss: 2.365601406683355

Epoch: 5| Step: 4
Training loss: 1.3658511797235755
Validation loss: 2.4101655635845582

Epoch: 5| Step: 5
Training loss: 0.8318694051300765
Validation loss: 2.4355289776881768

Epoch: 5| Step: 6
Training loss: 1.1175003680712885
Validation loss: 2.451977207002889

Epoch: 5| Step: 7
Training loss: 0.9155239257748697
Validation loss: 2.475183229861824

Epoch: 5| Step: 8
Training loss: 0.4019314403264002
Validation loss: 2.4738511675090518

Epoch: 5| Step: 9
Training loss: 1.0827509830939852
Validation loss: 2.4572500265198323

Epoch: 5| Step: 10
Training loss: 0.6201197826901896
Validation loss: 2.481396959760807

Epoch: 428| Step: 0
Training loss: 0.6981512263877854
Validation loss: 2.4332644492729885

Epoch: 5| Step: 1
Training loss: 1.049880198047413
Validation loss: 2.4273335381003047

Epoch: 5| Step: 2
Training loss: 1.4403441115999178
Validation loss: 2.429493878758468

Epoch: 5| Step: 3
Training loss: 0.868040335627748
Validation loss: 2.3876746385413568

Epoch: 5| Step: 4
Training loss: 0.597458401512807
Validation loss: 2.4143513106748182

Epoch: 5| Step: 5
Training loss: 0.8326953870008535
Validation loss: 2.4391804774482955

Epoch: 5| Step: 6
Training loss: 0.8040422982481278
Validation loss: 2.4413067677564184

Epoch: 5| Step: 7
Training loss: 0.9592342012450008
Validation loss: 2.4372112817316918

Epoch: 5| Step: 8
Training loss: 0.8207282329860166
Validation loss: 2.4420773281740624

Epoch: 5| Step: 9
Training loss: 0.8147689975233817
Validation loss: 2.4633945161936346

Epoch: 5| Step: 10
Training loss: 0.7355299450855095
Validation loss: 2.4523209993722532

Epoch: 429| Step: 0
Training loss: 0.8046898702938391
Validation loss: 2.4569725210760787

Epoch: 5| Step: 1
Training loss: 0.3810209665086348
Validation loss: 2.4204293913414765

Epoch: 5| Step: 2
Training loss: 0.9648506689402729
Validation loss: 2.3943535510084413

Epoch: 5| Step: 3
Training loss: 1.4701150273063543
Validation loss: 2.3912161896957245

Epoch: 5| Step: 4
Training loss: 0.6866653317450847
Validation loss: 2.3872259969262073

Epoch: 5| Step: 5
Training loss: 1.020660359785684
Validation loss: 2.4191581992766493

Epoch: 5| Step: 6
Training loss: 0.9800520539569676
Validation loss: 2.4248092664737895

Epoch: 5| Step: 7
Training loss: 1.1249239683949732
Validation loss: 2.3966609607862344

Epoch: 5| Step: 8
Training loss: 0.43975434893831794
Validation loss: 2.418958170172048

Epoch: 5| Step: 9
Training loss: 0.6442707344451886
Validation loss: 2.4032258739321395

Epoch: 5| Step: 10
Training loss: 0.8138897088241642
Validation loss: 2.4098933721023186

Epoch: 430| Step: 0
Training loss: 0.8605508216355291
Validation loss: 2.4151825709591876

Epoch: 5| Step: 1
Training loss: 0.6824461322877452
Validation loss: 2.451727618636682

Epoch: 5| Step: 2
Training loss: 0.4869919807529722
Validation loss: 2.448378628559366

Epoch: 5| Step: 3
Training loss: 1.4897425728715359
Validation loss: 2.4571618016876458

Epoch: 5| Step: 4
Training loss: 0.90078005364662
Validation loss: 2.474517484643694

Epoch: 5| Step: 5
Training loss: 0.7765183787409223
Validation loss: 2.48011655870828

Epoch: 5| Step: 6
Training loss: 0.8510827629286403
Validation loss: 2.4709728758594838

Epoch: 5| Step: 7
Training loss: 1.156932320187163
Validation loss: 2.4683845787483794

Epoch: 5| Step: 8
Training loss: 0.6435415356323991
Validation loss: 2.392816174107861

Epoch: 5| Step: 9
Training loss: 0.6127761899315206
Validation loss: 2.423025639485732

Epoch: 5| Step: 10
Training loss: 0.9718535454641967
Validation loss: 2.381291825156466

Epoch: 431| Step: 0
Training loss: 0.6493851045734731
Validation loss: 2.4349949250921457

Epoch: 5| Step: 1
Training loss: 1.0034894857421253
Validation loss: 2.416271373815792

Epoch: 5| Step: 2
Training loss: 0.7112413113537674
Validation loss: 2.49214622115425

Epoch: 5| Step: 3
Training loss: 0.8078906185665486
Validation loss: 2.413062390552338

Epoch: 5| Step: 4
Training loss: 0.8409417360469144
Validation loss: 2.476763017038647

Epoch: 5| Step: 5
Training loss: 0.8215836621414189
Validation loss: 2.4532783616597458

Epoch: 5| Step: 6
Training loss: 1.2953981930280611
Validation loss: 2.444239037722845

Epoch: 5| Step: 7
Training loss: 0.868047648499822
Validation loss: 2.4750138695573627

Epoch: 5| Step: 8
Training loss: 0.7117208420087299
Validation loss: 2.499362839751054

Epoch: 5| Step: 9
Training loss: 0.9918326096108749
Validation loss: 2.4601025335700246

Epoch: 5| Step: 10
Training loss: 0.8638379817599358
Validation loss: 2.479131689227342

Epoch: 432| Step: 0
Training loss: 0.49411927429633845
Validation loss: 2.422580157196995

Epoch: 5| Step: 1
Training loss: 1.3609940106542509
Validation loss: 2.48163628018405

Epoch: 5| Step: 2
Training loss: 0.7817411404806979
Validation loss: 2.4625698652070223

Epoch: 5| Step: 3
Training loss: 0.9074085985083631
Validation loss: 2.418607160441707

Epoch: 5| Step: 4
Training loss: 0.8880304054497601
Validation loss: 2.465644206822208

Epoch: 5| Step: 5
Training loss: 0.4910729974870266
Validation loss: 2.4605852439131017

Epoch: 5| Step: 6
Training loss: 0.8257006660920735
Validation loss: 2.451736934284496

Epoch: 5| Step: 7
Training loss: 0.8095179634056783
Validation loss: 2.4536912017907593

Epoch: 5| Step: 8
Training loss: 0.6857208074780394
Validation loss: 2.4111830591169277

Epoch: 5| Step: 9
Training loss: 1.1536847603848719
Validation loss: 2.452788307457425

Epoch: 5| Step: 10
Training loss: 0.8817377553294582
Validation loss: 2.4657227478901853

Epoch: 433| Step: 0
Training loss: 1.333813948237832
Validation loss: 2.4714671279137734

Epoch: 5| Step: 1
Training loss: 0.9811052482892305
Validation loss: 2.4508290846216414

Epoch: 5| Step: 2
Training loss: 0.6548885573884052
Validation loss: 2.458593999357581

Epoch: 5| Step: 3
Training loss: 0.8836078605570746
Validation loss: 2.4744774935704417

Epoch: 5| Step: 4
Training loss: 0.8606465729092216
Validation loss: 2.469088302616967

Epoch: 5| Step: 5
Training loss: 0.7578546571312004
Validation loss: 2.4011809641626014

Epoch: 5| Step: 6
Training loss: 0.8535793813117211
Validation loss: 2.410534631671968

Epoch: 5| Step: 7
Training loss: 0.7176625691639603
Validation loss: 2.4101055830866165

Epoch: 5| Step: 8
Training loss: 0.7619298789058054
Validation loss: 2.4229160734785062

Epoch: 5| Step: 9
Training loss: 0.9169886449840885
Validation loss: 2.3895460398071426

Epoch: 5| Step: 10
Training loss: 0.7663535719255596
Validation loss: 2.4647892324373215

Epoch: 434| Step: 0
Training loss: 0.910071733340783
Validation loss: 2.503471740850349

Epoch: 5| Step: 1
Training loss: 0.8067495351056537
Validation loss: 2.5194207707398304

Epoch: 5| Step: 2
Training loss: 0.8996767867716843
Validation loss: 2.5296515392192926

Epoch: 5| Step: 3
Training loss: 1.261262793575311
Validation loss: 2.4902586623183116

Epoch: 5| Step: 4
Training loss: 0.7476194669630062
Validation loss: 2.4210397561553343

Epoch: 5| Step: 5
Training loss: 0.5977464495640783
Validation loss: 2.412816315770147

Epoch: 5| Step: 6
Training loss: 0.6951962491696997
Validation loss: 2.405596227304494

Epoch: 5| Step: 7
Training loss: 0.6139558374306496
Validation loss: 2.422847360746187

Epoch: 5| Step: 8
Training loss: 0.852050851204331
Validation loss: 2.3671897082157907

Epoch: 5| Step: 9
Training loss: 1.0915091311133558
Validation loss: 2.372270227533635

Epoch: 5| Step: 10
Training loss: 0.8978336792999426
Validation loss: 2.3848156940179086

Epoch: 435| Step: 0
Training loss: 0.7101522867325077
Validation loss: 2.3926176136299917

Epoch: 5| Step: 1
Training loss: 0.8720970363302825
Validation loss: 2.4075662405998854

Epoch: 5| Step: 2
Training loss: 1.3191184338258284
Validation loss: 2.426688104572798

Epoch: 5| Step: 3
Training loss: 0.7110497522290254
Validation loss: 2.420220903205998

Epoch: 5| Step: 4
Training loss: 0.9406041570743141
Validation loss: 2.441849152324246

Epoch: 5| Step: 5
Training loss: 0.7081962808150996
Validation loss: 2.4257859011084295

Epoch: 5| Step: 6
Training loss: 0.8222390576055241
Validation loss: 2.409898880443971

Epoch: 5| Step: 7
Training loss: 1.0860406840310382
Validation loss: 2.403822799903629

Epoch: 5| Step: 8
Training loss: 0.8278278321473218
Validation loss: 2.4212788218878813

Epoch: 5| Step: 9
Training loss: 0.4025222049239147
Validation loss: 2.4234255714509314

Epoch: 5| Step: 10
Training loss: 0.7237547901634123
Validation loss: 2.4095602525338746

Epoch: 436| Step: 0
Training loss: 0.5879221556056048
Validation loss: 2.3761460227589173

Epoch: 5| Step: 1
Training loss: 0.8422162987026278
Validation loss: 2.3962190621610397

Epoch: 5| Step: 2
Training loss: 0.6449296586914588
Validation loss: 2.4468287857102933

Epoch: 5| Step: 3
Training loss: 0.9743191395836234
Validation loss: 2.4130638131072675

Epoch: 5| Step: 4
Training loss: 0.6750719835611018
Validation loss: 2.3898885934389846

Epoch: 5| Step: 5
Training loss: 0.8321427104956839
Validation loss: 2.4320534213528457

Epoch: 5| Step: 6
Training loss: 0.9502922236077325
Validation loss: 2.417995435173291

Epoch: 5| Step: 7
Training loss: 0.7022657866694741
Validation loss: 2.413482308503051

Epoch: 5| Step: 8
Training loss: 0.8086660970120836
Validation loss: 2.405495026965502

Epoch: 5| Step: 9
Training loss: 0.8156287036095495
Validation loss: 2.4604654359728015

Epoch: 5| Step: 10
Training loss: 1.3521266928344184
Validation loss: 2.4609917966260384

Epoch: 437| Step: 0
Training loss: 1.0667532331883898
Validation loss: 2.4460235047440637

Epoch: 5| Step: 1
Training loss: 0.7075962317299009
Validation loss: 2.4363216373707672

Epoch: 5| Step: 2
Training loss: 0.5426667011373839
Validation loss: 2.442347913575728

Epoch: 5| Step: 3
Training loss: 0.6697555424474088
Validation loss: 2.469757460191664

Epoch: 5| Step: 4
Training loss: 0.9710113834181349
Validation loss: 2.446613078995641

Epoch: 5| Step: 5
Training loss: 0.7825747130682242
Validation loss: 2.4290060688859385

Epoch: 5| Step: 6
Training loss: 0.8129960526561746
Validation loss: 2.524556290807049

Epoch: 5| Step: 7
Training loss: 0.6506512094105206
Validation loss: 2.47422055230525

Epoch: 5| Step: 8
Training loss: 0.7301033452445234
Validation loss: 2.465590600119052

Epoch: 5| Step: 9
Training loss: 1.4686748404244392
Validation loss: 2.4778889125757546

Epoch: 5| Step: 10
Training loss: 0.6132275260184945
Validation loss: 2.4563121862825836

Epoch: 438| Step: 0
Training loss: 1.4372959821468263
Validation loss: 2.42735191829749

Epoch: 5| Step: 1
Training loss: 0.9803533904157418
Validation loss: 2.4392273627152417

Epoch: 5| Step: 2
Training loss: 0.6484153927630906
Validation loss: 2.4377664200099187

Epoch: 5| Step: 3
Training loss: 0.7347599400447937
Validation loss: 2.417415292547899

Epoch: 5| Step: 4
Training loss: 0.5966093830452017
Validation loss: 2.3650699613646378

Epoch: 5| Step: 5
Training loss: 0.6739928555576862
Validation loss: 2.3484299382856886

Epoch: 5| Step: 6
Training loss: 0.9843151740407764
Validation loss: 2.3762035921357647

Epoch: 5| Step: 7
Training loss: 0.873993635468693
Validation loss: 2.415256480953361

Epoch: 5| Step: 8
Training loss: 0.8748872548081801
Validation loss: 2.441720655578595

Epoch: 5| Step: 9
Training loss: 0.7961581876991488
Validation loss: 2.4988779657203763

Epoch: 5| Step: 10
Training loss: 0.3560438429645225
Validation loss: 2.475385856402778

Epoch: 439| Step: 0
Training loss: 0.9176024010290114
Validation loss: 2.451231164382296

Epoch: 5| Step: 1
Training loss: 0.5561896119931219
Validation loss: 2.4839310345140855

Epoch: 5| Step: 2
Training loss: 0.8481139604135329
Validation loss: 2.4646100095171812

Epoch: 5| Step: 3
Training loss: 0.6069977681120512
Validation loss: 2.439160173129608

Epoch: 5| Step: 4
Training loss: 0.8977272875426964
Validation loss: 2.3919130807290627

Epoch: 5| Step: 5
Training loss: 0.716965741215606
Validation loss: 2.3862800004882505

Epoch: 5| Step: 6
Training loss: 0.9348189163798845
Validation loss: 2.380875142914996

Epoch: 5| Step: 7
Training loss: 0.627538532502621
Validation loss: 2.4399218101352926

Epoch: 5| Step: 8
Training loss: 0.9372540469200533
Validation loss: 2.4348367372064073

Epoch: 5| Step: 9
Training loss: 0.7770096717536914
Validation loss: 2.434706463616238

Epoch: 5| Step: 10
Training loss: 1.313985937112952
Validation loss: 2.509417890767727

Epoch: 440| Step: 0
Training loss: 0.7898544642837647
Validation loss: 2.488858114286439

Epoch: 5| Step: 1
Training loss: 0.6772855652278419
Validation loss: 2.523906263311924

Epoch: 5| Step: 2
Training loss: 0.7923789626270822
Validation loss: 2.5196210657753513

Epoch: 5| Step: 3
Training loss: 0.7241139324757572
Validation loss: 2.540386388045373

Epoch: 5| Step: 4
Training loss: 0.6528577778089607
Validation loss: 2.5095707594874748

Epoch: 5| Step: 5
Training loss: 0.8816687677883599
Validation loss: 2.4851626876364596

Epoch: 5| Step: 6
Training loss: 0.818399578554524
Validation loss: 2.4353426412073484

Epoch: 5| Step: 7
Training loss: 0.8146268444359412
Validation loss: 2.4568778565197156

Epoch: 5| Step: 8
Training loss: 0.7994338446247179
Validation loss: 2.432412873190752

Epoch: 5| Step: 9
Training loss: 1.3296527378366088
Validation loss: 2.401810288644589

Epoch: 5| Step: 10
Training loss: 0.7188891815102735
Validation loss: 2.3728351560183416

Epoch: 441| Step: 0
Training loss: 0.4699984931160734
Validation loss: 2.4118296721078836

Epoch: 5| Step: 1
Training loss: 0.8787914285892034
Validation loss: 2.437271215757445

Epoch: 5| Step: 2
Training loss: 0.8099725365986787
Validation loss: 2.4728393790136205

Epoch: 5| Step: 3
Training loss: 0.7485954723206965
Validation loss: 2.4517132984647465

Epoch: 5| Step: 4
Training loss: 1.334096521268575
Validation loss: 2.518577993265288

Epoch: 5| Step: 5
Training loss: 0.6756188963862277
Validation loss: 2.493105554396858

Epoch: 5| Step: 6
Training loss: 0.7116591176281075
Validation loss: 2.481571771916751

Epoch: 5| Step: 7
Training loss: 0.7155763384670141
Validation loss: 2.424554498090191

Epoch: 5| Step: 8
Training loss: 0.8397501693752671
Validation loss: 2.496084057606175

Epoch: 5| Step: 9
Training loss: 0.8604700913980757
Validation loss: 2.4043999868720007

Epoch: 5| Step: 10
Training loss: 0.8530809006803641
Validation loss: 2.3949908779451055

Epoch: 442| Step: 0
Training loss: 0.7501911476057381
Validation loss: 2.383551853163539

Epoch: 5| Step: 1
Training loss: 0.7616632685874192
Validation loss: 2.3847196808922178

Epoch: 5| Step: 2
Training loss: 0.6686480676205895
Validation loss: 2.4098498448033148

Epoch: 5| Step: 3
Training loss: 0.9058116971028625
Validation loss: 2.4137137687108767

Epoch: 5| Step: 4
Training loss: 0.7846657658601234
Validation loss: 2.4259745556965537

Epoch: 5| Step: 5
Training loss: 1.3801391104367358
Validation loss: 2.4350545093915326

Epoch: 5| Step: 6
Training loss: 0.5429385883543906
Validation loss: 2.4124313691578756

Epoch: 5| Step: 7
Training loss: 0.8247234010850376
Validation loss: 2.4662121529314915

Epoch: 5| Step: 8
Training loss: 0.6866624455376233
Validation loss: 2.4900565413134004

Epoch: 5| Step: 9
Training loss: 1.0269775898465345
Validation loss: 2.5129127120006753

Epoch: 5| Step: 10
Training loss: 0.41559758920557777
Validation loss: 2.478022859493433

Epoch: 443| Step: 0
Training loss: 0.9430638199788822
Validation loss: 2.4908288273917267

Epoch: 5| Step: 1
Training loss: 0.6349057087014184
Validation loss: 2.4402445278697398

Epoch: 5| Step: 2
Training loss: 1.3290655508214906
Validation loss: 2.4493235995619367

Epoch: 5| Step: 3
Training loss: 0.8887398159339608
Validation loss: 2.454348709414487

Epoch: 5| Step: 4
Training loss: 0.5641792979533238
Validation loss: 2.498328845028088

Epoch: 5| Step: 5
Training loss: 0.8196944315214052
Validation loss: 2.4560389218280734

Epoch: 5| Step: 6
Training loss: 0.8527166262503845
Validation loss: 2.477730447136328

Epoch: 5| Step: 7
Training loss: 0.6470171297730156
Validation loss: 2.4772596934841866

Epoch: 5| Step: 8
Training loss: 0.7563023415099126
Validation loss: 2.4594518622464143

Epoch: 5| Step: 9
Training loss: 0.720922462561196
Validation loss: 2.4439811281056607

Epoch: 5| Step: 10
Training loss: 0.7118247228590078
Validation loss: 2.41724442699735

Epoch: 444| Step: 0
Training loss: 0.5523606239773701
Validation loss: 2.4439222261436

Epoch: 5| Step: 1
Training loss: 0.7754768688753821
Validation loss: 2.413100874670374

Epoch: 5| Step: 2
Training loss: 0.8031646614820163
Validation loss: 2.4024747833951414

Epoch: 5| Step: 3
Training loss: 0.9030296724160929
Validation loss: 2.408539139031711

Epoch: 5| Step: 4
Training loss: 0.6495219205618071
Validation loss: 2.439538293295597

Epoch: 5| Step: 5
Training loss: 0.8765948270932747
Validation loss: 2.4928490625417514

Epoch: 5| Step: 6
Training loss: 0.5701312992222175
Validation loss: 2.4708798858695684

Epoch: 5| Step: 7
Training loss: 0.6290396317912769
Validation loss: 2.485356988185133

Epoch: 5| Step: 8
Training loss: 1.2679919491641662
Validation loss: 2.465910377510526

Epoch: 5| Step: 9
Training loss: 0.8997255794394071
Validation loss: 2.4908724823973616

Epoch: 5| Step: 10
Training loss: 0.9329323121383618
Validation loss: 2.4853821328834367

Epoch: 445| Step: 0
Training loss: 0.7426462060982325
Validation loss: 2.4667264538109697

Epoch: 5| Step: 1
Training loss: 1.303364156828465
Validation loss: 2.4359334313650582

Epoch: 5| Step: 2
Training loss: 0.9806853279341096
Validation loss: 2.41342675288053

Epoch: 5| Step: 3
Training loss: 0.8645915793213323
Validation loss: 2.381928671180884

Epoch: 5| Step: 4
Training loss: 0.7070712505005803
Validation loss: 2.392533118482018

Epoch: 5| Step: 5
Training loss: 0.5558939426420799
Validation loss: 2.3960790774742216

Epoch: 5| Step: 6
Training loss: 0.7509798960121885
Validation loss: 2.389067306228819

Epoch: 5| Step: 7
Training loss: 0.7014388104939534
Validation loss: 2.4035040352371397

Epoch: 5| Step: 8
Training loss: 0.5587746653990482
Validation loss: 2.4052327092136303

Epoch: 5| Step: 9
Training loss: 0.8199368661325132
Validation loss: 2.460298154682903

Epoch: 5| Step: 10
Training loss: 0.7107685433302497
Validation loss: 2.4198651482470215

Epoch: 446| Step: 0
Training loss: 0.5481521951155626
Validation loss: 2.482349081803534

Epoch: 5| Step: 1
Training loss: 0.7612383770486019
Validation loss: 2.4829079802248253

Epoch: 5| Step: 2
Training loss: 0.5744378586619501
Validation loss: 2.4944455267200283

Epoch: 5| Step: 3
Training loss: 0.8579509727568997
Validation loss: 2.5315101314655464

Epoch: 5| Step: 4
Training loss: 1.3785775633095905
Validation loss: 2.4794750954157303

Epoch: 5| Step: 5
Training loss: 0.7378418841200067
Validation loss: 2.496040716112891

Epoch: 5| Step: 6
Training loss: 0.7891160927881183
Validation loss: 2.440793297130283

Epoch: 5| Step: 7
Training loss: 0.5999829001771547
Validation loss: 2.4223270816006726

Epoch: 5| Step: 8
Training loss: 0.8600198580423081
Validation loss: 2.440049989230438

Epoch: 5| Step: 9
Training loss: 0.5937915586684219
Validation loss: 2.4407243219754116

Epoch: 5| Step: 10
Training loss: 0.72843347653882
Validation loss: 2.420761732172472

Epoch: 447| Step: 0
Training loss: 0.9191425367239003
Validation loss: 2.4364317716426553

Epoch: 5| Step: 1
Training loss: 0.46554887008431545
Validation loss: 2.464544334210897

Epoch: 5| Step: 2
Training loss: 0.8509218798551075
Validation loss: 2.47392807601448

Epoch: 5| Step: 3
Training loss: 0.7825790544496561
Validation loss: 2.4689852474078102

Epoch: 5| Step: 4
Training loss: 0.7937429998494652
Validation loss: 2.445883998551178

Epoch: 5| Step: 5
Training loss: 0.648382230494411
Validation loss: 2.4601244115662726

Epoch: 5| Step: 6
Training loss: 1.098784386245393
Validation loss: 2.3805872723081554

Epoch: 5| Step: 7
Training loss: 0.8043441410266049
Validation loss: 2.4090972726278035

Epoch: 5| Step: 8
Training loss: 0.6440223071621209
Validation loss: 2.4326266121615987

Epoch: 5| Step: 9
Training loss: 0.78867009291653
Validation loss: 2.385022864691011

Epoch: 5| Step: 10
Training loss: 0.8823007095996434
Validation loss: 2.447095269131996

Epoch: 448| Step: 0
Training loss: 0.527513321351256
Validation loss: 2.430801763374856

Epoch: 5| Step: 1
Training loss: 0.7773662161336192
Validation loss: 2.4425648922365637

Epoch: 5| Step: 2
Training loss: 0.9556880945567197
Validation loss: 2.4437541580930633

Epoch: 5| Step: 3
Training loss: 0.6546760257634977
Validation loss: 2.431681866145148

Epoch: 5| Step: 4
Training loss: 0.6880989283543522
Validation loss: 2.427868586436709

Epoch: 5| Step: 5
Training loss: 0.8682994415151366
Validation loss: 2.451610471004279

Epoch: 5| Step: 6
Training loss: 0.4749795388532987
Validation loss: 2.4630660719902275

Epoch: 5| Step: 7
Training loss: 0.7970707222924164
Validation loss: 2.4975537103681735

Epoch: 5| Step: 8
Training loss: 1.091552707072313
Validation loss: 2.523746661646136

Epoch: 5| Step: 9
Training loss: 0.6521107834430245
Validation loss: 2.5030458425997613

Epoch: 5| Step: 10
Training loss: 1.0404885050749553
Validation loss: 2.513501099164088

Epoch: 449| Step: 0
Training loss: 0.719798194498658
Validation loss: 2.4972854001813363

Epoch: 5| Step: 1
Training loss: 0.6346702151853804
Validation loss: 2.4472285890044976

Epoch: 5| Step: 2
Training loss: 0.7267083872694163
Validation loss: 2.4496869429027153

Epoch: 5| Step: 3
Training loss: 0.6395894030636069
Validation loss: 2.4112172326614285

Epoch: 5| Step: 4
Training loss: 0.6056882398910026
Validation loss: 2.4079538169432824

Epoch: 5| Step: 5
Training loss: 0.7223913583614597
Validation loss: 2.4134747593188584

Epoch: 5| Step: 6
Training loss: 0.6551825379315926
Validation loss: 2.453301906118006

Epoch: 5| Step: 7
Training loss: 1.3926364196303656
Validation loss: 2.471249862100664

Epoch: 5| Step: 8
Training loss: 0.8429702758775253
Validation loss: 2.4667957754638263

Epoch: 5| Step: 9
Training loss: 0.6989670625493083
Validation loss: 2.4767023224801346

Epoch: 5| Step: 10
Training loss: 0.7515497488102009
Validation loss: 2.460474271550509

Epoch: 450| Step: 0
Training loss: 0.5847555064088469
Validation loss: 2.490846826535207

Epoch: 5| Step: 1
Training loss: 0.9438582339337925
Validation loss: 2.4288695750114275

Epoch: 5| Step: 2
Training loss: 0.5871338393139052
Validation loss: 2.3950195756718027

Epoch: 5| Step: 3
Training loss: 0.8173438715802487
Validation loss: 2.3968389443553453

Epoch: 5| Step: 4
Training loss: 0.6681756262515929
Validation loss: 2.4143818913042354

Epoch: 5| Step: 5
Training loss: 0.8260020990183394
Validation loss: 2.4277201545943066

Epoch: 5| Step: 6
Training loss: 0.6328391081314019
Validation loss: 2.427424024612099

Epoch: 5| Step: 7
Training loss: 0.32688728271149814
Validation loss: 2.4445022372327707

Epoch: 5| Step: 8
Training loss: 0.730186448651306
Validation loss: 2.4859530451617986

Epoch: 5| Step: 9
Training loss: 0.7954703648344189
Validation loss: 2.4741418893244917

Epoch: 5| Step: 10
Training loss: 1.3861381067328356
Validation loss: 2.459727414647007

Epoch: 451| Step: 0
Training loss: 1.107977510761124
Validation loss: 2.4493890424340825

Epoch: 5| Step: 1
Training loss: 0.517886807503458
Validation loss: 2.4679280703221806

Epoch: 5| Step: 2
Training loss: 0.6573623584954258
Validation loss: 2.408283159890299

Epoch: 5| Step: 3
Training loss: 1.1622420034939664
Validation loss: 2.4496000333023553

Epoch: 5| Step: 4
Training loss: 0.5317587380025336
Validation loss: 2.436530653281787

Epoch: 5| Step: 5
Training loss: 0.9205447799217187
Validation loss: 2.463287055918971

Epoch: 5| Step: 6
Training loss: 0.8200943793086642
Validation loss: 2.433365126315152

Epoch: 5| Step: 7
Training loss: 0.5664670714246529
Validation loss: 2.4745803622687013

Epoch: 5| Step: 8
Training loss: 0.6277139153555711
Validation loss: 2.4543382737551074

Epoch: 5| Step: 9
Training loss: 0.673112240194874
Validation loss: 2.4216647953687676

Epoch: 5| Step: 10
Training loss: 0.4110366817635477
Validation loss: 2.463069949090383

Epoch: 452| Step: 0
Training loss: 0.6075423142723799
Validation loss: 2.4421763885270256

Epoch: 5| Step: 1
Training loss: 0.4790019464015239
Validation loss: 2.454348802116515

Epoch: 5| Step: 2
Training loss: 0.9317377707577242
Validation loss: 2.4414905426896687

Epoch: 5| Step: 3
Training loss: 1.151463783618904
Validation loss: 2.4129254888237694

Epoch: 5| Step: 4
Training loss: 0.9213701902684998
Validation loss: 2.404263987001838

Epoch: 5| Step: 5
Training loss: 0.7083864238888824
Validation loss: 2.436875216710168

Epoch: 5| Step: 6
Training loss: 0.5571354323196326
Validation loss: 2.476451687688519

Epoch: 5| Step: 7
Training loss: 0.6858971073362157
Validation loss: 2.4515515222891024

Epoch: 5| Step: 8
Training loss: 0.8006296898304716
Validation loss: 2.4707086492604207

Epoch: 5| Step: 9
Training loss: 0.5281784233746089
Validation loss: 2.507722151906945

Epoch: 5| Step: 10
Training loss: 0.7994165095690963
Validation loss: 2.49302239400307

Epoch: 453| Step: 0
Training loss: 0.6883583995520807
Validation loss: 2.472994936722517

Epoch: 5| Step: 1
Training loss: 0.6360515773345506
Validation loss: 2.463982925244942

Epoch: 5| Step: 2
Training loss: 0.5951837245200922
Validation loss: 2.458109600578046

Epoch: 5| Step: 3
Training loss: 1.0639729668008238
Validation loss: 2.438261287117911

Epoch: 5| Step: 4
Training loss: 0.6208635299388062
Validation loss: 2.375878417169571

Epoch: 5| Step: 5
Training loss: 0.9403788868779289
Validation loss: 2.380376986504458

Epoch: 5| Step: 6
Training loss: 0.6782089902134006
Validation loss: 2.4394351375935437

Epoch: 5| Step: 7
Training loss: 0.8189854378016973
Validation loss: 2.4759470265848433

Epoch: 5| Step: 8
Training loss: 0.8976529884113124
Validation loss: 2.454879092858218

Epoch: 5| Step: 9
Training loss: 0.5391600976580156
Validation loss: 2.495245544125831

Epoch: 5| Step: 10
Training loss: 0.8106795604523775
Validation loss: 2.473495045898906

Epoch: 454| Step: 0
Training loss: 0.23211596095378748
Validation loss: 2.4784460529338888

Epoch: 5| Step: 1
Training loss: 0.31468197095118206
Validation loss: 2.462925693955502

Epoch: 5| Step: 2
Training loss: 0.7169114107099439
Validation loss: 2.4335688297381926

Epoch: 5| Step: 3
Training loss: 0.6548485550991993
Validation loss: 2.397888265005897

Epoch: 5| Step: 4
Training loss: 1.0924741660758348
Validation loss: 2.4124111016550516

Epoch: 5| Step: 5
Training loss: 0.49590143095407346
Validation loss: 2.3824144740721502

Epoch: 5| Step: 6
Training loss: 1.1315576377412322
Validation loss: 2.40613122313172

Epoch: 5| Step: 7
Training loss: 0.6434680376777451
Validation loss: 2.4299412807724816

Epoch: 5| Step: 8
Training loss: 0.7391741968636493
Validation loss: 2.4457676915406963

Epoch: 5| Step: 9
Training loss: 0.8477454072675433
Validation loss: 2.487652636551964

Epoch: 5| Step: 10
Training loss: 1.0132067721369848
Validation loss: 2.491194689396162

Epoch: 455| Step: 0
Training loss: 0.5057520513205381
Validation loss: 2.4534948961160414

Epoch: 5| Step: 1
Training loss: 0.8570476575617912
Validation loss: 2.4448241133657818

Epoch: 5| Step: 2
Training loss: 0.7884998770709477
Validation loss: 2.440543496752068

Epoch: 5| Step: 3
Training loss: 0.7998777922032978
Validation loss: 2.4197130941576526

Epoch: 5| Step: 4
Training loss: 0.6746965202940636
Validation loss: 2.4212725760414813

Epoch: 5| Step: 5
Training loss: 0.6121496463617888
Validation loss: 2.4214575940727636

Epoch: 5| Step: 6
Training loss: 0.8323335769916749
Validation loss: 2.4141267955827845

Epoch: 5| Step: 7
Training loss: 1.1620058157803204
Validation loss: 2.438235103424688

Epoch: 5| Step: 8
Training loss: 0.6986090489953888
Validation loss: 2.4623097427600467

Epoch: 5| Step: 9
Training loss: 0.44831561648568474
Validation loss: 2.4535755762337557

Epoch: 5| Step: 10
Training loss: 0.6288372973440064
Validation loss: 2.4649802091955917

Epoch: 456| Step: 0
Training loss: 0.7486163329856682
Validation loss: 2.482542117588458

Epoch: 5| Step: 1
Training loss: 0.9234389600403373
Validation loss: 2.4658432755953954

Epoch: 5| Step: 2
Training loss: 0.8729647057970278
Validation loss: 2.46358484714543

Epoch: 5| Step: 3
Training loss: 0.6507955212991714
Validation loss: 2.4199061663165433

Epoch: 5| Step: 4
Training loss: 0.5733427775052421
Validation loss: 2.461074525788408

Epoch: 5| Step: 5
Training loss: 0.4049072081617892
Validation loss: 2.4576336177881246

Epoch: 5| Step: 6
Training loss: 1.1124859026755052
Validation loss: 2.462829395994365

Epoch: 5| Step: 7
Training loss: 0.5932204746305065
Validation loss: 2.4598208314511303

Epoch: 5| Step: 8
Training loss: 0.640635606631421
Validation loss: 2.4533600938493594

Epoch: 5| Step: 9
Training loss: 0.8191844268133486
Validation loss: 2.454165111008993

Epoch: 5| Step: 10
Training loss: 0.7193947263874861
Validation loss: 2.4698691499534347

Epoch: 457| Step: 0
Training loss: 0.9551236194470316
Validation loss: 2.446490538729961

Epoch: 5| Step: 1
Training loss: 0.5116850572515871
Validation loss: 2.488751145735262

Epoch: 5| Step: 2
Training loss: 0.6777411029052991
Validation loss: 2.4503606987807576

Epoch: 5| Step: 3
Training loss: 0.7827988339752183
Validation loss: 2.447975102139296

Epoch: 5| Step: 4
Training loss: 0.40059574734539305
Validation loss: 2.4159058853915765

Epoch: 5| Step: 5
Training loss: 0.7946492695434877
Validation loss: 2.4320975948194734

Epoch: 5| Step: 6
Training loss: 1.2089001652442553
Validation loss: 2.399028578446732

Epoch: 5| Step: 7
Training loss: 0.47050875690978244
Validation loss: 2.4233427085296784

Epoch: 5| Step: 8
Training loss: 0.476067755239577
Validation loss: 2.4010960165676583

Epoch: 5| Step: 9
Training loss: 0.7049187350612764
Validation loss: 2.429667016375519

Epoch: 5| Step: 10
Training loss: 0.6682000010888044
Validation loss: 2.40452890114645

Epoch: 458| Step: 0
Training loss: 0.5779226567600365
Validation loss: 2.4641463988247625

Epoch: 5| Step: 1
Training loss: 0.7747010977453035
Validation loss: 2.448940839055195

Epoch: 5| Step: 2
Training loss: 0.5346800084260889
Validation loss: 2.4309604468872035

Epoch: 5| Step: 3
Training loss: 0.5498810574492098
Validation loss: 2.437339891045408

Epoch: 5| Step: 4
Training loss: 0.8222934600395579
Validation loss: 2.4197676388156935

Epoch: 5| Step: 5
Training loss: 0.7903143517475147
Validation loss: 2.4587101495465804

Epoch: 5| Step: 6
Training loss: 1.1039730238106527
Validation loss: 2.4709320259343044

Epoch: 5| Step: 7
Training loss: 0.6474255858561595
Validation loss: 2.4521244135927045

Epoch: 5| Step: 8
Training loss: 0.7545724405913428
Validation loss: 2.438347001707556

Epoch: 5| Step: 9
Training loss: 0.6833491732537015
Validation loss: 2.4237324610167805

Epoch: 5| Step: 10
Training loss: 0.5317401588203623
Validation loss: 2.4125654330405406

Epoch: 459| Step: 0
Training loss: 0.674379471489168
Validation loss: 2.466762384873384

Epoch: 5| Step: 1
Training loss: 0.4994152494259046
Validation loss: 2.4406083531091847

Epoch: 5| Step: 2
Training loss: 0.8610577148029862
Validation loss: 2.4419257301830104

Epoch: 5| Step: 3
Training loss: 0.9819807575267303
Validation loss: 2.4568977812055555

Epoch: 5| Step: 4
Training loss: 0.5991386529141665
Validation loss: 2.4339738524393444

Epoch: 5| Step: 5
Training loss: 0.6570764061178236
Validation loss: 2.386485850573078

Epoch: 5| Step: 6
Training loss: 0.9536101560448662
Validation loss: 2.4395825597941654

Epoch: 5| Step: 7
Training loss: 0.7956064636516426
Validation loss: 2.4248395640282143

Epoch: 5| Step: 8
Training loss: 0.5242881126393499
Validation loss: 2.4296521865910505

Epoch: 5| Step: 9
Training loss: 0.5671588238909894
Validation loss: 2.449173574817193

Epoch: 5| Step: 10
Training loss: 0.7045794385113965
Validation loss: 2.4217532018440604

Epoch: 460| Step: 0
Training loss: 0.6923448043742897
Validation loss: 2.4436265084897744

Epoch: 5| Step: 1
Training loss: 0.4950281247423877
Validation loss: 2.429880229068276

Epoch: 5| Step: 2
Training loss: 0.7228931760315226
Validation loss: 2.4447974782764432

Epoch: 5| Step: 3
Training loss: 0.6796814929214388
Validation loss: 2.388839106085947

Epoch: 5| Step: 4
Training loss: 1.2150145284937908
Validation loss: 2.426387183366509

Epoch: 5| Step: 5
Training loss: 0.5141598374527887
Validation loss: 2.382517008259591

Epoch: 5| Step: 6
Training loss: 0.8316930522313403
Validation loss: 2.3870779864445724

Epoch: 5| Step: 7
Training loss: 0.8734192875309399
Validation loss: 2.4281618221154395

Epoch: 5| Step: 8
Training loss: 0.5625195499837513
Validation loss: 2.407591186164005

Epoch: 5| Step: 9
Training loss: 0.7416990982065611
Validation loss: 2.4321182542952013

Epoch: 5| Step: 10
Training loss: 0.4433513926321012
Validation loss: 2.4582835909018974

Epoch: 461| Step: 0
Training loss: 0.9795213354609638
Validation loss: 2.4984373746519184

Epoch: 5| Step: 1
Training loss: 0.6528136565333778
Validation loss: 2.503227610462413

Epoch: 5| Step: 2
Training loss: 0.3749592878176427
Validation loss: 2.4451673094308775

Epoch: 5| Step: 3
Training loss: 0.8071703706903544
Validation loss: 2.4208827891607227

Epoch: 5| Step: 4
Training loss: 0.864458308697796
Validation loss: 2.3891613918437797

Epoch: 5| Step: 5
Training loss: 0.6521945028838435
Validation loss: 2.3669646426360313

Epoch: 5| Step: 6
Training loss: 0.843833142175514
Validation loss: 2.3347032703440096

Epoch: 5| Step: 7
Training loss: 0.548460215997434
Validation loss: 2.3598972713090847

Epoch: 5| Step: 8
Training loss: 0.5263382827664185
Validation loss: 2.4074778125784833

Epoch: 5| Step: 9
Training loss: 0.7599385905552501
Validation loss: 2.4731713710501526

Epoch: 5| Step: 10
Training loss: 1.0225575282135302
Validation loss: 2.5064002741295437

Epoch: 462| Step: 0
Training loss: 0.5034045301802637
Validation loss: 2.515173507017715

Epoch: 5| Step: 1
Training loss: 0.6874420835201901
Validation loss: 2.4601431199149686

Epoch: 5| Step: 2
Training loss: 0.7707954131069604
Validation loss: 2.4325688400875363

Epoch: 5| Step: 3
Training loss: 0.7062724135226569
Validation loss: 2.390279588511578

Epoch: 5| Step: 4
Training loss: 0.8196289847892179
Validation loss: 2.406190562756012

Epoch: 5| Step: 5
Training loss: 1.2174812951501668
Validation loss: 2.3710521448305926

Epoch: 5| Step: 6
Training loss: 0.7005582584372154
Validation loss: 2.3665014833984057

Epoch: 5| Step: 7
Training loss: 0.583291015338877
Validation loss: 2.364798172108398

Epoch: 5| Step: 8
Training loss: 0.7099339874903392
Validation loss: 2.4504459723576604

Epoch: 5| Step: 9
Training loss: 0.6046382499569513
Validation loss: 2.4852263341892247

Epoch: 5| Step: 10
Training loss: 0.6826870163550266
Validation loss: 2.5082620299549268

Epoch: 463| Step: 0
Training loss: 0.9658842460986576
Validation loss: 2.5045205427980766

Epoch: 5| Step: 1
Training loss: 1.0800966671667886
Validation loss: 2.534060077166894

Epoch: 5| Step: 2
Training loss: 1.0069154399041513
Validation loss: 2.500610760972059

Epoch: 5| Step: 3
Training loss: 0.7038097861660844
Validation loss: 2.4163858270317027

Epoch: 5| Step: 4
Training loss: 0.5175097726276937
Validation loss: 2.3542601878714198

Epoch: 5| Step: 5
Training loss: 0.6801584957689524
Validation loss: 2.325505440919902

Epoch: 5| Step: 6
Training loss: 0.7846586633972004
Validation loss: 2.3099462703398856

Epoch: 5| Step: 7
Training loss: 0.6170060337658834
Validation loss: 2.324967428811304

Epoch: 5| Step: 8
Training loss: 0.5317823603691834
Validation loss: 2.355287984682432

Epoch: 5| Step: 9
Training loss: 0.6142486668620006
Validation loss: 2.3915467624278866

Epoch: 5| Step: 10
Training loss: 0.6070047645240455
Validation loss: 2.4320034333165466

Epoch: 464| Step: 0
Training loss: 0.8082895121215734
Validation loss: 2.4961641417168092

Epoch: 5| Step: 1
Training loss: 0.793791020452295
Validation loss: 2.503414091158281

Epoch: 5| Step: 2
Training loss: 0.9027611233731897
Validation loss: 2.4239086006114925

Epoch: 5| Step: 3
Training loss: 0.5829712362653052
Validation loss: 2.3846047511701225

Epoch: 5| Step: 4
Training loss: 0.80363862649814
Validation loss: 2.3446203791018525

Epoch: 5| Step: 5
Training loss: 0.5584223023979247
Validation loss: 2.3282640025708354

Epoch: 5| Step: 6
Training loss: 0.6801955198996236
Validation loss: 2.2931440448190092

Epoch: 5| Step: 7
Training loss: 1.0779669825534843
Validation loss: 2.3445355373914327

Epoch: 5| Step: 8
Training loss: 0.7131757192269683
Validation loss: 2.3469905881773525

Epoch: 5| Step: 9
Training loss: 0.6475431870451519
Validation loss: 2.370642285161268

Epoch: 5| Step: 10
Training loss: 0.68240549627955
Validation loss: 2.36085370144731

Epoch: 465| Step: 0
Training loss: 1.0097555901565571
Validation loss: 2.391934189639721

Epoch: 5| Step: 1
Training loss: 0.5295007179442699
Validation loss: 2.4229057677509713

Epoch: 5| Step: 2
Training loss: 0.6637768972733734
Validation loss: 2.399187069287216

Epoch: 5| Step: 3
Training loss: 0.6444429048043893
Validation loss: 2.3695967727423373

Epoch: 5| Step: 4
Training loss: 0.5373598381755483
Validation loss: 2.414208465335749

Epoch: 5| Step: 5
Training loss: 0.6524875961966329
Validation loss: 2.4171460672986633

Epoch: 5| Step: 6
Training loss: 0.7428723438182717
Validation loss: 2.3898015130420416

Epoch: 5| Step: 7
Training loss: 0.9898411197522029
Validation loss: 2.385623592077001

Epoch: 5| Step: 8
Training loss: 0.8917961451443507
Validation loss: 2.390713954865423

Epoch: 5| Step: 9
Training loss: 0.6246406952888252
Validation loss: 2.3812497737428906

Epoch: 5| Step: 10
Training loss: 0.43145746340894964
Validation loss: 2.411784540132998

Epoch: 466| Step: 0
Training loss: 0.5365578333852252
Validation loss: 2.3902797740588317

Epoch: 5| Step: 1
Training loss: 1.158681169377056
Validation loss: 2.4266738521530846

Epoch: 5| Step: 2
Training loss: 0.7686931092835884
Validation loss: 2.438151783828538

Epoch: 5| Step: 3
Training loss: 0.6801827478976272
Validation loss: 2.436157938035938

Epoch: 5| Step: 4
Training loss: 0.6285038009868512
Validation loss: 2.418020606054367

Epoch: 5| Step: 5
Training loss: 0.34263876635977886
Validation loss: 2.4140906545503436

Epoch: 5| Step: 6
Training loss: 0.5973873156666734
Validation loss: 2.4033672791875693

Epoch: 5| Step: 7
Training loss: 0.7335400806494001
Validation loss: 2.3890602470158813

Epoch: 5| Step: 8
Training loss: 0.8802096387563803
Validation loss: 2.3964770471970795

Epoch: 5| Step: 9
Training loss: 0.593826414511573
Validation loss: 2.3552322966936163

Epoch: 5| Step: 10
Training loss: 0.5287664084898341
Validation loss: 2.351148517736191

Epoch: 467| Step: 0
Training loss: 0.6971464936881284
Validation loss: 2.375113417071334

Epoch: 5| Step: 1
Training loss: 0.6567237597139881
Validation loss: 2.409616410111459

Epoch: 5| Step: 2
Training loss: 0.8001472009893165
Validation loss: 2.410482838980459

Epoch: 5| Step: 3
Training loss: 0.42487371475819924
Validation loss: 2.421041063897317

Epoch: 5| Step: 4
Training loss: 0.7648532247297426
Validation loss: 2.4090788968171495

Epoch: 5| Step: 5
Training loss: 0.606563341630512
Validation loss: 2.4310033225408527

Epoch: 5| Step: 6
Training loss: 0.6845754277668085
Validation loss: 2.4651604409905596

Epoch: 5| Step: 7
Training loss: 0.9503957727107044
Validation loss: 2.449752461357389

Epoch: 5| Step: 8
Training loss: 0.4685153850881125
Validation loss: 2.4400722844652925

Epoch: 5| Step: 9
Training loss: 0.5889782144568654
Validation loss: 2.4270272396118675

Epoch: 5| Step: 10
Training loss: 0.8977060408764724
Validation loss: 2.4289900632699686

Epoch: 468| Step: 0
Training loss: 0.3446934281545795
Validation loss: 2.426881375008983

Epoch: 5| Step: 1
Training loss: 0.4564761679017833
Validation loss: 2.402353146695817

Epoch: 5| Step: 2
Training loss: 0.902824174878777
Validation loss: 2.370341621707978

Epoch: 5| Step: 3
Training loss: 0.7856129319289076
Validation loss: 2.3939900080900784

Epoch: 5| Step: 4
Training loss: 0.8133715943094736
Validation loss: 2.4278053791596608

Epoch: 5| Step: 5
Training loss: 0.638006160852827
Validation loss: 2.4432841389606845

Epoch: 5| Step: 6
Training loss: 0.7607312575058244
Validation loss: 2.445912867433496

Epoch: 5| Step: 7
Training loss: 1.1083090590684568
Validation loss: 2.4430181779631983

Epoch: 5| Step: 8
Training loss: 0.4717935618173539
Validation loss: 2.4343943788187654

Epoch: 5| Step: 9
Training loss: 0.5373293616877338
Validation loss: 2.4928288266749723

Epoch: 5| Step: 10
Training loss: 0.5089057305356479
Validation loss: 2.455728043732002

Epoch: 469| Step: 0
Training loss: 0.8260330191725238
Validation loss: 2.446877240066908

Epoch: 5| Step: 1
Training loss: 0.5365679422145869
Validation loss: 2.454925345962476

Epoch: 5| Step: 2
Training loss: 0.5971717116955215
Validation loss: 2.4348794179936313

Epoch: 5| Step: 3
Training loss: 0.46360901725477277
Validation loss: 2.4267279424467523

Epoch: 5| Step: 4
Training loss: 0.44908939655326185
Validation loss: 2.376850380994435

Epoch: 5| Step: 5
Training loss: 0.7030255777215216
Validation loss: 2.374794448113625

Epoch: 5| Step: 6
Training loss: 0.6225423893035085
Validation loss: 2.4413894341658784

Epoch: 5| Step: 7
Training loss: 0.46823406436156395
Validation loss: 2.4036810406883324

Epoch: 5| Step: 8
Training loss: 0.7652638809879297
Validation loss: 2.4269204037270384

Epoch: 5| Step: 9
Training loss: 1.1317568365437862
Validation loss: 2.4034468921866536

Epoch: 5| Step: 10
Training loss: 0.7280037234572673
Validation loss: 2.4440181550958666

Epoch: 470| Step: 0
Training loss: 0.5785002907955853
Validation loss: 2.458323007488586

Epoch: 5| Step: 1
Training loss: 0.6854893152140178
Validation loss: 2.3880753367959837

Epoch: 5| Step: 2
Training loss: 0.3640715708441646
Validation loss: 2.407062805019856

Epoch: 5| Step: 3
Training loss: 0.5920136561413478
Validation loss: 2.385552310342489

Epoch: 5| Step: 4
Training loss: 0.6485794095940114
Validation loss: 2.3698815564120084

Epoch: 5| Step: 5
Training loss: 1.0490130327213356
Validation loss: 2.4104321300081386

Epoch: 5| Step: 6
Training loss: 0.7130941440148713
Validation loss: 2.392933394219447

Epoch: 5| Step: 7
Training loss: 0.6104237262026841
Validation loss: 2.3872839384667466

Epoch: 5| Step: 8
Training loss: 0.5616568232795355
Validation loss: 2.3845672886416844

Epoch: 5| Step: 9
Training loss: 0.6448358451815374
Validation loss: 2.4314669370487207

Epoch: 5| Step: 10
Training loss: 0.8487808221380762
Validation loss: 2.5000713051092083

Epoch: 471| Step: 0
Training loss: 0.6529264988024025
Validation loss: 2.5047578851614962

Epoch: 5| Step: 1
Training loss: 0.8172877175492337
Validation loss: 2.4927252645330515

Epoch: 5| Step: 2
Training loss: 0.7143780801861858
Validation loss: 2.501345996091469

Epoch: 5| Step: 3
Training loss: 0.3438236526132507
Validation loss: 2.4551292912259823

Epoch: 5| Step: 4
Training loss: 0.6034419190666268
Validation loss: 2.4479824951857867

Epoch: 5| Step: 5
Training loss: 0.584810138809739
Validation loss: 2.4159670525369257

Epoch: 5| Step: 6
Training loss: 1.0474461378211066
Validation loss: 2.3735644336323554

Epoch: 5| Step: 7
Training loss: 0.5974142045708049
Validation loss: 2.3843259397757515

Epoch: 5| Step: 8
Training loss: 0.5923624137689186
Validation loss: 2.3754602751558394

Epoch: 5| Step: 9
Training loss: 0.6371725606546778
Validation loss: 2.3694825041187584

Epoch: 5| Step: 10
Training loss: 0.6208106301357383
Validation loss: 2.431303142031459

Epoch: 472| Step: 0
Training loss: 0.8546665558698388
Validation loss: 2.4307134096731997

Epoch: 5| Step: 1
Training loss: 1.0489782584658316
Validation loss: 2.431895614547066

Epoch: 5| Step: 2
Training loss: 0.6288411361442102
Validation loss: 2.4512136142930543

Epoch: 5| Step: 3
Training loss: 0.7142942223723372
Validation loss: 2.413012334464422

Epoch: 5| Step: 4
Training loss: 0.5891657842452345
Validation loss: 2.469467876999913

Epoch: 5| Step: 5
Training loss: 0.6022177261344627
Validation loss: 2.4837584382823854

Epoch: 5| Step: 6
Training loss: 0.5158258104879926
Validation loss: 2.506768060085604

Epoch: 5| Step: 7
Training loss: 0.7035610542265565
Validation loss: 2.4798436580074683

Epoch: 5| Step: 8
Training loss: 0.48358700860028336
Validation loss: 2.4984317629177504

Epoch: 5| Step: 9
Training loss: 0.5608286398662429
Validation loss: 2.4544979695056353

Epoch: 5| Step: 10
Training loss: 0.541303289622486
Validation loss: 2.462097070311574

Epoch: 473| Step: 0
Training loss: 0.4275314511614507
Validation loss: 2.44956811317345

Epoch: 5| Step: 1
Training loss: 0.7478627907165881
Validation loss: 2.429927763797633

Epoch: 5| Step: 2
Training loss: 0.6951765720503441
Validation loss: 2.4075967114857746

Epoch: 5| Step: 3
Training loss: 0.8678105495981807
Validation loss: 2.4170633587344375

Epoch: 5| Step: 4
Training loss: 0.4843601870579067
Validation loss: 2.4097364184352377

Epoch: 5| Step: 5
Training loss: 0.5949857300561834
Validation loss: 2.4232126067731183

Epoch: 5| Step: 6
Training loss: 0.6114196221370877
Validation loss: 2.407364349525334

Epoch: 5| Step: 7
Training loss: 0.5435439431886188
Validation loss: 2.445142759803295

Epoch: 5| Step: 8
Training loss: 0.6663285580209994
Validation loss: 2.451335669552416

Epoch: 5| Step: 9
Training loss: 0.8872401851155254
Validation loss: 2.452069455366791

Epoch: 5| Step: 10
Training loss: 0.6323923906377
Validation loss: 2.4954335346110392

Epoch: 474| Step: 0
Training loss: 0.3779069169156193
Validation loss: 2.4750461648228015

Epoch: 5| Step: 1
Training loss: 0.6174084473126883
Validation loss: 2.4425230418845296

Epoch: 5| Step: 2
Training loss: 0.5903347068959474
Validation loss: 2.4466508771645

Epoch: 5| Step: 3
Training loss: 0.5141590549497049
Validation loss: 2.439011489307311

Epoch: 5| Step: 4
Training loss: 0.8674335646131561
Validation loss: 2.449588084757237

Epoch: 5| Step: 5
Training loss: 0.9181080164679148
Validation loss: 2.4604480637591593

Epoch: 5| Step: 6
Training loss: 0.6475857115319678
Validation loss: 2.4358150178885887

Epoch: 5| Step: 7
Training loss: 0.5408284934414616
Validation loss: 2.433357246897818

Epoch: 5| Step: 8
Training loss: 0.8083625499780598
Validation loss: 2.453729974376428

Epoch: 5| Step: 9
Training loss: 0.46628921228844056
Validation loss: 2.429309442173146

Epoch: 5| Step: 10
Training loss: 0.56078641870497
Validation loss: 2.451356727968344

Epoch: 475| Step: 0
Training loss: 0.41408693493414067
Validation loss: 2.458441430731296

Epoch: 5| Step: 1
Training loss: 0.4483290112415901
Validation loss: 2.497421929871735

Epoch: 5| Step: 2
Training loss: 0.7197220076231803
Validation loss: 2.434104639186707

Epoch: 5| Step: 3
Training loss: 0.599201324488038
Validation loss: 2.4596393787354707

Epoch: 5| Step: 4
Training loss: 0.7529844667370084
Validation loss: 2.4692403374663656

Epoch: 5| Step: 5
Training loss: 0.8229389469333622
Validation loss: 2.436447926186628

Epoch: 5| Step: 6
Training loss: 0.5909905306675519
Validation loss: 2.4268287966386897

Epoch: 5| Step: 7
Training loss: 0.6794408591879305
Validation loss: 2.400669077444321

Epoch: 5| Step: 8
Training loss: 0.49786069793520615
Validation loss: 2.384377841536243

Epoch: 5| Step: 9
Training loss: 0.7552376489320702
Validation loss: 2.4071420806615182

Epoch: 5| Step: 10
Training loss: 0.6562378746002435
Validation loss: 2.3744694581893295

Epoch: 476| Step: 0
Training loss: 0.43482214670801766
Validation loss: 2.4300298339828283

Epoch: 5| Step: 1
Training loss: 0.5600091568164142
Validation loss: 2.4056885534004206

Epoch: 5| Step: 2
Training loss: 0.5260360327189179
Validation loss: 2.411087803579678

Epoch: 5| Step: 3
Training loss: 0.4830248072712126
Validation loss: 2.4233294530768266

Epoch: 5| Step: 4
Training loss: 0.7359032657379247
Validation loss: 2.4599478298625956

Epoch: 5| Step: 5
Training loss: 0.4416409096614852
Validation loss: 2.4279069541270415

Epoch: 5| Step: 6
Training loss: 1.0335257879102546
Validation loss: 2.402362879501789

Epoch: 5| Step: 7
Training loss: 0.7219635814136148
Validation loss: 2.417869869477104

Epoch: 5| Step: 8
Training loss: 0.4809184567236329
Validation loss: 2.4399305582982778

Epoch: 5| Step: 9
Training loss: 0.8518716793317438
Validation loss: 2.4117147754545143

Epoch: 5| Step: 10
Training loss: 0.37428246833658396
Validation loss: 2.372462960393483

Epoch: 477| Step: 0
Training loss: 0.5741729458556439
Validation loss: 2.394172699292642

Epoch: 5| Step: 1
Training loss: 0.5627717050682056
Validation loss: 2.3903478882332125

Epoch: 5| Step: 2
Training loss: 0.5139232644047865
Validation loss: 2.3967819868155478

Epoch: 5| Step: 3
Training loss: 0.6520418393600456
Validation loss: 2.410097884511557

Epoch: 5| Step: 4
Training loss: 0.8266566231973748
Validation loss: 2.4713232280796213

Epoch: 5| Step: 5
Training loss: 0.9028034773045961
Validation loss: 2.4827127321528812

Epoch: 5| Step: 6
Training loss: 0.7216855927717419
Validation loss: 2.466637658514297

Epoch: 5| Step: 7
Training loss: 0.5661434747903564
Validation loss: 2.4381349671036006

Epoch: 5| Step: 8
Training loss: 0.4668518097925667
Validation loss: 2.4299687254229325

Epoch: 5| Step: 9
Training loss: 0.6875125493724914
Validation loss: 2.4331230388206824

Epoch: 5| Step: 10
Training loss: 0.3886531844509339
Validation loss: 2.3988211649816877

Epoch: 478| Step: 0
Training loss: 0.47958674537622586
Validation loss: 2.4310402793406793

Epoch: 5| Step: 1
Training loss: 0.6469613473731551
Validation loss: 2.3600052093276647

Epoch: 5| Step: 2
Training loss: 0.5761422101159027
Validation loss: 2.3719575086504037

Epoch: 5| Step: 3
Training loss: 0.3626711655047296
Validation loss: 2.4021042579109704

Epoch: 5| Step: 4
Training loss: 0.8123228540244203
Validation loss: 2.412900594157987

Epoch: 5| Step: 5
Training loss: 0.884119939249452
Validation loss: 2.4295109394296737

Epoch: 5| Step: 6
Training loss: 0.6143944229051665
Validation loss: 2.447426153053917

Epoch: 5| Step: 7
Training loss: 0.6005339561235082
Validation loss: 2.4512912032385934

Epoch: 5| Step: 8
Training loss: 0.45482505670816675
Validation loss: 2.4217918093257302

Epoch: 5| Step: 9
Training loss: 0.6684836026379777
Validation loss: 2.4372832267885096

Epoch: 5| Step: 10
Training loss: 0.5956938445822315
Validation loss: 2.434843137779678

Epoch: 479| Step: 0
Training loss: 0.6127341679177888
Validation loss: 2.4250963564674763

Epoch: 5| Step: 1
Training loss: 0.7566362277460998
Validation loss: 2.4402608620324613

Epoch: 5| Step: 2
Training loss: 0.6012985343933007
Validation loss: 2.4158904774317898

Epoch: 5| Step: 3
Training loss: 0.5748238521780976
Validation loss: 2.4272057217523098

Epoch: 5| Step: 4
Training loss: 0.6268346323953097
Validation loss: 2.3916322024843812

Epoch: 5| Step: 5
Training loss: 0.5975243167238545
Validation loss: 2.3604855421896787

Epoch: 5| Step: 6
Training loss: 0.5727181842197744
Validation loss: 2.388691192337681

Epoch: 5| Step: 7
Training loss: 0.6176883741459639
Validation loss: 2.387632241066042

Epoch: 5| Step: 8
Training loss: 0.7238500271657454
Validation loss: 2.3999708358896608

Epoch: 5| Step: 9
Training loss: 0.6749617618750255
Validation loss: 2.3693903003815704

Epoch: 5| Step: 10
Training loss: 0.2938974918234765
Validation loss: 2.37948273213586

Epoch: 480| Step: 0
Training loss: 0.7038031380818927
Validation loss: 2.4189734441328166

Epoch: 5| Step: 1
Training loss: 0.7155586794976873
Validation loss: 2.3783642351952854

Epoch: 5| Step: 2
Training loss: 0.5499288577972182
Validation loss: 2.4322818774263726

Epoch: 5| Step: 3
Training loss: 0.8851530393187026
Validation loss: 2.424548133798009

Epoch: 5| Step: 4
Training loss: 0.4121700802607821
Validation loss: 2.4204444770200397

Epoch: 5| Step: 5
Training loss: 0.435962444535171
Validation loss: 2.4588234410962553

Epoch: 5| Step: 6
Training loss: 0.5081218070930491
Validation loss: 2.438001046378635

Epoch: 5| Step: 7
Training loss: 0.4904950273467827
Validation loss: 2.3982634769002105

Epoch: 5| Step: 8
Training loss: 0.5617373117237128
Validation loss: 2.3865143659041417

Epoch: 5| Step: 9
Training loss: 0.6282817986482864
Validation loss: 2.369258980762452

Epoch: 5| Step: 10
Training loss: 0.8470708697956865
Validation loss: 2.3224221108721332

Epoch: 481| Step: 0
Training loss: 0.9884262280178742
Validation loss: 2.3671022931371115

Epoch: 5| Step: 1
Training loss: 0.3720468028092784
Validation loss: 2.356745665669722

Epoch: 5| Step: 2
Training loss: 0.7264784897667308
Validation loss: 2.387541623024651

Epoch: 5| Step: 3
Training loss: 0.6416940840110916
Validation loss: 2.4238974992545215

Epoch: 5| Step: 4
Training loss: 0.4004594511097805
Validation loss: 2.447232478101062

Epoch: 5| Step: 5
Training loss: 0.5983392390762843
Validation loss: 2.4769422341513043

Epoch: 5| Step: 6
Training loss: 0.39604581809974226
Validation loss: 2.5107323627563125

Epoch: 5| Step: 7
Training loss: 0.4715973365560859
Validation loss: 2.4751228518307533

Epoch: 5| Step: 8
Training loss: 0.5733718335546794
Validation loss: 2.4381409405319814

Epoch: 5| Step: 9
Training loss: 0.8110355972022432
Validation loss: 2.403073899955436

Epoch: 5| Step: 10
Training loss: 0.4953606512930859
Validation loss: 2.3933111149963175

Epoch: 482| Step: 0
Training loss: 0.5715511926999803
Validation loss: 2.3729357446066768

Epoch: 5| Step: 1
Training loss: 0.598753725569887
Validation loss: 2.3688602705507544

Epoch: 5| Step: 2
Training loss: 0.6177576546065469
Validation loss: 2.4130626285302186

Epoch: 5| Step: 3
Training loss: 0.8982553380313353
Validation loss: 2.4139281762283753

Epoch: 5| Step: 4
Training loss: 0.5102907596402634
Validation loss: 2.4245672868939625

Epoch: 5| Step: 5
Training loss: 0.7283999681070563
Validation loss: 2.439126018484793

Epoch: 5| Step: 6
Training loss: 0.37227959141345385
Validation loss: 2.439387943666606

Epoch: 5| Step: 7
Training loss: 0.6056496626769942
Validation loss: 2.399037936299932

Epoch: 5| Step: 8
Training loss: 0.6171592512788384
Validation loss: 2.400741324177129

Epoch: 5| Step: 9
Training loss: 0.7721515330047398
Validation loss: 2.4278651694696705

Epoch: 5| Step: 10
Training loss: 0.25200673205791563
Validation loss: 2.381690788948017

Epoch: 483| Step: 0
Training loss: 0.9150042125208874
Validation loss: 2.405181393916398

Epoch: 5| Step: 1
Training loss: 0.5482621991426299
Validation loss: 2.394520433469692

Epoch: 5| Step: 2
Training loss: 0.6365572718769379
Validation loss: 2.45382479328267

Epoch: 5| Step: 3
Training loss: 0.38414336490022494
Validation loss: 2.4931764872874367

Epoch: 5| Step: 4
Training loss: 0.49550796827555166
Validation loss: 2.453145557111294

Epoch: 5| Step: 5
Training loss: 0.6566648761326281
Validation loss: 2.4768331549387548

Epoch: 5| Step: 6
Training loss: 0.6123995426085326
Validation loss: 2.4854070586542023

Epoch: 5| Step: 7
Training loss: 0.5958419137839289
Validation loss: 2.421408159909343

Epoch: 5| Step: 8
Training loss: 0.6854859675550881
Validation loss: 2.3720345682283748

Epoch: 5| Step: 9
Training loss: 0.6088559067187043
Validation loss: 2.3757273084436354

Epoch: 5| Step: 10
Training loss: 0.6916499812821437
Validation loss: 2.3572072403446476

Epoch: 484| Step: 0
Training loss: 0.48991275587249694
Validation loss: 2.3543530832399804

Epoch: 5| Step: 1
Training loss: 0.5228629873721128
Validation loss: 2.4348914963623995

Epoch: 5| Step: 2
Training loss: 0.9306716838576644
Validation loss: 2.445379962951778

Epoch: 5| Step: 3
Training loss: 0.6625712536335319
Validation loss: 2.4953501970128205

Epoch: 5| Step: 4
Training loss: 0.5737910072365899
Validation loss: 2.5045030431798163

Epoch: 5| Step: 5
Training loss: 0.9281153488941805
Validation loss: 2.493291276562037

Epoch: 5| Step: 6
Training loss: 0.5949858051898858
Validation loss: 2.3876884247793133

Epoch: 5| Step: 7
Training loss: 0.46250638828505175
Validation loss: 2.358684698774792

Epoch: 5| Step: 8
Training loss: 0.5872937083764214
Validation loss: 2.3198253791060184

Epoch: 5| Step: 9
Training loss: 0.7041995420813595
Validation loss: 2.301198149301471

Epoch: 5| Step: 10
Training loss: 0.5192483978118201
Validation loss: 2.332081269467613

Epoch: 485| Step: 0
Training loss: 0.46559633512398246
Validation loss: 2.3692559997314833

Epoch: 5| Step: 1
Training loss: 0.35058930589338166
Validation loss: 2.446359818400389

Epoch: 5| Step: 2
Training loss: 0.6643636581586793
Validation loss: 2.5118145382270654

Epoch: 5| Step: 3
Training loss: 0.7792776387452957
Validation loss: 2.486488636572699

Epoch: 5| Step: 4
Training loss: 0.6782014320298794
Validation loss: 2.465733915407593

Epoch: 5| Step: 5
Training loss: 0.9343855943366254
Validation loss: 2.4007761423641476

Epoch: 5| Step: 6
Training loss: 0.598942140000968
Validation loss: 2.3303052019704564

Epoch: 5| Step: 7
Training loss: 0.6247977883332754
Validation loss: 2.3610563262995314

Epoch: 5| Step: 8
Training loss: 0.5598618844555662
Validation loss: 2.3489040743838

Epoch: 5| Step: 9
Training loss: 0.7748726140204155
Validation loss: 2.3569243781794786

Epoch: 5| Step: 10
Training loss: 0.5721242424057889
Validation loss: 2.432234343908835

Epoch: 486| Step: 0
Training loss: 0.6922979262470119
Validation loss: 2.449568077590123

Epoch: 5| Step: 1
Training loss: 0.6051265364723738
Validation loss: 2.4232019277903816

Epoch: 5| Step: 2
Training loss: 0.9528731341663375
Validation loss: 2.4804327653001503

Epoch: 5| Step: 3
Training loss: 0.6162513925176831
Validation loss: 2.4389329173986676

Epoch: 5| Step: 4
Training loss: 0.691464071496147
Validation loss: 2.441696191515625

Epoch: 5| Step: 5
Training loss: 0.626546543707739
Validation loss: 2.42044780278361

Epoch: 5| Step: 6
Training loss: 0.6217196687479222
Validation loss: 2.3730181049287715

Epoch: 5| Step: 7
Training loss: 0.4653405171728373
Validation loss: 2.4056908019372085

Epoch: 5| Step: 8
Training loss: 0.5742325554051013
Validation loss: 2.3939281219891466

Epoch: 5| Step: 9
Training loss: 0.4326426410291231
Validation loss: 2.388770147205494

Epoch: 5| Step: 10
Training loss: 0.6146205443631362
Validation loss: 2.4444646533458227

Epoch: 487| Step: 0
Training loss: 0.5068053013945059
Validation loss: 2.466645403559442

Epoch: 5| Step: 1
Training loss: 0.37313228647986457
Validation loss: 2.4386400071107297

Epoch: 5| Step: 2
Training loss: 0.4212899036071898
Validation loss: 2.4622448546608915

Epoch: 5| Step: 3
Training loss: 0.7826515214974832
Validation loss: 2.455585388923637

Epoch: 5| Step: 4
Training loss: 0.5672518764564005
Validation loss: 2.422023438116724

Epoch: 5| Step: 5
Training loss: 1.0652358231011827
Validation loss: 2.4043220410808788

Epoch: 5| Step: 6
Training loss: 0.6352980508207289
Validation loss: 2.4082166728940444

Epoch: 5| Step: 7
Training loss: 0.6448759602145614
Validation loss: 2.355918291068717

Epoch: 5| Step: 8
Training loss: 0.46972478600560635
Validation loss: 2.3825767278062746

Epoch: 5| Step: 9
Training loss: 0.2995964345910208
Validation loss: 2.3844831457820286

Epoch: 5| Step: 10
Training loss: 0.49951596971420176
Validation loss: 2.4124246647054917

Epoch: 488| Step: 0
Training loss: 0.44437031036563557
Validation loss: 2.384618948633007

Epoch: 5| Step: 1
Training loss: 0.8060130710086216
Validation loss: 2.421199012755805

Epoch: 5| Step: 2
Training loss: 0.5006603410416887
Validation loss: 2.420971575757445

Epoch: 5| Step: 3
Training loss: 0.5634811639184684
Validation loss: 2.3855491073374613

Epoch: 5| Step: 4
Training loss: 0.5651697012408201
Validation loss: 2.470092141211078

Epoch: 5| Step: 5
Training loss: 0.7451986565804568
Validation loss: 2.4415375059222866

Epoch: 5| Step: 6
Training loss: 0.4979179664286271
Validation loss: 2.461724370402481

Epoch: 5| Step: 7
Training loss: 0.5520489759970705
Validation loss: 2.4577890679690797

Epoch: 5| Step: 8
Training loss: 0.5584186466238678
Validation loss: 2.447339815774544

Epoch: 5| Step: 9
Training loss: 0.38844492051270957
Validation loss: 2.4355039051257092

Epoch: 5| Step: 10
Training loss: 0.6711956404229532
Validation loss: 2.432637063239229

Epoch: 489| Step: 0
Training loss: 0.5264800451451317
Validation loss: 2.4326740405344935

Epoch: 5| Step: 1
Training loss: 0.3095212831389722
Validation loss: 2.4094469513844543

Epoch: 5| Step: 2
Training loss: 0.6496442802626022
Validation loss: 2.4375188788394677

Epoch: 5| Step: 3
Training loss: 0.7842280276780166
Validation loss: 2.374153982835572

Epoch: 5| Step: 4
Training loss: 0.8125864863215363
Validation loss: 2.45177545231918

Epoch: 5| Step: 5
Training loss: 0.4916151745820905
Validation loss: 2.4159032940597585

Epoch: 5| Step: 6
Training loss: 0.38818985076276047
Validation loss: 2.4261546165405674

Epoch: 5| Step: 7
Training loss: 0.441745391463294
Validation loss: 2.4216421713375436

Epoch: 5| Step: 8
Training loss: 0.6807418844430627
Validation loss: 2.454412009199789

Epoch: 5| Step: 9
Training loss: 0.4316947005563202
Validation loss: 2.450084517232658

Epoch: 5| Step: 10
Training loss: 0.5953759717771171
Validation loss: 2.422032883890064

Epoch: 490| Step: 0
Training loss: 0.6839114513552397
Validation loss: 2.417860160391959

Epoch: 5| Step: 1
Training loss: 0.29977440448119974
Validation loss: 2.4147396872146882

Epoch: 5| Step: 2
Training loss: 0.5760047282216929
Validation loss: 2.438255203584821

Epoch: 5| Step: 3
Training loss: 0.8985659300189499
Validation loss: 2.426222893786009

Epoch: 5| Step: 4
Training loss: 0.5637815235315525
Validation loss: 2.4358676675092936

Epoch: 5| Step: 5
Training loss: 0.47551248911472044
Validation loss: 2.454578832850526

Epoch: 5| Step: 6
Training loss: 0.5718765759055515
Validation loss: 2.4470805887047824

Epoch: 5| Step: 7
Training loss: 0.4543428497798803
Validation loss: 2.465064770084455

Epoch: 5| Step: 8
Training loss: 0.4153350313330782
Validation loss: 2.4100711645478845

Epoch: 5| Step: 9
Training loss: 0.7516355958791565
Validation loss: 2.439376022870303

Epoch: 5| Step: 10
Training loss: 0.227404280269889
Validation loss: 2.4385507515421017

Epoch: 491| Step: 0
Training loss: 0.5985853167014243
Validation loss: 2.472294721761291

Epoch: 5| Step: 1
Training loss: 0.4847372146630001
Validation loss: 2.4274422002953386

Epoch: 5| Step: 2
Training loss: 0.3589113395705373
Validation loss: 2.4232312329899983

Epoch: 5| Step: 3
Training loss: 0.645333224649591
Validation loss: 2.445603049208296

Epoch: 5| Step: 4
Training loss: 0.568364828286768
Validation loss: 2.407408526092275

Epoch: 5| Step: 5
Training loss: 0.4533004914190413
Validation loss: 2.4054016074069526

Epoch: 5| Step: 6
Training loss: 0.739163875280684
Validation loss: 2.4349274923729576

Epoch: 5| Step: 7
Training loss: 0.7626464671808972
Validation loss: 2.4312881701240756

Epoch: 5| Step: 8
Training loss: 0.3870471369255171
Validation loss: 2.419910431443946

Epoch: 5| Step: 9
Training loss: 0.5220254955185812
Validation loss: 2.4227971052588777

Epoch: 5| Step: 10
Training loss: 0.4829059596790608
Validation loss: 2.513501816697464

Epoch: 492| Step: 0
Training loss: 0.5399784102362526
Validation loss: 2.4090079845394783

Epoch: 5| Step: 1
Training loss: 0.2196832910951196
Validation loss: 2.4268371250828373

Epoch: 5| Step: 2
Training loss: 0.4403032683899896
Validation loss: 2.453973403319322

Epoch: 5| Step: 3
Training loss: 0.5607544783703791
Validation loss: 2.390821982433104

Epoch: 5| Step: 4
Training loss: 0.6839003175230219
Validation loss: 2.4124048923603336

Epoch: 5| Step: 5
Training loss: 0.6615539516712968
Validation loss: 2.387658287143938

Epoch: 5| Step: 6
Training loss: 0.6109890713596212
Validation loss: 2.430115964449314

Epoch: 5| Step: 7
Training loss: 0.6807581482146403
Validation loss: 2.4271944849647977

Epoch: 5| Step: 8
Training loss: 0.4584821835033798
Validation loss: 2.396866870179725

Epoch: 5| Step: 9
Training loss: 0.7651700595001377
Validation loss: 2.4495001114463237

Epoch: 5| Step: 10
Training loss: 0.285315208025278
Validation loss: 2.43796254521411

Epoch: 493| Step: 0
Training loss: 0.7191726437081224
Validation loss: 2.4472126818804827

Epoch: 5| Step: 1
Training loss: 0.6380616752371818
Validation loss: 2.4431576054050184

Epoch: 5| Step: 2
Training loss: 0.2002242927974834
Validation loss: 2.405715814902351

Epoch: 5| Step: 3
Training loss: 0.2560193238909325
Validation loss: 2.404810028855359

Epoch: 5| Step: 4
Training loss: 0.6299340515587342
Validation loss: 2.4164100990975443

Epoch: 5| Step: 5
Training loss: 0.6345623218976096
Validation loss: 2.4105235966112093

Epoch: 5| Step: 6
Training loss: 0.6759679679687965
Validation loss: 2.3820498936136767

Epoch: 5| Step: 7
Training loss: 0.3803846089969927
Validation loss: 2.4278994181168247

Epoch: 5| Step: 8
Training loss: 0.32922874732424207
Validation loss: 2.4233721003599817

Epoch: 5| Step: 9
Training loss: 0.8298361751014588
Validation loss: 2.4379869168772994

Epoch: 5| Step: 10
Training loss: 0.5237927725722625
Validation loss: 2.4193442653951363

Epoch: 494| Step: 0
Training loss: 0.522986887083636
Validation loss: 2.4574224085462495

Epoch: 5| Step: 1
Training loss: 0.44657496470306157
Validation loss: 2.4298436993341386

Epoch: 5| Step: 2
Training loss: 0.44167984441975566
Validation loss: 2.397469819212875

Epoch: 5| Step: 3
Training loss: 0.884632024720144
Validation loss: 2.3883516109372773

Epoch: 5| Step: 4
Training loss: 0.4338993164266796
Validation loss: 2.4283233200922965

Epoch: 5| Step: 5
Training loss: 0.35618514926320105
Validation loss: 2.431053822820501

Epoch: 5| Step: 6
Training loss: 0.6897878293693294
Validation loss: 2.4251089003323933

Epoch: 5| Step: 7
Training loss: 0.528947947448879
Validation loss: 2.438348691282121

Epoch: 5| Step: 8
Training loss: 0.47245070031229536
Validation loss: 2.4328308126276563

Epoch: 5| Step: 9
Training loss: 0.6265754869594401
Validation loss: 2.4456701100084914

Epoch: 5| Step: 10
Training loss: 0.5476515025587461
Validation loss: 2.4609151052356775

Epoch: 495| Step: 0
Training loss: 0.4579872012838378
Validation loss: 2.443781119792254

Epoch: 5| Step: 1
Training loss: 0.5426012071350709
Validation loss: 2.44076569060179

Epoch: 5| Step: 2
Training loss: 0.4760573477078742
Validation loss: 2.425905523263778

Epoch: 5| Step: 3
Training loss: 0.5811587713287086
Validation loss: 2.4150004946205996

Epoch: 5| Step: 4
Training loss: 0.38814871769307163
Validation loss: 2.398233342277356

Epoch: 5| Step: 5
Training loss: 0.4387507951082595
Validation loss: 2.3957234165253816

Epoch: 5| Step: 6
Training loss: 0.7606708067091207
Validation loss: 2.38177675154998

Epoch: 5| Step: 7
Training loss: 0.4233326630824833
Validation loss: 2.435482509113918

Epoch: 5| Step: 8
Training loss: 0.5091843780781476
Validation loss: 2.3919385710952663

Epoch: 5| Step: 9
Training loss: 0.871287029360614
Validation loss: 2.4155368165177933

Epoch: 5| Step: 10
Training loss: 0.3998977046040723
Validation loss: 2.396590225555505

Epoch: 496| Step: 0
Training loss: 0.3062834025676038
Validation loss: 2.401825930491714

Epoch: 5| Step: 1
Training loss: 0.8682473038714743
Validation loss: 2.4155626344106156

Epoch: 5| Step: 2
Training loss: 0.2764662305661705
Validation loss: 2.4752014712073356

Epoch: 5| Step: 3
Training loss: 0.5146862790638119
Validation loss: 2.449195743560091

Epoch: 5| Step: 4
Training loss: 0.5464185717368513
Validation loss: 2.4004820609148294

Epoch: 5| Step: 5
Training loss: 0.7386107340280865
Validation loss: 2.4325943786771895

Epoch: 5| Step: 6
Training loss: 0.5074391386341823
Validation loss: 2.435271854702936

Epoch: 5| Step: 7
Training loss: 0.4738867482072665
Validation loss: 2.386157893864123

Epoch: 5| Step: 8
Training loss: 0.5974804488778099
Validation loss: 2.4408710823473996

Epoch: 5| Step: 9
Training loss: 0.33429142852361693
Validation loss: 2.4274962967022664

Epoch: 5| Step: 10
Training loss: 0.42233994259601726
Validation loss: 2.4453846742809344

Epoch: 497| Step: 0
Training loss: 0.4744412316638023
Validation loss: 2.4379087735883536

Epoch: 5| Step: 1
Training loss: 0.5060233067772675
Validation loss: 2.4358643449072024

Epoch: 5| Step: 2
Training loss: 0.38623777978201096
Validation loss: 2.4787558407979176

Epoch: 5| Step: 3
Training loss: 0.4800324668930937
Validation loss: 2.4786942137726062

Epoch: 5| Step: 4
Training loss: 0.790859856986457
Validation loss: 2.4636121594667553

Epoch: 5| Step: 5
Training loss: 0.42421230360440737
Validation loss: 2.4451806058634022

Epoch: 5| Step: 6
Training loss: 0.6368810060796277
Validation loss: 2.4522964071489577

Epoch: 5| Step: 7
Training loss: 0.4165067326046212
Validation loss: 2.413631313752884

Epoch: 5| Step: 8
Training loss: 0.6515921871822804
Validation loss: 2.42356513912843

Epoch: 5| Step: 9
Training loss: 0.4883908110725421
Validation loss: 2.376830540837535

Epoch: 5| Step: 10
Training loss: 0.6297213325214687
Validation loss: 2.3998214482215743

Epoch: 498| Step: 0
Training loss: 0.6172207932003123
Validation loss: 2.395286998189331

Epoch: 5| Step: 1
Training loss: 0.5246170759168409
Validation loss: 2.3836933183016304

Epoch: 5| Step: 2
Training loss: 0.284339912052416
Validation loss: 2.408248239462948

Epoch: 5| Step: 3
Training loss: 0.5462368102412624
Validation loss: 2.421055527370641

Epoch: 5| Step: 4
Training loss: 0.5221041307723953
Validation loss: 2.4386736545041567

Epoch: 5| Step: 5
Training loss: 0.5290331306575066
Validation loss: 2.429178417304525

Epoch: 5| Step: 6
Training loss: 0.6464885008527592
Validation loss: 2.4321350277693883

Epoch: 5| Step: 7
Training loss: 0.5597317980217213
Validation loss: 2.459565054486939

Epoch: 5| Step: 8
Training loss: 0.4751708238016868
Validation loss: 2.446196168563606

Epoch: 5| Step: 9
Training loss: 0.6725916699678317
Validation loss: 2.4501752046140512

Epoch: 5| Step: 10
Training loss: 0.45549601085603564
Validation loss: 2.437887868214492

Epoch: 499| Step: 0
Training loss: 0.5106283611714597
Validation loss: 2.4184901103667773

Epoch: 5| Step: 1
Training loss: 0.6879228245370795
Validation loss: 2.397967270921694

Epoch: 5| Step: 2
Training loss: 0.3767930516146483
Validation loss: 2.410449584569682

Epoch: 5| Step: 3
Training loss: 0.5013061985656135
Validation loss: 2.407052032288006

Epoch: 5| Step: 4
Training loss: 0.5766877790355079
Validation loss: 2.389300985683558

Epoch: 5| Step: 5
Training loss: 0.6720834009636003
Validation loss: 2.418743123455468

Epoch: 5| Step: 6
Training loss: 0.5732653481582788
Validation loss: 2.4161251951606375

Epoch: 5| Step: 7
Training loss: 0.697093782166104
Validation loss: 2.4171293478412443

Epoch: 5| Step: 8
Training loss: 0.3618435868775912
Validation loss: 2.3744035839817506

Epoch: 5| Step: 9
Training loss: 0.5011679895239979
Validation loss: 2.358915780175284

Epoch: 5| Step: 10
Training loss: 0.46497995320556457
Validation loss: 2.340856059195713

Epoch: 500| Step: 0
Training loss: 0.37701711951476596
Validation loss: 2.3677607547191726

Epoch: 5| Step: 1
Training loss: 0.6318231313076844
Validation loss: 2.3440286165845516

Epoch: 5| Step: 2
Training loss: 0.5129096464187473
Validation loss: 2.4068463250733325

Epoch: 5| Step: 3
Training loss: 0.44752544868821376
Validation loss: 2.3962030943121166

Epoch: 5| Step: 4
Training loss: 0.3006924956522619
Validation loss: 2.3977213357479363

Epoch: 5| Step: 5
Training loss: 0.5989758005221327
Validation loss: 2.39209847158301

Epoch: 5| Step: 6
Training loss: 0.5781808001421089
Validation loss: 2.4406419418545457

Epoch: 5| Step: 7
Training loss: 0.7230086008882004
Validation loss: 2.4231083550792785

Epoch: 5| Step: 8
Training loss: 0.5117030832935423
Validation loss: 2.408272527544561

Epoch: 5| Step: 9
Training loss: 0.529544336107184
Validation loss: 2.349223788448917

Epoch: 5| Step: 10
Training loss: 0.6665158672447238
Validation loss: 2.3455749778904407

Epoch: 501| Step: 0
Training loss: 0.5342640644501747
Validation loss: 2.3537616753447774

Epoch: 5| Step: 1
Training loss: 0.6959447879007125
Validation loss: 2.3459773024198594

Epoch: 5| Step: 2
Training loss: 0.47465342250551673
Validation loss: 2.366104786455871

Epoch: 5| Step: 3
Training loss: 0.7602930665266614
Validation loss: 2.3806098212890996

Epoch: 5| Step: 4
Training loss: 0.3689249811583368
Validation loss: 2.3856460354259847

Epoch: 5| Step: 5
Training loss: 0.6927275451825962
Validation loss: 2.383684026579298

Epoch: 5| Step: 6
Training loss: 0.36557344007891646
Validation loss: 2.408528770723064

Epoch: 5| Step: 7
Training loss: 0.6556505689917121
Validation loss: 2.4079926222492394

Epoch: 5| Step: 8
Training loss: 0.33224797748885826
Validation loss: 2.4181826758258245

Epoch: 5| Step: 9
Training loss: 0.521449827271401
Validation loss: 2.4260764366212766

Epoch: 5| Step: 10
Training loss: 0.37676303399137606
Validation loss: 2.409115151344027

Epoch: 502| Step: 0
Training loss: 0.6671700415013297
Validation loss: 2.4179167104673436

Epoch: 5| Step: 1
Training loss: 0.4779119927139789
Validation loss: 2.44517062987621

Epoch: 5| Step: 2
Training loss: 0.5891571343292429
Validation loss: 2.440761323272578

Epoch: 5| Step: 3
Training loss: 0.6785089205870193
Validation loss: 2.45202247220066

Epoch: 5| Step: 4
Training loss: 0.27154322199112396
Validation loss: 2.4276726817118957

Epoch: 5| Step: 5
Training loss: 0.29696475730057664
Validation loss: 2.438974806229115

Epoch: 5| Step: 6
Training loss: 0.47960785754470636
Validation loss: 2.4299290598985817

Epoch: 5| Step: 7
Training loss: 0.4856525922912076
Validation loss: 2.42705291731805

Epoch: 5| Step: 8
Training loss: 0.40847477247391867
Validation loss: 2.396175689276812

Epoch: 5| Step: 9
Training loss: 0.5967281090900675
Validation loss: 2.385548787627782

Epoch: 5| Step: 10
Training loss: 0.6847895163825426
Validation loss: 2.3811876803400573

Epoch: 503| Step: 0
Training loss: 0.5690749864292433
Validation loss: 2.4190552671290644

Epoch: 5| Step: 1
Training loss: 0.30429645043711984
Validation loss: 2.3646050411035833

Epoch: 5| Step: 2
Training loss: 0.45019695091363165
Validation loss: 2.3779361399062537

Epoch: 5| Step: 3
Training loss: 0.7415473988535048
Validation loss: 2.3670290987337093

Epoch: 5| Step: 4
Training loss: 0.6240772349490533
Validation loss: 2.4028132709078274

Epoch: 5| Step: 5
Training loss: 0.4852019142615113
Validation loss: 2.4504524137625414

Epoch: 5| Step: 6
Training loss: 0.49927014487802923
Validation loss: 2.3951712536624457

Epoch: 5| Step: 7
Training loss: 0.6707829316280531
Validation loss: 2.4303708824243353

Epoch: 5| Step: 8
Training loss: 0.2581610635267819
Validation loss: 2.479659423363153

Epoch: 5| Step: 9
Training loss: 0.4125407885123527
Validation loss: 2.4375300167603013

Epoch: 5| Step: 10
Training loss: 0.3813681505388992
Validation loss: 2.4448908856787854

Epoch: 504| Step: 0
Training loss: 0.6424074960978502
Validation loss: 2.4170374142138202

Epoch: 5| Step: 1
Training loss: 0.441490722270398
Validation loss: 2.4186510744220535

Epoch: 5| Step: 2
Training loss: 0.6505401027157898
Validation loss: 2.3745351702430537

Epoch: 5| Step: 3
Training loss: 0.2548957616797875
Validation loss: 2.36363992785384

Epoch: 5| Step: 4
Training loss: 0.6721435719797965
Validation loss: 2.3300860588031425

Epoch: 5| Step: 5
Training loss: 0.42429749476317824
Validation loss: 2.3428844010194214

Epoch: 5| Step: 6
Training loss: 0.48539029126145844
Validation loss: 2.311870116399458

Epoch: 5| Step: 7
Training loss: 0.4403152147890305
Validation loss: 2.3766261558472626

Epoch: 5| Step: 8
Training loss: 0.42292422051409495
Validation loss: 2.368406315768894

Epoch: 5| Step: 9
Training loss: 0.5076875092664787
Validation loss: 2.3628441028239293

Epoch: 5| Step: 10
Training loss: 0.5947891478031445
Validation loss: 2.399031051223182

Epoch: 505| Step: 0
Training loss: 0.6320627504097605
Validation loss: 2.410533920180079

Epoch: 5| Step: 1
Training loss: 0.472903321059664
Validation loss: 2.46592123332947

Epoch: 5| Step: 2
Training loss: 0.2755912428790628
Validation loss: 2.44097263874511

Epoch: 5| Step: 3
Training loss: 0.49770759545206733
Validation loss: 2.4359118628430667

Epoch: 5| Step: 4
Training loss: 0.40263778164556985
Validation loss: 2.4269032688587147

Epoch: 5| Step: 5
Training loss: 0.3903103705745911
Validation loss: 2.455453123643958

Epoch: 5| Step: 6
Training loss: 0.4644407721465676
Validation loss: 2.438084013091051

Epoch: 5| Step: 7
Training loss: 0.7452850752609214
Validation loss: 2.4429904239524904

Epoch: 5| Step: 8
Training loss: 0.5667704496526679
Validation loss: 2.4375018668555426

Epoch: 5| Step: 9
Training loss: 0.44925192005594167
Validation loss: 2.415731116010756

Epoch: 5| Step: 10
Training loss: 0.554893186875722
Validation loss: 2.3901385040780987

Epoch: 506| Step: 0
Training loss: 0.7247259246785532
Validation loss: 2.3680876098781867

Epoch: 5| Step: 1
Training loss: 0.4961408007079067
Validation loss: 2.3715684502770795

Epoch: 5| Step: 2
Training loss: 0.32135151774934023
Validation loss: 2.4020304584552763

Epoch: 5| Step: 3
Training loss: 0.5380915591297625
Validation loss: 2.4085596647664023

Epoch: 5| Step: 4
Training loss: 0.53224308093274
Validation loss: 2.3992615500292365

Epoch: 5| Step: 5
Training loss: 0.4658310287170634
Validation loss: 2.3908036345077632

Epoch: 5| Step: 6
Training loss: 0.4081557944569573
Validation loss: 2.3884260860973683

Epoch: 5| Step: 7
Training loss: 0.6056570683148967
Validation loss: 2.3938702652300385

Epoch: 5| Step: 8
Training loss: 0.4416318839999954
Validation loss: 2.384684605692889

Epoch: 5| Step: 9
Training loss: 0.2694103826885734
Validation loss: 2.390846849110514

Epoch: 5| Step: 10
Training loss: 0.6355395719346579
Validation loss: 2.3669450060953405

Epoch: 507| Step: 0
Training loss: 0.5266248252953476
Validation loss: 2.3671559696161397

Epoch: 5| Step: 1
Training loss: 0.5862819930499343
Validation loss: 2.3749909155196414

Epoch: 5| Step: 2
Training loss: 0.4520348391767854
Validation loss: 2.4131403164298986

Epoch: 5| Step: 3
Training loss: 0.5286111084255437
Validation loss: 2.402884639126388

Epoch: 5| Step: 4
Training loss: 0.5221550161689684
Validation loss: 2.4431013519266482

Epoch: 5| Step: 5
Training loss: 0.5379579256793026
Validation loss: 2.4267664486007248

Epoch: 5| Step: 6
Training loss: 0.5148009738314917
Validation loss: 2.4542787617334887

Epoch: 5| Step: 7
Training loss: 0.22994677383870407
Validation loss: 2.4250414385023285

Epoch: 5| Step: 8
Training loss: 0.426690539332319
Validation loss: 2.417849545773646

Epoch: 5| Step: 9
Training loss: 0.6350282331257694
Validation loss: 2.4039121707405022

Epoch: 5| Step: 10
Training loss: 0.37566830767834714
Validation loss: 2.4167946840635715

Epoch: 508| Step: 0
Training loss: 0.5446583920972438
Validation loss: 2.4186688878166014

Epoch: 5| Step: 1
Training loss: 0.6404061757826991
Validation loss: 2.438174368223221

Epoch: 5| Step: 2
Training loss: 0.43684861533260005
Validation loss: 2.415832465369459

Epoch: 5| Step: 3
Training loss: 0.48467254728744535
Validation loss: 2.4382452539368944

Epoch: 5| Step: 4
Training loss: 0.40793699505463354
Validation loss: 2.454217880384321

Epoch: 5| Step: 5
Training loss: 0.4264118005231256
Validation loss: 2.4172050299327887

Epoch: 5| Step: 6
Training loss: 0.4636874683975022
Validation loss: 2.424968239572345

Epoch: 5| Step: 7
Training loss: 0.5001086474631543
Validation loss: 2.4143428685477684

Epoch: 5| Step: 8
Training loss: 0.39206092129229403
Validation loss: 2.429805979975507

Epoch: 5| Step: 9
Training loss: 0.5292972691383161
Validation loss: 2.3899483476119245

Epoch: 5| Step: 10
Training loss: 0.4957630827635171
Validation loss: 2.43915282901744

Epoch: 509| Step: 0
Training loss: 0.47108804626554635
Validation loss: 2.407161549043416

Epoch: 5| Step: 1
Training loss: 0.4338484351186742
Validation loss: 2.4193576820247444

Epoch: 5| Step: 2
Training loss: 0.5027767208022687
Validation loss: 2.412826982812267

Epoch: 5| Step: 3
Training loss: 0.467328650544051
Validation loss: 2.4224332400941506

Epoch: 5| Step: 4
Training loss: 0.5264750071205991
Validation loss: 2.4012100138998553

Epoch: 5| Step: 5
Training loss: 0.5068228247679054
Validation loss: 2.3754155519208813

Epoch: 5| Step: 6
Training loss: 0.6513225991974534
Validation loss: 2.368342606165801

Epoch: 5| Step: 7
Training loss: 0.4401370004297967
Validation loss: 2.3455896228090096

Epoch: 5| Step: 8
Training loss: 0.4999933540379387
Validation loss: 2.366012156369076

Epoch: 5| Step: 9
Training loss: 0.33127973441058045
Validation loss: 2.3439337419794515

Epoch: 5| Step: 10
Training loss: 0.5051853004265155
Validation loss: 2.4014498452411264

Epoch: 510| Step: 0
Training loss: 0.5428977755258055
Validation loss: 2.4204512529936943

Epoch: 5| Step: 1
Training loss: 0.48026683875751924
Validation loss: 2.438560329888561

Epoch: 5| Step: 2
Training loss: 0.5028149520216781
Validation loss: 2.451140478939994

Epoch: 5| Step: 3
Training loss: 0.552566610696615
Validation loss: 2.4003605950474927

Epoch: 5| Step: 4
Training loss: 0.36733044216076327
Validation loss: 2.404306241137649

Epoch: 5| Step: 5
Training loss: 0.19056608743690784
Validation loss: 2.420244396925692

Epoch: 5| Step: 6
Training loss: 0.6474494760456833
Validation loss: 2.3945942467798402

Epoch: 5| Step: 7
Training loss: 0.4232231252027682
Validation loss: 2.362543162046938

Epoch: 5| Step: 8
Training loss: 0.5831394270638299
Validation loss: 2.3811937449478284

Epoch: 5| Step: 9
Training loss: 0.4908897608827032
Validation loss: 2.3584276527757897

Epoch: 5| Step: 10
Training loss: 0.4374804151783564
Validation loss: 2.38531905198114

Epoch: 511| Step: 0
Training loss: 0.5304292621999926
Validation loss: 2.426319104629712

Epoch: 5| Step: 1
Training loss: 0.47763094963874636
Validation loss: 2.4598793089485196

Epoch: 5| Step: 2
Training loss: 0.5564967454710577
Validation loss: 2.4251927795508714

Epoch: 5| Step: 3
Training loss: 0.2736296115118943
Validation loss: 2.4065972461044587

Epoch: 5| Step: 4
Training loss: 0.46183537464225316
Validation loss: 2.4068314385589953

Epoch: 5| Step: 5
Training loss: 0.6024835891783803
Validation loss: 2.398377252920126

Epoch: 5| Step: 6
Training loss: 0.5994010339677743
Validation loss: 2.4080343908326713

Epoch: 5| Step: 7
Training loss: 0.3991751107628148
Validation loss: 2.411087647278782

Epoch: 5| Step: 8
Training loss: 0.27000803862632033
Validation loss: 2.386648318409862

Epoch: 5| Step: 9
Training loss: 0.4663671806240233
Validation loss: 2.389382860767878

Epoch: 5| Step: 10
Training loss: 0.45020971047636377
Validation loss: 2.345902513446272

Epoch: 512| Step: 0
Training loss: 0.36995059166757965
Validation loss: 2.383558870072722

Epoch: 5| Step: 1
Training loss: 0.665145484598836
Validation loss: 2.3887397785238207

Epoch: 5| Step: 2
Training loss: 0.5884856447771776
Validation loss: 2.3435388668220285

Epoch: 5| Step: 3
Training loss: 0.3029299565700809
Validation loss: 2.407604111925785

Epoch: 5| Step: 4
Training loss: 0.3052814026206536
Validation loss: 2.4494612907450994

Epoch: 5| Step: 5
Training loss: 0.33474576617420243
Validation loss: 2.4200815060109853

Epoch: 5| Step: 6
Training loss: 0.4777982823444005
Validation loss: 2.4675451588699095

Epoch: 5| Step: 7
Training loss: 0.5608452989464716
Validation loss: 2.411828089383281

Epoch: 5| Step: 8
Training loss: 0.42860642464838333
Validation loss: 2.4164694552493633

Epoch: 5| Step: 9
Training loss: 0.4565595164844492
Validation loss: 2.3928624223767665

Epoch: 5| Step: 10
Training loss: 0.694422591713292
Validation loss: 2.340218903108633

Epoch: 513| Step: 0
Training loss: 0.5998607940915389
Validation loss: 2.3342662741097207

Epoch: 5| Step: 1
Training loss: 0.7006553936643384
Validation loss: 2.3331951687891417

Epoch: 5| Step: 2
Training loss: 0.5247443666705514
Validation loss: 2.384148918878607

Epoch: 5| Step: 3
Training loss: 0.42700502406521496
Validation loss: 2.4163492529666386

Epoch: 5| Step: 4
Training loss: 0.4620585951390507
Validation loss: 2.373269982186638

Epoch: 5| Step: 5
Training loss: 0.47583890919444255
Validation loss: 2.3685574932481215

Epoch: 5| Step: 6
Training loss: 0.4493331100187869
Validation loss: 2.37112531019121

Epoch: 5| Step: 7
Training loss: 0.4416877895228505
Validation loss: 2.396960012735848

Epoch: 5| Step: 8
Training loss: 0.32707272692611206
Validation loss: 2.3913658152956123

Epoch: 5| Step: 9
Training loss: 0.35924158522347993
Validation loss: 2.36905573943995

Epoch: 5| Step: 10
Training loss: 0.5117248942464948
Validation loss: 2.354764378061849

Epoch: 514| Step: 0
Training loss: 0.3342728289366999
Validation loss: 2.3904556191889306

Epoch: 5| Step: 1
Training loss: 0.2826750600491044
Validation loss: 2.3977691124177203

Epoch: 5| Step: 2
Training loss: 0.5523481063994713
Validation loss: 2.4230903807067317

Epoch: 5| Step: 3
Training loss: 0.594247133037053
Validation loss: 2.3913927523016674

Epoch: 5| Step: 4
Training loss: 0.4058328834677415
Validation loss: 2.457081136032893

Epoch: 5| Step: 5
Training loss: 0.35404612322353374
Validation loss: 2.4333176408240065

Epoch: 5| Step: 6
Training loss: 0.5221881475164941
Validation loss: 2.426906775384521

Epoch: 5| Step: 7
Training loss: 0.4098666485676971
Validation loss: 2.4188438116460516

Epoch: 5| Step: 8
Training loss: 0.5475503838231324
Validation loss: 2.4188556523953135

Epoch: 5| Step: 9
Training loss: 0.6835194574585022
Validation loss: 2.436974275497981

Epoch: 5| Step: 10
Training loss: 0.23488843628485273
Validation loss: 2.428813901647936

Epoch: 515| Step: 0
Training loss: 0.4728597407872629
Validation loss: 2.3560937253595626

Epoch: 5| Step: 1
Training loss: 0.4423806230436127
Validation loss: 2.3988508957343346

Epoch: 5| Step: 2
Training loss: 0.5533086805807513
Validation loss: 2.401553712374915

Epoch: 5| Step: 3
Training loss: 0.5160077726126197
Validation loss: 2.370116893290794

Epoch: 5| Step: 4
Training loss: 0.5429665270423667
Validation loss: 2.3666993991050473

Epoch: 5| Step: 5
Training loss: 0.5125669482163365
Validation loss: 2.419345934861729

Epoch: 5| Step: 6
Training loss: 0.36345178436652603
Validation loss: 2.4272617042341804

Epoch: 5| Step: 7
Training loss: 0.6796275583780002
Validation loss: 2.4175920143427208

Epoch: 5| Step: 8
Training loss: 0.2472981469219324
Validation loss: 2.4507436120236443

Epoch: 5| Step: 9
Training loss: 0.3270300579823925
Validation loss: 2.491844802518289

Epoch: 5| Step: 10
Training loss: 0.41417949750982797
Validation loss: 2.4494132998803058

Epoch: 516| Step: 0
Training loss: 0.5788254489700382
Validation loss: 2.46651996866708

Epoch: 5| Step: 1
Training loss: 0.47782285717753287
Validation loss: 2.3938587656765065

Epoch: 5| Step: 2
Training loss: 0.4181961795565789
Validation loss: 2.3827149385826996

Epoch: 5| Step: 3
Training loss: 0.43264303711415736
Validation loss: 2.3605387022987263

Epoch: 5| Step: 4
Training loss: 0.37601548030619847
Validation loss: 2.4156844809731255

Epoch: 5| Step: 5
Training loss: 0.5019953669129062
Validation loss: 2.395683621672975

Epoch: 5| Step: 6
Training loss: 0.38597426374523214
Validation loss: 2.378520244627268

Epoch: 5| Step: 7
Training loss: 0.35868204729316333
Validation loss: 2.4214446342715785

Epoch: 5| Step: 8
Training loss: 0.5401583879476516
Validation loss: 2.414224855659723

Epoch: 5| Step: 9
Training loss: 0.509956820941441
Validation loss: 2.4315724687792764

Epoch: 5| Step: 10
Training loss: 0.4969626349414936
Validation loss: 2.4121341258497897

Epoch: 517| Step: 0
Training loss: 0.29049536264529585
Validation loss: 2.4249479129865037

Epoch: 5| Step: 1
Training loss: 0.5676325184539001
Validation loss: 2.4294472947495436

Epoch: 5| Step: 2
Training loss: 0.44443281186629546
Validation loss: 2.427965830711404

Epoch: 5| Step: 3
Training loss: 0.25921819842040167
Validation loss: 2.409421200428543

Epoch: 5| Step: 4
Training loss: 0.4120245389713689
Validation loss: 2.443666000985014

Epoch: 5| Step: 5
Training loss: 0.4452809439738449
Validation loss: 2.4193377533517886

Epoch: 5| Step: 6
Training loss: 0.283428313075932
Validation loss: 2.443468697896436

Epoch: 5| Step: 7
Training loss: 0.4870136898131687
Validation loss: 2.451702134005426

Epoch: 5| Step: 8
Training loss: 0.5478582534789439
Validation loss: 2.436366127514581

Epoch: 5| Step: 9
Training loss: 0.7062888278246631
Validation loss: 2.4938293350655596

Epoch: 5| Step: 10
Training loss: 0.4476068186472393
Validation loss: 2.4529470568995393

Epoch: 518| Step: 0
Training loss: 0.32569816591070255
Validation loss: 2.4706652289045934

Epoch: 5| Step: 1
Training loss: 0.39989401560624727
Validation loss: 2.427725281933196

Epoch: 5| Step: 2
Training loss: 0.4862358587900591
Validation loss: 2.4187918290959187

Epoch: 5| Step: 3
Training loss: 0.3756941688502898
Validation loss: 2.423321549491783

Epoch: 5| Step: 4
Training loss: 0.6321590959142719
Validation loss: 2.387144764717403

Epoch: 5| Step: 5
Training loss: 0.46177356672119796
Validation loss: 2.3984274161697576

Epoch: 5| Step: 6
Training loss: 0.31021916594505766
Validation loss: 2.4171760589409237

Epoch: 5| Step: 7
Training loss: 0.6026381004712046
Validation loss: 2.4213103918061445

Epoch: 5| Step: 8
Training loss: 0.45778551380182925
Validation loss: 2.3819403402640194

Epoch: 5| Step: 9
Training loss: 0.5198550255128485
Validation loss: 2.4358976433426607

Epoch: 5| Step: 10
Training loss: 0.33504789686125
Validation loss: 2.433448418592702

Epoch: 519| Step: 0
Training loss: 0.38352769100303685
Validation loss: 2.4726844081880124

Epoch: 5| Step: 1
Training loss: 0.516305012669779
Validation loss: 2.441241418536847

Epoch: 5| Step: 2
Training loss: 0.47712266550250015
Validation loss: 2.4601234966219363

Epoch: 5| Step: 3
Training loss: 0.49279001988992976
Validation loss: 2.4382903303643806

Epoch: 5| Step: 4
Training loss: 0.5719614620197738
Validation loss: 2.431541946200507

Epoch: 5| Step: 5
Training loss: 0.39304765929066326
Validation loss: 2.451342202219521

Epoch: 5| Step: 6
Training loss: 0.5637968267206024
Validation loss: 2.4241879366937185

Epoch: 5| Step: 7
Training loss: 0.42874823127804373
Validation loss: 2.4325910790048955

Epoch: 5| Step: 8
Training loss: 0.38113547856410135
Validation loss: 2.4263191585161406

Epoch: 5| Step: 9
Training loss: 0.49228429599377294
Validation loss: 2.4133128534027306

Epoch: 5| Step: 10
Training loss: 0.5136107201669591
Validation loss: 2.4002364165241845

Epoch: 520| Step: 0
Training loss: 0.4137120833411209
Validation loss: 2.3973038628315444

Epoch: 5| Step: 1
Training loss: 0.4162659764875268
Validation loss: 2.40796963979739

Epoch: 5| Step: 2
Training loss: 0.4517461911301096
Validation loss: 2.4125910946493074

Epoch: 5| Step: 3
Training loss: 0.5203635067610921
Validation loss: 2.3877805763272484

Epoch: 5| Step: 4
Training loss: 0.33313194042225946
Validation loss: 2.416436946829039

Epoch: 5| Step: 5
Training loss: 0.6286251553535079
Validation loss: 2.412602448066793

Epoch: 5| Step: 6
Training loss: 0.46454873861425533
Validation loss: 2.3839995903873827

Epoch: 5| Step: 7
Training loss: 0.3990503347838288
Validation loss: 2.4676860532828027

Epoch: 5| Step: 8
Training loss: 0.5405989050769056
Validation loss: 2.4334497354687463

Epoch: 5| Step: 9
Training loss: 0.3566174235322991
Validation loss: 2.4872566589330516

Epoch: 5| Step: 10
Training loss: 0.46704050513726675
Validation loss: 2.4936364225460905

Epoch: 521| Step: 0
Training loss: 0.4426965337938578
Validation loss: 2.4599597431993767

Epoch: 5| Step: 1
Training loss: 0.732154817848998
Validation loss: 2.444042319522484

Epoch: 5| Step: 2
Training loss: 0.2288977696276769
Validation loss: 2.4364253399936144

Epoch: 5| Step: 3
Training loss: 0.29000003950348946
Validation loss: 2.4213395695535334

Epoch: 5| Step: 4
Training loss: 0.3850810505652746
Validation loss: 2.4027613907333722

Epoch: 5| Step: 5
Training loss: 0.40192656508056374
Validation loss: 2.4315927009787095

Epoch: 5| Step: 6
Training loss: 0.6067628382427569
Validation loss: 2.4205945798543764

Epoch: 5| Step: 7
Training loss: 0.4289128864101486
Validation loss: 2.4143402797857076

Epoch: 5| Step: 8
Training loss: 0.3106372989506988
Validation loss: 2.4927863891316626

Epoch: 5| Step: 9
Training loss: 0.39949497438642806
Validation loss: 2.4628802492149675

Epoch: 5| Step: 10
Training loss: 0.6518329059253495
Validation loss: 2.48120516774274

Epoch: 522| Step: 0
Training loss: 0.5944856302852333
Validation loss: 2.479027237921995

Epoch: 5| Step: 1
Training loss: 0.4853806208732806
Validation loss: 2.462161462522074

Epoch: 5| Step: 2
Training loss: 0.34574810101890247
Validation loss: 2.4399610673500534

Epoch: 5| Step: 3
Training loss: 0.36056911032110983
Validation loss: 2.444079566907505

Epoch: 5| Step: 4
Training loss: 0.450766988624542
Validation loss: 2.413935199358155

Epoch: 5| Step: 5
Training loss: 0.4051229910066551
Validation loss: 2.423228744706673

Epoch: 5| Step: 6
Training loss: 0.5929932791520419
Validation loss: 2.3618129224861195

Epoch: 5| Step: 7
Training loss: 0.4004504089382435
Validation loss: 2.4121853240598656

Epoch: 5| Step: 8
Training loss: 0.5261764888660259
Validation loss: 2.4214116336313825

Epoch: 5| Step: 9
Training loss: 0.46677269334286997
Validation loss: 2.454714206302158

Epoch: 5| Step: 10
Training loss: 0.4839753840537316
Validation loss: 2.4456424720492067

Epoch: 523| Step: 0
Training loss: 0.46651443811338406
Validation loss: 2.487642706190262

Epoch: 5| Step: 1
Training loss: 0.5567553217992819
Validation loss: 2.42733277344391

Epoch: 5| Step: 2
Training loss: 0.4458142682779386
Validation loss: 2.4620206830404885

Epoch: 5| Step: 3
Training loss: 0.44425750710944695
Validation loss: 2.4683154694534895

Epoch: 5| Step: 4
Training loss: 0.44395984201280847
Validation loss: 2.416670170895671

Epoch: 5| Step: 5
Training loss: 0.3544469126643983
Validation loss: 2.439556206381017

Epoch: 5| Step: 6
Training loss: 0.4118950272815392
Validation loss: 2.3893366218641683

Epoch: 5| Step: 7
Training loss: 0.6101584411269151
Validation loss: 2.4109206079289183

Epoch: 5| Step: 8
Training loss: 0.47740839319134476
Validation loss: 2.3645847485528892

Epoch: 5| Step: 9
Training loss: 0.4694916579934411
Validation loss: 2.379288376310468

Epoch: 5| Step: 10
Training loss: 0.38741586448590215
Validation loss: 2.4313156322580456

Epoch: 524| Step: 0
Training loss: 0.6093449952001168
Validation loss: 2.4055395165484312

Epoch: 5| Step: 1
Training loss: 0.463996612161362
Validation loss: 2.4394511986850027

Epoch: 5| Step: 2
Training loss: 0.35855803717006396
Validation loss: 2.430918714715812

Epoch: 5| Step: 3
Training loss: 0.556148646261167
Validation loss: 2.419584903067

Epoch: 5| Step: 4
Training loss: 0.3690976920214096
Validation loss: 2.4159381123285955

Epoch: 5| Step: 5
Training loss: 0.3222804441801672
Validation loss: 2.379215243243956

Epoch: 5| Step: 6
Training loss: 0.45910827912235963
Validation loss: 2.4201593531232035

Epoch: 5| Step: 7
Training loss: 0.29574224548379585
Validation loss: 2.3937918405628045

Epoch: 5| Step: 8
Training loss: 0.43305093277831963
Validation loss: 2.3588432563592803

Epoch: 5| Step: 9
Training loss: 0.6172609647655324
Validation loss: 2.372685848044462

Epoch: 5| Step: 10
Training loss: 0.3344412795893909
Validation loss: 2.432569995141989

Epoch: 525| Step: 0
Training loss: 0.44899209980503235
Validation loss: 2.427410280283401

Epoch: 5| Step: 1
Training loss: 0.3332486442429594
Validation loss: 2.4235224460537825

Epoch: 5| Step: 2
Training loss: 0.6746329987613493
Validation loss: 2.446233028930836

Epoch: 5| Step: 3
Training loss: 0.34787637192650595
Validation loss: 2.4226685683642835

Epoch: 5| Step: 4
Training loss: 0.4760134614174985
Validation loss: 2.4353235612767654

Epoch: 5| Step: 5
Training loss: 0.5707224326291415
Validation loss: 2.3907241902586764

Epoch: 5| Step: 6
Training loss: 0.32051889236518744
Validation loss: 2.371978606010906

Epoch: 5| Step: 7
Training loss: 0.5176193508787851
Validation loss: 2.3583934279349372

Epoch: 5| Step: 8
Training loss: 0.3907839833026337
Validation loss: 2.377032972339442

Epoch: 5| Step: 9
Training loss: 0.4300143645903513
Validation loss: 2.3810820107103323

Epoch: 5| Step: 10
Training loss: 0.34679591420026157
Validation loss: 2.3719708728557243

Epoch: 526| Step: 0
Training loss: 0.16285684907768397
Validation loss: 2.459655476745766

Epoch: 5| Step: 1
Training loss: 0.556351864520792
Validation loss: 2.42187953899592

Epoch: 5| Step: 2
Training loss: 0.3839162756449554
Validation loss: 2.4565265983126268

Epoch: 5| Step: 3
Training loss: 0.5515489030842494
Validation loss: 2.4465680039708877

Epoch: 5| Step: 4
Training loss: 0.431540723606199
Validation loss: 2.42711794932083

Epoch: 5| Step: 5
Training loss: 0.5166908287992262
Validation loss: 2.41475356629983

Epoch: 5| Step: 6
Training loss: 0.28471931530985617
Validation loss: 2.4139944321082316

Epoch: 5| Step: 7
Training loss: 0.5395433244146763
Validation loss: 2.438821072803952

Epoch: 5| Step: 8
Training loss: 0.6453592703729394
Validation loss: 2.4585718095203197

Epoch: 5| Step: 9
Training loss: 0.405903466687009
Validation loss: 2.4429641156967707

Epoch: 5| Step: 10
Training loss: 0.23966049251066796
Validation loss: 2.445079464347821

Epoch: 527| Step: 0
Training loss: 0.3337593659147606
Validation loss: 2.43848022322413

Epoch: 5| Step: 1
Training loss: 0.40482108367399455
Validation loss: 2.451003929613898

Epoch: 5| Step: 2
Training loss: 0.2632205915897261
Validation loss: 2.468514441200736

Epoch: 5| Step: 3
Training loss: 0.2890652707972342
Validation loss: 2.446727022884724

Epoch: 5| Step: 4
Training loss: 0.3363759373474953
Validation loss: 2.4452187123968256

Epoch: 5| Step: 5
Training loss: 0.5167530320903996
Validation loss: 2.438232566315751

Epoch: 5| Step: 6
Training loss: 0.3563996377186909
Validation loss: 2.4533238964860122

Epoch: 5| Step: 7
Training loss: 0.3544456094033746
Validation loss: 2.4392361974489307

Epoch: 5| Step: 8
Training loss: 0.576987332806635
Validation loss: 2.4485864404164017

Epoch: 5| Step: 9
Training loss: 0.5951106392550543
Validation loss: 2.4306795191954103

Epoch: 5| Step: 10
Training loss: 0.6489152182701716
Validation loss: 2.4523758766943637

Epoch: 528| Step: 0
Training loss: 0.4534137233491835
Validation loss: 2.438719732714067

Epoch: 5| Step: 1
Training loss: 0.5528976145463286
Validation loss: 2.4431608320448928

Epoch: 5| Step: 2
Training loss: 0.610322509074137
Validation loss: 2.432834993977731

Epoch: 5| Step: 3
Training loss: 0.41633298347431463
Validation loss: 2.435312121668222

Epoch: 5| Step: 4
Training loss: 0.17281109395412286
Validation loss: 2.4579917850513135

Epoch: 5| Step: 5
Training loss: 0.4817892706839855
Validation loss: 2.445032901525348

Epoch: 5| Step: 6
Training loss: 0.47502079152731
Validation loss: 2.4437389750248086

Epoch: 5| Step: 7
Training loss: 0.35571067039618964
Validation loss: 2.421163577657377

Epoch: 5| Step: 8
Training loss: 0.48688435439010125
Validation loss: 2.417721657749123

Epoch: 5| Step: 9
Training loss: 0.29999486501590583
Validation loss: 2.4172551863877016

Epoch: 5| Step: 10
Training loss: 0.4602399332218878
Validation loss: 2.4106518505497387

Epoch: 529| Step: 0
Training loss: 0.29339897355818023
Validation loss: 2.4430867992616268

Epoch: 5| Step: 1
Training loss: 0.4725189797812863
Validation loss: 2.3762117154206464

Epoch: 5| Step: 2
Training loss: 0.6330976903208971
Validation loss: 2.384112776110214

Epoch: 5| Step: 3
Training loss: 0.5181274665709387
Validation loss: 2.4145162365524055

Epoch: 5| Step: 4
Training loss: 0.2399147434969658
Validation loss: 2.4374403361214196

Epoch: 5| Step: 5
Training loss: 0.5128497663087732
Validation loss: 2.4298011656389282

Epoch: 5| Step: 6
Training loss: 0.42324680243116275
Validation loss: 2.4679361572311502

Epoch: 5| Step: 7
Training loss: 0.3460914133823989
Validation loss: 2.404347109336263

Epoch: 5| Step: 8
Training loss: 0.3636257220195842
Validation loss: 2.4201652702869083

Epoch: 5| Step: 9
Training loss: 0.4494797155908067
Validation loss: 2.4119007533355217

Epoch: 5| Step: 10
Training loss: 0.44476034834381956
Validation loss: 2.399487677193264

Epoch: 530| Step: 0
Training loss: 0.31119237546363426
Validation loss: 2.456634195688396

Epoch: 5| Step: 1
Training loss: 0.3946060449689682
Validation loss: 2.374549696740565

Epoch: 5| Step: 2
Training loss: 0.3368725958474738
Validation loss: 2.4257814560820212

Epoch: 5| Step: 3
Training loss: 0.6137142232345977
Validation loss: 2.3929493753160185

Epoch: 5| Step: 4
Training loss: 0.5521264929065726
Validation loss: 2.398295826529036

Epoch: 5| Step: 5
Training loss: 0.23848821688080976
Validation loss: 2.387255802013379

Epoch: 5| Step: 6
Training loss: 0.37493740989962493
Validation loss: 2.4009773296135624

Epoch: 5| Step: 7
Training loss: 0.375611680567451
Validation loss: 2.369888436389082

Epoch: 5| Step: 8
Training loss: 0.3712216407848935
Validation loss: 2.3940389600513763

Epoch: 5| Step: 9
Training loss: 0.3579637349450533
Validation loss: 2.407187997248279

Epoch: 5| Step: 10
Training loss: 0.5707643626190054
Validation loss: 2.402493180373731

Epoch: 531| Step: 0
Training loss: 0.40950691048935994
Validation loss: 2.423189469270361

Epoch: 5| Step: 1
Training loss: 0.4575324611404175
Validation loss: 2.397259236982852

Epoch: 5| Step: 2
Training loss: 0.2545537322332925
Validation loss: 2.420994655037633

Epoch: 5| Step: 3
Training loss: 0.4718995618427714
Validation loss: 2.424187416391101

Epoch: 5| Step: 4
Training loss: 0.22448191965602654
Validation loss: 2.4287490031934063

Epoch: 5| Step: 5
Training loss: 0.498226985901368
Validation loss: 2.469235919791627

Epoch: 5| Step: 6
Training loss: 0.3613199800140369
Validation loss: 2.4585400496707526

Epoch: 5| Step: 7
Training loss: 0.3760614670835501
Validation loss: 2.475988513374061

Epoch: 5| Step: 8
Training loss: 0.5205416498404305
Validation loss: 2.4536808764360982

Epoch: 5| Step: 9
Training loss: 0.5695763631569537
Validation loss: 2.3909727772937157

Epoch: 5| Step: 10
Training loss: 0.4454591409268366
Validation loss: 2.3813992757411917

Epoch: 532| Step: 0
Training loss: 0.2969312489075813
Validation loss: 2.3819664604200956

Epoch: 5| Step: 1
Training loss: 0.506950997465563
Validation loss: 2.391297581098202

Epoch: 5| Step: 2
Training loss: 0.17542569971574307
Validation loss: 2.378370107860894

Epoch: 5| Step: 3
Training loss: 0.3054409370541212
Validation loss: 2.411105062007176

Epoch: 5| Step: 4
Training loss: 0.5992925844621989
Validation loss: 2.403862100082906

Epoch: 5| Step: 5
Training loss: 0.5342165639586574
Validation loss: 2.4349964885471995

Epoch: 5| Step: 6
Training loss: 0.5663631291253599
Validation loss: 2.426546110140067

Epoch: 5| Step: 7
Training loss: 0.34625676107174896
Validation loss: 2.4430690993726683

Epoch: 5| Step: 8
Training loss: 0.3721179881551686
Validation loss: 2.4504701602318817

Epoch: 5| Step: 9
Training loss: 0.38630395858053707
Validation loss: 2.4886556235458372

Epoch: 5| Step: 10
Training loss: 0.3184955048445997
Validation loss: 2.50052424235855

Epoch: 533| Step: 0
Training loss: 0.5717059318062594
Validation loss: 2.4506772790071776

Epoch: 5| Step: 1
Training loss: 0.30203422059454826
Validation loss: 2.5005768715397583

Epoch: 5| Step: 2
Training loss: 0.4125804288077832
Validation loss: 2.4711762989091537

Epoch: 5| Step: 3
Training loss: 0.3480603516235465
Validation loss: 2.4397027879813376

Epoch: 5| Step: 4
Training loss: 0.4858670787749513
Validation loss: 2.4104180292804984

Epoch: 5| Step: 5
Training loss: 0.3713061076450176
Validation loss: 2.385694192541575

Epoch: 5| Step: 6
Training loss: 0.2870253355593282
Validation loss: 2.418994886016598

Epoch: 5| Step: 7
Training loss: 0.3600974492130759
Validation loss: 2.401855805501555

Epoch: 5| Step: 8
Training loss: 0.6482235429133556
Validation loss: 2.380277901423091

Epoch: 5| Step: 9
Training loss: 0.37010794756384546
Validation loss: 2.414343217361476

Epoch: 5| Step: 10
Training loss: 0.3518085042889568
Validation loss: 2.3682379806648512

Epoch: 534| Step: 0
Training loss: 0.46485721344243475
Validation loss: 2.431615535011796

Epoch: 5| Step: 1
Training loss: 0.6296365892450532
Validation loss: 2.463145378030516

Epoch: 5| Step: 2
Training loss: 0.43551284930831957
Validation loss: 2.4332738250702097

Epoch: 5| Step: 3
Training loss: 0.3659407776279405
Validation loss: 2.47864284308644

Epoch: 5| Step: 4
Training loss: 0.4458413748001078
Validation loss: 2.4881043292284577

Epoch: 5| Step: 5
Training loss: 0.49316510493102234
Validation loss: 2.4870691017847038

Epoch: 5| Step: 6
Training loss: 0.48663415433875074
Validation loss: 2.464756386989498

Epoch: 5| Step: 7
Training loss: 0.1824476914037355
Validation loss: 2.407834275550935

Epoch: 5| Step: 8
Training loss: 0.22296187690294494
Validation loss: 2.4059331158153983

Epoch: 5| Step: 9
Training loss: 0.4487386542934131
Validation loss: 2.395629819239959

Epoch: 5| Step: 10
Training loss: 0.21324704458362187
Validation loss: 2.397042495717833

Epoch: 535| Step: 0
Training loss: 0.4142355467312935
Validation loss: 2.4059250895510065

Epoch: 5| Step: 1
Training loss: 0.5713788345098086
Validation loss: 2.414623579326387

Epoch: 5| Step: 2
Training loss: 0.38003958480223476
Validation loss: 2.3951691311830507

Epoch: 5| Step: 3
Training loss: 0.3785760561610094
Validation loss: 2.464348804132761

Epoch: 5| Step: 4
Training loss: 0.5538091824682635
Validation loss: 2.4564573552643565

Epoch: 5| Step: 5
Training loss: 0.4850700836326097
Validation loss: 2.476030508876788

Epoch: 5| Step: 6
Training loss: 0.27580085933228465
Validation loss: 2.4587450153771107

Epoch: 5| Step: 7
Training loss: 0.3390076425887892
Validation loss: 2.4581132138125623

Epoch: 5| Step: 8
Training loss: 0.4281037360152407
Validation loss: 2.4546466385271275

Epoch: 5| Step: 9
Training loss: 0.3913221622986816
Validation loss: 2.4288074007448435

Epoch: 5| Step: 10
Training loss: 0.3099673880450924
Validation loss: 2.44139874253298

Epoch: 536| Step: 0
Training loss: 0.5429031826471257
Validation loss: 2.423319658488327

Epoch: 5| Step: 1
Training loss: 0.3514386488725939
Validation loss: 2.4529526681787512

Epoch: 5| Step: 2
Training loss: 0.44876229689068503
Validation loss: 2.4182386024253923

Epoch: 5| Step: 3
Training loss: 0.4809354980605549
Validation loss: 2.4435911258444567

Epoch: 5| Step: 4
Training loss: 0.1547627959361111
Validation loss: 2.414299715602902

Epoch: 5| Step: 5
Training loss: 0.5521350752377816
Validation loss: 2.4074581667903407

Epoch: 5| Step: 6
Training loss: 0.5209939486487148
Validation loss: 2.417290162294812

Epoch: 5| Step: 7
Training loss: 0.33351051444603574
Validation loss: 2.4590205276139474

Epoch: 5| Step: 8
Training loss: 0.49129846297426844
Validation loss: 2.4293937208742076

Epoch: 5| Step: 9
Training loss: 0.19056579420846292
Validation loss: 2.424801204894427

Epoch: 5| Step: 10
Training loss: 0.30910387007229073
Validation loss: 2.390915404977143

Epoch: 537| Step: 0
Training loss: 0.3017144280019893
Validation loss: 2.4255587029042047

Epoch: 5| Step: 1
Training loss: 0.5386423878832189
Validation loss: 2.4417571498920325

Epoch: 5| Step: 2
Training loss: 0.24638381393843087
Validation loss: 2.4088733714678714

Epoch: 5| Step: 3
Training loss: 0.3392897727551484
Validation loss: 2.461128924598314

Epoch: 5| Step: 4
Training loss: 0.28463980533791544
Validation loss: 2.479841421916021

Epoch: 5| Step: 5
Training loss: 0.5795194716502409
Validation loss: 2.46422347081026

Epoch: 5| Step: 6
Training loss: 0.28405899421282715
Validation loss: 2.461222279614189

Epoch: 5| Step: 7
Training loss: 0.2510720898698595
Validation loss: 2.4553133048768143

Epoch: 5| Step: 8
Training loss: 0.43724907763838067
Validation loss: 2.428162443450602

Epoch: 5| Step: 9
Training loss: 0.473986715647695
Validation loss: 2.424255262064246

Epoch: 5| Step: 10
Training loss: 0.5844867803385577
Validation loss: 2.4817826851259848

Epoch: 538| Step: 0
Training loss: 0.44005269157748994
Validation loss: 2.4250325811269655

Epoch: 5| Step: 1
Training loss: 0.39940070617280976
Validation loss: 2.4142489625605363

Epoch: 5| Step: 2
Training loss: 0.13553317877531895
Validation loss: 2.4098679993138816

Epoch: 5| Step: 3
Training loss: 0.3262086036698225
Validation loss: 2.466350155874685

Epoch: 5| Step: 4
Training loss: 0.4272145810086033
Validation loss: 2.432112462133557

Epoch: 5| Step: 5
Training loss: 0.5138816840150738
Validation loss: 2.439649286418365

Epoch: 5| Step: 6
Training loss: 0.2340182609412197
Validation loss: 2.439290220424173

Epoch: 5| Step: 7
Training loss: 0.5067011188988597
Validation loss: 2.4641381902384896

Epoch: 5| Step: 8
Training loss: 0.20360136111561902
Validation loss: 2.463577900517547

Epoch: 5| Step: 9
Training loss: 0.5178982878063572
Validation loss: 2.443410582027266

Epoch: 5| Step: 10
Training loss: 0.4666058776068326
Validation loss: 2.444639234140199

Epoch: 539| Step: 0
Training loss: 0.2617382355453626
Validation loss: 2.4089216878795985

Epoch: 5| Step: 1
Training loss: 0.6200162069448162
Validation loss: 2.4077973666297163

Epoch: 5| Step: 2
Training loss: 0.30439697989151115
Validation loss: 2.416554353612628

Epoch: 5| Step: 3
Training loss: 0.42263215608018895
Validation loss: 2.4264261603384902

Epoch: 5| Step: 4
Training loss: 0.36970523262866106
Validation loss: 2.4160444772704786

Epoch: 5| Step: 5
Training loss: 0.44510200611854556
Validation loss: 2.447606424759243

Epoch: 5| Step: 6
Training loss: 0.48739650679257324
Validation loss: 2.407031849161933

Epoch: 5| Step: 7
Training loss: 0.2783656836219602
Validation loss: 2.4655474639529085

Epoch: 5| Step: 8
Training loss: 0.43433704759298275
Validation loss: 2.432497763135938

Epoch: 5| Step: 9
Training loss: 0.3702313692414013
Validation loss: 2.4277711154583543

Epoch: 5| Step: 10
Training loss: 0.37738362372149
Validation loss: 2.4337391322444963

Epoch: 540| Step: 0
Training loss: 0.2506258551423664
Validation loss: 2.4103989190361426

Epoch: 5| Step: 1
Training loss: 0.5850250769399985
Validation loss: 2.380130277464834

Epoch: 5| Step: 2
Training loss: 0.3349554211576562
Validation loss: 2.3846384009335475

Epoch: 5| Step: 3
Training loss: 0.5609145337772051
Validation loss: 2.409698548704581

Epoch: 5| Step: 4
Training loss: 0.4704225265716856
Validation loss: 2.418868969459472

Epoch: 5| Step: 5
Training loss: 0.5151977213676632
Validation loss: 2.404467802335485

Epoch: 5| Step: 6
Training loss: 0.28995944384920314
Validation loss: 2.4052200552938787

Epoch: 5| Step: 7
Training loss: 0.3593263800530103
Validation loss: 2.4063615329625136

Epoch: 5| Step: 8
Training loss: 0.33331803445675756
Validation loss: 2.4121427590412003

Epoch: 5| Step: 9
Training loss: 0.2596291348390255
Validation loss: 2.419634447586919

Epoch: 5| Step: 10
Training loss: 0.22321522133494884
Validation loss: 2.4444456970544755

Epoch: 541| Step: 0
Training loss: 0.45723243914921363
Validation loss: 2.4718716564762313

Epoch: 5| Step: 1
Training loss: 0.29204996360307706
Validation loss: 2.4593400001237486

Epoch: 5| Step: 2
Training loss: 0.5047403278397168
Validation loss: 2.4950823362247663

Epoch: 5| Step: 3
Training loss: 0.45000827900900153
Validation loss: 2.489371532510178

Epoch: 5| Step: 4
Training loss: 0.27445508439873695
Validation loss: 2.449367406094422

Epoch: 5| Step: 5
Training loss: 0.4751533248294505
Validation loss: 2.4677451515940865

Epoch: 5| Step: 6
Training loss: 0.48351351206359877
Validation loss: 2.4348919643660683

Epoch: 5| Step: 7
Training loss: 0.39625478777715606
Validation loss: 2.4245640989512567

Epoch: 5| Step: 8
Training loss: 0.5689954050093087
Validation loss: 2.4879007219634475

Epoch: 5| Step: 9
Training loss: 0.291253702975133
Validation loss: 2.4573245272017448

Epoch: 5| Step: 10
Training loss: 0.20825049521683867
Validation loss: 2.498246939068052

Epoch: 542| Step: 0
Training loss: 0.41893307683545505
Validation loss: 2.486530713520569

Epoch: 5| Step: 1
Training loss: 0.4374808239140268
Validation loss: 2.4858372484882647

Epoch: 5| Step: 2
Training loss: 0.3127308469711992
Validation loss: 2.451024166674168

Epoch: 5| Step: 3
Training loss: 0.6745998441534261
Validation loss: 2.4406285954859457

Epoch: 5| Step: 4
Training loss: 0.4815566763999174
Validation loss: 2.434032490639478

Epoch: 5| Step: 5
Training loss: 0.4156728415811886
Validation loss: 2.3949088648829138

Epoch: 5| Step: 6
Training loss: 0.33162398324645925
Validation loss: 2.3676780090415614

Epoch: 5| Step: 7
Training loss: 0.569951766382608
Validation loss: 2.3648884865331787

Epoch: 5| Step: 8
Training loss: 0.3392272267804578
Validation loss: 2.449822070768032

Epoch: 5| Step: 9
Training loss: 0.3490460188380565
Validation loss: 2.473188527430614

Epoch: 5| Step: 10
Training loss: 0.41587847029255953
Validation loss: 2.4948599406526744

Epoch: 543| Step: 0
Training loss: 0.5563508467392775
Validation loss: 2.5076240062618917

Epoch: 5| Step: 1
Training loss: 0.48610849285177504
Validation loss: 2.4753906307582194

Epoch: 5| Step: 2
Training loss: 0.4792580897425034
Validation loss: 2.4333824329722638

Epoch: 5| Step: 3
Training loss: 0.3540456181648701
Validation loss: 2.382555039683435

Epoch: 5| Step: 4
Training loss: 0.4284349565548738
Validation loss: 2.314520303957464

Epoch: 5| Step: 5
Training loss: 0.4979976854155652
Validation loss: 2.3132551756665722

Epoch: 5| Step: 6
Training loss: 0.40680643634904107
Validation loss: 2.3293056628467013

Epoch: 5| Step: 7
Training loss: 0.34527904555574845
Validation loss: 2.363450002141279

Epoch: 5| Step: 8
Training loss: 0.7628653088972459
Validation loss: 2.4282750149333414

Epoch: 5| Step: 9
Training loss: 0.6321772931227703
Validation loss: 2.50880798938925

Epoch: 5| Step: 10
Training loss: 0.41879570341506756
Validation loss: 2.5042025979592317

Epoch: 544| Step: 0
Training loss: 0.4981650118869998
Validation loss: 2.5034837896075364

Epoch: 5| Step: 1
Training loss: 0.5393356792045677
Validation loss: 2.4359766751817173

Epoch: 5| Step: 2
Training loss: 0.28987633349764563
Validation loss: 2.4453022603555734

Epoch: 5| Step: 3
Training loss: 0.5022976060619262
Validation loss: 2.4215778169819835

Epoch: 5| Step: 4
Training loss: 0.4527362273789724
Validation loss: 2.364295921586635

Epoch: 5| Step: 5
Training loss: 0.3415190521276317
Validation loss: 2.3893922365485905

Epoch: 5| Step: 6
Training loss: 0.44701501746841255
Validation loss: 2.3716427936254227

Epoch: 5| Step: 7
Training loss: 0.5935039763458019
Validation loss: 2.3784903171398804

Epoch: 5| Step: 8
Training loss: 0.5190909104262961
Validation loss: 2.447649399500115

Epoch: 5| Step: 9
Training loss: 0.4521501841830632
Validation loss: 2.5054084400807946

Epoch: 5| Step: 10
Training loss: 0.5505823087217462
Validation loss: 2.5302601110137886

Epoch: 545| Step: 0
Training loss: 0.44082943184766077
Validation loss: 2.559689781398503

Epoch: 5| Step: 1
Training loss: 0.39475130799205466
Validation loss: 2.496096313543032

Epoch: 5| Step: 2
Training loss: 0.6376446971113152
Validation loss: 2.433734701217355

Epoch: 5| Step: 3
Training loss: 0.5574810175807288
Validation loss: 2.3963661124886015

Epoch: 5| Step: 4
Training loss: 0.44870262350166024
Validation loss: 2.396382754025192

Epoch: 5| Step: 5
Training loss: 0.5851187771664105
Validation loss: 2.426928696997889

Epoch: 5| Step: 6
Training loss: 0.5514920835419648
Validation loss: 2.4032960527743543

Epoch: 5| Step: 7
Training loss: 0.5471472743578871
Validation loss: 2.404546969490148

Epoch: 5| Step: 8
Training loss: 0.36367677875822507
Validation loss: 2.3849950984714336

Epoch: 5| Step: 9
Training loss: 0.40159264610921874
Validation loss: 2.4027469633112895

Epoch: 5| Step: 10
Training loss: 0.33760116835740595
Validation loss: 2.4083380538977055

Epoch: 546| Step: 0
Training loss: 0.52790457961836
Validation loss: 2.409965785896838

Epoch: 5| Step: 1
Training loss: 0.4298212363456456
Validation loss: 2.4131938378857645

Epoch: 5| Step: 2
Training loss: 0.4338456873925699
Validation loss: 2.405602749371349

Epoch: 5| Step: 3
Training loss: 0.5349827227521136
Validation loss: 2.383811233828155

Epoch: 5| Step: 4
Training loss: 0.39663251918514464
Validation loss: 2.3953861655682127

Epoch: 5| Step: 5
Training loss: 0.3137906838822381
Validation loss: 2.401747150242352

Epoch: 5| Step: 6
Training loss: 0.4071991908985336
Validation loss: 2.3764476455201047

Epoch: 5| Step: 7
Training loss: 0.4712843729126528
Validation loss: 2.3967957067635837

Epoch: 5| Step: 8
Training loss: 0.48963135794883583
Validation loss: 2.4060802125472076

Epoch: 5| Step: 9
Training loss: 0.5267853783059145
Validation loss: 2.4138113984347362

Epoch: 5| Step: 10
Training loss: 0.20412359164418475
Validation loss: 2.3824422181789617

Epoch: 547| Step: 0
Training loss: 0.29962838919532625
Validation loss: 2.4378455500573644

Epoch: 5| Step: 1
Training loss: 0.37564879162762993
Validation loss: 2.391321015381961

Epoch: 5| Step: 2
Training loss: 0.43134791603279193
Validation loss: 2.4338890908693234

Epoch: 5| Step: 3
Training loss: 0.6220953201225841
Validation loss: 2.443139617990105

Epoch: 5| Step: 4
Training loss: 0.3911760639372462
Validation loss: 2.4106921642588715

Epoch: 5| Step: 5
Training loss: 0.3784717743061149
Validation loss: 2.4241713683846022

Epoch: 5| Step: 6
Training loss: 0.41562369066763555
Validation loss: 2.439184470027764

Epoch: 5| Step: 7
Training loss: 0.40794037388940185
Validation loss: 2.4670784627584594

Epoch: 5| Step: 8
Training loss: 0.3016038520408894
Validation loss: 2.4874028943642683

Epoch: 5| Step: 9
Training loss: 0.5023354881164889
Validation loss: 2.4567823159538857

Epoch: 5| Step: 10
Training loss: 0.43760764977439265
Validation loss: 2.4672508833603652

Epoch: 548| Step: 0
Training loss: 0.5337208341004679
Validation loss: 2.4561661424025942

Epoch: 5| Step: 1
Training loss: 0.3031601035055351
Validation loss: 2.4276274081348594

Epoch: 5| Step: 2
Training loss: 0.48918312705753714
Validation loss: 2.4459558205720957

Epoch: 5| Step: 3
Training loss: 0.48363290360165423
Validation loss: 2.4373131999379374

Epoch: 5| Step: 4
Training loss: 0.4387004085510609
Validation loss: 2.42086944611034

Epoch: 5| Step: 5
Training loss: 0.39800877037760485
Validation loss: 2.429436144571066

Epoch: 5| Step: 6
Training loss: 0.28430046058316244
Validation loss: 2.421563498490188

Epoch: 5| Step: 7
Training loss: 0.39816113779570717
Validation loss: 2.436446892921927

Epoch: 5| Step: 8
Training loss: 0.31832713566525567
Validation loss: 2.4294126289391107

Epoch: 5| Step: 9
Training loss: 0.44366850977805466
Validation loss: 2.424974356967032

Epoch: 5| Step: 10
Training loss: 0.31749751439210433
Validation loss: 2.4524962951569287

Epoch: 549| Step: 0
Training loss: 0.3039098621732319
Validation loss: 2.425928906979351

Epoch: 5| Step: 1
Training loss: 0.2902913778195113
Validation loss: 2.4384602983892427

Epoch: 5| Step: 2
Training loss: 0.337910183026303
Validation loss: 2.438797132055406

Epoch: 5| Step: 3
Training loss: 0.26229312840014785
Validation loss: 2.443438646023726

Epoch: 5| Step: 4
Training loss: 0.4958148983592388
Validation loss: 2.4573590569436097

Epoch: 5| Step: 5
Training loss: 0.5039069301393635
Validation loss: 2.4857660636256376

Epoch: 5| Step: 6
Training loss: 0.3456221016801992
Validation loss: 2.4224444272683243

Epoch: 5| Step: 7
Training loss: 0.3287293227840238
Validation loss: 2.433515476175581

Epoch: 5| Step: 8
Training loss: 0.42831192043170047
Validation loss: 2.424089857676838

Epoch: 5| Step: 9
Training loss: 0.40967411586800856
Validation loss: 2.4380379536231236

Epoch: 5| Step: 10
Training loss: 0.49057060656955553
Validation loss: 2.4503971868231753

Epoch: 550| Step: 0
Training loss: 0.6598496261071269
Validation loss: 2.448298399167874

Epoch: 5| Step: 1
Training loss: 0.331564395532394
Validation loss: 2.427104081261433

Epoch: 5| Step: 2
Training loss: 0.30369880627509643
Validation loss: 2.455657625620525

Epoch: 5| Step: 3
Training loss: 0.45785412517787594
Validation loss: 2.4498515085554886

Epoch: 5| Step: 4
Training loss: 0.2955501760509691
Validation loss: 2.4195027419654114

Epoch: 5| Step: 5
Training loss: 0.1996280262066196
Validation loss: 2.4523975607123436

Epoch: 5| Step: 6
Training loss: 0.20523561152741682
Validation loss: 2.428472943328505

Epoch: 5| Step: 7
Training loss: 0.4060395869630282
Validation loss: 2.414509169456818

Epoch: 5| Step: 8
Training loss: 0.5349607737145063
Validation loss: 2.432260457023735

Epoch: 5| Step: 9
Training loss: 0.2713805761805478
Validation loss: 2.4371938952344574

Epoch: 5| Step: 10
Training loss: 0.31442504662677706
Validation loss: 2.4518165210352505

Testing loss: 2.5454170927337842
