Epoch: 1| Step: 0
Training loss: 6.20285701751709
Validation loss: 5.165669225877331

Epoch: 5| Step: 1
Training loss: 5.007086753845215
Validation loss: 5.143170192677488

Epoch: 5| Step: 2
Training loss: 4.268216609954834
Validation loss: 5.118664356970018

Epoch: 5| Step: 3
Training loss: 4.692918300628662
Validation loss: 5.092438964433567

Epoch: 5| Step: 4
Training loss: 4.812979698181152
Validation loss: 5.063048039713213

Epoch: 5| Step: 5
Training loss: 5.0054402351379395
Validation loss: 5.031512404000887

Epoch: 5| Step: 6
Training loss: 4.930258274078369
Validation loss: 4.998096594246485

Epoch: 5| Step: 7
Training loss: 3.9073429107666016
Validation loss: 4.960707300452776

Epoch: 5| Step: 8
Training loss: 4.839066982269287
Validation loss: 4.920842503988615

Epoch: 5| Step: 9
Training loss: 4.233477592468262
Validation loss: 4.87827512269379

Epoch: 5| Step: 10
Training loss: 5.032367706298828
Validation loss: 4.8327202796936035

Epoch: 2| Step: 0
Training loss: 5.651242256164551
Validation loss: 4.783804919130059

Epoch: 5| Step: 1
Training loss: 4.687622547149658
Validation loss: 4.732917667717062

Epoch: 5| Step: 2
Training loss: 3.240203857421875
Validation loss: 4.678984047264181

Epoch: 5| Step: 3
Training loss: 4.222419738769531
Validation loss: 4.623359551993749

Epoch: 5| Step: 4
Training loss: 4.336928844451904
Validation loss: 4.563699758181008

Epoch: 5| Step: 5
Training loss: 4.910887718200684
Validation loss: 4.501597583934825

Epoch: 5| Step: 6
Training loss: 4.216845512390137
Validation loss: 4.438252008089456

Epoch: 5| Step: 7
Training loss: 4.1540937423706055
Validation loss: 4.372946928906185

Epoch: 5| Step: 8
Training loss: 4.154351711273193
Validation loss: 4.3069964557565665

Epoch: 5| Step: 9
Training loss: 4.369696617126465
Validation loss: 4.2503521775686615

Epoch: 5| Step: 10
Training loss: 3.1242501735687256
Validation loss: 4.202777421602639

Epoch: 3| Step: 0
Training loss: 4.101738929748535
Validation loss: 4.1640993292613695

Epoch: 5| Step: 1
Training loss: 3.851132869720459
Validation loss: 4.127145192956411

Epoch: 5| Step: 2
Training loss: 4.710752487182617
Validation loss: 4.084772948295839

Epoch: 5| Step: 3
Training loss: 4.184824466705322
Validation loss: 4.036807085878106

Epoch: 5| Step: 4
Training loss: 3.9973366260528564
Validation loss: 3.9941762314047864

Epoch: 5| Step: 5
Training loss: 3.685854434967041
Validation loss: 3.958952147473571

Epoch: 5| Step: 6
Training loss: 4.828403472900391
Validation loss: 3.9305778447017876

Epoch: 5| Step: 7
Training loss: 3.7260055541992188
Validation loss: 3.9054609678124868

Epoch: 5| Step: 8
Training loss: 3.0952634811401367
Validation loss: 3.879926425154491

Epoch: 5| Step: 9
Training loss: 3.081881046295166
Validation loss: 3.8628248527485836

Epoch: 5| Step: 10
Training loss: 2.8125030994415283
Validation loss: 3.8396653231754097

Epoch: 4| Step: 0
Training loss: 4.340270519256592
Validation loss: 3.825364512781943

Epoch: 5| Step: 1
Training loss: 3.6622281074523926
Validation loss: 3.805738495242211

Epoch: 5| Step: 2
Training loss: 4.193642616271973
Validation loss: 3.7860691367938952

Epoch: 5| Step: 3
Training loss: 3.2949600219726562
Validation loss: 3.7640368784627607

Epoch: 5| Step: 4
Training loss: 3.282757520675659
Validation loss: 3.746948931806831

Epoch: 5| Step: 5
Training loss: 3.39219331741333
Validation loss: 3.7348026485853296

Epoch: 5| Step: 6
Training loss: 3.5367088317871094
Validation loss: 3.723128290586574

Epoch: 5| Step: 7
Training loss: 3.23417592048645
Validation loss: 3.7165691186023015

Epoch: 5| Step: 8
Training loss: 3.7979347705841064
Validation loss: 3.6876126643150084

Epoch: 5| Step: 9
Training loss: 4.332963466644287
Validation loss: 3.672736947254468

Epoch: 5| Step: 10
Training loss: 2.8394575119018555
Validation loss: 3.660896696070189

Epoch: 5| Step: 0
Training loss: 3.5566508769989014
Validation loss: 3.650760322488764

Epoch: 5| Step: 1
Training loss: 3.586635112762451
Validation loss: 3.638627313798474

Epoch: 5| Step: 2
Training loss: 3.4972338676452637
Validation loss: 3.6262943513931765

Epoch: 5| Step: 3
Training loss: 4.198833465576172
Validation loss: 3.6151039805463565

Epoch: 5| Step: 4
Training loss: 1.9607528448104858
Validation loss: 3.6042538945392897

Epoch: 5| Step: 5
Training loss: 3.5391814708709717
Validation loss: 3.5944599336193455

Epoch: 5| Step: 6
Training loss: 3.727313995361328
Validation loss: 3.5909320257043325

Epoch: 5| Step: 7
Training loss: 3.8505032062530518
Validation loss: 3.5724245963558072

Epoch: 5| Step: 8
Training loss: 3.798818588256836
Validation loss: 3.561984703104983

Epoch: 5| Step: 9
Training loss: 4.0726728439331055
Validation loss: 3.5568946253868843

Epoch: 5| Step: 10
Training loss: 2.7542593479156494
Validation loss: 3.54759213232225

Epoch: 6| Step: 0
Training loss: 2.9284236431121826
Validation loss: 3.542635968936387

Epoch: 5| Step: 1
Training loss: 3.273019313812256
Validation loss: 3.525517304738363

Epoch: 5| Step: 2
Training loss: 2.7888827323913574
Validation loss: 3.5134720340851815

Epoch: 5| Step: 3
Training loss: 4.840388298034668
Validation loss: 3.5062750898381716

Epoch: 5| Step: 4
Training loss: 3.192092180252075
Validation loss: 3.4945179365014516

Epoch: 5| Step: 5
Training loss: 3.074280261993408
Validation loss: 3.479743775501046

Epoch: 5| Step: 6
Training loss: 4.066121578216553
Validation loss: 3.4678257537144486

Epoch: 5| Step: 7
Training loss: 3.960871458053589
Validation loss: 3.4610857861016386

Epoch: 5| Step: 8
Training loss: 2.632179021835327
Validation loss: 3.458907165834981

Epoch: 5| Step: 9
Training loss: 4.557008266448975
Validation loss: 3.4479845416161323

Epoch: 5| Step: 10
Training loss: 2.209068775177002
Validation loss: 3.432522955761161

Epoch: 7| Step: 0
Training loss: 2.595144033432007
Validation loss: 3.4267843666897027

Epoch: 5| Step: 1
Training loss: 3.045788049697876
Validation loss: 3.4164501108149046

Epoch: 5| Step: 2
Training loss: 4.357502460479736
Validation loss: 3.410262615449967

Epoch: 5| Step: 3
Training loss: 3.1604888439178467
Validation loss: 3.397949867351081

Epoch: 5| Step: 4
Training loss: 4.36585807800293
Validation loss: 3.3904568738834833

Epoch: 5| Step: 5
Training loss: 3.6807167530059814
Validation loss: 3.377523071022444

Epoch: 5| Step: 6
Training loss: 2.736781597137451
Validation loss: 3.371691214141025

Epoch: 5| Step: 7
Training loss: 2.9513046741485596
Validation loss: 3.364697510196317

Epoch: 5| Step: 8
Training loss: 3.227351665496826
Validation loss: 3.3569471630998837

Epoch: 5| Step: 9
Training loss: 3.228315830230713
Validation loss: 3.360035409209549

Epoch: 5| Step: 10
Training loss: 3.434572219848633
Validation loss: 3.3376397817365584

Epoch: 8| Step: 0
Training loss: 4.447281837463379
Validation loss: 3.3257005291600383

Epoch: 5| Step: 1
Training loss: 3.8267135620117188
Validation loss: 3.31485628825362

Epoch: 5| Step: 2
Training loss: 4.2741289138793945
Validation loss: 3.303469334879229

Epoch: 5| Step: 3
Training loss: 3.278616428375244
Validation loss: 3.2909490600708993

Epoch: 5| Step: 4
Training loss: 2.853605270385742
Validation loss: 3.2833676158740954

Epoch: 5| Step: 5
Training loss: 1.7342700958251953
Validation loss: 3.278799013424945

Epoch: 5| Step: 6
Training loss: 2.8498587608337402
Validation loss: 3.265748295732724

Epoch: 5| Step: 7
Training loss: 3.3390541076660156
Validation loss: 3.2511841609913814

Epoch: 5| Step: 8
Training loss: 2.992645740509033
Validation loss: 3.239975811332785

Epoch: 5| Step: 9
Training loss: 2.6688647270202637
Validation loss: 3.2273853748075423

Epoch: 5| Step: 10
Training loss: 3.5647151470184326
Validation loss: 3.214055435631865

Epoch: 9| Step: 0
Training loss: 2.948312759399414
Validation loss: 3.2063417434692383

Epoch: 5| Step: 1
Training loss: 2.704831838607788
Validation loss: 3.197734127762497

Epoch: 5| Step: 2
Training loss: 3.318708896636963
Validation loss: 3.195460814301686

Epoch: 5| Step: 3
Training loss: 3.3388831615448
Validation loss: 3.1795311025393906

Epoch: 5| Step: 4
Training loss: 2.576859712600708
Validation loss: 3.1778174010656213

Epoch: 5| Step: 5
Training loss: 3.0335490703582764
Validation loss: 3.1670908620280604

Epoch: 5| Step: 6
Training loss: 3.1603665351867676
Validation loss: 3.150427472206854

Epoch: 5| Step: 7
Training loss: 3.4566617012023926
Validation loss: 3.144970747732347

Epoch: 5| Step: 8
Training loss: 3.883254289627075
Validation loss: 3.136556330547538

Epoch: 5| Step: 9
Training loss: 3.653512954711914
Validation loss: 3.127933899561564

Epoch: 5| Step: 10
Training loss: 2.686800479888916
Validation loss: 3.1174511166029077

Epoch: 10| Step: 0
Training loss: 2.803619861602783
Validation loss: 3.114437136598813

Epoch: 5| Step: 1
Training loss: 2.2585668563842773
Validation loss: 3.101353109523814

Epoch: 5| Step: 2
Training loss: 4.109040260314941
Validation loss: 3.0870824065259708

Epoch: 5| Step: 3
Training loss: 2.9293041229248047
Validation loss: 3.07931100937628

Epoch: 5| Step: 4
Training loss: 4.08829402923584
Validation loss: 3.072900697749148

Epoch: 5| Step: 5
Training loss: 3.4211411476135254
Validation loss: 3.062526046588857

Epoch: 5| Step: 6
Training loss: 3.066018581390381
Validation loss: 3.053460351882442

Epoch: 5| Step: 7
Training loss: 2.837472915649414
Validation loss: 3.0451013400990474

Epoch: 5| Step: 8
Training loss: 2.945568799972534
Validation loss: 3.043671449025472

Epoch: 5| Step: 9
Training loss: 2.955953598022461
Validation loss: 3.0308841787358767

Epoch: 5| Step: 10
Training loss: 2.7280426025390625
Validation loss: 3.0206280600640083

Epoch: 11| Step: 0
Training loss: 3.530294895172119
Validation loss: 3.019926445458525

Epoch: 5| Step: 1
Training loss: 2.5167434215545654
Validation loss: 3.0228814976189726

Epoch: 5| Step: 2
Training loss: 2.730447292327881
Validation loss: 3.047109442372476

Epoch: 5| Step: 3
Training loss: 3.0025110244750977
Validation loss: 3.020046672513408

Epoch: 5| Step: 4
Training loss: 2.3190758228302
Validation loss: 2.989600032888433

Epoch: 5| Step: 5
Training loss: 2.446523666381836
Validation loss: 2.986007890393657

Epoch: 5| Step: 6
Training loss: 3.2731285095214844
Validation loss: 3.003226685267623

Epoch: 5| Step: 7
Training loss: 4.191883087158203
Validation loss: 2.9813712284129155

Epoch: 5| Step: 8
Training loss: 3.564736843109131
Validation loss: 2.978741507376394

Epoch: 5| Step: 9
Training loss: 3.457244873046875
Validation loss: 2.967501030173353

Epoch: 5| Step: 10
Training loss: 2.6008946895599365
Validation loss: 2.966243492659702

Epoch: 12| Step: 0
Training loss: 2.9365081787109375
Validation loss: 2.9570513976517545

Epoch: 5| Step: 1
Training loss: 2.4618582725524902
Validation loss: 2.9493261460335023

Epoch: 5| Step: 2
Training loss: 3.1581809520721436
Validation loss: 2.9437411036542667

Epoch: 5| Step: 3
Training loss: 3.1402225494384766
Validation loss: 2.938103234896096

Epoch: 5| Step: 4
Training loss: 3.635796308517456
Validation loss: 2.9355866729572253

Epoch: 5| Step: 5
Training loss: 3.0686087608337402
Validation loss: 2.935939637563562

Epoch: 5| Step: 6
Training loss: 2.8615128993988037
Validation loss: 2.9265101725055325

Epoch: 5| Step: 7
Training loss: 3.2880783081054688
Validation loss: 2.9277929746976463

Epoch: 5| Step: 8
Training loss: 3.0577731132507324
Validation loss: 2.906577499963904

Epoch: 5| Step: 9
Training loss: 2.9866394996643066
Validation loss: 2.913267904712308

Epoch: 5| Step: 10
Training loss: 2.5643234252929688
Validation loss: 2.911381152368361

Epoch: 13| Step: 0
Training loss: 2.8584516048431396
Validation loss: 2.9067143496646675

Epoch: 5| Step: 1
Training loss: 3.2004692554473877
Validation loss: 2.8928883972988335

Epoch: 5| Step: 2
Training loss: 2.996983289718628
Validation loss: 2.887335649100683

Epoch: 5| Step: 3
Training loss: 3.4677491188049316
Validation loss: 2.884441062968264

Epoch: 5| Step: 4
Training loss: 3.1640584468841553
Validation loss: 2.8711355809242494

Epoch: 5| Step: 5
Training loss: 3.0080108642578125
Validation loss: 2.8645673721067366

Epoch: 5| Step: 6
Training loss: 2.685960531234741
Validation loss: 2.859567778084868

Epoch: 5| Step: 7
Training loss: 3.3749687671661377
Validation loss: 2.854438838138375

Epoch: 5| Step: 8
Training loss: 2.367981195449829
Validation loss: 2.8510602058902865

Epoch: 5| Step: 9
Training loss: 2.5002694129943848
Validation loss: 2.8485920788139425

Epoch: 5| Step: 10
Training loss: 3.2403995990753174
Validation loss: 2.869242678406418

Epoch: 14| Step: 0
Training loss: 2.6104788780212402
Validation loss: 2.8482362916392665

Epoch: 5| Step: 1
Training loss: 3.5823922157287598
Validation loss: 2.8352616704920286

Epoch: 5| Step: 2
Training loss: 2.8940882682800293
Validation loss: 2.835433175486903

Epoch: 5| Step: 3
Training loss: 3.371718645095825
Validation loss: 2.8349781805469143

Epoch: 5| Step: 4
Training loss: 2.9772772789001465
Validation loss: 2.83002152750569

Epoch: 5| Step: 5
Training loss: 3.385694980621338
Validation loss: 2.8199243109713317

Epoch: 5| Step: 6
Training loss: 2.9381556510925293
Validation loss: 2.816922926133679

Epoch: 5| Step: 7
Training loss: 2.587574005126953
Validation loss: 2.820920803213632

Epoch: 5| Step: 8
Training loss: 2.893343210220337
Validation loss: 2.816881125973117

Epoch: 5| Step: 9
Training loss: 2.5826821327209473
Validation loss: 2.809710407769808

Epoch: 5| Step: 10
Training loss: 2.5429673194885254
Validation loss: 2.7960026084735827

Epoch: 15| Step: 0
Training loss: 2.7748477458953857
Validation loss: 2.788661128731184

Epoch: 5| Step: 1
Training loss: 3.6536669731140137
Validation loss: 2.7875054523509037

Epoch: 5| Step: 2
Training loss: 2.387375593185425
Validation loss: 2.7859679601525746

Epoch: 5| Step: 3
Training loss: 2.7460289001464844
Validation loss: 2.787592298241072

Epoch: 5| Step: 4
Training loss: 3.1454811096191406
Validation loss: 2.781603802916824

Epoch: 5| Step: 5
Training loss: 3.226444721221924
Validation loss: 2.77289689740827

Epoch: 5| Step: 6
Training loss: 3.0592801570892334
Validation loss: 2.7657248486754713

Epoch: 5| Step: 7
Training loss: 2.221062183380127
Validation loss: 2.7536898172029884

Epoch: 5| Step: 8
Training loss: 2.96661639213562
Validation loss: 2.753903514595442

Epoch: 5| Step: 9
Training loss: 2.713972568511963
Validation loss: 2.7804713454297794

Epoch: 5| Step: 10
Training loss: 3.2724437713623047
Validation loss: 2.7752994568117204

Epoch: 16| Step: 0
Training loss: 3.3284249305725098
Validation loss: 2.766847784801196

Epoch: 5| Step: 1
Training loss: 2.8291287422180176
Validation loss: 2.7420087604112524

Epoch: 5| Step: 2
Training loss: 2.635938882827759
Validation loss: 2.749109652734572

Epoch: 5| Step: 3
Training loss: 3.1351077556610107
Validation loss: 2.7434404896151636

Epoch: 5| Step: 4
Training loss: 2.7708687782287598
Validation loss: 2.7276647578003588

Epoch: 5| Step: 5
Training loss: 3.574632167816162
Validation loss: 2.727506927264634

Epoch: 5| Step: 6
Training loss: 2.903820514678955
Validation loss: 2.7317768322524203

Epoch: 5| Step: 7
Training loss: 3.075650691986084
Validation loss: 2.7494312691432174

Epoch: 5| Step: 8
Training loss: 2.231207847595215
Validation loss: 2.734940964688537

Epoch: 5| Step: 9
Training loss: 2.40641713142395
Validation loss: 2.756250581433696

Epoch: 5| Step: 10
Training loss: 2.914494514465332
Validation loss: 2.7538870303861556

Epoch: 17| Step: 0
Training loss: 2.264885425567627
Validation loss: 2.7566000594887683

Epoch: 5| Step: 1
Training loss: 3.418574571609497
Validation loss: 2.738853285389562

Epoch: 5| Step: 2
Training loss: 3.3869590759277344
Validation loss: 2.7081580341503186

Epoch: 5| Step: 3
Training loss: 2.7988195419311523
Validation loss: 2.708910447294994

Epoch: 5| Step: 4
Training loss: 2.8670525550842285
Validation loss: 2.7479192005690707

Epoch: 5| Step: 5
Training loss: 3.0953986644744873
Validation loss: 2.7101140637551584

Epoch: 5| Step: 6
Training loss: 2.7545621395111084
Validation loss: 2.703075667863251

Epoch: 5| Step: 7
Training loss: 2.768213987350464
Validation loss: 2.7009745028711136

Epoch: 5| Step: 8
Training loss: 2.1596839427948
Validation loss: 2.6932566140287664

Epoch: 5| Step: 9
Training loss: 3.3633627891540527
Validation loss: 2.734305435611356

Epoch: 5| Step: 10
Training loss: 2.862940549850464
Validation loss: 2.783254018393896

Epoch: 18| Step: 0
Training loss: 2.5432515144348145
Validation loss: 2.80218828621731

Epoch: 5| Step: 1
Training loss: 3.018559217453003
Validation loss: 2.775581295772265

Epoch: 5| Step: 2
Training loss: 3.966376543045044
Validation loss: 2.7504602709124164

Epoch: 5| Step: 3
Training loss: 2.591838836669922
Validation loss: 2.7221270171544885

Epoch: 5| Step: 4
Training loss: 3.1014208793640137
Validation loss: 2.795887529209096

Epoch: 5| Step: 5
Training loss: 2.9388904571533203
Validation loss: 2.8191902099117154

Epoch: 5| Step: 6
Training loss: 2.9812874794006348
Validation loss: 2.8383376598358154

Epoch: 5| Step: 7
Training loss: 2.8471715450286865
Validation loss: 2.811594340109056

Epoch: 5| Step: 8
Training loss: 2.661027669906616
Validation loss: 2.816810066981982

Epoch: 5| Step: 9
Training loss: 2.5033507347106934
Validation loss: 2.8130418203210317

Epoch: 5| Step: 10
Training loss: 3.006295680999756
Validation loss: 2.8088025713479645

Epoch: 19| Step: 0
Training loss: 2.92747163772583
Validation loss: 2.790943517479845

Epoch: 5| Step: 1
Training loss: 2.5198276042938232
Validation loss: 2.7798131640239427

Epoch: 5| Step: 2
Training loss: 3.2099571228027344
Validation loss: 2.7733772211177374

Epoch: 5| Step: 3
Training loss: 2.7207999229431152
Validation loss: 2.7636148673231884

Epoch: 5| Step: 4
Training loss: 3.0986640453338623
Validation loss: 2.7531542162741385

Epoch: 5| Step: 5
Training loss: 2.742441177368164
Validation loss: 2.774331344071255

Epoch: 5| Step: 6
Training loss: 2.797820806503296
Validation loss: 2.8014082549720682

Epoch: 5| Step: 7
Training loss: 2.173867702484131
Validation loss: 2.8405634459628852

Epoch: 5| Step: 8
Training loss: 3.5281364917755127
Validation loss: 2.7814814147128852

Epoch: 5| Step: 9
Training loss: 2.8992037773132324
Validation loss: 2.7137596017570904

Epoch: 5| Step: 10
Training loss: 3.270906448364258
Validation loss: 2.6604436418061614

Epoch: 20| Step: 0
Training loss: 3.0436923503875732
Validation loss: 2.6488766849681897

Epoch: 5| Step: 1
Training loss: 2.07074236869812
Validation loss: 2.6628153862491732

Epoch: 5| Step: 2
Training loss: 2.950770378112793
Validation loss: 2.6952892400885142

Epoch: 5| Step: 3
Training loss: 2.2244060039520264
Validation loss: 2.6561744136195027

Epoch: 5| Step: 4
Training loss: 2.467383623123169
Validation loss: 2.63936536799195

Epoch: 5| Step: 5
Training loss: 2.907963275909424
Validation loss: 2.626944036893947

Epoch: 5| Step: 6
Training loss: 3.264280319213867
Validation loss: 2.622976282591461

Epoch: 5| Step: 7
Training loss: 3.2830958366394043
Validation loss: 2.6179933394155195

Epoch: 5| Step: 8
Training loss: 2.6015615463256836
Validation loss: 2.6104178954196233

Epoch: 5| Step: 9
Training loss: 2.6837477684020996
Validation loss: 2.608052976669804

Epoch: 5| Step: 10
Training loss: 3.721822738647461
Validation loss: 2.603127561589723

Epoch: 21| Step: 0
Training loss: 2.793623924255371
Validation loss: 2.5996493395938667

Epoch: 5| Step: 1
Training loss: 2.2916629314422607
Validation loss: 2.5935946433774886

Epoch: 5| Step: 2
Training loss: 2.7932114601135254
Validation loss: 2.5910400908480407

Epoch: 5| Step: 3
Training loss: 2.8282663822174072
Validation loss: 2.5829223766121814

Epoch: 5| Step: 4
Training loss: 2.602146863937378
Validation loss: 2.579366148159068

Epoch: 5| Step: 5
Training loss: 3.3909003734588623
Validation loss: 2.576516500083349

Epoch: 5| Step: 6
Training loss: 2.3264126777648926
Validation loss: 2.5715722755719255

Epoch: 5| Step: 7
Training loss: 2.594618797302246
Validation loss: 2.563043740487868

Epoch: 5| Step: 8
Training loss: 3.367192029953003
Validation loss: 2.56210232293734

Epoch: 5| Step: 9
Training loss: 2.8012373447418213
Validation loss: 2.562889673376596

Epoch: 5| Step: 10
Training loss: 2.9928135871887207
Validation loss: 2.567300659354015

Epoch: 22| Step: 0
Training loss: 2.776134967803955
Validation loss: 2.566719506376533

Epoch: 5| Step: 1
Training loss: 2.7248685359954834
Validation loss: 2.557897613894555

Epoch: 5| Step: 2
Training loss: 2.729980945587158
Validation loss: 2.5552456276391142

Epoch: 5| Step: 3
Training loss: 2.4104175567626953
Validation loss: 2.5472077861908944

Epoch: 5| Step: 4
Training loss: 2.9445438385009766
Validation loss: 2.548036539426414

Epoch: 5| Step: 5
Training loss: 3.582582473754883
Validation loss: 2.545826424834549

Epoch: 5| Step: 6
Training loss: 2.204390287399292
Validation loss: 2.5546109753270305

Epoch: 5| Step: 7
Training loss: 2.8064117431640625
Validation loss: 2.570081131432646

Epoch: 5| Step: 8
Training loss: 2.6978976726531982
Validation loss: 2.580973425219136

Epoch: 5| Step: 9
Training loss: 2.268181085586548
Validation loss: 2.5514093804103073

Epoch: 5| Step: 10
Training loss: 3.407613515853882
Validation loss: 2.5302206700847996

Epoch: 23| Step: 0
Training loss: 2.7954318523406982
Validation loss: 2.5329673174888856

Epoch: 5| Step: 1
Training loss: 2.8530755043029785
Validation loss: 2.5385437703901723

Epoch: 5| Step: 2
Training loss: 2.2128853797912598
Validation loss: 2.5416273455465994

Epoch: 5| Step: 3
Training loss: 2.60992431640625
Validation loss: 2.5430155108051915

Epoch: 5| Step: 4
Training loss: 2.679210662841797
Validation loss: 2.534908894569643

Epoch: 5| Step: 5
Training loss: 3.3011374473571777
Validation loss: 2.525235181213707

Epoch: 5| Step: 6
Training loss: 2.789715528488159
Validation loss: 2.525813220649637

Epoch: 5| Step: 7
Training loss: 2.879054546356201
Validation loss: 2.523418272695234

Epoch: 5| Step: 8
Training loss: 2.3377060890197754
Validation loss: 2.527719989899666

Epoch: 5| Step: 9
Training loss: 3.293950319290161
Validation loss: 2.545290900814918

Epoch: 5| Step: 10
Training loss: 2.6769204139709473
Validation loss: 2.5261474629884124

Epoch: 24| Step: 0
Training loss: 2.816727638244629
Validation loss: 2.515860704965489

Epoch: 5| Step: 1
Training loss: 2.5780720710754395
Validation loss: 2.5140804013898297

Epoch: 5| Step: 2
Training loss: 2.576138734817505
Validation loss: 2.5151111207982546

Epoch: 5| Step: 3
Training loss: 3.3629612922668457
Validation loss: 2.5162568707619943

Epoch: 5| Step: 4
Training loss: 1.7405192852020264
Validation loss: 2.51084404606973

Epoch: 5| Step: 5
Training loss: 2.564596176147461
Validation loss: 2.5105206120398735

Epoch: 5| Step: 6
Training loss: 2.658437490463257
Validation loss: 2.5151269589701006

Epoch: 5| Step: 7
Training loss: 2.7378525733947754
Validation loss: 2.5205051796410674

Epoch: 5| Step: 8
Training loss: 2.8033597469329834
Validation loss: 2.5306304167675715

Epoch: 5| Step: 9
Training loss: 3.438020706176758
Validation loss: 2.504503055285382

Epoch: 5| Step: 10
Training loss: 2.9167094230651855
Validation loss: 2.5072469993304183

Epoch: 25| Step: 0
Training loss: 3.584751605987549
Validation loss: 2.529049801570113

Epoch: 5| Step: 1
Training loss: 3.124389410018921
Validation loss: 2.513927816062845

Epoch: 5| Step: 2
Training loss: 3.349834442138672
Validation loss: 2.510445066677627

Epoch: 5| Step: 3
Training loss: 2.4825918674468994
Validation loss: 2.50824313522667

Epoch: 5| Step: 4
Training loss: 2.879086494445801
Validation loss: 2.505612891207459

Epoch: 5| Step: 5
Training loss: 3.287911891937256
Validation loss: 2.502167542775472

Epoch: 5| Step: 6
Training loss: 2.064924716949463
Validation loss: 2.498874915543423

Epoch: 5| Step: 7
Training loss: 2.3918776512145996
Validation loss: 2.5014491927239204

Epoch: 5| Step: 8
Training loss: 2.2741475105285645
Validation loss: 2.5137566328048706

Epoch: 5| Step: 9
Training loss: 2.255387306213379
Validation loss: 2.5127411606491252

Epoch: 5| Step: 10
Training loss: 2.3985133171081543
Validation loss: 2.5218833159374934

Epoch: 26| Step: 0
Training loss: 3.3290634155273438
Validation loss: 2.530909222941245

Epoch: 5| Step: 1
Training loss: 3.119237184524536
Validation loss: 2.5035594048038607

Epoch: 5| Step: 2
Training loss: 2.528212547302246
Validation loss: 2.4932040745212185

Epoch: 5| Step: 3
Training loss: 3.0715491771698
Validation loss: 2.497475116483627

Epoch: 5| Step: 4
Training loss: 2.3423027992248535
Validation loss: 2.5059902232180358

Epoch: 5| Step: 5
Training loss: 2.765272617340088
Validation loss: 2.5246465693237963

Epoch: 5| Step: 6
Training loss: 2.841338634490967
Validation loss: 2.537729873452135

Epoch: 5| Step: 7
Training loss: 3.3342299461364746
Validation loss: 2.546398232060094

Epoch: 5| Step: 8
Training loss: 2.537130832672119
Validation loss: 2.517133582022882

Epoch: 5| Step: 9
Training loss: 1.5925618410110474
Validation loss: 2.486111146147533

Epoch: 5| Step: 10
Training loss: 2.6676504611968994
Validation loss: 2.4791088104248047

Epoch: 27| Step: 0
Training loss: 2.988318681716919
Validation loss: 2.4871925102767123

Epoch: 5| Step: 1
Training loss: 2.566545009613037
Validation loss: 2.4893003791891117

Epoch: 5| Step: 2
Training loss: 2.409618854522705
Validation loss: 2.497929924277849

Epoch: 5| Step: 3
Training loss: 2.819232940673828
Validation loss: 2.523156342967864

Epoch: 5| Step: 4
Training loss: 2.3998115062713623
Validation loss: 2.5257426410593014

Epoch: 5| Step: 5
Training loss: 2.3062379360198975
Validation loss: 2.5167976553722093

Epoch: 5| Step: 6
Training loss: 2.940516233444214
Validation loss: 2.5020530377664874

Epoch: 5| Step: 7
Training loss: 2.2181875705718994
Validation loss: 2.485462521993986

Epoch: 5| Step: 8
Training loss: 3.914691209793091
Validation loss: 2.482863990209436

Epoch: 5| Step: 9
Training loss: 2.8821425437927246
Validation loss: 2.4735812064140075

Epoch: 5| Step: 10
Training loss: 2.425541400909424
Validation loss: 2.4749756192648285

Epoch: 28| Step: 0
Training loss: 2.4002528190612793
Validation loss: 2.4831437705665507

Epoch: 5| Step: 1
Training loss: 2.6701037883758545
Validation loss: 2.495673664154545

Epoch: 5| Step: 2
Training loss: 2.7807650566101074
Validation loss: 2.5222032941797727

Epoch: 5| Step: 3
Training loss: 2.2525112628936768
Validation loss: 2.5346700042806645

Epoch: 5| Step: 4
Training loss: 2.3743269443511963
Validation loss: 2.539276715247862

Epoch: 5| Step: 5
Training loss: 3.128401517868042
Validation loss: 2.5697345836188203

Epoch: 5| Step: 6
Training loss: 2.8367669582366943
Validation loss: 2.5113894170330417

Epoch: 5| Step: 7
Training loss: 2.4752674102783203
Validation loss: 2.483083350684053

Epoch: 5| Step: 8
Training loss: 2.8717246055603027
Validation loss: 2.481685374372749

Epoch: 5| Step: 9
Training loss: 2.993626832962036
Validation loss: 2.4805689178487307

Epoch: 5| Step: 10
Training loss: 3.020237445831299
Validation loss: 2.4840753642461633

Epoch: 29| Step: 0
Training loss: 2.419768810272217
Validation loss: 2.4908713089522494

Epoch: 5| Step: 1
Training loss: 3.069395065307617
Validation loss: 2.5081423456950853

Epoch: 5| Step: 2
Training loss: 3.294537305831909
Validation loss: 2.503366470336914

Epoch: 5| Step: 3
Training loss: 2.9324491024017334
Validation loss: 2.4814120082445044

Epoch: 5| Step: 4
Training loss: 2.587679386138916
Validation loss: 2.4825405869432675

Epoch: 5| Step: 5
Training loss: 2.246464729309082
Validation loss: 2.5097090300693305

Epoch: 5| Step: 6
Training loss: 2.5246522426605225
Validation loss: 2.572181091513685

Epoch: 5| Step: 7
Training loss: 2.3313918113708496
Validation loss: 2.6316676755105295

Epoch: 5| Step: 8
Training loss: 2.729149103164673
Validation loss: 2.5594895808927474

Epoch: 5| Step: 9
Training loss: 3.389460802078247
Validation loss: 2.4939823919726956

Epoch: 5| Step: 10
Training loss: 2.4366157054901123
Validation loss: 2.460292741816531

Epoch: 30| Step: 0
Training loss: 2.7844643592834473
Validation loss: 2.470160799641763

Epoch: 5| Step: 1
Training loss: 2.2668724060058594
Validation loss: 2.5046835689134497

Epoch: 5| Step: 2
Training loss: 2.6910529136657715
Validation loss: 2.5250309064824092

Epoch: 5| Step: 3
Training loss: 3.403442859649658
Validation loss: 2.494741742328931

Epoch: 5| Step: 4
Training loss: 2.927666187286377
Validation loss: 2.4774711516595658

Epoch: 5| Step: 5
Training loss: 3.0430285930633545
Validation loss: 2.4536412223692863

Epoch: 5| Step: 6
Training loss: 2.6522679328918457
Validation loss: 2.444873212486185

Epoch: 5| Step: 7
Training loss: 2.721339702606201
Validation loss: 2.465800331484887

Epoch: 5| Step: 8
Training loss: 3.090735673904419
Validation loss: 2.516697235004876

Epoch: 5| Step: 9
Training loss: 2.3870930671691895
Validation loss: 2.5449090362876974

Epoch: 5| Step: 10
Training loss: 1.9231986999511719
Validation loss: 2.563043394396382

Epoch: 31| Step: 0
Training loss: 2.369737386703491
Validation loss: 2.5319390322572444

Epoch: 5| Step: 1
Training loss: 2.686739683151245
Validation loss: 2.476084065693681

Epoch: 5| Step: 2
Training loss: 3.0442490577697754
Validation loss: 2.4552579695178616

Epoch: 5| Step: 3
Training loss: 2.4348466396331787
Validation loss: 2.4466581165149646

Epoch: 5| Step: 4
Training loss: 3.7172234058380127
Validation loss: 2.4487104467166367

Epoch: 5| Step: 5
Training loss: 2.278587818145752
Validation loss: 2.4469465901774745

Epoch: 5| Step: 6
Training loss: 2.4400768280029297
Validation loss: 2.4498684278098484

Epoch: 5| Step: 7
Training loss: 2.603925943374634
Validation loss: 2.4475329819545952

Epoch: 5| Step: 8
Training loss: 2.925858736038208
Validation loss: 2.443082167256263

Epoch: 5| Step: 9
Training loss: 2.8214950561523438
Validation loss: 2.441373066235614

Epoch: 5| Step: 10
Training loss: 2.5670981407165527
Validation loss: 2.446214461839327

Epoch: 32| Step: 0
Training loss: 3.066610336303711
Validation loss: 2.442641117239511

Epoch: 5| Step: 1
Training loss: 2.608217716217041
Validation loss: 2.4386303450471614

Epoch: 5| Step: 2
Training loss: 3.090947151184082
Validation loss: 2.4394816993385233

Epoch: 5| Step: 3
Training loss: 2.556013345718384
Validation loss: 2.439372993284656

Epoch: 5| Step: 4
Training loss: 2.942758083343506
Validation loss: 2.444791514386413

Epoch: 5| Step: 5
Training loss: 2.908834218978882
Validation loss: 2.4559304380929596

Epoch: 5| Step: 6
Training loss: 2.5117533206939697
Validation loss: 2.4855700769732074

Epoch: 5| Step: 7
Training loss: 2.8336875438690186
Validation loss: 2.50527685944752

Epoch: 5| Step: 8
Training loss: 2.4554741382598877
Validation loss: 2.4924633861869894

Epoch: 5| Step: 9
Training loss: 2.394054889678955
Validation loss: 2.4638254052849224

Epoch: 5| Step: 10
Training loss: 2.0661487579345703
Validation loss: 2.45219091446169

Epoch: 33| Step: 0
Training loss: 2.772371768951416
Validation loss: 2.4333124494039886

Epoch: 5| Step: 1
Training loss: 2.2465803623199463
Validation loss: 2.4275855120792182

Epoch: 5| Step: 2
Training loss: 3.1949169635772705
Validation loss: 2.42472324063701

Epoch: 5| Step: 3
Training loss: 3.1293606758117676
Validation loss: 2.416824435675016

Epoch: 5| Step: 4
Training loss: 2.983595848083496
Validation loss: 2.418828143868395

Epoch: 5| Step: 5
Training loss: 2.4307260513305664
Validation loss: 2.4170479492474626

Epoch: 5| Step: 6
Training loss: 2.516113758087158
Validation loss: 2.4149927657137633

Epoch: 5| Step: 7
Training loss: 2.9175384044647217
Validation loss: 2.4256214377700642

Epoch: 5| Step: 8
Training loss: 2.7218353748321533
Validation loss: 2.4338245468754924

Epoch: 5| Step: 9
Training loss: 2.4720828533172607
Validation loss: 2.4588947680688675

Epoch: 5| Step: 10
Training loss: 1.8428187370300293
Validation loss: 2.474542599852367

Epoch: 34| Step: 0
Training loss: 2.5341713428497314
Validation loss: 2.5217245266001713

Epoch: 5| Step: 1
Training loss: 2.4235167503356934
Validation loss: 2.5329873023494596

Epoch: 5| Step: 2
Training loss: 3.772331953048706
Validation loss: 2.5316278549932663

Epoch: 5| Step: 3
Training loss: 2.5046520233154297
Validation loss: 2.4727325490725938

Epoch: 5| Step: 4
Training loss: 2.847510814666748
Validation loss: 2.448746188994377

Epoch: 5| Step: 5
Training loss: 2.3723459243774414
Validation loss: 2.4389380229416715

Epoch: 5| Step: 6
Training loss: 1.8714427947998047
Validation loss: 2.440096898745465

Epoch: 5| Step: 7
Training loss: 2.184030532836914
Validation loss: 2.454626826829808

Epoch: 5| Step: 8
Training loss: 2.9518721103668213
Validation loss: 2.444152101393669

Epoch: 5| Step: 9
Training loss: 3.2249279022216797
Validation loss: 2.433085018588651

Epoch: 5| Step: 10
Training loss: 2.9758260250091553
Validation loss: 2.4304893632088937

Epoch: 35| Step: 0
Training loss: 2.3391470909118652
Validation loss: 2.423226629534075

Epoch: 5| Step: 1
Training loss: 3.163487672805786
Validation loss: 2.424219677525182

Epoch: 5| Step: 2
Training loss: 2.3783364295959473
Validation loss: 2.423097202854772

Epoch: 5| Step: 3
Training loss: 2.7599356174468994
Validation loss: 2.426872520036595

Epoch: 5| Step: 4
Training loss: 2.8920059204101562
Validation loss: 2.430296233905259

Epoch: 5| Step: 5
Training loss: 2.5458216667175293
Validation loss: 2.4192282294714325

Epoch: 5| Step: 6
Training loss: 2.577120542526245
Validation loss: 2.4185133493074806

Epoch: 5| Step: 7
Training loss: 3.2275500297546387
Validation loss: 2.441507767605525

Epoch: 5| Step: 8
Training loss: 2.2403721809387207
Validation loss: 2.4759495565968175

Epoch: 5| Step: 9
Training loss: 2.6634304523468018
Validation loss: 2.4972751627686205

Epoch: 5| Step: 10
Training loss: 2.4077796936035156
Validation loss: 2.496986399414719

Epoch: 36| Step: 0
Training loss: 3.222388744354248
Validation loss: 2.4918835393844114

Epoch: 5| Step: 1
Training loss: 2.4182491302490234
Validation loss: 2.4476276418214202

Epoch: 5| Step: 2
Training loss: 2.652578353881836
Validation loss: 2.4305459683941257

Epoch: 5| Step: 3
Training loss: 3.256190538406372
Validation loss: 2.4099682454139955

Epoch: 5| Step: 4
Training loss: 2.6026127338409424
Validation loss: 2.3990793510149886

Epoch: 5| Step: 5
Training loss: 2.481715202331543
Validation loss: 2.4010302174475884

Epoch: 5| Step: 6
Training loss: 2.007702589035034
Validation loss: 2.3997000417401715

Epoch: 5| Step: 7
Training loss: 2.709585428237915
Validation loss: 2.395159245819174

Epoch: 5| Step: 8
Training loss: 2.6404826641082764
Validation loss: 2.3959620088659306

Epoch: 5| Step: 9
Training loss: 2.9763941764831543
Validation loss: 2.3921122063872633

Epoch: 5| Step: 10
Training loss: 2.187260389328003
Validation loss: 2.40002352704284

Epoch: 37| Step: 0
Training loss: 3.5153069496154785
Validation loss: 2.417157598721084

Epoch: 5| Step: 1
Training loss: 2.5484819412231445
Validation loss: 2.427890803224297

Epoch: 5| Step: 2
Training loss: 2.4372591972351074
Validation loss: 2.431950902426115

Epoch: 5| Step: 3
Training loss: 2.498070001602173
Validation loss: 2.4458251999270533

Epoch: 5| Step: 4
Training loss: 2.266124725341797
Validation loss: 2.461638832605013

Epoch: 5| Step: 5
Training loss: 2.0084991455078125
Validation loss: 2.482787637300389

Epoch: 5| Step: 6
Training loss: 2.896998643875122
Validation loss: 2.5085124815663984

Epoch: 5| Step: 7
Training loss: 2.8055975437164307
Validation loss: 2.4838372071584067

Epoch: 5| Step: 8
Training loss: 2.4157183170318604
Validation loss: 2.4424343493676957

Epoch: 5| Step: 9
Training loss: 3.310749053955078
Validation loss: 2.395602322393848

Epoch: 5| Step: 10
Training loss: 2.431918144226074
Validation loss: 2.3868076186026297

Epoch: 38| Step: 0
Training loss: 3.120673179626465
Validation loss: 2.3841311393245572

Epoch: 5| Step: 1
Training loss: 2.681226968765259
Validation loss: 2.391561701733579

Epoch: 5| Step: 2
Training loss: 2.4369635581970215
Validation loss: 2.3906004505772747

Epoch: 5| Step: 3
Training loss: 2.360408306121826
Validation loss: 2.3948445115038144

Epoch: 5| Step: 4
Training loss: 2.563736915588379
Validation loss: 2.396897250606168

Epoch: 5| Step: 5
Training loss: 2.8470046520233154
Validation loss: 2.39619436828039

Epoch: 5| Step: 6
Training loss: 2.97721791267395
Validation loss: 2.396404527848767

Epoch: 5| Step: 7
Training loss: 2.135451555252075
Validation loss: 2.3927563787788473

Epoch: 5| Step: 8
Training loss: 2.823380708694458
Validation loss: 2.389729836935638

Epoch: 5| Step: 9
Training loss: 2.845181703567505
Validation loss: 2.379710469194638

Epoch: 5| Step: 10
Training loss: 2.496417999267578
Validation loss: 2.3837460266646517

Epoch: 39| Step: 0
Training loss: 2.8817811012268066
Validation loss: 2.39315204979271

Epoch: 5| Step: 1
Training loss: 2.4588370323181152
Validation loss: 2.4283074204639723

Epoch: 5| Step: 2
Training loss: 3.511812686920166
Validation loss: 2.4946838117414907

Epoch: 5| Step: 3
Training loss: 2.5573394298553467
Validation loss: 2.520495130169776

Epoch: 5| Step: 4
Training loss: 3.0305228233337402
Validation loss: 2.4798421167558238

Epoch: 5| Step: 5
Training loss: 1.9577869176864624
Validation loss: 2.4035963281508415

Epoch: 5| Step: 6
Training loss: 2.5242466926574707
Validation loss: 2.387581568892284

Epoch: 5| Step: 7
Training loss: 2.8461296558380127
Validation loss: 2.377711634482107

Epoch: 5| Step: 8
Training loss: 2.579403877258301
Validation loss: 2.382631448007399

Epoch: 5| Step: 9
Training loss: 2.3229212760925293
Validation loss: 2.404235541179616

Epoch: 5| Step: 10
Training loss: 2.5749428272247314
Validation loss: 2.4181657222009476

Epoch: 40| Step: 0
Training loss: 3.067178726196289
Validation loss: 2.3985217976313766

Epoch: 5| Step: 1
Training loss: 2.5329394340515137
Validation loss: 2.3942083927892868

Epoch: 5| Step: 2
Training loss: 2.7601821422576904
Validation loss: 2.3929341608478176

Epoch: 5| Step: 3
Training loss: 2.7215464115142822
Validation loss: 2.3942468191987727

Epoch: 5| Step: 4
Training loss: 2.5938193798065186
Validation loss: 2.401678523709697

Epoch: 5| Step: 5
Training loss: 2.397463321685791
Validation loss: 2.4042017382960164

Epoch: 5| Step: 6
Training loss: 2.873206615447998
Validation loss: 2.427302901462842

Epoch: 5| Step: 7
Training loss: 2.465909957885742
Validation loss: 2.4658603360576015

Epoch: 5| Step: 8
Training loss: 1.7543132305145264
Validation loss: 2.518705262932726

Epoch: 5| Step: 9
Training loss: 3.1061062812805176
Validation loss: 2.55617497556953

Epoch: 5| Step: 10
Training loss: 3.0303118228912354
Validation loss: 2.4940125352592877

Epoch: 41| Step: 0
Training loss: 2.743777275085449
Validation loss: 2.4501909850746073

Epoch: 5| Step: 1
Training loss: 2.3324222564697266
Validation loss: 2.392822293825047

Epoch: 5| Step: 2
Training loss: 2.5795788764953613
Validation loss: 2.3729139630512526

Epoch: 5| Step: 3
Training loss: 2.3640732765197754
Validation loss: 2.370349253377607

Epoch: 5| Step: 4
Training loss: 2.644892930984497
Validation loss: 2.3746492016700005

Epoch: 5| Step: 5
Training loss: 2.6520910263061523
Validation loss: 2.3750313097430813

Epoch: 5| Step: 6
Training loss: 2.906372547149658
Validation loss: 2.370519038169615

Epoch: 5| Step: 7
Training loss: 2.048750638961792
Validation loss: 2.3658498589710524

Epoch: 5| Step: 8
Training loss: 3.0952041149139404
Validation loss: 2.3643821234344156

Epoch: 5| Step: 9
Training loss: 2.8273401260375977
Validation loss: 2.3659394556476223

Epoch: 5| Step: 10
Training loss: 2.698821544647217
Validation loss: 2.3620352232328026

Epoch: 42| Step: 0
Training loss: 2.3044281005859375
Validation loss: 2.366892030162196

Epoch: 5| Step: 1
Training loss: 3.1718251705169678
Validation loss: 2.377802946234262

Epoch: 5| Step: 2
Training loss: 2.7779953479766846
Validation loss: 2.4184835931306243

Epoch: 5| Step: 3
Training loss: 2.4540672302246094
Validation loss: 2.482272986442812

Epoch: 5| Step: 4
Training loss: 2.4992902278900146
Validation loss: 2.550034805010724

Epoch: 5| Step: 5
Training loss: 2.8848681449890137
Validation loss: 2.524560441253006

Epoch: 5| Step: 6
Training loss: 2.8960399627685547
Validation loss: 2.4497858426904164

Epoch: 5| Step: 7
Training loss: 2.2569007873535156
Validation loss: 2.3807357383030716

Epoch: 5| Step: 8
Training loss: 2.4539432525634766
Validation loss: 2.3745742613269436

Epoch: 5| Step: 9
Training loss: 2.5362141132354736
Validation loss: 2.4051528387172247

Epoch: 5| Step: 10
Training loss: 3.231964111328125
Validation loss: 2.493001743029523

Epoch: 43| Step: 0
Training loss: 2.862527370452881
Validation loss: 2.5136128343561643

Epoch: 5| Step: 1
Training loss: 2.042619228363037
Validation loss: 2.552020431846701

Epoch: 5| Step: 2
Training loss: 3.0156469345092773
Validation loss: 2.539051230235766

Epoch: 5| Step: 3
Training loss: 2.6911420822143555
Validation loss: 2.476921445579939

Epoch: 5| Step: 4
Training loss: 3.373337507247925
Validation loss: 2.4344960720308366

Epoch: 5| Step: 5
Training loss: 2.8101840019226074
Validation loss: 2.3900177299335437

Epoch: 5| Step: 6
Training loss: 2.211564064025879
Validation loss: 2.3825299047654673

Epoch: 5| Step: 7
Training loss: 2.9177732467651367
Validation loss: 2.408139782567178

Epoch: 5| Step: 8
Training loss: 2.472564220428467
Validation loss: 2.440452819229454

Epoch: 5| Step: 9
Training loss: 2.4274392127990723
Validation loss: 2.493900050399124

Epoch: 5| Step: 10
Training loss: 3.0332014560699463
Validation loss: 2.5127783885566135

Epoch: 44| Step: 0
Training loss: 2.621634006500244
Validation loss: 2.4892136127718034

Epoch: 5| Step: 1
Training loss: 2.6770577430725098
Validation loss: 2.4678389487727994

Epoch: 5| Step: 2
Training loss: 1.899979829788208
Validation loss: 2.4356720114267

Epoch: 5| Step: 3
Training loss: 2.5199756622314453
Validation loss: 2.4330773045939784

Epoch: 5| Step: 4
Training loss: 3.636279582977295
Validation loss: 2.444180573186567

Epoch: 5| Step: 5
Training loss: 2.400153875350952
Validation loss: 2.43524532933389

Epoch: 5| Step: 6
Training loss: 2.5974979400634766
Validation loss: 2.409118124233779

Epoch: 5| Step: 7
Training loss: 2.8456931114196777
Validation loss: 2.378941923059443

Epoch: 5| Step: 8
Training loss: 2.587470769882202
Validation loss: 2.3544227871843564

Epoch: 5| Step: 9
Training loss: 2.3639140129089355
Validation loss: 2.3411473997177614

Epoch: 5| Step: 10
Training loss: 2.723747730255127
Validation loss: 2.337366860399964

Epoch: 45| Step: 0
Training loss: 2.8881137371063232
Validation loss: 2.338551195718909

Epoch: 5| Step: 1
Training loss: 2.916189432144165
Validation loss: 2.345097659736551

Epoch: 5| Step: 2
Training loss: 2.169844150543213
Validation loss: 2.342152028955439

Epoch: 5| Step: 3
Training loss: 3.2871272563934326
Validation loss: 2.3416661703458397

Epoch: 5| Step: 4
Training loss: 2.4111454486846924
Validation loss: 2.344630346503309

Epoch: 5| Step: 5
Training loss: 2.6670756340026855
Validation loss: 2.3467673281187653

Epoch: 5| Step: 6
Training loss: 2.5391056537628174
Validation loss: 2.347127181227489

Epoch: 5| Step: 7
Training loss: 2.428272008895874
Validation loss: 2.3551460568622877

Epoch: 5| Step: 8
Training loss: 2.180818557739258
Validation loss: 2.3549848525754866

Epoch: 5| Step: 9
Training loss: 2.802306652069092
Validation loss: 2.364135919078704

Epoch: 5| Step: 10
Training loss: 2.6648480892181396
Validation loss: 2.370585767171716

Epoch: 46| Step: 0
Training loss: 2.258864402770996
Validation loss: 2.3932069091386694

Epoch: 5| Step: 1
Training loss: 2.9520134925842285
Validation loss: 2.4091834945063435

Epoch: 5| Step: 2
Training loss: 2.4651787281036377
Validation loss: 2.406791910048454

Epoch: 5| Step: 3
Training loss: 2.1370840072631836
Validation loss: 2.391655447662518

Epoch: 5| Step: 4
Training loss: 2.5347177982330322
Validation loss: 2.3806307879827355

Epoch: 5| Step: 5
Training loss: 2.464273452758789
Validation loss: 2.3579953152646302

Epoch: 5| Step: 6
Training loss: 2.97261381149292
Validation loss: 2.3466243679805467

Epoch: 5| Step: 7
Training loss: 1.9533172845840454
Validation loss: 2.338695505613922

Epoch: 5| Step: 8
Training loss: 2.7616419792175293
Validation loss: 2.337159202944848

Epoch: 5| Step: 9
Training loss: 2.727454662322998
Validation loss: 2.3268300487149145

Epoch: 5| Step: 10
Training loss: 3.559363842010498
Validation loss: 2.319666113904727

Epoch: 47| Step: 0
Training loss: 2.6796534061431885
Validation loss: 2.322101595581219

Epoch: 5| Step: 1
Training loss: 2.4575085639953613
Validation loss: 2.3250602829840874

Epoch: 5| Step: 2
Training loss: 2.9661335945129395
Validation loss: 2.3242743540835638

Epoch: 5| Step: 3
Training loss: 2.766725540161133
Validation loss: 2.320886004355646

Epoch: 5| Step: 4
Training loss: 2.821683883666992
Validation loss: 2.3188248552301878

Epoch: 5| Step: 5
Training loss: 3.156644582748413
Validation loss: 2.3207506428482714

Epoch: 5| Step: 6
Training loss: 2.5193159580230713
Validation loss: 2.3240907192230225

Epoch: 5| Step: 7
Training loss: 2.4786014556884766
Validation loss: 2.3258172183908443

Epoch: 5| Step: 8
Training loss: 2.3257317543029785
Validation loss: 2.326455049617316

Epoch: 5| Step: 9
Training loss: 1.9190391302108765
Validation loss: 2.3295909538063952

Epoch: 5| Step: 10
Training loss: 2.3728160858154297
Validation loss: 2.3392084542141167

Epoch: 48| Step: 0
Training loss: 3.3832225799560547
Validation loss: 2.3494704308048373

Epoch: 5| Step: 1
Training loss: 2.45196533203125
Validation loss: 2.330968097973895

Epoch: 5| Step: 2
Training loss: 2.1382288932800293
Validation loss: 2.327063463067496

Epoch: 5| Step: 3
Training loss: 2.8401923179626465
Validation loss: 2.322203815624278

Epoch: 5| Step: 4
Training loss: 1.9642804861068726
Validation loss: 2.3192224887109574

Epoch: 5| Step: 5
Training loss: 2.710594415664673
Validation loss: 2.313802517870421

Epoch: 5| Step: 6
Training loss: 2.8558573722839355
Validation loss: 2.3190576030362036

Epoch: 5| Step: 7
Training loss: 2.1174752712249756
Validation loss: 2.311140497525533

Epoch: 5| Step: 8
Training loss: 2.7338316440582275
Validation loss: 2.315134549653658

Epoch: 5| Step: 9
Training loss: 2.6056747436523438
Validation loss: 2.306676741569273

Epoch: 5| Step: 10
Training loss: 2.565730094909668
Validation loss: 2.3087916784389044

Epoch: 49| Step: 0
Training loss: 2.6653499603271484
Validation loss: 2.3071096609997492

Epoch: 5| Step: 1
Training loss: 2.1492362022399902
Validation loss: 2.3124424052494827

Epoch: 5| Step: 2
Training loss: 3.6312007904052734
Validation loss: 2.320858440091533

Epoch: 5| Step: 3
Training loss: 2.189584255218506
Validation loss: 2.3206956360929754

Epoch: 5| Step: 4
Training loss: 2.7380571365356445
Validation loss: 2.318753691129787

Epoch: 5| Step: 5
Training loss: 2.531513214111328
Validation loss: 2.309348180729856

Epoch: 5| Step: 6
Training loss: 2.240813732147217
Validation loss: 2.3017538491115777

Epoch: 5| Step: 7
Training loss: 2.539734125137329
Validation loss: 2.3065604215027182

Epoch: 5| Step: 8
Training loss: 2.850472927093506
Validation loss: 2.3260952298359205

Epoch: 5| Step: 9
Training loss: 2.259904146194458
Validation loss: 2.344438883566087

Epoch: 5| Step: 10
Training loss: 2.44677472114563
Validation loss: 2.382526784814814

Epoch: 50| Step: 0
Training loss: 2.5952470302581787
Validation loss: 2.396605184001307

Epoch: 5| Step: 1
Training loss: 2.9436371326446533
Validation loss: 2.372730588400236

Epoch: 5| Step: 2
Training loss: 2.8145930767059326
Validation loss: 2.3281848456269953

Epoch: 5| Step: 3
Training loss: 3.043358325958252
Validation loss: 2.2913106897825837

Epoch: 5| Step: 4
Training loss: 2.817558526992798
Validation loss: 2.283381090369276

Epoch: 5| Step: 5
Training loss: 2.568758726119995
Validation loss: 2.289501195312828

Epoch: 5| Step: 6
Training loss: 2.090663433074951
Validation loss: 2.316689996309178

Epoch: 5| Step: 7
Training loss: 2.9386894702911377
Validation loss: 2.352502699821226

Epoch: 5| Step: 8
Training loss: 2.5952835083007812
Validation loss: 2.37677623123251

Epoch: 5| Step: 9
Training loss: 1.9843196868896484
Validation loss: 2.4075175818576606

Epoch: 5| Step: 10
Training loss: 2.5482888221740723
Validation loss: 2.4155595405127412

Epoch: 51| Step: 0
Training loss: 2.064314365386963
Validation loss: 2.39598024019631

Epoch: 5| Step: 1
Training loss: 3.3284080028533936
Validation loss: 2.3775760922380673

Epoch: 5| Step: 2
Training loss: 3.1751537322998047
Validation loss: 2.3553245298324095

Epoch: 5| Step: 3
Training loss: 3.1082286834716797
Validation loss: 2.348079889051376

Epoch: 5| Step: 4
Training loss: 3.142120361328125
Validation loss: 2.3365416936976935

Epoch: 5| Step: 5
Training loss: 2.3032615184783936
Validation loss: 2.332650056449316

Epoch: 5| Step: 6
Training loss: 2.060323476791382
Validation loss: 2.315390574034824

Epoch: 5| Step: 7
Training loss: 2.469299793243408
Validation loss: 2.3060904138831684

Epoch: 5| Step: 8
Training loss: 2.261190176010132
Validation loss: 2.3149350791849117

Epoch: 5| Step: 9
Training loss: 2.2286293506622314
Validation loss: 2.3342788373270342

Epoch: 5| Step: 10
Training loss: 2.642069101333618
Validation loss: 2.3574397743389173

Epoch: 52| Step: 0
Training loss: 2.5151751041412354
Validation loss: 2.3886355097575853

Epoch: 5| Step: 1
Training loss: 2.855381727218628
Validation loss: 2.38845290548058

Epoch: 5| Step: 2
Training loss: 3.0329909324645996
Validation loss: 2.398617221463111

Epoch: 5| Step: 3
Training loss: 2.02069091796875
Validation loss: 2.3857766043755317

Epoch: 5| Step: 4
Training loss: 2.5314395427703857
Validation loss: 2.4037384589513144

Epoch: 5| Step: 5
Training loss: 2.770888090133667
Validation loss: 2.448047217502389

Epoch: 5| Step: 6
Training loss: 2.5984606742858887
Validation loss: 2.43013072013855

Epoch: 5| Step: 7
Training loss: 3.0625791549682617
Validation loss: 2.347351843310941

Epoch: 5| Step: 8
Training loss: 2.36669921875
Validation loss: 2.2959090458449496

Epoch: 5| Step: 9
Training loss: 2.6647839546203613
Validation loss: 2.2734781413949947

Epoch: 5| Step: 10
Training loss: 2.2290289402008057
Validation loss: 2.2741106120488976

Epoch: 53| Step: 0
Training loss: 2.8774919509887695
Validation loss: 2.266074748449428

Epoch: 5| Step: 1
Training loss: 2.559555768966675
Validation loss: 2.266174490733813

Epoch: 5| Step: 2
Training loss: 2.5189127922058105
Validation loss: 2.267352880970124

Epoch: 5| Step: 3
Training loss: 2.1766135692596436
Validation loss: 2.2698673894328456

Epoch: 5| Step: 4
Training loss: 2.3229641914367676
Validation loss: 2.267798359676074

Epoch: 5| Step: 5
Training loss: 2.6781630516052246
Validation loss: 2.265413527847618

Epoch: 5| Step: 6
Training loss: 2.8482251167297363
Validation loss: 2.2630673454653834

Epoch: 5| Step: 7
Training loss: 2.800713300704956
Validation loss: 2.263938555153467

Epoch: 5| Step: 8
Training loss: 2.7632217407226562
Validation loss: 2.2659136992628857

Epoch: 5| Step: 9
Training loss: 2.389146566390991
Validation loss: 2.2628581370076826

Epoch: 5| Step: 10
Training loss: 2.3555126190185547
Validation loss: 2.263828064805718

Epoch: 54| Step: 0
Training loss: 1.755636215209961
Validation loss: 2.2757831670904674

Epoch: 5| Step: 1
Training loss: 2.7327780723571777
Validation loss: 2.285381314575031

Epoch: 5| Step: 2
Training loss: 2.733208417892456
Validation loss: 2.321184688998807

Epoch: 5| Step: 3
Training loss: 2.802323341369629
Validation loss: 2.351009033059561

Epoch: 5| Step: 4
Training loss: 2.7311770915985107
Validation loss: 2.3574276252459456

Epoch: 5| Step: 5
Training loss: 2.6703786849975586
Validation loss: 2.3395128711577384

Epoch: 5| Step: 6
Training loss: 2.76686954498291
Validation loss: 2.3302037677457257

Epoch: 5| Step: 7
Training loss: 2.6430563926696777
Validation loss: 2.3324835620900637

Epoch: 5| Step: 8
Training loss: 2.8847358226776123
Validation loss: 2.3127889940815587

Epoch: 5| Step: 9
Training loss: 2.0824763774871826
Validation loss: 2.290100751384612

Epoch: 5| Step: 10
Training loss: 2.4555246829986572
Validation loss: 2.288425732684392

Epoch: 55| Step: 0
Training loss: 2.4423398971557617
Validation loss: 2.283259307184527

Epoch: 5| Step: 1
Training loss: 1.759563684463501
Validation loss: 2.283957076329057

Epoch: 5| Step: 2
Training loss: 2.735248565673828
Validation loss: 2.2841986815134683

Epoch: 5| Step: 3
Training loss: 2.6952710151672363
Validation loss: 2.2859709211575088

Epoch: 5| Step: 4
Training loss: 2.6859564781188965
Validation loss: 2.28579609112073

Epoch: 5| Step: 5
Training loss: 2.545186758041382
Validation loss: 2.286164488843692

Epoch: 5| Step: 6
Training loss: 2.3507678508758545
Validation loss: 2.291801734637189

Epoch: 5| Step: 7
Training loss: 3.511023998260498
Validation loss: 2.297981613425798

Epoch: 5| Step: 8
Training loss: 2.9453494548797607
Validation loss: 2.3016280999747654

Epoch: 5| Step: 9
Training loss: 1.732466697692871
Validation loss: 2.3073997933377504

Epoch: 5| Step: 10
Training loss: 2.679082155227661
Validation loss: 2.3134520617864465

Epoch: 56| Step: 0
Training loss: 2.0657057762145996
Validation loss: 2.3109828964356454

Epoch: 5| Step: 1
Training loss: 2.474508762359619
Validation loss: 2.312563229632634

Epoch: 5| Step: 2
Training loss: 1.8541253805160522
Validation loss: 2.309512512658232

Epoch: 5| Step: 3
Training loss: 2.481236696243286
Validation loss: 2.3116175205476823

Epoch: 5| Step: 4
Training loss: 3.2019355297088623
Validation loss: 2.3027043034953456

Epoch: 5| Step: 5
Training loss: 2.7342019081115723
Validation loss: 2.2965967501363447

Epoch: 5| Step: 6
Training loss: 2.6608951091766357
Validation loss: 2.2753755431021414

Epoch: 5| Step: 7
Training loss: 2.1858315467834473
Validation loss: 2.271764482221296

Epoch: 5| Step: 8
Training loss: 2.597339153289795
Validation loss: 2.272821710955712

Epoch: 5| Step: 9
Training loss: 2.769068717956543
Validation loss: 2.2612836386567805

Epoch: 5| Step: 10
Training loss: 3.0374481678009033
Validation loss: 2.26041325189734

Epoch: 57| Step: 0
Training loss: 2.5214743614196777
Validation loss: 2.2488057510827177

Epoch: 5| Step: 1
Training loss: 2.447760820388794
Validation loss: 2.24771370169937

Epoch: 5| Step: 2
Training loss: 2.654479503631592
Validation loss: 2.2415585581974318

Epoch: 5| Step: 3
Training loss: 2.5304183959960938
Validation loss: 2.2420240986731743

Epoch: 5| Step: 4
Training loss: 2.942232131958008
Validation loss: 2.243246927056261

Epoch: 5| Step: 5
Training loss: 2.3214662075042725
Validation loss: 2.24735919121773

Epoch: 5| Step: 6
Training loss: 2.1644091606140137
Validation loss: 2.2477100985024565

Epoch: 5| Step: 7
Training loss: 1.9546940326690674
Validation loss: 2.240865061360021

Epoch: 5| Step: 8
Training loss: 2.8988595008850098
Validation loss: 2.2389028995267806

Epoch: 5| Step: 9
Training loss: 2.860384464263916
Validation loss: 2.259213452698082

Epoch: 5| Step: 10
Training loss: 2.753694534301758
Validation loss: 2.2828157101908038

Epoch: 58| Step: 0
Training loss: 2.894178867340088
Validation loss: 2.285907599233812

Epoch: 5| Step: 1
Training loss: 2.166450262069702
Validation loss: 2.2972164359143985

Epoch: 5| Step: 2
Training loss: 2.8327033519744873
Validation loss: 2.297241057119062

Epoch: 5| Step: 3
Training loss: 2.318422555923462
Validation loss: 2.29286648637505

Epoch: 5| Step: 4
Training loss: 2.553865909576416
Validation loss: 2.2912097925780923

Epoch: 5| Step: 5
Training loss: 2.912959575653076
Validation loss: 2.2918465598937003

Epoch: 5| Step: 6
Training loss: 2.688659191131592
Validation loss: 2.2658952666867163

Epoch: 5| Step: 7
Training loss: 2.355830669403076
Validation loss: 2.249557718153923

Epoch: 5| Step: 8
Training loss: 2.634852886199951
Validation loss: 2.244381353419314

Epoch: 5| Step: 9
Training loss: 2.487536907196045
Validation loss: 2.239470210126651

Epoch: 5| Step: 10
Training loss: 2.0919010639190674
Validation loss: 2.2387945882735716

Epoch: 59| Step: 0
Training loss: 2.518662929534912
Validation loss: 2.2386235165339645

Epoch: 5| Step: 1
Training loss: 2.7220635414123535
Validation loss: 2.2338894438999954

Epoch: 5| Step: 2
Training loss: 2.4593052864074707
Validation loss: 2.232667007753926

Epoch: 5| Step: 3
Training loss: 3.0275583267211914
Validation loss: 2.2304472846369587

Epoch: 5| Step: 4
Training loss: 2.5918686389923096
Validation loss: 2.2291240217865154

Epoch: 5| Step: 5
Training loss: 2.449467420578003
Validation loss: 2.2256626518823768

Epoch: 5| Step: 6
Training loss: 2.35023832321167
Validation loss: 2.2264398067228255

Epoch: 5| Step: 7
Training loss: 2.143852949142456
Validation loss: 2.222565871413036

Epoch: 5| Step: 8
Training loss: 2.3741302490234375
Validation loss: 2.216166134803526

Epoch: 5| Step: 9
Training loss: 3.005326986312866
Validation loss: 2.221404108949887

Epoch: 5| Step: 10
Training loss: 2.3850905895233154
Validation loss: 2.224538141681302

Epoch: 60| Step: 0
Training loss: 2.567553997039795
Validation loss: 2.22758565666855

Epoch: 5| Step: 1
Training loss: 2.7348790168762207
Validation loss: 2.2372480002782678

Epoch: 5| Step: 2
Training loss: 2.248826265335083
Validation loss: 2.2454501916003484

Epoch: 5| Step: 3
Training loss: 2.383507490158081
Validation loss: 2.256202297825967

Epoch: 5| Step: 4
Training loss: 2.1807188987731934
Validation loss: 2.26090177412956

Epoch: 5| Step: 5
Training loss: 2.2648510932922363
Validation loss: 2.256550806824879

Epoch: 5| Step: 6
Training loss: 3.0888895988464355
Validation loss: 2.250393282982611

Epoch: 5| Step: 7
Training loss: 2.0784964561462402
Validation loss: 2.235348511767644

Epoch: 5| Step: 8
Training loss: 3.014373779296875
Validation loss: 2.230725182000027

Epoch: 5| Step: 9
Training loss: 2.773541212081909
Validation loss: 2.226792461128645

Epoch: 5| Step: 10
Training loss: 2.466430425643921
Validation loss: 2.22482499512293

Epoch: 61| Step: 0
Training loss: 2.539077043533325
Validation loss: 2.238122240189583

Epoch: 5| Step: 1
Training loss: 2.524723768234253
Validation loss: 2.2452668977040116

Epoch: 5| Step: 2
Training loss: 2.230569839477539
Validation loss: 2.247350145411748

Epoch: 5| Step: 3
Training loss: 2.337219715118408
Validation loss: 2.2384142798762166

Epoch: 5| Step: 4
Training loss: 2.5749900341033936
Validation loss: 2.2441550121512464

Epoch: 5| Step: 5
Training loss: 2.8163962364196777
Validation loss: 2.229841975755589

Epoch: 5| Step: 6
Training loss: 3.0715346336364746
Validation loss: 2.215586026509603

Epoch: 5| Step: 7
Training loss: 2.896941661834717
Validation loss: 2.213299428263018

Epoch: 5| Step: 8
Training loss: 2.320286273956299
Validation loss: 2.2036069208575833

Epoch: 5| Step: 9
Training loss: 2.5245604515075684
Validation loss: 2.2009908614620084

Epoch: 5| Step: 10
Training loss: 1.7669469118118286
Validation loss: 2.1996692585688766

Epoch: 62| Step: 0
Training loss: 2.327859401702881
Validation loss: 2.2028584275194394

Epoch: 5| Step: 1
Training loss: 2.7405660152435303
Validation loss: 2.208443796762856

Epoch: 5| Step: 2
Training loss: 2.582195281982422
Validation loss: 2.2090807576333322

Epoch: 5| Step: 3
Training loss: 2.777663230895996
Validation loss: 2.2238958074200537

Epoch: 5| Step: 4
Training loss: 2.4871182441711426
Validation loss: 2.253324108739053

Epoch: 5| Step: 5
Training loss: 2.692279577255249
Validation loss: 2.243638833363851

Epoch: 5| Step: 6
Training loss: 2.8651223182678223
Validation loss: 2.247923599776401

Epoch: 5| Step: 7
Training loss: 2.080198287963867
Validation loss: 2.2245034222961753

Epoch: 5| Step: 8
Training loss: 2.066476345062256
Validation loss: 2.195455402456304

Epoch: 5| Step: 9
Training loss: 2.480100154876709
Validation loss: 2.193474784974129

Epoch: 5| Step: 10
Training loss: 2.7530646324157715
Validation loss: 2.1911828992187337

Epoch: 63| Step: 0
Training loss: 2.2223896980285645
Validation loss: 2.1955079724711757

Epoch: 5| Step: 1
Training loss: 2.275259017944336
Validation loss: 2.1968336412983556

Epoch: 5| Step: 2
Training loss: 2.7763638496398926
Validation loss: 2.200026745437294

Epoch: 5| Step: 3
Training loss: 2.6445133686065674
Validation loss: 2.200021905283774

Epoch: 5| Step: 4
Training loss: 3.043006181716919
Validation loss: 2.2118022518773235

Epoch: 5| Step: 5
Training loss: 3.144660234451294
Validation loss: 2.2276588409177718

Epoch: 5| Step: 6
Training loss: 2.816075086593628
Validation loss: 2.2400070339120846

Epoch: 5| Step: 7
Training loss: 2.4532129764556885
Validation loss: 2.2753531996921827

Epoch: 5| Step: 8
Training loss: 1.7913753986358643
Validation loss: 2.293199408438898

Epoch: 5| Step: 9
Training loss: 1.7931591272354126
Validation loss: 2.2966170977520686

Epoch: 5| Step: 10
Training loss: 3.0219240188598633
Validation loss: 2.2937708106092227

Epoch: 64| Step: 0
Training loss: 2.155144691467285
Validation loss: 2.2760818209699405

Epoch: 5| Step: 1
Training loss: 2.6064934730529785
Validation loss: 2.2694211313801427

Epoch: 5| Step: 2
Training loss: 2.864882469177246
Validation loss: 2.2341638841936664

Epoch: 5| Step: 3
Training loss: 2.3968143463134766
Validation loss: 2.226488367203743

Epoch: 5| Step: 4
Training loss: 2.690624713897705
Validation loss: 2.2195894025987193

Epoch: 5| Step: 5
Training loss: 2.650161027908325
Validation loss: 2.220239600827617

Epoch: 5| Step: 6
Training loss: 1.8645210266113281
Validation loss: 2.2163680368854153

Epoch: 5| Step: 7
Training loss: 2.275644063949585
Validation loss: 2.218887472665438

Epoch: 5| Step: 8
Training loss: 2.81406569480896
Validation loss: 2.219597751094449

Epoch: 5| Step: 9
Training loss: 2.4297733306884766
Validation loss: 2.2183227949245

Epoch: 5| Step: 10
Training loss: 2.944868803024292
Validation loss: 2.2100246824244016

Epoch: 65| Step: 0
Training loss: 2.7825379371643066
Validation loss: 2.211899972731067

Epoch: 5| Step: 1
Training loss: 2.7284467220306396
Validation loss: 2.2123376515603836

Epoch: 5| Step: 2
Training loss: 2.339028835296631
Validation loss: 2.2149922283746863

Epoch: 5| Step: 3
Training loss: 2.456653118133545
Validation loss: 2.2170732290514055

Epoch: 5| Step: 4
Training loss: 2.667245388031006
Validation loss: 2.220517696872834

Epoch: 5| Step: 5
Training loss: 2.4820494651794434
Validation loss: 2.2182639401446105

Epoch: 5| Step: 6
Training loss: 1.9015957117080688
Validation loss: 2.2159273419328915

Epoch: 5| Step: 7
Training loss: 2.7412097454071045
Validation loss: 2.2185065092579013

Epoch: 5| Step: 8
Training loss: 2.709745407104492
Validation loss: 2.21532783457028

Epoch: 5| Step: 9
Training loss: 2.4445290565490723
Validation loss: 2.2091572400062316

Epoch: 5| Step: 10
Training loss: 2.26540470123291
Validation loss: 2.209815714948921

Epoch: 66| Step: 0
Training loss: 2.186309337615967
Validation loss: 2.2164501836222987

Epoch: 5| Step: 1
Training loss: 2.7219338417053223
Validation loss: 2.2254065236737652

Epoch: 5| Step: 2
Training loss: 2.859224319458008
Validation loss: 2.237709355610673

Epoch: 5| Step: 3
Training loss: 2.9700279235839844
Validation loss: 2.247139992252473

Epoch: 5| Step: 4
Training loss: 2.838327407836914
Validation loss: 2.219155814058037

Epoch: 5| Step: 5
Training loss: 2.5186972618103027
Validation loss: 2.1961401354882026

Epoch: 5| Step: 6
Training loss: 2.0283572673797607
Validation loss: 2.1857800099157516

Epoch: 5| Step: 7
Training loss: 2.491739273071289
Validation loss: 2.1753047050968295

Epoch: 5| Step: 8
Training loss: 1.8938134908676147
Validation loss: 2.1785066589232414

Epoch: 5| Step: 9
Training loss: 2.2379918098449707
Validation loss: 2.1719587297849756

Epoch: 5| Step: 10
Training loss: 2.8207790851593018
Validation loss: 2.1702723298021542

Epoch: 67| Step: 0
Training loss: 2.6210601329803467
Validation loss: 2.1708836709299395

Epoch: 5| Step: 1
Training loss: 2.439222812652588
Validation loss: 2.172853873622033

Epoch: 5| Step: 2
Training loss: 2.4521565437316895
Validation loss: 2.171395609455724

Epoch: 5| Step: 3
Training loss: 2.1609046459198
Validation loss: 2.182613803494361

Epoch: 5| Step: 4
Training loss: 2.5994760990142822
Validation loss: 2.183442561857162

Epoch: 5| Step: 5
Training loss: 2.4995205402374268
Validation loss: 2.1981115033549647

Epoch: 5| Step: 6
Training loss: 2.5771701335906982
Validation loss: 2.198669820703486

Epoch: 5| Step: 7
Training loss: 2.448713779449463
Validation loss: 2.2144987890797276

Epoch: 5| Step: 8
Training loss: 2.6954798698425293
Validation loss: 2.1955327141669487

Epoch: 5| Step: 9
Training loss: 2.884787082672119
Validation loss: 2.178319295247396

Epoch: 5| Step: 10
Training loss: 2.0150933265686035
Validation loss: 2.165805055249122

Epoch: 68| Step: 0
Training loss: 1.9563955068588257
Validation loss: 2.1727584497902983

Epoch: 5| Step: 1
Training loss: 2.8690249919891357
Validation loss: 2.1598564835004908

Epoch: 5| Step: 2
Training loss: 2.5518696308135986
Validation loss: 2.1584260514987412

Epoch: 5| Step: 3
Training loss: 2.301344633102417
Validation loss: 2.1650792424396803

Epoch: 5| Step: 4
Training loss: 2.8271145820617676
Validation loss: 2.1678701728902836

Epoch: 5| Step: 5
Training loss: 2.783024549484253
Validation loss: 2.1690677596676733

Epoch: 5| Step: 6
Training loss: 2.305623769760132
Validation loss: 2.1679685833633586

Epoch: 5| Step: 7
Training loss: 2.5307273864746094
Validation loss: 2.166038103001092

Epoch: 5| Step: 8
Training loss: 2.577162742614746
Validation loss: 2.165200146295691

Epoch: 5| Step: 9
Training loss: 2.1030960083007812
Validation loss: 2.1752589184750795

Epoch: 5| Step: 10
Training loss: 2.607858419418335
Validation loss: 2.1761130440619683

Epoch: 69| Step: 0
Training loss: 2.2985758781433105
Validation loss: 2.186984057067543

Epoch: 5| Step: 1
Training loss: 1.9744113683700562
Validation loss: 2.203670158181139

Epoch: 5| Step: 2
Training loss: 2.591125965118408
Validation loss: 2.211701561045903

Epoch: 5| Step: 3
Training loss: 2.757267951965332
Validation loss: 2.211809842817245

Epoch: 5| Step: 4
Training loss: 2.9170823097229004
Validation loss: 2.2166053377172

Epoch: 5| Step: 5
Training loss: 2.090076208114624
Validation loss: 2.2105618394831175

Epoch: 5| Step: 6
Training loss: 2.514002561569214
Validation loss: 2.2015259445354505

Epoch: 5| Step: 7
Training loss: 2.4128172397613525
Validation loss: 2.2041788562651603

Epoch: 5| Step: 8
Training loss: 2.8875598907470703
Validation loss: 2.1800967852274575

Epoch: 5| Step: 9
Training loss: 2.621408700942993
Validation loss: 2.174280910081761

Epoch: 5| Step: 10
Training loss: 2.2926440238952637
Validation loss: 2.171651824828117

Epoch: 70| Step: 0
Training loss: 3.136472225189209
Validation loss: 2.1804609939616215

Epoch: 5| Step: 1
Training loss: 2.6805968284606934
Validation loss: 2.1775311808432303

Epoch: 5| Step: 2
Training loss: 1.8305505514144897
Validation loss: 2.1830751357540006

Epoch: 5| Step: 3
Training loss: 2.722630023956299
Validation loss: 2.1751906282158306

Epoch: 5| Step: 4
Training loss: 2.617924928665161
Validation loss: 2.178990729393498

Epoch: 5| Step: 5
Training loss: 2.857156276702881
Validation loss: 2.183353336908484

Epoch: 5| Step: 6
Training loss: 1.9434353113174438
Validation loss: 2.1859129013553744

Epoch: 5| Step: 7
Training loss: 2.3335609436035156
Validation loss: 2.2088745781170425

Epoch: 5| Step: 8
Training loss: 2.878577709197998
Validation loss: 2.222791684571133

Epoch: 5| Step: 9
Training loss: 2.1162095069885254
Validation loss: 2.175518787035378

Epoch: 5| Step: 10
Training loss: 2.0278148651123047
Validation loss: 2.158892023947931

Epoch: 71| Step: 0
Training loss: 2.6446030139923096
Validation loss: 2.157412528991699

Epoch: 5| Step: 1
Training loss: 2.7073683738708496
Validation loss: 2.155252956574963

Epoch: 5| Step: 2
Training loss: 3.0496468544006348
Validation loss: 2.150526444117228

Epoch: 5| Step: 3
Training loss: 2.409864664077759
Validation loss: 2.151559309292865

Epoch: 5| Step: 4
Training loss: 2.340150833129883
Validation loss: 2.160244708420128

Epoch: 5| Step: 5
Training loss: 2.0376784801483154
Validation loss: 2.1623765204542424

Epoch: 5| Step: 6
Training loss: 2.0167384147644043
Validation loss: 2.1665598166886197

Epoch: 5| Step: 7
Training loss: 2.906816005706787
Validation loss: 2.1873139924900507

Epoch: 5| Step: 8
Training loss: 2.9937758445739746
Validation loss: 2.201309859111745

Epoch: 5| Step: 9
Training loss: 2.1383461952209473
Validation loss: 2.1830519630062963

Epoch: 5| Step: 10
Training loss: 1.9237149953842163
Validation loss: 2.1819786679360176

Epoch: 72| Step: 0
Training loss: 2.6828720569610596
Validation loss: 2.1648589154725433

Epoch: 5| Step: 1
Training loss: 2.360069990158081
Validation loss: 2.156612544931391

Epoch: 5| Step: 2
Training loss: 2.763744831085205
Validation loss: 2.1479452066524054

Epoch: 5| Step: 3
Training loss: 2.9158382415771484
Validation loss: 2.1355604125607397

Epoch: 5| Step: 4
Training loss: 2.238190174102783
Validation loss: 2.1334073030820457

Epoch: 5| Step: 5
Training loss: 2.17924165725708
Validation loss: 2.1377701272246656

Epoch: 5| Step: 6
Training loss: 1.9140872955322266
Validation loss: 2.141219805645686

Epoch: 5| Step: 7
Training loss: 3.309051513671875
Validation loss: 2.1588014171969507

Epoch: 5| Step: 8
Training loss: 2.1730968952178955
Validation loss: 2.168275507547522

Epoch: 5| Step: 9
Training loss: 2.551532030105591
Validation loss: 2.1768118642991587

Epoch: 5| Step: 10
Training loss: 2.056635618209839
Validation loss: 2.1593251484696583

Epoch: 73| Step: 0
Training loss: 3.179504632949829
Validation loss: 2.143901599350796

Epoch: 5| Step: 1
Training loss: 2.16733980178833
Validation loss: 2.131046307984219

Epoch: 5| Step: 2
Training loss: 3.160487651824951
Validation loss: 2.1329261128620436

Epoch: 5| Step: 3
Training loss: 1.8358482122421265
Validation loss: 2.1337996580267466

Epoch: 5| Step: 4
Training loss: 1.6941074132919312
Validation loss: 2.135450601577759

Epoch: 5| Step: 5
Training loss: 2.97713041305542
Validation loss: 2.136573253139373

Epoch: 5| Step: 6
Training loss: 2.944469928741455
Validation loss: 2.137495284439415

Epoch: 5| Step: 7
Training loss: 3.0185976028442383
Validation loss: 2.1406488392942693

Epoch: 5| Step: 8
Training loss: 1.9984102249145508
Validation loss: 2.1391292297711937

Epoch: 5| Step: 9
Training loss: 2.3415539264678955
Validation loss: 2.1611997068569226

Epoch: 5| Step: 10
Training loss: 1.7158117294311523
Validation loss: 2.193970513600175

Epoch: 74| Step: 0
Training loss: 2.606733560562134
Validation loss: 2.235154392898724

Epoch: 5| Step: 1
Training loss: 2.8229129314422607
Validation loss: 2.276094618663993

Epoch: 5| Step: 2
Training loss: 2.3769257068634033
Validation loss: 2.2457190380301526

Epoch: 5| Step: 3
Training loss: 3.214101791381836
Validation loss: 2.1921993788852485

Epoch: 5| Step: 4
Training loss: 2.2080862522125244
Validation loss: 2.166080019807303

Epoch: 5| Step: 5
Training loss: 2.0176615715026855
Validation loss: 2.158222218995453

Epoch: 5| Step: 6
Training loss: 1.9243957996368408
Validation loss: 2.1579192351269465

Epoch: 5| Step: 7
Training loss: 2.518467664718628
Validation loss: 2.169074123905551

Epoch: 5| Step: 8
Training loss: 2.4561352729797363
Validation loss: 2.161801838105725

Epoch: 5| Step: 9
Training loss: 2.2263567447662354
Validation loss: 2.166625820180421

Epoch: 5| Step: 10
Training loss: 2.802797317504883
Validation loss: 2.1707687211293045

Epoch: 75| Step: 0
Training loss: 2.740090847015381
Validation loss: 2.177854017544818

Epoch: 5| Step: 1
Training loss: 2.275254726409912
Validation loss: 2.1843421382288777

Epoch: 5| Step: 2
Training loss: 2.689802646636963
Validation loss: 2.184977460932988

Epoch: 5| Step: 3
Training loss: 2.596928834915161
Validation loss: 2.1897771896854525

Epoch: 5| Step: 4
Training loss: 2.2517714500427246
Validation loss: 2.17328538433198

Epoch: 5| Step: 5
Training loss: 2.8481874465942383
Validation loss: 2.1778091076881654

Epoch: 5| Step: 6
Training loss: 2.4461381435394287
Validation loss: 2.1664127380617204

Epoch: 5| Step: 7
Training loss: 2.385953187942505
Validation loss: 2.1572780865494923

Epoch: 5| Step: 8
Training loss: 2.1254420280456543
Validation loss: 2.156089100786435

Epoch: 5| Step: 9
Training loss: 2.1960625648498535
Validation loss: 2.1532891360662316

Epoch: 5| Step: 10
Training loss: 2.354297399520874
Validation loss: 2.144523764169344

Epoch: 76| Step: 0
Training loss: 2.1245405673980713
Validation loss: 2.1395065707545124

Epoch: 5| Step: 1
Training loss: 2.2672910690307617
Validation loss: 2.144094467163086

Epoch: 5| Step: 2
Training loss: 2.389768362045288
Validation loss: 2.162494718387563

Epoch: 5| Step: 3
Training loss: 2.9289605617523193
Validation loss: 2.1794334406493814

Epoch: 5| Step: 4
Training loss: 2.439073085784912
Validation loss: 2.1962352747558267

Epoch: 5| Step: 5
Training loss: 2.8582730293273926
Validation loss: 2.2216525334183888

Epoch: 5| Step: 6
Training loss: 2.023170232772827
Validation loss: 2.215921276359148

Epoch: 5| Step: 7
Training loss: 2.7291414737701416
Validation loss: 2.1877557718625633

Epoch: 5| Step: 8
Training loss: 1.9146041870117188
Validation loss: 2.167874300351707

Epoch: 5| Step: 9
Training loss: 2.7371039390563965
Validation loss: 2.1716550063061457

Epoch: 5| Step: 10
Training loss: 2.6157872676849365
Validation loss: 2.189178894924861

Epoch: 77| Step: 0
Training loss: 2.551450252532959
Validation loss: 2.2007541400130077

Epoch: 5| Step: 1
Training loss: 2.548955202102661
Validation loss: 2.199721159473542

Epoch: 5| Step: 2
Training loss: 3.1326637268066406
Validation loss: 2.200632688819721

Epoch: 5| Step: 3
Training loss: 2.0640432834625244
Validation loss: 2.1735303376310613

Epoch: 5| Step: 4
Training loss: 2.2884912490844727
Validation loss: 2.156168859492066

Epoch: 5| Step: 5
Training loss: 2.0525527000427246
Validation loss: 2.1605724198843843

Epoch: 5| Step: 6
Training loss: 2.5674147605895996
Validation loss: 2.1843561959523026

Epoch: 5| Step: 7
Training loss: 2.9832425117492676
Validation loss: 2.243730996244697

Epoch: 5| Step: 8
Training loss: 2.7747926712036133
Validation loss: 2.3082292105561946

Epoch: 5| Step: 9
Training loss: 2.4158241748809814
Validation loss: 2.289918198380419

Epoch: 5| Step: 10
Training loss: 2.160207748413086
Validation loss: 2.2571691159279115

Epoch: 78| Step: 0
Training loss: 2.634554862976074
Validation loss: 2.2055747957639795

Epoch: 5| Step: 1
Training loss: 2.6512954235076904
Validation loss: 2.167071165577058

Epoch: 5| Step: 2
Training loss: 2.2470884323120117
Validation loss: 2.1226905879154

Epoch: 5| Step: 3
Training loss: 2.504164457321167
Validation loss: 2.121354196661262

Epoch: 5| Step: 4
Training loss: 2.143798828125
Validation loss: 2.131658684822821

Epoch: 5| Step: 5
Training loss: 3.2235260009765625
Validation loss: 2.122359468090919

Epoch: 5| Step: 6
Training loss: 2.1742660999298096
Validation loss: 2.125323736539451

Epoch: 5| Step: 7
Training loss: 2.4297900199890137
Validation loss: 2.097817461977723

Epoch: 5| Step: 8
Training loss: 3.0634987354278564
Validation loss: 2.095407211652366

Epoch: 5| Step: 9
Training loss: 2.0852348804473877
Validation loss: 2.1068634858695408

Epoch: 5| Step: 10
Training loss: 1.787647008895874
Validation loss: 2.1358155191585584

Epoch: 79| Step: 0
Training loss: 2.480093002319336
Validation loss: 2.1575890382130942

Epoch: 5| Step: 1
Training loss: 2.40000057220459
Validation loss: 2.191443422789215

Epoch: 5| Step: 2
Training loss: 3.0989859104156494
Validation loss: 2.1942731321498914

Epoch: 5| Step: 3
Training loss: 2.309232711791992
Validation loss: 2.191593198366063

Epoch: 5| Step: 4
Training loss: 2.2637720108032227
Validation loss: 2.1710690067660425

Epoch: 5| Step: 5
Training loss: 2.515263319015503
Validation loss: 2.134398824425154

Epoch: 5| Step: 6
Training loss: 2.504401206970215
Validation loss: 2.127037189340079

Epoch: 5| Step: 7
Training loss: 2.106205701828003
Validation loss: 2.131790502097017

Epoch: 5| Step: 8
Training loss: 2.842402219772339
Validation loss: 2.1414482952446066

Epoch: 5| Step: 9
Training loss: 2.4887213706970215
Validation loss: 2.1317190329233804

Epoch: 5| Step: 10
Training loss: 1.7687225341796875
Validation loss: 2.1196984219294723

Epoch: 80| Step: 0
Training loss: 2.4632065296173096
Validation loss: 2.1109711790597565

Epoch: 5| Step: 1
Training loss: 2.959596633911133
Validation loss: 2.1234636229853474

Epoch: 5| Step: 2
Training loss: 1.8831901550292969
Validation loss: 2.1283527279412873

Epoch: 5| Step: 3
Training loss: 2.366708517074585
Validation loss: 2.1474123642008793

Epoch: 5| Step: 4
Training loss: 2.249882459640503
Validation loss: 2.159888635399521

Epoch: 5| Step: 5
Training loss: 2.379135847091675
Validation loss: 2.1379203783568514

Epoch: 5| Step: 6
Training loss: 2.541465997695923
Validation loss: 2.1148454937883603

Epoch: 5| Step: 7
Training loss: 2.530118703842163
Validation loss: 2.105382732165757

Epoch: 5| Step: 8
Training loss: 2.284470319747925
Validation loss: 2.099478138390408

Epoch: 5| Step: 9
Training loss: 2.3921618461608887
Validation loss: 2.085452938592562

Epoch: 5| Step: 10
Training loss: 2.575061082839966
Validation loss: 2.095571143652803

Epoch: 81| Step: 0
Training loss: 2.3449318408966064
Validation loss: 2.091912382392473

Epoch: 5| Step: 1
Training loss: 2.1514527797698975
Validation loss: 2.0853665144212785

Epoch: 5| Step: 2
Training loss: 2.46938419342041
Validation loss: 2.090549886867564

Epoch: 5| Step: 3
Training loss: 2.210952043533325
Validation loss: 2.0972103918752363

Epoch: 5| Step: 4
Training loss: 2.3095810413360596
Validation loss: 2.097836184245284

Epoch: 5| Step: 5
Training loss: 2.3020718097686768
Validation loss: 2.1075480702102825

Epoch: 5| Step: 6
Training loss: 2.9301459789276123
Validation loss: 2.126982206939369

Epoch: 5| Step: 7
Training loss: 2.204662799835205
Validation loss: 2.1401231660637805

Epoch: 5| Step: 8
Training loss: 3.3224434852600098
Validation loss: 2.1580090368947675

Epoch: 5| Step: 9
Training loss: 2.0530149936676025
Validation loss: 2.1504816752608105

Epoch: 5| Step: 10
Training loss: 2.3629631996154785
Validation loss: 2.1532375479257233

Epoch: 82| Step: 0
Training loss: 2.2376868724823
Validation loss: 2.135021686553955

Epoch: 5| Step: 1
Training loss: 2.647557258605957
Validation loss: 2.1301201005135812

Epoch: 5| Step: 2
Training loss: 1.9104278087615967
Validation loss: 2.128153085708618

Epoch: 5| Step: 3
Training loss: 2.2709908485412598
Validation loss: 2.1196802610992105

Epoch: 5| Step: 4
Training loss: 2.272387742996216
Validation loss: 2.1160132628615185

Epoch: 5| Step: 5
Training loss: 3.0350089073181152
Validation loss: 2.119885395931941

Epoch: 5| Step: 6
Training loss: 2.5151309967041016
Validation loss: 2.1107283766551683

Epoch: 5| Step: 7
Training loss: 2.288916826248169
Validation loss: 2.1132438285376436

Epoch: 5| Step: 8
Training loss: 2.1376872062683105
Validation loss: 2.115118667643557

Epoch: 5| Step: 9
Training loss: 2.523474931716919
Validation loss: 2.118508296628152

Epoch: 5| Step: 10
Training loss: 2.9613916873931885
Validation loss: 2.1274439365633073

Epoch: 83| Step: 0
Training loss: 1.7510967254638672
Validation loss: 2.140643059566457

Epoch: 5| Step: 1
Training loss: 2.7498509883880615
Validation loss: 2.1404743579126175

Epoch: 5| Step: 2
Training loss: 2.322319269180298
Validation loss: 2.1256794814140565

Epoch: 5| Step: 3
Training loss: 2.2350006103515625
Validation loss: 2.1431554799438803

Epoch: 5| Step: 4
Training loss: 2.089064836502075
Validation loss: 2.1680785097101682

Epoch: 5| Step: 5
Training loss: 3.394181728363037
Validation loss: 2.189077772119994

Epoch: 5| Step: 6
Training loss: 2.335001230239868
Validation loss: 2.1763391648569415

Epoch: 5| Step: 7
Training loss: 2.58339262008667
Validation loss: 2.165477560412499

Epoch: 5| Step: 8
Training loss: 2.9416821002960205
Validation loss: 2.142176676821965

Epoch: 5| Step: 9
Training loss: 1.8057159185409546
Validation loss: 2.1304724498461654

Epoch: 5| Step: 10
Training loss: 2.38322377204895
Validation loss: 2.1070904398477204

Epoch: 84| Step: 0
Training loss: 2.5476245880126953
Validation loss: 2.1116519871578423

Epoch: 5| Step: 1
Training loss: 2.1623783111572266
Validation loss: 2.1074095541431057

Epoch: 5| Step: 2
Training loss: 2.2735352516174316
Validation loss: 2.1080653654631747

Epoch: 5| Step: 3
Training loss: 2.843299388885498
Validation loss: 2.106550142329226

Epoch: 5| Step: 4
Training loss: 1.7657947540283203
Validation loss: 2.105380132634153

Epoch: 5| Step: 5
Training loss: 2.4644391536712646
Validation loss: 2.124045443791215

Epoch: 5| Step: 6
Training loss: 2.3530116081237793
Validation loss: 2.1412449626512426

Epoch: 5| Step: 7
Training loss: 2.6410973072052
Validation loss: 2.144382183269788

Epoch: 5| Step: 8
Training loss: 2.2499566078186035
Validation loss: 2.136219398949736

Epoch: 5| Step: 9
Training loss: 3.052457332611084
Validation loss: 2.1258272919603574

Epoch: 5| Step: 10
Training loss: 2.238804578781128
Validation loss: 2.1169852133720153

Epoch: 85| Step: 0
Training loss: 2.0729026794433594
Validation loss: 2.109879024567143

Epoch: 5| Step: 1
Training loss: 2.2536215782165527
Validation loss: 2.09886670625338

Epoch: 5| Step: 2
Training loss: 2.7295050621032715
Validation loss: 2.106283805703604

Epoch: 5| Step: 3
Training loss: 2.447547197341919
Validation loss: 2.0947009235300045

Epoch: 5| Step: 4
Training loss: 2.003203868865967
Validation loss: 2.099358147190463

Epoch: 5| Step: 5
Training loss: 2.1217968463897705
Validation loss: 2.0921374072310743

Epoch: 5| Step: 6
Training loss: 2.588475465774536
Validation loss: 2.0912146837480607

Epoch: 5| Step: 7
Training loss: 1.8681347370147705
Validation loss: 2.084062360948132

Epoch: 5| Step: 8
Training loss: 3.168513774871826
Validation loss: 2.0802557186413835

Epoch: 5| Step: 9
Training loss: 2.506277084350586
Validation loss: 2.0835336087852396

Epoch: 5| Step: 10
Training loss: 2.6544015407562256
Validation loss: 2.098350099337998

Epoch: 86| Step: 0
Training loss: 2.5872159004211426
Validation loss: 2.13380854616883

Epoch: 5| Step: 1
Training loss: 2.026777744293213
Validation loss: 2.17402978609967

Epoch: 5| Step: 2
Training loss: 1.9327888488769531
Validation loss: 2.1759505374457246

Epoch: 5| Step: 3
Training loss: 2.4835495948791504
Validation loss: 2.159239202417353

Epoch: 5| Step: 4
Training loss: 2.7340033054351807
Validation loss: 2.117093204170145

Epoch: 5| Step: 5
Training loss: 3.1666481494903564
Validation loss: 2.081250444535286

Epoch: 5| Step: 6
Training loss: 2.458580493927002
Validation loss: 2.06964676098157

Epoch: 5| Step: 7
Training loss: 2.316783905029297
Validation loss: 2.06349241605369

Epoch: 5| Step: 8
Training loss: 2.4588794708251953
Validation loss: 2.079752722094136

Epoch: 5| Step: 9
Training loss: 2.371591567993164
Validation loss: 2.074905639053673

Epoch: 5| Step: 10
Training loss: 2.0663836002349854
Validation loss: 2.0860015628158406

Epoch: 87| Step: 0
Training loss: 2.831153154373169
Validation loss: 2.1111877015841904

Epoch: 5| Step: 1
Training loss: 2.4134440422058105
Validation loss: 2.1233149472103325

Epoch: 5| Step: 2
Training loss: 2.800924777984619
Validation loss: 2.12423889611357

Epoch: 5| Step: 3
Training loss: 2.5580639839172363
Validation loss: 2.1302560978038336

Epoch: 5| Step: 4
Training loss: 2.159425973892212
Validation loss: 2.1369819423203826

Epoch: 5| Step: 5
Training loss: 2.3125336170196533
Validation loss: 2.1729598019712713

Epoch: 5| Step: 6
Training loss: 2.4690041542053223
Validation loss: 2.1949104391118532

Epoch: 5| Step: 7
Training loss: 1.887536644935608
Validation loss: 2.186201598054619

Epoch: 5| Step: 8
Training loss: 1.9508569240570068
Validation loss: 2.1673141346182874

Epoch: 5| Step: 9
Training loss: 2.2465333938598633
Validation loss: 2.1527442932128906

Epoch: 5| Step: 10
Training loss: 2.988494634628296
Validation loss: 2.158821528957736

Epoch: 88| Step: 0
Training loss: 2.4429497718811035
Validation loss: 2.1713463644827566

Epoch: 5| Step: 1
Training loss: 2.286853313446045
Validation loss: 2.20272893803094

Epoch: 5| Step: 2
Training loss: 2.9418489933013916
Validation loss: 2.201523465494956

Epoch: 5| Step: 3
Training loss: 2.633002519607544
Validation loss: 2.2101087057462303

Epoch: 5| Step: 4
Training loss: 2.3520402908325195
Validation loss: 2.159473672989876

Epoch: 5| Step: 5
Training loss: 2.103748083114624
Validation loss: 2.1284888611044934

Epoch: 5| Step: 6
Training loss: 2.3147835731506348
Validation loss: 2.120474665395675

Epoch: 5| Step: 7
Training loss: 2.022261381149292
Validation loss: 2.1187402279146257

Epoch: 5| Step: 8
Training loss: 2.231924533843994
Validation loss: 2.109551032384237

Epoch: 5| Step: 9
Training loss: 3.1553237438201904
Validation loss: 2.0989044225344093

Epoch: 5| Step: 10
Training loss: 2.1049647331237793
Validation loss: 2.1023542111919773

Epoch: 89| Step: 0
Training loss: 2.4650747776031494
Validation loss: 2.10339641827409

Epoch: 5| Step: 1
Training loss: 2.6053054332733154
Validation loss: 2.095533945227182

Epoch: 5| Step: 2
Training loss: 2.5007591247558594
Validation loss: 2.0871099784810054

Epoch: 5| Step: 3
Training loss: 2.2931442260742188
Validation loss: 2.0825224256002777

Epoch: 5| Step: 4
Training loss: 2.812948703765869
Validation loss: 2.068496609246859

Epoch: 5| Step: 5
Training loss: 2.507922410964966
Validation loss: 2.0575590018303163

Epoch: 5| Step: 6
Training loss: 2.7114834785461426
Validation loss: 2.0690116625960155

Epoch: 5| Step: 7
Training loss: 2.5605106353759766
Validation loss: 2.073394101153138

Epoch: 5| Step: 8
Training loss: 1.5905014276504517
Validation loss: 2.081476631984916

Epoch: 5| Step: 9
Training loss: 1.6991907358169556
Validation loss: 2.0760931737961306

Epoch: 5| Step: 10
Training loss: 2.6493427753448486
Validation loss: 2.0810465735773884

Epoch: 90| Step: 0
Training loss: 2.255319118499756
Validation loss: 2.0909610627799906

Epoch: 5| Step: 1
Training loss: 2.332507371902466
Validation loss: 2.0976040811948877

Epoch: 5| Step: 2
Training loss: 2.7837748527526855
Validation loss: 2.099094478032922

Epoch: 5| Step: 3
Training loss: 2.346592426300049
Validation loss: 2.0740303506133375

Epoch: 5| Step: 4
Training loss: 2.274071455001831
Validation loss: 2.0544573517255884

Epoch: 5| Step: 5
Training loss: 2.1331875324249268
Validation loss: 2.043915815250848

Epoch: 5| Step: 6
Training loss: 2.4830164909362793
Validation loss: 2.038370886156636

Epoch: 5| Step: 7
Training loss: 2.1893703937530518
Validation loss: 2.0420289436976113

Epoch: 5| Step: 8
Training loss: 2.720475673675537
Validation loss: 2.0416002081286524

Epoch: 5| Step: 9
Training loss: 3.049360752105713
Validation loss: 2.032906275923534

Epoch: 5| Step: 10
Training loss: 1.6434900760650635
Validation loss: 2.045288534574611

Epoch: 91| Step: 0
Training loss: 2.814058780670166
Validation loss: 2.0641409799616826

Epoch: 5| Step: 1
Training loss: 1.9944051504135132
Validation loss: 2.0767892714469665

Epoch: 5| Step: 2
Training loss: 2.4079833030700684
Validation loss: 2.1050660687108196

Epoch: 5| Step: 3
Training loss: 2.6770637035369873
Validation loss: 2.186966633283964

Epoch: 5| Step: 4
Training loss: 2.5931172370910645
Validation loss: 2.25326967752108

Epoch: 5| Step: 5
Training loss: 2.077458381652832
Validation loss: 2.282820068379884

Epoch: 5| Step: 6
Training loss: 2.304628372192383
Validation loss: 2.213898117824267

Epoch: 5| Step: 7
Training loss: 2.464144706726074
Validation loss: 2.1682863132928007

Epoch: 5| Step: 8
Training loss: 2.5431177616119385
Validation loss: 2.157273934733483

Epoch: 5| Step: 9
Training loss: 2.6094045639038086
Validation loss: 2.1156563553758847

Epoch: 5| Step: 10
Training loss: 1.8364590406417847
Validation loss: 2.060255187813954

Epoch: 92| Step: 0
Training loss: 2.0983595848083496
Validation loss: 2.0429399667247647

Epoch: 5| Step: 1
Training loss: 2.3564887046813965
Validation loss: 2.034295792220741

Epoch: 5| Step: 2
Training loss: 2.1731910705566406
Validation loss: 2.032243005691036

Epoch: 5| Step: 3
Training loss: 2.617809295654297
Validation loss: 2.036074471730058

Epoch: 5| Step: 4
Training loss: 2.584805488586426
Validation loss: 2.03130708202239

Epoch: 5| Step: 5
Training loss: 2.1567161083221436
Validation loss: 2.0436191904929375

Epoch: 5| Step: 6
Training loss: 2.542534351348877
Validation loss: 2.0392760038375854

Epoch: 5| Step: 7
Training loss: 2.2517929077148438
Validation loss: 2.0523312937828804

Epoch: 5| Step: 8
Training loss: 2.093313694000244
Validation loss: 2.0745914495119484

Epoch: 5| Step: 9
Training loss: 2.593097686767578
Validation loss: 2.072928049231088

Epoch: 5| Step: 10
Training loss: 2.5156164169311523
Validation loss: 2.063234434332899

Epoch: 93| Step: 0
Training loss: 1.901206374168396
Validation loss: 2.056466289745864

Epoch: 5| Step: 1
Training loss: 2.850860118865967
Validation loss: 2.0672714210325673

Epoch: 5| Step: 2
Training loss: 2.3830208778381348
Validation loss: 2.0885658699979066

Epoch: 5| Step: 3
Training loss: 2.1205506324768066
Validation loss: 2.078036026288104

Epoch: 5| Step: 4
Training loss: 2.1126341819763184
Validation loss: 2.075944487766553

Epoch: 5| Step: 5
Training loss: 2.3679728507995605
Validation loss: 2.058560417544457

Epoch: 5| Step: 6
Training loss: 2.127473831176758
Validation loss: 2.0470572697219027

Epoch: 5| Step: 7
Training loss: 1.9833757877349854
Validation loss: 2.0529473468821537

Epoch: 5| Step: 8
Training loss: 2.8649497032165527
Validation loss: 2.0527738627567085

Epoch: 5| Step: 9
Training loss: 2.6692116260528564
Validation loss: 2.052752173075112

Epoch: 5| Step: 10
Training loss: 2.580833911895752
Validation loss: 2.053099665590512

Epoch: 94| Step: 0
Training loss: 2.977356195449829
Validation loss: 2.0494192954032653

Epoch: 5| Step: 1
Training loss: 2.1372647285461426
Validation loss: 2.0545959331656016

Epoch: 5| Step: 2
Training loss: 2.4547953605651855
Validation loss: 2.0567372178518646

Epoch: 5| Step: 3
Training loss: 2.9916069507598877
Validation loss: 2.086832854055589

Epoch: 5| Step: 4
Training loss: 2.3676350116729736
Validation loss: 2.1209517883998092

Epoch: 5| Step: 5
Training loss: 2.0885820388793945
Validation loss: 2.1139440498044415

Epoch: 5| Step: 6
Training loss: 2.108297348022461
Validation loss: 2.10958969208502

Epoch: 5| Step: 7
Training loss: 1.81548273563385
Validation loss: 2.113652075490644

Epoch: 5| Step: 8
Training loss: 2.0084376335144043
Validation loss: 2.04857260821968

Epoch: 5| Step: 9
Training loss: 2.781994342803955
Validation loss: 2.025331715101837

Epoch: 5| Step: 10
Training loss: 2.256396532058716
Validation loss: 2.0308245625547183

Epoch: 95| Step: 0
Training loss: 2.3523013591766357
Validation loss: 2.030159309346189

Epoch: 5| Step: 1
Training loss: 1.817025899887085
Validation loss: 2.0373198550234557

Epoch: 5| Step: 2
Training loss: 2.3613967895507812
Validation loss: 2.0490543073223484

Epoch: 5| Step: 3
Training loss: 2.5467629432678223
Validation loss: 2.0346313586799045

Epoch: 5| Step: 4
Training loss: 2.2087631225585938
Validation loss: 2.035319032207612

Epoch: 5| Step: 5
Training loss: 2.565668821334839
Validation loss: 2.0554635755477415

Epoch: 5| Step: 6
Training loss: 2.453742504119873
Validation loss: 2.072188195361886

Epoch: 5| Step: 7
Training loss: 2.3393733501434326
Validation loss: 2.109016820948611

Epoch: 5| Step: 8
Training loss: 2.3734214305877686
Validation loss: 2.1236829629508396

Epoch: 5| Step: 9
Training loss: 2.623138904571533
Validation loss: 2.1420171799198275

Epoch: 5| Step: 10
Training loss: 2.418256998062134
Validation loss: 2.1380907361225416

Epoch: 96| Step: 0
Training loss: 1.639240026473999
Validation loss: 2.1024350658539803

Epoch: 5| Step: 1
Training loss: 2.4216811656951904
Validation loss: 2.067197402318319

Epoch: 5| Step: 2
Training loss: 2.6696763038635254
Validation loss: 2.0511815022396784

Epoch: 5| Step: 3
Training loss: 3.007185459136963
Validation loss: 2.0564552712184128

Epoch: 5| Step: 4
Training loss: 2.421243667602539
Validation loss: 2.0430034168304934

Epoch: 5| Step: 5
Training loss: 1.703454613685608
Validation loss: 2.0382941128105245

Epoch: 5| Step: 6
Training loss: 1.9361053705215454
Validation loss: 2.038383412104781

Epoch: 5| Step: 7
Training loss: 2.691909074783325
Validation loss: 2.0302132201451126

Epoch: 5| Step: 8
Training loss: 2.119446277618408
Validation loss: 2.0268947744882233

Epoch: 5| Step: 9
Training loss: 2.775822401046753
Validation loss: 2.038511465954524

Epoch: 5| Step: 10
Training loss: 2.3173274993896484
Validation loss: 2.0589438433288247

Epoch: 97| Step: 0
Training loss: 1.8213716745376587
Validation loss: 2.0452128353939263

Epoch: 5| Step: 1
Training loss: 2.544344425201416
Validation loss: 2.0297448699192335

Epoch: 5| Step: 2
Training loss: 1.8518165349960327
Validation loss: 2.04811946294641

Epoch: 5| Step: 3
Training loss: 2.500392198562622
Validation loss: 2.056390336764756

Epoch: 5| Step: 4
Training loss: 2.952085494995117
Validation loss: 2.0646639049694104

Epoch: 5| Step: 5
Training loss: 2.7258381843566895
Validation loss: 2.0589142781431957

Epoch: 5| Step: 6
Training loss: 1.8770557641983032
Validation loss: 2.071774987764256

Epoch: 5| Step: 7
Training loss: 2.5444860458374023
Validation loss: 2.0507965498073126

Epoch: 5| Step: 8
Training loss: 1.9977216720581055
Validation loss: 2.0319767036745624

Epoch: 5| Step: 9
Training loss: 2.1558425426483154
Validation loss: 2.0136378247250795

Epoch: 5| Step: 10
Training loss: 2.798452854156494
Validation loss: 2.0192981484115764

Epoch: 98| Step: 0
Training loss: 2.5864923000335693
Validation loss: 2.0210418290989374

Epoch: 5| Step: 1
Training loss: 2.1976776123046875
Validation loss: 2.0205696449484876

Epoch: 5| Step: 2
Training loss: 3.2741539478302
Validation loss: 2.0282673835754395

Epoch: 5| Step: 3
Training loss: 3.0998458862304688
Validation loss: 2.028803986887778

Epoch: 5| Step: 4
Training loss: 2.5278639793395996
Validation loss: 2.0332866650755688

Epoch: 5| Step: 5
Training loss: 1.4616190195083618
Validation loss: 2.0541780738420385

Epoch: 5| Step: 6
Training loss: 1.8508670330047607
Validation loss: 2.0749689276500414

Epoch: 5| Step: 7
Training loss: 2.364530086517334
Validation loss: 2.1021787351177585

Epoch: 5| Step: 8
Training loss: 2.281283140182495
Validation loss: 2.1234950968014297

Epoch: 5| Step: 9
Training loss: 2.208042621612549
Validation loss: 2.158977900781939

Epoch: 5| Step: 10
Training loss: 1.9266998767852783
Validation loss: 2.120402897557905

Epoch: 99| Step: 0
Training loss: 2.3945279121398926
Validation loss: 2.0997635087659283

Epoch: 5| Step: 1
Training loss: 2.511547088623047
Validation loss: 2.063571622294764

Epoch: 5| Step: 2
Training loss: 2.3712708950042725
Validation loss: 2.046648335713212

Epoch: 5| Step: 3
Training loss: 2.3861172199249268
Validation loss: 2.0407527069891653

Epoch: 5| Step: 4
Training loss: 2.2494683265686035
Validation loss: 2.0386864857007096

Epoch: 5| Step: 5
Training loss: 2.3663642406463623
Validation loss: 2.045274628105984

Epoch: 5| Step: 6
Training loss: 1.9388542175292969
Validation loss: 2.039114937987379

Epoch: 5| Step: 7
Training loss: 2.8845136165618896
Validation loss: 2.0547476019910587

Epoch: 5| Step: 8
Training loss: 2.002535104751587
Validation loss: 2.0603764544251146

Epoch: 5| Step: 9
Training loss: 2.1186654567718506
Validation loss: 2.074365741463118

Epoch: 5| Step: 10
Training loss: 2.612532138824463
Validation loss: 2.0904795508230887

Epoch: 100| Step: 0
Training loss: 2.2128565311431885
Validation loss: 2.1057906125181463

Epoch: 5| Step: 1
Training loss: 2.7497215270996094
Validation loss: 2.092695241333336

Epoch: 5| Step: 2
Training loss: 2.3594555854797363
Validation loss: 2.0759976833097395

Epoch: 5| Step: 3
Training loss: 1.957645058631897
Validation loss: 2.0794395644177674

Epoch: 5| Step: 4
Training loss: 2.8120803833007812
Validation loss: 2.063824663880051

Epoch: 5| Step: 5
Training loss: 2.4943251609802246
Validation loss: 2.056535046587708

Epoch: 5| Step: 6
Training loss: 1.6598069667816162
Validation loss: 2.049159578097764

Epoch: 5| Step: 7
Training loss: 1.7688465118408203
Validation loss: 2.029564985664942

Epoch: 5| Step: 8
Training loss: 2.613673686981201
Validation loss: 2.0213504734859673

Epoch: 5| Step: 9
Training loss: 2.7491631507873535
Validation loss: 2.016662298992116

Epoch: 5| Step: 10
Training loss: 2.131845474243164
Validation loss: 2.013218774590441

Epoch: 101| Step: 0
Training loss: 2.042126178741455
Validation loss: 2.0035222191964426

Epoch: 5| Step: 1
Training loss: 2.297201633453369
Validation loss: 2.00849469759131

Epoch: 5| Step: 2
Training loss: 2.9186344146728516
Validation loss: 2.0351418782305974

Epoch: 5| Step: 3
Training loss: 2.5057315826416016
Validation loss: 2.0552206218883557

Epoch: 5| Step: 4
Training loss: 2.231555938720703
Validation loss: 2.119818038837884

Epoch: 5| Step: 5
Training loss: 3.20678448677063
Validation loss: 2.181012991935976

Epoch: 5| Step: 6
Training loss: 2.113799810409546
Validation loss: 2.132822767380745

Epoch: 5| Step: 7
Training loss: 1.9242337942123413
Validation loss: 2.0884005715770106

Epoch: 5| Step: 8
Training loss: 1.7853784561157227
Validation loss: 2.04075429901

Epoch: 5| Step: 9
Training loss: 2.1391243934631348
Validation loss: 2.0198732986245105

Epoch: 5| Step: 10
Training loss: 2.60368275642395
Validation loss: 2.007070482418101

Epoch: 102| Step: 0
Training loss: 1.9534887075424194
Validation loss: 2.014068721443094

Epoch: 5| Step: 1
Training loss: 2.4677507877349854
Validation loss: 2.0061795916608585

Epoch: 5| Step: 2
Training loss: 2.160884141921997
Validation loss: 2.020853991149574

Epoch: 5| Step: 3
Training loss: 2.148545742034912
Validation loss: 2.012534224858848

Epoch: 5| Step: 4
Training loss: 2.6893982887268066
Validation loss: 2.00827020470814

Epoch: 5| Step: 5
Training loss: 2.33964467048645
Validation loss: 2.0151301737754577

Epoch: 5| Step: 6
Training loss: 3.041400671005249
Validation loss: 2.0321402011379117

Epoch: 5| Step: 7
Training loss: 1.9545942544937134
Validation loss: 2.0377224542761363

Epoch: 5| Step: 8
Training loss: 1.754514455795288
Validation loss: 2.060559008711128

Epoch: 5| Step: 9
Training loss: 2.0402112007141113
Validation loss: 2.1022160104525986

Epoch: 5| Step: 10
Training loss: 2.767854928970337
Validation loss: 2.1949103263116654

Epoch: 103| Step: 0
Training loss: 2.1694629192352295
Validation loss: 2.236199027748518

Epoch: 5| Step: 1
Training loss: 2.7332892417907715
Validation loss: 2.2384812319150535

Epoch: 5| Step: 2
Training loss: 2.3908169269561768
Validation loss: 2.179480909019388

Epoch: 5| Step: 3
Training loss: 2.1456222534179688
Validation loss: 2.1407599423521306

Epoch: 5| Step: 4
Training loss: 2.0770483016967773
Validation loss: 2.09308228441464

Epoch: 5| Step: 5
Training loss: 2.5014309883117676
Validation loss: 2.078761713479155

Epoch: 5| Step: 6
Training loss: 1.949262261390686
Validation loss: 2.0610519404052408

Epoch: 5| Step: 7
Training loss: 2.5747437477111816
Validation loss: 2.0483945851684897

Epoch: 5| Step: 8
Training loss: 2.1561923027038574
Validation loss: 2.0522941722664783

Epoch: 5| Step: 9
Training loss: 2.6068363189697266
Validation loss: 2.048018991306264

Epoch: 5| Step: 10
Training loss: 2.25882887840271
Validation loss: 2.04918743718055

Epoch: 104| Step: 0
Training loss: 2.528217077255249
Validation loss: 2.0475436590051137

Epoch: 5| Step: 1
Training loss: 2.738132953643799
Validation loss: 2.0449507313389934

Epoch: 5| Step: 2
Training loss: 1.6255457401275635
Validation loss: 2.034371401674004

Epoch: 5| Step: 3
Training loss: 1.9697211980819702
Validation loss: 2.0397020706566433

Epoch: 5| Step: 4
Training loss: 2.325530529022217
Validation loss: 2.0407145651437903

Epoch: 5| Step: 5
Training loss: 2.4509928226470947
Validation loss: 2.0364597305174796

Epoch: 5| Step: 6
Training loss: 2.449908494949341
Validation loss: 2.0263209432683964

Epoch: 5| Step: 7
Training loss: 2.6468803882598877
Validation loss: 2.029001881999354

Epoch: 5| Step: 8
Training loss: 2.025731086730957
Validation loss: 2.0326427977572203

Epoch: 5| Step: 9
Training loss: 2.201946973800659
Validation loss: 2.0549737984134304

Epoch: 5| Step: 10
Training loss: 2.162306070327759
Validation loss: 2.0742771317881923

Epoch: 105| Step: 0
Training loss: 2.5221283435821533
Validation loss: 2.0719454365391887

Epoch: 5| Step: 1
Training loss: 2.6810505390167236
Validation loss: 2.0555470835778022

Epoch: 5| Step: 2
Training loss: 1.761007308959961
Validation loss: 2.043125870407269

Epoch: 5| Step: 3
Training loss: 1.978783369064331
Validation loss: 2.0301768651572605

Epoch: 5| Step: 4
Training loss: 2.3434643745422363
Validation loss: 2.019494641211725

Epoch: 5| Step: 5
Training loss: 2.4703073501586914
Validation loss: 2.020995304148684

Epoch: 5| Step: 6
Training loss: 1.958974838256836
Validation loss: 2.0317827309331586

Epoch: 5| Step: 7
Training loss: 2.0684094429016113
Validation loss: 2.0436299231744584

Epoch: 5| Step: 8
Training loss: 3.029453754425049
Validation loss: 2.079445723564394

Epoch: 5| Step: 9
Training loss: 1.8797028064727783
Validation loss: 2.0738742966805734

Epoch: 5| Step: 10
Training loss: 2.4406380653381348
Validation loss: 2.060272096305765

Epoch: 106| Step: 0
Training loss: 2.3710689544677734
Validation loss: 2.0372810299678514

Epoch: 5| Step: 1
Training loss: 1.6266381740570068
Validation loss: 2.033141956534437

Epoch: 5| Step: 2
Training loss: 2.686028003692627
Validation loss: 2.0215577079403784

Epoch: 5| Step: 3
Training loss: 3.0853805541992188
Validation loss: 2.014866039317141

Epoch: 5| Step: 4
Training loss: 2.334646701812744
Validation loss: 2.000064984444649

Epoch: 5| Step: 5
Training loss: 2.248809814453125
Validation loss: 2.009131098306307

Epoch: 5| Step: 6
Training loss: 2.184436321258545
Validation loss: 2.004073169923598

Epoch: 5| Step: 7
Training loss: 2.0620243549346924
Validation loss: 2.0019789818794496

Epoch: 5| Step: 8
Training loss: 1.5999095439910889
Validation loss: 2.0075314698680753

Epoch: 5| Step: 9
Training loss: 2.154778003692627
Validation loss: 2.003847086301414

Epoch: 5| Step: 10
Training loss: 2.5232741832733154
Validation loss: 2.0095634588631253

Epoch: 107| Step: 0
Training loss: 2.218837022781372
Validation loss: 2.0163585819223875

Epoch: 5| Step: 1
Training loss: 2.415381908416748
Validation loss: 2.0397989314089537

Epoch: 5| Step: 2
Training loss: 2.380495071411133
Validation loss: 2.058303194661294

Epoch: 5| Step: 3
Training loss: 2.192742109298706
Validation loss: 2.094859177066434

Epoch: 5| Step: 4
Training loss: 2.8140947818756104
Validation loss: 2.0991039635032736

Epoch: 5| Step: 5
Training loss: 1.9004123210906982
Validation loss: 2.053917392607658

Epoch: 5| Step: 6
Training loss: 1.5115458965301514
Validation loss: 2.0339326038155505

Epoch: 5| Step: 7
Training loss: 1.9574966430664062
Validation loss: 2.020625522059779

Epoch: 5| Step: 8
Training loss: 2.3448326587677
Validation loss: 2.012919633619247

Epoch: 5| Step: 9
Training loss: 2.553946018218994
Validation loss: 2.0020790100097656

Epoch: 5| Step: 10
Training loss: 2.6249616146087646
Validation loss: 1.9988784226038123

Epoch: 108| Step: 0
Training loss: 2.575031280517578
Validation loss: 2.010613336358019

Epoch: 5| Step: 1
Training loss: 2.3247761726379395
Validation loss: 2.012316155177291

Epoch: 5| Step: 2
Training loss: 2.1400835514068604
Validation loss: 2.036460250936529

Epoch: 5| Step: 3
Training loss: 1.8947627544403076
Validation loss: 2.0268681985075756

Epoch: 5| Step: 4
Training loss: 2.6016476154327393
Validation loss: 2.013769668917502

Epoch: 5| Step: 5
Training loss: 1.9812843799591064
Validation loss: 2.0210074634962183

Epoch: 5| Step: 6
Training loss: 2.1199498176574707
Validation loss: 2.0384501129068355

Epoch: 5| Step: 7
Training loss: 1.9982192516326904
Validation loss: 2.0491989556179253

Epoch: 5| Step: 8
Training loss: 2.593780994415283
Validation loss: 2.0713411569595337

Epoch: 5| Step: 9
Training loss: 2.703089475631714
Validation loss: 2.0855798157312537

Epoch: 5| Step: 10
Training loss: 1.8689167499542236
Validation loss: 2.0582091744228075

Epoch: 109| Step: 0
Training loss: 2.0524449348449707
Validation loss: 2.0050002054501603

Epoch: 5| Step: 1
Training loss: 2.794029712677002
Validation loss: 2.0002146472213087

Epoch: 5| Step: 2
Training loss: 2.3630619049072266
Validation loss: 2.0024661761458202

Epoch: 5| Step: 3
Training loss: 2.5292086601257324
Validation loss: 2.0218136797669115

Epoch: 5| Step: 4
Training loss: 1.9025570154190063
Validation loss: 2.0553849051075597

Epoch: 5| Step: 5
Training loss: 2.6683237552642822
Validation loss: 2.066928445651967

Epoch: 5| Step: 6
Training loss: 2.2223012447357178
Validation loss: 2.053531810801516

Epoch: 5| Step: 7
Training loss: 2.507607936859131
Validation loss: 2.0423515894079722

Epoch: 5| Step: 8
Training loss: 1.6440677642822266
Validation loss: 2.0293724613804973

Epoch: 5| Step: 9
Training loss: 2.5431668758392334
Validation loss: 2.0234970328628377

Epoch: 5| Step: 10
Training loss: 2.296525001525879
Validation loss: 2.0452684587047947

Epoch: 110| Step: 0
Training loss: 2.1980807781219482
Validation loss: 2.0582808268967496

Epoch: 5| Step: 1
Training loss: 2.097180128097534
Validation loss: 2.0800205366585844

Epoch: 5| Step: 2
Training loss: 1.7840133905410767
Validation loss: 2.138865619577387

Epoch: 5| Step: 3
Training loss: 2.1540884971618652
Validation loss: 2.1789808965498403

Epoch: 5| Step: 4
Training loss: 2.9583191871643066
Validation loss: 2.2150694734306744

Epoch: 5| Step: 5
Training loss: 1.890397310256958
Validation loss: 2.1838827825361684

Epoch: 5| Step: 6
Training loss: 2.4114584922790527
Validation loss: 2.154060294551234

Epoch: 5| Step: 7
Training loss: 2.9659476280212402
Validation loss: 2.126329206651257

Epoch: 5| Step: 8
Training loss: 2.2505125999450684
Validation loss: 2.098332622999786

Epoch: 5| Step: 9
Training loss: 2.2212796211242676
Validation loss: 2.0711081694531184

Epoch: 5| Step: 10
Training loss: 2.0306925773620605
Validation loss: 2.032733307089857

Epoch: 111| Step: 0
Training loss: 2.0143463611602783
Validation loss: 2.013624809121573

Epoch: 5| Step: 1
Training loss: 1.7820383310317993
Validation loss: 1.9988288725576093

Epoch: 5| Step: 2
Training loss: 2.2770373821258545
Validation loss: 1.9895660800318564

Epoch: 5| Step: 3
Training loss: 2.2668442726135254
Validation loss: 1.982900296488116

Epoch: 5| Step: 4
Training loss: 1.5904536247253418
Validation loss: 1.9828654207209104

Epoch: 5| Step: 5
Training loss: 2.3512840270996094
Validation loss: 1.9805018850552139

Epoch: 5| Step: 6
Training loss: 1.9616944789886475
Validation loss: 1.9812660627467658

Epoch: 5| Step: 7
Training loss: 2.6234264373779297
Validation loss: 2.00558138919133

Epoch: 5| Step: 8
Training loss: 2.7145421504974365
Validation loss: 2.0232950795081353

Epoch: 5| Step: 9
Training loss: 3.415134906768799
Validation loss: 2.077597746285059

Epoch: 5| Step: 10
Training loss: 1.5525106191635132
Validation loss: 2.113395416608421

Epoch: 112| Step: 0
Training loss: 2.299159288406372
Validation loss: 2.1361059629788963

Epoch: 5| Step: 1
Training loss: 1.996364951133728
Validation loss: 2.1169860619370655

Epoch: 5| Step: 2
Training loss: 2.094468116760254
Validation loss: 2.087804340547131

Epoch: 5| Step: 3
Training loss: 2.1519150733947754
Validation loss: 2.046300152296661

Epoch: 5| Step: 4
Training loss: 2.3431787490844727
Validation loss: 2.0337999366944834

Epoch: 5| Step: 5
Training loss: 2.085153341293335
Validation loss: 2.021367567841725

Epoch: 5| Step: 6
Training loss: 2.296353816986084
Validation loss: 2.0087668485538934

Epoch: 5| Step: 7
Training loss: 2.5567870140075684
Validation loss: 2.006283490888534

Epoch: 5| Step: 8
Training loss: 2.598649263381958
Validation loss: 2.0054757979608353

Epoch: 5| Step: 9
Training loss: 1.7650121450424194
Validation loss: 2.020673756958336

Epoch: 5| Step: 10
Training loss: 2.326225757598877
Validation loss: 2.031325344116457

Epoch: 113| Step: 0
Training loss: 1.9498331546783447
Validation loss: 2.027355558128767

Epoch: 5| Step: 1
Training loss: 2.1703364849090576
Validation loss: 2.0526581989821566

Epoch: 5| Step: 2
Training loss: 2.9092743396759033
Validation loss: 2.0614580185182634

Epoch: 5| Step: 3
Training loss: 2.274073600769043
Validation loss: 2.0790298395259406

Epoch: 5| Step: 4
Training loss: 2.3645427227020264
Validation loss: 2.07918091230495

Epoch: 5| Step: 5
Training loss: 1.5348825454711914
Validation loss: 2.0629789636981104

Epoch: 5| Step: 6
Training loss: 2.3522238731384277
Validation loss: 2.0694681444475727

Epoch: 5| Step: 7
Training loss: 2.496278762817383
Validation loss: 2.0622783886489047

Epoch: 5| Step: 8
Training loss: 2.5656845569610596
Validation loss: 2.0619429567808747

Epoch: 5| Step: 9
Training loss: 1.9684356451034546
Validation loss: 2.041006229257071

Epoch: 5| Step: 10
Training loss: 1.6846179962158203
Validation loss: 2.076629751472063

Epoch: 114| Step: 0
Training loss: 1.5160714387893677
Validation loss: 2.1130147800650647

Epoch: 5| Step: 1
Training loss: 1.9286428689956665
Validation loss: 2.1278260920637395

Epoch: 5| Step: 2
Training loss: 2.194257974624634
Validation loss: 2.115476542903531

Epoch: 5| Step: 3
Training loss: 2.519505262374878
Validation loss: 2.099218794094619

Epoch: 5| Step: 4
Training loss: 2.7223262786865234
Validation loss: 2.0844538263095322

Epoch: 5| Step: 5
Training loss: 2.4608144760131836
Validation loss: 2.079727336924563

Epoch: 5| Step: 6
Training loss: 2.390669584274292
Validation loss: 2.067792812983195

Epoch: 5| Step: 7
Training loss: 2.8503963947296143
Validation loss: 2.0442710358609437

Epoch: 5| Step: 8
Training loss: 1.6299734115600586
Validation loss: 2.0415097282778834

Epoch: 5| Step: 9
Training loss: 1.9927037954330444
Validation loss: 2.0207409551066737

Epoch: 5| Step: 10
Training loss: 1.9433962106704712
Validation loss: 1.9981229920541086

Epoch: 115| Step: 0
Training loss: 1.8171970844268799
Validation loss: 1.9795966763650217

Epoch: 5| Step: 1
Training loss: 2.574920654296875
Validation loss: 1.981221996327882

Epoch: 5| Step: 2
Training loss: 1.9673717021942139
Validation loss: 1.9767946761141542

Epoch: 5| Step: 3
Training loss: 1.882144570350647
Validation loss: 1.978371294595862

Epoch: 5| Step: 4
Training loss: 2.7772438526153564
Validation loss: 1.974934870196927

Epoch: 5| Step: 5
Training loss: 1.583412528038025
Validation loss: 2.009058852349558

Epoch: 5| Step: 6
Training loss: 2.3791539669036865
Validation loss: 2.04179948119707

Epoch: 5| Step: 7
Training loss: 2.164900541305542
Validation loss: 2.0539270677874164

Epoch: 5| Step: 8
Training loss: 2.8889129161834717
Validation loss: 2.07708639483298

Epoch: 5| Step: 9
Training loss: 2.046954393386841
Validation loss: 2.061720791683402

Epoch: 5| Step: 10
Training loss: 1.9138156175613403
Validation loss: 2.0284825153248285

Epoch: 116| Step: 0
Training loss: 2.3954083919525146
Validation loss: 1.9997171740378104

Epoch: 5| Step: 1
Training loss: 1.9339691400527954
Validation loss: 1.9894770576107887

Epoch: 5| Step: 2
Training loss: 1.6591167449951172
Validation loss: 1.9896469680211877

Epoch: 5| Step: 3
Training loss: 1.7271902561187744
Validation loss: 2.016629942001835

Epoch: 5| Step: 4
Training loss: 2.2362632751464844
Validation loss: 2.037084746104415

Epoch: 5| Step: 5
Training loss: 2.3506438732147217
Validation loss: 2.0518532722227034

Epoch: 5| Step: 6
Training loss: 1.857544183731079
Validation loss: 2.0307254534895702

Epoch: 5| Step: 7
Training loss: 2.379408597946167
Validation loss: 2.0167876725555747

Epoch: 5| Step: 8
Training loss: 2.5163564682006836
Validation loss: 1.9987904333299207

Epoch: 5| Step: 9
Training loss: 2.506639003753662
Validation loss: 1.977756892481158

Epoch: 5| Step: 10
Training loss: 2.1856048107147217
Validation loss: 1.9888815136365994

Epoch: 117| Step: 0
Training loss: 1.2822599411010742
Validation loss: 1.972067912419637

Epoch: 5| Step: 1
Training loss: 2.4795126914978027
Validation loss: 1.9757534521882252

Epoch: 5| Step: 2
Training loss: 2.3876101970672607
Validation loss: 1.978431196622951

Epoch: 5| Step: 3
Training loss: 1.9216620922088623
Validation loss: 1.9780340899703324

Epoch: 5| Step: 4
Training loss: 1.7307846546173096
Validation loss: 2.0074004486042965

Epoch: 5| Step: 5
Training loss: 2.5260462760925293
Validation loss: 2.020961234646459

Epoch: 5| Step: 6
Training loss: 2.628920793533325
Validation loss: 2.0198640746455037

Epoch: 5| Step: 7
Training loss: 2.1586105823516846
Validation loss: 2.0226874428410686

Epoch: 5| Step: 8
Training loss: 2.111359119415283
Validation loss: 1.9878397295551915

Epoch: 5| Step: 9
Training loss: 2.0560758113861084
Validation loss: 1.9876624371415825

Epoch: 5| Step: 10
Training loss: 2.337836742401123
Validation loss: 1.9777109635773527

Epoch: 118| Step: 0
Training loss: 1.8712215423583984
Validation loss: 1.9875175132546374

Epoch: 5| Step: 1
Training loss: 1.9228413105010986
Validation loss: 2.00033587537786

Epoch: 5| Step: 2
Training loss: 2.0417535305023193
Validation loss: 2.009068491638348

Epoch: 5| Step: 3
Training loss: 2.058521032333374
Validation loss: 2.0100876656911706

Epoch: 5| Step: 4
Training loss: 2.0542023181915283
Validation loss: 2.010704707073909

Epoch: 5| Step: 5
Training loss: 2.529785633087158
Validation loss: 2.0178876846067366

Epoch: 5| Step: 6
Training loss: 2.281156539916992
Validation loss: 2.025495772720665

Epoch: 5| Step: 7
Training loss: 2.106212615966797
Validation loss: 2.0352137729685795

Epoch: 5| Step: 8
Training loss: 2.058326244354248
Validation loss: 2.019147429414975

Epoch: 5| Step: 9
Training loss: 1.8746254444122314
Validation loss: 2.011885361004901

Epoch: 5| Step: 10
Training loss: 2.459103584289551
Validation loss: 2.000837443977274

Epoch: 119| Step: 0
Training loss: 2.3857312202453613
Validation loss: 2.0002234110268216

Epoch: 5| Step: 1
Training loss: 1.9862171411514282
Validation loss: 1.9924745495601366

Epoch: 5| Step: 2
Training loss: 1.862051010131836
Validation loss: 1.9909431421628563

Epoch: 5| Step: 3
Training loss: 2.1686363220214844
Validation loss: 1.98592621280301

Epoch: 5| Step: 4
Training loss: 2.1875693798065186
Validation loss: 1.9747036118661203

Epoch: 5| Step: 5
Training loss: 2.242446184158325
Validation loss: 1.9908441010341849

Epoch: 5| Step: 6
Training loss: 1.1557883024215698
Validation loss: 2.0041937340972242

Epoch: 5| Step: 7
Training loss: 2.552769184112549
Validation loss: 2.018726082258327

Epoch: 5| Step: 8
Training loss: 2.1193833351135254
Validation loss: 2.008119011438021

Epoch: 5| Step: 9
Training loss: 2.314174175262451
Validation loss: 1.9898296607437955

Epoch: 5| Step: 10
Training loss: 1.9572614431381226
Validation loss: 1.9914000226605324

Epoch: 120| Step: 0
Training loss: 2.042296886444092
Validation loss: 1.9835894364182667

Epoch: 5| Step: 1
Training loss: 1.945549726486206
Validation loss: 1.9766278215633926

Epoch: 5| Step: 2
Training loss: 2.968341827392578
Validation loss: 1.9674665299795007

Epoch: 5| Step: 3
Training loss: 2.056135654449463
Validation loss: 1.9744518264647453

Epoch: 5| Step: 4
Training loss: 1.9502317905426025
Validation loss: 1.9658102220104587

Epoch: 5| Step: 5
Training loss: 1.6329113245010376
Validation loss: 1.9614008331811557

Epoch: 5| Step: 6
Training loss: 2.1814188957214355
Validation loss: 1.9773212581552484

Epoch: 5| Step: 7
Training loss: 2.379992723464966
Validation loss: 2.0039963645319783

Epoch: 5| Step: 8
Training loss: 2.0559935569763184
Validation loss: 2.018769866676741

Epoch: 5| Step: 9
Training loss: 1.9632682800292969
Validation loss: 2.0242168775168796

Epoch: 5| Step: 10
Training loss: 1.654070258140564
Validation loss: 2.033944550380912

Epoch: 121| Step: 0
Training loss: 2.1769461631774902
Validation loss: 2.046566540195096

Epoch: 5| Step: 1
Training loss: 2.4331698417663574
Validation loss: 2.0288049892712663

Epoch: 5| Step: 2
Training loss: 1.692021369934082
Validation loss: 2.0350178236602456

Epoch: 5| Step: 3
Training loss: 1.8245770931243896
Validation loss: 2.0357310989851594

Epoch: 5| Step: 4
Training loss: 1.9974457025527954
Validation loss: 2.0431395115390902

Epoch: 5| Step: 5
Training loss: 2.3833796977996826
Validation loss: 2.049128927210326

Epoch: 5| Step: 6
Training loss: 2.123481512069702
Validation loss: 2.0379847659859607

Epoch: 5| Step: 7
Training loss: 1.8254114389419556
Validation loss: 2.043953316186064

Epoch: 5| Step: 8
Training loss: 1.9961503744125366
Validation loss: 2.0373448735924176

Epoch: 5| Step: 9
Training loss: 2.251614809036255
Validation loss: 2.013366263399842

Epoch: 5| Step: 10
Training loss: 2.050929069519043
Validation loss: 2.010832109758931

Epoch: 122| Step: 0
Training loss: 2.156153678894043
Validation loss: 2.003956414038135

Epoch: 5| Step: 1
Training loss: 2.1885275840759277
Validation loss: 2.002825680599418

Epoch: 5| Step: 2
Training loss: 2.2428948879241943
Validation loss: 2.008120959804904

Epoch: 5| Step: 3
Training loss: 2.024778366088867
Validation loss: 2.018098387666928

Epoch: 5| Step: 4
Training loss: 1.859440565109253
Validation loss: 2.0267139762960453

Epoch: 5| Step: 5
Training loss: 2.130200147628784
Validation loss: 2.0135585236293014

Epoch: 5| Step: 6
Training loss: 2.290235996246338
Validation loss: 2.0117208855126494

Epoch: 5| Step: 7
Training loss: 1.8652904033660889
Validation loss: 2.01298217363255

Epoch: 5| Step: 8
Training loss: 2.062046766281128
Validation loss: 2.0220153818848314

Epoch: 5| Step: 9
Training loss: 2.212087869644165
Validation loss: 2.040015620570029

Epoch: 5| Step: 10
Training loss: 1.4089750051498413
Validation loss: 2.051705342467113

Epoch: 123| Step: 0
Training loss: 2.0245392322540283
Validation loss: 2.0502295160806305

Epoch: 5| Step: 1
Training loss: 2.78932785987854
Validation loss: 2.049452361240182

Epoch: 5| Step: 2
Training loss: 2.1956870555877686
Validation loss: 2.0544950910793838

Epoch: 5| Step: 3
Training loss: 1.7960233688354492
Validation loss: 2.0513731753954323

Epoch: 5| Step: 4
Training loss: 2.05680513381958
Validation loss: 2.046876920166836

Epoch: 5| Step: 5
Training loss: 2.361624240875244
Validation loss: 2.078993452492581

Epoch: 5| Step: 6
Training loss: 2.2094528675079346
Validation loss: 2.1090483319374824

Epoch: 5| Step: 7
Training loss: 1.969943642616272
Validation loss: 2.1194612005705475

Epoch: 5| Step: 8
Training loss: 1.9105079174041748
Validation loss: 2.1059215812272924

Epoch: 5| Step: 9
Training loss: 1.8358694314956665
Validation loss: 2.07553461546539

Epoch: 5| Step: 10
Training loss: 1.516688346862793
Validation loss: 2.034017611575383

Epoch: 124| Step: 0
Training loss: 2.5744566917419434
Validation loss: 2.0295758311466505

Epoch: 5| Step: 1
Training loss: 1.9242079257965088
Validation loss: 2.020126922156221

Epoch: 5| Step: 2
Training loss: 2.020484447479248
Validation loss: 2.017663357078388

Epoch: 5| Step: 3
Training loss: 1.5697965621948242
Validation loss: 2.0245678347925984

Epoch: 5| Step: 4
Training loss: 2.575664758682251
Validation loss: 2.0466004904880317

Epoch: 5| Step: 5
Training loss: 2.2074034214019775
Validation loss: 2.0990546518756497

Epoch: 5| Step: 6
Training loss: 2.392821788787842
Validation loss: 2.130899331902945

Epoch: 5| Step: 7
Training loss: 1.7794134616851807
Validation loss: 2.1181165556753836

Epoch: 5| Step: 8
Training loss: 1.9624261856079102
Validation loss: 2.0944948401502383

Epoch: 5| Step: 9
Training loss: 2.165071964263916
Validation loss: 2.0774555360117266

Epoch: 5| Step: 10
Training loss: 1.7941421270370483
Validation loss: 2.057073370102913

Epoch: 125| Step: 0
Training loss: 2.092588186264038
Validation loss: 2.0604175777845484

Epoch: 5| Step: 1
Training loss: 2.3763625621795654
Validation loss: 2.0645994729893182

Epoch: 5| Step: 2
Training loss: 2.3646609783172607
Validation loss: 2.0640925566355386

Epoch: 5| Step: 3
Training loss: 1.7864090204238892
Validation loss: 2.059078517780509

Epoch: 5| Step: 4
Training loss: 2.0417017936706543
Validation loss: 2.0611778433604906

Epoch: 5| Step: 5
Training loss: 2.276761531829834
Validation loss: 2.049135782385385

Epoch: 5| Step: 6
Training loss: 2.1745686531066895
Validation loss: 2.057036938205842

Epoch: 5| Step: 7
Training loss: 1.7636001110076904
Validation loss: 2.039852560207408

Epoch: 5| Step: 8
Training loss: 2.2354373931884766
Validation loss: 2.024185198609547

Epoch: 5| Step: 9
Training loss: 1.7805955410003662
Validation loss: 2.0006433879175494

Epoch: 5| Step: 10
Training loss: 1.675690770149231
Validation loss: 2.0095398964420443

Epoch: 126| Step: 0
Training loss: 2.254662036895752
Validation loss: 2.0348160894968177

Epoch: 5| Step: 1
Training loss: 2.3965187072753906
Validation loss: 2.045930982917868

Epoch: 5| Step: 2
Training loss: 1.6379626989364624
Validation loss: 2.042436792004493

Epoch: 5| Step: 3
Training loss: 2.533597469329834
Validation loss: 2.0131585892810615

Epoch: 5| Step: 4
Training loss: 1.7448399066925049
Validation loss: 2.0124617212562153

Epoch: 5| Step: 5
Training loss: 1.6337047815322876
Validation loss: 2.016488980221492

Epoch: 5| Step: 6
Training loss: 2.104015827178955
Validation loss: 2.0240644126810055

Epoch: 5| Step: 7
Training loss: 1.8390734195709229
Validation loss: 2.0676540969520487

Epoch: 5| Step: 8
Training loss: 1.942517876625061
Validation loss: 2.0835297158969346

Epoch: 5| Step: 9
Training loss: 2.172457695007324
Validation loss: 2.099708875020345

Epoch: 5| Step: 10
Training loss: 2.0421142578125
Validation loss: 2.0900107493964573

Epoch: 127| Step: 0
Training loss: 1.6713855266571045
Validation loss: 2.0750970302089566

Epoch: 5| Step: 1
Training loss: 2.664456605911255
Validation loss: 2.0607294779951855

Epoch: 5| Step: 2
Training loss: 1.5893467664718628
Validation loss: 2.0608269655576317

Epoch: 5| Step: 3
Training loss: 2.398198366165161
Validation loss: 2.024556126645816

Epoch: 5| Step: 4
Training loss: 2.2903754711151123
Validation loss: 2.0421835120006273

Epoch: 5| Step: 5
Training loss: 1.7481603622436523
Validation loss: 2.040479488270257

Epoch: 5| Step: 6
Training loss: 1.6579549312591553
Validation loss: 2.0751565553808726

Epoch: 5| Step: 7
Training loss: 2.5802369117736816
Validation loss: 2.120056672762799

Epoch: 5| Step: 8
Training loss: 1.416405439376831
Validation loss: 2.100474928015022

Epoch: 5| Step: 9
Training loss: 2.3027307987213135
Validation loss: 2.070038123797345

Epoch: 5| Step: 10
Training loss: 2.088230609893799
Validation loss: 2.053962645992156

Epoch: 128| Step: 0
Training loss: 1.8801765441894531
Validation loss: 2.026346206665039

Epoch: 5| Step: 1
Training loss: 1.9832786321640015
Validation loss: 2.025858675279925

Epoch: 5| Step: 2
Training loss: 2.174417018890381
Validation loss: 2.0141153463753323

Epoch: 5| Step: 3
Training loss: 1.657761573791504
Validation loss: 2.0212924582983858

Epoch: 5| Step: 4
Training loss: 1.8691380023956299
Validation loss: 2.0139050009430095

Epoch: 5| Step: 5
Training loss: 2.684385299682617
Validation loss: 2.0287291337085027

Epoch: 5| Step: 6
Training loss: 2.0683932304382324
Validation loss: 2.032758971696259

Epoch: 5| Step: 7
Training loss: 1.7499052286148071
Validation loss: 2.033700978884133

Epoch: 5| Step: 8
Training loss: 1.7075649499893188
Validation loss: 2.0475246931916926

Epoch: 5| Step: 9
Training loss: 2.543511152267456
Validation loss: 2.059642458474764

Epoch: 5| Step: 10
Training loss: 1.751262903213501
Validation loss: 2.0800078453556186

Epoch: 129| Step: 0
Training loss: 1.6250709295272827
Validation loss: 2.0815849458017657

Epoch: 5| Step: 1
Training loss: 2.016019582748413
Validation loss: 2.061212352527085

Epoch: 5| Step: 2
Training loss: 2.1015753746032715
Validation loss: 2.037663277759347

Epoch: 5| Step: 3
Training loss: 1.7715479135513306
Validation loss: 2.02549994889126

Epoch: 5| Step: 4
Training loss: 2.4324913024902344
Validation loss: 2.0165290640246485

Epoch: 5| Step: 5
Training loss: 2.1625583171844482
Validation loss: 2.0278111734697895

Epoch: 5| Step: 6
Training loss: 2.05552077293396
Validation loss: 2.0362363887089554

Epoch: 5| Step: 7
Training loss: 1.92822265625
Validation loss: 2.0254368961498304

Epoch: 5| Step: 8
Training loss: 2.17611026763916
Validation loss: 2.018708323919645

Epoch: 5| Step: 9
Training loss: 2.1872973442077637
Validation loss: 2.0045984983444214

Epoch: 5| Step: 10
Training loss: 1.244059681892395
Validation loss: 1.9936429838980398

Epoch: 130| Step: 0
Training loss: 2.3933939933776855
Validation loss: 2.0036302740855882

Epoch: 5| Step: 1
Training loss: 1.7969917058944702
Validation loss: 1.9999497539253646

Epoch: 5| Step: 2
Training loss: 1.770897626876831
Validation loss: 2.032102060574357

Epoch: 5| Step: 3
Training loss: 1.9803249835968018
Validation loss: 2.0414203982199393

Epoch: 5| Step: 4
Training loss: 1.473534345626831
Validation loss: 2.0254875075432563

Epoch: 5| Step: 5
Training loss: 2.1394991874694824
Validation loss: 1.9972311873589792

Epoch: 5| Step: 6
Training loss: 2.3625741004943848
Validation loss: 1.990603050877971

Epoch: 5| Step: 7
Training loss: 2.021730422973633
Validation loss: 1.9931795404803367

Epoch: 5| Step: 8
Training loss: 1.7884857654571533
Validation loss: 1.992146538149926

Epoch: 5| Step: 9
Training loss: 2.131075859069824
Validation loss: 2.0025902255888908

Epoch: 5| Step: 10
Training loss: 1.75368070602417
Validation loss: 2.0300843946395384

Epoch: 131| Step: 0
Training loss: 1.4716742038726807
Validation loss: 2.04352141452092

Epoch: 5| Step: 1
Training loss: 1.2627147436141968
Validation loss: 2.0334086623243106

Epoch: 5| Step: 2
Training loss: 2.2055418491363525
Validation loss: 2.041869698032256

Epoch: 5| Step: 3
Training loss: 2.5127689838409424
Validation loss: 2.045587161535858

Epoch: 5| Step: 4
Training loss: 1.9465036392211914
Validation loss: 2.0377928467207056

Epoch: 5| Step: 5
Training loss: 1.9933303594589233
Validation loss: 2.0364982735726143

Epoch: 5| Step: 6
Training loss: 1.9330171346664429
Validation loss: 2.044231950595815

Epoch: 5| Step: 7
Training loss: 1.2899844646453857
Validation loss: 2.034720118327807

Epoch: 5| Step: 8
Training loss: 2.413153886795044
Validation loss: 2.0488725375103694

Epoch: 5| Step: 9
Training loss: 2.206529140472412
Validation loss: 2.0556438199935423

Epoch: 5| Step: 10
Training loss: 2.356682062149048
Validation loss: 2.051162770999375

Epoch: 132| Step: 0
Training loss: 1.1817699670791626
Validation loss: 2.0406342193644535

Epoch: 5| Step: 1
Training loss: 2.11323881149292
Validation loss: 2.0335315709472983

Epoch: 5| Step: 2
Training loss: 1.9342291355133057
Validation loss: 2.0327040098046743

Epoch: 5| Step: 3
Training loss: 1.6772350072860718
Validation loss: 2.021411298423685

Epoch: 5| Step: 4
Training loss: 2.3108556270599365
Validation loss: 2.021956028476838

Epoch: 5| Step: 5
Training loss: 1.7221885919570923
Validation loss: 2.0188650905445056

Epoch: 5| Step: 6
Training loss: 2.3099617958068848
Validation loss: 2.016670269350852

Epoch: 5| Step: 7
Training loss: 2.212214946746826
Validation loss: 2.027848841041647

Epoch: 5| Step: 8
Training loss: 2.068232297897339
Validation loss: 2.036552652235954

Epoch: 5| Step: 9
Training loss: 1.6522973775863647
Validation loss: 2.0520381517307733

Epoch: 5| Step: 10
Training loss: 2.088430881500244
Validation loss: 2.0761640917870308

Epoch: 133| Step: 0
Training loss: 2.1443185806274414
Validation loss: 2.0831842243030505

Epoch: 5| Step: 1
Training loss: 2.062800884246826
Validation loss: 2.0648864853766655

Epoch: 5| Step: 2
Training loss: 2.390836000442505
Validation loss: 2.0563677280179915

Epoch: 5| Step: 3
Training loss: 2.297060012817383
Validation loss: 2.0515698694413707

Epoch: 5| Step: 4
Training loss: 1.250970482826233
Validation loss: 2.0515515445381083

Epoch: 5| Step: 5
Training loss: 2.052454710006714
Validation loss: 2.065766719079787

Epoch: 5| Step: 6
Training loss: 1.5504025220870972
Validation loss: 2.060677307908253

Epoch: 5| Step: 7
Training loss: 2.027860641479492
Validation loss: 2.0429514287620463

Epoch: 5| Step: 8
Training loss: 1.6537754535675049
Validation loss: 2.0337272600461076

Epoch: 5| Step: 9
Training loss: 1.6844561100006104
Validation loss: 2.0197854016416814

Epoch: 5| Step: 10
Training loss: 2.0249898433685303
Validation loss: 2.019527878812564

Epoch: 134| Step: 0
Training loss: 1.4701151847839355
Validation loss: 2.030750973250276

Epoch: 5| Step: 1
Training loss: 2.7249836921691895
Validation loss: 2.0519421267253097

Epoch: 5| Step: 2
Training loss: 1.5613969564437866
Validation loss: 2.0555545078810824

Epoch: 5| Step: 3
Training loss: 2.5874533653259277
Validation loss: 2.031190001836387

Epoch: 5| Step: 4
Training loss: 2.027095317840576
Validation loss: 2.0408178529431744

Epoch: 5| Step: 5
Training loss: 1.5454967021942139
Validation loss: 2.0272249996021228

Epoch: 5| Step: 6
Training loss: 1.9710676670074463
Validation loss: 2.0255977146087156

Epoch: 5| Step: 7
Training loss: 1.761659860610962
Validation loss: 2.0393763870321293

Epoch: 5| Step: 8
Training loss: 1.6782957315444946
Validation loss: 2.0314728880441315

Epoch: 5| Step: 9
Training loss: 2.0197856426239014
Validation loss: 2.040972508409972

Epoch: 5| Step: 10
Training loss: 1.8148328065872192
Validation loss: 2.0462465991256056

Epoch: 135| Step: 0
Training loss: 1.50407075881958
Validation loss: 2.0573027236487276

Epoch: 5| Step: 1
Training loss: 1.9237207174301147
Validation loss: 2.059499627800398

Epoch: 5| Step: 2
Training loss: 1.8563215732574463
Validation loss: 2.0505492969225814

Epoch: 5| Step: 3
Training loss: 2.111396551132202
Validation loss: 2.039878970833235

Epoch: 5| Step: 4
Training loss: 1.7561099529266357
Validation loss: 2.033501375106073

Epoch: 5| Step: 5
Training loss: 1.5313224792480469
Validation loss: 2.031522786745461

Epoch: 5| Step: 6
Training loss: 2.445909261703491
Validation loss: 2.0342663141988937

Epoch: 5| Step: 7
Training loss: 1.8566710948944092
Validation loss: 2.0240953301870697

Epoch: 5| Step: 8
Training loss: 1.8024057149887085
Validation loss: 2.0081433339785506

Epoch: 5| Step: 9
Training loss: 2.1981728076934814
Validation loss: 2.017128970033379

Epoch: 5| Step: 10
Training loss: 2.1401219367980957
Validation loss: 2.0194899471857215

Epoch: 136| Step: 0
Training loss: 1.6997392177581787
Validation loss: 1.9995839595794678

Epoch: 5| Step: 1
Training loss: 1.8976590633392334
Validation loss: 1.9796876420256913

Epoch: 5| Step: 2
Training loss: 1.7133251428604126
Validation loss: 1.9940984197842178

Epoch: 5| Step: 3
Training loss: 2.1548473834991455
Validation loss: 2.0028153363094536

Epoch: 5| Step: 4
Training loss: 2.7615225315093994
Validation loss: 2.0097892181847685

Epoch: 5| Step: 5
Training loss: 1.5834710597991943
Validation loss: 2.038019654571369

Epoch: 5| Step: 6
Training loss: 1.7025730609893799
Validation loss: 2.044882923044184

Epoch: 5| Step: 7
Training loss: 2.144535541534424
Validation loss: 2.0519726558398177

Epoch: 5| Step: 8
Training loss: 1.3408130407333374
Validation loss: 2.0764788914752264

Epoch: 5| Step: 9
Training loss: 2.298581123352051
Validation loss: 2.0693328983040264

Epoch: 5| Step: 10
Training loss: 1.629259705543518
Validation loss: 2.0492450485947313

Epoch: 137| Step: 0
Training loss: 1.9382736682891846
Validation loss: 2.022610495167394

Epoch: 5| Step: 1
Training loss: 1.4954912662506104
Validation loss: 2.002540647342641

Epoch: 5| Step: 2
Training loss: 2.316873073577881
Validation loss: 2.026931817813586

Epoch: 5| Step: 3
Training loss: 2.2509665489196777
Validation loss: 2.0271046238560833

Epoch: 5| Step: 4
Training loss: 2.1258301734924316
Validation loss: 2.032911923623854

Epoch: 5| Step: 5
Training loss: 2.0328266620635986
Validation loss: 2.024332756637245

Epoch: 5| Step: 6
Training loss: 1.8308452367782593
Validation loss: 2.0160679919745332

Epoch: 5| Step: 7
Training loss: 1.8383738994598389
Validation loss: 2.0157055111341577

Epoch: 5| Step: 8
Training loss: 1.7063649892807007
Validation loss: 2.0124998246469805

Epoch: 5| Step: 9
Training loss: 1.645693063735962
Validation loss: 2.028980185908656

Epoch: 5| Step: 10
Training loss: 1.5281175374984741
Validation loss: 2.038475377585298

Epoch: 138| Step: 0
Training loss: 1.718896508216858
Validation loss: 2.0513773067023164

Epoch: 5| Step: 1
Training loss: 2.522984266281128
Validation loss: 2.0576701394973265

Epoch: 5| Step: 2
Training loss: 1.9893791675567627
Validation loss: 2.0229960769735356

Epoch: 5| Step: 3
Training loss: 1.7041900157928467
Validation loss: 2.0500077355292534

Epoch: 5| Step: 4
Training loss: 2.2096951007843018
Validation loss: 2.0631605373915805

Epoch: 5| Step: 5
Training loss: 1.6596717834472656
Validation loss: 2.0452466305866035

Epoch: 5| Step: 6
Training loss: 1.876894235610962
Validation loss: 2.030225428201819

Epoch: 5| Step: 7
Training loss: 1.9262816905975342
Validation loss: 2.0456002425122004

Epoch: 5| Step: 8
Training loss: 1.9016711711883545
Validation loss: 2.063286227564658

Epoch: 5| Step: 9
Training loss: 1.950138807296753
Validation loss: 2.0677967302260862

Epoch: 5| Step: 10
Training loss: 1.2456127405166626
Validation loss: 2.0886472373880367

Epoch: 139| Step: 0
Training loss: 2.2699220180511475
Validation loss: 2.0811825003675235

Epoch: 5| Step: 1
Training loss: 1.28450345993042
Validation loss: 2.0714674944518716

Epoch: 5| Step: 2
Training loss: 2.1265017986297607
Validation loss: 2.0424690374764065

Epoch: 5| Step: 3
Training loss: 1.793298363685608
Validation loss: 2.013401908259238

Epoch: 5| Step: 4
Training loss: 1.9725396633148193
Validation loss: 2.013139331212608

Epoch: 5| Step: 5
Training loss: 1.9972286224365234
Validation loss: 2.008828245183473

Epoch: 5| Step: 6
Training loss: 1.7798936367034912
Validation loss: 2.0032240498450493

Epoch: 5| Step: 7
Training loss: 1.862971305847168
Validation loss: 1.9999798805482927

Epoch: 5| Step: 8
Training loss: 1.6445672512054443
Validation loss: 2.007746834908762

Epoch: 5| Step: 9
Training loss: 1.8998863697052002
Validation loss: 2.0147069987430366

Epoch: 5| Step: 10
Training loss: 1.8104215860366821
Validation loss: 2.052805869810043

Epoch: 140| Step: 0
Training loss: 1.9618079662322998
Validation loss: 2.077731010734394

Epoch: 5| Step: 1
Training loss: 2.3689138889312744
Validation loss: 2.073230310152936

Epoch: 5| Step: 2
Training loss: 1.6586259603500366
Validation loss: 2.058045720541349

Epoch: 5| Step: 3
Training loss: 1.9210395812988281
Validation loss: 2.0286380449930825

Epoch: 5| Step: 4
Training loss: 1.7095661163330078
Validation loss: 2.025033708541624

Epoch: 5| Step: 5
Training loss: 1.8128410577774048
Validation loss: 2.0451354262649373

Epoch: 5| Step: 6
Training loss: 2.0988945960998535
Validation loss: 2.069992411521173

Epoch: 5| Step: 7
Training loss: 1.6641991138458252
Validation loss: 2.0862580883887505

Epoch: 5| Step: 8
Training loss: 1.7461192607879639
Validation loss: 2.0733230959984565

Epoch: 5| Step: 9
Training loss: 2.2017290592193604
Validation loss: 2.0686639278165755

Epoch: 5| Step: 10
Training loss: 1.597929835319519
Validation loss: 2.0526538818113265

Epoch: 141| Step: 0
Training loss: 1.8191521167755127
Validation loss: 2.0388588354151738

Epoch: 5| Step: 1
Training loss: 1.6632053852081299
Validation loss: 2.0350124707785984

Epoch: 5| Step: 2
Training loss: 2.0510239601135254
Validation loss: 2.020710781056394

Epoch: 5| Step: 3
Training loss: 1.7534096240997314
Validation loss: 2.0020001242237706

Epoch: 5| Step: 4
Training loss: 1.6361347436904907
Validation loss: 1.9888561541034329

Epoch: 5| Step: 5
Training loss: 1.6781104803085327
Validation loss: 1.9801380044670516

Epoch: 5| Step: 6
Training loss: 2.2126834392547607
Validation loss: 1.9754228386827695

Epoch: 5| Step: 7
Training loss: 2.5124588012695312
Validation loss: 1.9659474024208643

Epoch: 5| Step: 8
Training loss: 1.9616639614105225
Validation loss: 1.9593287719193326

Epoch: 5| Step: 9
Training loss: 1.5824644565582275
Validation loss: 1.9799822761166481

Epoch: 5| Step: 10
Training loss: 1.3881080150604248
Validation loss: 1.9958113316566712

Epoch: 142| Step: 0
Training loss: 2.187364101409912
Validation loss: 2.0143869512824604

Epoch: 5| Step: 1
Training loss: 1.2538765668869019
Validation loss: 2.01620699128797

Epoch: 5| Step: 2
Training loss: 1.8370730876922607
Validation loss: 2.0288589385248

Epoch: 5| Step: 3
Training loss: 1.3458391427993774
Validation loss: 2.0434487711998726

Epoch: 5| Step: 4
Training loss: 2.06779408454895
Validation loss: 2.078582755980953

Epoch: 5| Step: 5
Training loss: 1.786184549331665
Validation loss: 2.0976851896573137

Epoch: 5| Step: 6
Training loss: 1.6850392818450928
Validation loss: 2.065872476946923

Epoch: 5| Step: 7
Training loss: 1.9952462911605835
Validation loss: 2.0807002513639388

Epoch: 5| Step: 8
Training loss: 1.746364951133728
Validation loss: 2.062279798651254

Epoch: 5| Step: 9
Training loss: 1.7626556158065796
Validation loss: 2.0459936793132494

Epoch: 5| Step: 10
Training loss: 2.3545689582824707
Validation loss: 2.035669872837682

Epoch: 143| Step: 0
Training loss: 2.3252415657043457
Validation loss: 2.024511065534366

Epoch: 5| Step: 1
Training loss: 1.6938787698745728
Validation loss: 2.025744357416707

Epoch: 5| Step: 2
Training loss: 0.8998885154724121
Validation loss: 2.0308175086975098

Epoch: 5| Step: 3
Training loss: 1.5732438564300537
Validation loss: 2.029224685443345

Epoch: 5| Step: 4
Training loss: 1.300598382949829
Validation loss: 2.02510436888664

Epoch: 5| Step: 5
Training loss: 1.7130029201507568
Validation loss: 2.0426979039304998

Epoch: 5| Step: 6
Training loss: 2.5677871704101562
Validation loss: 2.0402093138746036

Epoch: 5| Step: 7
Training loss: 1.965105414390564
Validation loss: 2.0429327693036807

Epoch: 5| Step: 8
Training loss: 2.2566800117492676
Validation loss: 2.0361664590015205

Epoch: 5| Step: 9
Training loss: 1.6350734233856201
Validation loss: 2.0324087950491134

Epoch: 5| Step: 10
Training loss: 2.0878477096557617
Validation loss: 2.0120930466600644

Epoch: 144| Step: 0
Training loss: 1.6853668689727783
Validation loss: 2.007523618718629

Epoch: 5| Step: 1
Training loss: 1.6544290781021118
Validation loss: 2.000769768991778

Epoch: 5| Step: 2
Training loss: 2.2414498329162598
Validation loss: 2.0100559573019705

Epoch: 5| Step: 3
Training loss: 1.579109787940979
Validation loss: 1.9963978259794173

Epoch: 5| Step: 4
Training loss: 1.495641827583313
Validation loss: 1.9849795295346169

Epoch: 5| Step: 5
Training loss: 1.6586185693740845
Validation loss: 2.0048055956440587

Epoch: 5| Step: 6
Training loss: 2.565333843231201
Validation loss: 2.008795040909962

Epoch: 5| Step: 7
Training loss: 1.3574602603912354
Validation loss: 2.0369023610186834

Epoch: 5| Step: 8
Training loss: 2.3400344848632812
Validation loss: 2.035019523353987

Epoch: 5| Step: 9
Training loss: 1.642311453819275
Validation loss: 2.0500033299128213

Epoch: 5| Step: 10
Training loss: 1.5088716745376587
Validation loss: 2.0278542862143567

Epoch: 145| Step: 0
Training loss: 1.6935369968414307
Validation loss: 2.016612475918185

Epoch: 5| Step: 1
Training loss: 1.5804951190948486
Validation loss: 1.996358351040912

Epoch: 5| Step: 2
Training loss: 1.6716945171356201
Validation loss: 2.0158682882144885

Epoch: 5| Step: 3
Training loss: 1.5503675937652588
Validation loss: 2.0201142359805364

Epoch: 5| Step: 4
Training loss: 1.5653467178344727
Validation loss: 2.053518295288086

Epoch: 5| Step: 5
Training loss: 1.7192413806915283
Validation loss: 2.068227183434271

Epoch: 5| Step: 6
Training loss: 2.1049697399139404
Validation loss: 2.063468679305046

Epoch: 5| Step: 7
Training loss: 1.7038390636444092
Validation loss: 2.047710798119986

Epoch: 5| Step: 8
Training loss: 1.7006549835205078
Validation loss: 2.0643836400842153

Epoch: 5| Step: 9
Training loss: 2.1193082332611084
Validation loss: 2.061228698299777

Epoch: 5| Step: 10
Training loss: 2.495065212249756
Validation loss: 2.0732515114609913

Epoch: 146| Step: 0
Training loss: 1.8220380544662476
Validation loss: 2.036833470867526

Epoch: 5| Step: 1
Training loss: 1.8619918823242188
Validation loss: 2.0341422019466275

Epoch: 5| Step: 2
Training loss: 2.001121997833252
Validation loss: 2.0145730305743474

Epoch: 5| Step: 3
Training loss: 1.3255770206451416
Validation loss: 2.0190399462176907

Epoch: 5| Step: 4
Training loss: 1.3930726051330566
Validation loss: 2.000544282697862

Epoch: 5| Step: 5
Training loss: 1.782514214515686
Validation loss: 2.0031867681011075

Epoch: 5| Step: 6
Training loss: 2.189591884613037
Validation loss: 2.001312686551002

Epoch: 5| Step: 7
Training loss: 1.4995334148406982
Validation loss: 2.006748266117547

Epoch: 5| Step: 8
Training loss: 1.7648937702178955
Validation loss: 2.027879435528991

Epoch: 5| Step: 9
Training loss: 2.049039363861084
Validation loss: 2.042642019128287

Epoch: 5| Step: 10
Training loss: 2.294984817504883
Validation loss: 2.0450843893071657

Epoch: 147| Step: 0
Training loss: 1.6834529638290405
Validation loss: 2.042163687367593

Epoch: 5| Step: 1
Training loss: 1.540663719177246
Validation loss: 2.0368857947728967

Epoch: 5| Step: 2
Training loss: 1.6260414123535156
Validation loss: 2.015586740227156

Epoch: 5| Step: 3
Training loss: 1.6300979852676392
Validation loss: 2.0123315344574633

Epoch: 5| Step: 4
Training loss: 1.729933500289917
Validation loss: 2.0205148368753414

Epoch: 5| Step: 5
Training loss: 2.0315749645233154
Validation loss: 2.0178852824754614

Epoch: 5| Step: 6
Training loss: 1.9624340534210205
Validation loss: 2.0325442334657073

Epoch: 5| Step: 7
Training loss: 1.8378117084503174
Validation loss: 2.0377943182504303

Epoch: 5| Step: 8
Training loss: 1.5200910568237305
Validation loss: 2.0597613883274857

Epoch: 5| Step: 9
Training loss: 1.7646963596343994
Validation loss: 2.0526104191298127

Epoch: 5| Step: 10
Training loss: 2.242300033569336
Validation loss: 2.0462237122238323

Epoch: 148| Step: 0
Training loss: 1.4053750038146973
Validation loss: 2.0335745337188884

Epoch: 5| Step: 1
Training loss: 1.5433428287506104
Validation loss: 2.000215607304727

Epoch: 5| Step: 2
Training loss: 1.9883241653442383
Validation loss: 2.0021379788716636

Epoch: 5| Step: 3
Training loss: 1.407700538635254
Validation loss: 1.97857605513706

Epoch: 5| Step: 4
Training loss: 1.6178724765777588
Validation loss: 1.9847935092064641

Epoch: 5| Step: 5
Training loss: 1.4674018621444702
Validation loss: 1.9683649924493605

Epoch: 5| Step: 6
Training loss: 1.8129695653915405
Validation loss: 1.9742362909419562

Epoch: 5| Step: 7
Training loss: 2.1993727684020996
Validation loss: 1.9779014754038986

Epoch: 5| Step: 8
Training loss: 1.9978042840957642
Validation loss: 1.9756211234677223

Epoch: 5| Step: 9
Training loss: 1.9913667440414429
Validation loss: 1.9764192258158038

Epoch: 5| Step: 10
Training loss: 1.4594680070877075
Validation loss: 1.9839923330532607

Epoch: 149| Step: 0
Training loss: 1.6671535968780518
Validation loss: 1.9942607854002266

Epoch: 5| Step: 1
Training loss: 1.7357969284057617
Validation loss: 1.9952170977028467

Epoch: 5| Step: 2
Training loss: 1.8616565465927124
Validation loss: 1.999969305530671

Epoch: 5| Step: 3
Training loss: 1.6708015203475952
Validation loss: 2.0189763717753912

Epoch: 5| Step: 4
Training loss: 1.6470930576324463
Validation loss: 2.044033473537814

Epoch: 5| Step: 5
Training loss: 2.126520872116089
Validation loss: 2.071097513680817

Epoch: 5| Step: 6
Training loss: 1.1323833465576172
Validation loss: 2.066429224065555

Epoch: 5| Step: 7
Training loss: 2.1350035667419434
Validation loss: 2.069068662581905

Epoch: 5| Step: 8
Training loss: 1.4059677124023438
Validation loss: 2.068713773963272

Epoch: 5| Step: 9
Training loss: 1.6717475652694702
Validation loss: 2.075476336222823

Epoch: 5| Step: 10
Training loss: 2.041109800338745
Validation loss: 2.0549348579939974

Epoch: 150| Step: 0
Training loss: 1.9566078186035156
Validation loss: 2.0608206718198714

Epoch: 5| Step: 1
Training loss: 2.0997490882873535
Validation loss: 2.040434178485665

Epoch: 5| Step: 2
Training loss: 1.5168054103851318
Validation loss: 2.0021983513268093

Epoch: 5| Step: 3
Training loss: 1.4647988080978394
Validation loss: 2.0005503880080355

Epoch: 5| Step: 4
Training loss: 1.3699610233306885
Validation loss: 2.01941414289577

Epoch: 5| Step: 5
Training loss: 1.5155870914459229
Validation loss: 2.009125828742981

Epoch: 5| Step: 6
Training loss: 2.11543607711792
Validation loss: 2.0163543147425496

Epoch: 5| Step: 7
Training loss: 1.4124324321746826
Validation loss: 2.041867982956671

Epoch: 5| Step: 8
Training loss: 1.3458954095840454
Validation loss: 2.0548598330507994

Epoch: 5| Step: 9
Training loss: 1.880068063735962
Validation loss: 2.062088524141619

Epoch: 5| Step: 10
Training loss: 2.009800434112549
Validation loss: 2.058465496186287

Epoch: 151| Step: 0
Training loss: 2.5938587188720703
Validation loss: 2.0439983452520063

Epoch: 5| Step: 1
Training loss: 2.0110509395599365
Validation loss: 2.033910584706132

Epoch: 5| Step: 2
Training loss: 1.7297817468643188
Validation loss: 2.0217942858255036

Epoch: 5| Step: 3
Training loss: 1.682568907737732
Validation loss: 2.007992931591567

Epoch: 5| Step: 4
Training loss: 1.7577369213104248
Validation loss: 2.0047063494241364

Epoch: 5| Step: 5
Training loss: 0.8280919790267944
Validation loss: 2.013046572285314

Epoch: 5| Step: 6
Training loss: 1.4045817852020264
Validation loss: 2.0079106553908317

Epoch: 5| Step: 7
Training loss: 1.4430041313171387
Validation loss: 2.016744739265852

Epoch: 5| Step: 8
Training loss: 1.9291000366210938
Validation loss: 2.050024396629744

Epoch: 5| Step: 9
Training loss: 1.689340353012085
Validation loss: 2.067380186050169

Epoch: 5| Step: 10
Training loss: 1.722916603088379
Validation loss: 2.0677873857559694

Epoch: 152| Step: 0
Training loss: 1.5883216857910156
Validation loss: 2.056238628202869

Epoch: 5| Step: 1
Training loss: 1.6599289178848267
Validation loss: 2.038016669211849

Epoch: 5| Step: 2
Training loss: 1.8847782611846924
Validation loss: 2.0247518465083134

Epoch: 5| Step: 3
Training loss: 1.5102430582046509
Validation loss: 2.0220004896963797

Epoch: 5| Step: 4
Training loss: 2.050147533416748
Validation loss: 2.0198858502090618

Epoch: 5| Step: 5
Training loss: 1.7815558910369873
Validation loss: 2.0265944516786965

Epoch: 5| Step: 6
Training loss: 1.8259397745132446
Validation loss: 2.02920901262632

Epoch: 5| Step: 7
Training loss: 1.7619190216064453
Validation loss: 2.033825546182612

Epoch: 5| Step: 8
Training loss: 1.437028408050537
Validation loss: 2.048744482378806

Epoch: 5| Step: 9
Training loss: 1.4650089740753174
Validation loss: 2.066272712522937

Epoch: 5| Step: 10
Training loss: 1.3276877403259277
Validation loss: 2.0527897265649613

Epoch: 153| Step: 0
Training loss: 1.2713712453842163
Validation loss: 2.050435427696474

Epoch: 5| Step: 1
Training loss: 1.9088642597198486
Validation loss: 2.049254971165811

Epoch: 5| Step: 2
Training loss: 1.6352882385253906
Validation loss: 2.038421719304977

Epoch: 5| Step: 3
Training loss: 1.731909990310669
Validation loss: 2.024080491835071

Epoch: 5| Step: 4
Training loss: 1.8645050525665283
Validation loss: 2.028508286322317

Epoch: 5| Step: 5
Training loss: 1.3073289394378662
Validation loss: 2.0071268030392226

Epoch: 5| Step: 6
Training loss: 1.8889122009277344
Validation loss: 2.0064546036463913

Epoch: 5| Step: 7
Training loss: 1.6326881647109985
Validation loss: 1.9933864044886764

Epoch: 5| Step: 8
Training loss: 1.4974069595336914
Validation loss: 2.0097678451127905

Epoch: 5| Step: 9
Training loss: 1.6262569427490234
Validation loss: 2.0005534054130636

Epoch: 5| Step: 10
Training loss: 1.5139961242675781
Validation loss: 2.0196110330602175

Epoch: 154| Step: 0
Training loss: 1.4789572954177856
Validation loss: 1.995877327457551

Epoch: 5| Step: 1
Training loss: 1.3322746753692627
Validation loss: 2.0066385961348012

Epoch: 5| Step: 2
Training loss: 1.9100040197372437
Validation loss: 1.980861997091642

Epoch: 5| Step: 3
Training loss: 1.916823148727417
Validation loss: 2.006959069159723

Epoch: 5| Step: 4
Training loss: 2.0796263217926025
Validation loss: 2.016495371377596

Epoch: 5| Step: 5
Training loss: 1.5996794700622559
Validation loss: 2.029516355965727

Epoch: 5| Step: 6
Training loss: 0.9757317304611206
Validation loss: 2.037843028704325

Epoch: 5| Step: 7
Training loss: 1.4776532649993896
Validation loss: 2.039140162929412

Epoch: 5| Step: 8
Training loss: 1.2773973941802979
Validation loss: 2.0146195478336786

Epoch: 5| Step: 9
Training loss: 2.220392942428589
Validation loss: 2.014259501170087

Epoch: 5| Step: 10
Training loss: 1.652288794517517
Validation loss: 2.0117953669640327

Epoch: 155| Step: 0
Training loss: 1.9373023509979248
Validation loss: 2.0024464027855986

Epoch: 5| Step: 1
Training loss: 1.883776068687439
Validation loss: 1.9858805812815183

Epoch: 5| Step: 2
Training loss: 2.0183870792388916
Validation loss: 1.987744228814238

Epoch: 5| Step: 3
Training loss: 1.6522947549819946
Validation loss: 1.976043535817054

Epoch: 5| Step: 4
Training loss: 1.2987526655197144
Validation loss: 1.9733963140877344

Epoch: 5| Step: 5
Training loss: 1.386547327041626
Validation loss: 1.9680233655437347

Epoch: 5| Step: 6
Training loss: 1.5891401767730713
Validation loss: 1.9730946735669208

Epoch: 5| Step: 7
Training loss: 1.7820634841918945
Validation loss: 1.9714292492917789

Epoch: 5| Step: 8
Training loss: 1.2267314195632935
Validation loss: 1.9791896407322218

Epoch: 5| Step: 9
Training loss: 1.0746629238128662
Validation loss: 1.9844121471528084

Epoch: 5| Step: 10
Training loss: 1.5356476306915283
Validation loss: 1.9979964148613714

Epoch: 156| Step: 0
Training loss: 1.4941679239273071
Validation loss: 2.004359401682372

Epoch: 5| Step: 1
Training loss: 1.7966636419296265
Validation loss: 2.015736165867057

Epoch: 5| Step: 2
Training loss: 1.2801547050476074
Validation loss: 2.0218864461427093

Epoch: 5| Step: 3
Training loss: 1.786598801612854
Validation loss: 2.0182045659711285

Epoch: 5| Step: 4
Training loss: 1.6535682678222656
Validation loss: 2.012533535239517

Epoch: 5| Step: 5
Training loss: 1.604396104812622
Validation loss: 2.0290951703184392

Epoch: 5| Step: 6
Training loss: 1.9594612121582031
Validation loss: 2.022673237708307

Epoch: 5| Step: 7
Training loss: 1.5267311334609985
Validation loss: 2.0127661920362905

Epoch: 5| Step: 8
Training loss: 1.4088633060455322
Validation loss: 1.9947747030565817

Epoch: 5| Step: 9
Training loss: 1.1456445455551147
Validation loss: 2.0006307325055523

Epoch: 5| Step: 10
Training loss: 1.5855839252471924
Validation loss: 1.9939430144525343

Epoch: 157| Step: 0
Training loss: 1.648866891860962
Validation loss: 2.007955051237537

Epoch: 5| Step: 1
Training loss: 1.438603401184082
Validation loss: 2.006465196609497

Epoch: 5| Step: 2
Training loss: 1.2010418176651
Validation loss: 1.9927999268295944

Epoch: 5| Step: 3
Training loss: 1.2651102542877197
Validation loss: 2.018000989831904

Epoch: 5| Step: 4
Training loss: 1.6397759914398193
Validation loss: 2.0155334165019374

Epoch: 5| Step: 5
Training loss: 1.5558979511260986
Validation loss: 2.0190670746628956

Epoch: 5| Step: 6
Training loss: 1.7175624370574951
Validation loss: 2.0276625899858374

Epoch: 5| Step: 7
Training loss: 1.266129732131958
Validation loss: 2.011897711343663

Epoch: 5| Step: 8
Training loss: 2.114187717437744
Validation loss: 1.992340095581547

Epoch: 5| Step: 9
Training loss: 1.7859023809432983
Validation loss: 2.003937851998114

Epoch: 5| Step: 10
Training loss: 1.4935487508773804
Validation loss: 2.009686134194815

Epoch: 158| Step: 0
Training loss: 1.4680548906326294
Validation loss: 2.02069418661056

Epoch: 5| Step: 1
Training loss: 1.4977126121520996
Validation loss: 2.0280689847084785

Epoch: 5| Step: 2
Training loss: 1.6682018041610718
Validation loss: 2.0422354180325746

Epoch: 5| Step: 3
Training loss: 1.3145767450332642
Validation loss: 2.0343985685738186

Epoch: 5| Step: 4
Training loss: 1.291722059249878
Validation loss: 2.071557396201677

Epoch: 5| Step: 5
Training loss: 2.0546059608459473
Validation loss: 2.07160105564261

Epoch: 5| Step: 6
Training loss: 1.207922339439392
Validation loss: 2.0542014234809467

Epoch: 5| Step: 7
Training loss: 1.808061957359314
Validation loss: 2.028856199274781

Epoch: 5| Step: 8
Training loss: 1.2615476846694946
Validation loss: 2.017102820898897

Epoch: 5| Step: 9
Training loss: 1.753218412399292
Validation loss: 2.022266682758126

Epoch: 5| Step: 10
Training loss: 1.7859103679656982
Validation loss: 2.0136353290209206

Epoch: 159| Step: 0
Training loss: 1.6622425317764282
Validation loss: 2.0161113380103983

Epoch: 5| Step: 1
Training loss: 1.479630708694458
Validation loss: 2.0102835137356996

Epoch: 5| Step: 2
Training loss: 2.129777431488037
Validation loss: 1.9997819905639977

Epoch: 5| Step: 3
Training loss: 0.9819785356521606
Validation loss: 1.9852056887841993

Epoch: 5| Step: 4
Training loss: 1.312676191329956
Validation loss: 1.9925461379430627

Epoch: 5| Step: 5
Training loss: 1.6655895709991455
Validation loss: 2.016628401253813

Epoch: 5| Step: 6
Training loss: 1.6120703220367432
Validation loss: 2.0627238442820888

Epoch: 5| Step: 7
Training loss: 1.690739393234253
Validation loss: 2.049172665483208

Epoch: 5| Step: 8
Training loss: 1.108089566230774
Validation loss: 2.0514821929316365

Epoch: 5| Step: 9
Training loss: 1.2663930654525757
Validation loss: 2.0358743001055974

Epoch: 5| Step: 10
Training loss: 2.3303637504577637
Validation loss: 2.0250350634256997

Epoch: 160| Step: 0
Training loss: 1.6728172302246094
Validation loss: 2.003472343567879

Epoch: 5| Step: 1
Training loss: 1.5119621753692627
Validation loss: 1.9824234388207878

Epoch: 5| Step: 2
Training loss: 1.2263410091400146
Validation loss: 1.9597762964105094

Epoch: 5| Step: 3
Training loss: 1.6209118366241455
Validation loss: 1.9408228602460635

Epoch: 5| Step: 4
Training loss: 1.2969415187835693
Validation loss: 1.9544168595344789

Epoch: 5| Step: 5
Training loss: 2.0723049640655518
Validation loss: 1.9688846180515904

Epoch: 5| Step: 6
Training loss: 1.7491973638534546
Validation loss: 1.9648274696001442

Epoch: 5| Step: 7
Training loss: 1.2641061544418335
Validation loss: 1.9549966601915256

Epoch: 5| Step: 8
Training loss: 1.3870810270309448
Validation loss: 1.940920957954981

Epoch: 5| Step: 9
Training loss: 1.213649868965149
Validation loss: 1.9493891795476277

Epoch: 5| Step: 10
Training loss: 1.9887964725494385
Validation loss: 1.982169520470404

Epoch: 161| Step: 0
Training loss: 1.1347668170928955
Validation loss: 2.016892284475347

Epoch: 5| Step: 1
Training loss: 1.4979944229125977
Validation loss: 2.0304103564190608

Epoch: 5| Step: 2
Training loss: 1.727922797203064
Validation loss: 2.04836691194965

Epoch: 5| Step: 3
Training loss: 2.336216926574707
Validation loss: 2.0194527692692255

Epoch: 5| Step: 4
Training loss: 1.264176607131958
Validation loss: 2.0343576144146662

Epoch: 5| Step: 5
Training loss: 1.7534074783325195
Validation loss: 2.0613791147867837

Epoch: 5| Step: 6
Training loss: 1.8303651809692383
Validation loss: 2.0658944960563415

Epoch: 5| Step: 7
Training loss: 1.1783190965652466
Validation loss: 2.065598275071831

Epoch: 5| Step: 8
Training loss: 1.9372221231460571
Validation loss: 2.0739816657958494

Epoch: 5| Step: 9
Training loss: 1.2968482971191406
Validation loss: 2.021451965455086

Epoch: 5| Step: 10
Training loss: 1.2749052047729492
Validation loss: 1.983742613946238

Epoch: 162| Step: 0
Training loss: 0.569636344909668
Validation loss: 1.9703093562074887

Epoch: 5| Step: 1
Training loss: 1.7919282913208008
Validation loss: 1.9827354595225344

Epoch: 5| Step: 2
Training loss: 1.95585036277771
Validation loss: 2.042005444085726

Epoch: 5| Step: 3
Training loss: 0.7967789769172668
Validation loss: 2.038800322881309

Epoch: 5| Step: 4
Training loss: 2.126129627227783
Validation loss: 2.0325992107391357

Epoch: 5| Step: 5
Training loss: 1.6399637460708618
Validation loss: 1.9539160497726933

Epoch: 5| Step: 6
Training loss: 2.0308175086975098
Validation loss: 1.9268534914139779

Epoch: 5| Step: 7
Training loss: 1.9361302852630615
Validation loss: 1.8768163906630648

Epoch: 5| Step: 8
Training loss: 1.3792675733566284
Validation loss: 1.9016210635503132

Epoch: 5| Step: 9
Training loss: 1.2914589643478394
Validation loss: 1.929483393187164

Epoch: 5| Step: 10
Training loss: 1.5838892459869385
Validation loss: 1.9424793745881768

Epoch: 163| Step: 0
Training loss: 1.243767499923706
Validation loss: 1.9628789399259834

Epoch: 5| Step: 1
Training loss: 1.1428334712982178
Validation loss: 1.9559061822070871

Epoch: 5| Step: 2
Training loss: 1.3262016773223877
Validation loss: 1.9961725242676274

Epoch: 5| Step: 3
Training loss: 1.8994306325912476
Validation loss: 2.03922406447831

Epoch: 5| Step: 4
Training loss: 1.4706380367279053
Validation loss: 2.0410665824849117

Epoch: 5| Step: 5
Training loss: 1.2376365661621094
Validation loss: 2.0427937751175254

Epoch: 5| Step: 6
Training loss: 1.7257570028305054
Validation loss: 2.0404587625175394

Epoch: 5| Step: 7
Training loss: 1.8092056512832642
Validation loss: 2.0178521243474816

Epoch: 5| Step: 8
Training loss: 2.0935211181640625
Validation loss: 1.9893770781896447

Epoch: 5| Step: 9
Training loss: 1.4481124877929688
Validation loss: 1.9741639911487538

Epoch: 5| Step: 10
Training loss: 1.645517349243164
Validation loss: 1.9373601405851302

Epoch: 164| Step: 0
Training loss: 0.8722451329231262
Validation loss: 1.932848807304136

Epoch: 5| Step: 1
Training loss: 1.1680195331573486
Validation loss: 1.9282348822521906

Epoch: 5| Step: 2
Training loss: 1.8181114196777344
Validation loss: 1.9248945328497118

Epoch: 5| Step: 3
Training loss: 1.85440194606781
Validation loss: 1.9296166076455066

Epoch: 5| Step: 4
Training loss: 1.6226425170898438
Validation loss: 1.920762065918215

Epoch: 5| Step: 5
Training loss: 1.3065506219863892
Validation loss: 1.9220241141575638

Epoch: 5| Step: 6
Training loss: 1.1288387775421143
Validation loss: 1.943114052536667

Epoch: 5| Step: 7
Training loss: 1.9526245594024658
Validation loss: 1.9284684094049598

Epoch: 5| Step: 8
Training loss: 1.488308310508728
Validation loss: 1.9447775412631292

Epoch: 5| Step: 9
Training loss: 1.6179128885269165
Validation loss: 1.9829999131541098

Epoch: 5| Step: 10
Training loss: 1.725127100944519
Validation loss: 2.0112974618070867

Epoch: 165| Step: 0
Training loss: 1.1723284721374512
Validation loss: 2.065817161272931

Epoch: 5| Step: 1
Training loss: 1.1646957397460938
Validation loss: 2.061706681405344

Epoch: 5| Step: 2
Training loss: 1.8897908926010132
Validation loss: 2.030082186063131

Epoch: 5| Step: 3
Training loss: 1.249934434890747
Validation loss: 2.045931731500933

Epoch: 5| Step: 4
Training loss: 1.7321643829345703
Validation loss: 2.066399707589098

Epoch: 5| Step: 5
Training loss: 1.1156399250030518
Validation loss: 2.10192596784202

Epoch: 5| Step: 6
Training loss: 1.5779125690460205
Validation loss: 2.0811287267233736

Epoch: 5| Step: 7
Training loss: 1.3004803657531738
Validation loss: 2.0500162109251945

Epoch: 5| Step: 8
Training loss: 1.6100209951400757
Validation loss: 2.037626084461007

Epoch: 5| Step: 9
Training loss: 1.4087212085723877
Validation loss: 2.006666474444892

Epoch: 5| Step: 10
Training loss: 1.6254359483718872
Validation loss: 1.9855087649437688

Epoch: 166| Step: 0
Training loss: 1.2651551961898804
Validation loss: 1.9627157949632215

Epoch: 5| Step: 1
Training loss: 1.5843727588653564
Validation loss: 1.9612443344567412

Epoch: 5| Step: 2
Training loss: 1.2993131875991821
Validation loss: 1.9418802902262697

Epoch: 5| Step: 3
Training loss: 1.1105858087539673
Validation loss: 1.9207933564339914

Epoch: 5| Step: 4
Training loss: 1.708245038986206
Validation loss: 1.9197390220498527

Epoch: 5| Step: 5
Training loss: 1.8200302124023438
Validation loss: 1.9150067170461018

Epoch: 5| Step: 6
Training loss: 1.4845619201660156
Validation loss: 1.9357522226149035

Epoch: 5| Step: 7
Training loss: 1.2721900939941406
Validation loss: 1.9347066033271052

Epoch: 5| Step: 8
Training loss: 1.5218034982681274
Validation loss: 1.9210375226953977

Epoch: 5| Step: 9
Training loss: 1.4003121852874756
Validation loss: 1.9304091315115652

Epoch: 5| Step: 10
Training loss: 1.3938531875610352
Validation loss: 1.933263168540052

Epoch: 167| Step: 0
Training loss: 1.1370024681091309
Validation loss: 1.9493656363538516

Epoch: 5| Step: 1
Training loss: 1.5391027927398682
Validation loss: 1.9765184463993195

Epoch: 5| Step: 2
Training loss: 1.6473661661148071
Validation loss: 1.9843938260950067

Epoch: 5| Step: 3
Training loss: 1.2557132244110107
Validation loss: 2.007624299295487

Epoch: 5| Step: 4
Training loss: 0.9657354354858398
Validation loss: 1.9675215469893588

Epoch: 5| Step: 5
Training loss: 1.3401671648025513
Validation loss: 1.9765892887628207

Epoch: 5| Step: 6
Training loss: 1.7761646509170532
Validation loss: 1.96099651757107

Epoch: 5| Step: 7
Training loss: 1.8365799188613892
Validation loss: 1.9359928536158737

Epoch: 5| Step: 8
Training loss: 1.4808450937271118
Validation loss: 1.9149285208794378

Epoch: 5| Step: 9
Training loss: 1.5027759075164795
Validation loss: 1.9120011124559628

Epoch: 5| Step: 10
Training loss: 1.541686773300171
Validation loss: 1.9197462104981946

Epoch: 168| Step: 0
Training loss: 1.2673288583755493
Validation loss: 1.943825553822261

Epoch: 5| Step: 1
Training loss: 1.3424180746078491
Validation loss: 1.9449865254022742

Epoch: 5| Step: 2
Training loss: 1.3619663715362549
Validation loss: 1.9894446198658278

Epoch: 5| Step: 3
Training loss: 1.691255807876587
Validation loss: 2.0140310487439557

Epoch: 5| Step: 4
Training loss: 1.526397705078125
Validation loss: 2.0321803169865764

Epoch: 5| Step: 5
Training loss: 1.6246814727783203
Validation loss: 2.032504432944841

Epoch: 5| Step: 6
Training loss: 1.2557373046875
Validation loss: 2.01379685119916

Epoch: 5| Step: 7
Training loss: 1.447927713394165
Validation loss: 1.9972328011707594

Epoch: 5| Step: 8
Training loss: 1.3192387819290161
Validation loss: 1.991075732374704

Epoch: 5| Step: 9
Training loss: 1.347825050354004
Validation loss: 1.9903174087565432

Epoch: 5| Step: 10
Training loss: 1.4719321727752686
Validation loss: 1.9651560078385055

Epoch: 169| Step: 0
Training loss: 1.8935216665267944
Validation loss: 1.95686537027359

Epoch: 5| Step: 1
Training loss: 1.3877406120300293
Validation loss: 1.9459580836757537

Epoch: 5| Step: 2
Training loss: 1.5208264589309692
Validation loss: 1.9685212348097114

Epoch: 5| Step: 3
Training loss: 1.5323187112808228
Validation loss: 1.9934676001148839

Epoch: 5| Step: 4
Training loss: 1.3412392139434814
Validation loss: 1.9898093387644777

Epoch: 5| Step: 5
Training loss: 1.5145070552825928
Validation loss: 2.013610964180321

Epoch: 5| Step: 6
Training loss: 1.0329302549362183
Validation loss: 2.0224440661809777

Epoch: 5| Step: 7
Training loss: 1.7293012142181396
Validation loss: 1.9875602593985937

Epoch: 5| Step: 8
Training loss: 1.0647077560424805
Validation loss: 1.953776559522075

Epoch: 5| Step: 9
Training loss: 1.539048194885254
Validation loss: 1.9267839590708415

Epoch: 5| Step: 10
Training loss: 0.963140606880188
Validation loss: 1.9089023169650827

Epoch: 170| Step: 0
Training loss: 1.5737478733062744
Validation loss: 1.887721239879567

Epoch: 5| Step: 1
Training loss: 1.7218902111053467
Validation loss: 1.8798460088750368

Epoch: 5| Step: 2
Training loss: 1.5083774328231812
Validation loss: 1.876044423349442

Epoch: 5| Step: 3
Training loss: 1.4915788173675537
Validation loss: 1.8815463242992279

Epoch: 5| Step: 4
Training loss: 1.2554028034210205
Validation loss: 1.9009273141943

Epoch: 5| Step: 5
Training loss: 0.790404200553894
Validation loss: 1.891336517949258

Epoch: 5| Step: 6
Training loss: 1.5842716693878174
Validation loss: 1.9356908080398396

Epoch: 5| Step: 7
Training loss: 1.93123459815979
Validation loss: 1.9532805001863869

Epoch: 5| Step: 8
Training loss: 1.300523042678833
Validation loss: 1.9738311216395388

Epoch: 5| Step: 9
Training loss: 1.27680504322052
Validation loss: 1.9828180959147792

Epoch: 5| Step: 10
Training loss: 0.6776347756385803
Validation loss: 1.9797137219418761

Epoch: 171| Step: 0
Training loss: 1.111549973487854
Validation loss: 1.9680652579953593

Epoch: 5| Step: 1
Training loss: 1.2953457832336426
Validation loss: 1.9783308262466102

Epoch: 5| Step: 2
Training loss: 1.6934776306152344
Validation loss: 1.9785044090722197

Epoch: 5| Step: 3
Training loss: 1.1577621698379517
Validation loss: 1.991699549459642

Epoch: 5| Step: 4
Training loss: 1.6640708446502686
Validation loss: 1.975469131623545

Epoch: 5| Step: 5
Training loss: 1.3221522569656372
Validation loss: 1.9597235879590433

Epoch: 5| Step: 6
Training loss: 1.3370965719223022
Validation loss: 1.9675123101921492

Epoch: 5| Step: 7
Training loss: 1.2338169813156128
Validation loss: 1.9759672841718119

Epoch: 5| Step: 8
Training loss: 1.7385972738265991
Validation loss: 1.9834320365741689

Epoch: 5| Step: 9
Training loss: 1.2519078254699707
Validation loss: 2.016464348762266

Epoch: 5| Step: 10
Training loss: 0.9688637852668762
Validation loss: 2.006314307130793

Epoch: 172| Step: 0
Training loss: 1.6377136707305908
Validation loss: 2.013344241726783

Epoch: 5| Step: 1
Training loss: 1.4986371994018555
Validation loss: 2.039304066729802

Epoch: 5| Step: 2
Training loss: 1.6395196914672852
Validation loss: 2.0559675308965866

Epoch: 5| Step: 3
Training loss: 1.267911672592163
Validation loss: 2.054817714998799

Epoch: 5| Step: 4
Training loss: 1.2044765949249268
Validation loss: 2.0716521739959717

Epoch: 5| Step: 5
Training loss: 1.6673622131347656
Validation loss: 2.0849195141946115

Epoch: 5| Step: 6
Training loss: 1.1022555828094482
Validation loss: 2.070074294203071

Epoch: 5| Step: 7
Training loss: 1.2004754543304443
Validation loss: 2.037471171348326

Epoch: 5| Step: 8
Training loss: 0.784183144569397
Validation loss: 2.020544162360571

Epoch: 5| Step: 9
Training loss: 1.2934259176254272
Validation loss: 1.982201398059886

Epoch: 5| Step: 10
Training loss: 1.229374647140503
Validation loss: 1.9460222131462508

Epoch: 173| Step: 0
Training loss: 1.3740572929382324
Validation loss: 1.940306830149825

Epoch: 5| Step: 1
Training loss: 1.0535407066345215
Validation loss: 1.8941024977673766

Epoch: 5| Step: 2
Training loss: 1.4966537952423096
Validation loss: 1.8974017802105154

Epoch: 5| Step: 3
Training loss: 1.306819200515747
Validation loss: 1.8857092036995837

Epoch: 5| Step: 4
Training loss: 1.5375956296920776
Validation loss: 1.881105843410697

Epoch: 5| Step: 5
Training loss: 0.9132661819458008
Validation loss: 1.8893150898718065

Epoch: 5| Step: 6
Training loss: 1.5778203010559082
Validation loss: 1.9286201705214798

Epoch: 5| Step: 7
Training loss: 1.3673148155212402
Validation loss: 1.9480829008163945

Epoch: 5| Step: 8
Training loss: 1.2909698486328125
Validation loss: 1.980693506938155

Epoch: 5| Step: 9
Training loss: 1.511261224746704
Validation loss: 2.0235961932007984

Epoch: 5| Step: 10
Training loss: 1.138911247253418
Validation loss: 2.042003935383212

Epoch: 174| Step: 0
Training loss: 1.0915231704711914
Validation loss: 2.0398404367508425

Epoch: 5| Step: 1
Training loss: 1.3892252445220947
Validation loss: 2.0278773384709514

Epoch: 5| Step: 2
Training loss: 1.3855571746826172
Validation loss: 2.0505027322358984

Epoch: 5| Step: 3
Training loss: 1.1865723133087158
Validation loss: 2.0630931444065546

Epoch: 5| Step: 4
Training loss: 1.3344779014587402
Validation loss: 2.0538373711288616

Epoch: 5| Step: 5
Training loss: 1.0170302391052246
Validation loss: 1.9751993840740574

Epoch: 5| Step: 6
Training loss: 1.0843074321746826
Validation loss: 1.9341997677280056

Epoch: 5| Step: 7
Training loss: 1.3561747074127197
Validation loss: 1.9079759505487257

Epoch: 5| Step: 8
Training loss: 1.5811595916748047
Validation loss: 1.8876663510517409

Epoch: 5| Step: 9
Training loss: 1.146314263343811
Validation loss: 1.9039641913547312

Epoch: 5| Step: 10
Training loss: 1.8321161270141602
Validation loss: 1.899746948672879

Epoch: 175| Step: 0
Training loss: 1.2581874132156372
Validation loss: 1.8940031233654226

Epoch: 5| Step: 1
Training loss: 1.013620376586914
Validation loss: 1.9019610497259325

Epoch: 5| Step: 2
Training loss: 0.943824291229248
Validation loss: 1.8817607907838718

Epoch: 5| Step: 3
Training loss: 1.5409729480743408
Validation loss: 1.8537565482560026

Epoch: 5| Step: 4
Training loss: 1.2050318717956543
Validation loss: 1.8692048044614895

Epoch: 5| Step: 5
Training loss: 1.4775803089141846
Validation loss: 1.9078827147842736

Epoch: 5| Step: 6
Training loss: 1.8071041107177734
Validation loss: 1.9213606337065339

Epoch: 5| Step: 7
Training loss: 1.2805284261703491
Validation loss: 1.9358227534960675

Epoch: 5| Step: 8
Training loss: 1.1607141494750977
Validation loss: 1.9995174946323517

Epoch: 5| Step: 9
Training loss: 1.430846929550171
Validation loss: 2.0528873294912358

Epoch: 5| Step: 10
Training loss: 1.4811018705368042
Validation loss: 2.078630885770244

Epoch: 176| Step: 0
Training loss: 1.0084598064422607
Validation loss: 2.081990703459709

Epoch: 5| Step: 1
Training loss: 1.298672080039978
Validation loss: 2.019806364531158

Epoch: 5| Step: 2
Training loss: 1.175175428390503
Validation loss: 1.9743624656431136

Epoch: 5| Step: 3
Training loss: 1.259385347366333
Validation loss: 1.9454050679360666

Epoch: 5| Step: 4
Training loss: 1.3744289875030518
Validation loss: 1.9150301999943231

Epoch: 5| Step: 5
Training loss: 1.393969178199768
Validation loss: 1.9347783391193678

Epoch: 5| Step: 6
Training loss: 1.7914882898330688
Validation loss: 1.9153489169254099

Epoch: 5| Step: 7
Training loss: 1.5877141952514648
Validation loss: 1.9157861253266693

Epoch: 5| Step: 8
Training loss: 1.2160382270812988
Validation loss: 1.8879646434578845

Epoch: 5| Step: 9
Training loss: 1.4872033596038818
Validation loss: 1.8740639225129159

Epoch: 5| Step: 10
Training loss: 1.0863078832626343
Validation loss: 1.8671600613542783

Epoch: 177| Step: 0
Training loss: 1.1437652111053467
Validation loss: 1.8891311448107484

Epoch: 5| Step: 1
Training loss: 1.4733636379241943
Validation loss: 1.9156887274916454

Epoch: 5| Step: 2
Training loss: 1.3141709566116333
Validation loss: 1.9284968940160607

Epoch: 5| Step: 3
Training loss: 2.142803192138672
Validation loss: 1.9206375255379626

Epoch: 5| Step: 4
Training loss: 1.1276558637619019
Validation loss: 1.906420361611151

Epoch: 5| Step: 5
Training loss: 1.5382022857666016
Validation loss: 1.8864948698269424

Epoch: 5| Step: 6
Training loss: 0.7895469665527344
Validation loss: 1.883969440255114

Epoch: 5| Step: 7
Training loss: 1.2496445178985596
Validation loss: 1.8680007175732685

Epoch: 5| Step: 8
Training loss: 1.4990415573120117
Validation loss: 1.8820662203655447

Epoch: 5| Step: 9
Training loss: 0.9085679054260254
Validation loss: 1.8797232797068935

Epoch: 5| Step: 10
Training loss: 1.1224135160446167
Validation loss: 1.8649803925586004

Epoch: 178| Step: 0
Training loss: 1.0420525074005127
Validation loss: 1.8813269458791262

Epoch: 5| Step: 1
Training loss: 1.0978299379348755
Validation loss: 1.8724368797835482

Epoch: 5| Step: 2
Training loss: 1.1890180110931396
Validation loss: 1.8895350002473401

Epoch: 5| Step: 3
Training loss: 1.6066696643829346
Validation loss: 1.9353671330277638

Epoch: 5| Step: 4
Training loss: 1.2279266119003296
Validation loss: 1.9582214458014375

Epoch: 5| Step: 5
Training loss: 1.2287591695785522
Validation loss: 1.9500808933729767

Epoch: 5| Step: 6
Training loss: 1.5953738689422607
Validation loss: 1.9719416569637995

Epoch: 5| Step: 7
Training loss: 1.2036079168319702
Validation loss: 1.9375467531142696

Epoch: 5| Step: 8
Training loss: 1.2676525115966797
Validation loss: 1.932160714621185

Epoch: 5| Step: 9
Training loss: 1.5762028694152832
Validation loss: 1.92379577185518

Epoch: 5| Step: 10
Training loss: 0.9292956590652466
Validation loss: 1.918509478210121

Epoch: 179| Step: 0
Training loss: 1.0591853857040405
Validation loss: 1.9108091631243307

Epoch: 5| Step: 1
Training loss: 1.4180959463119507
Validation loss: 1.8904372158870901

Epoch: 5| Step: 2
Training loss: 0.8972126245498657
Validation loss: 1.8989020419377152

Epoch: 5| Step: 3
Training loss: 0.9828319549560547
Validation loss: 1.8932073744394446

Epoch: 5| Step: 4
Training loss: 1.1045825481414795
Validation loss: 1.9370428849292058

Epoch: 5| Step: 5
Training loss: 1.3023484945297241
Validation loss: 1.940796200947095

Epoch: 5| Step: 6
Training loss: 1.0310828685760498
Validation loss: 1.9393030879318074

Epoch: 5| Step: 7
Training loss: 1.2759530544281006
Validation loss: 1.9684996643374044

Epoch: 5| Step: 8
Training loss: 1.7430311441421509
Validation loss: 1.9620052947792956

Epoch: 5| Step: 9
Training loss: 1.4592363834381104
Validation loss: 1.970531016267756

Epoch: 5| Step: 10
Training loss: 1.4443351030349731
Validation loss: 1.9571923748139413

Epoch: 180| Step: 0
Training loss: 1.1511895656585693
Validation loss: 1.9469806468614967

Epoch: 5| Step: 1
Training loss: 1.1671113967895508
Validation loss: 1.9636597864089473

Epoch: 5| Step: 2
Training loss: 1.2220571041107178
Validation loss: 1.9652427396466654

Epoch: 5| Step: 3
Training loss: 1.0741978883743286
Validation loss: 1.9359304981846963

Epoch: 5| Step: 4
Training loss: 0.7708455920219421
Validation loss: 1.9624735104140414

Epoch: 5| Step: 5
Training loss: 1.4872065782546997
Validation loss: 2.002267615769499

Epoch: 5| Step: 6
Training loss: 1.224776268005371
Validation loss: 1.9865249151824622

Epoch: 5| Step: 7
Training loss: 1.6894667148590088
Validation loss: 1.98710383138349

Epoch: 5| Step: 8
Training loss: 1.1830800771713257
Validation loss: 1.9377191220560381

Epoch: 5| Step: 9
Training loss: 0.9285035133361816
Validation loss: 1.9089276380436395

Epoch: 5| Step: 10
Training loss: 1.3262758255004883
Validation loss: 1.926561185108718

Epoch: 181| Step: 0
Training loss: 0.9737730026245117
Validation loss: 1.9130510899328417

Epoch: 5| Step: 1
Training loss: 1.3477853536605835
Validation loss: 1.9331902086093862

Epoch: 5| Step: 2
Training loss: 1.371382713317871
Validation loss: 1.9272452105758011

Epoch: 5| Step: 3
Training loss: 1.0901283025741577
Validation loss: 1.9582628344976774

Epoch: 5| Step: 4
Training loss: 1.218244194984436
Validation loss: 1.9536756982085526

Epoch: 5| Step: 5
Training loss: 1.3603407144546509
Validation loss: 1.9770193061520975

Epoch: 5| Step: 6
Training loss: 1.5401809215545654
Validation loss: 1.9976684790785595

Epoch: 5| Step: 7
Training loss: 1.3473765850067139
Validation loss: 2.001782472415637

Epoch: 5| Step: 8
Training loss: 0.8055562973022461
Validation loss: 1.9526304557759275

Epoch: 5| Step: 9
Training loss: 1.1808264255523682
Validation loss: 1.9406256880811465

Epoch: 5| Step: 10
Training loss: 0.9195437431335449
Validation loss: 1.9485251416442215

Epoch: 182| Step: 0
Training loss: 1.4256953001022339
Validation loss: 1.9326094683780466

Epoch: 5| Step: 1
Training loss: 1.5034416913986206
Validation loss: 1.93797593732034

Epoch: 5| Step: 2
Training loss: 1.0371636152267456
Validation loss: 1.952027590044083

Epoch: 5| Step: 3
Training loss: 1.336796522140503
Validation loss: 1.9169534547354585

Epoch: 5| Step: 4
Training loss: 1.515263319015503
Validation loss: 1.897502440278248

Epoch: 5| Step: 5
Training loss: 0.9879277944564819
Validation loss: 1.9045749069542013

Epoch: 5| Step: 6
Training loss: 1.1315661668777466
Validation loss: 1.9431073063163347

Epoch: 5| Step: 7
Training loss: 0.918899416923523
Validation loss: 1.968206101848233

Epoch: 5| Step: 8
Training loss: 1.0384385585784912
Validation loss: 1.9670971209003079

Epoch: 5| Step: 9
Training loss: 1.415926218032837
Validation loss: 1.9811964329852854

Epoch: 5| Step: 10
Training loss: 1.1564418077468872
Validation loss: 1.9835476234395018

Epoch: 183| Step: 0
Training loss: 0.8127186894416809
Validation loss: 2.006691796805269

Epoch: 5| Step: 1
Training loss: 1.5321900844573975
Validation loss: 2.022453418342016

Epoch: 5| Step: 2
Training loss: 1.0078500509262085
Validation loss: 2.0343595358633224

Epoch: 5| Step: 3
Training loss: 1.3401912450790405
Validation loss: 2.0497242302022953

Epoch: 5| Step: 4
Training loss: 1.3033918142318726
Validation loss: 2.0283750398184663

Epoch: 5| Step: 5
Training loss: 1.1646195650100708
Validation loss: 2.0318641662597656

Epoch: 5| Step: 6
Training loss: 1.180696964263916
Validation loss: 2.0298721777495516

Epoch: 5| Step: 7
Training loss: 1.380963683128357
Validation loss: 2.029558761145479

Epoch: 5| Step: 8
Training loss: 0.6501075029373169
Validation loss: 2.0219306151072183

Epoch: 5| Step: 9
Training loss: 1.3488667011260986
Validation loss: 2.0490196520282375

Epoch: 5| Step: 10
Training loss: 1.4175876379013062
Validation loss: 2.020778089441279

Epoch: 184| Step: 0
Training loss: 1.1036235094070435
Validation loss: 2.0130593751066472

Epoch: 5| Step: 1
Training loss: 1.2579591274261475
Validation loss: 2.0043170067571823

Epoch: 5| Step: 2
Training loss: 1.4243404865264893
Validation loss: 1.9898225850956415

Epoch: 5| Step: 3
Training loss: 1.4659703969955444
Validation loss: 1.972688986409095

Epoch: 5| Step: 4
Training loss: 0.8417717814445496
Validation loss: 1.9425765545137468

Epoch: 5| Step: 5
Training loss: 0.9814094305038452
Validation loss: 1.916499089169246

Epoch: 5| Step: 6
Training loss: 0.8642263412475586
Validation loss: 1.8905563636492657

Epoch: 5| Step: 7
Training loss: 0.7537004947662354
Validation loss: 1.8839604123946159

Epoch: 5| Step: 8
Training loss: 1.5787146091461182
Validation loss: 1.8868183807660175

Epoch: 5| Step: 9
Training loss: 1.0688965320587158
Validation loss: 1.9124116013126988

Epoch: 5| Step: 10
Training loss: 1.465482234954834
Validation loss: 1.9419033142828173

Epoch: 185| Step: 0
Training loss: 1.2289416790008545
Validation loss: 2.0042309607228925

Epoch: 5| Step: 1
Training loss: 0.9958788156509399
Validation loss: 2.0440923347268054

Epoch: 5| Step: 2
Training loss: 1.5269540548324585
Validation loss: 2.1081317932375017

Epoch: 5| Step: 3
Training loss: 1.1113401651382446
Validation loss: 2.0887555076229956

Epoch: 5| Step: 4
Training loss: 1.226611852645874
Validation loss: 2.0771809188268517

Epoch: 5| Step: 5
Training loss: 1.6370865106582642
Validation loss: 2.027064618243966

Epoch: 5| Step: 6
Training loss: 1.0427100658416748
Validation loss: 1.9614672891555294

Epoch: 5| Step: 7
Training loss: 1.3949872255325317
Validation loss: 1.9127427871509264

Epoch: 5| Step: 8
Training loss: 1.229151725769043
Validation loss: 1.871645148082446

Epoch: 5| Step: 9
Training loss: 0.825649619102478
Validation loss: 1.814236722966676

Epoch: 5| Step: 10
Training loss: 1.1032166481018066
Validation loss: 1.8292313801345004

Epoch: 186| Step: 0
Training loss: 1.2032558917999268
Validation loss: 1.8422621757753435

Epoch: 5| Step: 1
Training loss: 1.1171997785568237
Validation loss: 1.8927640171461209

Epoch: 5| Step: 2
Training loss: 1.7486028671264648
Validation loss: 1.9057361169527935

Epoch: 5| Step: 3
Training loss: 1.2634532451629639
Validation loss: 1.9166086899336947

Epoch: 5| Step: 4
Training loss: 0.6851338148117065
Validation loss: 1.9329959551493328

Epoch: 5| Step: 5
Training loss: 1.5122836828231812
Validation loss: 1.946556419454595

Epoch: 5| Step: 6
Training loss: 0.9763875007629395
Validation loss: 1.9192764784700127

Epoch: 5| Step: 7
Training loss: 1.1703431606292725
Validation loss: 1.9372413453235422

Epoch: 5| Step: 8
Training loss: 1.033829927444458
Validation loss: 1.9676719993673346

Epoch: 5| Step: 9
Training loss: 0.9685166478157043
Validation loss: 1.9659281405069495

Epoch: 5| Step: 10
Training loss: 1.0158406496047974
Validation loss: 1.9449274642493135

Epoch: 187| Step: 0
Training loss: 1.0793921947479248
Validation loss: 1.9363911792796145

Epoch: 5| Step: 1
Training loss: 0.8752971887588501
Validation loss: 1.9226275925995202

Epoch: 5| Step: 2
Training loss: 1.0454288721084595
Validation loss: 1.888416632529228

Epoch: 5| Step: 3
Training loss: 1.537949800491333
Validation loss: 1.8958864083854101

Epoch: 5| Step: 4
Training loss: 1.580917239189148
Validation loss: 1.8899545477282615

Epoch: 5| Step: 5
Training loss: 1.1827492713928223
Validation loss: 1.8840336786803378

Epoch: 5| Step: 6
Training loss: 0.7668367624282837
Validation loss: 1.9055116150968818

Epoch: 5| Step: 7
Training loss: 0.8607950210571289
Validation loss: 1.931869782427306

Epoch: 5| Step: 8
Training loss: 1.1723674535751343
Validation loss: 1.9571129532270535

Epoch: 5| Step: 9
Training loss: 1.4355682134628296
Validation loss: 2.0058326105917654

Epoch: 5| Step: 10
Training loss: 0.8907037973403931
Validation loss: 2.0096054256603284

Epoch: 188| Step: 0
Training loss: 1.2027150392532349
Validation loss: 2.0069647950510823

Epoch: 5| Step: 1
Training loss: 1.2703503370285034
Validation loss: 1.9774562440892702

Epoch: 5| Step: 2
Training loss: 1.092036485671997
Validation loss: 1.9528954721266223

Epoch: 5| Step: 3
Training loss: 1.168040156364441
Validation loss: 1.9091205007286483

Epoch: 5| Step: 4
Training loss: 0.8229151964187622
Validation loss: 1.8913402800918908

Epoch: 5| Step: 5
Training loss: 0.6777084469795227
Validation loss: 1.8778476689451484

Epoch: 5| Step: 6
Training loss: 1.2355549335479736
Validation loss: 1.8436851219464374

Epoch: 5| Step: 7
Training loss: 1.1385396718978882
Validation loss: 1.8640090355309107

Epoch: 5| Step: 8
Training loss: 1.2111133337020874
Validation loss: 1.8421381340231946

Epoch: 5| Step: 9
Training loss: 1.0339299440383911
Validation loss: 1.8418815905048

Epoch: 5| Step: 10
Training loss: 1.3350932598114014
Validation loss: 1.8521341867344354

Epoch: 189| Step: 0
Training loss: 0.9494105577468872
Validation loss: 1.8702617909318657

Epoch: 5| Step: 1
Training loss: 1.2399429082870483
Validation loss: 1.8908686458423574

Epoch: 5| Step: 2
Training loss: 1.3867619037628174
Validation loss: 1.9377575920474144

Epoch: 5| Step: 3
Training loss: 1.0986188650131226
Validation loss: 1.922684759222051

Epoch: 5| Step: 4
Training loss: 1.1415717601776123
Validation loss: 1.9191657394491217

Epoch: 5| Step: 5
Training loss: 0.5395100712776184
Validation loss: 1.920216638554809

Epoch: 5| Step: 6
Training loss: 0.8167614936828613
Validation loss: 1.9221200058537145

Epoch: 5| Step: 7
Training loss: 1.077062726020813
Validation loss: 1.9305443289459392

Epoch: 5| Step: 8
Training loss: 1.2016606330871582
Validation loss: 1.9430653638737176

Epoch: 5| Step: 9
Training loss: 1.3376057147979736
Validation loss: 1.9396105389441214

Epoch: 5| Step: 10
Training loss: 1.2500638961791992
Validation loss: 1.9409435359380578

Epoch: 190| Step: 0
Training loss: 0.8456117510795593
Validation loss: 1.9521270721189437

Epoch: 5| Step: 1
Training loss: 1.0927846431732178
Validation loss: 1.9446207746382682

Epoch: 5| Step: 2
Training loss: 1.1809333562850952
Validation loss: 1.93412559904078

Epoch: 5| Step: 3
Training loss: 1.0717910528182983
Validation loss: 1.9663588359791746

Epoch: 5| Step: 4
Training loss: 1.2795684337615967
Validation loss: 2.005158278249925

Epoch: 5| Step: 5
Training loss: 0.9871547818183899
Validation loss: 2.037966348791635

Epoch: 5| Step: 6
Training loss: 1.2086330652236938
Validation loss: 2.007153962248115

Epoch: 5| Step: 7
Training loss: 1.2763700485229492
Validation loss: 1.9810848851357736

Epoch: 5| Step: 8
Training loss: 0.9987495541572571
Validation loss: 1.9133261185820385

Epoch: 5| Step: 9
Training loss: 0.7092541456222534
Validation loss: 1.9309195151893042

Epoch: 5| Step: 10
Training loss: 1.1723719835281372
Validation loss: 1.9314391382278935

Epoch: 191| Step: 0
Training loss: 0.9363992810249329
Validation loss: 1.9391814508745748

Epoch: 5| Step: 1
Training loss: 1.1396417617797852
Validation loss: 1.9393003935454993

Epoch: 5| Step: 2
Training loss: 1.145619511604309
Validation loss: 1.9127802464269823

Epoch: 5| Step: 3
Training loss: 0.9539626836776733
Validation loss: 1.932054663217196

Epoch: 5| Step: 4
Training loss: 1.1208399534225464
Validation loss: 1.9310810309584423

Epoch: 5| Step: 5
Training loss: 1.2792537212371826
Validation loss: 1.9876308184798046

Epoch: 5| Step: 6
Training loss: 0.7922691702842712
Validation loss: 2.024320576780586

Epoch: 5| Step: 7
Training loss: 1.3391027450561523
Validation loss: 2.057877352160792

Epoch: 5| Step: 8
Training loss: 1.8034824132919312
Validation loss: 2.027145221669187

Epoch: 5| Step: 9
Training loss: 0.47491326928138733
Validation loss: 1.97974609046854

Epoch: 5| Step: 10
Training loss: 1.0487067699432373
Validation loss: 1.9468846808197677

Epoch: 192| Step: 0
Training loss: 1.2434675693511963
Validation loss: 1.9403872823202482

Epoch: 5| Step: 1
Training loss: 0.9082916378974915
Validation loss: 1.944318293243326

Epoch: 5| Step: 2
Training loss: 0.9682407379150391
Validation loss: 1.920185951776402

Epoch: 5| Step: 3
Training loss: 1.582176923751831
Validation loss: 1.924408353785033

Epoch: 5| Step: 4
Training loss: 1.0802377462387085
Validation loss: 1.8938255233149375

Epoch: 5| Step: 5
Training loss: 1.0284267663955688
Validation loss: 1.8782819278778569

Epoch: 5| Step: 6
Training loss: 0.9158428311347961
Validation loss: 1.925971237562036

Epoch: 5| Step: 7
Training loss: 0.9334399104118347
Validation loss: 1.9498142503922986

Epoch: 5| Step: 8
Training loss: 1.1182358264923096
Validation loss: 1.996362114465365

Epoch: 5| Step: 9
Training loss: 1.2812528610229492
Validation loss: 1.9711809671053322

Epoch: 5| Step: 10
Training loss: 0.9823496341705322
Validation loss: 2.010801907508604

Epoch: 193| Step: 0
Training loss: 0.7328903675079346
Validation loss: 2.011819585677116

Epoch: 5| Step: 1
Training loss: 0.6957477331161499
Validation loss: 2.013615867143036

Epoch: 5| Step: 2
Training loss: 1.059361219406128
Validation loss: 1.97391927114097

Epoch: 5| Step: 3
Training loss: 0.8213573694229126
Validation loss: 1.9592981146227928

Epoch: 5| Step: 4
Training loss: 1.2466990947723389
Validation loss: 1.9356196990577124

Epoch: 5| Step: 5
Training loss: 1.0938926935195923
Validation loss: 1.9277165012974893

Epoch: 5| Step: 6
Training loss: 1.1162163019180298
Validation loss: 1.9119343808902207

Epoch: 5| Step: 7
Training loss: 1.557288408279419
Validation loss: 1.914973037217253

Epoch: 5| Step: 8
Training loss: 0.7456616163253784
Validation loss: 1.9221088604260517

Epoch: 5| Step: 9
Training loss: 1.397494912147522
Validation loss: 1.949375403824673

Epoch: 5| Step: 10
Training loss: 1.0397329330444336
Validation loss: 1.9800821811922136

Epoch: 194| Step: 0
Training loss: 1.0305854082107544
Validation loss: 1.9676753679911296

Epoch: 5| Step: 1
Training loss: 1.112419605255127
Validation loss: 1.9541520559659569

Epoch: 5| Step: 2
Training loss: 0.8463619351387024
Validation loss: 1.943993014674033

Epoch: 5| Step: 3
Training loss: 1.1352097988128662
Validation loss: 1.9951562996833556

Epoch: 5| Step: 4
Training loss: 1.2590444087982178
Validation loss: 1.9715295017406504

Epoch: 5| Step: 5
Training loss: 1.2372815608978271
Validation loss: 1.9784155045786211

Epoch: 5| Step: 6
Training loss: 0.7158018350601196
Validation loss: 1.9486908041020876

Epoch: 5| Step: 7
Training loss: 0.8005883097648621
Validation loss: 1.9193984423914263

Epoch: 5| Step: 8
Training loss: 1.1680680513381958
Validation loss: 1.903020720328054

Epoch: 5| Step: 9
Training loss: 1.1868813037872314
Validation loss: 1.8607934674909037

Epoch: 5| Step: 10
Training loss: 0.8134579658508301
Validation loss: 1.8262984534745574

Epoch: 195| Step: 0
Training loss: 0.9167996644973755
Validation loss: 1.8046921055804017

Epoch: 5| Step: 1
Training loss: 1.1161038875579834
Validation loss: 1.819513455513985

Epoch: 5| Step: 2
Training loss: 1.1787352561950684
Validation loss: 1.8137577618322065

Epoch: 5| Step: 3
Training loss: 1.0356048345565796
Validation loss: 1.833948589140369

Epoch: 5| Step: 4
Training loss: 1.4145305156707764
Validation loss: 1.8501884693740516

Epoch: 5| Step: 5
Training loss: 1.0633131265640259
Validation loss: 1.84004755045778

Epoch: 5| Step: 6
Training loss: 0.7944901585578918
Validation loss: 1.8409222018334173

Epoch: 5| Step: 7
Training loss: 0.957187831401825
Validation loss: 1.9108247897958244

Epoch: 5| Step: 8
Training loss: 1.1231775283813477
Validation loss: 1.9325415793285574

Epoch: 5| Step: 9
Training loss: 1.0738017559051514
Validation loss: 1.9714037167128695

Epoch: 5| Step: 10
Training loss: 0.8669317960739136
Validation loss: 2.0009707994358514

Epoch: 196| Step: 0
Training loss: 0.8763464093208313
Validation loss: 1.9727792457867694

Epoch: 5| Step: 1
Training loss: 1.1078813076019287
Validation loss: 1.9814607609984696

Epoch: 5| Step: 2
Training loss: 0.7766715288162231
Validation loss: 1.946108692435808

Epoch: 5| Step: 3
Training loss: 1.1570876836776733
Validation loss: 1.927933516040925

Epoch: 5| Step: 4
Training loss: 1.1092156171798706
Validation loss: 1.9071173039815759

Epoch: 5| Step: 5
Training loss: 0.8335739970207214
Validation loss: 1.8955447212342293

Epoch: 5| Step: 6
Training loss: 1.152340292930603
Validation loss: 1.879540607493411

Epoch: 5| Step: 7
Training loss: 1.167065978050232
Validation loss: 1.8806458339896253

Epoch: 5| Step: 8
Training loss: 0.5102027654647827
Validation loss: 1.882197485175184

Epoch: 5| Step: 9
Training loss: 1.4077742099761963
Validation loss: 1.8984606163476103

Epoch: 5| Step: 10
Training loss: 1.1668009757995605
Validation loss: 1.895252235474125

Epoch: 197| Step: 0
Training loss: 1.1141711473464966
Validation loss: 1.9104720597626061

Epoch: 5| Step: 1
Training loss: 0.9734237790107727
Validation loss: 1.9098982413609822

Epoch: 5| Step: 2
Training loss: 0.9786728024482727
Validation loss: 1.9429249391760877

Epoch: 5| Step: 3
Training loss: 0.9150818586349487
Validation loss: 1.9465885034171484

Epoch: 5| Step: 4
Training loss: 0.8541485071182251
Validation loss: 1.9710306557275916

Epoch: 5| Step: 5
Training loss: 1.3265159130096436
Validation loss: 1.9776411492337462

Epoch: 5| Step: 6
Training loss: 1.2993196249008179
Validation loss: 2.0008485317230225

Epoch: 5| Step: 7
Training loss: 1.1554487943649292
Validation loss: 1.9876117334570935

Epoch: 5| Step: 8
Training loss: 0.6373013257980347
Validation loss: 1.9863463742758638

Epoch: 5| Step: 9
Training loss: 0.7342620491981506
Validation loss: 1.9393927640812372

Epoch: 5| Step: 10
Training loss: 1.1410263776779175
Validation loss: 1.9435820643619826

Epoch: 198| Step: 0
Training loss: 0.8112815022468567
Validation loss: 1.9447048235965032

Epoch: 5| Step: 1
Training loss: 1.2062362432479858
Validation loss: 1.9350266789877286

Epoch: 5| Step: 2
Training loss: 0.9971809387207031
Validation loss: 1.9158620193440428

Epoch: 5| Step: 3
Training loss: 1.0551475286483765
Validation loss: 1.887650038606377

Epoch: 5| Step: 4
Training loss: 1.2842998504638672
Validation loss: 1.8831559073540471

Epoch: 5| Step: 5
Training loss: 0.8523966073989868
Validation loss: 1.8463341279696392

Epoch: 5| Step: 6
Training loss: 0.9951661825180054
Validation loss: 1.8682526337203158

Epoch: 5| Step: 7
Training loss: 0.7908282279968262
Validation loss: 1.8672342172233007

Epoch: 5| Step: 8
Training loss: 0.9211885333061218
Validation loss: 1.8795745090771747

Epoch: 5| Step: 9
Training loss: 1.1613279581069946
Validation loss: 1.8840508307180097

Epoch: 5| Step: 10
Training loss: 0.6466624140739441
Validation loss: 1.903511820300933

Epoch: 199| Step: 0
Training loss: 0.9239271283149719
Validation loss: 1.9335275849988383

Epoch: 5| Step: 1
Training loss: 0.8341646194458008
Validation loss: 1.9327157287187473

Epoch: 5| Step: 2
Training loss: 0.874172031879425
Validation loss: 1.9751761574898996

Epoch: 5| Step: 3
Training loss: 0.948407769203186
Validation loss: 1.9543568882890927

Epoch: 5| Step: 4
Training loss: 1.1511940956115723
Validation loss: 1.978801529894593

Epoch: 5| Step: 5
Training loss: 0.8155421018600464
Validation loss: 1.9896119999629196

Epoch: 5| Step: 6
Training loss: 1.3612830638885498
Validation loss: 1.9910958325991066

Epoch: 5| Step: 7
Training loss: 0.9026603698730469
Validation loss: 2.0326472379828013

Epoch: 5| Step: 8
Training loss: 1.0080838203430176
Validation loss: 1.9842002955816125

Epoch: 5| Step: 9
Training loss: 0.869968056678772
Validation loss: 1.9839852856051536

Epoch: 5| Step: 10
Training loss: 1.052302598953247
Validation loss: 1.9108454694030106

Epoch: 200| Step: 0
Training loss: 0.732623815536499
Validation loss: 1.9023008808012931

Epoch: 5| Step: 1
Training loss: 1.00630784034729
Validation loss: 1.8935858780337917

Epoch: 5| Step: 2
Training loss: 1.0594913959503174
Validation loss: 1.8838471968968709

Epoch: 5| Step: 3
Training loss: 1.149678111076355
Validation loss: 1.9310702611041326

Epoch: 5| Step: 4
Training loss: 1.021751046180725
Validation loss: 1.9219456129176642

Epoch: 5| Step: 5
Training loss: 1.182276964187622
Validation loss: 1.9420841329841203

Epoch: 5| Step: 6
Training loss: 1.377920150756836
Validation loss: 1.9564405577157133

Epoch: 5| Step: 7
Training loss: 0.8174998164176941
Validation loss: 1.9841621255361905

Epoch: 5| Step: 8
Training loss: 0.6342982053756714
Validation loss: 1.9858933289845784

Epoch: 5| Step: 9
Training loss: 0.9724264144897461
Validation loss: 2.0230508581284554

Epoch: 5| Step: 10
Training loss: 0.8619852066040039
Validation loss: 2.053285865373509

Epoch: 201| Step: 0
Training loss: 1.0179920196533203
Validation loss: 2.0867807429323912

Epoch: 5| Step: 1
Training loss: 0.8380200266838074
Validation loss: 2.0850634369798886

Epoch: 5| Step: 2
Training loss: 0.948686957359314
Validation loss: 2.040064109269009

Epoch: 5| Step: 3
Training loss: 0.8191377520561218
Validation loss: 1.9946512329962947

Epoch: 5| Step: 4
Training loss: 0.8108202219009399
Validation loss: 1.9546503200325915

Epoch: 5| Step: 5
Training loss: 1.0128358602523804
Validation loss: 1.900575953145181

Epoch: 5| Step: 6
Training loss: 0.8267213702201843
Validation loss: 1.863799507899951

Epoch: 5| Step: 7
Training loss: 1.3170523643493652
Validation loss: 1.8750745019605082

Epoch: 5| Step: 8
Training loss: 1.1784604787826538
Validation loss: 1.857575148664495

Epoch: 5| Step: 9
Training loss: 1.0385030508041382
Validation loss: 1.8539916366659186

Epoch: 5| Step: 10
Training loss: 1.0487890243530273
Validation loss: 1.8576437606606433

Epoch: 202| Step: 0
Training loss: 0.637018084526062
Validation loss: 1.8436543826133973

Epoch: 5| Step: 1
Training loss: 1.6280543804168701
Validation loss: 1.85541449182777

Epoch: 5| Step: 2
Training loss: 0.7121779322624207
Validation loss: 1.8850431044896443

Epoch: 5| Step: 3
Training loss: 1.248260259628296
Validation loss: 1.8782836301352388

Epoch: 5| Step: 4
Training loss: 1.4109127521514893
Validation loss: 1.931731339423887

Epoch: 5| Step: 5
Training loss: 0.7217508554458618
Validation loss: 1.9396037670873827

Epoch: 5| Step: 6
Training loss: 0.9146559834480286
Validation loss: 1.979201239924277

Epoch: 5| Step: 7
Training loss: 1.062137484550476
Validation loss: 1.9817440355977705

Epoch: 5| Step: 8
Training loss: 0.6944609880447388
Validation loss: 1.9590537509610575

Epoch: 5| Step: 9
Training loss: 0.5660480260848999
Validation loss: 1.9357385661012383

Epoch: 5| Step: 10
Training loss: 0.8953073620796204
Validation loss: 1.9059497053905199

Epoch: 203| Step: 0
Training loss: 0.8834174871444702
Validation loss: 1.8750164355001142

Epoch: 5| Step: 1
Training loss: 0.5825458765029907
Validation loss: 1.834267318889659

Epoch: 5| Step: 2
Training loss: 0.7578499913215637
Validation loss: 1.8353183320773545

Epoch: 5| Step: 3
Training loss: 1.0773084163665771
Validation loss: 1.8132215917751353

Epoch: 5| Step: 4
Training loss: 1.030440330505371
Validation loss: 1.8281051907488095

Epoch: 5| Step: 5
Training loss: 1.2599360942840576
Validation loss: 1.8485461101737073

Epoch: 5| Step: 6
Training loss: 1.2563488483428955
Validation loss: 1.866305338439121

Epoch: 5| Step: 7
Training loss: 0.8166515231132507
Validation loss: 1.8941117640464538

Epoch: 5| Step: 8
Training loss: 1.4449598789215088
Validation loss: 1.9390656973726006

Epoch: 5| Step: 9
Training loss: 0.6507071852684021
Validation loss: 1.9641433095419278

Epoch: 5| Step: 10
Training loss: 0.9978996515274048
Validation loss: 1.9864536267454906

Epoch: 204| Step: 0
Training loss: 0.8148622512817383
Validation loss: 2.018637204682955

Epoch: 5| Step: 1
Training loss: 0.8157840967178345
Validation loss: 2.0166083253839964

Epoch: 5| Step: 2
Training loss: 0.7534521818161011
Validation loss: 2.030281912895941

Epoch: 5| Step: 3
Training loss: 1.2632626295089722
Validation loss: 2.018319127380207

Epoch: 5| Step: 4
Training loss: 0.4266429543495178
Validation loss: 1.9734314974918161

Epoch: 5| Step: 5
Training loss: 1.043602705001831
Validation loss: 1.9541704090692664

Epoch: 5| Step: 6
Training loss: 0.698958694934845
Validation loss: 1.923545745111281

Epoch: 5| Step: 7
Training loss: 0.9085559844970703
Validation loss: 1.916210647552244

Epoch: 5| Step: 8
Training loss: 1.5522139072418213
Validation loss: 1.9177068523181382

Epoch: 5| Step: 9
Training loss: 0.8177394866943359
Validation loss: 1.9225252751381166

Epoch: 5| Step: 10
Training loss: 0.9675909876823425
Validation loss: 1.8757832075959893

Epoch: 205| Step: 0
Training loss: 0.7840896844863892
Validation loss: 1.8669198841177008

Epoch: 5| Step: 1
Training loss: 0.8990017771720886
Validation loss: 1.8877691607321463

Epoch: 5| Step: 2
Training loss: 1.0986030101776123
Validation loss: 1.8800453332162672

Epoch: 5| Step: 3
Training loss: 1.2189886569976807
Validation loss: 1.8681659403667654

Epoch: 5| Step: 4
Training loss: 0.9496153593063354
Validation loss: 1.9211019687755133

Epoch: 5| Step: 5
Training loss: 0.3899964392185211
Validation loss: 1.93301559007296

Epoch: 5| Step: 6
Training loss: 0.9904131889343262
Validation loss: 1.9532781698370492

Epoch: 5| Step: 7
Training loss: 1.0362310409545898
Validation loss: 1.961998631877284

Epoch: 5| Step: 8
Training loss: 0.9077569246292114
Validation loss: 1.9633766258916547

Epoch: 5| Step: 9
Training loss: 0.6212080717086792
Validation loss: 1.9551409008682414

Epoch: 5| Step: 10
Training loss: 0.9975137114524841
Validation loss: 1.9445372089262931

Epoch: 206| Step: 0
Training loss: 0.6897091865539551
Validation loss: 1.8905067725848126

Epoch: 5| Step: 1
Training loss: 1.1506751775741577
Validation loss: 1.8967760634678665

Epoch: 5| Step: 2
Training loss: 0.6690937280654907
Validation loss: 1.8487989005222116

Epoch: 5| Step: 3
Training loss: 0.9849172830581665
Validation loss: 1.8809911692014305

Epoch: 5| Step: 4
Training loss: 1.2109792232513428
Validation loss: 1.8446327588891471

Epoch: 5| Step: 5
Training loss: 1.0606721639633179
Validation loss: 1.8493337990135275

Epoch: 5| Step: 6
Training loss: 0.7509011030197144
Validation loss: 1.843799957665064

Epoch: 5| Step: 7
Training loss: 0.797813355922699
Validation loss: 1.8337493288901545

Epoch: 5| Step: 8
Training loss: 1.015878677368164
Validation loss: 1.858651570094529

Epoch: 5| Step: 9
Training loss: 1.1465208530426025
Validation loss: 1.841499194022148

Epoch: 5| Step: 10
Training loss: 0.4877876937389374
Validation loss: 1.869456139943933

Epoch: 207| Step: 0
Training loss: 0.5451536178588867
Validation loss: 1.8746217578969977

Epoch: 5| Step: 1
Training loss: 0.8247011303901672
Validation loss: 1.899809609177292

Epoch: 5| Step: 2
Training loss: 1.1099879741668701
Validation loss: 1.8623599954830703

Epoch: 5| Step: 3
Training loss: 0.6621526479721069
Validation loss: 1.871067576510932

Epoch: 5| Step: 4
Training loss: 1.3592958450317383
Validation loss: 1.8851730567152782

Epoch: 5| Step: 5
Training loss: 1.096442699432373
Validation loss: 1.8990010471754177

Epoch: 5| Step: 6
Training loss: 0.9539033770561218
Validation loss: 1.8751919961744739

Epoch: 5| Step: 7
Training loss: 0.5073167085647583
Validation loss: 1.918084180483254

Epoch: 5| Step: 8
Training loss: 0.7522064447402954
Validation loss: 1.9128241974820372

Epoch: 5| Step: 9
Training loss: 0.5911396741867065
Validation loss: 1.9400632368621005

Epoch: 5| Step: 10
Training loss: 1.1162891387939453
Validation loss: 1.9243205183295793

Epoch: 208| Step: 0
Training loss: 0.6755474209785461
Validation loss: 1.9491915472092167

Epoch: 5| Step: 1
Training loss: 0.7686761617660522
Validation loss: 1.9720068798270276

Epoch: 5| Step: 2
Training loss: 1.1905949115753174
Validation loss: 1.9413393492339759

Epoch: 5| Step: 3
Training loss: 0.7875000238418579
Validation loss: 1.9272296479953233

Epoch: 5| Step: 4
Training loss: 1.039246916770935
Validation loss: 1.9316952126000517

Epoch: 5| Step: 5
Training loss: 0.8421496152877808
Validation loss: 1.8971206154874576

Epoch: 5| Step: 6
Training loss: 1.0393106937408447
Validation loss: 1.8938950697580974

Epoch: 5| Step: 7
Training loss: 0.7577718496322632
Validation loss: 1.8853818011540238

Epoch: 5| Step: 8
Training loss: 0.810870349407196
Validation loss: 1.8761345699269285

Epoch: 5| Step: 9
Training loss: 0.7864095568656921
Validation loss: 1.893323020268512

Epoch: 5| Step: 10
Training loss: 0.9533714056015015
Validation loss: 1.896794488353114

Epoch: 209| Step: 0
Training loss: 0.9243760108947754
Validation loss: 1.9067149892930062

Epoch: 5| Step: 1
Training loss: 1.3319153785705566
Validation loss: 1.896547773832916

Epoch: 5| Step: 2
Training loss: 0.4834681451320648
Validation loss: 1.9032097606248752

Epoch: 5| Step: 3
Training loss: 0.6490351557731628
Validation loss: 1.904327295159781

Epoch: 5| Step: 4
Training loss: 0.7258512377738953
Validation loss: 1.876030437407955

Epoch: 5| Step: 5
Training loss: 0.7346863746643066
Validation loss: 1.837224333517013

Epoch: 5| Step: 6
Training loss: 0.8592621088027954
Validation loss: 1.8413282991737447

Epoch: 5| Step: 7
Training loss: 0.9060287475585938
Validation loss: 1.796312346253344

Epoch: 5| Step: 8
Training loss: 0.6465283036231995
Validation loss: 1.845495803381807

Epoch: 5| Step: 9
Training loss: 1.0680818557739258
Validation loss: 1.8603356192188878

Epoch: 5| Step: 10
Training loss: 0.9844771027565002
Validation loss: 1.873880910617049

Epoch: 210| Step: 0
Training loss: 0.5808404684066772
Validation loss: 1.8912228973962928

Epoch: 5| Step: 1
Training loss: 0.9011285901069641
Validation loss: 1.937308616535638

Epoch: 5| Step: 2
Training loss: 0.6105137467384338
Validation loss: 1.9388403482334589

Epoch: 5| Step: 3
Training loss: 1.1048506498336792
Validation loss: 1.9104495791978733

Epoch: 5| Step: 4
Training loss: 1.0226123332977295
Validation loss: 1.912924446085448

Epoch: 5| Step: 5
Training loss: 0.9238635897636414
Validation loss: 1.9059006770451863

Epoch: 5| Step: 6
Training loss: 1.0246105194091797
Validation loss: 1.916126258911625

Epoch: 5| Step: 7
Training loss: 0.8732145428657532
Validation loss: 1.8832711096732848

Epoch: 5| Step: 8
Training loss: 0.7302667498588562
Validation loss: 1.8850855058239353

Epoch: 5| Step: 9
Training loss: 0.652167558670044
Validation loss: 1.8882455184895506

Epoch: 5| Step: 10
Training loss: 1.0708528757095337
Validation loss: 1.8780514463301627

Epoch: 211| Step: 0
Training loss: 1.1345218420028687
Validation loss: 1.900402940729613

Epoch: 5| Step: 1
Training loss: 0.8390569686889648
Validation loss: 1.9399327475537536

Epoch: 5| Step: 2
Training loss: 0.8020967245101929
Validation loss: 1.904568705507504

Epoch: 5| Step: 3
Training loss: 0.9889934659004211
Validation loss: 1.9098059784981511

Epoch: 5| Step: 4
Training loss: 0.8673843145370483
Validation loss: 1.885604727652765

Epoch: 5| Step: 5
Training loss: 0.6830652952194214
Validation loss: 1.8850336869557698

Epoch: 5| Step: 6
Training loss: 0.7842450141906738
Validation loss: 1.8442721853974045

Epoch: 5| Step: 7
Training loss: 0.7578068971633911
Validation loss: 1.846672752852081

Epoch: 5| Step: 8
Training loss: 1.1412988901138306
Validation loss: 1.881793322101716

Epoch: 5| Step: 9
Training loss: 0.5989940762519836
Validation loss: 1.823268590434905

Epoch: 5| Step: 10
Training loss: 0.7227125763893127
Validation loss: 1.8394496761342531

Epoch: 212| Step: 0
Training loss: 0.7185200452804565
Validation loss: 1.8785311265658307

Epoch: 5| Step: 1
Training loss: 0.5343429446220398
Validation loss: 1.8696734482242214

Epoch: 5| Step: 2
Training loss: 0.6355575323104858
Validation loss: 1.8974898810027747

Epoch: 5| Step: 3
Training loss: 0.7253614664077759
Validation loss: 1.899119891146178

Epoch: 5| Step: 4
Training loss: 1.0649417638778687
Validation loss: 1.906362811724345

Epoch: 5| Step: 5
Training loss: 0.7586989998817444
Validation loss: 1.8839765274396507

Epoch: 5| Step: 6
Training loss: 1.0968191623687744
Validation loss: 1.9198047153411373

Epoch: 5| Step: 7
Training loss: 0.8821663856506348
Validation loss: 1.9696378887340587

Epoch: 5| Step: 8
Training loss: 0.7172179222106934
Validation loss: 1.9576043082821755

Epoch: 5| Step: 9
Training loss: 0.7860761284828186
Validation loss: 1.9437052434490574

Epoch: 5| Step: 10
Training loss: 1.112123727798462
Validation loss: 1.9128075620179534

Epoch: 213| Step: 0
Training loss: 0.873631477355957
Validation loss: 1.8734930099979523

Epoch: 5| Step: 1
Training loss: 0.8539857864379883
Validation loss: 1.8194377101877683

Epoch: 5| Step: 2
Training loss: 0.5535891652107239
Validation loss: 1.8175237050620459

Epoch: 5| Step: 3
Training loss: 1.0330216884613037
Validation loss: 1.7818151520144554

Epoch: 5| Step: 4
Training loss: 1.0484230518341064
Validation loss: 1.798515454415352

Epoch: 5| Step: 5
Training loss: 1.0546611547470093
Validation loss: 1.770783398741035

Epoch: 5| Step: 6
Training loss: 0.811065673828125
Validation loss: 1.8191302873755013

Epoch: 5| Step: 7
Training loss: 0.9871456027030945
Validation loss: 1.8288963892126595

Epoch: 5| Step: 8
Training loss: 0.9202176332473755
Validation loss: 1.8530398966163717

Epoch: 5| Step: 9
Training loss: 0.44069308042526245
Validation loss: 1.8804067565548805

Epoch: 5| Step: 10
Training loss: 0.8709079623222351
Validation loss: 1.9143014069526427

Epoch: 214| Step: 0
Training loss: 0.886196494102478
Validation loss: 1.9074682689482165

Epoch: 5| Step: 1
Training loss: 1.3780267238616943
Validation loss: 1.9086262295323033

Epoch: 5| Step: 2
Training loss: 0.7976564764976501
Validation loss: 1.933332589364821

Epoch: 5| Step: 3
Training loss: 0.8432145118713379
Validation loss: 1.9363227454564904

Epoch: 5| Step: 4
Training loss: 0.8666207194328308
Validation loss: 1.9044089394230996

Epoch: 5| Step: 5
Training loss: 0.7673853635787964
Validation loss: 1.8887519964607813

Epoch: 5| Step: 6
Training loss: 0.4201197624206543
Validation loss: 1.8635500092660227

Epoch: 5| Step: 7
Training loss: 0.9361310005187988
Validation loss: 1.8799189239419916

Epoch: 5| Step: 8
Training loss: 0.8180854916572571
Validation loss: 1.8617864924092447

Epoch: 5| Step: 9
Training loss: 0.805641770362854
Validation loss: 1.8770946161721342

Epoch: 5| Step: 10
Training loss: 0.6308758854866028
Validation loss: 1.9077888342642015

Epoch: 215| Step: 0
Training loss: 0.8519228100776672
Validation loss: 1.8788807776666456

Epoch: 5| Step: 1
Training loss: 0.9507709741592407
Validation loss: 1.8290762337305213

Epoch: 5| Step: 2
Training loss: 1.285582423210144
Validation loss: 1.8502391730585406

Epoch: 5| Step: 3
Training loss: 0.6349443197250366
Validation loss: 1.8350893348775885

Epoch: 5| Step: 4
Training loss: 0.941017746925354
Validation loss: 1.795982296748828

Epoch: 5| Step: 5
Training loss: 0.6282424926757812
Validation loss: 1.8123436025393906

Epoch: 5| Step: 6
Training loss: 0.5324512720108032
Validation loss: 1.8146621796392626

Epoch: 5| Step: 7
Training loss: 0.7423014044761658
Validation loss: 1.8044264893377981

Epoch: 5| Step: 8
Training loss: 0.7003795504570007
Validation loss: 1.8448796246641426

Epoch: 5| Step: 9
Training loss: 0.5367907881736755
Validation loss: 1.8917962915153914

Epoch: 5| Step: 10
Training loss: 1.1771881580352783
Validation loss: 1.9069511198228406

Epoch: 216| Step: 0
Training loss: 0.7077010273933411
Validation loss: 1.871416321364782

Epoch: 5| Step: 1
Training loss: 1.0704421997070312
Validation loss: 1.8900161507309123

Epoch: 5| Step: 2
Training loss: 0.5954340100288391
Validation loss: 1.890008085517473

Epoch: 5| Step: 3
Training loss: 0.8822924494743347
Validation loss: 1.8703664759153962

Epoch: 5| Step: 4
Training loss: 0.5186392068862915
Validation loss: 1.8604153151153235

Epoch: 5| Step: 5
Training loss: 1.0149600505828857
Validation loss: 1.8593423981820383

Epoch: 5| Step: 6
Training loss: 0.6466054916381836
Validation loss: 1.8727234268701205

Epoch: 5| Step: 7
Training loss: 0.7944611310958862
Validation loss: 1.8628283175089027

Epoch: 5| Step: 8
Training loss: 0.7795075178146362
Validation loss: 1.8805659945293138

Epoch: 5| Step: 9
Training loss: 0.7981316447257996
Validation loss: 1.8654066798507527

Epoch: 5| Step: 10
Training loss: 0.7572458982467651
Validation loss: 1.8445851597734677

Epoch: 217| Step: 0
Training loss: 0.6771795153617859
Validation loss: 1.8512741224740141

Epoch: 5| Step: 1
Training loss: 0.6108995676040649
Validation loss: 1.8568919807352045

Epoch: 5| Step: 2
Training loss: 1.1194452047348022
Validation loss: 1.8625531068412207

Epoch: 5| Step: 3
Training loss: 0.9342721700668335
Validation loss: 1.838782225885699

Epoch: 5| Step: 4
Training loss: 0.9296339750289917
Validation loss: 1.880060104913609

Epoch: 5| Step: 5
Training loss: 0.6881589889526367
Validation loss: 1.8625124628825853

Epoch: 5| Step: 6
Training loss: 0.5726446509361267
Validation loss: 1.8839084666262391

Epoch: 5| Step: 7
Training loss: 0.6025680899620056
Validation loss: 1.8667621433093984

Epoch: 5| Step: 8
Training loss: 1.065891981124878
Validation loss: 1.889158147637562

Epoch: 5| Step: 9
Training loss: 0.8033698797225952
Validation loss: 1.912760203884494

Epoch: 5| Step: 10
Training loss: 1.13886559009552
Validation loss: 1.867325271329572

Epoch: 218| Step: 0
Training loss: 0.8302071690559387
Validation loss: 1.8471162267910537

Epoch: 5| Step: 1
Training loss: 0.5003722310066223
Validation loss: 1.8487878550765335

Epoch: 5| Step: 2
Training loss: 0.796146810054779
Validation loss: 1.8490716885494929

Epoch: 5| Step: 3
Training loss: 0.795113742351532
Validation loss: 1.8088256518046062

Epoch: 5| Step: 4
Training loss: 0.7403019666671753
Validation loss: 1.8141525894083002

Epoch: 5| Step: 5
Training loss: 0.9110586047172546
Validation loss: 1.8020119077415877

Epoch: 5| Step: 6
Training loss: 0.958066463470459
Validation loss: 1.8114894474706342

Epoch: 5| Step: 7
Training loss: 1.1034481525421143
Validation loss: 1.820298344858231

Epoch: 5| Step: 8
Training loss: 0.8840541839599609
Validation loss: 1.8537820769894509

Epoch: 5| Step: 9
Training loss: 0.7891365885734558
Validation loss: 1.9162106296067596

Epoch: 5| Step: 10
Training loss: 0.7512437701225281
Validation loss: 1.927501945085423

Epoch: 219| Step: 0
Training loss: 0.8914510607719421
Validation loss: 2.004882433081186

Epoch: 5| Step: 1
Training loss: 0.9110298156738281
Validation loss: 1.9934382643750919

Epoch: 5| Step: 2
Training loss: 0.4931054711341858
Validation loss: 1.995228264921455

Epoch: 5| Step: 3
Training loss: 1.0347963571548462
Validation loss: 1.989028976809594

Epoch: 5| Step: 4
Training loss: 0.8891779184341431
Validation loss: 1.969817978079601

Epoch: 5| Step: 5
Training loss: 0.829296886920929
Validation loss: 1.9080562258279452

Epoch: 5| Step: 6
Training loss: 0.7580233812332153
Validation loss: 1.8865363892688547

Epoch: 5| Step: 7
Training loss: 0.8259038925170898
Validation loss: 1.878556057971011

Epoch: 5| Step: 8
Training loss: 0.9266851544380188
Validation loss: 1.8517610821672665

Epoch: 5| Step: 9
Training loss: 0.8740800619125366
Validation loss: 1.819073277135049

Epoch: 5| Step: 10
Training loss: 0.5992284417152405
Validation loss: 1.819385693919274

Epoch: 220| Step: 0
Training loss: 0.87346351146698
Validation loss: 1.8160881791063535

Epoch: 5| Step: 1
Training loss: 0.8323432803153992
Validation loss: 1.7969894883453206

Epoch: 5| Step: 2
Training loss: 0.7593003511428833
Validation loss: 1.7900831084097586

Epoch: 5| Step: 3
Training loss: 0.9125892519950867
Validation loss: 1.7845672093411928

Epoch: 5| Step: 4
Training loss: 0.4669123589992523
Validation loss: 1.8438308572256437

Epoch: 5| Step: 5
Training loss: 0.8023500442504883
Validation loss: 1.8518209431761055

Epoch: 5| Step: 6
Training loss: 0.4764840602874756
Validation loss: 1.9041201273600261

Epoch: 5| Step: 7
Training loss: 0.8440636396408081
Validation loss: 1.8846274832243561

Epoch: 5| Step: 8
Training loss: 0.5655202269554138
Validation loss: 1.9401343599442513

Epoch: 5| Step: 9
Training loss: 1.1327871084213257
Validation loss: 1.9209486310200026

Epoch: 5| Step: 10
Training loss: 0.7276113033294678
Validation loss: 1.9256458000470233

Epoch: 221| Step: 0
Training loss: 0.7474147081375122
Validation loss: 1.939617444110173

Epoch: 5| Step: 1
Training loss: 0.9400812387466431
Validation loss: 1.9286461901921097

Epoch: 5| Step: 2
Training loss: 0.8039185404777527
Validation loss: 1.925156516413535

Epoch: 5| Step: 3
Training loss: 0.8070868253707886
Validation loss: 1.906647664244457

Epoch: 5| Step: 4
Training loss: 1.1057300567626953
Validation loss: 1.876317326740552

Epoch: 5| Step: 5
Training loss: 0.39010173082351685
Validation loss: 1.8489706311174618

Epoch: 5| Step: 6
Training loss: 0.5628967881202698
Validation loss: 1.8191497889898156

Epoch: 5| Step: 7
Training loss: 0.9632959365844727
Validation loss: 1.7769917903407928

Epoch: 5| Step: 8
Training loss: 0.792742133140564
Validation loss: 1.764839118526828

Epoch: 5| Step: 9
Training loss: 0.690381646156311
Validation loss: 1.761086117836737

Epoch: 5| Step: 10
Training loss: 0.9814246892929077
Validation loss: 1.7668395990966468

Epoch: 222| Step: 0
Training loss: 1.1092880964279175
Validation loss: 1.7640183010408956

Epoch: 5| Step: 1
Training loss: 0.8475887179374695
Validation loss: 1.7640544958012079

Epoch: 5| Step: 2
Training loss: 0.898929238319397
Validation loss: 1.7999209498846402

Epoch: 5| Step: 3
Training loss: 0.7730127573013306
Validation loss: 1.7786563737418062

Epoch: 5| Step: 4
Training loss: 0.911867618560791
Validation loss: 1.8202348050250803

Epoch: 5| Step: 5
Training loss: 0.5982316732406616
Validation loss: 1.8398307856693064

Epoch: 5| Step: 6
Training loss: 0.6257209777832031
Validation loss: 1.8645354381171606

Epoch: 5| Step: 7
Training loss: 0.6223535537719727
Validation loss: 1.8702121601309827

Epoch: 5| Step: 8
Training loss: 0.6959418654441833
Validation loss: 1.8716851037035707

Epoch: 5| Step: 9
Training loss: 0.5386465191841125
Validation loss: 1.88349022019294

Epoch: 5| Step: 10
Training loss: 0.7769227027893066
Validation loss: 1.8901802993589831

Epoch: 223| Step: 0
Training loss: 0.6355708241462708
Validation loss: 1.8772946019326486

Epoch: 5| Step: 1
Training loss: 0.578349232673645
Validation loss: 1.8809625512810164

Epoch: 5| Step: 2
Training loss: 0.639350950717926
Validation loss: 1.8683842817942302

Epoch: 5| Step: 3
Training loss: 1.3390485048294067
Validation loss: 1.835144539033213

Epoch: 5| Step: 4
Training loss: 0.7918254137039185
Validation loss: 1.8355976176518265

Epoch: 5| Step: 5
Training loss: 0.7458506226539612
Validation loss: 1.8429801361535185

Epoch: 5| Step: 6
Training loss: 0.6066099405288696
Validation loss: 1.8369353855809858

Epoch: 5| Step: 7
Training loss: 0.4611811637878418
Validation loss: 1.8135683562165947

Epoch: 5| Step: 8
Training loss: 0.8118000030517578
Validation loss: 1.805862581858071

Epoch: 5| Step: 9
Training loss: 0.8383474349975586
Validation loss: 1.8264590360785042

Epoch: 5| Step: 10
Training loss: 0.9164380431175232
Validation loss: 1.8145706269048876

Epoch: 224| Step: 0
Training loss: 0.6084209680557251
Validation loss: 1.7985191127305389

Epoch: 5| Step: 1
Training loss: 0.7167885899543762
Validation loss: 1.7734023742778326

Epoch: 5| Step: 2
Training loss: 0.9783760905265808
Validation loss: 1.7947508314604401

Epoch: 5| Step: 3
Training loss: 0.4791582226753235
Validation loss: 1.7920678879625054

Epoch: 5| Step: 4
Training loss: 1.0681664943695068
Validation loss: 1.8426501597127607

Epoch: 5| Step: 5
Training loss: 0.5956642031669617
Validation loss: 1.8414269698563444

Epoch: 5| Step: 6
Training loss: 1.073455572128296
Validation loss: 1.8573998763997068

Epoch: 5| Step: 7
Training loss: 0.5613785982131958
Validation loss: 1.8674935589554489

Epoch: 5| Step: 8
Training loss: 0.7491711974143982
Validation loss: 1.8539596116670998

Epoch: 5| Step: 9
Training loss: 0.4064391255378723
Validation loss: 1.8680249901228054

Epoch: 5| Step: 10
Training loss: 0.8331665992736816
Validation loss: 1.8502214865017963

Epoch: 225| Step: 0
Training loss: 0.4908652901649475
Validation loss: 1.8232456202148108

Epoch: 5| Step: 1
Training loss: 0.6784694194793701
Validation loss: 1.8287563862339142

Epoch: 5| Step: 2
Training loss: 0.8208212852478027
Validation loss: 1.8619161498162053

Epoch: 5| Step: 3
Training loss: 0.7554699182510376
Validation loss: 1.8782738383098314

Epoch: 5| Step: 4
Training loss: 0.641798734664917
Validation loss: 1.8514858445813578

Epoch: 5| Step: 5
Training loss: 0.7566787004470825
Validation loss: 1.8505509130416378

Epoch: 5| Step: 6
Training loss: 0.35123926401138306
Validation loss: 1.842229441929889

Epoch: 5| Step: 7
Training loss: 0.49608153104782104
Validation loss: 1.8328544644899265

Epoch: 5| Step: 8
Training loss: 0.7280822396278381
Validation loss: 1.8436296011811943

Epoch: 5| Step: 9
Training loss: 1.3933571577072144
Validation loss: 1.8513535120153939

Epoch: 5| Step: 10
Training loss: 1.1346020698547363
Validation loss: 1.8960294569692304

Epoch: 226| Step: 0
Training loss: 0.5575464367866516
Validation loss: 1.961993617396201

Epoch: 5| Step: 1
Training loss: 0.5782760381698608
Validation loss: 1.9126782173751502

Epoch: 5| Step: 2
Training loss: 0.5653136968612671
Validation loss: 1.9100311315187843

Epoch: 5| Step: 3
Training loss: 0.9826785326004028
Validation loss: 1.8847137856227096

Epoch: 5| Step: 4
Training loss: 0.5882441997528076
Validation loss: 1.8706042766571045

Epoch: 5| Step: 5
Training loss: 0.7335048913955688
Validation loss: 1.8532289740859822

Epoch: 5| Step: 6
Training loss: 0.9090768694877625
Validation loss: 1.822269622997571

Epoch: 5| Step: 7
Training loss: 0.7760451436042786
Validation loss: 1.806629357799407

Epoch: 5| Step: 8
Training loss: 0.9283655285835266
Validation loss: 1.8235569089971564

Epoch: 5| Step: 9
Training loss: 0.9341434240341187
Validation loss: 1.8081989935649339

Epoch: 5| Step: 10
Training loss: 0.4034036099910736
Validation loss: 1.7779532683792936

Epoch: 227| Step: 0
Training loss: 0.7556635737419128
Validation loss: 1.7898917492999826

Epoch: 5| Step: 1
Training loss: 0.8108984231948853
Validation loss: 1.7750824907774567

Epoch: 5| Step: 2
Training loss: 0.9588497281074524
Validation loss: 1.7910454080950828

Epoch: 5| Step: 3
Training loss: 0.6278015971183777
Validation loss: 1.823462963104248

Epoch: 5| Step: 4
Training loss: 0.6372953653335571
Validation loss: 1.8598434155987156

Epoch: 5| Step: 5
Training loss: 0.6601300239562988
Validation loss: 1.85642929743695

Epoch: 5| Step: 6
Training loss: 0.4147666096687317
Validation loss: 1.8197723345089984

Epoch: 5| Step: 7
Training loss: 0.7984081506729126
Validation loss: 1.8102653000944404

Epoch: 5| Step: 8
Training loss: 0.7587016820907593
Validation loss: 1.805141778402431

Epoch: 5| Step: 9
Training loss: 0.7808867692947388
Validation loss: 1.7472786441926034

Epoch: 5| Step: 10
Training loss: 0.6352130770683289
Validation loss: 1.7814850896917365

Epoch: 228| Step: 0
Training loss: 0.675713837146759
Validation loss: 1.7384099383508005

Epoch: 5| Step: 1
Training loss: 0.4542387127876282
Validation loss: 1.7461749379352858

Epoch: 5| Step: 2
Training loss: 0.748790442943573
Validation loss: 1.7601889846145466

Epoch: 5| Step: 3
Training loss: 0.7670804262161255
Validation loss: 1.778785176174615

Epoch: 5| Step: 4
Training loss: 0.40318384766578674
Validation loss: 1.7317185850553616

Epoch: 5| Step: 5
Training loss: 0.6450815796852112
Validation loss: 1.7538934369241037

Epoch: 5| Step: 6
Training loss: 0.768651008605957
Validation loss: 1.7629083792368572

Epoch: 5| Step: 7
Training loss: 0.8277920484542847
Validation loss: 1.8203063671306898

Epoch: 5| Step: 8
Training loss: 0.7313343286514282
Validation loss: 1.844341819004346

Epoch: 5| Step: 9
Training loss: 1.062257170677185
Validation loss: 1.879923528240573

Epoch: 5| Step: 10
Training loss: 0.8083796501159668
Validation loss: 1.8987289974766393

Epoch: 229| Step: 0
Training loss: 1.0030256509780884
Validation loss: 1.8967333788512855

Epoch: 5| Step: 1
Training loss: 0.6513339281082153
Validation loss: 1.8910688431032243

Epoch: 5| Step: 2
Training loss: 0.8623316884040833
Validation loss: 1.9088770849730379

Epoch: 5| Step: 3
Training loss: 1.0486695766448975
Validation loss: 1.8949515742640342

Epoch: 5| Step: 4
Training loss: 0.7390747666358948
Validation loss: 1.833854785529516

Epoch: 5| Step: 5
Training loss: 0.8722082376480103
Validation loss: 1.8455714077077887

Epoch: 5| Step: 6
Training loss: 0.6124445199966431
Validation loss: 1.8418751634577268

Epoch: 5| Step: 7
Training loss: 0.5213959813117981
Validation loss: 1.8381200426368303

Epoch: 5| Step: 8
Training loss: 0.49812451004981995
Validation loss: 1.837854972449682

Epoch: 5| Step: 9
Training loss: 0.4917074143886566
Validation loss: 1.8384987436315066

Epoch: 5| Step: 10
Training loss: 0.5344266295433044
Validation loss: 1.8143708295719598

Epoch: 230| Step: 0
Training loss: 0.4586433470249176
Validation loss: 1.8751940791324904

Epoch: 5| Step: 1
Training loss: 0.535059928894043
Validation loss: 1.8783167459631478

Epoch: 5| Step: 2
Training loss: 1.3424171209335327
Validation loss: 1.8614088950618621

Epoch: 5| Step: 3
Training loss: 0.5513330698013306
Validation loss: 1.8960830165493874

Epoch: 5| Step: 4
Training loss: 0.6358648538589478
Validation loss: 1.8927607613225137

Epoch: 5| Step: 5
Training loss: 0.46882709860801697
Validation loss: 1.8664125934723885

Epoch: 5| Step: 6
Training loss: 0.6394316554069519
Validation loss: 1.8899228675391084

Epoch: 5| Step: 7
Training loss: 0.8306230306625366
Validation loss: 1.8393775199049263

Epoch: 5| Step: 8
Training loss: 0.6160967350006104
Validation loss: 1.8367684066936534

Epoch: 5| Step: 9
Training loss: 0.7739397287368774
Validation loss: 1.7958165855817898

Epoch: 5| Step: 10
Training loss: 0.7358542680740356
Validation loss: 1.8306135336558025

Epoch: 231| Step: 0
Training loss: 0.5696322917938232
Validation loss: 1.832315739764962

Epoch: 5| Step: 1
Training loss: 0.38651543855667114
Validation loss: 1.799441481149325

Epoch: 5| Step: 2
Training loss: 0.7072687745094299
Validation loss: 1.8220796046718475

Epoch: 5| Step: 3
Training loss: 1.2339236736297607
Validation loss: 1.773114836344155

Epoch: 5| Step: 4
Training loss: 0.6855834722518921
Validation loss: 1.7850727688881658

Epoch: 5| Step: 5
Training loss: 0.7479335069656372
Validation loss: 1.8158720898371872

Epoch: 5| Step: 6
Training loss: 0.7474995255470276
Validation loss: 1.8260240682991602

Epoch: 5| Step: 7
Training loss: 0.5682691335678101
Validation loss: 1.8237796880865609

Epoch: 5| Step: 8
Training loss: 0.46307530999183655
Validation loss: 1.839329800298137

Epoch: 5| Step: 9
Training loss: 0.36968982219696045
Validation loss: 1.849305768166819

Epoch: 5| Step: 10
Training loss: 0.8014001846313477
Validation loss: 1.8623269527189192

Epoch: 232| Step: 0
Training loss: 0.6014081835746765
Validation loss: 1.8355316974783455

Epoch: 5| Step: 1
Training loss: 0.3972828984260559
Validation loss: 1.8276573599025767

Epoch: 5| Step: 2
Training loss: 0.6873584389686584
Validation loss: 1.8233326827326128

Epoch: 5| Step: 3
Training loss: 0.7426844835281372
Validation loss: 1.7980554167942335

Epoch: 5| Step: 4
Training loss: 0.6393716931343079
Validation loss: 1.8045236397815008

Epoch: 5| Step: 5
Training loss: 0.5681146383285522
Validation loss: 1.7644230960517802

Epoch: 5| Step: 6
Training loss: 0.6353446245193481
Validation loss: 1.8012683506934875

Epoch: 5| Step: 7
Training loss: 0.6724594235420227
Validation loss: 1.7916540356092556

Epoch: 5| Step: 8
Training loss: 0.8278900384902954
Validation loss: 1.805731079911673

Epoch: 5| Step: 9
Training loss: 0.6476781964302063
Validation loss: 1.8205945594336397

Epoch: 5| Step: 10
Training loss: 0.5712409019470215
Validation loss: 1.8494628501194779

Epoch: 233| Step: 0
Training loss: 0.8204919695854187
Validation loss: 1.8888543831404818

Epoch: 5| Step: 1
Training loss: 0.8449677228927612
Validation loss: 1.855177890869879

Epoch: 5| Step: 2
Training loss: 0.5880202651023865
Validation loss: 1.8618629658094017

Epoch: 5| Step: 3
Training loss: 0.5452399253845215
Validation loss: 1.8564232882633005

Epoch: 5| Step: 4
Training loss: 0.465850830078125
Validation loss: 1.8188037436495545

Epoch: 5| Step: 5
Training loss: 0.5908451080322266
Validation loss: 1.8008538420482347

Epoch: 5| Step: 6
Training loss: 0.7820463180541992
Validation loss: 1.7915709095616494

Epoch: 5| Step: 7
Training loss: 0.6307776570320129
Validation loss: 1.793892147720501

Epoch: 5| Step: 8
Training loss: 0.46181225776672363
Validation loss: 1.7853587840193061

Epoch: 5| Step: 9
Training loss: 0.5662530660629272
Validation loss: 1.7792364833175496

Epoch: 5| Step: 10
Training loss: 0.6861457824707031
Validation loss: 1.7826698326295423

Epoch: 234| Step: 0
Training loss: 0.5859924554824829
Validation loss: 1.786142074933616

Epoch: 5| Step: 1
Training loss: 0.395500123500824
Validation loss: 1.7907528582439627

Epoch: 5| Step: 2
Training loss: 0.31514960527420044
Validation loss: 1.8371925738550001

Epoch: 5| Step: 3
Training loss: 0.5897267460823059
Validation loss: 1.8546995924365135

Epoch: 5| Step: 4
Training loss: 0.6059558987617493
Validation loss: 1.85149521212424

Epoch: 5| Step: 5
Training loss: 0.5265147089958191
Validation loss: 1.8453158204273512

Epoch: 5| Step: 6
Training loss: 0.8472400903701782
Validation loss: 1.841035953132055

Epoch: 5| Step: 7
Training loss: 0.9574917554855347
Validation loss: 1.8508306664805259

Epoch: 5| Step: 8
Training loss: 0.4408651292324066
Validation loss: 1.795017263581676

Epoch: 5| Step: 9
Training loss: 0.7590304613113403
Validation loss: 1.7818174516001055

Epoch: 5| Step: 10
Training loss: 0.9001734852790833
Validation loss: 1.7846334929107337

Epoch: 235| Step: 0
Training loss: 0.7226663827896118
Validation loss: 1.7816782715500041

Epoch: 5| Step: 1
Training loss: 0.5400751233100891
Validation loss: 1.8121650231781827

Epoch: 5| Step: 2
Training loss: 0.4492703974246979
Validation loss: 1.7975051941410187

Epoch: 5| Step: 3
Training loss: 0.40681982040405273
Validation loss: 1.8038008315588838

Epoch: 5| Step: 4
Training loss: 0.6581770777702332
Validation loss: 1.8152508761293145

Epoch: 5| Step: 5
Training loss: 0.6252098083496094
Validation loss: 1.7999220343046292

Epoch: 5| Step: 6
Training loss: 0.7060443162918091
Validation loss: 1.812929714879682

Epoch: 5| Step: 7
Training loss: 0.7100517153739929
Validation loss: 1.817406988913013

Epoch: 5| Step: 8
Training loss: 0.9686874151229858
Validation loss: 1.8386050552450202

Epoch: 5| Step: 9
Training loss: 0.5368636846542358
Validation loss: 1.8448211557121688

Epoch: 5| Step: 10
Training loss: 0.42990487813949585
Validation loss: 1.8523657014293056

Epoch: 236| Step: 0
Training loss: 0.5336865186691284
Validation loss: 1.8359185521320631

Epoch: 5| Step: 1
Training loss: 0.5749992728233337
Validation loss: 1.8266059801142702

Epoch: 5| Step: 2
Training loss: 0.685565173625946
Validation loss: 1.8345067783068585

Epoch: 5| Step: 3
Training loss: 0.6552960872650146
Validation loss: 1.8401876752094557

Epoch: 5| Step: 4
Training loss: 0.863206684589386
Validation loss: 1.8568154534985941

Epoch: 5| Step: 5
Training loss: 0.7327669262886047
Validation loss: 1.8508562208503805

Epoch: 5| Step: 6
Training loss: 0.6873522996902466
Validation loss: 1.8602610121491134

Epoch: 5| Step: 7
Training loss: 1.0394392013549805
Validation loss: 1.8309944034904562

Epoch: 5| Step: 8
Training loss: 0.41465121507644653
Validation loss: 1.8324576065104494

Epoch: 5| Step: 9
Training loss: 0.42520594596862793
Validation loss: 1.8105004167044034

Epoch: 5| Step: 10
Training loss: 0.14901034533977509
Validation loss: 1.8387190629077215

Epoch: 237| Step: 0
Training loss: 0.7131795287132263
Validation loss: 1.8469912993010653

Epoch: 5| Step: 1
Training loss: 0.6508009433746338
Validation loss: 1.880845812059218

Epoch: 5| Step: 2
Training loss: 0.5698640942573547
Validation loss: 1.8830385567039571

Epoch: 5| Step: 3
Training loss: 0.510668933391571
Validation loss: 1.9020129249941917

Epoch: 5| Step: 4
Training loss: 0.6800694465637207
Validation loss: 1.8898415950036818

Epoch: 5| Step: 5
Training loss: 0.6269012689590454
Validation loss: 1.8728778618638233

Epoch: 5| Step: 6
Training loss: 0.5054733157157898
Validation loss: 1.8222229480743408

Epoch: 5| Step: 7
Training loss: 0.35871440172195435
Validation loss: 1.8365783191496325

Epoch: 5| Step: 8
Training loss: 0.9848572611808777
Validation loss: 1.8406128524452128

Epoch: 5| Step: 9
Training loss: 0.9415084719657898
Validation loss: 1.8432418274623092

Epoch: 5| Step: 10
Training loss: 0.3420071005821228
Validation loss: 1.8660549797037596

Epoch: 238| Step: 0
Training loss: 0.6755400896072388
Validation loss: 1.84848343172381

Epoch: 5| Step: 1
Training loss: 0.9031705856323242
Validation loss: 1.8492578665415447

Epoch: 5| Step: 2
Training loss: 0.6869927048683167
Validation loss: 1.8241750911999774

Epoch: 5| Step: 3
Training loss: 0.5602113604545593
Validation loss: 1.7887923050952215

Epoch: 5| Step: 4
Training loss: 0.6496948003768921
Validation loss: 1.8258863302969164

Epoch: 5| Step: 5
Training loss: 0.6331867575645447
Validation loss: 1.869432092994772

Epoch: 5| Step: 6
Training loss: 0.677348256111145
Validation loss: 1.8543595011516283

Epoch: 5| Step: 7
Training loss: 0.31841081380844116
Validation loss: 1.830816457348485

Epoch: 5| Step: 8
Training loss: 0.5576646327972412
Validation loss: 1.8059788557790941

Epoch: 5| Step: 9
Training loss: 0.6947593688964844
Validation loss: 1.788650667795571

Epoch: 5| Step: 10
Training loss: 0.41498130559921265
Validation loss: 1.8042755896045315

Epoch: 239| Step: 0
Training loss: 0.6180151700973511
Validation loss: 1.8092605529292938

Epoch: 5| Step: 1
Training loss: 0.4367794096469879
Validation loss: 1.8020071906428183

Epoch: 5| Step: 2
Training loss: 0.5968433022499084
Validation loss: 1.8010854387796054

Epoch: 5| Step: 3
Training loss: 0.36700814962387085
Validation loss: 1.8021950080830564

Epoch: 5| Step: 4
Training loss: 0.8154306411743164
Validation loss: 1.8288535789776874

Epoch: 5| Step: 5
Training loss: 0.4764948785305023
Validation loss: 1.8595245448491906

Epoch: 5| Step: 6
Training loss: 0.8566206097602844
Validation loss: 1.837004215486588

Epoch: 5| Step: 7
Training loss: 0.7770881056785583
Validation loss: 1.8643809390324417

Epoch: 5| Step: 8
Training loss: 0.3919302225112915
Validation loss: 1.8256630653976111

Epoch: 5| Step: 9
Training loss: 0.7140873670578003
Validation loss: 1.776552036244382

Epoch: 5| Step: 10
Training loss: 0.7015879154205322
Validation loss: 1.7476688456791702

Epoch: 240| Step: 0
Training loss: 0.6631973385810852
Validation loss: 1.7353373445490354

Epoch: 5| Step: 1
Training loss: 0.47745293378829956
Validation loss: 1.7386216040580504

Epoch: 5| Step: 2
Training loss: 0.6393489837646484
Validation loss: 1.7177086978830316

Epoch: 5| Step: 3
Training loss: 0.4309307634830475
Validation loss: 1.7529761509228778

Epoch: 5| Step: 4
Training loss: 0.5703851580619812
Validation loss: 1.7691256717969013

Epoch: 5| Step: 5
Training loss: 0.2924669682979584
Validation loss: 1.7889257605357836

Epoch: 5| Step: 6
Training loss: 0.6228511929512024
Validation loss: 1.8092696641081123

Epoch: 5| Step: 7
Training loss: 1.04404616355896
Validation loss: 1.8260653429133917

Epoch: 5| Step: 8
Training loss: 0.5769715309143066
Validation loss: 1.8352222519536172

Epoch: 5| Step: 9
Training loss: 0.44932788610458374
Validation loss: 1.8292043209075928

Epoch: 5| Step: 10
Training loss: 0.7095885276794434
Validation loss: 1.830780844534597

Epoch: 241| Step: 0
Training loss: 0.6480066180229187
Validation loss: 1.8202309685368692

Epoch: 5| Step: 1
Training loss: 0.8689466714859009
Validation loss: 1.844499614930922

Epoch: 5| Step: 2
Training loss: 0.5094396471977234
Validation loss: 1.8311343757055139

Epoch: 5| Step: 3
Training loss: 0.41155919432640076
Validation loss: 1.8141963789539952

Epoch: 5| Step: 4
Training loss: 0.682666003704071
Validation loss: 1.7969370042124102

Epoch: 5| Step: 5
Training loss: 0.4439300000667572
Validation loss: 1.777071556737346

Epoch: 5| Step: 6
Training loss: 0.6679428815841675
Validation loss: 1.7798919652097969

Epoch: 5| Step: 7
Training loss: 0.824637234210968
Validation loss: 1.753159729383325

Epoch: 5| Step: 8
Training loss: 0.5485666990280151
Validation loss: 1.787016935245965

Epoch: 5| Step: 9
Training loss: 0.5539892911911011
Validation loss: 1.7752372193080124

Epoch: 5| Step: 10
Training loss: 0.3875819742679596
Validation loss: 1.7533970545696955

Epoch: 242| Step: 0
Training loss: 0.5451213717460632
Validation loss: 1.7867759722535328

Epoch: 5| Step: 1
Training loss: 0.43261879682540894
Validation loss: 1.805200869037259

Epoch: 5| Step: 2
Training loss: 1.10523521900177
Validation loss: 1.795041354753638

Epoch: 5| Step: 3
Training loss: 0.583199679851532
Validation loss: 1.8291685299206806

Epoch: 5| Step: 4
Training loss: 0.3902156949043274
Validation loss: 1.822000539431008

Epoch: 5| Step: 5
Training loss: 0.27323848009109497
Validation loss: 1.8916708525790964

Epoch: 5| Step: 6
Training loss: 0.6790942549705505
Validation loss: 1.865530006347164

Epoch: 5| Step: 7
Training loss: 0.35180407762527466
Validation loss: 1.86110871325257

Epoch: 5| Step: 8
Training loss: 0.7450405359268188
Validation loss: 1.8420300778522287

Epoch: 5| Step: 9
Training loss: 0.6840693354606628
Validation loss: 1.8290572345897715

Epoch: 5| Step: 10
Training loss: 0.4223199784755707
Validation loss: 1.8035410732351325

Epoch: 243| Step: 0
Training loss: 0.5214948058128357
Validation loss: 1.7747562457156438

Epoch: 5| Step: 1
Training loss: 0.6175322532653809
Validation loss: 1.748922973550776

Epoch: 5| Step: 2
Training loss: 0.682113528251648
Validation loss: 1.7590926949695875

Epoch: 5| Step: 3
Training loss: 0.760819137096405
Validation loss: 1.7357271384167414

Epoch: 5| Step: 4
Training loss: 0.33735010027885437
Validation loss: 1.7734472431162351

Epoch: 5| Step: 5
Training loss: 0.5309567451477051
Validation loss: 1.7411846063470329

Epoch: 5| Step: 6
Training loss: 0.5787906050682068
Validation loss: 1.7508487419415546

Epoch: 5| Step: 7
Training loss: 0.43254509568214417
Validation loss: 1.7573812136086084

Epoch: 5| Step: 8
Training loss: 0.34556642174720764
Validation loss: 1.8195229550843597

Epoch: 5| Step: 9
Training loss: 0.9683452844619751
Validation loss: 1.8620844015511133

Epoch: 5| Step: 10
Training loss: 0.4119536876678467
Validation loss: 1.8647346214581562

Epoch: 244| Step: 0
Training loss: 0.2381214201450348
Validation loss: 1.8941397974568028

Epoch: 5| Step: 1
Training loss: 0.6871423125267029
Validation loss: 1.8993571163505636

Epoch: 5| Step: 2
Training loss: 0.5966957807540894
Validation loss: 1.8872659539663663

Epoch: 5| Step: 3
Training loss: 0.8690090179443359
Validation loss: 1.8757093414183585

Epoch: 5| Step: 4
Training loss: 0.5067118406295776
Validation loss: 1.8481941120598906

Epoch: 5| Step: 5
Training loss: 0.5884717702865601
Validation loss: 1.8138452793962212

Epoch: 5| Step: 6
Training loss: 0.4912741184234619
Validation loss: 1.7777406297704226

Epoch: 5| Step: 7
Training loss: 0.6100512146949768
Validation loss: 1.785548456253544

Epoch: 5| Step: 8
Training loss: 0.3510107398033142
Validation loss: 1.7768822498218988

Epoch: 5| Step: 9
Training loss: 0.5887429714202881
Validation loss: 1.8027430888145202

Epoch: 5| Step: 10
Training loss: 0.8321530818939209
Validation loss: 1.779015939722779

Epoch: 245| Step: 0
Training loss: 0.5316849946975708
Validation loss: 1.8063396664075955

Epoch: 5| Step: 1
Training loss: 0.375995934009552
Validation loss: 1.8168521273520686

Epoch: 5| Step: 2
Training loss: 0.5734895467758179
Validation loss: 1.814435710189163

Epoch: 5| Step: 3
Training loss: 0.6787527799606323
Validation loss: 1.8343202772960867

Epoch: 5| Step: 4
Training loss: 0.5232879519462585
Validation loss: 1.8263285083155478

Epoch: 5| Step: 5
Training loss: 0.5967435240745544
Validation loss: 1.803116512554948

Epoch: 5| Step: 6
Training loss: 0.5816384553909302
Validation loss: 1.782923577934183

Epoch: 5| Step: 7
Training loss: 0.8132095336914062
Validation loss: 1.7866713462337371

Epoch: 5| Step: 8
Training loss: 0.6025255918502808
Validation loss: 1.8047317035736576

Epoch: 5| Step: 9
Training loss: 0.31984061002731323
Validation loss: 1.7913289685403146

Epoch: 5| Step: 10
Training loss: 0.552626371383667
Validation loss: 1.7793555618614278

Epoch: 246| Step: 0
Training loss: 0.4953194260597229
Validation loss: 1.8009675574559036

Epoch: 5| Step: 1
Training loss: 0.4946998655796051
Validation loss: 1.7827316868689753

Epoch: 5| Step: 2
Training loss: 0.3108542859554291
Validation loss: 1.8253639539082844

Epoch: 5| Step: 3
Training loss: 0.551444411277771
Validation loss: 1.8050072167509346

Epoch: 5| Step: 4
Training loss: 0.6501312255859375
Validation loss: 1.8036056603154829

Epoch: 5| Step: 5
Training loss: 0.9908266067504883
Validation loss: 1.8264025693298669

Epoch: 5| Step: 6
Training loss: 0.3195130228996277
Validation loss: 1.8690409532157324

Epoch: 5| Step: 7
Training loss: 0.7118942141532898
Validation loss: 1.8309644806769587

Epoch: 5| Step: 8
Training loss: 0.5604724287986755
Validation loss: 1.8436129913535169

Epoch: 5| Step: 9
Training loss: 0.6851605176925659
Validation loss: 1.8398631772687357

Epoch: 5| Step: 10
Training loss: 0.23174692690372467
Validation loss: 1.8193782683341735

Epoch: 247| Step: 0
Training loss: 0.7060788869857788
Validation loss: 1.8060901626463859

Epoch: 5| Step: 1
Training loss: 0.6125012636184692
Validation loss: 1.8244755562915598

Epoch: 5| Step: 2
Training loss: 0.5572776198387146
Validation loss: 1.8063164385416175

Epoch: 5| Step: 3
Training loss: 0.4712754189968109
Validation loss: 1.7953822061579714

Epoch: 5| Step: 4
Training loss: 0.7936617136001587
Validation loss: 1.7949136046953098

Epoch: 5| Step: 5
Training loss: 0.48390063643455505
Validation loss: 1.7799247362280404

Epoch: 5| Step: 6
Training loss: 0.26520273089408875
Validation loss: 1.8069762055591871

Epoch: 5| Step: 7
Training loss: 0.7357646226882935
Validation loss: 1.7855826936742312

Epoch: 5| Step: 8
Training loss: 0.4823325276374817
Validation loss: 1.7536089881773917

Epoch: 5| Step: 9
Training loss: 0.4497547149658203
Validation loss: 1.8074233724224953

Epoch: 5| Step: 10
Training loss: 0.41166383028030396
Validation loss: 1.830310571578241

Epoch: 248| Step: 0
Training loss: 0.46651211380958557
Validation loss: 1.8337372592700425

Epoch: 5| Step: 1
Training loss: 0.6114804148674011
Validation loss: 1.8049259467791485

Epoch: 5| Step: 2
Training loss: 0.6376146078109741
Validation loss: 1.8314259090731222

Epoch: 5| Step: 3
Training loss: 0.43102526664733887
Validation loss: 1.810648714342425

Epoch: 5| Step: 4
Training loss: 0.34612560272216797
Validation loss: 1.8134320910258959

Epoch: 5| Step: 5
Training loss: 0.8376070261001587
Validation loss: 1.8055699422795286

Epoch: 5| Step: 6
Training loss: 0.4186559319496155
Validation loss: 1.7889850331890969

Epoch: 5| Step: 7
Training loss: 0.4088312089443207
Validation loss: 1.7866195427474154

Epoch: 5| Step: 8
Training loss: 0.6283733248710632
Validation loss: 1.7541808159120622

Epoch: 5| Step: 9
Training loss: 0.4601503908634186
Validation loss: 1.7476947743405578

Epoch: 5| Step: 10
Training loss: 0.5877884030342102
Validation loss: 1.7614335013974098

Epoch: 249| Step: 0
Training loss: 0.30851230025291443
Validation loss: 1.7657185203285628

Epoch: 5| Step: 1
Training loss: 0.3132959008216858
Validation loss: 1.7495216285028765

Epoch: 5| Step: 2
Training loss: 0.4787203371524811
Validation loss: 1.769336114647568

Epoch: 5| Step: 3
Training loss: 0.6452757120132446
Validation loss: 1.7954612239714591

Epoch: 5| Step: 4
Training loss: 0.3146595060825348
Validation loss: 1.8353462078238045

Epoch: 5| Step: 5
Training loss: 0.4901277422904968
Validation loss: 1.8313424420613114

Epoch: 5| Step: 6
Training loss: 0.752508819103241
Validation loss: 1.8574715147736252

Epoch: 5| Step: 7
Training loss: 0.5227000713348389
Validation loss: 1.837602476919851

Epoch: 5| Step: 8
Training loss: 0.4471361041069031
Validation loss: 1.841969068332385

Epoch: 5| Step: 9
Training loss: 0.786230206489563
Validation loss: 1.8174925517010432

Epoch: 5| Step: 10
Training loss: 0.5686119794845581
Validation loss: 1.8340047687612555

Epoch: 250| Step: 0
Training loss: 0.3441532552242279
Validation loss: 1.8237254286325106

Epoch: 5| Step: 1
Training loss: 0.598764181137085
Validation loss: 1.7876171655552362

Epoch: 5| Step: 2
Training loss: 0.5075576901435852
Validation loss: 1.8236003800105023

Epoch: 5| Step: 3
Training loss: 0.5594707727432251
Validation loss: 1.8115187306557932

Epoch: 5| Step: 4
Training loss: 0.5332008004188538
Validation loss: 1.7783493393210954

Epoch: 5| Step: 5
Training loss: 0.45577335357666016
Validation loss: 1.7861957447503203

Epoch: 5| Step: 6
Training loss: 0.42229580879211426
Validation loss: 1.7933744897124588

Epoch: 5| Step: 7
Training loss: 0.39291977882385254
Validation loss: 1.789147542368981

Epoch: 5| Step: 8
Training loss: 0.5507560968399048
Validation loss: 1.7991749586597565

Epoch: 5| Step: 9
Training loss: 0.6705951690673828
Validation loss: 1.8052665866831297

Epoch: 5| Step: 10
Training loss: 0.6472015380859375
Validation loss: 1.7930416278941657

Epoch: 251| Step: 0
Training loss: 0.6847327947616577
Validation loss: 1.8008466612908147

Epoch: 5| Step: 1
Training loss: 0.8325340151786804
Validation loss: 1.7933333983985327

Epoch: 5| Step: 2
Training loss: 0.536335825920105
Validation loss: 1.7690493849016005

Epoch: 5| Step: 3
Training loss: 0.4360124170780182
Validation loss: 1.741470758632947

Epoch: 5| Step: 4
Training loss: 0.4708925783634186
Validation loss: 1.7551815189341062

Epoch: 5| Step: 5
Training loss: 0.3042527735233307
Validation loss: 1.7513232359322168

Epoch: 5| Step: 6
Training loss: 0.5165944695472717
Validation loss: 1.753420300381158

Epoch: 5| Step: 7
Training loss: 0.30012691020965576
Validation loss: 1.770968020603221

Epoch: 5| Step: 8
Training loss: 0.5465336441993713
Validation loss: 1.8128356702866093

Epoch: 5| Step: 9
Training loss: 0.525229811668396
Validation loss: 1.8170477510780416

Epoch: 5| Step: 10
Training loss: 0.6050132513046265
Validation loss: 1.8003179821916806

Epoch: 252| Step: 0
Training loss: 0.20562633872032166
Validation loss: 1.793223766870396

Epoch: 5| Step: 1
Training loss: 0.6115272045135498
Validation loss: 1.764509036976804

Epoch: 5| Step: 2
Training loss: 0.544101357460022
Validation loss: 1.7678539124868249

Epoch: 5| Step: 3
Training loss: 0.7067891359329224
Validation loss: 1.748005828549785

Epoch: 5| Step: 4
Training loss: 0.4334813058376312
Validation loss: 1.739888265568723

Epoch: 5| Step: 5
Training loss: 0.5195515751838684
Validation loss: 1.7197414950657917

Epoch: 5| Step: 6
Training loss: 0.4006611704826355
Validation loss: 1.711416857216948

Epoch: 5| Step: 7
Training loss: 0.5278598666191101
Validation loss: 1.7409137243865638

Epoch: 5| Step: 8
Training loss: 0.43316808342933655
Validation loss: 1.726087970118369

Epoch: 5| Step: 9
Training loss: 0.8111421465873718
Validation loss: 1.7389474466282835

Epoch: 5| Step: 10
Training loss: 0.46848273277282715
Validation loss: 1.7454981368075135

Epoch: 253| Step: 0
Training loss: 0.5932285189628601
Validation loss: 1.7730765227348573

Epoch: 5| Step: 1
Training loss: 0.4611232876777649
Validation loss: 1.771521455498152

Epoch: 5| Step: 2
Training loss: 0.23668494820594788
Validation loss: 1.741472380135649

Epoch: 5| Step: 3
Training loss: 0.3253863751888275
Validation loss: 1.7138603348885812

Epoch: 5| Step: 4
Training loss: 0.7077214121818542
Validation loss: 1.736962902930475

Epoch: 5| Step: 5
Training loss: 0.4633476734161377
Validation loss: 1.7552069194855229

Epoch: 5| Step: 6
Training loss: 0.7470750212669373
Validation loss: 1.7488950285860287

Epoch: 5| Step: 7
Training loss: 0.7270711064338684
Validation loss: 1.6967340912870181

Epoch: 5| Step: 8
Training loss: 0.18877723813056946
Validation loss: 1.7140794518173381

Epoch: 5| Step: 9
Training loss: 0.5225328207015991
Validation loss: 1.7036460548318841

Epoch: 5| Step: 10
Training loss: 0.8283123970031738
Validation loss: 1.7554988373992264

Epoch: 254| Step: 0
Training loss: 0.49354392290115356
Validation loss: 1.7826817779130832

Epoch: 5| Step: 1
Training loss: 0.3671680986881256
Validation loss: 1.786998374487764

Epoch: 5| Step: 2
Training loss: 0.4998657703399658
Validation loss: 1.7497095388750876

Epoch: 5| Step: 3
Training loss: 0.35422009229660034
Validation loss: 1.8128202076881164

Epoch: 5| Step: 4
Training loss: 0.8488109707832336
Validation loss: 1.8032022112159318

Epoch: 5| Step: 5
Training loss: 0.42846307158470154
Validation loss: 1.8233975697589178

Epoch: 5| Step: 6
Training loss: 0.39815568923950195
Validation loss: 1.815596685614637

Epoch: 5| Step: 7
Training loss: 0.41008463501930237
Validation loss: 1.8176092845137402

Epoch: 5| Step: 8
Training loss: 0.3805200755596161
Validation loss: 1.793465756600903

Epoch: 5| Step: 9
Training loss: 0.8585476875305176
Validation loss: 1.7672185590190272

Epoch: 5| Step: 10
Training loss: 0.4000280201435089
Validation loss: 1.7457491723440026

Epoch: 255| Step: 0
Training loss: 0.46880921721458435
Validation loss: 1.7290676639926048

Epoch: 5| Step: 1
Training loss: 0.7728690505027771
Validation loss: 1.7223908241077135

Epoch: 5| Step: 2
Training loss: 0.33649593591690063
Validation loss: 1.7500976939355173

Epoch: 5| Step: 3
Training loss: 0.3726397156715393
Validation loss: 1.7494016924212057

Epoch: 5| Step: 4
Training loss: 0.597395122051239
Validation loss: 1.7804767149750904

Epoch: 5| Step: 5
Training loss: 0.36095041036605835
Validation loss: 1.78089722253943

Epoch: 5| Step: 6
Training loss: 0.4369044303894043
Validation loss: 1.8128899810134724

Epoch: 5| Step: 7
Training loss: 0.3329894542694092
Validation loss: 1.809316909441384

Epoch: 5| Step: 8
Training loss: 0.5756564140319824
Validation loss: 1.804263945548765

Epoch: 5| Step: 9
Training loss: 0.6969678997993469
Validation loss: 1.8130806774221442

Epoch: 5| Step: 10
Training loss: 0.45046985149383545
Validation loss: 1.7806464805397937

Epoch: 256| Step: 0
Training loss: 0.5183236002922058
Validation loss: 1.7774119248954199

Epoch: 5| Step: 1
Training loss: 0.3641405701637268
Validation loss: 1.7867763632087297

Epoch: 5| Step: 2
Training loss: 0.6969447731971741
Validation loss: 1.773665105783811

Epoch: 5| Step: 3
Training loss: 0.4107086658477783
Validation loss: 1.7801523695709884

Epoch: 5| Step: 4
Training loss: 0.4456603527069092
Validation loss: 1.797244047605863

Epoch: 5| Step: 5
Training loss: 0.5085225105285645
Validation loss: 1.7684328735515635

Epoch: 5| Step: 6
Training loss: 0.25956666469573975
Validation loss: 1.8216254967515186

Epoch: 5| Step: 7
Training loss: 0.36907467246055603
Validation loss: 1.8093166043681483

Epoch: 5| Step: 8
Training loss: 0.5515704154968262
Validation loss: 1.85545305795567

Epoch: 5| Step: 9
Training loss: 0.4560117721557617
Validation loss: 1.8405183053785754

Epoch: 5| Step: 10
Training loss: 0.9010882377624512
Validation loss: 1.86416446521718

Epoch: 257| Step: 0
Training loss: 0.3507155776023865
Validation loss: 1.877950878553493

Epoch: 5| Step: 1
Training loss: 0.558797299861908
Validation loss: 1.8617431092005905

Epoch: 5| Step: 2
Training loss: 0.6677082777023315
Validation loss: 1.8438181825863418

Epoch: 5| Step: 3
Training loss: 0.47678622603416443
Validation loss: 1.8033993372353174

Epoch: 5| Step: 4
Training loss: 0.3506491184234619
Validation loss: 1.756343921025594

Epoch: 5| Step: 5
Training loss: 0.32664552330970764
Validation loss: 1.7525943940685642

Epoch: 5| Step: 6
Training loss: 0.6731927990913391
Validation loss: 1.7090872077531711

Epoch: 5| Step: 7
Training loss: 0.3226740062236786
Validation loss: 1.757589005654858

Epoch: 5| Step: 8
Training loss: 0.4191977381706238
Validation loss: 1.7655076339680662

Epoch: 5| Step: 9
Training loss: 0.5385078191757202
Validation loss: 1.7411502189533685

Epoch: 5| Step: 10
Training loss: 0.7642688751220703
Validation loss: 1.7774602341395553

Epoch: 258| Step: 0
Training loss: 0.6251181364059448
Validation loss: 1.8128330246094735

Epoch: 5| Step: 1
Training loss: 0.7479039430618286
Validation loss: 1.8444979267735635

Epoch: 5| Step: 2
Training loss: 0.45492902398109436
Validation loss: 1.8020290802883845

Epoch: 5| Step: 3
Training loss: 0.2495560646057129
Validation loss: 1.7821957436941003

Epoch: 5| Step: 4
Training loss: 0.6345478296279907
Validation loss: 1.8002944402797247

Epoch: 5| Step: 5
Training loss: 0.3825559914112091
Validation loss: 1.812781931251608

Epoch: 5| Step: 6
Training loss: 0.5070080757141113
Validation loss: 1.8177203824443202

Epoch: 5| Step: 7
Training loss: 0.4962020516395569
Validation loss: 1.8225457796486475

Epoch: 5| Step: 8
Training loss: 0.2652450501918793
Validation loss: 1.81919857763475

Epoch: 5| Step: 9
Training loss: 0.3785788416862488
Validation loss: 1.7970254228961082

Epoch: 5| Step: 10
Training loss: 0.5928847193717957
Validation loss: 1.778658643845589

Epoch: 259| Step: 0
Training loss: 0.6511988639831543
Validation loss: 1.7704365881540443

Epoch: 5| Step: 1
Training loss: 0.3509138226509094
Validation loss: 1.7649249517789452

Epoch: 5| Step: 2
Training loss: 0.626253068447113
Validation loss: 1.7867675430031233

Epoch: 5| Step: 3
Training loss: 0.7132989168167114
Validation loss: 1.7845928771521455

Epoch: 5| Step: 4
Training loss: 0.31512174010276794
Validation loss: 1.7936233115452591

Epoch: 5| Step: 5
Training loss: 0.4428044259548187
Validation loss: 1.7647240379805207

Epoch: 5| Step: 6
Training loss: 0.5668814778327942
Validation loss: 1.7387971134595974

Epoch: 5| Step: 7
Training loss: 0.496995210647583
Validation loss: 1.7523579571836738

Epoch: 5| Step: 8
Training loss: 0.46867209672927856
Validation loss: 1.7791642373608005

Epoch: 5| Step: 9
Training loss: 0.3323952555656433
Validation loss: 1.7576836155306907

Epoch: 5| Step: 10
Training loss: 0.5457472205162048
Validation loss: 1.780369520187378

Epoch: 260| Step: 0
Training loss: 0.5486559867858887
Validation loss: 1.7683833542690481

Epoch: 5| Step: 1
Training loss: 0.45334577560424805
Validation loss: 1.757041036441762

Epoch: 5| Step: 2
Training loss: 0.33124393224716187
Validation loss: 1.8020137138264154

Epoch: 5| Step: 3
Training loss: 0.3084205985069275
Validation loss: 1.7922212039270708

Epoch: 5| Step: 4
Training loss: 0.7475508451461792
Validation loss: 1.8068161164560625

Epoch: 5| Step: 5
Training loss: 0.33773085474967957
Validation loss: 1.8038223353765344

Epoch: 5| Step: 6
Training loss: 0.4585234522819519
Validation loss: 1.8344483196094472

Epoch: 5| Step: 7
Training loss: 0.3965308368206024
Validation loss: 1.8653224001648605

Epoch: 5| Step: 8
Training loss: 0.7337206602096558
Validation loss: 1.8542547046497304

Epoch: 5| Step: 9
Training loss: 0.40229564905166626
Validation loss: 1.838740696189224

Epoch: 5| Step: 10
Training loss: 0.4309481382369995
Validation loss: 1.8408814207200082

Epoch: 261| Step: 0
Training loss: 0.679306149482727
Validation loss: 1.8893978313733173

Epoch: 5| Step: 1
Training loss: 0.43089812994003296
Validation loss: 1.8844398144752748

Epoch: 5| Step: 2
Training loss: 0.5962311625480652
Validation loss: 1.8664631561566425

Epoch: 5| Step: 3
Training loss: 0.5380831956863403
Validation loss: 1.868089864330907

Epoch: 5| Step: 4
Training loss: 0.3704445958137512
Validation loss: 1.8264161668797976

Epoch: 5| Step: 5
Training loss: 0.37349405884742737
Validation loss: 1.8060781686536727

Epoch: 5| Step: 6
Training loss: 0.3806225657463074
Validation loss: 1.7957839658183437

Epoch: 5| Step: 7
Training loss: 0.3272666931152344
Validation loss: 1.7920553773962042

Epoch: 5| Step: 8
Training loss: 0.5402606129646301
Validation loss: 1.793755736402286

Epoch: 5| Step: 9
Training loss: 0.6380864381790161
Validation loss: 1.7990912622021091

Epoch: 5| Step: 10
Training loss: 0.3251783847808838
Validation loss: 1.7514309216571111

Epoch: 262| Step: 0
Training loss: 0.3817318081855774
Validation loss: 1.7600218942088466

Epoch: 5| Step: 1
Training loss: 0.4523755609989166
Validation loss: 1.7511980636145479

Epoch: 5| Step: 2
Training loss: 0.24888694286346436
Validation loss: 1.7719636706895725

Epoch: 5| Step: 3
Training loss: 0.7763732671737671
Validation loss: 1.7631403964052919

Epoch: 5| Step: 4
Training loss: 0.397929847240448
Validation loss: 1.7715394330281082

Epoch: 5| Step: 5
Training loss: 0.32015055418014526
Validation loss: 1.7912666464364657

Epoch: 5| Step: 6
Training loss: 0.5313290357589722
Validation loss: 1.7520700744403306

Epoch: 5| Step: 7
Training loss: 0.18743953108787537
Validation loss: 1.7840180371397285

Epoch: 5| Step: 8
Training loss: 0.3617653250694275
Validation loss: 1.736005570298882

Epoch: 5| Step: 9
Training loss: 0.8683540225028992
Validation loss: 1.7623299706366755

Epoch: 5| Step: 10
Training loss: 0.28102970123291016
Validation loss: 1.7273073375865977

Epoch: 263| Step: 0
Training loss: 0.4843769073486328
Validation loss: 1.761952530953192

Epoch: 5| Step: 1
Training loss: 0.4941627085208893
Validation loss: 1.7426268798048778

Epoch: 5| Step: 2
Training loss: 0.471839040517807
Validation loss: 1.7144230001716203

Epoch: 5| Step: 3
Training loss: 0.22803878784179688
Validation loss: 1.7435687870107672

Epoch: 5| Step: 4
Training loss: 0.336290180683136
Validation loss: 1.755146118902391

Epoch: 5| Step: 5
Training loss: 0.4607563018798828
Validation loss: 1.7660497298804663

Epoch: 5| Step: 6
Training loss: 0.5523678064346313
Validation loss: 1.7660824278349518

Epoch: 5| Step: 7
Training loss: 0.35278186202049255
Validation loss: 1.7525203151087607

Epoch: 5| Step: 8
Training loss: 0.4498871862888336
Validation loss: 1.766817900442308

Epoch: 5| Step: 9
Training loss: 0.28966593742370605
Validation loss: 1.7807636119986092

Epoch: 5| Step: 10
Training loss: 0.5183581113815308
Validation loss: 1.7937914068980882

Epoch: 264| Step: 0
Training loss: 0.39282092452049255
Validation loss: 1.7606528715420795

Epoch: 5| Step: 1
Training loss: 0.3278253674507141
Validation loss: 1.744705670623369

Epoch: 5| Step: 2
Training loss: 0.2877105474472046
Validation loss: 1.7521478514517508

Epoch: 5| Step: 3
Training loss: 0.30840787291526794
Validation loss: 1.795844772810577

Epoch: 5| Step: 4
Training loss: 0.3237640857696533
Validation loss: 1.7912478036777948

Epoch: 5| Step: 5
Training loss: 0.8821901082992554
Validation loss: 1.7875790621644707

Epoch: 5| Step: 6
Training loss: 0.41832178831100464
Validation loss: 1.8032243892710695

Epoch: 5| Step: 7
Training loss: 0.4194718897342682
Validation loss: 1.7787615676080026

Epoch: 5| Step: 8
Training loss: 0.36553478240966797
Validation loss: 1.7859229298048123

Epoch: 5| Step: 9
Training loss: 0.6555072069168091
Validation loss: 1.8023590336563766

Epoch: 5| Step: 10
Training loss: 0.5822354555130005
Validation loss: 1.816738700353971

Epoch: 265| Step: 0
Training loss: 0.8503691554069519
Validation loss: 1.8420160303833664

Epoch: 5| Step: 1
Training loss: 0.39187026023864746
Validation loss: 1.8624512457078504

Epoch: 5| Step: 2
Training loss: 0.4853935241699219
Validation loss: 1.8001355227603708

Epoch: 5| Step: 3
Training loss: 0.47504520416259766
Validation loss: 1.7909212420063634

Epoch: 5| Step: 4
Training loss: 0.4947012960910797
Validation loss: 1.774745725816296

Epoch: 5| Step: 5
Training loss: 0.42407697439193726
Validation loss: 1.785261042656437

Epoch: 5| Step: 6
Training loss: 0.3630436956882477
Validation loss: 1.7783634303718485

Epoch: 5| Step: 7
Training loss: 0.47408899664878845
Validation loss: 1.81993777777559

Epoch: 5| Step: 8
Training loss: 0.44386014342308044
Validation loss: 1.8195323482636483

Epoch: 5| Step: 9
Training loss: 0.40640750527381897
Validation loss: 1.8193832033423967

Epoch: 5| Step: 10
Training loss: 0.16327054798603058
Validation loss: 1.8093306729870458

Epoch: 266| Step: 0
Training loss: 0.5148035287857056
Validation loss: 1.8358826662904473

Epoch: 5| Step: 1
Training loss: 0.45093756914138794
Validation loss: 1.8306555209621307

Epoch: 5| Step: 2
Training loss: 0.3320801258087158
Validation loss: 1.8196869306666876

Epoch: 5| Step: 3
Training loss: 0.5362149477005005
Validation loss: 1.8355910572954404

Epoch: 5| Step: 4
Training loss: 0.599806547164917
Validation loss: 1.799671575587283

Epoch: 5| Step: 5
Training loss: 0.25324949622154236
Validation loss: 1.762613264463281

Epoch: 5| Step: 6
Training loss: 0.4807407259941101
Validation loss: 1.7447765668233235

Epoch: 5| Step: 7
Training loss: 0.45530349016189575
Validation loss: 1.732794843694215

Epoch: 5| Step: 8
Training loss: 0.48881977796554565
Validation loss: 1.7166390034460253

Epoch: 5| Step: 9
Training loss: 0.35619309544563293
Validation loss: 1.7130996668210594

Epoch: 5| Step: 10
Training loss: 0.29648876190185547
Validation loss: 1.7468255694194506

Epoch: 267| Step: 0
Training loss: 0.48969191312789917
Validation loss: 1.7548648606064499

Epoch: 5| Step: 1
Training loss: 0.5148590803146362
Validation loss: 1.7543050448099773

Epoch: 5| Step: 2
Training loss: 0.37271782755851746
Validation loss: 1.7928126576126262

Epoch: 5| Step: 3
Training loss: 0.34731587767601013
Validation loss: 1.8175301231363767

Epoch: 5| Step: 4
Training loss: 0.45269519090652466
Validation loss: 1.8164820850536387

Epoch: 5| Step: 5
Training loss: 0.3519195020198822
Validation loss: 1.8252290282198178

Epoch: 5| Step: 6
Training loss: 0.22395262122154236
Validation loss: 1.8149159569894113

Epoch: 5| Step: 7
Training loss: 0.25280123949050903
Validation loss: 1.7572239695056793

Epoch: 5| Step: 8
Training loss: 0.9097198247909546
Validation loss: 1.774398216637232

Epoch: 5| Step: 9
Training loss: 0.41896018385887146
Validation loss: 1.752824552597538

Epoch: 5| Step: 10
Training loss: 0.6946873664855957
Validation loss: 1.7487573431384178

Epoch: 268| Step: 0
Training loss: 0.3044296205043793
Validation loss: 1.7413907358723302

Epoch: 5| Step: 1
Training loss: 0.5688128471374512
Validation loss: 1.744110127931

Epoch: 5| Step: 2
Training loss: 0.44305849075317383
Validation loss: 1.7456029333094114

Epoch: 5| Step: 3
Training loss: 0.33952850103378296
Validation loss: 1.718671142414052

Epoch: 5| Step: 4
Training loss: 0.4801786541938782
Validation loss: 1.7553114685960995

Epoch: 5| Step: 5
Training loss: 0.36324945092201233
Validation loss: 1.7781809901678434

Epoch: 5| Step: 6
Training loss: 0.4249158501625061
Validation loss: 1.8052379726081766

Epoch: 5| Step: 7
Training loss: 0.5704092383384705
Validation loss: 1.8375043497290662

Epoch: 5| Step: 8
Training loss: 0.35355234146118164
Validation loss: 1.8355760394885976

Epoch: 5| Step: 9
Training loss: 0.48927822709083557
Validation loss: 1.8391008133529334

Epoch: 5| Step: 10
Training loss: 0.3852609694004059
Validation loss: 1.8473205553588046

Epoch: 269| Step: 0
Training loss: 0.6577308773994446
Validation loss: 1.833685968511848

Epoch: 5| Step: 1
Training loss: 0.394986629486084
Validation loss: 1.8131416984783706

Epoch: 5| Step: 2
Training loss: 0.3382858335971832
Validation loss: 1.8024960282028362

Epoch: 5| Step: 3
Training loss: 0.31299299001693726
Validation loss: 1.7585157630264119

Epoch: 5| Step: 4
Training loss: 0.28406772017478943
Validation loss: 1.7400543907637238

Epoch: 5| Step: 5
Training loss: 0.3732232451438904
Validation loss: 1.7454802605413622

Epoch: 5| Step: 6
Training loss: 0.26828533411026
Validation loss: 1.7777949379336448

Epoch: 5| Step: 7
Training loss: 0.4102662205696106
Validation loss: 1.7878389076520038

Epoch: 5| Step: 8
Training loss: 0.35692867636680603
Validation loss: 1.792187495898175

Epoch: 5| Step: 9
Training loss: 0.5135998129844666
Validation loss: 1.8281468217090895

Epoch: 5| Step: 10
Training loss: 0.711674153804779
Validation loss: 1.7952104255717287

Epoch: 270| Step: 0
Training loss: 0.38241568207740784
Validation loss: 1.8054915589670981

Epoch: 5| Step: 1
Training loss: 0.42783671617507935
Validation loss: 1.816393051096188

Epoch: 5| Step: 2
Training loss: 0.44318056106567383
Validation loss: 1.7867739610774542

Epoch: 5| Step: 3
Training loss: 0.393477201461792
Validation loss: 1.778704700931426

Epoch: 5| Step: 4
Training loss: 0.5546318292617798
Validation loss: 1.8046538983621905

Epoch: 5| Step: 5
Training loss: 0.29016977548599243
Validation loss: 1.7622755432641635

Epoch: 5| Step: 6
Training loss: 0.5083320736885071
Validation loss: 1.7169106045076925

Epoch: 5| Step: 7
Training loss: 0.3649360239505768
Validation loss: 1.7230279009829286

Epoch: 5| Step: 8
Training loss: 0.8029531240463257
Validation loss: 1.6872007077740085

Epoch: 5| Step: 9
Training loss: 0.46267837285995483
Validation loss: 1.71462111062901

Epoch: 5| Step: 10
Training loss: 0.3061524033546448
Validation loss: 1.714611904595488

Epoch: 271| Step: 0
Training loss: 0.41462579369544983
Validation loss: 1.7012535577179284

Epoch: 5| Step: 1
Training loss: 0.3303415775299072
Validation loss: 1.7226272641971547

Epoch: 5| Step: 2
Training loss: 0.37195324897766113
Validation loss: 1.7202059504806355

Epoch: 5| Step: 3
Training loss: 0.4685962200164795
Validation loss: 1.693203273639884

Epoch: 5| Step: 4
Training loss: 0.3858698308467865
Validation loss: 1.7232077583189933

Epoch: 5| Step: 5
Training loss: 0.3197898268699646
Validation loss: 1.768579540714141

Epoch: 5| Step: 6
Training loss: 0.7205933332443237
Validation loss: 1.7709115987182946

Epoch: 5| Step: 7
Training loss: 0.5077447891235352
Validation loss: 1.7811213270310433

Epoch: 5| Step: 8
Training loss: 0.42214712500572205
Validation loss: 1.7542005854268228

Epoch: 5| Step: 9
Training loss: 0.385250985622406
Validation loss: 1.772257569015667

Epoch: 5| Step: 10
Training loss: 0.5534749627113342
Validation loss: 1.7972101255129742

Epoch: 272| Step: 0
Training loss: 0.2553500235080719
Validation loss: 1.7839245411657518

Epoch: 5| Step: 1
Training loss: 0.39009910821914673
Validation loss: 1.8236376880317606

Epoch: 5| Step: 2
Training loss: 0.3063303530216217
Validation loss: 1.7786198072536017

Epoch: 5| Step: 3
Training loss: 0.5666137933731079
Validation loss: 1.806898045283492

Epoch: 5| Step: 4
Training loss: 0.4649117887020111
Validation loss: 1.7330094357972503

Epoch: 5| Step: 5
Training loss: 0.42362603545188904
Validation loss: 1.7359255795837731

Epoch: 5| Step: 6
Training loss: 0.7378562092781067
Validation loss: 1.7268412010644072

Epoch: 5| Step: 7
Training loss: 0.3727944493293762
Validation loss: 1.7196722005003242

Epoch: 5| Step: 8
Training loss: 0.5023711323738098
Validation loss: 1.7401214068935764

Epoch: 5| Step: 9
Training loss: 0.4693456292152405
Validation loss: 1.7512268520170642

Epoch: 5| Step: 10
Training loss: 0.4321664869785309
Validation loss: 1.7599457310092064

Epoch: 273| Step: 0
Training loss: 0.33851557970046997
Validation loss: 1.7860545240422732

Epoch: 5| Step: 1
Training loss: 0.21205702424049377
Validation loss: 1.8054651547503728

Epoch: 5| Step: 2
Training loss: 0.4278244972229004
Validation loss: 1.8160127773079822

Epoch: 5| Step: 3
Training loss: 0.5282870531082153
Validation loss: 1.8073861201604207

Epoch: 5| Step: 4
Training loss: 0.5360674858093262
Validation loss: 1.7712812507024376

Epoch: 5| Step: 5
Training loss: 0.28507304191589355
Validation loss: 1.7399972433684974

Epoch: 5| Step: 6
Training loss: 0.4478258490562439
Validation loss: 1.7500555502471102

Epoch: 5| Step: 7
Training loss: 0.5155261158943176
Validation loss: 1.7340722801864787

Epoch: 5| Step: 8
Training loss: 0.3592680096626282
Validation loss: 1.7509846366861814

Epoch: 5| Step: 9
Training loss: 0.4659663140773773
Validation loss: 1.7654823090440483

Epoch: 5| Step: 10
Training loss: 0.4866224229335785
Validation loss: 1.7479590677445935

Epoch: 274| Step: 0
Training loss: 0.5206440091133118
Validation loss: 1.7605440283334384

Epoch: 5| Step: 1
Training loss: 0.4197811186313629
Validation loss: 1.7386320393572572

Epoch: 5| Step: 2
Training loss: 0.3972230851650238
Validation loss: 1.740482998150651

Epoch: 5| Step: 3
Training loss: 0.39862310886383057
Validation loss: 1.7351499340867484

Epoch: 5| Step: 4
Training loss: 0.4507570266723633
Validation loss: 1.775892828100471

Epoch: 5| Step: 5
Training loss: 0.4711883068084717
Validation loss: 1.817535392699703

Epoch: 5| Step: 6
Training loss: 0.3399466276168823
Validation loss: 1.7837161774276404

Epoch: 5| Step: 7
Training loss: 0.5090550184249878
Validation loss: 1.7940551055374967

Epoch: 5| Step: 8
Training loss: 0.3905474841594696
Validation loss: 1.7535247187460623

Epoch: 5| Step: 9
Training loss: 0.4051898419857025
Validation loss: 1.7673350162403558

Epoch: 5| Step: 10
Training loss: 0.37288346886634827
Validation loss: 1.7596060998978154

Epoch: 275| Step: 0
Training loss: 0.20589807629585266
Validation loss: 1.7681197825298514

Epoch: 5| Step: 1
Training loss: 0.5374754071235657
Validation loss: 1.7486815914030998

Epoch: 5| Step: 2
Training loss: 0.42513900995254517
Validation loss: 1.7778961209840671

Epoch: 5| Step: 3
Training loss: 0.4337557852268219
Validation loss: 1.785590834515069

Epoch: 5| Step: 4
Training loss: 0.4871908724308014
Validation loss: 1.776531272037055

Epoch: 5| Step: 5
Training loss: 0.19576320052146912
Validation loss: 1.7733045444693616

Epoch: 5| Step: 6
Training loss: 0.37814250588417053
Validation loss: 1.758618252251738

Epoch: 5| Step: 7
Training loss: 0.30511167645454407
Validation loss: 1.7667937304383965

Epoch: 5| Step: 8
Training loss: 0.5940923690795898
Validation loss: 1.7621320165613645

Epoch: 5| Step: 9
Training loss: 0.37244781851768494
Validation loss: 1.7826279927325506

Epoch: 5| Step: 10
Training loss: 0.18188275396823883
Validation loss: 1.794590151438149

Epoch: 276| Step: 0
Training loss: 0.3002036511898041
Validation loss: 1.8201097634530836

Epoch: 5| Step: 1
Training loss: 0.4314654767513275
Validation loss: 1.7599412664290397

Epoch: 5| Step: 2
Training loss: 0.4561312794685364
Validation loss: 1.7734053750191965

Epoch: 5| Step: 3
Training loss: 0.534065306186676
Validation loss: 1.750268155528653

Epoch: 5| Step: 4
Training loss: 0.22614531219005585
Validation loss: 1.7241908683571765

Epoch: 5| Step: 5
Training loss: 0.2863607704639435
Validation loss: 1.7264160122922672

Epoch: 5| Step: 6
Training loss: 0.4362722933292389
Validation loss: 1.7456507375163417

Epoch: 5| Step: 7
Training loss: 0.4082389771938324
Validation loss: 1.7654014415638422

Epoch: 5| Step: 8
Training loss: 0.17478501796722412
Validation loss: 1.7226884595809444

Epoch: 5| Step: 9
Training loss: 0.7105745077133179
Validation loss: 1.745874471561883

Epoch: 5| Step: 10
Training loss: 0.2403443604707718
Validation loss: 1.7358407448696833

Epoch: 277| Step: 0
Training loss: 0.3371557593345642
Validation loss: 1.751273642304123

Epoch: 5| Step: 1
Training loss: 0.33244118094444275
Validation loss: 1.7563037449313748

Epoch: 5| Step: 2
Training loss: 0.4528314173221588
Validation loss: 1.7365653899408156

Epoch: 5| Step: 3
Training loss: 0.3808138966560364
Validation loss: 1.6850602511436708

Epoch: 5| Step: 4
Training loss: 0.5533636808395386
Validation loss: 1.7073049147923787

Epoch: 5| Step: 5
Training loss: 0.4455432891845703
Validation loss: 1.700443321658719

Epoch: 5| Step: 6
Training loss: 0.43052738904953003
Validation loss: 1.6836438102106894

Epoch: 5| Step: 7
Training loss: 0.4575785994529724
Validation loss: 1.6894352820611769

Epoch: 5| Step: 8
Training loss: 0.24436087906360626
Validation loss: 1.674069066201487

Epoch: 5| Step: 9
Training loss: 0.3453177511692047
Validation loss: 1.6977481918950235

Epoch: 5| Step: 10
Training loss: 0.33685290813446045
Validation loss: 1.7042658226464384

Epoch: 278| Step: 0
Training loss: 0.5081842541694641
Validation loss: 1.707118675272952

Epoch: 5| Step: 1
Training loss: 0.3144215941429138
Validation loss: 1.709520374574969

Epoch: 5| Step: 2
Training loss: 0.27044230699539185
Validation loss: 1.7487482127322946

Epoch: 5| Step: 3
Training loss: 0.3742646276950836
Validation loss: 1.7227805404252903

Epoch: 5| Step: 4
Training loss: 0.32182687520980835
Validation loss: 1.7175832230557677

Epoch: 5| Step: 5
Training loss: 0.2932880222797394
Validation loss: 1.7173729263326174

Epoch: 5| Step: 6
Training loss: 0.39550867676734924
Validation loss: 1.6810478305303922

Epoch: 5| Step: 7
Training loss: 0.3123193681240082
Validation loss: 1.711459562342654

Epoch: 5| Step: 8
Training loss: 0.4905814528465271
Validation loss: 1.7023060898627005

Epoch: 5| Step: 9
Training loss: 0.37887629866600037
Validation loss: 1.7313767069129533

Epoch: 5| Step: 10
Training loss: 0.32328441739082336
Validation loss: 1.7119468847910564

Epoch: 279| Step: 0
Training loss: 0.33292293548583984
Validation loss: 1.7307041306649484

Epoch: 5| Step: 1
Training loss: 0.28619733452796936
Validation loss: 1.7203775195665256

Epoch: 5| Step: 2
Training loss: 0.4398844838142395
Validation loss: 1.6902348238934752

Epoch: 5| Step: 3
Training loss: 0.4124324321746826
Validation loss: 1.6854591446538125

Epoch: 5| Step: 4
Training loss: 0.2985451817512512
Validation loss: 1.6962078463646673

Epoch: 5| Step: 5
Training loss: 0.38652077317237854
Validation loss: 1.6950606402530466

Epoch: 5| Step: 6
Training loss: 0.48738735914230347
Validation loss: 1.683833242744528

Epoch: 5| Step: 7
Training loss: 0.28443485498428345
Validation loss: 1.7022348693622056

Epoch: 5| Step: 8
Training loss: 0.33158963918685913
Validation loss: 1.7067750525730911

Epoch: 5| Step: 9
Training loss: 0.3782283067703247
Validation loss: 1.7268192691187705

Epoch: 5| Step: 10
Training loss: 0.34019938111305237
Validation loss: 1.6966523560144569

Epoch: 280| Step: 0
Training loss: 0.564186155796051
Validation loss: 1.685220472274288

Epoch: 5| Step: 1
Training loss: 0.29027748107910156
Validation loss: 1.704782885248943

Epoch: 5| Step: 2
Training loss: 0.31007033586502075
Validation loss: 1.689211053232993

Epoch: 5| Step: 3
Training loss: 0.4148545265197754
Validation loss: 1.7235714966251003

Epoch: 5| Step: 4
Training loss: 0.4190904200077057
Validation loss: 1.7117995267273278

Epoch: 5| Step: 5
Training loss: 0.4052940905094147
Validation loss: 1.6845753808175363

Epoch: 5| Step: 6
Training loss: 0.2609933614730835
Validation loss: 1.6853521972574212

Epoch: 5| Step: 7
Training loss: 0.19533386826515198
Validation loss: 1.6952361368363904

Epoch: 5| Step: 8
Training loss: 0.3753224015235901
Validation loss: 1.667041825991805

Epoch: 5| Step: 9
Training loss: 0.37522169947624207
Validation loss: 1.655761468795038

Epoch: 5| Step: 10
Training loss: 0.23339194059371948
Validation loss: 1.6649035740924139

Epoch: 281| Step: 0
Training loss: 0.3612406253814697
Validation loss: 1.6696356701594528

Epoch: 5| Step: 1
Training loss: 0.12676739692687988
Validation loss: 1.6903950078513033

Epoch: 5| Step: 2
Training loss: 0.30749836564064026
Validation loss: 1.727800367339965

Epoch: 5| Step: 3
Training loss: 0.7363473773002625
Validation loss: 1.6879697063917756

Epoch: 5| Step: 4
Training loss: 0.3646389842033386
Validation loss: 1.6964834966967184

Epoch: 5| Step: 5
Training loss: 0.46176284551620483
Validation loss: 1.70766879025326

Epoch: 5| Step: 6
Training loss: 0.2812175154685974
Validation loss: 1.701409093154374

Epoch: 5| Step: 7
Training loss: 0.22955374419689178
Validation loss: 1.7083341434437742

Epoch: 5| Step: 8
Training loss: 0.3707828223705292
Validation loss: 1.7429964016842585

Epoch: 5| Step: 9
Training loss: 0.2827848792076111
Validation loss: 1.7431926573476484

Epoch: 5| Step: 10
Training loss: 0.4367637634277344
Validation loss: 1.7125935413504159

Epoch: 282| Step: 0
Training loss: 0.2817292809486389
Validation loss: 1.7022290165706346

Epoch: 5| Step: 1
Training loss: 0.40440502762794495
Validation loss: 1.724693775177002

Epoch: 5| Step: 2
Training loss: 0.21655932068824768
Validation loss: 1.7468092018558132

Epoch: 5| Step: 3
Training loss: 0.25925812125205994
Validation loss: 1.781278093655904

Epoch: 5| Step: 4
Training loss: 0.19311653077602386
Validation loss: 1.7904378957645868

Epoch: 5| Step: 5
Training loss: 0.49087339639663696
Validation loss: 1.7933823703437723

Epoch: 5| Step: 6
Training loss: 0.2664453387260437
Validation loss: 1.750227669233917

Epoch: 5| Step: 7
Training loss: 0.3157651126384735
Validation loss: 1.7582004275373233

Epoch: 5| Step: 8
Training loss: 0.271260529756546
Validation loss: 1.754562497138977

Epoch: 5| Step: 9
Training loss: 0.5784860849380493
Validation loss: 1.733526454176954

Epoch: 5| Step: 10
Training loss: 0.634029746055603
Validation loss: 1.7306407702866422

Epoch: 283| Step: 0
Training loss: 0.38711273670196533
Validation loss: 1.7181507233650453

Epoch: 5| Step: 1
Training loss: 0.3393893837928772
Validation loss: 1.7103689421889603

Epoch: 5| Step: 2
Training loss: 0.3698694109916687
Validation loss: 1.6823147958324802

Epoch: 5| Step: 3
Training loss: 0.4651876389980316
Validation loss: 1.701372584988994

Epoch: 5| Step: 4
Training loss: 0.5346028208732605
Validation loss: 1.7375618514194284

Epoch: 5| Step: 5
Training loss: 0.3212295472621918
Validation loss: 1.7382026410871936

Epoch: 5| Step: 6
Training loss: 0.4502716660499573
Validation loss: 1.7355003651752268

Epoch: 5| Step: 7
Training loss: 0.4645978510379791
Validation loss: 1.7555181403313913

Epoch: 5| Step: 8
Training loss: 0.2558106482028961
Validation loss: 1.7626453779077018

Epoch: 5| Step: 9
Training loss: 0.27833351492881775
Validation loss: 1.758037656866094

Epoch: 5| Step: 10
Training loss: 0.30551162362098694
Validation loss: 1.7445804457510672

Epoch: 284| Step: 0
Training loss: 0.2812023162841797
Validation loss: 1.7196194189851002

Epoch: 5| Step: 1
Training loss: 0.3515755236148834
Validation loss: 1.7261802573357858

Epoch: 5| Step: 2
Training loss: 0.2788331210613251
Validation loss: 1.7047131740918724

Epoch: 5| Step: 3
Training loss: 0.31350070238113403
Validation loss: 1.6925868193308513

Epoch: 5| Step: 4
Training loss: 0.38085055351257324
Validation loss: 1.704596648934067

Epoch: 5| Step: 5
Training loss: 0.29664140939712524
Validation loss: 1.7182767288659209

Epoch: 5| Step: 6
Training loss: 0.533196210861206
Validation loss: 1.6894012651135843

Epoch: 5| Step: 7
Training loss: 0.3549540042877197
Validation loss: 1.6887605844005462

Epoch: 5| Step: 8
Training loss: 0.38624343276023865
Validation loss: 1.6990571150215723

Epoch: 5| Step: 9
Training loss: 0.49801284074783325
Validation loss: 1.683033989321801

Epoch: 5| Step: 10
Training loss: 0.2725008726119995
Validation loss: 1.7008108374893025

Epoch: 285| Step: 0
Training loss: 0.21712490916252136
Validation loss: 1.6914795380766674

Epoch: 5| Step: 1
Training loss: 0.27596142888069153
Validation loss: 1.7125651195485105

Epoch: 5| Step: 2
Training loss: 0.19636721909046173
Validation loss: 1.7380312373561244

Epoch: 5| Step: 3
Training loss: 0.31688356399536133
Validation loss: 1.7367208606453353

Epoch: 5| Step: 4
Training loss: 0.5738390684127808
Validation loss: 1.7305417163397676

Epoch: 5| Step: 5
Training loss: 0.566810667514801
Validation loss: 1.7726575559185398

Epoch: 5| Step: 6
Training loss: 0.48005008697509766
Validation loss: 1.7642625621570054

Epoch: 5| Step: 7
Training loss: 0.4231197237968445
Validation loss: 1.7405039123309556

Epoch: 5| Step: 8
Training loss: 0.24262914061546326
Validation loss: 1.687618701688705

Epoch: 5| Step: 9
Training loss: 0.4281249940395355
Validation loss: 1.6895709281326623

Epoch: 5| Step: 10
Training loss: 0.4454282820224762
Validation loss: 1.710761381733802

Epoch: 286| Step: 0
Training loss: 0.20592983067035675
Validation loss: 1.7359877632510277

Epoch: 5| Step: 1
Training loss: 0.26892736554145813
Validation loss: 1.7195281713239607

Epoch: 5| Step: 2
Training loss: 0.4446747303009033
Validation loss: 1.7223964429670764

Epoch: 5| Step: 3
Training loss: 0.3000815212726593
Validation loss: 1.7169782602658836

Epoch: 5| Step: 4
Training loss: 0.32902437448501587
Validation loss: 1.7118759129637031

Epoch: 5| Step: 5
Training loss: 0.5246695280075073
Validation loss: 1.7478516165928175

Epoch: 5| Step: 6
Training loss: 0.18935635685920715
Validation loss: 1.7247623012911888

Epoch: 5| Step: 7
Training loss: 0.5576598048210144
Validation loss: 1.755458244713404

Epoch: 5| Step: 8
Training loss: 0.357907772064209
Validation loss: 1.7484886261724657

Epoch: 5| Step: 9
Training loss: 0.36392858624458313
Validation loss: 1.7363721016914613

Epoch: 5| Step: 10
Training loss: 0.40229371190071106
Validation loss: 1.7126418390581686

Epoch: 287| Step: 0
Training loss: 0.24621108174324036
Validation loss: 1.7237114547401347

Epoch: 5| Step: 1
Training loss: 0.3399409055709839
Validation loss: 1.7453791044091667

Epoch: 5| Step: 2
Training loss: 0.4887416958808899
Validation loss: 1.743911338108842

Epoch: 5| Step: 3
Training loss: 0.26940101385116577
Validation loss: 1.7618923821756918

Epoch: 5| Step: 4
Training loss: 0.24508371949195862
Validation loss: 1.7846503949934436

Epoch: 5| Step: 5
Training loss: 0.16581812500953674
Validation loss: 1.756526239456669

Epoch: 5| Step: 6
Training loss: 0.5114573836326599
Validation loss: 1.799721025971956

Epoch: 5| Step: 7
Training loss: 0.41195935010910034
Validation loss: 1.7455775942853702

Epoch: 5| Step: 8
Training loss: 0.283063143491745
Validation loss: 1.7300618002491612

Epoch: 5| Step: 9
Training loss: 0.3088887631893158
Validation loss: 1.7180422890570857

Epoch: 5| Step: 10
Training loss: 0.3345302939414978
Validation loss: 1.6997665064309233

Epoch: 288| Step: 0
Training loss: 0.28730764985084534
Validation loss: 1.7144642132584766

Epoch: 5| Step: 1
Training loss: 0.2519495487213135
Validation loss: 1.7087619061111121

Epoch: 5| Step: 2
Training loss: 0.4213791787624359
Validation loss: 1.7047147058671521

Epoch: 5| Step: 3
Training loss: 0.35598793625831604
Validation loss: 1.7150549145155056

Epoch: 5| Step: 4
Training loss: 0.33635392785072327
Validation loss: 1.7053103664869904

Epoch: 5| Step: 5
Training loss: 0.4243270754814148
Validation loss: 1.7166146629600114

Epoch: 5| Step: 6
Training loss: 0.3531707227230072
Validation loss: 1.7260642256788028

Epoch: 5| Step: 7
Training loss: 0.4765626788139343
Validation loss: 1.7345905291136874

Epoch: 5| Step: 8
Training loss: 0.2166222780942917
Validation loss: 1.7497184327853623

Epoch: 5| Step: 9
Training loss: 0.22327978909015656
Validation loss: 1.714860661055452

Epoch: 5| Step: 10
Training loss: 0.26449108123779297
Validation loss: 1.7265200230383104

Epoch: 289| Step: 0
Training loss: 0.22397680580615997
Validation loss: 1.7084695023875083

Epoch: 5| Step: 1
Training loss: 0.23877468705177307
Validation loss: 1.7084121845101798

Epoch: 5| Step: 2
Training loss: 0.3371414840221405
Validation loss: 1.7122982753220426

Epoch: 5| Step: 3
Training loss: 0.42658883333206177
Validation loss: 1.7001366141021892

Epoch: 5| Step: 4
Training loss: 0.3221057951450348
Validation loss: 1.6949317404018935

Epoch: 5| Step: 5
Training loss: 0.33515480160713196
Validation loss: 1.7130460880135978

Epoch: 5| Step: 6
Training loss: 0.30733901262283325
Validation loss: 1.73007893946863

Epoch: 5| Step: 7
Training loss: 0.2861235737800598
Validation loss: 1.7313383920218355

Epoch: 5| Step: 8
Training loss: 0.4684796929359436
Validation loss: 1.7650012098332888

Epoch: 5| Step: 9
Training loss: 0.48513516783714294
Validation loss: 1.7294800627616145

Epoch: 5| Step: 10
Training loss: 0.4161790609359741
Validation loss: 1.7561320335634294

Epoch: 290| Step: 0
Training loss: 0.3064118027687073
Validation loss: 1.752979160636984

Epoch: 5| Step: 1
Training loss: 0.3392418324947357
Validation loss: 1.7683483785198582

Epoch: 5| Step: 2
Training loss: 0.24031785130500793
Validation loss: 1.7746367800620295

Epoch: 5| Step: 3
Training loss: 0.31745201349258423
Validation loss: 1.7835920831208587

Epoch: 5| Step: 4
Training loss: 0.4241170883178711
Validation loss: 1.7486006777773622

Epoch: 5| Step: 5
Training loss: 0.5664195418357849
Validation loss: 1.7468481256115822

Epoch: 5| Step: 6
Training loss: 0.24418020248413086
Validation loss: 1.7218585898799281

Epoch: 5| Step: 7
Training loss: 0.29544797539711
Validation loss: 1.7349438026387205

Epoch: 5| Step: 8
Training loss: 0.1866830438375473
Validation loss: 1.7141179448814803

Epoch: 5| Step: 9
Training loss: 0.4241696298122406
Validation loss: 1.7089455448171145

Epoch: 5| Step: 10
Training loss: 0.2521456480026245
Validation loss: 1.7224199143789147

Epoch: 291| Step: 0
Training loss: 0.31070148944854736
Validation loss: 1.7149715000583279

Epoch: 5| Step: 1
Training loss: 0.6205934882164001
Validation loss: 1.7241655472786195

Epoch: 5| Step: 2
Training loss: 0.4922713339328766
Validation loss: 1.7014153683057396

Epoch: 5| Step: 3
Training loss: 0.36779123544692993
Validation loss: 1.6968046606227916

Epoch: 5| Step: 4
Training loss: 0.21859288215637207
Validation loss: 1.6894821043937438

Epoch: 5| Step: 5
Training loss: 0.3510788679122925
Validation loss: 1.6763738739875056

Epoch: 5| Step: 6
Training loss: 0.45405131578445435
Validation loss: 1.6856536942143594

Epoch: 5| Step: 7
Training loss: 0.20888185501098633
Validation loss: 1.687229715367799

Epoch: 5| Step: 8
Training loss: 0.25053590536117554
Validation loss: 1.7076243008336713

Epoch: 5| Step: 9
Training loss: 0.3643713593482971
Validation loss: 1.6834494452322684

Epoch: 5| Step: 10
Training loss: 0.26422640681266785
Validation loss: 1.6932287575096212

Epoch: 292| Step: 0
Training loss: 0.6213536262512207
Validation loss: 1.724358222817862

Epoch: 5| Step: 1
Training loss: 0.3236212134361267
Validation loss: 1.7068421763758506

Epoch: 5| Step: 2
Training loss: 0.3249770700931549
Validation loss: 1.707640447924214

Epoch: 5| Step: 3
Training loss: 0.3913772404193878
Validation loss: 1.70431310771614

Epoch: 5| Step: 4
Training loss: 0.33060699701309204
Validation loss: 1.7268199920654297

Epoch: 5| Step: 5
Training loss: 0.37558993697166443
Validation loss: 1.7189630846823416

Epoch: 5| Step: 6
Training loss: 0.26398372650146484
Validation loss: 1.7330535457980247

Epoch: 5| Step: 7
Training loss: 0.30773237347602844
Validation loss: 1.7186025951498298

Epoch: 5| Step: 8
Training loss: 0.1691354215145111
Validation loss: 1.7272437951898063

Epoch: 5| Step: 9
Training loss: 0.28872793912887573
Validation loss: 1.734782124078402

Epoch: 5| Step: 10
Training loss: 0.2286776900291443
Validation loss: 1.7739318186236965

Epoch: 293| Step: 0
Training loss: 0.5735069513320923
Validation loss: 1.7439016372926774

Epoch: 5| Step: 1
Training loss: 0.17629985511302948
Validation loss: 1.7312773171291556

Epoch: 5| Step: 2
Training loss: 0.1925022453069687
Validation loss: 1.7073498015762658

Epoch: 5| Step: 3
Training loss: 0.31213435530662537
Validation loss: 1.7021559233306556

Epoch: 5| Step: 4
Training loss: 0.3295780420303345
Validation loss: 1.697946133152131

Epoch: 5| Step: 5
Training loss: 0.26110193133354187
Validation loss: 1.7219098934563257

Epoch: 5| Step: 6
Training loss: 0.2402169406414032
Validation loss: 1.69581933816274

Epoch: 5| Step: 7
Training loss: 0.38442641496658325
Validation loss: 1.7066277957731677

Epoch: 5| Step: 8
Training loss: 0.44792240858078003
Validation loss: 1.714814966724765

Epoch: 5| Step: 9
Training loss: 0.18257297575473785
Validation loss: 1.709246499564058

Epoch: 5| Step: 10
Training loss: 0.32510316371917725
Validation loss: 1.7777673480331257

Epoch: 294| Step: 0
Training loss: 0.3176998198032379
Validation loss: 1.7527829600918678

Epoch: 5| Step: 1
Training loss: 0.16323547065258026
Validation loss: 1.7444869818225983

Epoch: 5| Step: 2
Training loss: 0.3878742456436157
Validation loss: 1.7165596741502003

Epoch: 5| Step: 3
Training loss: 0.2398214340209961
Validation loss: 1.674540706860122

Epoch: 5| Step: 4
Training loss: 0.3464246690273285
Validation loss: 1.6616925501054334

Epoch: 5| Step: 5
Training loss: 0.25241583585739136
Validation loss: 1.6549176862162929

Epoch: 5| Step: 6
Training loss: 0.2572701573371887
Validation loss: 1.6866638173339188

Epoch: 5| Step: 7
Training loss: 0.21371956169605255
Validation loss: 1.663109000011157

Epoch: 5| Step: 8
Training loss: 0.5325655937194824
Validation loss: 1.687141356929656

Epoch: 5| Step: 9
Training loss: 0.24997839331626892
Validation loss: 1.6989946980630197

Epoch: 5| Step: 10
Training loss: 0.29438716173171997
Validation loss: 1.7289031500457435

Epoch: 295| Step: 0
Training loss: 0.23622512817382812
Validation loss: 1.7375880620812858

Epoch: 5| Step: 1
Training loss: 0.5147241950035095
Validation loss: 1.759218180051414

Epoch: 5| Step: 2
Training loss: 0.321280300617218
Validation loss: 1.7587307204482376

Epoch: 5| Step: 3
Training loss: 0.2741992771625519
Validation loss: 1.757649710101466

Epoch: 5| Step: 4
Training loss: 0.24277615547180176
Validation loss: 1.7117647201784196

Epoch: 5| Step: 5
Training loss: 0.30658960342407227
Validation loss: 1.7661784451494935

Epoch: 5| Step: 6
Training loss: 0.27719730138778687
Validation loss: 1.7236946193120812

Epoch: 5| Step: 7
Training loss: 0.39078935980796814
Validation loss: 1.7180153298121628

Epoch: 5| Step: 8
Training loss: 0.27401983737945557
Validation loss: 1.7276309767077047

Epoch: 5| Step: 9
Training loss: 0.13986365497112274
Validation loss: 1.6831653066860732

Epoch: 5| Step: 10
Training loss: 0.2782433032989502
Validation loss: 1.7110860040110927

Epoch: 296| Step: 0
Training loss: 0.38235217332839966
Validation loss: 1.7258470840351556

Epoch: 5| Step: 1
Training loss: 0.3232153058052063
Validation loss: 1.7054845504863287

Epoch: 5| Step: 2
Training loss: 0.29132315516471863
Validation loss: 1.7338200089752034

Epoch: 5| Step: 3
Training loss: 0.32056084275245667
Validation loss: 1.732843131147405

Epoch: 5| Step: 4
Training loss: 0.28848013281822205
Validation loss: 1.750487986431327

Epoch: 5| Step: 5
Training loss: 0.34285497665405273
Validation loss: 1.7142505261205858

Epoch: 5| Step: 6
Training loss: 0.5710016489028931
Validation loss: 1.7080482872583533

Epoch: 5| Step: 7
Training loss: 0.20990951359272003
Validation loss: 1.7043936098775556

Epoch: 5| Step: 8
Training loss: 0.3959132730960846
Validation loss: 1.712467989613933

Epoch: 5| Step: 9
Training loss: 0.23708248138427734
Validation loss: 1.7393414230756863

Epoch: 5| Step: 10
Training loss: 0.2664030194282532
Validation loss: 1.7198643184477282

Epoch: 297| Step: 0
Training loss: 0.2844388484954834
Validation loss: 1.7263562089653426

Epoch: 5| Step: 1
Training loss: 0.17352044582366943
Validation loss: 1.7171424229939778

Epoch: 5| Step: 2
Training loss: 0.31322479248046875
Validation loss: 1.714439220325921

Epoch: 5| Step: 3
Training loss: 0.3442089855670929
Validation loss: 1.6838362409222511

Epoch: 5| Step: 4
Training loss: 0.42097821831703186
Validation loss: 1.705892160374631

Epoch: 5| Step: 5
Training loss: 0.1749650537967682
Validation loss: 1.6997400201776975

Epoch: 5| Step: 6
Training loss: 0.47848382592201233
Validation loss: 1.6986894312725271

Epoch: 5| Step: 7
Training loss: 0.3164002299308777
Validation loss: 1.6907844812639299

Epoch: 5| Step: 8
Training loss: 0.21730628609657288
Validation loss: 1.669324044258364

Epoch: 5| Step: 9
Training loss: 0.25656658411026
Validation loss: 1.680182941498295

Epoch: 5| Step: 10
Training loss: 0.4194819927215576
Validation loss: 1.6464033652377386

Epoch: 298| Step: 0
Training loss: 0.3981724977493286
Validation loss: 1.676031825362995

Epoch: 5| Step: 1
Training loss: 0.3784100413322449
Validation loss: 1.667453755614578

Epoch: 5| Step: 2
Training loss: 0.39833882451057434
Validation loss: 1.6247633246965305

Epoch: 5| Step: 3
Training loss: 0.25476476550102234
Validation loss: 1.6606935711317166

Epoch: 5| Step: 4
Training loss: 0.3186764121055603
Validation loss: 1.6775236693761681

Epoch: 5| Step: 5
Training loss: 0.44344934821128845
Validation loss: 1.709132440628544

Epoch: 5| Step: 6
Training loss: 0.290182888507843
Validation loss: 1.7186298921544065

Epoch: 5| Step: 7
Training loss: 0.2632335126399994
Validation loss: 1.7629053669591104

Epoch: 5| Step: 8
Training loss: 0.28941813111305237
Validation loss: 1.7078570512033278

Epoch: 5| Step: 9
Training loss: 0.24506771564483643
Validation loss: 1.713221444878527

Epoch: 5| Step: 10
Training loss: 0.34910205006599426
Validation loss: 1.7107349288079046

Epoch: 299| Step: 0
Training loss: 0.4669150412082672
Validation loss: 1.698927669114964

Epoch: 5| Step: 1
Training loss: 0.19734495878219604
Validation loss: 1.6838282231361634

Epoch: 5| Step: 2
Training loss: 0.34459543228149414
Validation loss: 1.6696542155358098

Epoch: 5| Step: 3
Training loss: 0.3377871513366699
Validation loss: 1.7101478897115236

Epoch: 5| Step: 4
Training loss: 0.27468401193618774
Validation loss: 1.686582185888803

Epoch: 5| Step: 5
Training loss: 0.2818804383277893
Validation loss: 1.717191812812641

Epoch: 5| Step: 6
Training loss: 0.25634410977363586
Validation loss: 1.7337857920636413

Epoch: 5| Step: 7
Training loss: 0.3691975474357605
Validation loss: 1.7542981729712537

Epoch: 5| Step: 8
Training loss: 0.4316364824771881
Validation loss: 1.7883764031112834

Epoch: 5| Step: 9
Training loss: 0.24138769507408142
Validation loss: 1.782894246039852

Epoch: 5| Step: 10
Training loss: 0.19690170884132385
Validation loss: 1.7605556941801501

Epoch: 300| Step: 0
Training loss: 0.3332653343677521
Validation loss: 1.7731851967432166

Epoch: 5| Step: 1
Training loss: 0.28462523221969604
Validation loss: 1.7374423550021263

Epoch: 5| Step: 2
Training loss: 0.23002400994300842
Validation loss: 1.7181428042791222

Epoch: 5| Step: 3
Training loss: 0.3462553918361664
Validation loss: 1.692556353025539

Epoch: 5| Step: 4
Training loss: 0.28912267088890076
Validation loss: 1.6926471520495672

Epoch: 5| Step: 5
Training loss: 0.32252365350723267
Validation loss: 1.6975141250959007

Epoch: 5| Step: 6
Training loss: 0.27243247628211975
Validation loss: 1.6561386354507939

Epoch: 5| Step: 7
Training loss: 0.49934226274490356
Validation loss: 1.6944411121388918

Epoch: 5| Step: 8
Training loss: 0.37631356716156006
Validation loss: 1.6802922083485512

Epoch: 5| Step: 9
Training loss: 0.23074308037757874
Validation loss: 1.7109025242508098

Epoch: 5| Step: 10
Training loss: 0.13316500186920166
Validation loss: 1.6880427509225824

Epoch: 301| Step: 0
Training loss: 0.5247572660446167
Validation loss: 1.7010396616433257

Epoch: 5| Step: 1
Training loss: 0.16930870711803436
Validation loss: 1.7187131835568337

Epoch: 5| Step: 2
Training loss: 0.30787500739097595
Validation loss: 1.7216412892905615

Epoch: 5| Step: 3
Training loss: 0.2873626947402954
Validation loss: 1.7132656394794423

Epoch: 5| Step: 4
Training loss: 0.177383154630661
Validation loss: 1.7155130922153432

Epoch: 5| Step: 5
Training loss: 0.26760727167129517
Validation loss: 1.6732473450322305

Epoch: 5| Step: 6
Training loss: 0.4026518762111664
Validation loss: 1.6622559255169285

Epoch: 5| Step: 7
Training loss: 0.3111002743244171
Validation loss: 1.680202999422627

Epoch: 5| Step: 8
Training loss: 0.24403581023216248
Validation loss: 1.6415094162828179

Epoch: 5| Step: 9
Training loss: 0.20828862488269806
Validation loss: 1.6062630530326598

Epoch: 5| Step: 10
Training loss: 0.34532713890075684
Validation loss: 1.6414692760795675

Epoch: 302| Step: 0
Training loss: 0.48363572359085083
Validation loss: 1.654432048079788

Epoch: 5| Step: 1
Training loss: 0.2508833408355713
Validation loss: 1.6541315778609245

Epoch: 5| Step: 2
Training loss: 0.3120814859867096
Validation loss: 1.6825945595259308

Epoch: 5| Step: 3
Training loss: 0.25084900856018066
Validation loss: 1.6665125098279727

Epoch: 5| Step: 4
Training loss: 0.2516063451766968
Validation loss: 1.6971336449346235

Epoch: 5| Step: 5
Training loss: 0.14352650940418243
Validation loss: 1.7390191657568819

Epoch: 5| Step: 6
Training loss: 0.2673801779747009
Validation loss: 1.707103701048

Epoch: 5| Step: 7
Training loss: 0.2341800183057785
Validation loss: 1.6656614067733928

Epoch: 5| Step: 8
Training loss: 0.4571371078491211
Validation loss: 1.6624767511121687

Epoch: 5| Step: 9
Training loss: 0.17508885264396667
Validation loss: 1.6768637446946995

Epoch: 5| Step: 10
Training loss: 0.3737880289554596
Validation loss: 1.67006633486799

Epoch: 303| Step: 0
Training loss: 0.20461812615394592
Validation loss: 1.666203566776809

Epoch: 5| Step: 1
Training loss: 0.39122453331947327
Validation loss: 1.6836414055157733

Epoch: 5| Step: 2
Training loss: 0.4788169860839844
Validation loss: 1.6562403889112576

Epoch: 5| Step: 3
Training loss: 0.27521055936813354
Validation loss: 1.692397206060348

Epoch: 5| Step: 4
Training loss: 0.30506283044815063
Validation loss: 1.7032245128385481

Epoch: 5| Step: 5
Training loss: 0.21134045720100403
Validation loss: 1.7205981041795464

Epoch: 5| Step: 6
Training loss: 0.5026198625564575
Validation loss: 1.6903257728904806

Epoch: 5| Step: 7
Training loss: 0.22189751267433167
Validation loss: 1.671300261251388

Epoch: 5| Step: 8
Training loss: 0.2588021159172058
Validation loss: 1.7008844191028225

Epoch: 5| Step: 9
Training loss: 0.26180222630500793
Validation loss: 1.686806127589236

Epoch: 5| Step: 10
Training loss: 0.14240501821041107
Validation loss: 1.7354993384371522

Epoch: 304| Step: 0
Training loss: 0.2574160695075989
Validation loss: 1.6956631240024362

Epoch: 5| Step: 1
Training loss: 0.28701797127723694
Validation loss: 1.7014535665512085

Epoch: 5| Step: 2
Training loss: 0.3019499182701111
Validation loss: 1.6928112506866455

Epoch: 5| Step: 3
Training loss: 0.36924269795417786
Validation loss: 1.7110328379497732

Epoch: 5| Step: 4
Training loss: 0.2823270857334137
Validation loss: 1.6960890395666963

Epoch: 5| Step: 5
Training loss: 0.19581915438175201
Validation loss: 1.6757869874277422

Epoch: 5| Step: 6
Training loss: 0.19491730630397797
Validation loss: 1.703359575681789

Epoch: 5| Step: 7
Training loss: 0.24112839996814728
Validation loss: 1.6880423548401042

Epoch: 5| Step: 8
Training loss: 0.2778279781341553
Validation loss: 1.7335682415193128

Epoch: 5| Step: 9
Training loss: 0.27050909399986267
Validation loss: 1.7211825270806589

Epoch: 5| Step: 10
Training loss: 0.37268784642219543
Validation loss: 1.7102008673452562

Epoch: 305| Step: 0
Training loss: 0.17431087791919708
Validation loss: 1.7281497563085249

Epoch: 5| Step: 1
Training loss: 0.40773946046829224
Validation loss: 1.7262171673518356

Epoch: 5| Step: 2
Training loss: 0.261592298746109
Validation loss: 1.724792290759343

Epoch: 5| Step: 3
Training loss: 0.2270042896270752
Validation loss: 1.6840993191606255

Epoch: 5| Step: 4
Training loss: 0.349087119102478
Validation loss: 1.6885680114069292

Epoch: 5| Step: 5
Training loss: 0.18908950686454773
Validation loss: 1.703522002825173

Epoch: 5| Step: 6
Training loss: 0.23957796394824982
Validation loss: 1.698445516247903

Epoch: 5| Step: 7
Training loss: 0.4317934513092041
Validation loss: 1.7257875357904742

Epoch: 5| Step: 8
Training loss: 0.15376940369606018
Validation loss: 1.6848060777110438

Epoch: 5| Step: 9
Training loss: 0.3178466260433197
Validation loss: 1.6495215495427449

Epoch: 5| Step: 10
Training loss: 0.22998179495334625
Validation loss: 1.6606496252039427

Epoch: 306| Step: 0
Training loss: 0.5070260167121887
Validation loss: 1.6637552925335464

Epoch: 5| Step: 1
Training loss: 0.15768155455589294
Validation loss: 1.6799576269683016

Epoch: 5| Step: 2
Training loss: 0.28050723671913147
Validation loss: 1.6929848373577159

Epoch: 5| Step: 3
Training loss: 0.17154927551746368
Validation loss: 1.6543604449559284

Epoch: 5| Step: 4
Training loss: 0.1975458562374115
Validation loss: 1.6789432276961624

Epoch: 5| Step: 5
Training loss: 0.3142576813697815
Validation loss: 1.6920317885696248

Epoch: 5| Step: 6
Training loss: 0.4418085515499115
Validation loss: 1.6906603369661557

Epoch: 5| Step: 7
Training loss: 0.24317559599876404
Validation loss: 1.7026706767338577

Epoch: 5| Step: 8
Training loss: 0.15055525302886963
Validation loss: 1.6990906576956473

Epoch: 5| Step: 9
Training loss: 0.19677940011024475
Validation loss: 1.6747467838307863

Epoch: 5| Step: 10
Training loss: 0.2857130765914917
Validation loss: 1.6967362332087692

Epoch: 307| Step: 0
Training loss: 0.3539066016674042
Validation loss: 1.7092153256939304

Epoch: 5| Step: 1
Training loss: 0.2554786801338196
Validation loss: 1.6975007826282131

Epoch: 5| Step: 2
Training loss: 0.15457329154014587
Validation loss: 1.7046240401524368

Epoch: 5| Step: 3
Training loss: 0.3167470097541809
Validation loss: 1.7224498820561234

Epoch: 5| Step: 4
Training loss: 0.2640606462955475
Validation loss: 1.7017154418012148

Epoch: 5| Step: 5
Training loss: 0.19987896084785461
Validation loss: 1.7008057755808677

Epoch: 5| Step: 6
Training loss: 0.45831212401390076
Validation loss: 1.702890371763578

Epoch: 5| Step: 7
Training loss: 0.2911539077758789
Validation loss: 1.7478625928201983

Epoch: 5| Step: 8
Training loss: 0.2779448628425598
Validation loss: 1.7397608314791033

Epoch: 5| Step: 9
Training loss: 0.23250815272331238
Validation loss: 1.7182364591988184

Epoch: 5| Step: 10
Training loss: 0.22925247251987457
Validation loss: 1.700127669560012

Epoch: 308| Step: 0
Training loss: 0.261408269405365
Validation loss: 1.7130151448711273

Epoch: 5| Step: 1
Training loss: 0.11469151824712753
Validation loss: 1.7094625683240994

Epoch: 5| Step: 2
Training loss: 0.23987607657909393
Validation loss: 1.6949149408648092

Epoch: 5| Step: 3
Training loss: 0.27243590354919434
Validation loss: 1.7007684284640896

Epoch: 5| Step: 4
Training loss: 0.17561466991901398
Validation loss: 1.6806938545678252

Epoch: 5| Step: 5
Training loss: 0.2467566430568695
Validation loss: 1.691258430480957

Epoch: 5| Step: 6
Training loss: 0.30379727482795715
Validation loss: 1.6639263463276688

Epoch: 5| Step: 7
Training loss: 0.3585192561149597
Validation loss: 1.6697668157598025

Epoch: 5| Step: 8
Training loss: 0.22543171048164368
Validation loss: 1.653681726865871

Epoch: 5| Step: 9
Training loss: 0.20727315545082092
Validation loss: 1.6839421974715365

Epoch: 5| Step: 10
Training loss: 0.5820738673210144
Validation loss: 1.6704902290016093

Epoch: 309| Step: 0
Training loss: 0.7198301553726196
Validation loss: 1.686555189471091

Epoch: 5| Step: 1
Training loss: 0.3116309642791748
Validation loss: 1.6751952209780294

Epoch: 5| Step: 2
Training loss: 0.19633732736110687
Validation loss: 1.6620770833825553

Epoch: 5| Step: 3
Training loss: 0.13361169397830963
Validation loss: 1.6677803121587282

Epoch: 5| Step: 4
Training loss: 0.21592816710472107
Validation loss: 1.6420418921337332

Epoch: 5| Step: 5
Training loss: 0.16172254085540771
Validation loss: 1.664939353542943

Epoch: 5| Step: 6
Training loss: 0.2852388024330139
Validation loss: 1.7018676009229434

Epoch: 5| Step: 7
Training loss: 0.20052123069763184
Validation loss: 1.6555303681281306

Epoch: 5| Step: 8
Training loss: 0.28602761030197144
Validation loss: 1.6482846365180066

Epoch: 5| Step: 9
Training loss: 0.19902542233467102
Validation loss: 1.6532196229504001

Epoch: 5| Step: 10
Training loss: 0.20367461442947388
Validation loss: 1.6295505210917482

Epoch: 310| Step: 0
Training loss: 0.25745445489883423
Validation loss: 1.6663911791257962

Epoch: 5| Step: 1
Training loss: 0.4493878483772278
Validation loss: 1.6779234409332275

Epoch: 5| Step: 2
Training loss: 0.2739190459251404
Validation loss: 1.6941194226664882

Epoch: 5| Step: 3
Training loss: 0.24446828663349152
Validation loss: 1.7195913022564304

Epoch: 5| Step: 4
Training loss: 0.31815460324287415
Validation loss: 1.6734447479248047

Epoch: 5| Step: 5
Training loss: 0.3480333089828491
Validation loss: 1.7187116222996865

Epoch: 5| Step: 6
Training loss: 0.29001325368881226
Validation loss: 1.6982384125391643

Epoch: 5| Step: 7
Training loss: 0.2123904526233673
Validation loss: 1.725965912624072

Epoch: 5| Step: 8
Training loss: 0.16668295860290527
Validation loss: 1.7151824248734342

Epoch: 5| Step: 9
Training loss: 0.23764371871948242
Validation loss: 1.732036207311897

Epoch: 5| Step: 10
Training loss: 0.2285112738609314
Validation loss: 1.6998845825913131

Epoch: 311| Step: 0
Training loss: 0.22712688148021698
Validation loss: 1.7187755171970656

Epoch: 5| Step: 1
Training loss: 0.2933868169784546
Validation loss: 1.7190288959010955

Epoch: 5| Step: 2
Training loss: 0.24748949706554413
Validation loss: 1.7190522852764334

Epoch: 5| Step: 3
Training loss: 0.24671892821788788
Validation loss: 1.6886998171447425

Epoch: 5| Step: 4
Training loss: 0.32888442277908325
Validation loss: 1.7008712112262685

Epoch: 5| Step: 5
Training loss: 0.12893006205558777
Validation loss: 1.6495301672207412

Epoch: 5| Step: 6
Training loss: 0.2457047700881958
Validation loss: 1.6837467083366968

Epoch: 5| Step: 7
Training loss: 0.2563456594944
Validation loss: 1.6922278865691154

Epoch: 5| Step: 8
Training loss: 0.23654048144817352
Validation loss: 1.700402735381998

Epoch: 5| Step: 9
Training loss: 0.25187960267066956
Validation loss: 1.7305054549247987

Epoch: 5| Step: 10
Training loss: 0.48255735635757446
Validation loss: 1.7312169100648613

Epoch: 312| Step: 0
Training loss: 0.1974884569644928
Validation loss: 1.723071853319804

Epoch: 5| Step: 1
Training loss: 0.5697236657142639
Validation loss: 1.700493827942879

Epoch: 5| Step: 2
Training loss: 0.4106416702270508
Validation loss: 1.7308553418805521

Epoch: 5| Step: 3
Training loss: 0.3527069091796875
Validation loss: 1.7010129626079271

Epoch: 5| Step: 4
Training loss: 0.2969817519187927
Validation loss: 1.6897048258012342

Epoch: 5| Step: 5
Training loss: 0.2463914453983307
Validation loss: 1.666653290871651

Epoch: 5| Step: 6
Training loss: 0.24544723331928253
Validation loss: 1.6556714106631536

Epoch: 5| Step: 7
Training loss: 0.2014559805393219
Validation loss: 1.6986019316539969

Epoch: 5| Step: 8
Training loss: 0.31844836473464966
Validation loss: 1.6992651390772995

Epoch: 5| Step: 9
Training loss: 0.23000724613666534
Validation loss: 1.7415697202887586

Epoch: 5| Step: 10
Training loss: 0.1938251554965973
Validation loss: 1.727834939956665

Epoch: 313| Step: 0
Training loss: 0.3157168924808502
Validation loss: 1.7197463198374676

Epoch: 5| Step: 1
Training loss: 0.27137404680252075
Validation loss: 1.7208781857644357

Epoch: 5| Step: 2
Training loss: 0.19848036766052246
Validation loss: 1.7084793224129626

Epoch: 5| Step: 3
Training loss: 0.22628748416900635
Validation loss: 1.7461888546584754

Epoch: 5| Step: 4
Training loss: 0.3008236289024353
Validation loss: 1.7489437031489548

Epoch: 5| Step: 5
Training loss: 0.205437570810318
Validation loss: 1.7921396942548855

Epoch: 5| Step: 6
Training loss: 0.13846470415592194
Validation loss: 1.7701836093779533

Epoch: 5| Step: 7
Training loss: 0.37237703800201416
Validation loss: 1.7492117317773963

Epoch: 5| Step: 8
Training loss: 0.4605349004268646
Validation loss: 1.730904407398675

Epoch: 5| Step: 9
Training loss: 0.2198253571987152
Validation loss: 1.709175891773675

Epoch: 5| Step: 10
Training loss: 0.3808739185333252
Validation loss: 1.706525832094172

Epoch: 314| Step: 0
Training loss: 0.24393658339977264
Validation loss: 1.665928062572274

Epoch: 5| Step: 1
Training loss: 0.2936268448829651
Validation loss: 1.6925815459220641

Epoch: 5| Step: 2
Training loss: 0.2410249412059784
Validation loss: 1.6718250589986001

Epoch: 5| Step: 3
Training loss: 0.3064274787902832
Validation loss: 1.6519937002530662

Epoch: 5| Step: 4
Training loss: 0.2080746442079544
Validation loss: 1.6815381139837287

Epoch: 5| Step: 5
Training loss: 0.20148761570453644
Validation loss: 1.7018696787536784

Epoch: 5| Step: 6
Training loss: 0.37876972556114197
Validation loss: 1.7304747335372432

Epoch: 5| Step: 7
Training loss: 0.3120197057723999
Validation loss: 1.7612300431856545

Epoch: 5| Step: 8
Training loss: 0.3263685703277588
Validation loss: 1.7773064797924412

Epoch: 5| Step: 9
Training loss: 0.23273999989032745
Validation loss: 1.7973541495620564

Epoch: 5| Step: 10
Training loss: 0.523525059223175
Validation loss: 1.734161812772033

Epoch: 315| Step: 0
Training loss: 0.3725299835205078
Validation loss: 1.7460721051821144

Epoch: 5| Step: 1
Training loss: 0.3259708881378174
Validation loss: 1.730738696231637

Epoch: 5| Step: 2
Training loss: 0.19106407463550568
Validation loss: 1.7385542315821494

Epoch: 5| Step: 3
Training loss: 0.3055821359157562
Validation loss: 1.701387183640593

Epoch: 5| Step: 4
Training loss: 0.29563915729522705
Validation loss: 1.6814584847419494

Epoch: 5| Step: 5
Training loss: 0.21563275158405304
Validation loss: 1.6620879442461076

Epoch: 5| Step: 6
Training loss: 0.46055951714515686
Validation loss: 1.6405809720357258

Epoch: 5| Step: 7
Training loss: 0.23451486229896545
Validation loss: 1.6578267876819899

Epoch: 5| Step: 8
Training loss: 0.2065717875957489
Validation loss: 1.6846504621608283

Epoch: 5| Step: 9
Training loss: 0.24119973182678223
Validation loss: 1.646202004084023

Epoch: 5| Step: 10
Training loss: 0.1805083006620407
Validation loss: 1.662035370385775

Epoch: 316| Step: 0
Training loss: 0.21045663952827454
Validation loss: 1.6995521386464436

Epoch: 5| Step: 1
Training loss: 0.230809286236763
Validation loss: 1.666387463128695

Epoch: 5| Step: 2
Training loss: 0.21364712715148926
Validation loss: 1.629998876202491

Epoch: 5| Step: 3
Training loss: 0.23376643657684326
Validation loss: 1.6311309901616906

Epoch: 5| Step: 4
Training loss: 0.36165812611579895
Validation loss: 1.645561843790034

Epoch: 5| Step: 5
Training loss: 0.16372562944889069
Validation loss: 1.6570634303554412

Epoch: 5| Step: 6
Training loss: 0.23170599341392517
Validation loss: 1.6668450883639756

Epoch: 5| Step: 7
Training loss: 0.15565013885498047
Validation loss: 1.633950089895597

Epoch: 5| Step: 8
Training loss: 0.20718011260032654
Validation loss: 1.658476924383512

Epoch: 5| Step: 9
Training loss: 0.13318607211112976
Validation loss: 1.6433355346802743

Epoch: 5| Step: 10
Training loss: 0.5188841819763184
Validation loss: 1.6393396854400635

Epoch: 317| Step: 0
Training loss: 0.4629438519477844
Validation loss: 1.6672779667762019

Epoch: 5| Step: 1
Training loss: 0.1541944444179535
Validation loss: 1.6426958525052635

Epoch: 5| Step: 2
Training loss: 0.2512584328651428
Validation loss: 1.6027197363556072

Epoch: 5| Step: 3
Training loss: 0.14188805222511292
Validation loss: 1.6267631528198079

Epoch: 5| Step: 4
Training loss: 0.29622647166252136
Validation loss: 1.634860884758734

Epoch: 5| Step: 5
Training loss: 0.17243926227092743
Validation loss: 1.643050644987373

Epoch: 5| Step: 6
Training loss: 0.28831785917282104
Validation loss: 1.6662092452408166

Epoch: 5| Step: 7
Training loss: 0.19816258549690247
Validation loss: 1.6696336474469913

Epoch: 5| Step: 8
Training loss: 0.14558787643909454
Validation loss: 1.6828815167950046

Epoch: 5| Step: 9
Training loss: 0.26500266790390015
Validation loss: 1.6599386763829056

Epoch: 5| Step: 10
Training loss: 0.2923372983932495
Validation loss: 1.7079349397331156

Epoch: 318| Step: 0
Training loss: 0.17891769111156464
Validation loss: 1.653552770614624

Epoch: 5| Step: 1
Training loss: 0.17415599524974823
Validation loss: 1.6335918185531453

Epoch: 5| Step: 2
Training loss: 0.31261134147644043
Validation loss: 1.6067649356780513

Epoch: 5| Step: 3
Training loss: 0.15015563368797302
Validation loss: 1.602366816612982

Epoch: 5| Step: 4
Training loss: 0.43600910902023315
Validation loss: 1.6018126267258839

Epoch: 5| Step: 5
Training loss: 0.20728297531604767
Validation loss: 1.6166016414601316

Epoch: 5| Step: 6
Training loss: 0.1560613065958023
Validation loss: 1.6338011423746746

Epoch: 5| Step: 7
Training loss: 0.23068971931934357
Validation loss: 1.619536910005795

Epoch: 5| Step: 8
Training loss: 0.2515314817428589
Validation loss: 1.6315552508959206

Epoch: 5| Step: 9
Training loss: 0.18625958263874054
Validation loss: 1.6410819106204535

Epoch: 5| Step: 10
Training loss: 0.3005857467651367
Validation loss: 1.6976920109923168

Epoch: 319| Step: 0
Training loss: 0.472065269947052
Validation loss: 1.695639471853933

Epoch: 5| Step: 1
Training loss: 0.15207217633724213
Validation loss: 1.7173546360385032

Epoch: 5| Step: 2
Training loss: 0.2703043818473816
Validation loss: 1.7435851994381155

Epoch: 5| Step: 3
Training loss: 0.22666771709918976
Validation loss: 1.7535788282271354

Epoch: 5| Step: 4
Training loss: 0.3043128550052643
Validation loss: 1.74800996370213

Epoch: 5| Step: 5
Training loss: 0.3038842976093292
Validation loss: 1.711786408578196

Epoch: 5| Step: 6
Training loss: 0.15721070766448975
Validation loss: 1.6912748736719931

Epoch: 5| Step: 7
Training loss: 0.26221323013305664
Validation loss: 1.695322193125243

Epoch: 5| Step: 8
Training loss: 0.19210761785507202
Validation loss: 1.7196594092153734

Epoch: 5| Step: 9
Training loss: 0.1486414223909378
Validation loss: 1.7252731271969375

Epoch: 5| Step: 10
Training loss: 0.25735488533973694
Validation loss: 1.7263951532302364

Epoch: 320| Step: 0
Training loss: 0.296926885843277
Validation loss: 1.6999535227334628

Epoch: 5| Step: 1
Training loss: 0.3084416091442108
Validation loss: 1.6868660821709582

Epoch: 5| Step: 2
Training loss: 0.14151473343372345
Validation loss: 1.676596535149441

Epoch: 5| Step: 3
Training loss: 0.17242462933063507
Validation loss: 1.7108268917247813

Epoch: 5| Step: 4
Training loss: 0.23603412508964539
Validation loss: 1.722417873720969

Epoch: 5| Step: 5
Training loss: 0.2611815631389618
Validation loss: 1.730951742459369

Epoch: 5| Step: 6
Training loss: 0.4133451581001282
Validation loss: 1.7367170933754212

Epoch: 5| Step: 7
Training loss: 0.2425788938999176
Validation loss: 1.7507447786228632

Epoch: 5| Step: 8
Training loss: 0.3884304463863373
Validation loss: 1.691807322604682

Epoch: 5| Step: 9
Training loss: 0.29523155093193054
Validation loss: 1.690119844610973

Epoch: 5| Step: 10
Training loss: 0.1806197613477707
Validation loss: 1.7096705052160448

Epoch: 321| Step: 0
Training loss: 0.23514142632484436
Validation loss: 1.690820486314835

Epoch: 5| Step: 1
Training loss: 0.3110765218734741
Validation loss: 1.6983035226022043

Epoch: 5| Step: 2
Training loss: 0.18543657660484314
Validation loss: 1.7086703828586045

Epoch: 5| Step: 3
Training loss: 0.24369876086711884
Validation loss: 1.6766729329221992

Epoch: 5| Step: 4
Training loss: 0.35035428404808044
Validation loss: 1.6873383137487596

Epoch: 5| Step: 5
Training loss: 0.15931406617164612
Validation loss: 1.6983676738636468

Epoch: 5| Step: 6
Training loss: 0.15959881246089935
Validation loss: 1.6901199202383719

Epoch: 5| Step: 7
Training loss: 0.23973198235034943
Validation loss: 1.7209682644054454

Epoch: 5| Step: 8
Training loss: 0.4330832362174988
Validation loss: 1.7035840480558333

Epoch: 5| Step: 9
Training loss: 0.20509102940559387
Validation loss: 1.7108813921610515

Epoch: 5| Step: 10
Training loss: 0.18357670307159424
Validation loss: 1.6871492106427428

Epoch: 322| Step: 0
Training loss: 0.15836253762245178
Validation loss: 1.672463265798425

Epoch: 5| Step: 1
Training loss: 0.23488450050354004
Validation loss: 1.6970821067851076

Epoch: 5| Step: 2
Training loss: 0.40135177969932556
Validation loss: 1.6740484917035667

Epoch: 5| Step: 3
Training loss: 0.27487844228744507
Validation loss: 1.6731424235528516

Epoch: 5| Step: 4
Training loss: 0.11402542889118195
Validation loss: 1.6681946118672688

Epoch: 5| Step: 5
Training loss: 0.14286962151527405
Validation loss: 1.6891328032298754

Epoch: 5| Step: 6
Training loss: 0.18116845190525055
Validation loss: 1.6923888819192046

Epoch: 5| Step: 7
Training loss: 0.2211085855960846
Validation loss: 1.6890684404680807

Epoch: 5| Step: 8
Training loss: 0.4319535195827484
Validation loss: 1.7092858617023756

Epoch: 5| Step: 9
Training loss: 0.207787424325943
Validation loss: 1.6915023339691984

Epoch: 5| Step: 10
Training loss: 0.14755664765834808
Validation loss: 1.6682042767924647

Epoch: 323| Step: 0
Training loss: 0.23686733841896057
Validation loss: 1.7021936601208103

Epoch: 5| Step: 1
Training loss: 0.18327517807483673
Validation loss: 1.6647897125572286

Epoch: 5| Step: 2
Training loss: 0.3390100300312042
Validation loss: 1.6605907704240532

Epoch: 5| Step: 3
Training loss: 0.3082847595214844
Validation loss: 1.7263162353987336

Epoch: 5| Step: 4
Training loss: 0.20701821148395538
Validation loss: 1.7282056090652302

Epoch: 5| Step: 5
Training loss: 0.3150920271873474
Validation loss: 1.7336586841972925

Epoch: 5| Step: 6
Training loss: 0.21784338355064392
Validation loss: 1.7325579786813388

Epoch: 5| Step: 7
Training loss: 0.1008814200758934
Validation loss: 1.7059320506229196

Epoch: 5| Step: 8
Training loss: 0.20623548328876495
Validation loss: 1.699464113481583

Epoch: 5| Step: 9
Training loss: 0.1633801907300949
Validation loss: 1.7265845293639808

Epoch: 5| Step: 10
Training loss: 0.10644938051700592
Validation loss: 1.6753501738271406

Epoch: 324| Step: 0
Training loss: 0.3150835633277893
Validation loss: 1.6887042291702763

Epoch: 5| Step: 1
Training loss: 0.1709405928850174
Validation loss: 1.6925141952371086

Epoch: 5| Step: 2
Training loss: 0.19108352065086365
Validation loss: 1.7108648900062806

Epoch: 5| Step: 3
Training loss: 0.21093492209911346
Validation loss: 1.6980836750358663

Epoch: 5| Step: 4
Training loss: 0.3531773090362549
Validation loss: 1.6868049675418484

Epoch: 5| Step: 5
Training loss: 0.1820445954799652
Validation loss: 1.6603724930876045

Epoch: 5| Step: 6
Training loss: 0.16385605931282043
Validation loss: 1.6475526619982976

Epoch: 5| Step: 7
Training loss: 0.25893673300743103
Validation loss: 1.6617571692312918

Epoch: 5| Step: 8
Training loss: 0.16937372088432312
Validation loss: 1.6508944137122041

Epoch: 5| Step: 9
Training loss: 0.11677086353302002
Validation loss: 1.6556974700702134

Epoch: 5| Step: 10
Training loss: 0.386796772480011
Validation loss: 1.6598040301312682

Epoch: 325| Step: 0
Training loss: 0.14269855618476868
Validation loss: 1.6602704832630772

Epoch: 5| Step: 1
Training loss: 0.2880479693412781
Validation loss: 1.708811208765994

Epoch: 5| Step: 2
Training loss: 0.19812284409999847
Validation loss: 1.7043608439865934

Epoch: 5| Step: 3
Training loss: 0.4560980796813965
Validation loss: 1.7079283524585027

Epoch: 5| Step: 4
Training loss: 0.14667756855487823
Validation loss: 1.6955781008607598

Epoch: 5| Step: 5
Training loss: 0.1763049066066742
Validation loss: 1.69333682521697

Epoch: 5| Step: 6
Training loss: 0.1877320110797882
Validation loss: 1.7105221415078768

Epoch: 5| Step: 7
Training loss: 0.30443423986434937
Validation loss: 1.6894390172855829

Epoch: 5| Step: 8
Training loss: 0.1497696042060852
Validation loss: 1.682440298859791

Epoch: 5| Step: 9
Training loss: 0.17666137218475342
Validation loss: 1.6681125561396282

Epoch: 5| Step: 10
Training loss: 0.29592204093933105
Validation loss: 1.6244663538471344

Epoch: 326| Step: 0
Training loss: 0.1972755491733551
Validation loss: 1.6707152397401872

Epoch: 5| Step: 1
Training loss: 0.1424490213394165
Validation loss: 1.6317445719113914

Epoch: 5| Step: 2
Training loss: 0.24599775671958923
Validation loss: 1.648076989317453

Epoch: 5| Step: 3
Training loss: 0.2423955649137497
Validation loss: 1.6198544335621659

Epoch: 5| Step: 4
Training loss: 0.23604348301887512
Validation loss: 1.6377315803240704

Epoch: 5| Step: 5
Training loss: 0.1308799386024475
Validation loss: 1.6582277513319446

Epoch: 5| Step: 6
Training loss: 0.4041686952114105
Validation loss: 1.6968807943405644

Epoch: 5| Step: 7
Training loss: 0.13726022839546204
Validation loss: 1.659102169416284

Epoch: 5| Step: 8
Training loss: 0.1707165390253067
Validation loss: 1.6885727938785349

Epoch: 5| Step: 9
Training loss: 0.2161405086517334
Validation loss: 1.6757137877966768

Epoch: 5| Step: 10
Training loss: 0.29357561469078064
Validation loss: 1.7201066940061507

Epoch: 327| Step: 0
Training loss: 0.47708940505981445
Validation loss: 1.718729252456337

Epoch: 5| Step: 1
Training loss: 0.159947007894516
Validation loss: 1.718281006300321

Epoch: 5| Step: 2
Training loss: 0.22445520758628845
Validation loss: 1.7186292755988337

Epoch: 5| Step: 3
Training loss: 0.15367522835731506
Validation loss: 1.7256047892314132

Epoch: 5| Step: 4
Training loss: 0.2427513599395752
Validation loss: 1.6958505889420867

Epoch: 5| Step: 5
Training loss: 0.2527414858341217
Validation loss: 1.6939245577781432

Epoch: 5| Step: 6
Training loss: 0.18957003951072693
Validation loss: 1.7018742292158064

Epoch: 5| Step: 7
Training loss: 0.18918576836585999
Validation loss: 1.6797549442578388

Epoch: 5| Step: 8
Training loss: 0.18228156864643097
Validation loss: 1.6282054775504655

Epoch: 5| Step: 9
Training loss: 0.3244694471359253
Validation loss: 1.6238901640779229

Epoch: 5| Step: 10
Training loss: 0.2433518022298813
Validation loss: 1.6387509607499646

Epoch: 328| Step: 0
Training loss: 0.2542150318622589
Validation loss: 1.663996482408175

Epoch: 5| Step: 1
Training loss: 0.21600905060768127
Validation loss: 1.6765080395565237

Epoch: 5| Step: 2
Training loss: 0.11670146137475967
Validation loss: 1.7054371846619474

Epoch: 5| Step: 3
Training loss: 0.17811235785484314
Validation loss: 1.7169829158372776

Epoch: 5| Step: 4
Training loss: 0.25663819909095764
Validation loss: 1.7094465660792526

Epoch: 5| Step: 5
Training loss: 0.32318025827407837
Validation loss: 1.6991140227163992

Epoch: 5| Step: 6
Training loss: 0.21484823524951935
Validation loss: 1.7137472475728681

Epoch: 5| Step: 7
Training loss: 0.3821352422237396
Validation loss: 1.692673179411119

Epoch: 5| Step: 8
Training loss: 0.18282130360603333
Validation loss: 1.6920514696387834

Epoch: 5| Step: 9
Training loss: 0.2027338445186615
Validation loss: 1.6665469549035514

Epoch: 5| Step: 10
Training loss: 0.20231084525585175
Validation loss: 1.6485281464874104

Epoch: 329| Step: 0
Training loss: 0.11684592068195343
Validation loss: 1.6477803555868005

Epoch: 5| Step: 1
Training loss: 0.47946697473526
Validation loss: 1.6455303981739988

Epoch: 5| Step: 2
Training loss: 0.26809823513031006
Validation loss: 1.604512647915912

Epoch: 5| Step: 3
Training loss: 0.2563610374927521
Validation loss: 1.6342590855013939

Epoch: 5| Step: 4
Training loss: 0.18209201097488403
Validation loss: 1.618642835206883

Epoch: 5| Step: 5
Training loss: 0.24221837520599365
Validation loss: 1.6293167760295253

Epoch: 5| Step: 6
Training loss: 0.14347399771213531
Validation loss: 1.6390187535234677

Epoch: 5| Step: 7
Training loss: 0.2563827633857727
Validation loss: 1.6371154887701875

Epoch: 5| Step: 8
Training loss: 0.14105521142482758
Validation loss: 1.6560482664774823

Epoch: 5| Step: 9
Training loss: 0.2017795294523239
Validation loss: 1.6561504730614283

Epoch: 5| Step: 10
Training loss: 0.22490686178207397
Validation loss: 1.6460044384002686

Epoch: 330| Step: 0
Training loss: 0.1702689677476883
Validation loss: 1.6426477957797307

Epoch: 5| Step: 1
Training loss: 0.27010050415992737
Validation loss: 1.6521127095786474

Epoch: 5| Step: 2
Training loss: 0.35090264678001404
Validation loss: 1.642576272769641

Epoch: 5| Step: 3
Training loss: 0.14642676711082458
Validation loss: 1.6772941504755328

Epoch: 5| Step: 4
Training loss: 0.1702897995710373
Validation loss: 1.6792180627904914

Epoch: 5| Step: 5
Training loss: 0.4281102120876312
Validation loss: 1.6485664716330908

Epoch: 5| Step: 6
Training loss: 0.26562070846557617
Validation loss: 1.6751871224372619

Epoch: 5| Step: 7
Training loss: 0.14898255467414856
Validation loss: 1.6956314771406111

Epoch: 5| Step: 8
Training loss: 0.28256651759147644
Validation loss: 1.6434734367555188

Epoch: 5| Step: 9
Training loss: 0.1431448757648468
Validation loss: 1.671526664046831

Epoch: 5| Step: 10
Training loss: 0.26709023118019104
Validation loss: 1.6490560321397678

Epoch: 331| Step: 0
Training loss: 0.18489539623260498
Validation loss: 1.6626213378803705

Epoch: 5| Step: 1
Training loss: 0.21434617042541504
Validation loss: 1.644068661556449

Epoch: 5| Step: 2
Training loss: 0.1980632245540619
Validation loss: 1.6647756215064757

Epoch: 5| Step: 3
Training loss: 0.18704155087471008
Validation loss: 1.6829582939865768

Epoch: 5| Step: 4
Training loss: 0.23016175627708435
Validation loss: 1.6411532612257107

Epoch: 5| Step: 5
Training loss: 0.32498234510421753
Validation loss: 1.6477192755668395

Epoch: 5| Step: 6
Training loss: 0.16840267181396484
Validation loss: 1.6460590260003203

Epoch: 5| Step: 7
Training loss: 0.38480037450790405
Validation loss: 1.6669197261974376

Epoch: 5| Step: 8
Training loss: 0.19272808730602264
Validation loss: 1.6708099636980283

Epoch: 5| Step: 9
Training loss: 0.255826473236084
Validation loss: 1.6719717376975602

Epoch: 5| Step: 10
Training loss: 0.17878273129463196
Validation loss: 1.584933756500162

Epoch: 332| Step: 0
Training loss: 0.15141750872135162
Validation loss: 1.6360180583051456

Epoch: 5| Step: 1
Training loss: 0.1800212562084198
Validation loss: 1.6373397893803094

Epoch: 5| Step: 2
Training loss: 0.17258132994174957
Validation loss: 1.6391254983922487

Epoch: 5| Step: 3
Training loss: 0.1757219433784485
Validation loss: 1.625044563765167

Epoch: 5| Step: 4
Training loss: 0.12386859953403473
Validation loss: 1.6311425060354254

Epoch: 5| Step: 5
Training loss: 0.1663275957107544
Validation loss: 1.6392345607921641

Epoch: 5| Step: 6
Training loss: 0.14542540907859802
Validation loss: 1.6715460105608868

Epoch: 5| Step: 7
Training loss: 0.3418518006801605
Validation loss: 1.6734590722668556

Epoch: 5| Step: 8
Training loss: 0.3546789586544037
Validation loss: 1.6781235869212816

Epoch: 5| Step: 9
Training loss: 0.2624451816082001
Validation loss: 1.7023953468568864

Epoch: 5| Step: 10
Training loss: 0.22084715962409973
Validation loss: 1.664454262743714

Epoch: 333| Step: 0
Training loss: 0.2118566781282425
Validation loss: 1.6801019881361274

Epoch: 5| Step: 1
Training loss: 0.20578870177268982
Validation loss: 1.6570178590795046

Epoch: 5| Step: 2
Training loss: 0.17974554002285004
Validation loss: 1.6373793258461902

Epoch: 5| Step: 3
Training loss: 0.29233628511428833
Validation loss: 1.6849650657305153

Epoch: 5| Step: 4
Training loss: 0.27673283219337463
Validation loss: 1.6449498335520427

Epoch: 5| Step: 5
Training loss: 0.28622952103614807
Validation loss: 1.6311119641027143

Epoch: 5| Step: 6
Training loss: 0.1696588546037674
Validation loss: 1.615339978407788

Epoch: 5| Step: 7
Training loss: 0.40405672788619995
Validation loss: 1.6398654227615685

Epoch: 5| Step: 8
Training loss: 0.17189916968345642
Validation loss: 1.658252114890724

Epoch: 5| Step: 9
Training loss: 0.15751464664936066
Validation loss: 1.6637455878719207

Epoch: 5| Step: 10
Training loss: 0.26809972524642944
Validation loss: 1.6873211758111113

Epoch: 334| Step: 0
Training loss: 0.13106447458267212
Validation loss: 1.6593300181050454

Epoch: 5| Step: 1
Training loss: 0.42169514298439026
Validation loss: 1.6562118671273673

Epoch: 5| Step: 2
Training loss: 0.20175519585609436
Validation loss: 1.6430531394097112

Epoch: 5| Step: 3
Training loss: 0.17465202510356903
Validation loss: 1.6638776820193055

Epoch: 5| Step: 4
Training loss: 0.2354700267314911
Validation loss: 1.6776304385995353

Epoch: 5| Step: 5
Training loss: 0.3415173590183258
Validation loss: 1.6767557615874915

Epoch: 5| Step: 6
Training loss: 0.16186177730560303
Validation loss: 1.6491883070238176

Epoch: 5| Step: 7
Training loss: 0.12353780120611191
Validation loss: 1.6534935825614518

Epoch: 5| Step: 8
Training loss: 0.25367313623428345
Validation loss: 1.6376915747119534

Epoch: 5| Step: 9
Training loss: 0.11354707181453705
Validation loss: 1.6531364302481375

Epoch: 5| Step: 10
Training loss: 0.1543152779340744
Validation loss: 1.6958790697077268

Epoch: 335| Step: 0
Training loss: 0.1097208634018898
Validation loss: 1.672593798688663

Epoch: 5| Step: 1
Training loss: 0.197146937251091
Validation loss: 1.6655191593272711

Epoch: 5| Step: 2
Training loss: 0.14082717895507812
Validation loss: 1.6780940422447779

Epoch: 5| Step: 3
Training loss: 0.3481045365333557
Validation loss: 1.6564912449929021

Epoch: 5| Step: 4
Training loss: 0.14080889523029327
Validation loss: 1.6701347443365282

Epoch: 5| Step: 5
Training loss: 0.2568487524986267
Validation loss: 1.6859286536452591

Epoch: 5| Step: 6
Training loss: 0.1734739989042282
Validation loss: 1.6866998877576602

Epoch: 5| Step: 7
Training loss: 0.26109063625335693
Validation loss: 1.6705878691006733

Epoch: 5| Step: 8
Training loss: 0.21780121326446533
Validation loss: 1.6841954082571051

Epoch: 5| Step: 9
Training loss: 0.09656599909067154
Validation loss: 1.7145833135933004

Epoch: 5| Step: 10
Training loss: 0.2257811725139618
Validation loss: 1.6988564947600007

Epoch: 336| Step: 0
Training loss: 0.3379368782043457
Validation loss: 1.690307104459373

Epoch: 5| Step: 1
Training loss: 0.21685752272605896
Validation loss: 1.6780046442503571

Epoch: 5| Step: 2
Training loss: 0.1616152822971344
Validation loss: 1.6739273648108206

Epoch: 5| Step: 3
Training loss: 0.22019226849079132
Validation loss: 1.6967770463676863

Epoch: 5| Step: 4
Training loss: 0.10841081291437149
Validation loss: 1.6835904172671738

Epoch: 5| Step: 5
Training loss: 0.22930490970611572
Validation loss: 1.6699421046882548

Epoch: 5| Step: 6
Training loss: 0.18273678421974182
Validation loss: 1.6588954515354608

Epoch: 5| Step: 7
Training loss: 0.07772860676050186
Validation loss: 1.6508711256006712

Epoch: 5| Step: 8
Training loss: 0.14589950442314148
Validation loss: 1.6185063572340115

Epoch: 5| Step: 9
Training loss: 0.2743299603462219
Validation loss: 1.6509205154193345

Epoch: 5| Step: 10
Training loss: 0.13145454227924347
Validation loss: 1.6338285387203257

Epoch: 337| Step: 0
Training loss: 0.10518902540206909
Validation loss: 1.6259128175755984

Epoch: 5| Step: 1
Training loss: 0.12129471451044083
Validation loss: 1.6363864880736156

Epoch: 5| Step: 2
Training loss: 0.18357384204864502
Validation loss: 1.638348432638312

Epoch: 5| Step: 3
Training loss: 0.3316500782966614
Validation loss: 1.648545434398036

Epoch: 5| Step: 4
Training loss: 0.2781834006309509
Validation loss: 1.6509851460815759

Epoch: 5| Step: 5
Training loss: 0.1495019942522049
Validation loss: 1.6681786596134145

Epoch: 5| Step: 6
Training loss: 0.23293724656105042
Validation loss: 1.656475966976535

Epoch: 5| Step: 7
Training loss: 0.2940284311771393
Validation loss: 1.6778655962277484

Epoch: 5| Step: 8
Training loss: 0.28285977244377136
Validation loss: 1.672344575646103

Epoch: 5| Step: 9
Training loss: 0.1625656932592392
Validation loss: 1.6652388316328808

Epoch: 5| Step: 10
Training loss: 0.20328667759895325
Validation loss: 1.6699479459434428

Epoch: 338| Step: 0
Training loss: 0.24827782809734344
Validation loss: 1.6532052665628412

Epoch: 5| Step: 1
Training loss: 0.25841251015663147
Validation loss: 1.6689535802410496

Epoch: 5| Step: 2
Training loss: 0.37456706166267395
Validation loss: 1.63883218842168

Epoch: 5| Step: 3
Training loss: 0.11747938394546509
Validation loss: 1.6911503922554754

Epoch: 5| Step: 4
Training loss: 0.2365901917219162
Validation loss: 1.6838811469334427

Epoch: 5| Step: 5
Training loss: 0.1618657112121582
Validation loss: 1.666061665422173

Epoch: 5| Step: 6
Training loss: 0.23398151993751526
Validation loss: 1.6667890702524493

Epoch: 5| Step: 7
Training loss: 0.13344396650791168
Validation loss: 1.6578162934190483

Epoch: 5| Step: 8
Training loss: 0.11842574924230576
Validation loss: 1.672009286060128

Epoch: 5| Step: 9
Training loss: 0.13747207820415497
Validation loss: 1.6877685836566392

Epoch: 5| Step: 10
Training loss: 0.2067294865846634
Validation loss: 1.6854864628084245

Epoch: 339| Step: 0
Training loss: 0.20369970798492432
Validation loss: 1.6676457620436145

Epoch: 5| Step: 1
Training loss: 0.22197329998016357
Validation loss: 1.650522788365682

Epoch: 5| Step: 2
Training loss: 0.1867845356464386
Validation loss: 1.6347119013468425

Epoch: 5| Step: 3
Training loss: 0.1809600442647934
Validation loss: 1.64596382135986

Epoch: 5| Step: 4
Training loss: 0.16395530104637146
Validation loss: 1.6528874071695472

Epoch: 5| Step: 5
Training loss: 0.3882959485054016
Validation loss: 1.6342446586137176

Epoch: 5| Step: 6
Training loss: 0.19700635969638824
Validation loss: 1.7003820583384524

Epoch: 5| Step: 7
Training loss: 0.2546727657318115
Validation loss: 1.7006795457614365

Epoch: 5| Step: 8
Training loss: 0.24171432852745056
Validation loss: 1.6783698207588607

Epoch: 5| Step: 9
Training loss: 0.1483978033065796
Validation loss: 1.6997471381259222

Epoch: 5| Step: 10
Training loss: 0.1918412744998932
Validation loss: 1.7158598515295214

Epoch: 340| Step: 0
Training loss: 0.1205907016992569
Validation loss: 1.72376880081751

Epoch: 5| Step: 1
Training loss: 0.19090776145458221
Validation loss: 1.7236397433024582

Epoch: 5| Step: 2
Training loss: 0.1230819821357727
Validation loss: 1.7404525459453624

Epoch: 5| Step: 3
Training loss: 0.2838115096092224
Validation loss: 1.707273942168041

Epoch: 5| Step: 4
Training loss: 0.17509087920188904
Validation loss: 1.7201957651363906

Epoch: 5| Step: 5
Training loss: 0.34998154640197754
Validation loss: 1.7064332897945116

Epoch: 5| Step: 6
Training loss: 0.24191012978553772
Validation loss: 1.687396152045137

Epoch: 5| Step: 7
Training loss: 0.16449519991874695
Validation loss: 1.707930976344693

Epoch: 5| Step: 8
Training loss: 0.17590561509132385
Validation loss: 1.7053413724386564

Epoch: 5| Step: 9
Training loss: 0.21832945942878723
Validation loss: 1.6962790873742872

Epoch: 5| Step: 10
Training loss: 0.18826650083065033
Validation loss: 1.6795824727704447

Epoch: 341| Step: 0
Training loss: 0.15733233094215393
Validation loss: 1.685279510354483

Epoch: 5| Step: 1
Training loss: 0.3851803243160248
Validation loss: 1.6929497000991658

Epoch: 5| Step: 2
Training loss: 0.24337473511695862
Validation loss: 1.7131607397910087

Epoch: 5| Step: 3
Training loss: 0.2009238749742508
Validation loss: 1.685940146446228

Epoch: 5| Step: 4
Training loss: 0.2850281894207001
Validation loss: 1.690760858597294

Epoch: 5| Step: 5
Training loss: 0.20328471064567566
Validation loss: 1.6891943946961434

Epoch: 5| Step: 6
Training loss: 0.18023474514484406
Validation loss: 1.659271546589431

Epoch: 5| Step: 7
Training loss: 0.20629699528217316
Validation loss: 1.6153290194849814

Epoch: 5| Step: 8
Training loss: 0.2348862588405609
Validation loss: 1.6123078715416692

Epoch: 5| Step: 9
Training loss: 0.15920212864875793
Validation loss: 1.6334092950308194

Epoch: 5| Step: 10
Training loss: 0.19443285465240479
Validation loss: 1.6731239621357252

Epoch: 342| Step: 0
Training loss: 0.24838078022003174
Validation loss: 1.650453700814196

Epoch: 5| Step: 1
Training loss: 0.14431050419807434
Validation loss: 1.6427914096463112

Epoch: 5| Step: 2
Training loss: 0.2019541710615158
Validation loss: 1.6988546643205868

Epoch: 5| Step: 3
Training loss: 0.3384590744972229
Validation loss: 1.7118896310047438

Epoch: 5| Step: 4
Training loss: 0.13882677257061005
Validation loss: 1.7114815570974862

Epoch: 5| Step: 5
Training loss: 0.20189328491687775
Validation loss: 1.7104398563343992

Epoch: 5| Step: 6
Training loss: 0.3105161786079407
Validation loss: 1.6865852263665968

Epoch: 5| Step: 7
Training loss: 0.20951417088508606
Validation loss: 1.7205093112043155

Epoch: 5| Step: 8
Training loss: 0.1409062147140503
Validation loss: 1.7216794542087022

Epoch: 5| Step: 9
Training loss: 0.2346382588148117
Validation loss: 1.6979200698996102

Epoch: 5| Step: 10
Training loss: 0.1116025522351265
Validation loss: 1.6976370119279431

Epoch: 343| Step: 0
Training loss: 0.13135452568531036
Validation loss: 1.667883449985135

Epoch: 5| Step: 1
Training loss: 0.14533749222755432
Validation loss: 1.6703304706081268

Epoch: 5| Step: 2
Training loss: 0.1725146323442459
Validation loss: 1.635150650496124

Epoch: 5| Step: 3
Training loss: 0.25558483600616455
Validation loss: 1.6243161296331754

Epoch: 5| Step: 4
Training loss: 0.17528903484344482
Validation loss: 1.605123189187819

Epoch: 5| Step: 5
Training loss: 0.11652199923992157
Validation loss: 1.6173833429172475

Epoch: 5| Step: 6
Training loss: 0.14153829216957092
Validation loss: 1.5818802054210375

Epoch: 5| Step: 7
Training loss: 0.24755704402923584
Validation loss: 1.597422779247325

Epoch: 5| Step: 8
Training loss: 0.2749426066875458
Validation loss: 1.5997663210797053

Epoch: 5| Step: 9
Training loss: 0.12818387150764465
Validation loss: 1.6095317050974856

Epoch: 5| Step: 10
Training loss: 0.3161415755748749
Validation loss: 1.5862196107064523

Epoch: 344| Step: 0
Training loss: 0.21612648665905
Validation loss: 1.6253116156465264

Epoch: 5| Step: 1
Training loss: 0.1484055519104004
Validation loss: 1.6099410672341623

Epoch: 5| Step: 2
Training loss: 0.30287349224090576
Validation loss: 1.6509712485856907

Epoch: 5| Step: 3
Training loss: 0.2583220601081848
Validation loss: 1.6514477011977986

Epoch: 5| Step: 4
Training loss: 0.14051096141338348
Validation loss: 1.6636824941122403

Epoch: 5| Step: 5
Training loss: 0.16567668318748474
Validation loss: 1.669807384731949

Epoch: 5| Step: 6
Training loss: 0.19585135579109192
Validation loss: 1.6885342533870409

Epoch: 5| Step: 7
Training loss: 0.23480205237865448
Validation loss: 1.7114887827186174

Epoch: 5| Step: 8
Training loss: 0.11440809071063995
Validation loss: 1.697653487164487

Epoch: 5| Step: 9
Training loss: 0.16231215000152588
Validation loss: 1.7065758294956659

Epoch: 5| Step: 10
Training loss: 0.16810277104377747
Validation loss: 1.6919340023430445

Epoch: 345| Step: 0
Training loss: 0.26590755581855774
Validation loss: 1.7127667473208519

Epoch: 5| Step: 1
Training loss: 0.16652068495750427
Validation loss: 1.6597352873894475

Epoch: 5| Step: 2
Training loss: 0.225376695394516
Validation loss: 1.6746933947327316

Epoch: 5| Step: 3
Training loss: 0.23632068932056427
Validation loss: 1.6375099779457174

Epoch: 5| Step: 4
Training loss: 0.17007598280906677
Validation loss: 1.6173449639351136

Epoch: 5| Step: 5
Training loss: 0.29316550493240356
Validation loss: 1.6490664238570838

Epoch: 5| Step: 6
Training loss: 0.1839839220046997
Validation loss: 1.6142262207564486

Epoch: 5| Step: 7
Training loss: 0.20522566139698029
Validation loss: 1.6166471640268962

Epoch: 5| Step: 8
Training loss: 0.12565073370933533
Validation loss: 1.6044338646755423

Epoch: 5| Step: 9
Training loss: 0.1918623447418213
Validation loss: 1.5832786617740509

Epoch: 5| Step: 10
Training loss: 0.25180143117904663
Validation loss: 1.5815993085984261

Epoch: 346| Step: 0
Training loss: 0.10531656444072723
Validation loss: 1.5964433864880634

Epoch: 5| Step: 1
Training loss: 0.25745290517807007
Validation loss: 1.658792052217709

Epoch: 5| Step: 2
Training loss: 0.18395587801933289
Validation loss: 1.6254606810949181

Epoch: 5| Step: 3
Training loss: 0.20338702201843262
Validation loss: 1.6647402009656351

Epoch: 5| Step: 4
Training loss: 0.21347741782665253
Validation loss: 1.6621560742778163

Epoch: 5| Step: 5
Training loss: 0.14656007289886475
Validation loss: 1.6538050648986653

Epoch: 5| Step: 6
Training loss: 0.19450421631336212
Validation loss: 1.6454371970186952

Epoch: 5| Step: 7
Training loss: 0.16090235114097595
Validation loss: 1.6463299169335315

Epoch: 5| Step: 8
Training loss: 0.19633597135543823
Validation loss: 1.617337583213724

Epoch: 5| Step: 9
Training loss: 0.177396759390831
Validation loss: 1.6306549259411391

Epoch: 5| Step: 10
Training loss: 0.21139241755008698
Validation loss: 1.6280158463344778

Epoch: 347| Step: 0
Training loss: 0.1398242712020874
Validation loss: 1.6178130411332654

Epoch: 5| Step: 1
Training loss: 0.11816699802875519
Validation loss: 1.6228481620870612

Epoch: 5| Step: 2
Training loss: 0.1264495849609375
Validation loss: 1.6312456284799883

Epoch: 5| Step: 3
Training loss: 0.15769580006599426
Validation loss: 1.668456362139794

Epoch: 5| Step: 4
Training loss: 0.404940128326416
Validation loss: 1.6276399166353288

Epoch: 5| Step: 5
Training loss: 0.22029924392700195
Validation loss: 1.6670424348564559

Epoch: 5| Step: 6
Training loss: 0.17804959416389465
Validation loss: 1.6231195221665085

Epoch: 5| Step: 7
Training loss: 0.17347802221775055
Validation loss: 1.6735199715501519

Epoch: 5| Step: 8
Training loss: 0.1849014163017273
Validation loss: 1.6922819870774464

Epoch: 5| Step: 9
Training loss: 0.1348215639591217
Validation loss: 1.6801559361078406

Epoch: 5| Step: 10
Training loss: 0.20908010005950928
Validation loss: 1.693779348045267

Epoch: 348| Step: 0
Training loss: 0.12754563987255096
Validation loss: 1.6583021033194758

Epoch: 5| Step: 1
Training loss: 0.2095392495393753
Validation loss: 1.6901440492240332

Epoch: 5| Step: 2
Training loss: 0.17720037698745728
Validation loss: 1.685979256065943

Epoch: 5| Step: 3
Training loss: 0.3192991316318512
Validation loss: 1.6656875635987969

Epoch: 5| Step: 4
Training loss: 0.15475419163703918
Validation loss: 1.6299770878207298

Epoch: 5| Step: 5
Training loss: 0.1925843060016632
Validation loss: 1.6582091457100325

Epoch: 5| Step: 6
Training loss: 0.15283668041229248
Validation loss: 1.6452172507521927

Epoch: 5| Step: 7
Training loss: 0.19392217695713043
Validation loss: 1.6275142597895798

Epoch: 5| Step: 8
Training loss: 0.12242219597101212
Validation loss: 1.6117259699811217

Epoch: 5| Step: 9
Training loss: 0.23504260182380676
Validation loss: 1.6113223907768086

Epoch: 5| Step: 10
Training loss: 0.22574517130851746
Validation loss: 1.5984021540611022

Epoch: 349| Step: 0
Training loss: 0.14295904338359833
Validation loss: 1.6033663518967167

Epoch: 5| Step: 1
Training loss: 0.12039747089147568
Validation loss: 1.6416931126707344

Epoch: 5| Step: 2
Training loss: 0.2049427330493927
Validation loss: 1.6515782648517239

Epoch: 5| Step: 3
Training loss: 0.22266905009746552
Validation loss: 1.6623676598712962

Epoch: 5| Step: 4
Training loss: 0.13836313784122467
Validation loss: 1.6241114075465868

Epoch: 5| Step: 5
Training loss: 0.14239108562469482
Validation loss: 1.6169279544584212

Epoch: 5| Step: 6
Training loss: 0.3599773943424225
Validation loss: 1.6130548343863538

Epoch: 5| Step: 7
Training loss: 0.09179316461086273
Validation loss: 1.591194709142049

Epoch: 5| Step: 8
Training loss: 0.21780967712402344
Validation loss: 1.5915232268712853

Epoch: 5| Step: 9
Training loss: 0.21448437869548798
Validation loss: 1.5965754588445027

Epoch: 5| Step: 10
Training loss: 0.17882958054542542
Validation loss: 1.5947090759072253

Epoch: 350| Step: 0
Training loss: 0.13186484575271606
Validation loss: 1.5967925094789075

Epoch: 5| Step: 1
Training loss: 0.21164023876190186
Validation loss: 1.615858898367933

Epoch: 5| Step: 2
Training loss: 0.15072691440582275
Validation loss: 1.6111450374767344

Epoch: 5| Step: 3
Training loss: 0.18483075499534607
Validation loss: 1.6193733471696095

Epoch: 5| Step: 4
Training loss: 0.3497903347015381
Validation loss: 1.617078435036444

Epoch: 5| Step: 5
Training loss: 0.17940151691436768
Validation loss: 1.648552652328245

Epoch: 5| Step: 6
Training loss: 0.23055057227611542
Validation loss: 1.648977469372493

Epoch: 5| Step: 7
Training loss: 0.1710561215877533
Validation loss: 1.6719912200845697

Epoch: 5| Step: 8
Training loss: 0.1216067299246788
Validation loss: 1.656237558651996

Epoch: 5| Step: 9
Training loss: 0.2815910577774048
Validation loss: 1.66561169521783

Epoch: 5| Step: 10
Training loss: 0.17915956676006317
Validation loss: 1.6901788250092538

Testing loss: 2.0914824538760715
