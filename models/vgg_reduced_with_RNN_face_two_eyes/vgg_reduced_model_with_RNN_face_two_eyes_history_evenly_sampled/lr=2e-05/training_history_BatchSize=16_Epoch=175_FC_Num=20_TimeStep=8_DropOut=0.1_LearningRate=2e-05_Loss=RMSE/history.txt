Epoch: 1| Step: 0
Training loss: 6.016790420795246
Validation loss: 5.829719515141178

Epoch: 6| Step: 1
Training loss: 6.3136254242166165
Validation loss: 5.807510279009716

Epoch: 6| Step: 2
Training loss: 5.059346665131627
Validation loss: 5.787432257228066

Epoch: 6| Step: 3
Training loss: 5.199363104624026
Validation loss: 5.7676438062763005

Epoch: 6| Step: 4
Training loss: 6.416805447485447
Validation loss: 5.747014508785097

Epoch: 6| Step: 5
Training loss: 4.352473220173126
Validation loss: 5.723995661834723

Epoch: 6| Step: 6
Training loss: 5.81054326417955
Validation loss: 5.69945054456286

Epoch: 6| Step: 7
Training loss: 5.36695987935047
Validation loss: 5.67225676287711

Epoch: 6| Step: 8
Training loss: 5.682627172964461
Validation loss: 5.640721268670763

Epoch: 6| Step: 9
Training loss: 5.202033584269255
Validation loss: 5.60611552847268

Epoch: 6| Step: 10
Training loss: 6.093721203858244
Validation loss: 5.567989485657773

Epoch: 6| Step: 11
Training loss: 7.1223961606394655
Validation loss: 5.525763497630047

Epoch: 6| Step: 12
Training loss: 4.940652541024104
Validation loss: 5.481501198875763

Epoch: 6| Step: 13
Training loss: 5.671422346563997
Validation loss: 5.433622230450485

Epoch: 2| Step: 0
Training loss: 4.378348240957061
Validation loss: 5.384262439526659

Epoch: 6| Step: 1
Training loss: 4.895935685190371
Validation loss: 5.333944469605469

Epoch: 6| Step: 2
Training loss: 3.744735964951947
Validation loss: 5.28347170051977

Epoch: 6| Step: 3
Training loss: 6.417960725896536
Validation loss: 5.2307903045720145

Epoch: 6| Step: 4
Training loss: 4.878704912904373
Validation loss: 5.175224799382605

Epoch: 6| Step: 5
Training loss: 5.137988495632313
Validation loss: 5.116432417915666

Epoch: 6| Step: 6
Training loss: 4.751889304827295
Validation loss: 5.058026554200332

Epoch: 6| Step: 7
Training loss: 6.036654723963236
Validation loss: 5.002549261953519

Epoch: 6| Step: 8
Training loss: 6.040843548005888
Validation loss: 4.951457164033858

Epoch: 6| Step: 9
Training loss: 5.038675645276324
Validation loss: 4.897114500433589

Epoch: 6| Step: 10
Training loss: 4.070886494586485
Validation loss: 4.850686208685329

Epoch: 6| Step: 11
Training loss: 5.422309088575713
Validation loss: 4.804186117972457

Epoch: 6| Step: 12
Training loss: 5.085483513183993
Validation loss: 4.759631675991094

Epoch: 6| Step: 13
Training loss: 4.467642266687845
Validation loss: 4.710814013177485

Epoch: 3| Step: 0
Training loss: 3.562844778409391
Validation loss: 4.654516013534825

Epoch: 6| Step: 1
Training loss: 4.433833797191014
Validation loss: 4.61239528297586

Epoch: 6| Step: 2
Training loss: 4.802969077861175
Validation loss: 4.579549756231795

Epoch: 6| Step: 3
Training loss: 4.1605326450911475
Validation loss: 4.548529445692972

Epoch: 6| Step: 4
Training loss: 4.919507235219593
Validation loss: 4.516222232781278

Epoch: 6| Step: 5
Training loss: 4.853719971804849
Validation loss: 4.4836640319072405

Epoch: 6| Step: 6
Training loss: 5.679493057301809
Validation loss: 4.456505554987239

Epoch: 6| Step: 7
Training loss: 3.3609379880542125
Validation loss: 4.420863867723621

Epoch: 6| Step: 8
Training loss: 4.2744545571890935
Validation loss: 4.394058958062373

Epoch: 6| Step: 9
Training loss: 5.118573136586977
Validation loss: 4.366519578474311

Epoch: 6| Step: 10
Training loss: 4.159864875726345
Validation loss: 4.340030867752868

Epoch: 6| Step: 11
Training loss: 4.917862870559024
Validation loss: 4.317241293376386

Epoch: 6| Step: 12
Training loss: 4.780196329338523
Validation loss: 4.276728781162729

Epoch: 6| Step: 13
Training loss: 3.774796835377563
Validation loss: 4.248025488577438

Epoch: 4| Step: 0
Training loss: 4.631233345032679
Validation loss: 4.2213653296889815

Epoch: 6| Step: 1
Training loss: 4.809274955239384
Validation loss: 4.195437874342051

Epoch: 6| Step: 2
Training loss: 5.116969073343965
Validation loss: 4.16088307457805

Epoch: 6| Step: 3
Training loss: 4.136197468852615
Validation loss: 4.141546718966458

Epoch: 6| Step: 4
Training loss: 4.73649242627394
Validation loss: 4.128922651679384

Epoch: 6| Step: 5
Training loss: 4.633570385547442
Validation loss: 4.115036798642402

Epoch: 6| Step: 6
Training loss: 4.335737783970297
Validation loss: 4.102031960680207

Epoch: 6| Step: 7
Training loss: 2.739350419000573
Validation loss: 4.095222148953476

Epoch: 6| Step: 8
Training loss: 4.226715479989077
Validation loss: 4.084557618230746

Epoch: 6| Step: 9
Training loss: 4.526659304051505
Validation loss: 4.057242508497153

Epoch: 6| Step: 10
Training loss: 4.129031205609787
Validation loss: 4.048324478049824

Epoch: 6| Step: 11
Training loss: 2.8182122607838247
Validation loss: 4.045515639100125

Epoch: 6| Step: 12
Training loss: 4.417495553792152
Validation loss: 4.04194454349593

Epoch: 6| Step: 13
Training loss: 2.827760198680478
Validation loss: 4.027436692860912

Epoch: 5| Step: 0
Training loss: 3.9452653636571586
Validation loss: 4.0169331624860325

Epoch: 6| Step: 1
Training loss: 4.223643537739273
Validation loss: 3.9931830234997445

Epoch: 6| Step: 2
Training loss: 4.821318040822119
Validation loss: 3.993667314465494

Epoch: 6| Step: 3
Training loss: 4.128716153159994
Validation loss: 3.985009640444373

Epoch: 6| Step: 4
Training loss: 3.407695918338782
Validation loss: 3.97185543109022

Epoch: 6| Step: 5
Training loss: 4.608961597589705
Validation loss: 3.9548838837250138

Epoch: 6| Step: 6
Training loss: 4.721972445196325
Validation loss: 3.937967356343127

Epoch: 6| Step: 7
Training loss: 3.4662403272458744
Validation loss: 3.9245168085559867

Epoch: 6| Step: 8
Training loss: 3.977905046805588
Validation loss: 3.9247205936953753

Epoch: 6| Step: 9
Training loss: 4.1443278328379325
Validation loss: 3.916447513988458

Epoch: 6| Step: 10
Training loss: 3.2236060390152192
Validation loss: 3.893998704709427

Epoch: 6| Step: 11
Training loss: 4.609249824505301
Validation loss: 3.8741563625572453

Epoch: 6| Step: 12
Training loss: 3.9069989516386445
Validation loss: 3.863485131784192

Epoch: 6| Step: 13
Training loss: 3.681531828631203
Validation loss: 3.8582907702233546

Epoch: 6| Step: 0
Training loss: 4.3893215647555515
Validation loss: 3.855732539773816

Epoch: 6| Step: 1
Training loss: 2.6726986691861714
Validation loss: 3.8443743924513143

Epoch: 6| Step: 2
Training loss: 4.451369839827706
Validation loss: 3.8380997697098875

Epoch: 6| Step: 3
Training loss: 4.257321278645117
Validation loss: 3.826367756565524

Epoch: 6| Step: 4
Training loss: 4.407264322177873
Validation loss: 3.815716303154035

Epoch: 6| Step: 5
Training loss: 4.211095350488198
Validation loss: 3.806994851303182

Epoch: 6| Step: 6
Training loss: 3.1685150841908767
Validation loss: 3.784981765771422

Epoch: 6| Step: 7
Training loss: 4.281951178609594
Validation loss: 3.7728896629445385

Epoch: 6| Step: 8
Training loss: 4.158222848855288
Validation loss: 3.773861870146183

Epoch: 6| Step: 9
Training loss: 4.188817286757781
Validation loss: 3.7659673156083264

Epoch: 6| Step: 10
Training loss: 3.1568152799604845
Validation loss: 3.742831090364833

Epoch: 6| Step: 11
Training loss: 4.652222395562516
Validation loss: 3.7398532373901254

Epoch: 6| Step: 12
Training loss: 2.9307478549854733
Validation loss: 3.7293095128514095

Epoch: 6| Step: 13
Training loss: 3.797183805238962
Validation loss: 3.731274979797131

Epoch: 7| Step: 0
Training loss: 4.347943374461587
Validation loss: 3.721674595593621

Epoch: 6| Step: 1
Training loss: 3.531007876577265
Validation loss: 3.710214379520469

Epoch: 6| Step: 2
Training loss: 4.490775933115046
Validation loss: 3.695645415137805

Epoch: 6| Step: 3
Training loss: 3.6616951588659594
Validation loss: 3.684721326491551

Epoch: 6| Step: 4
Training loss: 3.298190030889427
Validation loss: 3.6760828306550737

Epoch: 6| Step: 5
Training loss: 4.043725633031902
Validation loss: 3.6772859792858195

Epoch: 6| Step: 6
Training loss: 3.761470037776823
Validation loss: 3.6615983920500312

Epoch: 6| Step: 7
Training loss: 2.4918195399036827
Validation loss: 3.644646614882334

Epoch: 6| Step: 8
Training loss: 4.318051952252719
Validation loss: 3.641911820347403

Epoch: 6| Step: 9
Training loss: 3.918536950362962
Validation loss: 3.623437610542325

Epoch: 6| Step: 10
Training loss: 4.308079098271963
Validation loss: 3.6209402650392235

Epoch: 6| Step: 11
Training loss: 4.014776830492229
Validation loss: 3.627289204444898

Epoch: 6| Step: 12
Training loss: 3.246037194669409
Validation loss: 3.6154539520772344

Epoch: 6| Step: 13
Training loss: 4.07968098272112
Validation loss: 3.602150451205281

Epoch: 8| Step: 0
Training loss: 3.254563135929231
Validation loss: 3.6035034368009704

Epoch: 6| Step: 1
Training loss: 3.7627332038466506
Validation loss: 3.6016018851347598

Epoch: 6| Step: 2
Training loss: 4.85944879113989
Validation loss: 3.5951377582502646

Epoch: 6| Step: 3
Training loss: 3.9337159396364654
Validation loss: 3.577722009717881

Epoch: 6| Step: 4
Training loss: 3.5110442433515376
Validation loss: 3.5651965209520498

Epoch: 6| Step: 5
Training loss: 4.068733480159196
Validation loss: 3.555957506826913

Epoch: 6| Step: 6
Training loss: 3.327582086686989
Validation loss: 3.559249808629543

Epoch: 6| Step: 7
Training loss: 3.5296494899423916
Validation loss: 3.5538319355583927

Epoch: 6| Step: 8
Training loss: 3.6527338319430673
Validation loss: 3.5389753946364952

Epoch: 6| Step: 9
Training loss: 3.145926029953263
Validation loss: 3.543391009305397

Epoch: 6| Step: 10
Training loss: 3.9107003457454863
Validation loss: 3.5356491598231328

Epoch: 6| Step: 11
Training loss: 4.220684596934113
Validation loss: 3.503876414560507

Epoch: 6| Step: 12
Training loss: 3.801506326168666
Validation loss: 3.485503640924333

Epoch: 6| Step: 13
Training loss: 2.773222493178934
Validation loss: 3.486522096724335

Epoch: 9| Step: 0
Training loss: 4.082904922951706
Validation loss: 3.489647642500241

Epoch: 6| Step: 1
Training loss: 2.365800709416071
Validation loss: 3.479951484225535

Epoch: 6| Step: 2
Training loss: 3.9061374495504215
Validation loss: 3.470234259300885

Epoch: 6| Step: 3
Training loss: 3.1914554064547356
Validation loss: 3.4578604144409675

Epoch: 6| Step: 4
Training loss: 3.4686015329291258
Validation loss: 3.4473253295788897

Epoch: 6| Step: 5
Training loss: 3.7175249919038458
Validation loss: 3.4452634161518754

Epoch: 6| Step: 6
Training loss: 3.882457079825168
Validation loss: 3.4618317223300634

Epoch: 6| Step: 7
Training loss: 3.8495784082817157
Validation loss: 3.4536804085153348

Epoch: 6| Step: 8
Training loss: 3.8238686078853563
Validation loss: 3.428116459997156

Epoch: 6| Step: 9
Training loss: 3.4844360346216887
Validation loss: 3.416247915202449

Epoch: 6| Step: 10
Training loss: 3.769584758161355
Validation loss: 3.411778972517861

Epoch: 6| Step: 11
Training loss: 4.000972152830435
Validation loss: 3.40842716105844

Epoch: 6| Step: 12
Training loss: 4.079964526153134
Validation loss: 3.409304207374699

Epoch: 6| Step: 13
Training loss: 2.7877082849528265
Validation loss: 3.4007497564619604

Epoch: 10| Step: 0
Training loss: 3.629270734437261
Validation loss: 3.3953119588988283

Epoch: 6| Step: 1
Training loss: 3.8910800407292854
Validation loss: 3.3980933079568194

Epoch: 6| Step: 2
Training loss: 2.883018424269983
Validation loss: 3.396398671769041

Epoch: 6| Step: 3
Training loss: 3.8800581866748365
Validation loss: 3.401066872507845

Epoch: 6| Step: 4
Training loss: 3.193938540512909
Validation loss: 3.3730612199089975

Epoch: 6| Step: 5
Training loss: 3.530161597035479
Validation loss: 3.3633326157000667

Epoch: 6| Step: 6
Training loss: 3.502276633830207
Validation loss: 3.363348002085361

Epoch: 6| Step: 7
Training loss: 3.527495692498533
Validation loss: 3.3674687573422557

Epoch: 6| Step: 8
Training loss: 3.732843060885323
Validation loss: 3.3936288199240217

Epoch: 6| Step: 9
Training loss: 3.7760208164384843
Validation loss: 3.369262225153351

Epoch: 6| Step: 10
Training loss: 3.561164471773177
Validation loss: 3.3498500031862424

Epoch: 6| Step: 11
Training loss: 3.116275816564507
Validation loss: 3.345508349640995

Epoch: 6| Step: 12
Training loss: 4.159966205679736
Validation loss: 3.3418373155375543

Epoch: 6| Step: 13
Training loss: 3.967025742720635
Validation loss: 3.3369334058680424

Epoch: 11| Step: 0
Training loss: 3.346809769821998
Validation loss: 3.3377624654932307

Epoch: 6| Step: 1
Training loss: 4.112710389666112
Validation loss: 3.334594845222168

Epoch: 6| Step: 2
Training loss: 2.479947253096991
Validation loss: 3.336446760629316

Epoch: 6| Step: 3
Training loss: 3.443409919908735
Validation loss: 3.369676195841549

Epoch: 6| Step: 4
Training loss: 3.5829375440268243
Validation loss: 3.325390805058212

Epoch: 6| Step: 5
Training loss: 3.698454539264192
Validation loss: 3.321568388390619

Epoch: 6| Step: 6
Training loss: 3.767606348512418
Validation loss: 3.326987414566272

Epoch: 6| Step: 7
Training loss: 3.4031999563994626
Validation loss: 3.347151478211973

Epoch: 6| Step: 8
Training loss: 3.194465058485958
Validation loss: 3.361203251019289

Epoch: 6| Step: 9
Training loss: 3.709411050160159
Validation loss: 3.3347781300875283

Epoch: 6| Step: 10
Training loss: 3.4257857041020077
Validation loss: 3.31955685668834

Epoch: 6| Step: 11
Training loss: 4.104949540863106
Validation loss: 3.3101347862544004

Epoch: 6| Step: 12
Training loss: 3.743481501916096
Validation loss: 3.310011435266132

Epoch: 6| Step: 13
Training loss: 3.633510858824265
Validation loss: 3.3154934657106687

Epoch: 12| Step: 0
Training loss: 3.1298118166674915
Validation loss: 3.3364390761070197

Epoch: 6| Step: 1
Training loss: 4.084651007808478
Validation loss: 3.333319859836379

Epoch: 6| Step: 2
Training loss: 3.504952877233995
Validation loss: 3.2988125418166714

Epoch: 6| Step: 3
Training loss: 3.2183839163878756
Validation loss: 3.287359923153791

Epoch: 6| Step: 4
Training loss: 3.5860967995492405
Validation loss: 3.2836625644075776

Epoch: 6| Step: 5
Training loss: 3.819070625892724
Validation loss: 3.2858189085477267

Epoch: 6| Step: 6
Training loss: 3.26610010514843
Validation loss: 3.2989549528371866

Epoch: 6| Step: 7
Training loss: 3.2382138087631964
Validation loss: 3.2826609416538317

Epoch: 6| Step: 8
Training loss: 3.896308149210418
Validation loss: 3.2779716322327452

Epoch: 6| Step: 9
Training loss: 4.022705485594008
Validation loss: 3.271210484849944

Epoch: 6| Step: 10
Training loss: 2.8886897026579694
Validation loss: 3.263251429853163

Epoch: 6| Step: 11
Training loss: 3.5778561953394394
Validation loss: 3.274339533656564

Epoch: 6| Step: 12
Training loss: 2.8937722059019917
Validation loss: 3.3061323701583696

Epoch: 6| Step: 13
Training loss: 4.375437687369652
Validation loss: 3.259096709487581

Epoch: 13| Step: 0
Training loss: 3.195032382615919
Validation loss: 3.262404672005311

Epoch: 6| Step: 1
Training loss: 2.677797590827015
Validation loss: 3.281789713594847

Epoch: 6| Step: 2
Training loss: 3.87810318269825
Validation loss: 3.2829372289087484

Epoch: 6| Step: 3
Training loss: 2.8653425470591305
Validation loss: 3.2828481584217815

Epoch: 6| Step: 4
Training loss: 4.194598202838021
Validation loss: 3.2952365455705257

Epoch: 6| Step: 5
Training loss: 3.545779962433116
Validation loss: 3.277691511554611

Epoch: 6| Step: 6
Training loss: 3.5693713393849698
Validation loss: 3.270279266746865

Epoch: 6| Step: 7
Training loss: 4.208138237890863
Validation loss: 3.270018058537078

Epoch: 6| Step: 8
Training loss: 2.7165026090578874
Validation loss: 3.268255741939723

Epoch: 6| Step: 9
Training loss: 4.21899955859095
Validation loss: 3.2657077749573333

Epoch: 6| Step: 10
Training loss: 4.044451013380406
Validation loss: 3.2610031733190166

Epoch: 6| Step: 11
Training loss: 3.5863528873314605
Validation loss: 3.2606587895866603

Epoch: 6| Step: 12
Training loss: 2.9352637361894365
Validation loss: 3.2598028018228162

Epoch: 6| Step: 13
Training loss: 2.4852079518614456
Validation loss: 3.2641236821150263

Epoch: 14| Step: 0
Training loss: 3.5249998430833713
Validation loss: 3.264933950318341

Epoch: 6| Step: 1
Training loss: 3.301330881799867
Validation loss: 3.2688638999396167

Epoch: 6| Step: 2
Training loss: 3.8857262345739376
Validation loss: 3.256901138621457

Epoch: 6| Step: 3
Training loss: 3.5462382413005615
Validation loss: 3.24243314948844

Epoch: 6| Step: 4
Training loss: 3.3176523121047015
Validation loss: 3.2378681341457063

Epoch: 6| Step: 5
Training loss: 3.3317267042828185
Validation loss: 3.2326116587655043

Epoch: 6| Step: 6
Training loss: 3.891609404399251
Validation loss: 3.2303298559455307

Epoch: 6| Step: 7
Training loss: 3.3260663609952434
Validation loss: 3.225554592698593

Epoch: 6| Step: 8
Training loss: 3.679777431806418
Validation loss: 3.2227928353926654

Epoch: 6| Step: 9
Training loss: 3.8606421981015924
Validation loss: 3.222676635558385

Epoch: 6| Step: 10
Training loss: 3.825720082238642
Validation loss: 3.222430644710359

Epoch: 6| Step: 11
Training loss: 2.922542067486877
Validation loss: 3.2160014463830695

Epoch: 6| Step: 12
Training loss: 2.9927614622692444
Validation loss: 3.2157678294386245

Epoch: 6| Step: 13
Training loss: 2.9759615394096426
Validation loss: 3.213815612226579

Epoch: 15| Step: 0
Training loss: 3.077485768512262
Validation loss: 3.2052377139647272

Epoch: 6| Step: 1
Training loss: 4.036703044077488
Validation loss: 3.2048611997543777

Epoch: 6| Step: 2
Training loss: 2.776264909328942
Validation loss: 3.1957828727007374

Epoch: 6| Step: 3
Training loss: 2.38700083362707
Validation loss: 3.1788097148677585

Epoch: 6| Step: 4
Training loss: 3.946696123795079
Validation loss: 3.167898934651601

Epoch: 6| Step: 5
Training loss: 3.404104134317191
Validation loss: 3.1563408951335523

Epoch: 6| Step: 6
Training loss: 3.321454594476484
Validation loss: 3.157065272539785

Epoch: 6| Step: 7
Training loss: 3.7632192944349936
Validation loss: 3.147142716515131

Epoch: 6| Step: 8
Training loss: 3.919702178774312
Validation loss: 3.144083129609393

Epoch: 6| Step: 9
Training loss: 3.7357228931035045
Validation loss: 3.149657110305277

Epoch: 6| Step: 10
Training loss: 3.160678589306015
Validation loss: 3.1479551910320986

Epoch: 6| Step: 11
Training loss: 3.491567262192028
Validation loss: 3.1495963472634303

Epoch: 6| Step: 12
Training loss: 3.044256248906913
Validation loss: 3.13777922687921

Epoch: 6| Step: 13
Training loss: 3.5370023343653116
Validation loss: 3.139868922641027

Epoch: 16| Step: 0
Training loss: 3.1559392190647704
Validation loss: 3.141251629413574

Epoch: 6| Step: 1
Training loss: 3.2361925703355356
Validation loss: 3.1505522680553466

Epoch: 6| Step: 2
Training loss: 3.8894090092720064
Validation loss: 3.154703393863502

Epoch: 6| Step: 3
Training loss: 3.491755175018791
Validation loss: 3.1354786303217

Epoch: 6| Step: 4
Training loss: 3.396018805246216
Validation loss: 3.139069589709673

Epoch: 6| Step: 5
Training loss: 2.967064308634423
Validation loss: 3.1476370444494126

Epoch: 6| Step: 6
Training loss: 3.2970893392448306
Validation loss: 3.172040030514704

Epoch: 6| Step: 7
Training loss: 3.3300060991569316
Validation loss: 3.1898678392171047

Epoch: 6| Step: 8
Training loss: 4.291014291505255
Validation loss: 3.168505030317617

Epoch: 6| Step: 9
Training loss: 3.8383398671549416
Validation loss: 3.1578279593895258

Epoch: 6| Step: 10
Training loss: 2.905031830815166
Validation loss: 3.1363075344472255

Epoch: 6| Step: 11
Training loss: 2.8013110225078934
Validation loss: 3.1202181106368174

Epoch: 6| Step: 12
Training loss: 3.802052676281939
Validation loss: 3.1196235182616054

Epoch: 6| Step: 13
Training loss: 2.6524896370903743
Validation loss: 3.117811134605798

Epoch: 17| Step: 0
Training loss: 3.148294374606232
Validation loss: 3.1178904081744943

Epoch: 6| Step: 1
Training loss: 3.209803025806652
Validation loss: 3.1302740404679636

Epoch: 6| Step: 2
Training loss: 2.9226118984288507
Validation loss: 3.122047525925667

Epoch: 6| Step: 3
Training loss: 3.374876231997083
Validation loss: 3.114515371250264

Epoch: 6| Step: 4
Training loss: 3.012655426701125
Validation loss: 3.109193717959862

Epoch: 6| Step: 5
Training loss: 4.1748486611353695
Validation loss: 3.105951185386163

Epoch: 6| Step: 6
Training loss: 3.6660463212953016
Validation loss: 3.1105289347287606

Epoch: 6| Step: 7
Training loss: 3.2536859884278173
Validation loss: 3.104535094951155

Epoch: 6| Step: 8
Training loss: 3.679136976134506
Validation loss: 3.104994656349136

Epoch: 6| Step: 9
Training loss: 3.002137058755923
Validation loss: 3.10323529511494

Epoch: 6| Step: 10
Training loss: 3.2489678137615337
Validation loss: 3.103381594805634

Epoch: 6| Step: 11
Training loss: 4.137887877754445
Validation loss: 3.1068956649359416

Epoch: 6| Step: 12
Training loss: 2.9942044862828374
Validation loss: 3.1033756718083043

Epoch: 6| Step: 13
Training loss: 3.0358747616193433
Validation loss: 3.1028453302054837

Epoch: 18| Step: 0
Training loss: 3.724528463331959
Validation loss: 3.100264708609422

Epoch: 6| Step: 1
Training loss: 3.1447779588294233
Validation loss: 3.0992029791323534

Epoch: 6| Step: 2
Training loss: 3.1522342327243043
Validation loss: 3.0978674446843746

Epoch: 6| Step: 3
Training loss: 3.6857709548666047
Validation loss: 3.0989112779425017

Epoch: 6| Step: 4
Training loss: 3.115475904136145
Validation loss: 3.09843593436423

Epoch: 6| Step: 5
Training loss: 3.287641857263108
Validation loss: 3.098193897668651

Epoch: 6| Step: 6
Training loss: 3.7618870841100147
Validation loss: 3.0959901609788822

Epoch: 6| Step: 7
Training loss: 3.3258725276336674
Validation loss: 3.0965059711788063

Epoch: 6| Step: 8
Training loss: 3.266921958549355
Validation loss: 3.0968314021027923

Epoch: 6| Step: 9
Training loss: 3.167179183309181
Validation loss: 3.095008331512386

Epoch: 6| Step: 10
Training loss: 3.3048030751897595
Validation loss: 3.0894288335866134

Epoch: 6| Step: 11
Training loss: 3.0969228176886654
Validation loss: 3.088914328949632

Epoch: 6| Step: 12
Training loss: 2.431085803609012
Validation loss: 3.087725118748533

Epoch: 6| Step: 13
Training loss: 4.981768748842459
Validation loss: 3.08558749707227

Epoch: 19| Step: 0
Training loss: 2.571333754774433
Validation loss: 3.083893817843215

Epoch: 6| Step: 1
Training loss: 2.960169226989733
Validation loss: 3.0840093713528107

Epoch: 6| Step: 2
Training loss: 2.944842637525822
Validation loss: 3.083506994725307

Epoch: 6| Step: 3
Training loss: 3.730919168652355
Validation loss: 3.080200792147245

Epoch: 6| Step: 4
Training loss: 3.6277634183383007
Validation loss: 3.0787060625742995

Epoch: 6| Step: 5
Training loss: 3.3660991706586696
Validation loss: 3.078425681985785

Epoch: 6| Step: 6
Training loss: 3.834150531295147
Validation loss: 3.076765374067774

Epoch: 6| Step: 7
Training loss: 3.0904403091341677
Validation loss: 3.077371297945943

Epoch: 6| Step: 8
Training loss: 3.654316839411325
Validation loss: 3.0781906659784433

Epoch: 6| Step: 9
Training loss: 3.759462371089929
Validation loss: 3.0774414542832518

Epoch: 6| Step: 10
Training loss: 3.136713581389733
Validation loss: 3.0788745990772086

Epoch: 6| Step: 11
Training loss: 2.8995783532204893
Validation loss: 3.0781115992876784

Epoch: 6| Step: 12
Training loss: 3.378027794045477
Validation loss: 3.0767168382755625

Epoch: 6| Step: 13
Training loss: 4.057392137072715
Validation loss: 3.074453528456537

Epoch: 20| Step: 0
Training loss: 3.7937895871756906
Validation loss: 3.0738065993476025

Epoch: 6| Step: 1
Training loss: 2.690128371852068
Validation loss: 3.0734450152849577

Epoch: 6| Step: 2
Training loss: 3.190497391527954
Validation loss: 3.0701410827654363

Epoch: 6| Step: 3
Training loss: 3.3298319706035637
Validation loss: 3.062674014563936

Epoch: 6| Step: 4
Training loss: 3.1310587323947736
Validation loss: 3.0631421545812825

Epoch: 6| Step: 5
Training loss: 2.8815999776324452
Validation loss: 3.0635801423303253

Epoch: 6| Step: 6
Training loss: 3.0303654904141784
Validation loss: 3.0617807500932908

Epoch: 6| Step: 7
Training loss: 4.183459253936353
Validation loss: 3.060938551139068

Epoch: 6| Step: 8
Training loss: 2.5795812019984674
Validation loss: 3.06339977390883

Epoch: 6| Step: 9
Training loss: 3.0465122104727516
Validation loss: 3.0613980666223477

Epoch: 6| Step: 10
Training loss: 3.950207866559161
Validation loss: 3.057290639742807

Epoch: 6| Step: 11
Training loss: 3.5039168647937045
Validation loss: 3.055921324847182

Epoch: 6| Step: 12
Training loss: 3.696770475172344
Validation loss: 3.058383095643703

Epoch: 6| Step: 13
Training loss: 3.462344467030111
Validation loss: 3.0533919431967926

Epoch: 21| Step: 0
Training loss: 3.817747538297198
Validation loss: 3.0546856032987386

Epoch: 6| Step: 1
Training loss: 3.274820185959255
Validation loss: 3.0516640106551813

Epoch: 6| Step: 2
Training loss: 3.1211197222988503
Validation loss: 3.0488769256587154

Epoch: 6| Step: 3
Training loss: 2.896102746373773
Validation loss: 3.0507655560935105

Epoch: 6| Step: 4
Training loss: 3.0324121194230718
Validation loss: 3.04902306061659

Epoch: 6| Step: 5
Training loss: 2.99769312856029
Validation loss: 3.0477560287752787

Epoch: 6| Step: 6
Training loss: 3.2876495443351605
Validation loss: 3.0475604703739965

Epoch: 6| Step: 7
Training loss: 3.811337152962814
Validation loss: 3.0445631050379798

Epoch: 6| Step: 8
Training loss: 2.752829743053188
Validation loss: 3.042306074822593

Epoch: 6| Step: 9
Training loss: 2.8484555392967934
Validation loss: 3.0420102425345292

Epoch: 6| Step: 10
Training loss: 3.853191162927363
Validation loss: 3.0422711773941478

Epoch: 6| Step: 11
Training loss: 3.7006680993725807
Validation loss: 3.0434781904602093

Epoch: 6| Step: 12
Training loss: 3.6375003880241685
Validation loss: 3.0398526352800372

Epoch: 6| Step: 13
Training loss: 3.3034550237583287
Validation loss: 3.0389244714026913

Epoch: 22| Step: 0
Training loss: 3.9542641185868526
Validation loss: 3.037443641785585

Epoch: 6| Step: 1
Training loss: 3.40118115048049
Validation loss: 3.0369839636610627

Epoch: 6| Step: 2
Training loss: 3.5729001473952273
Validation loss: 3.037157539276192

Epoch: 6| Step: 3
Training loss: 3.4449187246183435
Validation loss: 3.0332606516391225

Epoch: 6| Step: 4
Training loss: 3.31448189807782
Validation loss: 3.0322262395324526

Epoch: 6| Step: 5
Training loss: 3.410026206981378
Validation loss: 3.0306538320251866

Epoch: 6| Step: 6
Training loss: 2.950095262444099
Validation loss: 3.0278094223770693

Epoch: 6| Step: 7
Training loss: 3.348908909996086
Validation loss: 3.0237757220245847

Epoch: 6| Step: 8
Training loss: 3.8123196418500562
Validation loss: 3.018745727610772

Epoch: 6| Step: 9
Training loss: 2.238327478593832
Validation loss: 3.0154667954727534

Epoch: 6| Step: 10
Training loss: 2.9838940297759597
Validation loss: 3.0111260693677586

Epoch: 6| Step: 11
Training loss: 3.535143840620485
Validation loss: 3.0106902167289133

Epoch: 6| Step: 12
Training loss: 2.939839182497116
Validation loss: 3.008451270216796

Epoch: 6| Step: 13
Training loss: 2.9727958014837372
Validation loss: 3.003247660041061

Epoch: 23| Step: 0
Training loss: 4.087749247286507
Validation loss: 3.0035107299402384

Epoch: 6| Step: 1
Training loss: 3.671789290056848
Validation loss: 3.0047441642564383

Epoch: 6| Step: 2
Training loss: 3.2297296012862
Validation loss: 3.0095616965394

Epoch: 6| Step: 3
Training loss: 3.2349373885968937
Validation loss: 3.010849913680449

Epoch: 6| Step: 4
Training loss: 2.512461693315139
Validation loss: 3.0246735708817916

Epoch: 6| Step: 5
Training loss: 2.9344360930204285
Validation loss: 3.0381488683107487

Epoch: 6| Step: 6
Training loss: 2.9145651376159445
Validation loss: 3.0592497436714368

Epoch: 6| Step: 7
Training loss: 2.4513339167678856
Validation loss: 3.0305615662358942

Epoch: 6| Step: 8
Training loss: 3.429760074064863
Validation loss: 2.9981807572893984

Epoch: 6| Step: 9
Training loss: 3.7898884610393404
Validation loss: 2.9973649977140684

Epoch: 6| Step: 10
Training loss: 2.865731932663573
Validation loss: 3.003966039398639

Epoch: 6| Step: 11
Training loss: 3.3647276352367914
Validation loss: 3.0203010834174475

Epoch: 6| Step: 12
Training loss: 4.146066221408516
Validation loss: 3.019070523335355

Epoch: 6| Step: 13
Training loss: 2.6684400999434263
Validation loss: 3.0006559553802457

Epoch: 24| Step: 0
Training loss: 3.6548790603020738
Validation loss: 3.020195716267294

Epoch: 6| Step: 1
Training loss: 3.6452220004571996
Validation loss: 2.9930861115532625

Epoch: 6| Step: 2
Training loss: 4.113705981751354
Validation loss: 2.99118313613021

Epoch: 6| Step: 3
Training loss: 3.1376820910377368
Validation loss: 2.99043356220501

Epoch: 6| Step: 4
Training loss: 2.9476199231005973
Validation loss: 3.0169889016110836

Epoch: 6| Step: 5
Training loss: 3.181192627634902
Validation loss: 3.0451972357696016

Epoch: 6| Step: 6
Training loss: 3.5096591090542653
Validation loss: 2.9877910274378396

Epoch: 6| Step: 7
Training loss: 3.767936282143575
Validation loss: 2.98969873445221

Epoch: 6| Step: 8
Training loss: 2.89422745854349
Validation loss: 2.9948401445671293

Epoch: 6| Step: 9
Training loss: 2.6832611011078944
Validation loss: 3.0050976744359863

Epoch: 6| Step: 10
Training loss: 2.505789918598505
Validation loss: 3.044916207056608

Epoch: 6| Step: 11
Training loss: 3.1600774842432107
Validation loss: 3.0630979642710994

Epoch: 6| Step: 12
Training loss: 2.6380838660906116
Validation loss: 3.036514892681767

Epoch: 6| Step: 13
Training loss: 4.264045394913475
Validation loss: 3.0201187635171585

Epoch: 25| Step: 0
Training loss: 3.4215709255057978
Validation loss: 2.997751825801278

Epoch: 6| Step: 1
Training loss: 3.2117416971176103
Validation loss: 2.986744294155732

Epoch: 6| Step: 2
Training loss: 3.0595291675536966
Validation loss: 2.984280812021101

Epoch: 6| Step: 3
Training loss: 3.164026180105973
Validation loss: 2.98620224991918

Epoch: 6| Step: 4
Training loss: 2.789758077271165
Validation loss: 2.9895348796681738

Epoch: 6| Step: 5
Training loss: 3.388372138671027
Validation loss: 2.99427130516946

Epoch: 6| Step: 6
Training loss: 3.0028167852251464
Validation loss: 2.982192099478968

Epoch: 6| Step: 7
Training loss: 3.07829013129794
Validation loss: 2.9767763883864946

Epoch: 6| Step: 8
Training loss: 3.4811682206963415
Validation loss: 2.9733790242214133

Epoch: 6| Step: 9
Training loss: 3.8465432043333054
Validation loss: 2.9739302373514755

Epoch: 6| Step: 10
Training loss: 3.455205368364266
Validation loss: 2.975838344409852

Epoch: 6| Step: 11
Training loss: 3.2951508121969275
Validation loss: 2.9741133492572396

Epoch: 6| Step: 12
Training loss: 3.6004684673253426
Validation loss: 2.9732555868460557

Epoch: 6| Step: 13
Training loss: 2.595224995202982
Validation loss: 2.971388545297632

Epoch: 26| Step: 0
Training loss: 2.9457144627380107
Validation loss: 2.9693312451056024

Epoch: 6| Step: 1
Training loss: 3.222448057905803
Validation loss: 2.9713406945315795

Epoch: 6| Step: 2
Training loss: 2.615897244923067
Validation loss: 2.981357771793105

Epoch: 6| Step: 3
Training loss: 3.4672420763875103
Validation loss: 3.0074615303580843

Epoch: 6| Step: 4
Training loss: 3.538723893630177
Validation loss: 2.9812330661735698

Epoch: 6| Step: 5
Training loss: 2.9910985494006317
Validation loss: 2.9715640191213124

Epoch: 6| Step: 6
Training loss: 3.083902736015693
Validation loss: 2.9662988566293627

Epoch: 6| Step: 7
Training loss: 2.699964229911936
Validation loss: 2.963442731014287

Epoch: 6| Step: 8
Training loss: 4.053595541035481
Validation loss: 2.964598208802244

Epoch: 6| Step: 9
Training loss: 3.5659516327851786
Validation loss: 2.964253546395673

Epoch: 6| Step: 10
Training loss: 2.8698908978502935
Validation loss: 2.964597497976457

Epoch: 6| Step: 11
Training loss: 3.5158208495794963
Validation loss: 2.965129440291351

Epoch: 6| Step: 12
Training loss: 3.681585968178506
Validation loss: 2.968576136249018

Epoch: 6| Step: 13
Training loss: 3.0346490738173832
Validation loss: 2.970600681273006

Epoch: 27| Step: 0
Training loss: 3.16828361856171
Validation loss: 2.963418493726805

Epoch: 6| Step: 1
Training loss: 3.2003665118133773
Validation loss: 2.960713611977964

Epoch: 6| Step: 2
Training loss: 3.494139669726323
Validation loss: 2.9610049276076986

Epoch: 6| Step: 3
Training loss: 3.5466870497593477
Validation loss: 2.958984910430259

Epoch: 6| Step: 4
Training loss: 3.0888917326818803
Validation loss: 2.958125958301259

Epoch: 6| Step: 5
Training loss: 3.0683248749850707
Validation loss: 2.956531628262576

Epoch: 6| Step: 6
Training loss: 2.7772979088714234
Validation loss: 2.9558335372251374

Epoch: 6| Step: 7
Training loss: 3.321124527312327
Validation loss: 2.9542680585467522

Epoch: 6| Step: 8
Training loss: 3.514123485777217
Validation loss: 2.953220313589799

Epoch: 6| Step: 9
Training loss: 2.629916627526987
Validation loss: 2.9523580353531096

Epoch: 6| Step: 10
Training loss: 3.8528572676334454
Validation loss: 2.9526409553956485

Epoch: 6| Step: 11
Training loss: 3.166962526119579
Validation loss: 2.953407626960507

Epoch: 6| Step: 12
Training loss: 3.49111478232969
Validation loss: 2.9537815558451523

Epoch: 6| Step: 13
Training loss: 2.838626480002036
Validation loss: 2.9553655946758632

Epoch: 28| Step: 0
Training loss: 3.102154192468533
Validation loss: 2.9600539749022436

Epoch: 6| Step: 1
Training loss: 3.198115306404934
Validation loss: 2.957776691617909

Epoch: 6| Step: 2
Training loss: 2.267281183453819
Validation loss: 2.968799604034946

Epoch: 6| Step: 3
Training loss: 3.734409475765938
Validation loss: 2.9709989016421146

Epoch: 6| Step: 4
Training loss: 3.0627609453162186
Validation loss: 2.950479162841291

Epoch: 6| Step: 5
Training loss: 3.2810613668807393
Validation loss: 2.9448871189493597

Epoch: 6| Step: 6
Training loss: 3.965893175272544
Validation loss: 2.945792997113983

Epoch: 6| Step: 7
Training loss: 3.2363726210542523
Validation loss: 2.9450260180898544

Epoch: 6| Step: 8
Training loss: 3.637240559872396
Validation loss: 2.952024316460857

Epoch: 6| Step: 9
Training loss: 3.118282269281132
Validation loss: 2.949689243412525

Epoch: 6| Step: 10
Training loss: 3.2592410242007275
Validation loss: 2.9470003580145034

Epoch: 6| Step: 11
Training loss: 3.18645160861811
Validation loss: 2.9442374036745496

Epoch: 6| Step: 12
Training loss: 3.2392361731923427
Validation loss: 2.9572382088188265

Epoch: 6| Step: 13
Training loss: 2.5776274229829776
Validation loss: 2.956106696069772

Epoch: 29| Step: 0
Training loss: 2.799432959360059
Validation loss: 2.9439189128714567

Epoch: 6| Step: 1
Training loss: 2.992835390549697
Validation loss: 2.9416117363026433

Epoch: 6| Step: 2
Training loss: 3.2899196350578475
Validation loss: 2.9393622212650063

Epoch: 6| Step: 3
Training loss: 3.667883208783558
Validation loss: 2.9388012330904916

Epoch: 6| Step: 4
Training loss: 3.171568757104673
Validation loss: 2.9392426548674666

Epoch: 6| Step: 5
Training loss: 3.436169175980285
Validation loss: 2.9369269680259373

Epoch: 6| Step: 6
Training loss: 3.431544884967467
Validation loss: 2.935402708166614

Epoch: 6| Step: 7
Training loss: 3.2735911767980523
Validation loss: 2.9346440486555276

Epoch: 6| Step: 8
Training loss: 3.5693066805828986
Validation loss: 2.935813002225285

Epoch: 6| Step: 9
Training loss: 2.969072344496346
Validation loss: 2.932706452343998

Epoch: 6| Step: 10
Training loss: 2.8650017080251984
Validation loss: 2.9333152854574904

Epoch: 6| Step: 11
Training loss: 3.174150224040348
Validation loss: 2.934769405302396

Epoch: 6| Step: 12
Training loss: 3.5648137660022714
Validation loss: 2.9328987811642064

Epoch: 6| Step: 13
Training loss: 2.7715652378751345
Validation loss: 2.9332407730028773

Epoch: 30| Step: 0
Training loss: 2.466861823669919
Validation loss: 2.92951607851425

Epoch: 6| Step: 1
Training loss: 3.711948746878206
Validation loss: 2.9320264573332375

Epoch: 6| Step: 2
Training loss: 3.2072049092750725
Validation loss: 2.9259438201405343

Epoch: 6| Step: 3
Training loss: 3.520302335586469
Validation loss: 2.9172312235539475

Epoch: 6| Step: 4
Training loss: 3.424391008796736
Validation loss: 2.91302491116499

Epoch: 6| Step: 5
Training loss: 3.3941425412603206
Validation loss: 2.909654154756256

Epoch: 6| Step: 6
Training loss: 3.45820292644442
Validation loss: 2.907036059623409

Epoch: 6| Step: 7
Training loss: 3.313985527472011
Validation loss: 2.919315109289662

Epoch: 6| Step: 8
Training loss: 2.3536128740281432
Validation loss: 2.919502247299017

Epoch: 6| Step: 9
Training loss: 3.445768088323104
Validation loss: 2.9064127682082277

Epoch: 6| Step: 10
Training loss: 3.414609118944753
Validation loss: 2.9068470356089695

Epoch: 6| Step: 11
Training loss: 2.955610894120924
Validation loss: 2.9027120733861023

Epoch: 6| Step: 12
Training loss: 3.141760018443288
Validation loss: 2.902099827016371

Epoch: 6| Step: 13
Training loss: 2.777469766282309
Validation loss: 2.901121789741128

Epoch: 31| Step: 0
Training loss: 3.241643579657421
Validation loss: 2.9017414676069944

Epoch: 6| Step: 1
Training loss: 3.160019842157962
Validation loss: 2.9035201874840286

Epoch: 6| Step: 2
Training loss: 2.925791680555506
Validation loss: 2.899833135998705

Epoch: 6| Step: 3
Training loss: 3.2065340091074193
Validation loss: 2.900052766528501

Epoch: 6| Step: 4
Training loss: 2.306024299473703
Validation loss: 2.8975871940936915

Epoch: 6| Step: 5
Training loss: 2.7667400461446814
Validation loss: 2.8952386525366514

Epoch: 6| Step: 6
Training loss: 3.948969651090879
Validation loss: 2.8924153015060305

Epoch: 6| Step: 7
Training loss: 3.1546917080674013
Validation loss: 2.890205442871093

Epoch: 6| Step: 8
Training loss: 3.351450386928758
Validation loss: 2.8896623715281744

Epoch: 6| Step: 9
Training loss: 2.86745424614932
Validation loss: 2.889771387498149

Epoch: 6| Step: 10
Training loss: 3.052123884294038
Validation loss: 2.889805490850482

Epoch: 6| Step: 11
Training loss: 3.2090815542764055
Validation loss: 2.8881704865204507

Epoch: 6| Step: 12
Training loss: 4.085394566132668
Validation loss: 2.8894702053636716

Epoch: 6| Step: 13
Training loss: 3.1722453986317998
Validation loss: 2.8892106072173744

Epoch: 32| Step: 0
Training loss: 3.1644118127973924
Validation loss: 2.891345804325018

Epoch: 6| Step: 1
Training loss: 3.493132802531711
Validation loss: 2.889960226584417

Epoch: 6| Step: 2
Training loss: 3.5639380513982144
Validation loss: 2.8852956825043155

Epoch: 6| Step: 3
Training loss: 3.409316616100411
Validation loss: 2.883303867876883

Epoch: 6| Step: 4
Training loss: 3.1531022493507628
Validation loss: 2.884239381002005

Epoch: 6| Step: 5
Training loss: 2.563809874164193
Validation loss: 2.8823125150930795

Epoch: 6| Step: 6
Training loss: 3.2721547820548786
Validation loss: 2.8808626373255857

Epoch: 6| Step: 7
Training loss: 3.515596788081248
Validation loss: 2.880410963185418

Epoch: 6| Step: 8
Training loss: 2.8953147991107473
Validation loss: 2.8781123175032133

Epoch: 6| Step: 9
Training loss: 3.1903509218448995
Validation loss: 2.877171289041466

Epoch: 6| Step: 10
Training loss: 3.321240679089292
Validation loss: 2.8779072536727655

Epoch: 6| Step: 11
Training loss: 2.5938376905945613
Validation loss: 2.877160072757144

Epoch: 6| Step: 12
Training loss: 3.276890065160183
Validation loss: 2.8765202818979483

Epoch: 6| Step: 13
Training loss: 3.0363608465145546
Validation loss: 2.877229182122591

Epoch: 33| Step: 0
Training loss: 3.570420678834994
Validation loss: 2.874285074472032

Epoch: 6| Step: 1
Training loss: 3.4151155781212252
Validation loss: 2.8726759555058488

Epoch: 6| Step: 2
Training loss: 3.5721855342306617
Validation loss: 2.8726114469141226

Epoch: 6| Step: 3
Training loss: 2.8597835394833986
Validation loss: 2.8742005688879746

Epoch: 6| Step: 4
Training loss: 2.6741035492334073
Validation loss: 2.874965169944421

Epoch: 6| Step: 5
Training loss: 3.5546693906217968
Validation loss: 2.890796661379416

Epoch: 6| Step: 6
Training loss: 3.4235180955433395
Validation loss: 2.8908091008948977

Epoch: 6| Step: 7
Training loss: 2.393355262818811
Validation loss: 2.876806286498872

Epoch: 6| Step: 8
Training loss: 2.884676033751823
Validation loss: 2.8811406609233994

Epoch: 6| Step: 9
Training loss: 3.4978473037709987
Validation loss: 2.8791972727432733

Epoch: 6| Step: 10
Training loss: 3.0457692805355276
Validation loss: 2.8664924803205194

Epoch: 6| Step: 11
Training loss: 3.0186546800305774
Validation loss: 2.865440469224209

Epoch: 6| Step: 12
Training loss: 2.9517158496736022
Validation loss: 2.866258576524401

Epoch: 6| Step: 13
Training loss: 3.6992601273507555
Validation loss: 2.8710068565168454

Epoch: 34| Step: 0
Training loss: 2.4612982591476795
Validation loss: 2.8723572260869377

Epoch: 6| Step: 1
Training loss: 3.9570054621105655
Validation loss: 2.871572566613193

Epoch: 6| Step: 2
Training loss: 3.054753685743976
Validation loss: 2.8650390841183992

Epoch: 6| Step: 3
Training loss: 3.7948496247706025
Validation loss: 2.862234039066753

Epoch: 6| Step: 4
Training loss: 2.3448859958550496
Validation loss: 2.8613826831763927

Epoch: 6| Step: 5
Training loss: 3.336578379049564
Validation loss: 2.8623596283088184

Epoch: 6| Step: 6
Training loss: 2.905051527764574
Validation loss: 2.859485242379237

Epoch: 6| Step: 7
Training loss: 2.7466257374994743
Validation loss: 2.8573075675512194

Epoch: 6| Step: 8
Training loss: 3.1577964997487857
Validation loss: 2.8603033608184703

Epoch: 6| Step: 9
Training loss: 3.6044280264287534
Validation loss: 2.8608522822430396

Epoch: 6| Step: 10
Training loss: 3.567647327356304
Validation loss: 2.8603253429653575

Epoch: 6| Step: 11
Training loss: 3.0938566555558054
Validation loss: 2.8554875714229833

Epoch: 6| Step: 12
Training loss: 3.1769745521474793
Validation loss: 2.8575911933201623

Epoch: 6| Step: 13
Training loss: 2.596032207171669
Validation loss: 2.865958696501659

Epoch: 35| Step: 0
Training loss: 2.86923635178973
Validation loss: 2.8709762516831194

Epoch: 6| Step: 1
Training loss: 2.646734449670067
Validation loss: 2.8804367916240117

Epoch: 6| Step: 2
Training loss: 3.91749747913428
Validation loss: 2.8748105786142526

Epoch: 6| Step: 3
Training loss: 2.5774328053962936
Validation loss: 2.869672327728047

Epoch: 6| Step: 4
Training loss: 2.296066764784593
Validation loss: 2.8816911395226152

Epoch: 6| Step: 5
Training loss: 3.60412241884681
Validation loss: 2.9450280507030744

Epoch: 6| Step: 6
Training loss: 3.5605024124692317
Validation loss: 2.9216584208767036

Epoch: 6| Step: 7
Training loss: 3.262872585492004
Validation loss: 2.8744045477351983

Epoch: 6| Step: 8
Training loss: 3.268106056518863
Validation loss: 2.8539309597809903

Epoch: 6| Step: 9
Training loss: 3.4825820757634287
Validation loss: 2.850428989681755

Epoch: 6| Step: 10
Training loss: 2.7308294360921006
Validation loss: 2.8498319460088495

Epoch: 6| Step: 11
Training loss: 3.214238681146352
Validation loss: 2.843136657828434

Epoch: 6| Step: 12
Training loss: 3.2107970121144267
Validation loss: 2.8486641415525393

Epoch: 6| Step: 13
Training loss: 3.7035983141280466
Validation loss: 2.8482017888606723

Epoch: 36| Step: 0
Training loss: 2.8159268165582994
Validation loss: 2.851940795780638

Epoch: 6| Step: 1
Training loss: 3.858463071505275
Validation loss: 2.8708901190325795

Epoch: 6| Step: 2
Training loss: 2.9584256189127283
Validation loss: 2.860061268180677

Epoch: 6| Step: 3
Training loss: 3.2044581174477926
Validation loss: 2.8569700125082367

Epoch: 6| Step: 4
Training loss: 3.3547624015530553
Validation loss: 2.8513310496818027

Epoch: 6| Step: 5
Training loss: 2.633506615486476
Validation loss: 2.849782666805411

Epoch: 6| Step: 6
Training loss: 1.8277840581681024
Validation loss: 2.8466882735425627

Epoch: 6| Step: 7
Training loss: 3.4862252698413045
Validation loss: 2.843889725461921

Epoch: 6| Step: 8
Training loss: 3.367996862015882
Validation loss: 2.8445660649511226

Epoch: 6| Step: 9
Training loss: 2.9316087450381874
Validation loss: 2.845545686238225

Epoch: 6| Step: 10
Training loss: 3.09770012111312
Validation loss: 2.843616509958338

Epoch: 6| Step: 11
Training loss: 2.9539813056617708
Validation loss: 2.8474581041393967

Epoch: 6| Step: 12
Training loss: 4.065344650841666
Validation loss: 2.8527277376271885

Epoch: 6| Step: 13
Training loss: 3.246377393171355
Validation loss: 2.8565563948854042

Epoch: 37| Step: 0
Training loss: 2.5782551125725695
Validation loss: 2.854617585689516

Epoch: 6| Step: 1
Training loss: 3.3688114082811804
Validation loss: 2.858320505630102

Epoch: 6| Step: 2
Training loss: 2.8829319213281286
Validation loss: 2.8399083655908473

Epoch: 6| Step: 3
Training loss: 3.0005538747025815
Validation loss: 2.840367916442721

Epoch: 6| Step: 4
Training loss: 3.388755318001824
Validation loss: 2.840601735616727

Epoch: 6| Step: 5
Training loss: 3.24699732648236
Validation loss: 2.8394110915200135

Epoch: 6| Step: 6
Training loss: 3.1082451842816954
Validation loss: 2.839808633195663

Epoch: 6| Step: 7
Training loss: 3.3201056920888266
Validation loss: 2.845364705045098

Epoch: 6| Step: 8
Training loss: 3.4618221900274153
Validation loss: 2.83805056784233

Epoch: 6| Step: 9
Training loss: 2.693022531935711
Validation loss: 2.8375937346761457

Epoch: 6| Step: 10
Training loss: 3.219512997163361
Validation loss: 2.8359812958532125

Epoch: 6| Step: 11
Training loss: 3.0545023596188288
Validation loss: 2.8349412617839165

Epoch: 6| Step: 12
Training loss: 3.7312931128587823
Validation loss: 2.835427001703792

Epoch: 6| Step: 13
Training loss: 2.942816286160554
Validation loss: 2.8326009998890926

Epoch: 38| Step: 0
Training loss: 2.980781508768319
Validation loss: 2.8319994020068022

Epoch: 6| Step: 1
Training loss: 3.5043817067851766
Validation loss: 2.8314017118123154

Epoch: 6| Step: 2
Training loss: 3.1092664230022145
Validation loss: 2.8317048531046005

Epoch: 6| Step: 3
Training loss: 2.9727027678891513
Validation loss: 2.827883980089062

Epoch: 6| Step: 4
Training loss: 3.2141412127272133
Validation loss: 2.827833909544985

Epoch: 6| Step: 5
Training loss: 3.0454376743009792
Validation loss: 2.824451931905798

Epoch: 6| Step: 6
Training loss: 3.2894598569077447
Validation loss: 2.8259634503822215

Epoch: 6| Step: 7
Training loss: 2.653190556267803
Validation loss: 2.8256960409292633

Epoch: 6| Step: 8
Training loss: 3.1479537251426755
Validation loss: 2.823077130344171

Epoch: 6| Step: 9
Training loss: 2.9866969477730603
Validation loss: 2.823888654864443

Epoch: 6| Step: 10
Training loss: 3.4605116054702427
Validation loss: 2.8241069403198686

Epoch: 6| Step: 11
Training loss: 3.5735964707616112
Validation loss: 2.823888823722781

Epoch: 6| Step: 12
Training loss: 3.109335587601583
Validation loss: 2.8231006673293715

Epoch: 6| Step: 13
Training loss: 2.77728915261473
Validation loss: 2.8210215498312747

Epoch: 39| Step: 0
Training loss: 3.1531660668956785
Validation loss: 2.8201269396032225

Epoch: 6| Step: 1
Training loss: 3.1006005474557363
Validation loss: 2.819925114766019

Epoch: 6| Step: 2
Training loss: 2.876115831199275
Validation loss: 2.8189751943309753

Epoch: 6| Step: 3
Training loss: 2.86359465212258
Validation loss: 2.8178117259348827

Epoch: 6| Step: 4
Training loss: 2.704347719813531
Validation loss: 2.8188947783722353

Epoch: 6| Step: 5
Training loss: 3.0030097169213947
Validation loss: 2.8186550829349946

Epoch: 6| Step: 6
Training loss: 3.2130509078560534
Validation loss: 2.815021941973889

Epoch: 6| Step: 7
Training loss: 3.62274415430065
Validation loss: 2.814568332175416

Epoch: 6| Step: 8
Training loss: 3.3768445378634104
Validation loss: 2.8159538655429

Epoch: 6| Step: 9
Training loss: 2.817757334021618
Validation loss: 2.8164830697062477

Epoch: 6| Step: 10
Training loss: 3.051325125576207
Validation loss: 2.8245125483875615

Epoch: 6| Step: 11
Training loss: 3.9247006879260398
Validation loss: 2.828634366350487

Epoch: 6| Step: 12
Training loss: 3.1517864429530156
Validation loss: 2.827418237490123

Epoch: 6| Step: 13
Training loss: 2.736052167701849
Validation loss: 2.813846623979281

Epoch: 40| Step: 0
Training loss: 3.4715331313563023
Validation loss: 2.811782536664987

Epoch: 6| Step: 1
Training loss: 2.821317794722161
Validation loss: 2.814685205970336

Epoch: 6| Step: 2
Training loss: 3.6176451688056432
Validation loss: 2.814240577651715

Epoch: 6| Step: 3
Training loss: 3.5990783995250415
Validation loss: 2.8158229799476664

Epoch: 6| Step: 4
Training loss: 3.026079940334996
Validation loss: 2.8161264390671197

Epoch: 6| Step: 5
Training loss: 3.716069385336574
Validation loss: 2.8106982531795484

Epoch: 6| Step: 6
Training loss: 2.09967160154882
Validation loss: 2.8117375369203756

Epoch: 6| Step: 7
Training loss: 3.287898711767559
Validation loss: 2.811788771199487

Epoch: 6| Step: 8
Training loss: 2.41349524095381
Validation loss: 2.8104628993822165

Epoch: 6| Step: 9
Training loss: 3.5260949781135693
Validation loss: 2.812200305608371

Epoch: 6| Step: 10
Training loss: 2.821544599992801
Validation loss: 2.8091567482965782

Epoch: 6| Step: 11
Training loss: 3.471796570861167
Validation loss: 2.8105598329745627

Epoch: 6| Step: 12
Training loss: 2.576488738568578
Validation loss: 2.8065874890504117

Epoch: 6| Step: 13
Training loss: 2.7839992522260606
Validation loss: 2.805628784698484

Epoch: 41| Step: 0
Training loss: 3.097059695128266
Validation loss: 2.8087236645155476

Epoch: 6| Step: 1
Training loss: 3.0038379914424493
Validation loss: 2.808666644931122

Epoch: 6| Step: 2
Training loss: 3.0014106295051897
Validation loss: 2.810650943927687

Epoch: 6| Step: 3
Training loss: 3.9804161599890104
Validation loss: 2.8139942133186655

Epoch: 6| Step: 4
Training loss: 2.9756784002187335
Validation loss: 2.8112798872242704

Epoch: 6| Step: 5
Training loss: 2.95420664198443
Validation loss: 2.8127383132290413

Epoch: 6| Step: 6
Training loss: 2.7131063706453307
Validation loss: 2.8081543924904357

Epoch: 6| Step: 7
Training loss: 2.2698281072661968
Validation loss: 2.8082194003737238

Epoch: 6| Step: 8
Training loss: 3.0662384570433625
Validation loss: 2.8070037515774473

Epoch: 6| Step: 9
Training loss: 2.720519093179193
Validation loss: 2.804594429302967

Epoch: 6| Step: 10
Training loss: 3.6057184366414328
Validation loss: 2.803799874513963

Epoch: 6| Step: 11
Training loss: 3.8011342714876477
Validation loss: 2.8039186865687236

Epoch: 6| Step: 12
Training loss: 2.7624342448836514
Validation loss: 2.8032797531870663

Epoch: 6| Step: 13
Training loss: 3.795570180727287
Validation loss: 2.801849312156506

Epoch: 42| Step: 0
Training loss: 2.995628350628277
Validation loss: 2.8024915263763295

Epoch: 6| Step: 1
Training loss: 2.3828678312287352
Validation loss: 2.802514947184673

Epoch: 6| Step: 2
Training loss: 2.5829564916924315
Validation loss: 2.799150361852771

Epoch: 6| Step: 3
Training loss: 2.9884752796485223
Validation loss: 2.8023471277336545

Epoch: 6| Step: 4
Training loss: 3.4859924667723474
Validation loss: 2.799124201911297

Epoch: 6| Step: 5
Training loss: 3.1410388578958273
Validation loss: 2.796034525721824

Epoch: 6| Step: 6
Training loss: 2.808184046036437
Validation loss: 2.801782007129775

Epoch: 6| Step: 7
Training loss: 3.2187132601817035
Validation loss: 2.8010101629845754

Epoch: 6| Step: 8
Training loss: 3.8349987365243114
Validation loss: 2.819789914073119

Epoch: 6| Step: 9
Training loss: 2.842589424491421
Validation loss: 2.828509671543386

Epoch: 6| Step: 10
Training loss: 3.431067812448213
Validation loss: 2.801941913171556

Epoch: 6| Step: 11
Training loss: 2.5288975463000902
Validation loss: 2.811359793313613

Epoch: 6| Step: 12
Training loss: 3.5888804740400313
Validation loss: 2.801347271659721

Epoch: 6| Step: 13
Training loss: 3.7858057242401455
Validation loss: 2.7978865883444164

Epoch: 43| Step: 0
Training loss: 3.010232165181526
Validation loss: 2.7997407680039395

Epoch: 6| Step: 1
Training loss: 2.9329955282193474
Validation loss: 2.7918344250449136

Epoch: 6| Step: 2
Training loss: 3.2439048539024498
Validation loss: 2.7887159765177807

Epoch: 6| Step: 3
Training loss: 2.8340032196995786
Validation loss: 2.790711347950957

Epoch: 6| Step: 4
Training loss: 2.2826646572858813
Validation loss: 2.7908409898332547

Epoch: 6| Step: 5
Training loss: 3.1805891028739945
Validation loss: 2.790274329932762

Epoch: 6| Step: 6
Training loss: 3.1439209908611483
Validation loss: 2.7916577583456146

Epoch: 6| Step: 7
Training loss: 3.146072597541491
Validation loss: 2.7911227083069203

Epoch: 6| Step: 8
Training loss: 2.473464809515169
Validation loss: 2.7898195495731137

Epoch: 6| Step: 9
Training loss: 3.4646367610100466
Validation loss: 2.7923948697015315

Epoch: 6| Step: 10
Training loss: 3.3576431423415856
Validation loss: 2.790363873447633

Epoch: 6| Step: 11
Training loss: 3.5258913144277755
Validation loss: 2.7915772791219298

Epoch: 6| Step: 12
Training loss: 3.69562153401076
Validation loss: 2.788682458977784

Epoch: 6| Step: 13
Training loss: 3.0565584116839064
Validation loss: 2.790458060962447

Epoch: 44| Step: 0
Training loss: 2.9059490745372174
Validation loss: 2.7862564217700974

Epoch: 6| Step: 1
Training loss: 2.90461471655215
Validation loss: 2.7898533107484753

Epoch: 6| Step: 2
Training loss: 2.855450046963372
Validation loss: 2.7872728848732904

Epoch: 6| Step: 3
Training loss: 3.3590541952564448
Validation loss: 2.786928797327269

Epoch: 6| Step: 4
Training loss: 3.1677060847393075
Validation loss: 2.785257887802594

Epoch: 6| Step: 5
Training loss: 2.9975778020158517
Validation loss: 2.7840366955028277

Epoch: 6| Step: 6
Training loss: 3.2194927062384315
Validation loss: 2.7821971142064013

Epoch: 6| Step: 7
Training loss: 2.998842651920331
Validation loss: 2.782761779921009

Epoch: 6| Step: 8
Training loss: 3.7132635596504233
Validation loss: 2.7815835330373258

Epoch: 6| Step: 9
Training loss: 2.858041754735918
Validation loss: 2.7835109121544632

Epoch: 6| Step: 10
Training loss: 2.895008948646643
Validation loss: 2.780457037366704

Epoch: 6| Step: 11
Training loss: 3.4609789705913396
Validation loss: 2.779371164601506

Epoch: 6| Step: 12
Training loss: 3.3601030847085873
Validation loss: 2.7842491011964956

Epoch: 6| Step: 13
Training loss: 2.3235397757599445
Validation loss: 2.784003039672035

Epoch: 45| Step: 0
Training loss: 3.0962652905378842
Validation loss: 2.7828308743097825

Epoch: 6| Step: 1
Training loss: 2.6654764936788493
Validation loss: 2.7773894685307305

Epoch: 6| Step: 2
Training loss: 3.3485537809188695
Validation loss: 2.778007923012716

Epoch: 6| Step: 3
Training loss: 3.0893992648058317
Validation loss: 2.7759197343543214

Epoch: 6| Step: 4
Training loss: 3.449608025881573
Validation loss: 2.774531827569427

Epoch: 6| Step: 5
Training loss: 2.9171149499715736
Validation loss: 2.7760245205234013

Epoch: 6| Step: 6
Training loss: 2.9800287524378763
Validation loss: 2.7755082110076654

Epoch: 6| Step: 7
Training loss: 3.029303171334527
Validation loss: 2.777512798659931

Epoch: 6| Step: 8
Training loss: 3.167159159326056
Validation loss: 2.780218358218632

Epoch: 6| Step: 9
Training loss: 2.7720562141300227
Validation loss: 2.782098045164321

Epoch: 6| Step: 10
Training loss: 3.0376575821553327
Validation loss: 2.7784035138550887

Epoch: 6| Step: 11
Training loss: 3.476297775648051
Validation loss: 2.7798010026651685

Epoch: 6| Step: 12
Training loss: 3.2671385547505483
Validation loss: 2.7776505915602905

Epoch: 6| Step: 13
Training loss: 3.245169644616267
Validation loss: 2.777287086776583

Epoch: 46| Step: 0
Training loss: 2.5783523921677234
Validation loss: 2.7761424481401322

Epoch: 6| Step: 1
Training loss: 3.596248388518767
Validation loss: 2.775828594460677

Epoch: 6| Step: 2
Training loss: 3.6363565856691844
Validation loss: 2.7718017237333874

Epoch: 6| Step: 3
Training loss: 2.8260915622227114
Validation loss: 2.771198354753971

Epoch: 6| Step: 4
Training loss: 3.0126283610368594
Validation loss: 2.7706251902787797

Epoch: 6| Step: 5
Training loss: 2.7906665623764018
Validation loss: 2.771307515543588

Epoch: 6| Step: 6
Training loss: 2.820747236311841
Validation loss: 2.7709842751490243

Epoch: 6| Step: 7
Training loss: 2.925051996795948
Validation loss: 2.770539059873507

Epoch: 6| Step: 8
Training loss: 2.801356045146869
Validation loss: 2.773775052031411

Epoch: 6| Step: 9
Training loss: 2.8962673895671505
Validation loss: 2.7714666860471904

Epoch: 6| Step: 10
Training loss: 3.307433662470137
Validation loss: 2.7710921297520468

Epoch: 6| Step: 11
Training loss: 3.1056652846614945
Validation loss: 2.7676897674199297

Epoch: 6| Step: 12
Training loss: 3.5905575047881393
Validation loss: 2.7645473272726817

Epoch: 6| Step: 13
Training loss: 3.522962584704808
Validation loss: 2.766937301394894

Epoch: 47| Step: 0
Training loss: 3.1139073143250475
Validation loss: 2.76373496550852

Epoch: 6| Step: 1
Training loss: 3.127218450837391
Validation loss: 2.763996754304155

Epoch: 6| Step: 2
Training loss: 3.150498844187079
Validation loss: 2.764812478278822

Epoch: 6| Step: 3
Training loss: 3.1983061479768513
Validation loss: 2.7645201416073615

Epoch: 6| Step: 4
Training loss: 3.3245925424208176
Validation loss: 2.7623983416906723

Epoch: 6| Step: 5
Training loss: 2.61369195057256
Validation loss: 2.7595046063023343

Epoch: 6| Step: 6
Training loss: 3.310864890698938
Validation loss: 2.7613203520184677

Epoch: 6| Step: 7
Training loss: 3.3763509801503324
Validation loss: 2.758771870151433

Epoch: 6| Step: 8
Training loss: 2.76090661265308
Validation loss: 2.7603158596126653

Epoch: 6| Step: 9
Training loss: 2.815527579160117
Validation loss: 2.7761432423107024

Epoch: 6| Step: 10
Training loss: 3.498621124041911
Validation loss: 2.782773794937612

Epoch: 6| Step: 11
Training loss: 2.838512586158854
Validation loss: 2.7831143763262527

Epoch: 6| Step: 12
Training loss: 3.138723224630512
Validation loss: 2.789376932547672

Epoch: 6| Step: 13
Training loss: 2.6729949031885423
Validation loss: 2.7609615869256774

Epoch: 48| Step: 0
Training loss: 3.3148775025716506
Validation loss: 2.7562861875695326

Epoch: 6| Step: 1
Training loss: 3.2790057545547735
Validation loss: 2.7554362467375277

Epoch: 6| Step: 2
Training loss: 2.9919278901228257
Validation loss: 2.757035071573223

Epoch: 6| Step: 3
Training loss: 2.942869919023015
Validation loss: 2.757686073509941

Epoch: 6| Step: 4
Training loss: 2.745457452064
Validation loss: 2.759548699194759

Epoch: 6| Step: 5
Training loss: 2.5925198131013856
Validation loss: 2.7586511712910555

Epoch: 6| Step: 6
Training loss: 3.214193285264068
Validation loss: 2.7600861602078286

Epoch: 6| Step: 7
Training loss: 2.6638580870303348
Validation loss: 2.7621247699655003

Epoch: 6| Step: 8
Training loss: 3.637592411506008
Validation loss: 2.764879886770382

Epoch: 6| Step: 9
Training loss: 3.4551002066140053
Validation loss: 2.7604210012861983

Epoch: 6| Step: 10
Training loss: 2.5377188076146253
Validation loss: 2.7605368298786703

Epoch: 6| Step: 11
Training loss: 3.152682261390161
Validation loss: 2.761670365910305

Epoch: 6| Step: 12
Training loss: 2.9301438446669223
Validation loss: 2.7600479210927022

Epoch: 6| Step: 13
Training loss: 3.92784654939892
Validation loss: 2.756825320567343

Epoch: 49| Step: 0
Training loss: 3.1857411636987965
Validation loss: 2.756379658001633

Epoch: 6| Step: 1
Training loss: 3.3420956520988923
Validation loss: 2.7534295815675094

Epoch: 6| Step: 2
Training loss: 3.6693303807527653
Validation loss: 2.7532754355230735

Epoch: 6| Step: 3
Training loss: 3.6431323409648706
Validation loss: 2.7536892294218185

Epoch: 6| Step: 4
Training loss: 2.7492158812247482
Validation loss: 2.7509427370441615

Epoch: 6| Step: 5
Training loss: 3.3189430195054017
Validation loss: 2.7516417007827734

Epoch: 6| Step: 6
Training loss: 2.6261699430818046
Validation loss: 2.748745948365353

Epoch: 6| Step: 7
Training loss: 2.0944661296438043
Validation loss: 2.747964954357005

Epoch: 6| Step: 8
Training loss: 3.3256887195879785
Validation loss: 2.748617426916733

Epoch: 6| Step: 9
Training loss: 2.9895771482893245
Validation loss: 2.763245148360169

Epoch: 6| Step: 10
Training loss: 2.5477553642245674
Validation loss: 2.7614219118330094

Epoch: 6| Step: 11
Training loss: 2.8734083330790976
Validation loss: 2.764215300922393

Epoch: 6| Step: 12
Training loss: 3.183717465483458
Validation loss: 2.7797358669348333

Epoch: 6| Step: 13
Training loss: 3.29896688762327
Validation loss: 2.784643908518623

Epoch: 50| Step: 0
Training loss: 3.1089070797123615
Validation loss: 2.758483201855924

Epoch: 6| Step: 1
Training loss: 3.2399237025661125
Validation loss: 2.745810278838789

Epoch: 6| Step: 2
Training loss: 3.086811801335286
Validation loss: 2.743278272220234

Epoch: 6| Step: 3
Training loss: 3.2397232434315684
Validation loss: 2.7425363297334755

Epoch: 6| Step: 4
Training loss: 3.505231217663426
Validation loss: 2.741713021535413

Epoch: 6| Step: 5
Training loss: 3.1496503968981484
Validation loss: 2.7405844336699654

Epoch: 6| Step: 6
Training loss: 3.5968777521489117
Validation loss: 2.741788019054906

Epoch: 6| Step: 7
Training loss: 2.8875754276348804
Validation loss: 2.7410399165442905

Epoch: 6| Step: 8
Training loss: 2.9828621589919133
Validation loss: 2.739947724591809

Epoch: 6| Step: 9
Training loss: 2.289644030760602
Validation loss: 2.739343111350385

Epoch: 6| Step: 10
Training loss: 3.09669246809291
Validation loss: 2.737268643883855

Epoch: 6| Step: 11
Training loss: 2.366458793250753
Validation loss: 2.7386799113497764

Epoch: 6| Step: 12
Training loss: 3.0124415854967665
Validation loss: 2.738114924077601

Epoch: 6| Step: 13
Training loss: 3.325425176755774
Validation loss: 2.7376592130086443

Epoch: 51| Step: 0
Training loss: 2.89084306873813
Validation loss: 2.735304679278009

Epoch: 6| Step: 1
Training loss: 2.76051608692326
Validation loss: 2.7330243076342278

Epoch: 6| Step: 2
Training loss: 3.4142951798749595
Validation loss: 2.7399159346570046

Epoch: 6| Step: 3
Training loss: 3.221157025796611
Validation loss: 2.7481297353972063

Epoch: 6| Step: 4
Training loss: 3.34665617810717
Validation loss: 2.7457862576471985

Epoch: 6| Step: 5
Training loss: 2.6238398940274053
Validation loss: 2.7441654771007817

Epoch: 6| Step: 6
Training loss: 2.524011221937814
Validation loss: 2.7422136019736567

Epoch: 6| Step: 7
Training loss: 3.1986061040570677
Validation loss: 2.74050267349559

Epoch: 6| Step: 8
Training loss: 2.9098576949413815
Validation loss: 2.7376413808820006

Epoch: 6| Step: 9
Training loss: 3.1783171379051467
Validation loss: 2.7459280550761926

Epoch: 6| Step: 10
Training loss: 2.9124949639403717
Validation loss: 2.7553464864698336

Epoch: 6| Step: 11
Training loss: 3.7119951206701374
Validation loss: 2.7458647869681987

Epoch: 6| Step: 12
Training loss: 2.959107329077058
Validation loss: 2.7391479650321022

Epoch: 6| Step: 13
Training loss: 3.187711970443118
Validation loss: 2.736038050108053

Epoch: 52| Step: 0
Training loss: 2.833799286469685
Validation loss: 2.7308259973487514

Epoch: 6| Step: 1
Training loss: 3.560144281356747
Validation loss: 2.7322949914354258

Epoch: 6| Step: 2
Training loss: 3.420630659882491
Validation loss: 2.7294595121810103

Epoch: 6| Step: 3
Training loss: 3.3722296753629397
Validation loss: 2.7276436564744047

Epoch: 6| Step: 4
Training loss: 2.489862104527186
Validation loss: 2.729431423811375

Epoch: 6| Step: 5
Training loss: 3.583838818995909
Validation loss: 2.7309991589341536

Epoch: 6| Step: 6
Training loss: 2.5772681459621944
Validation loss: 2.728611282228127

Epoch: 6| Step: 7
Training loss: 2.6954152847815642
Validation loss: 2.7317730474576956

Epoch: 6| Step: 8
Training loss: 3.114588827853422
Validation loss: 2.726361140673889

Epoch: 6| Step: 9
Training loss: 3.283443480707932
Validation loss: 2.730969365709926

Epoch: 6| Step: 10
Training loss: 2.7410096684772105
Validation loss: 2.7286373458948994

Epoch: 6| Step: 11
Training loss: 2.6974241968345387
Validation loss: 2.7286238260036635

Epoch: 6| Step: 12
Training loss: 3.2595100645497137
Validation loss: 2.7325201734830507

Epoch: 6| Step: 13
Training loss: 3.0349724319940483
Validation loss: 2.74269453966341

Epoch: 53| Step: 0
Training loss: 3.017390865700626
Validation loss: 2.7446423272193434

Epoch: 6| Step: 1
Training loss: 3.3391443780723686
Validation loss: 2.7411834951449885

Epoch: 6| Step: 2
Training loss: 3.208564568315603
Validation loss: 2.7454077822335217

Epoch: 6| Step: 3
Training loss: 2.8559569895094246
Validation loss: 2.743156789774994

Epoch: 6| Step: 4
Training loss: 3.2023021106195184
Validation loss: 2.7529048912376983

Epoch: 6| Step: 5
Training loss: 3.277738454191315
Validation loss: 2.745758320423343

Epoch: 6| Step: 6
Training loss: 3.031276427478226
Validation loss: 2.7409616072119936

Epoch: 6| Step: 7
Training loss: 3.3650034040912793
Validation loss: 2.741268437148032

Epoch: 6| Step: 8
Training loss: 3.28489090690447
Validation loss: 2.731968317534503

Epoch: 6| Step: 9
Training loss: 2.623820630304634
Validation loss: 2.7229809850088684

Epoch: 6| Step: 10
Training loss: 3.2498620810955314
Validation loss: 2.7220053904186474

Epoch: 6| Step: 11
Training loss: 3.4009607528400556
Validation loss: 2.717576683326928

Epoch: 6| Step: 12
Training loss: 2.1403405216280302
Validation loss: 2.722088393682532

Epoch: 6| Step: 13
Training loss: 2.0283492283236177
Validation loss: 2.7190662238319137

Epoch: 54| Step: 0
Training loss: 3.052038893305588
Validation loss: 2.7151676235328255

Epoch: 6| Step: 1
Training loss: 2.9929529709924054
Validation loss: 2.7188942964889575

Epoch: 6| Step: 2
Training loss: 3.268100657982487
Validation loss: 2.7160816499857683

Epoch: 6| Step: 3
Training loss: 2.708779215177636
Validation loss: 2.7156458469712534

Epoch: 6| Step: 4
Training loss: 3.0625725562395165
Validation loss: 2.71818749107566

Epoch: 6| Step: 5
Training loss: 2.848004187741576
Validation loss: 2.717322366395558

Epoch: 6| Step: 6
Training loss: 3.586300368222902
Validation loss: 2.71699767877753

Epoch: 6| Step: 7
Training loss: 3.28024741705034
Validation loss: 2.7162823046627422

Epoch: 6| Step: 8
Training loss: 2.859458546903158
Validation loss: 2.7163435691813884

Epoch: 6| Step: 9
Training loss: 2.4113871245996688
Validation loss: 2.717215907067787

Epoch: 6| Step: 10
Training loss: 2.781149187296854
Validation loss: 2.7173329772860026

Epoch: 6| Step: 11
Training loss: 3.5491922346061333
Validation loss: 2.715399801847383

Epoch: 6| Step: 12
Training loss: 2.8984019644890364
Validation loss: 2.710695620073322

Epoch: 6| Step: 13
Training loss: 3.2967668126872924
Validation loss: 2.7127480787899736

Epoch: 55| Step: 0
Training loss: 3.03435113899443
Validation loss: 2.721366815802079

Epoch: 6| Step: 1
Training loss: 3.616201575357514
Validation loss: 2.7494694579288588

Epoch: 6| Step: 2
Training loss: 3.3735362516846714
Validation loss: 2.784241517761156

Epoch: 6| Step: 3
Training loss: 2.7326745549714975
Validation loss: 2.787680983971361

Epoch: 6| Step: 4
Training loss: 3.349650515645674
Validation loss: 2.7466855103901366

Epoch: 6| Step: 5
Training loss: 2.7464639297525175
Validation loss: 2.7304809528728162

Epoch: 6| Step: 6
Training loss: 3.2407488101273443
Validation loss: 2.7157338750369955

Epoch: 6| Step: 7
Training loss: 2.5873147575670266
Validation loss: 2.7109161477298467

Epoch: 6| Step: 8
Training loss: 3.6684491997641184
Validation loss: 2.7155809349588576

Epoch: 6| Step: 9
Training loss: 3.4461928992233193
Validation loss: 2.714346168017395

Epoch: 6| Step: 10
Training loss: 2.5146002725969834
Validation loss: 2.713201291782628

Epoch: 6| Step: 11
Training loss: 2.7415172485944383
Validation loss: 2.710259999058235

Epoch: 6| Step: 12
Training loss: 2.7074455175439356
Validation loss: 2.7112380972242853

Epoch: 6| Step: 13
Training loss: 2.1980161478631337
Validation loss: 2.7112865794785055

Epoch: 56| Step: 0
Training loss: 2.236899063991344
Validation loss: 2.7129623767534627

Epoch: 6| Step: 1
Training loss: 3.3979764077466075
Validation loss: 2.7186022265590863

Epoch: 6| Step: 2
Training loss: 3.1932381236537104
Validation loss: 2.721614324081967

Epoch: 6| Step: 3
Training loss: 3.3107884141697848
Validation loss: 2.72536360933999

Epoch: 6| Step: 4
Training loss: 2.998366546984081
Validation loss: 2.7303201253918217

Epoch: 6| Step: 5
Training loss: 2.8997748649288186
Validation loss: 2.746626790349902

Epoch: 6| Step: 6
Training loss: 3.606816693873977
Validation loss: 2.768914109396114

Epoch: 6| Step: 7
Training loss: 2.5908987160677253
Validation loss: 2.739161715626871

Epoch: 6| Step: 8
Training loss: 3.1120075985342583
Validation loss: 2.7267961844730957

Epoch: 6| Step: 9
Training loss: 2.757504886404984
Validation loss: 2.733782625738754

Epoch: 6| Step: 10
Training loss: 3.0499214787615974
Validation loss: 2.7146185503482445

Epoch: 6| Step: 11
Training loss: 2.867755220424585
Validation loss: 2.708449133739327

Epoch: 6| Step: 12
Training loss: 3.1291179228201917
Validation loss: 2.700392708424883

Epoch: 6| Step: 13
Training loss: 3.395882463782383
Validation loss: 2.7019716840049877

Epoch: 57| Step: 0
Training loss: 3.3900783115670245
Validation loss: 2.699750808859626

Epoch: 6| Step: 1
Training loss: 3.2673725033835215
Validation loss: 2.7015926445115865

Epoch: 6| Step: 2
Training loss: 2.6139276500516595
Validation loss: 2.7019836721126955

Epoch: 6| Step: 3
Training loss: 2.8994280415522726
Validation loss: 2.700440441745861

Epoch: 6| Step: 4
Training loss: 2.6674801559210644
Validation loss: 2.70262175738521

Epoch: 6| Step: 5
Training loss: 3.00229175769775
Validation loss: 2.703174282148483

Epoch: 6| Step: 6
Training loss: 2.9245976293569234
Validation loss: 2.7032807055351533

Epoch: 6| Step: 7
Training loss: 3.0720244238399124
Validation loss: 2.712459310951628

Epoch: 6| Step: 8
Training loss: 2.7064596786497637
Validation loss: 2.71442821076058

Epoch: 6| Step: 9
Training loss: 3.593346083788877
Validation loss: 2.7247756512672128

Epoch: 6| Step: 10
Training loss: 2.6646930921515346
Validation loss: 2.7256404268274905

Epoch: 6| Step: 11
Training loss: 3.185725597090254
Validation loss: 2.723817581728102

Epoch: 6| Step: 12
Training loss: 3.364312947434642
Validation loss: 2.7181115914927387

Epoch: 6| Step: 13
Training loss: 3.017637539868147
Validation loss: 2.7035883527065314

Epoch: 58| Step: 0
Training loss: 2.3862610922905803
Validation loss: 2.6987192123746726

Epoch: 6| Step: 1
Training loss: 3.1331342498624495
Validation loss: 2.6952482881962707

Epoch: 6| Step: 2
Training loss: 3.1935714044670567
Validation loss: 2.695608135724606

Epoch: 6| Step: 3
Training loss: 2.5641861927015097
Validation loss: 2.6991596431822082

Epoch: 6| Step: 4
Training loss: 3.0428968232533506
Validation loss: 2.708310725557107

Epoch: 6| Step: 5
Training loss: 3.2287429203394455
Validation loss: 2.728237282861004

Epoch: 6| Step: 6
Training loss: 3.070554767397879
Validation loss: 2.7795830552341334

Epoch: 6| Step: 7
Training loss: 3.1655797264122825
Validation loss: 2.826049755786644

Epoch: 6| Step: 8
Training loss: 3.5116580537805966
Validation loss: 2.7627829447674936

Epoch: 6| Step: 9
Training loss: 2.9416085587796923
Validation loss: 2.6967282066024616

Epoch: 6| Step: 10
Training loss: 3.1245267891226063
Validation loss: 2.690402706735956

Epoch: 6| Step: 11
Training loss: 2.8536559898742038
Validation loss: 2.7076601565937906

Epoch: 6| Step: 12
Training loss: 3.318027706534128
Validation loss: 2.792775330836841

Epoch: 6| Step: 13
Training loss: 3.343686539947966
Validation loss: 2.8640234836222382

Epoch: 59| Step: 0
Training loss: 2.741734741741711
Validation loss: 2.765870304212112

Epoch: 6| Step: 1
Training loss: 3.4135898289073237
Validation loss: 2.726400364727742

Epoch: 6| Step: 2
Training loss: 2.4873668002403644
Validation loss: 2.7131329111402964

Epoch: 6| Step: 3
Training loss: 3.4369857403412487
Validation loss: 2.7418055927954694

Epoch: 6| Step: 4
Training loss: 3.3703997307578777
Validation loss: 2.9003744275797563

Epoch: 6| Step: 5
Training loss: 3.2516007516014236
Validation loss: 3.03059303971568

Epoch: 6| Step: 6
Training loss: 3.4924011847812424
Validation loss: 3.0241492980126052

Epoch: 6| Step: 7
Training loss: 2.531565046131383
Validation loss: 2.892666794407043

Epoch: 6| Step: 8
Training loss: 2.560250760552407
Validation loss: 2.802942504678356

Epoch: 6| Step: 9
Training loss: 3.3680118693416694
Validation loss: 2.7635843803829356

Epoch: 6| Step: 10
Training loss: 3.2647676209361944
Validation loss: 2.7131767683423824

Epoch: 6| Step: 11
Training loss: 2.9361598427524997
Validation loss: 2.7190375595012184

Epoch: 6| Step: 12
Training loss: 2.86684205679369
Validation loss: 2.7512312945125634

Epoch: 6| Step: 13
Training loss: 3.5048039029672395
Validation loss: 2.7692209796011156

Epoch: 60| Step: 0
Training loss: 2.8025670443570934
Validation loss: 2.770470649976356

Epoch: 6| Step: 1
Training loss: 2.9469483383615955
Validation loss: 2.758650479884729

Epoch: 6| Step: 2
Training loss: 3.423188536595681
Validation loss: 2.7230470866779344

Epoch: 6| Step: 3
Training loss: 3.4212319801979376
Validation loss: 2.70179111019686

Epoch: 6| Step: 4
Training loss: 2.783248697543561
Validation loss: 2.685961139427009

Epoch: 6| Step: 5
Training loss: 2.9685444007754036
Validation loss: 2.682971474822414

Epoch: 6| Step: 6
Training loss: 3.72167533127533
Validation loss: 2.683007907707009

Epoch: 6| Step: 7
Training loss: 2.651029595508086
Validation loss: 2.684868128883374

Epoch: 6| Step: 8
Training loss: 2.8555585896648643
Validation loss: 2.6879689093000674

Epoch: 6| Step: 9
Training loss: 2.7258579688347235
Validation loss: 2.6933190805588456

Epoch: 6| Step: 10
Training loss: 2.665032979106285
Validation loss: 2.6986259069522283

Epoch: 6| Step: 11
Training loss: 3.219820011392208
Validation loss: 2.6977657206680377

Epoch: 6| Step: 12
Training loss: 2.763994415117465
Validation loss: 2.727978714980634

Epoch: 6| Step: 13
Training loss: 3.468858459426623
Validation loss: 2.677067452360438

Epoch: 61| Step: 0
Training loss: 3.4290989259971636
Validation loss: 2.673201798542945

Epoch: 6| Step: 1
Training loss: 3.4435220854122846
Validation loss: 2.685163307698019

Epoch: 6| Step: 2
Training loss: 3.7351378615340995
Validation loss: 2.701800918618039

Epoch: 6| Step: 3
Training loss: 3.490924786131428
Validation loss: 2.701011296501245

Epoch: 6| Step: 4
Training loss: 2.892884726956301
Validation loss: 2.7027447905113897

Epoch: 6| Step: 5
Training loss: 3.092383188741451
Validation loss: 2.691042645384484

Epoch: 6| Step: 6
Training loss: 1.8186467616613107
Validation loss: 2.6860434898689522

Epoch: 6| Step: 7
Training loss: 3.303072343043874
Validation loss: 2.682088960673487

Epoch: 6| Step: 8
Training loss: 2.5764020306531097
Validation loss: 2.680505590433476

Epoch: 6| Step: 9
Training loss: 2.939104007506941
Validation loss: 2.6791475076560833

Epoch: 6| Step: 10
Training loss: 2.8084479069944077
Validation loss: 2.6763978108110136

Epoch: 6| Step: 11
Training loss: 2.503577152709761
Validation loss: 2.6807777991970623

Epoch: 6| Step: 12
Training loss: 2.8512109827217564
Validation loss: 2.6828731420717085

Epoch: 6| Step: 13
Training loss: 3.2719029582959607
Validation loss: 2.6845700326985207

Epoch: 62| Step: 0
Training loss: 2.8677841521989613
Validation loss: 2.6782002146787023

Epoch: 6| Step: 1
Training loss: 3.4085769404596404
Validation loss: 2.6752837995719907

Epoch: 6| Step: 2
Training loss: 2.916519233973723
Validation loss: 2.6738581733210998

Epoch: 6| Step: 3
Training loss: 2.9490450978470544
Validation loss: 2.668317805327135

Epoch: 6| Step: 4
Training loss: 3.5163342925978758
Validation loss: 2.6681337538109937

Epoch: 6| Step: 5
Training loss: 2.2908190344508434
Validation loss: 2.666916988016726

Epoch: 6| Step: 6
Training loss: 2.7885938405592485
Validation loss: 2.665003200193474

Epoch: 6| Step: 7
Training loss: 3.2231944981380116
Validation loss: 2.6677928425698823

Epoch: 6| Step: 8
Training loss: 3.031763406908387
Validation loss: 2.6647884534676014

Epoch: 6| Step: 9
Training loss: 2.893104273552283
Validation loss: 2.6654557832773897

Epoch: 6| Step: 10
Training loss: 2.263090623511805
Validation loss: 2.66764916373756

Epoch: 6| Step: 11
Training loss: 3.0938528024566785
Validation loss: 2.665208302063915

Epoch: 6| Step: 12
Training loss: 3.3780989371537387
Validation loss: 2.666237178051081

Epoch: 6| Step: 13
Training loss: 3.524521620735117
Validation loss: 2.6694968145571463

Epoch: 63| Step: 0
Training loss: 3.273940309496568
Validation loss: 2.6797404744866746

Epoch: 6| Step: 1
Training loss: 2.839002901920288
Validation loss: 2.689459929076092

Epoch: 6| Step: 2
Training loss: 3.31449599679477
Validation loss: 2.736413510958052

Epoch: 6| Step: 3
Training loss: 3.382937669090168
Validation loss: 2.784123095263692

Epoch: 6| Step: 4
Training loss: 3.515293766948125
Validation loss: 2.822864702876582

Epoch: 6| Step: 5
Training loss: 3.5371460430871315
Validation loss: 2.7001300375967654

Epoch: 6| Step: 6
Training loss: 3.026693636092073
Validation loss: 2.662566224816679

Epoch: 6| Step: 7
Training loss: 3.0696060882245515
Validation loss: 2.662087832356562

Epoch: 6| Step: 8
Training loss: 2.605933655492287
Validation loss: 2.6701107239064643

Epoch: 6| Step: 9
Training loss: 2.6327207645542265
Validation loss: 2.675538719472771

Epoch: 6| Step: 10
Training loss: 2.8118044522964434
Validation loss: 2.693053853982331

Epoch: 6| Step: 11
Training loss: 2.7542182475082155
Validation loss: 2.7070680077847724

Epoch: 6| Step: 12
Training loss: 2.6453911018748557
Validation loss: 2.7292306819404026

Epoch: 6| Step: 13
Training loss: 2.8290595939349097
Validation loss: 2.737122813414484

Epoch: 64| Step: 0
Training loss: 3.0125620412175844
Validation loss: 2.7218763428740744

Epoch: 6| Step: 1
Training loss: 3.0222878648448233
Validation loss: 2.690359331124507

Epoch: 6| Step: 2
Training loss: 3.0401825789786687
Validation loss: 2.6824722135291843

Epoch: 6| Step: 3
Training loss: 3.027528031185551
Validation loss: 2.6713326549046355

Epoch: 6| Step: 4
Training loss: 2.544040155381755
Validation loss: 2.667566969108209

Epoch: 6| Step: 5
Training loss: 2.843716799364056
Validation loss: 2.6636121195540468

Epoch: 6| Step: 6
Training loss: 3.0906731303819153
Validation loss: 2.66117225475496

Epoch: 6| Step: 7
Training loss: 2.7973809663676654
Validation loss: 2.660619070033624

Epoch: 6| Step: 8
Training loss: 3.139311710413083
Validation loss: 2.6594509056806035

Epoch: 6| Step: 9
Training loss: 2.600826858207695
Validation loss: 2.6607059278689107

Epoch: 6| Step: 10
Training loss: 3.6145004277610973
Validation loss: 2.660511175250641

Epoch: 6| Step: 11
Training loss: 3.192793097726907
Validation loss: 2.6659966833358335

Epoch: 6| Step: 12
Training loss: 3.2814659410900764
Validation loss: 2.672652539156305

Epoch: 6| Step: 13
Training loss: 2.750429033277526
Validation loss: 2.6845920261518113

Epoch: 65| Step: 0
Training loss: 3.717386717106064
Validation loss: 2.7127931877486717

Epoch: 6| Step: 1
Training loss: 2.405962840198395
Validation loss: 2.763475421964547

Epoch: 6| Step: 2
Training loss: 3.1017346850819827
Validation loss: 2.78697500620644

Epoch: 6| Step: 3
Training loss: 2.2232890376416337
Validation loss: 2.695397707231516

Epoch: 6| Step: 4
Training loss: 2.9780836648864444
Validation loss: 2.659557711817927

Epoch: 6| Step: 5
Training loss: 3.2709074234720865
Validation loss: 2.6528768790614587

Epoch: 6| Step: 6
Training loss: 3.0264656614646093
Validation loss: 2.6538042538872837

Epoch: 6| Step: 7
Training loss: 2.666673203301366
Validation loss: 2.6623627446212565

Epoch: 6| Step: 8
Training loss: 2.899986983960637
Validation loss: 2.6641531562482497

Epoch: 6| Step: 9
Training loss: 2.6219562868014146
Validation loss: 2.6723652435299905

Epoch: 6| Step: 10
Training loss: 3.226664617737469
Validation loss: 2.69002152819607

Epoch: 6| Step: 11
Training loss: 3.4592123791137017
Validation loss: 2.714086688578673

Epoch: 6| Step: 12
Training loss: 3.5615897103187555
Validation loss: 2.6849845270908084

Epoch: 6| Step: 13
Training loss: 2.912747574790552
Validation loss: 2.6794064803543574

Epoch: 66| Step: 0
Training loss: 3.059527453168926
Validation loss: 2.6740173537989973

Epoch: 6| Step: 1
Training loss: 3.3586348317045807
Validation loss: 2.670142487540055

Epoch: 6| Step: 2
Training loss: 3.304305394945571
Validation loss: 2.665172771486837

Epoch: 6| Step: 3
Training loss: 3.2428238209812354
Validation loss: 2.659920231239674

Epoch: 6| Step: 4
Training loss: 2.287455961710283
Validation loss: 2.658258146871902

Epoch: 6| Step: 5
Training loss: 2.779206972149244
Validation loss: 2.656320946148306

Epoch: 6| Step: 6
Training loss: 2.6521635148802316
Validation loss: 2.6586078320257998

Epoch: 6| Step: 7
Training loss: 2.812199555350105
Validation loss: 2.6552754544083825

Epoch: 6| Step: 8
Training loss: 2.5623438717800027
Validation loss: 2.654824758475388

Epoch: 6| Step: 9
Training loss: 3.2487977078183374
Validation loss: 2.6552620089672248

Epoch: 6| Step: 10
Training loss: 3.4318666942734217
Validation loss: 2.6501073620695257

Epoch: 6| Step: 11
Training loss: 3.470910851268176
Validation loss: 2.655639883351111

Epoch: 6| Step: 12
Training loss: 2.5140902179259297
Validation loss: 2.6532845512290413

Epoch: 6| Step: 13
Training loss: 3.3218094626391657
Validation loss: 2.6602127242428986

Epoch: 67| Step: 0
Training loss: 3.3213365837988866
Validation loss: 2.6691905224731567

Epoch: 6| Step: 1
Training loss: 3.046112904240159
Validation loss: 2.666349608629561

Epoch: 6| Step: 2
Training loss: 2.8361564110369883
Validation loss: 2.679761375839886

Epoch: 6| Step: 3
Training loss: 2.7440545228095616
Validation loss: 2.665412740367886

Epoch: 6| Step: 4
Training loss: 2.8796413937467267
Validation loss: 2.6589421170181136

Epoch: 6| Step: 5
Training loss: 3.142935742596766
Validation loss: 2.6720733194775392

Epoch: 6| Step: 6
Training loss: 3.3208422428970445
Validation loss: 2.6754346957996664

Epoch: 6| Step: 7
Training loss: 2.402878517239192
Validation loss: 2.6686651867053905

Epoch: 6| Step: 8
Training loss: 2.84425902788839
Validation loss: 2.660830611046896

Epoch: 6| Step: 9
Training loss: 3.214766324154976
Validation loss: 2.6546670249239126

Epoch: 6| Step: 10
Training loss: 3.363921739155518
Validation loss: 2.6539695510333594

Epoch: 6| Step: 11
Training loss: 2.8554473750909968
Validation loss: 2.6477347406629272

Epoch: 6| Step: 12
Training loss: 3.166297857658544
Validation loss: 2.6502959189694133

Epoch: 6| Step: 13
Training loss: 2.3749075419850127
Validation loss: 2.647354507118086

Epoch: 68| Step: 0
Training loss: 3.210209153631363
Validation loss: 2.6387663191211854

Epoch: 6| Step: 1
Training loss: 2.2928275433655543
Validation loss: 2.6476752378209363

Epoch: 6| Step: 2
Training loss: 2.583771873495955
Validation loss: 2.6428559115768824

Epoch: 6| Step: 3
Training loss: 3.2698503381853516
Validation loss: 2.6432066935811367

Epoch: 6| Step: 4
Training loss: 2.8656227769083866
Validation loss: 2.6513259850954087

Epoch: 6| Step: 5
Training loss: 3.2491933848699612
Validation loss: 2.647097570331572

Epoch: 6| Step: 6
Training loss: 3.5397762564086688
Validation loss: 2.6551330930236543

Epoch: 6| Step: 7
Training loss: 3.0231294696830813
Validation loss: 2.641508597890511

Epoch: 6| Step: 8
Training loss: 2.3929204952743626
Validation loss: 2.6415077884755354

Epoch: 6| Step: 9
Training loss: 3.476483221971791
Validation loss: 2.6398425830469128

Epoch: 6| Step: 10
Training loss: 3.3713599461274586
Validation loss: 2.6334079008213505

Epoch: 6| Step: 11
Training loss: 2.9658051993770354
Validation loss: 2.6319836012498374

Epoch: 6| Step: 12
Training loss: 2.5998557967764255
Validation loss: 2.640262171805783

Epoch: 6| Step: 13
Training loss: 2.244592314067762
Validation loss: 2.6286500729996582

Epoch: 69| Step: 0
Training loss: 2.9253582922439585
Validation loss: 2.637440467422706

Epoch: 6| Step: 1
Training loss: 2.962556823958093
Validation loss: 2.636025723464605

Epoch: 6| Step: 2
Training loss: 2.646872268909545
Validation loss: 2.649579411960946

Epoch: 6| Step: 3
Training loss: 2.9560329107535335
Validation loss: 2.6484032612765778

Epoch: 6| Step: 4
Training loss: 2.8506463238186837
Validation loss: 2.6548399665077063

Epoch: 6| Step: 5
Training loss: 2.6548213931710496
Validation loss: 2.6640997929065318

Epoch: 6| Step: 6
Training loss: 3.1262878815904176
Validation loss: 2.6787073926116496

Epoch: 6| Step: 7
Training loss: 2.9633225470033
Validation loss: 2.6750137343316207

Epoch: 6| Step: 8
Training loss: 2.7806502134826685
Validation loss: 2.6617715909407074

Epoch: 6| Step: 9
Training loss: 2.727379181980574
Validation loss: 2.646824739565473

Epoch: 6| Step: 10
Training loss: 3.2933828652346944
Validation loss: 2.6284222968842954

Epoch: 6| Step: 11
Training loss: 3.1747076605828726
Validation loss: 2.6298205271412307

Epoch: 6| Step: 12
Training loss: 3.2304181206828373
Validation loss: 2.632873826560107

Epoch: 6| Step: 13
Training loss: 3.6737752988709365
Validation loss: 2.6416070447767854

Epoch: 70| Step: 0
Training loss: 3.010231056343224
Validation loss: 2.647246077516991

Epoch: 6| Step: 1
Training loss: 2.5274250660097586
Validation loss: 2.6481175993114188

Epoch: 6| Step: 2
Training loss: 2.822071319543993
Validation loss: 2.648454666142562

Epoch: 6| Step: 3
Training loss: 3.2491779755008023
Validation loss: 2.6464665577019337

Epoch: 6| Step: 4
Training loss: 3.284609283018278
Validation loss: 2.6488151642803794

Epoch: 6| Step: 5
Training loss: 2.7484830660618433
Validation loss: 2.642785255832122

Epoch: 6| Step: 6
Training loss: 3.0741080006059724
Validation loss: 2.63881017167783

Epoch: 6| Step: 7
Training loss: 3.4230404615314933
Validation loss: 2.639301109680197

Epoch: 6| Step: 8
Training loss: 3.039987300796085
Validation loss: 2.639622193459073

Epoch: 6| Step: 9
Training loss: 3.6697694625998474
Validation loss: 2.638845386876975

Epoch: 6| Step: 10
Training loss: 2.165050074678805
Validation loss: 2.6379329217815095

Epoch: 6| Step: 11
Training loss: 2.811333817198889
Validation loss: 2.636145596027761

Epoch: 6| Step: 12
Training loss: 2.9139620275281515
Validation loss: 2.636951559066945

Epoch: 6| Step: 13
Training loss: 3.0806256510911294
Validation loss: 2.638267653662466

Epoch: 71| Step: 0
Training loss: 3.091608712886181
Validation loss: 2.637596853741003

Epoch: 6| Step: 1
Training loss: 2.8941579312859873
Validation loss: 2.635876303036435

Epoch: 6| Step: 2
Training loss: 2.9391786364780392
Validation loss: 2.6367440409417795

Epoch: 6| Step: 3
Training loss: 2.8785343835793817
Validation loss: 2.6335565637770246

Epoch: 6| Step: 4
Training loss: 3.0781425049569675
Validation loss: 2.6317405579142585

Epoch: 6| Step: 5
Training loss: 2.9286653490324794
Validation loss: 2.6375575872060826

Epoch: 6| Step: 6
Training loss: 3.45740295825628
Validation loss: 2.631140822975758

Epoch: 6| Step: 7
Training loss: 2.6027032224258453
Validation loss: 2.627817652579441

Epoch: 6| Step: 8
Training loss: 2.3318176682907854
Validation loss: 2.6274167151140633

Epoch: 6| Step: 9
Training loss: 3.3293115354360867
Validation loss: 2.6299928196534883

Epoch: 6| Step: 10
Training loss: 3.4157455101986
Validation loss: 2.627405551801197

Epoch: 6| Step: 11
Training loss: 2.7746478811022532
Validation loss: 2.6279168747758432

Epoch: 6| Step: 12
Training loss: 3.1142973157184137
Validation loss: 2.6303233105799633

Epoch: 6| Step: 13
Training loss: 2.847050857555982
Validation loss: 2.6500211682734713

Epoch: 72| Step: 0
Training loss: 2.847569510102987
Validation loss: 2.6567942371228503

Epoch: 6| Step: 1
Training loss: 2.573251452782181
Validation loss: 2.6586990271813633

Epoch: 6| Step: 2
Training loss: 2.9929988547901902
Validation loss: 2.6593972802489585

Epoch: 6| Step: 3
Training loss: 3.1496237514981016
Validation loss: 2.652715113750369

Epoch: 6| Step: 4
Training loss: 2.8763590378631916
Validation loss: 2.6514524774984323

Epoch: 6| Step: 5
Training loss: 3.0501828748565813
Validation loss: 2.6540626268522076

Epoch: 6| Step: 6
Training loss: 2.977329105370209
Validation loss: 2.658684943362956

Epoch: 6| Step: 7
Training loss: 3.546668496191179
Validation loss: 2.6612860986297586

Epoch: 6| Step: 8
Training loss: 2.7570882824311487
Validation loss: 2.654182249846956

Epoch: 6| Step: 9
Training loss: 3.132081058188935
Validation loss: 2.6563369176977503

Epoch: 6| Step: 10
Training loss: 3.1383099730100494
Validation loss: 2.6512320347980274

Epoch: 6| Step: 11
Training loss: 3.1334249226055295
Validation loss: 2.6495682181763667

Epoch: 6| Step: 12
Training loss: 2.610043742664679
Validation loss: 2.652927468620408

Epoch: 6| Step: 13
Training loss: 3.083400948960148
Validation loss: 2.6565510438676294

Epoch: 73| Step: 0
Training loss: 3.0313291244404907
Validation loss: 2.670722410104947

Epoch: 6| Step: 1
Training loss: 3.2649596782256673
Validation loss: 2.673634026186868

Epoch: 6| Step: 2
Training loss: 2.009220327354006
Validation loss: 2.6718704664000823

Epoch: 6| Step: 3
Training loss: 3.4869684395353264
Validation loss: 2.6697885258095417

Epoch: 6| Step: 4
Training loss: 3.061875260137581
Validation loss: 2.6606438639976324

Epoch: 6| Step: 5
Training loss: 3.483603353544875
Validation loss: 2.651030209575774

Epoch: 6| Step: 6
Training loss: 3.3304304993643377
Validation loss: 2.650781558552002

Epoch: 6| Step: 7
Training loss: 3.348611879992536
Validation loss: 2.647492546813099

Epoch: 6| Step: 8
Training loss: 3.291813585567826
Validation loss: 2.6490505887169906

Epoch: 6| Step: 9
Training loss: 2.722666495480409
Validation loss: 2.6461289663518914

Epoch: 6| Step: 10
Training loss: 1.5566179568220895
Validation loss: 2.647154633072099

Epoch: 6| Step: 11
Training loss: 2.4763314413112316
Validation loss: 2.6489076711580832

Epoch: 6| Step: 12
Training loss: 3.2454050299760353
Validation loss: 2.6594687487732784

Epoch: 6| Step: 13
Training loss: 2.7654149034946744
Validation loss: 2.657096109383391

Epoch: 74| Step: 0
Training loss: 3.2342663438025334
Validation loss: 2.6585687774609417

Epoch: 6| Step: 1
Training loss: 2.4895786514131797
Validation loss: 2.659802304848316

Epoch: 6| Step: 2
Training loss: 2.685570667508242
Validation loss: 2.6654364654147273

Epoch: 6| Step: 3
Training loss: 3.383664065828045
Validation loss: 2.680723462364835

Epoch: 6| Step: 4
Training loss: 3.0127268092458097
Validation loss: 2.6681272691167197

Epoch: 6| Step: 5
Training loss: 3.3677009491977667
Validation loss: 2.6704795353376074

Epoch: 6| Step: 6
Training loss: 2.444915641780379
Validation loss: 2.6676086496016467

Epoch: 6| Step: 7
Training loss: 2.7531973717797373
Validation loss: 2.6478763186267806

Epoch: 6| Step: 8
Training loss: 2.701727356963457
Validation loss: 2.640590394932803

Epoch: 6| Step: 9
Training loss: 3.3332605989785926
Validation loss: 2.6371117511434483

Epoch: 6| Step: 10
Training loss: 3.3295969685384432
Validation loss: 2.6356515588005136

Epoch: 6| Step: 11
Training loss: 3.0225396609800286
Validation loss: 2.637004825290699

Epoch: 6| Step: 12
Training loss: 2.840956772837601
Validation loss: 2.6359916716992777

Epoch: 6| Step: 13
Training loss: 2.84338410088078
Validation loss: 2.6375866491052715

Epoch: 75| Step: 0
Training loss: 3.5569291309399595
Validation loss: 2.6405566146528336

Epoch: 6| Step: 1
Training loss: 3.347603262233797
Validation loss: 2.6463411531947933

Epoch: 6| Step: 2
Training loss: 3.3967008516227977
Validation loss: 2.6331501717405787

Epoch: 6| Step: 3
Training loss: 3.0881909604990914
Validation loss: 2.6333066979719217

Epoch: 6| Step: 4
Training loss: 2.85449135225997
Validation loss: 2.6350578878742064

Epoch: 6| Step: 5
Training loss: 2.594594059763673
Validation loss: 2.633462516909906

Epoch: 6| Step: 6
Training loss: 2.66890046814457
Validation loss: 2.637130780706513

Epoch: 6| Step: 7
Training loss: 3.2062898213254147
Validation loss: 2.6329493323531126

Epoch: 6| Step: 8
Training loss: 2.9133028160027394
Validation loss: 2.642652193281128

Epoch: 6| Step: 9
Training loss: 2.780313055401344
Validation loss: 2.637694299754501

Epoch: 6| Step: 10
Training loss: 2.6986760036824653
Validation loss: 2.6458431906141455

Epoch: 6| Step: 11
Training loss: 2.5857414793648474
Validation loss: 2.654091085916557

Epoch: 6| Step: 12
Training loss: 2.8716523956930184
Validation loss: 2.6669193835129574

Epoch: 6| Step: 13
Training loss: 3.0317703272409458
Validation loss: 2.674422558805482

Epoch: 76| Step: 0
Training loss: 3.1233532953862735
Validation loss: 2.674249948938985

Epoch: 6| Step: 1
Training loss: 2.8313293850108256
Validation loss: 2.6408826597081396

Epoch: 6| Step: 2
Training loss: 2.9023366853568966
Validation loss: 2.630913544111863

Epoch: 6| Step: 3
Training loss: 3.3487569808744806
Validation loss: 2.633435170554095

Epoch: 6| Step: 4
Training loss: 2.768486137819782
Validation loss: 2.6321103920542988

Epoch: 6| Step: 5
Training loss: 2.149068178028207
Validation loss: 2.6335730170096086

Epoch: 6| Step: 6
Training loss: 2.376101790395932
Validation loss: 2.6313369572924503

Epoch: 6| Step: 7
Training loss: 3.0380231555912625
Validation loss: 2.633548007120941

Epoch: 6| Step: 8
Training loss: 3.1704538854335422
Validation loss: 2.629885615082254

Epoch: 6| Step: 9
Training loss: 3.117933752847548
Validation loss: 2.6344090061384153

Epoch: 6| Step: 10
Training loss: 3.0092205764588282
Validation loss: 2.6338509094473417

Epoch: 6| Step: 11
Training loss: 3.1164546860464157
Validation loss: 2.63216488604862

Epoch: 6| Step: 12
Training loss: 3.4765568765316175
Validation loss: 2.630532107086076

Epoch: 6| Step: 13
Training loss: 3.3303710808639453
Validation loss: 2.633380442917442

Epoch: 77| Step: 0
Training loss: 2.866579412270916
Validation loss: 2.631071740961739

Epoch: 6| Step: 1
Training loss: 2.3331534339036675
Validation loss: 2.6320195837555573

Epoch: 6| Step: 2
Training loss: 2.8358651984800325
Validation loss: 2.6298381218761433

Epoch: 6| Step: 3
Training loss: 3.4667025185222786
Validation loss: 2.6275521922490017

Epoch: 6| Step: 4
Training loss: 3.59618500853343
Validation loss: 2.631448976334139

Epoch: 6| Step: 5
Training loss: 3.1877481700553005
Validation loss: 2.629442040755571

Epoch: 6| Step: 6
Training loss: 3.013181338682615
Validation loss: 2.638531502502827

Epoch: 6| Step: 7
Training loss: 2.681138071422698
Validation loss: 2.632508841301086

Epoch: 6| Step: 8
Training loss: 3.05770529830528
Validation loss: 2.6328489677713023

Epoch: 6| Step: 9
Training loss: 3.01968853184326
Validation loss: 2.6302564010849525

Epoch: 6| Step: 10
Training loss: 2.9414399690962374
Validation loss: 2.638228504001601

Epoch: 6| Step: 11
Training loss: 3.1232282575141954
Validation loss: 2.6336517968012316

Epoch: 6| Step: 12
Training loss: 2.318254476486355
Validation loss: 2.635501240726151

Epoch: 6| Step: 13
Training loss: 2.729619801494646
Validation loss: 2.6550854749967874

Epoch: 78| Step: 0
Training loss: 2.94236093456644
Validation loss: 2.659710360031973

Epoch: 6| Step: 1
Training loss: 2.7934936883765302
Validation loss: 2.6637780096524257

Epoch: 6| Step: 2
Training loss: 3.1586445704543804
Validation loss: 2.6751893116547367

Epoch: 6| Step: 3
Training loss: 2.956750007266213
Validation loss: 2.6785556906332038

Epoch: 6| Step: 4
Training loss: 3.0828212793982153
Validation loss: 2.6709338755932817

Epoch: 6| Step: 5
Training loss: 3.130612330884196
Validation loss: 2.689793894829704

Epoch: 6| Step: 6
Training loss: 2.763571801412531
Validation loss: 2.6606204151496775

Epoch: 6| Step: 7
Training loss: 3.6461203035311747
Validation loss: 2.637534234425888

Epoch: 6| Step: 8
Training loss: 2.8359489335599406
Validation loss: 2.623062443685676

Epoch: 6| Step: 9
Training loss: 2.7142510734584793
Validation loss: 2.6195467976347158

Epoch: 6| Step: 10
Training loss: 2.6620112154041538
Validation loss: 2.6203882174315694

Epoch: 6| Step: 11
Training loss: 2.1996925616026592
Validation loss: 2.6177312588210038

Epoch: 6| Step: 12
Training loss: 3.100143146286284
Validation loss: 2.6172794958288157

Epoch: 6| Step: 13
Training loss: 3.359575984176728
Validation loss: 2.6148025972459514

Epoch: 79| Step: 0
Training loss: 2.822931062068106
Validation loss: 2.6150172534174945

Epoch: 6| Step: 1
Training loss: 2.896844390081925
Validation loss: 2.6138850846388464

Epoch: 6| Step: 2
Training loss: 2.899628839089579
Validation loss: 2.6154141614602526

Epoch: 6| Step: 3
Training loss: 3.10563304154646
Validation loss: 2.6157482153724545

Epoch: 6| Step: 4
Training loss: 3.035610091400765
Validation loss: 2.619369567426523

Epoch: 6| Step: 5
Training loss: 2.859948439500111
Validation loss: 2.617785196220629

Epoch: 6| Step: 6
Training loss: 3.063639993050594
Validation loss: 2.616036360452377

Epoch: 6| Step: 7
Training loss: 2.7733800747796127
Validation loss: 2.617353950929158

Epoch: 6| Step: 8
Training loss: 2.9136718815462026
Validation loss: 2.61260057183044

Epoch: 6| Step: 9
Training loss: 3.1040121633153706
Validation loss: 2.6165934961655446

Epoch: 6| Step: 10
Training loss: 2.6925315774325083
Validation loss: 2.6225066162768544

Epoch: 6| Step: 11
Training loss: 3.3858172526921666
Validation loss: 2.62553349165362

Epoch: 6| Step: 12
Training loss: 3.0330610076171785
Validation loss: 2.6398362784380747

Epoch: 6| Step: 13
Training loss: 2.665722461273782
Validation loss: 2.6505204660728707

Epoch: 80| Step: 0
Training loss: 3.2848972939703294
Validation loss: 2.6592635479072997

Epoch: 6| Step: 1
Training loss: 2.352351566378993
Validation loss: 2.6606812395077983

Epoch: 6| Step: 2
Training loss: 3.1181492289911033
Validation loss: 2.6341902071677885

Epoch: 6| Step: 3
Training loss: 3.7373670777634613
Validation loss: 2.6312119034543975

Epoch: 6| Step: 4
Training loss: 2.7792834069146184
Validation loss: 2.6186550188452546

Epoch: 6| Step: 5
Training loss: 2.6330530979237006
Validation loss: 2.6213418127262518

Epoch: 6| Step: 6
Training loss: 2.2112031918537163
Validation loss: 2.61719488572346

Epoch: 6| Step: 7
Training loss: 2.767294945292153
Validation loss: 2.6114673759455433

Epoch: 6| Step: 8
Training loss: 3.3383371624771483
Validation loss: 2.6099970690542187

Epoch: 6| Step: 9
Training loss: 2.4738070686006806
Validation loss: 2.609416285156236

Epoch: 6| Step: 10
Training loss: 3.3863927910918843
Validation loss: 2.6081861509551816

Epoch: 6| Step: 11
Training loss: 2.816514435064597
Validation loss: 2.6167648804370187

Epoch: 6| Step: 12
Training loss: 2.808204676985461
Validation loss: 2.6253435307586677

Epoch: 6| Step: 13
Training loss: 3.5565865945666046
Validation loss: 2.630193507590229

Epoch: 81| Step: 0
Training loss: 2.5845355241178725
Validation loss: 2.6176947733731

Epoch: 6| Step: 1
Training loss: 2.6548440241570765
Validation loss: 2.6104266335652007

Epoch: 6| Step: 2
Training loss: 3.176785881418034
Validation loss: 2.607657153179389

Epoch: 6| Step: 3
Training loss: 3.1084743709799287
Validation loss: 2.607855340730637

Epoch: 6| Step: 4
Training loss: 2.9449263504223024
Validation loss: 2.6029355843609276

Epoch: 6| Step: 5
Training loss: 3.042365390178898
Validation loss: 2.6028418750056863

Epoch: 6| Step: 6
Training loss: 2.7916649396141366
Validation loss: 2.6007826412046158

Epoch: 6| Step: 7
Training loss: 2.6551618254459406
Validation loss: 2.6025247496309256

Epoch: 6| Step: 8
Training loss: 3.6378429080795596
Validation loss: 2.6026425846557486

Epoch: 6| Step: 9
Training loss: 2.859377668202307
Validation loss: 2.6043105809633618

Epoch: 6| Step: 10
Training loss: 2.592500224688234
Validation loss: 2.6080770729609357

Epoch: 6| Step: 11
Training loss: 3.198740121066665
Validation loss: 2.625030975432494

Epoch: 6| Step: 12
Training loss: 3.2461122588032794
Validation loss: 2.657446226244799

Epoch: 6| Step: 13
Training loss: 2.207158393910996
Validation loss: 2.6507983226667644

Epoch: 82| Step: 0
Training loss: 2.6091196997464454
Validation loss: 2.6605860460649615

Epoch: 6| Step: 1
Training loss: 3.063633922928897
Validation loss: 2.683667752351248

Epoch: 6| Step: 2
Training loss: 3.4507317858815485
Validation loss: 2.6808898403931853

Epoch: 6| Step: 3
Training loss: 2.7210545911881883
Validation loss: 2.6513643167346066

Epoch: 6| Step: 4
Training loss: 2.99909641645372
Validation loss: 2.6154072304253058

Epoch: 6| Step: 5
Training loss: 2.778220594926232
Validation loss: 2.6050642892374665

Epoch: 6| Step: 6
Training loss: 3.0787699841785057
Validation loss: 2.601070512366918

Epoch: 6| Step: 7
Training loss: 3.031777404837451
Validation loss: 2.5952233010742907

Epoch: 6| Step: 8
Training loss: 2.6040234539071525
Validation loss: 2.595452048820504

Epoch: 6| Step: 9
Training loss: 3.549022276652856
Validation loss: 2.589209043797353

Epoch: 6| Step: 10
Training loss: 2.206997113259229
Validation loss: 2.5766964780315114

Epoch: 6| Step: 11
Training loss: 3.258857833781391
Validation loss: 2.562592049302765

Epoch: 6| Step: 12
Training loss: 2.2422825597091203
Validation loss: 2.5650501972419866

Epoch: 6| Step: 13
Training loss: 3.827277389421385
Validation loss: 2.563190379210721

Epoch: 83| Step: 0
Training loss: 3.133866206640457
Validation loss: 2.56458882840014

Epoch: 6| Step: 1
Training loss: 2.7038020350033998
Validation loss: 2.563838854087287

Epoch: 6| Step: 2
Training loss: 2.920738121436297
Validation loss: 2.561056304155813

Epoch: 6| Step: 3
Training loss: 2.6706552677238213
Validation loss: 2.558117647516295

Epoch: 6| Step: 4
Training loss: 2.9131541945887784
Validation loss: 2.5626305637667315

Epoch: 6| Step: 5
Training loss: 2.7391914890032303
Validation loss: 2.561384729194439

Epoch: 6| Step: 6
Training loss: 3.3326392563772895
Validation loss: 2.559791884717766

Epoch: 6| Step: 7
Training loss: 2.859064804511518
Validation loss: 2.5612170561652814

Epoch: 6| Step: 8
Training loss: 3.1114354040277776
Validation loss: 2.566834038816202

Epoch: 6| Step: 9
Training loss: 2.872040925820843
Validation loss: 2.564656547459037

Epoch: 6| Step: 10
Training loss: 2.87322810759967
Validation loss: 2.5606751285662233

Epoch: 6| Step: 11
Training loss: 3.2054330837302563
Validation loss: 2.565377154622145

Epoch: 6| Step: 12
Training loss: 2.8181005029888997
Validation loss: 2.576112784158804

Epoch: 6| Step: 13
Training loss: 2.6461079572595234
Validation loss: 2.5911518184456495

Epoch: 84| Step: 0
Training loss: 3.0091012546976463
Validation loss: 2.5930551437574834

Epoch: 6| Step: 1
Training loss: 2.578152650627054
Validation loss: 2.6097112179535547

Epoch: 6| Step: 2
Training loss: 2.8101790282212087
Validation loss: 2.589703543227287

Epoch: 6| Step: 3
Training loss: 3.2175895302623525
Validation loss: 2.5935940617163435

Epoch: 6| Step: 4
Training loss: 2.635717221537929
Validation loss: 2.589624598591797

Epoch: 6| Step: 5
Training loss: 3.1690519952670475
Validation loss: 2.576576043538895

Epoch: 6| Step: 6
Training loss: 3.142684337274426
Validation loss: 2.580464582989484

Epoch: 6| Step: 7
Training loss: 3.031825374778273
Validation loss: 2.584928825356823

Epoch: 6| Step: 8
Training loss: 2.9218808750358716
Validation loss: 2.5683075907930757

Epoch: 6| Step: 9
Training loss: 2.8189976551686224
Validation loss: 2.578916320970986

Epoch: 6| Step: 10
Training loss: 2.737905435716646
Validation loss: 2.5825804484263095

Epoch: 6| Step: 11
Training loss: 2.9669772024895598
Validation loss: 2.5700345981759343

Epoch: 6| Step: 12
Training loss: 2.6609265616747066
Validation loss: 2.579952251979472

Epoch: 6| Step: 13
Training loss: 3.01171479181606
Validation loss: 2.583729268700245

Epoch: 85| Step: 0
Training loss: 2.5636897232803775
Validation loss: 2.565593072274573

Epoch: 6| Step: 1
Training loss: 2.9276897485549838
Validation loss: 2.560437575769485

Epoch: 6| Step: 2
Training loss: 2.7411505757403836
Validation loss: 2.556290721711869

Epoch: 6| Step: 3
Training loss: 3.2030533945407167
Validation loss: 2.561562686613666

Epoch: 6| Step: 4
Training loss: 3.0750182298569606
Validation loss: 2.561525531228263

Epoch: 6| Step: 5
Training loss: 3.247202476163692
Validation loss: 2.5573061067207616

Epoch: 6| Step: 6
Training loss: 2.9240257792660618
Validation loss: 2.5565072934715976

Epoch: 6| Step: 7
Training loss: 3.227123442651571
Validation loss: 2.5562498060809498

Epoch: 6| Step: 8
Training loss: 2.725827443198038
Validation loss: 2.560789072839757

Epoch: 6| Step: 9
Training loss: 2.7552506864834334
Validation loss: 2.5632367019279485

Epoch: 6| Step: 10
Training loss: 2.387979277592752
Validation loss: 2.568387941260643

Epoch: 6| Step: 11
Training loss: 3.3281774382422586
Validation loss: 2.5767686614073

Epoch: 6| Step: 12
Training loss: 2.7288848692643133
Validation loss: 2.5826133809142404

Epoch: 6| Step: 13
Training loss: 2.6538139392339217
Validation loss: 2.5854966820460676

Epoch: 86| Step: 0
Training loss: 2.5545786796514576
Validation loss: 2.6107489520466336

Epoch: 6| Step: 1
Training loss: 3.280358911044051
Validation loss: 2.6067224934714743

Epoch: 6| Step: 2
Training loss: 2.949098132363778
Validation loss: 2.57228471570108

Epoch: 6| Step: 3
Training loss: 3.2105287908983935
Validation loss: 2.5579022263721622

Epoch: 6| Step: 4
Training loss: 2.6845266172780837
Validation loss: 2.5531968939290786

Epoch: 6| Step: 5
Training loss: 2.3354698912391316
Validation loss: 2.549732565242253

Epoch: 6| Step: 6
Training loss: 2.2448153630987777
Validation loss: 2.5518590909387995

Epoch: 6| Step: 7
Training loss: 3.31574047581443
Validation loss: 2.5537658546211826

Epoch: 6| Step: 8
Training loss: 2.8531225666148576
Validation loss: 2.5491530115824723

Epoch: 6| Step: 9
Training loss: 2.731497858528807
Validation loss: 2.550905866053367

Epoch: 6| Step: 10
Training loss: 2.7421195084274745
Validation loss: 2.558497025760126

Epoch: 6| Step: 11
Training loss: 3.139828405368856
Validation loss: 2.56674082323566

Epoch: 6| Step: 12
Training loss: 3.3080670907021994
Validation loss: 2.5804613169210486

Epoch: 6| Step: 13
Training loss: 3.3234784997617943
Validation loss: 2.587498842016889

Epoch: 87| Step: 0
Training loss: 2.6438031455034756
Validation loss: 2.607239292596707

Epoch: 6| Step: 1
Training loss: 3.3735817649140425
Validation loss: 2.6146877560323065

Epoch: 6| Step: 2
Training loss: 3.405807046349351
Validation loss: 2.610972419960306

Epoch: 6| Step: 3
Training loss: 2.634425272071622
Validation loss: 2.608358333352122

Epoch: 6| Step: 4
Training loss: 2.8659642075980987
Validation loss: 2.5951239767718737

Epoch: 6| Step: 5
Training loss: 2.206999273828094
Validation loss: 2.5759160969995722

Epoch: 6| Step: 6
Training loss: 2.5146992561612587
Validation loss: 2.5736380692456495

Epoch: 6| Step: 7
Training loss: 2.818591070663978
Validation loss: 2.566313297590439

Epoch: 6| Step: 8
Training loss: 3.1782904327756523
Validation loss: 2.5612815343098982

Epoch: 6| Step: 9
Training loss: 3.337835482191529
Validation loss: 2.553736010492109

Epoch: 6| Step: 10
Training loss: 2.598457751995173
Validation loss: 2.545276679096764

Epoch: 6| Step: 11
Training loss: 2.9851696294640955
Validation loss: 2.544884332604354

Epoch: 6| Step: 12
Training loss: 2.750783895259973
Validation loss: 2.546705368032795

Epoch: 6| Step: 13
Training loss: 3.123597402520406
Validation loss: 2.546611100574054

Epoch: 88| Step: 0
Training loss: 2.79512736526757
Validation loss: 2.5473563708644926

Epoch: 6| Step: 1
Training loss: 3.036896784661684
Validation loss: 2.547588698081522

Epoch: 6| Step: 2
Training loss: 2.8417822768632783
Validation loss: 2.55173455660026

Epoch: 6| Step: 3
Training loss: 2.7223176896186176
Validation loss: 2.554006726108301

Epoch: 6| Step: 4
Training loss: 3.272733844885344
Validation loss: 2.564012076841598

Epoch: 6| Step: 5
Training loss: 3.072082475270363
Validation loss: 2.5540478121764725

Epoch: 6| Step: 6
Training loss: 2.8381673490233115
Validation loss: 2.5557614441460363

Epoch: 6| Step: 7
Training loss: 3.080553984424254
Validation loss: 2.5586904836086313

Epoch: 6| Step: 8
Training loss: 2.859296120144491
Validation loss: 2.5738480248838744

Epoch: 6| Step: 9
Training loss: 2.7149317445833847
Validation loss: 2.592649322913893

Epoch: 6| Step: 10
Training loss: 2.7696831880759922
Validation loss: 2.6258148436563267

Epoch: 6| Step: 11
Training loss: 2.5713799297939555
Validation loss: 2.6086676355220004

Epoch: 6| Step: 12
Training loss: 2.9131962611107256
Validation loss: 2.617854299808812

Epoch: 6| Step: 13
Training loss: 3.0497635671559458
Validation loss: 2.635469989528185

Epoch: 89| Step: 0
Training loss: 2.273241591779177
Validation loss: 2.6082868168206383

Epoch: 6| Step: 1
Training loss: 3.1446087371566986
Validation loss: 2.5878528500425726

Epoch: 6| Step: 2
Training loss: 3.0094565122028816
Validation loss: 2.5754796422199817

Epoch: 6| Step: 3
Training loss: 2.2486763345506975
Validation loss: 2.561080890823016

Epoch: 6| Step: 4
Training loss: 3.236184908380618
Validation loss: 2.552214044601718

Epoch: 6| Step: 5
Training loss: 3.0266832381759694
Validation loss: 2.550132379105753

Epoch: 6| Step: 6
Training loss: 3.1224229486394743
Validation loss: 2.5471925520520813

Epoch: 6| Step: 7
Training loss: 2.834665228506293
Validation loss: 2.545558576897793

Epoch: 6| Step: 8
Training loss: 3.3867500066139815
Validation loss: 2.5560772307475434

Epoch: 6| Step: 9
Training loss: 2.7649894889369624
Validation loss: 2.5545066480221337

Epoch: 6| Step: 10
Training loss: 2.5033851593111627
Validation loss: 2.5516133136558885

Epoch: 6| Step: 11
Training loss: 2.6234088798447694
Validation loss: 2.5452671709702015

Epoch: 6| Step: 12
Training loss: 3.139422437919653
Validation loss: 2.5501107440155093

Epoch: 6| Step: 13
Training loss: 2.862024632591165
Validation loss: 2.547284652304486

Epoch: 90| Step: 0
Training loss: 3.0178571751031043
Validation loss: 2.555235216308941

Epoch: 6| Step: 1
Training loss: 2.919187891130954
Validation loss: 2.5538130268880814

Epoch: 6| Step: 2
Training loss: 2.858005550114853
Validation loss: 2.579582221658081

Epoch: 6| Step: 3
Training loss: 2.379137651185268
Validation loss: 2.574329997555687

Epoch: 6| Step: 4
Training loss: 2.4647564033713767
Validation loss: 2.5624969226289442

Epoch: 6| Step: 5
Training loss: 3.1628729197046743
Validation loss: 2.5612543231253375

Epoch: 6| Step: 6
Training loss: 2.726546410455751
Validation loss: 2.564934561213978

Epoch: 6| Step: 7
Training loss: 2.8440650513904435
Validation loss: 2.5737348808811844

Epoch: 6| Step: 8
Training loss: 3.7074963485895287
Validation loss: 2.5662681432673367

Epoch: 6| Step: 9
Training loss: 2.679213234440855
Validation loss: 2.5690547158285897

Epoch: 6| Step: 10
Training loss: 3.0259557680072793
Validation loss: 2.5526915665264345

Epoch: 6| Step: 11
Training loss: 2.6746801630778143
Validation loss: 2.5677143341382385

Epoch: 6| Step: 12
Training loss: 2.6175350129300647
Validation loss: 2.561484633159523

Epoch: 6| Step: 13
Training loss: 3.2087469123376686
Validation loss: 2.5812280013717634

Epoch: 91| Step: 0
Training loss: 3.61829545455591
Validation loss: 2.5942351422132104

Epoch: 6| Step: 1
Training loss: 2.797482046388452
Validation loss: 2.596500666393228

Epoch: 6| Step: 2
Training loss: 2.160077885177231
Validation loss: 2.5976686612909905

Epoch: 6| Step: 3
Training loss: 3.5238999023163826
Validation loss: 2.580619178789865

Epoch: 6| Step: 4
Training loss: 2.83082611750852
Validation loss: 2.569791536871419

Epoch: 6| Step: 5
Training loss: 3.0565098938696798
Validation loss: 2.5594655199778824

Epoch: 6| Step: 6
Training loss: 2.962503386547873
Validation loss: 2.556687789348213

Epoch: 6| Step: 7
Training loss: 2.6108256436488486
Validation loss: 2.5589512568746655

Epoch: 6| Step: 8
Training loss: 3.474563126580558
Validation loss: 2.565251848437733

Epoch: 6| Step: 9
Training loss: 2.2454643097315254
Validation loss: 2.5641686733698608

Epoch: 6| Step: 10
Training loss: 2.546810406760943
Validation loss: 2.5454954206616462

Epoch: 6| Step: 11
Training loss: 2.4948605160912254
Validation loss: 2.5542794514768725

Epoch: 6| Step: 12
Training loss: 2.6206480008222903
Validation loss: 2.549101930404053

Epoch: 6| Step: 13
Training loss: 3.021114432750187
Validation loss: 2.5465840588006303

Epoch: 92| Step: 0
Training loss: 3.8571615319582047
Validation loss: 2.5557943144601922

Epoch: 6| Step: 1
Training loss: 2.5823750923430375
Validation loss: 2.545260857715697

Epoch: 6| Step: 2
Training loss: 2.0939608795096896
Validation loss: 2.548976751443409

Epoch: 6| Step: 3
Training loss: 2.8263576317344166
Validation loss: 2.5492178009006192

Epoch: 6| Step: 4
Training loss: 3.12694702529074
Validation loss: 2.54399331281594

Epoch: 6| Step: 5
Training loss: 2.8302755872710246
Validation loss: 2.5401951810159322

Epoch: 6| Step: 6
Training loss: 2.9187358782342896
Validation loss: 2.540679482388438

Epoch: 6| Step: 7
Training loss: 2.9030470066660303
Validation loss: 2.5368904398796404

Epoch: 6| Step: 8
Training loss: 2.946734259795335
Validation loss: 2.5401785559192858

Epoch: 6| Step: 9
Training loss: 3.0293267824724492
Validation loss: 2.5470518358680367

Epoch: 6| Step: 10
Training loss: 2.41696614569304
Validation loss: 2.5580465343270427

Epoch: 6| Step: 11
Training loss: 2.489463920336412
Validation loss: 2.5779265077809375

Epoch: 6| Step: 12
Training loss: 3.1693324529988702
Validation loss: 2.5751066167295704

Epoch: 6| Step: 13
Training loss: 2.700172090344311
Validation loss: 2.5782927527220614

Epoch: 93| Step: 0
Training loss: 2.4019558725234327
Validation loss: 2.568864150196021

Epoch: 6| Step: 1
Training loss: 3.2969342990261006
Validation loss: 2.5813806704687954

Epoch: 6| Step: 2
Training loss: 2.6223540822064058
Validation loss: 2.5833151324130808

Epoch: 6| Step: 3
Training loss: 2.9330410493825827
Validation loss: 2.5717318791464163

Epoch: 6| Step: 4
Training loss: 3.2491900094905866
Validation loss: 2.567800978992881

Epoch: 6| Step: 5
Training loss: 3.1683308762472766
Validation loss: 2.5532624611980985

Epoch: 6| Step: 6
Training loss: 2.5552134307880983
Validation loss: 2.542931064849256

Epoch: 6| Step: 7
Training loss: 3.0808132457895154
Validation loss: 2.53152775224899

Epoch: 6| Step: 8
Training loss: 2.977387721893871
Validation loss: 2.52858984580131

Epoch: 6| Step: 9
Training loss: 2.955889502838481
Validation loss: 2.535311091756979

Epoch: 6| Step: 10
Training loss: 2.8050916800246486
Validation loss: 2.53226193368372

Epoch: 6| Step: 11
Training loss: 2.5192066545390683
Validation loss: 2.5304055627786894

Epoch: 6| Step: 12
Training loss: 3.0119373920007897
Validation loss: 2.5361219297046813

Epoch: 6| Step: 13
Training loss: 2.651352260259545
Validation loss: 2.531249982782463

Epoch: 94| Step: 0
Training loss: 3.0028723635280645
Validation loss: 2.5350312197510068

Epoch: 6| Step: 1
Training loss: 2.8920782611646545
Validation loss: 2.5466682807681233

Epoch: 6| Step: 2
Training loss: 2.3364611392798706
Validation loss: 2.5726335358188623

Epoch: 6| Step: 3
Training loss: 3.4388583187236548
Validation loss: 2.61601578979328

Epoch: 6| Step: 4
Training loss: 2.6718913295313773
Validation loss: 2.652095569155464

Epoch: 6| Step: 5
Training loss: 2.816888056374189
Validation loss: 2.6648827916421105

Epoch: 6| Step: 6
Training loss: 3.3880846201790256
Validation loss: 2.6699023263565502

Epoch: 6| Step: 7
Training loss: 3.029508109878134
Validation loss: 2.6192319238548745

Epoch: 6| Step: 8
Training loss: 2.5151735457499704
Validation loss: 2.5852265547561792

Epoch: 6| Step: 9
Training loss: 2.28626296150784
Validation loss: 2.5579944892315365

Epoch: 6| Step: 10
Training loss: 2.4486216618866017
Validation loss: 2.5375996015103683

Epoch: 6| Step: 11
Training loss: 3.100073622782982
Validation loss: 2.53579792933646

Epoch: 6| Step: 12
Training loss: 3.2566088458589495
Validation loss: 2.535073826373336

Epoch: 6| Step: 13
Training loss: 3.0970202799728304
Validation loss: 2.536464845709168

Epoch: 95| Step: 0
Training loss: 3.251020124698752
Validation loss: 2.5307924157580466

Epoch: 6| Step: 1
Training loss: 2.9580021704200896
Validation loss: 2.5304346709724665

Epoch: 6| Step: 2
Training loss: 2.949724287952853
Validation loss: 2.5297250208962585

Epoch: 6| Step: 3
Training loss: 3.1793644621494264
Validation loss: 2.52979264057722

Epoch: 6| Step: 4
Training loss: 2.6086698024616197
Validation loss: 2.52724338909209

Epoch: 6| Step: 5
Training loss: 2.8093891317417357
Validation loss: 2.5252338551707116

Epoch: 6| Step: 6
Training loss: 2.5699522931313235
Validation loss: 2.5330585150004397

Epoch: 6| Step: 7
Training loss: 3.3277590554937864
Validation loss: 2.530864601668051

Epoch: 6| Step: 8
Training loss: 2.5860333842684207
Validation loss: 2.5334823752646276

Epoch: 6| Step: 9
Training loss: 3.2553512826685504
Validation loss: 2.55469423701919

Epoch: 6| Step: 10
Training loss: 3.093626077655412
Validation loss: 2.5819695895875827

Epoch: 6| Step: 11
Training loss: 2.0464279035949
Validation loss: 2.6129560719069054

Epoch: 6| Step: 12
Training loss: 2.519769228556346
Validation loss: 2.6100302999489435

Epoch: 6| Step: 13
Training loss: 2.511634172644098
Validation loss: 2.632114297738252

Epoch: 96| Step: 0
Training loss: 3.102241960564128
Validation loss: 2.6335535304991637

Epoch: 6| Step: 1
Training loss: 2.7764214595249483
Validation loss: 2.588360167504117

Epoch: 6| Step: 2
Training loss: 2.667910484470837
Validation loss: 2.5720259042969347

Epoch: 6| Step: 3
Training loss: 2.727320524721631
Validation loss: 2.55514022409768

Epoch: 6| Step: 4
Training loss: 2.231334725275319
Validation loss: 2.5418111705266293

Epoch: 6| Step: 5
Training loss: 3.102185395771234
Validation loss: 2.5298605462429413

Epoch: 6| Step: 6
Training loss: 2.4662921114234684
Validation loss: 2.5205255427471176

Epoch: 6| Step: 7
Training loss: 2.417003334096772
Validation loss: 2.530419811459184

Epoch: 6| Step: 8
Training loss: 3.232029455976055
Validation loss: 2.5264851255191796

Epoch: 6| Step: 9
Training loss: 3.259137732555288
Validation loss: 2.537984778134661

Epoch: 6| Step: 10
Training loss: 3.039689732328489
Validation loss: 2.5406355132029854

Epoch: 6| Step: 11
Training loss: 3.163306327224861
Validation loss: 2.5448083415062346

Epoch: 6| Step: 12
Training loss: 2.8172885396380987
Validation loss: 2.537775831568695

Epoch: 6| Step: 13
Training loss: 3.4401901815761
Validation loss: 2.562454874525261

Epoch: 97| Step: 0
Training loss: 2.9231192647515964
Validation loss: 2.540670625042645

Epoch: 6| Step: 1
Training loss: 2.977585984533123
Validation loss: 2.537174973038518

Epoch: 6| Step: 2
Training loss: 2.736864362801846
Validation loss: 2.5251980911278467

Epoch: 6| Step: 3
Training loss: 3.18975421257587
Validation loss: 2.526989384279513

Epoch: 6| Step: 4
Training loss: 2.672843356079839
Validation loss: 2.520639315645574

Epoch: 6| Step: 5
Training loss: 3.0039291083330553
Validation loss: 2.5170950294063177

Epoch: 6| Step: 6
Training loss: 3.0066700536817375
Validation loss: 2.5118600784556366

Epoch: 6| Step: 7
Training loss: 2.6757527370743617
Validation loss: 2.5204295861615065

Epoch: 6| Step: 8
Training loss: 2.4466092994609876
Validation loss: 2.523965370748355

Epoch: 6| Step: 9
Training loss: 2.8016514403931536
Validation loss: 2.5368919112319794

Epoch: 6| Step: 10
Training loss: 3.1873680536224445
Validation loss: 2.559324970227413

Epoch: 6| Step: 11
Training loss: 2.806698898740461
Validation loss: 2.5600804897506366

Epoch: 6| Step: 12
Training loss: 2.891133031792126
Validation loss: 2.5694999000028838

Epoch: 6| Step: 13
Training loss: 2.5914487626524907
Validation loss: 2.5592122705301232

Epoch: 98| Step: 0
Training loss: 2.3457962259053278
Validation loss: 2.558510336431693

Epoch: 6| Step: 1
Training loss: 2.916606212171091
Validation loss: 2.5790631538490154

Epoch: 6| Step: 2
Training loss: 2.753888502131419
Validation loss: 2.5831967650830197

Epoch: 6| Step: 3
Training loss: 3.0783125921878316
Validation loss: 2.5893612185694588

Epoch: 6| Step: 4
Training loss: 2.8098350614964827
Validation loss: 2.5823990610733882

Epoch: 6| Step: 5
Training loss: 2.5652936268401594
Validation loss: 2.5844146980603147

Epoch: 6| Step: 6
Training loss: 3.390235843387817
Validation loss: 2.5291469542054164

Epoch: 6| Step: 7
Training loss: 2.975613820840804
Validation loss: 2.526829864735255

Epoch: 6| Step: 8
Training loss: 3.3837818756687748
Validation loss: 2.520586000812899

Epoch: 6| Step: 9
Training loss: 3.237613549321626
Validation loss: 2.516279264542277

Epoch: 6| Step: 10
Training loss: 2.080178988164897
Validation loss: 2.522787674039878

Epoch: 6| Step: 11
Training loss: 2.7621750515345376
Validation loss: 2.5163632262989237

Epoch: 6| Step: 12
Training loss: 2.8526488860556003
Validation loss: 2.5176334779632095

Epoch: 6| Step: 13
Training loss: 2.436608567212726
Validation loss: 2.518729071404349

Epoch: 99| Step: 0
Training loss: 3.5402583445015687
Validation loss: 2.527192487918175

Epoch: 6| Step: 1
Training loss: 2.695378841744682
Validation loss: 2.521455591525728

Epoch: 6| Step: 2
Training loss: 3.2209503652638243
Validation loss: 2.5263705341557268

Epoch: 6| Step: 3
Training loss: 2.577500053723961
Validation loss: 2.5249408863644573

Epoch: 6| Step: 4
Training loss: 2.962667236758411
Validation loss: 2.5335141012882065

Epoch: 6| Step: 5
Training loss: 2.4764834610995012
Validation loss: 2.5255455579476602

Epoch: 6| Step: 6
Training loss: 3.2276319897268957
Validation loss: 2.5252520557756135

Epoch: 6| Step: 7
Training loss: 2.8053276160360805
Validation loss: 2.5255395516890795

Epoch: 6| Step: 8
Training loss: 2.9948097471714177
Validation loss: 2.5323136238449506

Epoch: 6| Step: 9
Training loss: 2.761810517034203
Validation loss: 2.5387504775905283

Epoch: 6| Step: 10
Training loss: 2.02910559508154
Validation loss: 2.5511287053124296

Epoch: 6| Step: 11
Training loss: 2.9540279562110885
Validation loss: 2.542897072023458

Epoch: 6| Step: 12
Training loss: 2.7015798044174506
Validation loss: 2.5672045644940282

Epoch: 6| Step: 13
Training loss: 2.4101538758598515
Validation loss: 2.5745472076740605

Epoch: 100| Step: 0
Training loss: 2.3944259047866114
Validation loss: 2.5870568155742513

Epoch: 6| Step: 1
Training loss: 2.8096187668256136
Validation loss: 2.5994311572601503

Epoch: 6| Step: 2
Training loss: 3.143581232656251
Validation loss: 2.571243604716819

Epoch: 6| Step: 3
Training loss: 2.8365625790760634
Validation loss: 2.559525427843168

Epoch: 6| Step: 4
Training loss: 2.8050786757697725
Validation loss: 2.5472541354256912

Epoch: 6| Step: 5
Training loss: 3.0647303964548174
Validation loss: 2.547774818697907

Epoch: 6| Step: 6
Training loss: 2.511545795282124
Validation loss: 2.5444110950891483

Epoch: 6| Step: 7
Training loss: 2.8482481206651498
Validation loss: 2.540646811565234

Epoch: 6| Step: 8
Training loss: 2.8754229027234994
Validation loss: 2.5472726698284918

Epoch: 6| Step: 9
Training loss: 2.835343227701378
Validation loss: 2.5407695161919177

Epoch: 6| Step: 10
Training loss: 2.7706876635204085
Validation loss: 2.5368817986990577

Epoch: 6| Step: 11
Training loss: 3.2301324856163083
Validation loss: 2.530073212644018

Epoch: 6| Step: 12
Training loss: 2.6697391651204114
Validation loss: 2.5335656333474916

Epoch: 6| Step: 13
Training loss: 3.146996861875974
Validation loss: 2.5311865151061808

Epoch: 101| Step: 0
Training loss: 2.90724280022548
Validation loss: 2.522008104663584

Epoch: 6| Step: 1
Training loss: 2.2493832060676673
Validation loss: 2.5422035697853005

Epoch: 6| Step: 2
Training loss: 2.594553995190688
Validation loss: 2.5432784011677567

Epoch: 6| Step: 3
Training loss: 2.896021409182157
Validation loss: 2.5441794606644503

Epoch: 6| Step: 4
Training loss: 2.800033831391988
Validation loss: 2.549002333644558

Epoch: 6| Step: 5
Training loss: 3.2036575991090404
Validation loss: 2.5546758031237067

Epoch: 6| Step: 6
Training loss: 3.3774337470660045
Validation loss: 2.553763217461862

Epoch: 6| Step: 7
Training loss: 2.2997339841175277
Validation loss: 2.538131559863614

Epoch: 6| Step: 8
Training loss: 2.7014290665812455
Validation loss: 2.519452870218107

Epoch: 6| Step: 9
Training loss: 2.972207234741959
Validation loss: 2.5303932754562246

Epoch: 6| Step: 10
Training loss: 2.913153539852119
Validation loss: 2.5241907518713322

Epoch: 6| Step: 11
Training loss: 2.733855977526866
Validation loss: 2.5105810076296957

Epoch: 6| Step: 12
Training loss: 2.8523352843059455
Validation loss: 2.5188520132332943

Epoch: 6| Step: 13
Training loss: 3.1801238639268425
Validation loss: 2.5053599212842683

Epoch: 102| Step: 0
Training loss: 3.0135426026936325
Validation loss: 2.524230155927053

Epoch: 6| Step: 1
Training loss: 2.7702991190510264
Validation loss: 2.535363390147571

Epoch: 6| Step: 2
Training loss: 3.005290770212658
Validation loss: 2.5726212399216988

Epoch: 6| Step: 3
Training loss: 2.715930924122875
Validation loss: 2.5882637662269112

Epoch: 6| Step: 4
Training loss: 2.7438360839408555
Validation loss: 2.58970711293386

Epoch: 6| Step: 5
Training loss: 2.9787858483978393
Validation loss: 2.5988846447695755

Epoch: 6| Step: 6
Training loss: 2.85831102264268
Validation loss: 2.5670394057747794

Epoch: 6| Step: 7
Training loss: 3.4042712422389116
Validation loss: 2.5502735711826374

Epoch: 6| Step: 8
Training loss: 2.8125163607651302
Validation loss: 2.5265676360377722

Epoch: 6| Step: 9
Training loss: 2.729363344594337
Validation loss: 2.5111186539082966

Epoch: 6| Step: 10
Training loss: 2.267805641713784
Validation loss: 2.5133647380955906

Epoch: 6| Step: 11
Training loss: 2.5483677707771104
Validation loss: 2.5103125829968764

Epoch: 6| Step: 12
Training loss: 2.8272696197312044
Validation loss: 2.508945167770591

Epoch: 6| Step: 13
Training loss: 2.9448700023514642
Validation loss: 2.507104728226626

Epoch: 103| Step: 0
Training loss: 2.845346861814581
Validation loss: 2.507797423639331

Epoch: 6| Step: 1
Training loss: 3.1630152346702123
Validation loss: 2.526247596952079

Epoch: 6| Step: 2
Training loss: 2.883736480429863
Validation loss: 2.538830862782906

Epoch: 6| Step: 3
Training loss: 2.612914100937295
Validation loss: 2.56576961374415

Epoch: 6| Step: 4
Training loss: 2.4215722663929578
Validation loss: 2.611775924167088

Epoch: 6| Step: 5
Training loss: 3.041496341761443
Validation loss: 2.6062157044448973

Epoch: 6| Step: 6
Training loss: 3.1887917986395413
Validation loss: 2.5841793235756176

Epoch: 6| Step: 7
Training loss: 2.9546646867715602
Validation loss: 2.546951273678119

Epoch: 6| Step: 8
Training loss: 3.022701676599961
Validation loss: 2.5241964962608656

Epoch: 6| Step: 9
Training loss: 2.324901422851421
Validation loss: 2.5102818658442283

Epoch: 6| Step: 10
Training loss: 2.7148195992911863
Validation loss: 2.5106756731730626

Epoch: 6| Step: 11
Training loss: 2.4750959705280065
Validation loss: 2.5108837608308745

Epoch: 6| Step: 12
Training loss: 3.2073738017420985
Validation loss: 2.5165675298240537

Epoch: 6| Step: 13
Training loss: 3.023309907019834
Validation loss: 2.5151732929710278

Epoch: 104| Step: 0
Training loss: 2.951435392923429
Validation loss: 2.516380089221246

Epoch: 6| Step: 1
Training loss: 2.912983303327341
Validation loss: 2.5187967297963176

Epoch: 6| Step: 2
Training loss: 2.295915883467319
Validation loss: 2.527194390973856

Epoch: 6| Step: 3
Training loss: 3.088356171173729
Validation loss: 2.5661039193225372

Epoch: 6| Step: 4
Training loss: 2.960217390841017
Validation loss: 2.5972072906954025

Epoch: 6| Step: 5
Training loss: 2.851622196774532
Validation loss: 2.599802274300712

Epoch: 6| Step: 6
Training loss: 2.5342481776631054
Validation loss: 2.5825629565938097

Epoch: 6| Step: 7
Training loss: 2.6046842340495795
Validation loss: 2.551744690644835

Epoch: 6| Step: 8
Training loss: 3.399520526063772
Validation loss: 2.5438414786877437

Epoch: 6| Step: 9
Training loss: 2.7337392885463125
Validation loss: 2.511933918824123

Epoch: 6| Step: 10
Training loss: 2.905874904914645
Validation loss: 2.5015746366994485

Epoch: 6| Step: 11
Training loss: 2.50036751906749
Validation loss: 2.5049427270215334

Epoch: 6| Step: 12
Training loss: 2.95237036049755
Validation loss: 2.500471250151808

Epoch: 6| Step: 13
Training loss: 2.8098315825848807
Validation loss: 2.499532374875296

Epoch: 105| Step: 0
Training loss: 2.7524077538772334
Validation loss: 2.5041375489724618

Epoch: 6| Step: 1
Training loss: 2.5387075322786283
Validation loss: 2.5067676208412375

Epoch: 6| Step: 2
Training loss: 2.890217190405393
Validation loss: 2.5015386563592883

Epoch: 6| Step: 3
Training loss: 2.497518738608567
Validation loss: 2.5023427230861897

Epoch: 6| Step: 4
Training loss: 2.9295445928687354
Validation loss: 2.505611854241893

Epoch: 6| Step: 5
Training loss: 3.078767815870188
Validation loss: 2.5054521994356818

Epoch: 6| Step: 6
Training loss: 3.210768794990199
Validation loss: 2.504565168011306

Epoch: 6| Step: 7
Training loss: 2.8194728457351976
Validation loss: 2.512450641662942

Epoch: 6| Step: 8
Training loss: 2.986327965326598
Validation loss: 2.533720574334499

Epoch: 6| Step: 9
Training loss: 2.5038205517462067
Validation loss: 2.528861321111476

Epoch: 6| Step: 10
Training loss: 2.7238190848144295
Validation loss: 2.5429473609403472

Epoch: 6| Step: 11
Training loss: 2.7918008990303482
Validation loss: 2.560729836265961

Epoch: 6| Step: 12
Training loss: 2.8062907872283853
Validation loss: 2.567333166488171

Epoch: 6| Step: 13
Training loss: 3.4917857645218415
Validation loss: 2.5330711684140113

Epoch: 106| Step: 0
Training loss: 2.815225340393483
Validation loss: 2.5216285456748966

Epoch: 6| Step: 1
Training loss: 3.335554686118474
Validation loss: 2.5159117394426698

Epoch: 6| Step: 2
Training loss: 2.533523856912526
Validation loss: 2.5061771966016493

Epoch: 6| Step: 3
Training loss: 2.3027215363562794
Validation loss: 2.495355504385491

Epoch: 6| Step: 4
Training loss: 3.53159296851487
Validation loss: 2.5036738954684643

Epoch: 6| Step: 5
Training loss: 2.864203373534397
Validation loss: 2.500124151982322

Epoch: 6| Step: 6
Training loss: 2.9364956701276967
Validation loss: 2.5169473488561698

Epoch: 6| Step: 7
Training loss: 2.8244725030258517
Validation loss: 2.5017431621791784

Epoch: 6| Step: 8
Training loss: 2.5000225066125576
Validation loss: 2.515709226127306

Epoch: 6| Step: 9
Training loss: 2.6973741690460584
Validation loss: 2.5113616017327436

Epoch: 6| Step: 10
Training loss: 2.465414377168159
Validation loss: 2.531142297962903

Epoch: 6| Step: 11
Training loss: 2.7307730356481295
Validation loss: 2.525198735794735

Epoch: 6| Step: 12
Training loss: 3.0382173044464884
Validation loss: 2.5265213107051103

Epoch: 6| Step: 13
Training loss: 2.735329684762786
Validation loss: 2.514430562564617

Epoch: 107| Step: 0
Training loss: 2.398553603154833
Validation loss: 2.5108046230416745

Epoch: 6| Step: 1
Training loss: 2.678908343243386
Validation loss: 2.510415450756085

Epoch: 6| Step: 2
Training loss: 1.995431749190355
Validation loss: 2.509836110282053

Epoch: 6| Step: 3
Training loss: 2.432295990530959
Validation loss: 2.510344659031881

Epoch: 6| Step: 4
Training loss: 2.8791076506893263
Validation loss: 2.4976342308033046

Epoch: 6| Step: 5
Training loss: 3.4233169652837883
Validation loss: 2.507990993827694

Epoch: 6| Step: 6
Training loss: 2.5933003782746087
Validation loss: 2.4996651035490456

Epoch: 6| Step: 7
Training loss: 2.639165350726271
Validation loss: 2.533068165100014

Epoch: 6| Step: 8
Training loss: 2.942554427091619
Validation loss: 2.5405332969156866

Epoch: 6| Step: 9
Training loss: 2.9556667147633147
Validation loss: 2.5418290073455436

Epoch: 6| Step: 10
Training loss: 2.531102399878973
Validation loss: 2.5547064726891033

Epoch: 6| Step: 11
Training loss: 3.7733841728407045
Validation loss: 2.5652527928440123

Epoch: 6| Step: 12
Training loss: 2.922800825184003
Validation loss: 2.560328372002407

Epoch: 6| Step: 13
Training loss: 3.12714007531789
Validation loss: 2.5527471754237085

Epoch: 108| Step: 0
Training loss: 3.1642900549924344
Validation loss: 2.5448027675543816

Epoch: 6| Step: 1
Training loss: 2.330397143592223
Validation loss: 2.525784122864336

Epoch: 6| Step: 2
Training loss: 3.051356692388579
Validation loss: 2.5025939835345525

Epoch: 6| Step: 3
Training loss: 3.025797393621809
Validation loss: 2.5082499433367764

Epoch: 6| Step: 4
Training loss: 2.9486806214350447
Validation loss: 2.5033297800869314

Epoch: 6| Step: 5
Training loss: 2.5267948456646883
Validation loss: 2.5032647104676498

Epoch: 6| Step: 6
Training loss: 3.101312814650661
Validation loss: 2.4975789827282746

Epoch: 6| Step: 7
Training loss: 2.587222791187538
Validation loss: 2.500596361915255

Epoch: 6| Step: 8
Training loss: 3.336667269142343
Validation loss: 2.5040565332870797

Epoch: 6| Step: 9
Training loss: 2.558635961752224
Validation loss: 2.509480930322153

Epoch: 6| Step: 10
Training loss: 2.4177514195797474
Validation loss: 2.535638603004044

Epoch: 6| Step: 11
Training loss: 2.840064206807921
Validation loss: 2.532993531982991

Epoch: 6| Step: 12
Training loss: 2.8499164167495326
Validation loss: 2.560069696739587

Epoch: 6| Step: 13
Training loss: 2.5116758446714527
Validation loss: 2.561303266215819

Epoch: 109| Step: 0
Training loss: 3.0687871740385413
Validation loss: 2.565379609957812

Epoch: 6| Step: 1
Training loss: 3.0149279169224394
Validation loss: 2.539867180344105

Epoch: 6| Step: 2
Training loss: 2.047118660205109
Validation loss: 2.5243154009695927

Epoch: 6| Step: 3
Training loss: 2.3221902666626004
Validation loss: 2.524540545714673

Epoch: 6| Step: 4
Training loss: 2.6095445771993675
Validation loss: 2.5033574519307678

Epoch: 6| Step: 5
Training loss: 3.0937575523207217
Validation loss: 2.4943973930956775

Epoch: 6| Step: 6
Training loss: 2.7244376836025257
Validation loss: 2.4981812937375034

Epoch: 6| Step: 7
Training loss: 2.6587303698218143
Validation loss: 2.5050839844025328

Epoch: 6| Step: 8
Training loss: 2.5808741852439443
Validation loss: 2.502047559589611

Epoch: 6| Step: 9
Training loss: 2.6120248462844726
Validation loss: 2.5157740717000894

Epoch: 6| Step: 10
Training loss: 2.8196407796799803
Validation loss: 2.5136341004454685

Epoch: 6| Step: 11
Training loss: 3.770996567932202
Validation loss: 2.5142563312057398

Epoch: 6| Step: 12
Training loss: 2.7638353494882453
Validation loss: 2.514963364538275

Epoch: 6| Step: 13
Training loss: 2.9851205903044633
Validation loss: 2.536567053118101

Epoch: 110| Step: 0
Training loss: 2.626265810991978
Validation loss: 2.5334080589420793

Epoch: 6| Step: 1
Training loss: 3.827646155478943
Validation loss: 2.5553696149393703

Epoch: 6| Step: 2
Training loss: 2.971180453002099
Validation loss: 2.560140931974663

Epoch: 6| Step: 3
Training loss: 2.834995081660127
Validation loss: 2.5604301735102797

Epoch: 6| Step: 4
Training loss: 2.550016373226483
Validation loss: 2.5672407289637262

Epoch: 6| Step: 5
Training loss: 2.9670080595713797
Validation loss: 2.571514797099746

Epoch: 6| Step: 6
Training loss: 2.8506520111068863
Validation loss: 2.5546339072751643

Epoch: 6| Step: 7
Training loss: 2.575170315045057
Validation loss: 2.526291534443985

Epoch: 6| Step: 8
Training loss: 2.699160805727547
Validation loss: 2.518723217851224

Epoch: 6| Step: 9
Training loss: 3.4001558716891536
Validation loss: 2.503801221623547

Epoch: 6| Step: 10
Training loss: 2.114482996271717
Validation loss: 2.493979575918859

Epoch: 6| Step: 11
Training loss: 2.4374061957673945
Validation loss: 2.502423205189677

Epoch: 6| Step: 12
Training loss: 2.650613706529157
Validation loss: 2.5004618771799674

Epoch: 6| Step: 13
Training loss: 2.6240650510167947
Validation loss: 2.516785960299445

Epoch: 111| Step: 0
Training loss: 2.9709933187486013
Validation loss: 2.5069280074157003

Epoch: 6| Step: 1
Training loss: 2.7598751664610197
Validation loss: 2.5079185758072726

Epoch: 6| Step: 2
Training loss: 2.3125907261552396
Validation loss: 2.5113610081275834

Epoch: 6| Step: 3
Training loss: 3.4670749778419183
Validation loss: 2.51551499225272

Epoch: 6| Step: 4
Training loss: 2.4025577108733827
Validation loss: 2.523092045287324

Epoch: 6| Step: 5
Training loss: 2.666724611685941
Validation loss: 2.5405942495871283

Epoch: 6| Step: 6
Training loss: 2.9015366265001505
Validation loss: 2.5555649471942643

Epoch: 6| Step: 7
Training loss: 3.101780804463066
Validation loss: 2.5783304440257933

Epoch: 6| Step: 8
Training loss: 2.37696235297613
Validation loss: 2.602182349137521

Epoch: 6| Step: 9
Training loss: 3.0442972870072476
Validation loss: 2.5897582237420407

Epoch: 6| Step: 10
Training loss: 2.7810968078256986
Validation loss: 2.5664791253474455

Epoch: 6| Step: 11
Training loss: 2.3718823499402344
Validation loss: 2.6025114650902674

Epoch: 6| Step: 12
Training loss: 3.0411863775218886
Validation loss: 2.5796028453301445

Epoch: 6| Step: 13
Training loss: 2.7069773482864132
Validation loss: 2.58380593281558

Epoch: 112| Step: 0
Training loss: 2.852244841575054
Validation loss: 2.6164365667915166

Epoch: 6| Step: 1
Training loss: 2.907132578731535
Validation loss: 2.6760184569487886

Epoch: 6| Step: 2
Training loss: 3.3175700990792474
Validation loss: 2.687873816241981

Epoch: 6| Step: 3
Training loss: 2.9409435460477713
Validation loss: 2.6532085806007566

Epoch: 6| Step: 4
Training loss: 2.9460914451976534
Validation loss: 2.5848871267781126

Epoch: 6| Step: 5
Training loss: 2.91595544772133
Validation loss: 2.5365900741304332

Epoch: 6| Step: 6
Training loss: 2.897997552843028
Validation loss: 2.5359978892249413

Epoch: 6| Step: 7
Training loss: 3.0437180033731144
Validation loss: 2.5207285335936365

Epoch: 6| Step: 8
Training loss: 3.2539661855318154
Validation loss: 2.5247441296490853

Epoch: 6| Step: 9
Training loss: 2.6482354821320633
Validation loss: 2.5253488595106695

Epoch: 6| Step: 10
Training loss: 2.4820929068452835
Validation loss: 2.5155566244502237

Epoch: 6| Step: 11
Training loss: 2.452707437342122
Validation loss: 2.516898848019487

Epoch: 6| Step: 12
Training loss: 2.3776449232727224
Validation loss: 2.512849928404307

Epoch: 6| Step: 13
Training loss: 2.664027775960466
Validation loss: 2.5145959325721607

Epoch: 113| Step: 0
Training loss: 2.677158418980353
Validation loss: 2.504025348296257

Epoch: 6| Step: 1
Training loss: 2.5527225135113194
Validation loss: 2.496525913224727

Epoch: 6| Step: 2
Training loss: 2.9423356531961704
Validation loss: 2.5356627364947886

Epoch: 6| Step: 3
Training loss: 2.6550006396621537
Validation loss: 2.5733971653800634

Epoch: 6| Step: 4
Training loss: 2.611734477049146
Validation loss: 2.5959229562282617

Epoch: 6| Step: 5
Training loss: 3.147279587982555
Validation loss: 2.6489566128825164

Epoch: 6| Step: 6
Training loss: 3.112391250119953
Validation loss: 2.6305006574878664

Epoch: 6| Step: 7
Training loss: 2.9731820201718633
Validation loss: 2.59798918484192

Epoch: 6| Step: 8
Training loss: 2.975636095275897
Validation loss: 2.5765479272515757

Epoch: 6| Step: 9
Training loss: 3.1516422592608584
Validation loss: 2.5587294415367623

Epoch: 6| Step: 10
Training loss: 2.640911560761764
Validation loss: 2.5800126191717987

Epoch: 6| Step: 11
Training loss: 2.934185349385887
Validation loss: 2.5768550296732773

Epoch: 6| Step: 12
Training loss: 2.5788158069226146
Validation loss: 2.567898297215163

Epoch: 6| Step: 13
Training loss: 3.5600451661577286
Validation loss: 2.5253551189977532

Epoch: 114| Step: 0
Training loss: 2.353718830374286
Validation loss: 2.4953001349677657

Epoch: 6| Step: 1
Training loss: 2.912154240201845
Validation loss: 2.488443202553661

Epoch: 6| Step: 2
Training loss: 2.7126496374808706
Validation loss: 2.488255381451713

Epoch: 6| Step: 3
Training loss: 2.6801623932901415
Validation loss: 2.5018724320590717

Epoch: 6| Step: 4
Training loss: 2.6614522815692774
Validation loss: 2.5193358342760876

Epoch: 6| Step: 5
Training loss: 3.428949993668912
Validation loss: 2.534248563081951

Epoch: 6| Step: 6
Training loss: 3.0148485201965696
Validation loss: 2.5481713108412345

Epoch: 6| Step: 7
Training loss: 2.818372402570809
Validation loss: 2.5415155341289695

Epoch: 6| Step: 8
Training loss: 2.616586280203515
Validation loss: 2.5344142179586893

Epoch: 6| Step: 9
Training loss: 2.6663625861682743
Validation loss: 2.5249369783678404

Epoch: 6| Step: 10
Training loss: 3.1529522276652027
Validation loss: 2.5184354212270015

Epoch: 6| Step: 11
Training loss: 2.757790022372102
Validation loss: 2.506827138518619

Epoch: 6| Step: 12
Training loss: 2.6548354028518135
Validation loss: 2.50705148397957

Epoch: 6| Step: 13
Training loss: 3.2044935326763193
Validation loss: 2.5159833190862306

Epoch: 115| Step: 0
Training loss: 2.7408266521808136
Validation loss: 2.489144613587814

Epoch: 6| Step: 1
Training loss: 2.7677195747749237
Validation loss: 2.486125075532744

Epoch: 6| Step: 2
Training loss: 2.749164280916882
Validation loss: 2.4948683846863164

Epoch: 6| Step: 3
Training loss: 2.860408908715856
Validation loss: 2.4899404356058565

Epoch: 6| Step: 4
Training loss: 2.999934513648863
Validation loss: 2.483300055237996

Epoch: 6| Step: 5
Training loss: 2.4903468686294543
Validation loss: 2.4814243627236774

Epoch: 6| Step: 6
Training loss: 3.168948622879627
Validation loss: 2.489006246076019

Epoch: 6| Step: 7
Training loss: 2.5128890614065167
Validation loss: 2.498216220305609

Epoch: 6| Step: 8
Training loss: 2.9738435116240427
Validation loss: 2.51380154924362

Epoch: 6| Step: 9
Training loss: 2.2565713923001334
Validation loss: 2.5142481393908627

Epoch: 6| Step: 10
Training loss: 2.83943536437732
Validation loss: 2.512146647578165

Epoch: 6| Step: 11
Training loss: 2.975595712723934
Validation loss: 2.526182267225992

Epoch: 6| Step: 12
Training loss: 3.032310379024748
Validation loss: 2.5318188237687784

Epoch: 6| Step: 13
Training loss: 3.182647002631516
Validation loss: 2.540630747432368

Epoch: 116| Step: 0
Training loss: 2.7248843912221528
Validation loss: 2.5514333460207355

Epoch: 6| Step: 1
Training loss: 2.0157416258198837
Validation loss: 2.556222879311201

Epoch: 6| Step: 2
Training loss: 2.955553136392749
Validation loss: 2.561023333707253

Epoch: 6| Step: 3
Training loss: 2.4569062654518987
Validation loss: 2.5734580021298354

Epoch: 6| Step: 4
Training loss: 3.0877538043889694
Validation loss: 2.5965722182627977

Epoch: 6| Step: 5
Training loss: 2.8669024333551936
Validation loss: 2.5777914080635456

Epoch: 6| Step: 6
Training loss: 3.072344779554861
Validation loss: 2.5867690340058918

Epoch: 6| Step: 7
Training loss: 1.7830256930568416
Validation loss: 2.5322694243578696

Epoch: 6| Step: 8
Training loss: 3.238227356023934
Validation loss: 2.502250886585227

Epoch: 6| Step: 9
Training loss: 2.783451366396445
Validation loss: 2.487197843856198

Epoch: 6| Step: 10
Training loss: 3.0304970346828717
Validation loss: 2.4850582463616484

Epoch: 6| Step: 11
Training loss: 3.009555222610054
Validation loss: 2.4887921358165284

Epoch: 6| Step: 12
Training loss: 3.143289678708035
Validation loss: 2.4922386357320425

Epoch: 6| Step: 13
Training loss: 3.018989859898493
Validation loss: 2.484960217647176

Epoch: 117| Step: 0
Training loss: 3.114413985089333
Validation loss: 2.4884227938382057

Epoch: 6| Step: 1
Training loss: 3.5363861810723796
Validation loss: 2.483222582180126

Epoch: 6| Step: 2
Training loss: 2.511006350662301
Validation loss: 2.4831325122210868

Epoch: 6| Step: 3
Training loss: 2.4376406506771042
Validation loss: 2.484267074769939

Epoch: 6| Step: 4
Training loss: 2.4377676987978165
Validation loss: 2.480656823755551

Epoch: 6| Step: 5
Training loss: 2.822246026099769
Validation loss: 2.475453028976602

Epoch: 6| Step: 6
Training loss: 2.6941849713618606
Validation loss: 2.4912420770874295

Epoch: 6| Step: 7
Training loss: 2.5719596431704392
Validation loss: 2.516655913179705

Epoch: 6| Step: 8
Training loss: 2.6429624426053544
Validation loss: 2.530368375411431

Epoch: 6| Step: 9
Training loss: 2.9408193461200014
Validation loss: 2.5662760151872206

Epoch: 6| Step: 10
Training loss: 2.976416716922938
Validation loss: 2.5643616493591783

Epoch: 6| Step: 11
Training loss: 2.5385328474010307
Validation loss: 2.5600046583214673

Epoch: 6| Step: 12
Training loss: 2.8495002710007933
Validation loss: 2.5624109868502276

Epoch: 6| Step: 13
Training loss: 3.1422562798892484
Validation loss: 2.5617001753678577

Epoch: 118| Step: 0
Training loss: 2.8643581972372236
Validation loss: 2.5399298578059595

Epoch: 6| Step: 1
Training loss: 2.6920280458029495
Validation loss: 2.589339608290734

Epoch: 6| Step: 2
Training loss: 2.7386474364527036
Validation loss: 2.622051030887824

Epoch: 6| Step: 3
Training loss: 2.789814823527317
Validation loss: 2.5842091038172996

Epoch: 6| Step: 4
Training loss: 2.7697821800716973
Validation loss: 2.5564153896013204

Epoch: 6| Step: 5
Training loss: 2.63216222322264
Validation loss: 2.52506601723899

Epoch: 6| Step: 6
Training loss: 3.104622126881179
Validation loss: 2.4986595210665317

Epoch: 6| Step: 7
Training loss: 2.8447118117751793
Validation loss: 2.491257973974587

Epoch: 6| Step: 8
Training loss: 2.5141271076708493
Validation loss: 2.4827176627965764

Epoch: 6| Step: 9
Training loss: 2.4568886040791518
Validation loss: 2.4796581806534532

Epoch: 6| Step: 10
Training loss: 2.7332297406298425
Validation loss: 2.4856579301217447

Epoch: 6| Step: 11
Training loss: 3.227130387326208
Validation loss: 2.489836452154029

Epoch: 6| Step: 12
Training loss: 2.683910456685926
Validation loss: 2.4803210706014327

Epoch: 6| Step: 13
Training loss: 3.531878390144337
Validation loss: 2.4772457558218175

Epoch: 119| Step: 0
Training loss: 2.826575682078464
Validation loss: 2.4915657102297257

Epoch: 6| Step: 1
Training loss: 2.3246741610027812
Validation loss: 2.5004394145079782

Epoch: 6| Step: 2
Training loss: 3.2637249105037744
Validation loss: 2.5192690207347646

Epoch: 6| Step: 3
Training loss: 2.573665391551213
Validation loss: 2.527764359628297

Epoch: 6| Step: 4
Training loss: 2.877799951213444
Validation loss: 2.5363992040363614

Epoch: 6| Step: 5
Training loss: 2.3335614319981337
Validation loss: 2.533372051054327

Epoch: 6| Step: 6
Training loss: 2.66339514643522
Validation loss: 2.539923318314717

Epoch: 6| Step: 7
Training loss: 3.2173918293729504
Validation loss: 2.560216627190991

Epoch: 6| Step: 8
Training loss: 2.9764945755865395
Validation loss: 2.5511636536406512

Epoch: 6| Step: 9
Training loss: 2.6571419508591143
Validation loss: 2.5367697517235666

Epoch: 6| Step: 10
Training loss: 2.707516141017377
Validation loss: 2.5228600778095833

Epoch: 6| Step: 11
Training loss: 2.874426245451351
Validation loss: 2.5028879077509254

Epoch: 6| Step: 12
Training loss: 2.4685552013175447
Validation loss: 2.4843866409005297

Epoch: 6| Step: 13
Training loss: 3.3068279431862497
Validation loss: 2.486883078850714

Epoch: 120| Step: 0
Training loss: 3.376487686620579
Validation loss: 2.4805487977291567

Epoch: 6| Step: 1
Training loss: 2.2774394360392245
Validation loss: 2.4829970279155265

Epoch: 6| Step: 2
Training loss: 2.688977921888593
Validation loss: 2.4807745875066067

Epoch: 6| Step: 3
Training loss: 2.7506988677733215
Validation loss: 2.482959894554567

Epoch: 6| Step: 4
Training loss: 2.4621221688186457
Validation loss: 2.48060606212343

Epoch: 6| Step: 5
Training loss: 1.9311010457590987
Validation loss: 2.4731263322641137

Epoch: 6| Step: 6
Training loss: 3.231901098060026
Validation loss: 2.486579904633091

Epoch: 6| Step: 7
Training loss: 3.306069376001221
Validation loss: 2.4927591511807976

Epoch: 6| Step: 8
Training loss: 2.7867403166984186
Validation loss: 2.49431909509203

Epoch: 6| Step: 9
Training loss: 3.066517588543984
Validation loss: 2.5014072959002345

Epoch: 6| Step: 10
Training loss: 2.91965698265435
Validation loss: 2.5101007344360826

Epoch: 6| Step: 11
Training loss: 2.855492629591925
Validation loss: 2.518019742781747

Epoch: 6| Step: 12
Training loss: 2.621996660103842
Validation loss: 2.5390818221727187

Epoch: 6| Step: 13
Training loss: 2.0207336506067137
Validation loss: 2.538356300254249

Epoch: 121| Step: 0
Training loss: 2.793177286112368
Validation loss: 2.5368333465055892

Epoch: 6| Step: 1
Training loss: 2.9267669361928195
Validation loss: 2.527685821339351

Epoch: 6| Step: 2
Training loss: 2.6546308182474196
Validation loss: 2.5092703141746746

Epoch: 6| Step: 3
Training loss: 3.104420457403084
Validation loss: 2.514395746010992

Epoch: 6| Step: 4
Training loss: 2.991266253212412
Validation loss: 2.502458273345824

Epoch: 6| Step: 5
Training loss: 2.2912460172278317
Validation loss: 2.5247076427974005

Epoch: 6| Step: 6
Training loss: 2.8455120957244344
Validation loss: 2.5005495785049354

Epoch: 6| Step: 7
Training loss: 2.702126555635109
Validation loss: 2.509692812815019

Epoch: 6| Step: 8
Training loss: 2.6417526455755227
Validation loss: 2.4899339779514134

Epoch: 6| Step: 9
Training loss: 2.624592885736173
Validation loss: 2.474177634984896

Epoch: 6| Step: 10
Training loss: 2.942640959832077
Validation loss: 2.471393601271822

Epoch: 6| Step: 11
Training loss: 2.6758846068085744
Validation loss: 2.4765406404110655

Epoch: 6| Step: 12
Training loss: 2.795423248127094
Validation loss: 2.4785761055264977

Epoch: 6| Step: 13
Training loss: 3.0980338291022917
Validation loss: 2.4782343271461924

Epoch: 122| Step: 0
Training loss: 3.0515181155866364
Validation loss: 2.4843200566072414

Epoch: 6| Step: 1
Training loss: 3.092694497433519
Validation loss: 2.4882628253322823

Epoch: 6| Step: 2
Training loss: 3.41610663561582
Validation loss: 2.4918678138572274

Epoch: 6| Step: 3
Training loss: 2.5392402469334656
Validation loss: 2.540479513576149

Epoch: 6| Step: 4
Training loss: 2.6461949939804117
Validation loss: 2.549476360497274

Epoch: 6| Step: 5
Training loss: 2.265745383385782
Validation loss: 2.5368601334696

Epoch: 6| Step: 6
Training loss: 3.0529625746941136
Validation loss: 2.5477934932023554

Epoch: 6| Step: 7
Training loss: 2.3293353525221048
Validation loss: 2.549653751456149

Epoch: 6| Step: 8
Training loss: 2.4492743332197184
Validation loss: 2.544572154616814

Epoch: 6| Step: 9
Training loss: 2.7465937933775924
Validation loss: 2.537557900580114

Epoch: 6| Step: 10
Training loss: 2.614485253752609
Validation loss: 2.5337180083862214

Epoch: 6| Step: 11
Training loss: 2.9908272063996004
Validation loss: 2.5283044387517495

Epoch: 6| Step: 12
Training loss: 2.406346703109593
Validation loss: 2.503775412057672

Epoch: 6| Step: 13
Training loss: 3.3103115121902436
Validation loss: 2.480583033126476

Epoch: 123| Step: 0
Training loss: 2.202904007020721
Validation loss: 2.476377492241306

Epoch: 6| Step: 1
Training loss: 2.902704023998992
Validation loss: 2.4812424957772743

Epoch: 6| Step: 2
Training loss: 3.3027456363461174
Validation loss: 2.4867068379932684

Epoch: 6| Step: 3
Training loss: 2.9763040906019476
Validation loss: 2.48467388691148

Epoch: 6| Step: 4
Training loss: 3.1441741171906217
Validation loss: 2.485876634503556

Epoch: 6| Step: 5
Training loss: 2.7140413923656133
Validation loss: 2.484751994641288

Epoch: 6| Step: 6
Training loss: 2.6924309849018364
Validation loss: 2.489446151138523

Epoch: 6| Step: 7
Training loss: 2.938613031425185
Validation loss: 2.4826955527844166

Epoch: 6| Step: 8
Training loss: 2.2734888864064784
Validation loss: 2.476859020647487

Epoch: 6| Step: 9
Training loss: 2.483758334034039
Validation loss: 2.4785004593848967

Epoch: 6| Step: 10
Training loss: 3.5231389428837825
Validation loss: 2.483416849738721

Epoch: 6| Step: 11
Training loss: 2.7308585089309885
Validation loss: 2.487486321468406

Epoch: 6| Step: 12
Training loss: 2.317387545098939
Validation loss: 2.503000516869819

Epoch: 6| Step: 13
Training loss: 2.8503527439732235
Validation loss: 2.520075741568983

Epoch: 124| Step: 0
Training loss: 2.9230301965229772
Validation loss: 2.5441639100692073

Epoch: 6| Step: 1
Training loss: 2.9459889897323976
Validation loss: 2.5116833998022168

Epoch: 6| Step: 2
Training loss: 3.0250268351728096
Validation loss: 2.511651140807069

Epoch: 6| Step: 3
Training loss: 2.7940384103623774
Validation loss: 2.5021383410641986

Epoch: 6| Step: 4
Training loss: 2.545445140288676
Validation loss: 2.5079329256687988

Epoch: 6| Step: 5
Training loss: 2.7669501281975384
Validation loss: 2.4854219840840157

Epoch: 6| Step: 6
Training loss: 2.6410218792680347
Validation loss: 2.4956442737835376

Epoch: 6| Step: 7
Training loss: 3.0004904663971903
Validation loss: 2.490206847644937

Epoch: 6| Step: 8
Training loss: 2.589155240835323
Validation loss: 2.4833053790733324

Epoch: 6| Step: 9
Training loss: 2.747698340854171
Validation loss: 2.484535333360379

Epoch: 6| Step: 10
Training loss: 2.659212950667601
Validation loss: 2.4840406060072597

Epoch: 6| Step: 11
Training loss: 2.995070858532705
Validation loss: 2.4936899814974676

Epoch: 6| Step: 12
Training loss: 2.9278112481568863
Validation loss: 2.512109665478844

Epoch: 6| Step: 13
Training loss: 1.91706245592845
Validation loss: 2.5091685213055497

Epoch: 125| Step: 0
Training loss: 2.7490193612591893
Validation loss: 2.5096959150958074

Epoch: 6| Step: 1
Training loss: 3.215937302144313
Validation loss: 2.515086606642354

Epoch: 6| Step: 2
Training loss: 3.067671943453036
Validation loss: 2.523391085708694

Epoch: 6| Step: 3
Training loss: 2.6518999270549433
Validation loss: 2.524931728098379

Epoch: 6| Step: 4
Training loss: 3.0677159324944787
Validation loss: 2.5119502991507443

Epoch: 6| Step: 5
Training loss: 2.886260495701636
Validation loss: 2.5235888784548806

Epoch: 6| Step: 6
Training loss: 2.2727630768469913
Validation loss: 2.5252756641849854

Epoch: 6| Step: 7
Training loss: 2.8122449123415563
Validation loss: 2.512668447490899

Epoch: 6| Step: 8
Training loss: 2.8048230831771876
Validation loss: 2.4896051580360012

Epoch: 6| Step: 9
Training loss: 2.525797304479405
Validation loss: 2.477777350485908

Epoch: 6| Step: 10
Training loss: 2.299166204828776
Validation loss: 2.479703803819481

Epoch: 6| Step: 11
Training loss: 2.3788565394026167
Validation loss: 2.474272131888214

Epoch: 6| Step: 12
Training loss: 3.0447729440105404
Validation loss: 2.4780363789669555

Epoch: 6| Step: 13
Training loss: 3.039710909750458
Validation loss: 2.4847070858082283

Epoch: 126| Step: 0
Training loss: 2.150988143242683
Validation loss: 2.479263748070191

Epoch: 6| Step: 1
Training loss: 2.7671144429519114
Validation loss: 2.478480692849161

Epoch: 6| Step: 2
Training loss: 2.414271274662127
Validation loss: 2.4864336264698936

Epoch: 6| Step: 3
Training loss: 3.0624051760570987
Validation loss: 2.495631519464422

Epoch: 6| Step: 4
Training loss: 2.7201743067259803
Validation loss: 2.513865438502365

Epoch: 6| Step: 5
Training loss: 2.5712451112484667
Validation loss: 2.527610486670963

Epoch: 6| Step: 6
Training loss: 2.9978327870425634
Validation loss: 2.5439267054829497

Epoch: 6| Step: 7
Training loss: 2.731157513412148
Validation loss: 2.5180992799398103

Epoch: 6| Step: 8
Training loss: 3.3248706362232543
Validation loss: 2.5151282398150725

Epoch: 6| Step: 9
Training loss: 2.558121079908583
Validation loss: 2.5621178254735333

Epoch: 6| Step: 10
Training loss: 2.9937348112545283
Validation loss: 2.688686882391061

Epoch: 6| Step: 11
Training loss: 3.123917353964316
Validation loss: 2.668467321024115

Epoch: 6| Step: 12
Training loss: 3.0689661699595123
Validation loss: 2.612694600366414

Epoch: 6| Step: 13
Training loss: 2.6272177637380167
Validation loss: 2.5242524028289552

Epoch: 127| Step: 0
Training loss: 2.9183720280645256
Validation loss: 2.5276285606238256

Epoch: 6| Step: 1
Training loss: 2.5059324448621694
Validation loss: 2.562496834589666

Epoch: 6| Step: 2
Training loss: 3.1790631405300918
Validation loss: 2.623563860959113

Epoch: 6| Step: 3
Training loss: 2.6630658833357495
Validation loss: 2.625663899946336

Epoch: 6| Step: 4
Training loss: 2.702354630081406
Validation loss: 2.5800896580268735

Epoch: 6| Step: 5
Training loss: 2.8072622058197774
Validation loss: 2.551780374980882

Epoch: 6| Step: 6
Training loss: 3.061874325735248
Validation loss: 2.533753983027206

Epoch: 6| Step: 7
Training loss: 2.2044565492130173
Validation loss: 2.515852435661271

Epoch: 6| Step: 8
Training loss: 3.523489467465988
Validation loss: 2.4991266540201518

Epoch: 6| Step: 9
Training loss: 2.8773553570967185
Validation loss: 2.492614307336337

Epoch: 6| Step: 10
Training loss: 2.7314139764302348
Validation loss: 2.494088071748583

Epoch: 6| Step: 11
Training loss: 2.918151114406804
Validation loss: 2.4877265781637687

Epoch: 6| Step: 12
Training loss: 2.5166937411875074
Validation loss: 2.4847761426116457

Epoch: 6| Step: 13
Training loss: 2.505065744721279
Validation loss: 2.4737314310385123

Epoch: 128| Step: 0
Training loss: 2.538147277208232
Validation loss: 2.4785419572191505

Epoch: 6| Step: 1
Training loss: 3.0431607030379055
Validation loss: 2.482417639821717

Epoch: 6| Step: 2
Training loss: 2.9215906994248564
Validation loss: 2.494453781511441

Epoch: 6| Step: 3
Training loss: 2.60717113875187
Validation loss: 2.4899181292396637

Epoch: 6| Step: 4
Training loss: 2.926272912471453
Validation loss: 2.5077128234156323

Epoch: 6| Step: 5
Training loss: 3.091432261941992
Validation loss: 2.4956826462634303

Epoch: 6| Step: 6
Training loss: 2.326944448708802
Validation loss: 2.4831999171062145

Epoch: 6| Step: 7
Training loss: 2.7410623790792172
Validation loss: 2.5071415060227014

Epoch: 6| Step: 8
Training loss: 2.902920199788539
Validation loss: 2.500707186894093

Epoch: 6| Step: 9
Training loss: 2.5098336414664844
Validation loss: 2.4873050904998464

Epoch: 6| Step: 10
Training loss: 2.8158808415192667
Validation loss: 2.469686924117195

Epoch: 6| Step: 11
Training loss: 2.665534096852707
Validation loss: 2.4754349241170237

Epoch: 6| Step: 12
Training loss: 2.937917963688698
Validation loss: 2.466966607161644

Epoch: 6| Step: 13
Training loss: 2.668649254355738
Validation loss: 2.4662449189607925

Epoch: 129| Step: 0
Training loss: 2.8955224691344905
Validation loss: 2.470698067655344

Epoch: 6| Step: 1
Training loss: 3.219852295799094
Validation loss: 2.476572956138052

Epoch: 6| Step: 2
Training loss: 2.9757860828139084
Validation loss: 2.486918806311999

Epoch: 6| Step: 3
Training loss: 2.135502387086342
Validation loss: 2.4806798267481334

Epoch: 6| Step: 4
Training loss: 3.1226364352714464
Validation loss: 2.51930622642261

Epoch: 6| Step: 5
Training loss: 2.774224999607946
Validation loss: 2.50441552380502

Epoch: 6| Step: 6
Training loss: 3.064166647051978
Validation loss: 2.494062549184484

Epoch: 6| Step: 7
Training loss: 2.878315713633769
Validation loss: 2.4842750568941883

Epoch: 6| Step: 8
Training loss: 2.770985295614974
Validation loss: 2.4933128545982965

Epoch: 6| Step: 9
Training loss: 2.6133458424612632
Validation loss: 2.48065543582865

Epoch: 6| Step: 10
Training loss: 2.597246685581514
Validation loss: 2.46760979902586

Epoch: 6| Step: 11
Training loss: 2.4520282601972907
Validation loss: 2.472120195208208

Epoch: 6| Step: 12
Training loss: 2.338805412480117
Validation loss: 2.474897206793365

Epoch: 6| Step: 13
Training loss: 2.6463568061966107
Validation loss: 2.465354033376956

Epoch: 130| Step: 0
Training loss: 2.741689087873647
Validation loss: 2.4714118861481325

Epoch: 6| Step: 1
Training loss: 2.6112061431401115
Validation loss: 2.483077280127071

Epoch: 6| Step: 2
Training loss: 3.266598205108514
Validation loss: 2.48957653733799

Epoch: 6| Step: 3
Training loss: 2.8107387538197357
Validation loss: 2.4841629250470425

Epoch: 6| Step: 4
Training loss: 2.678131096386731
Validation loss: 2.506679337808664

Epoch: 6| Step: 5
Training loss: 2.4850543550806043
Validation loss: 2.5192331028140607

Epoch: 6| Step: 6
Training loss: 2.638363744673305
Validation loss: 2.5303151075196504

Epoch: 6| Step: 7
Training loss: 2.997259477728122
Validation loss: 2.5418455490299476

Epoch: 6| Step: 8
Training loss: 2.6549991130647776
Validation loss: 2.5561553720938828

Epoch: 6| Step: 9
Training loss: 2.9748786709191104
Validation loss: 2.584628986650171

Epoch: 6| Step: 10
Training loss: 3.175300139410729
Validation loss: 2.5588334296388715

Epoch: 6| Step: 11
Training loss: 2.6715624888624583
Validation loss: 2.5299863781931755

Epoch: 6| Step: 12
Training loss: 2.5508108794520052
Validation loss: 2.500882703550748

Epoch: 6| Step: 13
Training loss: 2.4340155711996347
Validation loss: 2.4866899491091967

Epoch: 131| Step: 0
Training loss: 2.4785633368142137
Validation loss: 2.475257089288143

Epoch: 6| Step: 1
Training loss: 2.4923216206685788
Validation loss: 2.4732763816577017

Epoch: 6| Step: 2
Training loss: 3.072056864480388
Validation loss: 2.47125677627037

Epoch: 6| Step: 3
Training loss: 2.3521321262629344
Validation loss: 2.4824977610237946

Epoch: 6| Step: 4
Training loss: 2.3533062220444525
Validation loss: 2.4780328480616802

Epoch: 6| Step: 5
Training loss: 2.6609266512745395
Validation loss: 2.475069194583424

Epoch: 6| Step: 6
Training loss: 2.982375029050473
Validation loss: 2.474555665178635

Epoch: 6| Step: 7
Training loss: 3.1786347317094164
Validation loss: 2.4784410796577796

Epoch: 6| Step: 8
Training loss: 2.812929417358967
Validation loss: 2.500369721422791

Epoch: 6| Step: 9
Training loss: 3.2313783188507306
Validation loss: 2.5034783683908

Epoch: 6| Step: 10
Training loss: 2.6559606057887892
Validation loss: 2.5087649903398144

Epoch: 6| Step: 11
Training loss: 2.8058785377473683
Validation loss: 2.511335014413041

Epoch: 6| Step: 12
Training loss: 3.1914549582230065
Validation loss: 2.5248793537529797

Epoch: 6| Step: 13
Training loss: 1.549532909155855
Validation loss: 2.517556680605668

Epoch: 132| Step: 0
Training loss: 2.6162979663984594
Validation loss: 2.524669384498327

Epoch: 6| Step: 1
Training loss: 2.40740641759651
Validation loss: 2.5164574440860377

Epoch: 6| Step: 2
Training loss: 2.3884713438861236
Validation loss: 2.513916446354433

Epoch: 6| Step: 3
Training loss: 2.8329278618393623
Validation loss: 2.5275876516391054

Epoch: 6| Step: 4
Training loss: 2.2934818246178224
Validation loss: 2.5120613937284317

Epoch: 6| Step: 5
Training loss: 3.1044626969541422
Validation loss: 2.5288055296159513

Epoch: 6| Step: 6
Training loss: 3.0880510649239006
Validation loss: 2.5277415797391996

Epoch: 6| Step: 7
Training loss: 2.8195891152667376
Validation loss: 2.5380524040146093

Epoch: 6| Step: 8
Training loss: 2.739857436320785
Validation loss: 2.5385055973748507

Epoch: 6| Step: 9
Training loss: 3.0129328753074467
Validation loss: 2.513590402702128

Epoch: 6| Step: 10
Training loss: 2.698408300510174
Validation loss: 2.51931806614594

Epoch: 6| Step: 11
Training loss: 3.125123288583613
Validation loss: 2.5107888846284814

Epoch: 6| Step: 12
Training loss: 2.580069438680022
Validation loss: 2.504420150690957

Epoch: 6| Step: 13
Training loss: 2.233946965973778
Validation loss: 2.4784222735914945

Epoch: 133| Step: 0
Training loss: 2.7346323818597655
Validation loss: 2.4837050997153414

Epoch: 6| Step: 1
Training loss: 2.71336401262052
Validation loss: 2.475937364043264

Epoch: 6| Step: 2
Training loss: 2.9472086744829022
Validation loss: 2.470689893287702

Epoch: 6| Step: 3
Training loss: 3.0910068256817445
Validation loss: 2.480680849339545

Epoch: 6| Step: 4
Training loss: 2.41964215131316
Validation loss: 2.4756165673773447

Epoch: 6| Step: 5
Training loss: 2.661017862339557
Validation loss: 2.4860396429248572

Epoch: 6| Step: 6
Training loss: 2.975211570333214
Validation loss: 2.4810397585711943

Epoch: 6| Step: 7
Training loss: 2.574779304750247
Validation loss: 2.5097443304047893

Epoch: 6| Step: 8
Training loss: 2.9307807205101284
Validation loss: 2.5150358192523665

Epoch: 6| Step: 9
Training loss: 2.308000878953684
Validation loss: 2.5195720923991796

Epoch: 6| Step: 10
Training loss: 2.5216866197151733
Validation loss: 2.543044848489815

Epoch: 6| Step: 11
Training loss: 3.129606285317473
Validation loss: 2.556105415745663

Epoch: 6| Step: 12
Training loss: 2.7529561886251037
Validation loss: 2.5127614356636894

Epoch: 6| Step: 13
Training loss: 2.5775637853890294
Validation loss: 2.519509831387012

Epoch: 134| Step: 0
Training loss: 2.381669367509952
Validation loss: 2.514970317549539

Epoch: 6| Step: 1
Training loss: 3.1430527143193503
Validation loss: 2.5170454049414013

Epoch: 6| Step: 2
Training loss: 2.604672426066863
Validation loss: 2.519889863129258

Epoch: 6| Step: 3
Training loss: 2.8814808320694234
Validation loss: 2.5289559683848877

Epoch: 6| Step: 4
Training loss: 2.9534989377587046
Validation loss: 2.5165900166239865

Epoch: 6| Step: 5
Training loss: 2.7735358422265315
Validation loss: 2.5315142308403664

Epoch: 6| Step: 6
Training loss: 2.142654014224044
Validation loss: 2.547186762902894

Epoch: 6| Step: 7
Training loss: 2.798215065555288
Validation loss: 2.5998198256684053

Epoch: 6| Step: 8
Training loss: 2.7321143696472534
Validation loss: 2.6559615227670674

Epoch: 6| Step: 9
Training loss: 3.025998630097275
Validation loss: 2.6144652356921285

Epoch: 6| Step: 10
Training loss: 2.2848578364181877
Validation loss: 2.543264572291814

Epoch: 6| Step: 11
Training loss: 3.138032061080579
Validation loss: 2.5351386655605332

Epoch: 6| Step: 12
Training loss: 2.770885830336487
Validation loss: 2.5258075334546137

Epoch: 6| Step: 13
Training loss: 2.8006724571901263
Validation loss: 2.5144495122409434

Epoch: 135| Step: 0
Training loss: 2.366413455724214
Validation loss: 2.5343227252768648

Epoch: 6| Step: 1
Training loss: 2.8984059129006585
Validation loss: 2.5456174736360544

Epoch: 6| Step: 2
Training loss: 2.416075623244506
Validation loss: 2.526948600892835

Epoch: 6| Step: 3
Training loss: 2.178744094849385
Validation loss: 2.504050558412152

Epoch: 6| Step: 4
Training loss: 3.139323557987198
Validation loss: 2.489769520394051

Epoch: 6| Step: 5
Training loss: 2.757159190831909
Validation loss: 2.4958472894012727

Epoch: 6| Step: 6
Training loss: 2.665948910280188
Validation loss: 2.485506696320014

Epoch: 6| Step: 7
Training loss: 2.8533525257118737
Validation loss: 2.477278688442036

Epoch: 6| Step: 8
Training loss: 2.540456160487115
Validation loss: 2.482218079447901

Epoch: 6| Step: 9
Training loss: 2.661669419808139
Validation loss: 2.486961914030146

Epoch: 6| Step: 10
Training loss: 3.1816181442000437
Validation loss: 2.4855371554645576

Epoch: 6| Step: 11
Training loss: 3.0491309006449
Validation loss: 2.4893790178508355

Epoch: 6| Step: 12
Training loss: 2.9094835566377095
Validation loss: 2.500628090478115

Epoch: 6| Step: 13
Training loss: 2.4632702624859015
Validation loss: 2.497888043180863

Epoch: 136| Step: 0
Training loss: 3.2818255691714153
Validation loss: 2.5175938657758925

Epoch: 6| Step: 1
Training loss: 2.86931927918723
Validation loss: 2.481740757003365

Epoch: 6| Step: 2
Training loss: 3.003934029201446
Validation loss: 2.4816558180771984

Epoch: 6| Step: 3
Training loss: 2.7737988733538947
Validation loss: 2.494161925361938

Epoch: 6| Step: 4
Training loss: 2.511247890351901
Validation loss: 2.4667149800383528

Epoch: 6| Step: 5
Training loss: 2.7534292687273667
Validation loss: 2.46295244890842

Epoch: 6| Step: 6
Training loss: 3.011014269655305
Validation loss: 2.474461103472218

Epoch: 6| Step: 7
Training loss: 2.56710494704503
Validation loss: 2.4872669515831185

Epoch: 6| Step: 8
Training loss: 2.2172242412251553
Validation loss: 2.4878924021503144

Epoch: 6| Step: 9
Training loss: 2.9758767767385854
Validation loss: 2.506303508748805

Epoch: 6| Step: 10
Training loss: 2.611059866959242
Validation loss: 2.4953145080801202

Epoch: 6| Step: 11
Training loss: 2.856214934620044
Validation loss: 2.5089589058364603

Epoch: 6| Step: 12
Training loss: 2.2780728097387377
Validation loss: 2.485408314993076

Epoch: 6| Step: 13
Training loss: 2.563763469807594
Validation loss: 2.4727995176077373

Epoch: 137| Step: 0
Training loss: 2.421163343652284
Validation loss: 2.461181995169786

Epoch: 6| Step: 1
Training loss: 2.487563192820465
Validation loss: 2.4818686547241384

Epoch: 6| Step: 2
Training loss: 3.240623004732465
Validation loss: 2.4755341657458847

Epoch: 6| Step: 3
Training loss: 3.054704983166081
Validation loss: 2.489490969847829

Epoch: 6| Step: 4
Training loss: 2.643962849735459
Validation loss: 2.4870162712842214

Epoch: 6| Step: 5
Training loss: 2.8232933628295975
Validation loss: 2.501813254556881

Epoch: 6| Step: 6
Training loss: 2.226956730792665
Validation loss: 2.51891423859945

Epoch: 6| Step: 7
Training loss: 2.52090194440636
Validation loss: 2.5425265885054014

Epoch: 6| Step: 8
Training loss: 2.883077800504136
Validation loss: 2.5205688720902026

Epoch: 6| Step: 9
Training loss: 2.1481465090578533
Validation loss: 2.517897173691342

Epoch: 6| Step: 10
Training loss: 2.9967990328614587
Validation loss: 2.5198602139689235

Epoch: 6| Step: 11
Training loss: 3.054318769205483
Validation loss: 2.510457230835355

Epoch: 6| Step: 12
Training loss: 2.5644897551291947
Validation loss: 2.4943063298855934

Epoch: 6| Step: 13
Training loss: 2.8607167915617646
Validation loss: 2.4761198266768214

Epoch: 138| Step: 0
Training loss: 2.8371922263047153
Validation loss: 2.490427281345314

Epoch: 6| Step: 1
Training loss: 2.3141354113418617
Validation loss: 2.495417653023272

Epoch: 6| Step: 2
Training loss: 2.640810627027668
Validation loss: 2.507325334765675

Epoch: 6| Step: 3
Training loss: 2.817939245853742
Validation loss: 2.5312645163677496

Epoch: 6| Step: 4
Training loss: 2.7353088528105327
Validation loss: 2.537869989810639

Epoch: 6| Step: 5
Training loss: 2.9225358674627837
Validation loss: 2.536771865882319

Epoch: 6| Step: 6
Training loss: 2.6324704454579764
Validation loss: 2.527953034045924

Epoch: 6| Step: 7
Training loss: 2.2209034529942926
Validation loss: 2.5144755507352023

Epoch: 6| Step: 8
Training loss: 2.6713963129997014
Validation loss: 2.515045715866072

Epoch: 6| Step: 9
Training loss: 3.102013235707087
Validation loss: 2.490297328821586

Epoch: 6| Step: 10
Training loss: 3.494023397322576
Validation loss: 2.4992122619122275

Epoch: 6| Step: 11
Training loss: 2.657911521506773
Validation loss: 2.491854835475848

Epoch: 6| Step: 12
Training loss: 1.9871099053230876
Validation loss: 2.495486948151897

Epoch: 6| Step: 13
Training loss: 2.738356650453072
Validation loss: 2.482062373415047

Epoch: 139| Step: 0
Training loss: 2.5121932226752426
Validation loss: 2.486270477869356

Epoch: 6| Step: 1
Training loss: 2.8296309197433813
Validation loss: 2.4935241647127633

Epoch: 6| Step: 2
Training loss: 2.463978369128661
Validation loss: 2.50073534702755

Epoch: 6| Step: 3
Training loss: 2.544326255816816
Validation loss: 2.5184684280304244

Epoch: 6| Step: 4
Training loss: 2.0973729913789345
Validation loss: 2.511536573880682

Epoch: 6| Step: 5
Training loss: 2.7421586342186197
Validation loss: 2.512619144743339

Epoch: 6| Step: 6
Training loss: 2.4648651267211408
Validation loss: 2.5072475867008506

Epoch: 6| Step: 7
Training loss: 2.769751966368143
Validation loss: 2.517108615031712

Epoch: 6| Step: 8
Training loss: 2.2673518472910335
Validation loss: 2.509048525839301

Epoch: 6| Step: 9
Training loss: 3.2118790260136794
Validation loss: 2.492003844626035

Epoch: 6| Step: 10
Training loss: 2.688842704164384
Validation loss: 2.5013284568401715

Epoch: 6| Step: 11
Training loss: 3.0812894559427084
Validation loss: 2.4903838764042425

Epoch: 6| Step: 12
Training loss: 3.015916563180164
Validation loss: 2.4931362996255997

Epoch: 6| Step: 13
Training loss: 3.0880601753143195
Validation loss: 2.498164466007333

Epoch: 140| Step: 0
Training loss: 2.7926639844101864
Validation loss: 2.512238385612048

Epoch: 6| Step: 1
Training loss: 2.922158130656855
Validation loss: 2.5093677221769974

Epoch: 6| Step: 2
Training loss: 2.3565086485867726
Validation loss: 2.4967838447570068

Epoch: 6| Step: 3
Training loss: 2.410667229248645
Validation loss: 2.5163055092597486

Epoch: 6| Step: 4
Training loss: 2.948706010116003
Validation loss: 2.513644121905102

Epoch: 6| Step: 5
Training loss: 2.146695849455241
Validation loss: 2.518615293644978

Epoch: 6| Step: 6
Training loss: 2.7003739309988197
Validation loss: 2.5400585952493926

Epoch: 6| Step: 7
Training loss: 2.092176500879823
Validation loss: 2.5676774005607093

Epoch: 6| Step: 8
Training loss: 3.21219270772741
Validation loss: 2.597793651212671

Epoch: 6| Step: 9
Training loss: 3.548509263287639
Validation loss: 2.6027976597306943

Epoch: 6| Step: 10
Training loss: 2.5210626250935446
Validation loss: 2.577254575064913

Epoch: 6| Step: 11
Training loss: 2.9868977853497016
Validation loss: 2.554948633671098

Epoch: 6| Step: 12
Training loss: 2.5351334910260204
Validation loss: 2.560711047864457

Epoch: 6| Step: 13
Training loss: 3.0602642384052894
Validation loss: 2.534091540007703

Epoch: 141| Step: 0
Training loss: 2.7818824820416803
Validation loss: 2.5273526895536174

Epoch: 6| Step: 1
Training loss: 2.6596388796859083
Validation loss: 2.515985545473134

Epoch: 6| Step: 2
Training loss: 2.556204902232461
Validation loss: 2.5218727601484057

Epoch: 6| Step: 3
Training loss: 2.106850476796963
Validation loss: 2.530538126914583

Epoch: 6| Step: 4
Training loss: 2.5506264608949656
Validation loss: 2.5229490058710677

Epoch: 6| Step: 5
Training loss: 2.7539218334000584
Validation loss: 2.5410879603639676

Epoch: 6| Step: 6
Training loss: 3.3047382900943343
Validation loss: 2.547075226618137

Epoch: 6| Step: 7
Training loss: 2.759162982818009
Validation loss: 2.519187714187831

Epoch: 6| Step: 8
Training loss: 2.944395048898753
Validation loss: 2.5378397678301887

Epoch: 6| Step: 9
Training loss: 2.705411880781119
Validation loss: 2.5569333174872213

Epoch: 6| Step: 10
Training loss: 3.0090026878682155
Validation loss: 2.617491328909333

Epoch: 6| Step: 11
Training loss: 2.6685038039845255
Validation loss: 2.611165375219494

Epoch: 6| Step: 12
Training loss: 2.96777102742375
Validation loss: 2.611629834996117

Epoch: 6| Step: 13
Training loss: 2.229137551185869
Validation loss: 2.564729394556411

Epoch: 142| Step: 0
Training loss: 3.0178906720218293
Validation loss: 2.5436830260513386

Epoch: 6| Step: 1
Training loss: 2.604130299632136
Validation loss: 2.529538557300031

Epoch: 6| Step: 2
Training loss: 2.474876624220841
Validation loss: 2.5039679109971855

Epoch: 6| Step: 3
Training loss: 3.0641518633784623
Validation loss: 2.5173346324561083

Epoch: 6| Step: 4
Training loss: 2.823258908254273
Validation loss: 2.5119261011352583

Epoch: 6| Step: 5
Training loss: 2.5361016954254407
Validation loss: 2.5047349646104093

Epoch: 6| Step: 6
Training loss: 3.0242764198679875
Validation loss: 2.505652279971783

Epoch: 6| Step: 7
Training loss: 2.0520487619447363
Validation loss: 2.5122328077674654

Epoch: 6| Step: 8
Training loss: 2.587017836312767
Validation loss: 2.520303387940732

Epoch: 6| Step: 9
Training loss: 3.035085237867801
Validation loss: 2.5188021862360523

Epoch: 6| Step: 10
Training loss: 2.4716139972688618
Validation loss: 2.5204645675461768

Epoch: 6| Step: 11
Training loss: 2.633587550515545
Validation loss: 2.5340614317969297

Epoch: 6| Step: 12
Training loss: 2.4625845105536284
Validation loss: 2.5508827310267757

Epoch: 6| Step: 13
Training loss: 3.0589311006885667
Validation loss: 2.5476799769887735

Epoch: 143| Step: 0
Training loss: 2.2309092071744017
Validation loss: 2.526027433209184

Epoch: 6| Step: 1
Training loss: 3.21610573603336
Validation loss: 2.509077138989768

Epoch: 6| Step: 2
Training loss: 2.6720065257398216
Validation loss: 2.506932120910769

Epoch: 6| Step: 3
Training loss: 2.672898302934399
Validation loss: 2.4911421614708633

Epoch: 6| Step: 4
Training loss: 2.6038798873670177
Validation loss: 2.4991570774446923

Epoch: 6| Step: 5
Training loss: 2.593768567857579
Validation loss: 2.5080500153443297

Epoch: 6| Step: 6
Training loss: 2.846131386142864
Validation loss: 2.5035217849006206

Epoch: 6| Step: 7
Training loss: 2.7273058383550044
Validation loss: 2.517001779662705

Epoch: 6| Step: 8
Training loss: 3.1891738386217234
Validation loss: 2.502723063499567

Epoch: 6| Step: 9
Training loss: 3.3640416578328463
Validation loss: 2.503807254431701

Epoch: 6| Step: 10
Training loss: 1.8004101683271228
Validation loss: 2.533653931686865

Epoch: 6| Step: 11
Training loss: 2.449000688059762
Validation loss: 2.551076752227311

Epoch: 6| Step: 12
Training loss: 2.2980711021877562
Validation loss: 2.581691467954192

Epoch: 6| Step: 13
Training loss: 2.7849674027074474
Validation loss: 2.57241972890851

Epoch: 144| Step: 0
Training loss: 2.5818393653288765
Validation loss: 2.5663624828417078

Epoch: 6| Step: 1
Training loss: 2.3682150042845675
Validation loss: 2.557822025597629

Epoch: 6| Step: 2
Training loss: 2.509019222667853
Validation loss: 2.5472060838350483

Epoch: 6| Step: 3
Training loss: 2.197518540131667
Validation loss: 2.5917760565625367

Epoch: 6| Step: 4
Training loss: 2.2625772958271027
Validation loss: 2.609531873634907

Epoch: 6| Step: 5
Training loss: 3.154038967300654
Validation loss: 2.600934664189334

Epoch: 6| Step: 6
Training loss: 2.1870007626462846
Validation loss: 2.5548818368267523

Epoch: 6| Step: 7
Training loss: 2.6441724976207723
Validation loss: 2.5435148110002355

Epoch: 6| Step: 8
Training loss: 2.8946857694291017
Validation loss: 2.535384063089095

Epoch: 6| Step: 9
Training loss: 2.778324431565488
Validation loss: 2.5717904775312066

Epoch: 6| Step: 10
Training loss: 2.9531020713602283
Validation loss: 2.5608521021730883

Epoch: 6| Step: 11
Training loss: 2.4565627192638004
Validation loss: 2.604128922383771

Epoch: 6| Step: 12
Training loss: 3.11626663564686
Validation loss: 2.6438068506446926

Epoch: 6| Step: 13
Training loss: 3.796076686747769
Validation loss: 2.631436774542704

Epoch: 145| Step: 0
Training loss: 3.0315414760494868
Validation loss: 2.604692325493699

Epoch: 6| Step: 1
Training loss: 2.882813161627634
Validation loss: 2.578823690246081

Epoch: 6| Step: 2
Training loss: 2.0045361337580694
Validation loss: 2.558406611761908

Epoch: 6| Step: 3
Training loss: 2.8860189495561643
Validation loss: 2.550195440611895

Epoch: 6| Step: 4
Training loss: 2.50309866559181
Validation loss: 2.537766013494449

Epoch: 6| Step: 5
Training loss: 3.0480198983271327
Validation loss: 2.5393131356422685

Epoch: 6| Step: 6
Training loss: 2.7381268728494064
Validation loss: 2.5321988892510605

Epoch: 6| Step: 7
Training loss: 2.6520488951535484
Validation loss: 2.531601993136236

Epoch: 6| Step: 8
Training loss: 2.8995916736817398
Validation loss: 2.513229302472076

Epoch: 6| Step: 9
Training loss: 2.9354984688083174
Validation loss: 2.521772938876277

Epoch: 6| Step: 10
Training loss: 2.4111567419200366
Validation loss: 2.521039829391694

Epoch: 6| Step: 11
Training loss: 2.460565448066511
Validation loss: 2.5422069066861672

Epoch: 6| Step: 12
Training loss: 2.2077555590371576
Validation loss: 2.531708109105454

Epoch: 6| Step: 13
Training loss: 2.3072644326100344
Validation loss: 2.527392352672248

Epoch: 146| Step: 0
Training loss: 2.562328984206209
Validation loss: 2.515336899848023

Epoch: 6| Step: 1
Training loss: 2.332641521711177
Validation loss: 2.5114872131866197

Epoch: 6| Step: 2
Training loss: 2.297103040105422
Validation loss: 2.5264765065882857

Epoch: 6| Step: 3
Training loss: 2.6406317716432683
Validation loss: 2.53914021589991

Epoch: 6| Step: 4
Training loss: 2.2595786608319934
Validation loss: 2.517319025506591

Epoch: 6| Step: 5
Training loss: 3.1145996977887576
Validation loss: 2.521593348635916

Epoch: 6| Step: 6
Training loss: 2.47328542023732
Validation loss: 2.5249155670283066

Epoch: 6| Step: 7
Training loss: 2.3708396410955936
Validation loss: 2.523739433150041

Epoch: 6| Step: 8
Training loss: 2.5742222694754964
Validation loss: 2.5161539259400376

Epoch: 6| Step: 9
Training loss: 3.0749420904893934
Validation loss: 2.53624388995291

Epoch: 6| Step: 10
Training loss: 3.095574043543074
Validation loss: 2.543657541530989

Epoch: 6| Step: 11
Training loss: 2.9846025150514706
Validation loss: 2.547267117371949

Epoch: 6| Step: 12
Training loss: 2.3191613832341154
Validation loss: 2.5651844898867484

Epoch: 6| Step: 13
Training loss: 2.665054897150879
Validation loss: 2.604628751715146

Epoch: 147| Step: 0
Training loss: 2.3911573029341855
Validation loss: 2.623000657561969

Epoch: 6| Step: 1
Training loss: 3.1169543645196423
Validation loss: 2.6042019677179358

Epoch: 6| Step: 2
Training loss: 3.004412426113313
Validation loss: 2.608964211399247

Epoch: 6| Step: 3
Training loss: 2.797063213813787
Validation loss: 2.5842479290229323

Epoch: 6| Step: 4
Training loss: 2.4929588343973914
Validation loss: 2.5802757025633554

Epoch: 6| Step: 5
Training loss: 2.4309545813099023
Validation loss: 2.574613058676452

Epoch: 6| Step: 6
Training loss: 2.28978824502655
Validation loss: 2.589437394180401

Epoch: 6| Step: 7
Training loss: 2.711017178730445
Validation loss: 2.587483322401308

Epoch: 6| Step: 8
Training loss: 2.468912433157583
Validation loss: 2.571294273946748

Epoch: 6| Step: 9
Training loss: 2.9156708970295595
Validation loss: 2.565393460525249

Epoch: 6| Step: 10
Training loss: 2.306872660620988
Validation loss: 2.539143730485997

Epoch: 6| Step: 11
Training loss: 2.7484218230459128
Validation loss: 2.5573414247451898

Epoch: 6| Step: 12
Training loss: 2.674329021118344
Validation loss: 2.547677531764181

Epoch: 6| Step: 13
Training loss: 3.056906594109454
Validation loss: 2.549994114839445

Epoch: 148| Step: 0
Training loss: 2.1243125701197663
Validation loss: 2.5650415829638864

Epoch: 6| Step: 1
Training loss: 2.764726137115706
Validation loss: 2.5750040414493527

Epoch: 6| Step: 2
Training loss: 2.3956567008102825
Validation loss: 2.5653627633299014

Epoch: 6| Step: 3
Training loss: 3.4100400505063178
Validation loss: 2.5379574050499905

Epoch: 6| Step: 4
Training loss: 2.6124017030758577
Validation loss: 2.529731829967642

Epoch: 6| Step: 5
Training loss: 2.9555678179334355
Validation loss: 2.559586846698226

Epoch: 6| Step: 6
Training loss: 2.499369541781342
Validation loss: 2.6069110616571036

Epoch: 6| Step: 7
Training loss: 2.5586420185690324
Validation loss: 2.6546490780936067

Epoch: 6| Step: 8
Training loss: 2.6608282688410063
Validation loss: 2.7251938873492905

Epoch: 6| Step: 9
Training loss: 3.288391479761788
Validation loss: 2.7273060235330586

Epoch: 6| Step: 10
Training loss: 2.1950288093779142
Validation loss: 2.5964740879307735

Epoch: 6| Step: 11
Training loss: 2.879635101354956
Validation loss: 2.587606127334385

Epoch: 6| Step: 12
Training loss: 2.349284947956104
Validation loss: 2.5362674071654037

Epoch: 6| Step: 13
Training loss: 3.1337033952824083
Validation loss: 2.526357894367855

Epoch: 149| Step: 0
Training loss: 2.5115089625525795
Validation loss: 2.554982768176601

Epoch: 6| Step: 1
Training loss: 3.016783496708974
Validation loss: 2.6171436348381136

Epoch: 6| Step: 2
Training loss: 3.2250730757603217
Validation loss: 2.680865651565488

Epoch: 6| Step: 3
Training loss: 3.4975851447516755
Validation loss: 2.606775147089236

Epoch: 6| Step: 4
Training loss: 2.809300022164324
Validation loss: 2.5604939245534184

Epoch: 6| Step: 5
Training loss: 2.4691127076069677
Validation loss: 2.5186598752461133

Epoch: 6| Step: 6
Training loss: 2.3701949450638446
Validation loss: 2.514134127235391

Epoch: 6| Step: 7
Training loss: 2.62453810851558
Validation loss: 2.5014113380210494

Epoch: 6| Step: 8
Training loss: 2.4854852846516162
Validation loss: 2.5111361268209196

Epoch: 6| Step: 9
Training loss: 2.8341701244260995
Validation loss: 2.4990254912648293

Epoch: 6| Step: 10
Training loss: 2.7384513769480536
Validation loss: 2.5079866157886768

Epoch: 6| Step: 11
Training loss: 2.6765231029953616
Validation loss: 2.5246818702707214

Epoch: 6| Step: 12
Training loss: 1.9789636072761267
Validation loss: 2.5531208078410206

Epoch: 6| Step: 13
Training loss: 1.6462223301490513
Validation loss: 2.6004750018230833

Epoch: 150| Step: 0
Training loss: 1.9134337346165922
Validation loss: 2.638159177096562

Epoch: 6| Step: 1
Training loss: 2.946653834727844
Validation loss: 2.6307627526210426

Epoch: 6| Step: 2
Training loss: 2.5898168686152054
Validation loss: 2.601382817599706

Epoch: 6| Step: 3
Training loss: 3.0247352042832234
Validation loss: 2.575610803655375

Epoch: 6| Step: 4
Training loss: 2.672905082013503
Validation loss: 2.5577631663310267

Epoch: 6| Step: 5
Training loss: 1.5961420396398205
Validation loss: 2.5476065397328607

Epoch: 6| Step: 6
Training loss: 2.628627994769837
Validation loss: 2.525054690786977

Epoch: 6| Step: 7
Training loss: 2.6455550360310847
Validation loss: 2.5302085987681746

Epoch: 6| Step: 8
Training loss: 3.5187442759167475
Validation loss: 2.532733525544755

Epoch: 6| Step: 9
Training loss: 2.7020938207402723
Validation loss: 2.527918707974117

Epoch: 6| Step: 10
Training loss: 2.6383210915405786
Validation loss: 2.5377345755005023

Epoch: 6| Step: 11
Training loss: 3.0253874727630445
Validation loss: 2.5439597806113072

Epoch: 6| Step: 12
Training loss: 2.65376865950002
Validation loss: 2.5603944375088066

Epoch: 6| Step: 13
Training loss: 2.1043833126927
Validation loss: 2.5470940129403856

Epoch: 151| Step: 0
Training loss: 2.8484280852362582
Validation loss: 2.577937479616968

Epoch: 6| Step: 1
Training loss: 2.546910759610441
Validation loss: 2.5831051026694962

Epoch: 6| Step: 2
Training loss: 3.028758489995968
Validation loss: 2.602851703694031

Epoch: 6| Step: 3
Training loss: 2.6306025345002317
Validation loss: 2.5846156527789894

Epoch: 6| Step: 4
Training loss: 2.802647520839557
Validation loss: 2.5937238697604337

Epoch: 6| Step: 5
Training loss: 2.6577820791289795
Validation loss: 2.6103984242255662

Epoch: 6| Step: 6
Training loss: 2.866982268178477
Validation loss: 2.6180559006020685

Epoch: 6| Step: 7
Training loss: 1.9477554975394602
Validation loss: 2.6228543881949973

Epoch: 6| Step: 8
Training loss: 2.511164721288966
Validation loss: 2.621180417256654

Epoch: 6| Step: 9
Training loss: 2.8126269841667573
Validation loss: 2.6325827575897214

Epoch: 6| Step: 10
Training loss: 2.2683518409768118
Validation loss: 2.6510667120179208

Epoch: 6| Step: 11
Training loss: 2.3323631881054134
Validation loss: 2.676866397053788

Epoch: 6| Step: 12
Training loss: 2.9472559176032975
Validation loss: 2.7152051624747737

Epoch: 6| Step: 13
Training loss: 2.2840798997549
Validation loss: 2.726882425462327

Epoch: 152| Step: 0
Training loss: 2.697239372241673
Validation loss: 2.7890152217573276

Epoch: 6| Step: 1
Training loss: 2.245037327989212
Validation loss: 2.754673426688503

Epoch: 6| Step: 2
Training loss: 2.9306637370876194
Validation loss: 2.7244185948208535

Epoch: 6| Step: 3
Training loss: 3.063913758600526
Validation loss: 2.6408038762294157

Epoch: 6| Step: 4
Training loss: 2.572459150607249
Validation loss: 2.596411563935259

Epoch: 6| Step: 5
Training loss: 2.428414946812045
Validation loss: 2.5523487173240946

Epoch: 6| Step: 6
Training loss: 2.053167440826388
Validation loss: 2.532629787789227

Epoch: 6| Step: 7
Training loss: 2.1987685832007657
Validation loss: 2.511308004184632

Epoch: 6| Step: 8
Training loss: 2.9916229910748346
Validation loss: 2.5060087156009754

Epoch: 6| Step: 9
Training loss: 2.950421907674998
Validation loss: 2.5091100420746497

Epoch: 6| Step: 10
Training loss: 2.577911738042671
Validation loss: 2.50781870512076

Epoch: 6| Step: 11
Training loss: 2.9314413695506163
Validation loss: 2.506953546767741

Epoch: 6| Step: 12
Training loss: 2.383043321779993
Validation loss: 2.503453799707198

Epoch: 6| Step: 13
Training loss: 3.008394417886687
Validation loss: 2.5055362242178396

Epoch: 153| Step: 0
Training loss: 2.8560989039416476
Validation loss: 2.496145428608761

Epoch: 6| Step: 1
Training loss: 2.4913393688106678
Validation loss: 2.492701603410406

Epoch: 6| Step: 2
Training loss: 2.6064099123263396
Validation loss: 2.50144635067201

Epoch: 6| Step: 3
Training loss: 2.1650559111108616
Validation loss: 2.522643597048695

Epoch: 6| Step: 4
Training loss: 2.164259698469533
Validation loss: 2.521002376756137

Epoch: 6| Step: 5
Training loss: 3.412462221712032
Validation loss: 2.551305881906012

Epoch: 6| Step: 6
Training loss: 2.493670653034531
Validation loss: 2.5238655956736116

Epoch: 6| Step: 7
Training loss: 2.74848462748067
Validation loss: 2.5253064761012225

Epoch: 6| Step: 8
Training loss: 2.488453522232636
Validation loss: 2.513891645192925

Epoch: 6| Step: 9
Training loss: 2.619439366177162
Validation loss: 2.485402480954313

Epoch: 6| Step: 10
Training loss: 2.5844809126456303
Validation loss: 2.51755697591411

Epoch: 6| Step: 11
Training loss: 2.2272178354735783
Validation loss: 2.5362977792832506

Epoch: 6| Step: 12
Training loss: 2.502626565177363
Validation loss: 2.5645773266284055

Epoch: 6| Step: 13
Training loss: 2.889368062342113
Validation loss: 2.590633153920509

Epoch: 154| Step: 0
Training loss: 2.8268070416712714
Validation loss: 2.643973234350844

Epoch: 6| Step: 1
Training loss: 2.4255620639325577
Validation loss: 2.6543523776959765

Epoch: 6| Step: 2
Training loss: 2.581367441974001
Validation loss: 2.669724705503632

Epoch: 6| Step: 3
Training loss: 3.07527888824388
Validation loss: 2.672051734358764

Epoch: 6| Step: 4
Training loss: 2.4748101518046965
Validation loss: 2.670321649324638

Epoch: 6| Step: 5
Training loss: 2.5744326883193143
Validation loss: 2.6481722518219515

Epoch: 6| Step: 6
Training loss: 2.786652450692574
Validation loss: 2.6408035073328393

Epoch: 6| Step: 7
Training loss: 2.5912437739943823
Validation loss: 2.614108941524178

Epoch: 6| Step: 8
Training loss: 2.6182538493439655
Validation loss: 2.6059795784780055

Epoch: 6| Step: 9
Training loss: 2.8086636976251573
Validation loss: 2.5954407351829234

Epoch: 6| Step: 10
Training loss: 2.6672689433253316
Validation loss: 2.5632480256871393

Epoch: 6| Step: 11
Training loss: 3.007449120703964
Validation loss: 2.5443116215207677

Epoch: 6| Step: 12
Training loss: 2.316098892380174
Validation loss: 2.5446956028584706

Epoch: 6| Step: 13
Training loss: 1.3422532728286378
Validation loss: 2.520088714998444

Epoch: 155| Step: 0
Training loss: 2.579094721746418
Validation loss: 2.512331727462568

Epoch: 6| Step: 1
Training loss: 2.835107771290027
Validation loss: 2.5272527124432638

Epoch: 6| Step: 2
Training loss: 2.8126298662508664
Validation loss: 2.528482453251892

Epoch: 6| Step: 3
Training loss: 2.8539400405199147
Validation loss: 2.5458847215392035

Epoch: 6| Step: 4
Training loss: 2.3944420354506
Validation loss: 2.5634039968287854

Epoch: 6| Step: 5
Training loss: 3.0901281561092575
Validation loss: 2.5455377428650046

Epoch: 6| Step: 6
Training loss: 2.456052163579717
Validation loss: 2.5591077844143064

Epoch: 6| Step: 7
Training loss: 2.4785364028384396
Validation loss: 2.5550925776709046

Epoch: 6| Step: 8
Training loss: 2.1631516285171837
Validation loss: 2.5237412636396273

Epoch: 6| Step: 9
Training loss: 2.58306910076155
Validation loss: 2.540701909154852

Epoch: 6| Step: 10
Training loss: 2.4695218967935224
Validation loss: 2.551433245542285

Epoch: 6| Step: 11
Training loss: 2.619091286646123
Validation loss: 2.556649579434409

Epoch: 6| Step: 12
Training loss: 2.7550134908411605
Validation loss: 2.5759772210908563

Epoch: 6| Step: 13
Training loss: 2.168399142596623
Validation loss: 2.5567415175012504

Epoch: 156| Step: 0
Training loss: 2.515131362912299
Validation loss: 2.5769788464643812

Epoch: 6| Step: 1
Training loss: 2.208738709676197
Validation loss: 2.5388581820207645

Epoch: 6| Step: 2
Training loss: 2.403760439591692
Validation loss: 2.544797101916491

Epoch: 6| Step: 3
Training loss: 2.5946708790953035
Validation loss: 2.5571910468359578

Epoch: 6| Step: 4
Training loss: 2.1053534707976027
Validation loss: 2.5593871231029377

Epoch: 6| Step: 5
Training loss: 3.090360692277525
Validation loss: 2.5813814033969305

Epoch: 6| Step: 6
Training loss: 2.6597162406550896
Validation loss: 2.6027917923424164

Epoch: 6| Step: 7
Training loss: 2.8652170670915553
Validation loss: 2.6054359568403065

Epoch: 6| Step: 8
Training loss: 2.1666732078844757
Validation loss: 2.6315847432030073

Epoch: 6| Step: 9
Training loss: 2.5420548397964815
Validation loss: 2.6360726140669146

Epoch: 6| Step: 10
Training loss: 2.900115234453264
Validation loss: 2.6256179101839963

Epoch: 6| Step: 11
Training loss: 2.120847571824198
Validation loss: 2.5778703222587382

Epoch: 6| Step: 12
Training loss: 2.6538582299722155
Validation loss: 2.5429836672415984

Epoch: 6| Step: 13
Training loss: 2.960777580351158
Validation loss: 2.559780867153606

Epoch: 157| Step: 0
Training loss: 2.683780313861641
Validation loss: 2.549501889419056

Epoch: 6| Step: 1
Training loss: 2.066539623088303
Validation loss: 2.5685443957667995

Epoch: 6| Step: 2
Training loss: 2.514559692001984
Validation loss: 2.5992686271613157

Epoch: 6| Step: 3
Training loss: 2.4390211005304994
Validation loss: 2.6110753721160647

Epoch: 6| Step: 4
Training loss: 2.506583414707453
Validation loss: 2.5975350413886713

Epoch: 6| Step: 5
Training loss: 2.4113357106306856
Validation loss: 2.536550634171602

Epoch: 6| Step: 6
Training loss: 2.2733498258169575
Validation loss: 2.5021827623557567

Epoch: 6| Step: 7
Training loss: 2.8867488131680505
Validation loss: 2.4910429293146374

Epoch: 6| Step: 8
Training loss: 2.703201028272846
Validation loss: 2.4805967990831315

Epoch: 6| Step: 9
Training loss: 2.5922254195150223
Validation loss: 2.4866840716846546

Epoch: 6| Step: 10
Training loss: 2.4942858242227777
Validation loss: 2.494337044382904

Epoch: 6| Step: 11
Training loss: 3.134044528627804
Validation loss: 2.5127474500607865

Epoch: 6| Step: 12
Training loss: 2.166669356515633
Validation loss: 2.5209305867454512

Epoch: 6| Step: 13
Training loss: 3.556974174365005
Validation loss: 2.541570975003326

Epoch: 158| Step: 0
Training loss: 2.4147585757243775
Validation loss: 2.5840822504422434

Epoch: 6| Step: 1
Training loss: 2.872893349430951
Validation loss: 2.615601664912327

Epoch: 6| Step: 2
Training loss: 2.4668479062417483
Validation loss: 2.618104551487579

Epoch: 6| Step: 3
Training loss: 3.038658448648269
Validation loss: 2.636942993011095

Epoch: 6| Step: 4
Training loss: 2.4477231754098994
Validation loss: 2.6506674506633043

Epoch: 6| Step: 5
Training loss: 2.300359871947498
Validation loss: 2.6504840712087825

Epoch: 6| Step: 6
Training loss: 2.6407414698449907
Validation loss: 2.635763440673373

Epoch: 6| Step: 7
Training loss: 2.6784670527875925
Validation loss: 2.6786717290894417

Epoch: 6| Step: 8
Training loss: 2.8947187149356384
Validation loss: 2.645840320637683

Epoch: 6| Step: 9
Training loss: 3.0723821832526403
Validation loss: 2.6022452221353585

Epoch: 6| Step: 10
Training loss: 2.2227281180027525
Validation loss: 2.52981240647204

Epoch: 6| Step: 11
Training loss: 2.688358169869784
Validation loss: 2.5180264419877365

Epoch: 6| Step: 12
Training loss: 2.447689278504865
Validation loss: 2.504550822908597

Epoch: 6| Step: 13
Training loss: 2.5146789667442904
Validation loss: 2.5020518465837522

Epoch: 159| Step: 0
Training loss: 2.8891716680124935
Validation loss: 2.506011893029177

Epoch: 6| Step: 1
Training loss: 2.7663100951192003
Validation loss: 2.542477411009735

Epoch: 6| Step: 2
Training loss: 2.777850269855202
Validation loss: 2.5633789908986406

Epoch: 6| Step: 3
Training loss: 2.50415456793259
Validation loss: 2.542040072412916

Epoch: 6| Step: 4
Training loss: 2.3982299317246296
Validation loss: 2.514624891416801

Epoch: 6| Step: 5
Training loss: 2.5255631036119306
Validation loss: 2.487273873794077

Epoch: 6| Step: 6
Training loss: 2.7263688945074893
Validation loss: 2.4753090066548786

Epoch: 6| Step: 7
Training loss: 2.225497985146441
Validation loss: 2.444197759874163

Epoch: 6| Step: 8
Training loss: 3.0383651443241875
Validation loss: 2.465066999820202

Epoch: 6| Step: 9
Training loss: 1.5558468124031881
Validation loss: 2.469571752663404

Epoch: 6| Step: 10
Training loss: 2.0053520118134323
Validation loss: 2.4545436864182717

Epoch: 6| Step: 11
Training loss: 3.261212155410196
Validation loss: 2.469746100669012

Epoch: 6| Step: 12
Training loss: 2.25875634129726
Validation loss: 2.4701594074047337

Epoch: 6| Step: 13
Training loss: 3.151150653730298
Validation loss: 2.471437716274719

Epoch: 160| Step: 0
Training loss: 3.2675425179246425
Validation loss: 2.4822048874285847

Epoch: 6| Step: 1
Training loss: 2.362189830622941
Validation loss: 2.516484321619709

Epoch: 6| Step: 2
Training loss: 2.07690003509999
Validation loss: 2.510966039718575

Epoch: 6| Step: 3
Training loss: 2.6522842423023465
Validation loss: 2.5008645090856123

Epoch: 6| Step: 4
Training loss: 2.6269001214448324
Validation loss: 2.5116470845446583

Epoch: 6| Step: 5
Training loss: 2.156046318717339
Validation loss: 2.511399596254359

Epoch: 6| Step: 6
Training loss: 2.252132888328727
Validation loss: 2.523484709913439

Epoch: 6| Step: 7
Training loss: 2.4897276598436284
Validation loss: 2.519806563189517

Epoch: 6| Step: 8
Training loss: 2.8059731939534895
Validation loss: 2.5452550410067567

Epoch: 6| Step: 9
Training loss: 2.2706092467261643
Validation loss: 2.559141493795267

Epoch: 6| Step: 10
Training loss: 2.128337259112237
Validation loss: 2.567443339433596

Epoch: 6| Step: 11
Training loss: 2.654162136135896
Validation loss: 2.5815952635333708

Epoch: 6| Step: 12
Training loss: 2.7123371655507147
Validation loss: 2.594854104788341

Epoch: 6| Step: 13
Training loss: 2.092712145115628
Validation loss: 2.58369889254717

Epoch: 161| Step: 0
Training loss: 2.5773401163797702
Validation loss: 2.590058252583253

Epoch: 6| Step: 1
Training loss: 2.0107190657440026
Validation loss: 2.5764157543022352

Epoch: 6| Step: 2
Training loss: 2.464871027050437
Validation loss: 2.5829109950847884

Epoch: 6| Step: 3
Training loss: 1.8236860849477041
Validation loss: 2.580233075807387

Epoch: 6| Step: 4
Training loss: 2.3130737830044588
Validation loss: 2.5921904165616017

Epoch: 6| Step: 5
Training loss: 3.1762328630305605
Validation loss: 2.582022182034212

Epoch: 6| Step: 6
Training loss: 2.4368298905476165
Validation loss: 2.561339857316191

Epoch: 6| Step: 7
Training loss: 2.173677752864283
Validation loss: 2.5340405290363304

Epoch: 6| Step: 8
Training loss: 2.523180685763557
Validation loss: 2.5304454728629198

Epoch: 6| Step: 9
Training loss: 2.904362219233802
Validation loss: 2.5192652311415022

Epoch: 6| Step: 10
Training loss: 2.1732826336795847
Validation loss: 2.531569509977957

Epoch: 6| Step: 11
Training loss: 2.985959895442734
Validation loss: 2.540175023589465

Epoch: 6| Step: 12
Training loss: 2.7369454645222735
Validation loss: 2.5192922924165204

Epoch: 6| Step: 13
Training loss: 1.9115128955450982
Validation loss: 2.507495763904727

Epoch: 162| Step: 0
Training loss: 2.465259934004082
Validation loss: 2.4931021846815145

Epoch: 6| Step: 1
Training loss: 2.5740267460581303
Validation loss: 2.498937883666867

Epoch: 6| Step: 2
Training loss: 2.3772975449548874
Validation loss: 2.5283348183114436

Epoch: 6| Step: 3
Training loss: 2.660016878260936
Validation loss: 2.541923684113664

Epoch: 6| Step: 4
Training loss: 2.858230611959108
Validation loss: 2.5370283168431316

Epoch: 6| Step: 5
Training loss: 3.1180412633880312
Validation loss: 2.540758616932711

Epoch: 6| Step: 6
Training loss: 2.498267145414677
Validation loss: 2.5330741302297026

Epoch: 6| Step: 7
Training loss: 1.9834424328115359
Validation loss: 2.523020965039898

Epoch: 6| Step: 8
Training loss: 2.7119235573294356
Validation loss: 2.53976418516814

Epoch: 6| Step: 9
Training loss: 2.335883404669934
Validation loss: 2.5498567821249782

Epoch: 6| Step: 10
Training loss: 2.485027683341797
Validation loss: 2.5450979687237236

Epoch: 6| Step: 11
Training loss: 1.8229193623840745
Validation loss: 2.553943569995906

Epoch: 6| Step: 12
Training loss: 2.2650015137522104
Validation loss: 2.5496389189892645

Epoch: 6| Step: 13
Training loss: 2.302500472674492
Validation loss: 2.56352309705587

Epoch: 163| Step: 0
Training loss: 2.39380279960867
Validation loss: 2.5324392134404063

Epoch: 6| Step: 1
Training loss: 1.917852207846253
Validation loss: 2.5244624412932395

Epoch: 6| Step: 2
Training loss: 3.0795320499695324
Validation loss: 2.510737980692818

Epoch: 6| Step: 3
Training loss: 2.4300082568432595
Validation loss: 2.5172897330633703

Epoch: 6| Step: 4
Training loss: 2.689702395742163
Validation loss: 2.5013265105322215

Epoch: 6| Step: 5
Training loss: 2.03809751864672
Validation loss: 2.517904168491164

Epoch: 6| Step: 6
Training loss: 2.5755761696348296
Validation loss: 2.540816663374605

Epoch: 6| Step: 7
Training loss: 2.646387167408699
Validation loss: 2.551607849012687

Epoch: 6| Step: 8
Training loss: 2.4587852148919374
Validation loss: 2.5844336643001866

Epoch: 6| Step: 9
Training loss: 2.615708756102814
Validation loss: 2.612763734585967

Epoch: 6| Step: 10
Training loss: 2.10250322919999
Validation loss: 2.5914757379066513

Epoch: 6| Step: 11
Training loss: 2.462365502107028
Validation loss: 2.573599976512937

Epoch: 6| Step: 12
Training loss: 2.675122345595395
Validation loss: 2.562013994695107

Epoch: 6| Step: 13
Training loss: 0.9045127462687793
Validation loss: 2.557743417979379

Epoch: 164| Step: 0
Training loss: 2.3866996701940413
Validation loss: 2.540914050558362

Epoch: 6| Step: 1
Training loss: 2.25089669903064
Validation loss: 2.5432851830250596

Epoch: 6| Step: 2
Training loss: 2.9375189922611598
Validation loss: 2.5329601112360254

Epoch: 6| Step: 3
Training loss: 3.0597337958536945
Validation loss: 2.5427478472358818

Epoch: 6| Step: 4
Training loss: 1.9576108154266243
Validation loss: 2.538390572036362

Epoch: 6| Step: 5
Training loss: 2.408568714171346
Validation loss: 2.552542184176186

Epoch: 6| Step: 6
Training loss: 2.2951518751101805
Validation loss: 2.5478943245080687

Epoch: 6| Step: 7
Training loss: 2.260044776337904
Validation loss: 2.5653708209045565

Epoch: 6| Step: 8
Training loss: 2.222056973459128
Validation loss: 2.5629798165820725

Epoch: 6| Step: 9
Training loss: 2.0063856227584753
Validation loss: 2.544711335069572

Epoch: 6| Step: 10
Training loss: 2.206999921998341
Validation loss: 2.5492242672717444

Epoch: 6| Step: 11
Training loss: 2.9317125162945703
Validation loss: 2.564932360323871

Epoch: 6| Step: 12
Training loss: 2.2535972449508255
Validation loss: 2.567644259531092

Epoch: 6| Step: 13
Training loss: 2.5173653215979663
Validation loss: 2.5643187340697344

Epoch: 165| Step: 0
Training loss: 2.0852582304146905
Validation loss: 2.572027734310592

Epoch: 6| Step: 1
Training loss: 2.240745905084091
Validation loss: 2.548961923585995

Epoch: 6| Step: 2
Training loss: 3.1262906270397828
Validation loss: 2.5520345542989094

Epoch: 6| Step: 3
Training loss: 2.107361008664012
Validation loss: 2.5424969260348154

Epoch: 6| Step: 4
Training loss: 2.0925316753291594
Validation loss: 2.5507412309495283

Epoch: 6| Step: 5
Training loss: 2.2690300970859627
Validation loss: 2.5252174021292535

Epoch: 6| Step: 6
Training loss: 2.0475603659723993
Validation loss: 2.5168835857026157

Epoch: 6| Step: 7
Training loss: 2.39618211501808
Validation loss: 2.535030114415576

Epoch: 6| Step: 8
Training loss: 2.5281022833521454
Validation loss: 2.52638358282351

Epoch: 6| Step: 9
Training loss: 2.1689550956907344
Validation loss: 2.518232967320691

Epoch: 6| Step: 10
Training loss: 2.8556637886537213
Validation loss: 2.5074909780887586

Epoch: 6| Step: 11
Training loss: 2.5127996844821308
Validation loss: 2.5318795295756003

Epoch: 6| Step: 12
Training loss: 2.609352340143003
Validation loss: 2.552608981483256

Epoch: 6| Step: 13
Training loss: 2.260678383110161
Validation loss: 2.5806894871855532

Epoch: 166| Step: 0
Training loss: 2.55551759258582
Validation loss: 2.6103696263040237

Epoch: 6| Step: 1
Training loss: 2.591940650890378
Validation loss: 2.627082141520318

Epoch: 6| Step: 2
Training loss: 2.5555515519631395
Validation loss: 2.663461665241076

Epoch: 6| Step: 3
Training loss: 2.596847339395594
Validation loss: 2.6372486617796413

Epoch: 6| Step: 4
Training loss: 1.654078805865792
Validation loss: 2.596813300079109

Epoch: 6| Step: 5
Training loss: 2.096647847772916
Validation loss: 2.5743686381485738

Epoch: 6| Step: 6
Training loss: 1.9166112007187215
Validation loss: 2.5579883747577656

Epoch: 6| Step: 7
Training loss: 2.1272383849759042
Validation loss: 2.5636108805776607

Epoch: 6| Step: 8
Training loss: 2.841082485109298
Validation loss: 2.5679571298316324

Epoch: 6| Step: 9
Training loss: 1.708235954982835
Validation loss: 2.566895776169586

Epoch: 6| Step: 10
Training loss: 2.7663366404331784
Validation loss: 2.5534670623033415

Epoch: 6| Step: 11
Training loss: 3.13241886700582
Validation loss: 2.544820561242291

Epoch: 6| Step: 12
Training loss: 2.4860728478165877
Validation loss: 2.517306774110729

Epoch: 6| Step: 13
Training loss: 2.476250180548209
Validation loss: 2.500055687807114

Epoch: 167| Step: 0
Training loss: 2.088316742794853
Validation loss: 2.499966360706717

Epoch: 6| Step: 1
Training loss: 2.6030231762739806
Validation loss: 2.4912061965511434

Epoch: 6| Step: 2
Training loss: 2.124125805722815
Validation loss: 2.5238970535514866

Epoch: 6| Step: 3
Training loss: 2.2529169883419726
Validation loss: 2.4921390666197114

Epoch: 6| Step: 4
Training loss: 2.4638967977189243
Validation loss: 2.504286934925532

Epoch: 6| Step: 5
Training loss: 2.754769264431478
Validation loss: 2.4682281657069076

Epoch: 6| Step: 6
Training loss: 1.8867561541970364
Validation loss: 2.4870378913940674

Epoch: 6| Step: 7
Training loss: 2.0993073002176383
Validation loss: 2.473929321602538

Epoch: 6| Step: 8
Training loss: 2.3265098755407787
Validation loss: 2.494401283162379

Epoch: 6| Step: 9
Training loss: 2.961218022970519
Validation loss: 2.498635933068283

Epoch: 6| Step: 10
Training loss: 2.5094312155615595
Validation loss: 2.50966308711157

Epoch: 6| Step: 11
Training loss: 2.1705519124650787
Validation loss: 2.506874967011959

Epoch: 6| Step: 12
Training loss: 1.9059860171778837
Validation loss: 2.508945233165802

Epoch: 6| Step: 13
Training loss: 2.9883126849347432
Validation loss: 2.501777008657449

Epoch: 168| Step: 0
Training loss: 1.990726608485775
Validation loss: 2.5074937140103066

Epoch: 6| Step: 1
Training loss: 2.29135402511978
Validation loss: 2.553981159905544

Epoch: 6| Step: 2
Training loss: 3.0375415752061663
Validation loss: 2.5629662390462933

Epoch: 6| Step: 3
Training loss: 2.2011868223344533
Validation loss: 2.577694865142912

Epoch: 6| Step: 4
Training loss: 2.4402471858030745
Validation loss: 2.5426024138789485

Epoch: 6| Step: 5
Training loss: 2.7481072587982034
Validation loss: 2.518250898864742

Epoch: 6| Step: 6
Training loss: 2.6851278082124037
Validation loss: 2.5292140987533043

Epoch: 6| Step: 7
Training loss: 2.527387332687879
Validation loss: 2.516436599359091

Epoch: 6| Step: 8
Training loss: 2.5223503487299856
Validation loss: 2.5287064402610087

Epoch: 6| Step: 9
Training loss: 2.3661403039331224
Validation loss: 2.5165393543156336

Epoch: 6| Step: 10
Training loss: 2.129313298779475
Validation loss: 2.5168593352960267

Epoch: 6| Step: 11
Training loss: 1.7355226036364824
Validation loss: 2.5062206993367515

Epoch: 6| Step: 12
Training loss: 2.281452953768986
Validation loss: 2.4856352913798956

Epoch: 6| Step: 13
Training loss: 2.1543478938102587
Validation loss: 2.4792403167707344

Epoch: 169| Step: 0
Training loss: 2.213170302411359
Validation loss: 2.4870920789707376

Epoch: 6| Step: 1
Training loss: 2.701821955791747
Validation loss: 2.4788802875894733

Epoch: 6| Step: 2
Training loss: 2.7509405955061372
Validation loss: 2.4766334458055597

Epoch: 6| Step: 3
Training loss: 2.3165859519381717
Validation loss: 2.477723986630095

Epoch: 6| Step: 4
Training loss: 2.274986761704379
Validation loss: 2.5042357775128523

Epoch: 6| Step: 5
Training loss: 2.1829365677960038
Validation loss: 2.517288059810225

Epoch: 6| Step: 6
Training loss: 2.700508218194428
Validation loss: 2.5257701205582404

Epoch: 6| Step: 7
Training loss: 1.9903478168954438
Validation loss: 2.522550303425107

Epoch: 6| Step: 8
Training loss: 2.2951246585940224
Validation loss: 2.532461791128319

Epoch: 6| Step: 9
Training loss: 2.1153367177168954
Validation loss: 2.533251385531846

Epoch: 6| Step: 10
Training loss: 2.008568409923478
Validation loss: 2.525712125692706

Epoch: 6| Step: 11
Training loss: 2.180866100554402
Validation loss: 2.5338864175137994

Epoch: 6| Step: 12
Training loss: 2.297245436918447
Validation loss: 2.534649399322667

Epoch: 6| Step: 13
Training loss: 2.467714116508521
Validation loss: 2.5578519423240698

Epoch: 170| Step: 0
Training loss: 2.6743536266267154
Validation loss: 2.5450738138994606

Epoch: 6| Step: 1
Training loss: 2.25348287800949
Validation loss: 2.539785370389022

Epoch: 6| Step: 2
Training loss: 2.3541189093232733
Validation loss: 2.5633766891626926

Epoch: 6| Step: 3
Training loss: 1.8655047635130335
Validation loss: 2.5200374821266323

Epoch: 6| Step: 4
Training loss: 1.8787840488213947
Validation loss: 2.546170604641003

Epoch: 6| Step: 5
Training loss: 2.138916224625639
Validation loss: 2.5415108234700328

Epoch: 6| Step: 6
Training loss: 2.221010909815018
Validation loss: 2.5619040345667266

Epoch: 6| Step: 7
Training loss: 2.2030713230384826
Validation loss: 2.5350332423214534

Epoch: 6| Step: 8
Training loss: 2.2185501223514743
Validation loss: 2.5125764943110727

Epoch: 6| Step: 9
Training loss: 2.7303665862391933
Validation loss: 2.5383127988452356

Epoch: 6| Step: 10
Training loss: 2.279810830349785
Validation loss: 2.534227545024315

Epoch: 6| Step: 11
Training loss: 1.9932916909698155
Validation loss: 2.5536918334334198

Epoch: 6| Step: 12
Training loss: 2.245306736269079
Validation loss: 2.5556857619242743

Epoch: 6| Step: 13
Training loss: 3.177906034085119
Validation loss: 2.528153190545363

Epoch: 171| Step: 0
Training loss: 2.368924954276805
Validation loss: 2.4972961837725554

Epoch: 6| Step: 1
Training loss: 1.9674804469376643
Validation loss: 2.4862186120445613

Epoch: 6| Step: 2
Training loss: 2.297656283205117
Validation loss: 2.4783114378894204

Epoch: 6| Step: 3
Training loss: 1.9953575493634308
Validation loss: 2.5046307918805097

Epoch: 6| Step: 4
Training loss: 2.5038780651202317
Validation loss: 2.5054923299879692

Epoch: 6| Step: 5
Training loss: 2.559900407344008
Validation loss: 2.487021623242715

Epoch: 6| Step: 6
Training loss: 2.5061143491188456
Validation loss: 2.5036947532735945

Epoch: 6| Step: 7
Training loss: 2.040304456132015
Validation loss: 2.5118744700984483

Epoch: 6| Step: 8
Training loss: 2.3425216507699926
Validation loss: 2.538107708422905

Epoch: 6| Step: 9
Training loss: 1.896273034495877
Validation loss: 2.5456943026155696

Epoch: 6| Step: 10
Training loss: 2.329822510274618
Validation loss: 2.5828353684392527

Epoch: 6| Step: 11
Training loss: 2.079469862282714
Validation loss: 2.5756096923440763

Epoch: 6| Step: 12
Training loss: 2.5625186082117803
Validation loss: 2.5827635710024395

Epoch: 6| Step: 13
Training loss: 2.520561539891338
Validation loss: 2.5687871818664894

Epoch: 172| Step: 0
Training loss: 1.7853438197453058
Validation loss: 2.568931844372828

Epoch: 6| Step: 1
Training loss: 2.289748157495898
Validation loss: 2.5619571109710577

Epoch: 6| Step: 2
Training loss: 1.9070400414426352
Validation loss: 2.5871747169571075

Epoch: 6| Step: 3
Training loss: 1.9850118621356432
Validation loss: 2.580785273393854

Epoch: 6| Step: 4
Training loss: 2.1220422243452877
Validation loss: 2.567156387016836

Epoch: 6| Step: 5
Training loss: 3.1253997547048256
Validation loss: 2.5806427356685497

Epoch: 6| Step: 6
Training loss: 2.4703857217996212
Validation loss: 2.5857624217375808

Epoch: 6| Step: 7
Training loss: 2.582351641607999
Validation loss: 2.5829034487975715

Epoch: 6| Step: 8
Training loss: 2.0876118658552687
Validation loss: 2.5925172974388597

Epoch: 6| Step: 9
Training loss: 2.344224195193698
Validation loss: 2.5531557248843444

Epoch: 6| Step: 10
Training loss: 2.1380532959592715
Validation loss: 2.5765145530650506

Epoch: 6| Step: 11
Training loss: 2.003153103588139
Validation loss: 2.5661536520542647

Epoch: 6| Step: 12
Training loss: 2.283226097911587
Validation loss: 2.584245482686136

Epoch: 6| Step: 13
Training loss: 2.4667201328497224
Validation loss: 2.6043088258068043

Epoch: 173| Step: 0
Training loss: 2.4557105367418393
Validation loss: 2.58597762470761

Epoch: 6| Step: 1
Training loss: 1.7287713330456544
Validation loss: 2.5803618600529803

Epoch: 6| Step: 2
Training loss: 2.1572888953760443
Validation loss: 2.5422457642667173

Epoch: 6| Step: 3
Training loss: 2.335541248203102
Validation loss: 2.5595970287785477

Epoch: 6| Step: 4
Training loss: 2.783115404319369
Validation loss: 2.5462320395555555

Epoch: 6| Step: 5
Training loss: 2.1871600295596947
Validation loss: 2.60469758920033

Epoch: 6| Step: 6
Training loss: 2.6775697397362266
Validation loss: 2.6384311199820765

Epoch: 6| Step: 7
Training loss: 2.363039013766958
Validation loss: 2.688774401970092

Epoch: 6| Step: 8
Training loss: 2.758244121372718
Validation loss: 2.680319503551617

Epoch: 6| Step: 9
Training loss: 2.0171696857874317
Validation loss: 2.6612460208237048

Epoch: 6| Step: 10
Training loss: 2.1259960757171785
Validation loss: 2.662754870431849

Epoch: 6| Step: 11
Training loss: 1.7931293756345836
Validation loss: 2.630605551689926

Epoch: 6| Step: 12
Training loss: 2.401952001373182
Validation loss: 2.609248184208422

Epoch: 6| Step: 13
Training loss: 1.114355218426134
Validation loss: 2.552143442945723

Epoch: 174| Step: 0
Training loss: 1.85227759350522
Validation loss: 2.5343553825387843

Epoch: 6| Step: 1
Training loss: 2.539812652106508
Validation loss: 2.5086363934520888

Epoch: 6| Step: 2
Training loss: 1.7575047202338567
Validation loss: 2.4942590034946117

Epoch: 6| Step: 3
Training loss: 2.070734635987485
Validation loss: 2.5101411460875847

Epoch: 6| Step: 4
Training loss: 3.0806980900017975
Validation loss: 2.472236285949884

Epoch: 6| Step: 5
Training loss: 2.379497185333697
Validation loss: 2.470127529295244

Epoch: 6| Step: 6
Training loss: 1.8013030845555111
Validation loss: 2.487108228122503

Epoch: 6| Step: 7
Training loss: 2.2601920395676776
Validation loss: 2.4940622798753274

Epoch: 6| Step: 8
Training loss: 2.5107487396902544
Validation loss: 2.5205424713958156

Epoch: 6| Step: 9
Training loss: 2.11702094179516
Validation loss: 2.540246898469772

Epoch: 6| Step: 10
Training loss: 1.840833134695065
Validation loss: 2.526413090484657

Epoch: 6| Step: 11
Training loss: 2.347170254234247
Validation loss: 2.5591504134335494

Epoch: 6| Step: 12
Training loss: 2.364997883446938
Validation loss: 2.5529589877094936

Epoch: 6| Step: 13
Training loss: 2.175083123734311
Validation loss: 2.5482689390831874

Epoch: 175| Step: 0
Training loss: 2.0188471153685543
Validation loss: 2.5204433104524395

Epoch: 6| Step: 1
Training loss: 2.169138110169846
Validation loss: 2.510918106394327

Epoch: 6| Step: 2
Training loss: 2.284590378821798
Validation loss: 2.503036210925219

Epoch: 6| Step: 3
Training loss: 1.6645044447340196
Validation loss: 2.52354680377693

Epoch: 6| Step: 4
Training loss: 1.6802458079211569
Validation loss: 2.500173481695362

Epoch: 6| Step: 5
Training loss: 1.9128707601159616
Validation loss: 2.50662211575853

Epoch: 6| Step: 6
Training loss: 2.6385356153520925
Validation loss: 2.531462663604054

Epoch: 6| Step: 7
Training loss: 2.730989114623025
Validation loss: 2.522371614144973

Epoch: 6| Step: 8
Training loss: 2.218245972886692
Validation loss: 2.467918733726882

Epoch: 6| Step: 9
Training loss: 1.9201674900910184
Validation loss: 2.4640497448882175

Epoch: 6| Step: 10
Training loss: 3.3488063906328414
Validation loss: 2.4789651582191423

Epoch: 6| Step: 11
Training loss: 2.0387653704355624
Validation loss: 2.492621755683917

Epoch: 6| Step: 12
Training loss: 1.91202907374156
Validation loss: 2.5142484503825795

Epoch: 6| Step: 13
Training loss: 2.676059591476578
Validation loss: 2.5472397449027118

Testing loss: 2.61382681754564
