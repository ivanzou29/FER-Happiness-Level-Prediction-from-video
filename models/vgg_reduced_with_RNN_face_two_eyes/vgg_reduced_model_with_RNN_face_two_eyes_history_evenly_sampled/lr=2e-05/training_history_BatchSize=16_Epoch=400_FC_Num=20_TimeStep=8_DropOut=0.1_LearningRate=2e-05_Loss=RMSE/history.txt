Epoch: 1| Step: 0
Training loss: 5.98896060083627
Validation loss: 5.871557081731203

Epoch: 6| Step: 1
Training loss: 6.32071053627277
Validation loss: 5.850847506355595

Epoch: 6| Step: 2
Training loss: 5.48876481827621
Validation loss: 5.830048283315271

Epoch: 6| Step: 3
Training loss: 5.574185388006768
Validation loss: 5.806987239260595

Epoch: 6| Step: 4
Training loss: 6.148284871437852
Validation loss: 5.781191944472697

Epoch: 6| Step: 5
Training loss: 5.4740249044167495
Validation loss: 5.750321804135163

Epoch: 6| Step: 6
Training loss: 6.153897993162863
Validation loss: 5.716756343051483

Epoch: 6| Step: 7
Training loss: 6.573918463228886
Validation loss: 5.678936468135038

Epoch: 6| Step: 8
Training loss: 4.773396743125922
Validation loss: 5.6367867729139425

Epoch: 6| Step: 9
Training loss: 4.162275721834188
Validation loss: 5.5892524909020365

Epoch: 6| Step: 10
Training loss: 5.744408584046642
Validation loss: 5.539557831134785

Epoch: 6| Step: 11
Training loss: 5.177442982063591
Validation loss: 5.483149844584038

Epoch: 6| Step: 12
Training loss: 5.62483486356992
Validation loss: 5.424827253028677

Epoch: 6| Step: 13
Training loss: 6.69924636701669
Validation loss: 5.362446584296145

Epoch: 2| Step: 0
Training loss: 5.289888258332545
Validation loss: 5.296127260266263

Epoch: 6| Step: 1
Training loss: 4.1855821915069775
Validation loss: 5.232546445039569

Epoch: 6| Step: 2
Training loss: 4.35032803405746
Validation loss: 5.164697378310186

Epoch: 6| Step: 3
Training loss: 5.16095384993058
Validation loss: 5.098803373666117

Epoch: 6| Step: 4
Training loss: 4.407078658296791
Validation loss: 5.032315022701284

Epoch: 6| Step: 5
Training loss: 5.046392364572616
Validation loss: 4.969382740776138

Epoch: 6| Step: 6
Training loss: 4.921459555879358
Validation loss: 4.90362281600695

Epoch: 6| Step: 7
Training loss: 4.943739413359793
Validation loss: 4.842543834937005

Epoch: 6| Step: 8
Training loss: 4.463497035524143
Validation loss: 4.777203884238427

Epoch: 6| Step: 9
Training loss: 5.492241155109978
Validation loss: 4.713870962911028

Epoch: 6| Step: 10
Training loss: 6.020434866878648
Validation loss: 4.659803841426964

Epoch: 6| Step: 11
Training loss: 4.5699852981163955
Validation loss: 4.607985395894044

Epoch: 6| Step: 12
Training loss: 4.631089814951283
Validation loss: 4.564720923596901

Epoch: 6| Step: 13
Training loss: 5.869106177103566
Validation loss: 4.530920366483311

Epoch: 3| Step: 0
Training loss: 5.395056277061993
Validation loss: 4.506165641020195

Epoch: 6| Step: 1
Training loss: 2.35262834594093
Validation loss: 4.478053683802855

Epoch: 6| Step: 2
Training loss: 5.25737680157512
Validation loss: 4.455294831319267

Epoch: 6| Step: 3
Training loss: 5.655200333963488
Validation loss: 4.426361894209205

Epoch: 6| Step: 4
Training loss: 5.026073375331756
Validation loss: 4.400236106738955

Epoch: 6| Step: 5
Training loss: 4.572440201507539
Validation loss: 4.374142050817324

Epoch: 6| Step: 6
Training loss: 5.202489315757064
Validation loss: 4.352701952982387

Epoch: 6| Step: 7
Training loss: 4.678751194286474
Validation loss: 4.331791131607533

Epoch: 6| Step: 8
Training loss: 3.996006521874529
Validation loss: 4.317659271071133

Epoch: 6| Step: 9
Training loss: 3.6256323953364715
Validation loss: 4.3030403183387005

Epoch: 6| Step: 10
Training loss: 4.657399694864572
Validation loss: 4.279875622507037

Epoch: 6| Step: 11
Training loss: 3.9743687062424367
Validation loss: 4.258712257132696

Epoch: 6| Step: 12
Training loss: 2.4868711970727553
Validation loss: 4.237112466874175

Epoch: 6| Step: 13
Training loss: 4.254283765675101
Validation loss: 4.216413355653055

Epoch: 4| Step: 0
Training loss: 4.436254622090743
Validation loss: 4.202144054693394

Epoch: 6| Step: 1
Training loss: 4.340609066675108
Validation loss: 4.188524050289852

Epoch: 6| Step: 2
Training loss: 3.490586837792174
Validation loss: 4.173153843364732

Epoch: 6| Step: 3
Training loss: 5.174483180384494
Validation loss: 4.152171606534249

Epoch: 6| Step: 4
Training loss: 2.6039157797441317
Validation loss: 4.122094083853326

Epoch: 6| Step: 5
Training loss: 4.801658010231132
Validation loss: 4.116764884791052

Epoch: 6| Step: 6
Training loss: 5.021657198139375
Validation loss: 4.092899209365056

Epoch: 6| Step: 7
Training loss: 4.361925916963529
Validation loss: 4.054940682974441

Epoch: 6| Step: 8
Training loss: 3.084025966757617
Validation loss: 4.0140591969773025

Epoch: 6| Step: 9
Training loss: 4.01185567560874
Validation loss: 3.9897555698531115

Epoch: 6| Step: 10
Training loss: 3.903404114687096
Validation loss: 3.9822104345701796

Epoch: 6| Step: 11
Training loss: 4.102903426638301
Validation loss: 3.9739390724496055

Epoch: 6| Step: 12
Training loss: 4.5935342958631
Validation loss: 3.9600065433004397

Epoch: 6| Step: 13
Training loss: 4.4167107393956835
Validation loss: 3.9428651961390404

Epoch: 5| Step: 0
Training loss: 4.205410814391128
Validation loss: 3.935132152165972

Epoch: 6| Step: 1
Training loss: 3.319619211857131
Validation loss: 3.9292869287871803

Epoch: 6| Step: 2
Training loss: 3.8814264966851972
Validation loss: 3.9201107151233727

Epoch: 6| Step: 3
Training loss: 4.31206875179026
Validation loss: 3.896923675721246

Epoch: 6| Step: 4
Training loss: 3.1311546752795367
Validation loss: 3.884136880036591

Epoch: 6| Step: 5
Training loss: 4.220163066298783
Validation loss: 3.8724363065216396

Epoch: 6| Step: 6
Training loss: 5.272817346347618
Validation loss: 3.866139213186544

Epoch: 6| Step: 7
Training loss: 4.46926770179223
Validation loss: 3.8483810425926066

Epoch: 6| Step: 8
Training loss: 3.894942251421289
Validation loss: 3.830095491765626

Epoch: 6| Step: 9
Training loss: 3.991851254988789
Validation loss: 3.816283761241759

Epoch: 6| Step: 10
Training loss: 4.643512071801032
Validation loss: 3.8103230657903246

Epoch: 6| Step: 11
Training loss: 3.2906116452720457
Validation loss: 3.787678948948972

Epoch: 6| Step: 12
Training loss: 3.429486592519213
Validation loss: 3.776642837052448

Epoch: 6| Step: 13
Training loss: 3.4317381687011768
Validation loss: 3.7756554860625386

Epoch: 6| Step: 0
Training loss: 4.400880829469859
Validation loss: 3.7682804369195133

Epoch: 6| Step: 1
Training loss: 3.9353652495698506
Validation loss: 3.7459719391288924

Epoch: 6| Step: 2
Training loss: 4.156117831545143
Validation loss: 3.778314858606048

Epoch: 6| Step: 3
Training loss: 3.598606311384781
Validation loss: 3.7306767619639967

Epoch: 6| Step: 4
Training loss: 4.344776718320018
Validation loss: 3.7277405711946137

Epoch: 6| Step: 5
Training loss: 3.4323022559566514
Validation loss: 3.7252449445677773

Epoch: 6| Step: 6
Training loss: 4.168138523809173
Validation loss: 3.729477048244274

Epoch: 6| Step: 7
Training loss: 3.806872482637166
Validation loss: 3.70357609850898

Epoch: 6| Step: 8
Training loss: 4.066105812253344
Validation loss: 3.6904962379308386

Epoch: 6| Step: 9
Training loss: 2.906880136082208
Validation loss: 3.6807687180816213

Epoch: 6| Step: 10
Training loss: 4.016853827288193
Validation loss: 3.675406748334186

Epoch: 6| Step: 11
Training loss: 4.297742943235196
Validation loss: 3.669295846869883

Epoch: 6| Step: 12
Training loss: 3.9917452990937328
Validation loss: 3.6602324547242007

Epoch: 6| Step: 13
Training loss: 2.395855635387169
Validation loss: 3.6508540732769212

Epoch: 7| Step: 0
Training loss: 3.7561572071362614
Validation loss: 3.6410303968842173

Epoch: 6| Step: 1
Training loss: 3.2050317067022593
Validation loss: 3.627554649968714

Epoch: 6| Step: 2
Training loss: 3.476956257327471
Validation loss: 3.6151443778445387

Epoch: 6| Step: 3
Training loss: 2.904862595688323
Validation loss: 3.6096053994378754

Epoch: 6| Step: 4
Training loss: 4.049605343274736
Validation loss: 3.6071826242912395

Epoch: 6| Step: 5
Training loss: 4.722155018247222
Validation loss: 3.5982084377953325

Epoch: 6| Step: 6
Training loss: 3.4389936496579483
Validation loss: 3.582852514240553

Epoch: 6| Step: 7
Training loss: 3.2974147264446168
Validation loss: 3.5835935341261385

Epoch: 6| Step: 8
Training loss: 4.236633824406987
Validation loss: 3.586717903553329

Epoch: 6| Step: 9
Training loss: 3.592382817809425
Validation loss: 3.576996469796053

Epoch: 6| Step: 10
Training loss: 3.9058147950923137
Validation loss: 3.565160211837345

Epoch: 6| Step: 11
Training loss: 3.8954653370631784
Validation loss: 3.552169208873661

Epoch: 6| Step: 12
Training loss: 3.920706525502598
Validation loss: 3.5462810320243223

Epoch: 6| Step: 13
Training loss: 4.4913314401710265
Validation loss: 3.538817342541063

Epoch: 8| Step: 0
Training loss: 4.042839011354338
Validation loss: 3.5246799123811483

Epoch: 6| Step: 1
Training loss: 3.6211206132700977
Validation loss: 3.5148124384739634

Epoch: 6| Step: 2
Training loss: 3.8589128843084346
Validation loss: 3.506358998814563

Epoch: 6| Step: 3
Training loss: 2.5418927660157773
Validation loss: 3.500991223867881

Epoch: 6| Step: 4
Training loss: 3.126796816195921
Validation loss: 3.497563497016536

Epoch: 6| Step: 5
Training loss: 2.950429342029246
Validation loss: 3.493131967343484

Epoch: 6| Step: 6
Training loss: 4.637258625175298
Validation loss: 3.4898466541974207

Epoch: 6| Step: 7
Training loss: 3.870920063822415
Validation loss: 3.478076203669197

Epoch: 6| Step: 8
Training loss: 3.8896186476937946
Validation loss: 3.47185669389435

Epoch: 6| Step: 9
Training loss: 3.4260064532769796
Validation loss: 3.4639444895831333

Epoch: 6| Step: 10
Training loss: 3.5599310463217444
Validation loss: 3.474585649538854

Epoch: 6| Step: 11
Training loss: 3.8735013955752535
Validation loss: 3.4495589057980958

Epoch: 6| Step: 12
Training loss: 4.205695405082498
Validation loss: 3.445722817304822

Epoch: 6| Step: 13
Training loss: 3.6543270173045346
Validation loss: 3.4409457480338825

Epoch: 9| Step: 0
Training loss: 4.193100557482047
Validation loss: 3.443114339680844

Epoch: 6| Step: 1
Training loss: 3.227212392460373
Validation loss: 3.4331040779445923

Epoch: 6| Step: 2
Training loss: 3.881461509064607
Validation loss: 3.413462817208581

Epoch: 6| Step: 3
Training loss: 3.0915138563314186
Validation loss: 3.4046956512634154

Epoch: 6| Step: 4
Training loss: 4.289783743718451
Validation loss: 3.3996848505024855

Epoch: 6| Step: 5
Training loss: 2.4392575505507206
Validation loss: 3.405194160568626

Epoch: 6| Step: 6
Training loss: 3.2787236251671916
Validation loss: 3.45900835125376

Epoch: 6| Step: 7
Training loss: 3.7653813580088054
Validation loss: 3.379491317430333

Epoch: 6| Step: 8
Training loss: 4.144433224423937
Validation loss: 3.3740410272195476

Epoch: 6| Step: 9
Training loss: 4.193086456244495
Validation loss: 3.384376432449407

Epoch: 6| Step: 10
Training loss: 3.311754250701736
Validation loss: 3.359379408600479

Epoch: 6| Step: 11
Training loss: 3.5554919998793495
Validation loss: 3.35322842818956

Epoch: 6| Step: 12
Training loss: 3.7226682904940382
Validation loss: 3.3464188886898296

Epoch: 6| Step: 13
Training loss: 2.594659668760413
Validation loss: 3.333987466145434

Epoch: 10| Step: 0
Training loss: 4.295428556259968
Validation loss: 3.3181989345733034

Epoch: 6| Step: 1
Training loss: 3.148532761867227
Validation loss: 3.31998034249644

Epoch: 6| Step: 2
Training loss: 3.351298003886263
Validation loss: 3.331270430689101

Epoch: 6| Step: 3
Training loss: 3.8566398040266776
Validation loss: 3.31781006991246

Epoch: 6| Step: 4
Training loss: 3.0597269387674673
Validation loss: 3.3121934200544594

Epoch: 6| Step: 5
Training loss: 3.6507435603025886
Validation loss: 3.306876827413629

Epoch: 6| Step: 6
Training loss: 3.4766195571160607
Validation loss: 3.299647931957076

Epoch: 6| Step: 7
Training loss: 3.705909293920074
Validation loss: 3.2939616954378015

Epoch: 6| Step: 8
Training loss: 3.1637898645560947
Validation loss: 3.293411209003079

Epoch: 6| Step: 9
Training loss: 3.815558535585133
Validation loss: 3.283215042085505

Epoch: 6| Step: 10
Training loss: 3.56336977864806
Validation loss: 3.2772786724088636

Epoch: 6| Step: 11
Training loss: 2.8689445080607663
Validation loss: 3.266798529706104

Epoch: 6| Step: 12
Training loss: 3.9249043106757937
Validation loss: 3.25877251060452

Epoch: 6| Step: 13
Training loss: 3.2991021755615453
Validation loss: 3.2517526032820245

Epoch: 11| Step: 0
Training loss: 2.9592141644479426
Validation loss: 3.2504318382675033

Epoch: 6| Step: 1
Training loss: 3.7868888991472756
Validation loss: 3.245553373734883

Epoch: 6| Step: 2
Training loss: 4.542003840724946
Validation loss: 3.240557414382762

Epoch: 6| Step: 3
Training loss: 3.6805222003952833
Validation loss: 3.2356997378729355

Epoch: 6| Step: 4
Training loss: 3.5071591318888857
Validation loss: 3.2326069321509365

Epoch: 6| Step: 5
Training loss: 3.468425288767894
Validation loss: 3.231275618580471

Epoch: 6| Step: 6
Training loss: 3.134226339661828
Validation loss: 3.227955092647308

Epoch: 6| Step: 7
Training loss: 2.5868206072091344
Validation loss: 3.2256126182525424

Epoch: 6| Step: 8
Training loss: 4.350632737718257
Validation loss: 3.218159552248846

Epoch: 6| Step: 9
Training loss: 2.65685974303365
Validation loss: 3.2124697359221344

Epoch: 6| Step: 10
Training loss: 3.435541739576534
Validation loss: 3.2094819759223854

Epoch: 6| Step: 11
Training loss: 3.0570739633923427
Validation loss: 3.2046862535249323

Epoch: 6| Step: 12
Training loss: 3.4681257081353323
Validation loss: 3.207292302101779

Epoch: 6| Step: 13
Training loss: 3.5748206460418666
Validation loss: 3.2031690192830764

Epoch: 12| Step: 0
Training loss: 3.5145902340016044
Validation loss: 3.2016938196389626

Epoch: 6| Step: 1
Training loss: 3.564208173304265
Validation loss: 3.2113116540641875

Epoch: 6| Step: 2
Training loss: 3.1486522516128885
Validation loss: 3.201625681366779

Epoch: 6| Step: 3
Training loss: 3.3664303523555543
Validation loss: 3.1946588160447322

Epoch: 6| Step: 4
Training loss: 2.7151049152146145
Validation loss: 3.194905827412603

Epoch: 6| Step: 5
Training loss: 4.453730598897804
Validation loss: 3.1904233788944203

Epoch: 6| Step: 6
Training loss: 3.4806336985674773
Validation loss: 3.1877512662884806

Epoch: 6| Step: 7
Training loss: 2.579565766926371
Validation loss: 3.1868799013790015

Epoch: 6| Step: 8
Training loss: 3.842728890108692
Validation loss: 3.182672494371634

Epoch: 6| Step: 9
Training loss: 3.6812080108890335
Validation loss: 3.184016138891389

Epoch: 6| Step: 10
Training loss: 3.088091212205349
Validation loss: 3.185072263670354

Epoch: 6| Step: 11
Training loss: 3.676412692343425
Validation loss: 3.175151814086927

Epoch: 6| Step: 12
Training loss: 3.5428670008473873
Validation loss: 3.167404244074447

Epoch: 6| Step: 13
Training loss: 3.1524146921714564
Validation loss: 3.1663442867493563

Epoch: 13| Step: 0
Training loss: 2.938627635334288
Validation loss: 3.1679070579510613

Epoch: 6| Step: 1
Training loss: 3.225106194692047
Validation loss: 3.171818789546737

Epoch: 6| Step: 2
Training loss: 2.728898323980223
Validation loss: 3.1815493431018176

Epoch: 6| Step: 3
Training loss: 3.207605717047399
Validation loss: 3.2061897972448676

Epoch: 6| Step: 4
Training loss: 4.502721175671423
Validation loss: 3.209686590527781

Epoch: 6| Step: 5
Training loss: 2.9981117663987042
Validation loss: 3.170828426317886

Epoch: 6| Step: 6
Training loss: 2.9151203597855324
Validation loss: 3.169877655248773

Epoch: 6| Step: 7
Training loss: 3.459556424587873
Validation loss: 3.1797049134592887

Epoch: 6| Step: 8
Training loss: 3.39312722127873
Validation loss: 3.194691200647615

Epoch: 6| Step: 9
Training loss: 3.7884541131259253
Validation loss: 3.1847209006841695

Epoch: 6| Step: 10
Training loss: 3.4709034326869546
Validation loss: 3.149139735554476

Epoch: 6| Step: 11
Training loss: 4.003748805974567
Validation loss: 3.148945598377016

Epoch: 6| Step: 12
Training loss: 3.7267866726992294
Validation loss: 3.15404187391493

Epoch: 6| Step: 13
Training loss: 3.3106668546197504
Validation loss: 3.182581396729544

Epoch: 14| Step: 0
Training loss: 3.8161203673630535
Validation loss: 3.2109758425534767

Epoch: 6| Step: 1
Training loss: 2.737803636546788
Validation loss: 3.163511059713295

Epoch: 6| Step: 2
Training loss: 3.7528191460105793
Validation loss: 3.1529058973353683

Epoch: 6| Step: 3
Training loss: 3.702193002072848
Validation loss: 3.1557957937586054

Epoch: 6| Step: 4
Training loss: 3.2825285827368473
Validation loss: 3.1443919369111892

Epoch: 6| Step: 5
Training loss: 3.5389986348231717
Validation loss: 3.1435844156133927

Epoch: 6| Step: 6
Training loss: 3.8026143717823717
Validation loss: 3.1362924450723932

Epoch: 6| Step: 7
Training loss: 3.9254691991573076
Validation loss: 3.135242924352876

Epoch: 6| Step: 8
Training loss: 3.2518550273773874
Validation loss: 3.1288012464336976

Epoch: 6| Step: 9
Training loss: 3.2383208600280295
Validation loss: 3.1369812754303394

Epoch: 6| Step: 10
Training loss: 3.3171283847825923
Validation loss: 3.1323078068031744

Epoch: 6| Step: 11
Training loss: 2.4750586916967747
Validation loss: 3.133869832209634

Epoch: 6| Step: 12
Training loss: 3.301123895861844
Validation loss: 3.1415089531720453

Epoch: 6| Step: 13
Training loss: 3.3946061208389415
Validation loss: 3.1497622610026785

Epoch: 15| Step: 0
Training loss: 2.6482300803732577
Validation loss: 3.123771164178036

Epoch: 6| Step: 1
Training loss: 3.4678197764698204
Validation loss: 3.124234459743123

Epoch: 6| Step: 2
Training loss: 2.9167834303962277
Validation loss: 3.1204365542718153

Epoch: 6| Step: 3
Training loss: 3.9404619974279447
Validation loss: 3.108916284012677

Epoch: 6| Step: 4
Training loss: 3.977279388620322
Validation loss: 3.1079109147234303

Epoch: 6| Step: 5
Training loss: 3.561775937032334
Validation loss: 3.104164705498167

Epoch: 6| Step: 6
Training loss: 2.6951872423340526
Validation loss: 3.100084512189076

Epoch: 6| Step: 7
Training loss: 3.720219169641221
Validation loss: 3.099261235343179

Epoch: 6| Step: 8
Training loss: 3.81479663151835
Validation loss: 3.1019716305775926

Epoch: 6| Step: 9
Training loss: 2.411970497488644
Validation loss: 3.099881384727434

Epoch: 6| Step: 10
Training loss: 3.304363406186069
Validation loss: 3.1014170807981962

Epoch: 6| Step: 11
Training loss: 3.131998998181413
Validation loss: 3.097269577184773

Epoch: 6| Step: 12
Training loss: 3.6732338846063843
Validation loss: 3.0952860098741484

Epoch: 6| Step: 13
Training loss: 3.741560021277524
Validation loss: 3.0857657527418594

Epoch: 16| Step: 0
Training loss: 3.455227449165086
Validation loss: 3.088253285359147

Epoch: 6| Step: 1
Training loss: 3.866574017193015
Validation loss: 3.085462962734787

Epoch: 6| Step: 2
Training loss: 3.7376753137610326
Validation loss: 3.088350519026084

Epoch: 6| Step: 3
Training loss: 2.8303038913140584
Validation loss: 3.086866686200243

Epoch: 6| Step: 4
Training loss: 3.2159310746659284
Validation loss: 3.088741176865176

Epoch: 6| Step: 5
Training loss: 3.0890461004243486
Validation loss: 3.087722551557531

Epoch: 6| Step: 6
Training loss: 2.788813475703315
Validation loss: 3.0864402767450034

Epoch: 6| Step: 7
Training loss: 3.2389342382479493
Validation loss: 3.0872782043952403

Epoch: 6| Step: 8
Training loss: 3.381108442858372
Validation loss: 3.0835643045463583

Epoch: 6| Step: 9
Training loss: 2.920338272462687
Validation loss: 3.0838895033936944

Epoch: 6| Step: 10
Training loss: 2.8790765140034624
Validation loss: 3.0787374860395404

Epoch: 6| Step: 11
Training loss: 3.9643013118009924
Validation loss: 3.077166307919017

Epoch: 6| Step: 12
Training loss: 3.1456107425044464
Validation loss: 3.0743012215322527

Epoch: 6| Step: 13
Training loss: 4.771271908964366
Validation loss: 3.0714155387377065

Epoch: 17| Step: 0
Training loss: 2.705497979037352
Validation loss: 3.0692272320701033

Epoch: 6| Step: 1
Training loss: 2.597720037838761
Validation loss: 3.066127351673437

Epoch: 6| Step: 2
Training loss: 2.555541476151018
Validation loss: 3.0661240097127065

Epoch: 6| Step: 3
Training loss: 2.9218728784563655
Validation loss: 3.0705259995620247

Epoch: 6| Step: 4
Training loss: 3.6513763288866583
Validation loss: 3.0785066492839968

Epoch: 6| Step: 5
Training loss: 3.7222476186565996
Validation loss: 3.0683223834694093

Epoch: 6| Step: 6
Training loss: 3.558788172815596
Validation loss: 3.0597200816658727

Epoch: 6| Step: 7
Training loss: 2.7239132665306256
Validation loss: 3.0583327760439123

Epoch: 6| Step: 8
Training loss: 2.8450217285399173
Validation loss: 3.0597779409108865

Epoch: 6| Step: 9
Training loss: 3.5444221249405476
Validation loss: 3.0618784937033094

Epoch: 6| Step: 10
Training loss: 4.480441079224711
Validation loss: 3.0633518180350614

Epoch: 6| Step: 11
Training loss: 3.78018917619538
Validation loss: 3.057779944423336

Epoch: 6| Step: 12
Training loss: 3.8861867569335398
Validation loss: 3.0571050733548493

Epoch: 6| Step: 13
Training loss: 3.17716291150765
Validation loss: 3.051267593355316

Epoch: 18| Step: 0
Training loss: 3.799963805377648
Validation loss: 3.049481012242167

Epoch: 6| Step: 1
Training loss: 2.598066300460193
Validation loss: 3.0488825063586718

Epoch: 6| Step: 2
Training loss: 3.035137711594768
Validation loss: 3.0490926904315216

Epoch: 6| Step: 3
Training loss: 3.0941762919489864
Validation loss: 3.0500074567053073

Epoch: 6| Step: 4
Training loss: 2.7232534883701454
Validation loss: 3.0515223061010706

Epoch: 6| Step: 5
Training loss: 3.83332751453345
Validation loss: 3.0458783602431505

Epoch: 6| Step: 6
Training loss: 3.789064639376007
Validation loss: 3.0447243663775154

Epoch: 6| Step: 7
Training loss: 3.2233442092391176
Validation loss: 3.044719019708862

Epoch: 6| Step: 8
Training loss: 3.2932461840055014
Validation loss: 3.0407145579538

Epoch: 6| Step: 9
Training loss: 3.901813520698443
Validation loss: 3.0406666161151668

Epoch: 6| Step: 10
Training loss: 3.0736469672558835
Validation loss: 3.0399334214750593

Epoch: 6| Step: 11
Training loss: 2.974568657900087
Validation loss: 3.038009667437689

Epoch: 6| Step: 12
Training loss: 4.004743148053913
Validation loss: 3.034659533142082

Epoch: 6| Step: 13
Training loss: 2.5726268980944975
Validation loss: 3.034089014346033

Epoch: 19| Step: 0
Training loss: 2.8347895376945464
Validation loss: 3.03155094907097

Epoch: 6| Step: 1
Training loss: 4.48279376180621
Validation loss: 3.0313081776979773

Epoch: 6| Step: 2
Training loss: 3.010020528070654
Validation loss: 3.032558718948263

Epoch: 6| Step: 3
Training loss: 2.74904702754088
Validation loss: 3.027721655761628

Epoch: 6| Step: 4
Training loss: 3.373931574364491
Validation loss: 3.029028493421155

Epoch: 6| Step: 5
Training loss: 3.530337190382161
Validation loss: 3.028036205370227

Epoch: 6| Step: 6
Training loss: 2.9208783576604183
Validation loss: 3.0275873049844866

Epoch: 6| Step: 7
Training loss: 3.050757648606291
Validation loss: 3.033549955283044

Epoch: 6| Step: 8
Training loss: 3.020821792755883
Validation loss: 3.034555366594513

Epoch: 6| Step: 9
Training loss: 3.7032542789604217
Validation loss: 3.0318449971656842

Epoch: 6| Step: 10
Training loss: 3.6777284108588124
Validation loss: 3.028887475149175

Epoch: 6| Step: 11
Training loss: 3.05766397231454
Validation loss: 3.0235162879306525

Epoch: 6| Step: 12
Training loss: 3.2897342530497014
Validation loss: 3.0234466728115184

Epoch: 6| Step: 13
Training loss: 3.443046256989731
Validation loss: 3.025077058784716

Epoch: 20| Step: 0
Training loss: 3.6762417414629858
Validation loss: 3.024171516748388

Epoch: 6| Step: 1
Training loss: 2.3293909304979663
Validation loss: 3.0220807892655834

Epoch: 6| Step: 2
Training loss: 3.0389296004942685
Validation loss: 3.0183738843607912

Epoch: 6| Step: 3
Training loss: 2.817639550423084
Validation loss: 3.0176090576464

Epoch: 6| Step: 4
Training loss: 3.257755123520523
Validation loss: 3.016092321907176

Epoch: 6| Step: 5
Training loss: 3.6908383533072997
Validation loss: 3.016535190655786

Epoch: 6| Step: 6
Training loss: 2.7073039128103735
Validation loss: 3.010965512639739

Epoch: 6| Step: 7
Training loss: 3.555114183912626
Validation loss: 3.0403632488257903

Epoch: 6| Step: 8
Training loss: 3.4352867630888286
Validation loss: 3.0660509480391847

Epoch: 6| Step: 9
Training loss: 2.835240133836306
Validation loss: 3.0323180623861674

Epoch: 6| Step: 10
Training loss: 3.473699389429102
Validation loss: 3.0253336418784524

Epoch: 6| Step: 11
Training loss: 4.3778755547135635
Validation loss: 3.015368779348268

Epoch: 6| Step: 12
Training loss: 3.15499460162443
Validation loss: 3.0140059503701964

Epoch: 6| Step: 13
Training loss: 3.812124014903618
Validation loss: 3.0163759986795196

Epoch: 21| Step: 0
Training loss: 3.1180813303795216
Validation loss: 3.0179078671662354

Epoch: 6| Step: 1
Training loss: 3.4488689724793917
Validation loss: 3.019238906579441

Epoch: 6| Step: 2
Training loss: 2.6180463150450466
Validation loss: 3.018163696440829

Epoch: 6| Step: 3
Training loss: 3.255624452570025
Validation loss: 3.018992988245273

Epoch: 6| Step: 4
Training loss: 3.52473307471443
Validation loss: 3.019887411315186

Epoch: 6| Step: 5
Training loss: 3.8989392036106625
Validation loss: 3.0320433126263966

Epoch: 6| Step: 6
Training loss: 3.5582212217538487
Validation loss: 3.0140548733941617

Epoch: 6| Step: 7
Training loss: 3.3656815349679503
Validation loss: 3.011218317692426

Epoch: 6| Step: 8
Training loss: 3.953974817175547
Validation loss: 3.0059540620735805

Epoch: 6| Step: 9
Training loss: 2.535268443112839
Validation loss: 3.0033576063506615

Epoch: 6| Step: 10
Training loss: 3.1534208705222824
Validation loss: 3.0056184861399196

Epoch: 6| Step: 11
Training loss: 2.993474061230735
Validation loss: 3.0033727268330868

Epoch: 6| Step: 12
Training loss: 3.6670284670725306
Validation loss: 3.0028308583292453

Epoch: 6| Step: 13
Training loss: 2.55122733779404
Validation loss: 3.0049627523669913

Epoch: 22| Step: 0
Training loss: 3.6076972001305196
Validation loss: 3.0004933081541667

Epoch: 6| Step: 1
Training loss: 4.103278565856049
Validation loss: 3.000526904933878

Epoch: 6| Step: 2
Training loss: 2.819385915272952
Validation loss: 3.004046524233108

Epoch: 6| Step: 3
Training loss: 2.29339460483288
Validation loss: 3.0093322127966395

Epoch: 6| Step: 4
Training loss: 3.3847354770909246
Validation loss: 3.0022963140757284

Epoch: 6| Step: 5
Training loss: 3.3720840290319782
Validation loss: 2.9921148417670445

Epoch: 6| Step: 6
Training loss: 3.3916756544689215
Validation loss: 2.992702007544361

Epoch: 6| Step: 7
Training loss: 3.0298830076488206
Validation loss: 3.003524352535739

Epoch: 6| Step: 8
Training loss: 3.7739623911105156
Validation loss: 3.00650228477425

Epoch: 6| Step: 9
Training loss: 3.402636089532362
Validation loss: 3.004868764363013

Epoch: 6| Step: 10
Training loss: 3.3403816726892575
Validation loss: 2.98871153210113

Epoch: 6| Step: 11
Training loss: 3.6212125262848716
Validation loss: 2.9998507667668477

Epoch: 6| Step: 12
Training loss: 3.083375741477961
Validation loss: 3.016455169925352

Epoch: 6| Step: 13
Training loss: 1.5018880405883797
Validation loss: 3.0588034310411634

Epoch: 23| Step: 0
Training loss: 3.2311230219493643
Validation loss: 3.1215505483747963

Epoch: 6| Step: 1
Training loss: 3.50555347181266
Validation loss: 3.084057203848667

Epoch: 6| Step: 2
Training loss: 3.1449370128346397
Validation loss: 3.042887554054009

Epoch: 6| Step: 3
Training loss: 3.4374184338689338
Validation loss: 3.0166029018537928

Epoch: 6| Step: 4
Training loss: 3.6674518322528153
Validation loss: 2.998684401523523

Epoch: 6| Step: 5
Training loss: 3.6021365289564176
Validation loss: 2.989815114335395

Epoch: 6| Step: 6
Training loss: 2.560327492866399
Validation loss: 2.982964716187566

Epoch: 6| Step: 7
Training loss: 3.71574588254957
Validation loss: 2.9868621598699927

Epoch: 6| Step: 8
Training loss: 2.3672392685268564
Validation loss: 2.985927020808197

Epoch: 6| Step: 9
Training loss: 3.1412932790438113
Validation loss: 2.999683067712721

Epoch: 6| Step: 10
Training loss: 3.027369109016772
Validation loss: 3.0300954749858944

Epoch: 6| Step: 11
Training loss: 3.763376411436963
Validation loss: 2.996968945427428

Epoch: 6| Step: 12
Training loss: 3.792766718880835
Validation loss: 2.9877301635515328

Epoch: 6| Step: 13
Training loss: 2.87364015346884
Validation loss: 2.9841298287875113

Epoch: 24| Step: 0
Training loss: 3.98690129392367
Validation loss: 2.9826789567490932

Epoch: 6| Step: 1
Training loss: 2.606298860599632
Validation loss: 2.980005332252129

Epoch: 6| Step: 2
Training loss: 2.7974927848606965
Validation loss: 2.978669988625429

Epoch: 6| Step: 3
Training loss: 2.9179164570280816
Validation loss: 2.9851521323788828

Epoch: 6| Step: 4
Training loss: 2.8994954689754864
Validation loss: 2.9807870509675203

Epoch: 6| Step: 5
Training loss: 3.2889080962774373
Validation loss: 2.978690973315252

Epoch: 6| Step: 6
Training loss: 3.3195358983790855
Validation loss: 2.9820198739980768

Epoch: 6| Step: 7
Training loss: 3.178095688586256
Validation loss: 2.9770554107045686

Epoch: 6| Step: 8
Training loss: 2.187444849681461
Validation loss: 2.974843867551378

Epoch: 6| Step: 9
Training loss: 3.672286379880983
Validation loss: 2.9726540629341245

Epoch: 6| Step: 10
Training loss: 3.7942022013255245
Validation loss: 2.96861569543914

Epoch: 6| Step: 11
Training loss: 3.209600239755045
Validation loss: 2.96678456571893

Epoch: 6| Step: 12
Training loss: 4.186526057155992
Validation loss: 2.970126740285798

Epoch: 6| Step: 13
Training loss: 3.0561636945712083
Validation loss: 2.9642246290628425

Epoch: 25| Step: 0
Training loss: 4.481818663456219
Validation loss: 2.9941815288795617

Epoch: 6| Step: 1
Training loss: 3.423886617975821
Validation loss: 2.9713870863442464

Epoch: 6| Step: 2
Training loss: 3.068975492377699
Validation loss: 2.96272706750013

Epoch: 6| Step: 3
Training loss: 2.6459817218970967
Validation loss: 2.96194041619601

Epoch: 6| Step: 4
Training loss: 2.9998739533965573
Validation loss: 2.9625829261799446

Epoch: 6| Step: 5
Training loss: 2.99412533631126
Validation loss: 2.9671875119577162

Epoch: 6| Step: 6
Training loss: 3.4526416561116764
Validation loss: 2.969484192886238

Epoch: 6| Step: 7
Training loss: 3.073110766126693
Validation loss: 2.9704019195959406

Epoch: 6| Step: 8
Training loss: 3.7887113742753584
Validation loss: 2.970331292677347

Epoch: 6| Step: 9
Training loss: 3.102582557188434
Validation loss: 2.964832516058165

Epoch: 6| Step: 10
Training loss: 2.714452218563221
Validation loss: 2.9595515250174227

Epoch: 6| Step: 11
Training loss: 3.2347089069886428
Validation loss: 2.957702325623675

Epoch: 6| Step: 12
Training loss: 3.2229512767417035
Validation loss: 2.95820484867379

Epoch: 6| Step: 13
Training loss: 3.052563018773166
Validation loss: 2.956790818877483

Epoch: 26| Step: 0
Training loss: 3.24705327768088
Validation loss: 2.9528758789311342

Epoch: 6| Step: 1
Training loss: 4.398588838565382
Validation loss: 2.9546261963115437

Epoch: 6| Step: 2
Training loss: 3.057303710775139
Validation loss: 2.96384155761873

Epoch: 6| Step: 3
Training loss: 3.1222629004468594
Validation loss: 2.9708799725240933

Epoch: 6| Step: 4
Training loss: 2.6243698635355392
Validation loss: 2.999247191601409

Epoch: 6| Step: 5
Training loss: 3.2032689504143987
Validation loss: 3.0035171605641344

Epoch: 6| Step: 6
Training loss: 3.3708764776448072
Validation loss: 2.9703372082381674

Epoch: 6| Step: 7
Training loss: 2.6952063498119037
Validation loss: 2.9589846920994853

Epoch: 6| Step: 8
Training loss: 3.331908891226775
Validation loss: 2.9736398353549633

Epoch: 6| Step: 9
Training loss: 3.335377702042634
Validation loss: 2.9772225342743166

Epoch: 6| Step: 10
Training loss: 3.7632752997961316
Validation loss: 2.9824300049296677

Epoch: 6| Step: 11
Training loss: 2.960972285003457
Validation loss: 2.9499232018514836

Epoch: 6| Step: 12
Training loss: 3.2316909931822133
Validation loss: 2.9444588136957623

Epoch: 6| Step: 13
Training loss: 2.802293611220992
Validation loss: 2.9443362387630465

Epoch: 27| Step: 0
Training loss: 2.7276557545023126
Validation loss: 2.9437070803499137

Epoch: 6| Step: 1
Training loss: 3.4491787969709717
Validation loss: 2.9464716787371783

Epoch: 6| Step: 2
Training loss: 3.341148862096534
Validation loss: 2.9434970877089848

Epoch: 6| Step: 3
Training loss: 3.120930883481365
Validation loss: 2.9475918653989

Epoch: 6| Step: 4
Training loss: 3.1439589080260646
Validation loss: 2.9523213565858963

Epoch: 6| Step: 5
Training loss: 2.785381035207123
Validation loss: 2.9554314067317766

Epoch: 6| Step: 6
Training loss: 2.916992677906303
Validation loss: 2.9696738842944264

Epoch: 6| Step: 7
Training loss: 2.3572810904523664
Validation loss: 2.9888387459345456

Epoch: 6| Step: 8
Training loss: 3.9601369797491177
Validation loss: 3.0129651132300213

Epoch: 6| Step: 9
Training loss: 3.84699217976548
Validation loss: 2.949742735665472

Epoch: 6| Step: 10
Training loss: 3.82990320128185
Validation loss: 2.944449229387123

Epoch: 6| Step: 11
Training loss: 3.3567686394131133
Validation loss: 2.9608521089452373

Epoch: 6| Step: 12
Training loss: 3.172475673380863
Validation loss: 3.00521049955113

Epoch: 6| Step: 13
Training loss: 3.091914084954534
Validation loss: 2.9884783541538975

Epoch: 28| Step: 0
Training loss: 3.4072092088086303
Validation loss: 2.9694016523448012

Epoch: 6| Step: 1
Training loss: 3.2312837285360376
Validation loss: 2.9433235509066473

Epoch: 6| Step: 2
Training loss: 3.009786379258018
Validation loss: 2.934255586463483

Epoch: 6| Step: 3
Training loss: 3.5940819628438705
Validation loss: 2.934735124742957

Epoch: 6| Step: 4
Training loss: 3.1776833556522055
Validation loss: 2.935108911732038

Epoch: 6| Step: 5
Training loss: 3.3208802938232087
Validation loss: 2.9399841023073137

Epoch: 6| Step: 6
Training loss: 3.1401968137447587
Validation loss: 2.9503998912411395

Epoch: 6| Step: 7
Training loss: 3.3213582624737485
Validation loss: 2.962962787688272

Epoch: 6| Step: 8
Training loss: 3.3825693373470482
Validation loss: 2.9620271217324396

Epoch: 6| Step: 9
Training loss: 3.644863428348985
Validation loss: 2.93073046598925

Epoch: 6| Step: 10
Training loss: 2.5000675192298325
Validation loss: 2.9236409604882394

Epoch: 6| Step: 11
Training loss: 3.0311277699160346
Validation loss: 2.925469144162157

Epoch: 6| Step: 12
Training loss: 3.047507508967273
Validation loss: 2.9248289861995977

Epoch: 6| Step: 13
Training loss: 3.6064811434129207
Validation loss: 2.931812028944121

Epoch: 29| Step: 0
Training loss: 3.285049128288427
Validation loss: 2.9315966876482533

Epoch: 6| Step: 1
Training loss: 3.5778576613591393
Validation loss: 2.9284364698447845

Epoch: 6| Step: 2
Training loss: 3.197733290858212
Validation loss: 2.927052534742241

Epoch: 6| Step: 3
Training loss: 3.8637179136594595
Validation loss: 2.9258706497997555

Epoch: 6| Step: 4
Training loss: 3.0389771437242046
Validation loss: 2.9379856787680123

Epoch: 6| Step: 5
Training loss: 3.3055824168277694
Validation loss: 2.926084363219896

Epoch: 6| Step: 6
Training loss: 3.4268823504816983
Validation loss: 2.921200648831217

Epoch: 6| Step: 7
Training loss: 3.090808741832608
Validation loss: 2.9190216916817757

Epoch: 6| Step: 8
Training loss: 3.4621146032359964
Validation loss: 2.9173235497803383

Epoch: 6| Step: 9
Training loss: 3.0638253594371014
Validation loss: 2.9157041540718684

Epoch: 6| Step: 10
Training loss: 2.549245468406469
Validation loss: 2.9139818523855183

Epoch: 6| Step: 11
Training loss: 3.6765090594803267
Validation loss: 2.9126018754398557

Epoch: 6| Step: 12
Training loss: 2.2448439330162473
Validation loss: 2.9151606417408202

Epoch: 6| Step: 13
Training loss: 3.0126540021985417
Validation loss: 2.914177466718846

Epoch: 30| Step: 0
Training loss: 3.1391598144758914
Validation loss: 2.911290672315178

Epoch: 6| Step: 1
Training loss: 2.22777708956781
Validation loss: 2.912255338430316

Epoch: 6| Step: 2
Training loss: 3.2246933665621
Validation loss: 2.913277388064838

Epoch: 6| Step: 3
Training loss: 3.70932325087639
Validation loss: 2.914808172247938

Epoch: 6| Step: 4
Training loss: 3.508952543897148
Validation loss: 2.915997127441349

Epoch: 6| Step: 5
Training loss: 3.3084555352716514
Validation loss: 2.912442866685752

Epoch: 6| Step: 6
Training loss: 3.7183159326419486
Validation loss: 2.909442842742714

Epoch: 6| Step: 7
Training loss: 2.4070597685622914
Validation loss: 2.912419599282165

Epoch: 6| Step: 8
Training loss: 3.5000971371931375
Validation loss: 2.9143412383394796

Epoch: 6| Step: 9
Training loss: 2.7013312766483732
Validation loss: 2.9181764700075483

Epoch: 6| Step: 10
Training loss: 2.4975308622757835
Validation loss: 2.9080193715383866

Epoch: 6| Step: 11
Training loss: 3.8933827381613777
Validation loss: 2.9087723966454986

Epoch: 6| Step: 12
Training loss: 3.2122473353908454
Validation loss: 2.9070172699061136

Epoch: 6| Step: 13
Training loss: 3.5356703916525087
Validation loss: 2.904080192575663

Epoch: 31| Step: 0
Training loss: 3.219737966075878
Validation loss: 2.9038747218929806

Epoch: 6| Step: 1
Training loss: 3.2777701681303784
Validation loss: 2.9038761662097774

Epoch: 6| Step: 2
Training loss: 3.5677522457047037
Validation loss: 2.899537768140408

Epoch: 6| Step: 3
Training loss: 3.392088121727017
Validation loss: 2.900241571731866

Epoch: 6| Step: 4
Training loss: 3.197900297804368
Validation loss: 2.899747040946294

Epoch: 6| Step: 5
Training loss: 2.6133738502780535
Validation loss: 2.897332449178266

Epoch: 6| Step: 6
Training loss: 2.9583269754977253
Validation loss: 2.899069203316461

Epoch: 6| Step: 7
Training loss: 3.445090496496824
Validation loss: 2.898144904595803

Epoch: 6| Step: 8
Training loss: 3.3258533157236445
Validation loss: 2.8975405824278893

Epoch: 6| Step: 9
Training loss: 3.410975826395848
Validation loss: 2.8989803963456358

Epoch: 6| Step: 10
Training loss: 3.3972558784498568
Validation loss: 2.902702900580451

Epoch: 6| Step: 11
Training loss: 2.0964223404376523
Validation loss: 2.906290755094762

Epoch: 6| Step: 12
Training loss: 3.370255703153497
Validation loss: 2.907467254958491

Epoch: 6| Step: 13
Training loss: 3.4354580449715533
Validation loss: 2.902289793992823

Epoch: 32| Step: 0
Training loss: 3.622358741085854
Validation loss: 2.8996431778285467

Epoch: 6| Step: 1
Training loss: 3.0294978790200227
Validation loss: 2.8950337622025475

Epoch: 6| Step: 2
Training loss: 2.9947403259299423
Validation loss: 2.8946557541520885

Epoch: 6| Step: 3
Training loss: 2.8865251489122237
Validation loss: 2.8915253660167273

Epoch: 6| Step: 4
Training loss: 2.448582811553283
Validation loss: 2.891450898223405

Epoch: 6| Step: 5
Training loss: 3.4371423708674484
Validation loss: 2.8900653336115245

Epoch: 6| Step: 6
Training loss: 2.9732416807112982
Validation loss: 2.888523695641157

Epoch: 6| Step: 7
Training loss: 3.428322487830806
Validation loss: 2.8894016203558217

Epoch: 6| Step: 8
Training loss: 2.661854295831447
Validation loss: 2.892333669164255

Epoch: 6| Step: 9
Training loss: 3.0921099390419595
Validation loss: 2.8888363009757656

Epoch: 6| Step: 10
Training loss: 2.971385548877514
Validation loss: 2.8881347341446424

Epoch: 6| Step: 11
Training loss: 3.9805437404767496
Validation loss: 2.887025880982979

Epoch: 6| Step: 12
Training loss: 3.4160979813364283
Validation loss: 2.8904307470040624

Epoch: 6| Step: 13
Training loss: 3.621748419615895
Validation loss: 2.8923092339670533

Epoch: 33| Step: 0
Training loss: 3.2457188505681747
Validation loss: 2.886794901957974

Epoch: 6| Step: 1
Training loss: 3.4851416869074097
Validation loss: 2.8855934632357396

Epoch: 6| Step: 2
Training loss: 3.470826498317209
Validation loss: 2.887358060367794

Epoch: 6| Step: 3
Training loss: 3.611489473393307
Validation loss: 2.8890262260980064

Epoch: 6| Step: 4
Training loss: 3.8549795719698925
Validation loss: 2.8807583763420386

Epoch: 6| Step: 5
Training loss: 2.5001756606377503
Validation loss: 2.8802449578732587

Epoch: 6| Step: 6
Training loss: 3.2770389237803066
Validation loss: 2.8786520231327684

Epoch: 6| Step: 7
Training loss: 2.934306742531383
Validation loss: 2.8761043166505

Epoch: 6| Step: 8
Training loss: 2.5188665888380237
Validation loss: 2.877778513225143

Epoch: 6| Step: 9
Training loss: 3.1201482111622743
Validation loss: 2.87545778786064

Epoch: 6| Step: 10
Training loss: 3.9385517471670095
Validation loss: 2.878271164453367

Epoch: 6| Step: 11
Training loss: 2.7686258189164707
Validation loss: 2.876359641259536

Epoch: 6| Step: 12
Training loss: 2.5809059634246685
Validation loss: 2.8788292481975306

Epoch: 6| Step: 13
Training loss: 2.509033761391425
Validation loss: 2.878014475525505

Epoch: 34| Step: 0
Training loss: 3.3076948906303243
Validation loss: 2.884944324622648

Epoch: 6| Step: 1
Training loss: 3.513177044870981
Validation loss: 2.903165012837438

Epoch: 6| Step: 2
Training loss: 3.3439085735617597
Validation loss: 2.903647909334289

Epoch: 6| Step: 3
Training loss: 3.1639729805044645
Validation loss: 2.9015716637409312

Epoch: 6| Step: 4
Training loss: 3.7119249816910562
Validation loss: 2.895472141869213

Epoch: 6| Step: 5
Training loss: 2.7187495615290147
Validation loss: 2.884960869040537

Epoch: 6| Step: 6
Training loss: 3.109361504760287
Validation loss: 2.8714819700294036

Epoch: 6| Step: 7
Training loss: 3.0673775270568915
Validation loss: 2.8702202987458705

Epoch: 6| Step: 8
Training loss: 3.190371547574399
Validation loss: 2.8711361381142413

Epoch: 6| Step: 9
Training loss: 3.2960726227120505
Validation loss: 2.871700362243969

Epoch: 6| Step: 10
Training loss: 3.337840196508694
Validation loss: 2.8690955598575814

Epoch: 6| Step: 11
Training loss: 3.134078609490954
Validation loss: 2.8743381210961054

Epoch: 6| Step: 12
Training loss: 2.909686610070446
Validation loss: 2.8703312570999766

Epoch: 6| Step: 13
Training loss: 1.9516808015076417
Validation loss: 2.8682125307185142

Epoch: 35| Step: 0
Training loss: 2.7314702763540133
Validation loss: 2.8666883035569644

Epoch: 6| Step: 1
Training loss: 3.236745214664843
Validation loss: 2.8652196690108545

Epoch: 6| Step: 2
Training loss: 2.8941141051896038
Validation loss: 2.8762436264035993

Epoch: 6| Step: 3
Training loss: 3.558920551121755
Validation loss: 2.903000939227856

Epoch: 6| Step: 4
Training loss: 3.67944101856606
Validation loss: 2.8860845814877383

Epoch: 6| Step: 5
Training loss: 3.0027240465665677
Validation loss: 2.8690534498698397

Epoch: 6| Step: 6
Training loss: 2.2064626315695763
Validation loss: 2.8628175712550106

Epoch: 6| Step: 7
Training loss: 3.2326326699111143
Validation loss: 2.8625913323580896

Epoch: 6| Step: 8
Training loss: 4.152783317661453
Validation loss: 2.8630906575335078

Epoch: 6| Step: 9
Training loss: 3.4008174586718165
Validation loss: 2.861902823182897

Epoch: 6| Step: 10
Training loss: 2.95081008521331
Validation loss: 2.858710250451519

Epoch: 6| Step: 11
Training loss: 2.1799666249931406
Validation loss: 2.8592661090417306

Epoch: 6| Step: 12
Training loss: 3.4354468022573332
Validation loss: 2.859441707000408

Epoch: 6| Step: 13
Training loss: 3.0617852447367526
Validation loss: 2.8593099044167283

Epoch: 36| Step: 0
Training loss: 3.6807727549701394
Validation loss: 2.8574559445610883

Epoch: 6| Step: 1
Training loss: 3.560838010502041
Validation loss: 2.8562756498083584

Epoch: 6| Step: 2
Training loss: 2.6912653959536432
Validation loss: 2.857419890422537

Epoch: 6| Step: 3
Training loss: 2.942910588608486
Validation loss: 2.8554058135069815

Epoch: 6| Step: 4
Training loss: 3.919236712977862
Validation loss: 2.857123322354174

Epoch: 6| Step: 5
Training loss: 2.7698534521179488
Validation loss: 2.8720063955084005

Epoch: 6| Step: 6
Training loss: 3.4464943863283275
Validation loss: 2.899068396836718

Epoch: 6| Step: 7
Training loss: 2.4568869543840055
Validation loss: 2.8531384113997844

Epoch: 6| Step: 8
Training loss: 3.233461407618861
Validation loss: 2.856851369756234

Epoch: 6| Step: 9
Training loss: 3.1617655387491155
Validation loss: 2.862404373183009

Epoch: 6| Step: 10
Training loss: 3.2898407873803004
Validation loss: 2.870763920661133

Epoch: 6| Step: 11
Training loss: 3.2333207185898982
Validation loss: 2.8921614191360496

Epoch: 6| Step: 12
Training loss: 2.800170746774219
Validation loss: 2.9671393774393096

Epoch: 6| Step: 13
Training loss: 2.579120235816062
Validation loss: 3.096580005675032

Epoch: 37| Step: 0
Training loss: 3.5402459530060733
Validation loss: 3.0908534582824774

Epoch: 6| Step: 1
Training loss: 3.3023456906488264
Validation loss: 2.9759975305528923

Epoch: 6| Step: 2
Training loss: 3.5600763743491135
Validation loss: 2.885122137933013

Epoch: 6| Step: 3
Training loss: 3.11122681955091
Validation loss: 2.906922889567381

Epoch: 6| Step: 4
Training loss: 2.852473199770283
Validation loss: 2.9390560297422588

Epoch: 6| Step: 5
Training loss: 3.650084685296886
Validation loss: 2.972643005980635

Epoch: 6| Step: 6
Training loss: 2.9315599485068446
Validation loss: 2.9420078557185647

Epoch: 6| Step: 7
Training loss: 2.653683578227765
Validation loss: 2.904563956351822

Epoch: 6| Step: 8
Training loss: 3.1396400843104275
Validation loss: 2.883971540129287

Epoch: 6| Step: 9
Training loss: 2.9830923469717665
Validation loss: 2.860684990490958

Epoch: 6| Step: 10
Training loss: 3.3934258350087863
Validation loss: 2.8516788231373296

Epoch: 6| Step: 11
Training loss: 2.8810167793333474
Validation loss: 2.8524183651285813

Epoch: 6| Step: 12
Training loss: 3.3091160025393065
Validation loss: 2.8626547189510547

Epoch: 6| Step: 13
Training loss: 3.8906025713538384
Validation loss: 2.8565863913786855

Epoch: 38| Step: 0
Training loss: 3.2193644409362
Validation loss: 2.869448687742888

Epoch: 6| Step: 1
Training loss: 4.32445648835524
Validation loss: 2.9054058894284513

Epoch: 6| Step: 2
Training loss: 3.4962361397330404
Validation loss: 2.857826037058

Epoch: 6| Step: 3
Training loss: 3.7692170165333554
Validation loss: 2.8407113113393905

Epoch: 6| Step: 4
Training loss: 2.005462577522031
Validation loss: 2.840954901287678

Epoch: 6| Step: 5
Training loss: 3.6556544674751863
Validation loss: 2.844866829347711

Epoch: 6| Step: 6
Training loss: 3.186131651136918
Validation loss: 2.851700901432449

Epoch: 6| Step: 7
Training loss: 2.922792994265776
Validation loss: 2.8674110686886287

Epoch: 6| Step: 8
Training loss: 2.891957238921926
Validation loss: 2.865005721258477

Epoch: 6| Step: 9
Training loss: 2.8007732481689214
Validation loss: 2.8850682819303612

Epoch: 6| Step: 10
Training loss: 2.6478625548381407
Validation loss: 2.857585677738411

Epoch: 6| Step: 11
Training loss: 2.796062841721544
Validation loss: 2.8445040453497077

Epoch: 6| Step: 12
Training loss: 2.550714325428524
Validation loss: 2.8362277162767726

Epoch: 6| Step: 13
Training loss: 3.7408305915544307
Validation loss: 2.832424786035038

Epoch: 39| Step: 0
Training loss: 2.351050844006985
Validation loss: 2.829729282262769

Epoch: 6| Step: 1
Training loss: 3.1580008003760516
Validation loss: 2.8445330324604017

Epoch: 6| Step: 2
Training loss: 3.1868684928484967
Validation loss: 2.873652298806458

Epoch: 6| Step: 3
Training loss: 3.09211795800007
Validation loss: 2.8519746665417967

Epoch: 6| Step: 4
Training loss: 3.2695280414597456
Validation loss: 2.826813047178547

Epoch: 6| Step: 5
Training loss: 2.9751976268105453
Validation loss: 2.827849876987373

Epoch: 6| Step: 6
Training loss: 3.062733232608739
Validation loss: 2.8296481680853205

Epoch: 6| Step: 7
Training loss: 3.230028558374529
Validation loss: 2.829323604759928

Epoch: 6| Step: 8
Training loss: 3.90854900608228
Validation loss: 2.829940727907795

Epoch: 6| Step: 9
Training loss: 3.0919808617970514
Validation loss: 2.832537617744555

Epoch: 6| Step: 10
Training loss: 3.3544948883267875
Validation loss: 2.8476104352281375

Epoch: 6| Step: 11
Training loss: 3.10208855691081
Validation loss: 2.8407191456214522

Epoch: 6| Step: 12
Training loss: 3.0893875344693753
Validation loss: 2.8329107420599504

Epoch: 6| Step: 13
Training loss: 2.97495656983547
Validation loss: 2.8279604000765173

Epoch: 40| Step: 0
Training loss: 2.7325633996028564
Validation loss: 2.8235375710984645

Epoch: 6| Step: 1
Training loss: 3.2562394037641744
Validation loss: 2.8279799920090958

Epoch: 6| Step: 2
Training loss: 3.014839663061657
Validation loss: 2.8292854315567113

Epoch: 6| Step: 3
Training loss: 2.7925360924720004
Validation loss: 2.8314711634509937

Epoch: 6| Step: 4
Training loss: 3.2995434127289354
Validation loss: 2.8499097474823922

Epoch: 6| Step: 5
Training loss: 3.8880253574815997
Validation loss: 2.845314132115931

Epoch: 6| Step: 6
Training loss: 3.5742758490999242
Validation loss: 2.831386442572323

Epoch: 6| Step: 7
Training loss: 2.7297000703484
Validation loss: 2.8190675256179167

Epoch: 6| Step: 8
Training loss: 3.327438641906025
Validation loss: 2.8184820002428785

Epoch: 6| Step: 9
Training loss: 2.3608826121546205
Validation loss: 2.822236546345574

Epoch: 6| Step: 10
Training loss: 3.4755941692618166
Validation loss: 2.8287734328103498

Epoch: 6| Step: 11
Training loss: 2.842527189502166
Validation loss: 2.83252367603473

Epoch: 6| Step: 12
Training loss: 3.4577920022762876
Validation loss: 2.843115595970714

Epoch: 6| Step: 13
Training loss: 2.8395359549391324
Validation loss: 2.8434110753006974

Epoch: 41| Step: 0
Training loss: 3.178635931814766
Validation loss: 2.84128767127791

Epoch: 6| Step: 1
Training loss: 2.81284686174903
Validation loss: 2.82919498866613

Epoch: 6| Step: 2
Training loss: 3.07755518252545
Validation loss: 2.8254864579403445

Epoch: 6| Step: 3
Training loss: 3.239036849233636
Validation loss: 2.820002017705913

Epoch: 6| Step: 4
Training loss: 2.7365771336222484
Validation loss: 2.8183478737207017

Epoch: 6| Step: 5
Training loss: 2.9831872943389706
Validation loss: 2.8120346322389334

Epoch: 6| Step: 6
Training loss: 3.735401347707444
Validation loss: 2.8093328547869367

Epoch: 6| Step: 7
Training loss: 3.860457542657304
Validation loss: 2.8076250145987203

Epoch: 6| Step: 8
Training loss: 2.6235340202892803
Validation loss: 2.8073555524351312

Epoch: 6| Step: 9
Training loss: 3.2861509506835973
Validation loss: 2.8053746988736323

Epoch: 6| Step: 10
Training loss: 2.700465134009777
Validation loss: 2.8061026122032655

Epoch: 6| Step: 11
Training loss: 3.4429628833074166
Validation loss: 2.8048987897304354

Epoch: 6| Step: 12
Training loss: 2.527490720646971
Validation loss: 2.804076688881637

Epoch: 6| Step: 13
Training loss: 3.5545324270776435
Validation loss: 2.804501031920055

Epoch: 42| Step: 0
Training loss: 2.7759365803842546
Validation loss: 2.8047926966992995

Epoch: 6| Step: 1
Training loss: 2.5594452118238205
Validation loss: 2.801966130915119

Epoch: 6| Step: 2
Training loss: 3.5515060776115144
Validation loss: 2.8055661245714414

Epoch: 6| Step: 3
Training loss: 3.669736848382586
Validation loss: 2.808564507885882

Epoch: 6| Step: 4
Training loss: 2.822679704430907
Validation loss: 2.8091175344494346

Epoch: 6| Step: 5
Training loss: 3.219672802241124
Validation loss: 2.7963154404275445

Epoch: 6| Step: 6
Training loss: 3.635164151899455
Validation loss: 2.796345557811217

Epoch: 6| Step: 7
Training loss: 2.9704039132681914
Validation loss: 2.794423413694123

Epoch: 6| Step: 8
Training loss: 2.5997643657426446
Validation loss: 2.795328757431855

Epoch: 6| Step: 9
Training loss: 2.7570306896318324
Validation loss: 2.7911654475288024

Epoch: 6| Step: 10
Training loss: 2.9027721966735953
Validation loss: 2.7879011636852433

Epoch: 6| Step: 11
Training loss: 3.266124048384947
Validation loss: 2.7904871354408147

Epoch: 6| Step: 12
Training loss: 3.5379618097274372
Validation loss: 2.79261747216865

Epoch: 6| Step: 13
Training loss: 3.0833765147166745
Validation loss: 2.7922398274669455

Epoch: 43| Step: 0
Training loss: 3.4011871789684545
Validation loss: 2.7888679090672017

Epoch: 6| Step: 1
Training loss: 2.2748582732940132
Validation loss: 2.788569737436132

Epoch: 6| Step: 2
Training loss: 3.0571210684719246
Validation loss: 2.787900125502522

Epoch: 6| Step: 3
Training loss: 3.3488189209455927
Validation loss: 2.7872850478408915

Epoch: 6| Step: 4
Training loss: 3.1299329351973353
Validation loss: 2.7836652764731324

Epoch: 6| Step: 5
Training loss: 3.2031450968786466
Validation loss: 2.7913181413070713

Epoch: 6| Step: 6
Training loss: 3.173355283287279
Validation loss: 2.802721932407764

Epoch: 6| Step: 7
Training loss: 3.1852091616665383
Validation loss: 2.7891024379318656

Epoch: 6| Step: 8
Training loss: 2.94872104916787
Validation loss: 2.781738976133775

Epoch: 6| Step: 9
Training loss: 2.9454633841076925
Validation loss: 2.7858704360883753

Epoch: 6| Step: 10
Training loss: 3.6801830047216657
Validation loss: 2.7842720884737657

Epoch: 6| Step: 11
Training loss: 3.2323523937490926
Validation loss: 2.787218424958083

Epoch: 6| Step: 12
Training loss: 2.7499661877027326
Validation loss: 2.7872230873424146

Epoch: 6| Step: 13
Training loss: 2.933222964406787
Validation loss: 2.78650758178603

Epoch: 44| Step: 0
Training loss: 3.2135271085453687
Validation loss: 2.787602852781098

Epoch: 6| Step: 1
Training loss: 2.9293225684172897
Validation loss: 2.7910542453815657

Epoch: 6| Step: 2
Training loss: 3.9104125770597595
Validation loss: 2.790160194329422

Epoch: 6| Step: 3
Training loss: 2.8170756101471848
Validation loss: 2.7936924352572343

Epoch: 6| Step: 4
Training loss: 3.118987440959061
Validation loss: 2.784934686027558

Epoch: 6| Step: 5
Training loss: 3.130659547974239
Validation loss: 2.7802928398858584

Epoch: 6| Step: 6
Training loss: 3.490913858645247
Validation loss: 2.7778743220201854

Epoch: 6| Step: 7
Training loss: 3.372843583281068
Validation loss: 2.7759847010445386

Epoch: 6| Step: 8
Training loss: 2.262146377326718
Validation loss: 2.7758206112078336

Epoch: 6| Step: 9
Training loss: 2.3734801599361632
Validation loss: 2.7714364500068354

Epoch: 6| Step: 10
Training loss: 2.79760374666028
Validation loss: 2.7718236280639714

Epoch: 6| Step: 11
Training loss: 3.356058444163279
Validation loss: 2.770486011582948

Epoch: 6| Step: 12
Training loss: 3.225179232562637
Validation loss: 2.769679429179765

Epoch: 6| Step: 13
Training loss: 2.8830635767822663
Validation loss: 2.7742624620667082

Epoch: 45| Step: 0
Training loss: 2.8063378539065025
Validation loss: 2.7798167904281668

Epoch: 6| Step: 1
Training loss: 3.1069433777766147
Validation loss: 2.777152785538427

Epoch: 6| Step: 2
Training loss: 3.4021382844640824
Validation loss: 2.7844008659239625

Epoch: 6| Step: 3
Training loss: 3.3989804590510286
Validation loss: 2.7920400883709355

Epoch: 6| Step: 4
Training loss: 2.706276175920788
Validation loss: 2.7810643074086796

Epoch: 6| Step: 5
Training loss: 3.320288373074106
Validation loss: 2.773286221491955

Epoch: 6| Step: 6
Training loss: 2.986585667085138
Validation loss: 2.763013474935539

Epoch: 6| Step: 7
Training loss: 3.841854713675572
Validation loss: 2.7596039810730235

Epoch: 6| Step: 8
Training loss: 2.9748212872850326
Validation loss: 2.7621265510670807

Epoch: 6| Step: 9
Training loss: 3.2447817063931366
Validation loss: 2.759200596818011

Epoch: 6| Step: 10
Training loss: 2.371997943652132
Validation loss: 2.7617206455414562

Epoch: 6| Step: 11
Training loss: 2.8722957663975914
Validation loss: 2.7635635471278293

Epoch: 6| Step: 12
Training loss: 3.2089029442270065
Validation loss: 2.7639399630778816

Epoch: 6| Step: 13
Training loss: 2.306177104014999
Validation loss: 2.7641885914821644

Epoch: 46| Step: 0
Training loss: 3.633819374915561
Validation loss: 2.7636228989492673

Epoch: 6| Step: 1
Training loss: 2.5120041656884804
Validation loss: 2.7637036217257873

Epoch: 6| Step: 2
Training loss: 2.705761984857717
Validation loss: 2.7640707326125646

Epoch: 6| Step: 3
Training loss: 3.0386465224328836
Validation loss: 2.7608536364936898

Epoch: 6| Step: 4
Training loss: 3.4609587175739294
Validation loss: 2.7619215655582234

Epoch: 6| Step: 5
Training loss: 3.7065290426415536
Validation loss: 2.757376290676302

Epoch: 6| Step: 6
Training loss: 3.4035048315743293
Validation loss: 2.758529704152969

Epoch: 6| Step: 7
Training loss: 3.240843712719865
Validation loss: 2.7588965817109514

Epoch: 6| Step: 8
Training loss: 2.8563558346028297
Validation loss: 2.7537101671725575

Epoch: 6| Step: 9
Training loss: 3.5556459580955595
Validation loss: 2.7576633801041726

Epoch: 6| Step: 10
Training loss: 3.0061406232640513
Validation loss: 2.7543495270049245

Epoch: 6| Step: 11
Training loss: 2.6476515782580408
Validation loss: 2.7506803974124665

Epoch: 6| Step: 12
Training loss: 2.2224090921456296
Validation loss: 2.7554788575109637

Epoch: 6| Step: 13
Training loss: 2.5137004243049
Validation loss: 2.757224041690424

Epoch: 47| Step: 0
Training loss: 3.7255909291005223
Validation loss: 2.753939439557126

Epoch: 6| Step: 1
Training loss: 3.995094748699513
Validation loss: 2.758090704508307

Epoch: 6| Step: 2
Training loss: 2.5206873407465284
Validation loss: 2.754055806973661

Epoch: 6| Step: 3
Training loss: 3.202011286947359
Validation loss: 2.750029089243381

Epoch: 6| Step: 4
Training loss: 3.2262633695329095
Validation loss: 2.745106731634819

Epoch: 6| Step: 5
Training loss: 2.857438562622153
Validation loss: 2.747727940559452

Epoch: 6| Step: 6
Training loss: 3.351788706581806
Validation loss: 2.7496623860256384

Epoch: 6| Step: 7
Training loss: 2.991839117182036
Validation loss: 2.7511116989533213

Epoch: 6| Step: 8
Training loss: 3.0981668097233857
Validation loss: 2.7518032329538613

Epoch: 6| Step: 9
Training loss: 2.749061771213634
Validation loss: 2.7551570084014503

Epoch: 6| Step: 10
Training loss: 2.2546186726111177
Validation loss: 2.7535641079144306

Epoch: 6| Step: 11
Training loss: 2.658654235636053
Validation loss: 2.7611911875083353

Epoch: 6| Step: 12
Training loss: 3.3286639569658156
Validation loss: 2.757069948788808

Epoch: 6| Step: 13
Training loss: 2.284998492150675
Validation loss: 2.751046648094893

Epoch: 48| Step: 0
Training loss: 2.733943621804109
Validation loss: 2.752050437083848

Epoch: 6| Step: 1
Training loss: 3.325632800928468
Validation loss: 2.750905770583545

Epoch: 6| Step: 2
Training loss: 3.1995867283508304
Validation loss: 2.7468657181562794

Epoch: 6| Step: 3
Training loss: 2.3187182565660107
Validation loss: 2.7432974587250665

Epoch: 6| Step: 4
Training loss: 2.6164097783363043
Validation loss: 2.7441086762390596

Epoch: 6| Step: 5
Training loss: 3.2409194856628
Validation loss: 2.7395523058926563

Epoch: 6| Step: 6
Training loss: 3.022751052564741
Validation loss: 2.7395105703582097

Epoch: 6| Step: 7
Training loss: 2.9712451287383326
Validation loss: 2.7357492029699806

Epoch: 6| Step: 8
Training loss: 3.0007874726874264
Validation loss: 2.7356553022238903

Epoch: 6| Step: 9
Training loss: 2.9270896685295282
Validation loss: 2.737020852131408

Epoch: 6| Step: 10
Training loss: 3.1925438262392727
Validation loss: 2.7362157979200314

Epoch: 6| Step: 11
Training loss: 3.215510247113511
Validation loss: 2.7343608868728406

Epoch: 6| Step: 12
Training loss: 3.833020377168897
Validation loss: 2.7366243969275077

Epoch: 6| Step: 13
Training loss: 3.241490006393333
Validation loss: 2.7377356175687555

Epoch: 49| Step: 0
Training loss: 3.181163998024028
Validation loss: 2.735834267780638

Epoch: 6| Step: 1
Training loss: 3.635137654758478
Validation loss: 2.7423617184899864

Epoch: 6| Step: 2
Training loss: 3.261674599719906
Validation loss: 2.749458589703274

Epoch: 6| Step: 3
Training loss: 3.2208221580110807
Validation loss: 2.7517605717851548

Epoch: 6| Step: 4
Training loss: 3.5264635984034003
Validation loss: 2.7521820323660555

Epoch: 6| Step: 5
Training loss: 2.8559656715360195
Validation loss: 2.751795686804714

Epoch: 6| Step: 6
Training loss: 2.8126551267440365
Validation loss: 2.734992372632998

Epoch: 6| Step: 7
Training loss: 2.3902003091802517
Validation loss: 2.7392263570977056

Epoch: 6| Step: 8
Training loss: 2.943242405501787
Validation loss: 2.7404816881591683

Epoch: 6| Step: 9
Training loss: 2.896888010269463
Validation loss: 2.7329956016236934

Epoch: 6| Step: 10
Training loss: 3.084803582960636
Validation loss: 2.7326553998921415

Epoch: 6| Step: 11
Training loss: 2.661222851831119
Validation loss: 2.727532319578916

Epoch: 6| Step: 12
Training loss: 2.841539466971803
Validation loss: 2.7249882366178273

Epoch: 6| Step: 13
Training loss: 3.501611747208139
Validation loss: 2.723168665084079

Epoch: 50| Step: 0
Training loss: 3.1919799438458356
Validation loss: 2.724519442222531

Epoch: 6| Step: 1
Training loss: 3.1771707157979754
Validation loss: 2.7232277384375254

Epoch: 6| Step: 2
Training loss: 2.687545687264958
Validation loss: 2.725988704077207

Epoch: 6| Step: 3
Training loss: 3.1631361370572746
Validation loss: 2.728513590822884

Epoch: 6| Step: 4
Training loss: 2.9470931521560955
Validation loss: 2.725883600813418

Epoch: 6| Step: 5
Training loss: 3.076741793684098
Validation loss: 2.7247250925831557

Epoch: 6| Step: 6
Training loss: 3.0831157676300265
Validation loss: 2.722067295579982

Epoch: 6| Step: 7
Training loss: 3.255104604467105
Validation loss: 2.7225579503723654

Epoch: 6| Step: 8
Training loss: 2.884362607786726
Validation loss: 2.726504997683452

Epoch: 6| Step: 9
Training loss: 2.6869917987887146
Validation loss: 2.7251397747955366

Epoch: 6| Step: 10
Training loss: 3.0111764303288293
Validation loss: 2.723405292514856

Epoch: 6| Step: 11
Training loss: 3.2759014315931667
Validation loss: 2.7156609645635976

Epoch: 6| Step: 12
Training loss: 3.5108493496770734
Validation loss: 2.719080495542591

Epoch: 6| Step: 13
Training loss: 2.6084806999851127
Validation loss: 2.7221378034011705

Epoch: 51| Step: 0
Training loss: 2.94309497194977
Validation loss: 2.720514601064056

Epoch: 6| Step: 1
Training loss: 2.886483684874958
Validation loss: 2.7220815901697817

Epoch: 6| Step: 2
Training loss: 2.540037748401717
Validation loss: 2.722981227911503

Epoch: 6| Step: 3
Training loss: 2.661361802074368
Validation loss: 2.7238438917367818

Epoch: 6| Step: 4
Training loss: 2.8316756242232817
Validation loss: 2.7316683535107766

Epoch: 6| Step: 5
Training loss: 3.579022557322084
Validation loss: 2.7300194168376946

Epoch: 6| Step: 6
Training loss: 3.500805625839176
Validation loss: 2.728908404170083

Epoch: 6| Step: 7
Training loss: 3.143735341820946
Validation loss: 2.7275072068917696

Epoch: 6| Step: 8
Training loss: 3.2945264794991544
Validation loss: 2.7289248912596356

Epoch: 6| Step: 9
Training loss: 3.737200701412971
Validation loss: 2.726292908620246

Epoch: 6| Step: 10
Training loss: 3.1572801778331123
Validation loss: 2.7179678542810577

Epoch: 6| Step: 11
Training loss: 2.1657679478970464
Validation loss: 2.7124007658132694

Epoch: 6| Step: 12
Training loss: 3.138793411228133
Validation loss: 2.715016791216735

Epoch: 6| Step: 13
Training loss: 2.4894440956496675
Validation loss: 2.7095880679860227

Epoch: 52| Step: 0
Training loss: 3.36086775859439
Validation loss: 2.710408115713191

Epoch: 6| Step: 1
Training loss: 2.4835313048166707
Validation loss: 2.713595531833525

Epoch: 6| Step: 2
Training loss: 3.535484678070959
Validation loss: 2.7144460929103875

Epoch: 6| Step: 3
Training loss: 3.567775501073745
Validation loss: 2.7123437260212775

Epoch: 6| Step: 4
Training loss: 3.3651057134066895
Validation loss: 2.7105911713122075

Epoch: 6| Step: 5
Training loss: 3.1362365123934643
Validation loss: 2.7156296870839034

Epoch: 6| Step: 6
Training loss: 3.1112032168998773
Validation loss: 2.72760889596264

Epoch: 6| Step: 7
Training loss: 2.4448292410105443
Validation loss: 2.726497200984542

Epoch: 6| Step: 8
Training loss: 3.1111101839276096
Validation loss: 2.7236165625768245

Epoch: 6| Step: 9
Training loss: 2.840156716334478
Validation loss: 2.716118019120551

Epoch: 6| Step: 10
Training loss: 2.9465782622917973
Validation loss: 2.7187742940109367

Epoch: 6| Step: 11
Training loss: 2.6849038647822305
Validation loss: 2.7073514996600188

Epoch: 6| Step: 12
Training loss: 3.1898144565781594
Validation loss: 2.704436355456354

Epoch: 6| Step: 13
Training loss: 2.204357587000895
Validation loss: 2.7052520420023356

Epoch: 53| Step: 0
Training loss: 3.464790902922796
Validation loss: 2.7054542901599565

Epoch: 6| Step: 1
Training loss: 3.2520883159774416
Validation loss: 2.7050730300842902

Epoch: 6| Step: 2
Training loss: 2.5191679463418515
Validation loss: 2.704992556911342

Epoch: 6| Step: 3
Training loss: 2.98938622085153
Validation loss: 2.7059481609927505

Epoch: 6| Step: 4
Training loss: 2.9573243977257193
Validation loss: 2.7037630406378024

Epoch: 6| Step: 5
Training loss: 3.4023908399439318
Validation loss: 2.7008753124906537

Epoch: 6| Step: 6
Training loss: 2.796710132023166
Validation loss: 2.702371906241189

Epoch: 6| Step: 7
Training loss: 2.9313528795224686
Validation loss: 2.701796105028541

Epoch: 6| Step: 8
Training loss: 3.5222608542772256
Validation loss: 2.7039017124224882

Epoch: 6| Step: 9
Training loss: 2.868746383099572
Validation loss: 2.7006466536671168

Epoch: 6| Step: 10
Training loss: 3.191931243634003
Validation loss: 2.7011805932770896

Epoch: 6| Step: 11
Training loss: 3.1885951535660224
Validation loss: 2.700584631503755

Epoch: 6| Step: 12
Training loss: 2.4322637410708423
Validation loss: 2.700354984454024

Epoch: 6| Step: 13
Training loss: 2.6485278809015935
Validation loss: 2.6981888855166316

Epoch: 54| Step: 0
Training loss: 3.468201739998147
Validation loss: 2.6987957618304717

Epoch: 6| Step: 1
Training loss: 3.118509342181445
Validation loss: 2.6993274016556357

Epoch: 6| Step: 2
Training loss: 2.603209378087385
Validation loss: 2.6997611498114504

Epoch: 6| Step: 3
Training loss: 3.6185669215245637
Validation loss: 2.6977917430894958

Epoch: 6| Step: 4
Training loss: 3.1466101556757486
Validation loss: 2.696590830591943

Epoch: 6| Step: 5
Training loss: 2.508997556962686
Validation loss: 2.6992606953759792

Epoch: 6| Step: 6
Training loss: 2.202140534042081
Validation loss: 2.698045088425679

Epoch: 6| Step: 7
Training loss: 2.4128067058824194
Validation loss: 2.695632757177711

Epoch: 6| Step: 8
Training loss: 3.2766071714922456
Validation loss: 2.6961738027052666

Epoch: 6| Step: 9
Training loss: 3.0580390047089474
Validation loss: 2.699210891580413

Epoch: 6| Step: 10
Training loss: 3.141793104978389
Validation loss: 2.6971023406903

Epoch: 6| Step: 11
Training loss: 3.2302505806960107
Validation loss: 2.694783164690981

Epoch: 6| Step: 12
Training loss: 2.9535814366489848
Validation loss: 2.695098665876312

Epoch: 6| Step: 13
Training loss: 3.639056215653454
Validation loss: 2.694948137244595

Epoch: 55| Step: 0
Training loss: 3.553690810433523
Validation loss: 2.703590075651353

Epoch: 6| Step: 1
Training loss: 3.201360449086542
Validation loss: 2.7170039458721233

Epoch: 6| Step: 2
Training loss: 2.612227656574547
Validation loss: 2.703219549917948

Epoch: 6| Step: 3
Training loss: 3.4647236043060983
Validation loss: 2.698803401077985

Epoch: 6| Step: 4
Training loss: 3.0922898979638562
Validation loss: 2.692203393379944

Epoch: 6| Step: 5
Training loss: 2.9553028936432675
Validation loss: 2.6905790997196735

Epoch: 6| Step: 6
Training loss: 2.920473139851778
Validation loss: 2.6901189125482095

Epoch: 6| Step: 7
Training loss: 2.3749056345613586
Validation loss: 2.698362299327195

Epoch: 6| Step: 8
Training loss: 3.0905621991850043
Validation loss: 2.6910902187496486

Epoch: 6| Step: 9
Training loss: 3.147039287563125
Validation loss: 2.6899204005351858

Epoch: 6| Step: 10
Training loss: 3.0098019052505927
Validation loss: 2.6885229330754727

Epoch: 6| Step: 11
Training loss: 3.3673860354209246
Validation loss: 2.6936062560724925

Epoch: 6| Step: 12
Training loss: 2.3147928366853954
Validation loss: 2.689321405828288

Epoch: 6| Step: 13
Training loss: 3.1120940161970387
Validation loss: 2.6975851399668294

Epoch: 56| Step: 0
Training loss: 2.9722807116908316
Validation loss: 2.6966024072036614

Epoch: 6| Step: 1
Training loss: 2.969291236127957
Validation loss: 2.6943538102772244

Epoch: 6| Step: 2
Training loss: 2.782607015383773
Validation loss: 2.696294733085133

Epoch: 6| Step: 3
Training loss: 3.454350594906623
Validation loss: 2.6942282501759496

Epoch: 6| Step: 4
Training loss: 2.604111897210517
Validation loss: 2.694165846173142

Epoch: 6| Step: 5
Training loss: 2.0772981074133265
Validation loss: 2.694273000288637

Epoch: 6| Step: 6
Training loss: 3.2443261136579187
Validation loss: 2.6949433480391667

Epoch: 6| Step: 7
Training loss: 2.4439281896227465
Validation loss: 2.7109025035231817

Epoch: 6| Step: 8
Training loss: 2.8030601604536707
Validation loss: 2.729784209844509

Epoch: 6| Step: 9
Training loss: 3.622394809498792
Validation loss: 2.7527406889371875

Epoch: 6| Step: 10
Training loss: 3.529988696590838
Validation loss: 2.7798429697520315

Epoch: 6| Step: 11
Training loss: 2.8174058301702725
Validation loss: 2.7974482407342083

Epoch: 6| Step: 12
Training loss: 3.4322405721115516
Validation loss: 2.7619561764009983

Epoch: 6| Step: 13
Training loss: 3.617648859447759
Validation loss: 2.723277336471004

Epoch: 57| Step: 0
Training loss: 3.327625935705658
Validation loss: 2.6931145541063293

Epoch: 6| Step: 1
Training loss: 3.248298786645745
Validation loss: 2.683495613922858

Epoch: 6| Step: 2
Training loss: 3.081447918398705
Validation loss: 2.6861386066841093

Epoch: 6| Step: 3
Training loss: 2.9878041004884355
Validation loss: 2.6813110773337514

Epoch: 6| Step: 4
Training loss: 3.0807942082344955
Validation loss: 2.685363290248752

Epoch: 6| Step: 5
Training loss: 3.225590815873922
Validation loss: 2.6960227873364273

Epoch: 6| Step: 6
Training loss: 3.2712036376746316
Validation loss: 2.692906370731344

Epoch: 6| Step: 7
Training loss: 3.101519144749718
Validation loss: 2.702038827159679

Epoch: 6| Step: 8
Training loss: 2.638750844546011
Validation loss: 2.7178722223899623

Epoch: 6| Step: 9
Training loss: 2.828187383311451
Validation loss: 2.7198693867418293

Epoch: 6| Step: 10
Training loss: 2.932958460464544
Validation loss: 2.6995010794624035

Epoch: 6| Step: 11
Training loss: 2.299530362818975
Validation loss: 2.6938571238730056

Epoch: 6| Step: 12
Training loss: 3.505442066911484
Validation loss: 2.680628088371588

Epoch: 6| Step: 13
Training loss: 2.177786924814404
Validation loss: 2.677728727340472

Epoch: 58| Step: 0
Training loss: 3.113830441385689
Validation loss: 2.6738704169083958

Epoch: 6| Step: 1
Training loss: 3.8850940778380574
Validation loss: 2.6763459790163773

Epoch: 6| Step: 2
Training loss: 3.166922475286937
Validation loss: 2.6741290129200093

Epoch: 6| Step: 3
Training loss: 2.817179537998316
Validation loss: 2.6737988836516506

Epoch: 6| Step: 4
Training loss: 3.3263046229198565
Validation loss: 2.6711066680757933

Epoch: 6| Step: 5
Training loss: 3.2587398974602615
Validation loss: 2.6699112197156016

Epoch: 6| Step: 6
Training loss: 2.503240964110698
Validation loss: 2.669114292855944

Epoch: 6| Step: 7
Training loss: 2.079329521615189
Validation loss: 2.6694635316377227

Epoch: 6| Step: 8
Training loss: 2.9869179002930126
Validation loss: 2.6734696456871316

Epoch: 6| Step: 9
Training loss: 2.6730434249906954
Validation loss: 2.67749075751753

Epoch: 6| Step: 10
Training loss: 3.300435101117647
Validation loss: 2.671317732704847

Epoch: 6| Step: 11
Training loss: 3.2381491639885502
Validation loss: 2.6635226715975073

Epoch: 6| Step: 12
Training loss: 2.3414961086438804
Validation loss: 2.6718631732849

Epoch: 6| Step: 13
Training loss: 3.0469164723239213
Validation loss: 2.6736353436601386

Epoch: 59| Step: 0
Training loss: 2.7394566863246403
Validation loss: 2.677443743938257

Epoch: 6| Step: 1
Training loss: 3.595772348345753
Validation loss: 2.6751838435750193

Epoch: 6| Step: 2
Training loss: 3.3726233131933534
Validation loss: 2.6677743699831926

Epoch: 6| Step: 3
Training loss: 3.2367926513426286
Validation loss: 2.678472745789595

Epoch: 6| Step: 4
Training loss: 3.0067856658370586
Validation loss: 2.6841108850199693

Epoch: 6| Step: 5
Training loss: 2.3695229067028247
Validation loss: 2.683008043389412

Epoch: 6| Step: 6
Training loss: 2.240003845007185
Validation loss: 2.6973799903674487

Epoch: 6| Step: 7
Training loss: 2.4829665696178522
Validation loss: 2.7094336824671013

Epoch: 6| Step: 8
Training loss: 3.3089700279965064
Validation loss: 2.6964359709244787

Epoch: 6| Step: 9
Training loss: 3.2402938276266657
Validation loss: 2.6971122564615873

Epoch: 6| Step: 10
Training loss: 3.310800224219943
Validation loss: 2.673447649914373

Epoch: 6| Step: 11
Training loss: 2.720910627855202
Validation loss: 2.665413331404678

Epoch: 6| Step: 12
Training loss: 2.5949307247609896
Validation loss: 2.6605350702357797

Epoch: 6| Step: 13
Training loss: 3.7860933921164865
Validation loss: 2.661253071378524

Epoch: 60| Step: 0
Training loss: 2.7096635535027502
Validation loss: 2.6617506456002267

Epoch: 6| Step: 1
Training loss: 2.879227060070105
Validation loss: 2.6655913294686133

Epoch: 6| Step: 2
Training loss: 3.396781289809272
Validation loss: 2.6604183221460254

Epoch: 6| Step: 3
Training loss: 2.494398517464325
Validation loss: 2.6643620448536622

Epoch: 6| Step: 4
Training loss: 3.499523130355417
Validation loss: 2.6653423141978405

Epoch: 6| Step: 5
Training loss: 3.1821980980302627
Validation loss: 2.659781853878698

Epoch: 6| Step: 6
Training loss: 2.794289016782975
Validation loss: 2.6639344834160865

Epoch: 6| Step: 7
Training loss: 2.8837769918579923
Validation loss: 2.6606151079113265

Epoch: 6| Step: 8
Training loss: 3.619331268378349
Validation loss: 2.6581866834119565

Epoch: 6| Step: 9
Training loss: 2.60140358379355
Validation loss: 2.669137714146964

Epoch: 6| Step: 10
Training loss: 2.542366390112225
Validation loss: 2.6649921370884377

Epoch: 6| Step: 11
Training loss: 2.8471917086157634
Validation loss: 2.667575547344401

Epoch: 6| Step: 12
Training loss: 3.2834970681921085
Validation loss: 2.654833070807105

Epoch: 6| Step: 13
Training loss: 3.0679047828729793
Validation loss: 2.659845033739695

Epoch: 61| Step: 0
Training loss: 2.711738402158874
Validation loss: 2.6583926260571356

Epoch: 6| Step: 1
Training loss: 2.767649626094283
Validation loss: 2.6571411162971907

Epoch: 6| Step: 2
Training loss: 2.19272229936974
Validation loss: 2.6530515829450305

Epoch: 6| Step: 3
Training loss: 3.29643673266245
Validation loss: 2.653131359376853

Epoch: 6| Step: 4
Training loss: 3.194085890692989
Validation loss: 2.651295335242834

Epoch: 6| Step: 5
Training loss: 2.7745049799759114
Validation loss: 2.6540225095141703

Epoch: 6| Step: 6
Training loss: 2.924616705405198
Validation loss: 2.658469144787888

Epoch: 6| Step: 7
Training loss: 2.771594313523775
Validation loss: 2.675326930896924

Epoch: 6| Step: 8
Training loss: 4.022859342941389
Validation loss: 2.7009345573590964

Epoch: 6| Step: 9
Training loss: 3.1741231834001713
Validation loss: 2.6701177952193165

Epoch: 6| Step: 10
Training loss: 2.9342802542278683
Validation loss: 2.6564710145095334

Epoch: 6| Step: 11
Training loss: 3.0389762022813254
Validation loss: 2.6517217345533943

Epoch: 6| Step: 12
Training loss: 2.899893916590403
Validation loss: 2.651146250343163

Epoch: 6| Step: 13
Training loss: 3.059261400180807
Validation loss: 2.6557681511036884

Epoch: 62| Step: 0
Training loss: 2.208334316997189
Validation loss: 2.6556846436833936

Epoch: 6| Step: 1
Training loss: 3.0827205839534773
Validation loss: 2.6555026678191016

Epoch: 6| Step: 2
Training loss: 3.026291714884588
Validation loss: 2.659382263122005

Epoch: 6| Step: 3
Training loss: 3.3315947449099395
Validation loss: 2.6575294921295507

Epoch: 6| Step: 4
Training loss: 2.390808696794959
Validation loss: 2.654814921345666

Epoch: 6| Step: 5
Training loss: 3.2692977475516045
Validation loss: 2.653514144656796

Epoch: 6| Step: 6
Training loss: 3.0806456183968094
Validation loss: 2.6498198167990825

Epoch: 6| Step: 7
Training loss: 3.0794941137436895
Validation loss: 2.6463924557128515

Epoch: 6| Step: 8
Training loss: 2.87573829790832
Validation loss: 2.647954937185594

Epoch: 6| Step: 9
Training loss: 3.3845975540265
Validation loss: 2.6581342660090703

Epoch: 6| Step: 10
Training loss: 3.4409450953791842
Validation loss: 2.6785274106269967

Epoch: 6| Step: 11
Training loss: 2.509531068045988
Validation loss: 2.7178473090823227

Epoch: 6| Step: 12
Training loss: 3.1953654762857058
Validation loss: 2.7628696463650875

Epoch: 6| Step: 13
Training loss: 2.58078762466836
Validation loss: 2.7890037989342575

Epoch: 63| Step: 0
Training loss: 3.342273849791413
Validation loss: 2.7450563905131653

Epoch: 6| Step: 1
Training loss: 3.3256878593080303
Validation loss: 2.7218005631117803

Epoch: 6| Step: 2
Training loss: 2.6072614870497794
Validation loss: 2.6727628529848624

Epoch: 6| Step: 3
Training loss: 3.0871649123994165
Validation loss: 2.6417520400260432

Epoch: 6| Step: 4
Training loss: 3.331601042439122
Validation loss: 2.6562758066273737

Epoch: 6| Step: 5
Training loss: 3.029274208087344
Validation loss: 2.681361454538133

Epoch: 6| Step: 6
Training loss: 2.7655327560645024
Validation loss: 2.7107619475531357

Epoch: 6| Step: 7
Training loss: 2.758628227474339
Validation loss: 2.713255060402344

Epoch: 6| Step: 8
Training loss: 3.5749064133138697
Validation loss: 2.6795365505012008

Epoch: 6| Step: 9
Training loss: 3.506493947183674
Validation loss: 2.651168047249314

Epoch: 6| Step: 10
Training loss: 2.6821901073796472
Validation loss: 2.6479354025752513

Epoch: 6| Step: 11
Training loss: 1.746607148136777
Validation loss: 2.689357630673507

Epoch: 6| Step: 12
Training loss: 3.163478467751942
Validation loss: 2.9352094210841395

Epoch: 6| Step: 13
Training loss: 3.947648427635791
Validation loss: 3.2186312049729633

Epoch: 64| Step: 0
Training loss: 3.161301149653615
Validation loss: 2.8888929663893093

Epoch: 6| Step: 1
Training loss: 2.2252823211204924
Validation loss: 2.652124065760483

Epoch: 6| Step: 2
Training loss: 2.731788152755562
Validation loss: 2.6612796569752195

Epoch: 6| Step: 3
Training loss: 3.318126290831797
Validation loss: 2.7458978095061126

Epoch: 6| Step: 4
Training loss: 2.7493758793834018
Validation loss: 2.8962978847080745

Epoch: 6| Step: 5
Training loss: 3.6843188513698935
Validation loss: 3.117822322208382

Epoch: 6| Step: 6
Training loss: 3.2361168340615096
Validation loss: 3.1638198182177404

Epoch: 6| Step: 7
Training loss: 4.164974377611717
Validation loss: 3.0709688445905154

Epoch: 6| Step: 8
Training loss: 2.795796618004973
Validation loss: 2.8589795854183797

Epoch: 6| Step: 9
Training loss: 3.7827722937280126
Validation loss: 2.747437608023461

Epoch: 6| Step: 10
Training loss: 3.0922283707703526
Validation loss: 2.6680548890968083

Epoch: 6| Step: 11
Training loss: 2.9629434116919398
Validation loss: 2.6446035254714997

Epoch: 6| Step: 12
Training loss: 3.1616865114491803
Validation loss: 2.6501541578110026

Epoch: 6| Step: 13
Training loss: 3.0476223542558807
Validation loss: 2.6983230401331983

Epoch: 65| Step: 0
Training loss: 2.9349651356694535
Validation loss: 2.7385742747862856

Epoch: 6| Step: 1
Training loss: 2.6465629312602967
Validation loss: 2.726533483841016

Epoch: 6| Step: 2
Training loss: 3.563288551194285
Validation loss: 2.753157165346151

Epoch: 6| Step: 3
Training loss: 3.056683368810562
Validation loss: 2.718266380105045

Epoch: 6| Step: 4
Training loss: 3.0699790404657366
Validation loss: 2.676064358434863

Epoch: 6| Step: 5
Training loss: 2.5969520015753713
Validation loss: 2.6626252061697757

Epoch: 6| Step: 6
Training loss: 2.993551954117709
Validation loss: 2.651227134230073

Epoch: 6| Step: 7
Training loss: 2.3889158035457556
Validation loss: 2.6519865387817276

Epoch: 6| Step: 8
Training loss: 2.8834067458433776
Validation loss: 2.6763475020584213

Epoch: 6| Step: 9
Training loss: 3.289512041771762
Validation loss: 2.709716465151569

Epoch: 6| Step: 10
Training loss: 3.104162092440177
Validation loss: 2.717111569313189

Epoch: 6| Step: 11
Training loss: 3.533344694035338
Validation loss: 2.7440140217173146

Epoch: 6| Step: 12
Training loss: 3.5309723601446485
Validation loss: 2.7160888866631216

Epoch: 6| Step: 13
Training loss: 2.6920779958141767
Validation loss: 2.6664794989499776

Epoch: 66| Step: 0
Training loss: 3.082809988060463
Validation loss: 2.6497674999453054

Epoch: 6| Step: 1
Training loss: 3.1646718886547776
Validation loss: 2.6407041480177025

Epoch: 6| Step: 2
Training loss: 3.1572744387705463
Validation loss: 2.634077197132933

Epoch: 6| Step: 3
Training loss: 2.617355933391897
Validation loss: 2.634554001493827

Epoch: 6| Step: 4
Training loss: 2.6644606306761403
Validation loss: 2.6343466321898736

Epoch: 6| Step: 5
Training loss: 3.0760196514915674
Validation loss: 2.638936867643873

Epoch: 6| Step: 6
Training loss: 2.7610591116839367
Validation loss: 2.651738063475261

Epoch: 6| Step: 7
Training loss: 3.149145307089073
Validation loss: 2.649650418678892

Epoch: 6| Step: 8
Training loss: 3.296481863871392
Validation loss: 2.648626239176453

Epoch: 6| Step: 9
Training loss: 3.3379200531726445
Validation loss: 2.655006494990186

Epoch: 6| Step: 10
Training loss: 2.916505827329122
Validation loss: 2.6569008538330263

Epoch: 6| Step: 11
Training loss: 3.186657064841049
Validation loss: 2.6612037787561986

Epoch: 6| Step: 12
Training loss: 2.6368399133040965
Validation loss: 2.6575603884207215

Epoch: 6| Step: 13
Training loss: 2.368552843409132
Validation loss: 2.636992676914304

Epoch: 67| Step: 0
Training loss: 3.254828167905011
Validation loss: 2.6287869025893436

Epoch: 6| Step: 1
Training loss: 3.105752492933602
Validation loss: 2.6240581125455638

Epoch: 6| Step: 2
Training loss: 2.2314151820312618
Validation loss: 2.6220635388733817

Epoch: 6| Step: 3
Training loss: 3.0412846852310773
Validation loss: 2.62065140414085

Epoch: 6| Step: 4
Training loss: 2.367488225083843
Validation loss: 2.62031100050736

Epoch: 6| Step: 5
Training loss: 2.926186384563046
Validation loss: 2.620520269975578

Epoch: 6| Step: 6
Training loss: 2.9067060871542565
Validation loss: 2.6198564277302907

Epoch: 6| Step: 7
Training loss: 3.215372331811315
Validation loss: 2.622825502226626

Epoch: 6| Step: 8
Training loss: 2.308838807087987
Validation loss: 2.62126668261734

Epoch: 6| Step: 9
Training loss: 3.231839425432109
Validation loss: 2.6174895042369393

Epoch: 6| Step: 10
Training loss: 3.6428339073230847
Validation loss: 2.6164126707972004

Epoch: 6| Step: 11
Training loss: 2.6478613842931633
Validation loss: 2.618479359387038

Epoch: 6| Step: 12
Training loss: 3.0965626579313117
Validation loss: 2.6199043846765724

Epoch: 6| Step: 13
Training loss: 3.648541532744572
Validation loss: 2.621404309321493

Epoch: 68| Step: 0
Training loss: 3.527540706234737
Validation loss: 2.6460838041056225

Epoch: 6| Step: 1
Training loss: 3.209887404799311
Validation loss: 2.650773885360608

Epoch: 6| Step: 2
Training loss: 3.0622125607494843
Validation loss: 2.6581172790767815

Epoch: 6| Step: 3
Training loss: 3.056653885005184
Validation loss: 2.6351934712417466

Epoch: 6| Step: 4
Training loss: 2.7324600053462174
Validation loss: 2.616075371840237

Epoch: 6| Step: 5
Training loss: 2.959139557347852
Validation loss: 2.612853210534659

Epoch: 6| Step: 6
Training loss: 3.1516357534403117
Validation loss: 2.612146338454528

Epoch: 6| Step: 7
Training loss: 2.875621065146613
Validation loss: 2.6196510334114635

Epoch: 6| Step: 8
Training loss: 2.446517890994176
Validation loss: 2.6182368083122753

Epoch: 6| Step: 9
Training loss: 2.956647759871329
Validation loss: 2.621608724315299

Epoch: 6| Step: 10
Training loss: 3.2999165322122725
Validation loss: 2.6220017580543784

Epoch: 6| Step: 11
Training loss: 3.0881537482771235
Validation loss: 2.6215319667790755

Epoch: 6| Step: 12
Training loss: 2.466972870336205
Validation loss: 2.6264794492872032

Epoch: 6| Step: 13
Training loss: 2.3845887614531733
Validation loss: 2.6298121162529036

Epoch: 69| Step: 0
Training loss: 3.0562393656352564
Validation loss: 2.6425067186892535

Epoch: 6| Step: 1
Training loss: 2.769362774070591
Validation loss: 2.6454664258066125

Epoch: 6| Step: 2
Training loss: 2.433171267751798
Validation loss: 2.6393185916761612

Epoch: 6| Step: 3
Training loss: 3.3663504637732373
Validation loss: 2.6311829932922266

Epoch: 6| Step: 4
Training loss: 2.6136184269587406
Validation loss: 2.6351534207631557

Epoch: 6| Step: 5
Training loss: 3.025844197661292
Validation loss: 2.6404317557098156

Epoch: 6| Step: 6
Training loss: 2.7429103496335254
Validation loss: 2.6289053625916443

Epoch: 6| Step: 7
Training loss: 3.1220145651595477
Validation loss: 2.6212091198783103

Epoch: 6| Step: 8
Training loss: 2.894031393981514
Validation loss: 2.6166938229195367

Epoch: 6| Step: 9
Training loss: 3.0434997643724016
Validation loss: 2.6142206166348463

Epoch: 6| Step: 10
Training loss: 3.0440613886975374
Validation loss: 2.614428994915372

Epoch: 6| Step: 11
Training loss: 3.270286336138919
Validation loss: 2.609295695534595

Epoch: 6| Step: 12
Training loss: 2.907600663230989
Validation loss: 2.611623232579312

Epoch: 6| Step: 13
Training loss: 3.3914523895084736
Validation loss: 2.6144077153962306

Epoch: 70| Step: 0
Training loss: 3.1116082687360254
Validation loss: 2.6136199610513744

Epoch: 6| Step: 1
Training loss: 3.6069232490735135
Validation loss: 2.6109796985670797

Epoch: 6| Step: 2
Training loss: 3.307981179918401
Validation loss: 2.602742623758884

Epoch: 6| Step: 3
Training loss: 2.5991591157484515
Validation loss: 2.604966811443695

Epoch: 6| Step: 4
Training loss: 3.52306247246277
Validation loss: 2.605702702183651

Epoch: 6| Step: 5
Training loss: 2.9238538925676516
Validation loss: 2.6065583063701987

Epoch: 6| Step: 6
Training loss: 3.1717445083610314
Validation loss: 2.6033173148553783

Epoch: 6| Step: 7
Training loss: 3.288144669944344
Validation loss: 2.605527969102834

Epoch: 6| Step: 8
Training loss: 2.1565611241657825
Validation loss: 2.616115933894254

Epoch: 6| Step: 9
Training loss: 3.0518179681571116
Validation loss: 2.6435043268522977

Epoch: 6| Step: 10
Training loss: 3.24591453231952
Validation loss: 2.668779940042286

Epoch: 6| Step: 11
Training loss: 1.9818354899769748
Validation loss: 2.678789016687321

Epoch: 6| Step: 12
Training loss: 2.181652536931726
Validation loss: 2.6670393113006536

Epoch: 6| Step: 13
Training loss: 2.6397010044363483
Validation loss: 2.669768401000995

Epoch: 71| Step: 0
Training loss: 2.5350898534135573
Validation loss: 2.674654798570778

Epoch: 6| Step: 1
Training loss: 3.301149896203902
Validation loss: 2.6757785673452137

Epoch: 6| Step: 2
Training loss: 3.026292030014244
Validation loss: 2.6511374555246

Epoch: 6| Step: 3
Training loss: 2.807601647375471
Validation loss: 2.6300871124323346

Epoch: 6| Step: 4
Training loss: 3.2790633408692513
Validation loss: 2.610242448298047

Epoch: 6| Step: 5
Training loss: 2.998981302872772
Validation loss: 2.6049635608417048

Epoch: 6| Step: 6
Training loss: 3.2803645801289303
Validation loss: 2.608651579475216

Epoch: 6| Step: 7
Training loss: 3.2117431817857214
Validation loss: 2.6081447018350974

Epoch: 6| Step: 8
Training loss: 2.9013081855642415
Validation loss: 2.606217558159097

Epoch: 6| Step: 9
Training loss: 2.9919672553774674
Validation loss: 2.6084542013302046

Epoch: 6| Step: 10
Training loss: 3.038357925134165
Validation loss: 2.612411205323195

Epoch: 6| Step: 11
Training loss: 2.58392772194367
Validation loss: 2.617961804145625

Epoch: 6| Step: 12
Training loss: 2.4247765664272505
Validation loss: 2.6150268020406133

Epoch: 6| Step: 13
Training loss: 2.921264584675897
Validation loss: 2.6217673193184607

Epoch: 72| Step: 0
Training loss: 3.3049008997200224
Validation loss: 2.6221481835062717

Epoch: 6| Step: 1
Training loss: 2.8756099551461674
Validation loss: 2.613073270734419

Epoch: 6| Step: 2
Training loss: 2.8094017765861037
Validation loss: 2.61872900213513

Epoch: 6| Step: 3
Training loss: 2.1726213448967084
Validation loss: 2.62876272194471

Epoch: 6| Step: 4
Training loss: 3.4058081664059445
Validation loss: 2.6288997124263647

Epoch: 6| Step: 5
Training loss: 3.428778664819912
Validation loss: 2.6280571538264543

Epoch: 6| Step: 6
Training loss: 2.787488648258924
Validation loss: 2.6111194275844523

Epoch: 6| Step: 7
Training loss: 2.1833319054907094
Validation loss: 2.605927102588798

Epoch: 6| Step: 8
Training loss: 2.9941743872444153
Validation loss: 2.6076272651684165

Epoch: 6| Step: 9
Training loss: 2.2180856059196605
Validation loss: 2.610865012739974

Epoch: 6| Step: 10
Training loss: 2.9352377438800668
Validation loss: 2.611834324960124

Epoch: 6| Step: 11
Training loss: 3.881527601748096
Validation loss: 2.6129695986639505

Epoch: 6| Step: 12
Training loss: 2.7221943752222577
Validation loss: 2.613416579008165

Epoch: 6| Step: 13
Training loss: 3.3902489238259377
Validation loss: 2.609445454156784

Epoch: 73| Step: 0
Training loss: 3.0937544697430623
Validation loss: 2.6102617297280544

Epoch: 6| Step: 1
Training loss: 2.895908784683831
Validation loss: 2.6028554582648504

Epoch: 6| Step: 2
Training loss: 2.6847529010979043
Validation loss: 2.5999669915763066

Epoch: 6| Step: 3
Training loss: 3.224066926095876
Validation loss: 2.601840955904227

Epoch: 6| Step: 4
Training loss: 2.50584015575005
Validation loss: 2.599019668949926

Epoch: 6| Step: 5
Training loss: 2.914315956690757
Validation loss: 2.6023856141971415

Epoch: 6| Step: 6
Training loss: 2.836728660841438
Validation loss: 2.6013071396217136

Epoch: 6| Step: 7
Training loss: 3.311731933221947
Validation loss: 2.602574240498651

Epoch: 6| Step: 8
Training loss: 3.280122690464787
Validation loss: 2.6188404400969407

Epoch: 6| Step: 9
Training loss: 3.1125294389060225
Validation loss: 2.6517610233741715

Epoch: 6| Step: 10
Training loss: 3.345016239736962
Validation loss: 2.658662663277129

Epoch: 6| Step: 11
Training loss: 3.274874351362494
Validation loss: 2.639401592180812

Epoch: 6| Step: 12
Training loss: 2.261699353597744
Validation loss: 2.61549965545665

Epoch: 6| Step: 13
Training loss: 2.0911214469985744
Validation loss: 2.600227198285707

Epoch: 74| Step: 0
Training loss: 2.948171831462194
Validation loss: 2.603311361979303

Epoch: 6| Step: 1
Training loss: 2.4382454148054546
Validation loss: 2.599618698175759

Epoch: 6| Step: 2
Training loss: 2.5589017959241973
Validation loss: 2.599319961236143

Epoch: 6| Step: 3
Training loss: 2.5069001341543884
Validation loss: 2.600415675536209

Epoch: 6| Step: 4
Training loss: 2.6526350667579206
Validation loss: 2.602346260655568

Epoch: 6| Step: 5
Training loss: 3.6641016716073107
Validation loss: 2.6045032629884335

Epoch: 6| Step: 6
Training loss: 3.0284058116860604
Validation loss: 2.599411388176517

Epoch: 6| Step: 7
Training loss: 3.139810333112094
Validation loss: 2.604513174979116

Epoch: 6| Step: 8
Training loss: 3.1607784606477756
Validation loss: 2.5984686203674445

Epoch: 6| Step: 9
Training loss: 3.1923058874851673
Validation loss: 2.5993436869253976

Epoch: 6| Step: 10
Training loss: 3.140417291405739
Validation loss: 2.59679003896473

Epoch: 6| Step: 11
Training loss: 2.7865994046351266
Validation loss: 2.6024306619822695

Epoch: 6| Step: 12
Training loss: 2.6617550519657214
Validation loss: 2.6058773841963427

Epoch: 6| Step: 13
Training loss: 3.519772401734204
Validation loss: 2.6106520567207845

Epoch: 75| Step: 0
Training loss: 3.1849101896214576
Validation loss: 2.614130708914868

Epoch: 6| Step: 1
Training loss: 2.9074624106551332
Validation loss: 2.6254468948596252

Epoch: 6| Step: 2
Training loss: 2.457761040577494
Validation loss: 2.6220091370611205

Epoch: 6| Step: 3
Training loss: 2.6436010440500546
Validation loss: 2.6266347557795866

Epoch: 6| Step: 4
Training loss: 2.636509684998672
Validation loss: 2.6398093147031085

Epoch: 6| Step: 5
Training loss: 2.5738664076252595
Validation loss: 2.640214624449935

Epoch: 6| Step: 6
Training loss: 3.668985471690981
Validation loss: 2.6516108315401383

Epoch: 6| Step: 7
Training loss: 2.9968903637632445
Validation loss: 2.6608173825184522

Epoch: 6| Step: 8
Training loss: 2.9284386986882787
Validation loss: 2.6607410613926765

Epoch: 6| Step: 9
Training loss: 3.4290896092251226
Validation loss: 2.6550061106864002

Epoch: 6| Step: 10
Training loss: 2.6955934239923316
Validation loss: 2.6229856021201914

Epoch: 6| Step: 11
Training loss: 2.622900168377349
Validation loss: 2.608729875600761

Epoch: 6| Step: 12
Training loss: 3.1006872830385954
Validation loss: 2.596391825179098

Epoch: 6| Step: 13
Training loss: 3.339798348101491
Validation loss: 2.596189457492801

Epoch: 76| Step: 0
Training loss: 2.8741380809299946
Validation loss: 2.5911116640399374

Epoch: 6| Step: 1
Training loss: 2.184325830782114
Validation loss: 2.5892398067987243

Epoch: 6| Step: 2
Training loss: 2.7440162060317435
Validation loss: 2.5894053553722665

Epoch: 6| Step: 3
Training loss: 2.9563700290693142
Validation loss: 2.5900815226855882

Epoch: 6| Step: 4
Training loss: 3.051602339789698
Validation loss: 2.5901324608136598

Epoch: 6| Step: 5
Training loss: 3.438749329079133
Validation loss: 2.593353559449572

Epoch: 6| Step: 6
Training loss: 3.009796835547538
Validation loss: 2.591792295294413

Epoch: 6| Step: 7
Training loss: 3.72912611841644
Validation loss: 2.6001475950933015

Epoch: 6| Step: 8
Training loss: 3.1669244326702293
Validation loss: 2.602450238695482

Epoch: 6| Step: 9
Training loss: 2.1750120929951846
Validation loss: 2.603195423433765

Epoch: 6| Step: 10
Training loss: 2.7461611222620985
Validation loss: 2.60605630419219

Epoch: 6| Step: 11
Training loss: 3.0686140725667963
Validation loss: 2.604636052970485

Epoch: 6| Step: 12
Training loss: 3.0898158172232195
Validation loss: 2.6033477269956293

Epoch: 6| Step: 13
Training loss: 2.6147517014558215
Validation loss: 2.6016267202375443

Epoch: 77| Step: 0
Training loss: 2.6957191934453535
Validation loss: 2.597736801932783

Epoch: 6| Step: 1
Training loss: 3.157985399015567
Validation loss: 2.5979279910078583

Epoch: 6| Step: 2
Training loss: 2.645016421463582
Validation loss: 2.5940678571366567

Epoch: 6| Step: 3
Training loss: 2.843372026413501
Validation loss: 2.593729273345957

Epoch: 6| Step: 4
Training loss: 3.1803571666014685
Validation loss: 2.585462171033757

Epoch: 6| Step: 5
Training loss: 2.626941507873941
Validation loss: 2.583340582968086

Epoch: 6| Step: 6
Training loss: 2.5333499439431106
Validation loss: 2.582856546783272

Epoch: 6| Step: 7
Training loss: 3.282093048785148
Validation loss: 2.5876221455425137

Epoch: 6| Step: 8
Training loss: 2.8170855122331027
Validation loss: 2.5892540713209984

Epoch: 6| Step: 9
Training loss: 3.1272533684810813
Validation loss: 2.603173254387385

Epoch: 6| Step: 10
Training loss: 3.1687564646638013
Validation loss: 2.606436989454974

Epoch: 6| Step: 11
Training loss: 2.914059881868797
Validation loss: 2.6015929395515953

Epoch: 6| Step: 12
Training loss: 2.860243368398019
Validation loss: 2.5990909591321434

Epoch: 6| Step: 13
Training loss: 3.496885139784715
Validation loss: 2.6060611864107877

Epoch: 78| Step: 0
Training loss: 2.0463232796515194
Validation loss: 2.5894572136692178

Epoch: 6| Step: 1
Training loss: 2.328367182276917
Validation loss: 2.5914210748361435

Epoch: 6| Step: 2
Training loss: 3.1427045172007633
Validation loss: 2.593518549880094

Epoch: 6| Step: 3
Training loss: 3.4172778319536325
Validation loss: 2.595919824660224

Epoch: 6| Step: 4
Training loss: 2.678826641458494
Validation loss: 2.594774168798477

Epoch: 6| Step: 5
Training loss: 3.042594524284987
Validation loss: 2.590878656276318

Epoch: 6| Step: 6
Training loss: 3.1170773594263648
Validation loss: 2.600081296348684

Epoch: 6| Step: 7
Training loss: 2.6372414303990324
Validation loss: 2.607279663705948

Epoch: 6| Step: 8
Training loss: 3.5054698164487457
Validation loss: 2.6077376291807424

Epoch: 6| Step: 9
Training loss: 2.8697694384111543
Validation loss: 2.605051297132739

Epoch: 6| Step: 10
Training loss: 3.1821945017430706
Validation loss: 2.601913951176384

Epoch: 6| Step: 11
Training loss: 2.9134365360594345
Validation loss: 2.5872259649907168

Epoch: 6| Step: 12
Training loss: 2.917904037309532
Validation loss: 2.580814611027233

Epoch: 6| Step: 13
Training loss: 3.3162101265256827
Validation loss: 2.5851357080778694

Epoch: 79| Step: 0
Training loss: 3.106584840223559
Validation loss: 2.5849032525827793

Epoch: 6| Step: 1
Training loss: 2.2264202942526725
Validation loss: 2.5836704866412914

Epoch: 6| Step: 2
Training loss: 2.310493010717774
Validation loss: 2.591364519068904

Epoch: 6| Step: 3
Training loss: 2.7734166104241904
Validation loss: 2.582808916357317

Epoch: 6| Step: 4
Training loss: 3.2191709965311297
Validation loss: 2.5848760579881933

Epoch: 6| Step: 5
Training loss: 3.0748015921247043
Validation loss: 2.5828675145503017

Epoch: 6| Step: 6
Training loss: 3.126395562408328
Validation loss: 2.581128953954242

Epoch: 6| Step: 7
Training loss: 3.060831354938397
Validation loss: 2.5917635369322967

Epoch: 6| Step: 8
Training loss: 2.999872840729566
Validation loss: 2.627446943928998

Epoch: 6| Step: 9
Training loss: 2.569432534084266
Validation loss: 2.6729643262897698

Epoch: 6| Step: 10
Training loss: 2.8565246049357804
Validation loss: 2.703654750242134

Epoch: 6| Step: 11
Training loss: 3.335326520728957
Validation loss: 2.751629109142498

Epoch: 6| Step: 12
Training loss: 2.9660211167924597
Validation loss: 2.739116278127819

Epoch: 6| Step: 13
Training loss: 4.205564110256034
Validation loss: 2.654611095193337

Epoch: 80| Step: 0
Training loss: 3.810638848958902
Validation loss: 2.5852764749409234

Epoch: 6| Step: 1
Training loss: 2.8123933559968064
Validation loss: 2.573918899709022

Epoch: 6| Step: 2
Training loss: 2.456823779930568
Validation loss: 2.5909606310053492

Epoch: 6| Step: 3
Training loss: 1.9558751999489303
Validation loss: 2.608754217854316

Epoch: 6| Step: 4
Training loss: 3.063498198092631
Validation loss: 2.6452245049747765

Epoch: 6| Step: 5
Training loss: 3.2349322295128555
Validation loss: 2.6885787237446905

Epoch: 6| Step: 6
Training loss: 3.644636964235837
Validation loss: 2.743108116599267

Epoch: 6| Step: 7
Training loss: 2.4621866598078213
Validation loss: 2.757500334610725

Epoch: 6| Step: 8
Training loss: 3.6635413866835678
Validation loss: 2.7688662612058517

Epoch: 6| Step: 9
Training loss: 3.20666249021812
Validation loss: 2.707368660605686

Epoch: 6| Step: 10
Training loss: 2.954273141969659
Validation loss: 2.6473372544342215

Epoch: 6| Step: 11
Training loss: 3.1633501922940677
Validation loss: 2.615361502385931

Epoch: 6| Step: 12
Training loss: 2.7001062195688426
Validation loss: 2.5953226136731753

Epoch: 6| Step: 13
Training loss: 1.9924313863429948
Validation loss: 2.573958460793683

Epoch: 81| Step: 0
Training loss: 2.6134647139624265
Validation loss: 2.5724080110092467

Epoch: 6| Step: 1
Training loss: 2.604956809654159
Validation loss: 2.563393435832192

Epoch: 6| Step: 2
Training loss: 3.314286811715682
Validation loss: 2.568942487384164

Epoch: 6| Step: 3
Training loss: 3.0785017218709654
Validation loss: 2.5769104504057236

Epoch: 6| Step: 4
Training loss: 3.2914189756533605
Validation loss: 2.587898713476721

Epoch: 6| Step: 5
Training loss: 3.2027158894606176
Validation loss: 2.59192063971553

Epoch: 6| Step: 6
Training loss: 2.646248692227033
Validation loss: 2.61285917012527

Epoch: 6| Step: 7
Training loss: 2.457403739992048
Validation loss: 2.6176664459968393

Epoch: 6| Step: 8
Training loss: 2.577333918492303
Validation loss: 2.603780903126185

Epoch: 6| Step: 9
Training loss: 2.9937548802600813
Validation loss: 2.6587183756767305

Epoch: 6| Step: 10
Training loss: 3.111675389146013
Validation loss: 2.6897845334722454

Epoch: 6| Step: 11
Training loss: 3.7761458318965913
Validation loss: 2.6874551075350275

Epoch: 6| Step: 12
Training loss: 2.4851366710880947
Validation loss: 2.6627077507184014

Epoch: 6| Step: 13
Training loss: 2.550990985467132
Validation loss: 2.6345777631090135

Epoch: 82| Step: 0
Training loss: 3.122011205014069
Validation loss: 2.5633733098125355

Epoch: 6| Step: 1
Training loss: 2.500407757884397
Validation loss: 2.574775997119319

Epoch: 6| Step: 2
Training loss: 2.6021022294037692
Validation loss: 2.5742559064156354

Epoch: 6| Step: 3
Training loss: 3.316975575027955
Validation loss: 2.5908991019646215

Epoch: 6| Step: 4
Training loss: 2.7832227418442446
Validation loss: 2.618545795396453

Epoch: 6| Step: 5
Training loss: 3.0950083629883416
Validation loss: 2.6335723278098806

Epoch: 6| Step: 6
Training loss: 3.1797543830304513
Validation loss: 2.6335476508363644

Epoch: 6| Step: 7
Training loss: 2.7244791635552077
Validation loss: 2.6289887796180476

Epoch: 6| Step: 8
Training loss: 3.4233767205905843
Validation loss: 2.635426192286884

Epoch: 6| Step: 9
Training loss: 2.522024792615138
Validation loss: 2.6674344267596366

Epoch: 6| Step: 10
Training loss: 3.3601568687241494
Validation loss: 2.6157737796355507

Epoch: 6| Step: 11
Training loss: 3.070049400801925
Validation loss: 2.6175656643739527

Epoch: 6| Step: 12
Training loss: 3.218054538888176
Validation loss: 2.615952315780973

Epoch: 6| Step: 13
Training loss: 2.2413925197070417
Validation loss: 2.60445728345747

Epoch: 83| Step: 0
Training loss: 3.2769188770337534
Validation loss: 2.5920070085101603

Epoch: 6| Step: 1
Training loss: 2.545251434136925
Validation loss: 2.5777455239240035

Epoch: 6| Step: 2
Training loss: 2.6047017170884774
Validation loss: 2.5804714062029173

Epoch: 6| Step: 3
Training loss: 2.944011208512904
Validation loss: 2.593198580985442

Epoch: 6| Step: 4
Training loss: 2.8913027407020375
Validation loss: 2.6221213786089828

Epoch: 6| Step: 5
Training loss: 3.410037813172761
Validation loss: 2.634686244094539

Epoch: 6| Step: 6
Training loss: 2.7790384822568144
Validation loss: 2.6227036582524526

Epoch: 6| Step: 7
Training loss: 2.5732108705992816
Validation loss: 2.6077110285974108

Epoch: 6| Step: 8
Training loss: 2.8944758977501004
Validation loss: 2.6247073966071

Epoch: 6| Step: 9
Training loss: 2.8836546290732166
Validation loss: 2.633244942414382

Epoch: 6| Step: 10
Training loss: 3.1730799899497693
Validation loss: 2.6201856709078672

Epoch: 6| Step: 11
Training loss: 2.722215395116571
Validation loss: 2.599727827337377

Epoch: 6| Step: 12
Training loss: 2.9691277514603827
Validation loss: 2.583679489287365

Epoch: 6| Step: 13
Training loss: 3.583392268442869
Validation loss: 2.5716496334073145

Epoch: 84| Step: 0
Training loss: 3.2182382713856246
Validation loss: 2.561860508712976

Epoch: 6| Step: 1
Training loss: 2.5312741125394735
Validation loss: 2.5579699470625425

Epoch: 6| Step: 2
Training loss: 3.022959905552201
Validation loss: 2.5602495930083102

Epoch: 6| Step: 3
Training loss: 3.3018272773951964
Validation loss: 2.5590280241469934

Epoch: 6| Step: 4
Training loss: 3.347106959748971
Validation loss: 2.5591296650086766

Epoch: 6| Step: 5
Training loss: 2.123365895886463
Validation loss: 2.558857843301859

Epoch: 6| Step: 6
Training loss: 2.343923536869728
Validation loss: 2.5567535027271653

Epoch: 6| Step: 7
Training loss: 2.8225118668258604
Validation loss: 2.55443550405635

Epoch: 6| Step: 8
Training loss: 3.392638562267512
Validation loss: 2.555598737413672

Epoch: 6| Step: 9
Training loss: 2.979797687703572
Validation loss: 2.5573196210779194

Epoch: 6| Step: 10
Training loss: 2.5139097443541583
Validation loss: 2.5675919756494054

Epoch: 6| Step: 11
Training loss: 2.8698109777854315
Validation loss: 2.595475017703932

Epoch: 6| Step: 12
Training loss: 3.6905707811576876
Validation loss: 2.615007343988175

Epoch: 6| Step: 13
Training loss: 2.21118615575285
Validation loss: 2.6020544369749246

Epoch: 85| Step: 0
Training loss: 2.5236459179483255
Validation loss: 2.5740755299551377

Epoch: 6| Step: 1
Training loss: 2.6210601849972246
Validation loss: 2.5729948180333935

Epoch: 6| Step: 2
Training loss: 3.001680698083097
Validation loss: 2.5634116815266093

Epoch: 6| Step: 3
Training loss: 2.6270467862020523
Validation loss: 2.557812701417892

Epoch: 6| Step: 4
Training loss: 2.783246727317449
Validation loss: 2.554888686720585

Epoch: 6| Step: 5
Training loss: 2.953490865336471
Validation loss: 2.552707643137727

Epoch: 6| Step: 6
Training loss: 3.3781138996008937
Validation loss: 2.548298822088773

Epoch: 6| Step: 7
Training loss: 3.4688858143104984
Validation loss: 2.5511745064371514

Epoch: 6| Step: 8
Training loss: 3.513127910922951
Validation loss: 2.556815437364312

Epoch: 6| Step: 9
Training loss: 2.550940142088894
Validation loss: 2.558455110319617

Epoch: 6| Step: 10
Training loss: 2.8511420789176403
Validation loss: 2.5637167436206054

Epoch: 6| Step: 11
Training loss: 2.535872677052697
Validation loss: 2.573959373121695

Epoch: 6| Step: 12
Training loss: 3.1871110267415133
Validation loss: 2.589774708744862

Epoch: 6| Step: 13
Training loss: 2.5190925157010673
Validation loss: 2.562024365254295

Epoch: 86| Step: 0
Training loss: 2.3470441937570605
Validation loss: 2.56056077173269

Epoch: 6| Step: 1
Training loss: 3.342931201542968
Validation loss: 2.5586864848843476

Epoch: 6| Step: 2
Training loss: 3.2420379236487142
Validation loss: 2.553529334669209

Epoch: 6| Step: 3
Training loss: 3.0089007898255296
Validation loss: 2.5516134754147752

Epoch: 6| Step: 4
Training loss: 2.7057753783248932
Validation loss: 2.5486780494829584

Epoch: 6| Step: 5
Training loss: 2.988761354661765
Validation loss: 2.5499302259563095

Epoch: 6| Step: 6
Training loss: 3.005694230508488
Validation loss: 2.5592997907162496

Epoch: 6| Step: 7
Training loss: 2.9270763102998116
Validation loss: 2.561017695945284

Epoch: 6| Step: 8
Training loss: 2.954491838889052
Validation loss: 2.566012550486425

Epoch: 6| Step: 9
Training loss: 2.705472951781678
Validation loss: 2.5774572477818056

Epoch: 6| Step: 10
Training loss: 3.185472030274958
Validation loss: 2.581342137819761

Epoch: 6| Step: 11
Training loss: 2.4724434373825233
Validation loss: 2.57262832309907

Epoch: 6| Step: 12
Training loss: 2.7364373848970858
Validation loss: 2.579316767598057

Epoch: 6| Step: 13
Training loss: 3.238929527192078
Validation loss: 2.567805019432765

Epoch: 87| Step: 0
Training loss: 2.7919787806548957
Validation loss: 2.5758046158798886

Epoch: 6| Step: 1
Training loss: 3.0509266055521262
Validation loss: 2.5606607158537162

Epoch: 6| Step: 2
Training loss: 2.9760291555371117
Validation loss: 2.5667593837234395

Epoch: 6| Step: 3
Training loss: 3.183412212040341
Validation loss: 2.5515943154554233

Epoch: 6| Step: 4
Training loss: 2.890464324609598
Validation loss: 2.5529039909705404

Epoch: 6| Step: 5
Training loss: 3.175022912130511
Validation loss: 2.5552875313005377

Epoch: 6| Step: 6
Training loss: 2.7591871774414782
Validation loss: 2.555570555855895

Epoch: 6| Step: 7
Training loss: 2.8090712946436787
Validation loss: 2.554468181681941

Epoch: 6| Step: 8
Training loss: 2.632816756157307
Validation loss: 2.5551994327354546

Epoch: 6| Step: 9
Training loss: 2.5862605420391414
Validation loss: 2.5550044081673398

Epoch: 6| Step: 10
Training loss: 2.7927015483526674
Validation loss: 2.5517430821806473

Epoch: 6| Step: 11
Training loss: 3.068694098248949
Validation loss: 2.5513354017685312

Epoch: 6| Step: 12
Training loss: 2.9393321066242626
Validation loss: 2.5478734854262335

Epoch: 6| Step: 13
Training loss: 3.3550792108272636
Validation loss: 2.5458177296746194

Epoch: 88| Step: 0
Training loss: 3.121277384792544
Validation loss: 2.54604311972016

Epoch: 6| Step: 1
Training loss: 2.450086813965084
Validation loss: 2.541503409460232

Epoch: 6| Step: 2
Training loss: 3.1955649875412657
Validation loss: 2.537982251851416

Epoch: 6| Step: 3
Training loss: 3.402201635324871
Validation loss: 2.5418683754901084

Epoch: 6| Step: 4
Training loss: 2.859788875123183
Validation loss: 2.5499906594436923

Epoch: 6| Step: 5
Training loss: 2.68460326106895
Validation loss: 2.5711403528508203

Epoch: 6| Step: 6
Training loss: 2.896654593468525
Validation loss: 2.580010732221591

Epoch: 6| Step: 7
Training loss: 2.9705766378808405
Validation loss: 2.5641896799570305

Epoch: 6| Step: 8
Training loss: 3.1479834141566987
Validation loss: 2.5513378344439905

Epoch: 6| Step: 9
Training loss: 2.74774016381517
Validation loss: 2.5430232024987767

Epoch: 6| Step: 10
Training loss: 3.0061073126606663
Validation loss: 2.546241096038291

Epoch: 6| Step: 11
Training loss: 3.0729680116318647
Validation loss: 2.554181952603817

Epoch: 6| Step: 12
Training loss: 2.3777841010361174
Validation loss: 2.553681015428819

Epoch: 6| Step: 13
Training loss: 2.5379588384093634
Validation loss: 2.553570857102317

Epoch: 89| Step: 0
Training loss: 2.6245521890048327
Validation loss: 2.5885477915012345

Epoch: 6| Step: 1
Training loss: 3.423341201827662
Validation loss: 2.5917585021583585

Epoch: 6| Step: 2
Training loss: 2.64170625658985
Validation loss: 2.56312487586943

Epoch: 6| Step: 3
Training loss: 2.7899892426697
Validation loss: 2.551853634858867

Epoch: 6| Step: 4
Training loss: 3.245366975697171
Validation loss: 2.5604975940548793

Epoch: 6| Step: 5
Training loss: 2.8933946692063963
Validation loss: 2.563974484012728

Epoch: 6| Step: 6
Training loss: 3.194154263644907
Validation loss: 2.559334203754622

Epoch: 6| Step: 7
Training loss: 3.166682460812449
Validation loss: 2.5582089485852753

Epoch: 6| Step: 8
Training loss: 2.5877411881972057
Validation loss: 2.556812002216593

Epoch: 6| Step: 9
Training loss: 3.065867071675496
Validation loss: 2.5575248087855327

Epoch: 6| Step: 10
Training loss: 2.79807992905272
Validation loss: 2.549029695735156

Epoch: 6| Step: 11
Training loss: 3.2279859455658273
Validation loss: 2.5481229163662094

Epoch: 6| Step: 12
Training loss: 2.758991626965993
Validation loss: 2.549585440852435

Epoch: 6| Step: 13
Training loss: 2.0651163787929687
Validation loss: 2.5460038951722863

Epoch: 90| Step: 0
Training loss: 2.6001457503621257
Validation loss: 2.5453468588501353

Epoch: 6| Step: 1
Training loss: 2.9022505939058156
Validation loss: 2.543908697945015

Epoch: 6| Step: 2
Training loss: 2.696308781138282
Validation loss: 2.5586976113617514

Epoch: 6| Step: 3
Training loss: 2.8177560648280475
Validation loss: 2.576440257083027

Epoch: 6| Step: 4
Training loss: 2.335900449937416
Validation loss: 2.622523225836513

Epoch: 6| Step: 5
Training loss: 3.283691369946561
Validation loss: 2.647220653518306

Epoch: 6| Step: 6
Training loss: 2.9451337603258256
Validation loss: 2.6947976173284345

Epoch: 6| Step: 7
Training loss: 3.391405991293039
Validation loss: 2.7069374857465336

Epoch: 6| Step: 8
Training loss: 2.7707707868892735
Validation loss: 2.6262199206017613

Epoch: 6| Step: 9
Training loss: 3.204946604743644
Validation loss: 2.574799217156224

Epoch: 6| Step: 10
Training loss: 2.9456683280375797
Validation loss: 2.546983734795254

Epoch: 6| Step: 11
Training loss: 3.0808290329410366
Validation loss: 2.5408748845539173

Epoch: 6| Step: 12
Training loss: 2.829661589429619
Validation loss: 2.5457828620311718

Epoch: 6| Step: 13
Training loss: 2.7916369270524615
Validation loss: 2.5470621088216574

Epoch: 91| Step: 0
Training loss: 2.747622329029624
Validation loss: 2.5504181197976403

Epoch: 6| Step: 1
Training loss: 2.975331610141568
Validation loss: 2.5511679595936765

Epoch: 6| Step: 2
Training loss: 2.8323976056142017
Validation loss: 2.554546707436717

Epoch: 6| Step: 3
Training loss: 3.0359561214769233
Validation loss: 2.555418696319773

Epoch: 6| Step: 4
Training loss: 2.9798095294066984
Validation loss: 2.5548719665856088

Epoch: 6| Step: 5
Training loss: 2.9439396175536205
Validation loss: 2.555828337365496

Epoch: 6| Step: 6
Training loss: 2.984542122999768
Validation loss: 2.54995373457315

Epoch: 6| Step: 7
Training loss: 2.4374958918610212
Validation loss: 2.553827376857926

Epoch: 6| Step: 8
Training loss: 3.434121430940002
Validation loss: 2.559403869833892

Epoch: 6| Step: 9
Training loss: 3.3438757756901003
Validation loss: 2.555968823626347

Epoch: 6| Step: 10
Training loss: 2.4378167949120826
Validation loss: 2.566821158827826

Epoch: 6| Step: 11
Training loss: 2.941291634605002
Validation loss: 2.548545375704686

Epoch: 6| Step: 12
Training loss: 2.4964196316270333
Validation loss: 2.552379965771862

Epoch: 6| Step: 13
Training loss: 3.3730050301399803
Validation loss: 2.5485165337146896

Epoch: 92| Step: 0
Training loss: 3.1547313095761607
Validation loss: 2.5400123746656256

Epoch: 6| Step: 1
Training loss: 2.7469584377492726
Validation loss: 2.552654871542979

Epoch: 6| Step: 2
Training loss: 2.944264192482026
Validation loss: 2.5802445067980417

Epoch: 6| Step: 3
Training loss: 3.111601066231585
Validation loss: 2.6131807402332936

Epoch: 6| Step: 4
Training loss: 2.6064768703889936
Validation loss: 2.6149791556327373

Epoch: 6| Step: 5
Training loss: 3.462389363748851
Validation loss: 2.58234393881608

Epoch: 6| Step: 6
Training loss: 3.3001287955379364
Validation loss: 2.555176556309041

Epoch: 6| Step: 7
Training loss: 2.2034035364567734
Validation loss: 2.5357843053352687

Epoch: 6| Step: 8
Training loss: 3.0553090275427426
Validation loss: 2.539057575785845

Epoch: 6| Step: 9
Training loss: 3.3189639954621124
Validation loss: 2.5391003283892406

Epoch: 6| Step: 10
Training loss: 2.98490461673131
Validation loss: 2.53621735221589

Epoch: 6| Step: 11
Training loss: 3.0487070688851228
Validation loss: 2.5383939977751995

Epoch: 6| Step: 12
Training loss: 2.296598871980952
Validation loss: 2.536623595617259

Epoch: 6| Step: 13
Training loss: 2.375196649541448
Validation loss: 2.5430651636170785

Epoch: 93| Step: 0
Training loss: 2.0406061519202177
Validation loss: 2.589954835185382

Epoch: 6| Step: 1
Training loss: 3.1339261556079636
Validation loss: 2.6877833248289646

Epoch: 6| Step: 2
Training loss: 3.437573518833844
Validation loss: 2.745488182440489

Epoch: 6| Step: 3
Training loss: 3.035336757874423
Validation loss: 2.642516567682653

Epoch: 6| Step: 4
Training loss: 2.9555337760078206
Validation loss: 2.6183385652422073

Epoch: 6| Step: 5
Training loss: 2.569369528654894
Validation loss: 2.55747846380594

Epoch: 6| Step: 6
Training loss: 2.5066790054234045
Validation loss: 2.5461986344983445

Epoch: 6| Step: 7
Training loss: 2.7331302098264487
Validation loss: 2.5471574898564784

Epoch: 6| Step: 8
Training loss: 3.0196831629194056
Validation loss: 2.5347768019042736

Epoch: 6| Step: 9
Training loss: 3.1359135602598927
Validation loss: 2.5390829398797314

Epoch: 6| Step: 10
Training loss: 2.8461653962961693
Validation loss: 2.5394036742032635

Epoch: 6| Step: 11
Training loss: 2.9650235529924216
Validation loss: 2.537787109326212

Epoch: 6| Step: 12
Training loss: 3.031928861442763
Validation loss: 2.532649665156953

Epoch: 6| Step: 13
Training loss: 3.644508876915854
Validation loss: 2.5343470038123312

Epoch: 94| Step: 0
Training loss: 2.5011647372223624
Validation loss: 2.535633157518527

Epoch: 6| Step: 1
Training loss: 2.622110865899153
Validation loss: 2.5315384714989175

Epoch: 6| Step: 2
Training loss: 2.515161127954381
Validation loss: 2.544897242020706

Epoch: 6| Step: 3
Training loss: 2.96838890690501
Validation loss: 2.5430139974529924

Epoch: 6| Step: 4
Training loss: 3.230280841865267
Validation loss: 2.55319717306621

Epoch: 6| Step: 5
Training loss: 3.312648266047257
Validation loss: 2.5487900235698486

Epoch: 6| Step: 6
Training loss: 3.1226544542190546
Validation loss: 2.5441258345153708

Epoch: 6| Step: 7
Training loss: 2.556069003461715
Validation loss: 2.5427475530886663

Epoch: 6| Step: 8
Training loss: 3.182812703750147
Validation loss: 2.550725751012793

Epoch: 6| Step: 9
Training loss: 2.97140625025676
Validation loss: 2.555069744435377

Epoch: 6| Step: 10
Training loss: 3.2032336705079723
Validation loss: 2.579669460691864

Epoch: 6| Step: 11
Training loss: 2.3133615486923484
Validation loss: 2.581627331740974

Epoch: 6| Step: 12
Training loss: 3.0913569895936273
Validation loss: 2.5954200793206743

Epoch: 6| Step: 13
Training loss: 2.272744509024717
Validation loss: 2.5715131491608214

Epoch: 95| Step: 0
Training loss: 3.1949777591032698
Validation loss: 2.5515312282379425

Epoch: 6| Step: 1
Training loss: 2.492850092996192
Validation loss: 2.529235148336873

Epoch: 6| Step: 2
Training loss: 2.793604809019968
Validation loss: 2.52500264490412

Epoch: 6| Step: 3
Training loss: 2.5233065450129084
Validation loss: 2.5230174371395626

Epoch: 6| Step: 4
Training loss: 3.4467827045330353
Validation loss: 2.5277378424019648

Epoch: 6| Step: 5
Training loss: 3.2866328092872643
Validation loss: 2.5236575686820397

Epoch: 6| Step: 6
Training loss: 3.1076419160190003
Validation loss: 2.516225690236682

Epoch: 6| Step: 7
Training loss: 3.115366621409271
Validation loss: 2.5201908704108713

Epoch: 6| Step: 8
Training loss: 2.056726408615755
Validation loss: 2.5227297909895823

Epoch: 6| Step: 9
Training loss: 2.877769463165853
Validation loss: 2.5367664774015615

Epoch: 6| Step: 10
Training loss: 2.3710134074694005
Validation loss: 2.538976554583453

Epoch: 6| Step: 11
Training loss: 2.9488711120649693
Validation loss: 2.5439881522610976

Epoch: 6| Step: 12
Training loss: 2.939540073464871
Validation loss: 2.554279577938647

Epoch: 6| Step: 13
Training loss: 2.860736293582206
Validation loss: 2.5476623924510298

Epoch: 96| Step: 0
Training loss: 2.5666708149401676
Validation loss: 2.559220001873383

Epoch: 6| Step: 1
Training loss: 2.6124694201856276
Validation loss: 2.5650707658502743

Epoch: 6| Step: 2
Training loss: 3.0054654562892176
Validation loss: 2.5624391261928126

Epoch: 6| Step: 3
Training loss: 3.3089746393342643
Validation loss: 2.5751911711622277

Epoch: 6| Step: 4
Training loss: 2.495180825692854
Validation loss: 2.551947499708403

Epoch: 6| Step: 5
Training loss: 2.752125785398183
Validation loss: 2.530998356225001

Epoch: 6| Step: 6
Training loss: 2.9096984093500176
Validation loss: 2.531501774715487

Epoch: 6| Step: 7
Training loss: 2.303479514923323
Validation loss: 2.530074836911094

Epoch: 6| Step: 8
Training loss: 3.20917813626834
Validation loss: 2.520868733529634

Epoch: 6| Step: 9
Training loss: 3.150212471471961
Validation loss: 2.521704535850379

Epoch: 6| Step: 10
Training loss: 3.048761185003442
Validation loss: 2.52184430641064

Epoch: 6| Step: 11
Training loss: 2.754718027794985
Validation loss: 2.5281570722756537

Epoch: 6| Step: 12
Training loss: 3.083331202600791
Validation loss: 2.5379752346092337

Epoch: 6| Step: 13
Training loss: 2.7894622772669226
Validation loss: 2.5788719788043286

Epoch: 97| Step: 0
Training loss: 3.1194838094411907
Validation loss: 2.5876937626022443

Epoch: 6| Step: 1
Training loss: 2.9159855365159
Validation loss: 2.601968502188517

Epoch: 6| Step: 2
Training loss: 2.9864497936505003
Validation loss: 2.586953989718925

Epoch: 6| Step: 3
Training loss: 3.4069418948150547
Validation loss: 2.5726306997657797

Epoch: 6| Step: 4
Training loss: 2.8380552849253955
Validation loss: 2.5769238122080718

Epoch: 6| Step: 5
Training loss: 2.515018935084873
Validation loss: 2.565450435936617

Epoch: 6| Step: 6
Training loss: 2.247957149938901
Validation loss: 2.5615558200387945

Epoch: 6| Step: 7
Training loss: 2.542630268311822
Validation loss: 2.5623523830711314

Epoch: 6| Step: 8
Training loss: 3.2482427101027027
Validation loss: 2.574452940982511

Epoch: 6| Step: 9
Training loss: 2.538604413304392
Validation loss: 2.5742344531574126

Epoch: 6| Step: 10
Training loss: 3.1341730906603162
Validation loss: 2.5768676456128405

Epoch: 6| Step: 11
Training loss: 2.6914037696151487
Validation loss: 2.581961238282306

Epoch: 6| Step: 12
Training loss: 2.913995246008855
Validation loss: 2.5779707747214897

Epoch: 6| Step: 13
Training loss: 3.132771555949322
Validation loss: 2.5846928609201476

Epoch: 98| Step: 0
Training loss: 3.0965444871542362
Validation loss: 2.568609638140283

Epoch: 6| Step: 1
Training loss: 2.4753191501338834
Validation loss: 2.5623952652611703

Epoch: 6| Step: 2
Training loss: 3.0412577175633557
Validation loss: 2.5503637467807647

Epoch: 6| Step: 3
Training loss: 2.534347428666929
Validation loss: 2.535446379182747

Epoch: 6| Step: 4
Training loss: 2.6532266801776
Validation loss: 2.523611984333897

Epoch: 6| Step: 5
Training loss: 2.58153784303858
Validation loss: 2.527517098465068

Epoch: 6| Step: 6
Training loss: 2.8774405362425504
Validation loss: 2.5333761899180325

Epoch: 6| Step: 7
Training loss: 2.8057723218649717
Validation loss: 2.527057154261616

Epoch: 6| Step: 8
Training loss: 3.123412224809019
Validation loss: 2.520186190082228

Epoch: 6| Step: 9
Training loss: 2.971771629934474
Validation loss: 2.5198575372561214

Epoch: 6| Step: 10
Training loss: 2.986087487494496
Validation loss: 2.5238557509126456

Epoch: 6| Step: 11
Training loss: 3.0804419148471327
Validation loss: 2.5118853579271803

Epoch: 6| Step: 12
Training loss: 2.9880495467769843
Validation loss: 2.5260857095653986

Epoch: 6| Step: 13
Training loss: 3.331042662962026
Validation loss: 2.5445348387883278

Epoch: 99| Step: 0
Training loss: 2.555139530798775
Validation loss: 2.5666596251418974

Epoch: 6| Step: 1
Training loss: 3.0860564776312636
Validation loss: 2.590630743300741

Epoch: 6| Step: 2
Training loss: 2.8244299591990925
Validation loss: 2.5964281607253494

Epoch: 6| Step: 3
Training loss: 2.8624994269624495
Validation loss: 2.567161967357938

Epoch: 6| Step: 4
Training loss: 3.5271699002873627
Validation loss: 2.568211598743746

Epoch: 6| Step: 5
Training loss: 2.995205226483635
Validation loss: 2.547868563148038

Epoch: 6| Step: 6
Training loss: 2.852214916269261
Validation loss: 2.5440496751480683

Epoch: 6| Step: 7
Training loss: 2.5431476301572453
Validation loss: 2.5259199905818286

Epoch: 6| Step: 8
Training loss: 2.3947451124164307
Validation loss: 2.5294437149328832

Epoch: 6| Step: 9
Training loss: 2.957753908249078
Validation loss: 2.519766958711644

Epoch: 6| Step: 10
Training loss: 2.7507897890148545
Validation loss: 2.510854627126073

Epoch: 6| Step: 11
Training loss: 2.946176902955058
Validation loss: 2.5166534500356343

Epoch: 6| Step: 12
Training loss: 2.897220983491777
Validation loss: 2.5251987012771417

Epoch: 6| Step: 13
Training loss: 2.748878163484938
Validation loss: 2.529685137955741

Epoch: 100| Step: 0
Training loss: 2.6863265913548044
Validation loss: 2.5450093743951667

Epoch: 6| Step: 1
Training loss: 2.8717981836715576
Validation loss: 2.5435762858707673

Epoch: 6| Step: 2
Training loss: 3.596662585020769
Validation loss: 2.538939871402213

Epoch: 6| Step: 3
Training loss: 2.9179958766100214
Validation loss: 2.538059180644609

Epoch: 6| Step: 4
Training loss: 2.7705086730589956
Validation loss: 2.52786680117609

Epoch: 6| Step: 5
Training loss: 2.887976840721536
Validation loss: 2.528816974099644

Epoch: 6| Step: 6
Training loss: 2.997063789348147
Validation loss: 2.5292114218037707

Epoch: 6| Step: 7
Training loss: 2.2129494506882144
Validation loss: 2.530504306998448

Epoch: 6| Step: 8
Training loss: 2.7893279988412316
Validation loss: 2.548111872493852

Epoch: 6| Step: 9
Training loss: 3.3987798408749987
Validation loss: 2.548409517643764

Epoch: 6| Step: 10
Training loss: 2.583940639687985
Validation loss: 2.5497470779343403

Epoch: 6| Step: 11
Training loss: 2.5068534371954443
Validation loss: 2.5725965981251298

Epoch: 6| Step: 12
Training loss: 2.746756982275231
Validation loss: 2.587993909926631

Epoch: 6| Step: 13
Training loss: 3.1051760745535013
Validation loss: 2.613612794751591

Epoch: 101| Step: 0
Training loss: 2.5680717742372927
Validation loss: 2.5689965470137457

Epoch: 6| Step: 1
Training loss: 2.892396785968424
Validation loss: 2.5385585096031096

Epoch: 6| Step: 2
Training loss: 3.1232030661282577
Validation loss: 2.5307516105920573

Epoch: 6| Step: 3
Training loss: 3.321087914970762
Validation loss: 2.524185036922026

Epoch: 6| Step: 4
Training loss: 2.777970684558708
Validation loss: 2.528175872421096

Epoch: 6| Step: 5
Training loss: 2.642126796212321
Validation loss: 2.5214935864557453

Epoch: 6| Step: 6
Training loss: 2.988550430839898
Validation loss: 2.5254035467626137

Epoch: 6| Step: 7
Training loss: 2.87818566340198
Validation loss: 2.5367536812297864

Epoch: 6| Step: 8
Training loss: 2.4150106302663175
Validation loss: 2.5446629997173975

Epoch: 6| Step: 9
Training loss: 2.501221358456021
Validation loss: 2.570292478028914

Epoch: 6| Step: 10
Training loss: 2.8663247288953584
Validation loss: 2.58632037342749

Epoch: 6| Step: 11
Training loss: 3.0463315821490013
Validation loss: 2.609849513938756

Epoch: 6| Step: 12
Training loss: 3.2249660283155017
Validation loss: 2.6232721977815077

Epoch: 6| Step: 13
Training loss: 3.053963733989877
Validation loss: 2.5797582162232042

Epoch: 102| Step: 0
Training loss: 3.4091742326206003
Validation loss: 2.5330022066700693

Epoch: 6| Step: 1
Training loss: 2.6354006036763957
Validation loss: 2.5002348235810703

Epoch: 6| Step: 2
Training loss: 3.2746387544533775
Validation loss: 2.507269571205268

Epoch: 6| Step: 3
Training loss: 2.651991088973044
Validation loss: 2.5036474353979856

Epoch: 6| Step: 4
Training loss: 3.2827281710484524
Validation loss: 2.507960778763044

Epoch: 6| Step: 5
Training loss: 2.409464781754525
Validation loss: 2.5117684378557663

Epoch: 6| Step: 6
Training loss: 3.218936951772635
Validation loss: 2.512633190237828

Epoch: 6| Step: 7
Training loss: 2.417294804287926
Validation loss: 2.511396479745251

Epoch: 6| Step: 8
Training loss: 3.5747683576751035
Validation loss: 2.501834903575355

Epoch: 6| Step: 9
Training loss: 2.5599046915909383
Validation loss: 2.5114378137533215

Epoch: 6| Step: 10
Training loss: 2.7228353214347334
Validation loss: 2.5139837305101165

Epoch: 6| Step: 11
Training loss: 2.701602396717313
Validation loss: 2.5718238861072873

Epoch: 6| Step: 12
Training loss: 2.0739880449691723
Validation loss: 2.6362189231395323

Epoch: 6| Step: 13
Training loss: 3.0842003677232386
Validation loss: 2.6583061410775417

Epoch: 103| Step: 0
Training loss: 3.07629510541862
Validation loss: 2.6323968396053004

Epoch: 6| Step: 1
Training loss: 2.447036086975816
Validation loss: 2.552663460333448

Epoch: 6| Step: 2
Training loss: 2.904290964393784
Validation loss: 2.5363704392179383

Epoch: 6| Step: 3
Training loss: 2.49043360492864
Validation loss: 2.513035592038959

Epoch: 6| Step: 4
Training loss: 3.3461540350336345
Validation loss: 2.503465438936063

Epoch: 6| Step: 5
Training loss: 2.987436691315674
Validation loss: 2.501177191707803

Epoch: 6| Step: 6
Training loss: 2.4768545658443974
Validation loss: 2.500285295389458

Epoch: 6| Step: 7
Training loss: 3.334433294642935
Validation loss: 2.499545800572891

Epoch: 6| Step: 8
Training loss: 3.3169067148978537
Validation loss: 2.4942341415166442

Epoch: 6| Step: 9
Training loss: 2.6759375310771083
Validation loss: 2.500279274590166

Epoch: 6| Step: 10
Training loss: 2.3833588520986924
Validation loss: 2.502560227497212

Epoch: 6| Step: 11
Training loss: 2.7854010646918557
Validation loss: 2.4990648222795966

Epoch: 6| Step: 12
Training loss: 2.761762777838141
Validation loss: 2.5008173734369126

Epoch: 6| Step: 13
Training loss: 2.8679504211056233
Validation loss: 2.541633535808345

Epoch: 104| Step: 0
Training loss: 2.4851257341532604
Validation loss: 2.5716477223767993

Epoch: 6| Step: 1
Training loss: 3.8265504674071997
Validation loss: 2.6573077687717523

Epoch: 6| Step: 2
Training loss: 2.6689646078473754
Validation loss: 2.585466426309605

Epoch: 6| Step: 3
Training loss: 3.1282790718663596
Validation loss: 2.5268555554946808

Epoch: 6| Step: 4
Training loss: 2.6309411164338306
Validation loss: 2.5062975801457266

Epoch: 6| Step: 5
Training loss: 3.019520511583428
Validation loss: 2.497459492846242

Epoch: 6| Step: 6
Training loss: 2.7233205502076596
Validation loss: 2.4987552640965216

Epoch: 6| Step: 7
Training loss: 2.8395337718762876
Validation loss: 2.512863962406778

Epoch: 6| Step: 8
Training loss: 2.7137449826581164
Validation loss: 2.5116218128820056

Epoch: 6| Step: 9
Training loss: 2.7376703078712032
Validation loss: 2.5284500283667186

Epoch: 6| Step: 10
Training loss: 2.4409804316153982
Validation loss: 2.5377433031804566

Epoch: 6| Step: 11
Training loss: 2.8624138032020667
Validation loss: 2.5538113524687183

Epoch: 6| Step: 12
Training loss: 3.2480145772221616
Validation loss: 2.6105162721101434

Epoch: 6| Step: 13
Training loss: 2.371358287954879
Validation loss: 2.58193211821829

Epoch: 105| Step: 0
Training loss: 3.235620820792706
Validation loss: 2.5954688641097023

Epoch: 6| Step: 1
Training loss: 3.385691063348874
Validation loss: 2.5713177497532542

Epoch: 6| Step: 2
Training loss: 2.7476777762187234
Validation loss: 2.561010021081407

Epoch: 6| Step: 3
Training loss: 2.7113223283686776
Validation loss: 2.5495203773150714

Epoch: 6| Step: 4
Training loss: 2.8835588848411247
Validation loss: 2.550255836651778

Epoch: 6| Step: 5
Training loss: 2.885413838923385
Validation loss: 2.564599514425516

Epoch: 6| Step: 6
Training loss: 2.3359464817448563
Validation loss: 2.54866909721779

Epoch: 6| Step: 7
Training loss: 2.7452959228431992
Validation loss: 2.547971341401884

Epoch: 6| Step: 8
Training loss: 2.9674872674323383
Validation loss: 2.5288514400421254

Epoch: 6| Step: 9
Training loss: 2.5371877468770085
Validation loss: 2.5211739679033665

Epoch: 6| Step: 10
Training loss: 3.0768715102202875
Validation loss: 2.5179825252117602

Epoch: 6| Step: 11
Training loss: 2.359725218794623
Validation loss: 2.5162509961486905

Epoch: 6| Step: 12
Training loss: 3.031149007157
Validation loss: 2.5117582843924917

Epoch: 6| Step: 13
Training loss: 2.708884657473237
Validation loss: 2.515042163527493

Epoch: 106| Step: 0
Training loss: 3.0589816065544233
Validation loss: 2.5298145294851393

Epoch: 6| Step: 1
Training loss: 3.2474177445705172
Validation loss: 2.553551620470169

Epoch: 6| Step: 2
Training loss: 2.7452338270922163
Validation loss: 2.556700603068262

Epoch: 6| Step: 3
Training loss: 2.709867062704013
Validation loss: 2.5342461048977554

Epoch: 6| Step: 4
Training loss: 2.791212263181058
Validation loss: 2.530526708957011

Epoch: 6| Step: 5
Training loss: 2.5856229930830246
Validation loss: 2.517573543680517

Epoch: 6| Step: 6
Training loss: 3.1230989395773485
Validation loss: 2.522381146578636

Epoch: 6| Step: 7
Training loss: 2.5663506953295485
Validation loss: 2.5378354079479664

Epoch: 6| Step: 8
Training loss: 2.81442525454083
Validation loss: 2.5315690006056624

Epoch: 6| Step: 9
Training loss: 2.482500244632336
Validation loss: 2.5449569075554654

Epoch: 6| Step: 10
Training loss: 3.072721589356615
Validation loss: 2.602086990976406

Epoch: 6| Step: 11
Training loss: 2.5223749244312224
Validation loss: 2.6037471366039795

Epoch: 6| Step: 12
Training loss: 2.8347320096274093
Validation loss: 2.586122798696841

Epoch: 6| Step: 13
Training loss: 3.1256647547356358
Validation loss: 2.569306073670586

Epoch: 107| Step: 0
Training loss: 2.3874969961736667
Validation loss: 2.5325944379392373

Epoch: 6| Step: 1
Training loss: 3.315741913915687
Validation loss: 2.5249748143032797

Epoch: 6| Step: 2
Training loss: 2.7521378270389283
Validation loss: 2.5217973321349185

Epoch: 6| Step: 3
Training loss: 3.4227500040657413
Validation loss: 2.50506621547722

Epoch: 6| Step: 4
Training loss: 2.7066104005812637
Validation loss: 2.5075802733053254

Epoch: 6| Step: 5
Training loss: 2.9601105916782604
Validation loss: 2.5039937590198216

Epoch: 6| Step: 6
Training loss: 2.926936696860593
Validation loss: 2.5059000709120602

Epoch: 6| Step: 7
Training loss: 3.0823007521388535
Validation loss: 2.5120693773425558

Epoch: 6| Step: 8
Training loss: 2.2380304911754783
Validation loss: 2.516019864188324

Epoch: 6| Step: 9
Training loss: 2.367345622103927
Validation loss: 2.525070336222281

Epoch: 6| Step: 10
Training loss: 2.9546905081827957
Validation loss: 2.5372840972564092

Epoch: 6| Step: 11
Training loss: 2.2803288520434752
Validation loss: 2.535658099889717

Epoch: 6| Step: 12
Training loss: 3.009038977317609
Validation loss: 2.550052098838451

Epoch: 6| Step: 13
Training loss: 2.8718926596280183
Validation loss: 2.540456428914645

Epoch: 108| Step: 0
Training loss: 2.8798857928519674
Validation loss: 2.54438935140031

Epoch: 6| Step: 1
Training loss: 2.4925856317103112
Validation loss: 2.5433090564704153

Epoch: 6| Step: 2
Training loss: 2.745733940243568
Validation loss: 2.5306233114277044

Epoch: 6| Step: 3
Training loss: 2.991669054659118
Validation loss: 2.5087915813929147

Epoch: 6| Step: 4
Training loss: 3.20202573196203
Validation loss: 2.4982053765487042

Epoch: 6| Step: 5
Training loss: 3.485801644202115
Validation loss: 2.498287096084209

Epoch: 6| Step: 6
Training loss: 3.0998035122528647
Validation loss: 2.5006898215425113

Epoch: 6| Step: 7
Training loss: 2.4854354034851642
Validation loss: 2.5053521802921637

Epoch: 6| Step: 8
Training loss: 2.927883559199455
Validation loss: 2.4965705524672615

Epoch: 6| Step: 9
Training loss: 2.4863023299611933
Validation loss: 2.497275229408978

Epoch: 6| Step: 10
Training loss: 1.9872556788144666
Validation loss: 2.4932590788152424

Epoch: 6| Step: 11
Training loss: 2.8620641184941302
Validation loss: 2.4967400410321616

Epoch: 6| Step: 12
Training loss: 3.05972678292442
Validation loss: 2.515238678290444

Epoch: 6| Step: 13
Training loss: 2.0434674735582954
Validation loss: 2.5524187026290086

Epoch: 109| Step: 0
Training loss: 2.9924832588817436
Validation loss: 2.583081774681342

Epoch: 6| Step: 1
Training loss: 2.9598832883249586
Validation loss: 2.5866563996847143

Epoch: 6| Step: 2
Training loss: 3.147695752177902
Validation loss: 2.6018877216305065

Epoch: 6| Step: 3
Training loss: 2.2045664299178873
Validation loss: 2.617246116994363

Epoch: 6| Step: 4
Training loss: 3.033534496749419
Validation loss: 2.599181603587485

Epoch: 6| Step: 5
Training loss: 2.3925587929703678
Validation loss: 2.574660708292504

Epoch: 6| Step: 6
Training loss: 3.1463563160140935
Validation loss: 2.574072631750185

Epoch: 6| Step: 7
Training loss: 2.9161327054945025
Validation loss: 2.549824813038373

Epoch: 6| Step: 8
Training loss: 2.141154314298234
Validation loss: 2.5308033052633925

Epoch: 6| Step: 9
Training loss: 2.9436752666211983
Validation loss: 2.532200456471745

Epoch: 6| Step: 10
Training loss: 2.424751001532651
Validation loss: 2.5272459281389086

Epoch: 6| Step: 11
Training loss: 3.0981538813023803
Validation loss: 2.5251520553951767

Epoch: 6| Step: 12
Training loss: 2.4442647328447293
Validation loss: 2.503082889992675

Epoch: 6| Step: 13
Training loss: 3.5388863963928974
Validation loss: 2.5004719647600115

Epoch: 110| Step: 0
Training loss: 2.66509068132609
Validation loss: 2.50275032566176

Epoch: 6| Step: 1
Training loss: 2.956737911938598
Validation loss: 2.5014462830310293

Epoch: 6| Step: 2
Training loss: 2.831730183350601
Validation loss: 2.509611713932651

Epoch: 6| Step: 3
Training loss: 2.855874508940375
Validation loss: 2.512147395603089

Epoch: 6| Step: 4
Training loss: 2.742843071370701
Validation loss: 2.5106756016963487

Epoch: 6| Step: 5
Training loss: 2.632609826502247
Validation loss: 2.5082844685654444

Epoch: 6| Step: 6
Training loss: 2.8991698293585513
Validation loss: 2.515184626208417

Epoch: 6| Step: 7
Training loss: 1.8531572258705915
Validation loss: 2.5280415649266823

Epoch: 6| Step: 8
Training loss: 2.3685093578808467
Validation loss: 2.525297485651114

Epoch: 6| Step: 9
Training loss: 3.233251109175616
Validation loss: 2.5401155414452057

Epoch: 6| Step: 10
Training loss: 2.831619043277185
Validation loss: 2.571660011962951

Epoch: 6| Step: 11
Training loss: 2.903546460194634
Validation loss: 2.593826964909682

Epoch: 6| Step: 12
Training loss: 3.1765599721287745
Validation loss: 2.6055259648495523

Epoch: 6| Step: 13
Training loss: 2.817232346772826
Validation loss: 2.6252008157182485

Epoch: 111| Step: 0
Training loss: 3.106944912523092
Validation loss: 2.660970055776456

Epoch: 6| Step: 1
Training loss: 3.015752443773199
Validation loss: 2.6195264160222824

Epoch: 6| Step: 2
Training loss: 2.148702931046698
Validation loss: 2.5927847677201536

Epoch: 6| Step: 3
Training loss: 3.1097752299146673
Validation loss: 2.556237817490497

Epoch: 6| Step: 4
Training loss: 2.9245818140772615
Validation loss: 2.527133390022191

Epoch: 6| Step: 5
Training loss: 2.8812258109113755
Validation loss: 2.5109870043896287

Epoch: 6| Step: 6
Training loss: 2.918665301055844
Validation loss: 2.5130056161540377

Epoch: 6| Step: 7
Training loss: 2.2456478837352507
Validation loss: 2.5088541022636703

Epoch: 6| Step: 8
Training loss: 2.9706655646663975
Validation loss: 2.5208813774502246

Epoch: 6| Step: 9
Training loss: 2.940662710533805
Validation loss: 2.533588654311444

Epoch: 6| Step: 10
Training loss: 2.3947359529651338
Validation loss: 2.5322354159724725

Epoch: 6| Step: 11
Training loss: 2.5032162005589376
Validation loss: 2.5197774436271283

Epoch: 6| Step: 12
Training loss: 2.974503252887855
Validation loss: 2.507920889086555

Epoch: 6| Step: 13
Training loss: 2.8782615405570096
Validation loss: 2.5073670784052053

Epoch: 112| Step: 0
Training loss: 2.511515607672588
Validation loss: 2.510315794805914

Epoch: 6| Step: 1
Training loss: 2.651000996235848
Validation loss: 2.500945556418698

Epoch: 6| Step: 2
Training loss: 2.6525966877622476
Validation loss: 2.4999190153315336

Epoch: 6| Step: 3
Training loss: 3.1713557076644894
Validation loss: 2.505858267027442

Epoch: 6| Step: 4
Training loss: 2.753544863533319
Validation loss: 2.5108206768566466

Epoch: 6| Step: 5
Training loss: 2.3066439325759522
Validation loss: 2.5159824988379276

Epoch: 6| Step: 6
Training loss: 3.5223985311650234
Validation loss: 2.5194860346365733

Epoch: 6| Step: 7
Training loss: 2.649252796994891
Validation loss: 2.5270276886137

Epoch: 6| Step: 8
Training loss: 2.1990093992066226
Validation loss: 2.5365762946980697

Epoch: 6| Step: 9
Training loss: 2.6782238580358517
Validation loss: 2.5630495626114644

Epoch: 6| Step: 10
Training loss: 2.9940867957286152
Validation loss: 2.5494816768650264

Epoch: 6| Step: 11
Training loss: 2.362659113940071
Validation loss: 2.535663140908261

Epoch: 6| Step: 12
Training loss: 3.2774092221000486
Validation loss: 2.5160244401854324

Epoch: 6| Step: 13
Training loss: 3.1192647566486422
Validation loss: 2.5107459705572355

Epoch: 113| Step: 0
Training loss: 2.9862607420659857
Validation loss: 2.5147964559180638

Epoch: 6| Step: 1
Training loss: 2.935797177504578
Validation loss: 2.523220989529794

Epoch: 6| Step: 2
Training loss: 2.531911033688472
Validation loss: 2.5194230622649907

Epoch: 6| Step: 3
Training loss: 2.525886693441384
Validation loss: 2.5334899898298517

Epoch: 6| Step: 4
Training loss: 2.6778727355870533
Validation loss: 2.5457744967467377

Epoch: 6| Step: 5
Training loss: 3.099561069547193
Validation loss: 2.5565274434598453

Epoch: 6| Step: 6
Training loss: 3.042580732843278
Validation loss: 2.567872473472843

Epoch: 6| Step: 7
Training loss: 2.5935416999731298
Validation loss: 2.5579222170409905

Epoch: 6| Step: 8
Training loss: 2.4273989776428135
Validation loss: 2.552759452562513

Epoch: 6| Step: 9
Training loss: 2.7796549991896953
Validation loss: 2.5364298909339005

Epoch: 6| Step: 10
Training loss: 3.1261769939258195
Validation loss: 2.516709283765212

Epoch: 6| Step: 11
Training loss: 2.876958926027332
Validation loss: 2.513030860639015

Epoch: 6| Step: 12
Training loss: 2.4610511390243035
Validation loss: 2.5204875789948282

Epoch: 6| Step: 13
Training loss: 2.928836139319072
Validation loss: 2.5346718177460623

Epoch: 114| Step: 0
Training loss: 2.9101297057304514
Validation loss: 2.5435242737701125

Epoch: 6| Step: 1
Training loss: 2.16922296209434
Validation loss: 2.538398732397209

Epoch: 6| Step: 2
Training loss: 2.390978020427005
Validation loss: 2.5484257485233877

Epoch: 6| Step: 3
Training loss: 3.114508450393616
Validation loss: 2.5564390867788234

Epoch: 6| Step: 4
Training loss: 2.959472454847069
Validation loss: 2.544504895457693

Epoch: 6| Step: 5
Training loss: 3.049544509895613
Validation loss: 2.5405786361795766

Epoch: 6| Step: 6
Training loss: 2.5659184797959766
Validation loss: 2.5321806150623147

Epoch: 6| Step: 7
Training loss: 2.570413512126314
Validation loss: 2.5276791345490373

Epoch: 6| Step: 8
Training loss: 3.2807855186501853
Validation loss: 2.512653007454243

Epoch: 6| Step: 9
Training loss: 2.7508599930651747
Validation loss: 2.51399209042539

Epoch: 6| Step: 10
Training loss: 3.17944185025076
Validation loss: 2.505773515393856

Epoch: 6| Step: 11
Training loss: 2.421346102152919
Validation loss: 2.5136266327696393

Epoch: 6| Step: 12
Training loss: 2.7147710337608713
Validation loss: 2.5205327072287567

Epoch: 6| Step: 13
Training loss: 2.2115986512838064
Validation loss: 2.5134587839666613

Epoch: 115| Step: 0
Training loss: 3.0552395763202234
Validation loss: 2.5187013587661102

Epoch: 6| Step: 1
Training loss: 2.972812643461165
Validation loss: 2.5087147678168003

Epoch: 6| Step: 2
Training loss: 2.7710697006330607
Validation loss: 2.5064878448931744

Epoch: 6| Step: 3
Training loss: 2.564927230903267
Validation loss: 2.509239875441837

Epoch: 6| Step: 4
Training loss: 2.620914458781561
Validation loss: 2.525052659208416

Epoch: 6| Step: 5
Training loss: 2.3771551292424915
Validation loss: 2.5250191130514277

Epoch: 6| Step: 6
Training loss: 1.980469412116969
Validation loss: 2.523661104830093

Epoch: 6| Step: 7
Training loss: 2.5956755694784555
Validation loss: 2.5400111791466284

Epoch: 6| Step: 8
Training loss: 2.6516085295315137
Validation loss: 2.527097911549365

Epoch: 6| Step: 9
Training loss: 3.1573982793834103
Validation loss: 2.5468910569586276

Epoch: 6| Step: 10
Training loss: 3.3552135152854725
Validation loss: 2.5464657922139105

Epoch: 6| Step: 11
Training loss: 2.6930008415167026
Validation loss: 2.556634330806002

Epoch: 6| Step: 12
Training loss: 3.0865465553044107
Validation loss: 2.523825103109232

Epoch: 6| Step: 13
Training loss: 2.434643465451056
Validation loss: 2.5264196314601635

Epoch: 116| Step: 0
Training loss: 2.6436188108391696
Validation loss: 2.521952100567031

Epoch: 6| Step: 1
Training loss: 2.2122485044829747
Validation loss: 2.5388737292672734

Epoch: 6| Step: 2
Training loss: 2.490060694004598
Validation loss: 2.5448928952366368

Epoch: 6| Step: 3
Training loss: 2.849242554782995
Validation loss: 2.5350757058153883

Epoch: 6| Step: 4
Training loss: 2.993576006521921
Validation loss: 2.5129801969681944

Epoch: 6| Step: 5
Training loss: 2.339439701099771
Validation loss: 2.49429041953684

Epoch: 6| Step: 6
Training loss: 2.821789299391202
Validation loss: 2.4855206629532014

Epoch: 6| Step: 7
Training loss: 3.0276981269399985
Validation loss: 2.4910707119175965

Epoch: 6| Step: 8
Training loss: 2.8791886376197264
Validation loss: 2.495566666708533

Epoch: 6| Step: 9
Training loss: 3.009223428713943
Validation loss: 2.483569880964249

Epoch: 6| Step: 10
Training loss: 2.8958305706495833
Validation loss: 2.4860301577939117

Epoch: 6| Step: 11
Training loss: 3.0869041763721796
Validation loss: 2.4912913789231044

Epoch: 6| Step: 12
Training loss: 2.94779349744874
Validation loss: 2.4833311536253158

Epoch: 6| Step: 13
Training loss: 2.30689901508408
Validation loss: 2.490424411382291

Epoch: 117| Step: 0
Training loss: 3.157781550403441
Validation loss: 2.4838845229381614

Epoch: 6| Step: 1
Training loss: 2.828877891518485
Validation loss: 2.493488114472575

Epoch: 6| Step: 2
Training loss: 2.482184542063824
Validation loss: 2.5072434343573415

Epoch: 6| Step: 3
Training loss: 2.767866099470563
Validation loss: 2.5200706520762983

Epoch: 6| Step: 4
Training loss: 2.9849881645747556
Validation loss: 2.554696333835644

Epoch: 6| Step: 5
Training loss: 2.1013527237236334
Validation loss: 2.5570455476612857

Epoch: 6| Step: 6
Training loss: 2.8849239732056646
Validation loss: 2.550615264030273

Epoch: 6| Step: 7
Training loss: 3.1194115069054393
Validation loss: 2.5551633882999125

Epoch: 6| Step: 8
Training loss: 2.663472666845615
Validation loss: 2.525248587843609

Epoch: 6| Step: 9
Training loss: 2.409876481052642
Validation loss: 2.5128531446218134

Epoch: 6| Step: 10
Training loss: 2.9930441006241875
Validation loss: 2.5078640214597576

Epoch: 6| Step: 11
Training loss: 2.4409450736298894
Validation loss: 2.5266973830355597

Epoch: 6| Step: 12
Training loss: 2.919067992832189
Validation loss: 2.510376783675477

Epoch: 6| Step: 13
Training loss: 2.6023904668530764
Validation loss: 2.5082628261539344

Epoch: 118| Step: 0
Training loss: 2.872793428923513
Validation loss: 2.497353732428192

Epoch: 6| Step: 1
Training loss: 2.5967536907116564
Validation loss: 2.5151070935723623

Epoch: 6| Step: 2
Training loss: 2.272023498635265
Validation loss: 2.5029193609301665

Epoch: 6| Step: 3
Training loss: 2.573371991063171
Validation loss: 2.5033776262438603

Epoch: 6| Step: 4
Training loss: 2.969450215531409
Validation loss: 2.5079439624739512

Epoch: 6| Step: 5
Training loss: 2.674024642956324
Validation loss: 2.521166878456994

Epoch: 6| Step: 6
Training loss: 2.844680130982642
Validation loss: 2.529307322944388

Epoch: 6| Step: 7
Training loss: 2.7130872134776265
Validation loss: 2.5219825139526257

Epoch: 6| Step: 8
Training loss: 2.7606558258290876
Validation loss: 2.5242480824461824

Epoch: 6| Step: 9
Training loss: 2.8544221935375926
Validation loss: 2.504534718668498

Epoch: 6| Step: 10
Training loss: 2.2305685846062486
Validation loss: 2.489303000201585

Epoch: 6| Step: 11
Training loss: 3.226435993661025
Validation loss: 2.4838004484615115

Epoch: 6| Step: 12
Training loss: 2.9189575644293724
Validation loss: 2.4869571000387105

Epoch: 6| Step: 13
Training loss: 3.0332282778255233
Validation loss: 2.4943597953140313

Epoch: 119| Step: 0
Training loss: 2.5691211107512553
Validation loss: 2.487002163581889

Epoch: 6| Step: 1
Training loss: 2.244134250562096
Validation loss: 2.486911694466615

Epoch: 6| Step: 2
Training loss: 2.6464422131097254
Validation loss: 2.5053414155152045

Epoch: 6| Step: 3
Training loss: 3.1780269701457273
Validation loss: 2.5139389568679027

Epoch: 6| Step: 4
Training loss: 2.557760181486156
Validation loss: 2.5491680384581827

Epoch: 6| Step: 5
Training loss: 2.3848390060244657
Validation loss: 2.5602325023447547

Epoch: 6| Step: 6
Training loss: 2.4490781801516905
Validation loss: 2.531991680568217

Epoch: 6| Step: 7
Training loss: 2.930287048027529
Validation loss: 2.5172830232402554

Epoch: 6| Step: 8
Training loss: 2.7457461835801165
Validation loss: 2.4958753256430843

Epoch: 6| Step: 9
Training loss: 3.188610407077823
Validation loss: 2.480942983642223

Epoch: 6| Step: 10
Training loss: 3.1742559807763047
Validation loss: 2.480997285221813

Epoch: 6| Step: 11
Training loss: 2.38997077716535
Validation loss: 2.4813390141640888

Epoch: 6| Step: 12
Training loss: 3.0621868674118677
Validation loss: 2.482495499440466

Epoch: 6| Step: 13
Training loss: 3.1479325185326563
Validation loss: 2.483364550097065

Epoch: 120| Step: 0
Training loss: 2.9930479241844496
Validation loss: 2.4840925142109747

Epoch: 6| Step: 1
Training loss: 2.856783333365333
Validation loss: 2.5117302907101497

Epoch: 6| Step: 2
Training loss: 2.7129393120743663
Validation loss: 2.54130874311109

Epoch: 6| Step: 3
Training loss: 3.046403584324307
Validation loss: 2.557646749788159

Epoch: 6| Step: 4
Training loss: 2.772762076646932
Validation loss: 2.5186967855967692

Epoch: 6| Step: 5
Training loss: 2.9683082653474324
Validation loss: 2.483171160637902

Epoch: 6| Step: 6
Training loss: 2.6430248663862277
Validation loss: 2.481678705924731

Epoch: 6| Step: 7
Training loss: 2.4219549350467817
Validation loss: 2.4752383449952386

Epoch: 6| Step: 8
Training loss: 2.3368091806802758
Validation loss: 2.473756313570753

Epoch: 6| Step: 9
Training loss: 3.101925307416826
Validation loss: 2.471899760337872

Epoch: 6| Step: 10
Training loss: 3.3367237174091597
Validation loss: 2.477212345679848

Epoch: 6| Step: 11
Training loss: 2.4140109454825733
Validation loss: 2.4859247794526818

Epoch: 6| Step: 12
Training loss: 2.294337421422277
Validation loss: 2.498735461827495

Epoch: 6| Step: 13
Training loss: 2.7363925139361727
Validation loss: 2.5129352891454957

Epoch: 121| Step: 0
Training loss: 2.232652760711918
Validation loss: 2.5434719380683997

Epoch: 6| Step: 1
Training loss: 2.875188738391285
Validation loss: 2.5696819763969834

Epoch: 6| Step: 2
Training loss: 2.848681188256963
Validation loss: 2.5485926989170182

Epoch: 6| Step: 3
Training loss: 2.9426957301767356
Validation loss: 2.581853482078262

Epoch: 6| Step: 4
Training loss: 2.9861384269785827
Validation loss: 2.5890921400684412

Epoch: 6| Step: 5
Training loss: 2.5031930559410074
Validation loss: 2.5602178768597486

Epoch: 6| Step: 6
Training loss: 3.1044178462119745
Validation loss: 2.5378576881200674

Epoch: 6| Step: 7
Training loss: 2.2754549598603413
Validation loss: 2.51694817897555

Epoch: 6| Step: 8
Training loss: 2.845686033429284
Validation loss: 2.4866666362400323

Epoch: 6| Step: 9
Training loss: 2.2428221120172602
Validation loss: 2.483016377516596

Epoch: 6| Step: 10
Training loss: 3.1077315237965815
Validation loss: 2.48898307026174

Epoch: 6| Step: 11
Training loss: 2.818205492837529
Validation loss: 2.4978825975036334

Epoch: 6| Step: 12
Training loss: 2.884337975294348
Validation loss: 2.504016002961393

Epoch: 6| Step: 13
Training loss: 3.7520302680691855
Validation loss: 2.5055436494996397

Epoch: 122| Step: 0
Training loss: 2.92037452072651
Validation loss: 2.5331401303046324

Epoch: 6| Step: 1
Training loss: 3.2297653299595757
Validation loss: 2.562235161486275

Epoch: 6| Step: 2
Training loss: 2.7136512387656406
Validation loss: 2.580116792779245

Epoch: 6| Step: 3
Training loss: 2.255356346952628
Validation loss: 2.6175262422965337

Epoch: 6| Step: 4
Training loss: 3.5785009195012907
Validation loss: 2.644480068422634

Epoch: 6| Step: 5
Training loss: 3.188918452581815
Validation loss: 2.5870758328012067

Epoch: 6| Step: 6
Training loss: 3.3068998970820522
Validation loss: 2.5494881817833654

Epoch: 6| Step: 7
Training loss: 2.468826679052949
Validation loss: 2.526735817607486

Epoch: 6| Step: 8
Training loss: 2.677528868732419
Validation loss: 2.5103149379834915

Epoch: 6| Step: 9
Training loss: 2.786484411004701
Validation loss: 2.4946949631116286

Epoch: 6| Step: 10
Training loss: 2.2697681296816006
Validation loss: 2.499652661016022

Epoch: 6| Step: 11
Training loss: 2.5524343651413433
Validation loss: 2.4990563190774426

Epoch: 6| Step: 12
Training loss: 2.4130361405980887
Validation loss: 2.4878221844570994

Epoch: 6| Step: 13
Training loss: 2.4684976376341976
Validation loss: 2.486667584718168

Epoch: 123| Step: 0
Training loss: 3.1692873166276536
Validation loss: 2.480575342966831

Epoch: 6| Step: 1
Training loss: 2.975483536092843
Validation loss: 2.492067587011446

Epoch: 6| Step: 2
Training loss: 3.174011713440211
Validation loss: 2.4993154101158344

Epoch: 6| Step: 3
Training loss: 2.6831869958183696
Validation loss: 2.514332897995138

Epoch: 6| Step: 4
Training loss: 2.965338101593593
Validation loss: 2.543533976386188

Epoch: 6| Step: 5
Training loss: 2.7006109817942665
Validation loss: 2.5325159866785163

Epoch: 6| Step: 6
Training loss: 2.8129390797668354
Validation loss: 2.528718507672705

Epoch: 6| Step: 7
Training loss: 2.4699891276255403
Validation loss: 2.5453749632450693

Epoch: 6| Step: 8
Training loss: 2.2419909879586695
Validation loss: 2.547197407197653

Epoch: 6| Step: 9
Training loss: 2.910700518001322
Validation loss: 2.538386376711924

Epoch: 6| Step: 10
Training loss: 3.1150309433479366
Validation loss: 2.534688633709186

Epoch: 6| Step: 11
Training loss: 2.2396378857969585
Validation loss: 2.54101450108078

Epoch: 6| Step: 12
Training loss: 2.5242789079209067
Validation loss: 2.5054716662104317

Epoch: 6| Step: 13
Training loss: 2.2329776903021137
Validation loss: 2.488191578497006

Epoch: 124| Step: 0
Training loss: 3.2075857967756307
Validation loss: 2.5080620257528774

Epoch: 6| Step: 1
Training loss: 2.5912099143431875
Validation loss: 2.525021458383028

Epoch: 6| Step: 2
Training loss: 3.7099708342112665
Validation loss: 2.5304932875428285

Epoch: 6| Step: 3
Training loss: 2.25989665951391
Validation loss: 2.5132368111106667

Epoch: 6| Step: 4
Training loss: 2.772689761520635
Validation loss: 2.502437961514971

Epoch: 6| Step: 5
Training loss: 3.007589277431137
Validation loss: 2.490202553642485

Epoch: 6| Step: 6
Training loss: 2.936919459339076
Validation loss: 2.5064511874035125

Epoch: 6| Step: 7
Training loss: 2.3535514860468094
Validation loss: 2.521540889699366

Epoch: 6| Step: 8
Training loss: 2.154358407297803
Validation loss: 2.545741861099565

Epoch: 6| Step: 9
Training loss: 2.6165953008877643
Validation loss: 2.5467230618561483

Epoch: 6| Step: 10
Training loss: 2.9065417071555277
Validation loss: 2.56683979763625

Epoch: 6| Step: 11
Training loss: 2.5302357466557903
Validation loss: 2.5621292222179006

Epoch: 6| Step: 12
Training loss: 2.4878885627027683
Validation loss: 2.522768710780229

Epoch: 6| Step: 13
Training loss: 2.939157059165914
Validation loss: 2.498680566420978

Epoch: 125| Step: 0
Training loss: 2.2954770978957972
Validation loss: 2.495442849419844

Epoch: 6| Step: 1
Training loss: 3.105520034462544
Validation loss: 2.492876865122794

Epoch: 6| Step: 2
Training loss: 2.2942624966963914
Validation loss: 2.5057489119202025

Epoch: 6| Step: 3
Training loss: 2.779186554875242
Validation loss: 2.5032437200392126

Epoch: 6| Step: 4
Training loss: 3.2844957556334906
Validation loss: 2.522482314793829

Epoch: 6| Step: 5
Training loss: 2.8761942497729107
Validation loss: 2.513522174773006

Epoch: 6| Step: 6
Training loss: 2.7113631296364478
Validation loss: 2.5019892315585

Epoch: 6| Step: 7
Training loss: 2.642088535289479
Validation loss: 2.496580131044542

Epoch: 6| Step: 8
Training loss: 2.5104852142050524
Validation loss: 2.46845139659882

Epoch: 6| Step: 9
Training loss: 3.0314063592284204
Validation loss: 2.479168447685343

Epoch: 6| Step: 10
Training loss: 2.505106859802256
Validation loss: 2.483111544674156

Epoch: 6| Step: 11
Training loss: 2.4027135052718056
Validation loss: 2.485487069050315

Epoch: 6| Step: 12
Training loss: 2.7314821471975583
Validation loss: 2.478751965737736

Epoch: 6| Step: 13
Training loss: 2.8701854696390185
Validation loss: 2.4879682820612437

Epoch: 126| Step: 0
Training loss: 2.5792224744470706
Validation loss: 2.5177228961039257

Epoch: 6| Step: 1
Training loss: 2.6165063683395697
Validation loss: 2.5377382561919237

Epoch: 6| Step: 2
Training loss: 2.5026040819838262
Validation loss: 2.5765250722190913

Epoch: 6| Step: 3
Training loss: 3.166979690607089
Validation loss: 2.6434681961574245

Epoch: 6| Step: 4
Training loss: 3.0496128399373488
Validation loss: 2.6989575369427543

Epoch: 6| Step: 5
Training loss: 2.728628168536143
Validation loss: 2.645781980569599

Epoch: 6| Step: 6
Training loss: 2.833678467617121
Validation loss: 2.617482812781183

Epoch: 6| Step: 7
Training loss: 2.562992885917587
Validation loss: 2.532416110152022

Epoch: 6| Step: 8
Training loss: 2.4492255641227976
Validation loss: 2.4922371606478726

Epoch: 6| Step: 9
Training loss: 2.5908206805974108
Validation loss: 2.469351367492941

Epoch: 6| Step: 10
Training loss: 2.9564853501946406
Validation loss: 2.460165852560734

Epoch: 6| Step: 11
Training loss: 2.6684220516777564
Validation loss: 2.4662394637033556

Epoch: 6| Step: 12
Training loss: 3.0429308280491676
Validation loss: 2.466921021745609

Epoch: 6| Step: 13
Training loss: 2.6655124510855486
Validation loss: 2.4706196494727948

Epoch: 127| Step: 0
Training loss: 2.302200682628094
Validation loss: 2.454924457015083

Epoch: 6| Step: 1
Training loss: 2.403643893609275
Validation loss: 2.464402409760724

Epoch: 6| Step: 2
Training loss: 1.8910727483028724
Validation loss: 2.454392111076409

Epoch: 6| Step: 3
Training loss: 2.384919982463543
Validation loss: 2.4920629906846923

Epoch: 6| Step: 4
Training loss: 2.9349773207248036
Validation loss: 2.5205668063834006

Epoch: 6| Step: 5
Training loss: 2.7856764982965307
Validation loss: 2.5536743153907397

Epoch: 6| Step: 6
Training loss: 3.152136208510342
Validation loss: 2.566079816368646

Epoch: 6| Step: 7
Training loss: 3.0466023641042854
Validation loss: 2.5966625838669066

Epoch: 6| Step: 8
Training loss: 2.5064427327847514
Validation loss: 2.564634971918139

Epoch: 6| Step: 9
Training loss: 3.071403950057086
Validation loss: 2.519925639433586

Epoch: 6| Step: 10
Training loss: 3.243288005056016
Validation loss: 2.4929827116014724

Epoch: 6| Step: 11
Training loss: 3.222506654908594
Validation loss: 2.455418129632204

Epoch: 6| Step: 12
Training loss: 2.8770306920551514
Validation loss: 2.4512018142830834

Epoch: 6| Step: 13
Training loss: 2.933014712224271
Validation loss: 2.451188647779024

Epoch: 128| Step: 0
Training loss: 2.8146216972742697
Validation loss: 2.4589376876430897

Epoch: 6| Step: 1
Training loss: 3.4668282348933737
Validation loss: 2.468090989678717

Epoch: 6| Step: 2
Training loss: 1.9984332743011728
Validation loss: 2.4740198312746258

Epoch: 6| Step: 3
Training loss: 3.1571981686590536
Validation loss: 2.4693847116557435

Epoch: 6| Step: 4
Training loss: 2.6028121375556443
Validation loss: 2.4817359597421746

Epoch: 6| Step: 5
Training loss: 2.4000566714271585
Validation loss: 2.478131273911874

Epoch: 6| Step: 6
Training loss: 2.7519637812238233
Validation loss: 2.464424312520396

Epoch: 6| Step: 7
Training loss: 2.3705187230685305
Validation loss: 2.4680994375251264

Epoch: 6| Step: 8
Training loss: 3.0901360259006942
Validation loss: 2.4744050074876203

Epoch: 6| Step: 9
Training loss: 3.1018146249067104
Validation loss: 2.4835255355299592

Epoch: 6| Step: 10
Training loss: 2.2180340108645877
Validation loss: 2.4948258477367626

Epoch: 6| Step: 11
Training loss: 2.9435051753454005
Validation loss: 2.5002601334377905

Epoch: 6| Step: 12
Training loss: 2.5332690063474326
Validation loss: 2.5201774214361614

Epoch: 6| Step: 13
Training loss: 3.0563735406475927
Validation loss: 2.528053284134446

Epoch: 129| Step: 0
Training loss: 2.4627531589560987
Validation loss: 2.5314515860381666

Epoch: 6| Step: 1
Training loss: 3.0784691942515936
Validation loss: 2.5307351326429828

Epoch: 6| Step: 2
Training loss: 1.9946723550385608
Validation loss: 2.517693114508463

Epoch: 6| Step: 3
Training loss: 2.5800539141204135
Validation loss: 2.4944432009440587

Epoch: 6| Step: 4
Training loss: 2.926077854416629
Validation loss: 2.4909020216909683

Epoch: 6| Step: 5
Training loss: 2.637538482963801
Validation loss: 2.4825691774609244

Epoch: 6| Step: 6
Training loss: 3.1509357697318405
Validation loss: 2.472024797802835

Epoch: 6| Step: 7
Training loss: 3.0290092759694036
Validation loss: 2.4365175532235157

Epoch: 6| Step: 8
Training loss: 3.016576112965244
Validation loss: 2.453885214257204

Epoch: 6| Step: 9
Training loss: 2.2415627064286663
Validation loss: 2.443509244204266

Epoch: 6| Step: 10
Training loss: 2.804774886021137
Validation loss: 2.4471907866638922

Epoch: 6| Step: 11
Training loss: 3.054540918447999
Validation loss: 2.4506054980724765

Epoch: 6| Step: 12
Training loss: 2.7700010689413164
Validation loss: 2.4387953802456317

Epoch: 6| Step: 13
Training loss: 2.0670330056193054
Validation loss: 2.4464585429253702

Epoch: 130| Step: 0
Training loss: 2.9702729183892846
Validation loss: 2.4693648981055962

Epoch: 6| Step: 1
Training loss: 2.6611390839949034
Validation loss: 2.4672027169081963

Epoch: 6| Step: 2
Training loss: 2.340216860055367
Validation loss: 2.503855173374766

Epoch: 6| Step: 3
Training loss: 2.536135820776999
Validation loss: 2.545197559120991

Epoch: 6| Step: 4
Training loss: 2.562926931404599
Validation loss: 2.557412957512864

Epoch: 6| Step: 5
Training loss: 2.850959107821902
Validation loss: 2.5877981916789063

Epoch: 6| Step: 6
Training loss: 2.6418771878502594
Validation loss: 2.5650315504267156

Epoch: 6| Step: 7
Training loss: 2.8514290556318875
Validation loss: 2.534227793879461

Epoch: 6| Step: 8
Training loss: 2.63141764924481
Validation loss: 2.5454084455846

Epoch: 6| Step: 9
Training loss: 2.783731189624833
Validation loss: 2.529442935536235

Epoch: 6| Step: 10
Training loss: 3.255707058149785
Validation loss: 2.5410775709458733

Epoch: 6| Step: 11
Training loss: 2.6699160706262344
Validation loss: 2.5212860846641556

Epoch: 6| Step: 12
Training loss: 2.491464348513651
Validation loss: 2.4972653219127756

Epoch: 6| Step: 13
Training loss: 3.1125881136635836
Validation loss: 2.4723667491819223

Epoch: 131| Step: 0
Training loss: 3.061508641062729
Validation loss: 2.468004933840654

Epoch: 6| Step: 1
Training loss: 2.6597795261709445
Validation loss: 2.4813015326039807

Epoch: 6| Step: 2
Training loss: 3.2103085238301117
Validation loss: 2.474721998775068

Epoch: 6| Step: 3
Training loss: 1.8484158718620554
Validation loss: 2.4810174775774887

Epoch: 6| Step: 4
Training loss: 2.670063408516597
Validation loss: 2.49269926160886

Epoch: 6| Step: 5
Training loss: 2.7918430860961387
Validation loss: 2.505190940170451

Epoch: 6| Step: 6
Training loss: 1.8826051336670928
Validation loss: 2.5167051123985904

Epoch: 6| Step: 7
Training loss: 3.133337875795792
Validation loss: 2.5207472548962064

Epoch: 6| Step: 8
Training loss: 3.2326783968738284
Validation loss: 2.543366383475287

Epoch: 6| Step: 9
Training loss: 2.5544902947047903
Validation loss: 2.5350106784341366

Epoch: 6| Step: 10
Training loss: 2.9156803825000277
Validation loss: 2.5149084584172403

Epoch: 6| Step: 11
Training loss: 2.5918916226441095
Validation loss: 2.51745673707452

Epoch: 6| Step: 12
Training loss: 2.7406286607150223
Validation loss: 2.5489471871668963

Epoch: 6| Step: 13
Training loss: 2.0128838877877016
Validation loss: 2.5626350825431423

Epoch: 132| Step: 0
Training loss: 2.268967156224208
Validation loss: 2.595855779265532

Epoch: 6| Step: 1
Training loss: 2.9273327125033775
Validation loss: 2.591264687727488

Epoch: 6| Step: 2
Training loss: 2.894212301084701
Validation loss: 2.605367441931019

Epoch: 6| Step: 3
Training loss: 2.3274291361870008
Validation loss: 2.576994519870253

Epoch: 6| Step: 4
Training loss: 2.3670380296508706
Validation loss: 2.5268787370161023

Epoch: 6| Step: 5
Training loss: 2.558100575680685
Validation loss: 2.515292227753856

Epoch: 6| Step: 6
Training loss: 2.493785955413667
Validation loss: 2.5091339627746

Epoch: 6| Step: 7
Training loss: 2.605424826278936
Validation loss: 2.5050573263620617

Epoch: 6| Step: 8
Training loss: 3.358106222748065
Validation loss: 2.505298260779081

Epoch: 6| Step: 9
Training loss: 2.9079643853484654
Validation loss: 2.490515925339243

Epoch: 6| Step: 10
Training loss: 3.0214970002160277
Validation loss: 2.4833555032957686

Epoch: 6| Step: 11
Training loss: 2.8531954335672323
Validation loss: 2.47950688384798

Epoch: 6| Step: 12
Training loss: 2.65276700717233
Validation loss: 2.464998151638745

Epoch: 6| Step: 13
Training loss: 2.9215188854886085
Validation loss: 2.467791893598329

Epoch: 133| Step: 0
Training loss: 2.795568917776066
Validation loss: 2.4683508778162984

Epoch: 6| Step: 1
Training loss: 2.7806139443697124
Validation loss: 2.471586531175331

Epoch: 6| Step: 2
Training loss: 2.80010467401762
Validation loss: 2.467464094990733

Epoch: 6| Step: 3
Training loss: 2.486978761895964
Validation loss: 2.4816487634620272

Epoch: 6| Step: 4
Training loss: 2.459413862103119
Validation loss: 2.4807905261511416

Epoch: 6| Step: 5
Training loss: 3.0957607324095804
Validation loss: 2.478426233210732

Epoch: 6| Step: 6
Training loss: 2.691524242809971
Validation loss: 2.480996860014491

Epoch: 6| Step: 7
Training loss: 2.446157388703024
Validation loss: 2.4782800241086336

Epoch: 6| Step: 8
Training loss: 2.4818056843976812
Validation loss: 2.478074796505073

Epoch: 6| Step: 9
Training loss: 2.9847076390413445
Validation loss: 2.487397676695527

Epoch: 6| Step: 10
Training loss: 2.3331253322352765
Validation loss: 2.4914145479537515

Epoch: 6| Step: 11
Training loss: 3.0178044009013587
Validation loss: 2.483631713446152

Epoch: 6| Step: 12
Training loss: 2.8132953790692827
Validation loss: 2.480924995313484

Epoch: 6| Step: 13
Training loss: 2.4251483085349426
Validation loss: 2.490370265430676

Epoch: 134| Step: 0
Training loss: 3.328813078766469
Validation loss: 2.4680053410307012

Epoch: 6| Step: 1
Training loss: 2.7374086826369877
Validation loss: 2.4831099185952423

Epoch: 6| Step: 2
Training loss: 2.8304785951237315
Validation loss: 2.464337865445403

Epoch: 6| Step: 3
Training loss: 2.7349761302122566
Validation loss: 2.4717233721500205

Epoch: 6| Step: 4
Training loss: 2.671686712401211
Validation loss: 2.4600632835746774

Epoch: 6| Step: 5
Training loss: 3.416934692910837
Validation loss: 2.4791718218625634

Epoch: 6| Step: 6
Training loss: 2.6897793352456354
Validation loss: 2.4796601842899157

Epoch: 6| Step: 7
Training loss: 2.5552436619859056
Validation loss: 2.492422091747712

Epoch: 6| Step: 8
Training loss: 2.6613551727627076
Validation loss: 2.493643585121394

Epoch: 6| Step: 9
Training loss: 1.9069817186148443
Validation loss: 2.4959402088961546

Epoch: 6| Step: 10
Training loss: 2.4093659278312907
Validation loss: 2.480868708610026

Epoch: 6| Step: 11
Training loss: 2.4104944421545467
Validation loss: 2.4637276604997735

Epoch: 6| Step: 12
Training loss: 2.4801453867719867
Validation loss: 2.4678888705122275

Epoch: 6| Step: 13
Training loss: 2.6022556973725806
Validation loss: 2.4565504080192624

Epoch: 135| Step: 0
Training loss: 2.4657033156031103
Validation loss: 2.455842868537792

Epoch: 6| Step: 1
Training loss: 2.915393842260967
Validation loss: 2.455035882822135

Epoch: 6| Step: 2
Training loss: 2.7601571206966855
Validation loss: 2.46750332336704

Epoch: 6| Step: 3
Training loss: 2.922649097408382
Validation loss: 2.458453937934918

Epoch: 6| Step: 4
Training loss: 3.186316775448709
Validation loss: 2.4656884382071604

Epoch: 6| Step: 5
Training loss: 2.9570277023798073
Validation loss: 2.4659476860009493

Epoch: 6| Step: 6
Training loss: 2.259337863643303
Validation loss: 2.4825030566318564

Epoch: 6| Step: 7
Training loss: 3.0701456971030594
Validation loss: 2.495235893643492

Epoch: 6| Step: 8
Training loss: 3.0558558422459767
Validation loss: 2.4947181238849043

Epoch: 6| Step: 9
Training loss: 2.11810665659589
Validation loss: 2.4785238811292993

Epoch: 6| Step: 10
Training loss: 2.0081221642282734
Validation loss: 2.4843122593433624

Epoch: 6| Step: 11
Training loss: 2.4843625242291902
Validation loss: 2.474367942039409

Epoch: 6| Step: 12
Training loss: 2.270639382108653
Validation loss: 2.476785881785839

Epoch: 6| Step: 13
Training loss: 3.0042549794020825
Validation loss: 2.4770410014060857

Epoch: 136| Step: 0
Training loss: 2.800318808798063
Validation loss: 2.4924792767220483

Epoch: 6| Step: 1
Training loss: 3.467743598725821
Validation loss: 2.5031452656578543

Epoch: 6| Step: 2
Training loss: 2.289330164131603
Validation loss: 2.495356487573498

Epoch: 6| Step: 3
Training loss: 2.308662219895962
Validation loss: 2.516213555269801

Epoch: 6| Step: 4
Training loss: 2.1824136728733805
Validation loss: 2.513152276682713

Epoch: 6| Step: 5
Training loss: 2.397402362923712
Validation loss: 2.5162389066421564

Epoch: 6| Step: 6
Training loss: 2.323282210208541
Validation loss: 2.493717548534341

Epoch: 6| Step: 7
Training loss: 2.627963074040057
Validation loss: 2.487687233803874

Epoch: 6| Step: 8
Training loss: 2.7048152864748
Validation loss: 2.4730829605756797

Epoch: 6| Step: 9
Training loss: 2.814845484665022
Validation loss: 2.4717476733341632

Epoch: 6| Step: 10
Training loss: 2.912840722582386
Validation loss: 2.469486150181732

Epoch: 6| Step: 11
Training loss: 3.0507346722396678
Validation loss: 2.467568095524609

Epoch: 6| Step: 12
Training loss: 2.874849066711515
Validation loss: 2.4621679503271983

Epoch: 6| Step: 13
Training loss: 2.486423151997623
Validation loss: 2.489150537728704

Epoch: 137| Step: 0
Training loss: 2.0963546721337383
Validation loss: 2.4861122228811254

Epoch: 6| Step: 1
Training loss: 2.9609718018812075
Validation loss: 2.5073134619284616

Epoch: 6| Step: 2
Training loss: 2.4339539581244702
Validation loss: 2.499618775003758

Epoch: 6| Step: 3
Training loss: 2.772229600521539
Validation loss: 2.499405057933901

Epoch: 6| Step: 4
Training loss: 2.754221017583064
Validation loss: 2.4941704781415055

Epoch: 6| Step: 5
Training loss: 2.7767812424826546
Validation loss: 2.506856959209143

Epoch: 6| Step: 6
Training loss: 2.723129691031712
Validation loss: 2.4960562979383125

Epoch: 6| Step: 7
Training loss: 2.6247672931520394
Validation loss: 2.464009964201503

Epoch: 6| Step: 8
Training loss: 2.5125581990803454
Validation loss: 2.4740221503445787

Epoch: 6| Step: 9
Training loss: 2.970635387644071
Validation loss: 2.472028422328552

Epoch: 6| Step: 10
Training loss: 2.6123299684816415
Validation loss: 2.4650198702236077

Epoch: 6| Step: 11
Training loss: 2.6482832872172586
Validation loss: 2.47010916693136

Epoch: 6| Step: 12
Training loss: 2.8624682762020583
Validation loss: 2.4818515490504978

Epoch: 6| Step: 13
Training loss: 2.6679201359040903
Validation loss: 2.476779344290716

Epoch: 138| Step: 0
Training loss: 2.63766448967899
Validation loss: 2.4804787938311335

Epoch: 6| Step: 1
Training loss: 3.194878210573215
Validation loss: 2.4901764713563077

Epoch: 6| Step: 2
Training loss: 2.566138591772915
Validation loss: 2.498848555593278

Epoch: 6| Step: 3
Training loss: 3.053907680242774
Validation loss: 2.5014507842268445

Epoch: 6| Step: 4
Training loss: 3.0046788922214844
Validation loss: 2.5083832945907316

Epoch: 6| Step: 5
Training loss: 1.9302894796190995
Validation loss: 2.537891358527677

Epoch: 6| Step: 6
Training loss: 2.4913967875231875
Validation loss: 2.5289230092538566

Epoch: 6| Step: 7
Training loss: 2.54818888281246
Validation loss: 2.5172280755472967

Epoch: 6| Step: 8
Training loss: 2.5294823773673754
Validation loss: 2.506077880530065

Epoch: 6| Step: 9
Training loss: 2.284467544455364
Validation loss: 2.4760919591483996

Epoch: 6| Step: 10
Training loss: 2.9741242602413984
Validation loss: 2.46886842359774

Epoch: 6| Step: 11
Training loss: 2.5606518104868456
Validation loss: 2.457993217064874

Epoch: 6| Step: 12
Training loss: 2.892730770681141
Validation loss: 2.451158115315822

Epoch: 6| Step: 13
Training loss: 2.485907220086595
Validation loss: 2.462722895826311

Epoch: 139| Step: 0
Training loss: 2.789069595114181
Validation loss: 2.46342460560421

Epoch: 6| Step: 1
Training loss: 2.686728788214564
Validation loss: 2.4717718155928137

Epoch: 6| Step: 2
Training loss: 2.5969303350142052
Validation loss: 2.4784765398913406

Epoch: 6| Step: 3
Training loss: 2.527069973156849
Validation loss: 2.485748240663485

Epoch: 6| Step: 4
Training loss: 2.7008729936213847
Validation loss: 2.4882376025930073

Epoch: 6| Step: 5
Training loss: 2.8358211440920065
Validation loss: 2.494071344887801

Epoch: 6| Step: 6
Training loss: 2.527055349506899
Validation loss: 2.506589188197629

Epoch: 6| Step: 7
Training loss: 2.391692976413677
Validation loss: 2.5249225474617263

Epoch: 6| Step: 8
Training loss: 2.6877356137634125
Validation loss: 2.5220693230962845

Epoch: 6| Step: 9
Training loss: 3.043463572472615
Validation loss: 2.5081025162494086

Epoch: 6| Step: 10
Training loss: 2.704779498972425
Validation loss: 2.5156496638217174

Epoch: 6| Step: 11
Training loss: 2.165810770541306
Validation loss: 2.507686822043645

Epoch: 6| Step: 12
Training loss: 2.6577381229029395
Validation loss: 2.5042694326511326

Epoch: 6| Step: 13
Training loss: 3.004171649930492
Validation loss: 2.4957897368252127

Epoch: 140| Step: 0
Training loss: 2.539328787118146
Validation loss: 2.453971908367966

Epoch: 6| Step: 1
Training loss: 2.1263552439285793
Validation loss: 2.4572973187003098

Epoch: 6| Step: 2
Training loss: 1.814227497702984
Validation loss: 2.4456882706381378

Epoch: 6| Step: 3
Training loss: 2.264372801857286
Validation loss: 2.4435635252209225

Epoch: 6| Step: 4
Training loss: 2.7178146682665694
Validation loss: 2.4385943084826898

Epoch: 6| Step: 5
Training loss: 3.294923322187738
Validation loss: 2.4464061212331334

Epoch: 6| Step: 6
Training loss: 3.0920115509014843
Validation loss: 2.4521009602862223

Epoch: 6| Step: 7
Training loss: 2.7363197604261873
Validation loss: 2.4770983944990457

Epoch: 6| Step: 8
Training loss: 3.5981088492365805
Validation loss: 2.505331741502229

Epoch: 6| Step: 9
Training loss: 2.8368947328838034
Validation loss: 2.514553176249512

Epoch: 6| Step: 10
Training loss: 2.1979977079037627
Validation loss: 2.5386202216380362

Epoch: 6| Step: 11
Training loss: 2.7734883908183043
Validation loss: 2.5628689696131066

Epoch: 6| Step: 12
Training loss: 2.6047267972639685
Validation loss: 2.554842444438158

Epoch: 6| Step: 13
Training loss: 2.0423616926041155
Validation loss: 2.5451406198621878

Epoch: 141| Step: 0
Training loss: 2.3527109377075397
Validation loss: 2.504055255590555

Epoch: 6| Step: 1
Training loss: 2.901513454534247
Validation loss: 2.4982411945291303

Epoch: 6| Step: 2
Training loss: 2.749631163397921
Validation loss: 2.4973780819060556

Epoch: 6| Step: 3
Training loss: 1.9116543315078194
Validation loss: 2.478246209989173

Epoch: 6| Step: 4
Training loss: 2.9875830539028176
Validation loss: 2.492167940775694

Epoch: 6| Step: 5
Training loss: 2.9201704142760376
Validation loss: 2.4722815483410203

Epoch: 6| Step: 6
Training loss: 2.4798201546523826
Validation loss: 2.458884551950654

Epoch: 6| Step: 7
Training loss: 2.0723804438472504
Validation loss: 2.4583679973340686

Epoch: 6| Step: 8
Training loss: 3.0444359039811806
Validation loss: 2.459961471079149

Epoch: 6| Step: 9
Training loss: 3.018656891518302
Validation loss: 2.468931978807659

Epoch: 6| Step: 10
Training loss: 2.5746826309619215
Validation loss: 2.457369304770187

Epoch: 6| Step: 11
Training loss: 2.5258705526907343
Validation loss: 2.4593886166037033

Epoch: 6| Step: 12
Training loss: 2.7505002000368646
Validation loss: 2.4621126925470707

Epoch: 6| Step: 13
Training loss: 3.1318444637590517
Validation loss: 2.4542429790362745

Epoch: 142| Step: 0
Training loss: 2.5308839509750785
Validation loss: 2.465333351372756

Epoch: 6| Step: 1
Training loss: 2.532988339908959
Validation loss: 2.4780070442642455

Epoch: 6| Step: 2
Training loss: 2.294359555443157
Validation loss: 2.483868548929171

Epoch: 6| Step: 3
Training loss: 2.9248791922376163
Validation loss: 2.495081778818231

Epoch: 6| Step: 4
Training loss: 2.765785772963092
Validation loss: 2.5059779242102422

Epoch: 6| Step: 5
Training loss: 2.9673775160594147
Validation loss: 2.53563036905335

Epoch: 6| Step: 6
Training loss: 2.6337921402813866
Validation loss: 2.518727285110237

Epoch: 6| Step: 7
Training loss: 2.5489925638406907
Validation loss: 2.4670701013019265

Epoch: 6| Step: 8
Training loss: 2.8225280850874057
Validation loss: 2.4532051551441367

Epoch: 6| Step: 9
Training loss: 2.8636409434712657
Validation loss: 2.442213262327455

Epoch: 6| Step: 10
Training loss: 2.727292113524229
Validation loss: 2.4410213920869572

Epoch: 6| Step: 11
Training loss: 2.8362781330594657
Validation loss: 2.438648328857517

Epoch: 6| Step: 12
Training loss: 2.032620715771176
Validation loss: 2.4411111706337505

Epoch: 6| Step: 13
Training loss: 2.767159418860729
Validation loss: 2.446101742516789

Epoch: 143| Step: 0
Training loss: 2.308699603808651
Validation loss: 2.448673529423992

Epoch: 6| Step: 1
Training loss: 2.832885781637982
Validation loss: 2.4420041207627667

Epoch: 6| Step: 2
Training loss: 2.7464437899237875
Validation loss: 2.452966962303243

Epoch: 6| Step: 3
Training loss: 2.41317209161763
Validation loss: 2.4731224615998864

Epoch: 6| Step: 4
Training loss: 2.842340140834008
Validation loss: 2.509540481718705

Epoch: 6| Step: 5
Training loss: 2.5345883431344096
Validation loss: 2.4748512246553287

Epoch: 6| Step: 6
Training loss: 2.465361188692328
Validation loss: 2.4606209416732776

Epoch: 6| Step: 7
Training loss: 2.7964468686918593
Validation loss: 2.425188693376235

Epoch: 6| Step: 8
Training loss: 2.8180613317211605
Validation loss: 2.422661539864379

Epoch: 6| Step: 9
Training loss: 3.001921832902538
Validation loss: 2.428559767134618

Epoch: 6| Step: 10
Training loss: 2.5098520701917084
Validation loss: 2.4219151668545513

Epoch: 6| Step: 11
Training loss: 2.9325305215819606
Validation loss: 2.424816740723328

Epoch: 6| Step: 12
Training loss: 2.8535172960510167
Validation loss: 2.42646703527354

Epoch: 6| Step: 13
Training loss: 2.333116441818797
Validation loss: 2.4276498005608813

Epoch: 144| Step: 0
Training loss: 2.452292817490118
Validation loss: 2.4298834786143995

Epoch: 6| Step: 1
Training loss: 2.9076498618499804
Validation loss: 2.440159692050562

Epoch: 6| Step: 2
Training loss: 2.5114805781991687
Validation loss: 2.458265058203053

Epoch: 6| Step: 3
Training loss: 2.596737898640022
Validation loss: 2.470063577238697

Epoch: 6| Step: 4
Training loss: 2.2837797795835133
Validation loss: 2.4694106792604487

Epoch: 6| Step: 5
Training loss: 2.6503693053386725
Validation loss: 2.4806694494108372

Epoch: 6| Step: 6
Training loss: 3.2469788227242455
Validation loss: 2.5162912682742746

Epoch: 6| Step: 7
Training loss: 2.1790639334022517
Validation loss: 2.5170213985020204

Epoch: 6| Step: 8
Training loss: 2.5761357811748424
Validation loss: 2.536807930612561

Epoch: 6| Step: 9
Training loss: 2.6026402895709952
Validation loss: 2.5850765831344127

Epoch: 6| Step: 10
Training loss: 2.838532408719612
Validation loss: 2.623363348939565

Epoch: 6| Step: 11
Training loss: 2.855653268929229
Validation loss: 2.619711308806578

Epoch: 6| Step: 12
Training loss: 3.2929881537647474
Validation loss: 2.5520920559748914

Epoch: 6| Step: 13
Training loss: 2.921316491261133
Validation loss: 2.481160162165207

Epoch: 145| Step: 0
Training loss: 2.5792442897605117
Validation loss: 2.432316443320244

Epoch: 6| Step: 1
Training loss: 3.121936975423371
Validation loss: 2.4211486319925775

Epoch: 6| Step: 2
Training loss: 2.5373574503428853
Validation loss: 2.4362516169662447

Epoch: 6| Step: 3
Training loss: 2.5885770758209654
Validation loss: 2.4482277045298555

Epoch: 6| Step: 4
Training loss: 2.8875065658957073
Validation loss: 2.4793009073201353

Epoch: 6| Step: 5
Training loss: 2.974884441279164
Validation loss: 2.489979984255549

Epoch: 6| Step: 6
Training loss: 3.1793547135147007
Validation loss: 2.5068887726679

Epoch: 6| Step: 7
Training loss: 2.541381152850257
Validation loss: 2.501622407797473

Epoch: 6| Step: 8
Training loss: 2.3414454001512928
Validation loss: 2.476694969101432

Epoch: 6| Step: 9
Training loss: 2.742442409915676
Validation loss: 2.448695992696664

Epoch: 6| Step: 10
Training loss: 2.7250634037306005
Validation loss: 2.4352365854273494

Epoch: 6| Step: 11
Training loss: 2.688798457675118
Validation loss: 2.4648863555677467

Epoch: 6| Step: 12
Training loss: 2.9881274214900118
Validation loss: 2.500504700158449

Epoch: 6| Step: 13
Training loss: 2.568094984015161
Validation loss: 2.50465564789541

Epoch: 146| Step: 0
Training loss: 2.2471910532940638
Validation loss: 2.5106501701523425

Epoch: 6| Step: 1
Training loss: 2.6826274081473938
Validation loss: 2.517741226354166

Epoch: 6| Step: 2
Training loss: 2.835019470094163
Validation loss: 2.5129773548022047

Epoch: 6| Step: 3
Training loss: 3.1772732203703105
Validation loss: 2.5071413096959208

Epoch: 6| Step: 4
Training loss: 2.6443300156541456
Validation loss: 2.4929250445595024

Epoch: 6| Step: 5
Training loss: 2.3168507450255276
Validation loss: 2.4594514228905395

Epoch: 6| Step: 6
Training loss: 2.730833888709119
Validation loss: 2.4491735868546685

Epoch: 6| Step: 7
Training loss: 2.161252838538861
Validation loss: 2.429682759288031

Epoch: 6| Step: 8
Training loss: 2.6215312382308205
Validation loss: 2.407686197784589

Epoch: 6| Step: 9
Training loss: 2.5198450174054683
Validation loss: 2.4073173468722557

Epoch: 6| Step: 10
Training loss: 3.0411909245195186
Validation loss: 2.411320574344966

Epoch: 6| Step: 11
Training loss: 2.9739110155678206
Validation loss: 2.421775950808925

Epoch: 6| Step: 12
Training loss: 2.4347090760005643
Validation loss: 2.4113205690291224

Epoch: 6| Step: 13
Training loss: 2.8930251595820264
Validation loss: 2.4166424017746357

Epoch: 147| Step: 0
Training loss: 2.8680496790479095
Validation loss: 2.4151781839051827

Epoch: 6| Step: 1
Training loss: 2.297013051561834
Validation loss: 2.4035837535653735

Epoch: 6| Step: 2
Training loss: 2.6599257225048905
Validation loss: 2.4169038370490803

Epoch: 6| Step: 3
Training loss: 2.5901092347193235
Validation loss: 2.4447589881958023

Epoch: 6| Step: 4
Training loss: 2.673936907141607
Validation loss: 2.456424761337294

Epoch: 6| Step: 5
Training loss: 2.409893497630523
Validation loss: 2.4779141630598414

Epoch: 6| Step: 6
Training loss: 2.9210256066119005
Validation loss: 2.4960361661316774

Epoch: 6| Step: 7
Training loss: 2.7722750094511444
Validation loss: 2.5267022917679745

Epoch: 6| Step: 8
Training loss: 2.442013205802633
Validation loss: 2.569791610694296

Epoch: 6| Step: 9
Training loss: 2.7813173778816305
Validation loss: 2.5687524523512635

Epoch: 6| Step: 10
Training loss: 2.8358154270601847
Validation loss: 2.5551365980720937

Epoch: 6| Step: 11
Training loss: 2.4343607323048473
Validation loss: 2.529528633269313

Epoch: 6| Step: 12
Training loss: 2.8939524701268033
Validation loss: 2.5076262349588925

Epoch: 6| Step: 13
Training loss: 3.1499996427505534
Validation loss: 2.4537414106572313

Epoch: 148| Step: 0
Training loss: 2.099087871280624
Validation loss: 2.431498876028732

Epoch: 6| Step: 1
Training loss: 2.662620176370126
Validation loss: 2.4208177940453495

Epoch: 6| Step: 2
Training loss: 2.6279000203000713
Validation loss: 2.4366953089212533

Epoch: 6| Step: 3
Training loss: 2.9388132609215507
Validation loss: 2.444360693453633

Epoch: 6| Step: 4
Training loss: 2.4465404998027913
Validation loss: 2.462930217669716

Epoch: 6| Step: 5
Training loss: 3.262715334746631
Validation loss: 2.466100360956913

Epoch: 6| Step: 6
Training loss: 2.690533810797076
Validation loss: 2.4725765761114036

Epoch: 6| Step: 7
Training loss: 2.7298367577957197
Validation loss: 2.4453214259743015

Epoch: 6| Step: 8
Training loss: 2.7263351389355863
Validation loss: 2.4300135750549425

Epoch: 6| Step: 9
Training loss: 3.0298727780566126
Validation loss: 2.4150707845756285

Epoch: 6| Step: 10
Training loss: 2.9298030576168252
Validation loss: 2.4279971289055418

Epoch: 6| Step: 11
Training loss: 2.6260644480226407
Validation loss: 2.4497919105607027

Epoch: 6| Step: 12
Training loss: 2.721933715046876
Validation loss: 2.4716771753861506

Epoch: 6| Step: 13
Training loss: 2.6055962161063904
Validation loss: 2.4911041348140146

Epoch: 149| Step: 0
Training loss: 3.10308923306938
Validation loss: 2.4884551561521273

Epoch: 6| Step: 1
Training loss: 3.0278723076890017
Validation loss: 2.4895472026861127

Epoch: 6| Step: 2
Training loss: 2.565794432013659
Validation loss: 2.46309802015429

Epoch: 6| Step: 3
Training loss: 2.033183776587513
Validation loss: 2.45007232725003

Epoch: 6| Step: 4
Training loss: 2.6020877525550654
Validation loss: 2.450863550020268

Epoch: 6| Step: 5
Training loss: 2.287377371914532
Validation loss: 2.4693721549600713

Epoch: 6| Step: 6
Training loss: 2.9100159886501
Validation loss: 2.4687108132411857

Epoch: 6| Step: 7
Training loss: 2.4792419764088964
Validation loss: 2.462949693694627

Epoch: 6| Step: 8
Training loss: 2.8410851704910023
Validation loss: 2.4706545537262934

Epoch: 6| Step: 9
Training loss: 3.082827621090323
Validation loss: 2.4553928607995075

Epoch: 6| Step: 10
Training loss: 2.995123396482397
Validation loss: 2.4535709882533956

Epoch: 6| Step: 11
Training loss: 2.2735755065769085
Validation loss: 2.446105616636144

Epoch: 6| Step: 12
Training loss: 2.4440294501095785
Validation loss: 2.4516861390538547

Epoch: 6| Step: 13
Training loss: 2.2480566321193556
Validation loss: 2.43902380394297

Epoch: 150| Step: 0
Training loss: 2.698620874903484
Validation loss: 2.4424645576672748

Epoch: 6| Step: 1
Training loss: 2.6591422099016193
Validation loss: 2.4446442478670254

Epoch: 6| Step: 2
Training loss: 2.9969441426786614
Validation loss: 2.4600887884053475

Epoch: 6| Step: 3
Training loss: 2.1596455030590223
Validation loss: 2.454864479865551

Epoch: 6| Step: 4
Training loss: 2.717255718829203
Validation loss: 2.491835112116193

Epoch: 6| Step: 5
Training loss: 2.6924690617419356
Validation loss: 2.4667745620102535

Epoch: 6| Step: 6
Training loss: 2.42759786453744
Validation loss: 2.478191886921656

Epoch: 6| Step: 7
Training loss: 2.696937137741026
Validation loss: 2.4710194904089273

Epoch: 6| Step: 8
Training loss: 2.591264752034558
Validation loss: 2.4721296595625373

Epoch: 6| Step: 9
Training loss: 2.822396900331434
Validation loss: 2.474403561142595

Epoch: 6| Step: 10
Training loss: 2.738827812729519
Validation loss: 2.465023252327634

Epoch: 6| Step: 11
Training loss: 2.9259262965756956
Validation loss: 2.4580703912448434

Epoch: 6| Step: 12
Training loss: 1.960014582015309
Validation loss: 2.4632944753411303

Epoch: 6| Step: 13
Training loss: 2.7644305909734053
Validation loss: 2.444637377978527

Epoch: 151| Step: 0
Training loss: 2.496329569534573
Validation loss: 2.467893166981394

Epoch: 6| Step: 1
Training loss: 3.26808504594873
Validation loss: 2.4710863832928434

Epoch: 6| Step: 2
Training loss: 2.5686588243327986
Validation loss: 2.471374613985286

Epoch: 6| Step: 3
Training loss: 2.483782907622171
Validation loss: 2.4597081611644764

Epoch: 6| Step: 4
Training loss: 3.2457455885603816
Validation loss: 2.483710691049712

Epoch: 6| Step: 5
Training loss: 2.8638920360226816
Validation loss: 2.473873915125239

Epoch: 6| Step: 6
Training loss: 2.469419364482401
Validation loss: 2.5119056239821504

Epoch: 6| Step: 7
Training loss: 2.5068878655875064
Validation loss: 2.489149536640517

Epoch: 6| Step: 8
Training loss: 2.560805155678409
Validation loss: 2.5013987606906056

Epoch: 6| Step: 9
Training loss: 2.6081565707663787
Validation loss: 2.4839630734805036

Epoch: 6| Step: 10
Training loss: 2.373127851949148
Validation loss: 2.481946215492649

Epoch: 6| Step: 11
Training loss: 2.179658841727485
Validation loss: 2.4774248479854664

Epoch: 6| Step: 12
Training loss: 2.6969663991281245
Validation loss: 2.4689539270482483

Epoch: 6| Step: 13
Training loss: 2.0490389734511347
Validation loss: 2.4717905011263337

Epoch: 152| Step: 0
Training loss: 2.720042129919608
Validation loss: 2.4656949624798363

Epoch: 6| Step: 1
Training loss: 2.9684949263365006
Validation loss: 2.462709689942549

Epoch: 6| Step: 2
Training loss: 1.8730147342092158
Validation loss: 2.4574007240083473

Epoch: 6| Step: 3
Training loss: 2.1971404044179956
Validation loss: 2.460801551606977

Epoch: 6| Step: 4
Training loss: 2.479363719471223
Validation loss: 2.46051940126937

Epoch: 6| Step: 5
Training loss: 2.724121049989357
Validation loss: 2.459634509183857

Epoch: 6| Step: 6
Training loss: 2.6524138630966814
Validation loss: 2.462962467368558

Epoch: 6| Step: 7
Training loss: 2.936243965594188
Validation loss: 2.467074904739532

Epoch: 6| Step: 8
Training loss: 2.558158919097656
Validation loss: 2.4739036522064537

Epoch: 6| Step: 9
Training loss: 3.2167092677904185
Validation loss: 2.4670957228183417

Epoch: 6| Step: 10
Training loss: 2.1955203572221897
Validation loss: 2.466050113678062

Epoch: 6| Step: 11
Training loss: 2.6765433235617224
Validation loss: 2.489642928533424

Epoch: 6| Step: 12
Training loss: 2.6237241278286474
Validation loss: 2.494694598300497

Epoch: 6| Step: 13
Training loss: 2.757892726347249
Validation loss: 2.4932320681282207

Epoch: 153| Step: 0
Training loss: 2.653403159074203
Validation loss: 2.4840418785178966

Epoch: 6| Step: 1
Training loss: 2.080461264413108
Validation loss: 2.4837002608320904

Epoch: 6| Step: 2
Training loss: 2.928338882304973
Validation loss: 2.4833008563432863

Epoch: 6| Step: 3
Training loss: 3.123227036118352
Validation loss: 2.4774668563930957

Epoch: 6| Step: 4
Training loss: 2.8993068327047515
Validation loss: 2.494219207148883

Epoch: 6| Step: 5
Training loss: 2.748652474831746
Validation loss: 2.477868352784796

Epoch: 6| Step: 6
Training loss: 2.7290229080038277
Validation loss: 2.468743821293825

Epoch: 6| Step: 7
Training loss: 2.0376566867609975
Validation loss: 2.4491401852489387

Epoch: 6| Step: 8
Training loss: 2.4424400155111523
Validation loss: 2.44749841322

Epoch: 6| Step: 9
Training loss: 1.9248255588710188
Validation loss: 2.441325602456618

Epoch: 6| Step: 10
Training loss: 2.5424998330085273
Validation loss: 2.4370098857077322

Epoch: 6| Step: 11
Training loss: 2.3335645992474867
Validation loss: 2.4407920482865157

Epoch: 6| Step: 12
Training loss: 3.252776207305011
Validation loss: 2.435103558614872

Epoch: 6| Step: 13
Training loss: 2.8062692076571567
Validation loss: 2.416495909261029

Epoch: 154| Step: 0
Training loss: 2.224246671211296
Validation loss: 2.451386353347736

Epoch: 6| Step: 1
Training loss: 2.9284066210372433
Validation loss: 2.4559761608412867

Epoch: 6| Step: 2
Training loss: 2.7492050409042963
Validation loss: 2.4928719329767977

Epoch: 6| Step: 3
Training loss: 2.8043488109395325
Validation loss: 2.4737874759726193

Epoch: 6| Step: 4
Training loss: 2.8731275348764176
Validation loss: 2.466962006674697

Epoch: 6| Step: 5
Training loss: 2.491801838945371
Validation loss: 2.4648309663139094

Epoch: 6| Step: 6
Training loss: 2.2952517008665545
Validation loss: 2.466847893770899

Epoch: 6| Step: 7
Training loss: 3.180611740867247
Validation loss: 2.4563453092841776

Epoch: 6| Step: 8
Training loss: 1.7684156930903197
Validation loss: 2.433640110320447

Epoch: 6| Step: 9
Training loss: 2.4446880286644177
Validation loss: 2.4154332704791397

Epoch: 6| Step: 10
Training loss: 2.2132633767313536
Validation loss: 2.4273657991988453

Epoch: 6| Step: 11
Training loss: 2.9538373138527763
Validation loss: 2.4226239663558924

Epoch: 6| Step: 12
Training loss: 2.617753699248965
Validation loss: 2.420201945044816

Epoch: 6| Step: 13
Training loss: 2.8264370934210454
Validation loss: 2.4126347414440903

Epoch: 155| Step: 0
Training loss: 2.14865765917424
Validation loss: 2.4557203968360275

Epoch: 6| Step: 1
Training loss: 2.352110434534556
Validation loss: 2.46939943389781

Epoch: 6| Step: 2
Training loss: 2.3852632520447665
Validation loss: 2.4946162644077177

Epoch: 6| Step: 3
Training loss: 2.0385402434481676
Validation loss: 2.490172502624518

Epoch: 6| Step: 4
Training loss: 3.2120353511133337
Validation loss: 2.4822593034108986

Epoch: 6| Step: 5
Training loss: 2.123464927468136
Validation loss: 2.475553715553554

Epoch: 6| Step: 6
Training loss: 3.1305242919564282
Validation loss: 2.4663327669020454

Epoch: 6| Step: 7
Training loss: 3.1286447251425193
Validation loss: 2.451014058624429

Epoch: 6| Step: 8
Training loss: 2.548355514732545
Validation loss: 2.4440704150751644

Epoch: 6| Step: 9
Training loss: 2.9191235321659343
Validation loss: 2.444804876737582

Epoch: 6| Step: 10
Training loss: 2.4286050133025805
Validation loss: 2.43317564765085

Epoch: 6| Step: 11
Training loss: 2.4594660159262403
Validation loss: 2.423931737595646

Epoch: 6| Step: 12
Training loss: 2.6062830348859984
Validation loss: 2.4322980289666307

Epoch: 6| Step: 13
Training loss: 2.9391568969298847
Validation loss: 2.436763270304915

Epoch: 156| Step: 0
Training loss: 2.7039269817696074
Validation loss: 2.4349237378670914

Epoch: 6| Step: 1
Training loss: 2.7471242954280846
Validation loss: 2.436522615753883

Epoch: 6| Step: 2
Training loss: 2.0252580737273345
Validation loss: 2.4604750227815364

Epoch: 6| Step: 3
Training loss: 2.941678423403263
Validation loss: 2.4830404824834154

Epoch: 6| Step: 4
Training loss: 2.6934709975340154
Validation loss: 2.453656112647242

Epoch: 6| Step: 5
Training loss: 2.833184032620421
Validation loss: 2.4502735577889143

Epoch: 6| Step: 6
Training loss: 2.872607853045795
Validation loss: 2.433857166929058

Epoch: 6| Step: 7
Training loss: 1.8142908391247212
Validation loss: 2.406071323195464

Epoch: 6| Step: 8
Training loss: 2.7530455630876367
Validation loss: 2.4272943480937172

Epoch: 6| Step: 9
Training loss: 2.1231598459909744
Validation loss: 2.4274612999297145

Epoch: 6| Step: 10
Training loss: 3.1939259997581586
Validation loss: 2.4147663948011586

Epoch: 6| Step: 11
Training loss: 2.952918635832798
Validation loss: 2.446845667888277

Epoch: 6| Step: 12
Training loss: 2.0973994774538496
Validation loss: 2.4686014783137074

Epoch: 6| Step: 13
Training loss: 2.2827621047079507
Validation loss: 2.5067116168096315

Epoch: 157| Step: 0
Training loss: 2.648522929836437
Validation loss: 2.563570700796446

Epoch: 6| Step: 1
Training loss: 2.6768991627160434
Validation loss: 2.6108946447231265

Epoch: 6| Step: 2
Training loss: 2.7977574836931516
Validation loss: 2.626798354587778

Epoch: 6| Step: 3
Training loss: 3.040265235121787
Validation loss: 2.620950218628013

Epoch: 6| Step: 4
Training loss: 2.689181843957036
Validation loss: 2.5345270103509256

Epoch: 6| Step: 5
Training loss: 3.2965695208001833
Validation loss: 2.4906990203622734

Epoch: 6| Step: 6
Training loss: 2.556795795997725
Validation loss: 2.42932160759544

Epoch: 6| Step: 7
Training loss: 2.441995827248747
Validation loss: 2.431494770929882

Epoch: 6| Step: 8
Training loss: 2.3967129847790893
Validation loss: 2.425704297221064

Epoch: 6| Step: 9
Training loss: 3.0184796514351278
Validation loss: 2.443264606905276

Epoch: 6| Step: 10
Training loss: 3.163853315808917
Validation loss: 2.4340794281983618

Epoch: 6| Step: 11
Training loss: 2.0846209425287707
Validation loss: 2.4238002115399264

Epoch: 6| Step: 12
Training loss: 2.264609063033623
Validation loss: 2.4189913706713546

Epoch: 6| Step: 13
Training loss: 2.320817064083291
Validation loss: 2.4162913039070206

Epoch: 158| Step: 0
Training loss: 2.8543872794398157
Validation loss: 2.4231209494392263

Epoch: 6| Step: 1
Training loss: 2.6371485833095676
Validation loss: 2.4449046465559667

Epoch: 6| Step: 2
Training loss: 2.567981346942027
Validation loss: 2.467902513022557

Epoch: 6| Step: 3
Training loss: 2.7496608178168285
Validation loss: 2.4787601921210367

Epoch: 6| Step: 4
Training loss: 2.594745950335687
Validation loss: 2.4861555033843796

Epoch: 6| Step: 5
Training loss: 2.5564451558202452
Validation loss: 2.480985478587532

Epoch: 6| Step: 6
Training loss: 2.760527832863785
Validation loss: 2.5178567337966875

Epoch: 6| Step: 7
Training loss: 2.545437553429552
Validation loss: 2.537359176034595

Epoch: 6| Step: 8
Training loss: 2.7529868464711673
Validation loss: 2.4808379699713745

Epoch: 6| Step: 9
Training loss: 2.4009725984140178
Validation loss: 2.4684960902048276

Epoch: 6| Step: 10
Training loss: 2.1373618097976403
Validation loss: 2.47454781953524

Epoch: 6| Step: 11
Training loss: 2.841478887116738
Validation loss: 2.455742221483914

Epoch: 6| Step: 12
Training loss: 2.866668903734384
Validation loss: 2.4465346275683593

Epoch: 6| Step: 13
Training loss: 2.2921550808247644
Validation loss: 2.41972085908322

Epoch: 159| Step: 0
Training loss: 1.9719842653788116
Validation loss: 2.424440431030424

Epoch: 6| Step: 1
Training loss: 2.6431892179029073
Validation loss: 2.436902235581295

Epoch: 6| Step: 2
Training loss: 2.407910653303904
Validation loss: 2.442253571251134

Epoch: 6| Step: 3
Training loss: 2.144359255148918
Validation loss: 2.450838675651526

Epoch: 6| Step: 4
Training loss: 3.1437778115227317
Validation loss: 2.4698422436476775

Epoch: 6| Step: 5
Training loss: 2.594403288045347
Validation loss: 2.477645401769511

Epoch: 6| Step: 6
Training loss: 2.689963431552935
Validation loss: 2.498292244320309

Epoch: 6| Step: 7
Training loss: 2.8622185581228576
Validation loss: 2.488142972541864

Epoch: 6| Step: 8
Training loss: 2.2449209319126475
Validation loss: 2.4868393666994804

Epoch: 6| Step: 9
Training loss: 2.4909973172571904
Validation loss: 2.4734552968918617

Epoch: 6| Step: 10
Training loss: 2.8588493155778054
Validation loss: 2.4517350876789306

Epoch: 6| Step: 11
Training loss: 2.945473906852632
Validation loss: 2.4476475456211872

Epoch: 6| Step: 12
Training loss: 3.1621030415123417
Validation loss: 2.4293710052534974

Epoch: 6| Step: 13
Training loss: 2.010732820256532
Validation loss: 2.438337724271659

Epoch: 160| Step: 0
Training loss: 2.5445681931481614
Validation loss: 2.4429855222642543

Epoch: 6| Step: 1
Training loss: 2.41666684205504
Validation loss: 2.4421326372353516

Epoch: 6| Step: 2
Training loss: 2.7883981292759925
Validation loss: 2.4500269967241497

Epoch: 6| Step: 3
Training loss: 2.9002617290382307
Validation loss: 2.4473926155171433

Epoch: 6| Step: 4
Training loss: 2.417502609456655
Validation loss: 2.4431208796470836

Epoch: 6| Step: 5
Training loss: 2.2617989692231615
Validation loss: 2.4602130615978335

Epoch: 6| Step: 6
Training loss: 2.413926204055942
Validation loss: 2.454016283276389

Epoch: 6| Step: 7
Training loss: 2.9437505896176925
Validation loss: 2.465247413494091

Epoch: 6| Step: 8
Training loss: 2.603464891607624
Validation loss: 2.4731879935954226

Epoch: 6| Step: 9
Training loss: 2.1166153588672123
Validation loss: 2.465789443449984

Epoch: 6| Step: 10
Training loss: 2.660105521324769
Validation loss: 2.451244046186018

Epoch: 6| Step: 11
Training loss: 2.490430541446358
Validation loss: 2.4418115318011044

Epoch: 6| Step: 12
Training loss: 2.987843041297302
Validation loss: 2.438565570576962

Epoch: 6| Step: 13
Training loss: 2.5224115039738537
Validation loss: 2.4256932630026875

Epoch: 161| Step: 0
Training loss: 3.1271231496073284
Validation loss: 2.417999212783586

Epoch: 6| Step: 1
Training loss: 2.251272265691118
Validation loss: 2.4224211395583124

Epoch: 6| Step: 2
Training loss: 2.3886057984140634
Validation loss: 2.4117164010389986

Epoch: 6| Step: 3
Training loss: 2.787904643295725
Validation loss: 2.420012293292593

Epoch: 6| Step: 4
Training loss: 2.6879341307130735
Validation loss: 2.428941439957615

Epoch: 6| Step: 5
Training loss: 2.7600987281279763
Validation loss: 2.42083705713807

Epoch: 6| Step: 6
Training loss: 2.3213731801058395
Validation loss: 2.4393403573453383

Epoch: 6| Step: 7
Training loss: 2.63783360400851
Validation loss: 2.418885336682704

Epoch: 6| Step: 8
Training loss: 2.7729234675766574
Validation loss: 2.4246038215811896

Epoch: 6| Step: 9
Training loss: 2.390660104930161
Validation loss: 2.416850073166324

Epoch: 6| Step: 10
Training loss: 2.5558590317180343
Validation loss: 2.4214306061429425

Epoch: 6| Step: 11
Training loss: 1.8185745914989522
Validation loss: 2.428780231658066

Epoch: 6| Step: 12
Training loss: 2.738369187971437
Validation loss: 2.4451005284151734

Epoch: 6| Step: 13
Training loss: 2.90696346590425
Validation loss: 2.451619753635067

Epoch: 162| Step: 0
Training loss: 2.934295529720431
Validation loss: 2.449863547902745

Epoch: 6| Step: 1
Training loss: 2.277806858197585
Validation loss: 2.4590094244799547

Epoch: 6| Step: 2
Training loss: 2.125357429512983
Validation loss: 2.455271087105828

Epoch: 6| Step: 3
Training loss: 2.6654764936788493
Validation loss: 2.4398817337755623

Epoch: 6| Step: 4
Training loss: 2.2967782551638622
Validation loss: 2.4226289431041175

Epoch: 6| Step: 5
Training loss: 3.380752323776357
Validation loss: 2.4078283749314635

Epoch: 6| Step: 6
Training loss: 2.7709180967134066
Validation loss: 2.402931971734352

Epoch: 6| Step: 7
Training loss: 2.1157361225374873
Validation loss: 2.4073952020718403

Epoch: 6| Step: 8
Training loss: 2.414280458752546
Validation loss: 2.3985632621317032

Epoch: 6| Step: 9
Training loss: 2.6694328345783855
Validation loss: 2.4106118012391575

Epoch: 6| Step: 10
Training loss: 1.9246574047452885
Validation loss: 2.4174544539426632

Epoch: 6| Step: 11
Training loss: 2.9541433687640977
Validation loss: 2.4168793959830763

Epoch: 6| Step: 12
Training loss: 2.3611721242862815
Validation loss: 2.4118526762390124

Epoch: 6| Step: 13
Training loss: 2.5748359739041606
Validation loss: 2.424366540888901

Epoch: 163| Step: 0
Training loss: 2.757537741657851
Validation loss: 2.424235887599641

Epoch: 6| Step: 1
Training loss: 2.2767126867726573
Validation loss: 2.442044237877116

Epoch: 6| Step: 2
Training loss: 2.468484695278951
Validation loss: 2.424478364453538

Epoch: 6| Step: 3
Training loss: 2.7163031079313873
Validation loss: 2.425089272633078

Epoch: 6| Step: 4
Training loss: 2.4165464787906052
Validation loss: 2.4171858757722005

Epoch: 6| Step: 5
Training loss: 2.421684405302788
Validation loss: 2.406371817923217

Epoch: 6| Step: 6
Training loss: 2.6406426062363777
Validation loss: 2.395516196328051

Epoch: 6| Step: 7
Training loss: 2.532220724961937
Validation loss: 2.391578707135691

Epoch: 6| Step: 8
Training loss: 2.719442082153929
Validation loss: 2.4026258109456884

Epoch: 6| Step: 9
Training loss: 1.4758907990313115
Validation loss: 2.397088739983502

Epoch: 6| Step: 10
Training loss: 2.4077267759635124
Validation loss: 2.4014652028036956

Epoch: 6| Step: 11
Training loss: 2.74863608089099
Validation loss: 2.4062352514966956

Epoch: 6| Step: 12
Training loss: 3.1268594931523532
Validation loss: 2.4166704806537114

Epoch: 6| Step: 13
Training loss: 2.725141707069267
Validation loss: 2.444942581234328

Epoch: 164| Step: 0
Training loss: 2.993059076207316
Validation loss: 2.4914807255371776

Epoch: 6| Step: 1
Training loss: 2.5592951388353034
Validation loss: 2.500073174974656

Epoch: 6| Step: 2
Training loss: 2.666465682164572
Validation loss: 2.4634386495622356

Epoch: 6| Step: 3
Training loss: 2.6601892320826126
Validation loss: 2.4340805604182107

Epoch: 6| Step: 4
Training loss: 2.114837693824735
Validation loss: 2.3908492504647967

Epoch: 6| Step: 5
Training loss: 2.6172423399688247
Validation loss: 2.379983776452932

Epoch: 6| Step: 6
Training loss: 2.738790902720703
Validation loss: 2.37001741441326

Epoch: 6| Step: 7
Training loss: 2.290067068225609
Validation loss: 2.3976588424054706

Epoch: 6| Step: 8
Training loss: 2.298225057963911
Validation loss: 2.4049847177726003

Epoch: 6| Step: 9
Training loss: 2.817174037027376
Validation loss: 2.3725130761740973

Epoch: 6| Step: 10
Training loss: 2.634872762369552
Validation loss: 2.3869068814163206

Epoch: 6| Step: 11
Training loss: 2.900096326083243
Validation loss: 2.412553945026778

Epoch: 6| Step: 12
Training loss: 2.5312669541532906
Validation loss: 2.4739844460180596

Epoch: 6| Step: 13
Training loss: 2.298404729156993
Validation loss: 2.5052637583536135

Epoch: 165| Step: 0
Training loss: 3.240830323530235
Validation loss: 2.519568220844902

Epoch: 6| Step: 1
Training loss: 2.9543086510574503
Validation loss: 2.5084453299658978

Epoch: 6| Step: 2
Training loss: 2.7115971974589237
Validation loss: 2.4663845062453755

Epoch: 6| Step: 3
Training loss: 2.5249746264703035
Validation loss: 2.3995901068390033

Epoch: 6| Step: 4
Training loss: 2.3574950958233307
Validation loss: 2.3752366850983724

Epoch: 6| Step: 5
Training loss: 2.4792287054767774
Validation loss: 2.3906294235326904

Epoch: 6| Step: 6
Training loss: 2.8702806631948476
Validation loss: 2.3954611412027345

Epoch: 6| Step: 7
Training loss: 2.446001144795684
Validation loss: 2.377952284321384

Epoch: 6| Step: 8
Training loss: 2.1617033179986533
Validation loss: 2.3825093491229254

Epoch: 6| Step: 9
Training loss: 2.5643688923118946
Validation loss: 2.385224164012664

Epoch: 6| Step: 10
Training loss: 2.041229499671904
Validation loss: 2.39893617663632

Epoch: 6| Step: 11
Training loss: 2.605144978184677
Validation loss: 2.3967436824270316

Epoch: 6| Step: 12
Training loss: 2.2722719750816482
Validation loss: 2.4243683195151498

Epoch: 6| Step: 13
Training loss: 2.6487944145853457
Validation loss: 2.4373878661457584

Epoch: 166| Step: 0
Training loss: 2.187357870661704
Validation loss: 2.4386146506278443

Epoch: 6| Step: 1
Training loss: 1.933340714977686
Validation loss: 2.425059506771181

Epoch: 6| Step: 2
Training loss: 2.860640449040481
Validation loss: 2.4183690210633033

Epoch: 6| Step: 3
Training loss: 2.2901718003574727
Validation loss: 2.4024171639426783

Epoch: 6| Step: 4
Training loss: 2.2266843528197446
Validation loss: 2.3949621504376966

Epoch: 6| Step: 5
Training loss: 2.935845091514058
Validation loss: 2.386919661419803

Epoch: 6| Step: 6
Training loss: 2.6974264949085396
Validation loss: 2.4055465609722173

Epoch: 6| Step: 7
Training loss: 2.4134806206405046
Validation loss: 2.3962796491498213

Epoch: 6| Step: 8
Training loss: 2.8795369051439397
Validation loss: 2.4113246622252724

Epoch: 6| Step: 9
Training loss: 2.3820596474931284
Validation loss: 2.3985228517146933

Epoch: 6| Step: 10
Training loss: 2.766757022194186
Validation loss: 2.388620846812651

Epoch: 6| Step: 11
Training loss: 2.3172280717668845
Validation loss: 2.3823410667916587

Epoch: 6| Step: 12
Training loss: 2.7335283112958617
Validation loss: 2.3838099992252766

Epoch: 6| Step: 13
Training loss: 2.321436035228091
Validation loss: 2.3933904980132077

Epoch: 167| Step: 0
Training loss: 2.7513540575661013
Validation loss: 2.430521569392844

Epoch: 6| Step: 1
Training loss: 2.368520028014944
Validation loss: 2.4449310796798582

Epoch: 6| Step: 2
Training loss: 2.2673198805898496
Validation loss: 2.4507482868900876

Epoch: 6| Step: 3
Training loss: 2.68493592127199
Validation loss: 2.4255400163471754

Epoch: 6| Step: 4
Training loss: 2.4625798633618077
Validation loss: 2.4001355808640366

Epoch: 6| Step: 5
Training loss: 2.5672445336180667
Validation loss: 2.3714218722166516

Epoch: 6| Step: 6
Training loss: 2.7762273806252082
Validation loss: 2.368045474467126

Epoch: 6| Step: 7
Training loss: 2.8232434542272755
Validation loss: 2.3738476127642354

Epoch: 6| Step: 8
Training loss: 2.5845169821764467
Validation loss: 2.354892671763005

Epoch: 6| Step: 9
Training loss: 2.151554025094511
Validation loss: 2.3423187854669996

Epoch: 6| Step: 10
Training loss: 2.2109060116739596
Validation loss: 2.3597230329268335

Epoch: 6| Step: 11
Training loss: 2.64045461974022
Validation loss: 2.382539387259339

Epoch: 6| Step: 12
Training loss: 2.427460266008096
Validation loss: 2.3708415269200973

Epoch: 6| Step: 13
Training loss: 2.7803354366934663
Validation loss: 2.379942841590171

Epoch: 168| Step: 0
Training loss: 2.6238355324421825
Validation loss: 2.388923559114525

Epoch: 6| Step: 1
Training loss: 2.480376474661596
Validation loss: 2.4063775687035047

Epoch: 6| Step: 2
Training loss: 2.4108960764324583
Validation loss: 2.452837156222284

Epoch: 6| Step: 3
Training loss: 2.736435642349229
Validation loss: 2.4651614185422352

Epoch: 6| Step: 4
Training loss: 2.7171263834313666
Validation loss: 2.4516362065072346

Epoch: 6| Step: 5
Training loss: 2.9080601459144306
Validation loss: 2.4403988050760357

Epoch: 6| Step: 6
Training loss: 2.0145067765194593
Validation loss: 2.410866100242482

Epoch: 6| Step: 7
Training loss: 1.9757372675141147
Validation loss: 2.3950662769812854

Epoch: 6| Step: 8
Training loss: 2.8863216225058705
Validation loss: 2.408107413049205

Epoch: 6| Step: 9
Training loss: 2.9701502659863968
Validation loss: 2.3827665903183077

Epoch: 6| Step: 10
Training loss: 2.5047849639758053
Validation loss: 2.3810848724986635

Epoch: 6| Step: 11
Training loss: 2.3875349431701305
Validation loss: 2.4307833217269703

Epoch: 6| Step: 12
Training loss: 2.379550790147297
Validation loss: 2.4381436491262627

Epoch: 6| Step: 13
Training loss: 1.6009069822501434
Validation loss: 2.4412675930887784

Epoch: 169| Step: 0
Training loss: 2.5198180515967965
Validation loss: 2.4399599389096385

Epoch: 6| Step: 1
Training loss: 2.4283991399927807
Validation loss: 2.4363086251049513

Epoch: 6| Step: 2
Training loss: 2.5600857410377573
Validation loss: 2.4617584760278812

Epoch: 6| Step: 3
Training loss: 2.6018027804649333
Validation loss: 2.4742090283214555

Epoch: 6| Step: 4
Training loss: 2.951327952834226
Validation loss: 2.4633472598935207

Epoch: 6| Step: 5
Training loss: 2.407352046520203
Validation loss: 2.437447767431647

Epoch: 6| Step: 6
Training loss: 2.383565714873488
Validation loss: 2.4479431807199847

Epoch: 6| Step: 7
Training loss: 2.7584730875466663
Validation loss: 2.4455912457133557

Epoch: 6| Step: 8
Training loss: 2.7099379749871746
Validation loss: 2.4517910033454364

Epoch: 6| Step: 9
Training loss: 1.9604562723643344
Validation loss: 2.4720508724913297

Epoch: 6| Step: 10
Training loss: 2.373004878422111
Validation loss: 2.502403842759149

Epoch: 6| Step: 11
Training loss: 3.033215387028499
Validation loss: 2.519590556731392

Epoch: 6| Step: 12
Training loss: 2.519415043952919
Validation loss: 2.496350101541672

Epoch: 6| Step: 13
Training loss: 2.3883532532284732
Validation loss: 2.48806533189622

Epoch: 170| Step: 0
Training loss: 2.531787956434673
Validation loss: 2.5028489533193543

Epoch: 6| Step: 1
Training loss: 2.605609117927562
Validation loss: 2.5012643744443017

Epoch: 6| Step: 2
Training loss: 2.5252454204074053
Validation loss: 2.505345473800619

Epoch: 6| Step: 3
Training loss: 2.850249523817601
Validation loss: 2.509022611876739

Epoch: 6| Step: 4
Training loss: 2.6473027051513047
Validation loss: 2.4891858103813918

Epoch: 6| Step: 5
Training loss: 3.082943316012491
Validation loss: 2.488822070623614

Epoch: 6| Step: 6
Training loss: 2.507738344040871
Validation loss: 2.471860291631058

Epoch: 6| Step: 7
Training loss: 1.8641131001692945
Validation loss: 2.4380799869016143

Epoch: 6| Step: 8
Training loss: 1.829712203174232
Validation loss: 2.4310083633359105

Epoch: 6| Step: 9
Training loss: 2.9066775427915212
Validation loss: 2.433008835044557

Epoch: 6| Step: 10
Training loss: 2.230410707055913
Validation loss: 2.4254445284885513

Epoch: 6| Step: 11
Training loss: 2.250167416595921
Validation loss: 2.413085991681937

Epoch: 6| Step: 12
Training loss: 2.5765392628599866
Validation loss: 2.4013894826420232

Epoch: 6| Step: 13
Training loss: 3.0553850319028975
Validation loss: 2.4082609450684536

Epoch: 171| Step: 0
Training loss: 2.6092574955415095
Validation loss: 2.3930961227959706

Epoch: 6| Step: 1
Training loss: 2.711316524690193
Validation loss: 2.386348641358268

Epoch: 6| Step: 2
Training loss: 2.8862015153687546
Validation loss: 2.3807032617571817

Epoch: 6| Step: 3
Training loss: 1.8535058490587821
Validation loss: 2.3847637953367453

Epoch: 6| Step: 4
Training loss: 1.923983835802759
Validation loss: 2.3644056240311535

Epoch: 6| Step: 5
Training loss: 2.4689638069376922
Validation loss: 2.375928713394843

Epoch: 6| Step: 6
Training loss: 2.4774744899756738
Validation loss: 2.377593973272697

Epoch: 6| Step: 7
Training loss: 3.243001297999007
Validation loss: 2.369900321610597

Epoch: 6| Step: 8
Training loss: 2.1973718507308955
Validation loss: 2.37887132293932

Epoch: 6| Step: 9
Training loss: 2.4422707453797567
Validation loss: 2.393254803515944

Epoch: 6| Step: 10
Training loss: 2.5422816131934027
Validation loss: 2.396809067245596

Epoch: 6| Step: 11
Training loss: 2.3068806186670643
Validation loss: 2.4006964947240537

Epoch: 6| Step: 12
Training loss: 2.4439228240656483
Validation loss: 2.408906035171102

Epoch: 6| Step: 13
Training loss: 2.2744100790943005
Validation loss: 2.4206203268566764

Epoch: 172| Step: 0
Training loss: 2.6853460507298514
Validation loss: 2.4145414500736027

Epoch: 6| Step: 1
Training loss: 2.293406248190294
Validation loss: 2.4060253682499595

Epoch: 6| Step: 2
Training loss: 1.5784346777105844
Validation loss: 2.410794973620946

Epoch: 6| Step: 3
Training loss: 2.7140753886828755
Validation loss: 2.4181909534766497

Epoch: 6| Step: 4
Training loss: 2.801857202946925
Validation loss: 2.42876970593018

Epoch: 6| Step: 5
Training loss: 2.4213395049685893
Validation loss: 2.4272761380336743

Epoch: 6| Step: 6
Training loss: 2.2426663728064407
Validation loss: 2.416082479909968

Epoch: 6| Step: 7
Training loss: 2.7041484681287575
Validation loss: 2.420732454265165

Epoch: 6| Step: 8
Training loss: 1.9776109771838968
Validation loss: 2.4240551924546216

Epoch: 6| Step: 9
Training loss: 2.07668271603003
Validation loss: 2.428837205115685

Epoch: 6| Step: 10
Training loss: 2.29549652047497
Validation loss: 2.39492366761528

Epoch: 6| Step: 11
Training loss: 3.146854125543663
Validation loss: 2.3811196163587818

Epoch: 6| Step: 12
Training loss: 2.6343407426192758
Validation loss: 2.372275907526956

Epoch: 6| Step: 13
Training loss: 2.9866516057838175
Validation loss: 2.384735982562404

Epoch: 173| Step: 0
Training loss: 2.596898202069465
Validation loss: 2.401939159398585

Epoch: 6| Step: 1
Training loss: 2.657348674868972
Validation loss: 2.3980935847466274

Epoch: 6| Step: 2
Training loss: 2.215218971399342
Validation loss: 2.4137377484841553

Epoch: 6| Step: 3
Training loss: 2.589410483825915
Validation loss: 2.4245067036345036

Epoch: 6| Step: 4
Training loss: 2.1546421414166113
Validation loss: 2.4432899885789117

Epoch: 6| Step: 5
Training loss: 2.32555539460396
Validation loss: 2.451932821330383

Epoch: 6| Step: 6
Training loss: 2.428270914414012
Validation loss: 2.4526178554106854

Epoch: 6| Step: 7
Training loss: 2.6542678618091027
Validation loss: 2.454831213130686

Epoch: 6| Step: 8
Training loss: 2.5488940701777993
Validation loss: 2.496008059799756

Epoch: 6| Step: 9
Training loss: 2.340893034109751
Validation loss: 2.4710447280907304

Epoch: 6| Step: 10
Training loss: 3.028927414657565
Validation loss: 2.475544440857393

Epoch: 6| Step: 11
Training loss: 2.2283264668296336
Validation loss: 2.435559832390638

Epoch: 6| Step: 12
Training loss: 1.7652595614455406
Validation loss: 2.3852795478504834

Epoch: 6| Step: 13
Training loss: 2.8687590156363645
Validation loss: 2.3649567260508593

Epoch: 174| Step: 0
Training loss: 2.2020745986096375
Validation loss: 2.34594083164602

Epoch: 6| Step: 1
Training loss: 3.1144165878994734
Validation loss: 2.342435748054714

Epoch: 6| Step: 2
Training loss: 2.193571982265874
Validation loss: 2.350853926029169

Epoch: 6| Step: 3
Training loss: 2.074535051212907
Validation loss: 2.3380832631647537

Epoch: 6| Step: 4
Training loss: 2.356091975167094
Validation loss: 2.3471983275540587

Epoch: 6| Step: 5
Training loss: 2.830719490116616
Validation loss: 2.352338788200543

Epoch: 6| Step: 6
Training loss: 2.490938070764023
Validation loss: 2.38089108569855

Epoch: 6| Step: 7
Training loss: 2.4141294599709253
Validation loss: 2.388469580388676

Epoch: 6| Step: 8
Training loss: 2.3037852444697875
Validation loss: 2.4171940327480694

Epoch: 6| Step: 9
Training loss: 2.412630217995833
Validation loss: 2.4215457677924057

Epoch: 6| Step: 10
Training loss: 2.7449782209800473
Validation loss: 2.4287732651766034

Epoch: 6| Step: 11
Training loss: 1.171445131932476
Validation loss: 2.412403568247156

Epoch: 6| Step: 12
Training loss: 3.036946400872505
Validation loss: 2.4129270697660874

Epoch: 6| Step: 13
Training loss: 2.4475359573294635
Validation loss: 2.4042137062770004

Epoch: 175| Step: 0
Training loss: 1.6889286351685742
Validation loss: 2.3980206905700765

Epoch: 6| Step: 1
Training loss: 1.9941497115059876
Validation loss: 2.3735594101726827

Epoch: 6| Step: 2
Training loss: 1.832287280446308
Validation loss: 2.3689973401657287

Epoch: 6| Step: 3
Training loss: 2.3641670521612688
Validation loss: 2.3595137419175534

Epoch: 6| Step: 4
Training loss: 2.648784063389338
Validation loss: 2.356172693757371

Epoch: 6| Step: 5
Training loss: 2.9312791900157404
Validation loss: 2.3568139174217233

Epoch: 6| Step: 6
Training loss: 2.571493509396041
Validation loss: 2.4069686251250526

Epoch: 6| Step: 7
Training loss: 2.7505658174513097
Validation loss: 2.4289607990530526

Epoch: 6| Step: 8
Training loss: 2.33094678036926
Validation loss: 2.4548757949432254

Epoch: 6| Step: 9
Training loss: 2.9629858978584767
Validation loss: 2.4318464041621213

Epoch: 6| Step: 10
Training loss: 2.703012982291073
Validation loss: 2.4380778397380634

Epoch: 6| Step: 11
Training loss: 2.519693910537848
Validation loss: 2.4647925441307486

Epoch: 6| Step: 12
Training loss: 2.34788656771124
Validation loss: 2.5077842976860163

Epoch: 6| Step: 13
Training loss: 2.788438144757723
Validation loss: 2.5735777129068755

Epoch: 176| Step: 0
Training loss: 2.618760458986796
Validation loss: 2.632385041987334

Epoch: 6| Step: 1
Training loss: 2.575242251509784
Validation loss: 2.699209704362508

Epoch: 6| Step: 2
Training loss: 2.4125750752364876
Validation loss: 2.5906666925733544

Epoch: 6| Step: 3
Training loss: 2.857817011725867
Validation loss: 2.4782377905244357

Epoch: 6| Step: 4
Training loss: 2.390808597071972
Validation loss: 2.3692117436944393

Epoch: 6| Step: 5
Training loss: 2.8891916381296654
Validation loss: 2.334334582385938

Epoch: 6| Step: 6
Training loss: 1.8140461345134833
Validation loss: 2.322033443887606

Epoch: 6| Step: 7
Training loss: 2.8581813968355467
Validation loss: 2.3788303635450347

Epoch: 6| Step: 8
Training loss: 2.8621527515329976
Validation loss: 2.3833793333080404

Epoch: 6| Step: 9
Training loss: 2.6930831756495746
Validation loss: 2.4099804828486486

Epoch: 6| Step: 10
Training loss: 2.6022176748088164
Validation loss: 2.3955503905702304

Epoch: 6| Step: 11
Training loss: 2.477167482820965
Validation loss: 2.3875462401772767

Epoch: 6| Step: 12
Training loss: 2.268186502387543
Validation loss: 2.402753769454717

Epoch: 6| Step: 13
Training loss: 2.022855343529222
Validation loss: 2.437618430483902

Epoch: 177| Step: 0
Training loss: 2.2854350123774645
Validation loss: 2.492421202031017

Epoch: 6| Step: 1
Training loss: 2.6940646171495133
Validation loss: 2.531863174904377

Epoch: 6| Step: 2
Training loss: 2.8280417920090666
Validation loss: 2.513886369815624

Epoch: 6| Step: 3
Training loss: 2.5573017148651136
Validation loss: 2.446759972316139

Epoch: 6| Step: 4
Training loss: 2.638717775206811
Validation loss: 2.405266785572996

Epoch: 6| Step: 5
Training loss: 2.2964668170733376
Validation loss: 2.3665965663344175

Epoch: 6| Step: 6
Training loss: 2.4865093539729584
Validation loss: 2.355551886471833

Epoch: 6| Step: 7
Training loss: 2.013380708558119
Validation loss: 2.3419790729637078

Epoch: 6| Step: 8
Training loss: 2.7758718203652966
Validation loss: 2.335836652191497

Epoch: 6| Step: 9
Training loss: 2.5330770044982396
Validation loss: 2.3621318986778603

Epoch: 6| Step: 10
Training loss: 2.637983999092446
Validation loss: 2.375608025284261

Epoch: 6| Step: 11
Training loss: 2.3764846578335947
Validation loss: 2.401278086000616

Epoch: 6| Step: 12
Training loss: 2.1874856130944305
Validation loss: 2.412016222249737

Epoch: 6| Step: 13
Training loss: 3.096113900930749
Validation loss: 2.433680794042326

Epoch: 178| Step: 0
Training loss: 2.761857737452505
Validation loss: 2.459919562878457

Epoch: 6| Step: 1
Training loss: 2.2463597413832717
Validation loss: 2.491044692236827

Epoch: 6| Step: 2
Training loss: 2.602423906194092
Validation loss: 2.5316003931400695

Epoch: 6| Step: 3
Training loss: 2.750968415800415
Validation loss: 2.5442545566350345

Epoch: 6| Step: 4
Training loss: 2.16842948897801
Validation loss: 2.555849464660602

Epoch: 6| Step: 5
Training loss: 3.148180021070644
Validation loss: 2.5745716963740977

Epoch: 6| Step: 6
Training loss: 2.0731052204300595
Validation loss: 2.5351764898027715

Epoch: 6| Step: 7
Training loss: 2.817054620995287
Validation loss: 2.493371735179969

Epoch: 6| Step: 8
Training loss: 2.2166741559851
Validation loss: 2.4424515513628773

Epoch: 6| Step: 9
Training loss: 2.599389987690471
Validation loss: 2.3943846311625596

Epoch: 6| Step: 10
Training loss: 2.0399443959156667
Validation loss: 2.362776314417124

Epoch: 6| Step: 11
Training loss: 2.6404380957915903
Validation loss: 2.3425796310238653

Epoch: 6| Step: 12
Training loss: 2.4342354652462137
Validation loss: 2.361509114604165

Epoch: 6| Step: 13
Training loss: 1.8516161947069973
Validation loss: 2.3823267341535606

Epoch: 179| Step: 0
Training loss: 2.247313272868545
Validation loss: 2.395997691747602

Epoch: 6| Step: 1
Training loss: 2.521482483902273
Validation loss: 2.4366158963726283

Epoch: 6| Step: 2
Training loss: 2.55629929026344
Validation loss: 2.4993888846385

Epoch: 6| Step: 3
Training loss: 2.537440136734218
Validation loss: 2.498287851337368

Epoch: 6| Step: 4
Training loss: 2.7596222124140515
Validation loss: 2.5056792299255135

Epoch: 6| Step: 5
Training loss: 2.821688583147707
Validation loss: 2.5036826123523914

Epoch: 6| Step: 6
Training loss: 1.9045946406822507
Validation loss: 2.4714100729151784

Epoch: 6| Step: 7
Training loss: 2.0885632165826022
Validation loss: 2.4450412067563216

Epoch: 6| Step: 8
Training loss: 2.127807221514659
Validation loss: 2.3590224948788374

Epoch: 6| Step: 9
Training loss: 2.9155179804452103
Validation loss: 2.328978580863666

Epoch: 6| Step: 10
Training loss: 2.8774536277554175
Validation loss: 2.302464556937696

Epoch: 6| Step: 11
Training loss: 2.2989115088159027
Validation loss: 2.3076735262728363

Epoch: 6| Step: 12
Training loss: 2.0193443580789103
Validation loss: 2.3073986816329413

Epoch: 6| Step: 13
Training loss: 2.278945699670064
Validation loss: 2.3339172460721276

Epoch: 180| Step: 0
Training loss: 1.8880273297077532
Validation loss: 2.3319673018773286

Epoch: 6| Step: 1
Training loss: 2.5369940680891974
Validation loss: 2.369385072232702

Epoch: 6| Step: 2
Training loss: 2.2873806031132062
Validation loss: 2.372020190607075

Epoch: 6| Step: 3
Training loss: 1.9982648713784923
Validation loss: 2.400495050587692

Epoch: 6| Step: 4
Training loss: 2.93096879533434
Validation loss: 2.442655286801771

Epoch: 6| Step: 5
Training loss: 1.9887341056682504
Validation loss: 2.4687765153006405

Epoch: 6| Step: 6
Training loss: 3.0160357734116854
Validation loss: 2.481170343717924

Epoch: 6| Step: 7
Training loss: 2.145453249654687
Validation loss: 2.519381342341924

Epoch: 6| Step: 8
Training loss: 2.053695613352243
Validation loss: 2.4982309871137884

Epoch: 6| Step: 9
Training loss: 2.1538421898061304
Validation loss: 2.447048791810635

Epoch: 6| Step: 10
Training loss: 2.436616786475818
Validation loss: 2.4201996776822257

Epoch: 6| Step: 11
Training loss: 2.4537175914549993
Validation loss: 2.3890018710269865

Epoch: 6| Step: 12
Training loss: 3.1098019100775334
Validation loss: 2.3700317008828176

Epoch: 6| Step: 13
Training loss: 2.4999347678257107
Validation loss: 2.3480780216847172

Epoch: 181| Step: 0
Training loss: 1.9637127573232105
Validation loss: 2.348800913292918

Epoch: 6| Step: 1
Training loss: 2.5155671865323925
Validation loss: 2.3457334956584486

Epoch: 6| Step: 2
Training loss: 2.3323516370029567
Validation loss: 2.3211013979209105

Epoch: 6| Step: 3
Training loss: 2.1530625377171004
Validation loss: 2.324206839648399

Epoch: 6| Step: 4
Training loss: 2.501020223347419
Validation loss: 2.318237976046717

Epoch: 6| Step: 5
Training loss: 1.9952293360741475
Validation loss: 2.3391051285171605

Epoch: 6| Step: 6
Training loss: 2.4362461092796983
Validation loss: 2.3617698903330355

Epoch: 6| Step: 7
Training loss: 2.450038255665334
Validation loss: 2.3758386136311245

Epoch: 6| Step: 8
Training loss: 2.585201746522106
Validation loss: 2.4081469355294165

Epoch: 6| Step: 9
Training loss: 2.779040970216496
Validation loss: 2.4018283208690825

Epoch: 6| Step: 10
Training loss: 2.290304114125603
Validation loss: 2.3880808428608296

Epoch: 6| Step: 11
Training loss: 2.3027281627619764
Validation loss: 2.382588129021968

Epoch: 6| Step: 12
Training loss: 2.7768853046604676
Validation loss: 2.3870124016608916

Epoch: 6| Step: 13
Training loss: 2.818948431706426
Validation loss: 2.419584109473376

Epoch: 182| Step: 0
Training loss: 2.1407008470895077
Validation loss: 2.4229235667941453

Epoch: 6| Step: 1
Training loss: 2.38045087005741
Validation loss: 2.4338021374911514

Epoch: 6| Step: 2
Training loss: 2.1824572613388793
Validation loss: 2.4257407117407603

Epoch: 6| Step: 3
Training loss: 2.332943225220462
Validation loss: 2.420743934178423

Epoch: 6| Step: 4
Training loss: 1.7695180458771984
Validation loss: 2.3985677918011623

Epoch: 6| Step: 5
Training loss: 2.3994108828072136
Validation loss: 2.393014373151009

Epoch: 6| Step: 6
Training loss: 2.2536625193175137
Validation loss: 2.4027441774708818

Epoch: 6| Step: 7
Training loss: 2.804271273955087
Validation loss: 2.4110815653584723

Epoch: 6| Step: 8
Training loss: 2.042903629235184
Validation loss: 2.386127705740184

Epoch: 6| Step: 9
Training loss: 2.2312117372966624
Validation loss: 2.376676141772672

Epoch: 6| Step: 10
Training loss: 2.1852211117110945
Validation loss: 2.361387456525819

Epoch: 6| Step: 11
Training loss: 3.2855571270906214
Validation loss: 2.3567097270420025

Epoch: 6| Step: 12
Training loss: 2.859844398533893
Validation loss: 2.3898665289093666

Epoch: 6| Step: 13
Training loss: 2.438929212155264
Validation loss: 2.3962984141051975

Epoch: 183| Step: 0
Training loss: 2.225875373689915
Validation loss: 2.3671105003173056

Epoch: 6| Step: 1
Training loss: 2.295265931656174
Validation loss: 2.36903534974463

Epoch: 6| Step: 2
Training loss: 2.2759134240469967
Validation loss: 2.3882384124900455

Epoch: 6| Step: 3
Training loss: 2.644654489460169
Validation loss: 2.3994604282673198

Epoch: 6| Step: 4
Training loss: 2.270219235693503
Validation loss: 2.410325426993073

Epoch: 6| Step: 5
Training loss: 1.6502754848426981
Validation loss: 2.4221612449532914

Epoch: 6| Step: 6
Training loss: 2.354070093205201
Validation loss: 2.413075898947135

Epoch: 6| Step: 7
Training loss: 2.7252625260190766
Validation loss: 2.3991192840749442

Epoch: 6| Step: 8
Training loss: 1.6517099016974
Validation loss: 2.375834499222784

Epoch: 6| Step: 9
Training loss: 2.3174276689190076
Validation loss: 2.377197803087446

Epoch: 6| Step: 10
Training loss: 2.8320288927791912
Validation loss: 2.3768345839523404

Epoch: 6| Step: 11
Training loss: 2.8128942425236687
Validation loss: 2.4018208481967624

Epoch: 6| Step: 12
Training loss: 1.8697982476277126
Validation loss: 2.4022579518945912

Epoch: 6| Step: 13
Training loss: 3.005947257994837
Validation loss: 2.4186134939934725

Epoch: 184| Step: 0
Training loss: 2.7141451368999623
Validation loss: 2.455504688186843

Epoch: 6| Step: 1
Training loss: 2.4598767128731067
Validation loss: 2.482133825101657

Epoch: 6| Step: 2
Training loss: 1.6997053480044093
Validation loss: 2.4639295903765976

Epoch: 6| Step: 3
Training loss: 2.4139066479196343
Validation loss: 2.4469886928655344

Epoch: 6| Step: 4
Training loss: 2.3658835467574533
Validation loss: 2.418606353807674

Epoch: 6| Step: 5
Training loss: 1.8377165271054678
Validation loss: 2.3954702625644466

Epoch: 6| Step: 6
Training loss: 2.5642854936465294
Validation loss: 2.3925371795291515

Epoch: 6| Step: 7
Training loss: 2.6079480501102728
Validation loss: 2.3624419974855875

Epoch: 6| Step: 8
Training loss: 2.020405504486011
Validation loss: 2.3628654768502706

Epoch: 6| Step: 9
Training loss: 2.611519668846843
Validation loss: 2.3330550320806434

Epoch: 6| Step: 10
Training loss: 2.8728115211002967
Validation loss: 2.3287165445597258

Epoch: 6| Step: 11
Training loss: 2.4289575197754147
Validation loss: 2.344053865375689

Epoch: 6| Step: 12
Training loss: 1.7460701960056682
Validation loss: 2.352249397860625

Epoch: 6| Step: 13
Training loss: 2.993673329177894
Validation loss: 2.348667964382729

Epoch: 185| Step: 0
Training loss: 2.169422329073416
Validation loss: 2.3622408361264973

Epoch: 6| Step: 1
Training loss: 2.9880000761305303
Validation loss: 2.3350627459055264

Epoch: 6| Step: 2
Training loss: 2.0773584773476634
Validation loss: 2.355482680110289

Epoch: 6| Step: 3
Training loss: 2.905445438711018
Validation loss: 2.3604618669408906

Epoch: 6| Step: 4
Training loss: 2.474716316688338
Validation loss: 2.3735133150324836

Epoch: 6| Step: 5
Training loss: 2.0082581021898025
Validation loss: 2.37132591355287

Epoch: 6| Step: 6
Training loss: 2.6997525560939364
Validation loss: 2.3848642624118512

Epoch: 6| Step: 7
Training loss: 2.353626245455276
Validation loss: 2.394730506093895

Epoch: 6| Step: 8
Training loss: 1.5013809999456103
Validation loss: 2.397645042927134

Epoch: 6| Step: 9
Training loss: 1.8281763183694162
Validation loss: 2.4378736802198127

Epoch: 6| Step: 10
Training loss: 2.1333676688093512
Validation loss: 2.455828430391804

Epoch: 6| Step: 11
Training loss: 2.7965711716302097
Validation loss: 2.509973072116244

Epoch: 6| Step: 12
Training loss: 1.9594405946596707
Validation loss: 2.5145881150032636

Epoch: 6| Step: 13
Training loss: 2.363534154049223
Validation loss: 2.5239567706373975

Epoch: 186| Step: 0
Training loss: 2.397897168656616
Validation loss: 2.4706513339390255

Epoch: 6| Step: 1
Training loss: 2.2003798460328143
Validation loss: 2.398114716224354

Epoch: 6| Step: 2
Training loss: 2.339733496919871
Validation loss: 2.3707632639425533

Epoch: 6| Step: 3
Training loss: 2.2534455302858083
Validation loss: 2.33709624074251

Epoch: 6| Step: 4
Training loss: 1.9327927288502855
Validation loss: 2.3097739344209667

Epoch: 6| Step: 5
Training loss: 1.9292774459747237
Validation loss: 2.3050452703944964

Epoch: 6| Step: 6
Training loss: 2.716371833466948
Validation loss: 2.3063145815414163

Epoch: 6| Step: 7
Training loss: 2.7162817789633444
Validation loss: 2.295656066203497

Epoch: 6| Step: 8
Training loss: 2.3905599747335042
Validation loss: 2.2916833459316135

Epoch: 6| Step: 9
Training loss: 2.491492865209069
Validation loss: 2.3145711105566087

Epoch: 6| Step: 10
Training loss: 2.4377337612643646
Validation loss: 2.317980980998874

Epoch: 6| Step: 11
Training loss: 2.373864554985191
Validation loss: 2.350717621923684

Epoch: 6| Step: 12
Training loss: 1.9504973779820605
Validation loss: 2.360143970681686

Epoch: 6| Step: 13
Training loss: 2.8198623932075084
Validation loss: 2.385555093691797

Epoch: 187| Step: 0
Training loss: 1.6082073531281709
Validation loss: 2.4250883032424007

Epoch: 6| Step: 1
Training loss: 1.6390416815847508
Validation loss: 2.479942709770152

Epoch: 6| Step: 2
Training loss: 1.8576149183333055
Validation loss: 2.511935193533747

Epoch: 6| Step: 3
Training loss: 2.090790892264404
Validation loss: 2.539047221476209

Epoch: 6| Step: 4
Training loss: 2.150329866165932
Validation loss: 2.5677766159141617

Epoch: 6| Step: 5
Training loss: 2.558877198338036
Validation loss: 2.55783454899097

Epoch: 6| Step: 6
Training loss: 2.652265904313717
Validation loss: 2.543410014152114

Epoch: 6| Step: 7
Training loss: 2.3666247211912093
Validation loss: 2.5148427433999614

Epoch: 6| Step: 8
Training loss: 2.371543175526482
Validation loss: 2.473721864513962

Epoch: 6| Step: 9
Training loss: 2.9931849318705575
Validation loss: 2.4085934130622593

Epoch: 6| Step: 10
Training loss: 2.775868814226927
Validation loss: 2.3787096290757255

Epoch: 6| Step: 11
Training loss: 2.4701557261685827
Validation loss: 2.3581040035389864

Epoch: 6| Step: 12
Training loss: 2.3315928189206168
Validation loss: 2.374073384278579

Epoch: 6| Step: 13
Training loss: 1.8643266156600347
Validation loss: 2.375837593392322

Epoch: 188| Step: 0
Training loss: 1.9038610028011658
Validation loss: 2.3800028099225465

Epoch: 6| Step: 1
Training loss: 1.8805037783255398
Validation loss: 2.3841484597316773

Epoch: 6| Step: 2
Training loss: 2.183965497795866
Validation loss: 2.3916814353063556

Epoch: 6| Step: 3
Training loss: 1.9717981870655872
Validation loss: 2.40084022355117

Epoch: 6| Step: 4
Training loss: 2.1361821981153484
Validation loss: 2.4086948051829524

Epoch: 6| Step: 5
Training loss: 1.887924977642561
Validation loss: 2.3966113820553314

Epoch: 6| Step: 6
Training loss: 2.1818453044722728
Validation loss: 2.404043079725074

Epoch: 6| Step: 7
Training loss: 2.559507902651475
Validation loss: 2.422049607602805

Epoch: 6| Step: 8
Training loss: 2.690577497074045
Validation loss: 2.4336724958655127

Epoch: 6| Step: 9
Training loss: 2.7049485599047824
Validation loss: 2.4518562057459157

Epoch: 6| Step: 10
Training loss: 2.631849797766147
Validation loss: 2.4390183929106506

Epoch: 6| Step: 11
Training loss: 2.2730684275768147
Validation loss: 2.4391786523420067

Epoch: 6| Step: 12
Training loss: 2.0579615279031795
Validation loss: 2.4196674703462686

Epoch: 6| Step: 13
Training loss: 2.8476800276570735
Validation loss: 2.426617771327924

Epoch: 189| Step: 0
Training loss: 2.0069144648945745
Validation loss: 2.4136589316421824

Epoch: 6| Step: 1
Training loss: 1.7756567693632261
Validation loss: 2.40335269753203

Epoch: 6| Step: 2
Training loss: 2.1956816122008633
Validation loss: 2.4142825431932233

Epoch: 6| Step: 3
Training loss: 2.5970212231908336
Validation loss: 2.4342826811329195

Epoch: 6| Step: 4
Training loss: 2.314791600711416
Validation loss: 2.402439307416534

Epoch: 6| Step: 5
Training loss: 2.011653802804764
Validation loss: 2.4023437286571707

Epoch: 6| Step: 6
Training loss: 2.260329272665361
Validation loss: 2.3965749619095438

Epoch: 6| Step: 7
Training loss: 2.3326251681026084
Validation loss: 2.4043878360973117

Epoch: 6| Step: 8
Training loss: 2.1033882237127126
Validation loss: 2.4135214444890196

Epoch: 6| Step: 9
Training loss: 2.444346861866319
Validation loss: 2.4426089076193263

Epoch: 6| Step: 10
Training loss: 1.9525046011739873
Validation loss: 2.3976795778274522

Epoch: 6| Step: 11
Training loss: 2.666078939838832
Validation loss: 2.4198310835879826

Epoch: 6| Step: 12
Training loss: 2.38247458141173
Validation loss: 2.4083075950528285

Epoch: 6| Step: 13
Training loss: 1.3752790081277466
Validation loss: 2.397161017621852

Epoch: 190| Step: 0
Training loss: 1.8661560018569192
Validation loss: 2.412543845815671

Epoch: 6| Step: 1
Training loss: 1.8378364644193292
Validation loss: 2.4206908221783725

Epoch: 6| Step: 2
Training loss: 2.122535398298179
Validation loss: 2.431080083858955

Epoch: 6| Step: 3
Training loss: 2.6640415582365136
Validation loss: 2.430233322753578

Epoch: 6| Step: 4
Training loss: 1.8492513791530778
Validation loss: 2.4086803451832277

Epoch: 6| Step: 5
Training loss: 2.327482813393703
Validation loss: 2.409619485904069

Epoch: 6| Step: 6
Training loss: 2.034184258538731
Validation loss: 2.3946094577453354

Epoch: 6| Step: 7
Training loss: 2.0182877333152187
Validation loss: 2.3823302121317766

Epoch: 6| Step: 8
Training loss: 1.9677089784727828
Validation loss: 2.407231210853352

Epoch: 6| Step: 9
Training loss: 2.4343170511696366
Validation loss: 2.397345077642038

Epoch: 6| Step: 10
Training loss: 2.405656617557186
Validation loss: 2.409780274916409

Epoch: 6| Step: 11
Training loss: 2.680687987285085
Validation loss: 2.4509420187357223

Epoch: 6| Step: 12
Training loss: 2.0745208003062587
Validation loss: 2.451735093952791

Epoch: 6| Step: 13
Training loss: 2.0033974401252954
Validation loss: 2.446242133896768

Epoch: 191| Step: 0
Training loss: 2.1628924901154027
Validation loss: 2.5034163957992175

Epoch: 6| Step: 1
Training loss: 2.351049018637661
Validation loss: 2.5034415306356768

Epoch: 6| Step: 2
Training loss: 1.617844084353454
Validation loss: 2.4958675357183546

Epoch: 6| Step: 3
Training loss: 2.88250995485385
Validation loss: 2.509710132216331

Epoch: 6| Step: 4
Training loss: 1.5445404932327271
Validation loss: 2.453224571479705

Epoch: 6| Step: 5
Training loss: 2.1075184882134774
Validation loss: 2.416830999991421

Epoch: 6| Step: 6
Training loss: 1.6325145978990558
Validation loss: 2.402701329963619

Epoch: 6| Step: 7
Training loss: 2.2927322915636723
Validation loss: 2.401381466279079

Epoch: 6| Step: 8
Training loss: 2.5957275573177645
Validation loss: 2.394881605072276

Epoch: 6| Step: 9
Training loss: 2.2467717217277916
Validation loss: 2.372848864251863

Epoch: 6| Step: 10
Training loss: 2.4111076962417037
Validation loss: 2.3710124397571013

Epoch: 6| Step: 11
Training loss: 2.3020290753859123
Validation loss: 2.3650243441047203

Epoch: 6| Step: 12
Training loss: 2.467236501582779
Validation loss: 2.348652752776774

Epoch: 6| Step: 13
Training loss: 2.119627050308016
Validation loss: 2.3564523861911675

Epoch: 192| Step: 0
Training loss: 1.4141713306003167
Validation loss: 2.371240093194441

Epoch: 6| Step: 1
Training loss: 1.786068806197511
Validation loss: 2.3527998822943443

Epoch: 6| Step: 2
Training loss: 2.0330466907429163
Validation loss: 2.3766224322097083

Epoch: 6| Step: 3
Training loss: 2.7326814475024657
Validation loss: 2.3742058121796723

Epoch: 6| Step: 4
Training loss: 2.3826876248016258
Validation loss: 2.36776276317858

Epoch: 6| Step: 5
Training loss: 2.068753558844418
Validation loss: 2.3668441780704863

Epoch: 6| Step: 6
Training loss: 2.4270613728022274
Validation loss: 2.3731316091571992

Epoch: 6| Step: 7
Training loss: 2.342160716040465
Validation loss: 2.3639043545373597

Epoch: 6| Step: 8
Training loss: 2.3290580569508577
Validation loss: 2.36540272552046

Epoch: 6| Step: 9
Training loss: 2.3461572110703957
Validation loss: 2.3601726239615957

Epoch: 6| Step: 10
Training loss: 2.2397146378697745
Validation loss: 2.359229217178322

Epoch: 6| Step: 11
Training loss: 2.0702809457353615
Validation loss: 2.366217701387935

Epoch: 6| Step: 12
Training loss: 1.6023353758713557
Validation loss: 2.3799314427827305

Epoch: 6| Step: 13
Training loss: 1.664449727310763
Validation loss: 2.386999437425714

Epoch: 193| Step: 0
Training loss: 2.1431110731169087
Validation loss: 2.424777109863358

Epoch: 6| Step: 1
Training loss: 2.0037167108141922
Validation loss: 2.4341551920294595

Epoch: 6| Step: 2
Training loss: 1.970904790807382
Validation loss: 2.4470057405189345

Epoch: 6| Step: 3
Training loss: 2.460543937093916
Validation loss: 2.4330401073524692

Epoch: 6| Step: 4
Training loss: 1.2628573072565288
Validation loss: 2.415268120634566

Epoch: 6| Step: 5
Training loss: 2.304683568918787
Validation loss: 2.4106592798954063

Epoch: 6| Step: 6
Training loss: 1.9129409929857386
Validation loss: 2.3862174599783597

Epoch: 6| Step: 7
Training loss: 2.317687736734033
Validation loss: 2.4116189618298653

Epoch: 6| Step: 8
Training loss: 2.102710169426616
Validation loss: 2.387304715678192

Epoch: 6| Step: 9
Training loss: 1.7573529130098648
Validation loss: 2.370796125062232

Epoch: 6| Step: 10
Training loss: 2.288238481230674
Validation loss: 2.3897549555824487

Epoch: 6| Step: 11
Training loss: 2.388594120035837
Validation loss: 2.383562409710519

Epoch: 6| Step: 12
Training loss: 2.0861730549715443
Validation loss: 2.400851162169486

Epoch: 6| Step: 13
Training loss: 2.8253648471697956
Validation loss: 2.4413810713587396

Epoch: 194| Step: 0
Training loss: 1.6691345857510538
Validation loss: 2.4776252621223698

Epoch: 6| Step: 1
Training loss: 2.587770302332546
Validation loss: 2.4876612230469584

Epoch: 6| Step: 2
Training loss: 1.999920843465299
Validation loss: 2.507378201541045

Epoch: 6| Step: 3
Training loss: 2.2156815062985733
Validation loss: 2.520506299035772

Epoch: 6| Step: 4
Training loss: 1.8969372759530418
Validation loss: 2.5150590088050295

Epoch: 6| Step: 5
Training loss: 2.0032501038808737
Validation loss: 2.5026529489699247

Epoch: 6| Step: 6
Training loss: 1.285091317342348
Validation loss: 2.4701708547998305

Epoch: 6| Step: 7
Training loss: 2.1384854727557774
Validation loss: 2.438776658455628

Epoch: 6| Step: 8
Training loss: 2.4047819340873082
Validation loss: 2.3999398419658022

Epoch: 6| Step: 9
Training loss: 2.2223672528094593
Validation loss: 2.390314609496085

Epoch: 6| Step: 10
Training loss: 2.027953774581862
Validation loss: 2.3712244209486952

Epoch: 6| Step: 11
Training loss: 2.088404193517263
Validation loss: 2.3553575967624876

Epoch: 6| Step: 12
Training loss: 2.3290188500774556
Validation loss: 2.362171437202528

Epoch: 6| Step: 13
Training loss: 2.6051392125220243
Validation loss: 2.3532093296580334

Epoch: 195| Step: 0
Training loss: 2.507807746478653
Validation loss: 2.34492015654856

Epoch: 6| Step: 1
Training loss: 2.228828107371282
Validation loss: 2.374709963831935

Epoch: 6| Step: 2
Training loss: 1.9333560681924646
Validation loss: 2.366397333338749

Epoch: 6| Step: 3
Training loss: 2.482627493973719
Validation loss: 2.383638518718154

Epoch: 6| Step: 4
Training loss: 1.828673712390135
Validation loss: 2.3535725229226165

Epoch: 6| Step: 5
Training loss: 1.6215126323696045
Validation loss: 2.3987927403725684

Epoch: 6| Step: 6
Training loss: 2.11140750873398
Validation loss: 2.3818596273977355

Epoch: 6| Step: 7
Training loss: 1.927182320466743
Validation loss: 2.4175729035440954

Epoch: 6| Step: 8
Training loss: 2.101690692607982
Validation loss: 2.4179460404936703

Epoch: 6| Step: 9
Training loss: 2.5531030810382935
Validation loss: 2.4554488492581856

Epoch: 6| Step: 10
Training loss: 1.805757543888994
Validation loss: 2.47949296295321

Epoch: 6| Step: 11
Training loss: 1.9293407174917947
Validation loss: 2.5093431294243156

Epoch: 6| Step: 12
Training loss: 2.2114291773302748
Validation loss: 2.5397826753092687

Epoch: 6| Step: 13
Training loss: 2.056830155640969
Validation loss: 2.5629893110118305

Epoch: 196| Step: 0
Training loss: 2.1482531659202726
Validation loss: 2.5961996278464827

Epoch: 6| Step: 1
Training loss: 1.8454221481318778
Validation loss: 2.581063818459832

Epoch: 6| Step: 2
Training loss: 2.2570506991944446
Validation loss: 2.5663015508098517

Epoch: 6| Step: 3
Training loss: 1.758576019618007
Validation loss: 2.5246498819557277

Epoch: 6| Step: 4
Training loss: 2.035365000615364
Validation loss: 2.472625000764684

Epoch: 6| Step: 5
Training loss: 1.9930193192942407
Validation loss: 2.4536605312071327

Epoch: 6| Step: 6
Training loss: 2.5293131824100263
Validation loss: 2.4442621993723597

Epoch: 6| Step: 7
Training loss: 2.212854962511896
Validation loss: 2.44027084968666

Epoch: 6| Step: 8
Training loss: 2.024422070956181
Validation loss: 2.416013526138003

Epoch: 6| Step: 9
Training loss: 2.1227196070061307
Validation loss: 2.3828130314888742

Epoch: 6| Step: 10
Training loss: 2.099522731678841
Validation loss: 2.383715041506973

Epoch: 6| Step: 11
Training loss: 1.8296143423516584
Validation loss: 2.376402030367923

Epoch: 6| Step: 12
Training loss: 1.9506874437735786
Validation loss: 2.3844950292165525

Epoch: 6| Step: 13
Training loss: 2.4578262280215983
Validation loss: 2.393942551156633

Epoch: 197| Step: 0
Training loss: 2.2799842144603715
Validation loss: 2.374419650384981

Epoch: 6| Step: 1
Training loss: 2.167399123681245
Validation loss: 2.3759906259355072

Epoch: 6| Step: 2
Training loss: 2.6280859110824886
Validation loss: 2.3619255633910154

Epoch: 6| Step: 3
Training loss: 1.461711087148165
Validation loss: 2.3766443877798333

Epoch: 6| Step: 4
Training loss: 2.378613082786126
Validation loss: 2.376778593993298

Epoch: 6| Step: 5
Training loss: 2.0460636773217185
Validation loss: 2.3790274572558636

Epoch: 6| Step: 6
Training loss: 1.3935006658486102
Validation loss: 2.3747513192361005

Epoch: 6| Step: 7
Training loss: 1.656117703894144
Validation loss: 2.411525441446161

Epoch: 6| Step: 8
Training loss: 2.3556893974442907
Validation loss: 2.4412932953330753

Epoch: 6| Step: 9
Training loss: 2.279059834972368
Validation loss: 2.4620681459809455

Epoch: 6| Step: 10
Training loss: 2.1714272895249906
Validation loss: 2.4757276914785398

Epoch: 6| Step: 11
Training loss: 2.07294478149773
Validation loss: 2.4734767764221006

Epoch: 6| Step: 12
Training loss: 1.9590813716406035
Validation loss: 2.4777400592292556

Epoch: 6| Step: 13
Training loss: 1.1192587478905913
Validation loss: 2.4608329546302605

Epoch: 198| Step: 0
Training loss: 1.9935627098964794
Validation loss: 2.466736506828927

Epoch: 6| Step: 1
Training loss: 1.6878085384170551
Validation loss: 2.4426175548480096

Epoch: 6| Step: 2
Training loss: 1.6916060472848917
Validation loss: 2.4573653790324483

Epoch: 6| Step: 3
Training loss: 1.8046763366089726
Validation loss: 2.443023458409268

Epoch: 6| Step: 4
Training loss: 2.0873026863089263
Validation loss: 2.4351643346113105

Epoch: 6| Step: 5
Training loss: 2.3483989131191403
Validation loss: 2.4301647567852522

Epoch: 6| Step: 6
Training loss: 2.550235146544989
Validation loss: 2.4139311583794307

Epoch: 6| Step: 7
Training loss: 1.888380941490603
Validation loss: 2.3487657939614732

Epoch: 6| Step: 8
Training loss: 2.355142801737752
Validation loss: 2.35648807526118

Epoch: 6| Step: 9
Training loss: 2.3178476927503953
Validation loss: 2.36296771091807

Epoch: 6| Step: 10
Training loss: 2.336613483921161
Validation loss: 2.39073045639949

Epoch: 6| Step: 11
Training loss: 1.4169989177562428
Validation loss: 2.3737309222008314

Epoch: 6| Step: 12
Training loss: 2.15694548958991
Validation loss: 2.3693844360250575

Epoch: 6| Step: 13
Training loss: 1.4038314366348015
Validation loss: 2.3590560618197003

Epoch: 199| Step: 0
Training loss: 2.062506242222443
Validation loss: 2.3809145158109475

Epoch: 6| Step: 1
Training loss: 2.043668608838396
Validation loss: 2.3837866373640413

Epoch: 6| Step: 2
Training loss: 2.20558559366308
Validation loss: 2.400254956157191

Epoch: 6| Step: 3
Training loss: 1.3857257135015526
Validation loss: 2.4364628127255594

Epoch: 6| Step: 4
Training loss: 2.156679414753723
Validation loss: 2.4830412444389744

Epoch: 6| Step: 5
Training loss: 2.4120815012939087
Validation loss: 2.5040932903302906

Epoch: 6| Step: 6
Training loss: 1.9878369267700053
Validation loss: 2.5040679588135566

Epoch: 6| Step: 7
Training loss: 1.7919542688001129
Validation loss: 2.478787462893193

Epoch: 6| Step: 8
Training loss: 1.705202428038137
Validation loss: 2.4290182896541883

Epoch: 6| Step: 9
Training loss: 1.7165222989952673
Validation loss: 2.4334897586790203

Epoch: 6| Step: 10
Training loss: 2.206567766253253
Validation loss: 2.385912434800276

Epoch: 6| Step: 11
Training loss: 1.780492521146575
Validation loss: 2.3632005095175153

Epoch: 6| Step: 12
Training loss: 1.9655162350593756
Validation loss: 2.3639406511961227

Epoch: 6| Step: 13
Training loss: 2.5658168261018597
Validation loss: 2.353825826434215

Epoch: 200| Step: 0
Training loss: 2.0582286648515042
Validation loss: 2.365932438780925

Epoch: 6| Step: 1
Training loss: 2.2079564138754484
Validation loss: 2.3853407566193705

Epoch: 6| Step: 2
Training loss: 1.955888425909549
Validation loss: 2.3730763890510542

Epoch: 6| Step: 3
Training loss: 2.2345290764457384
Validation loss: 2.397877156778592

Epoch: 6| Step: 4
Training loss: 1.759929958380316
Validation loss: 2.3962875980627687

Epoch: 6| Step: 5
Training loss: 1.4322235461132664
Validation loss: 2.4077829731097307

Epoch: 6| Step: 6
Training loss: 1.8581525486592174
Validation loss: 2.493732396467496

Epoch: 6| Step: 7
Training loss: 2.2272521975248774
Validation loss: 2.479195921813087

Epoch: 6| Step: 8
Training loss: 1.9577363774996368
Validation loss: 2.5248269275525

Epoch: 6| Step: 9
Training loss: 2.1056007810962236
Validation loss: 2.5032316506679875

Epoch: 6| Step: 10
Training loss: 1.7682392717465039
Validation loss: 2.4509133168282924

Epoch: 6| Step: 11
Training loss: 2.004976875190846
Validation loss: 2.423754449946777

Epoch: 6| Step: 12
Training loss: 2.279748500873262
Validation loss: 2.421322207788011

Epoch: 6| Step: 13
Training loss: 1.4346733497714501
Validation loss: 2.389060593619056

Epoch: 201| Step: 0
Training loss: 1.9304015039443645
Validation loss: 2.4013193083992848

Epoch: 6| Step: 1
Training loss: 1.5937586017451315
Validation loss: 2.4117995990998717

Epoch: 6| Step: 2
Training loss: 1.9816478101230497
Validation loss: 2.4101765822021335

Epoch: 6| Step: 3
Training loss: 2.2388952454991284
Validation loss: 2.434462916224308

Epoch: 6| Step: 4
Training loss: 1.8909282598740964
Validation loss: 2.414217087923684

Epoch: 6| Step: 5
Training loss: 1.8586784789249589
Validation loss: 2.397276466102348

Epoch: 6| Step: 6
Training loss: 1.4656003091843042
Validation loss: 2.4129008650884707

Epoch: 6| Step: 7
Training loss: 2.0255292883615024
Validation loss: 2.4319330690536716

Epoch: 6| Step: 8
Training loss: 2.060195907425174
Validation loss: 2.401614155176027

Epoch: 6| Step: 9
Training loss: 2.296184617691476
Validation loss: 2.407157031817739

Epoch: 6| Step: 10
Training loss: 1.7388821709732976
Validation loss: 2.383914460713713

Epoch: 6| Step: 11
Training loss: 1.8447259809049839
Validation loss: 2.3674590826355244

Epoch: 6| Step: 12
Training loss: 1.8221801214407303
Validation loss: 2.3645340071984937

Epoch: 6| Step: 13
Training loss: 2.1635395616335327
Validation loss: 2.368169317160366

Epoch: 202| Step: 0
Training loss: 1.7008667419282462
Validation loss: 2.3768270035783257

Epoch: 6| Step: 1
Training loss: 2.217617659344895
Validation loss: 2.380566130627266

Epoch: 6| Step: 2
Training loss: 1.742336454994544
Validation loss: 2.394378759498375

Epoch: 6| Step: 3
Training loss: 2.1300907864273886
Validation loss: 2.4065899991612776

Epoch: 6| Step: 4
Training loss: 1.8711621743833478
Validation loss: 2.417586306144749

Epoch: 6| Step: 5
Training loss: 2.0019437166318554
Validation loss: 2.4343014838231287

Epoch: 6| Step: 6
Training loss: 1.5197932549464621
Validation loss: 2.467623822281476

Epoch: 6| Step: 7
Training loss: 2.2413914559993975
Validation loss: 2.4985356974952513

Epoch: 6| Step: 8
Training loss: 2.377831728443012
Validation loss: 2.510307341969299

Epoch: 6| Step: 9
Training loss: 2.108259570172081
Validation loss: 2.487597631578182

Epoch: 6| Step: 10
Training loss: 2.1778280879500254
Validation loss: 2.5034142939217103

Epoch: 6| Step: 11
Training loss: 1.5368829000486388
Validation loss: 2.460699539933198

Epoch: 6| Step: 12
Training loss: 1.3820019949085727
Validation loss: 2.446088654938492

Epoch: 6| Step: 13
Training loss: 1.542721035544652
Validation loss: 2.4665331292056276

Epoch: 203| Step: 0
Training loss: 1.8527801630264376
Validation loss: 2.483143672677831

Epoch: 6| Step: 1
Training loss: 1.817890832114
Validation loss: 2.487737453684634

Epoch: 6| Step: 2
Training loss: 2.3824143374114755
Validation loss: 2.4552042232838236

Epoch: 6| Step: 3
Training loss: 1.8973702150371594
Validation loss: 2.357111150282794

Epoch: 6| Step: 4
Training loss: 1.911633129252502
Validation loss: 2.3491815471373947

Epoch: 6| Step: 5
Training loss: 1.8049828754151636
Validation loss: 2.3458234468505035

Epoch: 6| Step: 6
Training loss: 2.1306760938162923
Validation loss: 2.373250851510825

Epoch: 6| Step: 7
Training loss: 2.3006648761223136
Validation loss: 2.41341862884836

Epoch: 6| Step: 8
Training loss: 2.411421531797399
Validation loss: 2.4244618340809563

Epoch: 6| Step: 9
Training loss: 1.9492378310376193
Validation loss: 2.400180145222932

Epoch: 6| Step: 10
Training loss: 1.5881899918638034
Validation loss: 2.378321368042807

Epoch: 6| Step: 11
Training loss: 2.094594301258655
Validation loss: 2.393329332297896

Epoch: 6| Step: 12
Training loss: 2.537062952146978
Validation loss: 2.406050660093815

Epoch: 6| Step: 13
Training loss: 1.0799880585186896
Validation loss: 2.385889195065775

Epoch: 204| Step: 0
Training loss: 2.5383919637433223
Validation loss: 2.4133469326539427

Epoch: 6| Step: 1
Training loss: 1.8152217161042155
Validation loss: 2.3927259163229184

Epoch: 6| Step: 2
Training loss: 2.4989437733064777
Validation loss: 2.4006412033249847

Epoch: 6| Step: 3
Training loss: 1.8872847882792656
Validation loss: 2.4036326359973024

Epoch: 6| Step: 4
Training loss: 1.683499008309843
Validation loss: 2.400069009692841

Epoch: 6| Step: 5
Training loss: 1.5382589963404691
Validation loss: 2.4165329866136878

Epoch: 6| Step: 6
Training loss: 2.193889985142085
Validation loss: 2.392237681849275

Epoch: 6| Step: 7
Training loss: 1.7446414787977576
Validation loss: 2.430999476554833

Epoch: 6| Step: 8
Training loss: 1.9552477478162649
Validation loss: 2.439456960810931

Epoch: 6| Step: 9
Training loss: 1.7364381083786822
Validation loss: 2.43087809655635

Epoch: 6| Step: 10
Training loss: 1.3865079047868123
Validation loss: 2.443910032697848

Epoch: 6| Step: 11
Training loss: 2.0253916844334863
Validation loss: 2.446775468778954

Epoch: 6| Step: 12
Training loss: 1.8715903751974519
Validation loss: 2.434729584331048

Epoch: 6| Step: 13
Training loss: 1.7682413616705608
Validation loss: 2.420450587312715

Epoch: 205| Step: 0
Training loss: 1.7814152958786396
Validation loss: 2.438817117734915

Epoch: 6| Step: 1
Training loss: 1.9937262482857665
Validation loss: 2.429587800657452

Epoch: 6| Step: 2
Training loss: 1.872012173780162
Validation loss: 2.406664423366157

Epoch: 6| Step: 3
Training loss: 2.198293379429474
Validation loss: 2.444181191375811

Epoch: 6| Step: 4
Training loss: 1.8681960953131267
Validation loss: 2.4506723330662084

Epoch: 6| Step: 5
Training loss: 1.4378368148953171
Validation loss: 2.4355295671447568

Epoch: 6| Step: 6
Training loss: 1.9746709525357824
Validation loss: 2.444994441888251

Epoch: 6| Step: 7
Training loss: 1.7921413266021686
Validation loss: 2.426382761629571

Epoch: 6| Step: 8
Training loss: 1.7763320223120482
Validation loss: 2.4225561448406716

Epoch: 6| Step: 9
Training loss: 1.781592888204069
Validation loss: 2.3889098197107184

Epoch: 6| Step: 10
Training loss: 2.0248633114870493
Validation loss: 2.392175006671071

Epoch: 6| Step: 11
Training loss: 2.1256117220752433
Validation loss: 2.379601981590093

Epoch: 6| Step: 12
Training loss: 1.8454246028276744
Validation loss: 2.3771428079304293

Epoch: 6| Step: 13
Training loss: 1.940938236922476
Validation loss: 2.4177747533282608

Epoch: 206| Step: 0
Training loss: 1.7714855862816283
Validation loss: 2.3870681198983905

Epoch: 6| Step: 1
Training loss: 1.7567393099816668
Validation loss: 2.4221784715795915

Epoch: 6| Step: 2
Training loss: 1.6250256756441375
Validation loss: 2.440956025774967

Epoch: 6| Step: 3
Training loss: 2.0602919579061467
Validation loss: 2.4686890694931725

Epoch: 6| Step: 4
Training loss: 1.7136918980872333
Validation loss: 2.439662135328042

Epoch: 6| Step: 5
Training loss: 2.1803375696723224
Validation loss: 2.4010061880205193

Epoch: 6| Step: 6
Training loss: 1.8774355011488733
Validation loss: 2.3812365542011658

Epoch: 6| Step: 7
Training loss: 1.904105308874148
Validation loss: 2.375286592334297

Epoch: 6| Step: 8
Training loss: 1.8709814878166715
Validation loss: 2.402971847119297

Epoch: 6| Step: 9
Training loss: 1.5374761626093723
Validation loss: 2.416371248609729

Epoch: 6| Step: 10
Training loss: 1.7506839233200657
Validation loss: 2.399402699566381

Epoch: 6| Step: 11
Training loss: 2.0832279051489446
Validation loss: 2.405369798314342

Epoch: 6| Step: 12
Training loss: 1.9495731253321729
Validation loss: 2.446382111146675

Epoch: 6| Step: 13
Training loss: 2.2642602427435095
Validation loss: 2.444489405898432

Epoch: 207| Step: 0
Training loss: 2.2993070221889895
Validation loss: 2.478758215681677

Epoch: 6| Step: 1
Training loss: 2.0381257108601134
Validation loss: 2.4644014527133553

Epoch: 6| Step: 2
Training loss: 1.79425733881408
Validation loss: 2.4590308123031956

Epoch: 6| Step: 3
Training loss: 1.688285221093418
Validation loss: 2.482599099528782

Epoch: 6| Step: 4
Training loss: 1.9164556373300494
Validation loss: 2.465986909910949

Epoch: 6| Step: 5
Training loss: 1.7543879401881826
Validation loss: 2.4510653379282794

Epoch: 6| Step: 6
Training loss: 1.1989557431367304
Validation loss: 2.4286716852738217

Epoch: 6| Step: 7
Training loss: 2.1997488138547037
Validation loss: 2.4331063016598766

Epoch: 6| Step: 8
Training loss: 2.1496425508950674
Validation loss: 2.364695799809523

Epoch: 6| Step: 9
Training loss: 2.0294678132332997
Validation loss: 2.369686313592011

Epoch: 6| Step: 10
Training loss: 1.7547072724530186
Validation loss: 2.3945939116835806

Epoch: 6| Step: 11
Training loss: 1.462790227279167
Validation loss: 2.4050208826518396

Epoch: 6| Step: 12
Training loss: 1.7206652980288109
Validation loss: 2.4451903081665027

Epoch: 6| Step: 13
Training loss: 1.8681848009377209
Validation loss: 2.4439333579595695

Epoch: 208| Step: 0
Training loss: 1.7058088521811121
Validation loss: 2.4614358835173547

Epoch: 6| Step: 1
Training loss: 2.0540378254172023
Validation loss: 2.4426012721297825

Epoch: 6| Step: 2
Training loss: 1.9079885840484294
Validation loss: 2.38250368169027

Epoch: 6| Step: 3
Training loss: 1.4115033253986293
Validation loss: 2.4038834565315543

Epoch: 6| Step: 4
Training loss: 1.670549312750868
Validation loss: 2.418069626019973

Epoch: 6| Step: 5
Training loss: 1.9110582714329079
Validation loss: 2.4303210673238254

Epoch: 6| Step: 6
Training loss: 2.26240331538037
Validation loss: 2.3921814560188426

Epoch: 6| Step: 7
Training loss: 2.0330754220747647
Validation loss: 2.388406555161911

Epoch: 6| Step: 8
Training loss: 1.7573378536694921
Validation loss: 2.398755720653562

Epoch: 6| Step: 9
Training loss: 1.9149398350041682
Validation loss: 2.4135557352233725

Epoch: 6| Step: 10
Training loss: 1.9977173892479052
Validation loss: 2.4162715637330594

Epoch: 6| Step: 11
Training loss: 1.7586449580487982
Validation loss: 2.4083412244653064

Epoch: 6| Step: 12
Training loss: 1.792705840737625
Validation loss: 2.4166327206437885

Epoch: 6| Step: 13
Training loss: 1.141160081745142
Validation loss: 2.410586765695252

Epoch: 209| Step: 0
Training loss: 2.0113813098744253
Validation loss: 2.4280145094604677

Epoch: 6| Step: 1
Training loss: 1.6054677847235161
Validation loss: 2.410605503294516

Epoch: 6| Step: 2
Training loss: 1.1597741522110945
Validation loss: 2.4386905889322357

Epoch: 6| Step: 3
Training loss: 1.7532830097436807
Validation loss: 2.4449370197272806

Epoch: 6| Step: 4
Training loss: 2.1083915395831467
Validation loss: 2.454933688476582

Epoch: 6| Step: 5
Training loss: 1.4227017524728287
Validation loss: 2.455251756912041

Epoch: 6| Step: 6
Training loss: 1.8925380013605084
Validation loss: 2.4857098488995653

Epoch: 6| Step: 7
Training loss: 1.6517156755481746
Validation loss: 2.463534208791711

Epoch: 6| Step: 8
Training loss: 1.9734334189039786
Validation loss: 2.4892328902721834

Epoch: 6| Step: 9
Training loss: 1.9276482312590002
Validation loss: 2.478826192500295

Epoch: 6| Step: 10
Training loss: 1.8862395694917005
Validation loss: 2.46518323344298

Epoch: 6| Step: 11
Training loss: 1.5135751607207615
Validation loss: 2.4803540269881643

Epoch: 6| Step: 12
Training loss: 1.9605138556631194
Validation loss: 2.4483672269127603

Epoch: 6| Step: 13
Training loss: 2.048636341119208
Validation loss: 2.4161408881064914

Epoch: 210| Step: 0
Training loss: 1.497673774023715
Validation loss: 2.39132703392164

Epoch: 6| Step: 1
Training loss: 1.4699176448666877
Validation loss: 2.3811361300120426

Epoch: 6| Step: 2
Training loss: 2.3864692020598905
Validation loss: 2.3831335547087313

Epoch: 6| Step: 3
Training loss: 2.0271181778560985
Validation loss: 2.405037599943836

Epoch: 6| Step: 4
Training loss: 1.7207379721881115
Validation loss: 2.4313191039507593

Epoch: 6| Step: 5
Training loss: 1.4918828523426817
Validation loss: 2.4311854773730395

Epoch: 6| Step: 6
Training loss: 1.6841395792166205
Validation loss: 2.48670434054465

Epoch: 6| Step: 7
Training loss: 2.094066083592199
Validation loss: 2.466095225562537

Epoch: 6| Step: 8
Training loss: 1.5561913352847654
Validation loss: 2.455324260276805

Epoch: 6| Step: 9
Training loss: 1.598329285718283
Validation loss: 2.4393643195616157

Epoch: 6| Step: 10
Training loss: 1.6513750559993277
Validation loss: 2.440269852709025

Epoch: 6| Step: 11
Training loss: 2.0988692145600405
Validation loss: 2.420813340955648

Epoch: 6| Step: 12
Training loss: 1.8306132931528694
Validation loss: 2.433063708569692

Epoch: 6| Step: 13
Training loss: 1.611365781401845
Validation loss: 2.409158817483536

Epoch: 211| Step: 0
Training loss: 1.3527070419718183
Validation loss: 2.396904419627268

Epoch: 6| Step: 1
Training loss: 1.6421400068767154
Validation loss: 2.407357316810286

Epoch: 6| Step: 2
Training loss: 2.100752209866628
Validation loss: 2.3939132708003057

Epoch: 6| Step: 3
Training loss: 1.7748460595443076
Validation loss: 2.4016639103024353

Epoch: 6| Step: 4
Training loss: 1.7770892621292131
Validation loss: 2.3831825833698015

Epoch: 6| Step: 5
Training loss: 1.963901847635932
Validation loss: 2.4149659728101365

Epoch: 6| Step: 6
Training loss: 1.468620700420463
Validation loss: 2.4185715856112013

Epoch: 6| Step: 7
Training loss: 1.5149393005297442
Validation loss: 2.4580721068943983

Epoch: 6| Step: 8
Training loss: 1.795510877201847
Validation loss: 2.456395263517893

Epoch: 6| Step: 9
Training loss: 1.7304872120029555
Validation loss: 2.4336518232485456

Epoch: 6| Step: 10
Training loss: 2.0382556707517843
Validation loss: 2.4549210160937993

Epoch: 6| Step: 11
Training loss: 1.71868549572673
Validation loss: 2.4044828047717046

Epoch: 6| Step: 12
Training loss: 1.6044400300123423
Validation loss: 2.415104031615158

Epoch: 6| Step: 13
Training loss: 1.8589514241882317
Validation loss: 2.42969548627975

Epoch: 212| Step: 0
Training loss: 1.8163660844853529
Validation loss: 2.43936624804711

Epoch: 6| Step: 1
Training loss: 1.6928263070492533
Validation loss: 2.4383254061709896

Epoch: 6| Step: 2
Training loss: 2.120930308864729
Validation loss: 2.4321423430043776

Epoch: 6| Step: 3
Training loss: 1.3323633221924147
Validation loss: 2.423531426894337

Epoch: 6| Step: 4
Training loss: 0.9232127295294129
Validation loss: 2.4252301103037146

Epoch: 6| Step: 5
Training loss: 2.0704437790040573
Validation loss: 2.4270522413005544

Epoch: 6| Step: 6
Training loss: 1.4780992050017008
Validation loss: 2.4092121624290517

Epoch: 6| Step: 7
Training loss: 1.9329987814712433
Validation loss: 2.433044726672078

Epoch: 6| Step: 8
Training loss: 1.6301585261949596
Validation loss: 2.393483705696045

Epoch: 6| Step: 9
Training loss: 1.705985650345445
Validation loss: 2.412693281983861

Epoch: 6| Step: 10
Training loss: 2.2074449539665717
Validation loss: 2.4146933855085826

Epoch: 6| Step: 11
Training loss: 1.2813670872477563
Validation loss: 2.390446514083497

Epoch: 6| Step: 12
Training loss: 1.6481781525009946
Validation loss: 2.4142357702688764

Epoch: 6| Step: 13
Training loss: 1.9579486942641595
Validation loss: 2.460914611970404

Epoch: 213| Step: 0
Training loss: 1.4988736056023166
Validation loss: 2.46349669672582

Epoch: 6| Step: 1
Training loss: 1.5794035010111722
Validation loss: 2.4986626647481334

Epoch: 6| Step: 2
Training loss: 2.050763578792913
Validation loss: 2.4990706264755267

Epoch: 6| Step: 3
Training loss: 1.43606694979787
Validation loss: 2.461824661982899

Epoch: 6| Step: 4
Training loss: 1.769788373914518
Validation loss: 2.463972186780651

Epoch: 6| Step: 5
Training loss: 1.7486046268880557
Validation loss: 2.4393163749253026

Epoch: 6| Step: 6
Training loss: 1.7604177200344329
Validation loss: 2.414372745825348

Epoch: 6| Step: 7
Training loss: 1.8199541778874504
Validation loss: 2.4096894311982346

Epoch: 6| Step: 8
Training loss: 1.6910376025891207
Validation loss: 2.441022649215248

Epoch: 6| Step: 9
Training loss: 1.5352437622907673
Validation loss: 2.4417679193847435

Epoch: 6| Step: 10
Training loss: 1.9206422403184331
Validation loss: 2.4411328706987216

Epoch: 6| Step: 11
Training loss: 1.4279906829508666
Validation loss: 2.4569475958652314

Epoch: 6| Step: 12
Training loss: 1.55147669498251
Validation loss: 2.48049831396986

Epoch: 6| Step: 13
Training loss: 2.198403351280623
Validation loss: 2.4746067228951425

Epoch: 214| Step: 0
Training loss: 1.563622262373966
Validation loss: 2.4705742964498283

Epoch: 6| Step: 1
Training loss: 1.615243452754683
Validation loss: 2.456638545234913

Epoch: 6| Step: 2
Training loss: 1.5529112517181691
Validation loss: 2.43908403450204

Epoch: 6| Step: 3
Training loss: 1.798739187752872
Validation loss: 2.4647187424450574

Epoch: 6| Step: 4
Training loss: 2.0469465170443844
Validation loss: 2.455534022352253

Epoch: 6| Step: 5
Training loss: 1.4829463307449784
Validation loss: 2.4406712550808556

Epoch: 6| Step: 6
Training loss: 1.4510288501765911
Validation loss: 2.459712456289403

Epoch: 6| Step: 7
Training loss: 1.432514834501938
Validation loss: 2.442324778645682

Epoch: 6| Step: 8
Training loss: 1.5436622316684878
Validation loss: 2.45746957639777

Epoch: 6| Step: 9
Training loss: 1.9960199331232373
Validation loss: 2.4889319119339905

Epoch: 6| Step: 10
Training loss: 2.029130857283538
Validation loss: 2.4991611016631805

Epoch: 6| Step: 11
Training loss: 1.6603603820961426
Validation loss: 2.479391312927795

Epoch: 6| Step: 12
Training loss: 1.7038095480909161
Validation loss: 2.4905909955252548

Epoch: 6| Step: 13
Training loss: 1.692479029064899
Validation loss: 2.4506766335666317

Epoch: 215| Step: 0
Training loss: 1.5693960979445731
Validation loss: 2.419866849666382

Epoch: 6| Step: 1
Training loss: 1.7202202490689984
Validation loss: 2.38719395262607

Epoch: 6| Step: 2
Training loss: 1.42676015197019
Validation loss: 2.4086125706270196

Epoch: 6| Step: 3
Training loss: 1.9781255761216516
Validation loss: 2.3969507809978796

Epoch: 6| Step: 4
Training loss: 1.6115679568201469
Validation loss: 2.412629886467227

Epoch: 6| Step: 5
Training loss: 1.3194185198640735
Validation loss: 2.4159513605841747

Epoch: 6| Step: 6
Training loss: 1.4667802141769741
Validation loss: 2.4357035600703854

Epoch: 6| Step: 7
Training loss: 2.111662690847137
Validation loss: 2.4633179740199904

Epoch: 6| Step: 8
Training loss: 1.4482531350995949
Validation loss: 2.4547042523497287

Epoch: 6| Step: 9
Training loss: 1.887384143330456
Validation loss: 2.4488303052829288

Epoch: 6| Step: 10
Training loss: 1.462158345801932
Validation loss: 2.4636660610389156

Epoch: 6| Step: 11
Training loss: 1.6972879599274824
Validation loss: 2.474032204803686

Epoch: 6| Step: 12
Training loss: 1.8906819989148116
Validation loss: 2.4469180462999556

Epoch: 6| Step: 13
Training loss: 1.889277963521966
Validation loss: 2.487257262929115

Epoch: 216| Step: 0
Training loss: 1.485253084367992
Validation loss: 2.4568345475525533

Epoch: 6| Step: 1
Training loss: 1.8292413547129625
Validation loss: 2.4656830014733644

Epoch: 6| Step: 2
Training loss: 1.9966208402164873
Validation loss: 2.4763048598976356

Epoch: 6| Step: 3
Training loss: 1.3816446232542383
Validation loss: 2.487509997158086

Epoch: 6| Step: 4
Training loss: 1.451717310145067
Validation loss: 2.4766366785182945

Epoch: 6| Step: 5
Training loss: 1.7653327632530498
Validation loss: 2.4435026648912936

Epoch: 6| Step: 6
Training loss: 1.631706776007458
Validation loss: 2.4291692124985595

Epoch: 6| Step: 7
Training loss: 1.9550241621041442
Validation loss: 2.474899373806139

Epoch: 6| Step: 8
Training loss: 1.626281526393379
Validation loss: 2.4385766048963

Epoch: 6| Step: 9
Training loss: 1.5329450450833935
Validation loss: 2.4201658422998182

Epoch: 6| Step: 10
Training loss: 1.5754235439895339
Validation loss: 2.4446618645177507

Epoch: 6| Step: 11
Training loss: 1.713616559866488
Validation loss: 2.443641100560621

Epoch: 6| Step: 12
Training loss: 1.7457380167115406
Validation loss: 2.4305246240041294

Epoch: 6| Step: 13
Training loss: 1.2543237294209484
Validation loss: 2.445107528062094

Epoch: 217| Step: 0
Training loss: 1.358752053126773
Validation loss: 2.4410506041364033

Epoch: 6| Step: 1
Training loss: 1.8891252606665025
Validation loss: 2.4670861180931176

Epoch: 6| Step: 2
Training loss: 1.4929318793278803
Validation loss: 2.5200656073341494

Epoch: 6| Step: 3
Training loss: 1.6530167311636867
Validation loss: 2.488719289446207

Epoch: 6| Step: 4
Training loss: 1.3030472912934388
Validation loss: 2.481225884829925

Epoch: 6| Step: 5
Training loss: 1.9955160421033935
Validation loss: 2.487920164291705

Epoch: 6| Step: 6
Training loss: 1.548398741266857
Validation loss: 2.4611638728269143

Epoch: 6| Step: 7
Training loss: 1.6975506190981862
Validation loss: 2.4837554212715465

Epoch: 6| Step: 8
Training loss: 1.4750641178484127
Validation loss: 2.440823297547584

Epoch: 6| Step: 9
Training loss: 1.757413963067737
Validation loss: 2.45080799238288

Epoch: 6| Step: 10
Training loss: 1.3462336896441396
Validation loss: 2.4432918258283114

Epoch: 6| Step: 11
Training loss: 1.8352259778985294
Validation loss: 2.433078061588731

Epoch: 6| Step: 12
Training loss: 2.073040241283314
Validation loss: 2.4088911635138848

Epoch: 6| Step: 13
Training loss: 1.3634747037286115
Validation loss: 2.440989129773581

Epoch: 218| Step: 0
Training loss: 1.5047842658153718
Validation loss: 2.485920694619148

Epoch: 6| Step: 1
Training loss: 1.6909628059948376
Validation loss: 2.4898787484659355

Epoch: 6| Step: 2
Training loss: 1.5268294695429943
Validation loss: 2.509161763711609

Epoch: 6| Step: 3
Training loss: 1.7243852653349956
Validation loss: 2.5227279069227553

Epoch: 6| Step: 4
Training loss: 1.5742513875678037
Validation loss: 2.5118909661407565

Epoch: 6| Step: 5
Training loss: 1.4342063821321052
Validation loss: 2.514584396857833

Epoch: 6| Step: 6
Training loss: 1.3349681706152345
Validation loss: 2.510158135577485

Epoch: 6| Step: 7
Training loss: 1.7765270997934872
Validation loss: 2.4820142878201095

Epoch: 6| Step: 8
Training loss: 1.6713442093538802
Validation loss: 2.4603950836370587

Epoch: 6| Step: 9
Training loss: 1.3986237045010703
Validation loss: 2.434038879635412

Epoch: 6| Step: 10
Training loss: 2.3021036437736737
Validation loss: 2.452858777633208

Epoch: 6| Step: 11
Training loss: 1.5276348490277745
Validation loss: 2.449706700029856

Epoch: 6| Step: 12
Training loss: 1.640861930087797
Validation loss: 2.4725054516869007

Epoch: 6| Step: 13
Training loss: 1.1140514185970942
Validation loss: 2.4870895154236936

Epoch: 219| Step: 0
Training loss: 1.4657505331388179
Validation loss: 2.4749111493949654

Epoch: 6| Step: 1
Training loss: 1.615626148098034
Validation loss: 2.4898960543375894

Epoch: 6| Step: 2
Training loss: 1.840044662617692
Validation loss: 2.499711290731972

Epoch: 6| Step: 3
Training loss: 1.2516750080340342
Validation loss: 2.5118861805339954

Epoch: 6| Step: 4
Training loss: 1.5415151195100159
Validation loss: 2.489245444622025

Epoch: 6| Step: 5
Training loss: 1.7003515917773566
Validation loss: 2.479488286449706

Epoch: 6| Step: 6
Training loss: 1.8927854694050559
Validation loss: 2.499501488317529

Epoch: 6| Step: 7
Training loss: 1.284364172154285
Validation loss: 2.4657800956377827

Epoch: 6| Step: 8
Training loss: 1.669913165867275
Validation loss: 2.461069569492165

Epoch: 6| Step: 9
Training loss: 1.881508276563085
Validation loss: 2.4592699741919386

Epoch: 6| Step: 10
Training loss: 1.7097455057307374
Validation loss: 2.4614160715983235

Epoch: 6| Step: 11
Training loss: 1.313619181891721
Validation loss: 2.4377910786240933

Epoch: 6| Step: 12
Training loss: 1.7457475767111972
Validation loss: 2.430890919586972

Epoch: 6| Step: 13
Training loss: 0.9222960722767575
Validation loss: 2.4338063961734253

Epoch: 220| Step: 0
Training loss: 1.5960010264496143
Validation loss: 2.443004359762554

Epoch: 6| Step: 1
Training loss: 1.3312959851126691
Validation loss: 2.446027550348961

Epoch: 6| Step: 2
Training loss: 1.0950209181890853
Validation loss: 2.4840758655599746

Epoch: 6| Step: 3
Training loss: 2.0115447626521563
Validation loss: 2.523594082756399

Epoch: 6| Step: 4
Training loss: 1.3962538735686882
Validation loss: 2.5333890233883714

Epoch: 6| Step: 5
Training loss: 1.4169375029829718
Validation loss: 2.5279190963862463

Epoch: 6| Step: 6
Training loss: 2.1284095114644717
Validation loss: 2.4866972234466638

Epoch: 6| Step: 7
Training loss: 1.6499482233420153
Validation loss: 2.4819562616081536

Epoch: 6| Step: 8
Training loss: 1.3726680661747526
Validation loss: 2.4477495278240338

Epoch: 6| Step: 9
Training loss: 1.3797146424057
Validation loss: 2.4316276625394693

Epoch: 6| Step: 10
Training loss: 1.631041154610029
Validation loss: 2.4176226335101174

Epoch: 6| Step: 11
Training loss: 1.7433515004487252
Validation loss: 2.4219558728780894

Epoch: 6| Step: 12
Training loss: 1.812618120225015
Validation loss: 2.4418034150654613

Epoch: 6| Step: 13
Training loss: 0.9298812279690737
Validation loss: 2.443890879088604

Epoch: 221| Step: 0
Training loss: 1.7795151410188896
Validation loss: 2.4524382374601545

Epoch: 6| Step: 1
Training loss: 1.2620715424591498
Validation loss: 2.4760718161843034

Epoch: 6| Step: 2
Training loss: 1.5973092520771424
Validation loss: 2.5066049754803705

Epoch: 6| Step: 3
Training loss: 1.1130659999557835
Validation loss: 2.491116621588556

Epoch: 6| Step: 4
Training loss: 1.6259611661714757
Validation loss: 2.5016455372279887

Epoch: 6| Step: 5
Training loss: 1.4816402742047023
Validation loss: 2.493922952686967

Epoch: 6| Step: 6
Training loss: 1.1574798435573628
Validation loss: 2.4731075614556057

Epoch: 6| Step: 7
Training loss: 1.5218762344887993
Validation loss: 2.478349386711695

Epoch: 6| Step: 8
Training loss: 1.9138857390081467
Validation loss: 2.4832054971893847

Epoch: 6| Step: 9
Training loss: 1.934801807061393
Validation loss: 2.4866843252977175

Epoch: 6| Step: 10
Training loss: 1.3576756521430733
Validation loss: 2.4788984107213152

Epoch: 6| Step: 11
Training loss: 1.8283825554332034
Validation loss: 2.4721800876323865

Epoch: 6| Step: 12
Training loss: 1.7526014610447247
Validation loss: 2.4627706288946545

Epoch: 6| Step: 13
Training loss: 1.353397072448315
Validation loss: 2.4329806399416336

Epoch: 222| Step: 0
Training loss: 1.8452696922046365
Validation loss: 2.426437529318467

Epoch: 6| Step: 1
Training loss: 1.3450844370916604
Validation loss: 2.4145469499350223

Epoch: 6| Step: 2
Training loss: 1.517576553952694
Validation loss: 2.3967677148629747

Epoch: 6| Step: 3
Training loss: 0.8363431498903059
Validation loss: 2.407675183209169

Epoch: 6| Step: 4
Training loss: 1.573492521594919
Validation loss: 2.40962703652739

Epoch: 6| Step: 5
Training loss: 1.6212186098846686
Validation loss: 2.4112729194620273

Epoch: 6| Step: 6
Training loss: 1.2909552347945332
Validation loss: 2.424765653274033

Epoch: 6| Step: 7
Training loss: 1.4757764227542312
Validation loss: 2.445936738533459

Epoch: 6| Step: 8
Training loss: 1.5894000209769468
Validation loss: 2.4797317413782056

Epoch: 6| Step: 9
Training loss: 1.7556747661964085
Validation loss: 2.477710604099311

Epoch: 6| Step: 10
Training loss: 1.7399997403155605
Validation loss: 2.4622278484850657

Epoch: 6| Step: 11
Training loss: 1.1462550803168645
Validation loss: 2.5119992823238224

Epoch: 6| Step: 12
Training loss: 1.7556465198125468
Validation loss: 2.5098086681930796

Epoch: 6| Step: 13
Training loss: 2.006853401497917
Validation loss: 2.5331121340710463

Epoch: 223| Step: 0
Training loss: 1.2923550258472483
Validation loss: 2.4682445141022984

Epoch: 6| Step: 1
Training loss: 1.3556818286175136
Validation loss: 2.438829885357967

Epoch: 6| Step: 2
Training loss: 1.5290843674690207
Validation loss: 2.4420820469245257

Epoch: 6| Step: 3
Training loss: 2.312551136997941
Validation loss: 2.459154587484003

Epoch: 6| Step: 4
Training loss: 1.6393702477209195
Validation loss: 2.422816000259296

Epoch: 6| Step: 5
Training loss: 1.737091823357965
Validation loss: 2.4456490665705557

Epoch: 6| Step: 6
Training loss: 1.4997924025248917
Validation loss: 2.4201242523716684

Epoch: 6| Step: 7
Training loss: 1.2833681044058443
Validation loss: 2.4155966801973143

Epoch: 6| Step: 8
Training loss: 1.7810516246957984
Validation loss: 2.4333858145368303

Epoch: 6| Step: 9
Training loss: 1.0913979444686102
Validation loss: 2.402147541625764

Epoch: 6| Step: 10
Training loss: 1.4220106458412982
Validation loss: 2.4479141629812142

Epoch: 6| Step: 11
Training loss: 0.9940917597004849
Validation loss: 2.469801241639794

Epoch: 6| Step: 12
Training loss: 1.6518789228262132
Validation loss: 2.4739201941839917

Epoch: 6| Step: 13
Training loss: 1.6694698681255746
Validation loss: 2.470754992794903

Epoch: 224| Step: 0
Training loss: 1.2336235173253502
Validation loss: 2.4721746713968242

Epoch: 6| Step: 1
Training loss: 1.3603700087502268
Validation loss: 2.50504004694129

Epoch: 6| Step: 2
Training loss: 1.3988950609492323
Validation loss: 2.50508295386357

Epoch: 6| Step: 3
Training loss: 1.543964151826079
Validation loss: 2.4947055364454394

Epoch: 6| Step: 4
Training loss: 1.3812736957985836
Validation loss: 2.4745403385413933

Epoch: 6| Step: 5
Training loss: 1.9116353742083139
Validation loss: 2.4760664912911077

Epoch: 6| Step: 6
Training loss: 1.390552047358956
Validation loss: 2.4575293929531576

Epoch: 6| Step: 7
Training loss: 1.4281471167256259
Validation loss: 2.462338285798093

Epoch: 6| Step: 8
Training loss: 1.8008413573719888
Validation loss: 2.4508819922456566

Epoch: 6| Step: 9
Training loss: 1.4275220303413834
Validation loss: 2.4350440676366394

Epoch: 6| Step: 10
Training loss: 1.7817623673094514
Validation loss: 2.4343312767432956

Epoch: 6| Step: 11
Training loss: 1.7191722004527559
Validation loss: 2.438858669028314

Epoch: 6| Step: 12
Training loss: 1.3187702358193856
Validation loss: 2.3947236161266003

Epoch: 6| Step: 13
Training loss: 1.8822594934559251
Validation loss: 2.4137923049662757

Epoch: 225| Step: 0
Training loss: 1.817506518450648
Validation loss: 2.422003948418894

Epoch: 6| Step: 1
Training loss: 1.4608612856645113
Validation loss: 2.433499693005541

Epoch: 6| Step: 2
Training loss: 1.477513567092493
Validation loss: 2.4560491991704483

Epoch: 6| Step: 3
Training loss: 1.1367275591636754
Validation loss: 2.456908709193228

Epoch: 6| Step: 4
Training loss: 1.1965321321138214
Validation loss: 2.490008969932214

Epoch: 6| Step: 5
Training loss: 1.6256211634161297
Validation loss: 2.50041367687094

Epoch: 6| Step: 6
Training loss: 1.4628449905265404
Validation loss: 2.501181052780442

Epoch: 6| Step: 7
Training loss: 1.777836724966339
Validation loss: 2.5072728022496205

Epoch: 6| Step: 8
Training loss: 1.63707457978525
Validation loss: 2.4583490231115666

Epoch: 6| Step: 9
Training loss: 1.063874029421529
Validation loss: 2.432452729023245

Epoch: 6| Step: 10
Training loss: 1.7550474672337646
Validation loss: 2.433692325590595

Epoch: 6| Step: 11
Training loss: 1.5926200002255428
Validation loss: 2.4405233135449595

Epoch: 6| Step: 12
Training loss: 1.0648589034482125
Validation loss: 2.443512929912753

Epoch: 6| Step: 13
Training loss: 1.9794263033636788
Validation loss: 2.4378765710356847

Epoch: 226| Step: 0
Training loss: 1.8595998932567426
Validation loss: 2.440079324802263

Epoch: 6| Step: 1
Training loss: 1.600471459903823
Validation loss: 2.4440115005796965

Epoch: 6| Step: 2
Training loss: 1.4802427899481907
Validation loss: 2.4439245727245535

Epoch: 6| Step: 3
Training loss: 1.4701914916880916
Validation loss: 2.4414485841423703

Epoch: 6| Step: 4
Training loss: 1.3513478014873583
Validation loss: 2.454391113045526

Epoch: 6| Step: 5
Training loss: 1.7598382424667438
Validation loss: 2.4632361673848746

Epoch: 6| Step: 6
Training loss: 1.1941365959141936
Validation loss: 2.458594705804551

Epoch: 6| Step: 7
Training loss: 0.8965494635063984
Validation loss: 2.473297789148307

Epoch: 6| Step: 8
Training loss: 1.5990235090692546
Validation loss: 2.479470233802033

Epoch: 6| Step: 9
Training loss: 1.2476685716263047
Validation loss: 2.502828502281754

Epoch: 6| Step: 10
Training loss: 1.784679925254921
Validation loss: 2.4982799622142977

Epoch: 6| Step: 11
Training loss: 1.3608639334800439
Validation loss: 2.4788688762776716

Epoch: 6| Step: 12
Training loss: 1.4457660685053126
Validation loss: 2.4584752377835635

Epoch: 6| Step: 13
Training loss: 1.0317519729074074
Validation loss: 2.4567212561150376

Epoch: 227| Step: 0
Training loss: 1.588256268321235
Validation loss: 2.431225969133758

Epoch: 6| Step: 1
Training loss: 1.6173055854475897
Validation loss: 2.4554510543159664

Epoch: 6| Step: 2
Training loss: 1.3165711432625304
Validation loss: 2.4425696814156717

Epoch: 6| Step: 3
Training loss: 1.5086480232167916
Validation loss: 2.450466919154284

Epoch: 6| Step: 4
Training loss: 0.9277908789844835
Validation loss: 2.4229046821553544

Epoch: 6| Step: 5
Training loss: 1.5533998610748783
Validation loss: 2.4411347400269503

Epoch: 6| Step: 6
Training loss: 1.6349677504412465
Validation loss: 2.4660256555082958

Epoch: 6| Step: 7
Training loss: 1.655472915017693
Validation loss: 2.451047967075741

Epoch: 6| Step: 8
Training loss: 1.1449298880487675
Validation loss: 2.474647335011238

Epoch: 6| Step: 9
Training loss: 1.545157895584457
Validation loss: 2.5101751055477055

Epoch: 6| Step: 10
Training loss: 1.393266120016529
Validation loss: 2.4975792650020847

Epoch: 6| Step: 11
Training loss: 1.5800573019911917
Validation loss: 2.498917143120192

Epoch: 6| Step: 12
Training loss: 1.5026376104572239
Validation loss: 2.488917649256325

Epoch: 6| Step: 13
Training loss: 1.1304597823941354
Validation loss: 2.460227931464953

Epoch: 228| Step: 0
Training loss: 1.3201508281974332
Validation loss: 2.4524143627412807

Epoch: 6| Step: 1
Training loss: 1.428072825340612
Validation loss: 2.456486680140723

Epoch: 6| Step: 2
Training loss: 1.1119708999695768
Validation loss: 2.4641529401849307

Epoch: 6| Step: 3
Training loss: 1.6297646143106317
Validation loss: 2.461202249578901

Epoch: 6| Step: 4
Training loss: 1.4459387994533262
Validation loss: 2.4618977053892896

Epoch: 6| Step: 5
Training loss: 1.3582576676027132
Validation loss: 2.4901012563785065

Epoch: 6| Step: 6
Training loss: 1.0613551984751959
Validation loss: 2.479483373164801

Epoch: 6| Step: 7
Training loss: 1.4138953600154367
Validation loss: 2.489092468798569

Epoch: 6| Step: 8
Training loss: 1.7239430437437628
Validation loss: 2.4980299252650666

Epoch: 6| Step: 9
Training loss: 0.984951970386553
Validation loss: 2.514524278260706

Epoch: 6| Step: 10
Training loss: 1.915363663587386
Validation loss: 2.496414829711927

Epoch: 6| Step: 11
Training loss: 1.502687113658048
Validation loss: 2.5363080154379083

Epoch: 6| Step: 12
Training loss: 1.6528133509607228
Validation loss: 2.4917279421305696

Epoch: 6| Step: 13
Training loss: 1.4489174912723266
Validation loss: 2.483593519152013

Epoch: 229| Step: 0
Training loss: 1.003115034202437
Validation loss: 2.488766590874676

Epoch: 6| Step: 1
Training loss: 1.5750984403334043
Validation loss: 2.46905483919897

Epoch: 6| Step: 2
Training loss: 0.6312811418915344
Validation loss: 2.46955421508887

Epoch: 6| Step: 3
Training loss: 1.3287166399639228
Validation loss: 2.4579140660356367

Epoch: 6| Step: 4
Training loss: 1.0324470623752875
Validation loss: 2.481723095722757

Epoch: 6| Step: 5
Training loss: 2.0405132642827555
Validation loss: 2.4483518452335664

Epoch: 6| Step: 6
Training loss: 1.623626054786212
Validation loss: 2.4396016810253798

Epoch: 6| Step: 7
Training loss: 1.647967086129991
Validation loss: 2.4403945001203993

Epoch: 6| Step: 8
Training loss: 1.5353401209860227
Validation loss: 2.4198981477295463

Epoch: 6| Step: 9
Training loss: 1.2727198538625912
Validation loss: 2.4214873131621433

Epoch: 6| Step: 10
Training loss: 1.1591684265361035
Validation loss: 2.4092124449473618

Epoch: 6| Step: 11
Training loss: 1.4034740175343403
Validation loss: 2.403486455571353

Epoch: 6| Step: 12
Training loss: 1.5415808507730675
Validation loss: 2.419890229759331

Epoch: 6| Step: 13
Training loss: 1.1838535237789576
Validation loss: 2.4307584380418583

Epoch: 230| Step: 0
Training loss: 1.755122589220519
Validation loss: 2.452934387840112

Epoch: 6| Step: 1
Training loss: 1.045948244648849
Validation loss: 2.4855831214449395

Epoch: 6| Step: 2
Training loss: 1.5132286554983723
Validation loss: 2.499468086425524

Epoch: 6| Step: 3
Training loss: 1.3227763915095854
Validation loss: 2.504264085818576

Epoch: 6| Step: 4
Training loss: 1.3708724579643612
Validation loss: 2.5231855261510656

Epoch: 6| Step: 5
Training loss: 1.0145382275173243
Validation loss: 2.4889204272248677

Epoch: 6| Step: 6
Training loss: 1.8840676077518645
Validation loss: 2.491691068523699

Epoch: 6| Step: 7
Training loss: 1.3781938738923576
Validation loss: 2.5094181415724046

Epoch: 6| Step: 8
Training loss: 1.2414328724123318
Validation loss: 2.499080579132188

Epoch: 6| Step: 9
Training loss: 1.252620477497497
Validation loss: 2.5048834900286505

Epoch: 6| Step: 10
Training loss: 1.1917930600465665
Validation loss: 2.484949149945653

Epoch: 6| Step: 11
Training loss: 1.2403533638171698
Validation loss: 2.444434121845944

Epoch: 6| Step: 12
Training loss: 1.6344276726077798
Validation loss: 2.448515014899855

Epoch: 6| Step: 13
Training loss: 1.4633947911894354
Validation loss: 2.444835250512631

Epoch: 231| Step: 0
Training loss: 1.2064774610087496
Validation loss: 2.4158353321539594

Epoch: 6| Step: 1
Training loss: 1.1166188319954113
Validation loss: 2.3711693110352217

Epoch: 6| Step: 2
Training loss: 1.4414746441418869
Validation loss: 2.391794276798252

Epoch: 6| Step: 3
Training loss: 0.9513873222474304
Validation loss: 2.404372221579292

Epoch: 6| Step: 4
Training loss: 1.8589704698594456
Validation loss: 2.434464920200663

Epoch: 6| Step: 5
Training loss: 1.436793775813888
Validation loss: 2.4008484349942223

Epoch: 6| Step: 6
Training loss: 1.2776636312242837
Validation loss: 2.417602604641993

Epoch: 6| Step: 7
Training loss: 1.259666734702667
Validation loss: 2.435212671550989

Epoch: 6| Step: 8
Training loss: 1.1109650191320366
Validation loss: 2.4878537405183723

Epoch: 6| Step: 9
Training loss: 1.5461050872618374
Validation loss: 2.513429042368765

Epoch: 6| Step: 10
Training loss: 1.7587182318252312
Validation loss: 2.5525684035503917

Epoch: 6| Step: 11
Training loss: 1.5458918057442244
Validation loss: 2.5375732315127073

Epoch: 6| Step: 12
Training loss: 1.3927100334451932
Validation loss: 2.529615104402629

Epoch: 6| Step: 13
Training loss: 1.4373867985478113
Validation loss: 2.5241021600698605

Epoch: 232| Step: 0
Training loss: 1.464601786656835
Validation loss: 2.493900376636486

Epoch: 6| Step: 1
Training loss: 0.8746399138529662
Validation loss: 2.479224946710693

Epoch: 6| Step: 2
Training loss: 1.3915154681427169
Validation loss: 2.4856600650630707

Epoch: 6| Step: 3
Training loss: 1.526711725849925
Validation loss: 2.474460761579001

Epoch: 6| Step: 4
Training loss: 1.0928239444245769
Validation loss: 2.465790189942634

Epoch: 6| Step: 5
Training loss: 1.4297602066980415
Validation loss: 2.4633183668942653

Epoch: 6| Step: 6
Training loss: 1.6821468357852516
Validation loss: 2.449816334067973

Epoch: 6| Step: 7
Training loss: 1.3474939220907125
Validation loss: 2.466414417817975

Epoch: 6| Step: 8
Training loss: 1.2904632818030213
Validation loss: 2.47184695513952

Epoch: 6| Step: 9
Training loss: 1.2325970363526226
Validation loss: 2.4667066978952246

Epoch: 6| Step: 10
Training loss: 1.4802132338197336
Validation loss: 2.49953976773588

Epoch: 6| Step: 11
Training loss: 1.5077150935991843
Validation loss: 2.466109930018513

Epoch: 6| Step: 12
Training loss: 1.2794656656748582
Validation loss: 2.462452062149887

Epoch: 6| Step: 13
Training loss: 1.7979029493224865
Validation loss: 2.4609707685709963

Epoch: 233| Step: 0
Training loss: 0.9688370573242512
Validation loss: 2.470985763682429

Epoch: 6| Step: 1
Training loss: 1.013759719482188
Validation loss: 2.5040658252335386

Epoch: 6| Step: 2
Training loss: 1.5787071438467348
Validation loss: 2.4914898421296687

Epoch: 6| Step: 3
Training loss: 1.7303376503360643
Validation loss: 2.522815574496502

Epoch: 6| Step: 4
Training loss: 1.7334168682999023
Validation loss: 2.5329940258873345

Epoch: 6| Step: 5
Training loss: 1.1704301701100936
Validation loss: 2.5639570122284434

Epoch: 6| Step: 6
Training loss: 1.2723954038219791
Validation loss: 2.564582086384889

Epoch: 6| Step: 7
Training loss: 1.3817654541156317
Validation loss: 2.5301079745689483

Epoch: 6| Step: 8
Training loss: 1.4870791248544513
Validation loss: 2.533364788293531

Epoch: 6| Step: 9
Training loss: 1.2989416087199896
Validation loss: 2.4799408934708365

Epoch: 6| Step: 10
Training loss: 1.3033081804142739
Validation loss: 2.463446333899303

Epoch: 6| Step: 11
Training loss: 1.1360237645027567
Validation loss: 2.467843051776814

Epoch: 6| Step: 12
Training loss: 1.515059768832291
Validation loss: 2.4852649087835164

Epoch: 6| Step: 13
Training loss: 1.1296605424843487
Validation loss: 2.4676938459426587

Epoch: 234| Step: 0
Training loss: 1.2375600742439419
Validation loss: 2.4609636525764778

Epoch: 6| Step: 1
Training loss: 1.3647401540009383
Validation loss: 2.4544466146448887

Epoch: 6| Step: 2
Training loss: 1.3699224528063187
Validation loss: 2.4479651142388845

Epoch: 6| Step: 3
Training loss: 1.5827070135154844
Validation loss: 2.4731657553701907

Epoch: 6| Step: 4
Training loss: 1.289654774861852
Validation loss: 2.4350772456894187

Epoch: 6| Step: 5
Training loss: 1.2836809125248627
Validation loss: 2.420184762080278

Epoch: 6| Step: 6
Training loss: 1.395193503710514
Validation loss: 2.4541764763182803

Epoch: 6| Step: 7
Training loss: 1.0296983315993624
Validation loss: 2.4583393477138102

Epoch: 6| Step: 8
Training loss: 1.225700269738686
Validation loss: 2.469916265902639

Epoch: 6| Step: 9
Training loss: 1.539732579012088
Validation loss: 2.508649950285142

Epoch: 6| Step: 10
Training loss: 1.4522022065480422
Validation loss: 2.530638387549907

Epoch: 6| Step: 11
Training loss: 1.4780789616131154
Validation loss: 2.5128049937679666

Epoch: 6| Step: 12
Training loss: 1.2404236176056516
Validation loss: 2.5384103548064534

Epoch: 6| Step: 13
Training loss: 1.046980952125135
Validation loss: 2.5259888630253213

Epoch: 235| Step: 0
Training loss: 1.0984763343425272
Validation loss: 2.5337679589185798

Epoch: 6| Step: 1
Training loss: 1.227078614714293
Validation loss: 2.5151576940148606

Epoch: 6| Step: 2
Training loss: 1.3229045366747376
Validation loss: 2.5038239438965215

Epoch: 6| Step: 3
Training loss: 0.9193939832520792
Validation loss: 2.4521449320461444

Epoch: 6| Step: 4
Training loss: 1.3997562945647304
Validation loss: 2.4777237776256085

Epoch: 6| Step: 5
Training loss: 1.166841147636144
Validation loss: 2.4544715307854914

Epoch: 6| Step: 6
Training loss: 1.1197650226114195
Validation loss: 2.450831163082279

Epoch: 6| Step: 7
Training loss: 1.4983755693575407
Validation loss: 2.4584308101425627

Epoch: 6| Step: 8
Training loss: 1.0503548249669246
Validation loss: 2.4230477787212195

Epoch: 6| Step: 9
Training loss: 1.9729516138716405
Validation loss: 2.419984154667579

Epoch: 6| Step: 10
Training loss: 1.2887048398531233
Validation loss: 2.4092160235097553

Epoch: 6| Step: 11
Training loss: 1.124518291339889
Validation loss: 2.4393914001926986

Epoch: 6| Step: 12
Training loss: 1.316943684340606
Validation loss: 2.422716568388878

Epoch: 6| Step: 13
Training loss: 1.5281714808722129
Validation loss: 2.4599448779640354

Epoch: 236| Step: 0
Training loss: 1.004465741353267
Validation loss: 2.4785098419694753

Epoch: 6| Step: 1
Training loss: 1.0914727618758941
Validation loss: 2.502331178524019

Epoch: 6| Step: 2
Training loss: 1.7525104499537987
Validation loss: 2.4801637218622385

Epoch: 6| Step: 3
Training loss: 1.0193652021450597
Validation loss: 2.4770392606012055

Epoch: 6| Step: 4
Training loss: 1.410179919945044
Validation loss: 2.475556640555202

Epoch: 6| Step: 5
Training loss: 1.432576080751851
Validation loss: 2.448056177541847

Epoch: 6| Step: 6
Training loss: 1.4314621713951703
Validation loss: 2.437901164389523

Epoch: 6| Step: 7
Training loss: 1.0968928278590921
Validation loss: 2.4208769425839685

Epoch: 6| Step: 8
Training loss: 1.13667145201346
Validation loss: 2.411305048842004

Epoch: 6| Step: 9
Training loss: 1.4523625167939265
Validation loss: 2.4170848682077666

Epoch: 6| Step: 10
Training loss: 1.3316182589813748
Validation loss: 2.427446966505149

Epoch: 6| Step: 11
Training loss: 1.3207504629538318
Validation loss: 2.4366032086843643

Epoch: 6| Step: 12
Training loss: 1.180704247080312
Validation loss: 2.4712077531964973

Epoch: 6| Step: 13
Training loss: 1.1438556017876946
Validation loss: 2.493623959184226

Epoch: 237| Step: 0
Training loss: 1.3132819162670035
Validation loss: 2.5328221828594466

Epoch: 6| Step: 1
Training loss: 1.0898488909418957
Validation loss: 2.525798846237697

Epoch: 6| Step: 2
Training loss: 1.600446954526813
Validation loss: 2.5407389008793855

Epoch: 6| Step: 3
Training loss: 1.082224914626633
Validation loss: 2.5248430470522356

Epoch: 6| Step: 4
Training loss: 1.3697468371966601
Validation loss: 2.5557455868606054

Epoch: 6| Step: 5
Training loss: 1.5240413936039714
Validation loss: 2.5664312119499217

Epoch: 6| Step: 6
Training loss: 1.084385648119972
Validation loss: 2.588985880795109

Epoch: 6| Step: 7
Training loss: 1.0151300251177224
Validation loss: 2.530854012261074

Epoch: 6| Step: 8
Training loss: 1.7537242225715617
Validation loss: 2.519877042298495

Epoch: 6| Step: 9
Training loss: 1.1917223901769336
Validation loss: 2.5140753668389535

Epoch: 6| Step: 10
Training loss: 0.8479578914196625
Validation loss: 2.4676221995025283

Epoch: 6| Step: 11
Training loss: 1.3388855290843407
Validation loss: 2.457903265594127

Epoch: 6| Step: 12
Training loss: 1.0868075610796726
Validation loss: 2.439326189884926

Epoch: 6| Step: 13
Training loss: 1.2939189634699306
Validation loss: 2.3876925745931428

Epoch: 238| Step: 0
Training loss: 1.2955775377456322
Validation loss: 2.400198732286778

Epoch: 6| Step: 1
Training loss: 1.656969382045208
Validation loss: 2.397537391224999

Epoch: 6| Step: 2
Training loss: 1.1766906465855165
Validation loss: 2.4229795268028176

Epoch: 6| Step: 3
Training loss: 1.083556054524693
Validation loss: 2.3946037547151886

Epoch: 6| Step: 4
Training loss: 0.9653501224317991
Validation loss: 2.3859904334888364

Epoch: 6| Step: 5
Training loss: 0.9511823399024871
Validation loss: 2.443460986404809

Epoch: 6| Step: 6
Training loss: 0.9807127994597138
Validation loss: 2.45765898354125

Epoch: 6| Step: 7
Training loss: 1.1042621619237298
Validation loss: 2.490700587963749

Epoch: 6| Step: 8
Training loss: 1.144096838887211
Validation loss: 2.5020929353696464

Epoch: 6| Step: 9
Training loss: 1.2542432765860325
Validation loss: 2.5783529469837854

Epoch: 6| Step: 10
Training loss: 1.4942012600033197
Validation loss: 2.6085079964042364

Epoch: 6| Step: 11
Training loss: 1.2620274310841175
Validation loss: 2.5683317107706247

Epoch: 6| Step: 12
Training loss: 1.4390549749618755
Validation loss: 2.5147713902273825

Epoch: 6| Step: 13
Training loss: 2.15451676741401
Validation loss: 2.51743245400077

Epoch: 239| Step: 0
Training loss: 1.5911791392668253
Validation loss: 2.4786452560886634

Epoch: 6| Step: 1
Training loss: 1.0324007029965891
Validation loss: 2.466969271636721

Epoch: 6| Step: 2
Training loss: 0.8608871680638134
Validation loss: 2.4151395768494273

Epoch: 6| Step: 3
Training loss: 1.1327048414965961
Validation loss: 2.376798120708035

Epoch: 6| Step: 4
Training loss: 1.8978653661813407
Validation loss: 2.3774714232311434

Epoch: 6| Step: 5
Training loss: 1.6929683387801617
Validation loss: 2.3553535902501777

Epoch: 6| Step: 6
Training loss: 1.1531656211583279
Validation loss: 2.355440226702069

Epoch: 6| Step: 7
Training loss: 1.3636288350070853
Validation loss: 2.363541090465936

Epoch: 6| Step: 8
Training loss: 1.0623651867776962
Validation loss: 2.3917391510047885

Epoch: 6| Step: 9
Training loss: 1.1869862097475006
Validation loss: 2.4080419868816123

Epoch: 6| Step: 10
Training loss: 1.385989704030535
Validation loss: 2.444142335491245

Epoch: 6| Step: 11
Training loss: 0.8714401172324224
Validation loss: 2.499827548201088

Epoch: 6| Step: 12
Training loss: 1.2071301071028935
Validation loss: 2.5131742431973145

Epoch: 6| Step: 13
Training loss: 0.939272254456822
Validation loss: 2.53166098368137

Epoch: 240| Step: 0
Training loss: 1.786654188209817
Validation loss: 2.541785399960075

Epoch: 6| Step: 1
Training loss: 1.2093842419805942
Validation loss: 2.5579343290291985

Epoch: 6| Step: 2
Training loss: 1.5824760659383061
Validation loss: 2.5385305635322553

Epoch: 6| Step: 3
Training loss: 1.333454345138996
Validation loss: 2.5257226818469967

Epoch: 6| Step: 4
Training loss: 0.9100667557492095
Validation loss: 2.4875591333502447

Epoch: 6| Step: 5
Training loss: 1.5384266115772258
Validation loss: 2.4750958679863553

Epoch: 6| Step: 6
Training loss: 1.3040771884305813
Validation loss: 2.4464857263135578

Epoch: 6| Step: 7
Training loss: 1.1989828368510345
Validation loss: 2.450879937886314

Epoch: 6| Step: 8
Training loss: 1.2054209414759152
Validation loss: 2.433728935023753

Epoch: 6| Step: 9
Training loss: 0.7651270590089023
Validation loss: 2.4455851877518677

Epoch: 6| Step: 10
Training loss: 1.379303612877597
Validation loss: 2.436533225832244

Epoch: 6| Step: 11
Training loss: 0.7148234463502557
Validation loss: 2.4444455271550996

Epoch: 6| Step: 12
Training loss: 0.7410941653941159
Validation loss: 2.448597297657956

Epoch: 6| Step: 13
Training loss: 1.1566259958462255
Validation loss: 2.403330100591269

Epoch: 241| Step: 0
Training loss: 0.9751340871699724
Validation loss: 2.402665061882588

Epoch: 6| Step: 1
Training loss: 0.942965597101612
Validation loss: 2.432790299104055

Epoch: 6| Step: 2
Training loss: 1.0098313212467271
Validation loss: 2.4588203033022653

Epoch: 6| Step: 3
Training loss: 0.9258245787963453
Validation loss: 2.4275127525514635

Epoch: 6| Step: 4
Training loss: 1.6053882587981065
Validation loss: 2.4430437652488943

Epoch: 6| Step: 5
Training loss: 0.8500434555838428
Validation loss: 2.472536497137557

Epoch: 6| Step: 6
Training loss: 1.4128305537895596
Validation loss: 2.46453921689853

Epoch: 6| Step: 7
Training loss: 1.1507636147240041
Validation loss: 2.5184511770035045

Epoch: 6| Step: 8
Training loss: 1.4761644260756588
Validation loss: 2.5237463599513084

Epoch: 6| Step: 9
Training loss: 1.6172253148177371
Validation loss: 2.5393954999094928

Epoch: 6| Step: 10
Training loss: 1.437699594324175
Validation loss: 2.559025072334267

Epoch: 6| Step: 11
Training loss: 1.1348794955506891
Validation loss: 2.557763964160026

Epoch: 6| Step: 12
Training loss: 1.1785787462444939
Validation loss: 2.505380558355594

Epoch: 6| Step: 13
Training loss: 1.1556948282654063
Validation loss: 2.5057330793425723

Epoch: 242| Step: 0
Training loss: 1.1079461473088883
Validation loss: 2.4436765254950994

Epoch: 6| Step: 1
Training loss: 0.9302048405791378
Validation loss: 2.442501108039973

Epoch: 6| Step: 2
Training loss: 1.4825049416007785
Validation loss: 2.414821887754934

Epoch: 6| Step: 3
Training loss: 1.2317497246232683
Validation loss: 2.413905311885859

Epoch: 6| Step: 4
Training loss: 1.0516342614728584
Validation loss: 2.435383788082097

Epoch: 6| Step: 5
Training loss: 1.1309616754145158
Validation loss: 2.392204613727976

Epoch: 6| Step: 6
Training loss: 1.6538274790403855
Validation loss: 2.4506599190033143

Epoch: 6| Step: 7
Training loss: 1.270761920402493
Validation loss: 2.465651516217012

Epoch: 6| Step: 8
Training loss: 1.1220979878039634
Validation loss: 2.432791702746754

Epoch: 6| Step: 9
Training loss: 1.2158123705501152
Validation loss: 2.445438353857703

Epoch: 6| Step: 10
Training loss: 0.9100834895180615
Validation loss: 2.4636109669361583

Epoch: 6| Step: 11
Training loss: 1.2204327825643706
Validation loss: 2.4587119074994512

Epoch: 6| Step: 12
Training loss: 1.3151612322924702
Validation loss: 2.4739713189000687

Epoch: 6| Step: 13
Training loss: 1.3097951356115691
Validation loss: 2.4797300314097432

Epoch: 243| Step: 0
Training loss: 1.2461004466292434
Validation loss: 2.4788485831661897

Epoch: 6| Step: 1
Training loss: 1.1246432162483597
Validation loss: 2.479459551039342

Epoch: 6| Step: 2
Training loss: 1.2116484493126212
Validation loss: 2.476602968249101

Epoch: 6| Step: 3
Training loss: 1.285232588057377
Validation loss: 2.490126777848245

Epoch: 6| Step: 4
Training loss: 1.2901671329430593
Validation loss: 2.528916620730508

Epoch: 6| Step: 5
Training loss: 0.7196061384264726
Validation loss: 2.5746680059125473

Epoch: 6| Step: 6
Training loss: 2.001991710756197
Validation loss: 2.5414250859343492

Epoch: 6| Step: 7
Training loss: 1.1134520817909135
Validation loss: 2.5364457492061803

Epoch: 6| Step: 8
Training loss: 1.1279084438949147
Validation loss: 2.499079309149964

Epoch: 6| Step: 9
Training loss: 1.1567398786231848
Validation loss: 2.490029391386153

Epoch: 6| Step: 10
Training loss: 1.013825333285642
Validation loss: 2.5092544864474826

Epoch: 6| Step: 11
Training loss: 1.129662125382948
Validation loss: 2.4432286524056566

Epoch: 6| Step: 12
Training loss: 0.7561529806657366
Validation loss: 2.4444710979270186

Epoch: 6| Step: 13
Training loss: 1.0782781298705153
Validation loss: 2.4506146087615734

Epoch: 244| Step: 0
Training loss: 1.1934079224346694
Validation loss: 2.4541944340264363

Epoch: 6| Step: 1
Training loss: 1.2051720976705618
Validation loss: 2.4586292197930613

Epoch: 6| Step: 2
Training loss: 0.8982604474299666
Validation loss: 2.469272230663192

Epoch: 6| Step: 3
Training loss: 0.9224512271341749
Validation loss: 2.4841614224636746

Epoch: 6| Step: 4
Training loss: 1.22439743714661
Validation loss: 2.4956412850094667

Epoch: 6| Step: 5
Training loss: 1.25414352311149
Validation loss: 2.4888885684673605

Epoch: 6| Step: 6
Training loss: 1.2811112677666057
Validation loss: 2.5348377342123483

Epoch: 6| Step: 7
Training loss: 0.8180403349265872
Validation loss: 2.5027744700126067

Epoch: 6| Step: 8
Training loss: 1.0921808158004176
Validation loss: 2.5078108464911772

Epoch: 6| Step: 9
Training loss: 1.6569667201087206
Validation loss: 2.511979844703438

Epoch: 6| Step: 10
Training loss: 1.0754062816340637
Validation loss: 2.493431516065623

Epoch: 6| Step: 11
Training loss: 1.1223460789013322
Validation loss: 2.4906278555685097

Epoch: 6| Step: 12
Training loss: 1.5788202548308687
Validation loss: 2.491816788830126

Epoch: 6| Step: 13
Training loss: 1.3131086663851235
Validation loss: 2.473394236131428

Epoch: 245| Step: 0
Training loss: 0.8119893303203042
Validation loss: 2.461902293471926

Epoch: 6| Step: 1
Training loss: 1.3887355698626391
Validation loss: 2.457487142837162

Epoch: 6| Step: 2
Training loss: 1.1807293869891113
Validation loss: 2.4289052217175042

Epoch: 6| Step: 3
Training loss: 1.763770150354073
Validation loss: 2.4451707189945098

Epoch: 6| Step: 4
Training loss: 0.7601066549653459
Validation loss: 2.4459992126324925

Epoch: 6| Step: 5
Training loss: 0.9803631790286993
Validation loss: 2.455596731999426

Epoch: 6| Step: 6
Training loss: 0.9309096757790607
Validation loss: 2.510064426921082

Epoch: 6| Step: 7
Training loss: 0.8540585534750982
Validation loss: 2.498768077366499

Epoch: 6| Step: 8
Training loss: 0.9516503229313354
Validation loss: 2.5036063823640875

Epoch: 6| Step: 9
Training loss: 1.1932847519438945
Validation loss: 2.4848635283428306

Epoch: 6| Step: 10
Training loss: 1.1373080269765983
Validation loss: 2.468670152271419

Epoch: 6| Step: 11
Training loss: 1.2900912716831594
Validation loss: 2.498274836528504

Epoch: 6| Step: 12
Training loss: 1.439334196770394
Validation loss: 2.533172596358753

Epoch: 6| Step: 13
Training loss: 1.6177700301975768
Validation loss: 2.529325125298911

Epoch: 246| Step: 0
Training loss: 1.3059683354615261
Validation loss: 2.531861937060455

Epoch: 6| Step: 1
Training loss: 0.970576256917793
Validation loss: 2.4797406670015802

Epoch: 6| Step: 2
Training loss: 1.2543413589748604
Validation loss: 2.496611719141133

Epoch: 6| Step: 3
Training loss: 0.8612381591868765
Validation loss: 2.4878817081509785

Epoch: 6| Step: 4
Training loss: 0.8505822936022694
Validation loss: 2.4988165320473246

Epoch: 6| Step: 5
Training loss: 1.0986832670706068
Validation loss: 2.4800465426095113

Epoch: 6| Step: 6
Training loss: 1.016087529425752
Validation loss: 2.5051989507961037

Epoch: 6| Step: 7
Training loss: 1.0634545358105456
Validation loss: 2.4670674338183125

Epoch: 6| Step: 8
Training loss: 0.9822345957083354
Validation loss: 2.4912542837818314

Epoch: 6| Step: 9
Training loss: 1.0844519903901046
Validation loss: 2.4888143636890123

Epoch: 6| Step: 10
Training loss: 1.6779696174162528
Validation loss: 2.520601515321783

Epoch: 6| Step: 11
Training loss: 1.3188266858407767
Validation loss: 2.498749536115763

Epoch: 6| Step: 12
Training loss: 1.2532583684179586
Validation loss: 2.479300757904596

Epoch: 6| Step: 13
Training loss: 0.9978067964079601
Validation loss: 2.5046759530007523

Epoch: 247| Step: 0
Training loss: 0.9762606344974796
Validation loss: 2.496085160673769

Epoch: 6| Step: 1
Training loss: 1.0867596813970273
Validation loss: 2.516086807312772

Epoch: 6| Step: 2
Training loss: 1.1868681481491545
Validation loss: 2.520310722925008

Epoch: 6| Step: 3
Training loss: 1.2784296022561448
Validation loss: 2.5405331849060873

Epoch: 6| Step: 4
Training loss: 0.9062830162611205
Validation loss: 2.5146383792633427

Epoch: 6| Step: 5
Training loss: 0.7409301547648113
Validation loss: 2.5129324357067464

Epoch: 6| Step: 6
Training loss: 0.9882712080976822
Validation loss: 2.4921572877539893

Epoch: 6| Step: 7
Training loss: 1.3300542395151354
Validation loss: 2.5131439353957727

Epoch: 6| Step: 8
Training loss: 1.7895341942657281
Validation loss: 2.492190147283028

Epoch: 6| Step: 9
Training loss: 0.9097790243325791
Validation loss: 2.5097913556004725

Epoch: 6| Step: 10
Training loss: 0.7941782329340176
Validation loss: 2.465785060140389

Epoch: 6| Step: 11
Training loss: 1.200552481387928
Validation loss: 2.4739895878335774

Epoch: 6| Step: 12
Training loss: 1.2459843028443698
Validation loss: 2.4567159612829235

Epoch: 6| Step: 13
Training loss: 1.1593713127961867
Validation loss: 2.4501518922130416

Epoch: 248| Step: 0
Training loss: 1.073894770924584
Validation loss: 2.4496027051552636

Epoch: 6| Step: 1
Training loss: 1.1352836227629506
Validation loss: 2.466201020843972

Epoch: 6| Step: 2
Training loss: 0.8973086355526949
Validation loss: 2.457153473259278

Epoch: 6| Step: 3
Training loss: 1.2089421722490639
Validation loss: 2.4613159274167953

Epoch: 6| Step: 4
Training loss: 0.7731132212846381
Validation loss: 2.4860801198349183

Epoch: 6| Step: 5
Training loss: 0.9271053711632822
Validation loss: 2.5015834777263586

Epoch: 6| Step: 6
Training loss: 0.5594023607264907
Validation loss: 2.469457496667847

Epoch: 6| Step: 7
Training loss: 1.0279889419643702
Validation loss: 2.5014233013895373

Epoch: 6| Step: 8
Training loss: 1.213868365973885
Validation loss: 2.478908279933292

Epoch: 6| Step: 9
Training loss: 1.5890790520240152
Validation loss: 2.4748986756387508

Epoch: 6| Step: 10
Training loss: 1.1899812775429326
Validation loss: 2.512237110035803

Epoch: 6| Step: 11
Training loss: 1.1594906320000178
Validation loss: 2.503940790583919

Epoch: 6| Step: 12
Training loss: 1.3301375007540275
Validation loss: 2.5244078331768103

Epoch: 6| Step: 13
Training loss: 1.0528492484468701
Validation loss: 2.524923693773966

Epoch: 249| Step: 0
Training loss: 1.146334636729273
Validation loss: 2.5029610305602086

Epoch: 6| Step: 1
Training loss: 1.689370566759915
Validation loss: 2.4745676102343075

Epoch: 6| Step: 2
Training loss: 0.5689395682938361
Validation loss: 2.452333883291619

Epoch: 6| Step: 3
Training loss: 0.9024848002054651
Validation loss: 2.4641231889504165

Epoch: 6| Step: 4
Training loss: 1.232986876867275
Validation loss: 2.467659098759438

Epoch: 6| Step: 5
Training loss: 1.277780533985722
Validation loss: 2.4640703357062117

Epoch: 6| Step: 6
Training loss: 0.9363722694121891
Validation loss: 2.4446633892817173

Epoch: 6| Step: 7
Training loss: 0.9811755060966606
Validation loss: 2.466632168788289

Epoch: 6| Step: 8
Training loss: 0.9836453352316938
Validation loss: 2.488067588416728

Epoch: 6| Step: 9
Training loss: 0.992374402562202
Validation loss: 2.4857533457694276

Epoch: 6| Step: 10
Training loss: 1.0572712650429108
Validation loss: 2.499895298723975

Epoch: 6| Step: 11
Training loss: 0.8557492497402137
Validation loss: 2.475511110278489

Epoch: 6| Step: 12
Training loss: 0.9717752534270554
Validation loss: 2.4695416789790317

Epoch: 6| Step: 13
Training loss: 1.257906702909193
Validation loss: 2.4673258800470768

Epoch: 250| Step: 0
Training loss: 1.1781936686206955
Validation loss: 2.4886219462841295

Epoch: 6| Step: 1
Training loss: 0.940307102156182
Validation loss: 2.4849069997913436

Epoch: 6| Step: 2
Training loss: 1.0312075172690414
Validation loss: 2.496143893183828

Epoch: 6| Step: 3
Training loss: 0.8613042849746919
Validation loss: 2.510273000304482

Epoch: 6| Step: 4
Training loss: 0.8812988267723454
Validation loss: 2.4871619400220824

Epoch: 6| Step: 5
Training loss: 0.9072272194982147
Validation loss: 2.491363550687817

Epoch: 6| Step: 6
Training loss: 0.8492082021386327
Validation loss: 2.501749941861329

Epoch: 6| Step: 7
Training loss: 1.6885659418669319
Validation loss: 2.492677026211835

Epoch: 6| Step: 8
Training loss: 1.0789105414568323
Validation loss: 2.503536268508664

Epoch: 6| Step: 9
Training loss: 1.1264571184241492
Validation loss: 2.4895858761202962

Epoch: 6| Step: 10
Training loss: 1.321482619538975
Validation loss: 2.4851574317379566

Epoch: 6| Step: 11
Training loss: 0.8331747301488188
Validation loss: 2.490863971298297

Epoch: 6| Step: 12
Training loss: 1.2066425080190522
Validation loss: 2.4736173910148973

Epoch: 6| Step: 13
Training loss: 0.4908284846580707
Validation loss: 2.450224504110681

Epoch: 251| Step: 0
Training loss: 1.9445316938474093
Validation loss: 2.44359512144637

Epoch: 6| Step: 1
Training loss: 1.1522226560943958
Validation loss: 2.454652681436207

Epoch: 6| Step: 2
Training loss: 1.2527492806594906
Validation loss: 2.4330626570091027

Epoch: 6| Step: 3
Training loss: 0.8365453132514068
Validation loss: 2.442311461679491

Epoch: 6| Step: 4
Training loss: 0.7928229512693731
Validation loss: 2.4651973516168884

Epoch: 6| Step: 5
Training loss: 0.9140297647466933
Validation loss: 2.446686268999217

Epoch: 6| Step: 6
Training loss: 1.3155619916529346
Validation loss: 2.453072790788578

Epoch: 6| Step: 7
Training loss: 1.0235245645777773
Validation loss: 2.4732922178078898

Epoch: 6| Step: 8
Training loss: 0.7638690040389261
Validation loss: 2.5167517640802104

Epoch: 6| Step: 9
Training loss: 0.8235877636464135
Validation loss: 2.518945771543061

Epoch: 6| Step: 10
Training loss: 1.0156988263807607
Validation loss: 2.5193098215932994

Epoch: 6| Step: 11
Training loss: 0.9293346216169136
Validation loss: 2.5291631581780036

Epoch: 6| Step: 12
Training loss: 0.8720942341256422
Validation loss: 2.52050267861816

Epoch: 6| Step: 13
Training loss: 1.0286960187170238
Validation loss: 2.489133729281084

Epoch: 252| Step: 0
Training loss: 0.7837979538406331
Validation loss: 2.4734398255859946

Epoch: 6| Step: 1
Training loss: 0.9511111512275738
Validation loss: 2.4704881766467377

Epoch: 6| Step: 2
Training loss: 1.6762548102097188
Validation loss: 2.420228107215347

Epoch: 6| Step: 3
Training loss: 0.8209290866544117
Validation loss: 2.440763827818148

Epoch: 6| Step: 4
Training loss: 1.0972761806198958
Validation loss: 2.4228038984607396

Epoch: 6| Step: 5
Training loss: 1.153926267043501
Validation loss: 2.4385923604637108

Epoch: 6| Step: 6
Training loss: 1.469879689905065
Validation loss: 2.442320965445705

Epoch: 6| Step: 7
Training loss: 1.0473987920116417
Validation loss: 2.466080164969283

Epoch: 6| Step: 8
Training loss: 0.9086763195197759
Validation loss: 2.472312756292093

Epoch: 6| Step: 9
Training loss: 0.7708641939601197
Validation loss: 2.514782198231528

Epoch: 6| Step: 10
Training loss: 0.7495044819734102
Validation loss: 2.497672299685344

Epoch: 6| Step: 11
Training loss: 1.3731951572447272
Validation loss: 2.530777930110873

Epoch: 6| Step: 12
Training loss: 1.010227651056698
Validation loss: 2.508784353236422

Epoch: 6| Step: 13
Training loss: 0.6532594569762976
Validation loss: 2.5149818331454696

Epoch: 253| Step: 0
Training loss: 0.8837268786393583
Validation loss: 2.5048720948320775

Epoch: 6| Step: 1
Training loss: 1.0908200939318269
Validation loss: 2.5347049185675012

Epoch: 6| Step: 2
Training loss: 1.2697471083014589
Validation loss: 2.533598326676378

Epoch: 6| Step: 3
Training loss: 1.5510126897266951
Validation loss: 2.5360898296847485

Epoch: 6| Step: 4
Training loss: 1.0123626545187359
Validation loss: 2.523660359709966

Epoch: 6| Step: 5
Training loss: 0.7189901199616995
Validation loss: 2.4460268890083072

Epoch: 6| Step: 6
Training loss: 0.872824894550411
Validation loss: 2.4579410987433805

Epoch: 6| Step: 7
Training loss: 1.1161238935945512
Validation loss: 2.4547771708261963

Epoch: 6| Step: 8
Training loss: 1.1675580173265683
Validation loss: 2.442642359703366

Epoch: 6| Step: 9
Training loss: 0.7905783492487077
Validation loss: 2.4273988345376547

Epoch: 6| Step: 10
Training loss: 1.1378228242987742
Validation loss: 2.4201328824835304

Epoch: 6| Step: 11
Training loss: 0.9249754348276702
Validation loss: 2.443050499529032

Epoch: 6| Step: 12
Training loss: 1.1571001072291538
Validation loss: 2.441822582948957

Epoch: 6| Step: 13
Training loss: 0.5649929962736865
Validation loss: 2.4671578372519685

Epoch: 254| Step: 0
Training loss: 0.9637400689213292
Validation loss: 2.4528517018601166

Epoch: 6| Step: 1
Training loss: 0.9580215624212358
Validation loss: 2.4616295178306844

Epoch: 6| Step: 2
Training loss: 1.0730070181027835
Validation loss: 2.461021457066209

Epoch: 6| Step: 3
Training loss: 0.6823689414567914
Validation loss: 2.4862259650964007

Epoch: 6| Step: 4
Training loss: 0.8916856907808609
Validation loss: 2.516097473643929

Epoch: 6| Step: 5
Training loss: 1.3955220354555335
Validation loss: 2.5224844277151437

Epoch: 6| Step: 6
Training loss: 1.7913652284752435
Validation loss: 2.4989711115781565

Epoch: 6| Step: 7
Training loss: 0.7753781718832323
Validation loss: 2.491634426209479

Epoch: 6| Step: 8
Training loss: 0.786119164768956
Validation loss: 2.5298865852160595

Epoch: 6| Step: 9
Training loss: 0.9349010683442648
Validation loss: 2.527905194642907

Epoch: 6| Step: 10
Training loss: 1.034576368755282
Validation loss: 2.524992127367156

Epoch: 6| Step: 11
Training loss: 1.0672351005516771
Validation loss: 2.5020829680557135

Epoch: 6| Step: 12
Training loss: 0.8745759208792773
Validation loss: 2.4981782048651695

Epoch: 6| Step: 13
Training loss: 0.6144417394903695
Validation loss: 2.4413393986563006

Epoch: 255| Step: 0
Training loss: 0.7650589699549604
Validation loss: 2.450340618407957

Epoch: 6| Step: 1
Training loss: 0.890936144637432
Validation loss: 2.4463384769898258

Epoch: 6| Step: 2
Training loss: 0.9945381134347753
Validation loss: 2.444725936293429

Epoch: 6| Step: 3
Training loss: 0.9203716887269818
Validation loss: 2.459210802518262

Epoch: 6| Step: 4
Training loss: 1.1201611936749856
Validation loss: 2.408450746730982

Epoch: 6| Step: 5
Training loss: 0.8989264111617666
Validation loss: 2.4359745293214505

Epoch: 6| Step: 6
Training loss: 1.0471049383636273
Validation loss: 2.4542048204182176

Epoch: 6| Step: 7
Training loss: 1.012674359037688
Validation loss: 2.4734423017062337

Epoch: 6| Step: 8
Training loss: 0.9473533353803503
Validation loss: 2.481887295229181

Epoch: 6| Step: 9
Training loss: 0.5985297507952091
Validation loss: 2.4669068245836354

Epoch: 6| Step: 10
Training loss: 1.1259596758036896
Validation loss: 2.4971168384725826

Epoch: 6| Step: 11
Training loss: 0.974539500084311
Validation loss: 2.4732960736950598

Epoch: 6| Step: 12
Training loss: 1.6205803851111285
Validation loss: 2.4703708809047233

Epoch: 6| Step: 13
Training loss: 0.9545964311533419
Validation loss: 2.494678101588146

Epoch: 256| Step: 0
Training loss: 0.8329374366360068
Validation loss: 2.4861604137951057

Epoch: 6| Step: 1
Training loss: 0.9912378767890923
Validation loss: 2.4870946806538976

Epoch: 6| Step: 2
Training loss: 0.7559763894203866
Validation loss: 2.5173194450878373

Epoch: 6| Step: 3
Training loss: 0.6130037348028292
Validation loss: 2.472460977274644

Epoch: 6| Step: 4
Training loss: 0.9679890381885963
Validation loss: 2.442921847695311

Epoch: 6| Step: 5
Training loss: 1.6871610230376561
Validation loss: 2.4469509769199833

Epoch: 6| Step: 6
Training loss: 0.866892927846643
Validation loss: 2.4532248651270883

Epoch: 6| Step: 7
Training loss: 1.2617352369430028
Validation loss: 2.45298639306552

Epoch: 6| Step: 8
Training loss: 0.9246785481681306
Validation loss: 2.4314182778638544

Epoch: 6| Step: 9
Training loss: 0.7655218405221011
Validation loss: 2.4047484169429314

Epoch: 6| Step: 10
Training loss: 0.6945195552154564
Validation loss: 2.396344995278623

Epoch: 6| Step: 11
Training loss: 1.2214968122892753
Validation loss: 2.405223777825616

Epoch: 6| Step: 12
Training loss: 1.1801531548436115
Validation loss: 2.412428247004368

Epoch: 6| Step: 13
Training loss: 0.7215182855606055
Validation loss: 2.4206432204410704

Epoch: 257| Step: 0
Training loss: 0.9846348495232901
Validation loss: 2.378330167089091

Epoch: 6| Step: 1
Training loss: 0.8170033147037271
Validation loss: 2.4448774088883596

Epoch: 6| Step: 2
Training loss: 0.7298113879095439
Validation loss: 2.4329707996465624

Epoch: 6| Step: 3
Training loss: 1.149667405670657
Validation loss: 2.4259939331836256

Epoch: 6| Step: 4
Training loss: 0.8903733282709501
Validation loss: 2.5154883239871224

Epoch: 6| Step: 5
Training loss: 0.9398534480963617
Validation loss: 2.464542161733919

Epoch: 6| Step: 6
Training loss: 1.639676573774933
Validation loss: 2.5090017421653603

Epoch: 6| Step: 7
Training loss: 0.527944011261055
Validation loss: 2.535997001654458

Epoch: 6| Step: 8
Training loss: 1.361132833519425
Validation loss: 2.523284457410648

Epoch: 6| Step: 9
Training loss: 1.04481873760859
Validation loss: 2.512410865108258

Epoch: 6| Step: 10
Training loss: 0.6970813197760298
Validation loss: 2.4835414570358383

Epoch: 6| Step: 11
Training loss: 1.100931839290882
Validation loss: 2.4522168984378365

Epoch: 6| Step: 12
Training loss: 0.9189684030872893
Validation loss: 2.4696991107091515

Epoch: 6| Step: 13
Training loss: 0.6772619574242121
Validation loss: 2.4604987713579156

Epoch: 258| Step: 0
Training loss: 1.0902584476471695
Validation loss: 2.4371353141643253

Epoch: 6| Step: 1
Training loss: 0.8521594483780911
Validation loss: 2.4521412002429823

Epoch: 6| Step: 2
Training loss: 1.024871811177978
Validation loss: 2.455281944023637

Epoch: 6| Step: 3
Training loss: 1.0607679498445257
Validation loss: 2.436084541952813

Epoch: 6| Step: 4
Training loss: 0.8388327967885004
Validation loss: 2.453218103913306

Epoch: 6| Step: 5
Training loss: 0.7101351223898849
Validation loss: 2.4653456405950234

Epoch: 6| Step: 6
Training loss: 1.1382558595945136
Validation loss: 2.4551876695432253

Epoch: 6| Step: 7
Training loss: 0.6593009554613186
Validation loss: 2.4432849316765846

Epoch: 6| Step: 8
Training loss: 1.0382357298184703
Validation loss: 2.4802412026088

Epoch: 6| Step: 9
Training loss: 0.9755048594038473
Validation loss: 2.457476485002624

Epoch: 6| Step: 10
Training loss: 0.8678305020523944
Validation loss: 2.4721044293271883

Epoch: 6| Step: 11
Training loss: 1.5590175731223954
Validation loss: 2.4758744882642185

Epoch: 6| Step: 12
Training loss: 0.822398521575174
Validation loss: 2.441498882021236

Epoch: 6| Step: 13
Training loss: 0.8168363761380766
Validation loss: 2.4539833241946054

Epoch: 259| Step: 0
Training loss: 0.7652292980670223
Validation loss: 2.465817168534406

Epoch: 6| Step: 1
Training loss: 0.786779822182836
Validation loss: 2.4804638241877313

Epoch: 6| Step: 2
Training loss: 1.10902329363494
Validation loss: 2.4703740813401964

Epoch: 6| Step: 3
Training loss: 1.6000574995676273
Validation loss: 2.497791186149294

Epoch: 6| Step: 4
Training loss: 0.8796374183072008
Validation loss: 2.490996795471828

Epoch: 6| Step: 5
Training loss: 0.9720660031165467
Validation loss: 2.4927165016185255

Epoch: 6| Step: 6
Training loss: 0.6636152668790838
Validation loss: 2.5196581996214933

Epoch: 6| Step: 7
Training loss: 0.5833405482890485
Validation loss: 2.5176944280504263

Epoch: 6| Step: 8
Training loss: 1.0418971124692695
Validation loss: 2.499180991855165

Epoch: 6| Step: 9
Training loss: 0.9854584740822275
Validation loss: 2.486979961776327

Epoch: 6| Step: 10
Training loss: 1.1179057660011555
Validation loss: 2.5040899743046663

Epoch: 6| Step: 11
Training loss: 0.9324688059419028
Validation loss: 2.4801844982974752

Epoch: 6| Step: 12
Training loss: 0.8929971258238945
Validation loss: 2.4305775928426074

Epoch: 6| Step: 13
Training loss: 1.1057140496050588
Validation loss: 2.4310766998780737

Epoch: 260| Step: 0
Training loss: 0.8245856024614686
Validation loss: 2.441782954598533

Epoch: 6| Step: 1
Training loss: 1.0495424590733942
Validation loss: 2.4048657718095146

Epoch: 6| Step: 2
Training loss: 0.5989509471493174
Validation loss: 2.410793410421671

Epoch: 6| Step: 3
Training loss: 0.7431266464458992
Validation loss: 2.41031868477456

Epoch: 6| Step: 4
Training loss: 1.0447218088443742
Validation loss: 2.4363240017949157

Epoch: 6| Step: 5
Training loss: 0.9705116497600358
Validation loss: 2.412984881289022

Epoch: 6| Step: 6
Training loss: 1.2484168040215637
Validation loss: 2.452080046267264

Epoch: 6| Step: 7
Training loss: 0.7313727023216227
Validation loss: 2.453944787013359

Epoch: 6| Step: 8
Training loss: 0.861305565225038
Validation loss: 2.442294374173806

Epoch: 6| Step: 9
Training loss: 1.103321483717459
Validation loss: 2.4620539822697958

Epoch: 6| Step: 10
Training loss: 0.7673200411232189
Validation loss: 2.4496047815168116

Epoch: 6| Step: 11
Training loss: 0.784054376796516
Validation loss: 2.4737781127847134

Epoch: 6| Step: 12
Training loss: 1.6621677554285186
Validation loss: 2.483294752038337

Epoch: 6| Step: 13
Training loss: 0.5425226313621256
Validation loss: 2.495006237521603

Epoch: 261| Step: 0
Training loss: 0.7215242747626776
Validation loss: 2.4877772367562203

Epoch: 6| Step: 1
Training loss: 0.7339736572262697
Validation loss: 2.516904776096787

Epoch: 6| Step: 2
Training loss: 0.7213345374639665
Validation loss: 2.515719392177913

Epoch: 6| Step: 3
Training loss: 0.7791090813094906
Validation loss: 2.499439502765612

Epoch: 6| Step: 4
Training loss: 1.6246850368732757
Validation loss: 2.531030949014728

Epoch: 6| Step: 5
Training loss: 1.0471546881261444
Validation loss: 2.51401991615927

Epoch: 6| Step: 6
Training loss: 1.0778137531754355
Validation loss: 2.5024796606742

Epoch: 6| Step: 7
Training loss: 0.43449603528232095
Validation loss: 2.490049097132509

Epoch: 6| Step: 8
Training loss: 0.6377809709440585
Validation loss: 2.492087952504962

Epoch: 6| Step: 9
Training loss: 1.2188262915574555
Validation loss: 2.475487258729813

Epoch: 6| Step: 10
Training loss: 0.7893264631147432
Validation loss: 2.4581479885114694

Epoch: 6| Step: 11
Training loss: 0.911849807956025
Validation loss: 2.437457464755198

Epoch: 6| Step: 12
Training loss: 1.0988136244439877
Validation loss: 2.425212834529365

Epoch: 6| Step: 13
Training loss: 1.1340659737343248
Validation loss: 2.4233717353908193

Epoch: 262| Step: 0
Training loss: 0.6256422795778076
Validation loss: 2.434417093901827

Epoch: 6| Step: 1
Training loss: 0.7442640467539651
Validation loss: 2.433683764630004

Epoch: 6| Step: 2
Training loss: 0.7425288569818517
Validation loss: 2.4116835266551693

Epoch: 6| Step: 3
Training loss: 1.6254231562220458
Validation loss: 2.4252952043963796

Epoch: 6| Step: 4
Training loss: 1.0635602933851025
Validation loss: 2.436224921827974

Epoch: 6| Step: 5
Training loss: 0.27492832040778825
Validation loss: 2.4261993427834296

Epoch: 6| Step: 6
Training loss: 0.9592448267395806
Validation loss: 2.4299331919081033

Epoch: 6| Step: 7
Training loss: 0.9625039707448723
Validation loss: 2.4304053320413597

Epoch: 6| Step: 8
Training loss: 0.93650443939892
Validation loss: 2.4644336992835036

Epoch: 6| Step: 9
Training loss: 1.2063903094502009
Validation loss: 2.4992206671350905

Epoch: 6| Step: 10
Training loss: 0.9712706351819057
Validation loss: 2.4741738566293794

Epoch: 6| Step: 11
Training loss: 0.9718144155673942
Validation loss: 2.466852014863438

Epoch: 6| Step: 12
Training loss: 0.9376254315707758
Validation loss: 2.5034441306884894

Epoch: 6| Step: 13
Training loss: 0.6855116397681918
Validation loss: 2.489356123049174

Epoch: 263| Step: 0
Training loss: 0.6856288154516752
Validation loss: 2.473769729929303

Epoch: 6| Step: 1
Training loss: 0.7057411901334248
Validation loss: 2.504839304951733

Epoch: 6| Step: 2
Training loss: 0.9552380012611228
Validation loss: 2.5119505216366886

Epoch: 6| Step: 3
Training loss: 1.040738754241026
Validation loss: 2.50583237941098

Epoch: 6| Step: 4
Training loss: 0.6974521034982388
Validation loss: 2.5388394872319773

Epoch: 6| Step: 5
Training loss: 0.8572911051999027
Validation loss: 2.5072605232364427

Epoch: 6| Step: 6
Training loss: 0.7916889480333043
Validation loss: 2.4861093706228887

Epoch: 6| Step: 7
Training loss: 0.7304261139039131
Validation loss: 2.4981735756543313

Epoch: 6| Step: 8
Training loss: 1.5589446244110086
Validation loss: 2.481683576124845

Epoch: 6| Step: 9
Training loss: 1.2438717346424557
Validation loss: 2.4990489052956026

Epoch: 6| Step: 10
Training loss: 0.9153239357371652
Validation loss: 2.4862785370821046

Epoch: 6| Step: 11
Training loss: 1.1417667474990592
Validation loss: 2.4786567149728573

Epoch: 6| Step: 12
Training loss: 0.6668901267655476
Validation loss: 2.4533114655361863

Epoch: 6| Step: 13
Training loss: 0.822935760051203
Validation loss: 2.453388321988346

Epoch: 264| Step: 0
Training loss: 0.959249797690785
Validation loss: 2.459338579318494

Epoch: 6| Step: 1
Training loss: 0.8740264722036177
Validation loss: 2.4515288478005344

Epoch: 6| Step: 2
Training loss: 0.9708350723207368
Validation loss: 2.4885194828953923

Epoch: 6| Step: 3
Training loss: 1.0941984074897033
Validation loss: 2.4714334036654346

Epoch: 6| Step: 4
Training loss: 0.5538458819508395
Validation loss: 2.4846792315340798

Epoch: 6| Step: 5
Training loss: 0.8361803931902192
Validation loss: 2.494858803133576

Epoch: 6| Step: 6
Training loss: 1.6715940435474577
Validation loss: 2.474894421371195

Epoch: 6| Step: 7
Training loss: 0.7179206126350567
Validation loss: 2.4827520138805923

Epoch: 6| Step: 8
Training loss: 0.8490485082996146
Validation loss: 2.465737052201401

Epoch: 6| Step: 9
Training loss: 0.7565128153480063
Validation loss: 2.4569123048901833

Epoch: 6| Step: 10
Training loss: 0.8379865115771286
Validation loss: 2.469893024098051

Epoch: 6| Step: 11
Training loss: 0.7327471608393578
Validation loss: 2.4421368131566643

Epoch: 6| Step: 12
Training loss: 1.0613891741253538
Validation loss: 2.4497379213868173

Epoch: 6| Step: 13
Training loss: 0.4416121112520197
Validation loss: 2.4459418114397256

Epoch: 265| Step: 0
Training loss: 1.0982818449818998
Validation loss: 2.4717764117949557

Epoch: 6| Step: 1
Training loss: 0.9376935759013614
Validation loss: 2.501145561846929

Epoch: 6| Step: 2
Training loss: 0.93856058528573
Validation loss: 2.4857864296958008

Epoch: 6| Step: 3
Training loss: 0.6728945249176305
Validation loss: 2.466168390409048

Epoch: 6| Step: 4
Training loss: 0.7941839368636239
Validation loss: 2.485315942479817

Epoch: 6| Step: 5
Training loss: 1.1835207775018162
Validation loss: 2.486605043151072

Epoch: 6| Step: 6
Training loss: 0.9540343402464005
Validation loss: 2.4901461945600007

Epoch: 6| Step: 7
Training loss: 0.5891239751413918
Validation loss: 2.4880014983077943

Epoch: 6| Step: 8
Training loss: 1.0360894944666355
Validation loss: 2.464943668692201

Epoch: 6| Step: 9
Training loss: 1.5022327971290002
Validation loss: 2.484667464063127

Epoch: 6| Step: 10
Training loss: 0.6139478523059632
Validation loss: 2.483670472797709

Epoch: 6| Step: 11
Training loss: 0.742490686428856
Validation loss: 2.457782440307344

Epoch: 6| Step: 12
Training loss: 0.8692324471993088
Validation loss: 2.4830427807389026

Epoch: 6| Step: 13
Training loss: 0.3537799837325467
Validation loss: 2.4763130053774884

Epoch: 266| Step: 0
Training loss: 1.6384651863047894
Validation loss: 2.489374058692874

Epoch: 6| Step: 1
Training loss: 0.7030095111520963
Validation loss: 2.4743571471088766

Epoch: 6| Step: 2
Training loss: 0.7706953432103057
Validation loss: 2.4964699795512915

Epoch: 6| Step: 3
Training loss: 0.9878974742357834
Validation loss: 2.4724577878355576

Epoch: 6| Step: 4
Training loss: 0.6364808837675007
Validation loss: 2.4670338749238665

Epoch: 6| Step: 5
Training loss: 0.965006640811662
Validation loss: 2.466700438202026

Epoch: 6| Step: 6
Training loss: 0.8243767826387857
Validation loss: 2.461166289424777

Epoch: 6| Step: 7
Training loss: 0.9439492918373052
Validation loss: 2.4540571254097236

Epoch: 6| Step: 8
Training loss: 0.5081670843622916
Validation loss: 2.4577424778611503

Epoch: 6| Step: 9
Training loss: 0.9411944392448964
Validation loss: 2.469414567681488

Epoch: 6| Step: 10
Training loss: 0.8027466636144066
Validation loss: 2.438356001543644

Epoch: 6| Step: 11
Training loss: 0.726769653650323
Validation loss: 2.4600504745257727

Epoch: 6| Step: 12
Training loss: 0.9954195920140897
Validation loss: 2.443214440337726

Epoch: 6| Step: 13
Training loss: 0.9301057403707219
Validation loss: 2.481812533005559

Epoch: 267| Step: 0
Training loss: 0.7122298012758519
Validation loss: 2.4889667221241076

Epoch: 6| Step: 1
Training loss: 0.9210466122072042
Validation loss: 2.4914087835451486

Epoch: 6| Step: 2
Training loss: 0.8166122541660606
Validation loss: 2.480105798102365

Epoch: 6| Step: 3
Training loss: 0.9543013270832881
Validation loss: 2.49928419366257

Epoch: 6| Step: 4
Training loss: 1.613062661350941
Validation loss: 2.4989379195730903

Epoch: 6| Step: 5
Training loss: 0.728617561306287
Validation loss: 2.4986388633684777

Epoch: 6| Step: 6
Training loss: 0.6721659850823261
Validation loss: 2.496191827266894

Epoch: 6| Step: 7
Training loss: 0.9150191949175525
Validation loss: 2.5059783201151054

Epoch: 6| Step: 8
Training loss: 1.124288333862765
Validation loss: 2.486541775728996

Epoch: 6| Step: 9
Training loss: 0.6533317621935553
Validation loss: 2.5151139167359484

Epoch: 6| Step: 10
Training loss: 0.5052310473130607
Validation loss: 2.5109686370848077

Epoch: 6| Step: 11
Training loss: 0.8660100211451282
Validation loss: 2.493931477503434

Epoch: 6| Step: 12
Training loss: 1.1882363094582105
Validation loss: 2.4780514874189645

Epoch: 6| Step: 13
Training loss: 0.5232588904528159
Validation loss: 2.463021798716614

Epoch: 268| Step: 0
Training loss: 0.9022345869080168
Validation loss: 2.4601781123670774

Epoch: 6| Step: 1
Training loss: 0.8370663872600566
Validation loss: 2.4776958660561528

Epoch: 6| Step: 2
Training loss: 0.5837201442476188
Validation loss: 2.506673723048675

Epoch: 6| Step: 3
Training loss: 0.6197001098411725
Validation loss: 2.4716641086190103

Epoch: 6| Step: 4
Training loss: 0.9897605168515419
Validation loss: 2.494305589871623

Epoch: 6| Step: 5
Training loss: 0.6601323230628323
Validation loss: 2.487062912926696

Epoch: 6| Step: 6
Training loss: 0.8146291126418422
Validation loss: 2.4829149311085223

Epoch: 6| Step: 7
Training loss: 0.8998153073160478
Validation loss: 2.4472350959702585

Epoch: 6| Step: 8
Training loss: 1.053118011270307
Validation loss: 2.4483290594384717

Epoch: 6| Step: 9
Training loss: 0.5310860829755273
Validation loss: 2.462810209440748

Epoch: 6| Step: 10
Training loss: 1.7864789006983488
Validation loss: 2.4341422218956565

Epoch: 6| Step: 11
Training loss: 0.7266156987228694
Validation loss: 2.4122739079048006

Epoch: 6| Step: 12
Training loss: 1.0078557914484598
Validation loss: 2.4424836752293486

Epoch: 6| Step: 13
Training loss: 0.42786647550876894
Validation loss: 2.4378352916687573

Epoch: 269| Step: 0
Training loss: 0.6709830773503613
Validation loss: 2.428955900716204

Epoch: 6| Step: 1
Training loss: 0.5621148221174166
Validation loss: 2.45732266653794

Epoch: 6| Step: 2
Training loss: 0.7950244809226102
Validation loss: 2.4135821611580526

Epoch: 6| Step: 3
Training loss: 0.37460697956930333
Validation loss: 2.4557528195114045

Epoch: 6| Step: 4
Training loss: 1.0397365362896651
Validation loss: 2.429356419277472

Epoch: 6| Step: 5
Training loss: 0.7682432830720494
Validation loss: 2.4860731089682098

Epoch: 6| Step: 6
Training loss: 1.0569877124963591
Validation loss: 2.4612266796431355

Epoch: 6| Step: 7
Training loss: 1.7912753882941546
Validation loss: 2.4566931007090558

Epoch: 6| Step: 8
Training loss: 0.8531390304250108
Validation loss: 2.4833770334622103

Epoch: 6| Step: 9
Training loss: 0.6021722205479856
Validation loss: 2.4589019847338487

Epoch: 6| Step: 10
Training loss: 0.7540615099802802
Validation loss: 2.464463746359448

Epoch: 6| Step: 11
Training loss: 0.9293790674280924
Validation loss: 2.521167775315769

Epoch: 6| Step: 12
Training loss: 0.8982225243825193
Validation loss: 2.4600508793850695

Epoch: 6| Step: 13
Training loss: 0.7656201732249797
Validation loss: 2.4929708182753147

Epoch: 270| Step: 0
Training loss: 0.7349098368247079
Validation loss: 2.4874142618873356

Epoch: 6| Step: 1
Training loss: 1.0346383580664413
Validation loss: 2.5065033111450243

Epoch: 6| Step: 2
Training loss: 1.0971200522539077
Validation loss: 2.5115193211743905

Epoch: 6| Step: 3
Training loss: 0.5624713625505737
Validation loss: 2.497195870297709

Epoch: 6| Step: 4
Training loss: 0.7815269742180105
Validation loss: 2.5037648043277945

Epoch: 6| Step: 5
Training loss: 0.7363065519132301
Validation loss: 2.467022428560119

Epoch: 6| Step: 6
Training loss: 0.9904411145248604
Validation loss: 2.48540619633914

Epoch: 6| Step: 7
Training loss: 0.8644607909044099
Validation loss: 2.47899000062831

Epoch: 6| Step: 8
Training loss: 0.6477212972152419
Validation loss: 2.479913719117292

Epoch: 6| Step: 9
Training loss: 1.7028571801949093
Validation loss: 2.4573835752904385

Epoch: 6| Step: 10
Training loss: 0.6167836860082534
Validation loss: 2.4766463072777496

Epoch: 6| Step: 11
Training loss: 0.30787521923892186
Validation loss: 2.5211772380715662

Epoch: 6| Step: 12
Training loss: 0.7185766176826199
Validation loss: 2.4743281855560775

Epoch: 6| Step: 13
Training loss: 1.0454119237308448
Validation loss: 2.499573867637681

Epoch: 271| Step: 0
Training loss: 0.5360708287719409
Validation loss: 2.5322786765601593

Epoch: 6| Step: 1
Training loss: 0.7213318519491871
Validation loss: 2.4775217153249156

Epoch: 6| Step: 2
Training loss: 0.5610761901351285
Validation loss: 2.4960495058725236

Epoch: 6| Step: 3
Training loss: 0.5609664675742815
Validation loss: 2.488837273259843

Epoch: 6| Step: 4
Training loss: 0.8391381781918587
Validation loss: 2.5070357756906705

Epoch: 6| Step: 5
Training loss: 0.8017964696451036
Validation loss: 2.4856704839629784

Epoch: 6| Step: 6
Training loss: 0.947773370636277
Validation loss: 2.461225414085518

Epoch: 6| Step: 7
Training loss: 1.1923604677248323
Validation loss: 2.4816954646620744

Epoch: 6| Step: 8
Training loss: 0.9281057477810265
Validation loss: 2.4751219735035854

Epoch: 6| Step: 9
Training loss: 0.6347921982118113
Validation loss: 2.4827178940977364

Epoch: 6| Step: 10
Training loss: 0.8381173776255797
Validation loss: 2.4643965884103296

Epoch: 6| Step: 11
Training loss: 0.8476551952443394
Validation loss: 2.4772116900773677

Epoch: 6| Step: 12
Training loss: 0.7916215247953324
Validation loss: 2.4824256981174244

Epoch: 6| Step: 13
Training loss: 1.9913323455661656
Validation loss: 2.4808419732702314

Epoch: 272| Step: 0
Training loss: 0.7183788419308471
Validation loss: 2.496524675830108

Epoch: 6| Step: 1
Training loss: 0.5224131054239879
Validation loss: 2.4659378402904157

Epoch: 6| Step: 2
Training loss: 0.9608216254609224
Validation loss: 2.509633346499371

Epoch: 6| Step: 3
Training loss: 0.7401672171774127
Validation loss: 2.4804474178343567

Epoch: 6| Step: 4
Training loss: 0.6875124410023796
Validation loss: 2.485299142138483

Epoch: 6| Step: 5
Training loss: 0.8011095072009637
Validation loss: 2.529480774003459

Epoch: 6| Step: 6
Training loss: 1.6770168630881537
Validation loss: 2.4799027446753206

Epoch: 6| Step: 7
Training loss: 0.988649141494146
Validation loss: 2.4922695618947253

Epoch: 6| Step: 8
Training loss: 0.7645342316482627
Validation loss: 2.481158734223379

Epoch: 6| Step: 9
Training loss: 0.9062091226237706
Validation loss: 2.4778111792808994

Epoch: 6| Step: 10
Training loss: 0.6961725038447047
Validation loss: 2.4479861621159955

Epoch: 6| Step: 11
Training loss: 0.9232867148459216
Validation loss: 2.4608670319811985

Epoch: 6| Step: 12
Training loss: 0.3252545093807272
Validation loss: 2.504455556321876

Epoch: 6| Step: 13
Training loss: 0.9297866127332096
Validation loss: 2.492853236805161

Epoch: 273| Step: 0
Training loss: 0.669356705516209
Validation loss: 2.482397504811645

Epoch: 6| Step: 1
Training loss: 0.872633663421366
Validation loss: 2.4938549874863147

Epoch: 6| Step: 2
Training loss: 1.679791185594304
Validation loss: 2.456577411902538

Epoch: 6| Step: 3
Training loss: 0.5772544130988457
Validation loss: 2.4448504970281597

Epoch: 6| Step: 4
Training loss: 0.9428257034889449
Validation loss: 2.487194573333467

Epoch: 6| Step: 5
Training loss: 0.5455525894444814
Validation loss: 2.4359255823563717

Epoch: 6| Step: 6
Training loss: 0.7352495870008608
Validation loss: 2.445991273820654

Epoch: 6| Step: 7
Training loss: 1.0360189046276373
Validation loss: 2.4680059014362814

Epoch: 6| Step: 8
Training loss: 0.5064462916978578
Validation loss: 2.4899668055604667

Epoch: 6| Step: 9
Training loss: 1.009030338175297
Validation loss: 2.4791132751517466

Epoch: 6| Step: 10
Training loss: 0.912628320267587
Validation loss: 2.5167421089705084

Epoch: 6| Step: 11
Training loss: 0.8305777089798065
Validation loss: 2.496609910861231

Epoch: 6| Step: 12
Training loss: 0.7143446216815736
Validation loss: 2.482772431005449

Epoch: 6| Step: 13
Training loss: 0.6547479242012995
Validation loss: 2.472122687168491

Epoch: 274| Step: 0
Training loss: 0.7534607277465616
Validation loss: 2.4657782855412567

Epoch: 6| Step: 1
Training loss: 0.6806866547653979
Validation loss: 2.472482149197879

Epoch: 6| Step: 2
Training loss: 0.7528723708525987
Validation loss: 2.4775958304611487

Epoch: 6| Step: 3
Training loss: 0.811649611083049
Validation loss: 2.4613578743356737

Epoch: 6| Step: 4
Training loss: 0.6432223815148257
Validation loss: 2.4724574404809223

Epoch: 6| Step: 5
Training loss: 0.46511951248921884
Validation loss: 2.4797284041472456

Epoch: 6| Step: 6
Training loss: 0.5543447160674236
Validation loss: 2.476389074459464

Epoch: 6| Step: 7
Training loss: 0.5082995206760456
Validation loss: 2.5265741583491086

Epoch: 6| Step: 8
Training loss: 0.8374108494807638
Validation loss: 2.489657687498211

Epoch: 6| Step: 9
Training loss: 1.0046976139396036
Validation loss: 2.4736794681253507

Epoch: 6| Step: 10
Training loss: 1.8338173819697612
Validation loss: 2.475350568348687

Epoch: 6| Step: 11
Training loss: 0.7231507954657784
Validation loss: 2.4714330831368674

Epoch: 6| Step: 12
Training loss: 1.0430728131788474
Validation loss: 2.4762843262953305

Epoch: 6| Step: 13
Training loss: 0.8014802812493498
Validation loss: 2.4843306637775076

Epoch: 275| Step: 0
Training loss: 0.6763281400878172
Validation loss: 2.4492481437502844

Epoch: 6| Step: 1
Training loss: 0.9572064297778556
Validation loss: 2.4618794867847558

Epoch: 6| Step: 2
Training loss: 0.6163440687486946
Validation loss: 2.468657821444272

Epoch: 6| Step: 3
Training loss: 0.762012209972168
Validation loss: 2.4359748187338086

Epoch: 6| Step: 4
Training loss: 0.5507404231097255
Validation loss: 2.4465794119066095

Epoch: 6| Step: 5
Training loss: 0.846794041497679
Validation loss: 2.462160150590216

Epoch: 6| Step: 6
Training loss: 0.886026591239911
Validation loss: 2.48035934215999

Epoch: 6| Step: 7
Training loss: 0.8516619562988015
Validation loss: 2.5021380336902115

Epoch: 6| Step: 8
Training loss: 0.49267532756924415
Validation loss: 2.512997383281578

Epoch: 6| Step: 9
Training loss: 1.7968309479994151
Validation loss: 2.5072931526209294

Epoch: 6| Step: 10
Training loss: 0.8549316322587669
Validation loss: 2.503319346613311

Epoch: 6| Step: 11
Training loss: 0.926487070136473
Validation loss: 2.4933214606723584

Epoch: 6| Step: 12
Training loss: 0.6355408145964938
Validation loss: 2.502420619443072

Epoch: 6| Step: 13
Training loss: 0.3616831916485244
Validation loss: 2.5010912713060174

Epoch: 276| Step: 0
Training loss: 0.6018257060716055
Validation loss: 2.458282561600865

Epoch: 6| Step: 1
Training loss: 0.7771717437140906
Validation loss: 2.4522669697005255

Epoch: 6| Step: 2
Training loss: 0.5983535588210033
Validation loss: 2.458546077275033

Epoch: 6| Step: 3
Training loss: 1.6235951439810474
Validation loss: 2.449748695038185

Epoch: 6| Step: 4
Training loss: 0.9649116399563634
Validation loss: 2.4153408413669797

Epoch: 6| Step: 5
Training loss: 0.8737662336508664
Validation loss: 2.4311490426477556

Epoch: 6| Step: 6
Training loss: 1.0272910100939563
Validation loss: 2.4735643364335207

Epoch: 6| Step: 7
Training loss: 0.8272087498534124
Validation loss: 2.4502315979334384

Epoch: 6| Step: 8
Training loss: 0.7293210728967152
Validation loss: 2.4877469575535267

Epoch: 6| Step: 9
Training loss: 0.5437483645008966
Validation loss: 2.4767841568452065

Epoch: 6| Step: 10
Training loss: 0.9439723075102316
Validation loss: 2.4976160655353183

Epoch: 6| Step: 11
Training loss: 0.7333971777853071
Validation loss: 2.4966817625380657

Epoch: 6| Step: 12
Training loss: 0.567119491325061
Validation loss: 2.4872491440141373

Epoch: 6| Step: 13
Training loss: 0.5943349917852755
Validation loss: 2.469583171639898

Epoch: 277| Step: 0
Training loss: 0.8780810063429548
Validation loss: 2.457451275412251

Epoch: 6| Step: 1
Training loss: 0.6279176796911514
Validation loss: 2.4622299058705277

Epoch: 6| Step: 2
Training loss: 0.7234283446686307
Validation loss: 2.449466125050689

Epoch: 6| Step: 3
Training loss: 0.9007292336286373
Validation loss: 2.439299968226704

Epoch: 6| Step: 4
Training loss: 0.5567685164381684
Validation loss: 2.425869090082201

Epoch: 6| Step: 5
Training loss: 0.8340496243183019
Validation loss: 2.4315103762783847

Epoch: 6| Step: 6
Training loss: 0.6357137084770031
Validation loss: 2.43232206846589

Epoch: 6| Step: 7
Training loss: 0.6812416592358597
Validation loss: 2.4177080030029683

Epoch: 6| Step: 8
Training loss: 0.8197200270440643
Validation loss: 2.449579743660716

Epoch: 6| Step: 9
Training loss: 0.7627419666278593
Validation loss: 2.463648199425395

Epoch: 6| Step: 10
Training loss: 1.712519919843444
Validation loss: 2.455503220268729

Epoch: 6| Step: 11
Training loss: 0.8256532019419619
Validation loss: 2.459709643249198

Epoch: 6| Step: 12
Training loss: 0.6799479237769156
Validation loss: 2.480312553786672

Epoch: 6| Step: 13
Training loss: 0.8716278491546005
Validation loss: 2.4930170816634516

Epoch: 278| Step: 0
Training loss: 1.111867549157226
Validation loss: 2.521066222843956

Epoch: 6| Step: 1
Training loss: 0.6929608556390234
Validation loss: 2.4787576313337882

Epoch: 6| Step: 2
Training loss: 1.6655078753717782
Validation loss: 2.5108263691310784

Epoch: 6| Step: 3
Training loss: 0.5337987514360475
Validation loss: 2.497959590230628

Epoch: 6| Step: 4
Training loss: 0.9974643328511608
Validation loss: 2.4450757904371496

Epoch: 6| Step: 5
Training loss: 0.8578818440854239
Validation loss: 2.4679795279573296

Epoch: 6| Step: 6
Training loss: 0.8242150618484204
Validation loss: 2.4806361768417604

Epoch: 6| Step: 7
Training loss: 0.7695355100562207
Validation loss: 2.463098533278287

Epoch: 6| Step: 8
Training loss: 0.5887234893629121
Validation loss: 2.4450095699768988

Epoch: 6| Step: 9
Training loss: 0.6554021808343526
Validation loss: 2.4887678887811853

Epoch: 6| Step: 10
Training loss: 0.6503186343562273
Validation loss: 2.4985041250015443

Epoch: 6| Step: 11
Training loss: 0.601583653858355
Validation loss: 2.4554198366942033

Epoch: 6| Step: 12
Training loss: 0.43980969691877436
Validation loss: 2.4346309422800347

Epoch: 6| Step: 13
Training loss: 0.6502378129576033
Validation loss: 2.4794357421265

Epoch: 279| Step: 0
Training loss: 0.64920683114212
Validation loss: 2.5101537899148787

Epoch: 6| Step: 1
Training loss: 0.7484960576923853
Validation loss: 2.4765878944366966

Epoch: 6| Step: 2
Training loss: 0.8307621549715265
Validation loss: 2.4758741973031606

Epoch: 6| Step: 3
Training loss: 0.6342327992080736
Validation loss: 2.4505660138437486

Epoch: 6| Step: 4
Training loss: 0.42698661554184025
Validation loss: 2.4097829435783775

Epoch: 6| Step: 5
Training loss: 0.9188260559468716
Validation loss: 2.4373102695360895

Epoch: 6| Step: 6
Training loss: 0.6673898474925641
Validation loss: 2.43041504269671

Epoch: 6| Step: 7
Training loss: 1.817494449948071
Validation loss: 2.424380500214781

Epoch: 6| Step: 8
Training loss: 0.9363599521159612
Validation loss: 2.462192279183861

Epoch: 6| Step: 9
Training loss: 0.6883418823970543
Validation loss: 2.446583813907447

Epoch: 6| Step: 10
Training loss: 0.7262408867558034
Validation loss: 2.472455867534097

Epoch: 6| Step: 11
Training loss: 0.8061383694986197
Validation loss: 2.500570902703622

Epoch: 6| Step: 12
Training loss: 0.6307612954064611
Validation loss: 2.4987945003603964

Epoch: 6| Step: 13
Training loss: 0.4490643443240291
Validation loss: 2.5253525541935775

Epoch: 280| Step: 0
Training loss: 0.19327913411122535
Validation loss: 2.554758464852044

Epoch: 6| Step: 1
Training loss: 0.662313289243367
Validation loss: 2.5154236234136973

Epoch: 6| Step: 2
Training loss: 0.9863220818967101
Validation loss: 2.5633870712105815

Epoch: 6| Step: 3
Training loss: 0.8804322960388977
Validation loss: 2.540441510456614

Epoch: 6| Step: 4
Training loss: 0.8412036974267425
Validation loss: 2.4925606224197048

Epoch: 6| Step: 5
Training loss: 0.9041533057519195
Validation loss: 2.4851124502826534

Epoch: 6| Step: 6
Training loss: 1.7053833433776329
Validation loss: 2.449725945258722

Epoch: 6| Step: 7
Training loss: 0.5224244862612849
Validation loss: 2.463471316154525

Epoch: 6| Step: 8
Training loss: 0.7059611869306592
Validation loss: 2.4497572835770245

Epoch: 6| Step: 9
Training loss: 0.728235513052617
Validation loss: 2.4337829633218164

Epoch: 6| Step: 10
Training loss: 0.8335678168055244
Validation loss: 2.4369006612508213

Epoch: 6| Step: 11
Training loss: 0.5835252315636001
Validation loss: 2.458141261697298

Epoch: 6| Step: 12
Training loss: 0.6909352007223353
Validation loss: 2.429191716826133

Epoch: 6| Step: 13
Training loss: 0.33732677005299744
Validation loss: 2.465517828846734

Epoch: 281| Step: 0
Training loss: 0.6588829898686308
Validation loss: 2.4629703925922075

Epoch: 6| Step: 1
Training loss: 0.8494693333758125
Validation loss: 2.447006289494983

Epoch: 6| Step: 2
Training loss: 0.7576667409506058
Validation loss: 2.49618715739948

Epoch: 6| Step: 3
Training loss: 0.8825398251892341
Validation loss: 2.474608305870571

Epoch: 6| Step: 4
Training loss: 0.3418278271420583
Validation loss: 2.5714069560627433

Epoch: 6| Step: 5
Training loss: 0.6737366766311171
Validation loss: 2.534447484998968

Epoch: 6| Step: 6
Training loss: 0.7808793523846381
Validation loss: 2.525144534470617

Epoch: 6| Step: 7
Training loss: 0.8294316905006995
Validation loss: 2.5463027114845356

Epoch: 6| Step: 8
Training loss: 0.6729186623920651
Validation loss: 2.510786995685532

Epoch: 6| Step: 9
Training loss: 1.722252208011146
Validation loss: 2.5038013680411604

Epoch: 6| Step: 10
Training loss: 0.8262153054944729
Validation loss: 2.4638856697372096

Epoch: 6| Step: 11
Training loss: 0.6086637062540097
Validation loss: 2.451780546604706

Epoch: 6| Step: 12
Training loss: 0.6112142584790891
Validation loss: 2.437151885856929

Epoch: 6| Step: 13
Training loss: 0.5842002546183845
Validation loss: 2.441918872068629

Epoch: 282| Step: 0
Training loss: 0.6466361383437084
Validation loss: 2.4017944529651296

Epoch: 6| Step: 1
Training loss: 0.9458641145265576
Validation loss: 2.448531900109757

Epoch: 6| Step: 2
Training loss: 0.30522364126664303
Validation loss: 2.42829112027889

Epoch: 6| Step: 3
Training loss: 0.3937050695367127
Validation loss: 2.4120003249688677

Epoch: 6| Step: 4
Training loss: 1.7450952597907137
Validation loss: 2.44749789001695

Epoch: 6| Step: 5
Training loss: 0.6176345268615696
Validation loss: 2.479039858433056

Epoch: 6| Step: 6
Training loss: 0.6419928763965872
Validation loss: 2.4743450062525323

Epoch: 6| Step: 7
Training loss: 0.8670230056499971
Validation loss: 2.461569211439331

Epoch: 6| Step: 8
Training loss: 0.6516303999029648
Validation loss: 2.5030703661261104

Epoch: 6| Step: 9
Training loss: 0.6364957266736773
Validation loss: 2.487234369726609

Epoch: 6| Step: 10
Training loss: 0.5475831215611855
Validation loss: 2.4533383248148755

Epoch: 6| Step: 11
Training loss: 0.9565782058558017
Validation loss: 2.502090165878404

Epoch: 6| Step: 12
Training loss: 0.7446371909759408
Validation loss: 2.5116466563605617

Epoch: 6| Step: 13
Training loss: 0.9098516781419108
Validation loss: 2.5298270121581066

Epoch: 283| Step: 0
Training loss: 0.5691645316795568
Validation loss: 2.5162368710023575

Epoch: 6| Step: 1
Training loss: 0.2879450566712202
Validation loss: 2.479725329507312

Epoch: 6| Step: 2
Training loss: 1.6568535478801152
Validation loss: 2.496762905089104

Epoch: 6| Step: 3
Training loss: 0.8335640985136485
Validation loss: 2.472144278867337

Epoch: 6| Step: 4
Training loss: 0.7930336159920617
Validation loss: 2.4525020214069677

Epoch: 6| Step: 5
Training loss: 0.6939154960224198
Validation loss: 2.4716410948433767

Epoch: 6| Step: 6
Training loss: 0.7169362278327499
Validation loss: 2.49495300378256

Epoch: 6| Step: 7
Training loss: 0.6397665831968264
Validation loss: 2.459826537523711

Epoch: 6| Step: 8
Training loss: 0.7372286523682121
Validation loss: 2.484967509428065

Epoch: 6| Step: 9
Training loss: 0.8589140262567493
Validation loss: 2.478867012135511

Epoch: 6| Step: 10
Training loss: 0.639103897917704
Validation loss: 2.492289132665066

Epoch: 6| Step: 11
Training loss: 0.7941180389690056
Validation loss: 2.474542634331413

Epoch: 6| Step: 12
Training loss: 0.7873074871478107
Validation loss: 2.466034119786105

Epoch: 6| Step: 13
Training loss: 0.6764416417101976
Validation loss: 2.505042010320134

Epoch: 284| Step: 0
Training loss: 0.8609646053858979
Validation loss: 2.4906817982960736

Epoch: 6| Step: 1
Training loss: 0.5635370919493781
Validation loss: 2.485599129816507

Epoch: 6| Step: 2
Training loss: 0.4604559176818337
Validation loss: 2.4769177500185

Epoch: 6| Step: 3
Training loss: 0.7448562825234711
Validation loss: 2.4807596036302644

Epoch: 6| Step: 4
Training loss: 0.5536141554872155
Validation loss: 2.481965225196113

Epoch: 6| Step: 5
Training loss: 0.9103021463839255
Validation loss: 2.4799623550762617

Epoch: 6| Step: 6
Training loss: 0.5711843019599014
Validation loss: 2.4817361849368136

Epoch: 6| Step: 7
Training loss: 0.78957067310044
Validation loss: 2.5023994918262344

Epoch: 6| Step: 8
Training loss: 0.7508879808980683
Validation loss: 2.507550366136439

Epoch: 6| Step: 9
Training loss: 0.7297394727866963
Validation loss: 2.503845134237083

Epoch: 6| Step: 10
Training loss: 0.7383573381886064
Validation loss: 2.5050385527869556

Epoch: 6| Step: 11
Training loss: 0.6981656119231726
Validation loss: 2.5109383884240013

Epoch: 6| Step: 12
Training loss: 1.6431976492670883
Validation loss: 2.4976590702269945

Epoch: 6| Step: 13
Training loss: 0.7296896466830124
Validation loss: 2.4973961929594255

Epoch: 285| Step: 0
Training loss: 0.9187666651453457
Validation loss: 2.4865374903469495

Epoch: 6| Step: 1
Training loss: 0.4038488144315334
Validation loss: 2.480446184821306

Epoch: 6| Step: 2
Training loss: 0.7131225626684022
Validation loss: 2.479643661994744

Epoch: 6| Step: 3
Training loss: 0.6006564463343249
Validation loss: 2.451690553321663

Epoch: 6| Step: 4
Training loss: 0.6188894057010127
Validation loss: 2.428435963293183

Epoch: 6| Step: 5
Training loss: 0.5171170754326875
Validation loss: 2.498585328416951

Epoch: 6| Step: 6
Training loss: 0.9058791750199373
Validation loss: 2.437997923321089

Epoch: 6| Step: 7
Training loss: 0.6385553469496684
Validation loss: 2.4311896040837353

Epoch: 6| Step: 8
Training loss: 0.5274271581173565
Validation loss: 2.4673237998959476

Epoch: 6| Step: 9
Training loss: 0.7975860863743283
Validation loss: 2.486636753838742

Epoch: 6| Step: 10
Training loss: 0.4274675765206531
Validation loss: 2.4907013866887437

Epoch: 6| Step: 11
Training loss: 0.6324422954351508
Validation loss: 2.5056616192038454

Epoch: 6| Step: 12
Training loss: 1.6400518233554773
Validation loss: 2.5097866466853707

Epoch: 6| Step: 13
Training loss: 1.2658953907671837
Validation loss: 2.523914160702983

Epoch: 286| Step: 0
Training loss: 0.5686857459693906
Validation loss: 2.4986881505848255

Epoch: 6| Step: 1
Training loss: 0.4595820168084073
Validation loss: 2.507718304994677

Epoch: 6| Step: 2
Training loss: 0.5166833016065916
Validation loss: 2.5215670542361908

Epoch: 6| Step: 3
Training loss: 0.8395247097388954
Validation loss: 2.531281888197057

Epoch: 6| Step: 4
Training loss: 0.5474719467988641
Validation loss: 2.508628316136358

Epoch: 6| Step: 5
Training loss: 0.5756440411958649
Validation loss: 2.490808086222917

Epoch: 6| Step: 6
Training loss: 0.7097274627251526
Validation loss: 2.488612356648913

Epoch: 6| Step: 7
Training loss: 0.8357267381452999
Validation loss: 2.461942146743325

Epoch: 6| Step: 8
Training loss: 0.4955295899281514
Validation loss: 2.432356711782686

Epoch: 6| Step: 9
Training loss: 0.5858021389057082
Validation loss: 2.4446376999230535

Epoch: 6| Step: 10
Training loss: 0.8347496077590025
Validation loss: 2.4457588908824914

Epoch: 6| Step: 11
Training loss: 0.8863917348538328
Validation loss: 2.4405856210697343

Epoch: 6| Step: 12
Training loss: 1.8147655665634812
Validation loss: 2.4160206440104255

Epoch: 6| Step: 13
Training loss: 0.47036230640988785
Validation loss: 2.4190517529313373

Epoch: 287| Step: 0
Training loss: 0.60030940442774
Validation loss: 2.4376692690788557

Epoch: 6| Step: 1
Training loss: 0.3615731310785768
Validation loss: 2.417311460029461

Epoch: 6| Step: 2
Training loss: 0.5492929953778716
Validation loss: 2.441762897127102

Epoch: 6| Step: 3
Training loss: 0.8219771796699485
Validation loss: 2.475530884473968

Epoch: 6| Step: 4
Training loss: 0.6278021936629251
Validation loss: 2.466276621168868

Epoch: 6| Step: 5
Training loss: 0.5462351734584707
Validation loss: 2.510475472192242

Epoch: 6| Step: 6
Training loss: 1.6973219534039734
Validation loss: 2.4927516065705797

Epoch: 6| Step: 7
Training loss: 0.5927126506073858
Validation loss: 2.51138070114633

Epoch: 6| Step: 8
Training loss: 0.8501689602715546
Validation loss: 2.5103579880975224

Epoch: 6| Step: 9
Training loss: 0.9162289629260677
Validation loss: 2.5162456503239996

Epoch: 6| Step: 10
Training loss: 0.7970658989924098
Validation loss: 2.4869842345414757

Epoch: 6| Step: 11
Training loss: 0.7503724762738929
Validation loss: 2.511756975911428

Epoch: 6| Step: 12
Training loss: 0.5431144573738036
Validation loss: 2.4774874091681864

Epoch: 6| Step: 13
Training loss: 0.6485438432012598
Validation loss: 2.4861307140145876

Epoch: 288| Step: 0
Training loss: 0.5025363902774458
Validation loss: 2.476107432001753

Epoch: 6| Step: 1
Training loss: 0.7143625192561542
Validation loss: 2.486874955621531

Epoch: 6| Step: 2
Training loss: 0.5588944965989812
Validation loss: 2.493453673792233

Epoch: 6| Step: 3
Training loss: 0.7926483634557898
Validation loss: 2.4936790512346145

Epoch: 6| Step: 4
Training loss: 0.7274508224330581
Validation loss: 2.552069718502679

Epoch: 6| Step: 5
Training loss: 0.7046330703725237
Validation loss: 2.5241719037630803

Epoch: 6| Step: 6
Training loss: 0.8704112163012099
Validation loss: 2.5597547326728205

Epoch: 6| Step: 7
Training loss: 0.6785427845738866
Validation loss: 2.539027740518251

Epoch: 6| Step: 8
Training loss: 0.7453029096134316
Validation loss: 2.52248884563581

Epoch: 6| Step: 9
Training loss: 0.5668980797944897
Validation loss: 2.5323388904719506

Epoch: 6| Step: 10
Training loss: 0.44149495811650824
Validation loss: 2.4750189118684602

Epoch: 6| Step: 11
Training loss: 1.736367395770049
Validation loss: 2.4629546701476692

Epoch: 6| Step: 12
Training loss: 0.7089705873099774
Validation loss: 2.478254173231012

Epoch: 6| Step: 13
Training loss: 0.27192464298531027
Validation loss: 2.4588000537738406

Epoch: 289| Step: 0
Training loss: 0.8400329731532267
Validation loss: 2.456373228110912

Epoch: 6| Step: 1
Training loss: 0.579222590904786
Validation loss: 2.430818859688922

Epoch: 6| Step: 2
Training loss: 0.827873227695398
Validation loss: 2.488489193150338

Epoch: 6| Step: 3
Training loss: 0.6839988598033259
Validation loss: 2.4902563843628136

Epoch: 6| Step: 4
Training loss: 1.5470076224762546
Validation loss: 2.4980529155473925

Epoch: 6| Step: 5
Training loss: 1.04346131541221
Validation loss: 2.4666357305638247

Epoch: 6| Step: 6
Training loss: 0.29467167883642487
Validation loss: 2.462028077123301

Epoch: 6| Step: 7
Training loss: 0.6597724114673723
Validation loss: 2.4722684412159226

Epoch: 6| Step: 8
Training loss: 0.4215512269522668
Validation loss: 2.464073962568866

Epoch: 6| Step: 9
Training loss: 0.6816675131667399
Validation loss: 2.473751117380823

Epoch: 6| Step: 10
Training loss: 0.5767737655422732
Validation loss: 2.452777842948638

Epoch: 6| Step: 11
Training loss: 0.4809538710437103
Validation loss: 2.4880021804335364

Epoch: 6| Step: 12
Training loss: 0.9218870259163302
Validation loss: 2.457946151046091

Epoch: 6| Step: 13
Training loss: 0.461322785038934
Validation loss: 2.471660521935966

Epoch: 290| Step: 0
Training loss: 0.8331315551293884
Validation loss: 2.4285463617563674

Epoch: 6| Step: 1
Training loss: 0.5726053316760158
Validation loss: 2.4284003872921156

Epoch: 6| Step: 2
Training loss: 1.61605375049921
Validation loss: 2.4468796843949345

Epoch: 6| Step: 3
Training loss: 0.653893280812202
Validation loss: 2.434440267912332

Epoch: 6| Step: 4
Training loss: 0.6362783394968001
Validation loss: 2.469768031294608

Epoch: 6| Step: 5
Training loss: 0.610776024281535
Validation loss: 2.4755040153690415

Epoch: 6| Step: 6
Training loss: 0.34896460807434926
Validation loss: 2.461381741462415

Epoch: 6| Step: 7
Training loss: 0.702484920346649
Validation loss: 2.4711281270123986

Epoch: 6| Step: 8
Training loss: 0.8311620120755853
Validation loss: 2.456082036066243

Epoch: 6| Step: 9
Training loss: 0.583730636128482
Validation loss: 2.4912135945678906

Epoch: 6| Step: 10
Training loss: 0.7551202042996793
Validation loss: 2.5102518172465373

Epoch: 6| Step: 11
Training loss: 0.7831276645599847
Validation loss: 2.517124515589578

Epoch: 6| Step: 12
Training loss: 0.793734288998806
Validation loss: 2.520998253169672

Epoch: 6| Step: 13
Training loss: 0.42873373818212074
Validation loss: 2.5000172911835614

Epoch: 291| Step: 0
Training loss: 0.8376011915422507
Validation loss: 2.506378471226778

Epoch: 6| Step: 1
Training loss: 0.3237870110893085
Validation loss: 2.515274185425099

Epoch: 6| Step: 2
Training loss: 0.8174216786467928
Validation loss: 2.501049992834827

Epoch: 6| Step: 3
Training loss: 0.8997279974729282
Validation loss: 2.474093480890273

Epoch: 6| Step: 4
Training loss: 0.804124209085316
Validation loss: 2.4639149311750925

Epoch: 6| Step: 5
Training loss: 0.5098234121958318
Validation loss: 2.469572167899838

Epoch: 6| Step: 6
Training loss: 0.5797307422477752
Validation loss: 2.477210679507459

Epoch: 6| Step: 7
Training loss: 0.7822957478572145
Validation loss: 2.4946583286142614

Epoch: 6| Step: 8
Training loss: 0.38595339630378106
Validation loss: 2.4913942232605284

Epoch: 6| Step: 9
Training loss: 0.7131264910402348
Validation loss: 2.4974668938958478

Epoch: 6| Step: 10
Training loss: 0.6182919531168856
Validation loss: 2.514625193186494

Epoch: 6| Step: 11
Training loss: 1.7079149136980598
Validation loss: 2.5229579366095067

Epoch: 6| Step: 12
Training loss: 0.3296474717233747
Validation loss: 2.4843786199224343

Epoch: 6| Step: 13
Training loss: 0.258172102318271
Validation loss: 2.4917464389172777

Epoch: 292| Step: 0
Training loss: 0.6544401552832994
Validation loss: 2.5160788828061995

Epoch: 6| Step: 1
Training loss: 0.6215911648806679
Validation loss: 2.5079939142197722

Epoch: 6| Step: 2
Training loss: 0.695388189760887
Validation loss: 2.474013456411616

Epoch: 6| Step: 3
Training loss: 0.6716833506642623
Validation loss: 2.497856236706927

Epoch: 6| Step: 4
Training loss: 0.6078743430009947
Validation loss: 2.4909673792593083

Epoch: 6| Step: 5
Training loss: 0.7083747702053459
Validation loss: 2.472392493638456

Epoch: 6| Step: 6
Training loss: 1.5695185385949297
Validation loss: 2.470952633064505

Epoch: 6| Step: 7
Training loss: 0.42379530326923953
Validation loss: 2.513237860747395

Epoch: 6| Step: 8
Training loss: 0.7302916204938905
Validation loss: 2.5120488237965075

Epoch: 6| Step: 9
Training loss: 0.43602688601042033
Validation loss: 2.5031564270130264

Epoch: 6| Step: 10
Training loss: 0.5325516853859557
Validation loss: 2.5072720394781327

Epoch: 6| Step: 11
Training loss: 0.7649623961961443
Validation loss: 2.4887485705059484

Epoch: 6| Step: 12
Training loss: 0.8299424004388887
Validation loss: 2.5126690713957585

Epoch: 6| Step: 13
Training loss: 1.0564273753012503
Validation loss: 2.531097004392713

Epoch: 293| Step: 0
Training loss: 0.9462668905426244
Validation loss: 2.5109223680334876

Epoch: 6| Step: 1
Training loss: 0.69124648840014
Validation loss: 2.481256825303456

Epoch: 6| Step: 2
Training loss: 0.5402247297704429
Validation loss: 2.471751240184404

Epoch: 6| Step: 3
Training loss: 0.6473812324634923
Validation loss: 2.506486510136285

Epoch: 6| Step: 4
Training loss: 0.4721356038596246
Validation loss: 2.501028261682083

Epoch: 6| Step: 5
Training loss: 0.6338643645001955
Validation loss: 2.521820005098893

Epoch: 6| Step: 6
Training loss: 0.6626055948207772
Validation loss: 2.5022748390465406

Epoch: 6| Step: 7
Training loss: 0.49331807668180616
Validation loss: 2.4698420505838583

Epoch: 6| Step: 8
Training loss: 0.6877878626804912
Validation loss: 2.4986410221028375

Epoch: 6| Step: 9
Training loss: 0.6200451426068846
Validation loss: 2.506125517709816

Epoch: 6| Step: 10
Training loss: 0.5502626669663649
Validation loss: 2.476755626577258

Epoch: 6| Step: 11
Training loss: 0.6550486786058203
Validation loss: 2.4613263472927422

Epoch: 6| Step: 12
Training loss: 1.7219893014289722
Validation loss: 2.498342398277387

Epoch: 6| Step: 13
Training loss: 0.4488741506644457
Validation loss: 2.4671595486603746

Epoch: 294| Step: 0
Training loss: 0.452931461437678
Validation loss: 2.481274601487964

Epoch: 6| Step: 1
Training loss: 0.8683607052523865
Validation loss: 2.4774210999349804

Epoch: 6| Step: 2
Training loss: 0.4737558578642375
Validation loss: 2.4828097086303558

Epoch: 6| Step: 3
Training loss: 0.825709147991238
Validation loss: 2.451530811683272

Epoch: 6| Step: 4
Training loss: 0.39265786495096744
Validation loss: 2.478714065483656

Epoch: 6| Step: 5
Training loss: 0.4253474309060067
Validation loss: 2.463031729463474

Epoch: 6| Step: 6
Training loss: 0.6231580294289111
Validation loss: 2.4617542209213013

Epoch: 6| Step: 7
Training loss: 0.48918023322407833
Validation loss: 2.48123924530146

Epoch: 6| Step: 8
Training loss: 0.7628687076574748
Validation loss: 2.4625785323936276

Epoch: 6| Step: 9
Training loss: 0.7850817365066954
Validation loss: 2.494128555776287

Epoch: 6| Step: 10
Training loss: 0.6190656502271411
Validation loss: 2.499719805038559

Epoch: 6| Step: 11
Training loss: 1.6171424601451843
Validation loss: 2.5064073685216353

Epoch: 6| Step: 12
Training loss: 0.8278726157180433
Validation loss: 2.5376092222178586

Epoch: 6| Step: 13
Training loss: 0.33512592978812705
Validation loss: 2.5389969608250715

Epoch: 295| Step: 0
Training loss: 1.610585470428736
Validation loss: 2.5367462250196917

Epoch: 6| Step: 1
Training loss: 0.8786819510884004
Validation loss: 2.47791113686404

Epoch: 6| Step: 2
Training loss: 0.923581177043959
Validation loss: 2.471310308820997

Epoch: 6| Step: 3
Training loss: 0.677411752914882
Validation loss: 2.47003246645568

Epoch: 6| Step: 4
Training loss: 0.49829379673900825
Validation loss: 2.475986193039647

Epoch: 6| Step: 5
Training loss: 0.7057131921478136
Validation loss: 2.4752859617775522

Epoch: 6| Step: 6
Training loss: 0.3257752022307659
Validation loss: 2.4679070702046273

Epoch: 6| Step: 7
Training loss: 0.4315323154354265
Validation loss: 2.432524364804576

Epoch: 6| Step: 8
Training loss: 0.5398318840080812
Validation loss: 2.4465192134098506

Epoch: 6| Step: 9
Training loss: 0.6114980199521338
Validation loss: 2.462791452129213

Epoch: 6| Step: 10
Training loss: 0.6600813738553016
Validation loss: 2.455044127063686

Epoch: 6| Step: 11
Training loss: 0.791119151934766
Validation loss: 2.4819406232820076

Epoch: 6| Step: 12
Training loss: 0.5565400685283158
Validation loss: 2.518021284211573

Epoch: 6| Step: 13
Training loss: 0.5976649763679466
Validation loss: 2.495363760276097

Epoch: 296| Step: 0
Training loss: 0.4973335992782144
Validation loss: 2.495763880361664

Epoch: 6| Step: 1
Training loss: 0.8366551393750814
Validation loss: 2.482042542803401

Epoch: 6| Step: 2
Training loss: 0.6000992454464311
Validation loss: 2.469856694327922

Epoch: 6| Step: 3
Training loss: 0.6855656982619925
Validation loss: 2.4635120806235262

Epoch: 6| Step: 4
Training loss: 0.4102244002626633
Validation loss: 2.4962362675967906

Epoch: 6| Step: 5
Training loss: 0.7991711689050193
Validation loss: 2.4785918261050846

Epoch: 6| Step: 6
Training loss: 0.8205416767965769
Validation loss: 2.453505226955384

Epoch: 6| Step: 7
Training loss: 0.32646004287882335
Validation loss: 2.4966491248781804

Epoch: 6| Step: 8
Training loss: 0.25401474028716786
Validation loss: 2.491984970139559

Epoch: 6| Step: 9
Training loss: 0.6262430703851452
Validation loss: 2.4616761416381623

Epoch: 6| Step: 10
Training loss: 0.6405594024568422
Validation loss: 2.524263478981007

Epoch: 6| Step: 11
Training loss: 1.717275784889663
Validation loss: 2.447305335319862

Epoch: 6| Step: 12
Training loss: 0.36182602265998304
Validation loss: 2.49119423968781

Epoch: 6| Step: 13
Training loss: 0.7604217050115464
Validation loss: 2.509132385233327

Epoch: 297| Step: 0
Training loss: 0.6609453980896068
Validation loss: 2.531958009669196

Epoch: 6| Step: 1
Training loss: 0.9383844336343836
Validation loss: 2.504299573504194

Epoch: 6| Step: 2
Training loss: 1.6287412857208992
Validation loss: 2.5052715477139613

Epoch: 6| Step: 3
Training loss: 0.4489809153011824
Validation loss: 2.4879947780197167

Epoch: 6| Step: 4
Training loss: 0.6372908847634028
Validation loss: 2.505122489619055

Epoch: 6| Step: 5
Training loss: 0.6815108036268042
Validation loss: 2.471877704983586

Epoch: 6| Step: 6
Training loss: 0.5526546784762277
Validation loss: 2.4579267302881562

Epoch: 6| Step: 7
Training loss: 0.5198490060231556
Validation loss: 2.468918156637531

Epoch: 6| Step: 8
Training loss: 0.7940395247713484
Validation loss: 2.4757608886691638

Epoch: 6| Step: 9
Training loss: 0.2839463183523875
Validation loss: 2.4525988377482086

Epoch: 6| Step: 10
Training loss: 0.556105185528076
Validation loss: 2.452621123958579

Epoch: 6| Step: 11
Training loss: 0.4430818403287142
Validation loss: 2.4921698664618956

Epoch: 6| Step: 12
Training loss: 0.5069402098660285
Validation loss: 2.5014919822955477

Epoch: 6| Step: 13
Training loss: 1.0143615493305702
Validation loss: 2.4733309184114214

Epoch: 298| Step: 0
Training loss: 0.6259084298462858
Validation loss: 2.490255714436063

Epoch: 6| Step: 1
Training loss: 0.4660308170320429
Validation loss: 2.494643380343397

Epoch: 6| Step: 2
Training loss: 0.355397793740931
Validation loss: 2.486122816217941

Epoch: 6| Step: 3
Training loss: 0.4247972860458843
Validation loss: 2.516812409566093

Epoch: 6| Step: 4
Training loss: 0.6644604107851445
Validation loss: 2.4934116237065473

Epoch: 6| Step: 5
Training loss: 0.6234664460922074
Validation loss: 2.5136538026828386

Epoch: 6| Step: 6
Training loss: 1.8097879574322233
Validation loss: 2.5371659822061807

Epoch: 6| Step: 7
Training loss: 0.6243326438917653
Validation loss: 2.482881476446505

Epoch: 6| Step: 8
Training loss: 0.6372323334446095
Validation loss: 2.4967694477594926

Epoch: 6| Step: 9
Training loss: 0.49207640711114115
Validation loss: 2.4573653185240842

Epoch: 6| Step: 10
Training loss: 0.43370453390118074
Validation loss: 2.4628444249405925

Epoch: 6| Step: 11
Training loss: 0.4330393021368911
Validation loss: 2.4502453670057163

Epoch: 6| Step: 12
Training loss: 0.7716664932270006
Validation loss: 2.4507846164388334

Epoch: 6| Step: 13
Training loss: 0.880258020808116
Validation loss: 2.436465039174934

Epoch: 299| Step: 0
Training loss: 0.46410927328089296
Validation loss: 2.4759809036837486

Epoch: 6| Step: 1
Training loss: 0.7415610631132291
Validation loss: 2.4102248044154013

Epoch: 6| Step: 2
Training loss: 0.8227920478107347
Validation loss: 2.4662404325113885

Epoch: 6| Step: 3
Training loss: 0.5263897213332349
Validation loss: 2.4718305870102624

Epoch: 6| Step: 4
Training loss: 1.6180362409203828
Validation loss: 2.480862546652305

Epoch: 6| Step: 5
Training loss: 0.5559771147021476
Validation loss: 2.4976441358097197

Epoch: 6| Step: 6
Training loss: 0.48083102516874254
Validation loss: 2.5282461826105025

Epoch: 6| Step: 7
Training loss: 0.39198613487630474
Validation loss: 2.503022457763807

Epoch: 6| Step: 8
Training loss: 0.32384891558308493
Validation loss: 2.495150929157363

Epoch: 6| Step: 9
Training loss: 0.7846890478145475
Validation loss: 2.5315954696012186

Epoch: 6| Step: 10
Training loss: 0.6943639006530186
Validation loss: 2.5120561083843507

Epoch: 6| Step: 11
Training loss: 0.5489490416558994
Validation loss: 2.4807789097121273

Epoch: 6| Step: 12
Training loss: 0.8654199405535387
Validation loss: 2.4993370264068004

Epoch: 6| Step: 13
Training loss: 0.6858340365644567
Validation loss: 2.487670181279214

Epoch: 300| Step: 0
Training loss: 0.49074605250216263
Validation loss: 2.5056719191250463

Epoch: 6| Step: 1
Training loss: 1.6314834223099965
Validation loss: 2.4640494405660607

Epoch: 6| Step: 2
Training loss: 0.7223250996440631
Validation loss: 2.487974986964702

Epoch: 6| Step: 3
Training loss: 0.7370694423061674
Validation loss: 2.508383020686927

Epoch: 6| Step: 4
Training loss: 0.7154512585952996
Validation loss: 2.445237151065578

Epoch: 6| Step: 5
Training loss: 0.5572732375713441
Validation loss: 2.472239307685423

Epoch: 6| Step: 6
Training loss: 0.512477603283413
Validation loss: 2.440442734518623

Epoch: 6| Step: 7
Training loss: 0.5657463702238378
Validation loss: 2.493824017248915

Epoch: 6| Step: 8
Training loss: 0.4388217204724905
Validation loss: 2.492562705165485

Epoch: 6| Step: 9
Training loss: 0.841333673405566
Validation loss: 2.472561161517372

Epoch: 6| Step: 10
Training loss: 0.6376636257740557
Validation loss: 2.4850569774663254

Epoch: 6| Step: 11
Training loss: 0.5516031234089152
Validation loss: 2.4531245516730973

Epoch: 6| Step: 12
Training loss: 0.33730608482049323
Validation loss: 2.5109023595034174

Epoch: 6| Step: 13
Training loss: 0.6064909397228425
Validation loss: 2.45325722882432

Epoch: 301| Step: 0
Training loss: 0.5138086057217719
Validation loss: 2.5072818675562614

Epoch: 6| Step: 1
Training loss: 0.7689511198871459
Validation loss: 2.5253783132771686

Epoch: 6| Step: 2
Training loss: 0.7126531754192997
Validation loss: 2.50614809411055

Epoch: 6| Step: 3
Training loss: 0.6488499536120802
Validation loss: 2.5044196634352303

Epoch: 6| Step: 4
Training loss: 1.6054457317103688
Validation loss: 2.5026976827737237

Epoch: 6| Step: 5
Training loss: 0.7564853963911021
Validation loss: 2.5086762135027127

Epoch: 6| Step: 6
Training loss: 0.6197487765519784
Validation loss: 2.530023295561045

Epoch: 6| Step: 7
Training loss: 0.2742416817838903
Validation loss: 2.49091406692413

Epoch: 6| Step: 8
Training loss: 0.5553779066354476
Validation loss: 2.5313336712898686

Epoch: 6| Step: 9
Training loss: 0.6457334230933651
Validation loss: 2.486266297709568

Epoch: 6| Step: 10
Training loss: 0.44469677034152727
Validation loss: 2.49266517102339

Epoch: 6| Step: 11
Training loss: 0.7488225993398804
Validation loss: 2.4903336249625223

Epoch: 6| Step: 12
Training loss: 0.49663685183781753
Validation loss: 2.4939151443283603

Epoch: 6| Step: 13
Training loss: 0.5283718965347654
Validation loss: 2.484021382038544

Epoch: 302| Step: 0
Training loss: 0.4998463305126189
Validation loss: 2.493070611759642

Epoch: 6| Step: 1
Training loss: 0.9938923164042274
Validation loss: 2.4819696460365166

Epoch: 6| Step: 2
Training loss: 0.6809842247445173
Validation loss: 2.4895224264936577

Epoch: 6| Step: 3
Training loss: 0.22831374812418087
Validation loss: 2.4825436774322713

Epoch: 6| Step: 4
Training loss: 1.6507465407644213
Validation loss: 2.4756153650960466

Epoch: 6| Step: 5
Training loss: 0.5906607924822993
Validation loss: 2.5013020711196745

Epoch: 6| Step: 6
Training loss: 0.1926465816191059
Validation loss: 2.4523708244150324

Epoch: 6| Step: 7
Training loss: 0.6271030805230764
Validation loss: 2.4719780020540956

Epoch: 6| Step: 8
Training loss: 0.5571714848020872
Validation loss: 2.478088568894865

Epoch: 6| Step: 9
Training loss: 0.48428399246245707
Validation loss: 2.502999152599123

Epoch: 6| Step: 10
Training loss: 0.7817767084363909
Validation loss: 2.536342752557316

Epoch: 6| Step: 11
Training loss: 0.3832980988038104
Validation loss: 2.496890243300368

Epoch: 6| Step: 12
Training loss: 0.4355892964732104
Validation loss: 2.496887657470934

Epoch: 6| Step: 13
Training loss: 0.8546262101927409
Validation loss: 2.509965765651413

Epoch: 303| Step: 0
Training loss: 0.6576260943669239
Validation loss: 2.521520965936719

Epoch: 6| Step: 1
Training loss: 0.3017952411241023
Validation loss: 2.505349223052911

Epoch: 6| Step: 2
Training loss: 0.3277743714107538
Validation loss: 2.489309124788308

Epoch: 6| Step: 3
Training loss: 0.7082694997260919
Validation loss: 2.5165060991083523

Epoch: 6| Step: 4
Training loss: 0.8694292596466688
Validation loss: 2.4773549689873153

Epoch: 6| Step: 5
Training loss: 0.45243547856848515
Validation loss: 2.5125741182317904

Epoch: 6| Step: 6
Training loss: 0.7461414821195569
Validation loss: 2.485952495505154

Epoch: 6| Step: 7
Training loss: 0.6240828460448317
Validation loss: 2.50849668308671

Epoch: 6| Step: 8
Training loss: 0.2922585334723051
Validation loss: 2.4941111816243042

Epoch: 6| Step: 9
Training loss: 0.4067718748436691
Validation loss: 2.5201743544373247

Epoch: 6| Step: 10
Training loss: 0.4893322124752041
Validation loss: 2.5187435825797144

Epoch: 6| Step: 11
Training loss: 0.4416637513526332
Validation loss: 2.5040021937524273

Epoch: 6| Step: 12
Training loss: 1.7421785362936795
Validation loss: 2.4831492756005233

Epoch: 6| Step: 13
Training loss: 0.9273885303152495
Validation loss: 2.501869333910596

Epoch: 304| Step: 0
Training loss: 0.5940748631025183
Validation loss: 2.509736780673047

Epoch: 6| Step: 1
Training loss: 0.43438589919433274
Validation loss: 2.5032338791790956

Epoch: 6| Step: 2
Training loss: 0.6692800533584817
Validation loss: 2.4910825098591443

Epoch: 6| Step: 3
Training loss: 0.5447429240092366
Validation loss: 2.5373487188098136

Epoch: 6| Step: 4
Training loss: 0.5518621565468058
Validation loss: 2.503253544474668

Epoch: 6| Step: 5
Training loss: 0.4702988308919399
Validation loss: 2.472472717817473

Epoch: 6| Step: 6
Training loss: 0.8876211808980273
Validation loss: 2.5095026163718894

Epoch: 6| Step: 7
Training loss: 0.6214137182825258
Validation loss: 2.477455195395801

Epoch: 6| Step: 8
Training loss: 0.29604455594570744
Validation loss: 2.4734699824680986

Epoch: 6| Step: 9
Training loss: 0.7375596571894104
Validation loss: 2.4675398841468223

Epoch: 6| Step: 10
Training loss: 0.3767297112331003
Validation loss: 2.4619706836301614

Epoch: 6| Step: 11
Training loss: 0.6025738080113785
Validation loss: 2.467535166028894

Epoch: 6| Step: 12
Training loss: 0.5243860730990116
Validation loss: 2.455051124465984

Epoch: 6| Step: 13
Training loss: 2.270940923912624
Validation loss: 2.4723153050899414

Epoch: 305| Step: 0
Training loss: 0.6762552087692506
Validation loss: 2.4734358113431028

Epoch: 6| Step: 1
Training loss: 0.6955445363205626
Validation loss: 2.4731374798261694

Epoch: 6| Step: 2
Training loss: 0.4055459818116451
Validation loss: 2.518554597415714

Epoch: 6| Step: 3
Training loss: 0.5121426755551786
Validation loss: 2.478793806862481

Epoch: 6| Step: 4
Training loss: 0.5989462450438546
Validation loss: 2.4751815478231953

Epoch: 6| Step: 5
Training loss: 0.2204162032312402
Validation loss: 2.5145758130897966

Epoch: 6| Step: 6
Training loss: 0.6681967898161846
Validation loss: 2.5211253633082453

Epoch: 6| Step: 7
Training loss: 0.44432542390227386
Validation loss: 2.50376795388626

Epoch: 6| Step: 8
Training loss: 0.7529805088332229
Validation loss: 2.518654515194888

Epoch: 6| Step: 9
Training loss: 0.6565019033248981
Validation loss: 2.4875349526215222

Epoch: 6| Step: 10
Training loss: 0.7591339073971379
Validation loss: 2.501454391736769

Epoch: 6| Step: 11
Training loss: 1.6141248810965347
Validation loss: 2.5162483431050378

Epoch: 6| Step: 12
Training loss: 0.7229551779596602
Validation loss: 2.513827276776964

Epoch: 6| Step: 13
Training loss: 0.5465251621079801
Validation loss: 2.5236325330997023

Epoch: 306| Step: 0
Training loss: 0.4951087002901452
Validation loss: 2.4813552947756357

Epoch: 6| Step: 1
Training loss: 0.5974875816746589
Validation loss: 2.4746119214323796

Epoch: 6| Step: 2
Training loss: 0.3742461176602718
Validation loss: 2.471204273741266

Epoch: 6| Step: 3
Training loss: 0.7991135886953004
Validation loss: 2.470107764774918

Epoch: 6| Step: 4
Training loss: 0.5932526262002552
Validation loss: 2.450431595001381

Epoch: 6| Step: 5
Training loss: 0.47774476221727663
Validation loss: 2.481127194271217

Epoch: 6| Step: 6
Training loss: 0.6487102164857526
Validation loss: 2.5002855117360294

Epoch: 6| Step: 7
Training loss: 0.7179964095506711
Validation loss: 2.4722543966053885

Epoch: 6| Step: 8
Training loss: 0.43758834219420617
Validation loss: 2.5283818891267997

Epoch: 6| Step: 9
Training loss: 1.6306035189458334
Validation loss: 2.51395615523754

Epoch: 6| Step: 10
Training loss: 0.5630676266554022
Validation loss: 2.490806313870093

Epoch: 6| Step: 11
Training loss: 0.46598502711771145
Validation loss: 2.5048205466300266

Epoch: 6| Step: 12
Training loss: 0.607443217304295
Validation loss: 2.5128109600696393

Epoch: 6| Step: 13
Training loss: 0.756146083344245
Validation loss: 2.441416551137542

Epoch: 307| Step: 0
Training loss: 0.5754620592534694
Validation loss: 2.4866993482172397

Epoch: 6| Step: 1
Training loss: 1.6443849620858053
Validation loss: 2.471438847976835

Epoch: 6| Step: 2
Training loss: 0.3371510100926737
Validation loss: 2.4742755800902043

Epoch: 6| Step: 3
Training loss: 0.745865991790213
Validation loss: 2.429171530061338

Epoch: 6| Step: 4
Training loss: 0.36491925113872303
Validation loss: 2.4606466871228334

Epoch: 6| Step: 5
Training loss: 0.4260647556076789
Validation loss: 2.4647753407502084

Epoch: 6| Step: 6
Training loss: 0.5736940023317852
Validation loss: 2.467202364657353

Epoch: 6| Step: 7
Training loss: 0.6220682524402947
Validation loss: 2.4654746726906853

Epoch: 6| Step: 8
Training loss: 0.4200744351776036
Validation loss: 2.4731435698111834

Epoch: 6| Step: 9
Training loss: 0.7355598468821806
Validation loss: 2.4940346251649355

Epoch: 6| Step: 10
Training loss: 0.6799310269858093
Validation loss: 2.513044040799542

Epoch: 6| Step: 11
Training loss: 0.5686616650825761
Validation loss: 2.4878885956771146

Epoch: 6| Step: 12
Training loss: 0.6452470446034515
Validation loss: 2.4977391726063245

Epoch: 6| Step: 13
Training loss: 0.4512565335199663
Validation loss: 2.517209720427565

Epoch: 308| Step: 0
Training loss: 0.7191172780935735
Validation loss: 2.493880973734235

Epoch: 6| Step: 1
Training loss: 0.738240760621393
Validation loss: 2.48725251238274

Epoch: 6| Step: 2
Training loss: 0.7166905545164349
Validation loss: 2.4945450037706083

Epoch: 6| Step: 3
Training loss: 0.5578577488089494
Validation loss: 2.5085438093400474

Epoch: 6| Step: 4
Training loss: 0.5304467355376539
Validation loss: 2.4936826566228882

Epoch: 6| Step: 5
Training loss: 1.6804489893618217
Validation loss: 2.500840431379325

Epoch: 6| Step: 6
Training loss: 0.6051206511002583
Validation loss: 2.4744999841931956

Epoch: 6| Step: 7
Training loss: 0.3738419812224465
Validation loss: 2.46610390686772

Epoch: 6| Step: 8
Training loss: 0.3225969634187514
Validation loss: 2.4771602053366792

Epoch: 6| Step: 9
Training loss: 0.4667954225397856
Validation loss: 2.4890242460395857

Epoch: 6| Step: 10
Training loss: 0.5549468656398989
Validation loss: 2.500046079477575

Epoch: 6| Step: 11
Training loss: 0.31791199217409927
Validation loss: 2.504712172813987

Epoch: 6| Step: 12
Training loss: 0.4158568818158968
Validation loss: 2.4945080916436195

Epoch: 6| Step: 13
Training loss: 0.577865671297493
Validation loss: 2.4955939536301774

Epoch: 309| Step: 0
Training loss: 1.6972640798054675
Validation loss: 2.4981458207335074

Epoch: 6| Step: 1
Training loss: 0.4033790157722284
Validation loss: 2.4859961273459135

Epoch: 6| Step: 2
Training loss: 0.5472333823704973
Validation loss: 2.493662447053843

Epoch: 6| Step: 3
Training loss: 0.4367617782113862
Validation loss: 2.4881733417157506

Epoch: 6| Step: 4
Training loss: 0.38810009328196743
Validation loss: 2.4796912507865994

Epoch: 6| Step: 5
Training loss: 0.42571779530702447
Validation loss: 2.4785619497836695

Epoch: 6| Step: 6
Training loss: 0.3744976732388016
Validation loss: 2.4717687569848694

Epoch: 6| Step: 7
Training loss: 0.6024079017764931
Validation loss: 2.480883549740695

Epoch: 6| Step: 8
Training loss: 0.5168277411207027
Validation loss: 2.5121881968107327

Epoch: 6| Step: 9
Training loss: 0.5877176581635432
Validation loss: 2.4876989292810157

Epoch: 6| Step: 10
Training loss: 0.34683574334092004
Validation loss: 2.4693845445103997

Epoch: 6| Step: 11
Training loss: 0.7902168667975583
Validation loss: 2.4676901080454283

Epoch: 6| Step: 12
Training loss: 0.7415732803557813
Validation loss: 2.489134038260924

Epoch: 6| Step: 13
Training loss: 0.6679271885841707
Validation loss: 2.5176938578307437

Epoch: 310| Step: 0
Training loss: 0.7022502968537303
Validation loss: 2.5010666776357593

Epoch: 6| Step: 1
Training loss: 0.5433208504024911
Validation loss: 2.491403600505176

Epoch: 6| Step: 2
Training loss: 0.6655413597461434
Validation loss: 2.555448241906175

Epoch: 6| Step: 3
Training loss: 0.4408776823545731
Validation loss: 2.5095943008923633

Epoch: 6| Step: 4
Training loss: 0.6567999034461022
Validation loss: 2.528014952241097

Epoch: 6| Step: 5
Training loss: 0.40550637043089377
Validation loss: 2.5196183145330484

Epoch: 6| Step: 6
Training loss: 0.5780492681440095
Validation loss: 2.50392020102951

Epoch: 6| Step: 7
Training loss: 0.33101692096815744
Validation loss: 2.521206586014366

Epoch: 6| Step: 8
Training loss: 0.43701328724840727
Validation loss: 2.5320778326959092

Epoch: 6| Step: 9
Training loss: 0.5471883148762438
Validation loss: 2.5336709157923574

Epoch: 6| Step: 10
Training loss: 0.34483415691408903
Validation loss: 2.493930911102086

Epoch: 6| Step: 11
Training loss: 0.5453284056346831
Validation loss: 2.515054713402486

Epoch: 6| Step: 12
Training loss: 1.7074480399049394
Validation loss: 2.506646499977576

Epoch: 6| Step: 13
Training loss: 0.6624001058804732
Validation loss: 2.4910411015551137

Epoch: 311| Step: 0
Training loss: 0.7655548919964913
Validation loss: 2.4881593518502445

Epoch: 6| Step: 1
Training loss: 0.39483879868211114
Validation loss: 2.497361057827276

Epoch: 6| Step: 2
Training loss: 0.3738712170357534
Validation loss: 2.4638069788013497

Epoch: 6| Step: 3
Training loss: 0.5267313757158077
Validation loss: 2.480530773469702

Epoch: 6| Step: 4
Training loss: 0.6903878594533368
Validation loss: 2.4608747618517657

Epoch: 6| Step: 5
Training loss: 0.4917778399285548
Validation loss: 2.4179112532598293

Epoch: 6| Step: 6
Training loss: 0.6609567833290121
Validation loss: 2.4383555830940575

Epoch: 6| Step: 7
Training loss: 1.6459209161302835
Validation loss: 2.4574685545798203

Epoch: 6| Step: 8
Training loss: 0.4097829845958737
Validation loss: 2.459892552954994

Epoch: 6| Step: 9
Training loss: 0.6414907002581448
Validation loss: 2.460247945205534

Epoch: 6| Step: 10
Training loss: 0.5262942573258703
Validation loss: 2.4823025839623547

Epoch: 6| Step: 11
Training loss: 0.46353037602536334
Validation loss: 2.5384191958005817

Epoch: 6| Step: 12
Training loss: 0.5188745636355763
Validation loss: 2.51524994549231

Epoch: 6| Step: 13
Training loss: 0.5525923367839101
Validation loss: 2.5295385147338063

Epoch: 312| Step: 0
Training loss: 0.6045883176227003
Validation loss: 2.52841253746207

Epoch: 6| Step: 1
Training loss: 0.7940740164289835
Validation loss: 2.5196532542731362

Epoch: 6| Step: 2
Training loss: 0.5870295203160342
Validation loss: 2.526298590228404

Epoch: 6| Step: 3
Training loss: 0.6975380501571823
Validation loss: 2.5546039358024824

Epoch: 6| Step: 4
Training loss: 0.506962196338306
Validation loss: 2.539101992316552

Epoch: 6| Step: 5
Training loss: 0.22571655719383274
Validation loss: 2.5057609180117315

Epoch: 6| Step: 6
Training loss: 0.5721703668151178
Validation loss: 2.487712834914344

Epoch: 6| Step: 7
Training loss: 0.4543937481419046
Validation loss: 2.4892833245944366

Epoch: 6| Step: 8
Training loss: 0.4801289356927471
Validation loss: 2.50968339256319

Epoch: 6| Step: 9
Training loss: 0.3512671607634561
Validation loss: 2.4913944753651203

Epoch: 6| Step: 10
Training loss: 0.6275754555325248
Validation loss: 2.472157370058644

Epoch: 6| Step: 11
Training loss: 0.26109137709228186
Validation loss: 2.4504135997785172

Epoch: 6| Step: 12
Training loss: 1.6733099937837672
Validation loss: 2.4777746433139396

Epoch: 6| Step: 13
Training loss: 0.47976987299228824
Validation loss: 2.499690608907188

Epoch: 313| Step: 0
Training loss: 1.6732744438452585
Validation loss: 2.4939359974021404

Epoch: 6| Step: 1
Training loss: 0.6250328055355219
Validation loss: 2.467067587092186

Epoch: 6| Step: 2
Training loss: 0.6512210573365775
Validation loss: 2.4919844537047697

Epoch: 6| Step: 3
Training loss: 0.6028104940473009
Validation loss: 2.4713293759590877

Epoch: 6| Step: 4
Training loss: 0.39641519704066097
Validation loss: 2.522230555528261

Epoch: 6| Step: 5
Training loss: 0.4969601312319459
Validation loss: 2.4809615102031475

Epoch: 6| Step: 6
Training loss: 0.382830385841285
Validation loss: 2.499072321158682

Epoch: 6| Step: 7
Training loss: 0.6930144620696455
Validation loss: 2.4959888314559158

Epoch: 6| Step: 8
Training loss: 0.6920599137427299
Validation loss: 2.5075028378167916

Epoch: 6| Step: 9
Training loss: 0.5737199498287712
Validation loss: 2.5160657888480733

Epoch: 6| Step: 10
Training loss: 0.27219620015181445
Validation loss: 2.520005790917351

Epoch: 6| Step: 11
Training loss: 0.3589785918889671
Validation loss: 2.499108869408967

Epoch: 6| Step: 12
Training loss: 0.5791893260511677
Validation loss: 2.49169433983215

Epoch: 6| Step: 13
Training loss: 0.4739427948245582
Validation loss: 2.5122064572336056

Epoch: 314| Step: 0
Training loss: 0.927884316624897
Validation loss: 2.4683557530215894

Epoch: 6| Step: 1
Training loss: 0.430839035923674
Validation loss: 2.502935099662611

Epoch: 6| Step: 2
Training loss: 0.6482734702510732
Validation loss: 2.4471069380864074

Epoch: 6| Step: 3
Training loss: 0.5551794315375819
Validation loss: 2.451482177410713

Epoch: 6| Step: 4
Training loss: 0.36717278877169596
Validation loss: 2.481886900646074

Epoch: 6| Step: 5
Training loss: 0.4311148777340558
Validation loss: 2.4708702647277105

Epoch: 6| Step: 6
Training loss: 0.4440662445887641
Validation loss: 2.4640118203357058

Epoch: 6| Step: 7
Training loss: 1.6465216617728957
Validation loss: 2.4778464322923948

Epoch: 6| Step: 8
Training loss: 0.48865186740280714
Validation loss: 2.506498275405677

Epoch: 6| Step: 9
Training loss: 0.5619797154784211
Validation loss: 2.4766707961642425

Epoch: 6| Step: 10
Training loss: 0.4025304601824593
Validation loss: 2.501256577729605

Epoch: 6| Step: 11
Training loss: 0.5224483310212442
Validation loss: 2.499313600201999

Epoch: 6| Step: 12
Training loss: 0.37989648240311763
Validation loss: 2.4980799115665415

Epoch: 6| Step: 13
Training loss: 0.5393910719686039
Validation loss: 2.5088002661892963

Epoch: 315| Step: 0
Training loss: 0.4475333399580336
Validation loss: 2.550782908317691

Epoch: 6| Step: 1
Training loss: 0.3756216380370334
Validation loss: 2.513003057618575

Epoch: 6| Step: 2
Training loss: 0.42685043761378494
Validation loss: 2.502199255695714

Epoch: 6| Step: 3
Training loss: 0.43440341101843105
Validation loss: 2.559204391407828

Epoch: 6| Step: 4
Training loss: 0.48138965958209945
Validation loss: 2.5486600388010676

Epoch: 6| Step: 5
Training loss: 1.772812518935638
Validation loss: 2.510017315940022

Epoch: 6| Step: 6
Training loss: 0.5102113258810926
Validation loss: 2.5299064856570124

Epoch: 6| Step: 7
Training loss: 0.5713378885385063
Validation loss: 2.4979933776491823

Epoch: 6| Step: 8
Training loss: 0.5319849148149626
Validation loss: 2.5244863272125277

Epoch: 6| Step: 9
Training loss: 0.5141762407618127
Validation loss: 2.5247215580855933

Epoch: 6| Step: 10
Training loss: 0.5606225790016183
Validation loss: 2.487775748721789

Epoch: 6| Step: 11
Training loss: 0.4599961998253876
Validation loss: 2.49573867333885

Epoch: 6| Step: 12
Training loss: 0.2962891293892128
Validation loss: 2.5284005649141386

Epoch: 6| Step: 13
Training loss: 0.7943335378107386
Validation loss: 2.4854182872892947

Epoch: 316| Step: 0
Training loss: 0.2005817869772879
Validation loss: 2.4675447001761985

Epoch: 6| Step: 1
Training loss: 0.5861067972381034
Validation loss: 2.502976445883938

Epoch: 6| Step: 2
Training loss: 1.6725720530044303
Validation loss: 2.466477343506023

Epoch: 6| Step: 3
Training loss: 0.3423064656501476
Validation loss: 2.4899776398943443

Epoch: 6| Step: 4
Training loss: 0.4564336309215458
Validation loss: 2.4619439575776827

Epoch: 6| Step: 5
Training loss: 0.662784086353097
Validation loss: 2.5175931346435725

Epoch: 6| Step: 6
Training loss: 0.3980668531800626
Validation loss: 2.484516950563366

Epoch: 6| Step: 7
Training loss: 0.6207067615553749
Validation loss: 2.4747490146658375

Epoch: 6| Step: 8
Training loss: 0.4801067756564838
Validation loss: 2.4861127490430115

Epoch: 6| Step: 9
Training loss: 0.6295997160878202
Validation loss: 2.4866863325514137

Epoch: 6| Step: 10
Training loss: 0.2799651414170495
Validation loss: 2.505878037562949

Epoch: 6| Step: 11
Training loss: 0.43994216834202343
Validation loss: 2.5195820810834917

Epoch: 6| Step: 12
Training loss: 0.6223119149768023
Validation loss: 2.4941212188273836

Epoch: 6| Step: 13
Training loss: 0.8267319676797716
Validation loss: 2.544103614779254

Epoch: 317| Step: 0
Training loss: 0.4128070187258911
Validation loss: 2.506216975938071

Epoch: 6| Step: 1
Training loss: 0.5052840743034607
Validation loss: 2.497552528911672

Epoch: 6| Step: 2
Training loss: 1.66702222210421
Validation loss: 2.4871000128589373

Epoch: 6| Step: 3
Training loss: 0.4863878696006631
Validation loss: 2.486011697880521

Epoch: 6| Step: 4
Training loss: 0.6486878888307004
Validation loss: 2.511695255044685

Epoch: 6| Step: 5
Training loss: 0.282776873541733
Validation loss: 2.504911350421182

Epoch: 6| Step: 6
Training loss: 0.5647194837791611
Validation loss: 2.494260575025592

Epoch: 6| Step: 7
Training loss: 0.48538428950354034
Validation loss: 2.514906228273527

Epoch: 6| Step: 8
Training loss: 0.38609047147685754
Validation loss: 2.508703432942651

Epoch: 6| Step: 9
Training loss: 0.45283656970512515
Validation loss: 2.531530270289436

Epoch: 6| Step: 10
Training loss: 0.558142686672562
Validation loss: 2.474503640836152

Epoch: 6| Step: 11
Training loss: 0.5950632129076348
Validation loss: 2.5261638612225137

Epoch: 6| Step: 12
Training loss: 0.5775074108688645
Validation loss: 2.51263028850183

Epoch: 6| Step: 13
Training loss: 0.5305603262912612
Validation loss: 2.537859657930007

Epoch: 318| Step: 0
Training loss: 0.5187289130279723
Validation loss: 2.5279173936600468

Epoch: 6| Step: 1
Training loss: 0.2922027364623914
Validation loss: 2.5411803464313785

Epoch: 6| Step: 2
Training loss: 0.5703715986175074
Validation loss: 2.5622817556073154

Epoch: 6| Step: 3
Training loss: 0.611188537456343
Validation loss: 2.531116106813462

Epoch: 6| Step: 4
Training loss: 1.7042855324674848
Validation loss: 2.5010064539747714

Epoch: 6| Step: 5
Training loss: 0.6549706249711654
Validation loss: 2.492177700862212

Epoch: 6| Step: 6
Training loss: 0.286541500445313
Validation loss: 2.472528615018447

Epoch: 6| Step: 7
Training loss: 0.5394830031134864
Validation loss: 2.460852518614825

Epoch: 6| Step: 8
Training loss: 0.3756947637949534
Validation loss: 2.471128131162148

Epoch: 6| Step: 9
Training loss: 0.3702697037058759
Validation loss: 2.4828677531003946

Epoch: 6| Step: 10
Training loss: 0.20591099868117801
Validation loss: 2.4193670534351965

Epoch: 6| Step: 11
Training loss: 0.4280869933473084
Validation loss: 2.479641623193166

Epoch: 6| Step: 12
Training loss: 0.4762597451251767
Validation loss: 2.441271704331915

Epoch: 6| Step: 13
Training loss: 0.927910589247627
Validation loss: 2.476951985922737

Epoch: 319| Step: 0
Training loss: 0.37510326076413364
Validation loss: 2.4851437555181684

Epoch: 6| Step: 1
Training loss: 0.656559099336557
Validation loss: 2.4713487972033183

Epoch: 6| Step: 2
Training loss: 0.40275463863569083
Validation loss: 2.4932204757248955

Epoch: 6| Step: 3
Training loss: 0.5744248623628772
Validation loss: 2.493250867367021

Epoch: 6| Step: 4
Training loss: 0.3395889467036764
Validation loss: 2.520317660166878

Epoch: 6| Step: 5
Training loss: 0.615260459710237
Validation loss: 2.52139218945226

Epoch: 6| Step: 6
Training loss: 0.4684117209203895
Validation loss: 2.540719112528014

Epoch: 6| Step: 7
Training loss: 0.5445761181860027
Validation loss: 2.523081480159037

Epoch: 6| Step: 8
Training loss: 0.44069898538821084
Validation loss: 2.531807491073904

Epoch: 6| Step: 9
Training loss: 0.32138416077144416
Validation loss: 2.562646816118625

Epoch: 6| Step: 10
Training loss: 1.7828761926050722
Validation loss: 2.5237254220389986

Epoch: 6| Step: 11
Training loss: 0.4339956191123087
Validation loss: 2.565389592916712

Epoch: 6| Step: 12
Training loss: 0.2218694336958575
Validation loss: 2.541654476484185

Epoch: 6| Step: 13
Training loss: 0.5466324404531344
Validation loss: 2.5709389032599312

Epoch: 320| Step: 0
Training loss: 0.24152904646504134
Validation loss: 2.5538420078214625

Epoch: 6| Step: 1
Training loss: 0.49068982977697284
Validation loss: 2.528790105991194

Epoch: 6| Step: 2
Training loss: 0.5130848013665987
Validation loss: 2.511714012036781

Epoch: 6| Step: 3
Training loss: 0.6754589304407698
Validation loss: 2.490785782480767

Epoch: 6| Step: 4
Training loss: 0.32266277925475334
Validation loss: 2.496582665336071

Epoch: 6| Step: 5
Training loss: 0.4945963089078282
Validation loss: 2.471483320036572

Epoch: 6| Step: 6
Training loss: 0.6047369934250857
Validation loss: 2.4901724851229625

Epoch: 6| Step: 7
Training loss: 1.6679120020626854
Validation loss: 2.507514305915976

Epoch: 6| Step: 8
Training loss: 0.5193102373676911
Validation loss: 2.498280900126436

Epoch: 6| Step: 9
Training loss: 0.732263247796297
Validation loss: 2.5233388048582652

Epoch: 6| Step: 10
Training loss: 0.5342039001668091
Validation loss: 2.5471446331610226

Epoch: 6| Step: 11
Training loss: 0.4369056956650093
Validation loss: 2.539236969234672

Epoch: 6| Step: 12
Training loss: 0.576764438899826
Validation loss: 2.538190012318577

Epoch: 6| Step: 13
Training loss: 0.49344927405913624
Validation loss: 2.527718352377645

Epoch: 321| Step: 0
Training loss: 0.5087202615036482
Validation loss: 2.455903364605258

Epoch: 6| Step: 1
Training loss: 0.5086925217309952
Validation loss: 2.4908910606685746

Epoch: 6| Step: 2
Training loss: 0.6055097504546565
Validation loss: 2.5014468395317704

Epoch: 6| Step: 3
Training loss: 0.6683128318432617
Validation loss: 2.4923987471222

Epoch: 6| Step: 4
Training loss: 0.5840971464654611
Validation loss: 2.5219441929657074

Epoch: 6| Step: 5
Training loss: 1.7354109136234954
Validation loss: 2.542424559165315

Epoch: 6| Step: 6
Training loss: 0.38206642784621947
Validation loss: 2.57635795467741

Epoch: 6| Step: 7
Training loss: 0.724914650990517
Validation loss: 2.5791598204929516

Epoch: 6| Step: 8
Training loss: 0.41085360145610567
Validation loss: 2.6112165284315165

Epoch: 6| Step: 9
Training loss: 0.42457518242501496
Validation loss: 2.6201175240850683

Epoch: 6| Step: 10
Training loss: 0.27332114059935586
Validation loss: 2.5712956533282925

Epoch: 6| Step: 11
Training loss: 0.5533016246113384
Validation loss: 2.5758019485345405

Epoch: 6| Step: 12
Training loss: 0.5352354617560906
Validation loss: 2.582001114007394

Epoch: 6| Step: 13
Training loss: 0.47728145024246654
Validation loss: 2.5550064781396937

Epoch: 322| Step: 0
Training loss: 0.6376760576270879
Validation loss: 2.539537971851462

Epoch: 6| Step: 1
Training loss: 0.4018537074035386
Validation loss: 2.5171686072337014

Epoch: 6| Step: 2
Training loss: 0.4642893586696916
Validation loss: 2.5100932368429567

Epoch: 6| Step: 3
Training loss: 0.5310415812786997
Validation loss: 2.494338493558449

Epoch: 6| Step: 4
Training loss: 0.45163714376024144
Validation loss: 2.52522473603763

Epoch: 6| Step: 5
Training loss: 0.5501635720031999
Validation loss: 2.501679424480639

Epoch: 6| Step: 6
Training loss: 1.7069068706251032
Validation loss: 2.5300557955312084

Epoch: 6| Step: 7
Training loss: 0.6042894753790302
Validation loss: 2.5109314599826527

Epoch: 6| Step: 8
Training loss: 0.3691655710661901
Validation loss: 2.527262498323879

Epoch: 6| Step: 9
Training loss: 0.5972719141028382
Validation loss: 2.572870939048602

Epoch: 6| Step: 10
Training loss: 0.4187962193389475
Validation loss: 2.6217606084680853

Epoch: 6| Step: 11
Training loss: 0.6336365738212597
Validation loss: 2.5853049514552877

Epoch: 6| Step: 12
Training loss: 0.20032835470647148
Validation loss: 2.6243739150571925

Epoch: 6| Step: 13
Training loss: 0.9327498576282484
Validation loss: 2.6007871804362446

Epoch: 323| Step: 0
Training loss: 0.4928576282213518
Validation loss: 2.607750680650156

Epoch: 6| Step: 1
Training loss: 0.5781662900459219
Validation loss: 2.5907785232087983

Epoch: 6| Step: 2
Training loss: 0.6144856817177415
Validation loss: 2.5859408637421706

Epoch: 6| Step: 3
Training loss: 0.442271591251402
Validation loss: 2.5742255867809036

Epoch: 6| Step: 4
Training loss: 0.5182480992320526
Validation loss: 2.541865642780538

Epoch: 6| Step: 5
Training loss: 0.36712491739887143
Validation loss: 2.521477066814482

Epoch: 6| Step: 6
Training loss: 0.6389846735714673
Validation loss: 2.500645603373364

Epoch: 6| Step: 7
Training loss: 0.3380909695132375
Validation loss: 2.4955155395879953

Epoch: 6| Step: 8
Training loss: 1.7284400363062773
Validation loss: 2.532583773771871

Epoch: 6| Step: 9
Training loss: 0.6734713286999693
Validation loss: 2.5007096114111236

Epoch: 6| Step: 10
Training loss: 0.5022086298449094
Validation loss: 2.528574532386415

Epoch: 6| Step: 11
Training loss: 0.4280195287277802
Validation loss: 2.5295446685863423

Epoch: 6| Step: 12
Training loss: 0.47458769509362747
Validation loss: 2.52554835551734

Epoch: 6| Step: 13
Training loss: 0.21155922711093256
Validation loss: 2.5442867639825275

Epoch: 324| Step: 0
Training loss: 0.5033573443430879
Validation loss: 2.564577380608682

Epoch: 6| Step: 1
Training loss: 0.5269059518521728
Validation loss: 2.546108474499824

Epoch: 6| Step: 2
Training loss: 0.37206260292696447
Validation loss: 2.596319323383579

Epoch: 6| Step: 3
Training loss: 0.4581549759824912
Validation loss: 2.5608179137575635

Epoch: 6| Step: 4
Training loss: 0.5750730219374777
Validation loss: 2.510270866381445

Epoch: 6| Step: 5
Training loss: 0.4480819083155615
Validation loss: 2.5428318454160124

Epoch: 6| Step: 6
Training loss: 1.7274456958543891
Validation loss: 2.5163652638740803

Epoch: 6| Step: 7
Training loss: 0.4598243818439557
Validation loss: 2.486189981748912

Epoch: 6| Step: 8
Training loss: 0.5471302254339915
Validation loss: 2.5254991011905963

Epoch: 6| Step: 9
Training loss: 0.39631720716047963
Validation loss: 2.48744305664876

Epoch: 6| Step: 10
Training loss: 0.3973797614504412
Validation loss: 2.53411244184171

Epoch: 6| Step: 11
Training loss: 0.49119487455583716
Validation loss: 2.543391404226874

Epoch: 6| Step: 12
Training loss: 0.5828825338385197
Validation loss: 2.5170587250044614

Epoch: 6| Step: 13
Training loss: 0.6072763593739132
Validation loss: 2.5306505217268263

Epoch: 325| Step: 0
Training loss: 0.6624432287543434
Validation loss: 2.5509437660396928

Epoch: 6| Step: 1
Training loss: 0.7475908448122548
Validation loss: 2.5712576500242843

Epoch: 6| Step: 2
Training loss: 0.525952177335916
Validation loss: 2.589559216443498

Epoch: 6| Step: 3
Training loss: 0.6346959941526642
Validation loss: 2.5793849865456466

Epoch: 6| Step: 4
Training loss: 1.6670298021807057
Validation loss: 2.5753675285145796

Epoch: 6| Step: 5
Training loss: 0.34144968110124246
Validation loss: 2.55682350533102

Epoch: 6| Step: 6
Training loss: 0.527808712030418
Validation loss: 2.5818558135140064

Epoch: 6| Step: 7
Training loss: 0.2353472729050618
Validation loss: 2.566226083030377

Epoch: 6| Step: 8
Training loss: 0.6242829501064967
Validation loss: 2.5595442950597773

Epoch: 6| Step: 9
Training loss: 0.36241563604551424
Validation loss: 2.5465922120332705

Epoch: 6| Step: 10
Training loss: 0.251192734535881
Validation loss: 2.512689612216163

Epoch: 6| Step: 11
Training loss: 0.2415702707045047
Validation loss: 2.5188924290069816

Epoch: 6| Step: 12
Training loss: 0.5269392369435916
Validation loss: 2.534848531498804

Epoch: 6| Step: 13
Training loss: 0.6077015959460262
Validation loss: 2.4808077621141016

Epoch: 326| Step: 0
Training loss: 0.3531126813512205
Validation loss: 2.509982234915008

Epoch: 6| Step: 1
Training loss: 0.7122107202980181
Validation loss: 2.496399996706247

Epoch: 6| Step: 2
Training loss: 0.48445719359962025
Validation loss: 2.494949291311626

Epoch: 6| Step: 3
Training loss: 0.21831685848237364
Validation loss: 2.4956251546074673

Epoch: 6| Step: 4
Training loss: 0.4895348440331184
Validation loss: 2.4880367017281824

Epoch: 6| Step: 5
Training loss: 0.3914537983412234
Validation loss: 2.5019573137891666

Epoch: 6| Step: 6
Training loss: 0.3680708790034433
Validation loss: 2.4819564082815524

Epoch: 6| Step: 7
Training loss: 0.5274714845027902
Validation loss: 2.4912970978111475

Epoch: 6| Step: 8
Training loss: 0.5733615159669047
Validation loss: 2.5061925097978266

Epoch: 6| Step: 9
Training loss: 0.4927514039933608
Validation loss: 2.5157791607136573

Epoch: 6| Step: 10
Training loss: 1.7530392413319733
Validation loss: 2.5480488278377087

Epoch: 6| Step: 11
Training loss: 0.3429377344136578
Validation loss: 2.524116079711699

Epoch: 6| Step: 12
Training loss: 0.3562762133675034
Validation loss: 2.537090142388484

Epoch: 6| Step: 13
Training loss: 0.5973987897441139
Validation loss: 2.5298698493089207

Epoch: 327| Step: 0
Training loss: 0.3980640081999075
Validation loss: 2.5326525895067444

Epoch: 6| Step: 1
Training loss: 1.721434629313195
Validation loss: 2.5163603798036673

Epoch: 6| Step: 2
Training loss: 0.2862983849499218
Validation loss: 2.5064564569506462

Epoch: 6| Step: 3
Training loss: 0.449307938719608
Validation loss: 2.498510868838854

Epoch: 6| Step: 4
Training loss: 0.4834147286800675
Validation loss: 2.4900004193316776

Epoch: 6| Step: 5
Training loss: 0.395785387381258
Validation loss: 2.476413658024552

Epoch: 6| Step: 6
Training loss: 0.21640829539795609
Validation loss: 2.4966969891927513

Epoch: 6| Step: 7
Training loss: 0.3859855560159893
Validation loss: 2.497456181357028

Epoch: 6| Step: 8
Training loss: 0.703723419697064
Validation loss: 2.49723736287176

Epoch: 6| Step: 9
Training loss: 0.3406135019059092
Validation loss: 2.484045963860901

Epoch: 6| Step: 10
Training loss: 0.3869469479907901
Validation loss: 2.471498446764993

Epoch: 6| Step: 11
Training loss: 0.8378328601336757
Validation loss: 2.44323360607021

Epoch: 6| Step: 12
Training loss: 0.4360692266158923
Validation loss: 2.435293102555307

Epoch: 6| Step: 13
Training loss: 0.39915915191773416
Validation loss: 2.432556596055067

Epoch: 328| Step: 0
Training loss: 0.5588035989608593
Validation loss: 2.460566619151552

Epoch: 6| Step: 1
Training loss: 0.6178827353704619
Validation loss: 2.4962727336181207

Epoch: 6| Step: 2
Training loss: 0.5087436062647699
Validation loss: 2.512150199929199

Epoch: 6| Step: 3
Training loss: 0.2892183965993048
Validation loss: 2.508096844368822

Epoch: 6| Step: 4
Training loss: 0.34433974265572576
Validation loss: 2.520618245131955

Epoch: 6| Step: 5
Training loss: 0.5129156601919448
Validation loss: 2.53808130936195

Epoch: 6| Step: 6
Training loss: 0.2766332794394944
Validation loss: 2.5376246154760262

Epoch: 6| Step: 7
Training loss: 1.7621270021788615
Validation loss: 2.50658516874529

Epoch: 6| Step: 8
Training loss: 0.3470136618762423
Validation loss: 2.5476479061220623

Epoch: 6| Step: 9
Training loss: 0.3175548498016392
Validation loss: 2.523677578684056

Epoch: 6| Step: 10
Training loss: 0.7056389055326364
Validation loss: 2.478337175417992

Epoch: 6| Step: 11
Training loss: 0.3589845069992935
Validation loss: 2.485440360702958

Epoch: 6| Step: 12
Training loss: 0.3162729194312155
Validation loss: 2.4502478927222784

Epoch: 6| Step: 13
Training loss: 0.44659390044815406
Validation loss: 2.4733440406362353

Epoch: 329| Step: 0
Training loss: 0.4311674467489418
Validation loss: 2.474541756316303

Epoch: 6| Step: 1
Training loss: 0.34687172312520415
Validation loss: 2.466327036642723

Epoch: 6| Step: 2
Training loss: 0.5563328745537054
Validation loss: 2.5043954223431357

Epoch: 6| Step: 3
Training loss: 0.21109684471047366
Validation loss: 2.5187139527511326

Epoch: 6| Step: 4
Training loss: 0.4557935142501729
Validation loss: 2.509872069730426

Epoch: 6| Step: 5
Training loss: 0.46856197718824816
Validation loss: 2.509913467656366

Epoch: 6| Step: 6
Training loss: 0.4769812292118414
Validation loss: 2.508038887010625

Epoch: 6| Step: 7
Training loss: 0.38178797271822146
Validation loss: 2.5239103699583585

Epoch: 6| Step: 8
Training loss: 0.7395673579966602
Validation loss: 2.5241890445988675

Epoch: 6| Step: 9
Training loss: 1.7305463855283423
Validation loss: 2.4791307554455906

Epoch: 6| Step: 10
Training loss: 0.170721016476547
Validation loss: 2.5039172953393276

Epoch: 6| Step: 11
Training loss: 0.5774671574951554
Validation loss: 2.4850837866108457

Epoch: 6| Step: 12
Training loss: 0.28591991745718387
Validation loss: 2.4992368271583048

Epoch: 6| Step: 13
Training loss: 0.42225280375252777
Validation loss: 2.47731048746579

Epoch: 330| Step: 0
Training loss: 0.42441683196468993
Validation loss: 2.493746438338589

Epoch: 6| Step: 1
Training loss: 0.46100577155945976
Validation loss: 2.513411817442637

Epoch: 6| Step: 2
Training loss: 0.6163036923492412
Validation loss: 2.496499624361754

Epoch: 6| Step: 3
Training loss: 0.2718707703666971
Validation loss: 2.5008816159254463

Epoch: 6| Step: 4
Training loss: 0.24656767850594064
Validation loss: 2.5267904509988184

Epoch: 6| Step: 5
Training loss: 0.47066285526976576
Validation loss: 2.5422315274134815

Epoch: 6| Step: 6
Training loss: 0.48146765852441903
Validation loss: 2.5220042348158347

Epoch: 6| Step: 7
Training loss: 0.5536290937484661
Validation loss: 2.567193926261044

Epoch: 6| Step: 8
Training loss: 0.5439002739222671
Validation loss: 2.5328649971884913

Epoch: 6| Step: 9
Training loss: 0.3967038942179554
Validation loss: 2.5529885135616834

Epoch: 6| Step: 10
Training loss: 0.42958754330535315
Validation loss: 2.5512357434810875

Epoch: 6| Step: 11
Training loss: 1.6805185790324564
Validation loss: 2.5165705726948917

Epoch: 6| Step: 12
Training loss: 0.4418118900138906
Validation loss: 2.545662679045065

Epoch: 6| Step: 13
Training loss: 0.6066488271577571
Validation loss: 2.535904913012375

Epoch: 331| Step: 0
Training loss: 0.2598627812245636
Validation loss: 2.4907355504696156

Epoch: 6| Step: 1
Training loss: 0.41908752588564485
Validation loss: 2.4995665515441012

Epoch: 6| Step: 2
Training loss: 0.48721211687478083
Validation loss: 2.4924013144657033

Epoch: 6| Step: 3
Training loss: 0.44056247984579955
Validation loss: 2.4805380317637873

Epoch: 6| Step: 4
Training loss: 0.3899335081321384
Validation loss: 2.498427433798432

Epoch: 6| Step: 5
Training loss: 0.523266066760643
Validation loss: 2.5036018095252004

Epoch: 6| Step: 6
Training loss: 0.4332668171627233
Validation loss: 2.5140011156967117

Epoch: 6| Step: 7
Training loss: 0.5562938747890295
Validation loss: 2.4933592036628496

Epoch: 6| Step: 8
Training loss: 0.17058371310730672
Validation loss: 2.5124805170311

Epoch: 6| Step: 9
Training loss: 0.37960825120532277
Validation loss: 2.4748006484961986

Epoch: 6| Step: 10
Training loss: 0.37431304317071257
Validation loss: 2.53791184824508

Epoch: 6| Step: 11
Training loss: 0.600806293536048
Validation loss: 2.5214137120513973

Epoch: 6| Step: 12
Training loss: 0.5097907049213916
Validation loss: 2.4969417755452055

Epoch: 6| Step: 13
Training loss: 2.260412178093692
Validation loss: 2.4874256236899326

Epoch: 332| Step: 0
Training loss: 0.4385194141544332
Validation loss: 2.502709218987024

Epoch: 6| Step: 1
Training loss: 0.3824441071419765
Validation loss: 2.510573928094906

Epoch: 6| Step: 2
Training loss: 0.31417184890365246
Validation loss: 2.49677331102786

Epoch: 6| Step: 3
Training loss: 1.779733782158912
Validation loss: 2.498352306632986

Epoch: 6| Step: 4
Training loss: 0.6843395633319475
Validation loss: 2.518564124956227

Epoch: 6| Step: 5
Training loss: 0.6023962015353911
Validation loss: 2.4748899708007794

Epoch: 6| Step: 6
Training loss: 0.36456024460116954
Validation loss: 2.5013965407934156

Epoch: 6| Step: 7
Training loss: 0.26349235357268624
Validation loss: 2.515630600895701

Epoch: 6| Step: 8
Training loss: 0.23455114103644326
Validation loss: 2.5263402720275483

Epoch: 6| Step: 9
Training loss: 0.1548202787677316
Validation loss: 2.5107119442796137

Epoch: 6| Step: 10
Training loss: 0.45185024900700754
Validation loss: 2.483316800968924

Epoch: 6| Step: 11
Training loss: 0.4198743039176783
Validation loss: 2.5043996664193604

Epoch: 6| Step: 12
Training loss: 0.41096264722340925
Validation loss: 2.486659127785676

Epoch: 6| Step: 13
Training loss: 0.31239600835483416
Validation loss: 2.479517673935168

Epoch: 333| Step: 0
Training loss: 1.6932807384918587
Validation loss: 2.492681984455154

Epoch: 6| Step: 1
Training loss: 0.246374250437459
Validation loss: 2.5127247248204396

Epoch: 6| Step: 2
Training loss: 0.14886049184002845
Validation loss: 2.5503136357701144

Epoch: 6| Step: 3
Training loss: 0.38542604649788864
Validation loss: 2.5475895333110787

Epoch: 6| Step: 4
Training loss: 0.5604838425555945
Validation loss: 2.5488961903727008

Epoch: 6| Step: 5
Training loss: 0.6512186776168521
Validation loss: 2.541979452932385

Epoch: 6| Step: 6
Training loss: 0.5221981635565811
Validation loss: 2.521112918900686

Epoch: 6| Step: 7
Training loss: 0.5163913003255185
Validation loss: 2.525459010411373

Epoch: 6| Step: 8
Training loss: 0.48000648404748725
Validation loss: 2.507082909465139

Epoch: 6| Step: 9
Training loss: 0.5886198065093824
Validation loss: 2.503298166671499

Epoch: 6| Step: 10
Training loss: 0.4599689879796161
Validation loss: 2.513974364067997

Epoch: 6| Step: 11
Training loss: 0.33776268714410285
Validation loss: 2.510668556124554

Epoch: 6| Step: 12
Training loss: 0.3464602138348207
Validation loss: 2.513244123876776

Epoch: 6| Step: 13
Training loss: 0.287329971787983
Validation loss: 2.5432961400006544

Epoch: 334| Step: 0
Training loss: 0.4465377081575473
Validation loss: 2.505347921968861

Epoch: 6| Step: 1
Training loss: 0.3450553558002495
Validation loss: 2.571960399715341

Epoch: 6| Step: 2
Training loss: 1.6904411822390453
Validation loss: 2.5583243595131715

Epoch: 6| Step: 3
Training loss: 0.2665534762099481
Validation loss: 2.548915450069995

Epoch: 6| Step: 4
Training loss: 0.6542757400970861
Validation loss: 2.557272531038358

Epoch: 6| Step: 5
Training loss: 0.5725297025613094
Validation loss: 2.5567849419949034

Epoch: 6| Step: 6
Training loss: 0.26475078110043837
Validation loss: 2.553141027733043

Epoch: 6| Step: 7
Training loss: 0.30661803970259305
Validation loss: 2.518006538777819

Epoch: 6| Step: 8
Training loss: 0.3067357468523112
Validation loss: 2.5016479167700285

Epoch: 6| Step: 9
Training loss: 0.2832496078754482
Validation loss: 2.504752601805769

Epoch: 6| Step: 10
Training loss: 0.29933783748501114
Validation loss: 2.485663053977846

Epoch: 6| Step: 11
Training loss: 0.5226083137642172
Validation loss: 2.477744717304363

Epoch: 6| Step: 12
Training loss: 0.6694287634521554
Validation loss: 2.4887215273469616

Epoch: 6| Step: 13
Training loss: 0.7116096170043601
Validation loss: 2.4890514718186134

Epoch: 335| Step: 0
Training loss: 0.6604221869236974
Validation loss: 2.4673090325388736

Epoch: 6| Step: 1
Training loss: 0.4136194521905741
Validation loss: 2.4872300221485184

Epoch: 6| Step: 2
Training loss: 0.2081016364744954
Validation loss: 2.4983539284349625

Epoch: 6| Step: 3
Training loss: 1.684640510312754
Validation loss: 2.4822949208180627

Epoch: 6| Step: 4
Training loss: 0.5276992729705376
Validation loss: 2.4975891635545846

Epoch: 6| Step: 5
Training loss: 0.5058475330984533
Validation loss: 2.5138375468104392

Epoch: 6| Step: 6
Training loss: 0.30424805275224176
Validation loss: 2.513419848276326

Epoch: 6| Step: 7
Training loss: 0.49049678937442553
Validation loss: 2.5408375623520345

Epoch: 6| Step: 8
Training loss: 0.5110798115522126
Validation loss: 2.4974709110860585

Epoch: 6| Step: 9
Training loss: 0.3597763349862851
Validation loss: 2.5063849678283803

Epoch: 6| Step: 10
Training loss: 0.21770933944220222
Validation loss: 2.5118040996820685

Epoch: 6| Step: 11
Training loss: 0.47656018616161516
Validation loss: 2.502302127094577

Epoch: 6| Step: 12
Training loss: 0.448809528546576
Validation loss: 2.502435248238555

Epoch: 6| Step: 13
Training loss: 0.28180586667015217
Validation loss: 2.4735117719856485

Epoch: 336| Step: 0
Training loss: 0.32941326921571734
Validation loss: 2.4896225348013923

Epoch: 6| Step: 1
Training loss: 0.14511164555806985
Validation loss: 2.468852920432607

Epoch: 6| Step: 2
Training loss: 0.13483179237195808
Validation loss: 2.4698170912492357

Epoch: 6| Step: 3
Training loss: 0.4197548822547291
Validation loss: 2.472796700794031

Epoch: 6| Step: 4
Training loss: 0.27997214042483315
Validation loss: 2.4787083635887597

Epoch: 6| Step: 5
Training loss: 0.6027567762265328
Validation loss: 2.473681377113273

Epoch: 6| Step: 6
Training loss: 0.5488107753196997
Validation loss: 2.4778572099524117

Epoch: 6| Step: 7
Training loss: 0.6537627587978921
Validation loss: 2.4773496603049847

Epoch: 6| Step: 8
Training loss: 0.4050327183611701
Validation loss: 2.4817385877003577

Epoch: 6| Step: 9
Training loss: 0.3493922001250576
Validation loss: 2.471593790842039

Epoch: 6| Step: 10
Training loss: 0.5786203633450419
Validation loss: 2.489865962553701

Epoch: 6| Step: 11
Training loss: 0.2004073346107312
Validation loss: 2.492414485945442

Epoch: 6| Step: 12
Training loss: 1.7366251739675398
Validation loss: 2.4811213506825767

Epoch: 6| Step: 13
Training loss: 0.29892522194332427
Validation loss: 2.474341551930753

Epoch: 337| Step: 0
Training loss: 0.5009208187150559
Validation loss: 2.520939684293739

Epoch: 6| Step: 1
Training loss: 0.41281856965563246
Validation loss: 2.5186160275342044

Epoch: 6| Step: 2
Training loss: 0.4372079248953883
Validation loss: 2.5360751147548397

Epoch: 6| Step: 3
Training loss: 0.18994098457348457
Validation loss: 2.5286116386666446

Epoch: 6| Step: 4
Training loss: 0.5088442957326456
Validation loss: 2.5543762671731662

Epoch: 6| Step: 5
Training loss: 0.523041703623818
Validation loss: 2.5107439810067924

Epoch: 6| Step: 6
Training loss: 0.41698060924170266
Validation loss: 2.5214764786408677

Epoch: 6| Step: 7
Training loss: 0.7554041553800145
Validation loss: 2.5322507963395626

Epoch: 6| Step: 8
Training loss: 0.38865230261821004
Validation loss: 2.493934116253572

Epoch: 6| Step: 9
Training loss: 0.23098434544802893
Validation loss: 2.4885749176752596

Epoch: 6| Step: 10
Training loss: 0.35924784857332037
Validation loss: 2.4841506907309006

Epoch: 6| Step: 11
Training loss: 1.698339195178956
Validation loss: 2.4741931161833186

Epoch: 6| Step: 12
Training loss: 0.19258592988267567
Validation loss: 2.5142827693567447

Epoch: 6| Step: 13
Training loss: 0.235673004276671
Validation loss: 2.4607758822664914

Epoch: 338| Step: 0
Training loss: 0.5635057041823868
Validation loss: 2.503182389414891

Epoch: 6| Step: 1
Training loss: 0.4123902651738586
Validation loss: 2.4752299691566297

Epoch: 6| Step: 2
Training loss: 0.3720607205653881
Validation loss: 2.508307082769579

Epoch: 6| Step: 3
Training loss: 0.5459269889776095
Validation loss: 2.518116091531329

Epoch: 6| Step: 4
Training loss: 0.6742528931071581
Validation loss: 2.5127805356599136

Epoch: 6| Step: 5
Training loss: 0.28390115675611605
Validation loss: 2.5536151491955508

Epoch: 6| Step: 6
Training loss: 0.3717133619536119
Validation loss: 2.568093243538663

Epoch: 6| Step: 7
Training loss: 0.4116086041602174
Validation loss: 2.584869568732478

Epoch: 6| Step: 8
Training loss: 0.341577633978781
Validation loss: 2.582525542475709

Epoch: 6| Step: 9
Training loss: 0.42056140549282467
Validation loss: 2.5286894729954783

Epoch: 6| Step: 10
Training loss: 1.723305162621367
Validation loss: 2.523990991886683

Epoch: 6| Step: 11
Training loss: 0.42930591285640235
Validation loss: 2.528752108161185

Epoch: 6| Step: 12
Training loss: 0.3091050873122406
Validation loss: 2.4775102175613055

Epoch: 6| Step: 13
Training loss: 0.4661616228579984
Validation loss: 2.4794427265253325

Epoch: 339| Step: 0
Training loss: 0.3790398784847012
Validation loss: 2.4490629505343273

Epoch: 6| Step: 1
Training loss: 0.5537963209304166
Validation loss: 2.473670441349261

Epoch: 6| Step: 2
Training loss: 0.4385619218487331
Validation loss: 2.4665413849080338

Epoch: 6| Step: 3
Training loss: 0.5300938142213005
Validation loss: 2.469194641404446

Epoch: 6| Step: 4
Training loss: 0.4132611239171332
Validation loss: 2.4568870660332376

Epoch: 6| Step: 5
Training loss: 0.4493867311286084
Validation loss: 2.498406132862452

Epoch: 6| Step: 6
Training loss: 0.299356940108993
Validation loss: 2.504014659720211

Epoch: 6| Step: 7
Training loss: 1.6956347321885903
Validation loss: 2.5166124258027724

Epoch: 6| Step: 8
Training loss: 0.28926912861286125
Validation loss: 2.5034267213428474

Epoch: 6| Step: 9
Training loss: 0.5103940634361305
Validation loss: 2.511848255630287

Epoch: 6| Step: 10
Training loss: 0.4809601294713027
Validation loss: 2.5562515460967252

Epoch: 6| Step: 11
Training loss: 0.21952928800147348
Validation loss: 2.5248365979447116

Epoch: 6| Step: 12
Training loss: 0.721257107995509
Validation loss: 2.5106838102731017

Epoch: 6| Step: 13
Training loss: 0.19572988734502586
Validation loss: 2.525765893613645

Epoch: 340| Step: 0
Training loss: 0.29840661533184343
Validation loss: 2.5284606298696106

Epoch: 6| Step: 1
Training loss: 0.596627940230015
Validation loss: 2.457102992415409

Epoch: 6| Step: 2
Training loss: 0.5907733488727397
Validation loss: 2.4845693647277005

Epoch: 6| Step: 3
Training loss: 0.37908860370670155
Validation loss: 2.487749651297347

Epoch: 6| Step: 4
Training loss: 1.6990232157835885
Validation loss: 2.488096898783588

Epoch: 6| Step: 5
Training loss: 0.35619349533500066
Validation loss: 2.4595530959821374

Epoch: 6| Step: 6
Training loss: 0.5136014940904116
Validation loss: 2.455042072010244

Epoch: 6| Step: 7
Training loss: 0.47682470393891924
Validation loss: 2.441611120016422

Epoch: 6| Step: 8
Training loss: 0.4225666592848447
Validation loss: 2.4905087856792414

Epoch: 6| Step: 9
Training loss: 0.4541359180867346
Validation loss: 2.453990007560572

Epoch: 6| Step: 10
Training loss: 0.41267569441593355
Validation loss: 2.466427099749589

Epoch: 6| Step: 11
Training loss: 0.3590585932838648
Validation loss: 2.445684374368958

Epoch: 6| Step: 12
Training loss: 0.17381474089798266
Validation loss: 2.4558191521862383

Epoch: 6| Step: 13
Training loss: 0.21955471524305364
Validation loss: 2.479742863381303

Epoch: 341| Step: 0
Training loss: 0.45982410639116744
Validation loss: 2.5056862890148968

Epoch: 6| Step: 1
Training loss: 0.23119477501854646
Validation loss: 2.5310807358229392

Epoch: 6| Step: 2
Training loss: 0.6039529345629556
Validation loss: 2.5275353323284495

Epoch: 6| Step: 3
Training loss: 0.43445563356950867
Validation loss: 2.5255966009257835

Epoch: 6| Step: 4
Training loss: 0.32234306560967
Validation loss: 2.531384919101866

Epoch: 6| Step: 5
Training loss: 0.2949638084258769
Validation loss: 2.544357798766252

Epoch: 6| Step: 6
Training loss: 0.26039430363320204
Validation loss: 2.547483149025586

Epoch: 6| Step: 7
Training loss: 0.38931372853880025
Validation loss: 2.5504799147734585

Epoch: 6| Step: 8
Training loss: 1.7784969403420492
Validation loss: 2.5711682251611796

Epoch: 6| Step: 9
Training loss: 0.15348788537375427
Validation loss: 2.5320705996343413

Epoch: 6| Step: 10
Training loss: 0.5442511967184553
Validation loss: 2.550324459011524

Epoch: 6| Step: 11
Training loss: 0.46307002586852847
Validation loss: 2.5264665137057705

Epoch: 6| Step: 12
Training loss: 0.3640051162092933
Validation loss: 2.5242077346499303

Epoch: 6| Step: 13
Training loss: 0.39212245021741365
Validation loss: 2.5584362045087587

Epoch: 342| Step: 0
Training loss: 0.5671292656041691
Validation loss: 2.5353788839996874

Epoch: 6| Step: 1
Training loss: 0.14520745351594166
Validation loss: 2.5231121563003036

Epoch: 6| Step: 2
Training loss: 0.581138027850082
Validation loss: 2.535559430499205

Epoch: 6| Step: 3
Training loss: 0.4406985120121068
Validation loss: 2.5017506827474882

Epoch: 6| Step: 4
Training loss: 0.5357050900578323
Validation loss: 2.5195683297165488

Epoch: 6| Step: 5
Training loss: 0.45984074668409036
Validation loss: 2.519504093609836

Epoch: 6| Step: 6
Training loss: 0.38344216624485317
Validation loss: 2.4999766000042234

Epoch: 6| Step: 7
Training loss: 0.39551310594572037
Validation loss: 2.495049937084258

Epoch: 6| Step: 8
Training loss: 0.23549990114434713
Validation loss: 2.4819777458117023

Epoch: 6| Step: 9
Training loss: 0.35313232464916045
Validation loss: 2.464068232518782

Epoch: 6| Step: 10
Training loss: 0.37995992235856185
Validation loss: 2.471061045921056

Epoch: 6| Step: 11
Training loss: 1.725945755253129
Validation loss: 2.4915883074344025

Epoch: 6| Step: 12
Training loss: 0.1914597553284077
Validation loss: 2.4894307792125643

Epoch: 6| Step: 13
Training loss: 0.343133623035662
Validation loss: 2.491452036864074

Epoch: 343| Step: 0
Training loss: 0.3309006459190933
Validation loss: 2.5317467997413163

Epoch: 6| Step: 1
Training loss: 0.4188275471807677
Validation loss: 2.4957633708720066

Epoch: 6| Step: 2
Training loss: 0.36615093502580087
Validation loss: 2.5135609056584656

Epoch: 6| Step: 3
Training loss: 0.285682062797072
Validation loss: 2.4957632547987436

Epoch: 6| Step: 4
Training loss: 1.7266344426559068
Validation loss: 2.513094277286055

Epoch: 6| Step: 5
Training loss: 0.4167569320974044
Validation loss: 2.4861961165822333

Epoch: 6| Step: 6
Training loss: 0.2841692657132771
Validation loss: 2.4974336208217136

Epoch: 6| Step: 7
Training loss: 0.288919645528086
Validation loss: 2.471045410747457

Epoch: 6| Step: 8
Training loss: 0.40168563943719593
Validation loss: 2.4943675781280676

Epoch: 6| Step: 9
Training loss: 0.21559823809971596
Validation loss: 2.46659386612481

Epoch: 6| Step: 10
Training loss: 0.6446388386026356
Validation loss: 2.4950721081803278

Epoch: 6| Step: 11
Training loss: 0.304001316705318
Validation loss: 2.487979537262335

Epoch: 6| Step: 12
Training loss: 0.5694114935911789
Validation loss: 2.4804838074632536

Epoch: 6| Step: 13
Training loss: 0.5246390600604043
Validation loss: 2.494884233292197

Epoch: 344| Step: 0
Training loss: 0.43428982029863683
Validation loss: 2.538148985192199

Epoch: 6| Step: 1
Training loss: 0.44166830605376584
Validation loss: 2.5177472349245384

Epoch: 6| Step: 2
Training loss: 0.4634174294733278
Validation loss: 2.530558886383111

Epoch: 6| Step: 3
Training loss: 0.24031185823461512
Validation loss: 2.5242649820677654

Epoch: 6| Step: 4
Training loss: 0.4373383734380412
Validation loss: 2.5028651011832466

Epoch: 6| Step: 5
Training loss: 0.44746234682111785
Validation loss: 2.5170614591836364

Epoch: 6| Step: 6
Training loss: 0.2980652589740274
Validation loss: 2.5111746709318243

Epoch: 6| Step: 7
Training loss: 0.14706376885678557
Validation loss: 2.5126118995392908

Epoch: 6| Step: 8
Training loss: 0.4874277666570138
Validation loss: 2.5033921885150194

Epoch: 6| Step: 9
Training loss: 0.33791076732421715
Validation loss: 2.5317322415843195

Epoch: 6| Step: 10
Training loss: 1.71716971140873
Validation loss: 2.485957907503748

Epoch: 6| Step: 11
Training loss: 0.5977628525549177
Validation loss: 2.4951338528944946

Epoch: 6| Step: 12
Training loss: 0.37952820375805396
Validation loss: 2.4964645284702165

Epoch: 6| Step: 13
Training loss: 0.3613953811323963
Validation loss: 2.4615201620680076

Epoch: 345| Step: 0
Training loss: 0.434364132779531
Validation loss: 2.492242124909533

Epoch: 6| Step: 1
Training loss: 0.42565982732130075
Validation loss: 2.4765780351282944

Epoch: 6| Step: 2
Training loss: 0.42618828312714757
Validation loss: 2.5134126818791973

Epoch: 6| Step: 3
Training loss: 0.16955071504536895
Validation loss: 2.4904778494894932

Epoch: 6| Step: 4
Training loss: 1.7050576399963253
Validation loss: 2.4952237886207524

Epoch: 6| Step: 5
Training loss: 0.43597374085216556
Validation loss: 2.5017636697391525

Epoch: 6| Step: 6
Training loss: 0.4067161892939649
Validation loss: 2.4984252369137274

Epoch: 6| Step: 7
Training loss: 0.2970051605590265
Validation loss: 2.5228882111807187

Epoch: 6| Step: 8
Training loss: 0.3602161308041783
Validation loss: 2.5147834098220043

Epoch: 6| Step: 9
Training loss: 0.24427184583919073
Validation loss: 2.5008973305787174

Epoch: 6| Step: 10
Training loss: 0.4380674258779852
Validation loss: 2.517268303525421

Epoch: 6| Step: 11
Training loss: 0.47654009594393965
Validation loss: 2.561967544801647

Epoch: 6| Step: 12
Training loss: 0.4792022760953327
Validation loss: 2.5483785469534297

Epoch: 6| Step: 13
Training loss: 0.632221251834582
Validation loss: 2.5195004239286836

Epoch: 346| Step: 0
Training loss: 0.2936956669901162
Validation loss: 2.514426167189933

Epoch: 6| Step: 1
Training loss: 0.47132133313329194
Validation loss: 2.4974252075314203

Epoch: 6| Step: 2
Training loss: 1.7276214528208504
Validation loss: 2.5024886224605734

Epoch: 6| Step: 3
Training loss: 0.46946499653821333
Validation loss: 2.4814999228321986

Epoch: 6| Step: 4
Training loss: 0.3276534779749278
Validation loss: 2.4894598299823056

Epoch: 6| Step: 5
Training loss: 0.18256857933975928
Validation loss: 2.4427560254606604

Epoch: 6| Step: 6
Training loss: 0.3899901189836145
Validation loss: 2.4760097079389474

Epoch: 6| Step: 7
Training loss: 0.33539422041065253
Validation loss: 2.486283460138759

Epoch: 6| Step: 8
Training loss: 0.5614093697830436
Validation loss: 2.4688954225479693

Epoch: 6| Step: 9
Training loss: 0.39039858932264676
Validation loss: 2.50779934856892

Epoch: 6| Step: 10
Training loss: 0.30851808658563534
Validation loss: 2.489529812007911

Epoch: 6| Step: 11
Training loss: 0.403815604982777
Validation loss: 2.473951337941528

Epoch: 6| Step: 12
Training loss: 0.5935323717918836
Validation loss: 2.4849213700865547

Epoch: 6| Step: 13
Training loss: 0.11649734401847403
Validation loss: 2.5164342195386107

Epoch: 347| Step: 0
Training loss: 1.6869571660409053
Validation loss: 2.5382584377005513

Epoch: 6| Step: 1
Training loss: 0.4905962729092418
Validation loss: 2.5413444973169135

Epoch: 6| Step: 2
Training loss: 0.4578499918613681
Validation loss: 2.576431224166226

Epoch: 6| Step: 3
Training loss: 0.3462017041653374
Validation loss: 2.484857779688234

Epoch: 6| Step: 4
Training loss: 0.38612671047979086
Validation loss: 2.516742627964793

Epoch: 6| Step: 5
Training loss: 0.33233830334962333
Validation loss: 2.492955325655938

Epoch: 6| Step: 6
Training loss: 0.4479871369158623
Validation loss: 2.4821241375844

Epoch: 6| Step: 7
Training loss: 0.5524848131966548
Validation loss: 2.495950094947175

Epoch: 6| Step: 8
Training loss: 0.48090527251140097
Validation loss: 2.4591704087614232

Epoch: 6| Step: 9
Training loss: 0.3645733854662353
Validation loss: 2.4719738838032717

Epoch: 6| Step: 10
Training loss: 0.21780007032725177
Validation loss: 2.484113369244432

Epoch: 6| Step: 11
Training loss: 0.48336230826948334
Validation loss: 2.487504039737832

Epoch: 6| Step: 12
Training loss: 0.36849503350243085
Validation loss: 2.4725709305676697

Epoch: 6| Step: 13
Training loss: 0.4261963422064719
Validation loss: 2.4825383318264085

Epoch: 348| Step: 0
Training loss: 0.5010414007216585
Validation loss: 2.490068784191089

Epoch: 6| Step: 1
Training loss: 0.38923209756685134
Validation loss: 2.5094535885516196

Epoch: 6| Step: 2
Training loss: 0.33625182151301064
Validation loss: 2.5054174678781407

Epoch: 6| Step: 3
Training loss: 0.350975754980518
Validation loss: 2.4703533074928647

Epoch: 6| Step: 4
Training loss: 1.662782633570027
Validation loss: 2.498361621333889

Epoch: 6| Step: 5
Training loss: 0.3267865813018232
Validation loss: 2.462080922145989

Epoch: 6| Step: 6
Training loss: 0.4833463081997046
Validation loss: 2.486677816403054

Epoch: 6| Step: 7
Training loss: 0.6167958139382647
Validation loss: 2.4848871418440943

Epoch: 6| Step: 8
Training loss: 0.2666709725707823
Validation loss: 2.485461192049435

Epoch: 6| Step: 9
Training loss: 0.4381713314563819
Validation loss: 2.4989944897000895

Epoch: 6| Step: 10
Training loss: 0.18580340671198117
Validation loss: 2.4928840555900504

Epoch: 6| Step: 11
Training loss: 0.4195383493970025
Validation loss: 2.508458163234667

Epoch: 6| Step: 12
Training loss: 0.47001952871373753
Validation loss: 2.5129462896979518

Epoch: 6| Step: 13
Training loss: 0.4452669388067333
Validation loss: 2.567697984066834

Epoch: 349| Step: 0
Training loss: 0.31619431026067
Validation loss: 2.5566442147994195

Epoch: 6| Step: 1
Training loss: 0.34849053907208716
Validation loss: 2.564029007332664

Epoch: 6| Step: 2
Training loss: 0.4413044567382745
Validation loss: 2.5858115661964853

Epoch: 6| Step: 3
Training loss: 0.41879881673917146
Validation loss: 2.573397797972508

Epoch: 6| Step: 4
Training loss: 0.2601521849672661
Validation loss: 2.5491162369984997

Epoch: 6| Step: 5
Training loss: 1.698883023474707
Validation loss: 2.5463411008245465

Epoch: 6| Step: 6
Training loss: 0.5429660330505456
Validation loss: 2.475704844917297

Epoch: 6| Step: 7
Training loss: 0.5623736239567168
Validation loss: 2.4814307681381096

Epoch: 6| Step: 8
Training loss: 0.38925690447466454
Validation loss: 2.4712520385360652

Epoch: 6| Step: 9
Training loss: 0.3860202993925596
Validation loss: 2.463880556779531

Epoch: 6| Step: 10
Training loss: 0.5615583060675301
Validation loss: 2.4434868308222804

Epoch: 6| Step: 11
Training loss: 0.5175577123683336
Validation loss: 2.4477850765832527

Epoch: 6| Step: 12
Training loss: 0.3757498317598841
Validation loss: 2.452850010778681

Epoch: 6| Step: 13
Training loss: 0.3399365177915354
Validation loss: 2.47653124881321

Epoch: 350| Step: 0
Training loss: 0.33440790593812336
Validation loss: 2.504610761748978

Epoch: 6| Step: 1
Training loss: 0.29764228097171724
Validation loss: 2.494541536312814

Epoch: 6| Step: 2
Training loss: 0.5907171490349946
Validation loss: 2.5284855309582066

Epoch: 6| Step: 3
Training loss: 0.5292904561346834
Validation loss: 2.5043073013709005

Epoch: 6| Step: 4
Training loss: 0.5943171904055176
Validation loss: 2.576138424290972

Epoch: 6| Step: 5
Training loss: 0.42772808679983787
Validation loss: 2.598157715273071

Epoch: 6| Step: 6
Training loss: 0.6008396512183057
Validation loss: 2.6211422144178522

Epoch: 6| Step: 7
Training loss: 0.4969171614123337
Validation loss: 2.6179979744747173

Epoch: 6| Step: 8
Training loss: 0.3266354196531045
Validation loss: 2.5853239924764155

Epoch: 6| Step: 9
Training loss: 0.3841964462030524
Validation loss: 2.580067226853311

Epoch: 6| Step: 10
Training loss: 0.38346967924308706
Validation loss: 2.5352575646967086

Epoch: 6| Step: 11
Training loss: 1.6535557840013875
Validation loss: 2.501130269000403

Epoch: 6| Step: 12
Training loss: 0.3062457317911225
Validation loss: 2.496470366438193

Epoch: 6| Step: 13
Training loss: 0.6377159687803524
Validation loss: 2.4949251421339187

Epoch: 351| Step: 0
Training loss: 0.47284277080948556
Validation loss: 2.452196074793385

Epoch: 6| Step: 1
Training loss: 1.6311413549731257
Validation loss: 2.4650605934844565

Epoch: 6| Step: 2
Training loss: 0.29203406961711653
Validation loss: 2.457951238800382

Epoch: 6| Step: 3
Training loss: 0.6222157211072887
Validation loss: 2.41248095113443

Epoch: 6| Step: 4
Training loss: 0.43342312041552417
Validation loss: 2.429601050455493

Epoch: 6| Step: 5
Training loss: 0.5466689675367983
Validation loss: 2.4753516847982184

Epoch: 6| Step: 6
Training loss: 0.47354842545194503
Validation loss: 2.4621908142115765

Epoch: 6| Step: 7
Training loss: 0.29991470952378946
Validation loss: 2.4815597572681707

Epoch: 6| Step: 8
Training loss: 0.531574290535588
Validation loss: 2.4921999900901697

Epoch: 6| Step: 9
Training loss: 0.3262304950050189
Validation loss: 2.490330250466988

Epoch: 6| Step: 10
Training loss: 0.3739668800879124
Validation loss: 2.514490290876876

Epoch: 6| Step: 11
Training loss: 0.3977394346755698
Validation loss: 2.5180865212586525

Epoch: 6| Step: 12
Training loss: 0.39684645557630277
Validation loss: 2.479297038540475

Epoch: 6| Step: 13
Training loss: 0.3459846083381809
Validation loss: 2.5169986334230257

Epoch: 352| Step: 0
Training loss: 0.34943616828057456
Validation loss: 2.4936010545229923

Epoch: 6| Step: 1
Training loss: 0.6537028106740488
Validation loss: 2.5201634749536375

Epoch: 6| Step: 2
Training loss: 0.4895649933592624
Validation loss: 2.5112980356740193

Epoch: 6| Step: 3
Training loss: 0.39702445392579494
Validation loss: 2.543770738379933

Epoch: 6| Step: 4
Training loss: 0.23199923740818626
Validation loss: 2.521732756834637

Epoch: 6| Step: 5
Training loss: 0.2920204837829003
Validation loss: 2.5274494047178337

Epoch: 6| Step: 6
Training loss: 0.29251157057121246
Validation loss: 2.5061736664721455

Epoch: 6| Step: 7
Training loss: 0.574157659693452
Validation loss: 2.482444456299232

Epoch: 6| Step: 8
Training loss: 0.5487486214935436
Validation loss: 2.4747850333229606

Epoch: 6| Step: 9
Training loss: 0.5295097514201073
Validation loss: 2.457287675937183

Epoch: 6| Step: 10
Training loss: 0.37539739215638046
Validation loss: 2.479615219940977

Epoch: 6| Step: 11
Training loss: 0.4346607585609798
Validation loss: 2.46275845121811

Epoch: 6| Step: 12
Training loss: 0.2958328501715319
Validation loss: 2.4444127541837397

Epoch: 6| Step: 13
Training loss: 2.1324910910309605
Validation loss: 2.4739587968826937

Epoch: 353| Step: 0
Training loss: 0.42140719296608364
Validation loss: 2.445110862218801

Epoch: 6| Step: 1
Training loss: 0.5798608392218627
Validation loss: 2.445639219332478

Epoch: 6| Step: 2
Training loss: 0.39313634404249037
Validation loss: 2.422860615662248

Epoch: 6| Step: 3
Training loss: 0.5922288231032502
Validation loss: 2.46067651737605

Epoch: 6| Step: 4
Training loss: 0.571411797796725
Validation loss: 2.4274976400410764

Epoch: 6| Step: 5
Training loss: 0.6757585598879422
Validation loss: 2.4085573263060795

Epoch: 6| Step: 6
Training loss: 0.636238548947695
Validation loss: 2.4354750975964414

Epoch: 6| Step: 7
Training loss: 0.6783191455728877
Validation loss: 2.4326140253877013

Epoch: 6| Step: 8
Training loss: 0.5081773181083408
Validation loss: 2.4362731009286933

Epoch: 6| Step: 9
Training loss: 1.502971566789809
Validation loss: 2.506169970622744

Epoch: 6| Step: 10
Training loss: 0.44917958959639276
Validation loss: 2.531050325410601

Epoch: 6| Step: 11
Training loss: 0.4523323624253073
Validation loss: 2.5660503212621495

Epoch: 6| Step: 12
Training loss: 0.3698507270751176
Validation loss: 2.5760382327684055

Epoch: 6| Step: 13
Training loss: 0.5279383380278544
Validation loss: 2.629901721830115

Epoch: 354| Step: 0
Training loss: 0.6340257293883492
Validation loss: 2.5709207339206976

Epoch: 6| Step: 1
Training loss: 0.48726175306383357
Validation loss: 2.6256601828724153

Epoch: 6| Step: 2
Training loss: 0.4939631871028284
Validation loss: 2.5218144453975415

Epoch: 6| Step: 3
Training loss: 0.38868929953311143
Validation loss: 2.4820567101981226

Epoch: 6| Step: 4
Training loss: 0.3412822227495601
Validation loss: 2.43632429537479

Epoch: 6| Step: 5
Training loss: 0.4492557012868088
Validation loss: 2.410068175493138

Epoch: 6| Step: 6
Training loss: 0.5451350188337291
Validation loss: 2.3941029356600625

Epoch: 6| Step: 7
Training loss: 0.43375431558842176
Validation loss: 2.4035182575902523

Epoch: 6| Step: 8
Training loss: 1.3875535628144071
Validation loss: 2.41674320108951

Epoch: 6| Step: 9
Training loss: 0.5022813784973478
Validation loss: 2.409376623449657

Epoch: 6| Step: 10
Training loss: 0.6198900662910695
Validation loss: 2.4331727249093698

Epoch: 6| Step: 11
Training loss: 0.3803167732832471
Validation loss: 2.464884680283388

Epoch: 6| Step: 12
Training loss: 0.5513151570606282
Validation loss: 2.4525406152308813

Epoch: 6| Step: 13
Training loss: 0.656465086430574
Validation loss: 2.459147301520349

Epoch: 355| Step: 0
Training loss: 0.45795206084438994
Validation loss: 2.4868967728231928

Epoch: 6| Step: 1
Training loss: 1.4006753842144422
Validation loss: 2.51472676262802

Epoch: 6| Step: 2
Training loss: 0.3657947464139154
Validation loss: 2.5053235358552155

Epoch: 6| Step: 3
Training loss: 0.4707353509658652
Validation loss: 2.459481231158475

Epoch: 6| Step: 4
Training loss: 0.4078397091378985
Validation loss: 2.513375645988524

Epoch: 6| Step: 5
Training loss: 0.6082258882960693
Validation loss: 2.465311408854615

Epoch: 6| Step: 6
Training loss: 0.2954309377375246
Validation loss: 2.4428970425295597

Epoch: 6| Step: 7
Training loss: 0.4235159079954141
Validation loss: 2.4495255216546594

Epoch: 6| Step: 8
Training loss: 0.5883125995930525
Validation loss: 2.434578911410597

Epoch: 6| Step: 9
Training loss: 0.530839256371351
Validation loss: 2.4546513341591143

Epoch: 6| Step: 10
Training loss: 0.6417332112085654
Validation loss: 2.426868987139196

Epoch: 6| Step: 11
Training loss: 0.36228436929739755
Validation loss: 2.428751350184467

Epoch: 6| Step: 12
Training loss: 0.4829154327690592
Validation loss: 2.411300623901194

Epoch: 6| Step: 13
Training loss: 0.599018116054524
Validation loss: 2.420774215895049

Epoch: 356| Step: 0
Training loss: 0.36869009468858566
Validation loss: 2.5112370109888813

Epoch: 6| Step: 1
Training loss: 0.3511115042420861
Validation loss: 2.5057060158900186

Epoch: 6| Step: 2
Training loss: 0.35021685455835944
Validation loss: 2.4997518559841683

Epoch: 6| Step: 3
Training loss: 0.668657962312488
Validation loss: 2.524703568925894

Epoch: 6| Step: 4
Training loss: 0.43663520150289636
Validation loss: 2.527412605961144

Epoch: 6| Step: 5
Training loss: 0.4776639404526321
Validation loss: 2.52874112060828

Epoch: 6| Step: 6
Training loss: 1.293487767350814
Validation loss: 2.486826709484766

Epoch: 6| Step: 7
Training loss: 0.4505696757159645
Validation loss: 2.5119397596219994

Epoch: 6| Step: 8
Training loss: 0.419201574666855
Validation loss: 2.5025534397661113

Epoch: 6| Step: 9
Training loss: 0.4987621481809429
Validation loss: 2.511354505002879

Epoch: 6| Step: 10
Training loss: 0.49286396224771445
Validation loss: 2.5153358449719887

Epoch: 6| Step: 11
Training loss: 0.44254042489266965
Validation loss: 2.454071955273349

Epoch: 6| Step: 12
Training loss: 0.5494650948938835
Validation loss: 2.3958662425844426

Epoch: 6| Step: 13
Training loss: 0.44496827457149946
Validation loss: 2.361425322070822

Epoch: 357| Step: 0
Training loss: 0.4120312657390616
Validation loss: 2.328621867939096

Epoch: 6| Step: 1
Training loss: 0.32471226279267723
Validation loss: 2.3295320040494114

Epoch: 6| Step: 2
Training loss: 0.36626297644583566
Validation loss: 2.3305527567663833

Epoch: 6| Step: 3
Training loss: 0.4426898690655384
Validation loss: 2.347886746781666

Epoch: 6| Step: 4
Training loss: 0.4291660439230589
Validation loss: 2.3959051955165265

Epoch: 6| Step: 5
Training loss: 0.5085271648176555
Validation loss: 2.4063481722492446

Epoch: 6| Step: 6
Training loss: 0.4768240632967563
Validation loss: 2.4412536862193583

Epoch: 6| Step: 7
Training loss: 0.5486862976794524
Validation loss: 2.439884193254934

Epoch: 6| Step: 8
Training loss: 1.0852118613135164
Validation loss: 2.449820658046718

Epoch: 6| Step: 9
Training loss: 0.416604963343278
Validation loss: 2.3694987707776916

Epoch: 6| Step: 10
Training loss: 0.4835557469733021
Validation loss: 2.3727074067726233

Epoch: 6| Step: 11
Training loss: 0.4125476694017415
Validation loss: 2.3848016621999593

Epoch: 6| Step: 12
Training loss: 0.40816227466660093
Validation loss: 2.3760149691636623

Epoch: 6| Step: 13
Training loss: 0.6206762482073936
Validation loss: 2.3416808425456135

Epoch: 358| Step: 0
Training loss: 0.688581180063933
Validation loss: 2.37561880706105

Epoch: 6| Step: 1
Training loss: 0.656658136518943
Validation loss: 2.3569877688289336

Epoch: 6| Step: 2
Training loss: 0.4884439273687129
Validation loss: 2.3585919973801426

Epoch: 6| Step: 3
Training loss: 0.4074160274623622
Validation loss: 2.318279423211796

Epoch: 6| Step: 4
Training loss: 0.4033169503799219
Validation loss: 2.3736539295746466

Epoch: 6| Step: 5
Training loss: 0.551538339361268
Validation loss: 2.410652082916537

Epoch: 6| Step: 6
Training loss: 0.36489648539951064
Validation loss: 2.459907284587743

Epoch: 6| Step: 7
Training loss: 0.4306907559034974
Validation loss: 2.4647289084451596

Epoch: 6| Step: 8
Training loss: 1.0955287638221807
Validation loss: 2.519287500517117

Epoch: 6| Step: 9
Training loss: 0.5844062633617414
Validation loss: 2.489131294518598

Epoch: 6| Step: 10
Training loss: 0.5277018990960863
Validation loss: 2.4627660314996307

Epoch: 6| Step: 11
Training loss: 0.459701659388407
Validation loss: 2.417026338573202

Epoch: 6| Step: 12
Training loss: 0.25423017526566305
Validation loss: 2.3649469092210103

Epoch: 6| Step: 13
Training loss: 0.5609938803048313
Validation loss: 2.330421558805042

Epoch: 359| Step: 0
Training loss: 0.4754692263417486
Validation loss: 2.353764065521564

Epoch: 6| Step: 1
Training loss: 0.39748457479837424
Validation loss: 2.3239000779805274

Epoch: 6| Step: 2
Training loss: 0.7209686369139182
Validation loss: 2.3174425179856972

Epoch: 6| Step: 3
Training loss: 0.3352860855051085
Validation loss: 2.3177884932221193

Epoch: 6| Step: 4
Training loss: 0.45054702094670857
Validation loss: 2.3714569198040127

Epoch: 6| Step: 5
Training loss: 0.6059801956409159
Validation loss: 2.3894380747189112

Epoch: 6| Step: 6
Training loss: 0.32708461765272034
Validation loss: 2.4609371135169016

Epoch: 6| Step: 7
Training loss: 0.5310245203707359
Validation loss: 2.4995433846705963

Epoch: 6| Step: 8
Training loss: 0.7934150003891783
Validation loss: 2.536864933608692

Epoch: 6| Step: 9
Training loss: 0.6022754754188615
Validation loss: 2.5338199400993364

Epoch: 6| Step: 10
Training loss: 0.2655319864443111
Validation loss: 2.472497845274297

Epoch: 6| Step: 11
Training loss: 0.40786245266679305
Validation loss: 2.425004263949073

Epoch: 6| Step: 12
Training loss: 0.3022737998773888
Validation loss: 2.4111506054169634

Epoch: 6| Step: 13
Training loss: 0.3919781707553679
Validation loss: 2.4168803813949546

Epoch: 360| Step: 0
Training loss: 0.5303040665971448
Validation loss: 2.3504839758134604

Epoch: 6| Step: 1
Training loss: 0.4368586948937557
Validation loss: 2.3587266747973703

Epoch: 6| Step: 2
Training loss: 0.4709334383803946
Validation loss: 2.31210324077388

Epoch: 6| Step: 3
Training loss: 0.35159197789692337
Validation loss: 2.3201897447363566

Epoch: 6| Step: 4
Training loss: 0.37119020914970124
Validation loss: 2.3508445006921943

Epoch: 6| Step: 5
Training loss: 0.7036682149817948
Validation loss: 2.349072208149486

Epoch: 6| Step: 6
Training loss: 0.45472844650629346
Validation loss: 2.355076690105109

Epoch: 6| Step: 7
Training loss: 0.4175951170073594
Validation loss: 2.375247449672741

Epoch: 6| Step: 8
Training loss: 0.24261468467471706
Validation loss: 2.386230332845043

Epoch: 6| Step: 9
Training loss: 0.5630866805914224
Validation loss: 2.4264982788435905

Epoch: 6| Step: 10
Training loss: 0.47395722595197265
Validation loss: 2.4383080770339527

Epoch: 6| Step: 11
Training loss: 0.3328020797136952
Validation loss: 2.411338877788375

Epoch: 6| Step: 12
Training loss: 0.5294628375793371
Validation loss: 2.4533993512925303

Epoch: 6| Step: 13
Training loss: 0.09006290554528455
Validation loss: 2.4368860372343515

Epoch: 361| Step: 0
Training loss: 0.28301618259602246
Validation loss: 2.416037677265641

Epoch: 6| Step: 1
Training loss: 0.4373518999654849
Validation loss: 2.438267242362701

Epoch: 6| Step: 2
Training loss: 0.2829984122348026
Validation loss: 2.3906103920964465

Epoch: 6| Step: 3
Training loss: 0.5210596419442829
Validation loss: 2.392397444471792

Epoch: 6| Step: 4
Training loss: 0.1964527984485356
Validation loss: 2.389335037115314

Epoch: 6| Step: 5
Training loss: 0.5237051720656445
Validation loss: 2.3951182018169237

Epoch: 6| Step: 6
Training loss: 0.12741043182108402
Validation loss: 2.396149389135202

Epoch: 6| Step: 7
Training loss: 0.4494769805407119
Validation loss: 2.3564424468983654

Epoch: 6| Step: 8
Training loss: 0.42930907144481145
Validation loss: 2.3634401779683656

Epoch: 6| Step: 9
Training loss: 0.3601447444906741
Validation loss: 2.3396823732975687

Epoch: 6| Step: 10
Training loss: 0.37933419826746406
Validation loss: 2.3572961245759063

Epoch: 6| Step: 11
Training loss: 0.708978490043155
Validation loss: 2.3674694007004673

Epoch: 6| Step: 12
Training loss: 0.24967464495093433
Validation loss: 2.373991385342856

Epoch: 6| Step: 13
Training loss: 0.6413952453635698
Validation loss: 2.3516002255856825

Epoch: 362| Step: 0
Training loss: 0.43649605957472454
Validation loss: 2.3375932910116677

Epoch: 6| Step: 1
Training loss: 0.4547309205864137
Validation loss: 2.334957900603538

Epoch: 6| Step: 2
Training loss: 0.35285569868363115
Validation loss: 2.3596469021905864

Epoch: 6| Step: 3
Training loss: 0.34587022008236545
Validation loss: 2.3429342612731645

Epoch: 6| Step: 4
Training loss: 0.20365120513998689
Validation loss: 2.328566405373043

Epoch: 6| Step: 5
Training loss: 0.3092514224763688
Validation loss: 2.3191840640711323

Epoch: 6| Step: 6
Training loss: 0.6430102811172361
Validation loss: 2.3025714240095256

Epoch: 6| Step: 7
Training loss: 0.3544457775663566
Validation loss: 2.303358795320661

Epoch: 6| Step: 8
Training loss: 0.5910213160067495
Validation loss: 2.340540103124889

Epoch: 6| Step: 9
Training loss: 0.35083578021486655
Validation loss: 2.317979836862268

Epoch: 6| Step: 10
Training loss: 0.4475521519176754
Validation loss: 2.323739488300082

Epoch: 6| Step: 11
Training loss: 0.533411397535564
Validation loss: 2.343228140537339

Epoch: 6| Step: 12
Training loss: 0.5079097654652499
Validation loss: 2.3379497047890507

Epoch: 6| Step: 13
Training loss: 0.3299386785167841
Validation loss: 2.3090999954562883

Epoch: 363| Step: 0
Training loss: 0.3330167506296524
Validation loss: 2.3763747902048307

Epoch: 6| Step: 1
Training loss: 0.47039693156907286
Validation loss: 2.35751814296949

Epoch: 6| Step: 2
Training loss: 0.7121633085500062
Validation loss: 2.3739226487785423

Epoch: 6| Step: 3
Training loss: 0.4657434044133933
Validation loss: 2.3933068570958183

Epoch: 6| Step: 4
Training loss: 0.4678981511225231
Validation loss: 2.3848747932627816

Epoch: 6| Step: 5
Training loss: 0.15963327106653974
Validation loss: 2.3966239969225867

Epoch: 6| Step: 6
Training loss: 0.30190111973309414
Validation loss: 2.35723171773357

Epoch: 6| Step: 7
Training loss: 0.19564897164889286
Validation loss: 2.3321336485423205

Epoch: 6| Step: 8
Training loss: 0.5080551448068592
Validation loss: 2.38679417834918

Epoch: 6| Step: 9
Training loss: 0.40627763727520017
Validation loss: 2.393796276449624

Epoch: 6| Step: 10
Training loss: 0.44312648286019857
Validation loss: 2.3665244330833732

Epoch: 6| Step: 11
Training loss: 0.47764366268085634
Validation loss: 2.382830768517192

Epoch: 6| Step: 12
Training loss: 0.26310139860559334
Validation loss: 2.327357179118809

Epoch: 6| Step: 13
Training loss: 0.18261168976530304
Validation loss: 2.308184512888047

Epoch: 364| Step: 0
Training loss: 0.48764222100150184
Validation loss: 2.3486400625370125

Epoch: 6| Step: 1
Training loss: 0.5777614584578427
Validation loss: 2.3249503596247747

Epoch: 6| Step: 2
Training loss: 0.5826204888726314
Validation loss: 2.350468194347952

Epoch: 6| Step: 3
Training loss: 0.3389385928685575
Validation loss: 2.3716350091106615

Epoch: 6| Step: 4
Training loss: 0.49913805934827565
Validation loss: 2.3833228387980934

Epoch: 6| Step: 5
Training loss: 0.31574057974471514
Validation loss: 2.3568797861651185

Epoch: 6| Step: 6
Training loss: 0.3103490715335007
Validation loss: 2.3795200150662987

Epoch: 6| Step: 7
Training loss: 0.47667820885940115
Validation loss: 2.412697296346704

Epoch: 6| Step: 8
Training loss: 0.3930945913504602
Validation loss: 2.368783794944161

Epoch: 6| Step: 9
Training loss: 0.24852653743286388
Validation loss: 2.3624020250749185

Epoch: 6| Step: 10
Training loss: 0.29790213733980725
Validation loss: 2.3441661689463835

Epoch: 6| Step: 11
Training loss: 0.38094436479724686
Validation loss: 2.406593629559766

Epoch: 6| Step: 12
Training loss: 0.2485496426840297
Validation loss: 2.3902105312209474

Epoch: 6| Step: 13
Training loss: 0.4724510157135893
Validation loss: 2.375043453041406

Epoch: 365| Step: 0
Training loss: 0.2824267037428659
Validation loss: 2.4415445163090155

Epoch: 6| Step: 1
Training loss: 0.37298863141016025
Validation loss: 2.4479410840983022

Epoch: 6| Step: 2
Training loss: 0.5255437578154498
Validation loss: 2.426694336480665

Epoch: 6| Step: 3
Training loss: 0.47275906224897474
Validation loss: 2.4498858480080563

Epoch: 6| Step: 4
Training loss: 0.4421440305337714
Validation loss: 2.423644775146798

Epoch: 6| Step: 5
Training loss: 0.648430491030397
Validation loss: 2.4148211053355495

Epoch: 6| Step: 6
Training loss: 0.42406330527423813
Validation loss: 2.422870344917064

Epoch: 6| Step: 7
Training loss: 0.40216949541151276
Validation loss: 2.3946990086328523

Epoch: 6| Step: 8
Training loss: 0.3803652174058679
Validation loss: 2.420698811133858

Epoch: 6| Step: 9
Training loss: 0.66147499864465
Validation loss: 2.3975131323293684

Epoch: 6| Step: 10
Training loss: 0.4722858427782694
Validation loss: 2.3877319700861794

Epoch: 6| Step: 11
Training loss: 0.39308223337094095
Validation loss: 2.399231330973578

Epoch: 6| Step: 12
Training loss: 0.4221487040451365
Validation loss: 2.3728569467569134

Epoch: 6| Step: 13
Training loss: 0.5909811510317282
Validation loss: 2.372307547629003

Epoch: 366| Step: 0
Training loss: 0.5142602488006939
Validation loss: 2.367770873601845

Epoch: 6| Step: 1
Training loss: 0.4935376555716061
Validation loss: 2.3842983036056986

Epoch: 6| Step: 2
Training loss: 0.5514085592652304
Validation loss: 2.3794985611571966

Epoch: 6| Step: 3
Training loss: 0.5348189467380036
Validation loss: 2.368567707492268

Epoch: 6| Step: 4
Training loss: 0.6817226633802866
Validation loss: 2.3819228683684446

Epoch: 6| Step: 5
Training loss: 0.31316537355022683
Validation loss: 2.3856435057911747

Epoch: 6| Step: 6
Training loss: 0.3464155023326001
Validation loss: 2.4047370024576424

Epoch: 6| Step: 7
Training loss: 0.23808120710322317
Validation loss: 2.4047400183944383

Epoch: 6| Step: 8
Training loss: 0.3536509470881246
Validation loss: 2.417244589263524

Epoch: 6| Step: 9
Training loss: 0.30169104173792927
Validation loss: 2.391269104580451

Epoch: 6| Step: 10
Training loss: 0.4326474112465084
Validation loss: 2.4030338278326266

Epoch: 6| Step: 11
Training loss: 0.45840310158162934
Validation loss: 2.400065647145205

Epoch: 6| Step: 12
Training loss: 0.4413489751875853
Validation loss: 2.3859440321379957

Epoch: 6| Step: 13
Training loss: 0.5233963622823526
Validation loss: 2.373527395763272

Epoch: 367| Step: 0
Training loss: 0.42626905932842757
Validation loss: 2.3649944932570817

Epoch: 6| Step: 1
Training loss: 0.5121900993872381
Validation loss: 2.380140349414713

Epoch: 6| Step: 2
Training loss: 0.19913340591748724
Validation loss: 2.3691625373686644

Epoch: 6| Step: 3
Training loss: 0.46605655589539297
Validation loss: 2.354260638691226

Epoch: 6| Step: 4
Training loss: 0.23256738899984794
Validation loss: 2.3730540688136985

Epoch: 6| Step: 5
Training loss: 0.47537558915018735
Validation loss: 2.375711090636784

Epoch: 6| Step: 6
Training loss: 0.34314586914677137
Validation loss: 2.38701877098285

Epoch: 6| Step: 7
Training loss: 0.32722417609464943
Validation loss: 2.3800295416188684

Epoch: 6| Step: 8
Training loss: 0.3855551157402079
Validation loss: 2.3870066987378458

Epoch: 6| Step: 9
Training loss: 0.49908936544685906
Validation loss: 2.347062860010398

Epoch: 6| Step: 10
Training loss: 0.5828749411016603
Validation loss: 2.351437337859534

Epoch: 6| Step: 11
Training loss: 0.29786209337972835
Validation loss: 2.3311826776983744

Epoch: 6| Step: 12
Training loss: 0.6254196188863583
Validation loss: 2.3260094692960225

Epoch: 6| Step: 13
Training loss: 0.6152212958989239
Validation loss: 2.316512269167375

Epoch: 368| Step: 0
Training loss: 0.44366642742570883
Validation loss: 2.3417232476229732

Epoch: 6| Step: 1
Training loss: 0.417467940293098
Validation loss: 2.3478124532200857

Epoch: 6| Step: 2
Training loss: 0.4224155812599795
Validation loss: 2.359659081274386

Epoch: 6| Step: 3
Training loss: 0.489567063108597
Validation loss: 2.3457234265210882

Epoch: 6| Step: 4
Training loss: 0.5054559166530556
Validation loss: 2.3598794357822936

Epoch: 6| Step: 5
Training loss: 0.39067071647153395
Validation loss: 2.3462702916323073

Epoch: 6| Step: 6
Training loss: 0.1895953362371669
Validation loss: 2.377702917153923

Epoch: 6| Step: 7
Training loss: 0.409659166207389
Validation loss: 2.3963753873987548

Epoch: 6| Step: 8
Training loss: 0.6238854245197895
Validation loss: 2.428830050917873

Epoch: 6| Step: 9
Training loss: 0.6841673705886894
Validation loss: 2.4060682742990096

Epoch: 6| Step: 10
Training loss: 0.46184076288130854
Validation loss: 2.403457447748377

Epoch: 6| Step: 11
Training loss: 0.24196483774629965
Validation loss: 2.4205598020882046

Epoch: 6| Step: 12
Training loss: 0.40670721294909357
Validation loss: 2.3812172797431246

Epoch: 6| Step: 13
Training loss: 0.3867867920481504
Validation loss: 2.3508694025620724

Epoch: 369| Step: 0
Training loss: 0.5010982313630776
Validation loss: 2.3152879750219055

Epoch: 6| Step: 1
Training loss: 0.6006354086745095
Validation loss: 2.3251444535859496

Epoch: 6| Step: 2
Training loss: 0.6028041658275263
Validation loss: 2.3324983545054927

Epoch: 6| Step: 3
Training loss: 0.42783734201401663
Validation loss: 2.29252762623516

Epoch: 6| Step: 4
Training loss: 0.5472190864374171
Validation loss: 2.328166130205281

Epoch: 6| Step: 5
Training loss: 0.26262709288419095
Validation loss: 2.3246750564727052

Epoch: 6| Step: 6
Training loss: 0.26890807049770643
Validation loss: 2.339804731526424

Epoch: 6| Step: 7
Training loss: 0.3338552526534693
Validation loss: 2.35726481262116

Epoch: 6| Step: 8
Training loss: 0.5106457825333685
Validation loss: 2.36571025317911

Epoch: 6| Step: 9
Training loss: 0.4137779013512129
Validation loss: 2.3516069802603896

Epoch: 6| Step: 10
Training loss: 0.37773273077116776
Validation loss: 2.37434839831662

Epoch: 6| Step: 11
Training loss: 0.3864065894816844
Validation loss: 2.4026635936918495

Epoch: 6| Step: 12
Training loss: 0.24979196028391232
Validation loss: 2.399729199261521

Epoch: 6| Step: 13
Training loss: 0.286828169355801
Validation loss: 2.3791208456504793

Epoch: 370| Step: 0
Training loss: 0.3510973183960287
Validation loss: 2.354502966887729

Epoch: 6| Step: 1
Training loss: 0.24656364447904627
Validation loss: 2.3269554680835602

Epoch: 6| Step: 2
Training loss: 0.3029647073972776
Validation loss: 2.3290371332716067

Epoch: 6| Step: 3
Training loss: 0.41287074334412904
Validation loss: 2.2804243543704503

Epoch: 6| Step: 4
Training loss: 0.4426514776035209
Validation loss: 2.2909032953242296

Epoch: 6| Step: 5
Training loss: 0.46620674019543407
Validation loss: 2.291137815143745

Epoch: 6| Step: 6
Training loss: 0.5177768253890452
Validation loss: 2.313086434515206

Epoch: 6| Step: 7
Training loss: 0.33340944474234535
Validation loss: 2.3179180360567466

Epoch: 6| Step: 8
Training loss: 0.18584985590799086
Validation loss: 2.329951483057521

Epoch: 6| Step: 9
Training loss: 0.33010254718788123
Validation loss: 2.274708260670857

Epoch: 6| Step: 10
Training loss: 0.5197268813231536
Validation loss: 2.330382952420996

Epoch: 6| Step: 11
Training loss: 0.38473750752374947
Validation loss: 2.3651853655753268

Epoch: 6| Step: 12
Training loss: 0.47695070620711566
Validation loss: 2.3006751923278754

Epoch: 6| Step: 13
Training loss: 0.30174147922792355
Validation loss: 2.282053997234811

Epoch: 371| Step: 0
Training loss: 0.4898760576560402
Validation loss: 2.3398824369433053

Epoch: 6| Step: 1
Training loss: 0.37175164380636855
Validation loss: 2.3640720027247344

Epoch: 6| Step: 2
Training loss: 0.35355276892671167
Validation loss: 2.357748261163649

Epoch: 6| Step: 3
Training loss: 0.2546368285246828
Validation loss: 2.3384016632597424

Epoch: 6| Step: 4
Training loss: 0.22073305821615
Validation loss: 2.3903473466222307

Epoch: 6| Step: 5
Training loss: 0.3029983231235282
Validation loss: 2.4116338081615103

Epoch: 6| Step: 6
Training loss: 0.41702834961941315
Validation loss: 2.434589885349681

Epoch: 6| Step: 7
Training loss: 0.29459317312753674
Validation loss: 2.3861586308887803

Epoch: 6| Step: 8
Training loss: 0.3684623380188363
Validation loss: 2.420266232708701

Epoch: 6| Step: 9
Training loss: 0.49080541112208953
Validation loss: 2.4186448323893175

Epoch: 6| Step: 10
Training loss: 0.32665595948584003
Validation loss: 2.411974325456039

Epoch: 6| Step: 11
Training loss: 0.34383414062354994
Validation loss: 2.44089086304398

Epoch: 6| Step: 12
Training loss: 0.5770777418597896
Validation loss: 2.3964967765867984

Epoch: 6| Step: 13
Training loss: 0.24409205144238233
Validation loss: 2.379979169404044

Epoch: 372| Step: 0
Training loss: 0.4565426423586734
Validation loss: 2.375901427341903

Epoch: 6| Step: 1
Training loss: 0.5009139767345414
Validation loss: 2.3592082448693055

Epoch: 6| Step: 2
Training loss: 0.2743506171573603
Validation loss: 2.380246064080086

Epoch: 6| Step: 3
Training loss: 0.40766277780273935
Validation loss: 2.373392924695215

Epoch: 6| Step: 4
Training loss: 0.2977002619447155
Validation loss: 2.3670372769251

Epoch: 6| Step: 5
Training loss: 0.26407959109642454
Validation loss: 2.3385053960205164

Epoch: 6| Step: 6
Training loss: 0.42339605290452054
Validation loss: 2.373709642772158

Epoch: 6| Step: 7
Training loss: 0.4463682542652787
Validation loss: 2.330509737022234

Epoch: 6| Step: 8
Training loss: 0.15885753445625125
Validation loss: 2.3939957811175163

Epoch: 6| Step: 9
Training loss: 0.4395514484189421
Validation loss: 2.392720752020098

Epoch: 6| Step: 10
Training loss: 0.30998611203740545
Validation loss: 2.3839948523782364

Epoch: 6| Step: 11
Training loss: 0.43702961975600996
Validation loss: 2.4026350811644512

Epoch: 6| Step: 12
Training loss: 0.324171614380337
Validation loss: 2.3937296066244413

Epoch: 6| Step: 13
Training loss: 0.15477326043563497
Validation loss: 2.409425055322237

Epoch: 373| Step: 0
Training loss: 0.3716780028553088
Validation loss: 2.3686629715708416

Epoch: 6| Step: 1
Training loss: 0.5684549048193457
Validation loss: 2.358625505232374

Epoch: 6| Step: 2
Training loss: 0.32160929110519043
Validation loss: 2.3572247692761747

Epoch: 6| Step: 3
Training loss: 0.3469638358449028
Validation loss: 2.2743264958499108

Epoch: 6| Step: 4
Training loss: 0.41273140629847543
Validation loss: 2.328289036389276

Epoch: 6| Step: 5
Training loss: 0.1737314662722447
Validation loss: 2.329576925037353

Epoch: 6| Step: 6
Training loss: 0.44734061332986
Validation loss: 2.2781831334958373

Epoch: 6| Step: 7
Training loss: 0.5233019183483276
Validation loss: 2.310675374843301

Epoch: 6| Step: 8
Training loss: 0.4205875354820457
Validation loss: 2.2885451759293063

Epoch: 6| Step: 9
Training loss: 0.3203924823549948
Validation loss: 2.3169264773050897

Epoch: 6| Step: 10
Training loss: 0.22116959487456572
Validation loss: 2.335445135822569

Epoch: 6| Step: 11
Training loss: 0.26790278988126315
Validation loss: 2.3460822617366253

Epoch: 6| Step: 12
Training loss: 0.32915272300900006
Validation loss: 2.3554050518095986

Epoch: 6| Step: 13
Training loss: 0.21992314340012223
Validation loss: 2.4148084124830955

Epoch: 374| Step: 0
Training loss: 0.3333437279729567
Validation loss: 2.3993825314286936

Epoch: 6| Step: 1
Training loss: 0.3632757740223311
Validation loss: 2.400428171657768

Epoch: 6| Step: 2
Training loss: 0.24052482972281297
Validation loss: 2.4232751266495023

Epoch: 6| Step: 3
Training loss: 0.6038220069230805
Validation loss: 2.403342209778921

Epoch: 6| Step: 4
Training loss: 0.5082658944447472
Validation loss: 2.405897842674389

Epoch: 6| Step: 5
Training loss: 0.3632672214875792
Validation loss: 2.406765406768057

Epoch: 6| Step: 6
Training loss: 0.2619283320944017
Validation loss: 2.361342668689981

Epoch: 6| Step: 7
Training loss: 0.41012071728061644
Validation loss: 2.3903240390012725

Epoch: 6| Step: 8
Training loss: 0.27486145636953585
Validation loss: 2.3573980569717365

Epoch: 6| Step: 9
Training loss: 0.3432026102716488
Validation loss: 2.375372019345652

Epoch: 6| Step: 10
Training loss: 0.2989041350190654
Validation loss: 2.361065662010146

Epoch: 6| Step: 11
Training loss: 0.18411065443200272
Validation loss: 2.4009148067691717

Epoch: 6| Step: 12
Training loss: 0.20484111350637532
Validation loss: 2.37984477311295

Epoch: 6| Step: 13
Training loss: 0.3032434920126037
Validation loss: 2.3633678545499506

Epoch: 375| Step: 0
Training loss: 0.3186889416986905
Validation loss: 2.35624510909628

Epoch: 6| Step: 1
Training loss: 0.23635260400021543
Validation loss: 2.3547880817433398

Epoch: 6| Step: 2
Training loss: 0.35328329471230935
Validation loss: 2.3743373516360338

Epoch: 6| Step: 3
Training loss: 0.28004349104702253
Validation loss: 2.3689896795233576

Epoch: 6| Step: 4
Training loss: 0.3255384313277025
Validation loss: 2.3420848769745817

Epoch: 6| Step: 5
Training loss: 0.32712197267897514
Validation loss: 2.3902374099222476

Epoch: 6| Step: 6
Training loss: 0.23493196748012365
Validation loss: 2.448132105981712

Epoch: 6| Step: 7
Training loss: 0.48237155543765853
Validation loss: 2.417484694943363

Epoch: 6| Step: 8
Training loss: 0.2928190611854312
Validation loss: 2.4182101208790123

Epoch: 6| Step: 9
Training loss: 0.4535526033845926
Validation loss: 2.415693380583541

Epoch: 6| Step: 10
Training loss: 0.45659977360614107
Validation loss: 2.4201872259521178

Epoch: 6| Step: 11
Training loss: 0.5480587001620524
Validation loss: 2.40038769571442

Epoch: 6| Step: 12
Training loss: 0.2102627558779261
Validation loss: 2.411227253966962

Epoch: 6| Step: 13
Training loss: 0.2661774024355864
Validation loss: 2.41054281328184

Epoch: 376| Step: 0
Training loss: 0.25926050393686284
Validation loss: 2.3879195369516024

Epoch: 6| Step: 1
Training loss: 0.2780884027512466
Validation loss: 2.3703257520862224

Epoch: 6| Step: 2
Training loss: 0.29062503486551056
Validation loss: 2.3584112567638558

Epoch: 6| Step: 3
Training loss: 0.27620476576769926
Validation loss: 2.298875273827589

Epoch: 6| Step: 4
Training loss: 0.1980203599504421
Validation loss: 2.3699709393884865

Epoch: 6| Step: 5
Training loss: 0.4495401310896993
Validation loss: 2.33135905514523

Epoch: 6| Step: 6
Training loss: 0.21925875561781655
Validation loss: 2.318148449631707

Epoch: 6| Step: 7
Training loss: 0.4144530883271312
Validation loss: 2.3558560871608543

Epoch: 6| Step: 8
Training loss: 0.4058234836837442
Validation loss: 2.351463148156216

Epoch: 6| Step: 9
Training loss: 0.29534061338433965
Validation loss: 2.372416119945604

Epoch: 6| Step: 10
Training loss: 0.40813728422105644
Validation loss: 2.375024896328221

Epoch: 6| Step: 11
Training loss: 0.44316363950383864
Validation loss: 2.3799740921608565

Epoch: 6| Step: 12
Training loss: 0.3794444479685557
Validation loss: 2.3863289290515692

Epoch: 6| Step: 13
Training loss: 0.4797781190796745
Validation loss: 2.3908052075602386

Epoch: 377| Step: 0
Training loss: 0.3361383436546989
Validation loss: 2.3622522779733015

Epoch: 6| Step: 1
Training loss: 0.3658710988276287
Validation loss: 2.387109757906778

Epoch: 6| Step: 2
Training loss: 0.26443908124454096
Validation loss: 2.3719563662316236

Epoch: 6| Step: 3
Training loss: 0.29512775889459886
Validation loss: 2.3850363013334714

Epoch: 6| Step: 4
Training loss: 0.5581965067680013
Validation loss: 2.3749891107090444

Epoch: 6| Step: 5
Training loss: 0.2931094022720644
Validation loss: 2.396523842054227

Epoch: 6| Step: 6
Training loss: 0.4639786275214455
Validation loss: 2.3994765320310485

Epoch: 6| Step: 7
Training loss: 0.2407107011716441
Validation loss: 2.364048117770301

Epoch: 6| Step: 8
Training loss: 0.18595624236204072
Validation loss: 2.3543071554264436

Epoch: 6| Step: 9
Training loss: 0.4508421712926918
Validation loss: 2.3178630268883174

Epoch: 6| Step: 10
Training loss: 0.31918910205828177
Validation loss: 2.322736457674443

Epoch: 6| Step: 11
Training loss: 0.23589847065040545
Validation loss: 2.3223305114464625

Epoch: 6| Step: 12
Training loss: 0.522648886270923
Validation loss: 2.3616397394578637

Epoch: 6| Step: 13
Training loss: 0.19898393293196087
Validation loss: 2.355966723948841

Epoch: 378| Step: 0
Training loss: 0.3907409114525074
Validation loss: 2.323352457388194

Epoch: 6| Step: 1
Training loss: 0.3010429630889609
Validation loss: 2.304276834854653

Epoch: 6| Step: 2
Training loss: 0.45777257478321665
Validation loss: 2.3416841039124043

Epoch: 6| Step: 3
Training loss: 0.18397004543474949
Validation loss: 2.3148171551144525

Epoch: 6| Step: 4
Training loss: 0.29147329760799556
Validation loss: 2.3556555409293405

Epoch: 6| Step: 5
Training loss: 0.3503859967252475
Validation loss: 2.366441392843278

Epoch: 6| Step: 6
Training loss: 0.37958581685294684
Validation loss: 2.344296975247524

Epoch: 6| Step: 7
Training loss: 0.3756488907971172
Validation loss: 2.3635845318209143

Epoch: 6| Step: 8
Training loss: 0.4495259768561596
Validation loss: 2.3879469546093137

Epoch: 6| Step: 9
Training loss: 0.5957132307352341
Validation loss: 2.424090760840014

Epoch: 6| Step: 10
Training loss: 0.43843586484314573
Validation loss: 2.3990352872094163

Epoch: 6| Step: 11
Training loss: 0.22888053385046295
Validation loss: 2.395238941894063

Epoch: 6| Step: 12
Training loss: 0.4415093698144547
Validation loss: 2.377292955346363

Epoch: 6| Step: 13
Training loss: 0.30671958149793865
Validation loss: 2.3582188691719033

Epoch: 379| Step: 0
Training loss: 0.26974023097912475
Validation loss: 2.3631457928725212

Epoch: 6| Step: 1
Training loss: 0.3573953170498386
Validation loss: 2.341146902453932

Epoch: 6| Step: 2
Training loss: 0.3199639284583016
Validation loss: 2.354983912001233

Epoch: 6| Step: 3
Training loss: 0.6324061513716797
Validation loss: 2.3352905602919707

Epoch: 6| Step: 4
Training loss: 0.4643758133564086
Validation loss: 2.346697428892983

Epoch: 6| Step: 5
Training loss: 0.28072443175466
Validation loss: 2.364621547577927

Epoch: 6| Step: 6
Training loss: 0.309625734969781
Validation loss: 2.3873421567274615

Epoch: 6| Step: 7
Training loss: 0.3457029094803133
Validation loss: 2.3887885091399497

Epoch: 6| Step: 8
Training loss: 0.48500481544149054
Validation loss: 2.3858174425621543

Epoch: 6| Step: 9
Training loss: 0.27952311762520615
Validation loss: 2.43449428147696

Epoch: 6| Step: 10
Training loss: 0.21863999325490538
Validation loss: 2.410252140118939

Epoch: 6| Step: 11
Training loss: 0.21417701609599804
Validation loss: 2.3939807665053965

Epoch: 6| Step: 12
Training loss: 0.3327070875190305
Validation loss: 2.381972922340426

Epoch: 6| Step: 13
Training loss: 0.31154114723689463
Validation loss: 2.368529543205565

Epoch: 380| Step: 0
Training loss: 0.3286873562492061
Validation loss: 2.370658118059145

Epoch: 6| Step: 1
Training loss: 0.25043649119475503
Validation loss: 2.3358721409624965

Epoch: 6| Step: 2
Training loss: 0.405366560566698
Validation loss: 2.350505679279645

Epoch: 6| Step: 3
Training loss: 0.3042041661823051
Validation loss: 2.352657372981296

Epoch: 6| Step: 4
Training loss: 0.31213816914564024
Validation loss: 2.3498553292403717

Epoch: 6| Step: 5
Training loss: 0.4927363287598328
Validation loss: 2.35552693887293

Epoch: 6| Step: 6
Training loss: 0.22296278749765958
Validation loss: 2.3368267885694953

Epoch: 6| Step: 7
Training loss: 0.4003256023922019
Validation loss: 2.3102482367368125

Epoch: 6| Step: 8
Training loss: 0.5109463168908787
Validation loss: 2.3621369160513934

Epoch: 6| Step: 9
Training loss: 0.4700172143685268
Validation loss: 2.3620363983262145

Epoch: 6| Step: 10
Training loss: 0.4432834442589942
Validation loss: 2.3312212274004107

Epoch: 6| Step: 11
Training loss: 0.2116627675467652
Validation loss: 2.398262067479935

Epoch: 6| Step: 12
Training loss: 0.34258947842965826
Validation loss: 2.3887988552731176

Epoch: 6| Step: 13
Training loss: 0.289189169168035
Validation loss: 2.3833149870184944

Epoch: 381| Step: 0
Training loss: 0.24262889508909455
Validation loss: 2.3661016616811286

Epoch: 6| Step: 1
Training loss: 0.4099930211380396
Validation loss: 2.345552807456869

Epoch: 6| Step: 2
Training loss: 0.3360771288235599
Validation loss: 2.3765373759219885

Epoch: 6| Step: 3
Training loss: 0.3150145689683258
Validation loss: 2.383634846904747

Epoch: 6| Step: 4
Training loss: 0.2609988603000677
Validation loss: 2.3482200146712655

Epoch: 6| Step: 5
Training loss: 0.19901684271880232
Validation loss: 2.358606339468717

Epoch: 6| Step: 6
Training loss: 0.26672657980261977
Validation loss: 2.3841748019341003

Epoch: 6| Step: 7
Training loss: 0.37695122752922694
Validation loss: 2.425337508726834

Epoch: 6| Step: 8
Training loss: 0.5291871242123134
Validation loss: 2.3745430526738756

Epoch: 6| Step: 9
Training loss: 0.17834674225698796
Validation loss: 2.440812753382443

Epoch: 6| Step: 10
Training loss: 0.20046329704949714
Validation loss: 2.3876949232879423

Epoch: 6| Step: 11
Training loss: 0.48749873210057415
Validation loss: 2.40455363513621

Epoch: 6| Step: 12
Training loss: 0.3220179212718673
Validation loss: 2.398933855244397

Epoch: 6| Step: 13
Training loss: 0.532699486837181
Validation loss: 2.427564123822506

Epoch: 382| Step: 0
Training loss: 0.4000237994266429
Validation loss: 2.4402162453887386

Epoch: 6| Step: 1
Training loss: 0.27797420464192707
Validation loss: 2.397476054356687

Epoch: 6| Step: 2
Training loss: 0.21783990230618
Validation loss: 2.4303273437135133

Epoch: 6| Step: 3
Training loss: 0.326706465331004
Validation loss: 2.4295220824060597

Epoch: 6| Step: 4
Training loss: 0.40594382853049643
Validation loss: 2.384081306121558

Epoch: 6| Step: 5
Training loss: 0.29554089892338
Validation loss: 2.3835911331767115

Epoch: 6| Step: 6
Training loss: 0.19103266790142437
Validation loss: 2.394161179775978

Epoch: 6| Step: 7
Training loss: 0.26447887548846555
Validation loss: 2.3739177805054164

Epoch: 6| Step: 8
Training loss: 0.25555218025468673
Validation loss: 2.358724254325899

Epoch: 6| Step: 9
Training loss: 0.3934193608024016
Validation loss: 2.365541811835406

Epoch: 6| Step: 10
Training loss: 0.29427183905010473
Validation loss: 2.360165818309586

Epoch: 6| Step: 11
Training loss: 0.29716285753821925
Validation loss: 2.3783587877480414

Epoch: 6| Step: 12
Training loss: 0.5887477620805133
Validation loss: 2.337016073775824

Epoch: 6| Step: 13
Training loss: 0.34546877574187296
Validation loss: 2.3418125723135725

Epoch: 383| Step: 0
Training loss: 0.4558464081136824
Validation loss: 2.366763679368233

Epoch: 6| Step: 1
Training loss: 0.41709966413529675
Validation loss: 2.3321293377576233

Epoch: 6| Step: 2
Training loss: 0.3649373402112535
Validation loss: 2.392712141966795

Epoch: 6| Step: 3
Training loss: 0.48711108564552147
Validation loss: 2.3376040507193063

Epoch: 6| Step: 4
Training loss: 0.3078022596911779
Validation loss: 2.3123102517674017

Epoch: 6| Step: 5
Training loss: 0.17881352966262806
Validation loss: 2.2907530763700272

Epoch: 6| Step: 6
Training loss: 0.2692251125431809
Validation loss: 2.328449275960934

Epoch: 6| Step: 7
Training loss: 0.2750343155041527
Validation loss: 2.337366364906627

Epoch: 6| Step: 8
Training loss: 0.24481586918327558
Validation loss: 2.305935480668937

Epoch: 6| Step: 9
Training loss: 0.2730490513879923
Validation loss: 2.3497858514567223

Epoch: 6| Step: 10
Training loss: 0.20633468767711788
Validation loss: 2.3225108764850124

Epoch: 6| Step: 11
Training loss: 0.18086340963588504
Validation loss: 2.354656076773118

Epoch: 6| Step: 12
Training loss: 0.2713298495056901
Validation loss: 2.3573235009204874

Epoch: 6| Step: 13
Training loss: 0.4576783774702787
Validation loss: 2.3490644552447155

Epoch: 384| Step: 0
Training loss: 0.3015800619200033
Validation loss: 2.3827941431192086

Epoch: 6| Step: 1
Training loss: 0.41587551426031605
Validation loss: 2.392123403761031

Epoch: 6| Step: 2
Training loss: 0.40065728588608546
Validation loss: 2.4196122442744707

Epoch: 6| Step: 3
Training loss: 0.5703574907506709
Validation loss: 2.4043404169943883

Epoch: 6| Step: 4
Training loss: 0.29128493578375225
Validation loss: 2.411592342168769

Epoch: 6| Step: 5
Training loss: 0.27916733198418736
Validation loss: 2.4115705027928622

Epoch: 6| Step: 6
Training loss: 0.15042369033163466
Validation loss: 2.405629774198171

Epoch: 6| Step: 7
Training loss: 0.15257889988160928
Validation loss: 2.4081884523313386

Epoch: 6| Step: 8
Training loss: 0.3421161141682424
Validation loss: 2.3770229023220737

Epoch: 6| Step: 9
Training loss: 0.2714460881082562
Validation loss: 2.386002631214156

Epoch: 6| Step: 10
Training loss: 0.20122926319393955
Validation loss: 2.3634368533383845

Epoch: 6| Step: 11
Training loss: 0.28309184551851163
Validation loss: 2.3745493431609486

Epoch: 6| Step: 12
Training loss: 0.19530300117282565
Validation loss: 2.385013385204659

Epoch: 6| Step: 13
Training loss: 0.41620133960385475
Validation loss: 2.3692011221225373

Epoch: 385| Step: 0
Training loss: 0.4029146976613505
Validation loss: 2.3623593433215038

Epoch: 6| Step: 1
Training loss: 0.4431930599754214
Validation loss: 2.4071768488658734

Epoch: 6| Step: 2
Training loss: 0.22781800293522736
Validation loss: 2.344972538008763

Epoch: 6| Step: 3
Training loss: 0.3160505768222551
Validation loss: 2.33044341721102

Epoch: 6| Step: 4
Training loss: 0.23243986589059046
Validation loss: 2.317253869244617

Epoch: 6| Step: 5
Training loss: 0.336302204440251
Validation loss: 2.3578619247500643

Epoch: 6| Step: 6
Training loss: 0.454858538650279
Validation loss: 2.3057529784838717

Epoch: 6| Step: 7
Training loss: 0.250986358807626
Validation loss: 2.3337651093502343

Epoch: 6| Step: 8
Training loss: 0.26683467412913947
Validation loss: 2.322990978775263

Epoch: 6| Step: 9
Training loss: 0.20661035975902609
Validation loss: 2.3059561753825895

Epoch: 6| Step: 10
Training loss: 0.25295734622502797
Validation loss: 2.3693433288588066

Epoch: 6| Step: 11
Training loss: 0.4462034614989983
Validation loss: 2.355894802792754

Epoch: 6| Step: 12
Training loss: 0.3171652062572554
Validation loss: 2.3654611084129895

Epoch: 6| Step: 13
Training loss: 0.3147197209315682
Validation loss: 2.3785894004325234

Epoch: 386| Step: 0
Training loss: 0.3697836387013596
Validation loss: 2.3735674195129906

Epoch: 6| Step: 1
Training loss: 0.24926743614798005
Validation loss: 2.4031432191388626

Epoch: 6| Step: 2
Training loss: 0.26489713462742975
Validation loss: 2.3965254498623842

Epoch: 6| Step: 3
Training loss: 0.3748686083445589
Validation loss: 2.402334775857065

Epoch: 6| Step: 4
Training loss: 0.41964476557416525
Validation loss: 2.415300735006977

Epoch: 6| Step: 5
Training loss: 0.21024973325224838
Validation loss: 2.4066861687840033

Epoch: 6| Step: 6
Training loss: 0.2874908119267646
Validation loss: 2.408125595067533

Epoch: 6| Step: 7
Training loss: 0.4052026342107229
Validation loss: 2.4039846090068733

Epoch: 6| Step: 8
Training loss: 0.2216083058784181
Validation loss: 2.391819656959548

Epoch: 6| Step: 9
Training loss: 0.32627334843685885
Validation loss: 2.3318575537091255

Epoch: 6| Step: 10
Training loss: 0.3635002624557996
Validation loss: 2.3355383481717844

Epoch: 6| Step: 11
Training loss: 0.32893636841953533
Validation loss: 2.3529988959958215

Epoch: 6| Step: 12
Training loss: 0.21657838207207875
Validation loss: 2.306648878232272

Epoch: 6| Step: 13
Training loss: 0.352000715740652
Validation loss: 2.2856216796679316

Epoch: 387| Step: 0
Training loss: 0.23758113127853914
Validation loss: 2.352009431629218

Epoch: 6| Step: 1
Training loss: 0.2678269809248695
Validation loss: 2.371627718570264

Epoch: 6| Step: 2
Training loss: 0.22542970374766166
Validation loss: 2.3706953753996647

Epoch: 6| Step: 3
Training loss: 0.45084456754438323
Validation loss: 2.3802556239440555

Epoch: 6| Step: 4
Training loss: 0.3138238047235233
Validation loss: 2.4221237938704094

Epoch: 6| Step: 5
Training loss: 0.30514190485803716
Validation loss: 2.402072421429437

Epoch: 6| Step: 6
Training loss: 0.2919588994982989
Validation loss: 2.3741387401564364

Epoch: 6| Step: 7
Training loss: 0.3403405471677675
Validation loss: 2.371933417223911

Epoch: 6| Step: 8
Training loss: 0.5107598092009661
Validation loss: 2.377578053936814

Epoch: 6| Step: 9
Training loss: 0.1929301400883138
Validation loss: 2.3469057677024656

Epoch: 6| Step: 10
Training loss: 0.43483943535449204
Validation loss: 2.3394745363491585

Epoch: 6| Step: 11
Training loss: 0.33496099310782723
Validation loss: 2.3480273805463305

Epoch: 6| Step: 12
Training loss: 0.15647629801282967
Validation loss: 2.367154558460818

Epoch: 6| Step: 13
Training loss: 0.4698982638724176
Validation loss: 2.40022678777823

Epoch: 388| Step: 0
Training loss: 0.15291016991255033
Validation loss: 2.402143671851626

Epoch: 6| Step: 1
Training loss: 0.13944074885696967
Validation loss: 2.4135484953653807

Epoch: 6| Step: 2
Training loss: 0.2650504911653134
Validation loss: 2.435389119818996

Epoch: 6| Step: 3
Training loss: 0.34584423999746494
Validation loss: 2.404274251745844

Epoch: 6| Step: 4
Training loss: 0.14520965982508083
Validation loss: 2.4111690967484662

Epoch: 6| Step: 5
Training loss: 0.38743598009215363
Validation loss: 2.453272352985012

Epoch: 6| Step: 6
Training loss: 0.47013231545527623
Validation loss: 2.406488541795873

Epoch: 6| Step: 7
Training loss: 0.2157117821027989
Validation loss: 2.4329022528723985

Epoch: 6| Step: 8
Training loss: 0.36280444859944294
Validation loss: 2.4277359975137975

Epoch: 6| Step: 9
Training loss: 0.2931154519581849
Validation loss: 2.386920548574409

Epoch: 6| Step: 10
Training loss: 0.45386925774747344
Validation loss: 2.413788455985131

Epoch: 6| Step: 11
Training loss: 0.24799042908020136
Validation loss: 2.4230129737418133

Epoch: 6| Step: 12
Training loss: 0.34173104878477284
Validation loss: 2.4000047882777475

Epoch: 6| Step: 13
Training loss: 0.2426386369182443
Validation loss: 2.3850937785239155

Epoch: 389| Step: 0
Training loss: 0.405625946061452
Validation loss: 2.409050620376301

Epoch: 6| Step: 1
Training loss: 0.48004808075819877
Validation loss: 2.4206591673973965

Epoch: 6| Step: 2
Training loss: 0.2618259665804363
Validation loss: 2.4224590278763056

Epoch: 6| Step: 3
Training loss: 0.31570159483163307
Validation loss: 2.3895821942702016

Epoch: 6| Step: 4
Training loss: 0.29941553462612813
Validation loss: 2.4233757468749433

Epoch: 6| Step: 5
Training loss: 0.24661982029581317
Validation loss: 2.4008003554747526

Epoch: 6| Step: 6
Training loss: 0.20612185861334753
Validation loss: 2.39834158111269

Epoch: 6| Step: 7
Training loss: 0.22800102327037705
Validation loss: 2.356502900127649

Epoch: 6| Step: 8
Training loss: 0.4094119084442312
Validation loss: 2.379446177489655

Epoch: 6| Step: 9
Training loss: 0.23125681867083414
Validation loss: 2.3682728447988053

Epoch: 6| Step: 10
Training loss: 0.23865347852217805
Validation loss: 2.380920429293684

Epoch: 6| Step: 11
Training loss: 0.2964555135759481
Validation loss: 2.394464656312869

Epoch: 6| Step: 12
Training loss: 0.2313600777559781
Validation loss: 2.3629233148640547

Epoch: 6| Step: 13
Training loss: 0.31644145157524367
Validation loss: 2.367538484068117

Epoch: 390| Step: 0
Training loss: 0.18887969866146123
Validation loss: 2.3990057388054624

Epoch: 6| Step: 1
Training loss: 0.4098843717931682
Validation loss: 2.3809570533659716

Epoch: 6| Step: 2
Training loss: 0.27848773404680927
Validation loss: 2.376950894576831

Epoch: 6| Step: 3
Training loss: 0.3691610704038008
Validation loss: 2.3128584359754045

Epoch: 6| Step: 4
Training loss: 0.42517871394984413
Validation loss: 2.3635801704755224

Epoch: 6| Step: 5
Training loss: 0.22905459788484733
Validation loss: 2.3496569608710125

Epoch: 6| Step: 6
Training loss: 0.3233477371160234
Validation loss: 2.378880513299848

Epoch: 6| Step: 7
Training loss: 0.36498180366909305
Validation loss: 2.3855703612184436

Epoch: 6| Step: 8
Training loss: 0.27523599165594054
Validation loss: 2.387042777283031

Epoch: 6| Step: 9
Training loss: 0.34772750038648376
Validation loss: 2.3973111410543635

Epoch: 6| Step: 10
Training loss: 0.27758505894433694
Validation loss: 2.441486434965134

Epoch: 6| Step: 11
Training loss: 0.24294551542017065
Validation loss: 2.416009302942008

Epoch: 6| Step: 12
Training loss: 0.1947416355187825
Validation loss: 2.3784838508776978

Epoch: 6| Step: 13
Training loss: 0.44197978677855226
Validation loss: 2.413781694763325

Epoch: 391| Step: 0
Training loss: 0.4030626411408165
Validation loss: 2.3943331791982567

Epoch: 6| Step: 1
Training loss: 0.42596088784617414
Validation loss: 2.403837817030113

Epoch: 6| Step: 2
Training loss: 0.40797816014038674
Validation loss: 2.4199224534267807

Epoch: 6| Step: 3
Training loss: 0.3693364345601659
Validation loss: 2.337814565166932

Epoch: 6| Step: 4
Training loss: 0.2864426897574719
Validation loss: 2.365620220464133

Epoch: 6| Step: 5
Training loss: 0.33016797259308533
Validation loss: 2.354788575465435

Epoch: 6| Step: 6
Training loss: 0.300387657557639
Validation loss: 2.3724222955852987

Epoch: 6| Step: 7
Training loss: 0.26280509328214063
Validation loss: 2.3872881238845167

Epoch: 6| Step: 8
Training loss: 0.2148470444860155
Validation loss: 2.367828532515788

Epoch: 6| Step: 9
Training loss: 0.40266057845169845
Validation loss: 2.3891297136570935

Epoch: 6| Step: 10
Training loss: 0.26925246706711625
Validation loss: 2.3741328810501345

Epoch: 6| Step: 11
Training loss: 0.16256114332094238
Validation loss: 2.38832321441686

Epoch: 6| Step: 12
Training loss: 0.2251219994876139
Validation loss: 2.4028052528933803

Epoch: 6| Step: 13
Training loss: 0.19668487004078525
Validation loss: 2.375869787083581

Epoch: 392| Step: 0
Training loss: 0.4515615984633795
Validation loss: 2.3824714463638417

Epoch: 6| Step: 1
Training loss: 0.20064463550524445
Validation loss: 2.3963325811383185

Epoch: 6| Step: 2
Training loss: 0.23842500040180917
Validation loss: 2.3904300636761007

Epoch: 6| Step: 3
Training loss: 0.26673956851798053
Validation loss: 2.3745848852064637

Epoch: 6| Step: 4
Training loss: 0.1766190801115706
Validation loss: 2.3595770711517052

Epoch: 6| Step: 5
Training loss: 0.29299275617791215
Validation loss: 2.3557465693391166

Epoch: 6| Step: 6
Training loss: 0.33878026281641743
Validation loss: 2.3533164959483885

Epoch: 6| Step: 7
Training loss: 0.2884467500172606
Validation loss: 2.324353146995343

Epoch: 6| Step: 8
Training loss: 0.22910187990340597
Validation loss: 2.34262215553075

Epoch: 6| Step: 9
Training loss: 0.3506349619641888
Validation loss: 2.317651788663107

Epoch: 6| Step: 10
Training loss: 0.3362907060992212
Validation loss: 2.3474867873230787

Epoch: 6| Step: 11
Training loss: 0.2593742950843516
Validation loss: 2.328259216655036

Epoch: 6| Step: 12
Training loss: 0.4022004881675656
Validation loss: 2.3241743439764826

Epoch: 6| Step: 13
Training loss: 0.14077983385531753
Validation loss: 2.3076740772890822

Epoch: 393| Step: 0
Training loss: 0.26561299465201066
Validation loss: 2.3105533913102225

Epoch: 6| Step: 1
Training loss: 0.44681941600382336
Validation loss: 2.3290739457889376

Epoch: 6| Step: 2
Training loss: 0.21263768980495312
Validation loss: 2.274283574718856

Epoch: 6| Step: 3
Training loss: 0.31593172966114463
Validation loss: 2.2827464101241977

Epoch: 6| Step: 4
Training loss: 0.2282678532439096
Validation loss: 2.295719394283742

Epoch: 6| Step: 5
Training loss: 0.28524871528914575
Validation loss: 2.3078014451635265

Epoch: 6| Step: 6
Training loss: 0.1492079641029024
Validation loss: 2.3247298727461505

Epoch: 6| Step: 7
Training loss: 0.16950757942547623
Validation loss: 2.2923668065015335

Epoch: 6| Step: 8
Training loss: 0.323434755064885
Validation loss: 2.31693661654334

Epoch: 6| Step: 9
Training loss: 0.14894103925744231
Validation loss: 2.353554355713004

Epoch: 6| Step: 10
Training loss: 0.27916276819913743
Validation loss: 2.3031803765766736

Epoch: 6| Step: 11
Training loss: 0.4310147334786744
Validation loss: 2.3195713323838034

Epoch: 6| Step: 12
Training loss: 0.26119103535151095
Validation loss: 2.3281707307704442

Epoch: 6| Step: 13
Training loss: 0.22588992588789686
Validation loss: 2.3443512449593227

Epoch: 394| Step: 0
Training loss: 0.20977488413857426
Validation loss: 2.3417035997625564

Epoch: 6| Step: 1
Training loss: 0.2616130131309778
Validation loss: 2.342748949664749

Epoch: 6| Step: 2
Training loss: 0.1777299943321213
Validation loss: 2.354583453600495

Epoch: 6| Step: 3
Training loss: 0.3606578280086584
Validation loss: 2.3347487657561605

Epoch: 6| Step: 4
Training loss: 0.20525343531638862
Validation loss: 2.326365811947701

Epoch: 6| Step: 5
Training loss: 0.1725504564008422
Validation loss: 2.3382758405074586

Epoch: 6| Step: 6
Training loss: 0.3996797717781137
Validation loss: 2.3421972790587904

Epoch: 6| Step: 7
Training loss: 0.33248127004386463
Validation loss: 2.308641719894061

Epoch: 6| Step: 8
Training loss: 0.33091613660952607
Validation loss: 2.340130110258426

Epoch: 6| Step: 9
Training loss: 0.350998362276544
Validation loss: 2.3089286833720006

Epoch: 6| Step: 10
Training loss: 0.23410737334546933
Validation loss: 2.2999500336108305

Epoch: 6| Step: 11
Training loss: 0.2378728994646607
Validation loss: 2.3000329665772505

Epoch: 6| Step: 12
Training loss: 0.19652446466767776
Validation loss: 2.299431336566864

Epoch: 6| Step: 13
Training loss: 0.4353592643895098
Validation loss: 2.3103021477831724

Epoch: 395| Step: 0
Training loss: 0.39146299122219436
Validation loss: 2.311753177637715

Epoch: 6| Step: 1
Training loss: 0.13946235369751311
Validation loss: 2.300956906701753

Epoch: 6| Step: 2
Training loss: 0.42244813981691315
Validation loss: 2.294189156302483

Epoch: 6| Step: 3
Training loss: 0.33519660955679803
Validation loss: 2.3353584140533137

Epoch: 6| Step: 4
Training loss: 0.1830682335187207
Validation loss: 2.3282302574704214

Epoch: 6| Step: 5
Training loss: 0.22385352291856606
Validation loss: 2.3175975950544108

Epoch: 6| Step: 6
Training loss: 0.23982938108364432
Validation loss: 2.3324731806648065

Epoch: 6| Step: 7
Training loss: 0.36699661406506445
Validation loss: 2.3315689651903186

Epoch: 6| Step: 8
Training loss: 0.3407914551156202
Validation loss: 2.338955914303595

Epoch: 6| Step: 9
Training loss: 0.23128613498963024
Validation loss: 2.3073907087077896

Epoch: 6| Step: 10
Training loss: 0.16392347712575164
Validation loss: 2.340215628745192

Epoch: 6| Step: 11
Training loss: 0.14516341652646125
Validation loss: 2.3171060448535123

Epoch: 6| Step: 12
Training loss: 0.19790848706726535
Validation loss: 2.329869621384021

Epoch: 6| Step: 13
Training loss: 0.269503315569913
Validation loss: 2.2930707776575825

Epoch: 396| Step: 0
Training loss: 0.2201389765680769
Validation loss: 2.3058440529378648

Epoch: 6| Step: 1
Training loss: 0.27897317174306785
Validation loss: 2.3292776996602313

Epoch: 6| Step: 2
Training loss: 0.467588447832903
Validation loss: 2.325004262762609

Epoch: 6| Step: 3
Training loss: 0.18137393364569837
Validation loss: 2.313682342584455

Epoch: 6| Step: 4
Training loss: 0.28640074440034236
Validation loss: 2.3194593364571627

Epoch: 6| Step: 5
Training loss: 0.2981553076687307
Validation loss: 2.373116573267455

Epoch: 6| Step: 6
Training loss: 0.30110054903217887
Validation loss: 2.3661661694569363

Epoch: 6| Step: 7
Training loss: 0.19909898112245678
Validation loss: 2.354035357414949

Epoch: 6| Step: 8
Training loss: 0.2528087960385661
Validation loss: 2.3625418870316883

Epoch: 6| Step: 9
Training loss: 0.23997929840162652
Validation loss: 2.3826743400727173

Epoch: 6| Step: 10
Training loss: 0.140113808756265
Validation loss: 2.3377145643400414

Epoch: 6| Step: 11
Training loss: 0.4036281233153085
Validation loss: 2.3891346818443515

Epoch: 6| Step: 12
Training loss: 0.31102625715858523
Validation loss: 2.3348323479379722

Epoch: 6| Step: 13
Training loss: 0.1864240191672624
Validation loss: 2.334360279222929

Epoch: 397| Step: 0
Training loss: 0.3464127278356753
Validation loss: 2.3640067703272343

Epoch: 6| Step: 1
Training loss: 0.2752011641671472
Validation loss: 2.34662599275015

Epoch: 6| Step: 2
Training loss: 0.28429460332245404
Validation loss: 2.3489511523091413

Epoch: 6| Step: 3
Training loss: 0.22233479702282807
Validation loss: 2.3228626878616625

Epoch: 6| Step: 4
Training loss: 0.347623459201815
Validation loss: 2.327776846297836

Epoch: 6| Step: 5
Training loss: 0.30403402138277263
Validation loss: 2.3696834694116498

Epoch: 6| Step: 6
Training loss: 0.22523190018335904
Validation loss: 2.3539049498749463

Epoch: 6| Step: 7
Training loss: 0.2195410050909307
Validation loss: 2.343693385380429

Epoch: 6| Step: 8
Training loss: 0.39123091434813123
Validation loss: 2.367555569973962

Epoch: 6| Step: 9
Training loss: 0.17433765826785297
Validation loss: 2.3513242125029326

Epoch: 6| Step: 10
Training loss: 0.30173093558802627
Validation loss: 2.337994347539274

Epoch: 6| Step: 11
Training loss: 0.15330610999154193
Validation loss: 2.3304726952730435

Epoch: 6| Step: 12
Training loss: 0.25137047339413215
Validation loss: 2.3757798145739275

Epoch: 6| Step: 13
Training loss: 0.3797443598491016
Validation loss: 2.344250583582867

Epoch: 398| Step: 0
Training loss: 0.10498273536541784
Validation loss: 2.347112368813334

Epoch: 6| Step: 1
Training loss: 0.15912431795359133
Validation loss: 2.337492403319985

Epoch: 6| Step: 2
Training loss: 0.3747279849542879
Validation loss: 2.3456271731351763

Epoch: 6| Step: 3
Training loss: 0.2492483432383749
Validation loss: 2.343775538917231

Epoch: 6| Step: 4
Training loss: 0.26302008424154943
Validation loss: 2.321556867200308

Epoch: 6| Step: 5
Training loss: 0.3791704141864798
Validation loss: 2.3288233661324167

Epoch: 6| Step: 6
Training loss: 0.3298759066738029
Validation loss: 2.2935037232190565

Epoch: 6| Step: 7
Training loss: 0.3027630084863236
Validation loss: 2.293743947743615

Epoch: 6| Step: 8
Training loss: 0.26386776464527634
Validation loss: 2.336899877444427

Epoch: 6| Step: 9
Training loss: 0.25788881155056526
Validation loss: 2.3216287953428427

Epoch: 6| Step: 10
Training loss: 0.10812410660881784
Validation loss: 2.3430183586726367

Epoch: 6| Step: 11
Training loss: 0.21771018645001336
Validation loss: 2.3557138247645564

Epoch: 6| Step: 12
Training loss: 0.3564893303434156
Validation loss: 2.32724917985982

Epoch: 6| Step: 13
Training loss: 0.1490951950276665
Validation loss: 2.330243557523357

Epoch: 399| Step: 0
Training loss: 0.15853476202496206
Validation loss: 2.341712725796567

Epoch: 6| Step: 1
Training loss: 0.3678551954252251
Validation loss: 2.361120481148774

Epoch: 6| Step: 2
Training loss: 0.1613902087978581
Validation loss: 2.3379309139638216

Epoch: 6| Step: 3
Training loss: 0.16635676843746067
Validation loss: 2.327721067333757

Epoch: 6| Step: 4
Training loss: 0.3288802809441702
Validation loss: 2.359083740493806

Epoch: 6| Step: 5
Training loss: 0.32440883166042256
Validation loss: 2.347950577967113

Epoch: 6| Step: 6
Training loss: 0.13362835190595107
Validation loss: 2.3170459694494356

Epoch: 6| Step: 7
Training loss: 0.2911093644086918
Validation loss: 2.3638153245604

Epoch: 6| Step: 8
Training loss: 0.25233277099157014
Validation loss: 2.3487290783306776

Epoch: 6| Step: 9
Training loss: 0.20661540824033747
Validation loss: 2.3555564781725553

Epoch: 6| Step: 10
Training loss: 0.310532095695389
Validation loss: 2.348189573820832

Epoch: 6| Step: 11
Training loss: 0.3237389265655792
Validation loss: 2.373803015742118

Epoch: 6| Step: 12
Training loss: 0.26572040639623723
Validation loss: 2.3682113832516523

Epoch: 6| Step: 13
Training loss: 0.42585045138414984
Validation loss: 2.3449595140883517

Epoch: 400| Step: 0
Training loss: 0.2665084145158702
Validation loss: 2.323361187654897

Epoch: 6| Step: 1
Training loss: 0.23160021463208802
Validation loss: 2.3615909007705427

Epoch: 6| Step: 2
Training loss: 0.1820960539368787
Validation loss: 2.2968965347594223

Epoch: 6| Step: 3
Training loss: 0.371730098222425
Validation loss: 2.3275147115987633

Epoch: 6| Step: 4
Training loss: 0.1582137092534776
Validation loss: 2.328101586995425

Epoch: 6| Step: 5
Training loss: 0.25359190041742496
Validation loss: 2.3284969964496685

Epoch: 6| Step: 6
Training loss: 0.42530502144589105
Validation loss: 2.328355173131309

Epoch: 6| Step: 7
Training loss: 0.2658369677144725
Validation loss: 2.3386665919475496

Epoch: 6| Step: 8
Training loss: 0.1426531320045224
Validation loss: 2.3134212194400696

Epoch: 6| Step: 9
Training loss: 0.27971223476724816
Validation loss: 2.346365165177065

Epoch: 6| Step: 10
Training loss: 0.29755813653683566
Validation loss: 2.339135676904217

Epoch: 6| Step: 11
Training loss: 0.31208778850972796
Validation loss: 2.351483477626539

Epoch: 6| Step: 12
Training loss: 0.3324829058985565
Validation loss: 2.3464845604704943

Epoch: 6| Step: 13
Training loss: 0.24555826207458303
Validation loss: 2.3257912925907296

Testing loss: 2.4521637779399796
