Epoch: 1| Step: 0
Training loss: 5.185563087463379
Validation loss: 5.171335440810009

Epoch: 6| Step: 1
Training loss: 5.592732906341553
Validation loss: 5.155379362003778

Epoch: 6| Step: 2
Training loss: 5.296933174133301
Validation loss: 5.13856807831795

Epoch: 6| Step: 3
Training loss: 5.26094913482666
Validation loss: 5.119811042662589

Epoch: 6| Step: 4
Training loss: 4.81374454498291
Validation loss: 5.099257756304997

Epoch: 6| Step: 5
Training loss: 4.165220260620117
Validation loss: 5.075949935502903

Epoch: 6| Step: 6
Training loss: 5.4687700271606445
Validation loss: 5.049866630185035

Epoch: 6| Step: 7
Training loss: 3.314939260482788
Validation loss: 5.020048305552493

Epoch: 6| Step: 8
Training loss: 3.342088222503662
Validation loss: 4.986809915111911

Epoch: 6| Step: 9
Training loss: 4.867541313171387
Validation loss: 4.950264556433565

Epoch: 6| Step: 10
Training loss: 3.939098596572876
Validation loss: 4.910467501609556

Epoch: 6| Step: 11
Training loss: 5.085554599761963
Validation loss: 4.866942226245839

Epoch: 6| Step: 12
Training loss: 6.513815402984619
Validation loss: 4.8213772568651425

Epoch: 6| Step: 13
Training loss: 4.1649250984191895
Validation loss: 4.771591924851941

Epoch: 2| Step: 0
Training loss: 5.2126922607421875
Validation loss: 4.721658101645849

Epoch: 6| Step: 1
Training loss: 4.329056739807129
Validation loss: 4.670992153947071

Epoch: 6| Step: 2
Training loss: 4.004587173461914
Validation loss: 4.619655137420983

Epoch: 6| Step: 3
Training loss: 3.222015619277954
Validation loss: 4.568972074857322

Epoch: 6| Step: 4
Training loss: 4.250049114227295
Validation loss: 4.520376046498616

Epoch: 6| Step: 5
Training loss: 3.8725545406341553
Validation loss: 4.469249904796642

Epoch: 6| Step: 6
Training loss: 3.9879941940307617
Validation loss: 4.415525774801931

Epoch: 6| Step: 7
Training loss: 4.686553955078125
Validation loss: 4.363164696642148

Epoch: 6| Step: 8
Training loss: 5.220599174499512
Validation loss: 4.309537082590083

Epoch: 6| Step: 9
Training loss: 3.5385735034942627
Validation loss: 4.257263106684531

Epoch: 6| Step: 10
Training loss: 4.351510047912598
Validation loss: 4.206176280975342

Epoch: 6| Step: 11
Training loss: 4.5806965827941895
Validation loss: 4.155764764355075

Epoch: 6| Step: 12
Training loss: 3.308183193206787
Validation loss: 4.107114604724351

Epoch: 6| Step: 13
Training loss: 4.491884231567383
Validation loss: 4.054438165439072

Epoch: 3| Step: 0
Training loss: 2.8025550842285156
Validation loss: 3.997849484925629

Epoch: 6| Step: 1
Training loss: 3.9477035999298096
Validation loss: 3.952450736876457

Epoch: 6| Step: 2
Training loss: 4.520816802978516
Validation loss: 3.920771086087791

Epoch: 6| Step: 3
Training loss: 4.756528854370117
Validation loss: 3.8919089096848682

Epoch: 6| Step: 4
Training loss: 4.48352575302124
Validation loss: 3.866842767243744

Epoch: 6| Step: 5
Training loss: 2.664734363555908
Validation loss: 3.840075167276526

Epoch: 6| Step: 6
Training loss: 2.7303719520568848
Validation loss: 3.814742329300091

Epoch: 6| Step: 7
Training loss: 4.178534984588623
Validation loss: 3.7858038179336058

Epoch: 6| Step: 8
Training loss: 2.692714214324951
Validation loss: 3.7593170340343187

Epoch: 6| Step: 9
Training loss: 3.9166951179504395
Validation loss: 3.7322021761248187

Epoch: 6| Step: 10
Training loss: 4.5311665534973145
Validation loss: 3.7085450849225445

Epoch: 6| Step: 11
Training loss: 3.4381017684936523
Validation loss: 3.6895011676255094

Epoch: 6| Step: 12
Training loss: 3.45009446144104
Validation loss: 3.66574610945999

Epoch: 6| Step: 13
Training loss: 3.5830912590026855
Validation loss: 3.6455808634399087

Epoch: 4| Step: 0
Training loss: 4.56225061416626
Validation loss: 3.6238939018659693

Epoch: 6| Step: 1
Training loss: 3.203672170639038
Validation loss: 3.600561547022994

Epoch: 6| Step: 2
Training loss: 3.9520962238311768
Validation loss: 3.57778730956457

Epoch: 6| Step: 3
Training loss: 3.555983543395996
Validation loss: 3.562826902635636

Epoch: 6| Step: 4
Training loss: 4.768637180328369
Validation loss: 3.545553171506492

Epoch: 6| Step: 5
Training loss: 3.8254806995391846
Validation loss: 3.5575899462546072

Epoch: 6| Step: 6
Training loss: 2.9142496585845947
Validation loss: 3.521868177639541

Epoch: 6| Step: 7
Training loss: 3.778317451477051
Validation loss: 3.542759521033174

Epoch: 6| Step: 8
Training loss: 3.186849594116211
Validation loss: 3.5029374963493756

Epoch: 6| Step: 9
Training loss: 2.925713062286377
Validation loss: 3.482326799823392

Epoch: 6| Step: 10
Training loss: 3.0938591957092285
Validation loss: 3.466568834038191

Epoch: 6| Step: 11
Training loss: 2.5404741764068604
Validation loss: 3.4600798827345653

Epoch: 6| Step: 12
Training loss: 2.471020221710205
Validation loss: 3.463635339531847

Epoch: 6| Step: 13
Training loss: 3.9863972663879395
Validation loss: 3.437491375912902

Epoch: 5| Step: 0
Training loss: 3.543869733810425
Validation loss: 3.4324448621401222

Epoch: 6| Step: 1
Training loss: 2.81937313079834
Validation loss: 3.426054903255996

Epoch: 6| Step: 2
Training loss: 2.3074538707733154
Validation loss: 3.4195439328429518

Epoch: 6| Step: 3
Training loss: 3.2910213470458984
Validation loss: 3.416414460828227

Epoch: 6| Step: 4
Training loss: 4.391717433929443
Validation loss: 3.4081531340076077

Epoch: 6| Step: 5
Training loss: 3.759289264678955
Validation loss: 3.3963305898891982

Epoch: 6| Step: 6
Training loss: 3.556558609008789
Validation loss: 3.383589385658182

Epoch: 6| Step: 7
Training loss: 2.8156418800354004
Validation loss: 3.3677715434822986

Epoch: 6| Step: 8
Training loss: 3.6498775482177734
Validation loss: 3.3576335599345546

Epoch: 6| Step: 9
Training loss: 3.830118417739868
Validation loss: 3.346661324142128

Epoch: 6| Step: 10
Training loss: 3.6880979537963867
Validation loss: 3.3410784531665105

Epoch: 6| Step: 11
Training loss: 2.912142753601074
Validation loss: 3.3303912455035793

Epoch: 6| Step: 12
Training loss: 3.132941722869873
Validation loss: 3.320552813109531

Epoch: 6| Step: 13
Training loss: 2.607926368713379
Validation loss: 3.307163489762173

Epoch: 6| Step: 0
Training loss: 3.4256367683410645
Validation loss: 3.2988444400090042

Epoch: 6| Step: 1
Training loss: 2.757676362991333
Validation loss: 3.2949693305518037

Epoch: 6| Step: 2
Training loss: 3.0758466720581055
Validation loss: 3.289413485475766

Epoch: 6| Step: 3
Training loss: 3.8270905017852783
Validation loss: 3.2810618467228387

Epoch: 6| Step: 4
Training loss: 2.954957962036133
Validation loss: 3.2689122846049647

Epoch: 6| Step: 5
Training loss: 2.977814197540283
Validation loss: 3.2572038917131323

Epoch: 6| Step: 6
Training loss: 3.2822797298431396
Validation loss: 3.2452470102617816

Epoch: 6| Step: 7
Training loss: 3.590562105178833
Validation loss: 3.2360198882318314

Epoch: 6| Step: 8
Training loss: 3.004173994064331
Validation loss: 3.2325246692985616

Epoch: 6| Step: 9
Training loss: 3.848407745361328
Validation loss: 3.2266166107628935

Epoch: 6| Step: 10
Training loss: 2.7489871978759766
Validation loss: 3.2181799309228056

Epoch: 6| Step: 11
Training loss: 2.8683433532714844
Validation loss: 3.2076592419737127

Epoch: 6| Step: 12
Training loss: 3.8837270736694336
Validation loss: 3.2001691454200336

Epoch: 6| Step: 13
Training loss: 2.7521510124206543
Validation loss: 3.1902457975572154

Epoch: 7| Step: 0
Training loss: 4.112318992614746
Validation loss: 3.1852532356016097

Epoch: 6| Step: 1
Training loss: 4.1403279304504395
Validation loss: 3.1759475072224936

Epoch: 6| Step: 2
Training loss: 2.2717463970184326
Validation loss: 3.166678633741153

Epoch: 6| Step: 3
Training loss: 2.8477165699005127
Validation loss: 3.1599235688486407

Epoch: 6| Step: 4
Training loss: 3.3070878982543945
Validation loss: 3.1545258773270475

Epoch: 6| Step: 5
Training loss: 3.437870979309082
Validation loss: 3.1446870270595757

Epoch: 6| Step: 6
Training loss: 3.3171474933624268
Validation loss: 3.136042179599885

Epoch: 6| Step: 7
Training loss: 2.911438226699829
Validation loss: 3.1298022654748734

Epoch: 6| Step: 8
Training loss: 2.4158689975738525
Validation loss: 3.138167235159105

Epoch: 6| Step: 9
Training loss: 2.9568405151367188
Validation loss: 3.116796221784366

Epoch: 6| Step: 10
Training loss: 3.3499646186828613
Validation loss: 3.120415877270442

Epoch: 6| Step: 11
Training loss: 3.4801034927368164
Validation loss: 3.1205124470495407

Epoch: 6| Step: 12
Training loss: 2.587953805923462
Validation loss: 3.1170829470439623

Epoch: 6| Step: 13
Training loss: 3.046208381652832
Validation loss: 3.1079765673606627

Epoch: 8| Step: 0
Training loss: 2.1584954261779785
Validation loss: 3.0962147840889553

Epoch: 6| Step: 1
Training loss: 2.7836949825286865
Validation loss: 3.0876688111212944

Epoch: 6| Step: 2
Training loss: 3.6552863121032715
Validation loss: 3.077993749290384

Epoch: 6| Step: 3
Training loss: 3.006023406982422
Validation loss: 3.0757409911001883

Epoch: 6| Step: 4
Training loss: 3.1438770294189453
Validation loss: 3.088121691057759

Epoch: 6| Step: 5
Training loss: 2.9921302795410156
Validation loss: 3.0602289092156196

Epoch: 6| Step: 6
Training loss: 2.925705671310425
Validation loss: 3.0585894123200448

Epoch: 6| Step: 7
Training loss: 2.335127353668213
Validation loss: 3.05914056429299

Epoch: 6| Step: 8
Training loss: 2.8709917068481445
Validation loss: 3.0632717993951615

Epoch: 6| Step: 9
Training loss: 4.076493740081787
Validation loss: 3.0571872085653324

Epoch: 6| Step: 10
Training loss: 2.9813835620880127
Validation loss: 3.045689941734396

Epoch: 6| Step: 11
Training loss: 2.8647234439849854
Validation loss: 3.033647714122649

Epoch: 6| Step: 12
Training loss: 4.608091354370117
Validation loss: 3.0290873614690637

Epoch: 6| Step: 13
Training loss: 3.116328716278076
Validation loss: 3.020925365468507

Epoch: 9| Step: 0
Training loss: 3.4114389419555664
Validation loss: 3.015166095508042

Epoch: 6| Step: 1
Training loss: 3.3473219871520996
Validation loss: 3.0091759850901942

Epoch: 6| Step: 2
Training loss: 2.7226901054382324
Validation loss: 3.003024898549562

Epoch: 6| Step: 3
Training loss: 2.7545316219329834
Validation loss: 3.014294857619911

Epoch: 6| Step: 4
Training loss: 3.3856329917907715
Validation loss: 3.0427976705694713

Epoch: 6| Step: 5
Training loss: 3.0585219860076904
Validation loss: 3.0057145831405476

Epoch: 6| Step: 6
Training loss: 2.4562318325042725
Validation loss: 2.990392815682196

Epoch: 6| Step: 7
Training loss: 3.5891096591949463
Validation loss: 3.0045648338974162

Epoch: 6| Step: 8
Training loss: 3.607544422149658
Validation loss: 3.015131506868588

Epoch: 6| Step: 9
Training loss: 2.706704616546631
Validation loss: 3.019088047806935

Epoch: 6| Step: 10
Training loss: 3.5892930030822754
Validation loss: 3.012079026109429

Epoch: 6| Step: 11
Training loss: 3.4758365154266357
Validation loss: 2.995894580759028

Epoch: 6| Step: 12
Training loss: 2.363243579864502
Validation loss: 2.9813337044049333

Epoch: 6| Step: 13
Training loss: 2.1537351608276367
Validation loss: 2.982249306094262

Epoch: 10| Step: 0
Training loss: 2.7428479194641113
Validation loss: 3.0004959772991877

Epoch: 6| Step: 1
Training loss: 3.7366647720336914
Validation loss: 2.967239528573969

Epoch: 6| Step: 2
Training loss: 2.2071638107299805
Validation loss: 2.9512803323807253

Epoch: 6| Step: 3
Training loss: 1.7449575662612915
Validation loss: 2.9454436609821935

Epoch: 6| Step: 4
Training loss: 3.5856895446777344
Validation loss: 2.9475824345824537

Epoch: 6| Step: 5
Training loss: 3.7385828495025635
Validation loss: 2.9490897783669094

Epoch: 6| Step: 6
Training loss: 2.849437952041626
Validation loss: 2.945570138192946

Epoch: 6| Step: 7
Training loss: 2.5441606044769287
Validation loss: 2.9436444620932303

Epoch: 6| Step: 8
Training loss: 4.140590190887451
Validation loss: 2.944554434027723

Epoch: 6| Step: 9
Training loss: 3.314311981201172
Validation loss: 2.930828120118828

Epoch: 6| Step: 10
Training loss: 2.762479543685913
Validation loss: 2.9293582362513386

Epoch: 6| Step: 11
Training loss: 3.0853514671325684
Validation loss: 2.9279938513232815

Epoch: 6| Step: 12
Training loss: 2.977633476257324
Validation loss: 2.923643424946775

Epoch: 6| Step: 13
Training loss: 2.9958276748657227
Validation loss: 2.922771833276236

Epoch: 11| Step: 0
Training loss: 3.2026684284210205
Validation loss: 2.9208628874953075

Epoch: 6| Step: 1
Training loss: 2.5291619300842285
Validation loss: 2.9152037764108307

Epoch: 6| Step: 2
Training loss: 3.5251221656799316
Validation loss: 2.9134443729154524

Epoch: 6| Step: 3
Training loss: 3.7920663356781006
Validation loss: 2.907370441703386

Epoch: 6| Step: 4
Training loss: 3.478318214416504
Validation loss: 2.903905427584084

Epoch: 6| Step: 5
Training loss: 1.9785311222076416
Validation loss: 2.8975359086067445

Epoch: 6| Step: 6
Training loss: 2.9483542442321777
Validation loss: 2.8933132809977375

Epoch: 6| Step: 7
Training loss: 2.3621814250946045
Validation loss: 2.888955282908614

Epoch: 6| Step: 8
Training loss: 2.4438042640686035
Validation loss: 2.8871596295346498

Epoch: 6| Step: 9
Training loss: 3.2584035396575928
Validation loss: 2.8834992377988753

Epoch: 6| Step: 10
Training loss: 3.464946746826172
Validation loss: 2.8814503249301704

Epoch: 6| Step: 11
Training loss: 2.368340015411377
Validation loss: 2.8799679253690984

Epoch: 6| Step: 12
Training loss: 3.5660574436187744
Validation loss: 2.8771528569600915

Epoch: 6| Step: 13
Training loss: 3.0842251777648926
Validation loss: 2.8741997365028626

Epoch: 12| Step: 0
Training loss: 2.8467512130737305
Validation loss: 2.8693119018308577

Epoch: 6| Step: 1
Training loss: 3.136042594909668
Validation loss: 2.865357393859535

Epoch: 6| Step: 2
Training loss: 2.109776496887207
Validation loss: 2.8626148367440827

Epoch: 6| Step: 3
Training loss: 3.7681937217712402
Validation loss: 2.8582844734191895

Epoch: 6| Step: 4
Training loss: 3.176842212677002
Validation loss: 2.8563108982578402

Epoch: 6| Step: 5
Training loss: 3.167202949523926
Validation loss: 2.851968788331555

Epoch: 6| Step: 6
Training loss: 3.152864933013916
Validation loss: 2.847343842188517

Epoch: 6| Step: 7
Training loss: 1.9409716129302979
Validation loss: 2.8446223658900105

Epoch: 6| Step: 8
Training loss: 2.9821417331695557
Validation loss: 2.8428540229797363

Epoch: 6| Step: 9
Training loss: 3.7654640674591064
Validation loss: 2.8399594112109114

Epoch: 6| Step: 10
Training loss: 3.3353569507598877
Validation loss: 2.8367812351513932

Epoch: 6| Step: 11
Training loss: 2.5079755783081055
Validation loss: 2.834266770270563

Epoch: 6| Step: 12
Training loss: 2.8921608924865723
Validation loss: 2.830893596013387

Epoch: 6| Step: 13
Training loss: 2.5415754318237305
Validation loss: 2.8296047026111233

Epoch: 13| Step: 0
Training loss: 2.9509215354919434
Validation loss: 2.827949221416186

Epoch: 6| Step: 1
Training loss: 3.260388135910034
Validation loss: 2.824938207544306

Epoch: 6| Step: 2
Training loss: 2.1836302280426025
Validation loss: 2.820066880154353

Epoch: 6| Step: 3
Training loss: 2.938657283782959
Validation loss: 2.818016331682923

Epoch: 6| Step: 4
Training loss: 2.991990566253662
Validation loss: 2.8138030523894937

Epoch: 6| Step: 5
Training loss: 2.8164873123168945
Validation loss: 2.8122805049342494

Epoch: 6| Step: 6
Training loss: 2.5932085514068604
Validation loss: 2.8100521615756455

Epoch: 6| Step: 7
Training loss: 2.454937219619751
Validation loss: 2.808011770248413

Epoch: 6| Step: 8
Training loss: 2.943694591522217
Validation loss: 2.8067061208909556

Epoch: 6| Step: 9
Training loss: 3.0114526748657227
Validation loss: 2.8047440539124193

Epoch: 6| Step: 10
Training loss: 4.089410781860352
Validation loss: 2.8022164375551286

Epoch: 6| Step: 11
Training loss: 2.9619998931884766
Validation loss: 2.8015549772529194

Epoch: 6| Step: 12
Training loss: 3.56766414642334
Validation loss: 2.7991904776583434

Epoch: 6| Step: 13
Training loss: 2.009478807449341
Validation loss: 2.7965728108600905

Epoch: 14| Step: 0
Training loss: 2.959458589553833
Validation loss: 2.7954125737631195

Epoch: 6| Step: 1
Training loss: 3.6685519218444824
Validation loss: 2.7921592804693405

Epoch: 6| Step: 2
Training loss: 2.531503200531006
Validation loss: 2.791306452084613

Epoch: 6| Step: 3
Training loss: 3.4086122512817383
Validation loss: 2.7876712327362387

Epoch: 6| Step: 4
Training loss: 3.0704500675201416
Validation loss: 2.7882247919677408

Epoch: 6| Step: 5
Training loss: 2.299229145050049
Validation loss: 2.7869624937734296

Epoch: 6| Step: 6
Training loss: 2.7180612087249756
Validation loss: 2.7863068452445408

Epoch: 6| Step: 7
Training loss: 2.681520938873291
Validation loss: 2.785146379983553

Epoch: 6| Step: 8
Training loss: 2.8132476806640625
Validation loss: 2.785429334127775

Epoch: 6| Step: 9
Training loss: 1.9914010763168335
Validation loss: 2.7790251957472933

Epoch: 6| Step: 10
Training loss: 3.469174385070801
Validation loss: 2.777918992503997

Epoch: 6| Step: 11
Training loss: 2.7334165573120117
Validation loss: 2.779480016359719

Epoch: 6| Step: 12
Training loss: 3.2388641834259033
Validation loss: 2.7804073364503923

Epoch: 6| Step: 13
Training loss: 3.696819305419922
Validation loss: 2.7799569035089142

Epoch: 15| Step: 0
Training loss: 3.658644199371338
Validation loss: 2.7822113857474378

Epoch: 6| Step: 1
Training loss: 2.7352235317230225
Validation loss: 2.779835536915769

Epoch: 6| Step: 2
Training loss: 2.9601311683654785
Validation loss: 2.774311201546782

Epoch: 6| Step: 3
Training loss: 3.146974563598633
Validation loss: 2.77061064012589

Epoch: 6| Step: 4
Training loss: 1.992376446723938
Validation loss: 2.767815430959066

Epoch: 6| Step: 5
Training loss: 2.520603895187378
Validation loss: 2.7693183986089562

Epoch: 6| Step: 6
Training loss: 2.201106548309326
Validation loss: 2.7651633421579995

Epoch: 6| Step: 7
Training loss: 2.988356590270996
Validation loss: 2.7639689394222793

Epoch: 6| Step: 8
Training loss: 2.5268173217773438
Validation loss: 2.7644312791926886

Epoch: 6| Step: 9
Training loss: 3.962989330291748
Validation loss: 2.766151892241611

Epoch: 6| Step: 10
Training loss: 2.9511682987213135
Validation loss: 2.765291654935447

Epoch: 6| Step: 11
Training loss: 3.0923004150390625
Validation loss: 2.763142872882146

Epoch: 6| Step: 12
Training loss: 2.56082820892334
Validation loss: 2.7600194818230084

Epoch: 6| Step: 13
Training loss: 3.968600034713745
Validation loss: 2.7571551466500885

Epoch: 16| Step: 0
Training loss: 3.8848226070404053
Validation loss: 2.756395157947335

Epoch: 6| Step: 1
Training loss: 2.4794349670410156
Validation loss: 2.7535811060218403

Epoch: 6| Step: 2
Training loss: 2.7917728424072266
Validation loss: 2.7523363277476323

Epoch: 6| Step: 3
Training loss: 2.3603851795196533
Validation loss: 2.7516463059251026

Epoch: 6| Step: 4
Training loss: 3.319221019744873
Validation loss: 2.750939387147145

Epoch: 6| Step: 5
Training loss: 3.0159926414489746
Validation loss: 2.7535974697400163

Epoch: 6| Step: 6
Training loss: 3.1079368591308594
Validation loss: 2.7458344710770475

Epoch: 6| Step: 7
Training loss: 2.6298303604125977
Validation loss: 2.742583323550481

Epoch: 6| Step: 8
Training loss: 2.9498941898345947
Validation loss: 2.7477693468011837

Epoch: 6| Step: 9
Training loss: 2.9392271041870117
Validation loss: 2.751075626701437

Epoch: 6| Step: 10
Training loss: 2.761791944503784
Validation loss: 2.7613832489136727

Epoch: 6| Step: 11
Training loss: 1.9343624114990234
Validation loss: 2.7639292978471324

Epoch: 6| Step: 12
Training loss: 2.7273430824279785
Validation loss: 2.765336451991912

Epoch: 6| Step: 13
Training loss: 4.403800010681152
Validation loss: 2.7628469236435427

Epoch: 17| Step: 0
Training loss: 3.1593284606933594
Validation loss: 2.740193379822598

Epoch: 6| Step: 1
Training loss: 2.840940475463867
Validation loss: 2.7318601787731214

Epoch: 6| Step: 2
Training loss: 2.8737447261810303
Validation loss: 2.731794636736634

Epoch: 6| Step: 3
Training loss: 2.421790599822998
Validation loss: 2.734185746921006

Epoch: 6| Step: 4
Training loss: 3.5380306243896484
Validation loss: 2.741999444141183

Epoch: 6| Step: 5
Training loss: 2.8108720779418945
Validation loss: 2.745593455529982

Epoch: 6| Step: 6
Training loss: 3.309530735015869
Validation loss: 2.7321199934969664

Epoch: 6| Step: 7
Training loss: 2.3350586891174316
Validation loss: 2.726569132138324

Epoch: 6| Step: 8
Training loss: 3.135044574737549
Validation loss: 2.7232700394045923

Epoch: 6| Step: 9
Training loss: 2.3304378986358643
Validation loss: 2.724518427284815

Epoch: 6| Step: 10
Training loss: 2.709336519241333
Validation loss: 2.725835787352695

Epoch: 6| Step: 11
Training loss: 2.1210455894470215
Validation loss: 2.7247608143796205

Epoch: 6| Step: 12
Training loss: 2.861787796020508
Validation loss: 2.7222703426114974

Epoch: 6| Step: 13
Training loss: 4.866064548492432
Validation loss: 2.7229040104855775

Epoch: 18| Step: 0
Training loss: 2.700011730194092
Validation loss: 2.7234415956722793

Epoch: 6| Step: 1
Training loss: 2.6225194931030273
Validation loss: 2.7232447234533166

Epoch: 6| Step: 2
Training loss: 2.183236598968506
Validation loss: 2.7248846894951275

Epoch: 6| Step: 3
Training loss: 2.992739200592041
Validation loss: 2.7234531448733423

Epoch: 6| Step: 4
Training loss: 2.6596083641052246
Validation loss: 2.7197381424647507

Epoch: 6| Step: 5
Training loss: 3.4794535636901855
Validation loss: 2.7138006071890555

Epoch: 6| Step: 6
Training loss: 3.317692756652832
Validation loss: 2.7118571676233763

Epoch: 6| Step: 7
Training loss: 2.6113200187683105
Validation loss: 2.711624099362281

Epoch: 6| Step: 8
Training loss: 2.644345283508301
Validation loss: 2.7130152640804166

Epoch: 6| Step: 9
Training loss: 3.6287543773651123
Validation loss: 2.709391842606247

Epoch: 6| Step: 10
Training loss: 3.7131009101867676
Validation loss: 2.70729160821566

Epoch: 6| Step: 11
Training loss: 1.8335521221160889
Validation loss: 2.701919037808654

Epoch: 6| Step: 12
Training loss: 2.966672897338867
Validation loss: 2.6994706994743756

Epoch: 6| Step: 13
Training loss: 2.9767515659332275
Validation loss: 2.697518979349444

Epoch: 19| Step: 0
Training loss: 3.076582431793213
Validation loss: 2.6972519684863347

Epoch: 6| Step: 1
Training loss: 1.9858781099319458
Validation loss: 2.6949628860719743

Epoch: 6| Step: 2
Training loss: 2.268577814102173
Validation loss: 2.6931685581002185

Epoch: 6| Step: 3
Training loss: 2.7266993522644043
Validation loss: 2.693571182989305

Epoch: 6| Step: 4
Training loss: 3.6676583290100098
Validation loss: 2.691622123923353

Epoch: 6| Step: 5
Training loss: 2.483694076538086
Validation loss: 2.6919545563318397

Epoch: 6| Step: 6
Training loss: 3.71345853805542
Validation loss: 2.69003959624998

Epoch: 6| Step: 7
Training loss: 2.569849967956543
Validation loss: 2.6881179655751875

Epoch: 6| Step: 8
Training loss: 2.437912940979004
Validation loss: 2.6833890279134116

Epoch: 6| Step: 9
Training loss: 3.75309419631958
Validation loss: 2.6870989568771853

Epoch: 6| Step: 10
Training loss: 2.7041258811950684
Validation loss: 2.683235160766109

Epoch: 6| Step: 11
Training loss: 2.821305751800537
Validation loss: 2.6810683076099684

Epoch: 6| Step: 12
Training loss: 2.669477939605713
Validation loss: 2.6801007947614117

Epoch: 6| Step: 13
Training loss: 3.415053606033325
Validation loss: 2.6803124284231536

Epoch: 20| Step: 0
Training loss: 3.7349424362182617
Validation loss: 2.6779600445942213

Epoch: 6| Step: 1
Training loss: 2.438382148742676
Validation loss: 2.678816205711775

Epoch: 6| Step: 2
Training loss: 3.415940523147583
Validation loss: 2.675811570177796

Epoch: 6| Step: 3
Training loss: 1.9825854301452637
Validation loss: 2.6716772869069088

Epoch: 6| Step: 4
Training loss: 2.6723697185516357
Validation loss: 2.66889125557356

Epoch: 6| Step: 5
Training loss: 2.807732105255127
Validation loss: 2.667435674257176

Epoch: 6| Step: 6
Training loss: 4.030084609985352
Validation loss: 2.6681739361055437

Epoch: 6| Step: 7
Training loss: 2.8037590980529785
Validation loss: 2.6664077569079656

Epoch: 6| Step: 8
Training loss: 3.1225712299346924
Validation loss: 2.670498929997926

Epoch: 6| Step: 9
Training loss: 2.9217276573181152
Validation loss: 2.665208198690927

Epoch: 6| Step: 10
Training loss: 3.1471481323242188
Validation loss: 2.66555191111821

Epoch: 6| Step: 11
Training loss: 2.7047901153564453
Validation loss: 2.6603653712939193

Epoch: 6| Step: 12
Training loss: 1.7647080421447754
Validation loss: 2.6560871678013958

Epoch: 6| Step: 13
Training loss: 1.8793996572494507
Validation loss: 2.652932164489582

Epoch: 21| Step: 0
Training loss: 2.744281768798828
Validation loss: 2.6621927779207946

Epoch: 6| Step: 1
Training loss: 2.869318962097168
Validation loss: 2.6719117164611816

Epoch: 6| Step: 2
Training loss: 2.3142480850219727
Validation loss: 2.678235625707975

Epoch: 6| Step: 3
Training loss: 2.6854095458984375
Validation loss: 2.6822854780381724

Epoch: 6| Step: 4
Training loss: 2.626699924468994
Validation loss: 2.7018416748251965

Epoch: 6| Step: 5
Training loss: 3.5823638439178467
Validation loss: 2.697350355886644

Epoch: 6| Step: 6
Training loss: 2.758704662322998
Validation loss: 2.6607872363059752

Epoch: 6| Step: 7
Training loss: 2.737544298171997
Validation loss: 2.642961340565835

Epoch: 6| Step: 8
Training loss: 2.9699480533599854
Validation loss: 2.635841610611126

Epoch: 6| Step: 9
Training loss: 3.522977113723755
Validation loss: 2.6446212235317437

Epoch: 6| Step: 10
Training loss: 2.1661429405212402
Validation loss: 2.6524762722753708

Epoch: 6| Step: 11
Training loss: 2.1357059478759766
Validation loss: 2.66406988328503

Epoch: 6| Step: 12
Training loss: 3.6966638565063477
Validation loss: 2.6482447296060543

Epoch: 6| Step: 13
Training loss: 2.7603394985198975
Validation loss: 2.6398175660000054

Epoch: 22| Step: 0
Training loss: 3.2172389030456543
Validation loss: 2.6416705910877516

Epoch: 6| Step: 1
Training loss: 2.39866042137146
Validation loss: 2.643945565787695

Epoch: 6| Step: 2
Training loss: 3.0309927463531494
Validation loss: 2.6319754738961496

Epoch: 6| Step: 3
Training loss: 3.04219388961792
Validation loss: 2.627371664970152

Epoch: 6| Step: 4
Training loss: 2.2590746879577637
Validation loss: 2.62837569175228

Epoch: 6| Step: 5
Training loss: 2.7041454315185547
Validation loss: 2.6280787555120324

Epoch: 6| Step: 6
Training loss: 3.1563003063201904
Validation loss: 2.6209902019910913

Epoch: 6| Step: 7
Training loss: 3.07342529296875
Validation loss: 2.626506100418747

Epoch: 6| Step: 8
Training loss: 2.8541982173919678
Validation loss: 2.634863358671947

Epoch: 6| Step: 9
Training loss: 3.7673048973083496
Validation loss: 2.6460942555499334

Epoch: 6| Step: 10
Training loss: 2.179048538208008
Validation loss: 2.6335087796693206

Epoch: 6| Step: 11
Training loss: 2.0501956939697266
Validation loss: 2.6251426871104906

Epoch: 6| Step: 12
Training loss: 2.1165390014648438
Validation loss: 2.623941006199006

Epoch: 6| Step: 13
Training loss: 4.066366195678711
Validation loss: 2.6203012389521443

Epoch: 23| Step: 0
Training loss: 3.0414438247680664
Validation loss: 2.628220881185224

Epoch: 6| Step: 1
Training loss: 2.646939992904663
Validation loss: 2.6396323621913953

Epoch: 6| Step: 2
Training loss: 3.2310171127319336
Validation loss: 2.6496372274173203

Epoch: 6| Step: 3
Training loss: 3.010582685470581
Validation loss: 2.6571497763356855

Epoch: 6| Step: 4
Training loss: 3.206186294555664
Validation loss: 2.664839231839744

Epoch: 6| Step: 5
Training loss: 2.6125741004943848
Validation loss: 2.6440347497181227

Epoch: 6| Step: 6
Training loss: 2.260824203491211
Validation loss: 2.629895010302144

Epoch: 6| Step: 7
Training loss: 2.8435544967651367
Validation loss: 2.612067691741451

Epoch: 6| Step: 8
Training loss: 2.9256374835968018
Validation loss: 2.615747872219291

Epoch: 6| Step: 9
Training loss: 2.959336757659912
Validation loss: 2.6246673137910905

Epoch: 6| Step: 10
Training loss: 2.585732936859131
Validation loss: 2.621505706541

Epoch: 6| Step: 11
Training loss: 2.3846940994262695
Validation loss: 2.615600980738158

Epoch: 6| Step: 12
Training loss: 2.8477652072906494
Validation loss: 2.606564057770596

Epoch: 6| Step: 13
Training loss: 2.605147123336792
Validation loss: 2.610756153701454

Epoch: 24| Step: 0
Training loss: 2.21352481842041
Validation loss: 2.6272718496220087

Epoch: 6| Step: 1
Training loss: 3.067248821258545
Validation loss: 2.631719781506446

Epoch: 6| Step: 2
Training loss: 3.0936269760131836
Validation loss: 2.617825113317018

Epoch: 6| Step: 3
Training loss: 3.63860821723938
Validation loss: 2.594425557762064

Epoch: 6| Step: 4
Training loss: 3.2458932399749756
Validation loss: 2.5917732818152315

Epoch: 6| Step: 5
Training loss: 3.357259750366211
Validation loss: 2.597732013271701

Epoch: 6| Step: 6
Training loss: 1.9787788391113281
Validation loss: 2.6002358928803475

Epoch: 6| Step: 7
Training loss: 2.8351237773895264
Validation loss: 2.60027660605728

Epoch: 6| Step: 8
Training loss: 2.648672342300415
Validation loss: 2.6028909221772225

Epoch: 6| Step: 9
Training loss: 2.056858539581299
Validation loss: 2.6141919269356677

Epoch: 6| Step: 10
Training loss: 2.5610885620117188
Validation loss: 2.6192466110311527

Epoch: 6| Step: 11
Training loss: 2.930896282196045
Validation loss: 2.6112344880257883

Epoch: 6| Step: 12
Training loss: 2.2537975311279297
Validation loss: 2.619876161698372

Epoch: 6| Step: 13
Training loss: 3.483090877532959
Validation loss: 2.6307887082458823

Epoch: 25| Step: 0
Training loss: 3.0376522541046143
Validation loss: 2.6467699440576697

Epoch: 6| Step: 1
Training loss: 2.99934720993042
Validation loss: 2.627698095895911

Epoch: 6| Step: 2
Training loss: 2.691906213760376
Validation loss: 2.6022244012483986

Epoch: 6| Step: 3
Training loss: 2.8106629848480225
Validation loss: 2.587294663152387

Epoch: 6| Step: 4
Training loss: 3.0701918601989746
Validation loss: 2.590075287767636

Epoch: 6| Step: 5
Training loss: 2.3944101333618164
Validation loss: 2.5914378704563266

Epoch: 6| Step: 6
Training loss: 1.67694091796875
Validation loss: 2.5878034304547053

Epoch: 6| Step: 7
Training loss: 3.211010456085205
Validation loss: 2.5893237308789323

Epoch: 6| Step: 8
Training loss: 2.792837619781494
Validation loss: 2.6071556204108783

Epoch: 6| Step: 9
Training loss: 2.6126928329467773
Validation loss: 2.6382288727709042

Epoch: 6| Step: 10
Training loss: 2.732804298400879
Validation loss: 2.6954969385618806

Epoch: 6| Step: 11
Training loss: 3.3720932006835938
Validation loss: 2.633883435239074

Epoch: 6| Step: 12
Training loss: 2.8167994022369385
Validation loss: 2.594714754371233

Epoch: 6| Step: 13
Training loss: 2.8627328872680664
Validation loss: 2.5781834997156614

Epoch: 26| Step: 0
Training loss: 3.2377676963806152
Validation loss: 2.5681344873161724

Epoch: 6| Step: 1
Training loss: 3.4392240047454834
Validation loss: 2.6091500430978756

Epoch: 6| Step: 2
Training loss: 2.477809429168701
Validation loss: 2.5595788058414253

Epoch: 6| Step: 3
Training loss: 2.762468099594116
Validation loss: 2.5586591484726116

Epoch: 6| Step: 4
Training loss: 2.7041006088256836
Validation loss: 2.5712159961782475

Epoch: 6| Step: 5
Training loss: 3.459174633026123
Validation loss: 2.5947675320409958

Epoch: 6| Step: 6
Training loss: 2.4765634536743164
Validation loss: 2.6300782516438472

Epoch: 6| Step: 7
Training loss: 2.7545106410980225
Validation loss: 2.6657403797231694

Epoch: 6| Step: 8
Training loss: 2.554989814758301
Validation loss: 2.7401880577046382

Epoch: 6| Step: 9
Training loss: 3.0067272186279297
Validation loss: 2.813258781228014

Epoch: 6| Step: 10
Training loss: 2.810241937637329
Validation loss: 2.7714159821951263

Epoch: 6| Step: 11
Training loss: 2.826448440551758
Validation loss: 2.6731470169559604

Epoch: 6| Step: 12
Training loss: 2.648672103881836
Validation loss: 2.584683897674725

Epoch: 6| Step: 13
Training loss: 1.6969455480575562
Validation loss: 2.5516235084943872

Epoch: 27| Step: 0
Training loss: 2.2134714126586914
Validation loss: 2.578510110096265

Epoch: 6| Step: 1
Training loss: 2.824313163757324
Validation loss: 2.635570467159312

Epoch: 6| Step: 2
Training loss: 3.058483600616455
Validation loss: 2.6853935590354343

Epoch: 6| Step: 3
Training loss: 2.5005719661712646
Validation loss: 2.6956908138849403

Epoch: 6| Step: 4
Training loss: 2.4498238563537598
Validation loss: 2.6803534030914307

Epoch: 6| Step: 5
Training loss: 2.9877281188964844
Validation loss: 2.644353679431382

Epoch: 6| Step: 6
Training loss: 3.6199443340301514
Validation loss: 2.6227640490378104

Epoch: 6| Step: 7
Training loss: 3.0513720512390137
Validation loss: 2.605908819424209

Epoch: 6| Step: 8
Training loss: 3.3380939960479736
Validation loss: 2.597947835922241

Epoch: 6| Step: 9
Training loss: 2.5993618965148926
Validation loss: 2.586685401137157

Epoch: 6| Step: 10
Training loss: 2.769845485687256
Validation loss: 2.561710208974859

Epoch: 6| Step: 11
Training loss: 2.868269920349121
Validation loss: 2.529210598238053

Epoch: 6| Step: 12
Training loss: 2.5185556411743164
Validation loss: 2.528622696476598

Epoch: 6| Step: 13
Training loss: 2.1659152507781982
Validation loss: 2.524422178986252

Epoch: 28| Step: 0
Training loss: 2.6454834938049316
Validation loss: 2.5328379241369103

Epoch: 6| Step: 1
Training loss: 2.4412312507629395
Validation loss: 2.5555037631783435

Epoch: 6| Step: 2
Training loss: 2.757727861404419
Validation loss: 2.572002713398267

Epoch: 6| Step: 3
Training loss: 3.2620303630828857
Validation loss: 2.5785059775075605

Epoch: 6| Step: 4
Training loss: 2.228365659713745
Validation loss: 2.5623481042923464

Epoch: 6| Step: 5
Training loss: 3.4587202072143555
Validation loss: 2.5517417230913715

Epoch: 6| Step: 6
Training loss: 2.1336328983306885
Validation loss: 2.5278165699333273

Epoch: 6| Step: 7
Training loss: 2.6197080612182617
Validation loss: 2.518269528624832

Epoch: 6| Step: 8
Training loss: 2.955012798309326
Validation loss: 2.508127215088055

Epoch: 6| Step: 9
Training loss: 2.929642677307129
Validation loss: 2.4978913209771596

Epoch: 6| Step: 10
Training loss: 3.167585849761963
Validation loss: 2.4915956374137633

Epoch: 6| Step: 11
Training loss: 2.9780707359313965
Validation loss: 2.488241800697901

Epoch: 6| Step: 12
Training loss: 2.483874797821045
Validation loss: 2.4864440451386156

Epoch: 6| Step: 13
Training loss: 1.6923322677612305
Validation loss: 2.483839829762777

Epoch: 29| Step: 0
Training loss: 2.8002066612243652
Validation loss: 2.477329161859328

Epoch: 6| Step: 1
Training loss: 2.9091384410858154
Validation loss: 2.476842608503116

Epoch: 6| Step: 2
Training loss: 2.820981979370117
Validation loss: 2.4759403826088033

Epoch: 6| Step: 3
Training loss: 2.9581658840179443
Validation loss: 2.4820994100263043

Epoch: 6| Step: 4
Training loss: 2.565340995788574
Validation loss: 2.4707832464607815

Epoch: 6| Step: 5
Training loss: 2.5870251655578613
Validation loss: 2.4665392880798667

Epoch: 6| Step: 6
Training loss: 2.6786022186279297
Validation loss: 2.461630887882684

Epoch: 6| Step: 7
Training loss: 2.0816779136657715
Validation loss: 2.460443676158946

Epoch: 6| Step: 8
Training loss: 2.495171546936035
Validation loss: 2.4691984140744774

Epoch: 6| Step: 9
Training loss: 3.8921866416931152
Validation loss: 2.4670979617744364

Epoch: 6| Step: 10
Training loss: 2.3353238105773926
Validation loss: 2.4618480718264015

Epoch: 6| Step: 11
Training loss: 2.3598268032073975
Validation loss: 2.4539997116211922

Epoch: 6| Step: 12
Training loss: 2.767517328262329
Validation loss: 2.451526067590201

Epoch: 6| Step: 13
Training loss: 2.432427406311035
Validation loss: 2.4480901097738617

Epoch: 30| Step: 0
Training loss: 2.61553692817688
Validation loss: 2.4503232843132428

Epoch: 6| Step: 1
Training loss: 2.3222975730895996
Validation loss: 2.453163439227689

Epoch: 6| Step: 2
Training loss: 3.0148468017578125
Validation loss: 2.4557442895827757

Epoch: 6| Step: 3
Training loss: 2.3348655700683594
Validation loss: 2.455747283915038

Epoch: 6| Step: 4
Training loss: 2.2607688903808594
Validation loss: 2.4651525943509993

Epoch: 6| Step: 5
Training loss: 2.7573304176330566
Validation loss: 2.4647136939469205

Epoch: 6| Step: 6
Training loss: 2.735996723175049
Validation loss: 2.455285644018522

Epoch: 6| Step: 7
Training loss: 3.2706098556518555
Validation loss: 2.45257838567098

Epoch: 6| Step: 8
Training loss: 2.2415544986724854
Validation loss: 2.4454620961220033

Epoch: 6| Step: 9
Training loss: 2.8304619789123535
Validation loss: 2.4441639069587953

Epoch: 6| Step: 10
Training loss: 2.5314838886260986
Validation loss: 2.4375989206375612

Epoch: 6| Step: 11
Training loss: 3.5806519985198975
Validation loss: 2.437630853345317

Epoch: 6| Step: 12
Training loss: 2.5702385902404785
Validation loss: 2.4343609963693926

Epoch: 6| Step: 13
Training loss: 2.2376420497894287
Validation loss: 2.432437542946108

Epoch: 31| Step: 0
Training loss: 2.642197847366333
Validation loss: 2.4310997122077533

Epoch: 6| Step: 1
Training loss: 2.475480556488037
Validation loss: 2.4305298123308408

Epoch: 6| Step: 2
Training loss: 2.475440502166748
Validation loss: 2.4305672030295096

Epoch: 6| Step: 3
Training loss: 2.051948070526123
Validation loss: 2.4499576604494484

Epoch: 6| Step: 4
Training loss: 3.5503413677215576
Validation loss: 2.475234446987029

Epoch: 6| Step: 5
Training loss: 2.777225971221924
Validation loss: 2.491321979030486

Epoch: 6| Step: 6
Training loss: 2.259392261505127
Validation loss: 2.4796607673809095

Epoch: 6| Step: 7
Training loss: 3.047853946685791
Validation loss: 2.4730175131110737

Epoch: 6| Step: 8
Training loss: 2.561668872833252
Validation loss: 2.4676624754423737

Epoch: 6| Step: 9
Training loss: 3.2845146656036377
Validation loss: 2.4656627639647453

Epoch: 6| Step: 10
Training loss: 2.117765426635742
Validation loss: 2.455094619463849

Epoch: 6| Step: 11
Training loss: 2.7697949409484863
Validation loss: 2.43726880832385

Epoch: 6| Step: 12
Training loss: 2.420769691467285
Validation loss: 2.4271350470922326

Epoch: 6| Step: 13
Training loss: 3.2427217960357666
Validation loss: 2.4270798211456626

Epoch: 32| Step: 0
Training loss: 3.0274384021759033
Validation loss: 2.432034730911255

Epoch: 6| Step: 1
Training loss: 2.554039239883423
Validation loss: 2.4446844285534275

Epoch: 6| Step: 2
Training loss: 2.0636062622070312
Validation loss: 2.4535068004362044

Epoch: 6| Step: 3
Training loss: 3.110102653503418
Validation loss: 2.4615336746297856

Epoch: 6| Step: 4
Training loss: 1.9714720249176025
Validation loss: 2.4646385715853785

Epoch: 6| Step: 5
Training loss: 3.614828109741211
Validation loss: 2.454391628183344

Epoch: 6| Step: 6
Training loss: 2.2298054695129395
Validation loss: 2.4407872589685584

Epoch: 6| Step: 7
Training loss: 2.9748151302337646
Validation loss: 2.4275285351660942

Epoch: 6| Step: 8
Training loss: 3.3519287109375
Validation loss: 2.4195815414510746

Epoch: 6| Step: 9
Training loss: 2.4520535469055176
Validation loss: 2.4085434200943157

Epoch: 6| Step: 10
Training loss: 2.4547524452209473
Validation loss: 2.401905175178282

Epoch: 6| Step: 11
Training loss: 2.7909812927246094
Validation loss: 2.4089213519968014

Epoch: 6| Step: 12
Training loss: 2.1298935413360596
Validation loss: 2.443811656326376

Epoch: 6| Step: 13
Training loss: 2.80938982963562
Validation loss: 2.4707187990988455

Epoch: 33| Step: 0
Training loss: 2.646315574645996
Validation loss: 2.5082762241363525

Epoch: 6| Step: 1
Training loss: 1.936999797821045
Validation loss: 2.5048989198541127

Epoch: 6| Step: 2
Training loss: 2.045079231262207
Validation loss: 2.4617264809147006

Epoch: 6| Step: 3
Training loss: 3.005502223968506
Validation loss: 2.4234739580462055

Epoch: 6| Step: 4
Training loss: 2.4322619438171387
Validation loss: 2.3966337865398777

Epoch: 6| Step: 5
Training loss: 2.557276964187622
Validation loss: 2.3966005002298663

Epoch: 6| Step: 6
Training loss: 2.7881298065185547
Validation loss: 2.404591880818849

Epoch: 6| Step: 7
Training loss: 2.626854419708252
Validation loss: 2.412604549879669

Epoch: 6| Step: 8
Training loss: 3.3650834560394287
Validation loss: 2.4297709734209123

Epoch: 6| Step: 9
Training loss: 2.7620391845703125
Validation loss: 2.440264665952293

Epoch: 6| Step: 10
Training loss: 3.1587069034576416
Validation loss: 2.4453625294470016

Epoch: 6| Step: 11
Training loss: 2.740989923477173
Validation loss: 2.438431034805954

Epoch: 6| Step: 12
Training loss: 2.6819772720336914
Validation loss: 2.4145113627115884

Epoch: 6| Step: 13
Training loss: 2.8031880855560303
Validation loss: 2.3983920005060013

Epoch: 34| Step: 0
Training loss: 2.295900583267212
Validation loss: 2.3856529676786034

Epoch: 6| Step: 1
Training loss: 2.5536575317382812
Validation loss: 2.3826481911443893

Epoch: 6| Step: 2
Training loss: 2.84083890914917
Validation loss: 2.3866985664572766

Epoch: 6| Step: 3
Training loss: 2.423161506652832
Validation loss: 2.4128818793963362

Epoch: 6| Step: 4
Training loss: 2.534700870513916
Validation loss: 2.432487021210373

Epoch: 6| Step: 5
Training loss: 2.8170080184936523
Validation loss: 2.455985394857263

Epoch: 6| Step: 6
Training loss: 2.714571237564087
Validation loss: 2.453816101115237

Epoch: 6| Step: 7
Training loss: 2.5372838973999023
Validation loss: 2.403551645176385

Epoch: 6| Step: 8
Training loss: 2.445258855819702
Validation loss: 2.3749936114075365

Epoch: 6| Step: 9
Training loss: 2.349836826324463
Validation loss: 2.36720036947599

Epoch: 6| Step: 10
Training loss: 2.240969657897949
Validation loss: 2.3560489531486266

Epoch: 6| Step: 11
Training loss: 3.0497286319732666
Validation loss: 2.3584622900973082

Epoch: 6| Step: 12
Training loss: 3.3567633628845215
Validation loss: 2.365429657761769

Epoch: 6| Step: 13
Training loss: 2.985485315322876
Validation loss: 2.3764661178793958

Epoch: 35| Step: 0
Training loss: 1.887878179550171
Validation loss: 2.3893470277068434

Epoch: 6| Step: 1
Training loss: 2.4719371795654297
Validation loss: 2.3903683090722687

Epoch: 6| Step: 2
Training loss: 2.72299861907959
Validation loss: 2.387197491943195

Epoch: 6| Step: 3
Training loss: 2.8892641067504883
Validation loss: 2.3815561648338073

Epoch: 6| Step: 4
Training loss: 2.597450017929077
Validation loss: 2.377019300255724

Epoch: 6| Step: 5
Training loss: 2.9040699005126953
Validation loss: 2.3647915868348974

Epoch: 6| Step: 6
Training loss: 2.9236414432525635
Validation loss: 2.35511419850011

Epoch: 6| Step: 7
Training loss: 2.7372851371765137
Validation loss: 2.34690954608302

Epoch: 6| Step: 8
Training loss: 1.9942185878753662
Validation loss: 2.340942536630938

Epoch: 6| Step: 9
Training loss: 2.696925163269043
Validation loss: 2.342147422093217

Epoch: 6| Step: 10
Training loss: 2.9511373043060303
Validation loss: 2.3502893960604103

Epoch: 6| Step: 11
Training loss: 2.6700234413146973
Validation loss: 2.3560757790842364

Epoch: 6| Step: 12
Training loss: 3.1419434547424316
Validation loss: 2.3786304971223236

Epoch: 6| Step: 13
Training loss: 2.396984815597534
Validation loss: 2.3966415825710503

Epoch: 36| Step: 0
Training loss: 2.429687023162842
Validation loss: 2.3916212999692528

Epoch: 6| Step: 1
Training loss: 2.2890784740448
Validation loss: 2.3663451133235807

Epoch: 6| Step: 2
Training loss: 3.322589159011841
Validation loss: 2.3590798377990723

Epoch: 6| Step: 3
Training loss: 2.5261945724487305
Validation loss: 2.3563431321933703

Epoch: 6| Step: 4
Training loss: 1.8161121606826782
Validation loss: 2.3433155475124234

Epoch: 6| Step: 5
Training loss: 2.708359956741333
Validation loss: 2.335292311124904

Epoch: 6| Step: 6
Training loss: 3.1807422637939453
Validation loss: 2.329811990901988

Epoch: 6| Step: 7
Training loss: 2.7933318614959717
Validation loss: 2.33119172306471

Epoch: 6| Step: 8
Training loss: 2.992265224456787
Validation loss: 2.3305408775165515

Epoch: 6| Step: 9
Training loss: 2.9955902099609375
Validation loss: 2.330489863631546

Epoch: 6| Step: 10
Training loss: 2.0531370639801025
Validation loss: 2.3341521447704685

Epoch: 6| Step: 11
Training loss: 2.893763542175293
Validation loss: 2.341778939770114

Epoch: 6| Step: 12
Training loss: 2.682600975036621
Validation loss: 2.3480908563060146

Epoch: 6| Step: 13
Training loss: 1.5197386741638184
Validation loss: 2.3464218903613347

Epoch: 37| Step: 0
Training loss: 2.6738669872283936
Validation loss: 2.3413201173146567

Epoch: 6| Step: 1
Training loss: 2.968658685684204
Validation loss: 2.3409922225500948

Epoch: 6| Step: 2
Training loss: 2.353276491165161
Validation loss: 2.342700760851624

Epoch: 6| Step: 3
Training loss: 2.4619662761688232
Validation loss: 2.334419817052862

Epoch: 6| Step: 4
Training loss: 3.238945960998535
Validation loss: 2.3289313598345687

Epoch: 6| Step: 5
Training loss: 2.624873399734497
Validation loss: 2.3287324700304257

Epoch: 6| Step: 6
Training loss: 3.319654941558838
Validation loss: 2.322796598557503

Epoch: 6| Step: 7
Training loss: 2.5545058250427246
Validation loss: 2.3265502555395967

Epoch: 6| Step: 8
Training loss: 1.939819574356079
Validation loss: 2.323608390746578

Epoch: 6| Step: 9
Training loss: 2.5589258670806885
Validation loss: 2.3224006173431233

Epoch: 6| Step: 10
Training loss: 2.2007265090942383
Validation loss: 2.340719481950165

Epoch: 6| Step: 11
Training loss: 2.0836029052734375
Validation loss: 2.3486219862455964

Epoch: 6| Step: 12
Training loss: 3.2893052101135254
Validation loss: 2.367620419430476

Epoch: 6| Step: 13
Training loss: 1.9284324645996094
Validation loss: 2.3599451459864134

Epoch: 38| Step: 0
Training loss: 2.582519054412842
Validation loss: 2.365060414037397

Epoch: 6| Step: 1
Training loss: 2.585383415222168
Validation loss: 2.3547173007842033

Epoch: 6| Step: 2
Training loss: 2.7141647338867188
Validation loss: 2.3463167964771228

Epoch: 6| Step: 3
Training loss: 2.9092464447021484
Validation loss: 2.338495700590072

Epoch: 6| Step: 4
Training loss: 2.829346179962158
Validation loss: 2.345055510920863

Epoch: 6| Step: 5
Training loss: 2.0185251235961914
Validation loss: 2.3405641817277476

Epoch: 6| Step: 6
Training loss: 2.6837968826293945
Validation loss: 2.339180798940761

Epoch: 6| Step: 7
Training loss: 2.444627523422241
Validation loss: 2.3315318861315326

Epoch: 6| Step: 8
Training loss: 3.082943916320801
Validation loss: 2.3277640188893964

Epoch: 6| Step: 9
Training loss: 2.4854586124420166
Validation loss: 2.323940387336157

Epoch: 6| Step: 10
Training loss: 2.254842758178711
Validation loss: 2.316327771832866

Epoch: 6| Step: 11
Training loss: 3.140320301055908
Validation loss: 2.311220707431916

Epoch: 6| Step: 12
Training loss: 2.0419511795043945
Validation loss: 2.3053595712107997

Epoch: 6| Step: 13
Training loss: 2.448805809020996
Validation loss: 2.301017743284984

Epoch: 39| Step: 0
Training loss: 2.168529987335205
Validation loss: 2.3028296450132966

Epoch: 6| Step: 1
Training loss: 1.97291898727417
Validation loss: 2.304086580071398

Epoch: 6| Step: 2
Training loss: 2.6599059104919434
Validation loss: 2.3028979096361386

Epoch: 6| Step: 3
Training loss: 2.6894736289978027
Validation loss: 2.3004068636125132

Epoch: 6| Step: 4
Training loss: 2.982452869415283
Validation loss: 2.30177338405322

Epoch: 6| Step: 5
Training loss: 3.4160232543945312
Validation loss: 2.3142012857621714

Epoch: 6| Step: 6
Training loss: 2.794285535812378
Validation loss: 2.33257019904352

Epoch: 6| Step: 7
Training loss: 2.4783105850219727
Validation loss: 2.3622072794104136

Epoch: 6| Step: 8
Training loss: 2.5483386516571045
Validation loss: 2.402133908323062

Epoch: 6| Step: 9
Training loss: 2.6005780696868896
Validation loss: 2.3819052583427838

Epoch: 6| Step: 10
Training loss: 3.548841953277588
Validation loss: 2.322304343664518

Epoch: 6| Step: 11
Training loss: 2.1187424659729004
Validation loss: 2.296373636491837

Epoch: 6| Step: 12
Training loss: 1.912459135055542
Validation loss: 2.2975517908732095

Epoch: 6| Step: 13
Training loss: 2.5939743518829346
Validation loss: 2.3092604350018244

Epoch: 40| Step: 0
Training loss: 2.2492213249206543
Validation loss: 2.3162808700274398

Epoch: 6| Step: 1
Training loss: 1.8945472240447998
Validation loss: 2.3256180799135597

Epoch: 6| Step: 2
Training loss: 2.42879581451416
Validation loss: 2.3217251095720517

Epoch: 6| Step: 3
Training loss: 2.648879051208496
Validation loss: 2.320153767062772

Epoch: 6| Step: 4
Training loss: 2.866729497909546
Validation loss: 2.314188890559699

Epoch: 6| Step: 5
Training loss: 2.812649726867676
Validation loss: 2.307499526649393

Epoch: 6| Step: 6
Training loss: 2.2601678371429443
Validation loss: 2.3163183299444055

Epoch: 6| Step: 7
Training loss: 2.997955322265625
Validation loss: 2.3731241764560824

Epoch: 6| Step: 8
Training loss: 2.9692699909210205
Validation loss: 2.3858647961770334

Epoch: 6| Step: 9
Training loss: 2.2858200073242188
Validation loss: 2.3998115549805346

Epoch: 6| Step: 10
Training loss: 3.1121621131896973
Validation loss: 2.388398898545132

Epoch: 6| Step: 11
Training loss: 2.8939597606658936
Validation loss: 2.356125352203205

Epoch: 6| Step: 12
Training loss: 2.8564436435699463
Validation loss: 2.3349879967269076

Epoch: 6| Step: 13
Training loss: 1.6842061281204224
Validation loss: 2.32800478576332

Epoch: 41| Step: 0
Training loss: 3.1658339500427246
Validation loss: 2.3323236306508384

Epoch: 6| Step: 1
Training loss: 2.9665474891662598
Validation loss: 2.3310219703182096

Epoch: 6| Step: 2
Training loss: 2.974125623703003
Validation loss: 2.3236492885056363

Epoch: 6| Step: 3
Training loss: 2.34218692779541
Validation loss: 2.3288358244844662

Epoch: 6| Step: 4
Training loss: 2.164689064025879
Validation loss: 2.326929928154074

Epoch: 6| Step: 5
Training loss: 2.180661678314209
Validation loss: 2.3195144386701685

Epoch: 6| Step: 6
Training loss: 2.43164324760437
Validation loss: 2.3284624904714604

Epoch: 6| Step: 7
Training loss: 3.402172327041626
Validation loss: 2.325317149521202

Epoch: 6| Step: 8
Training loss: 1.9887816905975342
Validation loss: 2.3203023326012397

Epoch: 6| Step: 9
Training loss: 2.5948784351348877
Validation loss: 2.3147174260949575

Epoch: 6| Step: 10
Training loss: 2.1827125549316406
Validation loss: 2.308589217483356

Epoch: 6| Step: 11
Training loss: 3.1458823680877686
Validation loss: 2.309402932402908

Epoch: 6| Step: 12
Training loss: 2.386667251586914
Validation loss: 2.306336675920794

Epoch: 6| Step: 13
Training loss: 2.235440731048584
Validation loss: 2.30246804862894

Epoch: 42| Step: 0
Training loss: 2.8048923015594482
Validation loss: 2.2952446373560096

Epoch: 6| Step: 1
Training loss: 2.2880380153656006
Validation loss: 2.2927997804457143

Epoch: 6| Step: 2
Training loss: 2.239034652709961
Validation loss: 2.288710060939994

Epoch: 6| Step: 3
Training loss: 2.014730453491211
Validation loss: 2.2926776075875885

Epoch: 6| Step: 4
Training loss: 2.680751085281372
Validation loss: 2.294556604918613

Epoch: 6| Step: 5
Training loss: 3.2753384113311768
Validation loss: 2.295553909834995

Epoch: 6| Step: 6
Training loss: 2.782296657562256
Validation loss: 2.298962188023393

Epoch: 6| Step: 7
Training loss: 2.4910635948181152
Validation loss: 2.3036401861457416

Epoch: 6| Step: 8
Training loss: 2.7016777992248535
Validation loss: 2.3001869391369563

Epoch: 6| Step: 9
Training loss: 2.8217127323150635
Validation loss: 2.2923781846159246

Epoch: 6| Step: 10
Training loss: 2.423773765563965
Validation loss: 2.288783275952903

Epoch: 6| Step: 11
Training loss: 2.157012939453125
Validation loss: 2.2824114163716636

Epoch: 6| Step: 12
Training loss: 2.509793281555176
Validation loss: 2.281564889415618

Epoch: 6| Step: 13
Training loss: 3.1291778087615967
Validation loss: 2.278257428958852

Epoch: 43| Step: 0
Training loss: 2.2561490535736084
Validation loss: 2.2775677955278786

Epoch: 6| Step: 1
Training loss: 2.1416501998901367
Validation loss: 2.276266764569026

Epoch: 6| Step: 2
Training loss: 3.146787643432617
Validation loss: 2.279588750613633

Epoch: 6| Step: 3
Training loss: 3.2351741790771484
Validation loss: 2.2846336826201408

Epoch: 6| Step: 4
Training loss: 2.19144606590271
Validation loss: 2.2943068986297934

Epoch: 6| Step: 5
Training loss: 1.5858068466186523
Validation loss: 2.305841512577508

Epoch: 6| Step: 6
Training loss: 3.052673816680908
Validation loss: 2.3081355428182952

Epoch: 6| Step: 7
Training loss: 2.1937103271484375
Validation loss: 2.319848547699631

Epoch: 6| Step: 8
Training loss: 2.7628989219665527
Validation loss: 2.3080011208852134

Epoch: 6| Step: 9
Training loss: 2.3419089317321777
Validation loss: 2.3029462752803678

Epoch: 6| Step: 10
Training loss: 2.3686652183532715
Validation loss: 2.301909803062357

Epoch: 6| Step: 11
Training loss: 3.1631336212158203
Validation loss: 2.2940049453448226

Epoch: 6| Step: 12
Training loss: 3.4315757751464844
Validation loss: 2.2830920809058735

Epoch: 6| Step: 13
Training loss: 1.678182601928711
Validation loss: 2.2743668146030878

Epoch: 44| Step: 0
Training loss: 2.647538185119629
Validation loss: 2.2712960358588927

Epoch: 6| Step: 1
Training loss: 2.3124516010284424
Validation loss: 2.2749169359924974

Epoch: 6| Step: 2
Training loss: 3.0129876136779785
Validation loss: 2.2704284614132297

Epoch: 6| Step: 3
Training loss: 2.39751935005188
Validation loss: 2.2716664421942925

Epoch: 6| Step: 4
Training loss: 3.11142635345459
Validation loss: 2.2756820673583658

Epoch: 6| Step: 5
Training loss: 2.5818793773651123
Validation loss: 2.2762027376441547

Epoch: 6| Step: 6
Training loss: 3.0192036628723145
Validation loss: 2.2794534724245787

Epoch: 6| Step: 7
Training loss: 2.258695125579834
Validation loss: 2.2855999213393017

Epoch: 6| Step: 8
Training loss: 2.7839417457580566
Validation loss: 2.2740665405027327

Epoch: 6| Step: 9
Training loss: 1.7696616649627686
Validation loss: 2.266274324027441

Epoch: 6| Step: 10
Training loss: 2.9783482551574707
Validation loss: 2.2672651454966557

Epoch: 6| Step: 11
Training loss: 2.0671207904815674
Validation loss: 2.27908520801093

Epoch: 6| Step: 12
Training loss: 2.2187726497650146
Validation loss: 2.2906956621395644

Epoch: 6| Step: 13
Training loss: 3.1295266151428223
Validation loss: 2.3038438084304973

Epoch: 45| Step: 0
Training loss: 2.459782361984253
Validation loss: 2.304401059304514

Epoch: 6| Step: 1
Training loss: 3.1932857036590576
Validation loss: 2.3197251353212582

Epoch: 6| Step: 2
Training loss: 2.376552104949951
Validation loss: 2.3211748574369695

Epoch: 6| Step: 3
Training loss: 1.9254188537597656
Validation loss: 2.3110005624832644

Epoch: 6| Step: 4
Training loss: 2.3375244140625
Validation loss: 2.286976788633613

Epoch: 6| Step: 5
Training loss: 2.398611545562744
Validation loss: 2.268904209136963

Epoch: 6| Step: 6
Training loss: 2.3078227043151855
Validation loss: 2.2573630886693157

Epoch: 6| Step: 7
Training loss: 2.682492971420288
Validation loss: 2.258168602502474

Epoch: 6| Step: 8
Training loss: 2.5558104515075684
Validation loss: 2.26126955914241

Epoch: 6| Step: 9
Training loss: 3.3325343132019043
Validation loss: 2.264667385367937

Epoch: 6| Step: 10
Training loss: 3.0571179389953613
Validation loss: 2.2636919021606445

Epoch: 6| Step: 11
Training loss: 2.749866485595703
Validation loss: 2.2592382507939495

Epoch: 6| Step: 12
Training loss: 2.644179344177246
Validation loss: 2.26016043847607

Epoch: 6| Step: 13
Training loss: 1.6795850992202759
Validation loss: 2.2555251198430217

Epoch: 46| Step: 0
Training loss: 2.92726731300354
Validation loss: 2.2551500258907193

Epoch: 6| Step: 1
Training loss: 3.0897629261016846
Validation loss: 2.2531200890899985

Epoch: 6| Step: 2
Training loss: 2.870706796646118
Validation loss: 2.2712229349279918

Epoch: 6| Step: 3
Training loss: 2.276442289352417
Validation loss: 2.300279119963287

Epoch: 6| Step: 4
Training loss: 2.5766537189483643
Validation loss: 2.3313388363007577

Epoch: 6| Step: 5
Training loss: 2.9409594535827637
Validation loss: 2.3330487935773787

Epoch: 6| Step: 6
Training loss: 2.1352195739746094
Validation loss: 2.324926435306508

Epoch: 6| Step: 7
Training loss: 3.4033217430114746
Validation loss: 2.3278050653396116

Epoch: 6| Step: 8
Training loss: 1.9210944175720215
Validation loss: 2.3346855076410438

Epoch: 6| Step: 9
Training loss: 2.054725408554077
Validation loss: 2.327046207202378

Epoch: 6| Step: 10
Training loss: 2.1113407611846924
Validation loss: 2.3293501228414555

Epoch: 6| Step: 11
Training loss: 2.3161659240722656
Validation loss: 2.3130871147237797

Epoch: 6| Step: 12
Training loss: 2.593834638595581
Validation loss: 2.302792397878503

Epoch: 6| Step: 13
Training loss: 2.748687982559204
Validation loss: 2.294868971711846

Epoch: 47| Step: 0
Training loss: 2.5527470111846924
Validation loss: 2.2797961235046387

Epoch: 6| Step: 1
Training loss: 2.399094581604004
Validation loss: 2.2943712665188696

Epoch: 6| Step: 2
Training loss: 2.267946243286133
Validation loss: 2.3064735115215345

Epoch: 6| Step: 3
Training loss: 2.390014886856079
Validation loss: 2.356452600930327

Epoch: 6| Step: 4
Training loss: 2.834235906600952
Validation loss: 2.431978448744743

Epoch: 6| Step: 5
Training loss: 2.4466423988342285
Validation loss: 2.4242029061881443

Epoch: 6| Step: 6
Training loss: 2.6176555156707764
Validation loss: 2.359809349941951

Epoch: 6| Step: 7
Training loss: 3.071502447128296
Validation loss: 2.3193940834332536

Epoch: 6| Step: 8
Training loss: 2.544280529022217
Validation loss: 2.285425983449464

Epoch: 6| Step: 9
Training loss: 2.495424270629883
Validation loss: 2.2853807185285833

Epoch: 6| Step: 10
Training loss: 2.2477002143859863
Validation loss: 2.284939686457316

Epoch: 6| Step: 11
Training loss: 2.7193496227264404
Validation loss: 2.2854903718476653

Epoch: 6| Step: 12
Training loss: 2.709056854248047
Validation loss: 2.3022061701743834

Epoch: 6| Step: 13
Training loss: 2.8208541870117188
Validation loss: 2.3199213397118355

Epoch: 48| Step: 0
Training loss: 1.8582826852798462
Validation loss: 2.344875030620124

Epoch: 6| Step: 1
Training loss: 3.2209789752960205
Validation loss: 2.413573206111949

Epoch: 6| Step: 2
Training loss: 2.451331615447998
Validation loss: 2.4411709231715046

Epoch: 6| Step: 3
Training loss: 3.4338276386260986
Validation loss: 2.4418094465809483

Epoch: 6| Step: 4
Training loss: 3.1435985565185547
Validation loss: 2.4390893700302287

Epoch: 6| Step: 5
Training loss: 2.7087836265563965
Validation loss: 2.434275991173201

Epoch: 6| Step: 6
Training loss: 3.1152243614196777
Validation loss: 2.4197586069824877

Epoch: 6| Step: 7
Training loss: 2.413379192352295
Validation loss: 2.3901989177990983

Epoch: 6| Step: 8
Training loss: 2.2487661838531494
Validation loss: 2.3614504196310557

Epoch: 6| Step: 9
Training loss: 2.4844202995300293
Validation loss: 2.3394796309932584

Epoch: 6| Step: 10
Training loss: 3.3219919204711914
Validation loss: 2.283584415271718

Epoch: 6| Step: 11
Training loss: 1.4338762760162354
Validation loss: 2.256717222993092

Epoch: 6| Step: 12
Training loss: 2.2943637371063232
Validation loss: 2.2583382591124503

Epoch: 6| Step: 13
Training loss: 2.391357421875
Validation loss: 2.2682216346904798

Epoch: 49| Step: 0
Training loss: 2.9688401222229004
Validation loss: 2.282914371900661

Epoch: 6| Step: 1
Training loss: 2.833076000213623
Validation loss: 2.2870519955952964

Epoch: 6| Step: 2
Training loss: 2.5211362838745117
Validation loss: 2.3034377251901934

Epoch: 6| Step: 3
Training loss: 2.768256187438965
Validation loss: 2.3198355602961716

Epoch: 6| Step: 4
Training loss: 2.151390552520752
Validation loss: 2.326653577948129

Epoch: 6| Step: 5
Training loss: 2.048771619796753
Validation loss: 2.307335566448909

Epoch: 6| Step: 6
Training loss: 3.0531771183013916
Validation loss: 2.2912065598272506

Epoch: 6| Step: 7
Training loss: 2.7743241786956787
Validation loss: 2.2710259063269502

Epoch: 6| Step: 8
Training loss: 2.306278705596924
Validation loss: 2.245990002027122

Epoch: 6| Step: 9
Training loss: 2.4643828868865967
Validation loss: 2.2340854419175016

Epoch: 6| Step: 10
Training loss: 2.6729671955108643
Validation loss: 2.230298790880429

Epoch: 6| Step: 11
Training loss: 2.652761936187744
Validation loss: 2.225996437893119

Epoch: 6| Step: 12
Training loss: 2.3412718772888184
Validation loss: 2.221626979048534

Epoch: 6| Step: 13
Training loss: 1.674668550491333
Validation loss: 2.2243562975237445

Epoch: 50| Step: 0
Training loss: 2.854792833328247
Validation loss: 2.222522403604241

Epoch: 6| Step: 1
Training loss: 2.396484136581421
Validation loss: 2.223238270769837

Epoch: 6| Step: 2
Training loss: 3.189912796020508
Validation loss: 2.225597445682813

Epoch: 6| Step: 3
Training loss: 2.134329319000244
Validation loss: 2.2268624292906893

Epoch: 6| Step: 4
Training loss: 2.457960367202759
Validation loss: 2.2354867637798352

Epoch: 6| Step: 5
Training loss: 2.0481972694396973
Validation loss: 2.2358534810363606

Epoch: 6| Step: 6
Training loss: 2.8052849769592285
Validation loss: 2.225755727419289

Epoch: 6| Step: 7
Training loss: 2.6135175228118896
Validation loss: 2.2375381274889876

Epoch: 6| Step: 8
Training loss: 2.1763837337493896
Validation loss: 2.238809649662305

Epoch: 6| Step: 9
Training loss: 2.851592540740967
Validation loss: 2.237276633580526

Epoch: 6| Step: 10
Training loss: 2.552009344100952
Validation loss: 2.2401455499792613

Epoch: 6| Step: 11
Training loss: 1.8578718900680542
Validation loss: 2.2326068544900544

Epoch: 6| Step: 12
Training loss: 2.9322757720947266
Validation loss: 2.2450008546152422

Epoch: 6| Step: 13
Training loss: 2.6102535724639893
Validation loss: 2.255447067240233

Epoch: 51| Step: 0
Training loss: 2.231398105621338
Validation loss: 2.260109519445768

Epoch: 6| Step: 1
Training loss: 2.7202377319335938
Validation loss: 2.2612691156325804

Epoch: 6| Step: 2
Training loss: 3.3300764560699463
Validation loss: 2.258999225913837

Epoch: 6| Step: 3
Training loss: 2.3199923038482666
Validation loss: 2.247385286515759

Epoch: 6| Step: 4
Training loss: 2.7082133293151855
Validation loss: 2.2410546323304534

Epoch: 6| Step: 5
Training loss: 3.562159776687622
Validation loss: 2.226785652099117

Epoch: 6| Step: 6
Training loss: 1.8140778541564941
Validation loss: 2.2107245127360025

Epoch: 6| Step: 7
Training loss: 1.8149511814117432
Validation loss: 2.210879200248308

Epoch: 6| Step: 8
Training loss: 2.2338738441467285
Validation loss: 2.2101870018948793

Epoch: 6| Step: 9
Training loss: 1.9336848258972168
Validation loss: 2.2154738903045654

Epoch: 6| Step: 10
Training loss: 2.68078351020813
Validation loss: 2.212219447217962

Epoch: 6| Step: 11
Training loss: 2.8700366020202637
Validation loss: 2.206479577608006

Epoch: 6| Step: 12
Training loss: 2.6197071075439453
Validation loss: 2.2044601799339376

Epoch: 6| Step: 13
Training loss: 2.916381359100342
Validation loss: 2.2116079048443864

Epoch: 52| Step: 0
Training loss: 2.406527519226074
Validation loss: 2.2267958400070027

Epoch: 6| Step: 1
Training loss: 2.498467206954956
Validation loss: 2.2441992887886624

Epoch: 6| Step: 2
Training loss: 2.2831931114196777
Validation loss: 2.294027684837259

Epoch: 6| Step: 3
Training loss: 2.084348678588867
Validation loss: 2.33586787152034

Epoch: 6| Step: 4
Training loss: 2.326542615890503
Validation loss: 2.365600993556361

Epoch: 6| Step: 5
Training loss: 2.82674503326416
Validation loss: 2.3750387366100023

Epoch: 6| Step: 6
Training loss: 2.5627527236938477
Validation loss: 2.369549976882114

Epoch: 6| Step: 7
Training loss: 2.860517978668213
Validation loss: 2.3187544781674623

Epoch: 6| Step: 8
Training loss: 2.7471985816955566
Validation loss: 2.2601376054107503

Epoch: 6| Step: 9
Training loss: 2.7279181480407715
Validation loss: 2.2233917508074033

Epoch: 6| Step: 10
Training loss: 2.531407594680786
Validation loss: 2.209480277953609

Epoch: 6| Step: 11
Training loss: 2.3831686973571777
Validation loss: 2.2076667765135407

Epoch: 6| Step: 12
Training loss: 3.0454328060150146
Validation loss: 2.2248294225303074

Epoch: 6| Step: 13
Training loss: 1.8041316270828247
Validation loss: 2.2555861037264586

Epoch: 53| Step: 0
Training loss: 2.6411516666412354
Validation loss: 2.2932535115108696

Epoch: 6| Step: 1
Training loss: 2.759402275085449
Validation loss: 2.3169741886918263

Epoch: 6| Step: 2
Training loss: 2.2939159870147705
Validation loss: 2.311670687890822

Epoch: 6| Step: 3
Training loss: 2.354414939880371
Validation loss: 2.302724374237881

Epoch: 6| Step: 4
Training loss: 2.570772647857666
Validation loss: 2.304312550893394

Epoch: 6| Step: 5
Training loss: 2.3409719467163086
Validation loss: 2.3052922500077115

Epoch: 6| Step: 6
Training loss: 2.583231210708618
Validation loss: 2.254034515350096

Epoch: 6| Step: 7
Training loss: 2.0799789428710938
Validation loss: 2.2304474820372877

Epoch: 6| Step: 8
Training loss: 2.6402816772460938
Validation loss: 2.2249588556187128

Epoch: 6| Step: 9
Training loss: 2.6836066246032715
Validation loss: 2.245496424295569

Epoch: 6| Step: 10
Training loss: 2.8400378227233887
Validation loss: 2.2774672585148967

Epoch: 6| Step: 11
Training loss: 2.8868842124938965
Validation loss: 2.312055380113663

Epoch: 6| Step: 12
Training loss: 2.2052550315856934
Validation loss: 2.3335054997474916

Epoch: 6| Step: 13
Training loss: 3.3117222785949707
Validation loss: 2.3628631586669595

Epoch: 54| Step: 0
Training loss: 2.9354026317596436
Validation loss: 2.3205112206038607

Epoch: 6| Step: 1
Training loss: 1.691723108291626
Validation loss: 2.2681390021436956

Epoch: 6| Step: 2
Training loss: 2.9714818000793457
Validation loss: 2.2379992802937827

Epoch: 6| Step: 3
Training loss: 2.486860752105713
Validation loss: 2.205090474056941

Epoch: 6| Step: 4
Training loss: 2.592576742172241
Validation loss: 2.190815592324862

Epoch: 6| Step: 5
Training loss: 2.8592138290405273
Validation loss: 2.198516248374857

Epoch: 6| Step: 6
Training loss: 2.679030656814575
Validation loss: 2.207506154173164

Epoch: 6| Step: 7
Training loss: 3.2580833435058594
Validation loss: 2.2005805225782495

Epoch: 6| Step: 8
Training loss: 2.406639814376831
Validation loss: 2.1876586316734232

Epoch: 6| Step: 9
Training loss: 2.3500537872314453
Validation loss: 2.1887808281888246

Epoch: 6| Step: 10
Training loss: 2.618516206741333
Validation loss: 2.1872330378460627

Epoch: 6| Step: 11
Training loss: 2.6377344131469727
Validation loss: 2.189289144290391

Epoch: 6| Step: 12
Training loss: 1.812939167022705
Validation loss: 2.207088783223142

Epoch: 6| Step: 13
Training loss: 2.24582839012146
Validation loss: 2.2299326671067106

Epoch: 55| Step: 0
Training loss: 2.205108165740967
Validation loss: 2.2638950194081953

Epoch: 6| Step: 1
Training loss: 2.755089521408081
Validation loss: 2.3215552555617465

Epoch: 6| Step: 2
Training loss: 2.6092050075531006
Validation loss: 2.380607533198531

Epoch: 6| Step: 3
Training loss: 2.2364046573638916
Validation loss: 2.4102324260178434

Epoch: 6| Step: 4
Training loss: 2.3592724800109863
Validation loss: 2.3483111140548543

Epoch: 6| Step: 5
Training loss: 2.166245937347412
Validation loss: 2.2606235345204673

Epoch: 6| Step: 6
Training loss: 2.408266067504883
Validation loss: 2.225590564871347

Epoch: 6| Step: 7
Training loss: 3.278794765472412
Validation loss: 2.193934803367943

Epoch: 6| Step: 8
Training loss: 2.4872567653656006
Validation loss: 2.1857044517353015

Epoch: 6| Step: 9
Training loss: 2.6319923400878906
Validation loss: 2.183693729421144

Epoch: 6| Step: 10
Training loss: 2.786855697631836
Validation loss: 2.186376279400241

Epoch: 6| Step: 11
Training loss: 2.6072821617126465
Validation loss: 2.1898522069377284

Epoch: 6| Step: 12
Training loss: 2.788935661315918
Validation loss: 2.185721981909967

Epoch: 6| Step: 13
Training loss: 1.5719711780548096
Validation loss: 2.1917139689127603

Epoch: 56| Step: 0
Training loss: 3.078345537185669
Validation loss: 2.1910768888329946

Epoch: 6| Step: 1
Training loss: 2.5957493782043457
Validation loss: 2.1836531444262435

Epoch: 6| Step: 2
Training loss: 2.134943723678589
Validation loss: 2.1863286033753426

Epoch: 6| Step: 3
Training loss: 2.56440806388855
Validation loss: 2.181915811313096

Epoch: 6| Step: 4
Training loss: 2.593137264251709
Validation loss: 2.1898914460212953

Epoch: 6| Step: 5
Training loss: 2.4178757667541504
Validation loss: 2.198396344338694

Epoch: 6| Step: 6
Training loss: 1.9393717050552368
Validation loss: 2.2100614193947083

Epoch: 6| Step: 7
Training loss: 2.089967966079712
Validation loss: 2.232561206304899

Epoch: 6| Step: 8
Training loss: 2.6038920879364014
Validation loss: 2.2687688809569164

Epoch: 6| Step: 9
Training loss: 2.864621877670288
Validation loss: 2.297740601724194

Epoch: 6| Step: 10
Training loss: 2.3096680641174316
Validation loss: 2.315837055124262

Epoch: 6| Step: 11
Training loss: 3.1016452312469482
Validation loss: 2.32848378791604

Epoch: 6| Step: 12
Training loss: 2.5476016998291016
Validation loss: 2.2913500980664323

Epoch: 6| Step: 13
Training loss: 2.5049285888671875
Validation loss: 2.263644190244777

Epoch: 57| Step: 0
Training loss: 2.2731552124023438
Validation loss: 2.2278176302550943

Epoch: 6| Step: 1
Training loss: 2.0819413661956787
Validation loss: 2.2038141681301977

Epoch: 6| Step: 2
Training loss: 2.0405569076538086
Validation loss: 2.1874594919143187

Epoch: 6| Step: 3
Training loss: 2.820283889770508
Validation loss: 2.1809541563833914

Epoch: 6| Step: 4
Training loss: 2.5158891677856445
Validation loss: 2.1809357455981675

Epoch: 6| Step: 5
Training loss: 1.779845952987671
Validation loss: 2.189737857029002

Epoch: 6| Step: 6
Training loss: 3.0075483322143555
Validation loss: 2.1976834368962113

Epoch: 6| Step: 7
Training loss: 2.2628250122070312
Validation loss: 2.205413942695946

Epoch: 6| Step: 8
Training loss: 2.8496956825256348
Validation loss: 2.207866725101266

Epoch: 6| Step: 9
Training loss: 2.5169358253479004
Validation loss: 2.2198807988115536

Epoch: 6| Step: 10
Training loss: 2.8271822929382324
Validation loss: 2.2235226246618454

Epoch: 6| Step: 11
Training loss: 2.7639081478118896
Validation loss: 2.234733340560749

Epoch: 6| Step: 12
Training loss: 2.436124324798584
Validation loss: 2.256158080152286

Epoch: 6| Step: 13
Training loss: 3.0537168979644775
Validation loss: 2.2733468060852378

Epoch: 58| Step: 0
Training loss: 2.0026631355285645
Validation loss: 2.265701657982283

Epoch: 6| Step: 1
Training loss: 2.2202680110931396
Validation loss: 2.264236750141267

Epoch: 6| Step: 2
Training loss: 1.9607582092285156
Validation loss: 2.2521432138258413

Epoch: 6| Step: 3
Training loss: 1.9842629432678223
Validation loss: 2.2247227340616207

Epoch: 6| Step: 4
Training loss: 2.938523769378662
Validation loss: 2.219826862376223

Epoch: 6| Step: 5
Training loss: 2.526545524597168
Validation loss: 2.210511439590044

Epoch: 6| Step: 6
Training loss: 2.901218891143799
Validation loss: 2.206654328171925

Epoch: 6| Step: 7
Training loss: 2.0091962814331055
Validation loss: 2.2065238760363672

Epoch: 6| Step: 8
Training loss: 2.844517707824707
Validation loss: 2.203228013489836

Epoch: 6| Step: 9
Training loss: 3.232409715652466
Validation loss: 2.1974944863268124

Epoch: 6| Step: 10
Training loss: 2.3360214233398438
Validation loss: 2.198785153768396

Epoch: 6| Step: 11
Training loss: 2.59031343460083
Validation loss: 2.184021706222206

Epoch: 6| Step: 12
Training loss: 2.3025269508361816
Validation loss: 2.178172770366874

Epoch: 6| Step: 13
Training loss: 3.3440699577331543
Validation loss: 2.1782012895871232

Epoch: 59| Step: 0
Training loss: 2.2791900634765625
Validation loss: 2.1743904365006315

Epoch: 6| Step: 1
Training loss: 3.072317123413086
Validation loss: 2.178042377195051

Epoch: 6| Step: 2
Training loss: 3.017850875854492
Validation loss: 2.1839786319322485

Epoch: 6| Step: 3
Training loss: 2.043260097503662
Validation loss: 2.184496807795699

Epoch: 6| Step: 4
Training loss: 2.390927314758301
Validation loss: 2.182706538067069

Epoch: 6| Step: 5
Training loss: 2.487882375717163
Validation loss: 2.1811668924106065

Epoch: 6| Step: 6
Training loss: 2.9615776538848877
Validation loss: 2.179807319436022

Epoch: 6| Step: 7
Training loss: 2.2034318447113037
Validation loss: 2.177004491129229

Epoch: 6| Step: 8
Training loss: 2.5256576538085938
Validation loss: 2.1730682401246924

Epoch: 6| Step: 9
Training loss: 2.57057785987854
Validation loss: 2.180292007743671

Epoch: 6| Step: 10
Training loss: 2.61856746673584
Validation loss: 2.198860127438781

Epoch: 6| Step: 11
Training loss: 2.3584578037261963
Validation loss: 2.2353904452375186

Epoch: 6| Step: 12
Training loss: 2.327854633331299
Validation loss: 2.2742534529778267

Epoch: 6| Step: 13
Training loss: 2.083791494369507
Validation loss: 2.319430676839685

Epoch: 60| Step: 0
Training loss: 2.867542266845703
Validation loss: 2.29456465987749

Epoch: 6| Step: 1
Training loss: 2.541553258895874
Validation loss: 2.2791744842324206

Epoch: 6| Step: 2
Training loss: 2.4387803077697754
Validation loss: 2.249298067503078

Epoch: 6| Step: 3
Training loss: 2.169279098510742
Validation loss: 2.2361419405988467

Epoch: 6| Step: 4
Training loss: 3.1101720333099365
Validation loss: 2.221994300042429

Epoch: 6| Step: 5
Training loss: 2.8660120964050293
Validation loss: 2.2258308702899563

Epoch: 6| Step: 6
Training loss: 2.5282161235809326
Validation loss: 2.2125829932510213

Epoch: 6| Step: 7
Training loss: 2.506943702697754
Validation loss: 2.2005355870851906

Epoch: 6| Step: 8
Training loss: 2.198129177093506
Validation loss: 2.2001210258853052

Epoch: 6| Step: 9
Training loss: 2.53120756149292
Validation loss: 2.191066312533553

Epoch: 6| Step: 10
Training loss: 1.9045580625534058
Validation loss: 2.1807128165357854

Epoch: 6| Step: 11
Training loss: 2.585470676422119
Validation loss: 2.1784484488989717

Epoch: 6| Step: 12
Training loss: 2.0053727626800537
Validation loss: 2.179415108055197

Epoch: 6| Step: 13
Training loss: 2.7206883430480957
Validation loss: 2.1840768244958695

Epoch: 61| Step: 0
Training loss: 3.179814100265503
Validation loss: 2.1767929407858078

Epoch: 6| Step: 1
Training loss: 2.4115993976593018
Validation loss: 2.1818133131150277

Epoch: 6| Step: 2
Training loss: 1.9823932647705078
Validation loss: 2.176677037310857

Epoch: 6| Step: 3
Training loss: 2.8191418647766113
Validation loss: 2.177553471698556

Epoch: 6| Step: 4
Training loss: 1.8645966053009033
Validation loss: 2.1839476272624028

Epoch: 6| Step: 5
Training loss: 2.3615729808807373
Validation loss: 2.1962219181881157

Epoch: 6| Step: 6
Training loss: 2.026007890701294
Validation loss: 2.2140614012236237

Epoch: 6| Step: 7
Training loss: 2.5682551860809326
Validation loss: 2.229730483024351

Epoch: 6| Step: 8
Training loss: 2.864198684692383
Validation loss: 2.2308523654937744

Epoch: 6| Step: 9
Training loss: 2.3278586864471436
Validation loss: 2.2099198038860033

Epoch: 6| Step: 10
Training loss: 2.254847526550293
Validation loss: 2.1637402593448596

Epoch: 6| Step: 11
Training loss: 2.6440846920013428
Validation loss: 2.1531307466568483

Epoch: 6| Step: 12
Training loss: 3.013967275619507
Validation loss: 2.1514133381587204

Epoch: 6| Step: 13
Training loss: 2.078538179397583
Validation loss: 2.1538272775629514

Epoch: 62| Step: 0
Training loss: 1.818852186203003
Validation loss: 2.1610068967265468

Epoch: 6| Step: 1
Training loss: 2.5343427658081055
Validation loss: 2.156077564403575

Epoch: 6| Step: 2
Training loss: 3.0863752365112305
Validation loss: 2.155301050473285

Epoch: 6| Step: 3
Training loss: 2.609340190887451
Validation loss: 2.1620137153133268

Epoch: 6| Step: 4
Training loss: 1.9638023376464844
Validation loss: 2.1684417801518596

Epoch: 6| Step: 5
Training loss: 2.5941457748413086
Validation loss: 2.1924634184888614

Epoch: 6| Step: 6
Training loss: 2.6883902549743652
Validation loss: 2.2136441584556334

Epoch: 6| Step: 7
Training loss: 2.429175853729248
Validation loss: 2.2219836916974796

Epoch: 6| Step: 8
Training loss: 1.91209876537323
Validation loss: 2.199657199203327

Epoch: 6| Step: 9
Training loss: 2.836700439453125
Validation loss: 2.174475610897105

Epoch: 6| Step: 10
Training loss: 2.3498599529266357
Validation loss: 2.1687574514778714

Epoch: 6| Step: 11
Training loss: 2.8138468265533447
Validation loss: 2.152530898330032

Epoch: 6| Step: 12
Training loss: 2.4895997047424316
Validation loss: 2.1484114944293933

Epoch: 6| Step: 13
Training loss: 2.64546799659729
Validation loss: 2.1482679228628836

Epoch: 63| Step: 0
Training loss: 2.1253199577331543
Validation loss: 2.142381852672946

Epoch: 6| Step: 1
Training loss: 1.5294517278671265
Validation loss: 2.150056794125547

Epoch: 6| Step: 2
Training loss: 2.7969415187835693
Validation loss: 2.1594711567765925

Epoch: 6| Step: 3
Training loss: 2.146852970123291
Validation loss: 2.169457802208521

Epoch: 6| Step: 4
Training loss: 2.621889352798462
Validation loss: 2.1868594102962042

Epoch: 6| Step: 5
Training loss: 2.157174825668335
Validation loss: 2.204672436560354

Epoch: 6| Step: 6
Training loss: 2.332599639892578
Validation loss: 2.2291567402501262

Epoch: 6| Step: 7
Training loss: 2.760310173034668
Validation loss: 2.248787864562004

Epoch: 6| Step: 8
Training loss: 1.9179859161376953
Validation loss: 2.2545912701596498

Epoch: 6| Step: 9
Training loss: 2.8940916061401367
Validation loss: 2.235349476978343

Epoch: 6| Step: 10
Training loss: 2.4441919326782227
Validation loss: 2.2244861484855734

Epoch: 6| Step: 11
Training loss: 3.4046688079833984
Validation loss: 2.225221064782912

Epoch: 6| Step: 12
Training loss: 2.463137626647949
Validation loss: 2.181577015948552

Epoch: 6| Step: 13
Training loss: 3.2368555068969727
Validation loss: 2.1522127505271667

Epoch: 64| Step: 0
Training loss: 2.3071601390838623
Validation loss: 2.140015220129362

Epoch: 6| Step: 1
Training loss: 3.0683090686798096
Validation loss: 2.1340461059283187

Epoch: 6| Step: 2
Training loss: 2.14074969291687
Validation loss: 2.128670036151845

Epoch: 6| Step: 3
Training loss: 1.9911553859710693
Validation loss: 2.124140980423138

Epoch: 6| Step: 4
Training loss: 2.4865775108337402
Validation loss: 2.1250797228146623

Epoch: 6| Step: 5
Training loss: 2.8440070152282715
Validation loss: 2.1238947247946136

Epoch: 6| Step: 6
Training loss: 2.317469596862793
Validation loss: 2.1261079208825224

Epoch: 6| Step: 7
Training loss: 2.1250104904174805
Validation loss: 2.1292085916765275

Epoch: 6| Step: 8
Training loss: 2.7534539699554443
Validation loss: 2.1349261653038765

Epoch: 6| Step: 9
Training loss: 2.0574612617492676
Validation loss: 2.152552300883878

Epoch: 6| Step: 10
Training loss: 2.897160291671753
Validation loss: 2.1719057893240326

Epoch: 6| Step: 11
Training loss: 2.0198769569396973
Validation loss: 2.1792900741741223

Epoch: 6| Step: 12
Training loss: 2.659627914428711
Validation loss: 2.178001662736298

Epoch: 6| Step: 13
Training loss: 2.7864274978637695
Validation loss: 2.181010259095059

Epoch: 65| Step: 0
Training loss: 2.759146213531494
Validation loss: 2.1730674184778684

Epoch: 6| Step: 1
Training loss: 2.519164562225342
Validation loss: 2.154808707134698

Epoch: 6| Step: 2
Training loss: 2.447787284851074
Validation loss: 2.1391444911238966

Epoch: 6| Step: 3
Training loss: 1.9559853076934814
Validation loss: 2.1320264390719834

Epoch: 6| Step: 4
Training loss: 2.0670175552368164
Validation loss: 2.1302114109839163

Epoch: 6| Step: 5
Training loss: 1.9889097213745117
Validation loss: 2.128084046866304

Epoch: 6| Step: 6
Training loss: 2.3310439586639404
Validation loss: 2.1334859017402894

Epoch: 6| Step: 7
Training loss: 2.5689072608947754
Validation loss: 2.1453697322517313

Epoch: 6| Step: 8
Training loss: 1.9917783737182617
Validation loss: 2.142888270398622

Epoch: 6| Step: 9
Training loss: 2.918562650680542
Validation loss: 2.1590707481548352

Epoch: 6| Step: 10
Training loss: 3.02797794342041
Validation loss: 2.1811567134754632

Epoch: 6| Step: 11
Training loss: 2.422638416290283
Validation loss: 2.200354186437463

Epoch: 6| Step: 12
Training loss: 2.713766574859619
Validation loss: 2.2059683287015526

Epoch: 6| Step: 13
Training loss: 2.223607063293457
Validation loss: 2.2143266675292805

Epoch: 66| Step: 0
Training loss: 1.7978520393371582
Validation loss: 2.2194702497092624

Epoch: 6| Step: 1
Training loss: 3.1144790649414062
Validation loss: 2.218954896414152

Epoch: 6| Step: 2
Training loss: 2.673109531402588
Validation loss: 2.2012547241744174

Epoch: 6| Step: 3
Training loss: 2.686702013015747
Validation loss: 2.188270092010498

Epoch: 6| Step: 4
Training loss: 2.2593863010406494
Validation loss: 2.1519409482197096

Epoch: 6| Step: 5
Training loss: 2.124441623687744
Validation loss: 2.139627601510735

Epoch: 6| Step: 6
Training loss: 2.3981549739837646
Validation loss: 2.1312910279920025

Epoch: 6| Step: 7
Training loss: 2.4439377784729004
Validation loss: 2.1256502597562728

Epoch: 6| Step: 8
Training loss: 2.7312891483306885
Validation loss: 2.1262703070076565

Epoch: 6| Step: 9
Training loss: 1.9199403524398804
Validation loss: 2.12335551938703

Epoch: 6| Step: 10
Training loss: 2.251901149749756
Validation loss: 2.129613309778193

Epoch: 6| Step: 11
Training loss: 2.9159014225006104
Validation loss: 2.1293564599047423

Epoch: 6| Step: 12
Training loss: 2.7591943740844727
Validation loss: 2.1235986781376663

Epoch: 6| Step: 13
Training loss: 2.10235857963562
Validation loss: 2.1207387396084365

Epoch: 67| Step: 0
Training loss: 2.3356704711914062
Validation loss: 2.1245786771979382

Epoch: 6| Step: 1
Training loss: 1.5607011318206787
Validation loss: 2.123272970158567

Epoch: 6| Step: 2
Training loss: 2.6730189323425293
Validation loss: 2.1235665326477378

Epoch: 6| Step: 3
Training loss: 2.486248016357422
Validation loss: 2.1237174259719027

Epoch: 6| Step: 4
Training loss: 2.407416343688965
Validation loss: 2.121275204484181

Epoch: 6| Step: 5
Training loss: 2.4104256629943848
Validation loss: 2.1339247854807044

Epoch: 6| Step: 6
Training loss: 2.486708879470825
Validation loss: 2.141753537680513

Epoch: 6| Step: 7
Training loss: 2.958099365234375
Validation loss: 2.1507252852121987

Epoch: 6| Step: 8
Training loss: 2.7161097526550293
Validation loss: 2.156147922238996

Epoch: 6| Step: 9
Training loss: 2.2318549156188965
Validation loss: 2.138392294606855

Epoch: 6| Step: 10
Training loss: 2.230458974838257
Validation loss: 2.12942498986439

Epoch: 6| Step: 11
Training loss: 2.635807991027832
Validation loss: 2.118312143510388

Epoch: 6| Step: 12
Training loss: 2.342458724975586
Validation loss: 2.115696212296845

Epoch: 6| Step: 13
Training loss: 2.535342216491699
Validation loss: 2.1139090138096965

Epoch: 68| Step: 0
Training loss: 2.4261271953582764
Validation loss: 2.122974859770908

Epoch: 6| Step: 1
Training loss: 2.764634609222412
Validation loss: 2.1284604252025647

Epoch: 6| Step: 2
Training loss: 2.589503765106201
Validation loss: 2.1230279168775006

Epoch: 6| Step: 3
Training loss: 2.1873626708984375
Validation loss: 2.119610191673361

Epoch: 6| Step: 4
Training loss: 2.1300745010375977
Validation loss: 2.117848124555362

Epoch: 6| Step: 5
Training loss: 2.5289106369018555
Validation loss: 2.1229512665861394

Epoch: 6| Step: 6
Training loss: 2.375627040863037
Validation loss: 2.121891406274611

Epoch: 6| Step: 7
Training loss: 2.4385905265808105
Validation loss: 2.12920037392647

Epoch: 6| Step: 8
Training loss: 1.9975701570510864
Validation loss: 2.1312222198773454

Epoch: 6| Step: 9
Training loss: 2.2495012283325195
Validation loss: 2.143644675131767

Epoch: 6| Step: 10
Training loss: 2.728144645690918
Validation loss: 2.15831696602606

Epoch: 6| Step: 11
Training loss: 1.9342334270477295
Validation loss: 2.1598781206274547

Epoch: 6| Step: 12
Training loss: 2.9200921058654785
Validation loss: 2.1688231678419214

Epoch: 6| Step: 13
Training loss: 2.6697089672088623
Validation loss: 2.1521087564447874

Epoch: 69| Step: 0
Training loss: 2.861476421356201
Validation loss: 2.141193820584205

Epoch: 6| Step: 1
Training loss: 2.5517678260803223
Validation loss: 2.1309413333092966

Epoch: 6| Step: 2
Training loss: 2.4418773651123047
Validation loss: 2.1279775378524617

Epoch: 6| Step: 3
Training loss: 1.723867654800415
Validation loss: 2.1144128717401975

Epoch: 6| Step: 4
Training loss: 2.9263901710510254
Validation loss: 2.101917037399866

Epoch: 6| Step: 5
Training loss: 2.995335817337036
Validation loss: 2.104436594952819

Epoch: 6| Step: 6
Training loss: 1.9667788743972778
Validation loss: 2.0980545449000534

Epoch: 6| Step: 7
Training loss: 2.282194137573242
Validation loss: 2.109429908055131

Epoch: 6| Step: 8
Training loss: 1.8939841985702515
Validation loss: 2.11605647302443

Epoch: 6| Step: 9
Training loss: 2.852193832397461
Validation loss: 2.123138314934187

Epoch: 6| Step: 10
Training loss: 1.7526220083236694
Validation loss: 2.129458422301918

Epoch: 6| Step: 11
Training loss: 1.9526703357696533
Validation loss: 2.1162096736251668

Epoch: 6| Step: 12
Training loss: 3.146446704864502
Validation loss: 2.1046167573621197

Epoch: 6| Step: 13
Training loss: 2.162112236022949
Validation loss: 2.1005251048713602

Epoch: 70| Step: 0
Training loss: 2.040286064147949
Validation loss: 2.0949716132174254

Epoch: 6| Step: 1
Training loss: 1.542569875717163
Validation loss: 2.0972974966931086

Epoch: 6| Step: 2
Training loss: 1.9673386812210083
Validation loss: 2.1115370514572307

Epoch: 6| Step: 3
Training loss: 2.569690227508545
Validation loss: 2.1206898843088458

Epoch: 6| Step: 4
Training loss: 2.8760056495666504
Validation loss: 2.1163479564010457

Epoch: 6| Step: 5
Training loss: 2.197526216506958
Validation loss: 2.112215562533307

Epoch: 6| Step: 6
Training loss: 2.4780564308166504
Validation loss: 2.1143491165612334

Epoch: 6| Step: 7
Training loss: 2.78938364982605
Validation loss: 2.1006413954560474

Epoch: 6| Step: 8
Training loss: 2.526611566543579
Validation loss: 2.0923022454784763

Epoch: 6| Step: 9
Training loss: 2.4023666381835938
Validation loss: 2.081929899031116

Epoch: 6| Step: 10
Training loss: 2.991358757019043
Validation loss: 2.0811193591804913

Epoch: 6| Step: 11
Training loss: 3.3653717041015625
Validation loss: 2.0797404730191795

Epoch: 6| Step: 12
Training loss: 1.4887620210647583
Validation loss: 2.082413174772775

Epoch: 6| Step: 13
Training loss: 2.440208673477173
Validation loss: 2.0827018573719966

Epoch: 71| Step: 0
Training loss: 2.4621310234069824
Validation loss: 2.0837601692445817

Epoch: 6| Step: 1
Training loss: 2.1697123050689697
Validation loss: 2.087604068940686

Epoch: 6| Step: 2
Training loss: 3.2649874687194824
Validation loss: 2.0950079707689184

Epoch: 6| Step: 3
Training loss: 2.3284528255462646
Validation loss: 2.1033876583140385

Epoch: 6| Step: 4
Training loss: 2.961090087890625
Validation loss: 2.1108124897044194

Epoch: 6| Step: 5
Training loss: 2.6777682304382324
Validation loss: 2.139879377939368

Epoch: 6| Step: 6
Training loss: 2.970217704772949
Validation loss: 2.1476948850898334

Epoch: 6| Step: 7
Training loss: 1.9939870834350586
Validation loss: 2.1209023255173878

Epoch: 6| Step: 8
Training loss: 2.5601601600646973
Validation loss: 2.107914460602627

Epoch: 6| Step: 9
Training loss: 2.3068249225616455
Validation loss: 2.1021612908250544

Epoch: 6| Step: 10
Training loss: 1.9794819355010986
Validation loss: 2.0945009723786385

Epoch: 6| Step: 11
Training loss: 2.0556485652923584
Validation loss: 2.0931302962764615

Epoch: 6| Step: 12
Training loss: 1.9956417083740234
Validation loss: 2.082562231248425

Epoch: 6| Step: 13
Training loss: 1.4406089782714844
Validation loss: 2.0837070326651297

Epoch: 72| Step: 0
Training loss: 2.975053310394287
Validation loss: 2.0814269742658063

Epoch: 6| Step: 1
Training loss: 2.2289886474609375
Validation loss: 2.088366566165801

Epoch: 6| Step: 2
Training loss: 2.068912982940674
Validation loss: 2.088496954210343

Epoch: 6| Step: 3
Training loss: 3.098227024078369
Validation loss: 2.0951728141436012

Epoch: 6| Step: 4
Training loss: 2.754530668258667
Validation loss: 2.0899038353273944

Epoch: 6| Step: 5
Training loss: 2.111847400665283
Validation loss: 2.08903234235702

Epoch: 6| Step: 6
Training loss: 3.172816276550293
Validation loss: 2.0977843666589386

Epoch: 6| Step: 7
Training loss: 2.3243772983551025
Validation loss: 2.0964313630134828

Epoch: 6| Step: 8
Training loss: 1.940803050994873
Validation loss: 2.1042065223058066

Epoch: 6| Step: 9
Training loss: 2.161674976348877
Validation loss: 2.0890882066501084

Epoch: 6| Step: 10
Training loss: 1.840987205505371
Validation loss: 2.081692052143876

Epoch: 6| Step: 11
Training loss: 1.8664820194244385
Validation loss: 2.082572697311319

Epoch: 6| Step: 12
Training loss: 2.017176866531372
Validation loss: 2.0913062428915374

Epoch: 6| Step: 13
Training loss: 2.992177724838257
Validation loss: 2.0961768255438855

Epoch: 73| Step: 0
Training loss: 2.6999802589416504
Validation loss: 2.093941323218807

Epoch: 6| Step: 1
Training loss: 2.24882435798645
Validation loss: 2.0845304125098774

Epoch: 6| Step: 2
Training loss: 2.680497884750366
Validation loss: 2.0825504667015484

Epoch: 6| Step: 3
Training loss: 2.6274023056030273
Validation loss: 2.0729328227299515

Epoch: 6| Step: 4
Training loss: 2.7282416820526123
Validation loss: 2.0727369503308366

Epoch: 6| Step: 5
Training loss: 2.043964147567749
Validation loss: 2.0776260898959253

Epoch: 6| Step: 6
Training loss: 2.9915053844451904
Validation loss: 2.0817098476553477

Epoch: 6| Step: 7
Training loss: 1.8405346870422363
Validation loss: 2.076785409322349

Epoch: 6| Step: 8
Training loss: 2.5947883129119873
Validation loss: 2.071932714472535

Epoch: 6| Step: 9
Training loss: 2.627683162689209
Validation loss: 2.0704445723564393

Epoch: 6| Step: 10
Training loss: 2.4101028442382812
Validation loss: 2.0804642105615265

Epoch: 6| Step: 11
Training loss: 2.1799159049987793
Validation loss: 2.0945803632018385

Epoch: 6| Step: 12
Training loss: 1.604952096939087
Validation loss: 2.111462595642254

Epoch: 6| Step: 13
Training loss: 1.543088436126709
Validation loss: 2.127296245226296

Epoch: 74| Step: 0
Training loss: 2.861631393432617
Validation loss: 2.1403374556572206

Epoch: 6| Step: 1
Training loss: 1.9738878011703491
Validation loss: 2.1261626392282467

Epoch: 6| Step: 2
Training loss: 2.286287784576416
Validation loss: 2.1146300069747435

Epoch: 6| Step: 3
Training loss: 2.253969192504883
Validation loss: 2.098165414666617

Epoch: 6| Step: 4
Training loss: 2.3239548206329346
Validation loss: 2.0750740830616285

Epoch: 6| Step: 5
Training loss: 1.979062557220459
Validation loss: 2.065533027854017

Epoch: 6| Step: 6
Training loss: 2.8572075366973877
Validation loss: 2.0643005883821877

Epoch: 6| Step: 7
Training loss: 2.0597949028015137
Validation loss: 2.0663456737354235

Epoch: 6| Step: 8
Training loss: 2.6112961769104004
Validation loss: 2.0748788541363132

Epoch: 6| Step: 9
Training loss: 3.518979549407959
Validation loss: 2.0946236066920783

Epoch: 6| Step: 10
Training loss: 2.0164082050323486
Validation loss: 2.108823883918024

Epoch: 6| Step: 11
Training loss: 2.005411386489868
Validation loss: 2.128221424677039

Epoch: 6| Step: 12
Training loss: 2.2778544425964355
Validation loss: 2.122421254393875

Epoch: 6| Step: 13
Training loss: 2.3526358604431152
Validation loss: 2.127788319382616

Epoch: 75| Step: 0
Training loss: 1.9258053302764893
Validation loss: 2.131298852223222

Epoch: 6| Step: 1
Training loss: 2.8428421020507812
Validation loss: 2.121607413855932

Epoch: 6| Step: 2
Training loss: 2.334000587463379
Validation loss: 2.1134409237933416

Epoch: 6| Step: 3
Training loss: 3.293221950531006
Validation loss: 2.102784081171918

Epoch: 6| Step: 4
Training loss: 2.094209671020508
Validation loss: 2.098794303914552

Epoch: 6| Step: 5
Training loss: 2.830604314804077
Validation loss: 2.095387061436971

Epoch: 6| Step: 6
Training loss: 1.9253761768341064
Validation loss: 2.0977974604534846

Epoch: 6| Step: 7
Training loss: 2.796515941619873
Validation loss: 2.102788109933176

Epoch: 6| Step: 8
Training loss: 1.8430720567703247
Validation loss: 2.093983542534613

Epoch: 6| Step: 9
Training loss: 1.8081157207489014
Validation loss: 2.0844481081090946

Epoch: 6| Step: 10
Training loss: 2.5933823585510254
Validation loss: 2.0945170925509546

Epoch: 6| Step: 11
Training loss: 2.2573981285095215
Validation loss: 2.084874777383702

Epoch: 6| Step: 12
Training loss: 2.2251505851745605
Validation loss: 2.082319527544001

Epoch: 6| Step: 13
Training loss: 2.323418140411377
Validation loss: 2.0662113876752954

Epoch: 76| Step: 0
Training loss: 2.6977291107177734
Validation loss: 2.055642927846601

Epoch: 6| Step: 1
Training loss: 2.4196228981018066
Validation loss: 2.0550702489832395

Epoch: 6| Step: 2
Training loss: 2.1858391761779785
Validation loss: 2.063297708829244

Epoch: 6| Step: 3
Training loss: 2.848052740097046
Validation loss: 2.0860608277782315

Epoch: 6| Step: 4
Training loss: 1.9232914447784424
Validation loss: 2.0947190869239067

Epoch: 6| Step: 5
Training loss: 2.6394684314727783
Validation loss: 2.0946689010948263

Epoch: 6| Step: 6
Training loss: 2.0431113243103027
Validation loss: 2.079136292139689

Epoch: 6| Step: 7
Training loss: 2.6365699768066406
Validation loss: 2.056853325136246

Epoch: 6| Step: 8
Training loss: 2.0361990928649902
Validation loss: 2.044668407850368

Epoch: 6| Step: 9
Training loss: 2.7597146034240723
Validation loss: 2.05460782717633

Epoch: 6| Step: 10
Training loss: 2.5842344760894775
Validation loss: 2.061533513889518

Epoch: 6| Step: 11
Training loss: 1.6155186891555786
Validation loss: 2.0609051091696626

Epoch: 6| Step: 12
Training loss: 2.4730358123779297
Validation loss: 2.0533998448361634

Epoch: 6| Step: 13
Training loss: 2.4655611515045166
Validation loss: 2.0471391088219097

Epoch: 77| Step: 0
Training loss: 3.0060715675354004
Validation loss: 2.079306394823136

Epoch: 6| Step: 1
Training loss: 1.9668458700180054
Validation loss: 2.1164727800635883

Epoch: 6| Step: 2
Training loss: 2.3190908432006836
Validation loss: 2.1474913653507026

Epoch: 6| Step: 3
Training loss: 1.9797680377960205
Validation loss: 2.148704526244953

Epoch: 6| Step: 4
Training loss: 1.1493254899978638
Validation loss: 2.1317240832954325

Epoch: 6| Step: 5
Training loss: 2.5622718334198
Validation loss: 2.0905104593564103

Epoch: 6| Step: 6
Training loss: 1.5559117794036865
Validation loss: 2.056071994125202

Epoch: 6| Step: 7
Training loss: 3.1312437057495117
Validation loss: 2.0511563054976927

Epoch: 6| Step: 8
Training loss: 2.3976926803588867
Validation loss: 2.0516602634101786

Epoch: 6| Step: 9
Training loss: 3.0963826179504395
Validation loss: 2.0520971180290304

Epoch: 6| Step: 10
Training loss: 2.8103578090667725
Validation loss: 2.057497347554853

Epoch: 6| Step: 11
Training loss: 2.2534000873565674
Validation loss: 2.054838434342415

Epoch: 6| Step: 12
Training loss: 2.9374022483825684
Validation loss: 2.055446837538032

Epoch: 6| Step: 13
Training loss: 1.9424304962158203
Validation loss: 2.054755605677123

Epoch: 78| Step: 0
Training loss: 2.0493340492248535
Validation loss: 2.055606201130857

Epoch: 6| Step: 1
Training loss: 2.113405227661133
Validation loss: 2.0528499516107703

Epoch: 6| Step: 2
Training loss: 2.6432299613952637
Validation loss: 2.0563008554520144

Epoch: 6| Step: 3
Training loss: 1.9749019145965576
Validation loss: 2.0484793865552513

Epoch: 6| Step: 4
Training loss: 2.3967225551605225
Validation loss: 2.054280073412003

Epoch: 6| Step: 5
Training loss: 2.907945156097412
Validation loss: 2.081339145219454

Epoch: 6| Step: 6
Training loss: 2.032944440841675
Validation loss: 2.0977345717850553

Epoch: 6| Step: 7
Training loss: 1.9949690103530884
Validation loss: 2.117093565643475

Epoch: 6| Step: 8
Training loss: 3.2786800861358643
Validation loss: 2.1183112641816497

Epoch: 6| Step: 9
Training loss: 2.5801286697387695
Validation loss: 2.0966287594969555

Epoch: 6| Step: 10
Training loss: 2.26175594329834
Validation loss: 2.0790048081387758

Epoch: 6| Step: 11
Training loss: 2.3984384536743164
Validation loss: 2.0632927648482786

Epoch: 6| Step: 12
Training loss: 2.3802876472473145
Validation loss: 2.056815201236356

Epoch: 6| Step: 13
Training loss: 1.951295256614685
Validation loss: 2.0557803428301247

Epoch: 79| Step: 0
Training loss: 2.4786243438720703
Validation loss: 2.0503201574407597

Epoch: 6| Step: 1
Training loss: 2.7420406341552734
Validation loss: 2.0429081609172206

Epoch: 6| Step: 2
Training loss: 1.850238561630249
Validation loss: 2.056099332788939

Epoch: 6| Step: 3
Training loss: 1.901542067527771
Validation loss: 2.0518673312279487

Epoch: 6| Step: 4
Training loss: 1.9385676383972168
Validation loss: 2.05113128436509

Epoch: 6| Step: 5
Training loss: 1.859994649887085
Validation loss: 2.0637301168134137

Epoch: 6| Step: 6
Training loss: 2.3658297061920166
Validation loss: 2.0869054614856677

Epoch: 6| Step: 7
Training loss: 2.158402919769287
Validation loss: 2.1073012941627094

Epoch: 6| Step: 8
Training loss: 2.733694076538086
Validation loss: 2.1218224469051568

Epoch: 6| Step: 9
Training loss: 2.669977903366089
Validation loss: 2.1276348534450737

Epoch: 6| Step: 10
Training loss: 2.6941800117492676
Validation loss: 2.132532687597377

Epoch: 6| Step: 11
Training loss: 2.3259308338165283
Validation loss: 2.127996224229054

Epoch: 6| Step: 12
Training loss: 2.50278902053833
Validation loss: 2.1288387583148096

Epoch: 6| Step: 13
Training loss: 2.949812173843384
Validation loss: 2.134882483431088

Epoch: 80| Step: 0
Training loss: 2.369748830795288
Validation loss: 2.141591877065679

Epoch: 6| Step: 1
Training loss: 2.024529457092285
Validation loss: 2.1583444597900554

Epoch: 6| Step: 2
Training loss: 1.991767168045044
Validation loss: 2.151403893706619

Epoch: 6| Step: 3
Training loss: 2.9969570636749268
Validation loss: 2.1398398901826594

Epoch: 6| Step: 4
Training loss: 1.866349220275879
Validation loss: 2.1182198396293064

Epoch: 6| Step: 5
Training loss: 2.759998321533203
Validation loss: 2.1038113153108986

Epoch: 6| Step: 6
Training loss: 2.4183273315429688
Validation loss: 2.0936438934777373

Epoch: 6| Step: 7
Training loss: 2.862335681915283
Validation loss: 2.0939270270768033

Epoch: 6| Step: 8
Training loss: 2.0797646045684814
Validation loss: 2.0973202490037486

Epoch: 6| Step: 9
Training loss: 2.4025495052337646
Validation loss: 2.10147964185284

Epoch: 6| Step: 10
Training loss: 2.294757843017578
Validation loss: 2.105481634857834

Epoch: 6| Step: 11
Training loss: 2.0387401580810547
Validation loss: 2.1019312912417996

Epoch: 6| Step: 12
Training loss: 2.7292919158935547
Validation loss: 2.1116815587525726

Epoch: 6| Step: 13
Training loss: 2.3085575103759766
Validation loss: 2.0884228701232583

Epoch: 81| Step: 0
Training loss: 1.9947891235351562
Validation loss: 2.0746116407455935

Epoch: 6| Step: 1
Training loss: 1.8135558366775513
Validation loss: 2.0851354419544177

Epoch: 6| Step: 2
Training loss: 2.855070114135742
Validation loss: 2.071154898212802

Epoch: 6| Step: 3
Training loss: 2.222571849822998
Validation loss: 2.060338963744461

Epoch: 6| Step: 4
Training loss: 2.2570419311523438
Validation loss: 2.0637636441056446

Epoch: 6| Step: 5
Training loss: 2.517179489135742
Validation loss: 2.0535842859616844

Epoch: 6| Step: 6
Training loss: 2.706719398498535
Validation loss: 2.0370075677030828

Epoch: 6| Step: 7
Training loss: 1.922297716140747
Validation loss: 2.026441838151665

Epoch: 6| Step: 8
Training loss: 2.200117826461792
Validation loss: 2.026755840547623

Epoch: 6| Step: 9
Training loss: 2.8171441555023193
Validation loss: 2.032490425212409

Epoch: 6| Step: 10
Training loss: 2.2896015644073486
Validation loss: 2.0319316887086436

Epoch: 6| Step: 11
Training loss: 2.7631587982177734
Validation loss: 2.0248262266958914

Epoch: 6| Step: 12
Training loss: 2.1074299812316895
Validation loss: 2.026974134547736

Epoch: 6| Step: 13
Training loss: 1.9566476345062256
Validation loss: 2.025682936432541

Epoch: 82| Step: 0
Training loss: 2.025597095489502
Validation loss: 2.0513634168973534

Epoch: 6| Step: 1
Training loss: 2.690197467803955
Validation loss: 2.0883166072189168

Epoch: 6| Step: 2
Training loss: 2.186849594116211
Validation loss: 2.1253697949071086

Epoch: 6| Step: 3
Training loss: 1.9248392581939697
Validation loss: 2.148623812583185

Epoch: 6| Step: 4
Training loss: 2.2257163524627686
Validation loss: 2.1703343622146116

Epoch: 6| Step: 5
Training loss: 1.7778422832489014
Validation loss: 2.1352738565014255

Epoch: 6| Step: 6
Training loss: 2.3228423595428467
Validation loss: 2.1160328080577235

Epoch: 6| Step: 7
Training loss: 2.7370126247406006
Validation loss: 2.0724487202141875

Epoch: 6| Step: 8
Training loss: 2.85623836517334
Validation loss: 2.0486855506896973

Epoch: 6| Step: 9
Training loss: 1.8166239261627197
Validation loss: 2.033045217555056

Epoch: 6| Step: 10
Training loss: 2.6598262786865234
Validation loss: 2.0223756964488695

Epoch: 6| Step: 11
Training loss: 2.4747424125671387
Validation loss: 2.0233301552393104

Epoch: 6| Step: 12
Training loss: 2.0819778442382812
Validation loss: 2.0319321924640286

Epoch: 6| Step: 13
Training loss: 3.2919726371765137
Validation loss: 2.0291216655444075

Epoch: 83| Step: 0
Training loss: 2.247676372528076
Validation loss: 2.031458306056197

Epoch: 6| Step: 1
Training loss: 2.802532434463501
Validation loss: 2.0304420609628

Epoch: 6| Step: 2
Training loss: 2.6187379360198975
Validation loss: 2.0326243741537935

Epoch: 6| Step: 3
Training loss: 2.0995562076568604
Validation loss: 2.0390993318250104

Epoch: 6| Step: 4
Training loss: 1.8020405769348145
Validation loss: 2.0383594843649093

Epoch: 6| Step: 5
Training loss: 2.1174240112304688
Validation loss: 2.0386578139438423

Epoch: 6| Step: 6
Training loss: 2.216905117034912
Validation loss: 2.0350265041474374

Epoch: 6| Step: 7
Training loss: 2.064401865005493
Validation loss: 2.0356126062331663

Epoch: 6| Step: 8
Training loss: 2.4564156532287598
Validation loss: 2.0227877324627292

Epoch: 6| Step: 9
Training loss: 2.9286551475524902
Validation loss: 2.018866779983685

Epoch: 6| Step: 10
Training loss: 2.184055805206299
Validation loss: 2.024185122982148

Epoch: 6| Step: 11
Training loss: 2.1932625770568848
Validation loss: 2.0307239229961107

Epoch: 6| Step: 12
Training loss: 2.069981575012207
Validation loss: 2.0423502691330446

Epoch: 6| Step: 13
Training loss: 2.5669198036193848
Validation loss: 2.0307668127039427

Epoch: 84| Step: 0
Training loss: 2.925394058227539
Validation loss: 2.044057851196617

Epoch: 6| Step: 1
Training loss: 2.0471887588500977
Validation loss: 2.068637514627108

Epoch: 6| Step: 2
Training loss: 2.456244468688965
Validation loss: 2.090369229675621

Epoch: 6| Step: 3
Training loss: 1.9516445398330688
Validation loss: 2.106329592325354

Epoch: 6| Step: 4
Training loss: 2.1718244552612305
Validation loss: 2.1065873599821523

Epoch: 6| Step: 5
Training loss: 2.966610908508301
Validation loss: 2.090402595458492

Epoch: 6| Step: 6
Training loss: 1.5342257022857666
Validation loss: 2.0554504497076875

Epoch: 6| Step: 7
Training loss: 2.075141429901123
Validation loss: 2.036314765612284

Epoch: 6| Step: 8
Training loss: 2.7864718437194824
Validation loss: 2.0224307314042123

Epoch: 6| Step: 9
Training loss: 2.350501775741577
Validation loss: 2.018389917189075

Epoch: 6| Step: 10
Training loss: 1.9663145542144775
Validation loss: 2.022476996144941

Epoch: 6| Step: 11
Training loss: 2.167043924331665
Validation loss: 2.031603446570776

Epoch: 6| Step: 12
Training loss: 2.495450258255005
Validation loss: 2.036609794503899

Epoch: 6| Step: 13
Training loss: 2.8954975605010986
Validation loss: 2.0381711067691928

Epoch: 85| Step: 0
Training loss: 2.023709774017334
Validation loss: 2.0408575483547744

Epoch: 6| Step: 1
Training loss: 1.6356585025787354
Validation loss: 2.035784698301746

Epoch: 6| Step: 2
Training loss: 2.407529830932617
Validation loss: 2.0476426360427693

Epoch: 6| Step: 3
Training loss: 2.611785888671875
Validation loss: 2.0496917155481156

Epoch: 6| Step: 4
Training loss: 3.351494312286377
Validation loss: 2.057376674426499

Epoch: 6| Step: 5
Training loss: 2.251307725906372
Validation loss: 2.071677577111029

Epoch: 6| Step: 6
Training loss: 2.3932926654815674
Validation loss: 2.079336077936234

Epoch: 6| Step: 7
Training loss: 2.2947020530700684
Validation loss: 2.0766088398553992

Epoch: 6| Step: 8
Training loss: 3.0225985050201416
Validation loss: 2.076764296459895

Epoch: 6| Step: 9
Training loss: 1.8247919082641602
Validation loss: 2.090670700996153

Epoch: 6| Step: 10
Training loss: 2.159938097000122
Validation loss: 2.0818426173220397

Epoch: 6| Step: 11
Training loss: 1.9886195659637451
Validation loss: 2.0762573980516

Epoch: 6| Step: 12
Training loss: 2.2684149742126465
Validation loss: 2.062611900350099

Epoch: 6| Step: 13
Training loss: 1.5892386436462402
Validation loss: 2.0396156669944845

Epoch: 86| Step: 0
Training loss: 2.0560245513916016
Validation loss: 2.050653124368319

Epoch: 6| Step: 1
Training loss: 2.53098726272583
Validation loss: 2.05444977360387

Epoch: 6| Step: 2
Training loss: 2.4055967330932617
Validation loss: 2.0641043468188216

Epoch: 6| Step: 3
Training loss: 1.4587937593460083
Validation loss: 2.0591526159676175

Epoch: 6| Step: 4
Training loss: 2.83255672454834
Validation loss: 2.0461643242066905

Epoch: 6| Step: 5
Training loss: 2.4944911003112793
Validation loss: 2.0279845473586873

Epoch: 6| Step: 6
Training loss: 2.270411491394043
Validation loss: 2.025160256252494

Epoch: 6| Step: 7
Training loss: 1.4622870683670044
Validation loss: 2.0222840539870726

Epoch: 6| Step: 8
Training loss: 2.288262367248535
Validation loss: 2.0328934449021534

Epoch: 6| Step: 9
Training loss: 2.1434621810913086
Validation loss: 2.0849341525826404

Epoch: 6| Step: 10
Training loss: 2.2564730644226074
Validation loss: 2.133282370464776

Epoch: 6| Step: 11
Training loss: 2.587717056274414
Validation loss: 2.1282791578641502

Epoch: 6| Step: 12
Training loss: 3.1853115558624268
Validation loss: 2.1012826632427912

Epoch: 6| Step: 13
Training loss: 2.103010892868042
Validation loss: 2.063772852702807

Epoch: 87| Step: 0
Training loss: 1.951264500617981
Validation loss: 2.0414048523031254

Epoch: 6| Step: 1
Training loss: 2.277829170227051
Validation loss: 2.0169190911836523

Epoch: 6| Step: 2
Training loss: 2.4745430946350098
Validation loss: 1.9986251105544388

Epoch: 6| Step: 3
Training loss: 2.489820957183838
Validation loss: 1.99914595132233

Epoch: 6| Step: 4
Training loss: 2.483276844024658
Validation loss: 1.9978296731107978

Epoch: 6| Step: 5
Training loss: 2.0567681789398193
Validation loss: 1.99854459557482

Epoch: 6| Step: 6
Training loss: 2.7758285999298096
Validation loss: 2.003437549837174

Epoch: 6| Step: 7
Training loss: 1.8091347217559814
Validation loss: 1.9991320256263978

Epoch: 6| Step: 8
Training loss: 2.400275707244873
Validation loss: 1.9977177394333707

Epoch: 6| Step: 9
Training loss: 1.6565163135528564
Validation loss: 2.00348598213606

Epoch: 6| Step: 10
Training loss: 2.6403098106384277
Validation loss: 2.0161163409550986

Epoch: 6| Step: 11
Training loss: 2.5278236865997314
Validation loss: 2.02636642097145

Epoch: 6| Step: 12
Training loss: 2.0822439193725586
Validation loss: 2.0439539391507386

Epoch: 6| Step: 13
Training loss: 2.3743319511413574
Validation loss: 2.0613631868875153

Epoch: 88| Step: 0
Training loss: 2.5678136348724365
Validation loss: 2.0969892419794554

Epoch: 6| Step: 1
Training loss: 2.668459415435791
Validation loss: 2.115044137483002

Epoch: 6| Step: 2
Training loss: 1.9557900428771973
Validation loss: 2.1434868689506286

Epoch: 6| Step: 3
Training loss: 2.4887335300445557
Validation loss: 2.1792124676448044

Epoch: 6| Step: 4
Training loss: 2.196873426437378
Validation loss: 2.1810681345642253

Epoch: 6| Step: 5
Training loss: 1.7851052284240723
Validation loss: 2.159294136108891

Epoch: 6| Step: 6
Training loss: 2.251951217651367
Validation loss: 2.1302488106553272

Epoch: 6| Step: 7
Training loss: 2.5867786407470703
Validation loss: 2.1089270166171494

Epoch: 6| Step: 8
Training loss: 1.9692749977111816
Validation loss: 2.0780045370901785

Epoch: 6| Step: 9
Training loss: 2.308900833129883
Validation loss: 2.071117103740733

Epoch: 6| Step: 10
Training loss: 1.890056848526001
Validation loss: 2.0503670643734675

Epoch: 6| Step: 11
Training loss: 3.0476112365722656
Validation loss: 2.0387287293711016

Epoch: 6| Step: 12
Training loss: 2.9012088775634766
Validation loss: 2.0463049950138217

Epoch: 6| Step: 13
Training loss: 1.3403818607330322
Validation loss: 2.0382215105077273

Epoch: 89| Step: 0
Training loss: 2.879352331161499
Validation loss: 2.0255502744387557

Epoch: 6| Step: 1
Training loss: 1.80806303024292
Validation loss: 2.0254329532705326

Epoch: 6| Step: 2
Training loss: 2.493633270263672
Validation loss: 2.0153158646757885

Epoch: 6| Step: 3
Training loss: 1.6130882501602173
Validation loss: 2.064736348326488

Epoch: 6| Step: 4
Training loss: 2.908527374267578
Validation loss: 2.06763578871245

Epoch: 6| Step: 5
Training loss: 2.5131092071533203
Validation loss: 2.0467673847752232

Epoch: 6| Step: 6
Training loss: 1.8893308639526367
Validation loss: 2.039922773197133

Epoch: 6| Step: 7
Training loss: 2.653170108795166
Validation loss: 2.0220593290944255

Epoch: 6| Step: 8
Training loss: 2.01389741897583
Validation loss: 2.023079108166438

Epoch: 6| Step: 9
Training loss: 2.0095956325531006
Validation loss: 2.0491814139068767

Epoch: 6| Step: 10
Training loss: 2.19315505027771
Validation loss: 2.0668082288516465

Epoch: 6| Step: 11
Training loss: 2.9553942680358887
Validation loss: 2.0705330551311536

Epoch: 6| Step: 12
Training loss: 1.9779255390167236
Validation loss: 2.053739640020555

Epoch: 6| Step: 13
Training loss: 2.200470447540283
Validation loss: 2.0467828589100994

Epoch: 90| Step: 0
Training loss: 2.0124049186706543
Validation loss: 2.031403139073362

Epoch: 6| Step: 1
Training loss: 1.8585628271102905
Validation loss: 2.024392379227505

Epoch: 6| Step: 2
Training loss: 2.9845237731933594
Validation loss: 2.021504489324426

Epoch: 6| Step: 3
Training loss: 1.9369277954101562
Validation loss: 2.0179523985872985

Epoch: 6| Step: 4
Training loss: 1.980336308479309
Validation loss: 2.0230505005005868

Epoch: 6| Step: 5
Training loss: 2.2992119789123535
Validation loss: 2.027135952826469

Epoch: 6| Step: 6
Training loss: 2.4632251262664795
Validation loss: 2.033324738984467

Epoch: 6| Step: 7
Training loss: 1.6915208101272583
Validation loss: 2.0465240888698126

Epoch: 6| Step: 8
Training loss: 2.646307945251465
Validation loss: 2.051606398756786

Epoch: 6| Step: 9
Training loss: 2.0147218704223633
Validation loss: 2.0464311402331115

Epoch: 6| Step: 10
Training loss: 1.9402053356170654
Validation loss: 2.0475974646947717

Epoch: 6| Step: 11
Training loss: 2.5165765285491943
Validation loss: 2.018802696658719

Epoch: 6| Step: 12
Training loss: 2.5780396461486816
Validation loss: 2.018136949949367

Epoch: 6| Step: 13
Training loss: 2.5672812461853027
Validation loss: 2.0148914514049405

Epoch: 91| Step: 0
Training loss: 2.8661510944366455
Validation loss: 2.02047360456118

Epoch: 6| Step: 1
Training loss: 2.396838426589966
Validation loss: 2.041649572310909

Epoch: 6| Step: 2
Training loss: 2.5978288650512695
Validation loss: 2.027992033189343

Epoch: 6| Step: 3
Training loss: 1.5677528381347656
Validation loss: 2.034575193159042

Epoch: 6| Step: 4
Training loss: 2.8328022956848145
Validation loss: 2.0403235804650093

Epoch: 6| Step: 5
Training loss: 1.8561737537384033
Validation loss: 2.0625530442883893

Epoch: 6| Step: 6
Training loss: 1.6466114521026611
Validation loss: 2.074617667864728

Epoch: 6| Step: 7
Training loss: 2.01727294921875
Validation loss: 2.0698184351767264

Epoch: 6| Step: 8
Training loss: 2.1062397956848145
Validation loss: 2.039877281394056

Epoch: 6| Step: 9
Training loss: 2.0841031074523926
Validation loss: 2.0079794801691526

Epoch: 6| Step: 10
Training loss: 2.4916257858276367
Validation loss: 1.9963831299094743

Epoch: 6| Step: 11
Training loss: 2.6519036293029785
Validation loss: 1.996512306633816

Epoch: 6| Step: 12
Training loss: 1.9541914463043213
Validation loss: 2.0013291912694133

Epoch: 6| Step: 13
Training loss: 2.17950177192688
Validation loss: 1.9960965430864723

Epoch: 92| Step: 0
Training loss: 2.825448513031006
Validation loss: 1.992630092046594

Epoch: 6| Step: 1
Training loss: 2.3123817443847656
Validation loss: 2.003301715338102

Epoch: 6| Step: 2
Training loss: 3.3739380836486816
Validation loss: 2.02200851901885

Epoch: 6| Step: 3
Training loss: 2.5301575660705566
Validation loss: 2.041983558285621

Epoch: 6| Step: 4
Training loss: 1.8377249240875244
Validation loss: 2.0592364649618826

Epoch: 6| Step: 5
Training loss: 2.212709426879883
Validation loss: 2.0700051720424364

Epoch: 6| Step: 6
Training loss: 1.915374755859375
Validation loss: 2.0571402131870227

Epoch: 6| Step: 7
Training loss: 2.041292667388916
Validation loss: 2.0141950986718618

Epoch: 6| Step: 8
Training loss: 1.8255183696746826
Validation loss: 1.9928053040658273

Epoch: 6| Step: 9
Training loss: 1.8333287239074707
Validation loss: 1.9851494194358907

Epoch: 6| Step: 10
Training loss: 1.9809300899505615
Validation loss: 1.9752164002387755

Epoch: 6| Step: 11
Training loss: 1.801504135131836
Validation loss: 1.9785007738297986

Epoch: 6| Step: 12
Training loss: 2.0071182250976562
Validation loss: 1.9784804172413324

Epoch: 6| Step: 13
Training loss: 2.912966728210449
Validation loss: 1.9737842211159327

Epoch: 93| Step: 0
Training loss: 2.573493719100952
Validation loss: 1.9793053826978129

Epoch: 6| Step: 1
Training loss: 1.7138614654541016
Validation loss: 1.9908883879261632

Epoch: 6| Step: 2
Training loss: 2.1009180545806885
Validation loss: 2.000567400327293

Epoch: 6| Step: 3
Training loss: 1.503567099571228
Validation loss: 2.0068365194464244

Epoch: 6| Step: 4
Training loss: 1.7023762464523315
Validation loss: 2.0228164631833314

Epoch: 6| Step: 5
Training loss: 3.1619410514831543
Validation loss: 2.0206772127459125

Epoch: 6| Step: 6
Training loss: 1.8602633476257324
Validation loss: 2.0183713179762646

Epoch: 6| Step: 7
Training loss: 2.789705276489258
Validation loss: 2.016554376130463

Epoch: 6| Step: 8
Training loss: 2.4097368717193604
Validation loss: 2.0200656588359545

Epoch: 6| Step: 9
Training loss: 2.474491834640503
Validation loss: 2.038636335762598

Epoch: 6| Step: 10
Training loss: 1.6234623193740845
Validation loss: 2.057439798949867

Epoch: 6| Step: 11
Training loss: 2.307837963104248
Validation loss: 2.070191953771858

Epoch: 6| Step: 12
Training loss: 2.3898990154266357
Validation loss: 2.0636813127866356

Epoch: 6| Step: 13
Training loss: 1.9510010480880737
Validation loss: 2.0517659956409084

Epoch: 94| Step: 0
Training loss: 1.6758766174316406
Validation loss: 2.0280754002191688

Epoch: 6| Step: 1
Training loss: 1.863095998764038
Validation loss: 2.0290099164491058

Epoch: 6| Step: 2
Training loss: 2.1193933486938477
Validation loss: 2.0508299745539182

Epoch: 6| Step: 3
Training loss: 2.557830333709717
Validation loss: 2.040697246469477

Epoch: 6| Step: 4
Training loss: 1.5800660848617554
Validation loss: 2.0406566819837018

Epoch: 6| Step: 5
Training loss: 1.9631038904190063
Validation loss: 2.041459750103694

Epoch: 6| Step: 6
Training loss: 2.388542652130127
Validation loss: 2.0427186425014208

Epoch: 6| Step: 7
Training loss: 2.717965841293335
Validation loss: 2.0449939158654984

Epoch: 6| Step: 8
Training loss: 3.3546924591064453
Validation loss: 2.0438258724827922

Epoch: 6| Step: 9
Training loss: 1.9865472316741943
Validation loss: 2.035251845595657

Epoch: 6| Step: 10
Training loss: 2.3737878799438477
Validation loss: 2.0437351657498266

Epoch: 6| Step: 11
Training loss: 2.3727948665618896
Validation loss: 2.0408535016480314

Epoch: 6| Step: 12
Training loss: 2.721877098083496
Validation loss: 2.027295263864661

Epoch: 6| Step: 13
Training loss: 1.249540090560913
Validation loss: 2.010327535290872

Epoch: 95| Step: 0
Training loss: 2.0644125938415527
Validation loss: 1.9758670612048077

Epoch: 6| Step: 1
Training loss: 2.2067956924438477
Validation loss: 1.9699759124427714

Epoch: 6| Step: 2
Training loss: 2.544497489929199
Validation loss: 1.9644390293346938

Epoch: 6| Step: 3
Training loss: 1.872693657875061
Validation loss: 1.965730946551087

Epoch: 6| Step: 4
Training loss: 2.2541937828063965
Validation loss: 1.9651661816463675

Epoch: 6| Step: 5
Training loss: 2.0154366493225098
Validation loss: 1.9881630328393751

Epoch: 6| Step: 6
Training loss: 2.0323479175567627
Validation loss: 1.9989392962507022

Epoch: 6| Step: 7
Training loss: 1.9150826930999756
Validation loss: 2.006883046960318

Epoch: 6| Step: 8
Training loss: 2.715883255004883
Validation loss: 2.015547038406454

Epoch: 6| Step: 9
Training loss: 1.6547918319702148
Validation loss: 2.0043316553997736

Epoch: 6| Step: 10
Training loss: 2.4197070598602295
Validation loss: 2.011663383053195

Epoch: 6| Step: 11
Training loss: 2.376232147216797
Validation loss: 2.0347093356552945

Epoch: 6| Step: 12
Training loss: 2.4307098388671875
Validation loss: 2.043522564313745

Epoch: 6| Step: 13
Training loss: 2.4026880264282227
Validation loss: 2.0196244716644287

Epoch: 96| Step: 0
Training loss: 1.722426176071167
Validation loss: 2.007137934366862

Epoch: 6| Step: 1
Training loss: 2.315103054046631
Validation loss: 2.0163899980565554

Epoch: 6| Step: 2
Training loss: 2.008694887161255
Validation loss: 2.0455180906480357

Epoch: 6| Step: 3
Training loss: 2.110645294189453
Validation loss: 2.028773348818543

Epoch: 6| Step: 4
Training loss: 1.7586748600006104
Validation loss: 2.035218543903802

Epoch: 6| Step: 5
Training loss: 3.1920723915100098
Validation loss: 2.051081604855035

Epoch: 6| Step: 6
Training loss: 2.4193577766418457
Validation loss: 2.061072503366778

Epoch: 6| Step: 7
Training loss: 2.1609725952148438
Validation loss: 2.0588706654887043

Epoch: 6| Step: 8
Training loss: 2.366602897644043
Validation loss: 2.0453921825655046

Epoch: 6| Step: 9
Training loss: 2.3851990699768066
Validation loss: 2.043728427220416

Epoch: 6| Step: 10
Training loss: 2.243506908416748
Validation loss: 2.0182442972736974

Epoch: 6| Step: 11
Training loss: 1.6025886535644531
Validation loss: 2.0203750377060263

Epoch: 6| Step: 12
Training loss: 1.9865787029266357
Validation loss: 1.9929061064156153

Epoch: 6| Step: 13
Training loss: 2.340686321258545
Validation loss: 1.9928146818632722

Epoch: 97| Step: 0
Training loss: 1.441572666168213
Validation loss: 1.9969814233882452

Epoch: 6| Step: 1
Training loss: 2.122333288192749
Validation loss: 1.9959396444341189

Epoch: 6| Step: 2
Training loss: 2.140843391418457
Validation loss: 1.9839656840088546

Epoch: 6| Step: 3
Training loss: 2.499251365661621
Validation loss: 1.984499155834157

Epoch: 6| Step: 4
Training loss: 2.080390453338623
Validation loss: 1.9740390521223827

Epoch: 6| Step: 5
Training loss: 2.7082560062408447
Validation loss: 1.96063264723747

Epoch: 6| Step: 6
Training loss: 1.8837167024612427
Validation loss: 1.9626828598719772

Epoch: 6| Step: 7
Training loss: 2.1486010551452637
Validation loss: 1.9535773928447435

Epoch: 6| Step: 8
Training loss: 2.184211254119873
Validation loss: 1.9510813964310514

Epoch: 6| Step: 9
Training loss: 1.9435131549835205
Validation loss: 1.961537379090504

Epoch: 6| Step: 10
Training loss: 1.6652686595916748
Validation loss: 1.9746823208306425

Epoch: 6| Step: 11
Training loss: 2.752932071685791
Validation loss: 1.9827298066949333

Epoch: 6| Step: 12
Training loss: 3.042022466659546
Validation loss: 1.992153799662026

Epoch: 6| Step: 13
Training loss: 1.497366189956665
Validation loss: 2.0234845915148334

Epoch: 98| Step: 0
Training loss: 2.6055917739868164
Validation loss: 2.048959260345787

Epoch: 6| Step: 1
Training loss: 2.6470274925231934
Validation loss: 2.0572711165233324

Epoch: 6| Step: 2
Training loss: 2.5248970985412598
Validation loss: 2.0439194735660347

Epoch: 6| Step: 3
Training loss: 2.845791816711426
Validation loss: 2.015712832891813

Epoch: 6| Step: 4
Training loss: 1.7405729293823242
Validation loss: 2.0110929704481557

Epoch: 6| Step: 5
Training loss: 1.5857763290405273
Validation loss: 2.0078545847246723

Epoch: 6| Step: 6
Training loss: 2.179659843444824
Validation loss: 1.9997202196428854

Epoch: 6| Step: 7
Training loss: 1.6621816158294678
Validation loss: 1.9936572505581764

Epoch: 6| Step: 8
Training loss: 2.4974865913391113
Validation loss: 1.9925813495471913

Epoch: 6| Step: 9
Training loss: 1.8138198852539062
Validation loss: 2.0016508358781055

Epoch: 6| Step: 10
Training loss: 1.5528197288513184
Validation loss: 2.0283799786721506

Epoch: 6| Step: 11
Training loss: 2.3838205337524414
Validation loss: 2.0685997419459845

Epoch: 6| Step: 12
Training loss: 2.3278067111968994
Validation loss: 2.0971918516261603

Epoch: 6| Step: 13
Training loss: 2.0851809978485107
Validation loss: 2.098285710939797

Epoch: 99| Step: 0
Training loss: 1.9425158500671387
Validation loss: 2.1166734554434337

Epoch: 6| Step: 1
Training loss: 2.2773191928863525
Validation loss: 2.1253752605889433

Epoch: 6| Step: 2
Training loss: 2.396397113800049
Validation loss: 2.094141980653168

Epoch: 6| Step: 3
Training loss: 1.8229838609695435
Validation loss: 2.047500693669883

Epoch: 6| Step: 4
Training loss: 2.309798002243042
Validation loss: 2.0264374927807878

Epoch: 6| Step: 5
Training loss: 2.4290242195129395
Validation loss: 2.019028548271425

Epoch: 6| Step: 6
Training loss: 2.817154884338379
Validation loss: 2.01517399408484

Epoch: 6| Step: 7
Training loss: 2.4917209148406982
Validation loss: 2.036217079367689

Epoch: 6| Step: 8
Training loss: 1.6506450176239014
Validation loss: 2.0477031764163764

Epoch: 6| Step: 9
Training loss: 1.9236763715744019
Validation loss: 2.028842500461045

Epoch: 6| Step: 10
Training loss: 1.5821092128753662
Validation loss: 2.013279959719668

Epoch: 6| Step: 11
Training loss: 2.550372362136841
Validation loss: 2.038337071736654

Epoch: 6| Step: 12
Training loss: 2.255222797393799
Validation loss: 2.0715796844933623

Epoch: 6| Step: 13
Training loss: 2.181011199951172
Validation loss: 2.0983953168315272

Epoch: 100| Step: 0
Training loss: 2.0024971961975098
Validation loss: 2.1297903445459183

Epoch: 6| Step: 1
Training loss: 1.6899011135101318
Validation loss: 2.139565183270362

Epoch: 6| Step: 2
Training loss: 1.3991128206253052
Validation loss: 2.1695304096386

Epoch: 6| Step: 3
Training loss: 2.63649320602417
Validation loss: 2.1377264504791587

Epoch: 6| Step: 4
Training loss: 2.5586538314819336
Validation loss: 2.0927788442181003

Epoch: 6| Step: 5
Training loss: 2.331052303314209
Validation loss: 2.0308659435600362

Epoch: 6| Step: 6
Training loss: 2.0271830558776855
Validation loss: 2.0141453614798923

Epoch: 6| Step: 7
Training loss: 2.1861519813537598
Validation loss: 1.9820043092132897

Epoch: 6| Step: 8
Training loss: 2.359314441680908
Validation loss: 1.9779632604250343

Epoch: 6| Step: 9
Training loss: 1.7289634943008423
Validation loss: 1.9995526703455115

Epoch: 6| Step: 10
Training loss: 2.477494955062866
Validation loss: 2.000321857390865

Epoch: 6| Step: 11
Training loss: 2.766808032989502
Validation loss: 2.014460905905693

Epoch: 6| Step: 12
Training loss: 2.7301902770996094
Validation loss: 2.0065657336224794

Epoch: 6| Step: 13
Training loss: 1.92390775680542
Validation loss: 1.9920708158964753

Epoch: 101| Step: 0
Training loss: 1.9038753509521484
Validation loss: 1.9862397127254035

Epoch: 6| Step: 1
Training loss: 2.2811481952667236
Validation loss: 1.997745806171048

Epoch: 6| Step: 2
Training loss: 2.808760166168213
Validation loss: 2.0145201657408025

Epoch: 6| Step: 3
Training loss: 1.9603090286254883
Validation loss: 2.0211876002691125

Epoch: 6| Step: 4
Training loss: 2.2807583808898926
Validation loss: 2.039500036547261

Epoch: 6| Step: 5
Training loss: 2.4309287071228027
Validation loss: 2.03317323295019

Epoch: 6| Step: 6
Training loss: 1.6231439113616943
Validation loss: 2.0158636518703994

Epoch: 6| Step: 7
Training loss: 2.3375418186187744
Validation loss: 1.9942118275550105

Epoch: 6| Step: 8
Training loss: 2.2255122661590576
Validation loss: 1.9935141058378323

Epoch: 6| Step: 9
Training loss: 3.2794814109802246
Validation loss: 1.984488724380411

Epoch: 6| Step: 10
Training loss: 1.4792824983596802
Validation loss: 1.9913095530643259

Epoch: 6| Step: 11
Training loss: 1.4946597814559937
Validation loss: 1.9954356275578982

Epoch: 6| Step: 12
Training loss: 2.5088019371032715
Validation loss: 2.0213255689990137

Epoch: 6| Step: 13
Training loss: 1.3153332471847534
Validation loss: 2.0144838415166384

Epoch: 102| Step: 0
Training loss: 1.7133862972259521
Validation loss: 2.0112480143065095

Epoch: 6| Step: 1
Training loss: 1.8180783987045288
Validation loss: 1.9909886032022455

Epoch: 6| Step: 2
Training loss: 1.4468441009521484
Validation loss: 1.9782945943135086

Epoch: 6| Step: 3
Training loss: 2.8062031269073486
Validation loss: 1.957392959184544

Epoch: 6| Step: 4
Training loss: 2.744366407394409
Validation loss: 1.9508465515669955

Epoch: 6| Step: 5
Training loss: 1.9046083688735962
Validation loss: 1.9821881965924335

Epoch: 6| Step: 6
Training loss: 2.6626720428466797
Validation loss: 2.006166151774827

Epoch: 6| Step: 7
Training loss: 2.2015490531921387
Validation loss: 1.9952570469148698

Epoch: 6| Step: 8
Training loss: 2.3217415809631348
Validation loss: 1.9927454610024729

Epoch: 6| Step: 9
Training loss: 2.306478261947632
Validation loss: 2.0060254117493987

Epoch: 6| Step: 10
Training loss: 2.0610463619232178
Validation loss: 2.0336162146701606

Epoch: 6| Step: 11
Training loss: 1.9159691333770752
Validation loss: 2.059491503623224

Epoch: 6| Step: 12
Training loss: 2.177239418029785
Validation loss: 2.059868179341798

Epoch: 6| Step: 13
Training loss: 1.8840124607086182
Validation loss: 2.0847748594899334

Epoch: 103| Step: 0
Training loss: 1.5762288570404053
Validation loss: 2.109652708935481

Epoch: 6| Step: 1
Training loss: 2.212817668914795
Validation loss: 2.0818364927845616

Epoch: 6| Step: 2
Training loss: 2.2304184436798096
Validation loss: 2.0664103902796263

Epoch: 6| Step: 3
Training loss: 1.3842861652374268
Validation loss: 2.0370331259183985

Epoch: 6| Step: 4
Training loss: 2.7652230262756348
Validation loss: 2.0353735505893664

Epoch: 6| Step: 5
Training loss: 2.557948112487793
Validation loss: 2.047756980824214

Epoch: 6| Step: 6
Training loss: 2.6761221885681152
Validation loss: 2.049832287655082

Epoch: 6| Step: 7
Training loss: 2.4061074256896973
Validation loss: 2.0620599639031196

Epoch: 6| Step: 8
Training loss: 2.1723411083221436
Validation loss: 2.0383995963681127

Epoch: 6| Step: 9
Training loss: 1.6721986532211304
Validation loss: 2.002048474486156

Epoch: 6| Step: 10
Training loss: 2.88706636428833
Validation loss: 2.0013984762212282

Epoch: 6| Step: 11
Training loss: 1.8636080026626587
Validation loss: 2.016481937900666

Epoch: 6| Step: 12
Training loss: 1.8246442079544067
Validation loss: 2.018882016981802

Epoch: 6| Step: 13
Training loss: 1.8941311836242676
Validation loss: 2.0382014231015275

Epoch: 104| Step: 0
Training loss: 2.4972031116485596
Validation loss: 2.042337474002633

Epoch: 6| Step: 1
Training loss: 2.047520637512207
Validation loss: 2.0442485706780547

Epoch: 6| Step: 2
Training loss: 1.629629373550415
Validation loss: 2.03329832835864

Epoch: 6| Step: 3
Training loss: 2.7986221313476562
Validation loss: 2.0108384778422694

Epoch: 6| Step: 4
Training loss: 1.5906412601470947
Validation loss: 2.0098450927324194

Epoch: 6| Step: 5
Training loss: 2.098491668701172
Validation loss: 2.013893042841265

Epoch: 6| Step: 6
Training loss: 2.222416400909424
Validation loss: 2.0068861669109714

Epoch: 6| Step: 7
Training loss: 2.1057825088500977
Validation loss: 2.0184422603217502

Epoch: 6| Step: 8
Training loss: 2.4053680896759033
Validation loss: 2.0182803189882668

Epoch: 6| Step: 9
Training loss: 2.30308198928833
Validation loss: 2.0167437650824107

Epoch: 6| Step: 10
Training loss: 1.9633729457855225
Validation loss: 2.0150093211922595

Epoch: 6| Step: 11
Training loss: 2.243802070617676
Validation loss: 1.9938859196119412

Epoch: 6| Step: 12
Training loss: 1.8783085346221924
Validation loss: 1.9776120339670489

Epoch: 6| Step: 13
Training loss: 1.9080647230148315
Validation loss: 1.9733957282958492

Epoch: 105| Step: 0
Training loss: 2.1155285835266113
Validation loss: 1.9679496390845186

Epoch: 6| Step: 1
Training loss: 2.214439868927002
Validation loss: 1.9721397892121346

Epoch: 6| Step: 2
Training loss: 2.421635627746582
Validation loss: 1.9757271351352814

Epoch: 6| Step: 3
Training loss: 2.461239814758301
Validation loss: 1.9899896370467318

Epoch: 6| Step: 4
Training loss: 2.1757078170776367
Validation loss: 1.9797338093480756

Epoch: 6| Step: 5
Training loss: 1.8473408222198486
Validation loss: 1.9884811550058343

Epoch: 6| Step: 6
Training loss: 2.3884620666503906
Validation loss: 1.9945433819165794

Epoch: 6| Step: 7
Training loss: 2.131293773651123
Validation loss: 1.9795032624275453

Epoch: 6| Step: 8
Training loss: 1.5265955924987793
Validation loss: 1.9935622548544278

Epoch: 6| Step: 9
Training loss: 1.8887829780578613
Validation loss: 2.0055370715356644

Epoch: 6| Step: 10
Training loss: 2.1333489418029785
Validation loss: 2.0411821334592757

Epoch: 6| Step: 11
Training loss: 1.7623839378356934
Validation loss: 2.055916206811064

Epoch: 6| Step: 12
Training loss: 2.394752264022827
Validation loss: 2.0672377296673354

Epoch: 6| Step: 13
Training loss: 1.849000334739685
Validation loss: 2.0312710679987425

Epoch: 106| Step: 0
Training loss: 2.358146905899048
Validation loss: 2.008575518925985

Epoch: 6| Step: 1
Training loss: 2.5880472660064697
Validation loss: 1.9868694607929518

Epoch: 6| Step: 2
Training loss: 1.560799479484558
Validation loss: 1.9865207210663827

Epoch: 6| Step: 3
Training loss: 2.346951484680176
Validation loss: 1.9935679205002323

Epoch: 6| Step: 4
Training loss: 1.8842517137527466
Validation loss: 1.9887575308481853

Epoch: 6| Step: 5
Training loss: 1.7136815786361694
Validation loss: 1.995267370695709

Epoch: 6| Step: 6
Training loss: 2.317257881164551
Validation loss: 1.9945963941594607

Epoch: 6| Step: 7
Training loss: 2.6482932567596436
Validation loss: 1.9918449232655187

Epoch: 6| Step: 8
Training loss: 1.9339356422424316
Validation loss: 1.9948473233048634

Epoch: 6| Step: 9
Training loss: 1.420008659362793
Validation loss: 1.991911284385189

Epoch: 6| Step: 10
Training loss: 1.9875109195709229
Validation loss: 1.989433991011753

Epoch: 6| Step: 11
Training loss: 1.6789838075637817
Validation loss: 1.9914488151509275

Epoch: 6| Step: 12
Training loss: 2.5983424186706543
Validation loss: 2.003459240800591

Epoch: 6| Step: 13
Training loss: 1.7171692848205566
Validation loss: 2.0175809962775118

Epoch: 107| Step: 0
Training loss: 1.586991786956787
Validation loss: 2.0207600952476583

Epoch: 6| Step: 1
Training loss: 2.4265995025634766
Validation loss: 2.034175160110638

Epoch: 6| Step: 2
Training loss: 1.864476203918457
Validation loss: 2.037096808033605

Epoch: 6| Step: 3
Training loss: 1.851930856704712
Validation loss: 2.047267137035247

Epoch: 6| Step: 4
Training loss: 2.1504902839660645
Validation loss: 2.04937917699096

Epoch: 6| Step: 5
Training loss: 2.0405821800231934
Validation loss: 2.0517575997178272

Epoch: 6| Step: 6
Training loss: 2.5615615844726562
Validation loss: 2.0648874775055917

Epoch: 6| Step: 7
Training loss: 1.9725651741027832
Validation loss: 2.064970185679774

Epoch: 6| Step: 8
Training loss: 2.3448410034179688
Validation loss: 2.0758357240307714

Epoch: 6| Step: 9
Training loss: 1.7390618324279785
Validation loss: 2.0903946686816472

Epoch: 6| Step: 10
Training loss: 2.149156093597412
Validation loss: 2.07255115560306

Epoch: 6| Step: 11
Training loss: 2.2121477127075195
Validation loss: 2.069411746917232

Epoch: 6| Step: 12
Training loss: 1.922417402267456
Validation loss: 2.0434324972091185

Epoch: 6| Step: 13
Training loss: 2.406191825866699
Validation loss: 2.019489630576103

Epoch: 108| Step: 0
Training loss: 2.333740472793579
Validation loss: 2.0115869404167257

Epoch: 6| Step: 1
Training loss: 1.6729568243026733
Validation loss: 2.0094180171207716

Epoch: 6| Step: 2
Training loss: 2.1182973384857178
Validation loss: 2.0002467170838387

Epoch: 6| Step: 3
Training loss: 2.698011875152588
Validation loss: 1.986095836085658

Epoch: 6| Step: 4
Training loss: 2.3955953121185303
Validation loss: 1.9750778444351689

Epoch: 6| Step: 5
Training loss: 1.2973577976226807
Validation loss: 1.965783126892582

Epoch: 6| Step: 6
Training loss: 1.619394063949585
Validation loss: 1.9598384903323265

Epoch: 6| Step: 7
Training loss: 2.357640504837036
Validation loss: 1.978019691282703

Epoch: 6| Step: 8
Training loss: 2.5263943672180176
Validation loss: 1.9853031430193173

Epoch: 6| Step: 9
Training loss: 1.8497838973999023
Validation loss: 1.9893785907376198

Epoch: 6| Step: 10
Training loss: 2.575969696044922
Validation loss: 2.0006066342835784

Epoch: 6| Step: 11
Training loss: 1.533656120300293
Validation loss: 1.9959994567337858

Epoch: 6| Step: 12
Training loss: 1.8543696403503418
Validation loss: 2.0113646471372215

Epoch: 6| Step: 13
Training loss: 2.2542662620544434
Validation loss: 2.0113240967514696

Epoch: 109| Step: 0
Training loss: 2.252683639526367
Validation loss: 1.996847855147495

Epoch: 6| Step: 1
Training loss: 2.4067270755767822
Validation loss: 1.9983200027096657

Epoch: 6| Step: 2
Training loss: 1.813795804977417
Validation loss: 2.0201617620324575

Epoch: 6| Step: 3
Training loss: 2.056807279586792
Validation loss: 2.0413319013452016

Epoch: 6| Step: 4
Training loss: 1.947664737701416
Validation loss: 2.050531333492648

Epoch: 6| Step: 5
Training loss: 1.963459849357605
Validation loss: 2.0286623790699947

Epoch: 6| Step: 6
Training loss: 2.3403637409210205
Validation loss: 2.0408586417475054

Epoch: 6| Step: 7
Training loss: 2.064884901046753
Validation loss: 2.053846300289195

Epoch: 6| Step: 8
Training loss: 2.128521203994751
Validation loss: 2.0964030886209137

Epoch: 6| Step: 9
Training loss: 2.1226367950439453
Validation loss: 2.1125922767064904

Epoch: 6| Step: 10
Training loss: 1.4322047233581543
Validation loss: 2.0994267873866583

Epoch: 6| Step: 11
Training loss: 1.76902174949646
Validation loss: 2.0472822984059653

Epoch: 6| Step: 12
Training loss: 2.4217238426208496
Validation loss: 2.0092970889101744

Epoch: 6| Step: 13
Training loss: 2.8504819869995117
Validation loss: 2.0093875828609673

Epoch: 110| Step: 0
Training loss: 2.280588388442993
Validation loss: 2.018842666379867

Epoch: 6| Step: 1
Training loss: 2.0299439430236816
Validation loss: 2.011738077286751

Epoch: 6| Step: 2
Training loss: 1.2627233266830444
Validation loss: 1.9913769691221175

Epoch: 6| Step: 3
Training loss: 2.3093624114990234
Validation loss: 1.9782154688271143

Epoch: 6| Step: 4
Training loss: 1.7885857820510864
Validation loss: 1.9678752896606282

Epoch: 6| Step: 5
Training loss: 2.115584373474121
Validation loss: 1.9684118506728963

Epoch: 6| Step: 6
Training loss: 1.6112459897994995
Validation loss: 1.9851182135202552

Epoch: 6| Step: 7
Training loss: 2.380692958831787
Validation loss: 1.9856081380639026

Epoch: 6| Step: 8
Training loss: 1.8937172889709473
Validation loss: 1.9993054277153426

Epoch: 6| Step: 9
Training loss: 2.042212963104248
Validation loss: 2.0125918901094826

Epoch: 6| Step: 10
Training loss: 1.964665174484253
Validation loss: 2.0220675878627326

Epoch: 6| Step: 11
Training loss: 2.627286195755005
Validation loss: 2.0367987220005324

Epoch: 6| Step: 12
Training loss: 2.1686673164367676
Validation loss: 2.050051035419587

Epoch: 6| Step: 13
Training loss: 2.7476625442504883
Validation loss: 2.0836671552350445

Epoch: 111| Step: 0
Training loss: 1.2584556341171265
Validation loss: 2.0729385601576937

Epoch: 6| Step: 1
Training loss: 2.4854559898376465
Validation loss: 2.0777698447627406

Epoch: 6| Step: 2
Training loss: 2.099923610687256
Validation loss: 2.0862859346533336

Epoch: 6| Step: 3
Training loss: 2.3453195095062256
Validation loss: 2.0716699143891693

Epoch: 6| Step: 4
Training loss: 1.7510221004486084
Validation loss: 2.074055576837191

Epoch: 6| Step: 5
Training loss: 1.7420530319213867
Validation loss: 2.0568681506700415

Epoch: 6| Step: 6
Training loss: 2.534038543701172
Validation loss: 2.0592760552642164

Epoch: 6| Step: 7
Training loss: 2.4598724842071533
Validation loss: 2.047899232115797

Epoch: 6| Step: 8
Training loss: 2.6989691257476807
Validation loss: 2.0383379074835006

Epoch: 6| Step: 9
Training loss: 1.9770042896270752
Validation loss: 2.0200534482156076

Epoch: 6| Step: 10
Training loss: 1.9734002351760864
Validation loss: 2.0072778142908567

Epoch: 6| Step: 11
Training loss: 1.5158042907714844
Validation loss: 1.9920556929803663

Epoch: 6| Step: 12
Training loss: 1.5736124515533447
Validation loss: 1.975763408086633

Epoch: 6| Step: 13
Training loss: 2.6624298095703125
Validation loss: 1.9597373201001076

Epoch: 112| Step: 0
Training loss: 1.0035990476608276
Validation loss: 1.9759346823538504

Epoch: 6| Step: 1
Training loss: 2.3049540519714355
Validation loss: 1.9870290499861523

Epoch: 6| Step: 2
Training loss: 2.3891398906707764
Validation loss: 1.9737830546594435

Epoch: 6| Step: 3
Training loss: 2.4042863845825195
Validation loss: 1.9833126850025629

Epoch: 6| Step: 4
Training loss: 1.9271154403686523
Validation loss: 1.9906673610851329

Epoch: 6| Step: 5
Training loss: 2.0285511016845703
Validation loss: 1.980556631600985

Epoch: 6| Step: 6
Training loss: 1.8836557865142822
Validation loss: 1.9776583589533323

Epoch: 6| Step: 7
Training loss: 1.8190971612930298
Validation loss: 1.9840460695246214

Epoch: 6| Step: 8
Training loss: 1.6971782445907593
Validation loss: 1.9949454030682963

Epoch: 6| Step: 9
Training loss: 1.6637547016143799
Validation loss: 1.9943817046380812

Epoch: 6| Step: 10
Training loss: 2.355896472930908
Validation loss: 2.018498833461474

Epoch: 6| Step: 11
Training loss: 2.219913959503174
Validation loss: 2.013769462544431

Epoch: 6| Step: 12
Training loss: 2.561915397644043
Validation loss: 2.012969820730148

Epoch: 6| Step: 13
Training loss: 2.5346250534057617
Validation loss: 2.025330020535377

Epoch: 113| Step: 0
Training loss: 1.6713902950286865
Validation loss: 2.0495973428090415

Epoch: 6| Step: 1
Training loss: 2.042818546295166
Validation loss: 2.054501093843932

Epoch: 6| Step: 2
Training loss: 1.4325793981552124
Validation loss: 2.0303120818189395

Epoch: 6| Step: 3
Training loss: 1.5446665287017822
Validation loss: 2.007748911457677

Epoch: 6| Step: 4
Training loss: 1.8189105987548828
Validation loss: 1.99697244680056

Epoch: 6| Step: 5
Training loss: 2.185004949569702
Validation loss: 1.9888947702223254

Epoch: 6| Step: 6
Training loss: 2.016516923904419
Validation loss: 1.9945399607381513

Epoch: 6| Step: 7
Training loss: 2.4795427322387695
Validation loss: 1.9890197938488376

Epoch: 6| Step: 8
Training loss: 2.333991050720215
Validation loss: 1.9654729135574833

Epoch: 6| Step: 9
Training loss: 2.5292999744415283
Validation loss: 1.9549827011682654

Epoch: 6| Step: 10
Training loss: 1.71675443649292
Validation loss: 1.9744191015920332

Epoch: 6| Step: 11
Training loss: 1.750096321105957
Validation loss: 1.9975378115971882

Epoch: 6| Step: 12
Training loss: 2.4843626022338867
Validation loss: 2.015616492558551

Epoch: 6| Step: 13
Training loss: 3.0110435485839844
Validation loss: 2.0304593475916053

Epoch: 114| Step: 0
Training loss: 2.7008466720581055
Validation loss: 2.0763685216185865

Epoch: 6| Step: 1
Training loss: 2.1696856021881104
Validation loss: 2.0856605729749127

Epoch: 6| Step: 2
Training loss: 2.3216171264648438
Validation loss: 2.111087765744937

Epoch: 6| Step: 3
Training loss: 1.4953620433807373
Validation loss: 2.0877222617467246

Epoch: 6| Step: 4
Training loss: 2.3447163105010986
Validation loss: 2.06837530930837

Epoch: 6| Step: 5
Training loss: 1.7902252674102783
Validation loss: 2.0894239794823433

Epoch: 6| Step: 6
Training loss: 1.563076376914978
Validation loss: 2.1233255376097975

Epoch: 6| Step: 7
Training loss: 1.8412883281707764
Validation loss: 2.14283811917869

Epoch: 6| Step: 8
Training loss: 1.8343820571899414
Validation loss: 2.161840056860319

Epoch: 6| Step: 9
Training loss: 1.661168098449707
Validation loss: 2.171689789782288

Epoch: 6| Step: 10
Training loss: 2.1408438682556152
Validation loss: 2.1668061479445426

Epoch: 6| Step: 11
Training loss: 2.5152511596679688
Validation loss: 2.150485114384723

Epoch: 6| Step: 12
Training loss: 2.4107420444488525
Validation loss: 2.1218299865722656

Epoch: 6| Step: 13
Training loss: 2.595999002456665
Validation loss: 2.0875567095254057

Epoch: 115| Step: 0
Training loss: 2.193286657333374
Validation loss: 2.050777171247749

Epoch: 6| Step: 1
Training loss: 2.717716693878174
Validation loss: 2.0218640001871253

Epoch: 6| Step: 2
Training loss: 1.6950355768203735
Validation loss: 2.009232697948333

Epoch: 6| Step: 3
Training loss: 1.898923397064209
Validation loss: 1.9831346017058178

Epoch: 6| Step: 4
Training loss: 1.4861276149749756
Validation loss: 1.9583578237923243

Epoch: 6| Step: 5
Training loss: 1.7158390283584595
Validation loss: 1.9456567789918633

Epoch: 6| Step: 6
Training loss: 1.4951326847076416
Validation loss: 1.9318743392985354

Epoch: 6| Step: 7
Training loss: 2.1176109313964844
Validation loss: 1.9404754997581564

Epoch: 6| Step: 8
Training loss: 2.6757144927978516
Validation loss: 1.9452730365978774

Epoch: 6| Step: 9
Training loss: 1.3573206663131714
Validation loss: 1.9439023694684427

Epoch: 6| Step: 10
Training loss: 2.4893858432769775
Validation loss: 1.9553111112245949

Epoch: 6| Step: 11
Training loss: 1.8569014072418213
Validation loss: 1.9752388064579298

Epoch: 6| Step: 12
Training loss: 2.5790798664093018
Validation loss: 1.9729398604362243

Epoch: 6| Step: 13
Training loss: 2.075031042098999
Validation loss: 1.9873919512635918

Epoch: 116| Step: 0
Training loss: 2.124199867248535
Validation loss: 1.9865706300222745

Epoch: 6| Step: 1
Training loss: 2.485844612121582
Validation loss: 2.0070336685385755

Epoch: 6| Step: 2
Training loss: 2.0110907554626465
Validation loss: 2.0395841008873394

Epoch: 6| Step: 3
Training loss: 1.9632477760314941
Validation loss: 2.087378578801309

Epoch: 6| Step: 4
Training loss: 1.689941644668579
Validation loss: 2.1429405827676096

Epoch: 6| Step: 5
Training loss: 2.432865858078003
Validation loss: 2.16321663959052

Epoch: 6| Step: 6
Training loss: 1.3976573944091797
Validation loss: 2.195943529887866

Epoch: 6| Step: 7
Training loss: 2.2557554244995117
Validation loss: 2.1434983104787846

Epoch: 6| Step: 8
Training loss: 2.491771697998047
Validation loss: 2.081783189568468

Epoch: 6| Step: 9
Training loss: 2.3674259185791016
Validation loss: 2.0668678052963747

Epoch: 6| Step: 10
Training loss: 2.068530559539795
Validation loss: 2.045215200352412

Epoch: 6| Step: 11
Training loss: 1.8819856643676758
Validation loss: 2.0476796370680614

Epoch: 6| Step: 12
Training loss: 1.7334154844284058
Validation loss: 2.052006329259565

Epoch: 6| Step: 13
Training loss: 1.9590163230895996
Validation loss: 2.024757262199156

Epoch: 117| Step: 0
Training loss: 2.0182762145996094
Validation loss: 2.003555118396718

Epoch: 6| Step: 1
Training loss: 1.3533977270126343
Validation loss: 2.0033747893507763

Epoch: 6| Step: 2
Training loss: 2.1668601036071777
Validation loss: 1.9907165778580533

Epoch: 6| Step: 3
Training loss: 1.7715811729431152
Validation loss: 1.9878063471086564

Epoch: 6| Step: 4
Training loss: 1.585373878479004
Validation loss: 1.9953415124647078

Epoch: 6| Step: 5
Training loss: 2.622673273086548
Validation loss: 2.0103021924213698

Epoch: 6| Step: 6
Training loss: 1.8068616390228271
Validation loss: 2.0072473710583103

Epoch: 6| Step: 7
Training loss: 1.186906099319458
Validation loss: 2.0165652741668043

Epoch: 6| Step: 8
Training loss: 2.4113714694976807
Validation loss: 2.032311636914489

Epoch: 6| Step: 9
Training loss: 2.2930734157562256
Validation loss: 2.043554672630884

Epoch: 6| Step: 10
Training loss: 1.7529792785644531
Validation loss: 2.072076956431071

Epoch: 6| Step: 11
Training loss: 2.126082420349121
Validation loss: 2.097369775977186

Epoch: 6| Step: 12
Training loss: 2.614034414291382
Validation loss: 2.0827211026222474

Epoch: 6| Step: 13
Training loss: 2.383939027786255
Validation loss: 2.0564967278511292

Epoch: 118| Step: 0
Training loss: 1.6858257055282593
Validation loss: 2.035679027598391

Epoch: 6| Step: 1
Training loss: 1.9929604530334473
Validation loss: 2.042013737463182

Epoch: 6| Step: 2
Training loss: 1.7623355388641357
Validation loss: 2.0397769571632467

Epoch: 6| Step: 3
Training loss: 1.8094632625579834
Validation loss: 2.034608393587092

Epoch: 6| Step: 4
Training loss: 2.4998486042022705
Validation loss: 2.052061885915777

Epoch: 6| Step: 5
Training loss: 1.9902640581130981
Validation loss: 2.0633836997452604

Epoch: 6| Step: 6
Training loss: 2.18959903717041
Validation loss: 2.067331125659327

Epoch: 6| Step: 7
Training loss: 1.3555690050125122
Validation loss: 2.052827658191804

Epoch: 6| Step: 8
Training loss: 2.0442113876342773
Validation loss: 2.048520718851397

Epoch: 6| Step: 9
Training loss: 1.8370038270950317
Validation loss: 2.0314081330453195

Epoch: 6| Step: 10
Training loss: 1.9079508781433105
Validation loss: 2.0322711339560886

Epoch: 6| Step: 11
Training loss: 2.4837818145751953
Validation loss: 2.029293780685753

Epoch: 6| Step: 12
Training loss: 2.1791205406188965
Validation loss: 2.038203195859027

Epoch: 6| Step: 13
Training loss: 1.5195233821868896
Validation loss: 2.0366297934644964

Epoch: 119| Step: 0
Training loss: 1.756121039390564
Validation loss: 2.0561854083050966

Epoch: 6| Step: 1
Training loss: 1.6732091903686523
Validation loss: 2.072460295051657

Epoch: 6| Step: 2
Training loss: 1.2708992958068848
Validation loss: 2.06502454767945

Epoch: 6| Step: 3
Training loss: 1.6698331832885742
Validation loss: 2.0844130874961935

Epoch: 6| Step: 4
Training loss: 1.5815292596817017
Validation loss: 2.094750027502737

Epoch: 6| Step: 5
Training loss: 2.937448740005493
Validation loss: 2.0971958227055048

Epoch: 6| Step: 6
Training loss: 2.443580150604248
Validation loss: 2.05419228153844

Epoch: 6| Step: 7
Training loss: 1.7246196269989014
Validation loss: 2.054109242654616

Epoch: 6| Step: 8
Training loss: 1.879209280014038
Validation loss: 2.0405664713151994

Epoch: 6| Step: 9
Training loss: 2.2692525386810303
Validation loss: 2.016727214218468

Epoch: 6| Step: 10
Training loss: 2.0579004287719727
Validation loss: 2.012712040255147

Epoch: 6| Step: 11
Training loss: 2.490673065185547
Validation loss: 2.003169741681827

Epoch: 6| Step: 12
Training loss: 1.7809035778045654
Validation loss: 2.008911035394156

Epoch: 6| Step: 13
Training loss: 1.8801320791244507
Validation loss: 1.999929290945812

Epoch: 120| Step: 0
Training loss: 1.2898612022399902
Validation loss: 1.9896590684049873

Epoch: 6| Step: 1
Training loss: 1.8100372552871704
Validation loss: 1.9914769203432146

Epoch: 6| Step: 2
Training loss: 2.1398048400878906
Validation loss: 1.983030265377414

Epoch: 6| Step: 3
Training loss: 1.4798004627227783
Validation loss: 1.9693347125925043

Epoch: 6| Step: 4
Training loss: 2.4247515201568604
Validation loss: 1.9734238014426282

Epoch: 6| Step: 5
Training loss: 2.108421802520752
Validation loss: 1.9539410734689364

Epoch: 6| Step: 6
Training loss: 2.11354923248291
Validation loss: 1.9586460103270829

Epoch: 6| Step: 7
Training loss: 2.484875202178955
Validation loss: 1.974757186828121

Epoch: 6| Step: 8
Training loss: 1.8168574571609497
Validation loss: 1.9711275062253397

Epoch: 6| Step: 9
Training loss: 1.7312155961990356
Validation loss: 1.9880948066711426

Epoch: 6| Step: 10
Training loss: 1.63893723487854
Validation loss: 2.008806910566104

Epoch: 6| Step: 11
Training loss: 2.164489984512329
Validation loss: 2.0366282360528105

Epoch: 6| Step: 12
Training loss: 1.975705862045288
Validation loss: 2.0827292742267733

Epoch: 6| Step: 13
Training loss: 2.2313449382781982
Validation loss: 2.0840317241607176

Epoch: 121| Step: 0
Training loss: 1.5298577547073364
Validation loss: 2.0699358268450667

Epoch: 6| Step: 1
Training loss: 1.6672008037567139
Validation loss: 2.0494041237779843

Epoch: 6| Step: 2
Training loss: 1.985978364944458
Validation loss: 2.04242463778424

Epoch: 6| Step: 3
Training loss: 2.353668689727783
Validation loss: 2.0406537850697837

Epoch: 6| Step: 4
Training loss: 1.89027738571167
Validation loss: 2.0448708905968616

Epoch: 6| Step: 5
Training loss: 2.4965016841888428
Validation loss: 2.0312055464713805

Epoch: 6| Step: 6
Training loss: 1.4167029857635498
Validation loss: 2.0371838538877425

Epoch: 6| Step: 7
Training loss: 2.335777521133423
Validation loss: 2.0392345023411576

Epoch: 6| Step: 8
Training loss: 1.6772124767303467
Validation loss: 2.0545026384374148

Epoch: 6| Step: 9
Training loss: 2.200162410736084
Validation loss: 2.056655071114981

Epoch: 6| Step: 10
Training loss: 1.357300043106079
Validation loss: 2.0497657073441373

Epoch: 6| Step: 11
Training loss: 1.8040121793746948
Validation loss: 2.0517365599191315

Epoch: 6| Step: 12
Training loss: 1.7667372226715088
Validation loss: 2.0717613953416065

Epoch: 6| Step: 13
Training loss: 2.283947706222534
Validation loss: 2.0505375067392984

Epoch: 122| Step: 0
Training loss: 1.7652937173843384
Validation loss: 2.043517851060437

Epoch: 6| Step: 1
Training loss: 1.8110382556915283
Validation loss: 2.068435594599734

Epoch: 6| Step: 2
Training loss: 1.9361202716827393
Validation loss: 2.086198719598914

Epoch: 6| Step: 3
Training loss: 2.2764101028442383
Validation loss: 2.090819033243323

Epoch: 6| Step: 4
Training loss: 1.6684484481811523
Validation loss: 2.07845143605304

Epoch: 6| Step: 5
Training loss: 1.52240788936615
Validation loss: 2.0807737124863492

Epoch: 6| Step: 6
Training loss: 1.783660888671875
Validation loss: 2.0565769364756923

Epoch: 6| Step: 7
Training loss: 2.393191337585449
Validation loss: 2.0337278022561023

Epoch: 6| Step: 8
Training loss: 1.6200637817382812
Validation loss: 2.041651721923582

Epoch: 6| Step: 9
Training loss: 1.4137754440307617
Validation loss: 2.0260413026296966

Epoch: 6| Step: 10
Training loss: 2.688173294067383
Validation loss: 2.018375055764311

Epoch: 6| Step: 11
Training loss: 1.5638115406036377
Validation loss: 2.009375833695935

Epoch: 6| Step: 12
Training loss: 1.8545565605163574
Validation loss: 2.021132260240534

Epoch: 6| Step: 13
Training loss: 2.1039087772369385
Validation loss: 2.026017254398715

Epoch: 123| Step: 0
Training loss: 2.2139999866485596
Validation loss: 2.0312790460484003

Epoch: 6| Step: 1
Training loss: 2.1327576637268066
Validation loss: 2.035052385381473

Epoch: 6| Step: 2
Training loss: 1.7890712022781372
Validation loss: 2.0608570037349576

Epoch: 6| Step: 3
Training loss: 1.5699784755706787
Validation loss: 2.0681720190150763

Epoch: 6| Step: 4
Training loss: 2.205293655395508
Validation loss: 2.1139642166835007

Epoch: 6| Step: 5
Training loss: 1.8532536029815674
Validation loss: 2.097015042458811

Epoch: 6| Step: 6
Training loss: 1.7933460474014282
Validation loss: 2.091574917557419

Epoch: 6| Step: 7
Training loss: 1.6248273849487305
Validation loss: 2.089151615737587

Epoch: 6| Step: 8
Training loss: 1.2533020973205566
Validation loss: 2.090995024609309

Epoch: 6| Step: 9
Training loss: 1.8987672328948975
Validation loss: 2.094130539125012

Epoch: 6| Step: 10
Training loss: 1.912574052810669
Validation loss: 2.072694343905295

Epoch: 6| Step: 11
Training loss: 2.1954185962677
Validation loss: 2.0772422257290093

Epoch: 6| Step: 12
Training loss: 1.3605116605758667
Validation loss: 2.070955399544008

Epoch: 6| Step: 13
Training loss: 2.269439697265625
Validation loss: 2.0774206294808337

Epoch: 124| Step: 0
Training loss: 1.8075501918792725
Validation loss: 2.0281527606389855

Epoch: 6| Step: 1
Training loss: 1.8931801319122314
Validation loss: 2.0192130739970873

Epoch: 6| Step: 2
Training loss: 1.4635249376296997
Validation loss: 2.0021947853026854

Epoch: 6| Step: 3
Training loss: 2.16841459274292
Validation loss: 1.9870710014015116

Epoch: 6| Step: 4
Training loss: 2.088196277618408
Validation loss: 1.99033094990638

Epoch: 6| Step: 5
Training loss: 1.9519014358520508
Validation loss: 1.9900353416319816

Epoch: 6| Step: 6
Training loss: 1.580741047859192
Validation loss: 1.9937504952953709

Epoch: 6| Step: 7
Training loss: 2.0579299926757812
Validation loss: 2.0145121646183792

Epoch: 6| Step: 8
Training loss: 1.7053951025009155
Validation loss: 2.0564703505526305

Epoch: 6| Step: 9
Training loss: 2.6664981842041016
Validation loss: 2.0709619406730897

Epoch: 6| Step: 10
Training loss: 1.7270218133926392
Validation loss: 2.122441335390973

Epoch: 6| Step: 11
Training loss: 1.8317232131958008
Validation loss: 2.1182864455766577

Epoch: 6| Step: 12
Training loss: 1.6987879276275635
Validation loss: 2.068994035003006

Epoch: 6| Step: 13
Training loss: 0.9730120897293091
Validation loss: 2.014467049670476

Epoch: 125| Step: 0
Training loss: 2.634307861328125
Validation loss: 2.011697587146554

Epoch: 6| Step: 1
Training loss: 1.239129900932312
Validation loss: 2.0336907627762004

Epoch: 6| Step: 2
Training loss: 1.9333910942077637
Validation loss: 2.0415718247813563

Epoch: 6| Step: 3
Training loss: 2.7163729667663574
Validation loss: 2.0495469711160146

Epoch: 6| Step: 4
Training loss: 2.0214786529541016
Validation loss: 2.0533993577444427

Epoch: 6| Step: 5
Training loss: 1.5793545246124268
Validation loss: 2.0858584885956137

Epoch: 6| Step: 6
Training loss: 1.7130428552627563
Validation loss: 2.122444055413687

Epoch: 6| Step: 7
Training loss: 1.796433925628662
Validation loss: 2.06446853504386

Epoch: 6| Step: 8
Training loss: 1.8694727420806885
Validation loss: 1.9790441695080008

Epoch: 6| Step: 9
Training loss: 1.8984860181808472
Validation loss: 1.9622923892031434

Epoch: 6| Step: 10
Training loss: 1.640784740447998
Validation loss: 1.9583458387723534

Epoch: 6| Step: 11
Training loss: 1.1518505811691284
Validation loss: 1.9570083182345155

Epoch: 6| Step: 12
Training loss: 1.7610739469528198
Validation loss: 1.9507310877564132

Epoch: 6| Step: 13
Training loss: 2.0598244667053223
Validation loss: 1.981784652638179

Epoch: 126| Step: 0
Training loss: 1.613563060760498
Validation loss: 1.9776007847119403

Epoch: 6| Step: 1
Training loss: 2.030017852783203
Validation loss: 1.9753619611904185

Epoch: 6| Step: 2
Training loss: 1.470550775527954
Validation loss: 1.9614227407722062

Epoch: 6| Step: 3
Training loss: 1.2532854080200195
Validation loss: 1.9788581312343638

Epoch: 6| Step: 4
Training loss: 2.735989570617676
Validation loss: 1.9957365989685059

Epoch: 6| Step: 5
Training loss: 1.4793885946273804
Validation loss: 2.022586909673547

Epoch: 6| Step: 6
Training loss: 1.8899433612823486
Validation loss: 2.061322586510771

Epoch: 6| Step: 7
Training loss: 1.6690974235534668
Validation loss: 2.091607714212069

Epoch: 6| Step: 8
Training loss: 1.7733144760131836
Validation loss: 2.1443972408130603

Epoch: 6| Step: 9
Training loss: 2.571381092071533
Validation loss: 2.1639787176603913

Epoch: 6| Step: 10
Training loss: 2.158243179321289
Validation loss: 2.175631751296341

Epoch: 6| Step: 11
Training loss: 1.6093989610671997
Validation loss: 2.192875413484471

Epoch: 6| Step: 12
Training loss: 2.1490719318389893
Validation loss: 2.1448398456778577

Epoch: 6| Step: 13
Training loss: 1.9326956272125244
Validation loss: 2.117443843554425

Epoch: 127| Step: 0
Training loss: 1.4671869277954102
Validation loss: 2.091973049666292

Epoch: 6| Step: 1
Training loss: 1.5876083374023438
Validation loss: 2.0644096969276347

Epoch: 6| Step: 2
Training loss: 1.96303129196167
Validation loss: 2.0680836810860583

Epoch: 6| Step: 3
Training loss: 1.7425286769866943
Validation loss: 2.0539744105390323

Epoch: 6| Step: 4
Training loss: 1.0962610244750977
Validation loss: 2.0641553248128583

Epoch: 6| Step: 5
Training loss: 1.6815829277038574
Validation loss: 2.0510900956328197

Epoch: 6| Step: 6
Training loss: 2.535529375076294
Validation loss: 2.074264826313142

Epoch: 6| Step: 7
Training loss: 1.6926486492156982
Validation loss: 2.037643554390118

Epoch: 6| Step: 8
Training loss: 2.1620712280273438
Validation loss: 2.0531444113741637

Epoch: 6| Step: 9
Training loss: 1.8822317123413086
Validation loss: 2.0297716881639216

Epoch: 6| Step: 10
Training loss: 2.2801713943481445
Validation loss: 2.024602496495811

Epoch: 6| Step: 11
Training loss: 1.6502559185028076
Validation loss: 2.027119707035762

Epoch: 6| Step: 12
Training loss: 1.8477504253387451
Validation loss: 2.037927307108397

Epoch: 6| Step: 13
Training loss: 1.7153944969177246
Validation loss: 2.04407613636345

Epoch: 128| Step: 0
Training loss: 2.0293822288513184
Validation loss: 2.0489756638003933

Epoch: 6| Step: 1
Training loss: 2.545189619064331
Validation loss: 2.0952300371662265

Epoch: 6| Step: 2
Training loss: 1.4667433500289917
Validation loss: 2.116398572921753

Epoch: 6| Step: 3
Training loss: 1.9670100212097168
Validation loss: 2.138271116441296

Epoch: 6| Step: 4
Training loss: 1.249561071395874
Validation loss: 2.147152905823082

Epoch: 6| Step: 5
Training loss: 2.1503169536590576
Validation loss: 2.1539760405017483

Epoch: 6| Step: 6
Training loss: 1.663841962814331
Validation loss: 2.126807338447981

Epoch: 6| Step: 7
Training loss: 1.4372447729110718
Validation loss: 2.137981299431093

Epoch: 6| Step: 8
Training loss: 1.5927786827087402
Validation loss: 2.130251192277478

Epoch: 6| Step: 9
Training loss: 1.5895638465881348
Validation loss: 2.135878147617463

Epoch: 6| Step: 10
Training loss: 2.0197315216064453
Validation loss: 2.119474546883696

Epoch: 6| Step: 11
Training loss: 1.9307655096054077
Validation loss: 2.118001872493375

Epoch: 6| Step: 12
Training loss: 1.1536494493484497
Validation loss: 2.101763773989934

Epoch: 6| Step: 13
Training loss: 2.4250755310058594
Validation loss: 2.1076063968802012

Epoch: 129| Step: 0
Training loss: 2.0723023414611816
Validation loss: 2.0776005714170394

Epoch: 6| Step: 1
Training loss: 1.575876235961914
Validation loss: 2.0543660194643083

Epoch: 6| Step: 2
Training loss: 1.982576847076416
Validation loss: 2.0554689463748725

Epoch: 6| Step: 3
Training loss: 2.0054192543029785
Validation loss: 2.0491198698679605

Epoch: 6| Step: 4
Training loss: 0.9684102535247803
Validation loss: 2.0268755958926294

Epoch: 6| Step: 5
Training loss: 2.561338186264038
Validation loss: 2.0085172473743396

Epoch: 6| Step: 6
Training loss: 0.9492868185043335
Validation loss: 2.0173958527144564

Epoch: 6| Step: 7
Training loss: 2.4399402141571045
Validation loss: 2.0199073822267595

Epoch: 6| Step: 8
Training loss: 1.9302821159362793
Validation loss: 2.0359094732551166

Epoch: 6| Step: 9
Training loss: 1.9525368213653564
Validation loss: 2.0560415355108117

Epoch: 6| Step: 10
Training loss: 2.0039329528808594
Validation loss: 2.075019062206309

Epoch: 6| Step: 11
Training loss: 1.1911722421646118
Validation loss: 2.074980314059924

Epoch: 6| Step: 12
Training loss: 1.3670151233673096
Validation loss: 2.0775257131104827

Epoch: 6| Step: 13
Training loss: 1.274203896522522
Validation loss: 2.0768655397558726

Epoch: 130| Step: 0
Training loss: 1.4238139390945435
Validation loss: 2.0835745360261653

Epoch: 6| Step: 1
Training loss: 2.1127443313598633
Validation loss: 2.085099966295304

Epoch: 6| Step: 2
Training loss: 1.6134216785430908
Validation loss: 2.1076219774061635

Epoch: 6| Step: 3
Training loss: 1.8280446529388428
Validation loss: 2.109295542522143

Epoch: 6| Step: 4
Training loss: 1.830272912979126
Validation loss: 2.1310931251895044

Epoch: 6| Step: 5
Training loss: 1.9278548955917358
Validation loss: 2.1358917349128315

Epoch: 6| Step: 6
Training loss: 1.612989068031311
Validation loss: 2.1252453480997393

Epoch: 6| Step: 7
Training loss: 1.7969942092895508
Validation loss: 2.0898439704730944

Epoch: 6| Step: 8
Training loss: 1.917234182357788
Validation loss: 2.0908202663544686

Epoch: 6| Step: 9
Training loss: 1.7426934242248535
Validation loss: 2.072669211254325

Epoch: 6| Step: 10
Training loss: 1.8714468479156494
Validation loss: 2.0500539861699587

Epoch: 6| Step: 11
Training loss: 1.2610466480255127
Validation loss: 2.055446373519077

Epoch: 6| Step: 12
Training loss: 1.4409067630767822
Validation loss: 2.0681432985490367

Epoch: 6| Step: 13
Training loss: 2.24717378616333
Validation loss: 2.070600971098869

Epoch: 131| Step: 0
Training loss: 1.991621732711792
Validation loss: 2.0453940053139963

Epoch: 6| Step: 1
Training loss: 1.6270744800567627
Validation loss: 2.0240562039036907

Epoch: 6| Step: 2
Training loss: 1.835691213607788
Validation loss: 2.0222692130714335

Epoch: 6| Step: 3
Training loss: 1.2066493034362793
Validation loss: 2.0291972608976465

Epoch: 6| Step: 4
Training loss: 1.618094801902771
Validation loss: 2.049172939792756

Epoch: 6| Step: 5
Training loss: 1.5537899732589722
Validation loss: 2.0570785973661687

Epoch: 6| Step: 6
Training loss: 2.5633344650268555
Validation loss: 2.0461670634567097

Epoch: 6| Step: 7
Training loss: 1.5671076774597168
Validation loss: 2.0501447736576037

Epoch: 6| Step: 8
Training loss: 1.5080010890960693
Validation loss: 2.038658083126109

Epoch: 6| Step: 9
Training loss: 1.8738484382629395
Validation loss: 2.0617470818181194

Epoch: 6| Step: 10
Training loss: 1.2341793775558472
Validation loss: 2.0557864609585015

Epoch: 6| Step: 11
Training loss: 1.6065155267715454
Validation loss: 2.0531231421296314

Epoch: 6| Step: 12
Training loss: 1.4938719272613525
Validation loss: 2.0729084758348364

Epoch: 6| Step: 13
Training loss: 2.815218448638916
Validation loss: 2.139500141143799

Epoch: 132| Step: 0
Training loss: 2.1787898540496826
Validation loss: 2.1162814991448515

Epoch: 6| Step: 1
Training loss: 1.4593937397003174
Validation loss: 2.070520563792157

Epoch: 6| Step: 2
Training loss: 1.6187492609024048
Validation loss: 2.045577840138507

Epoch: 6| Step: 3
Training loss: 2.0468668937683105
Validation loss: 2.033673523574747

Epoch: 6| Step: 4
Training loss: 1.957895278930664
Validation loss: 2.0190192217467935

Epoch: 6| Step: 5
Training loss: 2.134500741958618
Validation loss: 2.0048770981450237

Epoch: 6| Step: 6
Training loss: 1.318411111831665
Validation loss: 1.9992927300032748

Epoch: 6| Step: 7
Training loss: 1.8693894147872925
Validation loss: 1.9814242919286091

Epoch: 6| Step: 8
Training loss: 2.0913777351379395
Validation loss: 1.9905070027997416

Epoch: 6| Step: 9
Training loss: 1.6047712564468384
Validation loss: 1.9839996086653842

Epoch: 6| Step: 10
Training loss: 1.26475989818573
Validation loss: 1.9862086747282295

Epoch: 6| Step: 11
Training loss: 1.0059609413146973
Validation loss: 2.0071682135264077

Epoch: 6| Step: 12
Training loss: 1.8867485523223877
Validation loss: 2.029672502189554

Epoch: 6| Step: 13
Training loss: 1.2467432022094727
Validation loss: 2.041033965285106

Epoch: 133| Step: 0
Training loss: 1.5093965530395508
Validation loss: 2.102793143641564

Epoch: 6| Step: 1
Training loss: 2.318963050842285
Validation loss: 2.116885810770014

Epoch: 6| Step: 2
Training loss: 1.3204636573791504
Validation loss: 2.0884761771848126

Epoch: 6| Step: 3
Training loss: 1.5023835897445679
Validation loss: 2.0878319637749785

Epoch: 6| Step: 4
Training loss: 1.8501014709472656
Validation loss: 2.092330837762484

Epoch: 6| Step: 5
Training loss: 1.8419281244277954
Validation loss: 2.1020418828533542

Epoch: 6| Step: 6
Training loss: 1.5646791458129883
Validation loss: 2.1556450551556003

Epoch: 6| Step: 7
Training loss: 1.6907087564468384
Validation loss: 2.1689089344393824

Epoch: 6| Step: 8
Training loss: 1.4945558309555054
Validation loss: 2.1921262894907305

Epoch: 6| Step: 9
Training loss: 1.639190673828125
Validation loss: 2.2253208442400862

Epoch: 6| Step: 10
Training loss: 1.965689778327942
Validation loss: 2.2064770216582925

Epoch: 6| Step: 11
Training loss: 1.5087294578552246
Validation loss: 2.2009716674845707

Epoch: 6| Step: 12
Training loss: 2.2336196899414062
Validation loss: 2.1836095163899083

Epoch: 6| Step: 13
Training loss: 1.5816489458084106
Validation loss: 2.1359372805523615

Epoch: 134| Step: 0
Training loss: 1.8099806308746338
Validation loss: 2.0868866789725518

Epoch: 6| Step: 1
Training loss: 2.2598001956939697
Validation loss: 2.068925226888349

Epoch: 6| Step: 2
Training loss: 1.4842987060546875
Validation loss: 2.0617876052856445

Epoch: 6| Step: 3
Training loss: 1.7034683227539062
Validation loss: 2.0215549956085863

Epoch: 6| Step: 4
Training loss: 0.9963259696960449
Validation loss: 2.032691027528496

Epoch: 6| Step: 5
Training loss: 1.957762360572815
Validation loss: 2.048186577776427

Epoch: 6| Step: 6
Training loss: 1.978351354598999
Validation loss: 2.1054531528103735

Epoch: 6| Step: 7
Training loss: 1.4734270572662354
Validation loss: 2.1392538265515397

Epoch: 6| Step: 8
Training loss: 1.833716869354248
Validation loss: 2.173836692687004

Epoch: 6| Step: 9
Training loss: 2.081826686859131
Validation loss: 2.236930065257575

Epoch: 6| Step: 10
Training loss: 1.1972270011901855
Validation loss: 2.1859371418594034

Epoch: 6| Step: 11
Training loss: 2.169827938079834
Validation loss: 2.1340043057677565

Epoch: 6| Step: 12
Training loss: 1.8106815814971924
Validation loss: 2.0716683774866085

Epoch: 6| Step: 13
Training loss: 1.0458369255065918
Validation loss: 2.0458863909526537

Epoch: 135| Step: 0
Training loss: 1.712304949760437
Validation loss: 2.042335206462491

Epoch: 6| Step: 1
Training loss: 1.5699927806854248
Validation loss: 2.0549041019972933

Epoch: 6| Step: 2
Training loss: 2.037647247314453
Validation loss: 2.0686980960189656

Epoch: 6| Step: 3
Training loss: 1.9202420711517334
Validation loss: 2.047164194045528

Epoch: 6| Step: 4
Training loss: 1.3954102993011475
Validation loss: 2.0772986040320447

Epoch: 6| Step: 5
Training loss: 1.8634974956512451
Validation loss: 2.102985220570718

Epoch: 6| Step: 6
Training loss: 1.9223675727844238
Validation loss: 2.1249533404586134

Epoch: 6| Step: 7
Training loss: 1.6251616477966309
Validation loss: 2.1271498639096498

Epoch: 6| Step: 8
Training loss: 2.0483386516571045
Validation loss: 2.092636000725531

Epoch: 6| Step: 9
Training loss: 1.4022618532180786
Validation loss: 2.058882067280431

Epoch: 6| Step: 10
Training loss: 1.0991369485855103
Validation loss: 2.056804903091923

Epoch: 6| Step: 11
Training loss: 1.7324392795562744
Validation loss: 2.0542899536830124

Epoch: 6| Step: 12
Training loss: 1.4958816766738892
Validation loss: 2.104903777440389

Epoch: 6| Step: 13
Training loss: 1.5887030363082886
Validation loss: 2.124844238322268

Epoch: 136| Step: 0
Training loss: 1.0600204467773438
Validation loss: 2.1390310166984476

Epoch: 6| Step: 1
Training loss: 1.6809594631195068
Validation loss: 2.108859844105218

Epoch: 6| Step: 2
Training loss: 1.5601004362106323
Validation loss: 2.118019489831822

Epoch: 6| Step: 3
Training loss: 1.7560633420944214
Validation loss: 2.116807979922141

Epoch: 6| Step: 4
Training loss: 1.9495177268981934
Validation loss: 2.1213967441230692

Epoch: 6| Step: 5
Training loss: 2.068540096282959
Validation loss: 2.1401057832984516

Epoch: 6| Step: 6
Training loss: 1.6434781551361084
Validation loss: 2.1395767017077376

Epoch: 6| Step: 7
Training loss: 1.6323851346969604
Validation loss: 2.1440703343319636

Epoch: 6| Step: 8
Training loss: 1.459925651550293
Validation loss: 2.1794536934104016

Epoch: 6| Step: 9
Training loss: 1.6755876541137695
Validation loss: 2.13709456177168

Epoch: 6| Step: 10
Training loss: 1.615276575088501
Validation loss: 2.1171766660546743

Epoch: 6| Step: 11
Training loss: 1.6064761877059937
Validation loss: 2.1053929559646116

Epoch: 6| Step: 12
Training loss: 1.551867961883545
Validation loss: 2.050525147427795

Epoch: 6| Step: 13
Training loss: 1.474149227142334
Validation loss: 1.9984911052129601

Epoch: 137| Step: 0
Training loss: 1.4021235704421997
Validation loss: 1.995836425853032

Epoch: 6| Step: 1
Training loss: 2.2865185737609863
Validation loss: 1.9658719416587584

Epoch: 6| Step: 2
Training loss: 1.7294000387191772
Validation loss: 1.9807657554585447

Epoch: 6| Step: 3
Training loss: 1.1456329822540283
Validation loss: 1.9731745822455293

Epoch: 6| Step: 4
Training loss: 1.571983814239502
Validation loss: 1.9727431420356996

Epoch: 6| Step: 5
Training loss: 2.299156427383423
Validation loss: 2.004926694336758

Epoch: 6| Step: 6
Training loss: 1.624077320098877
Validation loss: 2.0109005333274923

Epoch: 6| Step: 7
Training loss: 1.4907430410385132
Validation loss: 2.02745981113885

Epoch: 6| Step: 8
Training loss: 1.7794605493545532
Validation loss: 2.0185275846912014

Epoch: 6| Step: 9
Training loss: 1.1490230560302734
Validation loss: 2.0033473301959295

Epoch: 6| Step: 10
Training loss: 1.5181552171707153
Validation loss: 2.001799107879721

Epoch: 6| Step: 11
Training loss: 1.0997083187103271
Validation loss: 2.0161141759605816

Epoch: 6| Step: 12
Training loss: 1.761777400970459
Validation loss: 2.026343499460528

Epoch: 6| Step: 13
Training loss: 1.8480069637298584
Validation loss: 2.0351396350450415

Epoch: 138| Step: 0
Training loss: 1.8689892292022705
Validation loss: 2.0442719792806976

Epoch: 6| Step: 1
Training loss: 1.2317004203796387
Validation loss: 2.075908963398267

Epoch: 6| Step: 2
Training loss: 1.3320050239562988
Validation loss: 2.073337503658828

Epoch: 6| Step: 3
Training loss: 2.066101312637329
Validation loss: 2.049611804305866

Epoch: 6| Step: 4
Training loss: 1.6524813175201416
Validation loss: 2.0438125582151514

Epoch: 6| Step: 5
Training loss: 1.578136920928955
Validation loss: 2.0041432970313617

Epoch: 6| Step: 6
Training loss: 1.4467101097106934
Validation loss: 1.9886728499525337

Epoch: 6| Step: 7
Training loss: 1.5900599956512451
Validation loss: 1.9589146285928705

Epoch: 6| Step: 8
Training loss: 1.6706061363220215
Validation loss: 1.959110306155297

Epoch: 6| Step: 9
Training loss: 1.5744115114212036
Validation loss: 1.9534318408658427

Epoch: 6| Step: 10
Training loss: 1.9777774810791016
Validation loss: 1.962888704833164

Epoch: 6| Step: 11
Training loss: 1.6121962070465088
Validation loss: 1.9771168847237863

Epoch: 6| Step: 12
Training loss: 1.6557998657226562
Validation loss: 2.0235524433915333

Epoch: 6| Step: 13
Training loss: 1.2378803491592407
Validation loss: 2.0512937217630367

Epoch: 139| Step: 0
Training loss: 1.9162094593048096
Validation loss: 2.0730991824980705

Epoch: 6| Step: 1
Training loss: 1.6789829730987549
Validation loss: 2.10528895162767

Epoch: 6| Step: 2
Training loss: 1.579393744468689
Validation loss: 2.13677530775788

Epoch: 6| Step: 3
Training loss: 1.6575253009796143
Validation loss: 2.12696139530469

Epoch: 6| Step: 4
Training loss: 1.7813764810562134
Validation loss: 2.124555000694849

Epoch: 6| Step: 5
Training loss: 2.3639326095581055
Validation loss: 2.1091004456243208

Epoch: 6| Step: 6
Training loss: 1.09517502784729
Validation loss: 2.1062633914332234

Epoch: 6| Step: 7
Training loss: 1.9249078035354614
Validation loss: 2.1207587488235964

Epoch: 6| Step: 8
Training loss: 1.905733346939087
Validation loss: 2.075890638495004

Epoch: 6| Step: 9
Training loss: 0.8809850215911865
Validation loss: 2.0514665239600727

Epoch: 6| Step: 10
Training loss: 1.4369268417358398
Validation loss: 2.031993378875076

Epoch: 6| Step: 11
Training loss: 1.295497179031372
Validation loss: 1.9956505683160597

Epoch: 6| Step: 12
Training loss: 1.3294739723205566
Validation loss: 1.9943757403281428

Epoch: 6| Step: 13
Training loss: 0.9961113333702087
Validation loss: 1.9925814431200746

Epoch: 140| Step: 0
Training loss: 1.262048363685608
Validation loss: 1.9861297479239843

Epoch: 6| Step: 1
Training loss: 1.9742770195007324
Validation loss: 1.9897114846014208

Epoch: 6| Step: 2
Training loss: 2.1358909606933594
Validation loss: 1.99409564592505

Epoch: 6| Step: 3
Training loss: 1.4696205854415894
Validation loss: 2.0111362190656763

Epoch: 6| Step: 4
Training loss: 1.5810539722442627
Validation loss: 2.0209451157559633

Epoch: 6| Step: 5
Training loss: 0.8256935477256775
Validation loss: 2.0553194515166746

Epoch: 6| Step: 6
Training loss: 1.3622241020202637
Validation loss: 2.069290584133517

Epoch: 6| Step: 7
Training loss: 1.2546379566192627
Validation loss: 2.067538131949722

Epoch: 6| Step: 8
Training loss: 1.2387217283248901
Validation loss: 2.064919589668192

Epoch: 6| Step: 9
Training loss: 1.197519302368164
Validation loss: 2.076496911305253

Epoch: 6| Step: 10
Training loss: 1.9394582509994507
Validation loss: 2.0841553544485443

Epoch: 6| Step: 11
Training loss: 2.2086267471313477
Validation loss: 2.055103136647132

Epoch: 6| Step: 12
Training loss: 1.7168753147125244
Validation loss: 2.0326964470647995

Epoch: 6| Step: 13
Training loss: 1.6890883445739746
Validation loss: 2.018439467235278

Epoch: 141| Step: 0
Training loss: 2.2304933071136475
Validation loss: 2.0356250116902013

Epoch: 6| Step: 1
Training loss: 1.4187604188919067
Validation loss: 2.038681758347378

Epoch: 6| Step: 2
Training loss: 1.5046383142471313
Validation loss: 2.02565751793564

Epoch: 6| Step: 3
Training loss: 1.5066754817962646
Validation loss: 2.029364260294104

Epoch: 6| Step: 4
Training loss: 1.491163969039917
Validation loss: 2.019038136287402

Epoch: 6| Step: 5
Training loss: 1.6142964363098145
Validation loss: 2.0084924569693943

Epoch: 6| Step: 6
Training loss: 1.344509243965149
Validation loss: 2.0151443212263045

Epoch: 6| Step: 7
Training loss: 2.1683287620544434
Validation loss: 2.0245121320088706

Epoch: 6| Step: 8
Training loss: 1.0351141691207886
Validation loss: 2.0412201958317913

Epoch: 6| Step: 9
Training loss: 1.9800715446472168
Validation loss: 2.0830251452743367

Epoch: 6| Step: 10
Training loss: 1.7569499015808105
Validation loss: 2.1082851809840046

Epoch: 6| Step: 11
Training loss: 1.0565565824508667
Validation loss: 2.1530762590387815

Epoch: 6| Step: 12
Training loss: 1.1234533786773682
Validation loss: 2.195508377526396

Epoch: 6| Step: 13
Training loss: 1.4497381448745728
Validation loss: 2.188271730176864

Epoch: 142| Step: 0
Training loss: 1.1416254043579102
Validation loss: 2.152075764953449

Epoch: 6| Step: 1
Training loss: 1.598620891571045
Validation loss: 2.1105377520284345

Epoch: 6| Step: 2
Training loss: 1.441335678100586
Validation loss: 2.0215489454166864

Epoch: 6| Step: 3
Training loss: 2.4196972846984863
Validation loss: 1.9916769842947684

Epoch: 6| Step: 4
Training loss: 1.460537314414978
Validation loss: 1.9837174607861427

Epoch: 6| Step: 5
Training loss: 1.8452589511871338
Validation loss: 1.9652145216541905

Epoch: 6| Step: 6
Training loss: 1.3294932842254639
Validation loss: 1.9452360086543585

Epoch: 6| Step: 7
Training loss: 1.8454382419586182
Validation loss: 1.9456667310448104

Epoch: 6| Step: 8
Training loss: 1.7075380086898804
Validation loss: 1.9708847922663535

Epoch: 6| Step: 9
Training loss: 1.9972472190856934
Validation loss: 2.088817011925482

Epoch: 6| Step: 10
Training loss: 1.2743821144104004
Validation loss: 2.1359210629617014

Epoch: 6| Step: 11
Training loss: 2.220305919647217
Validation loss: 2.190366034866661

Epoch: 6| Step: 12
Training loss: 1.7796144485473633
Validation loss: 2.1208735358330513

Epoch: 6| Step: 13
Training loss: 0.999576985836029
Validation loss: 2.0693248984634236

Epoch: 143| Step: 0
Training loss: 1.4685171842575073
Validation loss: 2.0571178672134236

Epoch: 6| Step: 1
Training loss: 1.6839532852172852
Validation loss: 2.0997262590674945

Epoch: 6| Step: 2
Training loss: 1.924706220626831
Validation loss: 2.1603888837240075

Epoch: 6| Step: 3
Training loss: 1.5639864206314087
Validation loss: 2.187937226346744

Epoch: 6| Step: 4
Training loss: 1.3901896476745605
Validation loss: 2.2028778676063783

Epoch: 6| Step: 5
Training loss: 1.147804856300354
Validation loss: 2.2156266525227535

Epoch: 6| Step: 6
Training loss: 1.9429678916931152
Validation loss: 2.214091218927855

Epoch: 6| Step: 7
Training loss: 1.6947276592254639
Validation loss: 2.2341229479799987

Epoch: 6| Step: 8
Training loss: 2.0947604179382324
Validation loss: 2.22694581554782

Epoch: 6| Step: 9
Training loss: 1.815680742263794
Validation loss: 2.1491298137172574

Epoch: 6| Step: 10
Training loss: 1.5751700401306152
Validation loss: 2.0886973437442573

Epoch: 6| Step: 11
Training loss: 1.675504207611084
Validation loss: 2.0279442289824128

Epoch: 6| Step: 12
Training loss: 1.4288028478622437
Validation loss: 1.989007285846177

Epoch: 6| Step: 13
Training loss: 0.8469802141189575
Validation loss: 1.9589595640859296

Epoch: 144| Step: 0
Training loss: 1.9819966554641724
Validation loss: 1.9505825260634064

Epoch: 6| Step: 1
Training loss: 1.4523104429244995
Validation loss: 1.9465598098693355

Epoch: 6| Step: 2
Training loss: 1.1910409927368164
Validation loss: 1.934893972130232

Epoch: 6| Step: 3
Training loss: 2.280883312225342
Validation loss: 1.9488981052111554

Epoch: 6| Step: 4
Training loss: 1.7646484375
Validation loss: 1.957432626396097

Epoch: 6| Step: 5
Training loss: 1.4672046899795532
Validation loss: 1.9781513175656718

Epoch: 6| Step: 6
Training loss: 1.453861117362976
Validation loss: 2.031865922353601

Epoch: 6| Step: 7
Training loss: 1.943518877029419
Validation loss: 2.076254557537776

Epoch: 6| Step: 8
Training loss: 1.1518936157226562
Validation loss: 2.0621961086027083

Epoch: 6| Step: 9
Training loss: 1.3388075828552246
Validation loss: 2.0565396047407583

Epoch: 6| Step: 10
Training loss: 1.254508376121521
Validation loss: 2.0506043831507363

Epoch: 6| Step: 11
Training loss: 1.3869837522506714
Validation loss: 2.087085072712232

Epoch: 6| Step: 12
Training loss: 1.3520441055297852
Validation loss: 2.0779242669382403

Epoch: 6| Step: 13
Training loss: 2.312061309814453
Validation loss: 2.0954692594466673

Epoch: 145| Step: 0
Training loss: 1.495513677597046
Validation loss: 2.088949248354922

Epoch: 6| Step: 1
Training loss: 1.1390631198883057
Validation loss: 2.0859356093150314

Epoch: 6| Step: 2
Training loss: 1.0530905723571777
Validation loss: 2.1147680051865114

Epoch: 6| Step: 3
Training loss: 1.792569875717163
Validation loss: 2.1062377857905563

Epoch: 6| Step: 4
Training loss: 2.1249003410339355
Validation loss: 2.1157901287078857

Epoch: 6| Step: 5
Training loss: 1.826939344406128
Validation loss: 2.095795355817323

Epoch: 6| Step: 6
Training loss: 1.4993650913238525
Validation loss: 2.058952469979563

Epoch: 6| Step: 7
Training loss: 1.555840253829956
Validation loss: 2.0378438682966333

Epoch: 6| Step: 8
Training loss: 1.2718528509140015
Validation loss: 2.0253893944524948

Epoch: 6| Step: 9
Training loss: 1.184395670890808
Validation loss: 2.0336700254871

Epoch: 6| Step: 10
Training loss: 0.7410756349563599
Validation loss: 2.0296942559621667

Epoch: 6| Step: 11
Training loss: 2.409832000732422
Validation loss: 2.0426745209642636

Epoch: 6| Step: 12
Training loss: 1.5810960531234741
Validation loss: 2.0182859166975944

Epoch: 6| Step: 13
Training loss: 0.9904278516769409
Validation loss: 1.9906676264219387

Epoch: 146| Step: 0
Training loss: 1.3408132791519165
Validation loss: 1.9619867442756571

Epoch: 6| Step: 1
Training loss: 1.850865364074707
Validation loss: 1.9607524474461873

Epoch: 6| Step: 2
Training loss: 1.3646714687347412
Validation loss: 1.9770603936205629

Epoch: 6| Step: 3
Training loss: 1.6149845123291016
Validation loss: 1.9968036682375017

Epoch: 6| Step: 4
Training loss: 2.039916515350342
Validation loss: 2.034948492562899

Epoch: 6| Step: 5
Training loss: 1.6458786725997925
Validation loss: 2.0560234823534564

Epoch: 6| Step: 6
Training loss: 2.081117630004883
Validation loss: 2.1009047544130715

Epoch: 6| Step: 7
Training loss: 1.4689249992370605
Validation loss: 2.10783540561635

Epoch: 6| Step: 8
Training loss: 0.7241401672363281
Validation loss: 2.122589865038472

Epoch: 6| Step: 9
Training loss: 1.3135108947753906
Validation loss: 2.0764850044763214

Epoch: 6| Step: 10
Training loss: 1.7298434972763062
Validation loss: 2.06383058973538

Epoch: 6| Step: 11
Training loss: 1.4604709148406982
Validation loss: 2.0744761523380073

Epoch: 6| Step: 12
Training loss: 1.2888081073760986
Validation loss: 2.0663222792328044

Epoch: 6| Step: 13
Training loss: 2.002239465713501
Validation loss: 2.08291204514042

Epoch: 147| Step: 0
Training loss: 1.5774469375610352
Validation loss: 2.0714828480956373

Epoch: 6| Step: 1
Training loss: 1.763342022895813
Validation loss: 2.088534341063551

Epoch: 6| Step: 2
Training loss: 0.9243605136871338
Validation loss: 2.082520607979067

Epoch: 6| Step: 3
Training loss: 2.2784414291381836
Validation loss: 2.0925494599085983

Epoch: 6| Step: 4
Training loss: 1.514587640762329
Validation loss: 2.111447316344066

Epoch: 6| Step: 5
Training loss: 1.4760197401046753
Validation loss: 2.1072309401727494

Epoch: 6| Step: 6
Training loss: 0.8643375635147095
Validation loss: 2.085498176595216

Epoch: 6| Step: 7
Training loss: 1.5087804794311523
Validation loss: 2.0487848507460726

Epoch: 6| Step: 8
Training loss: 1.6643962860107422
Validation loss: 2.0069936962537867

Epoch: 6| Step: 9
Training loss: 1.112347960472107
Validation loss: 1.9737696263097948

Epoch: 6| Step: 10
Training loss: 1.9432504177093506
Validation loss: 1.9839199627599409

Epoch: 6| Step: 11
Training loss: 1.1631104946136475
Validation loss: 1.9777775836247269

Epoch: 6| Step: 12
Training loss: 1.4691344499588013
Validation loss: 2.019691672376407

Epoch: 6| Step: 13
Training loss: 1.5282597541809082
Validation loss: 2.0396579260467202

Epoch: 148| Step: 0
Training loss: 1.5325981378555298
Validation loss: 2.0608462031169603

Epoch: 6| Step: 1
Training loss: 1.231697916984558
Validation loss: 2.0784598191579184

Epoch: 6| Step: 2
Training loss: 0.80912184715271
Validation loss: 2.0833891642990934

Epoch: 6| Step: 3
Training loss: 1.4514856338500977
Validation loss: 2.093684991200765

Epoch: 6| Step: 4
Training loss: 1.7550878524780273
Validation loss: 2.1000827512433453

Epoch: 6| Step: 5
Training loss: 1.3593693971633911
Validation loss: 2.0972192966809837

Epoch: 6| Step: 6
Training loss: 1.0491669178009033
Validation loss: 2.0989108111268733

Epoch: 6| Step: 7
Training loss: 1.4991289377212524
Validation loss: 2.10664297944756

Epoch: 6| Step: 8
Training loss: 1.9041742086410522
Validation loss: 2.1152292656642135

Epoch: 6| Step: 9
Training loss: 1.5868834257125854
Validation loss: 2.0830337539795907

Epoch: 6| Step: 10
Training loss: 2.083064079284668
Validation loss: 2.042846388714288

Epoch: 6| Step: 11
Training loss: 1.2413055896759033
Validation loss: 1.995105384498514

Epoch: 6| Step: 12
Training loss: 1.460355520248413
Validation loss: 1.973178111096864

Epoch: 6| Step: 13
Training loss: 1.9206990003585815
Validation loss: 1.949588526961624

Epoch: 149| Step: 0
Training loss: 1.3975780010223389
Validation loss: 1.9422535229754705

Epoch: 6| Step: 1
Training loss: 1.4224717617034912
Validation loss: 1.9687332389175252

Epoch: 6| Step: 2
Training loss: 1.3884239196777344
Validation loss: 1.9866948127746582

Epoch: 6| Step: 3
Training loss: 1.7617857456207275
Validation loss: 1.9821356599048903

Epoch: 6| Step: 4
Training loss: 1.119136929512024
Validation loss: 1.9546606284315868

Epoch: 6| Step: 5
Training loss: 1.4966825246810913
Validation loss: 1.9728110631306965

Epoch: 6| Step: 6
Training loss: 1.8555047512054443
Validation loss: 1.9541720690265778

Epoch: 6| Step: 7
Training loss: 1.437663197517395
Validation loss: 1.971510725636636

Epoch: 6| Step: 8
Training loss: 1.3095901012420654
Validation loss: 1.9702205350322108

Epoch: 6| Step: 9
Training loss: 1.875885248184204
Validation loss: 1.9752318628372685

Epoch: 6| Step: 10
Training loss: 0.8951404094696045
Validation loss: 1.9958257188079178

Epoch: 6| Step: 11
Training loss: 1.2788572311401367
Validation loss: 2.023410854801055

Epoch: 6| Step: 12
Training loss: 1.9445065259933472
Validation loss: 2.0136375632337344

Epoch: 6| Step: 13
Training loss: 1.5697740316390991
Validation loss: 2.033002907230008

Epoch: 150| Step: 0
Training loss: 1.235692024230957
Validation loss: 2.039832781719905

Epoch: 6| Step: 1
Training loss: 1.5349637269973755
Validation loss: 2.0592284638394593

Epoch: 6| Step: 2
Training loss: 1.6971310377120972
Validation loss: 2.0998579430323776

Epoch: 6| Step: 3
Training loss: 0.8190234899520874
Validation loss: 2.137802072750625

Epoch: 6| Step: 4
Training loss: 2.3976638317108154
Validation loss: 2.130830234096896

Epoch: 6| Step: 5
Training loss: 1.3655850887298584
Validation loss: 2.0834049383799234

Epoch: 6| Step: 6
Training loss: 1.3039836883544922
Validation loss: 2.045057519789665

Epoch: 6| Step: 7
Training loss: 1.145280361175537
Validation loss: 2.045387560321439

Epoch: 6| Step: 8
Training loss: 1.2069425582885742
Validation loss: 2.028581565426242

Epoch: 6| Step: 9
Training loss: 1.6745705604553223
Validation loss: 2.011079584398577

Epoch: 6| Step: 10
Training loss: 1.701258897781372
Validation loss: 1.9895663992051156

Epoch: 6| Step: 11
Training loss: 1.2365777492523193
Validation loss: 1.9991185049856863

Epoch: 6| Step: 12
Training loss: 1.67056143283844
Validation loss: 1.9934424251638434

Epoch: 6| Step: 13
Training loss: 1.0038982629776
Validation loss: 1.978819166460345

Epoch: 151| Step: 0
Training loss: 0.9336188435554504
Validation loss: 1.9732052933785222

Epoch: 6| Step: 1
Training loss: 1.5454515218734741
Validation loss: 1.989519546108861

Epoch: 6| Step: 2
Training loss: 1.675628423690796
Validation loss: 2.0163711591433455

Epoch: 6| Step: 3
Training loss: 1.4893057346343994
Validation loss: 2.0314581137831493

Epoch: 6| Step: 4
Training loss: 1.1503154039382935
Validation loss: 2.0478130361085296

Epoch: 6| Step: 5
Training loss: 1.917872667312622
Validation loss: 2.081166121267503

Epoch: 6| Step: 6
Training loss: 0.7330561876296997
Validation loss: 2.091866124060846

Epoch: 6| Step: 7
Training loss: 1.4823799133300781
Validation loss: 2.0707708046000493

Epoch: 6| Step: 8
Training loss: 1.8434263467788696
Validation loss: 2.0930611805249284

Epoch: 6| Step: 9
Training loss: 1.988349199295044
Validation loss: 2.0915426592673025

Epoch: 6| Step: 10
Training loss: 1.3943843841552734
Validation loss: 2.09960425284601

Epoch: 6| Step: 11
Training loss: 0.9992151260375977
Validation loss: 2.0830086661923315

Epoch: 6| Step: 12
Training loss: 1.271996021270752
Validation loss: 2.0768875793744157

Epoch: 6| Step: 13
Training loss: 1.4748573303222656
Validation loss: 2.034754858222059

Epoch: 152| Step: 0
Training loss: 1.357553482055664
Validation loss: 2.0276867984443583

Epoch: 6| Step: 1
Training loss: 1.0450389385223389
Validation loss: 1.9987612821722542

Epoch: 6| Step: 2
Training loss: 0.935981035232544
Validation loss: 1.9906834684392458

Epoch: 6| Step: 3
Training loss: 1.0045356750488281
Validation loss: 1.9970383592831191

Epoch: 6| Step: 4
Training loss: 1.5271245241165161
Validation loss: 2.0340046318628455

Epoch: 6| Step: 5
Training loss: 1.4166669845581055
Validation loss: 2.0603974147509505

Epoch: 6| Step: 6
Training loss: 1.9128692150115967
Validation loss: 2.0660988771787254

Epoch: 6| Step: 7
Training loss: 1.3788411617279053
Validation loss: 2.0450935620133595

Epoch: 6| Step: 8
Training loss: 1.6029200553894043
Validation loss: 2.039694134907056

Epoch: 6| Step: 9
Training loss: 1.6587448120117188
Validation loss: 2.0188925073992823

Epoch: 6| Step: 10
Training loss: 1.4471435546875
Validation loss: 2.0184522367292836

Epoch: 6| Step: 11
Training loss: 1.9149460792541504
Validation loss: 2.0195085848531416

Epoch: 6| Step: 12
Training loss: 1.46378493309021
Validation loss: 2.0252919773901663

Epoch: 6| Step: 13
Training loss: 1.0363966226577759
Validation loss: 2.0095615079326015

Epoch: 153| Step: 0
Training loss: 1.1046355962753296
Validation loss: 2.001542536161279

Epoch: 6| Step: 1
Training loss: 1.5545246601104736
Validation loss: 1.9895553204321093

Epoch: 6| Step: 2
Training loss: 1.6508132219314575
Validation loss: 1.958328834144018

Epoch: 6| Step: 3
Training loss: 1.6062939167022705
Validation loss: 1.9742075730395574

Epoch: 6| Step: 4
Training loss: 1.0197478532791138
Validation loss: 1.9698829291969218

Epoch: 6| Step: 5
Training loss: 1.3432374000549316
Validation loss: 1.9647363770392634

Epoch: 6| Step: 6
Training loss: 0.6918257474899292
Validation loss: 1.9914544705421693

Epoch: 6| Step: 7
Training loss: 2.0229766368865967
Validation loss: 1.9923586614670292

Epoch: 6| Step: 8
Training loss: 1.697982907295227
Validation loss: 2.0120494109328075

Epoch: 6| Step: 9
Training loss: 1.2926931381225586
Validation loss: 2.010180973237561

Epoch: 6| Step: 10
Training loss: 1.6902844905853271
Validation loss: 1.999950126935077

Epoch: 6| Step: 11
Training loss: 1.1860220432281494
Validation loss: 2.0017167919425556

Epoch: 6| Step: 12
Training loss: 1.3181031942367554
Validation loss: 2.0244970821565196

Epoch: 6| Step: 13
Training loss: 1.2083860635757446
Validation loss: 2.0295472657808693

Epoch: 154| Step: 0
Training loss: 0.9716002941131592
Validation loss: 2.0457750135852444

Epoch: 6| Step: 1
Training loss: 1.7123982906341553
Validation loss: 2.0458882572830364

Epoch: 6| Step: 2
Training loss: 1.2674081325531006
Validation loss: 2.0555703178528817

Epoch: 6| Step: 3
Training loss: 1.4646954536437988
Validation loss: 2.080439270183604

Epoch: 6| Step: 4
Training loss: 1.8671188354492188
Validation loss: 2.0842706900770946

Epoch: 6| Step: 5
Training loss: 1.7791340351104736
Validation loss: 2.084040803294028

Epoch: 6| Step: 6
Training loss: 1.1749701499938965
Validation loss: 2.0453833738962808

Epoch: 6| Step: 7
Training loss: 1.3679466247558594
Validation loss: 1.9922422209093649

Epoch: 6| Step: 8
Training loss: 1.9399683475494385
Validation loss: 1.9849405519423946

Epoch: 6| Step: 9
Training loss: 0.7842901945114136
Validation loss: 1.9616445187599427

Epoch: 6| Step: 10
Training loss: 1.3470165729522705
Validation loss: 1.9580732737818072

Epoch: 6| Step: 11
Training loss: 1.2613718509674072
Validation loss: 1.9793815638429375

Epoch: 6| Step: 12
Training loss: 1.793654203414917
Validation loss: 2.0366917348677114

Epoch: 6| Step: 13
Training loss: 1.0860201120376587
Validation loss: 2.061565104351249

Epoch: 155| Step: 0
Training loss: 1.5136406421661377
Validation loss: 2.079657700753981

Epoch: 6| Step: 1
Training loss: 1.714594841003418
Validation loss: 2.0816530399425055

Epoch: 6| Step: 2
Training loss: 1.508179783821106
Validation loss: 2.0440552978105444

Epoch: 6| Step: 3
Training loss: 1.2193539142608643
Validation loss: 1.9753784518088064

Epoch: 6| Step: 4
Training loss: 1.3350028991699219
Validation loss: 1.9583658390147711

Epoch: 6| Step: 5
Training loss: 1.988451361656189
Validation loss: 1.9701760533035442

Epoch: 6| Step: 6
Training loss: 1.6029701232910156
Validation loss: 1.9810005836589362

Epoch: 6| Step: 7
Training loss: 1.1056030988693237
Validation loss: 1.9620573354023758

Epoch: 6| Step: 8
Training loss: 0.8321665525436401
Validation loss: 1.9717189240199264

Epoch: 6| Step: 9
Training loss: 1.4248991012573242
Validation loss: 1.9796475492497927

Epoch: 6| Step: 10
Training loss: 0.7825446128845215
Validation loss: 1.9963992180362824

Epoch: 6| Step: 11
Training loss: 0.9581985473632812
Validation loss: 2.0266565635640132

Epoch: 6| Step: 12
Training loss: 1.643235445022583
Validation loss: 2.012692975741561

Epoch: 6| Step: 13
Training loss: 1.5976027250289917
Validation loss: 2.0224164570531538

Epoch: 156| Step: 0
Training loss: 0.9567615985870361
Validation loss: 2.0135113757143737

Epoch: 6| Step: 1
Training loss: 1.0761163234710693
Validation loss: 2.028051032814928

Epoch: 6| Step: 2
Training loss: 1.437889575958252
Validation loss: 2.0320486099489274

Epoch: 6| Step: 3
Training loss: 1.655288577079773
Validation loss: 2.0211596873498734

Epoch: 6| Step: 4
Training loss: 0.8768825531005859
Validation loss: 1.9954383527078936

Epoch: 6| Step: 5
Training loss: 1.768674612045288
Validation loss: 2.0113625936610724

Epoch: 6| Step: 6
Training loss: 1.8360271453857422
Validation loss: 2.0159703326481644

Epoch: 6| Step: 7
Training loss: 0.8247617483139038
Validation loss: 1.9704134002808602

Epoch: 6| Step: 8
Training loss: 1.248540997505188
Validation loss: 1.9629915875773276

Epoch: 6| Step: 9
Training loss: 1.3626806735992432
Validation loss: 1.9593558337098809

Epoch: 6| Step: 10
Training loss: 1.8802032470703125
Validation loss: 1.9721851246331328

Epoch: 6| Step: 11
Training loss: 1.2254278659820557
Validation loss: 1.9789416995099796

Epoch: 6| Step: 12
Training loss: 1.1429007053375244
Validation loss: 1.9975405329017228

Epoch: 6| Step: 13
Training loss: 1.293618083000183
Validation loss: 2.0048208262330744

Epoch: 157| Step: 0
Training loss: 1.3126764297485352
Validation loss: 2.00604223948653

Epoch: 6| Step: 1
Training loss: 1.310617446899414
Validation loss: 2.0189000124572427

Epoch: 6| Step: 2
Training loss: 0.849825382232666
Validation loss: 1.9864867810280091

Epoch: 6| Step: 3
Training loss: 1.2007677555084229
Validation loss: 1.9983612837329987

Epoch: 6| Step: 4
Training loss: 0.9356445074081421
Validation loss: 1.987170196348621

Epoch: 6| Step: 5
Training loss: 1.196200966835022
Validation loss: 2.000018594085529

Epoch: 6| Step: 6
Training loss: 1.0493135452270508
Validation loss: 2.0130759516069965

Epoch: 6| Step: 7
Training loss: 1.5512386560440063
Validation loss: 2.045399097986119

Epoch: 6| Step: 8
Training loss: 1.232116460800171
Validation loss: 2.0507688086519957

Epoch: 6| Step: 9
Training loss: 1.6171685457229614
Validation loss: 2.041361726740355

Epoch: 6| Step: 10
Training loss: 1.4151625633239746
Validation loss: 2.0296488167137228

Epoch: 6| Step: 11
Training loss: 1.6037960052490234
Validation loss: 1.9946443855121572

Epoch: 6| Step: 12
Training loss: 1.3860487937927246
Validation loss: 1.9630197043059974

Epoch: 6| Step: 13
Training loss: 1.751340389251709
Validation loss: 1.965070802678344

Epoch: 158| Step: 0
Training loss: 1.245145559310913
Validation loss: 1.9766205433876283

Epoch: 6| Step: 1
Training loss: 1.1129577159881592
Validation loss: 1.9743154612920617

Epoch: 6| Step: 2
Training loss: 1.4567441940307617
Validation loss: 2.0066179665186072

Epoch: 6| Step: 3
Training loss: 1.7229773998260498
Validation loss: 2.020000228317835

Epoch: 6| Step: 4
Training loss: 1.2931549549102783
Validation loss: 2.018496431330199

Epoch: 6| Step: 5
Training loss: 0.947479248046875
Validation loss: 1.9981721293541692

Epoch: 6| Step: 6
Training loss: 1.064704179763794
Validation loss: 1.9817480656408495

Epoch: 6| Step: 7
Training loss: 1.8636384010314941
Validation loss: 1.949543752977925

Epoch: 6| Step: 8
Training loss: 1.0429012775421143
Validation loss: 1.97245422486336

Epoch: 6| Step: 9
Training loss: 1.6553750038146973
Validation loss: 1.964858449915404

Epoch: 6| Step: 10
Training loss: 1.0060725212097168
Validation loss: 1.978108072793612

Epoch: 6| Step: 11
Training loss: 1.1280591487884521
Validation loss: 1.953620712603292

Epoch: 6| Step: 12
Training loss: 1.1999704837799072
Validation loss: 1.9391351117882678

Epoch: 6| Step: 13
Training loss: 1.4765877723693848
Validation loss: 1.9371027767017324

Epoch: 159| Step: 0
Training loss: 1.5417561531066895
Validation loss: 1.9410625619273032

Epoch: 6| Step: 1
Training loss: 1.3608779907226562
Validation loss: 1.9493153684882707

Epoch: 6| Step: 2
Training loss: 0.8042374849319458
Validation loss: 1.9897700894263484

Epoch: 6| Step: 3
Training loss: 1.1815869808197021
Validation loss: 1.9978174958177792

Epoch: 6| Step: 4
Training loss: 2.1049094200134277
Validation loss: 2.007896431030766

Epoch: 6| Step: 5
Training loss: 1.6034882068634033
Validation loss: 2.022904752403177

Epoch: 6| Step: 6
Training loss: 0.8978478908538818
Validation loss: 1.979097681660806

Epoch: 6| Step: 7
Training loss: 1.4074985980987549
Validation loss: 1.9558181839604531

Epoch: 6| Step: 8
Training loss: 1.0832916498184204
Validation loss: 1.9314302987949823

Epoch: 6| Step: 9
Training loss: 1.5299625396728516
Validation loss: 1.9506222650568972

Epoch: 6| Step: 10
Training loss: 0.987560510635376
Validation loss: 1.9606283582666868

Epoch: 6| Step: 11
Training loss: 1.2596423625946045
Validation loss: 1.9647008808710242

Epoch: 6| Step: 12
Training loss: 1.0781995058059692
Validation loss: 1.9416292944262106

Epoch: 6| Step: 13
Training loss: 1.5383036136627197
Validation loss: 1.9651224151734383

Epoch: 160| Step: 0
Training loss: 1.3651520013809204
Validation loss: 1.95710547636914

Epoch: 6| Step: 1
Training loss: 1.8172073364257812
Validation loss: 1.9712754603355163

Epoch: 6| Step: 2
Training loss: 0.8954476118087769
Validation loss: 1.9812171638652842

Epoch: 6| Step: 3
Training loss: 1.2396879196166992
Validation loss: 1.9954315385510843

Epoch: 6| Step: 4
Training loss: 1.1469231843948364
Validation loss: 2.0238200592738327

Epoch: 6| Step: 5
Training loss: 0.894496738910675
Validation loss: 2.0307441731934905

Epoch: 6| Step: 6
Training loss: 1.822005033493042
Validation loss: 2.0576525426680043

Epoch: 6| Step: 7
Training loss: 1.018698811531067
Validation loss: 2.0449236451938586

Epoch: 6| Step: 8
Training loss: 0.8752413392066956
Validation loss: 2.0174897242617864

Epoch: 6| Step: 9
Training loss: 1.3200783729553223
Validation loss: 1.990097879081644

Epoch: 6| Step: 10
Training loss: 1.6536571979522705
Validation loss: 1.9988789635319864

Epoch: 6| Step: 11
Training loss: 1.3067710399627686
Validation loss: 2.0016351592156196

Epoch: 6| Step: 12
Training loss: 1.4390068054199219
Validation loss: 1.9782323401461366

Epoch: 6| Step: 13
Training loss: 0.7610315680503845
Validation loss: 1.9594637629806355

Epoch: 161| Step: 0
Training loss: 0.9056576490402222
Validation loss: 1.952388850591516

Epoch: 6| Step: 1
Training loss: 1.5620235204696655
Validation loss: 1.9455337973051174

Epoch: 6| Step: 2
Training loss: 1.5049469470977783
Validation loss: 1.9157915974176059

Epoch: 6| Step: 3
Training loss: 0.931309700012207
Validation loss: 1.9237142121920021

Epoch: 6| Step: 4
Training loss: 1.9661145210266113
Validation loss: 1.9206092357635498

Epoch: 6| Step: 5
Training loss: 1.0521440505981445
Validation loss: 1.9598981334317116

Epoch: 6| Step: 6
Training loss: 1.206489086151123
Validation loss: 2.002064105003111

Epoch: 6| Step: 7
Training loss: 1.3823680877685547
Validation loss: 2.01945585332891

Epoch: 6| Step: 8
Training loss: 0.9993153214454651
Validation loss: 2.049629388316985

Epoch: 6| Step: 9
Training loss: 1.1985456943511963
Validation loss: 2.0374868710835776

Epoch: 6| Step: 10
Training loss: 0.8352352380752563
Validation loss: 2.0034984132295013

Epoch: 6| Step: 11
Training loss: 1.8117153644561768
Validation loss: 1.9993502170808855

Epoch: 6| Step: 12
Training loss: 0.9270073175430298
Validation loss: 1.9658408549524122

Epoch: 6| Step: 13
Training loss: 1.6333304643630981
Validation loss: 1.9763425345061927

Epoch: 162| Step: 0
Training loss: 0.9355295896530151
Validation loss: 1.972535006461605

Epoch: 6| Step: 1
Training loss: 0.9431712627410889
Validation loss: 1.9716702750934068

Epoch: 6| Step: 2
Training loss: 1.4849867820739746
Validation loss: 1.9811279491711689

Epoch: 6| Step: 3
Training loss: 0.9396470785140991
Validation loss: 1.963406567932457

Epoch: 6| Step: 4
Training loss: 1.4660896062850952
Validation loss: 1.9797369921079246

Epoch: 6| Step: 5
Training loss: 0.8462056517601013
Validation loss: 1.975110548798756

Epoch: 6| Step: 6
Training loss: 0.9765409231185913
Validation loss: 1.9771011157702374

Epoch: 6| Step: 7
Training loss: 1.3335431814193726
Validation loss: 1.9984451545182096

Epoch: 6| Step: 8
Training loss: 2.1473498344421387
Validation loss: 2.0336074034372964

Epoch: 6| Step: 9
Training loss: 1.8715522289276123
Validation loss: 2.011443422686669

Epoch: 6| Step: 10
Training loss: 1.1539726257324219
Validation loss: 1.9925955508344917

Epoch: 6| Step: 11
Training loss: 0.846703052520752
Validation loss: 1.9667892943146408

Epoch: 6| Step: 12
Training loss: 1.3278145790100098
Validation loss: 1.9558386571945683

Epoch: 6| Step: 13
Training loss: 1.3486100435256958
Validation loss: 1.9516964292013517

Epoch: 163| Step: 0
Training loss: 1.4327263832092285
Validation loss: 1.9481178599019204

Epoch: 6| Step: 1
Training loss: 0.9316800832748413
Validation loss: 1.9914218687242078

Epoch: 6| Step: 2
Training loss: 1.35178542137146
Validation loss: 2.027900670164375

Epoch: 6| Step: 3
Training loss: 0.9854874610900879
Validation loss: 2.0499830502335743

Epoch: 6| Step: 4
Training loss: 0.9214843511581421
Validation loss: 2.059354261685443

Epoch: 6| Step: 5
Training loss: 1.1672980785369873
Validation loss: 2.0373516159672893

Epoch: 6| Step: 6
Training loss: 1.1498827934265137
Validation loss: 2.001140876482892

Epoch: 6| Step: 7
Training loss: 1.1874611377716064
Validation loss: 2.025964762574883

Epoch: 6| Step: 8
Training loss: 1.651029348373413
Validation loss: 2.011491943431157

Epoch: 6| Step: 9
Training loss: 1.6599090099334717
Validation loss: 2.049687139449581

Epoch: 6| Step: 10
Training loss: 1.381107211112976
Validation loss: 2.079777168971236

Epoch: 6| Step: 11
Training loss: 1.533982515335083
Validation loss: 2.101598797305938

Epoch: 6| Step: 12
Training loss: 1.6941728591918945
Validation loss: 2.1011480964640135

Epoch: 6| Step: 13
Training loss: 0.7742183208465576
Validation loss: 2.0891849584476923

Epoch: 164| Step: 0
Training loss: 1.4562804698944092
Validation loss: 2.068310619682394

Epoch: 6| Step: 1
Training loss: 1.1021044254302979
Validation loss: 2.0250569492258053

Epoch: 6| Step: 2
Training loss: 1.6143702268600464
Validation loss: 1.994099086330783

Epoch: 6| Step: 3
Training loss: 1.0615519285202026
Validation loss: 2.0120808565488426

Epoch: 6| Step: 4
Training loss: 0.8954179883003235
Validation loss: 1.978408436621389

Epoch: 6| Step: 5
Training loss: 1.103224277496338
Validation loss: 1.965699957263085

Epoch: 6| Step: 6
Training loss: 0.8062101602554321
Validation loss: 1.977477788925171

Epoch: 6| Step: 7
Training loss: 1.2366359233856201
Validation loss: 1.975437105342906

Epoch: 6| Step: 8
Training loss: 1.3115816116333008
Validation loss: 1.9977666793331024

Epoch: 6| Step: 9
Training loss: 1.3006083965301514
Validation loss: 1.989752859197637

Epoch: 6| Step: 10
Training loss: 1.2235939502716064
Validation loss: 1.9809844647684405

Epoch: 6| Step: 11
Training loss: 1.3126134872436523
Validation loss: 1.9617599876978065

Epoch: 6| Step: 12
Training loss: 1.3172156810760498
Validation loss: 1.969417074675201

Epoch: 6| Step: 13
Training loss: 1.4952112436294556
Validation loss: 1.9576253326990272

Epoch: 165| Step: 0
Training loss: 1.393477439880371
Validation loss: 1.9479535266917238

Epoch: 6| Step: 1
Training loss: 1.312135934829712
Validation loss: 1.963707306051767

Epoch: 6| Step: 2
Training loss: 1.3629781007766724
Validation loss: 1.9753981790234965

Epoch: 6| Step: 3
Training loss: 0.7991682291030884
Validation loss: 1.9780037236470047

Epoch: 6| Step: 4
Training loss: 1.0687627792358398
Validation loss: 1.9942976633707683

Epoch: 6| Step: 5
Training loss: 1.2132914066314697
Validation loss: 1.9860665952005694

Epoch: 6| Step: 6
Training loss: 0.7435488700866699
Validation loss: 1.9854583137778825

Epoch: 6| Step: 7
Training loss: 0.9469473361968994
Validation loss: 1.964651532070611

Epoch: 6| Step: 8
Training loss: 1.4409942626953125
Validation loss: 1.946250323326357

Epoch: 6| Step: 9
Training loss: 1.156639814376831
Validation loss: 1.9361421933738134

Epoch: 6| Step: 10
Training loss: 1.0225181579589844
Validation loss: 1.9403967806088027

Epoch: 6| Step: 11
Training loss: 2.0337815284729004
Validation loss: 1.9341038952591598

Epoch: 6| Step: 12
Training loss: 1.2743592262268066
Validation loss: 1.9206296872067194

Epoch: 6| Step: 13
Training loss: 1.0905916690826416
Validation loss: 1.9215534605005735

Epoch: 166| Step: 0
Training loss: 0.5878613591194153
Validation loss: 1.9325013673433693

Epoch: 6| Step: 1
Training loss: 1.2612779140472412
Validation loss: 1.9326321745431552

Epoch: 6| Step: 2
Training loss: 1.481898307800293
Validation loss: 1.9739594485170098

Epoch: 6| Step: 3
Training loss: 0.8164792060852051
Validation loss: 1.9735528666486022

Epoch: 6| Step: 4
Training loss: 1.58860445022583
Validation loss: 1.9776973570546796

Epoch: 6| Step: 5
Training loss: 0.7629289627075195
Validation loss: 1.9720811664417226

Epoch: 6| Step: 6
Training loss: 1.282787561416626
Validation loss: 1.9624188523138724

Epoch: 6| Step: 7
Training loss: 1.1488075256347656
Validation loss: 1.9422872399771085

Epoch: 6| Step: 8
Training loss: 0.7999649047851562
Validation loss: 1.9816721203506633

Epoch: 6| Step: 9
Training loss: 1.411381483078003
Validation loss: 1.9997284591838878

Epoch: 6| Step: 10
Training loss: 1.739187240600586
Validation loss: 1.9871420245016775

Epoch: 6| Step: 11
Training loss: 1.1666702032089233
Validation loss: 1.9976263315446916

Epoch: 6| Step: 12
Training loss: 1.2883946895599365
Validation loss: 1.9816879815952753

Epoch: 6| Step: 13
Training loss: 1.6606158018112183
Validation loss: 1.9458129700794016

Epoch: 167| Step: 0
Training loss: 1.2787184715270996
Validation loss: 1.9522140526002454

Epoch: 6| Step: 1
Training loss: 0.5838556289672852
Validation loss: 1.928615580322922

Epoch: 6| Step: 2
Training loss: 1.057417869567871
Validation loss: 1.9439103885363507

Epoch: 6| Step: 3
Training loss: 1.0891942977905273
Validation loss: 1.9368944232181837

Epoch: 6| Step: 4
Training loss: 1.1360089778900146
Validation loss: 1.952008484512247

Epoch: 6| Step: 5
Training loss: 1.2859175205230713
Validation loss: 1.9666668202287407

Epoch: 6| Step: 6
Training loss: 1.5915143489837646
Validation loss: 1.9785202216076594

Epoch: 6| Step: 7
Training loss: 1.128849983215332
Validation loss: 1.9833176776927004

Epoch: 6| Step: 8
Training loss: 1.4267975091934204
Validation loss: 1.9835610671709942

Epoch: 6| Step: 9
Training loss: 1.04296875
Validation loss: 2.0001246736895655

Epoch: 6| Step: 10
Training loss: 1.1626839637756348
Validation loss: 1.971210793782306

Epoch: 6| Step: 11
Training loss: 1.648646593093872
Validation loss: 1.979973909675434

Epoch: 6| Step: 12
Training loss: 1.6226272583007812
Validation loss: 1.968145590956493

Epoch: 6| Step: 13
Training loss: 1.0329362154006958
Validation loss: 1.925545907789661

Epoch: 168| Step: 0
Training loss: 0.8835758566856384
Validation loss: 1.897696638620028

Epoch: 6| Step: 1
Training loss: 0.5397816300392151
Validation loss: 1.955614161747758

Epoch: 6| Step: 2
Training loss: 1.505367636680603
Validation loss: 2.0256902287083287

Epoch: 6| Step: 3
Training loss: 1.6751610040664673
Validation loss: 2.0621855361487276

Epoch: 6| Step: 4
Training loss: 1.2912194728851318
Validation loss: 2.0110759132651874

Epoch: 6| Step: 5
Training loss: 1.3708504438400269
Validation loss: 1.96078319703379

Epoch: 6| Step: 6
Training loss: 1.3470135927200317
Validation loss: 1.9293705827446395

Epoch: 6| Step: 7
Training loss: 1.113020420074463
Validation loss: 1.913808726495312

Epoch: 6| Step: 8
Training loss: 1.7434940338134766
Validation loss: 1.9205282413831322

Epoch: 6| Step: 9
Training loss: 1.82851243019104
Validation loss: 1.941496136367962

Epoch: 6| Step: 10
Training loss: 1.0702577829360962
Validation loss: 1.95654635788292

Epoch: 6| Step: 11
Training loss: 0.8706511855125427
Validation loss: 1.9704651089124783

Epoch: 6| Step: 12
Training loss: 1.2689437866210938
Validation loss: 1.953089400004315

Epoch: 6| Step: 13
Training loss: 1.3458157777786255
Validation loss: 1.9676551652211014

Epoch: 169| Step: 0
Training loss: 1.1319787502288818
Validation loss: 1.9880837983982538

Epoch: 6| Step: 1
Training loss: 1.0384562015533447
Validation loss: 2.0042026863303235

Epoch: 6| Step: 2
Training loss: 1.1634727716445923
Validation loss: 1.9892331541225474

Epoch: 6| Step: 3
Training loss: 1.221229076385498
Validation loss: 1.968745836647608

Epoch: 6| Step: 4
Training loss: 1.0292243957519531
Validation loss: 1.9396352562853085

Epoch: 6| Step: 5
Training loss: 0.9493311643600464
Validation loss: 1.9351781645128805

Epoch: 6| Step: 6
Training loss: 1.0590081214904785
Validation loss: 1.9352892150161087

Epoch: 6| Step: 7
Training loss: 1.6358799934387207
Validation loss: 1.925663237930626

Epoch: 6| Step: 8
Training loss: 1.2328822612762451
Validation loss: 1.9304608414250035

Epoch: 6| Step: 9
Training loss: 1.0732553005218506
Validation loss: 1.9148254266349218

Epoch: 6| Step: 10
Training loss: 1.369497299194336
Validation loss: 1.9279750829101892

Epoch: 6| Step: 11
Training loss: 1.533228874206543
Validation loss: 1.9373091138819212

Epoch: 6| Step: 12
Training loss: 0.9262923002243042
Validation loss: 1.9477327062237648

Epoch: 6| Step: 13
Training loss: 0.8579372763633728
Validation loss: 1.9417632061948058

Epoch: 170| Step: 0
Training loss: 1.284561276435852
Validation loss: 1.9379927035300963

Epoch: 6| Step: 1
Training loss: 1.2158784866333008
Validation loss: 1.9424234923496042

Epoch: 6| Step: 2
Training loss: 1.4224705696105957
Validation loss: 1.9718236897581367

Epoch: 6| Step: 3
Training loss: 0.6024743318557739
Validation loss: 1.9807326204033309

Epoch: 6| Step: 4
Training loss: 1.3590705394744873
Validation loss: 1.982835978590032

Epoch: 6| Step: 5
Training loss: 0.7626992464065552
Validation loss: 1.9807423494195426

Epoch: 6| Step: 6
Training loss: 1.1781355142593384
Validation loss: 2.0246199305339525

Epoch: 6| Step: 7
Training loss: 0.7618889808654785
Validation loss: 2.043192184099587

Epoch: 6| Step: 8
Training loss: 1.4381784200668335
Validation loss: 2.0392230556857203

Epoch: 6| Step: 9
Training loss: 1.5906314849853516
Validation loss: 2.036470215807679

Epoch: 6| Step: 10
Training loss: 1.7721225023269653
Validation loss: 2.014674622525451

Epoch: 6| Step: 11
Training loss: 1.3234269618988037
Validation loss: 1.9894366072070213

Epoch: 6| Step: 12
Training loss: 0.8821306228637695
Validation loss: 1.9765401924810102

Epoch: 6| Step: 13
Training loss: 0.776714026927948
Validation loss: 1.9340194040729153

Epoch: 171| Step: 0
Training loss: 0.6624708771705627
Validation loss: 1.9175897644412132

Epoch: 6| Step: 1
Training loss: 0.9057886004447937
Validation loss: 1.9161919470756286

Epoch: 6| Step: 2
Training loss: 0.8157376050949097
Validation loss: 1.92982094646782

Epoch: 6| Step: 3
Training loss: 1.4558168649673462
Validation loss: 1.9591390368758992

Epoch: 6| Step: 4
Training loss: 1.493080496788025
Validation loss: 1.9923562349811677

Epoch: 6| Step: 5
Training loss: 1.5361523628234863
Validation loss: 1.9583862699488157

Epoch: 6| Step: 6
Training loss: 0.4440954327583313
Validation loss: 1.942892925713652

Epoch: 6| Step: 7
Training loss: 1.09305739402771
Validation loss: 1.9215643405914307

Epoch: 6| Step: 8
Training loss: 0.9814037084579468
Validation loss: 1.908891188201084

Epoch: 6| Step: 9
Training loss: 1.1788506507873535
Validation loss: 1.9363052332273094

Epoch: 6| Step: 10
Training loss: 0.8596518039703369
Validation loss: 1.911764467916181

Epoch: 6| Step: 11
Training loss: 1.497941255569458
Validation loss: 1.8952979182684293

Epoch: 6| Step: 12
Training loss: 1.8602794408798218
Validation loss: 1.8939291789967527

Epoch: 6| Step: 13
Training loss: 1.6745065450668335
Validation loss: 1.8769152318277667

Epoch: 172| Step: 0
Training loss: 1.1119933128356934
Validation loss: 1.8720352854779971

Epoch: 6| Step: 1
Training loss: 1.3188878297805786
Validation loss: 1.8758879374432307

Epoch: 6| Step: 2
Training loss: 1.1849445104599
Validation loss: 1.9002864591536983

Epoch: 6| Step: 3
Training loss: 1.4616551399230957
Validation loss: 1.88739808400472

Epoch: 6| Step: 4
Training loss: 0.9367610812187195
Validation loss: 1.9113108009420416

Epoch: 6| Step: 5
Training loss: 1.0372889041900635
Validation loss: 1.8867939620889642

Epoch: 6| Step: 6
Training loss: 1.1534709930419922
Validation loss: 1.8893965931348904

Epoch: 6| Step: 7
Training loss: 1.2309508323669434
Validation loss: 1.902552959739521

Epoch: 6| Step: 8
Training loss: 1.114957571029663
Validation loss: 1.8916682568929528

Epoch: 6| Step: 9
Training loss: 0.5924138426780701
Validation loss: 1.8980685434033793

Epoch: 6| Step: 10
Training loss: 1.074563980102539
Validation loss: 1.945343432887908

Epoch: 6| Step: 11
Training loss: 0.7726142406463623
Validation loss: 1.9426934103811941

Epoch: 6| Step: 12
Training loss: 1.8193731307983398
Validation loss: 1.9556244816831363

Epoch: 6| Step: 13
Training loss: 1.3362722396850586
Validation loss: 1.97563353917932

Epoch: 173| Step: 0
Training loss: 1.2833192348480225
Validation loss: 1.9703161729279386

Epoch: 6| Step: 1
Training loss: 1.5866291522979736
Validation loss: 1.9666438384722638

Epoch: 6| Step: 2
Training loss: 0.812332808971405
Validation loss: 1.9618234967672696

Epoch: 6| Step: 3
Training loss: 1.831857442855835
Validation loss: 1.9270160916031047

Epoch: 6| Step: 4
Training loss: 0.991638720035553
Validation loss: 1.897408095739221

Epoch: 6| Step: 5
Training loss: 0.8632534742355347
Validation loss: 1.907265293982721

Epoch: 6| Step: 6
Training loss: 1.041741967201233
Validation loss: 1.8858234805445517

Epoch: 6| Step: 7
Training loss: 1.5039739608764648
Validation loss: 1.878965977699526

Epoch: 6| Step: 8
Training loss: 1.3649470806121826
Validation loss: 1.9117796151868758

Epoch: 6| Step: 9
Training loss: 0.8313709497451782
Validation loss: 1.9288275805852746

Epoch: 6| Step: 10
Training loss: 1.3358418941497803
Validation loss: 1.9384781583662956

Epoch: 6| Step: 11
Training loss: 0.9680572152137756
Validation loss: 1.8932538391441427

Epoch: 6| Step: 12
Training loss: 0.7377387285232544
Validation loss: 1.8726594012270692

Epoch: 6| Step: 13
Training loss: 0.5089304447174072
Validation loss: 1.8832035872244066

Epoch: 174| Step: 0
Training loss: 1.0336663722991943
Validation loss: 1.867644977825944

Epoch: 6| Step: 1
Training loss: 0.8857762813568115
Validation loss: 1.8602662599214943

Epoch: 6| Step: 2
Training loss: 1.0661284923553467
Validation loss: 1.894065091686864

Epoch: 6| Step: 3
Training loss: 0.8208341598510742
Validation loss: 1.916371004555815

Epoch: 6| Step: 4
Training loss: 1.3161799907684326
Validation loss: 1.9135792229765205

Epoch: 6| Step: 5
Training loss: 1.5466699600219727
Validation loss: 1.9103170376951977

Epoch: 6| Step: 6
Training loss: 1.0412726402282715
Validation loss: 1.9050283252551992

Epoch: 6| Step: 7
Training loss: 0.9326990842819214
Validation loss: 1.9308441608182845

Epoch: 6| Step: 8
Training loss: 1.6393380165100098
Validation loss: 1.936316442745988

Epoch: 6| Step: 9
Training loss: 0.694171130657196
Validation loss: 1.9673318721914803

Epoch: 6| Step: 10
Training loss: 1.0339773893356323
Validation loss: 1.9751666258740168

Epoch: 6| Step: 11
Training loss: 1.7877171039581299
Validation loss: 1.9976130480407386

Epoch: 6| Step: 12
Training loss: 1.1837544441223145
Validation loss: 1.990844912426446

Epoch: 6| Step: 13
Training loss: 0.41847294569015503
Validation loss: 1.978298612820205

Epoch: 175| Step: 0
Training loss: 0.9599645137786865
Validation loss: 1.9850285912072787

Epoch: 6| Step: 1
Training loss: 1.262866497039795
Validation loss: 1.9569293196483324

Epoch: 6| Step: 2
Training loss: 0.9138438701629639
Validation loss: 1.9224058787027996

Epoch: 6| Step: 3
Training loss: 0.9955617189407349
Validation loss: 1.9086399104005547

Epoch: 6| Step: 4
Training loss: 1.1600351333618164
Validation loss: 1.9069413318428943

Epoch: 6| Step: 5
Training loss: 0.47359275817871094
Validation loss: 1.9161177886429654

Epoch: 6| Step: 6
Training loss: 1.1745787858963013
Validation loss: 1.9232633998317104

Epoch: 6| Step: 7
Training loss: 1.3168654441833496
Validation loss: 1.9236604705933602

Epoch: 6| Step: 8
Training loss: 1.2164225578308105
Validation loss: 1.9419330730233142

Epoch: 6| Step: 9
Training loss: 1.2575515508651733
Validation loss: 1.9427846670150757

Epoch: 6| Step: 10
Training loss: 1.4088265895843506
Validation loss: 1.9056182702382405

Epoch: 6| Step: 11
Training loss: 0.8735724091529846
Validation loss: 1.8994893745709491

Epoch: 6| Step: 12
Training loss: 0.9777540564537048
Validation loss: 1.8841490386634745

Epoch: 6| Step: 13
Training loss: 1.493125081062317
Validation loss: 1.8483790966772264

Epoch: 176| Step: 0
Training loss: 1.0189099311828613
Validation loss: 1.8455435652886667

Epoch: 6| Step: 1
Training loss: 1.3065054416656494
Validation loss: 1.860417333982324

Epoch: 6| Step: 2
Training loss: 1.1636486053466797
Validation loss: 1.8731685569209438

Epoch: 6| Step: 3
Training loss: 0.769805908203125
Validation loss: 1.8866914779909196

Epoch: 6| Step: 4
Training loss: 0.9999815225601196
Validation loss: 1.9241206428056121

Epoch: 6| Step: 5
Training loss: 1.1044576168060303
Validation loss: 1.920298054654111

Epoch: 6| Step: 6
Training loss: 0.9520300030708313
Validation loss: 1.9336921181730045

Epoch: 6| Step: 7
Training loss: 0.9281942844390869
Validation loss: 1.9326517889576573

Epoch: 6| Step: 8
Training loss: 1.3529545068740845
Validation loss: 1.9313715119515695

Epoch: 6| Step: 9
Training loss: 1.6017963886260986
Validation loss: 1.9041620095570881

Epoch: 6| Step: 10
Training loss: 1.121619701385498
Validation loss: 1.9012594351204493

Epoch: 6| Step: 11
Training loss: 0.9966943264007568
Validation loss: 1.891611332534462

Epoch: 6| Step: 12
Training loss: 1.211437702178955
Validation loss: 1.9054972048728698

Epoch: 6| Step: 13
Training loss: 0.8667381405830383
Validation loss: 1.893928579104844

Epoch: 177| Step: 0
Training loss: 1.1899441480636597
Validation loss: 1.883761163680784

Epoch: 6| Step: 1
Training loss: 1.327522873878479
Validation loss: 1.8819041752046155

Epoch: 6| Step: 2
Training loss: 1.3642027378082275
Validation loss: 1.8643122988362466

Epoch: 6| Step: 3
Training loss: 0.6830160617828369
Validation loss: 1.8493792215983074

Epoch: 6| Step: 4
Training loss: 0.8658024072647095
Validation loss: 1.9159506597826559

Epoch: 6| Step: 5
Training loss: 1.5153955221176147
Validation loss: 1.9366790453592937

Epoch: 6| Step: 6
Training loss: 0.7031981945037842
Validation loss: 1.9469350050854426

Epoch: 6| Step: 7
Training loss: 1.100170612335205
Validation loss: 1.939898544742215

Epoch: 6| Step: 8
Training loss: 1.1348435878753662
Validation loss: 1.8801182136740735

Epoch: 6| Step: 9
Training loss: 0.6673208475112915
Validation loss: 1.8870425839577951

Epoch: 6| Step: 10
Training loss: 1.1357734203338623
Validation loss: 1.8810592005329747

Epoch: 6| Step: 11
Training loss: 0.8887126445770264
Validation loss: 1.9027035595268331

Epoch: 6| Step: 12
Training loss: 1.4193408489227295
Validation loss: 1.9126501044919413

Epoch: 6| Step: 13
Training loss: 1.8388476371765137
Validation loss: 1.9345120665847615

Epoch: 178| Step: 0
Training loss: 1.3169625997543335
Validation loss: 1.910143836852043

Epoch: 6| Step: 1
Training loss: 1.2060308456420898
Validation loss: 1.918958975422767

Epoch: 6| Step: 2
Training loss: 0.6043813824653625
Validation loss: 1.9097531252009894

Epoch: 6| Step: 3
Training loss: 1.7030779123306274
Validation loss: 1.9128608908704532

Epoch: 6| Step: 4
Training loss: 1.037620186805725
Validation loss: 1.9061618979259203

Epoch: 6| Step: 5
Training loss: 0.5931994915008545
Validation loss: 1.8985192160452566

Epoch: 6| Step: 6
Training loss: 0.684969425201416
Validation loss: 1.901218541206852

Epoch: 6| Step: 7
Training loss: 1.2320024967193604
Validation loss: 1.876838384136077

Epoch: 6| Step: 8
Training loss: 1.0773603916168213
Validation loss: 1.8616175292640604

Epoch: 6| Step: 9
Training loss: 1.2250765562057495
Validation loss: 1.8646241452104302

Epoch: 6| Step: 10
Training loss: 1.5401302576065063
Validation loss: 1.8477569472405218

Epoch: 6| Step: 11
Training loss: 0.5844920873641968
Validation loss: 1.840268196598176

Epoch: 6| Step: 12
Training loss: 0.7860961556434631
Validation loss: 1.8789415410769883

Epoch: 6| Step: 13
Training loss: 1.4061514139175415
Validation loss: 1.878865562459474

Epoch: 179| Step: 0
Training loss: 1.1243860721588135
Validation loss: 1.9045074575690812

Epoch: 6| Step: 1
Training loss: 1.1046156883239746
Validation loss: 1.9011595966995403

Epoch: 6| Step: 2
Training loss: 0.8612185716629028
Validation loss: 1.899488527287719

Epoch: 6| Step: 3
Training loss: 1.1932923793792725
Validation loss: 1.9237020323353429

Epoch: 6| Step: 4
Training loss: 0.9880925416946411
Validation loss: 1.9119105749232794

Epoch: 6| Step: 5
Training loss: 1.168370246887207
Validation loss: 1.9281479594528035

Epoch: 6| Step: 6
Training loss: 0.7813012599945068
Validation loss: 1.9158394029063563

Epoch: 6| Step: 7
Training loss: 0.9627198576927185
Validation loss: 1.9128273123054094

Epoch: 6| Step: 8
Training loss: 1.2856061458587646
Validation loss: 1.9121914422640236

Epoch: 6| Step: 9
Training loss: 1.1394298076629639
Validation loss: 1.9056267020522908

Epoch: 6| Step: 10
Training loss: 1.1851550340652466
Validation loss: 1.8807530915865334

Epoch: 6| Step: 11
Training loss: 0.937242865562439
Validation loss: 1.861046503948909

Epoch: 6| Step: 12
Training loss: 1.1664279699325562
Validation loss: 1.8570193077928276

Epoch: 6| Step: 13
Training loss: 1.063322901725769
Validation loss: 1.849321255119898

Epoch: 180| Step: 0
Training loss: 0.7499194145202637
Validation loss: 1.8594001672601188

Epoch: 6| Step: 1
Training loss: 1.2754881381988525
Validation loss: 1.8951689222807526

Epoch: 6| Step: 2
Training loss: 0.8636811971664429
Validation loss: 1.9312724644137966

Epoch: 6| Step: 3
Training loss: 1.1709718704223633
Validation loss: 1.8943485829137987

Epoch: 6| Step: 4
Training loss: 1.466811180114746
Validation loss: 1.885885819312065

Epoch: 6| Step: 5
Training loss: 0.9451940059661865
Validation loss: 1.896186194112224

Epoch: 6| Step: 6
Training loss: 0.782079815864563
Validation loss: 1.9008238110491025

Epoch: 6| Step: 7
Training loss: 1.127549648284912
Validation loss: 1.8978141494976577

Epoch: 6| Step: 8
Training loss: 1.1284316778182983
Validation loss: 1.882134965671006

Epoch: 6| Step: 9
Training loss: 1.0658187866210938
Validation loss: 1.9139586443542151

Epoch: 6| Step: 10
Training loss: 0.939987301826477
Validation loss: 1.942529280980428

Epoch: 6| Step: 11
Training loss: 1.104888916015625
Validation loss: 1.932294298243779

Epoch: 6| Step: 12
Training loss: 0.8822304010391235
Validation loss: 1.8967931552599835

Epoch: 6| Step: 13
Training loss: 1.273434042930603
Validation loss: 1.8601930051721551

Epoch: 181| Step: 0
Training loss: 1.2869255542755127
Validation loss: 1.8595223042272753

Epoch: 6| Step: 1
Training loss: 1.3661205768585205
Validation loss: 1.8545305421275478

Epoch: 6| Step: 2
Training loss: 1.4348477125167847
Validation loss: 1.830748596499043

Epoch: 6| Step: 3
Training loss: 0.6612508296966553
Validation loss: 1.828557784839343

Epoch: 6| Step: 4
Training loss: 0.7831885814666748
Validation loss: 1.860064414239699

Epoch: 6| Step: 5
Training loss: 1.0009821653366089
Validation loss: 1.9084852280155304

Epoch: 6| Step: 6
Training loss: 1.219247579574585
Validation loss: 1.922557791074117

Epoch: 6| Step: 7
Training loss: 1.0154508352279663
Validation loss: 1.9621572443234023

Epoch: 6| Step: 8
Training loss: 0.7514705657958984
Validation loss: 1.9803538104539276

Epoch: 6| Step: 9
Training loss: 1.6463918685913086
Validation loss: 1.9774011963157243

Epoch: 6| Step: 10
Training loss: 0.62786865234375
Validation loss: 1.9479781363600044

Epoch: 6| Step: 11
Training loss: 0.7430875301361084
Validation loss: 1.934021431912658

Epoch: 6| Step: 12
Training loss: 1.4279263019561768
Validation loss: 1.91900497610851

Epoch: 6| Step: 13
Training loss: 0.9955810904502869
Validation loss: 1.9369492864096036

Epoch: 182| Step: 0
Training loss: 0.5045733451843262
Validation loss: 1.9680593962310462

Epoch: 6| Step: 1
Training loss: 1.456955909729004
Validation loss: 1.9465703643778318

Epoch: 6| Step: 2
Training loss: 1.2080905437469482
Validation loss: 1.983286690968339

Epoch: 6| Step: 3
Training loss: 1.0775452852249146
Validation loss: 1.9865983686139506

Epoch: 6| Step: 4
Training loss: 1.340158462524414
Validation loss: 1.949074883614817

Epoch: 6| Step: 5
Training loss: 0.8671867251396179
Validation loss: 1.9079274041678316

Epoch: 6| Step: 6
Training loss: 0.9042903184890747
Validation loss: 1.9047958415041688

Epoch: 6| Step: 7
Training loss: 1.0839228630065918
Validation loss: 1.8714605351930023

Epoch: 6| Step: 8
Training loss: 1.2682558298110962
Validation loss: 1.8519017773289834

Epoch: 6| Step: 9
Training loss: 1.544102430343628
Validation loss: 1.8427725171530118

Epoch: 6| Step: 10
Training loss: 0.995832622051239
Validation loss: 1.834382519927076

Epoch: 6| Step: 11
Training loss: 0.882885754108429
Validation loss: 1.8757845227436354

Epoch: 6| Step: 12
Training loss: 0.56577467918396
Validation loss: 1.8813477177773752

Epoch: 6| Step: 13
Training loss: 1.4255362749099731
Validation loss: 1.9205474981697657

Epoch: 183| Step: 0
Training loss: 0.6199502944946289
Validation loss: 1.9507771422786098

Epoch: 6| Step: 1
Training loss: 1.636759877204895
Validation loss: 1.9789948514712754

Epoch: 6| Step: 2
Training loss: 0.4706132709980011
Validation loss: 1.9659277444244714

Epoch: 6| Step: 3
Training loss: 1.4293462038040161
Validation loss: 1.9382499238496185

Epoch: 6| Step: 4
Training loss: 0.9540195465087891
Validation loss: 1.886620145972057

Epoch: 6| Step: 5
Training loss: 1.0629384517669678
Validation loss: 1.8772272320203884

Epoch: 6| Step: 6
Training loss: 1.4469311237335205
Validation loss: 1.8540772904631913

Epoch: 6| Step: 7
Training loss: 1.1639857292175293
Validation loss: 1.868062933286031

Epoch: 6| Step: 8
Training loss: 1.0766091346740723
Validation loss: 1.8209314179676834

Epoch: 6| Step: 9
Training loss: 0.8293245434761047
Validation loss: 1.8217325031116445

Epoch: 6| Step: 10
Training loss: 1.1226825714111328
Validation loss: 1.805202772540431

Epoch: 6| Step: 11
Training loss: 1.2898509502410889
Validation loss: 1.8086014037491174

Epoch: 6| Step: 12
Training loss: 0.9921056032180786
Validation loss: 1.819228849103374

Epoch: 6| Step: 13
Training loss: 0.5455180406570435
Validation loss: 1.848677344219659

Epoch: 184| Step: 0
Training loss: 1.1296052932739258
Validation loss: 1.8732851653970697

Epoch: 6| Step: 1
Training loss: 1.1828582286834717
Validation loss: 1.8812829935422508

Epoch: 6| Step: 2
Training loss: 1.3665541410446167
Validation loss: 1.8724360645458262

Epoch: 6| Step: 3
Training loss: 0.5842545628547668
Validation loss: 1.8840256006486955

Epoch: 6| Step: 4
Training loss: 1.2278050184249878
Validation loss: 1.8506995298529183

Epoch: 6| Step: 5
Training loss: 0.8038193583488464
Validation loss: 1.8498388516005648

Epoch: 6| Step: 6
Training loss: 0.6249473690986633
Validation loss: 1.8433268249675792

Epoch: 6| Step: 7
Training loss: 0.8615209460258484
Validation loss: 1.8554615705244002

Epoch: 6| Step: 8
Training loss: 1.0864728689193726
Validation loss: 1.8836007079770487

Epoch: 6| Step: 9
Training loss: 1.055410385131836
Validation loss: 1.9022399199906217

Epoch: 6| Step: 10
Training loss: 1.5387598276138306
Validation loss: 1.9111353684497137

Epoch: 6| Step: 11
Training loss: 1.3210710287094116
Validation loss: 1.919263732048773

Epoch: 6| Step: 12
Training loss: 0.5648701190948486
Validation loss: 1.9159481922785442

Epoch: 6| Step: 13
Training loss: 1.1805856227874756
Validation loss: 1.9252369378202705

Epoch: 185| Step: 0
Training loss: 0.5804553031921387
Validation loss: 1.9331494005777503

Epoch: 6| Step: 1
Training loss: 1.0739202499389648
Validation loss: 1.9176971489383328

Epoch: 6| Step: 2
Training loss: 0.8181996941566467
Validation loss: 1.9371149283583446

Epoch: 6| Step: 3
Training loss: 0.9793713688850403
Validation loss: 1.920817543101567

Epoch: 6| Step: 4
Training loss: 1.5591771602630615
Validation loss: 1.8952653997687883

Epoch: 6| Step: 5
Training loss: 1.6153852939605713
Validation loss: 1.8971347129473122

Epoch: 6| Step: 6
Training loss: 1.1769535541534424
Validation loss: 1.8817494095012706

Epoch: 6| Step: 7
Training loss: 0.6184725165367126
Validation loss: 1.8988643538567327

Epoch: 6| Step: 8
Training loss: 0.9578332901000977
Validation loss: 1.8921420779279483

Epoch: 6| Step: 9
Training loss: 1.4435150623321533
Validation loss: 1.8923451874845771

Epoch: 6| Step: 10
Training loss: 0.7658255100250244
Validation loss: 1.9073356479726813

Epoch: 6| Step: 11
Training loss: 0.7319804430007935
Validation loss: 1.8905640443166096

Epoch: 6| Step: 12
Training loss: 0.7479535341262817
Validation loss: 1.8428741808860534

Epoch: 6| Step: 13
Training loss: 1.174367070198059
Validation loss: 1.8396243036434214

Epoch: 186| Step: 0
Training loss: 0.891191840171814
Validation loss: 1.8376477995226461

Epoch: 6| Step: 1
Training loss: 1.2931296825408936
Validation loss: 1.8408005173488329

Epoch: 6| Step: 2
Training loss: 1.5833461284637451
Validation loss: 1.8722811693786292

Epoch: 6| Step: 3
Training loss: 0.6283087730407715
Validation loss: 1.903680060499458

Epoch: 6| Step: 4
Training loss: 0.897226870059967
Validation loss: 1.9531722607151154

Epoch: 6| Step: 5
Training loss: 0.7129546403884888
Validation loss: 1.9916100809651036

Epoch: 6| Step: 6
Training loss: 0.6652549505233765
Validation loss: 2.0329228613966253

Epoch: 6| Step: 7
Training loss: 1.2168159484863281
Validation loss: 1.9837828195223244

Epoch: 6| Step: 8
Training loss: 1.0618078708648682
Validation loss: 1.9407212631676787

Epoch: 6| Step: 9
Training loss: 1.4076027870178223
Validation loss: 1.842988270585255

Epoch: 6| Step: 10
Training loss: 0.7871867418289185
Validation loss: 1.8315381362874021

Epoch: 6| Step: 11
Training loss: 1.025320291519165
Validation loss: 1.8157993849887644

Epoch: 6| Step: 12
Training loss: 1.2783117294311523
Validation loss: 1.8183897528597104

Epoch: 6| Step: 13
Training loss: 1.037123680114746
Validation loss: 1.803941374183983

Epoch: 187| Step: 0
Training loss: 0.989165186882019
Validation loss: 1.797874604502032

Epoch: 6| Step: 1
Training loss: 1.1406086683273315
Validation loss: 1.806297912392565

Epoch: 6| Step: 2
Training loss: 0.9383093118667603
Validation loss: 1.7879866694891324

Epoch: 6| Step: 3
Training loss: 1.4907114505767822
Validation loss: 1.8122557593930153

Epoch: 6| Step: 4
Training loss: 1.2679705619812012
Validation loss: 1.8161638936688822

Epoch: 6| Step: 5
Training loss: 0.7754396200180054
Validation loss: 1.8463975639753445

Epoch: 6| Step: 6
Training loss: 0.7441160678863525
Validation loss: 1.8239560075985488

Epoch: 6| Step: 7
Training loss: 0.7978916764259338
Validation loss: 1.822790935475339

Epoch: 6| Step: 8
Training loss: 0.7177995443344116
Validation loss: 1.8047788822522728

Epoch: 6| Step: 9
Training loss: 1.3442245721817017
Validation loss: 1.8284168884318361

Epoch: 6| Step: 10
Training loss: 1.0311429500579834
Validation loss: 1.8320121829227736

Epoch: 6| Step: 11
Training loss: 1.2424910068511963
Validation loss: 1.8608600413927467

Epoch: 6| Step: 12
Training loss: 1.2156898975372314
Validation loss: 1.8909103665300595

Epoch: 6| Step: 13
Training loss: 0.9151270985603333
Validation loss: 1.9199918957166775

Epoch: 188| Step: 0
Training loss: 1.142578125
Validation loss: 1.949746503624865

Epoch: 6| Step: 1
Training loss: 1.0519918203353882
Validation loss: 1.950259502216052

Epoch: 6| Step: 2
Training loss: 0.8842774629592896
Validation loss: 1.9685795281523017

Epoch: 6| Step: 3
Training loss: 1.016936182975769
Validation loss: 1.930423157189482

Epoch: 6| Step: 4
Training loss: 1.1705104112625122
Validation loss: 1.8928072196181103

Epoch: 6| Step: 5
Training loss: 0.9620624780654907
Validation loss: 1.871570553830875

Epoch: 6| Step: 6
Training loss: 1.2850589752197266
Validation loss: 1.8950398250292706

Epoch: 6| Step: 7
Training loss: 0.6989536285400391
Validation loss: 1.8760001467120262

Epoch: 6| Step: 8
Training loss: 0.8613633513450623
Validation loss: 1.8705760817373953

Epoch: 6| Step: 9
Training loss: 1.4822957515716553
Validation loss: 1.8232216732476347

Epoch: 6| Step: 10
Training loss: 1.2403101921081543
Validation loss: 1.7769752497314124

Epoch: 6| Step: 11
Training loss: 1.0199086666107178
Validation loss: 1.781490965556073

Epoch: 6| Step: 12
Training loss: 0.8871985077857971
Validation loss: 1.7586412570809806

Epoch: 6| Step: 13
Training loss: 0.900822103023529
Validation loss: 1.780070690698521

Epoch: 189| Step: 0
Training loss: 0.8920451998710632
Validation loss: 1.7717399263894686

Epoch: 6| Step: 1
Training loss: 0.9565787315368652
Validation loss: 1.7877322871197936

Epoch: 6| Step: 2
Training loss: 0.6956258416175842
Validation loss: 1.8008052931037

Epoch: 6| Step: 3
Training loss: 0.8703467845916748
Validation loss: 1.8492989040190173

Epoch: 6| Step: 4
Training loss: 1.1542840003967285
Validation loss: 1.8928506630723194

Epoch: 6| Step: 5
Training loss: 1.4757755994796753
Validation loss: 1.88066134401547

Epoch: 6| Step: 6
Training loss: 0.5163782238960266
Validation loss: 1.8729624850775606

Epoch: 6| Step: 7
Training loss: 0.8235254883766174
Validation loss: 1.8702737503154303

Epoch: 6| Step: 8
Training loss: 1.6778761148452759
Validation loss: 1.8951645538371096

Epoch: 6| Step: 9
Training loss: 0.9873224496841431
Validation loss: 1.8736779202697098

Epoch: 6| Step: 10
Training loss: 0.630125105381012
Validation loss: 1.8777344406292003

Epoch: 6| Step: 11
Training loss: 1.1231203079223633
Validation loss: 1.8789443456998436

Epoch: 6| Step: 12
Training loss: 1.3306283950805664
Validation loss: 1.8513681824489305

Epoch: 6| Step: 13
Training loss: 0.7834851741790771
Validation loss: 1.844259447948907

Epoch: 190| Step: 0
Training loss: 1.085146188735962
Validation loss: 1.842941625143892

Epoch: 6| Step: 1
Training loss: 0.9919159412384033
Validation loss: 1.8409696240578928

Epoch: 6| Step: 2
Training loss: 1.4246838092803955
Validation loss: 1.8532183785592355

Epoch: 6| Step: 3
Training loss: 0.987082302570343
Validation loss: 1.8333500508339173

Epoch: 6| Step: 4
Training loss: 0.9498931169509888
Validation loss: 1.8390167426037531

Epoch: 6| Step: 5
Training loss: 1.0710673332214355
Validation loss: 1.8126269258478636

Epoch: 6| Step: 6
Training loss: 0.8802826404571533
Validation loss: 1.8196683263265958

Epoch: 6| Step: 7
Training loss: 0.5000125169754028
Validation loss: 1.8354754306936776

Epoch: 6| Step: 8
Training loss: 1.084123134613037
Validation loss: 1.8293217023213704

Epoch: 6| Step: 9
Training loss: 0.836237370967865
Validation loss: 1.854504749339114

Epoch: 6| Step: 10
Training loss: 0.9049969911575317
Validation loss: 1.8347165046199676

Epoch: 6| Step: 11
Training loss: 1.2116810083389282
Validation loss: 1.8535185706230901

Epoch: 6| Step: 12
Training loss: 0.7174429893493652
Validation loss: 1.8599024780334965

Epoch: 6| Step: 13
Training loss: 0.7043302059173584
Validation loss: 1.8596493697935534

Epoch: 191| Step: 0
Training loss: 1.3750706911087036
Validation loss: 1.8420908733080792

Epoch: 6| Step: 1
Training loss: 1.3143818378448486
Validation loss: 1.8886180821285452

Epoch: 6| Step: 2
Training loss: 0.8564255833625793
Validation loss: 1.888943253024932

Epoch: 6| Step: 3
Training loss: 0.9374580979347229
Validation loss: 1.908137349672215

Epoch: 6| Step: 4
Training loss: 0.7982196807861328
Validation loss: 1.9067690205830399

Epoch: 6| Step: 5
Training loss: 1.1735707521438599
Validation loss: 1.8564358154932659

Epoch: 6| Step: 6
Training loss: 0.5770251154899597
Validation loss: 1.8315861558401456

Epoch: 6| Step: 7
Training loss: 0.6295400261878967
Validation loss: 1.787149538276016

Epoch: 6| Step: 8
Training loss: 0.6540393829345703
Validation loss: 1.778252335004909

Epoch: 6| Step: 9
Training loss: 1.3118009567260742
Validation loss: 1.770946987213627

Epoch: 6| Step: 10
Training loss: 1.0303131341934204
Validation loss: 1.7444574986734698

Epoch: 6| Step: 11
Training loss: 0.787385106086731
Validation loss: 1.7850499947865803

Epoch: 6| Step: 12
Training loss: 0.592422366142273
Validation loss: 1.8128287574296356

Epoch: 6| Step: 13
Training loss: 1.0426431894302368
Validation loss: 1.8343951766208937

Epoch: 192| Step: 0
Training loss: 0.6917856931686401
Validation loss: 1.8447116754388297

Epoch: 6| Step: 1
Training loss: 0.7800358533859253
Validation loss: 1.8328949533483034

Epoch: 6| Step: 2
Training loss: 1.1520681381225586
Validation loss: 1.8314403218607749

Epoch: 6| Step: 3
Training loss: 1.063765048980713
Validation loss: 1.8358214209156651

Epoch: 6| Step: 4
Training loss: 0.8664652109146118
Validation loss: 1.845005750656128

Epoch: 6| Step: 5
Training loss: 0.986359715461731
Validation loss: 1.8751925627390544

Epoch: 6| Step: 6
Training loss: 0.9576529264450073
Validation loss: 1.877883218949841

Epoch: 6| Step: 7
Training loss: 1.1088099479675293
Validation loss: 1.8826382826733332

Epoch: 6| Step: 8
Training loss: 0.6623122692108154
Validation loss: 1.8967353631091375

Epoch: 6| Step: 9
Training loss: 0.7944021224975586
Validation loss: 1.8942983701664915

Epoch: 6| Step: 10
Training loss: 1.0113677978515625
Validation loss: 1.865677047801274

Epoch: 6| Step: 11
Training loss: 0.8159005641937256
Validation loss: 1.82643590306723

Epoch: 6| Step: 12
Training loss: 1.1870609521865845
Validation loss: 1.8249986069176787

Epoch: 6| Step: 13
Training loss: 0.7988874316215515
Validation loss: 1.8185742465398644

Epoch: 193| Step: 0
Training loss: 0.8037428855895996
Validation loss: 1.7812127156924176

Epoch: 6| Step: 1
Training loss: 0.8419458866119385
Validation loss: 1.782751642247682

Epoch: 6| Step: 2
Training loss: 0.8628107905387878
Validation loss: 1.783497122667169

Epoch: 6| Step: 3
Training loss: 0.6516901850700378
Validation loss: 1.8004237413406372

Epoch: 6| Step: 4
Training loss: 0.6043456196784973
Validation loss: 1.8080932068568405

Epoch: 6| Step: 5
Training loss: 1.2291629314422607
Validation loss: 1.7981812338675223

Epoch: 6| Step: 6
Training loss: 0.6488330364227295
Validation loss: 1.810040609810942

Epoch: 6| Step: 7
Training loss: 1.1251754760742188
Validation loss: 1.8241574456614833

Epoch: 6| Step: 8
Training loss: 1.286642074584961
Validation loss: 1.8277645367448048

Epoch: 6| Step: 9
Training loss: 0.8730757832527161
Validation loss: 1.8497999944994528

Epoch: 6| Step: 10
Training loss: 0.9870274662971497
Validation loss: 1.8532735314420474

Epoch: 6| Step: 11
Training loss: 1.2056010961532593
Validation loss: 1.8628400295011458

Epoch: 6| Step: 12
Training loss: 1.0733916759490967
Validation loss: 1.8451075733348887

Epoch: 6| Step: 13
Training loss: 0.365285724401474
Validation loss: 1.8314513288518435

Epoch: 194| Step: 0
Training loss: 1.4924561977386475
Validation loss: 1.8170993187094246

Epoch: 6| Step: 1
Training loss: 0.8972210884094238
Validation loss: 1.8085833031644103

Epoch: 6| Step: 2
Training loss: 1.285090684890747
Validation loss: 1.8044313359004196

Epoch: 6| Step: 3
Training loss: 0.7227757573127747
Validation loss: 1.7911611833880026

Epoch: 6| Step: 4
Training loss: 1.0712952613830566
Validation loss: 1.8148257309390652

Epoch: 6| Step: 5
Training loss: 0.6659185290336609
Validation loss: 1.8084945230073826

Epoch: 6| Step: 6
Training loss: 1.14351224899292
Validation loss: 1.8302739281808176

Epoch: 6| Step: 7
Training loss: 0.4695526361465454
Validation loss: 1.847760469682755

Epoch: 6| Step: 8
Training loss: 0.9172882437705994
Validation loss: 1.8315830576804377

Epoch: 6| Step: 9
Training loss: 0.8014306426048279
Validation loss: 1.839292718518165

Epoch: 6| Step: 10
Training loss: 0.8258956670761108
Validation loss: 1.815115653058534

Epoch: 6| Step: 11
Training loss: 0.7539608478546143
Validation loss: 1.8128722880476265

Epoch: 6| Step: 12
Training loss: 0.8196366429328918
Validation loss: 1.7925679645230692

Epoch: 6| Step: 13
Training loss: 0.773802638053894
Validation loss: 1.774459308193576

Epoch: 195| Step: 0
Training loss: 1.0973215103149414
Validation loss: 1.7878669423441733

Epoch: 6| Step: 1
Training loss: 0.9185299873352051
Validation loss: 1.7823902304454515

Epoch: 6| Step: 2
Training loss: 0.9053100347518921
Validation loss: 1.790944528836076

Epoch: 6| Step: 3
Training loss: 1.1870312690734863
Validation loss: 1.7822851827067714

Epoch: 6| Step: 4
Training loss: 0.8924165964126587
Validation loss: 1.7977503627859137

Epoch: 6| Step: 5
Training loss: 0.9481732845306396
Validation loss: 1.789412872765654

Epoch: 6| Step: 6
Training loss: 0.48382556438446045
Validation loss: 1.8360385458956483

Epoch: 6| Step: 7
Training loss: 1.1467161178588867
Validation loss: 1.8089454199678154

Epoch: 6| Step: 8
Training loss: 0.9823312759399414
Validation loss: 1.8109516533472205

Epoch: 6| Step: 9
Training loss: 0.6939294338226318
Validation loss: 1.801021384936507

Epoch: 6| Step: 10
Training loss: 0.27429190278053284
Validation loss: 1.8170403575384488

Epoch: 6| Step: 11
Training loss: 1.05362868309021
Validation loss: 1.8151545434869745

Epoch: 6| Step: 12
Training loss: 0.9544012546539307
Validation loss: 1.8202464811263546

Epoch: 6| Step: 13
Training loss: 0.6809179782867432
Validation loss: 1.8278824795958817

Epoch: 196| Step: 0
Training loss: 0.9528294801712036
Validation loss: 1.8475997627422374

Epoch: 6| Step: 1
Training loss: 0.5686918497085571
Validation loss: 1.8746666254535798

Epoch: 6| Step: 2
Training loss: 0.8977580666542053
Validation loss: 1.8931483568683747

Epoch: 6| Step: 3
Training loss: 1.3627591133117676
Validation loss: 1.90676236409013

Epoch: 6| Step: 4
Training loss: 0.5460209846496582
Validation loss: 1.9003608816413469

Epoch: 6| Step: 5
Training loss: 1.1438322067260742
Validation loss: 1.8773080866823915

Epoch: 6| Step: 6
Training loss: 1.0246336460113525
Validation loss: 1.8155654989263064

Epoch: 6| Step: 7
Training loss: 1.0076770782470703
Validation loss: 1.8015895953742407

Epoch: 6| Step: 8
Training loss: 0.8834778666496277
Validation loss: 1.7657531602408296

Epoch: 6| Step: 9
Training loss: 1.4996570348739624
Validation loss: 1.7356547668416014

Epoch: 6| Step: 10
Training loss: 0.8297083377838135
Validation loss: 1.742059519214015

Epoch: 6| Step: 11
Training loss: 0.7511078715324402
Validation loss: 1.7409367458794707

Epoch: 6| Step: 12
Training loss: 0.6958911418914795
Validation loss: 1.7475611086814635

Epoch: 6| Step: 13
Training loss: 0.8976974487304688
Validation loss: 1.7895458103508077

Epoch: 197| Step: 0
Training loss: 1.0289214849472046
Validation loss: 1.7820761588311964

Epoch: 6| Step: 1
Training loss: 0.7814428806304932
Validation loss: 1.7693628265011696

Epoch: 6| Step: 2
Training loss: 0.6031118035316467
Validation loss: 1.7524928713357577

Epoch: 6| Step: 3
Training loss: 0.85616534948349
Validation loss: 1.7585903303597563

Epoch: 6| Step: 4
Training loss: 0.9845309257507324
Validation loss: 1.765766123289703

Epoch: 6| Step: 5
Training loss: 0.5527368783950806
Validation loss: 1.8059473627357072

Epoch: 6| Step: 6
Training loss: 0.7068353891372681
Validation loss: 1.8249532099693053

Epoch: 6| Step: 7
Training loss: 0.9797766208648682
Validation loss: 1.830050072362346

Epoch: 6| Step: 8
Training loss: 0.8739610910415649
Validation loss: 1.8080243705421366

Epoch: 6| Step: 9
Training loss: 1.064911961555481
Validation loss: 1.8078170002147715

Epoch: 6| Step: 10
Training loss: 0.7780469655990601
Validation loss: 1.8198168739195792

Epoch: 6| Step: 11
Training loss: 1.1626865863800049
Validation loss: 1.8022340548935758

Epoch: 6| Step: 12
Training loss: 1.0772618055343628
Validation loss: 1.8093598247856222

Epoch: 6| Step: 13
Training loss: 1.017498254776001
Validation loss: 1.8244225068758892

Epoch: 198| Step: 0
Training loss: 0.7488579154014587
Validation loss: 1.7848199464941537

Epoch: 6| Step: 1
Training loss: 0.6975634098052979
Validation loss: 1.7544334344966437

Epoch: 6| Step: 2
Training loss: 0.7396836876869202
Validation loss: 1.7328681753527733

Epoch: 6| Step: 3
Training loss: 0.7773023843765259
Validation loss: 1.751077466113593

Epoch: 6| Step: 4
Training loss: 0.6092897653579712
Validation loss: 1.7378208637237549

Epoch: 6| Step: 5
Training loss: 0.9996213912963867
Validation loss: 1.7390902247480167

Epoch: 6| Step: 6
Training loss: 0.9959365129470825
Validation loss: 1.7504172107224822

Epoch: 6| Step: 7
Training loss: 0.7940185070037842
Validation loss: 1.745480401541597

Epoch: 6| Step: 8
Training loss: 0.9216678142547607
Validation loss: 1.7590841913735995

Epoch: 6| Step: 9
Training loss: 0.7689119577407837
Validation loss: 1.7738811995393486

Epoch: 6| Step: 10
Training loss: 0.9320207834243774
Validation loss: 1.788552120167722

Epoch: 6| Step: 11
Training loss: 1.2154589891433716
Validation loss: 1.7825167012471024

Epoch: 6| Step: 12
Training loss: 0.593032717704773
Validation loss: 1.790034701747279

Epoch: 6| Step: 13
Training loss: 1.1169095039367676
Validation loss: 1.7826379396582162

Epoch: 199| Step: 0
Training loss: 0.7188416123390198
Validation loss: 1.8186023594230734

Epoch: 6| Step: 1
Training loss: 0.5763620734214783
Validation loss: 1.8329975425556142

Epoch: 6| Step: 2
Training loss: 0.8889180421829224
Validation loss: 1.8516058229630994

Epoch: 6| Step: 3
Training loss: 0.6719589829444885
Validation loss: 1.8833495314403246

Epoch: 6| Step: 4
Training loss: 1.134480595588684
Validation loss: 1.8785396493891233

Epoch: 6| Step: 5
Training loss: 0.8017170429229736
Validation loss: 1.8483787557130218

Epoch: 6| Step: 6
Training loss: 0.893507719039917
Validation loss: 1.8224402678910123

Epoch: 6| Step: 7
Training loss: 0.47471195459365845
Validation loss: 1.7527420020872546

Epoch: 6| Step: 8
Training loss: 0.8322945833206177
Validation loss: 1.7613991550219956

Epoch: 6| Step: 9
Training loss: 1.2334426641464233
Validation loss: 1.7313853028000041

Epoch: 6| Step: 10
Training loss: 0.6724942922592163
Validation loss: 1.7503978795902704

Epoch: 6| Step: 11
Training loss: 1.0904414653778076
Validation loss: 1.7438873321779313

Epoch: 6| Step: 12
Training loss: 0.7797304391860962
Validation loss: 1.776626653568719

Epoch: 6| Step: 13
Training loss: 1.5825695991516113
Validation loss: 1.7571965725191179

Epoch: 200| Step: 0
Training loss: 0.9649742841720581
Validation loss: 1.7798631780891008

Epoch: 6| Step: 1
Training loss: 0.8645056486129761
Validation loss: 1.7630997575739378

Epoch: 6| Step: 2
Training loss: 1.0196651220321655
Validation loss: 1.7688571663313015

Epoch: 6| Step: 3
Training loss: 0.5610443353652954
Validation loss: 1.7853010290412492

Epoch: 6| Step: 4
Training loss: 0.7966263294219971
Validation loss: 1.819214981089356

Epoch: 6| Step: 5
Training loss: 0.9547997117042542
Validation loss: 1.8290907131728305

Epoch: 6| Step: 6
Training loss: 0.5322517156600952
Validation loss: 1.808557802631009

Epoch: 6| Step: 7
Training loss: 1.6153130531311035
Validation loss: 1.831119562989922

Epoch: 6| Step: 8
Training loss: 0.7916592359542847
Validation loss: 1.7873619641027143

Epoch: 6| Step: 9
Training loss: 1.1355758905410767
Validation loss: 1.8003828115360712

Epoch: 6| Step: 10
Training loss: 0.607244074344635
Validation loss: 1.8146154931796494

Epoch: 6| Step: 11
Training loss: 0.5612967610359192
Validation loss: 1.7954136466467252

Epoch: 6| Step: 12
Training loss: 0.7049437165260315
Validation loss: 1.7777161598205566

Epoch: 6| Step: 13
Training loss: 0.3695867955684662
Validation loss: 1.7852739775052635

Epoch: 201| Step: 0
Training loss: 0.6568641662597656
Validation loss: 1.8019535733807472

Epoch: 6| Step: 1
Training loss: 0.47016867995262146
Validation loss: 1.7983505290041688

Epoch: 6| Step: 2
Training loss: 1.0578341484069824
Validation loss: 1.8131868262444772

Epoch: 6| Step: 3
Training loss: 1.3370070457458496
Validation loss: 1.813804079127568

Epoch: 6| Step: 4
Training loss: 0.9321475028991699
Validation loss: 1.8022932083375993

Epoch: 6| Step: 5
Training loss: 0.8635845184326172
Validation loss: 1.7858476792612383

Epoch: 6| Step: 6
Training loss: 0.7914308309555054
Validation loss: 1.7732341853521203

Epoch: 6| Step: 7
Training loss: 0.4872446358203888
Validation loss: 1.7363246666487826

Epoch: 6| Step: 8
Training loss: 0.628425121307373
Validation loss: 1.7406182699306036

Epoch: 6| Step: 9
Training loss: 0.6681644320487976
Validation loss: 1.7467538079907816

Epoch: 6| Step: 10
Training loss: 0.4922497272491455
Validation loss: 1.764799112914711

Epoch: 6| Step: 11
Training loss: 0.8513706922531128
Validation loss: 1.7394924356091408

Epoch: 6| Step: 12
Training loss: 1.2045516967773438
Validation loss: 1.7603426261614727

Epoch: 6| Step: 13
Training loss: 0.8509265780448914
Validation loss: 1.7642912915957871

Epoch: 202| Step: 0
Training loss: 0.8690072298049927
Validation loss: 1.7290433824703257

Epoch: 6| Step: 1
Training loss: 1.121446132659912
Validation loss: 1.7234030295443792

Epoch: 6| Step: 2
Training loss: 0.6881958246231079
Validation loss: 1.7196262677510579

Epoch: 6| Step: 3
Training loss: 0.8009520173072815
Validation loss: 1.7243899401798044

Epoch: 6| Step: 4
Training loss: 0.6116524934768677
Validation loss: 1.705611349433981

Epoch: 6| Step: 5
Training loss: 0.8160192370414734
Validation loss: 1.7191242633327362

Epoch: 6| Step: 6
Training loss: 0.5888576507568359
Validation loss: 1.7169804316695019

Epoch: 6| Step: 7
Training loss: 0.8845235705375671
Validation loss: 1.7344001108600247

Epoch: 6| Step: 8
Training loss: 0.8991327881813049
Validation loss: 1.7721943201557282

Epoch: 6| Step: 9
Training loss: 0.9870725274085999
Validation loss: 1.8500232004350232

Epoch: 6| Step: 10
Training loss: 0.9383155107498169
Validation loss: 1.8887975100548036

Epoch: 6| Step: 11
Training loss: 1.0421574115753174
Validation loss: 1.913188297261474

Epoch: 6| Step: 12
Training loss: 0.7884871363639832
Validation loss: 1.8790623680237801

Epoch: 6| Step: 13
Training loss: 0.6262087225914001
Validation loss: 1.8319306553051036

Epoch: 203| Step: 0
Training loss: 1.1148241758346558
Validation loss: 1.7954088923751668

Epoch: 6| Step: 1
Training loss: 0.7634868621826172
Validation loss: 1.7886885096949916

Epoch: 6| Step: 2
Training loss: 0.8807879686355591
Validation loss: 1.7744841844804826

Epoch: 6| Step: 3
Training loss: 0.6166338920593262
Validation loss: 1.7504819823849587

Epoch: 6| Step: 4
Training loss: 0.9380579590797424
Validation loss: 1.739517673369377

Epoch: 6| Step: 5
Training loss: 1.1691972017288208
Validation loss: 1.717899889074346

Epoch: 6| Step: 6
Training loss: 0.8232417106628418
Validation loss: 1.71453078844214

Epoch: 6| Step: 7
Training loss: 0.7015134692192078
Validation loss: 1.7212114398197462

Epoch: 6| Step: 8
Training loss: 0.9920598268508911
Validation loss: 1.7195544050585838

Epoch: 6| Step: 9
Training loss: 0.7286455631256104
Validation loss: 1.7161278263215096

Epoch: 6| Step: 10
Training loss: 0.7598736882209778
Validation loss: 1.727022353038993

Epoch: 6| Step: 11
Training loss: 0.4235473573207855
Validation loss: 1.723822074551736

Epoch: 6| Step: 12
Training loss: 0.35523849725723267
Validation loss: 1.7349946550143662

Epoch: 6| Step: 13
Training loss: 1.3752846717834473
Validation loss: 1.7392822324588735

Epoch: 204| Step: 0
Training loss: 0.9305435419082642
Validation loss: 1.767220192058112

Epoch: 6| Step: 1
Training loss: 0.953275740146637
Validation loss: 1.787152007061948

Epoch: 6| Step: 2
Training loss: 0.8751912117004395
Validation loss: 1.813943406587006

Epoch: 6| Step: 3
Training loss: 0.5393034219741821
Validation loss: 1.8182150881777528

Epoch: 6| Step: 4
Training loss: 1.106245517730713
Validation loss: 1.8332160621561029

Epoch: 6| Step: 5
Training loss: 1.0832045078277588
Validation loss: 1.8060617126444334

Epoch: 6| Step: 6
Training loss: 0.805924654006958
Validation loss: 1.8206010697990336

Epoch: 6| Step: 7
Training loss: 0.6897329688072205
Validation loss: 1.7890831449980378

Epoch: 6| Step: 8
Training loss: 0.7095357179641724
Validation loss: 1.7558741672064668

Epoch: 6| Step: 9
Training loss: 0.7937728762626648
Validation loss: 1.7369910632410357

Epoch: 6| Step: 10
Training loss: 0.5745689868927002
Validation loss: 1.7279186043688046

Epoch: 6| Step: 11
Training loss: 0.4879593551158905
Validation loss: 1.6988661968579857

Epoch: 6| Step: 12
Training loss: 1.0982534885406494
Validation loss: 1.7047947440096127

Epoch: 6| Step: 13
Training loss: 0.4705912172794342
Validation loss: 1.6912180236590806

Epoch: 205| Step: 0
Training loss: 1.1876494884490967
Validation loss: 1.7035483224417574

Epoch: 6| Step: 1
Training loss: 0.5764109492301941
Validation loss: 1.7087208109517251

Epoch: 6| Step: 2
Training loss: 0.8806462287902832
Validation loss: 1.7162644555491786

Epoch: 6| Step: 3
Training loss: 1.0480549335479736
Validation loss: 1.731630588090548

Epoch: 6| Step: 4
Training loss: 0.6302220821380615
Validation loss: 1.7284664569362518

Epoch: 6| Step: 5
Training loss: 0.6489475965499878
Validation loss: 1.7344531974484843

Epoch: 6| Step: 6
Training loss: 0.8839151263237
Validation loss: 1.7345974432524813

Epoch: 6| Step: 7
Training loss: 0.7766056060791016
Validation loss: 1.730937752672421

Epoch: 6| Step: 8
Training loss: 0.6867004036903381
Validation loss: 1.71622666235893

Epoch: 6| Step: 9
Training loss: 0.6208585500717163
Validation loss: 1.7079214408833494

Epoch: 6| Step: 10
Training loss: 0.8561176657676697
Validation loss: 1.7301367457194994

Epoch: 6| Step: 11
Training loss: 0.6812804937362671
Validation loss: 1.754056260149966

Epoch: 6| Step: 12
Training loss: 0.5424081087112427
Validation loss: 1.7925392261115454

Epoch: 6| Step: 13
Training loss: 0.6359274387359619
Validation loss: 1.8046969726521482

Epoch: 206| Step: 0
Training loss: 0.9643159508705139
Validation loss: 1.8021652544698408

Epoch: 6| Step: 1
Training loss: 0.6338537931442261
Validation loss: 1.8120360451359903

Epoch: 6| Step: 2
Training loss: 0.5943868160247803
Validation loss: 1.7649028839603547

Epoch: 6| Step: 3
Training loss: 0.5843104124069214
Validation loss: 1.7466649932246054

Epoch: 6| Step: 4
Training loss: 0.8765296936035156
Validation loss: 1.7288328473285963

Epoch: 6| Step: 5
Training loss: 0.6011298298835754
Validation loss: 1.7452511992505801

Epoch: 6| Step: 6
Training loss: 0.848513126373291
Validation loss: 1.701158732496282

Epoch: 6| Step: 7
Training loss: 0.6386845111846924
Validation loss: 1.7497955573502408

Epoch: 6| Step: 8
Training loss: 0.6025171279907227
Validation loss: 1.747036080206594

Epoch: 6| Step: 9
Training loss: 0.8226229548454285
Validation loss: 1.7277935192149172

Epoch: 6| Step: 10
Training loss: 1.1515607833862305
Validation loss: 1.7469089197856125

Epoch: 6| Step: 11
Training loss: 0.7188968658447266
Validation loss: 1.71629802514148

Epoch: 6| Step: 12
Training loss: 0.7627277970314026
Validation loss: 1.708078097271663

Epoch: 6| Step: 13
Training loss: 1.0263952016830444
Validation loss: 1.7062535798677834

Epoch: 207| Step: 0
Training loss: 1.095870018005371
Validation loss: 1.715600816152429

Epoch: 6| Step: 1
Training loss: 1.4070000648498535
Validation loss: 1.73453228704391

Epoch: 6| Step: 2
Training loss: 1.182819128036499
Validation loss: 1.7459207952663462

Epoch: 6| Step: 3
Training loss: 0.6981687545776367
Validation loss: 1.7576368431891165

Epoch: 6| Step: 4
Training loss: 0.6086543798446655
Validation loss: 1.777667082766051

Epoch: 6| Step: 5
Training loss: 0.6177329421043396
Validation loss: 1.7978298625638407

Epoch: 6| Step: 6
Training loss: 0.5358839631080627
Validation loss: 1.8343640553053988

Epoch: 6| Step: 7
Training loss: 0.6062968969345093
Validation loss: 1.8388823924526092

Epoch: 6| Step: 8
Training loss: 0.4453713595867157
Validation loss: 1.8432503925856722

Epoch: 6| Step: 9
Training loss: 0.6264595985412598
Validation loss: 1.8445746462832215

Epoch: 6| Step: 10
Training loss: 0.8971025347709656
Validation loss: 1.833182495127442

Epoch: 6| Step: 11
Training loss: 0.7782608866691589
Validation loss: 1.835582184535201

Epoch: 6| Step: 12
Training loss: 0.6750946044921875
Validation loss: 1.8184164262587024

Epoch: 6| Step: 13
Training loss: 0.7907466888427734
Validation loss: 1.8179680339751705

Epoch: 208| Step: 0
Training loss: 0.7356656193733215
Validation loss: 1.8132442825584

Epoch: 6| Step: 1
Training loss: 0.8748484253883362
Validation loss: 1.7674662964318388

Epoch: 6| Step: 2
Training loss: 0.8339107632637024
Validation loss: 1.8017815415577223

Epoch: 6| Step: 3
Training loss: 1.255366563796997
Validation loss: 1.795333884095633

Epoch: 6| Step: 4
Training loss: 1.0484099388122559
Validation loss: 1.7924672736916492

Epoch: 6| Step: 5
Training loss: 0.6750330328941345
Validation loss: 1.7620964178475

Epoch: 6| Step: 6
Training loss: 0.5872044563293457
Validation loss: 1.7219438719493088

Epoch: 6| Step: 7
Training loss: 0.6291340589523315
Validation loss: 1.7100906384888517

Epoch: 6| Step: 8
Training loss: 0.5240273475646973
Validation loss: 1.6926102151152909

Epoch: 6| Step: 9
Training loss: 0.5826591849327087
Validation loss: 1.7039232766756447

Epoch: 6| Step: 10
Training loss: 0.6887493133544922
Validation loss: 1.7265606875060706

Epoch: 6| Step: 11
Training loss: 1.160596251487732
Validation loss: 1.715142160333613

Epoch: 6| Step: 12
Training loss: 0.36596375703811646
Validation loss: 1.749753168834153

Epoch: 6| Step: 13
Training loss: 1.0215342044830322
Validation loss: 1.7755719384839457

Epoch: 209| Step: 0
Training loss: 0.9090624451637268
Validation loss: 1.7479864025628695

Epoch: 6| Step: 1
Training loss: 0.7899886965751648
Validation loss: 1.742712309283595

Epoch: 6| Step: 2
Training loss: 1.1057746410369873
Validation loss: 1.7594295342763264

Epoch: 6| Step: 3
Training loss: 0.5974161624908447
Validation loss: 1.77543988022753

Epoch: 6| Step: 4
Training loss: 0.7899559736251831
Validation loss: 1.7762001650307768

Epoch: 6| Step: 5
Training loss: 0.7805774807929993
Validation loss: 1.783627720289333

Epoch: 6| Step: 6
Training loss: 0.739652156829834
Validation loss: 1.7479783899040633

Epoch: 6| Step: 7
Training loss: 0.842755913734436
Validation loss: 1.7352991347671838

Epoch: 6| Step: 8
Training loss: 0.6506801843643188
Validation loss: 1.740954650345669

Epoch: 6| Step: 9
Training loss: 0.5863533616065979
Validation loss: 1.72893706188407

Epoch: 6| Step: 10
Training loss: 0.40564048290252686
Validation loss: 1.714931321400468

Epoch: 6| Step: 11
Training loss: 0.8137458562850952
Validation loss: 1.7269734413393083

Epoch: 6| Step: 12
Training loss: 0.5309419631958008
Validation loss: 1.7165326303051365

Epoch: 6| Step: 13
Training loss: 0.5565798878669739
Validation loss: 1.7188432524281163

Epoch: 210| Step: 0
Training loss: 0.8775421380996704
Validation loss: 1.741946272311672

Epoch: 6| Step: 1
Training loss: 0.8485114574432373
Validation loss: 1.7494981506819367

Epoch: 6| Step: 2
Training loss: 0.6173709034919739
Validation loss: 1.716959443143619

Epoch: 6| Step: 3
Training loss: 0.893262505531311
Validation loss: 1.7431188462882914

Epoch: 6| Step: 4
Training loss: 0.5655484199523926
Validation loss: 1.7372892800197806

Epoch: 6| Step: 5
Training loss: 0.31138595938682556
Validation loss: 1.7388138950511973

Epoch: 6| Step: 6
Training loss: 0.6579340696334839
Validation loss: 1.7680999745604813

Epoch: 6| Step: 7
Training loss: 0.8240108489990234
Validation loss: 1.7886598430654055

Epoch: 6| Step: 8
Training loss: 0.7672339677810669
Validation loss: 1.770303923596618

Epoch: 6| Step: 9
Training loss: 1.0891575813293457
Validation loss: 1.752043935560411

Epoch: 6| Step: 10
Training loss: 0.8058837652206421
Validation loss: 1.746162586314704

Epoch: 6| Step: 11
Training loss: 0.488276869058609
Validation loss: 1.7417391782165856

Epoch: 6| Step: 12
Training loss: 0.6809624433517456
Validation loss: 1.7212339665300103

Epoch: 6| Step: 13
Training loss: 0.8709583282470703
Validation loss: 1.7264200359262445

Epoch: 211| Step: 0
Training loss: 0.6474171876907349
Validation loss: 1.737010003418051

Epoch: 6| Step: 1
Training loss: 0.7748580574989319
Validation loss: 1.7605912044484129

Epoch: 6| Step: 2
Training loss: 0.4439299702644348
Validation loss: 1.743197879483623

Epoch: 6| Step: 3
Training loss: 0.3608544170856476
Validation loss: 1.746548689821715

Epoch: 6| Step: 4
Training loss: 0.7285423278808594
Validation loss: 1.7574634962184454

Epoch: 6| Step: 5
Training loss: 0.66487056016922
Validation loss: 1.7602788991825555

Epoch: 6| Step: 6
Training loss: 0.8508670926094055
Validation loss: 1.7766654799061437

Epoch: 6| Step: 7
Training loss: 0.7480289340019226
Validation loss: 1.7592771386587491

Epoch: 6| Step: 8
Training loss: 0.5126234889030457
Validation loss: 1.7474574171086794

Epoch: 6| Step: 9
Training loss: 0.9952488541603088
Validation loss: 1.7453624932996687

Epoch: 6| Step: 10
Training loss: 0.8664976358413696
Validation loss: 1.7353197400287916

Epoch: 6| Step: 11
Training loss: 0.6525847911834717
Validation loss: 1.712789386831304

Epoch: 6| Step: 12
Training loss: 1.0050873756408691
Validation loss: 1.6930664457300657

Epoch: 6| Step: 13
Training loss: 1.1635680198669434
Validation loss: 1.689415531773721

Epoch: 212| Step: 0
Training loss: 0.8834384679794312
Validation loss: 1.675906245426465

Epoch: 6| Step: 1
Training loss: 0.5180003046989441
Validation loss: 1.6750727635557934

Epoch: 6| Step: 2
Training loss: 0.5330789089202881
Validation loss: 1.7142914213160032

Epoch: 6| Step: 3
Training loss: 0.9299471974372864
Validation loss: 1.7485474360886442

Epoch: 6| Step: 4
Training loss: 0.6649855375289917
Validation loss: 1.757332630054925

Epoch: 6| Step: 5
Training loss: 0.7574403285980225
Validation loss: 1.7176435224471553

Epoch: 6| Step: 6
Training loss: 0.7972462177276611
Validation loss: 1.703543113123986

Epoch: 6| Step: 7
Training loss: 0.6092801094055176
Validation loss: 1.7299131296014274

Epoch: 6| Step: 8
Training loss: 1.1297328472137451
Validation loss: 1.7380829113785938

Epoch: 6| Step: 9
Training loss: 0.5454822182655334
Validation loss: 1.7266867917071107

Epoch: 6| Step: 10
Training loss: 0.8746107816696167
Validation loss: 1.755189977666383

Epoch: 6| Step: 11
Training loss: 0.8737133145332336
Validation loss: 1.75172516094741

Epoch: 6| Step: 12
Training loss: 0.4883909821510315
Validation loss: 1.7767645594894246

Epoch: 6| Step: 13
Training loss: 0.5718252658843994
Validation loss: 1.8020965835099578

Epoch: 213| Step: 0
Training loss: 0.6058170795440674
Validation loss: 1.8058646994252359

Epoch: 6| Step: 1
Training loss: 0.6692337989807129
Validation loss: 1.8188194177484

Epoch: 6| Step: 2
Training loss: 0.9191380739212036
Validation loss: 1.8368569189502346

Epoch: 6| Step: 3
Training loss: 1.263878345489502
Validation loss: 1.7916784414681055

Epoch: 6| Step: 4
Training loss: 0.719886302947998
Validation loss: 1.7515518972950597

Epoch: 6| Step: 5
Training loss: 0.42328381538391113
Validation loss: 1.7097460890329013

Epoch: 6| Step: 6
Training loss: 0.6992441415786743
Validation loss: 1.7000718757670412

Epoch: 6| Step: 7
Training loss: 0.31325486302375793
Validation loss: 1.6943618591113756

Epoch: 6| Step: 8
Training loss: 0.736724853515625
Validation loss: 1.711425604358796

Epoch: 6| Step: 9
Training loss: 0.6158768534660339
Validation loss: 1.7095959712100286

Epoch: 6| Step: 10
Training loss: 0.5417540073394775
Validation loss: 1.7011843099389026

Epoch: 6| Step: 11
Training loss: 1.1470134258270264
Validation loss: 1.7087793991129885

Epoch: 6| Step: 12
Training loss: 0.5940285325050354
Validation loss: 1.6935305621034356

Epoch: 6| Step: 13
Training loss: 0.716788113117218
Validation loss: 1.6926457458926785

Epoch: 214| Step: 0
Training loss: 0.577204704284668
Validation loss: 1.7396467206298665

Epoch: 6| Step: 1
Training loss: 0.5964637398719788
Validation loss: 1.7116948135437504

Epoch: 6| Step: 2
Training loss: 0.6638572216033936
Validation loss: 1.6965584011488064

Epoch: 6| Step: 3
Training loss: 0.9073934555053711
Validation loss: 1.7265056102506575

Epoch: 6| Step: 4
Training loss: 0.4980367124080658
Validation loss: 1.706509272257487

Epoch: 6| Step: 5
Training loss: 1.0069684982299805
Validation loss: 1.7150815917599587

Epoch: 6| Step: 6
Training loss: 0.794009804725647
Validation loss: 1.7232159081325735

Epoch: 6| Step: 7
Training loss: 0.7130005359649658
Validation loss: 1.7408868856327508

Epoch: 6| Step: 8
Training loss: 1.0264618396759033
Validation loss: 1.74240751676662

Epoch: 6| Step: 9
Training loss: 0.812545657157898
Validation loss: 1.737674799016727

Epoch: 6| Step: 10
Training loss: 0.44223377108573914
Validation loss: 1.7176459271420714

Epoch: 6| Step: 11
Training loss: 0.4437382221221924
Validation loss: 1.7267254244896673

Epoch: 6| Step: 12
Training loss: 0.6012837886810303
Validation loss: 1.7329485570230792

Epoch: 6| Step: 13
Training loss: 0.39807555079460144
Validation loss: 1.7482600212097168

Epoch: 215| Step: 0
Training loss: 0.9142096042633057
Validation loss: 1.731597340235146

Epoch: 6| Step: 1
Training loss: 0.7800655364990234
Validation loss: 1.7459825777238416

Epoch: 6| Step: 2
Training loss: 0.5862285494804382
Validation loss: 1.7473435940281037

Epoch: 6| Step: 3
Training loss: 0.6370645761489868
Validation loss: 1.7504565715789795

Epoch: 6| Step: 4
Training loss: 0.4903686046600342
Validation loss: 1.7843309589611587

Epoch: 6| Step: 5
Training loss: 0.5067421793937683
Validation loss: 1.7938955291624992

Epoch: 6| Step: 6
Training loss: 0.8669747114181519
Validation loss: 1.7749903266147902

Epoch: 6| Step: 7
Training loss: 0.8433176875114441
Validation loss: 1.7430380050854017

Epoch: 6| Step: 8
Training loss: 0.435563325881958
Validation loss: 1.703618070130707

Epoch: 6| Step: 9
Training loss: 0.8538585305213928
Validation loss: 1.6935034810855825

Epoch: 6| Step: 10
Training loss: 0.43664926290512085
Validation loss: 1.6843238376802014

Epoch: 6| Step: 11
Training loss: 0.7520111203193665
Validation loss: 1.6841787343384118

Epoch: 6| Step: 12
Training loss: 0.7598606944084167
Validation loss: 1.6925392573879612

Epoch: 6| Step: 13
Training loss: 1.229347825050354
Validation loss: 1.7172910282688756

Epoch: 216| Step: 0
Training loss: 0.672607421875
Validation loss: 1.7824382781982422

Epoch: 6| Step: 1
Training loss: 0.6759577989578247
Validation loss: 1.8564845618381296

Epoch: 6| Step: 2
Training loss: 0.8396660089492798
Validation loss: 1.847847366845736

Epoch: 6| Step: 3
Training loss: 0.8862103223800659
Validation loss: 1.75494009576818

Epoch: 6| Step: 4
Training loss: 0.7310786247253418
Validation loss: 1.6988010983313284

Epoch: 6| Step: 5
Training loss: 0.4403297007083893
Validation loss: 1.664870258300535

Epoch: 6| Step: 6
Training loss: 0.9502253532409668
Validation loss: 1.6819688440651022

Epoch: 6| Step: 7
Training loss: 0.8431679010391235
Validation loss: 1.7133876380100046

Epoch: 6| Step: 8
Training loss: 0.9850698709487915
Validation loss: 1.73246475701691

Epoch: 6| Step: 9
Training loss: 1.0788086652755737
Validation loss: 1.6973825218856975

Epoch: 6| Step: 10
Training loss: 1.0095369815826416
Validation loss: 1.650169954505018

Epoch: 6| Step: 11
Training loss: 0.6275574564933777
Validation loss: 1.658969981696016

Epoch: 6| Step: 12
Training loss: 0.7181552648544312
Validation loss: 1.6985499551219325

Epoch: 6| Step: 13
Training loss: 1.0643424987792969
Validation loss: 1.7882436360082319

Epoch: 217| Step: 0
Training loss: 0.8223314881324768
Validation loss: 1.8413325009807464

Epoch: 6| Step: 1
Training loss: 0.8208192586898804
Validation loss: 1.8616531920689408

Epoch: 6| Step: 2
Training loss: 0.46607285737991333
Validation loss: 1.784417087031949

Epoch: 6| Step: 3
Training loss: 0.7573110461235046
Validation loss: 1.7520621374089231

Epoch: 6| Step: 4
Training loss: 0.8191708922386169
Validation loss: 1.6940416584732712

Epoch: 6| Step: 5
Training loss: 0.5280707478523254
Validation loss: 1.6899791456037951

Epoch: 6| Step: 6
Training loss: 0.7004810571670532
Validation loss: 1.6829155555335424

Epoch: 6| Step: 7
Training loss: 0.7560343146324158
Validation loss: 1.6660839306410922

Epoch: 6| Step: 8
Training loss: 0.7629404664039612
Validation loss: 1.6817834646471086

Epoch: 6| Step: 9
Training loss: 1.1516276597976685
Validation loss: 1.6626528129782727

Epoch: 6| Step: 10
Training loss: 0.815530002117157
Validation loss: 1.6863851983060119

Epoch: 6| Step: 11
Training loss: 0.24319711327552795
Validation loss: 1.6986665802617227

Epoch: 6| Step: 12
Training loss: 0.5159003734588623
Validation loss: 1.743984116021023

Epoch: 6| Step: 13
Training loss: 0.8385093808174133
Validation loss: 1.7401927901852516

Epoch: 218| Step: 0
Training loss: 0.7651336193084717
Validation loss: 1.7796142870380032

Epoch: 6| Step: 1
Training loss: 0.7840082049369812
Validation loss: 1.8062278070757467

Epoch: 6| Step: 2
Training loss: 0.7302916049957275
Validation loss: 1.758129035272906

Epoch: 6| Step: 3
Training loss: 0.46339139342308044
Validation loss: 1.6960470496967275

Epoch: 6| Step: 4
Training loss: 0.7608001232147217
Validation loss: 1.7113019240799772

Epoch: 6| Step: 5
Training loss: 0.9999847412109375
Validation loss: 1.6832537151152087

Epoch: 6| Step: 6
Training loss: 0.43461373448371887
Validation loss: 1.6823307160408265

Epoch: 6| Step: 7
Training loss: 0.7914371490478516
Validation loss: 1.6697414510993547

Epoch: 6| Step: 8
Training loss: 0.8841663599014282
Validation loss: 1.6899355406402259

Epoch: 6| Step: 9
Training loss: 0.4105200469493866
Validation loss: 1.6703982199392011

Epoch: 6| Step: 10
Training loss: 1.031266689300537
Validation loss: 1.6920686357764787

Epoch: 6| Step: 11
Training loss: 0.5049574375152588
Validation loss: 1.7465858600472892

Epoch: 6| Step: 12
Training loss: 0.9408549070358276
Validation loss: 1.7817483358485724

Epoch: 6| Step: 13
Training loss: 0.4890845715999603
Validation loss: 1.768860690055355

Epoch: 219| Step: 0
Training loss: 0.5168178677558899
Validation loss: 1.7842235526730936

Epoch: 6| Step: 1
Training loss: 1.009019374847412
Validation loss: 1.734355890622703

Epoch: 6| Step: 2
Training loss: 1.0236599445343018
Validation loss: 1.738276397028277

Epoch: 6| Step: 3
Training loss: 0.5146907567977905
Validation loss: 1.7208012598817066

Epoch: 6| Step: 4
Training loss: 0.58094722032547
Validation loss: 1.7139016300119378

Epoch: 6| Step: 5
Training loss: 0.8452358245849609
Validation loss: 1.7150258582125428

Epoch: 6| Step: 6
Training loss: 0.8195317983627319
Validation loss: 1.7283079162720711

Epoch: 6| Step: 7
Training loss: 0.39510709047317505
Validation loss: 1.7106788799326906

Epoch: 6| Step: 8
Training loss: 0.7488712668418884
Validation loss: 1.7083976294404717

Epoch: 6| Step: 9
Training loss: 0.36826661229133606
Validation loss: 1.722002685710948

Epoch: 6| Step: 10
Training loss: 0.718034565448761
Validation loss: 1.732035401046917

Epoch: 6| Step: 11
Training loss: 0.3369000554084778
Validation loss: 1.7104336484786002

Epoch: 6| Step: 12
Training loss: 0.6477752327919006
Validation loss: 1.7193985369897657

Epoch: 6| Step: 13
Training loss: 0.6503949761390686
Validation loss: 1.7113158831032373

Epoch: 220| Step: 0
Training loss: 0.3975292146205902
Validation loss: 1.7127849517330047

Epoch: 6| Step: 1
Training loss: 0.6614261865615845
Validation loss: 1.7084205932514642

Epoch: 6| Step: 2
Training loss: 0.881490170955658
Validation loss: 1.7058730445882326

Epoch: 6| Step: 3
Training loss: 0.2932218313217163
Validation loss: 1.7160080607219408

Epoch: 6| Step: 4
Training loss: 0.8736562132835388
Validation loss: 1.736381124424678

Epoch: 6| Step: 5
Training loss: 0.2261832058429718
Validation loss: 1.7245188259309339

Epoch: 6| Step: 6
Training loss: 0.576619029045105
Validation loss: 1.7513571657160276

Epoch: 6| Step: 7
Training loss: 0.5687520503997803
Validation loss: 1.7354823145815121

Epoch: 6| Step: 8
Training loss: 0.4995618462562561
Validation loss: 1.7549404726233533

Epoch: 6| Step: 9
Training loss: 0.6904457807540894
Validation loss: 1.7173764680021553

Epoch: 6| Step: 10
Training loss: 0.48943448066711426
Validation loss: 1.7340741542077833

Epoch: 6| Step: 11
Training loss: 0.9369989633560181
Validation loss: 1.7346372117278397

Epoch: 6| Step: 12
Training loss: 0.8099901676177979
Validation loss: 1.6981758417621735

Epoch: 6| Step: 13
Training loss: 0.925887405872345
Validation loss: 1.713569538567656

Epoch: 221| Step: 0
Training loss: 0.5140841007232666
Validation loss: 1.7068546254147765

Epoch: 6| Step: 1
Training loss: 1.009655237197876
Validation loss: 1.7082506443864556

Epoch: 6| Step: 2
Training loss: 0.795313835144043
Validation loss: 1.7026006008989067

Epoch: 6| Step: 3
Training loss: 0.5186215043067932
Validation loss: 1.7275436642349407

Epoch: 6| Step: 4
Training loss: 0.5565066933631897
Validation loss: 1.7400188843409221

Epoch: 6| Step: 5
Training loss: 0.6604277491569519
Validation loss: 1.6925979378402873

Epoch: 6| Step: 6
Training loss: 0.5319504737854004
Validation loss: 1.6707513704094836

Epoch: 6| Step: 7
Training loss: 0.3443445563316345
Validation loss: 1.6883853661116732

Epoch: 6| Step: 8
Training loss: 0.4398743808269501
Validation loss: 1.7223502987174577

Epoch: 6| Step: 9
Training loss: 0.7255667448043823
Validation loss: 1.7157757718075988

Epoch: 6| Step: 10
Training loss: 0.8870241641998291
Validation loss: 1.727677974649655

Epoch: 6| Step: 11
Training loss: 0.4179637134075165
Validation loss: 1.7459972161118702

Epoch: 6| Step: 12
Training loss: 0.7157163619995117
Validation loss: 1.7320832501175583

Epoch: 6| Step: 13
Training loss: 0.5225399732589722
Validation loss: 1.746233817069761

Epoch: 222| Step: 0
Training loss: 0.4999898076057434
Validation loss: 1.717646268106276

Epoch: 6| Step: 1
Training loss: 0.7647421360015869
Validation loss: 1.7175639393509075

Epoch: 6| Step: 2
Training loss: 0.8705441951751709
Validation loss: 1.7199183869105514

Epoch: 6| Step: 3
Training loss: 0.5462081432342529
Validation loss: 1.7241832171716998

Epoch: 6| Step: 4
Training loss: 0.3164377212524414
Validation loss: 1.734821686180689

Epoch: 6| Step: 5
Training loss: 0.4628293216228485
Validation loss: 1.764967905577793

Epoch: 6| Step: 6
Training loss: 0.9642597436904907
Validation loss: 1.757989694995265

Epoch: 6| Step: 7
Training loss: 0.7051328420639038
Validation loss: 1.7132536954777215

Epoch: 6| Step: 8
Training loss: 0.4575654864311218
Validation loss: 1.7017744600131948

Epoch: 6| Step: 9
Training loss: 0.7330430150032043
Validation loss: 1.6794995723232147

Epoch: 6| Step: 10
Training loss: 0.5120444893836975
Validation loss: 1.683602467659981

Epoch: 6| Step: 11
Training loss: 0.7617032527923584
Validation loss: 1.7130181988080342

Epoch: 6| Step: 12
Training loss: 0.5761316418647766
Validation loss: 1.6981788835217875

Epoch: 6| Step: 13
Training loss: 0.327080637216568
Validation loss: 1.7041197899849183

Epoch: 223| Step: 0
Training loss: 0.6427004337310791
Validation loss: 1.7022773706784813

Epoch: 6| Step: 1
Training loss: 0.40320152044296265
Validation loss: 1.7026743940127793

Epoch: 6| Step: 2
Training loss: 0.5079632997512817
Validation loss: 1.6972544090722197

Epoch: 6| Step: 3
Training loss: 0.7318060994148254
Validation loss: 1.6812242205424974

Epoch: 6| Step: 4
Training loss: 0.9657289981842041
Validation loss: 1.6910759274677565

Epoch: 6| Step: 5
Training loss: 0.6589607000350952
Validation loss: 1.653021365083674

Epoch: 6| Step: 6
Training loss: 0.9158979654312134
Validation loss: 1.6638730943843882

Epoch: 6| Step: 7
Training loss: 0.681370735168457
Validation loss: 1.6705928912726782

Epoch: 6| Step: 8
Training loss: 0.5011755228042603
Validation loss: 1.6969103941353418

Epoch: 6| Step: 9
Training loss: 0.56011962890625
Validation loss: 1.7075430398346276

Epoch: 6| Step: 10
Training loss: 0.35070982575416565
Validation loss: 1.6957106628725607

Epoch: 6| Step: 11
Training loss: 0.5436211824417114
Validation loss: 1.7108674216014084

Epoch: 6| Step: 12
Training loss: 0.6403164267539978
Validation loss: 1.6759491248797345

Epoch: 6| Step: 13
Training loss: 0.10905294865369797
Validation loss: 1.6724448627041233

Epoch: 224| Step: 0
Training loss: 0.49719417095184326
Validation loss: 1.6598817110061646

Epoch: 6| Step: 1
Training loss: 0.5687282085418701
Validation loss: 1.6678246682690037

Epoch: 6| Step: 2
Training loss: 0.24742043018341064
Validation loss: 1.675887256540278

Epoch: 6| Step: 3
Training loss: 0.7259750366210938
Validation loss: 1.6720841174484582

Epoch: 6| Step: 4
Training loss: 0.6137096881866455
Validation loss: 1.6702759381263488

Epoch: 6| Step: 5
Training loss: 0.9819384813308716
Validation loss: 1.6935055832709036

Epoch: 6| Step: 6
Training loss: 0.2454850971698761
Validation loss: 1.6663714749838716

Epoch: 6| Step: 7
Training loss: 0.741217851638794
Validation loss: 1.7121672681582871

Epoch: 6| Step: 8
Training loss: 1.0320100784301758
Validation loss: 1.7281169083810621

Epoch: 6| Step: 9
Training loss: 0.3246767222881317
Validation loss: 1.718327610723434

Epoch: 6| Step: 10
Training loss: 0.31979408860206604
Validation loss: 1.6818763799564813

Epoch: 6| Step: 11
Training loss: 0.7627564072608948
Validation loss: 1.686327495882588

Epoch: 6| Step: 12
Training loss: 0.7388101816177368
Validation loss: 1.638538198445433

Epoch: 6| Step: 13
Training loss: 0.7071526646614075
Validation loss: 1.6594574374537314

Epoch: 225| Step: 0
Training loss: 0.773938775062561
Validation loss: 1.657115650433366

Epoch: 6| Step: 1
Training loss: 0.5310451984405518
Validation loss: 1.6794759535020398

Epoch: 6| Step: 2
Training loss: 0.7757405638694763
Validation loss: 1.683557862876564

Epoch: 6| Step: 3
Training loss: 0.6858516931533813
Validation loss: 1.6819257390114568

Epoch: 6| Step: 4
Training loss: 0.2431771606206894
Validation loss: 1.6941698058958976

Epoch: 6| Step: 5
Training loss: 0.40427765250205994
Validation loss: 1.7103563072860881

Epoch: 6| Step: 6
Training loss: 0.7628344297409058
Validation loss: 1.7088197123619817

Epoch: 6| Step: 7
Training loss: 0.7189635634422302
Validation loss: 1.6808276176452637

Epoch: 6| Step: 8
Training loss: 0.4757923483848572
Validation loss: 1.6795999388540945

Epoch: 6| Step: 9
Training loss: 0.8133171796798706
Validation loss: 1.6686286285359373

Epoch: 6| Step: 10
Training loss: 0.548408031463623
Validation loss: 1.676587841844046

Epoch: 6| Step: 11
Training loss: 0.6278112530708313
Validation loss: 1.6524482016922326

Epoch: 6| Step: 12
Training loss: 0.5082385540008545
Validation loss: 1.6646504658524708

Epoch: 6| Step: 13
Training loss: 0.575092077255249
Validation loss: 1.6922395735658624

Epoch: 226| Step: 0
Training loss: 0.8111344575881958
Validation loss: 1.6780975941688783

Epoch: 6| Step: 1
Training loss: 0.889333963394165
Validation loss: 1.7220066055174796

Epoch: 6| Step: 2
Training loss: 0.4157062768936157
Validation loss: 1.7006002164656115

Epoch: 6| Step: 3
Training loss: 0.6168848276138306
Validation loss: 1.685041218675593

Epoch: 6| Step: 4
Training loss: 0.44459837675094604
Validation loss: 1.6774830792539863

Epoch: 6| Step: 5
Training loss: 0.4617946445941925
Validation loss: 1.6632330161268993

Epoch: 6| Step: 6
Training loss: 0.6041591167449951
Validation loss: 1.6856209795962098

Epoch: 6| Step: 7
Training loss: 0.5738258957862854
Validation loss: 1.7117499677083825

Epoch: 6| Step: 8
Training loss: 0.7875672578811646
Validation loss: 1.7049987828859718

Epoch: 6| Step: 9
Training loss: 0.7759166955947876
Validation loss: 1.698804880983086

Epoch: 6| Step: 10
Training loss: 0.5718520283699036
Validation loss: 1.7125028666629587

Epoch: 6| Step: 11
Training loss: 0.347698837518692
Validation loss: 1.7047231857494642

Epoch: 6| Step: 12
Training loss: 0.3320361077785492
Validation loss: 1.7007101389669603

Epoch: 6| Step: 13
Training loss: 0.4213646948337555
Validation loss: 1.6875604993553572

Epoch: 227| Step: 0
Training loss: 0.4686996340751648
Validation loss: 1.6810702739223358

Epoch: 6| Step: 1
Training loss: 0.6812517046928406
Validation loss: 1.7146252227085892

Epoch: 6| Step: 2
Training loss: 0.547494649887085
Validation loss: 1.6994096848272509

Epoch: 6| Step: 3
Training loss: 0.6728711128234863
Validation loss: 1.6737333151601976

Epoch: 6| Step: 4
Training loss: 0.8056299686431885
Validation loss: 1.702803780955653

Epoch: 6| Step: 5
Training loss: 1.020700454711914
Validation loss: 1.697259569680819

Epoch: 6| Step: 6
Training loss: 0.549710750579834
Validation loss: 1.699829049007867

Epoch: 6| Step: 7
Training loss: 0.4266868233680725
Validation loss: 1.7018943525129748

Epoch: 6| Step: 8
Training loss: 0.45924752950668335
Validation loss: 1.6915159353645899

Epoch: 6| Step: 9
Training loss: 0.3471360206604004
Validation loss: 1.672787110010783

Epoch: 6| Step: 10
Training loss: 0.5865011215209961
Validation loss: 1.678131353470587

Epoch: 6| Step: 11
Training loss: 0.5140130519866943
Validation loss: 1.6708927590359923

Epoch: 6| Step: 12
Training loss: 0.5508736968040466
Validation loss: 1.6502424939986198

Epoch: 6| Step: 13
Training loss: 0.2808484435081482
Validation loss: 1.675173048050173

Epoch: 228| Step: 0
Training loss: 0.4562437832355499
Validation loss: 1.6634463853733514

Epoch: 6| Step: 1
Training loss: 0.735310435295105
Validation loss: 1.6818789256516324

Epoch: 6| Step: 2
Training loss: 0.607113242149353
Validation loss: 1.700079712816464

Epoch: 6| Step: 3
Training loss: 0.5574793815612793
Validation loss: 1.696466766377931

Epoch: 6| Step: 4
Training loss: 0.29756414890289307
Validation loss: 1.6866056444824382

Epoch: 6| Step: 5
Training loss: 0.5309596657752991
Validation loss: 1.6994321423192178

Epoch: 6| Step: 6
Training loss: 0.6767425537109375
Validation loss: 1.6903846533067766

Epoch: 6| Step: 7
Training loss: 0.5804103016853333
Validation loss: 1.688488087346477

Epoch: 6| Step: 8
Training loss: 0.5398637056350708
Validation loss: 1.6539963009536907

Epoch: 6| Step: 9
Training loss: 0.8552424311637878
Validation loss: 1.6612665781410791

Epoch: 6| Step: 10
Training loss: 0.9593679308891296
Validation loss: 1.6668890394190305

Epoch: 6| Step: 11
Training loss: 0.4792402982711792
Validation loss: 1.6591798387547976

Epoch: 6| Step: 12
Training loss: 0.561104953289032
Validation loss: 1.657377604515322

Epoch: 6| Step: 13
Training loss: 1.7471686601638794
Validation loss: 1.700538299416983

Epoch: 229| Step: 0
Training loss: 0.6187926530838013
Validation loss: 1.7560471744947537

Epoch: 6| Step: 1
Training loss: 0.3417247533798218
Validation loss: 1.7547484431215512

Epoch: 6| Step: 2
Training loss: 0.35869330167770386
Validation loss: 1.7274778555798274

Epoch: 6| Step: 3
Training loss: 0.5563338994979858
Validation loss: 1.780436869590513

Epoch: 6| Step: 4
Training loss: 0.47678038477897644
Validation loss: 1.7468846587724582

Epoch: 6| Step: 5
Training loss: 0.6416287422180176
Validation loss: 1.7261222075390559

Epoch: 6| Step: 6
Training loss: 0.8661144971847534
Validation loss: 1.6936368198804959

Epoch: 6| Step: 7
Training loss: 0.9902399778366089
Validation loss: 1.6801656523058492

Epoch: 6| Step: 8
Training loss: 0.6747153997421265
Validation loss: 1.6877708294058358

Epoch: 6| Step: 9
Training loss: 0.7433956861495972
Validation loss: 1.6995932927695654

Epoch: 6| Step: 10
Training loss: 0.3631281554698944
Validation loss: 1.7035579027668122

Epoch: 6| Step: 11
Training loss: 0.7246167063713074
Validation loss: 1.7105692663500387

Epoch: 6| Step: 12
Training loss: 0.6147590279579163
Validation loss: 1.7244249723290885

Epoch: 6| Step: 13
Training loss: 0.43636780977249146
Validation loss: 1.7401221183038527

Epoch: 230| Step: 0
Training loss: 0.3469661474227905
Validation loss: 1.7392751478379773

Epoch: 6| Step: 1
Training loss: 0.582607626914978
Validation loss: 1.7223912926130398

Epoch: 6| Step: 2
Training loss: 0.708696722984314
Validation loss: 1.7045677784950501

Epoch: 6| Step: 3
Training loss: 0.4910837411880493
Validation loss: 1.713695142858772

Epoch: 6| Step: 4
Training loss: 0.5619264245033264
Validation loss: 1.7182115547118648

Epoch: 6| Step: 5
Training loss: 0.447745680809021
Validation loss: 1.7146332110128095

Epoch: 6| Step: 6
Training loss: 0.543070912361145
Validation loss: 1.7295655024948942

Epoch: 6| Step: 7
Training loss: 0.9251316785812378
Validation loss: 1.7416897243069065

Epoch: 6| Step: 8
Training loss: 0.6967109441757202
Validation loss: 1.768216888109843

Epoch: 6| Step: 9
Training loss: 0.7174598574638367
Validation loss: 1.7734721886214388

Epoch: 6| Step: 10
Training loss: 0.5575563907623291
Validation loss: 1.7353003512146652

Epoch: 6| Step: 11
Training loss: 0.3451290726661682
Validation loss: 1.6960672204212477

Epoch: 6| Step: 12
Training loss: 0.7231508493423462
Validation loss: 1.7052051739026142

Epoch: 6| Step: 13
Training loss: 0.613540768623352
Validation loss: 1.680691299899932

Epoch: 231| Step: 0
Training loss: 0.6155149936676025
Validation loss: 1.6574684907031316

Epoch: 6| Step: 1
Training loss: 0.8733868598937988
Validation loss: 1.6800859038547804

Epoch: 6| Step: 2
Training loss: 0.5529487729072571
Validation loss: 1.6656378456341323

Epoch: 6| Step: 3
Training loss: 0.5429362058639526
Validation loss: 1.6628084362194102

Epoch: 6| Step: 4
Training loss: 0.7149571180343628
Validation loss: 1.6819648281220467

Epoch: 6| Step: 5
Training loss: 0.5365960001945496
Validation loss: 1.72066835177842

Epoch: 6| Step: 6
Training loss: 0.7538833618164062
Validation loss: 1.7210477090650989

Epoch: 6| Step: 7
Training loss: 0.7538657784461975
Validation loss: 1.7003068667586132

Epoch: 6| Step: 8
Training loss: 0.46486636996269226
Validation loss: 1.7074998681263258

Epoch: 6| Step: 9
Training loss: 0.6969294548034668
Validation loss: 1.7132455623278053

Epoch: 6| Step: 10
Training loss: 0.4276643395423889
Validation loss: 1.7066474806877874

Epoch: 6| Step: 11
Training loss: 0.5070648193359375
Validation loss: 1.6950103262419343

Epoch: 6| Step: 12
Training loss: 0.6788489818572998
Validation loss: 1.713120945038334

Epoch: 6| Step: 13
Training loss: 0.3373238742351532
Validation loss: 1.7172056833902996

Epoch: 232| Step: 0
Training loss: 0.18318143486976624
Validation loss: 1.7250121690893685

Epoch: 6| Step: 1
Training loss: 0.7243021130561829
Validation loss: 1.687016607612692

Epoch: 6| Step: 2
Training loss: 0.42384064197540283
Validation loss: 1.6728012907889582

Epoch: 6| Step: 3
Training loss: 0.4004204273223877
Validation loss: 1.648261515043115

Epoch: 6| Step: 4
Training loss: 0.5088950395584106
Validation loss: 1.616207456076017

Epoch: 6| Step: 5
Training loss: 0.9004076719284058
Validation loss: 1.6217285061395297

Epoch: 6| Step: 6
Training loss: 0.40192627906799316
Validation loss: 1.6418902540719638

Epoch: 6| Step: 7
Training loss: 0.7055770754814148
Validation loss: 1.6649571644362582

Epoch: 6| Step: 8
Training loss: 0.4076725244522095
Validation loss: 1.6772515248226862

Epoch: 6| Step: 9
Training loss: 0.5166829228401184
Validation loss: 1.7059944355359642

Epoch: 6| Step: 10
Training loss: 0.9901114106178284
Validation loss: 1.7241422143033756

Epoch: 6| Step: 11
Training loss: 0.6496171355247498
Validation loss: 1.7078170161093436

Epoch: 6| Step: 12
Training loss: 0.6806308031082153
Validation loss: 1.703104237074493

Epoch: 6| Step: 13
Training loss: 0.5513699650764465
Validation loss: 1.6878488961086477

Epoch: 233| Step: 0
Training loss: 0.5089998841285706
Validation loss: 1.6866215185452533

Epoch: 6| Step: 1
Training loss: 0.7318100929260254
Validation loss: 1.6961429606201828

Epoch: 6| Step: 2
Training loss: 0.9496129751205444
Validation loss: 1.7040435626942625

Epoch: 6| Step: 3
Training loss: 1.0909630060195923
Validation loss: 1.6936970269808205

Epoch: 6| Step: 4
Training loss: 0.3344009220600128
Validation loss: 1.6588525849003946

Epoch: 6| Step: 5
Training loss: 0.421608030796051
Validation loss: 1.6950171737260715

Epoch: 6| Step: 6
Training loss: 0.6843663454055786
Validation loss: 1.7373659495384461

Epoch: 6| Step: 7
Training loss: 0.5880615711212158
Validation loss: 1.7798782933142878

Epoch: 6| Step: 8
Training loss: 0.6714469194412231
Validation loss: 1.8178103405942199

Epoch: 6| Step: 9
Training loss: 0.5560858249664307
Validation loss: 1.7781563394813127

Epoch: 6| Step: 10
Training loss: 0.3101646900177002
Validation loss: 1.6884152363705378

Epoch: 6| Step: 11
Training loss: 0.6462090015411377
Validation loss: 1.628251314163208

Epoch: 6| Step: 12
Training loss: 0.5653469562530518
Validation loss: 1.6569435314465595

Epoch: 6| Step: 13
Training loss: 0.8795290589332581
Validation loss: 1.6487780809402466

Epoch: 234| Step: 0
Training loss: 0.7333930730819702
Validation loss: 1.6502636248065579

Epoch: 6| Step: 1
Training loss: 0.5053001046180725
Validation loss: 1.6630754816916682

Epoch: 6| Step: 2
Training loss: 0.5632056593894958
Validation loss: 1.6547114720908545

Epoch: 6| Step: 3
Training loss: 0.5544277429580688
Validation loss: 1.6943270634579402

Epoch: 6| Step: 4
Training loss: 0.5751254558563232
Validation loss: 1.7050579401754564

Epoch: 6| Step: 5
Training loss: 0.7829951047897339
Validation loss: 1.7510957256440194

Epoch: 6| Step: 6
Training loss: 0.5145554542541504
Validation loss: 1.7342285161377282

Epoch: 6| Step: 7
Training loss: 0.6338945627212524
Validation loss: 1.737002444523637

Epoch: 6| Step: 8
Training loss: 0.5254581570625305
Validation loss: 1.7210642419835573

Epoch: 6| Step: 9
Training loss: 0.4325120747089386
Validation loss: 1.7183782374987038

Epoch: 6| Step: 10
Training loss: 0.5945302248001099
Validation loss: 1.699276613932784

Epoch: 6| Step: 11
Training loss: 0.48091843724250793
Validation loss: 1.7235640851400231

Epoch: 6| Step: 12
Training loss: 0.8004393577575684
Validation loss: 1.73898833797824

Epoch: 6| Step: 13
Training loss: 1.1786190271377563
Validation loss: 1.7255431516196138

Epoch: 235| Step: 0
Training loss: 0.5137389898300171
Validation loss: 1.739898463731171

Epoch: 6| Step: 1
Training loss: 0.4630364179611206
Validation loss: 1.746262482417527

Epoch: 6| Step: 2
Training loss: 0.6945511102676392
Validation loss: 1.7414724762721727

Epoch: 6| Step: 3
Training loss: 0.5920125842094421
Validation loss: 1.7268992034337853

Epoch: 6| Step: 4
Training loss: 0.39324042201042175
Validation loss: 1.7032526744309293

Epoch: 6| Step: 5
Training loss: 0.7450957894325256
Validation loss: 1.7070288850415138

Epoch: 6| Step: 6
Training loss: 0.6998404264450073
Validation loss: 1.6996564339565974

Epoch: 6| Step: 7
Training loss: 0.3911844491958618
Validation loss: 1.7116907629915463

Epoch: 6| Step: 8
Training loss: 0.5139382481575012
Validation loss: 1.7111666625545872

Epoch: 6| Step: 9
Training loss: 0.21989552676677704
Validation loss: 1.6970832604233936

Epoch: 6| Step: 10
Training loss: 0.6919254064559937
Validation loss: 1.670692431029453

Epoch: 6| Step: 11
Training loss: 0.5743848085403442
Validation loss: 1.6500114907500565

Epoch: 6| Step: 12
Training loss: 0.44029751420021057
Validation loss: 1.6484589666448615

Epoch: 6| Step: 13
Training loss: 0.8224120140075684
Validation loss: 1.6844443403264528

Epoch: 236| Step: 0
Training loss: 0.5344231128692627
Validation loss: 1.6924479558903684

Epoch: 6| Step: 1
Training loss: 0.4420669674873352
Validation loss: 1.672405905621026

Epoch: 6| Step: 2
Training loss: 0.6186994314193726
Validation loss: 1.6707199696571595

Epoch: 6| Step: 3
Training loss: 0.9047824144363403
Validation loss: 1.7119814657395886

Epoch: 6| Step: 4
Training loss: 0.5744227170944214
Validation loss: 1.7167571347246888

Epoch: 6| Step: 5
Training loss: 0.3472999632358551
Validation loss: 1.6900833370865032

Epoch: 6| Step: 6
Training loss: 0.29156622290611267
Validation loss: 1.6946702388025099

Epoch: 6| Step: 7
Training loss: 0.5346008539199829
Validation loss: 1.692744856239647

Epoch: 6| Step: 8
Training loss: 0.28149503469467163
Validation loss: 1.6827291493774743

Epoch: 6| Step: 9
Training loss: 0.5238097310066223
Validation loss: 1.6876076254793393

Epoch: 6| Step: 10
Training loss: 0.5558590292930603
Validation loss: 1.7103078762690227

Epoch: 6| Step: 11
Training loss: 0.6310572624206543
Validation loss: 1.7566178178274503

Epoch: 6| Step: 12
Training loss: 0.6965389847755432
Validation loss: 1.7832590456931823

Epoch: 6| Step: 13
Training loss: 0.631693422794342
Validation loss: 1.7760155662413566

Epoch: 237| Step: 0
Training loss: 0.6502108573913574
Validation loss: 1.7527436178217652

Epoch: 6| Step: 1
Training loss: 0.7390481233596802
Validation loss: 1.7403538573172785

Epoch: 6| Step: 2
Training loss: 0.593803882598877
Validation loss: 1.6750390401450537

Epoch: 6| Step: 3
Training loss: 0.5015212893486023
Validation loss: 1.6627518284705378

Epoch: 6| Step: 4
Training loss: 0.16791512072086334
Validation loss: 1.6812584130994734

Epoch: 6| Step: 5
Training loss: 0.9665037989616394
Validation loss: 1.677132034814486

Epoch: 6| Step: 6
Training loss: 0.3760325014591217
Validation loss: 1.6843093479833295

Epoch: 6| Step: 7
Training loss: 0.5571222305297852
Validation loss: 1.6958494737584104

Epoch: 6| Step: 8
Training loss: 0.38757872581481934
Validation loss: 1.728749954572288

Epoch: 6| Step: 9
Training loss: 0.26672643423080444
Validation loss: 1.7474021219438123

Epoch: 6| Step: 10
Training loss: 0.45214876532554626
Validation loss: 1.7671663556047665

Epoch: 6| Step: 11
Training loss: 0.8395527005195618
Validation loss: 1.7476882178296325

Epoch: 6| Step: 12
Training loss: 0.565761923789978
Validation loss: 1.6943368681015507

Epoch: 6| Step: 13
Training loss: 0.39017438888549805
Validation loss: 1.6739194162430302

Epoch: 238| Step: 0
Training loss: 0.4919283092021942
Validation loss: 1.6524670072781142

Epoch: 6| Step: 1
Training loss: 0.39846372604370117
Validation loss: 1.6296007581936416

Epoch: 6| Step: 2
Training loss: 0.48211100697517395
Validation loss: 1.6549218431595834

Epoch: 6| Step: 3
Training loss: 0.749533474445343
Validation loss: 1.6359342746837164

Epoch: 6| Step: 4
Training loss: 0.5368208885192871
Validation loss: 1.6505680039364805

Epoch: 6| Step: 5
Training loss: 0.7560185790061951
Validation loss: 1.684636285228114

Epoch: 6| Step: 6
Training loss: 0.20135222375392914
Validation loss: 1.6903028847068868

Epoch: 6| Step: 7
Training loss: 0.8081876039505005
Validation loss: 1.706957801695793

Epoch: 6| Step: 8
Training loss: 0.5121092796325684
Validation loss: 1.6971134960010488

Epoch: 6| Step: 9
Training loss: 0.7951762676239014
Validation loss: 1.6939903279786468

Epoch: 6| Step: 10
Training loss: 0.6386575698852539
Validation loss: 1.6984698951885264

Epoch: 6| Step: 11
Training loss: 0.48837921023368835
Validation loss: 1.7131250776270384

Epoch: 6| Step: 12
Training loss: 0.33685940504074097
Validation loss: 1.7077792101008917

Epoch: 6| Step: 13
Training loss: 0.48018503189086914
Validation loss: 1.7095369690208024

Epoch: 239| Step: 0
Training loss: 0.6068011522293091
Validation loss: 1.7137920138656453

Epoch: 6| Step: 1
Training loss: 0.5306289196014404
Validation loss: 1.6822054296411493

Epoch: 6| Step: 2
Training loss: 0.3483263850212097
Validation loss: 1.717725710202289

Epoch: 6| Step: 3
Training loss: 0.30353260040283203
Validation loss: 1.7076107481474518

Epoch: 6| Step: 4
Training loss: 0.6211585998535156
Validation loss: 1.6902592182159424

Epoch: 6| Step: 5
Training loss: 0.46180224418640137
Validation loss: 1.670698332530196

Epoch: 6| Step: 6
Training loss: 0.42746561765670776
Validation loss: 1.7016128404166109

Epoch: 6| Step: 7
Training loss: 0.6068851947784424
Validation loss: 1.7582694740705593

Epoch: 6| Step: 8
Training loss: 0.35628876090049744
Validation loss: 1.7632594634127874

Epoch: 6| Step: 9
Training loss: 0.7628347277641296
Validation loss: 1.7331093344637143

Epoch: 6| Step: 10
Training loss: 0.7990652322769165
Validation loss: 1.6762041891774824

Epoch: 6| Step: 11
Training loss: 0.5262293815612793
Validation loss: 1.666879564203242

Epoch: 6| Step: 12
Training loss: 0.5010402202606201
Validation loss: 1.6357030278892928

Epoch: 6| Step: 13
Training loss: 0.7552594542503357
Validation loss: 1.6405453822946037

Epoch: 240| Step: 0
Training loss: 0.44285380840301514
Validation loss: 1.6374864962793165

Epoch: 6| Step: 1
Training loss: 0.6202528476715088
Validation loss: 1.6223564737586564

Epoch: 6| Step: 2
Training loss: 0.414704293012619
Validation loss: 1.6614701388984598

Epoch: 6| Step: 3
Training loss: 0.7588706016540527
Validation loss: 1.7238922272959063

Epoch: 6| Step: 4
Training loss: 0.2985333204269409
Validation loss: 1.7910689487252185

Epoch: 6| Step: 5
Training loss: 0.6233077049255371
Validation loss: 1.8025079773318382

Epoch: 6| Step: 6
Training loss: 0.49929001927375793
Validation loss: 1.7808224206329675

Epoch: 6| Step: 7
Training loss: 0.6516944169998169
Validation loss: 1.6853847952299221

Epoch: 6| Step: 8
Training loss: 0.6005861759185791
Validation loss: 1.6563822505294636

Epoch: 6| Step: 9
Training loss: 0.7032754421234131
Validation loss: 1.6542675469511299

Epoch: 6| Step: 10
Training loss: 0.37327250838279724
Validation loss: 1.6666978213094896

Epoch: 6| Step: 11
Training loss: 0.7115250825881958
Validation loss: 1.7263465004582559

Epoch: 6| Step: 12
Training loss: 1.0054229497909546
Validation loss: 1.7133721536205662

Epoch: 6| Step: 13
Training loss: 0.8287561535835266
Validation loss: 1.7188641948084677

Epoch: 241| Step: 0
Training loss: 0.9868186712265015
Validation loss: 1.6709054375207553

Epoch: 6| Step: 1
Training loss: 0.5168291926383972
Validation loss: 1.6402303416241881

Epoch: 6| Step: 2
Training loss: 0.5236459970474243
Validation loss: 1.661638489333532

Epoch: 6| Step: 3
Training loss: 0.28498637676239014
Validation loss: 1.6822629269733225

Epoch: 6| Step: 4
Training loss: 0.6566412448883057
Validation loss: 1.720813839666305

Epoch: 6| Step: 5
Training loss: 0.5796619057655334
Validation loss: 1.6937392014329151

Epoch: 6| Step: 6
Training loss: 0.604918360710144
Validation loss: 1.6871528651124688

Epoch: 6| Step: 7
Training loss: 0.7221626043319702
Validation loss: 1.6731815415043985

Epoch: 6| Step: 8
Training loss: 0.7217893600463867
Validation loss: 1.663796273610925

Epoch: 6| Step: 9
Training loss: 0.42229872941970825
Validation loss: 1.6687975634810746

Epoch: 6| Step: 10
Training loss: 0.5956254005432129
Validation loss: 1.6921828087940012

Epoch: 6| Step: 11
Training loss: 0.3994959592819214
Validation loss: 1.7108920979243454

Epoch: 6| Step: 12
Training loss: 0.6142750382423401
Validation loss: 1.741765461942201

Epoch: 6| Step: 13
Training loss: 0.6416813731193542
Validation loss: 1.7789235345778927

Epoch: 242| Step: 0
Training loss: 0.4937099814414978
Validation loss: 1.7506234158751786

Epoch: 6| Step: 1
Training loss: 0.39872682094573975
Validation loss: 1.7533595228707919

Epoch: 6| Step: 2
Training loss: 0.786096453666687
Validation loss: 1.717775034648116

Epoch: 6| Step: 3
Training loss: 0.3389347791671753
Validation loss: 1.7099469015675206

Epoch: 6| Step: 4
Training loss: 0.35973262786865234
Validation loss: 1.6747321326245543

Epoch: 6| Step: 5
Training loss: 0.6196452975273132
Validation loss: 1.6828368812478998

Epoch: 6| Step: 6
Training loss: 0.3418095111846924
Validation loss: 1.6897342307593233

Epoch: 6| Step: 7
Training loss: 0.307577908039093
Validation loss: 1.6847489687704271

Epoch: 6| Step: 8
Training loss: 0.5733799934387207
Validation loss: 1.6806203985726962

Epoch: 6| Step: 9
Training loss: 0.7571862936019897
Validation loss: 1.6895497101609425

Epoch: 6| Step: 10
Training loss: 0.6236743927001953
Validation loss: 1.682332896417187

Epoch: 6| Step: 11
Training loss: 0.39321279525756836
Validation loss: 1.6584232250849407

Epoch: 6| Step: 12
Training loss: 0.5594926476478577
Validation loss: 1.6433375535472747

Epoch: 6| Step: 13
Training loss: 0.24906842410564423
Validation loss: 1.627779718368284

Epoch: 243| Step: 0
Training loss: 0.36000996828079224
Validation loss: 1.6366690166534916

Epoch: 6| Step: 1
Training loss: 0.67592453956604
Validation loss: 1.6406420764102732

Epoch: 6| Step: 2
Training loss: 0.4435565769672394
Validation loss: 1.6495556754450644

Epoch: 6| Step: 3
Training loss: 0.6419169902801514
Validation loss: 1.6533972909373622

Epoch: 6| Step: 4
Training loss: 0.4135991036891937
Validation loss: 1.6798386061063377

Epoch: 6| Step: 5
Training loss: 0.36998414993286133
Validation loss: 1.6869124263845465

Epoch: 6| Step: 6
Training loss: 0.3829789161682129
Validation loss: 1.676411231358846

Epoch: 6| Step: 7
Training loss: 0.44675999879837036
Validation loss: 1.653463057292405

Epoch: 6| Step: 8
Training loss: 0.32895880937576294
Validation loss: 1.6741254688591085

Epoch: 6| Step: 9
Training loss: 0.5411754250526428
Validation loss: 1.6908787963210896

Epoch: 6| Step: 10
Training loss: 0.5558067560195923
Validation loss: 1.675922788599486

Epoch: 6| Step: 11
Training loss: 0.5090526938438416
Validation loss: 1.6974375978592904

Epoch: 6| Step: 12
Training loss: 0.9518289566040039
Validation loss: 1.6990006316092707

Epoch: 6| Step: 13
Training loss: 0.43870818614959717
Validation loss: 1.7080353639459098

Epoch: 244| Step: 0
Training loss: 0.6333342790603638
Validation loss: 1.7336959992685625

Epoch: 6| Step: 1
Training loss: 0.7130353450775146
Validation loss: 1.7315007050832112

Epoch: 6| Step: 2
Training loss: 0.43302375078201294
Validation loss: 1.7453455912169589

Epoch: 6| Step: 3
Training loss: 0.5133427381515503
Validation loss: 1.6967721216140255

Epoch: 6| Step: 4
Training loss: 0.30774611234664917
Validation loss: 1.640363247163834

Epoch: 6| Step: 5
Training loss: 0.49538934230804443
Validation loss: 1.6168014029020905

Epoch: 6| Step: 6
Training loss: 0.5938392281532288
Validation loss: 1.5701595057723343

Epoch: 6| Step: 7
Training loss: 0.9060201644897461
Validation loss: 1.5619214311722787

Epoch: 6| Step: 8
Training loss: 0.5064974427223206
Validation loss: 1.5939123938160558

Epoch: 6| Step: 9
Training loss: 0.3070910573005676
Validation loss: 1.620432702443933

Epoch: 6| Step: 10
Training loss: 0.44813674688339233
Validation loss: 1.6253560435387395

Epoch: 6| Step: 11
Training loss: 0.3588235080242157
Validation loss: 1.6264557864076348

Epoch: 6| Step: 12
Training loss: 0.27798521518707275
Validation loss: 1.6117529279442244

Epoch: 6| Step: 13
Training loss: 0.8760707378387451
Validation loss: 1.616440842228551

Epoch: 245| Step: 0
Training loss: 0.4048975706100464
Validation loss: 1.5781402254617343

Epoch: 6| Step: 1
Training loss: 0.37175461649894714
Validation loss: 1.5498510970864245

Epoch: 6| Step: 2
Training loss: 0.395548939704895
Validation loss: 1.5525194021963304

Epoch: 6| Step: 3
Training loss: 0.778998076915741
Validation loss: 1.5704335794653943

Epoch: 6| Step: 4
Training loss: 0.30655211210250854
Validation loss: 1.5646934176004061

Epoch: 6| Step: 5
Training loss: 0.7946754097938538
Validation loss: 1.58310450789749

Epoch: 6| Step: 6
Training loss: 0.3817836046218872
Validation loss: 1.5974012126204788

Epoch: 6| Step: 7
Training loss: 0.3395434617996216
Validation loss: 1.6463663526760635

Epoch: 6| Step: 8
Training loss: 0.44964224100112915
Validation loss: 1.666317484712088

Epoch: 6| Step: 9
Training loss: 0.4716797471046448
Validation loss: 1.6607479779951033

Epoch: 6| Step: 10
Training loss: 0.47555577754974365
Validation loss: 1.655846930319263

Epoch: 6| Step: 11
Training loss: 0.7842423915863037
Validation loss: 1.6523552299827657

Epoch: 6| Step: 12
Training loss: 0.42093515396118164
Validation loss: 1.643894209015754

Epoch: 6| Step: 13
Training loss: 0.5613430738449097
Validation loss: 1.6488901774088542

Epoch: 246| Step: 0
Training loss: 0.5631343126296997
Validation loss: 1.6687178816846622

Epoch: 6| Step: 1
Training loss: 0.16730263829231262
Validation loss: 1.6483397573553107

Epoch: 6| Step: 2
Training loss: 0.45175987482070923
Validation loss: 1.6278036794354838

Epoch: 6| Step: 3
Training loss: 0.6404969096183777
Validation loss: 1.651944064324902

Epoch: 6| Step: 4
Training loss: 0.5997861623764038
Validation loss: 1.6270196130198817

Epoch: 6| Step: 5
Training loss: 0.43298596143722534
Validation loss: 1.6363741479894167

Epoch: 6| Step: 6
Training loss: 0.6559138298034668
Validation loss: 1.6526790139495686

Epoch: 6| Step: 7
Training loss: 0.28477993607521057
Validation loss: 1.6472211396822365

Epoch: 6| Step: 8
Training loss: 0.6026111841201782
Validation loss: 1.6496625036321662

Epoch: 6| Step: 9
Training loss: 0.45517444610595703
Validation loss: 1.644819651880572

Epoch: 6| Step: 10
Training loss: 0.5407109260559082
Validation loss: 1.623063023372363

Epoch: 6| Step: 11
Training loss: 0.709887683391571
Validation loss: 1.6184371363732122

Epoch: 6| Step: 12
Training loss: 0.31081700325012207
Validation loss: 1.6610190304376746

Epoch: 6| Step: 13
Training loss: 0.29356086254119873
Validation loss: 1.6618559873232277

Epoch: 247| Step: 0
Training loss: 0.6363928914070129
Validation loss: 1.691281323791832

Epoch: 6| Step: 1
Training loss: 0.6388168334960938
Validation loss: 1.7315498321287093

Epoch: 6| Step: 2
Training loss: 0.4820999801158905
Validation loss: 1.7052030729991134

Epoch: 6| Step: 3
Training loss: 0.7636561393737793
Validation loss: 1.7236391831469793

Epoch: 6| Step: 4
Training loss: 0.5201051235198975
Validation loss: 1.678678063936131

Epoch: 6| Step: 5
Training loss: 0.5030564069747925
Validation loss: 1.6504799576215847

Epoch: 6| Step: 6
Training loss: 0.7197448015213013
Validation loss: 1.6300977724854664

Epoch: 6| Step: 7
Training loss: 0.4914824068546295
Validation loss: 1.6371738987584268

Epoch: 6| Step: 8
Training loss: 0.38408583402633667
Validation loss: 1.6524593445562548

Epoch: 6| Step: 9
Training loss: 0.22374458611011505
Validation loss: 1.6272881902674192

Epoch: 6| Step: 10
Training loss: 0.2823099195957184
Validation loss: 1.6427515873344996

Epoch: 6| Step: 11
Training loss: 0.4828035831451416
Validation loss: 1.6670150769654142

Epoch: 6| Step: 12
Training loss: 0.36287230253219604
Validation loss: 1.6455928894781298

Epoch: 6| Step: 13
Training loss: 0.6625075340270996
Validation loss: 1.6969617054026613

Epoch: 248| Step: 0
Training loss: 0.7428110837936401
Validation loss: 1.7210202640102756

Epoch: 6| Step: 1
Training loss: 0.5838595628738403
Validation loss: 1.7338131807183708

Epoch: 6| Step: 2
Training loss: 0.674889326095581
Validation loss: 1.7787461011640486

Epoch: 6| Step: 3
Training loss: 0.5457701086997986
Validation loss: 1.773667000955151

Epoch: 6| Step: 4
Training loss: 0.4180404543876648
Validation loss: 1.7312143118150773

Epoch: 6| Step: 5
Training loss: 0.20013603568077087
Validation loss: 1.6761363783190328

Epoch: 6| Step: 6
Training loss: 0.32933545112609863
Validation loss: 1.6558601138412312

Epoch: 6| Step: 7
Training loss: 0.49248620867729187
Validation loss: 1.6561631976917226

Epoch: 6| Step: 8
Training loss: 0.4821849465370178
Validation loss: 1.6519772878257177

Epoch: 6| Step: 9
Training loss: 0.31136220693588257
Validation loss: 1.6286604340358446

Epoch: 6| Step: 10
Training loss: 0.8175957798957825
Validation loss: 1.6409346929160498

Epoch: 6| Step: 11
Training loss: 0.5221719741821289
Validation loss: 1.6346624999917962

Epoch: 6| Step: 12
Training loss: 0.458749383687973
Validation loss: 1.6749520186455018

Epoch: 6| Step: 13
Training loss: 0.27308642864227295
Validation loss: 1.6732121526554067

Epoch: 249| Step: 0
Training loss: 0.5430695414543152
Validation loss: 1.6945790295959802

Epoch: 6| Step: 1
Training loss: 0.36518269777297974
Validation loss: 1.6778008425107567

Epoch: 6| Step: 2
Training loss: 0.450420081615448
Validation loss: 1.6881937339741697

Epoch: 6| Step: 3
Training loss: 0.49153703451156616
Validation loss: 1.683832562097939

Epoch: 6| Step: 4
Training loss: 0.23146061599254608
Validation loss: 1.6520509976212696

Epoch: 6| Step: 5
Training loss: 0.40332186222076416
Validation loss: 1.6649331828599334

Epoch: 6| Step: 6
Training loss: 0.5881360173225403
Validation loss: 1.6298512348564722

Epoch: 6| Step: 7
Training loss: 0.4946027100086212
Validation loss: 1.6353025590219805

Epoch: 6| Step: 8
Training loss: 0.385073721408844
Validation loss: 1.6228868230696647

Epoch: 6| Step: 9
Training loss: 0.5795354247093201
Validation loss: 1.6469249206204568

Epoch: 6| Step: 10
Training loss: 0.5441076755523682
Validation loss: 1.6720484302889915

Epoch: 6| Step: 11
Training loss: 0.4241979718208313
Validation loss: 1.731565434445617

Epoch: 6| Step: 12
Training loss: 0.7030965089797974
Validation loss: 1.7299271245156564

Epoch: 6| Step: 13
Training loss: 0.6496821045875549
Validation loss: 1.6677840832741029

Epoch: 250| Step: 0
Training loss: 0.3751755952835083
Validation loss: 1.6270716882521106

Epoch: 6| Step: 1
Training loss: 0.4515119791030884
Validation loss: 1.590418625903386

Epoch: 6| Step: 2
Training loss: 0.7169706225395203
Validation loss: 1.581461464205096

Epoch: 6| Step: 3
Training loss: 0.4049193263053894
Validation loss: 1.589636980846364

Epoch: 6| Step: 4
Training loss: 0.303132027387619
Validation loss: 1.5877310563159246

Epoch: 6| Step: 5
Training loss: 0.43569692969322205
Validation loss: 1.5889172246379237

Epoch: 6| Step: 6
Training loss: 0.3972856402397156
Validation loss: 1.6247556363382647

Epoch: 6| Step: 7
Training loss: 0.5125610828399658
Validation loss: 1.6482988185780023

Epoch: 6| Step: 8
Training loss: 0.48641282320022583
Validation loss: 1.7102804248050978

Epoch: 6| Step: 9
Training loss: 0.27551284432411194
Validation loss: 1.6912649831464213

Epoch: 6| Step: 10
Training loss: 0.3076385259628296
Validation loss: 1.679664905353259

Epoch: 6| Step: 11
Training loss: 0.44824671745300293
Validation loss: 1.6628735296187862

Epoch: 6| Step: 12
Training loss: 0.6520670652389526
Validation loss: 1.6009052645775579

Epoch: 6| Step: 13
Training loss: 0.959885835647583
Validation loss: 1.6412697710016722

Epoch: 251| Step: 0
Training loss: 0.35145601630210876
Validation loss: 1.6372108305654218

Epoch: 6| Step: 1
Training loss: 0.6211513876914978
Validation loss: 1.6679989971140379

Epoch: 6| Step: 2
Training loss: 0.4434414207935333
Validation loss: 1.6530338359135452

Epoch: 6| Step: 3
Training loss: 0.33619624376296997
Validation loss: 1.6434653318056496

Epoch: 6| Step: 4
Training loss: 0.42255911231040955
Validation loss: 1.6456109516082271

Epoch: 6| Step: 5
Training loss: 0.4939091205596924
Validation loss: 1.6284174432036698

Epoch: 6| Step: 6
Training loss: 0.6681134700775146
Validation loss: 1.6173554569162347

Epoch: 6| Step: 7
Training loss: 0.36554861068725586
Validation loss: 1.6142817953581452

Epoch: 6| Step: 8
Training loss: 0.1973632425069809
Validation loss: 1.6339498931361782

Epoch: 6| Step: 9
Training loss: 0.6108497381210327
Validation loss: 1.6515688793633574

Epoch: 6| Step: 10
Training loss: 0.2943323850631714
Validation loss: 1.669974782133615

Epoch: 6| Step: 11
Training loss: 0.6802499294281006
Validation loss: 1.649669551080273

Epoch: 6| Step: 12
Training loss: 0.6027306318283081
Validation loss: 1.6653270157434608

Epoch: 6| Step: 13
Training loss: 0.21038955450057983
Validation loss: 1.6511785932766494

Epoch: 252| Step: 0
Training loss: 0.4599602520465851
Validation loss: 1.6099787706969886

Epoch: 6| Step: 1
Training loss: 0.44265007972717285
Validation loss: 1.594247256555865

Epoch: 6| Step: 2
Training loss: 0.3083878457546234
Validation loss: 1.5946926314343688

Epoch: 6| Step: 3
Training loss: 0.18419891595840454
Validation loss: 1.5788631208481327

Epoch: 6| Step: 4
Training loss: 0.8348919749259949
Validation loss: 1.592256333238335

Epoch: 6| Step: 5
Training loss: 0.499208927154541
Validation loss: 1.6089477359607656

Epoch: 6| Step: 6
Training loss: 0.43517041206359863
Validation loss: 1.6338836941667783

Epoch: 6| Step: 7
Training loss: 0.5221117734909058
Validation loss: 1.6457075034418414

Epoch: 6| Step: 8
Training loss: 0.3220805823802948
Validation loss: 1.6461686767557615

Epoch: 6| Step: 9
Training loss: 0.4497915506362915
Validation loss: 1.650660563540715

Epoch: 6| Step: 10
Training loss: 0.20899038016796112
Validation loss: 1.6324255402370165

Epoch: 6| Step: 11
Training loss: 0.3686944246292114
Validation loss: 1.6381224637390466

Epoch: 6| Step: 12
Training loss: 0.4881858229637146
Validation loss: 1.6091321437589583

Epoch: 6| Step: 13
Training loss: 0.5364218950271606
Validation loss: 1.619274091976945

Epoch: 253| Step: 0
Training loss: 0.21276582777500153
Validation loss: 1.6267154934585735

Epoch: 6| Step: 1
Training loss: 0.24211342632770538
Validation loss: 1.621830455718502

Epoch: 6| Step: 2
Training loss: 0.5621682405471802
Validation loss: 1.6514970525618522

Epoch: 6| Step: 3
Training loss: 0.6510181427001953
Validation loss: 1.6649857439020628

Epoch: 6| Step: 4
Training loss: 0.24411968886852264
Validation loss: 1.6543362576474425

Epoch: 6| Step: 5
Training loss: 0.3617246747016907
Validation loss: 1.6422775855628393

Epoch: 6| Step: 6
Training loss: 0.6372886896133423
Validation loss: 1.6553400857474214

Epoch: 6| Step: 7
Training loss: 0.4455528259277344
Validation loss: 1.665345831583905

Epoch: 6| Step: 8
Training loss: 0.704222559928894
Validation loss: 1.6208606804570844

Epoch: 6| Step: 9
Training loss: 0.4889388382434845
Validation loss: 1.6392105869067612

Epoch: 6| Step: 10
Training loss: 0.4005897343158722
Validation loss: 1.598270256032226

Epoch: 6| Step: 11
Training loss: 0.6490407586097717
Validation loss: 1.63515777485345

Epoch: 6| Step: 12
Training loss: 0.2793159782886505
Validation loss: 1.6231184287737774

Epoch: 6| Step: 13
Training loss: 0.23836928606033325
Validation loss: 1.6336060749587191

Epoch: 254| Step: 0
Training loss: 0.22820545732975006
Validation loss: 1.6681295364133772

Epoch: 6| Step: 1
Training loss: 0.42007237672805786
Validation loss: 1.6676720406419487

Epoch: 6| Step: 2
Training loss: 0.4022410809993744
Validation loss: 1.652915488007248

Epoch: 6| Step: 3
Training loss: 0.37429502606391907
Validation loss: 1.6480914764506842

Epoch: 6| Step: 4
Training loss: 0.5998986959457397
Validation loss: 1.600511968776744

Epoch: 6| Step: 5
Training loss: 0.39827626943588257
Validation loss: 1.6000294018817205

Epoch: 6| Step: 6
Training loss: 0.563202440738678
Validation loss: 1.5736138756557176

Epoch: 6| Step: 7
Training loss: 0.48905324935913086
Validation loss: 1.5897976518959127

Epoch: 6| Step: 8
Training loss: 0.40844786167144775
Validation loss: 1.5838759099283526

Epoch: 6| Step: 9
Training loss: 0.31289130449295044
Validation loss: 1.6067040556220598

Epoch: 6| Step: 10
Training loss: 0.46988433599472046
Validation loss: 1.6088744709568639

Epoch: 6| Step: 11
Training loss: 0.6472513675689697
Validation loss: 1.5997894938274095

Epoch: 6| Step: 12
Training loss: 0.4486390948295593
Validation loss: 1.5902876392487557

Epoch: 6| Step: 13
Training loss: 0.19287054240703583
Validation loss: 1.588483848238504

Epoch: 255| Step: 0
Training loss: 0.25920945405960083
Validation loss: 1.5508451166973318

Epoch: 6| Step: 1
Training loss: 0.3440415859222412
Validation loss: 1.5372788303641862

Epoch: 6| Step: 2
Training loss: 0.5452961921691895
Validation loss: 1.5681533121293592

Epoch: 6| Step: 3
Training loss: 0.34997305274009705
Validation loss: 1.5586119646667151

Epoch: 6| Step: 4
Training loss: 0.36254793405532837
Validation loss: 1.5833311785933792

Epoch: 6| Step: 5
Training loss: 0.4457457661628723
Validation loss: 1.6102206835182764

Epoch: 6| Step: 6
Training loss: 0.5544613599777222
Validation loss: 1.5858586501049738

Epoch: 6| Step: 7
Training loss: 0.5186370611190796
Validation loss: 1.5702100774293304

Epoch: 6| Step: 8
Training loss: 0.4265124201774597
Validation loss: 1.5981056728670675

Epoch: 6| Step: 9
Training loss: 0.6140704154968262
Validation loss: 1.5944054254921534

Epoch: 6| Step: 10
Training loss: 0.1869712769985199
Validation loss: 1.627999380070676

Epoch: 6| Step: 11
Training loss: 0.7322753667831421
Validation loss: 1.626978753715433

Epoch: 6| Step: 12
Training loss: 0.3432438373565674
Validation loss: 1.6202972967137572

Epoch: 6| Step: 13
Training loss: 0.34421953558921814
Validation loss: 1.651063234575333

Epoch: 256| Step: 0
Training loss: 0.3264443576335907
Validation loss: 1.6275605065848238

Epoch: 6| Step: 1
Training loss: 0.3579093813896179
Validation loss: 1.6527190708344983

Epoch: 6| Step: 2
Training loss: 0.48549672961235046
Validation loss: 1.6203105257403465

Epoch: 6| Step: 3
Training loss: 0.6808773279190063
Validation loss: 1.635076110081006

Epoch: 6| Step: 4
Training loss: 0.23404242098331451
Validation loss: 1.6437657238334737

Epoch: 6| Step: 5
Training loss: 0.5003544092178345
Validation loss: 1.665557162736052

Epoch: 6| Step: 6
Training loss: 0.3289586901664734
Validation loss: 1.6607978959237375

Epoch: 6| Step: 7
Training loss: 0.5003676414489746
Validation loss: 1.6568654647437475

Epoch: 6| Step: 8
Training loss: 0.3866448700428009
Validation loss: 1.6399739314151067

Epoch: 6| Step: 9
Training loss: 0.5809080004692078
Validation loss: 1.6077261253069806

Epoch: 6| Step: 10
Training loss: 0.4137188494205475
Validation loss: 1.6110921944341352

Epoch: 6| Step: 11
Training loss: 0.35224974155426025
Validation loss: 1.5997774145936454

Epoch: 6| Step: 12
Training loss: 0.36783236265182495
Validation loss: 1.6026352092783938

Epoch: 6| Step: 13
Training loss: 0.333697646856308
Validation loss: 1.6286648729796052

Epoch: 257| Step: 0
Training loss: 0.28486573696136475
Validation loss: 1.6145360008362801

Epoch: 6| Step: 1
Training loss: 0.6040040254592896
Validation loss: 1.618249479160514

Epoch: 6| Step: 2
Training loss: 0.45242488384246826
Validation loss: 1.5995992242649038

Epoch: 6| Step: 3
Training loss: 0.6339598298072815
Validation loss: 1.5867590071052633

Epoch: 6| Step: 4
Training loss: 0.3369702696800232
Validation loss: 1.5892127470303608

Epoch: 6| Step: 5
Training loss: 0.13151203095912933
Validation loss: 1.561963185187309

Epoch: 6| Step: 6
Training loss: 0.4586610794067383
Validation loss: 1.59026889775389

Epoch: 6| Step: 7
Training loss: 0.2769310474395752
Validation loss: 1.5989528356059906

Epoch: 6| Step: 8
Training loss: 0.5553652048110962
Validation loss: 1.617561194204515

Epoch: 6| Step: 9
Training loss: 0.3782907724380493
Validation loss: 1.6246597407966532

Epoch: 6| Step: 10
Training loss: 0.39567238092422485
Validation loss: 1.6497347585616573

Epoch: 6| Step: 11
Training loss: 0.431449830532074
Validation loss: 1.6520764481636785

Epoch: 6| Step: 12
Training loss: 0.3484122157096863
Validation loss: 1.6473378045584566

Epoch: 6| Step: 13
Training loss: 1.0104732513427734
Validation loss: 1.6411526600519817

Epoch: 258| Step: 0
Training loss: 0.3177742660045624
Validation loss: 1.6297196931736444

Epoch: 6| Step: 1
Training loss: 0.2582111656665802
Validation loss: 1.606827312900174

Epoch: 6| Step: 2
Training loss: 0.3713689148426056
Validation loss: 1.589637743529453

Epoch: 6| Step: 3
Training loss: 0.3717758059501648
Validation loss: 1.5849149432233585

Epoch: 6| Step: 4
Training loss: 0.30817124247550964
Validation loss: 1.5797280803803475

Epoch: 6| Step: 5
Training loss: 0.41869208216667175
Validation loss: 1.5473311203782276

Epoch: 6| Step: 6
Training loss: 0.6343095302581787
Validation loss: 1.5796928514716446

Epoch: 6| Step: 7
Training loss: 0.3996785879135132
Validation loss: 1.5628173979379798

Epoch: 6| Step: 8
Training loss: 0.3347345292568207
Validation loss: 1.5671341393583564

Epoch: 6| Step: 9
Training loss: 0.4261454939842224
Validation loss: 1.5855666373365669

Epoch: 6| Step: 10
Training loss: 0.5015282034873962
Validation loss: 1.6009648224358917

Epoch: 6| Step: 11
Training loss: 0.49679163098335266
Validation loss: 1.6229573731781335

Epoch: 6| Step: 12
Training loss: 0.4925830066204071
Validation loss: 1.6440815041142125

Epoch: 6| Step: 13
Training loss: 0.7047551274299622
Validation loss: 1.6375444012303506

Epoch: 259| Step: 0
Training loss: 0.526791512966156
Validation loss: 1.6532863955343924

Epoch: 6| Step: 1
Training loss: 0.567868709564209
Validation loss: 1.6453991743826097

Epoch: 6| Step: 2
Training loss: 0.5691136121749878
Validation loss: 1.6301263865604196

Epoch: 6| Step: 3
Training loss: 0.5440727472305298
Validation loss: 1.6323073012854463

Epoch: 6| Step: 4
Training loss: 0.5615875720977783
Validation loss: 1.6500706544486425

Epoch: 6| Step: 5
Training loss: 0.34015774726867676
Validation loss: 1.596752876876503

Epoch: 6| Step: 6
Training loss: 0.3110122084617615
Validation loss: 1.6055147186402352

Epoch: 6| Step: 7
Training loss: 0.3166638910770416
Validation loss: 1.6218997124702699

Epoch: 6| Step: 8
Training loss: 0.193507581949234
Validation loss: 1.6156802972157795

Epoch: 6| Step: 9
Training loss: 0.4163435399532318
Validation loss: 1.6482044240479827

Epoch: 6| Step: 10
Training loss: 0.3198307752609253
Validation loss: 1.6646122752979238

Epoch: 6| Step: 11
Training loss: 0.9260979890823364
Validation loss: 1.6633330455390356

Epoch: 6| Step: 12
Training loss: 0.304230272769928
Validation loss: 1.6297417276649064

Epoch: 6| Step: 13
Training loss: 0.404419869184494
Validation loss: 1.6083043672705208

Epoch: 260| Step: 0
Training loss: 0.33185169100761414
Validation loss: 1.5806287155356458

Epoch: 6| Step: 1
Training loss: 0.5086933374404907
Validation loss: 1.5648689898111487

Epoch: 6| Step: 2
Training loss: 0.3881543278694153
Validation loss: 1.5686452170853973

Epoch: 6| Step: 3
Training loss: 0.5045355558395386
Validation loss: 1.596711702244256

Epoch: 6| Step: 4
Training loss: 0.3818134069442749
Validation loss: 1.6265074373573385

Epoch: 6| Step: 5
Training loss: 0.36574098467826843
Validation loss: 1.6184405255061325

Epoch: 6| Step: 6
Training loss: 0.5346869230270386
Validation loss: 1.6185347482722292

Epoch: 6| Step: 7
Training loss: 0.35446813702583313
Validation loss: 1.6164662094526394

Epoch: 6| Step: 8
Training loss: 0.30066627264022827
Validation loss: 1.6193784488144742

Epoch: 6| Step: 9
Training loss: 0.28694093227386475
Validation loss: 1.6225078849382297

Epoch: 6| Step: 10
Training loss: 0.3687724769115448
Validation loss: 1.5817170168763848

Epoch: 6| Step: 11
Training loss: 0.6828821301460266
Validation loss: 1.6065209937352005

Epoch: 6| Step: 12
Training loss: 0.3020839989185333
Validation loss: 1.6161047425321353

Epoch: 6| Step: 13
Training loss: 0.3439611792564392
Validation loss: 1.5926318976186937

Epoch: 261| Step: 0
Training loss: 0.38965630531311035
Validation loss: 1.5924887336710447

Epoch: 6| Step: 1
Training loss: 0.28432461619377136
Validation loss: 1.5739943737624793

Epoch: 6| Step: 2
Training loss: 0.4325807988643646
Validation loss: 1.5855131354383243

Epoch: 6| Step: 3
Training loss: 0.4926077723503113
Validation loss: 1.6108943082953011

Epoch: 6| Step: 4
Training loss: 0.3443129360675812
Validation loss: 1.6053166402283536

Epoch: 6| Step: 5
Training loss: 0.7518997192382812
Validation loss: 1.6453244275944208

Epoch: 6| Step: 6
Training loss: 0.48657482862472534
Validation loss: 1.6645168322388844

Epoch: 6| Step: 7
Training loss: 0.28819113969802856
Validation loss: 1.6657156136728102

Epoch: 6| Step: 8
Training loss: 0.45663413405418396
Validation loss: 1.6595924695332844

Epoch: 6| Step: 9
Training loss: 0.23746299743652344
Validation loss: 1.6283512307751564

Epoch: 6| Step: 10
Training loss: 0.49314287304878235
Validation loss: 1.5957183991709063

Epoch: 6| Step: 11
Training loss: 0.45882999897003174
Validation loss: 1.571421189974713

Epoch: 6| Step: 12
Training loss: 0.5575159788131714
Validation loss: 1.5599593500937186

Epoch: 6| Step: 13
Training loss: 0.4132702946662903
Validation loss: 1.5413541152913084

Epoch: 262| Step: 0
Training loss: 0.5621700882911682
Validation loss: 1.5551465172921457

Epoch: 6| Step: 1
Training loss: 0.5082691311836243
Validation loss: 1.5440230356749667

Epoch: 6| Step: 2
Training loss: 0.2455763816833496
Validation loss: 1.554025400069452

Epoch: 6| Step: 3
Training loss: 0.4146784842014313
Validation loss: 1.5837509939747472

Epoch: 6| Step: 4
Training loss: 0.37050196528434753
Validation loss: 1.6304094470957273

Epoch: 6| Step: 5
Training loss: 0.4345940947532654
Validation loss: 1.6863796698149813

Epoch: 6| Step: 6
Training loss: 0.32610005140304565
Validation loss: 1.6740342160706878

Epoch: 6| Step: 7
Training loss: 0.7367173433303833
Validation loss: 1.621324892966978

Epoch: 6| Step: 8
Training loss: 0.502251386642456
Validation loss: 1.6153289861576532

Epoch: 6| Step: 9
Training loss: 0.608275294303894
Validation loss: 1.6024863873758624

Epoch: 6| Step: 10
Training loss: 0.3519357442855835
Validation loss: 1.5959487115183184

Epoch: 6| Step: 11
Training loss: 0.5033761262893677
Validation loss: 1.5863906350187076

Epoch: 6| Step: 12
Training loss: 0.23705455660820007
Validation loss: 1.580280098222917

Epoch: 6| Step: 13
Training loss: 0.1062382161617279
Validation loss: 1.5628101236076766

Epoch: 263| Step: 0
Training loss: 0.27329879999160767
Validation loss: 1.6117050288825907

Epoch: 6| Step: 1
Training loss: 0.6742963790893555
Validation loss: 1.6218299378630936

Epoch: 6| Step: 2
Training loss: 0.33381226658821106
Validation loss: 1.6613587358946442

Epoch: 6| Step: 3
Training loss: 0.5478953123092651
Validation loss: 1.6696456337487826

Epoch: 6| Step: 4
Training loss: 0.4809180498123169
Validation loss: 1.6407393101722962

Epoch: 6| Step: 5
Training loss: 0.3517908453941345
Validation loss: 1.6126892400044266

Epoch: 6| Step: 6
Training loss: 0.4961971640586853
Validation loss: 1.5700601095794349

Epoch: 6| Step: 7
Training loss: 0.39067479968070984
Validation loss: 1.531611850825689

Epoch: 6| Step: 8
Training loss: 0.39804375171661377
Validation loss: 1.55943666478639

Epoch: 6| Step: 9
Training loss: 0.5666725635528564
Validation loss: 1.568618921823399

Epoch: 6| Step: 10
Training loss: 0.17068272829055786
Validation loss: 1.581935312158318

Epoch: 6| Step: 11
Training loss: 0.3241236209869385
Validation loss: 1.5933024319269324

Epoch: 6| Step: 12
Training loss: 0.30944356322288513
Validation loss: 1.566315258702924

Epoch: 6| Step: 13
Training loss: 0.546105682849884
Validation loss: 1.5880178841211463

Epoch: 264| Step: 0
Training loss: 0.22791746258735657
Validation loss: 1.5779326961886497

Epoch: 6| Step: 1
Training loss: 0.45899757742881775
Validation loss: 1.5999718917313444

Epoch: 6| Step: 2
Training loss: 0.4364806115627289
Validation loss: 1.6189511181205831

Epoch: 6| Step: 3
Training loss: 0.27450624108314514
Validation loss: 1.6300660512780631

Epoch: 6| Step: 4
Training loss: 0.6294490098953247
Validation loss: 1.6511828348200808

Epoch: 6| Step: 5
Training loss: 0.2997018098831177
Validation loss: 1.6294798133193806

Epoch: 6| Step: 6
Training loss: 0.2838716506958008
Validation loss: 1.645565430323283

Epoch: 6| Step: 7
Training loss: 0.5130053758621216
Validation loss: 1.6444970189884145

Epoch: 6| Step: 8
Training loss: 0.37511324882507324
Validation loss: 1.645595827410298

Epoch: 6| Step: 9
Training loss: 0.5060267448425293
Validation loss: 1.6543271682595695

Epoch: 6| Step: 10
Training loss: 0.43960654735565186
Validation loss: 1.6256743002963323

Epoch: 6| Step: 11
Training loss: 0.25139033794403076
Validation loss: 1.6160323401933074

Epoch: 6| Step: 12
Training loss: 0.3312302827835083
Validation loss: 1.605130773718639

Epoch: 6| Step: 13
Training loss: 0.24959437549114227
Validation loss: 1.6075143814086914

Epoch: 265| Step: 0
Training loss: 0.28261715173721313
Validation loss: 1.5903666442440403

Epoch: 6| Step: 1
Training loss: 0.5953577160835266
Validation loss: 1.5931639043233727

Epoch: 6| Step: 2
Training loss: 0.28535404801368713
Validation loss: 1.5911289158687796

Epoch: 6| Step: 3
Training loss: 0.16898277401924133
Validation loss: 1.5796941685420212

Epoch: 6| Step: 4
Training loss: 0.4035724699497223
Validation loss: 1.5742542769319268

Epoch: 6| Step: 5
Training loss: 0.44510337710380554
Validation loss: 1.5770253968495194

Epoch: 6| Step: 6
Training loss: 0.46817201375961304
Validation loss: 1.5740314081151

Epoch: 6| Step: 7
Training loss: 0.35470151901245117
Validation loss: 1.5452249466731984

Epoch: 6| Step: 8
Training loss: 0.258818656206131
Validation loss: 1.5429474230735534

Epoch: 6| Step: 9
Training loss: 0.5633242726325989
Validation loss: 1.5492848401428552

Epoch: 6| Step: 10
Training loss: 0.4984477758407593
Validation loss: 1.5390770281514814

Epoch: 6| Step: 11
Training loss: 0.4539642930030823
Validation loss: 1.5528149963707052

Epoch: 6| Step: 12
Training loss: 0.3365582823753357
Validation loss: 1.5547602920122043

Epoch: 6| Step: 13
Training loss: 0.10843082517385483
Validation loss: 1.5940712549353158

Epoch: 266| Step: 0
Training loss: 0.2621500790119171
Validation loss: 1.6455325900867421

Epoch: 6| Step: 1
Training loss: 0.4468580484390259
Validation loss: 1.6307186413836736

Epoch: 6| Step: 2
Training loss: 0.4861810803413391
Validation loss: 1.636835345657923

Epoch: 6| Step: 3
Training loss: 0.3877819776535034
Validation loss: 1.6112198304104548

Epoch: 6| Step: 4
Training loss: 0.14224961400032043
Validation loss: 1.5659657575750863

Epoch: 6| Step: 5
Training loss: 0.3442996144294739
Validation loss: 1.5649826283095984

Epoch: 6| Step: 6
Training loss: 0.35748404264450073
Validation loss: 1.5398389344574304

Epoch: 6| Step: 7
Training loss: 0.5316705107688904
Validation loss: 1.5708658156856414

Epoch: 6| Step: 8
Training loss: 0.4230228364467621
Validation loss: 1.5589545247375325

Epoch: 6| Step: 9
Training loss: 0.3522232174873352
Validation loss: 1.6158520656247293

Epoch: 6| Step: 10
Training loss: 0.4447086751461029
Validation loss: 1.6290937700579244

Epoch: 6| Step: 11
Training loss: 0.6398863792419434
Validation loss: 1.6067984040065477

Epoch: 6| Step: 12
Training loss: 0.22841593623161316
Validation loss: 1.6195110659445486

Epoch: 6| Step: 13
Training loss: 0.32985207438468933
Validation loss: 1.6006824342153405

Epoch: 267| Step: 0
Training loss: 0.2741650938987732
Validation loss: 1.5783002581647647

Epoch: 6| Step: 1
Training loss: 0.5311216115951538
Validation loss: 1.5587788499811643

Epoch: 6| Step: 2
Training loss: 0.3958173990249634
Validation loss: 1.5451194650383406

Epoch: 6| Step: 3
Training loss: 0.3603573143482208
Validation loss: 1.557328906110538

Epoch: 6| Step: 4
Training loss: 0.5953405499458313
Validation loss: 1.546715486434198

Epoch: 6| Step: 5
Training loss: 0.5117546319961548
Validation loss: 1.554196855073334

Epoch: 6| Step: 6
Training loss: 0.21228556334972382
Validation loss: 1.5550045903011034

Epoch: 6| Step: 7
Training loss: 0.3491019606590271
Validation loss: 1.5724220750152424

Epoch: 6| Step: 8
Training loss: 0.3226966857910156
Validation loss: 1.5925514813392394

Epoch: 6| Step: 9
Training loss: 0.28842464089393616
Validation loss: 1.6384520889610372

Epoch: 6| Step: 10
Training loss: 0.38700658082962036
Validation loss: 1.6472054143105783

Epoch: 6| Step: 11
Training loss: 0.3790208697319031
Validation loss: 1.6159020162397815

Epoch: 6| Step: 12
Training loss: 0.4964885413646698
Validation loss: 1.5959995459484797

Epoch: 6| Step: 13
Training loss: 0.2706994116306305
Validation loss: 1.540048066005912

Epoch: 268| Step: 0
Training loss: 0.36632946133613586
Validation loss: 1.5414589451205345

Epoch: 6| Step: 1
Training loss: 0.3618496060371399
Validation loss: 1.5123701428854337

Epoch: 6| Step: 2
Training loss: 0.4766119718551636
Validation loss: 1.5407434266100648

Epoch: 6| Step: 3
Training loss: 0.7575540542602539
Validation loss: 1.5340692253522976

Epoch: 6| Step: 4
Training loss: 0.6372475624084473
Validation loss: 1.5261506098572926

Epoch: 6| Step: 5
Training loss: 0.18904361128807068
Validation loss: 1.5491154078514344

Epoch: 6| Step: 6
Training loss: 0.370773047208786
Validation loss: 1.5960865700116722

Epoch: 6| Step: 7
Training loss: 0.4580139219760895
Validation loss: 1.6627264574009886

Epoch: 6| Step: 8
Training loss: 0.36466941237449646
Validation loss: 1.6281654386110203

Epoch: 6| Step: 9
Training loss: 0.3662186563014984
Validation loss: 1.6340482119591004

Epoch: 6| Step: 10
Training loss: 0.3193775415420532
Validation loss: 1.576986410284555

Epoch: 6| Step: 11
Training loss: 0.36232200264930725
Validation loss: 1.5655031178587226

Epoch: 6| Step: 12
Training loss: 0.4296707510948181
Validation loss: 1.5237549940745037

Epoch: 6| Step: 13
Training loss: 0.4060036242008209
Validation loss: 1.5241890453523206

Epoch: 269| Step: 0
Training loss: 0.4892506003379822
Validation loss: 1.5277749082093597

Epoch: 6| Step: 1
Training loss: 0.643086850643158
Validation loss: 1.506396960186702

Epoch: 6| Step: 2
Training loss: 0.2420436441898346
Validation loss: 1.5182785270034627

Epoch: 6| Step: 3
Training loss: 0.3570112884044647
Validation loss: 1.556685613047692

Epoch: 6| Step: 4
Training loss: 0.2572896182537079
Validation loss: 1.6152558916358537

Epoch: 6| Step: 5
Training loss: 0.47974544763565063
Validation loss: 1.6446843954824633

Epoch: 6| Step: 6
Training loss: 0.3942083418369293
Validation loss: 1.626182149815303

Epoch: 6| Step: 7
Training loss: 0.4062718451023102
Validation loss: 1.5907659030729724

Epoch: 6| Step: 8
Training loss: 0.5469155311584473
Validation loss: 1.5586378920462824

Epoch: 6| Step: 9
Training loss: 0.38274186849594116
Validation loss: 1.5522846252687517

Epoch: 6| Step: 10
Training loss: 0.23103195428848267
Validation loss: 1.562581354571927

Epoch: 6| Step: 11
Training loss: 0.29026514291763306
Validation loss: 1.5755856972868725

Epoch: 6| Step: 12
Training loss: 0.6479598879814148
Validation loss: 1.5921720125341927

Epoch: 6| Step: 13
Training loss: 0.47404929995536804
Validation loss: 1.6087838616422427

Epoch: 270| Step: 0
Training loss: 0.36795076727867126
Validation loss: 1.599580499433702

Epoch: 6| Step: 1
Training loss: 0.26988255977630615
Validation loss: 1.6358347797906527

Epoch: 6| Step: 2
Training loss: 0.3760412037372589
Validation loss: 1.6848466037422098

Epoch: 6| Step: 3
Training loss: 0.4402068853378296
Validation loss: 1.68029648001476

Epoch: 6| Step: 4
Training loss: 0.41265732049942017
Validation loss: 1.678256304033341

Epoch: 6| Step: 5
Training loss: 0.5340220928192139
Validation loss: 1.6548380287744666

Epoch: 6| Step: 6
Training loss: 0.5420175194740295
Validation loss: 1.6406002095950547

Epoch: 6| Step: 7
Training loss: 0.36903148889541626
Validation loss: 1.604372582127971

Epoch: 6| Step: 8
Training loss: 0.39813733100891113
Validation loss: 1.5917646000462193

Epoch: 6| Step: 9
Training loss: 0.5038608908653259
Validation loss: 1.5963732542530182

Epoch: 6| Step: 10
Training loss: 0.61357581615448
Validation loss: 1.5942519877546577

Epoch: 6| Step: 11
Training loss: 0.514707088470459
Validation loss: 1.6038688549431421

Epoch: 6| Step: 12
Training loss: 0.3787987530231476
Validation loss: 1.6204288851830266

Epoch: 6| Step: 13
Training loss: 0.26564204692840576
Validation loss: 1.607836450299909

Epoch: 271| Step: 0
Training loss: 0.45179638266563416
Validation loss: 1.5977627461956394

Epoch: 6| Step: 1
Training loss: 0.5435384511947632
Validation loss: 1.6124986499868414

Epoch: 6| Step: 2
Training loss: 0.4254835546016693
Validation loss: 1.6431032188477055

Epoch: 6| Step: 3
Training loss: 0.29359161853790283
Validation loss: 1.6172901763710925

Epoch: 6| Step: 4
Training loss: 0.2974269688129425
Validation loss: 1.6364462657641339

Epoch: 6| Step: 5
Training loss: 0.6740730404853821
Validation loss: 1.6107915229694818

Epoch: 6| Step: 6
Training loss: 0.2935125231742859
Validation loss: 1.5905865123195033

Epoch: 6| Step: 7
Training loss: 0.5659476518630981
Validation loss: 1.5525693611432148

Epoch: 6| Step: 8
Training loss: 0.3095797896385193
Validation loss: 1.5542078377098165

Epoch: 6| Step: 9
Training loss: 0.23287531733512878
Validation loss: 1.5457155127679147

Epoch: 6| Step: 10
Training loss: 0.35301536321640015
Validation loss: 1.55396451744982

Epoch: 6| Step: 11
Training loss: 0.1909635365009308
Validation loss: 1.5496159561218754

Epoch: 6| Step: 12
Training loss: 0.3788699507713318
Validation loss: 1.5679539313880346

Epoch: 6| Step: 13
Training loss: 0.1322564333677292
Validation loss: 1.5929063020213958

Epoch: 272| Step: 0
Training loss: 0.4337207078933716
Validation loss: 1.582277451792071

Epoch: 6| Step: 1
Training loss: 0.22255542874336243
Validation loss: 1.5972546467217066

Epoch: 6| Step: 2
Training loss: 0.3003629446029663
Validation loss: 1.6025146104956185

Epoch: 6| Step: 3
Training loss: 0.3193542957305908
Validation loss: 1.5880628234596663

Epoch: 6| Step: 4
Training loss: 0.3819173574447632
Validation loss: 1.5755961300224386

Epoch: 6| Step: 5
Training loss: 0.30774006247520447
Validation loss: 1.5785956831388577

Epoch: 6| Step: 6
Training loss: 0.1315770447254181
Validation loss: 1.5657111419144498

Epoch: 6| Step: 7
Training loss: 0.33971789479255676
Validation loss: 1.5832907717715028

Epoch: 6| Step: 8
Training loss: 0.3737902045249939
Validation loss: 1.5742265293675084

Epoch: 6| Step: 9
Training loss: 0.2112671136856079
Validation loss: 1.5646774051009968

Epoch: 6| Step: 10
Training loss: 0.32816171646118164
Validation loss: 1.5584297962086175

Epoch: 6| Step: 11
Training loss: 0.42651093006134033
Validation loss: 1.5835061239939865

Epoch: 6| Step: 12
Training loss: 0.5952908992767334
Validation loss: 1.5733820469148698

Epoch: 6| Step: 13
Training loss: 0.5769426822662354
Validation loss: 1.5878325623850669

Epoch: 273| Step: 0
Training loss: 0.3943464159965515
Validation loss: 1.5741679309516825

Epoch: 6| Step: 1
Training loss: 0.3823333978652954
Validation loss: 1.5991844669465096

Epoch: 6| Step: 2
Training loss: 0.32188722491264343
Validation loss: 1.5697594458057034

Epoch: 6| Step: 3
Training loss: 0.5047251582145691
Validation loss: 1.5811709716755857

Epoch: 6| Step: 4
Training loss: 0.3703681230545044
Validation loss: 1.5503647968333254

Epoch: 6| Step: 5
Training loss: 0.2878151535987854
Validation loss: 1.5741413190800657

Epoch: 6| Step: 6
Training loss: 0.12812280654907227
Validation loss: 1.563072023853179

Epoch: 6| Step: 7
Training loss: 0.22789862751960754
Validation loss: 1.5637456396574616

Epoch: 6| Step: 8
Training loss: 0.3547065854072571
Validation loss: 1.568813641866048

Epoch: 6| Step: 9
Training loss: 0.6096891164779663
Validation loss: 1.5786897943865867

Epoch: 6| Step: 10
Training loss: 0.40029847621917725
Validation loss: 1.5740521056677705

Epoch: 6| Step: 11
Training loss: 0.22780808806419373
Validation loss: 1.5715755160136888

Epoch: 6| Step: 12
Training loss: 0.39611321687698364
Validation loss: 1.5414251101914274

Epoch: 6| Step: 13
Training loss: 0.2960425317287445
Validation loss: 1.5590827144602293

Epoch: 274| Step: 0
Training loss: 0.3721104562282562
Validation loss: 1.5671820525200135

Epoch: 6| Step: 1
Training loss: 0.3923831582069397
Validation loss: 1.5809714383976434

Epoch: 6| Step: 2
Training loss: 0.6229428648948669
Validation loss: 1.612813893184867

Epoch: 6| Step: 3
Training loss: 0.278282105922699
Validation loss: 1.59636559665844

Epoch: 6| Step: 4
Training loss: 0.4395919740200043
Validation loss: 1.5996192411709858

Epoch: 6| Step: 5
Training loss: 0.22259649634361267
Validation loss: 1.5932011591490878

Epoch: 6| Step: 6
Training loss: 0.40862974524497986
Validation loss: 1.5990010512772428

Epoch: 6| Step: 7
Training loss: 0.3706602156162262
Validation loss: 1.600367848591138

Epoch: 6| Step: 8
Training loss: 0.34150636196136475
Validation loss: 1.5776119770542267

Epoch: 6| Step: 9
Training loss: 0.4119826555252075
Validation loss: 1.5736352859004852

Epoch: 6| Step: 10
Training loss: 0.24812741577625275
Validation loss: 1.5652283071189799

Epoch: 6| Step: 11
Training loss: 0.2707175016403198
Validation loss: 1.5659841965603571

Epoch: 6| Step: 12
Training loss: 0.20425021648406982
Validation loss: 1.5766544008767733

Epoch: 6| Step: 13
Training loss: 0.16795040667057037
Validation loss: 1.5465065266496392

Epoch: 275| Step: 0
Training loss: 0.43474459648132324
Validation loss: 1.5957833054245159

Epoch: 6| Step: 1
Training loss: 0.34571710228919983
Validation loss: 1.5951676278985956

Epoch: 6| Step: 2
Training loss: 0.11222176253795624
Validation loss: 1.5562505722045898

Epoch: 6| Step: 3
Training loss: 0.32521024346351624
Validation loss: 1.5853725351313108

Epoch: 6| Step: 4
Training loss: 0.2197139710187912
Validation loss: 1.5715420758852394

Epoch: 6| Step: 5
Training loss: 0.6570672988891602
Validation loss: 1.5730133313004688

Epoch: 6| Step: 6
Training loss: 0.20090697705745697
Validation loss: 1.5625600340545818

Epoch: 6| Step: 7
Training loss: 0.23639899492263794
Validation loss: 1.5789110160643054

Epoch: 6| Step: 8
Training loss: 0.3423069715499878
Validation loss: 1.5885715048800233

Epoch: 6| Step: 9
Training loss: 0.4231324791908264
Validation loss: 1.5913559044561079

Epoch: 6| Step: 10
Training loss: 0.29411837458610535
Validation loss: 1.58591176232984

Epoch: 6| Step: 11
Training loss: 0.36113831400871277
Validation loss: 1.5745010632340626

Epoch: 6| Step: 12
Training loss: 0.319240927696228
Validation loss: 1.5909020900726318

Epoch: 6| Step: 13
Training loss: 0.26185810565948486
Validation loss: 1.6078316703919442

Epoch: 276| Step: 0
Training loss: 0.4196870028972626
Validation loss: 1.617926202794557

Epoch: 6| Step: 1
Training loss: 0.2331027388572693
Validation loss: 1.5942771063056043

Epoch: 6| Step: 2
Training loss: 0.28608232736587524
Validation loss: 1.5962655300735145

Epoch: 6| Step: 3
Training loss: 0.3574245572090149
Validation loss: 1.5636464049739223

Epoch: 6| Step: 4
Training loss: 0.37257492542266846
Validation loss: 1.549001774480266

Epoch: 6| Step: 5
Training loss: 0.309306800365448
Validation loss: 1.5431943119213145

Epoch: 6| Step: 6
Training loss: 0.4156498908996582
Validation loss: 1.569524916269446

Epoch: 6| Step: 7
Training loss: 0.5032556653022766
Validation loss: 1.6280337482370355

Epoch: 6| Step: 8
Training loss: 0.2898496091365814
Validation loss: 1.6337794437203357

Epoch: 6| Step: 9
Training loss: 0.2967844605445862
Validation loss: 1.6374917517426193

Epoch: 6| Step: 10
Training loss: 0.0899515450000763
Validation loss: 1.6382183708170408

Epoch: 6| Step: 11
Training loss: 0.3903484344482422
Validation loss: 1.6002277789577362

Epoch: 6| Step: 12
Training loss: 0.2708565592765808
Validation loss: 1.6024542316313712

Epoch: 6| Step: 13
Training loss: 0.5233533382415771
Validation loss: 1.5832445083125946

Epoch: 277| Step: 0
Training loss: 0.3322513997554779
Validation loss: 1.6131951296201317

Epoch: 6| Step: 1
Training loss: 0.3212793469429016
Validation loss: 1.5887123064328266

Epoch: 6| Step: 2
Training loss: 0.47036248445510864
Validation loss: 1.623962866362705

Epoch: 6| Step: 3
Training loss: 0.33816999197006226
Validation loss: 1.6268646499162078

Epoch: 6| Step: 4
Training loss: 0.34171628952026367
Validation loss: 1.6072626254891837

Epoch: 6| Step: 5
Training loss: 0.23531006276607513
Validation loss: 1.6223828497753348

Epoch: 6| Step: 6
Training loss: 0.3297185003757477
Validation loss: 1.6335433465178295

Epoch: 6| Step: 7
Training loss: 0.4611569046974182
Validation loss: 1.6576073784982004

Epoch: 6| Step: 8
Training loss: 0.6486958265304565
Validation loss: 1.6439821925214542

Epoch: 6| Step: 9
Training loss: 0.21971352398395538
Validation loss: 1.6451976119831044

Epoch: 6| Step: 10
Training loss: 0.37577104568481445
Validation loss: 1.609633037479975

Epoch: 6| Step: 11
Training loss: 0.22875401377677917
Validation loss: 1.567718780168923

Epoch: 6| Step: 12
Training loss: 0.33735233545303345
Validation loss: 1.5677345004132999

Epoch: 6| Step: 13
Training loss: 0.24648255109786987
Validation loss: 1.5781320897481774

Epoch: 278| Step: 0
Training loss: 0.27772393822669983
Validation loss: 1.5915714566425612

Epoch: 6| Step: 1
Training loss: 0.4128309190273285
Validation loss: 1.568363296088352

Epoch: 6| Step: 2
Training loss: 0.1796039640903473
Validation loss: 1.5963667669603903

Epoch: 6| Step: 3
Training loss: 0.5074893832206726
Validation loss: 1.593623072870316

Epoch: 6| Step: 4
Training loss: 0.3021475672721863
Validation loss: 1.6048012061785626

Epoch: 6| Step: 5
Training loss: 0.4567250609397888
Validation loss: 1.5975369343193628

Epoch: 6| Step: 6
Training loss: 0.3275175094604492
Validation loss: 1.5848200872380247

Epoch: 6| Step: 7
Training loss: 0.2655258774757385
Validation loss: 1.5833337204430693

Epoch: 6| Step: 8
Training loss: 0.2760036587715149
Validation loss: 1.5677935884844871

Epoch: 6| Step: 9
Training loss: 0.4827042818069458
Validation loss: 1.5604173829478603

Epoch: 6| Step: 10
Training loss: 0.3470085859298706
Validation loss: 1.559759093869117

Epoch: 6| Step: 11
Training loss: 0.19921481609344482
Validation loss: 1.5702678785529187

Epoch: 6| Step: 12
Training loss: 0.19327647984027863
Validation loss: 1.5868465913239347

Epoch: 6| Step: 13
Training loss: 0.5056003928184509
Validation loss: 1.6026059863387898

Epoch: 279| Step: 0
Training loss: 0.24634329974651337
Validation loss: 1.601476474474835

Epoch: 6| Step: 1
Training loss: 0.3945538401603699
Validation loss: 1.6171726520343492

Epoch: 6| Step: 2
Training loss: 0.45136138796806335
Validation loss: 1.6420901859960249

Epoch: 6| Step: 3
Training loss: 0.2832365036010742
Validation loss: 1.6350909484330045

Epoch: 6| Step: 4
Training loss: 0.18806298077106476
Validation loss: 1.6416950648830784

Epoch: 6| Step: 5
Training loss: 0.4622214436531067
Validation loss: 1.6050063704931608

Epoch: 6| Step: 6
Training loss: 0.24828889966011047
Validation loss: 1.579326473256593

Epoch: 6| Step: 7
Training loss: 0.2922843396663666
Validation loss: 1.5565144259442565

Epoch: 6| Step: 8
Training loss: 0.291024386882782
Validation loss: 1.5599138429087978

Epoch: 6| Step: 9
Training loss: 0.445607453584671
Validation loss: 1.5661129310566893

Epoch: 6| Step: 10
Training loss: 0.2749217450618744
Validation loss: 1.5806544724331106

Epoch: 6| Step: 11
Training loss: 0.2752237915992737
Validation loss: 1.5795962156787995

Epoch: 6| Step: 12
Training loss: 0.507256269454956
Validation loss: 1.5990215142567952

Epoch: 6| Step: 13
Training loss: 0.2783585786819458
Validation loss: 1.607268674399263

Epoch: 280| Step: 0
Training loss: 0.12659215927124023
Validation loss: 1.5687685230726838

Epoch: 6| Step: 1
Training loss: 0.6070225238800049
Validation loss: 1.5717592316289102

Epoch: 6| Step: 2
Training loss: 0.25279104709625244
Validation loss: 1.5913476610696444

Epoch: 6| Step: 3
Training loss: 0.3538226783275604
Validation loss: 1.586757162565826

Epoch: 6| Step: 4
Training loss: 0.2824143171310425
Validation loss: 1.5854084081547235

Epoch: 6| Step: 5
Training loss: 0.47603416442871094
Validation loss: 1.5855747833046863

Epoch: 6| Step: 6
Training loss: 0.4976786673069
Validation loss: 1.5911104832926104

Epoch: 6| Step: 7
Training loss: 0.19922825694084167
Validation loss: 1.569370206966195

Epoch: 6| Step: 8
Training loss: 0.29025381803512573
Validation loss: 1.597149674610425

Epoch: 6| Step: 9
Training loss: 0.3891410231590271
Validation loss: 1.6105859920542727

Epoch: 6| Step: 10
Training loss: 0.1659793257713318
Validation loss: 1.5996760488838278

Epoch: 6| Step: 11
Training loss: 0.2807806730270386
Validation loss: 1.5989211848987046

Epoch: 6| Step: 12
Training loss: 0.3085227906703949
Validation loss: 1.597612327144992

Epoch: 6| Step: 13
Training loss: 0.4489057958126068
Validation loss: 1.6138003013467277

Epoch: 281| Step: 0
Training loss: 0.19464227557182312
Validation loss: 1.5949111318075528

Epoch: 6| Step: 1
Training loss: 0.2689833343029022
Validation loss: 1.5634168078822475

Epoch: 6| Step: 2
Training loss: 0.1896025836467743
Validation loss: 1.552793587407758

Epoch: 6| Step: 3
Training loss: 0.1403277963399887
Validation loss: 1.5871722954575733

Epoch: 6| Step: 4
Training loss: 0.4767634868621826
Validation loss: 1.5707944067575599

Epoch: 6| Step: 5
Training loss: 0.5196887850761414
Validation loss: 1.587000100843368

Epoch: 6| Step: 6
Training loss: 0.38205084204673767
Validation loss: 1.5785911108857842

Epoch: 6| Step: 7
Training loss: 0.2892068326473236
Validation loss: 1.5768724218491585

Epoch: 6| Step: 8
Training loss: 0.5095893740653992
Validation loss: 1.5512025830566243

Epoch: 6| Step: 9
Training loss: 0.38746127486228943
Validation loss: 1.5766783324621056

Epoch: 6| Step: 10
Training loss: 0.35215482115745544
Validation loss: 1.5452248204138972

Epoch: 6| Step: 11
Training loss: 0.3746812343597412
Validation loss: 1.5746085284858622

Epoch: 6| Step: 12
Training loss: 0.22464501857757568
Validation loss: 1.570902483437651

Epoch: 6| Step: 13
Training loss: 0.30312204360961914
Validation loss: 1.5565154757550967

Epoch: 282| Step: 0
Training loss: 0.3993714451789856
Validation loss: 1.5685201691042991

Epoch: 6| Step: 1
Training loss: 0.22198344767093658
Validation loss: 1.5679777694004837

Epoch: 6| Step: 2
Training loss: 0.31358590722084045
Validation loss: 1.5922417576595018

Epoch: 6| Step: 3
Training loss: 0.39719074964523315
Validation loss: 1.5912943873354184

Epoch: 6| Step: 4
Training loss: 0.3609233498573303
Validation loss: 1.5708102821021952

Epoch: 6| Step: 5
Training loss: 0.3110823631286621
Validation loss: 1.5601894291498328

Epoch: 6| Step: 6
Training loss: 0.4038417339324951
Validation loss: 1.5810921153714579

Epoch: 6| Step: 7
Training loss: 0.35648852586746216
Validation loss: 1.5760237375895183

Epoch: 6| Step: 8
Training loss: 0.18308600783348083
Validation loss: 1.6028077884386944

Epoch: 6| Step: 9
Training loss: 0.16238442063331604
Validation loss: 1.6042403392894293

Epoch: 6| Step: 10
Training loss: 0.3497265577316284
Validation loss: 1.613757344984239

Epoch: 6| Step: 11
Training loss: 0.37154847383499146
Validation loss: 1.6353638761787004

Epoch: 6| Step: 12
Training loss: 0.46438801288604736
Validation loss: 1.642342044461158

Epoch: 6| Step: 13
Training loss: 0.14739269018173218
Validation loss: 1.6530562998146139

Epoch: 283| Step: 0
Training loss: 0.11499989032745361
Validation loss: 1.6067755632503058

Epoch: 6| Step: 1
Training loss: 0.4158072769641876
Validation loss: 1.614571225258612

Epoch: 6| Step: 2
Training loss: 0.24143964052200317
Validation loss: 1.6136177329606907

Epoch: 6| Step: 3
Training loss: 0.3131140172481537
Validation loss: 1.6087879891036658

Epoch: 6| Step: 4
Training loss: 0.5302610397338867
Validation loss: 1.6138047531086912

Epoch: 6| Step: 5
Training loss: 0.4674198627471924
Validation loss: 1.6321824930047477

Epoch: 6| Step: 6
Training loss: 0.2764465808868408
Validation loss: 1.6270586008666663

Epoch: 6| Step: 7
Training loss: 0.18957579135894775
Validation loss: 1.5955187248927292

Epoch: 6| Step: 8
Training loss: 0.5828429460525513
Validation loss: 1.5925826770003124

Epoch: 6| Step: 9
Training loss: 0.28723832964897156
Validation loss: 1.5775425190566688

Epoch: 6| Step: 10
Training loss: 0.33640024065971375
Validation loss: 1.5901254095057005

Epoch: 6| Step: 11
Training loss: 0.28790873289108276
Validation loss: 1.5721960759931994

Epoch: 6| Step: 12
Training loss: 0.19655881822109222
Validation loss: 1.5591415179673063

Epoch: 6| Step: 13
Training loss: 0.17904376983642578
Validation loss: 1.5622294410582511

Epoch: 284| Step: 0
Training loss: 0.35783541202545166
Validation loss: 1.6018651993043962

Epoch: 6| Step: 1
Training loss: 0.28178519010543823
Validation loss: 1.6013973041247296

Epoch: 6| Step: 2
Training loss: 0.3232210874557495
Validation loss: 1.5941309095710836

Epoch: 6| Step: 3
Training loss: 0.25622400641441345
Validation loss: 1.607624484646705

Epoch: 6| Step: 4
Training loss: 0.18970993161201477
Validation loss: 1.608978053574921

Epoch: 6| Step: 5
Training loss: 0.2281275987625122
Validation loss: 1.6097996145166376

Epoch: 6| Step: 6
Training loss: 0.46640998125076294
Validation loss: 1.6036458598670138

Epoch: 6| Step: 7
Training loss: 0.33536744117736816
Validation loss: 1.6094307450837986

Epoch: 6| Step: 8
Training loss: 0.2914825677871704
Validation loss: 1.605146208117085

Epoch: 6| Step: 9
Training loss: 0.28868812322616577
Validation loss: 1.6079600523876887

Epoch: 6| Step: 10
Training loss: 0.2809435725212097
Validation loss: 1.5622224192465506

Epoch: 6| Step: 11
Training loss: 0.40684962272644043
Validation loss: 1.5739864700584

Epoch: 6| Step: 12
Training loss: 0.25422224402427673
Validation loss: 1.5804499387741089

Epoch: 6| Step: 13
Training loss: 0.40119749307632446
Validation loss: 1.583709923169946

Epoch: 285| Step: 0
Training loss: 0.3091418147087097
Validation loss: 1.5881762914760138

Epoch: 6| Step: 1
Training loss: 0.17217642068862915
Validation loss: 1.586814845761945

Epoch: 6| Step: 2
Training loss: 0.4785813093185425
Validation loss: 1.562258029496798

Epoch: 6| Step: 3
Training loss: 0.4778504967689514
Validation loss: 1.5640624428308139

Epoch: 6| Step: 4
Training loss: 0.24101775884628296
Validation loss: 1.5526347596158263

Epoch: 6| Step: 5
Training loss: 0.3299776613712311
Validation loss: 1.5584044020663026

Epoch: 6| Step: 6
Training loss: 0.20334427058696747
Validation loss: 1.5307002464930217

Epoch: 6| Step: 7
Training loss: 0.34962356090545654
Validation loss: 1.5609313441861061

Epoch: 6| Step: 8
Training loss: 0.2680443525314331
Validation loss: 1.5941396349219865

Epoch: 6| Step: 9
Training loss: 0.2748590111732483
Validation loss: 1.6027715795783586

Epoch: 6| Step: 10
Training loss: 0.33835360407829285
Validation loss: 1.6400088571733045

Epoch: 6| Step: 11
Training loss: 0.40546146035194397
Validation loss: 1.628279270664338

Epoch: 6| Step: 12
Training loss: 0.19910845160484314
Validation loss: 1.648529383444017

Epoch: 6| Step: 13
Training loss: 0.32294899225234985
Validation loss: 1.648381810034475

Epoch: 286| Step: 0
Training loss: 0.2724461257457733
Validation loss: 1.6317854055794336

Epoch: 6| Step: 1
Training loss: 0.3509620428085327
Validation loss: 1.5887206523649153

Epoch: 6| Step: 2
Training loss: 0.48993629217147827
Validation loss: 1.5829208204823155

Epoch: 6| Step: 3
Training loss: 0.266621470451355
Validation loss: 1.5402270068404496

Epoch: 6| Step: 4
Training loss: 0.20654472708702087
Validation loss: 1.5494774464638001

Epoch: 6| Step: 5
Training loss: 0.249646857380867
Validation loss: 1.5289139472028261

Epoch: 6| Step: 6
Training loss: 0.33999109268188477
Validation loss: 1.53306318354863

Epoch: 6| Step: 7
Training loss: 0.3944319486618042
Validation loss: 1.5365837966242144

Epoch: 6| Step: 8
Training loss: 0.3665654957294464
Validation loss: 1.564221119367948

Epoch: 6| Step: 9
Training loss: 0.36759912967681885
Validation loss: 1.577000864090458

Epoch: 6| Step: 10
Training loss: 0.252761572599411
Validation loss: 1.577840498698655

Epoch: 6| Step: 11
Training loss: 0.35048478841781616
Validation loss: 1.5526934669863792

Epoch: 6| Step: 12
Training loss: 0.22911903262138367
Validation loss: 1.5057949519926501

Epoch: 6| Step: 13
Training loss: 0.28722697496414185
Validation loss: 1.5325797860340407

Epoch: 287| Step: 0
Training loss: 0.4248603582382202
Validation loss: 1.5062053049764326

Epoch: 6| Step: 1
Training loss: 0.1422746777534485
Validation loss: 1.5521935891079646

Epoch: 6| Step: 2
Training loss: 0.2166062593460083
Validation loss: 1.5618583579217233

Epoch: 6| Step: 3
Training loss: 0.43458855152130127
Validation loss: 1.5742725787624237

Epoch: 6| Step: 4
Training loss: 0.3023871183395386
Validation loss: 1.5749187802755704

Epoch: 6| Step: 5
Training loss: 0.16916941106319427
Validation loss: 1.5797953765879396

Epoch: 6| Step: 6
Training loss: 0.20493866503238678
Validation loss: 1.5973243956924768

Epoch: 6| Step: 7
Training loss: 0.3948257565498352
Validation loss: 1.616654396057129

Epoch: 6| Step: 8
Training loss: 0.41540083289146423
Validation loss: 1.6050401015948224

Epoch: 6| Step: 9
Training loss: 0.23025275766849518
Validation loss: 1.5796560805330995

Epoch: 6| Step: 10
Training loss: 0.37312963604927063
Validation loss: 1.584344756218695

Epoch: 6| Step: 11
Training loss: 0.20573949813842773
Validation loss: 1.552376470258159

Epoch: 6| Step: 12
Training loss: 0.32721275091171265
Validation loss: 1.5417097012201946

Epoch: 6| Step: 13
Training loss: 0.649303674697876
Validation loss: 1.5528383229368476

Epoch: 288| Step: 0
Training loss: 0.2917523682117462
Validation loss: 1.538320069671959

Epoch: 6| Step: 1
Training loss: 0.37069863080978394
Validation loss: 1.548649667411722

Epoch: 6| Step: 2
Training loss: 0.22729119658470154
Validation loss: 1.5581221567687167

Epoch: 6| Step: 3
Training loss: 0.268059641122818
Validation loss: 1.5643015189837384

Epoch: 6| Step: 4
Training loss: 0.21668410301208496
Validation loss: 1.5862758178864755

Epoch: 6| Step: 5
Training loss: 0.36391234397888184
Validation loss: 1.6065954931320683

Epoch: 6| Step: 6
Training loss: 0.3019551634788513
Validation loss: 1.619706783243405

Epoch: 6| Step: 7
Training loss: 0.21006500720977783
Validation loss: 1.5668380439922374

Epoch: 6| Step: 8
Training loss: 0.2983996272087097
Validation loss: 1.5503693306317894

Epoch: 6| Step: 9
Training loss: 0.20155709981918335
Validation loss: 1.537154528402513

Epoch: 6| Step: 10
Training loss: 0.36173105239868164
Validation loss: 1.5127765760626843

Epoch: 6| Step: 11
Training loss: 0.6639271974563599
Validation loss: 1.522865113391671

Epoch: 6| Step: 12
Training loss: 0.37044858932495117
Validation loss: 1.5275069013718636

Epoch: 6| Step: 13
Training loss: 0.39653027057647705
Validation loss: 1.5013407802069059

Epoch: 289| Step: 0
Training loss: 0.46024903655052185
Validation loss: 1.516768938751631

Epoch: 6| Step: 1
Training loss: 0.3626065254211426
Validation loss: 1.544649512537064

Epoch: 6| Step: 2
Training loss: 0.3701266348361969
Validation loss: 1.5800182383547547

Epoch: 6| Step: 3
Training loss: 0.33085471391677856
Validation loss: 1.5749875896720475

Epoch: 6| Step: 4
Training loss: 0.11485661566257477
Validation loss: 1.5546776216517213

Epoch: 6| Step: 5
Training loss: 0.3661753535270691
Validation loss: 1.5717424038917787

Epoch: 6| Step: 6
Training loss: 0.0968361347913742
Validation loss: 1.5656707979017688

Epoch: 6| Step: 7
Training loss: 0.3845024108886719
Validation loss: 1.601456279395729

Epoch: 6| Step: 8
Training loss: 0.33987870812416077
Validation loss: 1.624682500798215

Epoch: 6| Step: 9
Training loss: 0.3108500838279724
Validation loss: 1.629621010954662

Epoch: 6| Step: 10
Training loss: 0.30849796533584595
Validation loss: 1.6496201407524846

Epoch: 6| Step: 11
Training loss: 0.3525988757610321
Validation loss: 1.6230805022742159

Epoch: 6| Step: 12
Training loss: 0.25881895422935486
Validation loss: 1.65489746421896

Epoch: 6| Step: 13
Training loss: 0.36207252740859985
Validation loss: 1.6438061550099363

Epoch: 290| Step: 0
Training loss: 0.19953462481498718
Validation loss: 1.634015134585801

Epoch: 6| Step: 1
Training loss: 0.4541255831718445
Validation loss: 1.6460368184633152

Epoch: 6| Step: 2
Training loss: 0.38465598225593567
Validation loss: 1.6371551598272016

Epoch: 6| Step: 3
Training loss: 0.19418160617351532
Validation loss: 1.6203382540774602

Epoch: 6| Step: 4
Training loss: 0.3647036552429199
Validation loss: 1.626234354511384

Epoch: 6| Step: 5
Training loss: 0.28937268257141113
Validation loss: 1.6052260796229045

Epoch: 6| Step: 6
Training loss: 0.4507251977920532
Validation loss: 1.6052316234957786

Epoch: 6| Step: 7
Training loss: 0.3111675977706909
Validation loss: 1.6065197439603909

Epoch: 6| Step: 8
Training loss: 0.46369612216949463
Validation loss: 1.5821135223552745

Epoch: 6| Step: 9
Training loss: 0.32536596059799194
Validation loss: 1.5962640854620165

Epoch: 6| Step: 10
Training loss: 0.22893521189689636
Validation loss: 1.584423138249305

Epoch: 6| Step: 11
Training loss: 0.31125423312187195
Validation loss: 1.6030600775954544

Epoch: 6| Step: 12
Training loss: 0.183518648147583
Validation loss: 1.6348702458925144

Epoch: 6| Step: 13
Training loss: 0.5621194839477539
Validation loss: 1.617814197335192

Epoch: 291| Step: 0
Training loss: 0.6288264393806458
Validation loss: 1.647921774976997

Epoch: 6| Step: 1
Training loss: 0.2235071063041687
Validation loss: 1.6432303356867966

Epoch: 6| Step: 2
Training loss: 0.26404261589050293
Validation loss: 1.597656960128456

Epoch: 6| Step: 3
Training loss: 0.21123433113098145
Validation loss: 1.5967999965913835

Epoch: 6| Step: 4
Training loss: 0.18687653541564941
Validation loss: 1.5741409768340409

Epoch: 6| Step: 5
Training loss: 0.2082461714744568
Validation loss: 1.5567252930774484

Epoch: 6| Step: 6
Training loss: 0.261863112449646
Validation loss: 1.5708071813788465

Epoch: 6| Step: 7
Training loss: 0.34849026799201965
Validation loss: 1.573001218098466

Epoch: 6| Step: 8
Training loss: 0.3184785842895508
Validation loss: 1.5607845706324424

Epoch: 6| Step: 9
Training loss: 0.3483573794364929
Validation loss: 1.591187588630184

Epoch: 6| Step: 10
Training loss: 0.3368002474308014
Validation loss: 1.5712683239290792

Epoch: 6| Step: 11
Training loss: 0.3277498781681061
Validation loss: 1.5441172366501184

Epoch: 6| Step: 12
Training loss: 0.28730660676956177
Validation loss: 1.5359137186440088

Epoch: 6| Step: 13
Training loss: 0.2828313410282135
Validation loss: 1.569590558287918

Epoch: 292| Step: 0
Training loss: 0.2000546157360077
Validation loss: 1.5678108789587533

Epoch: 6| Step: 1
Training loss: 0.24433165788650513
Validation loss: 1.5663906015375608

Epoch: 6| Step: 2
Training loss: 0.42948585748672485
Validation loss: 1.5742341087710472

Epoch: 6| Step: 3
Training loss: 0.4720529019832611
Validation loss: 1.5491505630554692

Epoch: 6| Step: 4
Training loss: 0.361510694026947
Validation loss: 1.555337409819326

Epoch: 6| Step: 5
Training loss: 0.4536285996437073
Validation loss: 1.5386656317659604

Epoch: 6| Step: 6
Training loss: 0.27519211173057556
Validation loss: 1.555951145387465

Epoch: 6| Step: 7
Training loss: 0.24633851647377014
Validation loss: 1.558301999363848

Epoch: 6| Step: 8
Training loss: 0.20401343703269958
Validation loss: 1.6067236482456166

Epoch: 6| Step: 9
Training loss: 0.17057952284812927
Validation loss: 1.5781991609963038

Epoch: 6| Step: 10
Training loss: 0.2989000082015991
Validation loss: 1.5726421174182688

Epoch: 6| Step: 11
Training loss: 0.2496957778930664
Validation loss: 1.5847884634489655

Epoch: 6| Step: 12
Training loss: 0.20778678357601166
Validation loss: 1.5926073699869134

Epoch: 6| Step: 13
Training loss: 0.29255354404449463
Validation loss: 1.5928279725454186

Epoch: 293| Step: 0
Training loss: 0.3558993935585022
Validation loss: 1.5964934928442842

Epoch: 6| Step: 1
Training loss: 0.1729937046766281
Validation loss: 1.59267900066991

Epoch: 6| Step: 2
Training loss: 0.2599371075630188
Validation loss: 1.6059490929367721

Epoch: 6| Step: 3
Training loss: 0.1590733826160431
Validation loss: 1.5829189041609406

Epoch: 6| Step: 4
Training loss: 0.3106629252433777
Validation loss: 1.6075945156876759

Epoch: 6| Step: 5
Training loss: 0.22863592207431793
Validation loss: 1.6066402273793374

Epoch: 6| Step: 6
Training loss: 0.4136142134666443
Validation loss: 1.6163024543434061

Epoch: 6| Step: 7
Training loss: 0.27166277170181274
Validation loss: 1.6172234076325611

Epoch: 6| Step: 8
Training loss: 0.24254807829856873
Validation loss: 1.627707044283549

Epoch: 6| Step: 9
Training loss: 0.38067322969436646
Validation loss: 1.5626749697551932

Epoch: 6| Step: 10
Training loss: 0.2387823462486267
Validation loss: 1.556014737775249

Epoch: 6| Step: 11
Training loss: 0.231138676404953
Validation loss: 1.5300192666310135

Epoch: 6| Step: 12
Training loss: 0.379059761762619
Validation loss: 1.5591700525693997

Epoch: 6| Step: 13
Training loss: 0.1535114198923111
Validation loss: 1.5471095987545547

Epoch: 294| Step: 0
Training loss: 0.29034140706062317
Validation loss: 1.5532173225956578

Epoch: 6| Step: 1
Training loss: 0.2848639190196991
Validation loss: 1.5476263043701008

Epoch: 6| Step: 2
Training loss: 0.16954922676086426
Validation loss: 1.573358181984194

Epoch: 6| Step: 3
Training loss: 0.1674826592206955
Validation loss: 1.5461705679534583

Epoch: 6| Step: 4
Training loss: 0.515153706073761
Validation loss: 1.5663283383974465

Epoch: 6| Step: 5
Training loss: 0.16825620830059052
Validation loss: 1.5611859957377117

Epoch: 6| Step: 6
Training loss: 0.37537842988967896
Validation loss: 1.6095257830876175

Epoch: 6| Step: 7
Training loss: 0.3367612659931183
Validation loss: 1.6128080583387805

Epoch: 6| Step: 8
Training loss: 0.20965678989887238
Validation loss: 1.5909424097307268

Epoch: 6| Step: 9
Training loss: 0.27975282073020935
Validation loss: 1.5500142305128035

Epoch: 6| Step: 10
Training loss: 0.27820801734924316
Validation loss: 1.5700923422331452

Epoch: 6| Step: 11
Training loss: 0.4102942943572998
Validation loss: 1.575584747458017

Epoch: 6| Step: 12
Training loss: 0.4335799217224121
Validation loss: 1.5844097701452111

Epoch: 6| Step: 13
Training loss: 0.32783815264701843
Validation loss: 1.6089500099100091

Epoch: 295| Step: 0
Training loss: 0.3494151532649994
Validation loss: 1.6038709379011584

Epoch: 6| Step: 1
Training loss: 0.2747659683227539
Validation loss: 1.597491559802845

Epoch: 6| Step: 2
Training loss: 0.26638609170913696
Validation loss: 1.6290396336586244

Epoch: 6| Step: 3
Training loss: 0.5929255485534668
Validation loss: 1.6552624907544864

Epoch: 6| Step: 4
Training loss: 0.22967374324798584
Validation loss: 1.6470883020790674

Epoch: 6| Step: 5
Training loss: 0.3980228900909424
Validation loss: 1.5958201551950106

Epoch: 6| Step: 6
Training loss: 0.3294525742530823
Validation loss: 1.5621612969265188

Epoch: 6| Step: 7
Training loss: 0.3180311620235443
Validation loss: 1.5314928639319636

Epoch: 6| Step: 8
Training loss: 0.26552289724349976
Validation loss: 1.572478578936669

Epoch: 6| Step: 9
Training loss: 0.38862788677215576
Validation loss: 1.5657753957215177

Epoch: 6| Step: 10
Training loss: 0.29811686277389526
Validation loss: 1.5574874070382887

Epoch: 6| Step: 11
Training loss: 0.41972947120666504
Validation loss: 1.567842379693062

Epoch: 6| Step: 12
Training loss: 0.2420080006122589
Validation loss: 1.5946943522781454

Epoch: 6| Step: 13
Training loss: 0.10339485108852386
Validation loss: 1.6339083499805902

Epoch: 296| Step: 0
Training loss: 0.3152116537094116
Validation loss: 1.6574329855621501

Epoch: 6| Step: 1
Training loss: 0.31016242504119873
Validation loss: 1.6847733041291595

Epoch: 6| Step: 2
Training loss: 0.44354408979415894
Validation loss: 1.6702070492570118

Epoch: 6| Step: 3
Training loss: 0.273721307516098
Validation loss: 1.6832645003513624

Epoch: 6| Step: 4
Training loss: 0.3427621126174927
Validation loss: 1.6287330606932282

Epoch: 6| Step: 5
Training loss: 0.2861925959587097
Validation loss: 1.6094000852236183

Epoch: 6| Step: 6
Training loss: 0.5189917087554932
Validation loss: 1.6109146341200797

Epoch: 6| Step: 7
Training loss: 0.13457706570625305
Validation loss: 1.5876505374908447

Epoch: 6| Step: 8
Training loss: 0.4047362208366394
Validation loss: 1.5770585844593663

Epoch: 6| Step: 9
Training loss: 0.5207549333572388
Validation loss: 1.5561898921125679

Epoch: 6| Step: 10
Training loss: 0.3115345239639282
Validation loss: 1.5721578136567147

Epoch: 6| Step: 11
Training loss: 0.25970014929771423
Validation loss: 1.5811992306863107

Epoch: 6| Step: 12
Training loss: 0.37961193919181824
Validation loss: 1.5579588554238761

Epoch: 6| Step: 13
Training loss: 0.11733133345842361
Validation loss: 1.5082933928376885

Epoch: 297| Step: 0
Training loss: 0.2055039405822754
Validation loss: 1.54781719305182

Epoch: 6| Step: 1
Training loss: 0.3868939280509949
Validation loss: 1.5518802788949781

Epoch: 6| Step: 2
Training loss: 0.14607588946819305
Validation loss: 1.5534614786025016

Epoch: 6| Step: 3
Training loss: 0.254949688911438
Validation loss: 1.5658713720178092

Epoch: 6| Step: 4
Training loss: 0.2738615870475769
Validation loss: 1.6116379794254099

Epoch: 6| Step: 5
Training loss: 0.18219229578971863
Validation loss: 1.6143670889639086

Epoch: 6| Step: 6
Training loss: 0.24022898077964783
Validation loss: 1.6123418833619805

Epoch: 6| Step: 7
Training loss: 0.3505929112434387
Validation loss: 1.6190601266840452

Epoch: 6| Step: 8
Training loss: 0.37487590312957764
Validation loss: 1.6113986122992732

Epoch: 6| Step: 9
Training loss: 0.4450218975543976
Validation loss: 1.6214023995143112

Epoch: 6| Step: 10
Training loss: 0.2959827482700348
Validation loss: 1.5765104614278322

Epoch: 6| Step: 11
Training loss: 0.30653560161590576
Validation loss: 1.5928540806616507

Epoch: 6| Step: 12
Training loss: 0.31546980142593384
Validation loss: 1.5368930530804459

Epoch: 6| Step: 13
Training loss: 0.12970593571662903
Validation loss: 1.554892373341386

Epoch: 298| Step: 0
Training loss: 0.20937764644622803
Validation loss: 1.5485411869582308

Epoch: 6| Step: 1
Training loss: 0.22676974534988403
Validation loss: 1.5309174253094582

Epoch: 6| Step: 2
Training loss: 0.25544261932373047
Validation loss: 1.5485714379177298

Epoch: 6| Step: 3
Training loss: 0.32145267724990845
Validation loss: 1.556818792896886

Epoch: 6| Step: 4
Training loss: 0.32183676958084106
Validation loss: 1.588809323567216

Epoch: 6| Step: 5
Training loss: 0.3368351459503174
Validation loss: 1.6096846518977996

Epoch: 6| Step: 6
Training loss: 0.40050360560417175
Validation loss: 1.6038092810620543

Epoch: 6| Step: 7
Training loss: 0.2122899740934372
Validation loss: 1.6027771811331473

Epoch: 6| Step: 8
Training loss: 0.3834688365459442
Validation loss: 1.6034240594474218

Epoch: 6| Step: 9
Training loss: 0.3268654942512512
Validation loss: 1.565795099863442

Epoch: 6| Step: 10
Training loss: 0.2277711033821106
Validation loss: 1.5751915516391877

Epoch: 6| Step: 11
Training loss: 0.25376808643341064
Validation loss: 1.5449405741947952

Epoch: 6| Step: 12
Training loss: 0.21945880353450775
Validation loss: 1.533747665343746

Epoch: 6| Step: 13
Training loss: 0.5778963565826416
Validation loss: 1.5363629684653333

Epoch: 299| Step: 0
Training loss: 0.22629185020923615
Validation loss: 1.5410329500834148

Epoch: 6| Step: 1
Training loss: 0.23745909333229065
Validation loss: 1.5816282918376308

Epoch: 6| Step: 2
Training loss: 0.21951383352279663
Validation loss: 1.5928666258371005

Epoch: 6| Step: 3
Training loss: 0.3326953947544098
Validation loss: 1.6092286135560723

Epoch: 6| Step: 4
Training loss: 0.16363456845283508
Validation loss: 1.5922981039170296

Epoch: 6| Step: 5
Training loss: 0.4992853105068207
Validation loss: 1.540307129583051

Epoch: 6| Step: 6
Training loss: 0.31908151507377625
Validation loss: 1.5693012988695534

Epoch: 6| Step: 7
Training loss: 0.5188906192779541
Validation loss: 1.5212869669801445

Epoch: 6| Step: 8
Training loss: 0.31064701080322266
Validation loss: 1.5128795055932895

Epoch: 6| Step: 9
Training loss: 0.22968649864196777
Validation loss: 1.5174140866084764

Epoch: 6| Step: 10
Training loss: 0.3167886435985565
Validation loss: 1.5433274270385824

Epoch: 6| Step: 11
Training loss: 0.2483517825603485
Validation loss: 1.5126839574947153

Epoch: 6| Step: 12
Training loss: 0.2354866862297058
Validation loss: 1.5172302460157743

Epoch: 6| Step: 13
Training loss: 0.23714855313301086
Validation loss: 1.5241817402583298

Epoch: 300| Step: 0
Training loss: 0.2888863980770111
Validation loss: 1.5364526330783803

Epoch: 6| Step: 1
Training loss: 0.2721385657787323
Validation loss: 1.5591139511395526

Epoch: 6| Step: 2
Training loss: 0.14030791819095612
Validation loss: 1.566908601791628

Epoch: 6| Step: 3
Training loss: 0.19260545074939728
Validation loss: 1.5865249172333749

Epoch: 6| Step: 4
Training loss: 0.46645963191986084
Validation loss: 1.6151855312367922

Epoch: 6| Step: 5
Training loss: 0.37435486912727356
Validation loss: 1.598129874916487

Epoch: 6| Step: 6
Training loss: 0.36477553844451904
Validation loss: 1.5954439191408054

Epoch: 6| Step: 7
Training loss: 0.27786386013031006
Validation loss: 1.5669897897269136

Epoch: 6| Step: 8
Training loss: 0.36249840259552
Validation loss: 1.5670074391108688

Epoch: 6| Step: 9
Training loss: 0.2220587134361267
Validation loss: 1.6087961081535584

Epoch: 6| Step: 10
Training loss: 0.27242881059646606
Validation loss: 1.5755478028328187

Epoch: 6| Step: 11
Training loss: 0.25479745864868164
Validation loss: 1.552351673444112

Epoch: 6| Step: 12
Training loss: 0.24936652183532715
Validation loss: 1.5419359078971289

Epoch: 6| Step: 13
Training loss: 0.3548000454902649
Validation loss: 1.510061716520658

Epoch: 301| Step: 0
Training loss: 0.2199673056602478
Validation loss: 1.5256187531255907

Epoch: 6| Step: 1
Training loss: 0.4190376400947571
Validation loss: 1.5108858180302445

Epoch: 6| Step: 2
Training loss: 0.19844499230384827
Validation loss: 1.534941542533136

Epoch: 6| Step: 3
Training loss: 0.37357237935066223
Validation loss: 1.5560876348967194

Epoch: 6| Step: 4
Training loss: 0.24305248260498047
Validation loss: 1.5825206836064656

Epoch: 6| Step: 5
Training loss: 0.3745041489601135
Validation loss: 1.5978562844696866

Epoch: 6| Step: 6
Training loss: 0.2946755886077881
Validation loss: 1.6205774596942368

Epoch: 6| Step: 7
Training loss: 0.30667710304260254
Validation loss: 1.651946536956295

Epoch: 6| Step: 8
Training loss: 0.38149893283843994
Validation loss: 1.6750155366877073

Epoch: 6| Step: 9
Training loss: 0.23796811699867249
Validation loss: 1.6710721369712584

Epoch: 6| Step: 10
Training loss: 0.21755534410476685
Validation loss: 1.6127455747255715

Epoch: 6| Step: 11
Training loss: 0.2452002614736557
Validation loss: 1.5635485238926385

Epoch: 6| Step: 12
Training loss: 0.21120283007621765
Validation loss: 1.5524501287808983

Epoch: 6| Step: 13
Training loss: 0.2380860596895218
Validation loss: 1.541097169281334

Epoch: 302| Step: 0
Training loss: 0.24274949729442596
Validation loss: 1.5728790862585909

Epoch: 6| Step: 1
Training loss: 0.07398641109466553
Validation loss: 1.5493627184180803

Epoch: 6| Step: 2
Training loss: 0.31836360692977905
Validation loss: 1.5380025909792991

Epoch: 6| Step: 3
Training loss: 0.15203094482421875
Validation loss: 1.5678453714616838

Epoch: 6| Step: 4
Training loss: 0.3545319437980652
Validation loss: 1.5896314587644351

Epoch: 6| Step: 5
Training loss: 0.24378234148025513
Validation loss: 1.5778587889927689

Epoch: 6| Step: 6
Training loss: 0.3724856376647949
Validation loss: 1.5883334759742982

Epoch: 6| Step: 7
Training loss: 0.16971763968467712
Validation loss: 1.579137215050318

Epoch: 6| Step: 8
Training loss: 0.3058032691478729
Validation loss: 1.5642565950270622

Epoch: 6| Step: 9
Training loss: 0.22094078361988068
Validation loss: 1.540150136075994

Epoch: 6| Step: 10
Training loss: 0.3010583519935608
Validation loss: 1.5357717724256619

Epoch: 6| Step: 11
Training loss: 0.469612181186676
Validation loss: 1.532599154979952

Epoch: 6| Step: 12
Training loss: 0.2595095634460449
Validation loss: 1.5364433244992328

Epoch: 6| Step: 13
Training loss: 0.2311301827430725
Validation loss: 1.5189402308515323

Epoch: 303| Step: 0
Training loss: 0.1596384346485138
Validation loss: 1.5229770098963091

Epoch: 6| Step: 1
Training loss: 0.23319096863269806
Validation loss: 1.5486845829153573

Epoch: 6| Step: 2
Training loss: 0.2922576367855072
Validation loss: 1.5248072916461575

Epoch: 6| Step: 3
Training loss: 0.25737956166267395
Validation loss: 1.5217577180554789

Epoch: 6| Step: 4
Training loss: 0.23799724876880646
Validation loss: 1.5058912589985838

Epoch: 6| Step: 5
Training loss: 0.4014434218406677
Validation loss: 1.5081194395660071

Epoch: 6| Step: 6
Training loss: 0.25655874609947205
Validation loss: 1.5048966356503066

Epoch: 6| Step: 7
Training loss: 0.2801470160484314
Validation loss: 1.5004564741606354

Epoch: 6| Step: 8
Training loss: 0.24840514361858368
Validation loss: 1.473337104243617

Epoch: 6| Step: 9
Training loss: 0.22992438077926636
Validation loss: 1.5064964307251798

Epoch: 6| Step: 10
Training loss: 0.23792678117752075
Validation loss: 1.4748709945268528

Epoch: 6| Step: 11
Training loss: 0.24347814917564392
Validation loss: 1.5130747249049525

Epoch: 6| Step: 12
Training loss: 0.2773439586162567
Validation loss: 1.524165411149302

Epoch: 6| Step: 13
Training loss: 0.258032888174057
Validation loss: 1.5152564792222873

Epoch: 304| Step: 0
Training loss: 0.16972744464874268
Validation loss: 1.548098478265988

Epoch: 6| Step: 1
Training loss: 0.16681918501853943
Validation loss: 1.5847567947961951

Epoch: 6| Step: 2
Training loss: 0.14874552190303802
Validation loss: 1.5850005649751233

Epoch: 6| Step: 3
Training loss: 0.3011050224304199
Validation loss: 1.58365559962488

Epoch: 6| Step: 4
Training loss: 0.2002321481704712
Validation loss: 1.573294561396363

Epoch: 6| Step: 5
Training loss: 0.274879515171051
Validation loss: 1.5826804061089792

Epoch: 6| Step: 6
Training loss: 0.2564728856086731
Validation loss: 1.565219727895593

Epoch: 6| Step: 7
Training loss: 0.2036188840866089
Validation loss: 1.5643760920852743

Epoch: 6| Step: 8
Training loss: 0.20194001495838165
Validation loss: 1.582488126652215

Epoch: 6| Step: 9
Training loss: 0.22441887855529785
Validation loss: 1.5409816682979625

Epoch: 6| Step: 10
Training loss: 0.31762242317199707
Validation loss: 1.596094880052792

Epoch: 6| Step: 11
Training loss: 0.33460691571235657
Validation loss: 1.5857372642845236

Epoch: 6| Step: 12
Training loss: 0.3741288185119629
Validation loss: 1.6303995681065384

Epoch: 6| Step: 13
Training loss: 0.3038898706436157
Validation loss: 1.6332984470552014

Epoch: 305| Step: 0
Training loss: 0.38827916979789734
Validation loss: 1.6296727118953582

Epoch: 6| Step: 1
Training loss: 0.1994083672761917
Validation loss: 1.6157747942914245

Epoch: 6| Step: 2
Training loss: 0.3083410859107971
Validation loss: 1.5779516017565163

Epoch: 6| Step: 3
Training loss: 0.2338026612997055
Validation loss: 1.5919728074022519

Epoch: 6| Step: 4
Training loss: 0.31895896792411804
Validation loss: 1.606225388024443

Epoch: 6| Step: 5
Training loss: 0.42510026693344116
Validation loss: 1.5530429911869827

Epoch: 6| Step: 6
Training loss: 0.3146153688430786
Validation loss: 1.5603983440706808

Epoch: 6| Step: 7
Training loss: 0.18607482314109802
Validation loss: 1.5349721613750662

Epoch: 6| Step: 8
Training loss: 0.2153993397951126
Validation loss: 1.5917073577962897

Epoch: 6| Step: 9
Training loss: 0.4440235495567322
Validation loss: 1.5757280511240805

Epoch: 6| Step: 10
Training loss: 0.3513707220554352
Validation loss: 1.5974104532631495

Epoch: 6| Step: 11
Training loss: 0.1799648106098175
Validation loss: 1.581375902698886

Epoch: 6| Step: 12
Training loss: 0.24580317735671997
Validation loss: 1.5603862988051547

Epoch: 6| Step: 13
Training loss: 0.15272171795368195
Validation loss: 1.5267104858993201

Epoch: 306| Step: 0
Training loss: 0.26200592517852783
Validation loss: 1.5538182361151582

Epoch: 6| Step: 1
Training loss: 0.18270845711231232
Validation loss: 1.5825371178247596

Epoch: 6| Step: 2
Training loss: 0.20576472580432892
Validation loss: 1.600284643070672

Epoch: 6| Step: 3
Training loss: 0.2587589621543884
Validation loss: 1.611167864132953

Epoch: 6| Step: 4
Training loss: 0.22282394766807556
Validation loss: 1.6245618186971194

Epoch: 6| Step: 5
Training loss: 0.7047041058540344
Validation loss: 1.6356484043982722

Epoch: 6| Step: 6
Training loss: 0.22534170746803284
Validation loss: 1.6143467041753954

Epoch: 6| Step: 7
Training loss: 0.2746187746524811
Validation loss: 1.5683051475914576

Epoch: 6| Step: 8
Training loss: 0.2502780854701996
Validation loss: 1.5774330631379159

Epoch: 6| Step: 9
Training loss: 0.18727920949459076
Validation loss: 1.559323355715762

Epoch: 6| Step: 10
Training loss: 0.12045971304178238
Validation loss: 1.5277537152331362

Epoch: 6| Step: 11
Training loss: 0.2569708228111267
Validation loss: 1.4866353029845862

Epoch: 6| Step: 12
Training loss: 0.46685147285461426
Validation loss: 1.536313570314838

Epoch: 6| Step: 13
Training loss: 0.20086659491062164
Validation loss: 1.510691919634419

Epoch: 307| Step: 0
Training loss: 0.26615166664123535
Validation loss: 1.5203050618530602

Epoch: 6| Step: 1
Training loss: 0.13173098862171173
Validation loss: 1.5215421197234944

Epoch: 6| Step: 2
Training loss: 0.2921740710735321
Validation loss: 1.5123605676876601

Epoch: 6| Step: 3
Training loss: 0.256158709526062
Validation loss: 1.4970568341593589

Epoch: 6| Step: 4
Training loss: 0.18487221002578735
Validation loss: 1.51596579628606

Epoch: 6| Step: 5
Training loss: 0.1779780387878418
Validation loss: 1.5285633815232145

Epoch: 6| Step: 6
Training loss: 0.2526280879974365
Validation loss: 1.5309775093550324

Epoch: 6| Step: 7
Training loss: 0.20657682418823242
Validation loss: 1.5297820439902685

Epoch: 6| Step: 8
Training loss: 0.2660577893257141
Validation loss: 1.5427656007069412

Epoch: 6| Step: 9
Training loss: 0.21391114592552185
Validation loss: 1.5192032039806407

Epoch: 6| Step: 10
Training loss: 0.21246597170829773
Validation loss: 1.5108004603334653

Epoch: 6| Step: 11
Training loss: 0.19746807217597961
Validation loss: 1.4970840689956502

Epoch: 6| Step: 12
Training loss: 0.3033995032310486
Validation loss: 1.5240892799951697

Epoch: 6| Step: 13
Training loss: 0.5676150918006897
Validation loss: 1.5020253401930614

Epoch: 308| Step: 0
Training loss: 0.16508126258850098
Validation loss: 1.5199941806895758

Epoch: 6| Step: 1
Training loss: 0.27842336893081665
Validation loss: 1.502297603955833

Epoch: 6| Step: 2
Training loss: 0.4307081997394562
Validation loss: 1.5035090561835998

Epoch: 6| Step: 3
Training loss: 0.34392380714416504
Validation loss: 1.512504687873266

Epoch: 6| Step: 4
Training loss: 0.20556247234344482
Validation loss: 1.5233592538423435

Epoch: 6| Step: 5
Training loss: 0.3590575158596039
Validation loss: 1.5048333906358289

Epoch: 6| Step: 6
Training loss: 0.25052058696746826
Validation loss: 1.4813711643218994

Epoch: 6| Step: 7
Training loss: 0.2519853413105011
Validation loss: 1.5153539257664834

Epoch: 6| Step: 8
Training loss: 0.28401505947113037
Validation loss: 1.5403425616602744

Epoch: 6| Step: 9
Training loss: 0.07558385282754898
Validation loss: 1.501552890705806

Epoch: 6| Step: 10
Training loss: 0.1369139403104782
Validation loss: 1.523382914963589

Epoch: 6| Step: 11
Training loss: 0.28351879119873047
Validation loss: 1.5760863686120639

Epoch: 6| Step: 12
Training loss: 0.2427387833595276
Validation loss: 1.561283947319113

Epoch: 6| Step: 13
Training loss: 0.2819098234176636
Validation loss: 1.566359451381109

Epoch: 309| Step: 0
Training loss: 0.20896248519420624
Validation loss: 1.561302295295141

Epoch: 6| Step: 1
Training loss: 0.2906695604324341
Validation loss: 1.5390924830590524

Epoch: 6| Step: 2
Training loss: 0.36954623460769653
Validation loss: 1.5522721852025678

Epoch: 6| Step: 3
Training loss: 0.19116373360157013
Validation loss: 1.527413809171287

Epoch: 6| Step: 4
Training loss: 0.2840288281440735
Validation loss: 1.5345875755433114

Epoch: 6| Step: 5
Training loss: 0.20819023251533508
Validation loss: 1.5281607681705105

Epoch: 6| Step: 6
Training loss: 0.10474620759487152
Validation loss: 1.5290553108338387

Epoch: 6| Step: 7
Training loss: 0.19207552075386047
Validation loss: 1.4876495792019753

Epoch: 6| Step: 8
Training loss: 0.30766814947128296
Validation loss: 1.5330357090119393

Epoch: 6| Step: 9
Training loss: 0.331048846244812
Validation loss: 1.5356543371754308

Epoch: 6| Step: 10
Training loss: 0.2836008667945862
Validation loss: 1.521718942990867

Epoch: 6| Step: 11
Training loss: 0.22470971941947937
Validation loss: 1.5580170616026847

Epoch: 6| Step: 12
Training loss: 0.11096575856208801
Validation loss: 1.5410424970811414

Epoch: 6| Step: 13
Training loss: 0.15386703610420227
Validation loss: 1.5395521758705057

Epoch: 310| Step: 0
Training loss: 0.2940063774585724
Validation loss: 1.530510543495096

Epoch: 6| Step: 1
Training loss: 0.2239951342344284
Validation loss: 1.5087969751768215

Epoch: 6| Step: 2
Training loss: 0.35289615392684937
Validation loss: 1.5095205550552697

Epoch: 6| Step: 3
Training loss: 0.20357197523117065
Validation loss: 1.5035653011773222

Epoch: 6| Step: 4
Training loss: 0.11854875832796097
Validation loss: 1.4759159152225783

Epoch: 6| Step: 5
Training loss: 0.19043387472629547
Validation loss: 1.4908239098005398

Epoch: 6| Step: 6
Training loss: 0.1765591949224472
Validation loss: 1.4879084415333246

Epoch: 6| Step: 7
Training loss: 0.19033406674861908
Validation loss: 1.5024964245416785

Epoch: 6| Step: 8
Training loss: 0.18450510501861572
Validation loss: 1.5102161130597513

Epoch: 6| Step: 9
Training loss: 0.3804090917110443
Validation loss: 1.5001118452318254

Epoch: 6| Step: 10
Training loss: 0.2497938871383667
Validation loss: 1.5443164860048602

Epoch: 6| Step: 11
Training loss: 0.22064119577407837
Validation loss: 1.5407132256415583

Epoch: 6| Step: 12
Training loss: 0.34459632635116577
Validation loss: 1.545764382167529

Epoch: 6| Step: 13
Training loss: 0.2204279750585556
Validation loss: 1.532816465182971

Epoch: 311| Step: 0
Training loss: 0.20396080613136292
Validation loss: 1.5354157711869927

Epoch: 6| Step: 1
Training loss: 0.2498537003993988
Validation loss: 1.5732119493587042

Epoch: 6| Step: 2
Training loss: 0.3453563153743744
Validation loss: 1.58496000946209

Epoch: 6| Step: 3
Training loss: 0.25269395112991333
Validation loss: 1.5946199086404615

Epoch: 6| Step: 4
Training loss: 0.3858042359352112
Validation loss: 1.5685441455533427

Epoch: 6| Step: 5
Training loss: 0.18370388448238373
Validation loss: 1.5697558464542511

Epoch: 6| Step: 6
Training loss: 0.17764121294021606
Validation loss: 1.5741008802126812

Epoch: 6| Step: 7
Training loss: 0.18937236070632935
Validation loss: 1.5570564859656877

Epoch: 6| Step: 8
Training loss: 0.23602598905563354
Validation loss: 1.5390364252110964

Epoch: 6| Step: 9
Training loss: 0.29203054308891296
Validation loss: 1.5097207279615505

Epoch: 6| Step: 10
Training loss: 0.16875797510147095
Validation loss: 1.5125352971015438

Epoch: 6| Step: 11
Training loss: 0.3879399299621582
Validation loss: 1.5088712656369774

Epoch: 6| Step: 12
Training loss: 0.4173162579536438
Validation loss: 1.4912482769258562

Epoch: 6| Step: 13
Training loss: 0.21307618916034698
Validation loss: 1.5118694049055859

Epoch: 312| Step: 0
Training loss: 0.2723655700683594
Validation loss: 1.4870082627060592

Epoch: 6| Step: 1
Training loss: 0.14905108511447906
Validation loss: 1.489658381349297

Epoch: 6| Step: 2
Training loss: 0.25616151094436646
Validation loss: 1.505275877573157

Epoch: 6| Step: 3
Training loss: 0.25931209325790405
Validation loss: 1.523333691781567

Epoch: 6| Step: 4
Training loss: 0.21990370750427246
Validation loss: 1.5470509516295565

Epoch: 6| Step: 5
Training loss: 0.1937102973461151
Validation loss: 1.5836292671900924

Epoch: 6| Step: 6
Training loss: 0.16423942148685455
Validation loss: 1.6047808175445886

Epoch: 6| Step: 7
Training loss: 0.12886525690555573
Validation loss: 1.5692780351126066

Epoch: 6| Step: 8
Training loss: 0.13478858768939972
Validation loss: 1.543894374242393

Epoch: 6| Step: 9
Training loss: 0.29375097155570984
Validation loss: 1.51526213717717

Epoch: 6| Step: 10
Training loss: 0.36201372742652893
Validation loss: 1.5267019541032854

Epoch: 6| Step: 11
Training loss: 0.29233717918395996
Validation loss: 1.5595592849998063

Epoch: 6| Step: 12
Training loss: 0.27850350737571716
Validation loss: 1.5360822587884881

Epoch: 6| Step: 13
Training loss: 0.3328523635864258
Validation loss: 1.5470733001667967

Epoch: 313| Step: 0
Training loss: 0.2332790493965149
Validation loss: 1.5748135607729676

Epoch: 6| Step: 1
Training loss: 0.26701903343200684
Validation loss: 1.540054613544095

Epoch: 6| Step: 2
Training loss: 0.27438801527023315
Validation loss: 1.5483007264393631

Epoch: 6| Step: 3
Training loss: 0.2820570766925812
Validation loss: 1.5656741114072903

Epoch: 6| Step: 4
Training loss: 0.15794715285301208
Validation loss: 1.5616961051059026

Epoch: 6| Step: 5
Training loss: 0.21821856498718262
Validation loss: 1.5944481049814532

Epoch: 6| Step: 6
Training loss: 0.24464666843414307
Validation loss: 1.5691875821800643

Epoch: 6| Step: 7
Training loss: 0.16670623421669006
Validation loss: 1.5438770209589312

Epoch: 6| Step: 8
Training loss: 0.3142938017845154
Validation loss: 1.5481274858597787

Epoch: 6| Step: 9
Training loss: 0.294481098651886
Validation loss: 1.525243248990787

Epoch: 6| Step: 10
Training loss: 0.24484272301197052
Validation loss: 1.531145852740093

Epoch: 6| Step: 11
Training loss: 0.25460097193717957
Validation loss: 1.52491077556405

Epoch: 6| Step: 12
Training loss: 0.1778486967086792
Validation loss: 1.5340831882210189

Epoch: 6| Step: 13
Training loss: 0.31125232577323914
Validation loss: 1.5250740230724376

Epoch: 314| Step: 0
Training loss: 0.25062674283981323
Validation loss: 1.5375067995440574

Epoch: 6| Step: 1
Training loss: 0.28893938660621643
Validation loss: 1.521785404092522

Epoch: 6| Step: 2
Training loss: 0.1744304597377777
Validation loss: 1.5326413928821523

Epoch: 6| Step: 3
Training loss: 0.3193870484828949
Validation loss: 1.520327280926448

Epoch: 6| Step: 4
Training loss: 0.13698190450668335
Validation loss: 1.482185725242861

Epoch: 6| Step: 5
Training loss: 0.2845330834388733
Validation loss: 1.506005060288214

Epoch: 6| Step: 6
Training loss: 0.24965214729309082
Validation loss: 1.5089174932049167

Epoch: 6| Step: 7
Training loss: 0.23753046989440918
Validation loss: 1.4988286828482023

Epoch: 6| Step: 8
Training loss: 0.14288398623466492
Validation loss: 1.525609649637694

Epoch: 6| Step: 9
Training loss: 0.19421210885047913
Validation loss: 1.5466062958522508

Epoch: 6| Step: 10
Training loss: 0.2863307595252991
Validation loss: 1.5310214399009623

Epoch: 6| Step: 11
Training loss: 0.25958216190338135
Validation loss: 1.545944893231956

Epoch: 6| Step: 12
Training loss: 0.2469106912612915
Validation loss: 1.5224111105806084

Epoch: 6| Step: 13
Training loss: 0.21097740530967712
Validation loss: 1.518784571719426

Epoch: 315| Step: 0
Training loss: 0.17235267162322998
Validation loss: 1.5159180548883253

Epoch: 6| Step: 1
Training loss: 0.29769909381866455
Validation loss: 1.5582633031311857

Epoch: 6| Step: 2
Training loss: 0.35918083786964417
Validation loss: 1.55392413754617

Epoch: 6| Step: 3
Training loss: 0.15250264108181
Validation loss: 1.5176412918234383

Epoch: 6| Step: 4
Training loss: 0.23855257034301758
Validation loss: 1.5199570848095802

Epoch: 6| Step: 5
Training loss: 0.17994670569896698
Validation loss: 1.5016109725480438

Epoch: 6| Step: 6
Training loss: 0.2890157103538513
Validation loss: 1.5044048729763235

Epoch: 6| Step: 7
Training loss: 0.22652938961982727
Validation loss: 1.505760859417659

Epoch: 6| Step: 8
Training loss: 0.23931452631950378
Validation loss: 1.5104516078067083

Epoch: 6| Step: 9
Training loss: 0.13630488514900208
Validation loss: 1.5342844532382103

Epoch: 6| Step: 10
Training loss: 0.2601509094238281
Validation loss: 1.5280552935856644

Epoch: 6| Step: 11
Training loss: 0.3546162545681
Validation loss: 1.5485765587898992

Epoch: 6| Step: 12
Training loss: 0.13923874497413635
Validation loss: 1.5505286006517307

Epoch: 6| Step: 13
Training loss: 0.17485874891281128
Validation loss: 1.5661045210335844

Epoch: 316| Step: 0
Training loss: 0.23716142773628235
Validation loss: 1.5805763557393064

Epoch: 6| Step: 1
Training loss: 0.21343839168548584
Validation loss: 1.5755417872500677

Epoch: 6| Step: 2
Training loss: 0.1861666440963745
Validation loss: 1.5768662575752503

Epoch: 6| Step: 3
Training loss: 0.26075616478919983
Validation loss: 1.5372521877288818

Epoch: 6| Step: 4
Training loss: 0.25602537393569946
Validation loss: 1.5569125349803636

Epoch: 6| Step: 5
Training loss: 0.2213798314332962
Validation loss: 1.5153506148246028

Epoch: 6| Step: 6
Training loss: 0.2893298864364624
Validation loss: 1.5006436173633864

Epoch: 6| Step: 7
Training loss: 0.25922122597694397
Validation loss: 1.5058114067200692

Epoch: 6| Step: 8
Training loss: 0.19118651747703552
Validation loss: 1.4986231865421418

Epoch: 6| Step: 9
Training loss: 0.22460144758224487
Validation loss: 1.4932655044781264

Epoch: 6| Step: 10
Training loss: 0.3399045467376709
Validation loss: 1.511698486984417

Epoch: 6| Step: 11
Training loss: 0.19608496129512787
Validation loss: 1.4967416281341224

Epoch: 6| Step: 12
Training loss: 0.20792056620121002
Validation loss: 1.4976095871258808

Epoch: 6| Step: 13
Training loss: 0.149271622300148
Validation loss: 1.5005497060796267

Epoch: 317| Step: 0
Training loss: 0.16457411646842957
Validation loss: 1.53940406281461

Epoch: 6| Step: 1
Training loss: 0.3978100121021271
Validation loss: 1.5897479108584824

Epoch: 6| Step: 2
Training loss: 0.25565305352211
Validation loss: 1.6125688399038007

Epoch: 6| Step: 3
Training loss: 0.16743212938308716
Validation loss: 1.5902481643102502

Epoch: 6| Step: 4
Training loss: 0.31164586544036865
Validation loss: 1.6005558544589626

Epoch: 6| Step: 5
Training loss: 0.2389531433582306
Validation loss: 1.5982512979097263

Epoch: 6| Step: 6
Training loss: 0.25972455739974976
Validation loss: 1.5836122446162726

Epoch: 6| Step: 7
Training loss: 0.20739778876304626
Validation loss: 1.562818883567728

Epoch: 6| Step: 8
Training loss: 0.18975535035133362
Validation loss: 1.5255181956034836

Epoch: 6| Step: 9
Training loss: 0.26833397150039673
Validation loss: 1.4765571919820641

Epoch: 6| Step: 10
Training loss: 0.23963001370429993
Validation loss: 1.49128597013412

Epoch: 6| Step: 11
Training loss: 0.19949683547019958
Validation loss: 1.4823945132634972

Epoch: 6| Step: 12
Training loss: 0.21791261434555054
Validation loss: 1.4910114106311594

Epoch: 6| Step: 13
Training loss: 0.2595231533050537
Validation loss: 1.4937088092168171

Epoch: 318| Step: 0
Training loss: 0.2281922698020935
Validation loss: 1.5076458902769192

Epoch: 6| Step: 1
Training loss: 0.3074151873588562
Validation loss: 1.5170083609960412

Epoch: 6| Step: 2
Training loss: 0.25504615902900696
Validation loss: 1.5469642871169633

Epoch: 6| Step: 3
Training loss: 0.3599591851234436
Validation loss: 1.5748992799430765

Epoch: 6| Step: 4
Training loss: 0.28359341621398926
Validation loss: 1.5623850591721073

Epoch: 6| Step: 5
Training loss: 0.27237504720687866
Validation loss: 1.5572992409429243

Epoch: 6| Step: 6
Training loss: 0.1813274770975113
Validation loss: 1.5017081999009656

Epoch: 6| Step: 7
Training loss: 0.2252633422613144
Validation loss: 1.5100886065472838

Epoch: 6| Step: 8
Training loss: 0.12758252024650574
Validation loss: 1.498521897100633

Epoch: 6| Step: 9
Training loss: 0.16655497252941132
Validation loss: 1.499941070874532

Epoch: 6| Step: 10
Training loss: 0.26912155747413635
Validation loss: 1.5100216513038964

Epoch: 6| Step: 11
Training loss: 0.0880025178194046
Validation loss: 1.4780461442086004

Epoch: 6| Step: 12
Training loss: 0.2296728640794754
Validation loss: 1.5357542525055587

Epoch: 6| Step: 13
Training loss: 0.04889398068189621
Validation loss: 1.5364777183019986

Epoch: 319| Step: 0
Training loss: 0.1881365180015564
Validation loss: 1.5684687924641434

Epoch: 6| Step: 1
Training loss: 0.2582542300224304
Validation loss: 1.5641398417052401

Epoch: 6| Step: 2
Training loss: 0.2903366684913635
Validation loss: 1.5656197449212432

Epoch: 6| Step: 3
Training loss: 0.10804201662540436
Validation loss: 1.548429980072924

Epoch: 6| Step: 4
Training loss: 0.30553650856018066
Validation loss: 1.5092386276491228

Epoch: 6| Step: 5
Training loss: 0.1364881694316864
Validation loss: 1.5002130282822477

Epoch: 6| Step: 6
Training loss: 0.19020181894302368
Validation loss: 1.4829625237372615

Epoch: 6| Step: 7
Training loss: 0.26358672976493835
Validation loss: 1.4926823877519177

Epoch: 6| Step: 8
Training loss: 0.3270617127418518
Validation loss: 1.491202151903542

Epoch: 6| Step: 9
Training loss: 0.16347703337669373
Validation loss: 1.4792898508810228

Epoch: 6| Step: 10
Training loss: 0.19647829234600067
Validation loss: 1.478689186034664

Epoch: 6| Step: 11
Training loss: 0.21350152790546417
Validation loss: 1.4558176904596307

Epoch: 6| Step: 12
Training loss: 0.25534549355506897
Validation loss: 1.4488144709217934

Epoch: 6| Step: 13
Training loss: 0.17413634061813354
Validation loss: 1.4576970120911956

Epoch: 320| Step: 0
Training loss: 0.24438002705574036
Validation loss: 1.4716213723664642

Epoch: 6| Step: 1
Training loss: 0.1887665092945099
Validation loss: 1.4560889838844218

Epoch: 6| Step: 2
Training loss: 0.2296123504638672
Validation loss: 1.4770566314779303

Epoch: 6| Step: 3
Training loss: 0.20141759514808655
Validation loss: 1.4572153129885275

Epoch: 6| Step: 4
Training loss: 0.27776098251342773
Validation loss: 1.4704580332643242

Epoch: 6| Step: 5
Training loss: 0.24991704523563385
Validation loss: 1.4657743720598118

Epoch: 6| Step: 6
Training loss: 0.3517615795135498
Validation loss: 1.4885957740968274

Epoch: 6| Step: 7
Training loss: 0.1671176552772522
Validation loss: 1.5064890897402199

Epoch: 6| Step: 8
Training loss: 0.21177899837493896
Validation loss: 1.5134039668626682

Epoch: 6| Step: 9
Training loss: 0.21387913823127747
Validation loss: 1.515941858291626

Epoch: 6| Step: 10
Training loss: 0.2796967327594757
Validation loss: 1.5154883092449558

Epoch: 6| Step: 11
Training loss: 0.16544747352600098
Validation loss: 1.5251167435799875

Epoch: 6| Step: 12
Training loss: 0.16233760118484497
Validation loss: 1.520854716659874

Epoch: 6| Step: 13
Training loss: 0.13117091357707977
Validation loss: 1.5155584491709226

Epoch: 321| Step: 0
Training loss: 0.12181314826011658
Validation loss: 1.5338954002626481

Epoch: 6| Step: 1
Training loss: 0.17841339111328125
Validation loss: 1.5369142076020599

Epoch: 6| Step: 2
Training loss: 0.1823703795671463
Validation loss: 1.5770099598874328

Epoch: 6| Step: 3
Training loss: 0.23017284274101257
Validation loss: 1.5728297499559258

Epoch: 6| Step: 4
Training loss: 0.25817936658859253
Validation loss: 1.5645666122436523

Epoch: 6| Step: 5
Training loss: 0.2566160559654236
Validation loss: 1.521451707809202

Epoch: 6| Step: 6
Training loss: 0.21213170886039734
Validation loss: 1.4922456600332772

Epoch: 6| Step: 7
Training loss: 0.1157541275024414
Validation loss: 1.4829969495855353

Epoch: 6| Step: 8
Training loss: 0.2682710886001587
Validation loss: 1.4893714958621609

Epoch: 6| Step: 9
Training loss: 0.2380862534046173
Validation loss: 1.5058720278483566

Epoch: 6| Step: 10
Training loss: 0.19625768065452576
Validation loss: 1.5185619733666862

Epoch: 6| Step: 11
Training loss: 0.17122924327850342
Validation loss: 1.4908051868920684

Epoch: 6| Step: 12
Training loss: 0.33358004689216614
Validation loss: 1.4923126505267235

Epoch: 6| Step: 13
Training loss: 0.561509370803833
Validation loss: 1.4794252739157727

Epoch: 322| Step: 0
Training loss: 0.32760655879974365
Validation loss: 1.5013240178426106

Epoch: 6| Step: 1
Training loss: 0.25655248761177063
Validation loss: 1.4896841600377073

Epoch: 6| Step: 2
Training loss: 0.31735479831695557
Validation loss: 1.4570994838591544

Epoch: 6| Step: 3
Training loss: 0.39603060483932495
Validation loss: 1.4961353758329987

Epoch: 6| Step: 4
Training loss: 0.1881544589996338
Validation loss: 1.480650346766236

Epoch: 6| Step: 5
Training loss: 0.22969140112400055
Validation loss: 1.527944121309506

Epoch: 6| Step: 6
Training loss: 0.2159782201051712
Validation loss: 1.521420209638534

Epoch: 6| Step: 7
Training loss: 0.1185944452881813
Validation loss: 1.4907707040027907

Epoch: 6| Step: 8
Training loss: 0.1961522251367569
Validation loss: 1.4912150572705012

Epoch: 6| Step: 9
Training loss: 0.10292377322912216
Validation loss: 1.472476625955233

Epoch: 6| Step: 10
Training loss: 0.13792391121387482
Validation loss: 1.4607292477802565

Epoch: 6| Step: 11
Training loss: 0.23283614218235016
Validation loss: 1.4690556372365644

Epoch: 6| Step: 12
Training loss: 0.19167906045913696
Validation loss: 1.4752547087207917

Epoch: 6| Step: 13
Training loss: 0.1664295792579651
Validation loss: 1.468587452365506

Epoch: 323| Step: 0
Training loss: 0.16448739171028137
Validation loss: 1.480496834683162

Epoch: 6| Step: 1
Training loss: 0.1351393461227417
Validation loss: 1.469435864879239

Epoch: 6| Step: 2
Training loss: 0.231540247797966
Validation loss: 1.4878175720091789

Epoch: 6| Step: 3
Training loss: 0.22822123765945435
Validation loss: 1.5148800624314176

Epoch: 6| Step: 4
Training loss: 0.17105995118618011
Validation loss: 1.5464045424615183

Epoch: 6| Step: 5
Training loss: 0.31125232577323914
Validation loss: 1.4927166213271439

Epoch: 6| Step: 6
Training loss: 0.32423847913742065
Validation loss: 1.51095792811404

Epoch: 6| Step: 7
Training loss: 0.08743990212678909
Validation loss: 1.487139182706033

Epoch: 6| Step: 8
Training loss: 0.12396656721830368
Validation loss: 1.4915116897193335

Epoch: 6| Step: 9
Training loss: 0.23415549099445343
Validation loss: 1.4557558631384244

Epoch: 6| Step: 10
Training loss: 0.1123022735118866
Validation loss: 1.4737434874298752

Epoch: 6| Step: 11
Training loss: 0.18680545687675476
Validation loss: 1.4600665415486982

Epoch: 6| Step: 12
Training loss: 0.21577751636505127
Validation loss: 1.4629797948304044

Epoch: 6| Step: 13
Training loss: 0.3539377748966217
Validation loss: 1.480616804092161

Epoch: 324| Step: 0
Training loss: 0.35751083493232727
Validation loss: 1.4670779179501277

Epoch: 6| Step: 1
Training loss: 0.1398133933544159
Validation loss: 1.5435946051792433

Epoch: 6| Step: 2
Training loss: 0.2354959398508072
Validation loss: 1.537355387082664

Epoch: 6| Step: 3
Training loss: 0.24475717544555664
Validation loss: 1.571717587850427

Epoch: 6| Step: 4
Training loss: 0.20909187197685242
Validation loss: 1.5403129657109578

Epoch: 6| Step: 5
Training loss: 0.20188410580158234
Validation loss: 1.5429274484675417

Epoch: 6| Step: 6
Training loss: 0.19072608649730682
Validation loss: 1.5048522372399606

Epoch: 6| Step: 7
Training loss: 0.19699370861053467
Validation loss: 1.5215038945597987

Epoch: 6| Step: 8
Training loss: 0.20427756011486053
Validation loss: 1.5345686289571947

Epoch: 6| Step: 9
Training loss: 0.2309798002243042
Validation loss: 1.5078192616021762

Epoch: 6| Step: 10
Training loss: 0.16988882422447205
Validation loss: 1.509731718288955

Epoch: 6| Step: 11
Training loss: 0.14474216103553772
Validation loss: 1.546390530883625

Epoch: 6| Step: 12
Training loss: 0.11759577691555023
Validation loss: 1.508016941367939

Epoch: 6| Step: 13
Training loss: 0.27969273924827576
Validation loss: 1.5310936666304065

Epoch: 325| Step: 0
Training loss: 0.3028596043586731
Validation loss: 1.54420893807565

Epoch: 6| Step: 1
Training loss: 0.23689332604408264
Validation loss: 1.544257088374066

Epoch: 6| Step: 2
Training loss: 0.31976422667503357
Validation loss: 1.5468768426167068

Epoch: 6| Step: 3
Training loss: 0.24715612828731537
Validation loss: 1.5086168832676385

Epoch: 6| Step: 4
Training loss: 0.23088636994361877
Validation loss: 1.5105257495757072

Epoch: 6| Step: 5
Training loss: 0.14127473533153534
Validation loss: 1.5157632174030427

Epoch: 6| Step: 6
Training loss: 0.23019559681415558
Validation loss: 1.5043563253136092

Epoch: 6| Step: 7
Training loss: 0.338451623916626
Validation loss: 1.4733011389291415

Epoch: 6| Step: 8
Training loss: 0.19205322861671448
Validation loss: 1.4638641867586362

Epoch: 6| Step: 9
Training loss: 0.19925472140312195
Validation loss: 1.491313785635015

Epoch: 6| Step: 10
Training loss: 0.17835025489330292
Validation loss: 1.4988552613924908

Epoch: 6| Step: 11
Training loss: 0.20150655508041382
Validation loss: 1.4906531162159418

Epoch: 6| Step: 12
Training loss: 0.2200043648481369
Validation loss: 1.5151203601591048

Epoch: 6| Step: 13
Training loss: 0.12356506288051605
Validation loss: 1.5132048770945559

Epoch: 326| Step: 0
Training loss: 0.18612578511238098
Validation loss: 1.4912566420852498

Epoch: 6| Step: 1
Training loss: 0.1524965465068817
Validation loss: 1.506945780528489

Epoch: 6| Step: 2
Training loss: 0.21561722457408905
Validation loss: 1.5022516160882928

Epoch: 6| Step: 3
Training loss: 0.21032488346099854
Validation loss: 1.5172220045520413

Epoch: 6| Step: 4
Training loss: 0.2647247612476349
Validation loss: 1.5267731963947255

Epoch: 6| Step: 5
Training loss: 0.2555379271507263
Validation loss: 1.4920206698038245

Epoch: 6| Step: 6
Training loss: 0.22970889508724213
Validation loss: 1.490142301846576

Epoch: 6| Step: 7
Training loss: 0.15963880717754364
Validation loss: 1.491333225721954

Epoch: 6| Step: 8
Training loss: 0.17706626653671265
Validation loss: 1.5004514135340208

Epoch: 6| Step: 9
Training loss: 0.14640012383460999
Validation loss: 1.517295233664974

Epoch: 6| Step: 10
Training loss: 0.29752132296562195
Validation loss: 1.4833275130999986

Epoch: 6| Step: 11
Training loss: 0.1341654509305954
Validation loss: 1.4971457988985124

Epoch: 6| Step: 12
Training loss: 0.13053813576698303
Validation loss: 1.5165890057881672

Epoch: 6| Step: 13
Training loss: 0.37223005294799805
Validation loss: 1.5127009999367498

Epoch: 327| Step: 0
Training loss: 0.23084348440170288
Validation loss: 1.5057808006963422

Epoch: 6| Step: 1
Training loss: 0.17688220739364624
Validation loss: 1.5325737025148125

Epoch: 6| Step: 2
Training loss: 0.22328872978687286
Validation loss: 1.5409078264749179

Epoch: 6| Step: 3
Training loss: 0.3328080475330353
Validation loss: 1.512428936137948

Epoch: 6| Step: 4
Training loss: 0.12737056612968445
Validation loss: 1.4933625805762507

Epoch: 6| Step: 5
Training loss: 0.16991478204727173
Validation loss: 1.4957286055370043

Epoch: 6| Step: 6
Training loss: 0.18142029643058777
Validation loss: 1.4649070770509782

Epoch: 6| Step: 7
Training loss: 0.17488762736320496
Validation loss: 1.4830069823931622

Epoch: 6| Step: 8
Training loss: 0.2296598106622696
Validation loss: 1.5000986822189823

Epoch: 6| Step: 9
Training loss: 0.16516679525375366
Validation loss: 1.467094091958897

Epoch: 6| Step: 10
Training loss: 0.1674959510564804
Validation loss: 1.5197686469683083

Epoch: 6| Step: 11
Training loss: 0.15000411868095398
Validation loss: 1.5041130614537064

Epoch: 6| Step: 12
Training loss: 0.17518296837806702
Validation loss: 1.523283189342868

Epoch: 6| Step: 13
Training loss: 0.3152788579463959
Validation loss: 1.508693391276944

Epoch: 328| Step: 0
Training loss: 0.1625988483428955
Validation loss: 1.4894484499449372

Epoch: 6| Step: 1
Training loss: 0.16006654500961304
Validation loss: 1.4949115245572981

Epoch: 6| Step: 2
Training loss: 0.14423714578151703
Validation loss: 1.4889559617606543

Epoch: 6| Step: 3
Training loss: 0.303774893283844
Validation loss: 1.47820540653762

Epoch: 6| Step: 4
Training loss: 0.13539279997348785
Validation loss: 1.5253892470431585

Epoch: 6| Step: 5
Training loss: 0.2846236824989319
Validation loss: 1.5363389856071883

Epoch: 6| Step: 6
Training loss: 0.2939985394477844
Validation loss: 1.598814300311509

Epoch: 6| Step: 7
Training loss: 0.22920212149620056
Validation loss: 1.6077713908687714

Epoch: 6| Step: 8
Training loss: 0.2564239501953125
Validation loss: 1.6056991341293498

Epoch: 6| Step: 9
Training loss: 0.23555105924606323
Validation loss: 1.5595052203824442

Epoch: 6| Step: 10
Training loss: 0.27628645300865173
Validation loss: 1.5068006271957068

Epoch: 6| Step: 11
Training loss: 0.16127285361289978
Validation loss: 1.5093340860900057

Epoch: 6| Step: 12
Training loss: 0.16243737936019897
Validation loss: 1.518786467531676

Epoch: 6| Step: 13
Training loss: 0.1584736704826355
Validation loss: 1.4773673267774685

Epoch: 329| Step: 0
Training loss: 0.18113809823989868
Validation loss: 1.523605013406405

Epoch: 6| Step: 1
Training loss: 0.23752689361572266
Validation loss: 1.5278233039763667

Epoch: 6| Step: 2
Training loss: 0.13908901810646057
Validation loss: 1.5478783948447115

Epoch: 6| Step: 3
Training loss: 0.18918344378471375
Validation loss: 1.5336096312410088

Epoch: 6| Step: 4
Training loss: 0.1936958134174347
Validation loss: 1.5521872607610558

Epoch: 6| Step: 5
Training loss: 0.24674144387245178
Validation loss: 1.5204503882315852

Epoch: 6| Step: 6
Training loss: 0.20598813891410828
Validation loss: 1.5485009544639177

Epoch: 6| Step: 7
Training loss: 0.2225182056427002
Validation loss: 1.5246140597968973

Epoch: 6| Step: 8
Training loss: 0.3068242371082306
Validation loss: 1.545491494158263

Epoch: 6| Step: 9
Training loss: 0.14591333270072937
Validation loss: 1.5456679738977903

Epoch: 6| Step: 10
Training loss: 0.164611354470253
Validation loss: 1.5287140107923938

Epoch: 6| Step: 11
Training loss: 0.14174723625183105
Validation loss: 1.5364708669724003

Epoch: 6| Step: 12
Training loss: 0.20320086181163788
Validation loss: 1.5387638820114957

Epoch: 6| Step: 13
Training loss: 0.18797343969345093
Validation loss: 1.5370407348038049

Epoch: 330| Step: 0
Training loss: 0.3004952073097229
Validation loss: 1.50312755825699

Epoch: 6| Step: 1
Training loss: 0.10684682428836823
Validation loss: 1.53567030865659

Epoch: 6| Step: 2
Training loss: 0.18952658772468567
Validation loss: 1.540503268600792

Epoch: 6| Step: 3
Training loss: 0.2904762327671051
Validation loss: 1.5035925526772775

Epoch: 6| Step: 4
Training loss: 0.1363867223262787
Validation loss: 1.5736081472007177

Epoch: 6| Step: 5
Training loss: 0.1227152943611145
Validation loss: 1.55317521608004

Epoch: 6| Step: 6
Training loss: 0.16505491733551025
Validation loss: 1.5525363568336732

Epoch: 6| Step: 7
Training loss: 0.2514028549194336
Validation loss: 1.5171438724763933

Epoch: 6| Step: 8
Training loss: 0.2596474885940552
Validation loss: 1.552685219754455

Epoch: 6| Step: 9
Training loss: 0.13888049125671387
Validation loss: 1.559290365506244

Epoch: 6| Step: 10
Training loss: 0.23842161893844604
Validation loss: 1.5468299363249092

Epoch: 6| Step: 11
Training loss: 0.24629035592079163
Validation loss: 1.5195811076830792

Epoch: 6| Step: 12
Training loss: 0.1456029862165451
Validation loss: 1.5026561124350435

Epoch: 6| Step: 13
Training loss: 0.1101628914475441
Validation loss: 1.5019965940906155

Epoch: 331| Step: 0
Training loss: 0.18625962734222412
Validation loss: 1.490233290580011

Epoch: 6| Step: 1
Training loss: 0.21404078602790833
Validation loss: 1.50768522549701

Epoch: 6| Step: 2
Training loss: 0.1395571231842041
Validation loss: 1.5184955148286716

Epoch: 6| Step: 3
Training loss: 0.2034825086593628
Validation loss: 1.5735987719669138

Epoch: 6| Step: 4
Training loss: 0.296385794878006
Validation loss: 1.572691571327948

Epoch: 6| Step: 5
Training loss: 0.24811141192913055
Validation loss: 1.5379479219836574

Epoch: 6| Step: 6
Training loss: 0.23527471721172333
Validation loss: 1.5217424669573385

Epoch: 6| Step: 7
Training loss: 0.14149591326713562
Validation loss: 1.5165771579229703

Epoch: 6| Step: 8
Training loss: 0.21914130449295044
Validation loss: 1.5407854292982368

Epoch: 6| Step: 9
Training loss: 0.3985034227371216
Validation loss: 1.5465514711154404

Epoch: 6| Step: 10
Training loss: 0.272550493478775
Validation loss: 1.5577689191346527

Epoch: 6| Step: 11
Training loss: 0.1892727017402649
Validation loss: 1.5222651497010262

Epoch: 6| Step: 12
Training loss: 0.19113901257514954
Validation loss: 1.5038753824849282

Epoch: 6| Step: 13
Training loss: 0.09382862597703934
Validation loss: 1.5242872750887306

Epoch: 332| Step: 0
Training loss: 0.17685040831565857
Validation loss: 1.519156321402519

Epoch: 6| Step: 1
Training loss: 0.20356351137161255
Validation loss: 1.5394071750743414

Epoch: 6| Step: 2
Training loss: 0.21437117457389832
Validation loss: 1.5641407902522753

Epoch: 6| Step: 3
Training loss: 0.26671573519706726
Validation loss: 1.5704067407115814

Epoch: 6| Step: 4
Training loss: 0.23878583312034607
Validation loss: 1.5580398741588797

Epoch: 6| Step: 5
Training loss: 0.3356463313102722
Validation loss: 1.5197021192119968

Epoch: 6| Step: 6
Training loss: 0.14420868456363678
Validation loss: 1.5118276867815243

Epoch: 6| Step: 7
Training loss: 0.18286746740341187
Validation loss: 1.5092086202354842

Epoch: 6| Step: 8
Training loss: 0.1919892132282257
Validation loss: 1.5009592393393159

Epoch: 6| Step: 9
Training loss: 0.17070026695728302
Validation loss: 1.5089422682280182

Epoch: 6| Step: 10
Training loss: 0.28847965598106384
Validation loss: 1.5223327208590764

Epoch: 6| Step: 11
Training loss: 0.16782759130001068
Validation loss: 1.5240496384200228

Epoch: 6| Step: 12
Training loss: 0.21113353967666626
Validation loss: 1.51545867612285

Epoch: 6| Step: 13
Training loss: 0.15210352838039398
Validation loss: 1.5102684138923563

Epoch: 333| Step: 0
Training loss: 0.35011357069015503
Validation loss: 1.547385113213652

Epoch: 6| Step: 1
Training loss: 0.3301323652267456
Validation loss: 1.5630212009594004

Epoch: 6| Step: 2
Training loss: 0.16883353888988495
Validation loss: 1.5420500219509166

Epoch: 6| Step: 3
Training loss: 0.29255497455596924
Validation loss: 1.5305623751814648

Epoch: 6| Step: 4
Training loss: 0.2176293581724167
Validation loss: 1.5117065868070048

Epoch: 6| Step: 5
Training loss: 0.16613882780075073
Validation loss: 1.4822989625315512

Epoch: 6| Step: 6
Training loss: 0.1927722543478012
Validation loss: 1.4760207130062966

Epoch: 6| Step: 7
Training loss: 0.39263564348220825
Validation loss: 1.4895944121063396

Epoch: 6| Step: 8
Training loss: 0.28911280632019043
Validation loss: 1.4862837810670175

Epoch: 6| Step: 9
Training loss: 0.129515141248703
Validation loss: 1.470433513323466

Epoch: 6| Step: 10
Training loss: 0.27030178904533386
Validation loss: 1.4806690690337971

Epoch: 6| Step: 11
Training loss: 0.1749649941921234
Validation loss: 1.49707959031546

Epoch: 6| Step: 12
Training loss: 0.12619523704051971
Validation loss: 1.541383066485005

Epoch: 6| Step: 13
Training loss: 0.11516842246055603
Validation loss: 1.5534054515182332

Epoch: 334| Step: 0
Training loss: 0.12014328688383102
Validation loss: 1.5809583638304023

Epoch: 6| Step: 1
Training loss: 0.2845812141895294
Validation loss: 1.5790104968573457

Epoch: 6| Step: 2
Training loss: 0.17178097367286682
Validation loss: 1.5721485640413018

Epoch: 6| Step: 3
Training loss: 0.2276545614004135
Validation loss: 1.5685269986429522

Epoch: 6| Step: 4
Training loss: 0.12235976755619049
Validation loss: 1.5530875754612747

Epoch: 6| Step: 5
Training loss: 0.11914199590682983
Validation loss: 1.5493262916482904

Epoch: 6| Step: 6
Training loss: 0.30716246366500854
Validation loss: 1.5069816561155422

Epoch: 6| Step: 7
Training loss: 0.19344943761825562
Validation loss: 1.5309870960891887

Epoch: 6| Step: 8
Training loss: 0.12863695621490479
Validation loss: 1.5164407555774977

Epoch: 6| Step: 9
Training loss: 0.16938768327236176
Validation loss: 1.5028787223241662

Epoch: 6| Step: 10
Training loss: 0.2641345262527466
Validation loss: 1.500271495952401

Epoch: 6| Step: 11
Training loss: 0.17275193333625793
Validation loss: 1.525676364539772

Epoch: 6| Step: 12
Training loss: 0.3397369384765625
Validation loss: 1.5342694841405398

Epoch: 6| Step: 13
Training loss: 0.18084368109703064
Validation loss: 1.4946306226074055

Epoch: 335| Step: 0
Training loss: 0.10954231768846512
Validation loss: 1.4730875030640633

Epoch: 6| Step: 1
Training loss: 0.12817645072937012
Validation loss: 1.459235619473201

Epoch: 6| Step: 2
Training loss: 0.23912903666496277
Validation loss: 1.4713675322071198

Epoch: 6| Step: 3
Training loss: 0.19113461673259735
Validation loss: 1.5012741755413752

Epoch: 6| Step: 4
Training loss: 0.20915497839450836
Validation loss: 1.4983948494798394

Epoch: 6| Step: 5
Training loss: 0.2138708233833313
Validation loss: 1.5162342722697923

Epoch: 6| Step: 6
Training loss: 0.15815097093582153
Validation loss: 1.5406866419699885

Epoch: 6| Step: 7
Training loss: 0.18526536226272583
Validation loss: 1.5750125185135873

Epoch: 6| Step: 8
Training loss: 0.3812524974346161
Validation loss: 1.5622007872468682

Epoch: 6| Step: 9
Training loss: 0.1335122287273407
Validation loss: 1.5747140402434974

Epoch: 6| Step: 10
Training loss: 0.20530708134174347
Validation loss: 1.5615686614026305

Epoch: 6| Step: 11
Training loss: 0.2965618669986725
Validation loss: 1.529318114762665

Epoch: 6| Step: 12
Training loss: 0.2218523919582367
Validation loss: 1.492511176293896

Epoch: 6| Step: 13
Training loss: 0.09938061982393265
Validation loss: 1.517734287887491

Epoch: 336| Step: 0
Training loss: 0.20614975690841675
Validation loss: 1.498780527422505

Epoch: 6| Step: 1
Training loss: 0.23541772365570068
Validation loss: 1.508177476544534

Epoch: 6| Step: 2
Training loss: 0.21514585614204407
Validation loss: 1.5004869558477913

Epoch: 6| Step: 3
Training loss: 0.12798868119716644
Validation loss: 1.486206667397612

Epoch: 6| Step: 4
Training loss: 0.2251192182302475
Validation loss: 1.512693448733258

Epoch: 6| Step: 5
Training loss: 0.2687366008758545
Validation loss: 1.5271764237393615

Epoch: 6| Step: 6
Training loss: 0.1720239818096161
Validation loss: 1.5322528539165374

Epoch: 6| Step: 7
Training loss: 0.27711278200149536
Validation loss: 1.5328762069825204

Epoch: 6| Step: 8
Training loss: 0.2152099609375
Validation loss: 1.5353997522784817

Epoch: 6| Step: 9
Training loss: 0.15928959846496582
Validation loss: 1.5183526162178285

Epoch: 6| Step: 10
Training loss: 0.29008224606513977
Validation loss: 1.5265336344319005

Epoch: 6| Step: 11
Training loss: 0.1592370867729187
Validation loss: 1.4902716605894026

Epoch: 6| Step: 12
Training loss: 0.12819769978523254
Validation loss: 1.5202851615926272

Epoch: 6| Step: 13
Training loss: 0.07414491474628448
Validation loss: 1.504461347415883

Epoch: 337| Step: 0
Training loss: 0.13159456849098206
Validation loss: 1.4957255740319528

Epoch: 6| Step: 1
Training loss: 0.17542177438735962
Validation loss: 1.5166444214441444

Epoch: 6| Step: 2
Training loss: 0.1755274087190628
Validation loss: 1.4916904075171358

Epoch: 6| Step: 3
Training loss: 0.1498318910598755
Validation loss: 1.4933018094749861

Epoch: 6| Step: 4
Training loss: 0.19931256771087646
Validation loss: 1.5204263835824945

Epoch: 6| Step: 5
Training loss: 0.17548400163650513
Validation loss: 1.52384308333038

Epoch: 6| Step: 6
Training loss: 0.2283054143190384
Validation loss: 1.5597439978712349

Epoch: 6| Step: 7
Training loss: 0.29998159408569336
Validation loss: 1.5876527704218382

Epoch: 6| Step: 8
Training loss: 0.19651135802268982
Validation loss: 1.566776023116163

Epoch: 6| Step: 9
Training loss: 0.2355346381664276
Validation loss: 1.555871598182186

Epoch: 6| Step: 10
Training loss: 0.23019030690193176
Validation loss: 1.5452265047257947

Epoch: 6| Step: 11
Training loss: 0.19152240455150604
Validation loss: 1.5359290517786497

Epoch: 6| Step: 12
Training loss: 0.25959861278533936
Validation loss: 1.5473485057071974

Epoch: 6| Step: 13
Training loss: 0.11865666508674622
Validation loss: 1.5699794664177844

Epoch: 338| Step: 0
Training loss: 0.20272818207740784
Validation loss: 1.5502852803917342

Epoch: 6| Step: 1
Training loss: 0.1885092556476593
Validation loss: 1.5385157908162763

Epoch: 6| Step: 2
Training loss: 0.2165592908859253
Validation loss: 1.5187767244154406

Epoch: 6| Step: 3
Training loss: 0.1614643782377243
Validation loss: 1.5083180332696566

Epoch: 6| Step: 4
Training loss: 0.12354467064142227
Validation loss: 1.4964986026927989

Epoch: 6| Step: 5
Training loss: 0.18715348839759827
Validation loss: 1.5031208261366813

Epoch: 6| Step: 6
Training loss: 0.2341393530368805
Validation loss: 1.5076049297086653

Epoch: 6| Step: 7
Training loss: 0.13301116228103638
Validation loss: 1.5262790213349045

Epoch: 6| Step: 8
Training loss: 0.3050898313522339
Validation loss: 1.515046178653676

Epoch: 6| Step: 9
Training loss: 0.2343333214521408
Validation loss: 1.5587685159457627

Epoch: 6| Step: 10
Training loss: 0.12645727396011353
Validation loss: 1.5577889398861957

Epoch: 6| Step: 11
Training loss: 0.1699628382921219
Validation loss: 1.5957254504644742

Epoch: 6| Step: 12
Training loss: 0.2729473114013672
Validation loss: 1.6025564760290167

Epoch: 6| Step: 13
Training loss: 0.376643568277359
Validation loss: 1.5751148885296238

Epoch: 339| Step: 0
Training loss: 0.19753700494766235
Validation loss: 1.5601866309360792

Epoch: 6| Step: 1
Training loss: 0.1823136806488037
Validation loss: 1.514305216650809

Epoch: 6| Step: 2
Training loss: 0.21982228755950928
Validation loss: 1.493684567430968

Epoch: 6| Step: 3
Training loss: 0.1570090502500534
Validation loss: 1.4852738406068535

Epoch: 6| Step: 4
Training loss: 0.17444753646850586
Validation loss: 1.4854606377181185

Epoch: 6| Step: 5
Training loss: 0.15728431940078735
Validation loss: 1.5142836878376622

Epoch: 6| Step: 6
Training loss: 0.23784920573234558
Validation loss: 1.4774104497765983

Epoch: 6| Step: 7
Training loss: 0.14626967906951904
Validation loss: 1.5044554843697497

Epoch: 6| Step: 8
Training loss: 0.21453312039375305
Validation loss: 1.4623503672179354

Epoch: 6| Step: 9
Training loss: 0.12728750705718994
Validation loss: 1.483962094911965

Epoch: 6| Step: 10
Training loss: 0.16988897323608398
Validation loss: 1.485567795333042

Epoch: 6| Step: 11
Training loss: 0.19642801582813263
Validation loss: 1.499352003297498

Epoch: 6| Step: 12
Training loss: 0.10595862567424774
Validation loss: 1.5481339962251726

Epoch: 6| Step: 13
Training loss: 0.27608877420425415
Validation loss: 1.5559221832982955

Epoch: 340| Step: 0
Training loss: 0.2787262797355652
Validation loss: 1.5391379915257937

Epoch: 6| Step: 1
Training loss: 0.23619277775287628
Validation loss: 1.549330266573096

Epoch: 6| Step: 2
Training loss: 0.1064653992652893
Validation loss: 1.4999127875092209

Epoch: 6| Step: 3
Training loss: 0.20190297067165375
Validation loss: 1.505314286037158

Epoch: 6| Step: 4
Training loss: 0.13285280764102936
Validation loss: 1.513879838169262

Epoch: 6| Step: 5
Training loss: 0.4070971608161926
Validation loss: 1.5274282693862915

Epoch: 6| Step: 6
Training loss: 0.1931547373533249
Validation loss: 1.5274117146768877

Epoch: 6| Step: 7
Training loss: 0.221073180437088
Validation loss: 1.5254444640169862

Epoch: 6| Step: 8
Training loss: 0.2376386821269989
Validation loss: 1.5090787961918821

Epoch: 6| Step: 9
Training loss: 0.278903603553772
Validation loss: 1.5083001390580209

Epoch: 6| Step: 10
Training loss: 0.17629584670066833
Validation loss: 1.5043490638015091

Epoch: 6| Step: 11
Training loss: 0.20580437779426575
Validation loss: 1.5064661156746648

Epoch: 6| Step: 12
Training loss: 0.2225458323955536
Validation loss: 1.5040226008302422

Epoch: 6| Step: 13
Training loss: 0.11701700091362
Validation loss: 1.4800650330000027

Epoch: 341| Step: 0
Training loss: 0.24972617626190186
Validation loss: 1.4932876261331702

Epoch: 6| Step: 1
Training loss: 0.1602475494146347
Validation loss: 1.4909157445353847

Epoch: 6| Step: 2
Training loss: 0.30099165439605713
Validation loss: 1.4873564063861806

Epoch: 6| Step: 3
Training loss: 0.1964721828699112
Validation loss: 1.4791865579543575

Epoch: 6| Step: 4
Training loss: 0.1195966973900795
Validation loss: 1.516481541818188

Epoch: 6| Step: 5
Training loss: 0.14840054512023926
Validation loss: 1.5208168632240706

Epoch: 6| Step: 6
Training loss: 0.06346035748720169
Validation loss: 1.5416100653268958

Epoch: 6| Step: 7
Training loss: 0.223393514752388
Validation loss: 1.5422807534535725

Epoch: 6| Step: 8
Training loss: 0.10596062242984772
Validation loss: 1.545055284295031

Epoch: 6| Step: 9
Training loss: 0.17210325598716736
Validation loss: 1.543494286075715

Epoch: 6| Step: 10
Training loss: 0.14422789216041565
Validation loss: 1.4992890563062442

Epoch: 6| Step: 11
Training loss: 0.22171875834465027
Validation loss: 1.4887025266565301

Epoch: 6| Step: 12
Training loss: 0.264434814453125
Validation loss: 1.463120383601035

Epoch: 6| Step: 13
Training loss: 0.18148410320281982
Validation loss: 1.4524340834668887

Epoch: 342| Step: 0
Training loss: 0.16638192534446716
Validation loss: 1.4616861715111682

Epoch: 6| Step: 1
Training loss: 0.19163820147514343
Validation loss: 1.463529388109843

Epoch: 6| Step: 2
Training loss: 0.14324016869068146
Validation loss: 1.467532257879934

Epoch: 6| Step: 3
Training loss: 0.28279849886894226
Validation loss: 1.503988109609132

Epoch: 6| Step: 4
Training loss: 0.18851988017559052
Validation loss: 1.512160861363975

Epoch: 6| Step: 5
Training loss: 0.1607004702091217
Validation loss: 1.5067210466630998

Epoch: 6| Step: 6
Training loss: 0.1774400770664215
Validation loss: 1.4975614855366368

Epoch: 6| Step: 7
Training loss: 0.16405168175697327
Validation loss: 1.5055196874885148

Epoch: 6| Step: 8
Training loss: 0.15230682492256165
Validation loss: 1.5068122071604575

Epoch: 6| Step: 9
Training loss: 0.32590949535369873
Validation loss: 1.4771704776312715

Epoch: 6| Step: 10
Training loss: 0.34169504046440125
Validation loss: 1.4768495534055976

Epoch: 6| Step: 11
Training loss: 0.10555953532457352
Validation loss: 1.4840901449162474

Epoch: 6| Step: 12
Training loss: 0.13712157309055328
Validation loss: 1.4966366342318955

Epoch: 6| Step: 13
Training loss: 0.17686429619789124
Validation loss: 1.507198522167821

Epoch: 343| Step: 0
Training loss: 0.15125873684883118
Validation loss: 1.5290374243131248

Epoch: 6| Step: 1
Training loss: 0.16309979557991028
Validation loss: 1.5448721166579955

Epoch: 6| Step: 2
Training loss: 0.20662984251976013
Validation loss: 1.557114129425377

Epoch: 6| Step: 3
Training loss: 0.17908957600593567
Validation loss: 1.5402809048211703

Epoch: 6| Step: 4
Training loss: 0.22903428971767426
Validation loss: 1.5672534947754235

Epoch: 6| Step: 5
Training loss: 0.0795157253742218
Validation loss: 1.557530906892592

Epoch: 6| Step: 6
Training loss: 0.1220349594950676
Validation loss: 1.5265749821098902

Epoch: 6| Step: 7
Training loss: 0.19354912638664246
Validation loss: 1.5280855317269602

Epoch: 6| Step: 8
Training loss: 0.17848306894302368
Validation loss: 1.497313722487419

Epoch: 6| Step: 9
Training loss: 0.1591038703918457
Validation loss: 1.5009567763215752

Epoch: 6| Step: 10
Training loss: 0.1299116015434265
Validation loss: 1.5014293847545501

Epoch: 6| Step: 11
Training loss: 0.15803563594818115
Validation loss: 1.4890102019873999

Epoch: 6| Step: 12
Training loss: 0.2158626914024353
Validation loss: 1.5186366791366248

Epoch: 6| Step: 13
Training loss: 0.22873276472091675
Validation loss: 1.5308072618258897

Epoch: 344| Step: 0
Training loss: 0.3148241341114044
Validation loss: 1.5497751966599496

Epoch: 6| Step: 1
Training loss: 0.1875535547733307
Validation loss: 1.54292691651211

Epoch: 6| Step: 2
Training loss: 0.09222729504108429
Validation loss: 1.5057815479975876

Epoch: 6| Step: 3
Training loss: 0.14079827070236206
Validation loss: 1.507900635401408

Epoch: 6| Step: 4
Training loss: 0.1372944712638855
Validation loss: 1.506188226643429

Epoch: 6| Step: 5
Training loss: 0.19529518485069275
Validation loss: 1.5259603274765836

Epoch: 6| Step: 6
Training loss: 0.2667329013347626
Validation loss: 1.5122206159817275

Epoch: 6| Step: 7
Training loss: 0.18285532295703888
Validation loss: 1.505772017663525

Epoch: 6| Step: 8
Training loss: 0.2689015567302704
Validation loss: 1.505932584885628

Epoch: 6| Step: 9
Training loss: 0.23256784677505493
Validation loss: 1.5008433262507122

Epoch: 6| Step: 10
Training loss: 0.158204585313797
Validation loss: 1.527829788064444

Epoch: 6| Step: 11
Training loss: 0.26557987928390503
Validation loss: 1.5294084228495115

Epoch: 6| Step: 12
Training loss: 0.1579592078924179
Validation loss: 1.5243526492067563

Epoch: 6| Step: 13
Training loss: 0.1848486214876175
Validation loss: 1.555586843080418

Epoch: 345| Step: 0
Training loss: 0.2054252028465271
Validation loss: 1.5711220964308708

Epoch: 6| Step: 1
Training loss: 0.14577898383140564
Validation loss: 1.543212947025094

Epoch: 6| Step: 2
Training loss: 0.3194601237773895
Validation loss: 1.5541070904783023

Epoch: 6| Step: 3
Training loss: 0.2019144594669342
Validation loss: 1.552580081006532

Epoch: 6| Step: 4
Training loss: 0.2027902901172638
Validation loss: 1.547990615970345

Epoch: 6| Step: 5
Training loss: 0.2642165720462799
Validation loss: 1.5352660712375437

Epoch: 6| Step: 6
Training loss: 0.10700348019599915
Validation loss: 1.536532941684928

Epoch: 6| Step: 7
Training loss: 0.11411404609680176
Validation loss: 1.4899465845477196

Epoch: 6| Step: 8
Training loss: 0.2346315085887909
Validation loss: 1.51678499098747

Epoch: 6| Step: 9
Training loss: 0.10493047535419464
Validation loss: 1.5194967997971403

Epoch: 6| Step: 10
Training loss: 0.19054433703422546
Validation loss: 1.5062038001193796

Epoch: 6| Step: 11
Training loss: 0.12261788547039032
Validation loss: 1.5046254050347112

Epoch: 6| Step: 12
Training loss: 0.16346639394760132
Validation loss: 1.5176697533617738

Epoch: 6| Step: 13
Training loss: 0.14842694997787476
Validation loss: 1.5096635267298708

Epoch: 346| Step: 0
Training loss: 0.09617757052183151
Validation loss: 1.537501186452886

Epoch: 6| Step: 1
Training loss: 0.1939506232738495
Validation loss: 1.5351376520690097

Epoch: 6| Step: 2
Training loss: 0.1797465682029724
Validation loss: 1.549994639171067

Epoch: 6| Step: 3
Training loss: 0.38295501470565796
Validation loss: 1.5188031914413616

Epoch: 6| Step: 4
Training loss: 0.16006837785243988
Validation loss: 1.5360626584740096

Epoch: 6| Step: 5
Training loss: 0.1904694139957428
Validation loss: 1.490237271913918

Epoch: 6| Step: 6
Training loss: 0.14234377443790436
Validation loss: 1.4950558100977251

Epoch: 6| Step: 7
Training loss: 0.09541688859462738
Validation loss: 1.4881182793648011

Epoch: 6| Step: 8
Training loss: 0.21592077612876892
Validation loss: 1.4645504919431542

Epoch: 6| Step: 9
Training loss: 0.18622350692749023
Validation loss: 1.4858111361021638

Epoch: 6| Step: 10
Training loss: 0.16385160386562347
Validation loss: 1.5062386502501786

Epoch: 6| Step: 11
Training loss: 0.19758392870426178
Validation loss: 1.4723065437809113

Epoch: 6| Step: 12
Training loss: 0.1709194779396057
Validation loss: 1.5032038970660138

Epoch: 6| Step: 13
Training loss: 0.2155183106660843
Validation loss: 1.4854968062011145

Epoch: 347| Step: 0
Training loss: 0.11255823820829391
Validation loss: 1.482255990787219

Epoch: 6| Step: 1
Training loss: 0.16855943202972412
Validation loss: 1.472730121304912

Epoch: 6| Step: 2
Training loss: 0.1945735514163971
Validation loss: 1.4610755661482453

Epoch: 6| Step: 3
Training loss: 0.11034934222698212
Validation loss: 1.4376211922655824

Epoch: 6| Step: 4
Training loss: 0.2379092574119568
Validation loss: 1.4576577678803475

Epoch: 6| Step: 5
Training loss: 0.21087448298931122
Validation loss: 1.458927191713805

Epoch: 6| Step: 6
Training loss: 0.15198153257369995
Validation loss: 1.4594119133487824

Epoch: 6| Step: 7
Training loss: 0.18719670176506042
Validation loss: 1.4704617095249954

Epoch: 6| Step: 8
Training loss: 0.20555388927459717
Validation loss: 1.491438929752637

Epoch: 6| Step: 9
Training loss: 0.11885682493448257
Validation loss: 1.5140534165085002

Epoch: 6| Step: 10
Training loss: 0.14454105496406555
Validation loss: 1.5062551383049256

Epoch: 6| Step: 11
Training loss: 0.1798068732023239
Validation loss: 1.5033075283932429

Epoch: 6| Step: 12
Training loss: 0.12428662180900574
Validation loss: 1.503406036284662

Epoch: 6| Step: 13
Training loss: 0.2584473192691803
Validation loss: 1.504610252636735

Epoch: 348| Step: 0
Training loss: 0.10512987524271011
Validation loss: 1.4980615005698255

Epoch: 6| Step: 1
Training loss: 0.20413906872272491
Validation loss: 1.47961002139635

Epoch: 6| Step: 2
Training loss: 0.2149500995874405
Validation loss: 1.4924543455082884

Epoch: 6| Step: 3
Training loss: 0.14719577133655548
Validation loss: 1.4878173406406114

Epoch: 6| Step: 4
Training loss: 0.13028600811958313
Validation loss: 1.5092926422754924

Epoch: 6| Step: 5
Training loss: 0.14529237151145935
Validation loss: 1.4833330326182868

Epoch: 6| Step: 6
Training loss: 0.20443736016750336
Validation loss: 1.5306866521476417

Epoch: 6| Step: 7
Training loss: 0.11200838536024094
Validation loss: 1.5148017368009012

Epoch: 6| Step: 8
Training loss: 0.259890079498291
Validation loss: 1.5111229112071376

Epoch: 6| Step: 9
Training loss: 0.193444162607193
Validation loss: 1.5090636181574997

Epoch: 6| Step: 10
Training loss: 0.19314861297607422
Validation loss: 1.510835047691099

Epoch: 6| Step: 11
Training loss: 0.10559087991714478
Validation loss: 1.5000184530852942

Epoch: 6| Step: 12
Training loss: 0.22776079177856445
Validation loss: 1.5139508144829863

Epoch: 6| Step: 13
Training loss: 0.05852821096777916
Validation loss: 1.5051824559447586

Epoch: 349| Step: 0
Training loss: 0.1321040838956833
Validation loss: 1.4915264703894173

Epoch: 6| Step: 1
Training loss: 0.14788436889648438
Validation loss: 1.4946303367614746

Epoch: 6| Step: 2
Training loss: 0.14593346416950226
Validation loss: 1.490136154236332

Epoch: 6| Step: 3
Training loss: 0.3144068121910095
Validation loss: 1.5110622721333657

Epoch: 6| Step: 4
Training loss: 0.1942652463912964
Validation loss: 1.5119292966781124

Epoch: 6| Step: 5
Training loss: 0.11752399802207947
Validation loss: 1.5040513353963052

Epoch: 6| Step: 6
Training loss: 0.19842424988746643
Validation loss: 1.5084963998486918

Epoch: 6| Step: 7
Training loss: 0.14722885191440582
Validation loss: 1.5143380459918772

Epoch: 6| Step: 8
Training loss: 0.15580087900161743
Validation loss: 1.525812513084822

Epoch: 6| Step: 9
Training loss: 0.13812223076820374
Validation loss: 1.4917743500842844

Epoch: 6| Step: 10
Training loss: 0.18100346624851227
Validation loss: 1.466182121666529

Epoch: 6| Step: 11
Training loss: 0.18518593907356262
Validation loss: 1.4704044326659171

Epoch: 6| Step: 12
Training loss: 0.14468619227409363
Validation loss: 1.471650049250613

Epoch: 6| Step: 13
Training loss: 0.17257818579673767
Validation loss: 1.484660936940101

Epoch: 350| Step: 0
Training loss: 0.15933966636657715
Validation loss: 1.4743605300944338

Epoch: 6| Step: 1
Training loss: 0.15607497096061707
Validation loss: 1.4872380200252737

Epoch: 6| Step: 2
Training loss: 0.10906711965799332
Validation loss: 1.4782737826788297

Epoch: 6| Step: 3
Training loss: 0.09377600252628326
Validation loss: 1.5117180142351376

Epoch: 6| Step: 4
Training loss: 0.12469130754470825
Validation loss: 1.5306630070491503

Epoch: 6| Step: 5
Training loss: 0.2762279510498047
Validation loss: 1.5358759677538307

Epoch: 6| Step: 6
Training loss: 0.19319549202919006
Validation loss: 1.550588164278256

Epoch: 6| Step: 7
Training loss: 0.24025680124759674
Validation loss: 1.5566783874265608

Epoch: 6| Step: 8
Training loss: 0.16119635105133057
Validation loss: 1.531817679764122

Epoch: 6| Step: 9
Training loss: 0.15495645999908447
Validation loss: 1.511910721819888

Epoch: 6| Step: 10
Training loss: 0.3085598349571228
Validation loss: 1.4996449921720771

Epoch: 6| Step: 11
Training loss: 0.14696407318115234
Validation loss: 1.4835435120008325

Epoch: 6| Step: 12
Training loss: 0.08448760211467743
Validation loss: 1.4783720636880526

Epoch: 6| Step: 13
Training loss: 0.19648635387420654
Validation loss: 1.4762741250376548

Epoch: 351| Step: 0
Training loss: 0.14758461713790894
Validation loss: 1.5005442775705808

Epoch: 6| Step: 1
Training loss: 0.1650201976299286
Validation loss: 1.4971087748004543

Epoch: 6| Step: 2
Training loss: 0.21125578880310059
Validation loss: 1.4755038061449606

Epoch: 6| Step: 3
Training loss: 0.19125515222549438
Validation loss: 1.4798651651669574

Epoch: 6| Step: 4
Training loss: 0.24290072917938232
Validation loss: 1.496932512970381

Epoch: 6| Step: 5
Training loss: 0.11855310201644897
Validation loss: 1.4975030806756788

Epoch: 6| Step: 6
Training loss: 0.1407841145992279
Validation loss: 1.5089835377149685

Epoch: 6| Step: 7
Training loss: 0.20147281885147095
Validation loss: 1.5004827771135556

Epoch: 6| Step: 8
Training loss: 0.19078007340431213
Validation loss: 1.520668702740823

Epoch: 6| Step: 9
Training loss: 0.11090496182441711
Validation loss: 1.5188922510352185

Epoch: 6| Step: 10
Training loss: 0.15070219337940216
Validation loss: 1.5182401505849694

Epoch: 6| Step: 11
Training loss: 0.18993699550628662
Validation loss: 1.5022217137839204

Epoch: 6| Step: 12
Training loss: 0.18211200833320618
Validation loss: 1.5410805158717658

Epoch: 6| Step: 13
Training loss: 0.10084133595228195
Validation loss: 1.5482902988310783

Epoch: 352| Step: 0
Training loss: 0.17445296049118042
Validation loss: 1.5261461273316415

Epoch: 6| Step: 1
Training loss: 0.20757463574409485
Validation loss: 1.5183545722756335

Epoch: 6| Step: 2
Training loss: 0.13827036321163177
Validation loss: 1.4785662261388635

Epoch: 6| Step: 3
Training loss: 0.24664926528930664
Validation loss: 1.510730189661826

Epoch: 6| Step: 4
Training loss: 0.19113853573799133
Validation loss: 1.5226326219497188

Epoch: 6| Step: 5
Training loss: 0.24923329055309296
Validation loss: 1.5101841867610972

Epoch: 6| Step: 6
Training loss: 0.1369452029466629
Validation loss: 1.50829622309695

Epoch: 6| Step: 7
Training loss: 0.15382614731788635
Validation loss: 1.4778106783026008

Epoch: 6| Step: 8
Training loss: 0.1885407418012619
Validation loss: 1.4700469355429373

Epoch: 6| Step: 9
Training loss: 0.17985183000564575
Validation loss: 1.4565127972633607

Epoch: 6| Step: 10
Training loss: 0.19786620140075684
Validation loss: 1.4637553256045106

Epoch: 6| Step: 11
Training loss: 0.1900014877319336
Validation loss: 1.4815249776327482

Epoch: 6| Step: 12
Training loss: 0.160283625125885
Validation loss: 1.4781587495598743

Epoch: 6| Step: 13
Training loss: 0.19121091067790985
Validation loss: 1.4953753538029169

Epoch: 353| Step: 0
Training loss: 0.22658595442771912
Validation loss: 1.4993735282651839

Epoch: 6| Step: 1
Training loss: 0.22443610429763794
Validation loss: 1.4803445826294601

Epoch: 6| Step: 2
Training loss: 0.19872230291366577
Validation loss: 1.4740838882743672

Epoch: 6| Step: 3
Training loss: 0.26525628566741943
Validation loss: 1.4621367992893342

Epoch: 6| Step: 4
Training loss: 0.06926354765892029
Validation loss: 1.4880461885083107

Epoch: 6| Step: 5
Training loss: 0.12853357195854187
Validation loss: 1.487665025136804

Epoch: 6| Step: 6
Training loss: 0.10718607157468796
Validation loss: 1.478232737510435

Epoch: 6| Step: 7
Training loss: 0.15139997005462646
Validation loss: 1.4999207450497536

Epoch: 6| Step: 8
Training loss: 0.10751552879810333
Validation loss: 1.4971773329601492

Epoch: 6| Step: 9
Training loss: 0.13572704792022705
Validation loss: 1.4810844775169127

Epoch: 6| Step: 10
Training loss: 0.12295247614383698
Validation loss: 1.4577385699877174

Epoch: 6| Step: 11
Training loss: 0.13452908396720886
Validation loss: 1.4873099096359745

Epoch: 6| Step: 12
Training loss: 0.19695940613746643
Validation loss: 1.472990919184941

Epoch: 6| Step: 13
Training loss: 0.11385444551706314
Validation loss: 1.4810494607494724

Epoch: 354| Step: 0
Training loss: 0.13125400245189667
Validation loss: 1.4717354280974275

Epoch: 6| Step: 1
Training loss: 0.08841103315353394
Validation loss: 1.5239669033276138

Epoch: 6| Step: 2
Training loss: 0.1157679557800293
Validation loss: 1.5035980465591594

Epoch: 6| Step: 3
Training loss: 0.13410580158233643
Validation loss: 1.528694720678432

Epoch: 6| Step: 4
Training loss: 0.15090912580490112
Validation loss: 1.4965324594128517

Epoch: 6| Step: 5
Training loss: 0.10225354880094528
Validation loss: 1.528233423027941

Epoch: 6| Step: 6
Training loss: 0.1543274223804474
Validation loss: 1.512377340306518

Epoch: 6| Step: 7
Training loss: 0.24578480422496796
Validation loss: 1.5178562274543188

Epoch: 6| Step: 8
Training loss: 0.11825210601091385
Validation loss: 1.5194329010543002

Epoch: 6| Step: 9
Training loss: 0.16152963042259216
Validation loss: 1.5140995992127286

Epoch: 6| Step: 10
Training loss: 0.18052098155021667
Validation loss: 1.5267744807786838

Epoch: 6| Step: 11
Training loss: 0.13354144990444183
Validation loss: 1.5007612038684148

Epoch: 6| Step: 12
Training loss: 0.19208335876464844
Validation loss: 1.4961004936566917

Epoch: 6| Step: 13
Training loss: 0.13860170543193817
Validation loss: 1.4969653044977496

Epoch: 355| Step: 0
Training loss: 0.22962814569473267
Validation loss: 1.5103700237889444

Epoch: 6| Step: 1
Training loss: 0.21155177056789398
Validation loss: 1.518615815588223

Epoch: 6| Step: 2
Training loss: 0.1165393739938736
Validation loss: 1.551618335067585

Epoch: 6| Step: 3
Training loss: 0.17200233042240143
Validation loss: 1.533084254111013

Epoch: 6| Step: 4
Training loss: 0.12220314145088196
Validation loss: 1.5233564069194179

Epoch: 6| Step: 5
Training loss: 0.13717344403266907
Validation loss: 1.5369704615685247

Epoch: 6| Step: 6
Training loss: 0.1612645983695984
Validation loss: 1.512936645938504

Epoch: 6| Step: 7
Training loss: 0.21828702092170715
Validation loss: 1.50612646918143

Epoch: 6| Step: 8
Training loss: 0.15539300441741943
Validation loss: 1.511142131461892

Epoch: 6| Step: 9
Training loss: 0.1912062168121338
Validation loss: 1.490532559733237

Epoch: 6| Step: 10
Training loss: 0.22842302918434143
Validation loss: 1.5291530586058093

Epoch: 6| Step: 11
Training loss: 0.16562561690807343
Validation loss: 1.529011905834239

Epoch: 6| Step: 12
Training loss: 0.0868799239397049
Validation loss: 1.5155935518203243

Epoch: 6| Step: 13
Training loss: 0.16108845174312592
Validation loss: 1.517972771839429

Epoch: 356| Step: 0
Training loss: 0.08174675703048706
Validation loss: 1.5046975561367568

Epoch: 6| Step: 1
Training loss: 0.14256809651851654
Validation loss: 1.5215519961490427

Epoch: 6| Step: 2
Training loss: 0.15605884790420532
Validation loss: 1.5731702068800568

Epoch: 6| Step: 3
Training loss: 0.21999309957027435
Validation loss: 1.5683642138716996

Epoch: 6| Step: 4
Training loss: 0.17701493203639984
Validation loss: 1.5641991746041082

Epoch: 6| Step: 5
Training loss: 0.245680034160614
Validation loss: 1.5320772791421542

Epoch: 6| Step: 6
Training loss: 0.12362601608037949
Validation loss: 1.4857657314628683

Epoch: 6| Step: 7
Training loss: 0.1848038285970688
Validation loss: 1.4802403642285256

Epoch: 6| Step: 8
Training loss: 0.16964729130268097
Validation loss: 1.5073959109603718

Epoch: 6| Step: 9
Training loss: 0.16389840841293335
Validation loss: 1.504713971127746

Epoch: 6| Step: 10
Training loss: 0.18616797029972076
Validation loss: 1.5092588829737839

Epoch: 6| Step: 11
Training loss: 0.1396167278289795
Validation loss: 1.4745539567803825

Epoch: 6| Step: 12
Training loss: 0.14506715536117554
Validation loss: 1.472190901797305

Epoch: 6| Step: 13
Training loss: 0.1317463368177414
Validation loss: 1.4935400229628368

Epoch: 357| Step: 0
Training loss: 0.0898066982626915
Validation loss: 1.4956209121211883

Epoch: 6| Step: 1
Training loss: 0.10315094143152237
Validation loss: 1.4949670068679317

Epoch: 6| Step: 2
Training loss: 0.19110745191574097
Validation loss: 1.4907549619674683

Epoch: 6| Step: 3
Training loss: 0.14125753939151764
Validation loss: 1.4838577605062915

Epoch: 6| Step: 4
Training loss: 0.17945633828639984
Validation loss: 1.4584027605672036

Epoch: 6| Step: 5
Training loss: 0.1486954689025879
Validation loss: 1.460002786369734

Epoch: 6| Step: 6
Training loss: 0.1498953253030777
Validation loss: 1.4600612835217548

Epoch: 6| Step: 7
Training loss: 0.10797591507434845
Validation loss: 1.4681282466457737

Epoch: 6| Step: 8
Training loss: 0.1014142632484436
Validation loss: 1.457555042800083

Epoch: 6| Step: 9
Training loss: 0.11386595666408539
Validation loss: 1.4617509470191052

Epoch: 6| Step: 10
Training loss: 0.1737067699432373
Validation loss: 1.4709463151552344

Epoch: 6| Step: 11
Training loss: 0.13762500882148743
Validation loss: 1.4852477299269808

Epoch: 6| Step: 12
Training loss: 0.09762343019247055
Validation loss: 1.4817104685691096

Epoch: 6| Step: 13
Training loss: 0.24268293380737305
Validation loss: 1.4811260110588484

Epoch: 358| Step: 0
Training loss: 0.1274622082710266
Validation loss: 1.4624782243082601

Epoch: 6| Step: 1
Training loss: 0.15955820679664612
Validation loss: 1.446512181271789

Epoch: 6| Step: 2
Training loss: 0.12096628546714783
Validation loss: 1.4507721034429406

Epoch: 6| Step: 3
Training loss: 0.06955114006996155
Validation loss: 1.4448872663641488

Epoch: 6| Step: 4
Training loss: 0.24953120946884155
Validation loss: 1.4572190392401911

Epoch: 6| Step: 5
Training loss: 0.13864976167678833
Validation loss: 1.4507037824200046

Epoch: 6| Step: 6
Training loss: 0.15429453551769257
Validation loss: 1.4791254099979196

Epoch: 6| Step: 7
Training loss: 0.16217000782489777
Validation loss: 1.4692724315069055

Epoch: 6| Step: 8
Training loss: 0.10794086754322052
Validation loss: 1.478770811070678

Epoch: 6| Step: 9
Training loss: 0.20003598928451538
Validation loss: 1.4846049624104654

Epoch: 6| Step: 10
Training loss: 0.09132708609104156
Validation loss: 1.5105911172846311

Epoch: 6| Step: 11
Training loss: 0.084002286195755
Validation loss: 1.5069609265173636

Epoch: 6| Step: 12
Training loss: 0.16135399043560028
Validation loss: 1.5382518281218827

Epoch: 6| Step: 13
Training loss: 0.2182801365852356
Validation loss: 1.523082398599194

Epoch: 359| Step: 0
Training loss: 0.10593147575855255
Validation loss: 1.5192491700572353

Epoch: 6| Step: 1
Training loss: 0.18994520604610443
Validation loss: 1.506423145212153

Epoch: 6| Step: 2
Training loss: 0.31592679023742676
Validation loss: 1.5150443097596527

Epoch: 6| Step: 3
Training loss: 0.12024453282356262
Validation loss: 1.4935282379068353

Epoch: 6| Step: 4
Training loss: 0.125494122505188
Validation loss: 1.5100039153970697

Epoch: 6| Step: 5
Training loss: 0.09714284539222717
Validation loss: 1.5249956243781633

Epoch: 6| Step: 6
Training loss: 0.1188015565276146
Validation loss: 1.5519594415541618

Epoch: 6| Step: 7
Training loss: 0.13769200444221497
Validation loss: 1.5738962414444133

Epoch: 6| Step: 8
Training loss: 0.25670695304870605
Validation loss: 1.5793308083729078

Epoch: 6| Step: 9
Training loss: 0.23001313209533691
Validation loss: 1.5636157092227732

Epoch: 6| Step: 10
Training loss: 0.12319250404834747
Validation loss: 1.5135884246518534

Epoch: 6| Step: 11
Training loss: 0.21283893287181854
Validation loss: 1.4957533036508868

Epoch: 6| Step: 12
Training loss: 0.2306516170501709
Validation loss: 1.4790121470728228

Epoch: 6| Step: 13
Training loss: 0.31244486570358276
Validation loss: 1.458899809468177

Epoch: 360| Step: 0
Training loss: 0.16965162754058838
Validation loss: 1.4571355350555912

Epoch: 6| Step: 1
Training loss: 0.15118718147277832
Validation loss: 1.4639034514786096

Epoch: 6| Step: 2
Training loss: 0.1422547698020935
Validation loss: 1.4825894922338507

Epoch: 6| Step: 3
Training loss: 0.16023464500904083
Validation loss: 1.5088062850377892

Epoch: 6| Step: 4
Training loss: 0.17336978018283844
Validation loss: 1.5337386618378341

Epoch: 6| Step: 5
Training loss: 0.08189615607261658
Validation loss: 1.53138013808958

Epoch: 6| Step: 6
Training loss: 0.21417607367038727
Validation loss: 1.5220018176622288

Epoch: 6| Step: 7
Training loss: 0.09665176272392273
Validation loss: 1.517117308032128

Epoch: 6| Step: 8
Training loss: 0.1788884699344635
Validation loss: 1.515763105884675

Epoch: 6| Step: 9
Training loss: 0.20908290147781372
Validation loss: 1.5026245130005704

Epoch: 6| Step: 10
Training loss: 0.1168169379234314
Validation loss: 1.5073518368505663

Epoch: 6| Step: 11
Training loss: 0.15625640749931335
Validation loss: 1.5442792407927974

Epoch: 6| Step: 12
Training loss: 0.13024955987930298
Validation loss: 1.4904981838759555

Epoch: 6| Step: 13
Training loss: 0.07126180082559586
Validation loss: 1.508398470058236

Epoch: 361| Step: 0
Training loss: 0.10616721957921982
Validation loss: 1.52283219111863

Epoch: 6| Step: 1
Training loss: 0.16992846131324768
Validation loss: 1.5450970870192333

Epoch: 6| Step: 2
Training loss: 0.15370897948741913
Validation loss: 1.5239100174237323

Epoch: 6| Step: 3
Training loss: 0.17164313793182373
Validation loss: 1.5281651494323567

Epoch: 6| Step: 4
Training loss: 0.1114654392004013
Validation loss: 1.5332316711384764

Epoch: 6| Step: 5
Training loss: 0.12168867886066437
Validation loss: 1.5179658512915335

Epoch: 6| Step: 6
Training loss: 0.15571749210357666
Validation loss: 1.5415591507829645

Epoch: 6| Step: 7
Training loss: 0.17424899339675903
Validation loss: 1.5139516835571618

Epoch: 6| Step: 8
Training loss: 0.1250070184469223
Validation loss: 1.5181862628588112

Epoch: 6| Step: 9
Training loss: 0.13789711892604828
Validation loss: 1.521012730495904

Epoch: 6| Step: 10
Training loss: 0.10738857090473175
Validation loss: 1.519712048192178

Epoch: 6| Step: 11
Training loss: 0.18255960941314697
Validation loss: 1.52762484294112

Epoch: 6| Step: 12
Training loss: 0.18315517902374268
Validation loss: 1.5330741559305499

Epoch: 6| Step: 13
Training loss: 0.2663315534591675
Validation loss: 1.53438280218391

Epoch: 362| Step: 0
Training loss: 0.13809466361999512
Validation loss: 1.5319549422110281

Epoch: 6| Step: 1
Training loss: 0.14404530823230743
Validation loss: 1.5450700367650678

Epoch: 6| Step: 2
Training loss: 0.17011716961860657
Validation loss: 1.5408490703951927

Epoch: 6| Step: 3
Training loss: 0.16184714436531067
Validation loss: 1.5652319782523698

Epoch: 6| Step: 4
Training loss: 0.1817585825920105
Validation loss: 1.5706789737106652

Epoch: 6| Step: 5
Training loss: 0.19761580228805542
Validation loss: 1.5409047526697959

Epoch: 6| Step: 6
Training loss: 0.166901096701622
Validation loss: 1.5346064452202088

Epoch: 6| Step: 7
Training loss: 0.14407691359519958
Validation loss: 1.5583265648093274

Epoch: 6| Step: 8
Training loss: 0.11396177113056183
Validation loss: 1.5427767922801356

Epoch: 6| Step: 9
Training loss: 0.1799200028181076
Validation loss: 1.5396932748056227

Epoch: 6| Step: 10
Training loss: 0.20242612063884735
Validation loss: 1.5325563415404289

Epoch: 6| Step: 11
Training loss: 0.22917228937149048
Validation loss: 1.5138652568222375

Epoch: 6| Step: 12
Training loss: 0.12211580574512482
Validation loss: 1.5439655934610674

Epoch: 6| Step: 13
Training loss: 0.14867153763771057
Validation loss: 1.5172100528593986

Epoch: 363| Step: 0
Training loss: 0.13196659088134766
Validation loss: 1.5200051710169802

Epoch: 6| Step: 1
Training loss: 0.16926440596580505
Validation loss: 1.4671289510624383

Epoch: 6| Step: 2
Training loss: 0.11523580551147461
Validation loss: 1.4862492020412157

Epoch: 6| Step: 3
Training loss: 0.2093987911939621
Validation loss: 1.4667803023451118

Epoch: 6| Step: 4
Training loss: 0.13408049941062927
Validation loss: 1.46672704527455

Epoch: 6| Step: 5
Training loss: 0.1614660918712616
Validation loss: 1.4739997592023624

Epoch: 6| Step: 6
Training loss: 0.14677223563194275
Validation loss: 1.4769650915617585

Epoch: 6| Step: 7
Training loss: 0.16081689298152924
Validation loss: 1.4693846356484197

Epoch: 6| Step: 8
Training loss: 0.18471643328666687
Validation loss: 1.4734280775952082

Epoch: 6| Step: 9
Training loss: 0.12926088273525238
Validation loss: 1.469724565423945

Epoch: 6| Step: 10
Training loss: 0.14713513851165771
Validation loss: 1.484843942426866

Epoch: 6| Step: 11
Training loss: 0.08797907084226608
Validation loss: 1.5014644758675688

Epoch: 6| Step: 12
Training loss: 0.16686266660690308
Validation loss: 1.49619843370171

Epoch: 6| Step: 13
Training loss: 0.20728132128715515
Validation loss: 1.5106516384309339

Epoch: 364| Step: 0
Training loss: 0.13248538970947266
Validation loss: 1.5074799804277317

Epoch: 6| Step: 1
Training loss: 0.18261264264583588
Validation loss: 1.5206820323903074

Epoch: 6| Step: 2
Training loss: 0.21630465984344482
Validation loss: 1.4951621845204344

Epoch: 6| Step: 3
Training loss: 0.17702461779117584
Validation loss: 1.5173421303431194

Epoch: 6| Step: 4
Training loss: 0.11073563992977142
Validation loss: 1.5106694570151709

Epoch: 6| Step: 5
Training loss: 0.1026199609041214
Validation loss: 1.4957662026087444

Epoch: 6| Step: 6
Training loss: 0.19240359961986542
Validation loss: 1.5120735514548518

Epoch: 6| Step: 7
Training loss: 0.20212484896183014
Validation loss: 1.5034361039438555

Epoch: 6| Step: 8
Training loss: 0.10613028705120087
Validation loss: 1.4965846705180343

Epoch: 6| Step: 9
Training loss: 0.172965407371521
Validation loss: 1.4758379702926965

Epoch: 6| Step: 10
Training loss: 0.1105085238814354
Validation loss: 1.4798484643300374

Epoch: 6| Step: 11
Training loss: 0.14779993891716003
Validation loss: 1.4828143773540374

Epoch: 6| Step: 12
Training loss: 0.08652722090482712
Validation loss: 1.5149030941788868

Epoch: 6| Step: 13
Training loss: 0.11209677159786224
Validation loss: 1.5014992234527424

Epoch: 365| Step: 0
Training loss: 0.11968198418617249
Validation loss: 1.4766613001464515

Epoch: 6| Step: 1
Training loss: 0.11248443275690079
Validation loss: 1.474344640649775

Epoch: 6| Step: 2
Training loss: 0.15455755591392517
Validation loss: 1.4687070154374646

Epoch: 6| Step: 3
Training loss: 0.18040524423122406
Validation loss: 1.4913554217225762

Epoch: 6| Step: 4
Training loss: 0.280474990606308
Validation loss: 1.4791452884674072

Epoch: 6| Step: 5
Training loss: 0.12311616539955139
Validation loss: 1.4595951162358767

Epoch: 6| Step: 6
Training loss: 0.1349996030330658
Validation loss: 1.4755893599602483

Epoch: 6| Step: 7
Training loss: 0.1488780677318573
Validation loss: 1.4864542484283447

Epoch: 6| Step: 8
Training loss: 0.11160844564437866
Validation loss: 1.4394326799659318

Epoch: 6| Step: 9
Training loss: 0.15977588295936584
Validation loss: 1.4752330780029297

Epoch: 6| Step: 10
Training loss: 0.16931280493736267
Validation loss: 1.509754983327722

Epoch: 6| Step: 11
Training loss: 0.11987793445587158
Validation loss: 1.4965702218394126

Epoch: 6| Step: 12
Training loss: 0.13267961144447327
Validation loss: 1.4911132076735139

Epoch: 6| Step: 13
Training loss: 0.1210346594452858
Validation loss: 1.486819371100395

Epoch: 366| Step: 0
Training loss: 0.11328255385160446
Validation loss: 1.5120807001667638

Epoch: 6| Step: 1
Training loss: 0.15219631791114807
Validation loss: 1.5302590227896167

Epoch: 6| Step: 2
Training loss: 0.16468843817710876
Validation loss: 1.5194629981953611

Epoch: 6| Step: 3
Training loss: 0.09892883151769638
Validation loss: 1.5403615556737429

Epoch: 6| Step: 4
Training loss: 0.2451520413160324
Validation loss: 1.5471969945456392

Epoch: 6| Step: 5
Training loss: 0.14104348421096802
Validation loss: 1.5634539486259542

Epoch: 6| Step: 6
Training loss: 0.16442470252513885
Validation loss: 1.5634609755649362

Epoch: 6| Step: 7
Training loss: 0.17414911091327667
Validation loss: 1.547645834184462

Epoch: 6| Step: 8
Training loss: 0.16679325699806213
Validation loss: 1.5425635050701838

Epoch: 6| Step: 9
Training loss: 0.11142709851264954
Validation loss: 1.529125572532736

Epoch: 6| Step: 10
Training loss: 0.17910991609096527
Validation loss: 1.5004400476332633

Epoch: 6| Step: 11
Training loss: 0.24005813896656036
Validation loss: 1.4907572833440637

Epoch: 6| Step: 12
Training loss: 0.17647382616996765
Validation loss: 1.4945427743337487

Epoch: 6| Step: 13
Training loss: 0.11868464946746826
Validation loss: 1.4837394786137406

Epoch: 367| Step: 0
Training loss: 0.12577283382415771
Validation loss: 1.468502934261035

Epoch: 6| Step: 1
Training loss: 0.16786730289459229
Validation loss: 1.4973903394514514

Epoch: 6| Step: 2
Training loss: 0.11468823254108429
Validation loss: 1.4995533112556703

Epoch: 6| Step: 3
Training loss: 0.14511942863464355
Validation loss: 1.505702522493178

Epoch: 6| Step: 4
Training loss: 0.25396427512168884
Validation loss: 1.5198773376403316

Epoch: 6| Step: 5
Training loss: 0.17405323684215546
Validation loss: 1.5256485272479314

Epoch: 6| Step: 6
Training loss: 0.24891233444213867
Validation loss: 1.5226451299523796

Epoch: 6| Step: 7
Training loss: 0.15251535177230835
Validation loss: 1.5081936992624754

Epoch: 6| Step: 8
Training loss: 0.17532885074615479
Validation loss: 1.5166476388131418

Epoch: 6| Step: 9
Training loss: 0.2810751795768738
Validation loss: 1.5148192938937937

Epoch: 6| Step: 10
Training loss: 0.2206869274377823
Validation loss: 1.5239539313059982

Epoch: 6| Step: 11
Training loss: 0.24362920224666595
Validation loss: 1.5279817299176288

Epoch: 6| Step: 12
Training loss: 0.109400175511837
Validation loss: 1.4966609272905576

Epoch: 6| Step: 13
Training loss: 0.09720805287361145
Validation loss: 1.4867386689750097

Epoch: 368| Step: 0
Training loss: 0.19096823036670685
Validation loss: 1.5371975821833457

Epoch: 6| Step: 1
Training loss: 0.16541436314582825
Validation loss: 1.5693461202806043

Epoch: 6| Step: 2
Training loss: 0.35848405957221985
Validation loss: 1.5724526746298677

Epoch: 6| Step: 3
Training loss: 0.2847095727920532
Validation loss: 1.5461528506330264

Epoch: 6| Step: 4
Training loss: 0.12406116724014282
Validation loss: 1.4908415322662683

Epoch: 6| Step: 5
Training loss: 0.11247177422046661
Validation loss: 1.4987062715714978

Epoch: 6| Step: 6
Training loss: 0.20533297955989838
Validation loss: 1.497361784340233

Epoch: 6| Step: 7
Training loss: 0.24703168869018555
Validation loss: 1.5319416228161062

Epoch: 6| Step: 8
Training loss: 0.3358554244041443
Validation loss: 1.5060928310117414

Epoch: 6| Step: 9
Training loss: 0.08795951306819916
Validation loss: 1.4907426564924178

Epoch: 6| Step: 10
Training loss: 0.17748752236366272
Validation loss: 1.496817696479059

Epoch: 6| Step: 11
Training loss: 0.15751905739307404
Validation loss: 1.5027897883487005

Epoch: 6| Step: 12
Training loss: 0.14645129442214966
Validation loss: 1.503383845411321

Epoch: 6| Step: 13
Training loss: 0.12758173048496246
Validation loss: 1.544824727119938

Epoch: 369| Step: 0
Training loss: 0.26081210374832153
Validation loss: 1.5512930513710104

Epoch: 6| Step: 1
Training loss: 0.14162661135196686
Validation loss: 1.5515240610286753

Epoch: 6| Step: 2
Training loss: 0.23883575201034546
Validation loss: 1.578509146167386

Epoch: 6| Step: 3
Training loss: 0.22647204995155334
Validation loss: 1.5436245318382018

Epoch: 6| Step: 4
Training loss: 0.28632497787475586
Validation loss: 1.5481359240829304

Epoch: 6| Step: 5
Training loss: 0.1808924674987793
Validation loss: 1.5142876819897724

Epoch: 6| Step: 6
Training loss: 0.18834638595581055
Validation loss: 1.4911089289572932

Epoch: 6| Step: 7
Training loss: 0.10955673456192017
Validation loss: 1.499914692294213

Epoch: 6| Step: 8
Training loss: 0.22325018048286438
Validation loss: 1.517364857017353

Epoch: 6| Step: 9
Training loss: 0.1729171872138977
Validation loss: 1.5356537654835691

Epoch: 6| Step: 10
Training loss: 0.10127615183591843
Validation loss: 1.598289688428243

Epoch: 6| Step: 11
Training loss: 0.21649456024169922
Validation loss: 1.5857627161087529

Epoch: 6| Step: 12
Training loss: 0.26279401779174805
Validation loss: 1.630531907081604

Epoch: 6| Step: 13
Training loss: 0.15671294927597046
Validation loss: 1.5906871672599547

Epoch: 370| Step: 0
Training loss: 0.16493737697601318
Validation loss: 1.623505566709785

Epoch: 6| Step: 1
Training loss: 0.26508408784866333
Validation loss: 1.6057276597587011

Epoch: 6| Step: 2
Training loss: 0.16135455667972565
Validation loss: 1.5350793215536302

Epoch: 6| Step: 3
Training loss: 0.11408059298992157
Validation loss: 1.496735288250831

Epoch: 6| Step: 4
Training loss: 0.19620361924171448
Validation loss: 1.4823599425695275

Epoch: 6| Step: 5
Training loss: 0.16829147934913635
Validation loss: 1.483835909956245

Epoch: 6| Step: 6
Training loss: 0.15193457901477814
Validation loss: 1.4935920315404092

Epoch: 6| Step: 7
Training loss: 0.13292911648750305
Validation loss: 1.486707833505446

Epoch: 6| Step: 8
Training loss: 0.18416358530521393
Validation loss: 1.508793939826309

Epoch: 6| Step: 9
Training loss: 0.09004218876361847
Validation loss: 1.507225150703102

Epoch: 6| Step: 10
Training loss: 0.08236158639192581
Validation loss: 1.5224762039799844

Epoch: 6| Step: 11
Training loss: 0.18138253688812256
Validation loss: 1.5253641220831102

Epoch: 6| Step: 12
Training loss: 0.1456526517868042
Validation loss: 1.5135573161545621

Epoch: 6| Step: 13
Training loss: 0.12574273347854614
Validation loss: 1.5354468399478542

Epoch: 371| Step: 0
Training loss: 0.15711519122123718
Validation loss: 1.5187217356056295

Epoch: 6| Step: 1
Training loss: 0.17683099210262299
Validation loss: 1.520436671472365

Epoch: 6| Step: 2
Training loss: 0.11406456679105759
Validation loss: 1.4789225221962057

Epoch: 6| Step: 3
Training loss: 0.11205785721540451
Validation loss: 1.4800509342583277

Epoch: 6| Step: 4
Training loss: 0.18744689226150513
Validation loss: 1.4934866633466495

Epoch: 6| Step: 5
Training loss: 0.134610116481781
Validation loss: 1.4688696950994513

Epoch: 6| Step: 6
Training loss: 0.1911357343196869
Validation loss: 1.4504321262400637

Epoch: 6| Step: 7
Training loss: 0.149335116147995
Validation loss: 1.4458350609707575

Epoch: 6| Step: 8
Training loss: 0.1699155569076538
Validation loss: 1.446797646502013

Epoch: 6| Step: 9
Training loss: 0.1693362593650818
Validation loss: 1.451597604700314

Epoch: 6| Step: 10
Training loss: 0.0839090570807457
Validation loss: 1.4420892115562194

Epoch: 6| Step: 11
Training loss: 0.15193066000938416
Validation loss: 1.4516362759374803

Epoch: 6| Step: 12
Training loss: 0.13179290294647217
Validation loss: 1.4382880695404545

Epoch: 6| Step: 13
Training loss: 0.09387339651584625
Validation loss: 1.4423110843986593

Epoch: 372| Step: 0
Training loss: 0.20095205307006836
Validation loss: 1.4540012472419328

Epoch: 6| Step: 1
Training loss: 0.14944246411323547
Validation loss: 1.4827317089162848

Epoch: 6| Step: 2
Training loss: 0.14612562954425812
Validation loss: 1.4921109612270067

Epoch: 6| Step: 3
Training loss: 0.13882282376289368
Validation loss: 1.492846909389701

Epoch: 6| Step: 4
Training loss: 0.08531014621257782
Validation loss: 1.4986000740399925

Epoch: 6| Step: 5
Training loss: 0.09551399946212769
Validation loss: 1.488334116115365

Epoch: 6| Step: 6
Training loss: 0.17083846032619476
Validation loss: 1.4730634638058242

Epoch: 6| Step: 7
Training loss: 0.18477480113506317
Validation loss: 1.4522343374067737

Epoch: 6| Step: 8
Training loss: 0.1720259040594101
Validation loss: 1.4360379224182458

Epoch: 6| Step: 9
Training loss: 0.1511516273021698
Validation loss: 1.4467290543740796

Epoch: 6| Step: 10
Training loss: 0.15714606642723083
Validation loss: 1.4680977931586645

Epoch: 6| Step: 11
Training loss: 0.09090424329042435
Validation loss: 1.4513112396322272

Epoch: 6| Step: 12
Training loss: 0.12923461198806763
Validation loss: 1.4556838825184812

Epoch: 6| Step: 13
Training loss: 0.13383540511131287
Validation loss: 1.4901357619993147

Epoch: 373| Step: 0
Training loss: 0.11662323027849197
Validation loss: 1.48935196732962

Epoch: 6| Step: 1
Training loss: 0.1385793536901474
Validation loss: 1.5029676345086866

Epoch: 6| Step: 2
Training loss: 0.06936207413673401
Validation loss: 1.4992839918341687

Epoch: 6| Step: 3
Training loss: 0.09752629697322845
Validation loss: 1.508062630571345

Epoch: 6| Step: 4
Training loss: 0.16381444036960602
Validation loss: 1.482174604169784

Epoch: 6| Step: 5
Training loss: 0.13133065402507782
Validation loss: 1.472141678615283

Epoch: 6| Step: 6
Training loss: 0.16223490238189697
Validation loss: 1.4615401798678982

Epoch: 6| Step: 7
Training loss: 0.11746091395616531
Validation loss: 1.4593327250531924

Epoch: 6| Step: 8
Training loss: 0.12858670949935913
Validation loss: 1.4396112259998117

Epoch: 6| Step: 9
Training loss: 0.1683405488729477
Validation loss: 1.46536543292384

Epoch: 6| Step: 10
Training loss: 0.10613663494586945
Validation loss: 1.4644676331550843

Epoch: 6| Step: 11
Training loss: 0.22241529822349548
Validation loss: 1.4804219244628825

Epoch: 6| Step: 12
Training loss: 0.1120448186993599
Validation loss: 1.5044024067540323

Epoch: 6| Step: 13
Training loss: 0.20894771814346313
Validation loss: 1.5072651460606565

Epoch: 374| Step: 0
Training loss: 0.1843557059764862
Validation loss: 1.485919015381926

Epoch: 6| Step: 1
Training loss: 0.12788856029510498
Validation loss: 1.4963032122581237

Epoch: 6| Step: 2
Training loss: 0.12554650008678436
Validation loss: 1.500349639564432

Epoch: 6| Step: 3
Training loss: 0.08265595138072968
Validation loss: 1.4770303439068537

Epoch: 6| Step: 4
Training loss: 0.09423872828483582
Validation loss: 1.4827078337310462

Epoch: 6| Step: 5
Training loss: 0.1393408477306366
Validation loss: 1.4631772272048458

Epoch: 6| Step: 6
Training loss: 0.08002690970897675
Validation loss: 1.4855803264084684

Epoch: 6| Step: 7
Training loss: 0.09993654489517212
Validation loss: 1.4776043161269157

Epoch: 6| Step: 8
Training loss: 0.12496648728847504
Validation loss: 1.465475675880268

Epoch: 6| Step: 9
Training loss: 0.12963569164276123
Validation loss: 1.5016561387687601

Epoch: 6| Step: 10
Training loss: 0.10987512767314911
Validation loss: 1.4829779747993714

Epoch: 6| Step: 11
Training loss: 0.1612069308757782
Validation loss: 1.495068762892036

Epoch: 6| Step: 12
Training loss: 0.17046061158180237
Validation loss: 1.4878879259991389

Epoch: 6| Step: 13
Training loss: 0.12900368869304657
Validation loss: 1.4737384485942062

Epoch: 375| Step: 0
Training loss: 0.07496190071105957
Validation loss: 1.4838248696378482

Epoch: 6| Step: 1
Training loss: 0.07604822516441345
Validation loss: 1.4685867069869913

Epoch: 6| Step: 2
Training loss: 0.14264503121376038
Validation loss: 1.4817554361076766

Epoch: 6| Step: 3
Training loss: 0.10320615023374557
Validation loss: 1.4817451494996265

Epoch: 6| Step: 4
Training loss: 0.05312259867787361
Validation loss: 1.5041569073994954

Epoch: 6| Step: 5
Training loss: 0.09288787841796875
Validation loss: 1.4894217573186403

Epoch: 6| Step: 6
Training loss: 0.10068890452384949
Validation loss: 1.4958825252389396

Epoch: 6| Step: 7
Training loss: 0.20746302604675293
Validation loss: 1.5103742179050241

Epoch: 6| Step: 8
Training loss: 0.1553616225719452
Validation loss: 1.4860212738795946

Epoch: 6| Step: 9
Training loss: 0.0858880802989006
Validation loss: 1.4959817253133303

Epoch: 6| Step: 10
Training loss: 0.1513320356607437
Validation loss: 1.509216909767479

Epoch: 6| Step: 11
Training loss: 0.1220579743385315
Validation loss: 1.503719481088782

Epoch: 6| Step: 12
Training loss: 0.1465681493282318
Validation loss: 1.477862032510901

Epoch: 6| Step: 13
Training loss: 0.16728639602661133
Validation loss: 1.5115809440612793

Epoch: 376| Step: 0
Training loss: 0.11637108027935028
Validation loss: 1.4700765507195586

Epoch: 6| Step: 1
Training loss: 0.15974314510822296
Validation loss: 1.4448990206564627

Epoch: 6| Step: 2
Training loss: 0.17984013259410858
Validation loss: 1.469953865133306

Epoch: 6| Step: 3
Training loss: 0.10618555545806885
Validation loss: 1.443706912379111

Epoch: 6| Step: 4
Training loss: 0.11934410035610199
Validation loss: 1.4603711751199537

Epoch: 6| Step: 5
Training loss: 0.1077268049120903
Validation loss: 1.4704430628848333

Epoch: 6| Step: 6
Training loss: 0.09245075285434723
Validation loss: 1.4799184517193866

Epoch: 6| Step: 7
Training loss: 0.09614889323711395
Validation loss: 1.505572335694426

Epoch: 6| Step: 8
Training loss: 0.1061004251241684
Validation loss: 1.5011721509759144

Epoch: 6| Step: 9
Training loss: 0.14301535487174988
Validation loss: 1.5171825398680985

Epoch: 6| Step: 10
Training loss: 0.12284065783023834
Validation loss: 1.4898046549930368

Epoch: 6| Step: 11
Training loss: 0.12218974530696869
Validation loss: 1.4874755874756844

Epoch: 6| Step: 12
Training loss: 0.11648156493902206
Validation loss: 1.4877132254262124

Epoch: 6| Step: 13
Training loss: 0.1897062510251999
Validation loss: 1.4666285046967127

Epoch: 377| Step: 0
Training loss: 0.1555316150188446
Validation loss: 1.4718253144653894

Epoch: 6| Step: 1
Training loss: 0.11344502866268158
Validation loss: 1.4818339578567012

Epoch: 6| Step: 2
Training loss: 0.13997676968574524
Validation loss: 1.5092508703149774

Epoch: 6| Step: 3
Training loss: 0.09442922472953796
Validation loss: 1.467495717028136

Epoch: 6| Step: 4
Training loss: 0.10720202326774597
Validation loss: 1.4925203989910822

Epoch: 6| Step: 5
Training loss: 0.08032654225826263
Validation loss: 1.493522156951248

Epoch: 6| Step: 6
Training loss: 0.09945066273212433
Validation loss: 1.4668099623854443

Epoch: 6| Step: 7
Training loss: 0.07884872704744339
Validation loss: 1.464299222474457

Epoch: 6| Step: 8
Training loss: 0.08979680389165878
Validation loss: 1.481580335606811

Epoch: 6| Step: 9
Training loss: 0.1356048882007599
Validation loss: 1.4810643311469787

Epoch: 6| Step: 10
Training loss: 0.12741802632808685
Validation loss: 1.461514622934403

Epoch: 6| Step: 11
Training loss: 0.18621866405010223
Validation loss: 1.4863861030147922

Epoch: 6| Step: 12
Training loss: 0.07321961224079132
Validation loss: 1.485476274644175

Epoch: 6| Step: 13
Training loss: 0.189238041639328
Validation loss: 1.5263792673746746

Epoch: 378| Step: 0
Training loss: 0.1384596973657608
Validation loss: 1.5499711062318535

Epoch: 6| Step: 1
Training loss: 0.2056586593389511
Validation loss: 1.5010686497534476

Epoch: 6| Step: 2
Training loss: 0.1336861252784729
Validation loss: 1.4903143432832533

Epoch: 6| Step: 3
Training loss: 0.12318983674049377
Validation loss: 1.4854523212678972

Epoch: 6| Step: 4
Training loss: 0.08225870132446289
Validation loss: 1.4789222017411263

Epoch: 6| Step: 5
Training loss: 0.09776849299669266
Validation loss: 1.4605050638157835

Epoch: 6| Step: 6
Training loss: 0.13445588946342468
Validation loss: 1.479113180150268

Epoch: 6| Step: 7
Training loss: 0.11419232189655304
Validation loss: 1.4703551671838249

Epoch: 6| Step: 8
Training loss: 0.18361936509609222
Validation loss: 1.4802797173941007

Epoch: 6| Step: 9
Training loss: 0.11662189662456512
Validation loss: 1.4643934798497025

Epoch: 6| Step: 10
Training loss: 0.11522281169891357
Validation loss: 1.4805650416240896

Epoch: 6| Step: 11
Training loss: 0.07371078431606293
Validation loss: 1.4938942924622567

Epoch: 6| Step: 12
Training loss: 0.08038972318172455
Validation loss: 1.4931486998834917

Epoch: 6| Step: 13
Training loss: 0.23176103830337524
Validation loss: 1.4874700384755288

Epoch: 379| Step: 0
Training loss: 0.13249193131923676
Validation loss: 1.4843135790158344

Epoch: 6| Step: 1
Training loss: 0.09026165306568146
Validation loss: 1.4858537681641117

Epoch: 6| Step: 2
Training loss: 0.10027492046356201
Validation loss: 1.4668536006763417

Epoch: 6| Step: 3
Training loss: 0.10655401647090912
Validation loss: 1.4726485026779996

Epoch: 6| Step: 4
Training loss: 0.17919376492500305
Validation loss: 1.4776251739071262

Epoch: 6| Step: 5
Training loss: 0.1362367868423462
Validation loss: 1.472275391701729

Epoch: 6| Step: 6
Training loss: 0.14043471217155457
Validation loss: 1.472789433694655

Epoch: 6| Step: 7
Training loss: 0.12393829226493835
Validation loss: 1.492702676403907

Epoch: 6| Step: 8
Training loss: 0.12959013879299164
Validation loss: 1.5084386269251506

Epoch: 6| Step: 9
Training loss: 0.17126202583312988
Validation loss: 1.5082177705662225

Epoch: 6| Step: 10
Training loss: 0.20794415473937988
Validation loss: 1.5012682740406325

Epoch: 6| Step: 11
Training loss: 0.11302495747804642
Validation loss: 1.509935623856001

Epoch: 6| Step: 12
Training loss: 0.10131439566612244
Validation loss: 1.499934160581199

Epoch: 6| Step: 13
Training loss: 0.09297677129507065
Validation loss: 1.507357479423605

Epoch: 380| Step: 0
Training loss: 0.13404247164726257
Validation loss: 1.5025263922188872

Epoch: 6| Step: 1
Training loss: 0.13118158280849457
Validation loss: 1.4793583641770065

Epoch: 6| Step: 2
Training loss: 0.13714481890201569
Validation loss: 1.485081415022573

Epoch: 6| Step: 3
Training loss: 0.09643380343914032
Validation loss: 1.4566206291157713

Epoch: 6| Step: 4
Training loss: 0.11997789889574051
Validation loss: 1.4656296622368596

Epoch: 6| Step: 5
Training loss: 0.21351337432861328
Validation loss: 1.4795691454282371

Epoch: 6| Step: 6
Training loss: 0.1331254541873932
Validation loss: 1.4704696837291922

Epoch: 6| Step: 7
Training loss: 0.13072270154953003
Validation loss: 1.49431663046601

Epoch: 6| Step: 8
Training loss: 0.09420838952064514
Validation loss: 1.4780577459642965

Epoch: 6| Step: 9
Training loss: 0.09086745977401733
Validation loss: 1.5128258094992688

Epoch: 6| Step: 10
Training loss: 0.10782915353775024
Validation loss: 1.5229949707626014

Epoch: 6| Step: 11
Training loss: 0.11147837340831757
Validation loss: 1.5144758173214492

Epoch: 6| Step: 12
Training loss: 0.18462786078453064
Validation loss: 1.5007334979631568

Epoch: 6| Step: 13
Training loss: 0.0499720424413681
Validation loss: 1.4915477486066921

Epoch: 381| Step: 0
Training loss: 0.10765604674816132
Validation loss: 1.4927374483436666

Epoch: 6| Step: 1
Training loss: 0.09520968049764633
Validation loss: 1.4736023808038363

Epoch: 6| Step: 2
Training loss: 0.11062656342983246
Validation loss: 1.4870483362546532

Epoch: 6| Step: 3
Training loss: 0.07082286477088928
Validation loss: 1.4828322843838764

Epoch: 6| Step: 4
Training loss: 0.09580062329769135
Validation loss: 1.4930569433396863

Epoch: 6| Step: 5
Training loss: 0.10117647051811218
Validation loss: 1.4933490189172889

Epoch: 6| Step: 6
Training loss: 0.11054659634828568
Validation loss: 1.5151641471411592

Epoch: 6| Step: 7
Training loss: 0.13284654915332794
Validation loss: 1.4980725447336833

Epoch: 6| Step: 8
Training loss: 0.14864036440849304
Validation loss: 1.5161739305783344

Epoch: 6| Step: 9
Training loss: 0.14500930905342102
Validation loss: 1.5334319055721324

Epoch: 6| Step: 10
Training loss: 0.19631999731063843
Validation loss: 1.5207036470854154

Epoch: 6| Step: 11
Training loss: 0.11338602006435394
Validation loss: 1.508368142189518

Epoch: 6| Step: 12
Training loss: 0.11660801619291306
Validation loss: 1.5131214754555815

Epoch: 6| Step: 13
Training loss: 0.25183168053627014
Validation loss: 1.5132039285475207

Epoch: 382| Step: 0
Training loss: 0.14410817623138428
Validation loss: 1.5151023223835935

Epoch: 6| Step: 1
Training loss: 0.0857120007276535
Validation loss: 1.5065933632594284

Epoch: 6| Step: 2
Training loss: 0.0954924002289772
Validation loss: 1.502565981239401

Epoch: 6| Step: 3
Training loss: 0.09178002178668976
Validation loss: 1.5343289195850331

Epoch: 6| Step: 4
Training loss: 0.2018243968486786
Validation loss: 1.518016687003515

Epoch: 6| Step: 5
Training loss: 0.18204785883426666
Validation loss: 1.494508626640484

Epoch: 6| Step: 6
Training loss: 0.1674787998199463
Validation loss: 1.5309825597270843

Epoch: 6| Step: 7
Training loss: 0.20537793636322021
Validation loss: 1.5049954319512973

Epoch: 6| Step: 8
Training loss: 0.13905532658100128
Validation loss: 1.4964009420846098

Epoch: 6| Step: 9
Training loss: 0.16090497374534607
Validation loss: 1.4838184400271344

Epoch: 6| Step: 10
Training loss: 0.0969303697347641
Validation loss: 1.5003284792746268

Epoch: 6| Step: 11
Training loss: 0.1563645601272583
Validation loss: 1.487877832945957

Epoch: 6| Step: 12
Training loss: 0.14617881178855896
Validation loss: 1.5046182499136975

Epoch: 6| Step: 13
Training loss: 0.1122540608048439
Validation loss: 1.4965016585524364

Epoch: 383| Step: 0
Training loss: 0.16916446387767792
Validation loss: 1.518074377890556

Epoch: 6| Step: 1
Training loss: 0.18007031083106995
Validation loss: 1.555030689444593

Epoch: 6| Step: 2
Training loss: 0.10015416145324707
Validation loss: 1.5650818168476064

Epoch: 6| Step: 3
Training loss: 0.24764840304851532
Validation loss: 1.5586408722785212

Epoch: 6| Step: 4
Training loss: 0.11979997903108597
Validation loss: 1.514882085143879

Epoch: 6| Step: 5
Training loss: 0.12439125776290894
Validation loss: 1.5163921169055405

Epoch: 6| Step: 6
Training loss: 0.13155217468738556
Validation loss: 1.499131638516662

Epoch: 6| Step: 7
Training loss: 0.06968283653259277
Validation loss: 1.4350981943068966

Epoch: 6| Step: 8
Training loss: 0.11667902022600174
Validation loss: 1.4515443373751897

Epoch: 6| Step: 9
Training loss: 0.24788756668567657
Validation loss: 1.4869795845400902

Epoch: 6| Step: 10
Training loss: 0.1404021978378296
Validation loss: 1.458111588672925

Epoch: 6| Step: 11
Training loss: 0.13609589636325836
Validation loss: 1.4595007947696153

Epoch: 6| Step: 12
Training loss: 0.11492743343114853
Validation loss: 1.4762973195763045

Epoch: 6| Step: 13
Training loss: 0.10253193229436874
Validation loss: 1.4835317429675852

Epoch: 384| Step: 0
Training loss: 0.13219968974590302
Validation loss: 1.5008966538213915

Epoch: 6| Step: 1
Training loss: 0.15676584839820862
Validation loss: 1.4738810587954778

Epoch: 6| Step: 2
Training loss: 0.10904011130332947
Validation loss: 1.4635902297112249

Epoch: 6| Step: 3
Training loss: 0.1416289359331131
Validation loss: 1.478839410248623

Epoch: 6| Step: 4
Training loss: 0.09479117393493652
Validation loss: 1.4687449271960924

Epoch: 6| Step: 5
Training loss: 0.11930359899997711
Validation loss: 1.4767259859269666

Epoch: 6| Step: 6
Training loss: 0.12368815392255783
Validation loss: 1.482473450322305

Epoch: 6| Step: 7
Training loss: 0.07540269196033478
Validation loss: 1.4790683484846545

Epoch: 6| Step: 8
Training loss: 0.10082735866308212
Validation loss: 1.5051308101223362

Epoch: 6| Step: 9
Training loss: 0.14118674397468567
Validation loss: 1.5101238066150295

Epoch: 6| Step: 10
Training loss: 0.1330006718635559
Validation loss: 1.5317684950367096

Epoch: 6| Step: 11
Training loss: 0.09413206577301025
Validation loss: 1.5269906866934992

Epoch: 6| Step: 12
Training loss: 0.1632823497056961
Validation loss: 1.5190445953799832

Epoch: 6| Step: 13
Training loss: 0.12137988954782486
Validation loss: 1.5142438616803897

Epoch: 385| Step: 0
Training loss: 0.1548534333705902
Validation loss: 1.5070323001953863

Epoch: 6| Step: 1
Training loss: 0.08706342428922653
Validation loss: 1.5007981408026911

Epoch: 6| Step: 2
Training loss: 0.06654221564531326
Validation loss: 1.490247800145098

Epoch: 6| Step: 3
Training loss: 0.1123589277267456
Validation loss: 1.4861719723670714

Epoch: 6| Step: 4
Training loss: 0.07198625802993774
Validation loss: 1.4788800535663482

Epoch: 6| Step: 5
Training loss: 0.12703156471252441
Validation loss: 1.4899724350180676

Epoch: 6| Step: 6
Training loss: 0.12138260900974274
Validation loss: 1.4849771940579979

Epoch: 6| Step: 7
Training loss: 0.08759482949972153
Validation loss: 1.4821799352604856

Epoch: 6| Step: 8
Training loss: 0.1117493063211441
Validation loss: 1.4779911605260705

Epoch: 6| Step: 9
Training loss: 0.12683077156543732
Validation loss: 1.4962578486370783

Epoch: 6| Step: 10
Training loss: 0.2404310554265976
Validation loss: 1.4926465762558805

Epoch: 6| Step: 11
Training loss: 0.1332758665084839
Validation loss: 1.4871706276811578

Epoch: 6| Step: 12
Training loss: 0.06826281547546387
Validation loss: 1.481931624873992

Epoch: 6| Step: 13
Training loss: 0.12299100309610367
Validation loss: 1.5058771948660574

Epoch: 386| Step: 0
Training loss: 0.09824411571025848
Validation loss: 1.485567448600646

Epoch: 6| Step: 1
Training loss: 0.1492958664894104
Validation loss: 1.4945648562523626

Epoch: 6| Step: 2
Training loss: 0.09739772230386734
Validation loss: 1.514439571288324

Epoch: 6| Step: 3
Training loss: 0.10647743940353394
Validation loss: 1.4957553763543405

Epoch: 6| Step: 4
Training loss: 0.09185099601745605
Validation loss: 1.4377240455278786

Epoch: 6| Step: 5
Training loss: 0.10439605265855789
Validation loss: 1.4298368096351624

Epoch: 6| Step: 6
Training loss: 0.12842826545238495
Validation loss: 1.4375868587083713

Epoch: 6| Step: 7
Training loss: 0.16820982098579407
Validation loss: 1.449146729643627

Epoch: 6| Step: 8
Training loss: 0.18381266295909882
Validation loss: 1.4366754344714585

Epoch: 6| Step: 9
Training loss: 0.08211201429367065
Validation loss: 1.4507148829839562

Epoch: 6| Step: 10
Training loss: 0.08866109699010849
Validation loss: 1.476690294922039

Epoch: 6| Step: 11
Training loss: 0.1645473837852478
Validation loss: 1.5173684576506257

Epoch: 6| Step: 12
Training loss: 0.11310131847858429
Validation loss: 1.543915403786526

Epoch: 6| Step: 13
Training loss: 0.17490895092487335
Validation loss: 1.5372113104789489

Epoch: 387| Step: 0
Training loss: 0.15753348171710968
Validation loss: 1.509982774334569

Epoch: 6| Step: 1
Training loss: 0.07393459230661392
Validation loss: 1.464550010619625

Epoch: 6| Step: 2
Training loss: 0.12926295399665833
Validation loss: 1.4669621734208957

Epoch: 6| Step: 3
Training loss: 0.09989333897829056
Validation loss: 1.487368095305658

Epoch: 6| Step: 4
Training loss: 0.11533885449171066
Validation loss: 1.4648731165034796

Epoch: 6| Step: 5
Training loss: 0.13576148450374603
Validation loss: 1.4562985679154754

Epoch: 6| Step: 6
Training loss: 0.144342839717865
Validation loss: 1.483748883329412

Epoch: 6| Step: 7
Training loss: 0.17107519507408142
Validation loss: 1.4397907410898516

Epoch: 6| Step: 8
Training loss: 0.14741890132427216
Validation loss: 1.4648332134369881

Epoch: 6| Step: 9
Training loss: 0.09256157279014587
Validation loss: 1.4865204275295298

Epoch: 6| Step: 10
Training loss: 0.17722159624099731
Validation loss: 1.5033679239211544

Epoch: 6| Step: 11
Training loss: 0.1302403211593628
Validation loss: 1.5074216704214773

Epoch: 6| Step: 12
Training loss: 0.0901273861527443
Validation loss: 1.544402458975392

Epoch: 6| Step: 13
Training loss: 0.14927473664283752
Validation loss: 1.5377316885097052

Epoch: 388| Step: 0
Training loss: 0.0776386708021164
Validation loss: 1.5127561771741478

Epoch: 6| Step: 1
Training loss: 0.2299395203590393
Validation loss: 1.4722991579322404

Epoch: 6| Step: 2
Training loss: 0.12308330833911896
Validation loss: 1.4742680044584378

Epoch: 6| Step: 3
Training loss: 0.18897706270217896
Validation loss: 1.4515488763009348

Epoch: 6| Step: 4
Training loss: 0.16783684492111206
Validation loss: 1.4795965712557557

Epoch: 6| Step: 5
Training loss: 0.11386089771986008
Validation loss: 1.4789644236205726

Epoch: 6| Step: 6
Training loss: 0.13504032790660858
Validation loss: 1.4487736237946378

Epoch: 6| Step: 7
Training loss: 0.17667508125305176
Validation loss: 1.4633317096259004

Epoch: 6| Step: 8
Training loss: 0.07794097065925598
Validation loss: 1.479883251651641

Epoch: 6| Step: 9
Training loss: 0.10600288212299347
Validation loss: 1.5122387165664344

Epoch: 6| Step: 10
Training loss: 0.10177528858184814
Validation loss: 1.5063264434055617

Epoch: 6| Step: 11
Training loss: 0.13516303896903992
Validation loss: 1.5232573824544107

Epoch: 6| Step: 12
Training loss: 0.043058253824710846
Validation loss: 1.4756676945635068

Epoch: 6| Step: 13
Training loss: 0.0920209288597107
Validation loss: 1.4654775383651897

Epoch: 389| Step: 0
Training loss: 0.14766144752502441
Validation loss: 1.4652517636617024

Epoch: 6| Step: 1
Training loss: 0.106113001704216
Validation loss: 1.46972075329032

Epoch: 6| Step: 2
Training loss: 0.10569590330123901
Validation loss: 1.4816176852872294

Epoch: 6| Step: 3
Training loss: 0.10567300021648407
Validation loss: 1.4761409041702107

Epoch: 6| Step: 4
Training loss: 0.1309872567653656
Validation loss: 1.4779349655233405

Epoch: 6| Step: 5
Training loss: 0.112498439848423
Validation loss: 1.4746534696189306

Epoch: 6| Step: 6
Training loss: 0.10933985561132431
Validation loss: 1.4692569439129164

Epoch: 6| Step: 7
Training loss: 0.06447715312242508
Validation loss: 1.448407328897907

Epoch: 6| Step: 8
Training loss: 0.10156860947608948
Validation loss: 1.4416497849649

Epoch: 6| Step: 9
Training loss: 0.0971231684088707
Validation loss: 1.4644976315959808

Epoch: 6| Step: 10
Training loss: 0.16957412660121918
Validation loss: 1.467863344377087

Epoch: 6| Step: 11
Training loss: 0.11008613556623459
Validation loss: 1.4722044198743758

Epoch: 6| Step: 12
Training loss: 0.10401890426874161
Validation loss: 1.4530386283833494

Epoch: 6| Step: 13
Training loss: 0.16715529561042786
Validation loss: 1.4663282658464165

Epoch: 390| Step: 0
Training loss: 0.08855316042900085
Validation loss: 1.4486660354880876

Epoch: 6| Step: 1
Training loss: 0.2073330283164978
Validation loss: 1.4544414422845329

Epoch: 6| Step: 2
Training loss: 0.16629165410995483
Validation loss: 1.4543543015756915

Epoch: 6| Step: 3
Training loss: 0.11736901104450226
Validation loss: 1.4765834833986016

Epoch: 6| Step: 4
Training loss: 0.1364557296037674
Validation loss: 1.478718360265096

Epoch: 6| Step: 5
Training loss: 0.09135880321264267
Validation loss: 1.4525140626456148

Epoch: 6| Step: 6
Training loss: 0.11301914602518082
Validation loss: 1.460077711330947

Epoch: 6| Step: 7
Training loss: 0.09154298901557922
Validation loss: 1.4292273393241308

Epoch: 6| Step: 8
Training loss: 0.12315937131643295
Validation loss: 1.4537305088453396

Epoch: 6| Step: 9
Training loss: 0.16233378648757935
Validation loss: 1.4414527570047686

Epoch: 6| Step: 10
Training loss: 0.1323963701725006
Validation loss: 1.4290874094091437

Epoch: 6| Step: 11
Training loss: 0.14999160170555115
Validation loss: 1.4520504410548876

Epoch: 6| Step: 12
Training loss: 0.08919749408960342
Validation loss: 1.4720019012369134

Epoch: 6| Step: 13
Training loss: 0.12932942807674408
Validation loss: 1.4366255742247387

Epoch: 391| Step: 0
Training loss: 0.0830354243516922
Validation loss: 1.4618530286255704

Epoch: 6| Step: 1
Training loss: 0.055788587778806686
Validation loss: 1.4696365453863656

Epoch: 6| Step: 2
Training loss: 0.09110361337661743
Validation loss: 1.4872707205434

Epoch: 6| Step: 3
Training loss: 0.11752021312713623
Validation loss: 1.5045785109202068

Epoch: 6| Step: 4
Training loss: 0.11436543613672256
Validation loss: 1.4939072862748177

Epoch: 6| Step: 5
Training loss: 0.13529714941978455
Validation loss: 1.4811711689477325

Epoch: 6| Step: 6
Training loss: 0.09307774901390076
Validation loss: 1.4669992962191183

Epoch: 6| Step: 7
Training loss: 0.20381495356559753
Validation loss: 1.4542127963035338

Epoch: 6| Step: 8
Training loss: 0.2277957946062088
Validation loss: 1.4835478490398777

Epoch: 6| Step: 9
Training loss: 0.07311585545539856
Validation loss: 1.4688867343369352

Epoch: 6| Step: 10
Training loss: 0.08472596853971481
Validation loss: 1.4558224703675957

Epoch: 6| Step: 11
Training loss: 0.09645682573318481
Validation loss: 1.4519451388748743

Epoch: 6| Step: 12
Training loss: 0.10610548406839371
Validation loss: 1.4808555501763538

Epoch: 6| Step: 13
Training loss: 0.12320467829704285
Validation loss: 1.483149440057816

Epoch: 392| Step: 0
Training loss: 0.15007995069026947
Validation loss: 1.4876884132303216

Epoch: 6| Step: 1
Training loss: 0.15196233987808228
Validation loss: 1.496598925641788

Epoch: 6| Step: 2
Training loss: 0.09279534220695496
Validation loss: 1.4649330031487249

Epoch: 6| Step: 3
Training loss: 0.09154468774795532
Validation loss: 1.469136804662725

Epoch: 6| Step: 4
Training loss: 0.11599332839250565
Validation loss: 1.4952274676292174

Epoch: 6| Step: 5
Training loss: 0.07631504535675049
Validation loss: 1.4784969347779469

Epoch: 6| Step: 6
Training loss: 0.07654091715812683
Validation loss: 1.464162274073529

Epoch: 6| Step: 7
Training loss: 0.11271066218614578
Validation loss: 1.4847860438849336

Epoch: 6| Step: 8
Training loss: 0.07437015324831009
Validation loss: 1.4776257802081365

Epoch: 6| Step: 9
Training loss: 0.1256633996963501
Validation loss: 1.4654580380326958

Epoch: 6| Step: 10
Training loss: 0.10824050009250641
Validation loss: 1.493471703221721

Epoch: 6| Step: 11
Training loss: 0.10594137012958527
Validation loss: 1.4485788511973556

Epoch: 6| Step: 12
Training loss: 0.10051707178354263
Validation loss: 1.4763668070557296

Epoch: 6| Step: 13
Training loss: 0.17793427407741547
Validation loss: 1.4745732750943912

Epoch: 393| Step: 0
Training loss: 0.10498391091823578
Validation loss: 1.4739301473863664

Epoch: 6| Step: 1
Training loss: 0.14173060655593872
Validation loss: 1.502772920875139

Epoch: 6| Step: 2
Training loss: 0.1308281421661377
Validation loss: 1.4719138183901388

Epoch: 6| Step: 3
Training loss: 0.08959561586380005
Validation loss: 1.4837216356749177

Epoch: 6| Step: 4
Training loss: 0.11215271055698395
Validation loss: 1.4451463914686633

Epoch: 6| Step: 5
Training loss: 0.09783100336790085
Validation loss: 1.4640141533267113

Epoch: 6| Step: 6
Training loss: 0.098075270652771
Validation loss: 1.4682997452315463

Epoch: 6| Step: 7
Training loss: 0.12148292362689972
Validation loss: 1.4253293493742585

Epoch: 6| Step: 8
Training loss: 0.10179221630096436
Validation loss: 1.4479312627546248

Epoch: 6| Step: 9
Training loss: 0.09693567454814911
Validation loss: 1.426471887096282

Epoch: 6| Step: 10
Training loss: 0.11609843373298645
Validation loss: 1.4235977318979078

Epoch: 6| Step: 11
Training loss: 0.07269713282585144
Validation loss: 1.4527846908056608

Epoch: 6| Step: 12
Training loss: 0.10590645670890808
Validation loss: 1.4639937890473234

Epoch: 6| Step: 13
Training loss: 0.06430646032094955
Validation loss: 1.4892515943896385

Epoch: 394| Step: 0
Training loss: 0.08056210726499557
Validation loss: 1.4838571817644182

Epoch: 6| Step: 1
Training loss: 0.08091165125370026
Validation loss: 1.4851517972125803

Epoch: 6| Step: 2
Training loss: 0.13128742575645447
Validation loss: 1.487541656340322

Epoch: 6| Step: 3
Training loss: 0.11900841444730759
Validation loss: 1.4901812230387042

Epoch: 6| Step: 4
Training loss: 0.12828919291496277
Validation loss: 1.4850663767066052

Epoch: 6| Step: 5
Training loss: 0.16209059953689575
Validation loss: 1.4698094437199254

Epoch: 6| Step: 6
Training loss: 0.10777875781059265
Validation loss: 1.4791840109773862

Epoch: 6| Step: 7
Training loss: 0.12725593149662018
Validation loss: 1.465314112683778

Epoch: 6| Step: 8
Training loss: 0.08269814401865005
Validation loss: 1.4610165857499646

Epoch: 6| Step: 9
Training loss: 0.047377366572618484
Validation loss: 1.4453098312500985

Epoch: 6| Step: 10
Training loss: 0.12064505368471146
Validation loss: 1.4543318581837479

Epoch: 6| Step: 11
Training loss: 0.13834647834300995
Validation loss: 1.4369108292364305

Epoch: 6| Step: 12
Training loss: 0.17080652713775635
Validation loss: 1.4409377741557297

Epoch: 6| Step: 13
Training loss: 0.11161671578884125
Validation loss: 1.4743965030998312

Epoch: 395| Step: 0
Training loss: 0.19717919826507568
Validation loss: 1.465639906544839

Epoch: 6| Step: 1
Training loss: 0.08474192023277283
Validation loss: 1.4719287849241687

Epoch: 6| Step: 2
Training loss: 0.10872498899698257
Validation loss: 1.4747024633551156

Epoch: 6| Step: 3
Training loss: 0.1386832296848297
Validation loss: 1.497837999815582

Epoch: 6| Step: 4
Training loss: 0.0821332037448883
Validation loss: 1.5094834848116803

Epoch: 6| Step: 5
Training loss: 0.10151366889476776
Validation loss: 1.4966647599333076

Epoch: 6| Step: 6
Training loss: 0.06818816810846329
Validation loss: 1.517041378123786

Epoch: 6| Step: 7
Training loss: 0.1659584939479828
Validation loss: 1.527563471947947

Epoch: 6| Step: 8
Training loss: 0.1561473309993744
Validation loss: 1.5332195169182234

Epoch: 6| Step: 9
Training loss: 0.2318141758441925
Validation loss: 1.5232121873927373

Epoch: 6| Step: 10
Training loss: 0.10867093503475189
Validation loss: 1.5236314624868414

Epoch: 6| Step: 11
Training loss: 0.043379396200180054
Validation loss: 1.5149839283317648

Epoch: 6| Step: 12
Training loss: 0.09658439457416534
Validation loss: 1.5154769446260186

Epoch: 6| Step: 13
Training loss: 0.0838044211268425
Validation loss: 1.5219925398467689

Epoch: 396| Step: 0
Training loss: 0.10789206624031067
Validation loss: 1.5206317504247029

Epoch: 6| Step: 1
Training loss: 0.10174630582332611
Validation loss: 1.5178451768813594

Epoch: 6| Step: 2
Training loss: 0.0908098891377449
Validation loss: 1.5404758299550703

Epoch: 6| Step: 3
Training loss: 0.14770597219467163
Validation loss: 1.5444042387829031

Epoch: 6| Step: 4
Training loss: 0.19876931607723236
Validation loss: 1.5268143517996675

Epoch: 6| Step: 5
Training loss: 0.0742652639746666
Validation loss: 1.5125531470903786

Epoch: 6| Step: 6
Training loss: 0.09192024171352386
Validation loss: 1.4825937888955558

Epoch: 6| Step: 7
Training loss: 0.13653965294361115
Validation loss: 1.4857424946241482

Epoch: 6| Step: 8
Training loss: 0.1399819701910019
Validation loss: 1.5095992216499903

Epoch: 6| Step: 9
Training loss: 0.12324708700180054
Validation loss: 1.5007505775779806

Epoch: 6| Step: 10
Training loss: 0.1031460240483284
Validation loss: 1.4902611432536956

Epoch: 6| Step: 11
Training loss: 0.15006829798221588
Validation loss: 1.4654614630565848

Epoch: 6| Step: 12
Training loss: 0.08926371484994888
Validation loss: 1.4646653372754332

Epoch: 6| Step: 13
Training loss: 0.1127530187368393
Validation loss: 1.4728061704225437

Epoch: 397| Step: 0
Training loss: 0.09757529199123383
Validation loss: 1.4631093279007943

Epoch: 6| Step: 1
Training loss: 0.16604125499725342
Validation loss: 1.455783180011216

Epoch: 6| Step: 2
Training loss: 0.13444939255714417
Validation loss: 1.4584179065560783

Epoch: 6| Step: 3
Training loss: 0.27203798294067383
Validation loss: 1.4683641823389197

Epoch: 6| Step: 4
Training loss: 0.09746336191892624
Validation loss: 1.491371621367752

Epoch: 6| Step: 5
Training loss: 0.14775797724723816
Validation loss: 1.5308608034605622

Epoch: 6| Step: 6
Training loss: 0.19676032662391663
Validation loss: 1.5170752425347604

Epoch: 6| Step: 7
Training loss: 0.09521484375
Validation loss: 1.5226765486501879

Epoch: 6| Step: 8
Training loss: 0.12286118417978287
Validation loss: 1.5264364955245808

Epoch: 6| Step: 9
Training loss: 0.11243964731693268
Validation loss: 1.4999093137761599

Epoch: 6| Step: 10
Training loss: 0.13754121959209442
Validation loss: 1.5074384443221553

Epoch: 6| Step: 11
Training loss: 0.13955488801002502
Validation loss: 1.488681459939608

Epoch: 6| Step: 12
Training loss: 0.090116947889328
Validation loss: 1.5074610325597948

Epoch: 6| Step: 13
Training loss: 0.10398752242326736
Validation loss: 1.487617378593773

Epoch: 398| Step: 0
Training loss: 0.09079253673553467
Validation loss: 1.475335048091027

Epoch: 6| Step: 1
Training loss: 0.12688881158828735
Validation loss: 1.5100118101284068

Epoch: 6| Step: 2
Training loss: 0.08062411099672318
Validation loss: 1.5129114274055726

Epoch: 6| Step: 3
Training loss: 0.11709292232990265
Validation loss: 1.5134077187507384

Epoch: 6| Step: 4
Training loss: 0.10475201904773712
Validation loss: 1.5242070805641912

Epoch: 6| Step: 5
Training loss: 0.1246841549873352
Validation loss: 1.497626600406503

Epoch: 6| Step: 6
Training loss: 0.10377641767263412
Validation loss: 1.496458653480776

Epoch: 6| Step: 7
Training loss: 0.12324338406324387
Validation loss: 1.456813520000827

Epoch: 6| Step: 8
Training loss: 0.1343151181936264
Validation loss: 1.4870399826316423

Epoch: 6| Step: 9
Training loss: 0.11310215294361115
Validation loss: 1.4798081844083724

Epoch: 6| Step: 10
Training loss: 0.1272033452987671
Validation loss: 1.4726361010664253

Epoch: 6| Step: 11
Training loss: 0.15761129558086395
Validation loss: 1.4913576341444446

Epoch: 6| Step: 12
Training loss: 0.11667846888303757
Validation loss: 1.5015491747087049

Epoch: 6| Step: 13
Training loss: 0.1520291268825531
Validation loss: 1.4819885953780143

Epoch: 399| Step: 0
Training loss: 0.1335982382297516
Validation loss: 1.494940475750995

Epoch: 6| Step: 1
Training loss: 0.08749452233314514
Validation loss: 1.511066948213885

Epoch: 6| Step: 2
Training loss: 0.1137283593416214
Validation loss: 1.4981772374081355

Epoch: 6| Step: 3
Training loss: 0.0972718596458435
Validation loss: 1.5151177247365315

Epoch: 6| Step: 4
Training loss: 0.0996570810675621
Validation loss: 1.5008961744205926

Epoch: 6| Step: 5
Training loss: 0.161250501871109
Validation loss: 1.5225383530380905

Epoch: 6| Step: 6
Training loss: 0.15479080379009247
Validation loss: 1.5394689152317662

Epoch: 6| Step: 7
Training loss: 0.1323135644197464
Validation loss: 1.5361382743363738

Epoch: 6| Step: 8
Training loss: 0.11891733109951019
Validation loss: 1.4837922268016364

Epoch: 6| Step: 9
Training loss: 0.22058114409446716
Validation loss: 1.5200968365515433

Epoch: 6| Step: 10
Training loss: 0.10375712811946869
Validation loss: 1.4737969066507073

Epoch: 6| Step: 11
Training loss: 0.145365372300148
Validation loss: 1.4759438755691692

Epoch: 6| Step: 12
Training loss: 0.10158742964267731
Validation loss: 1.486346467848747

Epoch: 6| Step: 13
Training loss: 0.16708172857761383
Validation loss: 1.4832339555986467

Epoch: 400| Step: 0
Training loss: 0.07757795602083206
Validation loss: 1.4539597457455051

Epoch: 6| Step: 1
Training loss: 0.13771985471248627
Validation loss: 1.4583629049280638

Epoch: 6| Step: 2
Training loss: 0.08475218713283539
Validation loss: 1.4705528290041032

Epoch: 6| Step: 3
Training loss: 0.140438973903656
Validation loss: 1.492377326052676

Epoch: 6| Step: 4
Training loss: 0.1436002403497696
Validation loss: 1.525885792188747

Epoch: 6| Step: 5
Training loss: 0.2508845925331116
Validation loss: 1.535213311513265

Epoch: 6| Step: 6
Training loss: 0.10835400223731995
Validation loss: 1.4866509873379943

Epoch: 6| Step: 7
Training loss: 0.09597524255514145
Validation loss: 1.4733295158673358

Epoch: 6| Step: 8
Training loss: 0.1040768101811409
Validation loss: 1.463870813769679

Epoch: 6| Step: 9
Training loss: 0.1710931807756424
Validation loss: 1.4371702260868524

Epoch: 6| Step: 10
Training loss: 0.21187222003936768
Validation loss: 1.4716120560963948

Epoch: 6| Step: 11
Training loss: 0.2636253833770752
Validation loss: 1.4627549984762747

Epoch: 6| Step: 12
Training loss: 0.18772509694099426
Validation loss: 1.4586033090468375

Epoch: 6| Step: 13
Training loss: 0.12609227001667023
Validation loss: 1.4655928983483264

Epoch: 401| Step: 0
Training loss: 0.1105804443359375
Validation loss: 1.5017658228515296

Epoch: 6| Step: 1
Training loss: 0.15490883588790894
Validation loss: 1.5157159579697477

Epoch: 6| Step: 2
Training loss: 0.17165815830230713
Validation loss: 1.5699919603204215

Epoch: 6| Step: 3
Training loss: 0.2185116708278656
Validation loss: 1.5832050385013703

Epoch: 6| Step: 4
Training loss: 0.11151890456676483
Validation loss: 1.5675218848771946

Epoch: 6| Step: 5
Training loss: 0.06847940385341644
Validation loss: 1.5178329406246063

Epoch: 6| Step: 6
Training loss: 0.12294980138540268
Validation loss: 1.4840301390617125

Epoch: 6| Step: 7
Training loss: 0.10396672785282135
Validation loss: 1.4684856822413783

Epoch: 6| Step: 8
Training loss: 0.1347779929637909
Validation loss: 1.4639443351376442

Epoch: 6| Step: 9
Training loss: 0.20066167414188385
Validation loss: 1.4532556777359338

Epoch: 6| Step: 10
Training loss: 0.16804347932338715
Validation loss: 1.472160581619509

Epoch: 6| Step: 11
Training loss: 0.18293970823287964
Validation loss: 1.465904034594054

Epoch: 6| Step: 12
Training loss: 0.16379782557487488
Validation loss: 1.473967973903943

Epoch: 6| Step: 13
Training loss: 0.2679913640022278
Validation loss: 1.4855913795450681

Epoch: 402| Step: 0
Training loss: 0.15035474300384521
Validation loss: 1.478144641845457

Epoch: 6| Step: 1
Training loss: 0.14799875020980835
Validation loss: 1.4956444117330736

Epoch: 6| Step: 2
Training loss: 0.11590489745140076
Validation loss: 1.523681463733796

Epoch: 6| Step: 3
Training loss: 0.17690208554267883
Validation loss: 1.5215934258635326

Epoch: 6| Step: 4
Training loss: 0.10432357341051102
Validation loss: 1.5029531435299945

Epoch: 6| Step: 5
Training loss: 0.09237267076969147
Validation loss: 1.5042602221171062

Epoch: 6| Step: 6
Training loss: 0.15626364946365356
Validation loss: 1.5040165019291702

Epoch: 6| Step: 7
Training loss: 0.128928542137146
Validation loss: 1.478047852875084

Epoch: 6| Step: 8
Training loss: 0.11991587281227112
Validation loss: 1.4558072468285919

Epoch: 6| Step: 9
Training loss: 0.15298756957054138
Validation loss: 1.4440535653022029

Epoch: 6| Step: 10
Training loss: 0.11808089911937714
Validation loss: 1.4552353735893004

Epoch: 6| Step: 11
Training loss: 0.1891596019268036
Validation loss: 1.4711929059797717

Epoch: 6| Step: 12
Training loss: 0.08594296872615814
Validation loss: 1.4590041304147372

Epoch: 6| Step: 13
Training loss: 0.12905031442642212
Validation loss: 1.492573579152425

Epoch: 403| Step: 0
Training loss: 0.15864820778369904
Validation loss: 1.5071573334355508

Epoch: 6| Step: 1
Training loss: 0.09747670590877533
Validation loss: 1.5197743792687692

Epoch: 6| Step: 2
Training loss: 0.12427379935979843
Validation loss: 1.515575570444907

Epoch: 6| Step: 3
Training loss: 0.10331898927688599
Validation loss: 1.4903717323016095

Epoch: 6| Step: 4
Training loss: 0.11218596249818802
Validation loss: 1.5176529845883768

Epoch: 6| Step: 5
Training loss: 0.12492942810058594
Validation loss: 1.4916481548740017

Epoch: 6| Step: 6
Training loss: 0.13342472910881042
Validation loss: 1.499974840430803

Epoch: 6| Step: 7
Training loss: 0.13550063967704773
Validation loss: 1.4952089927529777

Epoch: 6| Step: 8
Training loss: 0.08415444940328598
Validation loss: 1.488094490061524

Epoch: 6| Step: 9
Training loss: 0.13289673626422882
Validation loss: 1.4744315173036309

Epoch: 6| Step: 10
Training loss: 0.12787848711013794
Validation loss: 1.4942089280774515

Epoch: 6| Step: 11
Training loss: 0.08036593347787857
Validation loss: 1.4882638608255694

Epoch: 6| Step: 12
Training loss: 0.12586554884910583
Validation loss: 1.4867137965335642

Epoch: 6| Step: 13
Training loss: 0.06986098736524582
Validation loss: 1.521588801055826

Epoch: 404| Step: 0
Training loss: 0.06321849673986435
Validation loss: 1.5027550702453942

Epoch: 6| Step: 1
Training loss: 0.15022969245910645
Validation loss: 1.5155685870878157

Epoch: 6| Step: 2
Training loss: 0.11724162846803665
Validation loss: 1.5277594084380774

Epoch: 6| Step: 3
Training loss: 0.14557936787605286
Validation loss: 1.5072357526389502

Epoch: 6| Step: 4
Training loss: 0.07548367977142334
Validation loss: 1.4869574898032731

Epoch: 6| Step: 5
Training loss: 0.10241399705410004
Validation loss: 1.4779416989254694

Epoch: 6| Step: 6
Training loss: 0.11177869141101837
Validation loss: 1.5190506519809845

Epoch: 6| Step: 7
Training loss: 0.1882140189409256
Validation loss: 1.516677748772406

Epoch: 6| Step: 8
Training loss: 0.1544920802116394
Validation loss: 1.5386026110700382

Epoch: 6| Step: 9
Training loss: 0.12348267436027527
Validation loss: 1.5411439082955802

Epoch: 6| Step: 10
Training loss: 0.19399729371070862
Validation loss: 1.5273598099267611

Epoch: 6| Step: 11
Training loss: 0.16915011405944824
Validation loss: 1.5383353284610215

Epoch: 6| Step: 12
Training loss: 0.13264884054660797
Validation loss: 1.5024279740548903

Epoch: 6| Step: 13
Training loss: 0.13561508059501648
Validation loss: 1.4934730683603594

Epoch: 405| Step: 0
Training loss: 0.16719265282154083
Validation loss: 1.5157180825869243

Epoch: 6| Step: 1
Training loss: 0.09371067583560944
Validation loss: 1.5096119167984172

Epoch: 6| Step: 2
Training loss: 0.10616597533226013
Validation loss: 1.5203851910047634

Epoch: 6| Step: 3
Training loss: 0.10755667090415955
Validation loss: 1.5228511402683873

Epoch: 6| Step: 4
Training loss: 0.1641821563243866
Validation loss: 1.5019057822483841

Epoch: 6| Step: 5
Training loss: 0.18353129923343658
Validation loss: 1.5174752025194065

Epoch: 6| Step: 6
Training loss: 0.12625297904014587
Validation loss: 1.4964173839938255

Epoch: 6| Step: 7
Training loss: 0.10880690068006516
Validation loss: 1.5276563552118116

Epoch: 6| Step: 8
Training loss: 0.11113552749156952
Validation loss: 1.5113301802706975

Epoch: 6| Step: 9
Training loss: 0.09625385701656342
Validation loss: 1.5163909241717348

Epoch: 6| Step: 10
Training loss: 0.0930921882390976
Validation loss: 1.4810540573571318

Epoch: 6| Step: 11
Training loss: 0.12116727232933044
Validation loss: 1.4874465837273547

Epoch: 6| Step: 12
Training loss: 0.1856740117073059
Validation loss: 1.52218593576903

Epoch: 6| Step: 13
Training loss: 0.11114721745252609
Validation loss: 1.5352402784491097

Epoch: 406| Step: 0
Training loss: 0.15420207381248474
Validation loss: 1.546110228825641

Epoch: 6| Step: 1
Training loss: 0.13595308363437653
Validation loss: 1.5780002442739343

Epoch: 6| Step: 2
Training loss: 0.08245359361171722
Validation loss: 1.560962559074484

Epoch: 6| Step: 3
Training loss: 0.11451360583305359
Validation loss: 1.5413966512167325

Epoch: 6| Step: 4
Training loss: 0.08192905783653259
Validation loss: 1.4989734093348186

Epoch: 6| Step: 5
Training loss: 0.09674052894115448
Validation loss: 1.525807467840051

Epoch: 6| Step: 6
Training loss: 0.14438888430595398
Validation loss: 1.5128435691197712

Epoch: 6| Step: 7
Training loss: 0.10966872423887253
Validation loss: 1.4805501270037826

Epoch: 6| Step: 8
Training loss: 0.116288922727108
Validation loss: 1.4534520256903865

Epoch: 6| Step: 9
Training loss: 0.09503006935119629
Validation loss: 1.4533683689691688

Epoch: 6| Step: 10
Training loss: 0.14570897817611694
Validation loss: 1.469254643686356

Epoch: 6| Step: 11
Training loss: 0.09775860607624054
Validation loss: 1.4726487680148053

Epoch: 6| Step: 12
Training loss: 0.1574832648038864
Validation loss: 1.4750918239675543

Epoch: 6| Step: 13
Training loss: 0.09961143881082535
Validation loss: 1.4672898182304956

Epoch: 407| Step: 0
Training loss: 0.0916115939617157
Validation loss: 1.4741506858538556

Epoch: 6| Step: 1
Training loss: 0.11849438399076462
Validation loss: 1.4871652241676085

Epoch: 6| Step: 2
Training loss: 0.11457034200429916
Validation loss: 1.4715762766458655

Epoch: 6| Step: 3
Training loss: 0.12311860918998718
Validation loss: 1.4712166696466424

Epoch: 6| Step: 4
Training loss: 0.07271362841129303
Validation loss: 1.477200618354223

Epoch: 6| Step: 5
Training loss: 0.09008244425058365
Validation loss: 1.476827722723766

Epoch: 6| Step: 6
Training loss: 0.11544162034988403
Validation loss: 1.4620709842251194

Epoch: 6| Step: 7
Training loss: 0.11093724519014359
Validation loss: 1.4827341738567557

Epoch: 6| Step: 8
Training loss: 0.09732925146818161
Validation loss: 1.469586423648301

Epoch: 6| Step: 9
Training loss: 0.09878003597259521
Validation loss: 1.4737328701121832

Epoch: 6| Step: 10
Training loss: 0.09224862605333328
Validation loss: 1.4795610289419852

Epoch: 6| Step: 11
Training loss: 0.12745434045791626
Validation loss: 1.4858089211166545

Epoch: 6| Step: 12
Training loss: 0.19378851354122162
Validation loss: 1.4985562216851018

Epoch: 6| Step: 13
Training loss: 0.17285923659801483
Validation loss: 1.4878411651939474

Epoch: 408| Step: 0
Training loss: 0.13637083768844604
Validation loss: 1.4953161593406432

Epoch: 6| Step: 1
Training loss: 0.12183354049921036
Validation loss: 1.462808806409118

Epoch: 6| Step: 2
Training loss: 0.11270580440759659
Validation loss: 1.4752523232531805

Epoch: 6| Step: 3
Training loss: 0.16917553544044495
Validation loss: 1.4840750822456934

Epoch: 6| Step: 4
Training loss: 0.13754619657993317
Validation loss: 1.4719097178469422

Epoch: 6| Step: 5
Training loss: 0.13258014619350433
Validation loss: 1.4666080423580703

Epoch: 6| Step: 6
Training loss: 0.0953703448176384
Validation loss: 1.501546964850477

Epoch: 6| Step: 7
Training loss: 0.19593355059623718
Validation loss: 1.4770850161070466

Epoch: 6| Step: 8
Training loss: 0.0913274884223938
Validation loss: 1.4855654021745086

Epoch: 6| Step: 9
Training loss: 0.13871274888515472
Validation loss: 1.5002767283429381

Epoch: 6| Step: 10
Training loss: 0.08642043173313141
Validation loss: 1.501134369962959

Epoch: 6| Step: 11
Training loss: 0.08530185371637344
Validation loss: 1.454503829761218

Epoch: 6| Step: 12
Training loss: 0.09413426369428635
Validation loss: 1.4683376371219594

Epoch: 6| Step: 13
Training loss: 0.05685093626379967
Validation loss: 1.4557736535226145

Epoch: 409| Step: 0
Training loss: 0.16264334321022034
Validation loss: 1.468949394841348

Epoch: 6| Step: 1
Training loss: 0.07940875738859177
Validation loss: 1.449897616140304

Epoch: 6| Step: 2
Training loss: 0.08866184949874878
Validation loss: 1.495188315709432

Epoch: 6| Step: 3
Training loss: 0.09408921003341675
Validation loss: 1.4760640769876459

Epoch: 6| Step: 4
Training loss: 0.07012590765953064
Validation loss: 1.484536099177535

Epoch: 6| Step: 5
Training loss: 0.11322806775569916
Validation loss: 1.4665714130606702

Epoch: 6| Step: 6
Training loss: 0.08968791365623474
Validation loss: 1.475021832732744

Epoch: 6| Step: 7
Training loss: 0.16057619452476501
Validation loss: 1.4675121140736405

Epoch: 6| Step: 8
Training loss: 0.16364175081253052
Validation loss: 1.504161359161459

Epoch: 6| Step: 9
Training loss: 0.12126031517982483
Validation loss: 1.4764570625879432

Epoch: 6| Step: 10
Training loss: 0.11406825482845306
Validation loss: 1.5079564817490116

Epoch: 6| Step: 11
Training loss: 0.07844355702400208
Validation loss: 1.4836051874263312

Epoch: 6| Step: 12
Training loss: 0.12221968173980713
Validation loss: 1.4698757228030954

Epoch: 6| Step: 13
Training loss: 0.05491837114095688
Validation loss: 1.4811382832065705

Epoch: 410| Step: 0
Training loss: 0.13037805259227753
Validation loss: 1.4701825393143522

Epoch: 6| Step: 1
Training loss: 0.11516903340816498
Validation loss: 1.4648388258872493

Epoch: 6| Step: 2
Training loss: 0.0709204450249672
Validation loss: 1.4715630700511317

Epoch: 6| Step: 3
Training loss: 0.11209222674369812
Validation loss: 1.4626943936911962

Epoch: 6| Step: 4
Training loss: 0.14045126736164093
Validation loss: 1.4574178239350677

Epoch: 6| Step: 5
Training loss: 0.08443447202444077
Validation loss: 1.4630656524371075

Epoch: 6| Step: 6
Training loss: 0.11241993308067322
Validation loss: 1.4643006517041115

Epoch: 6| Step: 7
Training loss: 0.11666430532932281
Validation loss: 1.4738844389556556

Epoch: 6| Step: 8
Training loss: 0.1301366090774536
Validation loss: 1.4724198682333833

Epoch: 6| Step: 9
Training loss: 0.13128268718719482
Validation loss: 1.481658366418654

Epoch: 6| Step: 10
Training loss: 0.06620683521032333
Validation loss: 1.4844726362536032

Epoch: 6| Step: 11
Training loss: 0.13333608210086823
Validation loss: 1.4693820514986593

Epoch: 6| Step: 12
Training loss: 0.18153519928455353
Validation loss: 1.477453104911312

Epoch: 6| Step: 13
Training loss: 0.13245293498039246
Validation loss: 1.4885676740318217

Epoch: 411| Step: 0
Training loss: 0.11108658462762833
Validation loss: 1.4932345151901245

Epoch: 6| Step: 1
Training loss: 0.11330893635749817
Validation loss: 1.521433032968993

Epoch: 6| Step: 2
Training loss: 0.10422946512699127
Validation loss: 1.5266430134414344

Epoch: 6| Step: 3
Training loss: 0.19134941697120667
Validation loss: 1.514507451365071

Epoch: 6| Step: 4
Training loss: 0.1689068078994751
Validation loss: 1.5286523283168834

Epoch: 6| Step: 5
Training loss: 0.10627774894237518
Validation loss: 1.5220526085104993

Epoch: 6| Step: 6
Training loss: 0.1904476284980774
Validation loss: 1.486617056272363

Epoch: 6| Step: 7
Training loss: 0.15294528007507324
Validation loss: 1.4922900443435998

Epoch: 6| Step: 8
Training loss: 0.19511441886425018
Validation loss: 1.4776860321721723

Epoch: 6| Step: 9
Training loss: 0.0897151529788971
Validation loss: 1.4745712921183596

Epoch: 6| Step: 10
Training loss: 0.13216859102249146
Validation loss: 1.4488812595285394

Epoch: 6| Step: 11
Training loss: 0.2002098262310028
Validation loss: 1.4252510839892971

Epoch: 6| Step: 12
Training loss: 0.12653633952140808
Validation loss: 1.4394112889484694

Epoch: 6| Step: 13
Training loss: 0.14069974422454834
Validation loss: 1.41858660533864

Epoch: 412| Step: 0
Training loss: 0.12393303960561752
Validation loss: 1.4137464979643464

Epoch: 6| Step: 1
Training loss: 0.12054824829101562
Validation loss: 1.4343130280894618

Epoch: 6| Step: 2
Training loss: 0.10176540911197662
Validation loss: 1.4203890754330544

Epoch: 6| Step: 3
Training loss: 0.14682303369045258
Validation loss: 1.4305701012252479

Epoch: 6| Step: 4
Training loss: 0.10203012824058533
Validation loss: 1.455375406690823

Epoch: 6| Step: 5
Training loss: 0.10560446977615356
Validation loss: 1.4376734290071713

Epoch: 6| Step: 6
Training loss: 0.11345815658569336
Validation loss: 1.4491286188043573

Epoch: 6| Step: 7
Training loss: 0.15030473470687866
Validation loss: 1.4571317011310208

Epoch: 6| Step: 8
Training loss: 0.08030281960964203
Validation loss: 1.4489161083775182

Epoch: 6| Step: 9
Training loss: 0.11534976214170456
Validation loss: 1.4548854815062655

Epoch: 6| Step: 10
Training loss: 0.10550886392593384
Validation loss: 1.4553722027809388

Epoch: 6| Step: 11
Training loss: 0.1035320907831192
Validation loss: 1.4325730095627487

Epoch: 6| Step: 12
Training loss: 0.11416276544332504
Validation loss: 1.4519723410247474

Epoch: 6| Step: 13
Training loss: 0.11442060023546219
Validation loss: 1.467849632745148

Epoch: 413| Step: 0
Training loss: 0.09873548150062561
Validation loss: 1.4498141452830324

Epoch: 6| Step: 1
Training loss: 0.10863585770130157
Validation loss: 1.437427996307291

Epoch: 6| Step: 2
Training loss: 0.09965461492538452
Validation loss: 1.4767858469358055

Epoch: 6| Step: 3
Training loss: 0.11221850663423538
Validation loss: 1.4523583945407663

Epoch: 6| Step: 4
Training loss: 0.07499632239341736
Validation loss: 1.4531761536034205

Epoch: 6| Step: 5
Training loss: 0.08755611628293991
Validation loss: 1.4486998845172185

Epoch: 6| Step: 6
Training loss: 0.11553436517715454
Validation loss: 1.4715326729641165

Epoch: 6| Step: 7
Training loss: 0.14144489169120789
Validation loss: 1.4535501413447882

Epoch: 6| Step: 8
Training loss: 0.10381205379962921
Validation loss: 1.4531078223259217

Epoch: 6| Step: 9
Training loss: 0.08710519969463348
Validation loss: 1.465623051889481

Epoch: 6| Step: 10
Training loss: 0.12003064155578613
Validation loss: 1.4476522578988025

Epoch: 6| Step: 11
Training loss: 0.1318356841802597
Validation loss: 1.46965253737665

Epoch: 6| Step: 12
Training loss: 0.12334681302309036
Validation loss: 1.4840783572966052

Epoch: 6| Step: 13
Training loss: 0.09792200475931168
Validation loss: 1.4431351282263314

Epoch: 414| Step: 0
Training loss: 0.1271812468767166
Validation loss: 1.461030440945779

Epoch: 6| Step: 1
Training loss: 0.08936247229576111
Validation loss: 1.4465973543864425

Epoch: 6| Step: 2
Training loss: 0.077794149518013
Validation loss: 1.4531540345120173

Epoch: 6| Step: 3
Training loss: 0.05561178922653198
Validation loss: 1.457021092855802

Epoch: 6| Step: 4
Training loss: 0.10452622175216675
Validation loss: 1.4376284665958856

Epoch: 6| Step: 5
Training loss: 0.10765377432107925
Validation loss: 1.4404164578325005

Epoch: 6| Step: 6
Training loss: 0.08281784504652023
Validation loss: 1.4755394907407864

Epoch: 6| Step: 7
Training loss: 0.09081541001796722
Validation loss: 1.4555875851262001

Epoch: 6| Step: 8
Training loss: 0.09488840401172638
Validation loss: 1.4607463773860727

Epoch: 6| Step: 9
Training loss: 0.07522068917751312
Validation loss: 1.4524714895474014

Epoch: 6| Step: 10
Training loss: 0.08099298924207687
Validation loss: 1.4351934668838338

Epoch: 6| Step: 11
Training loss: 0.04929163306951523
Validation loss: 1.454145355891156

Epoch: 6| Step: 12
Training loss: 0.15203890204429626
Validation loss: 1.465839985878237

Epoch: 6| Step: 13
Training loss: 0.15667115151882172
Validation loss: 1.4792218144221971

Epoch: 415| Step: 0
Training loss: 0.04339835047721863
Validation loss: 1.475481661417151

Epoch: 6| Step: 1
Training loss: 0.14427277445793152
Validation loss: 1.4870338786032893

Epoch: 6| Step: 2
Training loss: 0.075068399310112
Validation loss: 1.4744907553477953

Epoch: 6| Step: 3
Training loss: 0.11204858124256134
Validation loss: 1.4652300124527307

Epoch: 6| Step: 4
Training loss: 0.14508619904518127
Validation loss: 1.48144624053791

Epoch: 6| Step: 5
Training loss: 0.17154531180858612
Validation loss: 1.4657591376253354

Epoch: 6| Step: 6
Training loss: 0.11629906296730042
Validation loss: 1.4606414982067641

Epoch: 6| Step: 7
Training loss: 0.08031930029392242
Validation loss: 1.4885009693843063

Epoch: 6| Step: 8
Training loss: 0.16305723786354065
Validation loss: 1.4972225722446237

Epoch: 6| Step: 9
Training loss: 0.10212031751871109
Validation loss: 1.4601071342345207

Epoch: 6| Step: 10
Training loss: 0.13131842017173767
Validation loss: 1.4721497310105192

Epoch: 6| Step: 11
Training loss: 0.07590954005718231
Validation loss: 1.4777715039509598

Epoch: 6| Step: 12
Training loss: 0.11388778686523438
Validation loss: 1.5054190081934775

Epoch: 6| Step: 13
Training loss: 0.07269445806741714
Validation loss: 1.5256167663040983

Epoch: 416| Step: 0
Training loss: 0.10962706804275513
Validation loss: 1.480685595543154

Epoch: 6| Step: 1
Training loss: 0.15369883179664612
Validation loss: 1.4878338716363395

Epoch: 6| Step: 2
Training loss: 0.09058642387390137
Validation loss: 1.4492546243052329

Epoch: 6| Step: 3
Training loss: 0.08654559403657913
Validation loss: 1.4661808347189298

Epoch: 6| Step: 4
Training loss: 0.11947455257177353
Validation loss: 1.4578102404071438

Epoch: 6| Step: 5
Training loss: 0.07315295189619064
Validation loss: 1.446016570573212

Epoch: 6| Step: 6
Training loss: 0.11310629546642303
Validation loss: 1.4342772447934715

Epoch: 6| Step: 7
Training loss: 0.08152221888303757
Validation loss: 1.4325190885092622

Epoch: 6| Step: 8
Training loss: 0.07395058125257492
Validation loss: 1.4587125432106756

Epoch: 6| Step: 9
Training loss: 0.07027914375066757
Validation loss: 1.4323564998565181

Epoch: 6| Step: 10
Training loss: 0.08910530060529709
Validation loss: 1.4670402619146532

Epoch: 6| Step: 11
Training loss: 0.11368802189826965
Validation loss: 1.4934315296911425

Epoch: 6| Step: 12
Training loss: 0.1557483971118927
Validation loss: 1.4876722135851461

Epoch: 6| Step: 13
Training loss: 0.060153961181640625
Validation loss: 1.4747851202564854

Epoch: 417| Step: 0
Training loss: 0.07716383039951324
Validation loss: 1.459677332191057

Epoch: 6| Step: 1
Training loss: 0.11162243783473969
Validation loss: 1.473076178181556

Epoch: 6| Step: 2
Training loss: 0.11023157835006714
Validation loss: 1.4817586541175842

Epoch: 6| Step: 3
Training loss: 0.07326245307922363
Validation loss: 1.4674246234278525

Epoch: 6| Step: 4
Training loss: 0.1359831988811493
Validation loss: 1.4579758592831191

Epoch: 6| Step: 5
Training loss: 0.09405583888292313
Validation loss: 1.481982247803801

Epoch: 6| Step: 6
Training loss: 0.08346377313137054
Validation loss: 1.4489071343534736

Epoch: 6| Step: 7
Training loss: 0.08355294167995453
Validation loss: 1.4584497982455837

Epoch: 6| Step: 8
Training loss: 0.1280219405889511
Validation loss: 1.4461558249688917

Epoch: 6| Step: 9
Training loss: 0.08167684078216553
Validation loss: 1.4563298827858382

Epoch: 6| Step: 10
Training loss: 0.08484162390232086
Validation loss: 1.4404613433345672

Epoch: 6| Step: 11
Training loss: 0.08707831799983978
Validation loss: 1.4293599884997132

Epoch: 6| Step: 12
Training loss: 0.060646943747997284
Validation loss: 1.4448013203118437

Epoch: 6| Step: 13
Training loss: 0.1702980250120163
Validation loss: 1.407129959393573

Epoch: 418| Step: 0
Training loss: 0.07763268798589706
Validation loss: 1.421425747615035

Epoch: 6| Step: 1
Training loss: 0.08092892169952393
Validation loss: 1.4286320337685205

Epoch: 6| Step: 2
Training loss: 0.09348021447658539
Validation loss: 1.4233394502311625

Epoch: 6| Step: 3
Training loss: 0.08847349137067795
Validation loss: 1.412885146756326

Epoch: 6| Step: 4
Training loss: 0.07525396347045898
Validation loss: 1.4331535677756033

Epoch: 6| Step: 5
Training loss: 0.09560396522283554
Validation loss: 1.427010097811299

Epoch: 6| Step: 6
Training loss: 0.11381970345973969
Validation loss: 1.4435301980664652

Epoch: 6| Step: 7
Training loss: 0.08120885491371155
Validation loss: 1.4424248600518832

Epoch: 6| Step: 8
Training loss: 0.12323061376810074
Validation loss: 1.4256862466053297

Epoch: 6| Step: 9
Training loss: 0.07957148551940918
Validation loss: 1.4540554105594594

Epoch: 6| Step: 10
Training loss: 0.11057295650243759
Validation loss: 1.4677544601501957

Epoch: 6| Step: 11
Training loss: 0.11748223751783371
Validation loss: 1.4313717926702192

Epoch: 6| Step: 12
Training loss: 0.0952431783080101
Validation loss: 1.4301893544453446

Epoch: 6| Step: 13
Training loss: 0.15019996464252472
Validation loss: 1.4527460375139791

Epoch: 419| Step: 0
Training loss: 0.07699378579854965
Validation loss: 1.431547200807961

Epoch: 6| Step: 1
Training loss: 0.07929164916276932
Validation loss: 1.4372910543154644

Epoch: 6| Step: 2
Training loss: 0.1474420577287674
Validation loss: 1.4286896509508933

Epoch: 6| Step: 3
Training loss: 0.07356789708137512
Validation loss: 1.4420559239643875

Epoch: 6| Step: 4
Training loss: 0.09834560751914978
Validation loss: 1.4237089483968672

Epoch: 6| Step: 5
Training loss: 0.14220619201660156
Validation loss: 1.4359443597896124

Epoch: 6| Step: 6
Training loss: 0.11684881150722504
Validation loss: 1.4187543533181632

Epoch: 6| Step: 7
Training loss: 0.07649862766265869
Validation loss: 1.4147200834366582

Epoch: 6| Step: 8
Training loss: 0.0641869604587555
Validation loss: 1.428243931903634

Epoch: 6| Step: 9
Training loss: 0.08297174423933029
Validation loss: 1.4626859157316145

Epoch: 6| Step: 10
Training loss: 0.13232192397117615
Validation loss: 1.4654295521397744

Epoch: 6| Step: 11
Training loss: 0.13757142424583435
Validation loss: 1.491283534675516

Epoch: 6| Step: 12
Training loss: 0.12955860793590546
Validation loss: 1.525965904676786

Epoch: 6| Step: 13
Training loss: 0.12198816239833832
Validation loss: 1.5052561426675448

Epoch: 420| Step: 0
Training loss: 0.09036105871200562
Validation loss: 1.4816736790441698

Epoch: 6| Step: 1
Training loss: 0.1421489268541336
Validation loss: 1.4690156008607598

Epoch: 6| Step: 2
Training loss: 0.07156220823526382
Validation loss: 1.4302710461360153

Epoch: 6| Step: 3
Training loss: 0.20950034260749817
Validation loss: 1.448891193636002

Epoch: 6| Step: 4
Training loss: 0.10046341270208359
Validation loss: 1.4344669785550845

Epoch: 6| Step: 5
Training loss: 0.117425836622715
Validation loss: 1.4520471570312337

Epoch: 6| Step: 6
Training loss: 0.1667613387107849
Validation loss: 1.4636842653315554

Epoch: 6| Step: 7
Training loss: 0.13237303495407104
Validation loss: 1.4597080061512608

Epoch: 6| Step: 8
Training loss: 0.08219237625598907
Validation loss: 1.4842682538493988

Epoch: 6| Step: 9
Training loss: 0.15272954106330872
Validation loss: 1.510008788877918

Epoch: 6| Step: 10
Training loss: 0.07527470588684082
Validation loss: 1.5390638343749508

Epoch: 6| Step: 11
Training loss: 0.17916029691696167
Validation loss: 1.535271208773377

Epoch: 6| Step: 12
Training loss: 0.09873434156179428
Validation loss: 1.4759602777419552

Epoch: 6| Step: 13
Training loss: 0.09865320473909378
Validation loss: 1.4618205242259528

Epoch: 421| Step: 0
Training loss: 0.18067675828933716
Validation loss: 1.4226010589189426

Epoch: 6| Step: 1
Training loss: 0.06458834558725357
Validation loss: 1.4221693828541746

Epoch: 6| Step: 2
Training loss: 0.1224215105175972
Validation loss: 1.409362978832696

Epoch: 6| Step: 3
Training loss: 0.10984837263822556
Validation loss: 1.408841888750753

Epoch: 6| Step: 4
Training loss: 0.13149015605449677
Validation loss: 1.4027349615609774

Epoch: 6| Step: 5
Training loss: 0.10973235964775085
Validation loss: 1.4069104624050919

Epoch: 6| Step: 6
Training loss: 0.17065921425819397
Validation loss: 1.4015628201987154

Epoch: 6| Step: 7
Training loss: 0.1009780541062355
Validation loss: 1.4246553861966698

Epoch: 6| Step: 8
Training loss: 0.13314276933670044
Validation loss: 1.4125889821719098

Epoch: 6| Step: 9
Training loss: 0.13429366052150726
Validation loss: 1.4221202308131802

Epoch: 6| Step: 10
Training loss: 0.15767332911491394
Validation loss: 1.4610135106630222

Epoch: 6| Step: 11
Training loss: 0.11459392309188843
Validation loss: 1.4681785260477374

Epoch: 6| Step: 12
Training loss: 0.1296725869178772
Validation loss: 1.4628307729639032

Epoch: 6| Step: 13
Training loss: 0.15477868914604187
Validation loss: 1.4799548054254184

Epoch: 422| Step: 0
Training loss: 0.14334732294082642
Validation loss: 1.470637309935785

Epoch: 6| Step: 1
Training loss: 0.11820034682750702
Validation loss: 1.5006457887670046

Epoch: 6| Step: 2
Training loss: 0.14421366155147552
Validation loss: 1.4915558394565378

Epoch: 6| Step: 3
Training loss: 0.07802335172891617
Validation loss: 1.4654870545992287

Epoch: 6| Step: 4
Training loss: 0.1298486888408661
Validation loss: 1.4579321530557448

Epoch: 6| Step: 5
Training loss: 0.08409617096185684
Validation loss: 1.4794781823312082

Epoch: 6| Step: 6
Training loss: 0.08304902166128159
Validation loss: 1.4347450579366376

Epoch: 6| Step: 7
Training loss: 0.09694783389568329
Validation loss: 1.45332036864373

Epoch: 6| Step: 8
Training loss: 0.12926465272903442
Validation loss: 1.4686300728910713

Epoch: 6| Step: 9
Training loss: 0.08218878507614136
Validation loss: 1.4827472099693872

Epoch: 6| Step: 10
Training loss: 0.1030707135796547
Validation loss: 1.503798875757443

Epoch: 6| Step: 11
Training loss: 0.09625454246997833
Validation loss: 1.497267473128534

Epoch: 6| Step: 12
Training loss: 0.14203454554080963
Validation loss: 1.487887950353725

Epoch: 6| Step: 13
Training loss: 0.06520698964595795
Validation loss: 1.4998715282768331

Epoch: 423| Step: 0
Training loss: 0.13271984457969666
Validation loss: 1.4818285126839914

Epoch: 6| Step: 1
Training loss: 0.07404040545225143
Validation loss: 1.4581020967934721

Epoch: 6| Step: 2
Training loss: 0.11392297595739365
Validation loss: 1.4634769462770032

Epoch: 6| Step: 3
Training loss: 0.0703374445438385
Validation loss: 1.4548009313562864

Epoch: 6| Step: 4
Training loss: 0.09581819176673889
Validation loss: 1.4526291085827736

Epoch: 6| Step: 5
Training loss: 0.0880858451128006
Validation loss: 1.4376626860710882

Epoch: 6| Step: 6
Training loss: 0.09471554309129715
Validation loss: 1.4595211834035895

Epoch: 6| Step: 7
Training loss: 0.07470734417438507
Validation loss: 1.4592224346694125

Epoch: 6| Step: 8
Training loss: 0.14532074332237244
Validation loss: 1.4412308636532034

Epoch: 6| Step: 9
Training loss: 0.1257859766483307
Validation loss: 1.4586539281311857

Epoch: 6| Step: 10
Training loss: 0.07821783423423767
Validation loss: 1.450363100215953

Epoch: 6| Step: 11
Training loss: 0.06792300939559937
Validation loss: 1.448667501890531

Epoch: 6| Step: 12
Training loss: 0.08986973762512207
Validation loss: 1.4490809261157949

Epoch: 6| Step: 13
Training loss: 0.13696417212486267
Validation loss: 1.4460798963423698

Epoch: 424| Step: 0
Training loss: 0.10405879467725754
Validation loss: 1.4788397460855462

Epoch: 6| Step: 1
Training loss: 0.12695735692977905
Validation loss: 1.4813474711551462

Epoch: 6| Step: 2
Training loss: 0.07489092648029327
Validation loss: 1.4604884591153873

Epoch: 6| Step: 3
Training loss: 0.06674300134181976
Validation loss: 1.4976412327058855

Epoch: 6| Step: 4
Training loss: 0.06381161510944366
Validation loss: 1.5171576494811683

Epoch: 6| Step: 5
Training loss: 0.10346320271492004
Validation loss: 1.5285111460634457

Epoch: 6| Step: 6
Training loss: 0.08982215076684952
Validation loss: 1.4931982114750852

Epoch: 6| Step: 7
Training loss: 0.14189347624778748
Validation loss: 1.5132718368243145

Epoch: 6| Step: 8
Training loss: 0.13889247179031372
Validation loss: 1.4923195351836502

Epoch: 6| Step: 9
Training loss: 0.1159994900226593
Validation loss: 1.4680797489740516

Epoch: 6| Step: 10
Training loss: 0.08847787231206894
Validation loss: 1.4601144790649414

Epoch: 6| Step: 11
Training loss: 0.07980024069547653
Validation loss: 1.43249124480832

Epoch: 6| Step: 12
Training loss: 0.12025430053472519
Validation loss: 1.4307148969301613

Epoch: 6| Step: 13
Training loss: 0.1392841637134552
Validation loss: 1.4356596572424776

Epoch: 425| Step: 0
Training loss: 0.09939467906951904
Validation loss: 1.4568957077559603

Epoch: 6| Step: 1
Training loss: 0.18383876979351044
Validation loss: 1.464697673756589

Epoch: 6| Step: 2
Training loss: 0.12860266864299774
Validation loss: 1.4766773434095486

Epoch: 6| Step: 3
Training loss: 0.15808001160621643
Validation loss: 1.5483908768623107

Epoch: 6| Step: 4
Training loss: 0.14944159984588623
Validation loss: 1.533010116187475

Epoch: 6| Step: 5
Training loss: 0.07585848122835159
Validation loss: 1.5261505944754488

Epoch: 6| Step: 6
Training loss: 0.17013703286647797
Validation loss: 1.5269018809000652

Epoch: 6| Step: 7
Training loss: 0.15135517716407776
Validation loss: 1.479219792991556

Epoch: 6| Step: 8
Training loss: 0.12100711464881897
Validation loss: 1.4442224951200588

Epoch: 6| Step: 9
Training loss: 0.10742606967687607
Validation loss: 1.465935496873753

Epoch: 6| Step: 10
Training loss: 0.11908062547445297
Validation loss: 1.4555483915472542

Epoch: 6| Step: 11
Training loss: 0.17074328660964966
Validation loss: 1.4657037642694288

Epoch: 6| Step: 12
Training loss: 0.13785725831985474
Validation loss: 1.4668457815724034

Epoch: 6| Step: 13
Training loss: 0.1857919692993164
Validation loss: 1.4788983573195755

Epoch: 426| Step: 0
Training loss: 0.07906077802181244
Validation loss: 1.4778548946944616

Epoch: 6| Step: 1
Training loss: 0.07993253320455551
Validation loss: 1.5042649725432038

Epoch: 6| Step: 2
Training loss: 0.15819892287254333
Validation loss: 1.5281916190219182

Epoch: 6| Step: 3
Training loss: 0.147853285074234
Validation loss: 1.5392649096827353

Epoch: 6| Step: 4
Training loss: 0.2118944674730301
Validation loss: 1.5344048533388364

Epoch: 6| Step: 5
Training loss: 0.1915551722049713
Validation loss: 1.533445978677401

Epoch: 6| Step: 6
Training loss: 0.13577312231063843
Validation loss: 1.480926985381752

Epoch: 6| Step: 7
Training loss: 0.09640096127986908
Validation loss: 1.481159787024221

Epoch: 6| Step: 8
Training loss: 0.07664111256599426
Validation loss: 1.4460771160741006

Epoch: 6| Step: 9
Training loss: 0.14705350995063782
Validation loss: 1.4615558847304313

Epoch: 6| Step: 10
Training loss: 0.13136497139930725
Validation loss: 1.4412266144188501

Epoch: 6| Step: 11
Training loss: 0.21966037154197693
Validation loss: 1.4663619584934686

Epoch: 6| Step: 12
Training loss: 0.12431282550096512
Validation loss: 1.4486419584161492

Epoch: 6| Step: 13
Training loss: 0.05825784429907799
Validation loss: 1.4577256851298834

Epoch: 427| Step: 0
Training loss: 0.058553002774715424
Validation loss: 1.4830952164947346

Epoch: 6| Step: 1
Training loss: 0.07485511153936386
Validation loss: 1.4892116336412327

Epoch: 6| Step: 2
Training loss: 0.11058943718671799
Validation loss: 1.5011416442932621

Epoch: 6| Step: 3
Training loss: 0.08962293714284897
Validation loss: 1.5229788941721762

Epoch: 6| Step: 4
Training loss: 0.10057012736797333
Validation loss: 1.536220985074197

Epoch: 6| Step: 5
Training loss: 0.1142987310886383
Validation loss: 1.530976547989794

Epoch: 6| Step: 6
Training loss: 0.11585134267807007
Validation loss: 1.487910250181793

Epoch: 6| Step: 7
Training loss: 0.1415245532989502
Validation loss: 1.4809499504745647

Epoch: 6| Step: 8
Training loss: 0.09534846246242523
Validation loss: 1.4839171055824525

Epoch: 6| Step: 9
Training loss: 0.14777378737926483
Validation loss: 1.4881971830962806

Epoch: 6| Step: 10
Training loss: 0.09976532310247421
Validation loss: 1.467398411484175

Epoch: 6| Step: 11
Training loss: 0.09889517724514008
Validation loss: 1.4600424099993963

Epoch: 6| Step: 12
Training loss: 0.14426305890083313
Validation loss: 1.4513498967693699

Epoch: 6| Step: 13
Training loss: 0.11544284224510193
Validation loss: 1.4422588515025314

Epoch: 428| Step: 0
Training loss: 0.07545818388462067
Validation loss: 1.4490101260523642

Epoch: 6| Step: 1
Training loss: 0.1198081523180008
Validation loss: 1.449429686351489

Epoch: 6| Step: 2
Training loss: 0.054272450506687164
Validation loss: 1.4684972570788475

Epoch: 6| Step: 3
Training loss: 0.11963687092065811
Validation loss: 1.4692061255055089

Epoch: 6| Step: 4
Training loss: 0.09799852222204208
Validation loss: 1.4926660060882568

Epoch: 6| Step: 5
Training loss: 0.08612591028213501
Validation loss: 1.494823517337922

Epoch: 6| Step: 6
Training loss: 0.08574531227350235
Validation loss: 1.4862239911992063

Epoch: 6| Step: 7
Training loss: 0.13428422808647156
Validation loss: 1.4992732271071403

Epoch: 6| Step: 8
Training loss: 0.0837307721376419
Validation loss: 1.4957931669809486

Epoch: 6| Step: 9
Training loss: 0.10712245851755142
Validation loss: 1.495371542951112

Epoch: 6| Step: 10
Training loss: 0.0869346484541893
Validation loss: 1.515043640649447

Epoch: 6| Step: 11
Training loss: 0.08198755979537964
Validation loss: 1.4968984447499758

Epoch: 6| Step: 12
Training loss: 0.07611793279647827
Validation loss: 1.4717004260709208

Epoch: 6| Step: 13
Training loss: 0.11460445821285248
Validation loss: 1.4864884268852971

Epoch: 429| Step: 0
Training loss: 0.09418871253728867
Validation loss: 1.474127930979575

Epoch: 6| Step: 1
Training loss: 0.054523345082998276
Validation loss: 1.4698664885695263

Epoch: 6| Step: 2
Training loss: 0.09055570513010025
Validation loss: 1.4482693838816818

Epoch: 6| Step: 3
Training loss: 0.08434760570526123
Validation loss: 1.4741888635901994

Epoch: 6| Step: 4
Training loss: 0.0683412104845047
Validation loss: 1.4572449589288363

Epoch: 6| Step: 5
Training loss: 0.10903437435626984
Validation loss: 1.4770993648036834

Epoch: 6| Step: 6
Training loss: 0.16385890543460846
Validation loss: 1.4822347740973196

Epoch: 6| Step: 7
Training loss: 0.12908212840557098
Validation loss: 1.4948572638214275

Epoch: 6| Step: 8
Training loss: 0.1367371380329132
Validation loss: 1.4592582339881568

Epoch: 6| Step: 9
Training loss: 0.11695098876953125
Validation loss: 1.446671429500785

Epoch: 6| Step: 10
Training loss: 0.1066436767578125
Validation loss: 1.4624341790394118

Epoch: 6| Step: 11
Training loss: 0.07384610176086426
Validation loss: 1.452212247797238

Epoch: 6| Step: 12
Training loss: 0.12257488071918488
Validation loss: 1.4595449316886164

Epoch: 6| Step: 13
Training loss: 0.05266974866390228
Validation loss: 1.454664966111542

Epoch: 430| Step: 0
Training loss: 0.09484134614467621
Validation loss: 1.4619277677228373

Epoch: 6| Step: 1
Training loss: 0.10925078392028809
Validation loss: 1.452594599416179

Epoch: 6| Step: 2
Training loss: 0.10971766710281372
Validation loss: 1.4461926875575897

Epoch: 6| Step: 3
Training loss: 0.10953528434038162
Validation loss: 1.4715440734740226

Epoch: 6| Step: 4
Training loss: 0.1288057416677475
Validation loss: 1.4760524239591373

Epoch: 6| Step: 5
Training loss: 0.1086544543504715
Validation loss: 1.4618658128605093

Epoch: 6| Step: 6
Training loss: 0.05767356604337692
Validation loss: 1.4675532694785827

Epoch: 6| Step: 7
Training loss: 0.1663680523633957
Validation loss: 1.4604641660567252

Epoch: 6| Step: 8
Training loss: 0.10183164477348328
Validation loss: 1.4528427085568827

Epoch: 6| Step: 9
Training loss: 0.11887337267398834
Validation loss: 1.4536697569713797

Epoch: 6| Step: 10
Training loss: 0.08881387114524841
Validation loss: 1.4550506799451766

Epoch: 6| Step: 11
Training loss: 0.12113358080387115
Validation loss: 1.4410604584601618

Epoch: 6| Step: 12
Training loss: 0.06205229461193085
Validation loss: 1.4494461269788845

Epoch: 6| Step: 13
Training loss: 0.10280659794807434
Validation loss: 1.464485131284242

Epoch: 431| Step: 0
Training loss: 0.11374201625585556
Validation loss: 1.494060371511726

Epoch: 6| Step: 1
Training loss: 0.07702823728322983
Validation loss: 1.5047137077136705

Epoch: 6| Step: 2
Training loss: 0.12936832010746002
Validation loss: 1.525386735957156

Epoch: 6| Step: 3
Training loss: 0.0724702775478363
Validation loss: 1.5114975206313594

Epoch: 6| Step: 4
Training loss: 0.11316186934709549
Validation loss: 1.478938651341264

Epoch: 6| Step: 5
Training loss: 0.06068594381213188
Validation loss: 1.4871987758144256

Epoch: 6| Step: 6
Training loss: 0.10616423189640045
Validation loss: 1.472003706039921

Epoch: 6| Step: 7
Training loss: 0.10118430852890015
Validation loss: 1.4506438566792397

Epoch: 6| Step: 8
Training loss: 0.12345615029335022
Validation loss: 1.4438971588688512

Epoch: 6| Step: 9
Training loss: 0.09920155256986618
Validation loss: 1.4677286404435352

Epoch: 6| Step: 10
Training loss: 0.07301310449838638
Validation loss: 1.4373058119127828

Epoch: 6| Step: 11
Training loss: 0.10231371968984604
Validation loss: 1.439808540446784

Epoch: 6| Step: 12
Training loss: 0.08447305858135223
Validation loss: 1.4884508835372103

Epoch: 6| Step: 13
Training loss: 0.08670217543840408
Validation loss: 1.4921766455455492

Epoch: 432| Step: 0
Training loss: 0.1091541200876236
Validation loss: 1.4981486566605107

Epoch: 6| Step: 1
Training loss: 0.09266199916601181
Validation loss: 1.4713125908246605

Epoch: 6| Step: 2
Training loss: 0.04818547144532204
Validation loss: 1.5053425431251526

Epoch: 6| Step: 3
Training loss: 0.09122122824192047
Validation loss: 1.515597169117261

Epoch: 6| Step: 4
Training loss: 0.191442608833313
Validation loss: 1.5001223580811613

Epoch: 6| Step: 5
Training loss: 0.16826769709587097
Validation loss: 1.5077783132112155

Epoch: 6| Step: 6
Training loss: 0.09615209698677063
Validation loss: 1.4644063531711538

Epoch: 6| Step: 7
Training loss: 0.08286842703819275
Validation loss: 1.463822139206753

Epoch: 6| Step: 8
Training loss: 0.1364971399307251
Validation loss: 1.4679415097800634

Epoch: 6| Step: 9
Training loss: 0.14475762844085693
Validation loss: 1.4536911672161472

Epoch: 6| Step: 10
Training loss: 0.11914149671792984
Validation loss: 1.4532682498296101

Epoch: 6| Step: 11
Training loss: 0.19579415023326874
Validation loss: 1.4544232711997083

Epoch: 6| Step: 12
Training loss: 0.15999288856983185
Validation loss: 1.4617853139036445

Epoch: 6| Step: 13
Training loss: 0.08995655179023743
Validation loss: 1.4454002585462344

Epoch: 433| Step: 0
Training loss: 0.058553267270326614
Validation loss: 1.4538226819807483

Epoch: 6| Step: 1
Training loss: 0.09017863869667053
Validation loss: 1.4478564852027482

Epoch: 6| Step: 2
Training loss: 0.1386229395866394
Validation loss: 1.477298681453992

Epoch: 6| Step: 3
Training loss: 0.11800965666770935
Validation loss: 1.4745961081597112

Epoch: 6| Step: 4
Training loss: 0.12980426847934723
Validation loss: 1.4705582331585627

Epoch: 6| Step: 5
Training loss: 0.09647071361541748
Validation loss: 1.461977021668547

Epoch: 6| Step: 6
Training loss: 0.06410781294107437
Validation loss: 1.4558118158771145

Epoch: 6| Step: 7
Training loss: 0.05036557838320732
Validation loss: 1.4632750057405042

Epoch: 6| Step: 8
Training loss: 0.1886335015296936
Validation loss: 1.4439499903750677

Epoch: 6| Step: 9
Training loss: 0.08822047710418701
Validation loss: 1.4347158619152602

Epoch: 6| Step: 10
Training loss: 0.12334099411964417
Validation loss: 1.442020603405532

Epoch: 6| Step: 11
Training loss: 0.09703042358160019
Validation loss: 1.4549645980199177

Epoch: 6| Step: 12
Training loss: 0.09615874290466309
Validation loss: 1.4486806508033507

Epoch: 6| Step: 13
Training loss: 0.07579215615987778
Validation loss: 1.4381516864222865

Epoch: 434| Step: 0
Training loss: 0.10966084897518158
Validation loss: 1.436946822750953

Epoch: 6| Step: 1
Training loss: 0.10945629328489304
Validation loss: 1.442464287563037

Epoch: 6| Step: 2
Training loss: 0.11386404931545258
Validation loss: 1.4567335664585073

Epoch: 6| Step: 3
Training loss: 0.09583186358213425
Validation loss: 1.4807131546799854

Epoch: 6| Step: 4
Training loss: 0.11673475056886673
Validation loss: 1.4806325551002257

Epoch: 6| Step: 5
Training loss: 0.0869043618440628
Validation loss: 1.4635358446387834

Epoch: 6| Step: 6
Training loss: 0.09951706230640411
Validation loss: 1.4899839714009275

Epoch: 6| Step: 7
Training loss: 0.05313432216644287
Validation loss: 1.454627247266872

Epoch: 6| Step: 8
Training loss: 0.08813796937465668
Validation loss: 1.4269480205351306

Epoch: 6| Step: 9
Training loss: 0.08797065168619156
Validation loss: 1.4536665126841555

Epoch: 6| Step: 10
Training loss: 0.0630282610654831
Validation loss: 1.4669273668719875

Epoch: 6| Step: 11
Training loss: 0.07721400260925293
Validation loss: 1.480746078234847

Epoch: 6| Step: 12
Training loss: 0.13497167825698853
Validation loss: 1.4667204067271242

Epoch: 6| Step: 13
Training loss: 0.13574530184268951
Validation loss: 1.478928235269362

Epoch: 435| Step: 0
Training loss: 0.0973915159702301
Validation loss: 1.4675292020202966

Epoch: 6| Step: 1
Training loss: 0.05892576277256012
Validation loss: 1.476441571789403

Epoch: 6| Step: 2
Training loss: 0.07676670700311661
Validation loss: 1.4674895066086964

Epoch: 6| Step: 3
Training loss: 0.05908837914466858
Validation loss: 1.4970887168761222

Epoch: 6| Step: 4
Training loss: 0.13470475375652313
Validation loss: 1.4588373181640462

Epoch: 6| Step: 5
Training loss: 0.08320717513561249
Validation loss: 1.4786200292648808

Epoch: 6| Step: 6
Training loss: 0.12218141555786133
Validation loss: 1.4589712978691183

Epoch: 6| Step: 7
Training loss: 0.14192979037761688
Validation loss: 1.4463896405312322

Epoch: 6| Step: 8
Training loss: 0.1205613762140274
Validation loss: 1.4588540856556227

Epoch: 6| Step: 9
Training loss: 0.06822076439857483
Validation loss: 1.4543132000072028

Epoch: 6| Step: 10
Training loss: 0.1289777159690857
Validation loss: 1.4439980137732722

Epoch: 6| Step: 11
Training loss: 0.107204869389534
Validation loss: 1.4631912028917702

Epoch: 6| Step: 12
Training loss: 0.08184171468019485
Validation loss: 1.444652739391532

Epoch: 6| Step: 13
Training loss: 0.0978192463517189
Validation loss: 1.4512462026329451

Epoch: 436| Step: 0
Training loss: 0.061883848160505295
Validation loss: 1.4280953022741503

Epoch: 6| Step: 1
Training loss: 0.11386207491159439
Validation loss: 1.439812364757702

Epoch: 6| Step: 2
Training loss: 0.06756322085857391
Validation loss: 1.4396635114505727

Epoch: 6| Step: 3
Training loss: 0.08460141718387604
Validation loss: 1.4300606186671923

Epoch: 6| Step: 4
Training loss: 0.1074182540178299
Validation loss: 1.4442532024075907

Epoch: 6| Step: 5
Training loss: 0.10460859537124634
Validation loss: 1.4589497350877332

Epoch: 6| Step: 6
Training loss: 0.13934966921806335
Validation loss: 1.449495106615046

Epoch: 6| Step: 7
Training loss: 0.11997374147176743
Validation loss: 1.4529960450305734

Epoch: 6| Step: 8
Training loss: 0.08453388512134552
Validation loss: 1.4443852068275533

Epoch: 6| Step: 9
Training loss: 0.10746929049491882
Validation loss: 1.4315440629118232

Epoch: 6| Step: 10
Training loss: 0.11717104911804199
Validation loss: 1.4280163735471747

Epoch: 6| Step: 11
Training loss: 0.07493197917938232
Validation loss: 1.4339588739538704

Epoch: 6| Step: 12
Training loss: 0.06518122553825378
Validation loss: 1.4538716282895816

Epoch: 6| Step: 13
Training loss: 0.09823840111494064
Validation loss: 1.4593610430276522

Epoch: 437| Step: 0
Training loss: 0.06881308555603027
Validation loss: 1.453729716680383

Epoch: 6| Step: 1
Training loss: 0.09502033144235611
Validation loss: 1.4715359326331847

Epoch: 6| Step: 2
Training loss: 0.08018793910741806
Validation loss: 1.4349501632875012

Epoch: 6| Step: 3
Training loss: 0.11772194504737854
Validation loss: 1.4545269986634612

Epoch: 6| Step: 4
Training loss: 0.13235485553741455
Validation loss: 1.446089139548681

Epoch: 6| Step: 5
Training loss: 0.1298736035823822
Validation loss: 1.4413130283355713

Epoch: 6| Step: 6
Training loss: 0.0553571842610836
Validation loss: 1.4251743772978425

Epoch: 6| Step: 7
Training loss: 0.05329296737909317
Validation loss: 1.4028955608285882

Epoch: 6| Step: 8
Training loss: 0.08077778667211533
Validation loss: 1.4173988167957594

Epoch: 6| Step: 9
Training loss: 0.09101158380508423
Validation loss: 1.4093703416086012

Epoch: 6| Step: 10
Training loss: 0.1292290985584259
Validation loss: 1.4119529685666483

Epoch: 6| Step: 11
Training loss: 0.051545388996601105
Validation loss: 1.4370549449356653

Epoch: 6| Step: 12
Training loss: 0.08102181553840637
Validation loss: 1.4245558361853323

Epoch: 6| Step: 13
Training loss: 0.102516308426857
Validation loss: 1.436383464003122

Epoch: 438| Step: 0
Training loss: 0.061214692890644073
Validation loss: 1.4307837306812246

Epoch: 6| Step: 1
Training loss: 0.07679478824138641
Validation loss: 1.442305048306783

Epoch: 6| Step: 2
Training loss: 0.10502681136131287
Validation loss: 1.4664917146005938

Epoch: 6| Step: 3
Training loss: 0.07793885469436646
Validation loss: 1.4682781850138018

Epoch: 6| Step: 4
Training loss: 0.04312439262866974
Validation loss: 1.4554551583464428

Epoch: 6| Step: 5
Training loss: 0.07259134948253632
Validation loss: 1.4451987192194948

Epoch: 6| Step: 6
Training loss: 0.10771284252405167
Validation loss: 1.4803880632564586

Epoch: 6| Step: 7
Training loss: 0.08167268335819244
Validation loss: 1.445120055188415

Epoch: 6| Step: 8
Training loss: 0.06805700808763504
Validation loss: 1.4613323839761878

Epoch: 6| Step: 9
Training loss: 0.13966411352157593
Validation loss: 1.4477111985606532

Epoch: 6| Step: 10
Training loss: 0.13312578201293945
Validation loss: 1.4546546192579373

Epoch: 6| Step: 11
Training loss: 0.1347273290157318
Validation loss: 1.4522398383386674

Epoch: 6| Step: 12
Training loss: 0.08531960099935532
Validation loss: 1.453049264928346

Epoch: 6| Step: 13
Training loss: 0.06252074241638184
Validation loss: 1.4833774194922498

Epoch: 439| Step: 0
Training loss: 0.08830180764198303
Validation loss: 1.4840267704379173

Epoch: 6| Step: 1
Training loss: 0.1407671868801117
Validation loss: 1.4788219134012859

Epoch: 6| Step: 2
Training loss: 0.12086382508277893
Validation loss: 1.4819188194890176

Epoch: 6| Step: 3
Training loss: 0.11009421944618225
Validation loss: 1.4633778782301052

Epoch: 6| Step: 4
Training loss: 0.06044277176260948
Validation loss: 1.4322781126986268

Epoch: 6| Step: 5
Training loss: 0.11693299561738968
Validation loss: 1.459984928049067

Epoch: 6| Step: 6
Training loss: 0.1226942166686058
Validation loss: 1.4623025437837005

Epoch: 6| Step: 7
Training loss: 0.08454294502735138
Validation loss: 1.4482375934559812

Epoch: 6| Step: 8
Training loss: 0.09528094530105591
Validation loss: 1.4432032678716926

Epoch: 6| Step: 9
Training loss: 0.1271563321352005
Validation loss: 1.445826151678639

Epoch: 6| Step: 10
Training loss: 0.11096794903278351
Validation loss: 1.4522479939204391

Epoch: 6| Step: 11
Training loss: 0.07789374142885208
Validation loss: 1.4850135157185216

Epoch: 6| Step: 12
Training loss: 0.10904472321271896
Validation loss: 1.4947499177789176

Epoch: 6| Step: 13
Training loss: 0.24629797041416168
Validation loss: 1.5186643023644724

Epoch: 440| Step: 0
Training loss: 0.1480325311422348
Validation loss: 1.53349176145369

Epoch: 6| Step: 1
Training loss: 0.2167615294456482
Validation loss: 1.5491016487921438

Epoch: 6| Step: 2
Training loss: 0.1310032606124878
Validation loss: 1.5205695193300965

Epoch: 6| Step: 3
Training loss: 0.05437881499528885
Validation loss: 1.478689311653055

Epoch: 6| Step: 4
Training loss: 0.1180911511182785
Validation loss: 1.4615970914081862

Epoch: 6| Step: 5
Training loss: 0.13462695479393005
Validation loss: 1.452459595536673

Epoch: 6| Step: 6
Training loss: 0.11011335253715515
Validation loss: 1.4697094553260392

Epoch: 6| Step: 7
Training loss: 0.11859894543886185
Validation loss: 1.4430697118082354

Epoch: 6| Step: 8
Training loss: 0.11748980730772018
Validation loss: 1.452924250274576

Epoch: 6| Step: 9
Training loss: 0.10255548357963562
Validation loss: 1.4212658379667549

Epoch: 6| Step: 10
Training loss: 0.08090344071388245
Validation loss: 1.4207883188801427

Epoch: 6| Step: 11
Training loss: 0.0771007314324379
Validation loss: 1.459596389083452

Epoch: 6| Step: 12
Training loss: 0.14079426229000092
Validation loss: 1.4320201937870314

Epoch: 6| Step: 13
Training loss: 0.08821947872638702
Validation loss: 1.4876886593398226

Epoch: 441| Step: 0
Training loss: 0.15284903347492218
Validation loss: 1.4899461846197806

Epoch: 6| Step: 1
Training loss: 0.18754050135612488
Validation loss: 1.4676774265945598

Epoch: 6| Step: 2
Training loss: 0.11620143055915833
Validation loss: 1.470971481774443

Epoch: 6| Step: 3
Training loss: 0.05109105259180069
Validation loss: 1.4501972236940939

Epoch: 6| Step: 4
Training loss: 0.1344687044620514
Validation loss: 1.4653721522259455

Epoch: 6| Step: 5
Training loss: 0.10791172832250595
Validation loss: 1.4779050850099134

Epoch: 6| Step: 6
Training loss: 0.11722976714372635
Validation loss: 1.5238275092135194

Epoch: 6| Step: 7
Training loss: 0.15622083842754364
Validation loss: 1.5070509141491306

Epoch: 6| Step: 8
Training loss: 0.2144986391067505
Validation loss: 1.5049556339940717

Epoch: 6| Step: 9
Training loss: 0.12401565164327621
Validation loss: 1.5180298641163816

Epoch: 6| Step: 10
Training loss: 0.11333692818880081
Validation loss: 1.5093253222844933

Epoch: 6| Step: 11
Training loss: 0.10088766366243362
Validation loss: 1.5235114071958809

Epoch: 6| Step: 12
Training loss: 0.12325941026210785
Validation loss: 1.5085150003433228

Epoch: 6| Step: 13
Training loss: 0.08095857501029968
Validation loss: 1.5156701239206458

Epoch: 442| Step: 0
Training loss: 0.08634331822395325
Validation loss: 1.494761888698865

Epoch: 6| Step: 1
Training loss: 0.08442815393209457
Validation loss: 1.4693496022173154

Epoch: 6| Step: 2
Training loss: 0.09596005827188492
Validation loss: 1.478565381419274

Epoch: 6| Step: 3
Training loss: 0.09922207146883011
Validation loss: 1.4944000436413674

Epoch: 6| Step: 4
Training loss: 0.07702077925205231
Validation loss: 1.5026073904447659

Epoch: 6| Step: 5
Training loss: 0.1960957646369934
Validation loss: 1.4914568829280075

Epoch: 6| Step: 6
Training loss: 0.07846781611442566
Validation loss: 1.4715975279449134

Epoch: 6| Step: 7
Training loss: 0.06680777668952942
Validation loss: 1.4608579617674633

Epoch: 6| Step: 8
Training loss: 0.07006369531154633
Validation loss: 1.4430726574313255

Epoch: 6| Step: 9
Training loss: 0.09978554397821426
Validation loss: 1.4411576806858022

Epoch: 6| Step: 10
Training loss: 0.09598444402217865
Validation loss: 1.422097199706621

Epoch: 6| Step: 11
Training loss: 0.06928884238004684
Validation loss: 1.4541690811034171

Epoch: 6| Step: 12
Training loss: 0.08835010230541229
Validation loss: 1.420895722604567

Epoch: 6| Step: 13
Training loss: 0.18827633559703827
Validation loss: 1.442193579930131

Epoch: 443| Step: 0
Training loss: 0.041551001369953156
Validation loss: 1.4482589921643656

Epoch: 6| Step: 1
Training loss: 0.11066782474517822
Validation loss: 1.452440607932306

Epoch: 6| Step: 2
Training loss: 0.12272384762763977
Validation loss: 1.47718261390604

Epoch: 6| Step: 3
Training loss: 0.07470852136611938
Validation loss: 1.4670673288324827

Epoch: 6| Step: 4
Training loss: 0.1040663868188858
Validation loss: 1.4906681250500422

Epoch: 6| Step: 5
Training loss: 0.10501864552497864
Validation loss: 1.4954145749409993

Epoch: 6| Step: 6
Training loss: 0.06751552224159241
Validation loss: 1.4825872016209427

Epoch: 6| Step: 7
Training loss: 0.08456320315599442
Validation loss: 1.4713841702348442

Epoch: 6| Step: 8
Training loss: 0.13075284659862518
Validation loss: 1.4647774042621735

Epoch: 6| Step: 9
Training loss: 0.09034692496061325
Validation loss: 1.4757661165729645

Epoch: 6| Step: 10
Training loss: 0.0647735595703125
Validation loss: 1.474474117320071

Epoch: 6| Step: 11
Training loss: 0.15874984860420227
Validation loss: 1.4363776945298719

Epoch: 6| Step: 12
Training loss: 0.1176290437579155
Validation loss: 1.4772366118687454

Epoch: 6| Step: 13
Training loss: 0.078745037317276
Validation loss: 1.4525851665004608

Epoch: 444| Step: 0
Training loss: 0.14455397427082062
Validation loss: 1.446899119243827

Epoch: 6| Step: 1
Training loss: 0.061690762639045715
Validation loss: 1.4428563669163694

Epoch: 6| Step: 2
Training loss: 0.10354892909526825
Validation loss: 1.4490121551739272

Epoch: 6| Step: 3
Training loss: 0.08166894316673279
Validation loss: 1.414039913044181

Epoch: 6| Step: 4
Training loss: 0.07488421350717545
Validation loss: 1.4258453166613014

Epoch: 6| Step: 5
Training loss: 0.10836304724216461
Validation loss: 1.4164606601961198

Epoch: 6| Step: 6
Training loss: 0.09846264868974686
Validation loss: 1.4195316248042609

Epoch: 6| Step: 7
Training loss: 0.08818569779396057
Validation loss: 1.4383033642204859

Epoch: 6| Step: 8
Training loss: 0.05806358903646469
Validation loss: 1.4296664922468123

Epoch: 6| Step: 9
Training loss: 0.15987861156463623
Validation loss: 1.4201764778424335

Epoch: 6| Step: 10
Training loss: 0.07353466004133224
Validation loss: 1.4551477060523084

Epoch: 6| Step: 11
Training loss: 0.08375328034162521
Validation loss: 1.4392977068501134

Epoch: 6| Step: 12
Training loss: 0.08857765048742294
Validation loss: 1.4376660803312897

Epoch: 6| Step: 13
Training loss: 0.041624173521995544
Validation loss: 1.4481884766650457

Epoch: 445| Step: 0
Training loss: 0.061838071793317795
Validation loss: 1.4357482681992233

Epoch: 6| Step: 1
Training loss: 0.10502912849187851
Validation loss: 1.4440113985410301

Epoch: 6| Step: 2
Training loss: 0.10539668798446655
Validation loss: 1.4460158988993654

Epoch: 6| Step: 3
Training loss: 0.08334740996360779
Validation loss: 1.474139452621501

Epoch: 6| Step: 4
Training loss: 0.08870530128479004
Validation loss: 1.4547533694133963

Epoch: 6| Step: 5
Training loss: 0.042715296149253845
Validation loss: 1.4658421060090423

Epoch: 6| Step: 6
Training loss: 0.06153368204832077
Validation loss: 1.4748638560695033

Epoch: 6| Step: 7
Training loss: 0.09611489623785019
Validation loss: 1.4795091613646476

Epoch: 6| Step: 8
Training loss: 0.0770568996667862
Validation loss: 1.4665741087287985

Epoch: 6| Step: 9
Training loss: 0.06378604471683502
Validation loss: 1.479026158650716

Epoch: 6| Step: 10
Training loss: 0.09124993532896042
Validation loss: 1.460766670524433

Epoch: 6| Step: 11
Training loss: 0.07212354987859726
Validation loss: 1.4489776652346376

Epoch: 6| Step: 12
Training loss: 0.13454926013946533
Validation loss: 1.448134821589275

Epoch: 6| Step: 13
Training loss: 0.10781973600387573
Validation loss: 1.4522363242282663

Epoch: 446| Step: 0
Training loss: 0.07280930876731873
Validation loss: 1.4519101894030007

Epoch: 6| Step: 1
Training loss: 0.10783614218235016
Validation loss: 1.4697412239607943

Epoch: 6| Step: 2
Training loss: 0.09555789828300476
Validation loss: 1.4783418165740145

Epoch: 6| Step: 3
Training loss: 0.11616939306259155
Validation loss: 1.4753595231681742

Epoch: 6| Step: 4
Training loss: 0.12126941978931427
Validation loss: 1.4440129982527865

Epoch: 6| Step: 5
Training loss: 0.06531191617250443
Validation loss: 1.4803237280538004

Epoch: 6| Step: 6
Training loss: 0.08050395548343658
Validation loss: 1.4480907647840437

Epoch: 6| Step: 7
Training loss: 0.09813082963228226
Validation loss: 1.4837512495697185

Epoch: 6| Step: 8
Training loss: 0.10067098587751389
Validation loss: 1.4714304913756668

Epoch: 6| Step: 9
Training loss: 0.08255014568567276
Validation loss: 1.4696736617754864

Epoch: 6| Step: 10
Training loss: 0.0932946503162384
Validation loss: 1.4519407813267042

Epoch: 6| Step: 11
Training loss: 0.09192319214344025
Validation loss: 1.4381474794880036

Epoch: 6| Step: 12
Training loss: 0.08906953781843185
Validation loss: 1.4590967585963588

Epoch: 6| Step: 13
Training loss: 0.07582340389490128
Validation loss: 1.4754138620950843

Epoch: 447| Step: 0
Training loss: 0.11227832734584808
Validation loss: 1.4578966171510759

Epoch: 6| Step: 1
Training loss: 0.050453513860702515
Validation loss: 1.446503242497803

Epoch: 6| Step: 2
Training loss: 0.07993665337562561
Validation loss: 1.4427691390437465

Epoch: 6| Step: 3
Training loss: 0.06751681864261627
Validation loss: 1.4691404655415525

Epoch: 6| Step: 4
Training loss: 0.1395694464445114
Validation loss: 1.4707075600982995

Epoch: 6| Step: 5
Training loss: 0.09441680461168289
Validation loss: 1.464920251600204

Epoch: 6| Step: 6
Training loss: 0.09131572395563126
Validation loss: 1.47720871433135

Epoch: 6| Step: 7
Training loss: 0.1420588493347168
Validation loss: 1.452121820501102

Epoch: 6| Step: 8
Training loss: 0.10678710043430328
Validation loss: 1.4746026044250817

Epoch: 6| Step: 9
Training loss: 0.07886537909507751
Validation loss: 1.4611709835708782

Epoch: 6| Step: 10
Training loss: 0.05257672071456909
Validation loss: 1.450306870604074

Epoch: 6| Step: 11
Training loss: 0.05721119046211243
Validation loss: 1.4616849307091004

Epoch: 6| Step: 12
Training loss: 0.128176748752594
Validation loss: 1.4351067273847518

Epoch: 6| Step: 13
Training loss: 0.06792884320020676
Validation loss: 1.4557156594850684

Epoch: 448| Step: 0
Training loss: 0.0776548981666565
Validation loss: 1.4366344328849547

Epoch: 6| Step: 1
Training loss: 0.11896418780088425
Validation loss: 1.453140902262862

Epoch: 6| Step: 2
Training loss: 0.0653315931558609
Validation loss: 1.4428175162243586

Epoch: 6| Step: 3
Training loss: 0.09010642766952515
Validation loss: 1.4536707003911336

Epoch: 6| Step: 4
Training loss: 0.0750463604927063
Validation loss: 1.4705663432357132

Epoch: 6| Step: 5
Training loss: 0.0901651382446289
Validation loss: 1.4659661490430114

Epoch: 6| Step: 6
Training loss: 0.0965111032128334
Validation loss: 1.4598924421495008

Epoch: 6| Step: 7
Training loss: 0.09315225481987
Validation loss: 1.4705337324450094

Epoch: 6| Step: 8
Training loss: 0.04583807289600372
Validation loss: 1.4440523770547682

Epoch: 6| Step: 9
Training loss: 0.0929175466299057
Validation loss: 1.4569708121720182

Epoch: 6| Step: 10
Training loss: 0.059794578701257706
Validation loss: 1.4740158588655534

Epoch: 6| Step: 11
Training loss: 0.0852457731962204
Validation loss: 1.4583618858809113

Epoch: 6| Step: 12
Training loss: 0.15393170714378357
Validation loss: 1.4738731717550626

Epoch: 6| Step: 13
Training loss: 0.08901156485080719
Validation loss: 1.4729071009543635

Epoch: 449| Step: 0
Training loss: 0.05731650069355965
Validation loss: 1.4601723635068504

Epoch: 6| Step: 1
Training loss: 0.09701798111200333
Validation loss: 1.4518642169173046

Epoch: 6| Step: 2
Training loss: 0.1241307482123375
Validation loss: 1.439533615625033

Epoch: 6| Step: 3
Training loss: 0.0588916540145874
Validation loss: 1.448074850984799

Epoch: 6| Step: 4
Training loss: 0.06733936816453934
Validation loss: 1.4584900076671312

Epoch: 6| Step: 5
Training loss: 0.09608837962150574
Validation loss: 1.4290370364342966

Epoch: 6| Step: 6
Training loss: 0.0761769488453865
Validation loss: 1.4540899536942924

Epoch: 6| Step: 7
Training loss: 0.07496383786201477
Validation loss: 1.43868173450552

Epoch: 6| Step: 8
Training loss: 0.1003522276878357
Validation loss: 1.4599020211927352

Epoch: 6| Step: 9
Training loss: 0.05982110649347305
Validation loss: 1.4636496202920073

Epoch: 6| Step: 10
Training loss: 0.05726215988397598
Validation loss: 1.457073305242805

Epoch: 6| Step: 11
Training loss: 0.13605748116970062
Validation loss: 1.4777625235178138

Epoch: 6| Step: 12
Training loss: 0.06835992634296417
Validation loss: 1.4654971297069261

Epoch: 6| Step: 13
Training loss: 0.11822699010372162
Validation loss: 1.489909097712527

Epoch: 450| Step: 0
Training loss: 0.09618711471557617
Validation loss: 1.4919224887765863

Epoch: 6| Step: 1
Training loss: 0.13858464360237122
Validation loss: 1.4791258663259528

Epoch: 6| Step: 2
Training loss: 0.06933177262544632
Validation loss: 1.470931799181046

Epoch: 6| Step: 3
Training loss: 0.09736911207437515
Validation loss: 1.4640279662224553

Epoch: 6| Step: 4
Training loss: 0.05185849219560623
Validation loss: 1.4697807527357531

Epoch: 6| Step: 5
Training loss: 0.06876584887504578
Validation loss: 1.4471658416973647

Epoch: 6| Step: 6
Training loss: 0.11629767715930939
Validation loss: 1.446391656834592

Epoch: 6| Step: 7
Training loss: 0.11525622010231018
Validation loss: 1.446067214012146

Epoch: 6| Step: 8
Training loss: 0.13776680827140808
Validation loss: 1.4454773869565738

Epoch: 6| Step: 9
Training loss: 0.062409907579422
Validation loss: 1.47101596478493

Epoch: 6| Step: 10
Training loss: 0.05885167419910431
Validation loss: 1.4368869719966766

Epoch: 6| Step: 11
Training loss: 0.10213738679885864
Validation loss: 1.4583721590298477

Epoch: 6| Step: 12
Training loss: 0.06348661333322525
Validation loss: 1.4690814915523733

Epoch: 6| Step: 13
Training loss: 0.10800894349813461
Validation loss: 1.465084243846196

Testing loss: 2.150801001654731
