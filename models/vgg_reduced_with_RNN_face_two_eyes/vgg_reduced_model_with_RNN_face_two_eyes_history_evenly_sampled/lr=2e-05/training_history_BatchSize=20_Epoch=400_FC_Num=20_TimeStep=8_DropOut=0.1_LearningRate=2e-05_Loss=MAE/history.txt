Epoch: 1| Step: 0
Training loss: 4.483036994934082
Validation loss: 5.214166892472134

Epoch: 5| Step: 1
Training loss: 5.642189979553223
Validation loss: 5.1835043302146335

Epoch: 5| Step: 2
Training loss: 5.281355857849121
Validation loss: 5.156378510177777

Epoch: 5| Step: 3
Training loss: 4.39630126953125
Validation loss: 5.1300472033921105

Epoch: 5| Step: 4
Training loss: 4.234116554260254
Validation loss: 5.101577938243907

Epoch: 5| Step: 5
Training loss: 4.51958703994751
Validation loss: 5.069326969885057

Epoch: 5| Step: 6
Training loss: 5.495960235595703
Validation loss: 5.032989958281158

Epoch: 5| Step: 7
Training loss: 4.8776068687438965
Validation loss: 4.992882426067065

Epoch: 5| Step: 8
Training loss: 4.19395637512207
Validation loss: 4.947121963706068

Epoch: 5| Step: 9
Training loss: 5.4411725997924805
Validation loss: 4.895711955203805

Epoch: 5| Step: 10
Training loss: 4.724512577056885
Validation loss: 4.838604322043798

Epoch: 2| Step: 0
Training loss: 4.656350612640381
Validation loss: 4.7761517391409924

Epoch: 5| Step: 1
Training loss: 5.341256141662598
Validation loss: 4.708356308680709

Epoch: 5| Step: 2
Training loss: 3.5712475776672363
Validation loss: 4.639768010826521

Epoch: 5| Step: 3
Training loss: 4.614947319030762
Validation loss: 4.563424066830707

Epoch: 5| Step: 4
Training loss: 4.801346778869629
Validation loss: 4.485770897198749

Epoch: 5| Step: 5
Training loss: 3.002255916595459
Validation loss: 4.407532312536753

Epoch: 5| Step: 6
Training loss: 3.269737958908081
Validation loss: 4.331033168300506

Epoch: 5| Step: 7
Training loss: 4.924752235412598
Validation loss: 4.259098737470565

Epoch: 5| Step: 8
Training loss: 4.3737077713012695
Validation loss: 4.185163503052086

Epoch: 5| Step: 9
Training loss: 3.3968377113342285
Validation loss: 4.115748420838387

Epoch: 5| Step: 10
Training loss: 4.501377582550049
Validation loss: 4.055434985827374

Epoch: 3| Step: 0
Training loss: 3.601886749267578
Validation loss: 3.99902920569143

Epoch: 5| Step: 1
Training loss: 3.042426109313965
Validation loss: 3.9512202098805416

Epoch: 5| Step: 2
Training loss: 3.9642300605773926
Validation loss: 3.906753904076033

Epoch: 5| Step: 3
Training loss: 4.582971572875977
Validation loss: 3.866619017816359

Epoch: 5| Step: 4
Training loss: 3.8839926719665527
Validation loss: 3.8305110700668825

Epoch: 5| Step: 5
Training loss: 3.9830875396728516
Validation loss: 3.8022201753431752

Epoch: 5| Step: 6
Training loss: 4.014641761779785
Validation loss: 3.7761993767112814

Epoch: 5| Step: 7
Training loss: 3.7153549194335938
Validation loss: 3.7537398005044587

Epoch: 5| Step: 8
Training loss: 3.4232261180877686
Validation loss: 3.726267291653541

Epoch: 5| Step: 9
Training loss: 2.404555320739746
Validation loss: 3.704119687439293

Epoch: 5| Step: 10
Training loss: 4.103480815887451
Validation loss: 3.6808277714637017

Epoch: 4| Step: 0
Training loss: 3.2613372802734375
Validation loss: 3.65896104228112

Epoch: 5| Step: 1
Training loss: 3.936821699142456
Validation loss: 3.637951748345488

Epoch: 5| Step: 2
Training loss: 3.576970338821411
Validation loss: 3.6171213529443227

Epoch: 5| Step: 3
Training loss: 3.683615207672119
Validation loss: 3.602887086970832

Epoch: 5| Step: 4
Training loss: 3.183363437652588
Validation loss: 3.5916190480673187

Epoch: 5| Step: 5
Training loss: 2.9534356594085693
Validation loss: 3.5738895118877454

Epoch: 5| Step: 6
Training loss: 2.94706392288208
Validation loss: 3.552188901491063

Epoch: 5| Step: 7
Training loss: 3.9158592224121094
Validation loss: 3.532588299884591

Epoch: 5| Step: 8
Training loss: 3.128613233566284
Validation loss: 3.5167670813939904

Epoch: 5| Step: 9
Training loss: 3.7240092754364014
Validation loss: 3.5003768987553094

Epoch: 5| Step: 10
Training loss: 4.26502799987793
Validation loss: 3.472227822067917

Epoch: 5| Step: 0
Training loss: 3.469647169113159
Validation loss: 3.4500881087395454

Epoch: 5| Step: 1
Training loss: 3.205366849899292
Validation loss: 3.428206302786386

Epoch: 5| Step: 2
Training loss: 3.9421226978302
Validation loss: 3.410316580085344

Epoch: 5| Step: 3
Training loss: 2.7101855278015137
Validation loss: 3.3943891499632146

Epoch: 5| Step: 4
Training loss: 2.114544630050659
Validation loss: 3.378757015351326

Epoch: 5| Step: 5
Training loss: 3.8192334175109863
Validation loss: 3.3656370639801025

Epoch: 5| Step: 6
Training loss: 2.460841178894043
Validation loss: 3.3502327754933345

Epoch: 5| Step: 7
Training loss: 4.534539222717285
Validation loss: 3.3333818476687194

Epoch: 5| Step: 8
Training loss: 3.863049268722534
Validation loss: 3.317445549913632

Epoch: 5| Step: 9
Training loss: 3.378645420074463
Validation loss: 3.296825957554643

Epoch: 5| Step: 10
Training loss: 2.9841701984405518
Validation loss: 3.2781597927052486

Epoch: 6| Step: 0
Training loss: 3.5263214111328125
Validation loss: 3.258960359839983

Epoch: 5| Step: 1
Training loss: 3.4517509937286377
Validation loss: 3.2495049276659564

Epoch: 5| Step: 2
Training loss: 2.7014148235321045
Validation loss: 3.222389021227437

Epoch: 5| Step: 3
Training loss: 2.5173542499542236
Validation loss: 3.200512527137674

Epoch: 5| Step: 4
Training loss: 3.0507357120513916
Validation loss: 3.1882686845717894

Epoch: 5| Step: 5
Training loss: 3.0062897205352783
Validation loss: 3.178040360891691

Epoch: 5| Step: 6
Training loss: 3.355175018310547
Validation loss: 3.1746733855175715

Epoch: 5| Step: 7
Training loss: 3.332094669342041
Validation loss: 3.1357575437074066

Epoch: 5| Step: 8
Training loss: 3.18341064453125
Validation loss: 3.124422355364728

Epoch: 5| Step: 9
Training loss: 3.3492255210876465
Validation loss: 3.1196230278220227

Epoch: 5| Step: 10
Training loss: 3.580183982849121
Validation loss: 3.101011589009275

Epoch: 7| Step: 0
Training loss: 4.035157680511475
Validation loss: 3.08567246314018

Epoch: 5| Step: 1
Training loss: 3.5312037467956543
Validation loss: 3.069494062854398

Epoch: 5| Step: 2
Training loss: 2.765547275543213
Validation loss: 3.0560777828257573

Epoch: 5| Step: 3
Training loss: 3.4200806617736816
Validation loss: 3.0415452039369972

Epoch: 5| Step: 4
Training loss: 3.290142774581909
Validation loss: 3.03346227317728

Epoch: 5| Step: 5
Training loss: 3.0204989910125732
Validation loss: 3.0213824523392545

Epoch: 5| Step: 6
Training loss: 3.895256757736206
Validation loss: 3.0105893996454056

Epoch: 5| Step: 7
Training loss: 2.7270500659942627
Validation loss: 2.9990784557916785

Epoch: 5| Step: 8
Training loss: 2.1518797874450684
Validation loss: 2.993909776851695

Epoch: 5| Step: 9
Training loss: 2.2338638305664062
Validation loss: 2.9854214909256145

Epoch: 5| Step: 10
Training loss: 2.785902500152588
Validation loss: 2.979808097244591

Epoch: 8| Step: 0
Training loss: 3.3761658668518066
Validation loss: 2.964393372176796

Epoch: 5| Step: 1
Training loss: 2.338364362716675
Validation loss: 2.9524604889654342

Epoch: 5| Step: 2
Training loss: 2.9197189807891846
Validation loss: 2.9463387227827504

Epoch: 5| Step: 3
Training loss: 2.176711320877075
Validation loss: 2.948538459757323

Epoch: 5| Step: 4
Training loss: 3.3532052040100098
Validation loss: 2.9532107691611014

Epoch: 5| Step: 5
Training loss: 3.727323055267334
Validation loss: 2.9377268924508044

Epoch: 5| Step: 6
Training loss: 2.9378247261047363
Validation loss: 2.9241802589867705

Epoch: 5| Step: 7
Training loss: 3.2267234325408936
Validation loss: 2.9209999345964

Epoch: 5| Step: 8
Training loss: 3.3582923412323
Validation loss: 2.911253539464807

Epoch: 5| Step: 9
Training loss: 2.430449962615967
Validation loss: 2.9051032655982563

Epoch: 5| Step: 10
Training loss: 3.450796127319336
Validation loss: 2.8967427874124176

Epoch: 9| Step: 0
Training loss: 2.7564187049865723
Validation loss: 2.889673481705368

Epoch: 5| Step: 1
Training loss: 2.6388516426086426
Validation loss: 2.8819304358574653

Epoch: 5| Step: 2
Training loss: 3.5033271312713623
Validation loss: 2.877173639112903

Epoch: 5| Step: 3
Training loss: 2.41908860206604
Validation loss: 2.8738002161825857

Epoch: 5| Step: 4
Training loss: 2.8445823192596436
Validation loss: 2.8805572063692155

Epoch: 5| Step: 5
Training loss: 2.141633987426758
Validation loss: 2.8699766794840493

Epoch: 5| Step: 6
Training loss: 3.5071709156036377
Validation loss: 2.8582945100722776

Epoch: 5| Step: 7
Training loss: 3.423809766769409
Validation loss: 2.850139815320251

Epoch: 5| Step: 8
Training loss: 3.6211981773376465
Validation loss: 2.8454384855044785

Epoch: 5| Step: 9
Training loss: 3.2260353565216064
Validation loss: 2.8361930308803434

Epoch: 5| Step: 10
Training loss: 2.525334119796753
Validation loss: 2.8291104788421304

Epoch: 10| Step: 0
Training loss: 3.3475074768066406
Validation loss: 2.8273905554125385

Epoch: 5| Step: 1
Training loss: 3.0347399711608887
Validation loss: 2.8250361181074575

Epoch: 5| Step: 2
Training loss: 2.579280138015747
Validation loss: 2.818883280600271

Epoch: 5| Step: 3
Training loss: 2.667011022567749
Validation loss: 2.819927592431345

Epoch: 5| Step: 4
Training loss: 3.4151580333709717
Validation loss: 2.807635740567279

Epoch: 5| Step: 5
Training loss: 2.007279872894287
Validation loss: 2.79932003636514

Epoch: 5| Step: 6
Training loss: 3.4527792930603027
Validation loss: 2.793291389301259

Epoch: 5| Step: 7
Training loss: 2.926405429840088
Validation loss: 2.790400548647809

Epoch: 5| Step: 8
Training loss: 3.7251510620117188
Validation loss: 2.785573367149599

Epoch: 5| Step: 9
Training loss: 2.3859870433807373
Validation loss: 2.7796312557753695

Epoch: 5| Step: 10
Training loss: 2.762876510620117
Validation loss: 2.784187780913486

Epoch: 11| Step: 0
Training loss: 2.830615758895874
Validation loss: 2.767493478713497

Epoch: 5| Step: 1
Training loss: 2.1909663677215576
Validation loss: 2.7685430793352026

Epoch: 5| Step: 2
Training loss: 3.318950653076172
Validation loss: 2.76793239449942

Epoch: 5| Step: 3
Training loss: 3.512676239013672
Validation loss: 2.7668480770562285

Epoch: 5| Step: 4
Training loss: 3.0655722618103027
Validation loss: 2.761632247637677

Epoch: 5| Step: 5
Training loss: 2.6701860427856445
Validation loss: 2.754821523543327

Epoch: 5| Step: 6
Training loss: 2.5619046688079834
Validation loss: 2.7535218218321442

Epoch: 5| Step: 7
Training loss: 3.361074447631836
Validation loss: 2.7510241180337887

Epoch: 5| Step: 8
Training loss: 2.982182025909424
Validation loss: 2.747083610103976

Epoch: 5| Step: 9
Training loss: 2.5430715084075928
Validation loss: 2.7473062212749193

Epoch: 5| Step: 10
Training loss: 2.937455892562866
Validation loss: 2.743329273757114

Epoch: 12| Step: 0
Training loss: 3.0038273334503174
Validation loss: 2.7412830116928264

Epoch: 5| Step: 1
Training loss: 3.1184144020080566
Validation loss: 2.7411147625215593

Epoch: 5| Step: 2
Training loss: 2.369745969772339
Validation loss: 2.739198079673193

Epoch: 5| Step: 3
Training loss: 3.34861421585083
Validation loss: 2.748803546351771

Epoch: 5| Step: 4
Training loss: 2.374706268310547
Validation loss: 2.7317587560222996

Epoch: 5| Step: 5
Training loss: 3.1873836517333984
Validation loss: 2.752598313875096

Epoch: 5| Step: 6
Training loss: 3.0430519580841064
Validation loss: 2.7348500067187893

Epoch: 5| Step: 7
Training loss: 1.8289973735809326
Validation loss: 2.72534466046159

Epoch: 5| Step: 8
Training loss: 3.561330795288086
Validation loss: 2.724293957474411

Epoch: 5| Step: 9
Training loss: 3.178363561630249
Validation loss: 2.723673794859199

Epoch: 5| Step: 10
Training loss: 2.7609307765960693
Validation loss: 2.723418381906325

Epoch: 13| Step: 0
Training loss: 2.842085599899292
Validation loss: 2.7218279120742634

Epoch: 5| Step: 1
Training loss: 3.092423915863037
Validation loss: 2.7221011474568355

Epoch: 5| Step: 2
Training loss: 3.134521961212158
Validation loss: 2.71693931600099

Epoch: 5| Step: 3
Training loss: 3.623929500579834
Validation loss: 2.718227929966424

Epoch: 5| Step: 4
Training loss: 2.422502040863037
Validation loss: 2.7159300004282305

Epoch: 5| Step: 5
Training loss: 3.1291165351867676
Validation loss: 2.7136461657862507

Epoch: 5| Step: 6
Training loss: 2.9721999168395996
Validation loss: 2.7108999811192995

Epoch: 5| Step: 7
Training loss: 2.657473087310791
Validation loss: 2.706706072694512

Epoch: 5| Step: 8
Training loss: 2.681946039199829
Validation loss: 2.706881835896482

Epoch: 5| Step: 9
Training loss: 3.0300216674804688
Validation loss: 2.715347779694424

Epoch: 5| Step: 10
Training loss: 1.9383338689804077
Validation loss: 2.710809520495835

Epoch: 14| Step: 0
Training loss: 2.9329068660736084
Validation loss: 2.71011185133329

Epoch: 5| Step: 1
Training loss: 2.532949924468994
Validation loss: 2.729563513109761

Epoch: 5| Step: 2
Training loss: 2.858067274093628
Validation loss: 2.7317649933599655

Epoch: 5| Step: 3
Training loss: 2.7012553215026855
Validation loss: 2.7237519961531445

Epoch: 5| Step: 4
Training loss: 2.739109516143799
Validation loss: 2.741481698969359

Epoch: 5| Step: 5
Training loss: 2.3520212173461914
Validation loss: 2.7157679347581762

Epoch: 5| Step: 6
Training loss: 4.198184013366699
Validation loss: 2.7351615300742527

Epoch: 5| Step: 7
Training loss: 2.784205675125122
Validation loss: 2.6963408095862276

Epoch: 5| Step: 8
Training loss: 2.909567356109619
Validation loss: 2.7256157090587

Epoch: 5| Step: 9
Training loss: 3.0426385402679443
Validation loss: 2.740241281447872

Epoch: 5| Step: 10
Training loss: 2.7084503173828125
Validation loss: 2.7242144307782574

Epoch: 15| Step: 0
Training loss: 3.5734448432922363
Validation loss: 2.7087611613735074

Epoch: 5| Step: 1
Training loss: 2.942572832107544
Validation loss: 2.704496363157867

Epoch: 5| Step: 2
Training loss: 2.5832250118255615
Validation loss: 2.699637269461027

Epoch: 5| Step: 3
Training loss: 3.11877703666687
Validation loss: 2.6988189810065815

Epoch: 5| Step: 4
Training loss: 3.310046434402466
Validation loss: 2.700450722889234

Epoch: 5| Step: 5
Training loss: 2.501025438308716
Validation loss: 2.701954657031644

Epoch: 5| Step: 6
Training loss: 2.3740086555480957
Validation loss: 2.7085382605111725

Epoch: 5| Step: 7
Training loss: 2.138669013977051
Validation loss: 2.720621250009024

Epoch: 5| Step: 8
Training loss: 3.1611742973327637
Validation loss: 2.7222065361597205

Epoch: 5| Step: 9
Training loss: 3.769322633743286
Validation loss: 2.7052466766808623

Epoch: 5| Step: 10
Training loss: 1.9966992139816284
Validation loss: 2.685253148437828

Epoch: 16| Step: 0
Training loss: 2.9561972618103027
Validation loss: 2.6849210057207333

Epoch: 5| Step: 1
Training loss: 2.954926013946533
Validation loss: 2.7261115479212936

Epoch: 5| Step: 2
Training loss: 2.393725872039795
Validation loss: 2.7072740780409945

Epoch: 5| Step: 3
Training loss: 3.417203426361084
Validation loss: 2.7371545299406974

Epoch: 5| Step: 4
Training loss: 2.806602954864502
Validation loss: 2.7453588285753803

Epoch: 5| Step: 5
Training loss: 2.772799491882324
Validation loss: 2.752059644268405

Epoch: 5| Step: 6
Training loss: 2.622222900390625
Validation loss: 2.689224317509641

Epoch: 5| Step: 7
Training loss: 2.268711805343628
Validation loss: 2.6851512770498953

Epoch: 5| Step: 8
Training loss: 2.6801838874816895
Validation loss: 2.7177486419677734

Epoch: 5| Step: 9
Training loss: 3.7239882946014404
Validation loss: 2.7264177722315632

Epoch: 5| Step: 10
Training loss: 3.154845714569092
Validation loss: 2.726970952044251

Epoch: 17| Step: 0
Training loss: 3.025597333908081
Validation loss: 2.7169510087659283

Epoch: 5| Step: 1
Training loss: 3.0242438316345215
Validation loss: 2.71095525064776

Epoch: 5| Step: 2
Training loss: 2.439457654953003
Validation loss: 2.6988145407810005

Epoch: 5| Step: 3
Training loss: 2.9858171939849854
Validation loss: 2.703759954821679

Epoch: 5| Step: 4
Training loss: 3.0039620399475098
Validation loss: 2.689168050724973

Epoch: 5| Step: 5
Training loss: 2.5003390312194824
Validation loss: 2.67284050808158

Epoch: 5| Step: 6
Training loss: 2.6116151809692383
Validation loss: 2.665299638625114

Epoch: 5| Step: 7
Training loss: 2.345602512359619
Validation loss: 2.66332148480159

Epoch: 5| Step: 8
Training loss: 2.93387508392334
Validation loss: 2.664995111444945

Epoch: 5| Step: 9
Training loss: 3.7486793994903564
Validation loss: 2.6631588910215642

Epoch: 5| Step: 10
Training loss: 2.764298915863037
Validation loss: 2.661648711850566

Epoch: 18| Step: 0
Training loss: 2.4487314224243164
Validation loss: 2.6591247256084154

Epoch: 5| Step: 1
Training loss: 2.931065082550049
Validation loss: 2.651420889362212

Epoch: 5| Step: 2
Training loss: 3.0989861488342285
Validation loss: 2.651016907025409

Epoch: 5| Step: 3
Training loss: 2.2904305458068848
Validation loss: 2.6505922732814664

Epoch: 5| Step: 4
Training loss: 2.5633254051208496
Validation loss: 2.6486924284247944

Epoch: 5| Step: 5
Training loss: 2.396928310394287
Validation loss: 2.6433467582989763

Epoch: 5| Step: 6
Training loss: 3.394427537918091
Validation loss: 2.6766081830506683

Epoch: 5| Step: 7
Training loss: 3.1779110431671143
Validation loss: 2.648498491574359

Epoch: 5| Step: 8
Training loss: 3.5480926036834717
Validation loss: 2.6435955570590113

Epoch: 5| Step: 9
Training loss: 2.390470027923584
Validation loss: 2.6438556025105138

Epoch: 5| Step: 10
Training loss: 2.9596939086914062
Validation loss: 2.6453634000593618

Epoch: 19| Step: 0
Training loss: 2.830550193786621
Validation loss: 2.647980538747644

Epoch: 5| Step: 1
Training loss: 2.2690939903259277
Validation loss: 2.653716487269248

Epoch: 5| Step: 2
Training loss: 3.1897246837615967
Validation loss: 2.6486964353951077

Epoch: 5| Step: 3
Training loss: 2.192127227783203
Validation loss: 2.6450057439906622

Epoch: 5| Step: 4
Training loss: 2.9983952045440674
Validation loss: 2.643949750931032

Epoch: 5| Step: 5
Training loss: 3.4906814098358154
Validation loss: 2.6469098444907897

Epoch: 5| Step: 6
Training loss: 2.596479892730713
Validation loss: 2.6431600534787743

Epoch: 5| Step: 7
Training loss: 2.6214356422424316
Validation loss: 2.6397150588291947

Epoch: 5| Step: 8
Training loss: 2.374258518218994
Validation loss: 2.6402922984092467

Epoch: 5| Step: 9
Training loss: 3.138923406600952
Validation loss: 2.6366354778248775

Epoch: 5| Step: 10
Training loss: 3.4912900924682617
Validation loss: 2.6371826997367283

Epoch: 20| Step: 0
Training loss: 2.1894137859344482
Validation loss: 2.6404592811420398

Epoch: 5| Step: 1
Training loss: 2.958897113800049
Validation loss: 2.6452896415546374

Epoch: 5| Step: 2
Training loss: 3.4348206520080566
Validation loss: 2.657893011646886

Epoch: 5| Step: 3
Training loss: 2.5135650634765625
Validation loss: 2.652133059758012

Epoch: 5| Step: 4
Training loss: 2.401888608932495
Validation loss: 2.646389966369957

Epoch: 5| Step: 5
Training loss: 2.8093998432159424
Validation loss: 2.6568570060114705

Epoch: 5| Step: 6
Training loss: 2.6134819984436035
Validation loss: 2.653467321908602

Epoch: 5| Step: 7
Training loss: 3.601477861404419
Validation loss: 2.6476619628167923

Epoch: 5| Step: 8
Training loss: 2.1979820728302
Validation loss: 2.6445967048727055

Epoch: 5| Step: 9
Training loss: 3.1790504455566406
Validation loss: 2.6398520136392243

Epoch: 5| Step: 10
Training loss: 3.2935125827789307
Validation loss: 2.6375144399622434

Epoch: 21| Step: 0
Training loss: 3.3307406902313232
Validation loss: 2.628809972475934

Epoch: 5| Step: 1
Training loss: 2.8687283992767334
Validation loss: 2.626674295753561

Epoch: 5| Step: 2
Training loss: 2.1497859954833984
Validation loss: 2.6253557230836604

Epoch: 5| Step: 3
Training loss: 2.7986011505126953
Validation loss: 2.621526869394446

Epoch: 5| Step: 4
Training loss: 3.567579746246338
Validation loss: 2.615620664370957

Epoch: 5| Step: 5
Training loss: 2.5670740604400635
Validation loss: 2.616103623502998

Epoch: 5| Step: 6
Training loss: 2.5442378520965576
Validation loss: 2.6118944152708976

Epoch: 5| Step: 7
Training loss: 2.5378623008728027
Validation loss: 2.6122350692749023

Epoch: 5| Step: 8
Training loss: 2.5966148376464844
Validation loss: 2.6136642374018186

Epoch: 5| Step: 9
Training loss: 2.4980099201202393
Validation loss: 2.615340781468217

Epoch: 5| Step: 10
Training loss: 3.5898051261901855
Validation loss: 2.6305909874618694

Epoch: 22| Step: 0
Training loss: 2.9956488609313965
Validation loss: 2.6245522986176195

Epoch: 5| Step: 1
Training loss: 2.6701319217681885
Validation loss: 2.6374570708121023

Epoch: 5| Step: 2
Training loss: 2.7631988525390625
Validation loss: 2.641394845900997

Epoch: 5| Step: 3
Training loss: 2.5203652381896973
Validation loss: 2.623519359096404

Epoch: 5| Step: 4
Training loss: 2.9026670455932617
Validation loss: 2.6084739802986063

Epoch: 5| Step: 5
Training loss: 2.9268813133239746
Validation loss: 2.6051022878257175

Epoch: 5| Step: 6
Training loss: 2.8367199897766113
Validation loss: 2.612892007315031

Epoch: 5| Step: 7
Training loss: 3.2325146198272705
Validation loss: 2.6070911704853015

Epoch: 5| Step: 8
Training loss: 2.9060468673706055
Validation loss: 2.605961445839174

Epoch: 5| Step: 9
Training loss: 2.5621838569641113
Validation loss: 2.6048706398215344

Epoch: 5| Step: 10
Training loss: 2.4719622135162354
Validation loss: 2.6053521889512257

Epoch: 23| Step: 0
Training loss: 3.139707565307617
Validation loss: 2.6137472967947684

Epoch: 5| Step: 1
Training loss: 2.3360538482666016
Validation loss: 2.6008879805123932

Epoch: 5| Step: 2
Training loss: 2.7191226482391357
Validation loss: 2.6016910383778233

Epoch: 5| Step: 3
Training loss: 2.738809585571289
Validation loss: 2.6058360120301605

Epoch: 5| Step: 4
Training loss: 3.3407387733459473
Validation loss: 2.6086484693711802

Epoch: 5| Step: 5
Training loss: 2.5348472595214844
Validation loss: 2.6083545684814453

Epoch: 5| Step: 6
Training loss: 2.87749981880188
Validation loss: 2.6100256648114932

Epoch: 5| Step: 7
Training loss: 2.8767712116241455
Validation loss: 2.6106371648849978

Epoch: 5| Step: 8
Training loss: 2.331657648086548
Validation loss: 2.6066688927271033

Epoch: 5| Step: 9
Training loss: 3.2604269981384277
Validation loss: 2.605483921625281

Epoch: 5| Step: 10
Training loss: 2.638662099838257
Validation loss: 2.599735285646172

Epoch: 24| Step: 0
Training loss: 2.895465612411499
Validation loss: 2.6089469053411998

Epoch: 5| Step: 1
Training loss: 2.8178882598876953
Validation loss: 2.621217304660428

Epoch: 5| Step: 2
Training loss: 2.6570980548858643
Validation loss: 2.6442549023576962

Epoch: 5| Step: 3
Training loss: 2.8765299320220947
Validation loss: 2.6276458617179625

Epoch: 5| Step: 4
Training loss: 2.3918373584747314
Validation loss: 2.623124864793593

Epoch: 5| Step: 5
Training loss: 2.9363090991973877
Validation loss: 2.608832005531557

Epoch: 5| Step: 6
Training loss: 3.2934234142303467
Validation loss: 2.603955513687544

Epoch: 5| Step: 7
Training loss: 1.9770488739013672
Validation loss: 2.604433121219758

Epoch: 5| Step: 8
Training loss: 3.049745798110962
Validation loss: 2.592656671359975

Epoch: 5| Step: 9
Training loss: 2.973832607269287
Validation loss: 2.5889630112596738

Epoch: 5| Step: 10
Training loss: 2.896580219268799
Validation loss: 2.5872248680360856

Epoch: 25| Step: 0
Training loss: 3.007822036743164
Validation loss: 2.5858069466006373

Epoch: 5| Step: 1
Training loss: 2.744734525680542
Validation loss: 2.583695550118723

Epoch: 5| Step: 2
Training loss: 2.425133466720581
Validation loss: 2.586090685218893

Epoch: 5| Step: 3
Training loss: 3.0675888061523438
Validation loss: 2.586251260131918

Epoch: 5| Step: 4
Training loss: 1.984731912612915
Validation loss: 2.582286447607061

Epoch: 5| Step: 5
Training loss: 2.6706459522247314
Validation loss: 2.5810703128896733

Epoch: 5| Step: 6
Training loss: 2.7357375621795654
Validation loss: 2.587140872914304

Epoch: 5| Step: 7
Training loss: 3.489253520965576
Validation loss: 2.608349477091143

Epoch: 5| Step: 8
Training loss: 2.2365458011627197
Validation loss: 2.6064138181747927

Epoch: 5| Step: 9
Training loss: 3.0738167762756348
Validation loss: 2.614599432996524

Epoch: 5| Step: 10
Training loss: 3.2780659198760986
Validation loss: 2.6183887822653658

Epoch: 26| Step: 0
Training loss: 2.548886775970459
Validation loss: 2.616980278363792

Epoch: 5| Step: 1
Training loss: 2.2995707988739014
Validation loss: 2.6153963842699604

Epoch: 5| Step: 2
Training loss: 3.4035744667053223
Validation loss: 2.6142810877933296

Epoch: 5| Step: 3
Training loss: 2.4385576248168945
Validation loss: 2.628730171470232

Epoch: 5| Step: 4
Training loss: 2.6372618675231934
Validation loss: 2.625582479661511

Epoch: 5| Step: 5
Training loss: 3.236807346343994
Validation loss: 2.5970537098505164

Epoch: 5| Step: 6
Training loss: 2.909125804901123
Validation loss: 2.579580714625697

Epoch: 5| Step: 7
Training loss: 2.796968936920166
Validation loss: 2.5744553483942503

Epoch: 5| Step: 8
Training loss: 2.797259569168091
Validation loss: 2.5830313121118853

Epoch: 5| Step: 9
Training loss: 2.7213737964630127
Validation loss: 2.5885049476418445

Epoch: 5| Step: 10
Training loss: 2.8360273838043213
Validation loss: 2.5888339293900358

Epoch: 27| Step: 0
Training loss: 2.8738012313842773
Validation loss: 2.6044808510811097

Epoch: 5| Step: 1
Training loss: 3.3103744983673096
Validation loss: 2.590384401300902

Epoch: 5| Step: 2
Training loss: 2.8116583824157715
Validation loss: 2.579344121358728

Epoch: 5| Step: 3
Training loss: 2.9647932052612305
Validation loss: 2.5777100209266908

Epoch: 5| Step: 4
Training loss: 2.5152087211608887
Validation loss: 2.576238614256664

Epoch: 5| Step: 5
Training loss: 2.765784740447998
Validation loss: 2.5760341331522953

Epoch: 5| Step: 6
Training loss: 2.2099461555480957
Validation loss: 2.5725985239910822

Epoch: 5| Step: 7
Training loss: 2.9712603092193604
Validation loss: 2.5686491022827806

Epoch: 5| Step: 8
Training loss: 2.2300331592559814
Validation loss: 2.572522165954754

Epoch: 5| Step: 9
Training loss: 3.1529617309570312
Validation loss: 2.579512293620776

Epoch: 5| Step: 10
Training loss: 2.5651228427886963
Validation loss: 2.5944128805591213

Epoch: 28| Step: 0
Training loss: 2.462644100189209
Validation loss: 2.635597659695533

Epoch: 5| Step: 1
Training loss: 3.121412754058838
Validation loss: 2.6452353385186966

Epoch: 5| Step: 2
Training loss: 2.3849713802337646
Validation loss: 2.645743357237949

Epoch: 5| Step: 3
Training loss: 3.2673068046569824
Validation loss: 2.647422585436093

Epoch: 5| Step: 4
Training loss: 3.1762478351593018
Validation loss: 2.6364146253114105

Epoch: 5| Step: 5
Training loss: 3.5201900005340576
Validation loss: 2.6205070505860033

Epoch: 5| Step: 6
Training loss: 2.7526402473449707
Validation loss: 2.6055809708051783

Epoch: 5| Step: 7
Training loss: 2.9332873821258545
Validation loss: 2.5990743098720426

Epoch: 5| Step: 8
Training loss: 2.866786241531372
Validation loss: 2.5921234905078845

Epoch: 5| Step: 9
Training loss: 1.7183644771575928
Validation loss: 2.5914098549914617

Epoch: 5| Step: 10
Training loss: 2.3406126499176025
Validation loss: 2.588815217377037

Epoch: 29| Step: 0
Training loss: 2.723532199859619
Validation loss: 2.590386506049864

Epoch: 5| Step: 1
Training loss: 3.3259098529815674
Validation loss: 2.590482024736302

Epoch: 5| Step: 2
Training loss: 2.672671318054199
Validation loss: 2.5862604007926038

Epoch: 5| Step: 3
Training loss: 2.421894073486328
Validation loss: 2.589022572322558

Epoch: 5| Step: 4
Training loss: 3.375885486602783
Validation loss: 2.590394259780966

Epoch: 5| Step: 5
Training loss: 2.5335288047790527
Validation loss: 2.5874125547306512

Epoch: 5| Step: 6
Training loss: 2.7034964561462402
Validation loss: 2.5893946821971605

Epoch: 5| Step: 7
Training loss: 2.795795202255249
Validation loss: 2.5862729857044835

Epoch: 5| Step: 8
Training loss: 2.6715879440307617
Validation loss: 2.5845488373951246

Epoch: 5| Step: 9
Training loss: 2.7011656761169434
Validation loss: 2.5879895776830693

Epoch: 5| Step: 10
Training loss: 2.3478989601135254
Validation loss: 2.5970634491212907

Epoch: 30| Step: 0
Training loss: 2.8647570610046387
Validation loss: 2.5826469723896315

Epoch: 5| Step: 1
Training loss: 2.093719005584717
Validation loss: 2.576500477329377

Epoch: 5| Step: 2
Training loss: 2.98808217048645
Validation loss: 2.582403293219946

Epoch: 5| Step: 3
Training loss: 2.4733805656433105
Validation loss: 2.590497442471084

Epoch: 5| Step: 4
Training loss: 2.8426003456115723
Validation loss: 2.5909167976789576

Epoch: 5| Step: 5
Training loss: 3.2592406272888184
Validation loss: 2.5947750819626676

Epoch: 5| Step: 6
Training loss: 2.826132297515869
Validation loss: 2.594754147273238

Epoch: 5| Step: 7
Training loss: 2.880979299545288
Validation loss: 2.5892787620585453

Epoch: 5| Step: 8
Training loss: 2.454540252685547
Validation loss: 2.5837310821779313

Epoch: 5| Step: 9
Training loss: 2.935906171798706
Validation loss: 2.5722235120752805

Epoch: 5| Step: 10
Training loss: 2.6922848224639893
Validation loss: 2.5560527052930606

Epoch: 31| Step: 0
Training loss: 1.9801639318466187
Validation loss: 2.5583878537660003

Epoch: 5| Step: 1
Training loss: 3.0263829231262207
Validation loss: 2.57817401424531

Epoch: 5| Step: 2
Training loss: 2.1831536293029785
Validation loss: 2.5688263908509286

Epoch: 5| Step: 3
Training loss: 2.993431806564331
Validation loss: 2.586725006821335

Epoch: 5| Step: 4
Training loss: 2.8957784175872803
Validation loss: 2.5662456712415143

Epoch: 5| Step: 5
Training loss: 2.796670436859131
Validation loss: 2.5587409106633996

Epoch: 5| Step: 6
Training loss: 2.7964348793029785
Validation loss: 2.561264508513994

Epoch: 5| Step: 7
Training loss: 3.2926814556121826
Validation loss: 2.557663115121985

Epoch: 5| Step: 8
Training loss: 2.6696581840515137
Validation loss: 2.5589143217250867

Epoch: 5| Step: 9
Training loss: 3.0449421405792236
Validation loss: 2.560752422578873

Epoch: 5| Step: 10
Training loss: 2.5876734256744385
Validation loss: 2.575373439378636

Epoch: 32| Step: 0
Training loss: 2.299950361251831
Validation loss: 2.5903917410040416

Epoch: 5| Step: 1
Training loss: 2.3869271278381348
Validation loss: 2.5854674949440906

Epoch: 5| Step: 2
Training loss: 3.2983384132385254
Validation loss: 2.55446304557144

Epoch: 5| Step: 3
Training loss: 3.67529559135437
Validation loss: 2.5340448912753852

Epoch: 5| Step: 4
Training loss: 2.871201992034912
Validation loss: 2.5269103280959593

Epoch: 5| Step: 5
Training loss: 2.5554873943328857
Validation loss: 2.520706502340173

Epoch: 5| Step: 6
Training loss: 2.849576234817505
Validation loss: 2.5210795428163264

Epoch: 5| Step: 7
Training loss: 2.6105809211730957
Validation loss: 2.522279329197381

Epoch: 5| Step: 8
Training loss: 2.160167694091797
Validation loss: 2.5214830342159478

Epoch: 5| Step: 9
Training loss: 2.832810163497925
Validation loss: 2.516307241173201

Epoch: 5| Step: 10
Training loss: 2.551339864730835
Validation loss: 2.5125536867367324

Epoch: 33| Step: 0
Training loss: 2.2685017585754395
Validation loss: 2.5081983343247445

Epoch: 5| Step: 1
Training loss: 2.5463690757751465
Validation loss: 2.508780374321886

Epoch: 5| Step: 2
Training loss: 2.5538854598999023
Validation loss: 2.5061564291677167

Epoch: 5| Step: 3
Training loss: 2.198385238647461
Validation loss: 2.5105909942298807

Epoch: 5| Step: 4
Training loss: 2.9482345581054688
Validation loss: 2.513033179826634

Epoch: 5| Step: 5
Training loss: 3.1239516735076904
Validation loss: 2.5178270519420667

Epoch: 5| Step: 6
Training loss: 2.2470622062683105
Validation loss: 2.5185542670629357

Epoch: 5| Step: 7
Training loss: 2.639747142791748
Validation loss: 2.5107589588370374

Epoch: 5| Step: 8
Training loss: 2.889655351638794
Validation loss: 2.509971385361046

Epoch: 5| Step: 9
Training loss: 3.4924705028533936
Validation loss: 2.5042672926379788

Epoch: 5| Step: 10
Training loss: 2.901636838912964
Validation loss: 2.502047182411276

Epoch: 34| Step: 0
Training loss: 2.7916440963745117
Validation loss: 2.497312702158446

Epoch: 5| Step: 1
Training loss: 2.5880379676818848
Validation loss: 2.4943629259704263

Epoch: 5| Step: 2
Training loss: 3.0968985557556152
Validation loss: 2.4894161993457424

Epoch: 5| Step: 3
Training loss: 2.871311664581299
Validation loss: 2.4933905832229124

Epoch: 5| Step: 4
Training loss: 2.024580478668213
Validation loss: 2.4888521907150105

Epoch: 5| Step: 5
Training loss: 2.422213315963745
Validation loss: 2.4885791142781577

Epoch: 5| Step: 6
Training loss: 1.9928538799285889
Validation loss: 2.4869499719271095

Epoch: 5| Step: 7
Training loss: 3.0938053131103516
Validation loss: 2.486155689403575

Epoch: 5| Step: 8
Training loss: 2.259498119354248
Validation loss: 2.48892463919937

Epoch: 5| Step: 9
Training loss: 2.994408130645752
Validation loss: 2.4928054271205777

Epoch: 5| Step: 10
Training loss: 3.783731460571289
Validation loss: 2.498496417076357

Epoch: 35| Step: 0
Training loss: 2.60400652885437
Validation loss: 2.499929702410134

Epoch: 5| Step: 1
Training loss: 2.593534231185913
Validation loss: 2.5043331115476546

Epoch: 5| Step: 2
Training loss: 2.5729682445526123
Validation loss: 2.5060134933840845

Epoch: 5| Step: 3
Training loss: 2.8878071308135986
Validation loss: 2.5111397081805813

Epoch: 5| Step: 4
Training loss: 2.6340298652648926
Validation loss: 2.5158020091313187

Epoch: 5| Step: 5
Training loss: 2.820502758026123
Validation loss: 2.5251736230747674

Epoch: 5| Step: 6
Training loss: 2.4762356281280518
Validation loss: 2.543602130746329

Epoch: 5| Step: 7
Training loss: 2.8632187843322754
Validation loss: 2.5457998014265493

Epoch: 5| Step: 8
Training loss: 2.4175198078155518
Validation loss: 2.5389753336547525

Epoch: 5| Step: 9
Training loss: 3.4304416179656982
Validation loss: 2.5169617488820064

Epoch: 5| Step: 10
Training loss: 2.4806578159332275
Validation loss: 2.499211157521894

Epoch: 36| Step: 0
Training loss: 2.566210985183716
Validation loss: 2.4953318411304104

Epoch: 5| Step: 1
Training loss: 2.2913050651550293
Validation loss: 2.5059350408533567

Epoch: 5| Step: 2
Training loss: 3.7346432209014893
Validation loss: 2.5152775574755926

Epoch: 5| Step: 3
Training loss: 2.3105177879333496
Validation loss: 2.5140270392100015

Epoch: 5| Step: 4
Training loss: 3.0146889686584473
Validation loss: 2.5051876678261706

Epoch: 5| Step: 5
Training loss: 2.4440135955810547
Validation loss: 2.4876460823961484

Epoch: 5| Step: 6
Training loss: 3.037680149078369
Validation loss: 2.485925530874601

Epoch: 5| Step: 7
Training loss: 2.72226619720459
Validation loss: 2.4991375630901707

Epoch: 5| Step: 8
Training loss: 2.7702178955078125
Validation loss: 2.48708116110935

Epoch: 5| Step: 9
Training loss: 2.3270416259765625
Validation loss: 2.4873318646543767

Epoch: 5| Step: 10
Training loss: 2.5175609588623047
Validation loss: 2.5141058147594495

Epoch: 37| Step: 0
Training loss: 2.8863413333892822
Validation loss: 2.547273515373148

Epoch: 5| Step: 1
Training loss: 3.2853140830993652
Validation loss: 2.57286484267122

Epoch: 5| Step: 2
Training loss: 2.48594069480896
Validation loss: 2.586265561401203

Epoch: 5| Step: 3
Training loss: 2.75137996673584
Validation loss: 2.5990719103044078

Epoch: 5| Step: 4
Training loss: 3.2025599479675293
Validation loss: 2.622785383655179

Epoch: 5| Step: 5
Training loss: 2.583451747894287
Validation loss: 2.5988606714433238

Epoch: 5| Step: 6
Training loss: 2.0650320053100586
Validation loss: 2.5773976182424896

Epoch: 5| Step: 7
Training loss: 2.683438777923584
Validation loss: 2.566660927188012

Epoch: 5| Step: 8
Training loss: 3.193901538848877
Validation loss: 2.557263607619911

Epoch: 5| Step: 9
Training loss: 2.1580657958984375
Validation loss: 2.5481562845168577

Epoch: 5| Step: 10
Training loss: 2.9950268268585205
Validation loss: 2.539094017397973

Epoch: 38| Step: 0
Training loss: 3.082456111907959
Validation loss: 2.538454137822633

Epoch: 5| Step: 1
Training loss: 1.9091081619262695
Validation loss: 2.5377563404780563

Epoch: 5| Step: 2
Training loss: 2.048720121383667
Validation loss: 2.528690222770937

Epoch: 5| Step: 3
Training loss: 3.087639331817627
Validation loss: 2.522700999372749

Epoch: 5| Step: 4
Training loss: 2.3996644020080566
Validation loss: 2.5214748715841644

Epoch: 5| Step: 5
Training loss: 3.2994093894958496
Validation loss: 2.515824279477519

Epoch: 5| Step: 6
Training loss: 2.7016677856445312
Validation loss: 2.5110877995849936

Epoch: 5| Step: 7
Training loss: 2.688175916671753
Validation loss: 2.5130966863324566

Epoch: 5| Step: 8
Training loss: 2.8199305534362793
Validation loss: 2.5116367083723827

Epoch: 5| Step: 9
Training loss: 2.7329821586608887
Validation loss: 2.5121966972145984

Epoch: 5| Step: 10
Training loss: 3.1706604957580566
Validation loss: 2.50889604578736

Epoch: 39| Step: 0
Training loss: 2.3225767612457275
Validation loss: 2.5024189538853143

Epoch: 5| Step: 1
Training loss: 2.6467087268829346
Validation loss: 2.4992386038585375

Epoch: 5| Step: 2
Training loss: 2.6494851112365723
Validation loss: 2.4988382965005855

Epoch: 5| Step: 3
Training loss: 3.0128791332244873
Validation loss: 2.5005765884153304

Epoch: 5| Step: 4
Training loss: 2.747558116912842
Validation loss: 2.500321239553472

Epoch: 5| Step: 5
Training loss: 3.208543300628662
Validation loss: 2.504604495981688

Epoch: 5| Step: 6
Training loss: 2.157540798187256
Validation loss: 2.499437132189351

Epoch: 5| Step: 7
Training loss: 2.752714157104492
Validation loss: 2.4981944099549325

Epoch: 5| Step: 8
Training loss: 2.6770145893096924
Validation loss: 2.5023988036699194

Epoch: 5| Step: 9
Training loss: 3.3883864879608154
Validation loss: 2.4973150709623932

Epoch: 5| Step: 10
Training loss: 2.093205690383911
Validation loss: 2.4944200772111134

Epoch: 40| Step: 0
Training loss: 2.914039373397827
Validation loss: 2.4907403710067912

Epoch: 5| Step: 1
Training loss: 3.2758285999298096
Validation loss: 2.485082423815163

Epoch: 5| Step: 2
Training loss: 2.0838725566864014
Validation loss: 2.4823448760535127

Epoch: 5| Step: 3
Training loss: 2.6090993881225586
Validation loss: 2.480734617479386

Epoch: 5| Step: 4
Training loss: 2.7933061122894287
Validation loss: 2.481214661752024

Epoch: 5| Step: 5
Training loss: 2.0622305870056152
Validation loss: 2.4780905195461806

Epoch: 5| Step: 6
Training loss: 3.138340950012207
Validation loss: 2.481142738813995

Epoch: 5| Step: 7
Training loss: 2.9204049110412598
Validation loss: 2.478076814323343

Epoch: 5| Step: 8
Training loss: 2.7560222148895264
Validation loss: 2.475728973265617

Epoch: 5| Step: 9
Training loss: 2.381870985031128
Validation loss: 2.4741676443366596

Epoch: 5| Step: 10
Training loss: 2.7577173709869385
Validation loss: 2.4754814870895876

Epoch: 41| Step: 0
Training loss: 2.9086203575134277
Validation loss: 2.4787830793729393

Epoch: 5| Step: 1
Training loss: 3.0397651195526123
Validation loss: 2.4805006929623183

Epoch: 5| Step: 2
Training loss: 2.650876522064209
Validation loss: 2.484762296881727

Epoch: 5| Step: 3
Training loss: 3.1282429695129395
Validation loss: 2.491378661124937

Epoch: 5| Step: 4
Training loss: 2.4419639110565186
Validation loss: 2.498614400945684

Epoch: 5| Step: 5
Training loss: 2.833359479904175
Validation loss: 2.5053554145238732

Epoch: 5| Step: 6
Training loss: 2.3479886054992676
Validation loss: 2.498572305966449

Epoch: 5| Step: 7
Training loss: 2.3307242393493652
Validation loss: 2.4993274647702455

Epoch: 5| Step: 8
Training loss: 2.2174696922302246
Validation loss: 2.4829076695185837

Epoch: 5| Step: 9
Training loss: 2.954124927520752
Validation loss: 2.459597049220916

Epoch: 5| Step: 10
Training loss: 2.7131361961364746
Validation loss: 2.45898780258753

Epoch: 42| Step: 0
Training loss: 2.6550376415252686
Validation loss: 2.4957066735913678

Epoch: 5| Step: 1
Training loss: 2.1047675609588623
Validation loss: 2.4710196987275155

Epoch: 5| Step: 2
Training loss: 2.4926352500915527
Validation loss: 2.4582956067977415

Epoch: 5| Step: 3
Training loss: 3.3613510131835938
Validation loss: 2.449448267618815

Epoch: 5| Step: 4
Training loss: 2.9163386821746826
Validation loss: 2.433433130223264

Epoch: 5| Step: 5
Training loss: 2.388181209564209
Validation loss: 2.4256191766390236

Epoch: 5| Step: 6
Training loss: 2.6545844078063965
Validation loss: 2.4291296210340274

Epoch: 5| Step: 7
Training loss: 3.152531147003174
Validation loss: 2.433912738676994

Epoch: 5| Step: 8
Training loss: 2.3854846954345703
Validation loss: 2.444490049474983

Epoch: 5| Step: 9
Training loss: 2.8803396224975586
Validation loss: 2.4706350603411273

Epoch: 5| Step: 10
Training loss: 2.588458299636841
Validation loss: 2.48524639427021

Epoch: 43| Step: 0
Training loss: 3.173835277557373
Validation loss: 2.5178466407201623

Epoch: 5| Step: 1
Training loss: 2.202235698699951
Validation loss: 2.482633756053063

Epoch: 5| Step: 2
Training loss: 2.736063003540039
Validation loss: 2.4306020480330273

Epoch: 5| Step: 3
Training loss: 2.302299976348877
Validation loss: 2.421619945956815

Epoch: 5| Step: 4
Training loss: 2.764944314956665
Validation loss: 2.416297827997515

Epoch: 5| Step: 5
Training loss: 2.9115447998046875
Validation loss: 2.4146905586283696

Epoch: 5| Step: 6
Training loss: 3.0011589527130127
Validation loss: 2.4125087389381985

Epoch: 5| Step: 7
Training loss: 2.5100765228271484
Validation loss: 2.4153119569183676

Epoch: 5| Step: 8
Training loss: 2.836137056350708
Validation loss: 2.4222992953433784

Epoch: 5| Step: 9
Training loss: 2.578479528427124
Validation loss: 2.4248476438624884

Epoch: 5| Step: 10
Training loss: 2.3490848541259766
Validation loss: 2.433864119232342

Epoch: 44| Step: 0
Training loss: 2.6434876918792725
Validation loss: 2.440566257763934

Epoch: 5| Step: 1
Training loss: 2.8261165618896484
Validation loss: 2.461674072409189

Epoch: 5| Step: 2
Training loss: 2.1586451530456543
Validation loss: 2.4766588544332855

Epoch: 5| Step: 3
Training loss: 2.09521484375
Validation loss: 2.489245776207216

Epoch: 5| Step: 4
Training loss: 3.0648207664489746
Validation loss: 2.505290105778684

Epoch: 5| Step: 5
Training loss: 3.017387866973877
Validation loss: 2.5355707599270727

Epoch: 5| Step: 6
Training loss: 2.316577672958374
Validation loss: 2.52769144376119

Epoch: 5| Step: 7
Training loss: 2.623741626739502
Validation loss: 2.5115153225519324

Epoch: 5| Step: 8
Training loss: 3.478654384613037
Validation loss: 2.5353839448703233

Epoch: 5| Step: 9
Training loss: 3.027395486831665
Validation loss: 2.5554175248710056

Epoch: 5| Step: 10
Training loss: 2.306973695755005
Validation loss: 2.5419222360016196

Epoch: 45| Step: 0
Training loss: 2.5938785076141357
Validation loss: 2.5355195794054257

Epoch: 5| Step: 1
Training loss: 2.79624342918396
Validation loss: 2.5260903296932096

Epoch: 5| Step: 2
Training loss: 2.2982442378997803
Validation loss: 2.508962139006584

Epoch: 5| Step: 3
Training loss: 3.159444570541382
Validation loss: 2.5042865763428392

Epoch: 5| Step: 4
Training loss: 3.6274402141571045
Validation loss: 2.491785967221824

Epoch: 5| Step: 5
Training loss: 2.64146089553833
Validation loss: 2.4645638209517284

Epoch: 5| Step: 6
Training loss: 2.069622755050659
Validation loss: 2.450414087182732

Epoch: 5| Step: 7
Training loss: 2.9871468544006348
Validation loss: 2.4348561071580455

Epoch: 5| Step: 8
Training loss: 2.7748847007751465
Validation loss: 2.423204614270118

Epoch: 5| Step: 9
Training loss: 2.4227566719055176
Validation loss: 2.416906800321353

Epoch: 5| Step: 10
Training loss: 2.0460093021392822
Validation loss: 2.4164232771883727

Epoch: 46| Step: 0
Training loss: 2.947697162628174
Validation loss: 2.4173336721235708

Epoch: 5| Step: 1
Training loss: 2.5748870372772217
Validation loss: 2.4185717644230014

Epoch: 5| Step: 2
Training loss: 2.913043975830078
Validation loss: 2.416266425963371

Epoch: 5| Step: 3
Training loss: 3.3005309104919434
Validation loss: 2.4164325062946608

Epoch: 5| Step: 4
Training loss: 2.6099085807800293
Validation loss: 2.414476543344477

Epoch: 5| Step: 5
Training loss: 2.4167706966400146
Validation loss: 2.4155007177783596

Epoch: 5| Step: 6
Training loss: 2.610989809036255
Validation loss: 2.4187827905019126

Epoch: 5| Step: 7
Training loss: 1.9048798084259033
Validation loss: 2.420067884588754

Epoch: 5| Step: 8
Training loss: 2.7905712127685547
Validation loss: 2.418735465695781

Epoch: 5| Step: 9
Training loss: 2.623241901397705
Validation loss: 2.4212162469023015

Epoch: 5| Step: 10
Training loss: 2.676098346710205
Validation loss: 2.420914283362768

Epoch: 47| Step: 0
Training loss: 2.7811622619628906
Validation loss: 2.424671410232462

Epoch: 5| Step: 1
Training loss: 2.33312726020813
Validation loss: 2.4269800391248477

Epoch: 5| Step: 2
Training loss: 2.5746092796325684
Validation loss: 2.4280215488967074

Epoch: 5| Step: 3
Training loss: 2.879708766937256
Validation loss: 2.44006105648574

Epoch: 5| Step: 4
Training loss: 2.5029633045196533
Validation loss: 2.455867403297014

Epoch: 5| Step: 5
Training loss: 2.6747281551361084
Validation loss: 2.472027245388236

Epoch: 5| Step: 6
Training loss: 3.246664047241211
Validation loss: 2.475813568279307

Epoch: 5| Step: 7
Training loss: 2.9498724937438965
Validation loss: 2.4712676643043436

Epoch: 5| Step: 8
Training loss: 2.565035343170166
Validation loss: 2.4665977211408716

Epoch: 5| Step: 9
Training loss: 2.55458402633667
Validation loss: 2.4590179971469346

Epoch: 5| Step: 10
Training loss: 2.254945993423462
Validation loss: 2.449232388568181

Epoch: 48| Step: 0
Training loss: 3.1588923931121826
Validation loss: 2.4398925791504564

Epoch: 5| Step: 1
Training loss: 2.261899709701538
Validation loss: 2.4317304665042507

Epoch: 5| Step: 2
Training loss: 2.662341833114624
Validation loss: 2.4276719939324165

Epoch: 5| Step: 3
Training loss: 2.5474822521209717
Validation loss: 2.427015032819522

Epoch: 5| Step: 4
Training loss: 2.7811026573181152
Validation loss: 2.424515393472487

Epoch: 5| Step: 5
Training loss: 2.5741240978240967
Validation loss: 2.4152493220503612

Epoch: 5| Step: 6
Training loss: 2.730370044708252
Validation loss: 2.4167899752175934

Epoch: 5| Step: 7
Training loss: 2.2236618995666504
Validation loss: 2.4192876149249334

Epoch: 5| Step: 8
Training loss: 2.9150309562683105
Validation loss: 2.414877958195184

Epoch: 5| Step: 9
Training loss: 2.419541835784912
Validation loss: 2.414053773367277

Epoch: 5| Step: 10
Training loss: 3.024550199508667
Validation loss: 2.412488055485551

Epoch: 49| Step: 0
Training loss: 2.9630942344665527
Validation loss: 2.4123689154142975

Epoch: 5| Step: 1
Training loss: 2.3225228786468506
Validation loss: 2.4113129313274095

Epoch: 5| Step: 2
Training loss: 1.9585771560668945
Validation loss: 2.4108242629676737

Epoch: 5| Step: 3
Training loss: 2.5382466316223145
Validation loss: 2.4194511546883533

Epoch: 5| Step: 4
Training loss: 2.6368017196655273
Validation loss: 2.418310664033377

Epoch: 5| Step: 5
Training loss: 2.927889347076416
Validation loss: 2.418517271677653

Epoch: 5| Step: 6
Training loss: 2.593822956085205
Validation loss: 2.415878781708338

Epoch: 5| Step: 7
Training loss: 2.9973702430725098
Validation loss: 2.415034729947326

Epoch: 5| Step: 8
Training loss: 2.9525036811828613
Validation loss: 2.4159486011792253

Epoch: 5| Step: 9
Training loss: 1.9832286834716797
Validation loss: 2.4172731368772444

Epoch: 5| Step: 10
Training loss: 3.357167959213257
Validation loss: 2.4165321832062094

Epoch: 50| Step: 0
Training loss: 3.0600924491882324
Validation loss: 2.4157216587374286

Epoch: 5| Step: 1
Training loss: 2.3164806365966797
Validation loss: 2.4164387590141705

Epoch: 5| Step: 2
Training loss: 2.4472453594207764
Validation loss: 2.424255706930673

Epoch: 5| Step: 3
Training loss: 2.699951410293579
Validation loss: 2.431527409502255

Epoch: 5| Step: 4
Training loss: 2.270613193511963
Validation loss: 2.440331644909356

Epoch: 5| Step: 5
Training loss: 3.4917728900909424
Validation loss: 2.465294794369769

Epoch: 5| Step: 6
Training loss: 3.2437233924865723
Validation loss: 2.4645967842430196

Epoch: 5| Step: 7
Training loss: 2.784670114517212
Validation loss: 2.4658036590904318

Epoch: 5| Step: 8
Training loss: 2.7460668087005615
Validation loss: 2.4653925485508417

Epoch: 5| Step: 9
Training loss: 1.839503526687622
Validation loss: 2.467781651404596

Epoch: 5| Step: 10
Training loss: 2.2680904865264893
Validation loss: 2.4543344423335087

Epoch: 51| Step: 0
Training loss: 3.3361732959747314
Validation loss: 2.4458758497750885

Epoch: 5| Step: 1
Training loss: 2.0595145225524902
Validation loss: 2.4398372404036985

Epoch: 5| Step: 2
Training loss: 2.921929359436035
Validation loss: 2.440534771129649

Epoch: 5| Step: 3
Training loss: 2.53943133354187
Validation loss: 2.434462808793591

Epoch: 5| Step: 4
Training loss: 3.3712410926818848
Validation loss: 2.427027053730462

Epoch: 5| Step: 5
Training loss: 1.9603233337402344
Validation loss: 2.4137131373087564

Epoch: 5| Step: 6
Training loss: 2.6917049884796143
Validation loss: 2.3979159683309574

Epoch: 5| Step: 7
Training loss: 2.97337007522583
Validation loss: 2.3944966023968113

Epoch: 5| Step: 8
Training loss: 2.388136625289917
Validation loss: 2.396940185177711

Epoch: 5| Step: 9
Training loss: 1.833444356918335
Validation loss: 2.3939778881688274

Epoch: 5| Step: 10
Training loss: 3.128324508666992
Validation loss: 2.393727207696566

Epoch: 52| Step: 0
Training loss: 2.467933177947998
Validation loss: 2.3910023473924205

Epoch: 5| Step: 1
Training loss: 2.2357230186462402
Validation loss: 2.3912023780166463

Epoch: 5| Step: 2
Training loss: 3.2590832710266113
Validation loss: 2.3893795577428674

Epoch: 5| Step: 3
Training loss: 2.658097743988037
Validation loss: 2.390514553234141

Epoch: 5| Step: 4
Training loss: 2.4296939373016357
Validation loss: 2.392056234421269

Epoch: 5| Step: 5
Training loss: 3.032517910003662
Validation loss: 2.384133118455128

Epoch: 5| Step: 6
Training loss: 2.6976425647735596
Validation loss: 2.3798945257740636

Epoch: 5| Step: 7
Training loss: 1.884225845336914
Validation loss: 2.387394715380925

Epoch: 5| Step: 8
Training loss: 2.990272283554077
Validation loss: 2.3913215898698374

Epoch: 5| Step: 9
Training loss: 2.8929080963134766
Validation loss: 2.3897638654196136

Epoch: 5| Step: 10
Training loss: 2.3713409900665283
Validation loss: 2.3829543180363153

Epoch: 53| Step: 0
Training loss: 2.7822043895721436
Validation loss: 2.38059002096935

Epoch: 5| Step: 1
Training loss: 2.541935443878174
Validation loss: 2.3812124665065477

Epoch: 5| Step: 2
Training loss: 2.4319517612457275
Validation loss: 2.371482200520013

Epoch: 5| Step: 3
Training loss: 2.9502925872802734
Validation loss: 2.3743095987586567

Epoch: 5| Step: 4
Training loss: 2.578664779663086
Validation loss: 2.372115783793952

Epoch: 5| Step: 5
Training loss: 2.6663570404052734
Validation loss: 2.3672447281499065

Epoch: 5| Step: 6
Training loss: 2.8409950733184814
Validation loss: 2.3709708593224965

Epoch: 5| Step: 7
Training loss: 2.806185245513916
Validation loss: 2.363343523394677

Epoch: 5| Step: 8
Training loss: 2.268315553665161
Validation loss: 2.365242378686064

Epoch: 5| Step: 9
Training loss: 2.8999252319335938
Validation loss: 2.367222668022238

Epoch: 5| Step: 10
Training loss: 1.8020944595336914
Validation loss: 2.36927669407219

Epoch: 54| Step: 0
Training loss: 2.709409713745117
Validation loss: 2.3847037643514652

Epoch: 5| Step: 1
Training loss: 2.5658364295959473
Validation loss: 2.379451074907857

Epoch: 5| Step: 2
Training loss: 2.5367836952209473
Validation loss: 2.3747906428511425

Epoch: 5| Step: 3
Training loss: 2.671217679977417
Validation loss: 2.37516753391553

Epoch: 5| Step: 4
Training loss: 2.9505441188812256
Validation loss: 2.3722336407630675

Epoch: 5| Step: 5
Training loss: 2.6399810314178467
Validation loss: 2.376519900496288

Epoch: 5| Step: 6
Training loss: 1.8642642498016357
Validation loss: 2.3865722840832126

Epoch: 5| Step: 7
Training loss: 3.1427338123321533
Validation loss: 2.387312167434282

Epoch: 5| Step: 8
Training loss: 2.5644538402557373
Validation loss: 2.3779360786561043

Epoch: 5| Step: 9
Training loss: 2.615109920501709
Validation loss: 2.3806386711776897

Epoch: 5| Step: 10
Training loss: 2.4527738094329834
Validation loss: 2.3875840633146224

Epoch: 55| Step: 0
Training loss: 2.1629765033721924
Validation loss: 2.3864891580356065

Epoch: 5| Step: 1
Training loss: 2.6036415100097656
Validation loss: 2.37839437043795

Epoch: 5| Step: 2
Training loss: 3.0068182945251465
Validation loss: 2.3781841621604016

Epoch: 5| Step: 3
Training loss: 3.256129741668701
Validation loss: 2.372805483879582

Epoch: 5| Step: 4
Training loss: 2.3669862747192383
Validation loss: 2.3726844967052503

Epoch: 5| Step: 5
Training loss: 3.2111916542053223
Validation loss: 2.371794846750075

Epoch: 5| Step: 6
Training loss: 2.621922016143799
Validation loss: 2.3653080386500203

Epoch: 5| Step: 7
Training loss: 2.3346190452575684
Validation loss: 2.354327952989968

Epoch: 5| Step: 8
Training loss: 2.5646214485168457
Validation loss: 2.3578437015574467

Epoch: 5| Step: 9
Training loss: 2.1808695793151855
Validation loss: 2.3513676043479674

Epoch: 5| Step: 10
Training loss: 2.2094430923461914
Validation loss: 2.351845872017645

Epoch: 56| Step: 0
Training loss: 2.9224534034729004
Validation loss: 2.3460810851025324

Epoch: 5| Step: 1
Training loss: 2.4420952796936035
Validation loss: 2.3404866623622116

Epoch: 5| Step: 2
Training loss: 2.3977887630462646
Validation loss: 2.337362612447431

Epoch: 5| Step: 3
Training loss: 2.438694953918457
Validation loss: 2.3340427798609578

Epoch: 5| Step: 4
Training loss: 2.7445273399353027
Validation loss: 2.331188545432142

Epoch: 5| Step: 5
Training loss: 3.1445846557617188
Validation loss: 2.333663873775031

Epoch: 5| Step: 6
Training loss: 2.505260944366455
Validation loss: 2.333976376441217

Epoch: 5| Step: 7
Training loss: 2.311265468597412
Validation loss: 2.335052967071533

Epoch: 5| Step: 8
Training loss: 2.388580799102783
Validation loss: 2.336656924216978

Epoch: 5| Step: 9
Training loss: 2.7819950580596924
Validation loss: 2.335888393463627

Epoch: 5| Step: 10
Training loss: 2.557981491088867
Validation loss: 2.3348598736588673

Epoch: 57| Step: 0
Training loss: 2.5941927433013916
Validation loss: 2.3357320754758772

Epoch: 5| Step: 1
Training loss: 2.2026469707489014
Validation loss: 2.3326337209311863

Epoch: 5| Step: 2
Training loss: 2.0136659145355225
Validation loss: 2.3282900625659573

Epoch: 5| Step: 3
Training loss: 2.850372791290283
Validation loss: 2.326993839715117

Epoch: 5| Step: 4
Training loss: 2.671966791152954
Validation loss: 2.324174875854164

Epoch: 5| Step: 5
Training loss: 2.7494640350341797
Validation loss: 2.3266747895107476

Epoch: 5| Step: 6
Training loss: 2.932478666305542
Validation loss: 2.327282685105519

Epoch: 5| Step: 7
Training loss: 2.521820068359375
Validation loss: 2.325078373314232

Epoch: 5| Step: 8
Training loss: 2.8461737632751465
Validation loss: 2.324123690205236

Epoch: 5| Step: 9
Training loss: 2.797210693359375
Validation loss: 2.3209599461606754

Epoch: 5| Step: 10
Training loss: 2.3536925315856934
Validation loss: 2.3274428895724717

Epoch: 58| Step: 0
Training loss: 2.627620220184326
Validation loss: 2.3241322322558333

Epoch: 5| Step: 1
Training loss: 2.7495408058166504
Validation loss: 2.32527413675862

Epoch: 5| Step: 2
Training loss: 2.937288999557495
Validation loss: 2.323754579790177

Epoch: 5| Step: 3
Training loss: 2.544684886932373
Validation loss: 2.3213132043038645

Epoch: 5| Step: 4
Training loss: 2.988196611404419
Validation loss: 2.3171887628493772

Epoch: 5| Step: 5
Training loss: 2.739929676055908
Validation loss: 2.316767108055853

Epoch: 5| Step: 6
Training loss: 1.6632425785064697
Validation loss: 2.3151526322928806

Epoch: 5| Step: 7
Training loss: 3.101748466491699
Validation loss: 2.313703347277898

Epoch: 5| Step: 8
Training loss: 2.1059253215789795
Validation loss: 2.314233982434837

Epoch: 5| Step: 9
Training loss: 2.453913450241089
Validation loss: 2.311667828149693

Epoch: 5| Step: 10
Training loss: 2.6278746128082275
Validation loss: 2.3152045075611403

Epoch: 59| Step: 0
Training loss: 2.851670026779175
Validation loss: 2.321513565637732

Epoch: 5| Step: 1
Training loss: 2.5839591026306152
Validation loss: 2.331079508668633

Epoch: 5| Step: 2
Training loss: 2.749743700027466
Validation loss: 2.3521764868049213

Epoch: 5| Step: 3
Training loss: 2.6214771270751953
Validation loss: 2.356882918265558

Epoch: 5| Step: 4
Training loss: 2.9657797813415527
Validation loss: 2.3662585699430077

Epoch: 5| Step: 5
Training loss: 2.214743137359619
Validation loss: 2.3441364201166297

Epoch: 5| Step: 6
Training loss: 2.1246063709259033
Validation loss: 2.3252520048490135

Epoch: 5| Step: 7
Training loss: 3.228999376296997
Validation loss: 2.320122721374676

Epoch: 5| Step: 8
Training loss: 2.702763557434082
Validation loss: 2.3147565805783836

Epoch: 5| Step: 9
Training loss: 2.575795888900757
Validation loss: 2.3140384766363327

Epoch: 5| Step: 10
Training loss: 1.8118027448654175
Validation loss: 2.311144692923433

Epoch: 60| Step: 0
Training loss: 2.9542369842529297
Validation loss: 2.3117248140355593

Epoch: 5| Step: 1
Training loss: 2.4306743144989014
Validation loss: 2.3136282326072775

Epoch: 5| Step: 2
Training loss: 2.5284392833709717
Validation loss: 2.3100178011002077

Epoch: 5| Step: 3
Training loss: 2.3632965087890625
Validation loss: 2.309286090635484

Epoch: 5| Step: 4
Training loss: 2.77752947807312
Validation loss: 2.3101275608103764

Epoch: 5| Step: 5
Training loss: 2.3508145809173584
Validation loss: 2.311495775817543

Epoch: 5| Step: 6
Training loss: 2.638324499130249
Validation loss: 2.3089626732692925

Epoch: 5| Step: 7
Training loss: 2.961545944213867
Validation loss: 2.310067971547445

Epoch: 5| Step: 8
Training loss: 2.4545669555664062
Validation loss: 2.30870226634446

Epoch: 5| Step: 9
Training loss: 2.427933692932129
Validation loss: 2.307255660333941

Epoch: 5| Step: 10
Training loss: 2.566545009613037
Validation loss: 2.310335592557025

Epoch: 61| Step: 0
Training loss: 2.6138253211975098
Validation loss: 2.3200073024278045

Epoch: 5| Step: 1
Training loss: 2.866868257522583
Validation loss: 2.3210400099395425

Epoch: 5| Step: 2
Training loss: 3.022059440612793
Validation loss: 2.3236648369860906

Epoch: 5| Step: 3
Training loss: 2.072563409805298
Validation loss: 2.3194293847648044

Epoch: 5| Step: 4
Training loss: 3.1445865631103516
Validation loss: 2.325082666130476

Epoch: 5| Step: 5
Training loss: 2.5926332473754883
Validation loss: 2.3307466609503633

Epoch: 5| Step: 6
Training loss: 2.590528964996338
Validation loss: 2.338635854823615

Epoch: 5| Step: 7
Training loss: 2.6625990867614746
Validation loss: 2.3500426430856027

Epoch: 5| Step: 8
Training loss: 2.681184768676758
Validation loss: 2.3333320310038905

Epoch: 5| Step: 9
Training loss: 2.2639174461364746
Validation loss: 2.307103753089905

Epoch: 5| Step: 10
Training loss: 1.845047950744629
Validation loss: 2.297172305404499

Epoch: 62| Step: 0
Training loss: 2.4710733890533447
Validation loss: 2.2983278523209276

Epoch: 5| Step: 1
Training loss: 3.2403883934020996
Validation loss: 2.2966671041263047

Epoch: 5| Step: 2
Training loss: 2.7175140380859375
Validation loss: 2.2975383189416703

Epoch: 5| Step: 3
Training loss: 2.103182315826416
Validation loss: 2.2970552880276918

Epoch: 5| Step: 4
Training loss: 2.49263858795166
Validation loss: 2.295738717561127

Epoch: 5| Step: 5
Training loss: 2.9381351470947266
Validation loss: 2.298839433218843

Epoch: 5| Step: 6
Training loss: 2.5447278022766113
Validation loss: 2.3034653022725093

Epoch: 5| Step: 7
Training loss: 2.216583728790283
Validation loss: 2.3054800751388713

Epoch: 5| Step: 8
Training loss: 2.669152021408081
Validation loss: 2.304542412040054

Epoch: 5| Step: 9
Training loss: 2.181668281555176
Validation loss: 2.3071950558693177

Epoch: 5| Step: 10
Training loss: 2.9314486980438232
Validation loss: 2.3185151520595757

Epoch: 63| Step: 0
Training loss: 2.360854387283325
Validation loss: 2.3192831905939246

Epoch: 5| Step: 1
Training loss: 2.606100559234619
Validation loss: 2.325344193366266

Epoch: 5| Step: 2
Training loss: 2.7878634929656982
Validation loss: 2.3285354619385092

Epoch: 5| Step: 3
Training loss: 2.2170166969299316
Validation loss: 2.3280092259889007

Epoch: 5| Step: 4
Training loss: 3.027876377105713
Validation loss: 2.3343111930354947

Epoch: 5| Step: 5
Training loss: 2.880427837371826
Validation loss: 2.3364493744347685

Epoch: 5| Step: 6
Training loss: 2.7415308952331543
Validation loss: 2.33259992958397

Epoch: 5| Step: 7
Training loss: 2.7015912532806396
Validation loss: 2.3244095899725474

Epoch: 5| Step: 8
Training loss: 2.1505308151245117
Validation loss: 2.302495812857023

Epoch: 5| Step: 9
Training loss: 2.347357988357544
Validation loss: 2.2963657071513515

Epoch: 5| Step: 10
Training loss: 2.4713973999023438
Validation loss: 2.2897909789957027

Epoch: 64| Step: 0
Training loss: 2.567025661468506
Validation loss: 2.290505040076471

Epoch: 5| Step: 1
Training loss: 2.906700611114502
Validation loss: 2.290062878721504

Epoch: 5| Step: 2
Training loss: 1.9682095050811768
Validation loss: 2.295799357916719

Epoch: 5| Step: 3
Training loss: 2.515859603881836
Validation loss: 2.2965761000110256

Epoch: 5| Step: 4
Training loss: 2.130974531173706
Validation loss: 2.296715946607692

Epoch: 5| Step: 5
Training loss: 2.395113229751587
Validation loss: 2.291862846702658

Epoch: 5| Step: 6
Training loss: 2.6279876232147217
Validation loss: 2.292211931238892

Epoch: 5| Step: 7
Training loss: 2.704982280731201
Validation loss: 2.293402479540917

Epoch: 5| Step: 8
Training loss: 3.3749802112579346
Validation loss: 2.296589361724033

Epoch: 5| Step: 9
Training loss: 2.7479248046875
Validation loss: 2.302531983262749

Epoch: 5| Step: 10
Training loss: 2.381312131881714
Validation loss: 2.2927051667244203

Epoch: 65| Step: 0
Training loss: 2.7857112884521484
Validation loss: 2.2906457942019225

Epoch: 5| Step: 1
Training loss: 2.9071426391601562
Validation loss: 2.2865283104681198

Epoch: 5| Step: 2
Training loss: 2.7037792205810547
Validation loss: 2.283152969934607

Epoch: 5| Step: 3
Training loss: 2.594974994659424
Validation loss: 2.278506491773872

Epoch: 5| Step: 4
Training loss: 3.000756025314331
Validation loss: 2.2788754842614614

Epoch: 5| Step: 5
Training loss: 2.489624261856079
Validation loss: 2.281031059962447

Epoch: 5| Step: 6
Training loss: 2.4982008934020996
Validation loss: 2.2784531116485596

Epoch: 5| Step: 7
Training loss: 2.058013439178467
Validation loss: 2.286819763081048

Epoch: 5| Step: 8
Training loss: 2.1572537422180176
Validation loss: 2.298003106988886

Epoch: 5| Step: 9
Training loss: 2.511709213256836
Validation loss: 2.3056752604822957

Epoch: 5| Step: 10
Training loss: 2.5918397903442383
Validation loss: 2.3212812382687806

Epoch: 66| Step: 0
Training loss: 2.3263955116271973
Validation loss: 2.3418185172542447

Epoch: 5| Step: 1
Training loss: 1.9539684057235718
Validation loss: 2.373382883687173

Epoch: 5| Step: 2
Training loss: 2.1248042583465576
Validation loss: 2.426706196159445

Epoch: 5| Step: 3
Training loss: 3.2367167472839355
Validation loss: 2.4384697021976596

Epoch: 5| Step: 4
Training loss: 3.1361193656921387
Validation loss: 2.416377221384356

Epoch: 5| Step: 5
Training loss: 2.235666513442993
Validation loss: 2.3694257505478395

Epoch: 5| Step: 6
Training loss: 2.788355588912964
Validation loss: 2.3128895246854393

Epoch: 5| Step: 7
Training loss: 2.4695518016815186
Validation loss: 2.2795222190118607

Epoch: 5| Step: 8
Training loss: 3.0200276374816895
Validation loss: 2.276955545589488

Epoch: 5| Step: 9
Training loss: 2.982042074203491
Validation loss: 2.301093711647936

Epoch: 5| Step: 10
Training loss: 2.2457900047302246
Validation loss: 2.3323143528353785

Epoch: 67| Step: 0
Training loss: 2.649777889251709
Validation loss: 2.4072544267100673

Epoch: 5| Step: 1
Training loss: 2.9630630016326904
Validation loss: 2.51465783580657

Epoch: 5| Step: 2
Training loss: 2.769700527191162
Validation loss: 2.498721397051247

Epoch: 5| Step: 3
Training loss: 2.4349002838134766
Validation loss: 2.446873236727971

Epoch: 5| Step: 4
Training loss: 2.542942523956299
Validation loss: 2.3784147231809554

Epoch: 5| Step: 5
Training loss: 2.9967381954193115
Validation loss: 2.3429344059318624

Epoch: 5| Step: 6
Training loss: 2.2174155712127686
Validation loss: 2.317831770066292

Epoch: 5| Step: 7
Training loss: 2.819457769393921
Validation loss: 2.302139748809158

Epoch: 5| Step: 8
Training loss: 2.8953022956848145
Validation loss: 2.2861916659980692

Epoch: 5| Step: 9
Training loss: 2.315639019012451
Validation loss: 2.2776697681796167

Epoch: 5| Step: 10
Training loss: 2.653318166732788
Validation loss: 2.292432044142036

Epoch: 68| Step: 0
Training loss: 2.8172314167022705
Validation loss: 2.338488273723151

Epoch: 5| Step: 1
Training loss: 2.638230800628662
Validation loss: 2.3610380516257337

Epoch: 5| Step: 2
Training loss: 2.195342779159546
Validation loss: 2.3991812813666558

Epoch: 5| Step: 3
Training loss: 2.41388201713562
Validation loss: 2.477548914570962

Epoch: 5| Step: 4
Training loss: 2.503390073776245
Validation loss: 2.5166046286142

Epoch: 5| Step: 5
Training loss: 2.406223773956299
Validation loss: 2.511974480844313

Epoch: 5| Step: 6
Training loss: 2.3095526695251465
Validation loss: 2.4899275943797123

Epoch: 5| Step: 7
Training loss: 2.7713325023651123
Validation loss: 2.4164113178048083

Epoch: 5| Step: 8
Training loss: 3.004774808883667
Validation loss: 2.367600664015739

Epoch: 5| Step: 9
Training loss: 3.4166316986083984
Validation loss: 2.3042613972899733

Epoch: 5| Step: 10
Training loss: 2.20635986328125
Validation loss: 2.2811701964306574

Epoch: 69| Step: 0
Training loss: 2.2730984687805176
Validation loss: 2.271795254881664

Epoch: 5| Step: 1
Training loss: 2.516174793243408
Validation loss: 2.2792015280774844

Epoch: 5| Step: 2
Training loss: 2.6975674629211426
Validation loss: 2.2867019676393077

Epoch: 5| Step: 3
Training loss: 2.9695816040039062
Validation loss: 2.274150712515718

Epoch: 5| Step: 4
Training loss: 2.3745532035827637
Validation loss: 2.2694808949706373

Epoch: 5| Step: 5
Training loss: 2.9604132175445557
Validation loss: 2.2658837738857476

Epoch: 5| Step: 6
Training loss: 1.9521783590316772
Validation loss: 2.2661286118210002

Epoch: 5| Step: 7
Training loss: 3.0918784141540527
Validation loss: 2.265441272848396

Epoch: 5| Step: 8
Training loss: 2.678088665008545
Validation loss: 2.262099350652387

Epoch: 5| Step: 9
Training loss: 2.275200366973877
Validation loss: 2.258062183216054

Epoch: 5| Step: 10
Training loss: 2.5316002368927
Validation loss: 2.260824413709743

Epoch: 70| Step: 0
Training loss: 2.1723384857177734
Validation loss: 2.2570338377388577

Epoch: 5| Step: 1
Training loss: 2.6831438541412354
Validation loss: 2.2658141095151185

Epoch: 5| Step: 2
Training loss: 2.806802272796631
Validation loss: 2.2595002958851476

Epoch: 5| Step: 3
Training loss: 2.28402042388916
Validation loss: 2.25157832073909

Epoch: 5| Step: 4
Training loss: 2.469728469848633
Validation loss: 2.25518464016658

Epoch: 5| Step: 5
Training loss: 3.241987705230713
Validation loss: 2.255913629326769

Epoch: 5| Step: 6
Training loss: 2.77388334274292
Validation loss: 2.255235472033101

Epoch: 5| Step: 7
Training loss: 2.2986340522766113
Validation loss: 2.2588559401932584

Epoch: 5| Step: 8
Training loss: 2.952599287033081
Validation loss: 2.2562434096490183

Epoch: 5| Step: 9
Training loss: 2.215210199356079
Validation loss: 2.25520142175818

Epoch: 5| Step: 10
Training loss: 2.1436831951141357
Validation loss: 2.255044501314881

Epoch: 71| Step: 0
Training loss: 2.848456382751465
Validation loss: 2.2593266835776706

Epoch: 5| Step: 1
Training loss: 2.6709446907043457
Validation loss: 2.2691760268262637

Epoch: 5| Step: 2
Training loss: 2.341475486755371
Validation loss: 2.2675163258788404

Epoch: 5| Step: 3
Training loss: 2.031982898712158
Validation loss: 2.281755147441741

Epoch: 5| Step: 4
Training loss: 2.371746063232422
Validation loss: 2.2975446934341104

Epoch: 5| Step: 5
Training loss: 2.1768012046813965
Validation loss: 2.309735490429786

Epoch: 5| Step: 6
Training loss: 2.6028926372528076
Validation loss: 2.320769417670465

Epoch: 5| Step: 7
Training loss: 2.821150064468384
Validation loss: 2.3140094869880268

Epoch: 5| Step: 8
Training loss: 3.308173656463623
Validation loss: 2.2903407594209075

Epoch: 5| Step: 9
Training loss: 2.9516632556915283
Validation loss: 2.274974566633983

Epoch: 5| Step: 10
Training loss: 1.892197608947754
Validation loss: 2.2693878937793035

Epoch: 72| Step: 0
Training loss: 2.301300048828125
Validation loss: 2.2544972845303115

Epoch: 5| Step: 1
Training loss: 2.178396701812744
Validation loss: 2.248867186166907

Epoch: 5| Step: 2
Training loss: 2.6252079010009766
Validation loss: 2.2466184272561023

Epoch: 5| Step: 3
Training loss: 3.2995147705078125
Validation loss: 2.248217195592901

Epoch: 5| Step: 4
Training loss: 2.7810616493225098
Validation loss: 2.264323026903214

Epoch: 5| Step: 5
Training loss: 2.584700107574463
Validation loss: 2.2762922727933494

Epoch: 5| Step: 6
Training loss: 3.069596290588379
Validation loss: 2.28651088283908

Epoch: 5| Step: 7
Training loss: 1.6297954320907593
Validation loss: 2.2958407043128886

Epoch: 5| Step: 8
Training loss: 2.0018584728240967
Validation loss: 2.2946117642105266

Epoch: 5| Step: 9
Training loss: 2.7120590209960938
Validation loss: 2.264847247831283

Epoch: 5| Step: 10
Training loss: 2.8753817081451416
Validation loss: 2.2505918061861427

Epoch: 73| Step: 0
Training loss: 2.4508697986602783
Validation loss: 2.2556030699001846

Epoch: 5| Step: 1
Training loss: 2.154546022415161
Validation loss: 2.2522523569804367

Epoch: 5| Step: 2
Training loss: 2.46838641166687
Validation loss: 2.2459046917576946

Epoch: 5| Step: 3
Training loss: 2.7907841205596924
Validation loss: 2.2625563170320246

Epoch: 5| Step: 4
Training loss: 2.2689054012298584
Validation loss: 2.2683899915346535

Epoch: 5| Step: 5
Training loss: 2.725025177001953
Validation loss: 2.2802565405445714

Epoch: 5| Step: 6
Training loss: 2.8494186401367188
Validation loss: 2.2930084582298034

Epoch: 5| Step: 7
Training loss: 2.8895316123962402
Validation loss: 2.310347036648822

Epoch: 5| Step: 8
Training loss: 2.574504852294922
Validation loss: 2.310666299635364

Epoch: 5| Step: 9
Training loss: 2.1801459789276123
Validation loss: 2.3207240514857794

Epoch: 5| Step: 10
Training loss: 2.7999258041381836
Validation loss: 2.291787314158614

Epoch: 74| Step: 0
Training loss: 2.5806102752685547
Validation loss: 2.270536499638711

Epoch: 5| Step: 1
Training loss: 2.699773073196411
Validation loss: 2.262744511327436

Epoch: 5| Step: 2
Training loss: 2.9560391902923584
Validation loss: 2.2511826920252975

Epoch: 5| Step: 3
Training loss: 2.609325885772705
Validation loss: 2.248300808732228

Epoch: 5| Step: 4
Training loss: 2.361706018447876
Validation loss: 2.2448986678995113

Epoch: 5| Step: 5
Training loss: 2.5457637310028076
Validation loss: 2.2519811763558337

Epoch: 5| Step: 6
Training loss: 2.4804935455322266
Validation loss: 2.2554731779201056

Epoch: 5| Step: 7
Training loss: 2.4835503101348877
Validation loss: 2.2683671905148413

Epoch: 5| Step: 8
Training loss: 2.93456768989563
Validation loss: 2.2410979194025837

Epoch: 5| Step: 9
Training loss: 1.9561792612075806
Validation loss: 2.2376336384845037

Epoch: 5| Step: 10
Training loss: 2.488464832305908
Validation loss: 2.2436663348187684

Epoch: 75| Step: 0
Training loss: 2.287386417388916
Validation loss: 2.266979225220219

Epoch: 5| Step: 1
Training loss: 2.2668802738189697
Validation loss: 2.295735256646269

Epoch: 5| Step: 2
Training loss: 2.220349073410034
Validation loss: 2.345183551952403

Epoch: 5| Step: 3
Training loss: 2.5321364402770996
Validation loss: 2.3868742245499805

Epoch: 5| Step: 4
Training loss: 2.86372447013855
Validation loss: 2.410481401669082

Epoch: 5| Step: 5
Training loss: 2.680569648742676
Validation loss: 2.4376549208036034

Epoch: 5| Step: 6
Training loss: 2.4416658878326416
Validation loss: 2.4111394472019647

Epoch: 5| Step: 7
Training loss: 3.193185329437256
Validation loss: 2.3782258520844164

Epoch: 5| Step: 8
Training loss: 2.1838033199310303
Validation loss: 2.3239667210527646

Epoch: 5| Step: 9
Training loss: 2.4411895275115967
Validation loss: 2.2789028998344176

Epoch: 5| Step: 10
Training loss: 3.3945083618164062
Validation loss: 2.241693191630866

Epoch: 76| Step: 0
Training loss: 2.2692179679870605
Validation loss: 2.2247853945660334

Epoch: 5| Step: 1
Training loss: 2.5071799755096436
Validation loss: 2.2306634341516802

Epoch: 5| Step: 2
Training loss: 2.87992262840271
Validation loss: 2.2377318592481714

Epoch: 5| Step: 3
Training loss: 2.4717650413513184
Validation loss: 2.2504141381991807

Epoch: 5| Step: 4
Training loss: 2.4165263175964355
Validation loss: 2.259022020524548

Epoch: 5| Step: 5
Training loss: 2.4958152770996094
Validation loss: 2.268570375698869

Epoch: 5| Step: 6
Training loss: 1.9291670322418213
Validation loss: 2.2661097536804857

Epoch: 5| Step: 7
Training loss: 2.678776502609253
Validation loss: 2.2587982505880375

Epoch: 5| Step: 8
Training loss: 3.1581172943115234
Validation loss: 2.253581254712997

Epoch: 5| Step: 9
Training loss: 3.149291515350342
Validation loss: 2.2469845792298675

Epoch: 5| Step: 10
Training loss: 2.1713812351226807
Validation loss: 2.2445094867419173

Epoch: 77| Step: 0
Training loss: 2.5139474868774414
Validation loss: 2.2369945638923237

Epoch: 5| Step: 1
Training loss: 2.7069878578186035
Validation loss: 2.238299774867232

Epoch: 5| Step: 2
Training loss: 2.516061305999756
Validation loss: 2.234100377687844

Epoch: 5| Step: 3
Training loss: 2.3411192893981934
Validation loss: 2.2404765082943823

Epoch: 5| Step: 4
Training loss: 2.282794952392578
Validation loss: 2.254273606884864

Epoch: 5| Step: 5
Training loss: 2.732326030731201
Validation loss: 2.285874507760489

Epoch: 5| Step: 6
Training loss: 2.5731022357940674
Validation loss: 2.3143297010852444

Epoch: 5| Step: 7
Training loss: 2.543360471725464
Validation loss: 2.295776782497283

Epoch: 5| Step: 8
Training loss: 2.5519752502441406
Validation loss: 2.2626136451639156

Epoch: 5| Step: 9
Training loss: 2.689366340637207
Validation loss: 2.240045750012962

Epoch: 5| Step: 10
Training loss: 2.4250247478485107
Validation loss: 2.2334053618933565

Epoch: 78| Step: 0
Training loss: 2.8043301105499268
Validation loss: 2.2284365597591607

Epoch: 5| Step: 1
Training loss: 2.941895008087158
Validation loss: 2.2266755719338693

Epoch: 5| Step: 2
Training loss: 1.8711646795272827
Validation loss: 2.2304546525401454

Epoch: 5| Step: 3
Training loss: 2.3794338703155518
Validation loss: 2.2299044516778763

Epoch: 5| Step: 4
Training loss: 2.5694289207458496
Validation loss: 2.2342372555886545

Epoch: 5| Step: 5
Training loss: 2.5651206970214844
Validation loss: 2.2330946947938655

Epoch: 5| Step: 6
Training loss: 2.69724702835083
Validation loss: 2.2389447996693272

Epoch: 5| Step: 7
Training loss: 2.491426467895508
Validation loss: 2.2449140074432536

Epoch: 5| Step: 8
Training loss: 3.269056797027588
Validation loss: 2.2567359196242465

Epoch: 5| Step: 9
Training loss: 1.8737716674804688
Validation loss: 2.252860830676171

Epoch: 5| Step: 10
Training loss: 2.1318767070770264
Validation loss: 2.2671456439520723

Epoch: 79| Step: 0
Training loss: 2.6307075023651123
Validation loss: 2.315345098895411

Epoch: 5| Step: 1
Training loss: 2.5655789375305176
Validation loss: 2.321723873897265

Epoch: 5| Step: 2
Training loss: 2.127683401107788
Validation loss: 2.3016090828885316

Epoch: 5| Step: 3
Training loss: 2.424509048461914
Validation loss: 2.297374274141045

Epoch: 5| Step: 4
Training loss: 2.56135630607605
Validation loss: 2.3362167983926754

Epoch: 5| Step: 5
Training loss: 2.4692187309265137
Validation loss: 2.3367449493818384

Epoch: 5| Step: 6
Training loss: 2.8317012786865234
Validation loss: 2.3212400918365805

Epoch: 5| Step: 7
Training loss: 2.661675214767456
Validation loss: 2.317972829264979

Epoch: 5| Step: 8
Training loss: 2.701824903488159
Validation loss: 2.3182722624912055

Epoch: 5| Step: 9
Training loss: 2.215850353240967
Validation loss: 2.307177828204247

Epoch: 5| Step: 10
Training loss: 2.820233106613159
Validation loss: 2.2864354733497865

Epoch: 80| Step: 0
Training loss: 2.9632999897003174
Validation loss: 2.2688229853107083

Epoch: 5| Step: 1
Training loss: 2.048309564590454
Validation loss: 2.242441249150102

Epoch: 5| Step: 2
Training loss: 2.8713228702545166
Validation loss: 2.224776952497421

Epoch: 5| Step: 3
Training loss: 2.235384941101074
Validation loss: 2.2198650734398955

Epoch: 5| Step: 4
Training loss: 2.124779224395752
Validation loss: 2.2096369215237197

Epoch: 5| Step: 5
Training loss: 2.695692777633667
Validation loss: 2.2095407132179505

Epoch: 5| Step: 6
Training loss: 3.0823683738708496
Validation loss: 2.2109156693181684

Epoch: 5| Step: 7
Training loss: 2.316117763519287
Validation loss: 2.2187223101174958

Epoch: 5| Step: 8
Training loss: 2.4021267890930176
Validation loss: 2.2209125539307952

Epoch: 5| Step: 9
Training loss: 2.31451416015625
Validation loss: 2.222255878551032

Epoch: 5| Step: 10
Training loss: 3.019228458404541
Validation loss: 2.2169243315214753

Epoch: 81| Step: 0
Training loss: 2.7280752658843994
Validation loss: 2.207234328792941

Epoch: 5| Step: 1
Training loss: 1.6871788501739502
Validation loss: 2.205487637109654

Epoch: 5| Step: 2
Training loss: 2.732057571411133
Validation loss: 2.2070061211944907

Epoch: 5| Step: 3
Training loss: 2.983473539352417
Validation loss: 2.2064476807912192

Epoch: 5| Step: 4
Training loss: 2.254983425140381
Validation loss: 2.2042037235793246

Epoch: 5| Step: 5
Training loss: 2.891918420791626
Validation loss: 2.2032142634032876

Epoch: 5| Step: 6
Training loss: 2.454789638519287
Validation loss: 2.205730648450954

Epoch: 5| Step: 7
Training loss: 3.0884125232696533
Validation loss: 2.209539633925243

Epoch: 5| Step: 8
Training loss: 2.4936013221740723
Validation loss: 2.2141077749190794

Epoch: 5| Step: 9
Training loss: 2.240676164627075
Validation loss: 2.2165215771685363

Epoch: 5| Step: 10
Training loss: 2.1997578144073486
Validation loss: 2.216699723274477

Epoch: 82| Step: 0
Training loss: 2.3108181953430176
Validation loss: 2.2282713818293747

Epoch: 5| Step: 1
Training loss: 2.853464365005493
Validation loss: 2.2279714768932712

Epoch: 5| Step: 2
Training loss: 3.0353665351867676
Validation loss: 2.2345268598166843

Epoch: 5| Step: 3
Training loss: 2.353327512741089
Validation loss: 2.2331693454455306

Epoch: 5| Step: 4
Training loss: 2.7603182792663574
Validation loss: 2.2349929014841714

Epoch: 5| Step: 5
Training loss: 2.6843342781066895
Validation loss: 2.2395510609431932

Epoch: 5| Step: 6
Training loss: 2.4797115325927734
Validation loss: 2.2362533359117407

Epoch: 5| Step: 7
Training loss: 2.806985855102539
Validation loss: 2.2366814113432363

Epoch: 5| Step: 8
Training loss: 2.3765769004821777
Validation loss: 2.230652291287658

Epoch: 5| Step: 9
Training loss: 1.641579270362854
Validation loss: 2.22279417386619

Epoch: 5| Step: 10
Training loss: 2.2541253566741943
Validation loss: 2.228690008963308

Epoch: 83| Step: 0
Training loss: 2.4867985248565674
Validation loss: 2.227154747132332

Epoch: 5| Step: 1
Training loss: 3.138131856918335
Validation loss: 2.2267108450653734

Epoch: 5| Step: 2
Training loss: 2.456963062286377
Validation loss: 2.2257305114499983

Epoch: 5| Step: 3
Training loss: 2.4714112281799316
Validation loss: 2.221055507659912

Epoch: 5| Step: 4
Training loss: 2.6305689811706543
Validation loss: 2.216970400143695

Epoch: 5| Step: 5
Training loss: 2.286435604095459
Validation loss: 2.214328101886216

Epoch: 5| Step: 6
Training loss: 2.107980728149414
Validation loss: 2.220711504259417

Epoch: 5| Step: 7
Training loss: 2.2952089309692383
Validation loss: 2.239756079130275

Epoch: 5| Step: 8
Training loss: 2.324401617050171
Validation loss: 2.272748742052304

Epoch: 5| Step: 9
Training loss: 2.866187810897827
Validation loss: 2.2938180405606508

Epoch: 5| Step: 10
Training loss: 2.343379497528076
Validation loss: 2.3057468962925736

Epoch: 84| Step: 0
Training loss: 2.556856870651245
Validation loss: 2.3178534123205368

Epoch: 5| Step: 1
Training loss: 2.0857086181640625
Validation loss: 2.3312089879025697

Epoch: 5| Step: 2
Training loss: 2.8813822269439697
Validation loss: 2.2923224420957666

Epoch: 5| Step: 3
Training loss: 2.085620403289795
Validation loss: 2.2648291280192714

Epoch: 5| Step: 4
Training loss: 2.46641206741333
Validation loss: 2.237706918870249

Epoch: 5| Step: 5
Training loss: 2.164641857147217
Validation loss: 2.222037994733421

Epoch: 5| Step: 6
Training loss: 2.8517837524414062
Validation loss: 2.207900654885077

Epoch: 5| Step: 7
Training loss: 2.92712664604187
Validation loss: 2.2005495358538885

Epoch: 5| Step: 8
Training loss: 2.512479305267334
Validation loss: 2.188546162779613

Epoch: 5| Step: 9
Training loss: 2.399662733078003
Validation loss: 2.1986815749957995

Epoch: 5| Step: 10
Training loss: 2.4504916667938232
Validation loss: 2.1972121628381873

Epoch: 85| Step: 0
Training loss: 2.7118563652038574
Validation loss: 2.1947989463806152

Epoch: 5| Step: 1
Training loss: 2.3694663047790527
Validation loss: 2.196258903831564

Epoch: 5| Step: 2
Training loss: 2.2542366981506348
Validation loss: 2.198857092088269

Epoch: 5| Step: 3
Training loss: 1.927349328994751
Validation loss: 2.2031508568794496

Epoch: 5| Step: 4
Training loss: 2.1736111640930176
Validation loss: 2.2014694521504063

Epoch: 5| Step: 5
Training loss: 2.490919589996338
Validation loss: 2.1999489876531784

Epoch: 5| Step: 6
Training loss: 2.9823222160339355
Validation loss: 2.2060400798756588

Epoch: 5| Step: 7
Training loss: 2.6532487869262695
Validation loss: 2.213846621974822

Epoch: 5| Step: 8
Training loss: 2.4605908393859863
Validation loss: 2.2208343975005613

Epoch: 5| Step: 9
Training loss: 2.725006580352783
Validation loss: 2.2302157084147134

Epoch: 5| Step: 10
Training loss: 2.658587694168091
Validation loss: 2.25093888467358

Epoch: 86| Step: 0
Training loss: 2.6273226737976074
Validation loss: 2.2598180693964802

Epoch: 5| Step: 1
Training loss: 2.8527934551239014
Validation loss: 2.2766961051571752

Epoch: 5| Step: 2
Training loss: 2.566707134246826
Validation loss: 2.2822793555516068

Epoch: 5| Step: 3
Training loss: 2.091492176055908
Validation loss: 2.256072682719077

Epoch: 5| Step: 4
Training loss: 2.8091330528259277
Validation loss: 2.2327445553195093

Epoch: 5| Step: 5
Training loss: 2.005293846130371
Validation loss: 2.214345973025086

Epoch: 5| Step: 6
Training loss: 2.6029789447784424
Validation loss: 2.196024149976751

Epoch: 5| Step: 7
Training loss: 2.6809921264648438
Validation loss: 2.1809583710085962

Epoch: 5| Step: 8
Training loss: 2.373194932937622
Validation loss: 2.1858467799361034

Epoch: 5| Step: 9
Training loss: 2.6692922115325928
Validation loss: 2.189909347923853

Epoch: 5| Step: 10
Training loss: 2.17192006111145
Validation loss: 2.1956353777198383

Epoch: 87| Step: 0
Training loss: 2.6626136302948
Validation loss: 2.1998771646971345

Epoch: 5| Step: 1
Training loss: 2.606865167617798
Validation loss: 2.202572161151517

Epoch: 5| Step: 2
Training loss: 2.6425952911376953
Validation loss: 2.2173272461019535

Epoch: 5| Step: 3
Training loss: 2.2558789253234863
Validation loss: 2.2257485364073064

Epoch: 5| Step: 4
Training loss: 2.633963108062744
Validation loss: 2.223311044836557

Epoch: 5| Step: 5
Training loss: 1.98540461063385
Validation loss: 2.214500883574127

Epoch: 5| Step: 6
Training loss: 2.737647533416748
Validation loss: 2.2091172177304506

Epoch: 5| Step: 7
Training loss: 2.60737681388855
Validation loss: 2.2055102830292075

Epoch: 5| Step: 8
Training loss: 2.466566324234009
Validation loss: 2.217889311493084

Epoch: 5| Step: 9
Training loss: 2.591632127761841
Validation loss: 2.219214347101027

Epoch: 5| Step: 10
Training loss: 2.3120789527893066
Validation loss: 2.2352183775235246

Epoch: 88| Step: 0
Training loss: 2.5807454586029053
Validation loss: 2.2389321096481813

Epoch: 5| Step: 1
Training loss: 2.051934242248535
Validation loss: 2.264887015024821

Epoch: 5| Step: 2
Training loss: 2.148003101348877
Validation loss: 2.2951097744767384

Epoch: 5| Step: 3
Training loss: 2.907723903656006
Validation loss: 2.283148447672526

Epoch: 5| Step: 4
Training loss: 2.438056468963623
Validation loss: 2.259938883525069

Epoch: 5| Step: 5
Training loss: 2.512659788131714
Validation loss: 2.2178066148552844

Epoch: 5| Step: 6
Training loss: 2.593337297439575
Validation loss: 2.1826349689114477

Epoch: 5| Step: 7
Training loss: 2.7655556201934814
Validation loss: 2.169668951342183

Epoch: 5| Step: 8
Training loss: 2.4246068000793457
Validation loss: 2.1718505531229

Epoch: 5| Step: 9
Training loss: 2.7082772254943848
Validation loss: 2.1719600551871845

Epoch: 5| Step: 10
Training loss: 2.1955206394195557
Validation loss: 2.1711148677333707

Epoch: 89| Step: 0
Training loss: 2.4221818447113037
Validation loss: 2.1814525717048237

Epoch: 5| Step: 1
Training loss: 2.1334452629089355
Validation loss: 2.186052409551477

Epoch: 5| Step: 2
Training loss: 2.3432655334472656
Validation loss: 2.2001584422203804

Epoch: 5| Step: 3
Training loss: 3.014927387237549
Validation loss: 2.2197953680510163

Epoch: 5| Step: 4
Training loss: 2.8478293418884277
Validation loss: 2.2104965794471

Epoch: 5| Step: 5
Training loss: 2.7926673889160156
Validation loss: 2.2178827152457288

Epoch: 5| Step: 6
Training loss: 2.86946439743042
Validation loss: 2.211453363459597

Epoch: 5| Step: 7
Training loss: 1.902360200881958
Validation loss: 2.2119058434681227

Epoch: 5| Step: 8
Training loss: 2.5238823890686035
Validation loss: 2.198475617234425

Epoch: 5| Step: 9
Training loss: 2.397151470184326
Validation loss: 2.1946204964832594

Epoch: 5| Step: 10
Training loss: 2.2352633476257324
Validation loss: 2.196761372268841

Epoch: 90| Step: 0
Training loss: 2.1581151485443115
Validation loss: 2.2153202205575924

Epoch: 5| Step: 1
Training loss: 2.6514785289764404
Validation loss: 2.2512761341628207

Epoch: 5| Step: 2
Training loss: 2.8415393829345703
Validation loss: 2.262031014247607

Epoch: 5| Step: 3
Training loss: 2.123753309249878
Validation loss: 2.2730695329686648

Epoch: 5| Step: 4
Training loss: 2.5725626945495605
Validation loss: 2.25995821081182

Epoch: 5| Step: 5
Training loss: 2.659795045852661
Validation loss: 2.2521948506755214

Epoch: 5| Step: 6
Training loss: 2.255669116973877
Validation loss: 2.2100405026507635

Epoch: 5| Step: 7
Training loss: 2.6622121334075928
Validation loss: 2.1933668557033745

Epoch: 5| Step: 8
Training loss: 2.726879596710205
Validation loss: 2.1805069779837005

Epoch: 5| Step: 9
Training loss: 2.23299503326416
Validation loss: 2.1682746384733464

Epoch: 5| Step: 10
Training loss: 2.292006492614746
Validation loss: 2.1647595333796676

Epoch: 91| Step: 0
Training loss: 2.295583486557007
Validation loss: 2.156076664565712

Epoch: 5| Step: 1
Training loss: 2.7387614250183105
Validation loss: 2.1627302656891527

Epoch: 5| Step: 2
Training loss: 2.199763774871826
Validation loss: 2.161404040551955

Epoch: 5| Step: 3
Training loss: 2.0668303966522217
Validation loss: 2.1608802144245436

Epoch: 5| Step: 4
Training loss: 2.269765853881836
Validation loss: 2.160950845287692

Epoch: 5| Step: 5
Training loss: 2.9635677337646484
Validation loss: 2.161968195310203

Epoch: 5| Step: 6
Training loss: 2.5053954124450684
Validation loss: 2.1666368028169036

Epoch: 5| Step: 7
Training loss: 2.982130527496338
Validation loss: 2.179588563980595

Epoch: 5| Step: 8
Training loss: 2.419975757598877
Validation loss: 2.1881544256723053

Epoch: 5| Step: 9
Training loss: 2.799703598022461
Validation loss: 2.18677504088289

Epoch: 5| Step: 10
Training loss: 1.9007896184921265
Validation loss: 2.176408362644975

Epoch: 92| Step: 0
Training loss: 2.2923312187194824
Validation loss: 2.171381752978089

Epoch: 5| Step: 1
Training loss: 2.4604811668395996
Validation loss: 2.161529517942859

Epoch: 5| Step: 2
Training loss: 1.8498961925506592
Validation loss: 2.157807839814053

Epoch: 5| Step: 3
Training loss: 2.4423840045928955
Validation loss: 2.1552351879817184

Epoch: 5| Step: 4
Training loss: 2.402198076248169
Validation loss: 2.157279879816117

Epoch: 5| Step: 5
Training loss: 2.3010058403015137
Validation loss: 2.1553804105327976

Epoch: 5| Step: 6
Training loss: 2.3366482257843018
Validation loss: 2.1585507521065335

Epoch: 5| Step: 7
Training loss: 2.2585718631744385
Validation loss: 2.1650403673930834

Epoch: 5| Step: 8
Training loss: 3.0935866832733154
Validation loss: 2.1724780503139702

Epoch: 5| Step: 9
Training loss: 2.6827454566955566
Validation loss: 2.175525124355029

Epoch: 5| Step: 10
Training loss: 3.007500171661377
Validation loss: 2.176098023691485

Epoch: 93| Step: 0
Training loss: 2.290100574493408
Validation loss: 2.1751409397330335

Epoch: 5| Step: 1
Training loss: 2.6760103702545166
Validation loss: 2.1869746356882076

Epoch: 5| Step: 2
Training loss: 2.9298288822174072
Validation loss: 2.176550870300621

Epoch: 5| Step: 3
Training loss: 2.6918492317199707
Validation loss: 2.1679144238912933

Epoch: 5| Step: 4
Training loss: 2.414092540740967
Validation loss: 2.179051406921879

Epoch: 5| Step: 5
Training loss: 2.075584888458252
Validation loss: 2.167866660702613

Epoch: 5| Step: 6
Training loss: 2.3367295265197754
Validation loss: 2.1659156148151686

Epoch: 5| Step: 7
Training loss: 2.2305173873901367
Validation loss: 2.1650199467136013

Epoch: 5| Step: 8
Training loss: 2.470207691192627
Validation loss: 2.162464239264047

Epoch: 5| Step: 9
Training loss: 2.3968570232391357
Validation loss: 2.1601953096287225

Epoch: 5| Step: 10
Training loss: 2.286194324493408
Validation loss: 2.1648577772161013

Epoch: 94| Step: 0
Training loss: 2.1962122917175293
Validation loss: 2.1615026407344367

Epoch: 5| Step: 1
Training loss: 2.177915096282959
Validation loss: 2.1656150510234218

Epoch: 5| Step: 2
Training loss: 2.5316710472106934
Validation loss: 2.169045776449224

Epoch: 5| Step: 3
Training loss: 2.637446880340576
Validation loss: 2.1724759609468522

Epoch: 5| Step: 4
Training loss: 2.3657288551330566
Validation loss: 2.1646495378145607

Epoch: 5| Step: 5
Training loss: 2.5998215675354004
Validation loss: 2.176594388100409

Epoch: 5| Step: 6
Training loss: 2.333616018295288
Validation loss: 2.1761519626904557

Epoch: 5| Step: 7
Training loss: 2.116812229156494
Validation loss: 2.1715146354449693

Epoch: 5| Step: 8
Training loss: 2.8211333751678467
Validation loss: 2.1592494672344578

Epoch: 5| Step: 9
Training loss: 2.768587589263916
Validation loss: 2.1567842075901646

Epoch: 5| Step: 10
Training loss: 2.0523037910461426
Validation loss: 2.1494906922822357

Epoch: 95| Step: 0
Training loss: 1.8987047672271729
Validation loss: 2.149107445952713

Epoch: 5| Step: 1
Training loss: 2.5600712299346924
Validation loss: 2.145677422964445

Epoch: 5| Step: 2
Training loss: 2.2679316997528076
Validation loss: 2.144628385061859

Epoch: 5| Step: 3
Training loss: 2.341609239578247
Validation loss: 2.150013514744338

Epoch: 5| Step: 4
Training loss: 2.398869752883911
Validation loss: 2.1478000328104985

Epoch: 5| Step: 5
Training loss: 2.2487807273864746
Validation loss: 2.1528541657232467

Epoch: 5| Step: 6
Training loss: 2.508850574493408
Validation loss: 2.1630576015800558

Epoch: 5| Step: 7
Training loss: 2.45999813079834
Validation loss: 2.1824909333259828

Epoch: 5| Step: 8
Training loss: 2.4720115661621094
Validation loss: 2.214225879279516

Epoch: 5| Step: 9
Training loss: 2.792813777923584
Validation loss: 2.2194069021491596

Epoch: 5| Step: 10
Training loss: 3.0046305656433105
Validation loss: 2.1904859491573867

Epoch: 96| Step: 0
Training loss: 2.976898670196533
Validation loss: 2.159121859458185

Epoch: 5| Step: 1
Training loss: 2.1967341899871826
Validation loss: 2.1342416886360414

Epoch: 5| Step: 2
Training loss: 1.9893985986709595
Validation loss: 2.143502762240748

Epoch: 5| Step: 3
Training loss: 2.59063982963562
Validation loss: 2.141892465212012

Epoch: 5| Step: 4
Training loss: 2.4593124389648438
Validation loss: 2.141629406200942

Epoch: 5| Step: 5
Training loss: 2.038547992706299
Validation loss: 2.1411775747934976

Epoch: 5| Step: 6
Training loss: 2.642308235168457
Validation loss: 2.1456382389991515

Epoch: 5| Step: 7
Training loss: 2.212021827697754
Validation loss: 2.1405241681683447

Epoch: 5| Step: 8
Training loss: 2.4875988960266113
Validation loss: 2.1467250393282984

Epoch: 5| Step: 9
Training loss: 2.647155284881592
Validation loss: 2.1542078910335416

Epoch: 5| Step: 10
Training loss: 2.9289937019348145
Validation loss: 2.1626779315292195

Epoch: 97| Step: 0
Training loss: 2.500605583190918
Validation loss: 2.1618751402824157

Epoch: 5| Step: 1
Training loss: 2.8544528484344482
Validation loss: 2.174306736197523

Epoch: 5| Step: 2
Training loss: 1.8593136072158813
Validation loss: 2.1881150045702533

Epoch: 5| Step: 3
Training loss: 3.334629535675049
Validation loss: 2.2406611455384122

Epoch: 5| Step: 4
Training loss: 2.6065831184387207
Validation loss: 2.2869116593432683

Epoch: 5| Step: 5
Training loss: 2.178410291671753
Validation loss: 2.275156787646714

Epoch: 5| Step: 6
Training loss: 2.4155948162078857
Validation loss: 2.240307524640073

Epoch: 5| Step: 7
Training loss: 2.4356796741485596
Validation loss: 2.235376299068492

Epoch: 5| Step: 8
Training loss: 1.9412834644317627
Validation loss: 2.2197512965048514

Epoch: 5| Step: 9
Training loss: 2.6422476768493652
Validation loss: 2.2094468044978317

Epoch: 5| Step: 10
Training loss: 2.2416434288024902
Validation loss: 2.1936641687987954

Epoch: 98| Step: 0
Training loss: 2.197873830795288
Validation loss: 2.1785367663188646

Epoch: 5| Step: 1
Training loss: 2.7970633506774902
Validation loss: 2.173091798700312

Epoch: 5| Step: 2
Training loss: 1.8510253429412842
Validation loss: 2.164174877187257

Epoch: 5| Step: 3
Training loss: 2.052773952484131
Validation loss: 2.157133771527198

Epoch: 5| Step: 4
Training loss: 2.9312148094177246
Validation loss: 2.1474843179025958

Epoch: 5| Step: 5
Training loss: 2.1920762062072754
Validation loss: 2.1375468418162358

Epoch: 5| Step: 6
Training loss: 1.7596931457519531
Validation loss: 2.137159255243117

Epoch: 5| Step: 7
Training loss: 3.5441527366638184
Validation loss: 2.1329522850692912

Epoch: 5| Step: 8
Training loss: 2.3578758239746094
Validation loss: 2.133960247039795

Epoch: 5| Step: 9
Training loss: 2.8578290939331055
Validation loss: 2.128247464856794

Epoch: 5| Step: 10
Training loss: 2.367814302444458
Validation loss: 2.1360989373217345

Epoch: 99| Step: 0
Training loss: 2.7653720378875732
Validation loss: 2.147356037170656

Epoch: 5| Step: 1
Training loss: 2.4039711952209473
Validation loss: 2.157371741469188

Epoch: 5| Step: 2
Training loss: 2.6700422763824463
Validation loss: 2.162948364852577

Epoch: 5| Step: 3
Training loss: 2.411407947540283
Validation loss: 2.168270023920203

Epoch: 5| Step: 4
Training loss: 1.5717799663543701
Validation loss: 2.1765204629590436

Epoch: 5| Step: 5
Training loss: 2.8135159015655518
Validation loss: 2.1652521676914667

Epoch: 5| Step: 6
Training loss: 2.2360825538635254
Validation loss: 2.152371152754753

Epoch: 5| Step: 7
Training loss: 1.895124077796936
Validation loss: 2.1455286266983196

Epoch: 5| Step: 8
Training loss: 2.2816123962402344
Validation loss: 2.1376784398991573

Epoch: 5| Step: 9
Training loss: 2.668205499649048
Validation loss: 2.1331107667697373

Epoch: 5| Step: 10
Training loss: 2.867316961288452
Validation loss: 2.132751346916281

Epoch: 100| Step: 0
Training loss: 1.786350965499878
Validation loss: 2.139597604351659

Epoch: 5| Step: 1
Training loss: 2.740283250808716
Validation loss: 2.1456985678724063

Epoch: 5| Step: 2
Training loss: 2.560821056365967
Validation loss: 2.1513938134716404

Epoch: 5| Step: 3
Training loss: 2.4926228523254395
Validation loss: 2.16355630915652

Epoch: 5| Step: 4
Training loss: 2.896608829498291
Validation loss: 2.1747594674428306

Epoch: 5| Step: 5
Training loss: 2.102687358856201
Validation loss: 2.177985078545027

Epoch: 5| Step: 6
Training loss: 2.7799410820007324
Validation loss: 2.1995889448350474

Epoch: 5| Step: 7
Training loss: 2.0125269889831543
Validation loss: 2.2085494995117188

Epoch: 5| Step: 8
Training loss: 2.42376446723938
Validation loss: 2.1900075789420836

Epoch: 5| Step: 9
Training loss: 2.6533799171447754
Validation loss: 2.1988960235349593

Epoch: 5| Step: 10
Training loss: 2.667048692703247
Validation loss: 2.1798631324562976

Epoch: 101| Step: 0
Training loss: 2.7185792922973633
Validation loss: 2.171689925655242

Epoch: 5| Step: 1
Training loss: 2.536154270172119
Validation loss: 2.1789766614155104

Epoch: 5| Step: 2
Training loss: 2.185490369796753
Validation loss: 2.2259358077920894

Epoch: 5| Step: 3
Training loss: 2.7823398113250732
Validation loss: 2.271539552237398

Epoch: 5| Step: 4
Training loss: 2.327122926712036
Validation loss: 2.2929107143032934

Epoch: 5| Step: 5
Training loss: 2.7493643760681152
Validation loss: 2.2781770690794914

Epoch: 5| Step: 6
Training loss: 2.757530689239502
Validation loss: 2.248185119321269

Epoch: 5| Step: 7
Training loss: 1.790757179260254
Validation loss: 2.1901707085230018

Epoch: 5| Step: 8
Training loss: 2.3184235095977783
Validation loss: 2.159462292989095

Epoch: 5| Step: 9
Training loss: 2.6282591819763184
Validation loss: 2.1332363467062674

Epoch: 5| Step: 10
Training loss: 2.1646885871887207
Validation loss: 2.1298500132817093

Epoch: 102| Step: 0
Training loss: 2.467756986618042
Validation loss: 2.126508838386946

Epoch: 5| Step: 1
Training loss: 1.8401168584823608
Validation loss: 2.129351149323166

Epoch: 5| Step: 2
Training loss: 2.63789701461792
Validation loss: 2.123417382599205

Epoch: 5| Step: 3
Training loss: 2.3746883869171143
Validation loss: 2.1293090774166967

Epoch: 5| Step: 4
Training loss: 2.943310260772705
Validation loss: 2.128513410527219

Epoch: 5| Step: 5
Training loss: 1.9969167709350586
Validation loss: 2.1279255344021704

Epoch: 5| Step: 6
Training loss: 2.679738998413086
Validation loss: 2.126168725311115

Epoch: 5| Step: 7
Training loss: 2.378779172897339
Validation loss: 2.121734752449938

Epoch: 5| Step: 8
Training loss: 2.33174729347229
Validation loss: 2.116631988556154

Epoch: 5| Step: 9
Training loss: 2.783721923828125
Validation loss: 2.1160960979359125

Epoch: 5| Step: 10
Training loss: 2.5282723903656006
Validation loss: 2.116521766108851

Epoch: 103| Step: 0
Training loss: 2.3467400074005127
Validation loss: 2.1227054096037343

Epoch: 5| Step: 1
Training loss: 1.8114612102508545
Validation loss: 2.1245422850372973

Epoch: 5| Step: 2
Training loss: 2.076676845550537
Validation loss: 2.131987460197941

Epoch: 5| Step: 3
Training loss: 2.5259642601013184
Validation loss: 2.1487971582720355

Epoch: 5| Step: 4
Training loss: 2.7251529693603516
Validation loss: 2.169605758882338

Epoch: 5| Step: 5
Training loss: 2.2867770195007324
Validation loss: 2.1889223590973885

Epoch: 5| Step: 6
Training loss: 2.6532912254333496
Validation loss: 2.1760534137807865

Epoch: 5| Step: 7
Training loss: 2.806678295135498
Validation loss: 2.1571763689799974

Epoch: 5| Step: 8
Training loss: 2.9101943969726562
Validation loss: 2.1409540484028478

Epoch: 5| Step: 9
Training loss: 2.116359233856201
Validation loss: 2.129292361197933

Epoch: 5| Step: 10
Training loss: 2.191133737564087
Validation loss: 2.124682959689889

Epoch: 104| Step: 0
Training loss: 2.1192879676818848
Validation loss: 2.126307160623612

Epoch: 5| Step: 1
Training loss: 2.340752363204956
Validation loss: 2.1286411157218357

Epoch: 5| Step: 2
Training loss: 2.532895088195801
Validation loss: 2.1295303349853842

Epoch: 5| Step: 3
Training loss: 2.2447075843811035
Validation loss: 2.139020481417256

Epoch: 5| Step: 4
Training loss: 1.6485702991485596
Validation loss: 2.1441357533137

Epoch: 5| Step: 5
Training loss: 2.440215587615967
Validation loss: 2.1487128350042526

Epoch: 5| Step: 6
Training loss: 2.627237558364868
Validation loss: 2.1650987696904007

Epoch: 5| Step: 7
Training loss: 2.093660354614258
Validation loss: 2.165182718666651

Epoch: 5| Step: 8
Training loss: 2.7458689212799072
Validation loss: 2.1715858213363157

Epoch: 5| Step: 9
Training loss: 2.6215739250183105
Validation loss: 2.1657749555444203

Epoch: 5| Step: 10
Training loss: 2.9825544357299805
Validation loss: 2.1700229978048675

Epoch: 105| Step: 0
Training loss: 2.2929024696350098
Validation loss: 2.1624138867983254

Epoch: 5| Step: 1
Training loss: 2.6040985584259033
Validation loss: 2.1607587696403585

Epoch: 5| Step: 2
Training loss: 2.4654650688171387
Validation loss: 2.159253906178218

Epoch: 5| Step: 3
Training loss: 2.13971209526062
Validation loss: 2.173318688587476

Epoch: 5| Step: 4
Training loss: 1.7876110076904297
Validation loss: 2.1707168035609747

Epoch: 5| Step: 5
Training loss: 2.0332648754119873
Validation loss: 2.165012619828665

Epoch: 5| Step: 6
Training loss: 2.841688632965088
Validation loss: 2.14202695251793

Epoch: 5| Step: 7
Training loss: 2.704723358154297
Validation loss: 2.1375248073249735

Epoch: 5| Step: 8
Training loss: 2.859880208969116
Validation loss: 2.1320714591651835

Epoch: 5| Step: 9
Training loss: 2.409825086593628
Validation loss: 2.147324244181315

Epoch: 5| Step: 10
Training loss: 2.164567470550537
Validation loss: 2.1459388040727183

Epoch: 106| Step: 0
Training loss: 2.0489604473114014
Validation loss: 2.1408662744747695

Epoch: 5| Step: 1
Training loss: 2.5692214965820312
Validation loss: 2.1456556512463476

Epoch: 5| Step: 2
Training loss: 2.550652027130127
Validation loss: 2.147869558744533

Epoch: 5| Step: 3
Training loss: 2.9668490886688232
Validation loss: 2.168029328828217

Epoch: 5| Step: 4
Training loss: 1.8150898218154907
Validation loss: 2.187328774441955

Epoch: 5| Step: 5
Training loss: 2.2370591163635254
Validation loss: 2.18973086982645

Epoch: 5| Step: 6
Training loss: 2.744795322418213
Validation loss: 2.1971888183265604

Epoch: 5| Step: 7
Training loss: 2.5828309059143066
Validation loss: 2.204477410162649

Epoch: 5| Step: 8
Training loss: 2.178131580352783
Validation loss: 2.2314402570006666

Epoch: 5| Step: 9
Training loss: 2.530609369277954
Validation loss: 2.2223648768599316

Epoch: 5| Step: 10
Training loss: 2.241903305053711
Validation loss: 2.1730865714370564

Epoch: 107| Step: 0
Training loss: 1.71807062625885
Validation loss: 2.1563805303265973

Epoch: 5| Step: 1
Training loss: 2.3119521141052246
Validation loss: 2.1376486324494883

Epoch: 5| Step: 2
Training loss: 2.459765672683716
Validation loss: 2.1239970166196107

Epoch: 5| Step: 3
Training loss: 2.6027255058288574
Validation loss: 2.1117641489992858

Epoch: 5| Step: 4
Training loss: 2.8345766067504883
Validation loss: 2.1062478711528163

Epoch: 5| Step: 5
Training loss: 2.2935829162597656
Validation loss: 2.094514014900372

Epoch: 5| Step: 6
Training loss: 1.812503457069397
Validation loss: 2.096869784016763

Epoch: 5| Step: 7
Training loss: 2.749267101287842
Validation loss: 2.0947268291186263

Epoch: 5| Step: 8
Training loss: 2.7464921474456787
Validation loss: 2.0913334456823205

Epoch: 5| Step: 9
Training loss: 2.2309999465942383
Validation loss: 2.105284056355876

Epoch: 5| Step: 10
Training loss: 2.4373819828033447
Validation loss: 2.0903828656801613

Epoch: 108| Step: 0
Training loss: 2.223280191421509
Validation loss: 2.092730647774153

Epoch: 5| Step: 1
Training loss: 2.3567442893981934
Validation loss: 2.1087703179287653

Epoch: 5| Step: 2
Training loss: 2.3669824600219727
Validation loss: 2.1118056158865652

Epoch: 5| Step: 3
Training loss: 2.08976411819458
Validation loss: 2.1057879822228545

Epoch: 5| Step: 4
Training loss: 2.2669289112091064
Validation loss: 2.0950571439599477

Epoch: 5| Step: 5
Training loss: 2.2977957725524902
Validation loss: 2.091078245511619

Epoch: 5| Step: 6
Training loss: 2.9621920585632324
Validation loss: 2.0932700608366277

Epoch: 5| Step: 7
Training loss: 2.7151613235473633
Validation loss: 2.0993472119813323

Epoch: 5| Step: 8
Training loss: 1.8918354511260986
Validation loss: 2.102362318705487

Epoch: 5| Step: 9
Training loss: 2.6157519817352295
Validation loss: 2.1029788447964575

Epoch: 5| Step: 10
Training loss: 2.467994451522827
Validation loss: 2.102598738926713

Epoch: 109| Step: 0
Training loss: 2.277035713195801
Validation loss: 2.0891191933744695

Epoch: 5| Step: 1
Training loss: 2.243722438812256
Validation loss: 2.0950897483415503

Epoch: 5| Step: 2
Training loss: 1.6650489568710327
Validation loss: 2.1039466242636404

Epoch: 5| Step: 3
Training loss: 2.4994518756866455
Validation loss: 2.0988544494875017

Epoch: 5| Step: 4
Training loss: 2.5492916107177734
Validation loss: 2.0966856197644304

Epoch: 5| Step: 5
Training loss: 2.621793031692505
Validation loss: 2.093699982089381

Epoch: 5| Step: 6
Training loss: 2.6547932624816895
Validation loss: 2.096278980214109

Epoch: 5| Step: 7
Training loss: 2.8862431049346924
Validation loss: 2.0975300060805453

Epoch: 5| Step: 8
Training loss: 2.0861308574676514
Validation loss: 2.0974259325253066

Epoch: 5| Step: 9
Training loss: 2.2726080417633057
Validation loss: 2.0982792223653486

Epoch: 5| Step: 10
Training loss: 2.2613232135772705
Validation loss: 2.102206604455107

Epoch: 110| Step: 0
Training loss: 2.9524707794189453
Validation loss: 2.097113001731134

Epoch: 5| Step: 1
Training loss: 2.593721866607666
Validation loss: 2.102110856322832

Epoch: 5| Step: 2
Training loss: 2.500183582305908
Validation loss: 2.1096651502834853

Epoch: 5| Step: 3
Training loss: 2.2787976264953613
Validation loss: 2.096799635118054

Epoch: 5| Step: 4
Training loss: 2.383394718170166
Validation loss: 2.082160756152163

Epoch: 5| Step: 5
Training loss: 2.193023204803467
Validation loss: 2.0773552451082455

Epoch: 5| Step: 6
Training loss: 2.3816609382629395
Validation loss: 2.076838513856293

Epoch: 5| Step: 7
Training loss: 2.590141773223877
Validation loss: 2.0757222149961736

Epoch: 5| Step: 8
Training loss: 1.607326865196228
Validation loss: 2.0694477353044736

Epoch: 5| Step: 9
Training loss: 2.6535277366638184
Validation loss: 2.066665341777186

Epoch: 5| Step: 10
Training loss: 1.6479218006134033
Validation loss: 2.067241355937014

Epoch: 111| Step: 0
Training loss: 2.0102832317352295
Validation loss: 2.0701536542625836

Epoch: 5| Step: 1
Training loss: 2.792273998260498
Validation loss: 2.072400716043288

Epoch: 5| Step: 2
Training loss: 2.275338888168335
Validation loss: 2.074700645221177

Epoch: 5| Step: 3
Training loss: 2.575474262237549
Validation loss: 2.0728332355458248

Epoch: 5| Step: 4
Training loss: 2.487312078475952
Validation loss: 2.0701280845108854

Epoch: 5| Step: 5
Training loss: 2.29460072517395
Validation loss: 2.0654996389983804

Epoch: 5| Step: 6
Training loss: 2.466820240020752
Validation loss: 2.062471507697977

Epoch: 5| Step: 7
Training loss: 2.189568042755127
Validation loss: 2.0603422221317085

Epoch: 5| Step: 8
Training loss: 1.467864751815796
Validation loss: 2.051867304309722

Epoch: 5| Step: 9
Training loss: 2.8332431316375732
Validation loss: 2.055286257497726

Epoch: 5| Step: 10
Training loss: 2.2646842002868652
Validation loss: 2.0625937369561966

Epoch: 112| Step: 0
Training loss: 2.4992494583129883
Validation loss: 2.0545011284530803

Epoch: 5| Step: 1
Training loss: 2.1412436962127686
Validation loss: 2.0479582560959684

Epoch: 5| Step: 2
Training loss: 2.1666760444641113
Validation loss: 2.0484701946217525

Epoch: 5| Step: 3
Training loss: 1.8737071752548218
Validation loss: 2.054620409524569

Epoch: 5| Step: 4
Training loss: 2.2224457263946533
Validation loss: 2.0527542957695584

Epoch: 5| Step: 5
Training loss: 3.0269734859466553
Validation loss: 2.057171308866111

Epoch: 5| Step: 6
Training loss: 2.2891111373901367
Validation loss: 2.059988575596963

Epoch: 5| Step: 7
Training loss: 2.1356136798858643
Validation loss: 2.073350303916521

Epoch: 5| Step: 8
Training loss: 2.4696602821350098
Validation loss: 2.070612056280977

Epoch: 5| Step: 9
Training loss: 2.153822898864746
Validation loss: 2.060959267359908

Epoch: 5| Step: 10
Training loss: 2.664263963699341
Validation loss: 2.066883481958861

Epoch: 113| Step: 0
Training loss: 2.625870704650879
Validation loss: 2.061346266859321

Epoch: 5| Step: 1
Training loss: 2.393608570098877
Validation loss: 2.062790081065188

Epoch: 5| Step: 2
Training loss: 1.9641460180282593
Validation loss: 2.0652757716435257

Epoch: 5| Step: 3
Training loss: 2.1791200637817383
Validation loss: 2.0615287929452877

Epoch: 5| Step: 4
Training loss: 2.6295974254608154
Validation loss: 2.057727511211108

Epoch: 5| Step: 5
Training loss: 2.39111590385437
Validation loss: 2.054086967181134

Epoch: 5| Step: 6
Training loss: 2.048635959625244
Validation loss: 2.055578359993555

Epoch: 5| Step: 7
Training loss: 1.768298864364624
Validation loss: 2.057955179163205

Epoch: 5| Step: 8
Training loss: 2.5152392387390137
Validation loss: 2.058828930700979

Epoch: 5| Step: 9
Training loss: 2.8566412925720215
Validation loss: 2.054582970116728

Epoch: 5| Step: 10
Training loss: 2.2477598190307617
Validation loss: 2.0522051703545356

Epoch: 114| Step: 0
Training loss: 2.4093918800354004
Validation loss: 2.0561635007140455

Epoch: 5| Step: 1
Training loss: 2.132502794265747
Validation loss: 2.054593700234608

Epoch: 5| Step: 2
Training loss: 2.6521170139312744
Validation loss: 2.060945581364375

Epoch: 5| Step: 3
Training loss: 2.4873974323272705
Validation loss: 2.0559512851058797

Epoch: 5| Step: 4
Training loss: 2.2890219688415527
Validation loss: 2.0595801978982906

Epoch: 5| Step: 5
Training loss: 2.786398410797119
Validation loss: 2.0580021796687955

Epoch: 5| Step: 6
Training loss: 2.467559337615967
Validation loss: 2.0584594536853094

Epoch: 5| Step: 7
Training loss: 1.787034034729004
Validation loss: 2.0549789500492874

Epoch: 5| Step: 8
Training loss: 2.5280609130859375
Validation loss: 2.0481241774815384

Epoch: 5| Step: 9
Training loss: 1.5128464698791504
Validation loss: 2.0497095174686883

Epoch: 5| Step: 10
Training loss: 2.3730883598327637
Validation loss: 2.0477758402465494

Epoch: 115| Step: 0
Training loss: 2.6033987998962402
Validation loss: 2.0401330712021037

Epoch: 5| Step: 1
Training loss: 2.0995640754699707
Validation loss: 2.0395138481611848

Epoch: 5| Step: 2
Training loss: 2.777116537094116
Validation loss: 2.040860968251382

Epoch: 5| Step: 3
Training loss: 2.102864980697632
Validation loss: 2.040298966951268

Epoch: 5| Step: 4
Training loss: 1.6181176900863647
Validation loss: 2.0422346386858212

Epoch: 5| Step: 5
Training loss: 2.4469757080078125
Validation loss: 2.04071811450425

Epoch: 5| Step: 6
Training loss: 2.0901074409484863
Validation loss: 2.0413089875252015

Epoch: 5| Step: 7
Training loss: 1.9750674962997437
Validation loss: 2.0378568544182727

Epoch: 5| Step: 8
Training loss: 2.678213596343994
Validation loss: 2.034540021291343

Epoch: 5| Step: 9
Training loss: 2.3519654273986816
Validation loss: 2.0412090311768236

Epoch: 5| Step: 10
Training loss: 2.6011836528778076
Validation loss: 2.046707284065985

Epoch: 116| Step: 0
Training loss: 1.8340885639190674
Validation loss: 2.0522191319414365

Epoch: 5| Step: 1
Training loss: 2.548180341720581
Validation loss: 2.063644205370257

Epoch: 5| Step: 2
Training loss: 2.3743789196014404
Validation loss: 2.075892884244201

Epoch: 5| Step: 3
Training loss: 2.4666101932525635
Validation loss: 2.0665295713691303

Epoch: 5| Step: 4
Training loss: 2.371359348297119
Validation loss: 2.06711273424087

Epoch: 5| Step: 5
Training loss: 2.134188175201416
Validation loss: 2.0439265517778296

Epoch: 5| Step: 6
Training loss: 2.6639397144317627
Validation loss: 2.0340090900339107

Epoch: 5| Step: 7
Training loss: 1.5828404426574707
Validation loss: 2.0273251315598846

Epoch: 5| Step: 8
Training loss: 2.340667247772217
Validation loss: 2.0324669794369767

Epoch: 5| Step: 9
Training loss: 2.3339171409606934
Validation loss: 2.0331970722444597

Epoch: 5| Step: 10
Training loss: 2.917696714401245
Validation loss: 2.0336444570172216

Epoch: 117| Step: 0
Training loss: 2.8784689903259277
Validation loss: 2.0330933922080585

Epoch: 5| Step: 1
Training loss: 1.7580230236053467
Validation loss: 2.0311555452244257

Epoch: 5| Step: 2
Training loss: 1.7612930536270142
Validation loss: 2.0293490348323697

Epoch: 5| Step: 3
Training loss: 2.7214019298553467
Validation loss: 2.0332930344407276

Epoch: 5| Step: 4
Training loss: 2.9639711380004883
Validation loss: 2.0361721310564267

Epoch: 5| Step: 5
Training loss: 1.7358739376068115
Validation loss: 2.037713953243789

Epoch: 5| Step: 6
Training loss: 2.5905885696411133
Validation loss: 2.0406571665117816

Epoch: 5| Step: 7
Training loss: 2.5013155937194824
Validation loss: 2.043069701040945

Epoch: 5| Step: 8
Training loss: 2.3825631141662598
Validation loss: 2.044454025965865

Epoch: 5| Step: 9
Training loss: 2.058424949645996
Validation loss: 2.0389061256121566

Epoch: 5| Step: 10
Training loss: 1.949084997177124
Validation loss: 2.037649111081195

Epoch: 118| Step: 0
Training loss: 2.603327989578247
Validation loss: 2.0349416373878397

Epoch: 5| Step: 1
Training loss: 1.549676775932312
Validation loss: 2.038711635015344

Epoch: 5| Step: 2
Training loss: 2.122164249420166
Validation loss: 2.0609357267297725

Epoch: 5| Step: 3
Training loss: 2.4172873497009277
Validation loss: 2.0750417952896445

Epoch: 5| Step: 4
Training loss: 2.2927398681640625
Validation loss: 2.0615663092623473

Epoch: 5| Step: 5
Training loss: 2.2231268882751465
Validation loss: 2.066984030508226

Epoch: 5| Step: 6
Training loss: 2.4556758403778076
Validation loss: 2.0467651185169013

Epoch: 5| Step: 7
Training loss: 2.897265672683716
Validation loss: 2.041165844086678

Epoch: 5| Step: 8
Training loss: 1.96344792842865
Validation loss: 2.053440147830594

Epoch: 5| Step: 9
Training loss: 2.3707642555236816
Validation loss: 2.065039337322276

Epoch: 5| Step: 10
Training loss: 2.389881134033203
Validation loss: 2.070242295983017

Epoch: 119| Step: 0
Training loss: 2.086594581604004
Validation loss: 2.0586056017106578

Epoch: 5| Step: 1
Training loss: 2.440998077392578
Validation loss: 2.050382862808884

Epoch: 5| Step: 2
Training loss: 2.4466967582702637
Validation loss: 2.049378307916785

Epoch: 5| Step: 3
Training loss: 2.2671267986297607
Validation loss: 2.058859989207278

Epoch: 5| Step: 4
Training loss: 2.6698808670043945
Validation loss: 2.067880984275572

Epoch: 5| Step: 5
Training loss: 2.871777296066284
Validation loss: 2.0827968812757924

Epoch: 5| Step: 6
Training loss: 2.1879265308380127
Validation loss: 2.071781612211658

Epoch: 5| Step: 7
Training loss: 2.5932281017303467
Validation loss: 2.0626027584075928

Epoch: 5| Step: 8
Training loss: 2.3703975677490234
Validation loss: 2.0436180906911052

Epoch: 5| Step: 9
Training loss: 1.5361994504928589
Validation loss: 2.0739185335815593

Epoch: 5| Step: 10
Training loss: 1.9161310195922852
Validation loss: 2.0957705513123543

Epoch: 120| Step: 0
Training loss: 2.13642954826355
Validation loss: 2.098262725337859

Epoch: 5| Step: 1
Training loss: 2.003734588623047
Validation loss: 2.0812460581461587

Epoch: 5| Step: 2
Training loss: 2.3819217681884766
Validation loss: 2.0699110082400742

Epoch: 5| Step: 3
Training loss: 2.542940378189087
Validation loss: 2.045265310554094

Epoch: 5| Step: 4
Training loss: 2.427924394607544
Validation loss: 2.0429306184091875

Epoch: 5| Step: 5
Training loss: 2.165649652481079
Validation loss: 2.0387963787201913

Epoch: 5| Step: 6
Training loss: 2.625094175338745
Validation loss: 2.034269391849477

Epoch: 5| Step: 7
Training loss: 2.013054370880127
Validation loss: 2.0321840509291618

Epoch: 5| Step: 8
Training loss: 2.179612159729004
Validation loss: 2.03958531220754

Epoch: 5| Step: 9
Training loss: 2.4137938022613525
Validation loss: 2.035918781834264

Epoch: 5| Step: 10
Training loss: 2.4722061157226562
Validation loss: 2.043108373559931

Epoch: 121| Step: 0
Training loss: 2.115720510482788
Validation loss: 2.0350033749816236

Epoch: 5| Step: 1
Training loss: 2.167928457260132
Validation loss: 2.022371304932461

Epoch: 5| Step: 2
Training loss: 1.941511869430542
Validation loss: 2.025410121487033

Epoch: 5| Step: 3
Training loss: 2.171639919281006
Validation loss: 2.0300249694496073

Epoch: 5| Step: 4
Training loss: 2.606614351272583
Validation loss: 2.03071105095648

Epoch: 5| Step: 5
Training loss: 2.3401310443878174
Validation loss: 2.024981229535995

Epoch: 5| Step: 6
Training loss: 2.582139253616333
Validation loss: 2.024536628876963

Epoch: 5| Step: 7
Training loss: 1.6217288970947266
Validation loss: 2.017343823627759

Epoch: 5| Step: 8
Training loss: 2.5645217895507812
Validation loss: 2.004794451498216

Epoch: 5| Step: 9
Training loss: 3.0588884353637695
Validation loss: 2.0044121255156813

Epoch: 5| Step: 10
Training loss: 1.8487639427185059
Validation loss: 2.0070490862733577

Epoch: 122| Step: 0
Training loss: 2.063075542449951
Validation loss: 2.014219072557265

Epoch: 5| Step: 1
Training loss: 2.4541478157043457
Validation loss: 2.033196812034935

Epoch: 5| Step: 2
Training loss: 2.2355918884277344
Validation loss: 2.0448026734013713

Epoch: 5| Step: 3
Training loss: 2.065168619155884
Validation loss: 2.038318536614859

Epoch: 5| Step: 4
Training loss: 2.275019884109497
Validation loss: 2.033965121033371

Epoch: 5| Step: 5
Training loss: 2.4951577186584473
Validation loss: 2.031332464628322

Epoch: 5| Step: 6
Training loss: 2.3640167713165283
Validation loss: 2.0154212367150093

Epoch: 5| Step: 7
Training loss: 2.842057228088379
Validation loss: 2.0043550755387995

Epoch: 5| Step: 8
Training loss: 2.508389949798584
Validation loss: 2.000999069982959

Epoch: 5| Step: 9
Training loss: 1.4703925848007202
Validation loss: 2.004580731032997

Epoch: 5| Step: 10
Training loss: 2.333878993988037
Validation loss: 2.0016087921716834

Epoch: 123| Step: 0
Training loss: 2.4044220447540283
Validation loss: 2.0131526147165606

Epoch: 5| Step: 1
Training loss: 2.6699841022491455
Validation loss: 2.0218711335171937

Epoch: 5| Step: 2
Training loss: 2.696204900741577
Validation loss: 2.0344258841647895

Epoch: 5| Step: 3
Training loss: 2.505127429962158
Validation loss: 2.0495087638978036

Epoch: 5| Step: 4
Training loss: 2.5044569969177246
Validation loss: 2.0604911722162718

Epoch: 5| Step: 5
Training loss: 2.1211328506469727
Validation loss: 2.044864414840616

Epoch: 5| Step: 6
Training loss: 1.8957023620605469
Validation loss: 2.0116355778068624

Epoch: 5| Step: 7
Training loss: 2.3159568309783936
Validation loss: 2.010388248710222

Epoch: 5| Step: 8
Training loss: 1.9695498943328857
Validation loss: 2.0070283284751316

Epoch: 5| Step: 9
Training loss: 2.185976505279541
Validation loss: 2.0101484662743023

Epoch: 5| Step: 10
Training loss: 1.826468586921692
Validation loss: 2.0056438138408046

Epoch: 124| Step: 0
Training loss: 2.7665562629699707
Validation loss: 2.0057841308655275

Epoch: 5| Step: 1
Training loss: 2.728421688079834
Validation loss: 2.0027035205594954

Epoch: 5| Step: 2
Training loss: 1.5373419523239136
Validation loss: 2.013543978814156

Epoch: 5| Step: 3
Training loss: 2.054103374481201
Validation loss: 2.022960644896312

Epoch: 5| Step: 4
Training loss: 2.2511305809020996
Validation loss: 2.0207398296684347

Epoch: 5| Step: 5
Training loss: 2.412717819213867
Validation loss: 2.0256924013937674

Epoch: 5| Step: 6
Training loss: 2.2892565727233887
Validation loss: 2.0227603758535078

Epoch: 5| Step: 7
Training loss: 2.582282543182373
Validation loss: 2.015272790385831

Epoch: 5| Step: 8
Training loss: 2.3151347637176514
Validation loss: 2.0085717042287192

Epoch: 5| Step: 9
Training loss: 2.6225130558013916
Validation loss: 2.0097317170071345

Epoch: 5| Step: 10
Training loss: 1.2724343538284302
Validation loss: 2.007847007884774

Epoch: 125| Step: 0
Training loss: 2.1654927730560303
Validation loss: 2.0126728729535173

Epoch: 5| Step: 1
Training loss: 2.3704030513763428
Validation loss: 2.0107048814014723

Epoch: 5| Step: 2
Training loss: 1.9667266607284546
Validation loss: 2.004571945436539

Epoch: 5| Step: 3
Training loss: 2.5587430000305176
Validation loss: 2.0099981856602493

Epoch: 5| Step: 4
Training loss: 2.357198715209961
Validation loss: 2.0104048713561027

Epoch: 5| Step: 5
Training loss: 2.574704885482788
Validation loss: 2.0052662331570863

Epoch: 5| Step: 6
Training loss: 2.6492953300476074
Validation loss: 1.9889754556840467

Epoch: 5| Step: 7
Training loss: 1.53960382938385
Validation loss: 1.9891989179836806

Epoch: 5| Step: 8
Training loss: 2.710451602935791
Validation loss: 1.9883180792613695

Epoch: 5| Step: 9
Training loss: 2.3614306449890137
Validation loss: 1.9846190380793747

Epoch: 5| Step: 10
Training loss: 1.4613375663757324
Validation loss: 1.981061827751898

Epoch: 126| Step: 0
Training loss: 2.466294527053833
Validation loss: 1.9871157394942416

Epoch: 5| Step: 1
Training loss: 1.944903016090393
Validation loss: 1.9835889159992177

Epoch: 5| Step: 2
Training loss: 1.7089866399765015
Validation loss: 1.988354234285252

Epoch: 5| Step: 3
Training loss: 1.4756953716278076
Validation loss: 1.990231596013551

Epoch: 5| Step: 4
Training loss: 1.942920446395874
Validation loss: 1.9825347341516966

Epoch: 5| Step: 5
Training loss: 2.0892374515533447
Validation loss: 1.97675839290824

Epoch: 5| Step: 6
Training loss: 2.4482128620147705
Validation loss: 1.977339921459075

Epoch: 5| Step: 7
Training loss: 3.014570713043213
Validation loss: 1.9708057244618733

Epoch: 5| Step: 8
Training loss: 2.280329465866089
Validation loss: 1.9785911267803562

Epoch: 5| Step: 9
Training loss: 2.998549461364746
Validation loss: 1.977188515406783

Epoch: 5| Step: 10
Training loss: 2.4222497940063477
Validation loss: 1.985193762727963

Epoch: 127| Step: 0
Training loss: 2.2024331092834473
Validation loss: 1.9906934333103958

Epoch: 5| Step: 1
Training loss: 2.04419207572937
Validation loss: 1.9840808760735296

Epoch: 5| Step: 2
Training loss: 2.2988522052764893
Validation loss: 1.9747601657785394

Epoch: 5| Step: 3
Training loss: 2.6031394004821777
Validation loss: 1.9703342658217236

Epoch: 5| Step: 4
Training loss: 2.4761643409729004
Validation loss: 1.9841820052874986

Epoch: 5| Step: 5
Training loss: 2.0863490104675293
Validation loss: 2.026804047246133

Epoch: 5| Step: 6
Training loss: 1.891702651977539
Validation loss: 2.041244287644663

Epoch: 5| Step: 7
Training loss: 2.008279323577881
Validation loss: 2.045928357749857

Epoch: 5| Step: 8
Training loss: 2.877443790435791
Validation loss: 2.0385166509177095

Epoch: 5| Step: 9
Training loss: 1.6453018188476562
Validation loss: 2.0202195721287883

Epoch: 5| Step: 10
Training loss: 2.978883743286133
Validation loss: 1.9955933837480442

Epoch: 128| Step: 0
Training loss: 2.461270809173584
Validation loss: 1.9805380657155027

Epoch: 5| Step: 1
Training loss: 2.076763391494751
Validation loss: 1.9932204510575982

Epoch: 5| Step: 2
Training loss: 2.707824230194092
Validation loss: 1.9914058523793374

Epoch: 5| Step: 3
Training loss: 1.5074288845062256
Validation loss: 1.9948305109495759

Epoch: 5| Step: 4
Training loss: 1.6477711200714111
Validation loss: 2.01765319737055

Epoch: 5| Step: 5
Training loss: 2.2108378410339355
Validation loss: 2.015677505923856

Epoch: 5| Step: 6
Training loss: 2.7300851345062256
Validation loss: 2.0148618400737806

Epoch: 5| Step: 7
Training loss: 2.5458903312683105
Validation loss: 2.006706340338594

Epoch: 5| Step: 8
Training loss: 2.016624927520752
Validation loss: 1.9920954678648262

Epoch: 5| Step: 9
Training loss: 2.7468345165252686
Validation loss: 1.9841118371614845

Epoch: 5| Step: 10
Training loss: 2.1656525135040283
Validation loss: 1.9848984005630657

Epoch: 129| Step: 0
Training loss: 1.9702558517456055
Validation loss: 1.9774212580855175

Epoch: 5| Step: 1
Training loss: 1.8632017374038696
Validation loss: 1.97760441354526

Epoch: 5| Step: 2
Training loss: 2.4092350006103516
Validation loss: 1.9774992927428214

Epoch: 5| Step: 3
Training loss: 2.412147045135498
Validation loss: 1.9759791128097042

Epoch: 5| Step: 4
Training loss: 2.4169740676879883
Validation loss: 1.9795221910681775

Epoch: 5| Step: 5
Training loss: 1.8949337005615234
Validation loss: 1.9711919779418616

Epoch: 5| Step: 6
Training loss: 2.129300594329834
Validation loss: 1.9729730852188603

Epoch: 5| Step: 7
Training loss: 2.1246650218963623
Validation loss: 1.9649734779070782

Epoch: 5| Step: 8
Training loss: 2.567060708999634
Validation loss: 1.9659513529910837

Epoch: 5| Step: 9
Training loss: 2.11271071434021
Validation loss: 1.9608355747756137

Epoch: 5| Step: 10
Training loss: 2.752716541290283
Validation loss: 1.9576014216228197

Epoch: 130| Step: 0
Training loss: 2.598994731903076
Validation loss: 1.9589715760241273

Epoch: 5| Step: 1
Training loss: 2.1624248027801514
Validation loss: 1.961623473833966

Epoch: 5| Step: 2
Training loss: 2.3220419883728027
Validation loss: 1.955643251378049

Epoch: 5| Step: 3
Training loss: 1.9777088165283203
Validation loss: 1.9631066835054787

Epoch: 5| Step: 4
Training loss: 2.370600461959839
Validation loss: 1.9652663097586682

Epoch: 5| Step: 5
Training loss: 2.1404292583465576
Validation loss: 1.9761137552158807

Epoch: 5| Step: 6
Training loss: 1.8651002645492554
Validation loss: 1.991186193240586

Epoch: 5| Step: 7
Training loss: 2.51652193069458
Validation loss: 1.9930592121616486

Epoch: 5| Step: 8
Training loss: 2.9006857872009277
Validation loss: 1.9914634279025498

Epoch: 5| Step: 9
Training loss: 1.7759641408920288
Validation loss: 1.987676796092782

Epoch: 5| Step: 10
Training loss: 1.8454396724700928
Validation loss: 1.9893795777392644

Epoch: 131| Step: 0
Training loss: 2.0278100967407227
Validation loss: 1.9789697995749853

Epoch: 5| Step: 1
Training loss: 1.9304864406585693
Validation loss: 1.9673177452497586

Epoch: 5| Step: 2
Training loss: 2.0832042694091797
Validation loss: 1.9658026541433027

Epoch: 5| Step: 3
Training loss: 2.0932457447052
Validation loss: 1.9642900266954977

Epoch: 5| Step: 4
Training loss: 2.4652671813964844
Validation loss: 1.9667964622538576

Epoch: 5| Step: 5
Training loss: 1.9699903726577759
Validation loss: 1.9639170246739541

Epoch: 5| Step: 6
Training loss: 2.2970855236053467
Validation loss: 1.9680186984359578

Epoch: 5| Step: 7
Training loss: 2.411517858505249
Validation loss: 1.9616593032754877

Epoch: 5| Step: 8
Training loss: 2.30887770652771
Validation loss: 1.975740122538741

Epoch: 5| Step: 9
Training loss: 2.5956292152404785
Validation loss: 1.9860361596589446

Epoch: 5| Step: 10
Training loss: 2.3983938694000244
Validation loss: 1.986269368920275

Epoch: 132| Step: 0
Training loss: 2.097472667694092
Validation loss: 1.9861995020220358

Epoch: 5| Step: 1
Training loss: 1.2403113842010498
Validation loss: 1.9781661123357794

Epoch: 5| Step: 2
Training loss: 2.7803030014038086
Validation loss: 1.9800194001966906

Epoch: 5| Step: 3
Training loss: 2.062216281890869
Validation loss: 1.9730640957432408

Epoch: 5| Step: 4
Training loss: 2.6257729530334473
Validation loss: 1.9787331140169533

Epoch: 5| Step: 5
Training loss: 2.726940631866455
Validation loss: 1.982953143376176

Epoch: 5| Step: 6
Training loss: 2.336444139480591
Validation loss: 1.9755934066669916

Epoch: 5| Step: 7
Training loss: 2.048473358154297
Validation loss: 1.980482227058821

Epoch: 5| Step: 8
Training loss: 1.639029860496521
Validation loss: 1.979622152543837

Epoch: 5| Step: 9
Training loss: 2.7131266593933105
Validation loss: 1.9779764195924163

Epoch: 5| Step: 10
Training loss: 2.070432662963867
Validation loss: 1.971154515461255

Epoch: 133| Step: 0
Training loss: 1.9237773418426514
Validation loss: 1.9806443901472195

Epoch: 5| Step: 1
Training loss: 2.2900230884552
Validation loss: 1.9699020539560625

Epoch: 5| Step: 2
Training loss: 2.2644050121307373
Validation loss: 1.9758899775884484

Epoch: 5| Step: 3
Training loss: 2.1537890434265137
Validation loss: 1.985871978985366

Epoch: 5| Step: 4
Training loss: 1.9596364498138428
Validation loss: 1.996966754236529

Epoch: 5| Step: 5
Training loss: 1.9452043771743774
Validation loss: 1.9934559483681955

Epoch: 5| Step: 6
Training loss: 2.874901294708252
Validation loss: 2.007139230287203

Epoch: 5| Step: 7
Training loss: 2.267287492752075
Validation loss: 2.00682052745614

Epoch: 5| Step: 8
Training loss: 2.3035006523132324
Validation loss: 2.003722745885131

Epoch: 5| Step: 9
Training loss: 2.280311346054077
Validation loss: 1.9896685692571825

Epoch: 5| Step: 10
Training loss: 2.119880199432373
Validation loss: 1.9877131215987667

Epoch: 134| Step: 0
Training loss: 2.390570640563965
Validation loss: 1.9807008440776537

Epoch: 5| Step: 1
Training loss: 2.3060410022735596
Validation loss: 1.986328714637346

Epoch: 5| Step: 2
Training loss: 2.8503451347351074
Validation loss: 1.9953708135953514

Epoch: 5| Step: 3
Training loss: 1.7666698694229126
Validation loss: 1.99355746341008

Epoch: 5| Step: 4
Training loss: 2.102781295776367
Validation loss: 1.9910087175266717

Epoch: 5| Step: 5
Training loss: 1.9302351474761963
Validation loss: 1.9771509042350195

Epoch: 5| Step: 6
Training loss: 2.132183313369751
Validation loss: 1.9628861963108022

Epoch: 5| Step: 7
Training loss: 1.9081617593765259
Validation loss: 1.9553851671116327

Epoch: 5| Step: 8
Training loss: 1.9174926280975342
Validation loss: 1.949690266322064

Epoch: 5| Step: 9
Training loss: 2.8139846324920654
Validation loss: 1.9553844954377861

Epoch: 5| Step: 10
Training loss: 2.3135228157043457
Validation loss: 1.962665770643501

Epoch: 135| Step: 0
Training loss: 2.41814923286438
Validation loss: 1.9670540568649129

Epoch: 5| Step: 1
Training loss: 1.858428955078125
Validation loss: 1.9576143116079352

Epoch: 5| Step: 2
Training loss: 1.8374313116073608
Validation loss: 1.9631527969914098

Epoch: 5| Step: 3
Training loss: 1.8452545404434204
Validation loss: 1.974982314212348

Epoch: 5| Step: 4
Training loss: 1.9830375909805298
Validation loss: 1.9731105399388138

Epoch: 5| Step: 5
Training loss: 2.0695536136627197
Validation loss: 1.9873517918330368

Epoch: 5| Step: 6
Training loss: 2.479302167892456
Validation loss: 1.9955512169868714

Epoch: 5| Step: 7
Training loss: 2.606635570526123
Validation loss: 1.9929279153065016

Epoch: 5| Step: 8
Training loss: 2.2889251708984375
Validation loss: 1.983446228888727

Epoch: 5| Step: 9
Training loss: 2.551610231399536
Validation loss: 1.9752324268382082

Epoch: 5| Step: 10
Training loss: 2.4332830905914307
Validation loss: 1.9670678774515789

Epoch: 136| Step: 0
Training loss: 2.2201642990112305
Validation loss: 1.9696550676899571

Epoch: 5| Step: 1
Training loss: 2.389786958694458
Validation loss: 1.976290036273259

Epoch: 5| Step: 2
Training loss: 2.613436460494995
Validation loss: 1.9734016028783654

Epoch: 5| Step: 3
Training loss: 2.6241209506988525
Validation loss: 1.9708888069275887

Epoch: 5| Step: 4
Training loss: 2.135580062866211
Validation loss: 1.9722363410457489

Epoch: 5| Step: 5
Training loss: 2.558940887451172
Validation loss: 1.9654948224303543

Epoch: 5| Step: 6
Training loss: 2.0938029289245605
Validation loss: 1.9738832596809632

Epoch: 5| Step: 7
Training loss: 2.1250462532043457
Validation loss: 1.9871168085323867

Epoch: 5| Step: 8
Training loss: 2.1168715953826904
Validation loss: 1.9954405292387931

Epoch: 5| Step: 9
Training loss: 1.815026879310608
Validation loss: 1.9858803108174314

Epoch: 5| Step: 10
Training loss: 1.6115831136703491
Validation loss: 1.9802870263335526

Epoch: 137| Step: 0
Training loss: 2.0815067291259766
Validation loss: 1.9641332152069255

Epoch: 5| Step: 1
Training loss: 1.2780876159667969
Validation loss: 1.952588096741707

Epoch: 5| Step: 2
Training loss: 2.327914237976074
Validation loss: 1.9727384826188445

Epoch: 5| Step: 3
Training loss: 2.18306303024292
Validation loss: 1.9623474997858847

Epoch: 5| Step: 4
Training loss: 2.4908623695373535
Validation loss: 1.9674100952763711

Epoch: 5| Step: 5
Training loss: 2.360844135284424
Validation loss: 1.9599542079433319

Epoch: 5| Step: 6
Training loss: 2.3966727256774902
Validation loss: 1.952894256960961

Epoch: 5| Step: 7
Training loss: 2.498570680618286
Validation loss: 1.954111473534697

Epoch: 5| Step: 8
Training loss: 1.8488496541976929
Validation loss: 1.966462314769786

Epoch: 5| Step: 9
Training loss: 2.040576219558716
Validation loss: 1.9866311793686242

Epoch: 5| Step: 10
Training loss: 2.8614020347595215
Validation loss: 1.9881580914220502

Epoch: 138| Step: 0
Training loss: 2.2167701721191406
Validation loss: 1.988736560267787

Epoch: 5| Step: 1
Training loss: 2.4769444465637207
Validation loss: 1.9985922344269291

Epoch: 5| Step: 2
Training loss: 2.530740261077881
Validation loss: 1.9891954109232912

Epoch: 5| Step: 3
Training loss: 1.7698354721069336
Validation loss: 1.9828839302062988

Epoch: 5| Step: 4
Training loss: 2.3432517051696777
Validation loss: 1.9750738631012619

Epoch: 5| Step: 5
Training loss: 2.00050687789917
Validation loss: 1.9797193375966882

Epoch: 5| Step: 6
Training loss: 1.8350350856781006
Validation loss: 1.9855554706306868

Epoch: 5| Step: 7
Training loss: 1.8562511205673218
Validation loss: 1.9838418909298476

Epoch: 5| Step: 8
Training loss: 2.160796642303467
Validation loss: 1.9765311389841058

Epoch: 5| Step: 9
Training loss: 2.0508358478546143
Validation loss: 1.9762516585729455

Epoch: 5| Step: 10
Training loss: 3.230679750442505
Validation loss: 1.9925129029058641

Epoch: 139| Step: 0
Training loss: 2.3888823986053467
Validation loss: 1.998170671924468

Epoch: 5| Step: 1
Training loss: 2.156388521194458
Validation loss: 2.011024563543258

Epoch: 5| Step: 2
Training loss: 2.1740505695343018
Validation loss: 2.0016599432114632

Epoch: 5| Step: 3
Training loss: 1.3628711700439453
Validation loss: 1.9855308891624532

Epoch: 5| Step: 4
Training loss: 2.5193915367126465
Validation loss: 1.9800032364424838

Epoch: 5| Step: 5
Training loss: 2.767913579940796
Validation loss: 1.9726368073494203

Epoch: 5| Step: 6
Training loss: 1.9102134704589844
Validation loss: 1.9552233193510322

Epoch: 5| Step: 7
Training loss: 2.2993831634521484
Validation loss: 1.9404298438820788

Epoch: 5| Step: 8
Training loss: 2.1971678733825684
Validation loss: 1.9406333533666467

Epoch: 5| Step: 9
Training loss: 2.142953395843506
Validation loss: 1.9367378155390422

Epoch: 5| Step: 10
Training loss: 2.4540467262268066
Validation loss: 1.931888182957967

Epoch: 140| Step: 0
Training loss: 2.9699816703796387
Validation loss: 1.9366515810771654

Epoch: 5| Step: 1
Training loss: 2.1838176250457764
Validation loss: 1.934719657385221

Epoch: 5| Step: 2
Training loss: 2.379335880279541
Validation loss: 1.9339591585179812

Epoch: 5| Step: 3
Training loss: 1.0828733444213867
Validation loss: 1.933692919310703

Epoch: 5| Step: 4
Training loss: 1.9641749858856201
Validation loss: 1.9442134006049043

Epoch: 5| Step: 5
Training loss: 2.6648755073547363
Validation loss: 1.9594118287486415

Epoch: 5| Step: 6
Training loss: 1.6736491918563843
Validation loss: 1.9753816589232414

Epoch: 5| Step: 7
Training loss: 1.975874900817871
Validation loss: 1.972835139561725

Epoch: 5| Step: 8
Training loss: 2.728295087814331
Validation loss: 1.9713538564661497

Epoch: 5| Step: 9
Training loss: 2.325080156326294
Validation loss: 1.9644245460469236

Epoch: 5| Step: 10
Training loss: 2.356445550918579
Validation loss: 1.955712531202583

Epoch: 141| Step: 0
Training loss: 2.358447313308716
Validation loss: 1.9442902982875865

Epoch: 5| Step: 1
Training loss: 2.0909976959228516
Validation loss: 1.9388175190135997

Epoch: 5| Step: 2
Training loss: 2.7708516120910645
Validation loss: 1.9389446832800423

Epoch: 5| Step: 3
Training loss: 1.8966875076293945
Validation loss: 1.9368076529554141

Epoch: 5| Step: 4
Training loss: 2.612978458404541
Validation loss: 1.9452138421356038

Epoch: 5| Step: 5
Training loss: 2.4756736755371094
Validation loss: 1.9482414901897471

Epoch: 5| Step: 6
Training loss: 1.7955100536346436
Validation loss: 1.9442644747354652

Epoch: 5| Step: 7
Training loss: 2.304636001586914
Validation loss: 1.9488353524156796

Epoch: 5| Step: 8
Training loss: 1.9103952646255493
Validation loss: 1.9547968936222855

Epoch: 5| Step: 9
Training loss: 1.9802945852279663
Validation loss: 1.9594161279739872

Epoch: 5| Step: 10
Training loss: 1.9569841623306274
Validation loss: 1.9789191381905669

Epoch: 142| Step: 0
Training loss: 1.5816246271133423
Validation loss: 1.976071693563974

Epoch: 5| Step: 1
Training loss: 2.5595977306365967
Validation loss: 1.9638414716207853

Epoch: 5| Step: 2
Training loss: 2.2633073329925537
Validation loss: 1.9512976702823435

Epoch: 5| Step: 3
Training loss: 2.3301258087158203
Validation loss: 1.9364220288492018

Epoch: 5| Step: 4
Training loss: 2.235930919647217
Validation loss: 1.9397370802458895

Epoch: 5| Step: 5
Training loss: 1.7642934322357178
Validation loss: 1.9371905249934043

Epoch: 5| Step: 6
Training loss: 2.322909116744995
Validation loss: 1.9351490441189017

Epoch: 5| Step: 7
Training loss: 1.6934740543365479
Validation loss: 1.9390712861091859

Epoch: 5| Step: 8
Training loss: 2.3518855571746826
Validation loss: 1.9378256618335683

Epoch: 5| Step: 9
Training loss: 2.3901607990264893
Validation loss: 1.9494176192950177

Epoch: 5| Step: 10
Training loss: 2.484485387802124
Validation loss: 1.9502260210693523

Epoch: 143| Step: 0
Training loss: 2.4142792224884033
Validation loss: 1.9542700705989715

Epoch: 5| Step: 1
Training loss: 2.004483699798584
Validation loss: 1.9607225874418854

Epoch: 5| Step: 2
Training loss: 1.5912971496582031
Validation loss: 1.961834212785126

Epoch: 5| Step: 3
Training loss: 1.4906834363937378
Validation loss: 1.9618354792236

Epoch: 5| Step: 4
Training loss: 2.2541236877441406
Validation loss: 1.9560915167613695

Epoch: 5| Step: 5
Training loss: 1.7871443033218384
Validation loss: 1.9525034709643292

Epoch: 5| Step: 6
Training loss: 3.210480213165283
Validation loss: 1.963012223602623

Epoch: 5| Step: 7
Training loss: 2.2865047454833984
Validation loss: 1.9681389229272002

Epoch: 5| Step: 8
Training loss: 2.157770872116089
Validation loss: 1.966809267638832

Epoch: 5| Step: 9
Training loss: 2.461519956588745
Validation loss: 1.9652760041657316

Epoch: 5| Step: 10
Training loss: 2.282022476196289
Validation loss: 1.9627466445328088

Epoch: 144| Step: 0
Training loss: 2.2926430702209473
Validation loss: 1.9505390992728613

Epoch: 5| Step: 1
Training loss: 2.083080768585205
Validation loss: 1.9450300816566712

Epoch: 5| Step: 2
Training loss: 2.317814588546753
Validation loss: 1.9390357412317747

Epoch: 5| Step: 3
Training loss: 1.3031337261199951
Validation loss: 1.9374322865598945

Epoch: 5| Step: 4
Training loss: 2.2884304523468018
Validation loss: 1.929028650765778

Epoch: 5| Step: 5
Training loss: 2.273467540740967
Validation loss: 1.9308035245505712

Epoch: 5| Step: 6
Training loss: 2.282656192779541
Validation loss: 1.9303103903288483

Epoch: 5| Step: 7
Training loss: 2.6410439014434814
Validation loss: 1.9335010128636514

Epoch: 5| Step: 8
Training loss: 1.911094069480896
Validation loss: 1.93363400941254

Epoch: 5| Step: 9
Training loss: 2.376417636871338
Validation loss: 1.9248526416799074

Epoch: 5| Step: 10
Training loss: 2.0895633697509766
Validation loss: 1.9330970305268482

Epoch: 145| Step: 0
Training loss: 2.3571667671203613
Validation loss: 1.9463836505848875

Epoch: 5| Step: 1
Training loss: 2.110045909881592
Validation loss: 1.9543860663649857

Epoch: 5| Step: 2
Training loss: 2.1663241386413574
Validation loss: 1.9500529432809481

Epoch: 5| Step: 3
Training loss: 2.4192428588867188
Validation loss: 1.9568346200450775

Epoch: 5| Step: 4
Training loss: 1.9165630340576172
Validation loss: 1.9650645076587636

Epoch: 5| Step: 5
Training loss: 1.8926159143447876
Validation loss: 1.9619825860505462

Epoch: 5| Step: 6
Training loss: 2.163511276245117
Validation loss: 1.9596417821863645

Epoch: 5| Step: 7
Training loss: 2.1838889122009277
Validation loss: 1.9569509388298116

Epoch: 5| Step: 8
Training loss: 1.7723737955093384
Validation loss: 1.9614876944531676

Epoch: 5| Step: 9
Training loss: 2.254986524581909
Validation loss: 1.9716353621534122

Epoch: 5| Step: 10
Training loss: 2.7012877464294434
Validation loss: 1.9647143733116887

Epoch: 146| Step: 0
Training loss: 2.2077443599700928
Validation loss: 1.963067650794983

Epoch: 5| Step: 1
Training loss: 2.1733086109161377
Validation loss: 1.9578902695768623

Epoch: 5| Step: 2
Training loss: 2.127850294113159
Validation loss: 1.9615649741183045

Epoch: 5| Step: 3
Training loss: 1.8172352313995361
Validation loss: 1.9487040645332747

Epoch: 5| Step: 4
Training loss: 2.536513090133667
Validation loss: 1.944329172052363

Epoch: 5| Step: 5
Training loss: 2.4852750301361084
Validation loss: 1.951954774959113

Epoch: 5| Step: 6
Training loss: 2.226689100265503
Validation loss: 1.9476619561513264

Epoch: 5| Step: 7
Training loss: 1.7788169384002686
Validation loss: 1.9506224996300154

Epoch: 5| Step: 8
Training loss: 2.116870164871216
Validation loss: 1.94702523626307

Epoch: 5| Step: 9
Training loss: 1.7756469249725342
Validation loss: 1.9481559184289747

Epoch: 5| Step: 10
Training loss: 2.5557990074157715
Validation loss: 1.9441862285778087

Epoch: 147| Step: 0
Training loss: 2.176830768585205
Validation loss: 1.9305905526684177

Epoch: 5| Step: 1
Training loss: 1.8058693408966064
Validation loss: 1.9315985172025618

Epoch: 5| Step: 2
Training loss: 2.5958142280578613
Validation loss: 1.92274478174025

Epoch: 5| Step: 3
Training loss: 2.399515390396118
Validation loss: 1.925631312913792

Epoch: 5| Step: 4
Training loss: 1.9540221691131592
Validation loss: 1.9238959191947855

Epoch: 5| Step: 5
Training loss: 2.0752274990081787
Validation loss: 1.9351377615364649

Epoch: 5| Step: 6
Training loss: 2.3923048973083496
Validation loss: 1.9365480407591789

Epoch: 5| Step: 7
Training loss: 2.0179989337921143
Validation loss: 1.9257405316957863

Epoch: 5| Step: 8
Training loss: 1.8317184448242188
Validation loss: 1.9322116080150809

Epoch: 5| Step: 9
Training loss: 2.1644484996795654
Validation loss: 1.9293976599170315

Epoch: 5| Step: 10
Training loss: 2.507434368133545
Validation loss: 1.9355558797877321

Epoch: 148| Step: 0
Training loss: 1.920536756515503
Validation loss: 1.9418026452423425

Epoch: 5| Step: 1
Training loss: 2.031952381134033
Validation loss: 1.9473936788497432

Epoch: 5| Step: 2
Training loss: 2.688284397125244
Validation loss: 1.9590237627747238

Epoch: 5| Step: 3
Training loss: 1.6699085235595703
Validation loss: 1.9672683515856344

Epoch: 5| Step: 4
Training loss: 2.5251898765563965
Validation loss: 1.9819673363880446

Epoch: 5| Step: 5
Training loss: 1.7053868770599365
Validation loss: 2.0033053121259137

Epoch: 5| Step: 6
Training loss: 2.186567783355713
Validation loss: 1.9761636949354602

Epoch: 5| Step: 7
Training loss: 2.0988972187042236
Validation loss: 1.987788466997044

Epoch: 5| Step: 8
Training loss: 2.5098488330841064
Validation loss: 1.9958459805416804

Epoch: 5| Step: 9
Training loss: 1.9323561191558838
Validation loss: 1.988164754324062

Epoch: 5| Step: 10
Training loss: 2.715975761413574
Validation loss: 1.979815544620637

Epoch: 149| Step: 0
Training loss: 1.9578078985214233
Validation loss: 1.9815533750800676

Epoch: 5| Step: 1
Training loss: 2.1163864135742188
Validation loss: 1.9639635470605665

Epoch: 5| Step: 2
Training loss: 1.5833356380462646
Validation loss: 1.9473003290032829

Epoch: 5| Step: 3
Training loss: 1.973811388015747
Validation loss: 1.9600916318995978

Epoch: 5| Step: 4
Training loss: 2.5343034267425537
Validation loss: 1.9573305306896087

Epoch: 5| Step: 5
Training loss: 2.410484552383423
Validation loss: 1.959730520043322

Epoch: 5| Step: 6
Training loss: 2.2176716327667236
Validation loss: 1.95296436484142

Epoch: 5| Step: 7
Training loss: 2.127495288848877
Validation loss: 1.95328317534539

Epoch: 5| Step: 8
Training loss: 2.029048442840576
Validation loss: 1.9438302260573193

Epoch: 5| Step: 9
Training loss: 2.4062840938568115
Validation loss: 1.951733935263849

Epoch: 5| Step: 10
Training loss: 2.3906874656677246
Validation loss: 1.9606045292269798

Epoch: 150| Step: 0
Training loss: 2.2109735012054443
Validation loss: 1.9778167714354813

Epoch: 5| Step: 1
Training loss: 2.1605448722839355
Validation loss: 1.9635647637869722

Epoch: 5| Step: 2
Training loss: 2.3511619567871094
Validation loss: 1.9506201205715057

Epoch: 5| Step: 3
Training loss: 2.0233070850372314
Validation loss: 1.9427416811707199

Epoch: 5| Step: 4
Training loss: 1.5223321914672852
Validation loss: 1.9506949660598591

Epoch: 5| Step: 5
Training loss: 2.2862942218780518
Validation loss: 1.9467959237355057

Epoch: 5| Step: 6
Training loss: 2.551246404647827
Validation loss: 1.9276785183978338

Epoch: 5| Step: 7
Training loss: 1.9153378009796143
Validation loss: 1.9330656464381883

Epoch: 5| Step: 8
Training loss: 2.4383974075317383
Validation loss: 1.939845056943996

Epoch: 5| Step: 9
Training loss: 1.9530160427093506
Validation loss: 1.9344367340046873

Epoch: 5| Step: 10
Training loss: 2.238593339920044
Validation loss: 1.9279180060150802

Epoch: 151| Step: 0
Training loss: 2.6894969940185547
Validation loss: 1.9295157322319605

Epoch: 5| Step: 1
Training loss: 3.139199733734131
Validation loss: 1.9347512452833113

Epoch: 5| Step: 2
Training loss: 1.77727472782135
Validation loss: 1.9373738586261708

Epoch: 5| Step: 3
Training loss: 1.0459458827972412
Validation loss: 1.9488432099742274

Epoch: 5| Step: 4
Training loss: 2.4128623008728027
Validation loss: 1.9479167999759797

Epoch: 5| Step: 5
Training loss: 2.3268401622772217
Validation loss: 1.9517768531717279

Epoch: 5| Step: 6
Training loss: 1.9763195514678955
Validation loss: 1.965019360665352

Epoch: 5| Step: 7
Training loss: 2.1945934295654297
Validation loss: 1.9701691699284378

Epoch: 5| Step: 8
Training loss: 2.41041898727417
Validation loss: 1.9707295381894676

Epoch: 5| Step: 9
Training loss: 1.4894593954086304
Validation loss: 1.9498795809284333

Epoch: 5| Step: 10
Training loss: 2.014082670211792
Validation loss: 1.9415682208153509

Epoch: 152| Step: 0
Training loss: 2.253889322280884
Validation loss: 1.9350524025578653

Epoch: 5| Step: 1
Training loss: 2.4033167362213135
Validation loss: 1.9335998232646654

Epoch: 5| Step: 2
Training loss: 2.257268190383911
Validation loss: 1.9411982631170621

Epoch: 5| Step: 3
Training loss: 2.009009838104248
Validation loss: 1.942155566266788

Epoch: 5| Step: 4
Training loss: 2.0008015632629395
Validation loss: 1.9353130632831204

Epoch: 5| Step: 5
Training loss: 2.338385820388794
Validation loss: 1.9276399907245432

Epoch: 5| Step: 6
Training loss: 1.4039973020553589
Validation loss: 1.9372019306305917

Epoch: 5| Step: 7
Training loss: 1.8860527276992798
Validation loss: 1.9399306748502998

Epoch: 5| Step: 8
Training loss: 2.4086241722106934
Validation loss: 1.9386032217292375

Epoch: 5| Step: 9
Training loss: 2.1434130668640137
Validation loss: 1.9365499122168428

Epoch: 5| Step: 10
Training loss: 2.2095468044281006
Validation loss: 1.9433557359121179

Epoch: 153| Step: 0
Training loss: 1.8228394985198975
Validation loss: 1.9395390351613362

Epoch: 5| Step: 1
Training loss: 2.7524611949920654
Validation loss: 1.9481031484501337

Epoch: 5| Step: 2
Training loss: 2.122161388397217
Validation loss: 1.946492087456488

Epoch: 5| Step: 3
Training loss: 2.076981782913208
Validation loss: 1.9523303560031358

Epoch: 5| Step: 4
Training loss: 2.2850441932678223
Validation loss: 1.959644720118533

Epoch: 5| Step: 5
Training loss: 2.105980157852173
Validation loss: 1.9726405400101856

Epoch: 5| Step: 6
Training loss: 1.9005476236343384
Validation loss: 1.9705695811138357

Epoch: 5| Step: 7
Training loss: 1.5730252265930176
Validation loss: 1.9982564180128035

Epoch: 5| Step: 8
Training loss: 2.1086106300354004
Validation loss: 1.983627526990829

Epoch: 5| Step: 9
Training loss: 2.352691411972046
Validation loss: 1.966918214674919

Epoch: 5| Step: 10
Training loss: 2.2469921112060547
Validation loss: 1.9604209776847594

Epoch: 154| Step: 0
Training loss: 1.7537548542022705
Validation loss: 1.958989329235528

Epoch: 5| Step: 1
Training loss: 2.088778018951416
Validation loss: 1.967019429770849

Epoch: 5| Step: 2
Training loss: 2.3628575801849365
Validation loss: 1.9734667449869134

Epoch: 5| Step: 3
Training loss: 2.301172971725464
Validation loss: 1.9639744143332205

Epoch: 5| Step: 4
Training loss: 1.7515093088150024
Validation loss: 1.9537430168480001

Epoch: 5| Step: 5
Training loss: 1.7164322137832642
Validation loss: 1.9544600030427337

Epoch: 5| Step: 6
Training loss: 2.5583925247192383
Validation loss: 1.949438992366996

Epoch: 5| Step: 7
Training loss: 2.5200843811035156
Validation loss: 1.946049008318173

Epoch: 5| Step: 8
Training loss: 1.824118971824646
Validation loss: 1.9402531372603549

Epoch: 5| Step: 9
Training loss: 2.311601161956787
Validation loss: 1.9404973727400585

Epoch: 5| Step: 10
Training loss: 2.0311827659606934
Validation loss: 1.9535185111466276

Epoch: 155| Step: 0
Training loss: 2.5927157402038574
Validation loss: 1.9776198992165186

Epoch: 5| Step: 1
Training loss: 2.525923252105713
Validation loss: 1.965871912176891

Epoch: 5| Step: 2
Training loss: 2.4837746620178223
Validation loss: 1.9877486280215684

Epoch: 5| Step: 3
Training loss: 2.714521646499634
Validation loss: 1.9976136325508036

Epoch: 5| Step: 4
Training loss: 1.521436333656311
Validation loss: 2.024180696856591

Epoch: 5| Step: 5
Training loss: 1.9554824829101562
Validation loss: 2.019270100901204

Epoch: 5| Step: 6
Training loss: 1.9053843021392822
Validation loss: 1.9928336874131234

Epoch: 5| Step: 7
Training loss: 1.7583621740341187
Validation loss: 1.9789911931560886

Epoch: 5| Step: 8
Training loss: 1.998732328414917
Validation loss: 1.9551573286774337

Epoch: 5| Step: 9
Training loss: 2.1272242069244385
Validation loss: 1.9584463398943666

Epoch: 5| Step: 10
Training loss: 1.9607229232788086
Validation loss: 1.9452082931354482

Epoch: 156| Step: 0
Training loss: 2.378528594970703
Validation loss: 1.9417246349396244

Epoch: 5| Step: 1
Training loss: 2.0444629192352295
Validation loss: 1.9221111189934514

Epoch: 5| Step: 2
Training loss: 2.216320276260376
Validation loss: 1.924213747824392

Epoch: 5| Step: 3
Training loss: 1.664324164390564
Validation loss: 1.915692667807302

Epoch: 5| Step: 4
Training loss: 2.162515640258789
Validation loss: 1.9126451784564602

Epoch: 5| Step: 5
Training loss: 2.1004297733306885
Validation loss: 1.9151928629926456

Epoch: 5| Step: 6
Training loss: 2.254664182662964
Validation loss: 1.9197946427970805

Epoch: 5| Step: 7
Training loss: 1.9991750717163086
Validation loss: 1.9241636235226867

Epoch: 5| Step: 8
Training loss: 1.4416329860687256
Validation loss: 1.9369097025163713

Epoch: 5| Step: 9
Training loss: 2.3694920539855957
Validation loss: 1.9306656301662486

Epoch: 5| Step: 10
Training loss: 2.9844532012939453
Validation loss: 1.9301599533327165

Epoch: 157| Step: 0
Training loss: 1.6428133249282837
Validation loss: 1.9150368218780847

Epoch: 5| Step: 1
Training loss: 1.7875343561172485
Validation loss: 1.9261958650363389

Epoch: 5| Step: 2
Training loss: 1.84515380859375
Validation loss: 1.9356187479470366

Epoch: 5| Step: 3
Training loss: 1.5201106071472168
Validation loss: 1.940148438176801

Epoch: 5| Step: 4
Training loss: 2.811753034591675
Validation loss: 1.9555934218950168

Epoch: 5| Step: 5
Training loss: 2.7389907836914062
Validation loss: 1.9553871231694375

Epoch: 5| Step: 6
Training loss: 2.1735424995422363
Validation loss: 1.96287186684147

Epoch: 5| Step: 7
Training loss: 2.2361397743225098
Validation loss: 1.9728058397129018

Epoch: 5| Step: 8
Training loss: 2.6698927879333496
Validation loss: 1.9556915760040283

Epoch: 5| Step: 9
Training loss: 1.748260259628296
Validation loss: 1.9404037370476672

Epoch: 5| Step: 10
Training loss: 1.9526093006134033
Validation loss: 1.9375066654656523

Epoch: 158| Step: 0
Training loss: 2.531569004058838
Validation loss: 1.9414680491211593

Epoch: 5| Step: 1
Training loss: 2.2744622230529785
Validation loss: 1.9288087762812132

Epoch: 5| Step: 2
Training loss: 2.506211042404175
Validation loss: 1.9289559113082064

Epoch: 5| Step: 3
Training loss: 1.941170334815979
Validation loss: 1.9214714393820813

Epoch: 5| Step: 4
Training loss: 1.6451969146728516
Validation loss: 1.911695162455241

Epoch: 5| Step: 5
Training loss: 1.9522783756256104
Validation loss: 1.9061710872957784

Epoch: 5| Step: 6
Training loss: 2.512632131576538
Validation loss: 1.9039996439410793

Epoch: 5| Step: 7
Training loss: 1.7751092910766602
Validation loss: 1.9144302837310299

Epoch: 5| Step: 8
Training loss: 1.8684213161468506
Validation loss: 1.9318287744317004

Epoch: 5| Step: 9
Training loss: 2.4857571125030518
Validation loss: 1.9350357747847033

Epoch: 5| Step: 10
Training loss: 1.7984758615493774
Validation loss: 1.9411356115853915

Epoch: 159| Step: 0
Training loss: 1.4819506406784058
Validation loss: 1.9497857145083848

Epoch: 5| Step: 1
Training loss: 1.8547098636627197
Validation loss: 1.9371278747435539

Epoch: 5| Step: 2
Training loss: 2.986093044281006
Validation loss: 1.9508941673463391

Epoch: 5| Step: 3
Training loss: 1.9350391626358032
Validation loss: 1.9688121413671842

Epoch: 5| Step: 4
Training loss: 2.119485855102539
Validation loss: 2.0222686285613687

Epoch: 5| Step: 5
Training loss: 2.535433769226074
Validation loss: 2.0409437764075493

Epoch: 5| Step: 6
Training loss: 1.772068738937378
Validation loss: 2.0364699876436623

Epoch: 5| Step: 7
Training loss: 2.2193198204040527
Validation loss: 2.0172881490440777

Epoch: 5| Step: 8
Training loss: 2.1476502418518066
Validation loss: 1.9748177925745647

Epoch: 5| Step: 9
Training loss: 2.1378631591796875
Validation loss: 1.959631876278949

Epoch: 5| Step: 10
Training loss: 2.2376210689544678
Validation loss: 1.9552424428283528

Epoch: 160| Step: 0
Training loss: 1.8466155529022217
Validation loss: 1.9559660701341526

Epoch: 5| Step: 1
Training loss: 2.6540138721466064
Validation loss: 1.9609506860856087

Epoch: 5| Step: 2
Training loss: 2.351952075958252
Validation loss: 1.9484730177028204

Epoch: 5| Step: 3
Training loss: 1.947350263595581
Validation loss: 1.949153854000953

Epoch: 5| Step: 4
Training loss: 2.0956432819366455
Validation loss: 1.9294710595120665

Epoch: 5| Step: 5
Training loss: 2.072864532470703
Validation loss: 1.9402508357519745

Epoch: 5| Step: 6
Training loss: 1.8132280111312866
Validation loss: 1.9467204540006575

Epoch: 5| Step: 7
Training loss: 1.6446548700332642
Validation loss: 1.9481813574350009

Epoch: 5| Step: 8
Training loss: 2.3121535778045654
Validation loss: 1.9501289859894784

Epoch: 5| Step: 9
Training loss: 2.651540756225586
Validation loss: 1.9527719866844915

Epoch: 5| Step: 10
Training loss: 1.8885780572891235
Validation loss: 1.9591064683852657

Epoch: 161| Step: 0
Training loss: 1.5962992906570435
Validation loss: 1.9358147818555114

Epoch: 5| Step: 1
Training loss: 2.2127327919006348
Validation loss: 1.9327408613697175

Epoch: 5| Step: 2
Training loss: 2.413809061050415
Validation loss: 1.916066918321835

Epoch: 5| Step: 3
Training loss: 2.444960355758667
Validation loss: 1.9186437245338195

Epoch: 5| Step: 4
Training loss: 2.349116802215576
Validation loss: 1.9363515851318196

Epoch: 5| Step: 5
Training loss: 1.7068336009979248
Validation loss: 1.952296474928497

Epoch: 5| Step: 6
Training loss: 1.7020604610443115
Validation loss: 1.9459341213267336

Epoch: 5| Step: 7
Training loss: 1.7010078430175781
Validation loss: 1.9546707971121675

Epoch: 5| Step: 8
Training loss: 2.405092239379883
Validation loss: 1.9298130568637644

Epoch: 5| Step: 9
Training loss: 2.2703824043273926
Validation loss: 1.9450482322323708

Epoch: 5| Step: 10
Training loss: 2.3789942264556885
Validation loss: 1.9459220722157469

Epoch: 162| Step: 0
Training loss: 2.0397496223449707
Validation loss: 1.9553632505478398

Epoch: 5| Step: 1
Training loss: 2.380363941192627
Validation loss: 1.9480174459436888

Epoch: 5| Step: 2
Training loss: 1.8728387355804443
Validation loss: 1.9492481229125813

Epoch: 5| Step: 3
Training loss: 2.0068717002868652
Validation loss: 1.9404051547409387

Epoch: 5| Step: 4
Training loss: 2.4109482765197754
Validation loss: 1.9249033261370916

Epoch: 5| Step: 5
Training loss: 2.201937198638916
Validation loss: 1.9211325337809901

Epoch: 5| Step: 6
Training loss: 2.659407377243042
Validation loss: 1.9512733618418376

Epoch: 5| Step: 7
Training loss: 1.9134852886199951
Validation loss: 1.966667366284196

Epoch: 5| Step: 8
Training loss: 2.0161995887756348
Validation loss: 1.9729784163095618

Epoch: 5| Step: 9
Training loss: 1.69780695438385
Validation loss: 1.950429767690679

Epoch: 5| Step: 10
Training loss: 2.273683786392212
Validation loss: 1.938475465261808

Epoch: 163| Step: 0
Training loss: 1.731395959854126
Validation loss: 1.936148843457622

Epoch: 5| Step: 1
Training loss: 1.276208758354187
Validation loss: 1.9407969982393327

Epoch: 5| Step: 2
Training loss: 1.638625144958496
Validation loss: 1.9620008314809492

Epoch: 5| Step: 3
Training loss: 1.9795849323272705
Validation loss: 1.9996933629435878

Epoch: 5| Step: 4
Training loss: 2.2735657691955566
Validation loss: 2.017011921892884

Epoch: 5| Step: 5
Training loss: 2.0833730697631836
Validation loss: 2.0884489474758023

Epoch: 5| Step: 6
Training loss: 2.6057021617889404
Validation loss: 2.031836079012963

Epoch: 5| Step: 7
Training loss: 2.20820951461792
Validation loss: 1.9755453935233496

Epoch: 5| Step: 8
Training loss: 2.767444133758545
Validation loss: 1.9732376196051156

Epoch: 5| Step: 9
Training loss: 2.2541279792785645
Validation loss: 1.9710480756657098

Epoch: 5| Step: 10
Training loss: 2.6798017024993896
Validation loss: 1.9963763016526417

Epoch: 164| Step: 0
Training loss: 2.4215691089630127
Validation loss: 2.004173996627972

Epoch: 5| Step: 1
Training loss: 2.242919445037842
Validation loss: 2.012732619880348

Epoch: 5| Step: 2
Training loss: 2.0850460529327393
Validation loss: 2.007523282881706

Epoch: 5| Step: 3
Training loss: 2.843776226043701
Validation loss: 1.9985638318523284

Epoch: 5| Step: 4
Training loss: 1.9952380657196045
Validation loss: 1.9924509089480165

Epoch: 5| Step: 5
Training loss: 1.7251449823379517
Validation loss: 1.9878308414131083

Epoch: 5| Step: 6
Training loss: 2.134521484375
Validation loss: 1.9566907549417147

Epoch: 5| Step: 7
Training loss: 1.9726718664169312
Validation loss: 1.93321777671896

Epoch: 5| Step: 8
Training loss: 2.3795244693756104
Validation loss: 1.9286624129100511

Epoch: 5| Step: 9
Training loss: 1.694854736328125
Validation loss: 1.952521119066464

Epoch: 5| Step: 10
Training loss: 2.151076316833496
Validation loss: 1.9633389737016411

Epoch: 165| Step: 0
Training loss: 2.1185505390167236
Validation loss: 1.9780474196198166

Epoch: 5| Step: 1
Training loss: 2.5356123447418213
Validation loss: 1.9753571107823362

Epoch: 5| Step: 2
Training loss: 2.342258930206299
Validation loss: 1.980790433063302

Epoch: 5| Step: 3
Training loss: 2.242259979248047
Validation loss: 1.9927274027178365

Epoch: 5| Step: 4
Training loss: 2.1287009716033936
Validation loss: 1.9953035334105134

Epoch: 5| Step: 5
Training loss: 2.4488542079925537
Validation loss: 1.9911306365843742

Epoch: 5| Step: 6
Training loss: 2.012216806411743
Validation loss: 1.9910171198588547

Epoch: 5| Step: 7
Training loss: 2.0480856895446777
Validation loss: 1.9869584985958633

Epoch: 5| Step: 8
Training loss: 1.196481466293335
Validation loss: 2.0021367713969243

Epoch: 5| Step: 9
Training loss: 2.1052608489990234
Validation loss: 2.0046600167469313

Epoch: 5| Step: 10
Training loss: 1.9021769762039185
Validation loss: 1.9881762894251014

Epoch: 166| Step: 0
Training loss: 2.9454846382141113
Validation loss: 1.9763324786258

Epoch: 5| Step: 1
Training loss: 1.424350619316101
Validation loss: 1.956107831770374

Epoch: 5| Step: 2
Training loss: 2.0964386463165283
Validation loss: 1.9650724216174054

Epoch: 5| Step: 3
Training loss: 2.3339505195617676
Validation loss: 1.9573386010303293

Epoch: 5| Step: 4
Training loss: 2.0920722484588623
Validation loss: 1.9308270844080115

Epoch: 5| Step: 5
Training loss: 2.124647617340088
Validation loss: 1.9402980471170077

Epoch: 5| Step: 6
Training loss: 1.9584035873413086
Validation loss: 1.9348302695059008

Epoch: 5| Step: 7
Training loss: 2.136914014816284
Validation loss: 1.9147304770767049

Epoch: 5| Step: 8
Training loss: 1.5600742101669312
Validation loss: 1.909505885134461

Epoch: 5| Step: 9
Training loss: 2.0685198307037354
Validation loss: 1.9206663613678308

Epoch: 5| Step: 10
Training loss: 2.249206781387329
Validation loss: 1.9323300212942145

Epoch: 167| Step: 0
Training loss: 2.181347608566284
Validation loss: 1.9536494683193903

Epoch: 5| Step: 1
Training loss: 2.064873695373535
Validation loss: 1.9650280039797547

Epoch: 5| Step: 2
Training loss: 2.1926722526550293
Validation loss: 1.9797415758973809

Epoch: 5| Step: 3
Training loss: 2.3732175827026367
Validation loss: 1.9791596858732161

Epoch: 5| Step: 4
Training loss: 2.3398478031158447
Validation loss: 2.0453939104592926

Epoch: 5| Step: 5
Training loss: 1.6081864833831787
Validation loss: 2.0459700156283636

Epoch: 5| Step: 6
Training loss: 2.406613349914551
Validation loss: 2.0476253468503236

Epoch: 5| Step: 7
Training loss: 1.9944556951522827
Validation loss: 1.9749972128099011

Epoch: 5| Step: 8
Training loss: 1.3076766729354858
Validation loss: 1.9523025648568266

Epoch: 5| Step: 9
Training loss: 2.499950647354126
Validation loss: 1.943847599849906

Epoch: 5| Step: 10
Training loss: 1.9420506954193115
Validation loss: 1.9366108473911081

Epoch: 168| Step: 0
Training loss: 1.9219245910644531
Validation loss: 1.9309774214221584

Epoch: 5| Step: 1
Training loss: 2.5661532878875732
Validation loss: 1.9341227162268855

Epoch: 5| Step: 2
Training loss: 1.4549535512924194
Validation loss: 1.9364438608128538

Epoch: 5| Step: 3
Training loss: 2.0438380241394043
Validation loss: 1.936342893108245

Epoch: 5| Step: 4
Training loss: 2.457301616668701
Validation loss: 1.930817843765341

Epoch: 5| Step: 5
Training loss: 2.3047478199005127
Validation loss: 1.9265013612726682

Epoch: 5| Step: 6
Training loss: 2.0320184230804443
Validation loss: 1.9386586809671054

Epoch: 5| Step: 7
Training loss: 2.3895530700683594
Validation loss: 1.9355122761059833

Epoch: 5| Step: 8
Training loss: 1.9163105487823486
Validation loss: 1.929802902283207

Epoch: 5| Step: 9
Training loss: 2.0267438888549805
Validation loss: 1.9327716340300858

Epoch: 5| Step: 10
Training loss: 1.5464197397232056
Validation loss: 1.9425672151709115

Epoch: 169| Step: 0
Training loss: 2.076434373855591
Validation loss: 1.9374449176173056

Epoch: 5| Step: 1
Training loss: 1.8638114929199219
Validation loss: 1.9600737851153138

Epoch: 5| Step: 2
Training loss: 1.952123999595642
Validation loss: 1.9850479505395378

Epoch: 5| Step: 3
Training loss: 2.1670899391174316
Validation loss: 2.018718313145381

Epoch: 5| Step: 4
Training loss: 2.1208643913269043
Validation loss: 2.0921857536479993

Epoch: 5| Step: 5
Training loss: 2.073669672012329
Validation loss: 2.1396871946191274

Epoch: 5| Step: 6
Training loss: 2.5898373126983643
Validation loss: 2.1917636368864324

Epoch: 5| Step: 7
Training loss: 1.5959810018539429
Validation loss: 2.155655248190767

Epoch: 5| Step: 8
Training loss: 2.7850840091705322
Validation loss: 2.069035913354607

Epoch: 5| Step: 9
Training loss: 1.6251211166381836
Validation loss: 2.0039113631812473

Epoch: 5| Step: 10
Training loss: 2.4449639320373535
Validation loss: 1.9771969908027238

Epoch: 170| Step: 0
Training loss: 2.4285614490509033
Validation loss: 1.9775172638636764

Epoch: 5| Step: 1
Training loss: 1.8008960485458374
Validation loss: 1.9648377856900614

Epoch: 5| Step: 2
Training loss: 2.427304744720459
Validation loss: 1.94553154899228

Epoch: 5| Step: 3
Training loss: 2.291858196258545
Validation loss: 1.9269417588428785

Epoch: 5| Step: 4
Training loss: 2.0856924057006836
Validation loss: 1.9133991297855173

Epoch: 5| Step: 5
Training loss: 1.181769609451294
Validation loss: 1.9089466961481238

Epoch: 5| Step: 6
Training loss: 1.404529333114624
Validation loss: 1.92227053770455

Epoch: 5| Step: 7
Training loss: 2.087355136871338
Validation loss: 1.938502747525451

Epoch: 5| Step: 8
Training loss: 2.1259520053863525
Validation loss: 1.9497421710721907

Epoch: 5| Step: 9
Training loss: 2.3804993629455566
Validation loss: 1.9441071402642034

Epoch: 5| Step: 10
Training loss: 3.0692319869995117
Validation loss: 1.9381954080315047

Epoch: 171| Step: 0
Training loss: 2.165468215942383
Validation loss: 1.9419379362495996

Epoch: 5| Step: 1
Training loss: 1.6145902872085571
Validation loss: 1.9333404699961345

Epoch: 5| Step: 2
Training loss: 1.9797124862670898
Validation loss: 1.9502640783145864

Epoch: 5| Step: 3
Training loss: 2.176258087158203
Validation loss: 1.9556661459707445

Epoch: 5| Step: 4
Training loss: 1.9502776861190796
Validation loss: 1.9415177952858709

Epoch: 5| Step: 5
Training loss: 2.07600998878479
Validation loss: 1.95720475463457

Epoch: 5| Step: 6
Training loss: 2.251335859298706
Validation loss: 1.9543519814809163

Epoch: 5| Step: 7
Training loss: 2.0487563610076904
Validation loss: 1.9821483537714968

Epoch: 5| Step: 8
Training loss: 2.3594777584075928
Validation loss: 1.9709242184956868

Epoch: 5| Step: 9
Training loss: 2.2244677543640137
Validation loss: 2.0712299141832577

Epoch: 5| Step: 10
Training loss: 2.1855874061584473
Validation loss: 2.16658983051136

Epoch: 172| Step: 0
Training loss: 1.996198058128357
Validation loss: 2.2078694348694174

Epoch: 5| Step: 1
Training loss: 1.8398373126983643
Validation loss: 2.187989996325585

Epoch: 5| Step: 2
Training loss: 2.277008295059204
Validation loss: 2.14331494480051

Epoch: 5| Step: 3
Training loss: 1.889108657836914
Validation loss: 2.098054714100335

Epoch: 5| Step: 4
Training loss: 2.264127016067505
Validation loss: 2.0972504949056976

Epoch: 5| Step: 5
Training loss: 2.0257439613342285
Validation loss: 2.0695793218510126

Epoch: 5| Step: 6
Training loss: 2.163104295730591
Validation loss: 2.0170804531343522

Epoch: 5| Step: 7
Training loss: 2.751099109649658
Validation loss: 1.9892272500581638

Epoch: 5| Step: 8
Training loss: 2.166733980178833
Validation loss: 1.9496780031470842

Epoch: 5| Step: 9
Training loss: 2.0809645652770996
Validation loss: 1.9396257810695197

Epoch: 5| Step: 10
Training loss: 1.6387786865234375
Validation loss: 1.9222855132113221

Epoch: 173| Step: 0
Training loss: 2.238179922103882
Validation loss: 1.9370014705965597

Epoch: 5| Step: 1
Training loss: 2.6626219749450684
Validation loss: 1.9476727798420896

Epoch: 5| Step: 2
Training loss: 2.154560089111328
Validation loss: 1.9849997489683089

Epoch: 5| Step: 3
Training loss: 2.1463918685913086
Validation loss: 2.0197996772745603

Epoch: 5| Step: 4
Training loss: 2.290473461151123
Validation loss: 2.0207477525998185

Epoch: 5| Step: 5
Training loss: 1.6714756488800049
Validation loss: 2.0169607439348773

Epoch: 5| Step: 6
Training loss: 2.464444637298584
Validation loss: 1.9761085253889843

Epoch: 5| Step: 7
Training loss: 1.3392374515533447
Validation loss: 1.9249969682385843

Epoch: 5| Step: 8
Training loss: 2.2075042724609375
Validation loss: 1.9324240376872401

Epoch: 5| Step: 9
Training loss: 1.8232231140136719
Validation loss: 1.949814445228987

Epoch: 5| Step: 10
Training loss: 1.8483011722564697
Validation loss: 1.9741693145485335

Epoch: 174| Step: 0
Training loss: 1.888448715209961
Validation loss: 1.9801852190366356

Epoch: 5| Step: 1
Training loss: 1.6654037237167358
Validation loss: 1.9782363201982232

Epoch: 5| Step: 2
Training loss: 2.314791440963745
Validation loss: 1.9880055573678785

Epoch: 5| Step: 3
Training loss: 2.2846519947052
Validation loss: 1.9803186180771037

Epoch: 5| Step: 4
Training loss: 1.9259083271026611
Validation loss: 1.986293537642366

Epoch: 5| Step: 5
Training loss: 2.202057361602783
Validation loss: 1.999599556769094

Epoch: 5| Step: 6
Training loss: 1.9893985986709595
Validation loss: 2.0237406940870386

Epoch: 5| Step: 7
Training loss: 2.0403552055358887
Validation loss: 2.0650947593873545

Epoch: 5| Step: 8
Training loss: 2.2271955013275146
Validation loss: 2.157514697761946

Epoch: 5| Step: 9
Training loss: 2.514941453933716
Validation loss: 2.1481383487742436

Epoch: 5| Step: 10
Training loss: 1.7433773279190063
Validation loss: 2.0612141342573267

Epoch: 175| Step: 0
Training loss: 2.534869432449341
Validation loss: 1.9909649792537893

Epoch: 5| Step: 1
Training loss: 1.7944694757461548
Validation loss: 1.954713236901068

Epoch: 5| Step: 2
Training loss: 2.227475643157959
Validation loss: 1.9413169507057435

Epoch: 5| Step: 3
Training loss: 2.3734312057495117
Validation loss: 1.9365969806589105

Epoch: 5| Step: 4
Training loss: 1.7700316905975342
Validation loss: 1.9333630402882893

Epoch: 5| Step: 5
Training loss: 1.8477318286895752
Validation loss: 1.9289901128379248

Epoch: 5| Step: 6
Training loss: 1.3669054508209229
Validation loss: 1.9357163072914205

Epoch: 5| Step: 7
Training loss: 2.1016197204589844
Validation loss: 1.944487020533572

Epoch: 5| Step: 8
Training loss: 2.3116023540496826
Validation loss: 1.9381262269071353

Epoch: 5| Step: 9
Training loss: 2.4407615661621094
Validation loss: 1.9324936225850096

Epoch: 5| Step: 10
Training loss: 1.9189996719360352
Validation loss: 1.9259326022158387

Epoch: 176| Step: 0
Training loss: 1.9731976985931396
Validation loss: 1.9240432580312092

Epoch: 5| Step: 1
Training loss: 2.315156936645508
Validation loss: 1.9277111432885612

Epoch: 5| Step: 2
Training loss: 2.8402090072631836
Validation loss: 1.9309041641091789

Epoch: 5| Step: 3
Training loss: 2.2432594299316406
Validation loss: 1.9414807724696335

Epoch: 5| Step: 4
Training loss: 1.637529730796814
Validation loss: 1.959025513741278

Epoch: 5| Step: 5
Training loss: 2.3306140899658203
Validation loss: 1.9897680744048087

Epoch: 5| Step: 6
Training loss: 1.5113592147827148
Validation loss: 1.994316852220925

Epoch: 5| Step: 7
Training loss: 1.6533849239349365
Validation loss: 2.0100486201624714

Epoch: 5| Step: 8
Training loss: 1.6232831478118896
Validation loss: 2.051388668757613

Epoch: 5| Step: 9
Training loss: 2.6406731605529785
Validation loss: 2.0543121535290956

Epoch: 5| Step: 10
Training loss: 2.1827967166900635
Validation loss: 2.036540860770851

Epoch: 177| Step: 0
Training loss: 2.298576831817627
Validation loss: 2.0019825684126986

Epoch: 5| Step: 1
Training loss: 2.3649237155914307
Validation loss: 1.9971605193230413

Epoch: 5| Step: 2
Training loss: 2.043339490890503
Validation loss: 1.993990421295166

Epoch: 5| Step: 3
Training loss: 2.516448497772217
Validation loss: 1.9925141872898224

Epoch: 5| Step: 4
Training loss: 1.5779858827590942
Validation loss: 1.986615675751881

Epoch: 5| Step: 5
Training loss: 1.6953471899032593
Validation loss: 1.9855591968823505

Epoch: 5| Step: 6
Training loss: 1.8642654418945312
Validation loss: 1.991378334260756

Epoch: 5| Step: 7
Training loss: 1.6633580923080444
Validation loss: 1.9788881450571039

Epoch: 5| Step: 8
Training loss: 1.8423430919647217
Validation loss: 2.002362798619014

Epoch: 5| Step: 9
Training loss: 2.5773425102233887
Validation loss: 1.996923723528462

Epoch: 5| Step: 10
Training loss: 1.913159966468811
Validation loss: 2.0038938112156366

Epoch: 178| Step: 0
Training loss: 1.8740828037261963
Validation loss: 1.9900024257680422

Epoch: 5| Step: 1
Training loss: 1.9645023345947266
Validation loss: 2.0162362411458004

Epoch: 5| Step: 2
Training loss: 2.1216351985931396
Validation loss: 2.0338961975548857

Epoch: 5| Step: 3
Training loss: 1.804137945175171
Validation loss: 2.045818087875202

Epoch: 5| Step: 4
Training loss: 2.5844149589538574
Validation loss: 2.0589642755446897

Epoch: 5| Step: 5
Training loss: 1.8602577447891235
Validation loss: 2.021327726302608

Epoch: 5| Step: 6
Training loss: 2.2312746047973633
Validation loss: 1.9798227138416742

Epoch: 5| Step: 7
Training loss: 1.9475017786026
Validation loss: 1.9572716707824378

Epoch: 5| Step: 8
Training loss: 1.4946353435516357
Validation loss: 1.9768246322549798

Epoch: 5| Step: 9
Training loss: 1.941748857498169
Validation loss: 1.9706184723043954

Epoch: 5| Step: 10
Training loss: 2.607208728790283
Validation loss: 1.9829216516146095

Epoch: 179| Step: 0
Training loss: 2.2771923542022705
Validation loss: 1.9743039761820147

Epoch: 5| Step: 1
Training loss: 1.9023936986923218
Validation loss: 1.9822989381769651

Epoch: 5| Step: 2
Training loss: 2.2806787490844727
Validation loss: 1.9963836900649532

Epoch: 5| Step: 3
Training loss: 2.039884328842163
Validation loss: 1.9985938097840996

Epoch: 5| Step: 4
Training loss: 1.7264655828475952
Validation loss: 2.043341718694215

Epoch: 5| Step: 5
Training loss: 2.1372478008270264
Validation loss: 2.091526381431087

Epoch: 5| Step: 6
Training loss: 2.2071266174316406
Validation loss: 2.0850386593931463

Epoch: 5| Step: 7
Training loss: 1.743903398513794
Validation loss: 2.0694212118784585

Epoch: 5| Step: 8
Training loss: 2.0242760181427
Validation loss: 2.0027788608304915

Epoch: 5| Step: 9
Training loss: 1.9486215114593506
Validation loss: 2.000332873354676

Epoch: 5| Step: 10
Training loss: 2.2023165225982666
Validation loss: 1.9964711589197959

Epoch: 180| Step: 0
Training loss: 1.8817293643951416
Validation loss: 2.0220242213177424

Epoch: 5| Step: 1
Training loss: 1.952925682067871
Validation loss: 2.028593140263711

Epoch: 5| Step: 2
Training loss: 2.2295331954956055
Validation loss: 2.029780564769622

Epoch: 5| Step: 3
Training loss: 2.5945098400115967
Validation loss: 2.0238156805756273

Epoch: 5| Step: 4
Training loss: 2.436427354812622
Validation loss: 1.9932044885491813

Epoch: 5| Step: 5
Training loss: 2.298766851425171
Validation loss: 1.9694770561751498

Epoch: 5| Step: 6
Training loss: 1.4152370691299438
Validation loss: 1.9609154680723786

Epoch: 5| Step: 7
Training loss: 2.3165905475616455
Validation loss: 1.9424548636200607

Epoch: 5| Step: 8
Training loss: 1.961316466331482
Validation loss: 1.9422616227980583

Epoch: 5| Step: 9
Training loss: 2.3052430152893066
Validation loss: 1.9631074449067474

Epoch: 5| Step: 10
Training loss: 1.5659410953521729
Validation loss: 1.9931954337704567

Epoch: 181| Step: 0
Training loss: 2.322885036468506
Validation loss: 2.0272778439265426

Epoch: 5| Step: 1
Training loss: 2.0544228553771973
Validation loss: 2.0671403074777253

Epoch: 5| Step: 2
Training loss: 2.072293758392334
Validation loss: 2.0798992572292203

Epoch: 5| Step: 3
Training loss: 1.8627475500106812
Validation loss: 2.0677068694945304

Epoch: 5| Step: 4
Training loss: 2.3146815299987793
Validation loss: 2.0384516728821622

Epoch: 5| Step: 5
Training loss: 2.450657606124878
Validation loss: 2.0200370332246185

Epoch: 5| Step: 6
Training loss: 2.3648250102996826
Validation loss: 2.0220977619130123

Epoch: 5| Step: 7
Training loss: 1.4280667304992676
Validation loss: 2.034266796163333

Epoch: 5| Step: 8
Training loss: 2.2031257152557373
Validation loss: 2.040593900988179

Epoch: 5| Step: 9
Training loss: 1.5946223735809326
Validation loss: 2.0291812599346204

Epoch: 5| Step: 10
Training loss: 1.7271631956100464
Validation loss: 2.020511475942468

Epoch: 182| Step: 0
Training loss: 2.194746732711792
Validation loss: 2.0176044253892798

Epoch: 5| Step: 1
Training loss: 2.669386148452759
Validation loss: 2.0158938028479136

Epoch: 5| Step: 2
Training loss: 2.129945755004883
Validation loss: 2.007947693588913

Epoch: 5| Step: 3
Training loss: 2.0556342601776123
Validation loss: 2.022543402128322

Epoch: 5| Step: 4
Training loss: 1.7476928234100342
Validation loss: 2.0606722908635295

Epoch: 5| Step: 5
Training loss: 2.1291584968566895
Validation loss: 2.0385342515924925

Epoch: 5| Step: 6
Training loss: 1.3201406002044678
Validation loss: 2.043885225890785

Epoch: 5| Step: 7
Training loss: 1.9423195123672485
Validation loss: 2.0390446442429737

Epoch: 5| Step: 8
Training loss: 2.137047052383423
Validation loss: 2.015751019600899

Epoch: 5| Step: 9
Training loss: 1.7417528629302979
Validation loss: 1.9875593159788398

Epoch: 5| Step: 10
Training loss: 2.216463088989258
Validation loss: 1.9950160313678045

Epoch: 183| Step: 0
Training loss: 1.3623409271240234
Validation loss: 2.0044308413741407

Epoch: 5| Step: 1
Training loss: 1.77484130859375
Validation loss: 2.0343514719317035

Epoch: 5| Step: 2
Training loss: 1.6417713165283203
Validation loss: 2.051494265115389

Epoch: 5| Step: 3
Training loss: 2.0288496017456055
Validation loss: 2.0659150205632693

Epoch: 5| Step: 4
Training loss: 2.3675596714019775
Validation loss: 2.1035502136394544

Epoch: 5| Step: 5
Training loss: 2.3753457069396973
Validation loss: 2.0937520355306645

Epoch: 5| Step: 6
Training loss: 1.734541654586792
Validation loss: 2.085991205707673

Epoch: 5| Step: 7
Training loss: 1.8480117321014404
Validation loss: 2.0650449914316975

Epoch: 5| Step: 8
Training loss: 2.5379245281219482
Validation loss: 2.019470525044267

Epoch: 5| Step: 9
Training loss: 2.076874256134033
Validation loss: 2.0018252352232575

Epoch: 5| Step: 10
Training loss: 2.070481538772583
Validation loss: 1.9811702582143969

Epoch: 184| Step: 0
Training loss: 1.3752506971359253
Validation loss: 1.964199266126079

Epoch: 5| Step: 1
Training loss: 1.6806621551513672
Validation loss: 1.9770599257561468

Epoch: 5| Step: 2
Training loss: 1.9998836517333984
Validation loss: 1.967432386131697

Epoch: 5| Step: 3
Training loss: 3.216068983078003
Validation loss: 1.9528075751437937

Epoch: 5| Step: 4
Training loss: 1.772243857383728
Validation loss: 1.9622896589258665

Epoch: 5| Step: 5
Training loss: 2.1218810081481934
Validation loss: 1.953428372260063

Epoch: 5| Step: 6
Training loss: 1.415890097618103
Validation loss: 1.9429019933105798

Epoch: 5| Step: 7
Training loss: 2.2213644981384277
Validation loss: 1.9441361683671192

Epoch: 5| Step: 8
Training loss: 1.8322923183441162
Validation loss: 1.9402278802728141

Epoch: 5| Step: 9
Training loss: 2.2693405151367188
Validation loss: 1.9522629014907344

Epoch: 5| Step: 10
Training loss: 2.4087347984313965
Validation loss: 1.962658905213879

Epoch: 185| Step: 0
Training loss: 1.8965480327606201
Validation loss: 1.9643395203416065

Epoch: 5| Step: 1
Training loss: 2.214845657348633
Validation loss: 1.9840523786442255

Epoch: 5| Step: 2
Training loss: 1.9953062534332275
Validation loss: 2.0143441923203005

Epoch: 5| Step: 3
Training loss: 2.7909951210021973
Validation loss: 2.0419201248435566

Epoch: 5| Step: 4
Training loss: 1.8312180042266846
Validation loss: 2.04380323297234

Epoch: 5| Step: 5
Training loss: 2.474374771118164
Validation loss: 2.0873145800764843

Epoch: 5| Step: 6
Training loss: 1.8221687078475952
Validation loss: 2.1126850753702144

Epoch: 5| Step: 7
Training loss: 1.6015288829803467
Validation loss: 2.1222745680039927

Epoch: 5| Step: 8
Training loss: 1.7044715881347656
Validation loss: 2.0881314880104473

Epoch: 5| Step: 9
Training loss: 1.708795189857483
Validation loss: 2.0585226038450837

Epoch: 5| Step: 10
Training loss: 1.825060486793518
Validation loss: 2.0125927861018846

Epoch: 186| Step: 0
Training loss: 2.081242799758911
Validation loss: 1.9883684394180134

Epoch: 5| Step: 1
Training loss: 2.1268999576568604
Validation loss: 1.9836171673190208

Epoch: 5| Step: 2
Training loss: 1.8454253673553467
Validation loss: 1.9685774503215667

Epoch: 5| Step: 3
Training loss: 1.6417007446289062
Validation loss: 1.9648919131166191

Epoch: 5| Step: 4
Training loss: 1.6622021198272705
Validation loss: 1.948363870702764

Epoch: 5| Step: 5
Training loss: 2.0038270950317383
Validation loss: 1.9479553353401922

Epoch: 5| Step: 6
Training loss: 2.6378724575042725
Validation loss: 1.9925810675467215

Epoch: 5| Step: 7
Training loss: 2.0442793369293213
Validation loss: 2.0328768286653744

Epoch: 5| Step: 8
Training loss: 1.7573179006576538
Validation loss: 2.1045699017022246

Epoch: 5| Step: 9
Training loss: 2.984182834625244
Validation loss: 2.18581477544641

Epoch: 5| Step: 10
Training loss: 1.5231993198394775
Validation loss: 2.1670730037073933

Epoch: 187| Step: 0
Training loss: 2.35463285446167
Validation loss: 2.0525130571857577

Epoch: 5| Step: 1
Training loss: 2.3318943977355957
Validation loss: 2.0118230517192552

Epoch: 5| Step: 2
Training loss: 2.0481460094451904
Validation loss: 2.0006523311779065

Epoch: 5| Step: 3
Training loss: 2.0781185626983643
Validation loss: 2.0130759926252466

Epoch: 5| Step: 4
Training loss: 2.4636380672454834
Validation loss: 2.023272342579339

Epoch: 5| Step: 5
Training loss: 1.6263773441314697
Validation loss: 2.008948369692731

Epoch: 5| Step: 6
Training loss: 1.854711890220642
Validation loss: 1.9867068080491916

Epoch: 5| Step: 7
Training loss: 1.6610593795776367
Validation loss: 1.9841933865700998

Epoch: 5| Step: 8
Training loss: 2.091862201690674
Validation loss: 2.0033758994071715

Epoch: 5| Step: 9
Training loss: 1.284271001815796
Validation loss: 2.0334865675177625

Epoch: 5| Step: 10
Training loss: 2.0497899055480957
Validation loss: 2.049050851534772

Epoch: 188| Step: 0
Training loss: 2.361924171447754
Validation loss: 2.1019868722525974

Epoch: 5| Step: 1
Training loss: 2.10374116897583
Validation loss: 2.099579385531846

Epoch: 5| Step: 2
Training loss: 2.15154767036438
Validation loss: 2.0725975087893906

Epoch: 5| Step: 3
Training loss: 2.2011523246765137
Validation loss: 2.062559199589555

Epoch: 5| Step: 4
Training loss: 2.0275468826293945
Validation loss: 2.0196502836801673

Epoch: 5| Step: 5
Training loss: 1.7549381256103516
Validation loss: 1.9964170481569024

Epoch: 5| Step: 6
Training loss: 2.252573013305664
Validation loss: 1.9480342916263047

Epoch: 5| Step: 7
Training loss: 2.220432758331299
Validation loss: 1.9235214469253377

Epoch: 5| Step: 8
Training loss: 1.9755386114120483
Validation loss: 1.9324106029284898

Epoch: 5| Step: 9
Training loss: 1.3588076829910278
Validation loss: 1.9328743437285065

Epoch: 5| Step: 10
Training loss: 1.6277847290039062
Validation loss: 1.9307291533357354

Epoch: 189| Step: 0
Training loss: 1.6651484966278076
Validation loss: 1.9373135771802676

Epoch: 5| Step: 1
Training loss: 1.9986778497695923
Validation loss: 1.9478964421056932

Epoch: 5| Step: 2
Training loss: 2.2400107383728027
Validation loss: 1.9552988108768259

Epoch: 5| Step: 3
Training loss: 1.736498475074768
Validation loss: 1.9763057283175889

Epoch: 5| Step: 4
Training loss: 1.9738794565200806
Validation loss: 1.9929382839510519

Epoch: 5| Step: 5
Training loss: 1.6964651346206665
Validation loss: 2.0087826021255983

Epoch: 5| Step: 6
Training loss: 1.8587623834609985
Validation loss: 2.041656530031594

Epoch: 5| Step: 7
Training loss: 2.102322816848755
Validation loss: 2.100011969125399

Epoch: 5| Step: 8
Training loss: 1.8262670040130615
Validation loss: 2.2121938531116774

Epoch: 5| Step: 9
Training loss: 2.630502223968506
Validation loss: 2.2516380715113815

Epoch: 5| Step: 10
Training loss: 2.3015997409820557
Validation loss: 2.181412091819189

Epoch: 190| Step: 0
Training loss: 1.6605154275894165
Validation loss: 2.08223194460715

Epoch: 5| Step: 1
Training loss: 2.151848316192627
Validation loss: 2.028186196921974

Epoch: 5| Step: 2
Training loss: 1.568963646888733
Validation loss: 1.992889811915736

Epoch: 5| Step: 3
Training loss: 2.884860038757324
Validation loss: 1.9795001168404855

Epoch: 5| Step: 4
Training loss: 2.680652618408203
Validation loss: 1.963221908897482

Epoch: 5| Step: 5
Training loss: 2.0505547523498535
Validation loss: 1.9747632677837084

Epoch: 5| Step: 6
Training loss: 2.3252036571502686
Validation loss: 1.9699522474760651

Epoch: 5| Step: 7
Training loss: 1.3419444561004639
Validation loss: 1.9751217621628956

Epoch: 5| Step: 8
Training loss: 1.874132513999939
Validation loss: 1.9659668232804985

Epoch: 5| Step: 9
Training loss: 0.9990119934082031
Validation loss: 1.9572901623223418

Epoch: 5| Step: 10
Training loss: 2.425849199295044
Validation loss: 1.9581400784113074

Epoch: 191| Step: 0
Training loss: 2.2001426219940186
Validation loss: 1.9657980626629246

Epoch: 5| Step: 1
Training loss: 2.016806125640869
Validation loss: 1.9777004757235128

Epoch: 5| Step: 2
Training loss: 1.9208590984344482
Validation loss: 1.9915908664785407

Epoch: 5| Step: 3
Training loss: 2.2376136779785156
Validation loss: 2.0040394157491703

Epoch: 5| Step: 4
Training loss: 1.891240119934082
Validation loss: 2.030699424846198

Epoch: 5| Step: 5
Training loss: 2.0622963905334473
Validation loss: 2.0498918038542553

Epoch: 5| Step: 6
Training loss: 1.9392549991607666
Validation loss: 2.040813466554047

Epoch: 5| Step: 7
Training loss: 1.8798243999481201
Validation loss: 2.0244032054819088

Epoch: 5| Step: 8
Training loss: 2.072719097137451
Validation loss: 2.0357263216408352

Epoch: 5| Step: 9
Training loss: 1.6963354349136353
Validation loss: 2.0258870893909084

Epoch: 5| Step: 10
Training loss: 1.4877867698669434
Validation loss: 1.9860865428883543

Epoch: 192| Step: 0
Training loss: 2.1056857109069824
Validation loss: 1.9916161311570035

Epoch: 5| Step: 1
Training loss: 2.195298433303833
Validation loss: 1.9761418847627537

Epoch: 5| Step: 2
Training loss: 2.363524913787842
Validation loss: 2.0053769542324926

Epoch: 5| Step: 3
Training loss: 1.8665227890014648
Validation loss: 2.016871313894949

Epoch: 5| Step: 4
Training loss: 1.763596534729004
Validation loss: 2.0446576354324177

Epoch: 5| Step: 5
Training loss: 1.2155319452285767
Validation loss: 2.0961896424652426

Epoch: 5| Step: 6
Training loss: 2.3627774715423584
Validation loss: 2.1693798700968423

Epoch: 5| Step: 7
Training loss: 1.7990257740020752
Validation loss: 2.164629167126071

Epoch: 5| Step: 8
Training loss: 1.9042065143585205
Validation loss: 2.1039379232673237

Epoch: 5| Step: 9
Training loss: 1.8152964115142822
Validation loss: 2.0225644778179865

Epoch: 5| Step: 10
Training loss: 2.0187647342681885
Validation loss: 2.0003235904119347

Epoch: 193| Step: 0
Training loss: 1.1366244554519653
Validation loss: 1.9852369780181556

Epoch: 5| Step: 1
Training loss: 2.055924415588379
Validation loss: 1.973316446427376

Epoch: 5| Step: 2
Training loss: 1.8605703115463257
Validation loss: 1.9653315890219905

Epoch: 5| Step: 3
Training loss: 1.8112671375274658
Validation loss: 1.9638071778000041

Epoch: 5| Step: 4
Training loss: 1.8907392024993896
Validation loss: 1.9747206857127528

Epoch: 5| Step: 5
Training loss: 2.405831813812256
Validation loss: 1.9857113925359582

Epoch: 5| Step: 6
Training loss: 2.324664354324341
Validation loss: 2.004834213564473

Epoch: 5| Step: 7
Training loss: 1.562515377998352
Validation loss: 2.0039741172585437

Epoch: 5| Step: 8
Training loss: 2.747920513153076
Validation loss: 2.003217404888522

Epoch: 5| Step: 9
Training loss: 2.0434365272521973
Validation loss: 2.0113690437809115

Epoch: 5| Step: 10
Training loss: 1.7348649501800537
Validation loss: 2.0096778843992498

Epoch: 194| Step: 0
Training loss: 1.6345961093902588
Validation loss: 2.000968915159984

Epoch: 5| Step: 1
Training loss: 1.8557536602020264
Validation loss: 1.9922893483151671

Epoch: 5| Step: 2
Training loss: 2.4426429271698
Validation loss: 1.9967604298745432

Epoch: 5| Step: 3
Training loss: 1.2626205682754517
Validation loss: 1.984319794562555

Epoch: 5| Step: 4
Training loss: 2.322608709335327
Validation loss: 1.980875345968431

Epoch: 5| Step: 5
Training loss: 1.7666813135147095
Validation loss: 1.9717413815118934

Epoch: 5| Step: 6
Training loss: 2.3084914684295654
Validation loss: 1.9623597796245287

Epoch: 5| Step: 7
Training loss: 2.476226806640625
Validation loss: 1.9655047642287387

Epoch: 5| Step: 8
Training loss: 2.4201226234436035
Validation loss: 1.9559629322380148

Epoch: 5| Step: 9
Training loss: 1.7322165966033936
Validation loss: 1.9477891422087146

Epoch: 5| Step: 10
Training loss: 1.1517573595046997
Validation loss: 1.9676157761645574

Epoch: 195| Step: 0
Training loss: 1.8627742528915405
Validation loss: 1.9834020753060617

Epoch: 5| Step: 1
Training loss: 2.03595232963562
Validation loss: 1.9959043174661615

Epoch: 5| Step: 2
Training loss: 2.17710280418396
Validation loss: 2.0195349800971245

Epoch: 5| Step: 3
Training loss: 1.9108705520629883
Validation loss: 2.028005069301974

Epoch: 5| Step: 4
Training loss: 2.1823549270629883
Validation loss: 2.0409311222773727

Epoch: 5| Step: 5
Training loss: 1.8537746667861938
Validation loss: 2.0402896647812216

Epoch: 5| Step: 6
Training loss: 1.3434464931488037
Validation loss: 2.0373563228114957

Epoch: 5| Step: 7
Training loss: 1.8413441181182861
Validation loss: 2.0152150302804928

Epoch: 5| Step: 8
Training loss: 1.794593095779419
Validation loss: 2.0044791801001436

Epoch: 5| Step: 9
Training loss: 2.382455348968506
Validation loss: 2.0194950026850544

Epoch: 5| Step: 10
Training loss: 1.5511436462402344
Validation loss: 2.009356898646201

Epoch: 196| Step: 0
Training loss: 1.4849909543991089
Validation loss: 1.9989528963642735

Epoch: 5| Step: 1
Training loss: 1.9863990545272827
Validation loss: 2.0023936122976322

Epoch: 5| Step: 2
Training loss: 2.173544406890869
Validation loss: 1.970207514301423

Epoch: 5| Step: 3
Training loss: 1.967163324356079
Validation loss: 1.9814148179946407

Epoch: 5| Step: 4
Training loss: 1.6906585693359375
Validation loss: 1.9749522042530838

Epoch: 5| Step: 5
Training loss: 2.1064047813415527
Validation loss: 1.980535203410733

Epoch: 5| Step: 6
Training loss: 1.9100313186645508
Validation loss: 2.0183096162734495

Epoch: 5| Step: 7
Training loss: 2.1751549243927
Validation loss: 2.020151379287884

Epoch: 5| Step: 8
Training loss: 1.6250633001327515
Validation loss: 2.0051917529875234

Epoch: 5| Step: 9
Training loss: 1.8034340143203735
Validation loss: 1.9854452071651336

Epoch: 5| Step: 10
Training loss: 1.7750990390777588
Validation loss: 1.989493695638513

Epoch: 197| Step: 0
Training loss: 1.5791000127792358
Validation loss: 1.9863964716593425

Epoch: 5| Step: 1
Training loss: 2.007796049118042
Validation loss: 1.9807705212664861

Epoch: 5| Step: 2
Training loss: 2.491823673248291
Validation loss: 1.9736384422548356

Epoch: 5| Step: 3
Training loss: 1.3917427062988281
Validation loss: 1.9815887815208846

Epoch: 5| Step: 4
Training loss: 1.9884570837020874
Validation loss: 1.979584627254035

Epoch: 5| Step: 5
Training loss: 1.9830944538116455
Validation loss: 1.9787455656195199

Epoch: 5| Step: 6
Training loss: 1.4480350017547607
Validation loss: 2.000383238638601

Epoch: 5| Step: 7
Training loss: 1.8742258548736572
Validation loss: 2.0160442885532173

Epoch: 5| Step: 8
Training loss: 1.6429336071014404
Validation loss: 2.006899333769275

Epoch: 5| Step: 9
Training loss: 2.125537157058716
Validation loss: 2.0327199582130677

Epoch: 5| Step: 10
Training loss: 1.8091827630996704
Validation loss: 2.060618910738217

Epoch: 198| Step: 0
Training loss: 1.9385398626327515
Validation loss: 2.1387316911451277

Epoch: 5| Step: 1
Training loss: 1.8162472248077393
Validation loss: 2.1567950299991074

Epoch: 5| Step: 2
Training loss: 2.1603004932403564
Validation loss: 2.1539157564922045

Epoch: 5| Step: 3
Training loss: 2.311525821685791
Validation loss: 2.0801154285348873

Epoch: 5| Step: 4
Training loss: 2.1694934368133545
Validation loss: 2.034576109660569

Epoch: 5| Step: 5
Training loss: 1.4161487817764282
Validation loss: 1.9852369011089366

Epoch: 5| Step: 6
Training loss: 2.1803133487701416
Validation loss: 1.9522955763724543

Epoch: 5| Step: 7
Training loss: 1.8577381372451782
Validation loss: 1.9486492385146439

Epoch: 5| Step: 8
Training loss: 1.9748523235321045
Validation loss: 1.9418182629410938

Epoch: 5| Step: 9
Training loss: 1.7136796712875366
Validation loss: 1.9593420208141368

Epoch: 5| Step: 10
Training loss: 1.583970069885254
Validation loss: 1.948610113513085

Epoch: 199| Step: 0
Training loss: 1.7745651006698608
Validation loss: 1.9513302413366174

Epoch: 5| Step: 1
Training loss: 2.2377541065216064
Validation loss: 1.9638789956287672

Epoch: 5| Step: 2
Training loss: 1.8799883127212524
Validation loss: 1.9680329984234226

Epoch: 5| Step: 3
Training loss: 1.9909610748291016
Validation loss: 1.9919925748661

Epoch: 5| Step: 4
Training loss: 1.5473631620407104
Validation loss: 2.026858061872503

Epoch: 5| Step: 5
Training loss: 1.8285024166107178
Validation loss: 2.053139084128923

Epoch: 5| Step: 6
Training loss: 2.0697524547576904
Validation loss: 2.034992712800221

Epoch: 5| Step: 7
Training loss: 1.8796463012695312
Validation loss: 2.038577628392045

Epoch: 5| Step: 8
Training loss: 1.748671531677246
Validation loss: 2.0395579504710373

Epoch: 5| Step: 9
Training loss: 1.4492361545562744
Validation loss: 2.0496557643336635

Epoch: 5| Step: 10
Training loss: 2.1916675567626953
Validation loss: 2.0667277805266844

Epoch: 200| Step: 0
Training loss: 1.9789655208587646
Validation loss: 2.054141552217545

Epoch: 5| Step: 1
Training loss: 2.6467580795288086
Validation loss: 2.064944919719491

Epoch: 5| Step: 2
Training loss: 1.4167293310165405
Validation loss: 2.0488333189359276

Epoch: 5| Step: 3
Training loss: 2.0796351432800293
Validation loss: 2.0397274827444427

Epoch: 5| Step: 4
Training loss: 1.7208963632583618
Validation loss: 2.070443671236756

Epoch: 5| Step: 5
Training loss: 2.177924394607544
Validation loss: 2.053996926994734

Epoch: 5| Step: 6
Training loss: 2.70306134223938
Validation loss: 2.078539122817337

Epoch: 5| Step: 7
Training loss: 1.561476469039917
Validation loss: 2.070979905384843

Epoch: 5| Step: 8
Training loss: 1.5676349401474
Validation loss: 1.9928488449383808

Epoch: 5| Step: 9
Training loss: 1.4698044061660767
Validation loss: 1.969703068015396

Epoch: 5| Step: 10
Training loss: 0.937599778175354
Validation loss: 1.9752482329645464

Epoch: 201| Step: 0
Training loss: 1.833512544631958
Validation loss: 1.9943574333703646

Epoch: 5| Step: 1
Training loss: 1.7644857168197632
Validation loss: 1.9887842427017868

Epoch: 5| Step: 2
Training loss: 1.4789925813674927
Validation loss: 1.9917444336798884

Epoch: 5| Step: 3
Training loss: 2.2894506454467773
Validation loss: 2.0220171174695416

Epoch: 5| Step: 4
Training loss: 1.8670217990875244
Validation loss: 2.0674659359839653

Epoch: 5| Step: 5
Training loss: 1.6683166027069092
Validation loss: 2.096282528292748

Epoch: 5| Step: 6
Training loss: 2.6183416843414307
Validation loss: 2.0948846160724597

Epoch: 5| Step: 7
Training loss: 1.3697577714920044
Validation loss: 2.084628184636434

Epoch: 5| Step: 8
Training loss: 1.7571109533309937
Validation loss: 2.052512626494131

Epoch: 5| Step: 9
Training loss: 1.8310238122940063
Validation loss: 2.0050448384336246

Epoch: 5| Step: 10
Training loss: 1.8741356134414673
Validation loss: 1.9952596515737555

Epoch: 202| Step: 0
Training loss: 1.937856912612915
Validation loss: 1.9986186078799668

Epoch: 5| Step: 1
Training loss: 2.2047038078308105
Validation loss: 1.9875668428277458

Epoch: 5| Step: 2
Training loss: 1.5521117448806763
Validation loss: 1.9749759909927205

Epoch: 5| Step: 3
Training loss: 2.1912853717803955
Validation loss: 1.9611061375628236

Epoch: 5| Step: 4
Training loss: 1.4976236820220947
Validation loss: 1.9800119041114725

Epoch: 5| Step: 5
Training loss: 1.8582594394683838
Validation loss: 1.9842514889214629

Epoch: 5| Step: 6
Training loss: 1.7479228973388672
Validation loss: 1.9914820424972042

Epoch: 5| Step: 7
Training loss: 2.0539073944091797
Validation loss: 2.011140528545585

Epoch: 5| Step: 8
Training loss: 2.3363590240478516
Validation loss: 2.0127752929605465

Epoch: 5| Step: 9
Training loss: 1.7655757665634155
Validation loss: 2.017399100847142

Epoch: 5| Step: 10
Training loss: 1.058462142944336
Validation loss: 1.994774753047574

Epoch: 203| Step: 0
Training loss: 1.9309022426605225
Validation loss: 1.9836466312408447

Epoch: 5| Step: 1
Training loss: 1.754725694656372
Validation loss: 1.972400455064671

Epoch: 5| Step: 2
Training loss: 1.6208837032318115
Validation loss: 1.9821543052632322

Epoch: 5| Step: 3
Training loss: 2.1188628673553467
Validation loss: 1.974299838466029

Epoch: 5| Step: 4
Training loss: 1.986749291419983
Validation loss: 1.9820194680203673

Epoch: 5| Step: 5
Training loss: 1.0731910467147827
Validation loss: 1.9794894213317542

Epoch: 5| Step: 6
Training loss: 1.8021959066390991
Validation loss: 1.9989348432069183

Epoch: 5| Step: 7
Training loss: 2.1058318614959717
Validation loss: 2.038936391953499

Epoch: 5| Step: 8
Training loss: 1.9110110998153687
Validation loss: 2.0742790647732314

Epoch: 5| Step: 9
Training loss: 1.8543421030044556
Validation loss: 2.0736058706878335

Epoch: 5| Step: 10
Training loss: 2.026970624923706
Validation loss: 2.0820568402608237

Epoch: 204| Step: 0
Training loss: 1.6663230657577515
Validation loss: 2.042014034845496

Epoch: 5| Step: 1
Training loss: 1.2678157091140747
Validation loss: 2.0517570408441688

Epoch: 5| Step: 2
Training loss: 1.4411565065383911
Validation loss: 2.020567956791129

Epoch: 5| Step: 3
Training loss: 1.949232816696167
Validation loss: 2.01475530029625

Epoch: 5| Step: 4
Training loss: 1.6763265132904053
Validation loss: 1.9958774607668641

Epoch: 5| Step: 5
Training loss: 2.593482494354248
Validation loss: 1.9940548891662269

Epoch: 5| Step: 6
Training loss: 2.471536636352539
Validation loss: 1.996907280337426

Epoch: 5| Step: 7
Training loss: 2.090272903442383
Validation loss: 2.0100109859179427

Epoch: 5| Step: 8
Training loss: 1.6574522256851196
Validation loss: 1.9972082081661429

Epoch: 5| Step: 9
Training loss: 1.2419939041137695
Validation loss: 2.0021704614803357

Epoch: 5| Step: 10
Training loss: 1.9901872873306274
Validation loss: 2.001676800430462

Epoch: 205| Step: 0
Training loss: 1.2168245315551758
Validation loss: 2.0007921034289944

Epoch: 5| Step: 1
Training loss: 2.1153173446655273
Validation loss: 1.977436770675003

Epoch: 5| Step: 2
Training loss: 1.7881381511688232
Validation loss: 1.9955970548814344

Epoch: 5| Step: 3
Training loss: 1.6188380718231201
Validation loss: 2.004381528464697

Epoch: 5| Step: 4
Training loss: 1.7630412578582764
Validation loss: 2.0126828301337456

Epoch: 5| Step: 5
Training loss: 2.430145263671875
Validation loss: 2.0021295803849415

Epoch: 5| Step: 6
Training loss: 1.6643218994140625
Validation loss: 2.0167146139247443

Epoch: 5| Step: 7
Training loss: 2.0811352729797363
Validation loss: 1.9965117490419777

Epoch: 5| Step: 8
Training loss: 1.691006064414978
Validation loss: 1.9902916646772815

Epoch: 5| Step: 9
Training loss: 1.4371273517608643
Validation loss: 2.0189673234057683

Epoch: 5| Step: 10
Training loss: 1.9518755674362183
Validation loss: 2.008892041380687

Epoch: 206| Step: 0
Training loss: 1.393416404724121
Validation loss: 2.026748778999493

Epoch: 5| Step: 1
Training loss: 1.846274971961975
Validation loss: 2.0338788865714945

Epoch: 5| Step: 2
Training loss: 1.6633964776992798
Validation loss: 2.037158432186291

Epoch: 5| Step: 3
Training loss: 2.3787734508514404
Validation loss: 2.0231687996977117

Epoch: 5| Step: 4
Training loss: 1.6898698806762695
Validation loss: 2.02217633493485

Epoch: 5| Step: 5
Training loss: 0.9639602899551392
Validation loss: 2.0138802707836194

Epoch: 5| Step: 6
Training loss: 1.6875579357147217
Validation loss: 1.9969442864899993

Epoch: 5| Step: 7
Training loss: 1.8013181686401367
Validation loss: 2.0058394657668246

Epoch: 5| Step: 8
Training loss: 2.0565237998962402
Validation loss: 1.9942175521645495

Epoch: 5| Step: 9
Training loss: 1.955392837524414
Validation loss: 2.0052588601266184

Epoch: 5| Step: 10
Training loss: 2.291339635848999
Validation loss: 2.0158070454033474

Epoch: 207| Step: 0
Training loss: 1.599407434463501
Validation loss: 2.0094194207140195

Epoch: 5| Step: 1
Training loss: 1.898847222328186
Validation loss: 2.0256086562269475

Epoch: 5| Step: 2
Training loss: 2.252636671066284
Validation loss: 2.045091594419172

Epoch: 5| Step: 3
Training loss: 1.4244427680969238
Validation loss: 2.045080272100305

Epoch: 5| Step: 4
Training loss: 1.6491152048110962
Validation loss: 2.0321929044620965

Epoch: 5| Step: 5
Training loss: 1.808990478515625
Validation loss: 2.021106602043234

Epoch: 5| Step: 6
Training loss: 2.1399567127227783
Validation loss: 2.0281799416388235

Epoch: 5| Step: 7
Training loss: 1.7591279745101929
Validation loss: 2.0123154681216002

Epoch: 5| Step: 8
Training loss: 2.0199742317199707
Validation loss: 2.022420164077513

Epoch: 5| Step: 9
Training loss: 1.670800805091858
Validation loss: 2.00971899237684

Epoch: 5| Step: 10
Training loss: 1.5327869653701782
Validation loss: 2.0168341026511243

Epoch: 208| Step: 0
Training loss: 1.459270715713501
Validation loss: 2.0375152941673034

Epoch: 5| Step: 1
Training loss: 1.021897554397583
Validation loss: 2.0373794007044967

Epoch: 5| Step: 2
Training loss: 1.8003082275390625
Validation loss: 2.0403435089254893

Epoch: 5| Step: 3
Training loss: 1.5115078687667847
Validation loss: 2.0339779828184392

Epoch: 5| Step: 4
Training loss: 2.023240089416504
Validation loss: 2.040320381041496

Epoch: 5| Step: 5
Training loss: 1.7679420709609985
Validation loss: 2.0141069940341416

Epoch: 5| Step: 6
Training loss: 2.020904064178467
Validation loss: 1.9866737960487284

Epoch: 5| Step: 7
Training loss: 2.327134370803833
Validation loss: 1.9714854378854074

Epoch: 5| Step: 8
Training loss: 2.26576828956604
Validation loss: 1.9812008245016939

Epoch: 5| Step: 9
Training loss: 1.8391491174697876
Validation loss: 1.9872057822442823

Epoch: 5| Step: 10
Training loss: 1.5461148023605347
Validation loss: 1.9951891655563025

Epoch: 209| Step: 0
Training loss: 0.9859708547592163
Validation loss: 2.0142534048326555

Epoch: 5| Step: 1
Training loss: 1.300283670425415
Validation loss: 2.0302140597374208

Epoch: 5| Step: 2
Training loss: 2.763542413711548
Validation loss: 2.031739966843718

Epoch: 5| Step: 3
Training loss: 1.712179183959961
Validation loss: 2.044272284353933

Epoch: 5| Step: 4
Training loss: 2.127091884613037
Validation loss: 2.084505911796324

Epoch: 5| Step: 5
Training loss: 1.5795137882232666
Validation loss: 2.064896155429143

Epoch: 5| Step: 6
Training loss: 2.0859763622283936
Validation loss: 2.0616241655042096

Epoch: 5| Step: 7
Training loss: 1.932735800743103
Validation loss: 2.050222913424174

Epoch: 5| Step: 8
Training loss: 2.1646571159362793
Validation loss: 2.0286678524427515

Epoch: 5| Step: 9
Training loss: 1.4107530117034912
Validation loss: 2.018067706015802

Epoch: 5| Step: 10
Training loss: 1.5338541269302368
Validation loss: 2.02781670324264

Epoch: 210| Step: 0
Training loss: 1.8217647075653076
Validation loss: 2.0087672356636292

Epoch: 5| Step: 1
Training loss: 1.9418014287948608
Validation loss: 1.9986800480914373

Epoch: 5| Step: 2
Training loss: 1.6641937494277954
Validation loss: 2.009023057517185

Epoch: 5| Step: 3
Training loss: 1.502931833267212
Validation loss: 2.0331571678961478

Epoch: 5| Step: 4
Training loss: 1.6651252508163452
Validation loss: 2.0313552707754154

Epoch: 5| Step: 5
Training loss: 2.3568689823150635
Validation loss: 2.029605321986701

Epoch: 5| Step: 6
Training loss: 1.6822487115859985
Validation loss: 2.0175783570094774

Epoch: 5| Step: 7
Training loss: 2.038742780685425
Validation loss: 2.012846763416003

Epoch: 5| Step: 8
Training loss: 1.4944920539855957
Validation loss: 2.006702438477547

Epoch: 5| Step: 9
Training loss: 1.7733564376831055
Validation loss: 2.0117966539116314

Epoch: 5| Step: 10
Training loss: 1.4123531579971313
Validation loss: 2.0139767380170923

Epoch: 211| Step: 0
Training loss: 1.7277085781097412
Validation loss: 2.030861945562465

Epoch: 5| Step: 1
Training loss: 1.938233733177185
Validation loss: 2.067386015768974

Epoch: 5| Step: 2
Training loss: 1.8848903179168701
Validation loss: 2.081164744592482

Epoch: 5| Step: 3
Training loss: 1.1197463274002075
Validation loss: 2.0283575211801836

Epoch: 5| Step: 4
Training loss: 1.518426775932312
Validation loss: 1.9912080277678788

Epoch: 5| Step: 5
Training loss: 1.7862062454223633
Validation loss: 1.9706779474853187

Epoch: 5| Step: 6
Training loss: 2.3266329765319824
Validation loss: 1.9690629102850472

Epoch: 5| Step: 7
Training loss: 1.9822843074798584
Validation loss: 1.982087126342199

Epoch: 5| Step: 8
Training loss: 1.4941177368164062
Validation loss: 1.9914236350726056

Epoch: 5| Step: 9
Training loss: 1.4266741275787354
Validation loss: 2.0353316619832027

Epoch: 5| Step: 10
Training loss: 2.645596981048584
Validation loss: 2.0793101121020574

Epoch: 212| Step: 0
Training loss: 2.6833972930908203
Validation loss: 2.145561756626252

Epoch: 5| Step: 1
Training loss: 2.1394641399383545
Validation loss: 2.123709794013731

Epoch: 5| Step: 2
Training loss: 2.511528253555298
Validation loss: 2.0572637665656304

Epoch: 5| Step: 3
Training loss: 1.6065616607666016
Validation loss: 1.9960271414890085

Epoch: 5| Step: 4
Training loss: 1.716069221496582
Validation loss: 2.0040750964995353

Epoch: 5| Step: 5
Training loss: 1.6526401042938232
Validation loss: 2.019254422956897

Epoch: 5| Step: 6
Training loss: 1.5109108686447144
Validation loss: 2.025471087424986

Epoch: 5| Step: 7
Training loss: 1.7786953449249268
Validation loss: 2.037030038013253

Epoch: 5| Step: 8
Training loss: 1.3539232015609741
Validation loss: 2.030471458229967

Epoch: 5| Step: 9
Training loss: 1.9993312358856201
Validation loss: 2.019135784077388

Epoch: 5| Step: 10
Training loss: 0.4992096722126007
Validation loss: 2.0348275733250443

Epoch: 213| Step: 0
Training loss: 1.4807733297348022
Validation loss: 2.0403550273628643

Epoch: 5| Step: 1
Training loss: 1.1855981349945068
Validation loss: 2.058305237882881

Epoch: 5| Step: 2
Training loss: 1.8067554235458374
Validation loss: 2.10058569651778

Epoch: 5| Step: 3
Training loss: 1.493048071861267
Validation loss: 2.14790286684549

Epoch: 5| Step: 4
Training loss: 1.814907431602478
Validation loss: 2.1357446870496197

Epoch: 5| Step: 5
Training loss: 1.5702943801879883
Validation loss: 2.1376653243136663

Epoch: 5| Step: 6
Training loss: 2.0232701301574707
Validation loss: 2.100543147774153

Epoch: 5| Step: 7
Training loss: 2.0248050689697266
Validation loss: 2.0493783745714413

Epoch: 5| Step: 8
Training loss: 2.129106044769287
Validation loss: 2.012244536030677

Epoch: 5| Step: 9
Training loss: 2.2266669273376465
Validation loss: 2.0121153118789836

Epoch: 5| Step: 10
Training loss: 1.990801453590393
Validation loss: 2.0161862629716114

Epoch: 214| Step: 0
Training loss: 1.953934669494629
Validation loss: 1.9941878216240996

Epoch: 5| Step: 1
Training loss: 1.6261484622955322
Validation loss: 1.9902151541043354

Epoch: 5| Step: 2
Training loss: 1.7349964380264282
Validation loss: 1.9858334231120285

Epoch: 5| Step: 3
Training loss: 2.089918613433838
Validation loss: 1.965140433721645

Epoch: 5| Step: 4
Training loss: 1.3657777309417725
Validation loss: 2.0027259139604467

Epoch: 5| Step: 5
Training loss: 1.4596503973007202
Validation loss: 2.0782268290878623

Epoch: 5| Step: 6
Training loss: 2.6035633087158203
Validation loss: 2.139548490124364

Epoch: 5| Step: 7
Training loss: 1.8806778192520142
Validation loss: 2.135063894333378

Epoch: 5| Step: 8
Training loss: 1.5943796634674072
Validation loss: 2.1272886107044835

Epoch: 5| Step: 9
Training loss: 1.8704330921173096
Validation loss: 2.102185013473675

Epoch: 5| Step: 10
Training loss: 2.0587055683135986
Validation loss: 2.084521416694887

Epoch: 215| Step: 0
Training loss: 1.6349769830703735
Validation loss: 2.0456028651165705

Epoch: 5| Step: 1
Training loss: 1.7332141399383545
Validation loss: 2.034701839570076

Epoch: 5| Step: 2
Training loss: 1.7740188837051392
Validation loss: 2.040624572384742

Epoch: 5| Step: 3
Training loss: 1.1935887336730957
Validation loss: 2.038968579743498

Epoch: 5| Step: 4
Training loss: 2.2187836170196533
Validation loss: 2.0564429349796747

Epoch: 5| Step: 5
Training loss: 1.5947151184082031
Validation loss: 2.0892899408135364

Epoch: 5| Step: 6
Training loss: 2.0506694316864014
Validation loss: 2.0539794429655998

Epoch: 5| Step: 7
Training loss: 1.7127177715301514
Validation loss: 2.036574127853558

Epoch: 5| Step: 8
Training loss: 2.0273873805999756
Validation loss: 2.045058124808855

Epoch: 5| Step: 9
Training loss: 1.104306936264038
Validation loss: 2.0339915060227916

Epoch: 5| Step: 10
Training loss: 2.2072346210479736
Validation loss: 2.007254095487697

Epoch: 216| Step: 0
Training loss: 1.5084058046340942
Validation loss: 2.013260749078566

Epoch: 5| Step: 1
Training loss: 1.9654130935668945
Validation loss: 2.002157145930875

Epoch: 5| Step: 2
Training loss: 1.474326729774475
Validation loss: 1.9888686569788123

Epoch: 5| Step: 3
Training loss: 1.8552560806274414
Validation loss: 1.9958572105694843

Epoch: 5| Step: 4
Training loss: 1.3826513290405273
Validation loss: 2.0052615263128795

Epoch: 5| Step: 5
Training loss: 2.0330193042755127
Validation loss: 1.9835776462349841

Epoch: 5| Step: 6
Training loss: 2.09421968460083
Validation loss: 1.9958689981891262

Epoch: 5| Step: 7
Training loss: 2.1904845237731934
Validation loss: 2.012492083734082

Epoch: 5| Step: 8
Training loss: 1.5997220277786255
Validation loss: 2.0190323783505346

Epoch: 5| Step: 9
Training loss: 1.1040141582489014
Validation loss: 2.052767280609377

Epoch: 5| Step: 10
Training loss: 1.928651213645935
Validation loss: 2.051382057128414

Epoch: 217| Step: 0
Training loss: 1.6713625192642212
Validation loss: 2.07984281868063

Epoch: 5| Step: 1
Training loss: 1.8052068948745728
Validation loss: 2.0885816107514086

Epoch: 5| Step: 2
Training loss: 1.5917441844940186
Validation loss: 2.1191474878659813

Epoch: 5| Step: 3
Training loss: 1.5514819622039795
Validation loss: 2.133936855100816

Epoch: 5| Step: 4
Training loss: 1.4955816268920898
Validation loss: 2.1421036617730254

Epoch: 5| Step: 5
Training loss: 1.664107084274292
Validation loss: 2.114207301088559

Epoch: 5| Step: 6
Training loss: 1.8334619998931885
Validation loss: 2.0880062721108876

Epoch: 5| Step: 7
Training loss: 1.7315857410430908
Validation loss: 2.071693438355641

Epoch: 5| Step: 8
Training loss: 2.162803888320923
Validation loss: 2.048020088544456

Epoch: 5| Step: 9
Training loss: 1.9188820123672485
Validation loss: 2.049270068445513

Epoch: 5| Step: 10
Training loss: 1.553106665611267
Validation loss: 2.034277186598829

Epoch: 218| Step: 0
Training loss: 2.003866195678711
Validation loss: 2.0169736364836335

Epoch: 5| Step: 1
Training loss: 1.3924410343170166
Validation loss: 2.017197652529645

Epoch: 5| Step: 2
Training loss: 1.1950874328613281
Validation loss: 2.0122132532058226

Epoch: 5| Step: 3
Training loss: 1.9255836009979248
Validation loss: 2.0089539609929568

Epoch: 5| Step: 4
Training loss: 1.9753278493881226
Validation loss: 2.017066632547686

Epoch: 5| Step: 5
Training loss: 2.059328079223633
Validation loss: 2.017611188273276

Epoch: 5| Step: 6
Training loss: 1.7137874364852905
Validation loss: 2.027932620817615

Epoch: 5| Step: 7
Training loss: 1.6627000570297241
Validation loss: 2.0292521753618793

Epoch: 5| Step: 8
Training loss: 1.6305930614471436
Validation loss: 2.0761436185529156

Epoch: 5| Step: 9
Training loss: 1.727621078491211
Validation loss: 2.082563938633088

Epoch: 5| Step: 10
Training loss: 1.5860768556594849
Validation loss: 2.0545301693741993

Epoch: 219| Step: 0
Training loss: 1.3892970085144043
Validation loss: 2.0519881376656155

Epoch: 5| Step: 1
Training loss: 2.0862081050872803
Validation loss: 2.014753116074429

Epoch: 5| Step: 2
Training loss: 1.5772942304611206
Validation loss: 1.9768279316604778

Epoch: 5| Step: 3
Training loss: 1.3945033550262451
Validation loss: 1.973843737315106

Epoch: 5| Step: 4
Training loss: 1.6680961847305298
Validation loss: 2.0160439245162474

Epoch: 5| Step: 5
Training loss: 2.178574323654175
Validation loss: 2.0828761439169607

Epoch: 5| Step: 6
Training loss: 1.9875547885894775
Validation loss: 2.113856032330503

Epoch: 5| Step: 7
Training loss: 1.6835943460464478
Validation loss: 2.0773299112114856

Epoch: 5| Step: 8
Training loss: 1.34735906124115
Validation loss: 2.034257217120099

Epoch: 5| Step: 9
Training loss: 1.9537458419799805
Validation loss: 2.006492814710063

Epoch: 5| Step: 10
Training loss: 1.4587005376815796
Validation loss: 2.0056907028280277

Epoch: 220| Step: 0
Training loss: 1.5690997838974
Validation loss: 1.9985906385606336

Epoch: 5| Step: 1
Training loss: 1.4834368228912354
Validation loss: 2.0161419940251175

Epoch: 5| Step: 2
Training loss: 1.877903699874878
Validation loss: 2.011310015955279

Epoch: 5| Step: 3
Training loss: 1.9174063205718994
Validation loss: 2.019236631290887

Epoch: 5| Step: 4
Training loss: 1.5430082082748413
Validation loss: 2.0319677411869006

Epoch: 5| Step: 5
Training loss: 2.1728477478027344
Validation loss: 2.009814654627154

Epoch: 5| Step: 6
Training loss: 1.6380136013031006
Validation loss: 2.019102352921681

Epoch: 5| Step: 7
Training loss: 2.061394214630127
Validation loss: 2.0290346081538866

Epoch: 5| Step: 8
Training loss: 1.749729871749878
Validation loss: 2.072024576125606

Epoch: 5| Step: 9
Training loss: 0.9759564399719238
Validation loss: 2.0533768246250768

Epoch: 5| Step: 10
Training loss: 1.8488613367080688
Validation loss: 2.0325956395877305

Epoch: 221| Step: 0
Training loss: 1.7624657154083252
Validation loss: 2.0269560839540217

Epoch: 5| Step: 1
Training loss: 1.9638712406158447
Validation loss: 2.0107738676891533

Epoch: 5| Step: 2
Training loss: 1.5875442028045654
Validation loss: 2.0025452977867535

Epoch: 5| Step: 3
Training loss: 1.6727018356323242
Validation loss: 2.021634517177459

Epoch: 5| Step: 4
Training loss: 1.63254714012146
Validation loss: 1.9857472053138159

Epoch: 5| Step: 5
Training loss: 1.7565851211547852
Validation loss: 2.0072739970299507

Epoch: 5| Step: 6
Training loss: 1.6040656566619873
Validation loss: 2.0196074465269684

Epoch: 5| Step: 7
Training loss: 1.7094444036483765
Validation loss: 2.0378603960878108

Epoch: 5| Step: 8
Training loss: 1.6710584163665771
Validation loss: 2.0915558030528407

Epoch: 5| Step: 9
Training loss: 1.3701932430267334
Validation loss: 2.058584617030236

Epoch: 5| Step: 10
Training loss: 1.9107890129089355
Validation loss: 2.057173704588285

Epoch: 222| Step: 0
Training loss: 2.098672389984131
Validation loss: 2.0382552864731

Epoch: 5| Step: 1
Training loss: 2.159519910812378
Validation loss: 2.0189885067683395

Epoch: 5| Step: 2
Training loss: 1.6979522705078125
Validation loss: 2.0116481819460468

Epoch: 5| Step: 3
Training loss: 1.7832212448120117
Validation loss: 2.004561657546669

Epoch: 5| Step: 4
Training loss: 1.3852816820144653
Validation loss: 2.0117272920505975

Epoch: 5| Step: 5
Training loss: 1.2415084838867188
Validation loss: 2.0315167211717173

Epoch: 5| Step: 6
Training loss: 1.762640357017517
Validation loss: 2.0143552364841586

Epoch: 5| Step: 7
Training loss: 1.1795568466186523
Validation loss: 1.984847189277731

Epoch: 5| Step: 8
Training loss: 1.6226199865341187
Validation loss: 1.9957405418478034

Epoch: 5| Step: 9
Training loss: 2.3309998512268066
Validation loss: 2.010451339906262

Epoch: 5| Step: 10
Training loss: 1.2245330810546875
Validation loss: 2.0575979345588276

Epoch: 223| Step: 0
Training loss: 1.3670164346694946
Validation loss: 2.095129318134759

Epoch: 5| Step: 1
Training loss: 1.5437510013580322
Validation loss: 2.0851075239078973

Epoch: 5| Step: 2
Training loss: 1.555012822151184
Validation loss: 2.008457153074203

Epoch: 5| Step: 3
Training loss: 1.827280044555664
Validation loss: 1.9804191961083362

Epoch: 5| Step: 4
Training loss: 2.064955472946167
Validation loss: 1.992157333640642

Epoch: 5| Step: 5
Training loss: 1.4703547954559326
Validation loss: 1.9665581500658424

Epoch: 5| Step: 6
Training loss: 1.388213872909546
Validation loss: 1.9626347864827802

Epoch: 5| Step: 7
Training loss: 1.6382744312286377
Validation loss: 1.968625109682801

Epoch: 5| Step: 8
Training loss: 2.2181668281555176
Validation loss: 1.9574269927958006

Epoch: 5| Step: 9
Training loss: 1.733896255493164
Validation loss: 1.9609366642531527

Epoch: 5| Step: 10
Training loss: 1.578859806060791
Validation loss: 1.9700795232608754

Epoch: 224| Step: 0
Training loss: 1.658107042312622
Validation loss: 1.9866205107781194

Epoch: 5| Step: 1
Training loss: 1.9891605377197266
Validation loss: 2.0198918234917427

Epoch: 5| Step: 2
Training loss: 1.3512519598007202
Validation loss: 2.075974278552558

Epoch: 5| Step: 3
Training loss: 1.0661194324493408
Validation loss: 2.049233671157591

Epoch: 5| Step: 4
Training loss: 1.7055187225341797
Validation loss: 2.0467604321818196

Epoch: 5| Step: 5
Training loss: 1.4924535751342773
Validation loss: 2.0187185810458277

Epoch: 5| Step: 6
Training loss: 1.4620530605316162
Validation loss: 2.0205053744777555

Epoch: 5| Step: 7
Training loss: 1.8505061864852905
Validation loss: 2.003926659143099

Epoch: 5| Step: 8
Training loss: 1.7486006021499634
Validation loss: 1.9985694769890077

Epoch: 5| Step: 9
Training loss: 1.906825304031372
Validation loss: 2.024267422255649

Epoch: 5| Step: 10
Training loss: 1.8611791133880615
Validation loss: 2.050755893030474

Epoch: 225| Step: 0
Training loss: 1.5746029615402222
Validation loss: 2.065508296412806

Epoch: 5| Step: 1
Training loss: 1.4570856094360352
Validation loss: 2.0659879561393493

Epoch: 5| Step: 2
Training loss: 1.7267754077911377
Validation loss: 2.0727091579027075

Epoch: 5| Step: 3
Training loss: 1.8862063884735107
Validation loss: 2.0403261146237774

Epoch: 5| Step: 4
Training loss: 1.7360401153564453
Validation loss: 2.0323117471510366

Epoch: 5| Step: 5
Training loss: 1.18185293674469
Validation loss: 2.008239646111765

Epoch: 5| Step: 6
Training loss: 1.4708720445632935
Validation loss: 2.000492944512316

Epoch: 5| Step: 7
Training loss: 1.6164966821670532
Validation loss: 1.982135857305219

Epoch: 5| Step: 8
Training loss: 2.190528154373169
Validation loss: 1.9728757899294618

Epoch: 5| Step: 9
Training loss: 1.7344274520874023
Validation loss: 1.9629643001864034

Epoch: 5| Step: 10
Training loss: 1.4846842288970947
Validation loss: 1.9529864634236982

Epoch: 226| Step: 0
Training loss: 2.13498854637146
Validation loss: 1.9376829580594135

Epoch: 5| Step: 1
Training loss: 0.8106681704521179
Validation loss: 1.9640699842924714

Epoch: 5| Step: 2
Training loss: 1.505469560623169
Validation loss: 1.9903946025397188

Epoch: 5| Step: 3
Training loss: 1.9049110412597656
Validation loss: 2.057922932409471

Epoch: 5| Step: 4
Training loss: 2.0165939331054688
Validation loss: 2.0528414890330327

Epoch: 5| Step: 5
Training loss: 1.2897889614105225
Validation loss: 2.0556547129026024

Epoch: 5| Step: 6
Training loss: 1.4415262937545776
Validation loss: 2.0582203736869236

Epoch: 5| Step: 7
Training loss: 1.689670205116272
Validation loss: 2.0295570435062533

Epoch: 5| Step: 8
Training loss: 1.8437649011611938
Validation loss: 2.022240731023973

Epoch: 5| Step: 9
Training loss: 1.6878591775894165
Validation loss: 2.030531129529399

Epoch: 5| Step: 10
Training loss: 1.680677056312561
Validation loss: 2.0137863082270466

Epoch: 227| Step: 0
Training loss: 1.5244107246398926
Validation loss: 2.010317187155447

Epoch: 5| Step: 1
Training loss: 1.525486707687378
Validation loss: 2.018693047185098

Epoch: 5| Step: 2
Training loss: 1.4758028984069824
Validation loss: 2.009707761067216

Epoch: 5| Step: 3
Training loss: 1.9603887796401978
Validation loss: 2.0015478569974183

Epoch: 5| Step: 4
Training loss: 1.8661476373672485
Validation loss: 2.0105225834795224

Epoch: 5| Step: 5
Training loss: 1.5882295370101929
Validation loss: 2.007171174531342

Epoch: 5| Step: 6
Training loss: 2.1175153255462646
Validation loss: 2.0212922224434475

Epoch: 5| Step: 7
Training loss: 1.4666011333465576
Validation loss: 2.040043807798816

Epoch: 5| Step: 8
Training loss: 1.1382077932357788
Validation loss: 2.045643114274548

Epoch: 5| Step: 9
Training loss: 1.3456928730010986
Validation loss: 2.0620957753991567

Epoch: 5| Step: 10
Training loss: 1.7476563453674316
Validation loss: 2.0790192260537097

Epoch: 228| Step: 0
Training loss: 2.144000291824341
Validation loss: 2.0794355664201962

Epoch: 5| Step: 1
Training loss: 1.7012979984283447
Validation loss: 2.0439364551216044

Epoch: 5| Step: 2
Training loss: 1.4806602001190186
Validation loss: 2.01463770738212

Epoch: 5| Step: 3
Training loss: 2.0188822746276855
Validation loss: 1.981062081552321

Epoch: 5| Step: 4
Training loss: 1.3304288387298584
Validation loss: 1.988147517686249

Epoch: 5| Step: 5
Training loss: 1.8802417516708374
Validation loss: 1.9775082731759677

Epoch: 5| Step: 6
Training loss: 1.562770128250122
Validation loss: 1.9827581349239554

Epoch: 5| Step: 7
Training loss: 1.0529329776763916
Validation loss: 1.9947734917363813

Epoch: 5| Step: 8
Training loss: 1.593472957611084
Validation loss: 2.0582799142406834

Epoch: 5| Step: 9
Training loss: 1.662738561630249
Validation loss: 2.157928587287985

Epoch: 5| Step: 10
Training loss: 1.7755604982376099
Validation loss: 2.182792804574454

Epoch: 229| Step: 0
Training loss: 1.255398154258728
Validation loss: 2.127783966320817

Epoch: 5| Step: 1
Training loss: 1.4527806043624878
Validation loss: 2.0353962721363192

Epoch: 5| Step: 2
Training loss: 1.2321984767913818
Validation loss: 1.9880957834182247

Epoch: 5| Step: 3
Training loss: 1.7984672784805298
Validation loss: 1.9841440621242727

Epoch: 5| Step: 4
Training loss: 2.4034876823425293
Validation loss: 1.9781974823244157

Epoch: 5| Step: 5
Training loss: 2.427586793899536
Validation loss: 1.9741053786329044

Epoch: 5| Step: 6
Training loss: 1.444823980331421
Validation loss: 1.984440436927221

Epoch: 5| Step: 7
Training loss: 2.017486333847046
Validation loss: 1.9657821193818124

Epoch: 5| Step: 8
Training loss: 2.1285998821258545
Validation loss: 1.956909974416097

Epoch: 5| Step: 9
Training loss: 1.5101392269134521
Validation loss: 1.9692834679798414

Epoch: 5| Step: 10
Training loss: 1.2995824813842773
Validation loss: 2.001268441959094

Epoch: 230| Step: 0
Training loss: 1.8392127752304077
Validation loss: 2.078112949607193

Epoch: 5| Step: 1
Training loss: 2.0900676250457764
Validation loss: 2.142583258690373

Epoch: 5| Step: 2
Training loss: 2.087188482284546
Validation loss: 2.110398848851522

Epoch: 5| Step: 3
Training loss: 1.380437970161438
Validation loss: 2.0985697302767026

Epoch: 5| Step: 4
Training loss: 1.5135223865509033
Validation loss: 2.07588457035762

Epoch: 5| Step: 5
Training loss: 1.8205642700195312
Validation loss: 2.042181240615024

Epoch: 5| Step: 6
Training loss: 1.0475027561187744
Validation loss: 2.0498930408108618

Epoch: 5| Step: 7
Training loss: 1.3665320873260498
Validation loss: 2.0188533900886454

Epoch: 5| Step: 8
Training loss: 1.4893968105316162
Validation loss: 2.0211061328969975

Epoch: 5| Step: 9
Training loss: 1.6125562191009521
Validation loss: 2.041438571868404

Epoch: 5| Step: 10
Training loss: 1.7733888626098633
Validation loss: 2.065781226722143

Epoch: 231| Step: 0
Training loss: 1.669584035873413
Validation loss: 2.1022771994272866

Epoch: 5| Step: 1
Training loss: 1.4485794305801392
Validation loss: 2.110150614092427

Epoch: 5| Step: 2
Training loss: 1.3412898778915405
Validation loss: 2.066395777528004

Epoch: 5| Step: 3
Training loss: 1.9268029928207397
Validation loss: 2.043491437870969

Epoch: 5| Step: 4
Training loss: 1.5218137502670288
Validation loss: 2.0139899664027716

Epoch: 5| Step: 5
Training loss: 2.174454689025879
Validation loss: 2.028252245277487

Epoch: 5| Step: 6
Training loss: 1.7983754873275757
Validation loss: 2.022791706105714

Epoch: 5| Step: 7
Training loss: 1.5411498546600342
Validation loss: 2.012102602630533

Epoch: 5| Step: 8
Training loss: 0.8509119153022766
Validation loss: 2.0125196723527807

Epoch: 5| Step: 9
Training loss: 1.7357900142669678
Validation loss: 2.0389602825205815

Epoch: 5| Step: 10
Training loss: 1.4158049821853638
Validation loss: 2.0668754039272184

Epoch: 232| Step: 0
Training loss: 1.3936258554458618
Validation loss: 2.043380662959109

Epoch: 5| Step: 1
Training loss: 1.85360848903656
Validation loss: 2.016461451848348

Epoch: 5| Step: 2
Training loss: 1.3985295295715332
Validation loss: 1.9977062940597534

Epoch: 5| Step: 3
Training loss: 1.9925302267074585
Validation loss: 1.9960718552271526

Epoch: 5| Step: 4
Training loss: 1.5104578733444214
Validation loss: 1.9772292298655356

Epoch: 5| Step: 5
Training loss: 1.789812684059143
Validation loss: 2.0021378378714285

Epoch: 5| Step: 6
Training loss: 1.4745826721191406
Validation loss: 1.9954799067589544

Epoch: 5| Step: 7
Training loss: 1.3023860454559326
Validation loss: 2.0087958869113716

Epoch: 5| Step: 8
Training loss: 1.6054741144180298
Validation loss: 2.0286647389012

Epoch: 5| Step: 9
Training loss: 1.9287135601043701
Validation loss: 2.028064893138024

Epoch: 5| Step: 10
Training loss: 1.1647573709487915
Validation loss: 2.0379843545216385

Epoch: 233| Step: 0
Training loss: 1.8696972131729126
Validation loss: 2.0262876428583616

Epoch: 5| Step: 1
Training loss: 1.633610486984253
Validation loss: 2.051937872363675

Epoch: 5| Step: 2
Training loss: 1.7513233423233032
Validation loss: 2.043299718569684

Epoch: 5| Step: 3
Training loss: 1.4439818859100342
Validation loss: 2.0272751213401876

Epoch: 5| Step: 4
Training loss: 2.0675837993621826
Validation loss: 2.0524065404809932

Epoch: 5| Step: 5
Training loss: 1.2305136919021606
Validation loss: 2.0107985170938636

Epoch: 5| Step: 6
Training loss: 1.479583501815796
Validation loss: 2.00642716756431

Epoch: 5| Step: 7
Training loss: 1.4984514713287354
Validation loss: 1.9923958701472129

Epoch: 5| Step: 8
Training loss: 1.0541598796844482
Validation loss: 1.985689709263463

Epoch: 5| Step: 9
Training loss: 1.1799912452697754
Validation loss: 1.9738341762173561

Epoch: 5| Step: 10
Training loss: 1.9919507503509521
Validation loss: 1.9803392541023992

Epoch: 234| Step: 0
Training loss: 1.585974931716919
Validation loss: 1.993254873060411

Epoch: 5| Step: 1
Training loss: 1.4501988887786865
Validation loss: 2.003930971186648

Epoch: 5| Step: 2
Training loss: 1.250818133354187
Validation loss: 2.016681723697211

Epoch: 5| Step: 3
Training loss: 1.6005678176879883
Validation loss: 2.023364467005576

Epoch: 5| Step: 4
Training loss: 1.712548017501831
Validation loss: 2.0545691238936556

Epoch: 5| Step: 5
Training loss: 1.5804178714752197
Validation loss: 2.0586437871379237

Epoch: 5| Step: 6
Training loss: 0.7825444936752319
Validation loss: 2.0119633815621816

Epoch: 5| Step: 7
Training loss: 1.8074567317962646
Validation loss: 2.0232726771344423

Epoch: 5| Step: 8
Training loss: 1.9190212488174438
Validation loss: 2.022321206267162

Epoch: 5| Step: 9
Training loss: 1.44651460647583
Validation loss: 2.0193259228942213

Epoch: 5| Step: 10
Training loss: 1.6791372299194336
Validation loss: 2.049516144619193

Epoch: 235| Step: 0
Training loss: 1.7670475244522095
Validation loss: 2.019321469850438

Epoch: 5| Step: 1
Training loss: 1.6915836334228516
Validation loss: 2.009286331874068

Epoch: 5| Step: 2
Training loss: 1.2981007099151611
Validation loss: 1.9881267688607658

Epoch: 5| Step: 3
Training loss: 2.1073591709136963
Validation loss: 1.9759963045838058

Epoch: 5| Step: 4
Training loss: 1.824629545211792
Validation loss: 1.989473158313382

Epoch: 5| Step: 5
Training loss: 1.2556750774383545
Validation loss: 1.9971987406412761

Epoch: 5| Step: 6
Training loss: 1.7883765697479248
Validation loss: 2.0147368459291357

Epoch: 5| Step: 7
Training loss: 1.6409757137298584
Validation loss: 2.0584704722127607

Epoch: 5| Step: 8
Training loss: 1.3265676498413086
Validation loss: 2.0952791885663102

Epoch: 5| Step: 9
Training loss: 1.1484251022338867
Validation loss: 2.081065850873147

Epoch: 5| Step: 10
Training loss: 1.0720125436782837
Validation loss: 2.0401498553573445

Epoch: 236| Step: 0
Training loss: 1.6122783422470093
Validation loss: 1.9746301661255539

Epoch: 5| Step: 1
Training loss: 1.2879369258880615
Validation loss: 1.9938764572143555

Epoch: 5| Step: 2
Training loss: 1.4318110942840576
Validation loss: 1.983233879971248

Epoch: 5| Step: 3
Training loss: 1.9042154550552368
Validation loss: 1.971315868439213

Epoch: 5| Step: 4
Training loss: 1.906577467918396
Validation loss: 1.985592560101581

Epoch: 5| Step: 5
Training loss: 2.1624557971954346
Validation loss: 1.9844708487551699

Epoch: 5| Step: 6
Training loss: 1.3311527967453003
Validation loss: 2.007886517432428

Epoch: 5| Step: 7
Training loss: 1.3141834735870361
Validation loss: 2.0225822797385593

Epoch: 5| Step: 8
Training loss: 1.3289483785629272
Validation loss: 2.0190184180454542

Epoch: 5| Step: 9
Training loss: 1.0044039487838745
Validation loss: 2.0016823494306175

Epoch: 5| Step: 10
Training loss: 1.617236852645874
Validation loss: 1.993192252292428

Epoch: 237| Step: 0
Training loss: 1.8177019357681274
Validation loss: 1.9662656104692848

Epoch: 5| Step: 1
Training loss: 1.597428321838379
Validation loss: 1.9434207716295797

Epoch: 5| Step: 2
Training loss: 1.4258630275726318
Validation loss: 1.9167400854890064

Epoch: 5| Step: 3
Training loss: 1.8198779821395874
Validation loss: 1.9287919382895193

Epoch: 5| Step: 4
Training loss: 1.6314834356307983
Validation loss: 1.9251959029064383

Epoch: 5| Step: 5
Training loss: 1.5898977518081665
Validation loss: 1.9539180263396232

Epoch: 5| Step: 6
Training loss: 1.58123779296875
Validation loss: 1.9857281279820267

Epoch: 5| Step: 7
Training loss: 1.3058395385742188
Validation loss: 2.0378538241950412

Epoch: 5| Step: 8
Training loss: 1.209795355796814
Validation loss: 2.0536041336674846

Epoch: 5| Step: 9
Training loss: 1.572968602180481
Validation loss: 2.076281992338037

Epoch: 5| Step: 10
Training loss: 1.23067307472229
Validation loss: 2.08094427662511

Epoch: 238| Step: 0
Training loss: 1.0516501665115356
Validation loss: 2.0838930299205165

Epoch: 5| Step: 1
Training loss: 1.9734306335449219
Validation loss: 2.054692109425863

Epoch: 5| Step: 2
Training loss: 1.2151527404785156
Validation loss: 1.9956445206878006

Epoch: 5| Step: 3
Training loss: 2.069607734680176
Validation loss: 1.9785554742300382

Epoch: 5| Step: 4
Training loss: 1.5545718669891357
Validation loss: 1.9459314859041603

Epoch: 5| Step: 5
Training loss: 1.285010576248169
Validation loss: 1.9585910663809827

Epoch: 5| Step: 6
Training loss: 1.4936237335205078
Validation loss: 1.9679362184257918

Epoch: 5| Step: 7
Training loss: 1.2620089054107666
Validation loss: 2.0168081201532835

Epoch: 5| Step: 8
Training loss: 1.5851762294769287
Validation loss: 2.066062286335935

Epoch: 5| Step: 9
Training loss: 1.5858083963394165
Validation loss: 2.0780081274688884

Epoch: 5| Step: 10
Training loss: 1.8256160020828247
Validation loss: 2.082943533056526

Epoch: 239| Step: 0
Training loss: 1.7445099353790283
Validation loss: 2.048883125346194

Epoch: 5| Step: 1
Training loss: 1.166130781173706
Validation loss: 2.0258452123211277

Epoch: 5| Step: 2
Training loss: 1.4759266376495361
Validation loss: 2.021150440298101

Epoch: 5| Step: 3
Training loss: 1.7021934986114502
Validation loss: 2.0464406026306974

Epoch: 5| Step: 4
Training loss: 1.4940001964569092
Validation loss: 2.0425599928825133

Epoch: 5| Step: 5
Training loss: 1.5461535453796387
Validation loss: 2.043233363859115

Epoch: 5| Step: 6
Training loss: 1.0841132402420044
Validation loss: 2.006303867986125

Epoch: 5| Step: 7
Training loss: 1.5807030200958252
Validation loss: 1.979260883023662

Epoch: 5| Step: 8
Training loss: 1.8183702230453491
Validation loss: 1.9773434310831048

Epoch: 5| Step: 9
Training loss: 1.8244644403457642
Validation loss: 1.9944734291363788

Epoch: 5| Step: 10
Training loss: 1.206825613975525
Validation loss: 1.9771045882214782

Epoch: 240| Step: 0
Training loss: 1.5871788263320923
Validation loss: 1.9944066937251756

Epoch: 5| Step: 1
Training loss: 0.8535332679748535
Validation loss: 1.9792313768017677

Epoch: 5| Step: 2
Training loss: 1.5950496196746826
Validation loss: 1.9900478586073844

Epoch: 5| Step: 3
Training loss: 1.6344562768936157
Validation loss: 2.000816704124533

Epoch: 5| Step: 4
Training loss: 1.4525028467178345
Validation loss: 2.0006988817645657

Epoch: 5| Step: 5
Training loss: 1.9681819677352905
Validation loss: 1.991947445818173

Epoch: 5| Step: 6
Training loss: 1.4755622148513794
Validation loss: 2.004066574958063

Epoch: 5| Step: 7
Training loss: 1.607642412185669
Validation loss: 2.021695060114707

Epoch: 5| Step: 8
Training loss: 1.1271531581878662
Validation loss: 1.970872361172912

Epoch: 5| Step: 9
Training loss: 1.232295274734497
Validation loss: 1.9757062273640786

Epoch: 5| Step: 10
Training loss: 1.6011139154434204
Validation loss: 1.9574320957224856

Epoch: 241| Step: 0
Training loss: 0.9275414347648621
Validation loss: 1.9652195002443047

Epoch: 5| Step: 1
Training loss: 1.3779733180999756
Validation loss: 1.981609329100578

Epoch: 5| Step: 2
Training loss: 1.6036157608032227
Validation loss: 2.0148490205887826

Epoch: 5| Step: 3
Training loss: 1.513359546661377
Validation loss: 2.016774182678551

Epoch: 5| Step: 4
Training loss: 1.371131181716919
Validation loss: 2.0214107062226985

Epoch: 5| Step: 5
Training loss: 1.5925865173339844
Validation loss: 2.0233053071524507

Epoch: 5| Step: 6
Training loss: 1.7655776739120483
Validation loss: 2.0010682305982037

Epoch: 5| Step: 7
Training loss: 1.2537205219268799
Validation loss: 2.014066452621132

Epoch: 5| Step: 8
Training loss: 1.28585684299469
Validation loss: 1.9981222844892932

Epoch: 5| Step: 9
Training loss: 1.3639519214630127
Validation loss: 2.0243051564821632

Epoch: 5| Step: 10
Training loss: 1.9272247552871704
Validation loss: 2.0097146470059633

Epoch: 242| Step: 0
Training loss: 1.1479976177215576
Validation loss: 2.0293199528930006

Epoch: 5| Step: 1
Training loss: 1.8041636943817139
Validation loss: 1.9811859489769064

Epoch: 5| Step: 2
Training loss: 1.396704912185669
Validation loss: 1.966474530517414

Epoch: 5| Step: 3
Training loss: 0.9810706973075867
Validation loss: 1.953417585742089

Epoch: 5| Step: 4
Training loss: 1.4191855192184448
Validation loss: 1.9395201257480088

Epoch: 5| Step: 5
Training loss: 1.4953209161758423
Validation loss: 1.9656487357231878

Epoch: 5| Step: 6
Training loss: 1.6204378604888916
Validation loss: 1.967540192347701

Epoch: 5| Step: 7
Training loss: 1.5203113555908203
Validation loss: 1.9674091031474452

Epoch: 5| Step: 8
Training loss: 1.6003153324127197
Validation loss: 1.9545884696386193

Epoch: 5| Step: 9
Training loss: 1.6396167278289795
Validation loss: 1.9573791193705734

Epoch: 5| Step: 10
Training loss: 0.9974913001060486
Validation loss: 1.9642082850138347

Epoch: 243| Step: 0
Training loss: 0.9242966771125793
Validation loss: 1.971066085241174

Epoch: 5| Step: 1
Training loss: 1.7145359516143799
Validation loss: 1.9897374478719567

Epoch: 5| Step: 2
Training loss: 1.2168221473693848
Validation loss: 1.983317316219371

Epoch: 5| Step: 3
Training loss: 1.5003098249435425
Validation loss: 2.0031999182957474

Epoch: 5| Step: 4
Training loss: 1.4315540790557861
Validation loss: 1.9793742831035326

Epoch: 5| Step: 5
Training loss: 1.7193527221679688
Validation loss: 1.985174673859791

Epoch: 5| Step: 6
Training loss: 1.5968408584594727
Validation loss: 2.0062758332939556

Epoch: 5| Step: 7
Training loss: 1.3561556339263916
Validation loss: 2.002774025804253

Epoch: 5| Step: 8
Training loss: 1.2675895690917969
Validation loss: 1.9974514207532328

Epoch: 5| Step: 9
Training loss: 1.620436429977417
Validation loss: 2.0102116189977175

Epoch: 5| Step: 10
Training loss: 1.4827710390090942
Validation loss: 1.9958376935733262

Epoch: 244| Step: 0
Training loss: 1.797076940536499
Validation loss: 2.0012034523871636

Epoch: 5| Step: 1
Training loss: 1.3756916522979736
Validation loss: 1.9897387053376885

Epoch: 5| Step: 2
Training loss: 1.422121286392212
Validation loss: 2.0082499622016825

Epoch: 5| Step: 3
Training loss: 1.453033685684204
Validation loss: 2.0069920452692176

Epoch: 5| Step: 4
Training loss: 1.4628387689590454
Validation loss: 2.020273165036273

Epoch: 5| Step: 5
Training loss: 1.3944305181503296
Validation loss: 2.022832921756211

Epoch: 5| Step: 6
Training loss: 1.1798311471939087
Validation loss: 2.0276722036382204

Epoch: 5| Step: 7
Training loss: 1.2558488845825195
Validation loss: 2.0219973261638353

Epoch: 5| Step: 8
Training loss: 1.5679702758789062
Validation loss: 2.059397973040099

Epoch: 5| Step: 9
Training loss: 1.507432460784912
Validation loss: 2.036396182993407

Epoch: 5| Step: 10
Training loss: 0.9528448581695557
Validation loss: 2.0307384652476155

Epoch: 245| Step: 0
Training loss: 1.0631625652313232
Validation loss: 2.0038650317858626

Epoch: 5| Step: 1
Training loss: 1.100162386894226
Validation loss: 1.9647181200724777

Epoch: 5| Step: 2
Training loss: 1.208162784576416
Validation loss: 1.9702461483658

Epoch: 5| Step: 3
Training loss: 1.0675990581512451
Validation loss: 1.9661052842294016

Epoch: 5| Step: 4
Training loss: 1.174438714981079
Validation loss: 1.9531381014854676

Epoch: 5| Step: 5
Training loss: 1.389190435409546
Validation loss: 1.9515271955920803

Epoch: 5| Step: 6
Training loss: 1.4205265045166016
Validation loss: 1.9559321275321386

Epoch: 5| Step: 7
Training loss: 1.709207534790039
Validation loss: 1.971331678411012

Epoch: 5| Step: 8
Training loss: 1.5347974300384521
Validation loss: 1.9855338988765594

Epoch: 5| Step: 9
Training loss: 1.7489147186279297
Validation loss: 2.0199271658415436

Epoch: 5| Step: 10
Training loss: 1.7772990465164185
Validation loss: 1.9940517743428547

Epoch: 246| Step: 0
Training loss: 1.6063235998153687
Validation loss: 1.9741852539841847

Epoch: 5| Step: 1
Training loss: 1.573563575744629
Validation loss: 1.9679481790911766

Epoch: 5| Step: 2
Training loss: 1.0091480016708374
Validation loss: 1.9552390293408466

Epoch: 5| Step: 3
Training loss: 1.4798557758331299
Validation loss: 1.9592598138316986

Epoch: 5| Step: 4
Training loss: 1.4165065288543701
Validation loss: 1.9633414360784716

Epoch: 5| Step: 5
Training loss: 0.9972777366638184
Validation loss: 1.9703875639105355

Epoch: 5| Step: 6
Training loss: 1.248487949371338
Validation loss: 1.9846772557945662

Epoch: 5| Step: 7
Training loss: 1.768139123916626
Validation loss: 2.011949849385087

Epoch: 5| Step: 8
Training loss: 1.2749831676483154
Validation loss: 1.9999867152142268

Epoch: 5| Step: 9
Training loss: 1.2313047647476196
Validation loss: 1.982639071761921

Epoch: 5| Step: 10
Training loss: 1.4672576189041138
Validation loss: 1.9688370529041495

Epoch: 247| Step: 0
Training loss: 1.5896281003952026
Validation loss: 1.9629226615352016

Epoch: 5| Step: 1
Training loss: 1.9700924158096313
Validation loss: 1.9381456439213087

Epoch: 5| Step: 2
Training loss: 1.0291682481765747
Validation loss: 1.9352079488897835

Epoch: 5| Step: 3
Training loss: 1.3064106702804565
Validation loss: 1.9301098469764955

Epoch: 5| Step: 4
Training loss: 1.5684106349945068
Validation loss: 1.9438202099133564

Epoch: 5| Step: 5
Training loss: 1.3617805242538452
Validation loss: 1.944468972503498

Epoch: 5| Step: 6
Training loss: 1.5254138708114624
Validation loss: 1.942164336481402

Epoch: 5| Step: 7
Training loss: 1.1426786184310913
Validation loss: 1.9709868969455842

Epoch: 5| Step: 8
Training loss: 0.9678847193717957
Validation loss: 2.015962573789781

Epoch: 5| Step: 9
Training loss: 1.275922417640686
Validation loss: 2.0562167398391233

Epoch: 5| Step: 10
Training loss: 1.2574920654296875
Validation loss: 2.05513435025369

Epoch: 248| Step: 0
Training loss: 1.8284895420074463
Validation loss: 2.051220845150691

Epoch: 5| Step: 1
Training loss: 1.1891520023345947
Validation loss: 2.014055367439024

Epoch: 5| Step: 2
Training loss: 1.3851397037506104
Validation loss: 1.986522392560077

Epoch: 5| Step: 3
Training loss: 0.8158544301986694
Validation loss: 1.9876598183826735

Epoch: 5| Step: 4
Training loss: 1.1289966106414795
Validation loss: 1.939468869598963

Epoch: 5| Step: 5
Training loss: 1.6956980228424072
Validation loss: 1.955619945321032

Epoch: 5| Step: 6
Training loss: 1.4810429811477661
Validation loss: 1.9541822723163071

Epoch: 5| Step: 7
Training loss: 1.1944873332977295
Validation loss: 1.9675789187031407

Epoch: 5| Step: 8
Training loss: 1.3369548320770264
Validation loss: 1.9446722781786354

Epoch: 5| Step: 9
Training loss: 1.7734897136688232
Validation loss: 1.9402023361575218

Epoch: 5| Step: 10
Training loss: 1.1217669248580933
Validation loss: 1.9191676634614185

Epoch: 249| Step: 0
Training loss: 1.224156141281128
Validation loss: 1.9115503577775852

Epoch: 5| Step: 1
Training loss: 1.0680794715881348
Validation loss: 1.9307001047236945

Epoch: 5| Step: 2
Training loss: 1.3364002704620361
Validation loss: 1.9605168834809334

Epoch: 5| Step: 3
Training loss: 1.3289577960968018
Validation loss: 2.0114028889645814

Epoch: 5| Step: 4
Training loss: 1.518794298171997
Validation loss: 2.0245411037116923

Epoch: 5| Step: 5
Training loss: 1.2843073606491089
Validation loss: 2.0078170337984638

Epoch: 5| Step: 6
Training loss: 1.1816809177398682
Validation loss: 2.005250400112521

Epoch: 5| Step: 7
Training loss: 1.6715497970581055
Validation loss: 1.978115015132453

Epoch: 5| Step: 8
Training loss: 1.6106380224227905
Validation loss: 1.9418811567368046

Epoch: 5| Step: 9
Training loss: 1.2594201564788818
Validation loss: 1.9297892316695182

Epoch: 5| Step: 10
Training loss: 1.2153974771499634
Validation loss: 1.926852600548857

Epoch: 250| Step: 0
Training loss: 1.8673759698867798
Validation loss: 1.9131743446473153

Epoch: 5| Step: 1
Training loss: 1.3698413372039795
Validation loss: 1.9147649221522833

Epoch: 5| Step: 2
Training loss: 2.0798873901367188
Validation loss: 1.9223909877961682

Epoch: 5| Step: 3
Training loss: 1.0425163507461548
Validation loss: 1.9450010561173963

Epoch: 5| Step: 4
Training loss: 1.3532001972198486
Validation loss: 1.9619259116470174

Epoch: 5| Step: 5
Training loss: 1.533164620399475
Validation loss: 1.9481553723735194

Epoch: 5| Step: 6
Training loss: 0.9599708318710327
Validation loss: 1.9505212050612255

Epoch: 5| Step: 7
Training loss: 1.0067187547683716
Validation loss: 1.934165354697935

Epoch: 5| Step: 8
Training loss: 1.48170804977417
Validation loss: 1.9390774926831644

Epoch: 5| Step: 9
Training loss: 1.1717166900634766
Validation loss: 1.9332616572738976

Epoch: 5| Step: 10
Training loss: 0.8604035377502441
Validation loss: 1.9311683652221516

Epoch: 251| Step: 0
Training loss: 1.216703176498413
Validation loss: 1.9347338599543418

Epoch: 5| Step: 1
Training loss: 1.3850866556167603
Validation loss: 1.962605522524926

Epoch: 5| Step: 2
Training loss: 0.6498050689697266
Validation loss: 1.9763317313245548

Epoch: 5| Step: 3
Training loss: 0.8306018710136414
Validation loss: 2.0104683983710503

Epoch: 5| Step: 4
Training loss: 1.4470713138580322
Validation loss: 1.998259566163504

Epoch: 5| Step: 5
Training loss: 1.5573365688323975
Validation loss: 2.0157661655897736

Epoch: 5| Step: 6
Training loss: 1.296204924583435
Validation loss: 1.9767853034439908

Epoch: 5| Step: 7
Training loss: 1.1328843832015991
Validation loss: 1.9749326090658865

Epoch: 5| Step: 8
Training loss: 1.7333768606185913
Validation loss: 1.970805275824762

Epoch: 5| Step: 9
Training loss: 1.479637861251831
Validation loss: 1.9672773371460617

Epoch: 5| Step: 10
Training loss: 1.5346248149871826
Validation loss: 1.9496808487881896

Epoch: 252| Step: 0
Training loss: 1.6739835739135742
Validation loss: 1.926050316902899

Epoch: 5| Step: 1
Training loss: 0.9570320844650269
Validation loss: 1.9377498626708984

Epoch: 5| Step: 2
Training loss: 0.8311129808425903
Validation loss: 1.9288506046418221

Epoch: 5| Step: 3
Training loss: 1.3472344875335693
Validation loss: 1.9576897646791191

Epoch: 5| Step: 4
Training loss: 1.2045470476150513
Validation loss: 2.0077037170369136

Epoch: 5| Step: 5
Training loss: 1.3456066846847534
Validation loss: 2.009249182157619

Epoch: 5| Step: 6
Training loss: 1.0332355499267578
Validation loss: 2.0428422958620134

Epoch: 5| Step: 7
Training loss: 1.36470627784729
Validation loss: 2.0772239777349655

Epoch: 5| Step: 8
Training loss: 1.6236846446990967
Validation loss: 2.0742476063389934

Epoch: 5| Step: 9
Training loss: 1.3660335540771484
Validation loss: 1.9877662825328049

Epoch: 5| Step: 10
Training loss: 2.1029465198516846
Validation loss: 1.9228773373429493

Epoch: 253| Step: 0
Training loss: 1.2024884223937988
Validation loss: 1.904999327915971

Epoch: 5| Step: 1
Training loss: 1.0697888135910034
Validation loss: 1.8955052898776146

Epoch: 5| Step: 2
Training loss: 1.2369511127471924
Validation loss: 1.8789463735395862

Epoch: 5| Step: 3
Training loss: 1.8822005987167358
Validation loss: 1.897629730163082

Epoch: 5| Step: 4
Training loss: 1.698487639427185
Validation loss: 1.937199325971706

Epoch: 5| Step: 5
Training loss: 1.3368139266967773
Validation loss: 2.001756347635741

Epoch: 5| Step: 6
Training loss: 1.0651609897613525
Validation loss: 2.0311022766174807

Epoch: 5| Step: 7
Training loss: 1.2255806922912598
Validation loss: 2.018321068056168

Epoch: 5| Step: 8
Training loss: 1.3446273803710938
Validation loss: 2.0049813896097164

Epoch: 5| Step: 9
Training loss: 1.1939427852630615
Validation loss: 1.9472302262501051

Epoch: 5| Step: 10
Training loss: 1.1720119714736938
Validation loss: 1.9051259973997712

Epoch: 254| Step: 0
Training loss: 1.2373371124267578
Validation loss: 1.9286599928332913

Epoch: 5| Step: 1
Training loss: 1.6234188079833984
Validation loss: 1.928381525060182

Epoch: 5| Step: 2
Training loss: 1.1162965297698975
Validation loss: 1.9090887628575808

Epoch: 5| Step: 3
Training loss: 1.5217840671539307
Validation loss: 1.9023426296890422

Epoch: 5| Step: 4
Training loss: 1.3420031070709229
Validation loss: 1.9199627778863395

Epoch: 5| Step: 5
Training loss: 1.1316404342651367
Validation loss: 1.9266369009530673

Epoch: 5| Step: 6
Training loss: 1.0249226093292236
Validation loss: 1.9459122086084017

Epoch: 5| Step: 7
Training loss: 1.6614068746566772
Validation loss: 1.9674473731748519

Epoch: 5| Step: 8
Training loss: 1.4194749593734741
Validation loss: 1.9883151285109981

Epoch: 5| Step: 9
Training loss: 1.580661416053772
Validation loss: 1.9994231295841995

Epoch: 5| Step: 10
Training loss: 1.0457768440246582
Validation loss: 1.9866533817783478

Epoch: 255| Step: 0
Training loss: 1.0210849046707153
Validation loss: 1.9495216492683656

Epoch: 5| Step: 1
Training loss: 0.9532868266105652
Validation loss: 1.9396054680629442

Epoch: 5| Step: 2
Training loss: 1.0491693019866943
Validation loss: 1.940538183335335

Epoch: 5| Step: 3
Training loss: 1.599645733833313
Validation loss: 1.9521903991699219

Epoch: 5| Step: 4
Training loss: 1.240727186203003
Validation loss: 1.9845881885097874

Epoch: 5| Step: 5
Training loss: 1.4865888357162476
Validation loss: 2.0241734058626237

Epoch: 5| Step: 6
Training loss: 1.378418207168579
Validation loss: 2.033889789735117

Epoch: 5| Step: 7
Training loss: 1.6075035333633423
Validation loss: 2.0312036660409745

Epoch: 5| Step: 8
Training loss: 1.6377280950546265
Validation loss: 1.9781444739269953

Epoch: 5| Step: 9
Training loss: 1.0693299770355225
Validation loss: 1.9122467489652737

Epoch: 5| Step: 10
Training loss: 1.3541101217269897
Validation loss: 1.8934157856049076

Epoch: 256| Step: 0
Training loss: 1.0863429307937622
Validation loss: 1.899159607066903

Epoch: 5| Step: 1
Training loss: 1.266203761100769
Validation loss: 1.9174676582377443

Epoch: 5| Step: 2
Training loss: 0.931950569152832
Validation loss: 1.9279977390843053

Epoch: 5| Step: 3
Training loss: 1.6641508340835571
Validation loss: 1.9414030313491821

Epoch: 5| Step: 4
Training loss: 1.560144066810608
Validation loss: 1.9492419714568763

Epoch: 5| Step: 5
Training loss: 1.4241983890533447
Validation loss: 1.9399620384298346

Epoch: 5| Step: 6
Training loss: 1.2695093154907227
Validation loss: 1.9547573007563108

Epoch: 5| Step: 7
Training loss: 1.4774534702301025
Validation loss: 2.010415795028851

Epoch: 5| Step: 8
Training loss: 1.2129032611846924
Validation loss: 2.0705733760710685

Epoch: 5| Step: 9
Training loss: 1.3792363405227661
Validation loss: 2.0379363247143325

Epoch: 5| Step: 10
Training loss: 1.5946645736694336
Validation loss: 2.013783401058566

Epoch: 257| Step: 0
Training loss: 1.1205871105194092
Validation loss: 1.9653117323434481

Epoch: 5| Step: 1
Training loss: 1.0850627422332764
Validation loss: 1.9480236627722298

Epoch: 5| Step: 2
Training loss: 1.5708556175231934
Validation loss: 1.935425071306126

Epoch: 5| Step: 3
Training loss: 1.6929473876953125
Validation loss: 1.964484368601153

Epoch: 5| Step: 4
Training loss: 1.2468466758728027
Validation loss: 1.9552887383327688

Epoch: 5| Step: 5
Training loss: 1.043433427810669
Validation loss: 1.950392315464635

Epoch: 5| Step: 6
Training loss: 1.3106107711791992
Validation loss: 1.9711114950077508

Epoch: 5| Step: 7
Training loss: 1.8052196502685547
Validation loss: 1.9559798330389044

Epoch: 5| Step: 8
Training loss: 1.4935821294784546
Validation loss: 1.9481221040089924

Epoch: 5| Step: 9
Training loss: 1.0514404773712158
Validation loss: 1.9356117530535626

Epoch: 5| Step: 10
Training loss: 1.0245981216430664
Validation loss: 1.9363145597519413

Epoch: 258| Step: 0
Training loss: 0.9942755699157715
Validation loss: 1.9334772120239914

Epoch: 5| Step: 1
Training loss: 1.1435703039169312
Validation loss: 1.956742630209974

Epoch: 5| Step: 2
Training loss: 0.7917232513427734
Validation loss: 1.9268342730819539

Epoch: 5| Step: 3
Training loss: 1.2340315580368042
Validation loss: 1.926845609500844

Epoch: 5| Step: 4
Training loss: 1.0416412353515625
Validation loss: 1.9259819087161814

Epoch: 5| Step: 5
Training loss: 0.7238126993179321
Validation loss: 1.9339263259723622

Epoch: 5| Step: 6
Training loss: 1.7755439281463623
Validation loss: 1.9495401613173946

Epoch: 5| Step: 7
Training loss: 1.4572036266326904
Validation loss: 1.9445092331978582

Epoch: 5| Step: 8
Training loss: 1.68376886844635
Validation loss: 1.9683080283544396

Epoch: 5| Step: 9
Training loss: 1.8160984516143799
Validation loss: 1.9522845155449324

Epoch: 5| Step: 10
Training loss: 0.8351039886474609
Validation loss: 1.9056256714687552

Epoch: 259| Step: 0
Training loss: 0.8334671854972839
Validation loss: 1.8986850912852953

Epoch: 5| Step: 1
Training loss: 1.4935779571533203
Validation loss: 1.9225003514238583

Epoch: 5| Step: 2
Training loss: 1.1500709056854248
Validation loss: 1.9357507498033586

Epoch: 5| Step: 3
Training loss: 1.1227872371673584
Validation loss: 1.95321483765879

Epoch: 5| Step: 4
Training loss: 1.3206884860992432
Validation loss: 1.94024444395496

Epoch: 5| Step: 5
Training loss: 1.2905447483062744
Validation loss: 1.908778598231654

Epoch: 5| Step: 6
Training loss: 1.2690117359161377
Validation loss: 1.907366152732603

Epoch: 5| Step: 7
Training loss: 1.3513864278793335
Validation loss: 1.8966973879004037

Epoch: 5| Step: 8
Training loss: 1.4868220090866089
Validation loss: 1.902662331058133

Epoch: 5| Step: 9
Training loss: 1.1812440156936646
Validation loss: 1.9000895612983293

Epoch: 5| Step: 10
Training loss: 0.892794132232666
Validation loss: 1.9072048779456847

Epoch: 260| Step: 0
Training loss: 1.2608426809310913
Validation loss: 1.9694377030095747

Epoch: 5| Step: 1
Training loss: 1.2219178676605225
Validation loss: 1.9991783236944547

Epoch: 5| Step: 2
Training loss: 1.5211069583892822
Validation loss: 2.01665057546349

Epoch: 5| Step: 3
Training loss: 1.296576976776123
Validation loss: 1.9804718366233252

Epoch: 5| Step: 4
Training loss: 0.890750527381897
Validation loss: 1.9223077399756319

Epoch: 5| Step: 5
Training loss: 0.8960976600646973
Validation loss: 1.8802290116586993

Epoch: 5| Step: 6
Training loss: 1.1941999197006226
Validation loss: 1.8882765308503182

Epoch: 5| Step: 7
Training loss: 1.4140636920928955
Validation loss: 1.9181531936891618

Epoch: 5| Step: 8
Training loss: 1.3014885187149048
Validation loss: 1.963295857111613

Epoch: 5| Step: 9
Training loss: 1.7962948083877563
Validation loss: 2.0029704211860575

Epoch: 5| Step: 10
Training loss: 1.3306550979614258
Validation loss: 2.015710107741817

Epoch: 261| Step: 0
Training loss: 1.0169422626495361
Validation loss: 1.9914798300753358

Epoch: 5| Step: 1
Training loss: 1.3293031454086304
Validation loss: 1.986130235015705

Epoch: 5| Step: 2
Training loss: 0.8923624157905579
Validation loss: 1.943688481084762

Epoch: 5| Step: 3
Training loss: 1.2032629251480103
Validation loss: 1.9288106426115958

Epoch: 5| Step: 4
Training loss: 1.2783496379852295
Validation loss: 1.9216215764322588

Epoch: 5| Step: 5
Training loss: 1.2214875221252441
Validation loss: 1.9334653680042555

Epoch: 5| Step: 6
Training loss: 0.9595632553100586
Validation loss: 1.9304314813306254

Epoch: 5| Step: 7
Training loss: 1.0848444700241089
Validation loss: 1.936421581493911

Epoch: 5| Step: 8
Training loss: 1.9484533071517944
Validation loss: 1.9307875056420603

Epoch: 5| Step: 9
Training loss: 1.1150308847427368
Validation loss: 1.9118549887852003

Epoch: 5| Step: 10
Training loss: 1.4978631734848022
Validation loss: 1.9027044029646023

Epoch: 262| Step: 0
Training loss: 0.8867179155349731
Validation loss: 1.9030267602653914

Epoch: 5| Step: 1
Training loss: 1.476783037185669
Validation loss: 1.92964724058746

Epoch: 5| Step: 2
Training loss: 1.1000226736068726
Validation loss: 1.960198487004926

Epoch: 5| Step: 3
Training loss: 0.982333779335022
Validation loss: 1.9946242301694808

Epoch: 5| Step: 4
Training loss: 1.798774003982544
Validation loss: 1.9846330893936979

Epoch: 5| Step: 5
Training loss: 1.1753947734832764
Validation loss: 1.9654114502732472

Epoch: 5| Step: 6
Training loss: 1.4411360025405884
Validation loss: 1.9379522095444381

Epoch: 5| Step: 7
Training loss: 1.7852067947387695
Validation loss: 1.8775272715476252

Epoch: 5| Step: 8
Training loss: 0.8816181421279907
Validation loss: 1.8725905251759354

Epoch: 5| Step: 9
Training loss: 0.7525771856307983
Validation loss: 1.8687155349280244

Epoch: 5| Step: 10
Training loss: 0.943862795829773
Validation loss: 1.8559130955767889

Epoch: 263| Step: 0
Training loss: 1.184036374092102
Validation loss: 1.8568726765212191

Epoch: 5| Step: 1
Training loss: 1.1903949975967407
Validation loss: 1.9014385707916752

Epoch: 5| Step: 2
Training loss: 1.250393271446228
Validation loss: 1.9329357390762658

Epoch: 5| Step: 3
Training loss: 1.5929702520370483
Validation loss: 1.9610151116565993

Epoch: 5| Step: 4
Training loss: 1.2576935291290283
Validation loss: 1.930800178999542

Epoch: 5| Step: 5
Training loss: 1.0534310340881348
Validation loss: 1.8875690737078268

Epoch: 5| Step: 6
Training loss: 0.8835433125495911
Validation loss: 1.8878350591146817

Epoch: 5| Step: 7
Training loss: 1.3807594776153564
Validation loss: 1.8871822472541564

Epoch: 5| Step: 8
Training loss: 1.0731514692306519
Validation loss: 1.897683879380585

Epoch: 5| Step: 9
Training loss: 1.377493143081665
Validation loss: 1.8871897343666322

Epoch: 5| Step: 10
Training loss: 1.117208480834961
Validation loss: 1.9107755614865212

Epoch: 264| Step: 0
Training loss: 1.133152961730957
Validation loss: 1.932286730376623

Epoch: 5| Step: 1
Training loss: 1.1123515367507935
Validation loss: 1.956399590738358

Epoch: 5| Step: 2
Training loss: 1.5744900703430176
Validation loss: 1.966780747136762

Epoch: 5| Step: 3
Training loss: 1.223361611366272
Validation loss: 1.977327489083813

Epoch: 5| Step: 4
Training loss: 1.001086711883545
Validation loss: 1.9484454739478327

Epoch: 5| Step: 5
Training loss: 1.1415283679962158
Validation loss: 1.9343233326429963

Epoch: 5| Step: 6
Training loss: 1.1698757410049438
Validation loss: 1.875011169782249

Epoch: 5| Step: 7
Training loss: 1.5480706691741943
Validation loss: 1.8600910261113157

Epoch: 5| Step: 8
Training loss: 1.0053565502166748
Validation loss: 1.8567146306396813

Epoch: 5| Step: 9
Training loss: 1.1297614574432373
Validation loss: 1.8650968561890304

Epoch: 5| Step: 10
Training loss: 1.1135892868041992
Validation loss: 1.9306468540622341

Epoch: 265| Step: 0
Training loss: 0.8851214647293091
Validation loss: 1.9474587748127599

Epoch: 5| Step: 1
Training loss: 1.6697204113006592
Validation loss: 1.9631709360307263

Epoch: 5| Step: 2
Training loss: 1.14908766746521
Validation loss: 1.9813958291084535

Epoch: 5| Step: 3
Training loss: 1.0569546222686768
Validation loss: 1.997395646187567

Epoch: 5| Step: 4
Training loss: 1.3294453620910645
Validation loss: 1.9797327185189852

Epoch: 5| Step: 5
Training loss: 1.0801500082015991
Validation loss: 1.9606791260421916

Epoch: 5| Step: 6
Training loss: 1.2006986141204834
Validation loss: 1.921142662725141

Epoch: 5| Step: 7
Training loss: 0.6999424695968628
Validation loss: 1.886861853702094

Epoch: 5| Step: 8
Training loss: 0.934963047504425
Validation loss: 1.8748976081930182

Epoch: 5| Step: 9
Training loss: 1.22883141040802
Validation loss: 1.8629717929388887

Epoch: 5| Step: 10
Training loss: 1.4671869277954102
Validation loss: 1.873088208577966

Epoch: 266| Step: 0
Training loss: 0.8680084943771362
Validation loss: 1.8484527295635593

Epoch: 5| Step: 1
Training loss: 1.1073757410049438
Validation loss: 1.8718994971244567

Epoch: 5| Step: 2
Training loss: 1.5800968408584595
Validation loss: 1.8655625786832584

Epoch: 5| Step: 3
Training loss: 0.5754935145378113
Validation loss: 1.8499741528623848

Epoch: 5| Step: 4
Training loss: 0.9946449995040894
Validation loss: 1.8902828488298642

Epoch: 5| Step: 5
Training loss: 1.2218797206878662
Validation loss: 1.929998678545798

Epoch: 5| Step: 6
Training loss: 1.5578277111053467
Validation loss: 1.9368431337418095

Epoch: 5| Step: 7
Training loss: 1.2061147689819336
Validation loss: 1.9315984223478584

Epoch: 5| Step: 8
Training loss: 1.3702220916748047
Validation loss: 1.920154017786826

Epoch: 5| Step: 9
Training loss: 1.0029284954071045
Validation loss: 1.9037069210442163

Epoch: 5| Step: 10
Training loss: 1.0724682807922363
Validation loss: 1.88034454981486

Epoch: 267| Step: 0
Training loss: 1.156700849533081
Validation loss: 1.9008354140866188

Epoch: 5| Step: 1
Training loss: 0.8679376840591431
Validation loss: 1.8991601479950773

Epoch: 5| Step: 2
Training loss: 1.0523650646209717
Validation loss: 1.8946580630476757

Epoch: 5| Step: 3
Training loss: 1.0045305490493774
Validation loss: 1.9013579481391496

Epoch: 5| Step: 4
Training loss: 1.3955234289169312
Validation loss: 1.914736368322885

Epoch: 5| Step: 5
Training loss: 1.0575329065322876
Validation loss: 1.8897353372266215

Epoch: 5| Step: 6
Training loss: 0.973628044128418
Validation loss: 1.9188866846023067

Epoch: 5| Step: 7
Training loss: 0.8516157269477844
Validation loss: 1.8975556383850753

Epoch: 5| Step: 8
Training loss: 1.4709162712097168
Validation loss: 1.9072325960282357

Epoch: 5| Step: 9
Training loss: 1.2441914081573486
Validation loss: 1.8747654627728205

Epoch: 5| Step: 10
Training loss: 1.0497632026672363
Validation loss: 1.8734004138618388

Epoch: 268| Step: 0
Training loss: 0.7978185415267944
Validation loss: 1.916729752735425

Epoch: 5| Step: 1
Training loss: 0.99717777967453
Validation loss: 1.9152130106444

Epoch: 5| Step: 2
Training loss: 0.9888799786567688
Validation loss: 1.9377722688900527

Epoch: 5| Step: 3
Training loss: 1.3419501781463623
Validation loss: 1.9356936075354134

Epoch: 5| Step: 4
Training loss: 0.729547381401062
Validation loss: 1.914332930759717

Epoch: 5| Step: 5
Training loss: 0.8710228204727173
Validation loss: 1.9058719681155296

Epoch: 5| Step: 6
Training loss: 1.4395983219146729
Validation loss: 1.896966557348928

Epoch: 5| Step: 7
Training loss: 0.9931899309158325
Validation loss: 1.9089187986107283

Epoch: 5| Step: 8
Training loss: 1.217478632926941
Validation loss: 1.9007134437561035

Epoch: 5| Step: 9
Training loss: 1.6327857971191406
Validation loss: 1.9074574901211647

Epoch: 5| Step: 10
Training loss: 1.3733183145523071
Validation loss: 1.8857915068185458

Epoch: 269| Step: 0
Training loss: 1.1250922679901123
Validation loss: 1.8808826810570174

Epoch: 5| Step: 1
Training loss: 1.6111644506454468
Validation loss: 1.8740895537919895

Epoch: 5| Step: 2
Training loss: 0.8237366676330566
Validation loss: 1.9056497850725729

Epoch: 5| Step: 3
Training loss: 1.2204289436340332
Validation loss: 1.9489846216735018

Epoch: 5| Step: 4
Training loss: 1.0609207153320312
Validation loss: 1.9828550251581336

Epoch: 5| Step: 5
Training loss: 0.8463804125785828
Validation loss: 1.9894348690586705

Epoch: 5| Step: 6
Training loss: 1.1833248138427734
Validation loss: 1.9651214666264032

Epoch: 5| Step: 7
Training loss: 0.811314582824707
Validation loss: 1.9207292372180569

Epoch: 5| Step: 8
Training loss: 0.8306475877761841
Validation loss: 1.8614025423603673

Epoch: 5| Step: 9
Training loss: 1.567362904548645
Validation loss: 1.8281999621340024

Epoch: 5| Step: 10
Training loss: 1.2928047180175781
Validation loss: 1.8361589036962038

Epoch: 270| Step: 0
Training loss: 1.6632152795791626
Validation loss: 1.83518660196694

Epoch: 5| Step: 1
Training loss: 1.1454447507858276
Validation loss: 1.8315566393636888

Epoch: 5| Step: 2
Training loss: 0.5594104528427124
Validation loss: 1.8771795252318024

Epoch: 5| Step: 3
Training loss: 1.6466823816299438
Validation loss: 1.9208913644154866

Epoch: 5| Step: 4
Training loss: 1.4228885173797607
Validation loss: 2.040735710051752

Epoch: 5| Step: 5
Training loss: 0.9400222897529602
Validation loss: 2.0169539631053968

Epoch: 5| Step: 6
Training loss: 1.1501356363296509
Validation loss: 1.96244857388158

Epoch: 5| Step: 7
Training loss: 1.1227303743362427
Validation loss: 1.914555162511846

Epoch: 5| Step: 8
Training loss: 0.5990184545516968
Validation loss: 1.873451143182734

Epoch: 5| Step: 9
Training loss: 0.998255729675293
Validation loss: 1.853555799812399

Epoch: 5| Step: 10
Training loss: 1.128403902053833
Validation loss: 1.828479064408169

Epoch: 271| Step: 0
Training loss: 1.1643234491348267
Validation loss: 1.8510217282079882

Epoch: 5| Step: 1
Training loss: 1.0130807161331177
Validation loss: 1.8898831131637737

Epoch: 5| Step: 2
Training loss: 1.0893526077270508
Validation loss: 1.9181208354170605

Epoch: 5| Step: 3
Training loss: 0.9687772989273071
Validation loss: 1.909296739485956

Epoch: 5| Step: 4
Training loss: 1.1561543941497803
Validation loss: 1.9170068797244821

Epoch: 5| Step: 5
Training loss: 1.1463149785995483
Validation loss: 1.8984477648171045

Epoch: 5| Step: 6
Training loss: 1.035434603691101
Validation loss: 1.869356192568297

Epoch: 5| Step: 7
Training loss: 0.8199256062507629
Validation loss: 1.8654170331134592

Epoch: 5| Step: 8
Training loss: 1.1745331287384033
Validation loss: 1.8324262108854068

Epoch: 5| Step: 9
Training loss: 1.1364336013793945
Validation loss: 1.843471295090132

Epoch: 5| Step: 10
Training loss: 1.189516544342041
Validation loss: 1.848038560600691

Epoch: 272| Step: 0
Training loss: 0.9248837232589722
Validation loss: 1.8450327586102229

Epoch: 5| Step: 1
Training loss: 0.5897537469863892
Validation loss: 1.8611966333081644

Epoch: 5| Step: 2
Training loss: 1.8054157495498657
Validation loss: 1.8901430970879012

Epoch: 5| Step: 3
Training loss: 0.9364434480667114
Validation loss: 1.8697365009656517

Epoch: 5| Step: 4
Training loss: 1.0129433870315552
Validation loss: 1.8624012611245597

Epoch: 5| Step: 5
Training loss: 1.2240421772003174
Validation loss: 1.8397668074536067

Epoch: 5| Step: 6
Training loss: 0.9893795251846313
Validation loss: 1.8315702817773307

Epoch: 5| Step: 7
Training loss: 1.0315848588943481
Validation loss: 1.8365608235841155

Epoch: 5| Step: 8
Training loss: 0.731372058391571
Validation loss: 1.832387464020842

Epoch: 5| Step: 9
Training loss: 0.9901221394538879
Validation loss: 1.8648907728092645

Epoch: 5| Step: 10
Training loss: 1.0852811336517334
Validation loss: 1.8669561416872087

Epoch: 273| Step: 0
Training loss: 1.259971261024475
Validation loss: 1.8925735924833564

Epoch: 5| Step: 1
Training loss: 1.1210509538650513
Validation loss: 1.9224515525243615

Epoch: 5| Step: 2
Training loss: 0.9035739898681641
Validation loss: 1.897086754921944

Epoch: 5| Step: 3
Training loss: 0.9172298312187195
Validation loss: 1.8562754405442106

Epoch: 5| Step: 4
Training loss: 0.8562650680541992
Validation loss: 1.8334084287766488

Epoch: 5| Step: 5
Training loss: 0.8014194369316101
Validation loss: 1.8174253868800339

Epoch: 5| Step: 6
Training loss: 1.0955828428268433
Validation loss: 1.8174595448278612

Epoch: 5| Step: 7
Training loss: 1.5288697481155396
Validation loss: 1.8080766021564443

Epoch: 5| Step: 8
Training loss: 1.1844946146011353
Validation loss: 1.8134958026229695

Epoch: 5| Step: 9
Training loss: 0.9785709381103516
Validation loss: 1.8246459140572497

Epoch: 5| Step: 10
Training loss: 0.9270765781402588
Validation loss: 1.8666766074395948

Epoch: 274| Step: 0
Training loss: 0.8674640655517578
Validation loss: 1.8832670488665182

Epoch: 5| Step: 1
Training loss: 1.2133227586746216
Validation loss: 1.9082852050822268

Epoch: 5| Step: 2
Training loss: 0.7931209802627563
Validation loss: 1.9149437437775314

Epoch: 5| Step: 3
Training loss: 0.8918388485908508
Validation loss: 1.9045224497395177

Epoch: 5| Step: 4
Training loss: 1.3189160823822021
Validation loss: 1.880476474761963

Epoch: 5| Step: 5
Training loss: 1.1020163297653198
Validation loss: 1.8620141936886696

Epoch: 5| Step: 6
Training loss: 1.1567065715789795
Validation loss: 1.8528159536341184

Epoch: 5| Step: 7
Training loss: 1.0301547050476074
Validation loss: 1.818815197995914

Epoch: 5| Step: 8
Training loss: 0.5764352679252625
Validation loss: 1.833183765411377

Epoch: 5| Step: 9
Training loss: 1.5560191869735718
Validation loss: 1.8027949487009356

Epoch: 5| Step: 10
Training loss: 0.6331911087036133
Validation loss: 1.8010960317427112

Epoch: 275| Step: 0
Training loss: 0.905166745185852
Validation loss: 1.819838725110536

Epoch: 5| Step: 1
Training loss: 1.1378395557403564
Validation loss: 1.8353861557540072

Epoch: 5| Step: 2
Training loss: 0.42889493703842163
Validation loss: 1.8373360377486034

Epoch: 5| Step: 3
Training loss: 0.8076403737068176
Validation loss: 1.8317953412250807

Epoch: 5| Step: 4
Training loss: 1.787453055381775
Validation loss: 1.8194178868365545

Epoch: 5| Step: 5
Training loss: 1.1773269176483154
Validation loss: 1.8170773111363894

Epoch: 5| Step: 6
Training loss: 0.78993821144104
Validation loss: 1.7994199260588615

Epoch: 5| Step: 7
Training loss: 0.8009419441223145
Validation loss: 1.8161543646166403

Epoch: 5| Step: 8
Training loss: 1.3552922010421753
Validation loss: 1.830467834267565

Epoch: 5| Step: 9
Training loss: 1.0219671726226807
Validation loss: 1.8202151406195857

Epoch: 5| Step: 10
Training loss: 0.8934786319732666
Validation loss: 1.81127578725097

Epoch: 276| Step: 0
Training loss: 0.5631915330886841
Validation loss: 1.8000142112854989

Epoch: 5| Step: 1
Training loss: 0.8543562889099121
Validation loss: 1.8105330236496464

Epoch: 5| Step: 2
Training loss: 0.938517689704895
Validation loss: 1.8274880583568285

Epoch: 5| Step: 3
Training loss: 1.3757776021957397
Validation loss: 1.8554390527868783

Epoch: 5| Step: 4
Training loss: 0.9524386525154114
Validation loss: 1.8605658059479089

Epoch: 5| Step: 5
Training loss: 0.9634668231010437
Validation loss: 1.8996613243574738

Epoch: 5| Step: 6
Training loss: 1.144892930984497
Validation loss: 1.8707243793754167

Epoch: 5| Step: 7
Training loss: 1.1005665063858032
Validation loss: 1.8612654824410715

Epoch: 5| Step: 8
Training loss: 0.9246155023574829
Validation loss: 1.8939608579040856

Epoch: 5| Step: 9
Training loss: 1.3958803415298462
Validation loss: 1.8834786722736974

Epoch: 5| Step: 10
Training loss: 0.9041813015937805
Validation loss: 1.8938294200487034

Epoch: 277| Step: 0
Training loss: 0.7679511308670044
Validation loss: 1.879523036300495

Epoch: 5| Step: 1
Training loss: 0.9763285517692566
Validation loss: 1.8614018296682706

Epoch: 5| Step: 2
Training loss: 1.2150261402130127
Validation loss: 1.8558808193411878

Epoch: 5| Step: 3
Training loss: 1.1325790882110596
Validation loss: 1.825888153045408

Epoch: 5| Step: 4
Training loss: 1.1320972442626953
Validation loss: 1.8252763594350507

Epoch: 5| Step: 5
Training loss: 0.8986572027206421
Validation loss: 1.8194802832859818

Epoch: 5| Step: 6
Training loss: 0.9224271774291992
Validation loss: 1.7896751408935876

Epoch: 5| Step: 7
Training loss: 1.0162928104400635
Validation loss: 1.7789670895504694

Epoch: 5| Step: 8
Training loss: 1.1408629417419434
Validation loss: 1.816366946825417

Epoch: 5| Step: 9
Training loss: 1.2792530059814453
Validation loss: 1.8225687652505853

Epoch: 5| Step: 10
Training loss: 0.8360397219657898
Validation loss: 1.869514024385842

Epoch: 278| Step: 0
Training loss: 1.3203089237213135
Validation loss: 1.9177729468191824

Epoch: 5| Step: 1
Training loss: 1.1297870874404907
Validation loss: 1.948403996805991

Epoch: 5| Step: 2
Training loss: 0.9973286390304565
Validation loss: 1.9605642390507523

Epoch: 5| Step: 3
Training loss: 0.7185717225074768
Validation loss: 1.936203118293516

Epoch: 5| Step: 4
Training loss: 0.9282062649726868
Validation loss: 1.8586957582863428

Epoch: 5| Step: 5
Training loss: 0.9945737719535828
Validation loss: 1.8473882418806835

Epoch: 5| Step: 6
Training loss: 1.095912218093872
Validation loss: 1.811321420054282

Epoch: 5| Step: 7
Training loss: 0.8438680768013
Validation loss: 1.8172672358892297

Epoch: 5| Step: 8
Training loss: 1.1571458578109741
Validation loss: 1.8099878193229757

Epoch: 5| Step: 9
Training loss: 1.291069746017456
Validation loss: 1.8054521083831787

Epoch: 5| Step: 10
Training loss: 0.5296155214309692
Validation loss: 1.8069196208830802

Epoch: 279| Step: 0
Training loss: 1.1165187358856201
Validation loss: 1.8335775957312634

Epoch: 5| Step: 1
Training loss: 1.0889307260513306
Validation loss: 1.8536982741407169

Epoch: 5| Step: 2
Training loss: 0.9186396598815918
Validation loss: 1.871875552720921

Epoch: 5| Step: 3
Training loss: 1.0194518566131592
Validation loss: 1.859533239436406

Epoch: 5| Step: 4
Training loss: 1.034316897392273
Validation loss: 1.8653851965422272

Epoch: 5| Step: 5
Training loss: 0.8401256799697876
Validation loss: 1.8620316815632645

Epoch: 5| Step: 6
Training loss: 1.147216558456421
Validation loss: 1.8487041458006828

Epoch: 5| Step: 7
Training loss: 1.0331202745437622
Validation loss: 1.8563933526315997

Epoch: 5| Step: 8
Training loss: 1.0014402866363525
Validation loss: 1.8688197251289123

Epoch: 5| Step: 9
Training loss: 0.9023450613021851
Validation loss: 1.8410453001658122

Epoch: 5| Step: 10
Training loss: 0.6807834506034851
Validation loss: 1.8454150512654295

Epoch: 280| Step: 0
Training loss: 0.8175603747367859
Validation loss: 1.8543993016724944

Epoch: 5| Step: 1
Training loss: 1.0421456098556519
Validation loss: 1.8606099697851366

Epoch: 5| Step: 2
Training loss: 1.1803982257843018
Validation loss: 1.8498219084996048

Epoch: 5| Step: 3
Training loss: 1.162453055381775
Validation loss: 1.8621623157173075

Epoch: 5| Step: 4
Training loss: 1.2681269645690918
Validation loss: 1.8483157747535295

Epoch: 5| Step: 5
Training loss: 0.7351186871528625
Validation loss: 1.8157147066567534

Epoch: 5| Step: 6
Training loss: 1.09213125705719
Validation loss: 1.8113620896493234

Epoch: 5| Step: 7
Training loss: 0.6660081148147583
Validation loss: 1.783692890597928

Epoch: 5| Step: 8
Training loss: 1.0294992923736572
Validation loss: 1.8059768279393513

Epoch: 5| Step: 9
Training loss: 0.8018134236335754
Validation loss: 1.829733879335465

Epoch: 5| Step: 10
Training loss: 0.9233977198600769
Validation loss: 1.8650449732298493

Epoch: 281| Step: 0
Training loss: 0.7461488842964172
Validation loss: 1.9074023436474543

Epoch: 5| Step: 1
Training loss: 0.9630057215690613
Validation loss: 1.9150524344495548

Epoch: 5| Step: 2
Training loss: 1.1483265161514282
Validation loss: 1.94257559955761

Epoch: 5| Step: 3
Training loss: 0.8089191317558289
Validation loss: 1.9286461414829377

Epoch: 5| Step: 4
Training loss: 0.9065413475036621
Validation loss: 1.8999781198399042

Epoch: 5| Step: 5
Training loss: 1.0641193389892578
Validation loss: 1.8697250350829093

Epoch: 5| Step: 6
Training loss: 1.498137354850769
Validation loss: 1.8512743314107258

Epoch: 5| Step: 7
Training loss: 0.9410400390625
Validation loss: 1.8179374510242092

Epoch: 5| Step: 8
Training loss: 0.9029369354248047
Validation loss: 1.8311963747906428

Epoch: 5| Step: 9
Training loss: 0.6963964700698853
Validation loss: 1.8263497532054942

Epoch: 5| Step: 10
Training loss: 0.9706132411956787
Validation loss: 1.8157956497643584

Epoch: 282| Step: 0
Training loss: 0.8909024000167847
Validation loss: 1.8226807476371847

Epoch: 5| Step: 1
Training loss: 0.9764654040336609
Validation loss: 1.8112261782410324

Epoch: 5| Step: 2
Training loss: 0.8588863611221313
Validation loss: 1.8064581424959245

Epoch: 5| Step: 3
Training loss: 0.6689547896385193
Validation loss: 1.8314880119856967

Epoch: 5| Step: 4
Training loss: 1.5505187511444092
Validation loss: 1.8641174454842844

Epoch: 5| Step: 5
Training loss: 0.9043182134628296
Validation loss: 1.8590175362043484

Epoch: 5| Step: 6
Training loss: 0.8587514758110046
Validation loss: 1.8913502513721425

Epoch: 5| Step: 7
Training loss: 0.8902038335800171
Validation loss: 1.8473679378468504

Epoch: 5| Step: 8
Training loss: 1.0300061702728271
Validation loss: 1.8144769489124257

Epoch: 5| Step: 9
Training loss: 1.0302417278289795
Validation loss: 1.7998638640167892

Epoch: 5| Step: 10
Training loss: 0.9453539252281189
Validation loss: 1.8069588035665534

Epoch: 283| Step: 0
Training loss: 0.7297429442405701
Validation loss: 1.8382715537983885

Epoch: 5| Step: 1
Training loss: 0.9706752896308899
Validation loss: 1.8718806735930904

Epoch: 5| Step: 2
Training loss: 1.1968938112258911
Validation loss: 1.8767424116852462

Epoch: 5| Step: 3
Training loss: 1.022037148475647
Validation loss: 1.8246116676638204

Epoch: 5| Step: 4
Training loss: 0.8422565460205078
Validation loss: 1.846389574389304

Epoch: 5| Step: 5
Training loss: 0.7668930888175964
Validation loss: 1.8476680888924548

Epoch: 5| Step: 6
Training loss: 0.8652821779251099
Validation loss: 1.841270508304719

Epoch: 5| Step: 7
Training loss: 1.2581994533538818
Validation loss: 1.8225299901859735

Epoch: 5| Step: 8
Training loss: 0.9034120440483093
Validation loss: 1.8044290606693556

Epoch: 5| Step: 9
Training loss: 0.9969080090522766
Validation loss: 1.7952819972909906

Epoch: 5| Step: 10
Training loss: 0.8926512598991394
Validation loss: 1.8019877864468483

Epoch: 284| Step: 0
Training loss: 1.4382346868515015
Validation loss: 1.8274135461417578

Epoch: 5| Step: 1
Training loss: 0.6267724633216858
Validation loss: 1.8059857481269426

Epoch: 5| Step: 2
Training loss: 0.9253612756729126
Validation loss: 1.8306292257001322

Epoch: 5| Step: 3
Training loss: 0.9624577760696411
Validation loss: 1.8443967719231882

Epoch: 5| Step: 4
Training loss: 0.8070567846298218
Validation loss: 1.8335891872323968

Epoch: 5| Step: 5
Training loss: 1.1282460689544678
Validation loss: 1.8284885550058017

Epoch: 5| Step: 6
Training loss: 0.7892261743545532
Validation loss: 1.8463901832539549

Epoch: 5| Step: 7
Training loss: 1.056244134902954
Validation loss: 1.8508332134574972

Epoch: 5| Step: 8
Training loss: 0.6634753346443176
Validation loss: 1.8600316816760647

Epoch: 5| Step: 9
Training loss: 1.0548909902572632
Validation loss: 1.8734094237768522

Epoch: 5| Step: 10
Training loss: 1.0495786666870117
Validation loss: 1.877400089335698

Epoch: 285| Step: 0
Training loss: 0.8707343935966492
Validation loss: 1.8621091740105742

Epoch: 5| Step: 1
Training loss: 0.8241165280342102
Validation loss: 1.8397358104746828

Epoch: 5| Step: 2
Training loss: 0.8167665600776672
Validation loss: 1.8312414512839368

Epoch: 5| Step: 3
Training loss: 0.8920534253120422
Validation loss: 1.8185301839664418

Epoch: 5| Step: 4
Training loss: 0.9969752430915833
Validation loss: 1.8377588025985225

Epoch: 5| Step: 5
Training loss: 0.6711597442626953
Validation loss: 1.8383206731529647

Epoch: 5| Step: 6
Training loss: 1.1110308170318604
Validation loss: 1.8136383628332486

Epoch: 5| Step: 7
Training loss: 0.8457967042922974
Validation loss: 1.8250135888335526

Epoch: 5| Step: 8
Training loss: 1.445021390914917
Validation loss: 1.8313784778759044

Epoch: 5| Step: 9
Training loss: 0.7571119070053101
Validation loss: 1.8548905772547568

Epoch: 5| Step: 10
Training loss: 1.3365713357925415
Validation loss: 1.8580719347923034

Epoch: 286| Step: 0
Training loss: 1.2626644372940063
Validation loss: 1.876356396623837

Epoch: 5| Step: 1
Training loss: 0.5817866325378418
Validation loss: 1.8376373449961345

Epoch: 5| Step: 2
Training loss: 0.6443871259689331
Validation loss: 1.847839141404757

Epoch: 5| Step: 3
Training loss: 0.8810791969299316
Validation loss: 1.848051315994673

Epoch: 5| Step: 4
Training loss: 1.243424654006958
Validation loss: 1.8247404226692774

Epoch: 5| Step: 5
Training loss: 0.8652070760726929
Validation loss: 1.8257777690887451

Epoch: 5| Step: 6
Training loss: 0.9380807876586914
Validation loss: 1.8456579139155727

Epoch: 5| Step: 7
Training loss: 1.1891040802001953
Validation loss: 1.8573470500207716

Epoch: 5| Step: 8
Training loss: 0.6490482091903687
Validation loss: 1.8601119133733934

Epoch: 5| Step: 9
Training loss: 0.8992727994918823
Validation loss: 1.865792251402332

Epoch: 5| Step: 10
Training loss: 0.9451942443847656
Validation loss: 1.8599792744523735

Epoch: 287| Step: 0
Training loss: 1.025842547416687
Validation loss: 1.8807787536292948

Epoch: 5| Step: 1
Training loss: 0.8464126586914062
Validation loss: 1.8817361285609584

Epoch: 5| Step: 2
Training loss: 0.8046599626541138
Validation loss: 1.8408062765675206

Epoch: 5| Step: 3
Training loss: 0.7438645958900452
Validation loss: 1.8471789924047326

Epoch: 5| Step: 4
Training loss: 0.6641110181808472
Validation loss: 1.8286278581106534

Epoch: 5| Step: 5
Training loss: 0.8506414294242859
Validation loss: 1.8547472620523104

Epoch: 5| Step: 6
Training loss: 1.1373423337936401
Validation loss: 1.8441426125905847

Epoch: 5| Step: 7
Training loss: 0.8596541285514832
Validation loss: 1.8637835876916045

Epoch: 5| Step: 8
Training loss: 1.2105586528778076
Validation loss: 1.886865949118009

Epoch: 5| Step: 9
Training loss: 0.8766342401504517
Validation loss: 1.8368283702481178

Epoch: 5| Step: 10
Training loss: 0.8215695023536682
Validation loss: 1.8043376412442935

Epoch: 288| Step: 0
Training loss: 0.7930160164833069
Validation loss: 1.785282527246783

Epoch: 5| Step: 1
Training loss: 0.7929979562759399
Validation loss: 1.7834878531835412

Epoch: 5| Step: 2
Training loss: 1.4697586297988892
Validation loss: 1.7701726549415178

Epoch: 5| Step: 3
Training loss: 0.7597726583480835
Validation loss: 1.807858233810753

Epoch: 5| Step: 4
Training loss: 0.5343698263168335
Validation loss: 1.8610276355538318

Epoch: 5| Step: 5
Training loss: 0.9294565320014954
Validation loss: 1.9402854878415343

Epoch: 5| Step: 6
Training loss: 1.0995197296142578
Validation loss: 1.9916520503259474

Epoch: 5| Step: 7
Training loss: 0.7039446234703064
Validation loss: 1.9706271797098138

Epoch: 5| Step: 8
Training loss: 1.039846420288086
Validation loss: 1.9258280941235122

Epoch: 5| Step: 9
Training loss: 1.1382179260253906
Validation loss: 1.8689558480375557

Epoch: 5| Step: 10
Training loss: 1.2268421649932861
Validation loss: 1.7859048945929414

Epoch: 289| Step: 0
Training loss: 1.0400941371917725
Validation loss: 1.7570387407015728

Epoch: 5| Step: 1
Training loss: 1.2899062633514404
Validation loss: 1.7309375014356387

Epoch: 5| Step: 2
Training loss: 0.828291118144989
Validation loss: 1.7474840571803432

Epoch: 5| Step: 3
Training loss: 1.2178239822387695
Validation loss: 1.7847822097039991

Epoch: 5| Step: 4
Training loss: 0.7200908660888672
Validation loss: 1.807388791473963

Epoch: 5| Step: 5
Training loss: 0.6650357246398926
Validation loss: 1.8301405624676776

Epoch: 5| Step: 6
Training loss: 0.5946459770202637
Validation loss: 1.8977759935522591

Epoch: 5| Step: 7
Training loss: 1.1446282863616943
Validation loss: 1.936942756816905

Epoch: 5| Step: 8
Training loss: 1.2649716138839722
Validation loss: 1.9877356867636404

Epoch: 5| Step: 9
Training loss: 1.218815565109253
Validation loss: 1.969421963537893

Epoch: 5| Step: 10
Training loss: 0.8677495121955872
Validation loss: 1.9322167699055006

Epoch: 290| Step: 0
Training loss: 0.7764495611190796
Validation loss: 1.825544713645853

Epoch: 5| Step: 1
Training loss: 1.130213975906372
Validation loss: 1.813890177716491

Epoch: 5| Step: 2
Training loss: 1.7624931335449219
Validation loss: 1.8058784879663938

Epoch: 5| Step: 3
Training loss: 0.845400333404541
Validation loss: 1.7992473853531705

Epoch: 5| Step: 4
Training loss: 1.1544544696807861
Validation loss: 1.8119834533301733

Epoch: 5| Step: 5
Training loss: 0.9618722796440125
Validation loss: 1.8287561529426164

Epoch: 5| Step: 6
Training loss: 0.7431303262710571
Validation loss: 1.8467732834559616

Epoch: 5| Step: 7
Training loss: 0.711476743221283
Validation loss: 1.89465590189862

Epoch: 5| Step: 8
Training loss: 0.5016453862190247
Validation loss: 1.9318013627042052

Epoch: 5| Step: 9
Training loss: 0.7745780348777771
Validation loss: 2.001316560212002

Epoch: 5| Step: 10
Training loss: 1.448311448097229
Validation loss: 2.049920448692896

Epoch: 291| Step: 0
Training loss: 1.1779167652130127
Validation loss: 2.1101771721275906

Epoch: 5| Step: 1
Training loss: 1.1021331548690796
Validation loss: 2.078786055246989

Epoch: 5| Step: 2
Training loss: 1.1289594173431396
Validation loss: 1.9620447876632854

Epoch: 5| Step: 3
Training loss: 0.9192430377006531
Validation loss: 1.853513672787656

Epoch: 5| Step: 4
Training loss: 0.7269797921180725
Validation loss: 1.8079169360540246

Epoch: 5| Step: 5
Training loss: 0.8574255108833313
Validation loss: 1.8015061911716257

Epoch: 5| Step: 6
Training loss: 0.9750614166259766
Validation loss: 1.783759520899865

Epoch: 5| Step: 7
Training loss: 0.9452721476554871
Validation loss: 1.803528147359048

Epoch: 5| Step: 8
Training loss: 0.5874027013778687
Validation loss: 1.8021895462466824

Epoch: 5| Step: 9
Training loss: 1.401842713356018
Validation loss: 1.8471162139728505

Epoch: 5| Step: 10
Training loss: 1.0577056407928467
Validation loss: 1.9010618450821086

Epoch: 292| Step: 0
Training loss: 1.083408236503601
Validation loss: 1.9608782811831402

Epoch: 5| Step: 1
Training loss: 1.2377502918243408
Validation loss: 1.9927899299129364

Epoch: 5| Step: 2
Training loss: 0.7003017663955688
Validation loss: 1.9038636966418194

Epoch: 5| Step: 3
Training loss: 0.8402006030082703
Validation loss: 1.8476520725475845

Epoch: 5| Step: 4
Training loss: 0.6998618841171265
Validation loss: 1.819466729317942

Epoch: 5| Step: 5
Training loss: 1.082858681678772
Validation loss: 1.7959498167037964

Epoch: 5| Step: 6
Training loss: 0.8177782297134399
Validation loss: 1.7942777359357445

Epoch: 5| Step: 7
Training loss: 1.4131344556808472
Validation loss: 1.8251888508437781

Epoch: 5| Step: 8
Training loss: 1.0232007503509521
Validation loss: 1.8328811648071452

Epoch: 5| Step: 9
Training loss: 0.5254713296890259
Validation loss: 1.850154140944122

Epoch: 5| Step: 10
Training loss: 1.201431155204773
Validation loss: 1.9152079089995353

Epoch: 293| Step: 0
Training loss: 1.7457666397094727
Validation loss: 1.9449201348007366

Epoch: 5| Step: 1
Training loss: 0.8617353439331055
Validation loss: 1.9815975222536313

Epoch: 5| Step: 2
Training loss: 0.823631763458252
Validation loss: 2.0052951382052515

Epoch: 5| Step: 3
Training loss: 0.5251325368881226
Validation loss: 1.9665535739673081

Epoch: 5| Step: 4
Training loss: 0.9051364660263062
Validation loss: 1.8960196023346276

Epoch: 5| Step: 5
Training loss: 0.6940145492553711
Validation loss: 1.8741603141189904

Epoch: 5| Step: 6
Training loss: 0.8916946649551392
Validation loss: 1.8418441613515217

Epoch: 5| Step: 7
Training loss: 0.8656541109085083
Validation loss: 1.8323429643466909

Epoch: 5| Step: 8
Training loss: 1.0629985332489014
Validation loss: 1.8061437606811523

Epoch: 5| Step: 9
Training loss: 1.0798122882843018
Validation loss: 1.8352957412760744

Epoch: 5| Step: 10
Training loss: 0.5690320134162903
Validation loss: 1.823658145884032

Epoch: 294| Step: 0
Training loss: 0.8416557312011719
Validation loss: 1.8478905923904911

Epoch: 5| Step: 1
Training loss: 0.9008868932723999
Validation loss: 1.9156967273322485

Epoch: 5| Step: 2
Training loss: 1.0123625993728638
Validation loss: 1.9208825429280598

Epoch: 5| Step: 3
Training loss: 0.908014178276062
Validation loss: 1.9541175403902609

Epoch: 5| Step: 4
Training loss: 0.8897022008895874
Validation loss: 1.916734831307524

Epoch: 5| Step: 5
Training loss: 0.7611790895462036
Validation loss: 1.8954926639474847

Epoch: 5| Step: 6
Training loss: 0.9066013097763062
Validation loss: 1.835957586124379

Epoch: 5| Step: 7
Training loss: 1.0746557712554932
Validation loss: 1.8280321333997993

Epoch: 5| Step: 8
Training loss: 0.5971454977989197
Validation loss: 1.803965796706497

Epoch: 5| Step: 9
Training loss: 1.15370512008667
Validation loss: 1.8103285310088948

Epoch: 5| Step: 10
Training loss: 0.794194757938385
Validation loss: 1.809693444159723

Epoch: 295| Step: 0
Training loss: 0.9554319381713867
Validation loss: 1.7810684968066472

Epoch: 5| Step: 1
Training loss: 0.9064527750015259
Validation loss: 1.8391951617374216

Epoch: 5| Step: 2
Training loss: 0.9331443905830383
Validation loss: 1.88355387667174

Epoch: 5| Step: 3
Training loss: 0.8214564323425293
Validation loss: 1.9345790891237156

Epoch: 5| Step: 4
Training loss: 0.8597471117973328
Validation loss: 1.9560651868902228

Epoch: 5| Step: 5
Training loss: 0.9319071769714355
Validation loss: 1.9665393816527499

Epoch: 5| Step: 6
Training loss: 0.6115410327911377
Validation loss: 1.936730569408786

Epoch: 5| Step: 7
Training loss: 1.0345560312271118
Validation loss: 1.9014647135170557

Epoch: 5| Step: 8
Training loss: 0.8528628349304199
Validation loss: 1.8106558053724227

Epoch: 5| Step: 9
Training loss: 0.8039883375167847
Validation loss: 1.7694099205796436

Epoch: 5| Step: 10
Training loss: 0.9216601252555847
Validation loss: 1.7529325536502305

Epoch: 296| Step: 0
Training loss: 1.0052233934402466
Validation loss: 1.727820409241543

Epoch: 5| Step: 1
Training loss: 1.4082783460617065
Validation loss: 1.7616648020282868

Epoch: 5| Step: 2
Training loss: 0.9129680395126343
Validation loss: 1.7316662150044595

Epoch: 5| Step: 3
Training loss: 0.9388759732246399
Validation loss: 1.7439339519828878

Epoch: 5| Step: 4
Training loss: 0.9368950128555298
Validation loss: 1.797409926691363

Epoch: 5| Step: 5
Training loss: 0.5652729868888855
Validation loss: 1.8611628317063855

Epoch: 5| Step: 6
Training loss: 0.5436098575592041
Validation loss: 1.9206235101146083

Epoch: 5| Step: 7
Training loss: 1.1194097995758057
Validation loss: 1.9853692080384941

Epoch: 5| Step: 8
Training loss: 0.7882482409477234
Validation loss: 1.9847862566671064

Epoch: 5| Step: 9
Training loss: 0.9967018365859985
Validation loss: 1.9286342564449515

Epoch: 5| Step: 10
Training loss: 0.32704636454582214
Validation loss: 1.8843377623506772

Epoch: 297| Step: 0
Training loss: 0.9591557383537292
Validation loss: 1.8419746198961813

Epoch: 5| Step: 1
Training loss: 0.764560341835022
Validation loss: 1.832538362472288

Epoch: 5| Step: 2
Training loss: 1.0245888233184814
Validation loss: 1.8037005727009108

Epoch: 5| Step: 3
Training loss: 0.6679986715316772
Validation loss: 1.8029317343106834

Epoch: 5| Step: 4
Training loss: 0.6077308654785156
Validation loss: 1.8240388824093727

Epoch: 5| Step: 5
Training loss: 1.0894973278045654
Validation loss: 1.8328033954866472

Epoch: 5| Step: 6
Training loss: 0.6535671353340149
Validation loss: 1.8920514968133741

Epoch: 5| Step: 7
Training loss: 1.073621392250061
Validation loss: 1.9485687171259234

Epoch: 5| Step: 8
Training loss: 0.9717577695846558
Validation loss: 1.973378663421959

Epoch: 5| Step: 9
Training loss: 0.6853371858596802
Validation loss: 1.9516959882551623

Epoch: 5| Step: 10
Training loss: 1.0451544523239136
Validation loss: 1.8576885628443893

Epoch: 298| Step: 0
Training loss: 0.9152947664260864
Validation loss: 1.7996443651055778

Epoch: 5| Step: 1
Training loss: 0.618617832660675
Validation loss: 1.7495957113081408

Epoch: 5| Step: 2
Training loss: 0.7762117981910706
Validation loss: 1.738286086308059

Epoch: 5| Step: 3
Training loss: 0.8891700506210327
Validation loss: 1.7260627990127893

Epoch: 5| Step: 4
Training loss: 1.3449511528015137
Validation loss: 1.735755294881841

Epoch: 5| Step: 5
Training loss: 0.7257776260375977
Validation loss: 1.7301489960762761

Epoch: 5| Step: 6
Training loss: 1.1374385356903076
Validation loss: 1.780847595584008

Epoch: 5| Step: 7
Training loss: 0.9146814346313477
Validation loss: 1.7754715181166125

Epoch: 5| Step: 8
Training loss: 0.40543776750564575
Validation loss: 1.845497058283898

Epoch: 5| Step: 9
Training loss: 0.5038219690322876
Validation loss: 1.8512012689344344

Epoch: 5| Step: 10
Training loss: 1.2826422452926636
Validation loss: 1.8616224206903929

Epoch: 299| Step: 0
Training loss: 0.7528643608093262
Validation loss: 1.829168435065977

Epoch: 5| Step: 1
Training loss: 0.8233885765075684
Validation loss: 1.819045989744125

Epoch: 5| Step: 2
Training loss: 0.590415358543396
Validation loss: 1.8005320013210337

Epoch: 5| Step: 3
Training loss: 0.8212849497795105
Validation loss: 1.7951619702000772

Epoch: 5| Step: 4
Training loss: 0.9805381894111633
Validation loss: 1.8030318547320623

Epoch: 5| Step: 5
Training loss: 0.5216532945632935
Validation loss: 1.8009193328119093

Epoch: 5| Step: 6
Training loss: 0.5644058585166931
Validation loss: 1.8107204667983516

Epoch: 5| Step: 7
Training loss: 0.683668315410614
Validation loss: 1.824719887907787

Epoch: 5| Step: 8
Training loss: 1.3092354536056519
Validation loss: 1.817084139393222

Epoch: 5| Step: 9
Training loss: 1.138119101524353
Validation loss: 1.8427157414856778

Epoch: 5| Step: 10
Training loss: 0.835174024105072
Validation loss: 1.8824451969515892

Epoch: 300| Step: 0
Training loss: 0.7139978408813477
Validation loss: 1.8930265006198679

Epoch: 5| Step: 1
Training loss: 1.0029795169830322
Validation loss: 1.8804413080215454

Epoch: 5| Step: 2
Training loss: 0.915920078754425
Validation loss: 1.8725900060387068

Epoch: 5| Step: 3
Training loss: 0.7880997657775879
Validation loss: 1.8328674711206907

Epoch: 5| Step: 4
Training loss: 0.8542240262031555
Validation loss: 1.8132600335664646

Epoch: 5| Step: 5
Training loss: 0.7911063432693481
Validation loss: 1.8243707661987634

Epoch: 5| Step: 6
Training loss: 1.081253170967102
Validation loss: 1.8579357311289797

Epoch: 5| Step: 7
Training loss: 0.5598402619361877
Validation loss: 1.8323234793960408

Epoch: 5| Step: 8
Training loss: 0.7699428200721741
Validation loss: 1.8405976321107598

Epoch: 5| Step: 9
Training loss: 0.7287558913230896
Validation loss: 1.8892378102066696

Epoch: 5| Step: 10
Training loss: 0.5439778566360474
Validation loss: 1.8613005902177544

Epoch: 301| Step: 0
Training loss: 0.6816652417182922
Validation loss: 1.8520686088069793

Epoch: 5| Step: 1
Training loss: 0.7783800363540649
Validation loss: 1.8588916101763326

Epoch: 5| Step: 2
Training loss: 0.7667282819747925
Validation loss: 1.8210702429535568

Epoch: 5| Step: 3
Training loss: 0.7172988653182983
Validation loss: 1.8123275772217782

Epoch: 5| Step: 4
Training loss: 1.1354825496673584
Validation loss: 1.796206066685338

Epoch: 5| Step: 5
Training loss: 0.8970238566398621
Validation loss: 1.7866872151692708

Epoch: 5| Step: 6
Training loss: 0.7544849514961243
Validation loss: 1.7812227164545367

Epoch: 5| Step: 7
Training loss: 1.1008323431015015
Validation loss: 1.792139458399947

Epoch: 5| Step: 8
Training loss: 0.4009276032447815
Validation loss: 1.7945347447549143

Epoch: 5| Step: 9
Training loss: 0.6477599740028381
Validation loss: 1.789850675931541

Epoch: 5| Step: 10
Training loss: 0.8187777996063232
Validation loss: 1.8142232753897225

Epoch: 302| Step: 0
Training loss: 0.7217243909835815
Validation loss: 1.8308035455724245

Epoch: 5| Step: 1
Training loss: 0.8019376993179321
Validation loss: 1.826075223184401

Epoch: 5| Step: 2
Training loss: 1.0340478420257568
Validation loss: 1.8561255188398464

Epoch: 5| Step: 3
Training loss: 0.8569434881210327
Validation loss: 1.8703348303353915

Epoch: 5| Step: 4
Training loss: 0.4378606677055359
Validation loss: 1.8567706577239498

Epoch: 5| Step: 5
Training loss: 0.8374873995780945
Validation loss: 1.8459813440999677

Epoch: 5| Step: 6
Training loss: 1.062546730041504
Validation loss: 1.8506447012706468

Epoch: 5| Step: 7
Training loss: 0.8277551531791687
Validation loss: 1.8356651721462127

Epoch: 5| Step: 8
Training loss: 0.5225316882133484
Validation loss: 1.8273223792352984

Epoch: 5| Step: 9
Training loss: 0.5907077789306641
Validation loss: 1.8184946865163825

Epoch: 5| Step: 10
Training loss: 0.742098331451416
Validation loss: 1.80042411563217

Epoch: 303| Step: 0
Training loss: 0.67181795835495
Validation loss: 1.8254038210838073

Epoch: 5| Step: 1
Training loss: 1.0176942348480225
Validation loss: 1.8109087905576151

Epoch: 5| Step: 2
Training loss: 0.5394954085350037
Validation loss: 1.7958888289748982

Epoch: 5| Step: 3
Training loss: 0.6751837730407715
Validation loss: 1.7900225526543074

Epoch: 5| Step: 4
Training loss: 0.4917948246002197
Validation loss: 1.828020650853393

Epoch: 5| Step: 5
Training loss: 0.8034085035324097
Validation loss: 1.796851832379577

Epoch: 5| Step: 6
Training loss: 1.0169904232025146
Validation loss: 1.7964330668090491

Epoch: 5| Step: 7
Training loss: 0.7494778633117676
Validation loss: 1.8049027958223898

Epoch: 5| Step: 8
Training loss: 0.7524827718734741
Validation loss: 1.8053472580448273

Epoch: 5| Step: 9
Training loss: 0.9764453768730164
Validation loss: 1.8140639835788357

Epoch: 5| Step: 10
Training loss: 0.6739874482154846
Validation loss: 1.8342838723172423

Epoch: 304| Step: 0
Training loss: 0.7854143381118774
Validation loss: 1.8553377979545183

Epoch: 5| Step: 1
Training loss: 1.1447062492370605
Validation loss: 1.8157163896868307

Epoch: 5| Step: 2
Training loss: 0.712098240852356
Validation loss: 1.795101147826

Epoch: 5| Step: 3
Training loss: 0.7961772680282593
Validation loss: 1.7843765520280408

Epoch: 5| Step: 4
Training loss: 0.48202449083328247
Validation loss: 1.7711404254359584

Epoch: 5| Step: 5
Training loss: 0.9175735712051392
Validation loss: 1.7684297420645272

Epoch: 5| Step: 6
Training loss: 0.5231789350509644
Validation loss: 1.797228938789778

Epoch: 5| Step: 7
Training loss: 0.6372283697128296
Validation loss: 1.8149470372866559

Epoch: 5| Step: 8
Training loss: 0.7501565217971802
Validation loss: 1.8497606182611117

Epoch: 5| Step: 9
Training loss: 0.7761349081993103
Validation loss: 1.8562772684199835

Epoch: 5| Step: 10
Training loss: 0.6143589615821838
Validation loss: 1.8245167040055799

Epoch: 305| Step: 0
Training loss: 0.810810923576355
Validation loss: 1.8168639008716871

Epoch: 5| Step: 1
Training loss: 1.1726727485656738
Validation loss: 1.8159506218407744

Epoch: 5| Step: 2
Training loss: 0.6259413957595825
Validation loss: 1.7812228907821

Epoch: 5| Step: 3
Training loss: 0.6057854890823364
Validation loss: 1.7718414593768377

Epoch: 5| Step: 4
Training loss: 0.6512150764465332
Validation loss: 1.7756732112617903

Epoch: 5| Step: 5
Training loss: 0.9597814679145813
Validation loss: 1.786035882529392

Epoch: 5| Step: 6
Training loss: 0.5320137739181519
Validation loss: 1.77663883983448

Epoch: 5| Step: 7
Training loss: 0.6029847860336304
Validation loss: 1.801981036381055

Epoch: 5| Step: 8
Training loss: 0.7520097494125366
Validation loss: 1.8514295201147757

Epoch: 5| Step: 9
Training loss: 0.5234395265579224
Validation loss: 1.8767753339582873

Epoch: 5| Step: 10
Training loss: 1.2937415838241577
Validation loss: 1.887022993897879

Epoch: 306| Step: 0
Training loss: 0.38667288422584534
Validation loss: 1.8472431821207846

Epoch: 5| Step: 1
Training loss: 0.6473811864852905
Validation loss: 1.8520686780252764

Epoch: 5| Step: 2
Training loss: 0.7766164541244507
Validation loss: 1.8218392197803785

Epoch: 5| Step: 3
Training loss: 0.7945573329925537
Validation loss: 1.7977044454184912

Epoch: 5| Step: 4
Training loss: 0.8369487524032593
Validation loss: 1.8011374165934901

Epoch: 5| Step: 5
Training loss: 1.101754903793335
Validation loss: 1.81892902364013

Epoch: 5| Step: 6
Training loss: 0.8571174740791321
Validation loss: 1.8271652908735379

Epoch: 5| Step: 7
Training loss: 0.8581026196479797
Validation loss: 1.8184475539832987

Epoch: 5| Step: 8
Training loss: 0.5929967164993286
Validation loss: 1.851380585342325

Epoch: 5| Step: 9
Training loss: 0.6796558499336243
Validation loss: 1.8668859479247883

Epoch: 5| Step: 10
Training loss: 0.7458716034889221
Validation loss: 1.8782993183341077

Epoch: 307| Step: 0
Training loss: 0.7159882187843323
Validation loss: 1.8317449323592647

Epoch: 5| Step: 1
Training loss: 0.8148414492607117
Validation loss: 1.8084441884871452

Epoch: 5| Step: 2
Training loss: 0.9923765063285828
Validation loss: 1.7748004467256608

Epoch: 5| Step: 3
Training loss: 1.0338866710662842
Validation loss: 1.7645688197946037

Epoch: 5| Step: 4
Training loss: 0.3892686367034912
Validation loss: 1.766882033758266

Epoch: 5| Step: 5
Training loss: 0.767427921295166
Validation loss: 1.7778138165832849

Epoch: 5| Step: 6
Training loss: 0.9338275790214539
Validation loss: 1.772877643185277

Epoch: 5| Step: 7
Training loss: 0.7103461027145386
Validation loss: 1.8623024302144204

Epoch: 5| Step: 8
Training loss: 0.5988598465919495
Validation loss: 1.8889178281189294

Epoch: 5| Step: 9
Training loss: 0.8104848861694336
Validation loss: 1.8844486269899594

Epoch: 5| Step: 10
Training loss: 0.6410197019577026
Validation loss: 1.901979043919553

Epoch: 308| Step: 0
Training loss: 0.8944026827812195
Validation loss: 1.97221799050608

Epoch: 5| Step: 1
Training loss: 0.9885326623916626
Validation loss: 1.9866325739891297

Epoch: 5| Step: 2
Training loss: 0.5652740597724915
Validation loss: 1.9015198702453284

Epoch: 5| Step: 3
Training loss: 0.4814330041408539
Validation loss: 1.8634988877081102

Epoch: 5| Step: 4
Training loss: 0.3832278251647949
Validation loss: 1.797828443588749

Epoch: 5| Step: 5
Training loss: 1.0224378108978271
Validation loss: 1.7503668095475884

Epoch: 5| Step: 6
Training loss: 0.9318259954452515
Validation loss: 1.7429127436812206

Epoch: 5| Step: 7
Training loss: 1.094597578048706
Validation loss: 1.7484136576293616

Epoch: 5| Step: 8
Training loss: 0.5203016996383667
Validation loss: 1.749492359417741

Epoch: 5| Step: 9
Training loss: 1.0399956703186035
Validation loss: 1.77305466898026

Epoch: 5| Step: 10
Training loss: 0.8257025480270386
Validation loss: 1.8421182888810352

Epoch: 309| Step: 0
Training loss: 0.9340577125549316
Validation loss: 1.8563085038174865

Epoch: 5| Step: 1
Training loss: 1.0081465244293213
Validation loss: 1.8885065624790807

Epoch: 5| Step: 2
Training loss: 1.0321733951568604
Validation loss: 1.872625030497069

Epoch: 5| Step: 3
Training loss: 0.753630518913269
Validation loss: 1.8720442736020653

Epoch: 5| Step: 4
Training loss: 0.6156123280525208
Validation loss: 1.8393092924548733

Epoch: 5| Step: 5
Training loss: 0.5239901542663574
Validation loss: 1.782768976303839

Epoch: 5| Step: 6
Training loss: 0.702526867389679
Validation loss: 1.769788916392993

Epoch: 5| Step: 7
Training loss: 1.1587169170379639
Validation loss: 1.7623376795040664

Epoch: 5| Step: 8
Training loss: 0.5803285837173462
Validation loss: 1.7360267998069845

Epoch: 5| Step: 9
Training loss: 0.563228964805603
Validation loss: 1.7037248175631288

Epoch: 5| Step: 10
Training loss: 0.8193191289901733
Validation loss: 1.7365551789601643

Epoch: 310| Step: 0
Training loss: 0.6443395614624023
Validation loss: 1.790544307360085

Epoch: 5| Step: 1
Training loss: 0.6798086166381836
Validation loss: 1.8211513847433112

Epoch: 5| Step: 2
Training loss: 0.6852284669876099
Validation loss: 1.890598153555265

Epoch: 5| Step: 3
Training loss: 0.7144132852554321
Validation loss: 1.9255580312462264

Epoch: 5| Step: 4
Training loss: 1.0621252059936523
Validation loss: 1.911454733981881

Epoch: 5| Step: 5
Training loss: 0.7452566027641296
Validation loss: 1.8491833825265207

Epoch: 5| Step: 6
Training loss: 0.7014630436897278
Validation loss: 1.7943079535679152

Epoch: 5| Step: 7
Training loss: 0.6239523887634277
Validation loss: 1.7411830194534794

Epoch: 5| Step: 8
Training loss: 0.9815473556518555
Validation loss: 1.7391583278614988

Epoch: 5| Step: 9
Training loss: 1.082031011581421
Validation loss: 1.7313677803162606

Epoch: 5| Step: 10
Training loss: 0.7352375984191895
Validation loss: 1.7343216724293207

Epoch: 311| Step: 0
Training loss: 0.46032142639160156
Validation loss: 1.7494882601563648

Epoch: 5| Step: 1
Training loss: 0.9028213620185852
Validation loss: 1.7641636556194675

Epoch: 5| Step: 2
Training loss: 0.969544529914856
Validation loss: 1.826470910861928

Epoch: 5| Step: 3
Training loss: 0.5984088778495789
Validation loss: 1.8695101302157167

Epoch: 5| Step: 4
Training loss: 0.7950822710990906
Validation loss: 1.9206745214359735

Epoch: 5| Step: 5
Training loss: 0.8363237380981445
Validation loss: 1.9251334962024484

Epoch: 5| Step: 6
Training loss: 0.91114342212677
Validation loss: 1.8866694716997043

Epoch: 5| Step: 7
Training loss: 0.35684436559677124
Validation loss: 1.824058122532342

Epoch: 5| Step: 8
Training loss: 0.851493239402771
Validation loss: 1.765792336515201

Epoch: 5| Step: 9
Training loss: 1.0412192344665527
Validation loss: 1.7459663255240327

Epoch: 5| Step: 10
Training loss: 0.9145987629890442
Validation loss: 1.7457196430493427

Epoch: 312| Step: 0
Training loss: 0.7864062190055847
Validation loss: 1.7235658527702413

Epoch: 5| Step: 1
Training loss: 0.6192430257797241
Validation loss: 1.7337766949848463

Epoch: 5| Step: 2
Training loss: 1.0170975923538208
Validation loss: 1.7465793740364812

Epoch: 5| Step: 3
Training loss: 0.9698235392570496
Validation loss: 1.7620471472381263

Epoch: 5| Step: 4
Training loss: 0.6446273922920227
Validation loss: 1.800116446710402

Epoch: 5| Step: 5
Training loss: 0.6186903119087219
Validation loss: 1.8297582980125182

Epoch: 5| Step: 6
Training loss: 0.6229281425476074
Validation loss: 1.880595867351819

Epoch: 5| Step: 7
Training loss: 0.7865298986434937
Validation loss: 1.902152516508615

Epoch: 5| Step: 8
Training loss: 0.6712645292282104
Validation loss: 1.8623560385037494

Epoch: 5| Step: 9
Training loss: 0.9598878026008606
Validation loss: 1.8304876794097245

Epoch: 5| Step: 10
Training loss: 0.6792434453964233
Validation loss: 1.76835802806321

Epoch: 313| Step: 0
Training loss: 0.7751351594924927
Validation loss: 1.7576434714819795

Epoch: 5| Step: 1
Training loss: 0.956608772277832
Validation loss: 1.7455207865725282

Epoch: 5| Step: 2
Training loss: 1.0190881490707397
Validation loss: 1.7369667919733192

Epoch: 5| Step: 3
Training loss: 0.6186473369598389
Validation loss: 1.7408179288269372

Epoch: 5| Step: 4
Training loss: 0.652664065361023
Validation loss: 1.7249918701828166

Epoch: 5| Step: 5
Training loss: 0.636992335319519
Validation loss: 1.7814626155361053

Epoch: 5| Step: 6
Training loss: 0.3828495144844055
Validation loss: 1.8053142921898955

Epoch: 5| Step: 7
Training loss: 0.790500283241272
Validation loss: 1.849216753436673

Epoch: 5| Step: 8
Training loss: 0.7112988233566284
Validation loss: 1.8967306075557586

Epoch: 5| Step: 9
Training loss: 1.0540471076965332
Validation loss: 1.9186147233491302

Epoch: 5| Step: 10
Training loss: 0.8981271386146545
Validation loss: 1.9173452854156494

Epoch: 314| Step: 0
Training loss: 0.9135595560073853
Validation loss: 1.8344373574820898

Epoch: 5| Step: 1
Training loss: 0.6638365983963013
Validation loss: 1.7835145599098616

Epoch: 5| Step: 2
Training loss: 0.7294114232063293
Validation loss: 1.7400870784636466

Epoch: 5| Step: 3
Training loss: 0.726945161819458
Validation loss: 1.693811749899259

Epoch: 5| Step: 4
Training loss: 0.9726260900497437
Validation loss: 1.7152658713761197

Epoch: 5| Step: 5
Training loss: 0.6795340776443481
Validation loss: 1.7313963777275496

Epoch: 5| Step: 6
Training loss: 0.8183751106262207
Validation loss: 1.7231961565632974

Epoch: 5| Step: 7
Training loss: 0.5795379281044006
Validation loss: 1.7287536641602874

Epoch: 5| Step: 8
Training loss: 0.7354528903961182
Validation loss: 1.7554085023941532

Epoch: 5| Step: 9
Training loss: 0.8149675130844116
Validation loss: 1.7723540888037732

Epoch: 5| Step: 10
Training loss: 0.5155730247497559
Validation loss: 1.8132714622764177

Epoch: 315| Step: 0
Training loss: 0.9314776659011841
Validation loss: 1.8420825107123262

Epoch: 5| Step: 1
Training loss: 0.49346914887428284
Validation loss: 1.842358681463426

Epoch: 5| Step: 2
Training loss: 0.568414032459259
Validation loss: 1.815265497853679

Epoch: 5| Step: 3
Training loss: 0.8287933468818665
Validation loss: 1.8365267989456013

Epoch: 5| Step: 4
Training loss: 0.7417687773704529
Validation loss: 1.789284408733409

Epoch: 5| Step: 5
Training loss: 0.539236843585968
Validation loss: 1.7730506004825715

Epoch: 5| Step: 6
Training loss: 0.5148957967758179
Validation loss: 1.7678313832129202

Epoch: 5| Step: 7
Training loss: 0.6508382558822632
Validation loss: 1.768636626581992

Epoch: 5| Step: 8
Training loss: 0.7727094888687134
Validation loss: 1.7601869516475226

Epoch: 5| Step: 9
Training loss: 1.0619367361068726
Validation loss: 1.8005969601292764

Epoch: 5| Step: 10
Training loss: 0.8909216523170471
Validation loss: 1.812847719397596

Epoch: 316| Step: 0
Training loss: 0.7530872225761414
Validation loss: 1.8675997898142824

Epoch: 5| Step: 1
Training loss: 0.5307641625404358
Validation loss: 1.8952857602027156

Epoch: 5| Step: 2
Training loss: 0.859752357006073
Validation loss: 1.8681801749813942

Epoch: 5| Step: 3
Training loss: 0.8261264562606812
Validation loss: 1.8603319916673886

Epoch: 5| Step: 4
Training loss: 0.7473365068435669
Validation loss: 1.8515454748625397

Epoch: 5| Step: 5
Training loss: 0.493842750787735
Validation loss: 1.8092030530334802

Epoch: 5| Step: 6
Training loss: 0.7664164304733276
Validation loss: 1.8097237322920112

Epoch: 5| Step: 7
Training loss: 1.1310423612594604
Validation loss: 1.7735758481487152

Epoch: 5| Step: 8
Training loss: 0.4544464945793152
Validation loss: 1.772793508345081

Epoch: 5| Step: 9
Training loss: 0.703794002532959
Validation loss: 1.7538774026337491

Epoch: 5| Step: 10
Training loss: 0.5319254994392395
Validation loss: 1.7619355596521848

Epoch: 317| Step: 0
Training loss: 0.6163407564163208
Validation loss: 1.7627312060325377

Epoch: 5| Step: 1
Training loss: 0.706518292427063
Validation loss: 1.8005223517776818

Epoch: 5| Step: 2
Training loss: 0.6418458223342896
Validation loss: 1.7810691505350091

Epoch: 5| Step: 3
Training loss: 0.36820656061172485
Validation loss: 1.771401301507027

Epoch: 5| Step: 4
Training loss: 0.9030967950820923
Validation loss: 1.7555235111585228

Epoch: 5| Step: 5
Training loss: 0.726806640625
Validation loss: 1.7574575716449368

Epoch: 5| Step: 6
Training loss: 0.4628472924232483
Validation loss: 1.7836058908893215

Epoch: 5| Step: 7
Training loss: 0.8103087544441223
Validation loss: 1.8036425895588373

Epoch: 5| Step: 8
Training loss: 1.0164778232574463
Validation loss: 1.829618095069803

Epoch: 5| Step: 9
Training loss: 0.470097154378891
Validation loss: 1.8600737228188464

Epoch: 5| Step: 10
Training loss: 0.8094704747200012
Validation loss: 1.862699180520991

Epoch: 318| Step: 0
Training loss: 0.35304298996925354
Validation loss: 1.8429996044405046

Epoch: 5| Step: 1
Training loss: 0.44792261719703674
Validation loss: 1.8598856169690368

Epoch: 5| Step: 2
Training loss: 0.5361971855163574
Validation loss: 1.8125828363562142

Epoch: 5| Step: 3
Training loss: 0.7664045691490173
Validation loss: 1.792572275284798

Epoch: 5| Step: 4
Training loss: 0.8429067730903625
Validation loss: 1.7715446090185514

Epoch: 5| Step: 5
Training loss: 0.499997615814209
Validation loss: 1.7577313338556597

Epoch: 5| Step: 6
Training loss: 0.8057391047477722
Validation loss: 1.7498503026141916

Epoch: 5| Step: 7
Training loss: 0.7707985043525696
Validation loss: 1.7523516211458432

Epoch: 5| Step: 8
Training loss: 0.4508649706840515
Validation loss: 1.7596630947564238

Epoch: 5| Step: 9
Training loss: 0.9855523109436035
Validation loss: 1.805132555705245

Epoch: 5| Step: 10
Training loss: 0.8986849784851074
Validation loss: 1.8021846586658108

Epoch: 319| Step: 0
Training loss: 0.9001450538635254
Validation loss: 1.8289153806624874

Epoch: 5| Step: 1
Training loss: 0.5086187720298767
Validation loss: 1.8329765924843409

Epoch: 5| Step: 2
Training loss: 0.7360268235206604
Validation loss: 1.8439081894454135

Epoch: 5| Step: 3
Training loss: 0.6174572706222534
Validation loss: 1.8356253639344247

Epoch: 5| Step: 4
Training loss: 0.8826624155044556
Validation loss: 1.8169311169655091

Epoch: 5| Step: 5
Training loss: 0.6877180933952332
Validation loss: 1.808202548693585

Epoch: 5| Step: 6
Training loss: 0.8292325735092163
Validation loss: 1.7951052419600948

Epoch: 5| Step: 7
Training loss: 0.40911993384361267
Validation loss: 1.7906572754665087

Epoch: 5| Step: 8
Training loss: 0.4888862073421478
Validation loss: 1.7941443433043778

Epoch: 5| Step: 9
Training loss: 0.6464274525642395
Validation loss: 1.7995076640959708

Epoch: 5| Step: 10
Training loss: 0.44935843348503113
Validation loss: 1.7942367266583186

Epoch: 320| Step: 0
Training loss: 0.8256209492683411
Validation loss: 1.7843560147029098

Epoch: 5| Step: 1
Training loss: 0.5501739978790283
Validation loss: 1.7782388669188305

Epoch: 5| Step: 2
Training loss: 0.8370196223258972
Validation loss: 1.8026693674825853

Epoch: 5| Step: 3
Training loss: 0.4253237247467041
Validation loss: 1.8121849029294905

Epoch: 5| Step: 4
Training loss: 0.9330482482910156
Validation loss: 1.7804135340516285

Epoch: 5| Step: 5
Training loss: 0.43678155541419983
Validation loss: 1.7622883832582863

Epoch: 5| Step: 6
Training loss: 0.34873709082603455
Validation loss: 1.7781949658547678

Epoch: 5| Step: 7
Training loss: 0.6869188547134399
Validation loss: 1.760485831127372

Epoch: 5| Step: 8
Training loss: 0.6841161847114563
Validation loss: 1.7592877239309332

Epoch: 5| Step: 9
Training loss: 0.7838135957717896
Validation loss: 1.7522474488904398

Epoch: 5| Step: 10
Training loss: 0.4762756824493408
Validation loss: 1.7730443682721866

Epoch: 321| Step: 0
Training loss: 0.6374601125717163
Validation loss: 1.7881841544182069

Epoch: 5| Step: 1
Training loss: 0.5590190887451172
Validation loss: 1.8051249429743776

Epoch: 5| Step: 2
Training loss: 0.852200984954834
Validation loss: 1.822645579614947

Epoch: 5| Step: 3
Training loss: 0.765835702419281
Validation loss: 1.8246808090517599

Epoch: 5| Step: 4
Training loss: 0.5342737436294556
Validation loss: 1.8236064449433358

Epoch: 5| Step: 5
Training loss: 0.3410995304584503
Validation loss: 1.8017396132151287

Epoch: 5| Step: 6
Training loss: 0.6822153925895691
Validation loss: 1.8160568667996315

Epoch: 5| Step: 7
Training loss: 0.36498090624809265
Validation loss: 1.8074600106926375

Epoch: 5| Step: 8
Training loss: 0.8185049295425415
Validation loss: 1.7824272263434626

Epoch: 5| Step: 9
Training loss: 0.4939449727535248
Validation loss: 1.7662526907459382

Epoch: 5| Step: 10
Training loss: 1.1058303117752075
Validation loss: 1.7752437245461248

Epoch: 322| Step: 0
Training loss: 0.5976220369338989
Validation loss: 1.7881234243351927

Epoch: 5| Step: 1
Training loss: 0.5132701992988586
Validation loss: 1.759735022821734

Epoch: 5| Step: 2
Training loss: 0.9206369519233704
Validation loss: 1.7839251205485354

Epoch: 5| Step: 3
Training loss: 0.46562662720680237
Validation loss: 1.7779415474143079

Epoch: 5| Step: 4
Training loss: 0.6226835250854492
Validation loss: 1.8012987952078543

Epoch: 5| Step: 5
Training loss: 0.9392610788345337
Validation loss: 1.8210515911861131

Epoch: 5| Step: 6
Training loss: 0.5544304251670837
Validation loss: 1.846312422906199

Epoch: 5| Step: 7
Training loss: 0.672484815120697
Validation loss: 1.8271820904106222

Epoch: 5| Step: 8
Training loss: 0.7395923137664795
Validation loss: 1.8526346068228445

Epoch: 5| Step: 9
Training loss: 0.44076403975486755
Validation loss: 1.8052234162566483

Epoch: 5| Step: 10
Training loss: 0.41168859601020813
Validation loss: 1.7886529584084787

Epoch: 323| Step: 0
Training loss: 0.3752925992012024
Validation loss: 1.761962939334172

Epoch: 5| Step: 1
Training loss: 0.5495794415473938
Validation loss: 1.7471388360505462

Epoch: 5| Step: 2
Training loss: 0.5693421959877014
Validation loss: 1.7395788418349398

Epoch: 5| Step: 3
Training loss: 0.3950960636138916
Validation loss: 1.7626509922806934

Epoch: 5| Step: 4
Training loss: 0.745873749256134
Validation loss: 1.7945226187347083

Epoch: 5| Step: 5
Training loss: 0.4748660624027252
Validation loss: 1.813063685612012

Epoch: 5| Step: 6
Training loss: 0.6840773820877075
Validation loss: 1.8320683253708707

Epoch: 5| Step: 7
Training loss: 0.7504967451095581
Validation loss: 1.8078827319606658

Epoch: 5| Step: 8
Training loss: 0.7483854293823242
Validation loss: 1.8165836052228046

Epoch: 5| Step: 9
Training loss: 0.6203194856643677
Validation loss: 1.8326485464649815

Epoch: 5| Step: 10
Training loss: 0.7590315341949463
Validation loss: 1.8236432460046583

Epoch: 324| Step: 0
Training loss: 0.6248189210891724
Validation loss: 1.807958250404686

Epoch: 5| Step: 1
Training loss: 0.4561389982700348
Validation loss: 1.7846988606196579

Epoch: 5| Step: 2
Training loss: 0.8341609239578247
Validation loss: 1.806936187128867

Epoch: 5| Step: 3
Training loss: 0.2643639147281647
Validation loss: 1.7639161873889226

Epoch: 5| Step: 4
Training loss: 0.775478720664978
Validation loss: 1.7357885235099382

Epoch: 5| Step: 5
Training loss: 0.44500216841697693
Validation loss: 1.728952759055681

Epoch: 5| Step: 6
Training loss: 0.645415186882019
Validation loss: 1.7295397097064602

Epoch: 5| Step: 7
Training loss: 0.6683539152145386
Validation loss: 1.750171922868298

Epoch: 5| Step: 8
Training loss: 0.8463777303695679
Validation loss: 1.7601903561622865

Epoch: 5| Step: 9
Training loss: 0.6599379777908325
Validation loss: 1.774017204520523

Epoch: 5| Step: 10
Training loss: 0.5554823279380798
Validation loss: 1.8140102086528656

Epoch: 325| Step: 0
Training loss: 0.6272532343864441
Validation loss: 1.815892679716951

Epoch: 5| Step: 1
Training loss: 0.45946750044822693
Validation loss: 1.8428166194628643

Epoch: 5| Step: 2
Training loss: 0.6717163324356079
Validation loss: 1.8562685315326979

Epoch: 5| Step: 3
Training loss: 0.6420247554779053
Validation loss: 1.8043119189559773

Epoch: 5| Step: 4
Training loss: 0.4704362750053406
Validation loss: 1.7757128592460387

Epoch: 5| Step: 5
Training loss: 0.9199021458625793
Validation loss: 1.7444713833511516

Epoch: 5| Step: 6
Training loss: 0.719122052192688
Validation loss: 1.715716423526887

Epoch: 5| Step: 7
Training loss: 0.37580054998397827
Validation loss: 1.715834213841346

Epoch: 5| Step: 8
Training loss: 1.0967280864715576
Validation loss: 1.7169526289868098

Epoch: 5| Step: 9
Training loss: 0.4718690514564514
Validation loss: 1.7149503487412647

Epoch: 5| Step: 10
Training loss: 0.3772415220737457
Validation loss: 1.762682064887016

Epoch: 326| Step: 0
Training loss: 0.9926189184188843
Validation loss: 1.7915424505869548

Epoch: 5| Step: 1
Training loss: 0.6237236261367798
Validation loss: 1.7885136142853768

Epoch: 5| Step: 2
Training loss: 0.5552562475204468
Validation loss: 1.8341621468144078

Epoch: 5| Step: 3
Training loss: 0.7539904713630676
Validation loss: 1.8509131657179965

Epoch: 5| Step: 4
Training loss: 0.6999233961105347
Validation loss: 1.8600195787286247

Epoch: 5| Step: 5
Training loss: 0.5658162832260132
Validation loss: 1.8363553324053365

Epoch: 5| Step: 6
Training loss: 0.5769366025924683
Validation loss: 1.819795476493015

Epoch: 5| Step: 7
Training loss: 0.5671743154525757
Validation loss: 1.7895447490035847

Epoch: 5| Step: 8
Training loss: 0.6836320161819458
Validation loss: 1.7852945494395431

Epoch: 5| Step: 9
Training loss: 0.4788249433040619
Validation loss: 1.754030401988696

Epoch: 5| Step: 10
Training loss: 0.56276935338974
Validation loss: 1.7388078833139071

Epoch: 327| Step: 0
Training loss: 0.5331927537918091
Validation loss: 1.7494621469128517

Epoch: 5| Step: 1
Training loss: 0.872569739818573
Validation loss: 1.741496539884998

Epoch: 5| Step: 2
Training loss: 0.6404215693473816
Validation loss: 1.7463865664697462

Epoch: 5| Step: 3
Training loss: 0.4654180407524109
Validation loss: 1.752720372651213

Epoch: 5| Step: 4
Training loss: 0.5699938535690308
Validation loss: 1.7614764257143902

Epoch: 5| Step: 5
Training loss: 0.5975977182388306
Validation loss: 1.8137372052797707

Epoch: 5| Step: 6
Training loss: 0.7357798218727112
Validation loss: 1.8542305038821312

Epoch: 5| Step: 7
Training loss: 0.681024432182312
Validation loss: 1.9124537232101604

Epoch: 5| Step: 8
Training loss: 0.6312823295593262
Validation loss: 1.861425115216163

Epoch: 5| Step: 9
Training loss: 0.725190281867981
Validation loss: 1.815077120257962

Epoch: 5| Step: 10
Training loss: 0.849590003490448
Validation loss: 1.7840988148925125

Epoch: 328| Step: 0
Training loss: 0.5379632115364075
Validation loss: 1.7595278242582917

Epoch: 5| Step: 1
Training loss: 0.5185624361038208
Validation loss: 1.7451253514136038

Epoch: 5| Step: 2
Training loss: 1.0182685852050781
Validation loss: 1.7031871836672547

Epoch: 5| Step: 3
Training loss: 0.5981091260910034
Validation loss: 1.7366238024926954

Epoch: 5| Step: 4
Training loss: 0.49886593222618103
Validation loss: 1.7789845928069083

Epoch: 5| Step: 5
Training loss: 0.6638009548187256
Validation loss: 1.7710556778856503

Epoch: 5| Step: 6
Training loss: 0.5033873319625854
Validation loss: 1.7724577406401276

Epoch: 5| Step: 7
Training loss: 0.6816383600234985
Validation loss: 1.816775837252217

Epoch: 5| Step: 8
Training loss: 0.5084718465805054
Validation loss: 1.8221685912019463

Epoch: 5| Step: 9
Training loss: 0.6896450519561768
Validation loss: 1.8036293381003923

Epoch: 5| Step: 10
Training loss: 0.657616138458252
Validation loss: 1.7849690119425456

Epoch: 329| Step: 0
Training loss: 0.5773561596870422
Validation loss: 1.7669911717855802

Epoch: 5| Step: 1
Training loss: 0.507479190826416
Validation loss: 1.7405657742613105

Epoch: 5| Step: 2
Training loss: 0.5062071084976196
Validation loss: 1.7501654689029982

Epoch: 5| Step: 3
Training loss: 1.005213737487793
Validation loss: 1.7325885962414485

Epoch: 5| Step: 4
Training loss: 0.6233323812484741
Validation loss: 1.706652231113885

Epoch: 5| Step: 5
Training loss: 0.6635218262672424
Validation loss: 1.7291746857345744

Epoch: 5| Step: 6
Training loss: 0.72918301820755
Validation loss: 1.730080560971332

Epoch: 5| Step: 7
Training loss: 0.38032642006874084
Validation loss: 1.7632820170412782

Epoch: 5| Step: 8
Training loss: 0.6818679571151733
Validation loss: 1.7855321848264305

Epoch: 5| Step: 9
Training loss: 0.6721028089523315
Validation loss: 1.8836739601627472

Epoch: 5| Step: 10
Training loss: 0.5700117349624634
Validation loss: 1.8948759507107478

Epoch: 330| Step: 0
Training loss: 0.804800808429718
Validation loss: 1.8925729708005024

Epoch: 5| Step: 1
Training loss: 0.6408756971359253
Validation loss: 1.7894610217822495

Epoch: 5| Step: 2
Training loss: 0.5740847587585449
Validation loss: 1.7519346898601902

Epoch: 5| Step: 3
Training loss: 0.9027145504951477
Validation loss: 1.7321450082204675

Epoch: 5| Step: 4
Training loss: 0.7497602105140686
Validation loss: 1.7084309003686393

Epoch: 5| Step: 5
Training loss: 0.5012350678443909
Validation loss: 1.7348671933656097

Epoch: 5| Step: 6
Training loss: 0.5869587659835815
Validation loss: 1.7580155685383787

Epoch: 5| Step: 7
Training loss: 0.3861772119998932
Validation loss: 1.7430816081262404

Epoch: 5| Step: 8
Training loss: 0.4625399112701416
Validation loss: 1.7501366997277865

Epoch: 5| Step: 9
Training loss: 0.7054790258407593
Validation loss: 1.7628683710610995

Epoch: 5| Step: 10
Training loss: 0.48872503638267517
Validation loss: 1.7799957157463155

Epoch: 331| Step: 0
Training loss: 0.48323068022727966
Validation loss: 1.8235602327572402

Epoch: 5| Step: 1
Training loss: 0.8048561215400696
Validation loss: 1.8254949995266494

Epoch: 5| Step: 2
Training loss: 0.8612291216850281
Validation loss: 1.8164611913824593

Epoch: 5| Step: 3
Training loss: 0.786187469959259
Validation loss: 1.8083729731139315

Epoch: 5| Step: 4
Training loss: 0.5118588209152222
Validation loss: 1.785965096565985

Epoch: 5| Step: 5
Training loss: 0.508284866809845
Validation loss: 1.7719455034502092

Epoch: 5| Step: 6
Training loss: 0.8611634969711304
Validation loss: 1.8002001226589244

Epoch: 5| Step: 7
Training loss: 0.6105077266693115
Validation loss: 1.8308020791699808

Epoch: 5| Step: 8
Training loss: 0.6772910356521606
Validation loss: 1.8322858964243243

Epoch: 5| Step: 9
Training loss: 0.5215306282043457
Validation loss: 1.8391945208272626

Epoch: 5| Step: 10
Training loss: 0.2979777157306671
Validation loss: 1.8217888160418438

Epoch: 332| Step: 0
Training loss: 0.4089972972869873
Validation loss: 1.7863687020476147

Epoch: 5| Step: 1
Training loss: 0.4085655212402344
Validation loss: 1.7931612255752727

Epoch: 5| Step: 2
Training loss: 0.4819699823856354
Validation loss: 1.7649451789035593

Epoch: 5| Step: 3
Training loss: 0.6552959680557251
Validation loss: 1.7547737424091627

Epoch: 5| Step: 4
Training loss: 0.5701291561126709
Validation loss: 1.7671415741725633

Epoch: 5| Step: 5
Training loss: 0.9393776059150696
Validation loss: 1.7737205464352843

Epoch: 5| Step: 6
Training loss: 0.7254856824874878
Validation loss: 1.727862661884677

Epoch: 5| Step: 7
Training loss: 0.5410717725753784
Validation loss: 1.7465555180785477

Epoch: 5| Step: 8
Training loss: 0.5993934869766235
Validation loss: 1.7710063393397997

Epoch: 5| Step: 9
Training loss: 0.7438041567802429
Validation loss: 1.7863915825402865

Epoch: 5| Step: 10
Training loss: 0.5454212427139282
Validation loss: 1.7552729947592622

Epoch: 333| Step: 0
Training loss: 0.5394670367240906
Validation loss: 1.7417396524901032

Epoch: 5| Step: 1
Training loss: 0.6036390066146851
Validation loss: 1.7458985697838567

Epoch: 5| Step: 2
Training loss: 0.7827565670013428
Validation loss: 1.729858257437265

Epoch: 5| Step: 3
Training loss: 0.43103542923927307
Validation loss: 1.7563559393728934

Epoch: 5| Step: 4
Training loss: 0.8196584582328796
Validation loss: 1.7486356381447083

Epoch: 5| Step: 5
Training loss: 0.533015251159668
Validation loss: 1.804787366620956

Epoch: 5| Step: 6
Training loss: 0.6150647401809692
Validation loss: 1.8096657645317815

Epoch: 5| Step: 7
Training loss: 0.5650392770767212
Validation loss: 1.8047321752835346

Epoch: 5| Step: 8
Training loss: 0.4289006292819977
Validation loss: 1.789520812290971

Epoch: 5| Step: 9
Training loss: 0.5952858924865723
Validation loss: 1.7566215633064188

Epoch: 5| Step: 10
Training loss: 0.7025376558303833
Validation loss: 1.7660722014724568

Epoch: 334| Step: 0
Training loss: 0.6334524154663086
Validation loss: 1.7998042196355841

Epoch: 5| Step: 1
Training loss: 0.5810095071792603
Validation loss: 1.8269776618608864

Epoch: 5| Step: 2
Training loss: 0.5996435880661011
Validation loss: 1.783142356462376

Epoch: 5| Step: 3
Training loss: 0.5877807140350342
Validation loss: 1.7994930333988641

Epoch: 5| Step: 4
Training loss: 0.6373732686042786
Validation loss: 1.7489256820371073

Epoch: 5| Step: 5
Training loss: 0.5702029466629028
Validation loss: 1.7478382638705674

Epoch: 5| Step: 6
Training loss: 0.771519660949707
Validation loss: 1.7324963038967502

Epoch: 5| Step: 7
Training loss: 0.5854316353797913
Validation loss: 1.7365214824676514

Epoch: 5| Step: 8
Training loss: 0.6153525114059448
Validation loss: 1.7501713870674052

Epoch: 5| Step: 9
Training loss: 0.30655723810195923
Validation loss: 1.7495822637311873

Epoch: 5| Step: 10
Training loss: 0.6278074979782104
Validation loss: 1.7343900536978116

Epoch: 335| Step: 0
Training loss: 0.49360084533691406
Validation loss: 1.797039439601283

Epoch: 5| Step: 1
Training loss: 0.7016869187355042
Validation loss: 1.7818542142068186

Epoch: 5| Step: 2
Training loss: 0.41297125816345215
Validation loss: 1.7388897108775314

Epoch: 5| Step: 3
Training loss: 0.5845621228218079
Validation loss: 1.7056844901013117

Epoch: 5| Step: 4
Training loss: 0.3757535517215729
Validation loss: 1.7017384946987193

Epoch: 5| Step: 5
Training loss: 0.9532154202461243
Validation loss: 1.7125531319648988

Epoch: 5| Step: 6
Training loss: 0.6253522634506226
Validation loss: 1.7186739316550634

Epoch: 5| Step: 7
Training loss: 0.42826104164123535
Validation loss: 1.7273070427679247

Epoch: 5| Step: 8
Training loss: 0.29213768243789673
Validation loss: 1.7210540899666407

Epoch: 5| Step: 9
Training loss: 0.78331458568573
Validation loss: 1.783121996028449

Epoch: 5| Step: 10
Training loss: 0.6566447615623474
Validation loss: 1.7802283238339167

Epoch: 336| Step: 0
Training loss: 0.6409174799919128
Validation loss: 1.7765888885785175

Epoch: 5| Step: 1
Training loss: 0.7156077027320862
Validation loss: 1.781883374337227

Epoch: 5| Step: 2
Training loss: 0.4564586281776428
Validation loss: 1.7588535995893582

Epoch: 5| Step: 3
Training loss: 0.3700665235519409
Validation loss: 1.7542667696552892

Epoch: 5| Step: 4
Training loss: 0.47851377725601196
Validation loss: 1.7503801186879475

Epoch: 5| Step: 5
Training loss: 0.8255467414855957
Validation loss: 1.7386636528917538

Epoch: 5| Step: 6
Training loss: 0.4719013273715973
Validation loss: 1.7570237075128863

Epoch: 5| Step: 7
Training loss: 0.6413060426712036
Validation loss: 1.7446537774096254

Epoch: 5| Step: 8
Training loss: 0.4990842938423157
Validation loss: 1.7462783141802716

Epoch: 5| Step: 9
Training loss: 0.4326143264770508
Validation loss: 1.7143047919837378

Epoch: 5| Step: 10
Training loss: 0.5615108013153076
Validation loss: 1.7022792305997623

Epoch: 337| Step: 0
Training loss: 0.7308974266052246
Validation loss: 1.6722528601205477

Epoch: 5| Step: 1
Training loss: 0.5614068508148193
Validation loss: 1.6922630417731501

Epoch: 5| Step: 2
Training loss: 0.27959781885147095
Validation loss: 1.7185341055675218

Epoch: 5| Step: 3
Training loss: 0.6068143248558044
Validation loss: 1.764654476155517

Epoch: 5| Step: 4
Training loss: 0.445692777633667
Validation loss: 1.7942284294354018

Epoch: 5| Step: 5
Training loss: 0.6531651616096497
Validation loss: 1.795051056851623

Epoch: 5| Step: 6
Training loss: 0.47898760437965393
Validation loss: 1.8259287726494573

Epoch: 5| Step: 7
Training loss: 1.0484535694122314
Validation loss: 1.797815010111819

Epoch: 5| Step: 8
Training loss: 0.3402552306652069
Validation loss: 1.7647261568295058

Epoch: 5| Step: 9
Training loss: 0.41155052185058594
Validation loss: 1.74319637462657

Epoch: 5| Step: 10
Training loss: 0.5509902834892273
Validation loss: 1.7095465544731385

Epoch: 338| Step: 0
Training loss: 0.6373535990715027
Validation loss: 1.7189277513052827

Epoch: 5| Step: 1
Training loss: 0.6509889960289001
Validation loss: 1.736718996237683

Epoch: 5| Step: 2
Training loss: 0.40203657746315
Validation loss: 1.7577808146835656

Epoch: 5| Step: 3
Training loss: 0.5898040533065796
Validation loss: 1.8111738594629432

Epoch: 5| Step: 4
Training loss: 0.6033579707145691
Validation loss: 1.8201711485462804

Epoch: 5| Step: 5
Training loss: 0.24841006100177765
Validation loss: 1.8340320151339295

Epoch: 5| Step: 6
Training loss: 0.8409775495529175
Validation loss: 1.7945355125652847

Epoch: 5| Step: 7
Training loss: 0.5857124328613281
Validation loss: 1.768501482984071

Epoch: 5| Step: 8
Training loss: 0.4115602374076843
Validation loss: 1.7554051594067646

Epoch: 5| Step: 9
Training loss: 0.5437026023864746
Validation loss: 1.7051734924316406

Epoch: 5| Step: 10
Training loss: 0.7724114060401917
Validation loss: 1.697375678247021

Epoch: 339| Step: 0
Training loss: 0.6500309705734253
Validation loss: 1.7066328333270164

Epoch: 5| Step: 1
Training loss: 0.5443056225776672
Validation loss: 1.6876513881068076

Epoch: 5| Step: 2
Training loss: 0.5877455472946167
Validation loss: 1.687876848764317

Epoch: 5| Step: 3
Training loss: 0.5515528917312622
Validation loss: 1.717866172072708

Epoch: 5| Step: 4
Training loss: 0.3909896910190582
Validation loss: 1.7658744640247797

Epoch: 5| Step: 5
Training loss: 0.8028256297111511
Validation loss: 1.8109482360142533

Epoch: 5| Step: 6
Training loss: 0.5532664656639099
Validation loss: 1.8349506739647157

Epoch: 5| Step: 7
Training loss: 0.8661321401596069
Validation loss: 1.9260889637854792

Epoch: 5| Step: 8
Training loss: 0.7452765703201294
Validation loss: 1.880076478886348

Epoch: 5| Step: 9
Training loss: 0.48417574167251587
Validation loss: 1.817105435555981

Epoch: 5| Step: 10
Training loss: 0.3916732370853424
Validation loss: 1.7718501398640294

Epoch: 340| Step: 0
Training loss: 0.5985487699508667
Validation loss: 1.7322349984158751

Epoch: 5| Step: 1
Training loss: 0.7231395244598389
Validation loss: 1.7273936989486858

Epoch: 5| Step: 2
Training loss: 0.7318581938743591
Validation loss: 1.7125866195207

Epoch: 5| Step: 3
Training loss: 0.44719499349594116
Validation loss: 1.7080179106804632

Epoch: 5| Step: 4
Training loss: 0.4237504005432129
Validation loss: 1.7142244256952757

Epoch: 5| Step: 5
Training loss: 0.33810538053512573
Validation loss: 1.7294067836576892

Epoch: 5| Step: 6
Training loss: 0.4973139762878418
Validation loss: 1.7638512119170158

Epoch: 5| Step: 7
Training loss: 0.435030460357666
Validation loss: 1.784711153276505

Epoch: 5| Step: 8
Training loss: 0.5757454633712769
Validation loss: 1.806206718567879

Epoch: 5| Step: 9
Training loss: 0.8306354284286499
Validation loss: 1.8149839396117835

Epoch: 5| Step: 10
Training loss: 0.5092588067054749
Validation loss: 1.7976430359707083

Epoch: 341| Step: 0
Training loss: 0.5168172717094421
Validation loss: 1.7781496496610745

Epoch: 5| Step: 1
Training loss: 0.6068639755249023
Validation loss: 1.7713080221606838

Epoch: 5| Step: 2
Training loss: 0.563278079032898
Validation loss: 1.7584543920332385

Epoch: 5| Step: 3
Training loss: 0.9235620498657227
Validation loss: 1.7429390927796722

Epoch: 5| Step: 4
Training loss: 0.47022348642349243
Validation loss: 1.7348990491641465

Epoch: 5| Step: 5
Training loss: 0.5984086990356445
Validation loss: 1.6996860760514454

Epoch: 5| Step: 6
Training loss: 0.7262210845947266
Validation loss: 1.6939025976324593

Epoch: 5| Step: 7
Training loss: 0.42882204055786133
Validation loss: 1.688104607725656

Epoch: 5| Step: 8
Training loss: 0.38295021653175354
Validation loss: 1.686649881383424

Epoch: 5| Step: 9
Training loss: 0.32521873712539673
Validation loss: 1.7196382143164193

Epoch: 5| Step: 10
Training loss: 0.20425280928611755
Validation loss: 1.7231024977981404

Epoch: 342| Step: 0
Training loss: 0.8014768362045288
Validation loss: 1.7197728310861895

Epoch: 5| Step: 1
Training loss: 0.6007610559463501
Validation loss: 1.734455939262144

Epoch: 5| Step: 2
Training loss: 0.5240170955657959
Validation loss: 1.692469564817285

Epoch: 5| Step: 3
Training loss: 0.6475878953933716
Validation loss: 1.7224443599741945

Epoch: 5| Step: 4
Training loss: 0.6425073742866516
Validation loss: 1.7341426854492517

Epoch: 5| Step: 5
Training loss: 0.3666146397590637
Validation loss: 1.7526632649924165

Epoch: 5| Step: 6
Training loss: 0.5196953415870667
Validation loss: 1.7842840456193494

Epoch: 5| Step: 7
Training loss: 0.37063977122306824
Validation loss: 1.7900893162655573

Epoch: 5| Step: 8
Training loss: 0.6195083856582642
Validation loss: 1.8198001243734871

Epoch: 5| Step: 9
Training loss: 0.3695369064807892
Validation loss: 1.826695490908879

Epoch: 5| Step: 10
Training loss: 0.25312989950180054
Validation loss: 1.8339428709399315

Epoch: 343| Step: 0
Training loss: 0.3126237392425537
Validation loss: 1.794680432606769

Epoch: 5| Step: 1
Training loss: 0.3751158118247986
Validation loss: 1.7878581964841453

Epoch: 5| Step: 2
Training loss: 0.5772629976272583
Validation loss: 1.7756912644191454

Epoch: 5| Step: 3
Training loss: 0.45013007521629333
Validation loss: 1.7321173426925496

Epoch: 5| Step: 4
Training loss: 0.5736921429634094
Validation loss: 1.7160915469610563

Epoch: 5| Step: 5
Training loss: 0.6871967315673828
Validation loss: 1.7282730020502561

Epoch: 5| Step: 6
Training loss: 0.7569162249565125
Validation loss: 1.728643835231822

Epoch: 5| Step: 7
Training loss: 0.62200927734375
Validation loss: 1.7483275692950013

Epoch: 5| Step: 8
Training loss: 0.4776178002357483
Validation loss: 1.7303759051907448

Epoch: 5| Step: 9
Training loss: 0.5171638131141663
Validation loss: 1.7400513361859065

Epoch: 5| Step: 10
Training loss: 0.6227413415908813
Validation loss: 1.746068267412083

Epoch: 344| Step: 0
Training loss: 0.5926910638809204
Validation loss: 1.7454239655566472

Epoch: 5| Step: 1
Training loss: 0.40957850217819214
Validation loss: 1.8062182088052072

Epoch: 5| Step: 2
Training loss: 0.6254915595054626
Validation loss: 1.833631306566218

Epoch: 5| Step: 3
Training loss: 0.6881371140480042
Validation loss: 1.8535612578033118

Epoch: 5| Step: 4
Training loss: 0.5599237680435181
Validation loss: 1.863927725822695

Epoch: 5| Step: 5
Training loss: 0.5810065269470215
Validation loss: 1.8976260282660042

Epoch: 5| Step: 6
Training loss: 0.3829619288444519
Validation loss: 1.8550849409513577

Epoch: 5| Step: 7
Training loss: 0.9620168805122375
Validation loss: 1.7999742941189838

Epoch: 5| Step: 8
Training loss: 0.6959161758422852
Validation loss: 1.74607051316128

Epoch: 5| Step: 9
Training loss: 0.22532252967357635
Validation loss: 1.6863635124698761

Epoch: 5| Step: 10
Training loss: 0.42480990290641785
Validation loss: 1.6831580964467858

Epoch: 345| Step: 0
Training loss: 0.5900967717170715
Validation loss: 1.6568693089228805

Epoch: 5| Step: 1
Training loss: 0.5149269104003906
Validation loss: 1.678283473496796

Epoch: 5| Step: 2
Training loss: 0.5223215818405151
Validation loss: 1.678309173994167

Epoch: 5| Step: 3
Training loss: 0.7207354307174683
Validation loss: 1.6973093991638513

Epoch: 5| Step: 4
Training loss: 0.3620913624763489
Validation loss: 1.7148895225217264

Epoch: 5| Step: 5
Training loss: 0.9648836255073547
Validation loss: 1.776969608440194

Epoch: 5| Step: 6
Training loss: 0.633614718914032
Validation loss: 1.8413171293914958

Epoch: 5| Step: 7
Training loss: 0.4177418649196625
Validation loss: 1.8012991002810899

Epoch: 5| Step: 8
Training loss: 0.4119926393032074
Validation loss: 1.7866338401712396

Epoch: 5| Step: 9
Training loss: 0.4718310236930847
Validation loss: 1.7455698649088542

Epoch: 5| Step: 10
Training loss: 0.4136902987957001
Validation loss: 1.7439251971501175

Epoch: 346| Step: 0
Training loss: 0.6826573014259338
Validation loss: 1.73670906020749

Epoch: 5| Step: 1
Training loss: 0.5909687876701355
Validation loss: 1.738328936279461

Epoch: 5| Step: 2
Training loss: 0.61431485414505
Validation loss: 1.7489904485723025

Epoch: 5| Step: 3
Training loss: 0.23306933045387268
Validation loss: 1.7436795888408538

Epoch: 5| Step: 4
Training loss: 0.5857898592948914
Validation loss: 1.7505743900934856

Epoch: 5| Step: 5
Training loss: 0.3542710840702057
Validation loss: 1.7298452085064304

Epoch: 5| Step: 6
Training loss: 0.5939595103263855
Validation loss: 1.7222047646840413

Epoch: 5| Step: 7
Training loss: 0.6977514624595642
Validation loss: 1.7653111168133315

Epoch: 5| Step: 8
Training loss: 0.6374648213386536
Validation loss: 1.786146640777588

Epoch: 5| Step: 9
Training loss: 0.5477262735366821
Validation loss: 1.8053071601416475

Epoch: 5| Step: 10
Training loss: 0.45611506700515747
Validation loss: 1.8277570637323524

Epoch: 347| Step: 0
Training loss: 0.33120542764663696
Validation loss: 1.8150693037176644

Epoch: 5| Step: 1
Training loss: 0.8013448715209961
Validation loss: 1.790907491919815

Epoch: 5| Step: 2
Training loss: 0.42912188172340393
Validation loss: 1.7662269505121375

Epoch: 5| Step: 3
Training loss: 0.7074177861213684
Validation loss: 1.7462572795088573

Epoch: 5| Step: 4
Training loss: 0.6789969205856323
Validation loss: 1.7269668720101798

Epoch: 5| Step: 5
Training loss: 0.482339084148407
Validation loss: 1.6674700398598947

Epoch: 5| Step: 6
Training loss: 0.47126007080078125
Validation loss: 1.7209226239112116

Epoch: 5| Step: 7
Training loss: 0.7068233489990234
Validation loss: 1.7096697258692917

Epoch: 5| Step: 8
Training loss: 0.4855332374572754
Validation loss: 1.6994978356105026

Epoch: 5| Step: 9
Training loss: 0.3408384919166565
Validation loss: 1.7013395332521009

Epoch: 5| Step: 10
Training loss: 0.533610463142395
Validation loss: 1.7423072079176545

Epoch: 348| Step: 0
Training loss: 0.3911794126033783
Validation loss: 1.7650778787110442

Epoch: 5| Step: 1
Training loss: 0.473524272441864
Validation loss: 1.8235041172273698

Epoch: 5| Step: 2
Training loss: 0.6552390456199646
Validation loss: 1.8186248066604778

Epoch: 5| Step: 3
Training loss: 0.5120413303375244
Validation loss: 1.758580288579387

Epoch: 5| Step: 4
Training loss: 0.5567809343338013
Validation loss: 1.7315161471725793

Epoch: 5| Step: 5
Training loss: 0.673503041267395
Validation loss: 1.6734226890789565

Epoch: 5| Step: 6
Training loss: 0.40356212854385376
Validation loss: 1.6876863292468491

Epoch: 5| Step: 7
Training loss: 0.5735287666320801
Validation loss: 1.6895604031060332

Epoch: 5| Step: 8
Training loss: 0.5580205917358398
Validation loss: 1.6655640486747987

Epoch: 5| Step: 9
Training loss: 0.6611603498458862
Validation loss: 1.6826393758097002

Epoch: 5| Step: 10
Training loss: 0.5117015838623047
Validation loss: 1.6701497236887615

Epoch: 349| Step: 0
Training loss: 0.849514365196228
Validation loss: 1.7210611130601616

Epoch: 5| Step: 1
Training loss: 0.5633472204208374
Validation loss: 1.737833917781871

Epoch: 5| Step: 2
Training loss: 0.528946578502655
Validation loss: 1.7399147133673392

Epoch: 5| Step: 3
Training loss: 0.5007984042167664
Validation loss: 1.720247430186118

Epoch: 5| Step: 4
Training loss: 0.5682098269462585
Validation loss: 1.7063957927047566

Epoch: 5| Step: 5
Training loss: 0.44138574600219727
Validation loss: 1.7074440140878

Epoch: 5| Step: 6
Training loss: 0.6730407476425171
Validation loss: 1.7349881177307458

Epoch: 5| Step: 7
Training loss: 0.41871100664138794
Validation loss: 1.7724894323656637

Epoch: 5| Step: 8
Training loss: 0.5835551023483276
Validation loss: 1.7495317728288713

Epoch: 5| Step: 9
Training loss: 0.330159068107605
Validation loss: 1.7251018067841888

Epoch: 5| Step: 10
Training loss: 0.6696943044662476
Validation loss: 1.6865060970347414

Epoch: 350| Step: 0
Training loss: 0.40926188230514526
Validation loss: 1.678741785787767

Epoch: 5| Step: 1
Training loss: 0.6586118936538696
Validation loss: 1.6476987677235757

Epoch: 5| Step: 2
Training loss: 0.7428140640258789
Validation loss: 1.6771454939278223

Epoch: 5| Step: 3
Training loss: 0.3681536018848419
Validation loss: 1.7028488138670563

Epoch: 5| Step: 4
Training loss: 0.5091687440872192
Validation loss: 1.6937697984838997

Epoch: 5| Step: 5
Training loss: 0.3549231290817261
Validation loss: 1.7225517944623066

Epoch: 5| Step: 6
Training loss: 0.4876512587070465
Validation loss: 1.720526982379216

Epoch: 5| Step: 7
Training loss: 0.49542099237442017
Validation loss: 1.7541794469279628

Epoch: 5| Step: 8
Training loss: 0.38559651374816895
Validation loss: 1.7566586636727857

Epoch: 5| Step: 9
Training loss: 0.6525624990463257
Validation loss: 1.773381067860511

Epoch: 5| Step: 10
Training loss: 0.6759048104286194
Validation loss: 1.7541812209672825

Epoch: 351| Step: 0
Training loss: 0.6976172924041748
Validation loss: 1.791649749202113

Epoch: 5| Step: 1
Training loss: 0.3491474986076355
Validation loss: 1.7482034672972977

Epoch: 5| Step: 2
Training loss: 0.4174448847770691
Validation loss: 1.7873056011815225

Epoch: 5| Step: 3
Training loss: 0.7461329698562622
Validation loss: 1.7259077077270837

Epoch: 5| Step: 4
Training loss: 0.4255431592464447
Validation loss: 1.7209810569722166

Epoch: 5| Step: 5
Training loss: 0.2654072642326355
Validation loss: 1.7114744827311525

Epoch: 5| Step: 6
Training loss: 0.580389678478241
Validation loss: 1.7034883037690194

Epoch: 5| Step: 7
Training loss: 0.43232887983322144
Validation loss: 1.696293827026121

Epoch: 5| Step: 8
Training loss: 0.465705931186676
Validation loss: 1.708862620015298

Epoch: 5| Step: 9
Training loss: 0.46598395705223083
Validation loss: 1.716693893555672

Epoch: 5| Step: 10
Training loss: 0.7038742303848267
Validation loss: 1.7268718263154388

Epoch: 352| Step: 0
Training loss: 0.45716971158981323
Validation loss: 1.7399341303815123

Epoch: 5| Step: 1
Training loss: 0.5501594543457031
Validation loss: 1.7548303322125507

Epoch: 5| Step: 2
Training loss: 0.7194783687591553
Validation loss: 1.8006093425135459

Epoch: 5| Step: 3
Training loss: 0.649276852607727
Validation loss: 1.7943035351332797

Epoch: 5| Step: 4
Training loss: 0.3647133409976959
Validation loss: 1.72934050713816

Epoch: 5| Step: 5
Training loss: 0.7054547071456909
Validation loss: 1.7074757493952268

Epoch: 5| Step: 6
Training loss: 0.2727753520011902
Validation loss: 1.6773197599636611

Epoch: 5| Step: 7
Training loss: 0.36359789967536926
Validation loss: 1.6922804719658309

Epoch: 5| Step: 8
Training loss: 0.5591490864753723
Validation loss: 1.6344961927783104

Epoch: 5| Step: 9
Training loss: 0.3341013491153717
Validation loss: 1.660077521877904

Epoch: 5| Step: 10
Training loss: 0.6353828310966492
Validation loss: 1.6952071523153653

Epoch: 353| Step: 0
Training loss: 0.39260345697402954
Validation loss: 1.6949853974003946

Epoch: 5| Step: 1
Training loss: 0.5055071711540222
Validation loss: 1.7222815059846448

Epoch: 5| Step: 2
Training loss: 0.6678818464279175
Validation loss: 1.7484533761137275

Epoch: 5| Step: 3
Training loss: 0.5250622630119324
Validation loss: 1.7828371229992117

Epoch: 5| Step: 4
Training loss: 0.5055153369903564
Validation loss: 1.8230471444386307

Epoch: 5| Step: 5
Training loss: 0.655376672744751
Validation loss: 1.826238586056617

Epoch: 5| Step: 6
Training loss: 0.31192439794540405
Validation loss: 1.7561683680421563

Epoch: 5| Step: 7
Training loss: 0.587431013584137
Validation loss: 1.7048086350963962

Epoch: 5| Step: 8
Training loss: 0.44880732893943787
Validation loss: 1.6900502186949535

Epoch: 5| Step: 9
Training loss: 0.4532518982887268
Validation loss: 1.6504154794959611

Epoch: 5| Step: 10
Training loss: 0.43268200755119324
Validation loss: 1.6938988777898973

Epoch: 354| Step: 0
Training loss: 0.6196239590644836
Validation loss: 1.682932214070392

Epoch: 5| Step: 1
Training loss: 0.6209574937820435
Validation loss: 1.7270396371041574

Epoch: 5| Step: 2
Training loss: 0.3764127194881439
Validation loss: 1.7180365093292729

Epoch: 5| Step: 3
Training loss: 0.6400653123855591
Validation loss: 1.7218140068874563

Epoch: 5| Step: 4
Training loss: 0.16107875108718872
Validation loss: 1.7767888192207582

Epoch: 5| Step: 5
Training loss: 0.4784620404243469
Validation loss: 1.752498435717757

Epoch: 5| Step: 6
Training loss: 0.31060582399368286
Validation loss: 1.731517671256937

Epoch: 5| Step: 7
Training loss: 0.58753901720047
Validation loss: 1.7023758939517442

Epoch: 5| Step: 8
Training loss: 0.2669302523136139
Validation loss: 1.6747942009279806

Epoch: 5| Step: 9
Training loss: 0.32941141724586487
Validation loss: 1.6937683654087845

Epoch: 5| Step: 10
Training loss: 0.7969493865966797
Validation loss: 1.6823691450139528

Epoch: 355| Step: 0
Training loss: 0.2799312472343445
Validation loss: 1.6953309864126227

Epoch: 5| Step: 1
Training loss: 0.45969662070274353
Validation loss: 1.7274111560595933

Epoch: 5| Step: 2
Training loss: 0.6337990164756775
Validation loss: 1.7330499131192443

Epoch: 5| Step: 3
Training loss: 0.4933672845363617
Validation loss: 1.7261321698465655

Epoch: 5| Step: 4
Training loss: 0.4491618275642395
Validation loss: 1.69753441374789

Epoch: 5| Step: 5
Training loss: 0.49046915769577026
Validation loss: 1.6678941775393743

Epoch: 5| Step: 6
Training loss: 0.28758352994918823
Validation loss: 1.6513824373163202

Epoch: 5| Step: 7
Training loss: 0.3777334988117218
Validation loss: 1.6597888726060108

Epoch: 5| Step: 8
Training loss: 0.27939626574516296
Validation loss: 1.6719648684224775

Epoch: 5| Step: 9
Training loss: 0.8078604936599731
Validation loss: 1.6639100018367972

Epoch: 5| Step: 10
Training loss: 0.6503329277038574
Validation loss: 1.6730471836623324

Epoch: 356| Step: 0
Training loss: 0.52644282579422
Validation loss: 1.690197278094548

Epoch: 5| Step: 1
Training loss: 0.6840669512748718
Validation loss: 1.7091563683684154

Epoch: 5| Step: 2
Training loss: 0.5981748700141907
Validation loss: 1.7236871975724415

Epoch: 5| Step: 3
Training loss: 0.378103107213974
Validation loss: 1.7341461502095705

Epoch: 5| Step: 4
Training loss: 0.3871448040008545
Validation loss: 1.7399625252651911

Epoch: 5| Step: 5
Training loss: 0.6136406660079956
Validation loss: 1.7435593810132755

Epoch: 5| Step: 6
Training loss: 0.2692703902721405
Validation loss: 1.7360372107516053

Epoch: 5| Step: 7
Training loss: 0.3610910475254059
Validation loss: 1.7236101146667235

Epoch: 5| Step: 8
Training loss: 0.3168911933898926
Validation loss: 1.740260124206543

Epoch: 5| Step: 9
Training loss: 0.36514294147491455
Validation loss: 1.7017958369306339

Epoch: 5| Step: 10
Training loss: 0.39128002524375916
Validation loss: 1.6901836209399725

Epoch: 357| Step: 0
Training loss: 0.42767634987831116
Validation loss: 1.7022494974956717

Epoch: 5| Step: 1
Training loss: 0.6286451816558838
Validation loss: 1.723640070166639

Epoch: 5| Step: 2
Training loss: 0.45188769698143005
Validation loss: 1.7456000735682826

Epoch: 5| Step: 3
Training loss: 0.4393445551395416
Validation loss: 1.7195247065636419

Epoch: 5| Step: 4
Training loss: 0.819536030292511
Validation loss: 1.7070989326764179

Epoch: 5| Step: 5
Training loss: 0.3720298409461975
Validation loss: 1.674955218069015

Epoch: 5| Step: 6
Training loss: 0.23845966160297394
Validation loss: 1.6624191794344174

Epoch: 5| Step: 7
Training loss: 0.35164889693260193
Validation loss: 1.6628566429179201

Epoch: 5| Step: 8
Training loss: 0.4444020390510559
Validation loss: 1.6717454848750946

Epoch: 5| Step: 9
Training loss: 0.3834671080112457
Validation loss: 1.6806831206044843

Epoch: 5| Step: 10
Training loss: 0.2557774484157562
Validation loss: 1.6905568645846458

Epoch: 358| Step: 0
Training loss: 0.27861571311950684
Validation loss: 1.6994482253187446

Epoch: 5| Step: 1
Training loss: 0.45221614837646484
Validation loss: 1.7306476434071858

Epoch: 5| Step: 2
Training loss: 0.5375186800956726
Validation loss: 1.7673335383015294

Epoch: 5| Step: 3
Training loss: 0.22504964470863342
Validation loss: 1.7499376984052761

Epoch: 5| Step: 4
Training loss: 0.3585253357887268
Validation loss: 1.7486494548859135

Epoch: 5| Step: 5
Training loss: 0.5126184225082397
Validation loss: 1.735550348476697

Epoch: 5| Step: 6
Training loss: 0.40142160654067993
Validation loss: 1.7312203786706413

Epoch: 5| Step: 7
Training loss: 0.4169100821018219
Validation loss: 1.7206539838544783

Epoch: 5| Step: 8
Training loss: 0.6146559119224548
Validation loss: 1.7011612820368942

Epoch: 5| Step: 9
Training loss: 0.5175976753234863
Validation loss: 1.6819005973877446

Epoch: 5| Step: 10
Training loss: 0.646165132522583
Validation loss: 1.7091096857542634

Epoch: 359| Step: 0
Training loss: 0.2811017334461212
Validation loss: 1.7112948612500263

Epoch: 5| Step: 1
Training loss: 0.542893648147583
Validation loss: 1.7108253766131658

Epoch: 5| Step: 2
Training loss: 0.514332115650177
Validation loss: 1.7393346191734396

Epoch: 5| Step: 3
Training loss: 0.3589431345462799
Validation loss: 1.7675590079317811

Epoch: 5| Step: 4
Training loss: 0.4302917420864105
Validation loss: 1.7497629286140524

Epoch: 5| Step: 5
Training loss: 0.57381671667099
Validation loss: 1.7164273544024395

Epoch: 5| Step: 6
Training loss: 0.5386167764663696
Validation loss: 1.7304897077621952

Epoch: 5| Step: 7
Training loss: 0.3190235495567322
Validation loss: 1.6788344434512559

Epoch: 5| Step: 8
Training loss: 0.552268385887146
Validation loss: 1.6857421218707997

Epoch: 5| Step: 9
Training loss: 0.37913012504577637
Validation loss: 1.6787108554634997

Epoch: 5| Step: 10
Training loss: 0.6054155826568604
Validation loss: 1.687074399763538

Epoch: 360| Step: 0
Training loss: 0.506435751914978
Validation loss: 1.6691723177509923

Epoch: 5| Step: 1
Training loss: 0.5021125078201294
Validation loss: 1.6822479950484408

Epoch: 5| Step: 2
Training loss: 0.4249936044216156
Validation loss: 1.6942147593344412

Epoch: 5| Step: 3
Training loss: 0.3389509320259094
Validation loss: 1.7087390166456982

Epoch: 5| Step: 4
Training loss: 0.5035204291343689
Validation loss: 1.7316504511781918

Epoch: 5| Step: 5
Training loss: 0.4349699020385742
Validation loss: 1.77731611651759

Epoch: 5| Step: 6
Training loss: 0.4099922776222229
Validation loss: 1.7590169355433474

Epoch: 5| Step: 7
Training loss: 0.6289576292037964
Validation loss: 1.7091374166550175

Epoch: 5| Step: 8
Training loss: 0.3908005654811859
Validation loss: 1.677669535401047

Epoch: 5| Step: 9
Training loss: 0.5015262365341187
Validation loss: 1.677423119544983

Epoch: 5| Step: 10
Training loss: 0.29765310883522034
Validation loss: 1.6533700945556804

Epoch: 361| Step: 0
Training loss: 0.3677327334880829
Validation loss: 1.6646825382786412

Epoch: 5| Step: 1
Training loss: 0.3304908573627472
Validation loss: 1.6828889269982614

Epoch: 5| Step: 2
Training loss: 0.5113961100578308
Validation loss: 1.7326248704746205

Epoch: 5| Step: 3
Training loss: 0.4825933575630188
Validation loss: 1.8006012439727783

Epoch: 5| Step: 4
Training loss: 0.4345908761024475
Validation loss: 1.8230432746230916

Epoch: 5| Step: 5
Training loss: 0.37829992175102234
Validation loss: 1.818078129522262

Epoch: 5| Step: 6
Training loss: 0.534574031829834
Validation loss: 1.7434294941604778

Epoch: 5| Step: 7
Training loss: 0.5291069746017456
Validation loss: 1.694563805416066

Epoch: 5| Step: 8
Training loss: 0.4939475953578949
Validation loss: 1.6490512701772875

Epoch: 5| Step: 9
Training loss: 0.4922052025794983
Validation loss: 1.6515604821584557

Epoch: 5| Step: 10
Training loss: 0.567929208278656
Validation loss: 1.637280043735299

Epoch: 362| Step: 0
Training loss: 0.38219189643859863
Validation loss: 1.6512719777322584

Epoch: 5| Step: 1
Training loss: 0.4340446889400482
Validation loss: 1.657644187250445

Epoch: 5| Step: 2
Training loss: 0.30647969245910645
Validation loss: 1.6450731459484305

Epoch: 5| Step: 3
Training loss: 0.3985539376735687
Validation loss: 1.6701463076376146

Epoch: 5| Step: 4
Training loss: 0.433828204870224
Validation loss: 1.6908967751328663

Epoch: 5| Step: 5
Training loss: 0.5085536241531372
Validation loss: 1.7446657162840649

Epoch: 5| Step: 6
Training loss: 0.4693201184272766
Validation loss: 1.753048122570079

Epoch: 5| Step: 7
Training loss: 0.43507105112075806
Validation loss: 1.770650714956304

Epoch: 5| Step: 8
Training loss: 0.7591320276260376
Validation loss: 1.7633826527544247

Epoch: 5| Step: 9
Training loss: 0.5617386102676392
Validation loss: 1.7613646189371746

Epoch: 5| Step: 10
Training loss: 0.3250490128993988
Validation loss: 1.6954149917889667

Epoch: 363| Step: 0
Training loss: 0.583787202835083
Validation loss: 1.7042137692051549

Epoch: 5| Step: 1
Training loss: 0.3198309540748596
Validation loss: 1.6855850950364144

Epoch: 5| Step: 2
Training loss: 0.5035226345062256
Validation loss: 1.7175867724162277

Epoch: 5| Step: 3
Training loss: 0.3279309868812561
Validation loss: 1.7208422973591795

Epoch: 5| Step: 4
Training loss: 0.3163280487060547
Validation loss: 1.70479449149101

Epoch: 5| Step: 5
Training loss: 0.4688524305820465
Validation loss: 1.7304065445418

Epoch: 5| Step: 6
Training loss: 0.490947961807251
Validation loss: 1.718044227169406

Epoch: 5| Step: 7
Training loss: 0.2848215103149414
Validation loss: 1.7263152624971123

Epoch: 5| Step: 8
Training loss: 0.6383233666419983
Validation loss: 1.712889099633822

Epoch: 5| Step: 9
Training loss: 0.5744554400444031
Validation loss: 1.6641170594000048

Epoch: 5| Step: 10
Training loss: 0.23225176334381104
Validation loss: 1.6411283798115228

Epoch: 364| Step: 0
Training loss: 0.44828882813453674
Validation loss: 1.650530977915692

Epoch: 5| Step: 1
Training loss: 0.3560618758201599
Validation loss: 1.687793331761514

Epoch: 5| Step: 2
Training loss: 0.45943623781204224
Validation loss: 1.6786226585347166

Epoch: 5| Step: 3
Training loss: 0.2145065814256668
Validation loss: 1.6704305718022008

Epoch: 5| Step: 4
Training loss: 0.5117889642715454
Validation loss: 1.7246423998186666

Epoch: 5| Step: 5
Training loss: 0.39502957463264465
Validation loss: 1.750628016328299

Epoch: 5| Step: 6
Training loss: 0.6183064579963684
Validation loss: 1.713315704817413

Epoch: 5| Step: 7
Training loss: 0.5101711750030518
Validation loss: 1.7226689477120676

Epoch: 5| Step: 8
Training loss: 0.3522384762763977
Validation loss: 1.7095441138872536

Epoch: 5| Step: 9
Training loss: 0.4250321388244629
Validation loss: 1.7092095023842269

Epoch: 5| Step: 10
Training loss: 0.449023962020874
Validation loss: 1.700997575636833

Epoch: 365| Step: 0
Training loss: 0.22758522629737854
Validation loss: 1.6713502804438274

Epoch: 5| Step: 1
Training loss: 0.6276088953018188
Validation loss: 1.654664985595211

Epoch: 5| Step: 2
Training loss: 0.32237690687179565
Validation loss: 1.6855056016675887

Epoch: 5| Step: 3
Training loss: 0.3331297039985657
Validation loss: 1.6965440550158102

Epoch: 5| Step: 4
Training loss: 0.47179684042930603
Validation loss: 1.703846062383344

Epoch: 5| Step: 5
Training loss: 0.5661317110061646
Validation loss: 1.7126460716288576

Epoch: 5| Step: 6
Training loss: 0.5016899108886719
Validation loss: 1.733982547636955

Epoch: 5| Step: 7
Training loss: 0.4525744318962097
Validation loss: 1.7389929615041262

Epoch: 5| Step: 8
Training loss: 0.3409918248653412
Validation loss: 1.7110938487514373

Epoch: 5| Step: 9
Training loss: 0.42487382888793945
Validation loss: 1.7097308507529638

Epoch: 5| Step: 10
Training loss: 0.5175676941871643
Validation loss: 1.7398153082016976

Epoch: 366| Step: 0
Training loss: 0.33812907338142395
Validation loss: 1.722392415487638

Epoch: 5| Step: 1
Training loss: 0.3189990520477295
Validation loss: 1.7636338151911253

Epoch: 5| Step: 2
Training loss: 0.380730003118515
Validation loss: 1.7403583065156014

Epoch: 5| Step: 3
Training loss: 0.4338086247444153
Validation loss: 1.7187997730829383

Epoch: 5| Step: 4
Training loss: 0.2870035469532013
Validation loss: 1.6932948404742825

Epoch: 5| Step: 5
Training loss: 0.3453724980354309
Validation loss: 1.7010608526968187

Epoch: 5| Step: 6
Training loss: 0.7919872403144836
Validation loss: 1.675850647752003

Epoch: 5| Step: 7
Training loss: 0.4821264147758484
Validation loss: 1.6744748853868054

Epoch: 5| Step: 8
Training loss: 0.3419458270072937
Validation loss: 1.7021453995858469

Epoch: 5| Step: 9
Training loss: 0.4893820285797119
Validation loss: 1.7139645827713834

Epoch: 5| Step: 10
Training loss: 0.5308654308319092
Validation loss: 1.7398134393076743

Epoch: 367| Step: 0
Training loss: 0.42056602239608765
Validation loss: 1.7392052424851285

Epoch: 5| Step: 1
Training loss: 0.1511879861354828
Validation loss: 1.724749929161482

Epoch: 5| Step: 2
Training loss: 0.678061842918396
Validation loss: 1.699260591178812

Epoch: 5| Step: 3
Training loss: 0.4593849182128906
Validation loss: 1.699690955941395

Epoch: 5| Step: 4
Training loss: 0.6825354695320129
Validation loss: 1.6706893508152296

Epoch: 5| Step: 5
Training loss: 0.5676193237304688
Validation loss: 1.6843904808003416

Epoch: 5| Step: 6
Training loss: 0.36062055826187134
Validation loss: 1.6845307080976424

Epoch: 5| Step: 7
Training loss: 0.1513497680425644
Validation loss: 1.6815684328797043

Epoch: 5| Step: 8
Training loss: 0.3025529980659485
Validation loss: 1.6989788829639394

Epoch: 5| Step: 9
Training loss: 0.38011711835861206
Validation loss: 1.7049111627763318

Epoch: 5| Step: 10
Training loss: 0.4648663103580475
Validation loss: 1.691922813333491

Epoch: 368| Step: 0
Training loss: 0.4754560887813568
Validation loss: 1.712764593862718

Epoch: 5| Step: 1
Training loss: 0.2909500002861023
Validation loss: 1.693129442071402

Epoch: 5| Step: 2
Training loss: 0.2956562638282776
Validation loss: 1.7259254686294063

Epoch: 5| Step: 3
Training loss: 0.4465402662754059
Validation loss: 1.6919759095356028

Epoch: 5| Step: 4
Training loss: 0.5298849940299988
Validation loss: 1.7009965860715477

Epoch: 5| Step: 5
Training loss: 0.4980774521827698
Validation loss: 1.6902502095827492

Epoch: 5| Step: 6
Training loss: 0.22376105189323425
Validation loss: 1.693001889413403

Epoch: 5| Step: 7
Training loss: 0.3693305253982544
Validation loss: 1.7229571803923576

Epoch: 5| Step: 8
Training loss: 0.5255305171012878
Validation loss: 1.6969000165180494

Epoch: 5| Step: 9
Training loss: 0.275640070438385
Validation loss: 1.722350658908967

Epoch: 5| Step: 10
Training loss: 0.5996383428573608
Validation loss: 1.7399489277152604

Epoch: 369| Step: 0
Training loss: 0.4440554678440094
Validation loss: 1.7232967166490452

Epoch: 5| Step: 1
Training loss: 0.22308707237243652
Validation loss: 1.7039105558908114

Epoch: 5| Step: 2
Training loss: 0.2056228369474411
Validation loss: 1.6851255239978913

Epoch: 5| Step: 3
Training loss: 0.4379885792732239
Validation loss: 1.6989581431111982

Epoch: 5| Step: 4
Training loss: 0.6239444017410278
Validation loss: 1.709549561623604

Epoch: 5| Step: 5
Training loss: 0.5202296376228333
Validation loss: 1.7070294823697818

Epoch: 5| Step: 6
Training loss: 0.49185052514076233
Validation loss: 1.7099763526711413

Epoch: 5| Step: 7
Training loss: 0.34221863746643066
Validation loss: 1.6904714427968508

Epoch: 5| Step: 8
Training loss: 0.4775036871433258
Validation loss: 1.6669914081532469

Epoch: 5| Step: 9
Training loss: 0.48172634840011597
Validation loss: 1.6807447453980804

Epoch: 5| Step: 10
Training loss: 0.34287887811660767
Validation loss: 1.6709464519254622

Epoch: 370| Step: 0
Training loss: 0.3415676951408386
Validation loss: 1.6692602288338445

Epoch: 5| Step: 1
Training loss: 0.35027432441711426
Validation loss: 1.6969672992665281

Epoch: 5| Step: 2
Training loss: 0.4144520163536072
Validation loss: 1.73638415721155

Epoch: 5| Step: 3
Training loss: 0.33758917450904846
Validation loss: 1.7210133690987863

Epoch: 5| Step: 4
Training loss: 0.5363617539405823
Validation loss: 1.7423239625910276

Epoch: 5| Step: 5
Training loss: 0.4471360743045807
Validation loss: 1.69687912284687

Epoch: 5| Step: 6
Training loss: 0.48799413442611694
Validation loss: 1.689463028343775

Epoch: 5| Step: 7
Training loss: 0.4169562757015228
Validation loss: 1.655717957404352

Epoch: 5| Step: 8
Training loss: 0.20230011641979218
Validation loss: 1.6431676880005868

Epoch: 5| Step: 9
Training loss: 0.3028583228588104
Validation loss: 1.6519623687190395

Epoch: 5| Step: 10
Training loss: 0.5832524299621582
Validation loss: 1.636145362290003

Epoch: 371| Step: 0
Training loss: 0.42678341269493103
Validation loss: 1.6538981827356483

Epoch: 5| Step: 1
Training loss: 0.45033177733421326
Validation loss: 1.683380784526948

Epoch: 5| Step: 2
Training loss: 0.30186766386032104
Validation loss: 1.6686769377800725

Epoch: 5| Step: 3
Training loss: 0.25534138083457947
Validation loss: 1.691785443213678

Epoch: 5| Step: 4
Training loss: 0.330657422542572
Validation loss: 1.6835068707825036

Epoch: 5| Step: 5
Training loss: 0.4650854170322418
Validation loss: 1.6695847549746115

Epoch: 5| Step: 6
Training loss: 0.2900930345058441
Validation loss: 1.661773120203326

Epoch: 5| Step: 7
Training loss: 0.4713691174983978
Validation loss: 1.6691464634351834

Epoch: 5| Step: 8
Training loss: 0.44237732887268066
Validation loss: 1.6651696402539489

Epoch: 5| Step: 9
Training loss: 0.4217913746833801
Validation loss: 1.7216326921216902

Epoch: 5| Step: 10
Training loss: 0.44304314255714417
Validation loss: 1.7317080190104823

Epoch: 372| Step: 0
Training loss: 0.35235434770584106
Validation loss: 1.754133725679049

Epoch: 5| Step: 1
Training loss: 0.37103521823883057
Validation loss: 1.7451884644005888

Epoch: 5| Step: 2
Training loss: 0.4733526110649109
Validation loss: 1.7042163764276812

Epoch: 5| Step: 3
Training loss: 0.6788941621780396
Validation loss: 1.7194711175016177

Epoch: 5| Step: 4
Training loss: 0.3322306275367737
Validation loss: 1.6879141535810245

Epoch: 5| Step: 5
Training loss: 0.4640282094478607
Validation loss: 1.6748345936498334

Epoch: 5| Step: 6
Training loss: 0.17110516130924225
Validation loss: 1.6715968706274544

Epoch: 5| Step: 7
Training loss: 0.370512992143631
Validation loss: 1.6654430345822406

Epoch: 5| Step: 8
Training loss: 0.34193795919418335
Validation loss: 1.6666465267058341

Epoch: 5| Step: 9
Training loss: 0.35947108268737793
Validation loss: 1.6682746282187841

Epoch: 5| Step: 10
Training loss: 0.41679322719573975
Validation loss: 1.7044487871149534

Epoch: 373| Step: 0
Training loss: 0.25234121084213257
Validation loss: 1.6981747073511924

Epoch: 5| Step: 1
Training loss: 0.4057866036891937
Validation loss: 1.7096195643947971

Epoch: 5| Step: 2
Training loss: 0.39660143852233887
Validation loss: 1.7288964973982943

Epoch: 5| Step: 3
Training loss: 0.610446035861969
Validation loss: 1.7510092924999934

Epoch: 5| Step: 4
Training loss: 0.385322242975235
Validation loss: 1.7078574857404154

Epoch: 5| Step: 5
Training loss: 0.1815004050731659
Validation loss: 1.7008981640620897

Epoch: 5| Step: 6
Training loss: 0.47212719917297363
Validation loss: 1.624644564044091

Epoch: 5| Step: 7
Training loss: 0.27463287115097046
Validation loss: 1.6516740873295774

Epoch: 5| Step: 8
Training loss: 0.5774810910224915
Validation loss: 1.6521392894047562

Epoch: 5| Step: 9
Training loss: 0.34026074409484863
Validation loss: 1.6753974230058732

Epoch: 5| Step: 10
Training loss: 0.381224662065506
Validation loss: 1.6984958251317341

Epoch: 374| Step: 0
Training loss: 0.39676398038864136
Validation loss: 1.702680915914556

Epoch: 5| Step: 1
Training loss: 0.45899495482444763
Validation loss: 1.7289646928028395

Epoch: 5| Step: 2
Training loss: 0.37277883291244507
Validation loss: 1.7285651122370074

Epoch: 5| Step: 3
Training loss: 0.29122740030288696
Validation loss: 1.7304577314725487

Epoch: 5| Step: 4
Training loss: 0.38634636998176575
Validation loss: 1.7291516603962067

Epoch: 5| Step: 5
Training loss: 0.4553568959236145
Validation loss: 1.6911217115258659

Epoch: 5| Step: 6
Training loss: 0.5097560882568359
Validation loss: 1.6975490969996299

Epoch: 5| Step: 7
Training loss: 0.47416871786117554
Validation loss: 1.6784482707259476

Epoch: 5| Step: 8
Training loss: 0.20329928398132324
Validation loss: 1.6630726322051017

Epoch: 5| Step: 9
Training loss: 0.5184839367866516
Validation loss: 1.6471085086945565

Epoch: 5| Step: 10
Training loss: 0.31661754846572876
Validation loss: 1.6488069834247712

Epoch: 375| Step: 0
Training loss: 0.3338569402694702
Validation loss: 1.7036189802231327

Epoch: 5| Step: 1
Training loss: 0.2357780486345291
Validation loss: 1.7192591800484607

Epoch: 5| Step: 2
Training loss: 0.36896488070487976
Validation loss: 1.7178810693884408

Epoch: 5| Step: 3
Training loss: 0.5199840664863586
Validation loss: 1.6887874064906951

Epoch: 5| Step: 4
Training loss: 0.5364071130752563
Validation loss: 1.6578217808918287

Epoch: 5| Step: 5
Training loss: 0.3329959809780121
Validation loss: 1.672601689574539

Epoch: 5| Step: 6
Training loss: 0.33869367837905884
Validation loss: 1.7003131604963733

Epoch: 5| Step: 7
Training loss: 0.5762985944747925
Validation loss: 1.689086934571625

Epoch: 5| Step: 8
Training loss: 0.4119539260864258
Validation loss: 1.6943207069109845

Epoch: 5| Step: 9
Training loss: 0.45345577597618103
Validation loss: 1.6783984617520404

Epoch: 5| Step: 10
Training loss: 0.37005168199539185
Validation loss: 1.621039818691951

Epoch: 376| Step: 0
Training loss: 0.6094551682472229
Validation loss: 1.644581115374001

Epoch: 5| Step: 1
Training loss: 0.3520657420158386
Validation loss: 1.6608218582727576

Epoch: 5| Step: 2
Training loss: 0.2421034276485443
Validation loss: 1.6930551477657851

Epoch: 5| Step: 3
Training loss: 0.39113014936447144
Validation loss: 1.6895669288532709

Epoch: 5| Step: 4
Training loss: 0.4179460108280182
Validation loss: 1.6872622569402058

Epoch: 5| Step: 5
Training loss: 0.49858957529067993
Validation loss: 1.671728587919666

Epoch: 5| Step: 6
Training loss: 0.35929301381111145
Validation loss: 1.6942998837399226

Epoch: 5| Step: 7
Training loss: 0.26306718587875366
Validation loss: 1.6957951117587347

Epoch: 5| Step: 8
Training loss: 0.2806950509548187
Validation loss: 1.6805651674988449

Epoch: 5| Step: 9
Training loss: 0.16792580485343933
Validation loss: 1.6271987653547717

Epoch: 5| Step: 10
Training loss: 0.5702507495880127
Validation loss: 1.662227435778546

Epoch: 377| Step: 0
Training loss: 0.5173423886299133
Validation loss: 1.6447058698182464

Epoch: 5| Step: 1
Training loss: 0.3615070879459381
Validation loss: 1.6516374670049196

Epoch: 5| Step: 2
Training loss: 0.23258905112743378
Validation loss: 1.7013035525557816

Epoch: 5| Step: 3
Training loss: 0.5532770156860352
Validation loss: 1.7361474299943576

Epoch: 5| Step: 4
Training loss: 0.36647945642471313
Validation loss: 1.761658994100427

Epoch: 5| Step: 5
Training loss: 0.32337889075279236
Validation loss: 1.7436220863813996

Epoch: 5| Step: 6
Training loss: 0.3501721918582916
Validation loss: 1.7080020263630857

Epoch: 5| Step: 7
Training loss: 0.2793785631656647
Validation loss: 1.6990602862450384

Epoch: 5| Step: 8
Training loss: 0.3845032751560211
Validation loss: 1.6624008019765217

Epoch: 5| Step: 9
Training loss: 0.3066440224647522
Validation loss: 1.6447219822996406

Epoch: 5| Step: 10
Training loss: 0.6732444167137146
Validation loss: 1.6463707980289255

Epoch: 378| Step: 0
Training loss: 0.22730913758277893
Validation loss: 1.6640319273036013

Epoch: 5| Step: 1
Training loss: 0.2957631051540375
Validation loss: 1.6462670680015319

Epoch: 5| Step: 2
Training loss: 0.43597492575645447
Validation loss: 1.6797639170000631

Epoch: 5| Step: 3
Training loss: 0.32717108726501465
Validation loss: 1.6876005408584431

Epoch: 5| Step: 4
Training loss: 0.35284408926963806
Validation loss: 1.716474425408148

Epoch: 5| Step: 5
Training loss: 0.5278010368347168
Validation loss: 1.7469959720488517

Epoch: 5| Step: 6
Training loss: 0.32314619421958923
Validation loss: 1.7624865513975903

Epoch: 5| Step: 7
Training loss: 0.4532850682735443
Validation loss: 1.7592242225523917

Epoch: 5| Step: 8
Training loss: 0.5002892017364502
Validation loss: 1.6825979819861792

Epoch: 5| Step: 9
Training loss: 0.49556559324264526
Validation loss: 1.6593657142372542

Epoch: 5| Step: 10
Training loss: 0.22881707549095154
Validation loss: 1.5958877583985687

Epoch: 379| Step: 0
Training loss: 0.2881838083267212
Validation loss: 1.5936316790119294

Epoch: 5| Step: 1
Training loss: 0.39903146028518677
Validation loss: 1.613875316035363

Epoch: 5| Step: 2
Training loss: 0.44224780797958374
Validation loss: 1.634273273970491

Epoch: 5| Step: 3
Training loss: 0.313732773065567
Validation loss: 1.659023945049573

Epoch: 5| Step: 4
Training loss: 0.2679104208946228
Validation loss: 1.6949086061087988

Epoch: 5| Step: 5
Training loss: 0.43559542298316956
Validation loss: 1.7218207877169374

Epoch: 5| Step: 6
Training loss: 0.5583416223526001
Validation loss: 1.7159315360489713

Epoch: 5| Step: 7
Training loss: 0.2817928194999695
Validation loss: 1.743479472334667

Epoch: 5| Step: 8
Training loss: 0.48781269788742065
Validation loss: 1.742017198634404

Epoch: 5| Step: 9
Training loss: 0.5249133706092834
Validation loss: 1.754833157344531

Epoch: 5| Step: 10
Training loss: 0.4831724762916565
Validation loss: 1.7420231155169907

Epoch: 380| Step: 0
Training loss: 0.3249739110469818
Validation loss: 1.698991819094586

Epoch: 5| Step: 1
Training loss: 0.3581307530403137
Validation loss: 1.6685116534592004

Epoch: 5| Step: 2
Training loss: 0.3535196781158447
Validation loss: 1.6362384339814544

Epoch: 5| Step: 3
Training loss: 0.2946752607822418
Validation loss: 1.629552702749929

Epoch: 5| Step: 4
Training loss: 0.5211113691329956
Validation loss: 1.621937636406191

Epoch: 5| Step: 5
Training loss: 0.2765255570411682
Validation loss: 1.6425945592182938

Epoch: 5| Step: 6
Training loss: 0.27839282155036926
Validation loss: 1.6554653618925361

Epoch: 5| Step: 7
Training loss: 0.31689172983169556
Validation loss: 1.6942367951075237

Epoch: 5| Step: 8
Training loss: 0.4615054130554199
Validation loss: 1.7307885692965599

Epoch: 5| Step: 9
Training loss: 0.5807413458824158
Validation loss: 1.764558164022302

Epoch: 5| Step: 10
Training loss: 0.22077001631259918
Validation loss: 1.7965450722684142

Epoch: 381| Step: 0
Training loss: 0.36788398027420044
Validation loss: 1.753613200238956

Epoch: 5| Step: 1
Training loss: 0.23180441558361053
Validation loss: 1.7794628630402267

Epoch: 5| Step: 2
Training loss: 0.372088760137558
Validation loss: 1.6999866385613718

Epoch: 5| Step: 3
Training loss: 0.48004594445228577
Validation loss: 1.6654908528891943

Epoch: 5| Step: 4
Training loss: 0.36452585458755493
Validation loss: 1.6493676541953959

Epoch: 5| Step: 5
Training loss: 0.4878588616847992
Validation loss: 1.6176484900136148

Epoch: 5| Step: 6
Training loss: 0.4850881099700928
Validation loss: 1.6044575616877566

Epoch: 5| Step: 7
Training loss: 0.39212310314178467
Validation loss: 1.5837159323435959

Epoch: 5| Step: 8
Training loss: 0.2526995837688446
Validation loss: 1.6096859901182112

Epoch: 5| Step: 9
Training loss: 0.39633113145828247
Validation loss: 1.646761695543925

Epoch: 5| Step: 10
Training loss: 0.3591347932815552
Validation loss: 1.6998436707322315

Epoch: 382| Step: 0
Training loss: 0.376509428024292
Validation loss: 1.7736122544093798

Epoch: 5| Step: 1
Training loss: 0.4755118489265442
Validation loss: 1.7920656793860978

Epoch: 5| Step: 2
Training loss: 0.5812749862670898
Validation loss: 1.797049710827489

Epoch: 5| Step: 3
Training loss: 0.3860081136226654
Validation loss: 1.761608204533977

Epoch: 5| Step: 4
Training loss: 0.3641231656074524
Validation loss: 1.729421970664814

Epoch: 5| Step: 5
Training loss: 0.29995569586753845
Validation loss: 1.7217194239298503

Epoch: 5| Step: 6
Training loss: 0.48315709829330444
Validation loss: 1.6645271573015439

Epoch: 5| Step: 7
Training loss: 0.4048615097999573
Validation loss: 1.6462609024458035

Epoch: 5| Step: 8
Training loss: 0.29212459921836853
Validation loss: 1.6294881912969774

Epoch: 5| Step: 9
Training loss: 0.3156610131263733
Validation loss: 1.622099232930009

Epoch: 5| Step: 10
Training loss: 0.41205698251724243
Validation loss: 1.6237858790223316

Epoch: 383| Step: 0
Training loss: 0.40964215993881226
Validation loss: 1.6210332442355413

Epoch: 5| Step: 1
Training loss: 0.34258532524108887
Validation loss: 1.6278369901000813

Epoch: 5| Step: 2
Training loss: 0.257804811000824
Validation loss: 1.664763609568278

Epoch: 5| Step: 3
Training loss: 0.5737539529800415
Validation loss: 1.6763453816854825

Epoch: 5| Step: 4
Training loss: 0.4016435742378235
Validation loss: 1.7027337794662805

Epoch: 5| Step: 5
Training loss: 0.519147515296936
Validation loss: 1.72158387912217

Epoch: 5| Step: 6
Training loss: 0.2742660343647003
Validation loss: 1.7034191046991656

Epoch: 5| Step: 7
Training loss: 0.3091326355934143
Validation loss: 1.691372335598033

Epoch: 5| Step: 8
Training loss: 0.31502291560173035
Validation loss: 1.7093351143662647

Epoch: 5| Step: 9
Training loss: 0.19464878737926483
Validation loss: 1.65523285506874

Epoch: 5| Step: 10
Training loss: 0.2552647590637207
Validation loss: 1.677919723654306

Epoch: 384| Step: 0
Training loss: 0.27435827255249023
Validation loss: 1.6481668077489382

Epoch: 5| Step: 1
Training loss: 0.35538551211357117
Validation loss: 1.6931525866190593

Epoch: 5| Step: 2
Training loss: 0.18733754754066467
Validation loss: 1.7032722055271108

Epoch: 5| Step: 3
Training loss: 0.3063248097896576
Validation loss: 1.7417489482510475

Epoch: 5| Step: 4
Training loss: 0.4722072184085846
Validation loss: 1.747274532113024

Epoch: 5| Step: 5
Training loss: 0.38818997144699097
Validation loss: 1.7373731456777102

Epoch: 5| Step: 6
Training loss: 0.45196598768234253
Validation loss: 1.713991326670493

Epoch: 5| Step: 7
Training loss: 0.25848788022994995
Validation loss: 1.684099228151383

Epoch: 5| Step: 8
Training loss: 0.7150318622589111
Validation loss: 1.675494219667168

Epoch: 5| Step: 9
Training loss: 0.25962525606155396
Validation loss: 1.657861658321914

Epoch: 5| Step: 10
Training loss: 0.1607898324728012
Validation loss: 1.6416392480173418

Epoch: 385| Step: 0
Training loss: 0.28122276067733765
Validation loss: 1.6555873335048716

Epoch: 5| Step: 1
Training loss: 0.3797762095928192
Validation loss: 1.6663221300289195

Epoch: 5| Step: 2
Training loss: 0.3861570358276367
Validation loss: 1.654998694696734

Epoch: 5| Step: 3
Training loss: 0.3602391183376312
Validation loss: 1.6646397229163878

Epoch: 5| Step: 4
Training loss: 0.5492599010467529
Validation loss: 1.66959293939734

Epoch: 5| Step: 5
Training loss: 0.43453341722488403
Validation loss: 1.7028378760942848

Epoch: 5| Step: 6
Training loss: 0.30587902665138245
Validation loss: 1.7362825191149147

Epoch: 5| Step: 7
Training loss: 0.3525826632976532
Validation loss: 1.7704441765303254

Epoch: 5| Step: 8
Training loss: 0.3759838938713074
Validation loss: 1.7456941104704333

Epoch: 5| Step: 9
Training loss: 0.4096372127532959
Validation loss: 1.7039356872599611

Epoch: 5| Step: 10
Training loss: 0.3291270136833191
Validation loss: 1.716254718842045

Epoch: 386| Step: 0
Training loss: 0.5204510688781738
Validation loss: 1.6777175152173607

Epoch: 5| Step: 1
Training loss: 0.346844881772995
Validation loss: 1.6697470167631745

Epoch: 5| Step: 2
Training loss: 0.26835304498672485
Validation loss: 1.6423711033277615

Epoch: 5| Step: 3
Training loss: 0.18764419853687286
Validation loss: 1.629394039030998

Epoch: 5| Step: 4
Training loss: 0.42738667130470276
Validation loss: 1.6159557129747124

Epoch: 5| Step: 5
Training loss: 0.24819178879261017
Validation loss: 1.610031561184955

Epoch: 5| Step: 6
Training loss: 0.502339780330658
Validation loss: 1.6077427787165488

Epoch: 5| Step: 7
Training loss: 0.4278285503387451
Validation loss: 1.6283053915987733

Epoch: 5| Step: 8
Training loss: 0.4633425772190094
Validation loss: 1.665968079720774

Epoch: 5| Step: 9
Training loss: 0.21794860064983368
Validation loss: 1.6923832778007752

Epoch: 5| Step: 10
Training loss: 0.3118613660335541
Validation loss: 1.7145298424587454

Epoch: 387| Step: 0
Training loss: 0.35969436168670654
Validation loss: 1.7483747108008272

Epoch: 5| Step: 1
Training loss: 0.4934330880641937
Validation loss: 1.7561101682724491

Epoch: 5| Step: 2
Training loss: 0.3306805193424225
Validation loss: 1.7121064816751788

Epoch: 5| Step: 3
Training loss: 0.44561606645584106
Validation loss: 1.685981745361

Epoch: 5| Step: 4
Training loss: 0.4012039303779602
Validation loss: 1.6652215488495365

Epoch: 5| Step: 5
Training loss: 0.3521537482738495
Validation loss: 1.6410266289146997

Epoch: 5| Step: 6
Training loss: 0.36948809027671814
Validation loss: 1.6122094546594927

Epoch: 5| Step: 7
Training loss: 0.2168755978345871
Validation loss: 1.6151382769307783

Epoch: 5| Step: 8
Training loss: 0.34593743085861206
Validation loss: 1.6044073335586055

Epoch: 5| Step: 9
Training loss: 0.4776408076286316
Validation loss: 1.6360822223847913

Epoch: 5| Step: 10
Training loss: 0.21938872337341309
Validation loss: 1.6145534079561952

Epoch: 388| Step: 0
Training loss: 0.14715120196342468
Validation loss: 1.6548155238551479

Epoch: 5| Step: 1
Training loss: 0.3382748067378998
Validation loss: 1.6910038430203673

Epoch: 5| Step: 2
Training loss: 0.41977959871292114
Validation loss: 1.68478778741693

Epoch: 5| Step: 3
Training loss: 0.4493928849697113
Validation loss: 1.7514839492818361

Epoch: 5| Step: 4
Training loss: 0.3354683518409729
Validation loss: 1.755672566352352

Epoch: 5| Step: 5
Training loss: 0.4284176826477051
Validation loss: 1.76540240164726

Epoch: 5| Step: 6
Training loss: 0.28385940194129944
Validation loss: 1.7090387241814726

Epoch: 5| Step: 7
Training loss: 0.3425983488559723
Validation loss: 1.679902913749859

Epoch: 5| Step: 8
Training loss: 0.3821038603782654
Validation loss: 1.641710304444836

Epoch: 5| Step: 9
Training loss: 0.31363722681999207
Validation loss: 1.6344027032134354

Epoch: 5| Step: 10
Training loss: 0.38703295588493347
Validation loss: 1.6164597183145502

Epoch: 389| Step: 0
Training loss: 0.29266995191574097
Validation loss: 1.6119991463999594

Epoch: 5| Step: 1
Training loss: 0.38694944977760315
Validation loss: 1.633227796964748

Epoch: 5| Step: 2
Training loss: 0.22247739136219025
Validation loss: 1.6369210750825944

Epoch: 5| Step: 3
Training loss: 0.29109078645706177
Validation loss: 1.6450377023348244

Epoch: 5| Step: 4
Training loss: 0.32670360803604126
Validation loss: 1.6816847606371808

Epoch: 5| Step: 5
Training loss: 0.34770604968070984
Validation loss: 1.680054892775833

Epoch: 5| Step: 6
Training loss: 0.4758695662021637
Validation loss: 1.6914802917870142

Epoch: 5| Step: 7
Training loss: 0.3424920439720154
Validation loss: 1.6516036910395469

Epoch: 5| Step: 8
Training loss: 0.3927357792854309
Validation loss: 1.6780867076689197

Epoch: 5| Step: 9
Training loss: 0.35488763451576233
Validation loss: 1.697407272554213

Epoch: 5| Step: 10
Training loss: 0.4344804286956787
Validation loss: 1.715931252766681

Epoch: 390| Step: 0
Training loss: 0.45086774230003357
Validation loss: 1.6810089349746704

Epoch: 5| Step: 1
Training loss: 0.47389093041419983
Validation loss: 1.6918139252611386

Epoch: 5| Step: 2
Training loss: 0.24946942925453186
Validation loss: 1.7031775982149187

Epoch: 5| Step: 3
Training loss: 0.393322229385376
Validation loss: 1.7117245287023566

Epoch: 5| Step: 4
Training loss: 0.34196189045906067
Validation loss: 1.6788296007340955

Epoch: 5| Step: 5
Training loss: 0.29532796144485474
Validation loss: 1.6889896098003592

Epoch: 5| Step: 6
Training loss: 0.45577722787857056
Validation loss: 1.6810202906208653

Epoch: 5| Step: 7
Training loss: 0.3367527723312378
Validation loss: 1.6540068734076716

Epoch: 5| Step: 8
Training loss: 0.300136536359787
Validation loss: 1.6466788598286208

Epoch: 5| Step: 9
Training loss: 0.16758625209331512
Validation loss: 1.6347793097137122

Epoch: 5| Step: 10
Training loss: 0.2598600685596466
Validation loss: 1.6739874065563243

Epoch: 391| Step: 0
Training loss: 0.23472781479358673
Validation loss: 1.6700874144031155

Epoch: 5| Step: 1
Training loss: 0.28475314378738403
Validation loss: 1.6810675795360277

Epoch: 5| Step: 2
Training loss: 0.4317288398742676
Validation loss: 1.666916178118798

Epoch: 5| Step: 3
Training loss: 0.5272188782691956
Validation loss: 1.6594659038769302

Epoch: 5| Step: 4
Training loss: 0.4919833242893219
Validation loss: 1.660294916040154

Epoch: 5| Step: 5
Training loss: 0.3973363935947418
Validation loss: 1.664303578356261

Epoch: 5| Step: 6
Training loss: 0.2675803303718567
Validation loss: 1.6342886288960774

Epoch: 5| Step: 7
Training loss: 0.23919768631458282
Validation loss: 1.6287967645993797

Epoch: 5| Step: 8
Training loss: 0.19990429282188416
Validation loss: 1.6360225408307967

Epoch: 5| Step: 9
Training loss: 0.2319255769252777
Validation loss: 1.6475154712635984

Epoch: 5| Step: 10
Training loss: 0.27137261629104614
Validation loss: 1.6541168856364425

Epoch: 392| Step: 0
Training loss: 0.3281787931919098
Validation loss: 1.6888043399780028

Epoch: 5| Step: 1
Training loss: 0.46729907393455505
Validation loss: 1.6690742443966609

Epoch: 5| Step: 2
Training loss: 0.2595447599887848
Validation loss: 1.6376872703593264

Epoch: 5| Step: 3
Training loss: 0.15118637681007385
Validation loss: 1.6664135981631536

Epoch: 5| Step: 4
Training loss: 0.3491249084472656
Validation loss: 1.6580082703662176

Epoch: 5| Step: 5
Training loss: 0.22979597747325897
Validation loss: 1.6636102763555383

Epoch: 5| Step: 6
Training loss: 0.3419543206691742
Validation loss: 1.659446406108077

Epoch: 5| Step: 7
Training loss: 0.3210044503211975
Validation loss: 1.6254249977809128

Epoch: 5| Step: 8
Training loss: 0.3126225471496582
Validation loss: 1.6579782283434303

Epoch: 5| Step: 9
Training loss: 0.17718413472175598
Validation loss: 1.6059002812190721

Epoch: 5| Step: 10
Training loss: 0.4750426709651947
Validation loss: 1.6185862915490263

Epoch: 393| Step: 0
Training loss: 0.23195281624794006
Validation loss: 1.5920379866835892

Epoch: 5| Step: 1
Training loss: 0.4890175461769104
Validation loss: 1.605344521102085

Epoch: 5| Step: 2
Training loss: 0.4030380845069885
Validation loss: 1.6387026092057586

Epoch: 5| Step: 3
Training loss: 0.20149412751197815
Validation loss: 1.6130368286563503

Epoch: 5| Step: 4
Training loss: 0.26805680990219116
Validation loss: 1.648133457347911

Epoch: 5| Step: 5
Training loss: 0.4757668375968933
Validation loss: 1.657073643899733

Epoch: 5| Step: 6
Training loss: 0.2348325252532959
Validation loss: 1.6458976627678

Epoch: 5| Step: 7
Training loss: 0.21177920699119568
Validation loss: 1.6385793506458242

Epoch: 5| Step: 8
Training loss: 0.27997535467147827
Validation loss: 1.6349973435043006

Epoch: 5| Step: 9
Training loss: 0.4333799481391907
Validation loss: 1.6540955971646052

Epoch: 5| Step: 10
Training loss: 0.2263941913843155
Validation loss: 1.6814131864937403

Epoch: 394| Step: 0
Training loss: 0.4394676089286804
Validation loss: 1.6928143937100646

Epoch: 5| Step: 1
Training loss: 0.33802634477615356
Validation loss: 1.7407032392358268

Epoch: 5| Step: 2
Training loss: 0.26619890332221985
Validation loss: 1.7672056305793025

Epoch: 5| Step: 3
Training loss: 0.37888455390930176
Validation loss: 1.744795609545964

Epoch: 5| Step: 4
Training loss: 0.5146028399467468
Validation loss: 1.7254335970006964

Epoch: 5| Step: 5
Training loss: 0.19116762280464172
Validation loss: 1.6470427256758495

Epoch: 5| Step: 6
Training loss: 0.18489280343055725
Validation loss: 1.6190711170114496

Epoch: 5| Step: 7
Training loss: 0.25943297147750854
Validation loss: 1.598006909893405

Epoch: 5| Step: 8
Training loss: 0.2296922206878662
Validation loss: 1.5997490165054158

Epoch: 5| Step: 9
Training loss: 0.4199455678462982
Validation loss: 1.59332130160383

Epoch: 5| Step: 10
Training loss: 0.5065513849258423
Validation loss: 1.5909353366462133

Epoch: 395| Step: 0
Training loss: 0.21571454405784607
Validation loss: 1.6127197114370202

Epoch: 5| Step: 1
Training loss: 0.29023846983909607
Validation loss: 1.6321461828806068

Epoch: 5| Step: 2
Training loss: 0.20617127418518066
Validation loss: 1.6746932319415513

Epoch: 5| Step: 3
Training loss: 0.30365830659866333
Validation loss: 1.6793042818705242

Epoch: 5| Step: 4
Training loss: 0.27623119950294495
Validation loss: 1.6881607476101126

Epoch: 5| Step: 5
Training loss: 0.4182566702365875
Validation loss: 1.7324883617380613

Epoch: 5| Step: 6
Training loss: 0.29358431696891785
Validation loss: 1.6974614198489855

Epoch: 5| Step: 7
Training loss: 0.41233405470848083
Validation loss: 1.6434797010114115

Epoch: 5| Step: 8
Training loss: 0.5088890194892883
Validation loss: 1.6163723699508175

Epoch: 5| Step: 9
Training loss: 0.2911856472492218
Validation loss: 1.6020446772216468

Epoch: 5| Step: 10
Training loss: 0.2735770046710968
Validation loss: 1.6133905226184475

Epoch: 396| Step: 0
Training loss: 0.3772760331630707
Validation loss: 1.6393144130706787

Epoch: 5| Step: 1
Training loss: 0.30636346340179443
Validation loss: 1.6246746509305892

Epoch: 5| Step: 2
Training loss: 0.19797688722610474
Validation loss: 1.6485570797356226

Epoch: 5| Step: 3
Training loss: 0.2201615571975708
Validation loss: 1.6780629183656426

Epoch: 5| Step: 4
Training loss: 0.3895858824253082
Validation loss: 1.6698485420596214

Epoch: 5| Step: 5
Training loss: 0.39796149730682373
Validation loss: 1.6639932611937165

Epoch: 5| Step: 6
Training loss: 0.3878368139266968
Validation loss: 1.6953493946342058

Epoch: 5| Step: 7
Training loss: 0.22200655937194824
Validation loss: 1.6850413455758044

Epoch: 5| Step: 8
Training loss: 0.29130426049232483
Validation loss: 1.6624454093235794

Epoch: 5| Step: 9
Training loss: 0.2875346541404724
Validation loss: 1.6508944880577825

Epoch: 5| Step: 10
Training loss: 0.3073473572731018
Validation loss: 1.6746628130635908

Epoch: 397| Step: 0
Training loss: 0.33491554856300354
Validation loss: 1.681204161336345

Epoch: 5| Step: 1
Training loss: 0.2993827760219574
Validation loss: 1.7206407323960335

Epoch: 5| Step: 2
Training loss: 0.4965800344944
Validation loss: 1.7131118415504374

Epoch: 5| Step: 3
Training loss: 0.30983805656433105
Validation loss: 1.6708317354161253

Epoch: 5| Step: 4
Training loss: 0.32903751730918884
Validation loss: 1.6338186007674023

Epoch: 5| Step: 5
Training loss: 0.29055437445640564
Validation loss: 1.6368067700375792

Epoch: 5| Step: 6
Training loss: 0.10243166983127594
Validation loss: 1.6469271375286965

Epoch: 5| Step: 7
Training loss: 0.23245041072368622
Validation loss: 1.6223643723354544

Epoch: 5| Step: 8
Training loss: 0.3546029329299927
Validation loss: 1.6342768694764824

Epoch: 5| Step: 9
Training loss: 0.35640090703964233
Validation loss: 1.6186359108135264

Epoch: 5| Step: 10
Training loss: 0.3728012442588806
Validation loss: 1.6289237327473138

Epoch: 398| Step: 0
Training loss: 0.22549882531166077
Validation loss: 1.6155797948119461

Epoch: 5| Step: 1
Training loss: 0.44778919219970703
Validation loss: 1.626642737337338

Epoch: 5| Step: 2
Training loss: 0.19270406663417816
Validation loss: 1.6279956384371685

Epoch: 5| Step: 3
Training loss: 0.3219841420650482
Validation loss: 1.6758803911106561

Epoch: 5| Step: 4
Training loss: 0.2812146246433258
Validation loss: 1.6859651688606507

Epoch: 5| Step: 5
Training loss: 0.4292610287666321
Validation loss: 1.6900512428693875

Epoch: 5| Step: 6
Training loss: 0.2261391431093216
Validation loss: 1.6715840748561326

Epoch: 5| Step: 7
Training loss: 0.2513943314552307
Validation loss: 1.6437818670785556

Epoch: 5| Step: 8
Training loss: 0.38807496428489685
Validation loss: 1.6339259371962598

Epoch: 5| Step: 9
Training loss: 0.31173843145370483
Validation loss: 1.625751006987787

Epoch: 5| Step: 10
Training loss: 0.24627777934074402
Validation loss: 1.6388075249169463

Epoch: 399| Step: 0
Training loss: 0.4301735758781433
Validation loss: 1.635844220397293

Epoch: 5| Step: 1
Training loss: 0.2646593153476715
Validation loss: 1.6297739769822808

Epoch: 5| Step: 2
Training loss: 0.23327898979187012
Validation loss: 1.6408405893592424

Epoch: 5| Step: 3
Training loss: 0.22726447880268097
Validation loss: 1.6262891754027335

Epoch: 5| Step: 4
Training loss: 0.28617963194847107
Validation loss: 1.6302282182119225

Epoch: 5| Step: 5
Training loss: 0.29062560200691223
Validation loss: 1.647067964717906

Epoch: 5| Step: 6
Training loss: 0.31469473242759705
Validation loss: 1.6376323546132734

Epoch: 5| Step: 7
Training loss: 0.18823856115341187
Validation loss: 1.624552333226768

Epoch: 5| Step: 8
Training loss: 0.2919972240924835
Validation loss: 1.6394528727377615

Epoch: 5| Step: 9
Training loss: 0.296996146440506
Validation loss: 1.688506974968859

Epoch: 5| Step: 10
Training loss: 0.4513724148273468
Validation loss: 1.7222349489888837

Epoch: 400| Step: 0
Training loss: 0.1777951866388321
Validation loss: 1.727106499415572

Epoch: 5| Step: 1
Training loss: 0.3494299650192261
Validation loss: 1.6823605414359801

Epoch: 5| Step: 2
Training loss: 0.3957974910736084
Validation loss: 1.6410690417853735

Epoch: 5| Step: 3
Training loss: 0.2962622046470642
Validation loss: 1.5803099037498556

Epoch: 5| Step: 4
Training loss: 0.24739587306976318
Validation loss: 1.5548094985305623

Epoch: 5| Step: 5
Training loss: 0.40011700987815857
Validation loss: 1.5569308252744778

Epoch: 5| Step: 6
Training loss: 0.37460482120513916
Validation loss: 1.566268692734421

Epoch: 5| Step: 7
Training loss: 0.43869534134864807
Validation loss: 1.583348479322208

Epoch: 5| Step: 8
Training loss: 0.24669155478477478
Validation loss: 1.5809217742694321

Epoch: 5| Step: 9
Training loss: 0.2541986405849457
Validation loss: 1.6547150752877677

Epoch: 5| Step: 10
Training loss: 0.29352864623069763
Validation loss: 1.6654094585808374

Testing loss: 2.131220433447096
