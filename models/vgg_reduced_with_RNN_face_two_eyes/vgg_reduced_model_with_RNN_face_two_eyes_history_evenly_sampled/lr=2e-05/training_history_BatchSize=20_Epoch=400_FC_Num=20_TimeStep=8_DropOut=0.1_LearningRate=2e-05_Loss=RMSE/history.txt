Epoch: 1| Step: 0
Training loss: 6.734480925609809
Validation loss: 5.725175860198572

Epoch: 5| Step: 1
Training loss: 6.128334227807328
Validation loss: 5.7093184180811605

Epoch: 5| Step: 2
Training loss: 4.730197788482429
Validation loss: 5.699160422030925

Epoch: 5| Step: 3
Training loss: 5.521636539787335
Validation loss: 5.689551728808462

Epoch: 5| Step: 4
Training loss: 5.467855325812276
Validation loss: 5.678536752786702

Epoch: 5| Step: 5
Training loss: 6.284558995084326
Validation loss: 5.665743259761114

Epoch: 5| Step: 6
Training loss: 4.689823846172677
Validation loss: 5.651246098230194

Epoch: 5| Step: 7
Training loss: 6.194725056874876
Validation loss: 5.633847964427768

Epoch: 5| Step: 8
Training loss: 5.162281554544335
Validation loss: 5.614080696483682

Epoch: 5| Step: 9
Training loss: 4.914238518744915
Validation loss: 5.592164753191994

Epoch: 5| Step: 10
Training loss: 6.491202342804036
Validation loss: 5.566270329115391

Epoch: 2| Step: 0
Training loss: 5.496883029292121
Validation loss: 5.537226729415296

Epoch: 5| Step: 1
Training loss: 6.85327795078051
Validation loss: 5.50491253451889

Epoch: 5| Step: 2
Training loss: 4.982531167644399
Validation loss: 5.468872762729012

Epoch: 5| Step: 3
Training loss: 5.693653173701604
Validation loss: 5.430588794573623

Epoch: 5| Step: 4
Training loss: 4.408733777112886
Validation loss: 5.390057439234524

Epoch: 5| Step: 5
Training loss: 4.861699079044349
Validation loss: 5.347276321575702

Epoch: 5| Step: 6
Training loss: 4.856150646003446
Validation loss: 5.303063391651641

Epoch: 5| Step: 7
Training loss: 5.799850317240314
Validation loss: 5.25884001829983

Epoch: 5| Step: 8
Training loss: 5.028620251814894
Validation loss: 5.213340434869552

Epoch: 5| Step: 9
Training loss: 5.431139327876216
Validation loss: 5.166826294660299

Epoch: 5| Step: 10
Training loss: 5.615185291905046
Validation loss: 5.121139691235327

Epoch: 3| Step: 0
Training loss: 4.367272664503906
Validation loss: 5.073500991639721

Epoch: 5| Step: 1
Training loss: 6.082210628777378
Validation loss: 5.020318258616883

Epoch: 5| Step: 2
Training loss: 4.947604113963228
Validation loss: 4.958679602135962

Epoch: 5| Step: 3
Training loss: 4.888212053572193
Validation loss: 4.912159033742274

Epoch: 5| Step: 4
Training loss: 5.519285203291585
Validation loss: 4.879344290797594

Epoch: 5| Step: 5
Training loss: 4.954005791843619
Validation loss: 4.852434314577101

Epoch: 5| Step: 6
Training loss: 3.6453467925445775
Validation loss: 4.819301229834591

Epoch: 5| Step: 7
Training loss: 4.748160959910764
Validation loss: 4.784770986263458

Epoch: 5| Step: 8
Training loss: 5.4581672507297245
Validation loss: 4.748949664469589

Epoch: 5| Step: 9
Training loss: 4.930361065438889
Validation loss: 4.718182612317778

Epoch: 5| Step: 10
Training loss: 4.291171641024672
Validation loss: 4.685774684584051

Epoch: 4| Step: 0
Training loss: 3.8868934477070662
Validation loss: 4.65701998708639

Epoch: 5| Step: 1
Training loss: 5.01839382480197
Validation loss: 4.63477472291847

Epoch: 5| Step: 2
Training loss: 5.662933615951354
Validation loss: 4.616308455880223

Epoch: 5| Step: 3
Training loss: 4.108662010390366
Validation loss: 4.599532978074908

Epoch: 5| Step: 4
Training loss: 5.566455591886574
Validation loss: 4.580638944096487

Epoch: 5| Step: 5
Training loss: 4.8869759593330935
Validation loss: 4.557950781439635

Epoch: 5| Step: 6
Training loss: 3.6924030875451677
Validation loss: 4.535839280396043

Epoch: 5| Step: 7
Training loss: 3.912046724332962
Validation loss: 4.516056724121827

Epoch: 5| Step: 8
Training loss: 4.596653027494655
Validation loss: 4.499105560575974

Epoch: 5| Step: 9
Training loss: 4.845081761539322
Validation loss: 4.48246366015924

Epoch: 5| Step: 10
Training loss: 4.63520717647525
Validation loss: 4.466048553343941

Epoch: 5| Step: 0
Training loss: 4.7965702121589855
Validation loss: 4.450035125402068

Epoch: 5| Step: 1
Training loss: 4.9824362305629135
Validation loss: 4.434411918560858

Epoch: 5| Step: 2
Training loss: 3.2961692597066756
Validation loss: 4.420790719055216

Epoch: 5| Step: 3
Training loss: 5.374341702624822
Validation loss: 4.406747182960304

Epoch: 5| Step: 4
Training loss: 5.1251417931271135
Validation loss: 4.395309887523102

Epoch: 5| Step: 5
Training loss: 3.916045579296285
Validation loss: 4.381852921783409

Epoch: 5| Step: 6
Training loss: 4.695971349105645
Validation loss: 4.372435103575293

Epoch: 5| Step: 7
Training loss: 4.435305200373361
Validation loss: 4.3620721444248804

Epoch: 5| Step: 8
Training loss: 4.293812163012648
Validation loss: 4.349695079348904

Epoch: 5| Step: 9
Training loss: 4.1327114273144065
Validation loss: 4.340656582791936

Epoch: 5| Step: 10
Training loss: 4.066522572783894
Validation loss: 4.331843438710767

Epoch: 6| Step: 0
Training loss: 4.517965904576637
Validation loss: 4.322223493991651

Epoch: 5| Step: 1
Training loss: 4.18802377641955
Validation loss: 4.309093150346711

Epoch: 5| Step: 2
Training loss: 4.264179138399937
Validation loss: 4.297348019693384

Epoch: 5| Step: 3
Training loss: 3.448688954569706
Validation loss: 4.278068827076167

Epoch: 5| Step: 4
Training loss: 4.206079515286892
Validation loss: 4.261174758091249

Epoch: 5| Step: 5
Training loss: 5.168881567095834
Validation loss: 4.251117824707261

Epoch: 5| Step: 6
Training loss: 4.624268757517025
Validation loss: 4.235814435981424

Epoch: 5| Step: 7
Training loss: 3.959330998562353
Validation loss: 4.2170288780240055

Epoch: 5| Step: 8
Training loss: 5.130351366350253
Validation loss: 4.202340734740409

Epoch: 5| Step: 9
Training loss: 4.229803679399289
Validation loss: 4.188484488798339

Epoch: 5| Step: 10
Training loss: 4.095000796661486
Validation loss: 4.176273158848182

Epoch: 7| Step: 0
Training loss: 4.153723845352176
Validation loss: 4.165755157853435

Epoch: 5| Step: 1
Training loss: 4.587663004211399
Validation loss: 4.152086413821301

Epoch: 5| Step: 2
Training loss: 4.300805198332506
Validation loss: 4.14020348800851

Epoch: 5| Step: 3
Training loss: 4.763172156292329
Validation loss: 4.125421239649934

Epoch: 5| Step: 4
Training loss: 3.636061398993892
Validation loss: 4.113111779822529

Epoch: 5| Step: 5
Training loss: 4.98611391162469
Validation loss: 4.102555460862594

Epoch: 5| Step: 6
Training loss: 3.2852613361982543
Validation loss: 4.088071506738722

Epoch: 5| Step: 7
Training loss: 4.383349707008405
Validation loss: 4.077615967264327

Epoch: 5| Step: 8
Training loss: 4.641007635608812
Validation loss: 4.070687307355847

Epoch: 5| Step: 9
Training loss: 4.117576160942516
Validation loss: 4.063578404619907

Epoch: 5| Step: 10
Training loss: 3.4284845210595627
Validation loss: 4.047068189763328

Epoch: 8| Step: 0
Training loss: 4.045758303186528
Validation loss: 4.040073880568178

Epoch: 5| Step: 1
Training loss: 4.23162031483114
Validation loss: 4.028830527571944

Epoch: 5| Step: 2
Training loss: 4.568805883146709
Validation loss: 4.0180419017360505

Epoch: 5| Step: 3
Training loss: 4.035113235643195
Validation loss: 4.006731941620038

Epoch: 5| Step: 4
Training loss: 3.520066909587605
Validation loss: 3.9955690322271304

Epoch: 5| Step: 5
Training loss: 4.453851794445429
Validation loss: 3.986148534252788

Epoch: 5| Step: 6
Training loss: 3.362752378841084
Validation loss: 3.97500421419731

Epoch: 5| Step: 7
Training loss: 4.183296029176588
Validation loss: 3.964559873825218

Epoch: 5| Step: 8
Training loss: 4.451552156789164
Validation loss: 3.951049327194334

Epoch: 5| Step: 9
Training loss: 4.749439206397799
Validation loss: 3.940834884608034

Epoch: 5| Step: 10
Training loss: 3.6438278059070743
Validation loss: 3.931164440502973

Epoch: 9| Step: 0
Training loss: 3.33292125697932
Validation loss: 3.919701563976994

Epoch: 5| Step: 1
Training loss: 3.6728812928785417
Validation loss: 3.9086179936635994

Epoch: 5| Step: 2
Training loss: 3.617596267442157
Validation loss: 3.8994355594964962

Epoch: 5| Step: 3
Training loss: 4.15489415590546
Validation loss: 3.8889661068337964

Epoch: 5| Step: 4
Training loss: 3.69572101294754
Validation loss: 3.878108613924734

Epoch: 5| Step: 5
Training loss: 4.988449488157461
Validation loss: 3.868297754873347

Epoch: 5| Step: 6
Training loss: 4.687581176054927
Validation loss: 3.8541111847604297

Epoch: 5| Step: 7
Training loss: 3.790143989303805
Validation loss: 3.8422295322436177

Epoch: 5| Step: 8
Training loss: 3.8259673596997392
Validation loss: 3.8318485837265874

Epoch: 5| Step: 9
Training loss: 3.4990581880164555
Validation loss: 3.8239113972437875

Epoch: 5| Step: 10
Training loss: 4.777475101040763
Validation loss: 3.81297958749314

Epoch: 10| Step: 0
Training loss: 4.2342558558970245
Validation loss: 3.8042407424073237

Epoch: 5| Step: 1
Training loss: 4.352060833926528
Validation loss: 3.7942149377434347

Epoch: 5| Step: 2
Training loss: 4.392255921375418
Validation loss: 3.7855808748769957

Epoch: 5| Step: 3
Training loss: 3.174104254814982
Validation loss: 3.7774060721146485

Epoch: 5| Step: 4
Training loss: 3.9633153515774904
Validation loss: 3.7789170164841384

Epoch: 5| Step: 5
Training loss: 3.5813790396299146
Validation loss: 3.759013960851684

Epoch: 5| Step: 6
Training loss: 2.990676857111057
Validation loss: 3.751160046389269

Epoch: 5| Step: 7
Training loss: 3.733745442078921
Validation loss: 3.7503170494674336

Epoch: 5| Step: 8
Training loss: 3.5976343806593043
Validation loss: 3.7421568226760535

Epoch: 5| Step: 9
Training loss: 4.8687698461791635
Validation loss: 3.727185716157521

Epoch: 5| Step: 10
Training loss: 4.10352515356164
Validation loss: 3.7244174822516167

Epoch: 11| Step: 0
Training loss: 2.9757322420034087
Validation loss: 3.718114340655272

Epoch: 5| Step: 1
Training loss: 3.8759451913176783
Validation loss: 3.7019150374028778

Epoch: 5| Step: 2
Training loss: 3.8538143237471814
Validation loss: 3.7041011569243243

Epoch: 5| Step: 3
Training loss: 3.771690959596524
Validation loss: 3.694375740189829

Epoch: 5| Step: 4
Training loss: 4.376596649919202
Validation loss: 3.675385944279768

Epoch: 5| Step: 5
Training loss: 3.71278197376862
Validation loss: 3.6812405582970364

Epoch: 5| Step: 6
Training loss: 3.7280196374040355
Validation loss: 3.6654752285315833

Epoch: 5| Step: 7
Training loss: 3.4804698460295693
Validation loss: 3.645634274065908

Epoch: 5| Step: 8
Training loss: 3.90166698922394
Validation loss: 3.640250292909045

Epoch: 5| Step: 9
Training loss: 4.148865528618702
Validation loss: 3.634794261929526

Epoch: 5| Step: 10
Training loss: 4.5132494951253275
Validation loss: 3.617657649510323

Epoch: 12| Step: 0
Training loss: 3.1857824747142245
Validation loss: 3.6127561839237465

Epoch: 5| Step: 1
Training loss: 2.95531209056037
Validation loss: 3.61209610020475

Epoch: 5| Step: 2
Training loss: 2.7785194794880037
Validation loss: 3.593073832928461

Epoch: 5| Step: 3
Training loss: 3.497004725936563
Validation loss: 3.595685752648487

Epoch: 5| Step: 4
Training loss: 4.438361930416019
Validation loss: 3.5836172375364392

Epoch: 5| Step: 5
Training loss: 3.6673378041188194
Validation loss: 3.5698731350149493

Epoch: 5| Step: 6
Training loss: 4.032624712610127
Validation loss: 3.5645588608838548

Epoch: 5| Step: 7
Training loss: 3.64385790395212
Validation loss: 3.5632025330561925

Epoch: 5| Step: 8
Training loss: 3.957251404251774
Validation loss: 3.5437890909436365

Epoch: 5| Step: 9
Training loss: 4.649514671347661
Validation loss: 3.5382321367013825

Epoch: 5| Step: 10
Training loss: 4.298510652818888
Validation loss: 3.539095841794708

Epoch: 13| Step: 0
Training loss: 3.43509409546553
Validation loss: 3.522592360842409

Epoch: 5| Step: 1
Training loss: 3.6869845272491726
Validation loss: 3.536606256427304

Epoch: 5| Step: 2
Training loss: 4.180779373300257
Validation loss: 3.5120868075922953

Epoch: 5| Step: 3
Training loss: 3.0517562499996
Validation loss: 3.5066679066387922

Epoch: 5| Step: 4
Training loss: 4.0951184031377865
Validation loss: 3.5037861150429905

Epoch: 5| Step: 5
Training loss: 4.067450690647596
Validation loss: 3.4985680588116623

Epoch: 5| Step: 6
Training loss: 4.050314130492111
Validation loss: 3.490266373403745

Epoch: 5| Step: 7
Training loss: 3.120621169195072
Validation loss: 3.4845727840210134

Epoch: 5| Step: 8
Training loss: 3.658412847907527
Validation loss: 3.477951390688535

Epoch: 5| Step: 9
Training loss: 3.4911210652768023
Validation loss: 3.464889081945189

Epoch: 5| Step: 10
Training loss: 3.7681312926191315
Validation loss: 3.458703005134075

Epoch: 14| Step: 0
Training loss: 3.875806539953206
Validation loss: 3.4506400406488513

Epoch: 5| Step: 1
Training loss: 3.956102177417993
Validation loss: 3.4445313793233114

Epoch: 5| Step: 2
Training loss: 3.228380037704155
Validation loss: 3.436645108414513

Epoch: 5| Step: 3
Training loss: 3.4943339943087492
Validation loss: 3.434000933018431

Epoch: 5| Step: 4
Training loss: 2.920385623708299
Validation loss: 3.4272129126475894

Epoch: 5| Step: 5
Training loss: 4.3151374160262215
Validation loss: 3.437254870671585

Epoch: 5| Step: 6
Training loss: 3.3046877885822865
Validation loss: 3.4183279186168356

Epoch: 5| Step: 7
Training loss: 3.943663964640423
Validation loss: 3.4231153139407455

Epoch: 5| Step: 8
Training loss: 2.96962524361651
Validation loss: 3.411229991182973

Epoch: 5| Step: 9
Training loss: 3.8245732237640717
Validation loss: 3.4025605831738295

Epoch: 5| Step: 10
Training loss: 4.088397304958676
Validation loss: 3.3993698046393956

Epoch: 15| Step: 0
Training loss: 3.5284654559476585
Validation loss: 3.3980503833500944

Epoch: 5| Step: 1
Training loss: 3.958184664427308
Validation loss: 3.3944711107651147

Epoch: 5| Step: 2
Training loss: 4.302508514058956
Validation loss: 3.389023160255329

Epoch: 5| Step: 3
Training loss: 2.749631857072192
Validation loss: 3.3813679611528125

Epoch: 5| Step: 4
Training loss: 3.7138308519044885
Validation loss: 3.3757312776949395

Epoch: 5| Step: 5
Training loss: 3.405520159724293
Validation loss: 3.3718771925254987

Epoch: 5| Step: 6
Training loss: 3.5024108757752885
Validation loss: 3.3678652261172077

Epoch: 5| Step: 7
Training loss: 3.710241762494356
Validation loss: 3.3654449029278166

Epoch: 5| Step: 8
Training loss: 3.764799541998307
Validation loss: 3.3610628886707046

Epoch: 5| Step: 9
Training loss: 3.261266546825162
Validation loss: 3.358805890919001

Epoch: 5| Step: 10
Training loss: 3.5604574136800045
Validation loss: 3.3569327548416594

Epoch: 16| Step: 0
Training loss: 3.5459339389058666
Validation loss: 3.3536694896462653

Epoch: 5| Step: 1
Training loss: 3.7348931244415784
Validation loss: 3.3483109785377736

Epoch: 5| Step: 2
Training loss: 3.4880396982523685
Validation loss: 3.346178608292056

Epoch: 5| Step: 3
Training loss: 3.3802480514065953
Validation loss: 3.3424473347731225

Epoch: 5| Step: 4
Training loss: 2.559830740757225
Validation loss: 3.339358668159985

Epoch: 5| Step: 5
Training loss: 3.6909083762298454
Validation loss: 3.337294626394386

Epoch: 5| Step: 6
Training loss: 4.362418694817874
Validation loss: 3.333937730651585

Epoch: 5| Step: 7
Training loss: 3.686433928963038
Validation loss: 3.3318514442216327

Epoch: 5| Step: 8
Training loss: 3.9015899938333436
Validation loss: 3.3303485232636714

Epoch: 5| Step: 9
Training loss: 2.7376394785007037
Validation loss: 3.3266158055267647

Epoch: 5| Step: 10
Training loss: 3.9212086632020866
Validation loss: 3.325166818704102

Epoch: 17| Step: 0
Training loss: 3.6756238913830344
Validation loss: 3.3254035323028406

Epoch: 5| Step: 1
Training loss: 3.319789279776893
Validation loss: 3.3242585807476903

Epoch: 5| Step: 2
Training loss: 3.1710824962941633
Validation loss: 3.321352099896813

Epoch: 5| Step: 3
Training loss: 3.632810006089534
Validation loss: 3.31339786687385

Epoch: 5| Step: 4
Training loss: 3.5809580152959084
Validation loss: 3.3239327948998945

Epoch: 5| Step: 5
Training loss: 3.9465379681309196
Validation loss: 3.3189211319465755

Epoch: 5| Step: 6
Training loss: 3.940173981983636
Validation loss: 3.311971288284115

Epoch: 5| Step: 7
Training loss: 2.995482540328697
Validation loss: 3.315985149717774

Epoch: 5| Step: 8
Training loss: 3.2260747730271393
Validation loss: 3.3185865052922385

Epoch: 5| Step: 9
Training loss: 4.15159908877248
Validation loss: 3.3080251585578826

Epoch: 5| Step: 10
Training loss: 3.276061397102913
Validation loss: 3.306604778004705

Epoch: 18| Step: 0
Training loss: 3.043128267742039
Validation loss: 3.3101275324457036

Epoch: 5| Step: 1
Training loss: 4.5187086512360874
Validation loss: 3.312180495762481

Epoch: 5| Step: 2
Training loss: 3.6697712817110006
Validation loss: 3.3059371462462463

Epoch: 5| Step: 3
Training loss: 3.76181103047507
Validation loss: 3.30134430206854

Epoch: 5| Step: 4
Training loss: 3.5249409988551803
Validation loss: 3.30024531960639

Epoch: 5| Step: 5
Training loss: 3.4792760652866512
Validation loss: 3.2986846562152827

Epoch: 5| Step: 6
Training loss: 3.6846563721976513
Validation loss: 3.297447070587982

Epoch: 5| Step: 7
Training loss: 2.9221762435577165
Validation loss: 3.2954974507792527

Epoch: 5| Step: 8
Training loss: 3.1040384321586405
Validation loss: 3.2924268480012024

Epoch: 5| Step: 9
Training loss: 3.2130471976951567
Validation loss: 3.2966299023734886

Epoch: 5| Step: 10
Training loss: 3.8549208169565405
Validation loss: 3.3276182069304836

Epoch: 19| Step: 0
Training loss: 2.813555710065571
Validation loss: 3.2903887780061405

Epoch: 5| Step: 1
Training loss: 3.891747737805203
Validation loss: 3.323430742191096

Epoch: 5| Step: 2
Training loss: 3.638881282135161
Validation loss: 3.3029079854809704

Epoch: 5| Step: 3
Training loss: 3.652847402188703
Validation loss: 3.2969661502342045

Epoch: 5| Step: 4
Training loss: 4.291158751026775
Validation loss: 3.327405108468065

Epoch: 5| Step: 5
Training loss: 3.998048902547422
Validation loss: 3.313767617637895

Epoch: 5| Step: 6
Training loss: 3.4122393386275163
Validation loss: 3.2866408216470373

Epoch: 5| Step: 7
Training loss: 3.7353761998778996
Validation loss: 3.294020433631759

Epoch: 5| Step: 8
Training loss: 2.871762982696201
Validation loss: 3.3110600780247665

Epoch: 5| Step: 9
Training loss: 3.2616678747903585
Validation loss: 3.317793484840086

Epoch: 5| Step: 10
Training loss: 3.0932584429861305
Validation loss: 3.307242812859341

Epoch: 20| Step: 0
Training loss: 3.710322728682313
Validation loss: 3.29919497066629

Epoch: 5| Step: 1
Training loss: 3.4793089572948963
Validation loss: 3.2878282539470587

Epoch: 5| Step: 2
Training loss: 3.1739902302351872
Validation loss: 3.291882598344907

Epoch: 5| Step: 3
Training loss: 3.74796227085824
Validation loss: 3.299297721543379

Epoch: 5| Step: 4
Training loss: 2.857863563511044
Validation loss: 3.2926150713618227

Epoch: 5| Step: 5
Training loss: 3.8874550280162254
Validation loss: 3.2815919181318467

Epoch: 5| Step: 6
Training loss: 3.8016527045257087
Validation loss: 3.274443829405488

Epoch: 5| Step: 7
Training loss: 3.518497497280153
Validation loss: 3.2711240332136478

Epoch: 5| Step: 8
Training loss: 3.159142707714401
Validation loss: 3.2752036457110187

Epoch: 5| Step: 9
Training loss: 3.620824447872613
Validation loss: 3.3135494520838766

Epoch: 5| Step: 10
Training loss: 3.8322714011937133
Validation loss: 3.267416473103655

Epoch: 21| Step: 0
Training loss: 3.725878254832869
Validation loss: 3.267388956790261

Epoch: 5| Step: 1
Training loss: 2.4648842785581944
Validation loss: 3.270556385194234

Epoch: 5| Step: 2
Training loss: 3.7119660889457755
Validation loss: 3.2781882006234384

Epoch: 5| Step: 3
Training loss: 3.0918875588801433
Validation loss: 3.2721014068272303

Epoch: 5| Step: 4
Training loss: 3.941923411894465
Validation loss: 3.2648380110598247

Epoch: 5| Step: 5
Training loss: 3.1930640034459907
Validation loss: 3.264743072532092

Epoch: 5| Step: 6
Training loss: 3.6302879175176597
Validation loss: 3.271300013267601

Epoch: 5| Step: 7
Training loss: 4.328290915493725
Validation loss: 3.2751052253387

Epoch: 5| Step: 8
Training loss: 3.7001281716081302
Validation loss: 3.2758296075793796

Epoch: 5| Step: 9
Training loss: 3.7296825599078356
Validation loss: 3.263033053017095

Epoch: 5| Step: 10
Training loss: 2.627100966593781
Validation loss: 3.2595147254107766

Epoch: 22| Step: 0
Training loss: 4.260055986851393
Validation loss: 3.259179003669383

Epoch: 5| Step: 1
Training loss: 3.093508932566567
Validation loss: 3.2623886508065723

Epoch: 5| Step: 2
Training loss: 3.445871320804928
Validation loss: 3.261429299021972

Epoch: 5| Step: 3
Training loss: 2.6555111923484693
Validation loss: 3.2582500489816506

Epoch: 5| Step: 4
Training loss: 3.389357369426474
Validation loss: 3.255179404378343

Epoch: 5| Step: 5
Training loss: 3.9808175754907356
Validation loss: 3.2509556856838184

Epoch: 5| Step: 6
Training loss: 3.87875836139433
Validation loss: 3.2475823591105093

Epoch: 5| Step: 7
Training loss: 3.397335321001622
Validation loss: 3.245828349196137

Epoch: 5| Step: 8
Training loss: 3.308843069579826
Validation loss: 3.245360950039959

Epoch: 5| Step: 9
Training loss: 3.5598209413223785
Validation loss: 3.2446128458708774

Epoch: 5| Step: 10
Training loss: 3.283728834881948
Validation loss: 3.246394940096458

Epoch: 23| Step: 0
Training loss: 3.6049441930337416
Validation loss: 3.2459674741194195

Epoch: 5| Step: 1
Training loss: 3.217377601554012
Validation loss: 3.24633804096458

Epoch: 5| Step: 2
Training loss: 3.4201781363690795
Validation loss: 3.2396867034777905

Epoch: 5| Step: 3
Training loss: 3.261354565419006
Validation loss: 3.2381345966874755

Epoch: 5| Step: 4
Training loss: 3.5347639846249925
Validation loss: 3.2379464857751272

Epoch: 5| Step: 5
Training loss: 3.7587682575255603
Validation loss: 3.237926728412281

Epoch: 5| Step: 6
Training loss: 3.881627475731225
Validation loss: 3.237355120425391

Epoch: 5| Step: 7
Training loss: 3.4481166232271625
Validation loss: 3.235410287126

Epoch: 5| Step: 8
Training loss: 3.288369873766754
Validation loss: 3.233870062783058

Epoch: 5| Step: 9
Training loss: 3.1834619412898006
Validation loss: 3.233323293868441

Epoch: 5| Step: 10
Training loss: 3.7771771146673023
Validation loss: 3.2307577991749126

Epoch: 24| Step: 0
Training loss: 3.941396571469782
Validation loss: 3.2291601100911964

Epoch: 5| Step: 1
Training loss: 3.1242739024615847
Validation loss: 3.2283445827532864

Epoch: 5| Step: 2
Training loss: 3.74621250891167
Validation loss: 3.23141438471533

Epoch: 5| Step: 3
Training loss: 3.8106128211794243
Validation loss: 3.226184242286147

Epoch: 5| Step: 4
Training loss: 3.357769675711751
Validation loss: 3.2311133898049076

Epoch: 5| Step: 5
Training loss: 3.350287205924683
Validation loss: 3.229625134004069

Epoch: 5| Step: 6
Training loss: 3.192281091842624
Validation loss: 3.232074425254043

Epoch: 5| Step: 7
Training loss: 4.011058065803956
Validation loss: 3.227664473990105

Epoch: 5| Step: 8
Training loss: 3.2386961741301383
Validation loss: 3.2277793886767836

Epoch: 5| Step: 9
Training loss: 2.877538306862047
Validation loss: 3.223035581158087

Epoch: 5| Step: 10
Training loss: 3.4698802034657925
Validation loss: 3.222617866633079

Epoch: 25| Step: 0
Training loss: 3.7189746436218605
Validation loss: 3.2222211077750313

Epoch: 5| Step: 1
Training loss: 3.9923667792808284
Validation loss: 3.2190412546294342

Epoch: 5| Step: 2
Training loss: 3.4411105527936545
Validation loss: 3.2217178067192824

Epoch: 5| Step: 3
Training loss: 3.5105243217344
Validation loss: 3.2211951488134076

Epoch: 5| Step: 4
Training loss: 3.274393674910434
Validation loss: 3.221808225066

Epoch: 5| Step: 5
Training loss: 3.0333177258715294
Validation loss: 3.2185137262071404

Epoch: 5| Step: 6
Training loss: 3.4950698461361425
Validation loss: 3.2188284641685545

Epoch: 5| Step: 7
Training loss: 3.8093977016057305
Validation loss: 3.221162231217487

Epoch: 5| Step: 8
Training loss: 3.4561337442833464
Validation loss: 3.221966262889767

Epoch: 5| Step: 9
Training loss: 4.0291581751757946
Validation loss: 3.222674877501965

Epoch: 5| Step: 10
Training loss: 1.6361684670763672
Validation loss: 3.2177946602602012

Epoch: 26| Step: 0
Training loss: 3.51251680091831
Validation loss: 3.215942174428261

Epoch: 5| Step: 1
Training loss: 3.655217734138414
Validation loss: 3.2156001001595014

Epoch: 5| Step: 2
Training loss: 4.173958133284651
Validation loss: 3.2144786666443887

Epoch: 5| Step: 3
Training loss: 3.7075679860791393
Validation loss: 3.2153044220182387

Epoch: 5| Step: 4
Training loss: 2.578440144091027
Validation loss: 3.211704238554419

Epoch: 5| Step: 5
Training loss: 3.080271171175693
Validation loss: 3.2111337444736283

Epoch: 5| Step: 6
Training loss: 3.332108240702692
Validation loss: 3.2099411260857527

Epoch: 5| Step: 7
Training loss: 3.794427781621546
Validation loss: 3.2093599086353577

Epoch: 5| Step: 8
Training loss: 3.4879841950347212
Validation loss: 3.209080312831384

Epoch: 5| Step: 9
Training loss: 3.55207584563032
Validation loss: 3.208525829402835

Epoch: 5| Step: 10
Training loss: 2.805067541359847
Validation loss: 3.2067321379656333

Epoch: 27| Step: 0
Training loss: 3.372073847693991
Validation loss: 3.205205292750452

Epoch: 5| Step: 1
Training loss: 3.052215434438981
Validation loss: 3.205271562530267

Epoch: 5| Step: 2
Training loss: 3.3612091025648123
Validation loss: 3.2099942458933737

Epoch: 5| Step: 3
Training loss: 3.8544689300508117
Validation loss: 3.221642758280451

Epoch: 5| Step: 4
Training loss: 3.405479694024196
Validation loss: 3.2443481875971636

Epoch: 5| Step: 5
Training loss: 3.976465370176127
Validation loss: 3.2289012094575265

Epoch: 5| Step: 6
Training loss: 3.4399826794565316
Validation loss: 3.2036060499262677

Epoch: 5| Step: 7
Training loss: 3.4233935744628936
Validation loss: 3.202583460496323

Epoch: 5| Step: 8
Training loss: 3.3596727815876384
Validation loss: 3.2116021352506423

Epoch: 5| Step: 9
Training loss: 3.7113839934929613
Validation loss: 3.241508758184495

Epoch: 5| Step: 10
Training loss: 2.94293716126115
Validation loss: 3.201492525055265

Epoch: 28| Step: 0
Training loss: 1.796557788215652
Validation loss: 3.196700309157137

Epoch: 5| Step: 1
Training loss: 3.40655726175629
Validation loss: 3.2020326365951757

Epoch: 5| Step: 2
Training loss: 3.9537041884405544
Validation loss: 3.2416816902988224

Epoch: 5| Step: 3
Training loss: 4.24070801059827
Validation loss: 3.2048583696272654

Epoch: 5| Step: 4
Training loss: 4.2505723904389985
Validation loss: 3.198106674658742

Epoch: 5| Step: 5
Training loss: 3.8309695516126596
Validation loss: 3.203799507520672

Epoch: 5| Step: 6
Training loss: 3.9575120308091325
Validation loss: 3.204425937155547

Epoch: 5| Step: 7
Training loss: 2.6644961543929657
Validation loss: 3.214709582135939

Epoch: 5| Step: 8
Training loss: 3.0862472958126093
Validation loss: 3.2370762842823986

Epoch: 5| Step: 9
Training loss: 2.888311501618775
Validation loss: 3.2205945376875524

Epoch: 5| Step: 10
Training loss: 3.203250640638045
Validation loss: 3.197034112721276

Epoch: 29| Step: 0
Training loss: 3.475996678630616
Validation loss: 3.189878383512744

Epoch: 5| Step: 1
Training loss: 2.7869213444478764
Validation loss: 3.1881406953679496

Epoch: 5| Step: 2
Training loss: 3.8714930754713808
Validation loss: 3.1874375422658274

Epoch: 5| Step: 3
Training loss: 3.33562101698765
Validation loss: 3.1858405245731647

Epoch: 5| Step: 4
Training loss: 3.950773844184897
Validation loss: 3.186181571279496

Epoch: 5| Step: 5
Training loss: 3.5978763939584715
Validation loss: 3.18715525754863

Epoch: 5| Step: 6
Training loss: 3.151226918893711
Validation loss: 3.195287706828669

Epoch: 5| Step: 7
Training loss: 3.923323041005167
Validation loss: 3.1906579395819663

Epoch: 5| Step: 8
Training loss: 2.874337493193914
Validation loss: 3.181940534295732

Epoch: 5| Step: 9
Training loss: 3.589430095097657
Validation loss: 3.181631969507941

Epoch: 5| Step: 10
Training loss: 2.9970303778599625
Validation loss: 3.1784267162813986

Epoch: 30| Step: 0
Training loss: 3.9110123557449357
Validation loss: 3.177685459692104

Epoch: 5| Step: 1
Training loss: 3.065589747483823
Validation loss: 3.1781589155313066

Epoch: 5| Step: 2
Training loss: 3.3484667728228588
Validation loss: 3.1776002667450545

Epoch: 5| Step: 3
Training loss: 4.0303864256408755
Validation loss: 3.193915749757548

Epoch: 5| Step: 4
Training loss: 2.741143443571471
Validation loss: 3.1774017857574464

Epoch: 5| Step: 5
Training loss: 3.3828161649265653
Validation loss: 3.174227225604961

Epoch: 5| Step: 6
Training loss: 4.436836730387895
Validation loss: 3.1725723677593627

Epoch: 5| Step: 7
Training loss: 3.1183330371828686
Validation loss: 3.169648658125009

Epoch: 5| Step: 8
Training loss: 3.1854319127784327
Validation loss: 3.171032815442716

Epoch: 5| Step: 9
Training loss: 3.2602427540831616
Validation loss: 3.170102662723144

Epoch: 5| Step: 10
Training loss: 2.8725130686118217
Validation loss: 3.1713341514974043

Epoch: 31| Step: 0
Training loss: 3.132228425866191
Validation loss: 3.169170564134488

Epoch: 5| Step: 1
Training loss: 4.331310876195566
Validation loss: 3.1703098601459927

Epoch: 5| Step: 2
Training loss: 3.4561770660817386
Validation loss: 3.169826843464016

Epoch: 5| Step: 3
Training loss: 2.8141777968099504
Validation loss: 3.1702586776473205

Epoch: 5| Step: 4
Training loss: 2.8904628398877525
Validation loss: 3.1686544798870098

Epoch: 5| Step: 5
Training loss: 3.7801653354554356
Validation loss: 3.1671004643180183

Epoch: 5| Step: 6
Training loss: 2.6870814152696596
Validation loss: 3.165152952729203

Epoch: 5| Step: 7
Training loss: 3.400365383486154
Validation loss: 3.164351234240902

Epoch: 5| Step: 8
Training loss: 3.735674388623476
Validation loss: 3.1636286904159703

Epoch: 5| Step: 9
Training loss: 3.3737199969828544
Validation loss: 3.162727505167202

Epoch: 5| Step: 10
Training loss: 3.712339244919914
Validation loss: 3.1620043259977693

Epoch: 32| Step: 0
Training loss: 2.887505905343495
Validation loss: 3.1586917467223827

Epoch: 5| Step: 1
Training loss: 3.2360060260466685
Validation loss: 3.1583552520140303

Epoch: 5| Step: 2
Training loss: 3.6193508986742877
Validation loss: 3.1578060616422428

Epoch: 5| Step: 3
Training loss: 3.8318438469561955
Validation loss: 3.1564172005793725

Epoch: 5| Step: 4
Training loss: 3.122561151594437
Validation loss: 3.154006609090028

Epoch: 5| Step: 5
Training loss: 3.129218801444222
Validation loss: 3.154811044176565

Epoch: 5| Step: 6
Training loss: 3.502610731532339
Validation loss: 3.1535947651645198

Epoch: 5| Step: 7
Training loss: 3.557837798540037
Validation loss: 3.154211568890052

Epoch: 5| Step: 8
Training loss: 3.2172702980595784
Validation loss: 3.153045196874611

Epoch: 5| Step: 9
Training loss: 3.404577001885488
Validation loss: 3.1535978868005894

Epoch: 5| Step: 10
Training loss: 3.941755266114564
Validation loss: 3.153001759222381

Epoch: 33| Step: 0
Training loss: 3.615717480003469
Validation loss: 3.150092033386901

Epoch: 5| Step: 1
Training loss: 2.7020137023973647
Validation loss: 3.148395119210843

Epoch: 5| Step: 2
Training loss: 3.9809162760566386
Validation loss: 3.1502866646784637

Epoch: 5| Step: 3
Training loss: 3.7452305026859842
Validation loss: 3.15401327583518

Epoch: 5| Step: 4
Training loss: 3.0984920033303536
Validation loss: 3.153817198387891

Epoch: 5| Step: 5
Training loss: 3.2246907048912323
Validation loss: 3.1507358799614757

Epoch: 5| Step: 6
Training loss: 3.4883718788531333
Validation loss: 3.1462228429708117

Epoch: 5| Step: 7
Training loss: 3.231409012148785
Validation loss: 3.1455143098044918

Epoch: 5| Step: 8
Training loss: 3.7018508972692015
Validation loss: 3.143280944525533

Epoch: 5| Step: 9
Training loss: 3.073155453127439
Validation loss: 3.1427179557296805

Epoch: 5| Step: 10
Training loss: 3.433862877411423
Validation loss: 3.1414455247422852

Epoch: 34| Step: 0
Training loss: 3.94432396921154
Validation loss: 3.139255098186493

Epoch: 5| Step: 1
Training loss: 3.2269084458628443
Validation loss: 3.137363875091309

Epoch: 5| Step: 2
Training loss: 3.213725195558631
Validation loss: 3.1414120844484397

Epoch: 5| Step: 3
Training loss: 2.8088445007697374
Validation loss: 3.1470865481927945

Epoch: 5| Step: 4
Training loss: 3.3717360078096066
Validation loss: 3.149367548249389

Epoch: 5| Step: 5
Training loss: 3.1064589739070083
Validation loss: 3.145090385533861

Epoch: 5| Step: 6
Training loss: 3.3652513783667946
Validation loss: 3.140565087478499

Epoch: 5| Step: 7
Training loss: 3.947401041598805
Validation loss: 3.1399179665873933

Epoch: 5| Step: 8
Training loss: 2.9244036009421843
Validation loss: 3.1382117769076507

Epoch: 5| Step: 9
Training loss: 3.1648620348806835
Validation loss: 3.134339075691646

Epoch: 5| Step: 10
Training loss: 4.098937031724086
Validation loss: 3.13248009910744

Epoch: 35| Step: 0
Training loss: 3.213424276539699
Validation loss: 3.132328613396842

Epoch: 5| Step: 1
Training loss: 3.464885311458031
Validation loss: 3.132015956476395

Epoch: 5| Step: 2
Training loss: 3.1321022198829813
Validation loss: 3.130598671697249

Epoch: 5| Step: 3
Training loss: 3.09610389016681
Validation loss: 3.1292939282303163

Epoch: 5| Step: 4
Training loss: 3.502670631581669
Validation loss: 3.1287265347184765

Epoch: 5| Step: 5
Training loss: 4.213450628490913
Validation loss: 3.128304600984886

Epoch: 5| Step: 6
Training loss: 3.135025118251117
Validation loss: 3.1276609416938124

Epoch: 5| Step: 7
Training loss: 3.5544958041975665
Validation loss: 3.127370787408555

Epoch: 5| Step: 8
Training loss: 3.510773290674113
Validation loss: 3.1255491270569857

Epoch: 5| Step: 9
Training loss: 2.7125360794128985
Validation loss: 3.1234522426014575

Epoch: 5| Step: 10
Training loss: 3.512790741206186
Validation loss: 3.122714672610248

Epoch: 36| Step: 0
Training loss: 3.2525510312767687
Validation loss: 3.1238161711890773

Epoch: 5| Step: 1
Training loss: 3.3778023564827544
Validation loss: 3.1246392318688394

Epoch: 5| Step: 2
Training loss: 3.138333979556084
Validation loss: 3.1217804786919223

Epoch: 5| Step: 3
Training loss: 3.8115487084417183
Validation loss: 3.1213915338348226

Epoch: 5| Step: 4
Training loss: 3.7871881942062187
Validation loss: 3.12283284341487

Epoch: 5| Step: 5
Training loss: 2.818406916882887
Validation loss: 3.1201590321510024

Epoch: 5| Step: 6
Training loss: 3.48902835513199
Validation loss: 3.1221058460858706

Epoch: 5| Step: 7
Training loss: 3.546369474574711
Validation loss: 3.1235449670664877

Epoch: 5| Step: 8
Training loss: 3.377075263705409
Validation loss: 3.119081005007173

Epoch: 5| Step: 9
Training loss: 3.0217015213664826
Validation loss: 3.1227801603318666

Epoch: 5| Step: 10
Training loss: 3.3834344939594367
Validation loss: 3.1235490084228488

Epoch: 37| Step: 0
Training loss: 2.908078510594117
Validation loss: 3.120998526245387

Epoch: 5| Step: 1
Training loss: 2.8033910108416857
Validation loss: 3.119373508324583

Epoch: 5| Step: 2
Training loss: 3.374553226993393
Validation loss: 3.116475192934394

Epoch: 5| Step: 3
Training loss: 3.219320302271609
Validation loss: 3.1139350738056386

Epoch: 5| Step: 4
Training loss: 3.4921877730879367
Validation loss: 3.1109209286981665

Epoch: 5| Step: 5
Training loss: 3.6065858575461034
Validation loss: 3.111605586130509

Epoch: 5| Step: 6
Training loss: 3.1572433268287523
Validation loss: 3.1105155483428195

Epoch: 5| Step: 7
Training loss: 3.937558491590293
Validation loss: 3.1103699938447797

Epoch: 5| Step: 8
Training loss: 3.5437075550154575
Validation loss: 3.1092532702914615

Epoch: 5| Step: 9
Training loss: 3.5802197051161335
Validation loss: 3.1093956145911408

Epoch: 5| Step: 10
Training loss: 3.263419688884024
Validation loss: 3.1078177452501987

Epoch: 38| Step: 0
Training loss: 3.7069684778009857
Validation loss: 3.1063798748972546

Epoch: 5| Step: 1
Training loss: 3.5422670790420554
Validation loss: 3.107453234956914

Epoch: 5| Step: 2
Training loss: 2.9153992396832384
Validation loss: 3.1036863669138643

Epoch: 5| Step: 3
Training loss: 3.4489667202037126
Validation loss: 3.104975879346895

Epoch: 5| Step: 4
Training loss: 3.5000846035132476
Validation loss: 3.1034847324506316

Epoch: 5| Step: 5
Training loss: 3.650134849670128
Validation loss: 3.102972741014226

Epoch: 5| Step: 6
Training loss: 3.3350424358636324
Validation loss: 3.101918252681724

Epoch: 5| Step: 7
Training loss: 3.5291689251588862
Validation loss: 3.1023729626739103

Epoch: 5| Step: 8
Training loss: 3.145999087246849
Validation loss: 3.104118342387179

Epoch: 5| Step: 9
Training loss: 2.945176989121947
Validation loss: 3.109502609898497

Epoch: 5| Step: 10
Training loss: 3.120398987176538
Validation loss: 3.1148051724332415

Epoch: 39| Step: 0
Training loss: 3.470117660198651
Validation loss: 3.103819539813213

Epoch: 5| Step: 1
Training loss: 2.6183716785222084
Validation loss: 3.1049412577644313

Epoch: 5| Step: 2
Training loss: 3.5091430587415307
Validation loss: 3.1034427009739582

Epoch: 5| Step: 3
Training loss: 3.9825817186456973
Validation loss: 3.1014839720972893

Epoch: 5| Step: 4
Training loss: 2.739813926671518
Validation loss: 3.0992386706730306

Epoch: 5| Step: 5
Training loss: 3.3623587199314446
Validation loss: 3.0946038473380186

Epoch: 5| Step: 6
Training loss: 3.370714645905389
Validation loss: 3.0918446102355364

Epoch: 5| Step: 7
Training loss: 2.8729139306320723
Validation loss: 3.0913957786998973

Epoch: 5| Step: 8
Training loss: 3.531724475953334
Validation loss: 3.0897340618295996

Epoch: 5| Step: 9
Training loss: 3.094633188280531
Validation loss: 3.08517718260256

Epoch: 5| Step: 10
Training loss: 4.078293135527655
Validation loss: 3.0853525953506353

Epoch: 40| Step: 0
Training loss: 2.850114177625256
Validation loss: 3.085327108008354

Epoch: 5| Step: 1
Training loss: 3.1196661633619063
Validation loss: 3.083219256420658

Epoch: 5| Step: 2
Training loss: 3.088502382968887
Validation loss: 3.081366751336639

Epoch: 5| Step: 3
Training loss: 2.9526597721240138
Validation loss: 3.0847189687930165

Epoch: 5| Step: 4
Training loss: 3.015526962663214
Validation loss: 3.083324727248997

Epoch: 5| Step: 5
Training loss: 4.1640379942554
Validation loss: 3.0816435342132107

Epoch: 5| Step: 6
Training loss: 3.35920594255758
Validation loss: 3.081101807865391

Epoch: 5| Step: 7
Training loss: 3.75252435278567
Validation loss: 3.080547990905585

Epoch: 5| Step: 8
Training loss: 3.33159760742468
Validation loss: 3.0767755610709124

Epoch: 5| Step: 9
Training loss: 2.568466590413065
Validation loss: 3.0783289751258445

Epoch: 5| Step: 10
Training loss: 4.306920076676023
Validation loss: 3.074408982067739

Epoch: 41| Step: 0
Training loss: 3.6345145227444116
Validation loss: 3.0774264144906778

Epoch: 5| Step: 1
Training loss: 3.70468660416546
Validation loss: 3.0741261672359603

Epoch: 5| Step: 2
Training loss: 3.0551267342260315
Validation loss: 3.075335667835374

Epoch: 5| Step: 3
Training loss: 3.3092478496270465
Validation loss: 3.0720348268464126

Epoch: 5| Step: 4
Training loss: 3.6471424622509074
Validation loss: 3.0707398900224665

Epoch: 5| Step: 5
Training loss: 2.8914803553940813
Validation loss: 3.068308695972036

Epoch: 5| Step: 6
Training loss: 3.0244025531041094
Validation loss: 3.070034217909662

Epoch: 5| Step: 7
Training loss: 3.2278461996921703
Validation loss: 3.069244528841139

Epoch: 5| Step: 8
Training loss: 3.254465703050057
Validation loss: 3.067765999576235

Epoch: 5| Step: 9
Training loss: 3.478357704514681
Validation loss: 3.066257005566666

Epoch: 5| Step: 10
Training loss: 3.3595190682679794
Validation loss: 3.0680066698396002

Epoch: 42| Step: 0
Training loss: 3.591640218001576
Validation loss: 3.0681595649684263

Epoch: 5| Step: 1
Training loss: 3.828536902863724
Validation loss: 3.06721630663704

Epoch: 5| Step: 2
Training loss: 3.1981287253251707
Validation loss: 3.074781790306823

Epoch: 5| Step: 3
Training loss: 3.4481560354130822
Validation loss: 3.0831682529064146

Epoch: 5| Step: 4
Training loss: 3.5688624536330424
Validation loss: 3.102301887642138

Epoch: 5| Step: 5
Training loss: 2.5145763794287412
Validation loss: 3.0662937519627502

Epoch: 5| Step: 6
Training loss: 3.476624906172683
Validation loss: 3.0629308756153697

Epoch: 5| Step: 7
Training loss: 3.0012423803827746
Validation loss: 3.062548921825093

Epoch: 5| Step: 8
Training loss: 3.702114949317677
Validation loss: 3.059822566251174

Epoch: 5| Step: 9
Training loss: 3.054104410311552
Validation loss: 3.061350759378201

Epoch: 5| Step: 10
Training loss: 2.973224039278598
Validation loss: 3.0625170015989487

Epoch: 43| Step: 0
Training loss: 3.3449891548380073
Validation loss: 3.061929759748755

Epoch: 5| Step: 1
Training loss: 2.742942945097662
Validation loss: 3.0632169184475595

Epoch: 5| Step: 2
Training loss: 3.0856055745144437
Validation loss: 3.0582774796914913

Epoch: 5| Step: 3
Training loss: 3.6168518569809684
Validation loss: 3.0572055257302235

Epoch: 5| Step: 4
Training loss: 4.077600438081397
Validation loss: 3.0573520197792106

Epoch: 5| Step: 5
Training loss: 3.0613810772324017
Validation loss: 3.0565052346226698

Epoch: 5| Step: 6
Training loss: 2.8675668242034
Validation loss: 3.0563563991868894

Epoch: 5| Step: 7
Training loss: 3.556303558214476
Validation loss: 3.053616267117943

Epoch: 5| Step: 8
Training loss: 2.9297711576597383
Validation loss: 3.0554253164174465

Epoch: 5| Step: 9
Training loss: 3.404755430694939
Validation loss: 3.056747286315313

Epoch: 5| Step: 10
Training loss: 3.6789638188317966
Validation loss: 3.055395050220944

Epoch: 44| Step: 0
Training loss: 2.937137987271693
Validation loss: 3.059241922639929

Epoch: 5| Step: 1
Training loss: 4.1162256496252505
Validation loss: 3.0565651852952835

Epoch: 5| Step: 2
Training loss: 3.684190590524873
Validation loss: 3.0523541923992368

Epoch: 5| Step: 3
Training loss: 3.525662618273079
Validation loss: 3.055086291372877

Epoch: 5| Step: 4
Training loss: 2.73202230328215
Validation loss: 3.050300881223886

Epoch: 5| Step: 5
Training loss: 3.058134275882701
Validation loss: 3.0470290244743374

Epoch: 5| Step: 6
Training loss: 3.076957055050969
Validation loss: 3.0462170265129282

Epoch: 5| Step: 7
Training loss: 3.0271712715483408
Validation loss: 3.044880156601658

Epoch: 5| Step: 8
Training loss: 3.5451672177496283
Validation loss: 3.046015139511197

Epoch: 5| Step: 9
Training loss: 2.9269938788993493
Validation loss: 3.044879792878699

Epoch: 5| Step: 10
Training loss: 3.629308967705677
Validation loss: 3.0431736696461282

Epoch: 45| Step: 0
Training loss: 3.2281767937935655
Validation loss: 3.042757108267461

Epoch: 5| Step: 1
Training loss: 3.0145543228648126
Validation loss: 3.0413774669499003

Epoch: 5| Step: 2
Training loss: 3.6121264782683515
Validation loss: 3.0430528140312694

Epoch: 5| Step: 3
Training loss: 2.6771623374671067
Validation loss: 3.041708076274962

Epoch: 5| Step: 4
Training loss: 4.031185179196635
Validation loss: 3.04103003725625

Epoch: 5| Step: 5
Training loss: 3.316958180432751
Validation loss: 3.041480350449098

Epoch: 5| Step: 6
Training loss: 2.9343228304026914
Validation loss: 3.038671655510434

Epoch: 5| Step: 7
Training loss: 3.97223636354954
Validation loss: 3.0379213533188643

Epoch: 5| Step: 8
Training loss: 3.132684186557515
Validation loss: 3.037460134590575

Epoch: 5| Step: 9
Training loss: 3.1970255021124285
Validation loss: 3.0360346656004946

Epoch: 5| Step: 10
Training loss: 2.9490289285973614
Validation loss: 3.035319504368825

Epoch: 46| Step: 0
Training loss: 3.1292271824524684
Validation loss: 3.0357361286811755

Epoch: 5| Step: 1
Training loss: 3.6159857119134484
Validation loss: 3.0364900288070653

Epoch: 5| Step: 2
Training loss: 3.483148333247002
Validation loss: 3.038015812385951

Epoch: 5| Step: 3
Training loss: 3.3533560837668484
Validation loss: 3.0327240252728425

Epoch: 5| Step: 4
Training loss: 3.074314295290979
Validation loss: 3.0339247769493816

Epoch: 5| Step: 5
Training loss: 3.25507340215141
Validation loss: 3.032075058197777

Epoch: 5| Step: 6
Training loss: 3.3959022624191233
Validation loss: 3.0301244363054103

Epoch: 5| Step: 7
Training loss: 2.9563493836938144
Validation loss: 3.0300928276650034

Epoch: 5| Step: 8
Training loss: 3.3011043954709103
Validation loss: 3.0265060700170694

Epoch: 5| Step: 9
Training loss: 3.252437411152497
Validation loss: 3.026845245441729

Epoch: 5| Step: 10
Training loss: 3.5030859557944165
Validation loss: 3.0282204960582506

Epoch: 47| Step: 0
Training loss: 3.6290000681662953
Validation loss: 3.0248393182971167

Epoch: 5| Step: 1
Training loss: 2.8646789719771033
Validation loss: 3.0252254874261726

Epoch: 5| Step: 2
Training loss: 3.538022459020325
Validation loss: 3.026452431832611

Epoch: 5| Step: 3
Training loss: 2.7729367945910477
Validation loss: 3.023987507463304

Epoch: 5| Step: 4
Training loss: 2.76111005795427
Validation loss: 3.0284124078516075

Epoch: 5| Step: 5
Training loss: 3.0243787458585407
Validation loss: 3.0280739328723336

Epoch: 5| Step: 6
Training loss: 3.0897576359878953
Validation loss: 3.0336728821324823

Epoch: 5| Step: 7
Training loss: 3.87421076951279
Validation loss: 3.0587109482631116

Epoch: 5| Step: 8
Training loss: 3.4826935273322954
Validation loss: 3.0774472305970333

Epoch: 5| Step: 9
Training loss: 3.669025240553724
Validation loss: 3.0696890427955923

Epoch: 5| Step: 10
Training loss: 3.3989648870151075
Validation loss: 3.0266770481972207

Epoch: 48| Step: 0
Training loss: 3.165921943497555
Validation loss: 3.021102526378072

Epoch: 5| Step: 1
Training loss: 2.948688707025952
Validation loss: 3.020761185330098

Epoch: 5| Step: 2
Training loss: 4.1067533651918575
Validation loss: 3.0234677215021346

Epoch: 5| Step: 3
Training loss: 3.0371506666706716
Validation loss: 3.0349878916505895

Epoch: 5| Step: 4
Training loss: 3.115570184192909
Validation loss: 3.0326936052168696

Epoch: 5| Step: 5
Training loss: 3.2446864781033193
Validation loss: 3.0296212309095156

Epoch: 5| Step: 6
Training loss: 2.931588250593952
Validation loss: 3.019013509236638

Epoch: 5| Step: 7
Training loss: 3.3495001861303435
Validation loss: 3.0176104483761708

Epoch: 5| Step: 8
Training loss: 3.9012425179548793
Validation loss: 3.0169242224993367

Epoch: 5| Step: 9
Training loss: 3.0594040149407764
Validation loss: 3.0172665906804834

Epoch: 5| Step: 10
Training loss: 3.0960401285414667
Validation loss: 3.0202175294891287

Epoch: 49| Step: 0
Training loss: 3.36267552254479
Validation loss: 3.0353183692218813

Epoch: 5| Step: 1
Training loss: 3.6621557288733
Validation loss: 3.0255627999388657

Epoch: 5| Step: 2
Training loss: 2.7023908025963372
Validation loss: 3.0162119178708147

Epoch: 5| Step: 3
Training loss: 3.336156761950436
Validation loss: 3.012829604082365

Epoch: 5| Step: 4
Training loss: 3.01098053787109
Validation loss: 3.011331294882745

Epoch: 5| Step: 5
Training loss: 3.4059617506781428
Validation loss: 3.0180473054484236

Epoch: 5| Step: 6
Training loss: 2.6242584816053443
Validation loss: 3.019625312244196

Epoch: 5| Step: 7
Training loss: 3.0740000393730367
Validation loss: 3.022046933297457

Epoch: 5| Step: 8
Training loss: 3.3000701318860197
Validation loss: 3.0135448774822704

Epoch: 5| Step: 9
Training loss: 3.620718696866126
Validation loss: 3.0117708630497666

Epoch: 5| Step: 10
Training loss: 3.8775973075496895
Validation loss: 3.009131066412559

Epoch: 50| Step: 0
Training loss: 3.102779120985025
Validation loss: 3.007133814942737

Epoch: 5| Step: 1
Training loss: 2.7064754471467687
Validation loss: 3.0071995238810785

Epoch: 5| Step: 2
Training loss: 3.2680608252627716
Validation loss: 3.00801745045286

Epoch: 5| Step: 3
Training loss: 3.3369955131630915
Validation loss: 3.008903163549521

Epoch: 5| Step: 4
Training loss: 3.043783487687959
Validation loss: 3.0098538368480936

Epoch: 5| Step: 5
Training loss: 3.996801289467035
Validation loss: 3.0083598531286353

Epoch: 5| Step: 6
Training loss: 3.1584993411062405
Validation loss: 3.0100581117438026

Epoch: 5| Step: 7
Training loss: 3.1270357748875783
Validation loss: 3.0091169801755213

Epoch: 5| Step: 8
Training loss: 3.71245985426855
Validation loss: 3.0037293531874707

Epoch: 5| Step: 9
Training loss: 3.15398711109612
Validation loss: 3.0031538659191566

Epoch: 5| Step: 10
Training loss: 3.320088313892921
Validation loss: 3.000797540008371

Epoch: 51| Step: 0
Training loss: 3.0571408773448936
Validation loss: 2.999366996408517

Epoch: 5| Step: 1
Training loss: 3.2754184309996677
Validation loss: 2.999452571759791

Epoch: 5| Step: 2
Training loss: 3.6053942903081246
Validation loss: 2.998583206143455

Epoch: 5| Step: 3
Training loss: 3.6617615720256516
Validation loss: 2.9991796629835243

Epoch: 5| Step: 4
Training loss: 3.5014885053259404
Validation loss: 2.997470529380218

Epoch: 5| Step: 5
Training loss: 3.686939261523583
Validation loss: 2.996870149799714

Epoch: 5| Step: 6
Training loss: 2.684890011997862
Validation loss: 3.0016794460185596

Epoch: 5| Step: 7
Training loss: 3.130523682681866
Validation loss: 3.0061440788129383

Epoch: 5| Step: 8
Training loss: 2.7717311714298747
Validation loss: 3.002768174283335

Epoch: 5| Step: 9
Training loss: 3.324839945217802
Validation loss: 3.0014115758979787

Epoch: 5| Step: 10
Training loss: 3.0635758670548188
Validation loss: 3.00335233115033

Epoch: 52| Step: 0
Training loss: 2.956493737010106
Validation loss: 2.9986862823508704

Epoch: 5| Step: 1
Training loss: 3.1697523409012454
Validation loss: 2.998555514164311

Epoch: 5| Step: 2
Training loss: 3.512885488622816
Validation loss: 3.010698595601177

Epoch: 5| Step: 3
Training loss: 3.207730290269477
Validation loss: 2.9938963442647086

Epoch: 5| Step: 4
Training loss: 3.2654490446298086
Validation loss: 2.9908050656745933

Epoch: 5| Step: 5
Training loss: 2.831798212394848
Validation loss: 2.9912122513693036

Epoch: 5| Step: 6
Training loss: 3.1680443092676907
Validation loss: 2.990372188858095

Epoch: 5| Step: 7
Training loss: 3.880526877348641
Validation loss: 2.9881381217260623

Epoch: 5| Step: 8
Training loss: 3.6333746362374217
Validation loss: 2.9883180089892476

Epoch: 5| Step: 9
Training loss: 2.9439551668692463
Validation loss: 2.986405484900708

Epoch: 5| Step: 10
Training loss: 3.112635450977771
Validation loss: 2.98670598793441

Epoch: 53| Step: 0
Training loss: 3.907882837442699
Validation loss: 2.989117895746364

Epoch: 5| Step: 1
Training loss: 3.350535273134147
Validation loss: 2.9869158815951398

Epoch: 5| Step: 2
Training loss: 3.2475048170281586
Validation loss: 2.985962556993025

Epoch: 5| Step: 3
Training loss: 3.2053243390251738
Validation loss: 2.983894492003687

Epoch: 5| Step: 4
Training loss: 2.4921976406166144
Validation loss: 2.9827939164960258

Epoch: 5| Step: 5
Training loss: 2.501018984076234
Validation loss: 2.983454991074444

Epoch: 5| Step: 6
Training loss: 3.2574784727402593
Validation loss: 2.980845005206425

Epoch: 5| Step: 7
Training loss: 3.493150684905891
Validation loss: 2.981783925326979

Epoch: 5| Step: 8
Training loss: 3.2194737481784133
Validation loss: 2.9802610224715727

Epoch: 5| Step: 9
Training loss: 3.745878625128467
Validation loss: 2.978692438158476

Epoch: 5| Step: 10
Training loss: 3.136513671251686
Validation loss: 2.980189469615511

Epoch: 54| Step: 0
Training loss: 3.759461483234121
Validation loss: 2.9763882002773094

Epoch: 5| Step: 1
Training loss: 3.3181426733612964
Validation loss: 2.977638030291949

Epoch: 5| Step: 2
Training loss: 3.312134920551032
Validation loss: 2.979001117572432

Epoch: 5| Step: 3
Training loss: 3.1488639599514694
Validation loss: 2.9753075843005976

Epoch: 5| Step: 4
Training loss: 2.541717924841474
Validation loss: 2.976303340365679

Epoch: 5| Step: 5
Training loss: 3.31608905331221
Validation loss: 2.9752988162506373

Epoch: 5| Step: 6
Training loss: 3.063485901623476
Validation loss: 2.9776241515118778

Epoch: 5| Step: 7
Training loss: 3.0972686178688718
Validation loss: 2.9796157631511484

Epoch: 5| Step: 8
Training loss: 2.859365994798832
Validation loss: 2.974727298381181

Epoch: 5| Step: 9
Training loss: 3.252905207381243
Validation loss: 2.975994418171795

Epoch: 5| Step: 10
Training loss: 3.9051360716416923
Validation loss: 2.983797326380671

Epoch: 55| Step: 0
Training loss: 2.5871606797792066
Validation loss: 2.9896576088869087

Epoch: 5| Step: 1
Training loss: 3.337487890100119
Validation loss: 3.011054819156517

Epoch: 5| Step: 2
Training loss: 3.1136210984815844
Validation loss: 2.9826373183845143

Epoch: 5| Step: 3
Training loss: 3.431773739503452
Validation loss: 2.9798203421035274

Epoch: 5| Step: 4
Training loss: 3.3582520493230144
Validation loss: 2.968325916995049

Epoch: 5| Step: 5
Training loss: 3.492784692278671
Validation loss: 2.965233005043083

Epoch: 5| Step: 6
Training loss: 2.870996424264518
Validation loss: 2.962954158749227

Epoch: 5| Step: 7
Training loss: 3.288601732032736
Validation loss: 2.9666583116290894

Epoch: 5| Step: 8
Training loss: 3.0124601052836026
Validation loss: 2.965216950867324

Epoch: 5| Step: 9
Training loss: 3.5191717948638335
Validation loss: 2.9690744418116624

Epoch: 5| Step: 10
Training loss: 3.674981803589491
Validation loss: 2.9742398333618865

Epoch: 56| Step: 0
Training loss: 3.99466993933095
Validation loss: 2.9727942483605836

Epoch: 5| Step: 1
Training loss: 2.9583567945239557
Validation loss: 2.9681912028508157

Epoch: 5| Step: 2
Training loss: 3.2186344459309453
Validation loss: 2.966436410102586

Epoch: 5| Step: 3
Training loss: 3.279541442730212
Validation loss: 2.9657190295931737

Epoch: 5| Step: 4
Training loss: 3.1636162337197873
Validation loss: 2.962151742755386

Epoch: 5| Step: 5
Training loss: 3.202578763209128
Validation loss: 2.961003277390785

Epoch: 5| Step: 6
Training loss: 2.859702836717664
Validation loss: 2.9604957773384277

Epoch: 5| Step: 7
Training loss: 3.4757690895915623
Validation loss: 2.958349807314403

Epoch: 5| Step: 8
Training loss: 3.360387463254534
Validation loss: 2.956125088342802

Epoch: 5| Step: 9
Training loss: 3.0158800402697326
Validation loss: 2.956873236326041

Epoch: 5| Step: 10
Training loss: 2.9676299542170037
Validation loss: 2.954984360075996

Epoch: 57| Step: 0
Training loss: 3.720970452584754
Validation loss: 2.956505491691989

Epoch: 5| Step: 1
Training loss: 3.4426464050232535
Validation loss: 2.9558913987539497

Epoch: 5| Step: 2
Training loss: 2.9920628773207323
Validation loss: 2.9557955155978752

Epoch: 5| Step: 3
Training loss: 3.5120824979768366
Validation loss: 2.952363302678426

Epoch: 5| Step: 4
Training loss: 3.5568150451894507
Validation loss: 2.951491516632416

Epoch: 5| Step: 5
Training loss: 3.2070630684132597
Validation loss: 2.9517172810033636

Epoch: 5| Step: 6
Training loss: 2.02831443524967
Validation loss: 2.955463537166738

Epoch: 5| Step: 7
Training loss: 3.1375945544338095
Validation loss: 2.954720269335218

Epoch: 5| Step: 8
Training loss: 3.235022733393274
Validation loss: 2.9567500991731723

Epoch: 5| Step: 9
Training loss: 2.961641655685558
Validation loss: 2.9571107114155764

Epoch: 5| Step: 10
Training loss: 3.4969024575308576
Validation loss: 2.9580282911662943

Epoch: 58| Step: 0
Training loss: 3.374488509237305
Validation loss: 2.9512389437189577

Epoch: 5| Step: 1
Training loss: 3.2466730548814073
Validation loss: 2.946578036081416

Epoch: 5| Step: 2
Training loss: 3.1328223934635706
Validation loss: 2.945761507030104

Epoch: 5| Step: 3
Training loss: 3.7402239209220745
Validation loss: 2.9430576097942325

Epoch: 5| Step: 4
Training loss: 3.065921351489713
Validation loss: 2.9436412752795436

Epoch: 5| Step: 5
Training loss: 2.726717094695002
Validation loss: 2.944301181463525

Epoch: 5| Step: 6
Training loss: 3.1340714586262832
Validation loss: 2.943905892254828

Epoch: 5| Step: 7
Training loss: 3.4494794701682605
Validation loss: 2.9452751033042266

Epoch: 5| Step: 8
Training loss: 2.8808213053628675
Validation loss: 2.94361846872429

Epoch: 5| Step: 9
Training loss: 3.114468337437763
Validation loss: 2.941398711783792

Epoch: 5| Step: 10
Training loss: 3.5392011400565853
Validation loss: 2.9389148351605625

Epoch: 59| Step: 0
Training loss: 3.7320628649782166
Validation loss: 2.9427777330711113

Epoch: 5| Step: 1
Training loss: 3.3774062162151317
Validation loss: 2.9401287464142682

Epoch: 5| Step: 2
Training loss: 3.302567760341263
Validation loss: 2.9373883531831684

Epoch: 5| Step: 3
Training loss: 2.9413610204129625
Validation loss: 2.9457209577426053

Epoch: 5| Step: 4
Training loss: 3.1921444136092005
Validation loss: 2.9448033544449053

Epoch: 5| Step: 5
Training loss: 3.265850442651888
Validation loss: 2.9392964715559633

Epoch: 5| Step: 6
Training loss: 3.0978035621202427
Validation loss: 2.948646972966891

Epoch: 5| Step: 7
Training loss: 3.3734259997017673
Validation loss: 2.93638927761186

Epoch: 5| Step: 8
Training loss: 2.5184843505409513
Validation loss: 2.933913559128596

Epoch: 5| Step: 9
Training loss: 2.773506099228645
Validation loss: 2.934348608031493

Epoch: 5| Step: 10
Training loss: 3.7184864880458806
Validation loss: 2.9326665381453245

Epoch: 60| Step: 0
Training loss: 3.442587953772279
Validation loss: 2.9346884750047364

Epoch: 5| Step: 1
Training loss: 3.5651862741307765
Validation loss: 2.9302026946760638

Epoch: 5| Step: 2
Training loss: 2.7460506864511065
Validation loss: 2.9291364971740332

Epoch: 5| Step: 3
Training loss: 3.1735859282589103
Validation loss: 2.9304781656667895

Epoch: 5| Step: 4
Training loss: 2.9005170492753884
Validation loss: 2.9317487638372914

Epoch: 5| Step: 5
Training loss: 3.0881417043913912
Validation loss: 2.9281942599102644

Epoch: 5| Step: 6
Training loss: 3.0047560185610913
Validation loss: 2.931302066337678

Epoch: 5| Step: 7
Training loss: 3.1009508582006884
Validation loss: 2.9289955447545424

Epoch: 5| Step: 8
Training loss: 2.6633874479803126
Validation loss: 2.9302088504811206

Epoch: 5| Step: 9
Training loss: 3.632981556886269
Validation loss: 2.931920570673799

Epoch: 5| Step: 10
Training loss: 3.8813204748171546
Validation loss: 2.9404454907771487

Epoch: 61| Step: 0
Training loss: 3.197657538403723
Validation loss: 2.9362292232290077

Epoch: 5| Step: 1
Training loss: 2.9848467868353556
Validation loss: 2.9479196002672685

Epoch: 5| Step: 2
Training loss: 3.4130771358523853
Validation loss: 2.959026415510773

Epoch: 5| Step: 3
Training loss: 3.024518906349928
Validation loss: 2.994585931175111

Epoch: 5| Step: 4
Training loss: 3.370022105022797
Validation loss: 2.954026676138316

Epoch: 5| Step: 5
Training loss: 2.870606257773854
Validation loss: 2.926188415369068

Epoch: 5| Step: 6
Training loss: 3.7001500795186555
Validation loss: 2.9209524815822467

Epoch: 5| Step: 7
Training loss: 3.697932598813977
Validation loss: 2.919239156680566

Epoch: 5| Step: 8
Training loss: 2.965077105801326
Validation loss: 2.923799498779299

Epoch: 5| Step: 9
Training loss: 3.08648738549153
Validation loss: 2.9210256838451754

Epoch: 5| Step: 10
Training loss: 2.6990262748227996
Validation loss: 2.922922674480511

Epoch: 62| Step: 0
Training loss: 3.6070131443123667
Validation loss: 2.9224559028153605

Epoch: 5| Step: 1
Training loss: 2.6784161368267925
Validation loss: 2.921978508049925

Epoch: 5| Step: 2
Training loss: 3.027322643575617
Validation loss: 2.922217043232052

Epoch: 5| Step: 3
Training loss: 2.947676380370816
Validation loss: 2.9214580405745747

Epoch: 5| Step: 4
Training loss: 2.8543797619944677
Validation loss: 2.9213392341074798

Epoch: 5| Step: 5
Training loss: 3.127831511396367
Validation loss: 2.919562317226416

Epoch: 5| Step: 6
Training loss: 3.2089472261810474
Validation loss: 2.9176284440704987

Epoch: 5| Step: 7
Training loss: 3.5295643792161164
Validation loss: 2.9187493501724715

Epoch: 5| Step: 8
Training loss: 2.8854733311199556
Validation loss: 2.916832669246789

Epoch: 5| Step: 9
Training loss: 3.5946009416297424
Validation loss: 2.9162029624357944

Epoch: 5| Step: 10
Training loss: 3.733826920260095
Validation loss: 2.9151420323469277

Epoch: 63| Step: 0
Training loss: 2.277057819508545
Validation loss: 2.9141830476145887

Epoch: 5| Step: 1
Training loss: 2.982010149062838
Validation loss: 2.9121710050527785

Epoch: 5| Step: 2
Training loss: 3.10777433207968
Validation loss: 2.9132805753690545

Epoch: 5| Step: 3
Training loss: 2.8944548109002755
Validation loss: 2.911631623899271

Epoch: 5| Step: 4
Training loss: 3.479042934265738
Validation loss: 2.9114844272807625

Epoch: 5| Step: 5
Training loss: 3.061931012294015
Validation loss: 2.9082709818924104

Epoch: 5| Step: 6
Training loss: 3.7923710486681506
Validation loss: 2.9096213810062825

Epoch: 5| Step: 7
Training loss: 3.072187089249699
Validation loss: 2.9096457633298796

Epoch: 5| Step: 8
Training loss: 3.3226838384075377
Validation loss: 2.911611187829173

Epoch: 5| Step: 9
Training loss: 3.5341752350845814
Validation loss: 2.9314654190946454

Epoch: 5| Step: 10
Training loss: 3.4781061410178435
Validation loss: 2.910608268826632

Epoch: 64| Step: 0
Training loss: 3.8149153765770922
Validation loss: 2.9049530187368138

Epoch: 5| Step: 1
Training loss: 3.761283429429245
Validation loss: 2.9033413429070185

Epoch: 5| Step: 2
Training loss: 2.916184212882368
Validation loss: 2.9067923253411636

Epoch: 5| Step: 3
Training loss: 2.937084736792358
Validation loss: 2.9068363518683564

Epoch: 5| Step: 4
Training loss: 3.528911390083358
Validation loss: 2.9061914818048455

Epoch: 5| Step: 5
Training loss: 2.4852578375930388
Validation loss: 2.9048606752932327

Epoch: 5| Step: 6
Training loss: 3.508190924743567
Validation loss: 2.90417488245166

Epoch: 5| Step: 7
Training loss: 3.191515468937031
Validation loss: 2.9028485156686292

Epoch: 5| Step: 8
Training loss: 3.124316636708119
Validation loss: 2.9038988920338933

Epoch: 5| Step: 9
Training loss: 2.375086933351915
Validation loss: 2.9033927637606913

Epoch: 5| Step: 10
Training loss: 3.1540593769432577
Validation loss: 2.902498980548271

Epoch: 65| Step: 0
Training loss: 3.7088833233173357
Validation loss: 2.9019608026433485

Epoch: 5| Step: 1
Training loss: 3.5261304084433167
Validation loss: 2.899821412390623

Epoch: 5| Step: 2
Training loss: 2.8962461511210162
Validation loss: 2.9013058581203053

Epoch: 5| Step: 3
Training loss: 3.096432380340793
Validation loss: 2.8986095442305646

Epoch: 5| Step: 4
Training loss: 2.8087825366836263
Validation loss: 2.8983914185594934

Epoch: 5| Step: 5
Training loss: 2.412132899366563
Validation loss: 2.897498554931287

Epoch: 5| Step: 6
Training loss: 3.4875309768449547
Validation loss: 2.897990406834721

Epoch: 5| Step: 7
Training loss: 3.235434833057214
Validation loss: 2.8949855862870284

Epoch: 5| Step: 8
Training loss: 3.1762115449765593
Validation loss: 2.8938558228116555

Epoch: 5| Step: 9
Training loss: 2.9072890526433928
Validation loss: 2.8936039441987846

Epoch: 5| Step: 10
Training loss: 3.5810636089079626
Validation loss: 2.904386328826338

Epoch: 66| Step: 0
Training loss: 2.597511780815835
Validation loss: 2.91646317740469

Epoch: 5| Step: 1
Training loss: 3.019954913225938
Validation loss: 2.9244425943762047

Epoch: 5| Step: 2
Training loss: 3.459308593994807
Validation loss: 2.900410837839356

Epoch: 5| Step: 3
Training loss: 3.0654757308783256
Validation loss: 2.8911270729923633

Epoch: 5| Step: 4
Training loss: 3.1508772037347215
Validation loss: 2.885039201812296

Epoch: 5| Step: 5
Training loss: 2.6456912946246463
Validation loss: 2.886474600826496

Epoch: 5| Step: 6
Training loss: 3.1886267073186048
Validation loss: 2.8873558086916766

Epoch: 5| Step: 7
Training loss: 3.691265317456856
Validation loss: 2.8881556949362475

Epoch: 5| Step: 8
Training loss: 3.255884858084887
Validation loss: 2.8861943419307976

Epoch: 5| Step: 9
Training loss: 2.890874078690176
Validation loss: 2.8852036784274966

Epoch: 5| Step: 10
Training loss: 3.954378313859347
Validation loss: 2.8845894774248277

Epoch: 67| Step: 0
Training loss: 2.5612271566940827
Validation loss: 2.881904272010418

Epoch: 5| Step: 1
Training loss: 3.008963228537923
Validation loss: 2.8825907163503457

Epoch: 5| Step: 2
Training loss: 3.2974977311942832
Validation loss: 2.8835246524883624

Epoch: 5| Step: 3
Training loss: 3.0952425352351165
Validation loss: 2.876360610080285

Epoch: 5| Step: 4
Training loss: 2.97155115587342
Validation loss: 2.880142956769646

Epoch: 5| Step: 5
Training loss: 3.253649203438823
Validation loss: 2.8794648151812625

Epoch: 5| Step: 6
Training loss: 2.9795965315840722
Validation loss: 2.8784386248961007

Epoch: 5| Step: 7
Training loss: 3.761976318414631
Validation loss: 2.876577585621743

Epoch: 5| Step: 8
Training loss: 3.4588298364599335
Validation loss: 2.878046254357454

Epoch: 5| Step: 9
Training loss: 3.2231857697071202
Validation loss: 2.87572962208816

Epoch: 5| Step: 10
Training loss: 3.149073382736712
Validation loss: 2.8725156549976933

Epoch: 68| Step: 0
Training loss: 3.2425954539087916
Validation loss: 2.8760033631565887

Epoch: 5| Step: 1
Training loss: 3.6730936828181755
Validation loss: 2.875192847077247

Epoch: 5| Step: 2
Training loss: 3.5020596030068787
Validation loss: 2.872537259885733

Epoch: 5| Step: 3
Training loss: 3.3727364190147497
Validation loss: 2.872264195277379

Epoch: 5| Step: 4
Training loss: 2.9112908730886873
Validation loss: 2.871384587812401

Epoch: 5| Step: 5
Training loss: 2.95639922267453
Validation loss: 2.8718257731788364

Epoch: 5| Step: 6
Training loss: 3.3159479873774673
Validation loss: 2.8712397717037774

Epoch: 5| Step: 7
Training loss: 2.466201625838721
Validation loss: 2.865594088122101

Epoch: 5| Step: 8
Training loss: 3.0781157052921215
Validation loss: 2.8680935440964803

Epoch: 5| Step: 9
Training loss: 3.469451146101929
Validation loss: 2.871596072137247

Epoch: 5| Step: 10
Training loss: 2.5279995805824513
Validation loss: 2.873168715190644

Epoch: 69| Step: 0
Training loss: 3.6333808044225546
Validation loss: 2.8762071071915343

Epoch: 5| Step: 1
Training loss: 3.052529589910282
Validation loss: 2.8636925713902843

Epoch: 5| Step: 2
Training loss: 3.3873811313845765
Validation loss: 2.867035973015152

Epoch: 5| Step: 3
Training loss: 3.2111379741819563
Validation loss: 2.8706059702066113

Epoch: 5| Step: 4
Training loss: 2.6924022940898364
Validation loss: 2.8732229807208833

Epoch: 5| Step: 5
Training loss: 2.487453640453088
Validation loss: 2.884688321031061

Epoch: 5| Step: 6
Training loss: 3.474575203378552
Validation loss: 2.8776620201554093

Epoch: 5| Step: 7
Training loss: 2.8565386269480224
Validation loss: 2.8689414859607667

Epoch: 5| Step: 8
Training loss: 3.6321637630597783
Validation loss: 2.8693252153724735

Epoch: 5| Step: 9
Training loss: 3.2191632940630357
Validation loss: 2.8626194789763324

Epoch: 5| Step: 10
Training loss: 3.017975676684389
Validation loss: 2.862041741245377

Epoch: 70| Step: 0
Training loss: 3.2658577429957587
Validation loss: 2.8633542702838746

Epoch: 5| Step: 1
Training loss: 3.369619814201706
Validation loss: 2.8621282216880193

Epoch: 5| Step: 2
Training loss: 3.613713814901609
Validation loss: 2.8655744044497973

Epoch: 5| Step: 3
Training loss: 2.870085620998578
Validation loss: 2.871913778240148

Epoch: 5| Step: 4
Training loss: 3.378402266649899
Validation loss: 2.8556151280943642

Epoch: 5| Step: 5
Training loss: 3.002577151562708
Validation loss: 2.8570641263612098

Epoch: 5| Step: 6
Training loss: 2.9401921049920894
Validation loss: 2.853032455252602

Epoch: 5| Step: 7
Training loss: 3.343725186550017
Validation loss: 2.8515559325772597

Epoch: 5| Step: 8
Training loss: 2.7031842704845914
Validation loss: 2.8491688381151365

Epoch: 5| Step: 9
Training loss: 2.7523225166829275
Validation loss: 2.849910276418635

Epoch: 5| Step: 10
Training loss: 3.3550126961526114
Validation loss: 2.8501621306725005

Epoch: 71| Step: 0
Training loss: 3.4015864373601503
Validation loss: 2.848305723165851

Epoch: 5| Step: 1
Training loss: 3.2449721545889445
Validation loss: 2.846590412376305

Epoch: 5| Step: 2
Training loss: 2.909708569802419
Validation loss: 2.8483429781270564

Epoch: 5| Step: 3
Training loss: 3.2371784536568744
Validation loss: 2.8496357866947566

Epoch: 5| Step: 4
Training loss: 3.521607187914933
Validation loss: 2.8489710872060447

Epoch: 5| Step: 5
Training loss: 3.577013001206904
Validation loss: 2.8501676354349734

Epoch: 5| Step: 6
Training loss: 2.4892829064667867
Validation loss: 2.8452456387368343

Epoch: 5| Step: 7
Training loss: 3.031683979233153
Validation loss: 2.8478877181130273

Epoch: 5| Step: 8
Training loss: 2.7713957672256395
Validation loss: 2.8454908370235867

Epoch: 5| Step: 9
Training loss: 3.1402780521495246
Validation loss: 2.849212653729997

Epoch: 5| Step: 10
Training loss: 3.073733532626054
Validation loss: 2.8542066046897583

Epoch: 72| Step: 0
Training loss: 3.301988008649507
Validation loss: 2.8510723129286406

Epoch: 5| Step: 1
Training loss: 3.676051455223748
Validation loss: 2.8408071063130067

Epoch: 5| Step: 2
Training loss: 3.1128977081030595
Validation loss: 2.8420647323551043

Epoch: 5| Step: 3
Training loss: 2.6356127418484485
Validation loss: 2.849460092773119

Epoch: 5| Step: 4
Training loss: 2.3104480196651704
Validation loss: 2.891983402153678

Epoch: 5| Step: 5
Training loss: 3.6214205729164326
Validation loss: 2.9163458060229397

Epoch: 5| Step: 6
Training loss: 3.000616487102832
Validation loss: 2.912817786643091

Epoch: 5| Step: 7
Training loss: 3.716384135114922
Validation loss: 2.8897000585414094

Epoch: 5| Step: 8
Training loss: 3.0409326756409394
Validation loss: 2.8798840374001067

Epoch: 5| Step: 9
Training loss: 2.6302391629568227
Validation loss: 2.8534652684068016

Epoch: 5| Step: 10
Training loss: 3.591651370081593
Validation loss: 2.8350080210300668

Epoch: 73| Step: 0
Training loss: 3.2736173958156765
Validation loss: 2.8391399715230015

Epoch: 5| Step: 1
Training loss: 2.940529255620767
Validation loss: 2.886856900157194

Epoch: 5| Step: 2
Training loss: 3.4955396841855224
Validation loss: 3.00959660611155

Epoch: 5| Step: 3
Training loss: 2.4459596210306502
Validation loss: 2.9039519026688705

Epoch: 5| Step: 4
Training loss: 3.0457415697822925
Validation loss: 2.823340368529309

Epoch: 5| Step: 5
Training loss: 3.472742755443224
Validation loss: 2.8410926175392834

Epoch: 5| Step: 6
Training loss: 3.4377122293327727
Validation loss: 2.839678044524577

Epoch: 5| Step: 7
Training loss: 3.008671942452318
Validation loss: 2.8584687053972555

Epoch: 5| Step: 8
Training loss: 3.0937328916134437
Validation loss: 2.863370359278963

Epoch: 5| Step: 9
Training loss: 3.1247743143603244
Validation loss: 2.8389919366802263

Epoch: 5| Step: 10
Training loss: 3.184198801783165
Validation loss: 2.8235289682265656

Epoch: 74| Step: 0
Training loss: 2.9807186396922454
Validation loss: 2.8190783664725525

Epoch: 5| Step: 1
Training loss: 3.247361359136671
Validation loss: 2.8184228249422496

Epoch: 5| Step: 2
Training loss: 3.70591148129938
Validation loss: 2.8189404123276303

Epoch: 5| Step: 3
Training loss: 3.717493951070414
Validation loss: 2.8263736737310476

Epoch: 5| Step: 4
Training loss: 3.3060331738625504
Validation loss: 2.8322876611826766

Epoch: 5| Step: 5
Training loss: 2.867277471393626
Validation loss: 2.8385156785885997

Epoch: 5| Step: 6
Training loss: 2.4374697756727395
Validation loss: 2.8630395166174605

Epoch: 5| Step: 7
Training loss: 3.1948347783836075
Validation loss: 2.876774670417288

Epoch: 5| Step: 8
Training loss: 2.544300205421687
Validation loss: 2.8431075329474935

Epoch: 5| Step: 9
Training loss: 3.1762854069189146
Validation loss: 2.821524985180967

Epoch: 5| Step: 10
Training loss: 2.9188022061565855
Validation loss: 2.8223764339823436

Epoch: 75| Step: 0
Training loss: 3.2704512419525185
Validation loss: 2.8214471206288194

Epoch: 5| Step: 1
Training loss: 2.560599296725736
Validation loss: 2.822026219507323

Epoch: 5| Step: 2
Training loss: 2.5816938263474407
Validation loss: 2.8273056883983076

Epoch: 5| Step: 3
Training loss: 3.1728266148218953
Validation loss: 2.828204885199948

Epoch: 5| Step: 4
Training loss: 3.287439376214064
Validation loss: 2.8101146969760697

Epoch: 5| Step: 5
Training loss: 3.4625419531528783
Validation loss: 2.8106671193522117

Epoch: 5| Step: 6
Training loss: 3.017636591767734
Validation loss: 2.810272464959794

Epoch: 5| Step: 7
Training loss: 3.0803159090998307
Validation loss: 2.820350763745771

Epoch: 5| Step: 8
Training loss: 3.30966194500988
Validation loss: 2.836561644562976

Epoch: 5| Step: 9
Training loss: 3.577742510346002
Validation loss: 2.8205476499839857

Epoch: 5| Step: 10
Training loss: 2.8063142357082134
Validation loss: 2.8110913968454536

Epoch: 76| Step: 0
Training loss: 3.0663070371091665
Validation loss: 2.804092200086054

Epoch: 5| Step: 1
Training loss: 2.6322963672792716
Validation loss: 2.805549517676171

Epoch: 5| Step: 2
Training loss: 2.6231944823043882
Validation loss: 2.8034410012743143

Epoch: 5| Step: 3
Training loss: 3.703080961714014
Validation loss: 2.803917419339848

Epoch: 5| Step: 4
Training loss: 3.090803187896874
Validation loss: 2.8034838928780497

Epoch: 5| Step: 5
Training loss: 3.768566454819345
Validation loss: 2.8039513819728628

Epoch: 5| Step: 6
Training loss: 3.032656156665801
Validation loss: 2.802586435103267

Epoch: 5| Step: 7
Training loss: 2.9022441862338737
Validation loss: 2.8038791672272363

Epoch: 5| Step: 8
Training loss: 3.2568659516514287
Validation loss: 2.802566574176942

Epoch: 5| Step: 9
Training loss: 3.226091031780863
Validation loss: 2.8004958720095474

Epoch: 5| Step: 10
Training loss: 2.6711917472060662
Validation loss: 2.7997818108116386

Epoch: 77| Step: 0
Training loss: 3.282739355769428
Validation loss: 2.79792550421338

Epoch: 5| Step: 1
Training loss: 2.959181131298737
Validation loss: 2.7973662537505826

Epoch: 5| Step: 2
Training loss: 3.2670623682360787
Validation loss: 2.7966782026360852

Epoch: 5| Step: 3
Training loss: 3.53832137745655
Validation loss: 2.795343105674329

Epoch: 5| Step: 4
Training loss: 3.133129531914907
Validation loss: 2.792991970707785

Epoch: 5| Step: 5
Training loss: 3.1366260177567478
Validation loss: 2.7907344156587603

Epoch: 5| Step: 6
Training loss: 2.913064166917058
Validation loss: 2.7915802178353863

Epoch: 5| Step: 7
Training loss: 2.870200920116635
Validation loss: 2.792640421315661

Epoch: 5| Step: 8
Training loss: 2.4282071918338
Validation loss: 2.788266657219949

Epoch: 5| Step: 9
Training loss: 3.3271309527717854
Validation loss: 2.792095312736015

Epoch: 5| Step: 10
Training loss: 3.231187807292559
Validation loss: 2.7874393061611538

Epoch: 78| Step: 0
Training loss: 3.411326973208468
Validation loss: 2.7868926678781185

Epoch: 5| Step: 1
Training loss: 3.276681535311312
Validation loss: 2.7851121289709146

Epoch: 5| Step: 2
Training loss: 3.0943451896499785
Validation loss: 2.7856057102434324

Epoch: 5| Step: 3
Training loss: 3.4158338756860207
Validation loss: 2.786275202832701

Epoch: 5| Step: 4
Training loss: 2.0607842909729532
Validation loss: 2.783625191458958

Epoch: 5| Step: 5
Training loss: 2.5886962557914237
Validation loss: 2.789066361457696

Epoch: 5| Step: 6
Training loss: 3.0986212710055305
Validation loss: 2.7939941543286695

Epoch: 5| Step: 7
Training loss: 3.1208994092342346
Validation loss: 2.7910681425626445

Epoch: 5| Step: 8
Training loss: 3.233378528659261
Validation loss: 2.7920808449669643

Epoch: 5| Step: 9
Training loss: 3.4486017074863025
Validation loss: 2.7855916896369246

Epoch: 5| Step: 10
Training loss: 3.037729162040958
Validation loss: 2.7862852521029593

Epoch: 79| Step: 0
Training loss: 3.4100573897916093
Validation loss: 2.7837642961868196

Epoch: 5| Step: 1
Training loss: 2.5949305410038006
Validation loss: 2.7857969649028336

Epoch: 5| Step: 2
Training loss: 2.9747052343180327
Validation loss: 2.7810687671701517

Epoch: 5| Step: 3
Training loss: 3.6202298052435067
Validation loss: 2.7959446210034273

Epoch: 5| Step: 4
Training loss: 3.2912646824805876
Validation loss: 2.785177590914147

Epoch: 5| Step: 5
Training loss: 3.142214548382463
Validation loss: 2.7822548909501377

Epoch: 5| Step: 6
Training loss: 2.828995544322211
Validation loss: 2.77130299382033

Epoch: 5| Step: 7
Training loss: 2.875046439417735
Validation loss: 2.772545823722057

Epoch: 5| Step: 8
Training loss: 3.334970517235509
Validation loss: 2.771261339595465

Epoch: 5| Step: 9
Training loss: 3.0557303831389437
Validation loss: 2.767508987919203

Epoch: 5| Step: 10
Training loss: 2.619050322361992
Validation loss: 2.77126671060934

Epoch: 80| Step: 0
Training loss: 3.489767648564414
Validation loss: 2.7687396403817273

Epoch: 5| Step: 1
Training loss: 3.2315053695027336
Validation loss: 2.766988646235588

Epoch: 5| Step: 2
Training loss: 2.785422206769487
Validation loss: 2.7685207277108996

Epoch: 5| Step: 3
Training loss: 2.6926690005904406
Validation loss: 2.769072081529663

Epoch: 5| Step: 4
Training loss: 3.473609613229038
Validation loss: 2.764057970357183

Epoch: 5| Step: 5
Training loss: 2.827496790795567
Validation loss: 2.76665105384111

Epoch: 5| Step: 6
Training loss: 3.0371701347921456
Validation loss: 2.7676377779191204

Epoch: 5| Step: 7
Training loss: 3.624979742585505
Validation loss: 2.7667172657737593

Epoch: 5| Step: 8
Training loss: 2.7854727930326475
Validation loss: 2.7678266488902827

Epoch: 5| Step: 9
Training loss: 3.1154330486217057
Validation loss: 2.7669059790639454

Epoch: 5| Step: 10
Training loss: 2.5855532818853333
Validation loss: 2.7652139749328963

Epoch: 81| Step: 0
Training loss: 2.486726427800451
Validation loss: 2.7678946851136255

Epoch: 5| Step: 1
Training loss: 2.9646274251511766
Validation loss: 2.7721594364183346

Epoch: 5| Step: 2
Training loss: 2.9315467733041247
Validation loss: 2.77239082918552

Epoch: 5| Step: 3
Training loss: 3.4923011027383506
Validation loss: 2.7709069758425615

Epoch: 5| Step: 4
Training loss: 3.4000209583309693
Validation loss: 2.7675744308655563

Epoch: 5| Step: 5
Training loss: 3.2272366242092776
Validation loss: 2.7645595967150034

Epoch: 5| Step: 6
Training loss: 2.9778907195382787
Validation loss: 2.760072613242894

Epoch: 5| Step: 7
Training loss: 3.0742364323069937
Validation loss: 2.7612618503546424

Epoch: 5| Step: 8
Training loss: 2.6731826526988276
Validation loss: 2.75996803790991

Epoch: 5| Step: 9
Training loss: 3.664265771363818
Validation loss: 2.7596389823544905

Epoch: 5| Step: 10
Training loss: 2.7045560367397603
Validation loss: 2.7583403685367

Epoch: 82| Step: 0
Training loss: 3.1587789243001065
Validation loss: 2.760093199773433

Epoch: 5| Step: 1
Training loss: 3.0849060652665834
Validation loss: 2.7574664534436137

Epoch: 5| Step: 2
Training loss: 2.980010191112732
Validation loss: 2.7600590597096195

Epoch: 5| Step: 3
Training loss: 3.11014213875025
Validation loss: 2.7564623888181057

Epoch: 5| Step: 4
Training loss: 3.714356720423823
Validation loss: 2.7565428162824848

Epoch: 5| Step: 5
Training loss: 3.025865156811286
Validation loss: 2.7599565979718133

Epoch: 5| Step: 6
Training loss: 2.9269212200483192
Validation loss: 2.759004201730381

Epoch: 5| Step: 7
Training loss: 2.4518039329200403
Validation loss: 2.757859804675642

Epoch: 5| Step: 8
Training loss: 3.258389428737996
Validation loss: 2.760762887898267

Epoch: 5| Step: 9
Training loss: 3.1068683277488987
Validation loss: 2.7604735139707617

Epoch: 5| Step: 10
Training loss: 2.853285010573339
Validation loss: 2.7552351859666606

Epoch: 83| Step: 0
Training loss: 2.8343021942848354
Validation loss: 2.75754812993507

Epoch: 5| Step: 1
Training loss: 3.33578569482247
Validation loss: 2.7670210636785986

Epoch: 5| Step: 2
Training loss: 2.410893109667593
Validation loss: 2.7888163980247187

Epoch: 5| Step: 3
Training loss: 3.44544605506625
Validation loss: 2.8081266156288924

Epoch: 5| Step: 4
Training loss: 3.4272043193266333
Validation loss: 2.775638342238045

Epoch: 5| Step: 5
Training loss: 2.5392938596515493
Validation loss: 2.774639456497834

Epoch: 5| Step: 6
Training loss: 3.162901564121351
Validation loss: 2.7651829501542453

Epoch: 5| Step: 7
Training loss: 2.930248318718157
Validation loss: 2.7476100175435754

Epoch: 5| Step: 8
Training loss: 3.2123239313109213
Validation loss: 2.751143781645138

Epoch: 5| Step: 9
Training loss: 3.1744527630520243
Validation loss: 2.7537069590241905

Epoch: 5| Step: 10
Training loss: 3.217377749760783
Validation loss: 2.7588370585170985

Epoch: 84| Step: 0
Training loss: 3.4044036060614005
Validation loss: 2.7609509366453753

Epoch: 5| Step: 1
Training loss: 3.1294859159914226
Validation loss: 2.7742850317064027

Epoch: 5| Step: 2
Training loss: 2.9925127375561886
Validation loss: 2.778779249927404

Epoch: 5| Step: 3
Training loss: 3.5437651457286297
Validation loss: 2.777465631181097

Epoch: 5| Step: 4
Training loss: 3.050171462695706
Validation loss: 2.7702352276275497

Epoch: 5| Step: 5
Training loss: 2.8972125896790732
Validation loss: 2.771581325069448

Epoch: 5| Step: 6
Training loss: 3.228713973933906
Validation loss: 2.7685247076412

Epoch: 5| Step: 7
Training loss: 3.132498023785259
Validation loss: 2.7624724054932694

Epoch: 5| Step: 8
Training loss: 2.345173517895963
Validation loss: 2.7742807347657314

Epoch: 5| Step: 9
Training loss: 2.8734094947167925
Validation loss: 2.759385611805057

Epoch: 5| Step: 10
Training loss: 3.293281368381038
Validation loss: 2.746633723471895

Epoch: 85| Step: 0
Training loss: 2.98378264455273
Validation loss: 2.7497969484363844

Epoch: 5| Step: 1
Training loss: 3.635174776936387
Validation loss: 2.757547949576913

Epoch: 5| Step: 2
Training loss: 2.871584978703746
Validation loss: 2.7950772288957437

Epoch: 5| Step: 3
Training loss: 3.5347692456934574
Validation loss: 2.780126590188133

Epoch: 5| Step: 4
Training loss: 3.386090459040006
Validation loss: 2.754878551367913

Epoch: 5| Step: 5
Training loss: 2.2998971584381964
Validation loss: 2.7418676334168084

Epoch: 5| Step: 6
Training loss: 3.045999410948568
Validation loss: 2.746395304752606

Epoch: 5| Step: 7
Training loss: 2.8387440647212694
Validation loss: 2.7475044276071285

Epoch: 5| Step: 8
Training loss: 2.8814217539007614
Validation loss: 2.7496010145040723

Epoch: 5| Step: 9
Training loss: 2.919554906131164
Validation loss: 2.7526613327077127

Epoch: 5| Step: 10
Training loss: 3.2092155795817874
Validation loss: 2.753484366218246

Epoch: 86| Step: 0
Training loss: 2.8570966137822222
Validation loss: 2.755443822923339

Epoch: 5| Step: 1
Training loss: 3.2090512417904025
Validation loss: 2.7524579363296064

Epoch: 5| Step: 2
Training loss: 2.3259389970542172
Validation loss: 2.7537991950571596

Epoch: 5| Step: 3
Training loss: 2.5224263435853733
Validation loss: 2.7489162996479286

Epoch: 5| Step: 4
Training loss: 3.6620080715155074
Validation loss: 2.744579281672757

Epoch: 5| Step: 5
Training loss: 2.9736762684119475
Validation loss: 2.7441033679142453

Epoch: 5| Step: 6
Training loss: 3.5807452207263215
Validation loss: 2.7435917782737076

Epoch: 5| Step: 7
Training loss: 3.435019551850359
Validation loss: 2.739718003700065

Epoch: 5| Step: 8
Training loss: 2.9852533296215586
Validation loss: 2.740937717495954

Epoch: 5| Step: 9
Training loss: 2.921799276258071
Validation loss: 2.739282808103331

Epoch: 5| Step: 10
Training loss: 3.091973150918911
Validation loss: 2.737212674891793

Epoch: 87| Step: 0
Training loss: 3.1095541130886537
Validation loss: 2.733640959814063

Epoch: 5| Step: 1
Training loss: 3.5026434044135075
Validation loss: 2.736363998313434

Epoch: 5| Step: 2
Training loss: 2.8182062542322988
Validation loss: 2.7345282248885723

Epoch: 5| Step: 3
Training loss: 3.372819690751464
Validation loss: 2.733693685896072

Epoch: 5| Step: 4
Training loss: 3.0460819092505984
Validation loss: 2.7359931182516317

Epoch: 5| Step: 5
Training loss: 3.0832546499024405
Validation loss: 2.7496234043036267

Epoch: 5| Step: 6
Training loss: 2.5984171047086964
Validation loss: 2.7476398915792335

Epoch: 5| Step: 7
Training loss: 3.2652707432513766
Validation loss: 2.7612109319530806

Epoch: 5| Step: 8
Training loss: 2.459606185962878
Validation loss: 2.7382244225744126

Epoch: 5| Step: 9
Training loss: 3.2346214900791765
Validation loss: 2.731929194068095

Epoch: 5| Step: 10
Training loss: 3.08818046083042
Validation loss: 2.7284804631190114

Epoch: 88| Step: 0
Training loss: 3.3502712652349778
Validation loss: 2.7304078493663693

Epoch: 5| Step: 1
Training loss: 3.1973871710155013
Validation loss: 2.7311722738717186

Epoch: 5| Step: 2
Training loss: 2.5392457866537974
Validation loss: 2.732347358805738

Epoch: 5| Step: 3
Training loss: 3.606518560554557
Validation loss: 2.7335719191161854

Epoch: 5| Step: 4
Training loss: 3.17262266771118
Validation loss: 2.7277309195353614

Epoch: 5| Step: 5
Training loss: 3.061471104516831
Validation loss: 2.730864289853827

Epoch: 5| Step: 6
Training loss: 2.93613142232888
Validation loss: 2.72840667459405

Epoch: 5| Step: 7
Training loss: 2.6326166187622264
Validation loss: 2.7300851893934754

Epoch: 5| Step: 8
Training loss: 3.103566173528323
Validation loss: 2.7269294234015886

Epoch: 5| Step: 9
Training loss: 3.18093015490605
Validation loss: 2.724715017616418

Epoch: 5| Step: 10
Training loss: 2.6514533322216365
Validation loss: 2.7262447411897006

Epoch: 89| Step: 0
Training loss: 2.969196647373482
Validation loss: 2.7312193636631927

Epoch: 5| Step: 1
Training loss: 3.294949950328669
Validation loss: 2.7440316699565335

Epoch: 5| Step: 2
Training loss: 3.0638197565872725
Validation loss: 2.765357845661713

Epoch: 5| Step: 3
Training loss: 2.7957435748894506
Validation loss: 2.7766713994581464

Epoch: 5| Step: 4
Training loss: 3.185582949529414
Validation loss: 2.7563362036110433

Epoch: 5| Step: 5
Training loss: 3.8571541145200796
Validation loss: 2.7202103968408693

Epoch: 5| Step: 6
Training loss: 2.2519393616096104
Validation loss: 2.721021503633399

Epoch: 5| Step: 7
Training loss: 2.517300539420715
Validation loss: 2.7190585434577

Epoch: 5| Step: 8
Training loss: 2.781169761614692
Validation loss: 2.7167051001429052

Epoch: 5| Step: 9
Training loss: 2.771216822500024
Validation loss: 2.718899101494121

Epoch: 5| Step: 10
Training loss: 3.8103566633074295
Validation loss: 2.7170317692575487

Epoch: 90| Step: 0
Training loss: 3.4770898311882643
Validation loss: 2.7162107482055027

Epoch: 5| Step: 1
Training loss: 3.571825370543909
Validation loss: 2.7174162006280986

Epoch: 5| Step: 2
Training loss: 3.265447000279334
Validation loss: 2.7159384774165383

Epoch: 5| Step: 3
Training loss: 3.1567302376275133
Validation loss: 2.7157719999168095

Epoch: 5| Step: 4
Training loss: 2.462390773306521
Validation loss: 2.71653589321059

Epoch: 5| Step: 5
Training loss: 2.3414337920286394
Validation loss: 2.7162321258662496

Epoch: 5| Step: 6
Training loss: 3.54892943452326
Validation loss: 2.7165309424676005

Epoch: 5| Step: 7
Training loss: 3.284909632585117
Validation loss: 2.721512899917825

Epoch: 5| Step: 8
Training loss: 2.795951221859185
Validation loss: 2.7269284550779127

Epoch: 5| Step: 9
Training loss: 2.2997790811008123
Validation loss: 2.7288305856416417

Epoch: 5| Step: 10
Training loss: 2.794055561875805
Validation loss: 2.763552403155012

Epoch: 91| Step: 0
Training loss: 3.2422400045165083
Validation loss: 2.7848531039161353

Epoch: 5| Step: 1
Training loss: 3.0195148265238996
Validation loss: 2.797761846288416

Epoch: 5| Step: 2
Training loss: 2.9954045384553694
Validation loss: 2.8363674977637423

Epoch: 5| Step: 3
Training loss: 3.0847782323627233
Validation loss: 2.7210966813983477

Epoch: 5| Step: 4
Training loss: 3.18874110574652
Validation loss: 2.7063846560223177

Epoch: 5| Step: 5
Training loss: 2.979892580029217
Validation loss: 2.712909344141007

Epoch: 5| Step: 6
Training loss: 3.143199264186075
Validation loss: 2.72845707955488

Epoch: 5| Step: 7
Training loss: 2.9160061406200413
Validation loss: 2.7571541345077746

Epoch: 5| Step: 8
Training loss: 2.362780607805676
Validation loss: 2.764469893418468

Epoch: 5| Step: 9
Training loss: 3.2839129586620226
Validation loss: 2.7449264653603875

Epoch: 5| Step: 10
Training loss: 3.4208836621861907
Validation loss: 2.731535728660115

Epoch: 92| Step: 0
Training loss: 3.2613700634636564
Validation loss: 2.714460004525687

Epoch: 5| Step: 1
Training loss: 3.133870771322988
Validation loss: 2.7107879180365724

Epoch: 5| Step: 2
Training loss: 3.457506532918036
Validation loss: 2.7068401779982456

Epoch: 5| Step: 3
Training loss: 2.9084203676100544
Validation loss: 2.7085615612509755

Epoch: 5| Step: 4
Training loss: 3.2631068399739034
Validation loss: 2.7080456665333283

Epoch: 5| Step: 5
Training loss: 2.808288982127928
Validation loss: 2.7126013364727775

Epoch: 5| Step: 6
Training loss: 3.4560008781838185
Validation loss: 2.7471524175320803

Epoch: 5| Step: 7
Training loss: 2.6279151714807187
Validation loss: 2.861364914746032

Epoch: 5| Step: 8
Training loss: 2.5396420800348696
Validation loss: 2.9100933862373837

Epoch: 5| Step: 9
Training loss: 3.366533751429164
Validation loss: 2.82062917674508

Epoch: 5| Step: 10
Training loss: 2.61755295664385
Validation loss: 2.726362453354521

Epoch: 93| Step: 0
Training loss: 3.284889600457651
Validation loss: 2.7128683742946476

Epoch: 5| Step: 1
Training loss: 2.696624878636994
Validation loss: 2.7137717672471973

Epoch: 5| Step: 2
Training loss: 2.8684285567630767
Validation loss: 2.751811989255805

Epoch: 5| Step: 3
Training loss: 3.0965512627106975
Validation loss: 2.9528379086443146

Epoch: 5| Step: 4
Training loss: 2.906884072977956
Validation loss: 2.9956841530091998

Epoch: 5| Step: 5
Training loss: 3.3034270207129985
Validation loss: 2.9467745228348883

Epoch: 5| Step: 6
Training loss: 2.989126846251011
Validation loss: 2.8253716859807563

Epoch: 5| Step: 7
Training loss: 3.324124649813842
Validation loss: 2.7061472441685246

Epoch: 5| Step: 8
Training loss: 3.2887085930346434
Validation loss: 2.693073826677879

Epoch: 5| Step: 9
Training loss: 2.931078771214026
Validation loss: 2.7114050724576613

Epoch: 5| Step: 10
Training loss: 3.434456882767615
Validation loss: 2.8540460824400533

Epoch: 94| Step: 0
Training loss: 3.699625027188144
Validation loss: 2.994997995481954

Epoch: 5| Step: 1
Training loss: 2.92849536291885
Validation loss: 2.853436723325639

Epoch: 5| Step: 2
Training loss: 2.7863106281432275
Validation loss: 2.763074361128728

Epoch: 5| Step: 3
Training loss: 3.0253490152077265
Validation loss: 2.82492155038201

Epoch: 5| Step: 4
Training loss: 3.1323896393816133
Validation loss: 2.879146466894357

Epoch: 5| Step: 5
Training loss: 3.5720099956804043
Validation loss: 2.883540852094898

Epoch: 5| Step: 6
Training loss: 3.2547793825450793
Validation loss: 2.8258691589554257

Epoch: 5| Step: 7
Training loss: 3.3035933033576117
Validation loss: 2.7880633526881478

Epoch: 5| Step: 8
Training loss: 2.505408159456497
Validation loss: 2.778743318971856

Epoch: 5| Step: 9
Training loss: 3.624018306003845
Validation loss: 2.7632848944314343

Epoch: 5| Step: 10
Training loss: 2.8533518572529855
Validation loss: 2.728789844501351

Epoch: 95| Step: 0
Training loss: 2.531658563490007
Validation loss: 2.7278372833290097

Epoch: 5| Step: 1
Training loss: 2.901505566163207
Validation loss: 2.7252456038054795

Epoch: 5| Step: 2
Training loss: 3.5525727741215505
Validation loss: 2.706283746688134

Epoch: 5| Step: 3
Training loss: 3.003744490575163
Validation loss: 2.697153189524023

Epoch: 5| Step: 4
Training loss: 2.889867734951324
Validation loss: 2.7102988791394402

Epoch: 5| Step: 5
Training loss: 3.3356568980072194
Validation loss: 2.7398246385305747

Epoch: 5| Step: 6
Training loss: 2.7291896809391387
Validation loss: 2.7513236396302703

Epoch: 5| Step: 7
Training loss: 3.4797899673921537
Validation loss: 2.736350113738636

Epoch: 5| Step: 8
Training loss: 2.843887996469341
Validation loss: 2.7055682629599627

Epoch: 5| Step: 9
Training loss: 3.226559248730959
Validation loss: 2.688280517378906

Epoch: 5| Step: 10
Training loss: 2.861756713848648
Validation loss: 2.691730758735475

Epoch: 96| Step: 0
Training loss: 3.3071807762639236
Validation loss: 2.690564632997466

Epoch: 5| Step: 1
Training loss: 3.0839822103578536
Validation loss: 2.691060756285923

Epoch: 5| Step: 2
Training loss: 3.534359533409323
Validation loss: 2.6945599266682234

Epoch: 5| Step: 3
Training loss: 2.487811129487811
Validation loss: 2.6958097047143212

Epoch: 5| Step: 4
Training loss: 3.003393002875934
Validation loss: 2.697637998672437

Epoch: 5| Step: 5
Training loss: 3.025464544015065
Validation loss: 2.696026711686493

Epoch: 5| Step: 6
Training loss: 3.270297271795126
Validation loss: 2.697493731239309

Epoch: 5| Step: 7
Training loss: 2.534539240208415
Validation loss: 2.693990832829437

Epoch: 5| Step: 8
Training loss: 2.9890686194620937
Validation loss: 2.6903657145871334

Epoch: 5| Step: 9
Training loss: 3.5798107990158488
Validation loss: 2.6912245700492567

Epoch: 5| Step: 10
Training loss: 2.1526963071549647
Validation loss: 2.691046041604575

Epoch: 97| Step: 0
Training loss: 3.3336392421224366
Validation loss: 2.689514761408424

Epoch: 5| Step: 1
Training loss: 3.09944768723096
Validation loss: 2.688819814918167

Epoch: 5| Step: 2
Training loss: 2.946008089125664
Validation loss: 2.691279512172356

Epoch: 5| Step: 3
Training loss: 3.1967688042238356
Validation loss: 2.6862651232446395

Epoch: 5| Step: 4
Training loss: 2.7946067435134974
Validation loss: 2.6853228939618976

Epoch: 5| Step: 5
Training loss: 3.5135262561455995
Validation loss: 2.691235442919336

Epoch: 5| Step: 6
Training loss: 3.2583222573588837
Validation loss: 2.6912528685691215

Epoch: 5| Step: 7
Training loss: 2.9060252112957525
Validation loss: 2.6895759160034127

Epoch: 5| Step: 8
Training loss: 2.592259725768204
Validation loss: 2.694259825582502

Epoch: 5| Step: 9
Training loss: 2.9726294617818114
Validation loss: 2.700987416007442

Epoch: 5| Step: 10
Training loss: 2.3358474765131207
Validation loss: 2.7192750291113392

Epoch: 98| Step: 0
Training loss: 2.6269034795785187
Validation loss: 2.7253616979181228

Epoch: 5| Step: 1
Training loss: 2.9070659845538085
Validation loss: 2.706737953030576

Epoch: 5| Step: 2
Training loss: 2.808668705944109
Validation loss: 2.6831112985753744

Epoch: 5| Step: 3
Training loss: 3.3965405310912606
Validation loss: 2.6811605519890427

Epoch: 5| Step: 4
Training loss: 3.105923524581981
Validation loss: 2.6810875877081974

Epoch: 5| Step: 5
Training loss: 3.023370944135821
Validation loss: 2.676969629606032

Epoch: 5| Step: 6
Training loss: 3.6944262871419546
Validation loss: 2.680045156230081

Epoch: 5| Step: 7
Training loss: 2.154543214964352
Validation loss: 2.677914983723393

Epoch: 5| Step: 8
Training loss: 2.999869661678745
Validation loss: 2.677846225692359

Epoch: 5| Step: 9
Training loss: 3.2595925716591228
Validation loss: 2.6745271356222515

Epoch: 5| Step: 10
Training loss: 2.906330558726821
Validation loss: 2.6740722420169427

Epoch: 99| Step: 0
Training loss: 2.887342744318545
Validation loss: 2.677484697627352

Epoch: 5| Step: 1
Training loss: 3.2168151076726006
Validation loss: 2.6818854475472547

Epoch: 5| Step: 2
Training loss: 3.432982649686257
Validation loss: 2.689137108268606

Epoch: 5| Step: 3
Training loss: 3.1387984244964797
Validation loss: 2.683970005347365

Epoch: 5| Step: 4
Training loss: 2.577334751045217
Validation loss: 2.6786680817440027

Epoch: 5| Step: 5
Training loss: 3.044258911701199
Validation loss: 2.6935832493135803

Epoch: 5| Step: 6
Training loss: 2.920564571827319
Validation loss: 2.6784426707520836

Epoch: 5| Step: 7
Training loss: 2.8462173321993203
Validation loss: 2.683988638688206

Epoch: 5| Step: 8
Training loss: 2.6669059189120956
Validation loss: 2.680951222329154

Epoch: 5| Step: 9
Training loss: 2.7557050308923046
Validation loss: 2.676746673949293

Epoch: 5| Step: 10
Training loss: 3.5549304250355256
Validation loss: 2.673078543093017

Epoch: 100| Step: 0
Training loss: 3.3384264342387016
Validation loss: 2.669181836092983

Epoch: 5| Step: 1
Training loss: 2.521045318601711
Validation loss: 2.671025741196958

Epoch: 5| Step: 2
Training loss: 3.184625114523867
Validation loss: 2.6697811780346346

Epoch: 5| Step: 3
Training loss: 2.588814509318825
Validation loss: 2.6663828559045535

Epoch: 5| Step: 4
Training loss: 2.5417193318731757
Validation loss: 2.671142001672498

Epoch: 5| Step: 5
Training loss: 3.385511911470695
Validation loss: 2.666928026314741

Epoch: 5| Step: 6
Training loss: 3.1290173457278443
Validation loss: 2.6662330387038415

Epoch: 5| Step: 7
Training loss: 3.357392617764466
Validation loss: 2.6651845191958086

Epoch: 5| Step: 8
Training loss: 2.993105117690395
Validation loss: 2.666419469299571

Epoch: 5| Step: 9
Training loss: 2.9142701430398947
Validation loss: 2.663541553374803

Epoch: 5| Step: 10
Training loss: 2.9020903978629207
Validation loss: 2.667896858632468

Epoch: 101| Step: 0
Training loss: 3.187035620278172
Validation loss: 2.664615304183233

Epoch: 5| Step: 1
Training loss: 2.582861139355279
Validation loss: 2.6628142615915924

Epoch: 5| Step: 2
Training loss: 3.043975702647461
Validation loss: 2.66546616783308

Epoch: 5| Step: 3
Training loss: 3.6613518747812748
Validation loss: 2.660695609524252

Epoch: 5| Step: 4
Training loss: 2.6599038518293407
Validation loss: 2.664212701951524

Epoch: 5| Step: 5
Training loss: 3.003796559328948
Validation loss: 2.670692567921846

Epoch: 5| Step: 6
Training loss: 2.9579039965068628
Validation loss: 2.6718996914332744

Epoch: 5| Step: 7
Training loss: 2.912041257167773
Validation loss: 2.6721713051663594

Epoch: 5| Step: 8
Training loss: 2.711850586952945
Validation loss: 2.671792808716897

Epoch: 5| Step: 9
Training loss: 2.9529028107551434
Validation loss: 2.669475147142358

Epoch: 5| Step: 10
Training loss: 3.3904690333061747
Validation loss: 2.6700727295610966

Epoch: 102| Step: 0
Training loss: 2.9644799291967474
Validation loss: 2.6645513570839325

Epoch: 5| Step: 1
Training loss: 3.352158997991435
Validation loss: 2.6640021416227073

Epoch: 5| Step: 2
Training loss: 2.8715711962179746
Validation loss: 2.6634158006695463

Epoch: 5| Step: 3
Training loss: 2.929298476775632
Validation loss: 2.661069830843187

Epoch: 5| Step: 4
Training loss: 2.7792293623487176
Validation loss: 2.665098964524617

Epoch: 5| Step: 5
Training loss: 2.603393002346036
Validation loss: 2.668731566469199

Epoch: 5| Step: 6
Training loss: 3.1143472299212345
Validation loss: 2.677055034740856

Epoch: 5| Step: 7
Training loss: 3.001735344298273
Validation loss: 2.6851688795718722

Epoch: 5| Step: 8
Training loss: 3.26229761891746
Validation loss: 2.6767827864371454

Epoch: 5| Step: 9
Training loss: 3.271595293129015
Validation loss: 2.6764816805765874

Epoch: 5| Step: 10
Training loss: 2.680630531865658
Validation loss: 2.6659736623687857

Epoch: 103| Step: 0
Training loss: 2.62035522062158
Validation loss: 2.6646393365043557

Epoch: 5| Step: 1
Training loss: 3.0091099702587063
Validation loss: 2.667076454926993

Epoch: 5| Step: 2
Training loss: 2.9462443934093114
Validation loss: 2.6631289265655114

Epoch: 5| Step: 3
Training loss: 3.002643691919672
Validation loss: 2.670743643126104

Epoch: 5| Step: 4
Training loss: 3.5227339691366946
Validation loss: 2.679057487026778

Epoch: 5| Step: 5
Training loss: 3.136689258403545
Validation loss: 2.6779869804561796

Epoch: 5| Step: 6
Training loss: 2.814479046820686
Validation loss: 2.6772782318760395

Epoch: 5| Step: 7
Training loss: 2.912479737829364
Validation loss: 2.6782243213287003

Epoch: 5| Step: 8
Training loss: 3.3217484544279734
Validation loss: 2.6745375741000177

Epoch: 5| Step: 9
Training loss: 2.6957729664980796
Validation loss: 2.6802013790267294

Epoch: 5| Step: 10
Training loss: 2.759598367189211
Validation loss: 2.675063198946583

Epoch: 104| Step: 0
Training loss: 2.457249375502658
Validation loss: 2.6618390065227744

Epoch: 5| Step: 1
Training loss: 3.0655141516815996
Validation loss: 2.660619348499682

Epoch: 5| Step: 2
Training loss: 2.67205461935651
Validation loss: 2.6557855893789437

Epoch: 5| Step: 3
Training loss: 3.069020394961947
Validation loss: 2.6627927766401074

Epoch: 5| Step: 4
Training loss: 2.9797237560064818
Validation loss: 2.663137406468297

Epoch: 5| Step: 5
Training loss: 3.0006379402897068
Validation loss: 2.6648915940078837

Epoch: 5| Step: 6
Training loss: 2.8248881157518633
Validation loss: 2.6649052419463755

Epoch: 5| Step: 7
Training loss: 3.1490108450699505
Validation loss: 2.6705709289107245

Epoch: 5| Step: 8
Training loss: 3.1741700536967388
Validation loss: 2.661225697511774

Epoch: 5| Step: 9
Training loss: 3.092317191590041
Validation loss: 2.6584624831902794

Epoch: 5| Step: 10
Training loss: 3.5048892068153568
Validation loss: 2.6582441494434765

Epoch: 105| Step: 0
Training loss: 2.8933625326426506
Validation loss: 2.6577970069108194

Epoch: 5| Step: 1
Training loss: 3.498953254032035
Validation loss: 2.6553033955282066

Epoch: 5| Step: 2
Training loss: 3.2588875366733
Validation loss: 2.656166618722635

Epoch: 5| Step: 3
Training loss: 3.336073289738527
Validation loss: 2.654447525234202

Epoch: 5| Step: 4
Training loss: 3.370376245340607
Validation loss: 2.6513904551853855

Epoch: 5| Step: 5
Training loss: 2.539417511989987
Validation loss: 2.6579704807630917

Epoch: 5| Step: 6
Training loss: 2.877377397856817
Validation loss: 2.6584858903196227

Epoch: 5| Step: 7
Training loss: 2.5509463106410037
Validation loss: 2.6710694739575516

Epoch: 5| Step: 8
Training loss: 2.922303193891977
Validation loss: 2.674824548226382

Epoch: 5| Step: 9
Training loss: 2.6635844677134397
Validation loss: 2.7030861988278585

Epoch: 5| Step: 10
Training loss: 2.7414328903508403
Validation loss: 2.693633602575827

Epoch: 106| Step: 0
Training loss: 3.6039666945414144
Validation loss: 2.7313689619362433

Epoch: 5| Step: 1
Training loss: 2.335351366485105
Validation loss: 2.7072345356808896

Epoch: 5| Step: 2
Training loss: 3.73741964298479
Validation loss: 2.686171414809528

Epoch: 5| Step: 3
Training loss: 2.771391895947607
Validation loss: 2.68108973340732

Epoch: 5| Step: 4
Training loss: 3.289718888630294
Validation loss: 2.675746828460671

Epoch: 5| Step: 5
Training loss: 2.6702407389775664
Validation loss: 2.6531872227093714

Epoch: 5| Step: 6
Training loss: 3.07966784234356
Validation loss: 2.6478959543637606

Epoch: 5| Step: 7
Training loss: 2.988206570758033
Validation loss: 2.6425713302105005

Epoch: 5| Step: 8
Training loss: 2.7551002024516853
Validation loss: 2.64411061771279

Epoch: 5| Step: 9
Training loss: 2.4991550925167965
Validation loss: 2.644743692979248

Epoch: 5| Step: 10
Training loss: 2.8966417533526
Validation loss: 2.6475866123779026

Epoch: 107| Step: 0
Training loss: 3.16270391236557
Validation loss: 2.646230872373305

Epoch: 5| Step: 1
Training loss: 3.310786685866228
Validation loss: 2.6433902258394317

Epoch: 5| Step: 2
Training loss: 2.6044931944540144
Validation loss: 2.6470112664223193

Epoch: 5| Step: 3
Training loss: 3.026999885964872
Validation loss: 2.644272745563553

Epoch: 5| Step: 4
Training loss: 2.6421230964774707
Validation loss: 2.6400522201969294

Epoch: 5| Step: 5
Training loss: 3.25564525062618
Validation loss: 2.642654505031792

Epoch: 5| Step: 6
Training loss: 3.301675925809101
Validation loss: 2.6598609147328025

Epoch: 5| Step: 7
Training loss: 3.127160813000542
Validation loss: 2.7043974754596847

Epoch: 5| Step: 8
Training loss: 2.7849509657099336
Validation loss: 2.7254395976204666

Epoch: 5| Step: 9
Training loss: 2.9013712962252125
Validation loss: 2.705906586455511

Epoch: 5| Step: 10
Training loss: 2.543158973810044
Validation loss: 2.6869024369325305

Epoch: 108| Step: 0
Training loss: 3.144759763387561
Validation loss: 2.6722038818393563

Epoch: 5| Step: 1
Training loss: 2.740364794846078
Validation loss: 2.668300997557671

Epoch: 5| Step: 2
Training loss: 3.1891276373932493
Validation loss: 2.657325589594611

Epoch: 5| Step: 3
Training loss: 3.264353381353197
Validation loss: 2.64161586744333

Epoch: 5| Step: 4
Training loss: 2.4846962775016714
Validation loss: 2.6381120932717526

Epoch: 5| Step: 5
Training loss: 3.08052782490155
Validation loss: 2.6440507996412435

Epoch: 5| Step: 6
Training loss: 2.466321595859486
Validation loss: 2.6374157342988163

Epoch: 5| Step: 7
Training loss: 2.922587098846123
Validation loss: 2.6366874412825942

Epoch: 5| Step: 8
Training loss: 2.093248335677856
Validation loss: 2.6407095612880767

Epoch: 5| Step: 9
Training loss: 3.5824237970312285
Validation loss: 2.642688501017418

Epoch: 5| Step: 10
Training loss: 3.414484971223827
Validation loss: 2.6409535139049884

Epoch: 109| Step: 0
Training loss: 2.6493339709258916
Validation loss: 2.6327025054996014

Epoch: 5| Step: 1
Training loss: 2.8693162878598506
Validation loss: 2.6347824900450343

Epoch: 5| Step: 2
Training loss: 3.14396042470315
Validation loss: 2.637989517069928

Epoch: 5| Step: 3
Training loss: 3.3041544455021237
Validation loss: 2.6337298539294944

Epoch: 5| Step: 4
Training loss: 2.826873924091547
Validation loss: 2.635368342509608

Epoch: 5| Step: 5
Training loss: 2.7920211358185787
Validation loss: 2.638291228301487

Epoch: 5| Step: 6
Training loss: 2.520649317390701
Validation loss: 2.6410523736407785

Epoch: 5| Step: 7
Training loss: 2.8932161831614525
Validation loss: 2.6391069048717766

Epoch: 5| Step: 8
Training loss: 2.988795656296639
Validation loss: 2.6445952217012185

Epoch: 5| Step: 9
Training loss: 2.9493286920732857
Validation loss: 2.6500191251157887

Epoch: 5| Step: 10
Training loss: 3.705732755286203
Validation loss: 2.659428189544179

Epoch: 110| Step: 0
Training loss: 2.8846599996002054
Validation loss: 2.6441436263925575

Epoch: 5| Step: 1
Training loss: 2.7854078267503346
Validation loss: 2.6301386949565067

Epoch: 5| Step: 2
Training loss: 3.2339279676730057
Validation loss: 2.6297897241300072

Epoch: 5| Step: 3
Training loss: 2.977587906238854
Validation loss: 2.625653466349614

Epoch: 5| Step: 4
Training loss: 3.336514639679541
Validation loss: 2.629202149852831

Epoch: 5| Step: 5
Training loss: 2.919733415218311
Validation loss: 2.630733000430443

Epoch: 5| Step: 6
Training loss: 3.376516919620556
Validation loss: 2.6281846559148114

Epoch: 5| Step: 7
Training loss: 2.9163480493811766
Validation loss: 2.625302000003796

Epoch: 5| Step: 8
Training loss: 2.6485824320249045
Validation loss: 2.625568816576071

Epoch: 5| Step: 9
Training loss: 2.57220166937149
Validation loss: 2.6243287442664274

Epoch: 5| Step: 10
Training loss: 2.9915499892013546
Validation loss: 2.6292054894452623

Epoch: 111| Step: 0
Training loss: 2.8656470710794673
Validation loss: 2.630070969779623

Epoch: 5| Step: 1
Training loss: 2.773034036866984
Validation loss: 2.646327102420408

Epoch: 5| Step: 2
Training loss: 3.4875197652714713
Validation loss: 2.6741383897769118

Epoch: 5| Step: 3
Training loss: 3.1774696657186987
Validation loss: 2.7272337288770157

Epoch: 5| Step: 4
Training loss: 2.7454998301997677
Validation loss: 2.7203362108860953

Epoch: 5| Step: 5
Training loss: 3.492483651321583
Validation loss: 2.681142095965653

Epoch: 5| Step: 6
Training loss: 3.326640053020224
Validation loss: 2.634474729039107

Epoch: 5| Step: 7
Training loss: 2.505886776448001
Validation loss: 2.6228220958645143

Epoch: 5| Step: 8
Training loss: 2.9149927694711932
Validation loss: 2.627792386943414

Epoch: 5| Step: 9
Training loss: 2.7831311668329386
Validation loss: 2.631478860230372

Epoch: 5| Step: 10
Training loss: 2.4371662400452316
Validation loss: 2.6382982508037855

Epoch: 112| Step: 0
Training loss: 2.814558420322789
Validation loss: 2.651790541571012

Epoch: 5| Step: 1
Training loss: 2.889680945396312
Validation loss: 2.665557567875155

Epoch: 5| Step: 2
Training loss: 2.7985612272155787
Validation loss: 2.654753497124075

Epoch: 5| Step: 3
Training loss: 3.5017480572103925
Validation loss: 2.6454757220732996

Epoch: 5| Step: 4
Training loss: 3.3013093604890082
Validation loss: 2.6402808553286157

Epoch: 5| Step: 5
Training loss: 2.7043336139824414
Validation loss: 2.6381890078194297

Epoch: 5| Step: 6
Training loss: 2.728042594303063
Validation loss: 2.6357930806419136

Epoch: 5| Step: 7
Training loss: 3.199261675536199
Validation loss: 2.635455568541964

Epoch: 5| Step: 8
Training loss: 2.259246265336952
Validation loss: 2.63410950623015

Epoch: 5| Step: 9
Training loss: 3.2474980627557795
Validation loss: 2.633939598004996

Epoch: 5| Step: 10
Training loss: 3.4076144784013707
Validation loss: 2.6344915998387752

Epoch: 113| Step: 0
Training loss: 2.838447069930815
Validation loss: 2.633589006782047

Epoch: 5| Step: 1
Training loss: 3.5942342680680794
Validation loss: 2.631710409589702

Epoch: 5| Step: 2
Training loss: 2.3003609083876144
Validation loss: 2.6282237064535545

Epoch: 5| Step: 3
Training loss: 3.290230659121358
Validation loss: 2.6283679330493883

Epoch: 5| Step: 4
Training loss: 2.259438955158967
Validation loss: 2.626511534624958

Epoch: 5| Step: 5
Training loss: 3.2412641934085173
Validation loss: 2.6266198783076464

Epoch: 5| Step: 6
Training loss: 2.933908742763527
Validation loss: 2.6246519429320796

Epoch: 5| Step: 7
Training loss: 2.6901643542597333
Validation loss: 2.6252421381188324

Epoch: 5| Step: 8
Training loss: 3.5332087932686704
Validation loss: 2.6224792680963254

Epoch: 5| Step: 9
Training loss: 2.929418444676559
Validation loss: 2.6262546935472493

Epoch: 5| Step: 10
Training loss: 2.8949858891434763
Validation loss: 2.6214389652241943

Epoch: 114| Step: 0
Training loss: 2.4501418909518526
Validation loss: 2.615701877793601

Epoch: 5| Step: 1
Training loss: 3.173874098224729
Validation loss: 2.6194801247259782

Epoch: 5| Step: 2
Training loss: 2.5788042503046174
Validation loss: 2.616961915859968

Epoch: 5| Step: 3
Training loss: 3.104607535850571
Validation loss: 2.620515938083836

Epoch: 5| Step: 4
Training loss: 3.453849060648168
Validation loss: 2.6219869256698

Epoch: 5| Step: 5
Training loss: 3.2284357207576497
Validation loss: 2.6250322967902

Epoch: 5| Step: 6
Training loss: 3.314463914933454
Validation loss: 2.628530094633446

Epoch: 5| Step: 7
Training loss: 2.408228073547776
Validation loss: 2.627538739588509

Epoch: 5| Step: 8
Training loss: 3.0395818036192996
Validation loss: 2.6227746956567137

Epoch: 5| Step: 9
Training loss: 2.7656489656778533
Validation loss: 2.624797097336986

Epoch: 5| Step: 10
Training loss: 2.9050705680220554
Validation loss: 2.6336698584861273

Epoch: 115| Step: 0
Training loss: 3.3580018541741037
Validation loss: 2.646105624305059

Epoch: 5| Step: 1
Training loss: 3.1725070868518936
Validation loss: 2.65170336367101

Epoch: 5| Step: 2
Training loss: 2.325938279524517
Validation loss: 2.6377267696200244

Epoch: 5| Step: 3
Training loss: 2.575667070814894
Validation loss: 2.64264801020051

Epoch: 5| Step: 4
Training loss: 3.0209475967019097
Validation loss: 2.6307428964258492

Epoch: 5| Step: 5
Training loss: 2.984221609277912
Validation loss: 2.616790558208791

Epoch: 5| Step: 6
Training loss: 2.20615508656139
Validation loss: 2.614811296619871

Epoch: 5| Step: 7
Training loss: 3.4078704059478775
Validation loss: 2.610843626601107

Epoch: 5| Step: 8
Training loss: 2.905994527109326
Validation loss: 2.606520059374317

Epoch: 5| Step: 9
Training loss: 2.9985879117880936
Validation loss: 2.608894726900428

Epoch: 5| Step: 10
Training loss: 3.202825020490105
Validation loss: 2.601142622524112

Epoch: 116| Step: 0
Training loss: 2.388110265579034
Validation loss: 2.6194002580831945

Epoch: 5| Step: 1
Training loss: 3.5081093711375764
Validation loss: 2.62349894158015

Epoch: 5| Step: 2
Training loss: 2.217135096892455
Validation loss: 2.6350379103258565

Epoch: 5| Step: 3
Training loss: 2.676043109193034
Validation loss: 2.6377757360805116

Epoch: 5| Step: 4
Training loss: 2.81370569452681
Validation loss: 2.656594151708576

Epoch: 5| Step: 5
Training loss: 2.895403896480573
Validation loss: 2.66462275664084

Epoch: 5| Step: 6
Training loss: 3.171174070586778
Validation loss: 2.6397416210643763

Epoch: 5| Step: 7
Training loss: 2.8008259406574374
Validation loss: 2.6278610361672943

Epoch: 5| Step: 8
Training loss: 3.2273165581397296
Validation loss: 2.6168862064260665

Epoch: 5| Step: 9
Training loss: 3.3210798745593464
Validation loss: 2.6022394874841983

Epoch: 5| Step: 10
Training loss: 3.1233366544930448
Validation loss: 2.5964520648930134

Epoch: 117| Step: 0
Training loss: 2.8653663443641113
Validation loss: 2.5983066260013277

Epoch: 5| Step: 1
Training loss: 2.891785095017713
Validation loss: 2.599033058139999

Epoch: 5| Step: 2
Training loss: 2.5976834173861314
Validation loss: 2.595633357605242

Epoch: 5| Step: 3
Training loss: 2.7952018293688092
Validation loss: 2.600204803787184

Epoch: 5| Step: 4
Training loss: 2.4214699683366203
Validation loss: 2.5979435774992887

Epoch: 5| Step: 5
Training loss: 3.6466682277399474
Validation loss: 2.6110276688206224

Epoch: 5| Step: 6
Training loss: 3.0989684203595464
Validation loss: 2.622957327485511

Epoch: 5| Step: 7
Training loss: 3.0388442404855383
Validation loss: 2.62877650186746

Epoch: 5| Step: 8
Training loss: 2.8348494194717118
Validation loss: 2.6126146950685394

Epoch: 5| Step: 9
Training loss: 3.301726040127372
Validation loss: 2.6052353642757238

Epoch: 5| Step: 10
Training loss: 2.6789887076008516
Validation loss: 2.61014954933059

Epoch: 118| Step: 0
Training loss: 2.9830578199071467
Validation loss: 2.601667453361375

Epoch: 5| Step: 1
Training loss: 2.7414015814762362
Validation loss: 2.5966037589092545

Epoch: 5| Step: 2
Training loss: 3.2708010013869426
Validation loss: 2.591792396186502

Epoch: 5| Step: 3
Training loss: 2.982738745343553
Validation loss: 2.5992616688543895

Epoch: 5| Step: 4
Training loss: 2.9759458368663907
Validation loss: 2.5966296518487737

Epoch: 5| Step: 5
Training loss: 2.7734500508628863
Validation loss: 2.5975286064581002

Epoch: 5| Step: 6
Training loss: 3.1725434599560742
Validation loss: 2.604469396571591

Epoch: 5| Step: 7
Training loss: 2.4212088376289636
Validation loss: 2.6012335566890883

Epoch: 5| Step: 8
Training loss: 2.515748299366974
Validation loss: 2.6131042050657736

Epoch: 5| Step: 9
Training loss: 2.8206382838045654
Validation loss: 2.618496862910192

Epoch: 5| Step: 10
Training loss: 3.5616569190694483
Validation loss: 2.606968935185122

Epoch: 119| Step: 0
Training loss: 3.0365569860399084
Validation loss: 2.609623154017278

Epoch: 5| Step: 1
Training loss: 3.0221567521608383
Validation loss: 2.5926937260884912

Epoch: 5| Step: 2
Training loss: 2.74906229157711
Validation loss: 2.589832530649064

Epoch: 5| Step: 3
Training loss: 2.571525681645016
Validation loss: 2.5897158203838284

Epoch: 5| Step: 4
Training loss: 3.4183423344942936
Validation loss: 2.588122518980481

Epoch: 5| Step: 5
Training loss: 3.1547130203915272
Validation loss: 2.594351489088609

Epoch: 5| Step: 6
Training loss: 2.5855622264165996
Validation loss: 2.5951842113406447

Epoch: 5| Step: 7
Training loss: 3.247635935228215
Validation loss: 2.616224648307972

Epoch: 5| Step: 8
Training loss: 2.6083362819017153
Validation loss: 2.6230025986169223

Epoch: 5| Step: 9
Training loss: 2.6675304762181695
Validation loss: 2.6664989005916673

Epoch: 5| Step: 10
Training loss: 2.9924450158443285
Validation loss: 2.738510357477329

Epoch: 120| Step: 0
Training loss: 2.5893552385589422
Validation loss: 2.7241010404793604

Epoch: 5| Step: 1
Training loss: 3.082265634653496
Validation loss: 2.6455415470020767

Epoch: 5| Step: 2
Training loss: 3.246907156380256
Validation loss: 2.6109683658077913

Epoch: 5| Step: 3
Training loss: 2.4995343728369996
Validation loss: 2.588524434322462

Epoch: 5| Step: 4
Training loss: 2.814582816424394
Validation loss: 2.5881716146635383

Epoch: 5| Step: 5
Training loss: 3.353378266424695
Validation loss: 2.5907503987709193

Epoch: 5| Step: 6
Training loss: 3.0664319079838167
Validation loss: 2.5882992769096935

Epoch: 5| Step: 7
Training loss: 3.1933184606515046
Validation loss: 2.5888347192857806

Epoch: 5| Step: 8
Training loss: 3.2224795761230625
Validation loss: 2.5849127577302746

Epoch: 5| Step: 9
Training loss: 2.3353455472854185
Validation loss: 2.5890181574907385

Epoch: 5| Step: 10
Training loss: 2.9431485997337523
Validation loss: 2.5915499540201066

Epoch: 121| Step: 0
Training loss: 2.9557380216804767
Validation loss: 2.586033164190734

Epoch: 5| Step: 1
Training loss: 2.6109890086345535
Validation loss: 2.5842430601556883

Epoch: 5| Step: 2
Training loss: 2.874969316401736
Validation loss: 2.5848930343118837

Epoch: 5| Step: 3
Training loss: 2.8729886192364575
Validation loss: 2.5885138282476476

Epoch: 5| Step: 4
Training loss: 3.2336935163887395
Validation loss: 2.5856594165056603

Epoch: 5| Step: 5
Training loss: 2.715803720368005
Validation loss: 2.5918262244891417

Epoch: 5| Step: 6
Training loss: 2.816117566851496
Validation loss: 2.5923897529183217

Epoch: 5| Step: 7
Training loss: 3.03039444323134
Validation loss: 2.593722335760809

Epoch: 5| Step: 8
Training loss: 2.8995745708561396
Validation loss: 2.601800984203308

Epoch: 5| Step: 9
Training loss: 2.9602718359901585
Validation loss: 2.6303653088226335

Epoch: 5| Step: 10
Training loss: 3.180430632409448
Validation loss: 2.6606013021044603

Epoch: 122| Step: 0
Training loss: 2.732292472169277
Validation loss: 2.696707567944462

Epoch: 5| Step: 1
Training loss: 3.186630728876768
Validation loss: 2.6881707077843418

Epoch: 5| Step: 2
Training loss: 3.2184499952631356
Validation loss: 2.6896698899420106

Epoch: 5| Step: 3
Training loss: 3.0947361154791024
Validation loss: 2.642358526295314

Epoch: 5| Step: 4
Training loss: 3.630053319408078
Validation loss: 2.5870207695635057

Epoch: 5| Step: 5
Training loss: 2.0449449597998575
Validation loss: 2.5807299040844676

Epoch: 5| Step: 6
Training loss: 2.9378317787618022
Validation loss: 2.5842738812797386

Epoch: 5| Step: 7
Training loss: 2.7457570375562277
Validation loss: 2.60121257034445

Epoch: 5| Step: 8
Training loss: 3.0822903871077014
Validation loss: 2.6045714266022144

Epoch: 5| Step: 9
Training loss: 2.958372106880085
Validation loss: 2.6254671397011693

Epoch: 5| Step: 10
Training loss: 2.8816555772093273
Validation loss: 2.599750464583318

Epoch: 123| Step: 0
Training loss: 3.0772787567116486
Validation loss: 2.594634037757241

Epoch: 5| Step: 1
Training loss: 3.0082820377221027
Validation loss: 2.593598447469708

Epoch: 5| Step: 2
Training loss: 2.4112362412633153
Validation loss: 2.5889163264950588

Epoch: 5| Step: 3
Training loss: 2.591938903182718
Validation loss: 2.58703757028761

Epoch: 5| Step: 4
Training loss: 3.3035514447995964
Validation loss: 2.5858607840769268

Epoch: 5| Step: 5
Training loss: 2.686381706179367
Validation loss: 2.5878326665850806

Epoch: 5| Step: 6
Training loss: 2.6129060712561083
Validation loss: 2.5877559791065425

Epoch: 5| Step: 7
Training loss: 2.960500236976381
Validation loss: 2.6285812424966832

Epoch: 5| Step: 8
Training loss: 3.2855292617639593
Validation loss: 2.645944871231762

Epoch: 5| Step: 9
Training loss: 3.649044141632574
Validation loss: 2.6539987684037865

Epoch: 5| Step: 10
Training loss: 2.5382961583895827
Validation loss: 2.62058537662409

Epoch: 124| Step: 0
Training loss: 2.92114150688512
Validation loss: 2.5958669399936323

Epoch: 5| Step: 1
Training loss: 2.6226260940595294
Validation loss: 2.5838062046771344

Epoch: 5| Step: 2
Training loss: 2.854023412371857
Validation loss: 2.5861111190959383

Epoch: 5| Step: 3
Training loss: 3.2497984016688264
Validation loss: 2.5878787146348587

Epoch: 5| Step: 4
Training loss: 3.0569117416703913
Validation loss: 2.5805897952236894

Epoch: 5| Step: 5
Training loss: 3.003856723014988
Validation loss: 2.5909140608671946

Epoch: 5| Step: 6
Training loss: 2.7570947680313793
Validation loss: 2.581915908820509

Epoch: 5| Step: 7
Training loss: 3.2258947388042167
Validation loss: 2.5858237032042304

Epoch: 5| Step: 8
Training loss: 3.1222680929788194
Validation loss: 2.584743476770838

Epoch: 5| Step: 9
Training loss: 2.922490672152916
Validation loss: 2.5859669853858946

Epoch: 5| Step: 10
Training loss: 2.5390272871656823
Validation loss: 2.592160003078545

Epoch: 125| Step: 0
Training loss: 3.173667213469009
Validation loss: 2.5795246380855366

Epoch: 5| Step: 1
Training loss: 2.643018371495088
Validation loss: 2.577035724904015

Epoch: 5| Step: 2
Training loss: 3.2878240215330603
Validation loss: 2.5914703622677986

Epoch: 5| Step: 3
Training loss: 2.9494383067074383
Validation loss: 2.6042708804700143

Epoch: 5| Step: 4
Training loss: 3.213338803277432
Validation loss: 2.6137516385575466

Epoch: 5| Step: 5
Training loss: 2.5609705012245043
Validation loss: 2.613536002486493

Epoch: 5| Step: 6
Training loss: 3.1913796543988218
Validation loss: 2.602744693193943

Epoch: 5| Step: 7
Training loss: 2.8717626506094733
Validation loss: 2.6118351474971795

Epoch: 5| Step: 8
Training loss: 2.4132843244785573
Validation loss: 2.6032323218570332

Epoch: 5| Step: 9
Training loss: 2.8291866775576557
Validation loss: 2.603408839719376

Epoch: 5| Step: 10
Training loss: 2.9169428195102625
Validation loss: 2.6124296091437844

Epoch: 126| Step: 0
Training loss: 2.5207708576962125
Validation loss: 2.6033519170936374

Epoch: 5| Step: 1
Training loss: 3.055825726288363
Validation loss: 2.601227743920249

Epoch: 5| Step: 2
Training loss: 3.4412786349689344
Validation loss: 2.5922412964369963

Epoch: 5| Step: 3
Training loss: 3.127433287277225
Validation loss: 2.586527682545629

Epoch: 5| Step: 4
Training loss: 2.9624171120681204
Validation loss: 2.5815902277965437

Epoch: 5| Step: 5
Training loss: 2.366993509029873
Validation loss: 2.577528856848231

Epoch: 5| Step: 6
Training loss: 3.0991287483780723
Validation loss: 2.576798919282617

Epoch: 5| Step: 7
Training loss: 2.5623101885207547
Validation loss: 2.5678459136778913

Epoch: 5| Step: 8
Training loss: 2.859101162498008
Validation loss: 2.5702385334306532

Epoch: 5| Step: 9
Training loss: 2.7161703916312967
Validation loss: 2.5728488993072256

Epoch: 5| Step: 10
Training loss: 3.166664692392905
Validation loss: 2.569491234792793

Epoch: 127| Step: 0
Training loss: 3.1864951550710092
Validation loss: 2.578804262234056

Epoch: 5| Step: 1
Training loss: 2.6338864634844943
Validation loss: 2.5832854232420783

Epoch: 5| Step: 2
Training loss: 2.7748432733765305
Validation loss: 2.5765173967830823

Epoch: 5| Step: 3
Training loss: 2.5819792634055942
Validation loss: 2.5773451882717784

Epoch: 5| Step: 4
Training loss: 3.238719142117537
Validation loss: 2.5717026671774463

Epoch: 5| Step: 5
Training loss: 2.6828533189497623
Validation loss: 2.5806542204754264

Epoch: 5| Step: 6
Training loss: 2.85141751691574
Validation loss: 2.5805704738912296

Epoch: 5| Step: 7
Training loss: 3.2706998243033922
Validation loss: 2.58785285202386

Epoch: 5| Step: 8
Training loss: 2.890957045171015
Validation loss: 2.596300200076753

Epoch: 5| Step: 9
Training loss: 2.9197879620212257
Validation loss: 2.6012999177199365

Epoch: 5| Step: 10
Training loss: 2.887419041411053
Validation loss: 2.5998490254227256

Epoch: 128| Step: 0
Training loss: 2.8249914186060376
Validation loss: 2.6046135290536028

Epoch: 5| Step: 1
Training loss: 2.586016696973387
Validation loss: 2.5830108594795993

Epoch: 5| Step: 2
Training loss: 3.449925247709393
Validation loss: 2.5885072480818994

Epoch: 5| Step: 3
Training loss: 2.746736844595243
Validation loss: 2.5778592188649445

Epoch: 5| Step: 4
Training loss: 3.1596564615600418
Validation loss: 2.5646594423102393

Epoch: 5| Step: 5
Training loss: 2.784217879703411
Validation loss: 2.562074850586126

Epoch: 5| Step: 6
Training loss: 3.0971762440399653
Validation loss: 2.5582752812687986

Epoch: 5| Step: 7
Training loss: 2.6367482275551333
Validation loss: 2.5608982249270125

Epoch: 5| Step: 8
Training loss: 3.3058727835232626
Validation loss: 2.5628675051718854

Epoch: 5| Step: 9
Training loss: 3.034920426760006
Validation loss: 2.557522481231859

Epoch: 5| Step: 10
Training loss: 1.7488516036777968
Validation loss: 2.5697074891480254

Epoch: 129| Step: 0
Training loss: 2.8820846176273283
Validation loss: 2.5829417090303886

Epoch: 5| Step: 1
Training loss: 2.9968166946292354
Validation loss: 2.598889233678795

Epoch: 5| Step: 2
Training loss: 3.266613824248287
Validation loss: 2.6159810787054902

Epoch: 5| Step: 3
Training loss: 3.155285074017153
Validation loss: 2.6119915416348602

Epoch: 5| Step: 4
Training loss: 2.4649468595336304
Validation loss: 2.6136545122278423

Epoch: 5| Step: 5
Training loss: 2.5538172741663256
Validation loss: 2.6005281930206072

Epoch: 5| Step: 6
Training loss: 2.56313278944929
Validation loss: 2.6010189279943394

Epoch: 5| Step: 7
Training loss: 2.7573099083627897
Validation loss: 2.592552837867697

Epoch: 5| Step: 8
Training loss: 3.0639521989903424
Validation loss: 2.5771861405656025

Epoch: 5| Step: 9
Training loss: 2.7244515978342596
Validation loss: 2.566447343339814

Epoch: 5| Step: 10
Training loss: 3.4100587881172264
Validation loss: 2.5629389737288353

Epoch: 130| Step: 0
Training loss: 3.12890625
Validation loss: 2.5578630132983933

Epoch: 5| Step: 1
Training loss: 2.8216773452902215
Validation loss: 2.5539394835354616

Epoch: 5| Step: 2
Training loss: 2.4343948147987104
Validation loss: 2.5595328427349786

Epoch: 5| Step: 3
Training loss: 3.0759765562992096
Validation loss: 2.5616748820982083

Epoch: 5| Step: 4
Training loss: 3.2357407786843524
Validation loss: 2.5613835351434413

Epoch: 5| Step: 5
Training loss: 2.984392575516801
Validation loss: 2.570472958386143

Epoch: 5| Step: 6
Training loss: 2.6977897427625424
Validation loss: 2.571678569844495

Epoch: 5| Step: 7
Training loss: 3.0509741181232606
Validation loss: 2.582131823053159

Epoch: 5| Step: 8
Training loss: 2.8640693527114727
Validation loss: 2.60277176314413

Epoch: 5| Step: 9
Training loss: 2.812669960820536
Validation loss: 2.6043718817464594

Epoch: 5| Step: 10
Training loss: 2.4173029905912773
Validation loss: 2.6055598391794397

Epoch: 131| Step: 0
Training loss: 2.7423719903773005
Validation loss: 2.60701009225574

Epoch: 5| Step: 1
Training loss: 2.80008832587848
Validation loss: 2.562360070922819

Epoch: 5| Step: 2
Training loss: 3.342467730643859
Validation loss: 2.5513991670428307

Epoch: 5| Step: 3
Training loss: 2.5447174482001564
Validation loss: 2.5517079750120417

Epoch: 5| Step: 4
Training loss: 2.6433873822946867
Validation loss: 2.547432605976998

Epoch: 5| Step: 5
Training loss: 3.302668827428356
Validation loss: 2.5536849637648737

Epoch: 5| Step: 6
Training loss: 3.0806501071531374
Validation loss: 2.5548783423854475

Epoch: 5| Step: 7
Training loss: 2.4931976280239065
Validation loss: 2.5458845614302756

Epoch: 5| Step: 8
Training loss: 2.9088598858610033
Validation loss: 2.5460275014646974

Epoch: 5| Step: 9
Training loss: 3.0656644081748095
Validation loss: 2.5476426251725375

Epoch: 5| Step: 10
Training loss: 2.907097969632517
Validation loss: 2.5493704028851716

Epoch: 132| Step: 0
Training loss: 2.631569226397579
Validation loss: 2.560938815026243

Epoch: 5| Step: 1
Training loss: 3.182430349638127
Validation loss: 2.592444343152601

Epoch: 5| Step: 2
Training loss: 3.0070319413828286
Validation loss: 2.6048481830028574

Epoch: 5| Step: 3
Training loss: 2.6663176983743986
Validation loss: 2.620043924425784

Epoch: 5| Step: 4
Training loss: 3.1574617080601644
Validation loss: 2.6203989654948043

Epoch: 5| Step: 5
Training loss: 2.712009976332103
Validation loss: 2.618002855966903

Epoch: 5| Step: 6
Training loss: 2.9932430785859077
Validation loss: 2.602017837128761

Epoch: 5| Step: 7
Training loss: 2.631312727010585
Validation loss: 2.570085823902332

Epoch: 5| Step: 8
Training loss: 3.128388513218304
Validation loss: 2.565286612353383

Epoch: 5| Step: 9
Training loss: 2.2624593783783733
Validation loss: 2.5551984254185025

Epoch: 5| Step: 10
Training loss: 3.2122504527023152
Validation loss: 2.5493143894805965

Epoch: 133| Step: 0
Training loss: 3.0469541881736752
Validation loss: 2.55407354031887

Epoch: 5| Step: 1
Training loss: 2.607054083669578
Validation loss: 2.554632245436158

Epoch: 5| Step: 2
Training loss: 3.236910945370867
Validation loss: 2.551053691608171

Epoch: 5| Step: 3
Training loss: 2.9164607020725306
Validation loss: 2.5538037051365916

Epoch: 5| Step: 4
Training loss: 3.0803222559499335
Validation loss: 2.55313477110084

Epoch: 5| Step: 5
Training loss: 2.764983280538328
Validation loss: 2.558727778350038

Epoch: 5| Step: 6
Training loss: 2.3770869271476607
Validation loss: 2.559440620305643

Epoch: 5| Step: 7
Training loss: 3.163209701335658
Validation loss: 2.573746247599928

Epoch: 5| Step: 8
Training loss: 3.1325348614505675
Validation loss: 2.570053969788109

Epoch: 5| Step: 9
Training loss: 2.9070041457370714
Validation loss: 2.5681016045034544

Epoch: 5| Step: 10
Training loss: 2.3338197019575264
Validation loss: 2.554166920096541

Epoch: 134| Step: 0
Training loss: 3.1465562069896538
Validation loss: 2.551579960964757

Epoch: 5| Step: 1
Training loss: 3.4930799739145106
Validation loss: 2.554222302158021

Epoch: 5| Step: 2
Training loss: 2.482209803588972
Validation loss: 2.5567638805859225

Epoch: 5| Step: 3
Training loss: 2.3193210320244724
Validation loss: 2.560634381107524

Epoch: 5| Step: 4
Training loss: 2.8369609572823755
Validation loss: 2.5627908619125095

Epoch: 5| Step: 5
Training loss: 3.540490003606451
Validation loss: 2.5686884541627713

Epoch: 5| Step: 6
Training loss: 2.799062289167377
Validation loss: 2.550091374718774

Epoch: 5| Step: 7
Training loss: 2.70846840937323
Validation loss: 2.55734556391234

Epoch: 5| Step: 8
Training loss: 2.979165848596278
Validation loss: 2.5507009589978726

Epoch: 5| Step: 9
Training loss: 2.443275261154588
Validation loss: 2.549901688176765

Epoch: 5| Step: 10
Training loss: 2.5499096910529273
Validation loss: 2.5472193931214115

Epoch: 135| Step: 0
Training loss: 2.549542393483233
Validation loss: 2.5483561183312933

Epoch: 5| Step: 1
Training loss: 2.651780081225087
Validation loss: 2.5473454907307134

Epoch: 5| Step: 2
Training loss: 3.384709555309541
Validation loss: 2.540247108385285

Epoch: 5| Step: 3
Training loss: 2.8753658559463338
Validation loss: 2.552513758960841

Epoch: 5| Step: 4
Training loss: 3.1819913049143898
Validation loss: 2.5507253530077274

Epoch: 5| Step: 5
Training loss: 3.022735119833574
Validation loss: 2.5522952572944186

Epoch: 5| Step: 6
Training loss: 3.0971934873638336
Validation loss: 2.546109133003095

Epoch: 5| Step: 7
Training loss: 2.6592582273564904
Validation loss: 2.5561177620048636

Epoch: 5| Step: 8
Training loss: 2.8121367325891358
Validation loss: 2.554139033893789

Epoch: 5| Step: 9
Training loss: 2.6684805740755824
Validation loss: 2.5720147896271923

Epoch: 5| Step: 10
Training loss: 2.528631857857288
Validation loss: 2.5922072302620207

Epoch: 136| Step: 0
Training loss: 2.729239999111072
Validation loss: 2.6182658594643446

Epoch: 5| Step: 1
Training loss: 2.400236269129363
Validation loss: 2.620468453115411

Epoch: 5| Step: 2
Training loss: 2.7147213256456966
Validation loss: 2.618159565145644

Epoch: 5| Step: 3
Training loss: 2.8182400091937105
Validation loss: 2.621683639271577

Epoch: 5| Step: 4
Training loss: 3.3101896470244085
Validation loss: 2.5926775454089745

Epoch: 5| Step: 5
Training loss: 3.261866400569026
Validation loss: 2.5856711050872834

Epoch: 5| Step: 6
Training loss: 2.931480245758858
Validation loss: 2.5580529904066767

Epoch: 5| Step: 7
Training loss: 2.3581569129367734
Validation loss: 2.54942877614916

Epoch: 5| Step: 8
Training loss: 2.9727159210913117
Validation loss: 2.543760172465389

Epoch: 5| Step: 9
Training loss: 2.954108826179086
Validation loss: 2.5413484385913874

Epoch: 5| Step: 10
Training loss: 2.95714057911745
Validation loss: 2.541693624928085

Epoch: 137| Step: 0
Training loss: 2.555273706217023
Validation loss: 2.5447755282527678

Epoch: 5| Step: 1
Training loss: 3.38051888675771
Validation loss: 2.5385969807077253

Epoch: 5| Step: 2
Training loss: 2.743961119295706
Validation loss: 2.540495055946034

Epoch: 5| Step: 3
Training loss: 2.39803606581749
Validation loss: 2.5377295976940197

Epoch: 5| Step: 4
Training loss: 3.0259983149370644
Validation loss: 2.543197767450064

Epoch: 5| Step: 5
Training loss: 3.1103970942016654
Validation loss: 2.5518526493274423

Epoch: 5| Step: 6
Training loss: 2.391444844804025
Validation loss: 2.5779140929325464

Epoch: 5| Step: 7
Training loss: 2.808542816167156
Validation loss: 2.594551218669539

Epoch: 5| Step: 8
Training loss: 3.242902488463478
Validation loss: 2.6253325988496314

Epoch: 5| Step: 9
Training loss: 2.944497397884308
Validation loss: 2.620214725890902

Epoch: 5| Step: 10
Training loss: 2.9241037283474984
Validation loss: 2.6003524783119545

Epoch: 138| Step: 0
Training loss: 2.242655954370909
Validation loss: 2.592324938934434

Epoch: 5| Step: 1
Training loss: 2.7134973054995144
Validation loss: 2.5746645438023017

Epoch: 5| Step: 2
Training loss: 2.674638178232796
Validation loss: 2.565304590747376

Epoch: 5| Step: 3
Training loss: 2.3076804172992045
Validation loss: 2.566881192645297

Epoch: 5| Step: 4
Training loss: 3.2154614583978294
Validation loss: 2.574805504780804

Epoch: 5| Step: 5
Training loss: 2.515058275916505
Validation loss: 2.5548406081354695

Epoch: 5| Step: 6
Training loss: 2.9984314314645144
Validation loss: 2.559199414791227

Epoch: 5| Step: 7
Training loss: 3.2361557338477733
Validation loss: 2.551023495674567

Epoch: 5| Step: 8
Training loss: 3.0469228887462543
Validation loss: 2.545489425219442

Epoch: 5| Step: 9
Training loss: 3.180729875595208
Validation loss: 2.5475523975328587

Epoch: 5| Step: 10
Training loss: 3.082147593653247
Validation loss: 2.5498769102683747

Epoch: 139| Step: 0
Training loss: 2.449275111959896
Validation loss: 2.5383466793484004

Epoch: 5| Step: 1
Training loss: 2.87338974681211
Validation loss: 2.5263120167644613

Epoch: 5| Step: 2
Training loss: 3.231608511480338
Validation loss: 2.5302382472377896

Epoch: 5| Step: 3
Training loss: 2.4228082642997326
Validation loss: 2.5340234604029934

Epoch: 5| Step: 4
Training loss: 2.999404371260472
Validation loss: 2.5286937776793827

Epoch: 5| Step: 5
Training loss: 2.183316289917718
Validation loss: 2.5256187444364593

Epoch: 5| Step: 6
Training loss: 2.7739932940566367
Validation loss: 2.536440135651918

Epoch: 5| Step: 7
Training loss: 2.9972475458756027
Validation loss: 2.5422742014314483

Epoch: 5| Step: 8
Training loss: 2.9762241441548047
Validation loss: 2.5473384811665776

Epoch: 5| Step: 9
Training loss: 3.446506561481135
Validation loss: 2.536685376452896

Epoch: 5| Step: 10
Training loss: 2.8408313907054534
Validation loss: 2.538473624701602

Epoch: 140| Step: 0
Training loss: 2.8095574986944936
Validation loss: 2.5361370863548314

Epoch: 5| Step: 1
Training loss: 2.9709040807688334
Validation loss: 2.531767029334577

Epoch: 5| Step: 2
Training loss: 2.777506934843153
Validation loss: 2.5372651281668794

Epoch: 5| Step: 3
Training loss: 2.588786235797019
Validation loss: 2.53618222522151

Epoch: 5| Step: 4
Training loss: 2.493585750362153
Validation loss: 2.556401083742436

Epoch: 5| Step: 5
Training loss: 2.9901160497694512
Validation loss: 2.5695836272748727

Epoch: 5| Step: 6
Training loss: 2.181694392102667
Validation loss: 2.545303372166488

Epoch: 5| Step: 7
Training loss: 2.993625066455915
Validation loss: 2.5506304250155316

Epoch: 5| Step: 8
Training loss: 3.186223092218087
Validation loss: 2.536364472743863

Epoch: 5| Step: 9
Training loss: 3.0806561437461624
Validation loss: 2.52806648079076

Epoch: 5| Step: 10
Training loss: 3.132857857468567
Validation loss: 2.529559359936606

Epoch: 141| Step: 0
Training loss: 3.0002466736151985
Validation loss: 2.5200435940731287

Epoch: 5| Step: 1
Training loss: 2.781464900597456
Validation loss: 2.523735483676312

Epoch: 5| Step: 2
Training loss: 2.646024972378277
Validation loss: 2.518189177330445

Epoch: 5| Step: 3
Training loss: 2.873215660671341
Validation loss: 2.5373851501799787

Epoch: 5| Step: 4
Training loss: 2.7393137771410943
Validation loss: 2.55700036803644

Epoch: 5| Step: 5
Training loss: 3.127459969268192
Validation loss: 2.5621410411586005

Epoch: 5| Step: 6
Training loss: 2.8506282582397175
Validation loss: 2.557354099858318

Epoch: 5| Step: 7
Training loss: 2.9877227061750795
Validation loss: 2.551552703587231

Epoch: 5| Step: 8
Training loss: 2.7011768178280877
Validation loss: 2.547727659405499

Epoch: 5| Step: 9
Training loss: 2.7002071442439695
Validation loss: 2.535527305916714

Epoch: 5| Step: 10
Training loss: 2.8621106012007744
Validation loss: 2.5332005504314523

Epoch: 142| Step: 0
Training loss: 3.2218382010962263
Validation loss: 2.5298522792993317

Epoch: 5| Step: 1
Training loss: 2.4142511287930297
Validation loss: 2.5366212428211337

Epoch: 5| Step: 2
Training loss: 3.3319639890082624
Validation loss: 2.525675484329799

Epoch: 5| Step: 3
Training loss: 2.746302806987244
Validation loss: 2.522848945703855

Epoch: 5| Step: 4
Training loss: 2.848700605284768
Validation loss: 2.5174506636548784

Epoch: 5| Step: 5
Training loss: 2.7815178731439754
Validation loss: 2.5165626843477145

Epoch: 5| Step: 6
Training loss: 2.750348849277962
Validation loss: 2.517809404101653

Epoch: 5| Step: 7
Training loss: 2.9024234314116746
Validation loss: 2.517106746108661

Epoch: 5| Step: 8
Training loss: 2.7884670444707367
Validation loss: 2.5154411510132757

Epoch: 5| Step: 9
Training loss: 2.5327021824829323
Validation loss: 2.5209112281598673

Epoch: 5| Step: 10
Training loss: 2.994475682492197
Validation loss: 2.5552438987614314

Epoch: 143| Step: 0
Training loss: 3.001435413281468
Validation loss: 2.542888731523171

Epoch: 5| Step: 1
Training loss: 2.4324874200132975
Validation loss: 2.5348948614087856

Epoch: 5| Step: 2
Training loss: 3.3506693327934
Validation loss: 2.5434146346096624

Epoch: 5| Step: 3
Training loss: 2.985591301044086
Validation loss: 2.5605759949761366

Epoch: 5| Step: 4
Training loss: 2.9768852799786907
Validation loss: 2.5457609905860563

Epoch: 5| Step: 5
Training loss: 2.9864502726511395
Validation loss: 2.5476170112044993

Epoch: 5| Step: 6
Training loss: 2.87112281421301
Validation loss: 2.5410353711908806

Epoch: 5| Step: 7
Training loss: 2.9105550403145095
Validation loss: 2.558834120935061

Epoch: 5| Step: 8
Training loss: 2.5631459980318256
Validation loss: 2.5505951316624835

Epoch: 5| Step: 9
Training loss: 2.70172894540396
Validation loss: 2.547097053563817

Epoch: 5| Step: 10
Training loss: 2.252897833643201
Validation loss: 2.5313112430514066

Epoch: 144| Step: 0
Training loss: 2.6020123433634725
Validation loss: 2.51747332994074

Epoch: 5| Step: 1
Training loss: 3.0727267104236073
Validation loss: 2.5221546249085547

Epoch: 5| Step: 2
Training loss: 2.8325167956616033
Validation loss: 2.5175225722475774

Epoch: 5| Step: 3
Training loss: 2.7303295618471384
Validation loss: 2.5203859492753202

Epoch: 5| Step: 4
Training loss: 3.181728898071417
Validation loss: 2.520782347810754

Epoch: 5| Step: 5
Training loss: 2.4194108794500107
Validation loss: 2.5401309931906524

Epoch: 5| Step: 6
Training loss: 2.094311766914987
Validation loss: 2.527169045522512

Epoch: 5| Step: 7
Training loss: 2.895192429862412
Validation loss: 2.5278887493537967

Epoch: 5| Step: 8
Training loss: 3.3504437622396623
Validation loss: 2.525719521095426

Epoch: 5| Step: 9
Training loss: 3.031262899155061
Validation loss: 2.520595380318278

Epoch: 5| Step: 10
Training loss: 2.8606384487723586
Validation loss: 2.5207740297378467

Epoch: 145| Step: 0
Training loss: 2.7197118351261937
Validation loss: 2.528315356210385

Epoch: 5| Step: 1
Training loss: 3.562891085390141
Validation loss: 2.518995077678875

Epoch: 5| Step: 2
Training loss: 2.963813130170127
Validation loss: 2.5262534898993203

Epoch: 5| Step: 3
Training loss: 3.1790143924374137
Validation loss: 2.524266603978622

Epoch: 5| Step: 4
Training loss: 2.3734585628617118
Validation loss: 2.5115755119723078

Epoch: 5| Step: 5
Training loss: 2.809647788105617
Validation loss: 2.5193432015872697

Epoch: 5| Step: 6
Training loss: 3.196448686053897
Validation loss: 2.5123340397396228

Epoch: 5| Step: 7
Training loss: 2.29468946213439
Validation loss: 2.5186371799416185

Epoch: 5| Step: 8
Training loss: 2.6238776941289697
Validation loss: 2.534929817124434

Epoch: 5| Step: 9
Training loss: 2.650142064874971
Validation loss: 2.5628669380007785

Epoch: 5| Step: 10
Training loss: 2.4537394537677217
Validation loss: 2.569777660128107

Epoch: 146| Step: 0
Training loss: 2.3575940010043666
Validation loss: 2.610895920212499

Epoch: 5| Step: 1
Training loss: 3.0744616401625593
Validation loss: 2.6395080780874207

Epoch: 5| Step: 2
Training loss: 3.237331200400482
Validation loss: 2.6147154313137126

Epoch: 5| Step: 3
Training loss: 3.2283058906088566
Validation loss: 2.580697495913002

Epoch: 5| Step: 4
Training loss: 2.891586061466388
Validation loss: 2.5260388547583355

Epoch: 5| Step: 5
Training loss: 3.019619998392576
Validation loss: 2.511287283113296

Epoch: 5| Step: 6
Training loss: 2.1787393893816813
Validation loss: 2.51805359598802

Epoch: 5| Step: 7
Training loss: 3.0650288008912687
Validation loss: 2.5227521872943193

Epoch: 5| Step: 8
Training loss: 3.2969533901929053
Validation loss: 2.527069107812454

Epoch: 5| Step: 9
Training loss: 2.3594291630268955
Validation loss: 2.5327960748729432

Epoch: 5| Step: 10
Training loss: 2.468181206572026
Validation loss: 2.533120580641091

Epoch: 147| Step: 0
Training loss: 3.0916366294642423
Validation loss: 2.5377098182039264

Epoch: 5| Step: 1
Training loss: 2.251194848587606
Validation loss: 2.5325439743180844

Epoch: 5| Step: 2
Training loss: 2.6428312756955243
Validation loss: 2.525049860581899

Epoch: 5| Step: 3
Training loss: 2.6848114227336097
Validation loss: 2.51187335763485

Epoch: 5| Step: 4
Training loss: 2.790913541941077
Validation loss: 2.5197312066073763

Epoch: 5| Step: 5
Training loss: 2.307101365989726
Validation loss: 2.5221185707094125

Epoch: 5| Step: 6
Training loss: 3.05763824075513
Validation loss: 2.5302841549714037

Epoch: 5| Step: 7
Training loss: 3.154878374950448
Validation loss: 2.5564839233375696

Epoch: 5| Step: 8
Training loss: 2.9800353128785937
Validation loss: 2.6090512157401116

Epoch: 5| Step: 9
Training loss: 2.7433370153403187
Validation loss: 2.6425808646417663

Epoch: 5| Step: 10
Training loss: 3.597505812756241
Validation loss: 2.672576807329402

Epoch: 148| Step: 0
Training loss: 2.916813183692019
Validation loss: 2.6422032911689493

Epoch: 5| Step: 1
Training loss: 2.770507468276327
Validation loss: 2.6010242622149953

Epoch: 5| Step: 2
Training loss: 2.7596158191493463
Validation loss: 2.5344675170330917

Epoch: 5| Step: 3
Training loss: 3.041186847901269
Validation loss: 2.5236933433820092

Epoch: 5| Step: 4
Training loss: 3.0515346793426676
Validation loss: 2.514024781322652

Epoch: 5| Step: 5
Training loss: 2.8587672520539367
Validation loss: 2.512844466181225

Epoch: 5| Step: 6
Training loss: 2.501458886768844
Validation loss: 2.5137853176377085

Epoch: 5| Step: 7
Training loss: 2.8075595272611746
Validation loss: 2.5146648623325034

Epoch: 5| Step: 8
Training loss: 2.9404606610063295
Validation loss: 2.5112525924435416

Epoch: 5| Step: 9
Training loss: 2.863369512303513
Validation loss: 2.515106476897717

Epoch: 5| Step: 10
Training loss: 2.9207328971395357
Validation loss: 2.539497818526183

Epoch: 149| Step: 0
Training loss: 2.618787407437183
Validation loss: 2.5685730987028235

Epoch: 5| Step: 1
Training loss: 2.8782068694458354
Validation loss: 2.5758911010655607

Epoch: 5| Step: 2
Training loss: 3.361202293048927
Validation loss: 2.6120694363378103

Epoch: 5| Step: 3
Training loss: 3.226019936080793
Validation loss: 2.6156635674953783

Epoch: 5| Step: 4
Training loss: 2.904383890866092
Validation loss: 2.590962669283187

Epoch: 5| Step: 5
Training loss: 2.526900050557804
Validation loss: 2.539350047650619

Epoch: 5| Step: 6
Training loss: 2.79920955808697
Validation loss: 2.5118444303464957

Epoch: 5| Step: 7
Training loss: 3.057036372394204
Validation loss: 2.5073162379198077

Epoch: 5| Step: 8
Training loss: 2.7915346958983944
Validation loss: 2.506670878334419

Epoch: 5| Step: 9
Training loss: 2.3820740603024646
Validation loss: 2.5006886702725413

Epoch: 5| Step: 10
Training loss: 2.7528041068044513
Validation loss: 2.501274835963489

Epoch: 150| Step: 0
Training loss: 2.8172116126765068
Validation loss: 2.4996776393486893

Epoch: 5| Step: 1
Training loss: 2.7315724861181563
Validation loss: 2.5033614427709834

Epoch: 5| Step: 2
Training loss: 2.5520650953821917
Validation loss: 2.5130147576942727

Epoch: 5| Step: 3
Training loss: 2.6441725877883293
Validation loss: 2.5225396943598155

Epoch: 5| Step: 4
Training loss: 2.925723229356277
Validation loss: 2.521463757891342

Epoch: 5| Step: 5
Training loss: 2.873738883031421
Validation loss: 2.529058117370169

Epoch: 5| Step: 6
Training loss: 2.6717042031827174
Validation loss: 2.537992968083204

Epoch: 5| Step: 7
Training loss: 2.6913356467233838
Validation loss: 2.538623288568584

Epoch: 5| Step: 8
Training loss: 3.206240743582825
Validation loss: 2.534386500823631

Epoch: 5| Step: 9
Training loss: 2.8316833703362505
Validation loss: 2.529077535236113

Epoch: 5| Step: 10
Training loss: 3.0303250504184938
Validation loss: 2.5257154447959738

Epoch: 151| Step: 0
Training loss: 2.5411109525258584
Validation loss: 2.523937181329949

Epoch: 5| Step: 1
Training loss: 2.2387764001905257
Validation loss: 2.524726869716895

Epoch: 5| Step: 2
Training loss: 2.8047768411247125
Validation loss: 2.524782169521912

Epoch: 5| Step: 3
Training loss: 2.7911812564295957
Validation loss: 2.511883725980605

Epoch: 5| Step: 4
Training loss: 3.458437462276997
Validation loss: 2.5126150380079384

Epoch: 5| Step: 5
Training loss: 2.988343800407442
Validation loss: 2.5168540060422946

Epoch: 5| Step: 6
Training loss: 2.944401040946902
Validation loss: 2.5288111357872576

Epoch: 5| Step: 7
Training loss: 2.96098677863429
Validation loss: 2.5368485757079595

Epoch: 5| Step: 8
Training loss: 2.37186566377393
Validation loss: 2.5518270474786444

Epoch: 5| Step: 9
Training loss: 2.883251291184602
Validation loss: 2.5681669888948395

Epoch: 5| Step: 10
Training loss: 2.7973717615974834
Validation loss: 2.579356377088226

Epoch: 152| Step: 0
Training loss: 2.67830326372828
Validation loss: 2.543366271590456

Epoch: 5| Step: 1
Training loss: 3.1745488965223285
Validation loss: 2.517779397485742

Epoch: 5| Step: 2
Training loss: 2.8814437635561485
Validation loss: 2.5093077886690764

Epoch: 5| Step: 3
Training loss: 2.620459307821389
Validation loss: 2.508167222207777

Epoch: 5| Step: 4
Training loss: 2.4941121385780245
Validation loss: 2.50709971772526

Epoch: 5| Step: 5
Training loss: 2.781417070149915
Validation loss: 2.5080384812093355

Epoch: 5| Step: 6
Training loss: 2.732688689003616
Validation loss: 2.507308774943832

Epoch: 5| Step: 7
Training loss: 2.5904728052139867
Validation loss: 2.5080513094047303

Epoch: 5| Step: 8
Training loss: 2.3430221444685952
Validation loss: 2.500760868123988

Epoch: 5| Step: 9
Training loss: 3.300778938608658
Validation loss: 2.5080974223922006

Epoch: 5| Step: 10
Training loss: 3.219833191762561
Validation loss: 2.5081851771637442

Epoch: 153| Step: 0
Training loss: 3.00021313863837
Validation loss: 2.541369356397318

Epoch: 5| Step: 1
Training loss: 3.3491895406991836
Validation loss: 2.548297173220781

Epoch: 5| Step: 2
Training loss: 2.8943548110129296
Validation loss: 2.54273865833302

Epoch: 5| Step: 3
Training loss: 2.78328878705893
Validation loss: 2.5800975980690857

Epoch: 5| Step: 4
Training loss: 2.2883568414905446
Validation loss: 2.5765976524155243

Epoch: 5| Step: 5
Training loss: 2.26299043261115
Validation loss: 2.575716415854771

Epoch: 5| Step: 6
Training loss: 3.2773460779193164
Validation loss: 2.5509596777960124

Epoch: 5| Step: 7
Training loss: 2.9089080796443727
Validation loss: 2.5393946892426396

Epoch: 5| Step: 8
Training loss: 2.4513433510426337
Validation loss: 2.51815533612751

Epoch: 5| Step: 9
Training loss: 2.6781991990626124
Validation loss: 2.505169232146704

Epoch: 5| Step: 10
Training loss: 2.752133582150002
Validation loss: 2.5104229034753476

Epoch: 154| Step: 0
Training loss: 2.6624055335250993
Validation loss: 2.5106709669376497

Epoch: 5| Step: 1
Training loss: 2.9382029564794117
Validation loss: 2.5202412253551802

Epoch: 5| Step: 2
Training loss: 2.707722189003116
Validation loss: 2.521983558932919

Epoch: 5| Step: 3
Training loss: 2.69167438383935
Validation loss: 2.512083030968192

Epoch: 5| Step: 4
Training loss: 2.9856767461715266
Validation loss: 2.5134416818960164

Epoch: 5| Step: 5
Training loss: 2.861485103949009
Validation loss: 2.5164916550014693

Epoch: 5| Step: 6
Training loss: 3.0521716906850025
Validation loss: 2.528139998397835

Epoch: 5| Step: 7
Training loss: 2.367639983086123
Validation loss: 2.571519112840418

Epoch: 5| Step: 8
Training loss: 2.424365725596646
Validation loss: 2.6379571515086027

Epoch: 5| Step: 9
Training loss: 3.201119292725175
Validation loss: 2.7450912382779764

Epoch: 5| Step: 10
Training loss: 3.1558166810764763
Validation loss: 2.799168963901678

Epoch: 155| Step: 0
Training loss: 3.3755400896614485
Validation loss: 2.7967547584874928

Epoch: 5| Step: 1
Training loss: 2.947781365370801
Validation loss: 2.666999433376816

Epoch: 5| Step: 2
Training loss: 2.784776573464635
Validation loss: 2.5713670376811346

Epoch: 5| Step: 3
Training loss: 2.661251610020356
Validation loss: 2.505776364707678

Epoch: 5| Step: 4
Training loss: 3.0582548029186833
Validation loss: 2.5015066098602436

Epoch: 5| Step: 5
Training loss: 1.867113247596073
Validation loss: 2.5102915708220626

Epoch: 5| Step: 6
Training loss: 3.173144307343593
Validation loss: 2.5205234576797824

Epoch: 5| Step: 7
Training loss: 3.0940767366131663
Validation loss: 2.5229131708254458

Epoch: 5| Step: 8
Training loss: 2.5758792227988443
Validation loss: 2.5284858275249986

Epoch: 5| Step: 9
Training loss: 3.345402389523142
Validation loss: 2.5198253025332322

Epoch: 5| Step: 10
Training loss: 2.578104469911155
Validation loss: 2.5075022898168013

Epoch: 156| Step: 0
Training loss: 2.683766455277845
Validation loss: 2.4997625781705715

Epoch: 5| Step: 1
Training loss: 3.204174930345241
Validation loss: 2.493698968703663

Epoch: 5| Step: 2
Training loss: 2.292406367362689
Validation loss: 2.4962887792176334

Epoch: 5| Step: 3
Training loss: 2.4833258566861174
Validation loss: 2.522757636703155

Epoch: 5| Step: 4
Training loss: 3.1571687173308276
Validation loss: 2.5455735262964025

Epoch: 5| Step: 5
Training loss: 2.2849736589044536
Validation loss: 2.550585096577676

Epoch: 5| Step: 6
Training loss: 3.071905678860745
Validation loss: 2.5703455926628895

Epoch: 5| Step: 7
Training loss: 3.03489198847568
Validation loss: 2.590170885457971

Epoch: 5| Step: 8
Training loss: 2.810499793977837
Validation loss: 2.6032791423552544

Epoch: 5| Step: 9
Training loss: 2.7530879976208613
Validation loss: 2.6218115901616295

Epoch: 5| Step: 10
Training loss: 2.9611540944134966
Validation loss: 2.5636883013072103

Epoch: 157| Step: 0
Training loss: 3.149457666849307
Validation loss: 2.5356100024474792

Epoch: 5| Step: 1
Training loss: 2.3119745430782315
Validation loss: 2.499759824557505

Epoch: 5| Step: 2
Training loss: 3.049681637517261
Validation loss: 2.4961007268158744

Epoch: 5| Step: 3
Training loss: 2.605778391223997
Validation loss: 2.504687005181165

Epoch: 5| Step: 4
Training loss: 3.0719820487074085
Validation loss: 2.5061372846739167

Epoch: 5| Step: 5
Training loss: 2.6724784125088696
Validation loss: 2.505420262342042

Epoch: 5| Step: 6
Training loss: 2.3565544801885916
Validation loss: 2.4979111137952072

Epoch: 5| Step: 7
Training loss: 3.0991136698966737
Validation loss: 2.5006844803834998

Epoch: 5| Step: 8
Training loss: 3.2138679293431993
Validation loss: 2.4957354463654697

Epoch: 5| Step: 9
Training loss: 2.575855898043
Validation loss: 2.496470650891165

Epoch: 5| Step: 10
Training loss: 2.856269525841013
Validation loss: 2.5049288349057153

Epoch: 158| Step: 0
Training loss: 2.835555458082133
Validation loss: 2.518319051616044

Epoch: 5| Step: 1
Training loss: 2.703173245567242
Validation loss: 2.545978801415263

Epoch: 5| Step: 2
Training loss: 2.394561817167001
Validation loss: 2.5921437893973027

Epoch: 5| Step: 3
Training loss: 3.255023595018318
Validation loss: 2.626844328563056

Epoch: 5| Step: 4
Training loss: 3.013140193297167
Validation loss: 2.591447954419368

Epoch: 5| Step: 5
Training loss: 2.3774834748826
Validation loss: 2.5756708311717196

Epoch: 5| Step: 6
Training loss: 2.8409846347821666
Validation loss: 2.545973999327471

Epoch: 5| Step: 7
Training loss: 2.9622997683045793
Validation loss: 2.5259696548459605

Epoch: 5| Step: 8
Training loss: 2.661035871227403
Validation loss: 2.522407864439335

Epoch: 5| Step: 9
Training loss: 3.1143943873901905
Validation loss: 2.5148763763697053

Epoch: 5| Step: 10
Training loss: 2.6232253842599906
Validation loss: 2.5091281021629004

Epoch: 159| Step: 0
Training loss: 3.0119128529579795
Validation loss: 2.517143907371501

Epoch: 5| Step: 1
Training loss: 2.8703891434505646
Validation loss: 2.508127718092448

Epoch: 5| Step: 2
Training loss: 2.5574255220041393
Validation loss: 2.504129472501744

Epoch: 5| Step: 3
Training loss: 2.921930322786336
Validation loss: 2.50663468528954

Epoch: 5| Step: 4
Training loss: 2.9407977808461414
Validation loss: 2.5257755609183494

Epoch: 5| Step: 5
Training loss: 3.106952586244107
Validation loss: 2.533800659754651

Epoch: 5| Step: 6
Training loss: 3.026384676710114
Validation loss: 2.5324283066737054

Epoch: 5| Step: 7
Training loss: 2.8227276803319183
Validation loss: 2.5448257674566124

Epoch: 5| Step: 8
Training loss: 2.583624874604628
Validation loss: 2.5598071405757374

Epoch: 5| Step: 9
Training loss: 2.624793907431217
Validation loss: 2.5317047117864377

Epoch: 5| Step: 10
Training loss: 1.9866914820027985
Validation loss: 2.514561723901938

Epoch: 160| Step: 0
Training loss: 2.833719526412259
Validation loss: 2.492332873696681

Epoch: 5| Step: 1
Training loss: 2.3111923232033256
Validation loss: 2.4984579180678423

Epoch: 5| Step: 2
Training loss: 2.485961503465049
Validation loss: 2.5033087031555348

Epoch: 5| Step: 3
Training loss: 3.1744674836784266
Validation loss: 2.5052174504542943

Epoch: 5| Step: 4
Training loss: 3.155384360476756
Validation loss: 2.511512506618772

Epoch: 5| Step: 5
Training loss: 2.7022969295066277
Validation loss: 2.5145614669834195

Epoch: 5| Step: 6
Training loss: 2.8402243756593166
Validation loss: 2.523094416795903

Epoch: 5| Step: 7
Training loss: 2.7850311807636783
Validation loss: 2.53425020187009

Epoch: 5| Step: 8
Training loss: 2.5113823221908866
Validation loss: 2.533649993620587

Epoch: 5| Step: 9
Training loss: 2.5684756872724375
Validation loss: 2.5219608970963323

Epoch: 5| Step: 10
Training loss: 3.128574006041618
Validation loss: 2.5091631205447524

Epoch: 161| Step: 0
Training loss: 2.490147248782223
Validation loss: 2.507340712521559

Epoch: 5| Step: 1
Training loss: 2.4483806630288822
Validation loss: 2.5013151596012895

Epoch: 5| Step: 2
Training loss: 3.285693837925565
Validation loss: 2.508044318813001

Epoch: 5| Step: 3
Training loss: 3.053496223613527
Validation loss: 2.510728536793449

Epoch: 5| Step: 4
Training loss: 2.548517364616428
Validation loss: 2.509100822960477

Epoch: 5| Step: 5
Training loss: 3.0858290254866896
Validation loss: 2.5187869161139074

Epoch: 5| Step: 6
Training loss: 2.568280654687146
Validation loss: 2.5434428440142964

Epoch: 5| Step: 7
Training loss: 2.6001562034928316
Validation loss: 2.561074090023531

Epoch: 5| Step: 8
Training loss: 3.1900265721855674
Validation loss: 2.5422789409279782

Epoch: 5| Step: 9
Training loss: 2.4067610160882222
Validation loss: 2.5486544405818425

Epoch: 5| Step: 10
Training loss: 2.9578250036363256
Validation loss: 2.526246466462609

Epoch: 162| Step: 0
Training loss: 2.7039127855682086
Validation loss: 2.507509955671457

Epoch: 5| Step: 1
Training loss: 3.116768639132191
Validation loss: 2.49617692207122

Epoch: 5| Step: 2
Training loss: 3.0048937619133462
Validation loss: 2.488692505043093

Epoch: 5| Step: 3
Training loss: 2.402945987299173
Validation loss: 2.4896775691775272

Epoch: 5| Step: 4
Training loss: 2.914417235027308
Validation loss: 2.487704398281198

Epoch: 5| Step: 5
Training loss: 2.6589479993403033
Validation loss: 2.4994438742364244

Epoch: 5| Step: 6
Training loss: 2.883866280343177
Validation loss: 2.508196534311011

Epoch: 5| Step: 7
Training loss: 3.213184173994815
Validation loss: 2.5131231345925245

Epoch: 5| Step: 8
Training loss: 2.2957440141402294
Validation loss: 2.5213598035321767

Epoch: 5| Step: 9
Training loss: 2.7815531019003403
Validation loss: 2.5351525276384663

Epoch: 5| Step: 10
Training loss: 2.2349231821124964
Validation loss: 2.542382626800162

Epoch: 163| Step: 0
Training loss: 2.8813562203974783
Validation loss: 2.547785920379775

Epoch: 5| Step: 1
Training loss: 3.090238022756901
Validation loss: 2.5387960395425786

Epoch: 5| Step: 2
Training loss: 2.818931685384162
Validation loss: 2.522800127461451

Epoch: 5| Step: 3
Training loss: 2.4253011772089046
Validation loss: 2.5138455676157045

Epoch: 5| Step: 4
Training loss: 2.9493031470746995
Validation loss: 2.5064103940650955

Epoch: 5| Step: 5
Training loss: 2.3867136554070525
Validation loss: 2.5037817828174713

Epoch: 5| Step: 6
Training loss: 2.228720706526822
Validation loss: 2.517440433310933

Epoch: 5| Step: 7
Training loss: 2.525427444083395
Validation loss: 2.512120691077378

Epoch: 5| Step: 8
Training loss: 3.200030362462005
Validation loss: 2.529258711458824

Epoch: 5| Step: 9
Training loss: 3.1430360260129744
Validation loss: 2.5234500599347323

Epoch: 5| Step: 10
Training loss: 2.488340847193962
Validation loss: 2.531615358128003

Epoch: 164| Step: 0
Training loss: 2.637561804603222
Validation loss: 2.520388804447239

Epoch: 5| Step: 1
Training loss: 2.996832924270015
Validation loss: 2.5322282299316585

Epoch: 5| Step: 2
Training loss: 2.5274662890200075
Validation loss: 2.5228440772339624

Epoch: 5| Step: 3
Training loss: 2.3215186070179823
Validation loss: 2.51627102837187

Epoch: 5| Step: 4
Training loss: 3.134214624959117
Validation loss: 2.5226959365127772

Epoch: 5| Step: 5
Training loss: 2.8996839285301386
Validation loss: 2.520145758943998

Epoch: 5| Step: 6
Training loss: 2.7169206098822305
Validation loss: 2.5049448905576113

Epoch: 5| Step: 7
Training loss: 3.2041505241896857
Validation loss: 2.499552898009556

Epoch: 5| Step: 8
Training loss: 2.4501421828760455
Validation loss: 2.50038293551386

Epoch: 5| Step: 9
Training loss: 2.671830918690187
Validation loss: 2.486693584218703

Epoch: 5| Step: 10
Training loss: 2.5783254834454055
Validation loss: 2.498879302489479

Epoch: 165| Step: 0
Training loss: 2.6436419886536004
Validation loss: 2.513134600507032

Epoch: 5| Step: 1
Training loss: 2.8587180461690647
Validation loss: 2.5005066819645156

Epoch: 5| Step: 2
Training loss: 2.3723432840054004
Validation loss: 2.5121344495359277

Epoch: 5| Step: 3
Training loss: 2.764082483852293
Validation loss: 2.5193440583919506

Epoch: 5| Step: 4
Training loss: 2.4676123786542816
Validation loss: 2.5217135635091594

Epoch: 5| Step: 5
Training loss: 2.919690626294417
Validation loss: 2.51883441267869

Epoch: 5| Step: 6
Training loss: 2.895931342865423
Validation loss: 2.5012350595113952

Epoch: 5| Step: 7
Training loss: 2.971082875033509
Validation loss: 2.495299452782248

Epoch: 5| Step: 8
Training loss: 2.709349241211264
Validation loss: 2.493790550620829

Epoch: 5| Step: 9
Training loss: 2.5265638513036546
Validation loss: 2.4864193010017934

Epoch: 5| Step: 10
Training loss: 3.136790501592178
Validation loss: 2.489257997878668

Epoch: 166| Step: 0
Training loss: 2.884043526330277
Validation loss: 2.4924693326766403

Epoch: 5| Step: 1
Training loss: 2.7755347690290884
Validation loss: 2.504049067762587

Epoch: 5| Step: 2
Training loss: 2.8884169934882125
Validation loss: 2.496290659618761

Epoch: 5| Step: 3
Training loss: 2.6498798954935245
Validation loss: 2.506867443408786

Epoch: 5| Step: 4
Training loss: 2.9888176729525204
Validation loss: 2.5169812847280943

Epoch: 5| Step: 5
Training loss: 2.5567674481531455
Validation loss: 2.5077390780463595

Epoch: 5| Step: 6
Training loss: 2.9210533578002664
Validation loss: 2.5108012964798836

Epoch: 5| Step: 7
Training loss: 2.7798300558055984
Validation loss: 2.509543653653647

Epoch: 5| Step: 8
Training loss: 2.393084488827443
Validation loss: 2.49560392323386

Epoch: 5| Step: 9
Training loss: 2.449775693317819
Validation loss: 2.4936477991775443

Epoch: 5| Step: 10
Training loss: 2.8921801533494955
Validation loss: 2.5013405282202665

Epoch: 167| Step: 0
Training loss: 2.5556074346814253
Validation loss: 2.5186076554842205

Epoch: 5| Step: 1
Training loss: 3.1814724647664927
Validation loss: 2.5156496577072556

Epoch: 5| Step: 2
Training loss: 2.5316894526541316
Validation loss: 2.5216562027608345

Epoch: 5| Step: 3
Training loss: 2.5586067024660224
Validation loss: 2.5062305622248746

Epoch: 5| Step: 4
Training loss: 2.042348968263383
Validation loss: 2.5032632265189623

Epoch: 5| Step: 5
Training loss: 3.081424706634295
Validation loss: 2.511035491795312

Epoch: 5| Step: 6
Training loss: 2.658190478449665
Validation loss: 2.5048442565193287

Epoch: 5| Step: 7
Training loss: 2.9447992418963373
Validation loss: 2.4957455438044844

Epoch: 5| Step: 8
Training loss: 2.839648464367391
Validation loss: 2.488276378804355

Epoch: 5| Step: 9
Training loss: 3.055570743022127
Validation loss: 2.4810276566158556

Epoch: 5| Step: 10
Training loss: 2.5123962153165285
Validation loss: 2.4834716562069783

Epoch: 168| Step: 0
Training loss: 1.9875254815345502
Validation loss: 2.485819982426054

Epoch: 5| Step: 1
Training loss: 2.7061244662376525
Validation loss: 2.487720857766015

Epoch: 5| Step: 2
Training loss: 2.9185978263705206
Validation loss: 2.490664978052342

Epoch: 5| Step: 3
Training loss: 2.781683898683462
Validation loss: 2.494142370314692

Epoch: 5| Step: 4
Training loss: 2.6790478001196485
Validation loss: 2.504019690728068

Epoch: 5| Step: 5
Training loss: 2.1712268987556613
Validation loss: 2.5146363209186506

Epoch: 5| Step: 6
Training loss: 2.6590527277578726
Validation loss: 2.53327358761797

Epoch: 5| Step: 7
Training loss: 3.0097223733001126
Validation loss: 2.5542106814393493

Epoch: 5| Step: 8
Training loss: 3.0385054443069555
Validation loss: 2.5508864213891314

Epoch: 5| Step: 9
Training loss: 3.0090381849762258
Validation loss: 2.529830973402631

Epoch: 5| Step: 10
Training loss: 3.0998438149761824
Validation loss: 2.5011715430718158

Epoch: 169| Step: 0
Training loss: 2.8350196382895314
Validation loss: 2.4847712016083094

Epoch: 5| Step: 1
Training loss: 2.4799670575630435
Validation loss: 2.4933338278675143

Epoch: 5| Step: 2
Training loss: 2.8935021180994993
Validation loss: 2.488330841278599

Epoch: 5| Step: 3
Training loss: 2.8780870863812362
Validation loss: 2.4877971231586353

Epoch: 5| Step: 4
Training loss: 2.9246242053559137
Validation loss: 2.478628204707556

Epoch: 5| Step: 5
Training loss: 2.6926470416906647
Validation loss: 2.488198300314192

Epoch: 5| Step: 6
Training loss: 2.4597431493819424
Validation loss: 2.5010315561412866

Epoch: 5| Step: 7
Training loss: 2.299671883605858
Validation loss: 2.5196370990277916

Epoch: 5| Step: 8
Training loss: 3.5113844325186854
Validation loss: 2.53492442978468

Epoch: 5| Step: 9
Training loss: 2.534288442993907
Validation loss: 2.5638708284156624

Epoch: 5| Step: 10
Training loss: 2.5385827183420653
Validation loss: 2.5694207895910806

Epoch: 170| Step: 0
Training loss: 3.345903505291752
Validation loss: 2.525398953245494

Epoch: 5| Step: 1
Training loss: 2.6184344153881742
Validation loss: 2.4861882860182987

Epoch: 5| Step: 2
Training loss: 2.7288507079667896
Validation loss: 2.472306159269349

Epoch: 5| Step: 3
Training loss: 3.021842910612002
Validation loss: 2.4731066979618155

Epoch: 5| Step: 4
Training loss: 2.489973657461029
Validation loss: 2.4661611282853753

Epoch: 5| Step: 5
Training loss: 2.8950409022259986
Validation loss: 2.4644296906557908

Epoch: 5| Step: 6
Training loss: 2.770706422428163
Validation loss: 2.465641999443102

Epoch: 5| Step: 7
Training loss: 2.3688503757437136
Validation loss: 2.462606009947889

Epoch: 5| Step: 8
Training loss: 2.4189461010041104
Validation loss: 2.4624124899019497

Epoch: 5| Step: 9
Training loss: 2.645680660939254
Validation loss: 2.4644319859821495

Epoch: 5| Step: 10
Training loss: 2.9576628198247894
Validation loss: 2.4751896887138205

Epoch: 171| Step: 0
Training loss: 3.1820894583949126
Validation loss: 2.4901478798740238

Epoch: 5| Step: 1
Training loss: 2.9734474362374215
Validation loss: 2.5053198847992455

Epoch: 5| Step: 2
Training loss: 2.7905977869362273
Validation loss: 2.5150590067663967

Epoch: 5| Step: 3
Training loss: 2.7787619616842623
Validation loss: 2.5187920428059103

Epoch: 5| Step: 4
Training loss: 3.0000669154015895
Validation loss: 2.5177604351972325

Epoch: 5| Step: 5
Training loss: 2.8375864830785678
Validation loss: 2.495960711238466

Epoch: 5| Step: 6
Training loss: 2.4628728129312285
Validation loss: 2.4882254006752897

Epoch: 5| Step: 7
Training loss: 2.363066961488298
Validation loss: 2.486116300181686

Epoch: 5| Step: 8
Training loss: 2.799165948896287
Validation loss: 2.4801232641650306

Epoch: 5| Step: 9
Training loss: 2.4279238073783977
Validation loss: 2.480406876912188

Epoch: 5| Step: 10
Training loss: 2.5053227980721933
Validation loss: 2.4829642279271606

Epoch: 172| Step: 0
Training loss: 3.2568231997033514
Validation loss: 2.4927389372098774

Epoch: 5| Step: 1
Training loss: 2.5374255728494273
Validation loss: 2.4913458516348035

Epoch: 5| Step: 2
Training loss: 2.7617640727639317
Validation loss: 2.515157113027301

Epoch: 5| Step: 3
Training loss: 2.817809793522392
Validation loss: 2.531137665231267

Epoch: 5| Step: 4
Training loss: 2.668621647984508
Validation loss: 2.519949402529879

Epoch: 5| Step: 5
Training loss: 2.2577663535711827
Validation loss: 2.5221417291917057

Epoch: 5| Step: 6
Training loss: 2.6943081518705925
Validation loss: 2.5094386242103117

Epoch: 5| Step: 7
Training loss: 2.8243751746369874
Validation loss: 2.5278926994376274

Epoch: 5| Step: 8
Training loss: 2.5802188577900633
Validation loss: 2.5275791500657054

Epoch: 5| Step: 9
Training loss: 3.111390500541967
Validation loss: 2.5244144803942152

Epoch: 5| Step: 10
Training loss: 2.489756387950012
Validation loss: 2.515813807308547

Epoch: 173| Step: 0
Training loss: 2.641731075701019
Validation loss: 2.5286323424751274

Epoch: 5| Step: 1
Training loss: 2.5863613922187416
Validation loss: 2.546934966465913

Epoch: 5| Step: 2
Training loss: 3.2479461635957287
Validation loss: 2.5511904700129926

Epoch: 5| Step: 3
Training loss: 2.5137484167578674
Validation loss: 2.5711678851595003

Epoch: 5| Step: 4
Training loss: 2.6259981709900275
Validation loss: 2.566722759016915

Epoch: 5| Step: 5
Training loss: 3.2433859207369946
Validation loss: 2.539590757080648

Epoch: 5| Step: 6
Training loss: 2.7135076734252648
Validation loss: 2.5181018842014478

Epoch: 5| Step: 7
Training loss: 2.400722049339493
Validation loss: 2.502221379837514

Epoch: 5| Step: 8
Training loss: 2.62369177780506
Validation loss: 2.4826062877520565

Epoch: 5| Step: 9
Training loss: 2.387606940945151
Validation loss: 2.482798214187783

Epoch: 5| Step: 10
Training loss: 3.124422859303035
Validation loss: 2.48836646141217

Epoch: 174| Step: 0
Training loss: 2.598809329076307
Validation loss: 2.4918919494545135

Epoch: 5| Step: 1
Training loss: 3.3714255725487035
Validation loss: 2.482682514063147

Epoch: 5| Step: 2
Training loss: 2.426839846293299
Validation loss: 2.4840768686928616

Epoch: 5| Step: 3
Training loss: 2.949625838522621
Validation loss: 2.47892135505323

Epoch: 5| Step: 4
Training loss: 2.650261624934985
Validation loss: 2.4789223002897898

Epoch: 5| Step: 5
Training loss: 2.4537488787935624
Validation loss: 2.470344421114475

Epoch: 5| Step: 6
Training loss: 2.336947015640781
Validation loss: 2.475630055463001

Epoch: 5| Step: 7
Training loss: 2.6852551333011934
Validation loss: 2.497841908497315

Epoch: 5| Step: 8
Training loss: 3.252493561980952
Validation loss: 2.51541188154548

Epoch: 5| Step: 9
Training loss: 2.3030737448052396
Validation loss: 2.506045004128333

Epoch: 5| Step: 10
Training loss: 2.8854027666291904
Validation loss: 2.514473258779421

Epoch: 175| Step: 0
Training loss: 2.2697110917342336
Validation loss: 2.521247474484939

Epoch: 5| Step: 1
Training loss: 2.578057860453901
Validation loss: 2.5020517974022165

Epoch: 5| Step: 2
Training loss: 3.017269338468851
Validation loss: 2.498639373297818

Epoch: 5| Step: 3
Training loss: 3.3942560538711164
Validation loss: 2.4950940674200544

Epoch: 5| Step: 4
Training loss: 2.2059386122766003
Validation loss: 2.491190063673651

Epoch: 5| Step: 5
Training loss: 2.614480876561588
Validation loss: 2.4947342277815117

Epoch: 5| Step: 6
Training loss: 2.5468252914352005
Validation loss: 2.491238251034839

Epoch: 5| Step: 7
Training loss: 2.837229704901678
Validation loss: 2.5019353266664566

Epoch: 5| Step: 8
Training loss: 3.0716701932139308
Validation loss: 2.522086548358674

Epoch: 5| Step: 9
Training loss: 2.435726792359735
Validation loss: 2.5188768347628785

Epoch: 5| Step: 10
Training loss: 2.869900866933029
Validation loss: 2.5000595936799317

Epoch: 176| Step: 0
Training loss: 2.3990304816513044
Validation loss: 2.496196419072145

Epoch: 5| Step: 1
Training loss: 2.799802643768874
Validation loss: 2.48708592933958

Epoch: 5| Step: 2
Training loss: 2.597722607675701
Validation loss: 2.4808390498499935

Epoch: 5| Step: 3
Training loss: 2.608136734139624
Validation loss: 2.484624950063168

Epoch: 5| Step: 4
Training loss: 2.776763640821106
Validation loss: 2.490074497135911

Epoch: 5| Step: 5
Training loss: 2.783574108361756
Validation loss: 2.474037033064151

Epoch: 5| Step: 6
Training loss: 2.3375459064728896
Validation loss: 2.4724916282381098

Epoch: 5| Step: 7
Training loss: 3.134965646607266
Validation loss: 2.474606149998681

Epoch: 5| Step: 8
Training loss: 2.9087821839981958
Validation loss: 2.474536532249456

Epoch: 5| Step: 9
Training loss: 2.6568425134769384
Validation loss: 2.4757992907780597

Epoch: 5| Step: 10
Training loss: 2.9961461108629464
Validation loss: 2.497808183690298

Epoch: 177| Step: 0
Training loss: 2.591050271168228
Validation loss: 2.5294521423338363

Epoch: 5| Step: 1
Training loss: 2.8279305069787384
Validation loss: 2.544179210767413

Epoch: 5| Step: 2
Training loss: 2.8237975506876
Validation loss: 2.5573565989854363

Epoch: 5| Step: 3
Training loss: 2.9424307813257164
Validation loss: 2.599008987337231

Epoch: 5| Step: 4
Training loss: 2.99297113341314
Validation loss: 2.611518636133778

Epoch: 5| Step: 5
Training loss: 3.3641547686958844
Validation loss: 2.579620093876057

Epoch: 5| Step: 6
Training loss: 2.421282886602796
Validation loss: 2.5235650775021163

Epoch: 5| Step: 7
Training loss: 2.781343694244549
Validation loss: 2.4947882204462077

Epoch: 5| Step: 8
Training loss: 2.4411024225009266
Validation loss: 2.47242007727978

Epoch: 5| Step: 9
Training loss: 2.155037801813716
Validation loss: 2.4676484755077257

Epoch: 5| Step: 10
Training loss: 2.4726323372165195
Validation loss: 2.4650013975304916

Epoch: 178| Step: 0
Training loss: 2.1985520322852885
Validation loss: 2.460433213977474

Epoch: 5| Step: 1
Training loss: 2.1905589922267086
Validation loss: 2.4662297901550674

Epoch: 5| Step: 2
Training loss: 2.605045770400464
Validation loss: 2.467558916524774

Epoch: 5| Step: 3
Training loss: 3.1946579092454472
Validation loss: 2.474065373970395

Epoch: 5| Step: 4
Training loss: 3.1092705637199742
Validation loss: 2.4911998378821076

Epoch: 5| Step: 5
Training loss: 2.8890863395932826
Validation loss: 2.504689314280304

Epoch: 5| Step: 6
Training loss: 2.7543347613756337
Validation loss: 2.513436898221858

Epoch: 5| Step: 7
Training loss: 3.1049351263717333
Validation loss: 2.5206545775970457

Epoch: 5| Step: 8
Training loss: 2.620270874202344
Validation loss: 2.523147994616122

Epoch: 5| Step: 9
Training loss: 2.4988490316241836
Validation loss: 2.527953010721228

Epoch: 5| Step: 10
Training loss: 2.449277934890965
Validation loss: 2.5302351286023224

Epoch: 179| Step: 0
Training loss: 3.088043961888995
Validation loss: 2.52300450417241

Epoch: 5| Step: 1
Training loss: 2.4613883438093485
Validation loss: 2.5262917287751443

Epoch: 5| Step: 2
Training loss: 2.7495239019081663
Validation loss: 2.522851375362523

Epoch: 5| Step: 3
Training loss: 2.7716858396098307
Validation loss: 2.518141019067625

Epoch: 5| Step: 4
Training loss: 3.121942321234763
Validation loss: 2.494500915107144

Epoch: 5| Step: 5
Training loss: 2.8932751853068863
Validation loss: 2.4952582880889707

Epoch: 5| Step: 6
Training loss: 2.2638917804639744
Validation loss: 2.478537229273155

Epoch: 5| Step: 7
Training loss: 2.431570519352107
Validation loss: 2.4677742446844917

Epoch: 5| Step: 8
Training loss: 2.4878061460795515
Validation loss: 2.462748857683631

Epoch: 5| Step: 9
Training loss: 2.9491637774264055
Validation loss: 2.465255256498737

Epoch: 5| Step: 10
Training loss: 2.4857659434758994
Validation loss: 2.4627714299116574

Epoch: 180| Step: 0
Training loss: 2.5175196934586044
Validation loss: 2.4673244274741952

Epoch: 5| Step: 1
Training loss: 3.1397413842190622
Validation loss: 2.4646601800592767

Epoch: 5| Step: 2
Training loss: 2.2033935816035366
Validation loss: 2.4629904407752727

Epoch: 5| Step: 3
Training loss: 2.510675999923729
Validation loss: 2.4666281528204426

Epoch: 5| Step: 4
Training loss: 2.877360991592807
Validation loss: 2.4650007319202287

Epoch: 5| Step: 5
Training loss: 2.70231245761122
Validation loss: 2.4605760003144512

Epoch: 5| Step: 6
Training loss: 3.0143996204918624
Validation loss: 2.47226429337705

Epoch: 5| Step: 7
Training loss: 2.8717256226984826
Validation loss: 2.480168672044617

Epoch: 5| Step: 8
Training loss: 2.89196284496874
Validation loss: 2.495399986834063

Epoch: 5| Step: 9
Training loss: 2.3275617903918344
Validation loss: 2.525309063793724

Epoch: 5| Step: 10
Training loss: 2.6077517640096253
Validation loss: 2.532816137174955

Epoch: 181| Step: 0
Training loss: 2.447727656000152
Validation loss: 2.5216764828044425

Epoch: 5| Step: 1
Training loss: 2.6722852603864014
Validation loss: 2.4904139753123986

Epoch: 5| Step: 2
Training loss: 3.1007813976284924
Validation loss: 2.49115572088855

Epoch: 5| Step: 3
Training loss: 2.7314320449043166
Validation loss: 2.4783605107806697

Epoch: 5| Step: 4
Training loss: 2.914852904441116
Validation loss: 2.4690752522597688

Epoch: 5| Step: 5
Training loss: 3.2838088457739887
Validation loss: 2.4683741954185767

Epoch: 5| Step: 6
Training loss: 2.48493711242312
Validation loss: 2.468315856858541

Epoch: 5| Step: 7
Training loss: 2.660938657624849
Validation loss: 2.4667508936001648

Epoch: 5| Step: 8
Training loss: 2.6448555188298317
Validation loss: 2.4756997957190814

Epoch: 5| Step: 9
Training loss: 2.5226192505912124
Validation loss: 2.4819766264035326

Epoch: 5| Step: 10
Training loss: 2.097727626957183
Validation loss: 2.481632071557311

Epoch: 182| Step: 0
Training loss: 2.8045941605616567
Validation loss: 2.490862142378238

Epoch: 5| Step: 1
Training loss: 2.7265277849408474
Validation loss: 2.5081843441441234

Epoch: 5| Step: 2
Training loss: 2.56380373656202
Validation loss: 2.5149559568741324

Epoch: 5| Step: 3
Training loss: 2.7735736652313463
Validation loss: 2.51887845403655

Epoch: 5| Step: 4
Training loss: 2.4136419331140693
Validation loss: 2.5038802582445348

Epoch: 5| Step: 5
Training loss: 2.541575060168105
Validation loss: 2.5273203658121624

Epoch: 5| Step: 6
Training loss: 2.9315944314731754
Validation loss: 2.5273911040167323

Epoch: 5| Step: 7
Training loss: 3.0118184945180375
Validation loss: 2.521988574425694

Epoch: 5| Step: 8
Training loss: 2.427913300111618
Validation loss: 2.5025230217767063

Epoch: 5| Step: 9
Training loss: 2.769859907828658
Validation loss: 2.5080263194062113

Epoch: 5| Step: 10
Training loss: 2.7167900299271244
Validation loss: 2.48951053671707

Epoch: 183| Step: 0
Training loss: 2.5013355502435313
Validation loss: 2.4908774498934

Epoch: 5| Step: 1
Training loss: 2.704349483037244
Validation loss: 2.4865243635154197

Epoch: 5| Step: 2
Training loss: 2.3851069175698907
Validation loss: 2.483127877674402

Epoch: 5| Step: 3
Training loss: 2.095670587832811
Validation loss: 2.4870408631909835

Epoch: 5| Step: 4
Training loss: 2.882529640276956
Validation loss: 2.4928607194042143

Epoch: 5| Step: 5
Training loss: 2.90833937490395
Validation loss: 2.5012090425601836

Epoch: 5| Step: 6
Training loss: 3.010111933049551
Validation loss: 2.5140263659913162

Epoch: 5| Step: 7
Training loss: 2.9807063216772005
Validation loss: 2.510367221998067

Epoch: 5| Step: 8
Training loss: 2.4520095913498743
Validation loss: 2.522746142882647

Epoch: 5| Step: 9
Training loss: 2.8562855524233606
Validation loss: 2.5195756149487836

Epoch: 5| Step: 10
Training loss: 2.7559840378928833
Validation loss: 2.502142295939463

Epoch: 184| Step: 0
Training loss: 1.528055634903784
Validation loss: 2.496793160688837

Epoch: 5| Step: 1
Training loss: 3.3081966733852695
Validation loss: 2.514791928657703

Epoch: 5| Step: 2
Training loss: 2.4153234651395374
Validation loss: 2.5010160278635825

Epoch: 5| Step: 3
Training loss: 2.5591301508635387
Validation loss: 2.495811584978862

Epoch: 5| Step: 4
Training loss: 3.018731765218121
Validation loss: 2.507469685646622

Epoch: 5| Step: 5
Training loss: 2.359449271744633
Validation loss: 2.521010125622937

Epoch: 5| Step: 6
Training loss: 3.12848209930415
Validation loss: 2.502940931756609

Epoch: 5| Step: 7
Training loss: 3.1311114252001704
Validation loss: 2.5025827991829606

Epoch: 5| Step: 8
Training loss: 2.3857544794441328
Validation loss: 2.509456121079799

Epoch: 5| Step: 9
Training loss: 2.2520305160365637
Validation loss: 2.5455787208998073

Epoch: 5| Step: 10
Training loss: 3.025446103832832
Validation loss: 2.5478495501051763

Epoch: 185| Step: 0
Training loss: 2.632976492916288
Validation loss: 2.559242525112565

Epoch: 5| Step: 1
Training loss: 2.2116235538047375
Validation loss: 2.553149461259394

Epoch: 5| Step: 2
Training loss: 2.7780546198749048
Validation loss: 2.544909464351975

Epoch: 5| Step: 3
Training loss: 2.0909667233300797
Validation loss: 2.5140560197097566

Epoch: 5| Step: 4
Training loss: 2.7911017306521826
Validation loss: 2.5018206304303834

Epoch: 5| Step: 5
Training loss: 3.0617808840618945
Validation loss: 2.4798424143563023

Epoch: 5| Step: 6
Training loss: 3.2612529490564652
Validation loss: 2.4645444054651966

Epoch: 5| Step: 7
Training loss: 2.9902181095450824
Validation loss: 2.4596753080571805

Epoch: 5| Step: 8
Training loss: 2.3996974356984984
Validation loss: 2.4637637612011636

Epoch: 5| Step: 9
Training loss: 2.734671701955166
Validation loss: 2.456720399384009

Epoch: 5| Step: 10
Training loss: 2.8563030813948376
Validation loss: 2.4614118346474068

Epoch: 186| Step: 0
Training loss: 2.944358448556151
Validation loss: 2.4546930618073253

Epoch: 5| Step: 1
Training loss: 2.4523881911242804
Validation loss: 2.4609382490061558

Epoch: 5| Step: 2
Training loss: 3.0950163744368506
Validation loss: 2.4700803369403177

Epoch: 5| Step: 3
Training loss: 3.1285295009603002
Validation loss: 2.479705720575786

Epoch: 5| Step: 4
Training loss: 2.9031360309830627
Validation loss: 2.503740014215483

Epoch: 5| Step: 5
Training loss: 2.630141808200443
Validation loss: 2.5254862966542815

Epoch: 5| Step: 6
Training loss: 2.3441687654860353
Validation loss: 2.5412486307672633

Epoch: 5| Step: 7
Training loss: 2.4250033938983884
Validation loss: 2.5260698877417282

Epoch: 5| Step: 8
Training loss: 2.5474645014302677
Validation loss: 2.573316495120246

Epoch: 5| Step: 9
Training loss: 2.35203400507498
Validation loss: 2.5709346862615714

Epoch: 5| Step: 10
Training loss: 2.927333201177367
Validation loss: 2.5614708775542594

Epoch: 187| Step: 0
Training loss: 2.6695158062924382
Validation loss: 2.510768822960712

Epoch: 5| Step: 1
Training loss: 2.561876360671163
Validation loss: 2.4770269279675063

Epoch: 5| Step: 2
Training loss: 3.1422688751078702
Validation loss: 2.4909433535743752

Epoch: 5| Step: 3
Training loss: 2.3759005997348788
Validation loss: 2.485729326928092

Epoch: 5| Step: 4
Training loss: 2.661997870435085
Validation loss: 2.494713527303424

Epoch: 5| Step: 5
Training loss: 2.1916635399664366
Validation loss: 2.511209328989008

Epoch: 5| Step: 6
Training loss: 2.7455288345303885
Validation loss: 2.519147464959795

Epoch: 5| Step: 7
Training loss: 3.090039735310195
Validation loss: 2.5173122113751543

Epoch: 5| Step: 8
Training loss: 2.9441098456933124
Validation loss: 2.518363166119257

Epoch: 5| Step: 9
Training loss: 2.548189257068173
Validation loss: 2.512304130996158

Epoch: 5| Step: 10
Training loss: 3.0112041424608265
Validation loss: 2.5147283962976674

Epoch: 188| Step: 0
Training loss: 2.699456167199759
Validation loss: 2.5286030938986572

Epoch: 5| Step: 1
Training loss: 2.781141643342178
Validation loss: 2.554265322846971

Epoch: 5| Step: 2
Training loss: 2.4807009610795054
Validation loss: 2.561672767475882

Epoch: 5| Step: 3
Training loss: 2.722578488173955
Validation loss: 2.58893357042407

Epoch: 5| Step: 4
Training loss: 2.8273042784120443
Validation loss: 2.586962076169234

Epoch: 5| Step: 5
Training loss: 3.2900571791483246
Validation loss: 2.588767839175218

Epoch: 5| Step: 6
Training loss: 2.5252042555578744
Validation loss: 2.5858533098483054

Epoch: 5| Step: 7
Training loss: 2.445043091969574
Validation loss: 2.5737826025346777

Epoch: 5| Step: 8
Training loss: 2.551847132956445
Validation loss: 2.5574707251931112

Epoch: 5| Step: 9
Training loss: 3.077517066988812
Validation loss: 2.5480557197443363

Epoch: 5| Step: 10
Training loss: 2.0600983479550363
Validation loss: 2.5117847274035014

Epoch: 189| Step: 0
Training loss: 2.5966082531190597
Validation loss: 2.500834134110593

Epoch: 5| Step: 1
Training loss: 2.8037633196735032
Validation loss: 2.4849887625570033

Epoch: 5| Step: 2
Training loss: 3.0502394660371994
Validation loss: 2.5008076275917057

Epoch: 5| Step: 3
Training loss: 2.5653755057385097
Validation loss: 2.4839067389942593

Epoch: 5| Step: 4
Training loss: 2.3894438973685643
Validation loss: 2.494542895959702

Epoch: 5| Step: 5
Training loss: 2.4176402816388105
Validation loss: 2.5061467315533004

Epoch: 5| Step: 6
Training loss: 2.7465093306350483
Validation loss: 2.505535668625386

Epoch: 5| Step: 7
Training loss: 2.705993012875307
Validation loss: 2.520015162409157

Epoch: 5| Step: 8
Training loss: 2.762809484070477
Validation loss: 2.527627824280123

Epoch: 5| Step: 9
Training loss: 2.6710999017082844
Validation loss: 2.529418162962649

Epoch: 5| Step: 10
Training loss: 2.8378785271593476
Validation loss: 2.5499023748566976

Epoch: 190| Step: 0
Training loss: 2.956534219188643
Validation loss: 2.571965909827493

Epoch: 5| Step: 1
Training loss: 2.90649068512565
Validation loss: 2.5710962624544647

Epoch: 5| Step: 2
Training loss: 1.9699561647679316
Validation loss: 2.6255121332121716

Epoch: 5| Step: 3
Training loss: 2.7313739111265622
Validation loss: 2.6139650256395064

Epoch: 5| Step: 4
Training loss: 2.5312769382126574
Validation loss: 2.6123494837679453

Epoch: 5| Step: 5
Training loss: 2.959153576536096
Validation loss: 2.6179312386185973

Epoch: 5| Step: 6
Training loss: 2.9322516448212848
Validation loss: 2.605513271209631

Epoch: 5| Step: 7
Training loss: 2.6270634851353782
Validation loss: 2.6228931496092476

Epoch: 5| Step: 8
Training loss: 2.807849599755552
Validation loss: 2.611370628028768

Epoch: 5| Step: 9
Training loss: 2.232987192953431
Validation loss: 2.545372070633884

Epoch: 5| Step: 10
Training loss: 2.5178946924163426
Validation loss: 2.5203215356558553

Epoch: 191| Step: 0
Training loss: 2.9774243966728746
Validation loss: 2.5137933467682583

Epoch: 5| Step: 1
Training loss: 2.6209824107779554
Validation loss: 2.4936826566228882

Epoch: 5| Step: 2
Training loss: 2.1308224514874965
Validation loss: 2.4884162827943217

Epoch: 5| Step: 3
Training loss: 2.699666716174048
Validation loss: 2.4948363455026303

Epoch: 5| Step: 4
Training loss: 2.8006827577859514
Validation loss: 2.485942393351256

Epoch: 5| Step: 5
Training loss: 2.8723080513003723
Validation loss: 2.496460533792969

Epoch: 5| Step: 6
Training loss: 2.5193065927578147
Validation loss: 2.505829028856185

Epoch: 5| Step: 7
Training loss: 2.8058340975113922
Validation loss: 2.507978306386578

Epoch: 5| Step: 8
Training loss: 2.9915911127465695
Validation loss: 2.5180358829509646

Epoch: 5| Step: 9
Training loss: 2.296619115576205
Validation loss: 2.5230440690071982

Epoch: 5| Step: 10
Training loss: 2.517635513492052
Validation loss: 2.555300324954146

Epoch: 192| Step: 0
Training loss: 2.7031474029847473
Validation loss: 2.56009665014175

Epoch: 5| Step: 1
Training loss: 2.7186929981789354
Validation loss: 2.5644487673773493

Epoch: 5| Step: 2
Training loss: 2.900367115066754
Validation loss: 2.593059850746464

Epoch: 5| Step: 3
Training loss: 2.3432818135892126
Validation loss: 2.5957219613516327

Epoch: 5| Step: 4
Training loss: 2.8584321348799513
Validation loss: 2.6221631938944214

Epoch: 5| Step: 5
Training loss: 2.1035915633780093
Validation loss: 2.6173387307761304

Epoch: 5| Step: 6
Training loss: 2.750339400414859
Validation loss: 2.609438944457947

Epoch: 5| Step: 7
Training loss: 2.356028020708326
Validation loss: 2.591666886358295

Epoch: 5| Step: 8
Training loss: 2.7440778949124547
Validation loss: 2.5783687552142145

Epoch: 5| Step: 9
Training loss: 2.8193224915519774
Validation loss: 2.575013694643138

Epoch: 5| Step: 10
Training loss: 2.904664786559343
Validation loss: 2.5544077015766704

Epoch: 193| Step: 0
Training loss: 2.648180653768526
Validation loss: 2.556098210557579

Epoch: 5| Step: 1
Training loss: 2.6069021785748783
Validation loss: 2.5407549209411218

Epoch: 5| Step: 2
Training loss: 2.8339219510375995
Validation loss: 2.5361938304959666

Epoch: 5| Step: 3
Training loss: 2.314995836456048
Validation loss: 2.5379498463134236

Epoch: 5| Step: 4
Training loss: 2.6567613894791986
Validation loss: 2.526293329596528

Epoch: 5| Step: 5
Training loss: 3.0244897396287573
Validation loss: 2.519380022556499

Epoch: 5| Step: 6
Training loss: 2.546256897232984
Validation loss: 2.516980406748339

Epoch: 5| Step: 7
Training loss: 3.0935647311752956
Validation loss: 2.5164974531307176

Epoch: 5| Step: 8
Training loss: 2.523701656912042
Validation loss: 2.5242147104392574

Epoch: 5| Step: 9
Training loss: 2.798811343476164
Validation loss: 2.5288351985904276

Epoch: 5| Step: 10
Training loss: 2.002554692391823
Validation loss: 2.5654822892519005

Epoch: 194| Step: 0
Training loss: 2.3888318685877863
Validation loss: 2.587302467035355

Epoch: 5| Step: 1
Training loss: 2.956073399242892
Validation loss: 2.5687735671620575

Epoch: 5| Step: 2
Training loss: 2.991460408049019
Validation loss: 2.572192042501431

Epoch: 5| Step: 3
Training loss: 2.444366467079869
Validation loss: 2.5620484143034337

Epoch: 5| Step: 4
Training loss: 2.808928022799457
Validation loss: 2.5308198774811506

Epoch: 5| Step: 5
Training loss: 2.7495265032872576
Validation loss: 2.5421387459109592

Epoch: 5| Step: 6
Training loss: 2.982593104275437
Validation loss: 2.5307811250642365

Epoch: 5| Step: 7
Training loss: 2.6691103904080253
Validation loss: 2.5261437197030685

Epoch: 5| Step: 8
Training loss: 2.634215844031304
Validation loss: 2.5229094121095756

Epoch: 5| Step: 9
Training loss: 2.231404283676419
Validation loss: 2.5117322422250115

Epoch: 5| Step: 10
Training loss: 2.0751738280137855
Validation loss: 2.5119560358118407

Epoch: 195| Step: 0
Training loss: 2.4561882574266187
Validation loss: 2.5315871728798833

Epoch: 5| Step: 1
Training loss: 2.590021970206497
Validation loss: 2.5312137294790267

Epoch: 5| Step: 2
Training loss: 2.367058073729489
Validation loss: 2.547343681228423

Epoch: 5| Step: 3
Training loss: 2.75850074544305
Validation loss: 2.5778995727348253

Epoch: 5| Step: 4
Training loss: 3.199345438292106
Validation loss: 2.6137438782353644

Epoch: 5| Step: 5
Training loss: 2.218015737328109
Validation loss: 2.6306440078862994

Epoch: 5| Step: 6
Training loss: 2.724238325988956
Validation loss: 2.644820325495899

Epoch: 5| Step: 7
Training loss: 2.4928892098424327
Validation loss: 2.5843335939915866

Epoch: 5| Step: 8
Training loss: 2.562325820585634
Validation loss: 2.539403659060098

Epoch: 5| Step: 9
Training loss: 2.300342666973346
Validation loss: 2.5169859944425768

Epoch: 5| Step: 10
Training loss: 3.2089396477691663
Validation loss: 2.5109006687206974

Epoch: 196| Step: 0
Training loss: 3.038314609633811
Validation loss: 2.5214075058181153

Epoch: 5| Step: 1
Training loss: 2.719614176594035
Validation loss: 2.5054653989998528

Epoch: 5| Step: 2
Training loss: 2.7832307084707706
Validation loss: 2.5141607033086464

Epoch: 5| Step: 3
Training loss: 2.067467689123302
Validation loss: 2.510477877063699

Epoch: 5| Step: 4
Training loss: 2.681916313697722
Validation loss: 2.5379693264540535

Epoch: 5| Step: 5
Training loss: 2.556228965915237
Validation loss: 2.5403384865938174

Epoch: 5| Step: 6
Training loss: 2.6353939090595553
Validation loss: 2.5771033257962968

Epoch: 5| Step: 7
Training loss: 2.6106608985659214
Validation loss: 2.6039614813581804

Epoch: 5| Step: 8
Training loss: 2.4333219667282435
Validation loss: 2.5792082091122595

Epoch: 5| Step: 9
Training loss: 2.6466822926743045
Validation loss: 2.55839633576145

Epoch: 5| Step: 10
Training loss: 2.4913645375092233
Validation loss: 2.542794181424852

Epoch: 197| Step: 0
Training loss: 2.056930188319862
Validation loss: 2.5353275151917494

Epoch: 5| Step: 1
Training loss: 2.3316930273209695
Validation loss: 2.523613513205218

Epoch: 5| Step: 2
Training loss: 2.9697455092292677
Validation loss: 2.5253317031982867

Epoch: 5| Step: 3
Training loss: 2.673668153713022
Validation loss: 2.5142825144489835

Epoch: 5| Step: 4
Training loss: 2.5957694407560523
Validation loss: 2.51992158529961

Epoch: 5| Step: 5
Training loss: 2.3627998807600648
Validation loss: 2.527526579035583

Epoch: 5| Step: 6
Training loss: 2.0136522205181695
Validation loss: 2.5267254401987826

Epoch: 5| Step: 7
Training loss: 2.65613277401025
Validation loss: 2.5404116717640117

Epoch: 5| Step: 8
Training loss: 3.208894919914902
Validation loss: 2.537456412016522

Epoch: 5| Step: 9
Training loss: 2.6904911871941044
Validation loss: 2.5439524805590223

Epoch: 5| Step: 10
Training loss: 2.7839985671149328
Validation loss: 2.5542784297457977

Epoch: 198| Step: 0
Training loss: 2.057390183291077
Validation loss: 2.5662401448104193

Epoch: 5| Step: 1
Training loss: 2.4546378749248086
Validation loss: 2.5509046439824936

Epoch: 5| Step: 2
Training loss: 2.1418058382327154
Validation loss: 2.566065409036047

Epoch: 5| Step: 3
Training loss: 3.1316204895004103
Validation loss: 2.559417259927879

Epoch: 5| Step: 4
Training loss: 2.3439938227666497
Validation loss: 2.5896157022459114

Epoch: 5| Step: 5
Training loss: 2.1709254542431573
Validation loss: 2.5813605456507336

Epoch: 5| Step: 6
Training loss: 2.688156136547732
Validation loss: 2.575068502911764

Epoch: 5| Step: 7
Training loss: 2.6123236710758833
Validation loss: 2.55824265377623

Epoch: 5| Step: 8
Training loss: 2.8575453610962427
Validation loss: 2.5467000277496195

Epoch: 5| Step: 9
Training loss: 2.842404728536755
Validation loss: 2.549299191505575

Epoch: 5| Step: 10
Training loss: 2.906449834044514
Validation loss: 2.5360704930559015

Epoch: 199| Step: 0
Training loss: 2.3866859845848327
Validation loss: 2.5315575037520444

Epoch: 5| Step: 1
Training loss: 2.549431483154349
Validation loss: 2.541393110649096

Epoch: 5| Step: 2
Training loss: 2.2124473349989695
Validation loss: 2.5433295559647084

Epoch: 5| Step: 3
Training loss: 2.4522760951251823
Validation loss: 2.5477342885451844

Epoch: 5| Step: 4
Training loss: 2.7604587383782904
Validation loss: 2.55250099954988

Epoch: 5| Step: 5
Training loss: 2.3148859448277435
Validation loss: 2.571756695701442

Epoch: 5| Step: 6
Training loss: 1.9172451417895993
Validation loss: 2.6134687426619223

Epoch: 5| Step: 7
Training loss: 2.460595485596483
Validation loss: 2.5995128198824506

Epoch: 5| Step: 8
Training loss: 3.175881997700461
Validation loss: 2.608577283839168

Epoch: 5| Step: 9
Training loss: 2.8327447242435193
Validation loss: 2.597217650035956

Epoch: 5| Step: 10
Training loss: 3.1677175250553007
Validation loss: 2.5735912643435426

Epoch: 200| Step: 0
Training loss: 2.391171760615165
Validation loss: 2.5515374476077146

Epoch: 5| Step: 1
Training loss: 2.2175713215640087
Validation loss: 2.5461136297502374

Epoch: 5| Step: 2
Training loss: 2.432756846433866
Validation loss: 2.547598222701126

Epoch: 5| Step: 3
Training loss: 2.929650064864996
Validation loss: 2.5259609306346795

Epoch: 5| Step: 4
Training loss: 2.543049566388145
Validation loss: 2.5322026837862937

Epoch: 5| Step: 5
Training loss: 2.6836312414934778
Validation loss: 2.547728263152997

Epoch: 5| Step: 6
Training loss: 2.530829218045798
Validation loss: 2.5834836634925074

Epoch: 5| Step: 7
Training loss: 2.608492399327833
Validation loss: 2.5956895388804884

Epoch: 5| Step: 8
Training loss: 2.6725430908154926
Validation loss: 2.637891436652221

Epoch: 5| Step: 9
Training loss: 2.714413923089442
Validation loss: 2.6086742709704263

Epoch: 5| Step: 10
Training loss: 2.582741597812638
Validation loss: 2.6014823976380956

Epoch: 201| Step: 0
Training loss: 2.7898638773426856
Validation loss: 2.5828841646234495

Epoch: 5| Step: 1
Training loss: 2.499816601701968
Validation loss: 2.5609555856459423

Epoch: 5| Step: 2
Training loss: 2.36659308798232
Validation loss: 2.5366418499261085

Epoch: 5| Step: 3
Training loss: 3.044326577221448
Validation loss: 2.5195990292983423

Epoch: 5| Step: 4
Training loss: 2.6826409171172445
Validation loss: 2.517042627457985

Epoch: 5| Step: 5
Training loss: 1.8759053269880501
Validation loss: 2.51871631082425

Epoch: 5| Step: 6
Training loss: 2.492975953323922
Validation loss: 2.519568206091267

Epoch: 5| Step: 7
Training loss: 2.429905823346504
Validation loss: 2.559548746168164

Epoch: 5| Step: 8
Training loss: 2.4723170139651396
Validation loss: 2.6033111453317783

Epoch: 5| Step: 9
Training loss: 2.780471692856777
Validation loss: 2.620837189867681

Epoch: 5| Step: 10
Training loss: 2.6641462654078
Validation loss: 2.6432020691038782

Epoch: 202| Step: 0
Training loss: 2.661152433270557
Validation loss: 2.6419220338585947

Epoch: 5| Step: 1
Training loss: 2.393207227559998
Validation loss: 2.654329625652282

Epoch: 5| Step: 2
Training loss: 3.1140172607688306
Validation loss: 2.6501957527945583

Epoch: 5| Step: 3
Training loss: 2.568168232698483
Validation loss: 2.60868271365003

Epoch: 5| Step: 4
Training loss: 2.480264682335274
Validation loss: 2.5591561815298935

Epoch: 5| Step: 5
Training loss: 2.8607046235671274
Validation loss: 2.547275373086441

Epoch: 5| Step: 6
Training loss: 2.416014243443926
Validation loss: 2.536016759627752

Epoch: 5| Step: 7
Training loss: 1.9972666301161477
Validation loss: 2.531180758221077

Epoch: 5| Step: 8
Training loss: 2.598776668908993
Validation loss: 2.5415261487145226

Epoch: 5| Step: 9
Training loss: 2.2741348927329397
Validation loss: 2.537109251724209

Epoch: 5| Step: 10
Training loss: 2.5526831927491402
Validation loss: 2.537577599927549

Epoch: 203| Step: 0
Training loss: 2.488749844729746
Validation loss: 2.535718653122521

Epoch: 5| Step: 1
Training loss: 1.9577328457958232
Validation loss: 2.5495275377439475

Epoch: 5| Step: 2
Training loss: 2.6025364974189986
Validation loss: 2.543061428637863

Epoch: 5| Step: 3
Training loss: 2.1462887647946034
Validation loss: 2.5596933048260735

Epoch: 5| Step: 4
Training loss: 2.2467859412358053
Validation loss: 2.559018840607129

Epoch: 5| Step: 5
Training loss: 3.11213216791225
Validation loss: 2.5672351178372312

Epoch: 5| Step: 6
Training loss: 2.3287576929396363
Validation loss: 2.5677429525030986

Epoch: 5| Step: 7
Training loss: 2.626470789536517
Validation loss: 2.546803924194883

Epoch: 5| Step: 8
Training loss: 2.8810654388696757
Validation loss: 2.5498492576573453

Epoch: 5| Step: 9
Training loss: 2.7038573226756473
Validation loss: 2.5383507575827307

Epoch: 5| Step: 10
Training loss: 2.7776418705647608
Validation loss: 2.543285227377218

Epoch: 204| Step: 0
Training loss: 2.6734388805142824
Validation loss: 2.530872985339214

Epoch: 5| Step: 1
Training loss: 2.067104401940189
Validation loss: 2.5375741180267344

Epoch: 5| Step: 2
Training loss: 2.6270784596320573
Validation loss: 2.5467392345292943

Epoch: 5| Step: 3
Training loss: 2.949544360647048
Validation loss: 2.548038044230199

Epoch: 5| Step: 4
Training loss: 2.71633725148632
Validation loss: 2.566178533543365

Epoch: 5| Step: 5
Training loss: 2.3613965803120145
Validation loss: 2.596123251214524

Epoch: 5| Step: 6
Training loss: 2.3417233669525404
Validation loss: 2.6272202930119204

Epoch: 5| Step: 7
Training loss: 2.5389808993798617
Validation loss: 2.5900673102306673

Epoch: 5| Step: 8
Training loss: 2.46400149505124
Validation loss: 2.535950243031691

Epoch: 5| Step: 9
Training loss: 2.7487680970446684
Validation loss: 2.52418104041078

Epoch: 5| Step: 10
Training loss: 2.5599418524754465
Validation loss: 2.5229455032733603

Epoch: 205| Step: 0
Training loss: 2.509326798485582
Validation loss: 2.536817867600179

Epoch: 5| Step: 1
Training loss: 2.3545745113731598
Validation loss: 2.5377338274411154

Epoch: 5| Step: 2
Training loss: 2.7622536838550777
Validation loss: 2.5545861139193256

Epoch: 5| Step: 3
Training loss: 2.430643660144386
Validation loss: 2.590482173148029

Epoch: 5| Step: 4
Training loss: 2.772539192108444
Validation loss: 2.635021004107521

Epoch: 5| Step: 5
Training loss: 3.216295954898216
Validation loss: 2.664718787187176

Epoch: 5| Step: 6
Training loss: 2.2982152026133655
Validation loss: 2.6452272990559726

Epoch: 5| Step: 7
Training loss: 2.3078778442966943
Validation loss: 2.6121550172318786

Epoch: 5| Step: 8
Training loss: 2.004329525152476
Validation loss: 2.5686827603675537

Epoch: 5| Step: 9
Training loss: 2.336785102088398
Validation loss: 2.542102914130524

Epoch: 5| Step: 10
Training loss: 2.9771111250573
Validation loss: 2.5258149032035955

Epoch: 206| Step: 0
Training loss: 2.774975331514703
Validation loss: 2.5292524960947644

Epoch: 5| Step: 1
Training loss: 2.3761006866532433
Validation loss: 2.5287638651346107

Epoch: 5| Step: 2
Training loss: 2.420163244936406
Validation loss: 2.5127310259582267

Epoch: 5| Step: 3
Training loss: 2.522614241433673
Validation loss: 2.5221994407473276

Epoch: 5| Step: 4
Training loss: 2.644815224032655
Validation loss: 2.5165297437240506

Epoch: 5| Step: 5
Training loss: 2.702432268054397
Validation loss: 2.521464319124661

Epoch: 5| Step: 6
Training loss: 2.1243480355419257
Validation loss: 2.5077000374479295

Epoch: 5| Step: 7
Training loss: 2.4073010415709404
Validation loss: 2.540364447432782

Epoch: 5| Step: 8
Training loss: 2.6901402478723404
Validation loss: 2.551420639484523

Epoch: 5| Step: 9
Training loss: 2.7419579564717242
Validation loss: 2.5578779829915654

Epoch: 5| Step: 10
Training loss: 2.0273409275630643
Validation loss: 2.5824739301552717

Epoch: 207| Step: 0
Training loss: 2.618440424936502
Validation loss: 2.6398740291465863

Epoch: 5| Step: 1
Training loss: 2.8753831027657686
Validation loss: 2.6560304284353626

Epoch: 5| Step: 2
Training loss: 2.8751202433775522
Validation loss: 2.6232816694483074

Epoch: 5| Step: 3
Training loss: 2.2280684882617523
Validation loss: 2.596849288152704

Epoch: 5| Step: 4
Training loss: 2.0348272661761313
Validation loss: 2.6181210959511274

Epoch: 5| Step: 5
Training loss: 2.694888758867137
Validation loss: 2.6160899212171715

Epoch: 5| Step: 6
Training loss: 2.4528678224691185
Validation loss: 2.62901266076752

Epoch: 5| Step: 7
Training loss: 2.142262632915257
Validation loss: 2.6436911674994756

Epoch: 5| Step: 8
Training loss: 2.4252004127666935
Validation loss: 2.6414055624170856

Epoch: 5| Step: 9
Training loss: 2.5034569680896572
Validation loss: 2.6342237892916107

Epoch: 5| Step: 10
Training loss: 2.8709406182589943
Validation loss: 2.634936416903988

Epoch: 208| Step: 0
Training loss: 2.8589145310479993
Validation loss: 2.6205609236675595

Epoch: 5| Step: 1
Training loss: 2.2504219083460693
Validation loss: 2.6052759740656337

Epoch: 5| Step: 2
Training loss: 2.1946671918765643
Validation loss: 2.6074037347309806

Epoch: 5| Step: 3
Training loss: 2.633716733602007
Validation loss: 2.5966078147562315

Epoch: 5| Step: 4
Training loss: 2.398756670761176
Validation loss: 2.591752550429676

Epoch: 5| Step: 5
Training loss: 2.3727189202395826
Validation loss: 2.60368960106468

Epoch: 5| Step: 6
Training loss: 2.49376951128753
Validation loss: 2.5886857147917137

Epoch: 5| Step: 7
Training loss: 2.3509875637100333
Validation loss: 2.5967762127091825

Epoch: 5| Step: 8
Training loss: 2.8178777355855487
Validation loss: 2.615362172859198

Epoch: 5| Step: 9
Training loss: 2.778971392297255
Validation loss: 2.6437267986571085

Epoch: 5| Step: 10
Training loss: 2.3749407710670725
Validation loss: 2.6252699916767477

Epoch: 209| Step: 0
Training loss: 2.630615313678218
Validation loss: 2.6065031860419525

Epoch: 5| Step: 1
Training loss: 2.0640452982714916
Validation loss: 2.5804972146359155

Epoch: 5| Step: 2
Training loss: 2.6705147476346176
Validation loss: 2.5691905224253526

Epoch: 5| Step: 3
Training loss: 2.413540780686463
Validation loss: 2.5690975809445997

Epoch: 5| Step: 4
Training loss: 3.0170634105417773
Validation loss: 2.5668906167155265

Epoch: 5| Step: 5
Training loss: 2.382593763974131
Validation loss: 2.584904222537871

Epoch: 5| Step: 6
Training loss: 2.2817350943061685
Validation loss: 2.6038802142364106

Epoch: 5| Step: 7
Training loss: 2.184835173197124
Validation loss: 2.607113193996376

Epoch: 5| Step: 8
Training loss: 2.2385910911541607
Validation loss: 2.6252825731890894

Epoch: 5| Step: 9
Training loss: 2.705987990736833
Validation loss: 2.6308930888013684

Epoch: 5| Step: 10
Training loss: 2.6135410698567805
Validation loss: 2.6533568655629685

Epoch: 210| Step: 0
Training loss: 2.9186853961207126
Validation loss: 2.636097159454783

Epoch: 5| Step: 1
Training loss: 2.2086107931434182
Validation loss: 2.6098062091296224

Epoch: 5| Step: 2
Training loss: 2.456235917611557
Validation loss: 2.5814347308088026

Epoch: 5| Step: 3
Training loss: 2.3302383559613085
Validation loss: 2.5830240219931664

Epoch: 5| Step: 4
Training loss: 2.3279734312553613
Validation loss: 2.593100462383462

Epoch: 5| Step: 5
Training loss: 2.0556719492128996
Validation loss: 2.585791407454483

Epoch: 5| Step: 6
Training loss: 2.93334829875712
Validation loss: 2.58438352844892

Epoch: 5| Step: 7
Training loss: 2.4200552718100723
Validation loss: 2.595782223524246

Epoch: 5| Step: 8
Training loss: 2.4227149737294944
Validation loss: 2.5757435817485326

Epoch: 5| Step: 9
Training loss: 2.406868396909458
Validation loss: 2.5660624718124847

Epoch: 5| Step: 10
Training loss: 2.3091160527104857
Validation loss: 2.5538820425276514

Epoch: 211| Step: 0
Training loss: 2.3434181487071277
Validation loss: 2.5329166036876267

Epoch: 5| Step: 1
Training loss: 1.9496608683764638
Validation loss: 2.5266852232789807

Epoch: 5| Step: 2
Training loss: 2.2596893429554115
Validation loss: 2.527482739086505

Epoch: 5| Step: 3
Training loss: 2.269737877689128
Validation loss: 2.545176324267475

Epoch: 5| Step: 4
Training loss: 3.011573718743696
Validation loss: 2.5577535532738587

Epoch: 5| Step: 5
Training loss: 2.2181165623766375
Validation loss: 2.5539241374178108

Epoch: 5| Step: 6
Training loss: 2.5877505858336542
Validation loss: 2.5641136271168667

Epoch: 5| Step: 7
Training loss: 2.0782825152137554
Validation loss: 2.5882749725682963

Epoch: 5| Step: 8
Training loss: 2.304205478757522
Validation loss: 2.6197908420610783

Epoch: 5| Step: 9
Training loss: 2.9228817434438272
Validation loss: 2.602902758301755

Epoch: 5| Step: 10
Training loss: 2.487428144634381
Validation loss: 2.6015147883164054

Epoch: 212| Step: 0
Training loss: 1.6951641246364157
Validation loss: 2.561828337172014

Epoch: 5| Step: 1
Training loss: 2.4227847451802793
Validation loss: 2.559809584228646

Epoch: 5| Step: 2
Training loss: 2.7960109974504337
Validation loss: 2.547510273837712

Epoch: 5| Step: 3
Training loss: 2.553527942176676
Validation loss: 2.5399614407176445

Epoch: 5| Step: 4
Training loss: 1.8817862091858122
Validation loss: 2.507518194036477

Epoch: 5| Step: 5
Training loss: 2.4906327231944343
Validation loss: 2.5190500127798434

Epoch: 5| Step: 6
Training loss: 2.3499480627286156
Validation loss: 2.5206761583635116

Epoch: 5| Step: 7
Training loss: 2.6663987998735377
Validation loss: 2.5205860821793933

Epoch: 5| Step: 8
Training loss: 2.4032907495769114
Validation loss: 2.5415578741886264

Epoch: 5| Step: 9
Training loss: 2.6370925299301833
Validation loss: 2.570387892682255

Epoch: 5| Step: 10
Training loss: 2.57791617732652
Validation loss: 2.6524165800143678

Epoch: 213| Step: 0
Training loss: 2.6702350245844153
Validation loss: 2.6634834961146785

Epoch: 5| Step: 1
Training loss: 2.5896377136298434
Validation loss: 2.692049756439889

Epoch: 5| Step: 2
Training loss: 2.2103000975662264
Validation loss: 2.686938473035863

Epoch: 5| Step: 3
Training loss: 2.5752060520727897
Validation loss: 2.6617101914530963

Epoch: 5| Step: 4
Training loss: 2.7029575891417035
Validation loss: 2.6364566693693905

Epoch: 5| Step: 5
Training loss: 2.4226884029731086
Validation loss: 2.610772808559005

Epoch: 5| Step: 6
Training loss: 2.542711751816538
Validation loss: 2.567190679758748

Epoch: 5| Step: 7
Training loss: 2.4649083632329503
Validation loss: 2.5256634450103226

Epoch: 5| Step: 8
Training loss: 2.2923951349433445
Validation loss: 2.4947020126909045

Epoch: 5| Step: 9
Training loss: 1.9269743467562408
Validation loss: 2.475742196859298

Epoch: 5| Step: 10
Training loss: 2.666570651789505
Validation loss: 2.4683499222998595

Epoch: 214| Step: 0
Training loss: 2.7432913881372993
Validation loss: 2.459442197962589

Epoch: 5| Step: 1
Training loss: 2.6306559166119055
Validation loss: 2.486388605207064

Epoch: 5| Step: 2
Training loss: 2.501144623984033
Validation loss: 2.5162738077258076

Epoch: 5| Step: 3
Training loss: 2.035963253581479
Validation loss: 2.558740483666509

Epoch: 5| Step: 4
Training loss: 1.8253979027062417
Validation loss: 2.5851763281732656

Epoch: 5| Step: 5
Training loss: 2.629098054823871
Validation loss: 2.5843275537396204

Epoch: 5| Step: 6
Training loss: 2.326201188089341
Validation loss: 2.5593361940972486

Epoch: 5| Step: 7
Training loss: 2.586977746567715
Validation loss: 2.554748845506131

Epoch: 5| Step: 8
Training loss: 2.6182714238932574
Validation loss: 2.5743699536433184

Epoch: 5| Step: 9
Training loss: 2.5923997972596333
Validation loss: 2.559223211906619

Epoch: 5| Step: 10
Training loss: 2.2205640871780514
Validation loss: 2.572784963160281

Epoch: 215| Step: 0
Training loss: 2.909337526401723
Validation loss: 2.5705853055096823

Epoch: 5| Step: 1
Training loss: 2.1223839757545173
Validation loss: 2.590112529697826

Epoch: 5| Step: 2
Training loss: 2.9255046637352367
Validation loss: 2.5848022998881404

Epoch: 5| Step: 3
Training loss: 3.1153435093050716
Validation loss: 2.5751339622797036

Epoch: 5| Step: 4
Training loss: 2.4679850105312697
Validation loss: 2.55944154582175

Epoch: 5| Step: 5
Training loss: 1.9072559391538788
Validation loss: 2.5404876995186925

Epoch: 5| Step: 6
Training loss: 2.097599646800904
Validation loss: 2.527180715011743

Epoch: 5| Step: 7
Training loss: 1.5464731330202812
Validation loss: 2.504556106689976

Epoch: 5| Step: 8
Training loss: 2.4490775960496163
Validation loss: 2.4997939640174347

Epoch: 5| Step: 9
Training loss: 2.2437991421134216
Validation loss: 2.5249916308822837

Epoch: 5| Step: 10
Training loss: 2.580663552526344
Validation loss: 2.542886744437537

Epoch: 216| Step: 0
Training loss: 2.6313803198792645
Validation loss: 2.555995644749482

Epoch: 5| Step: 1
Training loss: 2.5845221481038436
Validation loss: 2.5640663124098073

Epoch: 5| Step: 2
Training loss: 3.1069610273153327
Validation loss: 2.5696555445486293

Epoch: 5| Step: 3
Training loss: 2.1615881700854174
Validation loss: 2.5846287247939563

Epoch: 5| Step: 4
Training loss: 2.5243253769782137
Validation loss: 2.587050712313896

Epoch: 5| Step: 5
Training loss: 1.557631192996399
Validation loss: 2.608044386812467

Epoch: 5| Step: 6
Training loss: 2.4228762618085558
Validation loss: 2.6119789756025873

Epoch: 5| Step: 7
Training loss: 2.31897653465358
Validation loss: 2.6094063210531084

Epoch: 5| Step: 8
Training loss: 2.113859932971706
Validation loss: 2.5647766910336647

Epoch: 5| Step: 9
Training loss: 2.5251635621227413
Validation loss: 2.5567903574712627

Epoch: 5| Step: 10
Training loss: 1.828521424699732
Validation loss: 2.5463578351940264

Epoch: 217| Step: 0
Training loss: 2.4737985873932358
Validation loss: 2.553761727721628

Epoch: 5| Step: 1
Training loss: 2.7084072298581323
Validation loss: 2.555474375285041

Epoch: 5| Step: 2
Training loss: 2.1471188469211375
Validation loss: 2.560179042717518

Epoch: 5| Step: 3
Training loss: 2.3246214445656883
Validation loss: 2.583614330774815

Epoch: 5| Step: 4
Training loss: 2.0196882589020944
Validation loss: 2.6200012861660578

Epoch: 5| Step: 5
Training loss: 2.2811925175361654
Validation loss: 2.643471422686573

Epoch: 5| Step: 6
Training loss: 2.776454520285998
Validation loss: 2.683601061866296

Epoch: 5| Step: 7
Training loss: 2.3271488473037825
Validation loss: 2.633067008253515

Epoch: 5| Step: 8
Training loss: 2.4288213725457677
Validation loss: 2.6035309092229015

Epoch: 5| Step: 9
Training loss: 2.4189348647962707
Validation loss: 2.570045470037429

Epoch: 5| Step: 10
Training loss: 1.6977749708842054
Validation loss: 2.5366819105080656

Epoch: 218| Step: 0
Training loss: 1.9659221260853414
Validation loss: 2.5260105392894427

Epoch: 5| Step: 1
Training loss: 2.7642510228534225
Validation loss: 2.5351730071322556

Epoch: 5| Step: 2
Training loss: 2.465029556840033
Validation loss: 2.5448227754965105

Epoch: 5| Step: 3
Training loss: 2.636482194249698
Validation loss: 2.54678735129881

Epoch: 5| Step: 4
Training loss: 2.0759810093505386
Validation loss: 2.5580888743672943

Epoch: 5| Step: 5
Training loss: 2.427676432647749
Validation loss: 2.5747417426771597

Epoch: 5| Step: 6
Training loss: 2.1504779905333966
Validation loss: 2.554790331059912

Epoch: 5| Step: 7
Training loss: 2.419510603986925
Validation loss: 2.5581961554480284

Epoch: 5| Step: 8
Training loss: 2.4286996483013157
Validation loss: 2.57626061967433

Epoch: 5| Step: 9
Training loss: 2.14662898846054
Validation loss: 2.5997425579391407

Epoch: 5| Step: 10
Training loss: 1.9185612961613439
Validation loss: 2.5846232942471663

Epoch: 219| Step: 0
Training loss: 2.251243883259124
Validation loss: 2.5977843994486816

Epoch: 5| Step: 1
Training loss: 2.4156901480314867
Validation loss: 2.618654673261282

Epoch: 5| Step: 2
Training loss: 2.2720123753210633
Validation loss: 2.5784864722271204

Epoch: 5| Step: 3
Training loss: 2.4843345974689877
Validation loss: 2.5413339011394163

Epoch: 5| Step: 4
Training loss: 2.401647848425722
Validation loss: 2.5080144345547395

Epoch: 5| Step: 5
Training loss: 2.546337234733114
Validation loss: 2.509230365624745

Epoch: 5| Step: 6
Training loss: 2.6075434852843635
Validation loss: 2.5067063263219214

Epoch: 5| Step: 7
Training loss: 1.9865052810932882
Validation loss: 2.5261717880897665

Epoch: 5| Step: 8
Training loss: 1.9427168967814221
Validation loss: 2.5150445120468747

Epoch: 5| Step: 9
Training loss: 2.184582754141482
Validation loss: 2.515407342143493

Epoch: 5| Step: 10
Training loss: 2.430886809770312
Validation loss: 2.5308318679600412

Epoch: 220| Step: 0
Training loss: 2.294505031956741
Validation loss: 2.543988803251409

Epoch: 5| Step: 1
Training loss: 3.1316314525833926
Validation loss: 2.5666840392751213

Epoch: 5| Step: 2
Training loss: 2.1248614322137853
Validation loss: 2.595077616687697

Epoch: 5| Step: 3
Training loss: 2.345784232764602
Validation loss: 2.5900670934651338

Epoch: 5| Step: 4
Training loss: 2.0816810413573874
Validation loss: 2.571362833348871

Epoch: 5| Step: 5
Training loss: 2.2680859058802505
Validation loss: 2.57157068882038

Epoch: 5| Step: 6
Training loss: 2.061419811020566
Validation loss: 2.573122899491714

Epoch: 5| Step: 7
Training loss: 2.3420542367963435
Validation loss: 2.5650212200107165

Epoch: 5| Step: 8
Training loss: 1.7606673052833686
Validation loss: 2.5518829394267066

Epoch: 5| Step: 9
Training loss: 1.9532665964298155
Validation loss: 2.552769560444744

Epoch: 5| Step: 10
Training loss: 2.401586596257001
Validation loss: 2.5506125019954102

Epoch: 221| Step: 0
Training loss: 1.8913959791242585
Validation loss: 2.5424968695691117

Epoch: 5| Step: 1
Training loss: 2.1385499126896574
Validation loss: 2.5424189628454026

Epoch: 5| Step: 2
Training loss: 2.0301470769961076
Validation loss: 2.5846955448784867

Epoch: 5| Step: 3
Training loss: 1.8911974331949697
Validation loss: 2.587921247156014

Epoch: 5| Step: 4
Training loss: 2.291518836599693
Validation loss: 2.620666949395151

Epoch: 5| Step: 5
Training loss: 2.316126480061714
Validation loss: 2.6283002246696103

Epoch: 5| Step: 6
Training loss: 2.7759941244915174
Validation loss: 2.632860203427633

Epoch: 5| Step: 7
Training loss: 2.3113959486388906
Validation loss: 2.6003346022385503

Epoch: 5| Step: 8
Training loss: 2.355875717103875
Validation loss: 2.537524894561122

Epoch: 5| Step: 9
Training loss: 2.269045963371571
Validation loss: 2.5099893345034463

Epoch: 5| Step: 10
Training loss: 2.766148145949189
Validation loss: 2.5066681502079726

Epoch: 222| Step: 0
Training loss: 2.084422043208003
Validation loss: 2.502067463721611

Epoch: 5| Step: 1
Training loss: 2.453958843436365
Validation loss: 2.4935582630885365

Epoch: 5| Step: 2
Training loss: 2.5949505704607874
Validation loss: 2.5204667340325764

Epoch: 5| Step: 3
Training loss: 2.584610059535301
Validation loss: 2.4914347263657786

Epoch: 5| Step: 4
Training loss: 2.5160815849358347
Validation loss: 2.4993877614891

Epoch: 5| Step: 5
Training loss: 2.1748665165773278
Validation loss: 2.488395938763092

Epoch: 5| Step: 6
Training loss: 2.126403233087807
Validation loss: 2.4931414950017277

Epoch: 5| Step: 7
Training loss: 2.26417410860417
Validation loss: 2.506577742457741

Epoch: 5| Step: 8
Training loss: 1.9388217724341998
Validation loss: 2.581703960959339

Epoch: 5| Step: 9
Training loss: 2.6554986227610513
Validation loss: 2.618103960052406

Epoch: 5| Step: 10
Training loss: 2.173069028794587
Validation loss: 2.5548737908245815

Epoch: 223| Step: 0
Training loss: 2.3317600009426034
Validation loss: 2.540097880318101

Epoch: 5| Step: 1
Training loss: 2.610394215975639
Validation loss: 2.5006783744303553

Epoch: 5| Step: 2
Training loss: 2.068023913793073
Validation loss: 2.5075547377805543

Epoch: 5| Step: 3
Training loss: 2.469007840755554
Validation loss: 2.502887008439024

Epoch: 5| Step: 4
Training loss: 1.8410751206893656
Validation loss: 2.503427521639824

Epoch: 5| Step: 5
Training loss: 2.0306365040329672
Validation loss: 2.5122806323313585

Epoch: 5| Step: 6
Training loss: 2.154358407297803
Validation loss: 2.498339365015684

Epoch: 5| Step: 7
Training loss: 2.2415037807387614
Validation loss: 2.511241993328523

Epoch: 5| Step: 8
Training loss: 2.4699223306158644
Validation loss: 2.5012177895583574

Epoch: 5| Step: 9
Training loss: 2.1133733084154005
Validation loss: 2.5028594532838024

Epoch: 5| Step: 10
Training loss: 2.258514189663122
Validation loss: 2.503026738991352

Epoch: 224| Step: 0
Training loss: 2.2239465169719264
Validation loss: 2.5123804327922548

Epoch: 5| Step: 1
Training loss: 2.4363410346303995
Validation loss: 2.5304742756524874

Epoch: 5| Step: 2
Training loss: 2.2619129156859628
Validation loss: 2.555939790579227

Epoch: 5| Step: 3
Training loss: 2.7421271597372097
Validation loss: 2.5638134719241625

Epoch: 5| Step: 4
Training loss: 1.8374275816056707
Validation loss: 2.6058796823328243

Epoch: 5| Step: 5
Training loss: 2.136797971494705
Validation loss: 2.577113534167778

Epoch: 5| Step: 6
Training loss: 2.2445776557838757
Validation loss: 2.6016809856001863

Epoch: 5| Step: 7
Training loss: 2.089413265205369
Validation loss: 2.5774401200337276

Epoch: 5| Step: 8
Training loss: 1.8113828044089069
Validation loss: 2.5600100880165813

Epoch: 5| Step: 9
Training loss: 2.3551241747602267
Validation loss: 2.5378899948303006

Epoch: 5| Step: 10
Training loss: 2.143610633345944
Validation loss: 2.5404417642532806

Epoch: 225| Step: 0
Training loss: 2.158997154025472
Validation loss: 2.532390731925726

Epoch: 5| Step: 1
Training loss: 2.2856427058013167
Validation loss: 2.544955557717536

Epoch: 5| Step: 2
Training loss: 2.3933547647343696
Validation loss: 2.552855302599066

Epoch: 5| Step: 3
Training loss: 1.6836325514851542
Validation loss: 2.543513726486043

Epoch: 5| Step: 4
Training loss: 1.9196308959385515
Validation loss: 2.576547041709904

Epoch: 5| Step: 5
Training loss: 1.9662595467599413
Validation loss: 2.55629445039924

Epoch: 5| Step: 6
Training loss: 2.547456078267715
Validation loss: 2.556713501453036

Epoch: 5| Step: 7
Training loss: 2.4487986713925496
Validation loss: 2.5466232562922104

Epoch: 5| Step: 8
Training loss: 2.2074021829466943
Validation loss: 2.5594075128518874

Epoch: 5| Step: 9
Training loss: 2.0528632939268623
Validation loss: 2.5361006653601468

Epoch: 5| Step: 10
Training loss: 2.482535490952077
Validation loss: 2.536380925744748

Epoch: 226| Step: 0
Training loss: 2.779444933852769
Validation loss: 2.5377865557434407

Epoch: 5| Step: 1
Training loss: 2.215609302115416
Validation loss: 2.5422259568876524

Epoch: 5| Step: 2
Training loss: 2.45485611596889
Validation loss: 2.5500929972938358

Epoch: 5| Step: 3
Training loss: 1.8800374074014485
Validation loss: 2.5716018741657587

Epoch: 5| Step: 4
Training loss: 1.8470456685119085
Validation loss: 2.557045167683747

Epoch: 5| Step: 5
Training loss: 2.2929759244790335
Validation loss: 2.5541290779749115

Epoch: 5| Step: 6
Training loss: 2.1419795964228276
Validation loss: 2.569300342329978

Epoch: 5| Step: 7
Training loss: 2.3671743058947996
Validation loss: 2.5569383035274766

Epoch: 5| Step: 8
Training loss: 1.8760629184273951
Validation loss: 2.593874382143212

Epoch: 5| Step: 9
Training loss: 1.8290903525917839
Validation loss: 2.576244536794763

Epoch: 5| Step: 10
Training loss: 1.8621934318415996
Validation loss: 2.550782785702723

Epoch: 227| Step: 0
Training loss: 2.6820828155885295
Validation loss: 2.5326861995483254

Epoch: 5| Step: 1
Training loss: 2.1441724577834314
Validation loss: 2.542341777749601

Epoch: 5| Step: 2
Training loss: 2.1430006001908195
Validation loss: 2.5243321671005936

Epoch: 5| Step: 3
Training loss: 2.1760597804076327
Validation loss: 2.5118879186217025

Epoch: 5| Step: 4
Training loss: 1.455979855083656
Validation loss: 2.5217950976632815

Epoch: 5| Step: 5
Training loss: 2.343247219834937
Validation loss: 2.5325707479391717

Epoch: 5| Step: 6
Training loss: 2.0240306794853193
Validation loss: 2.550833020159711

Epoch: 5| Step: 7
Training loss: 2.0409266110224515
Validation loss: 2.5999580768805446

Epoch: 5| Step: 8
Training loss: 2.1235600248780946
Validation loss: 2.6195210558647974

Epoch: 5| Step: 9
Training loss: 2.29193809520213
Validation loss: 2.6026887341450693

Epoch: 5| Step: 10
Training loss: 2.036136325311718
Validation loss: 2.5784545986065517

Epoch: 228| Step: 0
Training loss: 2.209381742345728
Validation loss: 2.569495073030505

Epoch: 5| Step: 1
Training loss: 2.0919384307407936
Validation loss: 2.5496979562505464

Epoch: 5| Step: 2
Training loss: 2.096727446184063
Validation loss: 2.5369679343207205

Epoch: 5| Step: 3
Training loss: 1.9433691896737086
Validation loss: 2.5220425152471933

Epoch: 5| Step: 4
Training loss: 2.025307045723084
Validation loss: 2.530801006315445

Epoch: 5| Step: 5
Training loss: 1.6654175448453126
Validation loss: 2.5259508463994518

Epoch: 5| Step: 6
Training loss: 2.290478369376907
Validation loss: 2.537323015071252

Epoch: 5| Step: 7
Training loss: 2.1310991384859177
Validation loss: 2.54535371979972

Epoch: 5| Step: 8
Training loss: 1.9159933510826237
Validation loss: 2.5743362166171306

Epoch: 5| Step: 9
Training loss: 2.5821967136846995
Validation loss: 2.642094288241576

Epoch: 5| Step: 10
Training loss: 2.4713526659774376
Validation loss: 2.6690492471501783

Epoch: 229| Step: 0
Training loss: 1.9384062708642642
Validation loss: 2.64209898549002

Epoch: 5| Step: 1
Training loss: 1.7832281271778856
Validation loss: 2.5880026043196027

Epoch: 5| Step: 2
Training loss: 1.813836164261558
Validation loss: 2.57622481766619

Epoch: 5| Step: 3
Training loss: 2.3603497443233583
Validation loss: 2.552939049557793

Epoch: 5| Step: 4
Training loss: 2.452776161223076
Validation loss: 2.5322368302979124

Epoch: 5| Step: 5
Training loss: 2.239520144495266
Validation loss: 2.522737046767779

Epoch: 5| Step: 6
Training loss: 1.8568261893118734
Validation loss: 2.5307477085294052

Epoch: 5| Step: 7
Training loss: 2.381150463356797
Validation loss: 2.567602377595779

Epoch: 5| Step: 8
Training loss: 2.1388524645501628
Validation loss: 2.5601416599683655

Epoch: 5| Step: 9
Training loss: 1.9621722220992368
Validation loss: 2.567448201217396

Epoch: 5| Step: 10
Training loss: 2.1911527381632823
Validation loss: 2.5654003318179663

Epoch: 230| Step: 0
Training loss: 1.8453388157323936
Validation loss: 2.538201046335381

Epoch: 5| Step: 1
Training loss: 1.8776037575081543
Validation loss: 2.5368763164706456

Epoch: 5| Step: 2
Training loss: 1.9261265071863247
Validation loss: 2.5482785929499996

Epoch: 5| Step: 3
Training loss: 1.9892766293369364
Validation loss: 2.5557742630119815

Epoch: 5| Step: 4
Training loss: 2.2332964875137735
Validation loss: 2.574245069266132

Epoch: 5| Step: 5
Training loss: 2.1769737934012348
Validation loss: 2.632489004119276

Epoch: 5| Step: 6
Training loss: 2.3694108146953257
Validation loss: 2.59781645235275

Epoch: 5| Step: 7
Training loss: 2.16915053041279
Validation loss: 2.602522621902443

Epoch: 5| Step: 8
Training loss: 2.36025438909665
Validation loss: 2.599970877510331

Epoch: 5| Step: 9
Training loss: 2.163994412779867
Validation loss: 2.6341542499332107

Epoch: 5| Step: 10
Training loss: 1.829019311459864
Validation loss: 2.637167894521338

Epoch: 231| Step: 0
Training loss: 2.323435932048584
Validation loss: 2.646915092241623

Epoch: 5| Step: 1
Training loss: 2.4145733437867722
Validation loss: 2.636684382437624

Epoch: 5| Step: 2
Training loss: 1.9216876054909482
Validation loss: 2.5882260690220282

Epoch: 5| Step: 3
Training loss: 1.4213266677777685
Validation loss: 2.5431132309490905

Epoch: 5| Step: 4
Training loss: 2.521028106563037
Validation loss: 2.528531005647534

Epoch: 5| Step: 5
Training loss: 2.2741216829500406
Validation loss: 2.523521294703107

Epoch: 5| Step: 6
Training loss: 1.8323539661126904
Validation loss: 2.5077444368932866

Epoch: 5| Step: 7
Training loss: 1.8084306746387502
Validation loss: 2.5369432079426066

Epoch: 5| Step: 8
Training loss: 2.1341717200149275
Validation loss: 2.515122693861647

Epoch: 5| Step: 9
Training loss: 2.334132489089584
Validation loss: 2.492092573474718

Epoch: 5| Step: 10
Training loss: 1.835611062755154
Validation loss: 2.492063911905293

Epoch: 232| Step: 0
Training loss: 2.4281606507108218
Validation loss: 2.4999498095652783

Epoch: 5| Step: 1
Training loss: 2.2132717790815057
Validation loss: 2.498676029454815

Epoch: 5| Step: 2
Training loss: 2.150497614029264
Validation loss: 2.497848630003538

Epoch: 5| Step: 3
Training loss: 2.0683102696454894
Validation loss: 2.516656813683387

Epoch: 5| Step: 4
Training loss: 2.060164198210931
Validation loss: 2.5479988996935083

Epoch: 5| Step: 5
Training loss: 2.059695793948912
Validation loss: 2.5542412276167394

Epoch: 5| Step: 6
Training loss: 1.833963574828799
Validation loss: 2.5761784568191977

Epoch: 5| Step: 7
Training loss: 1.8242365246055892
Validation loss: 2.572918766401661

Epoch: 5| Step: 8
Training loss: 1.6772895907296521
Validation loss: 2.5934760923492224

Epoch: 5| Step: 9
Training loss: 1.8542891758368576
Validation loss: 2.613345785564409

Epoch: 5| Step: 10
Training loss: 2.3756382737043564
Validation loss: 2.5995938606249505

Epoch: 233| Step: 0
Training loss: 1.9178449353811147
Validation loss: 2.58802452095477

Epoch: 5| Step: 1
Training loss: 1.9554267442910813
Validation loss: 2.564885761379865

Epoch: 5| Step: 2
Training loss: 1.8850240421532691
Validation loss: 2.577331385023178

Epoch: 5| Step: 3
Training loss: 2.0789363109159864
Validation loss: 2.5808434645733023

Epoch: 5| Step: 4
Training loss: 1.6537946819286806
Validation loss: 2.5623817126417303

Epoch: 5| Step: 5
Training loss: 2.195765112650176
Validation loss: 2.575350701431688

Epoch: 5| Step: 6
Training loss: 1.9888758042092753
Validation loss: 2.558446449787163

Epoch: 5| Step: 7
Training loss: 2.1761034961448495
Validation loss: 2.6035747959690494

Epoch: 5| Step: 8
Training loss: 2.101699200690214
Validation loss: 2.597148449449416

Epoch: 5| Step: 9
Training loss: 2.2479779376240403
Validation loss: 2.5794629381284184

Epoch: 5| Step: 10
Training loss: 2.20290011076541
Validation loss: 2.566327656580606

Epoch: 234| Step: 0
Training loss: 1.8022814808949663
Validation loss: 2.5712557247438985

Epoch: 5| Step: 1
Training loss: 1.4861488585070217
Validation loss: 2.5540888423780292

Epoch: 5| Step: 2
Training loss: 1.9588355847462637
Validation loss: 2.5575307860379106

Epoch: 5| Step: 3
Training loss: 2.264699391675584
Validation loss: 2.552398732133528

Epoch: 5| Step: 4
Training loss: 1.7546495931170571
Validation loss: 2.5648812675585146

Epoch: 5| Step: 5
Training loss: 2.0736975293364917
Validation loss: 2.5373227453018603

Epoch: 5| Step: 6
Training loss: 2.463740420775272
Validation loss: 2.5448280008467594

Epoch: 5| Step: 7
Training loss: 2.100881246312699
Validation loss: 2.551100874833826

Epoch: 5| Step: 8
Training loss: 2.0692050490991183
Validation loss: 2.5679243842574073

Epoch: 5| Step: 9
Training loss: 2.1925235286829023
Validation loss: 2.5995299816855137

Epoch: 5| Step: 10
Training loss: 1.9010506686341517
Validation loss: 2.6060001703177167

Epoch: 235| Step: 0
Training loss: 1.4037385342572148
Validation loss: 2.609054554595728

Epoch: 5| Step: 1
Training loss: 2.206829446664386
Validation loss: 2.5870400506495144

Epoch: 5| Step: 2
Training loss: 2.083001746174652
Validation loss: 2.585523716424794

Epoch: 5| Step: 3
Training loss: 1.4946371213480945
Validation loss: 2.582455257264084

Epoch: 5| Step: 4
Training loss: 2.035393113540465
Validation loss: 2.5807956479915615

Epoch: 5| Step: 5
Training loss: 2.110171358463302
Validation loss: 2.584410597287013

Epoch: 5| Step: 6
Training loss: 1.919702620225515
Validation loss: 2.5889790364520686

Epoch: 5| Step: 7
Training loss: 2.5504883018155082
Validation loss: 2.5961850109437887

Epoch: 5| Step: 8
Training loss: 1.7015994177422291
Validation loss: 2.6256611563225425

Epoch: 5| Step: 9
Training loss: 2.3014457015204854
Validation loss: 2.628006913715865

Epoch: 5| Step: 10
Training loss: 1.678851394147675
Validation loss: 2.616338431914985

Epoch: 236| Step: 0
Training loss: 2.464069807178449
Validation loss: 2.6047489442301672

Epoch: 5| Step: 1
Training loss: 1.7864203120004905
Validation loss: 2.590238173236457

Epoch: 5| Step: 2
Training loss: 2.1410172374589123
Validation loss: 2.5806342707937415

Epoch: 5| Step: 3
Training loss: 1.764054874643582
Validation loss: 2.562079715552867

Epoch: 5| Step: 4
Training loss: 1.809460228475793
Validation loss: 2.575139405869196

Epoch: 5| Step: 5
Training loss: 1.8770762074709606
Validation loss: 2.577135193249638

Epoch: 5| Step: 6
Training loss: 2.3825361247891483
Validation loss: 2.6124002369612938

Epoch: 5| Step: 7
Training loss: 1.6276836976011788
Validation loss: 2.6508003710265817

Epoch: 5| Step: 8
Training loss: 1.6905395542629542
Validation loss: 2.6959621317716698

Epoch: 5| Step: 9
Training loss: 2.2483401003717605
Validation loss: 2.6928047183077473

Epoch: 5| Step: 10
Training loss: 2.1082652245578775
Validation loss: 2.656629570244353

Epoch: 237| Step: 0
Training loss: 1.8292959001055085
Validation loss: 2.635149352251118

Epoch: 5| Step: 1
Training loss: 2.1114940031175595
Validation loss: 2.6068288499497765

Epoch: 5| Step: 2
Training loss: 1.9829097354214955
Validation loss: 2.600815445723121

Epoch: 5| Step: 3
Training loss: 1.8560623022672114
Validation loss: 2.601392781392359

Epoch: 5| Step: 4
Training loss: 2.120973474735077
Validation loss: 2.587613220020541

Epoch: 5| Step: 5
Training loss: 1.912075272315429
Validation loss: 2.6153060044435863

Epoch: 5| Step: 6
Training loss: 2.108237744100659
Validation loss: 2.5860458572894127

Epoch: 5| Step: 7
Training loss: 1.905906896512799
Validation loss: 2.5958485905895765

Epoch: 5| Step: 8
Training loss: 1.9066449991186574
Validation loss: 2.56244909084361

Epoch: 5| Step: 9
Training loss: 1.5920598661198548
Validation loss: 2.60162662465383

Epoch: 5| Step: 10
Training loss: 2.530353528679844
Validation loss: 2.6239043272016844

Epoch: 238| Step: 0
Training loss: 1.484871148963865
Validation loss: 2.644324059126136

Epoch: 5| Step: 1
Training loss: 2.245484695786736
Validation loss: 2.6726154125943844

Epoch: 5| Step: 2
Training loss: 2.0142536081540046
Validation loss: 2.681514776501975

Epoch: 5| Step: 3
Training loss: 1.8941018158596368
Validation loss: 2.6646019491654247

Epoch: 5| Step: 4
Training loss: 1.778839823102888
Validation loss: 2.6249968601487343

Epoch: 5| Step: 5
Training loss: 2.0396911119838483
Validation loss: 2.6033486211463694

Epoch: 5| Step: 6
Training loss: 2.2005521211525383
Validation loss: 2.5968951911280027

Epoch: 5| Step: 7
Training loss: 1.6845732846441173
Validation loss: 2.632881414626987

Epoch: 5| Step: 8
Training loss: 1.7815843904064075
Validation loss: 2.6530843441382226

Epoch: 5| Step: 9
Training loss: 2.6126809564004834
Validation loss: 2.6669295191682236

Epoch: 5| Step: 10
Training loss: 1.7780542315997123
Validation loss: 2.6600024901211956

Epoch: 239| Step: 0
Training loss: 1.9723931165390571
Validation loss: 2.613345162641868

Epoch: 5| Step: 1
Training loss: 1.7690966748290942
Validation loss: 2.5839938478111195

Epoch: 5| Step: 2
Training loss: 2.158958061365733
Validation loss: 2.5573726572975315

Epoch: 5| Step: 3
Training loss: 1.8691262112084657
Validation loss: 2.561552700500011

Epoch: 5| Step: 4
Training loss: 2.330286034311879
Validation loss: 2.543605010523519

Epoch: 5| Step: 5
Training loss: 1.94613090978893
Validation loss: 2.545837071066608

Epoch: 5| Step: 6
Training loss: 1.5410925165484932
Validation loss: 2.588326613821046

Epoch: 5| Step: 7
Training loss: 1.6333093206755465
Validation loss: 2.5978450499594046

Epoch: 5| Step: 8
Training loss: 1.9082712807485118
Validation loss: 2.6255511395279543

Epoch: 5| Step: 9
Training loss: 2.1858343049586653
Validation loss: 2.643309740315222

Epoch: 5| Step: 10
Training loss: 1.9434371549290426
Validation loss: 2.7102946623650723

Epoch: 240| Step: 0
Training loss: 1.6434175974744583
Validation loss: 2.6632063729027964

Epoch: 5| Step: 1
Training loss: 1.845274408191169
Validation loss: 2.6244793427805813

Epoch: 5| Step: 2
Training loss: 1.6733830860740733
Validation loss: 2.6190591867545954

Epoch: 5| Step: 3
Training loss: 2.062383243839567
Validation loss: 2.5981498767989826

Epoch: 5| Step: 4
Training loss: 1.9661227664899656
Validation loss: 2.603632687531082

Epoch: 5| Step: 5
Training loss: 2.0320214787196584
Validation loss: 2.605736057697347

Epoch: 5| Step: 6
Training loss: 2.057458206067466
Validation loss: 2.5885180829636156

Epoch: 5| Step: 7
Training loss: 2.254650925136743
Validation loss: 2.6052274181876327

Epoch: 5| Step: 8
Training loss: 1.42635862600449
Validation loss: 2.645953782136701

Epoch: 5| Step: 9
Training loss: 1.6029592238705648
Validation loss: 2.6887789919258265

Epoch: 5| Step: 10
Training loss: 2.4330527008783562
Validation loss: 2.7450958722857353

Epoch: 241| Step: 0
Training loss: 1.7051644669352883
Validation loss: 2.73207638461297

Epoch: 5| Step: 1
Training loss: 1.893644270762406
Validation loss: 2.7631143286194724

Epoch: 5| Step: 2
Training loss: 2.0186892143050192
Validation loss: 2.734953171505984

Epoch: 5| Step: 3
Training loss: 1.276158801041894
Validation loss: 2.7097581193629283

Epoch: 5| Step: 4
Training loss: 2.0282583654253035
Validation loss: 2.681327171562306

Epoch: 5| Step: 5
Training loss: 2.106554872991056
Validation loss: 2.6280161000545856

Epoch: 5| Step: 6
Training loss: 1.803059359567212
Validation loss: 2.6079353328708463

Epoch: 5| Step: 7
Training loss: 1.8536128670816736
Validation loss: 2.6128516053479034

Epoch: 5| Step: 8
Training loss: 1.875386833976882
Validation loss: 2.606538826408428

Epoch: 5| Step: 9
Training loss: 1.9666158219677754
Validation loss: 2.6212183769862554

Epoch: 5| Step: 10
Training loss: 2.253722290782728
Validation loss: 2.626854818913728

Epoch: 242| Step: 0
Training loss: 1.9443587450790631
Validation loss: 2.6646485697301117

Epoch: 5| Step: 1
Training loss: 1.9656679157854502
Validation loss: 2.687050769688934

Epoch: 5| Step: 2
Training loss: 1.8676605902159984
Validation loss: 2.7117076277658017

Epoch: 5| Step: 3
Training loss: 1.8518898590037642
Validation loss: 2.7102867310657635

Epoch: 5| Step: 4
Training loss: 1.791374678069441
Validation loss: 2.6367030757558183

Epoch: 5| Step: 5
Training loss: 1.8766059355906068
Validation loss: 2.6394888092499302

Epoch: 5| Step: 6
Training loss: 1.5012676128081641
Validation loss: 2.6074413945750705

Epoch: 5| Step: 7
Training loss: 2.1193024041789994
Validation loss: 2.624605412864805

Epoch: 5| Step: 8
Training loss: 1.6931890030173729
Validation loss: 2.6140609410216222

Epoch: 5| Step: 9
Training loss: 2.108144669767574
Validation loss: 2.6165062292086336

Epoch: 5| Step: 10
Training loss: 1.9029102774319915
Validation loss: 2.5949531805818546

Epoch: 243| Step: 0
Training loss: 2.169158993723436
Validation loss: 2.601584247218725

Epoch: 5| Step: 1
Training loss: 1.8994071587679806
Validation loss: 2.612955207534252

Epoch: 5| Step: 2
Training loss: 1.6319165121443109
Validation loss: 2.6013535365116867

Epoch: 5| Step: 3
Training loss: 1.7640788642658143
Validation loss: 2.6040508206759916

Epoch: 5| Step: 4
Training loss: 1.5090199117996301
Validation loss: 2.6213438743239834

Epoch: 5| Step: 5
Training loss: 2.092101857581298
Validation loss: 2.619937846086787

Epoch: 5| Step: 6
Training loss: 1.6126495676389156
Validation loss: 2.6056343635163737

Epoch: 5| Step: 7
Training loss: 1.6847257769069226
Validation loss: 2.6162462452325443

Epoch: 5| Step: 8
Training loss: 1.8239194963533496
Validation loss: 2.6367051749295856

Epoch: 5| Step: 9
Training loss: 1.9405670501361758
Validation loss: 2.61396912123941

Epoch: 5| Step: 10
Training loss: 2.082184233063905
Validation loss: 2.614327048550763

Epoch: 244| Step: 0
Training loss: 2.133048802514535
Validation loss: 2.6146705285082645

Epoch: 5| Step: 1
Training loss: 1.5687696174519639
Validation loss: 2.6345971787944533

Epoch: 5| Step: 2
Training loss: 2.1072167552154415
Validation loss: 2.669057198215747

Epoch: 5| Step: 3
Training loss: 2.132112828445112
Validation loss: 2.64720414371895

Epoch: 5| Step: 4
Training loss: 2.0063098078574457
Validation loss: 2.6666040881054

Epoch: 5| Step: 5
Training loss: 1.8143862413248013
Validation loss: 2.6606647400046985

Epoch: 5| Step: 6
Training loss: 1.7691804314950978
Validation loss: 2.6301891799338217

Epoch: 5| Step: 7
Training loss: 1.6625513370016258
Validation loss: 2.6548701281070826

Epoch: 5| Step: 8
Training loss: 1.6299716749246038
Validation loss: 2.659925167355118

Epoch: 5| Step: 9
Training loss: 1.6660285761375637
Validation loss: 2.6336700599819944

Epoch: 5| Step: 10
Training loss: 1.6049147343788905
Validation loss: 2.602680426666982

Epoch: 245| Step: 0
Training loss: 1.6130568969492087
Validation loss: 2.613242226331092

Epoch: 5| Step: 1
Training loss: 2.0386571956353814
Validation loss: 2.640675425267978

Epoch: 5| Step: 2
Training loss: 2.0486242376506834
Validation loss: 2.618253617287453

Epoch: 5| Step: 3
Training loss: 1.8386857910148309
Validation loss: 2.6194163206688863

Epoch: 5| Step: 4
Training loss: 1.5928874954371752
Validation loss: 2.551043262884087

Epoch: 5| Step: 5
Training loss: 2.082295642548112
Validation loss: 2.5500918748620642

Epoch: 5| Step: 6
Training loss: 2.062424629452638
Validation loss: 2.535583736119075

Epoch: 5| Step: 7
Training loss: 1.7669503967801123
Validation loss: 2.555045874521165

Epoch: 5| Step: 8
Training loss: 1.5340513179307014
Validation loss: 2.5607722350556297

Epoch: 5| Step: 9
Training loss: 1.717006700905914
Validation loss: 2.5549188133922605

Epoch: 5| Step: 10
Training loss: 1.6417351735855537
Validation loss: 2.5758495562525874

Epoch: 246| Step: 0
Training loss: 2.0028811206630066
Validation loss: 2.606018474803772

Epoch: 5| Step: 1
Training loss: 1.7888300715558043
Validation loss: 2.6331061226906325

Epoch: 5| Step: 2
Training loss: 1.6582794711057516
Validation loss: 2.6459559631092984

Epoch: 5| Step: 3
Training loss: 1.4368454645480528
Validation loss: 2.6503172372864836

Epoch: 5| Step: 4
Training loss: 1.7473806806003038
Validation loss: 2.66133279173007

Epoch: 5| Step: 5
Training loss: 1.749616308383784
Validation loss: 2.666560475352632

Epoch: 5| Step: 6
Training loss: 2.0286879594286935
Validation loss: 2.6971845192053925

Epoch: 5| Step: 7
Training loss: 1.4630041345784295
Validation loss: 2.687737178996628

Epoch: 5| Step: 8
Training loss: 2.0103800346977017
Validation loss: 2.6502180837467804

Epoch: 5| Step: 9
Training loss: 1.8175031077949997
Validation loss: 2.687508056735387

Epoch: 5| Step: 10
Training loss: 1.8014081083181106
Validation loss: 2.692452751323471

Epoch: 247| Step: 0
Training loss: 2.13397721567477
Validation loss: 2.6872383308895262

Epoch: 5| Step: 1
Training loss: 1.9564641256418953
Validation loss: 2.663633756702572

Epoch: 5| Step: 2
Training loss: 1.2825727380422292
Validation loss: 2.651245543222778

Epoch: 5| Step: 3
Training loss: 1.7968249106681982
Validation loss: 2.6219078227645576

Epoch: 5| Step: 4
Training loss: 1.7652410579250157
Validation loss: 2.5743038773335614

Epoch: 5| Step: 5
Training loss: 1.3804892727892064
Validation loss: 2.5846793081773782

Epoch: 5| Step: 6
Training loss: 1.5597176765850465
Validation loss: 2.568364163182209

Epoch: 5| Step: 7
Training loss: 1.988012509274031
Validation loss: 2.5907786973652276

Epoch: 5| Step: 8
Training loss: 2.0328703066488982
Validation loss: 2.606941375820068

Epoch: 5| Step: 9
Training loss: 1.854912668521895
Validation loss: 2.627676059252384

Epoch: 5| Step: 10
Training loss: 1.168542676274478
Validation loss: 2.62958889618575

Epoch: 248| Step: 0
Training loss: 1.9018896293265528
Validation loss: 2.68393921630499

Epoch: 5| Step: 1
Training loss: 1.6835742073075455
Validation loss: 2.7172678112166384

Epoch: 5| Step: 2
Training loss: 1.404411852378126
Validation loss: 2.7011908547272023

Epoch: 5| Step: 3
Training loss: 1.5939321226890788
Validation loss: 2.703810049799562

Epoch: 5| Step: 4
Training loss: 1.7706714182113947
Validation loss: 2.7281754885727443

Epoch: 5| Step: 5
Training loss: 1.8583782954685528
Validation loss: 2.667707169740941

Epoch: 5| Step: 6
Training loss: 1.7445189609257037
Validation loss: 2.661639217509199

Epoch: 5| Step: 7
Training loss: 1.6213325784162804
Validation loss: 2.635117072442307

Epoch: 5| Step: 8
Training loss: 1.7767487923975103
Validation loss: 2.6357982520887875

Epoch: 5| Step: 9
Training loss: 1.624373315132914
Validation loss: 2.597054701064388

Epoch: 5| Step: 10
Training loss: 2.1281297860112756
Validation loss: 2.6087175503473468

Epoch: 249| Step: 0
Training loss: 1.4801839992483568
Validation loss: 2.6146889198579872

Epoch: 5| Step: 1
Training loss: 1.5543378120394378
Validation loss: 2.6131952792385533

Epoch: 5| Step: 2
Training loss: 2.168912994679872
Validation loss: 2.620080175598501

Epoch: 5| Step: 3
Training loss: 1.491284321776114
Validation loss: 2.60648489528727

Epoch: 5| Step: 4
Training loss: 2.0786897279187277
Validation loss: 2.588556170085067

Epoch: 5| Step: 5
Training loss: 1.4723387358202684
Validation loss: 2.592421462129542

Epoch: 5| Step: 6
Training loss: 1.5524778526065557
Validation loss: 2.5846094733301284

Epoch: 5| Step: 7
Training loss: 1.5507176768150435
Validation loss: 2.6175799645365734

Epoch: 5| Step: 8
Training loss: 1.7547194331075184
Validation loss: 2.6116480951169603

Epoch: 5| Step: 9
Training loss: 1.785740195495102
Validation loss: 2.6358962897919835

Epoch: 5| Step: 10
Training loss: 1.7614015687007076
Validation loss: 2.594389420413819

Epoch: 250| Step: 0
Training loss: 1.6269388369955218
Validation loss: 2.6203215209274204

Epoch: 5| Step: 1
Training loss: 2.286330223115121
Validation loss: 2.6239560107516438

Epoch: 5| Step: 2
Training loss: 1.2856826399889838
Validation loss: 2.654647660420179

Epoch: 5| Step: 3
Training loss: 1.1730990819654123
Validation loss: 2.667719211882845

Epoch: 5| Step: 4
Training loss: 1.4207623498511772
Validation loss: 2.6885277141701622

Epoch: 5| Step: 5
Training loss: 1.8524904139138152
Validation loss: 2.7069003861890697

Epoch: 5| Step: 6
Training loss: 1.9156649985190268
Validation loss: 2.664053390805398

Epoch: 5| Step: 7
Training loss: 1.7892998283923827
Validation loss: 2.651825955626236

Epoch: 5| Step: 8
Training loss: 1.516127984655957
Validation loss: 2.600805188441274

Epoch: 5| Step: 9
Training loss: 1.8473265275053172
Validation loss: 2.592273736323695

Epoch: 5| Step: 10
Training loss: 1.716601537499822
Validation loss: 2.573588655468419

Epoch: 251| Step: 0
Training loss: 1.6769117974485477
Validation loss: 2.5676021848935657

Epoch: 5| Step: 1
Training loss: 1.601331145160926
Validation loss: 2.6162777877888845

Epoch: 5| Step: 2
Training loss: 1.6273884459907804
Validation loss: 2.6690674083558106

Epoch: 5| Step: 3
Training loss: 1.3377734501892957
Validation loss: 2.686991031697663

Epoch: 5| Step: 4
Training loss: 1.649374022373316
Validation loss: 2.692367955550604

Epoch: 5| Step: 5
Training loss: 1.9661160969959162
Validation loss: 2.6951967171412505

Epoch: 5| Step: 6
Training loss: 1.9653772194921466
Validation loss: 2.6534608069607053

Epoch: 5| Step: 7
Training loss: 1.7472644951738048
Validation loss: 2.6530835711085934

Epoch: 5| Step: 8
Training loss: 1.6987929939853101
Validation loss: 2.621350878658623

Epoch: 5| Step: 9
Training loss: 1.549130346533547
Validation loss: 2.6306177471042202

Epoch: 5| Step: 10
Training loss: 1.636958138887818
Validation loss: 2.673367373109869

Epoch: 252| Step: 0
Training loss: 1.8923585368692075
Validation loss: 2.686614951340305

Epoch: 5| Step: 1
Training loss: 1.4535391432744025
Validation loss: 2.704734136462128

Epoch: 5| Step: 2
Training loss: 1.6677867781206834
Validation loss: 2.6757116275307853

Epoch: 5| Step: 3
Training loss: 1.834498389284181
Validation loss: 2.649418724515609

Epoch: 5| Step: 4
Training loss: 1.8005978041941715
Validation loss: 2.6530682322215973

Epoch: 5| Step: 5
Training loss: 1.8207135720516963
Validation loss: 2.6238376868551443

Epoch: 5| Step: 6
Training loss: 1.388470985271539
Validation loss: 2.5962770015105106

Epoch: 5| Step: 7
Training loss: 1.4642057529907007
Validation loss: 2.5964423067663938

Epoch: 5| Step: 8
Training loss: 1.8776116937564933
Validation loss: 2.565202176174851

Epoch: 5| Step: 9
Training loss: 1.2856014141613838
Validation loss: 2.6064358740744313

Epoch: 5| Step: 10
Training loss: 1.8098709507244894
Validation loss: 2.6425907812675002

Epoch: 253| Step: 0
Training loss: 2.110832219636214
Validation loss: 2.6901266602980414

Epoch: 5| Step: 1
Training loss: 1.3766929001806378
Validation loss: 2.674207012106452

Epoch: 5| Step: 2
Training loss: 1.8132394400414957
Validation loss: 2.6500284866733623

Epoch: 5| Step: 3
Training loss: 1.3966064826559217
Validation loss: 2.6381036252463

Epoch: 5| Step: 4
Training loss: 2.0963708217425223
Validation loss: 2.63854107582243

Epoch: 5| Step: 5
Training loss: 1.403915374675259
Validation loss: 2.6087388192839103

Epoch: 5| Step: 6
Training loss: 1.478558034553175
Validation loss: 2.623184124888163

Epoch: 5| Step: 7
Training loss: 1.6572212394489496
Validation loss: 2.6153258033571625

Epoch: 5| Step: 8
Training loss: 1.2650617123051948
Validation loss: 2.6224900945923735

Epoch: 5| Step: 9
Training loss: 1.6967549318438926
Validation loss: 2.6535324740191064

Epoch: 5| Step: 10
Training loss: 1.6617013719633744
Validation loss: 2.680075609298899

Epoch: 254| Step: 0
Training loss: 1.43024996340131
Validation loss: 2.7195522297324106

Epoch: 5| Step: 1
Training loss: 1.3303063822760859
Validation loss: 2.7347586188934425

Epoch: 5| Step: 2
Training loss: 1.8424029844666532
Validation loss: 2.731279996059247

Epoch: 5| Step: 3
Training loss: 1.6455253441666213
Validation loss: 2.7088436674506498

Epoch: 5| Step: 4
Training loss: 1.2660673804740132
Validation loss: 2.732533098046322

Epoch: 5| Step: 5
Training loss: 1.466081020442662
Validation loss: 2.721672651249412

Epoch: 5| Step: 6
Training loss: 1.6447390608521604
Validation loss: 2.7152998733415283

Epoch: 5| Step: 7
Training loss: 1.701410112659485
Validation loss: 2.700210474820226

Epoch: 5| Step: 8
Training loss: 1.9317010420712961
Validation loss: 2.6840271294806297

Epoch: 5| Step: 9
Training loss: 1.8231264556784796
Validation loss: 2.6541223535405734

Epoch: 5| Step: 10
Training loss: 1.5821614529754067
Validation loss: 2.640652218502602

Epoch: 255| Step: 0
Training loss: 1.5955057383941869
Validation loss: 2.6333555343936115

Epoch: 5| Step: 1
Training loss: 1.2205948682465577
Validation loss: 2.6366325380731053

Epoch: 5| Step: 2
Training loss: 1.6684240215676645
Validation loss: 2.649419565380565

Epoch: 5| Step: 3
Training loss: 1.9167502702917065
Validation loss: 2.627240653968464

Epoch: 5| Step: 4
Training loss: 1.34192751230472
Validation loss: 2.6037203170384644

Epoch: 5| Step: 5
Training loss: 1.5408458156846885
Validation loss: 2.5590585248437057

Epoch: 5| Step: 6
Training loss: 1.7657459858990903
Validation loss: 2.539008099877968

Epoch: 5| Step: 7
Training loss: 1.5124959204752737
Validation loss: 2.5574312438694493

Epoch: 5| Step: 8
Training loss: 1.6709097812251918
Validation loss: 2.592983279303227

Epoch: 5| Step: 9
Training loss: 1.973724197016098
Validation loss: 2.6200776198627382

Epoch: 5| Step: 10
Training loss: 1.4377681647904208
Validation loss: 2.609816861285411

Epoch: 256| Step: 0
Training loss: 1.2741630687043257
Validation loss: 2.6534918482061545

Epoch: 5| Step: 1
Training loss: 1.6940515284982554
Validation loss: 2.701358012549743

Epoch: 5| Step: 2
Training loss: 1.5267399133299397
Validation loss: 2.7134126571879276

Epoch: 5| Step: 3
Training loss: 1.6527960408516924
Validation loss: 2.7679408653590176

Epoch: 5| Step: 4
Training loss: 1.3561070063576328
Validation loss: 2.7282208686694616

Epoch: 5| Step: 5
Training loss: 1.5181966770506117
Validation loss: 2.7522451179954723

Epoch: 5| Step: 6
Training loss: 1.9223735131768276
Validation loss: 2.7563018086696416

Epoch: 5| Step: 7
Training loss: 1.8005699315069854
Validation loss: 2.680036735564513

Epoch: 5| Step: 8
Training loss: 1.7219141185491613
Validation loss: 2.6379109222171624

Epoch: 5| Step: 9
Training loss: 1.5213839261510331
Validation loss: 2.610440832399609

Epoch: 5| Step: 10
Training loss: 1.7193734165463077
Validation loss: 2.5780557284428705

Epoch: 257| Step: 0
Training loss: 2.079820557886914
Validation loss: 2.5423758092592483

Epoch: 5| Step: 1
Training loss: 1.1578779873879947
Validation loss: 2.5410851304674433

Epoch: 5| Step: 2
Training loss: 1.9972607808583136
Validation loss: 2.546151154020188

Epoch: 5| Step: 3
Training loss: 1.4813331355333124
Validation loss: 2.569485949848354

Epoch: 5| Step: 4
Training loss: 1.5657737767842799
Validation loss: 2.603385907352721

Epoch: 5| Step: 5
Training loss: 1.9004799487615047
Validation loss: 2.6416524398041226

Epoch: 5| Step: 6
Training loss: 1.2444236349644187
Validation loss: 2.6516487210967434

Epoch: 5| Step: 7
Training loss: 1.7224642761246558
Validation loss: 2.6431446484839265

Epoch: 5| Step: 8
Training loss: 1.315399600041024
Validation loss: 2.65211557287624

Epoch: 5| Step: 9
Training loss: 1.6557906611485502
Validation loss: 2.6625136298096943

Epoch: 5| Step: 10
Training loss: 1.6664405987325213
Validation loss: 2.631015937154651

Epoch: 258| Step: 0
Training loss: 1.7221287202918807
Validation loss: 2.626993050671932

Epoch: 5| Step: 1
Training loss: 1.6181897729409274
Validation loss: 2.6302865071082855

Epoch: 5| Step: 2
Training loss: 1.574260095853208
Validation loss: 2.657733344295515

Epoch: 5| Step: 3
Training loss: 1.8292330782687505
Validation loss: 2.67643538011662

Epoch: 5| Step: 4
Training loss: 1.8400250323292857
Validation loss: 2.6722677120096723

Epoch: 5| Step: 5
Training loss: 1.554535518099368
Validation loss: 2.6578224290891383

Epoch: 5| Step: 6
Training loss: 1.6535627048854353
Validation loss: 2.6491569596679807

Epoch: 5| Step: 7
Training loss: 1.520079839767898
Validation loss: 2.664002554460869

Epoch: 5| Step: 8
Training loss: 1.1017943875430045
Validation loss: 2.662023796614152

Epoch: 5| Step: 9
Training loss: 1.3205292653571419
Validation loss: 2.6544876699511284

Epoch: 5| Step: 10
Training loss: 1.5256906915170063
Validation loss: 2.677379203168658

Epoch: 259| Step: 0
Training loss: 1.650562670165332
Validation loss: 2.6435931250333664

Epoch: 5| Step: 1
Training loss: 1.7605375741222453
Validation loss: 2.6297169713233033

Epoch: 5| Step: 2
Training loss: 1.2969381477884143
Validation loss: 2.6326671506787127

Epoch: 5| Step: 3
Training loss: 1.372018963813401
Validation loss: 2.6114826607498833

Epoch: 5| Step: 4
Training loss: 1.6884356130264302
Validation loss: 2.6310537842128756

Epoch: 5| Step: 5
Training loss: 1.0527808580770082
Validation loss: 2.6145368509083218

Epoch: 5| Step: 6
Training loss: 1.758481114702336
Validation loss: 2.602812871343526

Epoch: 5| Step: 7
Training loss: 1.5827535605118657
Validation loss: 2.5930317639048788

Epoch: 5| Step: 8
Training loss: 1.7108988300290724
Validation loss: 2.5866994300074433

Epoch: 5| Step: 9
Training loss: 1.4685724029304534
Validation loss: 2.566844308503179

Epoch: 5| Step: 10
Training loss: 1.7175553071113752
Validation loss: 2.6059374710433483

Epoch: 260| Step: 0
Training loss: 1.5416242318714022
Validation loss: 2.6431047213978673

Epoch: 5| Step: 1
Training loss: 1.411744552064074
Validation loss: 2.663655975958772

Epoch: 5| Step: 2
Training loss: 1.4570683124318144
Validation loss: 2.6870023558093648

Epoch: 5| Step: 3
Training loss: 1.7149406527379687
Validation loss: 2.6617250278580578

Epoch: 5| Step: 4
Training loss: 1.1989914868253804
Validation loss: 2.674603725687685

Epoch: 5| Step: 5
Training loss: 1.8124388322703295
Validation loss: 2.659873313349621

Epoch: 5| Step: 6
Training loss: 1.2400613498892938
Validation loss: 2.6568428608481374

Epoch: 5| Step: 7
Training loss: 1.2733304967565715
Validation loss: 2.687631113069273

Epoch: 5| Step: 8
Training loss: 1.893462770541775
Validation loss: 2.659734837642521

Epoch: 5| Step: 9
Training loss: 1.6885239355657335
Validation loss: 2.656121925388573

Epoch: 5| Step: 10
Training loss: 1.6408210273979962
Validation loss: 2.627431878838918

Epoch: 261| Step: 0
Training loss: 1.4248240144711715
Validation loss: 2.6258341347306255

Epoch: 5| Step: 1
Training loss: 1.9402579090894538
Validation loss: 2.625499740276208

Epoch: 5| Step: 2
Training loss: 1.1946006600052885
Validation loss: 2.556243987299131

Epoch: 5| Step: 3
Training loss: 1.8510995278003044
Validation loss: 2.5632525183712365

Epoch: 5| Step: 4
Training loss: 1.5921691084858038
Validation loss: 2.5581102360386394

Epoch: 5| Step: 5
Training loss: 1.3804356034017524
Validation loss: 2.549559993209083

Epoch: 5| Step: 6
Training loss: 1.7440922336336995
Validation loss: 2.567906425702588

Epoch: 5| Step: 7
Training loss: 1.2638645880089845
Validation loss: 2.591306873317105

Epoch: 5| Step: 8
Training loss: 1.2738550355859266
Validation loss: 2.6500566195172044

Epoch: 5| Step: 9
Training loss: 1.4218490933583836
Validation loss: 2.701990357345385

Epoch: 5| Step: 10
Training loss: 1.7911419506720496
Validation loss: 2.6988411533859584

Epoch: 262| Step: 0
Training loss: 1.48244809013176
Validation loss: 2.6873854870067273

Epoch: 5| Step: 1
Training loss: 2.0142977580838033
Validation loss: 2.6893045358139687

Epoch: 5| Step: 2
Training loss: 1.7734163930031808
Validation loss: 2.6549453108095498

Epoch: 5| Step: 3
Training loss: 1.5927625102610299
Validation loss: 2.6113917109197344

Epoch: 5| Step: 4
Training loss: 0.936911684454309
Validation loss: 2.599953487885763

Epoch: 5| Step: 5
Training loss: 1.5389514244003344
Validation loss: 2.583449285354817

Epoch: 5| Step: 6
Training loss: 1.5248444931289578
Validation loss: 2.5631553598210273

Epoch: 5| Step: 7
Training loss: 1.5774813557534155
Validation loss: 2.569762105317127

Epoch: 5| Step: 8
Training loss: 1.236297558833002
Validation loss: 2.57516446733778

Epoch: 5| Step: 9
Training loss: 1.5562195250196837
Validation loss: 2.5910795252261725

Epoch: 5| Step: 10
Training loss: 1.4158303185592327
Validation loss: 2.6545532115341044

Epoch: 263| Step: 0
Training loss: 1.2740424655801559
Validation loss: 2.683794808556961

Epoch: 5| Step: 1
Training loss: 1.2262017758343053
Validation loss: 2.640513275573175

Epoch: 5| Step: 2
Training loss: 1.7441938676215183
Validation loss: 2.6557238700155255

Epoch: 5| Step: 3
Training loss: 1.0447511907909843
Validation loss: 2.64456490389689

Epoch: 5| Step: 4
Training loss: 1.8380689220311737
Validation loss: 2.5911828819063047

Epoch: 5| Step: 5
Training loss: 1.8239078624400895
Validation loss: 2.606011639779897

Epoch: 5| Step: 6
Training loss: 1.1465834618661759
Validation loss: 2.5621231681415266

Epoch: 5| Step: 7
Training loss: 1.2503192493930628
Validation loss: 2.5608808242538874

Epoch: 5| Step: 8
Training loss: 1.5945039349636305
Validation loss: 2.569373874938696

Epoch: 5| Step: 9
Training loss: 1.646107477783549
Validation loss: 2.5841596005116996

Epoch: 5| Step: 10
Training loss: 1.6872692656836532
Validation loss: 2.578378189994028

Epoch: 264| Step: 0
Training loss: 1.3454269768083684
Validation loss: 2.605024505755684

Epoch: 5| Step: 1
Training loss: 1.670919626660102
Validation loss: 2.649488053854364

Epoch: 5| Step: 2
Training loss: 1.4667087736732263
Validation loss: 2.639210201045943

Epoch: 5| Step: 3
Training loss: 1.4444040278543129
Validation loss: 2.6654412177084894

Epoch: 5| Step: 4
Training loss: 1.4326363258669674
Validation loss: 2.6991273557548148

Epoch: 5| Step: 5
Training loss: 1.43477255769961
Validation loss: 2.6337350961045343

Epoch: 5| Step: 6
Training loss: 1.2260542381417787
Validation loss: 2.6014576370088442

Epoch: 5| Step: 7
Training loss: 1.7272456962122147
Validation loss: 2.577491222451905

Epoch: 5| Step: 8
Training loss: 1.5718680501067548
Validation loss: 2.554614307340634

Epoch: 5| Step: 9
Training loss: 1.643101521495119
Validation loss: 2.555369958547925

Epoch: 5| Step: 10
Training loss: 1.310999966793802
Validation loss: 2.596466585012325

Epoch: 265| Step: 0
Training loss: 1.2901344235193137
Validation loss: 2.583770694751887

Epoch: 5| Step: 1
Training loss: 1.3972479166727578
Validation loss: 2.6299776833664064

Epoch: 5| Step: 2
Training loss: 1.4758905567180602
Validation loss: 2.63969342140524

Epoch: 5| Step: 3
Training loss: 1.816508103663132
Validation loss: 2.6753150791948963

Epoch: 5| Step: 4
Training loss: 1.532029245580503
Validation loss: 2.7040912324583672

Epoch: 5| Step: 5
Training loss: 1.7588303395394058
Validation loss: 2.6925964290959765

Epoch: 5| Step: 6
Training loss: 1.4206919516794527
Validation loss: 2.6722548106366797

Epoch: 5| Step: 7
Training loss: 1.0619543581851378
Validation loss: 2.6633646816766308

Epoch: 5| Step: 8
Training loss: 1.5657201010931172
Validation loss: 2.6483636080399586

Epoch: 5| Step: 9
Training loss: 1.3590842626692718
Validation loss: 2.6551580724249018

Epoch: 5| Step: 10
Training loss: 1.3935512229913793
Validation loss: 2.6692866460820515

Epoch: 266| Step: 0
Training loss: 1.2969791416499812
Validation loss: 2.6294000804154476

Epoch: 5| Step: 1
Training loss: 1.727324787865695
Validation loss: 2.620712986910864

Epoch: 5| Step: 2
Training loss: 1.947735422715633
Validation loss: 2.5837029111023235

Epoch: 5| Step: 3
Training loss: 1.6946841011386098
Validation loss: 2.587619311056077

Epoch: 5| Step: 4
Training loss: 1.4226000268291255
Validation loss: 2.6002795999092654

Epoch: 5| Step: 5
Training loss: 1.1719536818475103
Validation loss: 2.641512381950758

Epoch: 5| Step: 6
Training loss: 0.9821170159445424
Validation loss: 2.645292059274372

Epoch: 5| Step: 7
Training loss: 1.4342955656641478
Validation loss: 2.6525728585055357

Epoch: 5| Step: 8
Training loss: 1.5710920989237969
Validation loss: 2.6670794731483216

Epoch: 5| Step: 9
Training loss: 1.471031527183318
Validation loss: 2.6889127407868116

Epoch: 5| Step: 10
Training loss: 1.1250729007412905
Validation loss: 2.6849290169324402

Epoch: 267| Step: 0
Training loss: 1.6408750071092217
Validation loss: 2.6568874957394693

Epoch: 5| Step: 1
Training loss: 1.4411089830980068
Validation loss: 2.631353961224737

Epoch: 5| Step: 2
Training loss: 1.4678752810537956
Validation loss: 2.5807518049990796

Epoch: 5| Step: 3
Training loss: 1.2814767683366561
Validation loss: 2.5796716867726213

Epoch: 5| Step: 4
Training loss: 1.6240770212991933
Validation loss: 2.5892039634609327

Epoch: 5| Step: 5
Training loss: 1.530781343325162
Validation loss: 2.5919559380894888

Epoch: 5| Step: 6
Training loss: 1.5970432439215045
Validation loss: 2.6150023353396983

Epoch: 5| Step: 7
Training loss: 1.622323619853946
Validation loss: 2.6261161896097405

Epoch: 5| Step: 8
Training loss: 1.2801439116460838
Validation loss: 2.635935618032409

Epoch: 5| Step: 9
Training loss: 1.1715979184962804
Validation loss: 2.6765426166921484

Epoch: 5| Step: 10
Training loss: 1.1666201457330645
Validation loss: 2.6943157163039437

Epoch: 268| Step: 0
Training loss: 1.2522085229847726
Validation loss: 2.669719193582343

Epoch: 5| Step: 1
Training loss: 1.574532678695656
Validation loss: 2.6555528820195606

Epoch: 5| Step: 2
Training loss: 1.4418609646236844
Validation loss: 2.6692072439635424

Epoch: 5| Step: 3
Training loss: 0.9587426279075515
Validation loss: 2.644467301956581

Epoch: 5| Step: 4
Training loss: 1.8281110453276825
Validation loss: 2.6322891943639264

Epoch: 5| Step: 5
Training loss: 1.2572232400288164
Validation loss: 2.636795796583156

Epoch: 5| Step: 6
Training loss: 1.445782889036748
Validation loss: 2.594205553158458

Epoch: 5| Step: 7
Training loss: 1.0044207608920122
Validation loss: 2.5956717156327347

Epoch: 5| Step: 8
Training loss: 1.537289833032945
Validation loss: 2.6221305508588846

Epoch: 5| Step: 9
Training loss: 1.744149852014892
Validation loss: 2.597481522415096

Epoch: 5| Step: 10
Training loss: 1.419383790540329
Validation loss: 2.6032502814346725

Epoch: 269| Step: 0
Training loss: 1.3492196123377744
Validation loss: 2.6143399837724606

Epoch: 5| Step: 1
Training loss: 1.2830309237011401
Validation loss: 2.617132976259736

Epoch: 5| Step: 2
Training loss: 1.3107417454929826
Validation loss: 2.613251849130097

Epoch: 5| Step: 3
Training loss: 1.6994531930132468
Validation loss: 2.6271399502952777

Epoch: 5| Step: 4
Training loss: 1.4206979092283794
Validation loss: 2.627722387628985

Epoch: 5| Step: 5
Training loss: 1.3802686234267834
Validation loss: 2.641894150143077

Epoch: 5| Step: 6
Training loss: 1.6298066721982905
Validation loss: 2.6717931714157155

Epoch: 5| Step: 7
Training loss: 1.147133690453514
Validation loss: 2.633281477213399

Epoch: 5| Step: 8
Training loss: 1.387457035877268
Validation loss: 2.604643707553897

Epoch: 5| Step: 9
Training loss: 1.2033419723059744
Validation loss: 2.6060669303592614

Epoch: 5| Step: 10
Training loss: 1.6979202395286492
Validation loss: 2.5963622626774554

Epoch: 270| Step: 0
Training loss: 1.7260726993451587
Validation loss: 2.576755235126149

Epoch: 5| Step: 1
Training loss: 1.3529481785500352
Validation loss: 2.5720914540558724

Epoch: 5| Step: 2
Training loss: 1.3668148731879344
Validation loss: 2.5904720115209976

Epoch: 5| Step: 3
Training loss: 1.502759144248931
Validation loss: 2.607043388758062

Epoch: 5| Step: 4
Training loss: 1.4948963124223027
Validation loss: 2.6067088015273754

Epoch: 5| Step: 5
Training loss: 1.6013072484999593
Validation loss: 2.6276785607675297

Epoch: 5| Step: 6
Training loss: 1.166565782862739
Validation loss: 2.6664381358707128

Epoch: 5| Step: 7
Training loss: 1.4243904750999354
Validation loss: 2.6843590282958405

Epoch: 5| Step: 8
Training loss: 1.6902433630975633
Validation loss: 2.677655887836472

Epoch: 5| Step: 9
Training loss: 1.1078677616943882
Validation loss: 2.6839937803136675

Epoch: 5| Step: 10
Training loss: 1.1028484657067659
Validation loss: 2.655634064172547

Epoch: 271| Step: 0
Training loss: 1.4811653370544182
Validation loss: 2.66243443685417

Epoch: 5| Step: 1
Training loss: 1.7827575728625114
Validation loss: 2.619857702281476

Epoch: 5| Step: 2
Training loss: 1.249805912208583
Validation loss: 2.6176021114666512

Epoch: 5| Step: 3
Training loss: 1.5972215578750482
Validation loss: 2.650537674823642

Epoch: 5| Step: 4
Training loss: 1.405538972602661
Validation loss: 2.6219887110357605

Epoch: 5| Step: 5
Training loss: 0.8542066347649168
Validation loss: 2.6220368294170546

Epoch: 5| Step: 6
Training loss: 1.4388554858025346
Validation loss: 2.618748564693696

Epoch: 5| Step: 7
Training loss: 1.0949010514270578
Validation loss: 2.6296074254632056

Epoch: 5| Step: 8
Training loss: 1.548986131033429
Validation loss: 2.613434766807235

Epoch: 5| Step: 9
Training loss: 1.3163598841983002
Validation loss: 2.6262178228087003

Epoch: 5| Step: 10
Training loss: 1.3473862971954012
Validation loss: 2.612926600660712

Epoch: 272| Step: 0
Training loss: 1.3900833789599871
Validation loss: 2.6007080714856077

Epoch: 5| Step: 1
Training loss: 1.427019057485441
Validation loss: 2.595127278225535

Epoch: 5| Step: 2
Training loss: 1.3843746521133433
Validation loss: 2.611207282991186

Epoch: 5| Step: 3
Training loss: 1.3696612838753226
Validation loss: 2.6477097851475153

Epoch: 5| Step: 4
Training loss: 1.1587682056334225
Validation loss: 2.6704024458578566

Epoch: 5| Step: 5
Training loss: 1.8536264368342756
Validation loss: 2.6631390622073186

Epoch: 5| Step: 6
Training loss: 0.8388903506970108
Validation loss: 2.644372893728399

Epoch: 5| Step: 7
Training loss: 1.593172305255203
Validation loss: 2.651714377321281

Epoch: 5| Step: 8
Training loss: 1.4218748323209893
Validation loss: 2.6368538639356776

Epoch: 5| Step: 9
Training loss: 1.190177058262998
Validation loss: 2.6117374934595787

Epoch: 5| Step: 10
Training loss: 1.3946642985840478
Validation loss: 2.638158666925881

Epoch: 273| Step: 0
Training loss: 1.577323029954998
Validation loss: 2.6279394135782734

Epoch: 5| Step: 1
Training loss: 1.1611724923735418
Validation loss: 2.6039104957509402

Epoch: 5| Step: 2
Training loss: 1.295266774363262
Validation loss: 2.608143719881345

Epoch: 5| Step: 3
Training loss: 1.4225129593190151
Validation loss: 2.6238480309438983

Epoch: 5| Step: 4
Training loss: 1.6696718619954947
Validation loss: 2.620384290356507

Epoch: 5| Step: 5
Training loss: 0.9418707686887999
Validation loss: 2.619238815405715

Epoch: 5| Step: 6
Training loss: 1.2111640964276236
Validation loss: 2.654544121858724

Epoch: 5| Step: 7
Training loss: 1.2521122252589598
Validation loss: 2.6620958205855403

Epoch: 5| Step: 8
Training loss: 1.6951388081115568
Validation loss: 2.6773863443335473

Epoch: 5| Step: 9
Training loss: 1.5263963185249974
Validation loss: 2.6644573602882176

Epoch: 5| Step: 10
Training loss: 1.1887482557474491
Validation loss: 2.6613218679761674

Epoch: 274| Step: 0
Training loss: 1.2840170405555418
Validation loss: 2.6693583650841113

Epoch: 5| Step: 1
Training loss: 1.21679349503882
Validation loss: 2.6746301210698435

Epoch: 5| Step: 2
Training loss: 1.3764093285685433
Validation loss: 2.6437722193472903

Epoch: 5| Step: 3
Training loss: 1.6749728015570313
Validation loss: 2.6450860474314775

Epoch: 5| Step: 4
Training loss: 1.0883326839388614
Validation loss: 2.642497086004468

Epoch: 5| Step: 5
Training loss: 0.951628964863711
Validation loss: 2.6360864413593665

Epoch: 5| Step: 6
Training loss: 1.0157114432300682
Validation loss: 2.6272152676389298

Epoch: 5| Step: 7
Training loss: 1.4129142946976903
Validation loss: 2.6062082994115805

Epoch: 5| Step: 8
Training loss: 1.857559086718545
Validation loss: 2.5814954665259218

Epoch: 5| Step: 9
Training loss: 1.2043225162237465
Validation loss: 2.579852829643765

Epoch: 5| Step: 10
Training loss: 1.6163154499110672
Validation loss: 2.5893570578102922

Epoch: 275| Step: 0
Training loss: 1.1802663330389511
Validation loss: 2.5998314574888064

Epoch: 5| Step: 1
Training loss: 1.9007978796868428
Validation loss: 2.644204472007244

Epoch: 5| Step: 2
Training loss: 1.2424501345354875
Validation loss: 2.6080853661980785

Epoch: 5| Step: 3
Training loss: 1.5629065175524837
Validation loss: 2.637248568459088

Epoch: 5| Step: 4
Training loss: 0.9489510241051471
Validation loss: 2.6423044268747446

Epoch: 5| Step: 5
Training loss: 0.900231668007563
Validation loss: 2.646545421560877

Epoch: 5| Step: 6
Training loss: 1.4741225493740744
Validation loss: 2.6549012361598847

Epoch: 5| Step: 7
Training loss: 1.2742271081590673
Validation loss: 2.6243475177793187

Epoch: 5| Step: 8
Training loss: 1.4378749524262175
Validation loss: 2.6406394412971084

Epoch: 5| Step: 9
Training loss: 1.515495845364848
Validation loss: 2.6354217574643397

Epoch: 5| Step: 10
Training loss: 1.4632488876487144
Validation loss: 2.6180805825888984

Epoch: 276| Step: 0
Training loss: 1.3299724968239173
Validation loss: 2.6141691966229943

Epoch: 5| Step: 1
Training loss: 1.0693881087444461
Validation loss: 2.576767796834504

Epoch: 5| Step: 2
Training loss: 1.4027698262726849
Validation loss: 2.561984628894194

Epoch: 5| Step: 3
Training loss: 1.1969719132910264
Validation loss: 2.5761392860895453

Epoch: 5| Step: 4
Training loss: 1.3724938875767523
Validation loss: 2.5979484917393054

Epoch: 5| Step: 5
Training loss: 1.4224731528592969
Validation loss: 2.5894817029384605

Epoch: 5| Step: 6
Training loss: 1.438755399427051
Validation loss: 2.5906637599871805

Epoch: 5| Step: 7
Training loss: 1.6001303619683518
Validation loss: 2.6240788243456277

Epoch: 5| Step: 8
Training loss: 1.1900835543238015
Validation loss: 2.6036908318373633

Epoch: 5| Step: 9
Training loss: 1.5413789308798083
Validation loss: 2.6086914550523965

Epoch: 5| Step: 10
Training loss: 1.159756626956374
Validation loss: 2.6113980041917944

Epoch: 277| Step: 0
Training loss: 1.3971596105731772
Validation loss: 2.617074025142509

Epoch: 5| Step: 1
Training loss: 1.2627493130612737
Validation loss: 2.6680233062372762

Epoch: 5| Step: 2
Training loss: 1.3250280737152036
Validation loss: 2.6539213769755774

Epoch: 5| Step: 3
Training loss: 0.9823246447035778
Validation loss: 2.640154618091775

Epoch: 5| Step: 4
Training loss: 1.3113246377916192
Validation loss: 2.636426859885875

Epoch: 5| Step: 5
Training loss: 1.2595484346751429
Validation loss: 2.6683521584106815

Epoch: 5| Step: 6
Training loss: 1.524264927667565
Validation loss: 2.665265315636174

Epoch: 5| Step: 7
Training loss: 1.2668873649035153
Validation loss: 2.6710709928099035

Epoch: 5| Step: 8
Training loss: 1.2611018228585618
Validation loss: 2.699720760050873

Epoch: 5| Step: 9
Training loss: 1.3979313962854911
Validation loss: 2.678977688374624

Epoch: 5| Step: 10
Training loss: 1.623728621579248
Validation loss: 2.636339420938777

Epoch: 278| Step: 0
Training loss: 1.3744645810217655
Validation loss: 2.6381429429312386

Epoch: 5| Step: 1
Training loss: 1.518285716482975
Validation loss: 2.6066485293677157

Epoch: 5| Step: 2
Training loss: 1.6147834489744775
Validation loss: 2.569315919892325

Epoch: 5| Step: 3
Training loss: 1.3055772773928658
Validation loss: 2.566694491845135

Epoch: 5| Step: 4
Training loss: 1.505029432319457
Validation loss: 2.5767618462974147

Epoch: 5| Step: 5
Training loss: 1.315213033368741
Validation loss: 2.5840184126685295

Epoch: 5| Step: 6
Training loss: 1.3835920302618918
Validation loss: 2.605858794401392

Epoch: 5| Step: 7
Training loss: 0.6910320066555616
Validation loss: 2.636114894155191

Epoch: 5| Step: 8
Training loss: 1.3503102581815114
Validation loss: 2.682665477924446

Epoch: 5| Step: 9
Training loss: 1.171929014868436
Validation loss: 2.686411559689834

Epoch: 5| Step: 10
Training loss: 1.267767094190893
Validation loss: 2.648205286352596

Epoch: 279| Step: 0
Training loss: 1.4527961604987676
Validation loss: 2.6598585389029408

Epoch: 5| Step: 1
Training loss: 0.9887777897996158
Validation loss: 2.637474817842889

Epoch: 5| Step: 2
Training loss: 1.3340316920454982
Validation loss: 2.6149549512269625

Epoch: 5| Step: 3
Training loss: 0.811389200467422
Validation loss: 2.5976713871088846

Epoch: 5| Step: 4
Training loss: 1.5007604419828573
Validation loss: 2.602163718167393

Epoch: 5| Step: 5
Training loss: 1.1042254570238703
Validation loss: 2.6344454848959997

Epoch: 5| Step: 6
Training loss: 1.5904377195653667
Validation loss: 2.6787627532024376

Epoch: 5| Step: 7
Training loss: 1.3159633989577921
Validation loss: 2.687182902587779

Epoch: 5| Step: 8
Training loss: 1.7103784771402781
Validation loss: 2.691032840620694

Epoch: 5| Step: 9
Training loss: 1.0022077032514483
Validation loss: 2.719813582835229

Epoch: 5| Step: 10
Training loss: 1.5528746343638495
Validation loss: 2.6899061103986504

Epoch: 280| Step: 0
Training loss: 1.1348149457971237
Validation loss: 2.6467197655751624

Epoch: 5| Step: 1
Training loss: 1.2058379067257559
Validation loss: 2.6456126494967855

Epoch: 5| Step: 2
Training loss: 1.0331925101356902
Validation loss: 2.586899528403284

Epoch: 5| Step: 3
Training loss: 1.384345890884399
Validation loss: 2.596190238575796

Epoch: 5| Step: 4
Training loss: 1.4466330604048487
Validation loss: 2.5863780733249686

Epoch: 5| Step: 5
Training loss: 1.8125526157503073
Validation loss: 2.584113965361884

Epoch: 5| Step: 6
Training loss: 0.9659787810781166
Validation loss: 2.5894239702244652

Epoch: 5| Step: 7
Training loss: 1.4689205963404801
Validation loss: 2.612279523057998

Epoch: 5| Step: 8
Training loss: 0.7230394326954823
Validation loss: 2.612186879079699

Epoch: 5| Step: 9
Training loss: 1.1688257345865234
Validation loss: 2.625395089305131

Epoch: 5| Step: 10
Training loss: 1.7039913808622555
Validation loss: 2.6652016274919386

Epoch: 281| Step: 0
Training loss: 1.5354491286898546
Validation loss: 2.647196642224006

Epoch: 5| Step: 1
Training loss: 1.4409005123000116
Validation loss: 2.619877482942824

Epoch: 5| Step: 2
Training loss: 0.8838657409113944
Validation loss: 2.6189086407076685

Epoch: 5| Step: 3
Training loss: 1.521534048501147
Validation loss: 2.6079781153168535

Epoch: 5| Step: 4
Training loss: 1.469200795571153
Validation loss: 2.58139865793494

Epoch: 5| Step: 5
Training loss: 1.2073838789807219
Validation loss: 2.5576163094367805

Epoch: 5| Step: 6
Training loss: 1.5180736307221951
Validation loss: 2.590154611816729

Epoch: 5| Step: 7
Training loss: 1.2722944500579711
Validation loss: 2.6230133731073235

Epoch: 5| Step: 8
Training loss: 1.287191478096116
Validation loss: 2.652483131063787

Epoch: 5| Step: 9
Training loss: 0.9888355675768583
Validation loss: 2.6885015534493126

Epoch: 5| Step: 10
Training loss: 0.9775390320129085
Validation loss: 2.6862861580194752

Epoch: 282| Step: 0
Training loss: 1.3346014201478678
Validation loss: 2.7097860512050684

Epoch: 5| Step: 1
Training loss: 1.515934941956692
Validation loss: 2.6608256125400183

Epoch: 5| Step: 2
Training loss: 1.426321768530521
Validation loss: 2.6422954789217554

Epoch: 5| Step: 3
Training loss: 1.0681541566569044
Validation loss: 2.628695782479783

Epoch: 5| Step: 4
Training loss: 1.3231463295537729
Validation loss: 2.594556974266126

Epoch: 5| Step: 5
Training loss: 1.1667147126976651
Validation loss: 2.627568407940554

Epoch: 5| Step: 6
Training loss: 1.2977752318658489
Validation loss: 2.6027373738281985

Epoch: 5| Step: 7
Training loss: 1.335770936810783
Validation loss: 2.61759252816542

Epoch: 5| Step: 8
Training loss: 1.3194640102385817
Validation loss: 2.6107512144723106

Epoch: 5| Step: 9
Training loss: 1.281202268874404
Validation loss: 2.6463958307671676

Epoch: 5| Step: 10
Training loss: 1.0953869695012746
Validation loss: 2.610515916610358

Epoch: 283| Step: 0
Training loss: 1.3374925452764377
Validation loss: 2.6574162431732105

Epoch: 5| Step: 1
Training loss: 1.5216626122884787
Validation loss: 2.6352951395974977

Epoch: 5| Step: 2
Training loss: 0.64916303558542
Validation loss: 2.6274619435601365

Epoch: 5| Step: 3
Training loss: 1.3834276716780634
Validation loss: 2.618040547928527

Epoch: 5| Step: 4
Training loss: 1.4851305193330133
Validation loss: 2.5912392922461813

Epoch: 5| Step: 5
Training loss: 1.281338711900633
Validation loss: 2.6211465677699635

Epoch: 5| Step: 6
Training loss: 0.9579834852328201
Validation loss: 2.621970276535927

Epoch: 5| Step: 7
Training loss: 1.4366260857541064
Validation loss: 2.618519277196167

Epoch: 5| Step: 8
Training loss: 1.5616533655979636
Validation loss: 2.639670287587112

Epoch: 5| Step: 9
Training loss: 0.952674071157932
Validation loss: 2.6487286917885378

Epoch: 5| Step: 10
Training loss: 1.2339121759684661
Validation loss: 2.6364149111047444

Epoch: 284| Step: 0
Training loss: 1.0941251383907404
Validation loss: 2.6153736061663406

Epoch: 5| Step: 1
Training loss: 1.460022093853934
Validation loss: 2.6384710429759766

Epoch: 5| Step: 2
Training loss: 1.0224411169133074
Validation loss: 2.6241182114856896

Epoch: 5| Step: 3
Training loss: 1.0380251876553426
Validation loss: 2.643319847207948

Epoch: 5| Step: 4
Training loss: 1.4458167768660923
Validation loss: 2.634442518814105

Epoch: 5| Step: 5
Training loss: 1.398356003757494
Validation loss: 2.6370974762076353

Epoch: 5| Step: 6
Training loss: 1.0626428732459865
Validation loss: 2.6135905698770387

Epoch: 5| Step: 7
Training loss: 1.5585848012107997
Validation loss: 2.6038803067837613

Epoch: 5| Step: 8
Training loss: 1.1764641993012575
Validation loss: 2.6197945332128714

Epoch: 5| Step: 9
Training loss: 1.2631695322287024
Validation loss: 2.62135884726455

Epoch: 5| Step: 10
Training loss: 1.1826034784506818
Validation loss: 2.678453334211032

Epoch: 285| Step: 0
Training loss: 1.295585726829597
Validation loss: 2.6701822762794722

Epoch: 5| Step: 1
Training loss: 1.6121820949664223
Validation loss: 2.6611185248041154

Epoch: 5| Step: 2
Training loss: 1.3828636634111646
Validation loss: 2.662186268392544

Epoch: 5| Step: 3
Training loss: 0.9151723921298048
Validation loss: 2.6335978017969133

Epoch: 5| Step: 4
Training loss: 1.0767387101976724
Validation loss: 2.6000976360374386

Epoch: 5| Step: 5
Training loss: 1.2288444333737756
Validation loss: 2.650210033598039

Epoch: 5| Step: 6
Training loss: 1.2713848959920493
Validation loss: 2.644494263760886

Epoch: 5| Step: 7
Training loss: 1.1565845108720696
Validation loss: 2.6607119816517133

Epoch: 5| Step: 8
Training loss: 1.261161090450496
Validation loss: 2.671975598842868

Epoch: 5| Step: 9
Training loss: 1.1353064083961804
Validation loss: 2.6648884636398242

Epoch: 5| Step: 10
Training loss: 1.4515017395114231
Validation loss: 2.688050091920324

Epoch: 286| Step: 0
Training loss: 1.2435287815593197
Validation loss: 2.657225788745847

Epoch: 5| Step: 1
Training loss: 1.4119615490624677
Validation loss: 2.627511662339206

Epoch: 5| Step: 2
Training loss: 1.0928027274371415
Validation loss: 2.6355302260828646

Epoch: 5| Step: 3
Training loss: 1.098755906732542
Validation loss: 2.646345956248519

Epoch: 5| Step: 4
Training loss: 1.583442868241884
Validation loss: 2.609575572025981

Epoch: 5| Step: 5
Training loss: 1.0044211169457888
Validation loss: 2.625894263315919

Epoch: 5| Step: 6
Training loss: 1.0726165475186666
Validation loss: 2.6431702523258336

Epoch: 5| Step: 7
Training loss: 1.3489067136493524
Validation loss: 2.670710090651725

Epoch: 5| Step: 8
Training loss: 1.7303761614620823
Validation loss: 2.681668452018934

Epoch: 5| Step: 9
Training loss: 0.7531133642920236
Validation loss: 2.6662867747195373

Epoch: 5| Step: 10
Training loss: 0.9533907410425123
Validation loss: 2.6885679965100997

Epoch: 287| Step: 0
Training loss: 1.14878149784312
Validation loss: 2.6721802235929335

Epoch: 5| Step: 1
Training loss: 1.5599921891432624
Validation loss: 2.6865072264899243

Epoch: 5| Step: 2
Training loss: 1.0377513098546498
Validation loss: 2.636559722249053

Epoch: 5| Step: 3
Training loss: 1.2952500239675786
Validation loss: 2.6100587126570347

Epoch: 5| Step: 4
Training loss: 1.2187007991934329
Validation loss: 2.6080714513952437

Epoch: 5| Step: 5
Training loss: 1.026390416602026
Validation loss: 2.612361985211613

Epoch: 5| Step: 6
Training loss: 1.4828600732148058
Validation loss: 2.6167359262672805

Epoch: 5| Step: 7
Training loss: 1.0335201361198227
Validation loss: 2.680209245357152

Epoch: 5| Step: 8
Training loss: 1.161226183808242
Validation loss: 2.658234970161091

Epoch: 5| Step: 9
Training loss: 1.2493990884264923
Validation loss: 2.6720430467261886

Epoch: 5| Step: 10
Training loss: 1.4423809942545243
Validation loss: 2.686575801028008

Epoch: 288| Step: 0
Training loss: 1.3132900403401995
Validation loss: 2.689179816252699

Epoch: 5| Step: 1
Training loss: 1.220177474714777
Validation loss: 2.675839723541396

Epoch: 5| Step: 2
Training loss: 1.123713976884148
Validation loss: 2.618547436253896

Epoch: 5| Step: 3
Training loss: 1.036262468141063
Validation loss: 2.633821906583009

Epoch: 5| Step: 4
Training loss: 1.4935401258311245
Validation loss: 2.661725921661169

Epoch: 5| Step: 5
Training loss: 1.281467837912043
Validation loss: 2.6114067767550737

Epoch: 5| Step: 6
Training loss: 1.2207382319170448
Validation loss: 2.61339532165526

Epoch: 5| Step: 7
Training loss: 1.0192331631027478
Validation loss: 2.6148528322263065

Epoch: 5| Step: 8
Training loss: 1.5709873855832264
Validation loss: 2.6164187663149274

Epoch: 5| Step: 9
Training loss: 0.6188797987996699
Validation loss: 2.630895157531167

Epoch: 5| Step: 10
Training loss: 1.372038730244283
Validation loss: 2.6526506313984637

Epoch: 289| Step: 0
Training loss: 1.4192852707808064
Validation loss: 2.6852534587388694

Epoch: 5| Step: 1
Training loss: 0.9397004688155818
Validation loss: 2.6978491209577093

Epoch: 5| Step: 2
Training loss: 1.1467570251988144
Validation loss: 2.7005834814374863

Epoch: 5| Step: 3
Training loss: 1.6504063712728858
Validation loss: 2.6528234502755654

Epoch: 5| Step: 4
Training loss: 1.252416182890502
Validation loss: 2.632490453202714

Epoch: 5| Step: 5
Training loss: 0.629685765872205
Validation loss: 2.663902025998311

Epoch: 5| Step: 6
Training loss: 0.8627500669114013
Validation loss: 2.612977078723512

Epoch: 5| Step: 7
Training loss: 1.5044071304700015
Validation loss: 2.627023989917877

Epoch: 5| Step: 8
Training loss: 1.2151887655205973
Validation loss: 2.600816257945133

Epoch: 5| Step: 9
Training loss: 1.0635650009499784
Validation loss: 2.5831935922840072

Epoch: 5| Step: 10
Training loss: 1.440026095471762
Validation loss: 2.6381188839982532

Epoch: 290| Step: 0
Training loss: 1.3253928411877287
Validation loss: 2.6122928236763943

Epoch: 5| Step: 1
Training loss: 0.9604850262016353
Validation loss: 2.6471080210953812

Epoch: 5| Step: 2
Training loss: 1.2158644825215854
Validation loss: 2.6868034885374557

Epoch: 5| Step: 3
Training loss: 1.2615744682464347
Validation loss: 2.685286334960745

Epoch: 5| Step: 4
Training loss: 1.3855506382846192
Validation loss: 2.704149746086237

Epoch: 5| Step: 5
Training loss: 0.9332446798443231
Validation loss: 2.659917501264639

Epoch: 5| Step: 6
Training loss: 1.2275176975815774
Validation loss: 2.699434176139085

Epoch: 5| Step: 7
Training loss: 1.2333331962963405
Validation loss: 2.6201358718196395

Epoch: 5| Step: 8
Training loss: 1.4906166956128413
Validation loss: 2.6248714993731275

Epoch: 5| Step: 9
Training loss: 1.4059837089180807
Validation loss: 2.5774275934309285

Epoch: 5| Step: 10
Training loss: 0.7441546020797138
Validation loss: 2.548248593006524

Epoch: 291| Step: 0
Training loss: 1.2136513110660305
Validation loss: 2.560042771092996

Epoch: 5| Step: 1
Training loss: 0.8918259203638447
Validation loss: 2.6053970449302386

Epoch: 5| Step: 2
Training loss: 1.0205776062968206
Validation loss: 2.599769293304651

Epoch: 5| Step: 3
Training loss: 1.3854123691501745
Validation loss: 2.635020850387596

Epoch: 5| Step: 4
Training loss: 1.0389090976914155
Validation loss: 2.593950113898396

Epoch: 5| Step: 5
Training loss: 1.3028167286797603
Validation loss: 2.6136446849290564

Epoch: 5| Step: 6
Training loss: 1.2954045427519252
Validation loss: 2.572886022696053

Epoch: 5| Step: 7
Training loss: 1.4781949339244989
Validation loss: 2.5283129191278344

Epoch: 5| Step: 8
Training loss: 1.291127302501796
Validation loss: 2.5045429852449006

Epoch: 5| Step: 9
Training loss: 0.9903164139270328
Validation loss: 2.515865504236077

Epoch: 5| Step: 10
Training loss: 1.4797761046679627
Validation loss: 2.578774567701677

Epoch: 292| Step: 0
Training loss: 1.1120204277632202
Validation loss: 2.587540443520068

Epoch: 5| Step: 1
Training loss: 1.2140374160198
Validation loss: 2.614686080887189

Epoch: 5| Step: 2
Training loss: 1.3613132820797929
Validation loss: 2.6562662933641303

Epoch: 5| Step: 3
Training loss: 1.0047781160345068
Validation loss: 2.6861423727291043

Epoch: 5| Step: 4
Training loss: 1.1479295398708038
Validation loss: 2.662158588259716

Epoch: 5| Step: 5
Training loss: 1.6111456750399547
Validation loss: 2.6476629273221457

Epoch: 5| Step: 6
Training loss: 0.8698525930907288
Validation loss: 2.6116520088247737

Epoch: 5| Step: 7
Training loss: 1.194925981248308
Validation loss: 2.6296124374904073

Epoch: 5| Step: 8
Training loss: 1.1032260751211187
Validation loss: 2.618114263147356

Epoch: 5| Step: 9
Training loss: 1.3778769566147353
Validation loss: 2.6171062106060377

Epoch: 5| Step: 10
Training loss: 1.11136448805706
Validation loss: 2.5927258241285833

Epoch: 293| Step: 0
Training loss: 1.1179776898445848
Validation loss: 2.59466875480676

Epoch: 5| Step: 1
Training loss: 1.3750744279311424
Validation loss: 2.5705794443802503

Epoch: 5| Step: 2
Training loss: 1.0132738335190226
Validation loss: 2.6007400775137017

Epoch: 5| Step: 3
Training loss: 1.3924104608345003
Validation loss: 2.63334659740783

Epoch: 5| Step: 4
Training loss: 1.1707542146081065
Validation loss: 2.6211182449331076

Epoch: 5| Step: 5
Training loss: 1.2331585745245421
Validation loss: 2.644715095041016

Epoch: 5| Step: 6
Training loss: 0.99690913318327
Validation loss: 2.647015585946021

Epoch: 5| Step: 7
Training loss: 1.098201195597862
Validation loss: 2.663513633225696

Epoch: 5| Step: 8
Training loss: 1.1206836548500414
Validation loss: 2.630899629217104

Epoch: 5| Step: 9
Training loss: 1.199437373111367
Validation loss: 2.6394330114820415

Epoch: 5| Step: 10
Training loss: 1.4268383549092165
Validation loss: 2.6157189196585535

Epoch: 294| Step: 0
Training loss: 1.2634301168078383
Validation loss: 2.638787900600297

Epoch: 5| Step: 1
Training loss: 0.9828397495391764
Validation loss: 2.611552217750782

Epoch: 5| Step: 2
Training loss: 1.2745075060031135
Validation loss: 2.613835438172566

Epoch: 5| Step: 3
Training loss: 1.1561932420976195
Validation loss: 2.6113503661847464

Epoch: 5| Step: 4
Training loss: 1.2649938634489888
Validation loss: 2.639300548249582

Epoch: 5| Step: 5
Training loss: 1.3183768264180606
Validation loss: 2.6603987190884335

Epoch: 5| Step: 6
Training loss: 1.1310339284001973
Validation loss: 2.689633906638248

Epoch: 5| Step: 7
Training loss: 1.2877603600954892
Validation loss: 2.6730333978759595

Epoch: 5| Step: 8
Training loss: 1.2859006076865003
Validation loss: 2.6423764663733147

Epoch: 5| Step: 9
Training loss: 1.2561742408645227
Validation loss: 2.613767879056123

Epoch: 5| Step: 10
Training loss: 1.1741262047922993
Validation loss: 2.5794421508393377

Epoch: 295| Step: 0
Training loss: 1.1356637784963894
Validation loss: 2.5327560874505655

Epoch: 5| Step: 1
Training loss: 1.1896983427891825
Validation loss: 2.5860786207402393

Epoch: 5| Step: 2
Training loss: 1.059688213486517
Validation loss: 2.5906153572396167

Epoch: 5| Step: 3
Training loss: 1.4938062904637117
Validation loss: 2.631541954864268

Epoch: 5| Step: 4
Training loss: 1.3727288128731094
Validation loss: 2.6419511016030643

Epoch: 5| Step: 5
Training loss: 1.2023879927339598
Validation loss: 2.6750950523174333

Epoch: 5| Step: 6
Training loss: 1.1266267459237498
Validation loss: 2.6631806863779697

Epoch: 5| Step: 7
Training loss: 0.9870872371290976
Validation loss: 2.687758904263227

Epoch: 5| Step: 8
Training loss: 0.9366947530515408
Validation loss: 2.6639810463735714

Epoch: 5| Step: 9
Training loss: 1.4931843408838026
Validation loss: 2.6599260261023736

Epoch: 5| Step: 10
Training loss: 1.0184833505287458
Validation loss: 2.6040608249608117

Epoch: 296| Step: 0
Training loss: 1.2092329764943335
Validation loss: 2.5693188963015428

Epoch: 5| Step: 1
Training loss: 0.7381157664368294
Validation loss: 2.5689217002895712

Epoch: 5| Step: 2
Training loss: 1.162288107070263
Validation loss: 2.545238017865823

Epoch: 5| Step: 3
Training loss: 1.342632006045982
Validation loss: 2.507589975448393

Epoch: 5| Step: 4
Training loss: 0.8713909035778525
Validation loss: 2.5410548912373394

Epoch: 5| Step: 5
Training loss: 1.1924174535719732
Validation loss: 2.582527508988753

Epoch: 5| Step: 6
Training loss: 1.1345450470892802
Validation loss: 2.6113137267875137

Epoch: 5| Step: 7
Training loss: 1.2768379166456136
Validation loss: 2.6287390950116762

Epoch: 5| Step: 8
Training loss: 1.489825871424828
Validation loss: 2.6224266010767097

Epoch: 5| Step: 9
Training loss: 1.144590512977489
Validation loss: 2.6366252768054266

Epoch: 5| Step: 10
Training loss: 1.3857312191938413
Validation loss: 2.6411221070219564

Epoch: 297| Step: 0
Training loss: 1.534232057956003
Validation loss: 2.608688974639457

Epoch: 5| Step: 1
Training loss: 1.4106010940006655
Validation loss: 2.5642500543159845

Epoch: 5| Step: 2
Training loss: 0.8008559029369653
Validation loss: 2.5793226585692186

Epoch: 5| Step: 3
Training loss: 0.929497803640823
Validation loss: 2.539807597117484

Epoch: 5| Step: 4
Training loss: 1.0174497790677974
Validation loss: 2.5611125512398187

Epoch: 5| Step: 5
Training loss: 1.1586074509328237
Validation loss: 2.5602895235152103

Epoch: 5| Step: 6
Training loss: 1.0523520148617542
Validation loss: 2.5960586045057346

Epoch: 5| Step: 7
Training loss: 0.9660688028534089
Validation loss: 2.6497398390775757

Epoch: 5| Step: 8
Training loss: 1.0414181730785486
Validation loss: 2.656148293060262

Epoch: 5| Step: 9
Training loss: 1.466939012571625
Validation loss: 2.6733530788793565

Epoch: 5| Step: 10
Training loss: 1.3235310256860904
Validation loss: 2.6720045185822148

Epoch: 298| Step: 0
Training loss: 1.3008654226385092
Validation loss: 2.694828082534103

Epoch: 5| Step: 1
Training loss: 1.002963918902185
Validation loss: 2.6842862178098392

Epoch: 5| Step: 2
Training loss: 0.9483170484698881
Validation loss: 2.6897691865703792

Epoch: 5| Step: 3
Training loss: 1.1082205877585458
Validation loss: 2.6601874704272475

Epoch: 5| Step: 4
Training loss: 1.2997625904445647
Validation loss: 2.6422456274266035

Epoch: 5| Step: 5
Training loss: 1.1158354253561755
Validation loss: 2.6645387676035783

Epoch: 5| Step: 6
Training loss: 1.0005262897322151
Validation loss: 2.6361053198047153

Epoch: 5| Step: 7
Training loss: 1.258780681383925
Validation loss: 2.6391733947375124

Epoch: 5| Step: 8
Training loss: 1.1200934543107421
Validation loss: 2.6276389733280454

Epoch: 5| Step: 9
Training loss: 1.20942263447793
Validation loss: 2.647195661198115

Epoch: 5| Step: 10
Training loss: 1.2170330081779581
Validation loss: 2.624861467947479

Epoch: 299| Step: 0
Training loss: 1.2187819843496892
Validation loss: 2.6305357870640713

Epoch: 5| Step: 1
Training loss: 1.043052069947003
Validation loss: 2.599259837302609

Epoch: 5| Step: 2
Training loss: 1.0429808655224444
Validation loss: 2.6186133732006818

Epoch: 5| Step: 3
Training loss: 1.0554529308881442
Validation loss: 2.60034200526665

Epoch: 5| Step: 4
Training loss: 1.2002255068923589
Validation loss: 2.6091976310580596

Epoch: 5| Step: 5
Training loss: 1.3917691099795124
Validation loss: 2.6326318606272148

Epoch: 5| Step: 6
Training loss: 1.4207838294092767
Validation loss: 2.646911517361566

Epoch: 5| Step: 7
Training loss: 0.9679148365736394
Validation loss: 2.6443712776211337

Epoch: 5| Step: 8
Training loss: 0.8680904601814867
Validation loss: 2.6347183229009383

Epoch: 5| Step: 9
Training loss: 0.9162594728903909
Validation loss: 2.650539373253194

Epoch: 5| Step: 10
Training loss: 1.2183237553092587
Validation loss: 2.6572713125065044

Epoch: 300| Step: 0
Training loss: 1.1186969936323292
Validation loss: 2.6208205246263065

Epoch: 5| Step: 1
Training loss: 1.079724328038178
Validation loss: 2.603673862876938

Epoch: 5| Step: 2
Training loss: 1.1240151120829547
Validation loss: 2.6221724544779264

Epoch: 5| Step: 3
Training loss: 1.1954190574472283
Validation loss: 2.6280283162647757

Epoch: 5| Step: 4
Training loss: 1.3786602719421195
Validation loss: 2.606891070991746

Epoch: 5| Step: 5
Training loss: 0.9379246703565745
Validation loss: 2.6228938289087496

Epoch: 5| Step: 6
Training loss: 0.9423254756581891
Validation loss: 2.6370050566692838

Epoch: 5| Step: 7
Training loss: 0.8241972355497931
Validation loss: 2.6418001749540716

Epoch: 5| Step: 8
Training loss: 1.2178079925994036
Validation loss: 2.6607432923904573

Epoch: 5| Step: 9
Training loss: 1.340610384917012
Validation loss: 2.6417084886211195

Epoch: 5| Step: 10
Training loss: 0.8931701499786571
Validation loss: 2.679452651496865

Epoch: 301| Step: 0
Training loss: 0.9895333059950033
Validation loss: 2.6824161706533216

Epoch: 5| Step: 1
Training loss: 0.9591362050243506
Validation loss: 2.648042792258422

Epoch: 5| Step: 2
Training loss: 1.3752980776123556
Validation loss: 2.672268584058886

Epoch: 5| Step: 3
Training loss: 1.185185083429566
Validation loss: 2.6365086465163357

Epoch: 5| Step: 4
Training loss: 1.1956570695882391
Validation loss: 2.619498628619877

Epoch: 5| Step: 5
Training loss: 1.1917208396940315
Validation loss: 2.607914542011929

Epoch: 5| Step: 6
Training loss: 1.013545445549178
Validation loss: 2.6036405803925766

Epoch: 5| Step: 7
Training loss: 0.9832503842804811
Validation loss: 2.6140065727314132

Epoch: 5| Step: 8
Training loss: 1.2419000448956594
Validation loss: 2.6151925974406613

Epoch: 5| Step: 9
Training loss: 0.8063013134381358
Validation loss: 2.586328574858838

Epoch: 5| Step: 10
Training loss: 1.0377426943667727
Validation loss: 2.6219303496674327

Epoch: 302| Step: 0
Training loss: 1.4524994190628544
Validation loss: 2.6338988850922953

Epoch: 5| Step: 1
Training loss: 1.0069705492048624
Validation loss: 2.6467621177317424

Epoch: 5| Step: 2
Training loss: 0.9219917934594503
Validation loss: 2.6691315406853424

Epoch: 5| Step: 3
Training loss: 1.176124497304771
Validation loss: 2.602021398808632

Epoch: 5| Step: 4
Training loss: 0.7797126139110828
Validation loss: 2.6430082042813003

Epoch: 5| Step: 5
Training loss: 1.0357833977833968
Validation loss: 2.623100089332832

Epoch: 5| Step: 6
Training loss: 0.6934947136977963
Validation loss: 2.6177162827593445

Epoch: 5| Step: 7
Training loss: 1.0957769957203771
Validation loss: 2.6276596276338706

Epoch: 5| Step: 8
Training loss: 1.0001229568229815
Validation loss: 2.6163256153384915

Epoch: 5| Step: 9
Training loss: 1.312205690356398
Validation loss: 2.583375748502143

Epoch: 5| Step: 10
Training loss: 1.2886883741827517
Validation loss: 2.598325547077452

Epoch: 303| Step: 0
Training loss: 0.9439895767893222
Validation loss: 2.625159503409434

Epoch: 5| Step: 1
Training loss: 1.084083071502772
Validation loss: 2.628607354899959

Epoch: 5| Step: 2
Training loss: 0.6762546578985487
Validation loss: 2.6557860971288356

Epoch: 5| Step: 3
Training loss: 1.3239568040520304
Validation loss: 2.6340138946016483

Epoch: 5| Step: 4
Training loss: 1.1081998806873334
Validation loss: 2.650866697183921

Epoch: 5| Step: 5
Training loss: 0.8850247506813256
Validation loss: 2.638907891532326

Epoch: 5| Step: 6
Training loss: 1.217887866923526
Validation loss: 2.6885918633568284

Epoch: 5| Step: 7
Training loss: 1.0205836217730382
Validation loss: 2.6781069209322275

Epoch: 5| Step: 8
Training loss: 1.248413700645581
Validation loss: 2.6537629637354874

Epoch: 5| Step: 9
Training loss: 0.7526405660061468
Validation loss: 2.606397130533427

Epoch: 5| Step: 10
Training loss: 1.3517076271066024
Validation loss: 2.60370492020467

Epoch: 304| Step: 0
Training loss: 1.293067075557635
Validation loss: 2.6183362036285938

Epoch: 5| Step: 1
Training loss: 1.0635685876520888
Validation loss: 2.6576915914022847

Epoch: 5| Step: 2
Training loss: 1.1940188419733953
Validation loss: 2.611625148715079

Epoch: 5| Step: 3
Training loss: 1.0681817222609928
Validation loss: 2.587073724076976

Epoch: 5| Step: 4
Training loss: 1.3635659344142905
Validation loss: 2.604061344765152

Epoch: 5| Step: 5
Training loss: 0.8793898205840135
Validation loss: 2.603841722129685

Epoch: 5| Step: 6
Training loss: 0.578250407458342
Validation loss: 2.6157345726332575

Epoch: 5| Step: 7
Training loss: 1.178996155118618
Validation loss: 2.5887679718745784

Epoch: 5| Step: 8
Training loss: 0.8273045776430515
Validation loss: 2.5467969644774877

Epoch: 5| Step: 9
Training loss: 1.2628195952981012
Validation loss: 2.5700893405587766

Epoch: 5| Step: 10
Training loss: 0.929653872354588
Validation loss: 2.5869300949033502

Epoch: 305| Step: 0
Training loss: 1.1431074953902876
Validation loss: 2.608653878115959

Epoch: 5| Step: 1
Training loss: 1.2964875435280419
Validation loss: 2.6383790835413867

Epoch: 5| Step: 2
Training loss: 0.9059125008740964
Validation loss: 2.641195005751259

Epoch: 5| Step: 3
Training loss: 1.1334166921551978
Validation loss: 2.6831518399476466

Epoch: 5| Step: 4
Training loss: 1.1247765001175456
Validation loss: 2.6856962514969327

Epoch: 5| Step: 5
Training loss: 1.277697592905307
Validation loss: 2.6952537260324774

Epoch: 5| Step: 6
Training loss: 0.9683960298692389
Validation loss: 2.6877906415127044

Epoch: 5| Step: 7
Training loss: 1.002636533272543
Validation loss: 2.661744443929417

Epoch: 5| Step: 8
Training loss: 0.8814306331048671
Validation loss: 2.699907907292544

Epoch: 5| Step: 9
Training loss: 1.1733028613995968
Validation loss: 2.671064934191503

Epoch: 5| Step: 10
Training loss: 1.11840391293552
Validation loss: 2.642309161588491

Epoch: 306| Step: 0
Training loss: 1.3898226105410205
Validation loss: 2.605275509608701

Epoch: 5| Step: 1
Training loss: 0.6518479021754783
Validation loss: 2.593688892959736

Epoch: 5| Step: 2
Training loss: 0.8577249464925232
Validation loss: 2.553962142178601

Epoch: 5| Step: 3
Training loss: 1.1593258644241449
Validation loss: 2.5631452158807955

Epoch: 5| Step: 4
Training loss: 1.1046579575533937
Validation loss: 2.5694529319193604

Epoch: 5| Step: 5
Training loss: 0.6753938038333638
Validation loss: 2.6152345661530036

Epoch: 5| Step: 6
Training loss: 1.3266008495094022
Validation loss: 2.6180361096049727

Epoch: 5| Step: 7
Training loss: 1.058391819236493
Validation loss: 2.6336440376853028

Epoch: 5| Step: 8
Training loss: 1.2624742826354112
Validation loss: 2.655653572078543

Epoch: 5| Step: 9
Training loss: 1.2194742838270125
Validation loss: 2.62794737391244

Epoch: 5| Step: 10
Training loss: 1.1367770570043816
Validation loss: 2.6010489254510967

Epoch: 307| Step: 0
Training loss: 1.1195082668120184
Validation loss: 2.556122987332999

Epoch: 5| Step: 1
Training loss: 0.8265128728322185
Validation loss: 2.566823251231079

Epoch: 5| Step: 2
Training loss: 0.8478179988267966
Validation loss: 2.54000237649618

Epoch: 5| Step: 3
Training loss: 1.1673720248411446
Validation loss: 2.5649279245550556

Epoch: 5| Step: 4
Training loss: 1.1561132814149795
Validation loss: 2.6134141197561083

Epoch: 5| Step: 5
Training loss: 1.2215089137360684
Validation loss: 2.6380033537510084

Epoch: 5| Step: 6
Training loss: 0.8702649334659367
Validation loss: 2.621420919997718

Epoch: 5| Step: 7
Training loss: 0.990838432785485
Validation loss: 2.6502807399987316

Epoch: 5| Step: 8
Training loss: 1.3203723600462842
Validation loss: 2.612705462501942

Epoch: 5| Step: 9
Training loss: 0.9917482319848062
Validation loss: 2.650516720020982

Epoch: 5| Step: 10
Training loss: 1.23810207863724
Validation loss: 2.6346407105512344

Epoch: 308| Step: 0
Training loss: 1.1781376643221115
Validation loss: 2.650958969038695

Epoch: 5| Step: 1
Training loss: 1.0538832812567007
Validation loss: 2.6071309704924306

Epoch: 5| Step: 2
Training loss: 0.8907898198257339
Validation loss: 2.5802450184839665

Epoch: 5| Step: 3
Training loss: 1.2485158692780935
Validation loss: 2.6188907062825515

Epoch: 5| Step: 4
Training loss: 0.6643937574952271
Validation loss: 2.622760120316476

Epoch: 5| Step: 5
Training loss: 1.037938478032146
Validation loss: 2.6016534096353396

Epoch: 5| Step: 6
Training loss: 1.10822424507118
Validation loss: 2.591669930081871

Epoch: 5| Step: 7
Training loss: 0.7839420856498946
Validation loss: 2.5942740021637456

Epoch: 5| Step: 8
Training loss: 1.1627033671031692
Validation loss: 2.5991703264036388

Epoch: 5| Step: 9
Training loss: 0.8681367026653222
Validation loss: 2.595091914321212

Epoch: 5| Step: 10
Training loss: 1.2595378817729272
Validation loss: 2.62580576384661

Epoch: 309| Step: 0
Training loss: 1.0515506579340232
Validation loss: 2.6349045081008655

Epoch: 5| Step: 1
Training loss: 1.2733186537627101
Validation loss: 2.6137294050552375

Epoch: 5| Step: 2
Training loss: 0.6650735899354885
Validation loss: 2.5964112647595936

Epoch: 5| Step: 3
Training loss: 1.0884056858141347
Validation loss: 2.589051871533178

Epoch: 5| Step: 4
Training loss: 1.1608944480583823
Validation loss: 2.6098549902244472

Epoch: 5| Step: 5
Training loss: 0.9561522514897246
Validation loss: 2.5880443423483683

Epoch: 5| Step: 6
Training loss: 0.8905446200321742
Validation loss: 2.621625656886379

Epoch: 5| Step: 7
Training loss: 1.2925022816591765
Validation loss: 2.601630092271088

Epoch: 5| Step: 8
Training loss: 0.7076205332227091
Validation loss: 2.594117627936123

Epoch: 5| Step: 9
Training loss: 1.0489243333616707
Validation loss: 2.6080718612912457

Epoch: 5| Step: 10
Training loss: 0.9372724574835978
Validation loss: 2.6172409030129162

Epoch: 310| Step: 0
Training loss: 0.8763390580983411
Validation loss: 2.6281095780291337

Epoch: 5| Step: 1
Training loss: 1.1343942582778732
Validation loss: 2.5745587734433766

Epoch: 5| Step: 2
Training loss: 0.7383274689592894
Validation loss: 2.557572500114471

Epoch: 5| Step: 3
Training loss: 0.821439169140092
Validation loss: 2.5648330584352483

Epoch: 5| Step: 4
Training loss: 0.8598841459395395
Validation loss: 2.536963099008471

Epoch: 5| Step: 5
Training loss: 1.0051033808548002
Validation loss: 2.524857426121668

Epoch: 5| Step: 6
Training loss: 1.0675616031712416
Validation loss: 2.545547328535339

Epoch: 5| Step: 7
Training loss: 1.1536821254880099
Validation loss: 2.5575408760653207

Epoch: 5| Step: 8
Training loss: 1.138268950742149
Validation loss: 2.5965567430055416

Epoch: 5| Step: 9
Training loss: 1.2544508372343752
Validation loss: 2.576306799927755

Epoch: 5| Step: 10
Training loss: 1.1645716635313268
Validation loss: 2.5874566830177814

Epoch: 311| Step: 0
Training loss: 1.308366624849993
Validation loss: 2.6060025303218217

Epoch: 5| Step: 1
Training loss: 0.7772845911872781
Validation loss: 2.572467520801451

Epoch: 5| Step: 2
Training loss: 1.0609003254328562
Validation loss: 2.5861571660774922

Epoch: 5| Step: 3
Training loss: 1.1620146384211734
Validation loss: 2.5777727102037256

Epoch: 5| Step: 4
Training loss: 0.6579216827972832
Validation loss: 2.585077192042936

Epoch: 5| Step: 5
Training loss: 1.0026748169946496
Validation loss: 2.580018626798708

Epoch: 5| Step: 6
Training loss: 1.3553599113279557
Validation loss: 2.5910344176203335

Epoch: 5| Step: 7
Training loss: 0.7980145179436565
Validation loss: 2.5819779279581736

Epoch: 5| Step: 8
Training loss: 0.6401618585953051
Validation loss: 2.6059971866162623

Epoch: 5| Step: 9
Training loss: 1.0731992565451032
Validation loss: 2.584961100147352

Epoch: 5| Step: 10
Training loss: 0.9883831408903424
Validation loss: 2.6270235585821684

Epoch: 312| Step: 0
Training loss: 0.9093106315877294
Validation loss: 2.6424722071464046

Epoch: 5| Step: 1
Training loss: 1.190772766795848
Validation loss: 2.6330630358283353

Epoch: 5| Step: 2
Training loss: 1.1435027725593105
Validation loss: 2.6306225213683985

Epoch: 5| Step: 3
Training loss: 1.2195074710812601
Validation loss: 2.633179162531833

Epoch: 5| Step: 4
Training loss: 0.7439993977134072
Validation loss: 2.614684372894984

Epoch: 5| Step: 5
Training loss: 0.7078560081061509
Validation loss: 2.6407099865050427

Epoch: 5| Step: 6
Training loss: 1.0674295511160277
Validation loss: 2.637061378279339

Epoch: 5| Step: 7
Training loss: 0.8533302297821331
Validation loss: 2.5912669404526603

Epoch: 5| Step: 8
Training loss: 1.1051752893875375
Validation loss: 2.584299983068809

Epoch: 5| Step: 9
Training loss: 0.9615103092107101
Validation loss: 2.5783714099613135

Epoch: 5| Step: 10
Training loss: 0.9776785309922819
Validation loss: 2.6135647429582303

Epoch: 313| Step: 0
Training loss: 1.1859541920729888
Validation loss: 2.6314507625870944

Epoch: 5| Step: 1
Training loss: 1.1267053077117015
Validation loss: 2.6390297290463387

Epoch: 5| Step: 2
Training loss: 0.786477604476238
Validation loss: 2.6200286993511894

Epoch: 5| Step: 3
Training loss: 0.8501350267534409
Validation loss: 2.634607325921794

Epoch: 5| Step: 4
Training loss: 1.114367199676308
Validation loss: 2.6301911098355313

Epoch: 5| Step: 5
Training loss: 0.880335142191779
Validation loss: 2.598953693581471

Epoch: 5| Step: 6
Training loss: 1.111610363349911
Validation loss: 2.6090662120616472

Epoch: 5| Step: 7
Training loss: 0.8589290849170333
Validation loss: 2.6131167352739566

Epoch: 5| Step: 8
Training loss: 1.0837482367020532
Validation loss: 2.6267195195515476

Epoch: 5| Step: 9
Training loss: 0.850892739745555
Validation loss: 2.6206630383896297

Epoch: 5| Step: 10
Training loss: 0.8455079450318604
Validation loss: 2.58940681074528

Epoch: 314| Step: 0
Training loss: 1.2844946181383903
Validation loss: 2.5872056958850616

Epoch: 5| Step: 1
Training loss: 0.8540544707573038
Validation loss: 2.595840313563521

Epoch: 5| Step: 2
Training loss: 0.8678799862801494
Validation loss: 2.58595875703215

Epoch: 5| Step: 3
Training loss: 0.8620542549242912
Validation loss: 2.6407835441265095

Epoch: 5| Step: 4
Training loss: 0.8570541253597007
Validation loss: 2.613307018898849

Epoch: 5| Step: 5
Training loss: 1.2135376609550586
Validation loss: 2.6063448022327407

Epoch: 5| Step: 6
Training loss: 0.5019411909413948
Validation loss: 2.587444085021359

Epoch: 5| Step: 7
Training loss: 0.9314084833454656
Validation loss: 2.648578976998885

Epoch: 5| Step: 8
Training loss: 1.1071236560404643
Validation loss: 2.6185214868932745

Epoch: 5| Step: 9
Training loss: 1.117093489099306
Validation loss: 2.6141004055507273

Epoch: 5| Step: 10
Training loss: 0.9709229249231668
Validation loss: 2.653136407165343

Epoch: 315| Step: 0
Training loss: 0.8535209323883899
Validation loss: 2.6255365420084216

Epoch: 5| Step: 1
Training loss: 1.0095319053176621
Validation loss: 2.5924507412588853

Epoch: 5| Step: 2
Training loss: 1.188019638807919
Validation loss: 2.5900197965735074

Epoch: 5| Step: 3
Training loss: 1.2014211008436755
Validation loss: 2.566838802877414

Epoch: 5| Step: 4
Training loss: 0.6575902694844256
Validation loss: 2.585378046714027

Epoch: 5| Step: 5
Training loss: 1.0408989302338802
Validation loss: 2.6065979454692556

Epoch: 5| Step: 6
Training loss: 1.0471064752909867
Validation loss: 2.6358550001977243

Epoch: 5| Step: 7
Training loss: 0.8377795379198856
Validation loss: 2.666766378886781

Epoch: 5| Step: 8
Training loss: 1.0339217976598363
Validation loss: 2.627725433491616

Epoch: 5| Step: 9
Training loss: 0.5233884475270504
Validation loss: 2.661388827763404

Epoch: 5| Step: 10
Training loss: 1.1149171822415538
Validation loss: 2.6346001914094113

Epoch: 316| Step: 0
Training loss: 0.9861108823934179
Validation loss: 2.6710975992198858

Epoch: 5| Step: 1
Training loss: 1.0694342023736112
Validation loss: 2.6670994000518915

Epoch: 5| Step: 2
Training loss: 0.7928393028098166
Validation loss: 2.605991476453393

Epoch: 5| Step: 3
Training loss: 0.9252134746937503
Validation loss: 2.641113801041951

Epoch: 5| Step: 4
Training loss: 0.3711257719980744
Validation loss: 2.6010617285973847

Epoch: 5| Step: 5
Training loss: 1.168660651070896
Validation loss: 2.6326505408477843

Epoch: 5| Step: 6
Training loss: 0.8843438699048817
Validation loss: 2.6208063360514973

Epoch: 5| Step: 7
Training loss: 0.8435905800435
Validation loss: 2.6225234643580566

Epoch: 5| Step: 8
Training loss: 1.2702465683084196
Validation loss: 2.621836990678755

Epoch: 5| Step: 9
Training loss: 0.9902324488393496
Validation loss: 2.5885190347275664

Epoch: 5| Step: 10
Training loss: 1.02239605279662
Validation loss: 2.606514937536993

Epoch: 317| Step: 0
Training loss: 0.7287951385756738
Validation loss: 2.621109858936019

Epoch: 5| Step: 1
Training loss: 1.1046818065361703
Validation loss: 2.5911532253473863

Epoch: 5| Step: 2
Training loss: 0.7427730057760504
Validation loss: 2.6178654362801193

Epoch: 5| Step: 3
Training loss: 0.5075596987089546
Validation loss: 2.608796599199658

Epoch: 5| Step: 4
Training loss: 1.037272524887228
Validation loss: 2.601993494418822

Epoch: 5| Step: 5
Training loss: 0.9235182841380226
Validation loss: 2.629393005873382

Epoch: 5| Step: 6
Training loss: 0.9711446391219049
Validation loss: 2.6030504678762534

Epoch: 5| Step: 7
Training loss: 0.7939848379734157
Validation loss: 2.61918493436818

Epoch: 5| Step: 8
Training loss: 1.2184011987256962
Validation loss: 2.6339767733309394

Epoch: 5| Step: 9
Training loss: 1.211243031012266
Validation loss: 2.6346159686590065

Epoch: 5| Step: 10
Training loss: 0.9565440903754909
Validation loss: 2.625768690560091

Epoch: 318| Step: 0
Training loss: 0.8705555574719656
Validation loss: 2.59998869100719

Epoch: 5| Step: 1
Training loss: 0.9825804868640767
Validation loss: 2.6563528080829384

Epoch: 5| Step: 2
Training loss: 0.8380366911651203
Validation loss: 2.6195711161964272

Epoch: 5| Step: 3
Training loss: 0.5548812635239676
Validation loss: 2.637751638809699

Epoch: 5| Step: 4
Training loss: 1.3348995883912154
Validation loss: 2.6275033201641573

Epoch: 5| Step: 5
Training loss: 0.6533136752351683
Validation loss: 2.598152671182186

Epoch: 5| Step: 6
Training loss: 1.096056984728706
Validation loss: 2.6380641271944874

Epoch: 5| Step: 7
Training loss: 1.101412553253732
Validation loss: 2.595130075863411

Epoch: 5| Step: 8
Training loss: 1.1262090861417844
Validation loss: 2.631556915567158

Epoch: 5| Step: 9
Training loss: 0.3648762094243057
Validation loss: 2.590972350091566

Epoch: 5| Step: 10
Training loss: 1.1600962408196431
Validation loss: 2.5967700000021576

Epoch: 319| Step: 0
Training loss: 1.1220617601086982
Validation loss: 2.604458077810171

Epoch: 5| Step: 1
Training loss: 0.9504196984124123
Validation loss: 2.5424347101523574

Epoch: 5| Step: 2
Training loss: 0.7858684972121168
Validation loss: 2.5630904777183523

Epoch: 5| Step: 3
Training loss: 0.8174835106589489
Validation loss: 2.5989369245133993

Epoch: 5| Step: 4
Training loss: 0.5752043796206774
Validation loss: 2.5987214609681955

Epoch: 5| Step: 5
Training loss: 0.8126959931128489
Validation loss: 2.5664067654438956

Epoch: 5| Step: 6
Training loss: 1.0544366608901758
Validation loss: 2.607749841095412

Epoch: 5| Step: 7
Training loss: 1.1183956522758849
Validation loss: 2.641922824709641

Epoch: 5| Step: 8
Training loss: 1.0003456472037024
Validation loss: 2.607545528296564

Epoch: 5| Step: 9
Training loss: 1.18543560882255
Validation loss: 2.5935750013457355

Epoch: 5| Step: 10
Training loss: 0.9257631259866391
Validation loss: 2.5761974737438957

Epoch: 320| Step: 0
Training loss: 1.0100145752487761
Validation loss: 2.577969674869166

Epoch: 5| Step: 1
Training loss: 0.98061992801986
Validation loss: 2.5759550218206333

Epoch: 5| Step: 2
Training loss: 0.8743896058330342
Validation loss: 2.595048403748769

Epoch: 5| Step: 3
Training loss: 1.021603754190225
Validation loss: 2.607621293620543

Epoch: 5| Step: 4
Training loss: 0.7126722027331949
Validation loss: 2.6084544725884764

Epoch: 5| Step: 5
Training loss: 1.0614658820894936
Validation loss: 2.627463314432191

Epoch: 5| Step: 6
Training loss: 0.9009306440512638
Validation loss: 2.6271498930031276

Epoch: 5| Step: 7
Training loss: 1.0758643844717228
Validation loss: 2.6452211167960473

Epoch: 5| Step: 8
Training loss: 1.131274422229148
Validation loss: 2.6135705979323047

Epoch: 5| Step: 9
Training loss: 0.41424678804007614
Validation loss: 2.5981281393157203

Epoch: 5| Step: 10
Training loss: 1.0178266869675647
Validation loss: 2.580654667508654

Epoch: 321| Step: 0
Training loss: 1.0151030739937714
Validation loss: 2.547842096180902

Epoch: 5| Step: 1
Training loss: 0.8663324488035615
Validation loss: 2.578950013986686

Epoch: 5| Step: 2
Training loss: 0.878006062988515
Validation loss: 2.58693501222708

Epoch: 5| Step: 3
Training loss: 0.6505854317747021
Validation loss: 2.565696269603709

Epoch: 5| Step: 4
Training loss: 1.0181072711747503
Validation loss: 2.5776961262291542

Epoch: 5| Step: 5
Training loss: 1.1420439164156932
Validation loss: 2.606920870086694

Epoch: 5| Step: 6
Training loss: 0.5867813899790775
Validation loss: 2.5777078290402704

Epoch: 5| Step: 7
Training loss: 1.1376990846235748
Validation loss: 2.6125391878946416

Epoch: 5| Step: 8
Training loss: 0.9712493096721067
Validation loss: 2.628145367759992

Epoch: 5| Step: 9
Training loss: 1.0457423901373375
Validation loss: 2.5927600515805005

Epoch: 5| Step: 10
Training loss: 0.6379797448662009
Validation loss: 2.6270114850570856

Epoch: 322| Step: 0
Training loss: 1.2758151833015428
Validation loss: 2.5608889224589793

Epoch: 5| Step: 1
Training loss: 0.8531385064365903
Validation loss: 2.57095884241885

Epoch: 5| Step: 2
Training loss: 1.0903068843663042
Validation loss: 2.5875680698221237

Epoch: 5| Step: 3
Training loss: 0.7441693398049227
Validation loss: 2.558087167169658

Epoch: 5| Step: 4
Training loss: 0.9963892479699658
Validation loss: 2.5660107541477926

Epoch: 5| Step: 5
Training loss: 0.6778991674764462
Validation loss: 2.583420923344531

Epoch: 5| Step: 6
Training loss: 0.8094285718943719
Validation loss: 2.6232334566273883

Epoch: 5| Step: 7
Training loss: 0.9134160225451253
Validation loss: 2.6218521680963094

Epoch: 5| Step: 8
Training loss: 1.0639626028974796
Validation loss: 2.645819124185747

Epoch: 5| Step: 9
Training loss: 0.6564531919987668
Validation loss: 2.6687438984178415

Epoch: 5| Step: 10
Training loss: 0.991997167398654
Validation loss: 2.6511907916139337

Epoch: 323| Step: 0
Training loss: 0.676170171055666
Validation loss: 2.6267804291356285

Epoch: 5| Step: 1
Training loss: 1.2612424725099018
Validation loss: 2.6137161328353713

Epoch: 5| Step: 2
Training loss: 0.9089785311338524
Validation loss: 2.5972296616864825

Epoch: 5| Step: 3
Training loss: 1.0692448546754283
Validation loss: 2.5411682055351323

Epoch: 5| Step: 4
Training loss: 0.776477503586385
Validation loss: 2.5252417169384986

Epoch: 5| Step: 5
Training loss: 0.9366287633641319
Validation loss: 2.553431981849755

Epoch: 5| Step: 6
Training loss: 0.8629091591526091
Validation loss: 2.551272238814192

Epoch: 5| Step: 7
Training loss: 0.701064013842458
Validation loss: 2.58377909676436

Epoch: 5| Step: 8
Training loss: 1.0591530536424087
Validation loss: 2.63947724438335

Epoch: 5| Step: 9
Training loss: 0.8144676518231043
Validation loss: 2.614675694669361

Epoch: 5| Step: 10
Training loss: 0.8974033208539478
Validation loss: 2.656706493898642

Epoch: 324| Step: 0
Training loss: 0.9354105872032433
Validation loss: 2.5930657698149973

Epoch: 5| Step: 1
Training loss: 0.9680931571713096
Validation loss: 2.609710013596489

Epoch: 5| Step: 2
Training loss: 0.8887486015984845
Validation loss: 2.5997278588931803

Epoch: 5| Step: 3
Training loss: 0.748611038253614
Validation loss: 2.6006875225188075

Epoch: 5| Step: 4
Training loss: 1.1188831932015924
Validation loss: 2.6066835987995236

Epoch: 5| Step: 5
Training loss: 1.0237409418471546
Validation loss: 2.566274036220801

Epoch: 5| Step: 6
Training loss: 0.7376164263621506
Validation loss: 2.5942317496972764

Epoch: 5| Step: 7
Training loss: 0.6542162945220472
Validation loss: 2.650166474149895

Epoch: 5| Step: 8
Training loss: 0.6394758384739359
Validation loss: 2.6390967041321662

Epoch: 5| Step: 9
Training loss: 1.1033201871666927
Validation loss: 2.676667828349743

Epoch: 5| Step: 10
Training loss: 1.0539473585703658
Validation loss: 2.6373451855430066

Epoch: 325| Step: 0
Training loss: 1.0611596348260268
Validation loss: 2.643564864249198

Epoch: 5| Step: 1
Training loss: 0.7654869188627469
Validation loss: 2.5829641479942764

Epoch: 5| Step: 2
Training loss: 0.6721483162597007
Validation loss: 2.6350310834450847

Epoch: 5| Step: 3
Training loss: 0.6887446753958973
Validation loss: 2.6177230950564505

Epoch: 5| Step: 4
Training loss: 1.0937897811194672
Validation loss: 2.6070354599809784

Epoch: 5| Step: 5
Training loss: 0.636148536775911
Validation loss: 2.6005121715000312

Epoch: 5| Step: 6
Training loss: 1.074952197675456
Validation loss: 2.6260168583733536

Epoch: 5| Step: 7
Training loss: 0.9868724265376064
Validation loss: 2.609457178647351

Epoch: 5| Step: 8
Training loss: 0.6746362014852723
Validation loss: 2.6224047014069987

Epoch: 5| Step: 9
Training loss: 0.7881092696771688
Validation loss: 2.610689150240448

Epoch: 5| Step: 10
Training loss: 1.1484998309808323
Validation loss: 2.598057287474582

Epoch: 326| Step: 0
Training loss: 0.8861849350174144
Validation loss: 2.6069159865279077

Epoch: 5| Step: 1
Training loss: 0.7063092502282607
Validation loss: 2.6201769619818274

Epoch: 5| Step: 2
Training loss: 1.0391856529277699
Validation loss: 2.625340316127881

Epoch: 5| Step: 3
Training loss: 0.9002208756574591
Validation loss: 2.6634171077967053

Epoch: 5| Step: 4
Training loss: 0.6907996409965824
Validation loss: 2.6169811242713688

Epoch: 5| Step: 5
Training loss: 1.023440994373209
Validation loss: 2.6350707456532074

Epoch: 5| Step: 6
Training loss: 0.7932819443241887
Validation loss: 2.6101429667417846

Epoch: 5| Step: 7
Training loss: 0.7665557653268913
Validation loss: 2.634931594025463

Epoch: 5| Step: 8
Training loss: 0.5712412757123864
Validation loss: 2.603967973738047

Epoch: 5| Step: 9
Training loss: 1.0946757077630918
Validation loss: 2.6182314739099914

Epoch: 5| Step: 10
Training loss: 1.203379913671916
Validation loss: 2.601590580474443

Epoch: 327| Step: 0
Training loss: 1.0488468218225566
Validation loss: 2.6036571158401443

Epoch: 5| Step: 1
Training loss: 1.0532932814898541
Validation loss: 2.592168878329938

Epoch: 5| Step: 2
Training loss: 0.8608306347662206
Validation loss: 2.6232931131932595

Epoch: 5| Step: 3
Training loss: 0.5587983456973531
Validation loss: 2.6354494654984664

Epoch: 5| Step: 4
Training loss: 0.6934097056859116
Validation loss: 2.6589161202956095

Epoch: 5| Step: 5
Training loss: 0.7195831942783641
Validation loss: 2.7090286485604254

Epoch: 5| Step: 6
Training loss: 0.9409620257893028
Validation loss: 2.662042976488888

Epoch: 5| Step: 7
Training loss: 1.0394296786112824
Validation loss: 2.649374621790612

Epoch: 5| Step: 8
Training loss: 0.7599054124597483
Validation loss: 2.6294261252131337

Epoch: 5| Step: 9
Training loss: 0.9697920209567812
Validation loss: 2.599814059042997

Epoch: 5| Step: 10
Training loss: 1.0244189499555718
Validation loss: 2.6032402671414054

Epoch: 328| Step: 0
Training loss: 1.0835111667707193
Validation loss: 2.628004360811317

Epoch: 5| Step: 1
Training loss: 0.8482219724378561
Validation loss: 2.5908063049693477

Epoch: 5| Step: 2
Training loss: 0.6973508894903394
Validation loss: 2.6179799055301607

Epoch: 5| Step: 3
Training loss: 1.3608307771411505
Validation loss: 2.6547129266931577

Epoch: 5| Step: 4
Training loss: 0.7794648183110121
Validation loss: 2.6221567343443137

Epoch: 5| Step: 5
Training loss: 0.7849198550113548
Validation loss: 2.6381201745064073

Epoch: 5| Step: 6
Training loss: 0.6534983074586602
Validation loss: 2.64834530969671

Epoch: 5| Step: 7
Training loss: 0.7622379196525918
Validation loss: 2.6294580449238745

Epoch: 5| Step: 8
Training loss: 0.6935296078022524
Validation loss: 2.640547503980829

Epoch: 5| Step: 9
Training loss: 0.9298422227865224
Validation loss: 2.6264020824999186

Epoch: 5| Step: 10
Training loss: 1.02719074458813
Validation loss: 2.607195687792716

Epoch: 329| Step: 0
Training loss: 0.8273806195423414
Validation loss: 2.5961802493854145

Epoch: 5| Step: 1
Training loss: 0.9040031862498146
Validation loss: 2.6272776762351073

Epoch: 5| Step: 2
Training loss: 0.9670271165826932
Validation loss: 2.602004126339939

Epoch: 5| Step: 3
Training loss: 0.9209713790662906
Validation loss: 2.598649989980019

Epoch: 5| Step: 4
Training loss: 0.7474093995319621
Validation loss: 2.6286923115558722

Epoch: 5| Step: 5
Training loss: 0.955983861651332
Validation loss: 2.622395481236235

Epoch: 5| Step: 6
Training loss: 0.7700729012967635
Validation loss: 2.6497503200552432

Epoch: 5| Step: 7
Training loss: 1.02062783151527
Validation loss: 2.6272788676601837

Epoch: 5| Step: 8
Training loss: 0.8795590159495535
Validation loss: 2.6573710310907686

Epoch: 5| Step: 9
Training loss: 0.7576354695037159
Validation loss: 2.6464876007579883

Epoch: 5| Step: 10
Training loss: 0.882281354613469
Validation loss: 2.6864832227932287

Epoch: 330| Step: 0
Training loss: 0.918112268794571
Validation loss: 2.6930385009607174

Epoch: 5| Step: 1
Training loss: 0.603498514173586
Validation loss: 2.672290062857784

Epoch: 5| Step: 2
Training loss: 0.811429198447605
Validation loss: 2.6195669804225172

Epoch: 5| Step: 3
Training loss: 0.6268870238637145
Validation loss: 2.6278641491829027

Epoch: 5| Step: 4
Training loss: 0.771895325736719
Validation loss: 2.6448711505760873

Epoch: 5| Step: 5
Training loss: 1.0010914210969246
Validation loss: 2.6077233173180883

Epoch: 5| Step: 6
Training loss: 0.984041187664925
Validation loss: 2.6096582433994695

Epoch: 5| Step: 7
Training loss: 0.7697096099961322
Validation loss: 2.603321014593005

Epoch: 5| Step: 8
Training loss: 1.127187826750401
Validation loss: 2.627960157709912

Epoch: 5| Step: 9
Training loss: 0.8388275030516977
Validation loss: 2.5830613147557124

Epoch: 5| Step: 10
Training loss: 1.0100194143563326
Validation loss: 2.6053258505510244

Epoch: 331| Step: 0
Training loss: 0.48434042038078573
Validation loss: 2.575119009273489

Epoch: 5| Step: 1
Training loss: 0.8516943593260223
Validation loss: 2.6338447929521362

Epoch: 5| Step: 2
Training loss: 1.1134678734408714
Validation loss: 2.6289523948217104

Epoch: 5| Step: 3
Training loss: 1.120664401364311
Validation loss: 2.6282395132022227

Epoch: 5| Step: 4
Training loss: 0.7028937065325777
Validation loss: 2.625406837286074

Epoch: 5| Step: 5
Training loss: 1.0008398939664613
Validation loss: 2.657004661415084

Epoch: 5| Step: 6
Training loss: 1.0110708982962227
Validation loss: 2.651565404931673

Epoch: 5| Step: 7
Training loss: 0.8230362495420859
Validation loss: 2.633506520086379

Epoch: 5| Step: 8
Training loss: 0.634215201372405
Validation loss: 2.6498148313836447

Epoch: 5| Step: 9
Training loss: 0.8571681035955871
Validation loss: 2.627349840394435

Epoch: 5| Step: 10
Training loss: 0.7403854980806468
Validation loss: 2.592929485446807

Epoch: 332| Step: 0
Training loss: 0.7470505655708212
Validation loss: 2.5955555997975543

Epoch: 5| Step: 1
Training loss: 0.8019501876963073
Validation loss: 2.5749324139395853

Epoch: 5| Step: 2
Training loss: 0.7624185331005362
Validation loss: 2.611420133848879

Epoch: 5| Step: 3
Training loss: 0.4738735884753844
Validation loss: 2.5930361535752815

Epoch: 5| Step: 4
Training loss: 0.9336305235958408
Validation loss: 2.6056217825677934

Epoch: 5| Step: 5
Training loss: 0.9658003786689425
Validation loss: 2.6519539699335257

Epoch: 5| Step: 6
Training loss: 1.0100308628843386
Validation loss: 2.632871403495776

Epoch: 5| Step: 7
Training loss: 1.0691688163143043
Validation loss: 2.6341664065338684

Epoch: 5| Step: 8
Training loss: 0.7340284300814974
Validation loss: 2.651505351858857

Epoch: 5| Step: 9
Training loss: 1.0853218693744806
Validation loss: 2.634223675426585

Epoch: 5| Step: 10
Training loss: 0.838960298249039
Validation loss: 2.67915937206809

Epoch: 333| Step: 0
Training loss: 0.6002733611216484
Validation loss: 2.6035898454964492

Epoch: 5| Step: 1
Training loss: 0.9984224213848041
Validation loss: 2.61646764948232

Epoch: 5| Step: 2
Training loss: 1.0592716763051924
Validation loss: 2.607797353177001

Epoch: 5| Step: 3
Training loss: 0.9092095162223849
Validation loss: 2.595557033449507

Epoch: 5| Step: 4
Training loss: 1.0299092449092948
Validation loss: 2.621871466815596

Epoch: 5| Step: 5
Training loss: 0.8267874081814088
Validation loss: 2.6112469796389393

Epoch: 5| Step: 6
Training loss: 0.8679227718944943
Validation loss: 2.5933562700321393

Epoch: 5| Step: 7
Training loss: 0.660395065539991
Validation loss: 2.5917389584382886

Epoch: 5| Step: 8
Training loss: 0.7614575451708958
Validation loss: 2.597101777051576

Epoch: 5| Step: 9
Training loss: 0.49409397191491505
Validation loss: 2.5998176089507123

Epoch: 5| Step: 10
Training loss: 1.0164128109062662
Validation loss: 2.58790031531902

Epoch: 334| Step: 0
Training loss: 0.6545034509484781
Validation loss: 2.603135119167876

Epoch: 5| Step: 1
Training loss: 0.5821973576430387
Validation loss: 2.5452552233141996

Epoch: 5| Step: 2
Training loss: 0.8509772503184441
Validation loss: 2.560091659237449

Epoch: 5| Step: 3
Training loss: 0.6276246274617664
Validation loss: 2.5765669513991467

Epoch: 5| Step: 4
Training loss: 1.0517081671343713
Validation loss: 2.5984719057324677

Epoch: 5| Step: 5
Training loss: 0.8962994553077113
Validation loss: 2.557358219958278

Epoch: 5| Step: 6
Training loss: 1.131234483981289
Validation loss: 2.5884228275479937

Epoch: 5| Step: 7
Training loss: 0.8853059175827651
Validation loss: 2.6256846786538883

Epoch: 5| Step: 8
Training loss: 0.7671654443619917
Validation loss: 2.5910240632411425

Epoch: 5| Step: 9
Training loss: 0.8373461824051851
Validation loss: 2.6191136703957216

Epoch: 5| Step: 10
Training loss: 0.9303323128422555
Validation loss: 2.6241981641160548

Epoch: 335| Step: 0
Training loss: 0.6638454755805457
Validation loss: 2.61834314355507

Epoch: 5| Step: 1
Training loss: 0.6388659634369961
Validation loss: 2.6015875907303165

Epoch: 5| Step: 2
Training loss: 0.6657608305551134
Validation loss: 2.6209932023760927

Epoch: 5| Step: 3
Training loss: 0.8948393045577766
Validation loss: 2.653268620245055

Epoch: 5| Step: 4
Training loss: 0.8592251733739942
Validation loss: 2.5986135513311948

Epoch: 5| Step: 5
Training loss: 1.0262246073695627
Validation loss: 2.6035466502441293

Epoch: 5| Step: 6
Training loss: 0.976787876825138
Validation loss: 2.6177733562555243

Epoch: 5| Step: 7
Training loss: 0.6019386255101069
Validation loss: 2.5906067082302244

Epoch: 5| Step: 8
Training loss: 1.0525040808120592
Validation loss: 2.6211765079953175

Epoch: 5| Step: 9
Training loss: 1.0818331981320537
Validation loss: 2.6520791380362314

Epoch: 5| Step: 10
Training loss: 0.7245088492116984
Validation loss: 2.618142765358463

Epoch: 336| Step: 0
Training loss: 0.7952745859518283
Validation loss: 2.6006623669162163

Epoch: 5| Step: 1
Training loss: 1.1027828518045848
Validation loss: 2.6060690197800906

Epoch: 5| Step: 2
Training loss: 0.9224919339992964
Validation loss: 2.607947331529409

Epoch: 5| Step: 3
Training loss: 0.9293814083101616
Validation loss: 2.576033469797395

Epoch: 5| Step: 4
Training loss: 0.8241958253393273
Validation loss: 2.5669054258988395

Epoch: 5| Step: 5
Training loss: 0.45986412633144635
Validation loss: 2.58010028134275

Epoch: 5| Step: 6
Training loss: 0.6830394568460976
Validation loss: 2.5850240587800988

Epoch: 5| Step: 7
Training loss: 0.7632876939608919
Validation loss: 2.581356899847967

Epoch: 5| Step: 8
Training loss: 0.6316325171238673
Validation loss: 2.5906320634023206

Epoch: 5| Step: 9
Training loss: 0.9370895122857527
Validation loss: 2.6190000553244253

Epoch: 5| Step: 10
Training loss: 1.0398189687892812
Validation loss: 2.565020730274405

Epoch: 337| Step: 0
Training loss: 1.1357654887307704
Validation loss: 2.6203989635381246

Epoch: 5| Step: 1
Training loss: 0.8823417488725308
Validation loss: 2.609259511666235

Epoch: 5| Step: 2
Training loss: 0.6961793746261749
Validation loss: 2.599748802000869

Epoch: 5| Step: 3
Training loss: 0.9256421077159591
Validation loss: 2.637713035483286

Epoch: 5| Step: 4
Training loss: 0.7150112018507998
Validation loss: 2.620544692006325

Epoch: 5| Step: 5
Training loss: 0.9136396881083576
Validation loss: 2.59608466582049

Epoch: 5| Step: 6
Training loss: 0.654928056682512
Validation loss: 2.5776347907749697

Epoch: 5| Step: 7
Training loss: 0.9593282110379248
Validation loss: 2.561396882860394

Epoch: 5| Step: 8
Training loss: 0.3671066316874329
Validation loss: 2.5993432194359403

Epoch: 5| Step: 9
Training loss: 0.751628934656119
Validation loss: 2.603644641032058

Epoch: 5| Step: 10
Training loss: 0.9620542472505709
Validation loss: 2.5901899758271174

Epoch: 338| Step: 0
Training loss: 0.42050802440788576
Validation loss: 2.611292944664637

Epoch: 5| Step: 1
Training loss: 0.7249957183185293
Validation loss: 2.5791630300615855

Epoch: 5| Step: 2
Training loss: 0.6678425184401581
Validation loss: 2.571855216906585

Epoch: 5| Step: 3
Training loss: 0.8779579981226837
Validation loss: 2.569157978671005

Epoch: 5| Step: 4
Training loss: 1.0321224452464477
Validation loss: 2.5651618084454424

Epoch: 5| Step: 5
Training loss: 1.009554222895313
Validation loss: 2.5992570934245594

Epoch: 5| Step: 6
Training loss: 0.879422726939019
Validation loss: 2.5776676193632326

Epoch: 5| Step: 7
Training loss: 1.081247755279857
Validation loss: 2.5680060320268283

Epoch: 5| Step: 8
Training loss: 0.7922379833139489
Validation loss: 2.572948929061842

Epoch: 5| Step: 9
Training loss: 0.6774708788057175
Validation loss: 2.57095794398338

Epoch: 5| Step: 10
Training loss: 0.5672315175864764
Validation loss: 2.5977590163865036

Epoch: 339| Step: 0
Training loss: 0.9597923464503916
Validation loss: 2.607664356491745

Epoch: 5| Step: 1
Training loss: 0.6274558930264613
Validation loss: 2.612014845021228

Epoch: 5| Step: 2
Training loss: 0.7449071345598689
Validation loss: 2.5880203322915203

Epoch: 5| Step: 3
Training loss: 1.0214891597715974
Validation loss: 2.5779091424901046

Epoch: 5| Step: 4
Training loss: 0.8941658973038756
Validation loss: 2.5756264659769137

Epoch: 5| Step: 5
Training loss: 0.8409952475723088
Validation loss: 2.5727230831352057

Epoch: 5| Step: 6
Training loss: 0.9480419635056067
Validation loss: 2.5648470229019407

Epoch: 5| Step: 7
Training loss: 0.468852683582459
Validation loss: 2.6217027949980753

Epoch: 5| Step: 8
Training loss: 0.700047114183172
Validation loss: 2.57959746880084

Epoch: 5| Step: 9
Training loss: 1.0201462100459993
Validation loss: 2.5967138687593714

Epoch: 5| Step: 10
Training loss: 0.6241127153269063
Validation loss: 2.5849952558645017

Epoch: 340| Step: 0
Training loss: 0.9686541971396033
Validation loss: 2.631353598797486

Epoch: 5| Step: 1
Training loss: 0.6605834932740532
Validation loss: 2.6243577944086516

Epoch: 5| Step: 2
Training loss: 0.9342656610619129
Validation loss: 2.61914709884033

Epoch: 5| Step: 3
Training loss: 0.6774876829906913
Validation loss: 2.636003139042406

Epoch: 5| Step: 4
Training loss: 0.7760310374989209
Validation loss: 2.5786738880665183

Epoch: 5| Step: 5
Training loss: 0.4765160178357289
Validation loss: 2.601992942673051

Epoch: 5| Step: 6
Training loss: 0.8357185718813057
Validation loss: 2.658240569546405

Epoch: 5| Step: 7
Training loss: 0.7765104341610368
Validation loss: 2.575024399132546

Epoch: 5| Step: 8
Training loss: 1.0063600349682933
Validation loss: 2.588727929038783

Epoch: 5| Step: 9
Training loss: 0.8115115388624546
Validation loss: 2.578706010498529

Epoch: 5| Step: 10
Training loss: 0.9728314958060197
Validation loss: 2.630666952112779

Epoch: 341| Step: 0
Training loss: 0.642332940443315
Validation loss: 2.591665589535107

Epoch: 5| Step: 1
Training loss: 0.8877264338410676
Validation loss: 2.600890053762104

Epoch: 5| Step: 2
Training loss: 1.1047441244113714
Validation loss: 2.6173400001867035

Epoch: 5| Step: 3
Training loss: 0.9590097334669119
Validation loss: 2.6049316903589648

Epoch: 5| Step: 4
Training loss: 0.5205493788735532
Validation loss: 2.5951113853723475

Epoch: 5| Step: 5
Training loss: 0.9790015318121144
Validation loss: 2.5871495260841844

Epoch: 5| Step: 6
Training loss: 0.8175238666491922
Validation loss: 2.611914418045052

Epoch: 5| Step: 7
Training loss: 0.7035011556896485
Validation loss: 2.608020326930752

Epoch: 5| Step: 8
Training loss: 0.9782342258685829
Validation loss: 2.6164138937477146

Epoch: 5| Step: 9
Training loss: 0.5840198416768556
Validation loss: 2.681675436452106

Epoch: 5| Step: 10
Training loss: 0.5120539550124155
Validation loss: 2.6080069140880444

Epoch: 342| Step: 0
Training loss: 0.8466184741356837
Validation loss: 2.6067706123838685

Epoch: 5| Step: 1
Training loss: 0.5742177119862004
Validation loss: 2.591592768063429

Epoch: 5| Step: 2
Training loss: 0.7620757220183456
Validation loss: 2.5667633299197323

Epoch: 5| Step: 3
Training loss: 0.6866681311377245
Validation loss: 2.5840530054651247

Epoch: 5| Step: 4
Training loss: 1.0442652840914777
Validation loss: 2.5898386481413067

Epoch: 5| Step: 5
Training loss: 0.797049634160948
Validation loss: 2.5655988019045552

Epoch: 5| Step: 6
Training loss: 0.7373546052923046
Validation loss: 2.611253538827598

Epoch: 5| Step: 7
Training loss: 1.0157828575113343
Validation loss: 2.6054559389911804

Epoch: 5| Step: 8
Training loss: 1.0352890793131435
Validation loss: 2.575523400767603

Epoch: 5| Step: 9
Training loss: 0.3775291192905827
Validation loss: 2.617758481305349

Epoch: 5| Step: 10
Training loss: 0.7851866910736404
Validation loss: 2.5815808335540815

Epoch: 343| Step: 0
Training loss: 0.7115923621705369
Validation loss: 2.5986400862078747

Epoch: 5| Step: 1
Training loss: 0.7196478004786117
Validation loss: 2.59516264757508

Epoch: 5| Step: 2
Training loss: 1.109345664052871
Validation loss: 2.5517913296373878

Epoch: 5| Step: 3
Training loss: 0.6397098191490287
Validation loss: 2.586656527536884

Epoch: 5| Step: 4
Training loss: 0.7852483287357495
Validation loss: 2.599058577701857

Epoch: 5| Step: 5
Training loss: 0.6306153997819058
Validation loss: 2.572727972807447

Epoch: 5| Step: 6
Training loss: 0.4583118462583259
Validation loss: 2.5956385063468157

Epoch: 5| Step: 7
Training loss: 0.92026417836918
Validation loss: 2.6277798111064294

Epoch: 5| Step: 8
Training loss: 0.9270415278806463
Validation loss: 2.61537183686925

Epoch: 5| Step: 9
Training loss: 0.48252046017923134
Validation loss: 2.65473636664137

Epoch: 5| Step: 10
Training loss: 1.1334688587126092
Validation loss: 2.6741267686433807

Epoch: 344| Step: 0
Training loss: 0.8582944145144452
Validation loss: 2.6266677059127597

Epoch: 5| Step: 1
Training loss: 0.35965694894307587
Validation loss: 2.5977327172553344

Epoch: 5| Step: 2
Training loss: 0.7261793705644202
Validation loss: 2.626551761775932

Epoch: 5| Step: 3
Training loss: 0.5982741359507909
Validation loss: 2.6109810908572815

Epoch: 5| Step: 4
Training loss: 0.9526688781972442
Validation loss: 2.5930991020156355

Epoch: 5| Step: 5
Training loss: 0.9881023802994301
Validation loss: 2.6237987048972498

Epoch: 5| Step: 6
Training loss: 0.5826675470003262
Validation loss: 2.662776973787319

Epoch: 5| Step: 7
Training loss: 0.9743925476451639
Validation loss: 2.6473786990340384

Epoch: 5| Step: 8
Training loss: 0.9246896996557353
Validation loss: 2.629375253134949

Epoch: 5| Step: 9
Training loss: 0.9575614861649235
Validation loss: 2.680247721557536

Epoch: 5| Step: 10
Training loss: 0.7157332509219984
Validation loss: 2.662138998979833

Epoch: 345| Step: 0
Training loss: 0.6138010676983434
Validation loss: 2.6445318025648485

Epoch: 5| Step: 1
Training loss: 0.7223564557099459
Validation loss: 2.6263807701665494

Epoch: 5| Step: 2
Training loss: 0.310070175795614
Validation loss: 2.600132914112537

Epoch: 5| Step: 3
Training loss: 0.9795924674489462
Validation loss: 2.6236150245373344

Epoch: 5| Step: 4
Training loss: 0.6511520648178665
Validation loss: 2.6053296104123094

Epoch: 5| Step: 5
Training loss: 1.0688382876331075
Validation loss: 2.638681712074968

Epoch: 5| Step: 6
Training loss: 0.9395563461476724
Validation loss: 2.635062218236414

Epoch: 5| Step: 7
Training loss: 0.8894509725498563
Validation loss: 2.6359359428718756

Epoch: 5| Step: 8
Training loss: 0.48226419566981005
Validation loss: 2.645952627218454

Epoch: 5| Step: 9
Training loss: 0.8920846990093508
Validation loss: 2.6625960112469076

Epoch: 5| Step: 10
Training loss: 0.92144894857254
Validation loss: 2.6431354594395002

Epoch: 346| Step: 0
Training loss: 0.7297132940859062
Validation loss: 2.619983514801067

Epoch: 5| Step: 1
Training loss: 0.43708267062160894
Validation loss: 2.652512598215696

Epoch: 5| Step: 2
Training loss: 0.9495940859594387
Validation loss: 2.6240671378302363

Epoch: 5| Step: 3
Training loss: 0.5634715908102267
Validation loss: 2.655309979123833

Epoch: 5| Step: 4
Training loss: 0.9100768091462595
Validation loss: 2.652667280292258

Epoch: 5| Step: 5
Training loss: 0.7339008098982986
Validation loss: 2.6739254452445804

Epoch: 5| Step: 6
Training loss: 0.9893317387967314
Validation loss: 2.6753210922537076

Epoch: 5| Step: 7
Training loss: 0.7894730963202847
Validation loss: 2.673854493522512

Epoch: 5| Step: 8
Training loss: 0.7926465211312971
Validation loss: 2.653945409536279

Epoch: 5| Step: 9
Training loss: 0.9279970780914445
Validation loss: 2.6810380802918776

Epoch: 5| Step: 10
Training loss: 0.6277733307046083
Validation loss: 2.6344468706234045

Epoch: 347| Step: 0
Training loss: 0.5051095184223069
Validation loss: 2.627792339627434

Epoch: 5| Step: 1
Training loss: 0.7395700578886087
Validation loss: 2.617389241283892

Epoch: 5| Step: 2
Training loss: 0.8192143674009658
Validation loss: 2.582075091125036

Epoch: 5| Step: 3
Training loss: 0.7865879802494522
Validation loss: 2.601949243051092

Epoch: 5| Step: 4
Training loss: 0.7331579146675432
Validation loss: 2.621932529112284

Epoch: 5| Step: 5
Training loss: 0.9300530620532133
Validation loss: 2.5652062616830693

Epoch: 5| Step: 6
Training loss: 0.9257012505713146
Validation loss: 2.5693195962511144

Epoch: 5| Step: 7
Training loss: 0.6649607697725155
Validation loss: 2.5902917181536482

Epoch: 5| Step: 8
Training loss: 0.878847009993571
Validation loss: 2.6019036844309706

Epoch: 5| Step: 9
Training loss: 0.6238168484905348
Validation loss: 2.599937247867112

Epoch: 5| Step: 10
Training loss: 0.7878928249254659
Validation loss: 2.609552262575327

Epoch: 348| Step: 0
Training loss: 0.8168112740326127
Validation loss: 2.621358763158134

Epoch: 5| Step: 1
Training loss: 0.7250999579088049
Validation loss: 2.6483403142454263

Epoch: 5| Step: 2
Training loss: 0.8156883332082591
Validation loss: 2.6242588645504936

Epoch: 5| Step: 3
Training loss: 0.7183014672624572
Validation loss: 2.6268639058326166

Epoch: 5| Step: 4
Training loss: 0.7912503118047356
Validation loss: 2.6249660327625945

Epoch: 5| Step: 5
Training loss: 0.797020132274821
Validation loss: 2.5786371681301636

Epoch: 5| Step: 6
Training loss: 0.5348448299716897
Validation loss: 2.573528813980514

Epoch: 5| Step: 7
Training loss: 0.890062020369661
Validation loss: 2.607383665252155

Epoch: 5| Step: 8
Training loss: 0.9975774448609646
Validation loss: 2.594232027383717

Epoch: 5| Step: 9
Training loss: 0.7100189479126303
Validation loss: 2.5998222790441465

Epoch: 5| Step: 10
Training loss: 0.6756704603457863
Validation loss: 2.6247536338049153

Epoch: 349| Step: 0
Training loss: 0.9207851303798203
Validation loss: 2.6143198930147604

Epoch: 5| Step: 1
Training loss: 1.0214340751911246
Validation loss: 2.5950405845319207

Epoch: 5| Step: 2
Training loss: 0.5263425010879684
Validation loss: 2.586644084220482

Epoch: 5| Step: 3
Training loss: 0.7794231800033014
Validation loss: 2.598283917962768

Epoch: 5| Step: 4
Training loss: 0.7653551988695879
Validation loss: 2.6393128511290818

Epoch: 5| Step: 5
Training loss: 0.4963359391774076
Validation loss: 2.6190768400796043

Epoch: 5| Step: 6
Training loss: 0.7452269706994096
Validation loss: 2.5899498008547566

Epoch: 5| Step: 7
Training loss: 0.8729727967514813
Validation loss: 2.6021405817275483

Epoch: 5| Step: 8
Training loss: 0.8194977847122312
Validation loss: 2.5746256149048437

Epoch: 5| Step: 9
Training loss: 0.5966266165199335
Validation loss: 2.5909944978720008

Epoch: 5| Step: 10
Training loss: 0.7881529825614064
Validation loss: 2.616481889999151

Epoch: 350| Step: 0
Training loss: 0.8974323122857693
Validation loss: 2.592219025797476

Epoch: 5| Step: 1
Training loss: 0.5816337200751523
Validation loss: 2.6102422921367396

Epoch: 5| Step: 2
Training loss: 0.9301304443204139
Validation loss: 2.586684389248186

Epoch: 5| Step: 3
Training loss: 0.7090136309175616
Validation loss: 2.576723815663502

Epoch: 5| Step: 4
Training loss: 0.6464495692722946
Validation loss: 2.604348910610069

Epoch: 5| Step: 5
Training loss: 0.975502659753471
Validation loss: 2.624839727037501

Epoch: 5| Step: 6
Training loss: 1.0451307426689977
Validation loss: 2.61345031476876

Epoch: 5| Step: 7
Training loss: 0.5306712813126817
Validation loss: 2.605902791477855

Epoch: 5| Step: 8
Training loss: 0.5238420147515767
Validation loss: 2.5988509399102937

Epoch: 5| Step: 9
Training loss: 0.7346606409249231
Validation loss: 2.640687362537399

Epoch: 5| Step: 10
Training loss: 0.5665680489791753
Validation loss: 2.6258963193869267

Epoch: 351| Step: 0
Training loss: 0.8994388804703134
Validation loss: 2.643201831963415

Epoch: 5| Step: 1
Training loss: 0.5424820344560691
Validation loss: 2.6394828107162365

Epoch: 5| Step: 2
Training loss: 0.8108673565173391
Validation loss: 2.601732463237086

Epoch: 5| Step: 3
Training loss: 0.7998673224696956
Validation loss: 2.6199957117122152

Epoch: 5| Step: 4
Training loss: 0.9707073925392705
Validation loss: 2.6196757512570317

Epoch: 5| Step: 5
Training loss: 0.7421787462220196
Validation loss: 2.604655149524575

Epoch: 5| Step: 6
Training loss: 0.7561061958854255
Validation loss: 2.5814982004834377

Epoch: 5| Step: 7
Training loss: 0.7871108137926909
Validation loss: 2.5753982995734743

Epoch: 5| Step: 8
Training loss: 0.7196552132550131
Validation loss: 2.5965059891619373

Epoch: 5| Step: 9
Training loss: 0.7213530052717387
Validation loss: 2.589333803473998

Epoch: 5| Step: 10
Training loss: 0.47191381863212867
Validation loss: 2.5586714988805905

Epoch: 352| Step: 0
Training loss: 1.0161733467500225
Validation loss: 2.5556490773309894

Epoch: 5| Step: 1
Training loss: 0.9084382111842176
Validation loss: 2.6024589665541766

Epoch: 5| Step: 2
Training loss: 1.1143091642965401
Validation loss: 2.586160129051889

Epoch: 5| Step: 3
Training loss: 0.6850527207767901
Validation loss: 2.6226740668304327

Epoch: 5| Step: 4
Training loss: 0.4890645572509396
Validation loss: 2.6043563524299556

Epoch: 5| Step: 5
Training loss: 0.800001779196668
Validation loss: 2.6384731854384915

Epoch: 5| Step: 6
Training loss: 0.5567446695097418
Validation loss: 2.629209362392107

Epoch: 5| Step: 7
Training loss: 0.7010550654029774
Validation loss: 2.5793203541644365

Epoch: 5| Step: 8
Training loss: 0.7860403065720665
Validation loss: 2.558989053733568

Epoch: 5| Step: 9
Training loss: 0.7584167509694736
Validation loss: 2.5226310788302126

Epoch: 5| Step: 10
Training loss: 0.5709007312729883
Validation loss: 2.5018873786374627

Epoch: 353| Step: 0
Training loss: 0.7843940793334817
Validation loss: 2.5428981769637864

Epoch: 5| Step: 1
Training loss: 0.9302237430732869
Validation loss: 2.5200265176155585

Epoch: 5| Step: 2
Training loss: 0.8602141358233817
Validation loss: 2.5559892396409114

Epoch: 5| Step: 3
Training loss: 0.7936205510591415
Validation loss: 2.598425608340558

Epoch: 5| Step: 4
Training loss: 0.9818592318428799
Validation loss: 2.6049147964043113

Epoch: 5| Step: 5
Training loss: 0.8507913720235513
Validation loss: 2.6200787744450533

Epoch: 5| Step: 6
Training loss: 0.6045003961304659
Validation loss: 2.6167270304913237

Epoch: 5| Step: 7
Training loss: 0.7680472767479328
Validation loss: 2.6065456708688206

Epoch: 5| Step: 8
Training loss: 0.5098847290274249
Validation loss: 2.600868409164372

Epoch: 5| Step: 9
Training loss: 0.8738938560541377
Validation loss: 2.5826445043896875

Epoch: 5| Step: 10
Training loss: 0.6601654368105576
Validation loss: 2.6055450568491367

Epoch: 354| Step: 0
Training loss: 0.7742935991338215
Validation loss: 2.5713977020801555

Epoch: 5| Step: 1
Training loss: 0.9472140268646833
Validation loss: 2.5554127622816494

Epoch: 5| Step: 2
Training loss: 0.7658193691863691
Validation loss: 2.5795323314071172

Epoch: 5| Step: 3
Training loss: 0.7407139253950471
Validation loss: 2.567774452902885

Epoch: 5| Step: 4
Training loss: 0.789382794025329
Validation loss: 2.6033304938541835

Epoch: 5| Step: 5
Training loss: 0.7617870593619587
Validation loss: 2.601792250688697

Epoch: 5| Step: 6
Training loss: 0.52209434125742
Validation loss: 2.6259340225232646

Epoch: 5| Step: 7
Training loss: 0.8551598953735339
Validation loss: 2.630288816569176

Epoch: 5| Step: 8
Training loss: 0.5863713247915489
Validation loss: 2.6317799034472222

Epoch: 5| Step: 9
Training loss: 0.8272478388449418
Validation loss: 2.6148529979164166

Epoch: 5| Step: 10
Training loss: 0.5767992386504055
Validation loss: 2.6067672843712666

Epoch: 355| Step: 0
Training loss: 0.6693568390876777
Validation loss: 2.6315836238684605

Epoch: 5| Step: 1
Training loss: 0.6396118619522646
Validation loss: 2.597438454562938

Epoch: 5| Step: 2
Training loss: 0.9318984852421265
Validation loss: 2.58959275415558

Epoch: 5| Step: 3
Training loss: 0.6842079019568573
Validation loss: 2.6357718121453986

Epoch: 5| Step: 4
Training loss: 0.8396155113761965
Validation loss: 2.619482627217183

Epoch: 5| Step: 5
Training loss: 0.5644097757028177
Validation loss: 2.636488178218261

Epoch: 5| Step: 6
Training loss: 0.7165800177141852
Validation loss: 2.593395580080685

Epoch: 5| Step: 7
Training loss: 0.6618912599203541
Validation loss: 2.592070120407813

Epoch: 5| Step: 8
Training loss: 0.6199684986064191
Validation loss: 2.6339959452575745

Epoch: 5| Step: 9
Training loss: 0.8903369772462912
Validation loss: 2.616382374266277

Epoch: 5| Step: 10
Training loss: 0.9490517363379102
Validation loss: 2.652493263409194

Epoch: 356| Step: 0
Training loss: 0.832221855574616
Validation loss: 2.628037739574253

Epoch: 5| Step: 1
Training loss: 0.48146495043957005
Validation loss: 2.5637201305178197

Epoch: 5| Step: 2
Training loss: 0.8117135716879836
Validation loss: 2.5724457287411937

Epoch: 5| Step: 3
Training loss: 0.8446135517003328
Validation loss: 2.580331778581466

Epoch: 5| Step: 4
Training loss: 0.7885463650629387
Validation loss: 2.5856130324725646

Epoch: 5| Step: 5
Training loss: 0.6767763077491638
Validation loss: 2.5938080426455308

Epoch: 5| Step: 6
Training loss: 0.44015653475480354
Validation loss: 2.5757425844565534

Epoch: 5| Step: 7
Training loss: 0.8338221586534535
Validation loss: 2.5899114872587976

Epoch: 5| Step: 8
Training loss: 0.7224005994430961
Validation loss: 2.6250188898128606

Epoch: 5| Step: 9
Training loss: 0.9254839133972356
Validation loss: 2.6020980737465806

Epoch: 5| Step: 10
Training loss: 0.6260896958404802
Validation loss: 2.6270439752240216

Epoch: 357| Step: 0
Training loss: 0.7011022719155857
Validation loss: 2.6267592321086513

Epoch: 5| Step: 1
Training loss: 0.8717541436550074
Validation loss: 2.631313335936767

Epoch: 5| Step: 2
Training loss: 0.5391370196595734
Validation loss: 2.621428793529055

Epoch: 5| Step: 3
Training loss: 0.8052398119485954
Validation loss: 2.6438949570045205

Epoch: 5| Step: 4
Training loss: 0.7926630642998632
Validation loss: 2.605373640040696

Epoch: 5| Step: 5
Training loss: 0.8604742129450139
Validation loss: 2.594972362223737

Epoch: 5| Step: 6
Training loss: 0.6530492245827757
Validation loss: 2.589299794095203

Epoch: 5| Step: 7
Training loss: 0.5058099435345494
Validation loss: 2.598596271009289

Epoch: 5| Step: 8
Training loss: 0.319572559381897
Validation loss: 2.5703094075462336

Epoch: 5| Step: 9
Training loss: 0.7500323447564426
Validation loss: 2.609745667634974

Epoch: 5| Step: 10
Training loss: 1.0662372161707079
Validation loss: 2.5649249900269

Epoch: 358| Step: 0
Training loss: 0.6169348332337116
Validation loss: 2.6064902488121167

Epoch: 5| Step: 1
Training loss: 0.8264415832801771
Validation loss: 2.5690440193957698

Epoch: 5| Step: 2
Training loss: 0.43767377263339
Validation loss: 2.5926678927213445

Epoch: 5| Step: 3
Training loss: 0.9832840581175203
Validation loss: 2.611840979846768

Epoch: 5| Step: 4
Training loss: 0.8561623605024918
Validation loss: 2.6003554408856

Epoch: 5| Step: 5
Training loss: 0.7115772429066859
Validation loss: 2.589978500169599

Epoch: 5| Step: 6
Training loss: 0.4880933171050608
Validation loss: 2.598834990912087

Epoch: 5| Step: 7
Training loss: 0.7716025732734134
Validation loss: 2.624504966564989

Epoch: 5| Step: 8
Training loss: 0.7468973595372702
Validation loss: 2.6057605425351547

Epoch: 5| Step: 9
Training loss: 0.6535486526488794
Validation loss: 2.6318277483267893

Epoch: 5| Step: 10
Training loss: 0.9262234882982731
Validation loss: 2.6526885544246883

Epoch: 359| Step: 0
Training loss: 0.6935485796604405
Validation loss: 2.6344175755680923

Epoch: 5| Step: 1
Training loss: 0.6937676960174557
Validation loss: 2.6692764617516427

Epoch: 5| Step: 2
Training loss: 0.9082936231583133
Validation loss: 2.6878168158295153

Epoch: 5| Step: 3
Training loss: 0.857955523242887
Validation loss: 2.675177523549574

Epoch: 5| Step: 4
Training loss: 0.5698336851351912
Validation loss: 2.6529687447184322

Epoch: 5| Step: 5
Training loss: 0.3768552346684781
Validation loss: 2.63990649356668

Epoch: 5| Step: 6
Training loss: 0.6627681459427095
Validation loss: 2.638918267867128

Epoch: 5| Step: 7
Training loss: 0.9869100232761692
Validation loss: 2.6253610002356487

Epoch: 5| Step: 8
Training loss: 0.7524253254334936
Validation loss: 2.677705020252528

Epoch: 5| Step: 9
Training loss: 0.7515918606992944
Validation loss: 2.6576281939479562

Epoch: 5| Step: 10
Training loss: 0.6478136577678664
Validation loss: 2.6169208428111896

Epoch: 360| Step: 0
Training loss: 0.9375744472190269
Validation loss: 2.621577075745635

Epoch: 5| Step: 1
Training loss: 0.562975417665948
Validation loss: 2.607289957462006

Epoch: 5| Step: 2
Training loss: 0.5772163880393694
Validation loss: 2.6680694548100075

Epoch: 5| Step: 3
Training loss: 1.0676987190123852
Validation loss: 2.661308350972762

Epoch: 5| Step: 4
Training loss: 0.32584720145263674
Validation loss: 2.568887102327441

Epoch: 5| Step: 5
Training loss: 0.7329342283480192
Validation loss: 2.6165876117043196

Epoch: 5| Step: 6
Training loss: 0.687261063063115
Validation loss: 2.5947604730862635

Epoch: 5| Step: 7
Training loss: 0.8440672666492062
Validation loss: 2.5468754751070497

Epoch: 5| Step: 8
Training loss: 0.7046108229508385
Validation loss: 2.5707371077966754

Epoch: 5| Step: 9
Training loss: 0.586905684070163
Validation loss: 2.579590525011569

Epoch: 5| Step: 10
Training loss: 0.9479151435811868
Validation loss: 2.540129634732672

Epoch: 361| Step: 0
Training loss: 0.4475969811261432
Validation loss: 2.59447302231385

Epoch: 5| Step: 1
Training loss: 0.7360449127404978
Validation loss: 2.6040503786436267

Epoch: 5| Step: 2
Training loss: 0.6892361394037155
Validation loss: 2.655905966825318

Epoch: 5| Step: 3
Training loss: 0.885678323716631
Validation loss: 2.6717739617438823

Epoch: 5| Step: 4
Training loss: 0.9570362947292104
Validation loss: 2.6142447935170745

Epoch: 5| Step: 5
Training loss: 0.6435481579091881
Validation loss: 2.60065208340063

Epoch: 5| Step: 6
Training loss: 0.8130892304301789
Validation loss: 2.578235116485739

Epoch: 5| Step: 7
Training loss: 0.8426877505347254
Validation loss: 2.5557452608566154

Epoch: 5| Step: 8
Training loss: 0.5439854167077444
Validation loss: 2.615977262123704

Epoch: 5| Step: 9
Training loss: 1.0685478755487667
Validation loss: 2.5689394895821502

Epoch: 5| Step: 10
Training loss: 0.3309961677974817
Validation loss: 2.6010690162107837

Epoch: 362| Step: 0
Training loss: 0.53339214956795
Validation loss: 2.591625250195352

Epoch: 5| Step: 1
Training loss: 0.7704987229269189
Validation loss: 2.6265435678400584

Epoch: 5| Step: 2
Training loss: 0.6097379239502556
Validation loss: 2.6200582355238464

Epoch: 5| Step: 3
Training loss: 0.7194172622900313
Validation loss: 2.604085791203626

Epoch: 5| Step: 4
Training loss: 0.724365069804287
Validation loss: 2.6279421128756617

Epoch: 5| Step: 5
Training loss: 0.41235382278819416
Validation loss: 2.60369198679392

Epoch: 5| Step: 6
Training loss: 0.7988659539627521
Validation loss: 2.605765115400168

Epoch: 5| Step: 7
Training loss: 0.372520574827147
Validation loss: 2.5808690557209815

Epoch: 5| Step: 8
Training loss: 0.9941362182279693
Validation loss: 2.577944843539461

Epoch: 5| Step: 9
Training loss: 0.7972425847179683
Validation loss: 2.548395844874561

Epoch: 5| Step: 10
Training loss: 0.8712881923278691
Validation loss: 2.5591245690367628

Epoch: 363| Step: 0
Training loss: 0.7884199339927928
Validation loss: 2.517861963182639

Epoch: 5| Step: 1
Training loss: 0.6074582300621947
Validation loss: 2.5679297457928736

Epoch: 5| Step: 2
Training loss: 0.8184327522830529
Validation loss: 2.6039630713503485

Epoch: 5| Step: 3
Training loss: 0.6009506978744491
Validation loss: 2.5790927277657167

Epoch: 5| Step: 4
Training loss: 0.5499469579782291
Validation loss: 2.625944148455286

Epoch: 5| Step: 5
Training loss: 0.4953833171387883
Validation loss: 2.6319118607445597

Epoch: 5| Step: 6
Training loss: 0.5127563440236375
Validation loss: 2.659026163763599

Epoch: 5| Step: 7
Training loss: 0.7038682823653205
Validation loss: 2.606537169139486

Epoch: 5| Step: 8
Training loss: 1.024708955429046
Validation loss: 2.59508348472342

Epoch: 5| Step: 9
Training loss: 0.8602546697953779
Validation loss: 2.560122448675921

Epoch: 5| Step: 10
Training loss: 0.7678014998061369
Validation loss: 2.5669822898604817

Epoch: 364| Step: 0
Training loss: 0.5494174711716324
Validation loss: 2.608453311878065

Epoch: 5| Step: 1
Training loss: 0.6296143188736871
Validation loss: 2.5850436924398195

Epoch: 5| Step: 2
Training loss: 0.6890989263685335
Validation loss: 2.579305227636561

Epoch: 5| Step: 3
Training loss: 0.8349105730538456
Validation loss: 2.623731668097895

Epoch: 5| Step: 4
Training loss: 0.7265169272948184
Validation loss: 2.590311987359015

Epoch: 5| Step: 5
Training loss: 0.8365509776824205
Validation loss: 2.636242880285636

Epoch: 5| Step: 6
Training loss: 0.7509523544080566
Validation loss: 2.6208959511894623

Epoch: 5| Step: 7
Training loss: 0.8016745818005789
Validation loss: 2.6223689330440116

Epoch: 5| Step: 8
Training loss: 0.7671631135191823
Validation loss: 2.5984457795662363

Epoch: 5| Step: 9
Training loss: 0.7803370673024973
Validation loss: 2.5789224663458468

Epoch: 5| Step: 10
Training loss: 0.3031499778642163
Validation loss: 2.5841972112058964

Epoch: 365| Step: 0
Training loss: 0.519748814281012
Validation loss: 2.5600689146500817

Epoch: 5| Step: 1
Training loss: 0.8873650636311454
Validation loss: 2.5758097843512786

Epoch: 5| Step: 2
Training loss: 0.5057984834645268
Validation loss: 2.5916577057066434

Epoch: 5| Step: 3
Training loss: 0.6382381354610226
Validation loss: 2.5846287406640305

Epoch: 5| Step: 4
Training loss: 0.44786203590919893
Validation loss: 2.583557749979598

Epoch: 5| Step: 5
Training loss: 0.9093794884849495
Validation loss: 2.6180868720225137

Epoch: 5| Step: 6
Training loss: 0.6524447517097988
Validation loss: 2.6390562543775262

Epoch: 5| Step: 7
Training loss: 0.5440029476731044
Validation loss: 2.6437409010697865

Epoch: 5| Step: 8
Training loss: 0.7922467106166744
Validation loss: 2.6121411349037205

Epoch: 5| Step: 9
Training loss: 0.6221788153049442
Validation loss: 2.633935032688908

Epoch: 5| Step: 10
Training loss: 0.9267774605954457
Validation loss: 2.599505140328434

Epoch: 366| Step: 0
Training loss: 0.49946825242938137
Validation loss: 2.5926738754736327

Epoch: 5| Step: 1
Training loss: 0.5431945386208249
Validation loss: 2.582739658262941

Epoch: 5| Step: 2
Training loss: 0.6551135531850039
Validation loss: 2.570652536505451

Epoch: 5| Step: 3
Training loss: 0.6687290705320262
Validation loss: 2.6136844745205847

Epoch: 5| Step: 4
Training loss: 0.3827877231286947
Validation loss: 2.5364117513341533

Epoch: 5| Step: 5
Training loss: 0.5022696599117379
Validation loss: 2.5656784118605964

Epoch: 5| Step: 6
Training loss: 0.9475147037824648
Validation loss: 2.5699098323177894

Epoch: 5| Step: 7
Training loss: 0.8800196059708886
Validation loss: 2.5669394623275825

Epoch: 5| Step: 8
Training loss: 0.8671253628850306
Validation loss: 2.6233556434358243

Epoch: 5| Step: 9
Training loss: 0.43798936994708615
Validation loss: 2.595527470823055

Epoch: 5| Step: 10
Training loss: 0.8887924950871675
Validation loss: 2.619280705093559

Epoch: 367| Step: 0
Training loss: 0.6760628615134416
Validation loss: 2.621045729720827

Epoch: 5| Step: 1
Training loss: 0.506724056765434
Validation loss: 2.569883417277763

Epoch: 5| Step: 2
Training loss: 0.6793353604541341
Validation loss: 2.549420271991202

Epoch: 5| Step: 3
Training loss: 0.6981883635149783
Validation loss: 2.574184216260796

Epoch: 5| Step: 4
Training loss: 0.7935393962659043
Validation loss: 2.5570819515535663

Epoch: 5| Step: 5
Training loss: 0.7524684180795991
Validation loss: 2.5602564570785344

Epoch: 5| Step: 6
Training loss: 0.6049220909050279
Validation loss: 2.5955537280978085

Epoch: 5| Step: 7
Training loss: 0.6913019952999363
Validation loss: 2.5498452948358623

Epoch: 5| Step: 8
Training loss: 0.5953517690607777
Validation loss: 2.552321151759463

Epoch: 5| Step: 9
Training loss: 0.4973073218185004
Validation loss: 2.528386781407571

Epoch: 5| Step: 10
Training loss: 0.8933429070986928
Validation loss: 2.556925664452971

Epoch: 368| Step: 0
Training loss: 0.6451446388772223
Validation loss: 2.5584126550930737

Epoch: 5| Step: 1
Training loss: 0.5297541596094982
Validation loss: 2.543497581683835

Epoch: 5| Step: 2
Training loss: 0.6133245222047908
Validation loss: 2.562605841907145

Epoch: 5| Step: 3
Training loss: 0.9265904813147061
Validation loss: 2.579441398476567

Epoch: 5| Step: 4
Training loss: 0.8166979400978721
Validation loss: 2.551940199400247

Epoch: 5| Step: 5
Training loss: 0.6363202819902894
Validation loss: 2.579149492990437

Epoch: 5| Step: 6
Training loss: 0.5095189107730284
Validation loss: 2.5691270241030466

Epoch: 5| Step: 7
Training loss: 0.5331429248403682
Validation loss: 2.557557488538131

Epoch: 5| Step: 8
Training loss: 0.6595499086937644
Validation loss: 2.540906028934395

Epoch: 5| Step: 9
Training loss: 0.6423033152746965
Validation loss: 2.5512301534259483

Epoch: 5| Step: 10
Training loss: 0.7613228184616365
Validation loss: 2.545600031452945

Epoch: 369| Step: 0
Training loss: 0.725521613616049
Validation loss: 2.5731490775320505

Epoch: 5| Step: 1
Training loss: 1.0452846574710395
Validation loss: 2.5806520667675903

Epoch: 5| Step: 2
Training loss: 0.7186621321996317
Validation loss: 2.5538917896117583

Epoch: 5| Step: 3
Training loss: 0.4082676594658792
Validation loss: 2.591453703058535

Epoch: 5| Step: 4
Training loss: 0.6971464936881284
Validation loss: 2.6050921474493305

Epoch: 5| Step: 5
Training loss: 0.6040133303598613
Validation loss: 2.615577124687267

Epoch: 5| Step: 6
Training loss: 0.5706119796169942
Validation loss: 2.598163806256309

Epoch: 5| Step: 7
Training loss: 0.5741338342692495
Validation loss: 2.5990835377452113

Epoch: 5| Step: 8
Training loss: 0.6255920943410688
Validation loss: 2.602052889659558

Epoch: 5| Step: 9
Training loss: 0.583407854247489
Validation loss: 2.6214661990810657

Epoch: 5| Step: 10
Training loss: 0.5943665064416439
Validation loss: 2.584319565189595

Epoch: 370| Step: 0
Training loss: 0.7893230650089988
Validation loss: 2.556539576094888

Epoch: 5| Step: 1
Training loss: 0.6022357641020528
Validation loss: 2.5688882439907834

Epoch: 5| Step: 2
Training loss: 0.7664003922202633
Validation loss: 2.5943868448048604

Epoch: 5| Step: 3
Training loss: 0.6483109362156873
Validation loss: 2.584459621635515

Epoch: 5| Step: 4
Training loss: 0.47134019153032963
Validation loss: 2.5966062005140964

Epoch: 5| Step: 5
Training loss: 0.43513515496616134
Validation loss: 2.591396823021938

Epoch: 5| Step: 6
Training loss: 0.7880633987928686
Validation loss: 2.5834977891187676

Epoch: 5| Step: 7
Training loss: 0.6701222111850823
Validation loss: 2.5993842856970573

Epoch: 5| Step: 8
Training loss: 0.7018280359386988
Validation loss: 2.603684079318953

Epoch: 5| Step: 9
Training loss: 0.6059791382623168
Validation loss: 2.591248499113892

Epoch: 5| Step: 10
Training loss: 0.8620799064353015
Validation loss: 2.6440918061198806

Epoch: 371| Step: 0
Training loss: 0.6689654047934889
Validation loss: 2.6130816393553253

Epoch: 5| Step: 1
Training loss: 0.7660034567777358
Validation loss: 2.5884923257807073

Epoch: 5| Step: 2
Training loss: 0.4588059098685389
Validation loss: 2.5507932169993035

Epoch: 5| Step: 3
Training loss: 0.5220167892540354
Validation loss: 2.5726136564758004

Epoch: 5| Step: 4
Training loss: 0.6468771349369514
Validation loss: 2.55949690489889

Epoch: 5| Step: 5
Training loss: 0.6394271351281184
Validation loss: 2.612530521678292

Epoch: 5| Step: 6
Training loss: 0.6906225860346382
Validation loss: 2.6228308825103666

Epoch: 5| Step: 7
Training loss: 0.7089392277238239
Validation loss: 2.6375415116588083

Epoch: 5| Step: 8
Training loss: 0.7725132515767573
Validation loss: 2.626721009881258

Epoch: 5| Step: 9
Training loss: 0.8752434596188076
Validation loss: 2.6025511431700794

Epoch: 5| Step: 10
Training loss: 0.5418816256090571
Validation loss: 2.6153630276143414

Epoch: 372| Step: 0
Training loss: 0.8656363145660301
Validation loss: 2.5515041351199006

Epoch: 5| Step: 1
Training loss: 0.8007320481978784
Validation loss: 2.573573083596636

Epoch: 5| Step: 2
Training loss: 0.6691152315059181
Validation loss: 2.5799601020201823

Epoch: 5| Step: 3
Training loss: 0.7518184392619796
Validation loss: 2.618588704067897

Epoch: 5| Step: 4
Training loss: 0.49454355209500706
Validation loss: 2.5974070010382966

Epoch: 5| Step: 5
Training loss: 0.6857483179333925
Validation loss: 2.610831017730719

Epoch: 5| Step: 6
Training loss: 0.5688010790178872
Validation loss: 2.563695714658655

Epoch: 5| Step: 7
Training loss: 0.718877366432377
Validation loss: 2.5774672707439623

Epoch: 5| Step: 8
Training loss: 0.7936462364557914
Validation loss: 2.6247356533661046

Epoch: 5| Step: 9
Training loss: 0.48476254433783444
Validation loss: 2.636518443044578

Epoch: 5| Step: 10
Training loss: 0.5706678354787592
Validation loss: 2.625720560506796

Epoch: 373| Step: 0
Training loss: 0.5136016681688615
Validation loss: 2.647432962028021

Epoch: 5| Step: 1
Training loss: 0.4514490572450676
Validation loss: 2.648551263548952

Epoch: 5| Step: 2
Training loss: 0.5106797481028355
Validation loss: 2.6524226208210218

Epoch: 5| Step: 3
Training loss: 0.5142478469595858
Validation loss: 2.630209252304425

Epoch: 5| Step: 4
Training loss: 0.9220173289455823
Validation loss: 2.626457070722899

Epoch: 5| Step: 5
Training loss: 0.6539088222949845
Validation loss: 2.665092202142892

Epoch: 5| Step: 6
Training loss: 0.6509946933330818
Validation loss: 2.6600659750695743

Epoch: 5| Step: 7
Training loss: 0.8648360047859379
Validation loss: 2.6749980496773307

Epoch: 5| Step: 8
Training loss: 0.826047558821597
Validation loss: 2.6277901928468697

Epoch: 5| Step: 9
Training loss: 0.5091239134835222
Validation loss: 2.6562024751063524

Epoch: 5| Step: 10
Training loss: 0.5565677260464614
Validation loss: 2.674170418095795

Epoch: 374| Step: 0
Training loss: 0.6113696830688341
Validation loss: 2.670693199066568

Epoch: 5| Step: 1
Training loss: 0.8522252644703275
Validation loss: 2.657019708382478

Epoch: 5| Step: 2
Training loss: 0.8007687079215029
Validation loss: 2.6833787298085294

Epoch: 5| Step: 3
Training loss: 0.660719726974587
Validation loss: 2.6199050764933047

Epoch: 5| Step: 4
Training loss: 0.4553562345949833
Validation loss: 2.6022771816733923

Epoch: 5| Step: 5
Training loss: 0.40112834051612917
Validation loss: 2.5840613609231897

Epoch: 5| Step: 6
Training loss: 0.8978207669008634
Validation loss: 2.584968521913642

Epoch: 5| Step: 7
Training loss: 0.5404000481300558
Validation loss: 2.6271744290523653

Epoch: 5| Step: 8
Training loss: 0.5427592580068069
Validation loss: 2.6138608416591294

Epoch: 5| Step: 9
Training loss: 0.5149231671453257
Validation loss: 2.611285958511971

Epoch: 5| Step: 10
Training loss: 0.8680055900604677
Validation loss: 2.606864966264105

Epoch: 375| Step: 0
Training loss: 0.7540643555878795
Validation loss: 2.6383717376863856

Epoch: 5| Step: 1
Training loss: 0.7138577942027989
Validation loss: 2.619364559289513

Epoch: 5| Step: 2
Training loss: 0.4863266849113499
Validation loss: 2.580869266802443

Epoch: 5| Step: 3
Training loss: 0.6031523169621564
Validation loss: 2.6078265461839285

Epoch: 5| Step: 4
Training loss: 0.47119216523578766
Validation loss: 2.6177473571103325

Epoch: 5| Step: 5
Training loss: 0.6536890423438572
Validation loss: 2.6129257127309984

Epoch: 5| Step: 6
Training loss: 0.6614768233430807
Validation loss: 2.578090868612403

Epoch: 5| Step: 7
Training loss: 0.5354968191581309
Validation loss: 2.5942514218798562

Epoch: 5| Step: 8
Training loss: 0.87440034209277
Validation loss: 2.599779654269584

Epoch: 5| Step: 9
Training loss: 0.8458253274422839
Validation loss: 2.5459390532679698

Epoch: 5| Step: 10
Training loss: 0.5734714913753008
Validation loss: 2.584918751985202

Epoch: 376| Step: 0
Training loss: 0.5331092723928067
Validation loss: 2.559957527543282

Epoch: 5| Step: 1
Training loss: 0.5134753877634313
Validation loss: 2.567055982744114

Epoch: 5| Step: 2
Training loss: 0.5438122132763875
Validation loss: 2.596472096435781

Epoch: 5| Step: 3
Training loss: 0.387091408937199
Validation loss: 2.6356153807617653

Epoch: 5| Step: 4
Training loss: 0.6580600752871429
Validation loss: 2.5994773588320688

Epoch: 5| Step: 5
Training loss: 0.9972552838743761
Validation loss: 2.626383463256968

Epoch: 5| Step: 6
Training loss: 0.671044124238343
Validation loss: 2.637888015730206

Epoch: 5| Step: 7
Training loss: 0.8020486989325786
Validation loss: 2.6058969300972485

Epoch: 5| Step: 8
Training loss: 0.7027697195396101
Validation loss: 2.576362756353488

Epoch: 5| Step: 9
Training loss: 0.6336483556732874
Validation loss: 2.5558969899042503

Epoch: 5| Step: 10
Training loss: 0.6190001752618963
Validation loss: 2.5409980155298895

Epoch: 377| Step: 0
Training loss: 0.6127613317826216
Validation loss: 2.551480337348702

Epoch: 5| Step: 1
Training loss: 0.7129333483291767
Validation loss: 2.5475011182144143

Epoch: 5| Step: 2
Training loss: 0.4770858111449062
Validation loss: 2.560197886091805

Epoch: 5| Step: 3
Training loss: 0.7451523038856036
Validation loss: 2.5768580943743142

Epoch: 5| Step: 4
Training loss: 0.6257896441826524
Validation loss: 2.5638411849060105

Epoch: 5| Step: 5
Training loss: 0.7782726009970462
Validation loss: 2.600856316735428

Epoch: 5| Step: 6
Training loss: 0.3772099465025588
Validation loss: 2.6120248286178978

Epoch: 5| Step: 7
Training loss: 0.8029186102331051
Validation loss: 2.6218036483549585

Epoch: 5| Step: 8
Training loss: 0.5577122862738348
Validation loss: 2.630003935918066

Epoch: 5| Step: 9
Training loss: 0.38289258080375843
Validation loss: 2.6350100024081877

Epoch: 5| Step: 10
Training loss: 0.8108312268897907
Validation loss: 2.65600095060309

Epoch: 378| Step: 0
Training loss: 0.668032057589678
Validation loss: 2.6317115629650267

Epoch: 5| Step: 1
Training loss: 0.7918140667336703
Validation loss: 2.5642626857821624

Epoch: 5| Step: 2
Training loss: 0.5401184409991834
Validation loss: 2.599072089001082

Epoch: 5| Step: 3
Training loss: 0.4477910782454702
Validation loss: 2.5852256543375685

Epoch: 5| Step: 4
Training loss: 0.5097217175512677
Validation loss: 2.587596559756412

Epoch: 5| Step: 5
Training loss: 0.7360090378900901
Validation loss: 2.6204687113902603

Epoch: 5| Step: 6
Training loss: 0.7074148496871923
Validation loss: 2.5703860016585516

Epoch: 5| Step: 7
Training loss: 0.5279329469885707
Validation loss: 2.622787075077667

Epoch: 5| Step: 8
Training loss: 0.8038338883495794
Validation loss: 2.6170599813163764

Epoch: 5| Step: 9
Training loss: 0.534205127507791
Validation loss: 2.6066299372043065

Epoch: 5| Step: 10
Training loss: 0.5218149630339604
Validation loss: 2.60462848990108

Epoch: 379| Step: 0
Training loss: 0.5321613236786408
Validation loss: 2.615929836379799

Epoch: 5| Step: 1
Training loss: 0.6717369026380896
Validation loss: 2.558412285339015

Epoch: 5| Step: 2
Training loss: 0.35807810924117345
Validation loss: 2.553880811842708

Epoch: 5| Step: 3
Training loss: 0.6738734796712457
Validation loss: 2.5680918853971644

Epoch: 5| Step: 4
Training loss: 0.7010113205560228
Validation loss: 2.596113683425368

Epoch: 5| Step: 5
Training loss: 0.5137262641918287
Validation loss: 2.5628889995639526

Epoch: 5| Step: 6
Training loss: 0.7528452151716826
Validation loss: 2.6218530999372125

Epoch: 5| Step: 7
Training loss: 0.4915022393919726
Validation loss: 2.5765299855209354

Epoch: 5| Step: 8
Training loss: 0.4243555435023986
Validation loss: 2.6238691801647738

Epoch: 5| Step: 9
Training loss: 0.8689414835609933
Validation loss: 2.6030731707730848

Epoch: 5| Step: 10
Training loss: 0.708502992245447
Validation loss: 2.57522732899737

Epoch: 380| Step: 0
Training loss: 0.6445863642392188
Validation loss: 2.5983782879741892

Epoch: 5| Step: 1
Training loss: 0.6051783203544493
Validation loss: 2.5706665471461845

Epoch: 5| Step: 2
Training loss: 0.49167101872937213
Validation loss: 2.5685734180883038

Epoch: 5| Step: 3
Training loss: 0.5387717859063017
Validation loss: 2.6051095908476354

Epoch: 5| Step: 4
Training loss: 0.6375826959641285
Validation loss: 2.591369934499297

Epoch: 5| Step: 5
Training loss: 0.567214967256994
Validation loss: 2.562600184617382

Epoch: 5| Step: 6
Training loss: 0.6186800185037429
Validation loss: 2.619248769509773

Epoch: 5| Step: 7
Training loss: 0.8354387667262432
Validation loss: 2.6302304483314694

Epoch: 5| Step: 8
Training loss: 0.7722186879398083
Validation loss: 2.622872531563886

Epoch: 5| Step: 9
Training loss: 0.6145249409064397
Validation loss: 2.6131374837616987

Epoch: 5| Step: 10
Training loss: 0.2669836666642292
Validation loss: 2.5930099301275455

Epoch: 381| Step: 0
Training loss: 0.7156881546072148
Validation loss: 2.6089213979568484

Epoch: 5| Step: 1
Training loss: 0.548068515298681
Validation loss: 2.609646717268767

Epoch: 5| Step: 2
Training loss: 0.8757954455951327
Validation loss: 2.569465414588213

Epoch: 5| Step: 3
Training loss: 0.7387111562595726
Validation loss: 2.590580220706732

Epoch: 5| Step: 4
Training loss: 0.5863616425491749
Validation loss: 2.5772456912261963

Epoch: 5| Step: 5
Training loss: 0.6909099888424993
Validation loss: 2.5947644181938685

Epoch: 5| Step: 6
Training loss: 0.31012371911165304
Validation loss: 2.6232816596756603

Epoch: 5| Step: 7
Training loss: 0.5993850735801352
Validation loss: 2.6073384700135995

Epoch: 5| Step: 8
Training loss: 0.47995435890128313
Validation loss: 2.5606726006407836

Epoch: 5| Step: 9
Training loss: 0.4397712403828542
Validation loss: 2.5986993188648326

Epoch: 5| Step: 10
Training loss: 0.5670325664001472
Validation loss: 2.598446715854591

Epoch: 382| Step: 0
Training loss: 0.4313644975894268
Validation loss: 2.629076609302526

Epoch: 5| Step: 1
Training loss: 0.4808650359650246
Validation loss: 2.6200608861897265

Epoch: 5| Step: 2
Training loss: 0.7588239389306254
Validation loss: 2.635258218292871

Epoch: 5| Step: 3
Training loss: 0.2802148684669612
Validation loss: 2.6334024798428657

Epoch: 5| Step: 4
Training loss: 0.6205196726490756
Validation loss: 2.628074460893891

Epoch: 5| Step: 5
Training loss: 0.666259765625
Validation loss: 2.6098064497957396

Epoch: 5| Step: 6
Training loss: 0.7121060168866669
Validation loss: 2.601330917158009

Epoch: 5| Step: 7
Training loss: 0.710112585691489
Validation loss: 2.598786835549715

Epoch: 5| Step: 8
Training loss: 0.5573773511335255
Validation loss: 2.6148532920408463

Epoch: 5| Step: 9
Training loss: 0.7615860260971733
Validation loss: 2.6226004255248356

Epoch: 5| Step: 10
Training loss: 0.6816127082769962
Validation loss: 2.5824935866770438

Epoch: 383| Step: 0
Training loss: 0.546640918225129
Validation loss: 2.584241991741661

Epoch: 5| Step: 1
Training loss: 0.6580698574545043
Validation loss: 2.6496150810091956

Epoch: 5| Step: 2
Training loss: 0.5663093747131783
Validation loss: 2.6073560994551643

Epoch: 5| Step: 3
Training loss: 0.7093546087216265
Validation loss: 2.626427189717766

Epoch: 5| Step: 4
Training loss: 0.5217019816511795
Validation loss: 2.65485273330788

Epoch: 5| Step: 5
Training loss: 0.49192238282569223
Validation loss: 2.654761514181946

Epoch: 5| Step: 6
Training loss: 0.6694490860830433
Validation loss: 2.588688902646492

Epoch: 5| Step: 7
Training loss: 0.6404800948966697
Validation loss: 2.5851878434143867

Epoch: 5| Step: 8
Training loss: 0.693209371324744
Validation loss: 2.5435593991511327

Epoch: 5| Step: 9
Training loss: 0.6856073858177091
Validation loss: 2.5696032167879244

Epoch: 5| Step: 10
Training loss: 0.5826198238935935
Validation loss: 2.5268429982834393

Epoch: 384| Step: 0
Training loss: 0.6236663656410716
Validation loss: 2.5576302591794744

Epoch: 5| Step: 1
Training loss: 0.5956260506219394
Validation loss: 2.581253325142805

Epoch: 5| Step: 2
Training loss: 0.5451052777510894
Validation loss: 2.5735864111762483

Epoch: 5| Step: 3
Training loss: 0.41921275390135937
Validation loss: 2.6056201355383557

Epoch: 5| Step: 4
Training loss: 0.7869413210649047
Validation loss: 2.604274737833112

Epoch: 5| Step: 5
Training loss: 0.39467646504105663
Validation loss: 2.620091990462476

Epoch: 5| Step: 6
Training loss: 0.5614884606124239
Validation loss: 2.6010529014310633

Epoch: 5| Step: 7
Training loss: 0.7382707544620205
Validation loss: 2.613431760203371

Epoch: 5| Step: 8
Training loss: 0.6066431039340726
Validation loss: 2.604612377458491

Epoch: 5| Step: 9
Training loss: 0.5263153220475781
Validation loss: 2.6035763965363072

Epoch: 5| Step: 10
Training loss: 0.8195144767972109
Validation loss: 2.5956514556879693

Epoch: 385| Step: 0
Training loss: 0.8015259048406834
Validation loss: 2.594543367323547

Epoch: 5| Step: 1
Training loss: 0.5117824019818403
Validation loss: 2.6301142401705118

Epoch: 5| Step: 2
Training loss: 0.580557063535266
Validation loss: 2.6212444835172137

Epoch: 5| Step: 3
Training loss: 0.6951477198421451
Validation loss: 2.6500799780347237

Epoch: 5| Step: 4
Training loss: 0.6702740469264564
Validation loss: 2.640969188161382

Epoch: 5| Step: 5
Training loss: 0.3877641438991865
Validation loss: 2.633488167185049

Epoch: 5| Step: 6
Training loss: 0.8769889433412823
Validation loss: 2.63055713980089

Epoch: 5| Step: 7
Training loss: 0.5255363857764402
Validation loss: 2.6628736129173256

Epoch: 5| Step: 8
Training loss: 0.4834139272346642
Validation loss: 2.61382227094646

Epoch: 5| Step: 9
Training loss: 0.5032352445194982
Validation loss: 2.6048832107334494

Epoch: 5| Step: 10
Training loss: 0.520116118294981
Validation loss: 2.617389900463621

Epoch: 386| Step: 0
Training loss: 0.8281542934778804
Validation loss: 2.55731144390291

Epoch: 5| Step: 1
Training loss: 0.584945347344158
Validation loss: 2.564506280602426

Epoch: 5| Step: 2
Training loss: 0.6618001210017481
Validation loss: 2.5816741587713263

Epoch: 5| Step: 3
Training loss: 0.463836042462857
Validation loss: 2.561843620930907

Epoch: 5| Step: 4
Training loss: 0.592933092816865
Validation loss: 2.5934959649958325

Epoch: 5| Step: 5
Training loss: 0.374766634807932
Validation loss: 2.5740538481159545

Epoch: 5| Step: 6
Training loss: 0.7226367844717901
Validation loss: 2.62760378746125

Epoch: 5| Step: 7
Training loss: 0.37502578805627435
Validation loss: 2.6567207117206473

Epoch: 5| Step: 8
Training loss: 0.6317252485199072
Validation loss: 2.645186806396133

Epoch: 5| Step: 9
Training loss: 0.6920464132942657
Validation loss: 2.658136046385287

Epoch: 5| Step: 10
Training loss: 0.5349309405203124
Validation loss: 2.6705086498349617

Epoch: 387| Step: 0
Training loss: 0.7106504594441051
Validation loss: 2.6685069627753837

Epoch: 5| Step: 1
Training loss: 0.5256761817189904
Validation loss: 2.6595005209423066

Epoch: 5| Step: 2
Training loss: 0.4399348013971638
Validation loss: 2.6255761806757802

Epoch: 5| Step: 3
Training loss: 0.7139332710707911
Validation loss: 2.6818959998149983

Epoch: 5| Step: 4
Training loss: 0.7169113691395033
Validation loss: 2.6229600143170595

Epoch: 5| Step: 5
Training loss: 0.40972688999139295
Validation loss: 2.6032558548168203

Epoch: 5| Step: 6
Training loss: 0.7180884675510162
Validation loss: 2.632482533874087

Epoch: 5| Step: 7
Training loss: 0.31661996570264084
Validation loss: 2.5915782785064105

Epoch: 5| Step: 8
Training loss: 0.5038858453922029
Validation loss: 2.6088976070574836

Epoch: 5| Step: 9
Training loss: 0.7340350886229151
Validation loss: 2.635891726405965

Epoch: 5| Step: 10
Training loss: 0.733272414675469
Validation loss: 2.652230426537877

Epoch: 388| Step: 0
Training loss: 0.7596160819952121
Validation loss: 2.6648097539728557

Epoch: 5| Step: 1
Training loss: 0.3273637546990843
Validation loss: 2.685772039108262

Epoch: 5| Step: 2
Training loss: 0.6331977613387835
Validation loss: 2.6300524291467027

Epoch: 5| Step: 3
Training loss: 0.7478462926400493
Validation loss: 2.642086495700486

Epoch: 5| Step: 4
Training loss: 0.5658160851096476
Validation loss: 2.5813634376595083

Epoch: 5| Step: 5
Training loss: 0.6452056593116413
Validation loss: 2.5728553610892013

Epoch: 5| Step: 6
Training loss: 0.6567280027584955
Validation loss: 2.57570907442535

Epoch: 5| Step: 7
Training loss: 0.7139786034511578
Validation loss: 2.5846283032450703

Epoch: 5| Step: 8
Training loss: 0.6840105366564535
Validation loss: 2.58809905494653

Epoch: 5| Step: 9
Training loss: 0.620991704463069
Validation loss: 2.65350560405047

Epoch: 5| Step: 10
Training loss: 0.6915780408985939
Validation loss: 2.6726625648222955

Epoch: 389| Step: 0
Training loss: 0.8942312545475302
Validation loss: 2.692080589376443

Epoch: 5| Step: 1
Training loss: 0.7669770894265755
Validation loss: 2.671049100617271

Epoch: 5| Step: 2
Training loss: 0.7145533988250923
Validation loss: 2.646055943900252

Epoch: 5| Step: 3
Training loss: 0.6872718172270321
Validation loss: 2.602865098780228

Epoch: 5| Step: 4
Training loss: 0.43634715777271743
Validation loss: 2.6231113110391373

Epoch: 5| Step: 5
Training loss: 0.7714676867261504
Validation loss: 2.623380747561276

Epoch: 5| Step: 6
Training loss: 0.6248888393730748
Validation loss: 2.6206811279640316

Epoch: 5| Step: 7
Training loss: 0.5680913129162808
Validation loss: 2.6290641502840644

Epoch: 5| Step: 8
Training loss: 0.4783032315725861
Validation loss: 2.649940532002368

Epoch: 5| Step: 9
Training loss: 0.4406445438027734
Validation loss: 2.6574084309260946

Epoch: 5| Step: 10
Training loss: 0.41671552570298553
Validation loss: 2.6313948640343496

Epoch: 390| Step: 0
Training loss: 0.6632655803505437
Validation loss: 2.6895881414177856

Epoch: 5| Step: 1
Training loss: 0.7205732688631815
Validation loss: 2.6826422024535734

Epoch: 5| Step: 2
Training loss: 0.5996423271145698
Validation loss: 2.652325945965739

Epoch: 5| Step: 3
Training loss: 0.7047426688512235
Validation loss: 2.6513764055463076

Epoch: 5| Step: 4
Training loss: 0.4389187594485119
Validation loss: 2.641281672474574

Epoch: 5| Step: 5
Training loss: 0.38900177339992953
Validation loss: 2.6809813203843533

Epoch: 5| Step: 6
Training loss: 0.7126624173209266
Validation loss: 2.696031111478042

Epoch: 5| Step: 7
Training loss: 0.6110208000897503
Validation loss: 2.7172333208343806

Epoch: 5| Step: 8
Training loss: 0.6568903296775243
Validation loss: 2.6827704157192667

Epoch: 5| Step: 9
Training loss: 0.8220107891042974
Validation loss: 2.6740562498471565

Epoch: 5| Step: 10
Training loss: 0.42381792891231396
Validation loss: 2.635868223675741

Epoch: 391| Step: 0
Training loss: 0.438536404134869
Validation loss: 2.6460829728379176

Epoch: 5| Step: 1
Training loss: 0.6011017607910457
Validation loss: 2.682989167225759

Epoch: 5| Step: 2
Training loss: 0.7483268592302376
Validation loss: 2.612131555121911

Epoch: 5| Step: 3
Training loss: 0.4546845334405245
Validation loss: 2.6920924258353343

Epoch: 5| Step: 4
Training loss: 0.7516707249240758
Validation loss: 2.6402795930638017

Epoch: 5| Step: 5
Training loss: 0.6321446226309322
Validation loss: 2.663142571504265

Epoch: 5| Step: 6
Training loss: 0.4640368181565454
Validation loss: 2.6356916902220444

Epoch: 5| Step: 7
Training loss: 0.7212237206866305
Validation loss: 2.6244314547811993

Epoch: 5| Step: 8
Training loss: 0.6162288802205237
Validation loss: 2.6305491444833136

Epoch: 5| Step: 9
Training loss: 0.39642955607766955
Validation loss: 2.656340684494891

Epoch: 5| Step: 10
Training loss: 0.6722332864061871
Validation loss: 2.6305746038912896

Epoch: 392| Step: 0
Training loss: 0.7670682033543429
Validation loss: 2.655111756406466

Epoch: 5| Step: 1
Training loss: 0.5109596154329255
Validation loss: 2.589202876301308

Epoch: 5| Step: 2
Training loss: 0.5708476912880888
Validation loss: 2.6150850047522005

Epoch: 5| Step: 3
Training loss: 0.41984106661383047
Validation loss: 2.6095002603434416

Epoch: 5| Step: 4
Training loss: 0.8657919161610622
Validation loss: 2.544738215406535

Epoch: 5| Step: 5
Training loss: 0.6316666766982804
Validation loss: 2.5948596897824605

Epoch: 5| Step: 6
Training loss: 0.49817642322210065
Validation loss: 2.600608920187406

Epoch: 5| Step: 7
Training loss: 0.5089746821220527
Validation loss: 2.6116570710160225

Epoch: 5| Step: 8
Training loss: 0.5504070661267261
Validation loss: 2.581311396896297

Epoch: 5| Step: 9
Training loss: 0.5834810262993134
Validation loss: 2.5915712392085086

Epoch: 5| Step: 10
Training loss: 0.24834570568395195
Validation loss: 2.611365454347412

Epoch: 393| Step: 0
Training loss: 0.38625716588554965
Validation loss: 2.58682458127329

Epoch: 5| Step: 1
Training loss: 0.6905487475869901
Validation loss: 2.595372093711572

Epoch: 5| Step: 2
Training loss: 0.5348740829260217
Validation loss: 2.6117133640417585

Epoch: 5| Step: 3
Training loss: 0.5833564878591286
Validation loss: 2.599105611475941

Epoch: 5| Step: 4
Training loss: 0.3819152866658774
Validation loss: 2.603253992100181

Epoch: 5| Step: 5
Training loss: 0.5730595728345649
Validation loss: 2.623141310933774

Epoch: 5| Step: 6
Training loss: 0.5337435879199348
Validation loss: 2.6099234492107906

Epoch: 5| Step: 7
Training loss: 0.7486645809989789
Validation loss: 2.637937399030452

Epoch: 5| Step: 8
Training loss: 0.5065242566045965
Validation loss: 2.618507949654465

Epoch: 5| Step: 9
Training loss: 0.702952618130853
Validation loss: 2.5725864395933744

Epoch: 5| Step: 10
Training loss: 0.6126646112612317
Validation loss: 2.589088842801179

Epoch: 394| Step: 0
Training loss: 0.4255050323179781
Validation loss: 2.639594106743423

Epoch: 5| Step: 1
Training loss: 0.6135377529734044
Validation loss: 2.6013285716404035

Epoch: 5| Step: 2
Training loss: 0.653152786466905
Validation loss: 2.605735266685772

Epoch: 5| Step: 3
Training loss: 0.4524638680263789
Validation loss: 2.6136048142993618

Epoch: 5| Step: 4
Training loss: 0.6754265885405818
Validation loss: 2.6012464535387796

Epoch: 5| Step: 5
Training loss: 0.21330294795630386
Validation loss: 2.63402685772446

Epoch: 5| Step: 6
Training loss: 0.721739522598269
Validation loss: 2.6383814000078223

Epoch: 5| Step: 7
Training loss: 0.6871896823711359
Validation loss: 2.6307960291476586

Epoch: 5| Step: 8
Training loss: 0.5977871570709096
Validation loss: 2.5896116814815504

Epoch: 5| Step: 9
Training loss: 0.26491523329369127
Validation loss: 2.6418631744688748

Epoch: 5| Step: 10
Training loss: 0.7326277379959615
Validation loss: 2.591656011224446

Epoch: 395| Step: 0
Training loss: 0.410731974214921
Validation loss: 2.560790482407245

Epoch: 5| Step: 1
Training loss: 0.6490707752139216
Validation loss: 2.6301708219166775

Epoch: 5| Step: 2
Training loss: 0.5832942086677669
Validation loss: 2.6010832069904017

Epoch: 5| Step: 3
Training loss: 0.7055117681658635
Validation loss: 2.5952333334610835

Epoch: 5| Step: 4
Training loss: 0.6974058678047318
Validation loss: 2.6021694992896314

Epoch: 5| Step: 5
Training loss: 0.5399095542096968
Validation loss: 2.6271969381193525

Epoch: 5| Step: 6
Training loss: 0.558769865216252
Validation loss: 2.603412201566868

Epoch: 5| Step: 7
Training loss: 0.4487915163573221
Validation loss: 2.6675196287804575

Epoch: 5| Step: 8
Training loss: 0.49091437850498326
Validation loss: 2.5973384924668057

Epoch: 5| Step: 9
Training loss: 0.5368771970213233
Validation loss: 2.6273153985789373

Epoch: 5| Step: 10
Training loss: 0.6157778564684849
Validation loss: 2.6317397019029896

Epoch: 396| Step: 0
Training loss: 0.5971304132313204
Validation loss: 2.673392489957173

Epoch: 5| Step: 1
Training loss: 0.5011917455217252
Validation loss: 2.6231541284151083

Epoch: 5| Step: 2
Training loss: 0.5607949216488234
Validation loss: 2.6478029212548884

Epoch: 5| Step: 3
Training loss: 0.5468704495921874
Validation loss: 2.6626057474166456

Epoch: 5| Step: 4
Training loss: 0.34508759177939036
Validation loss: 2.616632551173713

Epoch: 5| Step: 5
Training loss: 0.4275927200210189
Validation loss: 2.6139733070614164

Epoch: 5| Step: 6
Training loss: 0.6441934336060272
Validation loss: 2.6588708156049052

Epoch: 5| Step: 7
Training loss: 0.6426429831751328
Validation loss: 2.6470649984712513

Epoch: 5| Step: 8
Training loss: 0.6079599628190916
Validation loss: 2.6890579862631143

Epoch: 5| Step: 9
Training loss: 0.5371905456243594
Validation loss: 2.632594385852929

Epoch: 5| Step: 10
Training loss: 0.6586571550901937
Validation loss: 2.6642833494639335

Epoch: 397| Step: 0
Training loss: 0.7556473782162406
Validation loss: 2.6087456781178266

Epoch: 5| Step: 1
Training loss: 0.7269631378451769
Validation loss: 2.610533995971747

Epoch: 5| Step: 2
Training loss: 0.4420743629032034
Validation loss: 2.623394146297629

Epoch: 5| Step: 3
Training loss: 0.5608238572637493
Validation loss: 2.6178093068855817

Epoch: 5| Step: 4
Training loss: 0.7213266048376128
Validation loss: 2.6511548430316147

Epoch: 5| Step: 5
Training loss: 0.5693264628385892
Validation loss: 2.6175828517868305

Epoch: 5| Step: 6
Training loss: 0.2301409863799298
Validation loss: 2.63164378474649

Epoch: 5| Step: 7
Training loss: 0.4722384505740229
Validation loss: 2.5933617868299756

Epoch: 5| Step: 8
Training loss: 0.6495117572927227
Validation loss: 2.6073234553971645

Epoch: 5| Step: 9
Training loss: 0.5038495290607334
Validation loss: 2.627637293268254

Epoch: 5| Step: 10
Training loss: 0.30179722846413143
Validation loss: 2.6162383316070117

Epoch: 398| Step: 0
Training loss: 0.49017892957123876
Validation loss: 2.630546312396442

Epoch: 5| Step: 1
Training loss: 0.7251573737114598
Validation loss: 2.629852447913875

Epoch: 5| Step: 2
Training loss: 0.4804785812736707
Validation loss: 2.6746387590837197

Epoch: 5| Step: 3
Training loss: 0.647186174966956
Validation loss: 2.6677981470605507

Epoch: 5| Step: 4
Training loss: 0.39924207496062963
Validation loss: 2.6929133564813084

Epoch: 5| Step: 5
Training loss: 0.5399656332082675
Validation loss: 2.688852906868451

Epoch: 5| Step: 6
Training loss: 0.6073629467214314
Validation loss: 2.715472181203749

Epoch: 5| Step: 7
Training loss: 0.4267565205639591
Validation loss: 2.6782065730392963

Epoch: 5| Step: 8
Training loss: 0.8513595619218958
Validation loss: 2.6793458724957655

Epoch: 5| Step: 9
Training loss: 0.7918781617063105
Validation loss: 2.6755916295036095

Epoch: 5| Step: 10
Training loss: 0.5364412348222902
Validation loss: 2.652171923515073

Epoch: 399| Step: 0
Training loss: 0.8008461530481686
Validation loss: 2.667032529327315

Epoch: 5| Step: 1
Training loss: 0.509338697064245
Validation loss: 2.5976970295924544

Epoch: 5| Step: 2
Training loss: 0.6773640173109521
Validation loss: 2.59539388786187

Epoch: 5| Step: 3
Training loss: 0.5419557851302944
Validation loss: 2.613821729544011

Epoch: 5| Step: 4
Training loss: 0.43105635649163965
Validation loss: 2.605388598491363

Epoch: 5| Step: 5
Training loss: 0.5886226165149686
Validation loss: 2.656545924882664

Epoch: 5| Step: 6
Training loss: 0.6238398035493387
Validation loss: 2.67828996547776

Epoch: 5| Step: 7
Training loss: 0.5558749638380069
Validation loss: 2.622891256366397

Epoch: 5| Step: 8
Training loss: 0.7332005951420626
Validation loss: 2.676239680035121

Epoch: 5| Step: 9
Training loss: 0.4964582350817909
Validation loss: 2.652755783350092

Epoch: 5| Step: 10
Training loss: 0.46783544014011386
Validation loss: 2.6488766274868465

Epoch: 400| Step: 0
Training loss: 0.6380166475327391
Validation loss: 2.607193273804114

Epoch: 5| Step: 1
Training loss: 0.40443852840947775
Validation loss: 2.6021268302066685

Epoch: 5| Step: 2
Training loss: 0.46752583873455894
Validation loss: 2.5555133747177927

Epoch: 5| Step: 3
Training loss: 0.6389464508492407
Validation loss: 2.55698984375515

Epoch: 5| Step: 4
Training loss: 0.6339063021664766
Validation loss: 2.5986620011756907

Epoch: 5| Step: 5
Training loss: 0.7867818676385934
Validation loss: 2.6170562485935203

Epoch: 5| Step: 6
Training loss: 0.5662380100185042
Validation loss: 2.5963085961016334

Epoch: 5| Step: 7
Training loss: 0.6363268389141464
Validation loss: 2.6143283302104128

Epoch: 5| Step: 8
Training loss: 0.6282929931241418
Validation loss: 2.624784408990132

Epoch: 5| Step: 9
Training loss: 0.6281281864977427
Validation loss: 2.603081038740192

Epoch: 5| Step: 10
Training loss: 0.5065098413563839
Validation loss: 2.5720862561849325

Testing loss: 2.482956882080068
