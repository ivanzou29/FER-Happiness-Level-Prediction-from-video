Epoch: 1| Step: 0
Training loss: 6.089810848236084
Validation loss: 5.232131086369996

Epoch: 6| Step: 1
Training loss: 5.563572406768799
Validation loss: 5.209253300902664

Epoch: 6| Step: 2
Training loss: 5.258828163146973
Validation loss: 5.189102721470658

Epoch: 6| Step: 3
Training loss: 5.361161231994629
Validation loss: 5.166283530573691

Epoch: 6| Step: 4
Training loss: 4.657130241394043
Validation loss: 5.140397774275913

Epoch: 6| Step: 5
Training loss: 4.891167163848877
Validation loss: 5.109538555145264

Epoch: 6| Step: 6
Training loss: 4.288210868835449
Validation loss: 5.07451670656922

Epoch: 6| Step: 7
Training loss: 3.9245781898498535
Validation loss: 5.03427093772478

Epoch: 6| Step: 8
Training loss: 3.8068554401397705
Validation loss: 4.9888519933146815

Epoch: 6| Step: 9
Training loss: 3.684626340866089
Validation loss: 4.938290585753738

Epoch: 6| Step: 10
Training loss: 4.37026834487915
Validation loss: 4.885059120834515

Epoch: 6| Step: 11
Training loss: 4.981557369232178
Validation loss: 4.827192624409993

Epoch: 6| Step: 12
Training loss: 5.1955037117004395
Validation loss: 4.767771582449636

Epoch: 6| Step: 13
Training loss: 5.971399307250977
Validation loss: 4.7077604006695495

Epoch: 2| Step: 0
Training loss: 4.514090538024902
Validation loss: 4.652534551517938

Epoch: 6| Step: 1
Training loss: 3.3956642150878906
Validation loss: 4.5980409396592

Epoch: 6| Step: 2
Training loss: 5.197972297668457
Validation loss: 4.548493595533474

Epoch: 6| Step: 3
Training loss: 5.179145336151123
Validation loss: 4.498138520025438

Epoch: 6| Step: 4
Training loss: 3.12800931930542
Validation loss: 4.4479068991958455

Epoch: 6| Step: 5
Training loss: 4.4474287033081055
Validation loss: 4.398921728134155

Epoch: 6| Step: 6
Training loss: 3.863344669342041
Validation loss: 4.352267221737933

Epoch: 6| Step: 7
Training loss: 5.5644636154174805
Validation loss: 4.304909260042252

Epoch: 6| Step: 8
Training loss: 4.994955062866211
Validation loss: 4.257169610710554

Epoch: 6| Step: 9
Training loss: 3.719939708709717
Validation loss: 4.206206919044576

Epoch: 6| Step: 10
Training loss: 3.71999192237854
Validation loss: 4.153242567534088

Epoch: 6| Step: 11
Training loss: 3.3399248123168945
Validation loss: 4.095392832192042

Epoch: 6| Step: 12
Training loss: 2.6963090896606445
Validation loss: 4.029176965836556

Epoch: 6| Step: 13
Training loss: 4.152738571166992
Validation loss: 3.973010145207887

Epoch: 3| Step: 0
Training loss: 3.400667428970337
Validation loss: 3.932507791826802

Epoch: 6| Step: 1
Training loss: 3.9845733642578125
Validation loss: 3.898270873613255

Epoch: 6| Step: 2
Training loss: 3.306049108505249
Validation loss: 3.854962969339022

Epoch: 6| Step: 3
Training loss: 2.860776424407959
Validation loss: 3.813840127760364

Epoch: 6| Step: 4
Training loss: 4.0598015785217285
Validation loss: 3.776883248359926

Epoch: 6| Step: 5
Training loss: 3.9190540313720703
Validation loss: 3.7408740546113703

Epoch: 6| Step: 6
Training loss: 3.8929007053375244
Validation loss: 3.7083069227075063

Epoch: 6| Step: 7
Training loss: 3.4172203540802
Validation loss: 3.6786518840379614

Epoch: 6| Step: 8
Training loss: 4.488652229309082
Validation loss: 3.653296842369982

Epoch: 6| Step: 9
Training loss: 4.179986953735352
Validation loss: 3.6289085418947282

Epoch: 6| Step: 10
Training loss: 2.943657398223877
Validation loss: 3.610729448256954

Epoch: 6| Step: 11
Training loss: 4.183142185211182
Validation loss: 3.5923581225897676

Epoch: 6| Step: 12
Training loss: 2.685823440551758
Validation loss: 3.5740068958651636

Epoch: 6| Step: 13
Training loss: 2.9891226291656494
Validation loss: 3.5538457696155836

Epoch: 4| Step: 0
Training loss: 2.2530059814453125
Validation loss: 3.5371999458600114

Epoch: 6| Step: 1
Training loss: 3.991677761077881
Validation loss: 3.519156466248215

Epoch: 6| Step: 2
Training loss: 4.290307998657227
Validation loss: 3.5060066715363534

Epoch: 6| Step: 3
Training loss: 3.4536852836608887
Validation loss: 3.491243598281696

Epoch: 6| Step: 4
Training loss: 3.649484634399414
Validation loss: 3.4798013317969536

Epoch: 6| Step: 5
Training loss: 4.1823410987854
Validation loss: 3.4653555654710337

Epoch: 6| Step: 6
Training loss: 3.4451115131378174
Validation loss: 3.451776804462556

Epoch: 6| Step: 7
Training loss: 3.573046922683716
Validation loss: 3.440111029532648

Epoch: 6| Step: 8
Training loss: 2.6773695945739746
Validation loss: 3.4287722367112354

Epoch: 6| Step: 9
Training loss: 3.805661678314209
Validation loss: 3.4169904980608212

Epoch: 6| Step: 10
Training loss: 2.8363804817199707
Validation loss: 3.406866540190994

Epoch: 6| Step: 11
Training loss: 3.558669090270996
Validation loss: 3.3958549884057816

Epoch: 6| Step: 12
Training loss: 2.552140235900879
Validation loss: 3.3846145650391937

Epoch: 6| Step: 13
Training loss: 3.1589553356170654
Validation loss: 3.373873241486088

Epoch: 5| Step: 0
Training loss: 3.975414752960205
Validation loss: 3.3645303915905695

Epoch: 6| Step: 1
Training loss: 3.81111478805542
Validation loss: 3.353915916976108

Epoch: 6| Step: 2
Training loss: 2.2533717155456543
Validation loss: 3.3421942674985496

Epoch: 6| Step: 3
Training loss: 2.900237560272217
Validation loss: 3.3335285520040863

Epoch: 6| Step: 4
Training loss: 3.358534812927246
Validation loss: 3.323892383165257

Epoch: 6| Step: 5
Training loss: 2.3769164085388184
Validation loss: 3.3116601949097006

Epoch: 6| Step: 6
Training loss: 2.3944149017333984
Validation loss: 3.3037012161747104

Epoch: 6| Step: 7
Training loss: 4.312665939331055
Validation loss: 3.292448684733401

Epoch: 6| Step: 8
Training loss: 2.726987838745117
Validation loss: 3.2747356840359267

Epoch: 6| Step: 9
Training loss: 3.522557020187378
Validation loss: 3.261195921128796

Epoch: 6| Step: 10
Training loss: 3.398059368133545
Validation loss: 3.249697600641558

Epoch: 6| Step: 11
Training loss: 3.5508222579956055
Validation loss: 3.2360152711150465

Epoch: 6| Step: 12
Training loss: 4.037534713745117
Validation loss: 3.2206964031342538

Epoch: 6| Step: 13
Training loss: 2.7166225910186768
Validation loss: 3.2113625105991157

Epoch: 6| Step: 0
Training loss: 3.1478469371795654
Validation loss: 3.205821503875076

Epoch: 6| Step: 1
Training loss: 2.126650810241699
Validation loss: 3.1928154012208343

Epoch: 6| Step: 2
Training loss: 5.021994590759277
Validation loss: 3.184634559897966

Epoch: 6| Step: 3
Training loss: 2.5784802436828613
Validation loss: 3.1757638531346477

Epoch: 6| Step: 4
Training loss: 3.867109537124634
Validation loss: 3.172569808139596

Epoch: 6| Step: 5
Training loss: 3.9918808937072754
Validation loss: 3.166822046361944

Epoch: 6| Step: 6
Training loss: 2.1111197471618652
Validation loss: 3.1549277305603027

Epoch: 6| Step: 7
Training loss: 3.422142505645752
Validation loss: 3.146651268005371

Epoch: 6| Step: 8
Training loss: 3.2606985569000244
Validation loss: 3.1354605126124557

Epoch: 6| Step: 9
Training loss: 3.4959709644317627
Validation loss: 3.125108697081125

Epoch: 6| Step: 10
Training loss: 2.644900321960449
Validation loss: 3.1141648292541504

Epoch: 6| Step: 11
Training loss: 2.779773235321045
Validation loss: 3.106681710930281

Epoch: 6| Step: 12
Training loss: 2.8400702476501465
Validation loss: 3.1015881005153862

Epoch: 6| Step: 13
Training loss: 2.9483742713928223
Validation loss: 3.09757472110051

Epoch: 7| Step: 0
Training loss: 2.634798049926758
Validation loss: 3.1068827670107604

Epoch: 6| Step: 1
Training loss: 3.678889751434326
Validation loss: 3.088002825296053

Epoch: 6| Step: 2
Training loss: 1.4898474216461182
Validation loss: 3.087230020953763

Epoch: 6| Step: 3
Training loss: 3.598630905151367
Validation loss: 3.08715828259786

Epoch: 6| Step: 4
Training loss: 3.9615659713745117
Validation loss: 3.0721215022507535

Epoch: 6| Step: 5
Training loss: 3.745546817779541
Validation loss: 3.0675618648529053

Epoch: 6| Step: 6
Training loss: 3.894497871398926
Validation loss: 3.0652445439369447

Epoch: 6| Step: 7
Training loss: 3.0246996879577637
Validation loss: 3.057184145014773

Epoch: 6| Step: 8
Training loss: 2.4562277793884277
Validation loss: 3.0499075048713276

Epoch: 6| Step: 9
Training loss: 3.323366403579712
Validation loss: 3.0480377469011533

Epoch: 6| Step: 10
Training loss: 2.5819430351257324
Validation loss: 3.0420926411946616

Epoch: 6| Step: 11
Training loss: 3.0714328289031982
Validation loss: 3.0365954265799573

Epoch: 6| Step: 12
Training loss: 2.8530735969543457
Validation loss: 3.031183809362432

Epoch: 6| Step: 13
Training loss: 3.2802884578704834
Validation loss: 3.0288185176029

Epoch: 8| Step: 0
Training loss: 3.330592632293701
Validation loss: 3.0250575183540263

Epoch: 6| Step: 1
Training loss: 3.356581926345825
Validation loss: 3.016660805671446

Epoch: 6| Step: 2
Training loss: 3.95438814163208
Validation loss: 3.0116396411772697

Epoch: 6| Step: 3
Training loss: 2.916893243789673
Validation loss: 3.0059775331968903

Epoch: 6| Step: 4
Training loss: 3.527770519256592
Validation loss: 3.0042247285125074

Epoch: 6| Step: 5
Training loss: 2.6738176345825195
Validation loss: 2.9982929793737267

Epoch: 6| Step: 6
Training loss: 2.994215965270996
Validation loss: 2.994312563250142

Epoch: 6| Step: 7
Training loss: 2.5964345932006836
Validation loss: 2.993631355224117

Epoch: 6| Step: 8
Training loss: 2.784963607788086
Validation loss: 2.985374830102408

Epoch: 6| Step: 9
Training loss: 3.2567477226257324
Validation loss: 3.00194642877066

Epoch: 6| Step: 10
Training loss: 2.5025699138641357
Validation loss: 2.9964048452274774

Epoch: 6| Step: 11
Training loss: 2.8009519577026367
Validation loss: 2.9928563564054427

Epoch: 6| Step: 12
Training loss: 3.3037333488464355
Validation loss: 2.990245234581732

Epoch: 6| Step: 13
Training loss: 2.8282055854797363
Validation loss: 2.9850988875153246

Epoch: 9| Step: 0
Training loss: 3.1299662590026855
Validation loss: 2.9792130941985757

Epoch: 6| Step: 1
Training loss: 2.7970547676086426
Validation loss: 2.9681448910825994

Epoch: 6| Step: 2
Training loss: 2.630685329437256
Validation loss: 2.9630525573607414

Epoch: 6| Step: 3
Training loss: 2.433699131011963
Validation loss: 2.952808654436501

Epoch: 6| Step: 4
Training loss: 3.1475634574890137
Validation loss: 2.944407078527635

Epoch: 6| Step: 5
Training loss: 3.826725482940674
Validation loss: 2.937659973739296

Epoch: 6| Step: 6
Training loss: 2.396365165710449
Validation loss: 2.9282413605720765

Epoch: 6| Step: 7
Training loss: 3.1578588485717773
Validation loss: 2.922278993873186

Epoch: 6| Step: 8
Training loss: 3.035083293914795
Validation loss: 3.0118295556755474

Epoch: 6| Step: 9
Training loss: 3.5078985691070557
Validation loss: 3.0250704083391415

Epoch: 6| Step: 10
Training loss: 3.041804313659668
Validation loss: 3.0180705952387985

Epoch: 6| Step: 11
Training loss: 3.0284976959228516
Validation loss: 3.0203587188515613

Epoch: 6| Step: 12
Training loss: 3.278865337371826
Validation loss: 3.062830199477493

Epoch: 6| Step: 13
Training loss: 3.4848334789276123
Validation loss: 2.9993560519269717

Epoch: 10| Step: 0
Training loss: 3.4663920402526855
Validation loss: 3.048015145845311

Epoch: 6| Step: 1
Training loss: 3.2397706508636475
Validation loss: 3.0521466808934368

Epoch: 6| Step: 2
Training loss: 2.619744300842285
Validation loss: 3.036756402702742

Epoch: 6| Step: 3
Training loss: 3.577436923980713
Validation loss: 3.04629946267733

Epoch: 6| Step: 4
Training loss: 2.4775238037109375
Validation loss: 3.0448231415082048

Epoch: 6| Step: 5
Training loss: 3.6530404090881348
Validation loss: 3.0341207929836806

Epoch: 6| Step: 6
Training loss: 2.804844856262207
Validation loss: 3.0202219306781726

Epoch: 6| Step: 7
Training loss: 4.077266216278076
Validation loss: 3.009372006180466

Epoch: 6| Step: 8
Training loss: 2.5455479621887207
Validation loss: 3.008123907991635

Epoch: 6| Step: 9
Training loss: 2.956376075744629
Validation loss: 3.018321539766045

Epoch: 6| Step: 10
Training loss: 3.4575304985046387
Validation loss: 3.0031775633494058

Epoch: 6| Step: 11
Training loss: 2.6319849491119385
Validation loss: 2.9826322012050177

Epoch: 6| Step: 12
Training loss: 2.1196484565734863
Validation loss: 2.9820704306325605

Epoch: 6| Step: 13
Training loss: 3.854459047317505
Validation loss: 3.0198098510824223

Epoch: 11| Step: 0
Training loss: 2.635702133178711
Validation loss: 2.9816239572340444

Epoch: 6| Step: 1
Training loss: 3.486145257949829
Validation loss: 2.9933330525634108

Epoch: 6| Step: 2
Training loss: 2.850437641143799
Validation loss: 3.0017259197850383

Epoch: 6| Step: 3
Training loss: 3.5461013317108154
Validation loss: 3.0101760100292903

Epoch: 6| Step: 4
Training loss: 3.3126988410949707
Validation loss: 3.015669625292542

Epoch: 6| Step: 5
Training loss: 3.109260320663452
Validation loss: 3.0133795661310994

Epoch: 6| Step: 6
Training loss: 4.1655473709106445
Validation loss: 3.010514161920035

Epoch: 6| Step: 7
Training loss: 2.712175130844116
Validation loss: 2.998013240034862

Epoch: 6| Step: 8
Training loss: 4.0934343338012695
Validation loss: 2.9907115056950557

Epoch: 6| Step: 9
Training loss: 1.9234611988067627
Validation loss: 2.9897567610586844

Epoch: 6| Step: 10
Training loss: 2.3575305938720703
Validation loss: 2.979442911763345

Epoch: 6| Step: 11
Training loss: 2.737208843231201
Validation loss: 2.9695622741535144

Epoch: 6| Step: 12
Training loss: 2.887817859649658
Validation loss: 2.943194079142745

Epoch: 6| Step: 13
Training loss: 2.9805233478546143
Validation loss: 2.9299354091767342

Epoch: 12| Step: 0
Training loss: 3.497542142868042
Validation loss: 2.925767380704162

Epoch: 6| Step: 1
Training loss: 2.0545849800109863
Validation loss: 2.9325884875430854

Epoch: 6| Step: 2
Training loss: 2.212535858154297
Validation loss: 3.0148820646347536

Epoch: 6| Step: 3
Training loss: 3.330040454864502
Validation loss: 3.035422468698153

Epoch: 6| Step: 4
Training loss: 3.3408799171447754
Validation loss: 2.942756199067639

Epoch: 6| Step: 5
Training loss: 3.050806760787964
Validation loss: 2.8938804262427875

Epoch: 6| Step: 6
Training loss: 2.980750560760498
Validation loss: 2.8720594785546743

Epoch: 6| Step: 7
Training loss: 2.8542158603668213
Validation loss: 2.8574163503544305

Epoch: 6| Step: 8
Training loss: 3.548537492752075
Validation loss: 2.882812107762983

Epoch: 6| Step: 9
Training loss: 3.1238296031951904
Validation loss: 2.8802763415921118

Epoch: 6| Step: 10
Training loss: 3.574398994445801
Validation loss: 2.8596441745758057

Epoch: 6| Step: 11
Training loss: 2.5171542167663574
Validation loss: 2.814728613822691

Epoch: 6| Step: 12
Training loss: 3.0858123302459717
Validation loss: 2.80871977344636

Epoch: 6| Step: 13
Training loss: 2.474492073059082
Validation loss: 2.813060716916156

Epoch: 13| Step: 0
Training loss: 3.030622720718384
Validation loss: 2.8163656419323337

Epoch: 6| Step: 1
Training loss: 2.5014562606811523
Validation loss: 2.8196248418541363

Epoch: 6| Step: 2
Training loss: 2.7969937324523926
Validation loss: 2.8135560558688257

Epoch: 6| Step: 3
Training loss: 3.146566390991211
Validation loss: 2.808298087889148

Epoch: 6| Step: 4
Training loss: 3.1536026000976562
Validation loss: 2.7888119297642864

Epoch: 6| Step: 5
Training loss: 3.020667791366577
Validation loss: 2.778367578342397

Epoch: 6| Step: 6
Training loss: 2.622314691543579
Validation loss: 2.773581930386123

Epoch: 6| Step: 7
Training loss: 3.562171697616577
Validation loss: 2.7730313372868363

Epoch: 6| Step: 8
Training loss: 2.4491422176361084
Validation loss: 2.7676293875581477

Epoch: 6| Step: 9
Training loss: 3.331925868988037
Validation loss: 2.7665540684935865

Epoch: 6| Step: 10
Training loss: 3.008460760116577
Validation loss: 2.7637558931945474

Epoch: 6| Step: 11
Training loss: 3.1445460319519043
Validation loss: 2.7645623325019755

Epoch: 6| Step: 12
Training loss: 2.9957027435302734
Validation loss: 2.7645124312370055

Epoch: 6| Step: 13
Training loss: 1.5856517553329468
Validation loss: 2.7664330082554973

Epoch: 14| Step: 0
Training loss: 2.1158461570739746
Validation loss: 2.76321848746269

Epoch: 6| Step: 1
Training loss: 2.0726122856140137
Validation loss: 2.759439355583601

Epoch: 6| Step: 2
Training loss: 4.309362411499023
Validation loss: 2.751455663352884

Epoch: 6| Step: 3
Training loss: 3.191262722015381
Validation loss: 2.7455253062709684

Epoch: 6| Step: 4
Training loss: 2.925537109375
Validation loss: 2.7438931106239237

Epoch: 6| Step: 5
Training loss: 2.758415460586548
Validation loss: 2.742808175343339

Epoch: 6| Step: 6
Training loss: 3.047244071960449
Validation loss: 2.741353875847273

Epoch: 6| Step: 7
Training loss: 2.925520181655884
Validation loss: 2.737541337167063

Epoch: 6| Step: 8
Training loss: 2.5055651664733887
Validation loss: 2.7370292807138092

Epoch: 6| Step: 9
Training loss: 3.044680118560791
Validation loss: 2.734764140139344

Epoch: 6| Step: 10
Training loss: 2.7399940490722656
Validation loss: 2.7337889671325684

Epoch: 6| Step: 11
Training loss: 2.7371959686279297
Validation loss: 2.7347636504839827

Epoch: 6| Step: 12
Training loss: 3.273960590362549
Validation loss: 2.731123237199681

Epoch: 6| Step: 13
Training loss: 2.9015581607818604
Validation loss: 2.7278117120906873

Epoch: 15| Step: 0
Training loss: 3.1129653453826904
Validation loss: 2.7271748896568053

Epoch: 6| Step: 1
Training loss: 3.1056227684020996
Validation loss: 2.726473090469196

Epoch: 6| Step: 2
Training loss: 2.0558571815490723
Validation loss: 2.7225276859857703

Epoch: 6| Step: 3
Training loss: 2.30827260017395
Validation loss: 2.721883886603899

Epoch: 6| Step: 4
Training loss: 2.8837685585021973
Validation loss: 2.7247211958772395

Epoch: 6| Step: 5
Training loss: 2.9020533561706543
Validation loss: 2.7212950055317213

Epoch: 6| Step: 6
Training loss: 3.327462673187256
Validation loss: 2.7204586408471547

Epoch: 6| Step: 7
Training loss: 3.096259117126465
Validation loss: 2.7197744615616335

Epoch: 6| Step: 8
Training loss: 3.422757863998413
Validation loss: 2.7171933830425306

Epoch: 6| Step: 9
Training loss: 2.923153877258301
Validation loss: 2.7145722809658257

Epoch: 6| Step: 10
Training loss: 2.548149824142456
Validation loss: 2.7152330388305006

Epoch: 6| Step: 11
Training loss: 2.6576809883117676
Validation loss: 2.7105832228096585

Epoch: 6| Step: 12
Training loss: 3.1831979751586914
Validation loss: 2.7119428957662275

Epoch: 6| Step: 13
Training loss: 2.7043774127960205
Validation loss: 2.7109194776063323

Epoch: 16| Step: 0
Training loss: 3.308384656906128
Validation loss: 2.7077008678067114

Epoch: 6| Step: 1
Training loss: 3.6617279052734375
Validation loss: 2.7050258267310356

Epoch: 6| Step: 2
Training loss: 2.9207851886749268
Validation loss: 2.7033001530554985

Epoch: 6| Step: 3
Training loss: 3.2941153049468994
Validation loss: 2.7058592406652306

Epoch: 6| Step: 4
Training loss: 3.1538267135620117
Validation loss: 2.7037612879148094

Epoch: 6| Step: 5
Training loss: 2.6814675331115723
Validation loss: 2.7021084011241956

Epoch: 6| Step: 6
Training loss: 2.065108299255371
Validation loss: 2.7032085849392797

Epoch: 6| Step: 7
Training loss: 2.931868076324463
Validation loss: 2.6973322694019606

Epoch: 6| Step: 8
Training loss: 2.714817523956299
Validation loss: 2.701551814233103

Epoch: 6| Step: 9
Training loss: 2.1865646839141846
Validation loss: 2.6999200877322944

Epoch: 6| Step: 10
Training loss: 2.5860464572906494
Validation loss: 2.6987487372531684

Epoch: 6| Step: 11
Training loss: 2.6640048027038574
Validation loss: 2.697806501901278

Epoch: 6| Step: 12
Training loss: 3.078847885131836
Validation loss: 2.695222170122208

Epoch: 6| Step: 13
Training loss: 2.9463424682617188
Validation loss: 2.694452790803807

Epoch: 17| Step: 0
Training loss: 2.5902528762817383
Validation loss: 2.691574288952735

Epoch: 6| Step: 1
Training loss: 3.8941879272460938
Validation loss: 2.690040880633939

Epoch: 6| Step: 2
Training loss: 2.9374828338623047
Validation loss: 2.6910621760993876

Epoch: 6| Step: 3
Training loss: 2.2526612281799316
Validation loss: 2.6936218046372935

Epoch: 6| Step: 4
Training loss: 2.807880401611328
Validation loss: 2.688682553588703

Epoch: 6| Step: 5
Training loss: 2.688751697540283
Validation loss: 2.689207682045557

Epoch: 6| Step: 6
Training loss: 2.9399735927581787
Validation loss: 2.6816786642997497

Epoch: 6| Step: 7
Training loss: 2.856478214263916
Validation loss: 2.683205255898096

Epoch: 6| Step: 8
Training loss: 2.414313316345215
Validation loss: 2.685659029150522

Epoch: 6| Step: 9
Training loss: 2.4513347148895264
Validation loss: 2.6888593525014897

Epoch: 6| Step: 10
Training loss: 2.8854713439941406
Validation loss: 2.697590353668377

Epoch: 6| Step: 11
Training loss: 3.079622268676758
Validation loss: 2.690927456783992

Epoch: 6| Step: 12
Training loss: 3.011420726776123
Validation loss: 2.690842507987894

Epoch: 6| Step: 13
Training loss: 3.5119881629943848
Validation loss: 2.687692052574568

Epoch: 18| Step: 0
Training loss: 2.745875358581543
Validation loss: 2.6810150582303285

Epoch: 6| Step: 1
Training loss: 3.026329517364502
Validation loss: 2.6778983992914998

Epoch: 6| Step: 2
Training loss: 3.6699957847595215
Validation loss: 2.68021499213352

Epoch: 6| Step: 3
Training loss: 3.03304386138916
Validation loss: 2.678429029321158

Epoch: 6| Step: 4
Training loss: 3.085531711578369
Validation loss: 2.6789056178062194

Epoch: 6| Step: 5
Training loss: 2.4402248859405518
Validation loss: 2.6785065435594126

Epoch: 6| Step: 6
Training loss: 2.778745651245117
Validation loss: 2.6729875405629477

Epoch: 6| Step: 7
Training loss: 2.9373083114624023
Validation loss: 2.6753010801089707

Epoch: 6| Step: 8
Training loss: 2.8671529293060303
Validation loss: 2.6739242333237843

Epoch: 6| Step: 9
Training loss: 2.763066291809082
Validation loss: 2.674636097364528

Epoch: 6| Step: 10
Training loss: 2.405824661254883
Validation loss: 2.7028792160813526

Epoch: 6| Step: 11
Training loss: 3.2252726554870605
Validation loss: 2.7221550582557597

Epoch: 6| Step: 12
Training loss: 2.3885631561279297
Validation loss: 2.7229232300994215

Epoch: 6| Step: 13
Training loss: 2.361524820327759
Validation loss: 2.6646967344386603

Epoch: 19| Step: 0
Training loss: 3.9697561264038086
Validation loss: 2.6644146980777865

Epoch: 6| Step: 1
Training loss: 3.041855812072754
Validation loss: 2.6678778381757837

Epoch: 6| Step: 2
Training loss: 2.631352424621582
Validation loss: 2.6774479522499988

Epoch: 6| Step: 3
Training loss: 2.908079147338867
Validation loss: 2.688804386764444

Epoch: 6| Step: 4
Training loss: 2.345763683319092
Validation loss: 2.6947628554477485

Epoch: 6| Step: 5
Training loss: 2.8825368881225586
Validation loss: 2.7049522835721254

Epoch: 6| Step: 6
Training loss: 3.2017343044281006
Validation loss: 2.712477966021466

Epoch: 6| Step: 7
Training loss: 2.6357593536376953
Validation loss: 2.6810134918459

Epoch: 6| Step: 8
Training loss: 2.3284053802490234
Validation loss: 2.674067397271433

Epoch: 6| Step: 9
Training loss: 2.7318108081817627
Validation loss: 2.666413599444974

Epoch: 6| Step: 10
Training loss: 3.486837863922119
Validation loss: 2.6601927639335714

Epoch: 6| Step: 11
Training loss: 2.3870456218719482
Validation loss: 2.6639434547834497

Epoch: 6| Step: 12
Training loss: 2.617030143737793
Validation loss: 2.6775947232400217

Epoch: 6| Step: 13
Training loss: 2.808527946472168
Validation loss: 2.6798513807276243

Epoch: 20| Step: 0
Training loss: 2.683713436126709
Validation loss: 2.6812504465861986

Epoch: 6| Step: 1
Training loss: 2.7831790447235107
Validation loss: 2.6826863083788144

Epoch: 6| Step: 2
Training loss: 2.976226329803467
Validation loss: 2.676445666179862

Epoch: 6| Step: 3
Training loss: 3.2302093505859375
Validation loss: 2.678970821442143

Epoch: 6| Step: 4
Training loss: 2.522519588470459
Validation loss: 2.673683069085562

Epoch: 6| Step: 5
Training loss: 3.135819435119629
Validation loss: 2.6755575031362553

Epoch: 6| Step: 6
Training loss: 3.035831928253174
Validation loss: 2.6676146958463933

Epoch: 6| Step: 7
Training loss: 2.500767230987549
Validation loss: 2.6701177217627086

Epoch: 6| Step: 8
Training loss: 2.754810333251953
Validation loss: 2.6643563624351256

Epoch: 6| Step: 9
Training loss: 3.0418097972869873
Validation loss: 2.6684236398307224

Epoch: 6| Step: 10
Training loss: 2.7130393981933594
Validation loss: 2.6611423979523363

Epoch: 6| Step: 11
Training loss: 2.3839521408081055
Validation loss: 2.6579934653415473

Epoch: 6| Step: 12
Training loss: 2.345099687576294
Validation loss: 2.6553863607427126

Epoch: 6| Step: 13
Training loss: 4.226794719696045
Validation loss: 2.655124336160639

Epoch: 21| Step: 0
Training loss: 2.5890886783599854
Validation loss: 2.6492352639475176

Epoch: 6| Step: 1
Training loss: 3.408940076828003
Validation loss: 2.647048250321419

Epoch: 6| Step: 2
Training loss: 2.58198881149292
Validation loss: 2.6436837180968253

Epoch: 6| Step: 3
Training loss: 2.7840023040771484
Validation loss: 2.641354560852051

Epoch: 6| Step: 4
Training loss: 3.3791310787200928
Validation loss: 2.6370326421594106

Epoch: 6| Step: 5
Training loss: 2.7608516216278076
Validation loss: 2.6357883381587204

Epoch: 6| Step: 6
Training loss: 2.9924280643463135
Validation loss: 2.639747081264373

Epoch: 6| Step: 7
Training loss: 3.276754856109619
Validation loss: 2.6467060427511893

Epoch: 6| Step: 8
Training loss: 2.734271764755249
Validation loss: 2.6448508565143873

Epoch: 6| Step: 9
Training loss: 1.9916080236434937
Validation loss: 2.6575249702699724

Epoch: 6| Step: 10
Training loss: 2.823207139968872
Validation loss: 2.6512612014688473

Epoch: 6| Step: 11
Training loss: 2.451097011566162
Validation loss: 2.648539376515214

Epoch: 6| Step: 12
Training loss: 2.621114730834961
Validation loss: 2.6401701229874805

Epoch: 6| Step: 13
Training loss: 3.4037723541259766
Validation loss: 2.6340787333826863

Epoch: 22| Step: 0
Training loss: 2.120177745819092
Validation loss: 2.6310486665336033

Epoch: 6| Step: 1
Training loss: 2.8982937335968018
Validation loss: 2.6315196611547984

Epoch: 6| Step: 2
Training loss: 2.931946039199829
Validation loss: 2.6390727848135014

Epoch: 6| Step: 3
Training loss: 2.6077871322631836
Validation loss: 2.638212591089228

Epoch: 6| Step: 4
Training loss: 3.252316474914551
Validation loss: 2.6439720712682253

Epoch: 6| Step: 5
Training loss: 2.798740863800049
Validation loss: 2.6412819021491596

Epoch: 6| Step: 6
Training loss: 2.828686237335205
Validation loss: 2.637764112923735

Epoch: 6| Step: 7
Training loss: 2.6114656925201416
Validation loss: 2.628616217643984

Epoch: 6| Step: 8
Training loss: 2.5085651874542236
Validation loss: 2.622131842438893

Epoch: 6| Step: 9
Training loss: 3.0236868858337402
Validation loss: 2.624195339859173

Epoch: 6| Step: 10
Training loss: 2.208221197128296
Validation loss: 2.6284493425840973

Epoch: 6| Step: 11
Training loss: 3.807859420776367
Validation loss: 2.628137542355445

Epoch: 6| Step: 12
Training loss: 2.573336601257324
Validation loss: 2.634895383670766

Epoch: 6| Step: 13
Training loss: 3.443173408508301
Validation loss: 2.6169159463656846

Epoch: 23| Step: 0
Training loss: 2.4303996562957764
Validation loss: 2.6204331074991534

Epoch: 6| Step: 1
Training loss: 3.240015983581543
Validation loss: 2.6226693148254068

Epoch: 6| Step: 2
Training loss: 2.0725557804107666
Validation loss: 2.624207373588316

Epoch: 6| Step: 3
Training loss: 2.586427927017212
Validation loss: 2.6330669413330736

Epoch: 6| Step: 4
Training loss: 2.956852912902832
Validation loss: 2.631484075259137

Epoch: 6| Step: 5
Training loss: 3.098677635192871
Validation loss: 2.6313931531803583

Epoch: 6| Step: 6
Training loss: 2.4173874855041504
Validation loss: 2.623085178354735

Epoch: 6| Step: 7
Training loss: 2.277642011642456
Validation loss: 2.6164560548720823

Epoch: 6| Step: 8
Training loss: 3.0894393920898438
Validation loss: 2.625961216547156

Epoch: 6| Step: 9
Training loss: 2.1989760398864746
Validation loss: 2.688324289937173

Epoch: 6| Step: 10
Training loss: 2.9988017082214355
Validation loss: 2.726737227491153

Epoch: 6| Step: 11
Training loss: 2.690675973892212
Validation loss: 2.775662224779847

Epoch: 6| Step: 12
Training loss: 4.146711826324463
Validation loss: 2.7186444882423646

Epoch: 6| Step: 13
Training loss: 3.497981548309326
Validation loss: 2.6344958069503948

Epoch: 24| Step: 0
Training loss: 3.555088520050049
Validation loss: 2.610030999747656

Epoch: 6| Step: 1
Training loss: 2.72385311126709
Validation loss: 2.610142623224566

Epoch: 6| Step: 2
Training loss: 2.643646478652954
Validation loss: 2.6190550173482587

Epoch: 6| Step: 3
Training loss: 2.3310744762420654
Validation loss: 2.6178576920622136

Epoch: 6| Step: 4
Training loss: 3.220886707305908
Validation loss: 2.6260498313493628

Epoch: 6| Step: 5
Training loss: 3.150885581970215
Validation loss: 2.6293583505897113

Epoch: 6| Step: 6
Training loss: 2.4106035232543945
Validation loss: 2.6303584960199173

Epoch: 6| Step: 7
Training loss: 2.8319125175476074
Validation loss: 2.6293858635810112

Epoch: 6| Step: 8
Training loss: 2.1952576637268066
Validation loss: 2.6256249232958724

Epoch: 6| Step: 9
Training loss: 3.278179168701172
Validation loss: 2.625130186798752

Epoch: 6| Step: 10
Training loss: 3.1427500247955322
Validation loss: 2.6175977081380863

Epoch: 6| Step: 11
Training loss: 2.0154428482055664
Validation loss: 2.6139994539240354

Epoch: 6| Step: 12
Training loss: 2.5288877487182617
Validation loss: 2.6144618680400233

Epoch: 6| Step: 13
Training loss: 3.4217560291290283
Validation loss: 2.613709065221971

Epoch: 25| Step: 0
Training loss: 2.0487537384033203
Validation loss: 2.635099305901476

Epoch: 6| Step: 1
Training loss: 3.0537869930267334
Validation loss: 2.6643262281212756

Epoch: 6| Step: 2
Training loss: 2.4891304969787598
Validation loss: 2.6211857052259546

Epoch: 6| Step: 3
Training loss: 2.4873194694519043
Validation loss: 2.602822370426629

Epoch: 6| Step: 4
Training loss: 2.559657335281372
Validation loss: 2.6128865441968365

Epoch: 6| Step: 5
Training loss: 2.275235891342163
Validation loss: 2.631666419326618

Epoch: 6| Step: 6
Training loss: 3.4358584880828857
Validation loss: 2.649410263184578

Epoch: 6| Step: 7
Training loss: 2.9186344146728516
Validation loss: 2.6476024837904077

Epoch: 6| Step: 8
Training loss: 3.1448307037353516
Validation loss: 2.6361409797463367

Epoch: 6| Step: 9
Training loss: 2.738039016723633
Validation loss: 2.626661208368117

Epoch: 6| Step: 10
Training loss: 3.20585298538208
Validation loss: 2.6170513527367705

Epoch: 6| Step: 11
Training loss: 2.871023178100586
Validation loss: 2.612415667503111

Epoch: 6| Step: 12
Training loss: 2.8539514541625977
Validation loss: 2.6205424339540544

Epoch: 6| Step: 13
Training loss: 3.470080614089966
Validation loss: 2.6318195404544955

Epoch: 26| Step: 0
Training loss: 2.607738494873047
Validation loss: 2.6502747766433226

Epoch: 6| Step: 1
Training loss: 3.5900731086730957
Validation loss: 2.65422123734669

Epoch: 6| Step: 2
Training loss: 3.0425896644592285
Validation loss: 2.636224187830443

Epoch: 6| Step: 3
Training loss: 2.33386492729187
Validation loss: 2.640160729808192

Epoch: 6| Step: 4
Training loss: 3.5913021564483643
Validation loss: 2.6439418690178984

Epoch: 6| Step: 5
Training loss: 2.680619239807129
Validation loss: 2.636132591514177

Epoch: 6| Step: 6
Training loss: 2.9037013053894043
Validation loss: 2.6347807979071014

Epoch: 6| Step: 7
Training loss: 2.6396865844726562
Validation loss: 2.6083022599579184

Epoch: 6| Step: 8
Training loss: 2.444094657897949
Validation loss: 2.5914984697936685

Epoch: 6| Step: 9
Training loss: 2.669604778289795
Validation loss: 2.5906826885797645

Epoch: 6| Step: 10
Training loss: 2.6118555068969727
Validation loss: 2.603047855438725

Epoch: 6| Step: 11
Training loss: 2.8998734951019287
Validation loss: 2.6275854674718713

Epoch: 6| Step: 12
Training loss: 2.4664552211761475
Validation loss: 2.6256783111121065

Epoch: 6| Step: 13
Training loss: 2.3681211471557617
Validation loss: 2.6269578792715587

Epoch: 27| Step: 0
Training loss: 2.4854469299316406
Validation loss: 2.6287105160374797

Epoch: 6| Step: 1
Training loss: 3.045123815536499
Validation loss: 2.6087937611405567

Epoch: 6| Step: 2
Training loss: 3.2120132446289062
Validation loss: 2.601915749170447

Epoch: 6| Step: 3
Training loss: 3.1343212127685547
Validation loss: 2.593888323794129

Epoch: 6| Step: 4
Training loss: 2.4988365173339844
Validation loss: 2.584949831808767

Epoch: 6| Step: 5
Training loss: 3.188615322113037
Validation loss: 2.5811797829084497

Epoch: 6| Step: 6
Training loss: 1.7677617073059082
Validation loss: 2.5759267319915113

Epoch: 6| Step: 7
Training loss: 2.7601919174194336
Validation loss: 2.5785105330969698

Epoch: 6| Step: 8
Training loss: 2.1983375549316406
Validation loss: 2.5950849440789994

Epoch: 6| Step: 9
Training loss: 3.0832417011260986
Validation loss: 2.609172236534857

Epoch: 6| Step: 10
Training loss: 2.4329352378845215
Validation loss: 2.6307815659430718

Epoch: 6| Step: 11
Training loss: 2.7558631896972656
Validation loss: 2.631684608356927

Epoch: 6| Step: 12
Training loss: 3.1491286754608154
Validation loss: 2.630075693130493

Epoch: 6| Step: 13
Training loss: 3.340508460998535
Validation loss: 2.6471784037928425

Epoch: 28| Step: 0
Training loss: 3.111416816711426
Validation loss: 2.6229084845512145

Epoch: 6| Step: 1
Training loss: 2.168696403503418
Validation loss: 2.5994693028029574

Epoch: 6| Step: 2
Training loss: 2.714942455291748
Validation loss: 2.5863948381075295

Epoch: 6| Step: 3
Training loss: 2.6881632804870605
Validation loss: 2.5727517579191472

Epoch: 6| Step: 4
Training loss: 3.1777591705322266
Validation loss: 2.5693290720703783

Epoch: 6| Step: 5
Training loss: 3.097278118133545
Validation loss: 2.569855895093692

Epoch: 6| Step: 6
Training loss: 2.646160364151001
Validation loss: 2.56830265701458

Epoch: 6| Step: 7
Training loss: 2.5137875080108643
Validation loss: 2.568441242300054

Epoch: 6| Step: 8
Training loss: 3.42026948928833
Validation loss: 2.564719061697683

Epoch: 6| Step: 9
Training loss: 2.368621349334717
Validation loss: 2.5637335341463805

Epoch: 6| Step: 10
Training loss: 3.3915069103240967
Validation loss: 2.565212183101203

Epoch: 6| Step: 11
Training loss: 2.165391683578491
Validation loss: 2.5781611473329606

Epoch: 6| Step: 12
Training loss: 2.5941781997680664
Validation loss: 2.5790300958900043

Epoch: 6| Step: 13
Training loss: 2.2658987045288086
Validation loss: 2.573362934973932

Epoch: 29| Step: 0
Training loss: 2.7882113456726074
Validation loss: 2.5706820282884824

Epoch: 6| Step: 1
Training loss: 2.5983927249908447
Validation loss: 2.577200335841025

Epoch: 6| Step: 2
Training loss: 3.760280132293701
Validation loss: 2.585773291126374

Epoch: 6| Step: 3
Training loss: 3.6017022132873535
Validation loss: 2.5882640013130764

Epoch: 6| Step: 4
Training loss: 2.295062303543091
Validation loss: 2.5866675274346465

Epoch: 6| Step: 5
Training loss: 1.8242199420928955
Validation loss: 2.576506366011917

Epoch: 6| Step: 6
Training loss: 2.7200191020965576
Validation loss: 2.56686734127742

Epoch: 6| Step: 7
Training loss: 2.8518357276916504
Validation loss: 2.563590277907669

Epoch: 6| Step: 8
Training loss: 2.2217955589294434
Validation loss: 2.555802816985756

Epoch: 6| Step: 9
Training loss: 3.2472660541534424
Validation loss: 2.559913305826085

Epoch: 6| Step: 10
Training loss: 2.466003179550171
Validation loss: 2.560938871035012

Epoch: 6| Step: 11
Training loss: 2.3456168174743652
Validation loss: 2.5647103786468506

Epoch: 6| Step: 12
Training loss: 2.9137802124023438
Validation loss: 2.572071249767016

Epoch: 6| Step: 13
Training loss: 2.7768125534057617
Validation loss: 2.5723695755004883

Epoch: 30| Step: 0
Training loss: 2.18699312210083
Validation loss: 2.5805268262022283

Epoch: 6| Step: 1
Training loss: 2.827495813369751
Validation loss: 2.584502050953527

Epoch: 6| Step: 2
Training loss: 3.302368640899658
Validation loss: 2.591951870149182

Epoch: 6| Step: 3
Training loss: 2.852802276611328
Validation loss: 2.5833644200396795

Epoch: 6| Step: 4
Training loss: 2.948720932006836
Validation loss: 2.599129469163956

Epoch: 6| Step: 5
Training loss: 1.756507396697998
Validation loss: 2.5767335891723633

Epoch: 6| Step: 6
Training loss: 2.7470788955688477
Validation loss: 2.5600797258397585

Epoch: 6| Step: 7
Training loss: 2.2840328216552734
Validation loss: 2.5485658466175036

Epoch: 6| Step: 8
Training loss: 2.9322519302368164
Validation loss: 2.5406348423291276

Epoch: 6| Step: 9
Training loss: 2.5720887184143066
Validation loss: 2.5442072653001353

Epoch: 6| Step: 10
Training loss: 2.8483922481536865
Validation loss: 2.5484539437037643

Epoch: 6| Step: 11
Training loss: 2.9792165756225586
Validation loss: 2.550100480356524

Epoch: 6| Step: 12
Training loss: 2.9080865383148193
Validation loss: 2.551578806292626

Epoch: 6| Step: 13
Training loss: 3.4181952476501465
Validation loss: 2.5562383641478834

Epoch: 31| Step: 0
Training loss: 2.38333797454834
Validation loss: 2.5516041709530737

Epoch: 6| Step: 1
Training loss: 3.105518341064453
Validation loss: 2.5461781960661694

Epoch: 6| Step: 2
Training loss: 2.670957088470459
Validation loss: 2.5417366104741252

Epoch: 6| Step: 3
Training loss: 2.1197962760925293
Validation loss: 2.539435073893557

Epoch: 6| Step: 4
Training loss: 2.49065899848938
Validation loss: 2.5389959965982745

Epoch: 6| Step: 5
Training loss: 3.3317413330078125
Validation loss: 2.5324578285217285

Epoch: 6| Step: 6
Training loss: 2.3697280883789062
Validation loss: 2.531366127793507

Epoch: 6| Step: 7
Training loss: 3.2293882369995117
Validation loss: 2.525949716567993

Epoch: 6| Step: 8
Training loss: 3.440978527069092
Validation loss: 2.5331209808267574

Epoch: 6| Step: 9
Training loss: 2.4536502361297607
Validation loss: 2.536049804379863

Epoch: 6| Step: 10
Training loss: 2.2062954902648926
Validation loss: 2.549228040120935

Epoch: 6| Step: 11
Training loss: 2.7743191719055176
Validation loss: 2.547891878312634

Epoch: 6| Step: 12
Training loss: 2.473323345184326
Validation loss: 2.5489738320791595

Epoch: 6| Step: 13
Training loss: 3.445615768432617
Validation loss: 2.546706509846513

Epoch: 32| Step: 0
Training loss: 2.8230113983154297
Validation loss: 2.5533053772423857

Epoch: 6| Step: 1
Training loss: 2.7680177688598633
Validation loss: 2.5537384530549407

Epoch: 6| Step: 2
Training loss: 2.460606575012207
Validation loss: 2.543439067820067

Epoch: 6| Step: 3
Training loss: 2.710509777069092
Validation loss: 2.540282669887748

Epoch: 6| Step: 4
Training loss: 2.19384765625
Validation loss: 2.538712857871927

Epoch: 6| Step: 5
Training loss: 2.412141799926758
Validation loss: 2.5421886367182576

Epoch: 6| Step: 6
Training loss: 2.9022154808044434
Validation loss: 2.5790725318334435

Epoch: 6| Step: 7
Training loss: 2.6895337104797363
Validation loss: 2.6116795642401582

Epoch: 6| Step: 8
Training loss: 3.2544312477111816
Validation loss: 2.622991710580805

Epoch: 6| Step: 9
Training loss: 3.238104820251465
Validation loss: 2.637247795699745

Epoch: 6| Step: 10
Training loss: 2.276435136795044
Validation loss: 2.642205786961381

Epoch: 6| Step: 11
Training loss: 3.685908555984497
Validation loss: 2.6597388277771654

Epoch: 6| Step: 12
Training loss: 2.3161370754241943
Validation loss: 2.654570943565779

Epoch: 6| Step: 13
Training loss: 3.316075325012207
Validation loss: 2.627792960853987

Epoch: 33| Step: 0
Training loss: 3.086242198944092
Validation loss: 2.610236193544121

Epoch: 6| Step: 1
Training loss: 2.7116386890411377
Validation loss: 2.598517225634667

Epoch: 6| Step: 2
Training loss: 2.8923521041870117
Validation loss: 2.5854295146080757

Epoch: 6| Step: 3
Training loss: 2.381371021270752
Validation loss: 2.580651016645534

Epoch: 6| Step: 4
Training loss: 2.750631809234619
Validation loss: 2.583238532466273

Epoch: 6| Step: 5
Training loss: 2.5230116844177246
Validation loss: 2.597903500321091

Epoch: 6| Step: 6
Training loss: 3.083761692047119
Validation loss: 2.6140588227138726

Epoch: 6| Step: 7
Training loss: 3.01436185836792
Validation loss: 2.6021210314125143

Epoch: 6| Step: 8
Training loss: 2.9166722297668457
Validation loss: 2.55901159778718

Epoch: 6| Step: 9
Training loss: 2.7003116607666016
Validation loss: 2.5388914820968465

Epoch: 6| Step: 10
Training loss: 2.9334254264831543
Validation loss: 2.5296534825396795

Epoch: 6| Step: 11
Training loss: 2.9252572059631348
Validation loss: 2.51818371716366

Epoch: 6| Step: 12
Training loss: 2.1713743209838867
Validation loss: 2.513413267750894

Epoch: 6| Step: 13
Training loss: 2.0522093772888184
Validation loss: 2.5176101705079437

Epoch: 34| Step: 0
Training loss: 2.607109546661377
Validation loss: 2.5904057871910835

Epoch: 6| Step: 1
Training loss: 2.816410541534424
Validation loss: 2.7363867708431777

Epoch: 6| Step: 2
Training loss: 3.648369073867798
Validation loss: 2.8707938168638494

Epoch: 6| Step: 3
Training loss: 2.611166477203369
Validation loss: 2.83004669989309

Epoch: 6| Step: 4
Training loss: 2.5331411361694336
Validation loss: 2.7253832740168416

Epoch: 6| Step: 5
Training loss: 1.8495725393295288
Validation loss: 2.617907198526526

Epoch: 6| Step: 6
Training loss: 2.2240190505981445
Validation loss: 2.5381940128982707

Epoch: 6| Step: 7
Training loss: 2.5225162506103516
Validation loss: 2.5157585272225003

Epoch: 6| Step: 8
Training loss: 2.835897922515869
Validation loss: 2.502928226224838

Epoch: 6| Step: 9
Training loss: 3.6795194149017334
Validation loss: 2.504948182772565

Epoch: 6| Step: 10
Training loss: 2.155578136444092
Validation loss: 2.5072768324164936

Epoch: 6| Step: 11
Training loss: 2.8596444129943848
Validation loss: 2.5237369050261793

Epoch: 6| Step: 12
Training loss: 3.587585926055908
Validation loss: 2.533676673007268

Epoch: 6| Step: 13
Training loss: 2.335604429244995
Validation loss: 2.5400583949140323

Epoch: 35| Step: 0
Training loss: 2.630323886871338
Validation loss: 2.546790797223327

Epoch: 6| Step: 1
Training loss: 2.9143505096435547
Validation loss: 2.5343218234277542

Epoch: 6| Step: 2
Training loss: 2.8265507221221924
Validation loss: 2.5051277247808312

Epoch: 6| Step: 3
Training loss: 2.1840548515319824
Validation loss: 2.5007931288852485

Epoch: 6| Step: 4
Training loss: 2.3728151321411133
Validation loss: 2.5001931626309633

Epoch: 6| Step: 5
Training loss: 2.6812350749969482
Validation loss: 2.5113448430133123

Epoch: 6| Step: 6
Training loss: 2.5598320960998535
Validation loss: 2.516404546717162

Epoch: 6| Step: 7
Training loss: 2.675814151763916
Validation loss: 2.5263182937457995

Epoch: 6| Step: 8
Training loss: 3.0803139209747314
Validation loss: 2.532350799088837

Epoch: 6| Step: 9
Training loss: 2.2813937664031982
Validation loss: 2.535479240520026

Epoch: 6| Step: 10
Training loss: 3.2564682960510254
Validation loss: 2.5602372231022006

Epoch: 6| Step: 11
Training loss: 2.6251630783081055
Validation loss: 2.5768107368100073

Epoch: 6| Step: 12
Training loss: 3.1671676635742188
Validation loss: 2.589744985744517

Epoch: 6| Step: 13
Training loss: 2.840970516204834
Validation loss: 2.5783505721758773

Epoch: 36| Step: 0
Training loss: 2.589602470397949
Validation loss: 2.5444179273420766

Epoch: 6| Step: 1
Training loss: 3.020594358444214
Validation loss: 2.5259509727519047

Epoch: 6| Step: 2
Training loss: 2.7574830055236816
Validation loss: 2.504363113834012

Epoch: 6| Step: 3
Training loss: 2.2174124717712402
Validation loss: 2.4991237014852543

Epoch: 6| Step: 4
Training loss: 2.500535726547241
Validation loss: 2.4927135257310766

Epoch: 6| Step: 5
Training loss: 2.4410576820373535
Validation loss: 2.488656208079348

Epoch: 6| Step: 6
Training loss: 2.6776740550994873
Validation loss: 2.491841247004847

Epoch: 6| Step: 7
Training loss: 2.7850236892700195
Validation loss: 2.4911606901435444

Epoch: 6| Step: 8
Training loss: 2.9550364017486572
Validation loss: 2.4904131299705914

Epoch: 6| Step: 9
Training loss: 2.4251341819763184
Validation loss: 2.4901273224943425

Epoch: 6| Step: 10
Training loss: 3.012025833129883
Validation loss: 2.4869247110941077

Epoch: 6| Step: 11
Training loss: 2.4580323696136475
Validation loss: 2.4843687985533025

Epoch: 6| Step: 12
Training loss: 2.7205097675323486
Validation loss: 2.48561002362159

Epoch: 6| Step: 13
Training loss: 3.5280368328094482
Validation loss: 2.488877027265487

Epoch: 37| Step: 0
Training loss: 3.3137502670288086
Validation loss: 2.502519392198132

Epoch: 6| Step: 1
Training loss: 2.3299360275268555
Validation loss: 2.5055799638071368

Epoch: 6| Step: 2
Training loss: 2.3684539794921875
Validation loss: 2.502079257401087

Epoch: 6| Step: 3
Training loss: 2.9086122512817383
Validation loss: 2.4955348430141324

Epoch: 6| Step: 4
Training loss: 2.6868696212768555
Validation loss: 2.489483223166517

Epoch: 6| Step: 5
Training loss: 2.7211294174194336
Validation loss: 2.4868786386264268

Epoch: 6| Step: 6
Training loss: 2.3906118869781494
Validation loss: 2.4800041875531598

Epoch: 6| Step: 7
Training loss: 3.2943551540374756
Validation loss: 2.479812390060835

Epoch: 6| Step: 8
Training loss: 2.743281364440918
Validation loss: 2.478760988481583

Epoch: 6| Step: 9
Training loss: 2.5848069190979004
Validation loss: 2.4806804759528047

Epoch: 6| Step: 10
Training loss: 2.1662280559539795
Validation loss: 2.479351624365776

Epoch: 6| Step: 11
Training loss: 2.9145383834838867
Validation loss: 2.474845693957421

Epoch: 6| Step: 12
Training loss: 2.297682523727417
Validation loss: 2.4805290135004188

Epoch: 6| Step: 13
Training loss: 3.202580451965332
Validation loss: 2.489318270837107

Epoch: 38| Step: 0
Training loss: 2.611020803451538
Validation loss: 2.4885228833844586

Epoch: 6| Step: 1
Training loss: 2.8825480937957764
Validation loss: 2.489885622455228

Epoch: 6| Step: 2
Training loss: 2.8654043674468994
Validation loss: 2.485830804353119

Epoch: 6| Step: 3
Training loss: 2.328507900238037
Validation loss: 2.4910413116537113

Epoch: 6| Step: 4
Training loss: 2.594444990158081
Validation loss: 2.486238064304475

Epoch: 6| Step: 5
Training loss: 2.9520936012268066
Validation loss: 2.4951079173754622

Epoch: 6| Step: 6
Training loss: 2.7458691596984863
Validation loss: 2.510044003045687

Epoch: 6| Step: 7
Training loss: 2.824491262435913
Validation loss: 2.5207689269896476

Epoch: 6| Step: 8
Training loss: 2.9966330528259277
Validation loss: 2.533322831635834

Epoch: 6| Step: 9
Training loss: 3.0643107891082764
Validation loss: 2.5430675424555296

Epoch: 6| Step: 10
Training loss: 1.9057750701904297
Validation loss: 2.534171441549896

Epoch: 6| Step: 11
Training loss: 2.558670997619629
Validation loss: 2.527278023381387

Epoch: 6| Step: 12
Training loss: 2.4638748168945312
Validation loss: 2.50792198283698

Epoch: 6| Step: 13
Training loss: 3.0474853515625
Validation loss: 2.4872634564676592

Epoch: 39| Step: 0
Training loss: 2.7746567726135254
Validation loss: 2.4846677639151133

Epoch: 6| Step: 1
Training loss: 2.4393117427825928
Validation loss: 2.4821695255976852

Epoch: 6| Step: 2
Training loss: 2.332812786102295
Validation loss: 2.485499797328826

Epoch: 6| Step: 3
Training loss: 2.1124141216278076
Validation loss: 2.4909287768025554

Epoch: 6| Step: 4
Training loss: 3.3476808071136475
Validation loss: 2.4900198495516213

Epoch: 6| Step: 5
Training loss: 2.644862174987793
Validation loss: 2.4852988027757212

Epoch: 6| Step: 6
Training loss: 2.5651135444641113
Validation loss: 2.485746811794978

Epoch: 6| Step: 7
Training loss: 2.6458258628845215
Validation loss: 2.4818144254786993

Epoch: 6| Step: 8
Training loss: 3.1068224906921387
Validation loss: 2.4745698103340725

Epoch: 6| Step: 9
Training loss: 2.5011656284332275
Validation loss: 2.467562634457824

Epoch: 6| Step: 10
Training loss: 2.6714043617248535
Validation loss: 2.461734171836607

Epoch: 6| Step: 11
Training loss: 2.799272298812866
Validation loss: 2.4703313304531958

Epoch: 6| Step: 12
Training loss: 3.125113010406494
Validation loss: 2.4722549530767624

Epoch: 6| Step: 13
Training loss: 2.79296612739563
Validation loss: 2.483570542386783

Epoch: 40| Step: 0
Training loss: 2.827098846435547
Validation loss: 2.480262497419952

Epoch: 6| Step: 1
Training loss: 2.386213779449463
Validation loss: 2.481148681332988

Epoch: 6| Step: 2
Training loss: 2.8373804092407227
Validation loss: 2.4733052945906118

Epoch: 6| Step: 3
Training loss: 2.998082399368286
Validation loss: 2.4674797840015863

Epoch: 6| Step: 4
Training loss: 3.3419320583343506
Validation loss: 2.4625379577759774

Epoch: 6| Step: 5
Training loss: 2.83976674079895
Validation loss: 2.4598896426539265

Epoch: 6| Step: 6
Training loss: 3.1045150756835938
Validation loss: 2.462105748473957

Epoch: 6| Step: 7
Training loss: 2.0712814331054688
Validation loss: 2.4635339526719946

Epoch: 6| Step: 8
Training loss: 2.4022297859191895
Validation loss: 2.4680700789215746

Epoch: 6| Step: 9
Training loss: 2.7210569381713867
Validation loss: 2.4659629227012716

Epoch: 6| Step: 10
Training loss: 2.683176040649414
Validation loss: 2.4584959630043275

Epoch: 6| Step: 11
Training loss: 2.1631691455841064
Validation loss: 2.4564451658597557

Epoch: 6| Step: 12
Training loss: 2.603733539581299
Validation loss: 2.455023298981369

Epoch: 6| Step: 13
Training loss: 2.380125045776367
Validation loss: 2.4544899489289973

Epoch: 41| Step: 0
Training loss: 2.631831407546997
Validation loss: 2.4523561205915225

Epoch: 6| Step: 1
Training loss: 2.4440536499023438
Validation loss: 2.4591843722968973

Epoch: 6| Step: 2
Training loss: 2.4865548610687256
Validation loss: 2.462293550532351

Epoch: 6| Step: 3
Training loss: 2.84466814994812
Validation loss: 2.4750561150171424

Epoch: 6| Step: 4
Training loss: 2.664278030395508
Validation loss: 2.4662177357622372

Epoch: 6| Step: 5
Training loss: 2.32962703704834
Validation loss: 2.463793736632152

Epoch: 6| Step: 6
Training loss: 2.3316152095794678
Validation loss: 2.46522771158526

Epoch: 6| Step: 7
Training loss: 2.8541712760925293
Validation loss: 2.462208568408925

Epoch: 6| Step: 8
Training loss: 2.861553192138672
Validation loss: 2.4554828802744546

Epoch: 6| Step: 9
Training loss: 3.092987298965454
Validation loss: 2.451401569510019

Epoch: 6| Step: 10
Training loss: 2.4293980598449707
Validation loss: 2.4491363289535686

Epoch: 6| Step: 11
Training loss: 3.316187620162964
Validation loss: 2.4476463615253405

Epoch: 6| Step: 12
Training loss: 2.2088184356689453
Validation loss: 2.448369049256848

Epoch: 6| Step: 13
Training loss: 3.017453670501709
Validation loss: 2.445559053010838

Epoch: 42| Step: 0
Training loss: 2.761470317840576
Validation loss: 2.4488200397901636

Epoch: 6| Step: 1
Training loss: 2.7212462425231934
Validation loss: 2.442051531166159

Epoch: 6| Step: 2
Training loss: 2.4419233798980713
Validation loss: 2.441435960031325

Epoch: 6| Step: 3
Training loss: 2.3505876064300537
Validation loss: 2.443550989192019

Epoch: 6| Step: 4
Training loss: 2.8962202072143555
Validation loss: 2.450033562157744

Epoch: 6| Step: 5
Training loss: 2.8189620971679688
Validation loss: 2.443855772736252

Epoch: 6| Step: 6
Training loss: 2.7586281299591064
Validation loss: 2.446234292881463

Epoch: 6| Step: 7
Training loss: 2.678668260574341
Validation loss: 2.4425960304916545

Epoch: 6| Step: 8
Training loss: 2.264035224914551
Validation loss: 2.4407379704137004

Epoch: 6| Step: 9
Training loss: 2.4118711948394775
Validation loss: 2.4421866555367746

Epoch: 6| Step: 10
Training loss: 2.593276023864746
Validation loss: 2.4388749702002412

Epoch: 6| Step: 11
Training loss: 3.064314365386963
Validation loss: 2.439342978180096

Epoch: 6| Step: 12
Training loss: 2.302009105682373
Validation loss: 2.445193418892481

Epoch: 6| Step: 13
Training loss: 3.655043363571167
Validation loss: 2.4664167255483647

Epoch: 43| Step: 0
Training loss: 3.331350564956665
Validation loss: 2.481664057700865

Epoch: 6| Step: 1
Training loss: 2.3155856132507324
Validation loss: 2.478113515402681

Epoch: 6| Step: 2
Training loss: 2.691279172897339
Validation loss: 2.483291790049563

Epoch: 6| Step: 3
Training loss: 2.3809823989868164
Validation loss: 2.462330146502423

Epoch: 6| Step: 4
Training loss: 3.1432695388793945
Validation loss: 2.4592221834326304

Epoch: 6| Step: 5
Training loss: 2.371365785598755
Validation loss: 2.449755850658622

Epoch: 6| Step: 6
Training loss: 2.427196979522705
Validation loss: 2.4434192770270893

Epoch: 6| Step: 7
Training loss: 3.645371675491333
Validation loss: 2.442833467196393

Epoch: 6| Step: 8
Training loss: 2.619218111038208
Validation loss: 2.4388834481598227

Epoch: 6| Step: 9
Training loss: 3.143205165863037
Validation loss: 2.4347462551568144

Epoch: 6| Step: 10
Training loss: 2.4074292182922363
Validation loss: 2.4308507416837957

Epoch: 6| Step: 11
Training loss: 2.9168331623077393
Validation loss: 2.436527050951476

Epoch: 6| Step: 12
Training loss: 1.8507312536239624
Validation loss: 2.433760381514026

Epoch: 6| Step: 13
Training loss: 1.70613694190979
Validation loss: 2.432815231302733

Epoch: 44| Step: 0
Training loss: 1.8923406600952148
Validation loss: 2.4328637635836037

Epoch: 6| Step: 1
Training loss: 2.4701614379882812
Validation loss: 2.4408782143746652

Epoch: 6| Step: 2
Training loss: 3.6534128189086914
Validation loss: 2.4569247743134857

Epoch: 6| Step: 3
Training loss: 2.4753634929656982
Validation loss: 2.4519065451878372

Epoch: 6| Step: 4
Training loss: 2.8545968532562256
Validation loss: 2.4901190265532462

Epoch: 6| Step: 5
Training loss: 3.65474796295166
Validation loss: 2.463706821523687

Epoch: 6| Step: 6
Training loss: 2.053534984588623
Validation loss: 2.4312940130951586

Epoch: 6| Step: 7
Training loss: 2.1866180896759033
Validation loss: 2.4304636934752106

Epoch: 6| Step: 8
Training loss: 2.8414316177368164
Validation loss: 2.4396139575589086

Epoch: 6| Step: 9
Training loss: 2.8804824352264404
Validation loss: 2.442669476232221

Epoch: 6| Step: 10
Training loss: 2.808957815170288
Validation loss: 2.445676806152508

Epoch: 6| Step: 11
Training loss: 2.5021486282348633
Validation loss: 2.445410777163762

Epoch: 6| Step: 12
Training loss: 2.6139092445373535
Validation loss: 2.4392518202463784

Epoch: 6| Step: 13
Training loss: 2.8690013885498047
Validation loss: 2.4357169494833997

Epoch: 45| Step: 0
Training loss: 3.125363349914551
Validation loss: 2.433370392809632

Epoch: 6| Step: 1
Training loss: 2.151689291000366
Validation loss: 2.434153961878951

Epoch: 6| Step: 2
Training loss: 2.858642101287842
Validation loss: 2.423574560432024

Epoch: 6| Step: 3
Training loss: 1.959425687789917
Validation loss: 2.4215335871583674

Epoch: 6| Step: 4
Training loss: 3.5850677490234375
Validation loss: 2.4205657846184185

Epoch: 6| Step: 5
Training loss: 2.4669981002807617
Validation loss: 2.431933077432776

Epoch: 6| Step: 6
Training loss: 2.615103006362915
Validation loss: 2.4381331551459526

Epoch: 6| Step: 7
Training loss: 3.2990753650665283
Validation loss: 2.4438068430910826

Epoch: 6| Step: 8
Training loss: 2.276327133178711
Validation loss: 2.442265061921971

Epoch: 6| Step: 9
Training loss: 2.680878162384033
Validation loss: 2.4352536816750803

Epoch: 6| Step: 10
Training loss: 3.2140512466430664
Validation loss: 2.4263527034431376

Epoch: 6| Step: 11
Training loss: 2.604182720184326
Validation loss: 2.4163275687925276

Epoch: 6| Step: 12
Training loss: 2.291069269180298
Validation loss: 2.4188383420308432

Epoch: 6| Step: 13
Training loss: 1.7059696912765503
Validation loss: 2.4189132605829546

Epoch: 46| Step: 0
Training loss: 2.046846389770508
Validation loss: 2.4208495514367216

Epoch: 6| Step: 1
Training loss: 2.446650266647339
Validation loss: 2.4227330915389524

Epoch: 6| Step: 2
Training loss: 3.5470504760742188
Validation loss: 2.437513300167617

Epoch: 6| Step: 3
Training loss: 1.971943974494934
Validation loss: 2.4393151062791065

Epoch: 6| Step: 4
Training loss: 3.202446937561035
Validation loss: 2.465070237395584

Epoch: 6| Step: 5
Training loss: 3.2921829223632812
Validation loss: 2.4573280606218564

Epoch: 6| Step: 6
Training loss: 2.584287643432617
Validation loss: 2.465217085294826

Epoch: 6| Step: 7
Training loss: 2.708164691925049
Validation loss: 2.4710169607593166

Epoch: 6| Step: 8
Training loss: 1.5728912353515625
Validation loss: 2.4576497359942366

Epoch: 6| Step: 9
Training loss: 1.942054271697998
Validation loss: 2.439550881744713

Epoch: 6| Step: 10
Training loss: 3.121798038482666
Validation loss: 2.4274869144603772

Epoch: 6| Step: 11
Training loss: 3.0619876384735107
Validation loss: 2.413756844817951

Epoch: 6| Step: 12
Training loss: 3.2963037490844727
Validation loss: 2.409736220554639

Epoch: 6| Step: 13
Training loss: 2.3111941814422607
Validation loss: 2.408989473055768

Epoch: 47| Step: 0
Training loss: 2.616720676422119
Validation loss: 2.4113424516493276

Epoch: 6| Step: 1
Training loss: 2.516615867614746
Validation loss: 2.4132487543167604

Epoch: 6| Step: 2
Training loss: 2.3980493545532227
Validation loss: 2.412793177430348

Epoch: 6| Step: 3
Training loss: 2.5644054412841797
Validation loss: 2.4153726716195383

Epoch: 6| Step: 4
Training loss: 2.2834954261779785
Validation loss: 2.4246584958927606

Epoch: 6| Step: 5
Training loss: 2.79575514793396
Validation loss: 2.433649680947745

Epoch: 6| Step: 6
Training loss: 2.725698471069336
Validation loss: 2.453023177321239

Epoch: 6| Step: 7
Training loss: 3.308345317840576
Validation loss: 2.4457277585101385

Epoch: 6| Step: 8
Training loss: 2.1174802780151367
Validation loss: 2.4266651099728

Epoch: 6| Step: 9
Training loss: 2.5220205783843994
Validation loss: 2.4145143826802573

Epoch: 6| Step: 10
Training loss: 2.6206307411193848
Validation loss: 2.4128339316255305

Epoch: 6| Step: 11
Training loss: 3.252624034881592
Validation loss: 2.4066724597766833

Epoch: 6| Step: 12
Training loss: 2.9233040809631348
Validation loss: 2.405210025848881

Epoch: 6| Step: 13
Training loss: 2.4333417415618896
Validation loss: 2.403442346921531

Epoch: 48| Step: 0
Training loss: 3.5618109703063965
Validation loss: 2.4023901544591433

Epoch: 6| Step: 1
Training loss: 3.005598783493042
Validation loss: 2.4010865303777877

Epoch: 6| Step: 2
Training loss: 2.4318654537200928
Validation loss: 2.3973131051627536

Epoch: 6| Step: 3
Training loss: 2.464245080947876
Validation loss: 2.396096683317615

Epoch: 6| Step: 4
Training loss: 3.0786166191101074
Validation loss: 2.401689483273414

Epoch: 6| Step: 5
Training loss: 2.831988573074341
Validation loss: 2.3925816782059206

Epoch: 6| Step: 6
Training loss: 2.3332886695861816
Validation loss: 2.3946127122448337

Epoch: 6| Step: 7
Training loss: 2.6412124633789062
Validation loss: 2.3905536436265513

Epoch: 6| Step: 8
Training loss: 2.4824843406677246
Validation loss: 2.395544913507277

Epoch: 6| Step: 9
Training loss: 2.888324499130249
Validation loss: 2.394389542200232

Epoch: 6| Step: 10
Training loss: 2.389453649520874
Validation loss: 2.392935960523544

Epoch: 6| Step: 11
Training loss: 1.8685404062271118
Validation loss: 2.3931529701396985

Epoch: 6| Step: 12
Training loss: 2.1577274799346924
Validation loss: 2.391592223157165

Epoch: 6| Step: 13
Training loss: 3.0211477279663086
Validation loss: 2.3919247760567615

Epoch: 49| Step: 0
Training loss: 2.7564120292663574
Validation loss: 2.398963689804077

Epoch: 6| Step: 1
Training loss: 2.521414041519165
Validation loss: 2.4151508885045208

Epoch: 6| Step: 2
Training loss: 2.2532706260681152
Validation loss: 2.4289383913881037

Epoch: 6| Step: 3
Training loss: 2.5790822505950928
Validation loss: 2.4249739223910916

Epoch: 6| Step: 4
Training loss: 3.1347126960754395
Validation loss: 2.416037574891121

Epoch: 6| Step: 5
Training loss: 3.0717575550079346
Validation loss: 2.399950381248228

Epoch: 6| Step: 6
Training loss: 2.3155224323272705
Validation loss: 2.3930320534654843

Epoch: 6| Step: 7
Training loss: 2.7345058917999268
Validation loss: 2.385020814916139

Epoch: 6| Step: 8
Training loss: 2.96218204498291
Validation loss: 2.385513005718108

Epoch: 6| Step: 9
Training loss: 2.423508882522583
Validation loss: 2.385896687866539

Epoch: 6| Step: 10
Training loss: 2.542402744293213
Validation loss: 2.386213010357272

Epoch: 6| Step: 11
Training loss: 2.781679630279541
Validation loss: 2.386108911165627

Epoch: 6| Step: 12
Training loss: 2.2891228199005127
Validation loss: 2.3861223049061273

Epoch: 6| Step: 13
Training loss: 2.6044747829437256
Validation loss: 2.388065404789422

Epoch: 50| Step: 0
Training loss: 2.9169840812683105
Validation loss: 2.3894859078109905

Epoch: 6| Step: 1
Training loss: 2.8965935707092285
Validation loss: 2.382757002307523

Epoch: 6| Step: 2
Training loss: 2.7192249298095703
Validation loss: 2.3900852254641953

Epoch: 6| Step: 3
Training loss: 2.1924710273742676
Validation loss: 2.3894636451557116

Epoch: 6| Step: 4
Training loss: 2.606034278869629
Validation loss: 2.3923385476553314

Epoch: 6| Step: 5
Training loss: 2.9766440391540527
Validation loss: 2.384254506839219

Epoch: 6| Step: 6
Training loss: 2.6058685779571533
Validation loss: 2.385242285266999

Epoch: 6| Step: 7
Training loss: 2.7532975673675537
Validation loss: 2.385537265449442

Epoch: 6| Step: 8
Training loss: 3.887608289718628
Validation loss: 2.3802269171643

Epoch: 6| Step: 9
Training loss: 1.931924819946289
Validation loss: 2.383705392960579

Epoch: 6| Step: 10
Training loss: 2.588494062423706
Validation loss: 2.3907832125181794

Epoch: 6| Step: 11
Training loss: 2.3932888507843018
Validation loss: 2.393779457256358

Epoch: 6| Step: 12
Training loss: 2.5661609172821045
Validation loss: 2.403867998430806

Epoch: 6| Step: 13
Training loss: 1.5563552379608154
Validation loss: 2.39872770924722

Epoch: 51| Step: 0
Training loss: 2.33939266204834
Validation loss: 2.4002870616092475

Epoch: 6| Step: 1
Training loss: 2.6190943717956543
Validation loss: 2.39655569548248

Epoch: 6| Step: 2
Training loss: 2.0907609462738037
Validation loss: 2.391072521927536

Epoch: 6| Step: 3
Training loss: 2.971717357635498
Validation loss: 2.3843434728601927

Epoch: 6| Step: 4
Training loss: 1.6971971988677979
Validation loss: 2.3788027455729823

Epoch: 6| Step: 5
Training loss: 2.8439626693725586
Validation loss: 2.3776445465703167

Epoch: 6| Step: 6
Training loss: 2.81599760055542
Validation loss: 2.3765497464005665

Epoch: 6| Step: 7
Training loss: 2.8714759349823
Validation loss: 2.3736526273911998

Epoch: 6| Step: 8
Training loss: 3.1537749767303467
Validation loss: 2.3789184965113157

Epoch: 6| Step: 9
Training loss: 3.16436767578125
Validation loss: 2.383206816129787

Epoch: 6| Step: 10
Training loss: 2.896129608154297
Validation loss: 2.3837880062800583

Epoch: 6| Step: 11
Training loss: 2.4543144702911377
Validation loss: 2.3789966388415267

Epoch: 6| Step: 12
Training loss: 2.2961180210113525
Validation loss: 2.3744903969508346

Epoch: 6| Step: 13
Training loss: 2.6798622608184814
Validation loss: 2.371600353589622

Epoch: 52| Step: 0
Training loss: 2.748159885406494
Validation loss: 2.3755483268409647

Epoch: 6| Step: 1
Training loss: 2.4060139656066895
Validation loss: 2.381724082013612

Epoch: 6| Step: 2
Training loss: 2.9485130310058594
Validation loss: 2.3848552960221485

Epoch: 6| Step: 3
Training loss: 2.857074022293091
Validation loss: 2.378955735955187

Epoch: 6| Step: 4
Training loss: 2.914618492126465
Validation loss: 2.384912285753476

Epoch: 6| Step: 5
Training loss: 2.057741641998291
Validation loss: 2.3867623549635693

Epoch: 6| Step: 6
Training loss: 1.9820224046707153
Validation loss: 2.3954402195510043

Epoch: 6| Step: 7
Training loss: 2.371807336807251
Validation loss: 2.403060987431516

Epoch: 6| Step: 8
Training loss: 2.992091417312622
Validation loss: 2.4103632908995434

Epoch: 6| Step: 9
Training loss: 3.622108221054077
Validation loss: 2.440796277856314

Epoch: 6| Step: 10
Training loss: 2.8279409408569336
Validation loss: 2.454660910432057

Epoch: 6| Step: 11
Training loss: 2.5947296619415283
Validation loss: 2.4848066094101116

Epoch: 6| Step: 12
Training loss: 2.7218806743621826
Validation loss: 2.471192805997787

Epoch: 6| Step: 13
Training loss: 1.708603024482727
Validation loss: 2.4707482476388254

Epoch: 53| Step: 0
Training loss: 3.260683059692383
Validation loss: 2.450481301994734

Epoch: 6| Step: 1
Training loss: 2.480471611022949
Validation loss: 2.429923877921156

Epoch: 6| Step: 2
Training loss: 2.7814083099365234
Validation loss: 2.405920551669213

Epoch: 6| Step: 3
Training loss: 2.370356559753418
Validation loss: 2.388168268306281

Epoch: 6| Step: 4
Training loss: 2.478584051132202
Validation loss: 2.380529219104398

Epoch: 6| Step: 5
Training loss: 2.908855438232422
Validation loss: 2.367352061374213

Epoch: 6| Step: 6
Training loss: 2.5435853004455566
Validation loss: 2.3628490483889015

Epoch: 6| Step: 7
Training loss: 2.009079933166504
Validation loss: 2.361963297731133

Epoch: 6| Step: 8
Training loss: 2.02445912361145
Validation loss: 2.362999181593618

Epoch: 6| Step: 9
Training loss: 2.308272361755371
Validation loss: 2.3659709807365172

Epoch: 6| Step: 10
Training loss: 2.9521260261535645
Validation loss: 2.3684921572285313

Epoch: 6| Step: 11
Training loss: 2.5346951484680176
Validation loss: 2.368684543076382

Epoch: 6| Step: 12
Training loss: 3.741508960723877
Validation loss: 2.3678556847315964

Epoch: 6| Step: 13
Training loss: 2.241630792617798
Validation loss: 2.361841586328322

Epoch: 54| Step: 0
Training loss: 2.5383052825927734
Validation loss: 2.3617730089413222

Epoch: 6| Step: 1
Training loss: 2.2252445220947266
Validation loss: 2.360292932038666

Epoch: 6| Step: 2
Training loss: 2.9638171195983887
Validation loss: 2.3647911804978565

Epoch: 6| Step: 3
Training loss: 3.014726161956787
Validation loss: 2.3710140592308453

Epoch: 6| Step: 4
Training loss: 2.087897539138794
Validation loss: 2.3771810147070114

Epoch: 6| Step: 5
Training loss: 2.6385273933410645
Validation loss: 2.395045808566514

Epoch: 6| Step: 6
Training loss: 3.0005624294281006
Validation loss: 2.4008508215668383

Epoch: 6| Step: 7
Training loss: 2.822599172592163
Validation loss: 2.3965962317682084

Epoch: 6| Step: 8
Training loss: 1.904205083847046
Validation loss: 2.391537020283361

Epoch: 6| Step: 9
Training loss: 2.4021005630493164
Validation loss: 2.3748280540589364

Epoch: 6| Step: 10
Training loss: 3.0245141983032227
Validation loss: 2.373285957562026

Epoch: 6| Step: 11
Training loss: 2.8410937786102295
Validation loss: 2.3656839837310133

Epoch: 6| Step: 12
Training loss: 2.827749729156494
Validation loss: 2.368213700991805

Epoch: 6| Step: 13
Training loss: 2.4997406005859375
Validation loss: 2.3600293205630396

Epoch: 55| Step: 0
Training loss: 2.1915993690490723
Validation loss: 2.3533700384119505

Epoch: 6| Step: 1
Training loss: 2.9027609825134277
Validation loss: 2.353043184485487

Epoch: 6| Step: 2
Training loss: 2.562812328338623
Validation loss: 2.349213461722097

Epoch: 6| Step: 3
Training loss: 2.41838002204895
Validation loss: 2.351453793946133

Epoch: 6| Step: 4
Training loss: 2.750725746154785
Validation loss: 2.3583685839047996

Epoch: 6| Step: 5
Training loss: 3.072174072265625
Validation loss: 2.360872468640727

Epoch: 6| Step: 6
Training loss: 1.9418025016784668
Validation loss: 2.3629053587554605

Epoch: 6| Step: 7
Training loss: 2.882005453109741
Validation loss: 2.360817955386254

Epoch: 6| Step: 8
Training loss: 2.733095645904541
Validation loss: 2.355841067529494

Epoch: 6| Step: 9
Training loss: 2.8118014335632324
Validation loss: 2.3568944456756755

Epoch: 6| Step: 10
Training loss: 3.114643096923828
Validation loss: 2.352553536815028

Epoch: 6| Step: 11
Training loss: 2.3367857933044434
Validation loss: 2.3533251618826263

Epoch: 6| Step: 12
Training loss: 2.200552463531494
Validation loss: 2.352432374031313

Epoch: 6| Step: 13
Training loss: 2.9695253372192383
Validation loss: 2.3529744148254395

Epoch: 56| Step: 0
Training loss: 3.281224250793457
Validation loss: 2.3564210976323774

Epoch: 6| Step: 1
Training loss: 2.895171880722046
Validation loss: 2.360930768392419

Epoch: 6| Step: 2
Training loss: 2.5696396827697754
Validation loss: 2.3594546420599825

Epoch: 6| Step: 3
Training loss: 2.6096014976501465
Validation loss: 2.362045124012937

Epoch: 6| Step: 4
Training loss: 2.758233070373535
Validation loss: 2.3597070940079226

Epoch: 6| Step: 5
Training loss: 2.5029735565185547
Validation loss: 2.3894919759483746

Epoch: 6| Step: 6
Training loss: 1.8956899642944336
Validation loss: 2.384438568545926

Epoch: 6| Step: 7
Training loss: 2.530735969543457
Validation loss: 2.395040004484115

Epoch: 6| Step: 8
Training loss: 2.368330955505371
Validation loss: 2.4097199132365565

Epoch: 6| Step: 9
Training loss: 3.0435173511505127
Validation loss: 2.409257491429647

Epoch: 6| Step: 10
Training loss: 2.413377523422241
Validation loss: 2.3797933183690554

Epoch: 6| Step: 11
Training loss: 2.4970555305480957
Validation loss: 2.3553292956403507

Epoch: 6| Step: 12
Training loss: 2.8774771690368652
Validation loss: 2.339121792906074

Epoch: 6| Step: 13
Training loss: 2.170065402984619
Validation loss: 2.33999535088898

Epoch: 57| Step: 0
Training loss: 2.266139507293701
Validation loss: 2.346126994779033

Epoch: 6| Step: 1
Training loss: 2.1168088912963867
Validation loss: 2.3575456526971634

Epoch: 6| Step: 2
Training loss: 2.743732452392578
Validation loss: 2.3646559343543103

Epoch: 6| Step: 3
Training loss: 2.924833297729492
Validation loss: 2.393582785001365

Epoch: 6| Step: 4
Training loss: 2.805819272994995
Validation loss: 2.399890697130593

Epoch: 6| Step: 5
Training loss: 2.3441390991210938
Validation loss: 2.403491876458609

Epoch: 6| Step: 6
Training loss: 2.3761348724365234
Validation loss: 2.3903281611780964

Epoch: 6| Step: 7
Training loss: 3.2734036445617676
Validation loss: 2.381193748084448

Epoch: 6| Step: 8
Training loss: 3.21860933303833
Validation loss: 2.371074349649491

Epoch: 6| Step: 9
Training loss: 2.2990753650665283
Validation loss: 2.354730003623552

Epoch: 6| Step: 10
Training loss: 2.5118422508239746
Validation loss: 2.3413819061812533

Epoch: 6| Step: 11
Training loss: 2.253915309906006
Validation loss: 2.333754695871825

Epoch: 6| Step: 12
Training loss: 3.2066235542297363
Validation loss: 2.331085535787767

Epoch: 6| Step: 13
Training loss: 2.6838674545288086
Validation loss: 2.3274819786830614

Epoch: 58| Step: 0
Training loss: 2.52125883102417
Validation loss: 2.3442609105058896

Epoch: 6| Step: 1
Training loss: 2.7347521781921387
Validation loss: 2.34591664806489

Epoch: 6| Step: 2
Training loss: 2.4291090965270996
Validation loss: 2.3510699041428103

Epoch: 6| Step: 3
Training loss: 2.2093706130981445
Validation loss: 2.3567998870726554

Epoch: 6| Step: 4
Training loss: 3.0852091312408447
Validation loss: 2.349481044277068

Epoch: 6| Step: 5
Training loss: 1.9272500276565552
Validation loss: 2.3493310020815943

Epoch: 6| Step: 6
Training loss: 2.712944507598877
Validation loss: 2.343117203763736

Epoch: 6| Step: 7
Training loss: 2.7977871894836426
Validation loss: 2.337847596855574

Epoch: 6| Step: 8
Training loss: 2.258650779724121
Validation loss: 2.337852693373157

Epoch: 6| Step: 9
Training loss: 2.4508752822875977
Validation loss: 2.339717585553405

Epoch: 6| Step: 10
Training loss: 2.272287607192993
Validation loss: 2.3405043848099245

Epoch: 6| Step: 11
Training loss: 2.6417441368103027
Validation loss: 2.34019483289411

Epoch: 6| Step: 12
Training loss: 3.0370891094207764
Validation loss: 2.3484869541660434

Epoch: 6| Step: 13
Training loss: 4.00178337097168
Validation loss: 2.3496746683633454

Epoch: 59| Step: 0
Training loss: 2.6380152702331543
Validation loss: 2.349259896944928

Epoch: 6| Step: 1
Training loss: 2.5720043182373047
Validation loss: 2.3453874229103007

Epoch: 6| Step: 2
Training loss: 2.3527355194091797
Validation loss: 2.3516544167713453

Epoch: 6| Step: 3
Training loss: 2.7133021354675293
Validation loss: 2.3451359195093953

Epoch: 6| Step: 4
Training loss: 3.517183780670166
Validation loss: 2.3475342104511876

Epoch: 6| Step: 5
Training loss: 2.224104166030884
Validation loss: 2.347222989605319

Epoch: 6| Step: 6
Training loss: 2.3363447189331055
Validation loss: 2.336961007887317

Epoch: 6| Step: 7
Training loss: 2.7163376808166504
Validation loss: 2.322686585046912

Epoch: 6| Step: 8
Training loss: 2.519526243209839
Validation loss: 2.320776790700933

Epoch: 6| Step: 9
Training loss: 2.430973768234253
Validation loss: 2.3209893498369443

Epoch: 6| Step: 10
Training loss: 2.8220176696777344
Validation loss: 2.313461372929235

Epoch: 6| Step: 11
Training loss: 2.7086055278778076
Validation loss: 2.3135888320143505

Epoch: 6| Step: 12
Training loss: 2.8458633422851562
Validation loss: 2.3164931984357935

Epoch: 6| Step: 13
Training loss: 1.7149747610092163
Validation loss: 2.315870313234227

Epoch: 60| Step: 0
Training loss: 2.726719617843628
Validation loss: 2.316780536405502

Epoch: 6| Step: 1
Training loss: 2.783792018890381
Validation loss: 2.3192732385409776

Epoch: 6| Step: 2
Training loss: 2.009307384490967
Validation loss: 2.320928758190524

Epoch: 6| Step: 3
Training loss: 3.231985092163086
Validation loss: 2.3210916544801448

Epoch: 6| Step: 4
Training loss: 2.98982834815979
Validation loss: 2.3237420358965473

Epoch: 6| Step: 5
Training loss: 1.4592911005020142
Validation loss: 2.3342217604319253

Epoch: 6| Step: 6
Training loss: 2.4691739082336426
Validation loss: 2.3272961288370113

Epoch: 6| Step: 7
Training loss: 3.3051161766052246
Validation loss: 2.3294211895235124

Epoch: 6| Step: 8
Training loss: 2.7283682823181152
Validation loss: 2.3248635107471096

Epoch: 6| Step: 9
Training loss: 2.277007579803467
Validation loss: 2.3182915128687376

Epoch: 6| Step: 10
Training loss: 2.9289040565490723
Validation loss: 2.3191860619411675

Epoch: 6| Step: 11
Training loss: 1.855388879776001
Validation loss: 2.317829183352891

Epoch: 6| Step: 12
Training loss: 2.5629405975341797
Validation loss: 2.3171807489087506

Epoch: 6| Step: 13
Training loss: 3.2140188217163086
Validation loss: 2.3177153615541357

Epoch: 61| Step: 0
Training loss: 2.7509098052978516
Validation loss: 2.3356500389755412

Epoch: 6| Step: 1
Training loss: 3.391542911529541
Validation loss: 2.3424698075940533

Epoch: 6| Step: 2
Training loss: 2.3006834983825684
Validation loss: 2.3418793575738066

Epoch: 6| Step: 3
Training loss: 1.2770814895629883
Validation loss: 2.3356943745766916

Epoch: 6| Step: 4
Training loss: 2.068875789642334
Validation loss: 2.334783128512803

Epoch: 6| Step: 5
Training loss: 2.1902520656585693
Validation loss: 2.333981280685753

Epoch: 6| Step: 6
Training loss: 2.1640729904174805
Validation loss: 2.3258065587730816

Epoch: 6| Step: 7
Training loss: 1.9034793376922607
Validation loss: 2.3305717360588813

Epoch: 6| Step: 8
Training loss: 2.873009443283081
Validation loss: 2.3259117295665126

Epoch: 6| Step: 9
Training loss: 3.339233636856079
Validation loss: 2.3141686390804987

Epoch: 6| Step: 10
Training loss: 3.0808987617492676
Validation loss: 2.312583395229873

Epoch: 6| Step: 11
Training loss: 3.705995559692383
Validation loss: 2.3091750619232014

Epoch: 6| Step: 12
Training loss: 2.3549251556396484
Validation loss: 2.304421883757396

Epoch: 6| Step: 13
Training loss: 2.867093801498413
Validation loss: 2.3106219217341435

Epoch: 62| Step: 0
Training loss: 1.8207533359527588
Validation loss: 2.3033113710341917

Epoch: 6| Step: 1
Training loss: 2.1306192874908447
Validation loss: 2.308272256646105

Epoch: 6| Step: 2
Training loss: 2.2652878761291504
Validation loss: 2.3008845108811573

Epoch: 6| Step: 3
Training loss: 3.371960163116455
Validation loss: 2.302924725317186

Epoch: 6| Step: 4
Training loss: 3.1590304374694824
Validation loss: 2.3021935775715816

Epoch: 6| Step: 5
Training loss: 2.266557216644287
Validation loss: 2.3001010110301356

Epoch: 6| Step: 6
Training loss: 3.255324363708496
Validation loss: 2.2989200392077045

Epoch: 6| Step: 7
Training loss: 2.2571916580200195
Validation loss: 2.3029753110742055

Epoch: 6| Step: 8
Training loss: 2.7401084899902344
Validation loss: 2.300643415861232

Epoch: 6| Step: 9
Training loss: 2.5011162757873535
Validation loss: 2.306297299682453

Epoch: 6| Step: 10
Training loss: 1.773755431175232
Validation loss: 2.3091243543932514

Epoch: 6| Step: 11
Training loss: 2.8871943950653076
Validation loss: 2.316449479390216

Epoch: 6| Step: 12
Training loss: 2.258759021759033
Validation loss: 2.31716328026146

Epoch: 6| Step: 13
Training loss: 4.0827226638793945
Validation loss: 2.3218442188796176

Epoch: 63| Step: 0
Training loss: 1.8170758485794067
Validation loss: 2.315463214792231

Epoch: 6| Step: 1
Training loss: 2.8967652320861816
Validation loss: 2.31148563854156

Epoch: 6| Step: 2
Training loss: 2.6824891567230225
Validation loss: 2.318232547852301

Epoch: 6| Step: 3
Training loss: 2.699620246887207
Validation loss: 2.315712292989095

Epoch: 6| Step: 4
Training loss: 2.9021353721618652
Validation loss: 2.316749257426108

Epoch: 6| Step: 5
Training loss: 2.5658535957336426
Validation loss: 2.3125636116150887

Epoch: 6| Step: 6
Training loss: 2.432255268096924
Validation loss: 2.3056014558320403

Epoch: 6| Step: 7
Training loss: 2.899574041366577
Validation loss: 2.300939613772977

Epoch: 6| Step: 8
Training loss: 2.480916976928711
Validation loss: 2.2951205609947123

Epoch: 6| Step: 9
Training loss: 2.715149164199829
Validation loss: 2.2969165361055763

Epoch: 6| Step: 10
Training loss: 2.840841293334961
Validation loss: 2.2984345959078882

Epoch: 6| Step: 11
Training loss: 2.3175926208496094
Validation loss: 2.294600696973903

Epoch: 6| Step: 12
Training loss: 2.470689535140991
Validation loss: 2.292117782818374

Epoch: 6| Step: 13
Training loss: 2.1379542350769043
Validation loss: 2.299747411922742

Epoch: 64| Step: 0
Training loss: 2.734863758087158
Validation loss: 2.3066325841411466

Epoch: 6| Step: 1
Training loss: 2.319462776184082
Validation loss: 2.313063324138682

Epoch: 6| Step: 2
Training loss: 2.438997268676758
Validation loss: 2.306009728421447

Epoch: 6| Step: 3
Training loss: 2.6609365940093994
Validation loss: 2.3104809894356677

Epoch: 6| Step: 4
Training loss: 2.1625943183898926
Validation loss: 2.305621941884359

Epoch: 6| Step: 5
Training loss: 2.7704014778137207
Validation loss: 2.307254086258591

Epoch: 6| Step: 6
Training loss: 3.1899828910827637
Validation loss: 2.3278492881405737

Epoch: 6| Step: 7
Training loss: 2.307157516479492
Validation loss: 2.3236740584014566

Epoch: 6| Step: 8
Training loss: 2.695387840270996
Validation loss: 2.3131694229700233

Epoch: 6| Step: 9
Training loss: 3.1701412200927734
Validation loss: 2.294776047429731

Epoch: 6| Step: 10
Training loss: 2.389970541000366
Validation loss: 2.2908449993338635

Epoch: 6| Step: 11
Training loss: 2.158487319946289
Validation loss: 2.2926346922433503

Epoch: 6| Step: 12
Training loss: 2.455373525619507
Validation loss: 2.291008062260125

Epoch: 6| Step: 13
Training loss: 2.6504430770874023
Validation loss: 2.2961794791683072

Epoch: 65| Step: 0
Training loss: 3.4931046962738037
Validation loss: 2.30031539804192

Epoch: 6| Step: 1
Training loss: 2.4143593311309814
Validation loss: 2.295171609488867

Epoch: 6| Step: 2
Training loss: 1.7901790142059326
Validation loss: 2.2968041794274443

Epoch: 6| Step: 3
Training loss: 2.5759401321411133
Validation loss: 2.2988555085274482

Epoch: 6| Step: 4
Training loss: 2.146106719970703
Validation loss: 2.3002230377607447

Epoch: 6| Step: 5
Training loss: 2.5007309913635254
Validation loss: 2.3040967897702287

Epoch: 6| Step: 6
Training loss: 3.0320963859558105
Validation loss: 2.299342075983683

Epoch: 6| Step: 7
Training loss: 2.181394100189209
Validation loss: 2.301475900475697

Epoch: 6| Step: 8
Training loss: 2.36179256439209
Validation loss: 2.3127632474386566

Epoch: 6| Step: 9
Training loss: 2.3807687759399414
Validation loss: 2.3233052376777894

Epoch: 6| Step: 10
Training loss: 3.003575325012207
Validation loss: 2.3173268943704586

Epoch: 6| Step: 11
Training loss: 2.060317039489746
Validation loss: 2.3124300433743383

Epoch: 6| Step: 12
Training loss: 3.092041015625
Validation loss: 2.3122911581429104

Epoch: 6| Step: 13
Training loss: 3.1082818508148193
Validation loss: 2.318155604024087

Epoch: 66| Step: 0
Training loss: 3.3378024101257324
Validation loss: 2.3006295311835503

Epoch: 6| Step: 1
Training loss: 2.6924314498901367
Validation loss: 2.288191803040043

Epoch: 6| Step: 2
Training loss: 2.1957406997680664
Validation loss: 2.2793876560785438

Epoch: 6| Step: 3
Training loss: 2.2171459197998047
Validation loss: 2.276137998027186

Epoch: 6| Step: 4
Training loss: 2.5355238914489746
Validation loss: 2.2681412799384004

Epoch: 6| Step: 5
Training loss: 2.9638757705688477
Validation loss: 2.274384125586479

Epoch: 6| Step: 6
Training loss: 2.481947422027588
Validation loss: 2.277607379421111

Epoch: 6| Step: 7
Training loss: 2.219804286956787
Validation loss: 2.275965318884901

Epoch: 6| Step: 8
Training loss: 3.0329172611236572
Validation loss: 2.284355683993268

Epoch: 6| Step: 9
Training loss: 1.590635061264038
Validation loss: 2.285786969687349

Epoch: 6| Step: 10
Training loss: 2.949441432952881
Validation loss: 2.305133406833936

Epoch: 6| Step: 11
Training loss: 2.3715591430664062
Validation loss: 2.3290413887270036

Epoch: 6| Step: 12
Training loss: 2.640611171722412
Validation loss: 2.380114516904277

Epoch: 6| Step: 13
Training loss: 2.8079044818878174
Validation loss: 2.3676086856472875

Epoch: 67| Step: 0
Training loss: 3.092430591583252
Validation loss: 2.351251022790068

Epoch: 6| Step: 1
Training loss: 2.845351219177246
Validation loss: 2.302117081098659

Epoch: 6| Step: 2
Training loss: 2.968597412109375
Validation loss: 2.2853339718234156

Epoch: 6| Step: 3
Training loss: 1.8495984077453613
Validation loss: 2.273180023316414

Epoch: 6| Step: 4
Training loss: 2.5873849391937256
Validation loss: 2.2682624837403655

Epoch: 6| Step: 5
Training loss: 2.3508758544921875
Validation loss: 2.268515209997854

Epoch: 6| Step: 6
Training loss: 2.0055899620056152
Validation loss: 2.2750070120698664

Epoch: 6| Step: 7
Training loss: 2.3767201900482178
Validation loss: 2.269696069020097

Epoch: 6| Step: 8
Training loss: 3.5880563259124756
Validation loss: 2.2654251308851343

Epoch: 6| Step: 9
Training loss: 2.3248682022094727
Validation loss: 2.2693004044153358

Epoch: 6| Step: 10
Training loss: 2.461392402648926
Validation loss: 2.2825948051227036

Epoch: 6| Step: 11
Training loss: 2.048462390899658
Validation loss: 2.291824419011352

Epoch: 6| Step: 12
Training loss: 3.2572851181030273
Validation loss: 2.2803154863337034

Epoch: 6| Step: 13
Training loss: 2.1090219020843506
Validation loss: 2.278072526378016

Epoch: 68| Step: 0
Training loss: 2.794870376586914
Validation loss: 2.282969727311083

Epoch: 6| Step: 1
Training loss: 1.500265121459961
Validation loss: 2.2838850021362305

Epoch: 6| Step: 2
Training loss: 3.059959888458252
Validation loss: 2.30602022909349

Epoch: 6| Step: 3
Training loss: 2.5135059356689453
Validation loss: 2.3754448736867597

Epoch: 6| Step: 4
Training loss: 2.8592262268066406
Validation loss: 2.4010878685981996

Epoch: 6| Step: 5
Training loss: 2.4878978729248047
Validation loss: 2.3599929296842186

Epoch: 6| Step: 6
Training loss: 3.0356760025024414
Validation loss: 2.3293708524396344

Epoch: 6| Step: 7
Training loss: 2.8857359886169434
Validation loss: 2.2855256372882473

Epoch: 6| Step: 8
Training loss: 2.089317798614502
Validation loss: 2.2638848468821537

Epoch: 6| Step: 9
Training loss: 3.388587713241577
Validation loss: 2.2612392120463873

Epoch: 6| Step: 10
Training loss: 2.18855357170105
Validation loss: 2.27490266676872

Epoch: 6| Step: 11
Training loss: 2.3108699321746826
Validation loss: 2.2703357332496235

Epoch: 6| Step: 12
Training loss: 2.176442861557007
Validation loss: 2.269054583323899

Epoch: 6| Step: 13
Training loss: 2.821582317352295
Validation loss: 2.277144314140402

Epoch: 69| Step: 0
Training loss: 1.8140177726745605
Validation loss: 2.270535135781893

Epoch: 6| Step: 1
Training loss: 2.2671115398406982
Validation loss: 2.267750076068345

Epoch: 6| Step: 2
Training loss: 2.0890820026397705
Validation loss: 2.2649639780803392

Epoch: 6| Step: 3
Training loss: 2.6469154357910156
Validation loss: 2.268334727133474

Epoch: 6| Step: 4
Training loss: 3.1288700103759766
Validation loss: 2.2701923155015513

Epoch: 6| Step: 5
Training loss: 2.878235340118408
Validation loss: 2.265069414210576

Epoch: 6| Step: 6
Training loss: 2.096050262451172
Validation loss: 2.256614440230913

Epoch: 6| Step: 7
Training loss: 2.065115451812744
Validation loss: 2.2563495418076873

Epoch: 6| Step: 8
Training loss: 3.3431828022003174
Validation loss: 2.250755471567954

Epoch: 6| Step: 9
Training loss: 2.55100154876709
Validation loss: 2.264327838856687

Epoch: 6| Step: 10
Training loss: 2.680544137954712
Validation loss: 2.273094008045812

Epoch: 6| Step: 11
Training loss: 3.228424549102783
Validation loss: 2.268214892315608

Epoch: 6| Step: 12
Training loss: 2.5530362129211426
Validation loss: 2.2693259152032996

Epoch: 6| Step: 13
Training loss: 2.5853190422058105
Validation loss: 2.3102469521184124

Epoch: 70| Step: 0
Training loss: 2.132741689682007
Validation loss: 2.3524325868134857

Epoch: 6| Step: 1
Training loss: 2.7887444496154785
Validation loss: 2.4919294003517396

Epoch: 6| Step: 2
Training loss: 2.0780105590820312
Validation loss: 2.6487089216068225

Epoch: 6| Step: 3
Training loss: 3.2615580558776855
Validation loss: 2.6803109709934523

Epoch: 6| Step: 4
Training loss: 1.366154432296753
Validation loss: 2.593487047380017

Epoch: 6| Step: 5
Training loss: 3.382780075073242
Validation loss: 2.4667260749365694

Epoch: 6| Step: 6
Training loss: 3.147430181503296
Validation loss: 2.3734535299321657

Epoch: 6| Step: 7
Training loss: 2.3948304653167725
Validation loss: 2.283824254107732

Epoch: 6| Step: 8
Training loss: 2.3684139251708984
Validation loss: 2.251635577089043

Epoch: 6| Step: 9
Training loss: 2.537477970123291
Validation loss: 2.266523758570353

Epoch: 6| Step: 10
Training loss: 3.2988452911376953
Validation loss: 2.277395702177478

Epoch: 6| Step: 11
Training loss: 3.21818208694458
Validation loss: 2.293140706195626

Epoch: 6| Step: 12
Training loss: 2.5918495655059814
Validation loss: 2.289572613213652

Epoch: 6| Step: 13
Training loss: 2.3546698093414307
Validation loss: 2.2806485493977866

Epoch: 71| Step: 0
Training loss: 2.8514227867126465
Validation loss: 2.2761312300159084

Epoch: 6| Step: 1
Training loss: 2.540358304977417
Validation loss: 2.2693389538795716

Epoch: 6| Step: 2
Training loss: 2.4394400119781494
Validation loss: 2.2629984732597106

Epoch: 6| Step: 3
Training loss: 3.016134738922119
Validation loss: 2.257699094792848

Epoch: 6| Step: 4
Training loss: 2.6892333030700684
Validation loss: 2.255181581743302

Epoch: 6| Step: 5
Training loss: 2.546070098876953
Validation loss: 2.2581366697947183

Epoch: 6| Step: 6
Training loss: 2.9976184368133545
Validation loss: 2.2649109055919032

Epoch: 6| Step: 7
Training loss: 1.8306102752685547
Validation loss: 2.2653822129772556

Epoch: 6| Step: 8
Training loss: 2.259734869003296
Validation loss: 2.2652989305475706

Epoch: 6| Step: 9
Training loss: 2.422332286834717
Validation loss: 2.267540357446158

Epoch: 6| Step: 10
Training loss: 2.843353748321533
Validation loss: 2.2925333951109197

Epoch: 6| Step: 11
Training loss: 2.7035951614379883
Validation loss: 2.3507983248720885

Epoch: 6| Step: 12
Training loss: 1.793396234512329
Validation loss: 2.3577047419804398

Epoch: 6| Step: 13
Training loss: 3.1855719089508057
Validation loss: 2.3438035570165163

Epoch: 72| Step: 0
Training loss: 2.7523436546325684
Validation loss: 2.30709905521844

Epoch: 6| Step: 1
Training loss: 2.8301639556884766
Validation loss: 2.2861421646610385

Epoch: 6| Step: 2
Training loss: 3.5162858963012695
Validation loss: 2.2554964045042634

Epoch: 6| Step: 3
Training loss: 2.500147819519043
Validation loss: 2.248536661107053

Epoch: 6| Step: 4
Training loss: 2.5027358531951904
Validation loss: 2.243263808629846

Epoch: 6| Step: 5
Training loss: 2.238576889038086
Validation loss: 2.2452629766156598

Epoch: 6| Step: 6
Training loss: 3.1071527004241943
Validation loss: 2.238655128786641

Epoch: 6| Step: 7
Training loss: 1.901121735572815
Validation loss: 2.233295855983611

Epoch: 6| Step: 8
Training loss: 2.4221057891845703
Validation loss: 2.231820297497575

Epoch: 6| Step: 9
Training loss: 2.6091582775115967
Validation loss: 2.2379614486489245

Epoch: 6| Step: 10
Training loss: 1.973103642463684
Validation loss: 2.2330092589060464

Epoch: 6| Step: 11
Training loss: 2.0415871143341064
Validation loss: 2.2363231694826515

Epoch: 6| Step: 12
Training loss: 2.460988998413086
Validation loss: 2.2396165094067975

Epoch: 6| Step: 13
Training loss: 2.98801326751709
Validation loss: 2.2378095862685994

Epoch: 73| Step: 0
Training loss: 2.2568247318267822
Validation loss: 2.237355000229292

Epoch: 6| Step: 1
Training loss: 3.038046360015869
Validation loss: 2.2362499390878985

Epoch: 6| Step: 2
Training loss: 3.117180347442627
Validation loss: 2.2377182552891393

Epoch: 6| Step: 3
Training loss: 1.909062147140503
Validation loss: 2.2335898671098935

Epoch: 6| Step: 4
Training loss: 2.5949511528015137
Validation loss: 2.2347932143877913

Epoch: 6| Step: 5
Training loss: 2.3913445472717285
Validation loss: 2.244201875502063

Epoch: 6| Step: 6
Training loss: 2.196506977081299
Validation loss: 2.267540867610644

Epoch: 6| Step: 7
Training loss: 2.9626331329345703
Validation loss: 2.305412507826282

Epoch: 6| Step: 8
Training loss: 2.509463310241699
Validation loss: 2.3316906370142454

Epoch: 6| Step: 9
Training loss: 2.8610124588012695
Validation loss: 2.358307610275925

Epoch: 6| Step: 10
Training loss: 2.9664111137390137
Validation loss: 2.3786227677458074

Epoch: 6| Step: 11
Training loss: 2.3383965492248535
Validation loss: 2.3597767481239895

Epoch: 6| Step: 12
Training loss: 2.316716432571411
Validation loss: 2.3158541494800198

Epoch: 6| Step: 13
Training loss: 2.412313222885132
Validation loss: 2.273185904308032

Epoch: 74| Step: 0
Training loss: 2.735574960708618
Validation loss: 2.2420732910915087

Epoch: 6| Step: 1
Training loss: 2.90669846534729
Validation loss: 2.220648293854088

Epoch: 6| Step: 2
Training loss: 2.739532947540283
Validation loss: 2.221926273838166

Epoch: 6| Step: 3
Training loss: 3.0222008228302
Validation loss: 2.231146809875324

Epoch: 6| Step: 4
Training loss: 3.184694290161133
Validation loss: 2.2349549057663127

Epoch: 6| Step: 5
Training loss: 2.61669921875
Validation loss: 2.245930092309111

Epoch: 6| Step: 6
Training loss: 2.2847273349761963
Validation loss: 2.2485809274899062

Epoch: 6| Step: 7
Training loss: 2.3353514671325684
Validation loss: 2.245284270214778

Epoch: 6| Step: 8
Training loss: 2.156986951828003
Validation loss: 2.2360764831625004

Epoch: 6| Step: 9
Training loss: 1.6176300048828125
Validation loss: 2.2305845137565368

Epoch: 6| Step: 10
Training loss: 2.9945125579833984
Validation loss: 2.2171718638430358

Epoch: 6| Step: 11
Training loss: 2.1118907928466797
Validation loss: 2.2128459048527542

Epoch: 6| Step: 12
Training loss: 2.3999109268188477
Validation loss: 2.2159141007290093

Epoch: 6| Step: 13
Training loss: 3.032945156097412
Validation loss: 2.223995057485437

Epoch: 75| Step: 0
Training loss: 1.676585078239441
Validation loss: 2.2304633522546418

Epoch: 6| Step: 1
Training loss: 2.0896754264831543
Validation loss: 2.2409768245553456

Epoch: 6| Step: 2
Training loss: 2.914283275604248
Validation loss: 2.2698267903379215

Epoch: 6| Step: 3
Training loss: 2.4878039360046387
Validation loss: 2.264250547655167

Epoch: 6| Step: 4
Training loss: 3.149685859680176
Validation loss: 2.251609416418178

Epoch: 6| Step: 5
Training loss: 2.4765100479125977
Validation loss: 2.247776359640142

Epoch: 6| Step: 6
Training loss: 2.977757453918457
Validation loss: 2.2578552666530816

Epoch: 6| Step: 7
Training loss: 2.225980758666992
Validation loss: 2.256076353852467

Epoch: 6| Step: 8
Training loss: 3.214491605758667
Validation loss: 2.2644357168546287

Epoch: 6| Step: 9
Training loss: 1.71767258644104
Validation loss: 2.2619812078373407

Epoch: 6| Step: 10
Training loss: 2.3293440341949463
Validation loss: 2.281608648197625

Epoch: 6| Step: 11
Training loss: 2.5713117122650146
Validation loss: 2.3070196182497087

Epoch: 6| Step: 12
Training loss: 3.0736093521118164
Validation loss: 2.3174367104807208

Epoch: 6| Step: 13
Training loss: 2.7873313426971436
Validation loss: 2.3138637414542575

Epoch: 76| Step: 0
Training loss: 3.057924509048462
Validation loss: 2.3401168854005876

Epoch: 6| Step: 1
Training loss: 2.0806760787963867
Validation loss: 2.360853241335961

Epoch: 6| Step: 2
Training loss: 2.353327989578247
Validation loss: 2.3838454215757308

Epoch: 6| Step: 3
Training loss: 2.943451404571533
Validation loss: 2.3379804780406337

Epoch: 6| Step: 4
Training loss: 2.399958610534668
Validation loss: 2.311566268244097

Epoch: 6| Step: 5
Training loss: 2.8960373401641846
Validation loss: 2.3051160176595054

Epoch: 6| Step: 6
Training loss: 3.4993677139282227
Validation loss: 2.26798221629153

Epoch: 6| Step: 7
Training loss: 2.3523082733154297
Validation loss: 2.231617860896613

Epoch: 6| Step: 8
Training loss: 2.2148232460021973
Validation loss: 2.2255443757580173

Epoch: 6| Step: 9
Training loss: 2.276386260986328
Validation loss: 2.215292963930356

Epoch: 6| Step: 10
Training loss: 1.877997875213623
Validation loss: 2.209830682764771

Epoch: 6| Step: 11
Training loss: 3.341310977935791
Validation loss: 2.2069862478522846

Epoch: 6| Step: 12
Training loss: 2.2298383712768555
Validation loss: 2.2075476979696624

Epoch: 6| Step: 13
Training loss: 1.9358582496643066
Validation loss: 2.2149645308012604

Epoch: 77| Step: 0
Training loss: 2.7419376373291016
Validation loss: 2.2137732108434043

Epoch: 6| Step: 1
Training loss: 2.7417972087860107
Validation loss: 2.2164228321403585

Epoch: 6| Step: 2
Training loss: 2.8922290802001953
Validation loss: 2.2159947220997145

Epoch: 6| Step: 3
Training loss: 2.050352096557617
Validation loss: 2.2251660670003583

Epoch: 6| Step: 4
Training loss: 2.948915481567383
Validation loss: 2.2291132147594164

Epoch: 6| Step: 5
Training loss: 1.626846194267273
Validation loss: 2.22693193856106

Epoch: 6| Step: 6
Training loss: 2.655658721923828
Validation loss: 2.2237137620167067

Epoch: 6| Step: 7
Training loss: 2.668891429901123
Validation loss: 2.2181443347725818

Epoch: 6| Step: 8
Training loss: 2.2505269050598145
Validation loss: 2.212496628043472

Epoch: 6| Step: 9
Training loss: 2.948892831802368
Validation loss: 2.2134920012566353

Epoch: 6| Step: 10
Training loss: 2.8038177490234375
Validation loss: 2.215404059297295

Epoch: 6| Step: 11
Training loss: 2.176302909851074
Validation loss: 2.211330344600062

Epoch: 6| Step: 12
Training loss: 2.070554733276367
Validation loss: 2.209782164583924

Epoch: 6| Step: 13
Training loss: 2.9588840007781982
Validation loss: 2.22150945150724

Epoch: 78| Step: 0
Training loss: 2.237546920776367
Validation loss: 2.2494291515760523

Epoch: 6| Step: 1
Training loss: 2.732475757598877
Validation loss: 2.256932843116022

Epoch: 6| Step: 2
Training loss: 2.3336544036865234
Validation loss: 2.248164733250936

Epoch: 6| Step: 3
Training loss: 2.7448320388793945
Validation loss: 2.2504163275482836

Epoch: 6| Step: 4
Training loss: 2.6967921257019043
Validation loss: 2.234841098067581

Epoch: 6| Step: 5
Training loss: 1.6714272499084473
Validation loss: 2.210781207648657

Epoch: 6| Step: 6
Training loss: 2.4499940872192383
Validation loss: 2.201720089040777

Epoch: 6| Step: 7
Training loss: 2.570744037628174
Validation loss: 2.1963548070640972

Epoch: 6| Step: 8
Training loss: 3.362823009490967
Validation loss: 2.194859117589971

Epoch: 6| Step: 9
Training loss: 2.86841082572937
Validation loss: 2.1922262971119215

Epoch: 6| Step: 10
Training loss: 2.3610010147094727
Validation loss: 2.1915157674461283

Epoch: 6| Step: 11
Training loss: 2.6288723945617676
Validation loss: 2.194643435939666

Epoch: 6| Step: 12
Training loss: 2.1447386741638184
Validation loss: 2.1939176641484743

Epoch: 6| Step: 13
Training loss: 2.1687657833099365
Validation loss: 2.187128443871775

Epoch: 79| Step: 0
Training loss: 2.0912203788757324
Validation loss: 2.189808699392503

Epoch: 6| Step: 1
Training loss: 2.912651538848877
Validation loss: 2.1907214169861167

Epoch: 6| Step: 2
Training loss: 2.8891029357910156
Validation loss: 2.191590819307553

Epoch: 6| Step: 3
Training loss: 2.379981756210327
Validation loss: 2.1910479799393685

Epoch: 6| Step: 4
Training loss: 2.7186622619628906
Validation loss: 2.188888712595868

Epoch: 6| Step: 5
Training loss: 2.4668960571289062
Validation loss: 2.193039424957768

Epoch: 6| Step: 6
Training loss: 2.065559148788452
Validation loss: 2.1875157228080173

Epoch: 6| Step: 7
Training loss: 1.8540146350860596
Validation loss: 2.192231560266146

Epoch: 6| Step: 8
Training loss: 2.3487627506256104
Validation loss: 2.201225301270844

Epoch: 6| Step: 9
Training loss: 2.642706871032715
Validation loss: 2.2034554353324314

Epoch: 6| Step: 10
Training loss: 2.8143503665924072
Validation loss: 2.2074755648131013

Epoch: 6| Step: 11
Training loss: 3.1865270137786865
Validation loss: 2.2247248567560667

Epoch: 6| Step: 12
Training loss: 2.4179701805114746
Validation loss: 2.214271257000585

Epoch: 6| Step: 13
Training loss: 2.183641195297241
Validation loss: 2.2047092222398326

Epoch: 80| Step: 0
Training loss: 2.1601004600524902
Validation loss: 2.213358526588768

Epoch: 6| Step: 1
Training loss: 2.246035575866699
Validation loss: 2.225683226380297

Epoch: 6| Step: 2
Training loss: 2.8823084831237793
Validation loss: 2.252569736972932

Epoch: 6| Step: 3
Training loss: 2.4497780799865723
Validation loss: 2.27639453898194

Epoch: 6| Step: 4
Training loss: 1.0208182334899902
Validation loss: 2.2811856910746586

Epoch: 6| Step: 5
Training loss: 2.9801788330078125
Validation loss: 2.30853545793923

Epoch: 6| Step: 6
Training loss: 3.3044629096984863
Validation loss: 2.2920877933502197

Epoch: 6| Step: 7
Training loss: 2.771739959716797
Validation loss: 2.2418965370424333

Epoch: 6| Step: 8
Training loss: 2.187495470046997
Validation loss: 2.1986840796727005

Epoch: 6| Step: 9
Training loss: 2.7453761100769043
Validation loss: 2.181744046108697

Epoch: 6| Step: 10
Training loss: 2.891787528991699
Validation loss: 2.1733580225257465

Epoch: 6| Step: 11
Training loss: 2.895859956741333
Validation loss: 2.1775490494184595

Epoch: 6| Step: 12
Training loss: 2.4066123962402344
Validation loss: 2.186578027663692

Epoch: 6| Step: 13
Training loss: 2.0838866233825684
Validation loss: 2.18289638334705

Epoch: 81| Step: 0
Training loss: 2.8711256980895996
Validation loss: 2.185626012022777

Epoch: 6| Step: 1
Training loss: 2.768124580383301
Validation loss: 2.173499943107687

Epoch: 6| Step: 2
Training loss: 2.4098997116088867
Validation loss: 2.1717581838689823

Epoch: 6| Step: 3
Training loss: 2.0662789344787598
Validation loss: 2.171425198995939

Epoch: 6| Step: 4
Training loss: 2.548856735229492
Validation loss: 2.170463396656898

Epoch: 6| Step: 5
Training loss: 2.506373882293701
Validation loss: 2.16732019506475

Epoch: 6| Step: 6
Training loss: 2.094151258468628
Validation loss: 2.170000894095308

Epoch: 6| Step: 7
Training loss: 2.577232837677002
Validation loss: 2.1647447847550914

Epoch: 6| Step: 8
Training loss: 2.5463106632232666
Validation loss: 2.1729612529918714

Epoch: 6| Step: 9
Training loss: 2.41882061958313
Validation loss: 2.170363376217504

Epoch: 6| Step: 10
Training loss: 2.5448198318481445
Validation loss: 2.180258886788481

Epoch: 6| Step: 11
Training loss: 2.70161509513855
Validation loss: 2.1822840577812603

Epoch: 6| Step: 12
Training loss: 2.4659063816070557
Validation loss: 2.177695151298277

Epoch: 6| Step: 13
Training loss: 2.6282479763031006
Validation loss: 2.1810102026949645

Epoch: 82| Step: 0
Training loss: 2.3997159004211426
Validation loss: 2.181020344457319

Epoch: 6| Step: 1
Training loss: 3.128575325012207
Validation loss: 2.185458119197558

Epoch: 6| Step: 2
Training loss: 2.2257001399993896
Validation loss: 2.178925727003364

Epoch: 6| Step: 3
Training loss: 3.4137020111083984
Validation loss: 2.1700772572589178

Epoch: 6| Step: 4
Training loss: 2.8842105865478516
Validation loss: 2.175025563086233

Epoch: 6| Step: 5
Training loss: 2.1547484397888184
Validation loss: 2.1747185953201784

Epoch: 6| Step: 6
Training loss: 2.7272114753723145
Validation loss: 2.166078770032493

Epoch: 6| Step: 7
Training loss: 1.4497578144073486
Validation loss: 2.1665511797833186

Epoch: 6| Step: 8
Training loss: 2.0340194702148438
Validation loss: 2.1674122912909395

Epoch: 6| Step: 9
Training loss: 2.6643738746643066
Validation loss: 2.17070750523639

Epoch: 6| Step: 10
Training loss: 2.5317859649658203
Validation loss: 2.174271660466348

Epoch: 6| Step: 11
Training loss: 2.26170015335083
Validation loss: 2.185965232951667

Epoch: 6| Step: 12
Training loss: 2.3866326808929443
Validation loss: 2.228178131964899

Epoch: 6| Step: 13
Training loss: 2.5225720405578613
Validation loss: 2.2734288195128083

Epoch: 83| Step: 0
Training loss: 2.297585964202881
Validation loss: 2.2608880330157537

Epoch: 6| Step: 1
Training loss: 2.9822890758514404
Validation loss: 2.2402726091364378

Epoch: 6| Step: 2
Training loss: 2.3427042961120605
Validation loss: 2.2083824834515973

Epoch: 6| Step: 3
Training loss: 3.4255285263061523
Validation loss: 2.1896776537741385

Epoch: 6| Step: 4
Training loss: 2.2529001235961914
Validation loss: 2.170540286648658

Epoch: 6| Step: 5
Training loss: 1.9012936353683472
Validation loss: 2.1696147354700233

Epoch: 6| Step: 6
Training loss: 2.2861804962158203
Validation loss: 2.160545964394846

Epoch: 6| Step: 7
Training loss: 2.225285053253174
Validation loss: 2.1668343941370645

Epoch: 6| Step: 8
Training loss: 3.0039596557617188
Validation loss: 2.1702208570254746

Epoch: 6| Step: 9
Training loss: 1.9556493759155273
Validation loss: 2.177736904031487

Epoch: 6| Step: 10
Training loss: 2.90142560005188
Validation loss: 2.1880397309539137

Epoch: 6| Step: 11
Training loss: 3.4319372177124023
Validation loss: 2.1684375783448577

Epoch: 6| Step: 12
Training loss: 1.9539717435836792
Validation loss: 2.164126310297238

Epoch: 6| Step: 13
Training loss: 1.8300942182540894
Validation loss: 2.1714171055824525

Epoch: 84| Step: 0
Training loss: 1.864012360572815
Validation loss: 2.1886907880024244

Epoch: 6| Step: 1
Training loss: 2.5449037551879883
Validation loss: 2.2012929865109023

Epoch: 6| Step: 2
Training loss: 1.6619956493377686
Validation loss: 2.2410496716858237

Epoch: 6| Step: 3
Training loss: 3.5696699619293213
Validation loss: 2.2150712320881505

Epoch: 6| Step: 4
Training loss: 2.488697052001953
Validation loss: 2.21976016670145

Epoch: 6| Step: 5
Training loss: 2.551441192626953
Validation loss: 2.214646098434284

Epoch: 6| Step: 6
Training loss: 2.2212867736816406
Validation loss: 2.1884977996990247

Epoch: 6| Step: 7
Training loss: 1.9413526058197021
Validation loss: 2.18286947665676

Epoch: 6| Step: 8
Training loss: 2.9592292308807373
Validation loss: 2.1880091633847965

Epoch: 6| Step: 9
Training loss: 2.4552812576293945
Validation loss: 2.1778398303575415

Epoch: 6| Step: 10
Training loss: 3.140791893005371
Validation loss: 2.165512070860914

Epoch: 6| Step: 11
Training loss: 2.1320395469665527
Validation loss: 2.153181077331625

Epoch: 6| Step: 12
Training loss: 2.767381191253662
Validation loss: 2.1571959295580463

Epoch: 6| Step: 13
Training loss: 2.74334979057312
Validation loss: 2.1556127391835695

Epoch: 85| Step: 0
Training loss: 2.0767407417297363
Validation loss: 2.15975808969108

Epoch: 6| Step: 1
Training loss: 3.1475939750671387
Validation loss: 2.1579979235126125

Epoch: 6| Step: 2
Training loss: 2.7005105018615723
Validation loss: 2.1547628577037523

Epoch: 6| Step: 3
Training loss: 2.551584243774414
Validation loss: 2.1537641312486384

Epoch: 6| Step: 4
Training loss: 1.6968088150024414
Validation loss: 2.1520227642469507

Epoch: 6| Step: 5
Training loss: 1.9916775226593018
Validation loss: 2.1560745700713126

Epoch: 6| Step: 6
Training loss: 2.8198494911193848
Validation loss: 2.17007553321059

Epoch: 6| Step: 7
Training loss: 2.6498327255249023
Validation loss: 2.156974966808032

Epoch: 6| Step: 8
Training loss: 2.6257338523864746
Validation loss: 2.170118906164682

Epoch: 6| Step: 9
Training loss: 2.3272457122802734
Validation loss: 2.1835045750423143

Epoch: 6| Step: 10
Training loss: 2.9822773933410645
Validation loss: 2.1981242061943136

Epoch: 6| Step: 11
Training loss: 2.343446731567383
Validation loss: 2.1942542663184543

Epoch: 6| Step: 12
Training loss: 2.5026330947875977
Validation loss: 2.1925118777059738

Epoch: 6| Step: 13
Training loss: 2.2271714210510254
Validation loss: 2.2054063376560005

Epoch: 86| Step: 0
Training loss: 2.910706043243408
Validation loss: 2.187044241095102

Epoch: 6| Step: 1
Training loss: 2.3150835037231445
Validation loss: 2.187660135248656

Epoch: 6| Step: 2
Training loss: 1.760427713394165
Validation loss: 2.1826091133138186

Epoch: 6| Step: 3
Training loss: 2.507591724395752
Validation loss: 2.181340386790614

Epoch: 6| Step: 4
Training loss: 2.7905659675598145
Validation loss: 2.1718645531644105

Epoch: 6| Step: 5
Training loss: 1.8949377536773682
Validation loss: 2.1585894400073635

Epoch: 6| Step: 6
Training loss: 2.3905630111694336
Validation loss: 2.1608702905716433

Epoch: 6| Step: 7
Training loss: 3.1297976970672607
Validation loss: 2.156565486743886

Epoch: 6| Step: 8
Training loss: 2.4490694999694824
Validation loss: 2.1528289523175967

Epoch: 6| Step: 9
Training loss: 2.325751304626465
Validation loss: 2.1515157709839525

Epoch: 6| Step: 10
Training loss: 2.8798906803131104
Validation loss: 2.1545238482054843

Epoch: 6| Step: 11
Training loss: 2.699957847595215
Validation loss: 2.156479225363783

Epoch: 6| Step: 12
Training loss: 2.2839279174804688
Validation loss: 2.1543591176309893

Epoch: 6| Step: 13
Training loss: 2.1073427200317383
Validation loss: 2.1577786194380892

Epoch: 87| Step: 0
Training loss: 2.2511696815490723
Validation loss: 2.157476843044322

Epoch: 6| Step: 1
Training loss: 2.0172135829925537
Validation loss: 2.155046944977135

Epoch: 6| Step: 2
Training loss: 2.178370475769043
Validation loss: 2.16344779281206

Epoch: 6| Step: 3
Training loss: 2.7696433067321777
Validation loss: 2.1944224219168387

Epoch: 6| Step: 4
Training loss: 2.861426830291748
Validation loss: 2.208984180163312

Epoch: 6| Step: 5
Training loss: 2.048887252807617
Validation loss: 2.24137217767777

Epoch: 6| Step: 6
Training loss: 2.2642464637756348
Validation loss: 2.2533428617703017

Epoch: 6| Step: 7
Training loss: 2.075514554977417
Validation loss: 2.2264233635317896

Epoch: 6| Step: 8
Training loss: 2.9216957092285156
Validation loss: 2.176963342133389

Epoch: 6| Step: 9
Training loss: 2.1919915676116943
Validation loss: 2.162727140611218

Epoch: 6| Step: 10
Training loss: 2.6031394004821777
Validation loss: 2.1442241796883206

Epoch: 6| Step: 11
Training loss: 2.69809889793396
Validation loss: 2.1507792921476465

Epoch: 6| Step: 12
Training loss: 2.710951805114746
Validation loss: 2.1609212121655865

Epoch: 6| Step: 13
Training loss: 3.5301012992858887
Validation loss: 2.1715915100548857

Epoch: 88| Step: 0
Training loss: 2.8035292625427246
Validation loss: 2.168081929606776

Epoch: 6| Step: 1
Training loss: 2.3603129386901855
Validation loss: 2.148589441853185

Epoch: 6| Step: 2
Training loss: 2.3608665466308594
Validation loss: 2.138537085184487

Epoch: 6| Step: 3
Training loss: 2.622786045074463
Validation loss: 2.1298828791546565

Epoch: 6| Step: 4
Training loss: 2.1921639442443848
Validation loss: 2.1306402119257117

Epoch: 6| Step: 5
Training loss: 1.9394046068191528
Validation loss: 2.130235110559771

Epoch: 6| Step: 6
Training loss: 2.626371145248413
Validation loss: 2.1509862099924395

Epoch: 6| Step: 7
Training loss: 2.8198511600494385
Validation loss: 2.1761704260303127

Epoch: 6| Step: 8
Training loss: 2.084620475769043
Validation loss: 2.216915709998018

Epoch: 6| Step: 9
Training loss: 2.5189571380615234
Validation loss: 2.2218307218244

Epoch: 6| Step: 10
Training loss: 2.167545795440674
Validation loss: 2.2248222751002156

Epoch: 6| Step: 11
Training loss: 3.207699775695801
Validation loss: 2.236121312264473

Epoch: 6| Step: 12
Training loss: 2.489565372467041
Validation loss: 2.228089799163162

Epoch: 6| Step: 13
Training loss: 2.3681602478027344
Validation loss: 2.1992880362336353

Epoch: 89| Step: 0
Training loss: 2.8416030406951904
Validation loss: 2.1609602051396526

Epoch: 6| Step: 1
Training loss: 2.7627248764038086
Validation loss: 2.14117722101109

Epoch: 6| Step: 2
Training loss: 1.6831008195877075
Validation loss: 2.1359024252942813

Epoch: 6| Step: 3
Training loss: 2.6065638065338135
Validation loss: 2.1356125595749065

Epoch: 6| Step: 4
Training loss: 2.5968828201293945
Validation loss: 2.1574014438095914

Epoch: 6| Step: 5
Training loss: 2.4426703453063965
Validation loss: 2.170040771525393

Epoch: 6| Step: 6
Training loss: 2.6991708278656006
Validation loss: 2.164199411228139

Epoch: 6| Step: 7
Training loss: 2.684722900390625
Validation loss: 2.1769645598626908

Epoch: 6| Step: 8
Training loss: 2.4669690132141113
Validation loss: 2.1629012297558528

Epoch: 6| Step: 9
Training loss: 2.6267588138580322
Validation loss: 2.151421804581919

Epoch: 6| Step: 10
Training loss: 1.8089470863342285
Validation loss: 2.1311575058967835

Epoch: 6| Step: 11
Training loss: 2.353182792663574
Validation loss: 2.1278772213125743

Epoch: 6| Step: 12
Training loss: 2.7998290061950684
Validation loss: 2.15045190113847

Epoch: 6| Step: 13
Training loss: 2.3183608055114746
Validation loss: 2.21261513874095

Epoch: 90| Step: 0
Training loss: 2.7248382568359375
Validation loss: 2.324891697975897

Epoch: 6| Step: 1
Training loss: 2.2323038578033447
Validation loss: 2.377734775184303

Epoch: 6| Step: 2
Training loss: 2.088682174682617
Validation loss: 2.4192732149554836

Epoch: 6| Step: 3
Training loss: 2.8749380111694336
Validation loss: 2.3655837325639624

Epoch: 6| Step: 4
Training loss: 2.637540340423584
Validation loss: 2.2473667962576753

Epoch: 6| Step: 5
Training loss: 2.102033853530884
Validation loss: 2.1743691223923878

Epoch: 6| Step: 6
Training loss: 2.254012107849121
Validation loss: 2.1481803604351577

Epoch: 6| Step: 7
Training loss: 2.5459959506988525
Validation loss: 2.1311003726015807

Epoch: 6| Step: 8
Training loss: 2.944728136062622
Validation loss: 2.1275490330111597

Epoch: 6| Step: 9
Training loss: 2.7187366485595703
Validation loss: 2.1292289508286344

Epoch: 6| Step: 10
Training loss: 2.2705349922180176
Validation loss: 2.1348554113859772

Epoch: 6| Step: 11
Training loss: 2.7564642429351807
Validation loss: 2.1371519475854854

Epoch: 6| Step: 12
Training loss: 2.781761646270752
Validation loss: 2.1378486130827214

Epoch: 6| Step: 13
Training loss: 1.4016013145446777
Validation loss: 2.138083368219355

Epoch: 91| Step: 0
Training loss: 2.803863525390625
Validation loss: 2.129089742578486

Epoch: 6| Step: 1
Training loss: 2.590749740600586
Validation loss: 2.1266181443327214

Epoch: 6| Step: 2
Training loss: 1.787900686264038
Validation loss: 2.1246123736904514

Epoch: 6| Step: 3
Training loss: 3.3910844326019287
Validation loss: 2.136350420213515

Epoch: 6| Step: 4
Training loss: 2.4644582271575928
Validation loss: 2.1386143110131703

Epoch: 6| Step: 5
Training loss: 2.2029800415039062
Validation loss: 2.143280442043017

Epoch: 6| Step: 6
Training loss: 2.3026885986328125
Validation loss: 2.1639519340248516

Epoch: 6| Step: 7
Training loss: 2.5162057876586914
Validation loss: 2.1848036794252295

Epoch: 6| Step: 8
Training loss: 1.8486881256103516
Validation loss: 2.184115194505261

Epoch: 6| Step: 9
Training loss: 2.271829128265381
Validation loss: 2.184818119131109

Epoch: 6| Step: 10
Training loss: 2.22373104095459
Validation loss: 2.2174342857894076

Epoch: 6| Step: 11
Training loss: 2.440451145172119
Validation loss: 2.1960869386631954

Epoch: 6| Step: 12
Training loss: 3.0562031269073486
Validation loss: 2.1812799387080695

Epoch: 6| Step: 13
Training loss: 2.945770740509033
Validation loss: 2.155107000822662

Epoch: 92| Step: 0
Training loss: 1.9022393226623535
Validation loss: 2.128417723922319

Epoch: 6| Step: 1
Training loss: 2.490790843963623
Validation loss: 2.1208715567024807

Epoch: 6| Step: 2
Training loss: 2.2450618743896484
Validation loss: 2.117988060879451

Epoch: 6| Step: 3
Training loss: 2.5527071952819824
Validation loss: 2.1233735584443614

Epoch: 6| Step: 4
Training loss: 2.6197779178619385
Validation loss: 2.121099820701025

Epoch: 6| Step: 5
Training loss: 2.9992563724517822
Validation loss: 2.124812513269404

Epoch: 6| Step: 6
Training loss: 2.4609646797180176
Validation loss: 2.129231849024373

Epoch: 6| Step: 7
Training loss: 2.125281572341919
Validation loss: 2.1375997066497803

Epoch: 6| Step: 8
Training loss: 1.7920547723770142
Validation loss: 2.1323778347302507

Epoch: 6| Step: 9
Training loss: 2.6223199367523193
Validation loss: 2.130128273399927

Epoch: 6| Step: 10
Training loss: 2.3990633487701416
Validation loss: 2.1223071954583608

Epoch: 6| Step: 11
Training loss: 2.9124045372009277
Validation loss: 2.118432908929804

Epoch: 6| Step: 12
Training loss: 2.6757678985595703
Validation loss: 2.1098466662950415

Epoch: 6| Step: 13
Training loss: 3.674992561340332
Validation loss: 2.1091257679846978

Epoch: 93| Step: 0
Training loss: 2.4236197471618652
Validation loss: 2.11610141364477

Epoch: 6| Step: 1
Training loss: 2.1527698040008545
Validation loss: 2.1318259457106232

Epoch: 6| Step: 2
Training loss: 2.5087194442749023
Validation loss: 2.140591739326395

Epoch: 6| Step: 3
Training loss: 3.0875959396362305
Validation loss: 2.1463138672613327

Epoch: 6| Step: 4
Training loss: 2.8818511962890625
Validation loss: 2.1605179181662937

Epoch: 6| Step: 5
Training loss: 2.7015187740325928
Validation loss: 2.1814666807010608

Epoch: 6| Step: 6
Training loss: 2.0098605155944824
Validation loss: 2.1622058242879887

Epoch: 6| Step: 7
Training loss: 2.950127124786377
Validation loss: 2.163991261554021

Epoch: 6| Step: 8
Training loss: 2.6875033378601074
Validation loss: 2.148537282020815

Epoch: 6| Step: 9
Training loss: 2.0928735733032227
Validation loss: 2.124088684717814

Epoch: 6| Step: 10
Training loss: 2.1062846183776855
Validation loss: 2.1160012304141955

Epoch: 6| Step: 11
Training loss: 2.0188751220703125
Validation loss: 2.1071808184346845

Epoch: 6| Step: 12
Training loss: 2.2280635833740234
Validation loss: 2.1075667963233045

Epoch: 6| Step: 13
Training loss: 2.4604594707489014
Validation loss: 2.102379893743864

Epoch: 94| Step: 0
Training loss: 2.460385322570801
Validation loss: 2.100760022799174

Epoch: 6| Step: 1
Training loss: 2.5162887573242188
Validation loss: 2.106353006055278

Epoch: 6| Step: 2
Training loss: 2.6859474182128906
Validation loss: 2.0999993380679878

Epoch: 6| Step: 3
Training loss: 2.3667545318603516
Validation loss: 2.10386138321251

Epoch: 6| Step: 4
Training loss: 2.6838765144348145
Validation loss: 2.1088394170166342

Epoch: 6| Step: 5
Training loss: 2.3586976528167725
Validation loss: 2.1025150616963706

Epoch: 6| Step: 6
Training loss: 2.016493797302246
Validation loss: 2.1079593038046234

Epoch: 6| Step: 7
Training loss: 2.2542946338653564
Validation loss: 2.1033245286633893

Epoch: 6| Step: 8
Training loss: 2.408838987350464
Validation loss: 2.1086299368130264

Epoch: 6| Step: 9
Training loss: 2.698237419128418
Validation loss: 2.1243180997910036

Epoch: 6| Step: 10
Training loss: 3.117351770401001
Validation loss: 2.139649855193271

Epoch: 6| Step: 11
Training loss: 2.2724826335906982
Validation loss: 2.1383901385850805

Epoch: 6| Step: 12
Training loss: 1.764723777770996
Validation loss: 2.173855020153907

Epoch: 6| Step: 13
Training loss: 3.0282678604125977
Validation loss: 2.166000166246968

Epoch: 95| Step: 0
Training loss: 2.1989288330078125
Validation loss: 2.1646735065726825

Epoch: 6| Step: 1
Training loss: 1.7158894538879395
Validation loss: 2.1373816741410123

Epoch: 6| Step: 2
Training loss: 2.503659248352051
Validation loss: 2.120549116083371

Epoch: 6| Step: 3
Training loss: 2.1418333053588867
Validation loss: 2.1138430103178947

Epoch: 6| Step: 4
Training loss: 2.3045973777770996
Validation loss: 2.108540247845393

Epoch: 6| Step: 5
Training loss: 2.1346423625946045
Validation loss: 2.107108054622527

Epoch: 6| Step: 6
Training loss: 2.7974023818969727
Validation loss: 2.1077442605008363

Epoch: 6| Step: 7
Training loss: 3.4781975746154785
Validation loss: 2.1002271841931086

Epoch: 6| Step: 8
Training loss: 2.3641865253448486
Validation loss: 2.1059116548107517

Epoch: 6| Step: 9
Training loss: 2.592074394226074
Validation loss: 2.1087956505437053

Epoch: 6| Step: 10
Training loss: 2.9272215366363525
Validation loss: 2.1001160247351534

Epoch: 6| Step: 11
Training loss: 2.6120479106903076
Validation loss: 2.104664961496989

Epoch: 6| Step: 12
Training loss: 1.966864824295044
Validation loss: 2.1148504980148806

Epoch: 6| Step: 13
Training loss: 2.396928071975708
Validation loss: 2.1058101013142574

Epoch: 96| Step: 0
Training loss: 2.707859516143799
Validation loss: 2.1099892944417973

Epoch: 6| Step: 1
Training loss: 2.1609766483306885
Validation loss: 2.124621557933028

Epoch: 6| Step: 2
Training loss: 3.2831273078918457
Validation loss: 2.1342535916195122

Epoch: 6| Step: 3
Training loss: 3.074449300765991
Validation loss: 2.1440280073432514

Epoch: 6| Step: 4
Training loss: 2.4071145057678223
Validation loss: 2.161770498880776

Epoch: 6| Step: 5
Training loss: 2.6146368980407715
Validation loss: 2.1499640492982763

Epoch: 6| Step: 6
Training loss: 1.652517557144165
Validation loss: 2.1593074798583984

Epoch: 6| Step: 7
Training loss: 1.9146394729614258
Validation loss: 2.1549467617465603

Epoch: 6| Step: 8
Training loss: 2.2455925941467285
Validation loss: 2.130382642951063

Epoch: 6| Step: 9
Training loss: 2.3204290866851807
Validation loss: 2.130746938849008

Epoch: 6| Step: 10
Training loss: 2.588148832321167
Validation loss: 2.122529657938147

Epoch: 6| Step: 11
Training loss: 2.7822561264038086
Validation loss: 2.1123860113082396

Epoch: 6| Step: 12
Training loss: 2.158933401107788
Validation loss: 2.1112249077007337

Epoch: 6| Step: 13
Training loss: 1.6967847347259521
Validation loss: 2.111289180735106

Epoch: 97| Step: 0
Training loss: 2.776254653930664
Validation loss: 2.1118747444563013

Epoch: 6| Step: 1
Training loss: 2.504957914352417
Validation loss: 2.1327468836179344

Epoch: 6| Step: 2
Training loss: 2.5115442276000977
Validation loss: 2.15621123262631

Epoch: 6| Step: 3
Training loss: 2.575148105621338
Validation loss: 2.1837884149243756

Epoch: 6| Step: 4
Training loss: 2.4039669036865234
Validation loss: 2.184126461705854

Epoch: 6| Step: 5
Training loss: 2.3318819999694824
Validation loss: 2.1753321668153167

Epoch: 6| Step: 6
Training loss: 2.5278737545013428
Validation loss: 2.1572240885867866

Epoch: 6| Step: 7
Training loss: 2.024047374725342
Validation loss: 2.1580203528045327

Epoch: 6| Step: 8
Training loss: 2.6244711875915527
Validation loss: 2.129141592210339

Epoch: 6| Step: 9
Training loss: 2.307673931121826
Validation loss: 2.1239685512358144

Epoch: 6| Step: 10
Training loss: 1.7937839031219482
Validation loss: 2.1122355371393184

Epoch: 6| Step: 11
Training loss: 2.912501811981201
Validation loss: 2.1058744204941617

Epoch: 6| Step: 12
Training loss: 2.3542869091033936
Validation loss: 2.092608226242886

Epoch: 6| Step: 13
Training loss: 2.575976610183716
Validation loss: 2.085652676961755

Epoch: 98| Step: 0
Training loss: 3.003786087036133
Validation loss: 2.0972553683865454

Epoch: 6| Step: 1
Training loss: 2.4738056659698486
Validation loss: 2.0941733391054216

Epoch: 6| Step: 2
Training loss: 2.9465816020965576
Validation loss: 2.104076668780337

Epoch: 6| Step: 3
Training loss: 2.2919087409973145
Validation loss: 2.10526373950384

Epoch: 6| Step: 4
Training loss: 2.2856969833374023
Validation loss: 2.099347496545443

Epoch: 6| Step: 5
Training loss: 2.31019926071167
Validation loss: 2.097352473966537

Epoch: 6| Step: 6
Training loss: 2.279043197631836
Validation loss: 2.092671143111362

Epoch: 6| Step: 7
Training loss: 2.393573522567749
Validation loss: 2.090143202453531

Epoch: 6| Step: 8
Training loss: 1.9153993129730225
Validation loss: 2.082708401064719

Epoch: 6| Step: 9
Training loss: 2.6013779640197754
Validation loss: 2.0778208214749574

Epoch: 6| Step: 10
Training loss: 2.3095357418060303
Validation loss: 2.093175124096614

Epoch: 6| Step: 11
Training loss: 2.3398356437683105
Validation loss: 2.110686158621183

Epoch: 6| Step: 12
Training loss: 2.7676825523376465
Validation loss: 2.1394408723359466

Epoch: 6| Step: 13
Training loss: 2.1506786346435547
Validation loss: 2.1443848763742754

Epoch: 99| Step: 0
Training loss: 2.9895386695861816
Validation loss: 2.1570149903656333

Epoch: 6| Step: 1
Training loss: 2.7394979000091553
Validation loss: 2.16474425408148

Epoch: 6| Step: 2
Training loss: 2.39188814163208
Validation loss: 2.132507760037658

Epoch: 6| Step: 3
Training loss: 2.362410306930542
Validation loss: 2.118145086432016

Epoch: 6| Step: 4
Training loss: 1.7193284034729004
Validation loss: 2.1252443277707664

Epoch: 6| Step: 5
Training loss: 1.9581308364868164
Validation loss: 2.114929122309531

Epoch: 6| Step: 6
Training loss: 2.0166468620300293
Validation loss: 2.1260079183886127

Epoch: 6| Step: 7
Training loss: 2.494408130645752
Validation loss: 2.096034285842731

Epoch: 6| Step: 8
Training loss: 2.588744640350342
Validation loss: 2.0846741789130756

Epoch: 6| Step: 9
Training loss: 2.535188913345337
Validation loss: 2.0878186712982836

Epoch: 6| Step: 10
Training loss: 2.7741143703460693
Validation loss: 2.093626824758386

Epoch: 6| Step: 11
Training loss: 2.6579360961914062
Validation loss: 2.094795593651392

Epoch: 6| Step: 12
Training loss: 2.094134569168091
Validation loss: 2.100388983244537

Epoch: 6| Step: 13
Training loss: 2.566354751586914
Validation loss: 2.092299884365451

Epoch: 100| Step: 0
Training loss: 2.0966787338256836
Validation loss: 2.0982200561031217

Epoch: 6| Step: 1
Training loss: 2.0592923164367676
Validation loss: 2.073637334249353

Epoch: 6| Step: 2
Training loss: 2.223613739013672
Validation loss: 2.070062438646952

Epoch: 6| Step: 3
Training loss: 2.5643057823181152
Validation loss: 2.0772882635875414

Epoch: 6| Step: 4
Training loss: 2.6839985847473145
Validation loss: 2.076808191114856

Epoch: 6| Step: 5
Training loss: 2.4482595920562744
Validation loss: 2.0841133094603017

Epoch: 6| Step: 6
Training loss: 2.3651416301727295
Validation loss: 2.0875489596397645

Epoch: 6| Step: 7
Training loss: 3.4807558059692383
Validation loss: 2.0927056099778865

Epoch: 6| Step: 8
Training loss: 2.5523366928100586
Validation loss: 2.0909723261351227

Epoch: 6| Step: 9
Training loss: 2.6384851932525635
Validation loss: 2.078905159427274

Epoch: 6| Step: 10
Training loss: 2.5286812782287598
Validation loss: 2.078242063522339

Epoch: 6| Step: 11
Training loss: 2.0404958724975586
Validation loss: 2.0718899157739457

Epoch: 6| Step: 12
Training loss: 2.0129342079162598
Validation loss: 2.070852438608805

Epoch: 6| Step: 13
Training loss: 2.6875007152557373
Validation loss: 2.086167671347177

Epoch: 101| Step: 0
Training loss: 1.9334096908569336
Validation loss: 2.1050448904755297

Epoch: 6| Step: 1
Training loss: 2.395467758178711
Validation loss: 2.107627946843383

Epoch: 6| Step: 2
Training loss: 2.575667142868042
Validation loss: 2.1237336461262037

Epoch: 6| Step: 3
Training loss: 2.4971933364868164
Validation loss: 2.1212455918712

Epoch: 6| Step: 4
Training loss: 2.1130099296569824
Validation loss: 2.1212256255970208

Epoch: 6| Step: 5
Training loss: 2.763302803039551
Validation loss: 2.127969600821054

Epoch: 6| Step: 6
Training loss: 2.2475874423980713
Validation loss: 2.1137444383354596

Epoch: 6| Step: 7
Training loss: 2.066694736480713
Validation loss: 2.116027834594891

Epoch: 6| Step: 8
Training loss: 2.459298610687256
Validation loss: 2.126862459285285

Epoch: 6| Step: 9
Training loss: 1.776930332183838
Validation loss: 2.1234560448636293

Epoch: 6| Step: 10
Training loss: 2.9825541973114014
Validation loss: 2.1346764782423615

Epoch: 6| Step: 11
Training loss: 2.815992832183838
Validation loss: 2.120211749948481

Epoch: 6| Step: 12
Training loss: 2.6012024879455566
Validation loss: 2.105540948529397

Epoch: 6| Step: 13
Training loss: 2.173656463623047
Validation loss: 2.104156909450408

Epoch: 102| Step: 0
Training loss: 3.1573739051818848
Validation loss: 2.0834562188835553

Epoch: 6| Step: 1
Training loss: 2.1421356201171875
Validation loss: 2.0646261681792555

Epoch: 6| Step: 2
Training loss: 2.0598318576812744
Validation loss: 2.0531967609159407

Epoch: 6| Step: 3
Training loss: 2.04233717918396
Validation loss: 2.0626788626434984

Epoch: 6| Step: 4
Training loss: 2.648338556289673
Validation loss: 2.0624084011200936

Epoch: 6| Step: 5
Training loss: 2.591248035430908
Validation loss: 2.068821337915236

Epoch: 6| Step: 6
Training loss: 2.0706591606140137
Validation loss: 2.079408255956506

Epoch: 6| Step: 7
Training loss: 2.274193286895752
Validation loss: 2.0886733301224245

Epoch: 6| Step: 8
Training loss: 2.2789597511291504
Validation loss: 2.0819534845249628

Epoch: 6| Step: 9
Training loss: 2.6669607162475586
Validation loss: 2.079411470761863

Epoch: 6| Step: 10
Training loss: 2.5113813877105713
Validation loss: 2.079352622391075

Epoch: 6| Step: 11
Training loss: 2.365360736846924
Validation loss: 2.1110082313578618

Epoch: 6| Step: 12
Training loss: 2.5997939109802246
Validation loss: 2.1452050542318695

Epoch: 6| Step: 13
Training loss: 2.0395021438598633
Validation loss: 2.1257479754827355

Epoch: 103| Step: 0
Training loss: 2.3059780597686768
Validation loss: 2.1350353071766515

Epoch: 6| Step: 1
Training loss: 2.3117945194244385
Validation loss: 2.1115739730096634

Epoch: 6| Step: 2
Training loss: 2.51302433013916
Validation loss: 2.099933043602974

Epoch: 6| Step: 3
Training loss: 2.3892745971679688
Validation loss: 2.0918141270196564

Epoch: 6| Step: 4
Training loss: 2.7268409729003906
Validation loss: 2.085369251107657

Epoch: 6| Step: 5
Training loss: 2.44004225730896
Validation loss: 2.0730990261159916

Epoch: 6| Step: 6
Training loss: 2.0837833881378174
Validation loss: 2.0735084728528093

Epoch: 6| Step: 7
Training loss: 2.047990322113037
Validation loss: 2.071498854185945

Epoch: 6| Step: 8
Training loss: 2.618530750274658
Validation loss: 2.0744299401519117

Epoch: 6| Step: 9
Training loss: 2.88718581199646
Validation loss: 2.0691030615119526

Epoch: 6| Step: 10
Training loss: 2.1930830478668213
Validation loss: 2.0701518981687483

Epoch: 6| Step: 11
Training loss: 2.2648262977600098
Validation loss: 2.0752898877666843

Epoch: 6| Step: 12
Training loss: 2.3478317260742188
Validation loss: 2.0843370986241165

Epoch: 6| Step: 13
Training loss: 2.1140828132629395
Validation loss: 2.0949794989760204

Epoch: 104| Step: 0
Training loss: 2.9297537803649902
Validation loss: 2.087519722600137

Epoch: 6| Step: 1
Training loss: 2.575511932373047
Validation loss: 2.067056712283883

Epoch: 6| Step: 2
Training loss: 2.159101963043213
Validation loss: 2.060774019969407

Epoch: 6| Step: 3
Training loss: 2.362532138824463
Validation loss: 2.0638942872324297

Epoch: 6| Step: 4
Training loss: 2.161607265472412
Validation loss: 2.062597615744478

Epoch: 6| Step: 5
Training loss: 2.0146989822387695
Validation loss: 2.0666476488113403

Epoch: 6| Step: 6
Training loss: 2.4079456329345703
Validation loss: 2.068252671149469

Epoch: 6| Step: 7
Training loss: 2.0620598793029785
Validation loss: 2.0601243434413785

Epoch: 6| Step: 8
Training loss: 2.9463536739349365
Validation loss: 2.058058818181356

Epoch: 6| Step: 9
Training loss: 1.996292233467102
Validation loss: 2.0660258134206138

Epoch: 6| Step: 10
Training loss: 2.3942947387695312
Validation loss: 2.0696724114879483

Epoch: 6| Step: 11
Training loss: 2.725130081176758
Validation loss: 2.079494294299874

Epoch: 6| Step: 12
Training loss: 2.303997039794922
Validation loss: 2.0900845643012755

Epoch: 6| Step: 13
Training loss: 2.42795729637146
Validation loss: 2.1041168628200406

Epoch: 105| Step: 0
Training loss: 2.505765199661255
Validation loss: 2.1464776121160036

Epoch: 6| Step: 1
Training loss: 2.6428747177124023
Validation loss: 2.1464102178491573

Epoch: 6| Step: 2
Training loss: 1.8232622146606445
Validation loss: 2.1348592619742117

Epoch: 6| Step: 3
Training loss: 1.9516022205352783
Validation loss: 2.0963828922599874

Epoch: 6| Step: 4
Training loss: 2.507169008255005
Validation loss: 2.0625270412814234

Epoch: 6| Step: 5
Training loss: 2.6103923320770264
Validation loss: 2.048501396691927

Epoch: 6| Step: 6
Training loss: 2.1282670497894287
Validation loss: 2.0579871772437968

Epoch: 6| Step: 7
Training loss: 2.26065731048584
Validation loss: 2.056234951942198

Epoch: 6| Step: 8
Training loss: 2.5147223472595215
Validation loss: 2.050264576429962

Epoch: 6| Step: 9
Training loss: 1.9957133531570435
Validation loss: 2.060530621518371

Epoch: 6| Step: 10
Training loss: 2.531163215637207
Validation loss: 2.0528220566370154

Epoch: 6| Step: 11
Training loss: 2.9957404136657715
Validation loss: 2.0601954101234354

Epoch: 6| Step: 12
Training loss: 3.042330503463745
Validation loss: 2.054983080074351

Epoch: 6| Step: 13
Training loss: 1.8772610425949097
Validation loss: 2.0590674748984714

Epoch: 106| Step: 0
Training loss: 2.687830686569214
Validation loss: 2.0599964229009484

Epoch: 6| Step: 1
Training loss: 2.1035985946655273
Validation loss: 2.0636225003068165

Epoch: 6| Step: 2
Training loss: 1.6038072109222412
Validation loss: 2.074093070081485

Epoch: 6| Step: 3
Training loss: 2.1007280349731445
Validation loss: 2.089128516053641

Epoch: 6| Step: 4
Training loss: 2.021852493286133
Validation loss: 2.105675715272145

Epoch: 6| Step: 5
Training loss: 2.498884677886963
Validation loss: 2.1137047224147345

Epoch: 6| Step: 6
Training loss: 2.714357852935791
Validation loss: 2.1002597475564606

Epoch: 6| Step: 7
Training loss: 2.8705217838287354
Validation loss: 2.0980124832481466

Epoch: 6| Step: 8
Training loss: 2.5233898162841797
Validation loss: 2.1130525655643915

Epoch: 6| Step: 9
Training loss: 2.2868854999542236
Validation loss: 2.109836683478407

Epoch: 6| Step: 10
Training loss: 1.7839715480804443
Validation loss: 2.1187162219837146

Epoch: 6| Step: 11
Training loss: 2.960944652557373
Validation loss: 2.1039259062018445

Epoch: 6| Step: 12
Training loss: 2.7195944786071777
Validation loss: 2.0941047283910934

Epoch: 6| Step: 13
Training loss: 2.3692805767059326
Validation loss: 2.0533928063607987

Epoch: 107| Step: 0
Training loss: 3.0965657234191895
Validation loss: 2.054366969293164

Epoch: 6| Step: 1
Training loss: 1.7004098892211914
Validation loss: 2.0514733458078034

Epoch: 6| Step: 2
Training loss: 2.420358180999756
Validation loss: 2.0474006847668718

Epoch: 6| Step: 3
Training loss: 1.9283268451690674
Validation loss: 2.0511592921390327

Epoch: 6| Step: 4
Training loss: 2.6072115898132324
Validation loss: 2.067593280987073

Epoch: 6| Step: 5
Training loss: 2.522533416748047
Validation loss: 2.0615883309354066

Epoch: 6| Step: 6
Training loss: 2.0694918632507324
Validation loss: 2.071709256018362

Epoch: 6| Step: 7
Training loss: 2.140909194946289
Validation loss: 2.073018914909773

Epoch: 6| Step: 8
Training loss: 2.5126724243164062
Validation loss: 2.0783429363722443

Epoch: 6| Step: 9
Training loss: 2.838313579559326
Validation loss: 2.0754390596061625

Epoch: 6| Step: 10
Training loss: 2.2175261974334717
Validation loss: 2.061236527658278

Epoch: 6| Step: 11
Training loss: 2.528243064880371
Validation loss: 2.0586807189449186

Epoch: 6| Step: 12
Training loss: 2.1716878414154053
Validation loss: 2.0525630033144386

Epoch: 6| Step: 13
Training loss: 1.9839025735855103
Validation loss: 2.0450875989852415

Epoch: 108| Step: 0
Training loss: 2.8960916996002197
Validation loss: 2.0374432994473364

Epoch: 6| Step: 1
Training loss: 2.1396162509918213
Validation loss: 2.0474869000014437

Epoch: 6| Step: 2
Training loss: 2.0534794330596924
Validation loss: 2.038476279986802

Epoch: 6| Step: 3
Training loss: 2.6993234157562256
Validation loss: 2.0430454746369393

Epoch: 6| Step: 4
Training loss: 2.1938157081604004
Validation loss: 2.0348807509227465

Epoch: 6| Step: 5
Training loss: 2.8560924530029297
Validation loss: 2.0369948187182025

Epoch: 6| Step: 6
Training loss: 2.8066623210906982
Validation loss: 2.04383687819204

Epoch: 6| Step: 7
Training loss: 1.8546245098114014
Validation loss: 2.035735237982965

Epoch: 6| Step: 8
Training loss: 2.3599555492401123
Validation loss: 2.0536041285402034

Epoch: 6| Step: 9
Training loss: 2.1754727363586426
Validation loss: 2.061014667634041

Epoch: 6| Step: 10
Training loss: 2.34468936920166
Validation loss: 2.080834545114989

Epoch: 6| Step: 11
Training loss: 2.137444257736206
Validation loss: 2.06982445973222

Epoch: 6| Step: 12
Training loss: 2.1849098205566406
Validation loss: 2.0938775103579284

Epoch: 6| Step: 13
Training loss: 2.288475513458252
Validation loss: 2.109453006457257

Epoch: 109| Step: 0
Training loss: 2.91719913482666
Validation loss: 2.1519477931402062

Epoch: 6| Step: 1
Training loss: 2.0331687927246094
Validation loss: 2.1475484268639677

Epoch: 6| Step: 2
Training loss: 3.2047119140625
Validation loss: 2.136014956299977

Epoch: 6| Step: 3
Training loss: 1.5695104598999023
Validation loss: 2.110472274082963

Epoch: 6| Step: 4
Training loss: 1.8327209949493408
Validation loss: 2.074523970644961

Epoch: 6| Step: 5
Training loss: 2.595369815826416
Validation loss: 2.050053988733599

Epoch: 6| Step: 6
Training loss: 1.9879939556121826
Validation loss: 2.03601457354843

Epoch: 6| Step: 7
Training loss: 2.2936580181121826
Validation loss: 2.0320707226312287

Epoch: 6| Step: 8
Training loss: 2.5386619567871094
Validation loss: 2.0390625102545625

Epoch: 6| Step: 9
Training loss: 2.6584815979003906
Validation loss: 2.0353862867560437

Epoch: 6| Step: 10
Training loss: 2.7903130054473877
Validation loss: 2.0493750315840527

Epoch: 6| Step: 11
Training loss: 2.551537036895752
Validation loss: 2.080781880245414

Epoch: 6| Step: 12
Training loss: 2.36631441116333
Validation loss: 2.108515795841012

Epoch: 6| Step: 13
Training loss: 1.8103044033050537
Validation loss: 2.1218424022838636

Epoch: 110| Step: 0
Training loss: 1.8074684143066406
Validation loss: 2.12603227297465

Epoch: 6| Step: 1
Training loss: 2.7685599327087402
Validation loss: 2.116081614648142

Epoch: 6| Step: 2
Training loss: 2.899796485900879
Validation loss: 2.092200534318083

Epoch: 6| Step: 3
Training loss: 2.8120179176330566
Validation loss: 2.066175660779399

Epoch: 6| Step: 4
Training loss: 2.415787935256958
Validation loss: 2.0344172587958713

Epoch: 6| Step: 5
Training loss: 2.01501727104187
Validation loss: 2.037951498903254

Epoch: 6| Step: 6
Training loss: 2.378699779510498
Validation loss: 2.035743071186927

Epoch: 6| Step: 7
Training loss: 2.062671422958374
Validation loss: 2.035767391163816

Epoch: 6| Step: 8
Training loss: 1.805026888847351
Validation loss: 2.0422804893985873

Epoch: 6| Step: 9
Training loss: 2.9277846813201904
Validation loss: 2.062660091666765

Epoch: 6| Step: 10
Training loss: 2.205944776535034
Validation loss: 2.091102247597069

Epoch: 6| Step: 11
Training loss: 2.6605875492095947
Validation loss: 2.0953068143577984

Epoch: 6| Step: 12
Training loss: 2.3036606311798096
Validation loss: 2.0920129245327366

Epoch: 6| Step: 13
Training loss: 2.5304317474365234
Validation loss: 2.092828950574321

Epoch: 111| Step: 0
Training loss: 2.293822765350342
Validation loss: 2.088026335162501

Epoch: 6| Step: 1
Training loss: 2.159625291824341
Validation loss: 2.0957115670686126

Epoch: 6| Step: 2
Training loss: 2.8983304500579834
Validation loss: 2.084345943184309

Epoch: 6| Step: 3
Training loss: 2.2335543632507324
Validation loss: 2.099818545003091

Epoch: 6| Step: 4
Training loss: 2.6955406665802
Validation loss: 2.0958566486194568

Epoch: 6| Step: 5
Training loss: 1.8030810356140137
Validation loss: 2.087334527764269

Epoch: 6| Step: 6
Training loss: 2.5250377655029297
Validation loss: 2.0850398130314325

Epoch: 6| Step: 7
Training loss: 2.101701021194458
Validation loss: 2.0820678280245875

Epoch: 6| Step: 8
Training loss: 2.781967878341675
Validation loss: 2.0835995289587204

Epoch: 6| Step: 9
Training loss: 3.0531249046325684
Validation loss: 2.0807741893235074

Epoch: 6| Step: 10
Training loss: 2.100659132003784
Validation loss: 2.0765124956766763

Epoch: 6| Step: 11
Training loss: 1.1714341640472412
Validation loss: 2.065742113256967

Epoch: 6| Step: 12
Training loss: 2.8546881675720215
Validation loss: 2.0652103859891175

Epoch: 6| Step: 13
Training loss: 2.192492961883545
Validation loss: 2.0639241818458802

Epoch: 112| Step: 0
Training loss: 2.737260341644287
Validation loss: 2.049399596388622

Epoch: 6| Step: 1
Training loss: 2.1814584732055664
Validation loss: 2.030908747385907

Epoch: 6| Step: 2
Training loss: 2.7145936489105225
Validation loss: 2.031433618196877

Epoch: 6| Step: 3
Training loss: 2.128025770187378
Validation loss: 2.038042083863289

Epoch: 6| Step: 4
Training loss: 2.731285810470581
Validation loss: 2.0351791945836877

Epoch: 6| Step: 5
Training loss: 2.5491771697998047
Validation loss: 2.038104926386187

Epoch: 6| Step: 6
Training loss: 2.054032325744629
Validation loss: 2.041258304349838

Epoch: 6| Step: 7
Training loss: 2.356919765472412
Validation loss: 2.02641212812034

Epoch: 6| Step: 8
Training loss: 2.269728422164917
Validation loss: 2.0454246613287155

Epoch: 6| Step: 9
Training loss: 2.2016472816467285
Validation loss: 2.0424347205828597

Epoch: 6| Step: 10
Training loss: 2.076108932495117
Validation loss: 2.0393077968269266

Epoch: 6| Step: 11
Training loss: 1.766796350479126
Validation loss: 2.056175398570235

Epoch: 6| Step: 12
Training loss: 2.6897640228271484
Validation loss: 2.0647197167078652

Epoch: 6| Step: 13
Training loss: 2.931565761566162
Validation loss: 2.070038292997627

Epoch: 113| Step: 0
Training loss: 1.4303357601165771
Validation loss: 2.085781899831628

Epoch: 6| Step: 1
Training loss: 2.5441274642944336
Validation loss: 2.0713599061453216

Epoch: 6| Step: 2
Training loss: 2.5665907859802246
Validation loss: 2.062116612670242

Epoch: 6| Step: 3
Training loss: 1.910433053970337
Validation loss: 2.0382050826985347

Epoch: 6| Step: 4
Training loss: 2.2705397605895996
Validation loss: 2.023878571807697

Epoch: 6| Step: 5
Training loss: 2.4207918643951416
Validation loss: 2.0219950881055606

Epoch: 6| Step: 6
Training loss: 2.427736282348633
Validation loss: 2.015608764463855

Epoch: 6| Step: 7
Training loss: 2.3642828464508057
Validation loss: 2.020260318633049

Epoch: 6| Step: 8
Training loss: 2.816528797149658
Validation loss: 2.0201850757803967

Epoch: 6| Step: 9
Training loss: 2.4556009769439697
Validation loss: 2.0236171432720718

Epoch: 6| Step: 10
Training loss: 3.5243842601776123
Validation loss: 2.0245197447397376

Epoch: 6| Step: 11
Training loss: 1.972870111465454
Validation loss: 2.021850069363912

Epoch: 6| Step: 12
Training loss: 2.232459306716919
Validation loss: 2.0276739635775165

Epoch: 6| Step: 13
Training loss: 1.9405392408370972
Validation loss: 2.0320605590779293

Epoch: 114| Step: 0
Training loss: 1.7824523448944092
Validation loss: 2.038245431838497

Epoch: 6| Step: 1
Training loss: 2.5025689601898193
Validation loss: 2.0384491566688783

Epoch: 6| Step: 2
Training loss: 1.8753938674926758
Validation loss: 2.0322146633619904

Epoch: 6| Step: 3
Training loss: 2.7002041339874268
Validation loss: 2.0437778221663607

Epoch: 6| Step: 4
Training loss: 3.367313861846924
Validation loss: 2.035881418053822

Epoch: 6| Step: 5
Training loss: 2.11069655418396
Validation loss: 2.0394385117356495

Epoch: 6| Step: 6
Training loss: 1.970310926437378
Validation loss: 2.0557190282370454

Epoch: 6| Step: 7
Training loss: 1.9454810619354248
Validation loss: 2.065629459196521

Epoch: 6| Step: 8
Training loss: 2.3256313800811768
Validation loss: 2.073891797373372

Epoch: 6| Step: 9
Training loss: 2.029475688934326
Validation loss: 2.0453194084987847

Epoch: 6| Step: 10
Training loss: 2.5512099266052246
Validation loss: 2.035854803618564

Epoch: 6| Step: 11
Training loss: 2.202059745788574
Validation loss: 2.024119894991639

Epoch: 6| Step: 12
Training loss: 2.758260726928711
Validation loss: 2.0089232114053543

Epoch: 6| Step: 13
Training loss: 2.7184033393859863
Validation loss: 2.00574222687752

Epoch: 115| Step: 0
Training loss: 2.5952062606811523
Validation loss: 2.0169462875653337

Epoch: 6| Step: 1
Training loss: 2.576195001602173
Validation loss: 2.0211673654535764

Epoch: 6| Step: 2
Training loss: 2.0857083797454834
Validation loss: 2.0161018025490547

Epoch: 6| Step: 3
Training loss: 1.4104092121124268
Validation loss: 2.027347631351922

Epoch: 6| Step: 4
Training loss: 3.043905735015869
Validation loss: 2.0293004038513347

Epoch: 6| Step: 5
Training loss: 2.0488221645355225
Validation loss: 2.0381859143575034

Epoch: 6| Step: 6
Training loss: 1.564367413520813
Validation loss: 2.0343282632930304

Epoch: 6| Step: 7
Training loss: 2.066706657409668
Validation loss: 2.053901451890187

Epoch: 6| Step: 8
Training loss: 2.6794066429138184
Validation loss: 2.039844351430093

Epoch: 6| Step: 9
Training loss: 2.628119945526123
Validation loss: 2.0573897028482087

Epoch: 6| Step: 10
Training loss: 2.2841973304748535
Validation loss: 2.0818007581977436

Epoch: 6| Step: 11
Training loss: 2.230839252471924
Validation loss: 2.077312807882986

Epoch: 6| Step: 12
Training loss: 3.08648681640625
Validation loss: 2.0749070259832565

Epoch: 6| Step: 13
Training loss: 2.7778255939483643
Validation loss: 2.0611478615832586

Epoch: 116| Step: 0
Training loss: 1.865093469619751
Validation loss: 2.0454829892804547

Epoch: 6| Step: 1
Training loss: 2.1097164154052734
Validation loss: 2.0211387244603967

Epoch: 6| Step: 2
Training loss: 2.212797164916992
Validation loss: 2.01052797994306

Epoch: 6| Step: 3
Training loss: 2.460960865020752
Validation loss: 2.036861332513953

Epoch: 6| Step: 4
Training loss: 1.8242461681365967
Validation loss: 2.0373200703692693

Epoch: 6| Step: 5
Training loss: 2.66741943359375
Validation loss: 2.0460577485381917

Epoch: 6| Step: 6
Training loss: 2.9298436641693115
Validation loss: 2.0484886630888908

Epoch: 6| Step: 7
Training loss: 2.3160295486450195
Validation loss: 2.046603733493436

Epoch: 6| Step: 8
Training loss: 2.944479465484619
Validation loss: 2.0367152114068308

Epoch: 6| Step: 9
Training loss: 2.0223875045776367
Validation loss: 2.0164717243563746

Epoch: 6| Step: 10
Training loss: 2.037893772125244
Validation loss: 2.019663623584214

Epoch: 6| Step: 11
Training loss: 2.658560276031494
Validation loss: 2.036967482618106

Epoch: 6| Step: 12
Training loss: 3.175596237182617
Validation loss: 2.1234362791943293

Epoch: 6| Step: 13
Training loss: 2.2360999584198
Validation loss: 2.1503112854496127

Epoch: 117| Step: 0
Training loss: 1.7638704776763916
Validation loss: 2.1513757564688243

Epoch: 6| Step: 1
Training loss: 2.5263161659240723
Validation loss: 2.0955085715939923

Epoch: 6| Step: 2
Training loss: 2.448854684829712
Validation loss: 2.067639738000849

Epoch: 6| Step: 3
Training loss: 2.4158244132995605
Validation loss: 2.025853166016199

Epoch: 6| Step: 4
Training loss: 3.13527250289917
Validation loss: 2.0046451194311983

Epoch: 6| Step: 5
Training loss: 2.525834321975708
Validation loss: 1.9962859256293184

Epoch: 6| Step: 6
Training loss: 1.929263949394226
Validation loss: 1.9938347570357784

Epoch: 6| Step: 7
Training loss: 2.4521753787994385
Validation loss: 1.9984940944179412

Epoch: 6| Step: 8
Training loss: 2.036647319793701
Validation loss: 2.0054383918803227

Epoch: 6| Step: 9
Training loss: 2.2052161693573
Validation loss: 1.9987614590634581

Epoch: 6| Step: 10
Training loss: 1.8104469776153564
Validation loss: 1.9961458457413541

Epoch: 6| Step: 11
Training loss: 2.097224712371826
Validation loss: 2.0073762068184475

Epoch: 6| Step: 12
Training loss: 3.5068588256835938
Validation loss: 2.016586208856234

Epoch: 6| Step: 13
Training loss: 1.8426344394683838
Validation loss: 2.025294135975581

Epoch: 118| Step: 0
Training loss: 2.2663321495056152
Validation loss: 2.0274391828044767

Epoch: 6| Step: 1
Training loss: 2.021131992340088
Validation loss: 2.043941879785189

Epoch: 6| Step: 2
Training loss: 2.0997538566589355
Validation loss: 2.0567986721633584

Epoch: 6| Step: 3
Training loss: 2.463405132293701
Validation loss: 2.0499138742364864

Epoch: 6| Step: 4
Training loss: 3.0809974670410156
Validation loss: 2.041467211579764

Epoch: 6| Step: 5
Training loss: 1.7926688194274902
Validation loss: 2.039251027568694

Epoch: 6| Step: 6
Training loss: 2.5017340183258057
Validation loss: 2.019527622448501

Epoch: 6| Step: 7
Training loss: 2.228520154953003
Validation loss: 1.9966622347472816

Epoch: 6| Step: 8
Training loss: 2.4895572662353516
Validation loss: 1.9854036172231038

Epoch: 6| Step: 9
Training loss: 1.8381013870239258
Validation loss: 1.9868486235218663

Epoch: 6| Step: 10
Training loss: 1.9736056327819824
Validation loss: 1.9878190666116693

Epoch: 6| Step: 11
Training loss: 2.5661940574645996
Validation loss: 1.9811621353190432

Epoch: 6| Step: 12
Training loss: 2.730987071990967
Validation loss: 1.9856962209106774

Epoch: 6| Step: 13
Training loss: 2.812546968460083
Validation loss: 1.9909077446947816

Epoch: 119| Step: 0
Training loss: 2.4907732009887695
Validation loss: 1.9848677868484168

Epoch: 6| Step: 1
Training loss: 2.096733331680298
Validation loss: 1.9936743833685433

Epoch: 6| Step: 2
Training loss: 2.950946092605591
Validation loss: 1.999379155456379

Epoch: 6| Step: 3
Training loss: 1.819993495941162
Validation loss: 2.015729469637717

Epoch: 6| Step: 4
Training loss: 1.6856486797332764
Validation loss: 2.0332480874112857

Epoch: 6| Step: 5
Training loss: 2.1370882987976074
Validation loss: 2.0706361416847474

Epoch: 6| Step: 6
Training loss: 2.956533908843994
Validation loss: 2.0893183895336684

Epoch: 6| Step: 7
Training loss: 1.8753926753997803
Validation loss: 2.090297629756312

Epoch: 6| Step: 8
Training loss: 2.7184581756591797
Validation loss: 2.0445799596848024

Epoch: 6| Step: 9
Training loss: 1.6420878171920776
Validation loss: 2.0133917639332433

Epoch: 6| Step: 10
Training loss: 2.920936107635498
Validation loss: 1.9921300731679445

Epoch: 6| Step: 11
Training loss: 2.9707674980163574
Validation loss: 1.9822241977978778

Epoch: 6| Step: 12
Training loss: 2.4496283531188965
Validation loss: 1.9820302519747006

Epoch: 6| Step: 13
Training loss: 1.7143938541412354
Validation loss: 1.9890578664759153

Epoch: 120| Step: 0
Training loss: 2.721519708633423
Validation loss: 1.9960211682063278

Epoch: 6| Step: 1
Training loss: 1.9254438877105713
Validation loss: 1.9929765219329505

Epoch: 6| Step: 2
Training loss: 2.5975704193115234
Validation loss: 1.9967692936620405

Epoch: 6| Step: 3
Training loss: 2.253570556640625
Validation loss: 1.987937319663263

Epoch: 6| Step: 4
Training loss: 2.913194179534912
Validation loss: 1.9847995260710358

Epoch: 6| Step: 5
Training loss: 1.970551609992981
Validation loss: 1.9955951398418796

Epoch: 6| Step: 6
Training loss: 2.4845070838928223
Validation loss: 1.9990251769301712

Epoch: 6| Step: 7
Training loss: 2.4984073638916016
Validation loss: 2.030839543188772

Epoch: 6| Step: 8
Training loss: 2.569958209991455
Validation loss: 2.0645328490964827

Epoch: 6| Step: 9
Training loss: 1.4965747594833374
Validation loss: 2.1235461670865297

Epoch: 6| Step: 10
Training loss: 2.430408000946045
Validation loss: 2.1250176993749474

Epoch: 6| Step: 11
Training loss: 2.181741237640381
Validation loss: 2.105858241358111

Epoch: 6| Step: 12
Training loss: 2.6122946739196777
Validation loss: 2.043271997923492

Epoch: 6| Step: 13
Training loss: 2.8008337020874023
Validation loss: 2.0094489628268826

Epoch: 121| Step: 0
Training loss: 2.509310722351074
Validation loss: 1.9895396014695526

Epoch: 6| Step: 1
Training loss: 1.9750066995620728
Validation loss: 2.00070555620296

Epoch: 6| Step: 2
Training loss: 1.9952318668365479
Validation loss: 2.010097752335251

Epoch: 6| Step: 3
Training loss: 2.34102725982666
Validation loss: 2.0172524144572597

Epoch: 6| Step: 4
Training loss: 1.8282568454742432
Validation loss: 2.0253215835940455

Epoch: 6| Step: 5
Training loss: 2.9255895614624023
Validation loss: 2.0169008060168196

Epoch: 6| Step: 6
Training loss: 2.5864109992980957
Validation loss: 2.0170083020323064

Epoch: 6| Step: 7
Training loss: 1.878163456916809
Validation loss: 2.0121610421006397

Epoch: 6| Step: 8
Training loss: 2.20866322517395
Validation loss: 2.00898717552103

Epoch: 6| Step: 9
Training loss: 2.593596935272217
Validation loss: 2.0021931163726316

Epoch: 6| Step: 10
Training loss: 3.4736380577087402
Validation loss: 1.9946542504013225

Epoch: 6| Step: 11
Training loss: 1.510494589805603
Validation loss: 1.9901053392758934

Epoch: 6| Step: 12
Training loss: 2.943155288696289
Validation loss: 2.013638759172091

Epoch: 6| Step: 13
Training loss: 1.520300269126892
Validation loss: 2.055023903487831

Epoch: 122| Step: 0
Training loss: 2.002920150756836
Validation loss: 2.0632633419447046

Epoch: 6| Step: 1
Training loss: 1.7512969970703125
Validation loss: 2.075547077322519

Epoch: 6| Step: 2
Training loss: 2.3704962730407715
Validation loss: 2.0697814879878873

Epoch: 6| Step: 3
Training loss: 2.310743570327759
Validation loss: 2.0420303626727034

Epoch: 6| Step: 4
Training loss: 2.695816993713379
Validation loss: 2.013664278932797

Epoch: 6| Step: 5
Training loss: 2.29583740234375
Validation loss: 1.989366477535617

Epoch: 6| Step: 6
Training loss: 2.4663877487182617
Validation loss: 1.9816675339975665

Epoch: 6| Step: 7
Training loss: 2.2280399799346924
Validation loss: 2.002648098494417

Epoch: 6| Step: 8
Training loss: 2.717620611190796
Validation loss: 2.0545692161847184

Epoch: 6| Step: 9
Training loss: 2.2078857421875
Validation loss: 2.1025432104705484

Epoch: 6| Step: 10
Training loss: 3.0919089317321777
Validation loss: 2.147394202088797

Epoch: 6| Step: 11
Training loss: 2.207240104675293
Validation loss: 2.1259164656362226

Epoch: 6| Step: 12
Training loss: 2.994965076446533
Validation loss: 2.1357872383568877

Epoch: 6| Step: 13
Training loss: 2.544703483581543
Validation loss: 2.098363689197007

Epoch: 123| Step: 0
Training loss: 1.7848525047302246
Validation loss: 2.056745634284071

Epoch: 6| Step: 1
Training loss: 2.5198774337768555
Validation loss: 2.0347053825214343

Epoch: 6| Step: 2
Training loss: 2.133432388305664
Validation loss: 2.012089107626228

Epoch: 6| Step: 3
Training loss: 2.5318315029144287
Validation loss: 1.9891475951799782

Epoch: 6| Step: 4
Training loss: 2.2650294303894043
Validation loss: 1.9826080901648409

Epoch: 6| Step: 5
Training loss: 3.120785713195801
Validation loss: 1.9820408205832205

Epoch: 6| Step: 6
Training loss: 2.670532703399658
Validation loss: 2.0068442898411907

Epoch: 6| Step: 7
Training loss: 2.2819664478302
Validation loss: 2.0352945584122852

Epoch: 6| Step: 8
Training loss: 2.7754759788513184
Validation loss: 2.040626710461032

Epoch: 6| Step: 9
Training loss: 1.9009637832641602
Validation loss: 2.0662508164682696

Epoch: 6| Step: 10
Training loss: 2.5090181827545166
Validation loss: 2.0691477765319166

Epoch: 6| Step: 11
Training loss: 2.3186488151550293
Validation loss: 2.065167720599841

Epoch: 6| Step: 12
Training loss: 2.4475655555725098
Validation loss: 2.018201497293288

Epoch: 6| Step: 13
Training loss: 2.1155598163604736
Validation loss: 1.9752908034991192

Epoch: 124| Step: 0
Training loss: 2.656705856323242
Validation loss: 1.9689055155682307

Epoch: 6| Step: 1
Training loss: 2.6173341274261475
Validation loss: 1.967342665118556

Epoch: 6| Step: 2
Training loss: 2.045152187347412
Validation loss: 1.9732250577660018

Epoch: 6| Step: 3
Training loss: 1.8212251663208008
Validation loss: 1.973607140202676

Epoch: 6| Step: 4
Training loss: 3.1768479347229004
Validation loss: 1.9757112200542162

Epoch: 6| Step: 5
Training loss: 2.5556507110595703
Validation loss: 1.9761870458561888

Epoch: 6| Step: 6
Training loss: 2.1495518684387207
Validation loss: 1.979489044476581

Epoch: 6| Step: 7
Training loss: 2.551007032394409
Validation loss: 1.9765210484945646

Epoch: 6| Step: 8
Training loss: 1.2451043128967285
Validation loss: 1.975247711263677

Epoch: 6| Step: 9
Training loss: 2.0590479373931885
Validation loss: 1.987201008745419

Epoch: 6| Step: 10
Training loss: 1.9850854873657227
Validation loss: 1.98114707521213

Epoch: 6| Step: 11
Training loss: 2.652592658996582
Validation loss: 1.984025429653865

Epoch: 6| Step: 12
Training loss: 2.372964859008789
Validation loss: 1.993657463340349

Epoch: 6| Step: 13
Training loss: 2.8479762077331543
Validation loss: 2.0118286404558408

Epoch: 125| Step: 0
Training loss: 2.460498332977295
Validation loss: 2.0172268024054905

Epoch: 6| Step: 1
Training loss: 2.7553794384002686
Validation loss: 2.014343030991093

Epoch: 6| Step: 2
Training loss: 2.5938897132873535
Validation loss: 2.0183559284415296

Epoch: 6| Step: 3
Training loss: 2.753774642944336
Validation loss: 2.024526442250898

Epoch: 6| Step: 4
Training loss: 1.569199562072754
Validation loss: 2.0200187903578564

Epoch: 6| Step: 5
Training loss: 2.3458642959594727
Validation loss: 2.0131581201348254

Epoch: 6| Step: 6
Training loss: 1.7916264533996582
Validation loss: 2.0249825626291256

Epoch: 6| Step: 7
Training loss: 2.5038046836853027
Validation loss: 2.0339651876880276

Epoch: 6| Step: 8
Training loss: 1.9179553985595703
Validation loss: 2.0247380041307017

Epoch: 6| Step: 9
Training loss: 2.226529598236084
Validation loss: 2.016340180109906

Epoch: 6| Step: 10
Training loss: 2.7208964824676514
Validation loss: 2.0028050689287085

Epoch: 6| Step: 11
Training loss: 2.0090785026550293
Validation loss: 1.9969256539498605

Epoch: 6| Step: 12
Training loss: 2.7104110717773438
Validation loss: 1.9830015487568353

Epoch: 6| Step: 13
Training loss: 1.8164681196212769
Validation loss: 1.99373617095332

Epoch: 126| Step: 0
Training loss: 2.8739216327667236
Validation loss: 1.9990656465612433

Epoch: 6| Step: 1
Training loss: 2.226341962814331
Validation loss: 1.9986923740756126

Epoch: 6| Step: 2
Training loss: 2.1528520584106445
Validation loss: 2.0085870065996723

Epoch: 6| Step: 3
Training loss: 2.744213342666626
Validation loss: 2.0090901197925692

Epoch: 6| Step: 4
Training loss: 2.7019388675689697
Validation loss: 2.027920151269564

Epoch: 6| Step: 5
Training loss: 1.6912109851837158
Validation loss: 2.0178045047226774

Epoch: 6| Step: 6
Training loss: 2.0242037773132324
Validation loss: 2.010333712382983

Epoch: 6| Step: 7
Training loss: 2.2683820724487305
Validation loss: 1.9870567039776874

Epoch: 6| Step: 8
Training loss: 2.209458112716675
Validation loss: 1.9822360366903327

Epoch: 6| Step: 9
Training loss: 1.7236459255218506
Validation loss: 1.988264661963268

Epoch: 6| Step: 10
Training loss: 2.2610318660736084
Validation loss: 1.9693836217285485

Epoch: 6| Step: 11
Training loss: 3.1176319122314453
Validation loss: 1.9789021412531536

Epoch: 6| Step: 12
Training loss: 2.5694167613983154
Validation loss: 1.9786714699960524

Epoch: 6| Step: 13
Training loss: 1.0426218509674072
Validation loss: 1.9679053342470558

Epoch: 127| Step: 0
Training loss: 2.0927798748016357
Validation loss: 1.9787108346980105

Epoch: 6| Step: 1
Training loss: 1.9775347709655762
Validation loss: 1.9767628382611018

Epoch: 6| Step: 2
Training loss: 1.962765097618103
Validation loss: 1.9787099361419678

Epoch: 6| Step: 3
Training loss: 2.2664542198181152
Validation loss: 1.9866163833166963

Epoch: 6| Step: 4
Training loss: 2.2501907348632812
Validation loss: 1.9813699863290275

Epoch: 6| Step: 5
Training loss: 2.149513006210327
Validation loss: 1.9941408095821258

Epoch: 6| Step: 6
Training loss: 1.668384313583374
Validation loss: 1.9972923622336438

Epoch: 6| Step: 7
Training loss: 2.9488847255706787
Validation loss: 2.0025054203566683

Epoch: 6| Step: 8
Training loss: 2.548229694366455
Validation loss: 2.018276109490343

Epoch: 6| Step: 9
Training loss: 2.7103021144866943
Validation loss: 2.042199230963184

Epoch: 6| Step: 10
Training loss: 1.980574369430542
Validation loss: 2.0693228449872745

Epoch: 6| Step: 11
Training loss: 3.0120961666107178
Validation loss: 2.06581013817941

Epoch: 6| Step: 12
Training loss: 2.6097793579101562
Validation loss: 2.058531274077713

Epoch: 6| Step: 13
Training loss: 2.294448137283325
Validation loss: 2.055680578754794

Epoch: 128| Step: 0
Training loss: 2.388519763946533
Validation loss: 2.074227535596458

Epoch: 6| Step: 1
Training loss: 2.3436760902404785
Validation loss: 2.1038148428804133

Epoch: 6| Step: 2
Training loss: 2.26564359664917
Validation loss: 2.072856277547857

Epoch: 6| Step: 3
Training loss: 2.4733166694641113
Validation loss: 2.0528562658576557

Epoch: 6| Step: 4
Training loss: 1.8044084310531616
Validation loss: 2.0285581581054197

Epoch: 6| Step: 5
Training loss: 1.960976243019104
Validation loss: 2.010014651924051

Epoch: 6| Step: 6
Training loss: 1.9678678512573242
Validation loss: 1.9923832493443643

Epoch: 6| Step: 7
Training loss: 2.446960926055908
Validation loss: 1.984563894169305

Epoch: 6| Step: 8
Training loss: 2.7117223739624023
Validation loss: 1.9943987387482838

Epoch: 6| Step: 9
Training loss: 2.493654727935791
Validation loss: 1.9843890846416514

Epoch: 6| Step: 10
Training loss: 2.222979784011841
Validation loss: 1.9663621789665633

Epoch: 6| Step: 11
Training loss: 2.467240810394287
Validation loss: 1.9656655429511942

Epoch: 6| Step: 12
Training loss: 2.3117172718048096
Validation loss: 1.963966413210797

Epoch: 6| Step: 13
Training loss: 2.483661651611328
Validation loss: 1.9625534819018455

Epoch: 129| Step: 0
Training loss: 2.831773042678833
Validation loss: 1.9660756613618584

Epoch: 6| Step: 1
Training loss: 2.126629590988159
Validation loss: 1.9623833728092972

Epoch: 6| Step: 2
Training loss: 2.1090612411499023
Validation loss: 1.9678758767343336

Epoch: 6| Step: 3
Training loss: 2.1206727027893066
Validation loss: 1.9634754375744892

Epoch: 6| Step: 4
Training loss: 2.6756701469421387
Validation loss: 1.964042559746773

Epoch: 6| Step: 5
Training loss: 2.698478937149048
Validation loss: 1.9721999642669514

Epoch: 6| Step: 6
Training loss: 2.0659961700439453
Validation loss: 1.9797481875265799

Epoch: 6| Step: 7
Training loss: 2.2125706672668457
Validation loss: 1.9830717553374588

Epoch: 6| Step: 8
Training loss: 2.6882829666137695
Validation loss: 1.992929881618869

Epoch: 6| Step: 9
Training loss: 2.267594337463379
Validation loss: 1.978166687873102

Epoch: 6| Step: 10
Training loss: 2.0744776725769043
Validation loss: 1.9929554103523173

Epoch: 6| Step: 11
Training loss: 1.91324782371521
Validation loss: 1.9817632500843336

Epoch: 6| Step: 12
Training loss: 1.7842744588851929
Validation loss: 1.9859119589610765

Epoch: 6| Step: 13
Training loss: 2.164543628692627
Validation loss: 1.9768539090310373

Epoch: 130| Step: 0
Training loss: 2.624403953552246
Validation loss: 1.9553963574030067

Epoch: 6| Step: 1
Training loss: 2.3914966583251953
Validation loss: 1.9528927931221582

Epoch: 6| Step: 2
Training loss: 2.13832950592041
Validation loss: 1.9521427962087816

Epoch: 6| Step: 3
Training loss: 1.8549411296844482
Validation loss: 1.9489522672468615

Epoch: 6| Step: 4
Training loss: 2.300358295440674
Validation loss: 1.950641284706772

Epoch: 6| Step: 5
Training loss: 1.8454935550689697
Validation loss: 1.9580986038331063

Epoch: 6| Step: 6
Training loss: 3.3059542179107666
Validation loss: 1.9546325591302687

Epoch: 6| Step: 7
Training loss: 2.5432932376861572
Validation loss: 1.9583420830388223

Epoch: 6| Step: 8
Training loss: 2.4152135848999023
Validation loss: 1.9698837918619956

Epoch: 6| Step: 9
Training loss: 1.8272297382354736
Validation loss: 1.9596017996470134

Epoch: 6| Step: 10
Training loss: 1.9178727865219116
Validation loss: 1.9675313913693993

Epoch: 6| Step: 11
Training loss: 2.493708610534668
Validation loss: 1.967325120843867

Epoch: 6| Step: 12
Training loss: 2.0157670974731445
Validation loss: 1.9845279237275482

Epoch: 6| Step: 13
Training loss: 2.072272777557373
Validation loss: 2.009235010352186

Epoch: 131| Step: 0
Training loss: 1.8914459943771362
Validation loss: 2.0133911409685687

Epoch: 6| Step: 1
Training loss: 1.7739577293395996
Validation loss: 2.0096008687890987

Epoch: 6| Step: 2
Training loss: 2.8615500926971436
Validation loss: 1.9725703090749762

Epoch: 6| Step: 3
Training loss: 2.082486152648926
Validation loss: 1.9710631575635684

Epoch: 6| Step: 4
Training loss: 1.68807053565979
Validation loss: 1.9635555667261924

Epoch: 6| Step: 5
Training loss: 2.3904852867126465
Validation loss: 1.9788415316612489

Epoch: 6| Step: 6
Training loss: 2.847625255584717
Validation loss: 1.984637137382261

Epoch: 6| Step: 7
Training loss: 1.9004135131835938
Validation loss: 1.9832579371749715

Epoch: 6| Step: 8
Training loss: 2.2577853202819824
Validation loss: 1.9905619570004043

Epoch: 6| Step: 9
Training loss: 2.3091588020324707
Validation loss: 2.0057377430700485

Epoch: 6| Step: 10
Training loss: 2.909200668334961
Validation loss: 2.020063149031772

Epoch: 6| Step: 11
Training loss: 2.1925573348999023
Validation loss: 1.996054728825887

Epoch: 6| Step: 12
Training loss: 2.4686191082000732
Validation loss: 1.9833629515863234

Epoch: 6| Step: 13
Training loss: 2.6483209133148193
Validation loss: 1.97189663815242

Epoch: 132| Step: 0
Training loss: 1.894345998764038
Validation loss: 1.9657463591585878

Epoch: 6| Step: 1
Training loss: 2.418224811553955
Validation loss: 1.9639536155167447

Epoch: 6| Step: 2
Training loss: 2.7306771278381348
Validation loss: 1.9529082954570811

Epoch: 6| Step: 3
Training loss: 2.3260116577148438
Validation loss: 1.9580588763759983

Epoch: 6| Step: 4
Training loss: 2.216810703277588
Validation loss: 1.9582051000287455

Epoch: 6| Step: 5
Training loss: 1.4013646841049194
Validation loss: 1.9593972980335195

Epoch: 6| Step: 6
Training loss: 2.435598373413086
Validation loss: 1.9682713426569456

Epoch: 6| Step: 7
Training loss: 2.8120319843292236
Validation loss: 1.9672333296909128

Epoch: 6| Step: 8
Training loss: 1.8097375631332397
Validation loss: 1.9723443728621288

Epoch: 6| Step: 9
Training loss: 2.411336660385132
Validation loss: 1.972801931442753

Epoch: 6| Step: 10
Training loss: 1.953618049621582
Validation loss: 1.9728882543502315

Epoch: 6| Step: 11
Training loss: 2.512795925140381
Validation loss: 1.964844685728832

Epoch: 6| Step: 12
Training loss: 2.5534133911132812
Validation loss: 1.9619777587152296

Epoch: 6| Step: 13
Training loss: 2.46616268157959
Validation loss: 1.9557631656687746

Epoch: 133| Step: 0
Training loss: 2.190833568572998
Validation loss: 1.95788392712993

Epoch: 6| Step: 1
Training loss: 2.064321756362915
Validation loss: 1.9542227970656527

Epoch: 6| Step: 2
Training loss: 2.0310850143432617
Validation loss: 1.957859226452407

Epoch: 6| Step: 3
Training loss: 1.5996603965759277
Validation loss: 1.9645104831264866

Epoch: 6| Step: 4
Training loss: 2.6323440074920654
Validation loss: 1.95773442458081

Epoch: 6| Step: 5
Training loss: 2.250938892364502
Validation loss: 1.9598269975313576

Epoch: 6| Step: 6
Training loss: 1.7601683139801025
Validation loss: 1.9521922501184608

Epoch: 6| Step: 7
Training loss: 2.42889666557312
Validation loss: 1.9474869787052114

Epoch: 6| Step: 8
Training loss: 2.835792064666748
Validation loss: 1.953987915028808

Epoch: 6| Step: 9
Training loss: 1.9461536407470703
Validation loss: 1.9561427088193997

Epoch: 6| Step: 10
Training loss: 2.5623490810394287
Validation loss: 1.9601264435757872

Epoch: 6| Step: 11
Training loss: 1.882962942123413
Validation loss: 1.961528148702396

Epoch: 6| Step: 12
Training loss: 3.0174694061279297
Validation loss: 1.9824331473278742

Epoch: 6| Step: 13
Training loss: 2.6764438152313232
Validation loss: 1.9774606304783975

Epoch: 134| Step: 0
Training loss: 2.4492239952087402
Validation loss: 1.984400228787494

Epoch: 6| Step: 1
Training loss: 2.0572142601013184
Validation loss: 1.9850724973986227

Epoch: 6| Step: 2
Training loss: 2.203718662261963
Validation loss: 1.9760694170510897

Epoch: 6| Step: 3
Training loss: 2.4507009983062744
Validation loss: 1.995653074274781

Epoch: 6| Step: 4
Training loss: 2.2100048065185547
Validation loss: 1.9795068643426383

Epoch: 6| Step: 5
Training loss: 2.06740665435791
Validation loss: 1.969657051947809

Epoch: 6| Step: 6
Training loss: 2.69031023979187
Validation loss: 1.9719426119199364

Epoch: 6| Step: 7
Training loss: 2.546797275543213
Validation loss: 1.9640091029546594

Epoch: 6| Step: 8
Training loss: 1.998953938484192
Validation loss: 1.9786178527339813

Epoch: 6| Step: 9
Training loss: 2.1054043769836426
Validation loss: 1.966617630374047

Epoch: 6| Step: 10
Training loss: 1.386022686958313
Validation loss: 1.93650068518936

Epoch: 6| Step: 11
Training loss: 2.386174201965332
Validation loss: 1.9549826498954528

Epoch: 6| Step: 12
Training loss: 2.838374614715576
Validation loss: 1.9507332924873597

Epoch: 6| Step: 13
Training loss: 2.721735715866089
Validation loss: 1.9598764142682474

Epoch: 135| Step: 0
Training loss: 2.672070026397705
Validation loss: 1.985966641415832

Epoch: 6| Step: 1
Training loss: 3.423198699951172
Validation loss: 1.9948662019545031

Epoch: 6| Step: 2
Training loss: 2.6062703132629395
Validation loss: 2.000568743674986

Epoch: 6| Step: 3
Training loss: 2.268810987472534
Validation loss: 1.9968021992714173

Epoch: 6| Step: 4
Training loss: 2.4957778453826904
Validation loss: 1.989341128257013

Epoch: 6| Step: 5
Training loss: 1.9977898597717285
Validation loss: 1.9815890327576668

Epoch: 6| Step: 6
Training loss: 1.8514631986618042
Validation loss: 1.9716961922184113

Epoch: 6| Step: 7
Training loss: 1.8230139017105103
Validation loss: 1.9773542752829931

Epoch: 6| Step: 8
Training loss: 2.029236316680908
Validation loss: 1.9847354965825235

Epoch: 6| Step: 9
Training loss: 2.547260284423828
Validation loss: 1.9645344685482722

Epoch: 6| Step: 10
Training loss: 1.8199031352996826
Validation loss: 1.968148217406324

Epoch: 6| Step: 11
Training loss: 1.3819688558578491
Validation loss: 1.9675982741899387

Epoch: 6| Step: 12
Training loss: 2.3357861042022705
Validation loss: 1.96096077657515

Epoch: 6| Step: 13
Training loss: 2.8494298458099365
Validation loss: 1.9650890250359812

Epoch: 136| Step: 0
Training loss: 2.6668810844421387
Validation loss: 1.9639929661186792

Epoch: 6| Step: 1
Training loss: 2.2036309242248535
Validation loss: 1.9749916420188

Epoch: 6| Step: 2
Training loss: 2.613853931427002
Validation loss: 1.9807134238622521

Epoch: 6| Step: 3
Training loss: 2.3044915199279785
Validation loss: 1.9819209011652137

Epoch: 6| Step: 4
Training loss: 1.9544272422790527
Validation loss: 1.9821791597591933

Epoch: 6| Step: 5
Training loss: 1.1411468982696533
Validation loss: 1.9577885366255237

Epoch: 6| Step: 6
Training loss: 2.1055245399475098
Validation loss: 1.9642762650725663

Epoch: 6| Step: 7
Training loss: 2.7724523544311523
Validation loss: 1.9518255136346305

Epoch: 6| Step: 8
Training loss: 2.2809135913848877
Validation loss: 1.952260910823781

Epoch: 6| Step: 9
Training loss: 2.831089496612549
Validation loss: 1.9496812166706208

Epoch: 6| Step: 10
Training loss: 1.7451485395431519
Validation loss: 1.9428781027434974

Epoch: 6| Step: 11
Training loss: 2.2770071029663086
Validation loss: 1.9574477070121354

Epoch: 6| Step: 12
Training loss: 2.3420753479003906
Validation loss: 1.9566087466414257

Epoch: 6| Step: 13
Training loss: 2.2126028537750244
Validation loss: 2.0082916418711343

Epoch: 137| Step: 0
Training loss: 2.975287675857544
Validation loss: 2.0654629020280737

Epoch: 6| Step: 1
Training loss: 2.0315489768981934
Validation loss: 2.1046008589447185

Epoch: 6| Step: 2
Training loss: 1.9005825519561768
Validation loss: 2.167509195625141

Epoch: 6| Step: 3
Training loss: 2.0295023918151855
Validation loss: 2.1510191912292154

Epoch: 6| Step: 4
Training loss: 2.335937261581421
Validation loss: 2.1614041238702755

Epoch: 6| Step: 5
Training loss: 2.2063655853271484
Validation loss: 2.1163896206886537

Epoch: 6| Step: 6
Training loss: 2.082427501678467
Validation loss: 2.055995023378762

Epoch: 6| Step: 7
Training loss: 2.6725058555603027
Validation loss: 1.9944795972557479

Epoch: 6| Step: 8
Training loss: 2.585611343383789
Validation loss: 1.9710705305940361

Epoch: 6| Step: 9
Training loss: 2.0466971397399902
Validation loss: 1.9585407433971282

Epoch: 6| Step: 10
Training loss: 2.328641414642334
Validation loss: 1.945289695134727

Epoch: 6| Step: 11
Training loss: 2.4243338108062744
Validation loss: 1.953885716776694

Epoch: 6| Step: 12
Training loss: 2.2120914459228516
Validation loss: 1.972462478504386

Epoch: 6| Step: 13
Training loss: 2.005037307739258
Validation loss: 1.9621688294154342

Epoch: 138| Step: 0
Training loss: 2.2168986797332764
Validation loss: 1.9542047080173288

Epoch: 6| Step: 1
Training loss: 2.466942310333252
Validation loss: 1.9459625521013815

Epoch: 6| Step: 2
Training loss: 1.9077816009521484
Validation loss: 1.9407933911969584

Epoch: 6| Step: 3
Training loss: 2.102142333984375
Validation loss: 1.9215911985725485

Epoch: 6| Step: 4
Training loss: 2.5947132110595703
Validation loss: 1.9240797065919446

Epoch: 6| Step: 5
Training loss: 2.651624917984009
Validation loss: 1.9314843313668364

Epoch: 6| Step: 6
Training loss: 2.697375535964966
Validation loss: 1.9691728981592322

Epoch: 6| Step: 7
Training loss: 1.790337324142456
Validation loss: 1.9761631386254424

Epoch: 6| Step: 8
Training loss: 2.1636667251586914
Validation loss: 1.9803081084323186

Epoch: 6| Step: 9
Training loss: 2.0238633155822754
Validation loss: 1.9833218410450926

Epoch: 6| Step: 10
Training loss: 2.414205551147461
Validation loss: 1.985767404238383

Epoch: 6| Step: 11
Training loss: 2.3109493255615234
Validation loss: 1.9750217891508532

Epoch: 6| Step: 12
Training loss: 2.545442581176758
Validation loss: 1.971954268793906

Epoch: 6| Step: 13
Training loss: 1.3574774265289307
Validation loss: 1.952530994210192

Epoch: 139| Step: 0
Training loss: 2.670496940612793
Validation loss: 1.939469861727889

Epoch: 6| Step: 1
Training loss: 2.530457019805908
Validation loss: 1.9255022284805134

Epoch: 6| Step: 2
Training loss: 2.505894660949707
Validation loss: 1.9444720437449794

Epoch: 6| Step: 3
Training loss: 2.372241497039795
Validation loss: 1.9525819516951037

Epoch: 6| Step: 4
Training loss: 1.6614093780517578
Validation loss: 1.9561068204141432

Epoch: 6| Step: 5
Training loss: 1.9053096771240234
Validation loss: 1.9605312885776642

Epoch: 6| Step: 6
Training loss: 2.3583385944366455
Validation loss: 1.9729950197281376

Epoch: 6| Step: 7
Training loss: 2.550037384033203
Validation loss: 1.939461786259887

Epoch: 6| Step: 8
Training loss: 2.4386582374572754
Validation loss: 1.931409130814255

Epoch: 6| Step: 9
Training loss: 2.2641124725341797
Validation loss: 1.9369981891365462

Epoch: 6| Step: 10
Training loss: 1.9156982898712158
Validation loss: 1.935904582341512

Epoch: 6| Step: 11
Training loss: 2.583148717880249
Validation loss: 1.9456333165527673

Epoch: 6| Step: 12
Training loss: 1.8212230205535889
Validation loss: 1.9863519309669413

Epoch: 6| Step: 13
Training loss: 1.1505650281906128
Validation loss: 2.010469146954116

Epoch: 140| Step: 0
Training loss: 2.280179023742676
Validation loss: 2.072798334142213

Epoch: 6| Step: 1
Training loss: 2.4263291358947754
Validation loss: 2.081517325934543

Epoch: 6| Step: 2
Training loss: 2.25803279876709
Validation loss: 2.0921651586409538

Epoch: 6| Step: 3
Training loss: 2.6931257247924805
Validation loss: 2.05558011352375

Epoch: 6| Step: 4
Training loss: 2.2524936199188232
Validation loss: 2.032808365360383

Epoch: 6| Step: 5
Training loss: 2.5665745735168457
Validation loss: 2.001646949398902

Epoch: 6| Step: 6
Training loss: 1.8705633878707886
Validation loss: 1.9833440370457147

Epoch: 6| Step: 7
Training loss: 2.2841625213623047
Validation loss: 1.9632089330304054

Epoch: 6| Step: 8
Training loss: 1.9477423429489136
Validation loss: 1.949172931332742

Epoch: 6| Step: 9
Training loss: 1.682281494140625
Validation loss: 1.9343962784736388

Epoch: 6| Step: 10
Training loss: 2.25315260887146
Validation loss: 1.9401807285124255

Epoch: 6| Step: 11
Training loss: 1.7843928337097168
Validation loss: 1.9428528688287223

Epoch: 6| Step: 12
Training loss: 3.151459217071533
Validation loss: 1.945324073555649

Epoch: 6| Step: 13
Training loss: 1.719358205795288
Validation loss: 1.9432831707821097

Epoch: 141| Step: 0
Training loss: 2.793088674545288
Validation loss: 1.935855746269226

Epoch: 6| Step: 1
Training loss: 1.9524211883544922
Validation loss: 1.9325162467136179

Epoch: 6| Step: 2
Training loss: 1.9344773292541504
Validation loss: 1.949313199648293

Epoch: 6| Step: 3
Training loss: 2.3585708141326904
Validation loss: 1.957575423743135

Epoch: 6| Step: 4
Training loss: 2.597158432006836
Validation loss: 1.98358235051555

Epoch: 6| Step: 5
Training loss: 2.4426944255828857
Validation loss: 2.0100771534827446

Epoch: 6| Step: 6
Training loss: 2.3148956298828125
Validation loss: 2.0110885327862156

Epoch: 6| Step: 7
Training loss: 2.3851828575134277
Validation loss: 1.9952225915847286

Epoch: 6| Step: 8
Training loss: 2.4423561096191406
Validation loss: 1.9861244796424784

Epoch: 6| Step: 9
Training loss: 1.518219232559204
Validation loss: 1.968256240249962

Epoch: 6| Step: 10
Training loss: 2.358290195465088
Validation loss: 1.9546520235717937

Epoch: 6| Step: 11
Training loss: 2.0509114265441895
Validation loss: 1.9432820427802302

Epoch: 6| Step: 12
Training loss: 2.046884059906006
Validation loss: 1.9470506919327604

Epoch: 6| Step: 13
Training loss: 2.295814037322998
Validation loss: 1.9383312809851863

Epoch: 142| Step: 0
Training loss: 2.509094715118408
Validation loss: 1.9379290637149607

Epoch: 6| Step: 1
Training loss: 2.953972339630127
Validation loss: 1.9390091665329472

Epoch: 6| Step: 2
Training loss: 2.5468761920928955
Validation loss: 1.9469728726212696

Epoch: 6| Step: 3
Training loss: 2.369166612625122
Validation loss: 1.9416402821899743

Epoch: 6| Step: 4
Training loss: 2.022714138031006
Validation loss: 1.946532408396403

Epoch: 6| Step: 5
Training loss: 1.5560892820358276
Validation loss: 1.9503236124592442

Epoch: 6| Step: 6
Training loss: 2.4894537925720215
Validation loss: 1.9629882740718063

Epoch: 6| Step: 7
Training loss: 1.3856216669082642
Validation loss: 1.9591301000246437

Epoch: 6| Step: 8
Training loss: 2.0232677459716797
Validation loss: 1.952439328675629

Epoch: 6| Step: 9
Training loss: 2.0635499954223633
Validation loss: 1.9583693717115669

Epoch: 6| Step: 10
Training loss: 2.2662158012390137
Validation loss: 1.9704387085412138

Epoch: 6| Step: 11
Training loss: 2.3072304725646973
Validation loss: 1.9719570106075657

Epoch: 6| Step: 12
Training loss: 2.4027392864227295
Validation loss: 1.9961430129184519

Epoch: 6| Step: 13
Training loss: 2.13462233543396
Validation loss: 2.007090735179122

Epoch: 143| Step: 0
Training loss: 2.024024486541748
Validation loss: 2.016420243888773

Epoch: 6| Step: 1
Training loss: 2.443356990814209
Validation loss: 2.019232947339294

Epoch: 6| Step: 2
Training loss: 2.104306221008301
Validation loss: 1.9669852666957404

Epoch: 6| Step: 3
Training loss: 2.2080328464508057
Validation loss: 1.9442611637935843

Epoch: 6| Step: 4
Training loss: 1.7610245943069458
Validation loss: 1.942475898291475

Epoch: 6| Step: 5
Training loss: 2.039170265197754
Validation loss: 1.9523656483619445

Epoch: 6| Step: 6
Training loss: 1.8198375701904297
Validation loss: 1.956188432631954

Epoch: 6| Step: 7
Training loss: 2.0753464698791504
Validation loss: 1.9553003798248947

Epoch: 6| Step: 8
Training loss: 2.625433921813965
Validation loss: 1.9660913598152898

Epoch: 6| Step: 9
Training loss: 2.231717109680176
Validation loss: 1.9504261068118516

Epoch: 6| Step: 10
Training loss: 2.9750020503997803
Validation loss: 1.9403749563360726

Epoch: 6| Step: 11
Training loss: 2.3856539726257324
Validation loss: 1.9308769318365282

Epoch: 6| Step: 12
Training loss: 2.252922773361206
Validation loss: 1.9311692214781238

Epoch: 6| Step: 13
Training loss: 2.4120426177978516
Validation loss: 1.9275577337511125

Epoch: 144| Step: 0
Training loss: 2.581481456756592
Validation loss: 1.929860007378363

Epoch: 6| Step: 1
Training loss: 2.0144662857055664
Validation loss: 1.9339867727730864

Epoch: 6| Step: 2
Training loss: 1.7002613544464111
Validation loss: 1.9479163513388684

Epoch: 6| Step: 3
Training loss: 2.3213202953338623
Validation loss: 1.943759128611575

Epoch: 6| Step: 4
Training loss: 1.7722389698028564
Validation loss: 1.9652779204871065

Epoch: 6| Step: 5
Training loss: 2.0467779636383057
Validation loss: 1.9767036707170549

Epoch: 6| Step: 6
Training loss: 2.431004524230957
Validation loss: 1.9677590888033631

Epoch: 6| Step: 7
Training loss: 2.7506628036499023
Validation loss: 1.9514235681103123

Epoch: 6| Step: 8
Training loss: 2.8117616176605225
Validation loss: 1.9326923816434798

Epoch: 6| Step: 9
Training loss: 2.3456411361694336
Validation loss: 1.9281793768687914

Epoch: 6| Step: 10
Training loss: 1.6423921585083008
Validation loss: 1.9244078128568587

Epoch: 6| Step: 11
Training loss: 2.2118663787841797
Validation loss: 1.9217939710104337

Epoch: 6| Step: 12
Training loss: 2.5553407669067383
Validation loss: 1.9341375366333993

Epoch: 6| Step: 13
Training loss: 1.802014708518982
Validation loss: 1.9259941090819657

Epoch: 145| Step: 0
Training loss: 2.4649899005889893
Validation loss: 1.9369797091330252

Epoch: 6| Step: 1
Training loss: 1.6360985040664673
Validation loss: 1.9617756066783782

Epoch: 6| Step: 2
Training loss: 2.162571430206299
Validation loss: 1.962032933388987

Epoch: 6| Step: 3
Training loss: 1.811591386795044
Validation loss: 1.9509970244540964

Epoch: 6| Step: 4
Training loss: 1.885493516921997
Validation loss: 1.9419016709891699

Epoch: 6| Step: 5
Training loss: 2.1868324279785156
Validation loss: 1.9341959312397947

Epoch: 6| Step: 6
Training loss: 2.022752285003662
Validation loss: 1.924987635304851

Epoch: 6| Step: 7
Training loss: 2.7851109504699707
Validation loss: 1.9241250099674347

Epoch: 6| Step: 8
Training loss: 1.8610161542892456
Validation loss: 1.9178590595081288

Epoch: 6| Step: 9
Training loss: 2.5808889865875244
Validation loss: 1.929333133082236

Epoch: 6| Step: 10
Training loss: 2.059399366378784
Validation loss: 1.928547061899657

Epoch: 6| Step: 11
Training loss: 3.0796091556549072
Validation loss: 1.9430064821756015

Epoch: 6| Step: 12
Training loss: 1.818380355834961
Validation loss: 1.9373773964502479

Epoch: 6| Step: 13
Training loss: 3.1229450702667236
Validation loss: 1.9493437108173166

Epoch: 146| Step: 0
Training loss: 2.0438480377197266
Validation loss: 1.956122480412965

Epoch: 6| Step: 1
Training loss: 2.4259936809539795
Validation loss: 1.9574724153805805

Epoch: 6| Step: 2
Training loss: 2.324817180633545
Validation loss: 1.946518830073777

Epoch: 6| Step: 3
Training loss: 3.0461678504943848
Validation loss: 1.9449035326639812

Epoch: 6| Step: 4
Training loss: 1.9468472003936768
Validation loss: 1.9446786526710755

Epoch: 6| Step: 5
Training loss: 2.3674564361572266
Validation loss: 1.9470384402941632

Epoch: 6| Step: 6
Training loss: 1.7852280139923096
Validation loss: 1.9377702948867634

Epoch: 6| Step: 7
Training loss: 1.856776237487793
Validation loss: 1.9363078763408046

Epoch: 6| Step: 8
Training loss: 2.199584722518921
Validation loss: 1.9269527991612752

Epoch: 6| Step: 9
Training loss: 1.7122925519943237
Validation loss: 1.9268574842842676

Epoch: 6| Step: 10
Training loss: 2.118476390838623
Validation loss: 1.9196266807535642

Epoch: 6| Step: 11
Training loss: 1.9816458225250244
Validation loss: 1.938350046834638

Epoch: 6| Step: 12
Training loss: 2.7411980628967285
Validation loss: 1.9501471032378495

Epoch: 6| Step: 13
Training loss: 2.1982202529907227
Validation loss: 1.9464841709342053

Epoch: 147| Step: 0
Training loss: 1.790604591369629
Validation loss: 1.964447090702672

Epoch: 6| Step: 1
Training loss: 2.2624154090881348
Validation loss: 1.966486072027555

Epoch: 6| Step: 2
Training loss: 2.0197296142578125
Validation loss: 1.9732645019408195

Epoch: 6| Step: 3
Training loss: 2.282557964324951
Validation loss: 1.9796322314969954

Epoch: 6| Step: 4
Training loss: 2.0715949535369873
Validation loss: 1.969426852400585

Epoch: 6| Step: 5
Training loss: 2.3421149253845215
Validation loss: 1.966420571009318

Epoch: 6| Step: 6
Training loss: 1.882063388824463
Validation loss: 1.9646855579909457

Epoch: 6| Step: 7
Training loss: 1.9529812335968018
Validation loss: 1.9550831869084349

Epoch: 6| Step: 8
Training loss: 2.1242942810058594
Validation loss: 1.9585332575664725

Epoch: 6| Step: 9
Training loss: 2.518425464630127
Validation loss: 1.9557255160424016

Epoch: 6| Step: 10
Training loss: 2.916203022003174
Validation loss: 1.956187266175465

Epoch: 6| Step: 11
Training loss: 2.160784959793091
Validation loss: 1.9543457467068908

Epoch: 6| Step: 12
Training loss: 2.940884590148926
Validation loss: 1.946309256297286

Epoch: 6| Step: 13
Training loss: 1.5522947311401367
Validation loss: 1.94947898644273

Epoch: 148| Step: 0
Training loss: 2.5390119552612305
Validation loss: 1.9498328265323435

Epoch: 6| Step: 1
Training loss: 2.380159378051758
Validation loss: 1.9576103892377628

Epoch: 6| Step: 2
Training loss: 2.298800230026245
Validation loss: 1.9560176121291293

Epoch: 6| Step: 3
Training loss: 1.8498060703277588
Validation loss: 1.9631378368664814

Epoch: 6| Step: 4
Training loss: 2.441300868988037
Validation loss: 1.9482901634708527

Epoch: 6| Step: 5
Training loss: 1.755443811416626
Validation loss: 1.9515733847054102

Epoch: 6| Step: 6
Training loss: 1.8867356777191162
Validation loss: 1.9477754177585724

Epoch: 6| Step: 7
Training loss: 2.1627347469329834
Validation loss: 1.9511358648218133

Epoch: 6| Step: 8
Training loss: 2.372748851776123
Validation loss: 1.9474392898621098

Epoch: 6| Step: 9
Training loss: 2.107994794845581
Validation loss: 1.9611830019181775

Epoch: 6| Step: 10
Training loss: 1.821097731590271
Validation loss: 1.9616944853977492

Epoch: 6| Step: 11
Training loss: 2.509692668914795
Validation loss: 1.9491698113820886

Epoch: 6| Step: 12
Training loss: 2.7441797256469727
Validation loss: 1.9382626805254208

Epoch: 6| Step: 13
Training loss: 1.5890460014343262
Validation loss: 1.9264946932433753

Epoch: 149| Step: 0
Training loss: 2.1369428634643555
Validation loss: 1.9385250306898547

Epoch: 6| Step: 1
Training loss: 1.9975804090499878
Validation loss: 1.9394387852761052

Epoch: 6| Step: 2
Training loss: 1.6019526720046997
Validation loss: 1.9534810781478882

Epoch: 6| Step: 3
Training loss: 2.092517852783203
Validation loss: 1.96505509397035

Epoch: 6| Step: 4
Training loss: 2.2800166606903076
Validation loss: 1.9843897409336542

Epoch: 6| Step: 5
Training loss: 1.7306411266326904
Validation loss: 1.9974840943531325

Epoch: 6| Step: 6
Training loss: 1.905658483505249
Validation loss: 2.024503815558649

Epoch: 6| Step: 7
Training loss: 2.130795478820801
Validation loss: 2.0481448481159825

Epoch: 6| Step: 8
Training loss: 2.738882303237915
Validation loss: 2.0299762756593767

Epoch: 6| Step: 9
Training loss: 2.916231155395508
Validation loss: 2.0312544722710886

Epoch: 6| Step: 10
Training loss: 2.6042230129241943
Validation loss: 2.0134611680943477

Epoch: 6| Step: 11
Training loss: 2.451751947402954
Validation loss: 2.0044961667829946

Epoch: 6| Step: 12
Training loss: 1.9819562435150146
Validation loss: 2.0074717267867057

Epoch: 6| Step: 13
Training loss: 1.4670093059539795
Validation loss: 2.015005939750261

Epoch: 150| Step: 0
Training loss: 2.1524791717529297
Validation loss: 2.020529762391121

Epoch: 6| Step: 1
Training loss: 2.252443790435791
Validation loss: 2.0294494077723515

Epoch: 6| Step: 2
Training loss: 2.728799343109131
Validation loss: 2.059441363939675

Epoch: 6| Step: 3
Training loss: 1.6691207885742188
Validation loss: 2.096365932495363

Epoch: 6| Step: 4
Training loss: 2.4168624877929688
Validation loss: 2.1475273152833343

Epoch: 6| Step: 5
Training loss: 1.4170119762420654
Validation loss: 2.1186576915043656

Epoch: 6| Step: 6
Training loss: 2.5933218002319336
Validation loss: 2.064071880873813

Epoch: 6| Step: 7
Training loss: 1.904636263847351
Validation loss: 2.004351733833231

Epoch: 6| Step: 8
Training loss: 2.5044217109680176
Validation loss: 1.9569573607496036

Epoch: 6| Step: 9
Training loss: 2.826193332672119
Validation loss: 1.9388832481958533

Epoch: 6| Step: 10
Training loss: 1.6777414083480835
Validation loss: 1.9371728538185038

Epoch: 6| Step: 11
Training loss: 2.2599668502807617
Validation loss: 1.9446597560759513

Epoch: 6| Step: 12
Training loss: 2.146470546722412
Validation loss: 1.9192826696621474

Epoch: 6| Step: 13
Training loss: 2.3984339237213135
Validation loss: 1.9111968355794107

Epoch: 151| Step: 0
Training loss: 2.4854612350463867
Validation loss: 1.9101951160738546

Epoch: 6| Step: 1
Training loss: 1.8141920566558838
Validation loss: 1.9342443866114463

Epoch: 6| Step: 2
Training loss: 2.1436331272125244
Validation loss: 1.9358909565915343

Epoch: 6| Step: 3
Training loss: 1.8637373447418213
Validation loss: 1.9540639949101273

Epoch: 6| Step: 4
Training loss: 1.6867454051971436
Validation loss: 1.965047533794116

Epoch: 6| Step: 5
Training loss: 2.5599207878112793
Validation loss: 1.9724271938364992

Epoch: 6| Step: 6
Training loss: 2.5926122665405273
Validation loss: 1.9432375892516105

Epoch: 6| Step: 7
Training loss: 2.672539710998535
Validation loss: 1.9242486312825193

Epoch: 6| Step: 8
Training loss: 1.9761478900909424
Validation loss: 1.9025077384005311

Epoch: 6| Step: 9
Training loss: 1.9483482837677002
Validation loss: 1.9140564536535611

Epoch: 6| Step: 10
Training loss: 2.045936107635498
Validation loss: 1.9110999902089436

Epoch: 6| Step: 11
Training loss: 2.9152047634124756
Validation loss: 1.9058776388886154

Epoch: 6| Step: 12
Training loss: 2.2095088958740234
Validation loss: 1.8930433411752023

Epoch: 6| Step: 13
Training loss: 1.1953517198562622
Validation loss: 1.9013830461809713

Epoch: 152| Step: 0
Training loss: 1.9877638816833496
Validation loss: 1.8990413437607467

Epoch: 6| Step: 1
Training loss: 2.644678831100464
Validation loss: 1.8939845741436045

Epoch: 6| Step: 2
Training loss: 2.505546808242798
Validation loss: 1.8999127431582379

Epoch: 6| Step: 3
Training loss: 2.4427907466888428
Validation loss: 1.9011196372329549

Epoch: 6| Step: 4
Training loss: 2.3851728439331055
Validation loss: 1.898373173129174

Epoch: 6| Step: 5
Training loss: 1.6869995594024658
Validation loss: 1.8947139273407638

Epoch: 6| Step: 6
Training loss: 1.7139866352081299
Validation loss: 1.8942636610359274

Epoch: 6| Step: 7
Training loss: 2.357553482055664
Validation loss: 1.8917177415663196

Epoch: 6| Step: 8
Training loss: 2.6586737632751465
Validation loss: 1.9003370628562024

Epoch: 6| Step: 9
Training loss: 1.3912923336029053
Validation loss: 1.9047275973904518

Epoch: 6| Step: 10
Training loss: 1.9961965084075928
Validation loss: 1.9105035720332977

Epoch: 6| Step: 11
Training loss: 2.2036232948303223
Validation loss: 1.9020017270118958

Epoch: 6| Step: 12
Training loss: 1.8950464725494385
Validation loss: 1.9215814964745634

Epoch: 6| Step: 13
Training loss: 2.2847237586975098
Validation loss: 1.9350590757144395

Epoch: 153| Step: 0
Training loss: 2.8169078826904297
Validation loss: 1.9656083506922568

Epoch: 6| Step: 1
Training loss: 2.7848920822143555
Validation loss: 1.9591922208827028

Epoch: 6| Step: 2
Training loss: 2.1958842277526855
Validation loss: 1.9689080766452256

Epoch: 6| Step: 3
Training loss: 1.4006633758544922
Validation loss: 1.9775462304392168

Epoch: 6| Step: 4
Training loss: 1.9428718090057373
Validation loss: 1.9807832881968508

Epoch: 6| Step: 5
Training loss: 2.9833827018737793
Validation loss: 1.9862780763256935

Epoch: 6| Step: 6
Training loss: 2.2438697814941406
Validation loss: 1.9767789071606052

Epoch: 6| Step: 7
Training loss: 2.3851985931396484
Validation loss: 1.9826635570936306

Epoch: 6| Step: 8
Training loss: 2.6680970191955566
Validation loss: 1.9874340180427796

Epoch: 6| Step: 9
Training loss: 2.131439447402954
Validation loss: 1.984803315131895

Epoch: 6| Step: 10
Training loss: 1.7159745693206787
Validation loss: 1.9811029895659416

Epoch: 6| Step: 11
Training loss: 1.5600311756134033
Validation loss: 1.972453858262749

Epoch: 6| Step: 12
Training loss: 1.2464932203292847
Validation loss: 1.9602757935882897

Epoch: 6| Step: 13
Training loss: 1.5345711708068848
Validation loss: 1.9489038785298665

Epoch: 154| Step: 0
Training loss: 1.9614101648330688
Validation loss: 1.9416548026505338

Epoch: 6| Step: 1
Training loss: 2.010481357574463
Validation loss: 1.938389608936925

Epoch: 6| Step: 2
Training loss: 2.436657428741455
Validation loss: 1.9364180859699045

Epoch: 6| Step: 3
Training loss: 1.9957789182662964
Validation loss: 1.9476612729410971

Epoch: 6| Step: 4
Training loss: 1.715137243270874
Validation loss: 1.9520438896712435

Epoch: 6| Step: 5
Training loss: 2.3130908012390137
Validation loss: 1.9700752201900686

Epoch: 6| Step: 6
Training loss: 2.852919816970825
Validation loss: 1.9639549511735157

Epoch: 6| Step: 7
Training loss: 2.419780731201172
Validation loss: 1.98321621905091

Epoch: 6| Step: 8
Training loss: 1.9681836366653442
Validation loss: 1.974031372736859

Epoch: 6| Step: 9
Training loss: 1.976912260055542
Validation loss: 1.9744456314271497

Epoch: 6| Step: 10
Training loss: 2.733029365539551
Validation loss: 1.9633765733370216

Epoch: 6| Step: 11
Training loss: 1.3124192953109741
Validation loss: 1.9687887058463147

Epoch: 6| Step: 12
Training loss: 2.036238670349121
Validation loss: 1.9359370546956216

Epoch: 6| Step: 13
Training loss: 1.6964411735534668
Validation loss: 1.9384674487575408

Epoch: 155| Step: 0
Training loss: 2.1071784496307373
Validation loss: 1.9670736584612118

Epoch: 6| Step: 1
Training loss: 2.3735339641571045
Validation loss: 1.9669120568101124

Epoch: 6| Step: 2
Training loss: 1.893830418586731
Validation loss: 1.950238904645366

Epoch: 6| Step: 3
Training loss: 2.0712618827819824
Validation loss: 1.9565485421047415

Epoch: 6| Step: 4
Training loss: 2.6054253578186035
Validation loss: 1.9799196668850478

Epoch: 6| Step: 5
Training loss: 1.9792556762695312
Validation loss: 1.989284570499133

Epoch: 6| Step: 6
Training loss: 1.74131178855896
Validation loss: 1.967399880450259

Epoch: 6| Step: 7
Training loss: 2.3073136806488037
Validation loss: 1.9685396917404667

Epoch: 6| Step: 8
Training loss: 1.9701063632965088
Validation loss: 1.9607367182290683

Epoch: 6| Step: 9
Training loss: 1.7438633441925049
Validation loss: 1.9395489949052052

Epoch: 6| Step: 10
Training loss: 1.7159805297851562
Validation loss: 1.967421834186841

Epoch: 6| Step: 11
Training loss: 2.066810131072998
Validation loss: 1.9559915091401787

Epoch: 6| Step: 12
Training loss: 2.015591859817505
Validation loss: 1.952064178323233

Epoch: 6| Step: 13
Training loss: 3.515273094177246
Validation loss: 1.9465114865251767

Epoch: 156| Step: 0
Training loss: 1.9359203577041626
Validation loss: 1.9546762999667917

Epoch: 6| Step: 1
Training loss: 1.5092363357543945
Validation loss: 1.9473895334428357

Epoch: 6| Step: 2
Training loss: 1.799867033958435
Validation loss: 1.9427098471631286

Epoch: 6| Step: 3
Training loss: 2.423630475997925
Validation loss: 1.9476892922514228

Epoch: 6| Step: 4
Training loss: 2.305962324142456
Validation loss: 1.9297346607331307

Epoch: 6| Step: 5
Training loss: 2.4937305450439453
Validation loss: 1.9098405799558085

Epoch: 6| Step: 6
Training loss: 2.325532913208008
Validation loss: 1.9004431104147306

Epoch: 6| Step: 7
Training loss: 2.040337324142456
Validation loss: 1.9087590645718318

Epoch: 6| Step: 8
Training loss: 2.2189598083496094
Validation loss: 1.917667147933796

Epoch: 6| Step: 9
Training loss: 2.209352493286133
Validation loss: 1.911104549643814

Epoch: 6| Step: 10
Training loss: 1.91018807888031
Validation loss: 1.9348888320307578

Epoch: 6| Step: 11
Training loss: 2.2690770626068115
Validation loss: 1.9362259039314844

Epoch: 6| Step: 12
Training loss: 2.3003463745117188
Validation loss: 1.9444542546426096

Epoch: 6| Step: 13
Training loss: 1.2002397775650024
Validation loss: 1.959380252386934

Epoch: 157| Step: 0
Training loss: 2.9235575199127197
Validation loss: 1.9979668253211564

Epoch: 6| Step: 1
Training loss: 2.5279641151428223
Validation loss: 1.9998494245672738

Epoch: 6| Step: 2
Training loss: 2.1964869499206543
Validation loss: 2.03239853407747

Epoch: 6| Step: 3
Training loss: 1.9022624492645264
Validation loss: 2.0271117789770967

Epoch: 6| Step: 4
Training loss: 2.075468063354492
Validation loss: 2.0157997864548878

Epoch: 6| Step: 5
Training loss: 1.6827352046966553
Validation loss: 2.023523079451694

Epoch: 6| Step: 6
Training loss: 1.6985464096069336
Validation loss: 2.012049513478433

Epoch: 6| Step: 7
Training loss: 2.184417724609375
Validation loss: 2.0157325575428624

Epoch: 6| Step: 8
Training loss: 2.0113205909729004
Validation loss: 2.0029699238397742

Epoch: 6| Step: 9
Training loss: 1.8407059907913208
Validation loss: 1.9762860651939147

Epoch: 6| Step: 10
Training loss: 2.4544901847839355
Validation loss: 1.9582014019771288

Epoch: 6| Step: 11
Training loss: 1.8050274848937988
Validation loss: 1.9373187326615857

Epoch: 6| Step: 12
Training loss: 1.911658763885498
Validation loss: 1.9132433937441917

Epoch: 6| Step: 13
Training loss: 2.8103654384613037
Validation loss: 1.9060682763335526

Epoch: 158| Step: 0
Training loss: 2.1369781494140625
Validation loss: 1.9121151662641955

Epoch: 6| Step: 1
Training loss: 2.4177653789520264
Validation loss: 1.90096539579412

Epoch: 6| Step: 2
Training loss: 2.014930248260498
Validation loss: 1.9009596096572055

Epoch: 6| Step: 3
Training loss: 2.2224860191345215
Validation loss: 1.9046986884968256

Epoch: 6| Step: 4
Training loss: 2.165814161300659
Validation loss: 1.8918762450577111

Epoch: 6| Step: 5
Training loss: 2.0829408168792725
Validation loss: 1.8831323333965835

Epoch: 6| Step: 6
Training loss: 1.9440734386444092
Validation loss: 1.8673273376239243

Epoch: 6| Step: 7
Training loss: 2.1395087242126465
Validation loss: 1.8595789324852727

Epoch: 6| Step: 8
Training loss: 2.294684648513794
Validation loss: 1.8609654749593427

Epoch: 6| Step: 9
Training loss: 2.4254772663116455
Validation loss: 1.8586129180846676

Epoch: 6| Step: 10
Training loss: 2.052689790725708
Validation loss: 1.8848711572667605

Epoch: 6| Step: 11
Training loss: 2.0596108436584473
Validation loss: 1.896935171978448

Epoch: 6| Step: 12
Training loss: 1.9621694087982178
Validation loss: 1.8883472719500143

Epoch: 6| Step: 13
Training loss: 1.3703250885009766
Validation loss: 1.9187263288805563

Epoch: 159| Step: 0
Training loss: 1.9162893295288086
Validation loss: 1.9295895381640362

Epoch: 6| Step: 1
Training loss: 2.393277168273926
Validation loss: 1.9565981972602107

Epoch: 6| Step: 2
Training loss: 2.3198609352111816
Validation loss: 1.9947476989479476

Epoch: 6| Step: 3
Training loss: 1.9125096797943115
Validation loss: 2.093514536016731

Epoch: 6| Step: 4
Training loss: 2.2069034576416016
Validation loss: 2.130877879358107

Epoch: 6| Step: 5
Training loss: 2.9434118270874023
Validation loss: 2.1241285390751337

Epoch: 6| Step: 6
Training loss: 1.5120885372161865
Validation loss: 2.086540381113688

Epoch: 6| Step: 7
Training loss: 2.09344482421875
Validation loss: 2.0526612548417944

Epoch: 6| Step: 8
Training loss: 1.6152950525283813
Validation loss: 2.0430810477143977

Epoch: 6| Step: 9
Training loss: 2.140523672103882
Validation loss: 2.019973793337422

Epoch: 6| Step: 10
Training loss: 2.1450772285461426
Validation loss: 1.9920237910362981

Epoch: 6| Step: 11
Training loss: 2.3566622734069824
Validation loss: 1.9773185714598625

Epoch: 6| Step: 12
Training loss: 2.1096765995025635
Validation loss: 1.9863834727195002

Epoch: 6| Step: 13
Training loss: 2.2581324577331543
Validation loss: 1.9843782378781227

Epoch: 160| Step: 0
Training loss: 1.783434271812439
Validation loss: 1.9870951842236262

Epoch: 6| Step: 1
Training loss: 1.9554871320724487
Validation loss: 1.9785986433746994

Epoch: 6| Step: 2
Training loss: 2.2430500984191895
Validation loss: 1.977969313180575

Epoch: 6| Step: 3
Training loss: 2.8027987480163574
Validation loss: 1.9643785440793602

Epoch: 6| Step: 4
Training loss: 1.7844547033309937
Validation loss: 1.970442174583353

Epoch: 6| Step: 5
Training loss: 2.0701828002929688
Validation loss: 1.9581781074564943

Epoch: 6| Step: 6
Training loss: 2.029444694519043
Validation loss: 1.9420797414677118

Epoch: 6| Step: 7
Training loss: 2.4093198776245117
Validation loss: 1.946934828194239

Epoch: 6| Step: 8
Training loss: 2.616300582885742
Validation loss: 1.911123457775321

Epoch: 6| Step: 9
Training loss: 2.4644060134887695
Validation loss: 1.9229649523253083

Epoch: 6| Step: 10
Training loss: 1.3688771724700928
Validation loss: 1.9042216834201608

Epoch: 6| Step: 11
Training loss: 1.5985286235809326
Validation loss: 1.9035634020323395

Epoch: 6| Step: 12
Training loss: 1.7926158905029297
Validation loss: 1.9021806204190819

Epoch: 6| Step: 13
Training loss: 2.7282185554504395
Validation loss: 1.8920268935541953

Epoch: 161| Step: 0
Training loss: 2.102336883544922
Validation loss: 1.8836090128908876

Epoch: 6| Step: 1
Training loss: 1.9731014966964722
Validation loss: 1.8807894440107449

Epoch: 6| Step: 2
Training loss: 2.290560007095337
Validation loss: 1.8997202868102698

Epoch: 6| Step: 3
Training loss: 1.7056033611297607
Validation loss: 1.923735519891144

Epoch: 6| Step: 4
Training loss: 2.2461318969726562
Validation loss: 1.9299622171668596

Epoch: 6| Step: 5
Training loss: 1.8918530941009521
Validation loss: 1.9466464904046827

Epoch: 6| Step: 6
Training loss: 2.013871431350708
Validation loss: 1.957125066429056

Epoch: 6| Step: 7
Training loss: 2.3924195766448975
Validation loss: 1.9733979445631786

Epoch: 6| Step: 8
Training loss: 2.0720009803771973
Validation loss: 1.972285911601077

Epoch: 6| Step: 9
Training loss: 3.2002005577087402
Validation loss: 1.9866454088559715

Epoch: 6| Step: 10
Training loss: 2.0151193141937256
Validation loss: 1.9817986719069942

Epoch: 6| Step: 11
Training loss: 1.505960464477539
Validation loss: 1.9622269958578131

Epoch: 6| Step: 12
Training loss: 2.042423725128174
Validation loss: 1.9630914734255882

Epoch: 6| Step: 13
Training loss: 0.9479162693023682
Validation loss: 1.9624205122711837

Epoch: 162| Step: 0
Training loss: 2.9739513397216797
Validation loss: 1.9738403315185218

Epoch: 6| Step: 1
Training loss: 2.1399524211883545
Validation loss: 1.9841458233453895

Epoch: 6| Step: 2
Training loss: 1.8694790601730347
Validation loss: 2.0111328901783114

Epoch: 6| Step: 3
Training loss: 2.0668258666992188
Validation loss: 2.0098441646945093

Epoch: 6| Step: 4
Training loss: 2.3764724731445312
Validation loss: 2.017999028646818

Epoch: 6| Step: 5
Training loss: 1.8324482440948486
Validation loss: 2.039552714235039

Epoch: 6| Step: 6
Training loss: 1.693403720855713
Validation loss: 2.0661989296636274

Epoch: 6| Step: 7
Training loss: 2.2806286811828613
Validation loss: 2.0838597359195834

Epoch: 6| Step: 8
Training loss: 2.0265164375305176
Validation loss: 2.1131605332897556

Epoch: 6| Step: 9
Training loss: 1.542213797569275
Validation loss: 2.116891566143241

Epoch: 6| Step: 10
Training loss: 2.490931987762451
Validation loss: 2.131458966962753

Epoch: 6| Step: 11
Training loss: 1.4873476028442383
Validation loss: 2.1155037021124237

Epoch: 6| Step: 12
Training loss: 1.929998517036438
Validation loss: 2.0633688152477307

Epoch: 6| Step: 13
Training loss: 2.7693049907684326
Validation loss: 2.0350166777128815

Epoch: 163| Step: 0
Training loss: 2.259829044342041
Validation loss: 1.984781252440586

Epoch: 6| Step: 1
Training loss: 2.6256589889526367
Validation loss: 1.9943466647978751

Epoch: 6| Step: 2
Training loss: 2.3557894229888916
Validation loss: 1.9849709067293393

Epoch: 6| Step: 3
Training loss: 2.0311031341552734
Validation loss: 1.9483996309259886

Epoch: 6| Step: 4
Training loss: 2.4275612831115723
Validation loss: 1.915428178284758

Epoch: 6| Step: 5
Training loss: 2.0299081802368164
Validation loss: 1.8860712230846446

Epoch: 6| Step: 6
Training loss: 1.822049856185913
Validation loss: 1.8715652470947595

Epoch: 6| Step: 7
Training loss: 2.342055559158325
Validation loss: 1.8776104193861767

Epoch: 6| Step: 8
Training loss: 1.713043451309204
Validation loss: 1.8778415328712874

Epoch: 6| Step: 9
Training loss: 2.480557680130005
Validation loss: 1.889071262010964

Epoch: 6| Step: 10
Training loss: 1.8821043968200684
Validation loss: 1.8877782347381755

Epoch: 6| Step: 11
Training loss: 1.3260196447372437
Validation loss: 1.898749941138811

Epoch: 6| Step: 12
Training loss: 2.5212628841400146
Validation loss: 1.9041251597865936

Epoch: 6| Step: 13
Training loss: 1.0057183504104614
Validation loss: 1.905104919146466

Epoch: 164| Step: 0
Training loss: 1.7333340644836426
Validation loss: 1.9111288773116244

Epoch: 6| Step: 1
Training loss: 2.2461788654327393
Validation loss: 1.9129576247225526

Epoch: 6| Step: 2
Training loss: 2.0936155319213867
Validation loss: 1.9144299786577943

Epoch: 6| Step: 3
Training loss: 1.8347480297088623
Validation loss: 1.9163430454910442

Epoch: 6| Step: 4
Training loss: 2.0362606048583984
Validation loss: 1.9316610674704275

Epoch: 6| Step: 5
Training loss: 2.3271896839141846
Validation loss: 1.9321682658246768

Epoch: 6| Step: 6
Training loss: 1.7391843795776367
Validation loss: 1.912978946521718

Epoch: 6| Step: 7
Training loss: 2.2600760459899902
Validation loss: 1.9249854536466702

Epoch: 6| Step: 8
Training loss: 1.990903615951538
Validation loss: 1.940175183357731

Epoch: 6| Step: 9
Training loss: 1.4155399799346924
Validation loss: 1.9369418659517843

Epoch: 6| Step: 10
Training loss: 2.1446056365966797
Validation loss: 1.9432850089124454

Epoch: 6| Step: 11
Training loss: 2.675352096557617
Validation loss: 1.9574289962809572

Epoch: 6| Step: 12
Training loss: 1.947810411453247
Validation loss: 1.9684481479788338

Epoch: 6| Step: 13
Training loss: 2.062612533569336
Validation loss: 1.9861681333152197

Epoch: 165| Step: 0
Training loss: 2.0281362533569336
Validation loss: 1.9993523141389251

Epoch: 6| Step: 1
Training loss: 2.5104100704193115
Validation loss: 2.0261920139353764

Epoch: 6| Step: 2
Training loss: 2.55802321434021
Validation loss: 2.0108256404117872

Epoch: 6| Step: 3
Training loss: 1.7796679735183716
Validation loss: 2.036198442982089

Epoch: 6| Step: 4
Training loss: 1.3894622325897217
Validation loss: 2.0326199608464397

Epoch: 6| Step: 5
Training loss: 1.8982070684432983
Validation loss: 2.031542078141243

Epoch: 6| Step: 6
Training loss: 1.8750567436218262
Validation loss: 2.017211086006575

Epoch: 6| Step: 7
Training loss: 2.2138707637786865
Validation loss: 2.0124972379335793

Epoch: 6| Step: 8
Training loss: 2.175222396850586
Validation loss: 1.9926652062323786

Epoch: 6| Step: 9
Training loss: 1.7344119548797607
Validation loss: 1.9833703143622285

Epoch: 6| Step: 10
Training loss: 1.7433836460113525
Validation loss: 1.9905024267012073

Epoch: 6| Step: 11
Training loss: 1.9924267530441284
Validation loss: 2.0025978601107033

Epoch: 6| Step: 12
Training loss: 2.71775484085083
Validation loss: 2.0022251323987077

Epoch: 6| Step: 13
Training loss: 1.80479896068573
Validation loss: 2.0081812053598385

Epoch: 166| Step: 0
Training loss: 2.572822093963623
Validation loss: 2.0033059761088383

Epoch: 6| Step: 1
Training loss: 2.1823625564575195
Validation loss: 2.0115945826294603

Epoch: 6| Step: 2
Training loss: 1.7925357818603516
Validation loss: 2.0061852829430693

Epoch: 6| Step: 3
Training loss: 1.9403107166290283
Validation loss: 1.9990022759283743

Epoch: 6| Step: 4
Training loss: 2.800844192504883
Validation loss: 1.9997319303533083

Epoch: 6| Step: 5
Training loss: 2.078702688217163
Validation loss: 2.009805724185

Epoch: 6| Step: 6
Training loss: 2.136664390563965
Validation loss: 2.00712953588014

Epoch: 6| Step: 7
Training loss: 2.4788098335266113
Validation loss: 2.004374829671716

Epoch: 6| Step: 8
Training loss: 1.8420276641845703
Validation loss: 1.9841561073897986

Epoch: 6| Step: 9
Training loss: 1.6186912059783936
Validation loss: 1.9699042958597983

Epoch: 6| Step: 10
Training loss: 2.458616256713867
Validation loss: 1.9938926004594373

Epoch: 6| Step: 11
Training loss: 1.1237598657608032
Validation loss: 1.9949586186357724

Epoch: 6| Step: 12
Training loss: 1.4346377849578857
Validation loss: 2.007501338117866

Epoch: 6| Step: 13
Training loss: 1.814258098602295
Validation loss: 2.0146548927471204

Epoch: 167| Step: 0
Training loss: 1.9468731880187988
Validation loss: 1.992058769349129

Epoch: 6| Step: 1
Training loss: 1.551087498664856
Validation loss: 1.9788880168750722

Epoch: 6| Step: 2
Training loss: 1.4683080911636353
Validation loss: 1.9605589810238089

Epoch: 6| Step: 3
Training loss: 1.1467019319534302
Validation loss: 1.93702402294323

Epoch: 6| Step: 4
Training loss: 1.785170316696167
Validation loss: 1.9415822875115178

Epoch: 6| Step: 5
Training loss: 2.165170192718506
Validation loss: 1.9200090977453417

Epoch: 6| Step: 6
Training loss: 1.9674632549285889
Validation loss: 1.9368797412482641

Epoch: 6| Step: 7
Training loss: 2.598752021789551
Validation loss: 1.9351765930011708

Epoch: 6| Step: 8
Training loss: 2.173288345336914
Validation loss: 1.9620092145858272

Epoch: 6| Step: 9
Training loss: 1.9023329019546509
Validation loss: 1.9554134568860453

Epoch: 6| Step: 10
Training loss: 2.5244593620300293
Validation loss: 1.973318176884805

Epoch: 6| Step: 11
Training loss: 1.9933016300201416
Validation loss: 1.9680770392058997

Epoch: 6| Step: 12
Training loss: 2.3256001472473145
Validation loss: 1.9716800848642986

Epoch: 6| Step: 13
Training loss: 2.1774520874023438
Validation loss: 1.9725675928977229

Epoch: 168| Step: 0
Training loss: 2.0370378494262695
Validation loss: 1.9597407566603793

Epoch: 6| Step: 1
Training loss: 1.8095453977584839
Validation loss: 1.9926338529074064

Epoch: 6| Step: 2
Training loss: 1.9671597480773926
Validation loss: 1.9843308835901239

Epoch: 6| Step: 3
Training loss: 1.7109334468841553
Validation loss: 1.9775190302120742

Epoch: 6| Step: 4
Training loss: 3.051757335662842
Validation loss: 1.9882478380715976

Epoch: 6| Step: 5
Training loss: 1.6109858751296997
Validation loss: 1.9804857187373663

Epoch: 6| Step: 6
Training loss: 1.5415066480636597
Validation loss: 1.980364502117198

Epoch: 6| Step: 7
Training loss: 2.0352656841278076
Validation loss: 1.9856945506988033

Epoch: 6| Step: 8
Training loss: 2.3987860679626465
Validation loss: 1.9824208521073865

Epoch: 6| Step: 9
Training loss: 1.7956056594848633
Validation loss: 1.9997633759693434

Epoch: 6| Step: 10
Training loss: 1.3950765132904053
Validation loss: 2.012040320263114

Epoch: 6| Step: 11
Training loss: 1.691684365272522
Validation loss: 2.004744622015184

Epoch: 6| Step: 12
Training loss: 2.105121612548828
Validation loss: 1.9919138723804104

Epoch: 6| Step: 13
Training loss: 2.09785532951355
Validation loss: 1.987303731262043

Epoch: 169| Step: 0
Training loss: 1.1955971717834473
Validation loss: 1.9963753877147552

Epoch: 6| Step: 1
Training loss: 2.190004825592041
Validation loss: 1.9782013918763848

Epoch: 6| Step: 2
Training loss: 1.82256281375885
Validation loss: 1.974871120145244

Epoch: 6| Step: 3
Training loss: 2.483031988143921
Validation loss: 1.9692887849705194

Epoch: 6| Step: 4
Training loss: 2.1427206993103027
Validation loss: 1.962575827875445

Epoch: 6| Step: 5
Training loss: 1.450073003768921
Validation loss: 1.9454366186613679

Epoch: 6| Step: 6
Training loss: 1.4516284465789795
Validation loss: 1.9482675572877288

Epoch: 6| Step: 7
Training loss: 1.8726387023925781
Validation loss: 1.9407422427208192

Epoch: 6| Step: 8
Training loss: 2.0051937103271484
Validation loss: 1.9453661057256884

Epoch: 6| Step: 9
Training loss: 2.175995349884033
Validation loss: 1.9636735762319257

Epoch: 6| Step: 10
Training loss: 2.131791353225708
Validation loss: 1.9756506630169448

Epoch: 6| Step: 11
Training loss: 2.177535057067871
Validation loss: 1.9795155512389315

Epoch: 6| Step: 12
Training loss: 2.11297869682312
Validation loss: 1.9878644609964022

Epoch: 6| Step: 13
Training loss: 2.1004393100738525
Validation loss: 1.9924783668210428

Epoch: 170| Step: 0
Training loss: 1.2873271703720093
Validation loss: 1.9678760369618733

Epoch: 6| Step: 1
Training loss: 1.4147340059280396
Validation loss: 2.004702306562854

Epoch: 6| Step: 2
Training loss: 2.5959227085113525
Validation loss: 2.0064403395498953

Epoch: 6| Step: 3
Training loss: 2.3448798656463623
Validation loss: 2.0091156369896344

Epoch: 6| Step: 4
Training loss: 2.6787056922912598
Validation loss: 1.9969136535480458

Epoch: 6| Step: 5
Training loss: 1.783571481704712
Validation loss: 1.9911671787179925

Epoch: 6| Step: 6
Training loss: 2.7139062881469727
Validation loss: 1.9838904244925386

Epoch: 6| Step: 7
Training loss: 2.038381576538086
Validation loss: 1.977771774415047

Epoch: 6| Step: 8
Training loss: 1.7831460237503052
Validation loss: 1.9665386035878172

Epoch: 6| Step: 9
Training loss: 1.3744008541107178
Validation loss: 1.998093940878427

Epoch: 6| Step: 10
Training loss: 2.0111582279205322
Validation loss: 1.9978061927262174

Epoch: 6| Step: 11
Training loss: 1.085296869277954
Validation loss: 2.0063706072427894

Epoch: 6| Step: 12
Training loss: 2.1625003814697266
Validation loss: 2.023544752469627

Epoch: 6| Step: 13
Training loss: 1.5062365531921387
Validation loss: 2.025349365767612

Epoch: 171| Step: 0
Training loss: 2.1549248695373535
Validation loss: 2.015918318943311

Epoch: 6| Step: 1
Training loss: 1.843096137046814
Validation loss: 1.9972196907125495

Epoch: 6| Step: 2
Training loss: 1.6924846172332764
Validation loss: 1.9874024314265097

Epoch: 6| Step: 3
Training loss: 1.7323371171951294
Validation loss: 1.9503816455923102

Epoch: 6| Step: 4
Training loss: 1.1449922323226929
Validation loss: 1.9413243596271803

Epoch: 6| Step: 5
Training loss: 2.083807945251465
Validation loss: 1.922926349024619

Epoch: 6| Step: 6
Training loss: 2.0890748500823975
Validation loss: 1.914157477758264

Epoch: 6| Step: 7
Training loss: 2.466398239135742
Validation loss: 1.9264951572623303

Epoch: 6| Step: 8
Training loss: 2.2816638946533203
Validation loss: 1.923401194234048

Epoch: 6| Step: 9
Training loss: 1.8232011795043945
Validation loss: 1.9157419050893476

Epoch: 6| Step: 10
Training loss: 1.7910149097442627
Validation loss: 1.9278612611114339

Epoch: 6| Step: 11
Training loss: 2.0104598999023438
Validation loss: 1.9431039210288756

Epoch: 6| Step: 12
Training loss: 1.6669625043869019
Validation loss: 1.9668957341101863

Epoch: 6| Step: 13
Training loss: 1.739824891090393
Validation loss: 1.9856693052476453

Epoch: 172| Step: 0
Training loss: 2.231314182281494
Validation loss: 2.0236674226740354

Epoch: 6| Step: 1
Training loss: 1.6561610698699951
Validation loss: 2.0749486800163024

Epoch: 6| Step: 2
Training loss: 1.8356683254241943
Validation loss: 2.083706000799774

Epoch: 6| Step: 3
Training loss: 1.9710334539413452
Validation loss: 2.086087070485597

Epoch: 6| Step: 4
Training loss: 1.4892754554748535
Validation loss: 2.096641637945688

Epoch: 6| Step: 5
Training loss: 1.5758392810821533
Validation loss: 2.076135745612524

Epoch: 6| Step: 6
Training loss: 1.8159410953521729
Validation loss: 2.09085827232689

Epoch: 6| Step: 7
Training loss: 1.7181065082550049
Validation loss: 2.071333610883323

Epoch: 6| Step: 8
Training loss: 1.6878180503845215
Validation loss: 2.045722402552123

Epoch: 6| Step: 9
Training loss: 1.9760078191757202
Validation loss: 2.055337408537506

Epoch: 6| Step: 10
Training loss: 2.0409836769104004
Validation loss: 2.0285284673013995

Epoch: 6| Step: 11
Training loss: 1.7599989175796509
Validation loss: 2.009834199823359

Epoch: 6| Step: 12
Training loss: 2.9245049953460693
Validation loss: 1.9669732470666208

Epoch: 6| Step: 13
Training loss: 2.065861940383911
Validation loss: 1.9411532071328932

Epoch: 173| Step: 0
Training loss: 2.0253584384918213
Validation loss: 1.9331361016919535

Epoch: 6| Step: 1
Training loss: 1.7454192638397217
Validation loss: 1.9509258936810236

Epoch: 6| Step: 2
Training loss: 2.489719867706299
Validation loss: 1.936044728884133

Epoch: 6| Step: 3
Training loss: 1.4529478549957275
Validation loss: 1.957411478924495

Epoch: 6| Step: 4
Training loss: 2.064960241317749
Validation loss: 1.9396607337459442

Epoch: 6| Step: 5
Training loss: 2.0210604667663574
Validation loss: 1.9518197044249503

Epoch: 6| Step: 6
Training loss: 2.0832152366638184
Validation loss: 1.9770845367062477

Epoch: 6| Step: 7
Training loss: 1.9731584787368774
Validation loss: 2.002430982487176

Epoch: 6| Step: 8
Training loss: 1.5078765153884888
Validation loss: 2.0161949652497486

Epoch: 6| Step: 9
Training loss: 1.8746399879455566
Validation loss: 2.0254608328624437

Epoch: 6| Step: 10
Training loss: 2.0267910957336426
Validation loss: 2.0373752078702374

Epoch: 6| Step: 11
Training loss: 2.0266711711883545
Validation loss: 2.0550724870415142

Epoch: 6| Step: 12
Training loss: 1.836104154586792
Validation loss: 2.069341378827249

Epoch: 6| Step: 13
Training loss: 1.077202320098877
Validation loss: 2.064667708130293

Epoch: 174| Step: 0
Training loss: 2.6280786991119385
Validation loss: 2.090318981037345

Epoch: 6| Step: 1
Training loss: 1.4293148517608643
Validation loss: 2.101414403607768

Epoch: 6| Step: 2
Training loss: 2.023890733718872
Validation loss: 2.075362674651607

Epoch: 6| Step: 3
Training loss: 1.424010992050171
Validation loss: 2.034362736568656

Epoch: 6| Step: 4
Training loss: 1.5846726894378662
Validation loss: 2.014692908974104

Epoch: 6| Step: 5
Training loss: 1.9279236793518066
Validation loss: 1.9916443440221971

Epoch: 6| Step: 6
Training loss: 1.4939770698547363
Validation loss: 2.014528033553913

Epoch: 6| Step: 7
Training loss: 2.2498433589935303
Validation loss: 2.0253260545833136

Epoch: 6| Step: 8
Training loss: 1.5651390552520752
Validation loss: 2.0173581287425053

Epoch: 6| Step: 9
Training loss: 2.2181644439697266
Validation loss: 1.9846312435724403

Epoch: 6| Step: 10
Training loss: 1.3155313730239868
Validation loss: 1.9647966572033462

Epoch: 6| Step: 11
Training loss: 2.2841696739196777
Validation loss: 1.9615579907612135

Epoch: 6| Step: 12
Training loss: 1.9949262142181396
Validation loss: 2.0049500619211504

Epoch: 6| Step: 13
Training loss: 2.5097262859344482
Validation loss: 2.0369459852095573

Epoch: 175| Step: 0
Training loss: 2.001699924468994
Validation loss: 2.0555605914003108

Epoch: 6| Step: 1
Training loss: 2.0804738998413086
Validation loss: 2.028522647837157

Epoch: 6| Step: 2
Training loss: 2.16929292678833
Validation loss: 2.018105709424583

Epoch: 6| Step: 3
Training loss: 2.405581474304199
Validation loss: 1.986887014040383

Epoch: 6| Step: 4
Training loss: 1.8475334644317627
Validation loss: 1.9870460212871592

Epoch: 6| Step: 5
Training loss: 1.7247222661972046
Validation loss: 1.9846217516929872

Epoch: 6| Step: 6
Training loss: 1.3039710521697998
Validation loss: 1.9999638167760705

Epoch: 6| Step: 7
Training loss: 1.5013501644134521
Validation loss: 2.019034775354529

Epoch: 6| Step: 8
Training loss: 1.782193899154663
Validation loss: 2.0111375624133694

Epoch: 6| Step: 9
Training loss: 1.9375327825546265
Validation loss: 2.003127374956685

Epoch: 6| Step: 10
Training loss: 1.8865904808044434
Validation loss: 1.9942030816949823

Epoch: 6| Step: 11
Training loss: 2.095383882522583
Validation loss: 1.9877903371728876

Epoch: 6| Step: 12
Training loss: 1.5697698593139648
Validation loss: 1.9842009621281778

Epoch: 6| Step: 13
Training loss: 2.4209203720092773
Validation loss: 1.9954705315251504

Epoch: 176| Step: 0
Training loss: 1.864508867263794
Validation loss: 1.9863992634639944

Epoch: 6| Step: 1
Training loss: 1.8771766424179077
Validation loss: 1.9823412972111856

Epoch: 6| Step: 2
Training loss: 1.47239351272583
Validation loss: 1.9769182128290976

Epoch: 6| Step: 3
Training loss: 1.4445409774780273
Validation loss: 1.995492922362461

Epoch: 6| Step: 4
Training loss: 2.0567915439605713
Validation loss: 2.02648994486819

Epoch: 6| Step: 5
Training loss: 2.9529428482055664
Validation loss: 2.010767508578557

Epoch: 6| Step: 6
Training loss: 1.527212381362915
Validation loss: 2.0025638200903453

Epoch: 6| Step: 7
Training loss: 2.3677453994750977
Validation loss: 2.0013636594177573

Epoch: 6| Step: 8
Training loss: 2.076535701751709
Validation loss: 2.003555393988086

Epoch: 6| Step: 9
Training loss: 2.260648250579834
Validation loss: 2.003018674030099

Epoch: 6| Step: 10
Training loss: 1.5045448541641235
Validation loss: 1.9954462051391602

Epoch: 6| Step: 11
Training loss: 1.2144461870193481
Validation loss: 1.985839101576036

Epoch: 6| Step: 12
Training loss: 1.5452167987823486
Validation loss: 1.9794179278035318

Epoch: 6| Step: 13
Training loss: 1.1169896125793457
Validation loss: 1.9601065074243853

Epoch: 177| Step: 0
Training loss: 1.9118983745574951
Validation loss: 1.9673478398271786

Epoch: 6| Step: 1
Training loss: 1.9404196739196777
Validation loss: 1.9725532172828593

Epoch: 6| Step: 2
Training loss: 2.034804582595825
Validation loss: 1.9921075400485788

Epoch: 6| Step: 3
Training loss: 2.536226749420166
Validation loss: 1.978833939439507

Epoch: 6| Step: 4
Training loss: 1.7347506284713745
Validation loss: 1.9944088100105204

Epoch: 6| Step: 5
Training loss: 1.3397619724273682
Validation loss: 1.9635782498185352

Epoch: 6| Step: 6
Training loss: 1.8858046531677246
Validation loss: 1.9696671065463816

Epoch: 6| Step: 7
Training loss: 1.8852366209030151
Validation loss: 1.9704109596949753

Epoch: 6| Step: 8
Training loss: 1.7925724983215332
Validation loss: 1.9773414698980187

Epoch: 6| Step: 9
Training loss: 1.1982418298721313
Validation loss: 1.982975516268002

Epoch: 6| Step: 10
Training loss: 2.719132661819458
Validation loss: 2.0281892130451817

Epoch: 6| Step: 11
Training loss: 1.0192992687225342
Validation loss: 2.025799097553376

Epoch: 6| Step: 12
Training loss: 2.0937952995300293
Validation loss: 2.0203759977894444

Epoch: 6| Step: 13
Training loss: 1.4933714866638184
Validation loss: 1.9974804539834299

Epoch: 178| Step: 0
Training loss: 1.1712634563446045
Validation loss: 2.0055547606560493

Epoch: 6| Step: 1
Training loss: 1.807358741760254
Validation loss: 2.035029806116576

Epoch: 6| Step: 2
Training loss: 2.098463773727417
Validation loss: 2.0883584842886975

Epoch: 6| Step: 3
Training loss: 1.7557134628295898
Validation loss: 2.1012215639955256

Epoch: 6| Step: 4
Training loss: 2.3328752517700195
Validation loss: 2.1064267414872364

Epoch: 6| Step: 5
Training loss: 1.8910640478134155
Validation loss: 2.103263644761937

Epoch: 6| Step: 6
Training loss: 1.1833667755126953
Validation loss: 2.0865198848068074

Epoch: 6| Step: 7
Training loss: 1.7934832572937012
Validation loss: 2.086559563554743

Epoch: 6| Step: 8
Training loss: 1.5894339084625244
Validation loss: 2.0960847126540316

Epoch: 6| Step: 9
Training loss: 1.8770580291748047
Validation loss: 2.0662643627453874

Epoch: 6| Step: 10
Training loss: 1.6840671300888062
Validation loss: 2.0516162098094983

Epoch: 6| Step: 11
Training loss: 1.7239658832550049
Validation loss: 2.0344914646558863

Epoch: 6| Step: 12
Training loss: 2.264948844909668
Validation loss: 2.0173771176286923

Epoch: 6| Step: 13
Training loss: 2.5430908203125
Validation loss: 2.0031658423844205

Epoch: 179| Step: 0
Training loss: 1.5269522666931152
Validation loss: 2.005914418928085

Epoch: 6| Step: 1
Training loss: 2.1017885208129883
Validation loss: 1.995863183852165

Epoch: 6| Step: 2
Training loss: 1.5819342136383057
Validation loss: 1.991404761550247

Epoch: 6| Step: 3
Training loss: 1.4953526258468628
Validation loss: 1.9685122966766357

Epoch: 6| Step: 4
Training loss: 1.4615784883499146
Validation loss: 1.9739773940014582

Epoch: 6| Step: 5
Training loss: 1.793859839439392
Validation loss: 1.9868518447363248

Epoch: 6| Step: 6
Training loss: 2.401803970336914
Validation loss: 1.9734754100922616

Epoch: 6| Step: 7
Training loss: 2.016934394836426
Validation loss: 1.9856559127889655

Epoch: 6| Step: 8
Training loss: 2.4065048694610596
Validation loss: 1.9948082149669688

Epoch: 6| Step: 9
Training loss: 1.7481939792633057
Validation loss: 2.0088400494667793

Epoch: 6| Step: 10
Training loss: 1.6128274202346802
Validation loss: 2.01154435834577

Epoch: 6| Step: 11
Training loss: 1.7965505123138428
Validation loss: 2.0195447411588443

Epoch: 6| Step: 12
Training loss: 1.8115274906158447
Validation loss: 2.029768955323004

Epoch: 6| Step: 13
Training loss: 1.7326422929763794
Validation loss: 2.0188168902550974

Epoch: 180| Step: 0
Training loss: 1.5056389570236206
Validation loss: 2.028491917476859

Epoch: 6| Step: 1
Training loss: 2.161998748779297
Validation loss: 2.0004273409484536

Epoch: 6| Step: 2
Training loss: 1.2638098001480103
Validation loss: 1.9657023991307905

Epoch: 6| Step: 3
Training loss: 1.695648431777954
Validation loss: 1.9475837958756315

Epoch: 6| Step: 4
Training loss: 1.793379783630371
Validation loss: 1.936902876823179

Epoch: 6| Step: 5
Training loss: 1.8250056505203247
Validation loss: 1.9432572459661832

Epoch: 6| Step: 6
Training loss: 2.399637222290039
Validation loss: 1.9768151749846756

Epoch: 6| Step: 7
Training loss: 1.4958608150482178
Validation loss: 1.9890497858806322

Epoch: 6| Step: 8
Training loss: 1.6358323097229004
Validation loss: 2.004706344296855

Epoch: 6| Step: 9
Training loss: 1.7394609451293945
Validation loss: 2.0051163704164567

Epoch: 6| Step: 10
Training loss: 1.524031400680542
Validation loss: 2.010447455990699

Epoch: 6| Step: 11
Training loss: 2.0214645862579346
Validation loss: 2.032971742332623

Epoch: 6| Step: 12
Training loss: 1.9304286241531372
Validation loss: 2.035741083083614

Epoch: 6| Step: 13
Training loss: 2.4571306705474854
Validation loss: 2.0309457945567306

Epoch: 181| Step: 0
Training loss: 1.5682920217514038
Validation loss: 2.0198352131792294

Epoch: 6| Step: 1
Training loss: 1.6188950538635254
Validation loss: 2.012348367321876

Epoch: 6| Step: 2
Training loss: 1.990260124206543
Validation loss: 2.0232932606051044

Epoch: 6| Step: 3
Training loss: 1.5419611930847168
Validation loss: 1.997534458355237

Epoch: 6| Step: 4
Training loss: 1.4224207401275635
Validation loss: 1.9802915280865085

Epoch: 6| Step: 5
Training loss: 1.8532614707946777
Validation loss: 2.000222603480021

Epoch: 6| Step: 6
Training loss: 1.8509896993637085
Validation loss: 2.004053161990258

Epoch: 6| Step: 7
Training loss: 2.302502155303955
Validation loss: 2.034106836524061

Epoch: 6| Step: 8
Training loss: 1.63265061378479
Validation loss: 2.0908980061930995

Epoch: 6| Step: 9
Training loss: 2.5577187538146973
Validation loss: 2.144882604640017

Epoch: 6| Step: 10
Training loss: 2.1048593521118164
Validation loss: 2.130414811513757

Epoch: 6| Step: 11
Training loss: 1.481446623802185
Validation loss: 2.0877349145950808

Epoch: 6| Step: 12
Training loss: 2.222468852996826
Validation loss: 2.0219611288398824

Epoch: 6| Step: 13
Training loss: 1.251452922821045
Validation loss: 2.0104585834728774

Epoch: 182| Step: 0
Training loss: 2.2176854610443115
Validation loss: 2.011535167694092

Epoch: 6| Step: 1
Training loss: 1.8264440298080444
Validation loss: 2.0001800060272217

Epoch: 6| Step: 2
Training loss: 2.10302734375
Validation loss: 2.000973338721901

Epoch: 6| Step: 3
Training loss: 1.612949013710022
Validation loss: 2.011165044640982

Epoch: 6| Step: 4
Training loss: 1.3026173114776611
Validation loss: 1.9864279377845027

Epoch: 6| Step: 5
Training loss: 1.2101203203201294
Validation loss: 1.9931117744855984

Epoch: 6| Step: 6
Training loss: 1.5468473434448242
Validation loss: 1.9945947201021257

Epoch: 6| Step: 7
Training loss: 2.033707857131958
Validation loss: 1.9992807501105851

Epoch: 6| Step: 8
Training loss: 1.7112312316894531
Validation loss: 2.0065369349654003

Epoch: 6| Step: 9
Training loss: 1.4202494621276855
Validation loss: 2.0275854038935837

Epoch: 6| Step: 10
Training loss: 1.6903724670410156
Validation loss: 2.064733182230303

Epoch: 6| Step: 11
Training loss: 2.978884696960449
Validation loss: 2.0747516052697295

Epoch: 6| Step: 12
Training loss: 1.114657998085022
Validation loss: 2.081001081774312

Epoch: 6| Step: 13
Training loss: 2.2710928916931152
Validation loss: 2.070114529261025

Epoch: 183| Step: 0
Training loss: 1.3639436960220337
Validation loss: 2.0688674860103156

Epoch: 6| Step: 1
Training loss: 1.8698025941848755
Validation loss: 2.072751070863457

Epoch: 6| Step: 2
Training loss: 1.627572774887085
Validation loss: 2.075907516223128

Epoch: 6| Step: 3
Training loss: 1.2862862348556519
Validation loss: 2.102448841576935

Epoch: 6| Step: 4
Training loss: 2.018585205078125
Validation loss: 2.1027859205840738

Epoch: 6| Step: 5
Training loss: 1.9148855209350586
Validation loss: 2.117401356338173

Epoch: 6| Step: 6
Training loss: 2.115631580352783
Validation loss: 2.099671635576474

Epoch: 6| Step: 7
Training loss: 1.9941624402999878
Validation loss: 2.0628273846000753

Epoch: 6| Step: 8
Training loss: 1.6515393257141113
Validation loss: 2.0397952025936497

Epoch: 6| Step: 9
Training loss: 1.7044527530670166
Validation loss: 1.998964245601367

Epoch: 6| Step: 10
Training loss: 1.7860796451568604
Validation loss: 1.9873757131638066

Epoch: 6| Step: 11
Training loss: 1.6927859783172607
Validation loss: 1.9895394284238097

Epoch: 6| Step: 12
Training loss: 1.5351176261901855
Validation loss: 2.0031796757892897

Epoch: 6| Step: 13
Training loss: 2.666532516479492
Validation loss: 1.9836548579636442

Epoch: 184| Step: 0
Training loss: 2.1969614028930664
Validation loss: 1.9475372965617845

Epoch: 6| Step: 1
Training loss: 1.5758644342422485
Validation loss: 1.915533293959915

Epoch: 6| Step: 2
Training loss: 1.420474648475647
Validation loss: 1.928328493589996

Epoch: 6| Step: 3
Training loss: 2.183478832244873
Validation loss: 1.9216687448563115

Epoch: 6| Step: 4
Training loss: 2.004901885986328
Validation loss: 1.9109678422251055

Epoch: 6| Step: 5
Training loss: 2.319434642791748
Validation loss: 1.9224194890709334

Epoch: 6| Step: 6
Training loss: 1.6296272277832031
Validation loss: 1.951621529876545

Epoch: 6| Step: 7
Training loss: 2.1833138465881348
Validation loss: 1.9683788386724328

Epoch: 6| Step: 8
Training loss: 1.624274492263794
Validation loss: 1.9801024647169216

Epoch: 6| Step: 9
Training loss: 1.7954169511795044
Validation loss: 2.012233864876532

Epoch: 6| Step: 10
Training loss: 1.5504356622695923
Validation loss: 2.0343738396962485

Epoch: 6| Step: 11
Training loss: 1.4781811237335205
Validation loss: 2.0641141655624553

Epoch: 6| Step: 12
Training loss: 1.1879117488861084
Validation loss: 2.1026635118710097

Epoch: 6| Step: 13
Training loss: 1.6872409582138062
Validation loss: 2.1250233368207048

Epoch: 185| Step: 0
Training loss: 2.05901837348938
Validation loss: 2.1097356709100867

Epoch: 6| Step: 1
Training loss: 1.478005290031433
Validation loss: 2.1175266017195997

Epoch: 6| Step: 2
Training loss: 1.8465876579284668
Validation loss: 2.1177311020512737

Epoch: 6| Step: 3
Training loss: 0.8876969814300537
Validation loss: 2.0914312665180494

Epoch: 6| Step: 4
Training loss: 1.3360008001327515
Validation loss: 2.0606589765958887

Epoch: 6| Step: 5
Training loss: 1.4922679662704468
Validation loss: 2.0212992109278196

Epoch: 6| Step: 6
Training loss: 1.7912704944610596
Validation loss: 2.0101391923043037

Epoch: 6| Step: 7
Training loss: 2.315214157104492
Validation loss: 2.003127348038458

Epoch: 6| Step: 8
Training loss: 1.3367069959640503
Validation loss: 2.0154229338451097

Epoch: 6| Step: 9
Training loss: 2.2425594329833984
Validation loss: 1.9796826698446786

Epoch: 6| Step: 10
Training loss: 1.4073638916015625
Validation loss: 1.9899736271109632

Epoch: 6| Step: 11
Training loss: 1.4250117540359497
Validation loss: 1.9766901475127026

Epoch: 6| Step: 12
Training loss: 2.2988040447235107
Validation loss: 1.9631539365296722

Epoch: 6| Step: 13
Training loss: 3.074537515640259
Validation loss: 1.9906375767082296

Epoch: 186| Step: 0
Training loss: 1.9136180877685547
Validation loss: 1.9907592099200013

Epoch: 6| Step: 1
Training loss: 2.0022854804992676
Validation loss: 1.97770510437668

Epoch: 6| Step: 2
Training loss: 1.216737985610962
Validation loss: 2.0173121216476604

Epoch: 6| Step: 3
Training loss: 2.189215898513794
Validation loss: 2.038016214165636

Epoch: 6| Step: 4
Training loss: 1.9591858386993408
Validation loss: 2.029981666995633

Epoch: 6| Step: 5
Training loss: 0.9328750371932983
Validation loss: 2.034476125112144

Epoch: 6| Step: 6
Training loss: 1.8526036739349365
Validation loss: 2.0266825704164404

Epoch: 6| Step: 7
Training loss: 1.4527020454406738
Validation loss: 2.0110003525210964

Epoch: 6| Step: 8
Training loss: 1.6871055364608765
Validation loss: 2.0224726251376572

Epoch: 6| Step: 9
Training loss: 1.319854497909546
Validation loss: 2.0245930994710615

Epoch: 6| Step: 10
Training loss: 1.655601978302002
Validation loss: 1.9993297207740046

Epoch: 6| Step: 11
Training loss: 2.079859733581543
Validation loss: 2.0192830126772643

Epoch: 6| Step: 12
Training loss: 2.0981407165527344
Validation loss: 2.009501003449963

Epoch: 6| Step: 13
Training loss: 2.3641064167022705
Validation loss: 1.9949402129778298

Epoch: 187| Step: 0
Training loss: 1.6054627895355225
Validation loss: 2.0360434568056496

Epoch: 6| Step: 1
Training loss: 2.0164434909820557
Validation loss: 2.0461125655840804

Epoch: 6| Step: 2
Training loss: 1.5123374462127686
Validation loss: 2.075420098920022

Epoch: 6| Step: 3
Training loss: 1.9511513710021973
Validation loss: 2.108843490641604

Epoch: 6| Step: 4
Training loss: 1.6864290237426758
Validation loss: 2.1187995121043217

Epoch: 6| Step: 5
Training loss: 1.7757195234298706
Validation loss: 2.104236443837484

Epoch: 6| Step: 6
Training loss: 1.6514296531677246
Validation loss: 2.061991000688204

Epoch: 6| Step: 7
Training loss: 1.4729299545288086
Validation loss: 2.033344118825851

Epoch: 6| Step: 8
Training loss: 1.2702473402023315
Validation loss: 2.035832121808042

Epoch: 6| Step: 9
Training loss: 2.0845537185668945
Validation loss: 2.0273076590671333

Epoch: 6| Step: 10
Training loss: 2.2318782806396484
Validation loss: 1.999036891486055

Epoch: 6| Step: 11
Training loss: 1.9864002466201782
Validation loss: 1.9979065874571442

Epoch: 6| Step: 12
Training loss: 1.4282574653625488
Validation loss: 1.9652100993740944

Epoch: 6| Step: 13
Training loss: 1.533818244934082
Validation loss: 1.9672218112535373

Epoch: 188| Step: 0
Training loss: 2.2334697246551514
Validation loss: 1.957496904557751

Epoch: 6| Step: 1
Training loss: 1.4953937530517578
Validation loss: 1.964209783461786

Epoch: 6| Step: 2
Training loss: 1.9299489259719849
Validation loss: 1.959717437785159

Epoch: 6| Step: 3
Training loss: 2.152583122253418
Validation loss: 1.9607258483927736

Epoch: 6| Step: 4
Training loss: 1.4402940273284912
Validation loss: 1.9617380172975603

Epoch: 6| Step: 5
Training loss: 2.2295331954956055
Validation loss: 1.9617635614128524

Epoch: 6| Step: 6
Training loss: 1.9260327816009521
Validation loss: 1.941983679289459

Epoch: 6| Step: 7
Training loss: 1.0954724550247192
Validation loss: 1.930100158978534

Epoch: 6| Step: 8
Training loss: 1.34463369846344
Validation loss: 1.9230934868576706

Epoch: 6| Step: 9
Training loss: 0.974916934967041
Validation loss: 1.9361074047703897

Epoch: 6| Step: 10
Training loss: 1.5766125917434692
Validation loss: 1.9512672757589689

Epoch: 6| Step: 11
Training loss: 1.9973235130310059
Validation loss: 1.9923045930042063

Epoch: 6| Step: 12
Training loss: 1.6350181102752686
Validation loss: 2.0084574735292824

Epoch: 6| Step: 13
Training loss: 2.414426565170288
Validation loss: 2.0251139120389055

Epoch: 189| Step: 0
Training loss: 2.5216808319091797
Validation loss: 2.072818153647966

Epoch: 6| Step: 1
Training loss: 1.2767008543014526
Validation loss: 2.101415088099818

Epoch: 6| Step: 2
Training loss: 2.0111002922058105
Validation loss: 2.0540192332319034

Epoch: 6| Step: 3
Training loss: 1.6740608215332031
Validation loss: 2.067277531470022

Epoch: 6| Step: 4
Training loss: 1.100731372833252
Validation loss: 2.037971019744873

Epoch: 6| Step: 5
Training loss: 1.5289485454559326
Validation loss: 2.033826894657586

Epoch: 6| Step: 6
Training loss: 1.6244664192199707
Validation loss: 2.035713234255391

Epoch: 6| Step: 7
Training loss: 1.9985101222991943
Validation loss: 2.0433992057718258

Epoch: 6| Step: 8
Training loss: 1.509474515914917
Validation loss: 2.0526508720972205

Epoch: 6| Step: 9
Training loss: 1.3911114931106567
Validation loss: 2.064987987600347

Epoch: 6| Step: 10
Training loss: 2.124779224395752
Validation loss: 2.0507044920357327

Epoch: 6| Step: 11
Training loss: 1.9201563596725464
Validation loss: 2.037520800867388

Epoch: 6| Step: 12
Training loss: 2.0732388496398926
Validation loss: 2.039727812172264

Epoch: 6| Step: 13
Training loss: 1.3772034645080566
Validation loss: 2.0223149150930424

Epoch: 190| Step: 0
Training loss: 1.9819443225860596
Validation loss: 2.023791333680512

Epoch: 6| Step: 1
Training loss: 1.727421522140503
Validation loss: 1.9961357193608438

Epoch: 6| Step: 2
Training loss: 1.7101774215698242
Validation loss: 1.9725614516965804

Epoch: 6| Step: 3
Training loss: 1.6355799436569214
Validation loss: 1.9454201344520814

Epoch: 6| Step: 4
Training loss: 1.7255041599273682
Validation loss: 1.9498850914739794

Epoch: 6| Step: 5
Training loss: 1.5077276229858398
Validation loss: 1.9753367977757608

Epoch: 6| Step: 6
Training loss: 1.6284968852996826
Validation loss: 1.9572898559672858

Epoch: 6| Step: 7
Training loss: 1.7174568176269531
Validation loss: 1.980714782591789

Epoch: 6| Step: 8
Training loss: 1.7740365266799927
Validation loss: 1.9949186937783354

Epoch: 6| Step: 9
Training loss: 1.601398229598999
Validation loss: 2.046110940235917

Epoch: 6| Step: 10
Training loss: 2.037487506866455
Validation loss: 2.0730089038930912

Epoch: 6| Step: 11
Training loss: 1.199872612953186
Validation loss: 2.0891899293468845

Epoch: 6| Step: 12
Training loss: 2.256439685821533
Validation loss: 2.0901665200469313

Epoch: 6| Step: 13
Training loss: 1.8988778591156006
Validation loss: 2.078174155245545

Epoch: 191| Step: 0
Training loss: 1.5007001161575317
Validation loss: 2.057927785381194

Epoch: 6| Step: 1
Training loss: 1.2806310653686523
Validation loss: 2.025773311174044

Epoch: 6| Step: 2
Training loss: 1.9965300559997559
Validation loss: 2.0283355277071715

Epoch: 6| Step: 3
Training loss: 1.484879970550537
Validation loss: 2.0215395958192888

Epoch: 6| Step: 4
Training loss: 2.0467257499694824
Validation loss: 2.0190363468662387

Epoch: 6| Step: 5
Training loss: 1.503833532333374
Validation loss: 2.001104034403319

Epoch: 6| Step: 6
Training loss: 1.6679878234863281
Validation loss: 1.9902509002275364

Epoch: 6| Step: 7
Training loss: 1.6171352863311768
Validation loss: 1.9860648211612497

Epoch: 6| Step: 8
Training loss: 1.6075389385223389
Validation loss: 1.987158267728744

Epoch: 6| Step: 9
Training loss: 1.733886957168579
Validation loss: 1.9847485993498115

Epoch: 6| Step: 10
Training loss: 1.2300766706466675
Validation loss: 2.005401243445694

Epoch: 6| Step: 11
Training loss: 2.4553160667419434
Validation loss: 1.9927870688899871

Epoch: 6| Step: 12
Training loss: 1.5742018222808838
Validation loss: 1.9932051115138556

Epoch: 6| Step: 13
Training loss: 1.378770112991333
Validation loss: 2.010971451318392

Epoch: 192| Step: 0
Training loss: 1.7336721420288086
Validation loss: 2.0243522274878716

Epoch: 6| Step: 1
Training loss: 1.2786802053451538
Validation loss: 2.026042874141406

Epoch: 6| Step: 2
Training loss: 1.31963050365448
Validation loss: 2.0257944163455757

Epoch: 6| Step: 3
Training loss: 2.3457891941070557
Validation loss: 2.0287084374376523

Epoch: 6| Step: 4
Training loss: 1.54520583152771
Validation loss: 2.0510759276728474

Epoch: 6| Step: 5
Training loss: 2.1599817276000977
Validation loss: 2.05176955141047

Epoch: 6| Step: 6
Training loss: 1.8235969543457031
Validation loss: 2.0463341897533787

Epoch: 6| Step: 7
Training loss: 1.575147032737732
Validation loss: 2.0619733333587646

Epoch: 6| Step: 8
Training loss: 1.2277591228485107
Validation loss: 2.0661246110034246

Epoch: 6| Step: 9
Training loss: 1.6267974376678467
Validation loss: 2.055291268133348

Epoch: 6| Step: 10
Training loss: 1.4631829261779785
Validation loss: 2.0377270342201315

Epoch: 6| Step: 11
Training loss: 1.758231520652771
Validation loss: 2.0223075702626216

Epoch: 6| Step: 12
Training loss: 1.0292835235595703
Validation loss: 2.0328890738948697

Epoch: 6| Step: 13
Training loss: 1.67681884765625
Validation loss: 2.025745625137001

Epoch: 193| Step: 0
Training loss: 1.5062230825424194
Validation loss: 2.0558585454058904

Epoch: 6| Step: 1
Training loss: 2.103078842163086
Validation loss: 2.0581870848132717

Epoch: 6| Step: 2
Training loss: 1.4158351421356201
Validation loss: 2.070825284527194

Epoch: 6| Step: 3
Training loss: 1.697097659111023
Validation loss: 2.0944698651631675

Epoch: 6| Step: 4
Training loss: 1.579829454421997
Validation loss: 2.1100212899587487

Epoch: 6| Step: 5
Training loss: 1.448761224746704
Validation loss: 2.097160534192157

Epoch: 6| Step: 6
Training loss: 1.8845078945159912
Validation loss: 2.095291337659282

Epoch: 6| Step: 7
Training loss: 1.477144479751587
Validation loss: 2.080267637006698

Epoch: 6| Step: 8
Training loss: 1.8930282592773438
Validation loss: 2.060626777269507

Epoch: 6| Step: 9
Training loss: 1.5758711099624634
Validation loss: 2.0478531673390377

Epoch: 6| Step: 10
Training loss: 1.5941717624664307
Validation loss: 2.0320379170038367

Epoch: 6| Step: 11
Training loss: 0.8469951152801514
Validation loss: 2.0151298610113

Epoch: 6| Step: 12
Training loss: 1.9353805780410767
Validation loss: 2.0073286141118696

Epoch: 6| Step: 13
Training loss: 1.4332575798034668
Validation loss: 1.9893250311574628

Epoch: 194| Step: 0
Training loss: 1.3337182998657227
Validation loss: 1.980898872498543

Epoch: 6| Step: 1
Training loss: 1.6024339199066162
Validation loss: 1.9937814538196852

Epoch: 6| Step: 2
Training loss: 1.8206950426101685
Validation loss: 1.9804035438004362

Epoch: 6| Step: 3
Training loss: 1.7384543418884277
Validation loss: 2.0012966958425378

Epoch: 6| Step: 4
Training loss: 1.9008755683898926
Validation loss: 2.006360815417382

Epoch: 6| Step: 5
Training loss: 1.45082426071167
Validation loss: 2.0464149149515296

Epoch: 6| Step: 6
Training loss: 2.172788143157959
Validation loss: 2.0544176793867543

Epoch: 6| Step: 7
Training loss: 2.099506378173828
Validation loss: 2.0599798797279276

Epoch: 6| Step: 8
Training loss: 1.108972191810608
Validation loss: 2.0393685525463474

Epoch: 6| Step: 9
Training loss: 1.3546768426895142
Validation loss: 2.060893876578218

Epoch: 6| Step: 10
Training loss: 1.4365631341934204
Validation loss: 2.042127715644016

Epoch: 6| Step: 11
Training loss: 1.1170616149902344
Validation loss: 2.044002567568133

Epoch: 6| Step: 12
Training loss: 1.7210079431533813
Validation loss: 2.030256509780884

Epoch: 6| Step: 13
Training loss: 1.3582515716552734
Validation loss: 2.029249334848055

Epoch: 195| Step: 0
Training loss: 1.4443933963775635
Validation loss: 1.9934742501986924

Epoch: 6| Step: 1
Training loss: 1.9765931367874146
Validation loss: 1.9671351486636746

Epoch: 6| Step: 2
Training loss: 1.3173487186431885
Validation loss: 1.9508935123361566

Epoch: 6| Step: 3
Training loss: 1.4422581195831299
Validation loss: 1.9309325192564277

Epoch: 6| Step: 4
Training loss: 1.8004614114761353
Validation loss: 1.9192946444275558

Epoch: 6| Step: 5
Training loss: 2.2451961040496826
Validation loss: 1.9135268759983841

Epoch: 6| Step: 6
Training loss: 1.796982765197754
Validation loss: 1.9076935937327724

Epoch: 6| Step: 7
Training loss: 2.0064852237701416
Validation loss: 1.9141851881498932

Epoch: 6| Step: 8
Training loss: 1.3917434215545654
Validation loss: 1.9520337812362178

Epoch: 6| Step: 9
Training loss: 1.289711356163025
Validation loss: 1.9860364160230082

Epoch: 6| Step: 10
Training loss: 0.9037274122238159
Validation loss: 2.0177424774375012

Epoch: 6| Step: 11
Training loss: 2.3357810974121094
Validation loss: 2.0269530473216886

Epoch: 6| Step: 12
Training loss: 1.3885443210601807
Validation loss: 2.0641546710844962

Epoch: 6| Step: 13
Training loss: 1.9920531511306763
Validation loss: 2.078197971467049

Epoch: 196| Step: 0
Training loss: 1.2807480096817017
Validation loss: 2.079844485047043

Epoch: 6| Step: 1
Training loss: 1.61211097240448
Validation loss: 2.060805889867967

Epoch: 6| Step: 2
Training loss: 2.0049593448638916
Validation loss: 2.0759534656360583

Epoch: 6| Step: 3
Training loss: 1.765735149383545
Validation loss: 2.068071944739229

Epoch: 6| Step: 4
Training loss: 1.2912238836288452
Validation loss: 2.051633334928943

Epoch: 6| Step: 5
Training loss: 1.4270319938659668
Validation loss: 2.054488915269093

Epoch: 6| Step: 6
Training loss: 1.0612125396728516
Validation loss: 2.0577818014288463

Epoch: 6| Step: 7
Training loss: 2.190469264984131
Validation loss: 2.0772277001411683

Epoch: 6| Step: 8
Training loss: 1.5595022439956665
Validation loss: 2.084519427309754

Epoch: 6| Step: 9
Training loss: 1.5982327461242676
Validation loss: 2.052883791667159

Epoch: 6| Step: 10
Training loss: 1.4565584659576416
Validation loss: 2.039697754767633

Epoch: 6| Step: 11
Training loss: 1.8124126195907593
Validation loss: 2.05512834108004

Epoch: 6| Step: 12
Training loss: 1.9334759712219238
Validation loss: 2.0668987407479236

Epoch: 6| Step: 13
Training loss: 2.0282702445983887
Validation loss: 2.0333087572487454

Epoch: 197| Step: 0
Training loss: 2.0366640090942383
Validation loss: 2.0153768882956555

Epoch: 6| Step: 1
Training loss: 1.5335297584533691
Validation loss: 2.017952307578056

Epoch: 6| Step: 2
Training loss: 1.7612156867980957
Validation loss: 2.036221011992424

Epoch: 6| Step: 3
Training loss: 1.532440423965454
Validation loss: 2.049474790532102

Epoch: 6| Step: 4
Training loss: 1.4796874523162842
Validation loss: 2.0647221701119536

Epoch: 6| Step: 5
Training loss: 0.9508083462715149
Validation loss: 2.0579676602476384

Epoch: 6| Step: 6
Training loss: 1.7572945356369019
Validation loss: 2.055375999019992

Epoch: 6| Step: 7
Training loss: 0.9035066962242126
Validation loss: 2.0459855500087945

Epoch: 6| Step: 8
Training loss: 1.5434033870697021
Validation loss: 2.034103911410096

Epoch: 6| Step: 9
Training loss: 2.0310909748077393
Validation loss: 2.0679188748841644

Epoch: 6| Step: 10
Training loss: 1.7525959014892578
Validation loss: 2.1094392999525993

Epoch: 6| Step: 11
Training loss: 1.5720980167388916
Validation loss: 2.1217581469525575

Epoch: 6| Step: 12
Training loss: 1.644841194152832
Validation loss: 2.1008511666328675

Epoch: 6| Step: 13
Training loss: 1.6621156930923462
Validation loss: 2.0924938263431674

Epoch: 198| Step: 0
Training loss: 2.1721484661102295
Validation loss: 2.06059665577386

Epoch: 6| Step: 1
Training loss: 1.4988455772399902
Validation loss: 2.0534956070684616

Epoch: 6| Step: 2
Training loss: 1.4780733585357666
Validation loss: 2.0393038231839418

Epoch: 6| Step: 3
Training loss: 1.4343171119689941
Validation loss: 2.044323085456766

Epoch: 6| Step: 4
Training loss: 1.724107265472412
Validation loss: 2.0625765759457826

Epoch: 6| Step: 5
Training loss: 1.9226124286651611
Validation loss: 2.065429772100141

Epoch: 6| Step: 6
Training loss: 1.0054432153701782
Validation loss: 2.0368341489504744

Epoch: 6| Step: 7
Training loss: 1.910494327545166
Validation loss: 2.019674872839323

Epoch: 6| Step: 8
Training loss: 1.3369202613830566
Validation loss: 1.9850375652313232

Epoch: 6| Step: 9
Training loss: 1.2879469394683838
Validation loss: 2.002181714580905

Epoch: 6| Step: 10
Training loss: 1.9429301023483276
Validation loss: 1.9934753987096971

Epoch: 6| Step: 11
Training loss: 1.706225037574768
Validation loss: 2.01475663082574

Epoch: 6| Step: 12
Training loss: 1.2210313081741333
Validation loss: 2.0203931177816083

Epoch: 6| Step: 13
Training loss: 2.112349510192871
Validation loss: 2.0527434272150837

Epoch: 199| Step: 0
Training loss: 1.4932010173797607
Validation loss: 2.030362897021796

Epoch: 6| Step: 1
Training loss: 1.4913398027420044
Validation loss: 2.0282125639659103

Epoch: 6| Step: 2
Training loss: 1.8351707458496094
Validation loss: 2.0084485251416444

Epoch: 6| Step: 3
Training loss: 1.7446300983428955
Validation loss: 2.0266789364558395

Epoch: 6| Step: 4
Training loss: 1.5024954080581665
Validation loss: 2.0173248937053065

Epoch: 6| Step: 5
Training loss: 1.4232585430145264
Validation loss: 2.022565593001663

Epoch: 6| Step: 6
Training loss: 1.2910224199295044
Validation loss: 2.0072078422833513

Epoch: 6| Step: 7
Training loss: 1.84609055519104
Validation loss: 1.983037881953742

Epoch: 6| Step: 8
Training loss: 2.019308090209961
Validation loss: 1.9839931585455453

Epoch: 6| Step: 9
Training loss: 1.6312017440795898
Validation loss: 1.9694774984031596

Epoch: 6| Step: 10
Training loss: 1.237768530845642
Validation loss: 1.9846879243850708

Epoch: 6| Step: 11
Training loss: 1.6327574253082275
Validation loss: 1.999824971281072

Epoch: 6| Step: 12
Training loss: 1.1845431327819824
Validation loss: 2.014942164062172

Epoch: 6| Step: 13
Training loss: 1.7842764854431152
Validation loss: 2.0281263577040805

Epoch: 200| Step: 0
Training loss: 1.56659734249115
Validation loss: 2.051636449752315

Epoch: 6| Step: 1
Training loss: 1.0209425687789917
Validation loss: 2.066591057726132

Epoch: 6| Step: 2
Training loss: 2.2603726387023926
Validation loss: 2.1176124977809128

Epoch: 6| Step: 3
Training loss: 1.2346681356430054
Validation loss: 2.0934702093883226

Epoch: 6| Step: 4
Training loss: 1.7149779796600342
Validation loss: 2.0786042290349163

Epoch: 6| Step: 5
Training loss: 1.7480297088623047
Validation loss: 2.075866068563154

Epoch: 6| Step: 6
Training loss: 1.57201087474823
Validation loss: 2.073432143016528

Epoch: 6| Step: 7
Training loss: 1.9880578517913818
Validation loss: 2.0555824810458767

Epoch: 6| Step: 8
Training loss: 1.6304610967636108
Validation loss: 2.0416099717540126

Epoch: 6| Step: 9
Training loss: 1.1663570404052734
Validation loss: 2.016762638604769

Epoch: 6| Step: 10
Training loss: 1.5686684846878052
Validation loss: 1.9946494179387246

Epoch: 6| Step: 11
Training loss: 1.2841463088989258
Validation loss: 1.9752425173277497

Epoch: 6| Step: 12
Training loss: 1.4580304622650146
Validation loss: 1.9895646469567412

Epoch: 6| Step: 13
Training loss: 0.962640106678009
Validation loss: 2.000977487974269

Epoch: 201| Step: 0
Training loss: 2.062981367111206
Validation loss: 1.9907198798271917

Epoch: 6| Step: 1
Training loss: 1.542494535446167
Validation loss: 1.9899756946871359

Epoch: 6| Step: 2
Training loss: 1.0699036121368408
Validation loss: 1.9667044211459417

Epoch: 6| Step: 3
Training loss: 1.5492846965789795
Validation loss: 1.9616947404799923

Epoch: 6| Step: 4
Training loss: 1.5291261672973633
Validation loss: 1.964905277375252

Epoch: 6| Step: 5
Training loss: 1.0386037826538086
Validation loss: 1.9819481706106534

Epoch: 6| Step: 6
Training loss: 1.685664415359497
Validation loss: 2.0150475681469007

Epoch: 6| Step: 7
Training loss: 1.993203043937683
Validation loss: 2.056319316228231

Epoch: 6| Step: 8
Training loss: 1.266513705253601
Validation loss: 2.0735720588314916

Epoch: 6| Step: 9
Training loss: 1.0587600469589233
Validation loss: 2.1024596537313154

Epoch: 6| Step: 10
Training loss: 1.6921546459197998
Validation loss: 2.164698980187857

Epoch: 6| Step: 11
Training loss: 1.4037833213806152
Validation loss: 2.106302697171447

Epoch: 6| Step: 12
Training loss: 2.056331157684326
Validation loss: 2.097184609341365

Epoch: 6| Step: 13
Training loss: 1.240455150604248
Validation loss: 2.096790022747491

Epoch: 202| Step: 0
Training loss: 1.5727990865707397
Validation loss: 2.0613850880694646

Epoch: 6| Step: 1
Training loss: 1.2420060634613037
Validation loss: 2.074598995588159

Epoch: 6| Step: 2
Training loss: 1.3902226686477661
Validation loss: 2.088639736175537

Epoch: 6| Step: 3
Training loss: 1.411689281463623
Validation loss: 2.049082412514635

Epoch: 6| Step: 4
Training loss: 1.602750301361084
Validation loss: 2.058777391269643

Epoch: 6| Step: 5
Training loss: 1.8777823448181152
Validation loss: 2.0242093404134116

Epoch: 6| Step: 6
Training loss: 1.1378096342086792
Validation loss: 2.0028306617531726

Epoch: 6| Step: 7
Training loss: 2.134713649749756
Validation loss: 1.9874013072700911

Epoch: 6| Step: 8
Training loss: 1.0033130645751953
Validation loss: 1.9720374973871375

Epoch: 6| Step: 9
Training loss: 1.165891408920288
Validation loss: 1.9761306880622782

Epoch: 6| Step: 10
Training loss: 1.18452787399292
Validation loss: 1.9862819243502874

Epoch: 6| Step: 11
Training loss: 1.6371898651123047
Validation loss: 1.9826695265308503

Epoch: 6| Step: 12
Training loss: 2.0175747871398926
Validation loss: 2.008771075997301

Epoch: 6| Step: 13
Training loss: 1.0936338901519775
Validation loss: 1.9726500972624748

Epoch: 203| Step: 0
Training loss: 2.2026143074035645
Validation loss: 2.025830785433451

Epoch: 6| Step: 1
Training loss: 1.9679211378097534
Validation loss: 2.048885988932784

Epoch: 6| Step: 2
Training loss: 0.9588115215301514
Validation loss: 2.0690937067872737

Epoch: 6| Step: 3
Training loss: 1.255813717842102
Validation loss: 2.068864537823585

Epoch: 6| Step: 4
Training loss: 1.1065925359725952
Validation loss: 2.0709576350386425

Epoch: 6| Step: 5
Training loss: 1.5155797004699707
Validation loss: 2.0544912622820948

Epoch: 6| Step: 6
Training loss: 2.1213035583496094
Validation loss: 2.033813888026822

Epoch: 6| Step: 7
Training loss: 1.6140775680541992
Validation loss: 2.016927315342811

Epoch: 6| Step: 8
Training loss: 0.8556432127952576
Validation loss: 2.008508483568827

Epoch: 6| Step: 9
Training loss: 1.8893578052520752
Validation loss: 1.994659029027467

Epoch: 6| Step: 10
Training loss: 1.6717228889465332
Validation loss: 1.9673214907287269

Epoch: 6| Step: 11
Training loss: 1.07503080368042
Validation loss: 2.012059514240552

Epoch: 6| Step: 12
Training loss: 1.4844540357589722
Validation loss: 2.0325400983133624

Epoch: 6| Step: 13
Training loss: 0.8892413377761841
Validation loss: 2.0344390382048902

Epoch: 204| Step: 0
Training loss: 1.509162425994873
Validation loss: 2.0352885774386826

Epoch: 6| Step: 1
Training loss: 1.9098855257034302
Validation loss: 2.052199121444456

Epoch: 6| Step: 2
Training loss: 1.3658058643341064
Validation loss: 2.0338815360940914

Epoch: 6| Step: 3
Training loss: 1.0555598735809326
Validation loss: 2.0299973423762987

Epoch: 6| Step: 4
Training loss: 1.2775903940200806
Validation loss: 2.01551192550249

Epoch: 6| Step: 5
Training loss: 1.1815284490585327
Validation loss: 2.02403433861271

Epoch: 6| Step: 6
Training loss: 1.286807656288147
Validation loss: 2.0327337928997573

Epoch: 6| Step: 7
Training loss: 1.3876820802688599
Validation loss: 2.0518798571760937

Epoch: 6| Step: 8
Training loss: 1.4285740852355957
Validation loss: 2.0438286873602096

Epoch: 6| Step: 9
Training loss: 1.1818543672561646
Validation loss: 2.03520703828463

Epoch: 6| Step: 10
Training loss: 2.061239242553711
Validation loss: 2.0332066987150457

Epoch: 6| Step: 11
Training loss: 1.4792776107788086
Validation loss: 2.0199002668421757

Epoch: 6| Step: 12
Training loss: 1.6855953931808472
Validation loss: 1.9963673084012923

Epoch: 6| Step: 13
Training loss: 1.3758045434951782
Validation loss: 1.9789771469690467

Epoch: 205| Step: 0
Training loss: 1.0782092809677124
Validation loss: 2.000535315082919

Epoch: 6| Step: 1
Training loss: 1.30662202835083
Validation loss: 1.9850403493450535

Epoch: 6| Step: 2
Training loss: 1.7200069427490234
Validation loss: 2.0141251394825597

Epoch: 6| Step: 3
Training loss: 1.5686084032058716
Validation loss: 2.007713387089391

Epoch: 6| Step: 4
Training loss: 1.223304271697998
Validation loss: 2.0111936317977084

Epoch: 6| Step: 5
Training loss: 1.0394654273986816
Validation loss: 2.032037906749274

Epoch: 6| Step: 6
Training loss: 1.6216132640838623
Validation loss: 2.051878306173509

Epoch: 6| Step: 7
Training loss: 1.3946311473846436
Validation loss: 2.066947397365365

Epoch: 6| Step: 8
Training loss: 1.3298898935317993
Validation loss: 2.040558999584567

Epoch: 6| Step: 9
Training loss: 1.6469240188598633
Validation loss: 2.047608583204208

Epoch: 6| Step: 10
Training loss: 1.1363978385925293
Validation loss: 2.0686673374586206

Epoch: 6| Step: 11
Training loss: 1.9517731666564941
Validation loss: 2.0650708765111943

Epoch: 6| Step: 12
Training loss: 1.548198938369751
Validation loss: 2.0482829950189076

Epoch: 6| Step: 13
Training loss: 1.6171549558639526
Validation loss: 2.025154426533689

Epoch: 206| Step: 0
Training loss: 1.345137596130371
Validation loss: 2.007258488285926

Epoch: 6| Step: 1
Training loss: 1.4489922523498535
Validation loss: 1.9920371809313375

Epoch: 6| Step: 2
Training loss: 1.1226682662963867
Validation loss: 1.976058013977543

Epoch: 6| Step: 3
Training loss: 1.507583737373352
Validation loss: 1.9972591861601798

Epoch: 6| Step: 4
Training loss: 1.5640357732772827
Validation loss: 1.9999081370651082

Epoch: 6| Step: 5
Training loss: 1.4796979427337646
Validation loss: 2.0131072946774062

Epoch: 6| Step: 6
Training loss: 0.6627587676048279
Validation loss: 2.0137654632650395

Epoch: 6| Step: 7
Training loss: 1.3373929262161255
Validation loss: 2.0201937165311588

Epoch: 6| Step: 8
Training loss: 0.9703983664512634
Validation loss: 2.0032407237637426

Epoch: 6| Step: 9
Training loss: 1.5540961027145386
Validation loss: 2.0073410593053347

Epoch: 6| Step: 10
Training loss: 1.6081374883651733
Validation loss: 2.0059808377296693

Epoch: 6| Step: 11
Training loss: 1.0381934642791748
Validation loss: 1.9830947511939592

Epoch: 6| Step: 12
Training loss: 2.210064172744751
Validation loss: 1.9812620685946556

Epoch: 6| Step: 13
Training loss: 2.6089298725128174
Validation loss: 1.9845452347109396

Epoch: 207| Step: 0
Training loss: 1.4105556011199951
Validation loss: 1.998069336337428

Epoch: 6| Step: 1
Training loss: 1.3489670753479004
Validation loss: 2.0290046097129903

Epoch: 6| Step: 2
Training loss: 1.2372016906738281
Validation loss: 2.0259089623728106

Epoch: 6| Step: 3
Training loss: 1.4051470756530762
Validation loss: 2.052842455525552

Epoch: 6| Step: 4
Training loss: 1.6837716102600098
Validation loss: 2.0949023244201497

Epoch: 6| Step: 5
Training loss: 1.2640894651412964
Validation loss: 2.0723278445582234

Epoch: 6| Step: 6
Training loss: 1.924566388130188
Validation loss: 2.0728513707396803

Epoch: 6| Step: 7
Training loss: 1.4597028493881226
Validation loss: 2.057962207384007

Epoch: 6| Step: 8
Training loss: 1.4450159072875977
Validation loss: 2.0191052549628803

Epoch: 6| Step: 9
Training loss: 1.5250561237335205
Validation loss: 1.9815665611656763

Epoch: 6| Step: 10
Training loss: 1.2900135517120361
Validation loss: 1.9679884577310214

Epoch: 6| Step: 11
Training loss: 1.6497410535812378
Validation loss: 1.9399533681972052

Epoch: 6| Step: 12
Training loss: 1.439436674118042
Validation loss: 1.926752854419011

Epoch: 6| Step: 13
Training loss: 1.4931185245513916
Validation loss: 1.9469439637276433

Epoch: 208| Step: 0
Training loss: 1.3393203020095825
Validation loss: 1.9580755669583556

Epoch: 6| Step: 1
Training loss: 1.0471079349517822
Validation loss: 1.9618487281184043

Epoch: 6| Step: 2
Training loss: 2.0012307167053223
Validation loss: 1.9750159863502748

Epoch: 6| Step: 3
Training loss: 1.044863224029541
Validation loss: 2.001995566070721

Epoch: 6| Step: 4
Training loss: 1.0618367195129395
Validation loss: 2.0282630125681558

Epoch: 6| Step: 5
Training loss: 1.6230841875076294
Validation loss: 2.0686651455458773

Epoch: 6| Step: 6
Training loss: 1.4678431749343872
Validation loss: 2.09526107388158

Epoch: 6| Step: 7
Training loss: 0.9865163564682007
Validation loss: 2.074945822838814

Epoch: 6| Step: 8
Training loss: 1.465666651725769
Validation loss: 2.0712967457309848

Epoch: 6| Step: 9
Training loss: 1.820408582687378
Validation loss: 2.070277681914709

Epoch: 6| Step: 10
Training loss: 1.8049728870391846
Validation loss: 2.0589247672788558

Epoch: 6| Step: 11
Training loss: 1.5299594402313232
Validation loss: 2.0447142854813607

Epoch: 6| Step: 12
Training loss: 1.103690266609192
Validation loss: 2.0079903512872677

Epoch: 6| Step: 13
Training loss: 1.9927679300308228
Validation loss: 2.004024710706485

Epoch: 209| Step: 0
Training loss: 1.0824297666549683
Validation loss: 2.000930731014539

Epoch: 6| Step: 1
Training loss: 1.9398651123046875
Validation loss: 2.029389235281175

Epoch: 6| Step: 2
Training loss: 1.9410251379013062
Validation loss: 2.00196538817498

Epoch: 6| Step: 3
Training loss: 1.1224148273468018
Validation loss: 2.0015719577830327

Epoch: 6| Step: 4
Training loss: 1.558631420135498
Validation loss: 2.008489174227561

Epoch: 6| Step: 5
Training loss: 1.5670497417449951
Validation loss: 1.9954302644216886

Epoch: 6| Step: 6
Training loss: 1.6378722190856934
Validation loss: 2.0063066867090042

Epoch: 6| Step: 7
Training loss: 1.3968533277511597
Validation loss: 2.010171882567867

Epoch: 6| Step: 8
Training loss: 1.428869605064392
Validation loss: 2.017554074205378

Epoch: 6| Step: 9
Training loss: 0.8114982843399048
Validation loss: 1.997189635871559

Epoch: 6| Step: 10
Training loss: 1.503199577331543
Validation loss: 2.033980449040731

Epoch: 6| Step: 11
Training loss: 1.4691967964172363
Validation loss: 2.0439857282946186

Epoch: 6| Step: 12
Training loss: 1.054505467414856
Validation loss: 2.0384732651454147

Epoch: 6| Step: 13
Training loss: 1.6979081630706787
Validation loss: 2.041877628654562

Epoch: 210| Step: 0
Training loss: 1.4645617008209229
Validation loss: 2.0321233964735463

Epoch: 6| Step: 1
Training loss: 1.1047102212905884
Validation loss: 2.0281891438268844

Epoch: 6| Step: 2
Training loss: 1.4030990600585938
Validation loss: 2.0226781778438117

Epoch: 6| Step: 3
Training loss: 2.6458587646484375
Validation loss: 2.009945688709136

Epoch: 6| Step: 4
Training loss: 1.4395287036895752
Validation loss: 1.983711968186081

Epoch: 6| Step: 5
Training loss: 1.5392682552337646
Validation loss: 1.9825824678585093

Epoch: 6| Step: 6
Training loss: 1.403250813484192
Validation loss: 1.9759823442787252

Epoch: 6| Step: 7
Training loss: 0.980513870716095
Validation loss: 1.972282176376671

Epoch: 6| Step: 8
Training loss: 1.640681505203247
Validation loss: 2.0092343514965427

Epoch: 6| Step: 9
Training loss: 1.3601710796356201
Validation loss: 2.0400045443606634

Epoch: 6| Step: 10
Training loss: 0.6060905456542969
Validation loss: 2.0312206386238016

Epoch: 6| Step: 11
Training loss: 1.2381330728530884
Validation loss: 2.0577011339126097

Epoch: 6| Step: 12
Training loss: 1.5302462577819824
Validation loss: 2.0453793182167956

Epoch: 6| Step: 13
Training loss: 1.2651299238204956
Validation loss: 2.051742874166017

Epoch: 211| Step: 0
Training loss: 1.4531259536743164
Validation loss: 2.083008966138286

Epoch: 6| Step: 1
Training loss: 1.8458099365234375
Validation loss: 2.103003971038326

Epoch: 6| Step: 2
Training loss: 1.2553856372833252
Validation loss: 2.0997202409211027

Epoch: 6| Step: 3
Training loss: 1.8808958530426025
Validation loss: 2.056496456105222

Epoch: 6| Step: 4
Training loss: 1.2275187969207764
Validation loss: 2.0167040324980214

Epoch: 6| Step: 5
Training loss: 0.8445420265197754
Validation loss: 2.009860405357935

Epoch: 6| Step: 6
Training loss: 0.9247697591781616
Validation loss: 2.0038963248652797

Epoch: 6| Step: 7
Training loss: 1.2135560512542725
Validation loss: 2.01184533872912

Epoch: 6| Step: 8
Training loss: 1.0384883880615234
Validation loss: 2.030381841044272

Epoch: 6| Step: 9
Training loss: 1.3145830631256104
Validation loss: 2.0441602404399584

Epoch: 6| Step: 10
Training loss: 1.8556339740753174
Validation loss: 2.058171151786722

Epoch: 6| Step: 11
Training loss: 2.3974475860595703
Validation loss: 2.055481272359048

Epoch: 6| Step: 12
Training loss: 1.6353161334991455
Validation loss: 2.047409986936918

Epoch: 6| Step: 13
Training loss: 0.857574462890625
Validation loss: 2.0794842550831456

Epoch: 212| Step: 0
Training loss: 2.028644561767578
Validation loss: 2.075062464642268

Epoch: 6| Step: 1
Training loss: 1.6748814582824707
Validation loss: 2.0935038071806713

Epoch: 6| Step: 2
Training loss: 1.8356106281280518
Validation loss: 2.0764113626172467

Epoch: 6| Step: 3
Training loss: 1.0358384847640991
Validation loss: 2.045735832183592

Epoch: 6| Step: 4
Training loss: 1.7132585048675537
Validation loss: 2.0884745685003137

Epoch: 6| Step: 5
Training loss: 1.0097861289978027
Validation loss: 2.057865327404391

Epoch: 6| Step: 6
Training loss: 1.934669017791748
Validation loss: 2.0648512763361775

Epoch: 6| Step: 7
Training loss: 1.1151567697525024
Validation loss: 2.047882290296657

Epoch: 6| Step: 8
Training loss: 1.6032766103744507
Validation loss: 2.0373705305078977

Epoch: 6| Step: 9
Training loss: 1.3011343479156494
Validation loss: 2.0190732338095225

Epoch: 6| Step: 10
Training loss: 1.2063376903533936
Validation loss: 1.9956726335710095

Epoch: 6| Step: 11
Training loss: 1.5485541820526123
Validation loss: 1.9993581874396211

Epoch: 6| Step: 12
Training loss: 1.372310996055603
Validation loss: 1.9976802256799513

Epoch: 6| Step: 13
Training loss: 1.3573544025421143
Validation loss: 2.0089854989000546

Epoch: 213| Step: 0
Training loss: 1.4885560274124146
Validation loss: 2.0388909257868284

Epoch: 6| Step: 1
Training loss: 1.5290119647979736
Validation loss: 2.0449078826494116

Epoch: 6| Step: 2
Training loss: 1.2303643226623535
Validation loss: 2.0577514504873626

Epoch: 6| Step: 3
Training loss: 1.061985731124878
Validation loss: 2.051145609988961

Epoch: 6| Step: 4
Training loss: 0.9384827017784119
Validation loss: 2.0697615915729153

Epoch: 6| Step: 5
Training loss: 1.1423834562301636
Validation loss: 2.0744788954334874

Epoch: 6| Step: 6
Training loss: 1.6370556354522705
Validation loss: 2.061735180116469

Epoch: 6| Step: 7
Training loss: 1.6348154544830322
Validation loss: 2.052503808852165

Epoch: 6| Step: 8
Training loss: 1.2909343242645264
Validation loss: 2.034198370031131

Epoch: 6| Step: 9
Training loss: 1.6417324542999268
Validation loss: 2.0248844828656924

Epoch: 6| Step: 10
Training loss: 1.6104211807250977
Validation loss: 2.002551301833122

Epoch: 6| Step: 11
Training loss: 1.6972472667694092
Validation loss: 1.9970847509240592

Epoch: 6| Step: 12
Training loss: 0.8423808813095093
Validation loss: 1.9843791095159387

Epoch: 6| Step: 13
Training loss: 1.6561472415924072
Validation loss: 1.9746947134694746

Epoch: 214| Step: 0
Training loss: 1.1206154823303223
Validation loss: 1.9602046243606075

Epoch: 6| Step: 1
Training loss: 1.2692875862121582
Validation loss: 1.9704106289853331

Epoch: 6| Step: 2
Training loss: 1.3343337774276733
Validation loss: 1.9743614953051332

Epoch: 6| Step: 3
Training loss: 1.5896888971328735
Validation loss: 1.9907981195757467

Epoch: 6| Step: 4
Training loss: 1.3050556182861328
Validation loss: 1.9935394051254436

Epoch: 6| Step: 5
Training loss: 0.8813079595565796
Validation loss: 2.0052357001971175

Epoch: 6| Step: 6
Training loss: 1.3181647062301636
Validation loss: 2.004780802675473

Epoch: 6| Step: 7
Training loss: 2.107062339782715
Validation loss: 2.0395376272098993

Epoch: 6| Step: 8
Training loss: 1.5975704193115234
Validation loss: 2.0433951193286526

Epoch: 6| Step: 9
Training loss: 1.263956904411316
Validation loss: 2.0316084559245775

Epoch: 6| Step: 10
Training loss: 1.829939365386963
Validation loss: 2.0170569804406937

Epoch: 6| Step: 11
Training loss: 0.9209280610084534
Validation loss: 1.9938061275789816

Epoch: 6| Step: 12
Training loss: 1.5384759902954102
Validation loss: 1.976581601686375

Epoch: 6| Step: 13
Training loss: 1.4026362895965576
Validation loss: 1.9754134070488714

Epoch: 215| Step: 0
Training loss: 1.256386637687683
Validation loss: 1.9888273336554085

Epoch: 6| Step: 1
Training loss: 1.1246073246002197
Validation loss: 2.0032285041706537

Epoch: 6| Step: 2
Training loss: 0.8803655505180359
Validation loss: 2.0137431544642292

Epoch: 6| Step: 3
Training loss: 1.3042328357696533
Validation loss: 2.018860293972877

Epoch: 6| Step: 4
Training loss: 1.0761646032333374
Validation loss: 2.0049273788288073

Epoch: 6| Step: 5
Training loss: 1.2993203401565552
Validation loss: 2.021315618227887

Epoch: 6| Step: 6
Training loss: 1.8249205350875854
Validation loss: 2.0064834522944626

Epoch: 6| Step: 7
Training loss: 1.603794813156128
Validation loss: 2.018277540001818

Epoch: 6| Step: 8
Training loss: 1.5988655090332031
Validation loss: 2.0331621246953167

Epoch: 6| Step: 9
Training loss: 1.8021886348724365
Validation loss: 2.029517989004812

Epoch: 6| Step: 10
Training loss: 1.529939889907837
Validation loss: 2.0164172572474324

Epoch: 6| Step: 11
Training loss: 1.3327701091766357
Validation loss: 1.9955153144815916

Epoch: 6| Step: 12
Training loss: 1.1682333946228027
Validation loss: 1.9874255016285887

Epoch: 6| Step: 13
Training loss: 1.6248823404312134
Validation loss: 1.9731026849439066

Epoch: 216| Step: 0
Training loss: 1.82161283493042
Validation loss: 1.986037979843796

Epoch: 6| Step: 1
Training loss: 1.2219769954681396
Validation loss: 1.9888700810811852

Epoch: 6| Step: 2
Training loss: 0.8435257077217102
Validation loss: 1.9708438022162325

Epoch: 6| Step: 3
Training loss: 2.219726800918579
Validation loss: 1.9918211531895462

Epoch: 6| Step: 4
Training loss: 1.302464485168457
Validation loss: 1.9824108398088844

Epoch: 6| Step: 5
Training loss: 0.8846204280853271
Validation loss: 1.9779828979123024

Epoch: 6| Step: 6
Training loss: 0.9930781722068787
Validation loss: 1.965444536619289

Epoch: 6| Step: 7
Training loss: 1.214240550994873
Validation loss: 1.9774528421381468

Epoch: 6| Step: 8
Training loss: 0.9420552253723145
Validation loss: 1.9840392310132262

Epoch: 6| Step: 9
Training loss: 1.4152541160583496
Validation loss: 2.0090428988138833

Epoch: 6| Step: 10
Training loss: 1.3385323286056519
Validation loss: 2.014198698023314

Epoch: 6| Step: 11
Training loss: 1.7519879341125488
Validation loss: 2.056406059572774

Epoch: 6| Step: 12
Training loss: 1.3112916946411133
Validation loss: 2.069150468354584

Epoch: 6| Step: 13
Training loss: 0.6908209323883057
Validation loss: 2.0914412595892466

Epoch: 217| Step: 0
Training loss: 1.2283447980880737
Validation loss: 2.112929513377528

Epoch: 6| Step: 1
Training loss: 0.7451011538505554
Validation loss: 2.1068288639027584

Epoch: 6| Step: 2
Training loss: 1.451486587524414
Validation loss: 2.1300234281888573

Epoch: 6| Step: 3
Training loss: 0.9198406338691711
Validation loss: 2.0639706580869612

Epoch: 6| Step: 4
Training loss: 1.2863181829452515
Validation loss: 2.014849034688806

Epoch: 6| Step: 5
Training loss: 0.7748813629150391
Validation loss: 2.0092110659486506

Epoch: 6| Step: 6
Training loss: 1.3100438117980957
Validation loss: 1.9750858917031238

Epoch: 6| Step: 7
Training loss: 1.5450654029846191
Validation loss: 1.9932395463348718

Epoch: 6| Step: 8
Training loss: 2.090751886367798
Validation loss: 2.0020283018389056

Epoch: 6| Step: 9
Training loss: 1.233306884765625
Validation loss: 1.9923967007667787

Epoch: 6| Step: 10
Training loss: 1.0404314994812012
Validation loss: 1.9996995259356756

Epoch: 6| Step: 11
Training loss: 1.0370972156524658
Validation loss: 1.9963181249557003

Epoch: 6| Step: 12
Training loss: 2.2782950401306152
Validation loss: 2.008473297601105

Epoch: 6| Step: 13
Training loss: 1.9616084098815918
Validation loss: 1.990260261361317

Epoch: 218| Step: 0
Training loss: 1.2980470657348633
Validation loss: 2.0065745128098356

Epoch: 6| Step: 1
Training loss: 1.4214410781860352
Validation loss: 1.9746588507006246

Epoch: 6| Step: 2
Training loss: 1.4640454053878784
Validation loss: 1.9716967690375544

Epoch: 6| Step: 3
Training loss: 1.0832526683807373
Validation loss: 1.9723502384719027

Epoch: 6| Step: 4
Training loss: 1.1694689989089966
Validation loss: 1.9923351926188315

Epoch: 6| Step: 5
Training loss: 0.9346112608909607
Validation loss: 1.993379565977281

Epoch: 6| Step: 6
Training loss: 1.2325830459594727
Validation loss: 1.9760252685957058

Epoch: 6| Step: 7
Training loss: 1.000550627708435
Validation loss: 1.9805710033703876

Epoch: 6| Step: 8
Training loss: 1.3658628463745117
Validation loss: 1.9816602455672396

Epoch: 6| Step: 9
Training loss: 1.8334770202636719
Validation loss: 1.9664815061835832

Epoch: 6| Step: 10
Training loss: 1.1495534181594849
Validation loss: 1.9771596782950944

Epoch: 6| Step: 11
Training loss: 1.2082414627075195
Validation loss: 1.9870525726708033

Epoch: 6| Step: 12
Training loss: 1.6678698062896729
Validation loss: 2.0120131584905807

Epoch: 6| Step: 13
Training loss: 1.8308156728744507
Validation loss: 2.0387428729764876

Epoch: 219| Step: 0
Training loss: 1.0828708410263062
Validation loss: 2.0459378919293805

Epoch: 6| Step: 1
Training loss: 1.2853851318359375
Validation loss: 2.085293616017988

Epoch: 6| Step: 2
Training loss: 1.3416357040405273
Validation loss: 2.114437505763064

Epoch: 6| Step: 3
Training loss: 1.5825109481811523
Validation loss: 2.1317488083275418

Epoch: 6| Step: 4
Training loss: 1.4797967672348022
Validation loss: 2.100567820251629

Epoch: 6| Step: 5
Training loss: 1.8999371528625488
Validation loss: 2.064905471699212

Epoch: 6| Step: 6
Training loss: 0.7666341066360474
Validation loss: 2.0599596449123916

Epoch: 6| Step: 7
Training loss: 0.8657143115997314
Validation loss: 2.024260155616268

Epoch: 6| Step: 8
Training loss: 1.7506099939346313
Validation loss: 2.0046648799732165

Epoch: 6| Step: 9
Training loss: 1.131504774093628
Validation loss: 1.9896029067295853

Epoch: 6| Step: 10
Training loss: 1.5699033737182617
Validation loss: 1.9659579120656496

Epoch: 6| Step: 11
Training loss: 1.5743958950042725
Validation loss: 1.9597887531403573

Epoch: 6| Step: 12
Training loss: 1.1066131591796875
Validation loss: 1.958208836534972

Epoch: 6| Step: 13
Training loss: 1.2364592552185059
Validation loss: 1.941302699427451

Epoch: 220| Step: 0
Training loss: 1.2347793579101562
Validation loss: 1.9497087104346162

Epoch: 6| Step: 1
Training loss: 1.4925601482391357
Validation loss: 1.9768165273051108

Epoch: 6| Step: 2
Training loss: 1.8971877098083496
Validation loss: 1.9945142051225067

Epoch: 6| Step: 3
Training loss: 0.757994532585144
Validation loss: 2.0236909902223976

Epoch: 6| Step: 4
Training loss: 1.2864513397216797
Validation loss: 2.030593755424664

Epoch: 6| Step: 5
Training loss: 1.6633813381195068
Validation loss: 2.053463446196689

Epoch: 6| Step: 6
Training loss: 0.8757777810096741
Validation loss: 2.0415470523218953

Epoch: 6| Step: 7
Training loss: 1.1168214082717896
Validation loss: 2.0617971125469414

Epoch: 6| Step: 8
Training loss: 1.6077537536621094
Validation loss: 2.0772509690253966

Epoch: 6| Step: 9
Training loss: 1.0478730201721191
Validation loss: 2.0789317200260777

Epoch: 6| Step: 10
Training loss: 1.1240688562393188
Validation loss: 2.0909994673985306

Epoch: 6| Step: 11
Training loss: 1.882644772529602
Validation loss: 2.0637333521278958

Epoch: 6| Step: 12
Training loss: 1.4138004779815674
Validation loss: 2.0302833998075096

Epoch: 6| Step: 13
Training loss: 0.9597916007041931
Validation loss: 2.0449307477602394

Epoch: 221| Step: 0
Training loss: 1.4604181051254272
Validation loss: 2.0042790289848083

Epoch: 6| Step: 1
Training loss: 1.2121737003326416
Validation loss: 1.9889188222987677

Epoch: 6| Step: 2
Training loss: 1.3193745613098145
Validation loss: 1.9437026490447342

Epoch: 6| Step: 3
Training loss: 1.1456139087677002
Validation loss: 1.9294320857653053

Epoch: 6| Step: 4
Training loss: 1.3462568521499634
Validation loss: 1.918921588569559

Epoch: 6| Step: 5
Training loss: 1.4832117557525635
Validation loss: 1.8721081672176239

Epoch: 6| Step: 6
Training loss: 1.1640962362289429
Validation loss: 1.8624901502363143

Epoch: 6| Step: 7
Training loss: 1.63196861743927
Validation loss: 1.89450151945955

Epoch: 6| Step: 8
Training loss: 1.612641453742981
Validation loss: 1.8741635750698786

Epoch: 6| Step: 9
Training loss: 1.4058037996292114
Validation loss: 1.9188515845165457

Epoch: 6| Step: 10
Training loss: 1.9974182844161987
Validation loss: 1.962550510642349

Epoch: 6| Step: 11
Training loss: 0.7712558507919312
Validation loss: 1.9693225058176185

Epoch: 6| Step: 12
Training loss: 1.0712311267852783
Validation loss: 2.015442627732472

Epoch: 6| Step: 13
Training loss: 1.9438353776931763
Validation loss: 2.0385344361746185

Epoch: 222| Step: 0
Training loss: 1.105736255645752
Validation loss: 2.087825426491358

Epoch: 6| Step: 1
Training loss: 1.5866940021514893
Validation loss: 2.1205546215016353

Epoch: 6| Step: 2
Training loss: 1.4047991037368774
Validation loss: 2.144934219698752

Epoch: 6| Step: 3
Training loss: 2.277885675430298
Validation loss: 2.119830741677233

Epoch: 6| Step: 4
Training loss: 1.7046949863433838
Validation loss: 2.101884513772944

Epoch: 6| Step: 5
Training loss: 1.910722255706787
Validation loss: 2.062878800976661

Epoch: 6| Step: 6
Training loss: 1.0127453804016113
Validation loss: 2.0353159725025134

Epoch: 6| Step: 7
Training loss: 0.5452654361724854
Validation loss: 1.9938668127982848

Epoch: 6| Step: 8
Training loss: 1.5554934740066528
Validation loss: 1.982154627000132

Epoch: 6| Step: 9
Training loss: 1.5198814868927002
Validation loss: 1.9782017969316052

Epoch: 6| Step: 10
Training loss: 1.1408027410507202
Validation loss: 1.9439553432567145

Epoch: 6| Step: 11
Training loss: 1.083620548248291
Validation loss: 1.936580765631891

Epoch: 6| Step: 12
Training loss: 0.7902756333351135
Validation loss: 1.9551262983711817

Epoch: 6| Step: 13
Training loss: 1.0626864433288574
Validation loss: 1.9413642819209764

Epoch: 223| Step: 0
Training loss: 1.3239707946777344
Validation loss: 1.9773132775419502

Epoch: 6| Step: 1
Training loss: 1.283221960067749
Validation loss: 1.9952109936744935

Epoch: 6| Step: 2
Training loss: 1.4920296669006348
Validation loss: 1.9901455909975114

Epoch: 6| Step: 3
Training loss: 0.712189257144928
Validation loss: 1.9775325944346767

Epoch: 6| Step: 4
Training loss: 1.155880093574524
Validation loss: 1.9607575196091847

Epoch: 6| Step: 5
Training loss: 1.1897637844085693
Validation loss: 1.9945524841226556

Epoch: 6| Step: 6
Training loss: 1.6885067224502563
Validation loss: 2.0113926331202188

Epoch: 6| Step: 7
Training loss: 1.1450859308242798
Validation loss: 1.9888521907150105

Epoch: 6| Step: 8
Training loss: 1.497178316116333
Validation loss: 2.020619571849864

Epoch: 6| Step: 9
Training loss: 1.1747767925262451
Validation loss: 2.0120976740314114

Epoch: 6| Step: 10
Training loss: 1.8501900434494019
Validation loss: 2.0129248403733775

Epoch: 6| Step: 11
Training loss: 1.0643004179000854
Validation loss: 1.966588661234866

Epoch: 6| Step: 12
Training loss: 0.8237635493278503
Validation loss: 1.9770430621280466

Epoch: 6| Step: 13
Training loss: 1.7421036958694458
Validation loss: 1.9797291371130175

Epoch: 224| Step: 0
Training loss: 1.2558847665786743
Validation loss: 1.9881828907997376

Epoch: 6| Step: 1
Training loss: 1.4457647800445557
Validation loss: 2.019167316857205

Epoch: 6| Step: 2
Training loss: 1.385372281074524
Validation loss: 1.9961034956798758

Epoch: 6| Step: 3
Training loss: 0.8310860991477966
Validation loss: 1.973585590239494

Epoch: 6| Step: 4
Training loss: 1.4878591299057007
Validation loss: 2.01001404177758

Epoch: 6| Step: 5
Training loss: 0.8393872976303101
Validation loss: 1.9901428479020313

Epoch: 6| Step: 6
Training loss: 1.5903804302215576
Validation loss: 1.9676181936776767

Epoch: 6| Step: 7
Training loss: 1.1237969398498535
Validation loss: 1.9870564655591083

Epoch: 6| Step: 8
Training loss: 1.2397079467773438
Validation loss: 1.9617490076249646

Epoch: 6| Step: 9
Training loss: 1.6151351928710938
Validation loss: 1.97577791829263

Epoch: 6| Step: 10
Training loss: 0.8235576152801514
Validation loss: 1.9725886006509104

Epoch: 6| Step: 11
Training loss: 1.1020221710205078
Validation loss: 1.9688258786355295

Epoch: 6| Step: 12
Training loss: 1.6816667318344116
Validation loss: 1.974449985770769

Epoch: 6| Step: 13
Training loss: 0.8159229159355164
Validation loss: 1.9930272807357132

Epoch: 225| Step: 0
Training loss: 1.666867971420288
Validation loss: 2.006996709813354

Epoch: 6| Step: 1
Training loss: 1.0625066757202148
Validation loss: 2.017837570559594

Epoch: 6| Step: 2
Training loss: 1.363337755203247
Validation loss: 2.01875231599295

Epoch: 6| Step: 3
Training loss: 1.244301676750183
Validation loss: 2.0032231115525767

Epoch: 6| Step: 4
Training loss: 1.2976062297821045
Validation loss: 1.9919611753955964

Epoch: 6| Step: 5
Training loss: 1.0369594097137451
Validation loss: 2.0025459694606003

Epoch: 6| Step: 6
Training loss: 1.3706949949264526
Validation loss: 2.0255532879983225

Epoch: 6| Step: 7
Training loss: 1.5785324573516846
Validation loss: 2.018567926140242

Epoch: 6| Step: 8
Training loss: 1.3954015970230103
Validation loss: 2.0200570168033725

Epoch: 6| Step: 9
Training loss: 0.7101753950119019
Validation loss: 2.0156866555572837

Epoch: 6| Step: 10
Training loss: 1.4870446920394897
Validation loss: 2.016919236029348

Epoch: 6| Step: 11
Training loss: 1.094035029411316
Validation loss: 1.9869536533150622

Epoch: 6| Step: 12
Training loss: 1.0071206092834473
Validation loss: 2.0032001041596934

Epoch: 6| Step: 13
Training loss: 1.0067198276519775
Validation loss: 2.0033683930673907

Epoch: 226| Step: 0
Training loss: 1.216604232788086
Validation loss: 1.9847725616988314

Epoch: 6| Step: 1
Training loss: 1.5177379846572876
Validation loss: 2.0034981055926253

Epoch: 6| Step: 2
Training loss: 1.5809016227722168
Validation loss: 2.0208841600725727

Epoch: 6| Step: 3
Training loss: 1.5168647766113281
Validation loss: 2.0229789915905205

Epoch: 6| Step: 4
Training loss: 1.2983922958374023
Validation loss: 2.024144326486895

Epoch: 6| Step: 5
Training loss: 0.6197866797447205
Validation loss: 1.992465772936421

Epoch: 6| Step: 6
Training loss: 1.5515415668487549
Validation loss: 1.9929673979359288

Epoch: 6| Step: 7
Training loss: 1.0226975679397583
Validation loss: 1.963501981509629

Epoch: 6| Step: 8
Training loss: 1.4375954866409302
Validation loss: 1.9623018041733773

Epoch: 6| Step: 9
Training loss: 1.3427555561065674
Validation loss: 1.9749071610871183

Epoch: 6| Step: 10
Training loss: 0.8748615980148315
Validation loss: 1.9744322953685638

Epoch: 6| Step: 11
Training loss: 1.05745267868042
Validation loss: 1.9975710222798009

Epoch: 6| Step: 12
Training loss: 1.27388596534729
Validation loss: 1.9790103820062452

Epoch: 6| Step: 13
Training loss: 0.6486097574234009
Validation loss: 1.9690781947105163

Epoch: 227| Step: 0
Training loss: 1.013101577758789
Validation loss: 1.9961044993451846

Epoch: 6| Step: 1
Training loss: 1.436215877532959
Validation loss: 1.992063066010834

Epoch: 6| Step: 2
Training loss: 1.2137000560760498
Validation loss: 1.9740778118051507

Epoch: 6| Step: 3
Training loss: 0.8130831122398376
Validation loss: 1.9941517614549207

Epoch: 6| Step: 4
Training loss: 1.4575939178466797
Validation loss: 1.9949587160541165

Epoch: 6| Step: 5
Training loss: 1.4489717483520508
Validation loss: 1.9869099458058674

Epoch: 6| Step: 6
Training loss: 1.2318427562713623
Validation loss: 1.9721114609831123

Epoch: 6| Step: 7
Training loss: 1.2756239175796509
Validation loss: 1.9810567184161114

Epoch: 6| Step: 8
Training loss: 1.0225160121917725
Validation loss: 1.991753972986693

Epoch: 6| Step: 9
Training loss: 0.6920428276062012
Validation loss: 1.9937063622218307

Epoch: 6| Step: 10
Training loss: 0.8324876427650452
Validation loss: 1.9760882316097137

Epoch: 6| Step: 11
Training loss: 1.3840129375457764
Validation loss: 1.9682097063269666

Epoch: 6| Step: 12
Training loss: 1.065631628036499
Validation loss: 1.9879338356756395

Epoch: 6| Step: 13
Training loss: 1.7339364290237427
Validation loss: 1.9706356692057785

Epoch: 228| Step: 0
Training loss: 1.4702420234680176
Validation loss: 2.0095934367948964

Epoch: 6| Step: 1
Training loss: 0.8210731744766235
Validation loss: 1.9821861815708939

Epoch: 6| Step: 2
Training loss: 1.110182523727417
Validation loss: 1.9830465726954962

Epoch: 6| Step: 3
Training loss: 0.8931441307067871
Validation loss: 1.9609514590232604

Epoch: 6| Step: 4
Training loss: 1.5023324489593506
Validation loss: 1.9626270314698577

Epoch: 6| Step: 5
Training loss: 0.8958579301834106
Validation loss: 1.953630280751054

Epoch: 6| Step: 6
Training loss: 1.326590657234192
Validation loss: 1.9875853061676025

Epoch: 6| Step: 7
Training loss: 0.6895155906677246
Validation loss: 1.9757816688988799

Epoch: 6| Step: 8
Training loss: 1.6070308685302734
Validation loss: 1.966971892182545

Epoch: 6| Step: 9
Training loss: 1.0022469758987427
Validation loss: 1.9975692123495123

Epoch: 6| Step: 10
Training loss: 1.483086109161377
Validation loss: 1.987236527986424

Epoch: 6| Step: 11
Training loss: 1.1859062910079956
Validation loss: 1.9716457654071111

Epoch: 6| Step: 12
Training loss: 1.2229117155075073
Validation loss: 1.9834588138006066

Epoch: 6| Step: 13
Training loss: 1.0827522277832031
Validation loss: 1.9607429927395237

Epoch: 229| Step: 0
Training loss: 0.7015236020088196
Validation loss: 1.955629147509093

Epoch: 6| Step: 1
Training loss: 0.9041454792022705
Validation loss: 1.9379852817904564

Epoch: 6| Step: 2
Training loss: 1.1192790269851685
Validation loss: 1.9424360875160462

Epoch: 6| Step: 3
Training loss: 0.9140212535858154
Validation loss: 1.957240209784559

Epoch: 6| Step: 4
Training loss: 1.1389527320861816
Validation loss: 1.9739880613101426

Epoch: 6| Step: 5
Training loss: 1.7724720239639282
Validation loss: 2.0008738419061065

Epoch: 6| Step: 6
Training loss: 1.3894078731536865
Validation loss: 2.0238048876485517

Epoch: 6| Step: 7
Training loss: 1.4201587438583374
Validation loss: 2.033424090313655

Epoch: 6| Step: 8
Training loss: 1.5068528652191162
Validation loss: 2.02067280456584

Epoch: 6| Step: 9
Training loss: 0.9022837281227112
Validation loss: 1.973785606763696

Epoch: 6| Step: 10
Training loss: 1.3191015720367432
Validation loss: 1.9496152388152255

Epoch: 6| Step: 11
Training loss: 1.0856122970581055
Validation loss: 1.9595320429853214

Epoch: 6| Step: 12
Training loss: 1.3889884948730469
Validation loss: 1.9419830537611438

Epoch: 6| Step: 13
Training loss: 1.0461926460266113
Validation loss: 1.9169745688797326

Epoch: 230| Step: 0
Training loss: 1.6146483421325684
Validation loss: 1.9259090795311877

Epoch: 6| Step: 1
Training loss: 1.3973331451416016
Validation loss: 1.9060111443201702

Epoch: 6| Step: 2
Training loss: 1.5504112243652344
Validation loss: 1.9293082606407903

Epoch: 6| Step: 3
Training loss: 1.1031391620635986
Validation loss: 1.9132309876462466

Epoch: 6| Step: 4
Training loss: 1.3348875045776367
Validation loss: 1.9294715337855841

Epoch: 6| Step: 5
Training loss: 1.163102149963379
Validation loss: 1.9734351301705966

Epoch: 6| Step: 6
Training loss: 0.632561981678009
Validation loss: 1.969715900318597

Epoch: 6| Step: 7
Training loss: 0.8544557094573975
Validation loss: 1.9683940384977607

Epoch: 6| Step: 8
Training loss: 1.2504597902297974
Validation loss: 1.9865453602165304

Epoch: 6| Step: 9
Training loss: 1.1345700025558472
Validation loss: 1.9902991992171093

Epoch: 6| Step: 10
Training loss: 1.0680949687957764
Validation loss: 2.023481494636946

Epoch: 6| Step: 11
Training loss: 1.0123569965362549
Validation loss: 2.0090913195763864

Epoch: 6| Step: 12
Training loss: 1.1161328554153442
Validation loss: 2.0270314678069083

Epoch: 6| Step: 13
Training loss: 0.770039439201355
Validation loss: 2.025587417746103

Epoch: 231| Step: 0
Training loss: 1.0153114795684814
Validation loss: 2.0256847181627826

Epoch: 6| Step: 1
Training loss: 0.9430285096168518
Validation loss: 2.0104056135300667

Epoch: 6| Step: 2
Training loss: 1.4912309646606445
Validation loss: 2.0268975816747195

Epoch: 6| Step: 3
Training loss: 1.6312031745910645
Validation loss: 1.9886815201851629

Epoch: 6| Step: 4
Training loss: 1.045229434967041
Validation loss: 1.9378152637071506

Epoch: 6| Step: 5
Training loss: 0.8504725694656372
Validation loss: 1.9413082125366374

Epoch: 6| Step: 6
Training loss: 1.2378909587860107
Validation loss: 1.9374274771700624

Epoch: 6| Step: 7
Training loss: 0.9954318404197693
Validation loss: 1.8942594579471055

Epoch: 6| Step: 8
Training loss: 0.9527272582054138
Validation loss: 1.910663495781601

Epoch: 6| Step: 9
Training loss: 0.8785099983215332
Validation loss: 1.9177817785611717

Epoch: 6| Step: 10
Training loss: 1.262336015701294
Validation loss: 1.901856376278785

Epoch: 6| Step: 11
Training loss: 0.8605210781097412
Validation loss: 1.9402483483796478

Epoch: 6| Step: 12
Training loss: 1.9264023303985596
Validation loss: 1.9433139370333763

Epoch: 6| Step: 13
Training loss: 0.9216940402984619
Validation loss: 1.9481557005195207

Epoch: 232| Step: 0
Training loss: 0.6563998460769653
Validation loss: 1.9535631966847244

Epoch: 6| Step: 1
Training loss: 1.0048214197158813
Validation loss: 1.9658080300977152

Epoch: 6| Step: 2
Training loss: 1.1948256492614746
Validation loss: 1.9879646480724376

Epoch: 6| Step: 3
Training loss: 1.2705764770507812
Validation loss: 1.9434222957139373

Epoch: 6| Step: 4
Training loss: 1.5098185539245605
Validation loss: 1.998918282088413

Epoch: 6| Step: 5
Training loss: 1.2031915187835693
Validation loss: 1.9580629897373978

Epoch: 6| Step: 6
Training loss: 0.948803186416626
Validation loss: 1.987006277166387

Epoch: 6| Step: 7
Training loss: 0.8825662136077881
Validation loss: 1.9823119640350342

Epoch: 6| Step: 8
Training loss: 1.0751551389694214
Validation loss: 1.962389310201009

Epoch: 6| Step: 9
Training loss: 1.4215223789215088
Validation loss: 1.9255742898551367

Epoch: 6| Step: 10
Training loss: 1.376859426498413
Validation loss: 1.934668940882529

Epoch: 6| Step: 11
Training loss: 0.8046753406524658
Validation loss: 1.9451380275910901

Epoch: 6| Step: 12
Training loss: 1.3774266242980957
Validation loss: 1.9300391571496123

Epoch: 6| Step: 13
Training loss: 0.9538607001304626
Validation loss: 1.9005171150289557

Epoch: 233| Step: 0
Training loss: 1.0728652477264404
Validation loss: 1.9248904643520233

Epoch: 6| Step: 1
Training loss: 1.4535225629806519
Validation loss: 1.894368584438037

Epoch: 6| Step: 2
Training loss: 1.7459629774093628
Validation loss: 1.8943898882917178

Epoch: 6| Step: 3
Training loss: 0.9731264114379883
Validation loss: 1.8700757847037366

Epoch: 6| Step: 4
Training loss: 0.797888457775116
Validation loss: 1.8747335582651117

Epoch: 6| Step: 5
Training loss: 1.3260244131088257
Validation loss: 1.877177079518636

Epoch: 6| Step: 6
Training loss: 0.8201169967651367
Validation loss: 1.896365261846973

Epoch: 6| Step: 7
Training loss: 0.8071861267089844
Validation loss: 1.9375880097830167

Epoch: 6| Step: 8
Training loss: 1.6329782009124756
Validation loss: 1.9416508046529626

Epoch: 6| Step: 9
Training loss: 1.150625228881836
Validation loss: 1.96290510700595

Epoch: 6| Step: 10
Training loss: 1.1655012369155884
Validation loss: 1.9783052065039193

Epoch: 6| Step: 11
Training loss: 1.296466588973999
Validation loss: 2.00109028303495

Epoch: 6| Step: 12
Training loss: 1.1301332712173462
Validation loss: 1.996902870875533

Epoch: 6| Step: 13
Training loss: 0.2628059983253479
Validation loss: 1.9923078167823054

Epoch: 234| Step: 0
Training loss: 1.1016323566436768
Validation loss: 1.9483444318976453

Epoch: 6| Step: 1
Training loss: 1.4231175184249878
Validation loss: 1.9299615352384505

Epoch: 6| Step: 2
Training loss: 1.1120530366897583
Validation loss: 1.905899634925268

Epoch: 6| Step: 3
Training loss: 1.0195026397705078
Validation loss: 1.8968384778627785

Epoch: 6| Step: 4
Training loss: 1.2035220861434937
Validation loss: 1.9166590334266744

Epoch: 6| Step: 5
Training loss: 1.214163899421692
Validation loss: 1.914003364501461

Epoch: 6| Step: 6
Training loss: 0.43723776936531067
Validation loss: 1.900118379182713

Epoch: 6| Step: 7
Training loss: 1.5270402431488037
Validation loss: 1.9177411589571225

Epoch: 6| Step: 8
Training loss: 1.0038530826568604
Validation loss: 1.9148636851259457

Epoch: 6| Step: 9
Training loss: 1.0859051942825317
Validation loss: 1.9177201447948333

Epoch: 6| Step: 10
Training loss: 1.314138412475586
Validation loss: 1.9435184694105578

Epoch: 6| Step: 11
Training loss: 1.1991641521453857
Validation loss: 1.9606689663343533

Epoch: 6| Step: 12
Training loss: 1.00690495967865
Validation loss: 1.9893541566787227

Epoch: 6| Step: 13
Training loss: 0.6361191272735596
Validation loss: 1.9922772838223366

Epoch: 235| Step: 0
Training loss: 1.454831838607788
Validation loss: 1.9866663845636512

Epoch: 6| Step: 1
Training loss: 0.703218936920166
Validation loss: 2.0104943090869534

Epoch: 6| Step: 2
Training loss: 1.0849875211715698
Validation loss: 2.0011421749668736

Epoch: 6| Step: 3
Training loss: 1.18149995803833
Validation loss: 2.002756416156728

Epoch: 6| Step: 4
Training loss: 1.2459685802459717
Validation loss: 2.0009334677009174

Epoch: 6| Step: 5
Training loss: 0.9336884021759033
Validation loss: 2.032515484799621

Epoch: 6| Step: 6
Training loss: 0.9440861344337463
Validation loss: 1.9919614509869648

Epoch: 6| Step: 7
Training loss: 1.6390680074691772
Validation loss: 1.967964638945877

Epoch: 6| Step: 8
Training loss: 1.300925850868225
Validation loss: 1.9237257626748854

Epoch: 6| Step: 9
Training loss: 1.0690488815307617
Validation loss: 1.9092493948116098

Epoch: 6| Step: 10
Training loss: 1.7391718626022339
Validation loss: 1.924574359770744

Epoch: 6| Step: 11
Training loss: 0.7996273040771484
Validation loss: 1.8984146938529065

Epoch: 6| Step: 12
Training loss: 1.3840714693069458
Validation loss: 1.8671654962724256

Epoch: 6| Step: 13
Training loss: 0.3661445379257202
Validation loss: 1.8622858344867665

Epoch: 236| Step: 0
Training loss: 1.063342809677124
Validation loss: 1.8915895108253724

Epoch: 6| Step: 1
Training loss: 1.8175232410430908
Validation loss: 1.905243581341159

Epoch: 6| Step: 2
Training loss: 1.0115647315979004
Validation loss: 1.9317126543291154

Epoch: 6| Step: 3
Training loss: 1.129995346069336
Validation loss: 1.9958975238184775

Epoch: 6| Step: 4
Training loss: 1.3375334739685059
Validation loss: 2.006103164406233

Epoch: 6| Step: 5
Training loss: 0.7832327485084534
Validation loss: 2.0409617077919746

Epoch: 6| Step: 6
Training loss: 1.0641881227493286
Validation loss: 2.0259116003590245

Epoch: 6| Step: 7
Training loss: 0.36177486181259155
Validation loss: 2.0844402928506174

Epoch: 6| Step: 8
Training loss: 1.4382550716400146
Validation loss: 2.087513364771361

Epoch: 6| Step: 9
Training loss: 1.2483665943145752
Validation loss: 2.076224873142858

Epoch: 6| Step: 10
Training loss: 1.675864577293396
Validation loss: 2.0782616779368412

Epoch: 6| Step: 11
Training loss: 0.45927560329437256
Validation loss: 2.0475976569678194

Epoch: 6| Step: 12
Training loss: 0.7675908803939819
Validation loss: 2.005076103312995

Epoch: 6| Step: 13
Training loss: 1.145652413368225
Validation loss: 1.9634617579880582

Epoch: 237| Step: 0
Training loss: 0.6821151375770569
Validation loss: 1.9303615503413702

Epoch: 6| Step: 1
Training loss: 1.0561662912368774
Validation loss: 1.9079272029220418

Epoch: 6| Step: 2
Training loss: 1.2833194732666016
Validation loss: 1.9105165748186008

Epoch: 6| Step: 3
Training loss: 1.2379738092422485
Validation loss: 1.9223481724339146

Epoch: 6| Step: 4
Training loss: 1.1789108514785767
Validation loss: 1.9086598683429021

Epoch: 6| Step: 5
Training loss: 0.7500713467597961
Validation loss: 1.912825689520887

Epoch: 6| Step: 6
Training loss: 0.4573741853237152
Validation loss: 1.907563356943028

Epoch: 6| Step: 7
Training loss: 1.576843023300171
Validation loss: 1.8968334441543908

Epoch: 6| Step: 8
Training loss: 1.1399775743484497
Validation loss: 1.896923295913204

Epoch: 6| Step: 9
Training loss: 1.292022943496704
Validation loss: 1.9211947430846512

Epoch: 6| Step: 10
Training loss: 1.2731702327728271
Validation loss: 1.9283064257714055

Epoch: 6| Step: 11
Training loss: 1.7102655172348022
Validation loss: 1.9365686396116852

Epoch: 6| Step: 12
Training loss: 1.1543267965316772
Validation loss: 1.9333529267259824

Epoch: 6| Step: 13
Training loss: 1.026660680770874
Validation loss: 1.977416725568874

Epoch: 238| Step: 0
Training loss: 1.2251888513565063
Validation loss: 2.003508807510458

Epoch: 6| Step: 1
Training loss: 1.8884681463241577
Validation loss: 2.020466394321893

Epoch: 6| Step: 2
Training loss: 0.7425777912139893
Validation loss: 1.9920379320780437

Epoch: 6| Step: 3
Training loss: 1.165926218032837
Validation loss: 1.9852122286314606

Epoch: 6| Step: 4
Training loss: 1.4057371616363525
Validation loss: 1.9885806678443827

Epoch: 6| Step: 5
Training loss: 0.8138426542282104
Validation loss: 1.9677455630353702

Epoch: 6| Step: 6
Training loss: 1.213517189025879
Validation loss: 1.9737130544518913

Epoch: 6| Step: 7
Training loss: 1.2048958539962769
Validation loss: 1.9835957378469489

Epoch: 6| Step: 8
Training loss: 0.6031899452209473
Validation loss: 1.9402025656033588

Epoch: 6| Step: 9
Training loss: 0.990787923336029
Validation loss: 1.965798375427082

Epoch: 6| Step: 10
Training loss: 0.8296158313751221
Validation loss: 1.9334469328644455

Epoch: 6| Step: 11
Training loss: 1.2518596649169922
Validation loss: 1.9363533181528891

Epoch: 6| Step: 12
Training loss: 0.6584231853485107
Validation loss: 1.9035125009475216

Epoch: 6| Step: 13
Training loss: 0.7260345816612244
Validation loss: 1.9282254249818864

Epoch: 239| Step: 0
Training loss: 0.7916829586029053
Validation loss: 1.9269884837571012

Epoch: 6| Step: 1
Training loss: 0.4798746407032013
Validation loss: 1.9055964562200731

Epoch: 6| Step: 2
Training loss: 0.7554289102554321
Validation loss: 1.9358287370333107

Epoch: 6| Step: 3
Training loss: 0.868786096572876
Validation loss: 1.9382714379218318

Epoch: 6| Step: 4
Training loss: 1.2873080968856812
Validation loss: 1.941720526705506

Epoch: 6| Step: 5
Training loss: 0.932645320892334
Validation loss: 1.9357464621143956

Epoch: 6| Step: 6
Training loss: 1.164574146270752
Validation loss: 1.974670034582897

Epoch: 6| Step: 7
Training loss: 1.1757864952087402
Validation loss: 1.9713611359237342

Epoch: 6| Step: 8
Training loss: 1.5664172172546387
Validation loss: 1.9424582040438088

Epoch: 6| Step: 9
Training loss: 1.4038293361663818
Validation loss: 1.9380628242287585

Epoch: 6| Step: 10
Training loss: 0.8416516780853271
Validation loss: 1.8893392368029522

Epoch: 6| Step: 11
Training loss: 1.4058411121368408
Validation loss: 1.900448537641956

Epoch: 6| Step: 12
Training loss: 1.327170968055725
Validation loss: 1.9012818503123459

Epoch: 6| Step: 13
Training loss: 1.1365618705749512
Validation loss: 1.9028016213447816

Epoch: 240| Step: 0
Training loss: 0.7975155115127563
Validation loss: 1.9561006535765946

Epoch: 6| Step: 1
Training loss: 1.0612571239471436
Validation loss: 1.978658647947414

Epoch: 6| Step: 2
Training loss: 0.8987743854522705
Validation loss: 1.9698632224913566

Epoch: 6| Step: 3
Training loss: 0.7725591063499451
Validation loss: 1.9917571442101591

Epoch: 6| Step: 4
Training loss: 1.318636417388916
Validation loss: 1.995868295751592

Epoch: 6| Step: 5
Training loss: 1.0327625274658203
Validation loss: 1.9905299730198358

Epoch: 6| Step: 6
Training loss: 1.5587811470031738
Validation loss: 1.9950597516952022

Epoch: 6| Step: 7
Training loss: 1.7475359439849854
Validation loss: 1.9865219259774813

Epoch: 6| Step: 8
Training loss: 1.0633327960968018
Validation loss: 1.9869499385997813

Epoch: 6| Step: 9
Training loss: 0.8505420088768005
Validation loss: 1.967392836847613

Epoch: 6| Step: 10
Training loss: 1.2228178977966309
Validation loss: 1.9857061857818274

Epoch: 6| Step: 11
Training loss: 0.7361215353012085
Validation loss: 1.9661834086141279

Epoch: 6| Step: 12
Training loss: 0.9535825848579407
Validation loss: 1.9646859194642754

Epoch: 6| Step: 13
Training loss: 1.0410035848617554
Validation loss: 1.9777089985468055

Epoch: 241| Step: 0
Training loss: 1.0861283540725708
Validation loss: 1.9435123192366732

Epoch: 6| Step: 1
Training loss: 0.8170801401138306
Validation loss: 1.9326662260998961

Epoch: 6| Step: 2
Training loss: 0.5142853260040283
Validation loss: 1.9594808393909084

Epoch: 6| Step: 3
Training loss: 0.9117884635925293
Validation loss: 1.979457752678984

Epoch: 6| Step: 4
Training loss: 1.3967417478561401
Validation loss: 1.9916493674760223

Epoch: 6| Step: 5
Training loss: 0.8907442688941956
Validation loss: 1.9944955841187508

Epoch: 6| Step: 6
Training loss: 0.9900410175323486
Validation loss: 1.9665711669511692

Epoch: 6| Step: 7
Training loss: 1.070899248123169
Validation loss: 1.9686631015551987

Epoch: 6| Step: 8
Training loss: 0.8912320137023926
Validation loss: 1.930074079062349

Epoch: 6| Step: 9
Training loss: 1.0578904151916504
Validation loss: 1.93781417159624

Epoch: 6| Step: 10
Training loss: 1.2939404249191284
Validation loss: 1.948540396587823

Epoch: 6| Step: 11
Training loss: 1.0402296781539917
Validation loss: 1.9673969053453015

Epoch: 6| Step: 12
Training loss: 1.5103849172592163
Validation loss: 1.9656163979602117

Epoch: 6| Step: 13
Training loss: 1.7590934038162231
Validation loss: 1.9793445551267235

Epoch: 242| Step: 0
Training loss: 0.3570491075515747
Validation loss: 1.993862412309134

Epoch: 6| Step: 1
Training loss: 1.263858437538147
Validation loss: 2.001254435508482

Epoch: 6| Step: 2
Training loss: 1.319934368133545
Validation loss: 2.0123653258046796

Epoch: 6| Step: 3
Training loss: 1.3663573265075684
Validation loss: 2.0351647433414253

Epoch: 6| Step: 4
Training loss: 0.788105309009552
Validation loss: 1.9903076207765968

Epoch: 6| Step: 5
Training loss: 1.1490622758865356
Validation loss: 1.982371909644014

Epoch: 6| Step: 6
Training loss: 0.7882736325263977
Validation loss: 1.96166197458903

Epoch: 6| Step: 7
Training loss: 1.4905511140823364
Validation loss: 1.9176537785478818

Epoch: 6| Step: 8
Training loss: 0.9234912991523743
Validation loss: 1.9484359936047626

Epoch: 6| Step: 9
Training loss: 1.0551865100860596
Validation loss: 1.9444324790790517

Epoch: 6| Step: 10
Training loss: 1.0338295698165894
Validation loss: 1.9618545809099752

Epoch: 6| Step: 11
Training loss: 0.988815188407898
Validation loss: 1.943510809252339

Epoch: 6| Step: 12
Training loss: 0.9929052591323853
Validation loss: 1.9123088416232858

Epoch: 6| Step: 13
Training loss: 0.7082793116569519
Validation loss: 1.9225203183389479

Epoch: 243| Step: 0
Training loss: 1.0592503547668457
Validation loss: 1.9211801200784662

Epoch: 6| Step: 1
Training loss: 0.8742728233337402
Validation loss: 1.9445206055077173

Epoch: 6| Step: 2
Training loss: 1.3262146711349487
Validation loss: 1.9315343313319708

Epoch: 6| Step: 3
Training loss: 0.7802625894546509
Validation loss: 1.9449773808961273

Epoch: 6| Step: 4
Training loss: 1.4076039791107178
Validation loss: 1.932529495608422

Epoch: 6| Step: 5
Training loss: 1.206827163696289
Validation loss: 1.921095440464635

Epoch: 6| Step: 6
Training loss: 0.9256045818328857
Validation loss: 1.929486269591957

Epoch: 6| Step: 7
Training loss: 1.3298983573913574
Validation loss: 1.942946050756721

Epoch: 6| Step: 8
Training loss: 0.6432220935821533
Validation loss: 1.9618773998752717

Epoch: 6| Step: 9
Training loss: 0.9929468631744385
Validation loss: 1.9618947941769835

Epoch: 6| Step: 10
Training loss: 1.2671453952789307
Validation loss: 1.9568427788313998

Epoch: 6| Step: 11
Training loss: 1.0084190368652344
Validation loss: 1.9628025447168658

Epoch: 6| Step: 12
Training loss: 0.8977368474006653
Validation loss: 1.9603838215592087

Epoch: 6| Step: 13
Training loss: 0.42736756801605225
Validation loss: 1.9298380497963197

Epoch: 244| Step: 0
Training loss: 1.433065414428711
Validation loss: 1.9265801829676474

Epoch: 6| Step: 1
Training loss: 0.7974108457565308
Validation loss: 1.9405931811178885

Epoch: 6| Step: 2
Training loss: 0.6212156414985657
Validation loss: 1.9587691163503995

Epoch: 6| Step: 3
Training loss: 0.9387881755828857
Validation loss: 1.9573338365042081

Epoch: 6| Step: 4
Training loss: 0.8781670928001404
Validation loss: 1.9427030342881397

Epoch: 6| Step: 5
Training loss: 1.2517142295837402
Validation loss: 1.9536508078216224

Epoch: 6| Step: 6
Training loss: 0.7024487853050232
Validation loss: 1.935645805892124

Epoch: 6| Step: 7
Training loss: 1.3197537660598755
Validation loss: 1.9366349853495115

Epoch: 6| Step: 8
Training loss: 0.6778857707977295
Validation loss: 1.9257123547215615

Epoch: 6| Step: 9
Training loss: 0.9103034734725952
Validation loss: 1.956449193339194

Epoch: 6| Step: 10
Training loss: 1.4446864128112793
Validation loss: 1.9754136121401222

Epoch: 6| Step: 11
Training loss: 1.104539394378662
Validation loss: 1.9770002121566443

Epoch: 6| Step: 12
Training loss: 1.0127018690109253
Validation loss: 1.9505824068541169

Epoch: 6| Step: 13
Training loss: 1.1845123767852783
Validation loss: 1.9638157134415002

Epoch: 245| Step: 0
Training loss: 0.8968236446380615
Validation loss: 1.9318933640756915

Epoch: 6| Step: 1
Training loss: 0.5111098885536194
Validation loss: 1.8997850161726757

Epoch: 6| Step: 2
Training loss: 0.7985438108444214
Validation loss: 1.9085283715237853

Epoch: 6| Step: 3
Training loss: 1.746666669845581
Validation loss: 1.919310026271369

Epoch: 6| Step: 4
Training loss: 1.016790509223938
Validation loss: 1.926061830212993

Epoch: 6| Step: 5
Training loss: 1.4013242721557617
Validation loss: 1.962897608357091

Epoch: 6| Step: 6
Training loss: 1.6308649778366089
Validation loss: 1.9382052434388028

Epoch: 6| Step: 7
Training loss: 1.3049015998840332
Validation loss: 1.944183881564807

Epoch: 6| Step: 8
Training loss: 0.9442493319511414
Validation loss: 1.9213879544247863

Epoch: 6| Step: 9
Training loss: 0.9615970849990845
Validation loss: 1.899937973227552

Epoch: 6| Step: 10
Training loss: 0.6583880186080933
Validation loss: 1.9161188064082977

Epoch: 6| Step: 11
Training loss: 0.6525249481201172
Validation loss: 1.9190238560399702

Epoch: 6| Step: 12
Training loss: 0.670501708984375
Validation loss: 1.945898086793961

Epoch: 6| Step: 13
Training loss: 0.7975888848304749
Validation loss: 1.9823022991098382

Epoch: 246| Step: 0
Training loss: 0.7352288365364075
Validation loss: 1.9553297873466247

Epoch: 6| Step: 1
Training loss: 1.083840250968933
Validation loss: 1.9511706085615261

Epoch: 6| Step: 2
Training loss: 1.095799207687378
Validation loss: 1.9254888949855682

Epoch: 6| Step: 3
Training loss: 0.3946758508682251
Validation loss: 1.9216628177191621

Epoch: 6| Step: 4
Training loss: 0.9830564260482788
Validation loss: 1.9183493634705902

Epoch: 6| Step: 5
Training loss: 1.3596751689910889
Validation loss: 1.9168079591566516

Epoch: 6| Step: 6
Training loss: 0.8892322182655334
Validation loss: 1.907542779881467

Epoch: 6| Step: 7
Training loss: 0.5173258781433105
Validation loss: 1.9312569146515222

Epoch: 6| Step: 8
Training loss: 1.2097705602645874
Validation loss: 1.9100438343581332

Epoch: 6| Step: 9
Training loss: 0.8013216257095337
Validation loss: 1.9048199320352206

Epoch: 6| Step: 10
Training loss: 1.2587087154388428
Validation loss: 1.8960780059137652

Epoch: 6| Step: 11
Training loss: 0.9360511302947998
Validation loss: 1.8908799232975129

Epoch: 6| Step: 12
Training loss: 1.3169760704040527
Validation loss: 1.8792710791351974

Epoch: 6| Step: 13
Training loss: 1.2184091806411743
Validation loss: 1.889152580691922

Epoch: 247| Step: 0
Training loss: 0.9158095717430115
Validation loss: 1.8944890858024679

Epoch: 6| Step: 1
Training loss: 1.0620176792144775
Validation loss: 1.8851922737654818

Epoch: 6| Step: 2
Training loss: 0.9658225774765015
Validation loss: 1.9069546986651678

Epoch: 6| Step: 3
Training loss: 1.0458704233169556
Validation loss: 1.9606629058878908

Epoch: 6| Step: 4
Training loss: 0.9922876358032227
Validation loss: 1.972961123271655

Epoch: 6| Step: 5
Training loss: 0.880002498626709
Validation loss: 1.9814708027788388

Epoch: 6| Step: 6
Training loss: 1.1790575981140137
Validation loss: 2.0066238808375534

Epoch: 6| Step: 7
Training loss: 1.363398551940918
Validation loss: 1.9803844498049827

Epoch: 6| Step: 8
Training loss: 0.5097067952156067
Validation loss: 1.9563519313771238

Epoch: 6| Step: 9
Training loss: 0.8387592434883118
Validation loss: 1.9205226846920547

Epoch: 6| Step: 10
Training loss: 1.0022145509719849
Validation loss: 1.9355451189061648

Epoch: 6| Step: 11
Training loss: 1.3274750709533691
Validation loss: 1.9232240620479788

Epoch: 6| Step: 12
Training loss: 0.7901772856712341
Validation loss: 1.9085702665390507

Epoch: 6| Step: 13
Training loss: 0.8289197087287903
Validation loss: 1.883894858821746

Epoch: 248| Step: 0
Training loss: 0.7141402363777161
Validation loss: 1.9202250357597106

Epoch: 6| Step: 1
Training loss: 1.402397871017456
Validation loss: 1.907937530548342

Epoch: 6| Step: 2
Training loss: 0.8917577266693115
Validation loss: 1.8901226956357238

Epoch: 6| Step: 3
Training loss: 0.8518062829971313
Validation loss: 1.8978789352601575

Epoch: 6| Step: 4
Training loss: 0.8604943156242371
Validation loss: 1.9174180235914005

Epoch: 6| Step: 5
Training loss: 0.7699581384658813
Validation loss: 1.9304879224428566

Epoch: 6| Step: 6
Training loss: 1.4115493297576904
Validation loss: 1.917354360703499

Epoch: 6| Step: 7
Training loss: 0.8305096626281738
Validation loss: 1.978865167146088

Epoch: 6| Step: 8
Training loss: 0.7942224144935608
Validation loss: 1.9239566544050812

Epoch: 6| Step: 9
Training loss: 0.823987603187561
Validation loss: 1.9350735102930376

Epoch: 6| Step: 10
Training loss: 1.337517499923706
Validation loss: 1.9301532929943455

Epoch: 6| Step: 11
Training loss: 0.6401151418685913
Validation loss: 1.9200127534968878

Epoch: 6| Step: 12
Training loss: 1.362390160560608
Validation loss: 1.8870633366287395

Epoch: 6| Step: 13
Training loss: 0.5454481244087219
Validation loss: 1.8739039590281825

Epoch: 249| Step: 0
Training loss: 0.7426319122314453
Validation loss: 1.868025807924168

Epoch: 6| Step: 1
Training loss: 0.4957340657711029
Validation loss: 1.868310482271256

Epoch: 6| Step: 2
Training loss: 1.6510621309280396
Validation loss: 1.8632680818598757

Epoch: 6| Step: 3
Training loss: 1.106317400932312
Validation loss: 1.8665707316449893

Epoch: 6| Step: 4
Training loss: 0.7487711906433105
Validation loss: 1.8668350096671813

Epoch: 6| Step: 5
Training loss: 1.2665815353393555
Validation loss: 1.877622640261086

Epoch: 6| Step: 6
Training loss: 0.7836440801620483
Validation loss: 1.9550856851762342

Epoch: 6| Step: 7
Training loss: 0.6987007856369019
Validation loss: 1.929634483911658

Epoch: 6| Step: 8
Training loss: 1.3055555820465088
Validation loss: 1.9581280703185706

Epoch: 6| Step: 9
Training loss: 0.7696876525878906
Validation loss: 1.9423473829864173

Epoch: 6| Step: 10
Training loss: 0.7033021450042725
Validation loss: 1.9194040195916289

Epoch: 6| Step: 11
Training loss: 0.8437031507492065
Validation loss: 1.9234089364287674

Epoch: 6| Step: 12
Training loss: 1.3024775981903076
Validation loss: 1.9326526413681686

Epoch: 6| Step: 13
Training loss: 1.1957671642303467
Validation loss: 1.942465636038011

Epoch: 250| Step: 0
Training loss: 1.0158581733703613
Validation loss: 1.9350043983869656

Epoch: 6| Step: 1
Training loss: 1.305450439453125
Validation loss: 1.9175095494075487

Epoch: 6| Step: 2
Training loss: 1.0714805126190186
Validation loss: 1.9304665416799567

Epoch: 6| Step: 3
Training loss: 0.7140055894851685
Validation loss: 1.9169654577009139

Epoch: 6| Step: 4
Training loss: 0.5815227627754211
Validation loss: 1.8901066113543767

Epoch: 6| Step: 5
Training loss: 0.9547792673110962
Validation loss: 1.8987396404307375

Epoch: 6| Step: 6
Training loss: 0.4660854935646057
Validation loss: 1.8641521059056765

Epoch: 6| Step: 7
Training loss: 1.041447639465332
Validation loss: 1.9041197838321808

Epoch: 6| Step: 8
Training loss: 1.0433001518249512
Validation loss: 1.9159432329157347

Epoch: 6| Step: 9
Training loss: 1.106372356414795
Validation loss: 1.9078731953456838

Epoch: 6| Step: 10
Training loss: 1.0913034677505493
Validation loss: 1.8972482450546757

Epoch: 6| Step: 11
Training loss: 0.8440115451812744
Validation loss: 1.935935128119684

Epoch: 6| Step: 12
Training loss: 1.5430285930633545
Validation loss: 1.9322193207279328

Epoch: 6| Step: 13
Training loss: 0.6150033473968506
Validation loss: 1.930691643427777

Epoch: 251| Step: 0
Training loss: 0.975602388381958
Validation loss: 1.9392185788000784

Epoch: 6| Step: 1
Training loss: 1.045595407485962
Validation loss: 1.913934548695882

Epoch: 6| Step: 2
Training loss: 0.6911041736602783
Validation loss: 1.909802698319958

Epoch: 6| Step: 3
Training loss: 1.2458151578903198
Validation loss: 1.877429840385273

Epoch: 6| Step: 4
Training loss: 0.9697622656822205
Validation loss: 1.930826965198722

Epoch: 6| Step: 5
Training loss: 1.0729804039001465
Validation loss: 1.9108015914117136

Epoch: 6| Step: 6
Training loss: 0.8746308088302612
Validation loss: 1.875216766070294

Epoch: 6| Step: 7
Training loss: 0.6913692951202393
Validation loss: 1.895843457150203

Epoch: 6| Step: 8
Training loss: 1.1931778192520142
Validation loss: 1.8983083873666742

Epoch: 6| Step: 9
Training loss: 1.1275687217712402
Validation loss: 1.910509701698057

Epoch: 6| Step: 10
Training loss: 0.9114465713500977
Validation loss: 1.8977810900698426

Epoch: 6| Step: 11
Training loss: 0.8649897575378418
Validation loss: 1.9158533696205384

Epoch: 6| Step: 12
Training loss: 0.6560182571411133
Validation loss: 1.9286096672857962

Epoch: 6| Step: 13
Training loss: 0.46474170684814453
Validation loss: 1.9408398623107581

Epoch: 252| Step: 0
Training loss: 0.9038742780685425
Validation loss: 1.9266668878575808

Epoch: 6| Step: 1
Training loss: 0.9867849349975586
Validation loss: 1.944058382382957

Epoch: 6| Step: 2
Training loss: 0.7417895793914795
Validation loss: 1.933963773071125

Epoch: 6| Step: 3
Training loss: 0.9916133880615234
Validation loss: 1.9362395630087903

Epoch: 6| Step: 4
Training loss: 0.834347128868103
Validation loss: 1.9087844484595842

Epoch: 6| Step: 5
Training loss: 1.0518819093704224
Validation loss: 1.892880061621307

Epoch: 6| Step: 6
Training loss: 1.131436824798584
Validation loss: 1.8849088530386648

Epoch: 6| Step: 7
Training loss: 0.6385835409164429
Validation loss: 1.844897513748497

Epoch: 6| Step: 8
Training loss: 0.9865845441818237
Validation loss: 1.8562370602802565

Epoch: 6| Step: 9
Training loss: 1.1239162683486938
Validation loss: 1.8705630315247403

Epoch: 6| Step: 10
Training loss: 0.439208984375
Validation loss: 1.8525843722845918

Epoch: 6| Step: 11
Training loss: 0.9088203310966492
Validation loss: 1.8600395725619407

Epoch: 6| Step: 12
Training loss: 1.2133899927139282
Validation loss: 1.8899856434073499

Epoch: 6| Step: 13
Training loss: 0.813840389251709
Validation loss: 1.8954014855046426

Epoch: 253| Step: 0
Training loss: 0.9111274480819702
Validation loss: 1.8709371064298896

Epoch: 6| Step: 1
Training loss: 0.7726035714149475
Validation loss: 1.8647445837656658

Epoch: 6| Step: 2
Training loss: 0.771461009979248
Validation loss: 1.8546288603095598

Epoch: 6| Step: 3
Training loss: 1.4323132038116455
Validation loss: 1.8547433178911927

Epoch: 6| Step: 4
Training loss: 1.075979232788086
Validation loss: 1.863592319591071

Epoch: 6| Step: 5
Training loss: 0.82809978723526
Validation loss: 1.8595447668465235

Epoch: 6| Step: 6
Training loss: 0.650029718875885
Validation loss: 1.8434715687587697

Epoch: 6| Step: 7
Training loss: 0.7004337310791016
Validation loss: 1.8345236560349822

Epoch: 6| Step: 8
Training loss: 1.3256100416183472
Validation loss: 1.855418816689522

Epoch: 6| Step: 9
Training loss: 0.839408278465271
Validation loss: 1.8671671113660258

Epoch: 6| Step: 10
Training loss: 0.8152342438697815
Validation loss: 1.9091369362287625

Epoch: 6| Step: 11
Training loss: 0.7666032314300537
Validation loss: 1.90789875676555

Epoch: 6| Step: 12
Training loss: 1.1185216903686523
Validation loss: 1.9245445292483094

Epoch: 6| Step: 13
Training loss: 0.671149492263794
Validation loss: 1.945768738305697

Epoch: 254| Step: 0
Training loss: 0.8059173822402954
Validation loss: 1.940063371453234

Epoch: 6| Step: 1
Training loss: 1.0442016124725342
Validation loss: 1.9394331465485275

Epoch: 6| Step: 2
Training loss: 0.9773385524749756
Validation loss: 1.946995617240988

Epoch: 6| Step: 3
Training loss: 1.1691582202911377
Validation loss: 1.9576253173171834

Epoch: 6| Step: 4
Training loss: 0.6783595085144043
Validation loss: 1.9589249703191942

Epoch: 6| Step: 5
Training loss: 0.8468186855316162
Validation loss: 1.9549855250184254

Epoch: 6| Step: 6
Training loss: 0.7028613090515137
Validation loss: 1.964003768018497

Epoch: 6| Step: 7
Training loss: 1.094125509262085
Validation loss: 1.9496245666216778

Epoch: 6| Step: 8
Training loss: 0.43937498331069946
Validation loss: 1.972648448841546

Epoch: 6| Step: 9
Training loss: 0.6163688898086548
Validation loss: 1.973724199879554

Epoch: 6| Step: 10
Training loss: 1.3961436748504639
Validation loss: 1.9086913139589372

Epoch: 6| Step: 11
Training loss: 0.815244734287262
Validation loss: 1.8958881003882295

Epoch: 6| Step: 12
Training loss: 0.7656238079071045
Validation loss: 1.8460095851652083

Epoch: 6| Step: 13
Training loss: 0.9887850880622864
Validation loss: 1.8334780521290277

Epoch: 255| Step: 0
Training loss: 0.9930325150489807
Validation loss: 1.7788589769794094

Epoch: 6| Step: 1
Training loss: 0.6666032075881958
Validation loss: 1.7720682915820871

Epoch: 6| Step: 2
Training loss: 1.3540961742401123
Validation loss: 1.8090566281349427

Epoch: 6| Step: 3
Training loss: 1.2807139158248901
Validation loss: 1.7867562411933817

Epoch: 6| Step: 4
Training loss: 0.9383932948112488
Validation loss: 1.7891160544528757

Epoch: 6| Step: 5
Training loss: 0.803773045539856
Validation loss: 1.8018815440516318

Epoch: 6| Step: 6
Training loss: 0.7350224852561951
Validation loss: 1.8027122610358781

Epoch: 6| Step: 7
Training loss: 0.784085750579834
Validation loss: 1.8525843210117792

Epoch: 6| Step: 8
Training loss: 0.7187463045120239
Validation loss: 1.8519523605223625

Epoch: 6| Step: 9
Training loss: 0.8344545364379883
Validation loss: 1.9073080913994902

Epoch: 6| Step: 10
Training loss: 0.7731386423110962
Validation loss: 1.9354345298582507

Epoch: 6| Step: 11
Training loss: 0.782066822052002
Validation loss: 1.9363917727624216

Epoch: 6| Step: 12
Training loss: 0.8931172490119934
Validation loss: 1.9410383560324227

Epoch: 6| Step: 13
Training loss: 1.2280385494232178
Validation loss: 1.9537447652509135

Epoch: 256| Step: 0
Training loss: 0.8713094592094421
Validation loss: 1.945872978497577

Epoch: 6| Step: 1
Training loss: 0.6817949414253235
Validation loss: 1.9160480076266873

Epoch: 6| Step: 2
Training loss: 0.3962526321411133
Validation loss: 1.9169382946465605

Epoch: 6| Step: 3
Training loss: 1.0776253938674927
Validation loss: 1.8733119387780466

Epoch: 6| Step: 4
Training loss: 1.437311053276062
Validation loss: 1.8767788000004266

Epoch: 6| Step: 5
Training loss: 0.9819954633712769
Validation loss: 1.857336982603996

Epoch: 6| Step: 6
Training loss: 0.5751572251319885
Validation loss: 1.871900523862531

Epoch: 6| Step: 7
Training loss: 0.7105096578598022
Validation loss: 1.836080671638571

Epoch: 6| Step: 8
Training loss: 1.55202054977417
Validation loss: 1.8835105075631091

Epoch: 6| Step: 9
Training loss: 0.5524680614471436
Validation loss: 1.8749499910621232

Epoch: 6| Step: 10
Training loss: 0.9587641358375549
Validation loss: 1.8638036853523665

Epoch: 6| Step: 11
Training loss: 1.2759895324707031
Validation loss: 1.8618864346575994

Epoch: 6| Step: 12
Training loss: 0.8100339770317078
Validation loss: 1.8799766494381813

Epoch: 6| Step: 13
Training loss: 0.4221533536911011
Validation loss: 1.8697352050453104

Epoch: 257| Step: 0
Training loss: 1.0874543190002441
Validation loss: 1.8646823552346998

Epoch: 6| Step: 1
Training loss: 0.9065777063369751
Validation loss: 1.871597497693954

Epoch: 6| Step: 2
Training loss: 0.9326112866401672
Validation loss: 1.9030166723394906

Epoch: 6| Step: 3
Training loss: 0.7557353973388672
Validation loss: 1.9169402686498498

Epoch: 6| Step: 4
Training loss: 0.7034261226654053
Validation loss: 1.9245929230925858

Epoch: 6| Step: 5
Training loss: 1.2738947868347168
Validation loss: 1.9056453858652422

Epoch: 6| Step: 6
Training loss: 0.8751746416091919
Validation loss: 1.891759632736124

Epoch: 6| Step: 7
Training loss: 0.8995113968849182
Validation loss: 1.9107316886225054

Epoch: 6| Step: 8
Training loss: 1.0406816005706787
Validation loss: 1.8919820990613712

Epoch: 6| Step: 9
Training loss: 1.0302574634552002
Validation loss: 1.9095934655076714

Epoch: 6| Step: 10
Training loss: 0.7538857460021973
Validation loss: 1.8853327587086668

Epoch: 6| Step: 11
Training loss: 0.6838089227676392
Validation loss: 1.9040270082412227

Epoch: 6| Step: 12
Training loss: 0.8152140378952026
Validation loss: 1.924603158427823

Epoch: 6| Step: 13
Training loss: 0.25571563839912415
Validation loss: 1.883084007488784

Epoch: 258| Step: 0
Training loss: 1.1132627725601196
Validation loss: 1.8914899005684802

Epoch: 6| Step: 1
Training loss: 0.8262598514556885
Validation loss: 1.8646714815529444

Epoch: 6| Step: 2
Training loss: 1.0583062171936035
Validation loss: 1.8942339984319543

Epoch: 6| Step: 3
Training loss: 1.115181803703308
Validation loss: 1.843070594213342

Epoch: 6| Step: 4
Training loss: 0.7484649419784546
Validation loss: 1.8506272236506145

Epoch: 6| Step: 5
Training loss: 0.8530319333076477
Validation loss: 1.8542664832966302

Epoch: 6| Step: 6
Training loss: 0.8194916248321533
Validation loss: 1.8479248067384124

Epoch: 6| Step: 7
Training loss: 0.5276567935943604
Validation loss: 1.8589033080685524

Epoch: 6| Step: 8
Training loss: 1.1451295614242554
Validation loss: 1.8813134290838753

Epoch: 6| Step: 9
Training loss: 0.6408429741859436
Validation loss: 1.874733498019557

Epoch: 6| Step: 10
Training loss: 0.5946736931800842
Validation loss: 1.878742528218095

Epoch: 6| Step: 11
Training loss: 0.9430767297744751
Validation loss: 1.9105668503751037

Epoch: 6| Step: 12
Training loss: 0.6344349384307861
Validation loss: 1.9133357809435936

Epoch: 6| Step: 13
Training loss: 1.1321440935134888
Validation loss: 1.9016113755523518

Epoch: 259| Step: 0
Training loss: 1.2540090084075928
Validation loss: 1.9371626107923445

Epoch: 6| Step: 1
Training loss: 0.7848721146583557
Validation loss: 1.9229203667691959

Epoch: 6| Step: 2
Training loss: 0.9105163812637329
Validation loss: 1.9046764514779533

Epoch: 6| Step: 3
Training loss: 0.6858580112457275
Validation loss: 1.904054775032946

Epoch: 6| Step: 4
Training loss: 1.0042427778244019
Validation loss: 1.8899831720577773

Epoch: 6| Step: 5
Training loss: 0.5177242755889893
Validation loss: 1.8731961404123614

Epoch: 6| Step: 6
Training loss: 0.8757221698760986
Validation loss: 1.852759873995217

Epoch: 6| Step: 7
Training loss: 1.1641584634780884
Validation loss: 1.8639857743376045

Epoch: 6| Step: 8
Training loss: 0.5201858282089233
Validation loss: 1.8571053128088675

Epoch: 6| Step: 9
Training loss: 0.5785196423530579
Validation loss: 1.8363518868723223

Epoch: 6| Step: 10
Training loss: 0.9360467195510864
Validation loss: 1.7964162877810899

Epoch: 6| Step: 11
Training loss: 0.8079030513763428
Validation loss: 1.8055181644296134

Epoch: 6| Step: 12
Training loss: 0.8951424360275269
Validation loss: 1.845083120048687

Epoch: 6| Step: 13
Training loss: 1.4077210426330566
Validation loss: 1.797517373997678

Epoch: 260| Step: 0
Training loss: 0.6455152034759521
Validation loss: 1.803371589670899

Epoch: 6| Step: 1
Training loss: 0.5782816410064697
Validation loss: 1.8222913838201953

Epoch: 6| Step: 2
Training loss: 0.9038918018341064
Validation loss: 1.8421662276790989

Epoch: 6| Step: 3
Training loss: 0.5469451546669006
Validation loss: 1.8690338262947657

Epoch: 6| Step: 4
Training loss: 0.8921916484832764
Validation loss: 1.8851317539009997

Epoch: 6| Step: 5
Training loss: 0.5758299827575684
Validation loss: 1.8807858344047301

Epoch: 6| Step: 6
Training loss: 1.1563408374786377
Validation loss: 1.916427848159626

Epoch: 6| Step: 7
Training loss: 1.140746831893921
Validation loss: 1.8927371078921902

Epoch: 6| Step: 8
Training loss: 1.0460718870162964
Validation loss: 1.8786396903376426

Epoch: 6| Step: 9
Training loss: 1.1287124156951904
Validation loss: 1.86998745318382

Epoch: 6| Step: 10
Training loss: 0.575476884841919
Validation loss: 1.846323892634402

Epoch: 6| Step: 11
Training loss: 0.6649386882781982
Validation loss: 1.8692702683069373

Epoch: 6| Step: 12
Training loss: 1.2146928310394287
Validation loss: 1.872619039268904

Epoch: 6| Step: 13
Training loss: 0.9194536209106445
Validation loss: 1.871825215637043

Epoch: 261| Step: 0
Training loss: 0.7494550943374634
Validation loss: 1.9053842700937742

Epoch: 6| Step: 1
Training loss: 0.9947192668914795
Validation loss: 1.9026222831459456

Epoch: 6| Step: 2
Training loss: 0.7188339233398438
Validation loss: 1.9268912743496638

Epoch: 6| Step: 3
Training loss: 0.8155131340026855
Validation loss: 1.9187598382273028

Epoch: 6| Step: 4
Training loss: 0.726029634475708
Validation loss: 1.8922720711718324

Epoch: 6| Step: 5
Training loss: 0.8398696184158325
Validation loss: 1.8671798654781875

Epoch: 6| Step: 6
Training loss: 1.050199031829834
Validation loss: 1.869735425518405

Epoch: 6| Step: 7
Training loss: 0.891777753829956
Validation loss: 1.8718447351968417

Epoch: 6| Step: 8
Training loss: 1.1422789096832275
Validation loss: 1.897267851778256

Epoch: 6| Step: 9
Training loss: 0.7347217202186584
Validation loss: 1.8768336208917762

Epoch: 6| Step: 10
Training loss: 1.030287265777588
Validation loss: 1.8517066150583246

Epoch: 6| Step: 11
Training loss: 1.202594518661499
Validation loss: 1.8281141090136703

Epoch: 6| Step: 12
Training loss: 0.6286883354187012
Validation loss: 1.8293841859345794

Epoch: 6| Step: 13
Training loss: 0.5099616646766663
Validation loss: 1.8517570111059374

Epoch: 262| Step: 0
Training loss: 0.9825478792190552
Validation loss: 1.8782853323926207

Epoch: 6| Step: 1
Training loss: 0.9338847398757935
Validation loss: 1.8526216988922448

Epoch: 6| Step: 2
Training loss: 0.8093228340148926
Validation loss: 1.8624134653358049

Epoch: 6| Step: 3
Training loss: 0.981985330581665
Validation loss: 1.8741890820123817

Epoch: 6| Step: 4
Training loss: 1.0204105377197266
Validation loss: 1.8703525527831046

Epoch: 6| Step: 5
Training loss: 0.6029624938964844
Validation loss: 1.9130216824111117

Epoch: 6| Step: 6
Training loss: 1.1859471797943115
Validation loss: 1.914269067907846

Epoch: 6| Step: 7
Training loss: 0.4114280045032501
Validation loss: 1.9034238874271352

Epoch: 6| Step: 8
Training loss: 0.7214744687080383
Validation loss: 1.9052741296829716

Epoch: 6| Step: 9
Training loss: 1.206984519958496
Validation loss: 1.8977410998395694

Epoch: 6| Step: 10
Training loss: 0.8111004829406738
Validation loss: 1.9449829786054549

Epoch: 6| Step: 11
Training loss: 0.6559209823608398
Validation loss: 1.9198496764706028

Epoch: 6| Step: 12
Training loss: 0.7006306648254395
Validation loss: 1.8779649606315039

Epoch: 6| Step: 13
Training loss: 0.8210901618003845
Validation loss: 1.8614617240044378

Epoch: 263| Step: 0
Training loss: 1.0391931533813477
Validation loss: 1.861071898091224

Epoch: 6| Step: 1
Training loss: 0.8195748925209045
Validation loss: 1.8338644414819696

Epoch: 6| Step: 2
Training loss: 0.6592286229133606
Validation loss: 1.8627091107829925

Epoch: 6| Step: 3
Training loss: 1.0579805374145508
Validation loss: 1.8474727548578733

Epoch: 6| Step: 4
Training loss: 0.49247562885284424
Validation loss: 1.8738664055383334

Epoch: 6| Step: 5
Training loss: 0.9672305583953857
Validation loss: 1.839142886541223

Epoch: 6| Step: 6
Training loss: 1.0510923862457275
Validation loss: 1.8661790663196194

Epoch: 6| Step: 7
Training loss: 0.7717453241348267
Validation loss: 1.8241932725393644

Epoch: 6| Step: 8
Training loss: 0.6186656355857849
Validation loss: 1.840639397662173

Epoch: 6| Step: 9
Training loss: 0.6424864530563354
Validation loss: 1.859235994277462

Epoch: 6| Step: 10
Training loss: 0.8832114934921265
Validation loss: 1.8597070696533367

Epoch: 6| Step: 11
Training loss: 0.4877328872680664
Validation loss: 1.8716412449395785

Epoch: 6| Step: 12
Training loss: 0.8769746422767639
Validation loss: 1.8775013390407767

Epoch: 6| Step: 13
Training loss: 1.2403489351272583
Validation loss: 1.8646982792885072

Epoch: 264| Step: 0
Training loss: 0.5575429201126099
Validation loss: 1.8845977834475938

Epoch: 6| Step: 1
Training loss: 0.877485990524292
Validation loss: 1.8706182177348802

Epoch: 6| Step: 2
Training loss: 0.9156975746154785
Validation loss: 1.8747200017334313

Epoch: 6| Step: 3
Training loss: 0.9468445181846619
Validation loss: 1.8892565952834262

Epoch: 6| Step: 4
Training loss: 0.6025252342224121
Validation loss: 1.8521651811497186

Epoch: 6| Step: 5
Training loss: 1.4047738313674927
Validation loss: 1.8633766417862268

Epoch: 6| Step: 6
Training loss: 0.714027464389801
Validation loss: 1.8293824272771035

Epoch: 6| Step: 7
Training loss: 0.7678169012069702
Validation loss: 1.8255644716242307

Epoch: 6| Step: 8
Training loss: 0.8093178272247314
Validation loss: 1.817260665278281

Epoch: 6| Step: 9
Training loss: 0.7099642753601074
Validation loss: 1.7762173491139566

Epoch: 6| Step: 10
Training loss: 0.9206393957138062
Validation loss: 1.78820022203589

Epoch: 6| Step: 11
Training loss: 0.5506726503372192
Validation loss: 1.796413965122674

Epoch: 6| Step: 12
Training loss: 0.6108925938606262
Validation loss: 1.7875824218155236

Epoch: 6| Step: 13
Training loss: 0.8239168524742126
Validation loss: 1.7925305943335257

Epoch: 265| Step: 0
Training loss: 0.6165667772293091
Validation loss: 1.7880602331571682

Epoch: 6| Step: 1
Training loss: 0.7203089594841003
Validation loss: 1.8217217704301238

Epoch: 6| Step: 2
Training loss: 1.2639071941375732
Validation loss: 1.8420876726027458

Epoch: 6| Step: 3
Training loss: 0.940470814704895
Validation loss: 1.822456927709682

Epoch: 6| Step: 4
Training loss: 0.7610602378845215
Validation loss: 1.8376110484523158

Epoch: 6| Step: 5
Training loss: 0.35540449619293213
Validation loss: 1.8592273419903171

Epoch: 6| Step: 6
Training loss: 1.0499879121780396
Validation loss: 1.8639246058720413

Epoch: 6| Step: 7
Training loss: 0.4062650203704834
Validation loss: 1.8821411773722658

Epoch: 6| Step: 8
Training loss: 0.46232476830482483
Validation loss: 1.8904890168097712

Epoch: 6| Step: 9
Training loss: 0.6678854823112488
Validation loss: 1.923897159996853

Epoch: 6| Step: 10
Training loss: 1.275322675704956
Validation loss: 1.9032636124600646

Epoch: 6| Step: 11
Training loss: 0.6700382232666016
Validation loss: 1.8953917064974386

Epoch: 6| Step: 12
Training loss: 1.3935410976409912
Validation loss: 1.858027861964318

Epoch: 6| Step: 13
Training loss: 0.7308720350265503
Validation loss: 1.864441417878674

Epoch: 266| Step: 0
Training loss: 0.7230365872383118
Validation loss: 1.8224052895781815

Epoch: 6| Step: 1
Training loss: 1.1965651512145996
Validation loss: 1.8163013945343673

Epoch: 6| Step: 2
Training loss: 1.2075929641723633
Validation loss: 1.8476976399780602

Epoch: 6| Step: 3
Training loss: 0.7936378717422485
Validation loss: 1.829807949322526

Epoch: 6| Step: 4
Training loss: 0.6336182951927185
Validation loss: 1.8068323776286135

Epoch: 6| Step: 5
Training loss: 0.7867580056190491
Validation loss: 1.8348385339142175

Epoch: 6| Step: 6
Training loss: 1.1708308458328247
Validation loss: 1.8389268113720802

Epoch: 6| Step: 7
Training loss: 0.21324928104877472
Validation loss: 1.84009135923078

Epoch: 6| Step: 8
Training loss: 1.119852066040039
Validation loss: 1.8479555973442652

Epoch: 6| Step: 9
Training loss: 0.28628748655319214
Validation loss: 1.8888386423869798

Epoch: 6| Step: 10
Training loss: 0.6719904541969299
Validation loss: 1.8773483614767752

Epoch: 6| Step: 11
Training loss: 1.0184481143951416
Validation loss: 1.879447397365365

Epoch: 6| Step: 12
Training loss: 0.566842257976532
Validation loss: 1.8885388053873533

Epoch: 6| Step: 13
Training loss: 0.44274622201919556
Validation loss: 1.8975450390128679

Epoch: 267| Step: 0
Training loss: 0.6662197113037109
Validation loss: 1.879984119886993

Epoch: 6| Step: 1
Training loss: 1.1230039596557617
Validation loss: 1.8457205731381652

Epoch: 6| Step: 2
Training loss: 0.5946987867355347
Validation loss: 1.8342173894246419

Epoch: 6| Step: 3
Training loss: 0.7476186156272888
Validation loss: 1.8408062124765048

Epoch: 6| Step: 4
Training loss: 0.7744166851043701
Validation loss: 1.8325616851929696

Epoch: 6| Step: 5
Training loss: 0.9797929525375366
Validation loss: 1.804166781005039

Epoch: 6| Step: 6
Training loss: 0.5797089338302612
Validation loss: 1.78594809321947

Epoch: 6| Step: 7
Training loss: 0.8371399641036987
Validation loss: 1.7748983726706555

Epoch: 6| Step: 8
Training loss: 0.7944412231445312
Validation loss: 1.7849136129502328

Epoch: 6| Step: 9
Training loss: 0.4155440330505371
Validation loss: 1.7963912179393153

Epoch: 6| Step: 10
Training loss: 0.7908334732055664
Validation loss: 1.8073665903460594

Epoch: 6| Step: 11
Training loss: 0.3178726136684418
Validation loss: 1.8463644366110525

Epoch: 6| Step: 12
Training loss: 1.4200265407562256
Validation loss: 1.8609684910825504

Epoch: 6| Step: 13
Training loss: 0.5836470127105713
Validation loss: 1.8495376084440498

Epoch: 268| Step: 0
Training loss: 1.3188902139663696
Validation loss: 1.8336919302581458

Epoch: 6| Step: 1
Training loss: 0.3972325325012207
Validation loss: 1.8299988110860188

Epoch: 6| Step: 2
Training loss: 0.4867658019065857
Validation loss: 1.8269734472356818

Epoch: 6| Step: 3
Training loss: 0.7996649742126465
Validation loss: 1.8144039312998455

Epoch: 6| Step: 4
Training loss: 0.6221280694007874
Validation loss: 1.8256388056662776

Epoch: 6| Step: 5
Training loss: 0.7940521836280823
Validation loss: 1.8176829507274013

Epoch: 6| Step: 6
Training loss: 1.083931803703308
Validation loss: 1.8613503825279973

Epoch: 6| Step: 7
Training loss: 0.7066885828971863
Validation loss: 1.8608417267440467

Epoch: 6| Step: 8
Training loss: 0.8619279861450195
Validation loss: 1.8635316177081036

Epoch: 6| Step: 9
Training loss: 0.7166333198547363
Validation loss: 1.8578083592076455

Epoch: 6| Step: 10
Training loss: 0.6091686487197876
Validation loss: 1.8312946519544047

Epoch: 6| Step: 11
Training loss: 0.8326276540756226
Validation loss: 1.8326981452203566

Epoch: 6| Step: 12
Training loss: 0.816027820110321
Validation loss: 1.8219529121152815

Epoch: 6| Step: 13
Training loss: 1.0699734687805176
Validation loss: 1.8191200866494128

Epoch: 269| Step: 0
Training loss: 0.6889678835868835
Validation loss: 1.796646741128737

Epoch: 6| Step: 1
Training loss: 0.7514653205871582
Validation loss: 1.8097544280431603

Epoch: 6| Step: 2
Training loss: 0.9843636751174927
Validation loss: 1.829072936888664

Epoch: 6| Step: 3
Training loss: 1.188844084739685
Validation loss: 1.8822790089473929

Epoch: 6| Step: 4
Training loss: 0.6485937833786011
Validation loss: 1.8714079036507556

Epoch: 6| Step: 5
Training loss: 0.8194389343261719
Validation loss: 1.905771178583945

Epoch: 6| Step: 6
Training loss: 0.5591996908187866
Validation loss: 1.8874180547652706

Epoch: 6| Step: 7
Training loss: 1.2788934707641602
Validation loss: 1.8582787770096973

Epoch: 6| Step: 8
Training loss: 0.6904856562614441
Validation loss: 1.841319900687023

Epoch: 6| Step: 9
Training loss: 0.672205924987793
Validation loss: 1.8142735547916864

Epoch: 6| Step: 10
Training loss: 1.0395472049713135
Validation loss: 1.795642670764718

Epoch: 6| Step: 11
Training loss: 0.940375566482544
Validation loss: 1.8093918472208002

Epoch: 6| Step: 12
Training loss: 0.3434719443321228
Validation loss: 1.8472501565051336

Epoch: 6| Step: 13
Training loss: 0.5641466379165649
Validation loss: 1.881326893324493

Epoch: 270| Step: 0
Training loss: 0.7451450824737549
Validation loss: 1.8951913618272351

Epoch: 6| Step: 1
Training loss: 0.5074087977409363
Validation loss: 1.8569174505049182

Epoch: 6| Step: 2
Training loss: 1.0926544666290283
Validation loss: 1.8657827428592149

Epoch: 6| Step: 3
Training loss: 0.9405196905136108
Validation loss: 1.8840068437719857

Epoch: 6| Step: 4
Training loss: 0.7011877298355103
Validation loss: 1.8496369905369257

Epoch: 6| Step: 5
Training loss: 0.8838192224502563
Validation loss: 1.8587840577607513

Epoch: 6| Step: 6
Training loss: 0.9552702307701111
Validation loss: 1.8447864209451983

Epoch: 6| Step: 7
Training loss: 0.6654214262962341
Validation loss: 1.852057421079246

Epoch: 6| Step: 8
Training loss: 0.9278354644775391
Validation loss: 1.8154785786905596

Epoch: 6| Step: 9
Training loss: 0.787311315536499
Validation loss: 1.8347261182723507

Epoch: 6| Step: 10
Training loss: 0.547994077205658
Validation loss: 1.8343976620704896

Epoch: 6| Step: 11
Training loss: 0.7099537253379822
Validation loss: 1.7876460821397844

Epoch: 6| Step: 12
Training loss: 0.7644674777984619
Validation loss: 1.8328119670191119

Epoch: 6| Step: 13
Training loss: 0.6460568904876709
Validation loss: 1.8134461910493913

Epoch: 271| Step: 0
Training loss: 1.0361387729644775
Validation loss: 1.8492012062380392

Epoch: 6| Step: 1
Training loss: 0.7109400629997253
Validation loss: 1.87368296423266

Epoch: 6| Step: 2
Training loss: 0.6623790264129639
Validation loss: 1.9040454472264936

Epoch: 6| Step: 3
Training loss: 0.6311866044998169
Validation loss: 1.9491121192132272

Epoch: 6| Step: 4
Training loss: 1.06044602394104
Validation loss: 1.9829478251036776

Epoch: 6| Step: 5
Training loss: 0.8578811883926392
Validation loss: 2.0133212612521265

Epoch: 6| Step: 6
Training loss: 0.8108214139938354
Validation loss: 1.965384873010779

Epoch: 6| Step: 7
Training loss: 0.8929678201675415
Validation loss: 1.94051375696736

Epoch: 6| Step: 8
Training loss: 0.5771501660346985
Validation loss: 1.8652755752686532

Epoch: 6| Step: 9
Training loss: 0.824700653553009
Validation loss: 1.8413460998124973

Epoch: 6| Step: 10
Training loss: 0.84768146276474
Validation loss: 1.7989539818097187

Epoch: 6| Step: 11
Training loss: 0.877293050289154
Validation loss: 1.7793081998825073

Epoch: 6| Step: 12
Training loss: 0.6966853141784668
Validation loss: 1.8093496189322522

Epoch: 6| Step: 13
Training loss: 0.4209394156932831
Validation loss: 1.7591426859619796

Epoch: 272| Step: 0
Training loss: 0.7950631380081177
Validation loss: 1.7584331804706204

Epoch: 6| Step: 1
Training loss: 0.5379867553710938
Validation loss: 1.7556993794697586

Epoch: 6| Step: 2
Training loss: 0.8656972050666809
Validation loss: 1.7487773113353278

Epoch: 6| Step: 3
Training loss: 0.5034520626068115
Validation loss: 1.8020590659110778

Epoch: 6| Step: 4
Training loss: 0.7092505097389221
Validation loss: 1.820045832664736

Epoch: 6| Step: 5
Training loss: 1.229411244392395
Validation loss: 1.8672116123219973

Epoch: 6| Step: 6
Training loss: 0.6343417167663574
Validation loss: 1.902554496642082

Epoch: 6| Step: 7
Training loss: 0.3994109630584717
Validation loss: 1.9072009312209262

Epoch: 6| Step: 8
Training loss: 0.9540508389472961
Validation loss: 1.9172764721737112

Epoch: 6| Step: 9
Training loss: 0.9153844714164734
Validation loss: 1.9253097247051936

Epoch: 6| Step: 10
Training loss: 0.5868254899978638
Validation loss: 1.8807091584769629

Epoch: 6| Step: 11
Training loss: 0.5488994121551514
Validation loss: 1.8848254654997139

Epoch: 6| Step: 12
Training loss: 1.078831672668457
Validation loss: 1.8857709412933679

Epoch: 6| Step: 13
Training loss: 1.0154950618743896
Validation loss: 1.8327220383510794

Epoch: 273| Step: 0
Training loss: 0.6243987083435059
Validation loss: 1.842846825558652

Epoch: 6| Step: 1
Training loss: 0.834810197353363
Validation loss: 1.831122225330722

Epoch: 6| Step: 2
Training loss: 0.7797579765319824
Validation loss: 1.78287721449329

Epoch: 6| Step: 3
Training loss: 0.8880242109298706
Validation loss: 1.7725361944526754

Epoch: 6| Step: 4
Training loss: 0.6886548399925232
Validation loss: 1.7609326980447257

Epoch: 6| Step: 5
Training loss: 0.5319706797599792
Validation loss: 1.760185521136048

Epoch: 6| Step: 6
Training loss: 0.9675787091255188
Validation loss: 1.783468133659773

Epoch: 6| Step: 7
Training loss: 1.122255802154541
Validation loss: 1.7771884484957623

Epoch: 6| Step: 8
Training loss: 0.6819192171096802
Validation loss: 1.8157705953044276

Epoch: 6| Step: 9
Training loss: 0.44064250588417053
Validation loss: 1.8368757168451946

Epoch: 6| Step: 10
Training loss: 0.5468787550926208
Validation loss: 1.8519344816925705

Epoch: 6| Step: 11
Training loss: 0.8399137854576111
Validation loss: 1.8909039215375019

Epoch: 6| Step: 12
Training loss: 0.6215484142303467
Validation loss: 1.8776973165491575

Epoch: 6| Step: 13
Training loss: 1.0813950300216675
Validation loss: 1.8498338986468572

Epoch: 274| Step: 0
Training loss: 1.0892179012298584
Validation loss: 1.8433084116187146

Epoch: 6| Step: 1
Training loss: 0.5651627779006958
Validation loss: 1.8247818652019705

Epoch: 6| Step: 2
Training loss: 1.0827155113220215
Validation loss: 1.8121462009286369

Epoch: 6| Step: 3
Training loss: 0.7797837853431702
Validation loss: 1.8132631060897664

Epoch: 6| Step: 4
Training loss: 0.527825653553009
Validation loss: 1.8122276234370407

Epoch: 6| Step: 5
Training loss: 0.9055201411247253
Validation loss: 1.8182364676588325

Epoch: 6| Step: 6
Training loss: 0.9096946716308594
Validation loss: 1.7833503676999

Epoch: 6| Step: 7
Training loss: 0.8710924386978149
Validation loss: 1.7816608362300421

Epoch: 6| Step: 8
Training loss: 0.5368176698684692
Validation loss: 1.7406123543298373

Epoch: 6| Step: 9
Training loss: 0.6549725532531738
Validation loss: 1.7801308708806192

Epoch: 6| Step: 10
Training loss: 0.600730836391449
Validation loss: 1.7855854303606096

Epoch: 6| Step: 11
Training loss: 0.7731982469558716
Validation loss: 1.8074316875908965

Epoch: 6| Step: 12
Training loss: 0.8556011915206909
Validation loss: 1.819475277777641

Epoch: 6| Step: 13
Training loss: 0.6037571430206299
Validation loss: 1.8115892153914257

Epoch: 275| Step: 0
Training loss: 0.5004456639289856
Validation loss: 1.8027712555341824

Epoch: 6| Step: 1
Training loss: 0.30591094493865967
Validation loss: 1.7886272386838031

Epoch: 6| Step: 2
Training loss: 0.6708265542984009
Validation loss: 1.8215164330697828

Epoch: 6| Step: 3
Training loss: 0.7613649368286133
Validation loss: 1.8113458028403662

Epoch: 6| Step: 4
Training loss: 1.1208957433700562
Validation loss: 1.8099251037002893

Epoch: 6| Step: 5
Training loss: 1.18898344039917
Validation loss: 1.8441870699646652

Epoch: 6| Step: 6
Training loss: 0.6457411050796509
Validation loss: 1.8479468014932448

Epoch: 6| Step: 7
Training loss: 0.5253894329071045
Validation loss: 1.8214251623358777

Epoch: 6| Step: 8
Training loss: 0.8373891115188599
Validation loss: 1.821529475591516

Epoch: 6| Step: 9
Training loss: 0.6437014937400818
Validation loss: 1.8161036109411588

Epoch: 6| Step: 10
Training loss: 0.7551034092903137
Validation loss: 1.8205180155333651

Epoch: 6| Step: 11
Training loss: 0.5855467319488525
Validation loss: 1.7836792956116378

Epoch: 6| Step: 12
Training loss: 0.8158397674560547
Validation loss: 1.7997984527259745

Epoch: 6| Step: 13
Training loss: 0.7042858004570007
Validation loss: 1.8216009281014884

Epoch: 276| Step: 0
Training loss: 0.498244047164917
Validation loss: 1.8143718422100108

Epoch: 6| Step: 1
Training loss: 0.47225648164749146
Validation loss: 1.8074633549618464

Epoch: 6| Step: 2
Training loss: 0.6474987864494324
Validation loss: 1.7893551241966985

Epoch: 6| Step: 3
Training loss: 0.7395844459533691
Validation loss: 1.7832014355608212

Epoch: 6| Step: 4
Training loss: 0.708319365978241
Validation loss: 1.7721343873649515

Epoch: 6| Step: 5
Training loss: 0.8487997055053711
Validation loss: 1.7647640602563017

Epoch: 6| Step: 6
Training loss: 0.5886081457138062
Validation loss: 1.7474074671345372

Epoch: 6| Step: 7
Training loss: 1.187150239944458
Validation loss: 1.7683870048933132

Epoch: 6| Step: 8
Training loss: 0.5883939862251282
Validation loss: 1.8025122778390044

Epoch: 6| Step: 9
Training loss: 0.4902804493904114
Validation loss: 1.8260047256305654

Epoch: 6| Step: 10
Training loss: 0.8585242033004761
Validation loss: 1.8295880953470867

Epoch: 6| Step: 11
Training loss: 0.8310737013816833
Validation loss: 1.8905230209391604

Epoch: 6| Step: 12
Training loss: 0.9151866436004639
Validation loss: 1.9020006605373916

Epoch: 6| Step: 13
Training loss: 0.9042809009552002
Validation loss: 1.8948217848295807

Epoch: 277| Step: 0
Training loss: 0.9657626152038574
Validation loss: 1.9029500984376477

Epoch: 6| Step: 1
Training loss: 0.8088817000389099
Validation loss: 1.9111674460031653

Epoch: 6| Step: 2
Training loss: 0.313338041305542
Validation loss: 1.8888448694700837

Epoch: 6| Step: 3
Training loss: 0.7379169464111328
Validation loss: 1.9012293892522012

Epoch: 6| Step: 4
Training loss: 0.7296925783157349
Validation loss: 1.8668616356388215

Epoch: 6| Step: 5
Training loss: 0.7483365535736084
Validation loss: 1.817791481171885

Epoch: 6| Step: 6
Training loss: 0.6952166557312012
Validation loss: 1.8044650208565496

Epoch: 6| Step: 7
Training loss: 1.1899824142456055
Validation loss: 1.7751971752412858

Epoch: 6| Step: 8
Training loss: 0.7295342683792114
Validation loss: 1.7795666315222298

Epoch: 6| Step: 9
Training loss: 0.5548752546310425
Validation loss: 1.7767370746981712

Epoch: 6| Step: 10
Training loss: 1.3976982831954956
Validation loss: 1.7837444877111783

Epoch: 6| Step: 11
Training loss: 0.38105159997940063
Validation loss: 1.7383238115618307

Epoch: 6| Step: 12
Training loss: 0.6069295406341553
Validation loss: 1.744414044964698

Epoch: 6| Step: 13
Training loss: 0.13255254924297333
Validation loss: 1.7704495691484021

Epoch: 278| Step: 0
Training loss: 1.1294021606445312
Validation loss: 1.7963989985886442

Epoch: 6| Step: 1
Training loss: 0.5255678296089172
Validation loss: 1.8054003036150368

Epoch: 6| Step: 2
Training loss: 0.5527896285057068
Validation loss: 1.8038157365655387

Epoch: 6| Step: 3
Training loss: 0.9758546352386475
Validation loss: 1.8428371285879483

Epoch: 6| Step: 4
Training loss: 0.6653895378112793
Validation loss: 1.8184152931295416

Epoch: 6| Step: 5
Training loss: 0.4535369277000427
Validation loss: 1.7746758102088847

Epoch: 6| Step: 6
Training loss: 0.468366801738739
Validation loss: 1.797849537223898

Epoch: 6| Step: 7
Training loss: 0.7573165893554688
Validation loss: 1.7778663058434763

Epoch: 6| Step: 8
Training loss: 0.8387326002120972
Validation loss: 1.741128900999664

Epoch: 6| Step: 9
Training loss: 0.8893591165542603
Validation loss: 1.742581267510691

Epoch: 6| Step: 10
Training loss: 0.9246810078620911
Validation loss: 1.7390503908998223

Epoch: 6| Step: 11
Training loss: 0.512997031211853
Validation loss: 1.7276491426652478

Epoch: 6| Step: 12
Training loss: 0.8784828782081604
Validation loss: 1.7526876580330633

Epoch: 6| Step: 13
Training loss: 0.7449905276298523
Validation loss: 1.7460918657241329

Epoch: 279| Step: 0
Training loss: 0.5013446807861328
Validation loss: 1.7605848414923555

Epoch: 6| Step: 1
Training loss: 0.6455628275871277
Validation loss: 1.7735907800735966

Epoch: 6| Step: 2
Training loss: 0.4434639513492584
Validation loss: 1.7665089099637923

Epoch: 6| Step: 3
Training loss: 1.006725549697876
Validation loss: 1.7642742741492488

Epoch: 6| Step: 4
Training loss: 1.0174951553344727
Validation loss: 1.7736370589143486

Epoch: 6| Step: 5
Training loss: 1.0224649906158447
Validation loss: 1.8176821457442416

Epoch: 6| Step: 6
Training loss: 0.6921983361244202
Validation loss: 1.8261672194286058

Epoch: 6| Step: 7
Training loss: 0.6245384216308594
Validation loss: 1.795796489202848

Epoch: 6| Step: 8
Training loss: 0.8995361328125
Validation loss: 1.8263361313009774

Epoch: 6| Step: 9
Training loss: 1.3144290447235107
Validation loss: 1.828977600220711

Epoch: 6| Step: 10
Training loss: 0.8314917683601379
Validation loss: 1.8772900348068566

Epoch: 6| Step: 11
Training loss: 0.4158759117126465
Validation loss: 1.8641029275873655

Epoch: 6| Step: 12
Training loss: 0.4301217198371887
Validation loss: 1.878114515735257

Epoch: 6| Step: 13
Training loss: 0.26649725437164307
Validation loss: 1.84892741839091

Epoch: 280| Step: 0
Training loss: 1.105964183807373
Validation loss: 1.8601271465260496

Epoch: 6| Step: 1
Training loss: 0.7371414303779602
Validation loss: 1.8540315833143008

Epoch: 6| Step: 2
Training loss: 0.7855285406112671
Validation loss: 1.8540765059891569

Epoch: 6| Step: 3
Training loss: 0.8452184200286865
Validation loss: 1.852386850182728

Epoch: 6| Step: 4
Training loss: 0.8216227293014526
Validation loss: 1.8592436287992744

Epoch: 6| Step: 5
Training loss: 0.7266191244125366
Validation loss: 1.8781559646770518

Epoch: 6| Step: 6
Training loss: 0.6156437397003174
Validation loss: 1.8241563484232912

Epoch: 6| Step: 7
Training loss: 0.4982143044471741
Validation loss: 1.799730254757789

Epoch: 6| Step: 8
Training loss: 0.6283246874809265
Validation loss: 1.7883979966563563

Epoch: 6| Step: 9
Training loss: 0.49248266220092773
Validation loss: 1.8011376024574361

Epoch: 6| Step: 10
Training loss: 1.0180375576019287
Validation loss: 1.79084732455592

Epoch: 6| Step: 11
Training loss: 0.4300541877746582
Validation loss: 1.7978038710932578

Epoch: 6| Step: 12
Training loss: 0.3703184723854065
Validation loss: 1.764924087832051

Epoch: 6| Step: 13
Training loss: 0.7853106260299683
Validation loss: 1.7900299115847516

Epoch: 281| Step: 0
Training loss: 0.6652699112892151
Validation loss: 1.7505692987031833

Epoch: 6| Step: 1
Training loss: 0.9735629558563232
Validation loss: 1.7666190208927277

Epoch: 6| Step: 2
Training loss: 0.4546468257904053
Validation loss: 1.7783872888934227

Epoch: 6| Step: 3
Training loss: 0.6767446398735046
Validation loss: 1.8102178727426836

Epoch: 6| Step: 4
Training loss: 0.676058292388916
Validation loss: 1.8208606038042294

Epoch: 6| Step: 5
Training loss: 0.5077234506607056
Validation loss: 1.8468184971040296

Epoch: 6| Step: 6
Training loss: 0.9599283933639526
Validation loss: 1.8343120736460532

Epoch: 6| Step: 7
Training loss: 0.7519807815551758
Validation loss: 1.8662073214848836

Epoch: 6| Step: 8
Training loss: 0.9475769996643066
Validation loss: 1.8624672216753806

Epoch: 6| Step: 9
Training loss: 0.418199360370636
Validation loss: 1.864700840365502

Epoch: 6| Step: 10
Training loss: 0.7085307836532593
Validation loss: 1.8425036425231605

Epoch: 6| Step: 11
Training loss: 0.35419121384620667
Validation loss: 1.8349185861567014

Epoch: 6| Step: 12
Training loss: 0.7973478436470032
Validation loss: 1.8375637274916454

Epoch: 6| Step: 13
Training loss: 0.4947119951248169
Validation loss: 1.81965378022963

Epoch: 282| Step: 0
Training loss: 0.7496544718742371
Validation loss: 1.7872588993400655

Epoch: 6| Step: 1
Training loss: 0.5934693813323975
Validation loss: 1.8044272571481683

Epoch: 6| Step: 2
Training loss: 0.8481488227844238
Validation loss: 1.7664263402262042

Epoch: 6| Step: 3
Training loss: 0.8782182931900024
Validation loss: 1.7869117003615185

Epoch: 6| Step: 4
Training loss: 0.8314588665962219
Validation loss: 1.768609901910187

Epoch: 6| Step: 5
Training loss: 0.7940610647201538
Validation loss: 1.774715785057314

Epoch: 6| Step: 6
Training loss: 0.7043647170066833
Validation loss: 1.7992426938908075

Epoch: 6| Step: 7
Training loss: 0.6738765239715576
Validation loss: 1.8072329298142464

Epoch: 6| Step: 8
Training loss: 0.5759217739105225
Validation loss: 1.8295303506235923

Epoch: 6| Step: 9
Training loss: 0.5787964463233948
Validation loss: 1.8725084322755055

Epoch: 6| Step: 10
Training loss: 0.7128168344497681
Validation loss: 1.8494157932137931

Epoch: 6| Step: 11
Training loss: 0.5148453712463379
Validation loss: 1.8577967843701761

Epoch: 6| Step: 12
Training loss: 0.5938052535057068
Validation loss: 1.833806723676702

Epoch: 6| Step: 13
Training loss: 0.7946606278419495
Validation loss: 1.8198649678179013

Epoch: 283| Step: 0
Training loss: 0.5807274580001831
Validation loss: 1.8138492299664406

Epoch: 6| Step: 1
Training loss: 0.618532657623291
Validation loss: 1.833379876229071

Epoch: 6| Step: 2
Training loss: 0.5955822467803955
Validation loss: 1.8306647551956998

Epoch: 6| Step: 3
Training loss: 0.5922924280166626
Validation loss: 1.818255236071925

Epoch: 6| Step: 4
Training loss: 0.38666096329689026
Validation loss: 1.8252832146101101

Epoch: 6| Step: 5
Training loss: 0.44081103801727295
Validation loss: 1.8374079735048356

Epoch: 6| Step: 6
Training loss: 0.5848100185394287
Validation loss: 1.830404382880016

Epoch: 6| Step: 7
Training loss: 0.9240962862968445
Validation loss: 1.7991358682673464

Epoch: 6| Step: 8
Training loss: 0.6385123133659363
Validation loss: 1.816483239973745

Epoch: 6| Step: 9
Training loss: 0.8051304817199707
Validation loss: 1.8375308795641827

Epoch: 6| Step: 10
Training loss: 0.9017000794410706
Validation loss: 1.832851109966155

Epoch: 6| Step: 11
Training loss: 0.8676625490188599
Validation loss: 1.8087458213170369

Epoch: 6| Step: 12
Training loss: 0.5172234773635864
Validation loss: 1.7974795256891558

Epoch: 6| Step: 13
Training loss: 0.5845052599906921
Validation loss: 1.7615454402021182

Epoch: 284| Step: 0
Training loss: 0.6687091588973999
Validation loss: 1.7763411383475027

Epoch: 6| Step: 1
Training loss: 0.49709272384643555
Validation loss: 1.7755260826438986

Epoch: 6| Step: 2
Training loss: 0.34216052293777466
Validation loss: 1.7986214007100751

Epoch: 6| Step: 3
Training loss: 0.594406247138977
Validation loss: 1.8088945381103023

Epoch: 6| Step: 4
Training loss: 0.7908990383148193
Validation loss: 1.8431292221110354

Epoch: 6| Step: 5
Training loss: 0.5699800848960876
Validation loss: 1.8157817048411216

Epoch: 6| Step: 6
Training loss: 0.8472621440887451
Validation loss: 1.8284435349126016

Epoch: 6| Step: 7
Training loss: 1.1083370447158813
Validation loss: 1.7645495489079466

Epoch: 6| Step: 8
Training loss: 0.2939702272415161
Validation loss: 1.7808110854958976

Epoch: 6| Step: 9
Training loss: 0.7293701171875
Validation loss: 1.8046414159959363

Epoch: 6| Step: 10
Training loss: 0.710364580154419
Validation loss: 1.7880984211480746

Epoch: 6| Step: 11
Training loss: 0.7948213815689087
Validation loss: 1.7734894047501266

Epoch: 6| Step: 12
Training loss: 0.4694085419178009
Validation loss: 1.7355539824372979

Epoch: 6| Step: 13
Training loss: 0.5429458022117615
Validation loss: 1.7315306907059045

Epoch: 285| Step: 0
Training loss: 0.2304007112979889
Validation loss: 1.7537372125092374

Epoch: 6| Step: 1
Training loss: 0.4621315598487854
Validation loss: 1.7747209751477806

Epoch: 6| Step: 2
Training loss: 0.46895620226860046
Validation loss: 1.7727661709631644

Epoch: 6| Step: 3
Training loss: 0.7506672143936157
Validation loss: 1.7567357222239177

Epoch: 6| Step: 4
Training loss: 0.4325524568557739
Validation loss: 1.7669626653835337

Epoch: 6| Step: 5
Training loss: 0.42849212884902954
Validation loss: 1.773007785120318

Epoch: 6| Step: 6
Training loss: 0.6894556283950806
Validation loss: 1.7836546692796933

Epoch: 6| Step: 7
Training loss: 1.343595027923584
Validation loss: 1.7667419628430439

Epoch: 6| Step: 8
Training loss: 0.5994210839271545
Validation loss: 1.809814460815922

Epoch: 6| Step: 9
Training loss: 0.6066881418228149
Validation loss: 1.740658160178892

Epoch: 6| Step: 10
Training loss: 0.8024237155914307
Validation loss: 1.777289080363448

Epoch: 6| Step: 11
Training loss: 0.8376175165176392
Validation loss: 1.7786561942869616

Epoch: 6| Step: 12
Training loss: 0.7029303312301636
Validation loss: 1.748038900154893

Epoch: 6| Step: 13
Training loss: 0.43063420057296753
Validation loss: 1.7905273206772343

Epoch: 286| Step: 0
Training loss: 0.5690062642097473
Validation loss: 1.7914897575173327

Epoch: 6| Step: 1
Training loss: 0.7594079971313477
Validation loss: 1.7756512793161536

Epoch: 6| Step: 2
Training loss: 0.2018337845802307
Validation loss: 1.812220081206291

Epoch: 6| Step: 3
Training loss: 0.5576215982437134
Validation loss: 1.8026439579584266

Epoch: 6| Step: 4
Training loss: 1.028946876525879
Validation loss: 1.8132339177593109

Epoch: 6| Step: 5
Training loss: 0.5304690599441528
Validation loss: 1.8390849931265718

Epoch: 6| Step: 6
Training loss: 0.6010528206825256
Validation loss: 1.829449204988377

Epoch: 6| Step: 7
Training loss: 0.671906590461731
Validation loss: 1.8289299575231408

Epoch: 6| Step: 8
Training loss: 0.7734160423278809
Validation loss: 1.8438640243263655

Epoch: 6| Step: 9
Training loss: 0.8294097185134888
Validation loss: 1.8251737151094662

Epoch: 6| Step: 10
Training loss: 0.7004970908164978
Validation loss: 1.8341644784455657

Epoch: 6| Step: 11
Training loss: 0.5911275148391724
Validation loss: 1.8093035951737435

Epoch: 6| Step: 12
Training loss: 0.6014335751533508
Validation loss: 1.8321098435309626

Epoch: 6| Step: 13
Training loss: 0.6198915243148804
Validation loss: 1.783529443125571

Epoch: 287| Step: 0
Training loss: 0.6324007511138916
Validation loss: 1.7790288540624803

Epoch: 6| Step: 1
Training loss: 0.5586735606193542
Validation loss: 1.7786726669598651

Epoch: 6| Step: 2
Training loss: 0.6295214295387268
Validation loss: 1.7673591670169626

Epoch: 6| Step: 3
Training loss: 0.6286379098892212
Validation loss: 1.7849896671951457

Epoch: 6| Step: 4
Training loss: 0.46522819995880127
Validation loss: 1.7471680000264158

Epoch: 6| Step: 5
Training loss: 0.6794736385345459
Validation loss: 1.755545231603807

Epoch: 6| Step: 6
Training loss: 0.6505154967308044
Validation loss: 1.7790156461859261

Epoch: 6| Step: 7
Training loss: 0.7391870021820068
Validation loss: 1.7849469082329863

Epoch: 6| Step: 8
Training loss: 0.36016571521759033
Validation loss: 1.7856088838269633

Epoch: 6| Step: 9
Training loss: 0.49655210971832275
Validation loss: 1.8026711222946004

Epoch: 6| Step: 10
Training loss: 0.7571152448654175
Validation loss: 1.8244038499811643

Epoch: 6| Step: 11
Training loss: 0.6740444302558899
Validation loss: 1.8020911114190215

Epoch: 6| Step: 12
Training loss: 0.7884512543678284
Validation loss: 1.8570364290668118

Epoch: 6| Step: 13
Training loss: 0.770249605178833
Validation loss: 1.8626406628598449

Epoch: 288| Step: 0
Training loss: 0.5304569005966187
Validation loss: 1.868980106487069

Epoch: 6| Step: 1
Training loss: 0.5571199059486389
Validation loss: 1.8427621651721258

Epoch: 6| Step: 2
Training loss: 0.5169780850410461
Validation loss: 1.8297133432921542

Epoch: 6| Step: 3
Training loss: 0.5829052925109863
Validation loss: 1.8123792961079588

Epoch: 6| Step: 4
Training loss: 0.7521806359291077
Validation loss: 1.7625247996340516

Epoch: 6| Step: 5
Training loss: 0.3552209734916687
Validation loss: 1.7785198047596922

Epoch: 6| Step: 6
Training loss: 0.37204277515411377
Validation loss: 1.7566680831293906

Epoch: 6| Step: 7
Training loss: 1.1537578105926514
Validation loss: 1.7252324370927707

Epoch: 6| Step: 8
Training loss: 0.7069270014762878
Validation loss: 1.7334302894530758

Epoch: 6| Step: 9
Training loss: 0.8716301918029785
Validation loss: 1.7377986010684763

Epoch: 6| Step: 10
Training loss: 0.6968675255775452
Validation loss: 1.7354151048967916

Epoch: 6| Step: 11
Training loss: 0.5053391456604004
Validation loss: 1.739693541680613

Epoch: 6| Step: 12
Training loss: 0.37234729528427124
Validation loss: 1.7026240248833933

Epoch: 6| Step: 13
Training loss: 0.8712126016616821
Validation loss: 1.7335831221713816

Epoch: 289| Step: 0
Training loss: 0.7822966575622559
Validation loss: 1.7546294389232513

Epoch: 6| Step: 1
Training loss: 0.5788966417312622
Validation loss: 1.7758434408454484

Epoch: 6| Step: 2
Training loss: 0.4722006618976593
Validation loss: 1.7990779338344451

Epoch: 6| Step: 3
Training loss: 0.3748810589313507
Validation loss: 1.8002786456897695

Epoch: 6| Step: 4
Training loss: 0.7072445750236511
Validation loss: 1.8270312675865747

Epoch: 6| Step: 5
Training loss: 0.5565778613090515
Validation loss: 1.8164477463691466

Epoch: 6| Step: 6
Training loss: 0.9604192972183228
Validation loss: 1.7731253741889872

Epoch: 6| Step: 7
Training loss: 0.5862988233566284
Validation loss: 1.7741062538598174

Epoch: 6| Step: 8
Training loss: 0.7942157983779907
Validation loss: 1.7652403513590496

Epoch: 6| Step: 9
Training loss: 0.5892757177352905
Validation loss: 1.7503594185716362

Epoch: 6| Step: 10
Training loss: 0.21616101264953613
Validation loss: 1.7048056458914151

Epoch: 6| Step: 11
Training loss: 0.44579046964645386
Validation loss: 1.7434264549645044

Epoch: 6| Step: 12
Training loss: 0.9491018056869507
Validation loss: 1.7346805808364705

Epoch: 6| Step: 13
Training loss: 0.6157240867614746
Validation loss: 1.760147879200597

Epoch: 290| Step: 0
Training loss: 0.9060881733894348
Validation loss: 1.7833029262481197

Epoch: 6| Step: 1
Training loss: 0.6902695894241333
Validation loss: 1.8023201816825456

Epoch: 6| Step: 2
Training loss: 0.7460386753082275
Validation loss: 1.7751987582893782

Epoch: 6| Step: 3
Training loss: 0.8114315271377563
Validation loss: 1.724320734700849

Epoch: 6| Step: 4
Training loss: 0.45294955372810364
Validation loss: 1.7518651254715458

Epoch: 6| Step: 5
Training loss: 0.42368653416633606
Validation loss: 1.7704530762087913

Epoch: 6| Step: 6
Training loss: 0.858234167098999
Validation loss: 1.732994782027378

Epoch: 6| Step: 7
Training loss: 0.5427026152610779
Validation loss: 1.77033277480833

Epoch: 6| Step: 8
Training loss: 0.7073521018028259
Validation loss: 1.771133057532772

Epoch: 6| Step: 9
Training loss: 0.5397940278053284
Validation loss: 1.7827573719845022

Epoch: 6| Step: 10
Training loss: 0.30910724401474
Validation loss: 1.779604467012549

Epoch: 6| Step: 11
Training loss: 0.5413440465927124
Validation loss: 1.8007744601977769

Epoch: 6| Step: 12
Training loss: 0.6255364418029785
Validation loss: 1.8056045193825998

Epoch: 6| Step: 13
Training loss: 0.6851317286491394
Validation loss: 1.802160551471095

Epoch: 291| Step: 0
Training loss: 0.7117265462875366
Validation loss: 1.8424947518174366

Epoch: 6| Step: 1
Training loss: 0.9364563226699829
Validation loss: 1.8178820827955842

Epoch: 6| Step: 2
Training loss: 0.4624939560890198
Validation loss: 1.7950750192006428

Epoch: 6| Step: 3
Training loss: 0.404705286026001
Validation loss: 1.76613966367578

Epoch: 6| Step: 4
Training loss: 0.7924081087112427
Validation loss: 1.7671363789548156

Epoch: 6| Step: 5
Training loss: 0.5632212162017822
Validation loss: 1.7878482213584326

Epoch: 6| Step: 6
Training loss: 0.6620758771896362
Validation loss: 1.7598030477441766

Epoch: 6| Step: 7
Training loss: 0.4577217698097229
Validation loss: 1.7518341797654347

Epoch: 6| Step: 8
Training loss: 0.3556448519229889
Validation loss: 1.7221232780846216

Epoch: 6| Step: 9
Training loss: 0.6134164333343506
Validation loss: 1.7585031063325944

Epoch: 6| Step: 10
Training loss: 0.6336010694503784
Validation loss: 1.7706849639133742

Epoch: 6| Step: 11
Training loss: 0.5313988327980042
Validation loss: 1.7752592332901493

Epoch: 6| Step: 12
Training loss: 0.6062027215957642
Validation loss: 1.7680445307044572

Epoch: 6| Step: 13
Training loss: 0.8030011653900146
Validation loss: 1.7564969857533772

Epoch: 292| Step: 0
Training loss: 0.5270816087722778
Validation loss: 1.7870989153462071

Epoch: 6| Step: 1
Training loss: 0.5695463418960571
Validation loss: 1.7523590890310143

Epoch: 6| Step: 2
Training loss: 0.7009636163711548
Validation loss: 1.778694696323846

Epoch: 6| Step: 3
Training loss: 0.752738893032074
Validation loss: 1.7774104802839217

Epoch: 6| Step: 4
Training loss: 0.8856912851333618
Validation loss: 1.7753910928644159

Epoch: 6| Step: 5
Training loss: 0.916281521320343
Validation loss: 1.7818203933777348

Epoch: 6| Step: 6
Training loss: 0.6938443779945374
Validation loss: 1.805195975047286

Epoch: 6| Step: 7
Training loss: 0.3367201089859009
Validation loss: 1.804082041786563

Epoch: 6| Step: 8
Training loss: 0.6308989524841309
Validation loss: 1.8134352609675417

Epoch: 6| Step: 9
Training loss: 0.40868648886680603
Validation loss: 1.798594428646949

Epoch: 6| Step: 10
Training loss: 0.3504388630390167
Validation loss: 1.7972843595730361

Epoch: 6| Step: 11
Training loss: 0.4544607996940613
Validation loss: 1.7946671337209723

Epoch: 6| Step: 12
Training loss: 0.5324611663818359
Validation loss: 1.7864017332753828

Epoch: 6| Step: 13
Training loss: 0.5760785341262817
Validation loss: 1.76244576643872

Epoch: 293| Step: 0
Training loss: 0.571470320224762
Validation loss: 1.7841736347444597

Epoch: 6| Step: 1
Training loss: 0.5829429626464844
Validation loss: 1.764385422070821

Epoch: 6| Step: 2
Training loss: 0.7641956806182861
Validation loss: 1.7642957779668993

Epoch: 6| Step: 3
Training loss: 0.40198302268981934
Validation loss: 1.7735014269428868

Epoch: 6| Step: 4
Training loss: 0.5048719644546509
Validation loss: 1.7795082253794516

Epoch: 6| Step: 5
Training loss: 0.6472259759902954
Validation loss: 1.8017136896810224

Epoch: 6| Step: 6
Training loss: 0.49519503116607666
Validation loss: 1.7971727668598134

Epoch: 6| Step: 7
Training loss: 0.7154233455657959
Validation loss: 1.8143824274821947

Epoch: 6| Step: 8
Training loss: 1.143941879272461
Validation loss: 1.8245230092797229

Epoch: 6| Step: 9
Training loss: 0.7160542011260986
Validation loss: 1.8120932002221384

Epoch: 6| Step: 10
Training loss: 0.460973858833313
Validation loss: 1.8064022461573284

Epoch: 6| Step: 11
Training loss: 0.5293798446655273
Validation loss: 1.8057976640680784

Epoch: 6| Step: 12
Training loss: 0.3177807629108429
Validation loss: 1.7921964571040163

Epoch: 6| Step: 13
Training loss: 0.34310656785964966
Validation loss: 1.8040569533583939

Epoch: 294| Step: 0
Training loss: 0.42357075214385986
Validation loss: 1.7926264091204571

Epoch: 6| Step: 1
Training loss: 0.8818288445472717
Validation loss: 1.8063462600913098

Epoch: 6| Step: 2
Training loss: 0.9448893070220947
Validation loss: 1.7982576021584131

Epoch: 6| Step: 3
Training loss: 0.6249232292175293
Validation loss: 1.810372047526862

Epoch: 6| Step: 4
Training loss: 0.7647928595542908
Validation loss: 1.7842830688722673

Epoch: 6| Step: 5
Training loss: 0.6961303949356079
Validation loss: 1.7747308079914381

Epoch: 6| Step: 6
Training loss: 0.4215643107891083
Validation loss: 1.767128962342457

Epoch: 6| Step: 7
Training loss: 0.33376652002334595
Validation loss: 1.7901104624553392

Epoch: 6| Step: 8
Training loss: 0.525048017501831
Validation loss: 1.7917286965154833

Epoch: 6| Step: 9
Training loss: 0.42572450637817383
Validation loss: 1.7953073516968758

Epoch: 6| Step: 10
Training loss: 0.585727334022522
Validation loss: 1.7705773986795896

Epoch: 6| Step: 11
Training loss: 0.6499856114387512
Validation loss: 1.7688512981578868

Epoch: 6| Step: 12
Training loss: 0.3551461100578308
Validation loss: 1.7665296754529398

Epoch: 6| Step: 13
Training loss: 0.2981482446193695
Validation loss: 1.753779608716247

Epoch: 295| Step: 0
Training loss: 0.4707683324813843
Validation loss: 1.7628626182515135

Epoch: 6| Step: 1
Training loss: 0.47168880701065063
Validation loss: 1.7596157686684721

Epoch: 6| Step: 2
Training loss: 0.7397441864013672
Validation loss: 1.7413567419975036

Epoch: 6| Step: 3
Training loss: 0.5482921600341797
Validation loss: 1.727797476194238

Epoch: 6| Step: 4
Training loss: 0.4812662899494171
Validation loss: 1.7414328039333384

Epoch: 6| Step: 5
Training loss: 0.47787272930145264
Validation loss: 1.7181428350428098

Epoch: 6| Step: 6
Training loss: 0.6150168776512146
Validation loss: 1.746313794966667

Epoch: 6| Step: 7
Training loss: 0.46059486269950867
Validation loss: 1.7662159601847331

Epoch: 6| Step: 8
Training loss: 0.6075754165649414
Validation loss: 1.7643534624448387

Epoch: 6| Step: 9
Training loss: 0.9041313529014587
Validation loss: 1.8157656295325166

Epoch: 6| Step: 10
Training loss: 0.4966143071651459
Validation loss: 1.8094876761077552

Epoch: 6| Step: 11
Training loss: 0.6507371664047241
Validation loss: 1.785100313924974

Epoch: 6| Step: 12
Training loss: 0.6318932771682739
Validation loss: 1.7943482347714004

Epoch: 6| Step: 13
Training loss: 0.6993509531021118
Validation loss: 1.7990539907127299

Epoch: 296| Step: 0
Training loss: 0.6064728498458862
Validation loss: 1.7655380720733314

Epoch: 6| Step: 1
Training loss: 0.8235170245170593
Validation loss: 1.7570414017605525

Epoch: 6| Step: 2
Training loss: 0.803539514541626
Validation loss: 1.7493235411182526

Epoch: 6| Step: 3
Training loss: 0.6479008197784424
Validation loss: 1.7391276667194981

Epoch: 6| Step: 4
Training loss: 0.5913462042808533
Validation loss: 1.7531171652578539

Epoch: 6| Step: 5
Training loss: 0.513759195804596
Validation loss: 1.7498102559838244

Epoch: 6| Step: 6
Training loss: 0.38623741269111633
Validation loss: 1.763092969053535

Epoch: 6| Step: 7
Training loss: 0.2698366940021515
Validation loss: 1.7539286972374044

Epoch: 6| Step: 8
Training loss: 0.6572666168212891
Validation loss: 1.7330312459699568

Epoch: 6| Step: 9
Training loss: 0.48865699768066406
Validation loss: 1.7714778877073718

Epoch: 6| Step: 10
Training loss: 0.4834834933280945
Validation loss: 1.8172523821553876

Epoch: 6| Step: 11
Training loss: 0.7222003936767578
Validation loss: 1.7885473851234681

Epoch: 6| Step: 12
Training loss: 0.6795715093612671
Validation loss: 1.806354316332007

Epoch: 6| Step: 13
Training loss: 0.37797659635543823
Validation loss: 1.8097060790625952

Epoch: 297| Step: 0
Training loss: 0.7665120363235474
Validation loss: 1.7950399652604134

Epoch: 6| Step: 1
Training loss: 0.6173980236053467
Validation loss: 1.8200229726811892

Epoch: 6| Step: 2
Training loss: 0.43519601225852966
Validation loss: 1.796281099319458

Epoch: 6| Step: 3
Training loss: 0.4528636336326599
Validation loss: 1.756901635918566

Epoch: 6| Step: 4
Training loss: 0.6666887998580933
Validation loss: 1.736496312643892

Epoch: 6| Step: 5
Training loss: 0.6526598334312439
Validation loss: 1.7345971099791988

Epoch: 6| Step: 6
Training loss: 1.231431007385254
Validation loss: 1.7503014456841253

Epoch: 6| Step: 7
Training loss: 0.4467308521270752
Validation loss: 1.7221701042626494

Epoch: 6| Step: 8
Training loss: 0.48605501651763916
Validation loss: 1.7386112584862659

Epoch: 6| Step: 9
Training loss: 0.7259382009506226
Validation loss: 1.7536016651379165

Epoch: 6| Step: 10
Training loss: 0.48256614804267883
Validation loss: 1.7890009457065212

Epoch: 6| Step: 11
Training loss: 0.44854506850242615
Validation loss: 1.785908931045122

Epoch: 6| Step: 12
Training loss: 0.49274390935897827
Validation loss: 1.8053433766929052

Epoch: 6| Step: 13
Training loss: 0.3405291736125946
Validation loss: 1.8338363388533234

Epoch: 298| Step: 0
Training loss: 0.7421566247940063
Validation loss: 1.8074506085406068

Epoch: 6| Step: 1
Training loss: 0.622850775718689
Validation loss: 1.8204875825553812

Epoch: 6| Step: 2
Training loss: 0.6046569347381592
Validation loss: 1.834194726841424

Epoch: 6| Step: 3
Training loss: 0.48783624172210693
Validation loss: 1.8165573714881815

Epoch: 6| Step: 4
Training loss: 0.6836738586425781
Validation loss: 1.7893823468556969

Epoch: 6| Step: 5
Training loss: 0.6880932450294495
Validation loss: 1.7831063193659629

Epoch: 6| Step: 6
Training loss: 0.45324498414993286
Validation loss: 1.7849903491235548

Epoch: 6| Step: 7
Training loss: 0.8378483057022095
Validation loss: 1.767200917325994

Epoch: 6| Step: 8
Training loss: 0.5235416889190674
Validation loss: 1.7902076398172686

Epoch: 6| Step: 9
Training loss: 0.40771764516830444
Validation loss: 1.763901308018674

Epoch: 6| Step: 10
Training loss: 0.45019835233688354
Validation loss: 1.7815804096960253

Epoch: 6| Step: 11
Training loss: 0.7391738891601562
Validation loss: 1.7722356229700067

Epoch: 6| Step: 12
Training loss: 0.5276256799697876
Validation loss: 1.8137272032358314

Epoch: 6| Step: 13
Training loss: 0.5363739728927612
Validation loss: 1.8017965747464089

Epoch: 299| Step: 0
Training loss: 0.39156588912010193
Validation loss: 1.795877141337241

Epoch: 6| Step: 1
Training loss: 0.6882899403572083
Validation loss: 1.7758091957338396

Epoch: 6| Step: 2
Training loss: 0.28113412857055664
Validation loss: 1.7965654621842087

Epoch: 6| Step: 3
Training loss: 1.0142126083374023
Validation loss: 1.8156301603522351

Epoch: 6| Step: 4
Training loss: 0.37580370903015137
Validation loss: 1.8362179404945784

Epoch: 6| Step: 5
Training loss: 0.5259193181991577
Validation loss: 1.8159902557249992

Epoch: 6| Step: 6
Training loss: 0.9299625754356384
Validation loss: 1.8233098073672223

Epoch: 6| Step: 7
Training loss: 0.41400742530822754
Validation loss: 1.8302160437389086

Epoch: 6| Step: 8
Training loss: 0.5353390574455261
Validation loss: 1.8126406515798261

Epoch: 6| Step: 9
Training loss: 0.37256336212158203
Validation loss: 1.8005255089011243

Epoch: 6| Step: 10
Training loss: 0.5487575531005859
Validation loss: 1.750519940930028

Epoch: 6| Step: 11
Training loss: 0.528711199760437
Validation loss: 1.7486889195698563

Epoch: 6| Step: 12
Training loss: 0.49290287494659424
Validation loss: 1.7783830652954757

Epoch: 6| Step: 13
Training loss: 0.4596027731895447
Validation loss: 1.7503434996451102

Epoch: 300| Step: 0
Training loss: 0.7941181659698486
Validation loss: 1.736763370934353

Epoch: 6| Step: 1
Training loss: 0.9253362417221069
Validation loss: 1.7468448300515451

Epoch: 6| Step: 2
Training loss: 0.39328432083129883
Validation loss: 1.7311384088249617

Epoch: 6| Step: 3
Training loss: 0.4456624388694763
Validation loss: 1.7133681261411278

Epoch: 6| Step: 4
Training loss: 0.6172391176223755
Validation loss: 1.738686942285107

Epoch: 6| Step: 5
Training loss: 0.6100561618804932
Validation loss: 1.693787436331472

Epoch: 6| Step: 6
Training loss: 0.3808971345424652
Validation loss: 1.7191329207471622

Epoch: 6| Step: 7
Training loss: 0.33187830448150635
Validation loss: 1.7609064527737197

Epoch: 6| Step: 8
Training loss: 0.3426414132118225
Validation loss: 1.7918864116873792

Epoch: 6| Step: 9
Training loss: 0.40910324454307556
Validation loss: 1.8207451861391786

Epoch: 6| Step: 10
Training loss: 0.5667502284049988
Validation loss: 1.8382579229211296

Epoch: 6| Step: 11
Training loss: 0.5568766593933105
Validation loss: 1.8763004605488112

Epoch: 6| Step: 12
Training loss: 0.7267682552337646
Validation loss: 1.8807514982838784

Epoch: 6| Step: 13
Training loss: 0.5737594366073608
Validation loss: 1.8736579905274093

Epoch: 301| Step: 0
Training loss: 0.874485969543457
Validation loss: 1.8680431509530673

Epoch: 6| Step: 1
Training loss: 0.5045555830001831
Validation loss: 1.880428998701034

Epoch: 6| Step: 2
Training loss: 0.7042639255523682
Validation loss: 1.8377850799150364

Epoch: 6| Step: 3
Training loss: 0.31294968724250793
Validation loss: 1.8021175707540205

Epoch: 6| Step: 4
Training loss: 0.39413881301879883
Validation loss: 1.8041680705162786

Epoch: 6| Step: 5
Training loss: 0.5283774137496948
Validation loss: 1.7741314108653734

Epoch: 6| Step: 6
Training loss: 0.3782810866832733
Validation loss: 1.7485233468394126

Epoch: 6| Step: 7
Training loss: 0.7868525385856628
Validation loss: 1.75993880661585

Epoch: 6| Step: 8
Training loss: 0.6040141582489014
Validation loss: 1.7827260878778273

Epoch: 6| Step: 9
Training loss: 0.6108102798461914
Validation loss: 1.758015073755736

Epoch: 6| Step: 10
Training loss: 0.4548550248146057
Validation loss: 1.7578055627884404

Epoch: 6| Step: 11
Training loss: 0.4407189190387726
Validation loss: 1.773170191754577

Epoch: 6| Step: 12
Training loss: 0.7243106365203857
Validation loss: 1.7729227158331102

Epoch: 6| Step: 13
Training loss: 0.25706446170806885
Validation loss: 1.795463260783944

Epoch: 302| Step: 0
Training loss: 0.807884156703949
Validation loss: 1.8153886948862383

Epoch: 6| Step: 1
Training loss: 0.5713328123092651
Validation loss: 1.8233439294240807

Epoch: 6| Step: 2
Training loss: 0.7852363586425781
Validation loss: 1.8244865581553469

Epoch: 6| Step: 3
Training loss: 0.33537811040878296
Validation loss: 1.8209246012472338

Epoch: 6| Step: 4
Training loss: 0.6874347925186157
Validation loss: 1.7911322527034308

Epoch: 6| Step: 5
Training loss: 0.38267505168914795
Validation loss: 1.7858004288006855

Epoch: 6| Step: 6
Training loss: 0.4135839343070984
Validation loss: 1.7818550179081578

Epoch: 6| Step: 7
Training loss: 0.5403716564178467
Validation loss: 1.7895476920630342

Epoch: 6| Step: 8
Training loss: 0.8205145597457886
Validation loss: 1.766451963814356

Epoch: 6| Step: 9
Training loss: 0.5080693960189819
Validation loss: 1.7454459897933468

Epoch: 6| Step: 10
Training loss: 0.19003692269325256
Validation loss: 1.7625051890650103

Epoch: 6| Step: 11
Training loss: 0.3630216419696808
Validation loss: 1.7635750911569084

Epoch: 6| Step: 12
Training loss: 0.4590336084365845
Validation loss: 1.785343248357055

Epoch: 6| Step: 13
Training loss: 0.5049387216567993
Validation loss: 1.7796853626928022

Epoch: 303| Step: 0
Training loss: 0.42497962713241577
Validation loss: 1.776324801547553

Epoch: 6| Step: 1
Training loss: 0.488162100315094
Validation loss: 1.7569793514026109

Epoch: 6| Step: 2
Training loss: 0.5196972489356995
Validation loss: 1.7965719930587276

Epoch: 6| Step: 3
Training loss: 0.5187898874282837
Validation loss: 1.8176413082307386

Epoch: 6| Step: 4
Training loss: 0.20554842054843903
Validation loss: 1.81773115229863

Epoch: 6| Step: 5
Training loss: 0.42526179552078247
Validation loss: 1.801327710510582

Epoch: 6| Step: 6
Training loss: 0.6939770579338074
Validation loss: 1.808474063873291

Epoch: 6| Step: 7
Training loss: 0.6555823087692261
Validation loss: 1.7972938142797

Epoch: 6| Step: 8
Training loss: 0.588273286819458
Validation loss: 1.7815569139296008

Epoch: 6| Step: 9
Training loss: 0.5499768257141113
Validation loss: 1.796705634363236

Epoch: 6| Step: 10
Training loss: 0.770096480846405
Validation loss: 1.8084457946080033

Epoch: 6| Step: 11
Training loss: 0.3460083603858948
Validation loss: 1.8011983594586771

Epoch: 6| Step: 12
Training loss: 0.5560995936393738
Validation loss: 1.796859582265218

Epoch: 6| Step: 13
Training loss: 0.5455580949783325
Validation loss: 1.8193941539333713

Epoch: 304| Step: 0
Training loss: 1.001055359840393
Validation loss: 1.8170686178309943

Epoch: 6| Step: 1
Training loss: 0.47997361421585083
Validation loss: 1.833554498610958

Epoch: 6| Step: 2
Training loss: 0.4211416244506836
Validation loss: 1.811101754506429

Epoch: 6| Step: 3
Training loss: 0.5972462296485901
Validation loss: 1.8005828242148123

Epoch: 6| Step: 4
Training loss: 0.6809589266777039
Validation loss: 1.7921240188742196

Epoch: 6| Step: 5
Training loss: 0.3446550667285919
Validation loss: 1.7946146829153902

Epoch: 6| Step: 6
Training loss: 0.5680065155029297
Validation loss: 1.8008679830899803

Epoch: 6| Step: 7
Training loss: 0.7125325202941895
Validation loss: 1.827767918186803

Epoch: 6| Step: 8
Training loss: 0.633062481880188
Validation loss: 1.8410086272865214

Epoch: 6| Step: 9
Training loss: 0.6541168689727783
Validation loss: 1.8252674456565612

Epoch: 6| Step: 10
Training loss: 0.4297828674316406
Validation loss: 1.7960257389212166

Epoch: 6| Step: 11
Training loss: 0.6082013845443726
Validation loss: 1.8271424001263035

Epoch: 6| Step: 12
Training loss: 0.5929425358772278
Validation loss: 1.9028002241606354

Epoch: 6| Step: 13
Training loss: 0.7206892967224121
Validation loss: 1.8795742578403924

Epoch: 305| Step: 0
Training loss: 0.5353661775588989
Validation loss: 1.911860982577006

Epoch: 6| Step: 1
Training loss: 1.0723202228546143
Validation loss: 1.8987837799133793

Epoch: 6| Step: 2
Training loss: 0.5169457197189331
Validation loss: 1.870812551949614

Epoch: 6| Step: 3
Training loss: 0.5249111652374268
Validation loss: 1.8347776089945147

Epoch: 6| Step: 4
Training loss: 0.6646248698234558
Validation loss: 1.827414584416215

Epoch: 6| Step: 5
Training loss: 0.617746114730835
Validation loss: 1.79389367693214

Epoch: 6| Step: 6
Training loss: 0.5421892404556274
Validation loss: 1.770815618576542

Epoch: 6| Step: 7
Training loss: 0.56353360414505
Validation loss: 1.7737310099345382

Epoch: 6| Step: 8
Training loss: 0.7917659878730774
Validation loss: 1.7934220375553254

Epoch: 6| Step: 9
Training loss: 0.6289643049240112
Validation loss: 1.836911903914585

Epoch: 6| Step: 10
Training loss: 1.0805529356002808
Validation loss: 1.8208455013972458

Epoch: 6| Step: 11
Training loss: 0.658728837966919
Validation loss: 1.809835405759914

Epoch: 6| Step: 12
Training loss: 0.49627795815467834
Validation loss: 1.8351120243790329

Epoch: 6| Step: 13
Training loss: 0.42840874195098877
Validation loss: 1.8866243106062695

Epoch: 306| Step: 0
Training loss: 0.6399951577186584
Validation loss: 1.8727506399154663

Epoch: 6| Step: 1
Training loss: 0.40693625807762146
Validation loss: 1.9167073926618021

Epoch: 6| Step: 2
Training loss: 0.6427456140518188
Validation loss: 1.899869372767787

Epoch: 6| Step: 3
Training loss: 0.9147807359695435
Validation loss: 1.925518863944597

Epoch: 6| Step: 4
Training loss: 0.6503233909606934
Validation loss: 1.8815755549297537

Epoch: 6| Step: 5
Training loss: 0.49045172333717346
Validation loss: 1.8611338356489777

Epoch: 6| Step: 6
Training loss: 0.6013827323913574
Validation loss: 1.8300824357617287

Epoch: 6| Step: 7
Training loss: 0.5785214900970459
Validation loss: 1.8126363497908398

Epoch: 6| Step: 8
Training loss: 0.8122812509536743
Validation loss: 1.7680871307208974

Epoch: 6| Step: 9
Training loss: 0.6607787609100342
Validation loss: 1.7533965854234592

Epoch: 6| Step: 10
Training loss: 0.4583260118961334
Validation loss: 1.724580777588711

Epoch: 6| Step: 11
Training loss: 0.5770367980003357
Validation loss: 1.730919539287526

Epoch: 6| Step: 12
Training loss: 0.4009220600128174
Validation loss: 1.7657843494928012

Epoch: 6| Step: 13
Training loss: 0.5174987316131592
Validation loss: 1.7511428427952591

Epoch: 307| Step: 0
Training loss: 0.4044504761695862
Validation loss: 1.7687929958425543

Epoch: 6| Step: 1
Training loss: 0.4321596622467041
Validation loss: 1.7704795791256813

Epoch: 6| Step: 2
Training loss: 0.5467817187309265
Validation loss: 1.7467593018726637

Epoch: 6| Step: 3
Training loss: 0.49290141463279724
Validation loss: 1.7678903584839196

Epoch: 6| Step: 4
Training loss: 0.6464328765869141
Validation loss: 1.7620907829653831

Epoch: 6| Step: 5
Training loss: 0.647516131401062
Validation loss: 1.8223644328373734

Epoch: 6| Step: 6
Training loss: 0.3950667679309845
Validation loss: 1.8329993960677937

Epoch: 6| Step: 7
Training loss: 0.2758716642856598
Validation loss: 1.834052275585872

Epoch: 6| Step: 8
Training loss: 0.43569567799568176
Validation loss: 1.829912926561089

Epoch: 6| Step: 9
Training loss: 0.6878212690353394
Validation loss: 1.8413035613234325

Epoch: 6| Step: 10
Training loss: 0.3647184371948242
Validation loss: 1.820215529011142

Epoch: 6| Step: 11
Training loss: 0.8450319170951843
Validation loss: 1.7646085075152818

Epoch: 6| Step: 12
Training loss: 0.7769293785095215
Validation loss: 1.8101460446593582

Epoch: 6| Step: 13
Training loss: 0.6303540468215942
Validation loss: 1.7621997633287985

Epoch: 308| Step: 0
Training loss: 0.5291751027107239
Validation loss: 1.7754172599443825

Epoch: 6| Step: 1
Training loss: 0.553742527961731
Validation loss: 1.7693412150106123

Epoch: 6| Step: 2
Training loss: 0.3543374538421631
Validation loss: 1.761527112735215

Epoch: 6| Step: 3
Training loss: 0.799270749092102
Validation loss: 1.7785176692470428

Epoch: 6| Step: 4
Training loss: 0.4299977123737335
Validation loss: 1.7700491823175901

Epoch: 6| Step: 5
Training loss: 0.3298864960670471
Validation loss: 1.8022037667612876

Epoch: 6| Step: 6
Training loss: 0.7578266859054565
Validation loss: 1.8253009165486982

Epoch: 6| Step: 7
Training loss: 0.47923219203948975
Validation loss: 1.812943135538409

Epoch: 6| Step: 8
Training loss: 0.6144121885299683
Validation loss: 1.8331202665964763

Epoch: 6| Step: 9
Training loss: 0.5113929510116577
Validation loss: 1.7741735468628586

Epoch: 6| Step: 10
Training loss: 0.48515748977661133
Validation loss: 1.8103219668070476

Epoch: 6| Step: 11
Training loss: 0.3990152180194855
Validation loss: 1.814079479504657

Epoch: 6| Step: 12
Training loss: 0.7830948829650879
Validation loss: 1.7981737326550227

Epoch: 6| Step: 13
Training loss: 0.7493832111358643
Validation loss: 1.7923948559709775

Epoch: 309| Step: 0
Training loss: 0.4767531752586365
Validation loss: 1.804826626213648

Epoch: 6| Step: 1
Training loss: 0.645230233669281
Validation loss: 1.8038841498795377

Epoch: 6| Step: 2
Training loss: 0.43556126952171326
Validation loss: 1.8175048879397813

Epoch: 6| Step: 3
Training loss: 0.6123025417327881
Validation loss: 1.8065621602919795

Epoch: 6| Step: 4
Training loss: 0.19989699125289917
Validation loss: 1.8183253003704933

Epoch: 6| Step: 5
Training loss: 0.5512386560440063
Validation loss: 1.8292533569438483

Epoch: 6| Step: 6
Training loss: 0.5962824821472168
Validation loss: 1.8420607325851277

Epoch: 6| Step: 7
Training loss: 0.715407133102417
Validation loss: 1.840277438522667

Epoch: 6| Step: 8
Training loss: 0.8108832836151123
Validation loss: 1.818830741349087

Epoch: 6| Step: 9
Training loss: 0.5712573528289795
Validation loss: 1.779466398300663

Epoch: 6| Step: 10
Training loss: 0.5097439289093018
Validation loss: 1.7837097875533565

Epoch: 6| Step: 11
Training loss: 0.19143807888031006
Validation loss: 1.794746671953509

Epoch: 6| Step: 12
Training loss: 0.4638381004333496
Validation loss: 1.7889310698355398

Epoch: 6| Step: 13
Training loss: 0.26666781306266785
Validation loss: 1.7918159513063328

Epoch: 310| Step: 0
Training loss: 0.5139625072479248
Validation loss: 1.8164682311396445

Epoch: 6| Step: 1
Training loss: 0.45345836877822876
Validation loss: 1.8002570316355715

Epoch: 6| Step: 2
Training loss: 0.4970076382160187
Validation loss: 1.8202112233766945

Epoch: 6| Step: 3
Training loss: 0.5133135318756104
Validation loss: 1.8499060523125432

Epoch: 6| Step: 4
Training loss: 0.41335344314575195
Validation loss: 1.8641686900969474

Epoch: 6| Step: 5
Training loss: 0.2080148309469223
Validation loss: 1.8669580208357943

Epoch: 6| Step: 6
Training loss: 0.3152283728122711
Validation loss: 1.8820376511543029

Epoch: 6| Step: 7
Training loss: 0.4340815544128418
Validation loss: 1.8439435279497536

Epoch: 6| Step: 8
Training loss: 0.4196825623512268
Validation loss: 1.8331570548395957

Epoch: 6| Step: 9
Training loss: 0.7128065824508667
Validation loss: 1.8268151270445956

Epoch: 6| Step: 10
Training loss: 0.514522910118103
Validation loss: 1.8187774894058064

Epoch: 6| Step: 11
Training loss: 0.9938980937004089
Validation loss: 1.822717733280633

Epoch: 6| Step: 12
Training loss: 0.695034384727478
Validation loss: 1.8278400192978561

Epoch: 6| Step: 13
Training loss: 0.8899145126342773
Validation loss: 1.8080032563978625

Epoch: 311| Step: 0
Training loss: 0.3830356299877167
Validation loss: 1.7888981655079832

Epoch: 6| Step: 1
Training loss: 0.4524584412574768
Validation loss: 1.8134610037649832

Epoch: 6| Step: 2
Training loss: 0.5492138862609863
Validation loss: 1.8238261899640482

Epoch: 6| Step: 3
Training loss: 0.40830284357070923
Validation loss: 1.837075041186425

Epoch: 6| Step: 4
Training loss: 0.5915939807891846
Validation loss: 1.8361864948785434

Epoch: 6| Step: 5
Training loss: 0.49652448296546936
Validation loss: 1.8747337697654642

Epoch: 6| Step: 6
Training loss: 0.5607997179031372
Validation loss: 1.8432889997318227

Epoch: 6| Step: 7
Training loss: 0.5067660808563232
Validation loss: 1.8551910487554406

Epoch: 6| Step: 8
Training loss: 0.46426352858543396
Validation loss: 1.8690359887256418

Epoch: 6| Step: 9
Training loss: 0.7307415008544922
Validation loss: 1.8890261829540294

Epoch: 6| Step: 10
Training loss: 0.4256894886493683
Validation loss: 1.844248201257439

Epoch: 6| Step: 11
Training loss: 0.48912709951400757
Validation loss: 1.8483939017018964

Epoch: 6| Step: 12
Training loss: 0.5987217426300049
Validation loss: 1.8150010493493849

Epoch: 6| Step: 13
Training loss: 0.2956724464893341
Validation loss: 1.835430699010049

Epoch: 312| Step: 0
Training loss: 0.22998744249343872
Validation loss: 1.796304270785342

Epoch: 6| Step: 1
Training loss: 0.5968161821365356
Validation loss: 1.807731964254892

Epoch: 6| Step: 2
Training loss: 0.5178692936897278
Validation loss: 1.8207843322907724

Epoch: 6| Step: 3
Training loss: 0.46426889300346375
Validation loss: 1.8143107724446121

Epoch: 6| Step: 4
Training loss: 0.48694828152656555
Validation loss: 1.8058183962298977

Epoch: 6| Step: 5
Training loss: 0.5075411796569824
Validation loss: 1.8191538831239105

Epoch: 6| Step: 6
Training loss: 0.7819180488586426
Validation loss: 1.8074700165820379

Epoch: 6| Step: 7
Training loss: 0.4708194136619568
Validation loss: 1.8190712723680722

Epoch: 6| Step: 8
Training loss: 0.3529505133628845
Validation loss: 1.8357544009403517

Epoch: 6| Step: 9
Training loss: 0.36305922269821167
Validation loss: 1.8623504331035

Epoch: 6| Step: 10
Training loss: 0.43549466133117676
Validation loss: 1.859766593543432

Epoch: 6| Step: 11
Training loss: 0.48918479681015015
Validation loss: 1.8600775528979558

Epoch: 6| Step: 12
Training loss: 0.4562702775001526
Validation loss: 1.8678933394852506

Epoch: 6| Step: 13
Training loss: 0.6871492862701416
Validation loss: 1.8718294405168103

Epoch: 313| Step: 0
Training loss: 0.7701634168624878
Validation loss: 1.8304094755521385

Epoch: 6| Step: 1
Training loss: 0.6267732381820679
Validation loss: 1.8227306937658658

Epoch: 6| Step: 2
Training loss: 0.6739327311515808
Validation loss: 1.8301717863287976

Epoch: 6| Step: 3
Training loss: 0.5541569590568542
Validation loss: 1.7867214910445675

Epoch: 6| Step: 4
Training loss: 0.30126696825027466
Validation loss: 1.7858195535598262

Epoch: 6| Step: 5
Training loss: 0.34163227677345276
Validation loss: 1.772688236287845

Epoch: 6| Step: 6
Training loss: 0.2487635314464569
Validation loss: 1.7868868253564323

Epoch: 6| Step: 7
Training loss: 0.3208802342414856
Validation loss: 1.793351464374091

Epoch: 6| Step: 8
Training loss: 0.4723708927631378
Validation loss: 1.797486082200081

Epoch: 6| Step: 9
Training loss: 0.6629091501235962
Validation loss: 1.8210524141147573

Epoch: 6| Step: 10
Training loss: 0.4724889397621155
Validation loss: 1.8421016226532638

Epoch: 6| Step: 11
Training loss: 0.4341486096382141
Validation loss: 1.833463704714211

Epoch: 6| Step: 12
Training loss: 0.5006547570228577
Validation loss: 1.8629218891102781

Epoch: 6| Step: 13
Training loss: 0.4009822607040405
Validation loss: 1.8254718472880702

Epoch: 314| Step: 0
Training loss: 0.6577771902084351
Validation loss: 1.829455311580371

Epoch: 6| Step: 1
Training loss: 0.3456842303276062
Validation loss: 1.8016717523656867

Epoch: 6| Step: 2
Training loss: 0.3118980824947357
Validation loss: 1.8184909166828278

Epoch: 6| Step: 3
Training loss: 0.6350131034851074
Validation loss: 1.8417082204613635

Epoch: 6| Step: 4
Training loss: 0.4083916246891022
Validation loss: 1.8442018596074914

Epoch: 6| Step: 5
Training loss: 0.640205979347229
Validation loss: 1.8605234546046103

Epoch: 6| Step: 6
Training loss: 0.47932684421539307
Validation loss: 1.8232582384540188

Epoch: 6| Step: 7
Training loss: 0.6517596244812012
Validation loss: 1.8123254699091758

Epoch: 6| Step: 8
Training loss: 0.39468327164649963
Validation loss: 1.7924698296413626

Epoch: 6| Step: 9
Training loss: 0.32795000076293945
Validation loss: 1.82005778948466

Epoch: 6| Step: 10
Training loss: 0.5697027444839478
Validation loss: 1.8151968756029684

Epoch: 6| Step: 11
Training loss: 0.45992493629455566
Validation loss: 1.7884349746088828

Epoch: 6| Step: 12
Training loss: 0.4348171651363373
Validation loss: 1.8081372835302865

Epoch: 6| Step: 13
Training loss: 0.6216007471084595
Validation loss: 1.7795434741563694

Epoch: 315| Step: 0
Training loss: 0.3367874026298523
Validation loss: 1.8040215610176005

Epoch: 6| Step: 1
Training loss: 0.4663156270980835
Validation loss: 1.8149261628427813

Epoch: 6| Step: 2
Training loss: 0.5018346309661865
Validation loss: 1.798639899940901

Epoch: 6| Step: 3
Training loss: 0.5860515832901001
Validation loss: 1.8104828378205657

Epoch: 6| Step: 4
Training loss: 0.41323673725128174
Validation loss: 1.7960044760857858

Epoch: 6| Step: 5
Training loss: 0.3649817705154419
Validation loss: 1.7947660325675883

Epoch: 6| Step: 6
Training loss: 0.27775806188583374
Validation loss: 1.8189572954690585

Epoch: 6| Step: 7
Training loss: 0.5622868537902832
Validation loss: 1.8265660680750364

Epoch: 6| Step: 8
Training loss: 0.18552836775779724
Validation loss: 1.823788058373236

Epoch: 6| Step: 9
Training loss: 0.5852593779563904
Validation loss: 1.7996876060321767

Epoch: 6| Step: 10
Training loss: 0.47458845376968384
Validation loss: 1.8101361438792238

Epoch: 6| Step: 11
Training loss: 0.43615204095840454
Validation loss: 1.8375211274752052

Epoch: 6| Step: 12
Training loss: 1.010957956314087
Validation loss: 1.8264321563064412

Epoch: 6| Step: 13
Training loss: 0.5234896540641785
Validation loss: 1.8438760849737352

Epoch: 316| Step: 0
Training loss: 0.3302978277206421
Validation loss: 1.8675439639758038

Epoch: 6| Step: 1
Training loss: 0.37591010332107544
Validation loss: 1.8904000918070476

Epoch: 6| Step: 2
Training loss: 0.7306950092315674
Validation loss: 1.8920978974270564

Epoch: 6| Step: 3
Training loss: 0.5032822489738464
Validation loss: 1.8758268176868398

Epoch: 6| Step: 4
Training loss: 0.2796902060508728
Validation loss: 1.8780441963544456

Epoch: 6| Step: 5
Training loss: 0.6240845918655396
Validation loss: 1.812667505715483

Epoch: 6| Step: 6
Training loss: 0.41605493426322937
Validation loss: 1.8010719258298156

Epoch: 6| Step: 7
Training loss: 0.2662616968154907
Validation loss: 1.784357904106058

Epoch: 6| Step: 8
Training loss: 0.47237837314605713
Validation loss: 1.802540038221626

Epoch: 6| Step: 9
Training loss: 0.4501127004623413
Validation loss: 1.7731586681899203

Epoch: 6| Step: 10
Training loss: 0.6682384014129639
Validation loss: 1.799480999669721

Epoch: 6| Step: 11
Training loss: 0.761798620223999
Validation loss: 1.766726622017481

Epoch: 6| Step: 12
Training loss: 0.24051718413829803
Validation loss: 1.8073130294840822

Epoch: 6| Step: 13
Training loss: 0.31194373965263367
Validation loss: 1.7882498066912416

Epoch: 317| Step: 0
Training loss: 0.4952932298183441
Validation loss: 1.7807953716606222

Epoch: 6| Step: 1
Training loss: 0.7636657953262329
Validation loss: 1.7757468018480527

Epoch: 6| Step: 2
Training loss: 0.4319249093532562
Validation loss: 1.8357442784053024

Epoch: 6| Step: 3
Training loss: 0.5112383365631104
Validation loss: 1.8209287312722975

Epoch: 6| Step: 4
Training loss: 0.2192968875169754
Validation loss: 1.7894430852705432

Epoch: 6| Step: 5
Training loss: 0.34465306997299194
Validation loss: 1.7865431936838294

Epoch: 6| Step: 6
Training loss: 0.6236032247543335
Validation loss: 1.7799462349184099

Epoch: 6| Step: 7
Training loss: 0.31020092964172363
Validation loss: 1.8078266266853578

Epoch: 6| Step: 8
Training loss: 0.3412376046180725
Validation loss: 1.76282286900346

Epoch: 6| Step: 9
Training loss: 0.8498284816741943
Validation loss: 1.7864947613849436

Epoch: 6| Step: 10
Training loss: 0.4405945837497711
Validation loss: 1.8081212800036195

Epoch: 6| Step: 11
Training loss: 0.1358511745929718
Validation loss: 1.7983175054673226

Epoch: 6| Step: 12
Training loss: 0.39187172055244446
Validation loss: 1.7810902864702287

Epoch: 6| Step: 13
Training loss: 0.7060143947601318
Validation loss: 1.791231752723776

Epoch: 318| Step: 0
Training loss: 0.5665243864059448
Validation loss: 1.7738232715155489

Epoch: 6| Step: 1
Training loss: 0.5372930765151978
Validation loss: 1.806679860238106

Epoch: 6| Step: 2
Training loss: 0.1499137580394745
Validation loss: 1.7787961498383553

Epoch: 6| Step: 3
Training loss: 0.32552289962768555
Validation loss: 1.8026506618786884

Epoch: 6| Step: 4
Training loss: 0.3588140308856964
Validation loss: 1.7940575307415378

Epoch: 6| Step: 5
Training loss: 0.8171223998069763
Validation loss: 1.763977599400346

Epoch: 6| Step: 6
Training loss: 0.34322550892829895
Validation loss: 1.7767292363669283

Epoch: 6| Step: 7
Training loss: 0.5313042998313904
Validation loss: 1.786420004342192

Epoch: 6| Step: 8
Training loss: 0.3868992030620575
Validation loss: 1.7593975195320704

Epoch: 6| Step: 9
Training loss: 0.9120195508003235
Validation loss: 1.7661941205301592

Epoch: 6| Step: 10
Training loss: 0.4694496989250183
Validation loss: 1.7878235770810036

Epoch: 6| Step: 11
Training loss: 0.5181423425674438
Validation loss: 1.7549143965526293

Epoch: 6| Step: 12
Training loss: 0.35243839025497437
Validation loss: 1.7776078485673474

Epoch: 6| Step: 13
Training loss: 0.6177657842636108
Validation loss: 1.774514611049365

Epoch: 319| Step: 0
Training loss: 0.3833599090576172
Validation loss: 1.7818660492538123

Epoch: 6| Step: 1
Training loss: 0.5340641140937805
Validation loss: 1.815541668604779

Epoch: 6| Step: 2
Training loss: 0.6785277724266052
Validation loss: 1.8011678803351618

Epoch: 6| Step: 3
Training loss: 0.2465246617794037
Validation loss: 1.8197539878147904

Epoch: 6| Step: 4
Training loss: 0.487650990486145
Validation loss: 1.8217644371012205

Epoch: 6| Step: 5
Training loss: 0.47849199175834656
Validation loss: 1.7851267014780352

Epoch: 6| Step: 6
Training loss: 0.5432727932929993
Validation loss: 1.8073059576813892

Epoch: 6| Step: 7
Training loss: 0.37614136934280396
Validation loss: 1.8120934681225849

Epoch: 6| Step: 8
Training loss: 0.29404592514038086
Validation loss: 1.7393627717930784

Epoch: 6| Step: 9
Training loss: 0.2698984146118164
Validation loss: 1.7794712871633551

Epoch: 6| Step: 10
Training loss: 0.8100754022598267
Validation loss: 1.814618702857725

Epoch: 6| Step: 11
Training loss: 0.549425482749939
Validation loss: 1.782218199904247

Epoch: 6| Step: 12
Training loss: 0.49382442235946655
Validation loss: 1.7855568034674532

Epoch: 6| Step: 13
Training loss: 0.36344191431999207
Validation loss: 1.7649711101285872

Epoch: 320| Step: 0
Training loss: 0.26296836137771606
Validation loss: 1.7855665658109932

Epoch: 6| Step: 1
Training loss: 0.498005211353302
Validation loss: 1.795605380048034

Epoch: 6| Step: 2
Training loss: 0.6054278016090393
Validation loss: 1.8263279853328582

Epoch: 6| Step: 3
Training loss: 0.34326595067977905
Validation loss: 1.8243417637322539

Epoch: 6| Step: 4
Training loss: 0.34955352544784546
Validation loss: 1.8500893372361378

Epoch: 6| Step: 5
Training loss: 0.4454347491264343
Validation loss: 1.8436818661228302

Epoch: 6| Step: 6
Training loss: 0.4899356961250305
Validation loss: 1.8283965459433935

Epoch: 6| Step: 7
Training loss: 0.7864291071891785
Validation loss: 1.7981412128735614

Epoch: 6| Step: 8
Training loss: 0.3607174754142761
Validation loss: 1.769260610303571

Epoch: 6| Step: 9
Training loss: 0.5085936784744263
Validation loss: 1.7532942782166183

Epoch: 6| Step: 10
Training loss: 0.6231565475463867
Validation loss: 1.792280827799151

Epoch: 6| Step: 11
Training loss: 0.36069199442863464
Validation loss: 1.7700356437313942

Epoch: 6| Step: 12
Training loss: 0.529361367225647
Validation loss: 1.76488842246353

Epoch: 6| Step: 13
Training loss: 0.5027785897254944
Validation loss: 1.7413639118594508

Epoch: 321| Step: 0
Training loss: 0.9786339402198792
Validation loss: 1.771875487860813

Epoch: 6| Step: 1
Training loss: 0.41249096393585205
Validation loss: 1.7694009388646772

Epoch: 6| Step: 2
Training loss: 0.2514142394065857
Validation loss: 1.7923397761519237

Epoch: 6| Step: 3
Training loss: 0.4017264246940613
Validation loss: 1.7724730327565184

Epoch: 6| Step: 4
Training loss: 0.6042622327804565
Validation loss: 1.7612545336446455

Epoch: 6| Step: 5
Training loss: 0.32798856496810913
Validation loss: 1.7984557267158263

Epoch: 6| Step: 6
Training loss: 0.4960668087005615
Validation loss: 1.80417081873904

Epoch: 6| Step: 7
Training loss: 0.4763587415218353
Validation loss: 1.738798729835018

Epoch: 6| Step: 8
Training loss: 0.3315403461456299
Validation loss: 1.771081438628576

Epoch: 6| Step: 9
Training loss: 0.576778769493103
Validation loss: 1.8240719405553674

Epoch: 6| Step: 10
Training loss: 0.375136137008667
Validation loss: 1.7784714916700959

Epoch: 6| Step: 11
Training loss: 0.512606680393219
Validation loss: 1.7636543217525686

Epoch: 6| Step: 12
Training loss: 0.3842678666114807
Validation loss: 1.790946375939154

Epoch: 6| Step: 13
Training loss: 0.45638689398765564
Validation loss: 1.7717680213271931

Epoch: 322| Step: 0
Training loss: 0.2631543278694153
Validation loss: 1.78793913830993

Epoch: 6| Step: 1
Training loss: 0.3283402919769287
Validation loss: 1.7793492219781364

Epoch: 6| Step: 2
Training loss: 0.3745805621147156
Validation loss: 1.7563269112699775

Epoch: 6| Step: 3
Training loss: 0.5780602693557739
Validation loss: 1.7961369893884147

Epoch: 6| Step: 4
Training loss: 0.5403357148170471
Validation loss: 1.820978703037385

Epoch: 6| Step: 5
Training loss: 0.48905855417251587
Validation loss: 1.7767353083497734

Epoch: 6| Step: 6
Training loss: 0.5198147892951965
Validation loss: 1.81483426145328

Epoch: 6| Step: 7
Training loss: 0.46345070004463196
Validation loss: 1.8391516349648918

Epoch: 6| Step: 8
Training loss: 0.5178446769714355
Validation loss: 1.8261505237189672

Epoch: 6| Step: 9
Training loss: 0.3084776699542999
Validation loss: 1.819483668573441

Epoch: 6| Step: 10
Training loss: 0.31279802322387695
Validation loss: 1.815207673657325

Epoch: 6| Step: 11
Training loss: 0.3427031636238098
Validation loss: 1.8041303465443272

Epoch: 6| Step: 12
Training loss: 0.4901507496833801
Validation loss: 1.8244970895910775

Epoch: 6| Step: 13
Training loss: 0.9883492588996887
Validation loss: 1.775732365987634

Epoch: 323| Step: 0
Training loss: 0.5626736879348755
Validation loss: 1.7670704908268426

Epoch: 6| Step: 1
Training loss: 0.19151537120342255
Validation loss: 1.7968767099483038

Epoch: 6| Step: 2
Training loss: 0.8062611818313599
Validation loss: 1.7728918701089837

Epoch: 6| Step: 3
Training loss: 0.4557214379310608
Validation loss: 1.8008161821672994

Epoch: 6| Step: 4
Training loss: 0.49669283628463745
Validation loss: 1.8033752287587812

Epoch: 6| Step: 5
Training loss: 0.3082473576068878
Validation loss: 1.8008134031808505

Epoch: 6| Step: 6
Training loss: 0.5852007269859314
Validation loss: 1.82816134729693

Epoch: 6| Step: 7
Training loss: 0.4699576497077942
Validation loss: 1.8310198142964353

Epoch: 6| Step: 8
Training loss: 0.38925623893737793
Validation loss: 1.8172215313039801

Epoch: 6| Step: 9
Training loss: 0.4214716851711273
Validation loss: 1.8023452681879844

Epoch: 6| Step: 10
Training loss: 0.2679404020309448
Validation loss: 1.7998084663062968

Epoch: 6| Step: 11
Training loss: 0.3094882667064667
Validation loss: 1.8115143545212284

Epoch: 6| Step: 12
Training loss: 0.4051659405231476
Validation loss: 1.8163636897199897

Epoch: 6| Step: 13
Training loss: 0.8195429444313049
Validation loss: 1.7972710645327004

Epoch: 324| Step: 0
Training loss: 0.293662428855896
Validation loss: 1.7785089913234915

Epoch: 6| Step: 1
Training loss: 0.7222062349319458
Validation loss: 1.7807002157293341

Epoch: 6| Step: 2
Training loss: 0.27386409044265747
Validation loss: 1.7716255034169843

Epoch: 6| Step: 3
Training loss: 0.23486876487731934
Validation loss: 1.7499345361545522

Epoch: 6| Step: 4
Training loss: 0.6799498796463013
Validation loss: 1.7602299041645502

Epoch: 6| Step: 5
Training loss: 0.35261601209640503
Validation loss: 1.7605394355712398

Epoch: 6| Step: 6
Training loss: 0.28941041231155396
Validation loss: 1.762331162729571

Epoch: 6| Step: 7
Training loss: 0.5553425550460815
Validation loss: 1.733147048181103

Epoch: 6| Step: 8
Training loss: 0.4240769147872925
Validation loss: 1.7293105548427952

Epoch: 6| Step: 9
Training loss: 0.26159852743148804
Validation loss: 1.7498963545727473

Epoch: 6| Step: 10
Training loss: 0.7248640060424805
Validation loss: 1.7287416624766525

Epoch: 6| Step: 11
Training loss: 0.29113519191741943
Validation loss: 1.7516169419852636

Epoch: 6| Step: 12
Training loss: 0.4454624652862549
Validation loss: 1.7204591125570319

Epoch: 6| Step: 13
Training loss: 0.360351026058197
Validation loss: 1.7530704621345765

Epoch: 325| Step: 0
Training loss: 0.18521694839000702
Validation loss: 1.7687961721933017

Epoch: 6| Step: 1
Training loss: 0.33517277240753174
Validation loss: 1.76761842543079

Epoch: 6| Step: 2
Training loss: 0.3230542838573456
Validation loss: 1.7670903231507988

Epoch: 6| Step: 3
Training loss: 0.3222261071205139
Validation loss: 1.7848077717647757

Epoch: 6| Step: 4
Training loss: 0.44073742628097534
Validation loss: 1.801467828853156

Epoch: 6| Step: 5
Training loss: 0.5040111541748047
Validation loss: 1.8305163614211544

Epoch: 6| Step: 6
Training loss: 0.33169689774513245
Validation loss: 1.8355560559098438

Epoch: 6| Step: 7
Training loss: 0.550682544708252
Validation loss: 1.821967198002723

Epoch: 6| Step: 8
Training loss: 0.4994904398918152
Validation loss: 1.8132307375631025

Epoch: 6| Step: 9
Training loss: 0.5440607070922852
Validation loss: 1.8415551134335097

Epoch: 6| Step: 10
Training loss: 0.42266595363616943
Validation loss: 1.8472827634503763

Epoch: 6| Step: 11
Training loss: 0.5308172702789307
Validation loss: 1.8316472589328725

Epoch: 6| Step: 12
Training loss: 0.3208138346672058
Validation loss: 1.8429343546590498

Epoch: 6| Step: 13
Training loss: 1.0452626943588257
Validation loss: 1.8219240878217964

Epoch: 326| Step: 0
Training loss: 0.3152807354927063
Validation loss: 1.7847079371893277

Epoch: 6| Step: 1
Training loss: 1.0537059307098389
Validation loss: 1.8051298356825305

Epoch: 6| Step: 2
Training loss: 0.22243064641952515
Validation loss: 1.8059907138988536

Epoch: 6| Step: 3
Training loss: 0.18601202964782715
Validation loss: 1.759868005270599

Epoch: 6| Step: 4
Training loss: 0.49505728483200073
Validation loss: 1.781875850051962

Epoch: 6| Step: 5
Training loss: 0.46119439601898193
Validation loss: 1.7526383156417518

Epoch: 6| Step: 6
Training loss: 0.6029168963432312
Validation loss: 1.7632258835659231

Epoch: 6| Step: 7
Training loss: 0.45776012539863586
Validation loss: 1.740545677882369

Epoch: 6| Step: 8
Training loss: 0.3702635169029236
Validation loss: 1.7593410989289642

Epoch: 6| Step: 9
Training loss: 0.35542169213294983
Validation loss: 1.7515781169296594

Epoch: 6| Step: 10
Training loss: 0.26992934942245483
Validation loss: 1.7564793940513366

Epoch: 6| Step: 11
Training loss: 0.3192843198776245
Validation loss: 1.7737118326207644

Epoch: 6| Step: 12
Training loss: 0.5640414953231812
Validation loss: 1.7968393487315024

Epoch: 6| Step: 13
Training loss: 0.33222800493240356
Validation loss: 1.7751371463139851

Epoch: 327| Step: 0
Training loss: 0.4722321927547455
Validation loss: 1.7869284063257196

Epoch: 6| Step: 1
Training loss: 0.0897417962551117
Validation loss: 1.803253916002089

Epoch: 6| Step: 2
Training loss: 0.2797122001647949
Validation loss: 1.7787559263167843

Epoch: 6| Step: 3
Training loss: 0.49978137016296387
Validation loss: 1.7616928444113782

Epoch: 6| Step: 4
Training loss: 0.35486704111099243
Validation loss: 1.7890674157809185

Epoch: 6| Step: 5
Training loss: 0.30319303274154663
Validation loss: 1.7891945762019004

Epoch: 6| Step: 6
Training loss: 0.384234219789505
Validation loss: 1.7738315559202624

Epoch: 6| Step: 7
Training loss: 0.5740251541137695
Validation loss: 1.7801160235558786

Epoch: 6| Step: 8
Training loss: 0.507576584815979
Validation loss: 1.7483045144747662

Epoch: 6| Step: 9
Training loss: 0.38064640760421753
Validation loss: 1.7773991797560005

Epoch: 6| Step: 10
Training loss: 0.6945013403892517
Validation loss: 1.7729698714389597

Epoch: 6| Step: 11
Training loss: 0.5285842418670654
Validation loss: 1.748406938327256

Epoch: 6| Step: 12
Training loss: 0.3781193494796753
Validation loss: 1.8087330710503362

Epoch: 6| Step: 13
Training loss: 0.23395228385925293
Validation loss: 1.8144442676216044

Epoch: 328| Step: 0
Training loss: 0.44858622550964355
Validation loss: 1.7982584494416431

Epoch: 6| Step: 1
Training loss: 0.35564354062080383
Validation loss: 1.7906845936211206

Epoch: 6| Step: 2
Training loss: 0.2949167788028717
Validation loss: 1.8296551922316193

Epoch: 6| Step: 3
Training loss: 0.7161388993263245
Validation loss: 1.8164174710550616

Epoch: 6| Step: 4
Training loss: 0.7458236217498779
Validation loss: 1.8349446596637848

Epoch: 6| Step: 5
Training loss: 0.344769686460495
Validation loss: 1.8006912380136468

Epoch: 6| Step: 6
Training loss: 0.47820132970809937
Validation loss: 1.794656753540039

Epoch: 6| Step: 7
Training loss: 0.19087129831314087
Validation loss: 1.7648327581344112

Epoch: 6| Step: 8
Training loss: 0.19306915998458862
Validation loss: 1.7901496528297343

Epoch: 6| Step: 9
Training loss: 0.30863773822784424
Validation loss: 1.7598575186985794

Epoch: 6| Step: 10
Training loss: 0.2846828103065491
Validation loss: 1.7787358312196628

Epoch: 6| Step: 11
Training loss: 0.38794687390327454
Validation loss: 1.7835021993165374

Epoch: 6| Step: 12
Training loss: 0.6818724870681763
Validation loss: 1.7779276576093448

Epoch: 6| Step: 13
Training loss: 0.3455132246017456
Validation loss: 1.7557720599635955

Epoch: 329| Step: 0
Training loss: 0.61857008934021
Validation loss: 1.7881600190234441

Epoch: 6| Step: 1
Training loss: 0.2140466570854187
Validation loss: 1.7599676116820304

Epoch: 6| Step: 2
Training loss: 0.415899395942688
Validation loss: 1.763772342794685

Epoch: 6| Step: 3
Training loss: 0.38586440682411194
Validation loss: 1.7733343865281792

Epoch: 6| Step: 4
Training loss: 0.41091060638427734
Validation loss: 1.7579404295131724

Epoch: 6| Step: 5
Training loss: 0.5578176975250244
Validation loss: 1.7819707342373428

Epoch: 6| Step: 6
Training loss: 0.3550602197647095
Validation loss: 1.8048102419863465

Epoch: 6| Step: 7
Training loss: 0.3821098208427429
Validation loss: 1.7798402399145148

Epoch: 6| Step: 8
Training loss: 0.47304433584213257
Validation loss: 1.8098891909404466

Epoch: 6| Step: 9
Training loss: 0.4223337173461914
Validation loss: 1.7928191051688245

Epoch: 6| Step: 10
Training loss: 0.5546780824661255
Validation loss: 1.8019979871729368

Epoch: 6| Step: 11
Training loss: 0.1805199384689331
Validation loss: 1.8304300141590897

Epoch: 6| Step: 12
Training loss: 0.36624711751937866
Validation loss: 1.818551158392301

Epoch: 6| Step: 13
Training loss: 0.52638179063797
Validation loss: 1.8047967649275256

Epoch: 330| Step: 0
Training loss: 0.3205685615539551
Validation loss: 1.8163728124351912

Epoch: 6| Step: 1
Training loss: 0.6507948637008667
Validation loss: 1.8207254948154572

Epoch: 6| Step: 2
Training loss: 0.5007909536361694
Validation loss: 1.7942730406279206

Epoch: 6| Step: 3
Training loss: 0.4460858106613159
Validation loss: 1.8310245262679232

Epoch: 6| Step: 4
Training loss: 0.5597063302993774
Validation loss: 1.8501614678290583

Epoch: 6| Step: 5
Training loss: 0.440972238779068
Validation loss: 1.8372210430842575

Epoch: 6| Step: 6
Training loss: 0.40407684445381165
Validation loss: 1.8258808735878236

Epoch: 6| Step: 7
Training loss: 0.4322608709335327
Validation loss: 1.8233966263391639

Epoch: 6| Step: 8
Training loss: 0.34066247940063477
Validation loss: 1.8064818600172639

Epoch: 6| Step: 9
Training loss: 0.4228605031967163
Validation loss: 1.7553793973820184

Epoch: 6| Step: 10
Training loss: 0.3897109627723694
Validation loss: 1.7655998558126471

Epoch: 6| Step: 11
Training loss: 0.3566247224807739
Validation loss: 1.7587184841914842

Epoch: 6| Step: 12
Training loss: 0.37820178270339966
Validation loss: 1.7565403164073985

Epoch: 6| Step: 13
Training loss: 0.3880941569805145
Validation loss: 1.7311380370970695

Epoch: 331| Step: 0
Training loss: 0.45446696877479553
Validation loss: 1.7301877314044583

Epoch: 6| Step: 1
Training loss: 0.37228816747665405
Validation loss: 1.7337884159498318

Epoch: 6| Step: 2
Training loss: 0.5161681175231934
Validation loss: 1.7274304923190866

Epoch: 6| Step: 3
Training loss: 0.28834909200668335
Validation loss: 1.736725261134486

Epoch: 6| Step: 4
Training loss: 0.36210697889328003
Validation loss: 1.7229054563788957

Epoch: 6| Step: 5
Training loss: 0.733769953250885
Validation loss: 1.7660602497798141

Epoch: 6| Step: 6
Training loss: 0.34174665808677673
Validation loss: 1.7181108997714134

Epoch: 6| Step: 7
Training loss: 0.256775438785553
Validation loss: 1.7555114325656687

Epoch: 6| Step: 8
Training loss: 0.40076160430908203
Validation loss: 1.7451070585558492

Epoch: 6| Step: 9
Training loss: 0.5431309938430786
Validation loss: 1.7667260298164942

Epoch: 6| Step: 10
Training loss: 0.398484468460083
Validation loss: 1.7886495878619533

Epoch: 6| Step: 11
Training loss: 0.4664222300052643
Validation loss: 1.780689170283656

Epoch: 6| Step: 12
Training loss: 0.5046346187591553
Validation loss: 1.7927842396561817

Epoch: 6| Step: 13
Training loss: 0.45837223529815674
Validation loss: 1.8174078464508057

Epoch: 332| Step: 0
Training loss: 0.3995220959186554
Validation loss: 1.7887847372280654

Epoch: 6| Step: 1
Training loss: 0.3932805359363556
Validation loss: 1.7754396879544823

Epoch: 6| Step: 2
Training loss: 0.6105629205703735
Validation loss: 1.7664523855332406

Epoch: 6| Step: 3
Training loss: 0.27033576369285583
Validation loss: 1.7588372384348223

Epoch: 6| Step: 4
Training loss: 0.7031914591789246
Validation loss: 1.7609988245912778

Epoch: 6| Step: 5
Training loss: 0.34296607971191406
Validation loss: 1.7356169146876181

Epoch: 6| Step: 6
Training loss: 0.503531813621521
Validation loss: 1.7425556452043596

Epoch: 6| Step: 7
Training loss: 0.29222357273101807
Validation loss: 1.733624291676347

Epoch: 6| Step: 8
Training loss: 0.4498346745967865
Validation loss: 1.755186027096164

Epoch: 6| Step: 9
Training loss: 0.2527819871902466
Validation loss: 1.8051829440619356

Epoch: 6| Step: 10
Training loss: 0.47416630387306213
Validation loss: 1.7795783037780433

Epoch: 6| Step: 11
Training loss: 0.2581685185432434
Validation loss: 1.7821799324404808

Epoch: 6| Step: 12
Training loss: 0.17722828686237335
Validation loss: 1.7911179296432003

Epoch: 6| Step: 13
Training loss: 0.41941821575164795
Validation loss: 1.8236729765451083

Epoch: 333| Step: 0
Training loss: 0.22980618476867676
Validation loss: 1.803806822787049

Epoch: 6| Step: 1
Training loss: 0.2593446969985962
Validation loss: 1.784034429057952

Epoch: 6| Step: 2
Training loss: 0.24338743090629578
Validation loss: 1.779157959004884

Epoch: 6| Step: 3
Training loss: 0.3829592168331146
Validation loss: 1.8072345525987688

Epoch: 6| Step: 4
Training loss: 0.4966834783554077
Validation loss: 1.7663865454735295

Epoch: 6| Step: 5
Training loss: 0.48712825775146484
Validation loss: 1.7650137229632306

Epoch: 6| Step: 6
Training loss: 0.3560739755630493
Validation loss: 1.7501320544109549

Epoch: 6| Step: 7
Training loss: 0.23861798644065857
Validation loss: 1.7599523682748117

Epoch: 6| Step: 8
Training loss: 0.43911466002464294
Validation loss: 1.75310379715376

Epoch: 6| Step: 9
Training loss: 0.4458463191986084
Validation loss: 1.7544906639283704

Epoch: 6| Step: 10
Training loss: 0.5777902603149414
Validation loss: 1.7499470659481582

Epoch: 6| Step: 11
Training loss: 0.3697705566883087
Validation loss: 1.7571013627513763

Epoch: 6| Step: 12
Training loss: 0.42623692750930786
Validation loss: 1.7897907098134358

Epoch: 6| Step: 13
Training loss: 0.6619994640350342
Validation loss: 1.8216346925304783

Epoch: 334| Step: 0
Training loss: 0.46905237436294556
Validation loss: 1.7859859710098596

Epoch: 6| Step: 1
Training loss: 0.532585859298706
Validation loss: 1.7785540767895278

Epoch: 6| Step: 2
Training loss: 0.540355920791626
Validation loss: 1.7804788902241697

Epoch: 6| Step: 3
Training loss: 0.316096693277359
Validation loss: 1.7375470220401723

Epoch: 6| Step: 4
Training loss: 0.7426053285598755
Validation loss: 1.7444284295523038

Epoch: 6| Step: 5
Training loss: 0.35110265016555786
Validation loss: 1.729299291487663

Epoch: 6| Step: 6
Training loss: 0.21664977073669434
Validation loss: 1.6990615680653562

Epoch: 6| Step: 7
Training loss: 0.515932023525238
Validation loss: 1.7331428758559688

Epoch: 6| Step: 8
Training loss: 0.34531551599502563
Validation loss: 1.7305072930551344

Epoch: 6| Step: 9
Training loss: 0.2571002244949341
Validation loss: 1.7280472850286832

Epoch: 6| Step: 10
Training loss: 0.24690136313438416
Validation loss: 1.7083760358953988

Epoch: 6| Step: 11
Training loss: 0.4657741189002991
Validation loss: 1.7370588779449463

Epoch: 6| Step: 12
Training loss: 0.49056172370910645
Validation loss: 1.7317969145313385

Epoch: 6| Step: 13
Training loss: 0.44816669821739197
Validation loss: 1.7348531984513806

Epoch: 335| Step: 0
Training loss: 0.42774340510368347
Validation loss: 1.743055974283526

Epoch: 6| Step: 1
Training loss: 0.4223460555076599
Validation loss: 1.7435301837100778

Epoch: 6| Step: 2
Training loss: 0.3168709874153137
Validation loss: 1.7907078240507392

Epoch: 6| Step: 3
Training loss: 0.5446830987930298
Validation loss: 1.7503301802501883

Epoch: 6| Step: 4
Training loss: 0.5320984721183777
Validation loss: 1.7931300568324264

Epoch: 6| Step: 5
Training loss: 0.3537580966949463
Validation loss: 1.8180085946154851

Epoch: 6| Step: 6
Training loss: 0.3213917016983032
Validation loss: 1.8174937386666574

Epoch: 6| Step: 7
Training loss: 0.36193957924842834
Validation loss: 1.8323173958768126

Epoch: 6| Step: 8
Training loss: 0.4591745436191559
Validation loss: 1.8057535386854602

Epoch: 6| Step: 9
Training loss: 0.3245241940021515
Validation loss: 1.8268666908305178

Epoch: 6| Step: 10
Training loss: 0.3811976909637451
Validation loss: 1.8050001872483121

Epoch: 6| Step: 11
Training loss: 0.2747620940208435
Validation loss: 1.7889484128644388

Epoch: 6| Step: 12
Training loss: 0.3534148037433624
Validation loss: 1.7846824815196376

Epoch: 6| Step: 13
Training loss: 0.4412398934364319
Validation loss: 1.804116242675371

Epoch: 336| Step: 0
Training loss: 0.3525552749633789
Validation loss: 1.7829854693464053

Epoch: 6| Step: 1
Training loss: 0.3895740509033203
Validation loss: 1.7770787515947897

Epoch: 6| Step: 2
Training loss: 0.35048621892929077
Validation loss: 1.7971874847207019

Epoch: 6| Step: 3
Training loss: 0.3132669925689697
Validation loss: 1.7890341538254932

Epoch: 6| Step: 4
Training loss: 0.3478206396102905
Validation loss: 1.8063116586336525

Epoch: 6| Step: 5
Training loss: 0.4773348569869995
Validation loss: 1.8274093597166

Epoch: 6| Step: 6
Training loss: 0.3437657952308655
Validation loss: 1.8085003565716486

Epoch: 6| Step: 7
Training loss: 0.3109161853790283
Validation loss: 1.7897743678862048

Epoch: 6| Step: 8
Training loss: 0.3913795053958893
Validation loss: 1.7594153599072528

Epoch: 6| Step: 9
Training loss: 0.36654168367385864
Validation loss: 1.7871294790698635

Epoch: 6| Step: 10
Training loss: 0.8832656145095825
Validation loss: 1.7858204162249

Epoch: 6| Step: 11
Training loss: 0.3151116967201233
Validation loss: 1.7689784637061499

Epoch: 6| Step: 12
Training loss: 0.30069154500961304
Validation loss: 1.8023611076416508

Epoch: 6| Step: 13
Training loss: 0.33564475178718567
Validation loss: 1.8138339827137608

Epoch: 337| Step: 0
Training loss: 0.3471677303314209
Validation loss: 1.7841794843314795

Epoch: 6| Step: 1
Training loss: 0.29571908712387085
Validation loss: 1.7559212817940661

Epoch: 6| Step: 2
Training loss: 0.2844090759754181
Validation loss: 1.781199219406292

Epoch: 6| Step: 3
Training loss: 0.4886469542980194
Validation loss: 1.7848541710966377

Epoch: 6| Step: 4
Training loss: 0.2889084219932556
Validation loss: 1.7656061508322274

Epoch: 6| Step: 5
Training loss: 0.2825843095779419
Validation loss: 1.77534455637778

Epoch: 6| Step: 6
Training loss: 0.31553077697753906
Validation loss: 1.749633865971719

Epoch: 6| Step: 7
Training loss: 0.32934409379959106
Validation loss: 1.7724921267519715

Epoch: 6| Step: 8
Training loss: 0.39744722843170166
Validation loss: 1.7990199430014497

Epoch: 6| Step: 9
Training loss: 0.5094225406646729
Validation loss: 1.7790014423349851

Epoch: 6| Step: 10
Training loss: 0.377078115940094
Validation loss: 1.8122653397180701

Epoch: 6| Step: 11
Training loss: 0.4112136960029602
Validation loss: 1.7944997549057007

Epoch: 6| Step: 12
Training loss: 0.3192051947116852
Validation loss: 1.7830460648382864

Epoch: 6| Step: 13
Training loss: 0.7739362120628357
Validation loss: 1.7554888738098966

Epoch: 338| Step: 0
Training loss: 0.14355036616325378
Validation loss: 1.7715367937600741

Epoch: 6| Step: 1
Training loss: 0.5049904584884644
Validation loss: 1.7673577307372965

Epoch: 6| Step: 2
Training loss: 0.5214188098907471
Validation loss: 1.7891483358157578

Epoch: 6| Step: 3
Training loss: 0.2944250702857971
Validation loss: 1.7661713297649095

Epoch: 6| Step: 4
Training loss: 0.19296440482139587
Validation loss: 1.7681417708755822

Epoch: 6| Step: 5
Training loss: 0.3778378367424011
Validation loss: 1.7692913547638924

Epoch: 6| Step: 6
Training loss: 0.4740394353866577
Validation loss: 1.756675781101309

Epoch: 6| Step: 7
Training loss: 0.3499132990837097
Validation loss: 1.7305798030668689

Epoch: 6| Step: 8
Training loss: 0.40721291303634644
Validation loss: 1.7862171485859861

Epoch: 6| Step: 9
Training loss: 0.32867226004600525
Validation loss: 1.74953463257

Epoch: 6| Step: 10
Training loss: 0.6604376435279846
Validation loss: 1.7513397073233

Epoch: 6| Step: 11
Training loss: 0.13786718249320984
Validation loss: 1.7768506350055817

Epoch: 6| Step: 12
Training loss: 0.43465861678123474
Validation loss: 1.794417744041771

Epoch: 6| Step: 13
Training loss: 0.5356373190879822
Validation loss: 1.7816815337827128

Epoch: 339| Step: 0
Training loss: 0.35051700472831726
Validation loss: 1.7707289803412654

Epoch: 6| Step: 1
Training loss: 0.3783135414123535
Validation loss: 1.7901926886650823

Epoch: 6| Step: 2
Training loss: 0.25467491149902344
Validation loss: 1.7851956608474895

Epoch: 6| Step: 3
Training loss: 0.33013492822647095
Validation loss: 1.7478676970287035

Epoch: 6| Step: 4
Training loss: 0.4518923759460449
Validation loss: 1.7442766908676393

Epoch: 6| Step: 5
Training loss: 0.3141399025917053
Validation loss: 1.704903066799205

Epoch: 6| Step: 6
Training loss: 0.35911619663238525
Validation loss: 1.7576009124837897

Epoch: 6| Step: 7
Training loss: 0.48432254791259766
Validation loss: 1.761721880205216

Epoch: 6| Step: 8
Training loss: 0.2867056131362915
Validation loss: 1.7340746848813948

Epoch: 6| Step: 9
Training loss: 0.3943690359592438
Validation loss: 1.7770414698508479

Epoch: 6| Step: 10
Training loss: 0.5314827561378479
Validation loss: 1.7391501062659807

Epoch: 6| Step: 11
Training loss: 0.3446028530597687
Validation loss: 1.7877706276473178

Epoch: 6| Step: 12
Training loss: 0.31840813159942627
Validation loss: 1.7756077153708345

Epoch: 6| Step: 13
Training loss: 0.5320228338241577
Validation loss: 1.7742920152602657

Epoch: 340| Step: 0
Training loss: 0.3401526212692261
Validation loss: 1.7630090610955351

Epoch: 6| Step: 1
Training loss: 0.4251237213611603
Validation loss: 1.7655975741724814

Epoch: 6| Step: 2
Training loss: 0.23345786333084106
Validation loss: 1.7420855709301528

Epoch: 6| Step: 3
Training loss: 0.3001066744327545
Validation loss: 1.734146523219283

Epoch: 6| Step: 4
Training loss: 0.6267974972724915
Validation loss: 1.7525412074981197

Epoch: 6| Step: 5
Training loss: 0.3346576690673828
Validation loss: 1.7586883755140408

Epoch: 6| Step: 6
Training loss: 0.3624265491962433
Validation loss: 1.7818647571789321

Epoch: 6| Step: 7
Training loss: 0.12445183843374252
Validation loss: 1.7854470745209725

Epoch: 6| Step: 8
Training loss: 0.5050555467605591
Validation loss: 1.8155602114174956

Epoch: 6| Step: 9
Training loss: 0.5846822261810303
Validation loss: 1.8217044991831626

Epoch: 6| Step: 10
Training loss: 0.4062317907810211
Validation loss: 1.7951786248914656

Epoch: 6| Step: 11
Training loss: 0.26749879121780396
Validation loss: 1.8009058185802993

Epoch: 6| Step: 12
Training loss: 0.37844398617744446
Validation loss: 1.8105879957957933

Epoch: 6| Step: 13
Training loss: 0.29939594864845276
Validation loss: 1.7922727049037974

Epoch: 341| Step: 0
Training loss: 0.36833271384239197
Validation loss: 1.790846133744845

Epoch: 6| Step: 1
Training loss: 0.4127396047115326
Validation loss: 1.7981997036164807

Epoch: 6| Step: 2
Training loss: 0.7224266529083252
Validation loss: 1.8031153601984824

Epoch: 6| Step: 3
Training loss: 0.3390093147754669
Validation loss: 1.7973258277421356

Epoch: 6| Step: 4
Training loss: 0.3245677053928375
Validation loss: 1.7888260490150862

Epoch: 6| Step: 5
Training loss: 0.4073599576950073
Validation loss: 1.7801332678846133

Epoch: 6| Step: 6
Training loss: 0.4620122015476227
Validation loss: 1.809736897868495

Epoch: 6| Step: 7
Training loss: 0.36298197507858276
Validation loss: 1.7990249254370247

Epoch: 6| Step: 8
Training loss: 0.2918057441711426
Validation loss: 1.7781418036389094

Epoch: 6| Step: 9
Training loss: 0.24773654341697693
Validation loss: 1.8149111706723449

Epoch: 6| Step: 10
Training loss: 0.39872807264328003
Validation loss: 1.786576747894287

Epoch: 6| Step: 11
Training loss: 0.354963093996048
Validation loss: 1.783548931921682

Epoch: 6| Step: 12
Training loss: 0.3382645547389984
Validation loss: 1.7717368397661435

Epoch: 6| Step: 13
Training loss: 0.21013695001602173
Validation loss: 1.8206291032093826

Epoch: 342| Step: 0
Training loss: 0.47617021203041077
Validation loss: 1.764445315125168

Epoch: 6| Step: 1
Training loss: 0.289049357175827
Validation loss: 1.7695630340165989

Epoch: 6| Step: 2
Training loss: 0.5969957113265991
Validation loss: 1.7684108313693796

Epoch: 6| Step: 3
Training loss: 0.38112741708755493
Validation loss: 1.7555977259912798

Epoch: 6| Step: 4
Training loss: 0.4180580973625183
Validation loss: 1.781209776478429

Epoch: 6| Step: 5
Training loss: 0.22758209705352783
Validation loss: 1.7601221364031556

Epoch: 6| Step: 6
Training loss: 0.3152298927307129
Validation loss: 1.7581530206946916

Epoch: 6| Step: 7
Training loss: 0.2274690866470337
Validation loss: 1.7890649585313694

Epoch: 6| Step: 8
Training loss: 0.30175966024398804
Validation loss: 1.7989725630770448

Epoch: 6| Step: 9
Training loss: 0.5954105257987976
Validation loss: 1.762260793357767

Epoch: 6| Step: 10
Training loss: 0.37466174364089966
Validation loss: 1.79062702450701

Epoch: 6| Step: 11
Training loss: 0.34443509578704834
Validation loss: 1.7995302497699697

Epoch: 6| Step: 12
Training loss: 0.39995214343070984
Validation loss: 1.7601884590682162

Epoch: 6| Step: 13
Training loss: 0.21222977340221405
Validation loss: 1.7586274839216662

Epoch: 343| Step: 0
Training loss: 0.29976093769073486
Validation loss: 1.774050058857087

Epoch: 6| Step: 1
Training loss: 0.5195382237434387
Validation loss: 1.738848740054715

Epoch: 6| Step: 2
Training loss: 0.33602312207221985
Validation loss: 1.7420060314157957

Epoch: 6| Step: 3
Training loss: 0.44310465455055237
Validation loss: 1.7470696972262474

Epoch: 6| Step: 4
Training loss: 0.16331660747528076
Validation loss: 1.7522097915731452

Epoch: 6| Step: 5
Training loss: 0.3689224123954773
Validation loss: 1.7507355315710909

Epoch: 6| Step: 6
Training loss: 0.5450422763824463
Validation loss: 1.8086369819538568

Epoch: 6| Step: 7
Training loss: 0.5587058663368225
Validation loss: 1.7552399660951348

Epoch: 6| Step: 8
Training loss: 0.20945195853710175
Validation loss: 1.750284505146806

Epoch: 6| Step: 9
Training loss: 0.2256210893392563
Validation loss: 1.7609737957677534

Epoch: 6| Step: 10
Training loss: 0.21302413940429688
Validation loss: 1.780631766524366

Epoch: 6| Step: 11
Training loss: 0.4041861891746521
Validation loss: 1.7762854586365402

Epoch: 6| Step: 12
Training loss: 0.4122201204299927
Validation loss: 1.7734708016918552

Epoch: 6| Step: 13
Training loss: 0.33374348282814026
Validation loss: 1.7841939541601366

Epoch: 344| Step: 0
Training loss: 0.3287006616592407
Validation loss: 1.77260846220037

Epoch: 6| Step: 1
Training loss: 0.22592677175998688
Validation loss: 1.7849201617702362

Epoch: 6| Step: 2
Training loss: 0.35561275482177734
Validation loss: 1.7674942183238205

Epoch: 6| Step: 3
Training loss: 0.23198272287845612
Validation loss: 1.762779817786268

Epoch: 6| Step: 4
Training loss: 0.2978981137275696
Validation loss: 1.7903200375136508

Epoch: 6| Step: 5
Training loss: 1.044518232345581
Validation loss: 1.7523065728525962

Epoch: 6| Step: 6
Training loss: 0.2813946604728699
Validation loss: 1.8091122001729987

Epoch: 6| Step: 7
Training loss: 0.24173793196678162
Validation loss: 1.758997171155868

Epoch: 6| Step: 8
Training loss: 0.4422228932380676
Validation loss: 1.7659543534760833

Epoch: 6| Step: 9
Training loss: 0.39837950468063354
Validation loss: 1.7900034932680027

Epoch: 6| Step: 10
Training loss: 0.364846795797348
Validation loss: 1.7369976415429065

Epoch: 6| Step: 11
Training loss: 0.25753360986709595
Validation loss: 1.7602004851064375

Epoch: 6| Step: 12
Training loss: 0.3274838328361511
Validation loss: 1.7390889403640584

Epoch: 6| Step: 13
Training loss: 0.24154292047023773
Validation loss: 1.7118072586674844

Epoch: 345| Step: 0
Training loss: 0.33149540424346924
Validation loss: 1.7270019028776435

Epoch: 6| Step: 1
Training loss: 0.4200190305709839
Validation loss: 1.7235759778689312

Epoch: 6| Step: 2
Training loss: 0.3557038903236389
Validation loss: 1.7066167182819818

Epoch: 6| Step: 3
Training loss: 0.505272626876831
Validation loss: 1.739595700335759

Epoch: 6| Step: 4
Training loss: 0.2542811930179596
Validation loss: 1.733370647635511

Epoch: 6| Step: 5
Training loss: 0.4166985750198364
Validation loss: 1.7244857383030716

Epoch: 6| Step: 6
Training loss: 0.30552729964256287
Validation loss: 1.7129530791313416

Epoch: 6| Step: 7
Training loss: 0.16090355813503265
Validation loss: 1.7276880407846102

Epoch: 6| Step: 8
Training loss: 0.1527136266231537
Validation loss: 1.751849453936341

Epoch: 6| Step: 9
Training loss: 0.511182427406311
Validation loss: 1.7248738452952395

Epoch: 6| Step: 10
Training loss: 0.26051971316337585
Validation loss: 1.7187270425981092

Epoch: 6| Step: 11
Training loss: 0.6448850631713867
Validation loss: 1.7603975117847483

Epoch: 6| Step: 12
Training loss: 0.23580966889858246
Validation loss: 1.7101915139023975

Epoch: 6| Step: 13
Training loss: 0.33232390880584717
Validation loss: 1.7611846718736874

Epoch: 346| Step: 0
Training loss: 0.27522674202919006
Validation loss: 1.7420402752455844

Epoch: 6| Step: 1
Training loss: 0.3387603163719177
Validation loss: 1.778418771682247

Epoch: 6| Step: 2
Training loss: 0.3030717372894287
Validation loss: 1.770282901743407

Epoch: 6| Step: 3
Training loss: 0.28789210319519043
Validation loss: 1.789293393012016

Epoch: 6| Step: 4
Training loss: 0.4978524148464203
Validation loss: 1.7593951558554044

Epoch: 6| Step: 5
Training loss: 0.3446125388145447
Validation loss: 1.7807636517350391

Epoch: 6| Step: 6
Training loss: 0.373961478471756
Validation loss: 1.7902681148180397

Epoch: 6| Step: 7
Training loss: 0.48721545934677124
Validation loss: 1.7750212210480885

Epoch: 6| Step: 8
Training loss: 0.365913987159729
Validation loss: 1.7998214947280062

Epoch: 6| Step: 9
Training loss: 0.3588773310184479
Validation loss: 1.7929681321626068

Epoch: 6| Step: 10
Training loss: 0.1627996563911438
Validation loss: 1.782198977726762

Epoch: 6| Step: 11
Training loss: 0.16907623410224915
Validation loss: 1.8036276050793227

Epoch: 6| Step: 12
Training loss: 0.5508835315704346
Validation loss: 1.7983035195258357

Epoch: 6| Step: 13
Training loss: 0.2335088551044464
Validation loss: 1.8066916683668732

Epoch: 347| Step: 0
Training loss: 0.30785438418388367
Validation loss: 1.795819317140887

Epoch: 6| Step: 1
Training loss: 0.5981603860855103
Validation loss: 1.7699753981764599

Epoch: 6| Step: 2
Training loss: 0.2843701243400574
Validation loss: 1.7795340579043153

Epoch: 6| Step: 3
Training loss: 0.17021015286445618
Validation loss: 1.7866114954794607

Epoch: 6| Step: 4
Training loss: 0.47712743282318115
Validation loss: 1.7530599896625807

Epoch: 6| Step: 5
Training loss: 0.3891657590866089
Validation loss: 1.7780014840505456

Epoch: 6| Step: 6
Training loss: 0.42742711305618286
Validation loss: 1.7269928314352547

Epoch: 6| Step: 7
Training loss: 0.3843906819820404
Validation loss: 1.7620975048311296

Epoch: 6| Step: 8
Training loss: 0.12299086898565292
Validation loss: 1.6957952617317118

Epoch: 6| Step: 9
Training loss: 0.4164692163467407
Validation loss: 1.739835803226758

Epoch: 6| Step: 10
Training loss: 0.2268415093421936
Validation loss: 1.7054187085038872

Epoch: 6| Step: 11
Training loss: 0.3057759404182434
Validation loss: 1.7371514356264504

Epoch: 6| Step: 12
Training loss: 0.30264103412628174
Validation loss: 1.7268286135888868

Epoch: 6| Step: 13
Training loss: 0.5590829849243164
Validation loss: 1.7154970412613244

Epoch: 348| Step: 0
Training loss: 0.2675836980342865
Validation loss: 1.7483570293713642

Epoch: 6| Step: 1
Training loss: 0.3574067950248718
Validation loss: 1.7072467906500703

Epoch: 6| Step: 2
Training loss: 0.22896620631217957
Validation loss: 1.7337827644040507

Epoch: 6| Step: 3
Training loss: 0.09688177704811096
Validation loss: 1.7367585679536224

Epoch: 6| Step: 4
Training loss: 0.45737606287002563
Validation loss: 1.7568888369426932

Epoch: 6| Step: 5
Training loss: 0.10925064980983734
Validation loss: 1.763751329914216

Epoch: 6| Step: 6
Training loss: 0.38985687494277954
Validation loss: 1.7783937300405195

Epoch: 6| Step: 7
Training loss: 0.64755779504776
Validation loss: 1.7947344779968262

Epoch: 6| Step: 8
Training loss: 0.2258657068014145
Validation loss: 1.7840039717253817

Epoch: 6| Step: 9
Training loss: 0.47662755846977234
Validation loss: 1.787248775523196

Epoch: 6| Step: 10
Training loss: 0.3483161926269531
Validation loss: 1.7982821092810681

Epoch: 6| Step: 11
Training loss: 0.48675745725631714
Validation loss: 1.7812117786817654

Epoch: 6| Step: 12
Training loss: 0.376921147108078
Validation loss: 1.7595004215035388

Epoch: 6| Step: 13
Training loss: 0.46910613775253296
Validation loss: 1.756870965803823

Epoch: 349| Step: 0
Training loss: 0.283832848072052
Validation loss: 1.7342999763386224

Epoch: 6| Step: 1
Training loss: 0.37460824847221375
Validation loss: 1.7475975841604254

Epoch: 6| Step: 2
Training loss: 0.5280249714851379
Validation loss: 1.7303835192034323

Epoch: 6| Step: 3
Training loss: 0.32018744945526123
Validation loss: 1.7690369288126628

Epoch: 6| Step: 4
Training loss: 0.25734609365463257
Validation loss: 1.7821703598063479

Epoch: 6| Step: 5
Training loss: 0.2557953894138336
Validation loss: 1.7724488819799116

Epoch: 6| Step: 6
Training loss: 0.27499040961265564
Validation loss: 1.7747075262890066

Epoch: 6| Step: 7
Training loss: 0.349109411239624
Validation loss: 1.8010701633268786

Epoch: 6| Step: 8
Training loss: 0.3232031464576721
Validation loss: 1.7874758064105947

Epoch: 6| Step: 9
Training loss: 0.5701504349708557
Validation loss: 1.7664523457968107

Epoch: 6| Step: 10
Training loss: 0.40107232332229614
Validation loss: 1.740889669746481

Epoch: 6| Step: 11
Training loss: 0.3279605507850647
Validation loss: 1.7148470763237245

Epoch: 6| Step: 12
Training loss: 0.2637398838996887
Validation loss: 1.7591297549586142

Epoch: 6| Step: 13
Training loss: 0.19150620698928833
Validation loss: 1.7189680171269242

Epoch: 350| Step: 0
Training loss: 0.5811569690704346
Validation loss: 1.7289635366009128

Epoch: 6| Step: 1
Training loss: 0.2842715382575989
Validation loss: 1.7324239297579693

Epoch: 6| Step: 2
Training loss: 0.345604807138443
Validation loss: 1.7109016269765875

Epoch: 6| Step: 3
Training loss: 0.2615223526954651
Validation loss: 1.712094098009089

Epoch: 6| Step: 4
Training loss: 0.2948225140571594
Validation loss: 1.7510980572751773

Epoch: 6| Step: 5
Training loss: 0.3328756093978882
Validation loss: 1.767435376362134

Epoch: 6| Step: 6
Training loss: 0.5299190282821655
Validation loss: 1.7861919056984685

Epoch: 6| Step: 7
Training loss: 0.3586656451225281
Validation loss: 1.7330997964387298

Epoch: 6| Step: 8
Training loss: 0.23608608543872833
Validation loss: 1.7526777880166167

Epoch: 6| Step: 9
Training loss: 0.34271737933158875
Validation loss: 1.733800967534383

Epoch: 6| Step: 10
Training loss: 0.2326134294271469
Validation loss: 1.7696309179388068

Epoch: 6| Step: 11
Training loss: 0.45744723081588745
Validation loss: 1.7593380507602487

Epoch: 6| Step: 12
Training loss: 0.3200242817401886
Validation loss: 1.7292595473668908

Epoch: 6| Step: 13
Training loss: 0.5920487642288208
Validation loss: 1.76258764343877

Epoch: 351| Step: 0
Training loss: 0.32594913244247437
Validation loss: 1.7694460550944011

Epoch: 6| Step: 1
Training loss: 0.15347303450107574
Validation loss: 1.779928788062065

Epoch: 6| Step: 2
Training loss: 0.1754664182662964
Validation loss: 1.7824893677106468

Epoch: 6| Step: 3
Training loss: 0.42277902364730835
Validation loss: 1.7518912476878012

Epoch: 6| Step: 4
Training loss: 0.5500686168670654
Validation loss: 1.7461785065230502

Epoch: 6| Step: 5
Training loss: 0.3231355547904968
Validation loss: 1.7455471741255892

Epoch: 6| Step: 6
Training loss: 0.25615382194519043
Validation loss: 1.7335563654540687

Epoch: 6| Step: 7
Training loss: 0.3417769968509674
Validation loss: 1.6967782038514332

Epoch: 6| Step: 8
Training loss: 0.43174809217453003
Validation loss: 1.7127076759133288

Epoch: 6| Step: 9
Training loss: 0.413340300321579
Validation loss: 1.6930297049142982

Epoch: 6| Step: 10
Training loss: 0.3180983066558838
Validation loss: 1.7117487435699792

Epoch: 6| Step: 11
Training loss: 0.3298659324645996
Validation loss: 1.7108200096314954

Epoch: 6| Step: 12
Training loss: 0.323217511177063
Validation loss: 1.7163702928891746

Epoch: 6| Step: 13
Training loss: 0.3195759654045105
Validation loss: 1.7044306621756604

Epoch: 352| Step: 0
Training loss: 0.40008437633514404
Validation loss: 1.6928608622602237

Epoch: 6| Step: 1
Training loss: 0.400486558675766
Validation loss: 1.6753112410986295

Epoch: 6| Step: 2
Training loss: 0.3287367820739746
Validation loss: 1.711054878850137

Epoch: 6| Step: 3
Training loss: 0.18105515837669373
Validation loss: 1.7240298704434467

Epoch: 6| Step: 4
Training loss: 0.2979790270328522
Validation loss: 1.7270857416173464

Epoch: 6| Step: 5
Training loss: 0.1805843710899353
Validation loss: 1.746093406472155

Epoch: 6| Step: 6
Training loss: 0.26961690187454224
Validation loss: 1.7538139217643327

Epoch: 6| Step: 7
Training loss: 0.4476976990699768
Validation loss: 1.71856645102142

Epoch: 6| Step: 8
Training loss: 0.3723883628845215
Validation loss: 1.7227116451468518

Epoch: 6| Step: 9
Training loss: 0.5047504305839539
Validation loss: 1.7356179811621224

Epoch: 6| Step: 10
Training loss: 0.346307635307312
Validation loss: 1.7318042837163454

Epoch: 6| Step: 11
Training loss: 0.39157646894454956
Validation loss: 1.7314033117345584

Epoch: 6| Step: 12
Training loss: 0.3882170617580414
Validation loss: 1.7215517349140619

Epoch: 6| Step: 13
Training loss: 0.22788125276565552
Validation loss: 1.7458672831135411

Epoch: 353| Step: 0
Training loss: 0.6599693298339844
Validation loss: 1.7205437152616438

Epoch: 6| Step: 1
Training loss: 0.2920905351638794
Validation loss: 1.704816085036083

Epoch: 6| Step: 2
Training loss: 0.3322179913520813
Validation loss: 1.750822469752322

Epoch: 6| Step: 3
Training loss: 0.4093337655067444
Validation loss: 1.73517091812626

Epoch: 6| Step: 4
Training loss: 0.41781020164489746
Validation loss: 1.7320764705698977

Epoch: 6| Step: 5
Training loss: 0.3102289140224457
Validation loss: 1.7017180791465185

Epoch: 6| Step: 6
Training loss: 0.20729640126228333
Validation loss: 1.7324151274978474

Epoch: 6| Step: 7
Training loss: 0.3173949718475342
Validation loss: 1.7012805528538202

Epoch: 6| Step: 8
Training loss: 0.3148304522037506
Validation loss: 1.6922992121788762

Epoch: 6| Step: 9
Training loss: 0.3262255787849426
Validation loss: 1.7011544896710304

Epoch: 6| Step: 10
Training loss: 0.2369164526462555
Validation loss: 1.7242791498861005

Epoch: 6| Step: 11
Training loss: 0.16909849643707275
Validation loss: 1.7022671289341424

Epoch: 6| Step: 12
Training loss: 0.3884474039077759
Validation loss: 1.7147729166092411

Epoch: 6| Step: 13
Training loss: 0.4640412926673889
Validation loss: 1.7094090061803018

Epoch: 354| Step: 0
Training loss: 0.41245806217193604
Validation loss: 1.7239262839799285

Epoch: 6| Step: 1
Training loss: 0.2505550980567932
Validation loss: 1.74417685116491

Epoch: 6| Step: 2
Training loss: 0.20796692371368408
Validation loss: 1.7431465541162798

Epoch: 6| Step: 3
Training loss: 0.4917513430118561
Validation loss: 1.760987126699058

Epoch: 6| Step: 4
Training loss: 0.520923912525177
Validation loss: 1.7650385774591917

Epoch: 6| Step: 5
Training loss: 0.3394618034362793
Validation loss: 1.7557270091067079

Epoch: 6| Step: 6
Training loss: 0.30863291025161743
Validation loss: 1.7630353576393538

Epoch: 6| Step: 7
Training loss: 0.4793042838573456
Validation loss: 1.7263003241631292

Epoch: 6| Step: 8
Training loss: 0.1390562504529953
Validation loss: 1.7599181500814294

Epoch: 6| Step: 9
Training loss: 0.29684555530548096
Validation loss: 1.738131622473399

Epoch: 6| Step: 10
Training loss: 0.23789478838443756
Validation loss: 1.7274347146352131

Epoch: 6| Step: 11
Training loss: 0.22636720538139343
Validation loss: 1.733018877685711

Epoch: 6| Step: 12
Training loss: 0.3204464316368103
Validation loss: 1.7423540110229163

Epoch: 6| Step: 13
Training loss: 0.41278424859046936
Validation loss: 1.7416745526816255

Epoch: 355| Step: 0
Training loss: 0.5166151523590088
Validation loss: 1.7321784009215653

Epoch: 6| Step: 1
Training loss: 0.2753888964653015
Validation loss: 1.6846368441017725

Epoch: 6| Step: 2
Training loss: 0.17911319434642792
Validation loss: 1.6926841043656873

Epoch: 6| Step: 3
Training loss: 0.2086842805147171
Validation loss: 1.6791361172993977

Epoch: 6| Step: 4
Training loss: 0.3712429404258728
Validation loss: 1.6873707745664863

Epoch: 6| Step: 5
Training loss: 0.35147884488105774
Validation loss: 1.6925618366528583

Epoch: 6| Step: 6
Training loss: 0.36136341094970703
Validation loss: 1.7024430510818318

Epoch: 6| Step: 7
Training loss: 0.28816941380500793
Validation loss: 1.65569515638454

Epoch: 6| Step: 8
Training loss: 0.20736640691757202
Validation loss: 1.681915634421892

Epoch: 6| Step: 9
Training loss: 0.23838159441947937
Validation loss: 1.6979570824612853

Epoch: 6| Step: 10
Training loss: 0.44652628898620605
Validation loss: 1.6912033903983332

Epoch: 6| Step: 11
Training loss: 0.3197215795516968
Validation loss: 1.657252924416655

Epoch: 6| Step: 12
Training loss: 0.3598794937133789
Validation loss: 1.688421210935039

Epoch: 6| Step: 13
Training loss: 0.20084248483181
Validation loss: 1.6969616387480049

Epoch: 356| Step: 0
Training loss: 0.24909429252147675
Validation loss: 1.711352095809034

Epoch: 6| Step: 1
Training loss: 0.19634467363357544
Validation loss: 1.7121839087496522

Epoch: 6| Step: 2
Training loss: 0.36404603719711304
Validation loss: 1.7176411139067782

Epoch: 6| Step: 3
Training loss: 0.22849208116531372
Validation loss: 1.7233751076523975

Epoch: 6| Step: 4
Training loss: 0.3764035701751709
Validation loss: 1.7134009330503401

Epoch: 6| Step: 5
Training loss: 0.43740418553352356
Validation loss: 1.7061048041107834

Epoch: 6| Step: 6
Training loss: 0.2120698094367981
Validation loss: 1.7163252920232794

Epoch: 6| Step: 7
Training loss: 0.15310943126678467
Validation loss: 1.7167483786100983

Epoch: 6| Step: 8
Training loss: 0.5295923948287964
Validation loss: 1.7287522554397583

Epoch: 6| Step: 9
Training loss: 0.24074611067771912
Validation loss: 1.7220942025543542

Epoch: 6| Step: 10
Training loss: 0.19885194301605225
Validation loss: 1.741913636525472

Epoch: 6| Step: 11
Training loss: 0.2911033034324646
Validation loss: 1.7158695741366314

Epoch: 6| Step: 12
Training loss: 0.14534060657024384
Validation loss: 1.7420916275311542

Epoch: 6| Step: 13
Training loss: 0.447827011346817
Validation loss: 1.72293125173097

Epoch: 357| Step: 0
Training loss: 0.22658121585845947
Validation loss: 1.6938546447343723

Epoch: 6| Step: 1
Training loss: 0.49254143238067627
Validation loss: 1.7412239979672175

Epoch: 6| Step: 2
Training loss: 0.16254201531410217
Validation loss: 1.73801968302778

Epoch: 6| Step: 3
Training loss: 0.3999131917953491
Validation loss: 1.7220950870103733

Epoch: 6| Step: 4
Training loss: 0.5922836661338806
Validation loss: 1.7082884350130636

Epoch: 6| Step: 5
Training loss: 0.17700569331645966
Validation loss: 1.7262563859262774

Epoch: 6| Step: 6
Training loss: 0.33497798442840576
Validation loss: 1.7212101092902563

Epoch: 6| Step: 7
Training loss: 0.3166520297527313
Validation loss: 1.7127235935580345

Epoch: 6| Step: 8
Training loss: 0.239396870136261
Validation loss: 1.7205679365383681

Epoch: 6| Step: 9
Training loss: 0.35354578495025635
Validation loss: 1.7273904969615321

Epoch: 6| Step: 10
Training loss: 0.33482158184051514
Validation loss: 1.7425459405427337

Epoch: 6| Step: 11
Training loss: 0.29715684056282043
Validation loss: 1.7341605078789495

Epoch: 6| Step: 12
Training loss: 0.14642973244190216
Validation loss: 1.7609356616133003

Epoch: 6| Step: 13
Training loss: 0.29152584075927734
Validation loss: 1.7462690978921869

Epoch: 358| Step: 0
Training loss: 0.37234872579574585
Validation loss: 1.7024661699930828

Epoch: 6| Step: 1
Training loss: 0.2852567434310913
Validation loss: 1.740137259165446

Epoch: 6| Step: 2
Training loss: 0.41211196780204773
Validation loss: 1.7239423669794554

Epoch: 6| Step: 3
Training loss: 0.21389979124069214
Validation loss: 1.722704279807306

Epoch: 6| Step: 4
Training loss: 0.22993063926696777
Validation loss: 1.7203806843808902

Epoch: 6| Step: 5
Training loss: 0.19281287491321564
Validation loss: 1.7099803314414075

Epoch: 6| Step: 6
Training loss: 0.37612468004226685
Validation loss: 1.7607392534132926

Epoch: 6| Step: 7
Training loss: 0.4337112307548523
Validation loss: 1.723500491470419

Epoch: 6| Step: 8
Training loss: 0.3457798659801483
Validation loss: 1.7520214203865296

Epoch: 6| Step: 9
Training loss: 0.38635462522506714
Validation loss: 1.7460874178076302

Epoch: 6| Step: 10
Training loss: 0.30029088258743286
Validation loss: 1.7638449989339358

Epoch: 6| Step: 11
Training loss: 0.3114861845970154
Validation loss: 1.7442854578777025

Epoch: 6| Step: 12
Training loss: 0.28085556626319885
Validation loss: 1.7520191413100048

Epoch: 6| Step: 13
Training loss: 0.21093827486038208
Validation loss: 1.737125999184065

Epoch: 359| Step: 0
Training loss: 0.4793075919151306
Validation loss: 1.7242603866002892

Epoch: 6| Step: 1
Training loss: 0.20597568154335022
Validation loss: 1.7052713312128538

Epoch: 6| Step: 2
Training loss: 0.302162766456604
Validation loss: 1.7102197024130052

Epoch: 6| Step: 3
Training loss: 0.44126296043395996
Validation loss: 1.7275222693720171

Epoch: 6| Step: 4
Training loss: 0.23371414840221405
Validation loss: 1.708387477423555

Epoch: 6| Step: 5
Training loss: 0.14148414134979248
Validation loss: 1.7217958255480694

Epoch: 6| Step: 6
Training loss: 0.29800206422805786
Validation loss: 1.7085538987190492

Epoch: 6| Step: 7
Training loss: 0.23206953704357147
Validation loss: 1.6991340883316532

Epoch: 6| Step: 8
Training loss: 0.45147374272346497
Validation loss: 1.7083469501105688

Epoch: 6| Step: 9
Training loss: 0.19942578673362732
Validation loss: 1.6952334039954728

Epoch: 6| Step: 10
Training loss: 0.4585927128791809
Validation loss: 1.732906582534954

Epoch: 6| Step: 11
Training loss: 0.283433198928833
Validation loss: 1.7232464321198002

Epoch: 6| Step: 12
Training loss: 0.25320425629615784
Validation loss: 1.6963124454662364

Epoch: 6| Step: 13
Training loss: 0.2581436336040497
Validation loss: 1.679416723148797

Epoch: 360| Step: 0
Training loss: 0.24350906908512115
Validation loss: 1.6814113413133929

Epoch: 6| Step: 1
Training loss: 0.47836053371429443
Validation loss: 1.6605069970571866

Epoch: 6| Step: 2
Training loss: 0.5231836438179016
Validation loss: 1.6622182605087117

Epoch: 6| Step: 3
Training loss: 0.4185824692249298
Validation loss: 1.6861607105501237

Epoch: 6| Step: 4
Training loss: 0.2732839584350586
Validation loss: 1.6851415762337305

Epoch: 6| Step: 5
Training loss: 0.24879109859466553
Validation loss: 1.6852185623620146

Epoch: 6| Step: 6
Training loss: 0.278370201587677
Validation loss: 1.6996842379211097

Epoch: 6| Step: 7
Training loss: 0.18543656170368195
Validation loss: 1.7079946123143679

Epoch: 6| Step: 8
Training loss: 0.25963079929351807
Validation loss: 1.6915654815653318

Epoch: 6| Step: 9
Training loss: 0.40159860253334045
Validation loss: 1.6863552549833893

Epoch: 6| Step: 10
Training loss: 0.24655850231647491
Validation loss: 1.7265482538489885

Epoch: 6| Step: 11
Training loss: 0.21062493324279785
Validation loss: 1.6994220441387546

Epoch: 6| Step: 12
Training loss: 0.24362698197364807
Validation loss: 1.7446472426896453

Epoch: 6| Step: 13
Training loss: 0.26287201046943665
Validation loss: 1.7074701760404853

Epoch: 361| Step: 0
Training loss: 0.23182937502861023
Validation loss: 1.6965829249351256

Epoch: 6| Step: 1
Training loss: 0.30827242136001587
Validation loss: 1.6858206923289965

Epoch: 6| Step: 2
Training loss: 0.4410136938095093
Validation loss: 1.7409925024996522

Epoch: 6| Step: 3
Training loss: 0.32543930411338806
Validation loss: 1.720960682438266

Epoch: 6| Step: 4
Training loss: 0.1667720079421997
Validation loss: 1.6948278232287335

Epoch: 6| Step: 5
Training loss: 0.23540723323822021
Validation loss: 1.694236070879044

Epoch: 6| Step: 6
Training loss: 0.3036498427391052
Validation loss: 1.6912186235509894

Epoch: 6| Step: 7
Training loss: 0.3519408106803894
Validation loss: 1.7306554714838664

Epoch: 6| Step: 8
Training loss: 0.18555885553359985
Validation loss: 1.714108722184294

Epoch: 6| Step: 9
Training loss: 0.3940284848213196
Validation loss: 1.7399534974046933

Epoch: 6| Step: 10
Training loss: 0.19737106561660767
Validation loss: 1.7123866606784124

Epoch: 6| Step: 11
Training loss: 0.3680475950241089
Validation loss: 1.7544371504937448

Epoch: 6| Step: 12
Training loss: 0.23734979331493378
Validation loss: 1.7466470297946726

Epoch: 6| Step: 13
Training loss: 0.12982940673828125
Validation loss: 1.7648146216587355

Epoch: 362| Step: 0
Training loss: 0.35562393069267273
Validation loss: 1.6938891116008963

Epoch: 6| Step: 1
Training loss: 0.3587687313556671
Validation loss: 1.6973084852259646

Epoch: 6| Step: 2
Training loss: 0.1563018560409546
Validation loss: 1.681491518533358

Epoch: 6| Step: 3
Training loss: 0.22718048095703125
Validation loss: 1.6796723411929222

Epoch: 6| Step: 4
Training loss: 0.28567421436309814
Validation loss: 1.6826456669838197

Epoch: 6| Step: 5
Training loss: 0.3689364790916443
Validation loss: 1.688696551066573

Epoch: 6| Step: 6
Training loss: 0.4520312547683716
Validation loss: 1.6861712676222607

Epoch: 6| Step: 7
Training loss: 0.20839360356330872
Validation loss: 1.7044034145211662

Epoch: 6| Step: 8
Training loss: 0.36964285373687744
Validation loss: 1.6900730838057816

Epoch: 6| Step: 9
Training loss: 0.3191167116165161
Validation loss: 1.7077948380542058

Epoch: 6| Step: 10
Training loss: 0.40040820837020874
Validation loss: 1.6778406058588335

Epoch: 6| Step: 11
Training loss: 0.24337857961654663
Validation loss: 1.7082238504963536

Epoch: 6| Step: 12
Training loss: 0.2182382047176361
Validation loss: 1.689954093707505

Epoch: 6| Step: 13
Training loss: 0.353744238615036
Validation loss: 1.6986655291690622

Epoch: 363| Step: 0
Training loss: 0.28287696838378906
Validation loss: 1.6662162196251653

Epoch: 6| Step: 1
Training loss: 0.1619034707546234
Validation loss: 1.6671951919473627

Epoch: 6| Step: 2
Training loss: 0.46492502093315125
Validation loss: 1.7011752936147875

Epoch: 6| Step: 3
Training loss: 0.17591117322444916
Validation loss: 1.718565733202042

Epoch: 6| Step: 4
Training loss: 0.3721825182437897
Validation loss: 1.7263271013895671

Epoch: 6| Step: 5
Training loss: 0.3118450939655304
Validation loss: 1.7384210209692679

Epoch: 6| Step: 6
Training loss: 0.2738451361656189
Validation loss: 1.7384906315034436

Epoch: 6| Step: 7
Training loss: 0.4350217282772064
Validation loss: 1.7485491819279169

Epoch: 6| Step: 8
Training loss: 0.1144208088517189
Validation loss: 1.7349774734948271

Epoch: 6| Step: 9
Training loss: 0.25172147154808044
Validation loss: 1.7252286313682474

Epoch: 6| Step: 10
Training loss: 0.35738569498062134
Validation loss: 1.744849919631917

Epoch: 6| Step: 11
Training loss: 0.6285088658332825
Validation loss: 1.740679676814746

Epoch: 6| Step: 12
Training loss: 0.07657354325056076
Validation loss: 1.7380973267298874

Epoch: 6| Step: 13
Training loss: 0.22256016731262207
Validation loss: 1.7104354462315958

Epoch: 364| Step: 0
Training loss: 0.25969550013542175
Validation loss: 1.7314320379687893

Epoch: 6| Step: 1
Training loss: 0.25487321615219116
Validation loss: 1.6898251861654303

Epoch: 6| Step: 2
Training loss: 0.25478917360305786
Validation loss: 1.7068790005099388

Epoch: 6| Step: 3
Training loss: 0.2757088541984558
Validation loss: 1.7183846228866166

Epoch: 6| Step: 4
Training loss: 0.45357340574264526
Validation loss: 1.7409279596421026

Epoch: 6| Step: 5
Training loss: 0.25514960289001465
Validation loss: 1.7209541336182625

Epoch: 6| Step: 6
Training loss: 0.18456603586673737
Validation loss: 1.7340078584609493

Epoch: 6| Step: 7
Training loss: 0.31057727336883545
Validation loss: 1.6952319260566466

Epoch: 6| Step: 8
Training loss: 0.2517024278640747
Validation loss: 1.7460522446581113

Epoch: 6| Step: 9
Training loss: 0.6317127346992493
Validation loss: 1.706904431825043

Epoch: 6| Step: 10
Training loss: 0.3970743417739868
Validation loss: 1.6928138194545623

Epoch: 6| Step: 11
Training loss: 0.18636050820350647
Validation loss: 1.6877987359159736

Epoch: 6| Step: 12
Training loss: 0.5139192342758179
Validation loss: 1.7020708412252448

Epoch: 6| Step: 13
Training loss: 0.2719631791114807
Validation loss: 1.7085853084441154

Epoch: 365| Step: 0
Training loss: 0.29889458417892456
Validation loss: 1.6950134820835565

Epoch: 6| Step: 1
Training loss: 0.5233108997344971
Validation loss: 1.726758606972233

Epoch: 6| Step: 2
Training loss: 0.3670033812522888
Validation loss: 1.753341720950219

Epoch: 6| Step: 3
Training loss: 0.3435419201850891
Validation loss: 1.7417890256451023

Epoch: 6| Step: 4
Training loss: 0.16989201307296753
Validation loss: 1.7430454197750296

Epoch: 6| Step: 5
Training loss: 0.24892178177833557
Validation loss: 1.7396180193911317

Epoch: 6| Step: 6
Training loss: 0.36810624599456787
Validation loss: 1.7288991815300399

Epoch: 6| Step: 7
Training loss: 0.403494268655777
Validation loss: 1.6845634547613

Epoch: 6| Step: 8
Training loss: 0.3066485524177551
Validation loss: 1.695196528588572

Epoch: 6| Step: 9
Training loss: 0.36033016443252563
Validation loss: 1.6995859646028089

Epoch: 6| Step: 10
Training loss: 0.46117085218429565
Validation loss: 1.6870807101649623

Epoch: 6| Step: 11
Training loss: 0.3815324008464813
Validation loss: 1.6768912640951013

Epoch: 6| Step: 12
Training loss: 0.4178709387779236
Validation loss: 1.6639682336520123

Epoch: 6| Step: 13
Training loss: 0.33514460921287537
Validation loss: 1.6939334190019997

Epoch: 366| Step: 0
Training loss: 0.44378772377967834
Validation loss: 1.6808029656769128

Epoch: 6| Step: 1
Training loss: 0.333817720413208
Validation loss: 1.718201889786669

Epoch: 6| Step: 2
Training loss: 0.3381287753582001
Validation loss: 1.6805526428325201

Epoch: 6| Step: 3
Training loss: 0.2734268307685852
Validation loss: 1.7028511813891831

Epoch: 6| Step: 4
Training loss: 0.227064311504364
Validation loss: 1.681596484235538

Epoch: 6| Step: 5
Training loss: 0.2952895164489746
Validation loss: 1.730085939489385

Epoch: 6| Step: 6
Training loss: 0.3202737867832184
Validation loss: 1.7274109996775144

Epoch: 6| Step: 7
Training loss: 0.13803550601005554
Validation loss: 1.6938261203868414

Epoch: 6| Step: 8
Training loss: 0.30542492866516113
Validation loss: 1.7266963886958298

Epoch: 6| Step: 9
Training loss: 0.37689220905303955
Validation loss: 1.7449599107106526

Epoch: 6| Step: 10
Training loss: 0.4052908420562744
Validation loss: 1.7280004280869679

Epoch: 6| Step: 11
Training loss: 0.3297978937625885
Validation loss: 1.7324480856618574

Epoch: 6| Step: 12
Training loss: 0.37256309390068054
Validation loss: 1.7144127648363832

Epoch: 6| Step: 13
Training loss: 0.38935205340385437
Validation loss: 1.7186677859675499

Epoch: 367| Step: 0
Training loss: 0.23568248748779297
Validation loss: 1.7191736493059384

Epoch: 6| Step: 1
Training loss: 0.1518370509147644
Validation loss: 1.7288438081741333

Epoch: 6| Step: 2
Training loss: 0.5259464979171753
Validation loss: 1.754036921326832

Epoch: 6| Step: 3
Training loss: 0.24947002530097961
Validation loss: 1.762344075787452

Epoch: 6| Step: 4
Training loss: 0.27763497829437256
Validation loss: 1.754006112775495

Epoch: 6| Step: 5
Training loss: 0.19095098972320557
Validation loss: 1.71901148749936

Epoch: 6| Step: 6
Training loss: 0.27892351150512695
Validation loss: 1.7212173426023094

Epoch: 6| Step: 7
Training loss: 0.26461830735206604
Validation loss: 1.7307696316831855

Epoch: 6| Step: 8
Training loss: 0.23885157704353333
Validation loss: 1.739696466794578

Epoch: 6| Step: 9
Training loss: 0.16996760666370392
Validation loss: 1.728114757486569

Epoch: 6| Step: 10
Training loss: 0.4918946325778961
Validation loss: 1.7299216126882901

Epoch: 6| Step: 11
Training loss: 0.20241224765777588
Validation loss: 1.7065871428417903

Epoch: 6| Step: 12
Training loss: 0.3515777885913849
Validation loss: 1.7110874447771298

Epoch: 6| Step: 13
Training loss: 0.45308515429496765
Validation loss: 1.6947814533787389

Epoch: 368| Step: 0
Training loss: 0.29369425773620605
Validation loss: 1.6851346005675614

Epoch: 6| Step: 1
Training loss: 0.3456837832927704
Validation loss: 1.6729933484908073

Epoch: 6| Step: 2
Training loss: 0.2776154577732086
Validation loss: 1.6593402252402356

Epoch: 6| Step: 3
Training loss: 0.24413758516311646
Validation loss: 1.695740871531989

Epoch: 6| Step: 4
Training loss: 0.288141131401062
Validation loss: 1.7160172359917754

Epoch: 6| Step: 5
Training loss: 0.30270588397979736
Validation loss: 1.6984005141001877

Epoch: 6| Step: 6
Training loss: 0.44548600912094116
Validation loss: 1.7135725662272463

Epoch: 6| Step: 7
Training loss: 0.35447049140930176
Validation loss: 1.7306948169585197

Epoch: 6| Step: 8
Training loss: 0.3277748227119446
Validation loss: 1.737288293018136

Epoch: 6| Step: 9
Training loss: 0.29403790831565857
Validation loss: 1.7835229314783567

Epoch: 6| Step: 10
Training loss: 0.23873336613178253
Validation loss: 1.7878453398263583

Epoch: 6| Step: 11
Training loss: 0.5010278224945068
Validation loss: 1.7913560803218553

Epoch: 6| Step: 12
Training loss: 0.3757287859916687
Validation loss: 1.8273347398286224

Epoch: 6| Step: 13
Training loss: 0.20239078998565674
Validation loss: 1.8349357997217486

Epoch: 369| Step: 0
Training loss: 0.41824159026145935
Validation loss: 1.823685916521216

Epoch: 6| Step: 1
Training loss: 0.24677616357803345
Validation loss: 1.8081600018726882

Epoch: 6| Step: 2
Training loss: 0.25170624256134033
Validation loss: 1.7773475980245939

Epoch: 6| Step: 3
Training loss: 0.42301368713378906
Validation loss: 1.7466461273931688

Epoch: 6| Step: 4
Training loss: 0.3671441078186035
Validation loss: 1.773429193804341

Epoch: 6| Step: 5
Training loss: 0.3290520906448364
Validation loss: 1.755720438495759

Epoch: 6| Step: 6
Training loss: 0.29931581020355225
Validation loss: 1.7363505696737638

Epoch: 6| Step: 7
Training loss: 0.20034053921699524
Validation loss: 1.6982169330760997

Epoch: 6| Step: 8
Training loss: 0.3802473545074463
Validation loss: 1.7133317634623537

Epoch: 6| Step: 9
Training loss: 0.3144797682762146
Validation loss: 1.6952578713816981

Epoch: 6| Step: 10
Training loss: 0.24302585422992706
Validation loss: 1.7021106776370798

Epoch: 6| Step: 11
Training loss: 0.22334253787994385
Validation loss: 1.6876297612344064

Epoch: 6| Step: 12
Training loss: 0.5586363077163696
Validation loss: 1.6599626451410272

Epoch: 6| Step: 13
Training loss: 0.2838062047958374
Validation loss: 1.6883796556021577

Epoch: 370| Step: 0
Training loss: 0.17439989745616913
Validation loss: 1.6720916071245748

Epoch: 6| Step: 1
Training loss: 0.3347678780555725
Validation loss: 1.6966813764264506

Epoch: 6| Step: 2
Training loss: 0.2133643627166748
Validation loss: 1.6809129612420195

Epoch: 6| Step: 3
Training loss: 0.24580857157707214
Validation loss: 1.6861410692173948

Epoch: 6| Step: 4
Training loss: 0.4112221300601959
Validation loss: 1.6855219948676325

Epoch: 6| Step: 5
Training loss: 0.2717640995979309
Validation loss: 1.754947539298765

Epoch: 6| Step: 6
Training loss: 0.21597659587860107
Validation loss: 1.7217732706377584

Epoch: 6| Step: 7
Training loss: 0.2547835111618042
Validation loss: 1.7092072694532332

Epoch: 6| Step: 8
Training loss: 0.5097514390945435
Validation loss: 1.7146406109615038

Epoch: 6| Step: 9
Training loss: 0.5120772123336792
Validation loss: 1.7129856181401077

Epoch: 6| Step: 10
Training loss: 0.13096198439598083
Validation loss: 1.7316555284684705

Epoch: 6| Step: 11
Training loss: 0.22671973705291748
Validation loss: 1.7571880586685673

Epoch: 6| Step: 12
Training loss: 0.26628294587135315
Validation loss: 1.771540472584386

Epoch: 6| Step: 13
Training loss: 0.361004114151001
Validation loss: 1.7395072726793186

Epoch: 371| Step: 0
Training loss: 0.4193745255470276
Validation loss: 1.7150804855490243

Epoch: 6| Step: 1
Training loss: 0.22101916372776031
Validation loss: 1.718323717835129

Epoch: 6| Step: 2
Training loss: 0.1692919135093689
Validation loss: 1.7192057589048981

Epoch: 6| Step: 3
Training loss: 0.37093955278396606
Validation loss: 1.723714441381475

Epoch: 6| Step: 4
Training loss: 0.5903500914573669
Validation loss: 1.7339376326530211

Epoch: 6| Step: 5
Training loss: 0.4276720881462097
Validation loss: 1.7290820485802108

Epoch: 6| Step: 6
Training loss: 0.159636989235878
Validation loss: 1.7281199527043167

Epoch: 6| Step: 7
Training loss: 0.3109435439109802
Validation loss: 1.6944777401544715

Epoch: 6| Step: 8
Training loss: 0.3350693881511688
Validation loss: 1.752939703643963

Epoch: 6| Step: 9
Training loss: 0.1748427450656891
Validation loss: 1.7549728232045327

Epoch: 6| Step: 10
Training loss: 0.19602181017398834
Validation loss: 1.7461533123447048

Epoch: 6| Step: 11
Training loss: 0.3304084241390228
Validation loss: 1.7418993224379837

Epoch: 6| Step: 12
Training loss: 0.3545396327972412
Validation loss: 1.6769623807681504

Epoch: 6| Step: 13
Training loss: 0.3377424478530884
Validation loss: 1.712803861146332

Epoch: 372| Step: 0
Training loss: 0.2253335416316986
Validation loss: 1.6577001707528227

Epoch: 6| Step: 1
Training loss: 0.4943685531616211
Validation loss: 1.6903637045173234

Epoch: 6| Step: 2
Training loss: 0.4433717727661133
Validation loss: 1.6965402685185915

Epoch: 6| Step: 3
Training loss: 0.12052981555461884
Validation loss: 1.7093270453073646

Epoch: 6| Step: 4
Training loss: 0.29156649112701416
Validation loss: 1.7424296294489214

Epoch: 6| Step: 5
Training loss: 0.25832995772361755
Validation loss: 1.6928851392961317

Epoch: 6| Step: 6
Training loss: 0.12557250261306763
Validation loss: 1.720925308042957

Epoch: 6| Step: 7
Training loss: 0.2021280974149704
Validation loss: 1.7049860608193181

Epoch: 6| Step: 8
Training loss: 0.29979264736175537
Validation loss: 1.7378599156615555

Epoch: 6| Step: 9
Training loss: 0.2636833190917969
Validation loss: 1.7270822781388477

Epoch: 6| Step: 10
Training loss: 0.20080512762069702
Validation loss: 1.7095107045224918

Epoch: 6| Step: 11
Training loss: 0.21865476667881012
Validation loss: 1.6938849533757856

Epoch: 6| Step: 12
Training loss: 0.3584384620189667
Validation loss: 1.6711996383564447

Epoch: 6| Step: 13
Training loss: 0.3586432635784149
Validation loss: 1.6821064551671345

Epoch: 373| Step: 0
Training loss: 0.15531210601329803
Validation loss: 1.6845095683169622

Epoch: 6| Step: 1
Training loss: 0.24232378602027893
Validation loss: 1.665163860526136

Epoch: 6| Step: 2
Training loss: 0.2976597547531128
Validation loss: 1.6777060057527275

Epoch: 6| Step: 3
Training loss: 0.22954823076725006
Validation loss: 1.6945604855014431

Epoch: 6| Step: 4
Training loss: 0.13532117009162903
Validation loss: 1.7304298429078953

Epoch: 6| Step: 5
Training loss: 0.41745150089263916
Validation loss: 1.7090664704640706

Epoch: 6| Step: 6
Training loss: 0.5533306002616882
Validation loss: 1.735561433658805

Epoch: 6| Step: 7
Training loss: 0.1979159116744995
Validation loss: 1.7532660160013425

Epoch: 6| Step: 8
Training loss: 0.3037272095680237
Validation loss: 1.740612151802227

Epoch: 6| Step: 9
Training loss: 0.24174073338508606
Validation loss: 1.755968314345165

Epoch: 6| Step: 10
Training loss: 0.2940157651901245
Validation loss: 1.738716003715351

Epoch: 6| Step: 11
Training loss: 0.3629205822944641
Validation loss: 1.752407540557205

Epoch: 6| Step: 12
Training loss: 0.19234362244606018
Validation loss: 1.6857302317055323

Epoch: 6| Step: 13
Training loss: 0.49301984906196594
Validation loss: 1.691450834274292

Epoch: 374| Step: 0
Training loss: 0.3331519067287445
Validation loss: 1.6755846046632337

Epoch: 6| Step: 1
Training loss: 0.34220972657203674
Validation loss: 1.6686875384341004

Epoch: 6| Step: 2
Training loss: 0.3101590573787689
Validation loss: 1.6516538819959086

Epoch: 6| Step: 3
Training loss: 0.2104419469833374
Validation loss: 1.659550077171736

Epoch: 6| Step: 4
Training loss: 0.21025244891643524
Validation loss: 1.6922355236545685

Epoch: 6| Step: 5
Training loss: 0.19458694756031036
Validation loss: 1.6874849873204385

Epoch: 6| Step: 6
Training loss: 0.32504546642303467
Validation loss: 1.6857883276477936

Epoch: 6| Step: 7
Training loss: 0.28264978528022766
Validation loss: 1.7066111487727011

Epoch: 6| Step: 8
Training loss: 0.2792823910713196
Validation loss: 1.6893630540499123

Epoch: 6| Step: 9
Training loss: 0.3149235248565674
Validation loss: 1.7141362749120241

Epoch: 6| Step: 10
Training loss: 0.22909247875213623
Validation loss: 1.7010853470012706

Epoch: 6| Step: 11
Training loss: 0.2601865828037262
Validation loss: 1.7475398407187512

Epoch: 6| Step: 12
Training loss: 0.22016692161560059
Validation loss: 1.7074159601683259

Epoch: 6| Step: 13
Training loss: 0.7103704214096069
Validation loss: 1.6687274953370452

Epoch: 375| Step: 0
Training loss: 0.19710062444210052
Validation loss: 1.7043590737927345

Epoch: 6| Step: 1
Training loss: 0.22871750593185425
Validation loss: 1.7065445069343812

Epoch: 6| Step: 2
Training loss: 0.21379342675209045
Validation loss: 1.701308060717839

Epoch: 6| Step: 3
Training loss: 0.5805438756942749
Validation loss: 1.731877060346706

Epoch: 6| Step: 4
Training loss: 0.20025016367435455
Validation loss: 1.7461641552627727

Epoch: 6| Step: 5
Training loss: 0.3494333028793335
Validation loss: 1.72963253144295

Epoch: 6| Step: 6
Training loss: 0.26939675211906433
Validation loss: 1.7449950710419686

Epoch: 6| Step: 7
Training loss: 0.336991548538208
Validation loss: 1.7069963062963178

Epoch: 6| Step: 8
Training loss: 0.23772291839122772
Validation loss: 1.6765347309010004

Epoch: 6| Step: 9
Training loss: 0.28497016429901123
Validation loss: 1.6667758803213797

Epoch: 6| Step: 10
Training loss: 0.28558897972106934
Validation loss: 1.6723980583170408

Epoch: 6| Step: 11
Training loss: 0.4221397638320923
Validation loss: 1.6544385520360803

Epoch: 6| Step: 12
Training loss: 0.29496684670448303
Validation loss: 1.6633401506690568

Epoch: 6| Step: 13
Training loss: 0.18455025553703308
Validation loss: 1.645898934333555

Epoch: 376| Step: 0
Training loss: 0.2827209532260895
Validation loss: 1.6653116415905695

Epoch: 6| Step: 1
Training loss: 0.44407719373703003
Validation loss: 1.6300311473108107

Epoch: 6| Step: 2
Training loss: 0.14898619055747986
Validation loss: 1.652439965996691

Epoch: 6| Step: 3
Training loss: 0.30269813537597656
Validation loss: 1.6544862178064161

Epoch: 6| Step: 4
Training loss: 0.24144183099269867
Validation loss: 1.6714093403149677

Epoch: 6| Step: 5
Training loss: 0.19971051812171936
Validation loss: 1.6643911356567054

Epoch: 6| Step: 6
Training loss: 0.2969210743904114
Validation loss: 1.6605837088759228

Epoch: 6| Step: 7
Training loss: 0.23697429895401
Validation loss: 1.6821152292272097

Epoch: 6| Step: 8
Training loss: 0.20396706461906433
Validation loss: 1.7055195159809564

Epoch: 6| Step: 9
Training loss: 0.3255915641784668
Validation loss: 1.7187299587393319

Epoch: 6| Step: 10
Training loss: 0.4487037658691406
Validation loss: 1.7343321564376994

Epoch: 6| Step: 11
Training loss: 0.2693046033382416
Validation loss: 1.7313048275568153

Epoch: 6| Step: 12
Training loss: 0.17659246921539307
Validation loss: 1.734261264083206

Epoch: 6| Step: 13
Training loss: 0.14538894593715668
Validation loss: 1.7307820845675725

Epoch: 377| Step: 0
Training loss: 0.1938745677471161
Validation loss: 1.7256699415945238

Epoch: 6| Step: 1
Training loss: 0.380658358335495
Validation loss: 1.7268315322937504

Epoch: 6| Step: 2
Training loss: 0.29583045840263367
Validation loss: 1.7279273386924499

Epoch: 6| Step: 3
Training loss: 0.3201093375682831
Validation loss: 1.7063288316931775

Epoch: 6| Step: 4
Training loss: 0.1336476057767868
Validation loss: 1.6830022591416554

Epoch: 6| Step: 5
Training loss: 0.29490557312965393
Validation loss: 1.7028125255338606

Epoch: 6| Step: 6
Training loss: 0.27008408308029175
Validation loss: 1.7178128509111301

Epoch: 6| Step: 7
Training loss: 0.18168054521083832
Validation loss: 1.735731670933385

Epoch: 6| Step: 8
Training loss: 0.18225103616714478
Validation loss: 1.7325087926721061

Epoch: 6| Step: 9
Training loss: 0.3065435290336609
Validation loss: 1.7422697364643056

Epoch: 6| Step: 10
Training loss: 0.3238059878349304
Validation loss: 1.7335401593997914

Epoch: 6| Step: 11
Training loss: 0.22991256415843964
Validation loss: 1.7289653747312483

Epoch: 6| Step: 12
Training loss: 0.20868149399757385
Validation loss: 1.710427584186677

Epoch: 6| Step: 13
Training loss: 0.2064184695482254
Validation loss: 1.6882603796579505

Epoch: 378| Step: 0
Training loss: 0.2463071048259735
Validation loss: 1.683976133023539

Epoch: 6| Step: 1
Training loss: 0.42074084281921387
Validation loss: 1.674216631920107

Epoch: 6| Step: 2
Training loss: 0.2592707872390747
Validation loss: 1.692055925246208

Epoch: 6| Step: 3
Training loss: 0.2781186103820801
Validation loss: 1.69847071555353

Epoch: 6| Step: 4
Training loss: 0.21696212887763977
Validation loss: 1.7008422600325717

Epoch: 6| Step: 5
Training loss: 0.23354361951351166
Validation loss: 1.7068706379141858

Epoch: 6| Step: 6
Training loss: 0.2970707416534424
Validation loss: 1.738708387139023

Epoch: 6| Step: 7
Training loss: 0.22741730511188507
Validation loss: 1.7252565968421198

Epoch: 6| Step: 8
Training loss: 0.34745311737060547
Validation loss: 1.7676928902185092

Epoch: 6| Step: 9
Training loss: 0.18960081040859222
Validation loss: 1.7460822905263593

Epoch: 6| Step: 10
Training loss: 0.24533918499946594
Validation loss: 1.7243082888664738

Epoch: 6| Step: 11
Training loss: 0.24774470925331116
Validation loss: 1.7439540278527044

Epoch: 6| Step: 12
Training loss: 0.28309011459350586
Validation loss: 1.7164932207394672

Epoch: 6| Step: 13
Training loss: 0.336839884519577
Validation loss: 1.7314970429225633

Epoch: 379| Step: 0
Training loss: 0.1593836545944214
Validation loss: 1.6745636681074738

Epoch: 6| Step: 1
Training loss: 0.3840303122997284
Validation loss: 1.7165664549796813

Epoch: 6| Step: 2
Training loss: 0.3363288640975952
Validation loss: 1.688583033059233

Epoch: 6| Step: 3
Training loss: 0.25713175535202026
Validation loss: 1.6889031715290521

Epoch: 6| Step: 4
Training loss: 0.19932568073272705
Validation loss: 1.7178237489474717

Epoch: 6| Step: 5
Training loss: 0.12712030112743378
Validation loss: 1.6997404175419961

Epoch: 6| Step: 6
Training loss: 0.2367142289876938
Validation loss: 1.6894732008698166

Epoch: 6| Step: 7
Training loss: 0.22215743362903595
Validation loss: 1.6705718527558029

Epoch: 6| Step: 8
Training loss: 0.187864288687706
Validation loss: 1.6943207639519886

Epoch: 6| Step: 9
Training loss: 0.2803322672843933
Validation loss: 1.6864011851690148

Epoch: 6| Step: 10
Training loss: 0.5147637128829956
Validation loss: 1.6792060213704263

Epoch: 6| Step: 11
Training loss: 0.1636514961719513
Validation loss: 1.6671638937406643

Epoch: 6| Step: 12
Training loss: 0.18685083091259003
Validation loss: 1.6604164159426125

Epoch: 6| Step: 13
Training loss: 0.39303362369537354
Validation loss: 1.6631674035902946

Epoch: 380| Step: 0
Training loss: 0.2563568353652954
Validation loss: 1.6657308634891306

Epoch: 6| Step: 1
Training loss: 0.2532389760017395
Validation loss: 1.6566074689229329

Epoch: 6| Step: 2
Training loss: 0.2966754734516144
Validation loss: 1.6818703297645814

Epoch: 6| Step: 3
Training loss: 0.13600704073905945
Validation loss: 1.640705124024422

Epoch: 6| Step: 4
Training loss: 0.2515541911125183
Validation loss: 1.6596944703850696

Epoch: 6| Step: 5
Training loss: 0.13788075745105743
Validation loss: 1.674578917923794

Epoch: 6| Step: 6
Training loss: 0.13047409057617188
Validation loss: 1.6874298331558064

Epoch: 6| Step: 7
Training loss: 0.22457575798034668
Validation loss: 1.7085941747952533

Epoch: 6| Step: 8
Training loss: 0.30935806035995483
Validation loss: 1.7100457709322694

Epoch: 6| Step: 9
Training loss: 0.4555239975452423
Validation loss: 1.6903093425176476

Epoch: 6| Step: 10
Training loss: 0.19401207566261292
Validation loss: 1.6957980355908793

Epoch: 6| Step: 11
Training loss: 0.2882939279079437
Validation loss: 1.7010174169335315

Epoch: 6| Step: 12
Training loss: 0.5359561443328857
Validation loss: 1.7128697159469768

Epoch: 6| Step: 13
Training loss: 0.2784065008163452
Validation loss: 1.6941918647417458

Epoch: 381| Step: 0
Training loss: 0.21672362089157104
Validation loss: 1.7031532000469904

Epoch: 6| Step: 1
Training loss: 0.4159591794013977
Validation loss: 1.7114087432943366

Epoch: 6| Step: 2
Training loss: 0.32328182458877563
Validation loss: 1.686842623577323

Epoch: 6| Step: 3
Training loss: 0.2825167775154114
Validation loss: 1.6796102357167069

Epoch: 6| Step: 4
Training loss: 0.1952006220817566
Validation loss: 1.6508918205897014

Epoch: 6| Step: 5
Training loss: 0.24089929461479187
Validation loss: 1.658457266387119

Epoch: 6| Step: 6
Training loss: 0.1851852834224701
Validation loss: 1.6533756935468285

Epoch: 6| Step: 7
Training loss: 0.2876352071762085
Validation loss: 1.655648043078761

Epoch: 6| Step: 8
Training loss: 0.32806795835494995
Validation loss: 1.6774852878303939

Epoch: 6| Step: 9
Training loss: 0.3361462354660034
Validation loss: 1.6908013346374675

Epoch: 6| Step: 10
Training loss: 0.23288613557815552
Validation loss: 1.7273350300327424

Epoch: 6| Step: 11
Training loss: 0.2746588885784149
Validation loss: 1.7341524593291744

Epoch: 6| Step: 12
Training loss: 0.2653251886367798
Validation loss: 1.7044752977227653

Epoch: 6| Step: 13
Training loss: 0.15854090452194214
Validation loss: 1.734445530881164

Epoch: 382| Step: 0
Training loss: 0.1580790877342224
Validation loss: 1.7270113460479244

Epoch: 6| Step: 1
Training loss: 0.3018202781677246
Validation loss: 1.7000294257235784

Epoch: 6| Step: 2
Training loss: 0.23156236112117767
Validation loss: 1.7183532817389375

Epoch: 6| Step: 3
Training loss: 0.22703026235103607
Validation loss: 1.6944694698497813

Epoch: 6| Step: 4
Training loss: 0.1705140769481659
Validation loss: 1.6895798278111283

Epoch: 6| Step: 5
Training loss: 0.19854648411273956
Validation loss: 1.6858393210236744

Epoch: 6| Step: 6
Training loss: 0.3373880982398987
Validation loss: 1.6996373617520897

Epoch: 6| Step: 7
Training loss: 0.25754326581954956
Validation loss: 1.6636093508812688

Epoch: 6| Step: 8
Training loss: 0.15199822187423706
Validation loss: 1.7071180497446368

Epoch: 6| Step: 9
Training loss: 0.19252818822860718
Validation loss: 1.6730694488812519

Epoch: 6| Step: 10
Training loss: 0.18104499578475952
Validation loss: 1.6836305997704948

Epoch: 6| Step: 11
Training loss: 0.33998697996139526
Validation loss: 1.6710603288424912

Epoch: 6| Step: 12
Training loss: 0.24229413270950317
Validation loss: 1.7050601872064735

Epoch: 6| Step: 13
Training loss: 0.5733691453933716
Validation loss: 1.6989345332627654

Epoch: 383| Step: 0
Training loss: 0.41373211145401
Validation loss: 1.70745470446925

Epoch: 6| Step: 1
Training loss: 0.2276797890663147
Validation loss: 1.6870096832193353

Epoch: 6| Step: 2
Training loss: 0.226909339427948
Validation loss: 1.728622938997002

Epoch: 6| Step: 3
Training loss: 0.24719533324241638
Validation loss: 1.7413239786701817

Epoch: 6| Step: 4
Training loss: 0.2532366216182709
Validation loss: 1.7182695378539383

Epoch: 6| Step: 5
Training loss: 0.15688952803611755
Validation loss: 1.6984884482558056

Epoch: 6| Step: 6
Training loss: 0.2819940149784088
Validation loss: 1.685413033731522

Epoch: 6| Step: 7
Training loss: 0.13519510626792908
Validation loss: 1.682501334016041

Epoch: 6| Step: 8
Training loss: 0.24898147583007812
Validation loss: 1.6824056833021102

Epoch: 6| Step: 9
Training loss: 0.24197286367416382
Validation loss: 1.6629630090087972

Epoch: 6| Step: 10
Training loss: 0.23775453865528107
Validation loss: 1.6443427249949465

Epoch: 6| Step: 11
Training loss: 0.3509391248226166
Validation loss: 1.6612538022379721

Epoch: 6| Step: 12
Training loss: 0.2912532091140747
Validation loss: 1.6446099883766585

Epoch: 6| Step: 13
Training loss: 0.40880170464515686
Validation loss: 1.6218428701482794

Epoch: 384| Step: 0
Training loss: 0.4562668800354004
Validation loss: 1.656531444159887

Epoch: 6| Step: 1
Training loss: 0.251537948846817
Validation loss: 1.6629229245647308

Epoch: 6| Step: 2
Training loss: 0.2059449702501297
Validation loss: 1.672782833858203

Epoch: 6| Step: 3
Training loss: 0.15263999998569489
Validation loss: 1.661105336681489

Epoch: 6| Step: 4
Training loss: 0.08916433900594711
Validation loss: 1.633880199924592

Epoch: 6| Step: 5
Training loss: 0.39177581667900085
Validation loss: 1.6855412016632736

Epoch: 6| Step: 6
Training loss: 0.26924794912338257
Validation loss: 1.6401944442461895

Epoch: 6| Step: 7
Training loss: 0.19730499386787415
Validation loss: 1.6544615261016353

Epoch: 6| Step: 8
Training loss: 0.14832255244255066
Validation loss: 1.640251983878433

Epoch: 6| Step: 9
Training loss: 0.24278944730758667
Validation loss: 1.6761048211846301

Epoch: 6| Step: 10
Training loss: 0.33937859535217285
Validation loss: 1.6662320513879099

Epoch: 6| Step: 11
Training loss: 0.14656831324100494
Validation loss: 1.6418486026025587

Epoch: 6| Step: 12
Training loss: 0.31347012519836426
Validation loss: 1.65968277377467

Epoch: 6| Step: 13
Training loss: 0.2767223119735718
Validation loss: 1.6451620004510368

Epoch: 385| Step: 0
Training loss: 0.377804160118103
Validation loss: 1.6481974355636104

Epoch: 6| Step: 1
Training loss: 0.1216360479593277
Validation loss: 1.6437492550060313

Epoch: 6| Step: 2
Training loss: 0.21568600833415985
Validation loss: 1.634832961584932

Epoch: 6| Step: 3
Training loss: 0.3855246305465698
Validation loss: 1.65922248876223

Epoch: 6| Step: 4
Training loss: 0.1529218852519989
Validation loss: 1.6512309505093483

Epoch: 6| Step: 5
Training loss: 0.22181494534015656
Validation loss: 1.6238675681493615

Epoch: 6| Step: 6
Training loss: 0.2610529065132141
Validation loss: 1.642174982255505

Epoch: 6| Step: 7
Training loss: 0.19687128067016602
Validation loss: 1.6142754516293925

Epoch: 6| Step: 8
Training loss: 0.16073022782802582
Validation loss: 1.6143788035197923

Epoch: 6| Step: 9
Training loss: 0.406651109457016
Validation loss: 1.6436611760047175

Epoch: 6| Step: 10
Training loss: 0.21830686926841736
Validation loss: 1.6397315532930437

Epoch: 6| Step: 11
Training loss: 0.24641045928001404
Validation loss: 1.6468205439147128

Epoch: 6| Step: 12
Training loss: 0.1594492793083191
Validation loss: 1.6700334010585662

Epoch: 6| Step: 13
Training loss: 0.14143818616867065
Validation loss: 1.6514415728148593

Epoch: 386| Step: 0
Training loss: 0.31697070598602295
Validation loss: 1.71277976933346

Epoch: 6| Step: 1
Training loss: 0.23891189694404602
Validation loss: 1.7005221010536276

Epoch: 6| Step: 2
Training loss: 0.3925051689147949
Validation loss: 1.6945690108883766

Epoch: 6| Step: 3
Training loss: 0.17916330695152283
Validation loss: 1.7122612153330157

Epoch: 6| Step: 4
Training loss: 0.18266399204730988
Validation loss: 1.6641214393800305

Epoch: 6| Step: 5
Training loss: 0.20544016361236572
Validation loss: 1.7273546239381194

Epoch: 6| Step: 6
Training loss: 0.3564351797103882
Validation loss: 1.7230769703465123

Epoch: 6| Step: 7
Training loss: 0.1548035740852356
Validation loss: 1.7113549645229051

Epoch: 6| Step: 8
Training loss: 0.2588111162185669
Validation loss: 1.7124822831922961

Epoch: 6| Step: 9
Training loss: 0.1391843855381012
Validation loss: 1.676597108123123

Epoch: 6| Step: 10
Training loss: 0.1477469801902771
Validation loss: 1.656225590295689

Epoch: 6| Step: 11
Training loss: 0.3127594292163849
Validation loss: 1.628239857253208

Epoch: 6| Step: 12
Training loss: 0.23614804446697235
Validation loss: 1.6270579599565076

Epoch: 6| Step: 13
Training loss: 0.15744437277317047
Validation loss: 1.6217505944672452

Epoch: 387| Step: 0
Training loss: 0.22386600077152252
Validation loss: 1.6195404888481222

Epoch: 6| Step: 1
Training loss: 0.20769378542900085
Validation loss: 1.6332874554459766

Epoch: 6| Step: 2
Training loss: 0.3674117624759674
Validation loss: 1.6260423160368396

Epoch: 6| Step: 3
Training loss: 0.3001132607460022
Validation loss: 1.6459251360226703

Epoch: 6| Step: 4
Training loss: 0.29517024755477905
Validation loss: 1.6093389090671335

Epoch: 6| Step: 5
Training loss: 0.3333759009838104
Validation loss: 1.6624215302928802

Epoch: 6| Step: 6
Training loss: 0.2042572796344757
Validation loss: 1.589469866086078

Epoch: 6| Step: 7
Training loss: 0.2887108325958252
Validation loss: 1.6622173798981534

Epoch: 6| Step: 8
Training loss: 0.2978454530239105
Validation loss: 1.637942055220245

Epoch: 6| Step: 9
Training loss: 0.13444584608078003
Validation loss: 1.5945687191460722

Epoch: 6| Step: 10
Training loss: 0.10078602284193039
Validation loss: 1.570763248269276

Epoch: 6| Step: 11
Training loss: 0.2046506702899933
Validation loss: 1.6085752505128101

Epoch: 6| Step: 12
Training loss: 0.2546447217464447
Validation loss: 1.619728849780175

Epoch: 6| Step: 13
Training loss: 0.051010746508836746
Validation loss: 1.6200420830839424

Epoch: 388| Step: 0
Training loss: 0.15122944116592407
Validation loss: 1.6128008775813605

Epoch: 6| Step: 1
Training loss: 0.2870211601257324
Validation loss: 1.629735900509742

Epoch: 6| Step: 2
Training loss: 0.22751641273498535
Validation loss: 1.661564984629231

Epoch: 6| Step: 3
Training loss: 0.21333587169647217
Validation loss: 1.6586372070415045

Epoch: 6| Step: 4
Training loss: 0.24172261357307434
Validation loss: 1.6367785655042177

Epoch: 6| Step: 5
Training loss: 0.2361757904291153
Validation loss: 1.648992499997539

Epoch: 6| Step: 6
Training loss: 0.24512869119644165
Validation loss: 1.6517160015721475

Epoch: 6| Step: 7
Training loss: 0.11823773384094238
Validation loss: 1.6236198448365735

Epoch: 6| Step: 8
Training loss: 0.2195008248090744
Validation loss: 1.6529666505834109

Epoch: 6| Step: 9
Training loss: 0.2189359962940216
Validation loss: 1.6475831154854066

Epoch: 6| Step: 10
Training loss: 0.163476824760437
Validation loss: 1.641315843469353

Epoch: 6| Step: 11
Training loss: 0.42286497354507446
Validation loss: 1.6538931733818465

Epoch: 6| Step: 12
Training loss: 0.2738524377346039
Validation loss: 1.625851438891503

Epoch: 6| Step: 13
Training loss: 0.26140040159225464
Validation loss: 1.6171449422836304

Epoch: 389| Step: 0
Training loss: 0.15245011448860168
Validation loss: 1.6404803773408294

Epoch: 6| Step: 1
Training loss: 0.16107407212257385
Validation loss: 1.6223291017675912

Epoch: 6| Step: 2
Training loss: 0.31288522481918335
Validation loss: 1.6349172476799256

Epoch: 6| Step: 3
Training loss: 0.19220329821109772
Validation loss: 1.6617348963214504

Epoch: 6| Step: 4
Training loss: 0.3783046007156372
Validation loss: 1.6498251461213636

Epoch: 6| Step: 5
Training loss: 0.1616193950176239
Validation loss: 1.6754103424728557

Epoch: 6| Step: 6
Training loss: 0.40514421463012695
Validation loss: 1.682516494104939

Epoch: 6| Step: 7
Training loss: 0.21572013199329376
Validation loss: 1.6758490185583792

Epoch: 6| Step: 8
Training loss: 0.3671107292175293
Validation loss: 1.65215894996479

Epoch: 6| Step: 9
Training loss: 0.14330381155014038
Validation loss: 1.6683370490227976

Epoch: 6| Step: 10
Training loss: 0.3584986925125122
Validation loss: 1.6807982203780965

Epoch: 6| Step: 11
Training loss: 0.39670950174331665
Validation loss: 1.6925846453635924

Epoch: 6| Step: 12
Training loss: 0.15093383193016052
Validation loss: 1.6661782021163611

Epoch: 6| Step: 13
Training loss: 0.22466319799423218
Validation loss: 1.6762917798052552

Epoch: 390| Step: 0
Training loss: 0.3478955030441284
Validation loss: 1.6908100433247064

Epoch: 6| Step: 1
Training loss: 0.3282824456691742
Validation loss: 1.6773247680356425

Epoch: 6| Step: 2
Training loss: 0.1108265146613121
Validation loss: 1.6925499900694816

Epoch: 6| Step: 3
Training loss: 0.1405266970396042
Validation loss: 1.6850904687758415

Epoch: 6| Step: 4
Training loss: 0.21028712391853333
Validation loss: 1.702721357345581

Epoch: 6| Step: 5
Training loss: 0.20865122973918915
Validation loss: 1.7140727658425607

Epoch: 6| Step: 6
Training loss: 0.2213127613067627
Validation loss: 1.702183308139924

Epoch: 6| Step: 7
Training loss: 0.28189805150032043
Validation loss: 1.7112812111454625

Epoch: 6| Step: 8
Training loss: 0.1342284083366394
Validation loss: 1.7087878950180546

Epoch: 6| Step: 9
Training loss: 0.20688217878341675
Validation loss: 1.7412266731262207

Epoch: 6| Step: 10
Training loss: 0.2699940800666809
Validation loss: 1.6648542816920946

Epoch: 6| Step: 11
Training loss: 0.15879467129707336
Validation loss: 1.6813094962027766

Epoch: 6| Step: 12
Training loss: 0.2925494909286499
Validation loss: 1.6672612415846957

Epoch: 6| Step: 13
Training loss: 0.4807492792606354
Validation loss: 1.6495642764593965

Epoch: 391| Step: 0
Training loss: 0.1877613067626953
Validation loss: 1.6235683195052608

Epoch: 6| Step: 1
Training loss: 0.2302694022655487
Validation loss: 1.6279107421957038

Epoch: 6| Step: 2
Training loss: 0.2104179561138153
Validation loss: 1.6398541517155145

Epoch: 6| Step: 3
Training loss: 0.3366294503211975
Validation loss: 1.6243702211687643

Epoch: 6| Step: 4
Training loss: 0.31468385457992554
Validation loss: 1.6191124762258222

Epoch: 6| Step: 5
Training loss: 0.2604811489582062
Validation loss: 1.604382323962386

Epoch: 6| Step: 6
Training loss: 0.46901434659957886
Validation loss: 1.616200105477405

Epoch: 6| Step: 7
Training loss: 0.15347185730934143
Validation loss: 1.6290587584177654

Epoch: 6| Step: 8
Training loss: 0.17092928290367126
Validation loss: 1.650537824118009

Epoch: 6| Step: 9
Training loss: 0.22620254755020142
Validation loss: 1.6525534365766792

Epoch: 6| Step: 10
Training loss: 0.2467510998249054
Validation loss: 1.6951760938090663

Epoch: 6| Step: 11
Training loss: 0.27513089776039124
Validation loss: 1.6821135923426638

Epoch: 6| Step: 12
Training loss: 0.1476573348045349
Validation loss: 1.6901205996031403

Epoch: 6| Step: 13
Training loss: 0.15815675258636475
Validation loss: 1.6805110169995217

Epoch: 392| Step: 0
Training loss: 0.21120589971542358
Validation loss: 1.6622564613178212

Epoch: 6| Step: 1
Training loss: 0.19061893224716187
Validation loss: 1.682146824816222

Epoch: 6| Step: 2
Training loss: 0.19166889786720276
Validation loss: 1.6922232604795886

Epoch: 6| Step: 3
Training loss: 0.24902692437171936
Validation loss: 1.694885492324829

Epoch: 6| Step: 4
Training loss: 0.2679743766784668
Validation loss: 1.687216458782073

Epoch: 6| Step: 5
Training loss: 0.19651135802268982
Validation loss: 1.6267672290084183

Epoch: 6| Step: 6
Training loss: 0.30644673109054565
Validation loss: 1.6665909239040908

Epoch: 6| Step: 7
Training loss: 0.16375714540481567
Validation loss: 1.6600987783042334

Epoch: 6| Step: 8
Training loss: 0.197142094373703
Validation loss: 1.6807239414543234

Epoch: 6| Step: 9
Training loss: 0.15053130686283112
Validation loss: 1.642398388155045

Epoch: 6| Step: 10
Training loss: 0.20301005244255066
Validation loss: 1.6337401687457997

Epoch: 6| Step: 11
Training loss: 0.12166320532560349
Validation loss: 1.6670053799947102

Epoch: 6| Step: 12
Training loss: 0.5200420618057251
Validation loss: 1.6541515729760612

Epoch: 6| Step: 13
Training loss: 0.21791817247867584
Validation loss: 1.6403472205644012

Epoch: 393| Step: 0
Training loss: 0.2451895773410797
Validation loss: 1.6403027067902267

Epoch: 6| Step: 1
Training loss: 0.18272128701210022
Validation loss: 1.6266881829948836

Epoch: 6| Step: 2
Training loss: 0.19631792604923248
Validation loss: 1.6317767725195935

Epoch: 6| Step: 3
Training loss: 0.2891594469547272
Validation loss: 1.6290945199228102

Epoch: 6| Step: 4
Training loss: 0.12333224713802338
Validation loss: 1.6541130055663407

Epoch: 6| Step: 5
Training loss: 0.25456878542900085
Validation loss: 1.6331197702756493

Epoch: 6| Step: 6
Training loss: 0.21155916154384613
Validation loss: 1.6636352372425858

Epoch: 6| Step: 7
Training loss: 0.3710799813270569
Validation loss: 1.6308678798778082

Epoch: 6| Step: 8
Training loss: 0.1740613877773285
Validation loss: 1.630659452048681

Epoch: 6| Step: 9
Training loss: 0.2481176108121872
Validation loss: 1.6279107409138833

Epoch: 6| Step: 10
Training loss: 0.27395159006118774
Validation loss: 1.6231984797344412

Epoch: 6| Step: 11
Training loss: 0.23352167010307312
Validation loss: 1.6303626811632546

Epoch: 6| Step: 12
Training loss: 0.11605512350797653
Validation loss: 1.606695875044792

Epoch: 6| Step: 13
Training loss: 0.23719164729118347
Validation loss: 1.6301509834104968

Epoch: 394| Step: 0
Training loss: 0.11960911750793457
Validation loss: 1.6182204190120901

Epoch: 6| Step: 1
Training loss: 0.176721453666687
Validation loss: 1.5978878313495266

Epoch: 6| Step: 2
Training loss: 0.33538612723350525
Validation loss: 1.6026842389055478

Epoch: 6| Step: 3
Training loss: 0.19986341893672943
Validation loss: 1.6493403950045187

Epoch: 6| Step: 4
Training loss: 0.26718518137931824
Validation loss: 1.639076034228007

Epoch: 6| Step: 5
Training loss: 0.20490896701812744
Validation loss: 1.6670314791382

Epoch: 6| Step: 6
Training loss: 0.17575952410697937
Validation loss: 1.6316631122301983

Epoch: 6| Step: 7
Training loss: 0.15531526505947113
Validation loss: 1.6871019127548381

Epoch: 6| Step: 8
Training loss: 0.11675046384334564
Validation loss: 1.6927680494964763

Epoch: 6| Step: 9
Training loss: 0.3669357895851135
Validation loss: 1.6600316519378333

Epoch: 6| Step: 10
Training loss: 0.18356367945671082
Validation loss: 1.6695752066950644

Epoch: 6| Step: 11
Training loss: 0.1698922961950302
Validation loss: 1.7088094295993927

Epoch: 6| Step: 12
Training loss: 0.2653966546058655
Validation loss: 1.641770088544456

Epoch: 6| Step: 13
Training loss: 0.3123134970664978
Validation loss: 1.666926735190935

Epoch: 395| Step: 0
Training loss: 0.30205485224723816
Validation loss: 1.652373469004067

Epoch: 6| Step: 1
Training loss: 0.1686115860939026
Validation loss: 1.6339726255786033

Epoch: 6| Step: 2
Training loss: 0.30939990282058716
Validation loss: 1.6393796013247581

Epoch: 6| Step: 3
Training loss: 0.2740064263343811
Validation loss: 1.6054510544705134

Epoch: 6| Step: 4
Training loss: 0.2621724009513855
Validation loss: 1.6091659030606669

Epoch: 6| Step: 5
Training loss: 0.14034602046012878
Validation loss: 1.6412600458309214

Epoch: 6| Step: 6
Training loss: 0.11696986854076385
Validation loss: 1.6299162372466056

Epoch: 6| Step: 7
Training loss: 0.25939470529556274
Validation loss: 1.650033841850937

Epoch: 6| Step: 8
Training loss: 0.2671915590763092
Validation loss: 1.6306427204480736

Epoch: 6| Step: 9
Training loss: 0.13169850409030914
Validation loss: 1.6394012743426907

Epoch: 6| Step: 10
Training loss: 0.13983047008514404
Validation loss: 1.6442547434119767

Epoch: 6| Step: 11
Training loss: 0.39403480291366577
Validation loss: 1.631997726296866

Epoch: 6| Step: 12
Training loss: 0.16756191849708557
Validation loss: 1.636338483902716

Epoch: 6| Step: 13
Training loss: 0.17557747662067413
Validation loss: 1.6228426220596477

Epoch: 396| Step: 0
Training loss: 0.1578434556722641
Validation loss: 1.6421173810958862

Epoch: 6| Step: 1
Training loss: 0.2735881805419922
Validation loss: 1.6445905841806883

Epoch: 6| Step: 2
Training loss: 0.14033089578151703
Validation loss: 1.6578160626913911

Epoch: 6| Step: 3
Training loss: 0.13695278763771057
Validation loss: 1.673810234633825

Epoch: 6| Step: 4
Training loss: 0.21993231773376465
Validation loss: 1.6328762731244486

Epoch: 6| Step: 5
Training loss: 0.1714375764131546
Validation loss: 1.6258672693724274

Epoch: 6| Step: 6
Training loss: 0.3220473527908325
Validation loss: 1.645068419876919

Epoch: 6| Step: 7
Training loss: 0.2534274458885193
Validation loss: 1.6159869957995672

Epoch: 6| Step: 8
Training loss: 0.20413368940353394
Validation loss: 1.583744538727627

Epoch: 6| Step: 9
Training loss: 0.20489230751991272
Validation loss: 1.6228373922327513

Epoch: 6| Step: 10
Training loss: 0.3147287964820862
Validation loss: 1.6249125663952162

Epoch: 6| Step: 11
Training loss: 0.13918259739875793
Validation loss: 1.631226017910947

Epoch: 6| Step: 12
Training loss: 0.39951327443122864
Validation loss: 1.6516743744573286

Epoch: 6| Step: 13
Training loss: 0.2656085193157196
Validation loss: 1.6376463162001742

Epoch: 397| Step: 0
Training loss: 0.1468026340007782
Validation loss: 1.6491980386036698

Epoch: 6| Step: 1
Training loss: 0.21438395977020264
Validation loss: 1.6549585865389915

Epoch: 6| Step: 2
Training loss: 0.424815833568573
Validation loss: 1.6078000485256154

Epoch: 6| Step: 3
Training loss: 0.15754596889019012
Validation loss: 1.6200078815542243

Epoch: 6| Step: 4
Training loss: 0.2160494327545166
Validation loss: 1.6007851400683004

Epoch: 6| Step: 5
Training loss: 0.33405137062072754
Validation loss: 1.647679199454605

Epoch: 6| Step: 6
Training loss: 0.22417032718658447
Validation loss: 1.6344298008949525

Epoch: 6| Step: 7
Training loss: 0.22221997380256653
Validation loss: 1.6339223974494523

Epoch: 6| Step: 8
Training loss: 0.27504193782806396
Validation loss: 1.632420361682933

Epoch: 6| Step: 9
Training loss: 0.25666800141334534
Validation loss: 1.6457459888150614

Epoch: 6| Step: 10
Training loss: 0.18041209876537323
Validation loss: 1.6706756802015408

Epoch: 6| Step: 11
Training loss: 0.3058585524559021
Validation loss: 1.6856753492868075

Epoch: 6| Step: 12
Training loss: 0.25634604692459106
Validation loss: 1.6821587111360283

Epoch: 6| Step: 13
Training loss: 0.5219928026199341
Validation loss: 1.71393996156672

Epoch: 398| Step: 0
Training loss: 0.15376754105091095
Validation loss: 1.682445882469095

Epoch: 6| Step: 1
Training loss: 0.32707861065864563
Validation loss: 1.7150464993651195

Epoch: 6| Step: 2
Training loss: 0.48983892798423767
Validation loss: 1.6679006238137521

Epoch: 6| Step: 3
Training loss: 0.36688026785850525
Validation loss: 1.7096580638680408

Epoch: 6| Step: 4
Training loss: 0.15527355670928955
Validation loss: 1.6806512744196

Epoch: 6| Step: 5
Training loss: 0.23499998450279236
Validation loss: 1.654751467448409

Epoch: 6| Step: 6
Training loss: 0.1619211733341217
Validation loss: 1.6839492513287453

Epoch: 6| Step: 7
Training loss: 0.14289048314094543
Validation loss: 1.652400157784903

Epoch: 6| Step: 8
Training loss: 0.33106541633605957
Validation loss: 1.6731299674639137

Epoch: 6| Step: 9
Training loss: 0.28396838903427124
Validation loss: 1.6272134934702227

Epoch: 6| Step: 10
Training loss: 0.4895777404308319
Validation loss: 1.656168617228026

Epoch: 6| Step: 11
Training loss: 0.2095934897661209
Validation loss: 1.6505936807201755

Epoch: 6| Step: 12
Training loss: 0.21484749019145966
Validation loss: 1.649719169062953

Epoch: 6| Step: 13
Training loss: 0.08082333207130432
Validation loss: 1.668311454916513

Epoch: 399| Step: 0
Training loss: 0.210097536444664
Validation loss: 1.6765467274573542

Epoch: 6| Step: 1
Training loss: 0.15205690264701843
Validation loss: 1.6816491978142851

Epoch: 6| Step: 2
Training loss: 0.12010270357131958
Validation loss: 1.6635785730936195

Epoch: 6| Step: 3
Training loss: 0.2701405882835388
Validation loss: 1.6508652817818426

Epoch: 6| Step: 4
Training loss: 0.07580642402172089
Validation loss: 1.636716220968513

Epoch: 6| Step: 5
Training loss: 0.2855245769023895
Validation loss: 1.6292719302638885

Epoch: 6| Step: 6
Training loss: 0.3124607801437378
Validation loss: 1.6356096844519339

Epoch: 6| Step: 7
Training loss: 0.19053012132644653
Validation loss: 1.5813060236233536

Epoch: 6| Step: 8
Training loss: 0.13147161900997162
Validation loss: 1.5951581026918145

Epoch: 6| Step: 9
Training loss: 0.2418808937072754
Validation loss: 1.5832561574956423

Epoch: 6| Step: 10
Training loss: 0.18471330404281616
Validation loss: 1.5927898550546298

Epoch: 6| Step: 11
Training loss: 0.2597116231918335
Validation loss: 1.6052094787679694

Epoch: 6| Step: 12
Training loss: 0.3152003884315491
Validation loss: 1.6116547148714784

Epoch: 6| Step: 13
Training loss: 0.1845715343952179
Validation loss: 1.6260014195596018

Epoch: 400| Step: 0
Training loss: 0.13978689908981323
Validation loss: 1.6084699976828791

Epoch: 6| Step: 1
Training loss: 0.16705304384231567
Validation loss: 1.6337197314026535

Epoch: 6| Step: 2
Training loss: 0.43560460209846497
Validation loss: 1.6230423976016302

Epoch: 6| Step: 3
Training loss: 0.2076314091682434
Validation loss: 1.6275159107741488

Epoch: 6| Step: 4
Training loss: 0.2060142457485199
Validation loss: 1.621019576185493

Epoch: 6| Step: 5
Training loss: 0.1753336787223816
Validation loss: 1.636066286794601

Epoch: 6| Step: 6
Training loss: 0.2893645167350769
Validation loss: 1.6381712344384962

Epoch: 6| Step: 7
Training loss: 0.24761423468589783
Validation loss: 1.665232946795802

Epoch: 6| Step: 8
Training loss: 0.2420469969511032
Validation loss: 1.6929909644588348

Epoch: 6| Step: 9
Training loss: 0.3174751400947571
Validation loss: 1.6932628654664563

Epoch: 6| Step: 10
Training loss: 0.31504493951797485
Validation loss: 1.65887971590924

Epoch: 6| Step: 11
Training loss: 0.26719775795936584
Validation loss: 1.6509921717387375

Epoch: 6| Step: 12
Training loss: 0.12051836401224136
Validation loss: 1.6462795849769347

Epoch: 6| Step: 13
Training loss: 0.36638143658638
Validation loss: 1.6447638670603435

Epoch: 401| Step: 0
Training loss: 0.18782714009284973
Validation loss: 1.6098278453273158

Epoch: 6| Step: 1
Training loss: 0.20810957252979279
Validation loss: 1.6146031246390393

Epoch: 6| Step: 2
Training loss: 0.1315794289112091
Validation loss: 1.6165273343363116

Epoch: 6| Step: 3
Training loss: 0.2811688780784607
Validation loss: 1.605429248143268

Epoch: 6| Step: 4
Training loss: 0.19117093086242676
Validation loss: 1.6331087658482213

Epoch: 6| Step: 5
Training loss: 0.2205381691455841
Validation loss: 1.6209503604519753

Epoch: 6| Step: 6
Training loss: 0.2202891856431961
Validation loss: 1.6348985010577786

Epoch: 6| Step: 7
Training loss: 0.16493427753448486
Validation loss: 1.6545908771535403

Epoch: 6| Step: 8
Training loss: 0.18324227631092072
Validation loss: 1.6644105885618476

Epoch: 6| Step: 9
Training loss: 0.22259309887886047
Validation loss: 1.6540397341533373

Epoch: 6| Step: 10
Training loss: 0.4214803874492645
Validation loss: 1.6489888275823286

Epoch: 6| Step: 11
Training loss: 0.19154298305511475
Validation loss: 1.6882335780769266

Epoch: 6| Step: 12
Training loss: 0.30524611473083496
Validation loss: 1.652408920308595

Epoch: 6| Step: 13
Training loss: 0.45149052143096924
Validation loss: 1.6664235476524598

Epoch: 402| Step: 0
Training loss: 0.2278674840927124
Validation loss: 1.665109113980365

Epoch: 6| Step: 1
Training loss: 0.1718798726797104
Validation loss: 1.6391904059276785

Epoch: 6| Step: 2
Training loss: 0.23861104249954224
Validation loss: 1.63484279571041

Epoch: 6| Step: 3
Training loss: 0.2935299873352051
Validation loss: 1.6613867834050169

Epoch: 6| Step: 4
Training loss: 0.22569012641906738
Validation loss: 1.6709925282386042

Epoch: 6| Step: 5
Training loss: 0.19784006476402283
Validation loss: 1.6847481753236504

Epoch: 6| Step: 6
Training loss: 0.16555306315422058
Validation loss: 1.665281241939914

Epoch: 6| Step: 7
Training loss: 0.17958685755729675
Validation loss: 1.670102427082677

Epoch: 6| Step: 8
Training loss: 0.38427793979644775
Validation loss: 1.6763912599573854

Epoch: 6| Step: 9
Training loss: 0.30766162276268005
Validation loss: 1.6609140185899631

Epoch: 6| Step: 10
Training loss: 0.15051230788230896
Validation loss: 1.6209446653243034

Epoch: 6| Step: 11
Training loss: 0.23074975609779358
Validation loss: 1.636586058524347

Epoch: 6| Step: 12
Training loss: 0.1895323544740677
Validation loss: 1.6313161817930077

Epoch: 6| Step: 13
Training loss: 0.18452061712741852
Validation loss: 1.6421074175065564

Epoch: 403| Step: 0
Training loss: 0.19963985681533813
Validation loss: 1.6047987002198414

Epoch: 6| Step: 1
Training loss: 0.1133686900138855
Validation loss: 1.6251211576564337

Epoch: 6| Step: 2
Training loss: 0.2063298225402832
Validation loss: 1.6161568549371534

Epoch: 6| Step: 3
Training loss: 0.31001999974250793
Validation loss: 1.6289311006505003

Epoch: 6| Step: 4
Training loss: 0.2654483914375305
Validation loss: 1.6139387212773806

Epoch: 6| Step: 5
Training loss: 0.15438999235630035
Validation loss: 1.624928492371754

Epoch: 6| Step: 6
Training loss: 0.1375828981399536
Validation loss: 1.614458639134643

Epoch: 6| Step: 7
Training loss: 0.17721931636333466
Validation loss: 1.5937376541476096

Epoch: 6| Step: 8
Training loss: 0.21551936864852905
Validation loss: 1.6305643960993776

Epoch: 6| Step: 9
Training loss: 0.21457602083683014
Validation loss: 1.6299903379973544

Epoch: 6| Step: 10
Training loss: 0.19752052426338196
Validation loss: 1.6334154951956965

Epoch: 6| Step: 11
Training loss: 0.21497154235839844
Validation loss: 1.61851514539411

Epoch: 6| Step: 12
Training loss: 0.16012437641620636
Validation loss: 1.6224669256517965

Epoch: 6| Step: 13
Training loss: 0.058616671711206436
Validation loss: 1.6270738006919943

Epoch: 404| Step: 0
Training loss: 0.12927654385566711
Validation loss: 1.608593217788204

Epoch: 6| Step: 1
Training loss: 0.1999599039554596
Validation loss: 1.6219066919819

Epoch: 6| Step: 2
Training loss: 0.22056855261325836
Validation loss: 1.6167630482745428

Epoch: 6| Step: 3
Training loss: 0.10086347162723541
Validation loss: 1.6415797446363716

Epoch: 6| Step: 4
Training loss: 0.36074578762054443
Validation loss: 1.6681623945954025

Epoch: 6| Step: 5
Training loss: 0.23143425583839417
Validation loss: 1.6523148590518582

Epoch: 6| Step: 6
Training loss: 0.16131561994552612
Validation loss: 1.633900406540081

Epoch: 6| Step: 7
Training loss: 0.18181706964969635
Validation loss: 1.6484415326067197

Epoch: 6| Step: 8
Training loss: 0.2564345598220825
Validation loss: 1.6633612314860027

Epoch: 6| Step: 9
Training loss: 0.33023566007614136
Validation loss: 1.6325288113727365

Epoch: 6| Step: 10
Training loss: 0.12249130755662918
Validation loss: 1.6403320925210112

Epoch: 6| Step: 11
Training loss: 0.19629843533039093
Validation loss: 1.6362081625128304

Epoch: 6| Step: 12
Training loss: 0.1195976585149765
Validation loss: 1.6396340862397225

Epoch: 6| Step: 13
Training loss: 0.18502368032932281
Validation loss: 1.6105628231520295

Epoch: 405| Step: 0
Training loss: 0.10742154717445374
Validation loss: 1.6246491298880628

Epoch: 6| Step: 1
Training loss: 0.14240381121635437
Validation loss: 1.6272384094935592

Epoch: 6| Step: 2
Training loss: 0.18925367295742035
Validation loss: 1.6039251717188026

Epoch: 6| Step: 3
Training loss: 0.4838253855705261
Validation loss: 1.615420719628693

Epoch: 6| Step: 4
Training loss: 0.21013647317886353
Validation loss: 1.6281750753361692

Epoch: 6| Step: 5
Training loss: 0.19870606064796448
Validation loss: 1.6100368256209998

Epoch: 6| Step: 6
Training loss: 0.2167702317237854
Validation loss: 1.6096616816777054

Epoch: 6| Step: 7
Training loss: 0.19949880242347717
Validation loss: 1.6225625981566727

Epoch: 6| Step: 8
Training loss: 0.3003079295158386
Validation loss: 1.586723449409649

Epoch: 6| Step: 9
Training loss: 0.2445753514766693
Validation loss: 1.6142930933224258

Epoch: 6| Step: 10
Training loss: 0.1313496083021164
Validation loss: 1.6001331575455204

Epoch: 6| Step: 11
Training loss: 0.22569754719734192
Validation loss: 1.6019352533484017

Epoch: 6| Step: 12
Training loss: 0.23259979486465454
Validation loss: 1.6304434948070075

Epoch: 6| Step: 13
Training loss: 0.1724129617214203
Validation loss: 1.6240239451008458

Epoch: 406| Step: 0
Training loss: 0.13729244470596313
Validation loss: 1.6432588574706868

Epoch: 6| Step: 1
Training loss: 0.2528996169567108
Validation loss: 1.6380342206647318

Epoch: 6| Step: 2
Training loss: 0.42955875396728516
Validation loss: 1.627453302824369

Epoch: 6| Step: 3
Training loss: 0.20020298659801483
Validation loss: 1.644546111424764

Epoch: 6| Step: 4
Training loss: 0.1328372359275818
Validation loss: 1.616163884439776

Epoch: 6| Step: 5
Training loss: 0.29799363017082214
Validation loss: 1.6699366607973654

Epoch: 6| Step: 6
Training loss: 0.1306321918964386
Validation loss: 1.6209087557690118

Epoch: 6| Step: 7
Training loss: 0.15501776337623596
Validation loss: 1.672839633880123

Epoch: 6| Step: 8
Training loss: 0.1649658977985382
Validation loss: 1.6589985893618675

Epoch: 6| Step: 9
Training loss: 0.1342882513999939
Validation loss: 1.6552927955504386

Epoch: 6| Step: 10
Training loss: 0.21893031895160675
Validation loss: 1.6600486668207313

Epoch: 6| Step: 11
Training loss: 0.13790594041347504
Validation loss: 1.6485742074187084

Epoch: 6| Step: 12
Training loss: 0.2384164184331894
Validation loss: 1.6574467741033083

Epoch: 6| Step: 13
Training loss: 0.2430104911327362
Validation loss: 1.6686688559029692

Epoch: 407| Step: 0
Training loss: 0.11072440445423126
Validation loss: 1.6687139067598569

Epoch: 6| Step: 1
Training loss: 0.252473384141922
Validation loss: 1.6526515176219325

Epoch: 6| Step: 2
Training loss: 0.20040182769298553
Validation loss: 1.6504637220854401

Epoch: 6| Step: 3
Training loss: 0.2722376883029938
Validation loss: 1.6237211406871837

Epoch: 6| Step: 4
Training loss: 0.25588762760162354
Validation loss: 1.6672383213555941

Epoch: 6| Step: 5
Training loss: 0.15814019739627838
Validation loss: 1.6391278197688441

Epoch: 6| Step: 6
Training loss: 0.2502622604370117
Validation loss: 1.6415813712663547

Epoch: 6| Step: 7
Training loss: 0.10647944360971451
Validation loss: 1.6480597783160467

Epoch: 6| Step: 8
Training loss: 0.2876657545566559
Validation loss: 1.6535597116716447

Epoch: 6| Step: 9
Training loss: 0.2567042112350464
Validation loss: 1.6639000831111785

Epoch: 6| Step: 10
Training loss: 0.21734318137168884
Validation loss: 1.6742080770513064

Epoch: 6| Step: 11
Training loss: 0.1176612377166748
Validation loss: 1.6508222626101585

Epoch: 6| Step: 12
Training loss: 0.08682993054389954
Validation loss: 1.6758270635399768

Epoch: 6| Step: 13
Training loss: 0.13445459306240082
Validation loss: 1.6409628455356886

Epoch: 408| Step: 0
Training loss: 0.1479824185371399
Validation loss: 1.6176590124766033

Epoch: 6| Step: 1
Training loss: 0.17943769693374634
Validation loss: 1.669062670841012

Epoch: 6| Step: 2
Training loss: 0.24711765348911285
Validation loss: 1.664959289694345

Epoch: 6| Step: 3
Training loss: 0.19973590970039368
Validation loss: 1.6589085363572644

Epoch: 6| Step: 4
Training loss: 0.21321672201156616
Validation loss: 1.6963235050119378

Epoch: 6| Step: 5
Training loss: 0.1064310297369957
Validation loss: 1.7255562236232143

Epoch: 6| Step: 6
Training loss: 0.3151952922344208
Validation loss: 1.6977134173916233

Epoch: 6| Step: 7
Training loss: 0.20309078693389893
Validation loss: 1.7153296086095995

Epoch: 6| Step: 8
Training loss: 0.25163620710372925
Validation loss: 1.7004530532385713

Epoch: 6| Step: 9
Training loss: 0.25571027398109436
Validation loss: 1.6841885979457567

Epoch: 6| Step: 10
Training loss: 0.19262772798538208
Validation loss: 1.6739350800873132

Epoch: 6| Step: 11
Training loss: 0.23061536252498627
Validation loss: 1.6572732412686912

Epoch: 6| Step: 12
Training loss: 0.12588468194007874
Validation loss: 1.6171804781882995

Epoch: 6| Step: 13
Training loss: 0.06624235212802887
Validation loss: 1.619869153986695

Epoch: 409| Step: 0
Training loss: 0.14434540271759033
Validation loss: 1.6321755532295472

Epoch: 6| Step: 1
Training loss: 0.2628956139087677
Validation loss: 1.6300353106632028

Epoch: 6| Step: 2
Training loss: 0.22362425923347473
Validation loss: 1.6410330726254372

Epoch: 6| Step: 3
Training loss: 0.2015787661075592
Validation loss: 1.619920253753662

Epoch: 6| Step: 4
Training loss: 0.21708445250988007
Validation loss: 1.6673002550678868

Epoch: 6| Step: 5
Training loss: 0.17150259017944336
Validation loss: 1.6413621761465584

Epoch: 6| Step: 6
Training loss: 0.18398869037628174
Validation loss: 1.663225543114447

Epoch: 6| Step: 7
Training loss: 0.2173597514629364
Validation loss: 1.661484569631597

Epoch: 6| Step: 8
Training loss: 0.17896300554275513
Validation loss: 1.6640303147736417

Epoch: 6| Step: 9
Training loss: 0.2358088195323944
Validation loss: 1.643509889161715

Epoch: 6| Step: 10
Training loss: 0.15051677823066711
Validation loss: 1.6450800382962791

Epoch: 6| Step: 11
Training loss: 0.23745666444301605
Validation loss: 1.6601082073744906

Epoch: 6| Step: 12
Training loss: 0.20577214658260345
Validation loss: 1.6667599344766268

Epoch: 6| Step: 13
Training loss: 0.18155115842819214
Validation loss: 1.6412935961959183

Epoch: 410| Step: 0
Training loss: 0.250832200050354
Validation loss: 1.6573942720249135

Epoch: 6| Step: 1
Training loss: 0.22299529612064362
Validation loss: 1.659435825963174

Epoch: 6| Step: 2
Training loss: 0.1247379258275032
Validation loss: 1.6707513332366943

Epoch: 6| Step: 3
Training loss: 0.21916252374649048
Validation loss: 1.6444898266946115

Epoch: 6| Step: 4
Training loss: 0.289084792137146
Validation loss: 1.6469879304209063

Epoch: 6| Step: 5
Training loss: 0.20569728314876556
Validation loss: 1.6418319927748812

Epoch: 6| Step: 6
Training loss: 0.19629791378974915
Validation loss: 1.6080988440462338

Epoch: 6| Step: 7
Training loss: 0.2467086762189865
Validation loss: 1.5969237665976248

Epoch: 6| Step: 8
Training loss: 0.17797225713729858
Validation loss: 1.6008355053522254

Epoch: 6| Step: 9
Training loss: 0.15877598524093628
Validation loss: 1.6124313941565893

Epoch: 6| Step: 10
Training loss: 0.21771454811096191
Validation loss: 1.5973981862427087

Epoch: 6| Step: 11
Training loss: 0.18049979209899902
Validation loss: 1.5991243354735836

Epoch: 6| Step: 12
Training loss: 0.21577468514442444
Validation loss: 1.6009238894267748

Epoch: 6| Step: 13
Training loss: 0.13968801498413086
Validation loss: 1.6208002926200948

Epoch: 411| Step: 0
Training loss: 0.17124809324741364
Validation loss: 1.6260013657231485

Epoch: 6| Step: 1
Training loss: 0.10431329160928726
Validation loss: 1.6373758085312382

Epoch: 6| Step: 2
Training loss: 0.17835110425949097
Validation loss: 1.6318727462522444

Epoch: 6| Step: 3
Training loss: 0.10114623606204987
Validation loss: 1.6223380783552765

Epoch: 6| Step: 4
Training loss: 0.17303526401519775
Validation loss: 1.6445565377512286

Epoch: 6| Step: 5
Training loss: 0.1664707511663437
Validation loss: 1.6176539915864185

Epoch: 6| Step: 6
Training loss: 0.27513283491134644
Validation loss: 1.643945054341388

Epoch: 6| Step: 7
Training loss: 0.2345515638589859
Validation loss: 1.671303851630098

Epoch: 6| Step: 8
Training loss: 0.270870566368103
Validation loss: 1.6670190185628913

Epoch: 6| Step: 9
Training loss: 0.2999093234539032
Validation loss: 1.6741645015696043

Epoch: 6| Step: 10
Training loss: 0.13092145323753357
Validation loss: 1.6553448451462613

Epoch: 6| Step: 11
Training loss: 0.10850438475608826
Validation loss: 1.6790683679683234

Epoch: 6| Step: 12
Training loss: 0.2928822338581085
Validation loss: 1.6917452991649669

Epoch: 6| Step: 13
Training loss: 0.27953842282295227
Validation loss: 1.7047267844600063

Epoch: 412| Step: 0
Training loss: 0.14287245273590088
Validation loss: 1.7021134553417083

Epoch: 6| Step: 1
Training loss: 0.18142178654670715
Validation loss: 1.6985279001215452

Epoch: 6| Step: 2
Training loss: 0.12720613181591034
Validation loss: 1.7018423759809105

Epoch: 6| Step: 3
Training loss: 0.18251055479049683
Validation loss: 1.6788093454094344

Epoch: 6| Step: 4
Training loss: 0.12818896770477295
Validation loss: 1.6852066645058252

Epoch: 6| Step: 5
Training loss: 0.2271290421485901
Validation loss: 1.6883134201008787

Epoch: 6| Step: 6
Training loss: 0.18397679924964905
Validation loss: 1.6721609151491554

Epoch: 6| Step: 7
Training loss: 0.20598918199539185
Validation loss: 1.6385354341999177

Epoch: 6| Step: 8
Training loss: 0.23153090476989746
Validation loss: 1.6415582844006118

Epoch: 6| Step: 9
Training loss: 0.2793201208114624
Validation loss: 1.675743055599992

Epoch: 6| Step: 10
Training loss: 0.15847711265087128
Validation loss: 1.6542091215810468

Epoch: 6| Step: 11
Training loss: 0.3586644232273102
Validation loss: 1.6494394502332133

Epoch: 6| Step: 12
Training loss: 0.20802265405654907
Validation loss: 1.6453091829053816

Epoch: 6| Step: 13
Training loss: 0.24003294110298157
Validation loss: 1.6383591210970314

Epoch: 413| Step: 0
Training loss: 0.14838144183158875
Validation loss: 1.6202494047021354

Epoch: 6| Step: 1
Training loss: 0.29356929659843445
Validation loss: 1.6285874561596942

Epoch: 6| Step: 2
Training loss: 0.3133815824985504
Validation loss: 1.6244754393895466

Epoch: 6| Step: 3
Training loss: 0.16532650589942932
Validation loss: 1.610926188448424

Epoch: 6| Step: 4
Training loss: 0.19956651329994202
Validation loss: 1.6234706947880406

Epoch: 6| Step: 5
Training loss: 0.1241886094212532
Validation loss: 1.595258698668531

Epoch: 6| Step: 6
Training loss: 0.10867226123809814
Validation loss: 1.633480106630633

Epoch: 6| Step: 7
Training loss: 0.2776675820350647
Validation loss: 1.6295778687282274

Epoch: 6| Step: 8
Training loss: 0.14916974306106567
Validation loss: 1.6310526427402292

Epoch: 6| Step: 9
Training loss: 0.1627783626317978
Validation loss: 1.667365776595249

Epoch: 6| Step: 10
Training loss: 0.1598818004131317
Validation loss: 1.6517490443362985

Epoch: 6| Step: 11
Training loss: 0.1562071442604065
Validation loss: 1.6769184617586033

Epoch: 6| Step: 12
Training loss: 0.2700153589248657
Validation loss: 1.6628023603911042

Epoch: 6| Step: 13
Training loss: 0.16991068422794342
Validation loss: 1.634182471101002

Epoch: 414| Step: 0
Training loss: 0.18978038430213928
Validation loss: 1.6333254204001477

Epoch: 6| Step: 1
Training loss: 0.1713101863861084
Validation loss: 1.6340209181590746

Epoch: 6| Step: 2
Training loss: 0.14499548077583313
Validation loss: 1.6312830166150165

Epoch: 6| Step: 3
Training loss: 0.22956541180610657
Validation loss: 1.587857300235379

Epoch: 6| Step: 4
Training loss: 0.1073431596159935
Validation loss: 1.6058810321233605

Epoch: 6| Step: 5
Training loss: 0.20777985453605652
Validation loss: 1.578698271064348

Epoch: 6| Step: 6
Training loss: 0.29480451345443726
Validation loss: 1.5856047868728638

Epoch: 6| Step: 7
Training loss: 0.1136404499411583
Validation loss: 1.565851455093712

Epoch: 6| Step: 8
Training loss: 0.23161011934280396
Validation loss: 1.5635305066262521

Epoch: 6| Step: 9
Training loss: 0.24497751891613007
Validation loss: 1.5821871321688417

Epoch: 6| Step: 10
Training loss: 0.13292238116264343
Validation loss: 1.5868333744746383

Epoch: 6| Step: 11
Training loss: 0.1171853244304657
Validation loss: 1.579985007163017

Epoch: 6| Step: 12
Training loss: 0.17136269807815552
Validation loss: 1.6213242802568661

Epoch: 6| Step: 13
Training loss: 0.3044150173664093
Validation loss: 1.6001887347108574

Epoch: 415| Step: 0
Training loss: 0.14773374795913696
Validation loss: 1.6235129076947448

Epoch: 6| Step: 1
Training loss: 0.20666691660881042
Validation loss: 1.5630051974327333

Epoch: 6| Step: 2
Training loss: 0.11980165541172028
Validation loss: 1.589749204215183

Epoch: 6| Step: 3
Training loss: 0.2533300518989563
Validation loss: 1.5693273377674881

Epoch: 6| Step: 4
Training loss: 0.22607244551181793
Validation loss: 1.566035448863942

Epoch: 6| Step: 5
Training loss: 0.25697433948516846
Validation loss: 1.5560679487002793

Epoch: 6| Step: 6
Training loss: 0.30982938408851624
Validation loss: 1.5632130561336395

Epoch: 6| Step: 7
Training loss: 0.24286723136901855
Validation loss: 1.5635627033889934

Epoch: 6| Step: 8
Training loss: 0.3622930943965912
Validation loss: 1.5830691360658216

Epoch: 6| Step: 9
Training loss: 0.22329072654247284
Validation loss: 1.6037386258443196

Epoch: 6| Step: 10
Training loss: 0.22229400277137756
Validation loss: 1.5886206075709353

Epoch: 6| Step: 11
Training loss: 0.22581996023654938
Validation loss: 1.6405256153434835

Epoch: 6| Step: 12
Training loss: 0.25173914432525635
Validation loss: 1.646183176707196

Epoch: 6| Step: 13
Training loss: 0.18812185525894165
Validation loss: 1.682615949261573

Epoch: 416| Step: 0
Training loss: 0.20683573186397552
Validation loss: 1.706043686918033

Epoch: 6| Step: 1
Training loss: 0.16597667336463928
Validation loss: 1.673381668265148

Epoch: 6| Step: 2
Training loss: 0.1328774392604828
Validation loss: 1.6678784534495363

Epoch: 6| Step: 3
Training loss: 0.26371657848358154
Validation loss: 1.6754591093268445

Epoch: 6| Step: 4
Training loss: 0.15883739292621613
Validation loss: 1.672616248489708

Epoch: 6| Step: 5
Training loss: 0.3377258777618408
Validation loss: 1.6662839317834506

Epoch: 6| Step: 6
Training loss: 0.3587632179260254
Validation loss: 1.6362626193672098

Epoch: 6| Step: 7
Training loss: 0.18715044856071472
Validation loss: 1.636494034080095

Epoch: 6| Step: 8
Training loss: 0.10788433253765106
Validation loss: 1.622668311160098

Epoch: 6| Step: 9
Training loss: 0.18579325079917908
Validation loss: 1.6387884437396962

Epoch: 6| Step: 10
Training loss: 0.23609477281570435
Validation loss: 1.6160871213482273

Epoch: 6| Step: 11
Training loss: 0.20319798588752747
Validation loss: 1.594487113337363

Epoch: 6| Step: 12
Training loss: 0.16477270424365997
Validation loss: 1.6231115005349601

Epoch: 6| Step: 13
Training loss: 0.12072534114122391
Validation loss: 1.6176093509120326

Epoch: 417| Step: 0
Training loss: 0.1723567545413971
Validation loss: 1.6300354875544065

Epoch: 6| Step: 1
Training loss: 0.30325502157211304
Validation loss: 1.6242424595740534

Epoch: 6| Step: 2
Training loss: 0.23788470029830933
Validation loss: 1.6522249739657167

Epoch: 6| Step: 3
Training loss: 0.15323658287525177
Validation loss: 1.661660220033379

Epoch: 6| Step: 4
Training loss: 0.36471670866012573
Validation loss: 1.655930817768138

Epoch: 6| Step: 5
Training loss: 0.17464642226696014
Validation loss: 1.638528427770061

Epoch: 6| Step: 6
Training loss: 0.16370512545108795
Validation loss: 1.6589264280052596

Epoch: 6| Step: 7
Training loss: 0.17637699842453003
Validation loss: 1.6680800325127059

Epoch: 6| Step: 8
Training loss: 0.13652752339839935
Validation loss: 1.6369745064807195

Epoch: 6| Step: 9
Training loss: 0.2530396580696106
Validation loss: 1.6482582496058555

Epoch: 6| Step: 10
Training loss: 0.2908654510974884
Validation loss: 1.6751598465827204

Epoch: 6| Step: 11
Training loss: 0.1781957447528839
Validation loss: 1.6367160017772386

Epoch: 6| Step: 12
Training loss: 0.2171483337879181
Validation loss: 1.6116907929861417

Epoch: 6| Step: 13
Training loss: 0.054589781910181046
Validation loss: 1.628403990499435

Epoch: 418| Step: 0
Training loss: 0.1296972632408142
Validation loss: 1.6540735793370072

Epoch: 6| Step: 1
Training loss: 0.25331658124923706
Validation loss: 1.6521417684452508

Epoch: 6| Step: 2
Training loss: 0.2528725862503052
Validation loss: 1.6641714419088056

Epoch: 6| Step: 3
Training loss: 0.20748081803321838
Validation loss: 1.6141184106949837

Epoch: 6| Step: 4
Training loss: 0.21679368615150452
Validation loss: 1.6230319417932981

Epoch: 6| Step: 5
Training loss: 0.36889201402664185
Validation loss: 1.6083540813897246

Epoch: 6| Step: 6
Training loss: 0.25806188583374023
Validation loss: 1.6258783507090744

Epoch: 6| Step: 7
Training loss: 0.23682375252246857
Validation loss: 1.6430708554483229

Epoch: 6| Step: 8
Training loss: 0.15398374199867249
Validation loss: 1.651367461809548

Epoch: 6| Step: 9
Training loss: 0.24467121064662933
Validation loss: 1.653960620203326

Epoch: 6| Step: 10
Training loss: 0.18570566177368164
Validation loss: 1.67590271529331

Epoch: 6| Step: 11
Training loss: 0.15826304256916046
Validation loss: 1.6400818555585799

Epoch: 6| Step: 12
Training loss: 0.16755907237529755
Validation loss: 1.6493067728575839

Epoch: 6| Step: 13
Training loss: 0.2020030915737152
Validation loss: 1.6708196260595833

Epoch: 419| Step: 0
Training loss: 0.15459954738616943
Validation loss: 1.6583439271937135

Epoch: 6| Step: 1
Training loss: 0.19885091483592987
Validation loss: 1.661213597943706

Epoch: 6| Step: 2
Training loss: 0.1904309093952179
Validation loss: 1.6386588875965407

Epoch: 6| Step: 3
Training loss: 0.21921676397323608
Validation loss: 1.666187055649296

Epoch: 6| Step: 4
Training loss: 0.14951619505882263
Validation loss: 1.6350206790431854

Epoch: 6| Step: 5
Training loss: 0.12690788507461548
Validation loss: 1.630959064729752

Epoch: 6| Step: 6
Training loss: 0.16281253099441528
Validation loss: 1.6417018764762468

Epoch: 6| Step: 7
Training loss: 0.2168891727924347
Validation loss: 1.6427836892425374

Epoch: 6| Step: 8
Training loss: 0.456211656332016
Validation loss: 1.6322569295924196

Epoch: 6| Step: 9
Training loss: 0.17003539204597473
Validation loss: 1.613347549592295

Epoch: 6| Step: 10
Training loss: 0.1449427604675293
Validation loss: 1.6004376103801112

Epoch: 6| Step: 11
Training loss: 0.1930658221244812
Validation loss: 1.6227399533794773

Epoch: 6| Step: 12
Training loss: 0.2436659038066864
Validation loss: 1.6056682909688642

Epoch: 6| Step: 13
Training loss: 0.08652797341346741
Validation loss: 1.589398709676599

Epoch: 420| Step: 0
Training loss: 0.18211105465888977
Validation loss: 1.6433235919603737

Epoch: 6| Step: 1
Training loss: 0.1627054512500763
Validation loss: 1.6695525825664561

Epoch: 6| Step: 2
Training loss: 0.12391230463981628
Validation loss: 1.6377804689509894

Epoch: 6| Step: 3
Training loss: 0.12315458059310913
Validation loss: 1.6421942057148102

Epoch: 6| Step: 4
Training loss: 0.12524214386940002
Validation loss: 1.6797099049373339

Epoch: 6| Step: 5
Training loss: 0.2884025275707245
Validation loss: 1.6245566362975745

Epoch: 6| Step: 6
Training loss: 0.2763858437538147
Validation loss: 1.6351773815770303

Epoch: 6| Step: 7
Training loss: 0.12672829627990723
Validation loss: 1.6616495578519759

Epoch: 6| Step: 8
Training loss: 0.18171118199825287
Validation loss: 1.6757545419918594

Epoch: 6| Step: 9
Training loss: 0.19224879145622253
Validation loss: 1.6718548010754328

Epoch: 6| Step: 10
Training loss: 0.22724291682243347
Validation loss: 1.6671604430803688

Epoch: 6| Step: 11
Training loss: 0.22971796989440918
Validation loss: 1.6718099219824678

Epoch: 6| Step: 12
Training loss: 0.20999285578727722
Validation loss: 1.6644177565010645

Epoch: 6| Step: 13
Training loss: 0.10218396782875061
Validation loss: 1.6694052578300558

Epoch: 421| Step: 0
Training loss: 0.20126867294311523
Validation loss: 1.6747473362953431

Epoch: 6| Step: 1
Training loss: 0.2603113353252411
Validation loss: 1.6991205625636603

Epoch: 6| Step: 2
Training loss: 0.20924361050128937
Validation loss: 1.6787972334892518

Epoch: 6| Step: 3
Training loss: 0.18262812495231628
Validation loss: 1.6772983176733858

Epoch: 6| Step: 4
Training loss: 0.17554299533367157
Validation loss: 1.6856936639355076

Epoch: 6| Step: 5
Training loss: 0.38141047954559326
Validation loss: 1.696035728659681

Epoch: 6| Step: 6
Training loss: 0.19886696338653564
Validation loss: 1.6767014976470702

Epoch: 6| Step: 7
Training loss: 0.13428544998168945
Validation loss: 1.7096461813936952

Epoch: 6| Step: 8
Training loss: 0.19895368814468384
Validation loss: 1.700179321791536

Epoch: 6| Step: 9
Training loss: 0.1148127019405365
Validation loss: 1.7114039518499886

Epoch: 6| Step: 10
Training loss: 0.21335166692733765
Validation loss: 1.7021678314414075

Epoch: 6| Step: 11
Training loss: 0.2558078169822693
Validation loss: 1.7005829836732598

Epoch: 6| Step: 12
Training loss: 0.20125579833984375
Validation loss: 1.734955910713442

Epoch: 6| Step: 13
Training loss: 0.14792609214782715
Validation loss: 1.7118339820574688

Epoch: 422| Step: 0
Training loss: 0.2899106442928314
Validation loss: 1.7100234621314592

Epoch: 6| Step: 1
Training loss: 0.1576305627822876
Validation loss: 1.6867523847087738

Epoch: 6| Step: 2
Training loss: 0.1327294409275055
Validation loss: 1.6542724665775095

Epoch: 6| Step: 3
Training loss: 0.28033193945884705
Validation loss: 1.6649138389095184

Epoch: 6| Step: 4
Training loss: 0.11485517024993896
Validation loss: 1.6798098702584543

Epoch: 6| Step: 5
Training loss: 0.0975271463394165
Validation loss: 1.6630836199688654

Epoch: 6| Step: 6
Training loss: 0.14640094339847565
Validation loss: 1.6711002460090063

Epoch: 6| Step: 7
Training loss: 0.261962890625
Validation loss: 1.6504706503242574

Epoch: 6| Step: 8
Training loss: 0.3025517165660858
Validation loss: 1.6584873340463127

Epoch: 6| Step: 9
Training loss: 0.15828359127044678
Validation loss: 1.6397116056052587

Epoch: 6| Step: 10
Training loss: 0.22882869839668274
Validation loss: 1.630310599521924

Epoch: 6| Step: 11
Training loss: 0.17438729107379913
Validation loss: 1.614544617232456

Epoch: 6| Step: 12
Training loss: 0.21996234357357025
Validation loss: 1.6326754657171105

Epoch: 6| Step: 13
Training loss: 0.14274856448173523
Validation loss: 1.6064652640332457

Epoch: 423| Step: 0
Training loss: 0.17019197344779968
Validation loss: 1.6321009878189332

Epoch: 6| Step: 1
Training loss: 0.16922760009765625
Validation loss: 1.6487674879771408

Epoch: 6| Step: 2
Training loss: 0.18357448279857635
Validation loss: 1.6161613368218946

Epoch: 6| Step: 3
Training loss: 0.2163017839193344
Validation loss: 1.6221034129460652

Epoch: 6| Step: 4
Training loss: 0.17417633533477783
Validation loss: 1.6052768896984797

Epoch: 6| Step: 5
Training loss: 0.26726752519607544
Validation loss: 1.6218684014453684

Epoch: 6| Step: 6
Training loss: 0.2876151204109192
Validation loss: 1.6079284144986061

Epoch: 6| Step: 7
Training loss: 0.22656944394111633
Validation loss: 1.6161711369791338

Epoch: 6| Step: 8
Training loss: 0.1746443510055542
Validation loss: 1.6203715083419636

Epoch: 6| Step: 9
Training loss: 0.1239762082695961
Validation loss: 1.6305040736352243

Epoch: 6| Step: 10
Training loss: 0.12502509355545044
Validation loss: 1.6356957368953253

Epoch: 6| Step: 11
Training loss: 0.13264736533164978
Validation loss: 1.6176337003707886

Epoch: 6| Step: 12
Training loss: 0.2776145339012146
Validation loss: 1.5838315102361864

Epoch: 6| Step: 13
Training loss: 0.251249760389328
Validation loss: 1.5631810977894773

Epoch: 424| Step: 0
Training loss: 0.16687490046024323
Validation loss: 1.5811867496018768

Epoch: 6| Step: 1
Training loss: 0.16087019443511963
Validation loss: 1.578961423648301

Epoch: 6| Step: 2
Training loss: 0.27847999334335327
Validation loss: 1.565402320636216

Epoch: 6| Step: 3
Training loss: 0.23177340626716614
Validation loss: 1.5845712513052008

Epoch: 6| Step: 4
Training loss: 0.13026821613311768
Validation loss: 1.5740309210233792

Epoch: 6| Step: 5
Training loss: 0.19893649220466614
Validation loss: 1.5982928974654085

Epoch: 6| Step: 6
Training loss: 0.23328129947185516
Validation loss: 1.5787073489158385

Epoch: 6| Step: 7
Training loss: 0.2745382785797119
Validation loss: 1.6129257986622472

Epoch: 6| Step: 8
Training loss: 0.1561919003725052
Validation loss: 1.6231820711525538

Epoch: 6| Step: 9
Training loss: 0.21013550460338593
Validation loss: 1.6697602297670098

Epoch: 6| Step: 10
Training loss: 0.2920929193496704
Validation loss: 1.6624805004365983

Epoch: 6| Step: 11
Training loss: 0.28264960646629333
Validation loss: 1.6998520769098753

Epoch: 6| Step: 12
Training loss: 0.12254169583320618
Validation loss: 1.6416012240994362

Epoch: 6| Step: 13
Training loss: 0.15934628248214722
Validation loss: 1.6786343339950807

Epoch: 425| Step: 0
Training loss: 0.2507569193840027
Validation loss: 1.6469151089268346

Epoch: 6| Step: 1
Training loss: 0.12340019643306732
Validation loss: 1.5995500587647962

Epoch: 6| Step: 2
Training loss: 0.22889304161071777
Validation loss: 1.600124777004283

Epoch: 6| Step: 3
Training loss: 0.11517158150672913
Validation loss: 1.5983147826246036

Epoch: 6| Step: 4
Training loss: 0.16632017493247986
Validation loss: 1.572564455770677

Epoch: 6| Step: 5
Training loss: 0.17942379415035248
Validation loss: 1.6281969624180948

Epoch: 6| Step: 6
Training loss: 0.20428913831710815
Validation loss: 1.6257303901897964

Epoch: 6| Step: 7
Training loss: 0.2474251091480255
Validation loss: 1.642404346055882

Epoch: 6| Step: 8
Training loss: 0.18489359319210052
Validation loss: 1.6228844901566863

Epoch: 6| Step: 9
Training loss: 0.21527156233787537
Validation loss: 1.6391773377695391

Epoch: 6| Step: 10
Training loss: 0.10561257600784302
Validation loss: 1.6550721891464726

Epoch: 6| Step: 11
Training loss: 0.2506662607192993
Validation loss: 1.6771081545019662

Epoch: 6| Step: 12
Training loss: 0.08952587842941284
Validation loss: 1.6535175859287221

Epoch: 6| Step: 13
Training loss: 0.09684865921735764
Validation loss: 1.7066864249526814

Epoch: 426| Step: 0
Training loss: 0.23718838393688202
Validation loss: 1.6814651899440314

Epoch: 6| Step: 1
Training loss: 0.08973725140094757
Validation loss: 1.6987714703365038

Epoch: 6| Step: 2
Training loss: 0.21261273324489594
Validation loss: 1.70596214648216

Epoch: 6| Step: 3
Training loss: 0.20733386278152466
Validation loss: 1.7262969209301857

Epoch: 6| Step: 4
Training loss: 0.19215911626815796
Validation loss: 1.6968715972797845

Epoch: 6| Step: 5
Training loss: 0.16676941514015198
Validation loss: 1.729232935495274

Epoch: 6| Step: 6
Training loss: 0.2877674102783203
Validation loss: 1.656862788302924

Epoch: 6| Step: 7
Training loss: 0.16710439324378967
Validation loss: 1.6633954842885335

Epoch: 6| Step: 8
Training loss: 0.14089557528495789
Validation loss: 1.632670271781183

Epoch: 6| Step: 9
Training loss: 0.1137809008359909
Validation loss: 1.6250859409250238

Epoch: 6| Step: 10
Training loss: 0.2166007161140442
Validation loss: 1.6361113248332855

Epoch: 6| Step: 11
Training loss: 0.23823975026607513
Validation loss: 1.6039156913757324

Epoch: 6| Step: 12
Training loss: 0.12538518011569977
Validation loss: 1.598053882198949

Epoch: 6| Step: 13
Training loss: 0.14863534271717072
Validation loss: 1.5827052823958858

Epoch: 427| Step: 0
Training loss: 0.15418940782546997
Validation loss: 1.581308505868399

Epoch: 6| Step: 1
Training loss: 0.1890530288219452
Validation loss: 1.5532844643439017

Epoch: 6| Step: 2
Training loss: 0.17502346634864807
Validation loss: 1.5558855648963683

Epoch: 6| Step: 3
Training loss: 0.18256224691867828
Validation loss: 1.5685317670145342

Epoch: 6| Step: 4
Training loss: 0.19268769025802612
Validation loss: 1.605304697508453

Epoch: 6| Step: 5
Training loss: 0.17705722153186798
Validation loss: 1.6083946381845782

Epoch: 6| Step: 6
Training loss: 0.2849079668521881
Validation loss: 1.60061058562289

Epoch: 6| Step: 7
Training loss: 0.09008634090423584
Validation loss: 1.649818854947244

Epoch: 6| Step: 8
Training loss: 0.11494803428649902
Validation loss: 1.6812184446601457

Epoch: 6| Step: 9
Training loss: 0.20562610030174255
Validation loss: 1.6326702922903082

Epoch: 6| Step: 10
Training loss: 0.1514100730419159
Validation loss: 1.6045893417891635

Epoch: 6| Step: 11
Training loss: 0.2505509853363037
Validation loss: 1.6459618537656722

Epoch: 6| Step: 12
Training loss: 0.10707665234804153
Validation loss: 1.6206340148884764

Epoch: 6| Step: 13
Training loss: 0.3668537735939026
Validation loss: 1.626948384828465

Epoch: 428| Step: 0
Training loss: 0.12729737162590027
Validation loss: 1.6505849963875228

Epoch: 6| Step: 1
Training loss: 0.13016928732395172
Validation loss: 1.638810799967858

Epoch: 6| Step: 2
Training loss: 0.22587351500988007
Validation loss: 1.6428532331220564

Epoch: 6| Step: 3
Training loss: 0.3384037911891937
Validation loss: 1.64300299075342

Epoch: 6| Step: 4
Training loss: 0.11528878659009933
Validation loss: 1.6590099244989374

Epoch: 6| Step: 5
Training loss: 0.1397342085838318
Validation loss: 1.6628525282747002

Epoch: 6| Step: 6
Training loss: 0.32653650641441345
Validation loss: 1.635845918809214

Epoch: 6| Step: 7
Training loss: 0.1866702437400818
Validation loss: 1.6675450635212723

Epoch: 6| Step: 8
Training loss: 0.2399691343307495
Validation loss: 1.636924187342326

Epoch: 6| Step: 9
Training loss: 0.24678733944892883
Validation loss: 1.6510294265644525

Epoch: 6| Step: 10
Training loss: 0.23111014068126678
Validation loss: 1.684123682719405

Epoch: 6| Step: 11
Training loss: 0.20838607847690582
Validation loss: 1.6469942356950493

Epoch: 6| Step: 12
Training loss: 0.11279211938381195
Validation loss: 1.6578608353932698

Epoch: 6| Step: 13
Training loss: 0.16804708540439606
Validation loss: 1.6352544612781976

Epoch: 429| Step: 0
Training loss: 0.16490204632282257
Validation loss: 1.601290105491556

Epoch: 6| Step: 1
Training loss: 0.1684299260377884
Validation loss: 1.590113502676769

Epoch: 6| Step: 2
Training loss: 0.224652498960495
Validation loss: 1.6040659899352698

Epoch: 6| Step: 3
Training loss: 0.13269832730293274
Validation loss: 1.5719723432294783

Epoch: 6| Step: 4
Training loss: 0.28587979078292847
Validation loss: 1.5808309560180993

Epoch: 6| Step: 5
Training loss: 0.2147296667098999
Validation loss: 1.5603713784166562

Epoch: 6| Step: 6
Training loss: 0.14591851830482483
Validation loss: 1.5508400047979047

Epoch: 6| Step: 7
Training loss: 0.20059731602668762
Validation loss: 1.5756271116195186

Epoch: 6| Step: 8
Training loss: 0.13499948382377625
Validation loss: 1.5963651659668132

Epoch: 6| Step: 9
Training loss: 0.2240331768989563
Validation loss: 1.598773749925757

Epoch: 6| Step: 10
Training loss: 0.19260290265083313
Validation loss: 1.6166899152981338

Epoch: 6| Step: 11
Training loss: 0.32234877347946167
Validation loss: 1.6108676297690279

Epoch: 6| Step: 12
Training loss: 0.2325240969657898
Validation loss: 1.6708035815146662

Epoch: 6| Step: 13
Training loss: 0.1507881134748459
Validation loss: 1.6479128752985308

Epoch: 430| Step: 0
Training loss: 0.1651868224143982
Validation loss: 1.643886734080571

Epoch: 6| Step: 1
Training loss: 0.14882856607437134
Validation loss: 1.6580013126455329

Epoch: 6| Step: 2
Training loss: 0.11496336758136749
Validation loss: 1.6727644320457213

Epoch: 6| Step: 3
Training loss: 0.26467984914779663
Validation loss: 1.6429081027225783

Epoch: 6| Step: 4
Training loss: 0.15997150540351868
Validation loss: 1.6632038470237487

Epoch: 6| Step: 5
Training loss: 0.13137760758399963
Validation loss: 1.6718807053822342

Epoch: 6| Step: 6
Training loss: 0.2515800893306732
Validation loss: 1.652197052073735

Epoch: 6| Step: 7
Training loss: 0.12964117527008057
Validation loss: 1.6492747786224529

Epoch: 6| Step: 8
Training loss: 0.16936038434505463
Validation loss: 1.6235051257635957

Epoch: 6| Step: 9
Training loss: 0.20263853669166565
Validation loss: 1.6336088026723554

Epoch: 6| Step: 10
Training loss: 0.16310980916023254
Validation loss: 1.6121596726038123

Epoch: 6| Step: 11
Training loss: 0.1486087441444397
Validation loss: 1.6248600444486063

Epoch: 6| Step: 12
Training loss: 0.16155773401260376
Validation loss: 1.6196523327981271

Epoch: 6| Step: 13
Training loss: 0.2091948390007019
Validation loss: 1.5947028154967933

Epoch: 431| Step: 0
Training loss: 0.19773705303668976
Validation loss: 1.6136245458356795

Epoch: 6| Step: 1
Training loss: 0.18198618292808533
Validation loss: 1.6198660327542214

Epoch: 6| Step: 2
Training loss: 0.12148316949605942
Validation loss: 1.6503139759904595

Epoch: 6| Step: 3
Training loss: 0.1581578254699707
Validation loss: 1.6512713342584588

Epoch: 6| Step: 4
Training loss: 0.1637750267982483
Validation loss: 1.6401129281649025

Epoch: 6| Step: 5
Training loss: 0.159805029630661
Validation loss: 1.6698779982905234

Epoch: 6| Step: 6
Training loss: 0.15100686252117157
Validation loss: 1.6684435311184134

Epoch: 6| Step: 7
Training loss: 0.1624172478914261
Validation loss: 1.6697832525417369

Epoch: 6| Step: 8
Training loss: 0.1628279834985733
Validation loss: 1.6865774758400456

Epoch: 6| Step: 9
Training loss: 0.22629842162132263
Validation loss: 1.6576288912885933

Epoch: 6| Step: 10
Training loss: 0.19701555371284485
Validation loss: 1.646938822602713

Epoch: 6| Step: 11
Training loss: 0.1740218698978424
Validation loss: 1.6480569531840663

Epoch: 6| Step: 12
Training loss: 0.10154195129871368
Validation loss: 1.597138326655152

Epoch: 6| Step: 13
Training loss: 0.14393335580825806
Validation loss: 1.6205053996014338

Epoch: 432| Step: 0
Training loss: 0.17880147695541382
Validation loss: 1.6345417050905124

Epoch: 6| Step: 1
Training loss: 0.16880999505519867
Validation loss: 1.6084166957486061

Epoch: 6| Step: 2
Training loss: 0.20090356469154358
Validation loss: 1.6252852024570588

Epoch: 6| Step: 3
Training loss: 0.15903356671333313
Validation loss: 1.6432812213897705

Epoch: 6| Step: 4
Training loss: 0.09115506708621979
Validation loss: 1.6117074079411005

Epoch: 6| Step: 5
Training loss: 0.12782888114452362
Validation loss: 1.6535832817836473

Epoch: 6| Step: 6
Training loss: 0.21813331544399261
Validation loss: 1.6468084845491635

Epoch: 6| Step: 7
Training loss: 0.18156129121780396
Validation loss: 1.6886996274353356

Epoch: 6| Step: 8
Training loss: 0.18648867309093475
Validation loss: 1.6792898216555197

Epoch: 6| Step: 9
Training loss: 0.2416805624961853
Validation loss: 1.7077602083965013

Epoch: 6| Step: 10
Training loss: 0.22712992131710052
Validation loss: 1.6642113488207582

Epoch: 6| Step: 11
Training loss: 0.16241933405399323
Validation loss: 1.6998906597014396

Epoch: 6| Step: 12
Training loss: 0.15402847528457642
Validation loss: 1.6771116090077225

Epoch: 6| Step: 13
Training loss: 0.3091071844100952
Validation loss: 1.6391224450962518

Epoch: 433| Step: 0
Training loss: 0.1755153238773346
Validation loss: 1.6755808886661325

Epoch: 6| Step: 1
Training loss: 0.17754000425338745
Validation loss: 1.6411603291829426

Epoch: 6| Step: 2
Training loss: 0.17473827302455902
Validation loss: 1.6673060168502152

Epoch: 6| Step: 3
Training loss: 0.2720555067062378
Validation loss: 1.6622519916103733

Epoch: 6| Step: 4
Training loss: 0.1322306990623474
Validation loss: 1.646118817790862

Epoch: 6| Step: 5
Training loss: 0.1165892481803894
Validation loss: 1.6895028673192507

Epoch: 6| Step: 6
Training loss: 0.1169670969247818
Validation loss: 1.6551533206816642

Epoch: 6| Step: 7
Training loss: 0.26915228366851807
Validation loss: 1.6307477886958788

Epoch: 6| Step: 8
Training loss: 0.14606153964996338
Validation loss: 1.6277109538355181

Epoch: 6| Step: 9
Training loss: 0.11775361001491547
Validation loss: 1.5879796410119662

Epoch: 6| Step: 10
Training loss: 0.16320683062076569
Validation loss: 1.6049042927321566

Epoch: 6| Step: 11
Training loss: 0.21489261090755463
Validation loss: 1.6283928245626471

Epoch: 6| Step: 12
Training loss: 0.1973029375076294
Validation loss: 1.625993206936826

Epoch: 6| Step: 13
Training loss: 0.12907809019088745
Validation loss: 1.5942257168472453

Epoch: 434| Step: 0
Training loss: 0.13697665929794312
Validation loss: 1.6093936299764982

Epoch: 6| Step: 1
Training loss: 0.16941885650157928
Validation loss: 1.6717299370355503

Epoch: 6| Step: 2
Training loss: 0.2086014747619629
Validation loss: 1.6384028503971715

Epoch: 6| Step: 3
Training loss: 0.25024768710136414
Validation loss: 1.6884293287031111

Epoch: 6| Step: 4
Training loss: 0.1737557053565979
Validation loss: 1.6705127287936468

Epoch: 6| Step: 5
Training loss: 0.1428215503692627
Validation loss: 1.6956956707021242

Epoch: 6| Step: 6
Training loss: 0.15597659349441528
Validation loss: 1.651168745051148

Epoch: 6| Step: 7
Training loss: 0.1616661101579666
Validation loss: 1.614208818763815

Epoch: 6| Step: 8
Training loss: 0.29875820875167847
Validation loss: 1.6093847559344383

Epoch: 6| Step: 9
Training loss: 0.1490628719329834
Validation loss: 1.6304270349523073

Epoch: 6| Step: 10
Training loss: 0.13779930770397186
Validation loss: 1.5905067792502783

Epoch: 6| Step: 11
Training loss: 0.10227862000465393
Validation loss: 1.5870482575508855

Epoch: 6| Step: 12
Training loss: 0.11937956511974335
Validation loss: 1.6202432263282038

Epoch: 6| Step: 13
Training loss: 0.10254351794719696
Validation loss: 1.5813804057336622

Epoch: 435| Step: 0
Training loss: 0.1460520625114441
Validation loss: 1.5913793502315399

Epoch: 6| Step: 1
Training loss: 0.16760438680648804
Validation loss: 1.6182910139842699

Epoch: 6| Step: 2
Training loss: 0.05921445041894913
Validation loss: 1.601620029377681

Epoch: 6| Step: 3
Training loss: 0.1658792346715927
Validation loss: 1.6032631961248254

Epoch: 6| Step: 4
Training loss: 0.1437983512878418
Validation loss: 1.6370887358983357

Epoch: 6| Step: 5
Training loss: 0.15252980589866638
Validation loss: 1.6246779490542669

Epoch: 6| Step: 6
Training loss: 0.1820843666791916
Validation loss: 1.6469355674200161

Epoch: 6| Step: 7
Training loss: 0.17055073380470276
Validation loss: 1.67199190714026

Epoch: 6| Step: 8
Training loss: 0.16065822541713715
Validation loss: 1.6597697388741277

Epoch: 6| Step: 9
Training loss: 0.154707133769989
Validation loss: 1.6826385951811267

Epoch: 6| Step: 10
Training loss: 0.12282101809978485
Validation loss: 1.6614372307254421

Epoch: 6| Step: 11
Training loss: 0.24382814764976501
Validation loss: 1.6566929458290018

Epoch: 6| Step: 12
Training loss: 0.18969781696796417
Validation loss: 1.653152581184141

Epoch: 6| Step: 13
Training loss: 0.23669910430908203
Validation loss: 1.6227249509544783

Epoch: 436| Step: 0
Training loss: 0.11765162646770477
Validation loss: 1.6155144206939205

Epoch: 6| Step: 1
Training loss: 0.19234077632427216
Validation loss: 1.6107692590323828

Epoch: 6| Step: 2
Training loss: 0.18580716848373413
Validation loss: 1.63994982165675

Epoch: 6| Step: 3
Training loss: 0.15132613480091095
Validation loss: 1.6723434732806297

Epoch: 6| Step: 4
Training loss: 0.26501309871673584
Validation loss: 1.6423306638194668

Epoch: 6| Step: 5
Training loss: 0.2773655652999878
Validation loss: 1.6343329068153136

Epoch: 6| Step: 6
Training loss: 0.11658544093370438
Validation loss: 1.602341236606721

Epoch: 6| Step: 7
Training loss: 0.19271768629550934
Validation loss: 1.6156988323375743

Epoch: 6| Step: 8
Training loss: 0.13908171653747559
Validation loss: 1.622319943161421

Epoch: 6| Step: 9
Training loss: 0.144332155585289
Validation loss: 1.6095823511000602

Epoch: 6| Step: 10
Training loss: 0.17748665809631348
Validation loss: 1.6043200133949198

Epoch: 6| Step: 11
Training loss: 0.16157248616218567
Validation loss: 1.6042718957829218

Epoch: 6| Step: 12
Training loss: 0.09905121475458145
Validation loss: 1.604135879906275

Epoch: 6| Step: 13
Training loss: 0.1025865375995636
Validation loss: 1.6225311333133328

Epoch: 437| Step: 0
Training loss: 0.1569402515888214
Validation loss: 1.5943435289526497

Epoch: 6| Step: 1
Training loss: 0.24039483070373535
Validation loss: 1.5874993128161277

Epoch: 6| Step: 2
Training loss: 0.16715842485427856
Validation loss: 1.6175808579690996

Epoch: 6| Step: 3
Training loss: 0.28510525822639465
Validation loss: 1.583384516418621

Epoch: 6| Step: 4
Training loss: 0.16094523668289185
Validation loss: 1.6154590332379906

Epoch: 6| Step: 5
Training loss: 0.11698679625988007
Validation loss: 1.5772183684892551

Epoch: 6| Step: 6
Training loss: 0.16624069213867188
Validation loss: 1.5872848943997455

Epoch: 6| Step: 7
Training loss: 0.12028101086616516
Validation loss: 1.5757435214134954

Epoch: 6| Step: 8
Training loss: 0.271793931722641
Validation loss: 1.6152837584095616

Epoch: 6| Step: 9
Training loss: 0.1809823215007782
Validation loss: 1.5736306751928022

Epoch: 6| Step: 10
Training loss: 0.2099873423576355
Validation loss: 1.6235743094516057

Epoch: 6| Step: 11
Training loss: 0.22761386632919312
Validation loss: 1.619807598411396

Epoch: 6| Step: 12
Training loss: 0.17034223675727844
Validation loss: 1.6040041792777278

Epoch: 6| Step: 13
Training loss: 0.16641336679458618
Validation loss: 1.6142401490160214

Epoch: 438| Step: 0
Training loss: 0.1915363371372223
Validation loss: 1.6176063847798172

Epoch: 6| Step: 1
Training loss: 0.10437115281820297
Validation loss: 1.644594689851166

Epoch: 6| Step: 2
Training loss: 0.12486547231674194
Validation loss: 1.6345169980038878

Epoch: 6| Step: 3
Training loss: 0.13937979936599731
Validation loss: 1.660735768656577

Epoch: 6| Step: 4
Training loss: 0.1875254511833191
Validation loss: 1.660237677635685

Epoch: 6| Step: 5
Training loss: 0.14446622133255005
Validation loss: 1.6765526584399644

Epoch: 6| Step: 6
Training loss: 0.20190390944480896
Validation loss: 1.652621482008247

Epoch: 6| Step: 7
Training loss: 0.22781440615653992
Validation loss: 1.6697191653713104

Epoch: 6| Step: 8
Training loss: 0.17649835348129272
Validation loss: 1.6743895725537372

Epoch: 6| Step: 9
Training loss: 0.20318222045898438
Validation loss: 1.6344664776197044

Epoch: 6| Step: 10
Training loss: 0.14207789301872253
Validation loss: 1.6282895880360757

Epoch: 6| Step: 11
Training loss: 0.17178216576576233
Validation loss: 1.6290130102506248

Epoch: 6| Step: 12
Training loss: 0.11193818598985672
Validation loss: 1.6195046876066475

Epoch: 6| Step: 13
Training loss: 0.09461481124162674
Validation loss: 1.6050090238612185

Epoch: 439| Step: 0
Training loss: 0.14308571815490723
Validation loss: 1.6552490213865876

Epoch: 6| Step: 1
Training loss: 0.08398372679948807
Validation loss: 1.6253805211795274

Epoch: 6| Step: 2
Training loss: 0.11801062524318695
Validation loss: 1.5993813391654723

Epoch: 6| Step: 3
Training loss: 0.13420239090919495
Validation loss: 1.629471149495853

Epoch: 6| Step: 4
Training loss: 0.18078598380088806
Validation loss: 1.661964597240571

Epoch: 6| Step: 5
Training loss: 0.1519460678100586
Validation loss: 1.6577932309078913

Epoch: 6| Step: 6
Training loss: 0.128441721200943
Validation loss: 1.659489086879197

Epoch: 6| Step: 7
Training loss: 0.14356626570224762
Validation loss: 1.6574620469923942

Epoch: 6| Step: 8
Training loss: 0.21429210901260376
Validation loss: 1.6189875884722638

Epoch: 6| Step: 9
Training loss: 0.3198438286781311
Validation loss: 1.6151923274481168

Epoch: 6| Step: 10
Training loss: 0.17163121700286865
Validation loss: 1.634513634507374

Epoch: 6| Step: 11
Training loss: 0.13651761412620544
Validation loss: 1.6272695756727649

Epoch: 6| Step: 12
Training loss: 0.08631192892789841
Validation loss: 1.6058260522862917

Epoch: 6| Step: 13
Training loss: 0.08433935046195984
Validation loss: 1.6195883622733496

Epoch: 440| Step: 0
Training loss: 0.2049703150987625
Validation loss: 1.616087644330917

Epoch: 6| Step: 1
Training loss: 0.1690179705619812
Validation loss: 1.6158310251851236

Epoch: 6| Step: 2
Training loss: 0.15356160700321198
Validation loss: 1.6197355280640304

Epoch: 6| Step: 3
Training loss: 0.1900036633014679
Validation loss: 1.6535714185366066

Epoch: 6| Step: 4
Training loss: 0.16777896881103516
Validation loss: 1.6326346371763496

Epoch: 6| Step: 5
Training loss: 0.19275760650634766
Validation loss: 1.6463632455436132

Epoch: 6| Step: 6
Training loss: 0.13095635175704956
Validation loss: 1.6255560151992305

Epoch: 6| Step: 7
Training loss: 0.11567717790603638
Validation loss: 1.6340813098415252

Epoch: 6| Step: 8
Training loss: 0.18503785133361816
Validation loss: 1.6583455416464037

Epoch: 6| Step: 9
Training loss: 0.1533258855342865
Validation loss: 1.6856544940702376

Epoch: 6| Step: 10
Training loss: 0.10615571588277817
Validation loss: 1.6458898154638146

Epoch: 6| Step: 11
Training loss: 0.18043887615203857
Validation loss: 1.6727666406221287

Epoch: 6| Step: 12
Training loss: 0.17436298727989197
Validation loss: 1.698195852259154

Epoch: 6| Step: 13
Training loss: 0.2401970475912094
Validation loss: 1.6691868766661613

Epoch: 441| Step: 0
Training loss: 0.19362977147102356
Validation loss: 1.6906103075191539

Epoch: 6| Step: 1
Training loss: 0.14979562163352966
Validation loss: 1.6717649236802132

Epoch: 6| Step: 2
Training loss: 0.17122729122638702
Validation loss: 1.63870035576564

Epoch: 6| Step: 3
Training loss: 0.15940043330192566
Validation loss: 1.6570395718338669

Epoch: 6| Step: 4
Training loss: 0.1519542932510376
Validation loss: 1.627313958701267

Epoch: 6| Step: 5
Training loss: 0.24827831983566284
Validation loss: 1.6112097809391637

Epoch: 6| Step: 6
Training loss: 0.1335718333721161
Validation loss: 1.640491089513225

Epoch: 6| Step: 7
Training loss: 0.10677642375230789
Validation loss: 1.6241723555390553

Epoch: 6| Step: 8
Training loss: 0.1485276222229004
Validation loss: 1.6043977660517539

Epoch: 6| Step: 9
Training loss: 0.14043466746807098
Validation loss: 1.6027343080889793

Epoch: 6| Step: 10
Training loss: 0.14359810948371887
Validation loss: 1.6057933684318297

Epoch: 6| Step: 11
Training loss: 0.10766056925058365
Validation loss: 1.6184524131077591

Epoch: 6| Step: 12
Training loss: 0.12030066549777985
Validation loss: 1.6093859493091542

Epoch: 6| Step: 13
Training loss: 0.20940080285072327
Validation loss: 1.59670550592484

Epoch: 442| Step: 0
Training loss: 0.16894851624965668
Validation loss: 1.5978514391888854

Epoch: 6| Step: 1
Training loss: 0.17329902946949005
Validation loss: 1.5729468753260951

Epoch: 6| Step: 2
Training loss: 0.2593079209327698
Validation loss: 1.6159973900805238

Epoch: 6| Step: 3
Training loss: 0.14099852740764618
Validation loss: 1.595061291930496

Epoch: 6| Step: 4
Training loss: 0.09894226491451263
Validation loss: 1.5781966620875942

Epoch: 6| Step: 5
Training loss: 0.2459971010684967
Validation loss: 1.590081455887005

Epoch: 6| Step: 6
Training loss: 0.09391051530838013
Validation loss: 1.5993494179940992

Epoch: 6| Step: 7
Training loss: 0.11495517194271088
Validation loss: 1.5989940140836982

Epoch: 6| Step: 8
Training loss: 0.1699753999710083
Validation loss: 1.598411133212428

Epoch: 6| Step: 9
Training loss: 0.17450790107250214
Validation loss: 1.62358650981739

Epoch: 6| Step: 10
Training loss: 0.12088891863822937
Validation loss: 1.5955050760699856

Epoch: 6| Step: 11
Training loss: 0.11518311500549316
Validation loss: 1.6021568954631846

Epoch: 6| Step: 12
Training loss: 0.2568468153476715
Validation loss: 1.5967370566501413

Epoch: 6| Step: 13
Training loss: 0.15090161561965942
Validation loss: 1.5875178075605823

Epoch: 443| Step: 0
Training loss: 0.1068558320403099
Validation loss: 1.6055692921402633

Epoch: 6| Step: 1
Training loss: 0.1329452097415924
Validation loss: 1.6020040435175742

Epoch: 6| Step: 2
Training loss: 0.19999615848064423
Validation loss: 1.564654497049188

Epoch: 6| Step: 3
Training loss: 0.22900569438934326
Validation loss: 1.5710814332449308

Epoch: 6| Step: 4
Training loss: 0.14133532345294952
Validation loss: 1.5809802598850702

Epoch: 6| Step: 5
Training loss: 0.11147823184728622
Validation loss: 1.6071302801050165

Epoch: 6| Step: 6
Training loss: 0.04841399937868118
Validation loss: 1.5825514049940212

Epoch: 6| Step: 7
Training loss: 0.10511124134063721
Validation loss: 1.6491936970782537

Epoch: 6| Step: 8
Training loss: 0.1130094975233078
Validation loss: 1.6062442205285514

Epoch: 6| Step: 9
Training loss: 0.2647511661052704
Validation loss: 1.6181411999528126

Epoch: 6| Step: 10
Training loss: 0.18570730090141296
Validation loss: 1.630321648172153

Epoch: 6| Step: 11
Training loss: 0.2716400921344757
Validation loss: 1.6524288859418643

Epoch: 6| Step: 12
Training loss: 0.2084379643201828
Validation loss: 1.601886571094554

Epoch: 6| Step: 13
Training loss: 0.18718069791793823
Validation loss: 1.6083246533588698

Epoch: 444| Step: 0
Training loss: 0.1356024444103241
Validation loss: 1.577605833930354

Epoch: 6| Step: 1
Training loss: 0.12496872246265411
Validation loss: 1.6071604387734526

Epoch: 6| Step: 2
Training loss: 0.1491515338420868
Validation loss: 1.5513451509578253

Epoch: 6| Step: 3
Training loss: 0.19398483633995056
Validation loss: 1.5562644709822953

Epoch: 6| Step: 4
Training loss: 0.2194768190383911
Validation loss: 1.5705730568978093

Epoch: 6| Step: 5
Training loss: 0.3468385338783264
Validation loss: 1.5841505745405793

Epoch: 6| Step: 6
Training loss: 0.20315060019493103
Validation loss: 1.5915279503791564

Epoch: 6| Step: 7
Training loss: 0.19215652346611023
Validation loss: 1.5814363597541727

Epoch: 6| Step: 8
Training loss: 0.2216833084821701
Validation loss: 1.6101706092075636

Epoch: 6| Step: 9
Training loss: 0.18936455249786377
Validation loss: 1.654172134655778

Epoch: 6| Step: 10
Training loss: 0.1805221438407898
Validation loss: 1.6523814073172949

Epoch: 6| Step: 11
Training loss: 0.23973020911216736
Validation loss: 1.6797700453830022

Epoch: 6| Step: 12
Training loss: 0.18409189581871033
Validation loss: 1.6740587629297727

Epoch: 6| Step: 13
Training loss: 0.10128844529390335
Validation loss: 1.6981438462452223

Epoch: 445| Step: 0
Training loss: 0.20475348830223083
Validation loss: 1.6692244070832447

Epoch: 6| Step: 1
Training loss: 0.2236991822719574
Validation loss: 1.677407083972808

Epoch: 6| Step: 2
Training loss: 0.18752369284629822
Validation loss: 1.6209422490930046

Epoch: 6| Step: 3
Training loss: 0.11854903399944305
Validation loss: 1.5977867457174486

Epoch: 6| Step: 4
Training loss: 0.13823723793029785
Validation loss: 1.613113817348275

Epoch: 6| Step: 5
Training loss: 0.19306576251983643
Validation loss: 1.5860290668343986

Epoch: 6| Step: 6
Training loss: 0.19853074848651886
Validation loss: 1.5882057630887596

Epoch: 6| Step: 7
Training loss: 0.15542596578598022
Validation loss: 1.623529904632158

Epoch: 6| Step: 8
Training loss: 0.208363875746727
Validation loss: 1.5975554373956495

Epoch: 6| Step: 9
Training loss: 0.11695079505443573
Validation loss: 1.5801558340749433

Epoch: 6| Step: 10
Training loss: 0.14882385730743408
Validation loss: 1.5957662725961337

Epoch: 6| Step: 11
Training loss: 0.20810279250144958
Validation loss: 1.586640146470839

Epoch: 6| Step: 12
Training loss: 0.23058705031871796
Validation loss: 1.5972902236446258

Epoch: 6| Step: 13
Training loss: 0.09970512986183167
Validation loss: 1.6026400776319607

Epoch: 446| Step: 0
Training loss: 0.20252272486686707
Validation loss: 1.5821038728119226

Epoch: 6| Step: 1
Training loss: 0.1454164683818817
Validation loss: 1.6175638155270649

Epoch: 6| Step: 2
Training loss: 0.16928303241729736
Validation loss: 1.5894443194071453

Epoch: 6| Step: 3
Training loss: 0.11549634486436844
Validation loss: 1.6088572432917934

Epoch: 6| Step: 4
Training loss: 0.19721069931983948
Validation loss: 1.5867790701568767

Epoch: 6| Step: 5
Training loss: 0.16223004460334778
Validation loss: 1.6034705920885968

Epoch: 6| Step: 6
Training loss: 0.21806877851486206
Validation loss: 1.617043912410736

Epoch: 6| Step: 7
Training loss: 0.13981348276138306
Validation loss: 1.6045768735229329

Epoch: 6| Step: 8
Training loss: 0.11856848001480103
Validation loss: 1.6184014979229178

Epoch: 6| Step: 9
Training loss: 0.1589277982711792
Validation loss: 1.6204358544400943

Epoch: 6| Step: 10
Training loss: 0.16584694385528564
Validation loss: 1.6260922531927786

Epoch: 6| Step: 11
Training loss: 0.08507101237773895
Validation loss: 1.6194066642433085

Epoch: 6| Step: 12
Training loss: 0.1633187234401703
Validation loss: 1.6447963688963203

Epoch: 6| Step: 13
Training loss: 0.13608236610889435
Validation loss: 1.6251146421637586

Epoch: 447| Step: 0
Training loss: 0.16263625025749207
Validation loss: 1.6217810248815885

Epoch: 6| Step: 1
Training loss: 0.14614452421665192
Validation loss: 1.608979074544804

Epoch: 6| Step: 2
Training loss: 0.2377312183380127
Validation loss: 1.6065474620429419

Epoch: 6| Step: 3
Training loss: 0.23932430148124695
Validation loss: 1.6233234020971483

Epoch: 6| Step: 4
Training loss: 0.09719154983758926
Validation loss: 1.5914536163371096

Epoch: 6| Step: 5
Training loss: 0.17228981852531433
Validation loss: 1.6261271046053978

Epoch: 6| Step: 6
Training loss: 0.20341342687606812
Validation loss: 1.573493569127975

Epoch: 6| Step: 7
Training loss: 0.24541419744491577
Validation loss: 1.5746093821781937

Epoch: 6| Step: 8
Training loss: 0.14707475900650024
Validation loss: 1.55760242221176

Epoch: 6| Step: 9
Training loss: 0.12080749869346619
Validation loss: 1.5724338844258299

Epoch: 6| Step: 10
Training loss: 0.10423506796360016
Validation loss: 1.5841063120031869

Epoch: 6| Step: 11
Training loss: 0.1539475917816162
Validation loss: 1.606164627818651

Epoch: 6| Step: 12
Training loss: 0.1797824651002884
Validation loss: 1.6206025897815663

Epoch: 6| Step: 13
Training loss: 0.1909627914428711
Validation loss: 1.6457812055464713

Epoch: 448| Step: 0
Training loss: 0.14125367999076843
Validation loss: 1.6045315983474895

Epoch: 6| Step: 1
Training loss: 0.12455984205007553
Validation loss: 1.5636724374627555

Epoch: 6| Step: 2
Training loss: 0.08428391814231873
Validation loss: 1.5924244260275235

Epoch: 6| Step: 3
Training loss: 0.1705525517463684
Validation loss: 1.599639440095553

Epoch: 6| Step: 4
Training loss: 0.18237683176994324
Validation loss: 1.5945506224068262

Epoch: 6| Step: 5
Training loss: 0.15044119954109192
Validation loss: 1.5811077792157409

Epoch: 6| Step: 6
Training loss: 0.11834870278835297
Validation loss: 1.5927478062209262

Epoch: 6| Step: 7
Training loss: 0.13383811712265015
Validation loss: 1.6282615302711405

Epoch: 6| Step: 8
Training loss: 0.12388260662555695
Validation loss: 1.6319582359765166

Epoch: 6| Step: 9
Training loss: 0.11965353786945343
Validation loss: 1.627355343552046

Epoch: 6| Step: 10
Training loss: 0.19626867771148682
Validation loss: 1.6349215110143025

Epoch: 6| Step: 11
Training loss: 0.21868079900741577
Validation loss: 1.635132367892932

Epoch: 6| Step: 12
Training loss: 0.1570160686969757
Validation loss: 1.6297766111230338

Epoch: 6| Step: 13
Training loss: 0.266435831785202
Validation loss: 1.6264803319848993

Epoch: 449| Step: 0
Training loss: 0.3142489492893219
Validation loss: 1.6434675288456742

Epoch: 6| Step: 1
Training loss: 0.16332852840423584
Validation loss: 1.639736210146258

Epoch: 6| Step: 2
Training loss: 0.15563391149044037
Validation loss: 1.6204704994796424

Epoch: 6| Step: 3
Training loss: 0.10360224545001984
Validation loss: 1.6405020798406293

Epoch: 6| Step: 4
Training loss: 0.18925678730010986
Validation loss: 1.6225352825657013

Epoch: 6| Step: 5
Training loss: 0.13238342106342316
Validation loss: 1.626061285695722

Epoch: 6| Step: 6
Training loss: 0.12475734949111938
Validation loss: 1.6260452475599063

Epoch: 6| Step: 7
Training loss: 0.12832972407341003
Validation loss: 1.621875201502154

Epoch: 6| Step: 8
Training loss: 0.23004050552845
Validation loss: 1.625939078228448

Epoch: 6| Step: 9
Training loss: 0.16336321830749512
Validation loss: 1.5993286217412641

Epoch: 6| Step: 10
Training loss: 0.11334897577762604
Validation loss: 1.5987944103056384

Epoch: 6| Step: 11
Training loss: 0.1177540197968483
Validation loss: 1.599462971892408

Epoch: 6| Step: 12
Training loss: 0.1269664168357849
Validation loss: 1.5792896850134737

Epoch: 6| Step: 13
Training loss: 0.18238414824008942
Validation loss: 1.622036978762637

Epoch: 450| Step: 0
Training loss: 0.32676786184310913
Validation loss: 1.5922034491774857

Epoch: 6| Step: 1
Training loss: 0.153448224067688
Validation loss: 1.6052085750846452

Epoch: 6| Step: 2
Training loss: 0.14934174716472626
Validation loss: 1.6070556948261876

Epoch: 6| Step: 3
Training loss: 0.14290401339530945
Validation loss: 1.650971306267605

Epoch: 6| Step: 4
Training loss: 0.14181604981422424
Validation loss: 1.5835794582161853

Epoch: 6| Step: 5
Training loss: 0.16021962463855743
Validation loss: 1.6158101674049132

Epoch: 6| Step: 6
Training loss: 0.19123575091362
Validation loss: 1.58905807874536

Epoch: 6| Step: 7
Training loss: 0.12228955328464508
Validation loss: 1.5927560816528976

Epoch: 6| Step: 8
Training loss: 0.157770037651062
Validation loss: 1.5944260871538551

Epoch: 6| Step: 9
Training loss: 0.10031679272651672
Validation loss: 1.6029116889481902

Epoch: 6| Step: 10
Training loss: 0.16607798635959625
Validation loss: 1.658248782157898

Epoch: 6| Step: 11
Training loss: 0.2611423134803772
Validation loss: 1.6635234445653937

Epoch: 6| Step: 12
Training loss: 0.21019937098026276
Validation loss: 1.6765978156879384

Epoch: 6| Step: 13
Training loss: 0.15837213397026062
Validation loss: 1.69612552145476

Epoch: 451| Step: 0
Training loss: 0.12651976943016052
Validation loss: 1.6549780073986258

Epoch: 6| Step: 1
Training loss: 0.20576807856559753
Validation loss: 1.6402271806552846

Epoch: 6| Step: 2
Training loss: 0.1372421532869339
Validation loss: 1.687132058605071

Epoch: 6| Step: 3
Training loss: 0.20545876026153564
Validation loss: 1.6638411603948122

Epoch: 6| Step: 4
Training loss: 0.15546834468841553
Validation loss: 1.6534824755883986

Epoch: 6| Step: 5
Training loss: 0.16066737473011017
Validation loss: 1.668359899392692

Epoch: 6| Step: 6
Training loss: 0.13448908925056458
Validation loss: 1.6234050694332327

Epoch: 6| Step: 7
Training loss: 0.13781413435935974
Validation loss: 1.6332838766036495

Epoch: 6| Step: 8
Training loss: 0.17717108130455017
Validation loss: 1.5921649112496326

Epoch: 6| Step: 9
Training loss: 0.18793264031410217
Validation loss: 1.6111637879443426

Epoch: 6| Step: 10
Training loss: 0.15400910377502441
Validation loss: 1.5875388178774106

Epoch: 6| Step: 11
Training loss: 0.1938166320323944
Validation loss: 1.6114457666233022

Epoch: 6| Step: 12
Training loss: 0.1789315938949585
Validation loss: 1.5911702443194646

Epoch: 6| Step: 13
Training loss: 0.17674843966960907
Validation loss: 1.589887704900516

Epoch: 452| Step: 0
Training loss: 0.12558183073997498
Validation loss: 1.6080679534583964

Epoch: 6| Step: 1
Training loss: 0.2030325084924698
Validation loss: 1.566760261853536

Epoch: 6| Step: 2
Training loss: 0.10568017512559891
Validation loss: 1.5892106051086097

Epoch: 6| Step: 3
Training loss: 0.10524650663137436
Validation loss: 1.5673924722979147

Epoch: 6| Step: 4
Training loss: 0.2625904679298401
Validation loss: 1.5958660917897378

Epoch: 6| Step: 5
Training loss: 0.130048468708992
Validation loss: 1.5873959666939192

Epoch: 6| Step: 6
Training loss: 0.2757711410522461
Validation loss: 1.5993784883970856

Epoch: 6| Step: 7
Training loss: 0.21878591179847717
Validation loss: 1.5928088183044105

Epoch: 6| Step: 8
Training loss: 0.1706204116344452
Validation loss: 1.6193144936715402

Epoch: 6| Step: 9
Training loss: 0.0898284912109375
Validation loss: 1.5903174889984952

Epoch: 6| Step: 10
Training loss: 0.1071915328502655
Validation loss: 1.59740964827999

Epoch: 6| Step: 11
Training loss: 0.10134685784578323
Validation loss: 1.6414893378493607

Epoch: 6| Step: 12
Training loss: 0.11997421085834503
Validation loss: 1.6034150469687678

Epoch: 6| Step: 13
Training loss: 0.23669716715812683
Validation loss: 1.641587366339981

Epoch: 453| Step: 0
Training loss: 0.2046000361442566
Validation loss: 1.604973639211347

Epoch: 6| Step: 1
Training loss: 0.09733326733112335
Validation loss: 1.624563532490884

Epoch: 6| Step: 2
Training loss: 0.23828467726707458
Validation loss: 1.5945565854349444

Epoch: 6| Step: 3
Training loss: 0.14345675706863403
Validation loss: 1.6300153655390586

Epoch: 6| Step: 4
Training loss: 0.14016136527061462
Validation loss: 1.578074997471225

Epoch: 6| Step: 5
Training loss: 0.09099481254816055
Validation loss: 1.5918215820866246

Epoch: 6| Step: 6
Training loss: 0.12142493575811386
Validation loss: 1.5928055419716785

Epoch: 6| Step: 7
Training loss: 0.15920960903167725
Validation loss: 1.6077787773583525

Epoch: 6| Step: 8
Training loss: 0.2311345338821411
Validation loss: 1.586209766326412

Epoch: 6| Step: 9
Training loss: 0.15457263588905334
Validation loss: 1.600126843298635

Epoch: 6| Step: 10
Training loss: 0.19371041655540466
Validation loss: 1.612882858963423

Epoch: 6| Step: 11
Training loss: 0.18179503083229065
Validation loss: 1.6041595756366689

Epoch: 6| Step: 12
Training loss: 0.11009542644023895
Validation loss: 1.6126910935166061

Epoch: 6| Step: 13
Training loss: 0.13376100361347198
Validation loss: 1.5769838633075837

Epoch: 454| Step: 0
Training loss: 0.10758834332227707
Validation loss: 1.561741622545386

Epoch: 6| Step: 1
Training loss: 0.10707224905490875
Validation loss: 1.5734384226542648

Epoch: 6| Step: 2
Training loss: 0.14328090846538544
Validation loss: 1.5822661615187121

Epoch: 6| Step: 3
Training loss: 0.0868086963891983
Validation loss: 1.5911083093253515

Epoch: 6| Step: 4
Training loss: 0.17724314332008362
Validation loss: 1.572179114946755

Epoch: 6| Step: 5
Training loss: 0.18192434310913086
Validation loss: 1.5925402628478182

Epoch: 6| Step: 6
Training loss: 0.12358411401510239
Validation loss: 1.5973380663061654

Epoch: 6| Step: 7
Training loss: 0.1487298458814621
Validation loss: 1.5952338992908437

Epoch: 6| Step: 8
Training loss: 0.18404392898082733
Validation loss: 1.6248901403078468

Epoch: 6| Step: 9
Training loss: 0.1306685507297516
Validation loss: 1.6080354682860836

Epoch: 6| Step: 10
Training loss: 0.1330868899822235
Validation loss: 1.5966636955097158

Epoch: 6| Step: 11
Training loss: 0.12898370623588562
Validation loss: 1.6024150412569764

Epoch: 6| Step: 12
Training loss: 0.09470295906066895
Validation loss: 1.6015759719315397

Epoch: 6| Step: 13
Training loss: 0.21134239435195923
Validation loss: 1.635058774743029

Epoch: 455| Step: 0
Training loss: 0.15030354261398315
Validation loss: 1.6279536088307698

Epoch: 6| Step: 1
Training loss: 0.12491567432880402
Validation loss: 1.5846951007843018

Epoch: 6| Step: 2
Training loss: 0.07406746596097946
Validation loss: 1.607601354199071

Epoch: 6| Step: 3
Training loss: 0.11191855370998383
Validation loss: 1.6326658648829306

Epoch: 6| Step: 4
Training loss: 0.1142842024564743
Validation loss: 1.6220283354482343

Epoch: 6| Step: 5
Training loss: 0.10523267090320587
Validation loss: 1.6117165139926377

Epoch: 6| Step: 6
Training loss: 0.07518468797206879
Validation loss: 1.608600535700398

Epoch: 6| Step: 7
Training loss: 0.08019731938838959
Validation loss: 1.5864032327487905

Epoch: 6| Step: 8
Training loss: 0.08778811991214752
Validation loss: 1.5660724063073435

Epoch: 6| Step: 9
Training loss: 0.17166085541248322
Validation loss: 1.5982862493043304

Epoch: 6| Step: 10
Training loss: 0.24393193423748016
Validation loss: 1.5580435837468793

Epoch: 6| Step: 11
Training loss: 0.17072945833206177
Validation loss: 1.575548691134299

Epoch: 6| Step: 12
Training loss: 0.1150432825088501
Validation loss: 1.5731832545290712

Epoch: 6| Step: 13
Training loss: 0.26373612880706787
Validation loss: 1.56265430296621

Epoch: 456| Step: 0
Training loss: 0.11042069643735886
Validation loss: 1.579483812855136

Epoch: 6| Step: 1
Training loss: 0.11155730485916138
Validation loss: 1.5802792169714486

Epoch: 6| Step: 2
Training loss: 0.17480868101119995
Validation loss: 1.5790747955281248

Epoch: 6| Step: 3
Training loss: 0.19941741228103638
Validation loss: 1.5982923571781447

Epoch: 6| Step: 4
Training loss: 0.1964893639087677
Validation loss: 1.5883076178130282

Epoch: 6| Step: 5
Training loss: 0.1818481683731079
Validation loss: 1.5772319891119515

Epoch: 6| Step: 6
Training loss: 0.09669910371303558
Validation loss: 1.5625670033116494

Epoch: 6| Step: 7
Training loss: 0.1398169994354248
Validation loss: 1.5632651416204308

Epoch: 6| Step: 8
Training loss: 0.11540727317333221
Validation loss: 1.5711514719070927

Epoch: 6| Step: 9
Training loss: 0.1027802973985672
Validation loss: 1.549366424801529

Epoch: 6| Step: 10
Training loss: 0.16859635710716248
Validation loss: 1.5592792328967844

Epoch: 6| Step: 11
Training loss: 0.08098320662975311
Validation loss: 1.5771447394483833

Epoch: 6| Step: 12
Training loss: 0.14360150694847107
Validation loss: 1.583161320096703

Epoch: 6| Step: 13
Training loss: 0.08791600167751312
Validation loss: 1.5660588651575067

Epoch: 457| Step: 0
Training loss: 0.10744642466306686
Validation loss: 1.5552388711642193

Epoch: 6| Step: 1
Training loss: 0.21406012773513794
Validation loss: 1.565930861298756

Epoch: 6| Step: 2
Training loss: 0.04280814900994301
Validation loss: 1.5961696691410516

Epoch: 6| Step: 3
Training loss: 0.17823612689971924
Validation loss: 1.5910881809009019

Epoch: 6| Step: 4
Training loss: 0.11641032993793488
Validation loss: 1.5671195996704923

Epoch: 6| Step: 5
Training loss: 0.1118374839425087
Validation loss: 1.580536816709785

Epoch: 6| Step: 6
Training loss: 0.09352376312017441
Validation loss: 1.5635301323347195

Epoch: 6| Step: 7
Training loss: 0.11182044446468353
Validation loss: 1.5949234911190566

Epoch: 6| Step: 8
Training loss: 0.14902211725711823
Validation loss: 1.577078705192894

Epoch: 6| Step: 9
Training loss: 0.0785246342420578
Validation loss: 1.5417588962021695

Epoch: 6| Step: 10
Training loss: 0.12938597798347473
Validation loss: 1.5704157685720792

Epoch: 6| Step: 11
Training loss: 0.11013510823249817
Validation loss: 1.5537056794730566

Epoch: 6| Step: 12
Training loss: 0.22441540658473969
Validation loss: 1.5706153556864748

Epoch: 6| Step: 13
Training loss: 0.3077687621116638
Validation loss: 1.5748823573512416

Epoch: 458| Step: 0
Training loss: 0.1616436243057251
Validation loss: 1.5562123278135895

Epoch: 6| Step: 1
Training loss: 0.16692519187927246
Validation loss: 1.5939891761349094

Epoch: 6| Step: 2
Training loss: 0.15687189996242523
Validation loss: 1.5697037020037252

Epoch: 6| Step: 3
Training loss: 0.15167734026908875
Validation loss: 1.5778305953548801

Epoch: 6| Step: 4
Training loss: 0.25019359588623047
Validation loss: 1.5794290650275447

Epoch: 6| Step: 5
Training loss: 0.1496545672416687
Validation loss: 1.6073212956869474

Epoch: 6| Step: 6
Training loss: 0.1597769409418106
Validation loss: 1.6072789994619225

Epoch: 6| Step: 7
Training loss: 0.12722499668598175
Validation loss: 1.5786663742475613

Epoch: 6| Step: 8
Training loss: 0.17091144621372223
Validation loss: 1.6164315362130441

Epoch: 6| Step: 9
Training loss: 0.20415136218070984
Validation loss: 1.6027052838315246

Epoch: 6| Step: 10
Training loss: 0.1871495544910431
Validation loss: 1.5932333379663446

Epoch: 6| Step: 11
Training loss: 0.32200372219085693
Validation loss: 1.5916092626510128

Epoch: 6| Step: 12
Training loss: 0.10252101719379425
Validation loss: 1.6057760536029775

Epoch: 6| Step: 13
Training loss: 0.06771326065063477
Validation loss: 1.5653281404126076

Epoch: 459| Step: 0
Training loss: 0.09709717333316803
Validation loss: 1.5509899226568078

Epoch: 6| Step: 1
Training loss: 0.14281564950942993
Validation loss: 1.5431598783821188

Epoch: 6| Step: 2
Training loss: 0.10821143537759781
Validation loss: 1.5507077311956754

Epoch: 6| Step: 3
Training loss: 0.1086416020989418
Validation loss: 1.5782976688877228

Epoch: 6| Step: 4
Training loss: 0.17996549606323242
Validation loss: 1.5383904210982784

Epoch: 6| Step: 5
Training loss: 0.11639710515737534
Validation loss: 1.5414235873888897

Epoch: 6| Step: 6
Training loss: 0.17786046862602234
Validation loss: 1.5426944366065405

Epoch: 6| Step: 7
Training loss: 0.15275751054286957
Validation loss: 1.5460189234825872

Epoch: 6| Step: 8
Training loss: 0.134536013007164
Validation loss: 1.552028549614773

Epoch: 6| Step: 9
Training loss: 0.16249245405197144
Validation loss: 1.5620252214452273

Epoch: 6| Step: 10
Training loss: 0.15954580903053284
Validation loss: 1.5779549716621317

Epoch: 6| Step: 11
Training loss: 0.14940005540847778
Validation loss: 1.5965320717903875

Epoch: 6| Step: 12
Training loss: 0.1771077960729599
Validation loss: 1.5671375900186517

Epoch: 6| Step: 13
Training loss: 0.11562763154506683
Validation loss: 1.5803826829438568

Epoch: 460| Step: 0
Training loss: 0.14353138208389282
Validation loss: 1.5958678530108543

Epoch: 6| Step: 1
Training loss: 0.1444639265537262
Validation loss: 1.6093946426145491

Epoch: 6| Step: 2
Training loss: 0.18967363238334656
Validation loss: 1.5867565062738234

Epoch: 6| Step: 3
Training loss: 0.14501772820949554
Validation loss: 1.6282062274153515

Epoch: 6| Step: 4
Training loss: 0.17986983060836792
Validation loss: 1.6176596354412776

Epoch: 6| Step: 5
Training loss: 0.16606022417545319
Validation loss: 1.6763568744864514

Epoch: 6| Step: 6
Training loss: 0.20525003969669342
Validation loss: 1.6264943794537616

Epoch: 6| Step: 7
Training loss: 0.142743319272995
Validation loss: 1.6199396682041947

Epoch: 6| Step: 8
Training loss: 0.10219915211200714
Validation loss: 1.5993818236935524

Epoch: 6| Step: 9
Training loss: 0.06456662714481354
Validation loss: 1.588906982893585

Epoch: 6| Step: 10
Training loss: 0.13962239027023315
Validation loss: 1.6029073986955868

Epoch: 6| Step: 11
Training loss: 0.17978905141353607
Validation loss: 1.6127575712819253

Epoch: 6| Step: 12
Training loss: 0.09373535960912704
Validation loss: 1.6146765639705043

Epoch: 6| Step: 13
Training loss: 0.17231591045856476
Validation loss: 1.5779154441689933

Epoch: 461| Step: 0
Training loss: 0.12504585087299347
Validation loss: 1.586726547569357

Epoch: 6| Step: 1
Training loss: 0.15526804327964783
Validation loss: 1.5728545445267872

Epoch: 6| Step: 2
Training loss: 0.19684183597564697
Validation loss: 1.5789261197531095

Epoch: 6| Step: 3
Training loss: 0.09748329222202301
Validation loss: 1.5903481680859801

Epoch: 6| Step: 4
Training loss: 0.14231252670288086
Validation loss: 1.5954967173196937

Epoch: 6| Step: 5
Training loss: 0.11172422021627426
Validation loss: 1.6066597110481673

Epoch: 6| Step: 6
Training loss: 0.2715049386024475
Validation loss: 1.5982376798506706

Epoch: 6| Step: 7
Training loss: 0.14235621690750122
Validation loss: 1.5922512123661656

Epoch: 6| Step: 8
Training loss: 0.13911451399326324
Validation loss: 1.57832129668164

Epoch: 6| Step: 9
Training loss: 0.10883797705173492
Validation loss: 1.5711438027761315

Epoch: 6| Step: 10
Training loss: 0.1446300745010376
Validation loss: 1.55923326810201

Epoch: 6| Step: 11
Training loss: 0.09680044651031494
Validation loss: 1.588916217127154

Epoch: 6| Step: 12
Training loss: 0.17656420171260834
Validation loss: 1.5938122003309187

Epoch: 6| Step: 13
Training loss: 0.0956319123506546
Validation loss: 1.5832424215091172

Epoch: 462| Step: 0
Training loss: 0.14088431000709534
Validation loss: 1.6334281736804592

Epoch: 6| Step: 1
Training loss: 0.06998829543590546
Validation loss: 1.5966113036678684

Epoch: 6| Step: 2
Training loss: 0.11019792407751083
Validation loss: 1.619780098238299

Epoch: 6| Step: 3
Training loss: 0.1425313651561737
Validation loss: 1.6217423164716331

Epoch: 6| Step: 4
Training loss: 0.12612563371658325
Validation loss: 1.6797965470180716

Epoch: 6| Step: 5
Training loss: 0.21022778749465942
Validation loss: 1.6872581012787358

Epoch: 6| Step: 6
Training loss: 0.1045972928404808
Validation loss: 1.6726789589851134

Epoch: 6| Step: 7
Training loss: 0.1331525444984436
Validation loss: 1.665297269821167

Epoch: 6| Step: 8
Training loss: 0.21342700719833374
Validation loss: 1.6962434604603758

Epoch: 6| Step: 9
Training loss: 0.22899362444877625
Validation loss: 1.636586239261012

Epoch: 6| Step: 10
Training loss: 0.14554569125175476
Validation loss: 1.6224753625931279

Epoch: 6| Step: 11
Training loss: 0.14976540207862854
Validation loss: 1.6103424000483688

Epoch: 6| Step: 12
Training loss: 0.15751129388809204
Validation loss: 1.5930350442086496

Epoch: 6| Step: 13
Training loss: 0.19680459797382355
Validation loss: 1.5875225682412424

Epoch: 463| Step: 0
Training loss: 0.1091727614402771
Validation loss: 1.5963312643830494

Epoch: 6| Step: 1
Training loss: 0.2300407588481903
Validation loss: 1.587311706235332

Epoch: 6| Step: 2
Training loss: 0.12863898277282715
Validation loss: 1.6013140729678574

Epoch: 6| Step: 3
Training loss: 0.16512669622898102
Validation loss: 1.6129785160864554

Epoch: 6| Step: 4
Training loss: 0.1382659673690796
Validation loss: 1.6080431963807793

Epoch: 6| Step: 5
Training loss: 0.24287188053131104
Validation loss: 1.6150207263167187

Epoch: 6| Step: 6
Training loss: 0.1764291375875473
Validation loss: 1.6247371806893298

Epoch: 6| Step: 7
Training loss: 0.1671682447195053
Validation loss: 1.605962545641007

Epoch: 6| Step: 8
Training loss: 0.1096019595861435
Validation loss: 1.6280318665248092

Epoch: 6| Step: 9
Training loss: 0.06772815436124802
Validation loss: 1.6135122468394618

Epoch: 6| Step: 10
Training loss: 0.17618125677108765
Validation loss: 1.6012477977301485

Epoch: 6| Step: 11
Training loss: 0.1255297213792801
Validation loss: 1.6312656876861409

Epoch: 6| Step: 12
Training loss: 0.13962626457214355
Validation loss: 1.598701100836518

Epoch: 6| Step: 13
Training loss: 0.1738918572664261
Validation loss: 1.6016731480116486

Epoch: 464| Step: 0
Training loss: 0.14772364497184753
Validation loss: 1.6061551981074835

Epoch: 6| Step: 1
Training loss: 0.08713553845882416
Validation loss: 1.5692265700268488

Epoch: 6| Step: 2
Training loss: 0.08555923402309418
Validation loss: 1.610158843378867

Epoch: 6| Step: 3
Training loss: 0.14431387186050415
Validation loss: 1.5859246587240567

Epoch: 6| Step: 4
Training loss: 0.17246446013450623
Validation loss: 1.6127560343793643

Epoch: 6| Step: 5
Training loss: 0.18072496354579926
Validation loss: 1.6161268526507961

Epoch: 6| Step: 6
Training loss: 0.14711147546768188
Validation loss: 1.5827071628262919

Epoch: 6| Step: 7
Training loss: 0.204763263463974
Validation loss: 1.565389379378288

Epoch: 6| Step: 8
Training loss: 0.11403094232082367
Validation loss: 1.569187653962002

Epoch: 6| Step: 9
Training loss: 0.12931710481643677
Validation loss: 1.5788162087881437

Epoch: 6| Step: 10
Training loss: 0.19187453389167786
Validation loss: 1.5797074667869075

Epoch: 6| Step: 11
Training loss: 0.10481627285480499
Validation loss: 1.5997635908024286

Epoch: 6| Step: 12
Training loss: 0.15475451946258545
Validation loss: 1.571842339731032

Epoch: 6| Step: 13
Training loss: 0.14408132433891296
Validation loss: 1.5672849685915056

Epoch: 465| Step: 0
Training loss: 0.08447641134262085
Validation loss: 1.557918353747296

Epoch: 6| Step: 1
Training loss: 0.20237785577774048
Validation loss: 1.565812999202359

Epoch: 6| Step: 2
Training loss: 0.10791004449129105
Validation loss: 1.568950435807628

Epoch: 6| Step: 3
Training loss: 0.1416071504354477
Validation loss: 1.5792270142544982

Epoch: 6| Step: 4
Training loss: 0.1812131702899933
Validation loss: 1.5676734960207375

Epoch: 6| Step: 5
Training loss: 0.08601029217243195
Validation loss: 1.5596328371314592

Epoch: 6| Step: 6
Training loss: 0.15199215710163116
Validation loss: 1.5382569746304584

Epoch: 6| Step: 7
Training loss: 0.10345152020454407
Validation loss: 1.5464696525245585

Epoch: 6| Step: 8
Training loss: 0.09263619035482407
Validation loss: 1.5688344112006567

Epoch: 6| Step: 9
Training loss: 0.10943575203418732
Validation loss: 1.5819986520274993

Epoch: 6| Step: 10
Training loss: 0.08247427642345428
Validation loss: 1.577447948917266

Epoch: 6| Step: 11
Training loss: 0.10342605412006378
Validation loss: 1.5871294044679212

Epoch: 6| Step: 12
Training loss: 0.19757932424545288
Validation loss: 1.5680370766629455

Epoch: 6| Step: 13
Training loss: 0.15738460421562195
Validation loss: 1.5486924494466474

Epoch: 466| Step: 0
Training loss: 0.06203830987215042
Validation loss: 1.571693749837978

Epoch: 6| Step: 1
Training loss: 0.08908937126398087
Validation loss: 1.5901843937494422

Epoch: 6| Step: 2
Training loss: 0.05691004917025566
Validation loss: 1.5415081721480175

Epoch: 6| Step: 3
Training loss: 0.13430818915367126
Validation loss: 1.566229861269715

Epoch: 6| Step: 4
Training loss: 0.14343507587909698
Validation loss: 1.5750556325399747

Epoch: 6| Step: 5
Training loss: 0.14372317492961884
Validation loss: 1.5773712768349597

Epoch: 6| Step: 6
Training loss: 0.08566655218601227
Validation loss: 1.5665299584788661

Epoch: 6| Step: 7
Training loss: 0.16900235414505005
Validation loss: 1.596542041788819

Epoch: 6| Step: 8
Training loss: 0.08033358305692673
Validation loss: 1.627730497749903

Epoch: 6| Step: 9
Training loss: 0.11996332556009293
Validation loss: 1.5941306134705902

Epoch: 6| Step: 10
Training loss: 0.0711706280708313
Validation loss: 1.5911774942951817

Epoch: 6| Step: 11
Training loss: 0.22164911031723022
Validation loss: 1.5990203695912515

Epoch: 6| Step: 12
Training loss: 0.10998440533876419
Validation loss: 1.6041290529312626

Epoch: 6| Step: 13
Training loss: 0.10538777709007263
Validation loss: 1.5914637061857408

Epoch: 467| Step: 0
Training loss: 0.10729561001062393
Validation loss: 1.6135159961638912

Epoch: 6| Step: 1
Training loss: 0.11672145128250122
Validation loss: 1.5986211684442335

Epoch: 6| Step: 2
Training loss: 0.053855348378419876
Validation loss: 1.5926384925842285

Epoch: 6| Step: 3
Training loss: 0.14717471599578857
Validation loss: 1.5837892665657947

Epoch: 6| Step: 4
Training loss: 0.1053566038608551
Validation loss: 1.5637067184653333

Epoch: 6| Step: 5
Training loss: 0.13326624035835266
Validation loss: 1.6025677586114535

Epoch: 6| Step: 6
Training loss: 0.09973184764385223
Validation loss: 1.5958953096020607

Epoch: 6| Step: 7
Training loss: 0.0927986428141594
Validation loss: 1.5735287563775175

Epoch: 6| Step: 8
Training loss: 0.12384607642889023
Validation loss: 1.5807871728815057

Epoch: 6| Step: 9
Training loss: 0.15856939554214478
Validation loss: 1.5594302108210902

Epoch: 6| Step: 10
Training loss: 0.13268952071666718
Validation loss: 1.5877835699307021

Epoch: 6| Step: 11
Training loss: 0.0657544881105423
Validation loss: 1.6123428280635546

Epoch: 6| Step: 12
Training loss: 0.0871267169713974
Validation loss: 1.590436694442585

Epoch: 6| Step: 13
Training loss: 0.1373240351676941
Validation loss: 1.6245886830873386

Epoch: 468| Step: 0
Training loss: 0.09499332308769226
Validation loss: 1.5895412378413702

Epoch: 6| Step: 1
Training loss: 0.07691633701324463
Validation loss: 1.6069326644302697

Epoch: 6| Step: 2
Training loss: 0.06421537697315216
Validation loss: 1.6003418866024222

Epoch: 6| Step: 3
Training loss: 0.1172444298863411
Validation loss: 1.6054431828119422

Epoch: 6| Step: 4
Training loss: 0.1373976618051529
Validation loss: 1.6049349654105403

Epoch: 6| Step: 5
Training loss: 0.1976693868637085
Validation loss: 1.6249561284178047

Epoch: 6| Step: 6
Training loss: 0.19238680601119995
Validation loss: 1.611457565779327

Epoch: 6| Step: 7
Training loss: 0.17201733589172363
Validation loss: 1.5928142673225814

Epoch: 6| Step: 8
Training loss: 0.10646196454763412
Validation loss: 1.6051953569535287

Epoch: 6| Step: 9
Training loss: 0.1182098314166069
Validation loss: 1.6109850906556653

Epoch: 6| Step: 10
Training loss: 0.09048380702733994
Validation loss: 1.6190304422891268

Epoch: 6| Step: 11
Training loss: 0.10819602757692337
Validation loss: 1.6083152935069094

Epoch: 6| Step: 12
Training loss: 0.07060623168945312
Validation loss: 1.614193215165087

Epoch: 6| Step: 13
Training loss: 0.20967642962932587
Validation loss: 1.6437382980059552

Epoch: 469| Step: 0
Training loss: 0.07804172486066818
Validation loss: 1.6308278396565428

Epoch: 6| Step: 1
Training loss: 0.12466052919626236
Validation loss: 1.6087661789309593

Epoch: 6| Step: 2
Training loss: 0.12043476849794388
Validation loss: 1.6076022348096293

Epoch: 6| Step: 3
Training loss: 0.1927867829799652
Validation loss: 1.598474499999836

Epoch: 6| Step: 4
Training loss: 0.11970150470733643
Validation loss: 1.5785130057283627

Epoch: 6| Step: 5
Training loss: 0.10774117708206177
Validation loss: 1.6034456709379792

Epoch: 6| Step: 6
Training loss: 0.1477624773979187
Validation loss: 1.5858626570752872

Epoch: 6| Step: 7
Training loss: 0.079900823533535
Validation loss: 1.6001796978776173

Epoch: 6| Step: 8
Training loss: 0.09240572899580002
Validation loss: 1.5832606028485041

Epoch: 6| Step: 9
Training loss: 0.14879685640335083
Validation loss: 1.6176206745127195

Epoch: 6| Step: 10
Training loss: 0.08502049744129181
Validation loss: 1.6186470972594393

Epoch: 6| Step: 11
Training loss: 0.10508965700864792
Validation loss: 1.608383091547156

Epoch: 6| Step: 12
Training loss: 0.21094894409179688
Validation loss: 1.5976348974371468

Epoch: 6| Step: 13
Training loss: 0.16086813807487488
Validation loss: 1.591683836393459

Epoch: 470| Step: 0
Training loss: 0.12977667152881622
Validation loss: 1.571231226767263

Epoch: 6| Step: 1
Training loss: 0.08641936630010605
Validation loss: 1.5793597031665105

Epoch: 6| Step: 2
Training loss: 0.11079229414463043
Validation loss: 1.564364888334787

Epoch: 6| Step: 3
Training loss: 0.1209174320101738
Validation loss: 1.5573464055215158

Epoch: 6| Step: 4
Training loss: 0.13409042358398438
Validation loss: 1.529276837584793

Epoch: 6| Step: 5
Training loss: 0.19272568821907043
Validation loss: 1.5457580320296749

Epoch: 6| Step: 6
Training loss: 0.11431577801704407
Validation loss: 1.524887183661102

Epoch: 6| Step: 7
Training loss: 0.13548192381858826
Validation loss: 1.5342884448266798

Epoch: 6| Step: 8
Training loss: 0.08377282321453094
Validation loss: 1.5433785184737174

Epoch: 6| Step: 9
Training loss: 0.06589576601982117
Validation loss: 1.5596427661116405

Epoch: 6| Step: 10
Training loss: 0.17765411734580994
Validation loss: 1.5717324941389021

Epoch: 6| Step: 11
Training loss: 0.0947137400507927
Validation loss: 1.5729633928627096

Epoch: 6| Step: 12
Training loss: 0.1815747171640396
Validation loss: 1.5848231841159124

Epoch: 6| Step: 13
Training loss: 0.09762229025363922
Validation loss: 1.5832619179961502

Epoch: 471| Step: 0
Training loss: 0.13305987417697906
Validation loss: 1.5798973601351503

Epoch: 6| Step: 1
Training loss: 0.13952139019966125
Validation loss: 1.5952409211025442

Epoch: 6| Step: 2
Training loss: 0.17898328602313995
Validation loss: 1.5490063915970504

Epoch: 6| Step: 3
Training loss: 0.13447785377502441
Validation loss: 1.5642860512579642

Epoch: 6| Step: 4
Training loss: 0.12352173775434494
Validation loss: 1.5801982072091871

Epoch: 6| Step: 5
Training loss: 0.12428133189678192
Validation loss: 1.5924394194797804

Epoch: 6| Step: 6
Training loss: 0.12575878202915192
Validation loss: 1.5801794464870165

Epoch: 6| Step: 7
Training loss: 0.22680073976516724
Validation loss: 1.5660393135522002

Epoch: 6| Step: 8
Training loss: 0.08160710334777832
Validation loss: 1.5763493994230866

Epoch: 6| Step: 9
Training loss: 0.1220703125
Validation loss: 1.5674158988460418

Epoch: 6| Step: 10
Training loss: 0.20114868879318237
Validation loss: 1.5731375102073915

Epoch: 6| Step: 11
Training loss: 0.17033842206001282
Validation loss: 1.568454041275927

Epoch: 6| Step: 12
Training loss: 0.09145094454288483
Validation loss: 1.5584581462285851

Epoch: 6| Step: 13
Training loss: 0.06778290867805481
Validation loss: 1.5623889456513107

Epoch: 472| Step: 0
Training loss: 0.14026552438735962
Validation loss: 1.5844585664810673

Epoch: 6| Step: 1
Training loss: 0.09582474827766418
Validation loss: 1.5543581670330417

Epoch: 6| Step: 2
Training loss: 0.12908273935317993
Validation loss: 1.5631912683927884

Epoch: 6| Step: 3
Training loss: 0.0635184496641159
Validation loss: 1.5849980846528084

Epoch: 6| Step: 4
Training loss: 0.10754178464412689
Validation loss: 1.5759490971924157

Epoch: 6| Step: 5
Training loss: 0.15600265562534332
Validation loss: 1.5837432504982076

Epoch: 6| Step: 6
Training loss: 0.08170156180858612
Validation loss: 1.5807701926077566

Epoch: 6| Step: 7
Training loss: 0.12237055599689484
Validation loss: 1.6083522996594828

Epoch: 6| Step: 8
Training loss: 0.09088413417339325
Validation loss: 1.5964523617939284

Epoch: 6| Step: 9
Training loss: 0.12292648106813431
Validation loss: 1.606262565940939

Epoch: 6| Step: 10
Training loss: 0.14755694568157196
Validation loss: 1.5975040684464157

Epoch: 6| Step: 11
Training loss: 0.10391517728567123
Validation loss: 1.5620858009143541

Epoch: 6| Step: 12
Training loss: 0.1754901111125946
Validation loss: 1.5836977625405917

Epoch: 6| Step: 13
Training loss: 0.13578154146671295
Validation loss: 1.5753272592380483

Epoch: 473| Step: 0
Training loss: 0.26077035069465637
Validation loss: 1.5593085007000995

Epoch: 6| Step: 1
Training loss: 0.2291320264339447
Validation loss: 1.5501275370197911

Epoch: 6| Step: 2
Training loss: 0.07126539200544357
Validation loss: 1.5766870091038365

Epoch: 6| Step: 3
Training loss: 0.17193642258644104
Validation loss: 1.59017869733995

Epoch: 6| Step: 4
Training loss: 0.1363452970981598
Validation loss: 1.5720219906940256

Epoch: 6| Step: 5
Training loss: 0.06855179369449615
Validation loss: 1.604798150318925

Epoch: 6| Step: 6
Training loss: 0.14701899886131287
Validation loss: 1.5748206466756842

Epoch: 6| Step: 7
Training loss: 0.04079662635922432
Validation loss: 1.5799959064811788

Epoch: 6| Step: 8
Training loss: 0.06229003146290779
Validation loss: 1.5796760371936265

Epoch: 6| Step: 9
Training loss: 0.13147303462028503
Validation loss: 1.5773623130654777

Epoch: 6| Step: 10
Training loss: 0.07648855447769165
Validation loss: 1.5819154862434632

Epoch: 6| Step: 11
Training loss: 0.10362270474433899
Validation loss: 1.5425363234294358

Epoch: 6| Step: 12
Training loss: 0.08800577372312546
Validation loss: 1.588227218197238

Epoch: 6| Step: 13
Training loss: 0.07395252585411072
Validation loss: 1.5674827150119248

Epoch: 474| Step: 0
Training loss: 0.09640993177890778
Validation loss: 1.5502662043417654

Epoch: 6| Step: 1
Training loss: 0.11282260715961456
Validation loss: 1.5219045531365178

Epoch: 6| Step: 2
Training loss: 0.13446354866027832
Validation loss: 1.531397097854204

Epoch: 6| Step: 3
Training loss: 0.12657888233661652
Validation loss: 1.5192382745845343

Epoch: 6| Step: 4
Training loss: 0.05622323974967003
Validation loss: 1.5360154759499334

Epoch: 6| Step: 5
Training loss: 0.06483565270900726
Validation loss: 1.538330130679633

Epoch: 6| Step: 6
Training loss: 0.08092173933982849
Validation loss: 1.585201258300453

Epoch: 6| Step: 7
Training loss: 0.138168603181839
Validation loss: 1.559484702284618

Epoch: 6| Step: 8
Training loss: 0.14073622226715088
Validation loss: 1.5618637479761595

Epoch: 6| Step: 9
Training loss: 0.09987561404705048
Validation loss: 1.5673479854419667

Epoch: 6| Step: 10
Training loss: 0.147745281457901
Validation loss: 1.5522689280971405

Epoch: 6| Step: 11
Training loss: 0.1370674967765808
Validation loss: 1.5704217085274317

Epoch: 6| Step: 12
Training loss: 0.19607728719711304
Validation loss: 1.5927358814465102

Epoch: 6| Step: 13
Training loss: 0.035341110080480576
Validation loss: 1.602746909023613

Epoch: 475| Step: 0
Training loss: 0.06265422701835632
Validation loss: 1.5938723343674854

Epoch: 6| Step: 1
Training loss: 0.1169949546456337
Validation loss: 1.5873281814718758

Epoch: 6| Step: 2
Training loss: 0.12226992100477219
Validation loss: 1.5935197722527288

Epoch: 6| Step: 3
Training loss: 0.10744081437587738
Validation loss: 1.6306900388451033

Epoch: 6| Step: 4
Training loss: 0.06786100566387177
Validation loss: 1.5982892051819833

Epoch: 6| Step: 5
Training loss: 0.11534172296524048
Validation loss: 1.5971184571584065

Epoch: 6| Step: 6
Training loss: 0.12486954778432846
Validation loss: 1.6057459244164087

Epoch: 6| Step: 7
Training loss: 0.1076631098985672
Validation loss: 1.6091583467298938

Epoch: 6| Step: 8
Training loss: 0.12860578298568726
Validation loss: 1.604334008309149

Epoch: 6| Step: 9
Training loss: 0.08902551233768463
Validation loss: 1.5858377769429197

Epoch: 6| Step: 10
Training loss: 0.18248850107192993
Validation loss: 1.5894133455009871

Epoch: 6| Step: 11
Training loss: 0.13641357421875
Validation loss: 1.5923617732140325

Epoch: 6| Step: 12
Training loss: 0.0986032485961914
Validation loss: 1.5811292740606493

Epoch: 6| Step: 13
Training loss: 0.2601795792579651
Validation loss: 1.5440679545043616

Epoch: 476| Step: 0
Training loss: 0.10612513870000839
Validation loss: 1.5838779813499861

Epoch: 6| Step: 1
Training loss: 0.1323940008878708
Validation loss: 1.5769612327698739

Epoch: 6| Step: 2
Training loss: 0.06947644054889679
Validation loss: 1.5565745317807762

Epoch: 6| Step: 3
Training loss: 0.058803822845220566
Validation loss: 1.5799490328757995

Epoch: 6| Step: 4
Training loss: 0.07948622107505798
Validation loss: 1.5539740157383743

Epoch: 6| Step: 5
Training loss: 0.17390131950378418
Validation loss: 1.5648571611732565

Epoch: 6| Step: 6
Training loss: 0.15225505828857422
Validation loss: 1.5699776231601674

Epoch: 6| Step: 7
Training loss: 0.12233871966600418
Validation loss: 1.5851184655261297

Epoch: 6| Step: 8
Training loss: 0.08343376964330673
Validation loss: 1.5982470755935998

Epoch: 6| Step: 9
Training loss: 0.09740705043077469
Validation loss: 1.58466516130714

Epoch: 6| Step: 10
Training loss: 0.06837668269872665
Validation loss: 1.6272364752266997

Epoch: 6| Step: 11
Training loss: 0.11998827010393143
Validation loss: 1.610417148118378

Epoch: 6| Step: 12
Training loss: 0.12325600534677505
Validation loss: 1.6144099902081233

Epoch: 6| Step: 13
Training loss: 0.236062154173851
Validation loss: 1.5975999101515739

Epoch: 477| Step: 0
Training loss: 0.13983239233493805
Validation loss: 1.6145184911707395

Epoch: 6| Step: 1
Training loss: 0.12614792585372925
Validation loss: 1.5913277563228403

Epoch: 6| Step: 2
Training loss: 0.1137981116771698
Validation loss: 1.5946781007192468

Epoch: 6| Step: 3
Training loss: 0.14386838674545288
Validation loss: 1.574665541289955

Epoch: 6| Step: 4
Training loss: 0.12955361604690552
Validation loss: 1.5576405294479863

Epoch: 6| Step: 5
Training loss: 0.15435759723186493
Validation loss: 1.5513587190258888

Epoch: 6| Step: 6
Training loss: 0.11634985357522964
Validation loss: 1.5625715665919806

Epoch: 6| Step: 7
Training loss: 0.11916652321815491
Validation loss: 1.5675344313344648

Epoch: 6| Step: 8
Training loss: 0.15176177024841309
Validation loss: 1.5756823606388544

Epoch: 6| Step: 9
Training loss: 0.07275237143039703
Validation loss: 1.5747234436773485

Epoch: 6| Step: 10
Training loss: 0.12491253018379211
Validation loss: 1.55595560355853

Epoch: 6| Step: 11
Training loss: 0.06610997021198273
Validation loss: 1.5761890795923048

Epoch: 6| Step: 12
Training loss: 0.184385284781456
Validation loss: 1.5909898793825539

Epoch: 6| Step: 13
Training loss: 0.07576094567775726
Validation loss: 1.5708237335246096

Epoch: 478| Step: 0
Training loss: 0.09987469017505646
Validation loss: 1.568991861035747

Epoch: 6| Step: 1
Training loss: 0.13301405310630798
Validation loss: 1.5412748552137805

Epoch: 6| Step: 2
Training loss: 0.08447231352329254
Validation loss: 1.5460060770793627

Epoch: 6| Step: 3
Training loss: 0.08471363037824631
Validation loss: 1.5318303121033536

Epoch: 6| Step: 4
Training loss: 0.15438728034496307
Validation loss: 1.5369681478828512

Epoch: 6| Step: 5
Training loss: 0.1097252145409584
Validation loss: 1.536237870493243

Epoch: 6| Step: 6
Training loss: 0.08478952944278717
Validation loss: 1.5369719766801404

Epoch: 6| Step: 7
Training loss: 0.14382228255271912
Validation loss: 1.5376173078372914

Epoch: 6| Step: 8
Training loss: 0.10406827181577682
Validation loss: 1.5446082122864262

Epoch: 6| Step: 9
Training loss: 0.12526443600654602
Validation loss: 1.5543669321203744

Epoch: 6| Step: 10
Training loss: 0.12171871215105057
Validation loss: 1.5440596047268118

Epoch: 6| Step: 11
Training loss: 0.10844138264656067
Validation loss: 1.5457187801279046

Epoch: 6| Step: 12
Training loss: 0.1163167655467987
Validation loss: 1.5567398032834452

Epoch: 6| Step: 13
Training loss: 0.12918907403945923
Validation loss: 1.5385320122523973

Epoch: 479| Step: 0
Training loss: 0.07753846049308777
Validation loss: 1.5235685481820056

Epoch: 6| Step: 1
Training loss: 0.10937556624412537
Validation loss: 1.544664768762486

Epoch: 6| Step: 2
Training loss: 0.09686712920665741
Validation loss: 1.552073654308114

Epoch: 6| Step: 3
Training loss: 0.17009299993515015
Validation loss: 1.5656527396171325

Epoch: 6| Step: 4
Training loss: 0.1927897185087204
Validation loss: 1.550385122658104

Epoch: 6| Step: 5
Training loss: 0.09556971490383148
Validation loss: 1.5202280372701666

Epoch: 6| Step: 6
Training loss: 0.18314357101917267
Validation loss: 1.5560753473671534

Epoch: 6| Step: 7
Training loss: 0.09624410420656204
Validation loss: 1.539084506291215

Epoch: 6| Step: 8
Training loss: 0.09768100082874298
Validation loss: 1.5333008445719236

Epoch: 6| Step: 9
Training loss: 0.10042664408683777
Validation loss: 1.5668780355043308

Epoch: 6| Step: 10
Training loss: 0.08120521903038025
Validation loss: 1.592818324283887

Epoch: 6| Step: 11
Training loss: 0.14180895686149597
Validation loss: 1.595211955808824

Epoch: 6| Step: 12
Training loss: 0.09730634093284607
Validation loss: 1.5934226320635887

Epoch: 6| Step: 13
Training loss: 0.15292689204216003
Validation loss: 1.5844469967708792

Epoch: 480| Step: 0
Training loss: 0.17176708579063416
Validation loss: 1.5917678789425922

Epoch: 6| Step: 1
Training loss: 0.13338465988636017
Validation loss: 1.6110217212348856

Epoch: 6| Step: 2
Training loss: 0.15437206625938416
Validation loss: 1.6218686308912051

Epoch: 6| Step: 3
Training loss: 0.13384810090065002
Validation loss: 1.6236887452422932

Epoch: 6| Step: 4
Training loss: 0.17743736505508423
Validation loss: 1.602924600724251

Epoch: 6| Step: 5
Training loss: 0.11645270884037018
Validation loss: 1.5925800338868172

Epoch: 6| Step: 6
Training loss: 0.11031825840473175
Validation loss: 1.6077432991355978

Epoch: 6| Step: 7
Training loss: 0.08820350468158722
Validation loss: 1.6008615980866134

Epoch: 6| Step: 8
Training loss: 0.07659456133842468
Validation loss: 1.612964448108468

Epoch: 6| Step: 9
Training loss: 0.1241765171289444
Validation loss: 1.5811537529832573

Epoch: 6| Step: 10
Training loss: 0.0652582049369812
Validation loss: 1.5994305687565957

Epoch: 6| Step: 11
Training loss: 0.12933115661144257
Validation loss: 1.6053926688368603

Epoch: 6| Step: 12
Training loss: 0.07417375594377518
Validation loss: 1.5647675350148191

Epoch: 6| Step: 13
Training loss: 0.10662384331226349
Validation loss: 1.610345405917014

Epoch: 481| Step: 0
Training loss: 0.13316261768341064
Validation loss: 1.5732837236055763

Epoch: 6| Step: 1
Training loss: 0.09180229902267456
Validation loss: 1.5746977136981102

Epoch: 6| Step: 2
Training loss: 0.217973992228508
Validation loss: 1.6004904726500153

Epoch: 6| Step: 3
Training loss: 0.09778466820716858
Validation loss: 1.5817262741827196

Epoch: 6| Step: 4
Training loss: 0.07695449888706207
Validation loss: 1.5867661686353787

Epoch: 6| Step: 5
Training loss: 0.15371689200401306
Validation loss: 1.564609209696452

Epoch: 6| Step: 6
Training loss: 0.12484678626060486
Validation loss: 1.5906317234039307

Epoch: 6| Step: 7
Training loss: 0.07054659724235535
Validation loss: 1.5726091861724854

Epoch: 6| Step: 8
Training loss: 0.09162279963493347
Validation loss: 1.5585690954680085

Epoch: 6| Step: 9
Training loss: 0.173213392496109
Validation loss: 1.5552029430225331

Epoch: 6| Step: 10
Training loss: 0.15955939888954163
Validation loss: 1.5833387913242463

Epoch: 6| Step: 11
Training loss: 0.1628056764602661
Validation loss: 1.548480078738223

Epoch: 6| Step: 12
Training loss: 0.12065945565700531
Validation loss: 1.5614717237411007

Epoch: 6| Step: 13
Training loss: 0.06640541553497314
Validation loss: 1.5649459618394093

Epoch: 482| Step: 0
Training loss: 0.0880831778049469
Validation loss: 1.575826282142311

Epoch: 6| Step: 1
Training loss: 0.11969221383333206
Validation loss: 1.5629103247837355

Epoch: 6| Step: 2
Training loss: 0.1338895708322525
Validation loss: 1.5890640981735722

Epoch: 6| Step: 3
Training loss: 0.08799588680267334
Validation loss: 1.606791850059263

Epoch: 6| Step: 4
Training loss: 0.10555674880743027
Validation loss: 1.6234664352991248

Epoch: 6| Step: 5
Training loss: 0.1748257875442505
Validation loss: 1.629570140633532

Epoch: 6| Step: 6
Training loss: 0.1800539493560791
Validation loss: 1.6400840269621981

Epoch: 6| Step: 7
Training loss: 0.09989996254444122
Validation loss: 1.6253541387537473

Epoch: 6| Step: 8
Training loss: 0.10603228211402893
Validation loss: 1.5962777099301737

Epoch: 6| Step: 9
Training loss: 0.1261521279811859
Validation loss: 1.6007808408429545

Epoch: 6| Step: 10
Training loss: 0.11395680159330368
Validation loss: 1.5728504427017704

Epoch: 6| Step: 11
Training loss: 0.055563680827617645
Validation loss: 1.5795675170037053

Epoch: 6| Step: 12
Training loss: 0.14707808196544647
Validation loss: 1.5605179930246005

Epoch: 6| Step: 13
Training loss: 0.22802329063415527
Validation loss: 1.5736647241859025

Epoch: 483| Step: 0
Training loss: 0.11794457584619522
Validation loss: 1.5897902455381168

Epoch: 6| Step: 1
Training loss: 0.13286586105823517
Validation loss: 1.5959460658411826

Epoch: 6| Step: 2
Training loss: 0.14831925928592682
Validation loss: 1.5988654577603905

Epoch: 6| Step: 3
Training loss: 0.08104585111141205
Validation loss: 1.6248633489813855

Epoch: 6| Step: 4
Training loss: 0.09864357113838196
Validation loss: 1.6083361743598856

Epoch: 6| Step: 5
Training loss: 0.13183197379112244
Validation loss: 1.6461203944298528

Epoch: 6| Step: 6
Training loss: 0.12656979262828827
Validation loss: 1.6182485985499557

Epoch: 6| Step: 7
Training loss: 0.14639967679977417
Validation loss: 1.6239404434798865

Epoch: 6| Step: 8
Training loss: 0.13553723692893982
Validation loss: 1.5983420392518402

Epoch: 6| Step: 9
Training loss: 0.09819904714822769
Validation loss: 1.5712966803581483

Epoch: 6| Step: 10
Training loss: 0.0975794792175293
Validation loss: 1.5830382121506559

Epoch: 6| Step: 11
Training loss: 0.09274425357580185
Validation loss: 1.5900136296467116

Epoch: 6| Step: 12
Training loss: 0.20065370202064514
Validation loss: 1.5643957558498587

Epoch: 6| Step: 13
Training loss: 0.14965029060840607
Validation loss: 1.5455317612617248

Epoch: 484| Step: 0
Training loss: 0.10118846595287323
Validation loss: 1.5928389962001512

Epoch: 6| Step: 1
Training loss: 0.09737688302993774
Validation loss: 1.594483083294284

Epoch: 6| Step: 2
Training loss: 0.17783261835575104
Validation loss: 1.5807803010427823

Epoch: 6| Step: 3
Training loss: 0.13430818915367126
Validation loss: 1.592564680243051

Epoch: 6| Step: 4
Training loss: 0.11634598672389984
Validation loss: 1.5961588774957964

Epoch: 6| Step: 5
Training loss: 0.055006105452775955
Validation loss: 1.57004133091178

Epoch: 6| Step: 6
Training loss: 0.13276991248130798
Validation loss: 1.5962878542561685

Epoch: 6| Step: 7
Training loss: 0.15526898205280304
Validation loss: 1.5811044041828444

Epoch: 6| Step: 8
Training loss: 0.09600797295570374
Validation loss: 1.5680305163065593

Epoch: 6| Step: 9
Training loss: 0.0975637137889862
Validation loss: 1.5816128805119505

Epoch: 6| Step: 10
Training loss: 0.1316956877708435
Validation loss: 1.5512169420078237

Epoch: 6| Step: 11
Training loss: 0.09615199267864227
Validation loss: 1.5534206718526862

Epoch: 6| Step: 12
Training loss: 0.0966818630695343
Validation loss: 1.5658216848168323

Epoch: 6| Step: 13
Training loss: 0.10255176573991776
Validation loss: 1.5729829342134538

Epoch: 485| Step: 0
Training loss: 0.07349523901939392
Validation loss: 1.570275701502318

Epoch: 6| Step: 1
Training loss: 0.14337003231048584
Validation loss: 1.6064113468252204

Epoch: 6| Step: 2
Training loss: 0.14156252145767212
Validation loss: 1.6127650724944247

Epoch: 6| Step: 3
Training loss: 0.10713658481836319
Validation loss: 1.6068950788949126

Epoch: 6| Step: 4
Training loss: 0.15055060386657715
Validation loss: 1.6347830833927277

Epoch: 6| Step: 5
Training loss: 0.0971219465136528
Validation loss: 1.6402414767972884

Epoch: 6| Step: 6
Training loss: 0.1636790931224823
Validation loss: 1.6468838645565895

Epoch: 6| Step: 7
Training loss: 0.08691546320915222
Validation loss: 1.620973314008405

Epoch: 6| Step: 8
Training loss: 0.09227140247821808
Validation loss: 1.6068946135941373

Epoch: 6| Step: 9
Training loss: 0.10497426986694336
Validation loss: 1.6009880573518815

Epoch: 6| Step: 10
Training loss: 0.08056832104921341
Validation loss: 1.5921089597927627

Epoch: 6| Step: 11
Training loss: 0.14042456448078156
Validation loss: 1.5760372274665422

Epoch: 6| Step: 12
Training loss: 0.0977001041173935
Validation loss: 1.5672483482668478

Epoch: 6| Step: 13
Training loss: 0.13886290788650513
Validation loss: 1.5581224938874603

Epoch: 486| Step: 0
Training loss: 0.14274384081363678
Validation loss: 1.5443139050596504

Epoch: 6| Step: 1
Training loss: 0.17810165882110596
Validation loss: 1.5630362982391028

Epoch: 6| Step: 2
Training loss: 0.15199556946754456
Validation loss: 1.5308692557837373

Epoch: 6| Step: 3
Training loss: 0.113331139087677
Validation loss: 1.535829359485257

Epoch: 6| Step: 4
Training loss: 0.12916114926338196
Validation loss: 1.5499609003784836

Epoch: 6| Step: 5
Training loss: 0.11988507211208344
Validation loss: 1.5406997396099953

Epoch: 6| Step: 6
Training loss: 0.07418754696846008
Validation loss: 1.5771874843105194

Epoch: 6| Step: 7
Training loss: 0.11089707911014557
Validation loss: 1.6001727798933625

Epoch: 6| Step: 8
Training loss: 0.13222593069076538
Validation loss: 1.6310936033084829

Epoch: 6| Step: 9
Training loss: 0.17952856421470642
Validation loss: 1.6329983921461209

Epoch: 6| Step: 10
Training loss: 0.0866432934999466
Validation loss: 1.6395097208279434

Epoch: 6| Step: 11
Training loss: 0.11114399135112762
Validation loss: 1.6231640833680347

Epoch: 6| Step: 12
Training loss: 0.13799446821212769
Validation loss: 1.5961365494676816

Epoch: 6| Step: 13
Training loss: 0.10390082001686096
Validation loss: 1.6010935383458291

Epoch: 487| Step: 0
Training loss: 0.08699357509613037
Validation loss: 1.622174898783366

Epoch: 6| Step: 1
Training loss: 0.07630150020122528
Validation loss: 1.6191702324856994

Epoch: 6| Step: 2
Training loss: 0.08029153943061829
Validation loss: 1.6320366013434626

Epoch: 6| Step: 3
Training loss: 0.18939131498336792
Validation loss: 1.5891878399797665

Epoch: 6| Step: 4
Training loss: 0.08816923201084137
Validation loss: 1.594521141180428

Epoch: 6| Step: 5
Training loss: 0.097064308822155
Validation loss: 1.5709448552900744

Epoch: 6| Step: 6
Training loss: 0.14704570174217224
Validation loss: 1.5835653787018151

Epoch: 6| Step: 7
Training loss: 0.13060574233531952
Validation loss: 1.5621883407715829

Epoch: 6| Step: 8
Training loss: 0.13662786781787872
Validation loss: 1.5681177813519713

Epoch: 6| Step: 9
Training loss: 0.12793132662773132
Validation loss: 1.5494251994676487

Epoch: 6| Step: 10
Training loss: 0.19597825407981873
Validation loss: 1.5439202888037569

Epoch: 6| Step: 11
Training loss: 0.09049652516841888
Validation loss: 1.5599849583000265

Epoch: 6| Step: 12
Training loss: 0.12438644468784332
Validation loss: 1.5272896841008177

Epoch: 6| Step: 13
Training loss: 0.08471570163965225
Validation loss: 1.5515929306707075

Epoch: 488| Step: 0
Training loss: 0.05757978558540344
Validation loss: 1.5291443127457813

Epoch: 6| Step: 1
Training loss: 0.16027623414993286
Validation loss: 1.5538977628113122

Epoch: 6| Step: 2
Training loss: 0.08048663288354874
Validation loss: 1.5512517421476302

Epoch: 6| Step: 3
Training loss: 0.08015350252389908
Validation loss: 1.5242550475623018

Epoch: 6| Step: 4
Training loss: 0.06141085550189018
Validation loss: 1.5643131707304267

Epoch: 6| Step: 5
Training loss: 0.18112343549728394
Validation loss: 1.5697508089004024

Epoch: 6| Step: 6
Training loss: 0.06827784329652786
Validation loss: 1.5895481545438048

Epoch: 6| Step: 7
Training loss: 0.1043957769870758
Validation loss: 1.5474631337709324

Epoch: 6| Step: 8
Training loss: 0.11936073005199432
Validation loss: 1.5526626315168155

Epoch: 6| Step: 9
Training loss: 0.0701010674238205
Validation loss: 1.5796587505648214

Epoch: 6| Step: 10
Training loss: 0.09048091620206833
Validation loss: 1.5816007455190022

Epoch: 6| Step: 11
Training loss: 0.12484212219715118
Validation loss: 1.5799503557143673

Epoch: 6| Step: 12
Training loss: 0.12596406042575836
Validation loss: 1.5678256634742982

Epoch: 6| Step: 13
Training loss: 0.06444735080003738
Validation loss: 1.5385563899112005

Epoch: 489| Step: 0
Training loss: 0.10283102840185165
Validation loss: 1.563155871565624

Epoch: 6| Step: 1
Training loss: 0.06082608550786972
Validation loss: 1.541856042800411

Epoch: 6| Step: 2
Training loss: 0.11506232619285583
Validation loss: 1.5667382312077347

Epoch: 6| Step: 3
Training loss: 0.07937934994697571
Validation loss: 1.5544971355827906

Epoch: 6| Step: 4
Training loss: 0.07365207374095917
Validation loss: 1.5499156777576735

Epoch: 6| Step: 5
Training loss: 0.17610618472099304
Validation loss: 1.5584175496973016

Epoch: 6| Step: 6
Training loss: 0.15127617120742798
Validation loss: 1.5635730592153405

Epoch: 6| Step: 7
Training loss: 0.09293896704912186
Validation loss: 1.5582239602201728

Epoch: 6| Step: 8
Training loss: 0.08719299733638763
Validation loss: 1.566815269890652

Epoch: 6| Step: 9
Training loss: 0.12376190721988678
Validation loss: 1.5945940184336838

Epoch: 6| Step: 10
Training loss: 0.1161205992102623
Validation loss: 1.5587554814354065

Epoch: 6| Step: 11
Training loss: 0.09222303330898285
Validation loss: 1.5905286983777118

Epoch: 6| Step: 12
Training loss: 0.12827074527740479
Validation loss: 1.5698567154586955

Epoch: 6| Step: 13
Training loss: 0.1441214680671692
Validation loss: 1.58661360638116

Epoch: 490| Step: 0
Training loss: 0.12938958406448364
Validation loss: 1.5523097130560106

Epoch: 6| Step: 1
Training loss: 0.15049725770950317
Validation loss: 1.5533215333056707

Epoch: 6| Step: 2
Training loss: 0.1034555584192276
Validation loss: 1.5500211754152853

Epoch: 6| Step: 3
Training loss: 0.044241540133953094
Validation loss: 1.5376325409899476

Epoch: 6| Step: 4
Training loss: 0.12359637022018433
Validation loss: 1.5638383742301696

Epoch: 6| Step: 5
Training loss: 0.08420136570930481
Validation loss: 1.5668840856962307

Epoch: 6| Step: 6
Training loss: 0.1368490755558014
Validation loss: 1.552441373948128

Epoch: 6| Step: 7
Training loss: 0.14696133136749268
Validation loss: 1.5738267847286758

Epoch: 6| Step: 8
Training loss: 0.11016962677240372
Validation loss: 1.5708290300061625

Epoch: 6| Step: 9
Training loss: 0.10412593185901642
Validation loss: 1.5820065916225474

Epoch: 6| Step: 10
Training loss: 0.07220900058746338
Validation loss: 1.5615638327854935

Epoch: 6| Step: 11
Training loss: 0.2093219757080078
Validation loss: 1.612919702324816

Epoch: 6| Step: 12
Training loss: 0.11800789833068848
Validation loss: 1.6232330106919812

Epoch: 6| Step: 13
Training loss: 0.18327197432518005
Validation loss: 1.6283979069802068

Epoch: 491| Step: 0
Training loss: 0.11038569360971451
Validation loss: 1.6124046220574328

Epoch: 6| Step: 1
Training loss: 0.08919486403465271
Validation loss: 1.5657350965725478

Epoch: 6| Step: 2
Training loss: 0.13327333331108093
Validation loss: 1.57741125552885

Epoch: 6| Step: 3
Training loss: 0.09686844050884247
Validation loss: 1.5867292842557352

Epoch: 6| Step: 4
Training loss: 0.06555113196372986
Validation loss: 1.5853736035285457

Epoch: 6| Step: 5
Training loss: 0.07021249830722809
Validation loss: 1.5534617490665887

Epoch: 6| Step: 6
Training loss: 0.07343465089797974
Validation loss: 1.5967728066188034

Epoch: 6| Step: 7
Training loss: 0.09735912084579468
Validation loss: 1.554898932415952

Epoch: 6| Step: 8
Training loss: 0.12874388694763184
Validation loss: 1.5793509098791307

Epoch: 6| Step: 9
Training loss: 0.08101813495159149
Validation loss: 1.5870533143320391

Epoch: 6| Step: 10
Training loss: 0.0826922357082367
Validation loss: 1.5710788375587874

Epoch: 6| Step: 11
Training loss: 0.1595567911863327
Validation loss: 1.574066977347097

Epoch: 6| Step: 12
Training loss: 0.18965274095535278
Validation loss: 1.5737606581821237

Epoch: 6| Step: 13
Training loss: 0.15226943790912628
Validation loss: 1.5822916082156602

Epoch: 492| Step: 0
Training loss: 0.06339798867702484
Validation loss: 1.5872259691197386

Epoch: 6| Step: 1
Training loss: 0.13159024715423584
Validation loss: 1.5933485338764806

Epoch: 6| Step: 2
Training loss: 0.1684150993824005
Validation loss: 1.5740034708412745

Epoch: 6| Step: 3
Training loss: 0.17269034683704376
Validation loss: 1.5554660725337204

Epoch: 6| Step: 4
Training loss: 0.18324457108974457
Validation loss: 1.590357316437588

Epoch: 6| Step: 5
Training loss: 0.0973489060997963
Validation loss: 1.5707651953543387

Epoch: 6| Step: 6
Training loss: 0.11902559548616409
Validation loss: 1.586828803503385

Epoch: 6| Step: 7
Training loss: 0.15087170898914337
Validation loss: 1.5754526622833744

Epoch: 6| Step: 8
Training loss: 0.06348919868469238
Validation loss: 1.5534885314203077

Epoch: 6| Step: 9
Training loss: 0.1704765111207962
Validation loss: 1.579080177891639

Epoch: 6| Step: 10
Training loss: 0.058824218809604645
Validation loss: 1.5623525522088493

Epoch: 6| Step: 11
Training loss: 0.10343453288078308
Validation loss: 1.5503401051285446

Epoch: 6| Step: 12
Training loss: 0.09639694541692734
Validation loss: 1.567007141728555

Epoch: 6| Step: 13
Training loss: 0.08800818026065826
Validation loss: 1.5192613255593084

Epoch: 493| Step: 0
Training loss: 0.16187292337417603
Validation loss: 1.5538642265463387

Epoch: 6| Step: 1
Training loss: 0.14384260773658752
Validation loss: 1.555886125051847

Epoch: 6| Step: 2
Training loss: 0.14717841148376465
Validation loss: 1.5953319213723625

Epoch: 6| Step: 3
Training loss: 0.08779141306877136
Validation loss: 1.5731694185605614

Epoch: 6| Step: 4
Training loss: 0.13809187710285187
Validation loss: 1.557761780036393

Epoch: 6| Step: 5
Training loss: 0.0695270299911499
Validation loss: 1.601856643153775

Epoch: 6| Step: 6
Training loss: 0.13744798302650452
Validation loss: 1.5978243261255243

Epoch: 6| Step: 7
Training loss: 0.1366095244884491
Validation loss: 1.601106712895055

Epoch: 6| Step: 8
Training loss: 0.04122071713209152
Validation loss: 1.6131536358146257

Epoch: 6| Step: 9
Training loss: 0.08478131145238876
Validation loss: 1.6071084494231849

Epoch: 6| Step: 10
Training loss: 0.12504838407039642
Validation loss: 1.61144422459346

Epoch: 6| Step: 11
Training loss: 0.11381500214338303
Validation loss: 1.6131226080720142

Epoch: 6| Step: 12
Training loss: 0.14199170470237732
Validation loss: 1.6131924095974173

Epoch: 6| Step: 13
Training loss: 0.10577479004859924
Validation loss: 1.5971746213974491

Epoch: 494| Step: 0
Training loss: 0.06697619706392288
Validation loss: 1.6093756755193074

Epoch: 6| Step: 1
Training loss: 0.09548866748809814
Validation loss: 1.584536567811043

Epoch: 6| Step: 2
Training loss: 0.05648359656333923
Validation loss: 1.6235388350743118

Epoch: 6| Step: 3
Training loss: 0.15577684342861176
Validation loss: 1.5604489593095676

Epoch: 6| Step: 4
Training loss: 0.10010528564453125
Validation loss: 1.570001870073298

Epoch: 6| Step: 5
Training loss: 0.17785724997520447
Validation loss: 1.57697557890287

Epoch: 6| Step: 6
Training loss: 0.1218326985836029
Validation loss: 1.5735088497079828

Epoch: 6| Step: 7
Training loss: 0.04729926586151123
Validation loss: 1.584798018137614

Epoch: 6| Step: 8
Training loss: 0.16061842441558838
Validation loss: 1.5644449264772478

Epoch: 6| Step: 9
Training loss: 0.13003495335578918
Validation loss: 1.5577349239780056

Epoch: 6| Step: 10
Training loss: 0.14778363704681396
Validation loss: 1.5763483790941135

Epoch: 6| Step: 11
Training loss: 0.09983896464109421
Validation loss: 1.578420728765508

Epoch: 6| Step: 12
Training loss: 0.19093303382396698
Validation loss: 1.581610466844292

Epoch: 6| Step: 13
Training loss: 0.08926650881767273
Validation loss: 1.5445534112632915

Epoch: 495| Step: 0
Training loss: 0.0780666172504425
Validation loss: 1.5856840841231807

Epoch: 6| Step: 1
Training loss: 0.059091173112392426
Validation loss: 1.5681782858346098

Epoch: 6| Step: 2
Training loss: 0.08854250609874725
Validation loss: 1.5813623346308225

Epoch: 6| Step: 3
Training loss: 0.08776019513607025
Validation loss: 1.5509778081729848

Epoch: 6| Step: 4
Training loss: 0.23339535295963287
Validation loss: 1.5313562193224508

Epoch: 6| Step: 5
Training loss: 0.10405871272087097
Validation loss: 1.5669139508278138

Epoch: 6| Step: 6
Training loss: 0.08821661025285721
Validation loss: 1.5485235696197839

Epoch: 6| Step: 7
Training loss: 0.1327127367258072
Validation loss: 1.5230131854293167

Epoch: 6| Step: 8
Training loss: 0.10704850405454636
Validation loss: 1.5412646493604105

Epoch: 6| Step: 9
Training loss: 0.06867499649524689
Validation loss: 1.5589592174817157

Epoch: 6| Step: 10
Training loss: 0.08588388562202454
Validation loss: 1.5478229804705548

Epoch: 6| Step: 11
Training loss: 0.15991438925266266
Validation loss: 1.5335281715598157

Epoch: 6| Step: 12
Training loss: 0.07662658393383026
Validation loss: 1.5691506401185067

Epoch: 6| Step: 13
Training loss: 0.07252804189920425
Validation loss: 1.5688730811560025

Epoch: 496| Step: 0
Training loss: 0.12805671989917755
Validation loss: 1.5926842176786034

Epoch: 6| Step: 1
Training loss: 0.16957533359527588
Validation loss: 1.607533149821784

Epoch: 6| Step: 2
Training loss: 0.143033966422081
Validation loss: 1.606712504099774

Epoch: 6| Step: 3
Training loss: 0.06506238132715225
Validation loss: 1.6170415532204412

Epoch: 6| Step: 4
Training loss: 0.03376465290784836
Validation loss: 1.6282413608284407

Epoch: 6| Step: 5
Training loss: 0.1426524817943573
Validation loss: 1.5980672041575115

Epoch: 6| Step: 6
Training loss: 0.13243776559829712
Validation loss: 1.5749650437344787

Epoch: 6| Step: 7
Training loss: 0.14069125056266785
Validation loss: 1.5405471183920418

Epoch: 6| Step: 8
Training loss: 0.06204045191407204
Validation loss: 1.541406052086943

Epoch: 6| Step: 9
Training loss: 0.14776846766471863
Validation loss: 1.5356298223618539

Epoch: 6| Step: 10
Training loss: 0.1080111563205719
Validation loss: 1.5448645622499528

Epoch: 6| Step: 11
Training loss: 0.10200422257184982
Validation loss: 1.5225708689740909

Epoch: 6| Step: 12
Training loss: 0.08505377173423767
Validation loss: 1.5077037401096796

Epoch: 6| Step: 13
Training loss: 0.1133977472782135
Validation loss: 1.5216787527966242

Epoch: 497| Step: 0
Training loss: 0.12562763690948486
Validation loss: 1.5421018626100274

Epoch: 6| Step: 1
Training loss: 0.17645245790481567
Validation loss: 1.5300467565495481

Epoch: 6| Step: 2
Training loss: 0.09441737830638885
Validation loss: 1.5236795756124681

Epoch: 6| Step: 3
Training loss: 0.0698033794760704
Validation loss: 1.528875498361485

Epoch: 6| Step: 4
Training loss: 0.09969288855791092
Validation loss: 1.5236194390122608

Epoch: 6| Step: 5
Training loss: 0.06266124546527863
Validation loss: 1.5303433992529427

Epoch: 6| Step: 6
Training loss: 0.10477350652217865
Validation loss: 1.5252941090573546

Epoch: 6| Step: 7
Training loss: 0.05015622824430466
Validation loss: 1.5424769642532512

Epoch: 6| Step: 8
Training loss: 0.1396181434392929
Validation loss: 1.5219137168699695

Epoch: 6| Step: 9
Training loss: 0.11550009250640869
Validation loss: 1.5180166639307493

Epoch: 6| Step: 10
Training loss: 0.11411809921264648
Validation loss: 1.5362896906432284

Epoch: 6| Step: 11
Training loss: 0.13803671300411224
Validation loss: 1.5315858035959222

Epoch: 6| Step: 12
Training loss: 0.1645374596118927
Validation loss: 1.533936107030479

Epoch: 6| Step: 13
Training loss: 0.17941103875637054
Validation loss: 1.523754721046776

Epoch: 498| Step: 0
Training loss: 0.11249902844429016
Validation loss: 1.5129967479295627

Epoch: 6| Step: 1
Training loss: 0.15229062736034393
Validation loss: 1.5068169947593444

Epoch: 6| Step: 2
Training loss: 0.11105701327323914
Validation loss: 1.5594676694562357

Epoch: 6| Step: 3
Training loss: 0.1405058205127716
Validation loss: 1.5816102309893536

Epoch: 6| Step: 4
Training loss: 0.1214057207107544
Validation loss: 1.5609084431843092

Epoch: 6| Step: 5
Training loss: 0.08065730333328247
Validation loss: 1.5463735185643679

Epoch: 6| Step: 6
Training loss: 0.08159563690423965
Validation loss: 1.4924304369957215

Epoch: 6| Step: 7
Training loss: 0.06576095521450043
Validation loss: 1.514615979245914

Epoch: 6| Step: 8
Training loss: 0.0857524424791336
Validation loss: 1.508899482347632

Epoch: 6| Step: 9
Training loss: 0.16153007745742798
Validation loss: 1.5164404684497463

Epoch: 6| Step: 10
Training loss: 0.05510660260915756
Validation loss: 1.5162606380319084

Epoch: 6| Step: 11
Training loss: 0.1482483148574829
Validation loss: 1.5066191778388074

Epoch: 6| Step: 12
Training loss: 0.1505562961101532
Validation loss: 1.5155209905357772

Epoch: 6| Step: 13
Training loss: 0.19183343648910522
Validation loss: 1.5247403703710085

Epoch: 499| Step: 0
Training loss: 0.1181357279419899
Validation loss: 1.5278807237584104

Epoch: 6| Step: 1
Training loss: 0.07912079989910126
Validation loss: 1.510420342927338

Epoch: 6| Step: 2
Training loss: 0.09744812548160553
Validation loss: 1.5370604030547603

Epoch: 6| Step: 3
Training loss: 0.08506530523300171
Validation loss: 1.5592312457100037

Epoch: 6| Step: 4
Training loss: 0.14861205220222473
Validation loss: 1.567309623123497

Epoch: 6| Step: 5
Training loss: 0.172853022813797
Validation loss: 1.551401662570174

Epoch: 6| Step: 6
Training loss: 0.14699774980545044
Validation loss: 1.5674187034688971

Epoch: 6| Step: 7
Training loss: 0.12083938717842102
Validation loss: 1.5534556001745246

Epoch: 6| Step: 8
Training loss: 0.081403449177742
Validation loss: 1.5242443853808987

Epoch: 6| Step: 9
Training loss: 0.10741376876831055
Validation loss: 1.5585717398633239

Epoch: 6| Step: 10
Training loss: 0.11630342900753021
Validation loss: 1.5598297631868752

Epoch: 6| Step: 11
Training loss: 0.09725514054298401
Validation loss: 1.5382646873433103

Epoch: 6| Step: 12
Training loss: 0.10221858322620392
Validation loss: 1.5423919629025202

Epoch: 6| Step: 13
Training loss: 0.11979486048221588
Validation loss: 1.5486997968407088

Epoch: 500| Step: 0
Training loss: 0.13563916087150574
Validation loss: 1.538064686200952

Epoch: 6| Step: 1
Training loss: 0.07860349863767624
Validation loss: 1.5212761394439205

Epoch: 6| Step: 2
Training loss: 0.058372803032398224
Validation loss: 1.5354030061793584

Epoch: 6| Step: 3
Training loss: 0.11356372386217117
Validation loss: 1.5276362049964167

Epoch: 6| Step: 4
Training loss: 0.07497593015432358
Validation loss: 1.5540191819590907

Epoch: 6| Step: 5
Training loss: 0.11983082443475723
Validation loss: 1.5536877077112916

Epoch: 6| Step: 6
Training loss: 0.08097919821739197
Validation loss: 1.5531058529371857

Epoch: 6| Step: 7
Training loss: 0.0664234310388565
Validation loss: 1.5711991581865536

Epoch: 6| Step: 8
Training loss: 0.09495314955711365
Validation loss: 1.5705247489354943

Epoch: 6| Step: 9
Training loss: 0.05982008948922157
Validation loss: 1.5843682494214786

Epoch: 6| Step: 10
Training loss: 0.1260022073984146
Validation loss: 1.5514067834423435

Epoch: 6| Step: 11
Training loss: 0.07638441026210785
Validation loss: 1.5508842122170232

Epoch: 6| Step: 12
Training loss: 0.05700348690152168
Validation loss: 1.5462097262823453

Epoch: 6| Step: 13
Training loss: 0.11300083994865417
Validation loss: 1.5670813578431324

Epoch: 501| Step: 0
Training loss: 0.09586189687252045
Validation loss: 1.5608577805180703

Epoch: 6| Step: 1
Training loss: 0.09391885995864868
Validation loss: 1.535497901260212

Epoch: 6| Step: 2
Training loss: 0.0711081251502037
Validation loss: 1.5637306526143064

Epoch: 6| Step: 3
Training loss: 0.08370391279459
Validation loss: 1.539861838022868

Epoch: 6| Step: 4
Training loss: 0.11618608236312866
Validation loss: 1.5520663274231778

Epoch: 6| Step: 5
Training loss: 0.13383865356445312
Validation loss: 1.5761451990373674

Epoch: 6| Step: 6
Training loss: 0.0839550644159317
Validation loss: 1.5537831488476004

Epoch: 6| Step: 7
Training loss: 0.08621247112751007
Validation loss: 1.5614974883294874

Epoch: 6| Step: 8
Training loss: 0.09010893851518631
Validation loss: 1.5611553153684061

Epoch: 6| Step: 9
Training loss: 0.10253801941871643
Validation loss: 1.5551600315237557

Epoch: 6| Step: 10
Training loss: 0.062330830842256546
Validation loss: 1.5351151727860974

Epoch: 6| Step: 11
Training loss: 0.1039295643568039
Validation loss: 1.5760387105326499

Epoch: 6| Step: 12
Training loss: 0.08890583366155624
Validation loss: 1.5620509488608247

Epoch: 6| Step: 13
Training loss: 0.1124337762594223
Validation loss: 1.5902048432698814

Epoch: 502| Step: 0
Training loss: 0.10342562198638916
Validation loss: 1.5779749706227293

Epoch: 6| Step: 1
Training loss: 0.06787672638893127
Validation loss: 1.5623077352841694

Epoch: 6| Step: 2
Training loss: 0.2033107876777649
Validation loss: 1.556828155312487

Epoch: 6| Step: 3
Training loss: 0.10878150910139084
Validation loss: 1.5695581077247538

Epoch: 6| Step: 4
Training loss: 0.1441001296043396
Validation loss: 1.5718875649154826

Epoch: 6| Step: 5
Training loss: 0.08771500736474991
Validation loss: 1.5713136567864368

Epoch: 6| Step: 6
Training loss: 0.053448691964149475
Validation loss: 1.5685613668093117

Epoch: 6| Step: 7
Training loss: 0.17696082592010498
Validation loss: 1.5642280681158907

Epoch: 6| Step: 8
Training loss: 0.08972451835870743
Validation loss: 1.5603688634851927

Epoch: 6| Step: 9
Training loss: 0.11194422841072083
Validation loss: 1.5510363886433263

Epoch: 6| Step: 10
Training loss: 0.14078223705291748
Validation loss: 1.5951843684719456

Epoch: 6| Step: 11
Training loss: 0.09192706644535065
Validation loss: 1.6064803228583386

Epoch: 6| Step: 12
Training loss: 0.06510373950004578
Validation loss: 1.6185601193417785

Epoch: 6| Step: 13
Training loss: 0.11171317100524902
Validation loss: 1.6320816816822175

Epoch: 503| Step: 0
Training loss: 0.10503888875246048
Validation loss: 1.6221346227071618

Epoch: 6| Step: 1
Training loss: 0.1254613697528839
Validation loss: 1.619190994129386

Epoch: 6| Step: 2
Training loss: 0.10745804011821747
Validation loss: 1.6216196103762555

Epoch: 6| Step: 3
Training loss: 0.12046109884977341
Validation loss: 1.6215228444786483

Epoch: 6| Step: 4
Training loss: 0.0906696766614914
Validation loss: 1.5721520416198238

Epoch: 6| Step: 5
Training loss: 0.10155583173036575
Validation loss: 1.577565299567356

Epoch: 6| Step: 6
Training loss: 0.09678243100643158
Validation loss: 1.5604342465759606

Epoch: 6| Step: 7
Training loss: 0.1069135069847107
Validation loss: 1.581209699312846

Epoch: 6| Step: 8
Training loss: 0.10190755873918533
Validation loss: 1.5549466122863114

Epoch: 6| Step: 9
Training loss: 0.09469129145145416
Validation loss: 1.58796021246141

Epoch: 6| Step: 10
Training loss: 0.11122670769691467
Validation loss: 1.5678730850578637

Epoch: 6| Step: 11
Training loss: 0.15805932879447937
Validation loss: 1.5617741038722377

Epoch: 6| Step: 12
Training loss: 0.09577791392803192
Validation loss: 1.5504516504144157

Epoch: 6| Step: 13
Training loss: 0.10945038497447968
Validation loss: 1.56974373966135

Epoch: 504| Step: 0
Training loss: 0.10536706447601318
Validation loss: 1.5499468208641134

Epoch: 6| Step: 1
Training loss: 0.12252706289291382
Validation loss: 1.556283321431888

Epoch: 6| Step: 2
Training loss: 0.11816207319498062
Validation loss: 1.5776599196977512

Epoch: 6| Step: 3
Training loss: 0.11176836490631104
Validation loss: 1.5990226563586984

Epoch: 6| Step: 4
Training loss: 0.1574556529521942
Validation loss: 1.584247055874076

Epoch: 6| Step: 5
Training loss: 0.08201621472835541
Validation loss: 1.5895241896311443

Epoch: 6| Step: 6
Training loss: 0.12358877062797546
Validation loss: 1.566505387265195

Epoch: 6| Step: 7
Training loss: 0.10667829215526581
Validation loss: 1.5910461833400111

Epoch: 6| Step: 8
Training loss: 0.08045084774494171
Validation loss: 1.5602318292023034

Epoch: 6| Step: 9
Training loss: 0.11527226120233536
Validation loss: 1.5176119445472636

Epoch: 6| Step: 10
Training loss: 0.0696537047624588
Validation loss: 1.5550192479164369

Epoch: 6| Step: 11
Training loss: 0.10095370560884476
Validation loss: 1.5575596555586784

Epoch: 6| Step: 12
Training loss: 0.09619538486003876
Validation loss: 1.558014231343423

Epoch: 6| Step: 13
Training loss: 0.14267784357070923
Validation loss: 1.564408561234833

Epoch: 505| Step: 0
Training loss: 0.13391441106796265
Validation loss: 1.5473687283454403

Epoch: 6| Step: 1
Training loss: 0.10038188844919205
Validation loss: 1.5463023660003499

Epoch: 6| Step: 2
Training loss: 0.08222329616546631
Validation loss: 1.592580520978538

Epoch: 6| Step: 3
Training loss: 0.09721381217241287
Validation loss: 1.5493142463827645

Epoch: 6| Step: 4
Training loss: 0.053584061563014984
Validation loss: 1.5483516980242986

Epoch: 6| Step: 5
Training loss: 0.0747024342417717
Validation loss: 1.549853576126919

Epoch: 6| Step: 6
Training loss: 0.0779370367527008
Validation loss: 1.569888081601871

Epoch: 6| Step: 7
Training loss: 0.11652658879756927
Validation loss: 1.5669794121096212

Epoch: 6| Step: 8
Training loss: 0.1609557718038559
Validation loss: 1.5683831937851445

Epoch: 6| Step: 9
Training loss: 0.11296059936285019
Validation loss: 1.5957009817964287

Epoch: 6| Step: 10
Training loss: 0.08229992538690567
Validation loss: 1.5722137689590454

Epoch: 6| Step: 11
Training loss: 0.08880186080932617
Validation loss: 1.572844139991268

Epoch: 6| Step: 12
Training loss: 0.11776381731033325
Validation loss: 1.595603358361029

Epoch: 6| Step: 13
Training loss: 0.1720706671476364
Validation loss: 1.5684218880950764

Epoch: 506| Step: 0
Training loss: 0.05376772582530975
Validation loss: 1.5755594763704526

Epoch: 6| Step: 1
Training loss: 0.12303593754768372
Validation loss: 1.5642110506693523

Epoch: 6| Step: 2
Training loss: 0.054686516523361206
Validation loss: 1.597720367934114

Epoch: 6| Step: 3
Training loss: 0.1378626823425293
Validation loss: 1.5906794225015948

Epoch: 6| Step: 4
Training loss: 0.16113325953483582
Validation loss: 1.581502091500067

Epoch: 6| Step: 5
Training loss: 0.08338627964258194
Validation loss: 1.6107864431155625

Epoch: 6| Step: 6
Training loss: 0.07447433471679688
Validation loss: 1.6069686720448155

Epoch: 6| Step: 7
Training loss: 0.07816525548696518
Validation loss: 1.6067456968369023

Epoch: 6| Step: 8
Training loss: 0.08262795209884644
Validation loss: 1.6166755050741217

Epoch: 6| Step: 9
Training loss: 0.09665298461914062
Validation loss: 1.621142069498698

Epoch: 6| Step: 10
Training loss: 0.11126671731472015
Validation loss: 1.6072796371675306

Epoch: 6| Step: 11
Training loss: 0.06657519936561584
Validation loss: 1.603517299057335

Epoch: 6| Step: 12
Training loss: 0.08027705550193787
Validation loss: 1.5686793224785918

Epoch: 6| Step: 13
Training loss: 0.11434923112392426
Validation loss: 1.572054918094348

Epoch: 507| Step: 0
Training loss: 0.11056733876466751
Validation loss: 1.5694286336180985

Epoch: 6| Step: 1
Training loss: 0.09761404991149902
Validation loss: 1.5861587652596094

Epoch: 6| Step: 2
Training loss: 0.10838121175765991
Validation loss: 1.5663244006454304

Epoch: 6| Step: 3
Training loss: 0.09704898297786713
Validation loss: 1.5927260274528174

Epoch: 6| Step: 4
Training loss: 0.13153746724128723
Validation loss: 1.5664484603430635

Epoch: 6| Step: 5
Training loss: 0.13043427467346191
Validation loss: 1.5908549049849152

Epoch: 6| Step: 6
Training loss: 0.11430928111076355
Validation loss: 1.5962919817175916

Epoch: 6| Step: 7
Training loss: 0.09811893850564957
Validation loss: 1.595523993174235

Epoch: 6| Step: 8
Training loss: 0.10085088014602661
Validation loss: 1.5660787192724084

Epoch: 6| Step: 9
Training loss: 0.12230872362852097
Validation loss: 1.5704166684099423

Epoch: 6| Step: 10
Training loss: 0.10944504290819168
Validation loss: 1.5290417555839784

Epoch: 6| Step: 11
Training loss: 0.1566900610923767
Validation loss: 1.5058543271915887

Epoch: 6| Step: 12
Training loss: 0.1258704662322998
Validation loss: 1.5006076943489812

Epoch: 6| Step: 13
Training loss: 0.05991918593645096
Validation loss: 1.5046314500993299

Epoch: 508| Step: 0
Training loss: 0.1071031391620636
Validation loss: 1.5297035786413378

Epoch: 6| Step: 1
Training loss: 0.08561807870864868
Validation loss: 1.532402280838259

Epoch: 6| Step: 2
Training loss: 0.08234213292598724
Validation loss: 1.5701373866809312

Epoch: 6| Step: 3
Training loss: 0.11014255881309509
Validation loss: 1.604619813221757

Epoch: 6| Step: 4
Training loss: 0.17945577204227448
Validation loss: 1.534071651838159

Epoch: 6| Step: 5
Training loss: 0.09068118035793304
Validation loss: 1.5637784209302676

Epoch: 6| Step: 6
Training loss: 0.070992112159729
Validation loss: 1.5430677283194758

Epoch: 6| Step: 7
Training loss: 0.10134094953536987
Validation loss: 1.53561637350308

Epoch: 6| Step: 8
Training loss: 0.10800549387931824
Validation loss: 1.5385944804837626

Epoch: 6| Step: 9
Training loss: 0.1549021303653717
Validation loss: 1.5544316114917878

Epoch: 6| Step: 10
Training loss: 0.0801272988319397
Validation loss: 1.5487874169503488

Epoch: 6| Step: 11
Training loss: 0.10457399487495422
Validation loss: 1.5271329373441718

Epoch: 6| Step: 12
Training loss: 0.0693349838256836
Validation loss: 1.5507341097759944

Epoch: 6| Step: 13
Training loss: 0.0726795420050621
Validation loss: 1.5676102792063067

Epoch: 509| Step: 0
Training loss: 0.11506465077400208
Validation loss: 1.5651658068421066

Epoch: 6| Step: 1
Training loss: 0.1029505655169487
Validation loss: 1.5763657221230127

Epoch: 6| Step: 2
Training loss: 0.07923438400030136
Validation loss: 1.565003643753708

Epoch: 6| Step: 3
Training loss: 0.12325967848300934
Validation loss: 1.5597211878786805

Epoch: 6| Step: 4
Training loss: 0.13664750754833221
Validation loss: 1.5879336557080668

Epoch: 6| Step: 5
Training loss: 0.10818719118833542
Validation loss: 1.5607359922060402

Epoch: 6| Step: 6
Training loss: 0.07727552950382233
Validation loss: 1.5615982740156111

Epoch: 6| Step: 7
Training loss: 0.13911229372024536
Validation loss: 1.5762949310323244

Epoch: 6| Step: 8
Training loss: 0.14034593105316162
Validation loss: 1.5474331763482863

Epoch: 6| Step: 9
Training loss: 0.08487293124198914
Validation loss: 1.5517908527005104

Epoch: 6| Step: 10
Training loss: 0.08968702703714371
Validation loss: 1.5864630386393557

Epoch: 6| Step: 11
Training loss: 0.14027589559555054
Validation loss: 1.5678405902718986

Epoch: 6| Step: 12
Training loss: 0.11862562596797943
Validation loss: 1.582897445207001

Epoch: 6| Step: 13
Training loss: 0.1567099690437317
Validation loss: 1.5679488156431465

Epoch: 510| Step: 0
Training loss: 0.10105167329311371
Validation loss: 1.6036267357487832

Epoch: 6| Step: 1
Training loss: 0.14896991848945618
Validation loss: 1.587592068538871

Epoch: 6| Step: 2
Training loss: 0.0896746888756752
Validation loss: 1.6090247784891436

Epoch: 6| Step: 3
Training loss: 0.0799332708120346
Validation loss: 1.5743590477974183

Epoch: 6| Step: 4
Training loss: 0.16261635720729828
Validation loss: 1.5847117721393544

Epoch: 6| Step: 5
Training loss: 0.17932656407356262
Validation loss: 1.5866162674401396

Epoch: 6| Step: 6
Training loss: 0.10322681814432144
Validation loss: 1.575492114149114

Epoch: 6| Step: 7
Training loss: 0.1057155579328537
Validation loss: 1.5700996947544876

Epoch: 6| Step: 8
Training loss: 0.10165528208017349
Validation loss: 1.5998491112903883

Epoch: 6| Step: 9
Training loss: 0.20932090282440186
Validation loss: 1.5697794191298946

Epoch: 6| Step: 10
Training loss: 0.14795318245887756
Validation loss: 1.5815965321756178

Epoch: 6| Step: 11
Training loss: 0.0675322487950325
Validation loss: 1.5752441921541769

Epoch: 6| Step: 12
Training loss: 0.0813845694065094
Validation loss: 1.5772779756976711

Epoch: 6| Step: 13
Training loss: 0.143497034907341
Validation loss: 1.6394380407948648

Epoch: 511| Step: 0
Training loss: 0.12439101934432983
Validation loss: 1.6384753334906794

Epoch: 6| Step: 1
Training loss: 0.15185680985450745
Validation loss: 1.6341079665768532

Epoch: 6| Step: 2
Training loss: 0.11623696982860565
Validation loss: 1.6308540631366033

Epoch: 6| Step: 3
Training loss: 0.15853317081928253
Validation loss: 1.6009972133944113

Epoch: 6| Step: 4
Training loss: 0.12130199372768402
Validation loss: 1.594748003508455

Epoch: 6| Step: 5
Training loss: 0.19965505599975586
Validation loss: 1.57069516951038

Epoch: 6| Step: 6
Training loss: 0.09305046498775482
Validation loss: 1.5692499555567259

Epoch: 6| Step: 7
Training loss: 0.1886933594942093
Validation loss: 1.5762545959923857

Epoch: 6| Step: 8
Training loss: 0.13224047422409058
Validation loss: 1.5274600213573826

Epoch: 6| Step: 9
Training loss: 0.10723262280225754
Validation loss: 1.5463789624552573

Epoch: 6| Step: 10
Training loss: 0.09126885235309601
Validation loss: 1.5549264556618148

Epoch: 6| Step: 11
Training loss: 0.0975504070520401
Validation loss: 1.568624242659538

Epoch: 6| Step: 12
Training loss: 0.11410542577505112
Validation loss: 1.5616841495677989

Epoch: 6| Step: 13
Training loss: 0.09952256083488464
Validation loss: 1.569786871633222

Epoch: 512| Step: 0
Training loss: 0.10414138436317444
Validation loss: 1.5824661459974063

Epoch: 6| Step: 1
Training loss: 0.0898008793592453
Validation loss: 1.5946202220455292

Epoch: 6| Step: 2
Training loss: 0.15437917411327362
Validation loss: 1.5830784830995785

Epoch: 6| Step: 3
Training loss: 0.119625523686409
Validation loss: 1.6186858761695124

Epoch: 6| Step: 4
Training loss: 0.15015389025211334
Validation loss: 1.610297849101405

Epoch: 6| Step: 5
Training loss: 0.08967956900596619
Validation loss: 1.5883698710190353

Epoch: 6| Step: 6
Training loss: 0.08989807963371277
Validation loss: 1.5575901013548656

Epoch: 6| Step: 7
Training loss: 0.09016960859298706
Validation loss: 1.5429986164134035

Epoch: 6| Step: 8
Training loss: 0.1131562739610672
Validation loss: 1.5510243927278826

Epoch: 6| Step: 9
Training loss: 0.15279309451580048
Validation loss: 1.5477692574583075

Epoch: 6| Step: 10
Training loss: 0.21046878397464752
Validation loss: 1.5495616620586765

Epoch: 6| Step: 11
Training loss: 0.15451133251190186
Validation loss: 1.5526252126180997

Epoch: 6| Step: 12
Training loss: 0.0992954671382904
Validation loss: 1.5808077742976527

Epoch: 6| Step: 13
Training loss: 0.1266738772392273
Validation loss: 1.5638460100338023

Epoch: 513| Step: 0
Training loss: 0.11065274477005005
Validation loss: 1.5680713179290935

Epoch: 6| Step: 1
Training loss: 0.13896088302135468
Validation loss: 1.5924687001012987

Epoch: 6| Step: 2
Training loss: 0.09155361354351044
Validation loss: 1.5871240605590164

Epoch: 6| Step: 3
Training loss: 0.17672455310821533
Validation loss: 1.643530309841197

Epoch: 6| Step: 4
Training loss: 0.09288260340690613
Validation loss: 1.5775255310919978

Epoch: 6| Step: 5
Training loss: 0.07296997308731079
Validation loss: 1.6078316319373347

Epoch: 6| Step: 6
Training loss: 0.1525706797838211
Validation loss: 1.5749703402160316

Epoch: 6| Step: 7
Training loss: 0.14387208223342896
Validation loss: 1.5842606175330378

Epoch: 6| Step: 8
Training loss: 0.09672780334949493
Validation loss: 1.5760742451554985

Epoch: 6| Step: 9
Training loss: 0.11353109776973724
Validation loss: 1.5877648566358833

Epoch: 6| Step: 10
Training loss: 0.10014066100120544
Validation loss: 1.531678791969053

Epoch: 6| Step: 11
Training loss: 0.11873815953731537
Validation loss: 1.5528093986613776

Epoch: 6| Step: 12
Training loss: 0.18160457909107208
Validation loss: 1.5630110848334529

Epoch: 6| Step: 13
Training loss: 0.15452921390533447
Validation loss: 1.5268489109572543

Epoch: 514| Step: 0
Training loss: 0.09208203852176666
Validation loss: 1.5739018058264127

Epoch: 6| Step: 1
Training loss: 0.06205469369888306
Validation loss: 1.548450143106522

Epoch: 6| Step: 2
Training loss: 0.09937834739685059
Validation loss: 1.533943389051704

Epoch: 6| Step: 3
Training loss: 0.06735347211360931
Validation loss: 1.567668040593465

Epoch: 6| Step: 4
Training loss: 0.23507416248321533
Validation loss: 1.5869675246618127

Epoch: 6| Step: 5
Training loss: 0.12537068128585815
Validation loss: 1.5562298938792238

Epoch: 6| Step: 6
Training loss: 0.12434610724449158
Validation loss: 1.5865165802740282

Epoch: 6| Step: 7
Training loss: 0.09180920571088791
Validation loss: 1.5926022260419783

Epoch: 6| Step: 8
Training loss: 0.0671430230140686
Validation loss: 1.6072759538568475

Epoch: 6| Step: 9
Training loss: 0.07341386377811432
Validation loss: 1.594486621118361

Epoch: 6| Step: 10
Training loss: 0.16261780261993408
Validation loss: 1.605109207091793

Epoch: 6| Step: 11
Training loss: 0.17395447194576263
Validation loss: 1.6014088123075423

Epoch: 6| Step: 12
Training loss: 0.11180429905653
Validation loss: 1.5749639464962868

Epoch: 6| Step: 13
Training loss: 0.14136259257793427
Validation loss: 1.5633314207036009

Epoch: 515| Step: 0
Training loss: 0.10061022639274597
Validation loss: 1.5509345723736672

Epoch: 6| Step: 1
Training loss: 0.05541783571243286
Validation loss: 1.5671384937019759

Epoch: 6| Step: 2
Training loss: 0.07537737488746643
Validation loss: 1.5198576078620007

Epoch: 6| Step: 3
Training loss: 0.1416308879852295
Validation loss: 1.5136911369139148

Epoch: 6| Step: 4
Training loss: 0.11339432001113892
Validation loss: 1.4983344795883342

Epoch: 6| Step: 5
Training loss: 0.19281190633773804
Validation loss: 1.5244108758946902

Epoch: 6| Step: 6
Training loss: 0.13580261170864105
Validation loss: 1.5300689666501937

Epoch: 6| Step: 7
Training loss: 0.0695178210735321
Validation loss: 1.5391630049674743

Epoch: 6| Step: 8
Training loss: 0.12114028632640839
Validation loss: 1.528274961697158

Epoch: 6| Step: 9
Training loss: 0.12431365251541138
Validation loss: 1.5424583752950032

Epoch: 6| Step: 10
Training loss: 0.14431461691856384
Validation loss: 1.5576747937869

Epoch: 6| Step: 11
Training loss: 0.08376982808113098
Validation loss: 1.5547094447638399

Epoch: 6| Step: 12
Training loss: 0.08571226894855499
Validation loss: 1.6036934609054236

Epoch: 6| Step: 13
Training loss: 0.12021875381469727
Validation loss: 1.5789578166059268

Epoch: 516| Step: 0
Training loss: 0.08880678564310074
Validation loss: 1.574526321503424

Epoch: 6| Step: 1
Training loss: 0.08687818795442581
Validation loss: 1.6120811508547874

Epoch: 6| Step: 2
Training loss: 0.09229762852191925
Validation loss: 1.5721711535607614

Epoch: 6| Step: 3
Training loss: 0.13965953886508942
Validation loss: 1.566484506412219

Epoch: 6| Step: 4
Training loss: 0.07155144214630127
Validation loss: 1.5538819605304348

Epoch: 6| Step: 5
Training loss: 0.07128217816352844
Validation loss: 1.5255264223262828

Epoch: 6| Step: 6
Training loss: 0.11524532735347748
Validation loss: 1.5376907087141467

Epoch: 6| Step: 7
Training loss: 0.12868651747703552
Validation loss: 1.5350182517882316

Epoch: 6| Step: 8
Training loss: 0.14138999581336975
Validation loss: 1.5029117573973954

Epoch: 6| Step: 9
Training loss: 0.19828113913536072
Validation loss: 1.525171870826393

Epoch: 6| Step: 10
Training loss: 0.21356378495693207
Validation loss: 1.5157609690902054

Epoch: 6| Step: 11
Training loss: 0.07401446253061295
Validation loss: 1.5263885208355483

Epoch: 6| Step: 12
Training loss: 0.11084185540676117
Validation loss: 1.5343486391088015

Epoch: 6| Step: 13
Training loss: 0.04934734106063843
Validation loss: 1.5317089224374423

Epoch: 517| Step: 0
Training loss: 0.15872247517108917
Validation loss: 1.5360402317457302

Epoch: 6| Step: 1
Training loss: 0.0935254767537117
Validation loss: 1.549773427747911

Epoch: 6| Step: 2
Training loss: 0.10724440962076187
Validation loss: 1.5276001371363157

Epoch: 6| Step: 3
Training loss: 0.09810413420200348
Validation loss: 1.5529118353320706

Epoch: 6| Step: 4
Training loss: 0.12714549899101257
Validation loss: 1.5667545103257703

Epoch: 6| Step: 5
Training loss: 0.08006490767002106
Validation loss: 1.5659212271372478

Epoch: 6| Step: 6
Training loss: 0.11333481222391129
Validation loss: 1.5561430261981102

Epoch: 6| Step: 7
Training loss: 0.06683776527643204
Validation loss: 1.5420588601020075

Epoch: 6| Step: 8
Training loss: 0.03966960310935974
Validation loss: 1.5723811336742934

Epoch: 6| Step: 9
Training loss: 0.1275356560945511
Validation loss: 1.5841509283229869

Epoch: 6| Step: 10
Training loss: 0.11703962087631226
Validation loss: 1.6090002418846212

Epoch: 6| Step: 11
Training loss: 0.13546939194202423
Validation loss: 1.6032225239661433

Epoch: 6| Step: 12
Training loss: 0.13681238889694214
Validation loss: 1.6077989891011228

Epoch: 6| Step: 13
Training loss: 0.07716014981269836
Validation loss: 1.5735705052652667

Epoch: 518| Step: 0
Training loss: 0.06463116407394409
Validation loss: 1.5711846120895878

Epoch: 6| Step: 1
Training loss: 0.09414976090192795
Validation loss: 1.5486917406000116

Epoch: 6| Step: 2
Training loss: 0.07697060704231262
Validation loss: 1.5750524459346649

Epoch: 6| Step: 3
Training loss: 0.07212468981742859
Validation loss: 1.5784028499357161

Epoch: 6| Step: 4
Training loss: 0.15846675634384155
Validation loss: 1.5471943245139173

Epoch: 6| Step: 5
Training loss: 0.07630105316638947
Validation loss: 1.530462630333439

Epoch: 6| Step: 6
Training loss: 0.07749705761671066
Validation loss: 1.5450180692057456

Epoch: 6| Step: 7
Training loss: 0.1764962375164032
Validation loss: 1.533977570072297

Epoch: 6| Step: 8
Training loss: 0.044496338814496994
Validation loss: 1.5497246250029533

Epoch: 6| Step: 9
Training loss: 0.06978248804807663
Validation loss: 1.5214406610817037

Epoch: 6| Step: 10
Training loss: 0.14038468897342682
Validation loss: 1.545643482156979

Epoch: 6| Step: 11
Training loss: 0.14879268407821655
Validation loss: 1.5579865568427629

Epoch: 6| Step: 12
Training loss: 0.07916511595249176
Validation loss: 1.536151115612317

Epoch: 6| Step: 13
Training loss: 0.06802504509687424
Validation loss: 1.5514876714316748

Epoch: 519| Step: 0
Training loss: 0.10512852668762207
Validation loss: 1.5701500549111316

Epoch: 6| Step: 1
Training loss: 0.09428835660219193
Validation loss: 1.5835893718145226

Epoch: 6| Step: 2
Training loss: 0.1358841061592102
Validation loss: 1.569749366852545

Epoch: 6| Step: 3
Training loss: 0.14613747596740723
Validation loss: 1.556576330174682

Epoch: 6| Step: 4
Training loss: 0.12923631072044373
Validation loss: 1.5785138709570772

Epoch: 6| Step: 5
Training loss: 0.10809143632650375
Validation loss: 1.5444277063492806

Epoch: 6| Step: 6
Training loss: 0.049056001007556915
Validation loss: 1.5410175041485858

Epoch: 6| Step: 7
Training loss: 0.08927404880523682
Validation loss: 1.542349071912868

Epoch: 6| Step: 8
Training loss: 0.10969734191894531
Validation loss: 1.5179447820109706

Epoch: 6| Step: 9
Training loss: 0.06655135005712509
Validation loss: 1.5120681703731578

Epoch: 6| Step: 10
Training loss: 0.08733321726322174
Validation loss: 1.528524500067516

Epoch: 6| Step: 11
Training loss: 0.11706569045782089
Validation loss: 1.516646828702701

Epoch: 6| Step: 12
Training loss: 0.06627530604600906
Validation loss: 1.5416191841966362

Epoch: 6| Step: 13
Training loss: 0.08586201071739197
Validation loss: 1.5484322860676756

Epoch: 520| Step: 0
Training loss: 0.13330072164535522
Validation loss: 1.5426117912415536

Epoch: 6| Step: 1
Training loss: 0.07802102714776993
Validation loss: 1.5454873782332226

Epoch: 6| Step: 2
Training loss: 0.10359127819538116
Validation loss: 1.5482863738972654

Epoch: 6| Step: 3
Training loss: 0.1073278933763504
Validation loss: 1.5429673579431349

Epoch: 6| Step: 4
Training loss: 0.16661089658737183
Validation loss: 1.5406978899432766

Epoch: 6| Step: 5
Training loss: 0.0940627008676529
Validation loss: 1.5195098826962132

Epoch: 6| Step: 6
Training loss: 0.14306744933128357
Validation loss: 1.5191216007355721

Epoch: 6| Step: 7
Training loss: 0.11766529828310013
Validation loss: 1.496575399111676

Epoch: 6| Step: 8
Training loss: 0.09039807319641113
Validation loss: 1.5406225214722336

Epoch: 6| Step: 9
Training loss: 0.15562531352043152
Validation loss: 1.5009616959479548

Epoch: 6| Step: 10
Training loss: 0.11791051179170609
Validation loss: 1.5202905734380086

Epoch: 6| Step: 11
Training loss: 0.10550519824028015
Validation loss: 1.5309625287209787

Epoch: 6| Step: 12
Training loss: 0.08690395951271057
Validation loss: 1.5333853767764183

Epoch: 6| Step: 13
Training loss: 0.11974826455116272
Validation loss: 1.5285757305801555

Epoch: 521| Step: 0
Training loss: 0.0512702651321888
Validation loss: 1.55136138649397

Epoch: 6| Step: 1
Training loss: 0.1282041370868683
Validation loss: 1.530763223607053

Epoch: 6| Step: 2
Training loss: 0.10481537878513336
Validation loss: 1.5153959617819837

Epoch: 6| Step: 3
Training loss: 0.06702722609043121
Validation loss: 1.565610420319342

Epoch: 6| Step: 4
Training loss: 0.12613259255886078
Validation loss: 1.5491195135219122

Epoch: 6| Step: 5
Training loss: 0.1208079606294632
Validation loss: 1.5328137964330695

Epoch: 6| Step: 6
Training loss: 0.14184026420116425
Validation loss: 1.5432526475639754

Epoch: 6| Step: 7
Training loss: 0.09239093959331512
Validation loss: 1.5298731685966573

Epoch: 6| Step: 8
Training loss: 0.049416251480579376
Validation loss: 1.5574864866913005

Epoch: 6| Step: 9
Training loss: 0.06112079322338104
Validation loss: 1.536714861469884

Epoch: 6| Step: 10
Training loss: 0.06450788676738739
Validation loss: 1.5748145093200028

Epoch: 6| Step: 11
Training loss: 0.09461577236652374
Validation loss: 1.5703524299847182

Epoch: 6| Step: 12
Training loss: 0.0822516605257988
Validation loss: 1.594030241812429

Epoch: 6| Step: 13
Training loss: 0.08115337789058685
Validation loss: 1.593732173724841

Epoch: 522| Step: 0
Training loss: 0.11542882025241852
Validation loss: 1.6087979514111754

Epoch: 6| Step: 1
Training loss: 0.10535503923892975
Validation loss: 1.6288027532639042

Epoch: 6| Step: 2
Training loss: 0.16077499091625214
Validation loss: 1.6376924489134101

Epoch: 6| Step: 3
Training loss: 0.11755731701850891
Validation loss: 1.6392182124558317

Epoch: 6| Step: 4
Training loss: 0.11814987659454346
Validation loss: 1.6557637132624143

Epoch: 6| Step: 5
Training loss: 0.1120147705078125
Validation loss: 1.6160288703057073

Epoch: 6| Step: 6
Training loss: 0.10557402670383453
Validation loss: 1.6141125117578814

Epoch: 6| Step: 7
Training loss: 0.13728398084640503
Validation loss: 1.6048704731848933

Epoch: 6| Step: 8
Training loss: 0.08115889877080917
Validation loss: 1.5830107837594964

Epoch: 6| Step: 9
Training loss: 0.11265450716018677
Validation loss: 1.5875713735498407

Epoch: 6| Step: 10
Training loss: 0.07641039788722992
Validation loss: 1.5703874300884944

Epoch: 6| Step: 11
Training loss: 0.0949845016002655
Validation loss: 1.571049694092043

Epoch: 6| Step: 12
Training loss: 0.0988900288939476
Validation loss: 1.5539491663696945

Epoch: 6| Step: 13
Training loss: 0.07384917140007019
Validation loss: 1.5467063355189499

Epoch: 523| Step: 0
Training loss: 0.04778861254453659
Validation loss: 1.5527578541027602

Epoch: 6| Step: 1
Training loss: 0.0832805186510086
Validation loss: 1.513638993745209

Epoch: 6| Step: 2
Training loss: 0.06133286654949188
Validation loss: 1.521828992392427

Epoch: 6| Step: 3
Training loss: 0.1034315675497055
Validation loss: 1.534960603201261

Epoch: 6| Step: 4
Training loss: 0.07066495716571808
Validation loss: 1.5315335207088019

Epoch: 6| Step: 5
Training loss: 0.13863030076026917
Validation loss: 1.5463990383250739

Epoch: 6| Step: 6
Training loss: 0.07223084568977356
Validation loss: 1.5197017500477452

Epoch: 6| Step: 7
Training loss: 0.1452222466468811
Validation loss: 1.5068485506119267

Epoch: 6| Step: 8
Training loss: 0.07698175311088562
Validation loss: 1.524644741448023

Epoch: 6| Step: 9
Training loss: 0.08073034882545471
Validation loss: 1.5274952560342767

Epoch: 6| Step: 10
Training loss: 0.16362619400024414
Validation loss: 1.5304062084485126

Epoch: 6| Step: 11
Training loss: 0.08070816844701767
Validation loss: 1.5468364082356936

Epoch: 6| Step: 12
Training loss: 0.09442996978759766
Validation loss: 1.5660226550153507

Epoch: 6| Step: 13
Training loss: 0.06881295144557953
Validation loss: 1.5531995873297415

Epoch: 524| Step: 0
Training loss: 0.1440364420413971
Validation loss: 1.6035531220897552

Epoch: 6| Step: 1
Training loss: 0.071395143866539
Validation loss: 1.5730908045204737

Epoch: 6| Step: 2
Training loss: 0.1359882950782776
Validation loss: 1.6026617852590417

Epoch: 6| Step: 3
Training loss: 0.07873557507991791
Validation loss: 1.611652103803491

Epoch: 6| Step: 4
Training loss: 0.08122467994689941
Validation loss: 1.5691664244538994

Epoch: 6| Step: 5
Training loss: 0.13543707132339478
Validation loss: 1.5456842427612634

Epoch: 6| Step: 6
Training loss: 0.10274496674537659
Validation loss: 1.5659018075594338

Epoch: 6| Step: 7
Training loss: 0.10574966669082642
Validation loss: 1.5833089710563741

Epoch: 6| Step: 8
Training loss: 0.08896443247795105
Validation loss: 1.5851480089208132

Epoch: 6| Step: 9
Training loss: 0.17393866181373596
Validation loss: 1.573887704521097

Epoch: 6| Step: 10
Training loss: 0.07254108041524887
Validation loss: 1.5555279985550912

Epoch: 6| Step: 11
Training loss: 0.0941208004951477
Validation loss: 1.5587260735932218

Epoch: 6| Step: 12
Training loss: 0.11035534739494324
Validation loss: 1.535863523842186

Epoch: 6| Step: 13
Training loss: 0.05839262902736664
Validation loss: 1.5401580769528624

Epoch: 525| Step: 0
Training loss: 0.05644785612821579
Validation loss: 1.5586786564960275

Epoch: 6| Step: 1
Training loss: 0.1575150489807129
Validation loss: 1.5542006377250916

Epoch: 6| Step: 2
Training loss: 0.11653006821870804
Validation loss: 1.5460588823082626

Epoch: 6| Step: 3
Training loss: 0.0646602138876915
Validation loss: 1.5590731866898075

Epoch: 6| Step: 4
Training loss: 0.1340382695198059
Validation loss: 1.5550889071597849

Epoch: 6| Step: 5
Training loss: 0.17294850945472717
Validation loss: 1.5860887906884635

Epoch: 6| Step: 6
Training loss: 0.08738422393798828
Validation loss: 1.5665151957542665

Epoch: 6| Step: 7
Training loss: 0.15619710087776184
Validation loss: 1.5414998813342022

Epoch: 6| Step: 8
Training loss: 0.07831698656082153
Validation loss: 1.5420848067088793

Epoch: 6| Step: 9
Training loss: 0.05228397995233536
Validation loss: 1.5268108062846686

Epoch: 6| Step: 10
Training loss: 0.12859401106834412
Validation loss: 1.5325025255962084

Epoch: 6| Step: 11
Training loss: 0.07600048929452896
Validation loss: 1.548295138984598

Epoch: 6| Step: 12
Training loss: 0.1331540048122406
Validation loss: 1.5515457404557096

Epoch: 6| Step: 13
Training loss: 0.06905721127986908
Validation loss: 1.5527350114237877

Epoch: 526| Step: 0
Training loss: 0.0705404058098793
Validation loss: 1.5425919230266283

Epoch: 6| Step: 1
Training loss: 0.10708606243133545
Validation loss: 1.5390566138811008

Epoch: 6| Step: 2
Training loss: 0.08762776851654053
Validation loss: 1.5394472665684198

Epoch: 6| Step: 3
Training loss: 0.0981312245130539
Validation loss: 1.562775129913002

Epoch: 6| Step: 4
Training loss: 0.1014532744884491
Validation loss: 1.564220392575828

Epoch: 6| Step: 5
Training loss: 0.11870519816875458
Validation loss: 1.588735777844665

Epoch: 6| Step: 6
Training loss: 0.08338563144207001
Validation loss: 1.558699095120994

Epoch: 6| Step: 7
Training loss: 0.1577136516571045
Validation loss: 1.6022886627463884

Epoch: 6| Step: 8
Training loss: 0.11623437702655792
Validation loss: 1.5591126962374615

Epoch: 6| Step: 9
Training loss: 0.08157852292060852
Validation loss: 1.531793612305836

Epoch: 6| Step: 10
Training loss: 0.09970758855342865
Validation loss: 1.5693919735570108

Epoch: 6| Step: 11
Training loss: 0.24695520102977753
Validation loss: 1.580032604996876

Epoch: 6| Step: 12
Training loss: 0.07555107772350311
Validation loss: 1.5408894977261942

Epoch: 6| Step: 13
Training loss: 0.20553454756736755
Validation loss: 1.5185853306965162

Epoch: 527| Step: 0
Training loss: 0.12869155406951904
Validation loss: 1.512527040255967

Epoch: 6| Step: 1
Training loss: 0.06451922655105591
Validation loss: 1.5232081387632637

Epoch: 6| Step: 2
Training loss: 0.11796405911445618
Validation loss: 1.5403885591414668

Epoch: 6| Step: 3
Training loss: 0.11665128171443939
Validation loss: 1.5520375326115599

Epoch: 6| Step: 4
Training loss: 0.16937854886054993
Validation loss: 1.5648440532786871

Epoch: 6| Step: 5
Training loss: 0.14566965401172638
Validation loss: 1.5800847686747068

Epoch: 6| Step: 6
Training loss: 0.13424324989318848
Validation loss: 1.5970652949425481

Epoch: 6| Step: 7
Training loss: 0.07334789633750916
Validation loss: 1.5633844226919196

Epoch: 6| Step: 8
Training loss: 0.11887028068304062
Validation loss: 1.5653185024056384

Epoch: 6| Step: 9
Training loss: 0.11813545227050781
Validation loss: 1.5601584372981903

Epoch: 6| Step: 10
Training loss: 0.14668115973472595
Validation loss: 1.519729656557883

Epoch: 6| Step: 11
Training loss: 0.10990908741950989
Validation loss: 1.5215221854948229

Epoch: 6| Step: 12
Training loss: 0.07945804297924042
Validation loss: 1.510869659403319

Epoch: 6| Step: 13
Training loss: 0.126492440700531
Validation loss: 1.5282615192474858

Epoch: 528| Step: 0
Training loss: 0.08470353484153748
Validation loss: 1.5165901107172812

Epoch: 6| Step: 1
Training loss: 0.14696115255355835
Validation loss: 1.5319399808042793

Epoch: 6| Step: 2
Training loss: 0.09109707921743393
Validation loss: 1.5187670210356354

Epoch: 6| Step: 3
Training loss: 0.08600297570228577
Validation loss: 1.5456600278936408

Epoch: 6| Step: 4
Training loss: 0.12171586602926254
Validation loss: 1.552806778620648

Epoch: 6| Step: 5
Training loss: 0.08236142992973328
Validation loss: 1.5413338118983853

Epoch: 6| Step: 6
Training loss: 0.084745392203331
Validation loss: 1.5439645410865865

Epoch: 6| Step: 7
Training loss: 0.11161324381828308
Validation loss: 1.5813166121000886

Epoch: 6| Step: 8
Training loss: 0.08051979541778564
Validation loss: 1.5490089693377096

Epoch: 6| Step: 9
Training loss: 0.09114325791597366
Validation loss: 1.5908414125442505

Epoch: 6| Step: 10
Training loss: 0.16963118314743042
Validation loss: 1.5501574905969764

Epoch: 6| Step: 11
Training loss: 0.1571073830127716
Validation loss: 1.5368908643722534

Epoch: 6| Step: 12
Training loss: 0.23411951959133148
Validation loss: 1.539478587847884

Epoch: 6| Step: 13
Training loss: 0.0793905258178711
Validation loss: 1.5311381124681043

Epoch: 529| Step: 0
Training loss: 0.11632920056581497
Validation loss: 1.5588753043964345

Epoch: 6| Step: 1
Training loss: 0.0830995962023735
Validation loss: 1.5334834437216482

Epoch: 6| Step: 2
Training loss: 0.07645907998085022
Validation loss: 1.5156674602980256

Epoch: 6| Step: 3
Training loss: 0.07023322582244873
Validation loss: 1.5296256965206516

Epoch: 6| Step: 4
Training loss: 0.12556950747966766
Validation loss: 1.5180137516349874

Epoch: 6| Step: 5
Training loss: 0.1569388210773468
Validation loss: 1.497611335528794

Epoch: 6| Step: 6
Training loss: 0.11398138850927353
Validation loss: 1.5029170666971514

Epoch: 6| Step: 7
Training loss: 0.14823420345783234
Validation loss: 1.5331580908067766

Epoch: 6| Step: 8
Training loss: 0.11508958041667938
Validation loss: 1.5680182403133762

Epoch: 6| Step: 9
Training loss: 0.07256750762462616
Validation loss: 1.5394398909743114

Epoch: 6| Step: 10
Training loss: 0.12261873483657837
Validation loss: 1.5582645234241281

Epoch: 6| Step: 11
Training loss: 0.0884961411356926
Validation loss: 1.596907728461809

Epoch: 6| Step: 12
Training loss: 0.12776502966880798
Validation loss: 1.5867444251173286

Epoch: 6| Step: 13
Training loss: 0.19410832226276398
Validation loss: 1.6302021729048861

Epoch: 530| Step: 0
Training loss: 0.0897301435470581
Validation loss: 1.6265964027374022

Epoch: 6| Step: 1
Training loss: 0.08706758916378021
Validation loss: 1.6462894191024124

Epoch: 6| Step: 2
Training loss: 0.12486103177070618
Validation loss: 1.5988166114335418

Epoch: 6| Step: 3
Training loss: 0.09935605525970459
Validation loss: 1.6310025479203911

Epoch: 6| Step: 4
Training loss: 0.15473505854606628
Validation loss: 1.5956250685517506

Epoch: 6| Step: 5
Training loss: 0.09331810474395752
Validation loss: 1.5910533961429392

Epoch: 6| Step: 6
Training loss: 0.1808048039674759
Validation loss: 1.592316560847785

Epoch: 6| Step: 7
Training loss: 0.14582595229148865
Validation loss: 1.573469728551885

Epoch: 6| Step: 8
Training loss: 0.12889809906482697
Validation loss: 1.5287810724268678

Epoch: 6| Step: 9
Training loss: 0.08392927795648575
Validation loss: 1.5397924274526618

Epoch: 6| Step: 10
Training loss: 0.1557643562555313
Validation loss: 1.534473180770874

Epoch: 6| Step: 11
Training loss: 0.10852883756160736
Validation loss: 1.553112644021229

Epoch: 6| Step: 12
Training loss: 0.16786259412765503
Validation loss: 1.5283783469148862

Epoch: 6| Step: 13
Training loss: 0.1290322095155716
Validation loss: 1.5205302225646151

Epoch: 531| Step: 0
Training loss: 0.07174234092235565
Validation loss: 1.5072492002159037

Epoch: 6| Step: 1
Training loss: 0.0677078440785408
Validation loss: 1.5245783457192041

Epoch: 6| Step: 2
Training loss: 0.1339114010334015
Validation loss: 1.5257671007546045

Epoch: 6| Step: 3
Training loss: 0.15786400437355042
Validation loss: 1.5321915457325597

Epoch: 6| Step: 4
Training loss: 0.129817932844162
Validation loss: 1.5189621602335284

Epoch: 6| Step: 5
Training loss: 0.11241356283426285
Validation loss: 1.5274865306833738

Epoch: 6| Step: 6
Training loss: 0.08916161209344864
Validation loss: 1.5578695189568303

Epoch: 6| Step: 7
Training loss: 0.09096604585647583
Validation loss: 1.5410983729106125

Epoch: 6| Step: 8
Training loss: 0.08426075428724289
Validation loss: 1.5490923363675353

Epoch: 6| Step: 9
Training loss: 0.050350211560726166
Validation loss: 1.5356016940968011

Epoch: 6| Step: 10
Training loss: 0.14757567644119263
Validation loss: 1.5110128464237336

Epoch: 6| Step: 11
Training loss: 0.09355784952640533
Validation loss: 1.5385173405370405

Epoch: 6| Step: 12
Training loss: 0.07712184637784958
Validation loss: 1.5405075152715046

Epoch: 6| Step: 13
Training loss: 0.1413664072751999
Validation loss: 1.5210011005401611

Epoch: 532| Step: 0
Training loss: 0.11056867241859436
Validation loss: 1.5351920935415453

Epoch: 6| Step: 1
Training loss: 0.07142893970012665
Validation loss: 1.5247313976287842

Epoch: 6| Step: 2
Training loss: 0.07376927882432938
Validation loss: 1.5172902973749305

Epoch: 6| Step: 3
Training loss: 0.10956978052854538
Validation loss: 1.527006168519297

Epoch: 6| Step: 4
Training loss: 0.06888140738010406
Validation loss: 1.5270576541141798

Epoch: 6| Step: 5
Training loss: 0.13379347324371338
Validation loss: 1.5496917898936937

Epoch: 6| Step: 6
Training loss: 0.08346286416053772
Validation loss: 1.5527451666452552

Epoch: 6| Step: 7
Training loss: 0.13655805587768555
Validation loss: 1.5586065758940995

Epoch: 6| Step: 8
Training loss: 0.14180320501327515
Validation loss: 1.603234298767582

Epoch: 6| Step: 9
Training loss: 0.04649485647678375
Validation loss: 1.6016508328017367

Epoch: 6| Step: 10
Training loss: 0.09959337115287781
Validation loss: 1.5893330484308221

Epoch: 6| Step: 11
Training loss: 0.07338845729827881
Validation loss: 1.6059991313565163

Epoch: 6| Step: 12
Training loss: 0.07885102927684784
Validation loss: 1.563119972905805

Epoch: 6| Step: 13
Training loss: 0.15177863836288452
Validation loss: 1.583251735215546

Epoch: 533| Step: 0
Training loss: 0.0926031842827797
Validation loss: 1.577593295804916

Epoch: 6| Step: 1
Training loss: 0.1481332778930664
Validation loss: 1.5731569669579948

Epoch: 6| Step: 2
Training loss: 0.08687290549278259
Validation loss: 1.5740874326357277

Epoch: 6| Step: 3
Training loss: 0.20487567782402039
Validation loss: 1.5266549023248817

Epoch: 6| Step: 4
Training loss: 0.11209458112716675
Validation loss: 1.5505844335402212

Epoch: 6| Step: 5
Training loss: 0.10497189313173294
Validation loss: 1.551222808899418

Epoch: 6| Step: 6
Training loss: 0.07484004646539688
Validation loss: 1.514777228396426

Epoch: 6| Step: 7
Training loss: 0.09082227945327759
Validation loss: 1.5356968936099802

Epoch: 6| Step: 8
Training loss: 0.1296464055776596
Validation loss: 1.5206834693108835

Epoch: 6| Step: 9
Training loss: 0.06249796971678734
Validation loss: 1.5376802362421507

Epoch: 6| Step: 10
Training loss: 0.07537289708852768
Validation loss: 1.5189599048706792

Epoch: 6| Step: 11
Training loss: 0.08909668028354645
Validation loss: 1.52373985193109

Epoch: 6| Step: 12
Training loss: 0.09662365168333054
Validation loss: 1.536598211975508

Epoch: 6| Step: 13
Training loss: 0.1177108958363533
Validation loss: 1.5478422257208055

Epoch: 534| Step: 0
Training loss: 0.11676125228404999
Validation loss: 1.5301788032695811

Epoch: 6| Step: 1
Training loss: 0.11787156760692596
Validation loss: 1.543287661767775

Epoch: 6| Step: 2
Training loss: 0.07450287789106369
Validation loss: 1.5160927131611814

Epoch: 6| Step: 3
Training loss: 0.10635153949260712
Validation loss: 1.5439282027623986

Epoch: 6| Step: 4
Training loss: 0.0964265912771225
Validation loss: 1.5552408695220947

Epoch: 6| Step: 5
Training loss: 0.08766748011112213
Validation loss: 1.5440196003965152

Epoch: 6| Step: 6
Training loss: 0.12108096480369568
Validation loss: 1.5708023604526316

Epoch: 6| Step: 7
Training loss: 0.08822151273488998
Validation loss: 1.559019782209909

Epoch: 6| Step: 8
Training loss: 0.05796701833605766
Validation loss: 1.5657911351931992

Epoch: 6| Step: 9
Training loss: 0.1437467634677887
Validation loss: 1.5287924671685824

Epoch: 6| Step: 10
Training loss: 0.06411194056272507
Validation loss: 1.5742629817737046

Epoch: 6| Step: 11
Training loss: 0.16753540933132172
Validation loss: 1.571469432564192

Epoch: 6| Step: 12
Training loss: 0.09711478650569916
Validation loss: 1.576246807652135

Epoch: 6| Step: 13
Training loss: 0.09130503237247467
Validation loss: 1.5806979953601796

Epoch: 535| Step: 0
Training loss: 0.12177848815917969
Validation loss: 1.5420595856123074

Epoch: 6| Step: 1
Training loss: 0.08676621317863464
Validation loss: 1.542550991940242

Epoch: 6| Step: 2
Training loss: 0.1724715530872345
Validation loss: 1.517277886790614

Epoch: 6| Step: 3
Training loss: 0.10531465709209442
Validation loss: 1.5229764100044005

Epoch: 6| Step: 4
Training loss: 0.09690553694963455
Validation loss: 1.5286006619853358

Epoch: 6| Step: 5
Training loss: 0.12527358531951904
Validation loss: 1.5023000342871553

Epoch: 6| Step: 6
Training loss: 0.10778659582138062
Validation loss: 1.5050426349844983

Epoch: 6| Step: 7
Training loss: 0.09755728393793106
Validation loss: 1.520916155589524

Epoch: 6| Step: 8
Training loss: 0.10544997453689575
Validation loss: 1.5201626490521174

Epoch: 6| Step: 9
Training loss: 0.10205122828483582
Validation loss: 1.491609989955861

Epoch: 6| Step: 10
Training loss: 0.0667189359664917
Validation loss: 1.4954404254113474

Epoch: 6| Step: 11
Training loss: 0.07557697594165802
Validation loss: 1.5177293849247757

Epoch: 6| Step: 12
Training loss: 0.08205634355545044
Validation loss: 1.4983200744916034

Epoch: 6| Step: 13
Training loss: 0.04765719175338745
Validation loss: 1.4770256268080844

Epoch: 536| Step: 0
Training loss: 0.09041352570056915
Validation loss: 1.548932437614728

Epoch: 6| Step: 1
Training loss: 0.09884951263666153
Validation loss: 1.5250266662207983

Epoch: 6| Step: 2
Training loss: 0.10637399554252625
Validation loss: 1.5071362551822458

Epoch: 6| Step: 3
Training loss: 0.0815153494477272
Validation loss: 1.4974794951818322

Epoch: 6| Step: 4
Training loss: 0.09644797444343567
Validation loss: 1.5625298253951534

Epoch: 6| Step: 5
Training loss: 0.0836249366402626
Validation loss: 1.5255257442433348

Epoch: 6| Step: 6
Training loss: 0.09114348143339157
Validation loss: 1.537267836191321

Epoch: 6| Step: 7
Training loss: 0.060718901455402374
Validation loss: 1.5622830711385256

Epoch: 6| Step: 8
Training loss: 0.11819715797901154
Validation loss: 1.5692202198889948

Epoch: 6| Step: 9
Training loss: 0.048323508352041245
Validation loss: 1.5682318915602982

Epoch: 6| Step: 10
Training loss: 0.10090749710798264
Validation loss: 1.5667446556911673

Epoch: 6| Step: 11
Training loss: 0.11288454383611679
Validation loss: 1.586545136667067

Epoch: 6| Step: 12
Training loss: 0.1202758252620697
Validation loss: 1.6037089863131124

Epoch: 6| Step: 13
Training loss: 0.08350370824337006
Validation loss: 1.5596413022728377

Epoch: 537| Step: 0
Training loss: 0.11169500648975372
Validation loss: 1.558526066041762

Epoch: 6| Step: 1
Training loss: 0.09403209388256073
Validation loss: 1.5318823027354416

Epoch: 6| Step: 2
Training loss: 0.11721626669168472
Validation loss: 1.5152187770412815

Epoch: 6| Step: 3
Training loss: 0.11499997973442078
Validation loss: 1.514795252071914

Epoch: 6| Step: 4
Training loss: 0.06840130686759949
Validation loss: 1.5168246863990702

Epoch: 6| Step: 5
Training loss: 0.08228837698698044
Validation loss: 1.4973494147741666

Epoch: 6| Step: 6
Training loss: 0.11279118806123734
Validation loss: 1.5092262593648766

Epoch: 6| Step: 7
Training loss: 0.13045665621757507
Validation loss: 1.502954715041704

Epoch: 6| Step: 8
Training loss: 0.11567796021699905
Validation loss: 1.5337878401561449

Epoch: 6| Step: 9
Training loss: 0.10515578091144562
Validation loss: 1.5124365309233307

Epoch: 6| Step: 10
Training loss: 0.09950374066829681
Validation loss: 1.5382518768310547

Epoch: 6| Step: 11
Training loss: 0.10242107510566711
Validation loss: 1.5417220554044169

Epoch: 6| Step: 12
Training loss: 0.06292036175727844
Validation loss: 1.5761876247262443

Epoch: 6| Step: 13
Training loss: 0.11744377017021179
Validation loss: 1.5436284003719207

Epoch: 538| Step: 0
Training loss: 0.12613484263420105
Validation loss: 1.586322940805907

Epoch: 6| Step: 1
Training loss: 0.09666687995195389
Validation loss: 1.5962867377906718

Epoch: 6| Step: 2
Training loss: 0.08076449483633041
Validation loss: 1.6052751079682381

Epoch: 6| Step: 3
Training loss: 0.08281445503234863
Validation loss: 1.5603181854371102

Epoch: 6| Step: 4
Training loss: 0.14968864619731903
Validation loss: 1.557293233051095

Epoch: 6| Step: 5
Training loss: 0.0889538824558258
Validation loss: 1.549247266143881

Epoch: 6| Step: 6
Training loss: 0.054673440754413605
Validation loss: 1.5712701335389128

Epoch: 6| Step: 7
Training loss: 0.12178406119346619
Validation loss: 1.5662381302925847

Epoch: 6| Step: 8
Training loss: 0.0809231847524643
Validation loss: 1.5663287229435419

Epoch: 6| Step: 9
Training loss: 0.08094820380210876
Validation loss: 1.5725393013287616

Epoch: 6| Step: 10
Training loss: 0.13927021622657776
Validation loss: 1.5509392548632879

Epoch: 6| Step: 11
Training loss: 0.07837239652872086
Validation loss: 1.5519078546954739

Epoch: 6| Step: 12
Training loss: 0.08643539249897003
Validation loss: 1.5611666402509135

Epoch: 6| Step: 13
Training loss: 0.07924313098192215
Validation loss: 1.5695366000616422

Epoch: 539| Step: 0
Training loss: 0.11143554747104645
Validation loss: 1.570351477592222

Epoch: 6| Step: 1
Training loss: 0.08813861757516861
Validation loss: 1.5670423764054493

Epoch: 6| Step: 2
Training loss: 0.20348864793777466
Validation loss: 1.5716322673264371

Epoch: 6| Step: 3
Training loss: 0.05443504452705383
Validation loss: 1.5531936896744596

Epoch: 6| Step: 4
Training loss: 0.08029136806726456
Validation loss: 1.5387949969178887

Epoch: 6| Step: 5
Training loss: 0.13216140866279602
Validation loss: 1.570624238701277

Epoch: 6| Step: 6
Training loss: 0.10148502141237259
Validation loss: 1.5539564868455291

Epoch: 6| Step: 7
Training loss: 0.1587435007095337
Validation loss: 1.5665643189543037

Epoch: 6| Step: 8
Training loss: 0.08703088760375977
Validation loss: 1.5411448632517168

Epoch: 6| Step: 9
Training loss: 0.11409944295883179
Validation loss: 1.599649824121947

Epoch: 6| Step: 10
Training loss: 0.10351541638374329
Validation loss: 1.571754099861268

Epoch: 6| Step: 11
Training loss: 0.09557605534791946
Validation loss: 1.5798876362462198

Epoch: 6| Step: 12
Training loss: 0.17323553562164307
Validation loss: 1.5665659084114978

Epoch: 6| Step: 13
Training loss: 0.13348205387592316
Validation loss: 1.5576583531595045

Epoch: 540| Step: 0
Training loss: 0.11034180223941803
Validation loss: 1.5505096515019734

Epoch: 6| Step: 1
Training loss: 0.05277451127767563
Validation loss: 1.528133847380197

Epoch: 6| Step: 2
Training loss: 0.16562458872795105
Validation loss: 1.5263740401114188

Epoch: 6| Step: 3
Training loss: 0.08971768617630005
Validation loss: 1.5324582476769724

Epoch: 6| Step: 4
Training loss: 0.060542233288288116
Validation loss: 1.5167652265999907

Epoch: 6| Step: 5
Training loss: 0.12108726799488068
Validation loss: 1.5507222580653366

Epoch: 6| Step: 6
Training loss: 0.08068728446960449
Validation loss: 1.5236677738928026

Epoch: 6| Step: 7
Training loss: 0.12441779673099518
Validation loss: 1.5415361286491476

Epoch: 6| Step: 8
Training loss: 0.1090814620256424
Validation loss: 1.5403038763230847

Epoch: 6| Step: 9
Training loss: 0.11242435872554779
Validation loss: 1.550915119468525

Epoch: 6| Step: 10
Training loss: 0.11499445885419846
Validation loss: 1.5510172869569512

Epoch: 6| Step: 11
Training loss: 0.09051015973091125
Validation loss: 1.539449586663195

Epoch: 6| Step: 12
Training loss: 0.08874324709177017
Validation loss: 1.573111170081682

Epoch: 6| Step: 13
Training loss: 0.053853027522563934
Validation loss: 1.5372662057158768

Epoch: 541| Step: 0
Training loss: 0.07565370202064514
Validation loss: 1.551968168186885

Epoch: 6| Step: 1
Training loss: 0.11050349473953247
Validation loss: 1.5445009482804166

Epoch: 6| Step: 2
Training loss: 0.051117487251758575
Validation loss: 1.5303043742333688

Epoch: 6| Step: 3
Training loss: 0.08301372826099396
Validation loss: 1.5334820132101736

Epoch: 6| Step: 4
Training loss: 0.09970061480998993
Validation loss: 1.5236796256034606

Epoch: 6| Step: 5
Training loss: 0.11380475014448166
Validation loss: 1.567605301898013

Epoch: 6| Step: 6
Training loss: 0.11978494375944138
Validation loss: 1.5586372959998347

Epoch: 6| Step: 7
Training loss: 0.1044897511601448
Validation loss: 1.570464207920977

Epoch: 6| Step: 8
Training loss: 0.130742609500885
Validation loss: 1.5827100507674678

Epoch: 6| Step: 9
Training loss: 0.16622154414653778
Validation loss: 1.5931629262944704

Epoch: 6| Step: 10
Training loss: 0.14173215627670288
Validation loss: 1.585082047729082

Epoch: 6| Step: 11
Training loss: 0.13115110993385315
Validation loss: 1.5794085405206169

Epoch: 6| Step: 12
Training loss: 0.09015166759490967
Validation loss: 1.569723142090664

Epoch: 6| Step: 13
Training loss: 0.11397521942853928
Validation loss: 1.564915733952676

Epoch: 542| Step: 0
Training loss: 0.05239075422286987
Validation loss: 1.5465863391917238

Epoch: 6| Step: 1
Training loss: 0.08425271511077881
Validation loss: 1.5595704188910864

Epoch: 6| Step: 2
Training loss: 0.08300264924764633
Validation loss: 1.5442972939501527

Epoch: 6| Step: 3
Training loss: 0.07503141462802887
Validation loss: 1.548552728468372

Epoch: 6| Step: 4
Training loss: 0.05738285183906555
Validation loss: 1.5652273624174056

Epoch: 6| Step: 5
Training loss: 0.1301451027393341
Validation loss: 1.5400018422834334

Epoch: 6| Step: 6
Training loss: 0.12766042351722717
Validation loss: 1.5491662935544086

Epoch: 6| Step: 7
Training loss: 0.1826970875263214
Validation loss: 1.5250219106674194

Epoch: 6| Step: 8
Training loss: 0.12289994955062866
Validation loss: 1.5941053000829553

Epoch: 6| Step: 9
Training loss: 0.08168390393257141
Validation loss: 1.5510172305568573

Epoch: 6| Step: 10
Training loss: 0.05478909611701965
Validation loss: 1.5632595971066465

Epoch: 6| Step: 11
Training loss: 0.0863284319639206
Validation loss: 1.5476130631662184

Epoch: 6| Step: 12
Training loss: 0.11226508021354675
Validation loss: 1.5392013775405062

Epoch: 6| Step: 13
Training loss: 0.09406197816133499
Validation loss: 1.543621906670191

Epoch: 543| Step: 0
Training loss: 0.05717252194881439
Validation loss: 1.5363030997655724

Epoch: 6| Step: 1
Training loss: 0.17510512471199036
Validation loss: 1.550842136465093

Epoch: 6| Step: 2
Training loss: 0.08478100597858429
Validation loss: 1.540080003840949

Epoch: 6| Step: 3
Training loss: 0.06157560646533966
Validation loss: 1.51401791585389

Epoch: 6| Step: 4
Training loss: 0.12288780510425568
Validation loss: 1.520490865553579

Epoch: 6| Step: 5
Training loss: 0.0968073233962059
Validation loss: 1.5143366436804495

Epoch: 6| Step: 6
Training loss: 0.060152821242809296
Validation loss: 1.5222842616419638

Epoch: 6| Step: 7
Training loss: 0.11270345002412796
Validation loss: 1.5441978041843702

Epoch: 6| Step: 8
Training loss: 0.04689420387148857
Validation loss: 1.5635925069932015

Epoch: 6| Step: 9
Training loss: 0.13151513040065765
Validation loss: 1.547536680775304

Epoch: 6| Step: 10
Training loss: 0.07600362598896027
Validation loss: 1.5404562693770214

Epoch: 6| Step: 11
Training loss: 0.04369119554758072
Validation loss: 1.5425026967961302

Epoch: 6| Step: 12
Training loss: 0.09487003087997437
Validation loss: 1.5742696562120992

Epoch: 6| Step: 13
Training loss: 0.07671797275543213
Validation loss: 1.522328022987612

Epoch: 544| Step: 0
Training loss: 0.09764653444290161
Validation loss: 1.5304399075046662

Epoch: 6| Step: 1
Training loss: 0.07447301596403122
Validation loss: 1.5065454308704664

Epoch: 6| Step: 2
Training loss: 0.07778892666101456
Validation loss: 1.5376569660761024

Epoch: 6| Step: 3
Training loss: 0.17934486269950867
Validation loss: 1.523898748941319

Epoch: 6| Step: 4
Training loss: 0.0676296278834343
Validation loss: 1.5585935384996477

Epoch: 6| Step: 5
Training loss: 0.10940306633710861
Validation loss: 1.5407006740570068

Epoch: 6| Step: 6
Training loss: 0.12170968949794769
Validation loss: 1.564913575367261

Epoch: 6| Step: 7
Training loss: 0.105519600212574
Validation loss: 1.5592189617054437

Epoch: 6| Step: 8
Training loss: 0.1068047285079956
Validation loss: 1.5492941512856433

Epoch: 6| Step: 9
Training loss: 0.06773898750543594
Validation loss: 1.572948371210406

Epoch: 6| Step: 10
Training loss: 0.1204269528388977
Validation loss: 1.5716490232816307

Epoch: 6| Step: 11
Training loss: 0.04151899740099907
Validation loss: 1.5429720481236775

Epoch: 6| Step: 12
Training loss: 0.0930098444223404
Validation loss: 1.564114534726707

Epoch: 6| Step: 13
Training loss: 0.12185655534267426
Validation loss: 1.5382207221882318

Epoch: 545| Step: 0
Training loss: 0.15761640667915344
Validation loss: 1.538850562546843

Epoch: 6| Step: 1
Training loss: 0.09622876346111298
Validation loss: 1.5307716996439042

Epoch: 6| Step: 2
Training loss: 0.17697030305862427
Validation loss: 1.5540945978574856

Epoch: 6| Step: 3
Training loss: 0.07858089357614517
Validation loss: 1.5363204671490578

Epoch: 6| Step: 4
Training loss: 0.12326080352067947
Validation loss: 1.5618037536580076

Epoch: 6| Step: 5
Training loss: 0.0769626647233963
Validation loss: 1.5682523455671085

Epoch: 6| Step: 6
Training loss: 0.07837409526109695
Validation loss: 1.5767294399199947

Epoch: 6| Step: 7
Training loss: 0.04884336143732071
Validation loss: 1.571129310515619

Epoch: 6| Step: 8
Training loss: 0.07478541135787964
Validation loss: 1.5702879172499462

Epoch: 6| Step: 9
Training loss: 0.09523149579763412
Validation loss: 1.6041032101518364

Epoch: 6| Step: 10
Training loss: 0.061931759119033813
Validation loss: 1.5978492331761185

Epoch: 6| Step: 11
Training loss: 0.08839680999517441
Validation loss: 1.5803045662500526

Epoch: 6| Step: 12
Training loss: 0.09540759772062302
Validation loss: 1.580987597024569

Epoch: 6| Step: 13
Training loss: 0.1341652125120163
Validation loss: 1.5656664525308917

Epoch: 546| Step: 0
Training loss: 0.08824700117111206
Validation loss: 1.5995698398159397

Epoch: 6| Step: 1
Training loss: 0.07372398674488068
Validation loss: 1.5845968428478445

Epoch: 6| Step: 2
Training loss: 0.08840864151716232
Validation loss: 1.5762983778471589

Epoch: 6| Step: 3
Training loss: 0.09022887051105499
Validation loss: 1.584003403622617

Epoch: 6| Step: 4
Training loss: 0.1194850280880928
Validation loss: 1.5698551131832985

Epoch: 6| Step: 5
Training loss: 0.1462196260690689
Validation loss: 1.5644435100657965

Epoch: 6| Step: 6
Training loss: 0.09166509658098221
Validation loss: 1.5640139669500372

Epoch: 6| Step: 7
Training loss: 0.06656259298324585
Validation loss: 1.566171259008428

Epoch: 6| Step: 8
Training loss: 0.07664954662322998
Validation loss: 1.56430636682818

Epoch: 6| Step: 9
Training loss: 0.05883528292179108
Validation loss: 1.570561929415631

Epoch: 6| Step: 10
Training loss: 0.10263321548700333
Validation loss: 1.5559540333286408

Epoch: 6| Step: 11
Training loss: 0.0973079726099968
Validation loss: 1.5657017461715206

Epoch: 6| Step: 12
Training loss: 0.06266064941883087
Validation loss: 1.5708113267857542

Epoch: 6| Step: 13
Training loss: 0.08419803529977798
Validation loss: 1.5844382803927186

Epoch: 547| Step: 0
Training loss: 0.05960816517472267
Validation loss: 1.5388040722057383

Epoch: 6| Step: 1
Training loss: 0.0741296261548996
Validation loss: 1.5592189450417795

Epoch: 6| Step: 2
Training loss: 0.09375663846731186
Validation loss: 1.5708140916721796

Epoch: 6| Step: 3
Training loss: 0.06514479964971542
Validation loss: 1.5463219329875002

Epoch: 6| Step: 4
Training loss: 0.04459083452820778
Validation loss: 1.5016251302534533

Epoch: 6| Step: 5
Training loss: 0.0509638786315918
Validation loss: 1.5389569908060052

Epoch: 6| Step: 6
Training loss: 0.09159905463457108
Validation loss: 1.5574214625102218

Epoch: 6| Step: 7
Training loss: 0.09127306193113327
Validation loss: 1.5760669016068982

Epoch: 6| Step: 8
Training loss: 0.09818913042545319
Validation loss: 1.554008912014705

Epoch: 6| Step: 9
Training loss: 0.09889127314090729
Validation loss: 1.544822391643319

Epoch: 6| Step: 10
Training loss: 0.08314606547355652
Validation loss: 1.5588008434541765

Epoch: 6| Step: 11
Training loss: 0.05870514363050461
Validation loss: 1.592327110229

Epoch: 6| Step: 12
Training loss: 0.0626034215092659
Validation loss: 1.54596891198107

Epoch: 6| Step: 13
Training loss: 0.13622647523880005
Validation loss: 1.5773146870315715

Epoch: 548| Step: 0
Training loss: 0.07583741843700409
Validation loss: 1.5556624602246028

Epoch: 6| Step: 1
Training loss: 0.1310891956090927
Validation loss: 1.5488176076642928

Epoch: 6| Step: 2
Training loss: 0.13010497391223907
Validation loss: 1.5575564984352357

Epoch: 6| Step: 3
Training loss: 0.10349054634571075
Validation loss: 1.5613891027306999

Epoch: 6| Step: 4
Training loss: 0.099358931183815
Validation loss: 1.5486738297247118

Epoch: 6| Step: 5
Training loss: 0.09664304554462433
Validation loss: 1.5632523311081754

Epoch: 6| Step: 6
Training loss: 0.11808394640684128
Validation loss: 1.564116011383713

Epoch: 6| Step: 7
Training loss: 0.09516977518796921
Validation loss: 1.578086296717326

Epoch: 6| Step: 8
Training loss: 0.07830402255058289
Validation loss: 1.585682463902299

Epoch: 6| Step: 9
Training loss: 0.10951253026723862
Validation loss: 1.604662432465502

Epoch: 6| Step: 10
Training loss: 0.15610501170158386
Validation loss: 1.6437992421529626

Epoch: 6| Step: 11
Training loss: 0.07505545765161514
Validation loss: 1.6179356998012913

Epoch: 6| Step: 12
Training loss: 0.08832181990146637
Validation loss: 1.6137333800715785

Epoch: 6| Step: 13
Training loss: 0.1017409935593605
Validation loss: 1.5979337948624805

Epoch: 549| Step: 0
Training loss: 0.09661844372749329
Validation loss: 1.583838798666513

Epoch: 6| Step: 1
Training loss: 0.0580265149474144
Validation loss: 1.557203613301759

Epoch: 6| Step: 2
Training loss: 0.11859747022390366
Validation loss: 1.5342718106444164

Epoch: 6| Step: 3
Training loss: 0.06825271993875504
Validation loss: 1.5285771719871029

Epoch: 6| Step: 4
Training loss: 0.0693664625287056
Validation loss: 1.548921045436654

Epoch: 6| Step: 5
Training loss: 0.1476232260465622
Validation loss: 1.53091642420779

Epoch: 6| Step: 6
Training loss: 0.08912773430347443
Validation loss: 1.5182114570371565

Epoch: 6| Step: 7
Training loss: 0.07614816725254059
Validation loss: 1.5360536818863244

Epoch: 6| Step: 8
Training loss: 0.07425685226917267
Validation loss: 1.4994542803815616

Epoch: 6| Step: 9
Training loss: 0.05595661327242851
Validation loss: 1.5390767205146052

Epoch: 6| Step: 10
Training loss: 0.14476251602172852
Validation loss: 1.5703821079705351

Epoch: 6| Step: 11
Training loss: 0.07594559341669083
Validation loss: 1.5557432328501055

Epoch: 6| Step: 12
Training loss: 0.11850500106811523
Validation loss: 1.5519175990935294

Epoch: 6| Step: 13
Training loss: 0.07935147732496262
Validation loss: 1.54250164698529

Epoch: 550| Step: 0
Training loss: 0.07730270177125931
Validation loss: 1.5646985858999274

Epoch: 6| Step: 1
Training loss: 0.053475622087717056
Validation loss: 1.5283511543786654

Epoch: 6| Step: 2
Training loss: 0.12488363683223724
Validation loss: 1.5222729931595504

Epoch: 6| Step: 3
Training loss: 0.09647883474826813
Validation loss: 1.5442817570060812

Epoch: 6| Step: 4
Training loss: 0.07923024147748947
Validation loss: 1.514192892659095

Epoch: 6| Step: 5
Training loss: 0.06352517008781433
Validation loss: 1.4959858694384176

Epoch: 6| Step: 6
Training loss: 0.05743846297264099
Validation loss: 1.5298361086076306

Epoch: 6| Step: 7
Training loss: 0.07932121306657791
Validation loss: 1.52517411785741

Epoch: 6| Step: 8
Training loss: 0.08878596872091293
Validation loss: 1.550189245772618

Epoch: 6| Step: 9
Training loss: 0.16237375140190125
Validation loss: 1.533953897414669

Epoch: 6| Step: 10
Training loss: 0.06000048667192459
Validation loss: 1.5712340788174701

Epoch: 6| Step: 11
Training loss: 0.1255723237991333
Validation loss: 1.5750300499700731

Epoch: 6| Step: 12
Training loss: 0.09613513946533203
Validation loss: 1.5622888547117992

Epoch: 6| Step: 13
Training loss: 0.11907514184713364
Validation loss: 1.5521594696147467

Epoch: 551| Step: 0
Training loss: 0.0553804375231266
Validation loss: 1.5419496079926849

Epoch: 6| Step: 1
Training loss: 0.09457942098379135
Validation loss: 1.5392415331256004

Epoch: 6| Step: 2
Training loss: 0.09047291427850723
Validation loss: 1.5435737102262435

Epoch: 6| Step: 3
Training loss: 0.07630739361047745
Validation loss: 1.5329195581456667

Epoch: 6| Step: 4
Training loss: 0.10803284496068954
Validation loss: 1.559658024900703

Epoch: 6| Step: 5
Training loss: 0.08995562791824341
Validation loss: 1.5254868307421285

Epoch: 6| Step: 6
Training loss: 0.05704880505800247
Validation loss: 1.563679607965613

Epoch: 6| Step: 7
Training loss: 0.0674477368593216
Validation loss: 1.5563113022876043

Epoch: 6| Step: 8
Training loss: 0.08955750614404678
Validation loss: 1.5627545233695739

Epoch: 6| Step: 9
Training loss: 0.05207159370183945
Validation loss: 1.5660221692054503

Epoch: 6| Step: 10
Training loss: 0.0441306009888649
Validation loss: 1.523277541642548

Epoch: 6| Step: 11
Training loss: 0.10746654123067856
Validation loss: 1.5243698544399713

Epoch: 6| Step: 12
Training loss: 0.07522125542163849
Validation loss: 1.5242229071996545

Epoch: 6| Step: 13
Training loss: 0.1802995502948761
Validation loss: 1.5162098048835673

Epoch: 552| Step: 0
Training loss: 0.058609459549188614
Validation loss: 1.5316008457573511

Epoch: 6| Step: 1
Training loss: 0.06866162270307541
Validation loss: 1.494229712793904

Epoch: 6| Step: 2
Training loss: 0.13309550285339355
Validation loss: 1.5000648306262108

Epoch: 6| Step: 3
Training loss: 0.06471298635005951
Validation loss: 1.494633408002956

Epoch: 6| Step: 4
Training loss: 0.11579825729131699
Validation loss: 1.494176838987617

Epoch: 6| Step: 5
Training loss: 0.06743264198303223
Validation loss: 1.5357531270673197

Epoch: 6| Step: 6
Training loss: 0.11628302931785583
Validation loss: 1.5387933779788274

Epoch: 6| Step: 7
Training loss: 0.06926336884498596
Validation loss: 1.5604753840354182

Epoch: 6| Step: 8
Training loss: 0.14399297535419464
Validation loss: 1.5672245640908518

Epoch: 6| Step: 9
Training loss: 0.10832277685403824
Validation loss: 1.5407628295242146

Epoch: 6| Step: 10
Training loss: 0.13077285885810852
Validation loss: 1.583075241375995

Epoch: 6| Step: 11
Training loss: 0.09866812825202942
Validation loss: 1.5352126244575746

Epoch: 6| Step: 12
Training loss: 0.06964805722236633
Validation loss: 1.5522494194328145

Epoch: 6| Step: 13
Training loss: 0.16378532350063324
Validation loss: 1.540553487757201

Epoch: 553| Step: 0
Training loss: 0.11330564320087433
Validation loss: 1.5250605902364176

Epoch: 6| Step: 1
Training loss: 0.06839308142662048
Validation loss: 1.5381142093289284

Epoch: 6| Step: 2
Training loss: 0.085137277841568
Validation loss: 1.5397167269901564

Epoch: 6| Step: 3
Training loss: 0.08229738473892212
Validation loss: 1.49232909499958

Epoch: 6| Step: 4
Training loss: 0.11142201721668243
Validation loss: 1.5114891170173563

Epoch: 6| Step: 5
Training loss: 0.10859861969947815
Validation loss: 1.532987129303717

Epoch: 6| Step: 6
Training loss: 0.1018839180469513
Validation loss: 1.5413569801597184

Epoch: 6| Step: 7
Training loss: 0.06317491829395294
Validation loss: 1.5486222544024069

Epoch: 6| Step: 8
Training loss: 0.04571762681007385
Validation loss: 1.5595296262412943

Epoch: 6| Step: 9
Training loss: 0.08641436696052551
Validation loss: 1.5425319158902733

Epoch: 6| Step: 10
Training loss: 0.08862462639808655
Validation loss: 1.5819933209367978

Epoch: 6| Step: 11
Training loss: 0.0622432716190815
Validation loss: 1.54831822072306

Epoch: 6| Step: 12
Training loss: 0.0878753587603569
Validation loss: 1.5656981147745603

Epoch: 6| Step: 13
Training loss: 0.11428742855787277
Validation loss: 1.5368112005213255

Epoch: 554| Step: 0
Training loss: 0.0807117372751236
Validation loss: 1.553331990395823

Epoch: 6| Step: 1
Training loss: 0.08524767309427261
Validation loss: 1.5662197451437674

Epoch: 6| Step: 2
Training loss: 0.07252965122461319
Validation loss: 1.5338802568374141

Epoch: 6| Step: 3
Training loss: 0.09473466873168945
Validation loss: 1.556615617967421

Epoch: 6| Step: 4
Training loss: 0.13511008024215698
Validation loss: 1.5318289149192073

Epoch: 6| Step: 5
Training loss: 0.12486744672060013
Validation loss: 1.5591705896521126

Epoch: 6| Step: 6
Training loss: 0.1053161770105362
Validation loss: 1.5512174124358802

Epoch: 6| Step: 7
Training loss: 0.07615184783935547
Validation loss: 1.5449209584984729

Epoch: 6| Step: 8
Training loss: 0.04917444288730621
Validation loss: 1.5394605103359427

Epoch: 6| Step: 9
Training loss: 0.09525919705629349
Validation loss: 1.5803624955556725

Epoch: 6| Step: 10
Training loss: 0.13965031504631042
Validation loss: 1.5532468826540056

Epoch: 6| Step: 11
Training loss: 0.10577501356601715
Validation loss: 1.5641294140969553

Epoch: 6| Step: 12
Training loss: 0.12315037846565247
Validation loss: 1.564691787124962

Epoch: 6| Step: 13
Training loss: 0.10146122425794601
Validation loss: 1.5963626625717326

Epoch: 555| Step: 0
Training loss: 0.05586924031376839
Validation loss: 1.5659855296534877

Epoch: 6| Step: 1
Training loss: 0.09722420573234558
Validation loss: 1.5506404189653293

Epoch: 6| Step: 2
Training loss: 0.0681537538766861
Validation loss: 1.516385180975801

Epoch: 6| Step: 3
Training loss: 0.14591187238693237
Validation loss: 1.5420776048014242

Epoch: 6| Step: 4
Training loss: 0.1429566591978073
Validation loss: 1.5186989858586302

Epoch: 6| Step: 5
Training loss: 0.07695303112268448
Validation loss: 1.5215434246165778

Epoch: 6| Step: 6
Training loss: 0.04900692403316498
Validation loss: 1.5304352493696316

Epoch: 6| Step: 7
Training loss: 0.059325143694877625
Validation loss: 1.517107202160743

Epoch: 6| Step: 8
Training loss: 0.10381954908370972
Validation loss: 1.5152264205358361

Epoch: 6| Step: 9
Training loss: 0.16213229298591614
Validation loss: 1.5486361454891902

Epoch: 6| Step: 10
Training loss: 0.10525260865688324
Validation loss: 1.5429686769362418

Epoch: 6| Step: 11
Training loss: 0.13247504830360413
Validation loss: 1.5765995479399157

Epoch: 6| Step: 12
Training loss: 0.08353935182094574
Validation loss: 1.5556643694959662

Epoch: 6| Step: 13
Training loss: 0.14218741655349731
Validation loss: 1.5300338499007686

Epoch: 556| Step: 0
Training loss: 0.0744449570775032
Validation loss: 1.5221295074750019

Epoch: 6| Step: 1
Training loss: 0.09297871589660645
Validation loss: 1.54569661489097

Epoch: 6| Step: 2
Training loss: 0.06438186019659042
Validation loss: 1.5290380677869242

Epoch: 6| Step: 3
Training loss: 0.09025523066520691
Validation loss: 1.5379939143375685

Epoch: 6| Step: 4
Training loss: 0.09233162552118301
Validation loss: 1.5215808217243483

Epoch: 6| Step: 5
Training loss: 0.08790308982133865
Validation loss: 1.5200421355103935

Epoch: 6| Step: 6
Training loss: 0.11101508885622025
Validation loss: 1.5536517109922183

Epoch: 6| Step: 7
Training loss: 0.12314532697200775
Validation loss: 1.5399359400554369

Epoch: 6| Step: 8
Training loss: 0.13993951678276062
Validation loss: 1.5262008943865377

Epoch: 6| Step: 9
Training loss: 0.06001286208629608
Validation loss: 1.549543325619031

Epoch: 6| Step: 10
Training loss: 0.07598388940095901
Validation loss: 1.53257873494138

Epoch: 6| Step: 11
Training loss: 0.07240918278694153
Validation loss: 1.5620787682071808

Epoch: 6| Step: 12
Training loss: 0.06518743932247162
Validation loss: 1.540117908549565

Epoch: 6| Step: 13
Training loss: 0.16773737967014313
Validation loss: 1.5521698818411878

Epoch: 557| Step: 0
Training loss: 0.06666100025177002
Validation loss: 1.5353988601315407

Epoch: 6| Step: 1
Training loss: 0.05199123173952103
Validation loss: 1.5302830255159767

Epoch: 6| Step: 2
Training loss: 0.06914643198251724
Validation loss: 1.5368495448943107

Epoch: 6| Step: 3
Training loss: 0.08271805942058563
Validation loss: 1.5228000430650608

Epoch: 6| Step: 4
Training loss: 0.08749856054782867
Validation loss: 1.5358237425486247

Epoch: 6| Step: 5
Training loss: 0.12254069000482559
Validation loss: 1.5086094653734596

Epoch: 6| Step: 6
Training loss: 0.1615409553050995
Validation loss: 1.5127620043293122

Epoch: 6| Step: 7
Training loss: 0.13249021768569946
Validation loss: 1.5014776568258963

Epoch: 6| Step: 8
Training loss: 0.07599897682666779
Validation loss: 1.5257847065566688

Epoch: 6| Step: 9
Training loss: 0.04668956995010376
Validation loss: 1.5050288746433873

Epoch: 6| Step: 10
Training loss: 0.08818259835243225
Validation loss: 1.5386669443499656

Epoch: 6| Step: 11
Training loss: 0.06267721205949783
Validation loss: 1.5807286411203363

Epoch: 6| Step: 12
Training loss: 0.11810111254453659
Validation loss: 1.5548126543721845

Epoch: 6| Step: 13
Training loss: 0.09543432295322418
Validation loss: 1.5658240151661698

Epoch: 558| Step: 0
Training loss: 0.08801445364952087
Validation loss: 1.5609830797359507

Epoch: 6| Step: 1
Training loss: 0.0667291134595871
Validation loss: 1.5502333089869509

Epoch: 6| Step: 2
Training loss: 0.078034907579422
Validation loss: 1.5317144970740042

Epoch: 6| Step: 3
Training loss: 0.1267215460538864
Validation loss: 1.5403063399817354

Epoch: 6| Step: 4
Training loss: 0.06627818197011948
Validation loss: 1.527880455857964

Epoch: 6| Step: 5
Training loss: 0.08735441416501999
Validation loss: 1.5223338142518075

Epoch: 6| Step: 6
Training loss: 0.10738369822502136
Validation loss: 1.4908399235817693

Epoch: 6| Step: 7
Training loss: 0.09991013258695602
Validation loss: 1.5258043722439838

Epoch: 6| Step: 8
Training loss: 0.06386726349592209
Validation loss: 1.5642550485108488

Epoch: 6| Step: 9
Training loss: 0.07777494937181473
Validation loss: 1.5485235670561432

Epoch: 6| Step: 10
Training loss: 0.07651660591363907
Validation loss: 1.5581005734782065

Epoch: 6| Step: 11
Training loss: 0.14801080524921417
Validation loss: 1.5602533432745165

Epoch: 6| Step: 12
Training loss: 0.08871441334486008
Validation loss: 1.5586191531150573

Epoch: 6| Step: 13
Training loss: 0.04452846944332123
Validation loss: 1.5629071368966052

Epoch: 559| Step: 0
Training loss: 0.047516196966171265
Validation loss: 1.5474045712460753

Epoch: 6| Step: 1
Training loss: 0.07536514103412628
Validation loss: 1.5468193548981861

Epoch: 6| Step: 2
Training loss: 0.0797504335641861
Validation loss: 1.561872475890703

Epoch: 6| Step: 3
Training loss: 0.12204033136367798
Validation loss: 1.5602503822695823

Epoch: 6| Step: 4
Training loss: 0.06340423226356506
Validation loss: 1.5601928605828235

Epoch: 6| Step: 5
Training loss: 0.09000364691019058
Validation loss: 1.548445217071041

Epoch: 6| Step: 6
Training loss: 0.09774366021156311
Validation loss: 1.5311268427038704

Epoch: 6| Step: 7
Training loss: 0.05556380748748779
Validation loss: 1.5173936659289944

Epoch: 6| Step: 8
Training loss: 0.07752922177314758
Validation loss: 1.5557064375569742

Epoch: 6| Step: 9
Training loss: 0.1270861178636551
Validation loss: 1.5244000188765987

Epoch: 6| Step: 10
Training loss: 0.05222748592495918
Validation loss: 1.5644584169951818

Epoch: 6| Step: 11
Training loss: 0.08000141382217407
Validation loss: 1.5538990138679423

Epoch: 6| Step: 12
Training loss: 0.06959136575460434
Validation loss: 1.537536987694361

Epoch: 6| Step: 13
Training loss: 0.10358163714408875
Validation loss: 1.5563332957606162

Epoch: 560| Step: 0
Training loss: 0.10192009806632996
Validation loss: 1.5308598279953003

Epoch: 6| Step: 1
Training loss: 0.05475406348705292
Validation loss: 1.5323692419195687

Epoch: 6| Step: 2
Training loss: 0.09561528265476227
Validation loss: 1.5322652145098614

Epoch: 6| Step: 3
Training loss: 0.07033708691596985
Validation loss: 1.5357336664712558

Epoch: 6| Step: 4
Training loss: 0.08443476259708405
Validation loss: 1.5214645631851689

Epoch: 6| Step: 5
Training loss: 0.04722782224416733
Validation loss: 1.5462109299116238

Epoch: 6| Step: 6
Training loss: 0.05374725162982941
Validation loss: 1.5528768076691577

Epoch: 6| Step: 7
Training loss: 0.11031045764684677
Validation loss: 1.5841773504851966

Epoch: 6| Step: 8
Training loss: 0.06379106640815735
Validation loss: 1.562670346229307

Epoch: 6| Step: 9
Training loss: 0.11289526522159576
Validation loss: 1.5565957433433943

Epoch: 6| Step: 10
Training loss: 0.06327685713768005
Validation loss: 1.5298172555943972

Epoch: 6| Step: 11
Training loss: 0.05610956996679306
Validation loss: 1.5565082821794736

Epoch: 6| Step: 12
Training loss: 0.07816702127456665
Validation loss: 1.5287377206228112

Epoch: 6| Step: 13
Training loss: 0.13386519253253937
Validation loss: 1.5224784189654934

Epoch: 561| Step: 0
Training loss: 0.09413990378379822
Validation loss: 1.5299144457745295

Epoch: 6| Step: 1
Training loss: 0.10433750599622726
Validation loss: 1.526182049064226

Epoch: 6| Step: 2
Training loss: 0.0728844553232193
Validation loss: 1.4855449257358428

Epoch: 6| Step: 3
Training loss: 0.0724731981754303
Validation loss: 1.5086622340704805

Epoch: 6| Step: 4
Training loss: 0.05790882930159569
Validation loss: 1.5292859179999239

Epoch: 6| Step: 5
Training loss: 0.08645320683717728
Validation loss: 1.5045783679972413

Epoch: 6| Step: 6
Training loss: 0.07550206035375595
Validation loss: 1.5172948529643397

Epoch: 6| Step: 7
Training loss: 0.05613076686859131
Validation loss: 1.5331882520388531

Epoch: 6| Step: 8
Training loss: 0.053807664662599564
Validation loss: 1.5190477986489572

Epoch: 6| Step: 9
Training loss: 0.059450745582580566
Validation loss: 1.5021663314552718

Epoch: 6| Step: 10
Training loss: 0.10049191117286682
Validation loss: 1.5425095635075723

Epoch: 6| Step: 11
Training loss: 0.11259579658508301
Validation loss: 1.515783150990804

Epoch: 6| Step: 12
Training loss: 0.11197477579116821
Validation loss: 1.5130912770507157

Epoch: 6| Step: 13
Training loss: 0.18352116644382477
Validation loss: 1.5100870414446759

Epoch: 562| Step: 0
Training loss: 0.08283757418394089
Validation loss: 1.5121311936327206

Epoch: 6| Step: 1
Training loss: 0.11281292140483856
Validation loss: 1.4948774973551433

Epoch: 6| Step: 2
Training loss: 0.08521047234535217
Validation loss: 1.5043366109171221

Epoch: 6| Step: 3
Training loss: 0.1296946108341217
Validation loss: 1.501979008156766

Epoch: 6| Step: 4
Training loss: 0.07745566219091415
Validation loss: 1.4976571862415602

Epoch: 6| Step: 5
Training loss: 0.08723434805870056
Validation loss: 1.489941736703278

Epoch: 6| Step: 6
Training loss: 0.05400795489549637
Validation loss: 1.5134849240702968

Epoch: 6| Step: 7
Training loss: 0.05473944544792175
Validation loss: 1.525786494696012

Epoch: 6| Step: 8
Training loss: 0.05031608045101166
Validation loss: 1.5118776777739167

Epoch: 6| Step: 9
Training loss: 0.045387476682662964
Validation loss: 1.5253211734115437

Epoch: 6| Step: 10
Training loss: 0.05947495624423027
Validation loss: 1.536663818103011

Epoch: 6| Step: 11
Training loss: 0.06357653439044952
Validation loss: 1.5228325731010848

Epoch: 6| Step: 12
Training loss: 0.04343266785144806
Validation loss: 1.5458387303095993

Epoch: 6| Step: 13
Training loss: 0.11613701283931732
Validation loss: 1.5564743959775535

Epoch: 563| Step: 0
Training loss: 0.1468743085861206
Validation loss: 1.5915350965274278

Epoch: 6| Step: 1
Training loss: 0.11178839951753616
Validation loss: 1.5571089726622387

Epoch: 6| Step: 2
Training loss: 0.07147441059350967
Validation loss: 1.583312672953452

Epoch: 6| Step: 3
Training loss: 0.14742040634155273
Validation loss: 1.5647433086108136

Epoch: 6| Step: 4
Training loss: 0.11433202028274536
Validation loss: 1.560342531050405

Epoch: 6| Step: 5
Training loss: 0.07210151851177216
Validation loss: 1.508005315257657

Epoch: 6| Step: 6
Training loss: 0.055421262979507446
Validation loss: 1.5174190113621373

Epoch: 6| Step: 7
Training loss: 0.05484753102064133
Validation loss: 1.4938883614796463

Epoch: 6| Step: 8
Training loss: 0.052468471229076385
Validation loss: 1.4603502263305008

Epoch: 6| Step: 9
Training loss: 0.09960959851741791
Validation loss: 1.5104554660858647

Epoch: 6| Step: 10
Training loss: 0.05546865984797478
Validation loss: 1.509583289905261

Epoch: 6| Step: 11
Training loss: 0.057838357985019684
Validation loss: 1.515668975409641

Epoch: 6| Step: 12
Training loss: 0.07208725810050964
Validation loss: 1.504014313861888

Epoch: 6| Step: 13
Training loss: 0.10177654772996902
Validation loss: 1.5207083314977667

Epoch: 564| Step: 0
Training loss: 0.08816444873809814
Validation loss: 1.5073344284488308

Epoch: 6| Step: 1
Training loss: 0.04737268388271332
Validation loss: 1.4957561262192265

Epoch: 6| Step: 2
Training loss: 0.14637455344200134
Validation loss: 1.5074768412497737

Epoch: 6| Step: 3
Training loss: 0.04919072240591049
Validation loss: 1.533486149644339

Epoch: 6| Step: 4
Training loss: 0.07125598192214966
Validation loss: 1.4984518276747836

Epoch: 6| Step: 5
Training loss: 0.07446110993623734
Validation loss: 1.5170864366715955

Epoch: 6| Step: 6
Training loss: 0.0805824026465416
Validation loss: 1.528294094788131

Epoch: 6| Step: 7
Training loss: 0.06449848413467407
Validation loss: 1.5143863949724423

Epoch: 6| Step: 8
Training loss: 0.06139547377824783
Validation loss: 1.5220787332903953

Epoch: 6| Step: 9
Training loss: 0.08498138934373856
Validation loss: 1.5143130376774778

Epoch: 6| Step: 10
Training loss: 0.0961184874176979
Validation loss: 1.5034267928010674

Epoch: 6| Step: 11
Training loss: 0.1182028129696846
Validation loss: 1.4835369933036067

Epoch: 6| Step: 12
Training loss: 0.052575789391994476
Validation loss: 1.5063518285751343

Epoch: 6| Step: 13
Training loss: 0.16821961104869843
Validation loss: 1.5257869266694593

Epoch: 565| Step: 0
Training loss: 0.07517369836568832
Validation loss: 1.5043309991077711

Epoch: 6| Step: 1
Training loss: 0.04777147248387337
Validation loss: 1.4866851029857513

Epoch: 6| Step: 2
Training loss: 0.08389589935541153
Validation loss: 1.4953957309005081

Epoch: 6| Step: 3
Training loss: 0.08773568272590637
Validation loss: 1.4545120462294547

Epoch: 6| Step: 4
Training loss: 0.06340382993221283
Validation loss: 1.4827636813604703

Epoch: 6| Step: 5
Training loss: 0.08436428010463715
Validation loss: 1.4926193439832298

Epoch: 6| Step: 6
Training loss: 0.06688949465751648
Validation loss: 1.4871047055849465

Epoch: 6| Step: 7
Training loss: 0.09915405511856079
Validation loss: 1.4950368481297647

Epoch: 6| Step: 8
Training loss: 0.11354612559080124
Validation loss: 1.5026065918707079

Epoch: 6| Step: 9
Training loss: 0.115289606153965
Validation loss: 1.4884167614803518

Epoch: 6| Step: 10
Training loss: 0.06581470370292664
Validation loss: 1.499077400853557

Epoch: 6| Step: 11
Training loss: 0.07616874575614929
Validation loss: 1.4967431240184332

Epoch: 6| Step: 12
Training loss: 0.04129236936569214
Validation loss: 1.505210349636693

Epoch: 6| Step: 13
Training loss: 0.06106610596179962
Validation loss: 1.5102549419608167

Epoch: 566| Step: 0
Training loss: 0.06879347562789917
Validation loss: 1.5360222862612816

Epoch: 6| Step: 1
Training loss: 0.08568257093429565
Validation loss: 1.541240297338014

Epoch: 6| Step: 2
Training loss: 0.0633203536272049
Validation loss: 1.5324328817347044

Epoch: 6| Step: 3
Training loss: 0.0703311488032341
Validation loss: 1.5485500430548063

Epoch: 6| Step: 4
Training loss: 0.08235855400562286
Validation loss: 1.5675217195223736

Epoch: 6| Step: 5
Training loss: 0.06330167502164841
Validation loss: 1.5266832882358181

Epoch: 6| Step: 6
Training loss: 0.12932664155960083
Validation loss: 1.5448118832803541

Epoch: 6| Step: 7
Training loss: 0.1427491009235382
Validation loss: 1.5460069525626399

Epoch: 6| Step: 8
Training loss: 0.10941319167613983
Validation loss: 1.5363853387935187

Epoch: 6| Step: 9
Training loss: 0.08495906740427017
Validation loss: 1.5368692695453603

Epoch: 6| Step: 10
Training loss: 0.11328145861625671
Validation loss: 1.5458697503612888

Epoch: 6| Step: 11
Training loss: 0.04680345952510834
Validation loss: 1.5356269985116937

Epoch: 6| Step: 12
Training loss: 0.05414921045303345
Validation loss: 1.5569132874088902

Epoch: 6| Step: 13
Training loss: 0.06841770559549332
Validation loss: 1.5617375066203456

Epoch: 567| Step: 0
Training loss: 0.09929509460926056
Validation loss: 1.5408801442833358

Epoch: 6| Step: 1
Training loss: 0.06735733151435852
Validation loss: 1.547786074299966

Epoch: 6| Step: 2
Training loss: 0.06564972549676895
Validation loss: 1.5453552058947984

Epoch: 6| Step: 3
Training loss: 0.08606111258268356
Validation loss: 1.5532667841962589

Epoch: 6| Step: 4
Training loss: 0.08006362617015839
Validation loss: 1.5234284118939472

Epoch: 6| Step: 5
Training loss: 0.062124304473400116
Validation loss: 1.505276370433069

Epoch: 6| Step: 6
Training loss: 0.0878400206565857
Validation loss: 1.543139462829918

Epoch: 6| Step: 7
Training loss: 0.13994884490966797
Validation loss: 1.5731813061621882

Epoch: 6| Step: 8
Training loss: 0.09434681385755539
Validation loss: 1.5627249774112497

Epoch: 6| Step: 9
Training loss: 0.10893958806991577
Validation loss: 1.5560311014934252

Epoch: 6| Step: 10
Training loss: 0.08849016577005386
Validation loss: 1.577854456440095

Epoch: 6| Step: 11
Training loss: 0.06932078301906586
Validation loss: 1.5981651198479436

Epoch: 6| Step: 12
Training loss: 0.08896151185035706
Validation loss: 1.6033269782220163

Epoch: 6| Step: 13
Training loss: 0.050947174429893494
Validation loss: 1.6056275444646035

Epoch: 568| Step: 0
Training loss: 0.08078057318925858
Validation loss: 1.6248314790828253

Epoch: 6| Step: 1
Training loss: 0.0675705224275589
Validation loss: 1.610626571921892

Epoch: 6| Step: 2
Training loss: 0.10017023980617523
Validation loss: 1.5770078525748303

Epoch: 6| Step: 3
Training loss: 0.07514728605747223
Validation loss: 1.5728448655015679

Epoch: 6| Step: 4
Training loss: 0.11104397475719452
Validation loss: 1.544543497024044

Epoch: 6| Step: 5
Training loss: 0.08021047711372375
Validation loss: 1.533008909994556

Epoch: 6| Step: 6
Training loss: 0.06084786355495453
Validation loss: 1.510355862238074

Epoch: 6| Step: 7
Training loss: 0.09865522384643555
Validation loss: 1.5093691297756728

Epoch: 6| Step: 8
Training loss: 0.0873180627822876
Validation loss: 1.5061920278815812

Epoch: 6| Step: 9
Training loss: 0.12565553188323975
Validation loss: 1.5034463533791163

Epoch: 6| Step: 10
Training loss: 0.16478729248046875
Validation loss: 1.5101149312911495

Epoch: 6| Step: 11
Training loss: 0.10972432047128677
Validation loss: 1.4774915890027118

Epoch: 6| Step: 12
Training loss: 0.10007317364215851
Validation loss: 1.4732109782516316

Epoch: 6| Step: 13
Training loss: 0.09704755246639252
Validation loss: 1.479679358902798

Epoch: 569| Step: 0
Training loss: 0.057027190923690796
Validation loss: 1.4992225323953936

Epoch: 6| Step: 1
Training loss: 0.10911586135625839
Validation loss: 1.4981134091654131

Epoch: 6| Step: 2
Training loss: 0.13463066518306732
Validation loss: 1.5315515020842194

Epoch: 6| Step: 3
Training loss: 0.161744624376297
Validation loss: 1.5637054879178283

Epoch: 6| Step: 4
Training loss: 0.16239413619041443
Validation loss: 1.593364845040024

Epoch: 6| Step: 5
Training loss: 0.11982516944408417
Validation loss: 1.5745717146063363

Epoch: 6| Step: 6
Training loss: 0.07491753995418549
Validation loss: 1.5504577159881592

Epoch: 6| Step: 7
Training loss: 0.07742596417665482
Validation loss: 1.5517555206052718

Epoch: 6| Step: 8
Training loss: 0.08377696573734283
Validation loss: 1.5418070862370152

Epoch: 6| Step: 9
Training loss: 0.12448051571846008
Validation loss: 1.5319678193779402

Epoch: 6| Step: 10
Training loss: 0.10638559609651566
Validation loss: 1.5581575311640257

Epoch: 6| Step: 11
Training loss: 0.1474030464887619
Validation loss: 1.546538975930983

Epoch: 6| Step: 12
Training loss: 0.060452282428741455
Validation loss: 1.5529015461603801

Epoch: 6| Step: 13
Training loss: 0.04224761202931404
Validation loss: 1.5139610190545358

Epoch: 570| Step: 0
Training loss: 0.08650774508714676
Validation loss: 1.4989203009554135

Epoch: 6| Step: 1
Training loss: 0.11555138975381851
Validation loss: 1.512758731842041

Epoch: 6| Step: 2
Training loss: 0.12384073436260223
Validation loss: 1.5348947522460774

Epoch: 6| Step: 3
Training loss: 0.15249082446098328
Validation loss: 1.5276549939186341

Epoch: 6| Step: 4
Training loss: 0.06274014711380005
Validation loss: 1.5291401378570064

Epoch: 6| Step: 5
Training loss: 0.14402788877487183
Validation loss: 1.5006856636334491

Epoch: 6| Step: 6
Training loss: 0.09032180905342102
Validation loss: 1.554795737548541

Epoch: 6| Step: 7
Training loss: 0.10529597103595734
Validation loss: 1.5478757453221146

Epoch: 6| Step: 8
Training loss: 0.07142417132854462
Validation loss: 1.5525156297991354

Epoch: 6| Step: 9
Training loss: 0.09824231266975403
Validation loss: 1.5794839307826052

Epoch: 6| Step: 10
Training loss: 0.10291840136051178
Validation loss: 1.5601309037977649

Epoch: 6| Step: 11
Training loss: 0.10972397774457932
Validation loss: 1.601690407722227

Epoch: 6| Step: 12
Training loss: 0.07037205249071121
Validation loss: 1.6014109298747072

Epoch: 6| Step: 13
Training loss: 0.14406520128250122
Validation loss: 1.5876477456861926

Epoch: 571| Step: 0
Training loss: 0.0830540806055069
Validation loss: 1.6065848879916693

Epoch: 6| Step: 1
Training loss: 0.1066453754901886
Validation loss: 1.6085420846939087

Epoch: 6| Step: 2
Training loss: 0.09846560657024384
Validation loss: 1.591869987467284

Epoch: 6| Step: 3
Training loss: 0.08771072328090668
Validation loss: 1.6020747461626608

Epoch: 6| Step: 4
Training loss: 0.08134414255619049
Validation loss: 1.6014276601934945

Epoch: 6| Step: 5
Training loss: 0.08124984055757523
Validation loss: 1.6063050980209022

Epoch: 6| Step: 6
Training loss: 0.07997806370258331
Validation loss: 1.524764189156153

Epoch: 6| Step: 7
Training loss: 0.13504625856876373
Validation loss: 1.564950043155301

Epoch: 6| Step: 8
Training loss: 0.08999187499284744
Validation loss: 1.5506789793250382

Epoch: 6| Step: 9
Training loss: 0.11716178059577942
Validation loss: 1.5806690249391782

Epoch: 6| Step: 10
Training loss: 0.08735936135053635
Validation loss: 1.56484535560813

Epoch: 6| Step: 11
Training loss: 0.10918019711971283
Validation loss: 1.5548080116189935

Epoch: 6| Step: 12
Training loss: 0.11117257177829742
Validation loss: 1.5588040685140958

Epoch: 6| Step: 13
Training loss: 0.10476265847682953
Validation loss: 1.5578746193198747

Epoch: 572| Step: 0
Training loss: 0.07129727303981781
Validation loss: 1.589009787446709

Epoch: 6| Step: 1
Training loss: 0.11183236539363861
Validation loss: 1.5913916121246994

Epoch: 6| Step: 2
Training loss: 0.0733577162027359
Validation loss: 1.5684387273685907

Epoch: 6| Step: 3
Training loss: 0.07574012875556946
Validation loss: 1.5513377420363887

Epoch: 6| Step: 4
Training loss: 0.10101557523012161
Validation loss: 1.5673198110313826

Epoch: 6| Step: 5
Training loss: 0.0697120875120163
Validation loss: 1.5646161263988865

Epoch: 6| Step: 6
Training loss: 0.07755328714847565
Validation loss: 1.5534370996618783

Epoch: 6| Step: 7
Training loss: 0.09721837937831879
Validation loss: 1.5235755238481747

Epoch: 6| Step: 8
Training loss: 0.06541144847869873
Validation loss: 1.4995403174431092

Epoch: 6| Step: 9
Training loss: 0.08072202652692795
Validation loss: 1.5300460195028653

Epoch: 6| Step: 10
Training loss: 0.04639682173728943
Validation loss: 1.5566848567737046

Epoch: 6| Step: 11
Training loss: 0.072825588285923
Validation loss: 1.5414631033456454

Epoch: 6| Step: 12
Training loss: 0.10145007073879242
Validation loss: 1.5750201607263217

Epoch: 6| Step: 13
Training loss: 0.07797034829854965
Validation loss: 1.5853405690962268

Epoch: 573| Step: 0
Training loss: 0.10958762466907501
Validation loss: 1.5424868009423698

Epoch: 6| Step: 1
Training loss: 0.09199656546115875
Validation loss: 1.5312971761149745

Epoch: 6| Step: 2
Training loss: 0.0598272979259491
Validation loss: 1.5739068715803084

Epoch: 6| Step: 3
Training loss: 0.05373543128371239
Validation loss: 1.5598232887124504

Epoch: 6| Step: 4
Training loss: 0.06061352789402008
Validation loss: 1.5520066471510037

Epoch: 6| Step: 5
Training loss: 0.039340678602457047
Validation loss: 1.5455586679520146

Epoch: 6| Step: 6
Training loss: 0.07931474596261978
Validation loss: 1.5450066366503317

Epoch: 6| Step: 7
Training loss: 0.08548635244369507
Validation loss: 1.55282558420653

Epoch: 6| Step: 8
Training loss: 0.054192397743463516
Validation loss: 1.5214376359857538

Epoch: 6| Step: 9
Training loss: 0.14984528720378876
Validation loss: 1.5170231865298363

Epoch: 6| Step: 10
Training loss: 0.0863688588142395
Validation loss: 1.5322283275665776

Epoch: 6| Step: 11
Training loss: 0.1062704473733902
Validation loss: 1.5320053536404845

Epoch: 6| Step: 12
Training loss: 0.03947528451681137
Validation loss: 1.5327587896777737

Epoch: 6| Step: 13
Training loss: 0.05638931691646576
Validation loss: 1.5394075993568666

Epoch: 574| Step: 0
Training loss: 0.10625085234642029
Validation loss: 1.5445978032645358

Epoch: 6| Step: 1
Training loss: 0.09568607062101364
Validation loss: 1.5365128388968847

Epoch: 6| Step: 2
Training loss: 0.06578080356121063
Validation loss: 1.5180910838547574

Epoch: 6| Step: 3
Training loss: 0.12817347049713135
Validation loss: 1.486236761975032

Epoch: 6| Step: 4
Training loss: 0.09793458133935928
Validation loss: 1.5252329969918856

Epoch: 6| Step: 5
Training loss: 0.07779776304960251
Validation loss: 1.5160546072067753

Epoch: 6| Step: 6
Training loss: 0.1367509514093399
Validation loss: 1.5435766878948416

Epoch: 6| Step: 7
Training loss: 0.1111619845032692
Validation loss: 1.553541241153594

Epoch: 6| Step: 8
Training loss: 0.09646295011043549
Validation loss: 1.5684033478460004

Epoch: 6| Step: 9
Training loss: 0.07260843366384506
Validation loss: 1.5818248128378263

Epoch: 6| Step: 10
Training loss: 0.12906736135482788
Validation loss: 1.594090687331333

Epoch: 6| Step: 11
Training loss: 0.07628007233142853
Validation loss: 1.5612883785719514

Epoch: 6| Step: 12
Training loss: 0.097803495824337
Validation loss: 1.606123165417743

Epoch: 6| Step: 13
Training loss: 0.06447608023881912
Validation loss: 1.5954408696902695

Epoch: 575| Step: 0
Training loss: 0.07610276341438293
Validation loss: 1.5960344114611227

Epoch: 6| Step: 1
Training loss: 0.10185063630342484
Validation loss: 1.5699922743663992

Epoch: 6| Step: 2
Training loss: 0.0590030774474144
Validation loss: 1.577917306653915

Epoch: 6| Step: 3
Training loss: 0.0816856399178505
Validation loss: 1.5744054407201789

Epoch: 6| Step: 4
Training loss: 0.06680714339017868
Validation loss: 1.6063932372677712

Epoch: 6| Step: 5
Training loss: 0.05213566869497299
Validation loss: 1.5935889059497463

Epoch: 6| Step: 6
Training loss: 0.04821464419364929
Validation loss: 1.5993539697380477

Epoch: 6| Step: 7
Training loss: 0.08894124627113342
Validation loss: 1.6125126987375238

Epoch: 6| Step: 8
Training loss: 0.049936696887016296
Validation loss: 1.6183549883545085

Epoch: 6| Step: 9
Training loss: 0.0892515480518341
Validation loss: 1.5753292422140799

Epoch: 6| Step: 10
Training loss: 0.11640818417072296
Validation loss: 1.6172005771308817

Epoch: 6| Step: 11
Training loss: 0.0861254334449768
Validation loss: 1.5895321740899035

Epoch: 6| Step: 12
Training loss: 0.10400797426700592
Validation loss: 1.6052833834002096

Epoch: 6| Step: 13
Training loss: 0.07166872918605804
Validation loss: 1.5666735428635792

Epoch: 576| Step: 0
Training loss: 0.07886344939470291
Validation loss: 1.582705484923496

Epoch: 6| Step: 1
Training loss: 0.07370792329311371
Validation loss: 1.534754624930761

Epoch: 6| Step: 2
Training loss: 0.10036677122116089
Validation loss: 1.535167944046759

Epoch: 6| Step: 3
Training loss: 0.08338288217782974
Validation loss: 1.525533527456304

Epoch: 6| Step: 4
Training loss: 0.06739357113838196
Validation loss: 1.5327501989180041

Epoch: 6| Step: 5
Training loss: 0.13392634689807892
Validation loss: 1.5375843637733049

Epoch: 6| Step: 6
Training loss: 0.11657442152500153
Validation loss: 1.5314955339636853

Epoch: 6| Step: 7
Training loss: 0.09657158702611923
Validation loss: 1.5311212751173204

Epoch: 6| Step: 8
Training loss: 0.07240812480449677
Validation loss: 1.5108399275810487

Epoch: 6| Step: 9
Training loss: 0.09873552620410919
Validation loss: 1.5478773373429493

Epoch: 6| Step: 10
Training loss: 0.050394780933856964
Validation loss: 1.5429290481792983

Epoch: 6| Step: 11
Training loss: 0.06892403215169907
Validation loss: 1.5714223897585304

Epoch: 6| Step: 12
Training loss: 0.09837248921394348
Validation loss: 1.5595728569133307

Epoch: 6| Step: 13
Training loss: 0.07467607408761978
Validation loss: 1.614360426061897

Epoch: 577| Step: 0
Training loss: 0.11626982688903809
Validation loss: 1.6318906289274975

Epoch: 6| Step: 1
Training loss: 0.08517611026763916
Validation loss: 1.6394120006151096

Epoch: 6| Step: 2
Training loss: 0.08200918138027191
Validation loss: 1.6309908538736322

Epoch: 6| Step: 3
Training loss: 0.07273085415363312
Validation loss: 1.5977017174484909

Epoch: 6| Step: 4
Training loss: 0.047909319400787354
Validation loss: 1.552738376843032

Epoch: 6| Step: 5
Training loss: 0.07167966663837433
Validation loss: 1.5390697063938263

Epoch: 6| Step: 6
Training loss: 0.05995224416255951
Validation loss: 1.5245722480999526

Epoch: 6| Step: 7
Training loss: 0.07775717228651047
Validation loss: 1.537291721631122

Epoch: 6| Step: 8
Training loss: 0.10630293190479279
Validation loss: 1.5055426320722025

Epoch: 6| Step: 9
Training loss: 0.062166109681129456
Validation loss: 1.5136785827657229

Epoch: 6| Step: 10
Training loss: 0.06444191932678223
Validation loss: 1.5411865121574813

Epoch: 6| Step: 11
Training loss: 0.15404784679412842
Validation loss: 1.5355913972341886

Epoch: 6| Step: 12
Training loss: 0.1012725830078125
Validation loss: 1.5581340853885939

Epoch: 6| Step: 13
Training loss: 0.11044038832187653
Validation loss: 1.5223822516779746

Epoch: 578| Step: 0
Training loss: 0.08801229298114777
Validation loss: 1.5266580530392226

Epoch: 6| Step: 1
Training loss: 0.0585860051214695
Validation loss: 1.5225100414727324

Epoch: 6| Step: 2
Training loss: 0.1177879124879837
Validation loss: 1.5357222646795294

Epoch: 6| Step: 3
Training loss: 0.05765353515744209
Validation loss: 1.541758466792363

Epoch: 6| Step: 4
Training loss: 0.04777967557311058
Validation loss: 1.5543825671237002

Epoch: 6| Step: 5
Training loss: 0.10957497358322144
Validation loss: 1.5590685670093825

Epoch: 6| Step: 6
Training loss: 0.0934433713555336
Validation loss: 1.5514360268910725

Epoch: 6| Step: 7
Training loss: 0.09871631860733032
Validation loss: 1.5696454432702833

Epoch: 6| Step: 8
Training loss: 0.16853082180023193
Validation loss: 1.6175785513334378

Epoch: 6| Step: 9
Training loss: 0.03877181559801102
Validation loss: 1.5529150245010213

Epoch: 6| Step: 10
Training loss: 0.10282868146896362
Validation loss: 1.556957479446165

Epoch: 6| Step: 11
Training loss: 0.09244897961616516
Validation loss: 1.5593718879966325

Epoch: 6| Step: 12
Training loss: 0.10761591792106628
Validation loss: 1.512038582114763

Epoch: 6| Step: 13
Training loss: 0.05772659555077553
Validation loss: 1.5275863229587514

Epoch: 579| Step: 0
Training loss: 0.09475647658109665
Validation loss: 1.5067737179417764

Epoch: 6| Step: 1
Training loss: 0.12565645575523376
Validation loss: 1.5241182119615617

Epoch: 6| Step: 2
Training loss: 0.06697773933410645
Validation loss: 1.5256855282732236

Epoch: 6| Step: 3
Training loss: 0.11126653850078583
Validation loss: 1.530826973658736

Epoch: 6| Step: 4
Training loss: 0.046500250697135925
Validation loss: 1.5424655970706735

Epoch: 6| Step: 5
Training loss: 0.05007830262184143
Validation loss: 1.517040414194907

Epoch: 6| Step: 6
Training loss: 0.11924292147159576
Validation loss: 1.5333928728616366

Epoch: 6| Step: 7
Training loss: 0.043632254004478455
Validation loss: 1.5283312912910216

Epoch: 6| Step: 8
Training loss: 0.04394538700580597
Validation loss: 1.5293665009160196

Epoch: 6| Step: 9
Training loss: 0.08804234862327576
Validation loss: 1.5285104192713255

Epoch: 6| Step: 10
Training loss: 0.11274950206279755
Validation loss: 1.5307571670060516

Epoch: 6| Step: 11
Training loss: 0.1400805115699768
Validation loss: 1.5410462758874381

Epoch: 6| Step: 12
Training loss: 0.1182193011045456
Validation loss: 1.5047329446320892

Epoch: 6| Step: 13
Training loss: 0.06142071262001991
Validation loss: 1.5548199710025583

Epoch: 580| Step: 0
Training loss: 0.09335985779762268
Validation loss: 1.5275846988924089

Epoch: 6| Step: 1
Training loss: 0.07278058677911758
Validation loss: 1.5274404735975369

Epoch: 6| Step: 2
Training loss: 0.07203870266675949
Validation loss: 1.5285248218044158

Epoch: 6| Step: 3
Training loss: 0.09106883406639099
Validation loss: 1.5201915053911106

Epoch: 6| Step: 4
Training loss: 0.08152446150779724
Validation loss: 1.5183453675239318

Epoch: 6| Step: 5
Training loss: 0.13378068804740906
Validation loss: 1.50607083946146

Epoch: 6| Step: 6
Training loss: 0.11003386229276657
Validation loss: 1.5025786340877574

Epoch: 6| Step: 7
Training loss: 0.15774884819984436
Validation loss: 1.5156393256238712

Epoch: 6| Step: 8
Training loss: 0.09459433704614639
Validation loss: 1.4847897996184647

Epoch: 6| Step: 9
Training loss: 0.11557471752166748
Validation loss: 1.5303711045172907

Epoch: 6| Step: 10
Training loss: 0.06418907642364502
Validation loss: 1.4971480536204513

Epoch: 6| Step: 11
Training loss: 0.11334486305713654
Validation loss: 1.5473147822964577

Epoch: 6| Step: 12
Training loss: 0.04920383542776108
Validation loss: 1.5432430698025612

Epoch: 6| Step: 13
Training loss: 0.0844234973192215
Validation loss: 1.5576210624428206

Epoch: 581| Step: 0
Training loss: 0.08867000788450241
Validation loss: 1.5816535116523824

Epoch: 6| Step: 1
Training loss: 0.10083439946174622
Validation loss: 1.5707599834729267

Epoch: 6| Step: 2
Training loss: 0.05734693259000778
Validation loss: 1.597730464832757

Epoch: 6| Step: 3
Training loss: 0.18373948335647583
Validation loss: 1.592265554653701

Epoch: 6| Step: 4
Training loss: 0.1817265897989273
Validation loss: 1.6267866537135134

Epoch: 6| Step: 5
Training loss: 0.11691774427890778
Validation loss: 1.590638114560035

Epoch: 6| Step: 6
Training loss: 0.06558461487293243
Validation loss: 1.5708593860749276

Epoch: 6| Step: 7
Training loss: 0.08693058788776398
Validation loss: 1.5557801890116867

Epoch: 6| Step: 8
Training loss: 0.08606159687042236
Validation loss: 1.5154240336469424

Epoch: 6| Step: 9
Training loss: 0.1475817710161209
Validation loss: 1.529702922349335

Epoch: 6| Step: 10
Training loss: 0.08974003791809082
Validation loss: 1.5266149249128116

Epoch: 6| Step: 11
Training loss: 0.11182830482721329
Validation loss: 1.499207576115926

Epoch: 6| Step: 12
Training loss: 0.08559387177228928
Validation loss: 1.5247916547201013

Epoch: 6| Step: 13
Training loss: 0.053533703088760376
Validation loss: 1.5064532910623858

Epoch: 582| Step: 0
Training loss: 0.08000323176383972
Validation loss: 1.5220997859072942

Epoch: 6| Step: 1
Training loss: 0.0651109367609024
Validation loss: 1.5020473464842765

Epoch: 6| Step: 2
Training loss: 0.09271899610757828
Validation loss: 1.4871813404944636

Epoch: 6| Step: 3
Training loss: 0.10268703103065491
Validation loss: 1.4936016426291516

Epoch: 6| Step: 4
Training loss: 0.07029464840888977
Validation loss: 1.5110987322304839

Epoch: 6| Step: 5
Training loss: 0.05046758055686951
Validation loss: 1.469210433703597

Epoch: 6| Step: 6
Training loss: 0.058447182178497314
Validation loss: 1.5035310740111976

Epoch: 6| Step: 7
Training loss: 0.09948067367076874
Validation loss: 1.4866465394214918

Epoch: 6| Step: 8
Training loss: 0.049676425755023956
Validation loss: 1.4971209367116292

Epoch: 6| Step: 9
Training loss: 0.0989922285079956
Validation loss: 1.4705336927085795

Epoch: 6| Step: 10
Training loss: 0.12923531234264374
Validation loss: 1.4856199808018182

Epoch: 6| Step: 11
Training loss: 0.06163059175014496
Validation loss: 1.510761171258906

Epoch: 6| Step: 12
Training loss: 0.09372439980506897
Validation loss: 1.5485239080203477

Epoch: 6| Step: 13
Training loss: 0.08182141184806824
Validation loss: 1.5329243380536315

Epoch: 583| Step: 0
Training loss: 0.06930273771286011
Validation loss: 1.5379974931798956

Epoch: 6| Step: 1
Training loss: 0.10182475298643112
Validation loss: 1.5590031595640286

Epoch: 6| Step: 2
Training loss: 0.12922915816307068
Validation loss: 1.5403289179648123

Epoch: 6| Step: 3
Training loss: 0.11727264523506165
Validation loss: 1.5201663406946326

Epoch: 6| Step: 4
Training loss: 0.09834294766187668
Validation loss: 1.528136798771479

Epoch: 6| Step: 5
Training loss: 0.048282355070114136
Validation loss: 1.5118733285575785

Epoch: 6| Step: 6
Training loss: 0.08431777358055115
Validation loss: 1.5070386035467989

Epoch: 6| Step: 7
Training loss: 0.06920453906059265
Validation loss: 1.5171987113132273

Epoch: 6| Step: 8
Training loss: 0.11345909535884857
Validation loss: 1.5110375150557487

Epoch: 6| Step: 9
Training loss: 0.11917275190353394
Validation loss: 1.523944588117702

Epoch: 6| Step: 10
Training loss: 0.09978732466697693
Validation loss: 1.528291489488335

Epoch: 6| Step: 11
Training loss: 0.10826129466295242
Validation loss: 1.5255930833919074

Epoch: 6| Step: 12
Training loss: 0.07892549782991409
Validation loss: 1.5448269574872908

Epoch: 6| Step: 13
Training loss: 0.15427526831626892
Validation loss: 1.5578614383615472

Epoch: 584| Step: 0
Training loss: 0.12835818529129028
Validation loss: 1.5684920959575201

Epoch: 6| Step: 1
Training loss: 0.08742116391658783
Validation loss: 1.5856366131895332

Epoch: 6| Step: 2
Training loss: 0.10192178189754486
Validation loss: 1.5868341858668993

Epoch: 6| Step: 3
Training loss: 0.054714035242795944
Validation loss: 1.5813560447385233

Epoch: 6| Step: 4
Training loss: 0.09513209760189056
Validation loss: 1.55407125847314

Epoch: 6| Step: 5
Training loss: 0.05765366554260254
Validation loss: 1.5461257875606578

Epoch: 6| Step: 6
Training loss: 0.10140404105186462
Validation loss: 1.5051686674036004

Epoch: 6| Step: 7
Training loss: 0.09741190820932388
Validation loss: 1.5120214287952711

Epoch: 6| Step: 8
Training loss: 0.049722328782081604
Validation loss: 1.5179798180057156

Epoch: 6| Step: 9
Training loss: 0.07500569522380829
Validation loss: 1.5246959206878499

Epoch: 6| Step: 10
Training loss: 0.0843442901968956
Validation loss: 1.518693531713178

Epoch: 6| Step: 11
Training loss: 0.06732966750860214
Validation loss: 1.4819657277035456

Epoch: 6| Step: 12
Training loss: 0.08471167087554932
Validation loss: 1.5003094211701424

Epoch: 6| Step: 13
Training loss: 0.07815095782279968
Validation loss: 1.479035036538237

Epoch: 585| Step: 0
Training loss: 0.0839417576789856
Validation loss: 1.4768306119467622

Epoch: 6| Step: 1
Training loss: 0.09519169479608536
Validation loss: 1.4907824095859323

Epoch: 6| Step: 2
Training loss: 0.13188108801841736
Validation loss: 1.4896206727591894

Epoch: 6| Step: 3
Training loss: 0.09177976846694946
Validation loss: 1.4695247168182044

Epoch: 6| Step: 4
Training loss: 0.047526560723781586
Validation loss: 1.4915031386959938

Epoch: 6| Step: 5
Training loss: 0.1166318729519844
Validation loss: 1.48395340224748

Epoch: 6| Step: 6
Training loss: 0.10176445543766022
Validation loss: 1.469470735519163

Epoch: 6| Step: 7
Training loss: 0.14457754790782928
Validation loss: 1.4761229330493557

Epoch: 6| Step: 8
Training loss: 0.07218915969133377
Validation loss: 1.5094627308589157

Epoch: 6| Step: 9
Training loss: 0.06864343583583832
Validation loss: 1.509683657717961

Epoch: 6| Step: 10
Training loss: 0.10023992508649826
Validation loss: 1.508126397286692

Epoch: 6| Step: 11
Training loss: 0.10955184698104858
Validation loss: 1.5268095360007337

Epoch: 6| Step: 12
Training loss: 0.08492725342512131
Validation loss: 1.554461020295338

Epoch: 6| Step: 13
Training loss: 0.07893431186676025
Validation loss: 1.567276672650409

Epoch: 586| Step: 0
Training loss: 0.05873490124940872
Validation loss: 1.5518848473025906

Epoch: 6| Step: 1
Training loss: 0.1039782240986824
Validation loss: 1.5372967220121814

Epoch: 6| Step: 2
Training loss: 0.08465956151485443
Validation loss: 1.523500128458905

Epoch: 6| Step: 3
Training loss: 0.06611993908882141
Validation loss: 1.5326900943633048

Epoch: 6| Step: 4
Training loss: 0.042259491980075836
Validation loss: 1.5389923818649784

Epoch: 6| Step: 5
Training loss: 0.10128927230834961
Validation loss: 1.5437963072971632

Epoch: 6| Step: 6
Training loss: 0.05787146836519241
Validation loss: 1.5184363626664685

Epoch: 6| Step: 7
Training loss: 0.08847177773714066
Validation loss: 1.519199291865031

Epoch: 6| Step: 8
Training loss: 0.07096588611602783
Validation loss: 1.504561637678454

Epoch: 6| Step: 9
Training loss: 0.10477592796087265
Validation loss: 1.528757982356574

Epoch: 6| Step: 10
Training loss: 0.09288191795349121
Validation loss: 1.4920589616221767

Epoch: 6| Step: 11
Training loss: 0.11149735748767853
Validation loss: 1.498779877539604

Epoch: 6| Step: 12
Training loss: 0.05697233974933624
Validation loss: 1.502898289952227

Epoch: 6| Step: 13
Training loss: 0.09642826020717621
Validation loss: 1.5035772092880741

Epoch: 587| Step: 0
Training loss: 0.06976599991321564
Validation loss: 1.4977087788684393

Epoch: 6| Step: 1
Training loss: 0.08807569742202759
Validation loss: 1.5133457164610586

Epoch: 6| Step: 2
Training loss: 0.06394223123788834
Validation loss: 1.5267659515462897

Epoch: 6| Step: 3
Training loss: 0.07615384459495544
Validation loss: 1.5220127490258986

Epoch: 6| Step: 4
Training loss: 0.0810408964753151
Validation loss: 1.5113020763602307

Epoch: 6| Step: 5
Training loss: 0.09714983403682709
Validation loss: 1.5189285214229296

Epoch: 6| Step: 6
Training loss: 0.0723261907696724
Validation loss: 1.5355227339652278

Epoch: 6| Step: 7
Training loss: 0.10487889498472214
Validation loss: 1.5525402817674863

Epoch: 6| Step: 8
Training loss: 0.09937841445207596
Validation loss: 1.552446824248119

Epoch: 6| Step: 9
Training loss: 0.13121327757835388
Validation loss: 1.561831619149895

Epoch: 6| Step: 10
Training loss: 0.12105438858270645
Validation loss: 1.5653675935601676

Epoch: 6| Step: 11
Training loss: 0.08219394087791443
Validation loss: 1.5751081218001663

Epoch: 6| Step: 12
Training loss: 0.06017369404435158
Validation loss: 1.5597566545650523

Epoch: 6| Step: 13
Training loss: 0.05453791469335556
Validation loss: 1.5641197530172204

Epoch: 588| Step: 0
Training loss: 0.0861826092004776
Validation loss: 1.5574785509417135

Epoch: 6| Step: 1
Training loss: 0.09969304502010345
Validation loss: 1.5207623525332379

Epoch: 6| Step: 2
Training loss: 0.0743851289153099
Validation loss: 1.56521785900157

Epoch: 6| Step: 3
Training loss: 0.061886951327323914
Validation loss: 1.552021812367183

Epoch: 6| Step: 4
Training loss: 0.0826089084148407
Validation loss: 1.5550285244500766

Epoch: 6| Step: 5
Training loss: 0.07840953767299652
Validation loss: 1.5682698757417741

Epoch: 6| Step: 6
Training loss: 0.09349219501018524
Validation loss: 1.568899505881853

Epoch: 6| Step: 7
Training loss: 0.12119551002979279
Validation loss: 1.584953567033173

Epoch: 6| Step: 8
Training loss: 0.09218226373195648
Validation loss: 1.565295389903489

Epoch: 6| Step: 9
Training loss: 0.08654782921075821
Validation loss: 1.5685534079869587

Epoch: 6| Step: 10
Training loss: 0.05315021798014641
Validation loss: 1.5539694973217544

Epoch: 6| Step: 11
Training loss: 0.09919649362564087
Validation loss: 1.5745096168210428

Epoch: 6| Step: 12
Training loss: 0.06018178164958954
Validation loss: 1.5499868905672463

Epoch: 6| Step: 13
Training loss: 0.09506777673959732
Validation loss: 1.5348573089927755

Epoch: 589| Step: 0
Training loss: 0.07309042662382126
Validation loss: 1.5328054466555197

Epoch: 6| Step: 1
Training loss: 0.11093457788228989
Validation loss: 1.5628086072142406

Epoch: 6| Step: 2
Training loss: 0.05515389144420624
Validation loss: 1.5287220093511766

Epoch: 6| Step: 3
Training loss: 0.05962314084172249
Validation loss: 1.5453015322326331

Epoch: 6| Step: 4
Training loss: 0.04891936480998993
Validation loss: 1.5290700658675163

Epoch: 6| Step: 5
Training loss: 0.04855266958475113
Validation loss: 1.5246347214585991

Epoch: 6| Step: 6
Training loss: 0.09815723448991776
Validation loss: 1.520355293827672

Epoch: 6| Step: 7
Training loss: 0.10858609527349472
Validation loss: 1.5313380379830637

Epoch: 6| Step: 8
Training loss: 0.09239982068538666
Validation loss: 1.5399386498235887

Epoch: 6| Step: 9
Training loss: 0.09958693385124207
Validation loss: 1.5482441917542489

Epoch: 6| Step: 10
Training loss: 0.07968440651893616
Validation loss: 1.5574201383898336

Epoch: 6| Step: 11
Training loss: 0.0802047923207283
Validation loss: 1.5642069520488862

Epoch: 6| Step: 12
Training loss: 0.08851385861635208
Validation loss: 1.5380009528129333

Epoch: 6| Step: 13
Training loss: 0.10877038538455963
Validation loss: 1.5479019329112063

Epoch: 590| Step: 0
Training loss: 0.08473915606737137
Validation loss: 1.5304940169857395

Epoch: 6| Step: 1
Training loss: 0.10218781232833862
Validation loss: 1.5789204694891488

Epoch: 6| Step: 2
Training loss: 0.0355854332447052
Validation loss: 1.5714293013336837

Epoch: 6| Step: 3
Training loss: 0.06851918250322342
Validation loss: 1.5900518291740007

Epoch: 6| Step: 4
Training loss: 0.15172608196735382
Validation loss: 1.588402460980159

Epoch: 6| Step: 5
Training loss: 0.11494232714176178
Validation loss: 1.6225658783348658

Epoch: 6| Step: 6
Training loss: 0.12044715881347656
Validation loss: 1.6356407826946628

Epoch: 6| Step: 7
Training loss: 0.07032015919685364
Validation loss: 1.5684858111925022

Epoch: 6| Step: 8
Training loss: 0.1082916259765625
Validation loss: 1.580421136271569

Epoch: 6| Step: 9
Training loss: 0.06433920562267303
Validation loss: 1.5966167424314766

Epoch: 6| Step: 10
Training loss: 0.060044728219509125
Validation loss: 1.560535523199266

Epoch: 6| Step: 11
Training loss: 0.07968924939632416
Validation loss: 1.56714068946018

Epoch: 6| Step: 12
Training loss: 0.089825838804245
Validation loss: 1.5488297477845223

Epoch: 6| Step: 13
Training loss: 0.10505309700965881
Validation loss: 1.534387699378434

Epoch: 591| Step: 0
Training loss: 0.07070782035589218
Validation loss: 1.5219504897312452

Epoch: 6| Step: 1
Training loss: 0.07598162442445755
Validation loss: 1.5534920077170096

Epoch: 6| Step: 2
Training loss: 0.0829719826579094
Validation loss: 1.5483960284981677

Epoch: 6| Step: 3
Training loss: 0.07291628420352936
Validation loss: 1.5479219190536007

Epoch: 6| Step: 4
Training loss: 0.07730275392532349
Validation loss: 1.5743799645413634

Epoch: 6| Step: 5
Training loss: 0.07342192530632019
Validation loss: 1.5738182452417189

Epoch: 6| Step: 6
Training loss: 0.09327221661806107
Validation loss: 1.577621458679117

Epoch: 6| Step: 7
Training loss: 0.09600663185119629
Validation loss: 1.5898112507276638

Epoch: 6| Step: 8
Training loss: 0.05232449620962143
Validation loss: 1.6094367068300965

Epoch: 6| Step: 9
Training loss: 0.09986468404531479
Validation loss: 1.5798890026666785

Epoch: 6| Step: 10
Training loss: 0.07145050168037415
Validation loss: 1.5720287881871706

Epoch: 6| Step: 11
Training loss: 0.06003666669130325
Validation loss: 1.5790503922329153

Epoch: 6| Step: 12
Training loss: 0.12165466696023941
Validation loss: 1.5329396070972565

Epoch: 6| Step: 13
Training loss: 0.11162780225276947
Validation loss: 1.555431854340338

Epoch: 592| Step: 0
Training loss: 0.09593504667282104
Validation loss: 1.544582534861821

Epoch: 6| Step: 1
Training loss: 0.05740908533334732
Validation loss: 1.568706068941342

Epoch: 6| Step: 2
Training loss: 0.10693947225809097
Validation loss: 1.565343226155927

Epoch: 6| Step: 3
Training loss: 0.16302557289600372
Validation loss: 1.5875081464808474

Epoch: 6| Step: 4
Training loss: 0.07302426546812057
Validation loss: 1.551086236071843

Epoch: 6| Step: 5
Training loss: 0.07993365079164505
Validation loss: 1.5616210070989465

Epoch: 6| Step: 6
Training loss: 0.062496207654476166
Validation loss: 1.5479841181026992

Epoch: 6| Step: 7
Training loss: 0.1222890317440033
Validation loss: 1.5386191388612152

Epoch: 6| Step: 8
Training loss: 0.06485641747713089
Validation loss: 1.5167173749657088

Epoch: 6| Step: 9
Training loss: 0.0574350580573082
Validation loss: 1.5062373325388918

Epoch: 6| Step: 10
Training loss: 0.07601870596408844
Validation loss: 1.4859832281707435

Epoch: 6| Step: 11
Training loss: 0.06215493753552437
Validation loss: 1.4864611702580606

Epoch: 6| Step: 12
Training loss: 0.0743594542145729
Validation loss: 1.4946696360905964

Epoch: 6| Step: 13
Training loss: 0.12241845577955246
Validation loss: 1.519543347820159

Epoch: 593| Step: 0
Training loss: 0.1178784966468811
Validation loss: 1.490602703504665

Epoch: 6| Step: 1
Training loss: 0.11938676238059998
Validation loss: 1.4780872073224796

Epoch: 6| Step: 2
Training loss: 0.0608849823474884
Validation loss: 1.4897542935545727

Epoch: 6| Step: 3
Training loss: 0.0906323716044426
Validation loss: 1.457311854567579

Epoch: 6| Step: 4
Training loss: 0.0958917886018753
Validation loss: 1.4553719156531877

Epoch: 6| Step: 5
Training loss: 0.07866358011960983
Validation loss: 1.4681725719923615

Epoch: 6| Step: 6
Training loss: 0.06900224089622498
Validation loss: 1.4653294227456535

Epoch: 6| Step: 7
Training loss: 0.05150660127401352
Validation loss: 1.51614720718835

Epoch: 6| Step: 8
Training loss: 0.07143040746450424
Validation loss: 1.5173888219300138

Epoch: 6| Step: 9
Training loss: 0.06689134240150452
Validation loss: 1.508358827201269

Epoch: 6| Step: 10
Training loss: 0.11026539653539658
Validation loss: 1.536170022462004

Epoch: 6| Step: 11
Training loss: 0.10524004697799683
Validation loss: 1.5354057332520843

Epoch: 6| Step: 12
Training loss: 0.12952658534049988
Validation loss: 1.5426194026906004

Epoch: 6| Step: 13
Training loss: 0.1161184012889862
Validation loss: 1.521624865070466

Epoch: 594| Step: 0
Training loss: 0.1434793472290039
Validation loss: 1.5177896157387765

Epoch: 6| Step: 1
Training loss: 0.09065931290388107
Validation loss: 1.5195834213687527

Epoch: 6| Step: 2
Training loss: 0.10977689176797867
Validation loss: 1.5316045534226201

Epoch: 6| Step: 3
Training loss: 0.08550280332565308
Validation loss: 1.5199736382371636

Epoch: 6| Step: 4
Training loss: 0.12188220024108887
Validation loss: 1.5184061745161652

Epoch: 6| Step: 5
Training loss: 0.06582693755626678
Validation loss: 1.5421669290911766

Epoch: 6| Step: 6
Training loss: 0.05262438952922821
Validation loss: 1.5494845118573917

Epoch: 6| Step: 7
Training loss: 0.10023379325866699
Validation loss: 1.564039780247596

Epoch: 6| Step: 8
Training loss: 0.047015316784381866
Validation loss: 1.5763250909825808

Epoch: 6| Step: 9
Training loss: 0.08666564524173737
Validation loss: 1.5754958673190045

Epoch: 6| Step: 10
Training loss: 0.09300507605075836
Validation loss: 1.5666367366749754

Epoch: 6| Step: 11
Training loss: 0.09493321180343628
Validation loss: 1.5693127852614208

Epoch: 6| Step: 12
Training loss: 0.08833175897598267
Validation loss: 1.54905963841305

Epoch: 6| Step: 13
Training loss: 0.14682358503341675
Validation loss: 1.5698614556302306

Epoch: 595| Step: 0
Training loss: 0.0733037069439888
Validation loss: 1.5854187229628205

Epoch: 6| Step: 1
Training loss: 0.07458080351352692
Validation loss: 1.5727708865237493

Epoch: 6| Step: 2
Training loss: 0.09321427345275879
Validation loss: 1.5823464073160642

Epoch: 6| Step: 3
Training loss: 0.07255122810602188
Validation loss: 1.574544406706287

Epoch: 6| Step: 4
Training loss: 0.06786364316940308
Validation loss: 1.5642966942120624

Epoch: 6| Step: 5
Training loss: 0.08111587166786194
Validation loss: 1.551323631758331

Epoch: 6| Step: 6
Training loss: 0.055893659591674805
Validation loss: 1.5377821768483808

Epoch: 6| Step: 7
Training loss: 0.07524660974740982
Validation loss: 1.5169573189109884

Epoch: 6| Step: 8
Training loss: 0.1002158671617508
Validation loss: 1.5190535607517406

Epoch: 6| Step: 9
Training loss: 0.0767940953373909
Validation loss: 1.4922170972311368

Epoch: 6| Step: 10
Training loss: 0.07869046926498413
Validation loss: 1.5062817142855736

Epoch: 6| Step: 11
Training loss: 0.08372809737920761
Validation loss: 1.502876207392703

Epoch: 6| Step: 12
Training loss: 0.13942904770374298
Validation loss: 1.533745801577004

Epoch: 6| Step: 13
Training loss: 0.038100678473711014
Validation loss: 1.5302634957016155

Epoch: 596| Step: 0
Training loss: 0.05661299079656601
Validation loss: 1.5291301537585515

Epoch: 6| Step: 1
Training loss: 0.06990721076726913
Validation loss: 1.5464477782608361

Epoch: 6| Step: 2
Training loss: 0.08591359853744507
Validation loss: 1.5369146690573743

Epoch: 6| Step: 3
Training loss: 0.06417293846607208
Validation loss: 1.527500762734362

Epoch: 6| Step: 4
Training loss: 0.09658548980951309
Validation loss: 1.500841066401492

Epoch: 6| Step: 5
Training loss: 0.06295676529407501
Validation loss: 1.4965090136374197

Epoch: 6| Step: 6
Training loss: 0.042424075305461884
Validation loss: 1.4914036950757426

Epoch: 6| Step: 7
Training loss: 0.0677337497472763
Validation loss: 1.5263671900636406

Epoch: 6| Step: 8
Training loss: 0.05641111731529236
Validation loss: 1.4937400458961405

Epoch: 6| Step: 9
Training loss: 0.11668366938829422
Validation loss: 1.4895475628555461

Epoch: 6| Step: 10
Training loss: 0.107240229845047
Validation loss: 1.4968084007181146

Epoch: 6| Step: 11
Training loss: 0.057661302387714386
Validation loss: 1.4974322216485136

Epoch: 6| Step: 12
Training loss: 0.09324713796377182
Validation loss: 1.458858452817445

Epoch: 6| Step: 13
Training loss: 0.036096930503845215
Validation loss: 1.507870517751222

Epoch: 597| Step: 0
Training loss: 0.053671542555093765
Validation loss: 1.456419135934563

Epoch: 6| Step: 1
Training loss: 0.08658580482006073
Validation loss: 1.4772912558688913

Epoch: 6| Step: 2
Training loss: 0.0882958173751831
Validation loss: 1.4651841437944801

Epoch: 6| Step: 3
Training loss: 0.06960023939609528
Validation loss: 1.475656295335421

Epoch: 6| Step: 4
Training loss: 0.09337818622589111
Validation loss: 1.4845653721081313

Epoch: 6| Step: 5
Training loss: 0.0952865481376648
Validation loss: 1.5190677719731485

Epoch: 6| Step: 6
Training loss: 0.04741960018873215
Validation loss: 1.5278117015797605

Epoch: 6| Step: 7
Training loss: 0.07720992714166641
Validation loss: 1.5262850522994995

Epoch: 6| Step: 8
Training loss: 0.0887412428855896
Validation loss: 1.515559474627177

Epoch: 6| Step: 9
Training loss: 0.047147318720817566
Validation loss: 1.5499169544507099

Epoch: 6| Step: 10
Training loss: 0.10594994574785233
Validation loss: 1.5310911145261539

Epoch: 6| Step: 11
Training loss: 0.06675943732261658
Validation loss: 1.5457680186917704

Epoch: 6| Step: 12
Training loss: 0.1267622411251068
Validation loss: 1.535497837169196

Epoch: 6| Step: 13
Training loss: 0.06752923130989075
Validation loss: 1.5318443775177002

Epoch: 598| Step: 0
Training loss: 0.06352318078279495
Validation loss: 1.509931533567367

Epoch: 6| Step: 1
Training loss: 0.11705595254898071
Validation loss: 1.5081026592562277

Epoch: 6| Step: 2
Training loss: 0.07927774637937546
Validation loss: 1.5416971906538932

Epoch: 6| Step: 3
Training loss: 0.0677081048488617
Validation loss: 1.4962365909289288

Epoch: 6| Step: 4
Training loss: 0.06205519288778305
Validation loss: 1.5226907191738006

Epoch: 6| Step: 5
Training loss: 0.1075693815946579
Validation loss: 1.5009391077103154

Epoch: 6| Step: 6
Training loss: 0.08850843459367752
Validation loss: 1.5364190109314457

Epoch: 6| Step: 7
Training loss: 0.05774009972810745
Validation loss: 1.5237926308826735

Epoch: 6| Step: 8
Training loss: 0.09669730812311172
Validation loss: 1.515360370759041

Epoch: 6| Step: 9
Training loss: 0.0753670483827591
Validation loss: 1.5354808363863217

Epoch: 6| Step: 10
Training loss: 0.10463830828666687
Validation loss: 1.5392820348021805

Epoch: 6| Step: 11
Training loss: 0.051604196429252625
Validation loss: 1.5405354820271975

Epoch: 6| Step: 12
Training loss: 0.13367831707000732
Validation loss: 1.547583318525745

Epoch: 6| Step: 13
Training loss: 0.07305659353733063
Validation loss: 1.5416491262374385

Epoch: 599| Step: 0
Training loss: 0.14702367782592773
Validation loss: 1.5705086864450926

Epoch: 6| Step: 1
Training loss: 0.04985571652650833
Validation loss: 1.5792480040622014

Epoch: 6| Step: 2
Training loss: 0.04620767757296562
Validation loss: 1.5778850291364936

Epoch: 6| Step: 3
Training loss: 0.12320701032876968
Validation loss: 1.5868376031998666

Epoch: 6| Step: 4
Training loss: 0.04033129662275314
Validation loss: 1.6205682600698164

Epoch: 6| Step: 5
Training loss: 0.06309440732002258
Validation loss: 1.571503769966864

Epoch: 6| Step: 6
Training loss: 0.05651348829269409
Validation loss: 1.5555317119885517

Epoch: 6| Step: 7
Training loss: 0.08919814974069595
Validation loss: 1.568951235022596

Epoch: 6| Step: 8
Training loss: 0.06433147192001343
Validation loss: 1.56679408396444

Epoch: 6| Step: 9
Training loss: 0.08768508583307266
Validation loss: 1.5667410166032854

Epoch: 6| Step: 10
Training loss: 0.03650172799825668
Validation loss: 1.543830580608819

Epoch: 6| Step: 11
Training loss: 0.07650681585073471
Validation loss: 1.554570787696428

Epoch: 6| Step: 12
Training loss: 0.05710862576961517
Validation loss: 1.5423095200651435

Epoch: 6| Step: 13
Training loss: 0.079645536839962
Validation loss: 1.546343913642309

Epoch: 600| Step: 0
Training loss: 0.21649503707885742
Validation loss: 1.5343190188048987

Epoch: 6| Step: 1
Training loss: 0.11859580874443054
Validation loss: 1.5315660404902633

Epoch: 6| Step: 2
Training loss: 0.10031616687774658
Validation loss: 1.5624089971665414

Epoch: 6| Step: 3
Training loss: 0.06926065683364868
Validation loss: 1.5459999730510097

Epoch: 6| Step: 4
Training loss: 0.06362253427505493
Validation loss: 1.5797722454993957

Epoch: 6| Step: 5
Training loss: 0.046204812824726105
Validation loss: 1.5636417993935205

Epoch: 6| Step: 6
Training loss: 0.055177029222249985
Validation loss: 1.5788616602138807

Epoch: 6| Step: 7
Training loss: 0.12248945981264114
Validation loss: 1.5997731467728973

Epoch: 6| Step: 8
Training loss: 0.07945398986339569
Validation loss: 1.6109703099855812

Epoch: 6| Step: 9
Training loss: 0.10120459645986557
Validation loss: 1.6096802193631408

Epoch: 6| Step: 10
Training loss: 0.10358838737010956
Validation loss: 1.6094848417466687

Epoch: 6| Step: 11
Training loss: 0.05079801753163338
Validation loss: 1.6106252337014804

Epoch: 6| Step: 12
Training loss: 0.060790710151195526
Validation loss: 1.5830861586396412

Epoch: 6| Step: 13
Training loss: 0.05652524530887604
Validation loss: 1.5980164274092643

Epoch: 601| Step: 0
Training loss: 0.058448225259780884
Validation loss: 1.560418657077256

Epoch: 6| Step: 1
Training loss: 0.05583503097295761
Validation loss: 1.5708637583640315

Epoch: 6| Step: 2
Training loss: 0.0736517384648323
Validation loss: 1.57613129256874

Epoch: 6| Step: 3
Training loss: 0.07415297627449036
Validation loss: 1.5480830541221045

Epoch: 6| Step: 4
Training loss: 0.1463170349597931
Validation loss: 1.5677937384574645

Epoch: 6| Step: 5
Training loss: 0.07733507454395294
Validation loss: 1.5479658624177337

Epoch: 6| Step: 6
Training loss: 0.05659829080104828
Validation loss: 1.5413302298515075

Epoch: 6| Step: 7
Training loss: 0.05028817057609558
Validation loss: 1.550005921753504

Epoch: 6| Step: 8
Training loss: 0.04678073897957802
Validation loss: 1.5537161391268495

Epoch: 6| Step: 9
Training loss: 0.09193678200244904
Validation loss: 1.5878743266546598

Epoch: 6| Step: 10
Training loss: 0.0782892107963562
Validation loss: 1.5882777180722965

Epoch: 6| Step: 11
Training loss: 0.05824065953493118
Validation loss: 1.6072965027183614

Epoch: 6| Step: 12
Training loss: 0.1010921373963356
Validation loss: 1.5924906448651386

Epoch: 6| Step: 13
Training loss: 0.022835155948996544
Validation loss: 1.5890350367433281

Epoch: 602| Step: 0
Training loss: 0.0729021281003952
Validation loss: 1.603560733538802

Epoch: 6| Step: 1
Training loss: 0.08060803264379501
Validation loss: 1.5768053390646493

Epoch: 6| Step: 2
Training loss: 0.08356107771396637
Validation loss: 1.6013681568125242

Epoch: 6| Step: 3
Training loss: 0.06995797157287598
Validation loss: 1.636070305301297

Epoch: 6| Step: 4
Training loss: 0.09842900931835175
Validation loss: 1.6132902278695056

Epoch: 6| Step: 5
Training loss: 0.06285423785448074
Validation loss: 1.5810288466433042

Epoch: 6| Step: 6
Training loss: 0.07851174473762512
Validation loss: 1.5862184698863695

Epoch: 6| Step: 7
Training loss: 0.06194503605365753
Validation loss: 1.5939248338822396

Epoch: 6| Step: 8
Training loss: 0.11757165193557739
Validation loss: 1.5657683726279967

Epoch: 6| Step: 9
Training loss: 0.09580983221530914
Validation loss: 1.5584292270803963

Epoch: 6| Step: 10
Training loss: 0.07479606568813324
Validation loss: 1.5406952750298284

Epoch: 6| Step: 11
Training loss: 0.07097801566123962
Validation loss: 1.5462301238890617

Epoch: 6| Step: 12
Training loss: 0.05543430894613266
Validation loss: 1.5423281884962512

Epoch: 6| Step: 13
Training loss: 0.06940993666648865
Validation loss: 1.553562694339342

Epoch: 603| Step: 0
Training loss: 0.07712133228778839
Validation loss: 1.5490987582873272

Epoch: 6| Step: 1
Training loss: 0.05449638515710831
Validation loss: 1.5319112500836771

Epoch: 6| Step: 2
Training loss: 0.06344050914049149
Validation loss: 1.5414086567458285

Epoch: 6| Step: 3
Training loss: 0.047952763736248016
Validation loss: 1.5637436515541487

Epoch: 6| Step: 4
Training loss: 0.029361966997385025
Validation loss: 1.568982147401379

Epoch: 6| Step: 5
Training loss: 0.06842101365327835
Validation loss: 1.591286410567581

Epoch: 6| Step: 6
Training loss: 0.10541762411594391
Validation loss: 1.5493335416240077

Epoch: 6| Step: 7
Training loss: 0.06297415494918823
Validation loss: 1.578671569465309

Epoch: 6| Step: 8
Training loss: 0.08739852905273438
Validation loss: 1.5881153806563346

Epoch: 6| Step: 9
Training loss: 0.05698554962873459
Validation loss: 1.5754677775085613

Epoch: 6| Step: 10
Training loss: 0.10257329791784286
Validation loss: 1.5760768293052592

Epoch: 6| Step: 11
Training loss: 0.052300162613391876
Validation loss: 1.584963628040847

Epoch: 6| Step: 12
Training loss: 0.08945146203041077
Validation loss: 1.562353923756589

Epoch: 6| Step: 13
Training loss: 0.09765270352363586
Validation loss: 1.5676424484099112

Epoch: 604| Step: 0
Training loss: 0.09020630270242691
Validation loss: 1.5422993590754848

Epoch: 6| Step: 1
Training loss: 0.06753943860530853
Validation loss: 1.5443230341839533

Epoch: 6| Step: 2
Training loss: 0.09561066329479218
Validation loss: 1.5586065476940525

Epoch: 6| Step: 3
Training loss: 0.06089372932910919
Validation loss: 1.5614113705132597

Epoch: 6| Step: 4
Training loss: 0.049745380878448486
Validation loss: 1.541895406220549

Epoch: 6| Step: 5
Training loss: 0.09026430547237396
Validation loss: 1.5349564013942596

Epoch: 6| Step: 6
Training loss: 0.05394991487264633
Validation loss: 1.5165823505770775

Epoch: 6| Step: 7
Training loss: 0.0809503123164177
Validation loss: 1.5467215840534498

Epoch: 6| Step: 8
Training loss: 0.08481739461421967
Validation loss: 1.5381819330235964

Epoch: 6| Step: 9
Training loss: 0.05718906223773956
Validation loss: 1.5403193132851714

Epoch: 6| Step: 10
Training loss: 0.07923077046871185
Validation loss: 1.565430264319143

Epoch: 6| Step: 11
Training loss: 0.07964380830526352
Validation loss: 1.5327806113868632

Epoch: 6| Step: 12
Training loss: 0.09960047900676727
Validation loss: 1.5658944896472398

Epoch: 6| Step: 13
Training loss: 0.053914476186037064
Validation loss: 1.5420719321056078

Epoch: 605| Step: 0
Training loss: 0.06960292160511017
Validation loss: 1.5916750648970246

Epoch: 6| Step: 1
Training loss: 0.05352509394288063
Validation loss: 1.5954749276561122

Epoch: 6| Step: 2
Training loss: 0.05422866344451904
Validation loss: 1.599726036030759

Epoch: 6| Step: 3
Training loss: 0.05582910031080246
Validation loss: 1.5443782357759372

Epoch: 6| Step: 4
Training loss: 0.04977878928184509
Validation loss: 1.5859941487671227

Epoch: 6| Step: 5
Training loss: 0.11904112994670868
Validation loss: 1.5653934722305627

Epoch: 6| Step: 6
Training loss: 0.11405350267887115
Validation loss: 1.550785913262316

Epoch: 6| Step: 7
Training loss: 0.04950512573122978
Validation loss: 1.5284384527514059

Epoch: 6| Step: 8
Training loss: 0.11211267858743668
Validation loss: 1.5284281872933911

Epoch: 6| Step: 9
Training loss: 0.08607584238052368
Validation loss: 1.5144986183412614

Epoch: 6| Step: 10
Training loss: 0.06676198542118073
Validation loss: 1.5143049570821947

Epoch: 6| Step: 11
Training loss: 0.07372767478227615
Validation loss: 1.5099040885125437

Epoch: 6| Step: 12
Training loss: 0.07319756597280502
Validation loss: 1.509153610916548

Epoch: 6| Step: 13
Training loss: 0.05587785691022873
Validation loss: 1.5021600082356443

Epoch: 606| Step: 0
Training loss: 0.13267096877098083
Validation loss: 1.5433291017368276

Epoch: 6| Step: 1
Training loss: 0.06254379451274872
Validation loss: 1.5269400817091747

Epoch: 6| Step: 2
Training loss: 0.06577170640230179
Validation loss: 1.519471372968407

Epoch: 6| Step: 3
Training loss: 0.05011548101902008
Validation loss: 1.5133772306544806

Epoch: 6| Step: 4
Training loss: 0.058689311146736145
Validation loss: 1.5386269393787588

Epoch: 6| Step: 5
Training loss: 0.050682079046964645
Validation loss: 1.5720710472394062

Epoch: 6| Step: 6
Training loss: 0.07159468531608582
Validation loss: 1.5776849164757678

Epoch: 6| Step: 7
Training loss: 0.08529877662658691
Validation loss: 1.5599976688302972

Epoch: 6| Step: 8
Training loss: 0.05950668081641197
Validation loss: 1.569865680509998

Epoch: 6| Step: 9
Training loss: 0.13598336279392242
Validation loss: 1.5819952603309386

Epoch: 6| Step: 10
Training loss: 0.06631150096654892
Validation loss: 1.5669054805591542

Epoch: 6| Step: 11
Training loss: 0.06872890889644623
Validation loss: 1.5506772046448083

Epoch: 6| Step: 12
Training loss: 0.08943498134613037
Validation loss: 1.56658483705213

Epoch: 6| Step: 13
Training loss: 0.04469924420118332
Validation loss: 1.5554443764430221

Epoch: 607| Step: 0
Training loss: 0.06438808143138885
Validation loss: 1.5640460432216685

Epoch: 6| Step: 1
Training loss: 0.08683225512504578
Validation loss: 1.559156253773679

Epoch: 6| Step: 2
Training loss: 0.07642410695552826
Validation loss: 1.544627160154363

Epoch: 6| Step: 3
Training loss: 0.08846648037433624
Validation loss: 1.551884243565221

Epoch: 6| Step: 4
Training loss: 0.07241807132959366
Validation loss: 1.543581506257416

Epoch: 6| Step: 5
Training loss: 0.11079459637403488
Validation loss: 1.5540990791013163

Epoch: 6| Step: 6
Training loss: 0.10088277608156204
Validation loss: 1.5730658141515588

Epoch: 6| Step: 7
Training loss: 0.07352418452501297
Validation loss: 1.5185583047969367

Epoch: 6| Step: 8
Training loss: 0.11223790049552917
Validation loss: 1.5513168111924203

Epoch: 6| Step: 9
Training loss: 0.0879933312535286
Validation loss: 1.5528785323583951

Epoch: 6| Step: 10
Training loss: 0.08093326538801193
Validation loss: 1.5253436417989834

Epoch: 6| Step: 11
Training loss: 0.08719535171985626
Validation loss: 1.551276171079246

Epoch: 6| Step: 12
Training loss: 0.08313703536987305
Validation loss: 1.5558189692035798

Epoch: 6| Step: 13
Training loss: 0.13926848769187927
Validation loss: 1.5651219955054663

Epoch: 608| Step: 0
Training loss: 0.10785726457834244
Validation loss: 1.5761979344070598

Epoch: 6| Step: 1
Training loss: 0.043890245258808136
Validation loss: 1.5578135905727264

Epoch: 6| Step: 2
Training loss: 0.10203076899051666
Validation loss: 1.568185890874555

Epoch: 6| Step: 3
Training loss: 0.05100703984498978
Validation loss: 1.5568623735058693

Epoch: 6| Step: 4
Training loss: 0.054948996752500534
Validation loss: 1.526476158890673

Epoch: 6| Step: 5
Training loss: 0.0693235844373703
Validation loss: 1.5321213314610143

Epoch: 6| Step: 6
Training loss: 0.10049878060817719
Validation loss: 1.534710471348096

Epoch: 6| Step: 7
Training loss: 0.06942345201969147
Validation loss: 1.4969430546606741

Epoch: 6| Step: 8
Training loss: 0.08438284695148468
Validation loss: 1.513559627276595

Epoch: 6| Step: 9
Training loss: 0.056371524930000305
Validation loss: 1.5119390763262266

Epoch: 6| Step: 10
Training loss: 0.15141929686069489
Validation loss: 1.4916390616406676

Epoch: 6| Step: 11
Training loss: 0.08474026620388031
Validation loss: 1.5001961210722565

Epoch: 6| Step: 12
Training loss: 0.06298237293958664
Validation loss: 1.5046105795009161

Epoch: 6| Step: 13
Training loss: 0.052009742707014084
Validation loss: 1.502757381367427

Epoch: 609| Step: 0
Training loss: 0.04324118420481682
Validation loss: 1.505341543946215

Epoch: 6| Step: 1
Training loss: 0.09554019570350647
Validation loss: 1.5277401298604987

Epoch: 6| Step: 2
Training loss: 0.06306004524230957
Validation loss: 1.526463113805299

Epoch: 6| Step: 3
Training loss: 0.07929687201976776
Validation loss: 1.5205340487982637

Epoch: 6| Step: 4
Training loss: 0.09801730513572693
Validation loss: 1.529601227852606

Epoch: 6| Step: 5
Training loss: 0.08661168813705444
Validation loss: 1.5204041786091302

Epoch: 6| Step: 6
Training loss: 0.051224321126937866
Validation loss: 1.532511148401486

Epoch: 6| Step: 7
Training loss: 0.14560386538505554
Validation loss: 1.5099628125467608

Epoch: 6| Step: 8
Training loss: 0.10528655350208282
Validation loss: 1.5422887763669413

Epoch: 6| Step: 9
Training loss: 0.13541261851787567
Validation loss: 1.546998026550457

Epoch: 6| Step: 10
Training loss: 0.10446052998304367
Validation loss: 1.5476384662812757

Epoch: 6| Step: 11
Training loss: 0.05996815115213394
Validation loss: 1.5653613735270757

Epoch: 6| Step: 12
Training loss: 0.06730832904577255
Validation loss: 1.570062574519906

Epoch: 6| Step: 13
Training loss: 0.052632372826337814
Validation loss: 1.5726504441230529

Epoch: 610| Step: 0
Training loss: 0.09667934477329254
Validation loss: 1.5713123352296892

Epoch: 6| Step: 1
Training loss: 0.08095306158065796
Validation loss: 1.5944703984004196

Epoch: 6| Step: 2
Training loss: 0.08312223851680756
Validation loss: 1.5647655481933265

Epoch: 6| Step: 3
Training loss: 0.05732649192214012
Validation loss: 1.548322316138975

Epoch: 6| Step: 4
Training loss: 0.0916840136051178
Validation loss: 1.5566897238454511

Epoch: 6| Step: 5
Training loss: 0.07046519964933395
Validation loss: 1.5361436464453255

Epoch: 6| Step: 6
Training loss: 0.06177312880754471
Validation loss: 1.5407289503723063

Epoch: 6| Step: 7
Training loss: 0.06598849594593048
Validation loss: 1.5196174037071966

Epoch: 6| Step: 8
Training loss: 0.06280607730150223
Validation loss: 1.51405135790507

Epoch: 6| Step: 9
Training loss: 0.0748843252658844
Validation loss: 1.5488231649962805

Epoch: 6| Step: 10
Training loss: 0.06342031061649323
Validation loss: 1.5064024771413496

Epoch: 6| Step: 11
Training loss: 0.10565584897994995
Validation loss: 1.5372976103136617

Epoch: 6| Step: 12
Training loss: 0.05441493168473244
Validation loss: 1.4908392352442588

Epoch: 6| Step: 13
Training loss: 0.0988619327545166
Validation loss: 1.5056271155675252

Epoch: 611| Step: 0
Training loss: 0.11188481748104095
Validation loss: 1.4953743232193815

Epoch: 6| Step: 1
Training loss: 0.10765985399484634
Validation loss: 1.5202158292134602

Epoch: 6| Step: 2
Training loss: 0.07250133156776428
Validation loss: 1.5070955561053367

Epoch: 6| Step: 3
Training loss: 0.09057145565748215
Validation loss: 1.5172027900654783

Epoch: 6| Step: 4
Training loss: 0.06396090984344482
Validation loss: 1.5122571113289043

Epoch: 6| Step: 5
Training loss: 0.09751169383525848
Validation loss: 1.5062870492217362

Epoch: 6| Step: 6
Training loss: 0.07745963335037231
Validation loss: 1.4990372734685098

Epoch: 6| Step: 7
Training loss: 0.07440657168626785
Validation loss: 1.5159252112911594

Epoch: 6| Step: 8
Training loss: 0.04336489737033844
Validation loss: 1.5263376979417698

Epoch: 6| Step: 9
Training loss: 0.06715511530637741
Validation loss: 1.514359951019287

Epoch: 6| Step: 10
Training loss: 0.07139600068330765
Validation loss: 1.5259387364951513

Epoch: 6| Step: 11
Training loss: 0.08660322427749634
Validation loss: 1.5118018247747933

Epoch: 6| Step: 12
Training loss: 0.06428620219230652
Validation loss: 1.543476527737033

Epoch: 6| Step: 13
Training loss: 0.08603876829147339
Validation loss: 1.5390729827265586

Epoch: 612| Step: 0
Training loss: 0.0784079059958458
Validation loss: 1.5155279879928918

Epoch: 6| Step: 1
Training loss: 0.05997934192419052
Validation loss: 1.5141707825404342

Epoch: 6| Step: 2
Training loss: 0.06029418855905533
Validation loss: 1.458792059652267

Epoch: 6| Step: 3
Training loss: 0.06849037110805511
Validation loss: 1.4557782232120473

Epoch: 6| Step: 4
Training loss: 0.09952244162559509
Validation loss: 1.4676610680036648

Epoch: 6| Step: 5
Training loss: 0.1309579759836197
Validation loss: 1.4638514255964628

Epoch: 6| Step: 6
Training loss: 0.21453022956848145
Validation loss: 1.4810338097233926

Epoch: 6| Step: 7
Training loss: 0.0757170021533966
Validation loss: 1.4916244873436548

Epoch: 6| Step: 8
Training loss: 0.09212476015090942
Validation loss: 1.4747637446208666

Epoch: 6| Step: 9
Training loss: 0.07820898294448853
Validation loss: 1.464938502157888

Epoch: 6| Step: 10
Training loss: 0.07968566566705704
Validation loss: 1.508589562549386

Epoch: 6| Step: 11
Training loss: 0.09706167876720428
Validation loss: 1.480909127061085

Epoch: 6| Step: 12
Training loss: 0.10808645188808441
Validation loss: 1.526368784648116

Epoch: 6| Step: 13
Training loss: 0.07095612585544586
Validation loss: 1.4850071386624408

Epoch: 613| Step: 0
Training loss: 0.07616403698921204
Validation loss: 1.4867437603653118

Epoch: 6| Step: 1
Training loss: 0.10911069810390472
Validation loss: 1.4864839366687241

Epoch: 6| Step: 2
Training loss: 0.08945554494857788
Validation loss: 1.4769004865359234

Epoch: 6| Step: 3
Training loss: 0.04350583255290985
Validation loss: 1.4746277883488645

Epoch: 6| Step: 4
Training loss: 0.07742248475551605
Validation loss: 1.4992115753953175

Epoch: 6| Step: 5
Training loss: 0.08118415623903275
Validation loss: 1.5151661365262923

Epoch: 6| Step: 6
Training loss: 0.0470733642578125
Validation loss: 1.5315395016824045

Epoch: 6| Step: 7
Training loss: 0.05622447282075882
Validation loss: 1.5259573337852315

Epoch: 6| Step: 8
Training loss: 0.14757589995861053
Validation loss: 1.558721939722697

Epoch: 6| Step: 9
Training loss: 0.0782930925488472
Validation loss: 1.54767785661964

Epoch: 6| Step: 10
Training loss: 0.042284827679395676
Validation loss: 1.5378107909233338

Epoch: 6| Step: 11
Training loss: 0.06292357295751572
Validation loss: 1.5295142460894842

Epoch: 6| Step: 12
Training loss: 0.07754314690828323
Validation loss: 1.5281358265107678

Epoch: 6| Step: 13
Training loss: 0.1073155552148819
Validation loss: 1.5409698563237344

Epoch: 614| Step: 0
Training loss: 0.08112320303916931
Validation loss: 1.487025378852762

Epoch: 6| Step: 1
Training loss: 0.038970403373241425
Validation loss: 1.5373863468887985

Epoch: 6| Step: 2
Training loss: 0.070964515209198
Validation loss: 1.5071235651611

Epoch: 6| Step: 3
Training loss: 0.1023443415760994
Validation loss: 1.5184262734587475

Epoch: 6| Step: 4
Training loss: 0.06693702191114426
Validation loss: 1.511923873296348

Epoch: 6| Step: 5
Training loss: 0.0638999193906784
Validation loss: 1.5178190444105415

Epoch: 6| Step: 6
Training loss: 0.06429695338010788
Validation loss: 1.48063027346006

Epoch: 6| Step: 7
Training loss: 0.05671948194503784
Validation loss: 1.4941126864443544

Epoch: 6| Step: 8
Training loss: 0.06967144459486008
Validation loss: 1.502929097862654

Epoch: 6| Step: 9
Training loss: 0.15843802690505981
Validation loss: 1.4797917489082582

Epoch: 6| Step: 10
Training loss: 0.06393995881080627
Validation loss: 1.4887504603273125

Epoch: 6| Step: 11
Training loss: 0.09414339065551758
Validation loss: 1.4874979795948151

Epoch: 6| Step: 12
Training loss: 0.13003969192504883
Validation loss: 1.4843122895045946

Epoch: 6| Step: 13
Training loss: 0.07107218354940414
Validation loss: 1.473013731741136

Epoch: 615| Step: 0
Training loss: 0.05473458766937256
Validation loss: 1.4857401976021387

Epoch: 6| Step: 1
Training loss: 0.0701698586344719
Validation loss: 1.4777419054380028

Epoch: 6| Step: 2
Training loss: 0.1032206118106842
Validation loss: 1.4553174946897773

Epoch: 6| Step: 3
Training loss: 0.12622800469398499
Validation loss: 1.4835565423452726

Epoch: 6| Step: 4
Training loss: 0.054121438413858414
Validation loss: 1.5168439470311648

Epoch: 6| Step: 5
Training loss: 0.06676588952541351
Validation loss: 1.4924703003257833

Epoch: 6| Step: 6
Training loss: 0.10366262495517731
Validation loss: 1.5045398153284544

Epoch: 6| Step: 7
Training loss: 0.06282410025596619
Validation loss: 1.4899976099691083

Epoch: 6| Step: 8
Training loss: 0.0400271937251091
Validation loss: 1.4986918965975444

Epoch: 6| Step: 9
Training loss: 0.07682955265045166
Validation loss: 1.4869688877495386

Epoch: 6| Step: 10
Training loss: 0.08850031346082687
Validation loss: 1.4590231513464322

Epoch: 6| Step: 11
Training loss: 0.10189099609851837
Validation loss: 1.4921253368418703

Epoch: 6| Step: 12
Training loss: 0.08083058148622513
Validation loss: 1.4913142445266887

Epoch: 6| Step: 13
Training loss: 0.06952790170907974
Validation loss: 1.4410435307410456

Epoch: 616| Step: 0
Training loss: 0.10467088967561722
Validation loss: 1.4494190690337971

Epoch: 6| Step: 1
Training loss: 0.07131324708461761
Validation loss: 1.4749216315566853

Epoch: 6| Step: 2
Training loss: 0.06410575658082962
Validation loss: 1.4621571084504486

Epoch: 6| Step: 3
Training loss: 0.05829808861017227
Validation loss: 1.4944399005623275

Epoch: 6| Step: 4
Training loss: 0.06604652106761932
Validation loss: 1.5158133840048185

Epoch: 6| Step: 5
Training loss: 0.09648368507623672
Validation loss: 1.5329384496135097

Epoch: 6| Step: 6
Training loss: 0.09652617573738098
Validation loss: 1.514196494574188

Epoch: 6| Step: 7
Training loss: 0.08358689397573471
Validation loss: 1.5196857067846483

Epoch: 6| Step: 8
Training loss: 0.11139561235904694
Validation loss: 1.5223293817171486

Epoch: 6| Step: 9
Training loss: 0.09685610234737396
Validation loss: 1.5154064688631284

Epoch: 6| Step: 10
Training loss: 0.06484805047512054
Validation loss: 1.50321747667046

Epoch: 6| Step: 11
Training loss: 0.09110550582408905
Validation loss: 1.5116148789723713

Epoch: 6| Step: 12
Training loss: 0.05178126320242882
Validation loss: 1.4948488589256042

Epoch: 6| Step: 13
Training loss: 0.03322945535182953
Validation loss: 1.4869666599458264

Epoch: 617| Step: 0
Training loss: 0.1453748345375061
Validation loss: 1.483539164707225

Epoch: 6| Step: 1
Training loss: 0.07812183350324631
Validation loss: 1.468493810264013

Epoch: 6| Step: 2
Training loss: 0.05584637075662613
Validation loss: 1.4748892809755059

Epoch: 6| Step: 3
Training loss: 0.0755501240491867
Validation loss: 1.4783811517941055

Epoch: 6| Step: 4
Training loss: 0.03861940652132034
Validation loss: 1.521570638943744

Epoch: 6| Step: 5
Training loss: 0.0666985958814621
Validation loss: 1.5348580063030284

Epoch: 6| Step: 6
Training loss: 0.0715772807598114
Validation loss: 1.5457863673087089

Epoch: 6| Step: 7
Training loss: 0.0886310413479805
Validation loss: 1.5512254084310224

Epoch: 6| Step: 8
Training loss: 0.11871051788330078
Validation loss: 1.5505546498042282

Epoch: 6| Step: 9
Training loss: 0.10220861434936523
Validation loss: 1.552572843849018

Epoch: 6| Step: 10
Training loss: 0.083729088306427
Validation loss: 1.5623778258600542

Epoch: 6| Step: 11
Training loss: 0.05272805690765381
Validation loss: 1.5597326165886336

Epoch: 6| Step: 12
Training loss: 0.09274933487176895
Validation loss: 1.533510011370464

Epoch: 6| Step: 13
Training loss: 0.0236057061702013
Validation loss: 1.4930826361461351

Epoch: 618| Step: 0
Training loss: 0.06078552454710007
Validation loss: 1.4923468802564888

Epoch: 6| Step: 1
Training loss: 0.10181446373462677
Validation loss: 1.5046440709021784

Epoch: 6| Step: 2
Training loss: 0.09125372767448425
Validation loss: 1.4685810067320382

Epoch: 6| Step: 3
Training loss: 0.09847548604011536
Validation loss: 1.4872513663384221

Epoch: 6| Step: 4
Training loss: 0.11308862268924713
Validation loss: 1.4739642604704826

Epoch: 6| Step: 5
Training loss: 0.10234113037586212
Validation loss: 1.5024960540956067

Epoch: 6| Step: 6
Training loss: 0.13699987530708313
Validation loss: 1.5094073459666262

Epoch: 6| Step: 7
Training loss: 0.06926402449607849
Validation loss: 1.5324026346206665

Epoch: 6| Step: 8
Training loss: 0.061825864017009735
Validation loss: 1.4984285261041375

Epoch: 6| Step: 9
Training loss: 0.0435914546251297
Validation loss: 1.5167094392161216

Epoch: 6| Step: 10
Training loss: 0.05418872833251953
Validation loss: 1.5220335350241712

Epoch: 6| Step: 11
Training loss: 0.06696593016386032
Validation loss: 1.5461210332890993

Epoch: 6| Step: 12
Training loss: 0.06276566535234451
Validation loss: 1.538324599624962

Epoch: 6| Step: 13
Training loss: 0.04956882819533348
Validation loss: 1.539446303921361

Epoch: 619| Step: 0
Training loss: 0.10356016457080841
Validation loss: 1.549815809854897

Epoch: 6| Step: 1
Training loss: 0.04824979230761528
Validation loss: 1.536978716491371

Epoch: 6| Step: 2
Training loss: 0.03654024377465248
Validation loss: 1.5465993599225116

Epoch: 6| Step: 3
Training loss: 0.05718968063592911
Validation loss: 1.506099142054076

Epoch: 6| Step: 4
Training loss: 0.0734461098909378
Validation loss: 1.5211520207825528

Epoch: 6| Step: 5
Training loss: 0.055827546864748
Validation loss: 1.5340039422435146

Epoch: 6| Step: 6
Training loss: 0.10617437958717346
Validation loss: 1.5363613866990613

Epoch: 6| Step: 7
Training loss: 0.09912718832492828
Validation loss: 1.5256993847508584

Epoch: 6| Step: 8
Training loss: 0.0743599459528923
Validation loss: 1.5255239509767102

Epoch: 6| Step: 9
Training loss: 0.13993661105632782
Validation loss: 1.539227145974354

Epoch: 6| Step: 10
Training loss: 0.09907612204551697
Validation loss: 1.5530896827738772

Epoch: 6| Step: 11
Training loss: 0.10661885142326355
Validation loss: 1.5612132126285183

Epoch: 6| Step: 12
Training loss: 0.11041110754013062
Validation loss: 1.5482578187860467

Epoch: 6| Step: 13
Training loss: 0.0423952080309391
Validation loss: 1.5539434494510773

Epoch: 620| Step: 0
Training loss: 0.03619879111647606
Validation loss: 1.552309254805247

Epoch: 6| Step: 1
Training loss: 0.07008235156536102
Validation loss: 1.530692179997762

Epoch: 6| Step: 2
Training loss: 0.07859274744987488
Validation loss: 1.5320160312037314

Epoch: 6| Step: 3
Training loss: 0.09226340800523758
Validation loss: 1.5209176899284444

Epoch: 6| Step: 4
Training loss: 0.03265143930912018
Validation loss: 1.5302713148055538

Epoch: 6| Step: 5
Training loss: 0.07046093046665192
Validation loss: 1.5258233957393195

Epoch: 6| Step: 6
Training loss: 0.06632523238658905
Validation loss: 1.5241543285308345

Epoch: 6| Step: 7
Training loss: 0.15545660257339478
Validation loss: 1.5269106382964759

Epoch: 6| Step: 8
Training loss: 0.05952420085668564
Validation loss: 1.5464235749295963

Epoch: 6| Step: 9
Training loss: 0.08355160057544708
Validation loss: 1.55037223780027

Epoch: 6| Step: 10
Training loss: 0.07183712720870972
Validation loss: 1.569048281638853

Epoch: 6| Step: 11
Training loss: 0.1228269413113594
Validation loss: 1.5881860768923195

Epoch: 6| Step: 12
Training loss: 0.1029423326253891
Validation loss: 1.5556241786608132

Epoch: 6| Step: 13
Training loss: 0.06935269385576248
Validation loss: 1.5455226372647028

Epoch: 621| Step: 0
Training loss: 0.09320701658725739
Validation loss: 1.569255607102507

Epoch: 6| Step: 1
Training loss: 0.03904568403959274
Validation loss: 1.56861489178032

Epoch: 6| Step: 2
Training loss: 0.06765978038311005
Validation loss: 1.5390176708980272

Epoch: 6| Step: 3
Training loss: 0.12607154250144958
Validation loss: 1.54284676044218

Epoch: 6| Step: 4
Training loss: 0.09011487662792206
Validation loss: 1.527656735912446

Epoch: 6| Step: 5
Training loss: 0.12135370075702667
Validation loss: 1.5227031361672185

Epoch: 6| Step: 6
Training loss: 0.13247397541999817
Validation loss: 1.5011139185197893

Epoch: 6| Step: 7
Training loss: 0.2136247754096985
Validation loss: 1.4774215734133156

Epoch: 6| Step: 8
Training loss: 0.0823124423623085
Validation loss: 1.5034415503983856

Epoch: 6| Step: 9
Training loss: 0.08927460759878159
Validation loss: 1.5078373647505237

Epoch: 6| Step: 10
Training loss: 0.10602696239948273
Validation loss: 1.5150219112314203

Epoch: 6| Step: 11
Training loss: 0.06070634722709656
Validation loss: 1.5003665070379935

Epoch: 6| Step: 12
Training loss: 0.06767039000988007
Validation loss: 1.5097225545555033

Epoch: 6| Step: 13
Training loss: 0.10338648408651352
Validation loss: 1.532506355675318

Epoch: 622| Step: 0
Training loss: 0.18091928958892822
Validation loss: 1.5020667083801762

Epoch: 6| Step: 1
Training loss: 0.10165104269981384
Validation loss: 1.4904882228502663

Epoch: 6| Step: 2
Training loss: 0.057157255709171295
Validation loss: 1.4842373491615377

Epoch: 6| Step: 3
Training loss: 0.10824382305145264
Validation loss: 1.4986031401541926

Epoch: 6| Step: 4
Training loss: 0.08188394457101822
Validation loss: 1.5313572268332205

Epoch: 6| Step: 5
Training loss: 0.08646329492330551
Validation loss: 1.4984216004289606

Epoch: 6| Step: 6
Training loss: 0.11038006842136383
Validation loss: 1.56189594217526

Epoch: 6| Step: 7
Training loss: 0.12877750396728516
Validation loss: 1.6052637715493479

Epoch: 6| Step: 8
Training loss: 0.14909011125564575
Validation loss: 1.6162176286020586

Epoch: 6| Step: 9
Training loss: 0.076839379966259
Validation loss: 1.6466104856101416

Epoch: 6| Step: 10
Training loss: 0.11283726990222931
Validation loss: 1.6250667290021015

Epoch: 6| Step: 11
Training loss: 0.07363754510879517
Validation loss: 1.641046711193618

Epoch: 6| Step: 12
Training loss: 0.1556277871131897
Validation loss: 1.6386492124167822

Epoch: 6| Step: 13
Training loss: 0.1357049196958542
Validation loss: 1.6395818315526491

Epoch: 623| Step: 0
Training loss: 0.07271921634674072
Validation loss: 1.6185958231649091

Epoch: 6| Step: 1
Training loss: 0.0965244397521019
Validation loss: 1.5707796119874524

Epoch: 6| Step: 2
Training loss: 0.1224982738494873
Validation loss: 1.5516348782406058

Epoch: 6| Step: 3
Training loss: 0.0945030152797699
Validation loss: 1.511238468590603

Epoch: 6| Step: 4
Training loss: 0.1279626488685608
Validation loss: 1.5391483588885235

Epoch: 6| Step: 5
Training loss: 0.1710486114025116
Validation loss: 1.5123833020528157

Epoch: 6| Step: 6
Training loss: 0.10458579659461975
Validation loss: 1.522093210169064

Epoch: 6| Step: 7
Training loss: 0.10245765000581741
Validation loss: 1.528281650235576

Epoch: 6| Step: 8
Training loss: 0.0883031040430069
Validation loss: 1.5080907389681826

Epoch: 6| Step: 9
Training loss: 0.07384321093559265
Validation loss: 1.548107700963174

Epoch: 6| Step: 10
Training loss: 0.11487330496311188
Validation loss: 1.5521470314712935

Epoch: 6| Step: 11
Training loss: 0.11211946606636047
Validation loss: 1.572190906411858

Epoch: 6| Step: 12
Training loss: 0.10162854939699173
Validation loss: 1.5935558042218607

Epoch: 6| Step: 13
Training loss: 0.06476015597581863
Validation loss: 1.55429107399397

Epoch: 624| Step: 0
Training loss: 0.04879800230264664
Validation loss: 1.5356084480080554

Epoch: 6| Step: 1
Training loss: 0.04716147482395172
Validation loss: 1.5006131946399648

Epoch: 6| Step: 2
Training loss: 0.09277006983757019
Validation loss: 1.4920415583477225

Epoch: 6| Step: 3
Training loss: 0.06848975270986557
Validation loss: 1.4802800250309769

Epoch: 6| Step: 4
Training loss: 0.04697996750473976
Validation loss: 1.4870812604504247

Epoch: 6| Step: 5
Training loss: 0.08363129198551178
Validation loss: 1.4963775962911627

Epoch: 6| Step: 6
Training loss: 0.130129873752594
Validation loss: 1.505652096963698

Epoch: 6| Step: 7
Training loss: 0.08845791220664978
Validation loss: 1.5131282614123436

Epoch: 6| Step: 8
Training loss: 0.059418678283691406
Validation loss: 1.5088635849696335

Epoch: 6| Step: 9
Training loss: 0.11160147935152054
Validation loss: 1.4880302259998937

Epoch: 6| Step: 10
Training loss: 0.10858698934316635
Validation loss: 1.5482002804356236

Epoch: 6| Step: 11
Training loss: 0.06559661030769348
Validation loss: 1.55383167728301

Epoch: 6| Step: 12
Training loss: 0.09388542175292969
Validation loss: 1.562230760051358

Epoch: 6| Step: 13
Training loss: 0.07033068686723709
Validation loss: 1.543319861094157

Epoch: 625| Step: 0
Training loss: 0.11119478195905685
Validation loss: 1.5607353282231156

Epoch: 6| Step: 1
Training loss: 0.074146568775177
Validation loss: 1.5085910097245248

Epoch: 6| Step: 2
Training loss: 0.0942397490143776
Validation loss: 1.5004080931345622

Epoch: 6| Step: 3
Training loss: 0.07970377802848816
Validation loss: 1.496757322742093

Epoch: 6| Step: 4
Training loss: 0.1089019924402237
Validation loss: 1.4900023052769322

Epoch: 6| Step: 5
Training loss: 0.08422347903251648
Validation loss: 1.48539573530997

Epoch: 6| Step: 6
Training loss: 0.06713970750570297
Validation loss: 1.4946073300095015

Epoch: 6| Step: 7
Training loss: 0.07588993012905121
Validation loss: 1.5038211730218702

Epoch: 6| Step: 8
Training loss: 0.04831743240356445
Validation loss: 1.5284821359060143

Epoch: 6| Step: 9
Training loss: 0.06667351722717285
Validation loss: 1.5549539160984818

Epoch: 6| Step: 10
Training loss: 0.07960419356822968
Validation loss: 1.56865265036142

Epoch: 6| Step: 11
Training loss: 0.07186637818813324
Validation loss: 1.5643269708079677

Epoch: 6| Step: 12
Training loss: 0.08905722200870514
Validation loss: 1.5681053105221

Epoch: 6| Step: 13
Training loss: 0.13700832426548004
Validation loss: 1.5825700247159569

Epoch: 626| Step: 0
Training loss: 0.06319411844015121
Validation loss: 1.5714204644644132

Epoch: 6| Step: 1
Training loss: 0.056957364082336426
Validation loss: 1.570763208532846

Epoch: 6| Step: 2
Training loss: 0.1394452154636383
Validation loss: 1.5700872303337179

Epoch: 6| Step: 3
Training loss: 0.07780146598815918
Validation loss: 1.5623325609391736

Epoch: 6| Step: 4
Training loss: 0.07302768528461456
Validation loss: 1.546554733348149

Epoch: 6| Step: 5
Training loss: 0.078216552734375
Validation loss: 1.5192424353732858

Epoch: 6| Step: 6
Training loss: 0.114504873752594
Validation loss: 1.5409569894113848

Epoch: 6| Step: 7
Training loss: 0.08512918651103973
Validation loss: 1.5929834682454345

Epoch: 6| Step: 8
Training loss: 0.061553068459033966
Validation loss: 1.5412787314384215

Epoch: 6| Step: 9
Training loss: 0.060282789170742035
Validation loss: 1.5677972762815413

Epoch: 6| Step: 10
Training loss: 0.08258166909217834
Validation loss: 1.5625618991031442

Epoch: 6| Step: 11
Training loss: 0.06188112497329712
Validation loss: 1.5741117782490228

Epoch: 6| Step: 12
Training loss: 0.0793963074684143
Validation loss: 1.5701537500786524

Epoch: 6| Step: 13
Training loss: 0.08568138629198074
Validation loss: 1.5904687643051147

Epoch: 627| Step: 0
Training loss: 0.08763746172189713
Validation loss: 1.5657378627407936

Epoch: 6| Step: 1
Training loss: 0.05793337523937225
Validation loss: 1.5638035612721597

Epoch: 6| Step: 2
Training loss: 0.10603832453489304
Validation loss: 1.5617164488761657

Epoch: 6| Step: 3
Training loss: 0.08922601491212845
Validation loss: 1.5413044498812767

Epoch: 6| Step: 4
Training loss: 0.09301412105560303
Validation loss: 1.5330488194701493

Epoch: 6| Step: 5
Training loss: 0.09227587282657623
Validation loss: 1.510023223456516

Epoch: 6| Step: 6
Training loss: 0.18724432587623596
Validation loss: 1.506200921150946

Epoch: 6| Step: 7
Training loss: 0.08800525218248367
Validation loss: 1.4869077577385852

Epoch: 6| Step: 8
Training loss: 0.10273078083992004
Validation loss: 1.4969676771471578

Epoch: 6| Step: 9
Training loss: 0.055153150111436844
Validation loss: 1.51193126363139

Epoch: 6| Step: 10
Training loss: 0.07564063370227814
Validation loss: 1.5298451595408942

Epoch: 6| Step: 11
Training loss: 0.04034604877233505
Validation loss: 1.5304102974553262

Epoch: 6| Step: 12
Training loss: 0.08862625062465668
Validation loss: 1.5080463194078015

Epoch: 6| Step: 13
Training loss: 0.11246450990438461
Validation loss: 1.5548963277570662

Epoch: 628| Step: 0
Training loss: 0.08176805078983307
Validation loss: 1.5577401602140037

Epoch: 6| Step: 1
Training loss: 0.06667819619178772
Validation loss: 1.5602286220878683

Epoch: 6| Step: 2
Training loss: 0.04032815992832184
Validation loss: 1.569239627930426

Epoch: 6| Step: 3
Training loss: 0.13650257885456085
Validation loss: 1.5760036104468889

Epoch: 6| Step: 4
Training loss: 0.14154353737831116
Validation loss: 1.556115706761678

Epoch: 6| Step: 5
Training loss: 0.061920855194330215
Validation loss: 1.5688833062366774

Epoch: 6| Step: 6
Training loss: 0.08005911111831665
Validation loss: 1.5474696749000139

Epoch: 6| Step: 7
Training loss: 0.059714943170547485
Validation loss: 1.5410373800544328

Epoch: 6| Step: 8
Training loss: 0.07203974574804306
Validation loss: 1.5394329793991581

Epoch: 6| Step: 9
Training loss: 0.10991676896810532
Validation loss: 1.5472239986542733

Epoch: 6| Step: 10
Training loss: 0.08261667937040329
Validation loss: 1.50942402116714

Epoch: 6| Step: 11
Training loss: 0.07149041444063187
Validation loss: 1.560519487627091

Epoch: 6| Step: 12
Training loss: 0.04512172192335129
Validation loss: 1.5146167906381751

Epoch: 6| Step: 13
Training loss: 0.049619004130363464
Validation loss: 1.540924160711227

Epoch: 629| Step: 0
Training loss: 0.07058891654014587
Validation loss: 1.5333392850814327

Epoch: 6| Step: 1
Training loss: 0.05579919368028641
Validation loss: 1.5365151628371208

Epoch: 6| Step: 2
Training loss: 0.10685431212186813
Validation loss: 1.57104294530807

Epoch: 6| Step: 3
Training loss: 0.08433885872364044
Validation loss: 1.567384635248492

Epoch: 6| Step: 4
Training loss: 0.12914344668388367
Validation loss: 1.5827997089714132

Epoch: 6| Step: 5
Training loss: 0.0952998474240303
Validation loss: 1.5916063260006648

Epoch: 6| Step: 6
Training loss: 0.05179540067911148
Validation loss: 1.5432622330163115

Epoch: 6| Step: 7
Training loss: 0.11035272479057312
Validation loss: 1.554482436949207

Epoch: 6| Step: 8
Training loss: 0.07862860709428787
Validation loss: 1.5630751476492932

Epoch: 6| Step: 9
Training loss: 0.056364767253398895
Validation loss: 1.5231322133412926

Epoch: 6| Step: 10
Training loss: 0.0696219652891159
Validation loss: 1.5254513986649052

Epoch: 6| Step: 11
Training loss: 0.1000036671757698
Validation loss: 1.4970248271060247

Epoch: 6| Step: 12
Training loss: 0.0665815994143486
Validation loss: 1.4856391991338422

Epoch: 6| Step: 13
Training loss: 0.07632502913475037
Validation loss: 1.4737819945940407

Epoch: 630| Step: 0
Training loss: 0.07028239220380783
Validation loss: 1.472169603070905

Epoch: 6| Step: 1
Training loss: 0.05336915701627731
Validation loss: 1.5021824798276346

Epoch: 6| Step: 2
Training loss: 0.0407882034778595
Validation loss: 1.507892467642343

Epoch: 6| Step: 3
Training loss: 0.1354082226753235
Validation loss: 1.5001916731557539

Epoch: 6| Step: 4
Training loss: 0.08100777119398117
Validation loss: 1.4845964036962038

Epoch: 6| Step: 5
Training loss: 0.06637626141309738
Validation loss: 1.5094299559952111

Epoch: 6| Step: 6
Training loss: 0.033848389983177185
Validation loss: 1.4833881355101062

Epoch: 6| Step: 7
Training loss: 0.07470706105232239
Validation loss: 1.489861180705409

Epoch: 6| Step: 8
Training loss: 0.061651717871427536
Validation loss: 1.4930591519160936

Epoch: 6| Step: 9
Training loss: 0.07706345617771149
Validation loss: 1.491963214771722

Epoch: 6| Step: 10
Training loss: 0.0871441662311554
Validation loss: 1.506996762367987

Epoch: 6| Step: 11
Training loss: 0.06074424460530281
Validation loss: 1.4961017709906383

Epoch: 6| Step: 12
Training loss: 0.04288588464260101
Validation loss: 1.5158386897015315

Epoch: 6| Step: 13
Training loss: 0.09321796894073486
Validation loss: 1.5172976678417576

Epoch: 631| Step: 0
Training loss: 0.11511874198913574
Validation loss: 1.5113895657241985

Epoch: 6| Step: 1
Training loss: 0.06700877845287323
Validation loss: 1.5012304385503132

Epoch: 6| Step: 2
Training loss: 0.09617054462432861
Validation loss: 1.5131778153040076

Epoch: 6| Step: 3
Training loss: 0.07159797847270966
Validation loss: 1.5205613797710789

Epoch: 6| Step: 4
Training loss: 0.082614965736866
Validation loss: 1.5429209188748432

Epoch: 6| Step: 5
Training loss: 0.05865585803985596
Validation loss: 1.5318252155857701

Epoch: 6| Step: 6
Training loss: 0.11105205118656158
Validation loss: 1.5559219538524587

Epoch: 6| Step: 7
Training loss: 0.10819278657436371
Validation loss: 1.568881521942795

Epoch: 6| Step: 8
Training loss: 0.09345480799674988
Validation loss: 1.5845272964046848

Epoch: 6| Step: 9
Training loss: 0.10567061603069305
Validation loss: 1.5744755204005907

Epoch: 6| Step: 10
Training loss: 0.07810664921998978
Validation loss: 1.5999690813402976

Epoch: 6| Step: 11
Training loss: 0.15681800246238708
Validation loss: 1.5792994217206073

Epoch: 6| Step: 12
Training loss: 0.13707543909549713
Validation loss: 1.576670487721761

Epoch: 6| Step: 13
Training loss: 0.1085941419005394
Validation loss: 1.5663727239895893

Epoch: 632| Step: 0
Training loss: 0.1316716969013214
Validation loss: 1.5654757471494778

Epoch: 6| Step: 1
Training loss: 0.0934813991189003
Validation loss: 1.5443860215525473

Epoch: 6| Step: 2
Training loss: 0.07499273121356964
Validation loss: 1.526260377258383

Epoch: 6| Step: 3
Training loss: 0.0698864758014679
Validation loss: 1.5123923209405714

Epoch: 6| Step: 4
Training loss: 0.06338576972484589
Validation loss: 1.5125742612346527

Epoch: 6| Step: 5
Training loss: 0.03370874375104904
Validation loss: 1.5127405389662711

Epoch: 6| Step: 6
Training loss: 0.06632694602012634
Validation loss: 1.5130477964237172

Epoch: 6| Step: 7
Training loss: 0.09780091792345047
Validation loss: 1.5085619867488902

Epoch: 6| Step: 8
Training loss: 0.0634976327419281
Validation loss: 1.5183946394151258

Epoch: 6| Step: 9
Training loss: 0.15290872752666473
Validation loss: 1.5087750086220362

Epoch: 6| Step: 10
Training loss: 0.06025380641222
Validation loss: 1.5193331600517355

Epoch: 6| Step: 11
Training loss: 0.12319061160087585
Validation loss: 1.5334887735305294

Epoch: 6| Step: 12
Training loss: 0.052902959287166595
Validation loss: 1.5220879418875581

Epoch: 6| Step: 13
Training loss: 0.05899818614125252
Validation loss: 1.5279683143861833

Epoch: 633| Step: 0
Training loss: 0.07151515036821365
Validation loss: 1.5338828653417609

Epoch: 6| Step: 1
Training loss: 0.059660203754901886
Validation loss: 1.507740802021437

Epoch: 6| Step: 2
Training loss: 0.1073426604270935
Validation loss: 1.5247343112063665

Epoch: 6| Step: 3
Training loss: 0.09420256316661835
Validation loss: 1.5026289493806901

Epoch: 6| Step: 4
Training loss: 0.09938733279705048
Validation loss: 1.506448886727774

Epoch: 6| Step: 5
Training loss: 0.09347856789827347
Validation loss: 1.5544914058459702

Epoch: 6| Step: 6
Training loss: 0.08465276658535004
Validation loss: 1.5698154575081282

Epoch: 6| Step: 7
Training loss: 0.05452587455511093
Validation loss: 1.5546059198276971

Epoch: 6| Step: 8
Training loss: 0.06818143278360367
Validation loss: 1.550814103054744

Epoch: 6| Step: 9
Training loss: 0.06467171013355255
Validation loss: 1.5601383742465769

Epoch: 6| Step: 10
Training loss: 0.07062043249607086
Validation loss: 1.5237207604992775

Epoch: 6| Step: 11
Training loss: 0.100906603038311
Validation loss: 1.5360531294217674

Epoch: 6| Step: 12
Training loss: 0.0609075203537941
Validation loss: 1.4996314202585528

Epoch: 6| Step: 13
Training loss: 0.07040993124246597
Validation loss: 1.5086553148044053

Epoch: 634| Step: 0
Training loss: 0.07079790532588959
Validation loss: 1.5091150729886946

Epoch: 6| Step: 1
Training loss: 0.07967635989189148
Validation loss: 1.5218235087651077

Epoch: 6| Step: 2
Training loss: 0.06587490439414978
Validation loss: 1.5421538647784983

Epoch: 6| Step: 3
Training loss: 0.06826919317245483
Validation loss: 1.518718397745522

Epoch: 6| Step: 4
Training loss: 0.06744969636201859
Validation loss: 1.5095842442204874

Epoch: 6| Step: 5
Training loss: 0.08029918372631073
Validation loss: 1.5142073541559198

Epoch: 6| Step: 6
Training loss: 0.06210736930370331
Validation loss: 1.5251865630508752

Epoch: 6| Step: 7
Training loss: 0.04793992266058922
Validation loss: 1.521674956044843

Epoch: 6| Step: 8
Training loss: 0.10822676122188568
Validation loss: 1.5142471700586297

Epoch: 6| Step: 9
Training loss: 0.10918281972408295
Validation loss: 1.5355496111736502

Epoch: 6| Step: 10
Training loss: 0.05949290096759796
Validation loss: 1.5525874655733827

Epoch: 6| Step: 11
Training loss: 0.08991216123104095
Validation loss: 1.5405855922288791

Epoch: 6| Step: 12
Training loss: 0.053519971668720245
Validation loss: 1.5139607678177536

Epoch: 6| Step: 13
Training loss: 0.06368865817785263
Validation loss: 1.5056220023862776

Epoch: 635| Step: 0
Training loss: 0.09920548647642136
Validation loss: 1.5270763776635612

Epoch: 6| Step: 1
Training loss: 0.11505912244319916
Validation loss: 1.4694394193669802

Epoch: 6| Step: 2
Training loss: 0.07094305008649826
Validation loss: 1.4943221576752201

Epoch: 6| Step: 3
Training loss: 0.1223556250333786
Validation loss: 1.4583844004138824

Epoch: 6| Step: 4
Training loss: 0.058211345225572586
Validation loss: 1.489306633190442

Epoch: 6| Step: 5
Training loss: 0.04123591631650925
Validation loss: 1.5106646053252681

Epoch: 6| Step: 6
Training loss: 0.12472420930862427
Validation loss: 1.4953195561644852

Epoch: 6| Step: 7
Training loss: 0.0971992015838623
Validation loss: 1.5038362767106743

Epoch: 6| Step: 8
Training loss: 0.06186741590499878
Validation loss: 1.508556140366421

Epoch: 6| Step: 9
Training loss: 0.04442828893661499
Validation loss: 1.521624763806661

Epoch: 6| Step: 10
Training loss: 0.051289789378643036
Validation loss: 1.488479248939022

Epoch: 6| Step: 11
Training loss: 0.0626407340168953
Validation loss: 1.497216300297809

Epoch: 6| Step: 12
Training loss: 0.05723566561937332
Validation loss: 1.5168411757356377

Epoch: 6| Step: 13
Training loss: 0.06106938421726227
Validation loss: 1.496367198164745

Epoch: 636| Step: 0
Training loss: 0.045687273144721985
Validation loss: 1.48055023788124

Epoch: 6| Step: 1
Training loss: 0.09156301617622375
Validation loss: 1.4847559057256228

Epoch: 6| Step: 2
Training loss: 0.047041140496730804
Validation loss: 1.4971430455484698

Epoch: 6| Step: 3
Training loss: 0.06973408162593842
Validation loss: 1.508730794793816

Epoch: 6| Step: 4
Training loss: 0.06082494184374809
Validation loss: 1.5099175155803721

Epoch: 6| Step: 5
Training loss: 0.11314234137535095
Validation loss: 1.5123551500740873

Epoch: 6| Step: 6
Training loss: 0.05609321594238281
Validation loss: 1.5134858392900037

Epoch: 6| Step: 7
Training loss: 0.04805765300989151
Validation loss: 1.5266874451791086

Epoch: 6| Step: 8
Training loss: 0.05509146675467491
Validation loss: 1.5183813456566102

Epoch: 6| Step: 9
Training loss: 0.05272357910871506
Validation loss: 1.51119597752889

Epoch: 6| Step: 10
Training loss: 0.04544651880860329
Validation loss: 1.517439055186446

Epoch: 6| Step: 11
Training loss: 0.07464540004730225
Validation loss: 1.5301472422897175

Epoch: 6| Step: 12
Training loss: 0.08093670755624771
Validation loss: 1.5063962962037774

Epoch: 6| Step: 13
Training loss: 0.03678591921925545
Validation loss: 1.5039612708553192

Epoch: 637| Step: 0
Training loss: 0.05055857077240944
Validation loss: 1.4992867708206177

Epoch: 6| Step: 1
Training loss: 0.058627545833587646
Validation loss: 1.5096375852502801

Epoch: 6| Step: 2
Training loss: 0.09151557832956314
Validation loss: 1.477469830102818

Epoch: 6| Step: 3
Training loss: 0.08983970433473587
Validation loss: 1.5197004490001227

Epoch: 6| Step: 4
Training loss: 0.05632634833455086
Validation loss: 1.503324866935771

Epoch: 6| Step: 5
Training loss: 0.04859708249568939
Validation loss: 1.5154283713268977

Epoch: 6| Step: 6
Training loss: 0.06332352757453918
Validation loss: 1.4912496356553928

Epoch: 6| Step: 7
Training loss: 0.047196775674819946
Validation loss: 1.4819672005150908

Epoch: 6| Step: 8
Training loss: 0.029779329895973206
Validation loss: 1.4695839087168376

Epoch: 6| Step: 9
Training loss: 0.07939925044775009
Validation loss: 1.466243359350389

Epoch: 6| Step: 10
Training loss: 0.07040620595216751
Validation loss: 1.4536163307005359

Epoch: 6| Step: 11
Training loss: 0.1101808249950409
Validation loss: 1.4851134092577043

Epoch: 6| Step: 12
Training loss: 0.06401658803224564
Validation loss: 1.48827455377066

Epoch: 6| Step: 13
Training loss: 0.031731367111206055
Validation loss: 1.4784634497857863

Epoch: 638| Step: 0
Training loss: 0.05083872377872467
Validation loss: 1.4898832831331479

Epoch: 6| Step: 1
Training loss: 0.05338669568300247
Validation loss: 1.5183447137955697

Epoch: 6| Step: 2
Training loss: 0.08896440267562866
Validation loss: 1.508597327816871

Epoch: 6| Step: 3
Training loss: 0.06836529076099396
Validation loss: 1.488975154456272

Epoch: 6| Step: 4
Training loss: 0.09097442775964737
Validation loss: 1.476664299605995

Epoch: 6| Step: 5
Training loss: 0.06181836873292923
Validation loss: 1.4737807102100824

Epoch: 6| Step: 6
Training loss: 0.06031621992588043
Validation loss: 1.484569316269249

Epoch: 6| Step: 7
Training loss: 0.05889860540628433
Validation loss: 1.4887114353077386

Epoch: 6| Step: 8
Training loss: 0.05933328717947006
Validation loss: 1.5345846542748072

Epoch: 6| Step: 9
Training loss: 0.04704958200454712
Validation loss: 1.496343187106553

Epoch: 6| Step: 10
Training loss: 0.07625733315944672
Validation loss: 1.5034889508319158

Epoch: 6| Step: 11
Training loss: 0.07488956302404404
Validation loss: 1.487829198119461

Epoch: 6| Step: 12
Training loss: 0.06986827403306961
Validation loss: 1.4855909501352618

Epoch: 6| Step: 13
Training loss: 0.13751405477523804
Validation loss: 1.510428992650842

Epoch: 639| Step: 0
Training loss: 0.060198813676834106
Validation loss: 1.5119531821179133

Epoch: 6| Step: 1
Training loss: 0.10494507849216461
Validation loss: 1.5234157628910516

Epoch: 6| Step: 2
Training loss: 0.08411848545074463
Validation loss: 1.5370005112822338

Epoch: 6| Step: 3
Training loss: 0.06990735232830048
Validation loss: 1.5418663024902344

Epoch: 6| Step: 4
Training loss: 0.08502417057752609
Validation loss: 1.5531578640783987

Epoch: 6| Step: 5
Training loss: 0.07479158043861389
Validation loss: 1.5557550819971229

Epoch: 6| Step: 6
Training loss: 0.052630797028541565
Validation loss: 1.5520519159173454

Epoch: 6| Step: 7
Training loss: 0.05904737114906311
Validation loss: 1.5676222142352854

Epoch: 6| Step: 8
Training loss: 0.06653277575969696
Validation loss: 1.5424248377482097

Epoch: 6| Step: 9
Training loss: 0.07470808923244476
Validation loss: 1.5267893742489558

Epoch: 6| Step: 10
Training loss: 0.047690145671367645
Validation loss: 1.5400230910188408

Epoch: 6| Step: 11
Training loss: 0.03557419776916504
Validation loss: 1.5613388399924002

Epoch: 6| Step: 12
Training loss: 0.05724737048149109
Validation loss: 1.5471787465515958

Epoch: 6| Step: 13
Training loss: 0.053700778633356094
Validation loss: 1.5384403313359907

Epoch: 640| Step: 0
Training loss: 0.06747990101575851
Validation loss: 1.5377334087125716

Epoch: 6| Step: 1
Training loss: 0.09193217754364014
Validation loss: 1.531321278182409

Epoch: 6| Step: 2
Training loss: 0.05010884255170822
Validation loss: 1.4997064721199773

Epoch: 6| Step: 3
Training loss: 0.07591802626848221
Validation loss: 1.4972115780717583

Epoch: 6| Step: 4
Training loss: 0.06848198175430298
Validation loss: 1.50385755877341

Epoch: 6| Step: 5
Training loss: 0.05062824860215187
Validation loss: 1.4860010108640116

Epoch: 6| Step: 6
Training loss: 0.084642693400383
Validation loss: 1.5015704054986276

Epoch: 6| Step: 7
Training loss: 0.05255638808012009
Validation loss: 1.4704601687769736

Epoch: 6| Step: 8
Training loss: 0.10542818158864975
Validation loss: 1.4826814756598523

Epoch: 6| Step: 9
Training loss: 0.07486690580844879
Validation loss: 1.4780145242650022

Epoch: 6| Step: 10
Training loss: 0.08465421944856644
Validation loss: 1.4762196412650488

Epoch: 6| Step: 11
Training loss: 0.08162535727024078
Validation loss: 1.477631147189807

Epoch: 6| Step: 12
Training loss: 0.052809588611125946
Validation loss: 1.4941316432850336

Epoch: 6| Step: 13
Training loss: 0.0630936473608017
Validation loss: 1.510423985860681

Epoch: 641| Step: 0
Training loss: 0.08455907553434372
Validation loss: 1.5281033644112207

Epoch: 6| Step: 1
Training loss: 0.049284033477306366
Validation loss: 1.55525037037429

Epoch: 6| Step: 2
Training loss: 0.09104755520820618
Validation loss: 1.5433028410839778

Epoch: 6| Step: 3
Training loss: 0.05580621957778931
Validation loss: 1.5463798956204486

Epoch: 6| Step: 4
Training loss: 0.04983789473772049
Validation loss: 1.5631350855673514

Epoch: 6| Step: 5
Training loss: 0.10583999752998352
Validation loss: 1.6078442540220035

Epoch: 6| Step: 6
Training loss: 0.05724485591053963
Validation loss: 1.533854808858646

Epoch: 6| Step: 7
Training loss: 0.10197123140096664
Validation loss: 1.5529817304303568

Epoch: 6| Step: 8
Training loss: 0.0747561901807785
Validation loss: 1.5392077827966342

Epoch: 6| Step: 9
Training loss: 0.070798359811306
Validation loss: 1.5229122946339269

Epoch: 6| Step: 10
Training loss: 0.05652247369289398
Validation loss: 1.5394518080578055

Epoch: 6| Step: 11
Training loss: 0.10463103652000427
Validation loss: 1.5176873168637675

Epoch: 6| Step: 12
Training loss: 0.14552584290504456
Validation loss: 1.4991683985597344

Epoch: 6| Step: 13
Training loss: 0.045559510588645935
Validation loss: 1.5280409679617932

Epoch: 642| Step: 0
Training loss: 0.04485253989696503
Validation loss: 1.5283152826370732

Epoch: 6| Step: 1
Training loss: 0.06642890721559525
Validation loss: 1.5170027056047994

Epoch: 6| Step: 2
Training loss: 0.08313979208469391
Validation loss: 1.5195682202616045

Epoch: 6| Step: 3
Training loss: 0.035666219890117645
Validation loss: 1.5211328947415916

Epoch: 6| Step: 4
Training loss: 0.11008639633655548
Validation loss: 1.534317155038157

Epoch: 6| Step: 5
Training loss: 0.08060313761234283
Validation loss: 1.5343787157407371

Epoch: 6| Step: 6
Training loss: 0.06621064245700836
Validation loss: 1.5353598261392245

Epoch: 6| Step: 7
Training loss: 0.10324487090110779
Validation loss: 1.555396931145781

Epoch: 6| Step: 8
Training loss: 0.10198868811130524
Validation loss: 1.5382942333016345

Epoch: 6| Step: 9
Training loss: 0.09566445648670197
Validation loss: 1.5476046698067778

Epoch: 6| Step: 10
Training loss: 0.1167670488357544
Validation loss: 1.5340967703891057

Epoch: 6| Step: 11
Training loss: 0.077488474547863
Validation loss: 1.5359342976283001

Epoch: 6| Step: 12
Training loss: 0.07268631458282471
Validation loss: 1.5120233669075915

Epoch: 6| Step: 13
Training loss: 0.08085992932319641
Validation loss: 1.5160363707491147

Epoch: 643| Step: 0
Training loss: 0.10293683409690857
Validation loss: 1.5373921548166583

Epoch: 6| Step: 1
Training loss: 0.06913140416145325
Validation loss: 1.5559912061178556

Epoch: 6| Step: 2
Training loss: 0.0761994868516922
Validation loss: 1.5589963569436023

Epoch: 6| Step: 3
Training loss: 0.08289723098278046
Validation loss: 1.5656658872481315

Epoch: 6| Step: 4
Training loss: 0.11023485660552979
Validation loss: 1.58747197094784

Epoch: 6| Step: 5
Training loss: 0.14579744637012482
Validation loss: 1.5436495991163357

Epoch: 6| Step: 6
Training loss: 0.07315701246261597
Validation loss: 1.5295349590239986

Epoch: 6| Step: 7
Training loss: 0.06500624120235443
Validation loss: 1.5391571137212938

Epoch: 6| Step: 8
Training loss: 0.0709105059504509
Validation loss: 1.460799281315137

Epoch: 6| Step: 9
Training loss: 0.06771468371152878
Validation loss: 1.5048473112044796

Epoch: 6| Step: 10
Training loss: 0.059854283928871155
Validation loss: 1.4808719542718702

Epoch: 6| Step: 11
Training loss: 0.08232688158750534
Validation loss: 1.4663002696088565

Epoch: 6| Step: 12
Training loss: 0.04546608775854111
Validation loss: 1.5038827087289544

Epoch: 6| Step: 13
Training loss: 0.1163160428404808
Validation loss: 1.504781202603412

Epoch: 644| Step: 0
Training loss: 0.08212267607450485
Validation loss: 1.5153209804206766

Epoch: 6| Step: 1
Training loss: 0.07897130399942398
Validation loss: 1.5501335385025188

Epoch: 6| Step: 2
Training loss: 0.06122896820306778
Validation loss: 1.5644996589229954

Epoch: 6| Step: 3
Training loss: 0.07852673530578613
Validation loss: 1.5854335305511311

Epoch: 6| Step: 4
Training loss: 0.07720906287431717
Validation loss: 1.5542552471160889

Epoch: 6| Step: 5
Training loss: 0.1049252301454544
Validation loss: 1.549868784924989

Epoch: 6| Step: 6
Training loss: 0.05221228301525116
Validation loss: 1.548013343605944

Epoch: 6| Step: 7
Training loss: 0.10401927679777145
Validation loss: 1.540474731435058

Epoch: 6| Step: 8
Training loss: 0.07022835314273834
Validation loss: 1.5460684818606223

Epoch: 6| Step: 9
Training loss: 0.05679479241371155
Validation loss: 1.486242219965945

Epoch: 6| Step: 10
Training loss: 0.07448248565196991
Validation loss: 1.5048109921075965

Epoch: 6| Step: 11
Training loss: 0.11185543984174728
Validation loss: 1.4895760513121081

Epoch: 6| Step: 12
Training loss: 0.062326520681381226
Validation loss: 1.4854736558852657

Epoch: 6| Step: 13
Training loss: 0.06374183297157288
Validation loss: 1.4920944449722127

Epoch: 645| Step: 0
Training loss: 0.04735855758190155
Validation loss: 1.4852512472419328

Epoch: 6| Step: 1
Training loss: 0.06257456541061401
Validation loss: 1.4965338072469156

Epoch: 6| Step: 2
Training loss: 0.0727730393409729
Validation loss: 1.5313792203062324

Epoch: 6| Step: 3
Training loss: 0.07858337461948395
Validation loss: 1.5371681285160843

Epoch: 6| Step: 4
Training loss: 0.0765165239572525
Validation loss: 1.5458010178740307

Epoch: 6| Step: 5
Training loss: 0.10581041127443314
Validation loss: 1.5476196427499094

Epoch: 6| Step: 6
Training loss: 0.05098175257444382
Validation loss: 1.543347736840607

Epoch: 6| Step: 7
Training loss: 0.05191304162144661
Validation loss: 1.5607781775536076

Epoch: 6| Step: 8
Training loss: 0.07188166677951813
Validation loss: 1.5453169493265049

Epoch: 6| Step: 9
Training loss: 0.10943879187107086
Validation loss: 1.5247202009283087

Epoch: 6| Step: 10
Training loss: 0.0878775343298912
Validation loss: 1.5415032781580442

Epoch: 6| Step: 11
Training loss: 0.05323684960603714
Validation loss: 1.5364619173029417

Epoch: 6| Step: 12
Training loss: 0.12427347898483276
Validation loss: 1.552674747282459

Epoch: 6| Step: 13
Training loss: 0.09259627759456635
Validation loss: 1.5202112556785665

Epoch: 646| Step: 0
Training loss: 0.06719484180212021
Validation loss: 1.5504008723843483

Epoch: 6| Step: 1
Training loss: 0.08758314698934555
Validation loss: 1.541883840355822

Epoch: 6| Step: 2
Training loss: 0.08369780331850052
Validation loss: 1.5276864561983334

Epoch: 6| Step: 3
Training loss: 0.09009099006652832
Validation loss: 1.52078668661015

Epoch: 6| Step: 4
Training loss: 0.07558952271938324
Validation loss: 1.5324982250890424

Epoch: 6| Step: 5
Training loss: 0.06322542577981949
Validation loss: 1.547273188508967

Epoch: 6| Step: 6
Training loss: 0.06101004034280777
Validation loss: 1.5671251999434603

Epoch: 6| Step: 7
Training loss: 0.09925609081983566
Validation loss: 1.5605733586895851

Epoch: 6| Step: 8
Training loss: 0.049599140882492065
Validation loss: 1.5533875034701439

Epoch: 6| Step: 9
Training loss: 0.056572601199150085
Validation loss: 1.5494402813655075

Epoch: 6| Step: 10
Training loss: 0.09138493239879608
Validation loss: 1.5631407544177065

Epoch: 6| Step: 11
Training loss: 0.08518581092357635
Validation loss: 1.543197593381328

Epoch: 6| Step: 12
Training loss: 0.08130067586898804
Validation loss: 1.5477421450358566

Epoch: 6| Step: 13
Training loss: 0.09254055470228195
Validation loss: 1.5607489501276324

Epoch: 647| Step: 0
Training loss: 0.05953381955623627
Validation loss: 1.5439051338421401

Epoch: 6| Step: 1
Training loss: 0.040481362491846085
Validation loss: 1.5577234132315523

Epoch: 6| Step: 2
Training loss: 0.031394340097904205
Validation loss: 1.5651784776359476

Epoch: 6| Step: 3
Training loss: 0.08475591242313385
Validation loss: 1.5500015994553924

Epoch: 6| Step: 4
Training loss: 0.10979215800762177
Validation loss: 1.5126836081986785

Epoch: 6| Step: 5
Training loss: 0.1573224663734436
Validation loss: 1.5323377642580258

Epoch: 6| Step: 6
Training loss: 0.037688955664634705
Validation loss: 1.5567946536566621

Epoch: 6| Step: 7
Training loss: 0.05823897197842598
Validation loss: 1.525032244702821

Epoch: 6| Step: 8
Training loss: 0.04662296175956726
Validation loss: 1.529497782389323

Epoch: 6| Step: 9
Training loss: 0.0630873590707779
Validation loss: 1.513402537633014

Epoch: 6| Step: 10
Training loss: 0.10728500038385391
Validation loss: 1.5453732423884894

Epoch: 6| Step: 11
Training loss: 0.049400314688682556
Validation loss: 1.5088226487559657

Epoch: 6| Step: 12
Training loss: 0.06943018734455109
Validation loss: 1.5084274327883156

Epoch: 6| Step: 13
Training loss: 0.0719795897603035
Validation loss: 1.5146536955269434

Epoch: 648| Step: 0
Training loss: 0.06805156171321869
Validation loss: 1.5022927939250905

Epoch: 6| Step: 1
Training loss: 0.04132426157593727
Validation loss: 1.5145306946128927

Epoch: 6| Step: 2
Training loss: 0.06878545135259628
Validation loss: 1.5212106140710975

Epoch: 6| Step: 3
Training loss: 0.05119670182466507
Validation loss: 1.5305106075861121

Epoch: 6| Step: 4
Training loss: 0.10492923855781555
Validation loss: 1.5021598505717453

Epoch: 6| Step: 5
Training loss: 0.07935940474271774
Validation loss: 1.5543474125605758

Epoch: 6| Step: 6
Training loss: 0.08616086840629578
Validation loss: 1.5094369611432474

Epoch: 6| Step: 7
Training loss: 0.09666258841753006
Validation loss: 1.5378882051796041

Epoch: 6| Step: 8
Training loss: 0.07599989324808121
Validation loss: 1.5075197668485745

Epoch: 6| Step: 9
Training loss: 0.08270715177059174
Validation loss: 1.4965702987486316

Epoch: 6| Step: 10
Training loss: 0.06717789173126221
Validation loss: 1.5054645205056796

Epoch: 6| Step: 11
Training loss: 0.0857934057712555
Validation loss: 1.4725688074224739

Epoch: 6| Step: 12
Training loss: 0.06772615015506744
Validation loss: 1.5062499994872718

Epoch: 6| Step: 13
Training loss: 0.05740250647068024
Validation loss: 1.480560262997945

Epoch: 649| Step: 0
Training loss: 0.06227046623826027
Validation loss: 1.4942338223098426

Epoch: 6| Step: 1
Training loss: 0.09782055020332336
Validation loss: 1.4968810350664201

Epoch: 6| Step: 2
Training loss: 0.08581488579511642
Validation loss: 1.5084024052466116

Epoch: 6| Step: 3
Training loss: 0.05689996853470802
Validation loss: 1.5307186060054327

Epoch: 6| Step: 4
Training loss: 0.0623963326215744
Validation loss: 1.5568882573035456

Epoch: 6| Step: 5
Training loss: 0.06682667136192322
Validation loss: 1.5563669006029766

Epoch: 6| Step: 6
Training loss: 0.05996443331241608
Validation loss: 1.56471158612159

Epoch: 6| Step: 7
Training loss: 0.07796226441860199
Validation loss: 1.5870096145137664

Epoch: 6| Step: 8
Training loss: 0.09644997119903564
Validation loss: 1.5722155596620293

Epoch: 6| Step: 9
Training loss: 0.07164211571216583
Validation loss: 1.5704796134784658

Epoch: 6| Step: 10
Training loss: 0.06742268800735474
Validation loss: 1.5472727193627307

Epoch: 6| Step: 11
Training loss: 0.0910058468580246
Validation loss: 1.5750475442537697

Epoch: 6| Step: 12
Training loss: 0.07919342070817947
Validation loss: 1.5466139355013448

Epoch: 6| Step: 13
Training loss: 0.061961736530065536
Validation loss: 1.5336535976779075

Epoch: 650| Step: 0
Training loss: 0.10538466274738312
Validation loss: 1.5412698477827094

Epoch: 6| Step: 1
Training loss: 0.07656297087669373
Validation loss: 1.5239428397147887

Epoch: 6| Step: 2
Training loss: 0.09207379072904587
Validation loss: 1.5229234464706913

Epoch: 6| Step: 3
Training loss: 0.1094188466668129
Validation loss: 1.5409883940091698

Epoch: 6| Step: 4
Training loss: 0.09552021324634552
Validation loss: 1.4915441889916696

Epoch: 6| Step: 5
Training loss: 0.06419672816991806
Validation loss: 1.5126817123864287

Epoch: 6| Step: 6
Training loss: 0.037955015897750854
Validation loss: 1.515413199701617

Epoch: 6| Step: 7
Training loss: 0.04429095983505249
Validation loss: 1.527762427124926

Epoch: 6| Step: 8
Training loss: 0.03394431620836258
Validation loss: 1.4976798513884186

Epoch: 6| Step: 9
Training loss: 0.10158033668994904
Validation loss: 1.4909970016889675

Epoch: 6| Step: 10
Training loss: 0.08396051824092865
Validation loss: 1.5075983988341464

Epoch: 6| Step: 11
Training loss: 0.05662823095917702
Validation loss: 1.513823724562122

Epoch: 6| Step: 12
Training loss: 0.0581974983215332
Validation loss: 1.4789977124942246

Epoch: 6| Step: 13
Training loss: 0.02619471773505211
Validation loss: 1.5149352447960966

Epoch: 651| Step: 0
Training loss: 0.04804959520697594
Validation loss: 1.489223717361368

Epoch: 6| Step: 1
Training loss: 0.05010951682925224
Validation loss: 1.4921869718900291

Epoch: 6| Step: 2
Training loss: 0.06566494703292847
Validation loss: 1.5156169335047405

Epoch: 6| Step: 3
Training loss: 0.07839614897966385
Validation loss: 1.5144717770238076

Epoch: 6| Step: 4
Training loss: 0.06128455698490143
Validation loss: 1.4889805720698448

Epoch: 6| Step: 5
Training loss: 0.0639248862862587
Validation loss: 1.4906275131369149

Epoch: 6| Step: 6
Training loss: 0.07806330919265747
Validation loss: 1.5039730200203516

Epoch: 6| Step: 7
Training loss: 0.06535761058330536
Validation loss: 1.5316710087560839

Epoch: 6| Step: 8
Training loss: 0.07830134779214859
Validation loss: 1.536311928303011

Epoch: 6| Step: 9
Training loss: 0.10934367775917053
Validation loss: 1.5173541397176764

Epoch: 6| Step: 10
Training loss: 0.06028752028942108
Validation loss: 1.5421946074372979

Epoch: 6| Step: 11
Training loss: 0.06113775074481964
Validation loss: 1.5339874516251266

Epoch: 6| Step: 12
Training loss: 0.0600028932094574
Validation loss: 1.5311829159336705

Epoch: 6| Step: 13
Training loss: 0.04737494885921478
Validation loss: 1.556023101652822

Epoch: 652| Step: 0
Training loss: 0.06758518517017365
Validation loss: 1.5604193633602512

Epoch: 6| Step: 1
Training loss: 0.07884878665208817
Validation loss: 1.5669325936225154

Epoch: 6| Step: 2
Training loss: 0.08345934003591537
Validation loss: 1.5529507296059721

Epoch: 6| Step: 3
Training loss: 0.07321205735206604
Validation loss: 1.5628126885301323

Epoch: 6| Step: 4
Training loss: 0.03976666182279587
Validation loss: 1.5391565599749166

Epoch: 6| Step: 5
Training loss: 0.051319416612386703
Validation loss: 1.550146190069055

Epoch: 6| Step: 6
Training loss: 0.10954206436872482
Validation loss: 1.542865409645983

Epoch: 6| Step: 7
Training loss: 0.06574562937021255
Validation loss: 1.5527766981432516

Epoch: 6| Step: 8
Training loss: 0.046016670763492584
Validation loss: 1.5542125291721796

Epoch: 6| Step: 9
Training loss: 0.04274603724479675
Validation loss: 1.5372556114709506

Epoch: 6| Step: 10
Training loss: 0.08721116185188293
Validation loss: 1.557323113564522

Epoch: 6| Step: 11
Training loss: 0.04794134199619293
Validation loss: 1.572507648057835

Epoch: 6| Step: 12
Training loss: 0.07403136789798737
Validation loss: 1.5380645298188733

Epoch: 6| Step: 13
Training loss: 0.04639464244246483
Validation loss: 1.5510062017748434

Epoch: 653| Step: 0
Training loss: 0.0647888258099556
Validation loss: 1.5535880211860902

Epoch: 6| Step: 1
Training loss: 0.06879585981369019
Validation loss: 1.5549261159794305

Epoch: 6| Step: 2
Training loss: 0.08015672862529755
Validation loss: 1.5410677233049948

Epoch: 6| Step: 3
Training loss: 0.05339384824037552
Validation loss: 1.5478088471197313

Epoch: 6| Step: 4
Training loss: 0.05184624716639519
Validation loss: 1.5698305291514243

Epoch: 6| Step: 5
Training loss: 0.10099947452545166
Validation loss: 1.523438653638286

Epoch: 6| Step: 6
Training loss: 0.0806611031293869
Validation loss: 1.5320898140630415

Epoch: 6| Step: 7
Training loss: 0.052149005234241486
Validation loss: 1.5759872287832282

Epoch: 6| Step: 8
Training loss: 0.07370845973491669
Validation loss: 1.5461909860693

Epoch: 6| Step: 9
Training loss: 0.09438443183898926
Validation loss: 1.5542481753133959

Epoch: 6| Step: 10
Training loss: 0.08221694827079773
Validation loss: 1.5518521390935427

Epoch: 6| Step: 11
Training loss: 0.030001498758792877
Validation loss: 1.5526113228131366

Epoch: 6| Step: 12
Training loss: 0.04183262586593628
Validation loss: 1.5531828839291808

Epoch: 6| Step: 13
Training loss: 0.09874740242958069
Validation loss: 1.567903027739576

Epoch: 654| Step: 0
Training loss: 0.11460171639919281
Validation loss: 1.5820674063057028

Epoch: 6| Step: 1
Training loss: 0.07551144063472748
Validation loss: 1.5730059275063135

Epoch: 6| Step: 2
Training loss: 0.09605202078819275
Validation loss: 1.6035881093753281

Epoch: 6| Step: 3
Training loss: 0.09314711391925812
Validation loss: 1.559738254034391

Epoch: 6| Step: 4
Training loss: 0.061941150575876236
Validation loss: 1.5622982132819392

Epoch: 6| Step: 5
Training loss: 0.07221470028162003
Validation loss: 1.5425669557304793

Epoch: 6| Step: 6
Training loss: 0.0752703994512558
Validation loss: 1.5252700467263498

Epoch: 6| Step: 7
Training loss: 0.05977530777454376
Validation loss: 1.5223343833800285

Epoch: 6| Step: 8
Training loss: 0.05549190938472748
Validation loss: 1.5184748679079034

Epoch: 6| Step: 9
Training loss: 0.0543554350733757
Validation loss: 1.49395534171853

Epoch: 6| Step: 10
Training loss: 0.06961332261562347
Validation loss: 1.511675662891839

Epoch: 6| Step: 11
Training loss: 0.06756527721881866
Validation loss: 1.5087870679875857

Epoch: 6| Step: 12
Training loss: 0.06212800741195679
Validation loss: 1.5224345858379076

Epoch: 6| Step: 13
Training loss: 0.06471525132656097
Validation loss: 1.523814787787776

Epoch: 655| Step: 0
Training loss: 0.08282031118869781
Validation loss: 1.5225158320960177

Epoch: 6| Step: 1
Training loss: 0.06600260734558105
Validation loss: 1.5231207647631246

Epoch: 6| Step: 2
Training loss: 0.041704244911670685
Validation loss: 1.540432886410785

Epoch: 6| Step: 3
Training loss: 0.07247643172740936
Validation loss: 1.5146276797017744

Epoch: 6| Step: 4
Training loss: 0.0782531276345253
Validation loss: 1.5233085950215657

Epoch: 6| Step: 5
Training loss: 0.08447813242673874
Validation loss: 1.529865885293612

Epoch: 6| Step: 6
Training loss: 0.05139726400375366
Validation loss: 1.5357031847840996

Epoch: 6| Step: 7
Training loss: 0.08570162951946259
Validation loss: 1.529834376227471

Epoch: 6| Step: 8
Training loss: 0.10012742131948471
Validation loss: 1.498735390042746

Epoch: 6| Step: 9
Training loss: 0.08170852810144424
Validation loss: 1.5362109907211796

Epoch: 6| Step: 10
Training loss: 0.06287118047475815
Validation loss: 1.5562022527058919

Epoch: 6| Step: 11
Training loss: 0.04557114467024803
Validation loss: 1.5523432582937262

Epoch: 6| Step: 12
Training loss: 0.04961809515953064
Validation loss: 1.5415719491179272

Epoch: 6| Step: 13
Training loss: 0.08880048990249634
Validation loss: 1.590992755787347

Epoch: 656| Step: 0
Training loss: 0.04123305901885033
Validation loss: 1.5624167226975965

Epoch: 6| Step: 1
Training loss: 0.040143467485904694
Validation loss: 1.5962046615539058

Epoch: 6| Step: 2
Training loss: 0.06800796091556549
Validation loss: 1.5332347423799577

Epoch: 6| Step: 3
Training loss: 0.12007388472557068
Validation loss: 1.564552657065853

Epoch: 6| Step: 4
Training loss: 0.06016465276479721
Validation loss: 1.5742565066583696

Epoch: 6| Step: 5
Training loss: 0.034540023654699326
Validation loss: 1.5703124833363358

Epoch: 6| Step: 6
Training loss: 0.08216088265180588
Validation loss: 1.5706542166330482

Epoch: 6| Step: 7
Training loss: 0.04741609841585159
Validation loss: 1.5819140121500979

Epoch: 6| Step: 8
Training loss: 0.09762218594551086
Validation loss: 1.5887959336721769

Epoch: 6| Step: 9
Training loss: 0.09128264337778091
Validation loss: 1.5618064031806043

Epoch: 6| Step: 10
Training loss: 0.051148753613233566
Validation loss: 1.556143194116572

Epoch: 6| Step: 11
Training loss: 0.07261986285448074
Validation loss: 1.5523660516226163

Epoch: 6| Step: 12
Training loss: 0.07069820165634155
Validation loss: 1.5456022267700524

Epoch: 6| Step: 13
Training loss: 0.07633685320615768
Validation loss: 1.5135375748398483

Epoch: 657| Step: 0
Training loss: 0.08990607410669327
Validation loss: 1.5097677605126494

Epoch: 6| Step: 1
Training loss: 0.051538627594709396
Validation loss: 1.5493161985951085

Epoch: 6| Step: 2
Training loss: 0.06862962245941162
Validation loss: 1.5572348820265902

Epoch: 6| Step: 3
Training loss: 0.050260793417692184
Validation loss: 1.5530820046701739

Epoch: 6| Step: 4
Training loss: 0.1076916977763176
Validation loss: 1.5526829560597737

Epoch: 6| Step: 5
Training loss: 0.08138735592365265
Validation loss: 1.5476165657402368

Epoch: 6| Step: 6
Training loss: 0.061344027519226074
Validation loss: 1.5454740267927929

Epoch: 6| Step: 7
Training loss: 0.03055482730269432
Validation loss: 1.5432273546854656

Epoch: 6| Step: 8
Training loss: 0.04945832118391991
Validation loss: 1.5590645574754285

Epoch: 6| Step: 9
Training loss: 0.03603336960077286
Validation loss: 1.54281279348558

Epoch: 6| Step: 10
Training loss: 0.0731811597943306
Validation loss: 1.5597281276538808

Epoch: 6| Step: 11
Training loss: 0.05812466889619827
Validation loss: 1.586010544530807

Epoch: 6| Step: 12
Training loss: 0.09324675798416138
Validation loss: 1.5438737394989177

Epoch: 6| Step: 13
Training loss: 0.04718466103076935
Validation loss: 1.5520996598787205

Epoch: 658| Step: 0
Training loss: 0.13865604996681213
Validation loss: 1.5358755524440477

Epoch: 6| Step: 1
Training loss: 0.09772606194019318
Validation loss: 1.5202974478403728

Epoch: 6| Step: 2
Training loss: 0.11457334458827972
Validation loss: 1.5136087248402257

Epoch: 6| Step: 3
Training loss: 0.09867213666439056
Validation loss: 1.4928024238155735

Epoch: 6| Step: 4
Training loss: 0.09075770527124405
Validation loss: 1.483880110966262

Epoch: 6| Step: 5
Training loss: 0.07764998078346252
Validation loss: 1.5092355781985867

Epoch: 6| Step: 6
Training loss: 0.11114728450775146
Validation loss: 1.517012132111416

Epoch: 6| Step: 7
Training loss: 0.18848952651023865
Validation loss: 1.488190112575408

Epoch: 6| Step: 8
Training loss: 0.05363354831933975
Validation loss: 1.4926024765096686

Epoch: 6| Step: 9
Training loss: 0.05286193639039993
Validation loss: 1.4870049427914362

Epoch: 6| Step: 10
Training loss: 0.11704131960868835
Validation loss: 1.5249347635494765

Epoch: 6| Step: 11
Training loss: 0.10966507345438004
Validation loss: 1.5282596708625875

Epoch: 6| Step: 12
Training loss: 0.0781751200556755
Validation loss: 1.5278155290952293

Epoch: 6| Step: 13
Training loss: 0.07397130131721497
Validation loss: 1.5468473921539962

Epoch: 659| Step: 0
Training loss: 0.1868475377559662
Validation loss: 1.523919387530255

Epoch: 6| Step: 1
Training loss: 0.05830245092511177
Validation loss: 1.5482870199347054

Epoch: 6| Step: 2
Training loss: 0.0597972497344017
Validation loss: 1.546708978632445

Epoch: 6| Step: 3
Training loss: 0.05511154979467392
Validation loss: 1.5028013990771385

Epoch: 6| Step: 4
Training loss: 0.07475792616605759
Validation loss: 1.492382320024634

Epoch: 6| Step: 5
Training loss: 0.08617641776800156
Validation loss: 1.500158517591415

Epoch: 6| Step: 6
Training loss: 0.06984449177980423
Validation loss: 1.5024310517054733

Epoch: 6| Step: 7
Training loss: 0.13176749646663666
Validation loss: 1.5256358833723171

Epoch: 6| Step: 8
Training loss: 0.1523711085319519
Validation loss: 1.5187573650831818

Epoch: 6| Step: 9
Training loss: 0.11529755592346191
Validation loss: 1.502590266607141

Epoch: 6| Step: 10
Training loss: 0.06549453735351562
Validation loss: 1.5038089553515117

Epoch: 6| Step: 11
Training loss: 0.08244718611240387
Validation loss: 1.4900449488752632

Epoch: 6| Step: 12
Training loss: 0.1286221444606781
Validation loss: 1.520156139968544

Epoch: 6| Step: 13
Training loss: 0.1070590689778328
Validation loss: 1.5043426918727096

Epoch: 660| Step: 0
Training loss: 0.1250855177640915
Validation loss: 1.52628880546939

Epoch: 6| Step: 1
Training loss: 0.07934224605560303
Validation loss: 1.5428106848911574

Epoch: 6| Step: 2
Training loss: 0.1340038776397705
Validation loss: 1.5536820016881472

Epoch: 6| Step: 3
Training loss: 0.07818230986595154
Validation loss: 1.5768988491386495

Epoch: 6| Step: 4
Training loss: 0.11367858946323395
Validation loss: 1.532948072238635

Epoch: 6| Step: 5
Training loss: 0.03871525824069977
Validation loss: 1.5110552874944543

Epoch: 6| Step: 6
Training loss: 0.035571128129959106
Validation loss: 1.5244761077306603

Epoch: 6| Step: 7
Training loss: 0.1353793442249298
Validation loss: 1.5106915940520584

Epoch: 6| Step: 8
Training loss: 0.06334856897592545
Validation loss: 1.5075351012650358

Epoch: 6| Step: 9
Training loss: 0.10186176747083664
Validation loss: 1.5093173070620465

Epoch: 6| Step: 10
Training loss: 0.08576031029224396
Validation loss: 1.5157385615892307

Epoch: 6| Step: 11
Training loss: 0.0910705029964447
Validation loss: 1.532206654548645

Epoch: 6| Step: 12
Training loss: 0.11402368545532227
Validation loss: 1.5282575276590162

Epoch: 6| Step: 13
Training loss: 0.051039088517427444
Validation loss: 1.5348166214522494

Epoch: 661| Step: 0
Training loss: 0.07964988052845001
Validation loss: 1.5564414685772312

Epoch: 6| Step: 1
Training loss: 0.0945960283279419
Validation loss: 1.5548373870952155

Epoch: 6| Step: 2
Training loss: 0.06144660338759422
Validation loss: 1.5676930001986924

Epoch: 6| Step: 3
Training loss: 0.11422619968652725
Validation loss: 1.5497950597475934

Epoch: 6| Step: 4
Training loss: 0.06269039213657379
Validation loss: 1.5393744822471374

Epoch: 6| Step: 5
Training loss: 0.05363444983959198
Validation loss: 1.5260578291390532

Epoch: 6| Step: 6
Training loss: 0.061648402363061905
Validation loss: 1.5447202805549867

Epoch: 6| Step: 7
Training loss: 0.0597030445933342
Validation loss: 1.513002921176213

Epoch: 6| Step: 8
Training loss: 0.05742182582616806
Validation loss: 1.5228308003435853

Epoch: 6| Step: 9
Training loss: 0.09437926113605499
Validation loss: 1.5048333162902503

Epoch: 6| Step: 10
Training loss: 0.1508958637714386
Validation loss: 1.5106897020852694

Epoch: 6| Step: 11
Training loss: 0.09241118282079697
Validation loss: 1.5384332197968678

Epoch: 6| Step: 12
Training loss: 0.14242398738861084
Validation loss: 1.5299494894601966

Epoch: 6| Step: 13
Training loss: 0.0696694552898407
Validation loss: 1.559443086706182

Epoch: 662| Step: 0
Training loss: 0.05590376257896423
Validation loss: 1.5614684166446808

Epoch: 6| Step: 1
Training loss: 0.08477215468883514
Validation loss: 1.562966105758503

Epoch: 6| Step: 2
Training loss: 0.08571277558803558
Validation loss: 1.5598862209627706

Epoch: 6| Step: 3
Training loss: 0.06546003371477127
Validation loss: 1.5727495551109314

Epoch: 6| Step: 4
Training loss: 0.09322579205036163
Validation loss: 1.5796263423017276

Epoch: 6| Step: 5
Training loss: 0.10139696300029755
Validation loss: 1.5915034163382746

Epoch: 6| Step: 6
Training loss: 0.04950433224439621
Validation loss: 1.5846872175893476

Epoch: 6| Step: 7
Training loss: 0.08029896020889282
Validation loss: 1.5661427308154363

Epoch: 6| Step: 8
Training loss: 0.04618614912033081
Validation loss: 1.5376157568347069

Epoch: 6| Step: 9
Training loss: 0.07165949791669846
Validation loss: 1.5463032004653767

Epoch: 6| Step: 10
Training loss: 0.06174971163272858
Validation loss: 1.5199308856841056

Epoch: 6| Step: 11
Training loss: 0.14304417371749878
Validation loss: 1.486585593992664

Epoch: 6| Step: 12
Training loss: 0.10936867445707321
Validation loss: 1.5237392469119

Epoch: 6| Step: 13
Training loss: 0.08090119808912277
Validation loss: 1.4911711626155402

Epoch: 663| Step: 0
Training loss: 0.08880442380905151
Validation loss: 1.4887960764669603

Epoch: 6| Step: 1
Training loss: 0.07861444354057312
Validation loss: 1.5126529816658265

Epoch: 6| Step: 2
Training loss: 0.10066375136375427
Validation loss: 1.5270509168665896

Epoch: 6| Step: 3
Training loss: 0.09148696064949036
Validation loss: 1.5369722099714382

Epoch: 6| Step: 4
Training loss: 0.09215779602527618
Validation loss: 1.5153105771669777

Epoch: 6| Step: 5
Training loss: 0.059183403849601746
Validation loss: 1.521673205078289

Epoch: 6| Step: 6
Training loss: 0.09390988945960999
Validation loss: 1.5035435461228894

Epoch: 6| Step: 7
Training loss: 0.036942608654499054
Validation loss: 1.5227768831355597

Epoch: 6| Step: 8
Training loss: 0.1015404760837555
Validation loss: 1.5268246986532723

Epoch: 6| Step: 9
Training loss: 0.058417387306690216
Validation loss: 1.5366839337092575

Epoch: 6| Step: 10
Training loss: 0.10388488322496414
Validation loss: 1.537983243183423

Epoch: 6| Step: 11
Training loss: 0.08452126383781433
Validation loss: 1.5543483405984857

Epoch: 6| Step: 12
Training loss: 0.13536489009857178
Validation loss: 1.5721410782106462

Epoch: 6| Step: 13
Training loss: 0.053357720375061035
Validation loss: 1.5685061344536402

Epoch: 664| Step: 0
Training loss: 0.08690305054187775
Validation loss: 1.5204114522985233

Epoch: 6| Step: 1
Training loss: 0.09348016232252121
Validation loss: 1.5055959340064757

Epoch: 6| Step: 2
Training loss: 0.04744141176342964
Validation loss: 1.5428563766582037

Epoch: 6| Step: 3
Training loss: 0.07729136943817139
Validation loss: 1.5332976336120276

Epoch: 6| Step: 4
Training loss: 0.06965486705303192
Validation loss: 1.5538275062396962

Epoch: 6| Step: 5
Training loss: 0.11707885563373566
Validation loss: 1.5458127349935553

Epoch: 6| Step: 6
Training loss: 0.07171440124511719
Validation loss: 1.5451542703054284

Epoch: 6| Step: 7
Training loss: 0.07831018418073654
Validation loss: 1.5438043571287585

Epoch: 6| Step: 8
Training loss: 0.04453257471323013
Validation loss: 1.5424151305229432

Epoch: 6| Step: 9
Training loss: 0.06290939450263977
Validation loss: 1.5627905245750182

Epoch: 6| Step: 10
Training loss: 0.09537799656391144
Validation loss: 1.5377884487951956

Epoch: 6| Step: 11
Training loss: 0.08443017303943634
Validation loss: 1.5453620802971624

Epoch: 6| Step: 12
Training loss: 0.05462824925780296
Validation loss: 1.5127677686752812

Epoch: 6| Step: 13
Training loss: 0.061263322830200195
Validation loss: 1.5168271987668929

Epoch: 665| Step: 0
Training loss: 0.1136770248413086
Validation loss: 1.5110622964879519

Epoch: 6| Step: 1
Training loss: 0.055692464113235474
Validation loss: 1.5290493426784393

Epoch: 6| Step: 2
Training loss: 0.09369553625583649
Validation loss: 1.5443134653952815

Epoch: 6| Step: 3
Training loss: 0.06413890421390533
Validation loss: 1.5358275367367653

Epoch: 6| Step: 4
Training loss: 0.07198375463485718
Validation loss: 1.531740468035462

Epoch: 6| Step: 5
Training loss: 0.07103265821933746
Validation loss: 1.52057029995867

Epoch: 6| Step: 6
Training loss: 0.04066718369722366
Validation loss: 1.5308091528313135

Epoch: 6| Step: 7
Training loss: 0.04262145608663559
Validation loss: 1.5395903766796153

Epoch: 6| Step: 8
Training loss: 0.07101170718669891
Validation loss: 1.5443826631833149

Epoch: 6| Step: 9
Training loss: 0.05938161909580231
Validation loss: 1.5656872962110786

Epoch: 6| Step: 10
Training loss: 0.0420791432261467
Validation loss: 1.5306005375359648

Epoch: 6| Step: 11
Training loss: 0.06684400141239166
Validation loss: 1.5394117947547667

Epoch: 6| Step: 12
Training loss: 0.05636119470000267
Validation loss: 1.5065879841004648

Epoch: 6| Step: 13
Training loss: 0.05272606387734413
Validation loss: 1.511707257199031

Epoch: 666| Step: 0
Training loss: 0.08102552592754364
Validation loss: 1.4958679432510047

Epoch: 6| Step: 1
Training loss: 0.04893992096185684
Validation loss: 1.4778888610101515

Epoch: 6| Step: 2
Training loss: 0.07623331248760223
Validation loss: 1.5254845426928612

Epoch: 6| Step: 3
Training loss: 0.05421050637960434
Validation loss: 1.5189907755903018

Epoch: 6| Step: 4
Training loss: 0.056270532310009
Validation loss: 1.5319309414073985

Epoch: 6| Step: 5
Training loss: 0.08355528116226196
Validation loss: 1.528427662387971

Epoch: 6| Step: 6
Training loss: 0.07686908543109894
Validation loss: 1.5289488120745587

Epoch: 6| Step: 7
Training loss: 0.06560651957988739
Validation loss: 1.5275322057867562

Epoch: 6| Step: 8
Training loss: 0.07233434915542603
Validation loss: 1.5333509778463712

Epoch: 6| Step: 9
Training loss: 0.08786685764789581
Validation loss: 1.5301182487959504

Epoch: 6| Step: 10
Training loss: 0.05291016772389412
Validation loss: 1.509498614777801

Epoch: 6| Step: 11
Training loss: 0.05495908856391907
Validation loss: 1.5072711052433136

Epoch: 6| Step: 12
Training loss: 0.04628204554319382
Validation loss: 1.5060460823838429

Epoch: 6| Step: 13
Training loss: 0.10771626979112625
Validation loss: 1.5098123909324728

Epoch: 667| Step: 0
Training loss: 0.09703518450260162
Validation loss: 1.4918503838200723

Epoch: 6| Step: 1
Training loss: 0.07273608446121216
Validation loss: 1.507955994657291

Epoch: 6| Step: 2
Training loss: 0.07949689775705338
Validation loss: 1.5025702106055392

Epoch: 6| Step: 3
Training loss: 0.10355453938245773
Validation loss: 1.4890178172819075

Epoch: 6| Step: 4
Training loss: 0.07836601138114929
Validation loss: 1.5168125020560397

Epoch: 6| Step: 5
Training loss: 0.061462417244911194
Validation loss: 1.5314096302114508

Epoch: 6| Step: 6
Training loss: 0.1052890494465828
Validation loss: 1.5623910350184287

Epoch: 6| Step: 7
Training loss: 0.06571831554174423
Validation loss: 1.5785651283879434

Epoch: 6| Step: 8
Training loss: 0.06553766131401062
Validation loss: 1.5780418771569447

Epoch: 6| Step: 9
Training loss: 0.051357924938201904
Validation loss: 1.5867630704756706

Epoch: 6| Step: 10
Training loss: 0.07155248522758484
Validation loss: 1.592499771425801

Epoch: 6| Step: 11
Training loss: 0.06913822889328003
Validation loss: 1.5920830439495783

Epoch: 6| Step: 12
Training loss: 0.055933039635419846
Validation loss: 1.5743095285149031

Epoch: 6| Step: 13
Training loss: 0.10215477645397186
Validation loss: 1.5573453980107461

Epoch: 668| Step: 0
Training loss: 0.0631246417760849
Validation loss: 1.5541548613579041

Epoch: 6| Step: 1
Training loss: 0.0790475606918335
Validation loss: 1.5761345765923942

Epoch: 6| Step: 2
Training loss: 0.05702966824173927
Validation loss: 1.5483272485835577

Epoch: 6| Step: 3
Training loss: 0.05934415012598038
Validation loss: 1.5680396428672216

Epoch: 6| Step: 4
Training loss: 0.07850019633769989
Validation loss: 1.5775979398399271

Epoch: 6| Step: 5
Training loss: 0.09512022882699966
Validation loss: 1.5710628724867297

Epoch: 6| Step: 6
Training loss: 0.05585746467113495
Validation loss: 1.5883399382714303

Epoch: 6| Step: 7
Training loss: 0.06289657950401306
Validation loss: 1.572495710465216

Epoch: 6| Step: 8
Training loss: 0.04056214541196823
Validation loss: 1.5589244468237764

Epoch: 6| Step: 9
Training loss: 0.04340571165084839
Validation loss: 1.554716548612041

Epoch: 6| Step: 10
Training loss: 0.049339018762111664
Validation loss: 1.5333468619213309

Epoch: 6| Step: 11
Training loss: 0.026711666956543922
Validation loss: 1.533941004865913

Epoch: 6| Step: 12
Training loss: 0.05297745019197464
Validation loss: 1.531281494325207

Epoch: 6| Step: 13
Training loss: 0.07024187594652176
Validation loss: 1.5412126741101664

Epoch: 669| Step: 0
Training loss: 0.05815555900335312
Validation loss: 1.5708979868119763

Epoch: 6| Step: 1
Training loss: 0.05357423797249794
Validation loss: 1.5599232899245394

Epoch: 6| Step: 2
Training loss: 0.1038430780172348
Validation loss: 1.5485680282756846

Epoch: 6| Step: 3
Training loss: 0.03176872059702873
Validation loss: 1.5619079605225594

Epoch: 6| Step: 4
Training loss: 0.12024864554405212
Validation loss: 1.5363127057270338

Epoch: 6| Step: 5
Training loss: 0.10391762107610703
Validation loss: 1.5388563948292886

Epoch: 6| Step: 6
Training loss: 0.07670131325721741
Validation loss: 1.5375102796862203

Epoch: 6| Step: 7
Training loss: 0.05245067551732063
Validation loss: 1.5656863771459109

Epoch: 6| Step: 8
Training loss: 0.08670535683631897
Validation loss: 1.5138340739793674

Epoch: 6| Step: 9
Training loss: 0.0466521680355072
Validation loss: 1.5557315362397062

Epoch: 6| Step: 10
Training loss: 0.04741537943482399
Validation loss: 1.512902489272497

Epoch: 6| Step: 11
Training loss: 0.08980683237314224
Validation loss: 1.5132642548571351

Epoch: 6| Step: 12
Training loss: 0.0772457867860794
Validation loss: 1.5201025585974417

Epoch: 6| Step: 13
Training loss: 0.09008639305830002
Validation loss: 1.5261478193344609

Epoch: 670| Step: 0
Training loss: 0.057800374925136566
Validation loss: 1.5276249083139564

Epoch: 6| Step: 1
Training loss: 0.11527583003044128
Validation loss: 1.5005414844841085

Epoch: 6| Step: 2
Training loss: 0.059323959052562714
Validation loss: 1.5274873837347953

Epoch: 6| Step: 3
Training loss: 0.05696878582239151
Validation loss: 1.5260308775850522

Epoch: 6| Step: 4
Training loss: 0.05172460526227951
Validation loss: 1.5191549152456305

Epoch: 6| Step: 5
Training loss: 0.10062740743160248
Validation loss: 1.5386565641690326

Epoch: 6| Step: 6
Training loss: 0.07438813894987106
Validation loss: 1.536320064657478

Epoch: 6| Step: 7
Training loss: 0.06256549060344696
Validation loss: 1.5139664667908863

Epoch: 6| Step: 8
Training loss: 0.12203439325094223
Validation loss: 1.5423102789027716

Epoch: 6| Step: 9
Training loss: 0.04408488795161247
Validation loss: 1.5522670899668047

Epoch: 6| Step: 10
Training loss: 0.03902040794491768
Validation loss: 1.563274924473096

Epoch: 6| Step: 11
Training loss: 0.11095194518566132
Validation loss: 1.573001580853616

Epoch: 6| Step: 12
Training loss: 0.06512647867202759
Validation loss: 1.5874544766641432

Epoch: 6| Step: 13
Training loss: 0.017509792000055313
Validation loss: 1.5867459261289207

Epoch: 671| Step: 0
Training loss: 0.05552837997674942
Validation loss: 1.5982689998483146

Epoch: 6| Step: 1
Training loss: 0.06574980914592743
Validation loss: 1.60486094028719

Epoch: 6| Step: 2
Training loss: 0.10052919387817383
Validation loss: 1.6306108787495603

Epoch: 6| Step: 3
Training loss: 0.05811724066734314
Validation loss: 1.6203218621592368

Epoch: 6| Step: 4
Training loss: 0.06926582753658295
Validation loss: 1.6125166416168213

Epoch: 6| Step: 5
Training loss: 0.06824532151222229
Validation loss: 1.606136247675906

Epoch: 6| Step: 6
Training loss: 0.08050017058849335
Validation loss: 1.5951041957383514

Epoch: 6| Step: 7
Training loss: 0.08142971992492676
Validation loss: 1.556077564916303

Epoch: 6| Step: 8
Training loss: 0.045008786022663116
Validation loss: 1.5842878472420476

Epoch: 6| Step: 9
Training loss: 0.0831962525844574
Validation loss: 1.5814477423185944

Epoch: 6| Step: 10
Training loss: 0.04777950793504715
Validation loss: 1.5628720880836569

Epoch: 6| Step: 11
Training loss: 0.07083044946193695
Validation loss: 1.5808822134489655

Epoch: 6| Step: 12
Training loss: 0.06973253935575485
Validation loss: 1.5411038796106975

Epoch: 6| Step: 13
Training loss: 0.037666600197553635
Validation loss: 1.5438434680302937

Epoch: 672| Step: 0
Training loss: 0.06909172981977463
Validation loss: 1.5476815982531476

Epoch: 6| Step: 1
Training loss: 0.09063145518302917
Validation loss: 1.5562877001300934

Epoch: 6| Step: 2
Training loss: 0.05157520994544029
Validation loss: 1.562912989688176

Epoch: 6| Step: 3
Training loss: 0.061068445444107056
Validation loss: 1.5602267660120481

Epoch: 6| Step: 4
Training loss: 0.03236383944749832
Validation loss: 1.5597829382906678

Epoch: 6| Step: 5
Training loss: 0.03263820707798004
Validation loss: 1.5496732829719462

Epoch: 6| Step: 6
Training loss: 0.0896478071808815
Validation loss: 1.542700945690114

Epoch: 6| Step: 7
Training loss: 0.05403730273246765
Validation loss: 1.5346981363911782

Epoch: 6| Step: 8
Training loss: 0.07891015708446503
Validation loss: 1.5449049075444539

Epoch: 6| Step: 9
Training loss: 0.06311260163784027
Validation loss: 1.5368264977649977

Epoch: 6| Step: 10
Training loss: 0.048882126808166504
Validation loss: 1.5127420527960664

Epoch: 6| Step: 11
Training loss: 0.045739032328128815
Validation loss: 1.494620503917817

Epoch: 6| Step: 12
Training loss: 0.08090765029191971
Validation loss: 1.512074972993584

Epoch: 6| Step: 13
Training loss: 0.04020443186163902
Validation loss: 1.4862991494517173

Epoch: 673| Step: 0
Training loss: 0.08728218823671341
Validation loss: 1.5028272162201584

Epoch: 6| Step: 1
Training loss: 0.07586874067783356
Validation loss: 1.4836525814507597

Epoch: 6| Step: 2
Training loss: 0.05144928768277168
Validation loss: 1.4872494352761136

Epoch: 6| Step: 3
Training loss: 0.06242121756076813
Validation loss: 1.4893510046825613

Epoch: 6| Step: 4
Training loss: 0.11971010267734528
Validation loss: 1.4948689463318034

Epoch: 6| Step: 5
Training loss: 0.09560522437095642
Validation loss: 1.498205206727469

Epoch: 6| Step: 6
Training loss: 0.0636572316288948
Validation loss: 1.5313106724011

Epoch: 6| Step: 7
Training loss: 0.08295030146837234
Validation loss: 1.5420819463268403

Epoch: 6| Step: 8
Training loss: 0.0693768709897995
Validation loss: 1.569436147648801

Epoch: 6| Step: 9
Training loss: 0.1018831729888916
Validation loss: 1.569028728751726

Epoch: 6| Step: 10
Training loss: 0.08690355718135834
Validation loss: 1.5752929308081185

Epoch: 6| Step: 11
Training loss: 0.08812970668077469
Validation loss: 1.5909298645552767

Epoch: 6| Step: 12
Training loss: 0.05760188400745392
Validation loss: 1.6024092243563743

Epoch: 6| Step: 13
Training loss: 0.03622330725193024
Validation loss: 1.5943432084975704

Epoch: 674| Step: 0
Training loss: 0.050024088472127914
Validation loss: 1.5703398566092215

Epoch: 6| Step: 1
Training loss: 0.06574950367212296
Validation loss: 1.5579746436047297

Epoch: 6| Step: 2
Training loss: 0.11963271349668503
Validation loss: 1.5725086837686517

Epoch: 6| Step: 3
Training loss: 0.06121215224266052
Validation loss: 1.5690723772971862

Epoch: 6| Step: 4
Training loss: 0.05737180635333061
Validation loss: 1.5170298801955355

Epoch: 6| Step: 5
Training loss: 0.0688733235001564
Validation loss: 1.5466678296366045

Epoch: 6| Step: 6
Training loss: 0.06920505315065384
Validation loss: 1.5646656623450659

Epoch: 6| Step: 7
Training loss: 0.04190748929977417
Validation loss: 1.5509246498025873

Epoch: 6| Step: 8
Training loss: 0.058858007192611694
Validation loss: 1.567512422479609

Epoch: 6| Step: 9
Training loss: 0.09442317485809326
Validation loss: 1.5472005464697396

Epoch: 6| Step: 10
Training loss: 0.03621019423007965
Validation loss: 1.5636465152104695

Epoch: 6| Step: 11
Training loss: 0.07067348062992096
Validation loss: 1.5384703848951606

Epoch: 6| Step: 12
Training loss: 0.09049559384584427
Validation loss: 1.518005044229569

Epoch: 6| Step: 13
Training loss: 0.04380379989743233
Validation loss: 1.5292366448269095

Epoch: 675| Step: 0
Training loss: 0.04763384908437729
Validation loss: 1.5400056249351912

Epoch: 6| Step: 1
Training loss: 0.07399420440196991
Validation loss: 1.5243954761053926

Epoch: 6| Step: 2
Training loss: 0.05421660840511322
Validation loss: 1.5237456034588557

Epoch: 6| Step: 3
Training loss: 0.060020752251148224
Validation loss: 1.5071753968474686

Epoch: 6| Step: 4
Training loss: 0.09248073399066925
Validation loss: 1.5131759438463437

Epoch: 6| Step: 5
Training loss: 0.10415269434452057
Validation loss: 1.5364488247902162

Epoch: 6| Step: 6
Training loss: 0.11611922085285187
Validation loss: 1.5585925848253313

Epoch: 6| Step: 7
Training loss: 0.11654753237962723
Validation loss: 1.5629698909739012

Epoch: 6| Step: 8
Training loss: 0.05430996045470238
Validation loss: 1.594688255299804

Epoch: 6| Step: 9
Training loss: 0.10468489676713943
Validation loss: 1.6034878684628395

Epoch: 6| Step: 10
Training loss: 0.061851270496845245
Validation loss: 1.6203383309866792

Epoch: 6| Step: 11
Training loss: 0.09751582145690918
Validation loss: 1.6342861960011144

Epoch: 6| Step: 12
Training loss: 0.09758001565933228
Validation loss: 1.630069492965616

Epoch: 6| Step: 13
Training loss: 0.06857059895992279
Validation loss: 1.6120775156123663

Epoch: 676| Step: 0
Training loss: 0.051004648208618164
Validation loss: 1.6186680088761032

Epoch: 6| Step: 1
Training loss: 0.07509637624025345
Validation loss: 1.5770522650852

Epoch: 6| Step: 2
Training loss: 0.06579108536243439
Validation loss: 1.5661930743084158

Epoch: 6| Step: 3
Training loss: 0.0672224685549736
Validation loss: 1.5522839202675769

Epoch: 6| Step: 4
Training loss: 0.07812543213367462
Validation loss: 1.5558022593939176

Epoch: 6| Step: 5
Training loss: 0.0703265517950058
Validation loss: 1.569584572187034

Epoch: 6| Step: 6
Training loss: 0.08259888738393784
Validation loss: 1.5728440361638223

Epoch: 6| Step: 7
Training loss: 0.1084195002913475
Validation loss: 1.5430465577751078

Epoch: 6| Step: 8
Training loss: 0.04702936112880707
Validation loss: 1.5618016066089753

Epoch: 6| Step: 9
Training loss: 0.04721938073635101
Validation loss: 1.5697672828551261

Epoch: 6| Step: 10
Training loss: 0.08518011122941971
Validation loss: 1.569314056827176

Epoch: 6| Step: 11
Training loss: 0.08043832331895828
Validation loss: 1.6013220676811792

Epoch: 6| Step: 12
Training loss: 0.0930333286523819
Validation loss: 1.6274685398224862

Epoch: 6| Step: 13
Training loss: 0.09897390753030777
Validation loss: 1.6619217831601378

Epoch: 677| Step: 0
Training loss: 0.05803670734167099
Validation loss: 1.6346940545625583

Epoch: 6| Step: 1
Training loss: 0.05870279669761658
Validation loss: 1.6139754031294136

Epoch: 6| Step: 2
Training loss: 0.0900866687297821
Validation loss: 1.5867357087391678

Epoch: 6| Step: 3
Training loss: 0.054262783378362656
Validation loss: 1.5765206198538504

Epoch: 6| Step: 4
Training loss: 0.07952818274497986
Validation loss: 1.6011967133450251

Epoch: 6| Step: 5
Training loss: 0.059227921068668365
Validation loss: 1.5927119934430687

Epoch: 6| Step: 6
Training loss: 0.031920142471790314
Validation loss: 1.5650260089546122

Epoch: 6| Step: 7
Training loss: 0.07714046537876129
Validation loss: 1.5800710724246116

Epoch: 6| Step: 8
Training loss: 0.041798800230026245
Validation loss: 1.5509382883707683

Epoch: 6| Step: 9
Training loss: 0.09895391762256622
Validation loss: 1.5698569102953839

Epoch: 6| Step: 10
Training loss: 0.11667618155479431
Validation loss: 1.5169481308229509

Epoch: 6| Step: 11
Training loss: 0.06464079022407532
Validation loss: 1.5355185783037575

Epoch: 6| Step: 12
Training loss: 0.06273139268159866
Validation loss: 1.5518003061253538

Epoch: 6| Step: 13
Training loss: 0.11013276129961014
Validation loss: 1.575897571861103

Epoch: 678| Step: 0
Training loss: 0.08849307894706726
Validation loss: 1.602701066642679

Epoch: 6| Step: 1
Training loss: 0.08537927269935608
Validation loss: 1.5555649572803127

Epoch: 6| Step: 2
Training loss: 0.07276517897844315
Validation loss: 1.5704702638810681

Epoch: 6| Step: 3
Training loss: 0.08403751999139786
Validation loss: 1.5691761496246501

Epoch: 6| Step: 4
Training loss: 0.07204414904117584
Validation loss: 1.5684744875918153

Epoch: 6| Step: 5
Training loss: 0.07107091695070267
Validation loss: 1.535412375644971

Epoch: 6| Step: 6
Training loss: 0.06618441641330719
Validation loss: 1.554531475549103

Epoch: 6| Step: 7
Training loss: 0.08474944531917572
Validation loss: 1.5524654311518515

Epoch: 6| Step: 8
Training loss: 0.08174489438533783
Validation loss: 1.5519856573433004

Epoch: 6| Step: 9
Training loss: 0.08783247321844101
Validation loss: 1.5576837062835693

Epoch: 6| Step: 10
Training loss: 0.083168625831604
Validation loss: 1.559486598096868

Epoch: 6| Step: 11
Training loss: 0.09041309356689453
Validation loss: 1.5482692910778908

Epoch: 6| Step: 12
Training loss: 0.05807236209511757
Validation loss: 1.5486812271097654

Epoch: 6| Step: 13
Training loss: 0.06338215619325638
Validation loss: 1.5543076017851472

Epoch: 679| Step: 0
Training loss: 0.07569730281829834
Validation loss: 1.5328013884123934

Epoch: 6| Step: 1
Training loss: 0.09024645388126373
Validation loss: 1.5564646964432092

Epoch: 6| Step: 2
Training loss: 0.06890691816806793
Validation loss: 1.556244409212502

Epoch: 6| Step: 3
Training loss: 0.08626812696456909
Validation loss: 1.5571901426520398

Epoch: 6| Step: 4
Training loss: 0.06401481479406357
Validation loss: 1.5471598127836823

Epoch: 6| Step: 5
Training loss: 0.04851756989955902
Validation loss: 1.567985519286125

Epoch: 6| Step: 6
Training loss: 0.05925120785832405
Validation loss: 1.5493293551988498

Epoch: 6| Step: 7
Training loss: 0.08280708640813828
Validation loss: 1.5528875576552523

Epoch: 6| Step: 8
Training loss: 0.0832676887512207
Validation loss: 1.5313634000798708

Epoch: 6| Step: 9
Training loss: 0.08026596903800964
Validation loss: 1.5177437547714479

Epoch: 6| Step: 10
Training loss: 0.050154104828834534
Validation loss: 1.5291643706701135

Epoch: 6| Step: 11
Training loss: 0.05158799886703491
Validation loss: 1.5285374477345457

Epoch: 6| Step: 12
Training loss: 0.07913514971733093
Validation loss: 1.5071238586979527

Epoch: 6| Step: 13
Training loss: 0.06837783753871918
Validation loss: 1.509982330824739

Epoch: 680| Step: 0
Training loss: 0.034852251410484314
Validation loss: 1.5321852161038307

Epoch: 6| Step: 1
Training loss: 0.0590745285153389
Validation loss: 1.5429576584087905

Epoch: 6| Step: 2
Training loss: 0.03839334473013878
Validation loss: 1.5459317359873044

Epoch: 6| Step: 3
Training loss: 0.04254903644323349
Validation loss: 1.5198392688587148

Epoch: 6| Step: 4
Training loss: 0.10738904029130936
Validation loss: 1.5191572327767648

Epoch: 6| Step: 5
Training loss: 0.04616386443376541
Validation loss: 1.5130278820632606

Epoch: 6| Step: 6
Training loss: 0.03282768279314041
Validation loss: 1.5369557616531209

Epoch: 6| Step: 7
Training loss: 0.09272859245538712
Validation loss: 1.5303981970715266

Epoch: 6| Step: 8
Training loss: 0.060730934143066406
Validation loss: 1.5178793502110306

Epoch: 6| Step: 9
Training loss: 0.02557848021388054
Validation loss: 1.5249591501810218

Epoch: 6| Step: 10
Training loss: 0.06878319382667542
Validation loss: 1.549006010896416

Epoch: 6| Step: 11
Training loss: 0.05465497449040413
Validation loss: 1.5428599824187577

Epoch: 6| Step: 12
Training loss: 0.10404703766107559
Validation loss: 1.5379405008849276

Epoch: 6| Step: 13
Training loss: 0.11546026170253754
Validation loss: 1.5718340642990605

Epoch: 681| Step: 0
Training loss: 0.05020851269364357
Validation loss: 1.550676714989447

Epoch: 6| Step: 1
Training loss: 0.08283322304487228
Validation loss: 1.54339127643134

Epoch: 6| Step: 2
Training loss: 0.06159541755914688
Validation loss: 1.5662553489849131

Epoch: 6| Step: 3
Training loss: 0.08634333312511444
Validation loss: 1.5550972146372641

Epoch: 6| Step: 4
Training loss: 0.057323843240737915
Validation loss: 1.5503308619222333

Epoch: 6| Step: 5
Training loss: 0.0833093672990799
Validation loss: 1.5378403535453222

Epoch: 6| Step: 6
Training loss: 0.04439219459891319
Validation loss: 1.5499444700056506

Epoch: 6| Step: 7
Training loss: 0.05644170194864273
Validation loss: 1.545589893094955

Epoch: 6| Step: 8
Training loss: 0.05906735360622406
Validation loss: 1.5379948257118143

Epoch: 6| Step: 9
Training loss: 0.042106226086616516
Validation loss: 1.552436331266998

Epoch: 6| Step: 10
Training loss: 0.08192074298858643
Validation loss: 1.519742174815106

Epoch: 6| Step: 11
Training loss: 0.08476151525974274
Validation loss: 1.5562956474160636

Epoch: 6| Step: 12
Training loss: 0.061328038573265076
Validation loss: 1.5163037289855301

Epoch: 6| Step: 13
Training loss: 0.08083583414554596
Validation loss: 1.518432145477623

Epoch: 682| Step: 0
Training loss: 0.08044072985649109
Validation loss: 1.5534781538030153

Epoch: 6| Step: 1
Training loss: 0.04874562472105026
Validation loss: 1.544104915793224

Epoch: 6| Step: 2
Training loss: 0.09294502437114716
Validation loss: 1.5724088145840553

Epoch: 6| Step: 3
Training loss: 0.05733634531497955
Validation loss: 1.5644533852095246

Epoch: 6| Step: 4
Training loss: 0.07178685069084167
Validation loss: 1.5607009619794867

Epoch: 6| Step: 5
Training loss: 0.08604639023542404
Validation loss: 1.6080287233475716

Epoch: 6| Step: 6
Training loss: 0.05210946872830391
Validation loss: 1.5855996980462024

Epoch: 6| Step: 7
Training loss: 0.05937352776527405
Validation loss: 1.5548331711881904

Epoch: 6| Step: 8
Training loss: 0.06567814201116562
Validation loss: 1.5928021682206022

Epoch: 6| Step: 9
Training loss: 0.03945103660225868
Validation loss: 1.6057908740094913

Epoch: 6| Step: 10
Training loss: 0.06156490743160248
Validation loss: 1.5912831239802863

Epoch: 6| Step: 11
Training loss: 0.04613887891173363
Validation loss: 1.5578464872093611

Epoch: 6| Step: 12
Training loss: 0.0607336051762104
Validation loss: 1.5671938401396557

Epoch: 6| Step: 13
Training loss: 0.09710356593132019
Validation loss: 1.5592163993466286

Epoch: 683| Step: 0
Training loss: 0.05845541134476662
Validation loss: 1.545340294479042

Epoch: 6| Step: 1
Training loss: 0.09538309276103973
Validation loss: 1.5454116188069826

Epoch: 6| Step: 2
Training loss: 0.09664696455001831
Validation loss: 1.5506682511298888

Epoch: 6| Step: 3
Training loss: 0.07599092274904251
Validation loss: 1.5392588312907884

Epoch: 6| Step: 4
Training loss: 0.10602279752492905
Validation loss: 1.5449423982251076

Epoch: 6| Step: 5
Training loss: 0.07001538574695587
Validation loss: 1.523250247842522

Epoch: 6| Step: 6
Training loss: 0.0782347172498703
Validation loss: 1.5478348808903848

Epoch: 6| Step: 7
Training loss: 0.06144813448190689
Validation loss: 1.54838478308852

Epoch: 6| Step: 8
Training loss: 0.05955219268798828
Validation loss: 1.5615021349281393

Epoch: 6| Step: 9
Training loss: 0.06044312193989754
Validation loss: 1.5587209475937711

Epoch: 6| Step: 10
Training loss: 0.06379736959934235
Validation loss: 1.558718309607557

Epoch: 6| Step: 11
Training loss: 0.05300651490688324
Validation loss: 1.5297805045240669

Epoch: 6| Step: 12
Training loss: 0.051741115748882294
Validation loss: 1.553104615980579

Epoch: 6| Step: 13
Training loss: 0.11968353390693665
Validation loss: 1.5467631945046045

Epoch: 684| Step: 0
Training loss: 0.06203894317150116
Validation loss: 1.5725373568073395

Epoch: 6| Step: 1
Training loss: 0.08579803258180618
Validation loss: 1.5619059865192702

Epoch: 6| Step: 2
Training loss: 0.052896320819854736
Validation loss: 1.5406557642003542

Epoch: 6| Step: 3
Training loss: 0.061102233827114105
Validation loss: 1.5803654834788332

Epoch: 6| Step: 4
Training loss: 0.05064941942691803
Validation loss: 1.590746586040784

Epoch: 6| Step: 5
Training loss: 0.04518720507621765
Validation loss: 1.5736726548082085

Epoch: 6| Step: 6
Training loss: 0.07126539200544357
Validation loss: 1.5934077693570046

Epoch: 6| Step: 7
Training loss: 0.06082811951637268
Validation loss: 1.5691468241394206

Epoch: 6| Step: 8
Training loss: 0.11731866002082825
Validation loss: 1.5511598663945352

Epoch: 6| Step: 9
Training loss: 0.09607534855604172
Validation loss: 1.5741932238301923

Epoch: 6| Step: 10
Training loss: 0.053254179656505585
Validation loss: 1.5593542821945683

Epoch: 6| Step: 11
Training loss: 0.09221269935369492
Validation loss: 1.5735545748023576

Epoch: 6| Step: 12
Training loss: 0.057018183171749115
Validation loss: 1.5578133572814286

Epoch: 6| Step: 13
Training loss: 0.06363452970981598
Validation loss: 1.557560041386594

Epoch: 685| Step: 0
Training loss: 0.05670303851366043
Validation loss: 1.5513016241852955

Epoch: 6| Step: 1
Training loss: 0.1096746027469635
Validation loss: 1.5364713348368162

Epoch: 6| Step: 2
Training loss: 0.03238146752119064
Validation loss: 1.5642639898484754

Epoch: 6| Step: 3
Training loss: 0.05497625470161438
Validation loss: 1.5338287167651679

Epoch: 6| Step: 4
Training loss: 0.04755815118551254
Validation loss: 1.5487140096643919

Epoch: 6| Step: 5
Training loss: 0.08641614764928818
Validation loss: 1.5405687132189352

Epoch: 6| Step: 6
Training loss: 0.11661212891340256
Validation loss: 1.5332091540418646

Epoch: 6| Step: 7
Training loss: 0.10139034688472748
Validation loss: 1.5152150264350317

Epoch: 6| Step: 8
Training loss: 0.06260253489017487
Validation loss: 1.5067354081779398

Epoch: 6| Step: 9
Training loss: 0.05971277505159378
Validation loss: 1.520757362406741

Epoch: 6| Step: 10
Training loss: 0.08919905126094818
Validation loss: 1.5253046661294916

Epoch: 6| Step: 11
Training loss: 0.04962361231446266
Validation loss: 1.5682318646420714

Epoch: 6| Step: 12
Training loss: 0.06079725921154022
Validation loss: 1.5541309387453142

Epoch: 6| Step: 13
Training loss: 0.039890144020318985
Validation loss: 1.5582753637785554

Epoch: 686| Step: 0
Training loss: 0.07783249020576477
Validation loss: 1.5724308747117237

Epoch: 6| Step: 1
Training loss: 0.07263602316379547
Validation loss: 1.5847801482805641

Epoch: 6| Step: 2
Training loss: 0.0861487090587616
Validation loss: 1.5751230998705792

Epoch: 6| Step: 3
Training loss: 0.08522143214941025
Validation loss: 1.5921729392902826

Epoch: 6| Step: 4
Training loss: 0.1049128919839859
Validation loss: 1.5631608283647926

Epoch: 6| Step: 5
Training loss: 0.057280972599983215
Validation loss: 1.5674505323492072

Epoch: 6| Step: 6
Training loss: 0.03988957777619362
Validation loss: 1.554079883842058

Epoch: 6| Step: 7
Training loss: 0.060713186860084534
Validation loss: 1.5499734840085428

Epoch: 6| Step: 8
Training loss: 0.08141658455133438
Validation loss: 1.5548558837624007

Epoch: 6| Step: 9
Training loss: 0.11605508625507355
Validation loss: 1.5124366039870887

Epoch: 6| Step: 10
Training loss: 0.105791836977005
Validation loss: 1.5110468479894823

Epoch: 6| Step: 11
Training loss: 0.04378225654363632
Validation loss: 1.5128142449163622

Epoch: 6| Step: 12
Training loss: 0.05702535808086395
Validation loss: 1.5311141308917795

Epoch: 6| Step: 13
Training loss: 0.13557785749435425
Validation loss: 1.5564807102244387

Epoch: 687| Step: 0
Training loss: 0.07200620323419571
Validation loss: 1.5705127792973672

Epoch: 6| Step: 1
Training loss: 0.08161357045173645
Validation loss: 1.533898074139831

Epoch: 6| Step: 2
Training loss: 0.07215632498264313
Validation loss: 1.576158711987157

Epoch: 6| Step: 3
Training loss: 0.12281085550785065
Validation loss: 1.5744713198754094

Epoch: 6| Step: 4
Training loss: 0.10840587317943573
Validation loss: 1.5475083769008677

Epoch: 6| Step: 5
Training loss: 0.11107586324214935
Validation loss: 1.543538167912473

Epoch: 6| Step: 6
Training loss: 0.04603393375873566
Validation loss: 1.5345111995614984

Epoch: 6| Step: 7
Training loss: 0.0654476061463356
Validation loss: 1.5120972753852926

Epoch: 6| Step: 8
Training loss: 0.07427151501178741
Validation loss: 1.499120686643867

Epoch: 6| Step: 9
Training loss: 0.036838240921497345
Validation loss: 1.4887710950707878

Epoch: 6| Step: 10
Training loss: 0.0920741856098175
Validation loss: 1.5112555334644933

Epoch: 6| Step: 11
Training loss: 0.12777861952781677
Validation loss: 1.5080461367484062

Epoch: 6| Step: 12
Training loss: 0.05561141297221184
Validation loss: 1.4849349311603013

Epoch: 6| Step: 13
Training loss: 0.048714347183704376
Validation loss: 1.5043287033675818

Epoch: 688| Step: 0
Training loss: 0.07649236172437668
Validation loss: 1.5190819360876595

Epoch: 6| Step: 1
Training loss: 0.07037483155727386
Validation loss: 1.5453908763906008

Epoch: 6| Step: 2
Training loss: 0.03274358808994293
Validation loss: 1.5278776063713977

Epoch: 6| Step: 3
Training loss: 0.06106527894735336
Validation loss: 1.5480536068639448

Epoch: 6| Step: 4
Training loss: 0.10570935904979706
Validation loss: 1.5395265189550256

Epoch: 6| Step: 5
Training loss: 0.08628436177968979
Validation loss: 1.5030380654078659

Epoch: 6| Step: 6
Training loss: 0.052698276937007904
Validation loss: 1.534270824924592

Epoch: 6| Step: 7
Training loss: 0.04778680205345154
Validation loss: 1.5344476558828866

Epoch: 6| Step: 8
Training loss: 0.0478953942656517
Validation loss: 1.5045183704745384

Epoch: 6| Step: 9
Training loss: 0.08431179076433182
Validation loss: 1.513135454987967

Epoch: 6| Step: 10
Training loss: 0.14302584528923035
Validation loss: 1.5337658780877308

Epoch: 6| Step: 11
Training loss: 0.060674235224723816
Validation loss: 1.5021598800536125

Epoch: 6| Step: 12
Training loss: 0.0881563201546669
Validation loss: 1.5126495758692424

Epoch: 6| Step: 13
Training loss: 0.032831646502017975
Validation loss: 1.5410383093741633

Epoch: 689| Step: 0
Training loss: 0.042111072689294815
Validation loss: 1.5185558629292313

Epoch: 6| Step: 1
Training loss: 0.0767311155796051
Validation loss: 1.5559093349723405

Epoch: 6| Step: 2
Training loss: 0.06297855079174042
Validation loss: 1.5523302426902197

Epoch: 6| Step: 3
Training loss: 0.10214213281869888
Validation loss: 1.5468355660797448

Epoch: 6| Step: 4
Training loss: 0.07522016763687134
Validation loss: 1.5360317307133828

Epoch: 6| Step: 5
Training loss: 0.042033009231090546
Validation loss: 1.5472222169240315

Epoch: 6| Step: 6
Training loss: 0.0630849301815033
Validation loss: 1.5416278044382732

Epoch: 6| Step: 7
Training loss: 0.08590953052043915
Validation loss: 1.55168193258265

Epoch: 6| Step: 8
Training loss: 0.055514946579933167
Validation loss: 1.5341556905418314

Epoch: 6| Step: 9
Training loss: 0.05325848236680031
Validation loss: 1.5217462508909163

Epoch: 6| Step: 10
Training loss: 0.09940559417009354
Validation loss: 1.5271214080113236

Epoch: 6| Step: 11
Training loss: 0.04878861457109451
Validation loss: 1.5200542583260486

Epoch: 6| Step: 12
Training loss: 0.04129894822835922
Validation loss: 1.4884563428099438

Epoch: 6| Step: 13
Training loss: 0.06678097695112228
Validation loss: 1.5227761883889475

Epoch: 690| Step: 0
Training loss: 0.086870476603508
Validation loss: 1.4924413645139305

Epoch: 6| Step: 1
Training loss: 0.022832030430436134
Validation loss: 1.5059403168257846

Epoch: 6| Step: 2
Training loss: 0.08236567676067352
Validation loss: 1.515965602731192

Epoch: 6| Step: 3
Training loss: 0.06838081032037735
Validation loss: 1.4928749774091987

Epoch: 6| Step: 4
Training loss: 0.07716601341962814
Validation loss: 1.4803476179799726

Epoch: 6| Step: 5
Training loss: 0.0637180283665657
Validation loss: 1.5074911553372619

Epoch: 6| Step: 6
Training loss: 0.05380827561020851
Validation loss: 1.501035431379913

Epoch: 6| Step: 7
Training loss: 0.03871304541826248
Validation loss: 1.4844802810299782

Epoch: 6| Step: 8
Training loss: 0.052104972302913666
Validation loss: 1.501519150631402

Epoch: 6| Step: 9
Training loss: 0.058091938495635986
Validation loss: 1.517937570489863

Epoch: 6| Step: 10
Training loss: 0.0863180011510849
Validation loss: 1.5042415908587876

Epoch: 6| Step: 11
Training loss: 0.0381767675280571
Validation loss: 1.5165321557752547

Epoch: 6| Step: 12
Training loss: 0.0398310087621212
Validation loss: 1.5460455033086962

Epoch: 6| Step: 13
Training loss: 0.05359109863638878
Validation loss: 1.5309214258706698

Epoch: 691| Step: 0
Training loss: 0.09482300281524658
Validation loss: 1.5519223642605606

Epoch: 6| Step: 1
Training loss: 0.045983146876096725
Validation loss: 1.5498743134160196

Epoch: 6| Step: 2
Training loss: 0.0435735285282135
Validation loss: 1.5431760331635833

Epoch: 6| Step: 3
Training loss: 0.06285236775875092
Validation loss: 1.5677218706377092

Epoch: 6| Step: 4
Training loss: 0.08981350064277649
Validation loss: 1.543991296522079

Epoch: 6| Step: 5
Training loss: 0.06055433303117752
Validation loss: 1.5497390147178405

Epoch: 6| Step: 6
Training loss: 0.04386678338050842
Validation loss: 1.5360375142866565

Epoch: 6| Step: 7
Training loss: 0.042751096189022064
Validation loss: 1.5453509310240388

Epoch: 6| Step: 8
Training loss: 0.0610748790204525
Validation loss: 1.5278522301745672

Epoch: 6| Step: 9
Training loss: 0.03935329616069794
Validation loss: 1.4922793347348449

Epoch: 6| Step: 10
Training loss: 0.11978516727685928
Validation loss: 1.5431567110041136

Epoch: 6| Step: 11
Training loss: 0.0432165190577507
Validation loss: 1.5221178967465636

Epoch: 6| Step: 12
Training loss: 0.09231245517730713
Validation loss: 1.536090099683372

Epoch: 6| Step: 13
Training loss: 0.024527158588171005
Validation loss: 1.5462352204066452

Epoch: 692| Step: 0
Training loss: 0.032921306788921356
Validation loss: 1.5550500526223132

Epoch: 6| Step: 1
Training loss: 0.05420849099755287
Validation loss: 1.561341191491773

Epoch: 6| Step: 2
Training loss: 0.04466305673122406
Validation loss: 1.5416524179520146

Epoch: 6| Step: 3
Training loss: 0.05967460200190544
Validation loss: 1.5383659434574906

Epoch: 6| Step: 4
Training loss: 0.050869014114141464
Validation loss: 1.5393861429665678

Epoch: 6| Step: 5
Training loss: 0.06605739146471024
Validation loss: 1.5298522646709154

Epoch: 6| Step: 6
Training loss: 0.09270144253969193
Validation loss: 1.5052621928594445

Epoch: 6| Step: 7
Training loss: 0.0682268962264061
Validation loss: 1.5178676677006546

Epoch: 6| Step: 8
Training loss: 0.06965496391057968
Validation loss: 1.536998132223724

Epoch: 6| Step: 9
Training loss: 0.09700597077608109
Validation loss: 1.4728484051201933

Epoch: 6| Step: 10
Training loss: 0.03572840243577957
Validation loss: 1.5037090932169268

Epoch: 6| Step: 11
Training loss: 0.051660872995853424
Validation loss: 1.5296068781165666

Epoch: 6| Step: 12
Training loss: 0.07674463093280792
Validation loss: 1.4962679070811118

Epoch: 6| Step: 13
Training loss: 0.04110566899180412
Validation loss: 1.5067965189615886

Epoch: 693| Step: 0
Training loss: 0.046265698969364166
Validation loss: 1.5541737733348724

Epoch: 6| Step: 1
Training loss: 0.05939989909529686
Validation loss: 1.5363406135189919

Epoch: 6| Step: 2
Training loss: 0.060896072536706924
Validation loss: 1.5397574311943465

Epoch: 6| Step: 3
Training loss: 0.07209513336420059
Validation loss: 1.5335509802705498

Epoch: 6| Step: 4
Training loss: 0.07768560945987701
Validation loss: 1.5492781285316712

Epoch: 6| Step: 5
Training loss: 0.06322439014911652
Validation loss: 1.541512937955959

Epoch: 6| Step: 6
Training loss: 0.10298547148704529
Validation loss: 1.5232303950094408

Epoch: 6| Step: 7
Training loss: 0.050603944808244705
Validation loss: 1.5229809309846611

Epoch: 6| Step: 8
Training loss: 0.03300681710243225
Validation loss: 1.5286568300698393

Epoch: 6| Step: 9
Training loss: 0.050988588482141495
Validation loss: 1.525689200688434

Epoch: 6| Step: 10
Training loss: 0.07112254947423935
Validation loss: 1.5066262778415476

Epoch: 6| Step: 11
Training loss: 0.044497061520814896
Validation loss: 1.5066866938785841

Epoch: 6| Step: 12
Training loss: 0.08370433747768402
Validation loss: 1.5246103886635072

Epoch: 6| Step: 13
Training loss: 0.04630401358008385
Validation loss: 1.5078592467051681

Epoch: 694| Step: 0
Training loss: 0.07699534296989441
Validation loss: 1.5185593699896207

Epoch: 6| Step: 1
Training loss: 0.06468652188777924
Validation loss: 1.5054374849924477

Epoch: 6| Step: 2
Training loss: 0.02817399613559246
Validation loss: 1.5070874133417684

Epoch: 6| Step: 3
Training loss: 0.04254763573408127
Validation loss: 1.5032420401932092

Epoch: 6| Step: 4
Training loss: 0.06773541122674942
Validation loss: 1.512212340549756

Epoch: 6| Step: 5
Training loss: 0.04936875402927399
Validation loss: 1.5097529734334638

Epoch: 6| Step: 6
Training loss: 0.06196730211377144
Validation loss: 1.517387145309038

Epoch: 6| Step: 7
Training loss: 0.0763663798570633
Validation loss: 1.5241382211767218

Epoch: 6| Step: 8
Training loss: 0.05409315600991249
Validation loss: 1.505573223995906

Epoch: 6| Step: 9
Training loss: 0.04123590141534805
Validation loss: 1.5125711502567414

Epoch: 6| Step: 10
Training loss: 0.0656445175409317
Validation loss: 1.5093922281777987

Epoch: 6| Step: 11
Training loss: 0.05804974213242531
Validation loss: 1.4982346219401206

Epoch: 6| Step: 12
Training loss: 0.08014117181301117
Validation loss: 1.507334650203746

Epoch: 6| Step: 13
Training loss: 0.03887846693396568
Validation loss: 1.5059347665438088

Epoch: 695| Step: 0
Training loss: 0.075984425842762
Validation loss: 1.5109304433227868

Epoch: 6| Step: 1
Training loss: 0.059314094483852386
Validation loss: 1.4976138530238983

Epoch: 6| Step: 2
Training loss: 0.052753593772649765
Validation loss: 1.5118513501459552

Epoch: 6| Step: 3
Training loss: 0.0884854793548584
Validation loss: 1.5032207350577078

Epoch: 6| Step: 4
Training loss: 0.057666562497615814
Validation loss: 1.4861672892365405

Epoch: 6| Step: 5
Training loss: 0.0926075279712677
Validation loss: 1.500994925857872

Epoch: 6| Step: 6
Training loss: 0.024051709100604057
Validation loss: 1.5091224780646704

Epoch: 6| Step: 7
Training loss: 0.04686123877763748
Validation loss: 1.5135752488208074

Epoch: 6| Step: 8
Training loss: 0.0658610463142395
Validation loss: 1.530573707754894

Epoch: 6| Step: 9
Training loss: 0.05880538374185562
Validation loss: 1.510524744628578

Epoch: 6| Step: 10
Training loss: 0.08172152936458588
Validation loss: 1.5406154842786892

Epoch: 6| Step: 11
Training loss: 0.07624426484107971
Validation loss: 1.5371793623893493

Epoch: 6| Step: 12
Training loss: 0.04794084653258324
Validation loss: 1.5309416030042915

Epoch: 6| Step: 13
Training loss: 0.03704480454325676
Validation loss: 1.5399309806926276

Epoch: 696| Step: 0
Training loss: 0.048763029277324677
Validation loss: 1.511272914948002

Epoch: 6| Step: 1
Training loss: 0.05307895690202713
Validation loss: 1.5104314960459226

Epoch: 6| Step: 2
Training loss: 0.040528446435928345
Validation loss: 1.5047133238084855

Epoch: 6| Step: 3
Training loss: 0.04028773307800293
Validation loss: 1.5014119955801195

Epoch: 6| Step: 4
Training loss: 0.08931431174278259
Validation loss: 1.4770811514187885

Epoch: 6| Step: 5
Training loss: 0.10932010412216187
Validation loss: 1.4721251264695199

Epoch: 6| Step: 6
Training loss: 0.10294926911592484
Validation loss: 1.4804553178048903

Epoch: 6| Step: 7
Training loss: 0.051123086363077164
Validation loss: 1.4910094802097609

Epoch: 6| Step: 8
Training loss: 0.043741993606090546
Validation loss: 1.4871126900437057

Epoch: 6| Step: 9
Training loss: 0.043672338128089905
Validation loss: 1.4940001938932685

Epoch: 6| Step: 10
Training loss: 0.04602827876806259
Validation loss: 1.4996611431080809

Epoch: 6| Step: 11
Training loss: 0.03747154772281647
Validation loss: 1.4912797212600708

Epoch: 6| Step: 12
Training loss: 0.046573057770729065
Validation loss: 1.4985770999744374

Epoch: 6| Step: 13
Training loss: 0.057188842445611954
Validation loss: 1.5124899392486901

Epoch: 697| Step: 0
Training loss: 0.04505011439323425
Validation loss: 1.524603775752488

Epoch: 6| Step: 1
Training loss: 0.055585190653800964
Validation loss: 1.5354597183965868

Epoch: 6| Step: 2
Training loss: 0.03680241480469704
Validation loss: 1.5299044578306136

Epoch: 6| Step: 3
Training loss: 0.07264140248298645
Validation loss: 1.5188362213873094

Epoch: 6| Step: 4
Training loss: 0.07532884180545807
Validation loss: 1.5234650501640894

Epoch: 6| Step: 5
Training loss: 0.10626235604286194
Validation loss: 1.514683379921862

Epoch: 6| Step: 6
Training loss: 0.07001792639493942
Validation loss: 1.52465614580339

Epoch: 6| Step: 7
Training loss: 0.050244104117155075
Validation loss: 1.5498293061410227

Epoch: 6| Step: 8
Training loss: 0.06763198226690292
Validation loss: 1.5386833939501035

Epoch: 6| Step: 9
Training loss: 0.03714776039123535
Validation loss: 1.5504834799356357

Epoch: 6| Step: 10
Training loss: 0.07218478620052338
Validation loss: 1.535156830664604

Epoch: 6| Step: 11
Training loss: 0.05977648124098778
Validation loss: 1.5542334471979449

Epoch: 6| Step: 12
Training loss: 0.0476713553071022
Validation loss: 1.5345490722246067

Epoch: 6| Step: 13
Training loss: 0.04090457409620285
Validation loss: 1.5471605549576462

Epoch: 698| Step: 0
Training loss: 0.0520508848130703
Validation loss: 1.5690659284591675

Epoch: 6| Step: 1
Training loss: 0.07921628654003143
Validation loss: 1.5558250399046047

Epoch: 6| Step: 2
Training loss: 0.03821886330842972
Validation loss: 1.5682103505698584

Epoch: 6| Step: 3
Training loss: 0.1011737659573555
Validation loss: 1.5765198994708318

Epoch: 6| Step: 4
Training loss: 0.042592380195856094
Validation loss: 1.541861666146145

Epoch: 6| Step: 5
Training loss: 0.057204119861125946
Validation loss: 1.5546200006238875

Epoch: 6| Step: 6
Training loss: 0.05040477216243744
Validation loss: 1.5708555470230758

Epoch: 6| Step: 7
Training loss: 0.06580780446529388
Validation loss: 1.559879752897447

Epoch: 6| Step: 8
Training loss: 0.0484587624669075
Validation loss: 1.5815219545877108

Epoch: 6| Step: 9
Training loss: 0.07592157274484634
Validation loss: 1.5428212714451615

Epoch: 6| Step: 10
Training loss: 0.04963105171918869
Validation loss: 1.5694456536282775

Epoch: 6| Step: 11
Training loss: 0.06854524463415146
Validation loss: 1.554279314574375

Epoch: 6| Step: 12
Training loss: 0.062272876501083374
Validation loss: 1.5235759289033952

Epoch: 6| Step: 13
Training loss: 0.11193367838859558
Validation loss: 1.5302570737818235

Epoch: 699| Step: 0
Training loss: 0.05328219756484032
Validation loss: 1.517578096799953

Epoch: 6| Step: 1
Training loss: 0.06336059421300888
Validation loss: 1.5363081680831088

Epoch: 6| Step: 2
Training loss: 0.05387522280216217
Validation loss: 1.5341027193172003

Epoch: 6| Step: 3
Training loss: 0.09168374538421631
Validation loss: 1.5284155158586399

Epoch: 6| Step: 4
Training loss: 0.09087841212749481
Validation loss: 1.5490417313832108

Epoch: 6| Step: 5
Training loss: 0.06576617062091827
Validation loss: 1.5413588528992028

Epoch: 6| Step: 6
Training loss: 0.09079236537218094
Validation loss: 1.5336841639652048

Epoch: 6| Step: 7
Training loss: 0.0619489923119545
Validation loss: 1.522216776365875

Epoch: 6| Step: 8
Training loss: 0.08638424426317215
Validation loss: 1.5410042347446564

Epoch: 6| Step: 9
Training loss: 0.049251485615968704
Validation loss: 1.5460526622751707

Epoch: 6| Step: 10
Training loss: 0.06648692488670349
Validation loss: 1.5328025548688826

Epoch: 6| Step: 11
Training loss: 0.0998629629611969
Validation loss: 1.533955950890818

Epoch: 6| Step: 12
Training loss: 0.043880850076675415
Validation loss: 1.559681333521361

Epoch: 6| Step: 13
Training loss: 0.05346732586622238
Validation loss: 1.5415099429827865

Epoch: 700| Step: 0
Training loss: 0.1242653876543045
Validation loss: 1.5111802662572553

Epoch: 6| Step: 1
Training loss: 0.13110214471817017
Validation loss: 1.5397014476919686

Epoch: 6| Step: 2
Training loss: 0.06423639506101608
Validation loss: 1.5502433956310313

Epoch: 6| Step: 3
Training loss: 0.09848403930664062
Validation loss: 1.5577527399986022

Epoch: 6| Step: 4
Training loss: 0.07352360337972641
Validation loss: 1.5770389597903016

Epoch: 6| Step: 5
Training loss: 0.051697079092264175
Validation loss: 1.5997344947630359

Epoch: 6| Step: 6
Training loss: 0.1588926613330841
Validation loss: 1.5784830841966855

Epoch: 6| Step: 7
Training loss: 0.08152200281620026
Validation loss: 1.542603878564732

Epoch: 6| Step: 8
Training loss: 0.08847035467624664
Validation loss: 1.5125107252469627

Epoch: 6| Step: 9
Training loss: 0.04825201630592346
Validation loss: 1.5492052057737946

Epoch: 6| Step: 10
Training loss: 0.08080118894577026
Validation loss: 1.5340490661641604

Epoch: 6| Step: 11
Training loss: 0.11066827923059464
Validation loss: 1.5614521503448486

Epoch: 6| Step: 12
Training loss: 0.14116114377975464
Validation loss: 1.567794410772221

Epoch: 6| Step: 13
Training loss: 0.27366504073143005
Validation loss: 1.5691409021295526

Testing loss: 2.125198311275906
