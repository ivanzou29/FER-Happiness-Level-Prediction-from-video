Epoch: 1| Step: 0
Training loss: 4.886244773864746
Validation loss: 5.178142680916735

Epoch: 5| Step: 1
Training loss: 4.629186630249023
Validation loss: 5.157671225968228

Epoch: 5| Step: 2
Training loss: 5.477625846862793
Validation loss: 5.141650220399262

Epoch: 5| Step: 3
Training loss: 4.701082229614258
Validation loss: 5.12730251332765

Epoch: 5| Step: 4
Training loss: 5.264082431793213
Validation loss: 5.111464013335525

Epoch: 5| Step: 5
Training loss: 5.3134260177612305
Validation loss: 5.093269732690627

Epoch: 5| Step: 6
Training loss: 6.053171634674072
Validation loss: 5.071407900061659

Epoch: 5| Step: 7
Training loss: 3.9367899894714355
Validation loss: 5.046736255768807

Epoch: 5| Step: 8
Training loss: 4.569758415222168
Validation loss: 5.017972864130492

Epoch: 5| Step: 9
Training loss: 3.8362746238708496
Validation loss: 4.98557876258768

Epoch: 5| Step: 10
Training loss: 5.011124134063721
Validation loss: 4.9495311552478425

Epoch: 2| Step: 0
Training loss: 5.055285453796387
Validation loss: 4.909073937323786

Epoch: 5| Step: 1
Training loss: 4.09991455078125
Validation loss: 4.863717120180848

Epoch: 5| Step: 2
Training loss: 5.5362868309021
Validation loss: 4.81539390420401

Epoch: 5| Step: 3
Training loss: 4.711978912353516
Validation loss: 4.763244921161283

Epoch: 5| Step: 4
Training loss: 4.351052284240723
Validation loss: 4.707826050378943

Epoch: 5| Step: 5
Training loss: 4.752300262451172
Validation loss: 4.65005531618672

Epoch: 5| Step: 6
Training loss: 3.6518867015838623
Validation loss: 4.58852675140545

Epoch: 5| Step: 7
Training loss: 4.210160732269287
Validation loss: 4.525014984992243

Epoch: 5| Step: 8
Training loss: 3.6381773948669434
Validation loss: 4.458073303263674

Epoch: 5| Step: 9
Training loss: 4.482893943786621
Validation loss: 4.39074142261218

Epoch: 5| Step: 10
Training loss: 4.180448532104492
Validation loss: 4.322134125617243

Epoch: 3| Step: 0
Training loss: 4.371419906616211
Validation loss: 4.252327180677844

Epoch: 5| Step: 1
Training loss: 3.6256823539733887
Validation loss: 4.18126888685329

Epoch: 5| Step: 2
Training loss: 5.169756889343262
Validation loss: 4.100442778679632

Epoch: 5| Step: 3
Training loss: 4.13604736328125
Validation loss: 3.9945346129837858

Epoch: 5| Step: 4
Training loss: 3.0160231590270996
Validation loss: 3.9484816264080744

Epoch: 5| Step: 5
Training loss: 3.8194737434387207
Validation loss: 3.9084669338759555

Epoch: 5| Step: 6
Training loss: 4.482605934143066
Validation loss: 3.8763116149492163

Epoch: 5| Step: 7
Training loss: 2.6011834144592285
Validation loss: 3.8423575688433904

Epoch: 5| Step: 8
Training loss: 3.070530652999878
Validation loss: 3.813728481210688

Epoch: 5| Step: 9
Training loss: 3.978452205657959
Validation loss: 3.7821266933154036

Epoch: 5| Step: 10
Training loss: 3.6611363887786865
Validation loss: 3.7524893565844466

Epoch: 4| Step: 0
Training loss: 4.667905330657959
Validation loss: 3.721601214460147

Epoch: 5| Step: 1
Training loss: 3.2471160888671875
Validation loss: 3.697713190509427

Epoch: 5| Step: 2
Training loss: 3.6058478355407715
Validation loss: 3.6713557474074827

Epoch: 5| Step: 3
Training loss: 3.1580071449279785
Validation loss: 3.656045949587258

Epoch: 5| Step: 4
Training loss: 3.9645981788635254
Validation loss: 3.639122037477391

Epoch: 5| Step: 5
Training loss: 3.338454484939575
Validation loss: 3.6255872326512493

Epoch: 5| Step: 6
Training loss: 3.3862617015838623
Validation loss: 3.6098691853143836

Epoch: 5| Step: 7
Training loss: 3.7314186096191406
Validation loss: 3.593153815115652

Epoch: 5| Step: 8
Training loss: 3.2359142303466797
Validation loss: 3.5762168950932

Epoch: 5| Step: 9
Training loss: 3.616960048675537
Validation loss: 3.568573213392688

Epoch: 5| Step: 10
Training loss: 2.9137790203094482
Validation loss: 3.5447393489140335

Epoch: 5| Step: 0
Training loss: 3.904050350189209
Validation loss: 3.5306679946120068

Epoch: 5| Step: 1
Training loss: 4.003829002380371
Validation loss: 3.5096435290510937

Epoch: 5| Step: 2
Training loss: 3.4170875549316406
Validation loss: 3.4933392873374363

Epoch: 5| Step: 3
Training loss: 4.270632266998291
Validation loss: 3.4709517904507217

Epoch: 5| Step: 4
Training loss: 2.9049599170684814
Validation loss: 3.4515631506519933

Epoch: 5| Step: 5
Training loss: 3.7343997955322266
Validation loss: 3.427465941316338

Epoch: 5| Step: 6
Training loss: 2.088348865509033
Validation loss: 3.407613403053694

Epoch: 5| Step: 7
Training loss: 2.893673896789551
Validation loss: 3.3845446443045013

Epoch: 5| Step: 8
Training loss: 3.198129177093506
Validation loss: 3.3695234790925057

Epoch: 5| Step: 9
Training loss: 3.36462140083313
Validation loss: 3.3507303371224353

Epoch: 5| Step: 10
Training loss: 3.4431400299072266
Validation loss: 3.335609459107922

Epoch: 6| Step: 0
Training loss: 2.9364781379699707
Validation loss: 3.3115174129445064

Epoch: 5| Step: 1
Training loss: 3.2099063396453857
Validation loss: 3.295687678039715

Epoch: 5| Step: 2
Training loss: 3.2687301635742188
Validation loss: 3.2953782491786505

Epoch: 5| Step: 3
Training loss: 2.5396275520324707
Validation loss: 3.2525344279504593

Epoch: 5| Step: 4
Training loss: 2.610328435897827
Validation loss: 3.259341985948624

Epoch: 5| Step: 5
Training loss: 4.109347343444824
Validation loss: 3.2483696578651347

Epoch: 5| Step: 6
Training loss: 3.5919623374938965
Validation loss: 3.2387317790780017

Epoch: 5| Step: 7
Training loss: 3.105187177658081
Validation loss: 3.2287143225310952

Epoch: 5| Step: 8
Training loss: 3.7117278575897217
Validation loss: 3.2169387981455815

Epoch: 5| Step: 9
Training loss: 2.650207281112671
Validation loss: 3.202929442928683

Epoch: 5| Step: 10
Training loss: 3.8874247074127197
Validation loss: 3.191265231819563

Epoch: 7| Step: 0
Training loss: 3.5680038928985596
Validation loss: 3.176905391036823

Epoch: 5| Step: 1
Training loss: 3.9479408264160156
Validation loss: 3.163355001839258

Epoch: 5| Step: 2
Training loss: 2.5243606567382812
Validation loss: 3.1528965503938737

Epoch: 5| Step: 3
Training loss: 3.284158229827881
Validation loss: 3.140326402520621

Epoch: 5| Step: 4
Training loss: 3.4355545043945312
Validation loss: 3.1254896707432245

Epoch: 5| Step: 5
Training loss: 3.228745937347412
Validation loss: 3.11793843905131

Epoch: 5| Step: 6
Training loss: 2.7861168384552
Validation loss: 3.109802802403768

Epoch: 5| Step: 7
Training loss: 2.2553348541259766
Validation loss: 3.1046335312627975

Epoch: 5| Step: 8
Training loss: 3.3446221351623535
Validation loss: 3.101639650201285

Epoch: 5| Step: 9
Training loss: 2.87764310836792
Validation loss: 3.0879535059775076

Epoch: 5| Step: 10
Training loss: 3.394351005554199
Validation loss: 3.0752709040077786

Epoch: 8| Step: 0
Training loss: 3.778135299682617
Validation loss: 3.0712428862048733

Epoch: 5| Step: 1
Training loss: 3.0311646461486816
Validation loss: 3.0613103374358146

Epoch: 5| Step: 2
Training loss: 3.4618148803710938
Validation loss: 3.0464981986630346

Epoch: 5| Step: 3
Training loss: 2.592714786529541
Validation loss: 3.0430201433038198

Epoch: 5| Step: 4
Training loss: 3.013019323348999
Validation loss: 3.037136411154142

Epoch: 5| Step: 5
Training loss: 3.0763392448425293
Validation loss: 3.0224563383286998

Epoch: 5| Step: 6
Training loss: 2.096290111541748
Validation loss: 3.0190603963790403

Epoch: 5| Step: 7
Training loss: 2.998685121536255
Validation loss: 3.015779761857884

Epoch: 5| Step: 8
Training loss: 3.3497474193573
Validation loss: 3.016670088614187

Epoch: 5| Step: 9
Training loss: 3.1498031616210938
Validation loss: 3.0098802351182505

Epoch: 5| Step: 10
Training loss: 3.360388994216919
Validation loss: 3.00008197240932

Epoch: 9| Step: 0
Training loss: 3.7190723419189453
Validation loss: 2.9789535845479658

Epoch: 5| Step: 1
Training loss: 3.0787367820739746
Validation loss: 2.9760989989003828

Epoch: 5| Step: 2
Training loss: 2.3562889099121094
Validation loss: 2.973080265906549

Epoch: 5| Step: 3
Training loss: 2.421400547027588
Validation loss: 2.9670169738031205

Epoch: 5| Step: 4
Training loss: 2.537978410720825
Validation loss: 2.9665515781730734

Epoch: 5| Step: 5
Training loss: 3.1294848918914795
Validation loss: 2.949537282348961

Epoch: 5| Step: 6
Training loss: 3.5898938179016113
Validation loss: 2.9375634013965564

Epoch: 5| Step: 7
Training loss: 2.832399845123291
Validation loss: 2.9525606657869075

Epoch: 5| Step: 8
Training loss: 3.2345833778381348
Validation loss: 2.970350311648461

Epoch: 5| Step: 9
Training loss: 3.1366560459136963
Validation loss: 2.9626165307978147

Epoch: 5| Step: 10
Training loss: 3.412513494491577
Validation loss: 2.922901604765205

Epoch: 10| Step: 0
Training loss: 3.472562313079834
Validation loss: 2.9069341075035835

Epoch: 5| Step: 1
Training loss: 3.3311126232147217
Validation loss: 2.913083391804849

Epoch: 5| Step: 2
Training loss: 2.9560532569885254
Validation loss: 2.9211065692286335

Epoch: 5| Step: 3
Training loss: 2.492034435272217
Validation loss: 2.894638861379316

Epoch: 5| Step: 4
Training loss: 3.5770809650421143
Validation loss: 2.89520203169956

Epoch: 5| Step: 5
Training loss: 3.4317049980163574
Validation loss: 2.900436252676031

Epoch: 5| Step: 6
Training loss: 2.9317238330841064
Validation loss: 2.891508610017838

Epoch: 5| Step: 7
Training loss: 2.291532278060913
Validation loss: 2.879038590256886

Epoch: 5| Step: 8
Training loss: 3.055206775665283
Validation loss: 2.8809888696157806

Epoch: 5| Step: 9
Training loss: 2.9614710807800293
Validation loss: 2.8738739695600284

Epoch: 5| Step: 10
Training loss: 2.3632891178131104
Validation loss: 2.8699571804333757

Epoch: 11| Step: 0
Training loss: 3.7133095264434814
Validation loss: 2.8667142955205773

Epoch: 5| Step: 1
Training loss: 2.8906028270721436
Validation loss: 2.861817611161099

Epoch: 5| Step: 2
Training loss: 3.051529884338379
Validation loss: 2.8579872808148785

Epoch: 5| Step: 3
Training loss: 3.2120652198791504
Validation loss: 2.8551923280121176

Epoch: 5| Step: 4
Training loss: 3.2203152179718018
Validation loss: 2.856377160677346

Epoch: 5| Step: 5
Training loss: 2.550534725189209
Validation loss: 2.854208643718432

Epoch: 5| Step: 6
Training loss: 2.3235416412353516
Validation loss: 2.8501754319795998

Epoch: 5| Step: 7
Training loss: 3.2987091541290283
Validation loss: 2.8434091332138225

Epoch: 5| Step: 8
Training loss: 2.45880389213562
Validation loss: 2.839679776981313

Epoch: 5| Step: 9
Training loss: 3.0006206035614014
Validation loss: 2.833928790143741

Epoch: 5| Step: 10
Training loss: 2.931722640991211
Validation loss: 2.8328635436232372

Epoch: 12| Step: 0
Training loss: 3.1195456981658936
Validation loss: 2.830912184971635

Epoch: 5| Step: 1
Training loss: 3.0891244411468506
Validation loss: 2.8287256148553666

Epoch: 5| Step: 2
Training loss: 2.902245283126831
Validation loss: 2.823924551727951

Epoch: 5| Step: 3
Training loss: 2.156219005584717
Validation loss: 2.8277939288846907

Epoch: 5| Step: 4
Training loss: 2.840012311935425
Validation loss: 2.8236155894494828

Epoch: 5| Step: 5
Training loss: 2.9982523918151855
Validation loss: 2.818116413649692

Epoch: 5| Step: 6
Training loss: 2.7019143104553223
Validation loss: 2.815399467304189

Epoch: 5| Step: 7
Training loss: 3.559645891189575
Validation loss: 2.810426850472727

Epoch: 5| Step: 8
Training loss: 2.7441465854644775
Validation loss: 2.813117991211594

Epoch: 5| Step: 9
Training loss: 3.3001480102539062
Validation loss: 2.8075821450961533

Epoch: 5| Step: 10
Training loss: 2.9776737689971924
Validation loss: 2.803301367708432

Epoch: 13| Step: 0
Training loss: 2.795806884765625
Validation loss: 2.803003795685307

Epoch: 5| Step: 1
Training loss: 2.896737575531006
Validation loss: 2.80492332930206

Epoch: 5| Step: 2
Training loss: 3.1802115440368652
Validation loss: 2.8058576558225896

Epoch: 5| Step: 3
Training loss: 3.8658690452575684
Validation loss: 2.818297550242434

Epoch: 5| Step: 4
Training loss: 2.793224334716797
Validation loss: 2.8189835689401113

Epoch: 5| Step: 5
Training loss: 2.8018264770507812
Validation loss: 2.8031754442440566

Epoch: 5| Step: 6
Training loss: 2.953059196472168
Validation loss: 2.7984276817690943

Epoch: 5| Step: 7
Training loss: 2.443260431289673
Validation loss: 2.793038752771193

Epoch: 5| Step: 8
Training loss: 3.149336338043213
Validation loss: 2.793650524590605

Epoch: 5| Step: 9
Training loss: 2.6529157161712646
Validation loss: 2.8014895659621044

Epoch: 5| Step: 10
Training loss: 2.711787462234497
Validation loss: 2.8035513688159246

Epoch: 14| Step: 0
Training loss: 3.355480909347534
Validation loss: 2.799102460184405

Epoch: 5| Step: 1
Training loss: 2.9711756706237793
Validation loss: 2.7899917376938688

Epoch: 5| Step: 2
Training loss: 3.8607897758483887
Validation loss: 2.7868874431938253

Epoch: 5| Step: 3
Training loss: 2.355071544647217
Validation loss: 2.7851970631589174

Epoch: 5| Step: 4
Training loss: 3.085453510284424
Validation loss: 2.7926951069985666

Epoch: 5| Step: 5
Training loss: 2.740185260772705
Validation loss: 2.793671623353035

Epoch: 5| Step: 6
Training loss: 2.7982001304626465
Validation loss: 2.797677045227379

Epoch: 5| Step: 7
Training loss: 2.847822666168213
Validation loss: 2.801278514246787

Epoch: 5| Step: 8
Training loss: 2.8922855854034424
Validation loss: 2.801213918193694

Epoch: 5| Step: 9
Training loss: 2.5288703441619873
Validation loss: 2.80462727239055

Epoch: 5| Step: 10
Training loss: 2.6917190551757812
Validation loss: 2.7888128321657897

Epoch: 15| Step: 0
Training loss: 3.287905216217041
Validation loss: 2.78631624098747

Epoch: 5| Step: 1
Training loss: 2.623216152191162
Validation loss: 2.784002468150149

Epoch: 5| Step: 2
Training loss: 2.8425240516662598
Validation loss: 2.7804280814304145

Epoch: 5| Step: 3
Training loss: 2.5396790504455566
Validation loss: 2.780926073751142

Epoch: 5| Step: 4
Training loss: 2.4807655811309814
Validation loss: 2.779536703581451

Epoch: 5| Step: 5
Training loss: 3.7534122467041016
Validation loss: 2.7777681786526918

Epoch: 5| Step: 6
Training loss: 2.3915724754333496
Validation loss: 2.7791249085498113

Epoch: 5| Step: 7
Training loss: 2.507511615753174
Validation loss: 2.775766590590118

Epoch: 5| Step: 8
Training loss: 3.3143792152404785
Validation loss: 2.777297104558637

Epoch: 5| Step: 9
Training loss: 3.160737991333008
Validation loss: 2.774104433674966

Epoch: 5| Step: 10
Training loss: 3.1975784301757812
Validation loss: 2.779969705048428

Epoch: 16| Step: 0
Training loss: 2.9397709369659424
Validation loss: 2.7761712356280257

Epoch: 5| Step: 1
Training loss: 2.9642860889434814
Validation loss: 2.768950044467885

Epoch: 5| Step: 2
Training loss: 2.601520538330078
Validation loss: 2.7680045904651767

Epoch: 5| Step: 3
Training loss: 3.20819091796875
Validation loss: 2.767755490477367

Epoch: 5| Step: 4
Training loss: 2.625201940536499
Validation loss: 2.7683521316897486

Epoch: 5| Step: 5
Training loss: 2.5257632732391357
Validation loss: 2.7652556665482058

Epoch: 5| Step: 6
Training loss: 2.6578781604766846
Validation loss: 2.7630103685522593

Epoch: 5| Step: 7
Training loss: 2.889794111251831
Validation loss: 2.765442209859048

Epoch: 5| Step: 8
Training loss: 3.525433301925659
Validation loss: 2.765004878403038

Epoch: 5| Step: 9
Training loss: 2.973215341567993
Validation loss: 2.7630105146797757

Epoch: 5| Step: 10
Training loss: 3.1003258228302
Validation loss: 2.7582310220246673

Epoch: 17| Step: 0
Training loss: 2.4899802207946777
Validation loss: 2.756790325205813

Epoch: 5| Step: 1
Training loss: 3.0297188758850098
Validation loss: 2.7569187123288392

Epoch: 5| Step: 2
Training loss: 2.504049062728882
Validation loss: 2.7548007452359764

Epoch: 5| Step: 3
Training loss: 3.9588851928710938
Validation loss: 2.754051487932923

Epoch: 5| Step: 4
Training loss: 3.0681843757629395
Validation loss: 2.751604351946103

Epoch: 5| Step: 5
Training loss: 3.017826795578003
Validation loss: 2.7530556519826255

Epoch: 5| Step: 6
Training loss: 3.1134707927703857
Validation loss: 2.750932406353694

Epoch: 5| Step: 7
Training loss: 3.0303473472595215
Validation loss: 2.750875667859149

Epoch: 5| Step: 8
Training loss: 2.76908802986145
Validation loss: 2.7486348639252367

Epoch: 5| Step: 9
Training loss: 2.1500861644744873
Validation loss: 2.747667520276962

Epoch: 5| Step: 10
Training loss: 2.6945972442626953
Validation loss: 2.7471516901446926

Epoch: 18| Step: 0
Training loss: 3.4953856468200684
Validation loss: 2.745949555468816

Epoch: 5| Step: 1
Training loss: 3.4380927085876465
Validation loss: 2.7443832287224392

Epoch: 5| Step: 2
Training loss: 2.4334397315979004
Validation loss: 2.748470765288158

Epoch: 5| Step: 3
Training loss: 2.435702085494995
Validation loss: 2.743519603565175

Epoch: 5| Step: 4
Training loss: 3.7365665435791016
Validation loss: 2.7455517015149518

Epoch: 5| Step: 5
Training loss: 3.1818087100982666
Validation loss: 2.7464777449125886

Epoch: 5| Step: 6
Training loss: 2.637155055999756
Validation loss: 2.7393768628438315

Epoch: 5| Step: 7
Training loss: 2.6597375869750977
Validation loss: 2.739234185987903

Epoch: 5| Step: 8
Training loss: 3.0906877517700195
Validation loss: 2.7366790925302813

Epoch: 5| Step: 9
Training loss: 2.569188117980957
Validation loss: 2.7336767437637493

Epoch: 5| Step: 10
Training loss: 1.9301559925079346
Validation loss: 2.7362907112285657

Epoch: 19| Step: 0
Training loss: 2.715181827545166
Validation loss: 2.735775891170707

Epoch: 5| Step: 1
Training loss: 3.038081645965576
Validation loss: 2.7320667082263577

Epoch: 5| Step: 2
Training loss: 2.824744462966919
Validation loss: 2.733510196849864

Epoch: 5| Step: 3
Training loss: 2.8973121643066406
Validation loss: 2.73329742493168

Epoch: 5| Step: 4
Training loss: 1.9732393026351929
Validation loss: 2.7345415597320883

Epoch: 5| Step: 5
Training loss: 3.280532121658325
Validation loss: 2.73572366212004

Epoch: 5| Step: 6
Training loss: 3.17022442817688
Validation loss: 2.7604553212401686

Epoch: 5| Step: 7
Training loss: 2.167828321456909
Validation loss: 2.8183216382098455

Epoch: 5| Step: 8
Training loss: 3.6462454795837402
Validation loss: 2.882101361469556

Epoch: 5| Step: 9
Training loss: 3.233699083328247
Validation loss: 2.812511162091327

Epoch: 5| Step: 10
Training loss: 2.98545503616333
Validation loss: 2.7675939939355336

Epoch: 20| Step: 0
Training loss: 3.0823657512664795
Validation loss: 2.7757659419890373

Epoch: 5| Step: 1
Training loss: 2.4545812606811523
Validation loss: 2.7902466635550223

Epoch: 5| Step: 2
Training loss: 2.9098172187805176
Validation loss: 2.7849344284303728

Epoch: 5| Step: 3
Training loss: 2.7330410480499268
Validation loss: 2.751779986966041

Epoch: 5| Step: 4
Training loss: 2.151916980743408
Validation loss: 2.7651130973651843

Epoch: 5| Step: 5
Training loss: 3.504085063934326
Validation loss: 2.7701102277284027

Epoch: 5| Step: 6
Training loss: 3.209888458251953
Validation loss: 2.7638104359308877

Epoch: 5| Step: 7
Training loss: 2.8408761024475098
Validation loss: 2.74511916406693

Epoch: 5| Step: 8
Training loss: 2.9927473068237305
Validation loss: 2.7410610029774327

Epoch: 5| Step: 9
Training loss: 3.1471076011657715
Validation loss: 2.740141289208525

Epoch: 5| Step: 10
Training loss: 2.78790283203125
Validation loss: 2.729303567640243

Epoch: 21| Step: 0
Training loss: 2.9660637378692627
Validation loss: 2.7324492598092682

Epoch: 5| Step: 1
Training loss: 2.2062647342681885
Validation loss: 2.7470980613462386

Epoch: 5| Step: 2
Training loss: 3.0808303356170654
Validation loss: 2.7431579097624748

Epoch: 5| Step: 3
Training loss: 3.0585904121398926
Validation loss: 2.7376981396828928

Epoch: 5| Step: 4
Training loss: 2.997016429901123
Validation loss: 2.724278760212724

Epoch: 5| Step: 5
Training loss: 3.202725887298584
Validation loss: 2.7173598171562277

Epoch: 5| Step: 6
Training loss: 2.691260814666748
Validation loss: 2.7159183294542375

Epoch: 5| Step: 7
Training loss: 2.4353585243225098
Validation loss: 2.7147504309172272

Epoch: 5| Step: 8
Training loss: 3.8974947929382324
Validation loss: 2.7154195154866865

Epoch: 5| Step: 9
Training loss: 2.065084934234619
Validation loss: 2.7151775206288984

Epoch: 5| Step: 10
Training loss: 3.020118236541748
Validation loss: 2.7176504340223087

Epoch: 22| Step: 0
Training loss: 2.649949789047241
Validation loss: 2.72390180249368

Epoch: 5| Step: 1
Training loss: 2.535443067550659
Validation loss: 2.737072708786175

Epoch: 5| Step: 2
Training loss: 1.9762580394744873
Validation loss: 2.7156899949555755

Epoch: 5| Step: 3
Training loss: 3.0382132530212402
Validation loss: 2.713057218059417

Epoch: 5| Step: 4
Training loss: 3.0680434703826904
Validation loss: 2.707788593025618

Epoch: 5| Step: 5
Training loss: 3.1925785541534424
Validation loss: 2.7070035190992456

Epoch: 5| Step: 6
Training loss: 2.950878620147705
Validation loss: 2.7057058580460085

Epoch: 5| Step: 7
Training loss: 3.492785692214966
Validation loss: 2.7054396265296528

Epoch: 5| Step: 8
Training loss: 2.446030855178833
Validation loss: 2.705881313611102

Epoch: 5| Step: 9
Training loss: 3.383841037750244
Validation loss: 2.701210865410425

Epoch: 5| Step: 10
Training loss: 2.722130298614502
Validation loss: 2.700045149813416

Epoch: 23| Step: 0
Training loss: 2.4756855964660645
Validation loss: 2.7023203014045634

Epoch: 5| Step: 1
Training loss: 3.5186245441436768
Validation loss: 2.701009945202899

Epoch: 5| Step: 2
Training loss: 3.0884408950805664
Validation loss: 2.6981657192271244

Epoch: 5| Step: 3
Training loss: 2.794455051422119
Validation loss: 2.6999099664790656

Epoch: 5| Step: 4
Training loss: 2.7615437507629395
Validation loss: 2.6943024332805345

Epoch: 5| Step: 5
Training loss: 2.2290310859680176
Validation loss: 2.694389466316469

Epoch: 5| Step: 6
Training loss: 2.8292555809020996
Validation loss: 2.6882256461728002

Epoch: 5| Step: 7
Training loss: 2.799805164337158
Validation loss: 2.687106442707841

Epoch: 5| Step: 8
Training loss: 3.1613190174102783
Validation loss: 2.688200440458072

Epoch: 5| Step: 9
Training loss: 2.7948155403137207
Validation loss: 2.6858854832187777

Epoch: 5| Step: 10
Training loss: 2.826470375061035
Validation loss: 2.6864822885041595

Epoch: 24| Step: 0
Training loss: 1.882035493850708
Validation loss: 2.6829782532107447

Epoch: 5| Step: 1
Training loss: 3.3946633338928223
Validation loss: 2.6828678423358547

Epoch: 5| Step: 2
Training loss: 2.923588275909424
Validation loss: 2.6816097613303893

Epoch: 5| Step: 3
Training loss: 2.8735897541046143
Validation loss: 2.678348959133189

Epoch: 5| Step: 4
Training loss: 3.0828731060028076
Validation loss: 2.673665646583803

Epoch: 5| Step: 5
Training loss: 2.952162504196167
Validation loss: 2.6705429502712783

Epoch: 5| Step: 6
Training loss: 2.4675564765930176
Validation loss: 2.669708900554206

Epoch: 5| Step: 7
Training loss: 2.5753719806671143
Validation loss: 2.67174925855411

Epoch: 5| Step: 8
Training loss: 3.585632801055908
Validation loss: 2.6779063158137824

Epoch: 5| Step: 9
Training loss: 2.4630818367004395
Validation loss: 2.6821285217039046

Epoch: 5| Step: 10
Training loss: 3.038029670715332
Validation loss: 2.673646257769677

Epoch: 25| Step: 0
Training loss: 2.640864610671997
Validation loss: 2.662808705401677

Epoch: 5| Step: 1
Training loss: 2.743248701095581
Validation loss: 2.6650716361179145

Epoch: 5| Step: 2
Training loss: 2.3731188774108887
Validation loss: 2.6650494144808863

Epoch: 5| Step: 3
Training loss: 3.0622963905334473
Validation loss: 2.664603820411108

Epoch: 5| Step: 4
Training loss: 2.5967326164245605
Validation loss: 2.6644060047723914

Epoch: 5| Step: 5
Training loss: 2.9604554176330566
Validation loss: 2.662022821364864

Epoch: 5| Step: 6
Training loss: 2.76564884185791
Validation loss: 2.6622462734099357

Epoch: 5| Step: 7
Training loss: 2.8727011680603027
Validation loss: 2.6688216168393373

Epoch: 5| Step: 8
Training loss: 3.0905404090881348
Validation loss: 2.6736804208447857

Epoch: 5| Step: 9
Training loss: 2.851780891418457
Validation loss: 2.685320090222102

Epoch: 5| Step: 10
Training loss: 3.2341160774230957
Validation loss: 2.6788480512557493

Epoch: 26| Step: 0
Training loss: 3.1495349407196045
Validation loss: 2.6623169529822563

Epoch: 5| Step: 1
Training loss: 2.8379123210906982
Validation loss: 2.6530015673688663

Epoch: 5| Step: 2
Training loss: 2.3976855278015137
Validation loss: 2.6561704374128774

Epoch: 5| Step: 3
Training loss: 2.930840492248535
Validation loss: 2.659232549769904

Epoch: 5| Step: 4
Training loss: 3.233372449874878
Validation loss: 2.6707263197950137

Epoch: 5| Step: 5
Training loss: 3.1968836784362793
Validation loss: 2.6643480998213573

Epoch: 5| Step: 6
Training loss: 3.608922243118286
Validation loss: 2.6557552250482703

Epoch: 5| Step: 7
Training loss: 3.165135622024536
Validation loss: 2.6457068381770963

Epoch: 5| Step: 8
Training loss: 2.1447243690490723
Validation loss: 2.6508310353884132

Epoch: 5| Step: 9
Training loss: 2.440049409866333
Validation loss: 2.6623947440937

Epoch: 5| Step: 10
Training loss: 1.8262097835540771
Validation loss: 2.676283697928152

Epoch: 27| Step: 0
Training loss: 2.6270089149475098
Validation loss: 2.6796894611850863

Epoch: 5| Step: 1
Training loss: 2.749804735183716
Validation loss: 2.676773596835393

Epoch: 5| Step: 2
Training loss: 2.769779682159424
Validation loss: 2.646743502668155

Epoch: 5| Step: 3
Training loss: 3.3763694763183594
Validation loss: 2.6334625239013345

Epoch: 5| Step: 4
Training loss: 2.722809314727783
Validation loss: 2.6387575672518824

Epoch: 5| Step: 5
Training loss: 2.8122973442077637
Validation loss: 2.6321139386905137

Epoch: 5| Step: 6
Training loss: 3.226130723953247
Validation loss: 2.631842992639029

Epoch: 5| Step: 7
Training loss: 2.487997531890869
Validation loss: 2.638043483098348

Epoch: 5| Step: 8
Training loss: 2.463993549346924
Validation loss: 2.642100795622795

Epoch: 5| Step: 9
Training loss: 3.026681900024414
Validation loss: 2.6390668012762584

Epoch: 5| Step: 10
Training loss: 2.6459336280822754
Validation loss: 2.636567772075694

Epoch: 28| Step: 0
Training loss: 2.0881965160369873
Validation loss: 2.625816781033752

Epoch: 5| Step: 1
Training loss: 2.800260066986084
Validation loss: 2.625916491272629

Epoch: 5| Step: 2
Training loss: 2.6558432579040527
Validation loss: 2.622199922479609

Epoch: 5| Step: 3
Training loss: 2.7578158378601074
Validation loss: 2.6210650372248825

Epoch: 5| Step: 4
Training loss: 2.554380178451538
Validation loss: 2.621640738620553

Epoch: 5| Step: 5
Training loss: 2.832496166229248
Validation loss: 2.619520894942745

Epoch: 5| Step: 6
Training loss: 2.9884960651397705
Validation loss: 2.617105837791197

Epoch: 5| Step: 7
Training loss: 2.91339373588562
Validation loss: 2.6195669379285587

Epoch: 5| Step: 8
Training loss: 2.948040723800659
Validation loss: 2.6251488526662192

Epoch: 5| Step: 9
Training loss: 2.9066944122314453
Validation loss: 2.6219726788100375

Epoch: 5| Step: 10
Training loss: 3.3229751586914062
Validation loss: 2.618649959564209

Epoch: 29| Step: 0
Training loss: 3.019824504852295
Validation loss: 2.6256653544723347

Epoch: 5| Step: 1
Training loss: 3.0604052543640137
Validation loss: 2.6228873780978623

Epoch: 5| Step: 2
Training loss: 2.7899410724639893
Validation loss: 2.6336466676445416

Epoch: 5| Step: 3
Training loss: 2.81852388381958
Validation loss: 2.6694074984519713

Epoch: 5| Step: 4
Training loss: 3.049144983291626
Validation loss: 2.6475710689380603

Epoch: 5| Step: 5
Training loss: 2.361070156097412
Validation loss: 2.6012096276847263

Epoch: 5| Step: 6
Training loss: 2.5210750102996826
Validation loss: 2.60708979124664

Epoch: 5| Step: 7
Training loss: 3.507972002029419
Validation loss: 2.610147970978932

Epoch: 5| Step: 8
Training loss: 2.2818827629089355
Validation loss: 2.613991350255987

Epoch: 5| Step: 9
Training loss: 2.386390447616577
Validation loss: 2.6162539784626295

Epoch: 5| Step: 10
Training loss: 3.029977798461914
Validation loss: 2.6204572646848616

Epoch: 30| Step: 0
Training loss: 3.055436611175537
Validation loss: 2.637299809404599

Epoch: 5| Step: 1
Training loss: 2.612765312194824
Validation loss: 2.658756579122236

Epoch: 5| Step: 2
Training loss: 2.7085986137390137
Validation loss: 2.6584280870294057

Epoch: 5| Step: 3
Training loss: 2.868151903152466
Validation loss: 2.648447039306805

Epoch: 5| Step: 4
Training loss: 2.204909086227417
Validation loss: 2.6336777979327786

Epoch: 5| Step: 5
Training loss: 2.6423115730285645
Validation loss: 2.6198916742878575

Epoch: 5| Step: 6
Training loss: 2.2183961868286133
Validation loss: 2.610280304826716

Epoch: 5| Step: 7
Training loss: 3.5692660808563232
Validation loss: 2.6108135510516424

Epoch: 5| Step: 8
Training loss: 2.6315417289733887
Validation loss: 2.598863258156725

Epoch: 5| Step: 9
Training loss: 3.030911684036255
Validation loss: 2.596143727661461

Epoch: 5| Step: 10
Training loss: 3.2100460529327393
Validation loss: 2.602282959927795

Epoch: 31| Step: 0
Training loss: 3.040278434753418
Validation loss: 2.6000788314368135

Epoch: 5| Step: 1
Training loss: 2.7908918857574463
Validation loss: 2.5940866393427693

Epoch: 5| Step: 2
Training loss: 2.6259326934814453
Validation loss: 2.588933637065272

Epoch: 5| Step: 3
Training loss: 2.928676128387451
Validation loss: 2.590595324834188

Epoch: 5| Step: 4
Training loss: 2.217634916305542
Validation loss: 2.586220209316541

Epoch: 5| Step: 5
Training loss: 2.7058749198913574
Validation loss: 2.589213535349856

Epoch: 5| Step: 6
Training loss: 2.9378209114074707
Validation loss: 2.5885173607898015

Epoch: 5| Step: 7
Training loss: 2.732297420501709
Validation loss: 2.5909908228023077

Epoch: 5| Step: 8
Training loss: 2.8393893241882324
Validation loss: 2.589327255884806

Epoch: 5| Step: 9
Training loss: 2.8026282787323
Validation loss: 2.586498442516532

Epoch: 5| Step: 10
Training loss: 2.8717381954193115
Validation loss: 2.584994104600722

Epoch: 32| Step: 0
Training loss: 2.6124625205993652
Validation loss: 2.589058586346206

Epoch: 5| Step: 1
Training loss: 2.548430919647217
Validation loss: 2.6004579118503037

Epoch: 5| Step: 2
Training loss: 3.0603723526000977
Validation loss: 2.5966461781532533

Epoch: 5| Step: 3
Training loss: 2.437143325805664
Validation loss: 2.5807091523242254

Epoch: 5| Step: 4
Training loss: 2.5654170513153076
Validation loss: 2.585246983394828

Epoch: 5| Step: 5
Training loss: 2.8790650367736816
Validation loss: 2.590887595248479

Epoch: 5| Step: 6
Training loss: 2.7681822776794434
Validation loss: 2.597240932526127

Epoch: 5| Step: 7
Training loss: 3.146583080291748
Validation loss: 2.637009028465517

Epoch: 5| Step: 8
Training loss: 2.963994026184082
Validation loss: 2.6307128475558375

Epoch: 5| Step: 9
Training loss: 3.0687546730041504
Validation loss: 2.5981169644222466

Epoch: 5| Step: 10
Training loss: 2.300466775894165
Validation loss: 2.5921005202877905

Epoch: 33| Step: 0
Training loss: 3.415631055831909
Validation loss: 2.592695641261275

Epoch: 5| Step: 1
Training loss: 2.5244064331054688
Validation loss: 2.5829580009624524

Epoch: 5| Step: 2
Training loss: 2.9174840450286865
Validation loss: 2.5798381656728764

Epoch: 5| Step: 3
Training loss: 2.9553487300872803
Validation loss: 2.5749426093152774

Epoch: 5| Step: 4
Training loss: 2.496321439743042
Validation loss: 2.5778283047419723

Epoch: 5| Step: 5
Training loss: 3.1957802772521973
Validation loss: 2.5759634869073027

Epoch: 5| Step: 6
Training loss: 2.2853286266326904
Validation loss: 2.5727103038500716

Epoch: 5| Step: 7
Training loss: 2.4852054119110107
Validation loss: 2.5765123418582383

Epoch: 5| Step: 8
Training loss: 3.052623748779297
Validation loss: 2.5815802517757622

Epoch: 5| Step: 9
Training loss: 2.5489230155944824
Validation loss: 2.587086608332972

Epoch: 5| Step: 10
Training loss: 2.381758689880371
Validation loss: 2.592727884169548

Epoch: 34| Step: 0
Training loss: 2.609783887863159
Validation loss: 2.6086183542846353

Epoch: 5| Step: 1
Training loss: 2.8907041549682617
Validation loss: 2.6181045014371156

Epoch: 5| Step: 2
Training loss: 2.857365131378174
Validation loss: 2.5859337981029222

Epoch: 5| Step: 3
Training loss: 2.2464749813079834
Validation loss: 2.571251197527814

Epoch: 5| Step: 4
Training loss: 2.528595447540283
Validation loss: 2.566526074563303

Epoch: 5| Step: 5
Training loss: 3.018538475036621
Validation loss: 2.565099831550352

Epoch: 5| Step: 6
Training loss: 2.6312317848205566
Validation loss: 2.5702937597869546

Epoch: 5| Step: 7
Training loss: 2.812178611755371
Validation loss: 2.568280989123929

Epoch: 5| Step: 8
Training loss: 2.862163782119751
Validation loss: 2.5609189771836802

Epoch: 5| Step: 9
Training loss: 3.433687686920166
Validation loss: 2.554735614407447

Epoch: 5| Step: 10
Training loss: 2.4798521995544434
Validation loss: 2.552248816336355

Epoch: 35| Step: 0
Training loss: 3.249607801437378
Validation loss: 2.5521126870186097

Epoch: 5| Step: 1
Training loss: 2.6843714714050293
Validation loss: 2.557954590807679

Epoch: 5| Step: 2
Training loss: 2.948012351989746
Validation loss: 2.564798811430572

Epoch: 5| Step: 3
Training loss: 2.5364651679992676
Validation loss: 2.5678945100435646

Epoch: 5| Step: 4
Training loss: 3.157564163208008
Validation loss: 2.5675423196567

Epoch: 5| Step: 5
Training loss: 2.518932342529297
Validation loss: 2.5632417150723037

Epoch: 5| Step: 6
Training loss: 2.96710467338562
Validation loss: 2.5614032924816175

Epoch: 5| Step: 7
Training loss: 2.435515880584717
Validation loss: 2.5604023548864547

Epoch: 5| Step: 8
Training loss: 2.524839401245117
Validation loss: 2.563885465745003

Epoch: 5| Step: 9
Training loss: 2.566749095916748
Validation loss: 2.5622079962043354

Epoch: 5| Step: 10
Training loss: 2.495464324951172
Validation loss: 2.5502134805084555

Epoch: 36| Step: 0
Training loss: 2.371642827987671
Validation loss: 2.5483033657073975

Epoch: 5| Step: 1
Training loss: 3.4329349994659424
Validation loss: 2.543468403559859

Epoch: 5| Step: 2
Training loss: 2.023655652999878
Validation loss: 2.5477484913282495

Epoch: 5| Step: 3
Training loss: 2.12069034576416
Validation loss: 2.5494492438531693

Epoch: 5| Step: 4
Training loss: 3.1169328689575195
Validation loss: 2.5474257264085995

Epoch: 5| Step: 5
Training loss: 2.6459696292877197
Validation loss: 2.5479797881136657

Epoch: 5| Step: 6
Training loss: 2.8092408180236816
Validation loss: 2.5537127141029603

Epoch: 5| Step: 7
Training loss: 3.283750057220459
Validation loss: 2.55561843738761

Epoch: 5| Step: 8
Training loss: 2.900113105773926
Validation loss: 2.567175417818049

Epoch: 5| Step: 9
Training loss: 2.4950945377349854
Validation loss: 2.5946587721506753

Epoch: 5| Step: 10
Training loss: 3.0053305625915527
Validation loss: 2.642240165382303

Epoch: 37| Step: 0
Training loss: 3.0354866981506348
Validation loss: 2.6389119702000774

Epoch: 5| Step: 1
Training loss: 2.497335910797119
Validation loss: 2.5979997470814693

Epoch: 5| Step: 2
Training loss: 2.822993516921997
Validation loss: 2.588231840441304

Epoch: 5| Step: 3
Training loss: 2.300096035003662
Validation loss: 2.571689354476108

Epoch: 5| Step: 4
Training loss: 2.4971508979797363
Validation loss: 2.5604475826345463

Epoch: 5| Step: 5
Training loss: 2.027907133102417
Validation loss: 2.555687048101938

Epoch: 5| Step: 6
Training loss: 3.5080666542053223
Validation loss: 2.5505931736320577

Epoch: 5| Step: 7
Training loss: 3.2307960987091064
Validation loss: 2.5405726714800765

Epoch: 5| Step: 8
Training loss: 2.2135889530181885
Validation loss: 2.5420758108938895

Epoch: 5| Step: 9
Training loss: 2.9399399757385254
Validation loss: 2.5484656287777807

Epoch: 5| Step: 10
Training loss: 3.093257188796997
Validation loss: 2.553238445712674

Epoch: 38| Step: 0
Training loss: 2.44942045211792
Validation loss: 2.5551095444669008

Epoch: 5| Step: 1
Training loss: 2.9888455867767334
Validation loss: 2.6041867194637174

Epoch: 5| Step: 2
Training loss: 2.6431221961975098
Validation loss: 2.6416482515232538

Epoch: 5| Step: 3
Training loss: 2.919344186782837
Validation loss: 2.608374577696605

Epoch: 5| Step: 4
Training loss: 2.655414581298828
Validation loss: 2.581613984159244

Epoch: 5| Step: 5
Training loss: 2.365251302719116
Validation loss: 2.5547500989770375

Epoch: 5| Step: 6
Training loss: 2.707430839538574
Validation loss: 2.5396579029739543

Epoch: 5| Step: 7
Training loss: 2.9071059226989746
Validation loss: 2.5400523703585387

Epoch: 5| Step: 8
Training loss: 2.545186996459961
Validation loss: 2.5416904828881703

Epoch: 5| Step: 9
Training loss: 2.876878261566162
Validation loss: 2.5665021609234553

Epoch: 5| Step: 10
Training loss: 3.097987174987793
Validation loss: 2.5800468203842

Epoch: 39| Step: 0
Training loss: 2.6650023460388184
Validation loss: 2.5636086720292286

Epoch: 5| Step: 1
Training loss: 2.7944626808166504
Validation loss: 2.5388348205115205

Epoch: 5| Step: 2
Training loss: 2.958691120147705
Validation loss: 2.5307254534895702

Epoch: 5| Step: 3
Training loss: 2.707949161529541
Validation loss: 2.527412958042596

Epoch: 5| Step: 4
Training loss: 2.40348482131958
Validation loss: 2.534492414484742

Epoch: 5| Step: 5
Training loss: 2.4443564414978027
Validation loss: 2.5445785240460466

Epoch: 5| Step: 6
Training loss: 2.2898478507995605
Validation loss: 2.5409578841219664

Epoch: 5| Step: 7
Training loss: 3.3826003074645996
Validation loss: 2.542875656517603

Epoch: 5| Step: 8
Training loss: 2.6854307651519775
Validation loss: 2.536050852908883

Epoch: 5| Step: 9
Training loss: 3.2837283611297607
Validation loss: 2.536301125762283

Epoch: 5| Step: 10
Training loss: 2.203535556793213
Validation loss: 2.5390743106924076

Epoch: 40| Step: 0
Training loss: 3.018281936645508
Validation loss: 2.5465620204966557

Epoch: 5| Step: 1
Training loss: 3.1117491722106934
Validation loss: 2.5492811356821368

Epoch: 5| Step: 2
Training loss: 1.8632497787475586
Validation loss: 2.5490617470074723

Epoch: 5| Step: 3
Training loss: 2.502772331237793
Validation loss: 2.5229410433000132

Epoch: 5| Step: 4
Training loss: 2.2507967948913574
Validation loss: 2.51208681701332

Epoch: 5| Step: 5
Training loss: 3.2567996978759766
Validation loss: 2.516137989618445

Epoch: 5| Step: 6
Training loss: 3.0955662727355957
Validation loss: 2.5153266127391527

Epoch: 5| Step: 7
Training loss: 2.7060937881469727
Validation loss: 2.5165025162440475

Epoch: 5| Step: 8
Training loss: 3.058138370513916
Validation loss: 2.510100200612058

Epoch: 5| Step: 9
Training loss: 2.0618109703063965
Validation loss: 2.517104466756185

Epoch: 5| Step: 10
Training loss: 2.8807289600372314
Validation loss: 2.5181392905532674

Epoch: 41| Step: 0
Training loss: 2.7199013233184814
Validation loss: 2.5165125426425727

Epoch: 5| Step: 1
Training loss: 2.4934239387512207
Validation loss: 2.513197211809056

Epoch: 5| Step: 2
Training loss: 3.32453989982605
Validation loss: 2.510558488548443

Epoch: 5| Step: 3
Training loss: 2.3645055294036865
Validation loss: 2.5091671200208765

Epoch: 5| Step: 4
Training loss: 3.01560640335083
Validation loss: 2.507346425005185

Epoch: 5| Step: 5
Training loss: 2.3918256759643555
Validation loss: 2.507517291653541

Epoch: 5| Step: 6
Training loss: 2.5174736976623535
Validation loss: 2.50439985721342

Epoch: 5| Step: 7
Training loss: 2.6896169185638428
Validation loss: 2.5075267463602047

Epoch: 5| Step: 8
Training loss: 2.4879913330078125
Validation loss: 2.508128253362512

Epoch: 5| Step: 9
Training loss: 2.8490943908691406
Validation loss: 2.5056459237170476

Epoch: 5| Step: 10
Training loss: 2.9826080799102783
Validation loss: 2.5053486413853143

Epoch: 42| Step: 0
Training loss: 2.7888481616973877
Validation loss: 2.522104524797009

Epoch: 5| Step: 1
Training loss: 2.6237149238586426
Validation loss: 2.5371016635689685

Epoch: 5| Step: 2
Training loss: 2.533245801925659
Validation loss: 2.5384297781093146

Epoch: 5| Step: 3
Training loss: 2.674677610397339
Validation loss: 2.533447495070837

Epoch: 5| Step: 4
Training loss: 3.108333110809326
Validation loss: 2.533056902629073

Epoch: 5| Step: 5
Training loss: 2.636535882949829
Validation loss: 2.526755245782996

Epoch: 5| Step: 6
Training loss: 2.855515718460083
Validation loss: 2.518601555978098

Epoch: 5| Step: 7
Training loss: 2.4537675380706787
Validation loss: 2.5170062152288293

Epoch: 5| Step: 8
Training loss: 2.1014938354492188
Validation loss: 2.513563856001823

Epoch: 5| Step: 9
Training loss: 3.0479671955108643
Validation loss: 2.5095822465035225

Epoch: 5| Step: 10
Training loss: 2.858325481414795
Validation loss: 2.5189229390954457

Epoch: 43| Step: 0
Training loss: 2.6115920543670654
Validation loss: 2.5174734951347433

Epoch: 5| Step: 1
Training loss: 2.995720148086548
Validation loss: 2.5169342922908005

Epoch: 5| Step: 2
Training loss: 2.6922574043273926
Validation loss: 2.5249422186164447

Epoch: 5| Step: 3
Training loss: 2.5417187213897705
Validation loss: 2.5115006790366223

Epoch: 5| Step: 4
Training loss: 3.0558857917785645
Validation loss: 2.4993911199672247

Epoch: 5| Step: 5
Training loss: 2.4666895866394043
Validation loss: 2.4975614650275118

Epoch: 5| Step: 6
Training loss: 2.500546455383301
Validation loss: 2.4955347173957416

Epoch: 5| Step: 7
Training loss: 2.779268980026245
Validation loss: 2.4972722914911087

Epoch: 5| Step: 8
Training loss: 2.075313091278076
Validation loss: 2.4916470191812

Epoch: 5| Step: 9
Training loss: 3.519601821899414
Validation loss: 2.489339529827077

Epoch: 5| Step: 10
Training loss: 2.4540493488311768
Validation loss: 2.4886826751052693

Epoch: 44| Step: 0
Training loss: 2.9763894081115723
Validation loss: 2.4939600293354323

Epoch: 5| Step: 1
Training loss: 2.430295944213867
Validation loss: 2.515450959564537

Epoch: 5| Step: 2
Training loss: 2.6148197650909424
Validation loss: 2.5178023358826995

Epoch: 5| Step: 3
Training loss: 2.9527721405029297
Validation loss: 2.5049334572207544

Epoch: 5| Step: 4
Training loss: 2.5290777683258057
Validation loss: 2.494424248254427

Epoch: 5| Step: 5
Training loss: 3.0041167736053467
Validation loss: 2.487520799841932

Epoch: 5| Step: 6
Training loss: 1.6328786611557007
Validation loss: 2.490056986449867

Epoch: 5| Step: 7
Training loss: 2.86299729347229
Validation loss: 2.4890825748443604

Epoch: 5| Step: 8
Training loss: 3.157421827316284
Validation loss: 2.4921129365121164

Epoch: 5| Step: 9
Training loss: 2.476809501647949
Validation loss: 2.5011337905801754

Epoch: 5| Step: 10
Training loss: 2.941270112991333
Validation loss: 2.508554345817976

Epoch: 45| Step: 0
Training loss: 2.2063345909118652
Validation loss: 2.5578183461261053

Epoch: 5| Step: 1
Training loss: 3.0882697105407715
Validation loss: 2.607424933423278

Epoch: 5| Step: 2
Training loss: 2.9668357372283936
Validation loss: 2.555143189686601

Epoch: 5| Step: 3
Training loss: 3.1115198135375977
Validation loss: 2.509335587101598

Epoch: 5| Step: 4
Training loss: 2.6249094009399414
Validation loss: 2.4901971483743317

Epoch: 5| Step: 5
Training loss: 3.0518062114715576
Validation loss: 2.4807611665418072

Epoch: 5| Step: 6
Training loss: 2.175374746322632
Validation loss: 2.495141444667693

Epoch: 5| Step: 7
Training loss: 2.74680757522583
Validation loss: 2.524393545683994

Epoch: 5| Step: 8
Training loss: 2.4900736808776855
Validation loss: 2.522539266975977

Epoch: 5| Step: 9
Training loss: 3.0439720153808594
Validation loss: 2.4917889461722424

Epoch: 5| Step: 10
Training loss: 2.4237239360809326
Validation loss: 2.479103419088548

Epoch: 46| Step: 0
Training loss: 2.788750171661377
Validation loss: 2.486575162538918

Epoch: 5| Step: 1
Training loss: 2.862377643585205
Validation loss: 2.484892483680479

Epoch: 5| Step: 2
Training loss: 2.191230297088623
Validation loss: 2.4894209830991683

Epoch: 5| Step: 3
Training loss: 3.089351177215576
Validation loss: 2.493133088593842

Epoch: 5| Step: 4
Training loss: 2.2316644191741943
Validation loss: 2.5040921216369956

Epoch: 5| Step: 5
Training loss: 2.1959991455078125
Validation loss: 2.5114102004676737

Epoch: 5| Step: 6
Training loss: 2.064713478088379
Validation loss: 2.56447801538693

Epoch: 5| Step: 7
Training loss: 2.1687488555908203
Validation loss: 2.5551365319118706

Epoch: 5| Step: 8
Training loss: 3.2007973194122314
Validation loss: 2.567698786335607

Epoch: 5| Step: 9
Training loss: 3.509112596511841
Validation loss: 2.536432650781447

Epoch: 5| Step: 10
Training loss: 3.6006672382354736
Validation loss: 2.521850447500906

Epoch: 47| Step: 0
Training loss: 2.6005749702453613
Validation loss: 2.4846914147817962

Epoch: 5| Step: 1
Training loss: 2.939086437225342
Validation loss: 2.480029757304858

Epoch: 5| Step: 2
Training loss: 3.7083258628845215
Validation loss: 2.4761347155417166

Epoch: 5| Step: 3
Training loss: 2.1649727821350098
Validation loss: 2.495354906205208

Epoch: 5| Step: 4
Training loss: 2.569286584854126
Validation loss: 2.517801441172118

Epoch: 5| Step: 5
Training loss: 2.865640640258789
Validation loss: 2.513871733860303

Epoch: 5| Step: 6
Training loss: 3.126481533050537
Validation loss: 2.475545621687366

Epoch: 5| Step: 7
Training loss: 1.909751534461975
Validation loss: 2.4713813104937152

Epoch: 5| Step: 8
Training loss: 2.9871058464050293
Validation loss: 2.471327309967369

Epoch: 5| Step: 9
Training loss: 2.2783875465393066
Validation loss: 2.473450227450299

Epoch: 5| Step: 10
Training loss: 2.507227897644043
Validation loss: 2.4965495499231483

Epoch: 48| Step: 0
Training loss: 3.1003665924072266
Validation loss: 2.5691638390223184

Epoch: 5| Step: 1
Training loss: 2.840757369995117
Validation loss: 2.6213028712939193

Epoch: 5| Step: 2
Training loss: 2.340111255645752
Validation loss: 2.612997119144727

Epoch: 5| Step: 3
Training loss: 2.7335801124572754
Validation loss: 2.5948690470828804

Epoch: 5| Step: 4
Training loss: 2.6975512504577637
Validation loss: 2.5341144992459204

Epoch: 5| Step: 5
Training loss: 2.7274692058563232
Validation loss: 2.4858819925656883

Epoch: 5| Step: 6
Training loss: 2.5622143745422363
Validation loss: 2.467749539241996

Epoch: 5| Step: 7
Training loss: 2.4837703704833984
Validation loss: 2.4679220158566713

Epoch: 5| Step: 8
Training loss: 2.5231761932373047
Validation loss: 2.4845878462637625

Epoch: 5| Step: 9
Training loss: 3.1003682613372803
Validation loss: 2.5460123861989667

Epoch: 5| Step: 10
Training loss: 2.8418819904327393
Validation loss: 2.5138239450352167

Epoch: 49| Step: 0
Training loss: 2.1072487831115723
Validation loss: 2.517373582368256

Epoch: 5| Step: 1
Training loss: 3.3118796348571777
Validation loss: 2.5404676545050835

Epoch: 5| Step: 2
Training loss: 2.2130208015441895
Validation loss: 2.509270962848458

Epoch: 5| Step: 3
Training loss: 2.814177989959717
Validation loss: 2.483400883213166

Epoch: 5| Step: 4
Training loss: 2.6015639305114746
Validation loss: 2.4656859802943405

Epoch: 5| Step: 5
Training loss: 2.566718578338623
Validation loss: 2.466542213193832

Epoch: 5| Step: 6
Training loss: 2.3183562755584717
Validation loss: 2.470405868304673

Epoch: 5| Step: 7
Training loss: 2.8555331230163574
Validation loss: 2.4984672607914096

Epoch: 5| Step: 8
Training loss: 2.6749470233917236
Validation loss: 2.5346179277666154

Epoch: 5| Step: 9
Training loss: 3.807058334350586
Validation loss: 2.5212913328601467

Epoch: 5| Step: 10
Training loss: 2.4718759059906006
Validation loss: 2.493670076452276

Epoch: 50| Step: 0
Training loss: 2.502513885498047
Validation loss: 2.4849302614888837

Epoch: 5| Step: 1
Training loss: 3.0613980293273926
Validation loss: 2.4716943156334663

Epoch: 5| Step: 2
Training loss: 3.2872397899627686
Validation loss: 2.475952450947095

Epoch: 5| Step: 3
Training loss: 2.3243532180786133
Validation loss: 2.472403928797732

Epoch: 5| Step: 4
Training loss: 2.4250729084014893
Validation loss: 2.4732178962358864

Epoch: 5| Step: 5
Training loss: 3.029589891433716
Validation loss: 2.467363585707962

Epoch: 5| Step: 6
Training loss: 2.4492297172546387
Validation loss: 2.4789871477311656

Epoch: 5| Step: 7
Training loss: 3.0908093452453613
Validation loss: 2.480887464297715

Epoch: 5| Step: 8
Training loss: 2.830723762512207
Validation loss: 2.480116667286042

Epoch: 5| Step: 9
Training loss: 2.235445499420166
Validation loss: 2.4605626854845273

Epoch: 5| Step: 10
Training loss: 2.36629056930542
Validation loss: 2.4569171039007043

Epoch: 51| Step: 0
Training loss: 3.1643874645233154
Validation loss: 2.4536583551796536

Epoch: 5| Step: 1
Training loss: 2.735356569290161
Validation loss: 2.455019320211103

Epoch: 5| Step: 2
Training loss: 2.9124152660369873
Validation loss: 2.454276023372527

Epoch: 5| Step: 3
Training loss: 2.4966437816619873
Validation loss: 2.456944722001271

Epoch: 5| Step: 4
Training loss: 2.7727644443511963
Validation loss: 2.4572625237126506

Epoch: 5| Step: 5
Training loss: 2.2959160804748535
Validation loss: 2.460416914314352

Epoch: 5| Step: 6
Training loss: 3.0757575035095215
Validation loss: 2.4616739314089537

Epoch: 5| Step: 7
Training loss: 2.318093776702881
Validation loss: 2.4785454709042787

Epoch: 5| Step: 8
Training loss: 2.3034353256225586
Validation loss: 2.467602388833159

Epoch: 5| Step: 9
Training loss: 2.2279019355773926
Validation loss: 2.4658094298455024

Epoch: 5| Step: 10
Training loss: 3.2172188758850098
Validation loss: 2.457714080810547

Epoch: 52| Step: 0
Training loss: 2.044520854949951
Validation loss: 2.4533317960718626

Epoch: 5| Step: 1
Training loss: 2.1974143981933594
Validation loss: 2.4532004312802385

Epoch: 5| Step: 2
Training loss: 2.4603188037872314
Validation loss: 2.453373719287175

Epoch: 5| Step: 3
Training loss: 3.1629819869995117
Validation loss: 2.4524832002578245

Epoch: 5| Step: 4
Training loss: 3.3382153511047363
Validation loss: 2.4480520448377057

Epoch: 5| Step: 5
Training loss: 3.0724616050720215
Validation loss: 2.4507177260614212

Epoch: 5| Step: 6
Training loss: 2.494536876678467
Validation loss: 2.4531046267478698

Epoch: 5| Step: 7
Training loss: 2.4976134300231934
Validation loss: 2.4459232002176265

Epoch: 5| Step: 8
Training loss: 2.620340585708618
Validation loss: 2.4503621901235273

Epoch: 5| Step: 9
Training loss: 2.4396116733551025
Validation loss: 2.449303921832833

Epoch: 5| Step: 10
Training loss: 3.1214096546173096
Validation loss: 2.449078749584895

Epoch: 53| Step: 0
Training loss: 2.8453125953674316
Validation loss: 2.4438868158607074

Epoch: 5| Step: 1
Training loss: 2.600424289703369
Validation loss: 2.4506180568407943

Epoch: 5| Step: 2
Training loss: 2.1770894527435303
Validation loss: 2.4647145989120647

Epoch: 5| Step: 3
Training loss: 2.703085422515869
Validation loss: 2.4659992520527174

Epoch: 5| Step: 4
Training loss: 2.0570995807647705
Validation loss: 2.4781433766888035

Epoch: 5| Step: 5
Training loss: 2.7228708267211914
Validation loss: 2.476699108718544

Epoch: 5| Step: 6
Training loss: 2.594752788543701
Validation loss: 2.463369884798604

Epoch: 5| Step: 7
Training loss: 2.740334987640381
Validation loss: 2.458750396646479

Epoch: 5| Step: 8
Training loss: 3.3232359886169434
Validation loss: 2.4488313710817726

Epoch: 5| Step: 9
Training loss: 3.0418081283569336
Validation loss: 2.448893008693572

Epoch: 5| Step: 10
Training loss: 2.4366238117218018
Validation loss: 2.442323884656352

Epoch: 54| Step: 0
Training loss: 2.6055588722229004
Validation loss: 2.443515551987515

Epoch: 5| Step: 1
Training loss: 2.1087450981140137
Validation loss: 2.445602640028923

Epoch: 5| Step: 2
Training loss: 2.464790105819702
Validation loss: 2.4459980021240892

Epoch: 5| Step: 3
Training loss: 2.4584555625915527
Validation loss: 2.45267915725708

Epoch: 5| Step: 4
Training loss: 2.5413177013397217
Validation loss: 2.4556377010960735

Epoch: 5| Step: 5
Training loss: 2.1229300498962402
Validation loss: 2.4512489585466284

Epoch: 5| Step: 6
Training loss: 3.6610584259033203
Validation loss: 2.462527039230511

Epoch: 5| Step: 7
Training loss: 2.901458263397217
Validation loss: 2.444886561362974

Epoch: 5| Step: 8
Training loss: 3.1275134086608887
Validation loss: 2.444091663565687

Epoch: 5| Step: 9
Training loss: 2.8504998683929443
Validation loss: 2.440778863045477

Epoch: 5| Step: 10
Training loss: 2.354597330093384
Validation loss: 2.445023170081518

Epoch: 55| Step: 0
Training loss: 2.2831265926361084
Validation loss: 2.437990552635603

Epoch: 5| Step: 1
Training loss: 2.7660584449768066
Validation loss: 2.4423282146453857

Epoch: 5| Step: 2
Training loss: 2.1885883808135986
Validation loss: 2.4469836296573764

Epoch: 5| Step: 3
Training loss: 2.14601993560791
Validation loss: 2.4593672572925525

Epoch: 5| Step: 4
Training loss: 2.94480562210083
Validation loss: 2.4522087779096378

Epoch: 5| Step: 5
Training loss: 2.153210401535034
Validation loss: 2.4448550439650014

Epoch: 5| Step: 6
Training loss: 2.561290979385376
Validation loss: 2.4466942356478785

Epoch: 5| Step: 7
Training loss: 3.2958552837371826
Validation loss: 2.448023578172089

Epoch: 5| Step: 8
Training loss: 3.178813934326172
Validation loss: 2.4434598235673803

Epoch: 5| Step: 9
Training loss: 3.286975860595703
Validation loss: 2.432188928768199

Epoch: 5| Step: 10
Training loss: 2.3410773277282715
Validation loss: 2.425612149700042

Epoch: 56| Step: 0
Training loss: 3.2728774547576904
Validation loss: 2.4329504428371305

Epoch: 5| Step: 1
Training loss: 2.569363832473755
Validation loss: 2.4337432897219093

Epoch: 5| Step: 2
Training loss: 2.7316360473632812
Validation loss: 2.4309164221568773

Epoch: 5| Step: 3
Training loss: 2.090139865875244
Validation loss: 2.4293908995966755

Epoch: 5| Step: 4
Training loss: 3.672323703765869
Validation loss: 2.424307712944605

Epoch: 5| Step: 5
Training loss: 2.539936065673828
Validation loss: 2.4255120920878586

Epoch: 5| Step: 6
Training loss: 2.402374267578125
Validation loss: 2.4244087639675347

Epoch: 5| Step: 7
Training loss: 2.3508403301239014
Validation loss: 2.4345522695972073

Epoch: 5| Step: 8
Training loss: 2.3135247230529785
Validation loss: 2.4406156616826213

Epoch: 5| Step: 9
Training loss: 2.6827926635742188
Validation loss: 2.492214620754283

Epoch: 5| Step: 10
Training loss: 2.5831997394561768
Validation loss: 2.5033209067518993

Epoch: 57| Step: 0
Training loss: 2.6922450065612793
Validation loss: 2.52112183519589

Epoch: 5| Step: 1
Training loss: 2.622901201248169
Validation loss: 2.5006457631305983

Epoch: 5| Step: 2
Training loss: 2.536825656890869
Validation loss: 2.4919182946605067

Epoch: 5| Step: 3
Training loss: 2.4611549377441406
Validation loss: 2.4635707460423952

Epoch: 5| Step: 4
Training loss: 2.3580729961395264
Validation loss: 2.460196623238184

Epoch: 5| Step: 5
Training loss: 3.310208797454834
Validation loss: 2.442448400682019

Epoch: 5| Step: 6
Training loss: 3.1310153007507324
Validation loss: 2.434346124690066

Epoch: 5| Step: 7
Training loss: 2.2799744606018066
Validation loss: 2.423063398689352

Epoch: 5| Step: 8
Training loss: 2.825355052947998
Validation loss: 2.4177302801480858

Epoch: 5| Step: 9
Training loss: 2.1265673637390137
Validation loss: 2.4282146551275767

Epoch: 5| Step: 10
Training loss: 2.920738935470581
Validation loss: 2.425130415988225

Epoch: 58| Step: 0
Training loss: 2.79215931892395
Validation loss: 2.4226431820982244

Epoch: 5| Step: 1
Training loss: 2.6635117530822754
Validation loss: 2.4329181563469673

Epoch: 5| Step: 2
Training loss: 3.2223968505859375
Validation loss: 2.473012788321382

Epoch: 5| Step: 3
Training loss: 2.73702073097229
Validation loss: 2.474869061541814

Epoch: 5| Step: 4
Training loss: 2.559359073638916
Validation loss: 2.444730435648272

Epoch: 5| Step: 5
Training loss: 2.4496572017669678
Validation loss: 2.457226155906595

Epoch: 5| Step: 6
Training loss: 3.2985942363739014
Validation loss: 2.453763246536255

Epoch: 5| Step: 7
Training loss: 2.3073208332061768
Validation loss: 2.4376615298691617

Epoch: 5| Step: 8
Training loss: 1.8069185018539429
Validation loss: 2.441581041582169

Epoch: 5| Step: 9
Training loss: 3.1476352214813232
Validation loss: 2.430106334788825

Epoch: 5| Step: 10
Training loss: 2.0922608375549316
Validation loss: 2.436422271113242

Epoch: 59| Step: 0
Training loss: 2.3614792823791504
Validation loss: 2.43834117920168

Epoch: 5| Step: 1
Training loss: 2.6006019115448
Validation loss: 2.437733522025488

Epoch: 5| Step: 2
Training loss: 2.75106143951416
Validation loss: 2.4185505861877115

Epoch: 5| Step: 3
Training loss: 2.633784532546997
Validation loss: 2.4081616452945176

Epoch: 5| Step: 4
Training loss: 2.203606128692627
Validation loss: 2.410348376920146

Epoch: 5| Step: 5
Training loss: 2.671126127243042
Validation loss: 2.4033176078591296

Epoch: 5| Step: 6
Training loss: 3.235985279083252
Validation loss: 2.4058271723408855

Epoch: 5| Step: 7
Training loss: 2.886772394180298
Validation loss: 2.4045654958294285

Epoch: 5| Step: 8
Training loss: 2.1288671493530273
Validation loss: 2.410209227633733

Epoch: 5| Step: 9
Training loss: 3.0027995109558105
Validation loss: 2.4196872557363203

Epoch: 5| Step: 10
Training loss: 2.542632579803467
Validation loss: 2.4233615244588544

Epoch: 60| Step: 0
Training loss: 2.801628828048706
Validation loss: 2.430955094675864

Epoch: 5| Step: 1
Training loss: 3.6561145782470703
Validation loss: 2.4450480348320416

Epoch: 5| Step: 2
Training loss: 1.9224636554718018
Validation loss: 2.4446567784073534

Epoch: 5| Step: 3
Training loss: 2.6216492652893066
Validation loss: 2.433466689561003

Epoch: 5| Step: 4
Training loss: 2.66703462600708
Validation loss: 2.4428769157778834

Epoch: 5| Step: 5
Training loss: 2.4426894187927246
Validation loss: 2.417112463264055

Epoch: 5| Step: 6
Training loss: 2.6324102878570557
Validation loss: 2.4124388925490843

Epoch: 5| Step: 7
Training loss: 2.726125717163086
Validation loss: 2.403572036374

Epoch: 5| Step: 8
Training loss: 2.5252602100372314
Validation loss: 2.4007231958450808

Epoch: 5| Step: 9
Training loss: 2.1681885719299316
Validation loss: 2.3970194606370825

Epoch: 5| Step: 10
Training loss: 2.912663221359253
Validation loss: 2.401850623469199

Epoch: 61| Step: 0
Training loss: 2.6348750591278076
Validation loss: 2.4087171298201366

Epoch: 5| Step: 1
Training loss: 2.3346972465515137
Validation loss: 2.4202657335547992

Epoch: 5| Step: 2
Training loss: 2.596308469772339
Validation loss: 2.453630660169868

Epoch: 5| Step: 3
Training loss: 2.7703537940979004
Validation loss: 2.5133343204375236

Epoch: 5| Step: 4
Training loss: 3.249181032180786
Validation loss: 2.608969585869902

Epoch: 5| Step: 5
Training loss: 3.0465972423553467
Validation loss: 2.5990476480094333

Epoch: 5| Step: 6
Training loss: 2.5178885459899902
Validation loss: 2.5029390781156478

Epoch: 5| Step: 7
Training loss: 2.9790329933166504
Validation loss: 2.4141341255557154

Epoch: 5| Step: 8
Training loss: 2.878199577331543
Validation loss: 2.393529015202676

Epoch: 5| Step: 9
Training loss: 2.4109044075012207
Validation loss: 2.3890043638085805

Epoch: 5| Step: 10
Training loss: 1.9677680730819702
Validation loss: 2.4147162437438965

Epoch: 62| Step: 0
Training loss: 2.73419189453125
Validation loss: 2.41359709155175

Epoch: 5| Step: 1
Training loss: 2.5457301139831543
Validation loss: 2.4522272899586666

Epoch: 5| Step: 2
Training loss: 2.3406224250793457
Validation loss: 2.455956792318693

Epoch: 5| Step: 3
Training loss: 3.1963534355163574
Validation loss: 2.443090097878569

Epoch: 5| Step: 4
Training loss: 2.46496319770813
Validation loss: 2.426841776858094

Epoch: 5| Step: 5
Training loss: 2.8254199028015137
Validation loss: 2.4173059232773317

Epoch: 5| Step: 6
Training loss: 2.7647030353546143
Validation loss: 2.404989988573136

Epoch: 5| Step: 7
Training loss: 2.7987184524536133
Validation loss: 2.390922523313953

Epoch: 5| Step: 8
Training loss: 2.6259818077087402
Validation loss: 2.3963236808776855

Epoch: 5| Step: 9
Training loss: 2.31156325340271
Validation loss: 2.415264086056781

Epoch: 5| Step: 10
Training loss: 2.4218883514404297
Validation loss: 2.4490735838490147

Epoch: 63| Step: 0
Training loss: 2.8711352348327637
Validation loss: 2.480352440188008

Epoch: 5| Step: 1
Training loss: 3.006294012069702
Validation loss: 2.5549458675487067

Epoch: 5| Step: 2
Training loss: 2.981205463409424
Validation loss: 2.58386331219827

Epoch: 5| Step: 3
Training loss: 2.894745349884033
Validation loss: 2.6025195429402013

Epoch: 5| Step: 4
Training loss: 2.191434383392334
Validation loss: 2.5955046838329685

Epoch: 5| Step: 5
Training loss: 2.596043348312378
Validation loss: 2.5623830108232397

Epoch: 5| Step: 6
Training loss: 2.6758980751037598
Validation loss: 2.471049670250185

Epoch: 5| Step: 7
Training loss: 2.7740795612335205
Validation loss: 2.441036988330144

Epoch: 5| Step: 8
Training loss: 3.092254161834717
Validation loss: 2.4096240228222263

Epoch: 5| Step: 9
Training loss: 2.0124897956848145
Validation loss: 2.3944924569899038

Epoch: 5| Step: 10
Training loss: 2.454990863800049
Validation loss: 2.4194549975856656

Epoch: 64| Step: 0
Training loss: 3.327390193939209
Validation loss: 2.4437121370787263

Epoch: 5| Step: 1
Training loss: 2.4212265014648438
Validation loss: 2.419993572337653

Epoch: 5| Step: 2
Training loss: 3.067460298538208
Validation loss: 2.3916014907180623

Epoch: 5| Step: 3
Training loss: 2.224332809448242
Validation loss: 2.393840402685186

Epoch: 5| Step: 4
Training loss: 2.6479756832122803
Validation loss: 2.4005485042448966

Epoch: 5| Step: 5
Training loss: 2.4193320274353027
Validation loss: 2.3978557048305387

Epoch: 5| Step: 6
Training loss: 2.7523438930511475
Validation loss: 2.3902053397188903

Epoch: 5| Step: 7
Training loss: 2.59946870803833
Validation loss: 2.3924991571775047

Epoch: 5| Step: 8
Training loss: 2.7954277992248535
Validation loss: 2.391059390960201

Epoch: 5| Step: 9
Training loss: 2.450425386428833
Validation loss: 2.394076660115232

Epoch: 5| Step: 10
Training loss: 2.4382801055908203
Validation loss: 2.3954288600593485

Epoch: 65| Step: 0
Training loss: 2.4761855602264404
Validation loss: 2.3881263656000935

Epoch: 5| Step: 1
Training loss: 2.759934902191162
Validation loss: 2.3867622395997405

Epoch: 5| Step: 2
Training loss: 2.570262908935547
Validation loss: 2.3808857753712642

Epoch: 5| Step: 3
Training loss: 1.8799155950546265
Validation loss: 2.366963537790442

Epoch: 5| Step: 4
Training loss: 3.3414883613586426
Validation loss: 2.367769823279432

Epoch: 5| Step: 5
Training loss: 2.872990369796753
Validation loss: 2.3729175290753766

Epoch: 5| Step: 6
Training loss: 1.6098873615264893
Validation loss: 2.3729661357018257

Epoch: 5| Step: 7
Training loss: 2.5632987022399902
Validation loss: 2.3839968507007887

Epoch: 5| Step: 8
Training loss: 2.7362759113311768
Validation loss: 2.391143855228219

Epoch: 5| Step: 9
Training loss: 3.5023574829101562
Validation loss: 2.394659503813713

Epoch: 5| Step: 10
Training loss: 2.5866405963897705
Validation loss: 2.390137623715144

Epoch: 66| Step: 0
Training loss: 2.700140953063965
Validation loss: 2.388500726351174

Epoch: 5| Step: 1
Training loss: 2.648202419281006
Validation loss: 2.4003520986085296

Epoch: 5| Step: 2
Training loss: 2.8081345558166504
Validation loss: 2.3928528203759143

Epoch: 5| Step: 3
Training loss: 2.204073905944824
Validation loss: 2.394361206280288

Epoch: 5| Step: 4
Training loss: 2.3705313205718994
Validation loss: 2.385097085788686

Epoch: 5| Step: 5
Training loss: 2.4052584171295166
Validation loss: 2.3883549577446392

Epoch: 5| Step: 6
Training loss: 2.4772849082946777
Validation loss: 2.376847441478442

Epoch: 5| Step: 7
Training loss: 2.4494054317474365
Validation loss: 2.3691039931389595

Epoch: 5| Step: 8
Training loss: 2.6132915019989014
Validation loss: 2.3771717676552395

Epoch: 5| Step: 9
Training loss: 3.3011043071746826
Validation loss: 2.3670259778217604

Epoch: 5| Step: 10
Training loss: 2.924570083618164
Validation loss: 2.362496150437222

Epoch: 67| Step: 0
Training loss: 2.794686794281006
Validation loss: 2.360098925969934

Epoch: 5| Step: 1
Training loss: 2.9606077671051025
Validation loss: 2.3638194145694857

Epoch: 5| Step: 2
Training loss: 2.6126201152801514
Validation loss: 2.367697923414169

Epoch: 5| Step: 3
Training loss: 2.8061816692352295
Validation loss: 2.3666864774560414

Epoch: 5| Step: 4
Training loss: 2.643765687942505
Validation loss: 2.377030288019488

Epoch: 5| Step: 5
Training loss: 2.6997876167297363
Validation loss: 2.3755623409824986

Epoch: 5| Step: 6
Training loss: 2.418405055999756
Validation loss: 2.3685688818654707

Epoch: 5| Step: 7
Training loss: 2.149134635925293
Validation loss: 2.364753400125811

Epoch: 5| Step: 8
Training loss: 2.5138533115386963
Validation loss: 2.3610815104617866

Epoch: 5| Step: 9
Training loss: 2.320338726043701
Validation loss: 2.356250075883763

Epoch: 5| Step: 10
Training loss: 2.904592752456665
Validation loss: 2.355426744748187

Epoch: 68| Step: 0
Training loss: 2.4443538188934326
Validation loss: 2.3561986415616927

Epoch: 5| Step: 1
Training loss: 2.3013129234313965
Validation loss: 2.355978035157727

Epoch: 5| Step: 2
Training loss: 3.1316351890563965
Validation loss: 2.365745375233312

Epoch: 5| Step: 3
Training loss: 3.0038042068481445
Validation loss: 2.3718183835347495

Epoch: 5| Step: 4
Training loss: 2.2648873329162598
Validation loss: 2.378634004182713

Epoch: 5| Step: 5
Training loss: 3.141965389251709
Validation loss: 2.3887613076035694

Epoch: 5| Step: 6
Training loss: 2.820547103881836
Validation loss: 2.400112123899562

Epoch: 5| Step: 7
Training loss: 2.7874960899353027
Validation loss: 2.38806293600349

Epoch: 5| Step: 8
Training loss: 3.0064620971679688
Validation loss: 2.3726524640155096

Epoch: 5| Step: 9
Training loss: 1.5199817419052124
Validation loss: 2.3557090887459378

Epoch: 5| Step: 10
Training loss: 2.450430393218994
Validation loss: 2.3544372371447984

Epoch: 69| Step: 0
Training loss: 2.8355331420898438
Validation loss: 2.352787225477157

Epoch: 5| Step: 1
Training loss: 2.194903612136841
Validation loss: 2.3497727968359507

Epoch: 5| Step: 2
Training loss: 2.4190125465393066
Validation loss: 2.3521998364438295

Epoch: 5| Step: 3
Training loss: 1.9386518001556396
Validation loss: 2.352152665456136

Epoch: 5| Step: 4
Training loss: 2.437312602996826
Validation loss: 2.352444400069534

Epoch: 5| Step: 5
Training loss: 2.2778260707855225
Validation loss: 2.357256858579574

Epoch: 5| Step: 6
Training loss: 3.176781177520752
Validation loss: 2.358709781400619

Epoch: 5| Step: 7
Training loss: 2.65022611618042
Validation loss: 2.3643715227803876

Epoch: 5| Step: 8
Training loss: 3.339688539505005
Validation loss: 2.3678873482570855

Epoch: 5| Step: 9
Training loss: 2.3479766845703125
Validation loss: 2.3644436841369956

Epoch: 5| Step: 10
Training loss: 3.1702325344085693
Validation loss: 2.3617818176105456

Epoch: 70| Step: 0
Training loss: 3.2383875846862793
Validation loss: 2.364248770539479

Epoch: 5| Step: 1
Training loss: 2.1822168827056885
Validation loss: 2.374008683748143

Epoch: 5| Step: 2
Training loss: 2.658799409866333
Validation loss: 2.398248923722134

Epoch: 5| Step: 3
Training loss: 2.873018741607666
Validation loss: 2.384842244527673

Epoch: 5| Step: 4
Training loss: 2.3201115131378174
Validation loss: 2.360627366650489

Epoch: 5| Step: 5
Training loss: 2.5442607402801514
Validation loss: 2.34655176695957

Epoch: 5| Step: 6
Training loss: 2.8384830951690674
Validation loss: 2.332053299873106

Epoch: 5| Step: 7
Training loss: 1.974366545677185
Validation loss: 2.336676879595685

Epoch: 5| Step: 8
Training loss: 2.778841733932495
Validation loss: 2.3427605552058064

Epoch: 5| Step: 9
Training loss: 2.6447908878326416
Validation loss: 2.3483965858336417

Epoch: 5| Step: 10
Training loss: 2.7662525177001953
Validation loss: 2.3705694213990243

Epoch: 71| Step: 0
Training loss: 2.4730982780456543
Validation loss: 2.3666525220358245

Epoch: 5| Step: 1
Training loss: 2.574505567550659
Validation loss: 2.3491738932107085

Epoch: 5| Step: 2
Training loss: 2.740243434906006
Validation loss: 2.3466080042623703

Epoch: 5| Step: 3
Training loss: 2.137396812438965
Validation loss: 2.3399361025902534

Epoch: 5| Step: 4
Training loss: 2.4881598949432373
Validation loss: 2.33857419413905

Epoch: 5| Step: 5
Training loss: 2.8924968242645264
Validation loss: 2.348772318132462

Epoch: 5| Step: 6
Training loss: 2.595458507537842
Validation loss: 2.351464104908769

Epoch: 5| Step: 7
Training loss: 1.8435195684432983
Validation loss: 2.356966159676993

Epoch: 5| Step: 8
Training loss: 3.1531596183776855
Validation loss: 2.3573953003011723

Epoch: 5| Step: 9
Training loss: 2.511408567428589
Validation loss: 2.378826638703705

Epoch: 5| Step: 10
Training loss: 3.5370447635650635
Validation loss: 2.3906881347779305

Epoch: 72| Step: 0
Training loss: 2.9109718799591064
Validation loss: 2.399994206684892

Epoch: 5| Step: 1
Training loss: 2.418372631072998
Validation loss: 2.4190418297244656

Epoch: 5| Step: 2
Training loss: 2.447366952896118
Validation loss: 2.4476924122020765

Epoch: 5| Step: 3
Training loss: 2.7121641635894775
Validation loss: 2.4694301184787544

Epoch: 5| Step: 4
Training loss: 3.6034018993377686
Validation loss: 2.499315589986822

Epoch: 5| Step: 5
Training loss: 2.278838634490967
Validation loss: 2.4499239306296072

Epoch: 5| Step: 6
Training loss: 2.3098232746124268
Validation loss: 2.374452829360962

Epoch: 5| Step: 7
Training loss: 2.7456846237182617
Validation loss: 2.3567699463136735

Epoch: 5| Step: 8
Training loss: 2.3833212852478027
Validation loss: 2.3440130872111165

Epoch: 5| Step: 9
Training loss: 2.2872426509857178
Validation loss: 2.345080678180982

Epoch: 5| Step: 10
Training loss: 2.8304483890533447
Validation loss: 2.3434453087468303

Epoch: 73| Step: 0
Training loss: 2.0636954307556152
Validation loss: 2.347338071433447

Epoch: 5| Step: 1
Training loss: 3.0173182487487793
Validation loss: 2.3610535924152662

Epoch: 5| Step: 2
Training loss: 2.08549165725708
Validation loss: 2.3475019213973836

Epoch: 5| Step: 3
Training loss: 2.7787346839904785
Validation loss: 2.343047934193765

Epoch: 5| Step: 4
Training loss: 2.957871198654175
Validation loss: 2.363302251344086

Epoch: 5| Step: 5
Training loss: 2.356894016265869
Validation loss: 2.374101923358056

Epoch: 5| Step: 6
Training loss: 3.047095775604248
Validation loss: 2.3820799473793275

Epoch: 5| Step: 7
Training loss: 2.8088736534118652
Validation loss: 2.4047038785872923

Epoch: 5| Step: 8
Training loss: 2.112919569015503
Validation loss: 2.3792303915946715

Epoch: 5| Step: 9
Training loss: 2.5822315216064453
Validation loss: 2.378797677255446

Epoch: 5| Step: 10
Training loss: 3.0736844539642334
Validation loss: 2.3739379657212125

Epoch: 74| Step: 0
Training loss: 2.608699321746826
Validation loss: 2.3630791171904533

Epoch: 5| Step: 1
Training loss: 2.278571605682373
Validation loss: 2.3683293839936614

Epoch: 5| Step: 2
Training loss: 3.183645248413086
Validation loss: 2.354855247723159

Epoch: 5| Step: 3
Training loss: 2.1722798347473145
Validation loss: 2.357147526997392

Epoch: 5| Step: 4
Training loss: 2.675901174545288
Validation loss: 2.3424460644363077

Epoch: 5| Step: 5
Training loss: 2.7341504096984863
Validation loss: 2.3411705904109503

Epoch: 5| Step: 6
Training loss: 2.30283784866333
Validation loss: 2.333995037181403

Epoch: 5| Step: 7
Training loss: 3.1564011573791504
Validation loss: 2.339565307863297

Epoch: 5| Step: 8
Training loss: 2.865718364715576
Validation loss: 2.328968796678769

Epoch: 5| Step: 9
Training loss: 2.2500171661376953
Validation loss: 2.3304355964865735

Epoch: 5| Step: 10
Training loss: 2.3706541061401367
Validation loss: 2.3322045187796316

Epoch: 75| Step: 0
Training loss: 2.9851596355438232
Validation loss: 2.3290913463920675

Epoch: 5| Step: 1
Training loss: 2.633019208908081
Validation loss: 2.326251132513887

Epoch: 5| Step: 2
Training loss: 2.532827377319336
Validation loss: 2.325344524075908

Epoch: 5| Step: 3
Training loss: 2.753462553024292
Validation loss: 2.3269543647766113

Epoch: 5| Step: 4
Training loss: 2.2462053298950195
Validation loss: 2.3260323437311317

Epoch: 5| Step: 5
Training loss: 2.2158751487731934
Validation loss: 2.32624908672866

Epoch: 5| Step: 6
Training loss: 2.8092520236968994
Validation loss: 2.334272394898117

Epoch: 5| Step: 7
Training loss: 2.597309112548828
Validation loss: 2.333278348368983

Epoch: 5| Step: 8
Training loss: 2.4836456775665283
Validation loss: 2.3389148353248514

Epoch: 5| Step: 9
Training loss: 2.712947368621826
Validation loss: 2.353877229075278

Epoch: 5| Step: 10
Training loss: 2.4487080574035645
Validation loss: 2.3590825398763022

Epoch: 76| Step: 0
Training loss: 2.971080780029297
Validation loss: 2.349881466998849

Epoch: 5| Step: 1
Training loss: 2.6606011390686035
Validation loss: 2.3357343955706527

Epoch: 5| Step: 2
Training loss: 2.8205454349517822
Validation loss: 2.3270053350797264

Epoch: 5| Step: 3
Training loss: 2.892540454864502
Validation loss: 2.3277014865670154

Epoch: 5| Step: 4
Training loss: 3.188986301422119
Validation loss: 2.326667208825388

Epoch: 5| Step: 5
Training loss: 2.1079986095428467
Validation loss: 2.3200699103775846

Epoch: 5| Step: 6
Training loss: 2.5853066444396973
Validation loss: 2.313808212998093

Epoch: 5| Step: 7
Training loss: 2.58435320854187
Validation loss: 2.3188581620493243

Epoch: 5| Step: 8
Training loss: 1.9788353443145752
Validation loss: 2.3227400651542087

Epoch: 5| Step: 9
Training loss: 1.8554950952529907
Validation loss: 2.3288929129159577

Epoch: 5| Step: 10
Training loss: 3.003545045852661
Validation loss: 2.3316592042164137

Epoch: 77| Step: 0
Training loss: 2.9829039573669434
Validation loss: 2.326437332296884

Epoch: 5| Step: 1
Training loss: 2.820791721343994
Validation loss: 2.32327744524966

Epoch: 5| Step: 2
Training loss: 3.2031822204589844
Validation loss: 2.3238436752750027

Epoch: 5| Step: 3
Training loss: 1.929221510887146
Validation loss: 2.318110389094199

Epoch: 5| Step: 4
Training loss: 2.8547165393829346
Validation loss: 2.3222276908095165

Epoch: 5| Step: 5
Training loss: 2.681995391845703
Validation loss: 2.3073357177037064

Epoch: 5| Step: 6
Training loss: 2.998114824295044
Validation loss: 2.3060656696237545

Epoch: 5| Step: 7
Training loss: 1.9571853876113892
Validation loss: 2.3073947429656982

Epoch: 5| Step: 8
Training loss: 2.660703659057617
Validation loss: 2.3095531668714298

Epoch: 5| Step: 9
Training loss: 2.514024019241333
Validation loss: 2.316548598709927

Epoch: 5| Step: 10
Training loss: 1.8167614936828613
Validation loss: 2.338630458360077

Epoch: 78| Step: 0
Training loss: 2.877713680267334
Validation loss: 2.36871886509721

Epoch: 5| Step: 1
Training loss: 2.5860395431518555
Validation loss: 2.387731190650694

Epoch: 5| Step: 2
Training loss: 1.9421117305755615
Validation loss: 2.349148973341911

Epoch: 5| Step: 3
Training loss: 2.149096965789795
Validation loss: 2.3437405376024145

Epoch: 5| Step: 4
Training loss: 2.7839906215667725
Validation loss: 2.3370923534516366

Epoch: 5| Step: 5
Training loss: 2.297495126724243
Validation loss: 2.33590680040339

Epoch: 5| Step: 6
Training loss: 2.9669814109802246
Validation loss: 2.355655541983984

Epoch: 5| Step: 7
Training loss: 2.61122727394104
Validation loss: 2.3458307763581634

Epoch: 5| Step: 8
Training loss: 3.3223705291748047
Validation loss: 2.356163122320688

Epoch: 5| Step: 9
Training loss: 2.348574638366699
Validation loss: 2.3535297173325733

Epoch: 5| Step: 10
Training loss: 2.650114059448242
Validation loss: 2.345720862829557

Epoch: 79| Step: 0
Training loss: 3.0420632362365723
Validation loss: 2.331079263840952

Epoch: 5| Step: 1
Training loss: 2.884065628051758
Validation loss: 2.3054543054232033

Epoch: 5| Step: 2
Training loss: 2.4569122791290283
Validation loss: 2.3003619614467827

Epoch: 5| Step: 3
Training loss: 2.0275769233703613
Validation loss: 2.3050463327797512

Epoch: 5| Step: 4
Training loss: 2.730625629425049
Validation loss: 2.2992214541281424

Epoch: 5| Step: 5
Training loss: 2.605198383331299
Validation loss: 2.3039254014210035

Epoch: 5| Step: 6
Training loss: 1.6804777383804321
Validation loss: 2.306940209481024

Epoch: 5| Step: 7
Training loss: 2.7618539333343506
Validation loss: 2.3122951984405518

Epoch: 5| Step: 8
Training loss: 1.9921998977661133
Validation loss: 2.300999344036143

Epoch: 5| Step: 9
Training loss: 3.134139060974121
Validation loss: 2.3053991051130396

Epoch: 5| Step: 10
Training loss: 3.240365505218506
Validation loss: 2.3329800969810894

Epoch: 80| Step: 0
Training loss: 2.6403424739837646
Validation loss: 2.3632931017106578

Epoch: 5| Step: 1
Training loss: 3.238553524017334
Validation loss: 2.398333400808355

Epoch: 5| Step: 2
Training loss: 2.1922924518585205
Validation loss: 2.4254890129130375

Epoch: 5| Step: 3
Training loss: 2.719637155532837
Validation loss: 2.4049123846074587

Epoch: 5| Step: 4
Training loss: 2.3485937118530273
Validation loss: 2.3593818449204966

Epoch: 5| Step: 5
Training loss: 2.1939821243286133
Validation loss: 2.33054074933452

Epoch: 5| Step: 6
Training loss: 2.798438549041748
Validation loss: 2.3110370379622265

Epoch: 5| Step: 7
Training loss: 3.01347017288208
Validation loss: 2.29447849335209

Epoch: 5| Step: 8
Training loss: 2.01068115234375
Validation loss: 2.2991172934091217

Epoch: 5| Step: 9
Training loss: 2.7276527881622314
Validation loss: 2.315295932113483

Epoch: 5| Step: 10
Training loss: 2.6238982677459717
Validation loss: 2.326706117199313

Epoch: 81| Step: 0
Training loss: 2.233914613723755
Validation loss: 2.314139079022151

Epoch: 5| Step: 1
Training loss: 2.692081928253174
Validation loss: 2.3145550348425425

Epoch: 5| Step: 2
Training loss: 2.327136993408203
Validation loss: 2.315002777243173

Epoch: 5| Step: 3
Training loss: 2.1613574028015137
Validation loss: 2.304110191201651

Epoch: 5| Step: 4
Training loss: 2.757908821105957
Validation loss: 2.305286899689705

Epoch: 5| Step: 5
Training loss: 2.7069268226623535
Validation loss: 2.2933224221711517

Epoch: 5| Step: 6
Training loss: 2.6843655109405518
Validation loss: 2.301062435232183

Epoch: 5| Step: 7
Training loss: 2.8081963062286377
Validation loss: 2.324015801952731

Epoch: 5| Step: 8
Training loss: 2.514702320098877
Validation loss: 2.323285328444614

Epoch: 5| Step: 9
Training loss: 2.8657846450805664
Validation loss: 2.339331511528261

Epoch: 5| Step: 10
Training loss: 2.507213592529297
Validation loss: 2.3464557842541764

Epoch: 82| Step: 0
Training loss: 3.0312905311584473
Validation loss: 2.3357688842281217

Epoch: 5| Step: 1
Training loss: 2.938887119293213
Validation loss: 2.3312438175242436

Epoch: 5| Step: 2
Training loss: 2.44610595703125
Validation loss: 2.331533060278944

Epoch: 5| Step: 3
Training loss: 2.6874938011169434
Validation loss: 2.338507383100448

Epoch: 5| Step: 4
Training loss: 2.474990129470825
Validation loss: 2.3277855201434066

Epoch: 5| Step: 5
Training loss: 1.9895975589752197
Validation loss: 2.3256508842591317

Epoch: 5| Step: 6
Training loss: 2.7896790504455566
Validation loss: 2.3126502626685688

Epoch: 5| Step: 7
Training loss: 2.3344767093658447
Validation loss: 2.2966797146745908

Epoch: 5| Step: 8
Training loss: 2.535437822341919
Validation loss: 2.285621755866594

Epoch: 5| Step: 9
Training loss: 2.554548978805542
Validation loss: 2.2857266344049925

Epoch: 5| Step: 10
Training loss: 2.5236096382141113
Validation loss: 2.289982803406254

Epoch: 83| Step: 0
Training loss: 2.6188008785247803
Validation loss: 2.2983295545783093

Epoch: 5| Step: 1
Training loss: 2.4917070865631104
Validation loss: 2.299720346286733

Epoch: 5| Step: 2
Training loss: 2.5797338485717773
Validation loss: 2.3110615194484754

Epoch: 5| Step: 3
Training loss: 2.429975986480713
Validation loss: 2.3161128926020798

Epoch: 5| Step: 4
Training loss: 2.530508279800415
Validation loss: 2.3132610961955082

Epoch: 5| Step: 5
Training loss: 2.5166685581207275
Validation loss: 2.328834543945969

Epoch: 5| Step: 6
Training loss: 2.9834144115448
Validation loss: 2.3222814811173307

Epoch: 5| Step: 7
Training loss: 2.8054146766662598
Validation loss: 2.2928998829216085

Epoch: 5| Step: 8
Training loss: 2.7918548583984375
Validation loss: 2.282677842724708

Epoch: 5| Step: 9
Training loss: 2.7873406410217285
Validation loss: 2.2844868372845393

Epoch: 5| Step: 10
Training loss: 1.8476667404174805
Validation loss: 2.283653046495171

Epoch: 84| Step: 0
Training loss: 2.003669261932373
Validation loss: 2.288075500918973

Epoch: 5| Step: 1
Training loss: 1.6915775537490845
Validation loss: 2.297565742205548

Epoch: 5| Step: 2
Training loss: 2.6090164184570312
Validation loss: 2.3010938244481243

Epoch: 5| Step: 3
Training loss: 2.656161069869995
Validation loss: 2.3071148023810437

Epoch: 5| Step: 4
Training loss: 2.9007537364959717
Validation loss: 2.31333141685814

Epoch: 5| Step: 5
Training loss: 2.612915515899658
Validation loss: 2.3147900181431926

Epoch: 5| Step: 6
Training loss: 2.674669027328491
Validation loss: 2.341874930166429

Epoch: 5| Step: 7
Training loss: 3.4586215019226074
Validation loss: 2.338191052918793

Epoch: 5| Step: 8
Training loss: 2.2773661613464355
Validation loss: 2.3060537128038305

Epoch: 5| Step: 9
Training loss: 2.51960825920105
Validation loss: 2.280328928783376

Epoch: 5| Step: 10
Training loss: 2.7062489986419678
Validation loss: 2.2786275802120084

Epoch: 85| Step: 0
Training loss: 2.621657133102417
Validation loss: 2.276114902188701

Epoch: 5| Step: 1
Training loss: 1.9407809972763062
Validation loss: 2.277561358226243

Epoch: 5| Step: 2
Training loss: 2.873030424118042
Validation loss: 2.2761151136890536

Epoch: 5| Step: 3
Training loss: 2.6048130989074707
Validation loss: 2.293748381317303

Epoch: 5| Step: 4
Training loss: 2.8264822959899902
Validation loss: 2.3089400927225747

Epoch: 5| Step: 5
Training loss: 2.849285364151001
Validation loss: 2.3246608421366703

Epoch: 5| Step: 6
Training loss: 2.1461949348449707
Validation loss: 2.3301904098961943

Epoch: 5| Step: 7
Training loss: 3.1885294914245605
Validation loss: 2.2901957675974858

Epoch: 5| Step: 8
Training loss: 2.5523593425750732
Validation loss: 2.271330484779932

Epoch: 5| Step: 9
Training loss: 2.395977735519409
Validation loss: 2.261865254371397

Epoch: 5| Step: 10
Training loss: 2.03495717048645
Validation loss: 2.2527509838022213

Epoch: 86| Step: 0
Training loss: 2.837329626083374
Validation loss: 2.257973268467893

Epoch: 5| Step: 1
Training loss: 2.483405351638794
Validation loss: 2.254876200870801

Epoch: 5| Step: 2
Training loss: 2.4929442405700684
Validation loss: 2.2555748185803814

Epoch: 5| Step: 3
Training loss: 2.7899136543273926
Validation loss: 2.2632945224802983

Epoch: 5| Step: 4
Training loss: 2.3061065673828125
Validation loss: 2.2631320415004605

Epoch: 5| Step: 5
Training loss: 3.057006359100342
Validation loss: 2.2643717770935385

Epoch: 5| Step: 6
Training loss: 2.6565887928009033
Validation loss: 2.263289600290278

Epoch: 5| Step: 7
Training loss: 2.33864164352417
Validation loss: 2.265774734558598

Epoch: 5| Step: 8
Training loss: 2.4031524658203125
Validation loss: 2.266084888929962

Epoch: 5| Step: 9
Training loss: 2.8072686195373535
Validation loss: 2.2580894167705248

Epoch: 5| Step: 10
Training loss: 1.9627174139022827
Validation loss: 2.264544476744949

Epoch: 87| Step: 0
Training loss: 2.3024871349334717
Validation loss: 2.2690412370107507

Epoch: 5| Step: 1
Training loss: 2.4726498126983643
Validation loss: 2.2671243503529537

Epoch: 5| Step: 2
Training loss: 3.4055709838867188
Validation loss: 2.2648238674286874

Epoch: 5| Step: 3
Training loss: 3.123326301574707
Validation loss: 2.264093179856577

Epoch: 5| Step: 4
Training loss: 2.7586050033569336
Validation loss: 2.26436867508837

Epoch: 5| Step: 5
Training loss: 2.5761590003967285
Validation loss: 2.261798293359818

Epoch: 5| Step: 6
Training loss: 1.779679298400879
Validation loss: 2.2666995679178545

Epoch: 5| Step: 7
Training loss: 2.4061222076416016
Validation loss: 2.272531014616771

Epoch: 5| Step: 8
Training loss: 1.9727709293365479
Validation loss: 2.27240676008245

Epoch: 5| Step: 9
Training loss: 2.2199110984802246
Validation loss: 2.3029136016804683

Epoch: 5| Step: 10
Training loss: 2.960554361343384
Validation loss: 2.3078582312471125

Epoch: 88| Step: 0
Training loss: 3.1380815505981445
Validation loss: 2.3054922421773276

Epoch: 5| Step: 1
Training loss: 2.159935712814331
Validation loss: 2.2873617577296432

Epoch: 5| Step: 2
Training loss: 2.4494898319244385
Validation loss: 2.277074590806038

Epoch: 5| Step: 3
Training loss: 2.379467487335205
Validation loss: 2.265149442098474

Epoch: 5| Step: 4
Training loss: 2.769897937774658
Validation loss: 2.2525096042181856

Epoch: 5| Step: 5
Training loss: 2.7685418128967285
Validation loss: 2.259063051592919

Epoch: 5| Step: 6
Training loss: 2.2721657752990723
Validation loss: 2.258842158061202

Epoch: 5| Step: 7
Training loss: 2.2349023818969727
Validation loss: 2.2637671770588046

Epoch: 5| Step: 8
Training loss: 2.3661599159240723
Validation loss: 2.25675005297507

Epoch: 5| Step: 9
Training loss: 2.75347900390625
Validation loss: 2.2441596587498984

Epoch: 5| Step: 10
Training loss: 2.6930196285247803
Validation loss: 2.250739264231856

Epoch: 89| Step: 0
Training loss: 2.612528085708618
Validation loss: 2.2696402765089467

Epoch: 5| Step: 1
Training loss: 2.2594692707061768
Validation loss: 2.303762630749774

Epoch: 5| Step: 2
Training loss: 2.838641405105591
Validation loss: 2.3208844661712646

Epoch: 5| Step: 3
Training loss: 2.4036638736724854
Validation loss: 2.350533959686115

Epoch: 5| Step: 4
Training loss: 2.760139226913452
Validation loss: 2.327577002586857

Epoch: 5| Step: 5
Training loss: 2.6445860862731934
Validation loss: 2.344710744837279

Epoch: 5| Step: 6
Training loss: 2.528507947921753
Validation loss: 2.342211200344947

Epoch: 5| Step: 7
Training loss: 3.0567755699157715
Validation loss: 2.322515700453071

Epoch: 5| Step: 8
Training loss: 2.251063823699951
Validation loss: 2.2928876235920894

Epoch: 5| Step: 9
Training loss: 2.0646424293518066
Validation loss: 2.278488605253158

Epoch: 5| Step: 10
Training loss: 2.4321649074554443
Validation loss: 2.2625854630624094

Epoch: 90| Step: 0
Training loss: 2.477681875228882
Validation loss: 2.2472206648959907

Epoch: 5| Step: 1
Training loss: 2.5275397300720215
Validation loss: 2.2423485299592376

Epoch: 5| Step: 2
Training loss: 2.180577278137207
Validation loss: 2.249667283027403

Epoch: 5| Step: 3
Training loss: 2.3295578956604004
Validation loss: 2.273497453299902

Epoch: 5| Step: 4
Training loss: 2.607224464416504
Validation loss: 2.2916953614963

Epoch: 5| Step: 5
Training loss: 2.493104934692383
Validation loss: 2.3248854580745903

Epoch: 5| Step: 6
Training loss: 3.3424694538116455
Validation loss: 2.336458312567844

Epoch: 5| Step: 7
Training loss: 2.2838759422302246
Validation loss: 2.303596391472765

Epoch: 5| Step: 8
Training loss: 2.628495693206787
Validation loss: 2.2755266145993303

Epoch: 5| Step: 9
Training loss: 2.460930824279785
Validation loss: 2.2629067872160222

Epoch: 5| Step: 10
Training loss: 2.6198976039886475
Validation loss: 2.2602481585676952

Epoch: 91| Step: 0
Training loss: 2.5225234031677246
Validation loss: 2.259742926525813

Epoch: 5| Step: 1
Training loss: 3.0582945346832275
Validation loss: 2.260509475584953

Epoch: 5| Step: 2
Training loss: 2.2867414951324463
Validation loss: 2.2659405098166516

Epoch: 5| Step: 3
Training loss: 2.9453330039978027
Validation loss: 2.2659216696216213

Epoch: 5| Step: 4
Training loss: 2.3863186836242676
Validation loss: 2.2881593986224105

Epoch: 5| Step: 5
Training loss: 2.7560112476348877
Validation loss: 2.2757719973082184

Epoch: 5| Step: 6
Training loss: 3.167019844055176
Validation loss: 2.260994129283454

Epoch: 5| Step: 7
Training loss: 2.2848739624023438
Validation loss: 2.250680926025555

Epoch: 5| Step: 8
Training loss: 2.2562167644500732
Validation loss: 2.247547423967751

Epoch: 5| Step: 9
Training loss: 2.0671005249023438
Validation loss: 2.2386642553473033

Epoch: 5| Step: 10
Training loss: 2.1713147163391113
Validation loss: 2.241303715654599

Epoch: 92| Step: 0
Training loss: 2.552157163619995
Validation loss: 2.248491641013853

Epoch: 5| Step: 1
Training loss: 2.899169445037842
Validation loss: 2.2620534819941365

Epoch: 5| Step: 2
Training loss: 2.3359551429748535
Validation loss: 2.270529467572448

Epoch: 5| Step: 3
Training loss: 1.9433205127716064
Validation loss: 2.29429599290253

Epoch: 5| Step: 4
Training loss: 2.348665237426758
Validation loss: 2.309097993758417

Epoch: 5| Step: 5
Training loss: 2.3929519653320312
Validation loss: 2.2985315156239334

Epoch: 5| Step: 6
Training loss: 2.61570405960083
Validation loss: 2.258095987381474

Epoch: 5| Step: 7
Training loss: 2.838656187057495
Validation loss: 2.238764606496339

Epoch: 5| Step: 8
Training loss: 2.431687116622925
Validation loss: 2.2481790409293225

Epoch: 5| Step: 9
Training loss: 2.6217546463012695
Validation loss: 2.258347270309284

Epoch: 5| Step: 10
Training loss: 2.7987897396087646
Validation loss: 2.284183491942703

Epoch: 93| Step: 0
Training loss: 3.307305097579956
Validation loss: 2.3013665932481007

Epoch: 5| Step: 1
Training loss: 2.522951364517212
Validation loss: 2.2722020918323147

Epoch: 5| Step: 2
Training loss: 2.1176085472106934
Validation loss: 2.2607191019160773

Epoch: 5| Step: 3
Training loss: 2.3996386528015137
Validation loss: 2.2257837377568728

Epoch: 5| Step: 4
Training loss: 2.569087028503418
Validation loss: 2.2260699323428574

Epoch: 5| Step: 5
Training loss: 3.2505252361297607
Validation loss: 2.214617636895949

Epoch: 5| Step: 6
Training loss: 2.8519558906555176
Validation loss: 2.2331382882210518

Epoch: 5| Step: 7
Training loss: 2.0065667629241943
Validation loss: 2.2461599226920836

Epoch: 5| Step: 8
Training loss: 2.3445496559143066
Validation loss: 2.260205855933569

Epoch: 5| Step: 9
Training loss: 2.006467342376709
Validation loss: 2.2680790424346924

Epoch: 5| Step: 10
Training loss: 2.5786468982696533
Validation loss: 2.257334150293822

Epoch: 94| Step: 0
Training loss: 2.584246873855591
Validation loss: 2.244690005497266

Epoch: 5| Step: 1
Training loss: 2.0403800010681152
Validation loss: 2.23485763354968

Epoch: 5| Step: 2
Training loss: 2.2237536907196045
Validation loss: 2.2288834920493503

Epoch: 5| Step: 3
Training loss: 2.8358967304229736
Validation loss: 2.213493703514017

Epoch: 5| Step: 4
Training loss: 2.513989210128784
Validation loss: 2.2217633467848583

Epoch: 5| Step: 5
Training loss: 2.8562958240509033
Validation loss: 2.2126653450791554

Epoch: 5| Step: 6
Training loss: 2.354905605316162
Validation loss: 2.220492988504389

Epoch: 5| Step: 7
Training loss: 2.817660093307495
Validation loss: 2.220241037748193

Epoch: 5| Step: 8
Training loss: 2.1658425331115723
Validation loss: 2.228479172593804

Epoch: 5| Step: 9
Training loss: 3.133139133453369
Validation loss: 2.2264887056043072

Epoch: 5| Step: 10
Training loss: 2.050266742706299
Validation loss: 2.232778851703931

Epoch: 95| Step: 0
Training loss: 2.1890993118286133
Validation loss: 2.2258009269673336

Epoch: 5| Step: 1
Training loss: 2.1974384784698486
Validation loss: 2.2294236742040163

Epoch: 5| Step: 2
Training loss: 2.8907103538513184
Validation loss: 2.2300928305554133

Epoch: 5| Step: 3
Training loss: 2.6851887702941895
Validation loss: 2.241615818392846

Epoch: 5| Step: 4
Training loss: 2.9592678546905518
Validation loss: 2.25629255079454

Epoch: 5| Step: 5
Training loss: 2.535956859588623
Validation loss: 2.2750411700176936

Epoch: 5| Step: 6
Training loss: 3.112140655517578
Validation loss: 2.2999359843551472

Epoch: 5| Step: 7
Training loss: 2.615229845046997
Validation loss: 2.3240249131315496

Epoch: 5| Step: 8
Training loss: 1.8841975927352905
Validation loss: 2.3103823200348885

Epoch: 5| Step: 9
Training loss: 2.3392271995544434
Validation loss: 2.2849940561479136

Epoch: 5| Step: 10
Training loss: 2.2756640911102295
Validation loss: 2.2526237323719966

Epoch: 96| Step: 0
Training loss: 3.23230242729187
Validation loss: 2.2289980996039604

Epoch: 5| Step: 1
Training loss: 2.329119920730591
Validation loss: 2.216682780173517

Epoch: 5| Step: 2
Training loss: 2.040105104446411
Validation loss: 2.2108753701691986

Epoch: 5| Step: 3
Training loss: 2.7259058952331543
Validation loss: 2.2211692307585027

Epoch: 5| Step: 4
Training loss: 2.800076961517334
Validation loss: 2.23195751508077

Epoch: 5| Step: 5
Training loss: 2.42309308052063
Validation loss: 2.242156147956848

Epoch: 5| Step: 6
Training loss: 2.505399227142334
Validation loss: 2.242098408360635

Epoch: 5| Step: 7
Training loss: 2.1042087078094482
Validation loss: 2.242273002542475

Epoch: 5| Step: 8
Training loss: 2.0766124725341797
Validation loss: 2.233255446598094

Epoch: 5| Step: 9
Training loss: 2.8714709281921387
Validation loss: 2.216475663646575

Epoch: 5| Step: 10
Training loss: 2.6821494102478027
Validation loss: 2.212656336445962

Epoch: 97| Step: 0
Training loss: 2.4598045349121094
Validation loss: 2.2170820313115276

Epoch: 5| Step: 1
Training loss: 2.816906452178955
Validation loss: 2.236243645350138

Epoch: 5| Step: 2
Training loss: 1.921823263168335
Validation loss: 2.2348882306006645

Epoch: 5| Step: 3
Training loss: 2.1535513401031494
Validation loss: 2.243400712167063

Epoch: 5| Step: 4
Training loss: 2.4683585166931152
Validation loss: 2.2585794848780476

Epoch: 5| Step: 5
Training loss: 2.8766982555389404
Validation loss: 2.252802747552113

Epoch: 5| Step: 6
Training loss: 2.9136853218078613
Validation loss: 2.260699784883889

Epoch: 5| Step: 7
Training loss: 2.557751178741455
Validation loss: 2.253732201873615

Epoch: 5| Step: 8
Training loss: 2.1828994750976562
Validation loss: 2.2486591441656953

Epoch: 5| Step: 9
Training loss: 2.937211513519287
Validation loss: 2.248302741717267

Epoch: 5| Step: 10
Training loss: 2.1055679321289062
Validation loss: 2.2491815525998353

Epoch: 98| Step: 0
Training loss: 1.6634209156036377
Validation loss: 2.243991054514403

Epoch: 5| Step: 1
Training loss: 2.2894937992095947
Validation loss: 2.2281252671313543

Epoch: 5| Step: 2
Training loss: 2.560211658477783
Validation loss: 2.2246889760417323

Epoch: 5| Step: 3
Training loss: 2.6352920532226562
Validation loss: 2.2175435507169334

Epoch: 5| Step: 4
Training loss: 2.2877376079559326
Validation loss: 2.214445407672595

Epoch: 5| Step: 5
Training loss: 2.3372762203216553
Validation loss: 2.2090395291646323

Epoch: 5| Step: 6
Training loss: 2.6626555919647217
Validation loss: 2.2104590349299933

Epoch: 5| Step: 7
Training loss: 2.889056921005249
Validation loss: 2.2151876700821744

Epoch: 5| Step: 8
Training loss: 2.5733184814453125
Validation loss: 2.2439535356337026

Epoch: 5| Step: 9
Training loss: 2.693385601043701
Validation loss: 2.242321869378449

Epoch: 5| Step: 10
Training loss: 2.979060173034668
Validation loss: 2.2423912427758657

Epoch: 99| Step: 0
Training loss: 2.1715211868286133
Validation loss: 2.231434832337082

Epoch: 5| Step: 1
Training loss: 2.6157314777374268
Validation loss: 2.2157807875705022

Epoch: 5| Step: 2
Training loss: 1.8338524103164673
Validation loss: 2.220998737119859

Epoch: 5| Step: 3
Training loss: 2.0985145568847656
Validation loss: 2.2279390122300837

Epoch: 5| Step: 4
Training loss: 3.3029308319091797
Validation loss: 2.234285751978556

Epoch: 5| Step: 5
Training loss: 2.716487169265747
Validation loss: 2.253807685708487

Epoch: 5| Step: 6
Training loss: 2.6429848670959473
Validation loss: 2.2522594954377864

Epoch: 5| Step: 7
Training loss: 2.3703532218933105
Validation loss: 2.270828793125768

Epoch: 5| Step: 8
Training loss: 2.4574854373931885
Validation loss: 2.293362791820239

Epoch: 5| Step: 9
Training loss: 2.712299346923828
Validation loss: 2.3132444658587055

Epoch: 5| Step: 10
Training loss: 2.5624780654907227
Validation loss: 2.320619667730024

Epoch: 100| Step: 0
Training loss: 2.4142298698425293
Validation loss: 2.3204195384056336

Epoch: 5| Step: 1
Training loss: 2.866410255432129
Validation loss: 2.276079265020227

Epoch: 5| Step: 2
Training loss: 2.7972187995910645
Validation loss: 2.2160692394420667

Epoch: 5| Step: 3
Training loss: 2.059786319732666
Validation loss: 2.1915681105788036

Epoch: 5| Step: 4
Training loss: 2.431969165802002
Validation loss: 2.1842022813776487

Epoch: 5| Step: 5
Training loss: 2.0382866859436035
Validation loss: 2.183082101165607

Epoch: 5| Step: 6
Training loss: 2.158113956451416
Validation loss: 2.1910075910629763

Epoch: 5| Step: 7
Training loss: 3.0660574436187744
Validation loss: 2.1938045832418624

Epoch: 5| Step: 8
Training loss: 2.827629804611206
Validation loss: 2.182974103958376

Epoch: 5| Step: 9
Training loss: 2.5340843200683594
Validation loss: 2.18486278031462

Epoch: 5| Step: 10
Training loss: 2.6411569118499756
Validation loss: 2.1798866154045187

Epoch: 101| Step: 0
Training loss: 1.7692954540252686
Validation loss: 2.182006774410125

Epoch: 5| Step: 1
Training loss: 3.331439256668091
Validation loss: 2.1869569747678694

Epoch: 5| Step: 2
Training loss: 2.164882183074951
Validation loss: 2.2080518084187664

Epoch: 5| Step: 3
Training loss: 2.549923896789551
Validation loss: 2.2422612969593336

Epoch: 5| Step: 4
Training loss: 2.3724727630615234
Validation loss: 2.2892314285360356

Epoch: 5| Step: 5
Training loss: 2.8099706172943115
Validation loss: 2.3105199952279367

Epoch: 5| Step: 6
Training loss: 1.54293692111969
Validation loss: 2.330011110151968

Epoch: 5| Step: 7
Training loss: 2.803326368331909
Validation loss: 2.3577531050610285

Epoch: 5| Step: 8
Training loss: 2.7960052490234375
Validation loss: 2.3215433705237603

Epoch: 5| Step: 9
Training loss: 2.8023743629455566
Validation loss: 2.2931571391321

Epoch: 5| Step: 10
Training loss: 2.898115634918213
Validation loss: 2.2359300839003695

Epoch: 102| Step: 0
Training loss: 2.1778852939605713
Validation loss: 2.2147612443534275

Epoch: 5| Step: 1
Training loss: 2.5671257972717285
Validation loss: 2.2038973454506166

Epoch: 5| Step: 2
Training loss: 2.915541410446167
Validation loss: 2.1982500783858763

Epoch: 5| Step: 3
Training loss: 1.8063713312149048
Validation loss: 2.2048534193346576

Epoch: 5| Step: 4
Training loss: 2.5369925498962402
Validation loss: 2.1992631355921426

Epoch: 5| Step: 5
Training loss: 2.7728240489959717
Validation loss: 2.193769488283383

Epoch: 5| Step: 6
Training loss: 2.4743826389312744
Validation loss: 2.1971078508643695

Epoch: 5| Step: 7
Training loss: 2.95208477973938
Validation loss: 2.203958631843649

Epoch: 5| Step: 8
Training loss: 2.0393552780151367
Validation loss: 2.2121502737845145

Epoch: 5| Step: 9
Training loss: 2.6348586082458496
Validation loss: 2.2122973421568513

Epoch: 5| Step: 10
Training loss: 2.607783794403076
Validation loss: 2.2092905813647854

Epoch: 103| Step: 0
Training loss: 2.1434288024902344
Validation loss: 2.1965487926237044

Epoch: 5| Step: 1
Training loss: 2.5750362873077393
Validation loss: 2.1990976154163318

Epoch: 5| Step: 2
Training loss: 3.274475574493408
Validation loss: 2.1903889051047702

Epoch: 5| Step: 3
Training loss: 2.780144691467285
Validation loss: 2.1991660107848463

Epoch: 5| Step: 4
Training loss: 1.9781980514526367
Validation loss: 2.2091060889664518

Epoch: 5| Step: 5
Training loss: 2.354419708251953
Validation loss: 2.228988762824766

Epoch: 5| Step: 6
Training loss: 2.018066644668579
Validation loss: 2.238031020728491

Epoch: 5| Step: 7
Training loss: 2.037753105163574
Validation loss: 2.2590446625986407

Epoch: 5| Step: 8
Training loss: 2.7098145484924316
Validation loss: 2.258562316176712

Epoch: 5| Step: 9
Training loss: 2.8899083137512207
Validation loss: 2.265318685962308

Epoch: 5| Step: 10
Training loss: 2.4485132694244385
Validation loss: 2.266899488305533

Epoch: 104| Step: 0
Training loss: 2.4050655364990234
Validation loss: 2.2476007451293287

Epoch: 5| Step: 1
Training loss: 2.3108699321746826
Validation loss: 2.2025739018635084

Epoch: 5| Step: 2
Training loss: 1.9345123767852783
Validation loss: 2.1921290197680072

Epoch: 5| Step: 3
Training loss: 3.3036131858825684
Validation loss: 2.1832220297987743

Epoch: 5| Step: 4
Training loss: 2.289005756378174
Validation loss: 2.1700937850500948

Epoch: 5| Step: 5
Training loss: 2.6368136405944824
Validation loss: 2.165730804525396

Epoch: 5| Step: 6
Training loss: 1.9921214580535889
Validation loss: 2.1751643611538793

Epoch: 5| Step: 7
Training loss: 2.5483975410461426
Validation loss: 2.169317396738196

Epoch: 5| Step: 8
Training loss: 2.182593584060669
Validation loss: 2.1651145335166686

Epoch: 5| Step: 9
Training loss: 2.723909854888916
Validation loss: 2.1638766052902385

Epoch: 5| Step: 10
Training loss: 2.8949906826019287
Validation loss: 2.1656299380845923

Epoch: 105| Step: 0
Training loss: 2.0599796772003174
Validation loss: 2.1734606630058697

Epoch: 5| Step: 1
Training loss: 2.3094496726989746
Validation loss: 2.183245598628957

Epoch: 5| Step: 2
Training loss: 2.877574920654297
Validation loss: 2.1896552091003745

Epoch: 5| Step: 3
Training loss: 2.208038568496704
Validation loss: 2.179396338360284

Epoch: 5| Step: 4
Training loss: 2.235522508621216
Validation loss: 2.1725550492604575

Epoch: 5| Step: 5
Training loss: 2.785342216491699
Validation loss: 2.1692333336799376

Epoch: 5| Step: 6
Training loss: 2.7204089164733887
Validation loss: 2.1782594534658615

Epoch: 5| Step: 7
Training loss: 2.8354249000549316
Validation loss: 2.1758150131471696

Epoch: 5| Step: 8
Training loss: 1.930413007736206
Validation loss: 2.1842875685743106

Epoch: 5| Step: 9
Training loss: 2.693192720413208
Validation loss: 2.19609917876541

Epoch: 5| Step: 10
Training loss: 2.770329475402832
Validation loss: 2.1841892529559392

Epoch: 106| Step: 0
Training loss: 2.208434820175171
Validation loss: 2.181470517189272

Epoch: 5| Step: 1
Training loss: 2.6588025093078613
Validation loss: 2.1795800629482476

Epoch: 5| Step: 2
Training loss: 2.9718825817108154
Validation loss: 2.186210947652017

Epoch: 5| Step: 3
Training loss: 2.4260857105255127
Validation loss: 2.2039884623660835

Epoch: 5| Step: 4
Training loss: 1.4164245128631592
Validation loss: 2.205623680545438

Epoch: 5| Step: 5
Training loss: 2.95300030708313
Validation loss: 2.226363451250138

Epoch: 5| Step: 6
Training loss: 2.161726474761963
Validation loss: 2.2275685584673317

Epoch: 5| Step: 7
Training loss: 2.5766541957855225
Validation loss: 2.2183754444122314

Epoch: 5| Step: 8
Training loss: 2.517244815826416
Validation loss: 2.1883927570876254

Epoch: 5| Step: 9
Training loss: 2.946718692779541
Validation loss: 2.1759875051436888

Epoch: 5| Step: 10
Training loss: 2.21419620513916
Validation loss: 2.163487652296661

Epoch: 107| Step: 0
Training loss: 1.9481747150421143
Validation loss: 2.1604531298401537

Epoch: 5| Step: 1
Training loss: 2.1113905906677246
Validation loss: 2.1671244790477138

Epoch: 5| Step: 2
Training loss: 2.5018792152404785
Validation loss: 2.1787200435515373

Epoch: 5| Step: 3
Training loss: 3.0757393836975098
Validation loss: 2.1816496541423183

Epoch: 5| Step: 4
Training loss: 2.614229202270508
Validation loss: 2.1754505044670513

Epoch: 5| Step: 5
Training loss: 2.1808230876922607
Validation loss: 2.18420688439441

Epoch: 5| Step: 6
Training loss: 2.6856064796447754
Validation loss: 2.188764008142615

Epoch: 5| Step: 7
Training loss: 2.683607578277588
Validation loss: 2.1764326582672777

Epoch: 5| Step: 8
Training loss: 2.849428653717041
Validation loss: 2.169771453385712

Epoch: 5| Step: 9
Training loss: 1.5077362060546875
Validation loss: 2.166436877301944

Epoch: 5| Step: 10
Training loss: 2.774923801422119
Validation loss: 2.1584857330527356

Epoch: 108| Step: 0
Training loss: 2.6538596153259277
Validation loss: 2.1677368584499566

Epoch: 5| Step: 1
Training loss: 2.6599221229553223
Validation loss: 2.1738309270592144

Epoch: 5| Step: 2
Training loss: 2.643127918243408
Validation loss: 2.177523289957354

Epoch: 5| Step: 3
Training loss: 1.7896230220794678
Validation loss: 2.185695496938562

Epoch: 5| Step: 4
Training loss: 2.40912127494812
Validation loss: 2.179721083692325

Epoch: 5| Step: 5
Training loss: 2.045330047607422
Validation loss: 2.1609058713400238

Epoch: 5| Step: 6
Training loss: 2.2473535537719727
Validation loss: 2.1506041044829995

Epoch: 5| Step: 7
Training loss: 2.817814826965332
Validation loss: 2.148094141355125

Epoch: 5| Step: 8
Training loss: 3.0712292194366455
Validation loss: 2.1457932969575286

Epoch: 5| Step: 9
Training loss: 2.2817816734313965
Validation loss: 2.15548127184632

Epoch: 5| Step: 10
Training loss: 2.107454538345337
Validation loss: 2.153578899239981

Epoch: 109| Step: 0
Training loss: 2.1166393756866455
Validation loss: 2.154730625050042

Epoch: 5| Step: 1
Training loss: 3.1097846031188965
Validation loss: 2.1521830789504515

Epoch: 5| Step: 2
Training loss: 2.7485668659210205
Validation loss: 2.1660950337686846

Epoch: 5| Step: 3
Training loss: 2.2488980293273926
Validation loss: 2.154342534721539

Epoch: 5| Step: 4
Training loss: 2.1355299949645996
Validation loss: 2.1531810068315074

Epoch: 5| Step: 5
Training loss: 2.768312454223633
Validation loss: 2.143338441848755

Epoch: 5| Step: 6
Training loss: 2.180995464324951
Validation loss: 2.164599748067958

Epoch: 5| Step: 7
Training loss: 1.9306541681289673
Validation loss: 2.1842646470633884

Epoch: 5| Step: 8
Training loss: 2.744874954223633
Validation loss: 2.215870382965252

Epoch: 5| Step: 9
Training loss: 2.9134089946746826
Validation loss: 2.2633457465838362

Epoch: 5| Step: 10
Training loss: 2.152219772338867
Validation loss: 2.3134731554215953

Epoch: 110| Step: 0
Training loss: 2.5627529621124268
Validation loss: 2.2759112440129763

Epoch: 5| Step: 1
Training loss: 2.608501434326172
Validation loss: 2.2084196049679994

Epoch: 5| Step: 2
Training loss: 1.7889705896377563
Validation loss: 2.164029831527382

Epoch: 5| Step: 3
Training loss: 2.6131253242492676
Validation loss: 2.152009719161577

Epoch: 5| Step: 4
Training loss: 2.8974673748016357
Validation loss: 2.139186696339679

Epoch: 5| Step: 5
Training loss: 2.646214246749878
Validation loss: 2.138194248240481

Epoch: 5| Step: 6
Training loss: 2.320160388946533
Validation loss: 2.144081108031734

Epoch: 5| Step: 7
Training loss: 2.0490875244140625
Validation loss: 2.138690757495101

Epoch: 5| Step: 8
Training loss: 2.5002245903015137
Validation loss: 2.1458556934069564

Epoch: 5| Step: 9
Training loss: 1.904381513595581
Validation loss: 2.1400540272394815

Epoch: 5| Step: 10
Training loss: 3.094853401184082
Validation loss: 2.142314692979218

Epoch: 111| Step: 0
Training loss: 2.592381238937378
Validation loss: 2.155070653525732

Epoch: 5| Step: 1
Training loss: 1.6951453685760498
Validation loss: 2.1822692809566373

Epoch: 5| Step: 2
Training loss: 1.9226138591766357
Validation loss: 2.21843962002826

Epoch: 5| Step: 3
Training loss: 3.0753276348114014
Validation loss: 2.2799627729641494

Epoch: 5| Step: 4
Training loss: 2.2771992683410645
Validation loss: 2.3196014819606656

Epoch: 5| Step: 5
Training loss: 2.6144986152648926
Validation loss: 2.391834987107144

Epoch: 5| Step: 6
Training loss: 2.8964591026306152
Validation loss: 2.31714040745971

Epoch: 5| Step: 7
Training loss: 2.6072213649749756
Validation loss: 2.238464570814563

Epoch: 5| Step: 8
Training loss: 2.6345479488372803
Validation loss: 2.2009551294388308

Epoch: 5| Step: 9
Training loss: 2.448575258255005
Validation loss: 2.182274228783064

Epoch: 5| Step: 10
Training loss: 2.4877052307128906
Validation loss: 2.162067799157994

Epoch: 112| Step: 0
Training loss: 2.6033947467803955
Validation loss: 2.156376684865644

Epoch: 5| Step: 1
Training loss: 2.032191514968872
Validation loss: 2.1391203070199616

Epoch: 5| Step: 2
Training loss: 2.447154998779297
Validation loss: 2.148063311012842

Epoch: 5| Step: 3
Training loss: 2.4852371215820312
Validation loss: 2.1444159656442623

Epoch: 5| Step: 4
Training loss: 2.3162131309509277
Validation loss: 2.1410142875486806

Epoch: 5| Step: 5
Training loss: 2.8274316787719727
Validation loss: 2.1482400676255584

Epoch: 5| Step: 6
Training loss: 2.572563648223877
Validation loss: 2.150021081329674

Epoch: 5| Step: 7
Training loss: 2.951869487762451
Validation loss: 2.142288855327073

Epoch: 5| Step: 8
Training loss: 2.4309639930725098
Validation loss: 2.1495834217276624

Epoch: 5| Step: 9
Training loss: 2.3095226287841797
Validation loss: 2.15052923464006

Epoch: 5| Step: 10
Training loss: 2.0614633560180664
Validation loss: 2.1405622164408364

Epoch: 113| Step: 0
Training loss: 1.6570427417755127
Validation loss: 2.1624558253954818

Epoch: 5| Step: 1
Training loss: 2.81437349319458
Validation loss: 2.196837668777794

Epoch: 5| Step: 2
Training loss: 2.2812485694885254
Validation loss: 2.2360523951950895

Epoch: 5| Step: 3
Training loss: 2.6756114959716797
Validation loss: 2.273698486307616

Epoch: 5| Step: 4
Training loss: 2.847372531890869
Validation loss: 2.25045504108552

Epoch: 5| Step: 5
Training loss: 2.483041763305664
Validation loss: 2.1998487851952993

Epoch: 5| Step: 6
Training loss: 2.173388957977295
Validation loss: 2.1526989219009236

Epoch: 5| Step: 7
Training loss: 2.664100170135498
Validation loss: 2.157111011525636

Epoch: 5| Step: 8
Training loss: 2.157733201980591
Validation loss: 2.151086071486114

Epoch: 5| Step: 9
Training loss: 2.0723366737365723
Validation loss: 2.1540955343554096

Epoch: 5| Step: 10
Training loss: 3.163419008255005
Validation loss: 2.178240209497431

Epoch: 114| Step: 0
Training loss: 3.0794801712036133
Validation loss: 2.188695582010413

Epoch: 5| Step: 1
Training loss: 2.1674327850341797
Validation loss: 2.1754667246213524

Epoch: 5| Step: 2
Training loss: 2.972473621368408
Validation loss: 2.166469704720282

Epoch: 5| Step: 3
Training loss: 1.9320461750030518
Validation loss: 2.1537207877764137

Epoch: 5| Step: 4
Training loss: 2.5896055698394775
Validation loss: 2.157087100449429

Epoch: 5| Step: 5
Training loss: 2.3791050910949707
Validation loss: 2.14278289323212

Epoch: 5| Step: 6
Training loss: 2.275944948196411
Validation loss: 2.1533478818913943

Epoch: 5| Step: 7
Training loss: 2.291175365447998
Validation loss: 2.147046512173068

Epoch: 5| Step: 8
Training loss: 2.107790470123291
Validation loss: 2.16043992452724

Epoch: 5| Step: 9
Training loss: 2.371290683746338
Validation loss: 2.1609388166858303

Epoch: 5| Step: 10
Training loss: 2.500922679901123
Validation loss: 2.162247955158193

Epoch: 115| Step: 0
Training loss: 2.2678616046905518
Validation loss: 2.1594350773801088

Epoch: 5| Step: 1
Training loss: 2.196052074432373
Validation loss: 2.1629382410357074

Epoch: 5| Step: 2
Training loss: 2.8517889976501465
Validation loss: 2.1681834318304576

Epoch: 5| Step: 3
Training loss: 2.110365867614746
Validation loss: 2.148678961620536

Epoch: 5| Step: 4
Training loss: 2.3769452571868896
Validation loss: 2.156967111813125

Epoch: 5| Step: 5
Training loss: 3.1999270915985107
Validation loss: 2.1540915709669872

Epoch: 5| Step: 6
Training loss: 1.8689628839492798
Validation loss: 2.153640199733037

Epoch: 5| Step: 7
Training loss: 1.9982261657714844
Validation loss: 2.144176072971795

Epoch: 5| Step: 8
Training loss: 2.5149388313293457
Validation loss: 2.138146226124097

Epoch: 5| Step: 9
Training loss: 2.6715054512023926
Validation loss: 2.1349518119647937

Epoch: 5| Step: 10
Training loss: 2.510188579559326
Validation loss: 2.1332747244065806

Epoch: 116| Step: 0
Training loss: 1.7480418682098389
Validation loss: 2.1433882995318343

Epoch: 5| Step: 1
Training loss: 2.6495041847229004
Validation loss: 2.143873478776665

Epoch: 5| Step: 2
Training loss: 2.5185153484344482
Validation loss: 2.1495040360317437

Epoch: 5| Step: 3
Training loss: 1.9235652685165405
Validation loss: 2.1500341623060164

Epoch: 5| Step: 4
Training loss: 1.9430996179580688
Validation loss: 2.1485439077500375

Epoch: 5| Step: 5
Training loss: 2.24068021774292
Validation loss: 2.1464112368963097

Epoch: 5| Step: 6
Training loss: 3.12453293800354
Validation loss: 2.134294033050537

Epoch: 5| Step: 7
Training loss: 2.084301710128784
Validation loss: 2.1301376140245827

Epoch: 5| Step: 8
Training loss: 3.138840675354004
Validation loss: 2.14995256803369

Epoch: 5| Step: 9
Training loss: 2.732239246368408
Validation loss: 2.14417516544301

Epoch: 5| Step: 10
Training loss: 2.4008240699768066
Validation loss: 2.1439383388847433

Epoch: 117| Step: 0
Training loss: 2.2869465351104736
Validation loss: 2.1568198383495374

Epoch: 5| Step: 1
Training loss: 2.511615753173828
Validation loss: 2.168380944959579

Epoch: 5| Step: 2
Training loss: 2.363893747329712
Validation loss: 2.149519870358129

Epoch: 5| Step: 3
Training loss: 2.5436248779296875
Validation loss: 2.137023595071608

Epoch: 5| Step: 4
Training loss: 2.365844249725342
Validation loss: 2.1293936416666996

Epoch: 5| Step: 5
Training loss: 2.5854992866516113
Validation loss: 2.1224310321192585

Epoch: 5| Step: 6
Training loss: 2.6287567615509033
Validation loss: 2.1127862943116056

Epoch: 5| Step: 7
Training loss: 2.7825636863708496
Validation loss: 2.1177053400265273

Epoch: 5| Step: 8
Training loss: 2.393709182739258
Validation loss: 2.119003785553799

Epoch: 5| Step: 9
Training loss: 1.874833345413208
Validation loss: 2.1388863671210503

Epoch: 5| Step: 10
Training loss: 2.0399420261383057
Validation loss: 2.1574481584692515

Epoch: 118| Step: 0
Training loss: 2.7417986392974854
Validation loss: 2.155398594435825

Epoch: 5| Step: 1
Training loss: 2.7156028747558594
Validation loss: 2.1628396152168192

Epoch: 5| Step: 2
Training loss: 2.5521247386932373
Validation loss: 2.1570000930499007

Epoch: 5| Step: 3
Training loss: 2.5344138145446777
Validation loss: 2.1479501519151913

Epoch: 5| Step: 4
Training loss: 1.6439945697784424
Validation loss: 2.1370873015414

Epoch: 5| Step: 5
Training loss: 2.3247153759002686
Validation loss: 2.1279281364974154

Epoch: 5| Step: 6
Training loss: 1.8068275451660156
Validation loss: 2.1564185401444793

Epoch: 5| Step: 7
Training loss: 2.594921827316284
Validation loss: 2.187774340311686

Epoch: 5| Step: 8
Training loss: 2.66908597946167
Validation loss: 2.221658855356196

Epoch: 5| Step: 9
Training loss: 2.297184467315674
Validation loss: 2.269730806350708

Epoch: 5| Step: 10
Training loss: 2.888353109359741
Validation loss: 2.237922942766579

Epoch: 119| Step: 0
Training loss: 2.722137928009033
Validation loss: 2.1920552945906118

Epoch: 5| Step: 1
Training loss: 2.5610313415527344
Validation loss: 2.1410730269647416

Epoch: 5| Step: 2
Training loss: 2.0317206382751465
Validation loss: 2.124230287408316

Epoch: 5| Step: 3
Training loss: 2.431705951690674
Validation loss: 2.122953925081479

Epoch: 5| Step: 4
Training loss: 2.8245558738708496
Validation loss: 2.122536297767393

Epoch: 5| Step: 5
Training loss: 2.525822401046753
Validation loss: 2.1061371116228003

Epoch: 5| Step: 6
Training loss: 2.2337756156921387
Validation loss: 2.115077467374904

Epoch: 5| Step: 7
Training loss: 2.168679714202881
Validation loss: 2.1187277301665275

Epoch: 5| Step: 8
Training loss: 2.6843366622924805
Validation loss: 2.114098741162208

Epoch: 5| Step: 9
Training loss: 2.0679500102996826
Validation loss: 2.118839366461641

Epoch: 5| Step: 10
Training loss: 1.9680732488632202
Validation loss: 2.132747921892392

Epoch: 120| Step: 0
Training loss: 2.02642822265625
Validation loss: 2.1466603945660334

Epoch: 5| Step: 1
Training loss: 2.104346752166748
Validation loss: 2.138078902357368

Epoch: 5| Step: 2
Training loss: 2.217865467071533
Validation loss: 2.1351785557244414

Epoch: 5| Step: 3
Training loss: 2.6911330223083496
Validation loss: 2.162462698516025

Epoch: 5| Step: 4
Training loss: 2.405034065246582
Validation loss: 2.1500023770075973

Epoch: 5| Step: 5
Training loss: 2.853391170501709
Validation loss: 2.1554146223170783

Epoch: 5| Step: 6
Training loss: 1.847794771194458
Validation loss: 2.128210790695683

Epoch: 5| Step: 7
Training loss: 2.987863063812256
Validation loss: 2.140377903497347

Epoch: 5| Step: 8
Training loss: 3.1059746742248535
Validation loss: 2.1607464180197766

Epoch: 5| Step: 9
Training loss: 1.887125015258789
Validation loss: 2.148033777872721

Epoch: 5| Step: 10
Training loss: 2.050057888031006
Validation loss: 2.146341400761758

Epoch: 121| Step: 0
Training loss: 2.118786334991455
Validation loss: 2.1191766902964604

Epoch: 5| Step: 1
Training loss: 2.374777317047119
Validation loss: 2.11533155492557

Epoch: 5| Step: 2
Training loss: 3.2659523487091064
Validation loss: 2.120160764263522

Epoch: 5| Step: 3
Training loss: 2.387479782104492
Validation loss: 2.1091040539485153

Epoch: 5| Step: 4
Training loss: 3.0725455284118652
Validation loss: 2.1089882017463766

Epoch: 5| Step: 5
Training loss: 1.9185314178466797
Validation loss: 2.09272087517605

Epoch: 5| Step: 6
Training loss: 1.660913109779358
Validation loss: 2.0849789752755115

Epoch: 5| Step: 7
Training loss: 2.4490439891815186
Validation loss: 2.0856305347975863

Epoch: 5| Step: 8
Training loss: 2.211397886276245
Validation loss: 2.074960152308146

Epoch: 5| Step: 9
Training loss: 2.2463126182556152
Validation loss: 2.0859655667376775

Epoch: 5| Step: 10
Training loss: 2.379328966140747
Validation loss: 2.08854829624135

Epoch: 122| Step: 0
Training loss: 2.7923786640167236
Validation loss: 2.09590644221152

Epoch: 5| Step: 1
Training loss: 2.8253073692321777
Validation loss: 2.113459481987902

Epoch: 5| Step: 2
Training loss: 2.4979195594787598
Validation loss: 2.1324605685408398

Epoch: 5| Step: 3
Training loss: 2.116658926010132
Validation loss: 2.135853950695325

Epoch: 5| Step: 4
Training loss: 2.303311586380005
Validation loss: 2.1501326637883342

Epoch: 5| Step: 5
Training loss: 1.7319988012313843
Validation loss: 2.192189931869507

Epoch: 5| Step: 6
Training loss: 2.0638370513916016
Validation loss: 2.224301395877715

Epoch: 5| Step: 7
Training loss: 2.6102585792541504
Validation loss: 2.2605767634607132

Epoch: 5| Step: 8
Training loss: 2.8092122077941895
Validation loss: 2.229929421537666

Epoch: 5| Step: 9
Training loss: 2.2338340282440186
Validation loss: 2.186653116697906

Epoch: 5| Step: 10
Training loss: 2.0322422981262207
Validation loss: 2.1480404664111394

Epoch: 123| Step: 0
Training loss: 2.2193634510040283
Validation loss: 2.1220109975466164

Epoch: 5| Step: 1
Training loss: 2.673699140548706
Validation loss: 2.095731794193227

Epoch: 5| Step: 2
Training loss: 2.9605553150177
Validation loss: 2.0937917450422883

Epoch: 5| Step: 3
Training loss: 1.9552135467529297
Validation loss: 2.0951145797647457

Epoch: 5| Step: 4
Training loss: 2.417555570602417
Validation loss: 2.076952559973604

Epoch: 5| Step: 5
Training loss: 2.4786128997802734
Validation loss: 2.0866353486173894

Epoch: 5| Step: 6
Training loss: 2.115812063217163
Validation loss: 2.0771502743485155

Epoch: 5| Step: 7
Training loss: 2.6521763801574707
Validation loss: 2.0864586086683374

Epoch: 5| Step: 8
Training loss: 2.2756659984588623
Validation loss: 2.0902254222541727

Epoch: 5| Step: 9
Training loss: 2.088392734527588
Validation loss: 2.075265387053131

Epoch: 5| Step: 10
Training loss: 2.087374448776245
Validation loss: 2.087431493625846

Epoch: 124| Step: 0
Training loss: 1.8557487726211548
Validation loss: 2.0971690288154026

Epoch: 5| Step: 1
Training loss: 2.95861554145813
Validation loss: 2.082929116423412

Epoch: 5| Step: 2
Training loss: 2.1337740421295166
Validation loss: 2.087573041198074

Epoch: 5| Step: 3
Training loss: 2.0812065601348877
Validation loss: 2.085237531251805

Epoch: 5| Step: 4
Training loss: 2.9343008995056152
Validation loss: 2.09414469170314

Epoch: 5| Step: 5
Training loss: 2.26554012298584
Validation loss: 2.0950644939176497

Epoch: 5| Step: 6
Training loss: 2.7792789936065674
Validation loss: 2.0997381799964496

Epoch: 5| Step: 7
Training loss: 1.8581254482269287
Validation loss: 2.1198680913576515

Epoch: 5| Step: 8
Training loss: 2.6435961723327637
Validation loss: 2.1289848717310096

Epoch: 5| Step: 9
Training loss: 1.9951326847076416
Validation loss: 2.13682831487348

Epoch: 5| Step: 10
Training loss: 2.5094048976898193
Validation loss: 2.1397979092854325

Epoch: 125| Step: 0
Training loss: 2.283766031265259
Validation loss: 2.1225154579326673

Epoch: 5| Step: 1
Training loss: 1.9778480529785156
Validation loss: 2.1090731851516233

Epoch: 5| Step: 2
Training loss: 1.9302294254302979
Validation loss: 2.0961627344931326

Epoch: 5| Step: 3
Training loss: 2.4745090007781982
Validation loss: 2.102081514173938

Epoch: 5| Step: 4
Training loss: 2.4492177963256836
Validation loss: 2.101982834518597

Epoch: 5| Step: 5
Training loss: 2.6974594593048096
Validation loss: 2.101534366607666

Epoch: 5| Step: 6
Training loss: 2.573381185531616
Validation loss: 2.0916153179701937

Epoch: 5| Step: 7
Training loss: 1.7222591638565063
Validation loss: 2.0883147665249404

Epoch: 5| Step: 8
Training loss: 2.4124302864074707
Validation loss: 2.1096285850771013

Epoch: 5| Step: 9
Training loss: 3.0599842071533203
Validation loss: 2.11460288622046

Epoch: 5| Step: 10
Training loss: 2.237924337387085
Validation loss: 2.120411560099612

Epoch: 126| Step: 0
Training loss: 2.4479308128356934
Validation loss: 2.095745493006963

Epoch: 5| Step: 1
Training loss: 2.6329360008239746
Validation loss: 2.085548032996475

Epoch: 5| Step: 2
Training loss: 2.1116600036621094
Validation loss: 2.0768702055818293

Epoch: 5| Step: 3
Training loss: 1.6658786535263062
Validation loss: 2.0688695189773396

Epoch: 5| Step: 4
Training loss: 2.530391216278076
Validation loss: 2.068810648815606

Epoch: 5| Step: 5
Training loss: 2.563041925430298
Validation loss: 2.0705348573705202

Epoch: 5| Step: 6
Training loss: 2.220116138458252
Validation loss: 2.065383957278344

Epoch: 5| Step: 7
Training loss: 2.7961506843566895
Validation loss: 2.081998727654898

Epoch: 5| Step: 8
Training loss: 1.9554831981658936
Validation loss: 2.0687288315065446

Epoch: 5| Step: 9
Training loss: 2.815986394882202
Validation loss: 2.074808059200164

Epoch: 5| Step: 10
Training loss: 2.125905990600586
Validation loss: 2.0712492863337197

Epoch: 127| Step: 0
Training loss: 2.658341646194458
Validation loss: 2.0803580296936857

Epoch: 5| Step: 1
Training loss: 2.2036023139953613
Validation loss: 2.083196839978618

Epoch: 5| Step: 2
Training loss: 2.3393187522888184
Validation loss: 2.088309368779582

Epoch: 5| Step: 3
Training loss: 2.0555872917175293
Validation loss: 2.0823925490020425

Epoch: 5| Step: 4
Training loss: 1.8241817951202393
Validation loss: 2.081179481680675

Epoch: 5| Step: 5
Training loss: 2.329688310623169
Validation loss: 2.07802648826312

Epoch: 5| Step: 6
Training loss: 2.67073392868042
Validation loss: 2.0925648302160282

Epoch: 5| Step: 7
Training loss: 2.4279067516326904
Validation loss: 2.0815623857641734

Epoch: 5| Step: 8
Training loss: 2.0713095664978027
Validation loss: 2.0776820528891777

Epoch: 5| Step: 9
Training loss: 2.310941219329834
Validation loss: 2.0686633561247136

Epoch: 5| Step: 10
Training loss: 2.88496994972229
Validation loss: 2.073298315848074

Epoch: 128| Step: 0
Training loss: 2.6623129844665527
Validation loss: 2.093808029287605

Epoch: 5| Step: 1
Training loss: 2.511147975921631
Validation loss: 2.083041444901497

Epoch: 5| Step: 2
Training loss: 1.870452642440796
Validation loss: 2.085502907794009

Epoch: 5| Step: 3
Training loss: 2.2917842864990234
Validation loss: 2.1048688914186213

Epoch: 5| Step: 4
Training loss: 2.2497262954711914
Validation loss: 2.1086057052817395

Epoch: 5| Step: 5
Training loss: 2.061133623123169
Validation loss: 2.1152626135016

Epoch: 5| Step: 6
Training loss: 2.5515363216400146
Validation loss: 2.1351356711438907

Epoch: 5| Step: 7
Training loss: 2.113349437713623
Validation loss: 2.131967262555194

Epoch: 5| Step: 8
Training loss: 2.055445432662964
Validation loss: 2.1449243612186883

Epoch: 5| Step: 9
Training loss: 2.681896448135376
Validation loss: 2.133145820709967

Epoch: 5| Step: 10
Training loss: 2.5895304679870605
Validation loss: 2.127184865295246

Epoch: 129| Step: 0
Training loss: 2.1278622150421143
Validation loss: 2.098315659389701

Epoch: 5| Step: 1
Training loss: 2.1545310020446777
Validation loss: 2.0944081416694065

Epoch: 5| Step: 2
Training loss: 2.4387946128845215
Validation loss: 2.0744780776321248

Epoch: 5| Step: 3
Training loss: 2.576964855194092
Validation loss: 2.0702095441920783

Epoch: 5| Step: 4
Training loss: 2.070537567138672
Validation loss: 2.068145182824904

Epoch: 5| Step: 5
Training loss: 1.9817390441894531
Validation loss: 2.0582577772037958

Epoch: 5| Step: 6
Training loss: 2.2957255840301514
Validation loss: 2.0597689100491103

Epoch: 5| Step: 7
Training loss: 2.69500994682312
Validation loss: 2.070468205277638

Epoch: 5| Step: 8
Training loss: 2.4681148529052734
Validation loss: 2.084703697953173

Epoch: 5| Step: 9
Training loss: 2.5613903999328613
Validation loss: 2.093454025124991

Epoch: 5| Step: 10
Training loss: 2.16619610786438
Validation loss: 2.084416793238732

Epoch: 130| Step: 0
Training loss: 2.4218602180480957
Validation loss: 2.093444521709155

Epoch: 5| Step: 1
Training loss: 2.5606777667999268
Validation loss: 2.0960637587372974

Epoch: 5| Step: 2
Training loss: 2.1803507804870605
Validation loss: 2.113466232053695

Epoch: 5| Step: 3
Training loss: 1.9984575510025024
Validation loss: 2.1041070863764775

Epoch: 5| Step: 4
Training loss: 2.3461358547210693
Validation loss: 2.1182291174447663

Epoch: 5| Step: 5
Training loss: 2.671757936477661
Validation loss: 2.1161871469149025

Epoch: 5| Step: 6
Training loss: 2.263669729232788
Validation loss: 2.145811270642024

Epoch: 5| Step: 7
Training loss: 2.5512170791625977
Validation loss: 2.1278137545431814

Epoch: 5| Step: 8
Training loss: 2.7156059741973877
Validation loss: 2.1145784034523913

Epoch: 5| Step: 9
Training loss: 2.0844202041625977
Validation loss: 2.077307483201386

Epoch: 5| Step: 10
Training loss: 1.786138653755188
Validation loss: 2.055647123244501

Epoch: 131| Step: 0
Training loss: 2.6523022651672363
Validation loss: 2.0625323069992887

Epoch: 5| Step: 1
Training loss: 2.0197043418884277
Validation loss: 2.093270096727597

Epoch: 5| Step: 2
Training loss: 1.9055675268173218
Validation loss: 2.100109391315009

Epoch: 5| Step: 3
Training loss: 2.635615110397339
Validation loss: 2.125793344231062

Epoch: 5| Step: 4
Training loss: 3.0883703231811523
Validation loss: 2.113835706505724

Epoch: 5| Step: 5
Training loss: 2.6735422611236572
Validation loss: 2.091485995118336

Epoch: 5| Step: 6
Training loss: 2.0519344806671143
Validation loss: 2.0755928383078626

Epoch: 5| Step: 7
Training loss: 2.3753905296325684
Validation loss: 2.0703199396851244

Epoch: 5| Step: 8
Training loss: 2.6244335174560547
Validation loss: 2.089702178073186

Epoch: 5| Step: 9
Training loss: 2.0285379886627197
Validation loss: 2.1333389538590626

Epoch: 5| Step: 10
Training loss: 2.1136415004730225
Validation loss: 2.165729780350962

Epoch: 132| Step: 0
Training loss: 2.4756522178649902
Validation loss: 2.1361081292552333

Epoch: 5| Step: 1
Training loss: 1.8933343887329102
Validation loss: 2.136905304847225

Epoch: 5| Step: 2
Training loss: 2.652045249938965
Validation loss: 2.124749924546929

Epoch: 5| Step: 3
Training loss: 3.0394225120544434
Validation loss: 2.153007253523796

Epoch: 5| Step: 4
Training loss: 2.0476410388946533
Validation loss: 2.175406212447792

Epoch: 5| Step: 5
Training loss: 2.276679039001465
Validation loss: 2.133128866072624

Epoch: 5| Step: 6
Training loss: 1.6931568384170532
Validation loss: 2.118058890424749

Epoch: 5| Step: 7
Training loss: 2.400913715362549
Validation loss: 2.10672805898933

Epoch: 5| Step: 8
Training loss: 2.289306163787842
Validation loss: 2.0990192761985202

Epoch: 5| Step: 9
Training loss: 2.291790008544922
Validation loss: 2.079361205459923

Epoch: 5| Step: 10
Training loss: 2.8942506313323975
Validation loss: 2.066330994329145

Epoch: 133| Step: 0
Training loss: 1.877123236656189
Validation loss: 2.057892161030923

Epoch: 5| Step: 1
Training loss: 2.057974338531494
Validation loss: 2.064181820038826

Epoch: 5| Step: 2
Training loss: 3.171494245529175
Validation loss: 2.0551830171256937

Epoch: 5| Step: 3
Training loss: 1.9039363861083984
Validation loss: 2.060412842740295

Epoch: 5| Step: 4
Training loss: 2.468766450881958
Validation loss: 2.0734492053267775

Epoch: 5| Step: 5
Training loss: 2.693572998046875
Validation loss: 2.0866282537419307

Epoch: 5| Step: 6
Training loss: 1.5100734233856201
Validation loss: 2.096882886784051

Epoch: 5| Step: 7
Training loss: 2.4789721965789795
Validation loss: 2.1025006066086473

Epoch: 5| Step: 8
Training loss: 1.8515517711639404
Validation loss: 2.1112220466777845

Epoch: 5| Step: 9
Training loss: 3.1061253547668457
Validation loss: 2.1211758608459146

Epoch: 5| Step: 10
Training loss: 2.213346481323242
Validation loss: 2.103634862489598

Epoch: 134| Step: 0
Training loss: 2.244117021560669
Validation loss: 2.1024442923966276

Epoch: 5| Step: 1
Training loss: 2.8411240577697754
Validation loss: 2.115334963285795

Epoch: 5| Step: 2
Training loss: 2.4616739749908447
Validation loss: 2.1051298469625492

Epoch: 5| Step: 3
Training loss: 1.8808189630508423
Validation loss: 2.0958239211831042

Epoch: 5| Step: 4
Training loss: 2.2931084632873535
Validation loss: 2.085181209348863

Epoch: 5| Step: 5
Training loss: 2.6202845573425293
Validation loss: 2.0898635643784718

Epoch: 5| Step: 6
Training loss: 2.216177463531494
Validation loss: 2.0761340971915954

Epoch: 5| Step: 7
Training loss: 1.7332794666290283
Validation loss: 2.083853563954753

Epoch: 5| Step: 8
Training loss: 1.9191303253173828
Validation loss: 2.0931658026992634

Epoch: 5| Step: 9
Training loss: 2.2732596397399902
Validation loss: 2.0959729430496052

Epoch: 5| Step: 10
Training loss: 3.139047861099243
Validation loss: 2.078367599876978

Epoch: 135| Step: 0
Training loss: 1.9648411273956299
Validation loss: 2.0653447489584646

Epoch: 5| Step: 1
Training loss: 2.172905445098877
Validation loss: 2.073821542083576

Epoch: 5| Step: 2
Training loss: 2.105060577392578
Validation loss: 2.0852741220945954

Epoch: 5| Step: 3
Training loss: 2.1860687732696533
Validation loss: 2.1084391916951826

Epoch: 5| Step: 4
Training loss: 2.465937614440918
Validation loss: 2.1410783721554663

Epoch: 5| Step: 5
Training loss: 2.6926231384277344
Validation loss: 2.198427359263102

Epoch: 5| Step: 6
Training loss: 1.974334955215454
Validation loss: 2.188360893598167

Epoch: 5| Step: 7
Training loss: 2.255568504333496
Validation loss: 2.155643937408283

Epoch: 5| Step: 8
Training loss: 2.9862093925476074
Validation loss: 2.096113533102056

Epoch: 5| Step: 9
Training loss: 2.198983669281006
Validation loss: 2.0492098921088764

Epoch: 5| Step: 10
Training loss: 2.29141902923584
Validation loss: 2.051696636343515

Epoch: 136| Step: 0
Training loss: 2.235788106918335
Validation loss: 2.066504070835729

Epoch: 5| Step: 1
Training loss: 2.126432418823242
Validation loss: 2.0857306834190124

Epoch: 5| Step: 2
Training loss: 2.6148533821105957
Validation loss: 2.0651869850773967

Epoch: 5| Step: 3
Training loss: 2.110067844390869
Validation loss: 2.04957664397455

Epoch: 5| Step: 4
Training loss: 2.2748653888702393
Validation loss: 2.048036052334693

Epoch: 5| Step: 5
Training loss: 2.7005767822265625
Validation loss: 2.0541390936861754

Epoch: 5| Step: 6
Training loss: 2.590879440307617
Validation loss: 2.05801498505377

Epoch: 5| Step: 7
Training loss: 1.8042875528335571
Validation loss: 2.051003900907373

Epoch: 5| Step: 8
Training loss: 2.62967586517334
Validation loss: 2.035172361199574

Epoch: 5| Step: 9
Training loss: 2.094783306121826
Validation loss: 2.048137964740876

Epoch: 5| Step: 10
Training loss: 2.156423807144165
Validation loss: 2.048666395166869

Epoch: 137| Step: 0
Training loss: 2.3130645751953125
Validation loss: 2.0412086427852674

Epoch: 5| Step: 1
Training loss: 2.3528664112091064
Validation loss: 2.0421459995290285

Epoch: 5| Step: 2
Training loss: 1.470703363418579
Validation loss: 2.047718542878346

Epoch: 5| Step: 3
Training loss: 2.7297637462615967
Validation loss: 2.046564720010245

Epoch: 5| Step: 4
Training loss: 2.349465847015381
Validation loss: 2.058241564740417

Epoch: 5| Step: 5
Training loss: 1.7740745544433594
Validation loss: 2.055433932171073

Epoch: 5| Step: 6
Training loss: 1.9962173700332642
Validation loss: 2.0791668071541736

Epoch: 5| Step: 7
Training loss: 2.3214361667633057
Validation loss: 2.0831772947824128

Epoch: 5| Step: 8
Training loss: 2.1546132564544678
Validation loss: 2.162120903691938

Epoch: 5| Step: 9
Training loss: 3.3332772254943848
Validation loss: 2.1584124552306307

Epoch: 5| Step: 10
Training loss: 2.304532766342163
Validation loss: 2.125851818310317

Epoch: 138| Step: 0
Training loss: 2.9221975803375244
Validation loss: 2.0965199188519548

Epoch: 5| Step: 1
Training loss: 1.4427471160888672
Validation loss: 2.066789541193234

Epoch: 5| Step: 2
Training loss: 2.474372148513794
Validation loss: 2.0626661841587355

Epoch: 5| Step: 3
Training loss: 1.9986178874969482
Validation loss: 2.061143062447989

Epoch: 5| Step: 4
Training loss: 2.0627880096435547
Validation loss: 2.103377132005589

Epoch: 5| Step: 5
Training loss: 2.4822967052459717
Validation loss: 2.1125811889607418

Epoch: 5| Step: 6
Training loss: 2.012211561203003
Validation loss: 2.117313419618914

Epoch: 5| Step: 7
Training loss: 2.4699885845184326
Validation loss: 2.1124354562451764

Epoch: 5| Step: 8
Training loss: 2.4207236766815186
Validation loss: 2.10601330572559

Epoch: 5| Step: 9
Training loss: 2.5053086280822754
Validation loss: 2.0900900543376966

Epoch: 5| Step: 10
Training loss: 2.165860176086426
Validation loss: 2.069984092507311

Epoch: 139| Step: 0
Training loss: 2.306079387664795
Validation loss: 2.085772047760666

Epoch: 5| Step: 1
Training loss: 1.932143211364746
Validation loss: 2.082686221727761

Epoch: 5| Step: 2
Training loss: 2.7040741443634033
Validation loss: 2.101753363045313

Epoch: 5| Step: 3
Training loss: 1.9191577434539795
Validation loss: 2.112190754182877

Epoch: 5| Step: 4
Training loss: 2.1766929626464844
Validation loss: 2.1125181951830463

Epoch: 5| Step: 5
Training loss: 1.9050605297088623
Validation loss: 2.110031097166

Epoch: 5| Step: 6
Training loss: 2.1871743202209473
Validation loss: 2.0846022559750463

Epoch: 5| Step: 7
Training loss: 2.070115327835083
Validation loss: 2.051051846114538

Epoch: 5| Step: 8
Training loss: 2.263859987258911
Validation loss: 2.0515808777142595

Epoch: 5| Step: 9
Training loss: 2.6348166465759277
Validation loss: 2.0804403289671867

Epoch: 5| Step: 10
Training loss: 2.896387815475464
Validation loss: 2.1275216456382506

Epoch: 140| Step: 0
Training loss: 2.635117769241333
Validation loss: 2.1039423455474195

Epoch: 5| Step: 1
Training loss: 1.66990065574646
Validation loss: 2.0806728639910297

Epoch: 5| Step: 2
Training loss: 2.4476754665374756
Validation loss: 2.060979248375021

Epoch: 5| Step: 3
Training loss: 1.9364311695098877
Validation loss: 2.0391810555611887

Epoch: 5| Step: 4
Training loss: 1.8727744817733765
Validation loss: 2.0496578626735236

Epoch: 5| Step: 5
Training loss: 2.7443201541900635
Validation loss: 2.0462094148000083

Epoch: 5| Step: 6
Training loss: 2.0297293663024902
Validation loss: 2.056523461495676

Epoch: 5| Step: 7
Training loss: 2.476074695587158
Validation loss: 2.0374284585316977

Epoch: 5| Step: 8
Training loss: 2.804614543914795
Validation loss: 2.031120652793556

Epoch: 5| Step: 9
Training loss: 2.0469565391540527
Validation loss: 2.039999261979134

Epoch: 5| Step: 10
Training loss: 1.9994298219680786
Validation loss: 2.0336683873207337

Epoch: 141| Step: 0
Training loss: 2.181676149368286
Validation loss: 2.0331973593722106

Epoch: 5| Step: 1
Training loss: 1.533582329750061
Validation loss: 2.0299445480428715

Epoch: 5| Step: 2
Training loss: 2.011793851852417
Validation loss: 2.0249431748544016

Epoch: 5| Step: 3
Training loss: 2.751105785369873
Validation loss: 2.0291048877982685

Epoch: 5| Step: 4
Training loss: 2.7629764080047607
Validation loss: 2.0218677290024294

Epoch: 5| Step: 5
Training loss: 1.900926947593689
Validation loss: 2.0359849660627303

Epoch: 5| Step: 6
Training loss: 2.3662140369415283
Validation loss: 2.0215262264333744

Epoch: 5| Step: 7
Training loss: 2.5368199348449707
Validation loss: 2.0386673429960847

Epoch: 5| Step: 8
Training loss: 2.2449793815612793
Validation loss: 2.038426778649771

Epoch: 5| Step: 9
Training loss: 2.122720241546631
Validation loss: 2.0447838511518253

Epoch: 5| Step: 10
Training loss: 1.874295949935913
Validation loss: 2.080150181247342

Epoch: 142| Step: 0
Training loss: 2.6035361289978027
Validation loss: 2.1019934966999996

Epoch: 5| Step: 1
Training loss: 1.9324169158935547
Validation loss: 2.096695037298305

Epoch: 5| Step: 2
Training loss: 1.6769249439239502
Validation loss: 2.0638891035510647

Epoch: 5| Step: 3
Training loss: 2.4087634086608887
Validation loss: 2.040232164885408

Epoch: 5| Step: 4
Training loss: 2.6629433631896973
Validation loss: 2.0383764723295807

Epoch: 5| Step: 5
Training loss: 2.0234341621398926
Validation loss: 2.0578425033118135

Epoch: 5| Step: 6
Training loss: 2.147408962249756
Validation loss: 2.070075770860077

Epoch: 5| Step: 7
Training loss: 2.346524715423584
Validation loss: 2.0486633559708953

Epoch: 5| Step: 8
Training loss: 2.570128917694092
Validation loss: 2.0469526026838567

Epoch: 5| Step: 9
Training loss: 2.049556255340576
Validation loss: 2.0517289228336786

Epoch: 5| Step: 10
Training loss: 1.8046973943710327
Validation loss: 2.0436967854858725

Epoch: 143| Step: 0
Training loss: 2.582021951675415
Validation loss: 2.0473695211513068

Epoch: 5| Step: 1
Training loss: 1.780311942100525
Validation loss: 2.0591987153535247

Epoch: 5| Step: 2
Training loss: 2.293602466583252
Validation loss: 2.0656059621482767

Epoch: 5| Step: 3
Training loss: 1.4447722434997559
Validation loss: 2.0709724567269765

Epoch: 5| Step: 4
Training loss: 2.3449277877807617
Validation loss: 2.0921028301280034

Epoch: 5| Step: 5
Training loss: 1.6387735605239868
Validation loss: 2.102118020416588

Epoch: 5| Step: 6
Training loss: 2.8000500202178955
Validation loss: 2.1017798557076404

Epoch: 5| Step: 7
Training loss: 2.120933771133423
Validation loss: 2.1030347321623113

Epoch: 5| Step: 8
Training loss: 2.4688260555267334
Validation loss: 2.1476515569994525

Epoch: 5| Step: 9
Training loss: 2.5578794479370117
Validation loss: 2.1691807303377377

Epoch: 5| Step: 10
Training loss: 2.1989493370056152
Validation loss: 2.165125734062605

Epoch: 144| Step: 0
Training loss: 2.4504659175872803
Validation loss: 2.128954883544676

Epoch: 5| Step: 1
Training loss: 2.4948296546936035
Validation loss: 2.0820084438529065

Epoch: 5| Step: 2
Training loss: 1.9257434606552124
Validation loss: 2.031764558566514

Epoch: 5| Step: 3
Training loss: 1.8943264484405518
Validation loss: 2.0227419560955417

Epoch: 5| Step: 4
Training loss: 2.0187201499938965
Validation loss: 2.020568632310437

Epoch: 5| Step: 5
Training loss: 2.483050584793091
Validation loss: 2.0409460554840746

Epoch: 5| Step: 6
Training loss: 2.0785446166992188
Validation loss: 2.021799704079987

Epoch: 5| Step: 7
Training loss: 2.6804299354553223
Validation loss: 2.0329340760425856

Epoch: 5| Step: 8
Training loss: 2.2211339473724365
Validation loss: 2.028817449846575

Epoch: 5| Step: 9
Training loss: 2.054229259490967
Validation loss: 2.0202517048005135

Epoch: 5| Step: 10
Training loss: 2.0232694149017334
Validation loss: 2.0307364925261466

Epoch: 145| Step: 0
Training loss: 1.6598732471466064
Validation loss: 2.05089751110282

Epoch: 5| Step: 1
Training loss: 2.8069427013397217
Validation loss: 2.090037691977716

Epoch: 5| Step: 2
Training loss: 1.9321823120117188
Validation loss: 2.1981519832405993

Epoch: 5| Step: 3
Training loss: 2.3711912631988525
Validation loss: 2.240295240955968

Epoch: 5| Step: 4
Training loss: 2.4919075965881348
Validation loss: 2.228021175630631

Epoch: 5| Step: 5
Training loss: 2.205479145050049
Validation loss: 2.1675034774247037

Epoch: 5| Step: 6
Training loss: 1.9380671977996826
Validation loss: 2.1156908645424792

Epoch: 5| Step: 7
Training loss: 2.532331705093384
Validation loss: 2.135928548792357

Epoch: 5| Step: 8
Training loss: 2.4195683002471924
Validation loss: 2.1400527800283125

Epoch: 5| Step: 9
Training loss: 1.8359086513519287
Validation loss: 2.093020935212412

Epoch: 5| Step: 10
Training loss: 2.1205101013183594
Validation loss: 2.0871079583321848

Epoch: 146| Step: 0
Training loss: 2.2860212326049805
Validation loss: 2.0828564987387708

Epoch: 5| Step: 1
Training loss: 1.31565260887146
Validation loss: 2.065851229493336

Epoch: 5| Step: 2
Training loss: 1.6058658361434937
Validation loss: 2.049709612323392

Epoch: 5| Step: 3
Training loss: 2.1355226039886475
Validation loss: 2.03810142829854

Epoch: 5| Step: 4
Training loss: 2.690917491912842
Validation loss: 2.040862093689621

Epoch: 5| Step: 5
Training loss: 2.7187089920043945
Validation loss: 2.046851404251591

Epoch: 5| Step: 6
Training loss: 2.3590569496154785
Validation loss: 2.0683902591787358

Epoch: 5| Step: 7
Training loss: 2.747079849243164
Validation loss: 2.0563727758264028

Epoch: 5| Step: 8
Training loss: 2.145559787750244
Validation loss: 2.0396589925212245

Epoch: 5| Step: 9
Training loss: 2.154181718826294
Validation loss: 2.009660837470844

Epoch: 5| Step: 10
Training loss: 2.0781800746917725
Validation loss: 2.006479190241906

Epoch: 147| Step: 0
Training loss: 2.2749311923980713
Validation loss: 2.0256206502196608

Epoch: 5| Step: 1
Training loss: 1.9198949337005615
Validation loss: 2.056837511318986

Epoch: 5| Step: 2
Training loss: 2.016026496887207
Validation loss: 2.0863444574417604

Epoch: 5| Step: 3
Training loss: 2.029205799102783
Validation loss: 2.1016717046819706

Epoch: 5| Step: 4
Training loss: 2.3704981803894043
Validation loss: 2.09564180784328

Epoch: 5| Step: 5
Training loss: 2.456953763961792
Validation loss: 2.09049173965249

Epoch: 5| Step: 6
Training loss: 1.96152663230896
Validation loss: 2.0813290034571

Epoch: 5| Step: 7
Training loss: 2.4065933227539062
Validation loss: 2.064279361437726

Epoch: 5| Step: 8
Training loss: 1.8369611501693726
Validation loss: 2.096038446631483

Epoch: 5| Step: 9
Training loss: 2.4790070056915283
Validation loss: 2.1442380412932365

Epoch: 5| Step: 10
Training loss: 2.40622615814209
Validation loss: 2.160896452524329

Epoch: 148| Step: 0
Training loss: 2.7531485557556152
Validation loss: 2.179407769633878

Epoch: 5| Step: 1
Training loss: 1.8520549535751343
Validation loss: 2.153677490449721

Epoch: 5| Step: 2
Training loss: 2.0873916149139404
Validation loss: 2.0758237633653867

Epoch: 5| Step: 3
Training loss: 1.8338816165924072
Validation loss: 2.0352400272123274

Epoch: 5| Step: 4
Training loss: 2.014366626739502
Validation loss: 1.9945809148973035

Epoch: 5| Step: 5
Training loss: 2.6721198558807373
Validation loss: 1.9803541001453195

Epoch: 5| Step: 6
Training loss: 2.28235125541687
Validation loss: 1.9783148355381464

Epoch: 5| Step: 7
Training loss: 1.9105695486068726
Validation loss: 2.011999850632042

Epoch: 5| Step: 8
Training loss: 1.75205397605896
Validation loss: 2.0134499329392628

Epoch: 5| Step: 9
Training loss: 2.6993017196655273
Validation loss: 2.013119743716332

Epoch: 5| Step: 10
Training loss: 2.3703060150146484
Validation loss: 2.0153585685196744

Epoch: 149| Step: 0
Training loss: 2.358018398284912
Validation loss: 2.015604188365321

Epoch: 5| Step: 1
Training loss: 2.358182668685913
Validation loss: 1.9926239521272722

Epoch: 5| Step: 2
Training loss: 1.8201347589492798
Validation loss: 2.0117754423490135

Epoch: 5| Step: 3
Training loss: 1.6950191259384155
Validation loss: 2.0059702896302745

Epoch: 5| Step: 4
Training loss: 1.4601588249206543
Validation loss: 2.016228439987347

Epoch: 5| Step: 5
Training loss: 2.3204617500305176
Validation loss: 2.0570534160060268

Epoch: 5| Step: 6
Training loss: 2.2307722568511963
Validation loss: 2.0834083877583986

Epoch: 5| Step: 7
Training loss: 2.545271635055542
Validation loss: 2.1193266607099965

Epoch: 5| Step: 8
Training loss: 2.348020315170288
Validation loss: 2.083584527815542

Epoch: 5| Step: 9
Training loss: 2.469947338104248
Validation loss: 2.0436591358594995

Epoch: 5| Step: 10
Training loss: 2.2111384868621826
Validation loss: 2.0034299640245337

Epoch: 150| Step: 0
Training loss: 1.708282470703125
Validation loss: 1.9806972831808112

Epoch: 5| Step: 1
Training loss: 1.7519807815551758
Validation loss: 1.9873749620171004

Epoch: 5| Step: 2
Training loss: 2.6303136348724365
Validation loss: 1.9776230806945472

Epoch: 5| Step: 3
Training loss: 1.7962814569473267
Validation loss: 1.9828638184455134

Epoch: 5| Step: 4
Training loss: 2.6553049087524414
Validation loss: 1.9750216648142824

Epoch: 5| Step: 5
Training loss: 2.384955644607544
Validation loss: 1.9835708064417685

Epoch: 5| Step: 6
Training loss: 1.7848037481307983
Validation loss: 1.9729630742021786

Epoch: 5| Step: 7
Training loss: 2.010890245437622
Validation loss: 1.9931144099081717

Epoch: 5| Step: 8
Training loss: 2.4260048866271973
Validation loss: 2.0149503907849713

Epoch: 5| Step: 9
Training loss: 1.6830503940582275
Validation loss: 2.0261878121283745

Epoch: 5| Step: 10
Training loss: 3.0364649295806885
Validation loss: 2.0435158744935067

Epoch: 151| Step: 0
Training loss: 1.80938720703125
Validation loss: 2.0566501143158122

Epoch: 5| Step: 1
Training loss: 1.648664116859436
Validation loss: 2.0514932012045257

Epoch: 5| Step: 2
Training loss: 1.8462250232696533
Validation loss: 2.0557876581786783

Epoch: 5| Step: 3
Training loss: 2.4492897987365723
Validation loss: 2.0396490430319183

Epoch: 5| Step: 4
Training loss: 2.5668601989746094
Validation loss: 2.035848116361967

Epoch: 5| Step: 5
Training loss: 2.273327350616455
Validation loss: 2.0484990791607927

Epoch: 5| Step: 6
Training loss: 1.868424654006958
Validation loss: 2.0614727671428392

Epoch: 5| Step: 7
Training loss: 2.0842623710632324
Validation loss: 2.0459938690226567

Epoch: 5| Step: 8
Training loss: 2.267071485519409
Validation loss: 2.0575186103902836

Epoch: 5| Step: 9
Training loss: 2.5403006076812744
Validation loss: 2.0505732041533276

Epoch: 5| Step: 10
Training loss: 2.372403860092163
Validation loss: 2.0367879995735745

Epoch: 152| Step: 0
Training loss: 2.1255431175231934
Validation loss: 2.007063452915479

Epoch: 5| Step: 1
Training loss: 1.9044029712677002
Validation loss: 2.0085661949649936

Epoch: 5| Step: 2
Training loss: 2.5375916957855225
Validation loss: 2.0097984754911034

Epoch: 5| Step: 3
Training loss: 2.408812999725342
Validation loss: 2.028361958842124

Epoch: 5| Step: 4
Training loss: 1.9023969173431396
Validation loss: 2.0468919738646476

Epoch: 5| Step: 5
Training loss: 2.098128080368042
Validation loss: 2.0489134839785996

Epoch: 5| Step: 6
Training loss: 2.030674934387207
Validation loss: 2.052247683207194

Epoch: 5| Step: 7
Training loss: 2.341329336166382
Validation loss: 2.054173743853005

Epoch: 5| Step: 8
Training loss: 2.2095420360565186
Validation loss: 2.057846383381915

Epoch: 5| Step: 9
Training loss: 1.8635057210922241
Validation loss: 2.061817323007891

Epoch: 5| Step: 10
Training loss: 1.88523530960083
Validation loss: 2.056701542228781

Epoch: 153| Step: 0
Training loss: 2.447113275527954
Validation loss: 2.0755301560125043

Epoch: 5| Step: 1
Training loss: 2.820420742034912
Validation loss: 2.0921733994637766

Epoch: 5| Step: 2
Training loss: 2.076456308364868
Validation loss: 2.093734771974625

Epoch: 5| Step: 3
Training loss: 1.962057113647461
Validation loss: 2.1015618321716145

Epoch: 5| Step: 4
Training loss: 2.69307541847229
Validation loss: 2.1337960663662163

Epoch: 5| Step: 5
Training loss: 2.5517730712890625
Validation loss: 2.1430087653539514

Epoch: 5| Step: 6
Training loss: 1.7323758602142334
Validation loss: 2.123971111030989

Epoch: 5| Step: 7
Training loss: 2.0956871509552
Validation loss: 2.1016476231236614

Epoch: 5| Step: 8
Training loss: 1.4072920083999634
Validation loss: 2.0907850316775742

Epoch: 5| Step: 9
Training loss: 1.9466001987457275
Validation loss: 2.0436662832895913

Epoch: 5| Step: 10
Training loss: 1.506212592124939
Validation loss: 2.038762859118882

Epoch: 154| Step: 0
Training loss: 1.9307024478912354
Validation loss: 2.0348974607324086

Epoch: 5| Step: 1
Training loss: 2.52616286277771
Validation loss: 2.0195616804143435

Epoch: 5| Step: 2
Training loss: 1.9290670156478882
Validation loss: 2.028855803192303

Epoch: 5| Step: 3
Training loss: 1.6701157093048096
Validation loss: 2.0190586146487983

Epoch: 5| Step: 4
Training loss: 1.9587234258651733
Validation loss: 2.0174841009160525

Epoch: 5| Step: 5
Training loss: 2.349313735961914
Validation loss: 2.0449856763244956

Epoch: 5| Step: 6
Training loss: 2.360729694366455
Validation loss: 2.0459745724995932

Epoch: 5| Step: 7
Training loss: 1.973524808883667
Validation loss: 2.040752822352994

Epoch: 5| Step: 8
Training loss: 2.0681772232055664
Validation loss: 2.04858394335675

Epoch: 5| Step: 9
Training loss: 1.6460888385772705
Validation loss: 2.044308434250534

Epoch: 5| Step: 10
Training loss: 2.6958954334259033
Validation loss: 2.056610543240783

Epoch: 155| Step: 0
Training loss: 1.8051834106445312
Validation loss: 2.054206271325388

Epoch: 5| Step: 1
Training loss: 2.3110480308532715
Validation loss: 2.0419366795529603

Epoch: 5| Step: 2
Training loss: 1.4780298471450806
Validation loss: 2.031671468929578

Epoch: 5| Step: 3
Training loss: 2.1103515625
Validation loss: 2.0203447136827695

Epoch: 5| Step: 4
Training loss: 1.6438987255096436
Validation loss: 2.008442328822228

Epoch: 5| Step: 5
Training loss: 2.3938097953796387
Validation loss: 2.006736683589156

Epoch: 5| Step: 6
Training loss: 2.5038914680480957
Validation loss: 2.0209819578355357

Epoch: 5| Step: 7
Training loss: 2.5413014888763428
Validation loss: 2.04181384271191

Epoch: 5| Step: 8
Training loss: 2.3411591053009033
Validation loss: 2.0642237304359354

Epoch: 5| Step: 9
Training loss: 1.844415307044983
Validation loss: 2.069952731491417

Epoch: 5| Step: 10
Training loss: 1.8382819890975952
Validation loss: 2.0765786940051663

Epoch: 156| Step: 0
Training loss: 1.516906976699829
Validation loss: 2.0935833787405365

Epoch: 5| Step: 1
Training loss: 2.1531777381896973
Validation loss: 2.0939531095566286

Epoch: 5| Step: 2
Training loss: 2.1736502647399902
Validation loss: 2.0796483242383568

Epoch: 5| Step: 3
Training loss: 1.4523584842681885
Validation loss: 2.050161107893913

Epoch: 5| Step: 4
Training loss: 2.681004285812378
Validation loss: 2.0158729758313907

Epoch: 5| Step: 5
Training loss: 2.6579208374023438
Validation loss: 2.008872106511106

Epoch: 5| Step: 6
Training loss: 2.3126440048217773
Validation loss: 2.017299098353232

Epoch: 5| Step: 7
Training loss: 1.6239407062530518
Validation loss: 2.0318192025666595

Epoch: 5| Step: 8
Training loss: 2.2683098316192627
Validation loss: 2.0336848535845355

Epoch: 5| Step: 9
Training loss: 1.5441319942474365
Validation loss: 2.0350615209148777

Epoch: 5| Step: 10
Training loss: 2.4475972652435303
Validation loss: 2.0658421913782754

Epoch: 157| Step: 0
Training loss: 1.947119951248169
Validation loss: 2.067645900992937

Epoch: 5| Step: 1
Training loss: 2.608327865600586
Validation loss: 2.0772599584312847

Epoch: 5| Step: 2
Training loss: 2.8088669776916504
Validation loss: 2.0762209994818575

Epoch: 5| Step: 3
Training loss: 1.9816694259643555
Validation loss: 2.074583384298509

Epoch: 5| Step: 4
Training loss: 1.8264567852020264
Validation loss: 2.0801549842280727

Epoch: 5| Step: 5
Training loss: 1.8246170282363892
Validation loss: 2.0409995843005437

Epoch: 5| Step: 6
Training loss: 2.475984573364258
Validation loss: 2.0505337997149398

Epoch: 5| Step: 7
Training loss: 1.6380863189697266
Validation loss: 2.0502243259901642

Epoch: 5| Step: 8
Training loss: 2.4291789531707764
Validation loss: 2.0454826893345004

Epoch: 5| Step: 9
Training loss: 1.2978371381759644
Validation loss: 2.0389592314279206

Epoch: 5| Step: 10
Training loss: 1.8075644969940186
Validation loss: 2.049991479483984

Epoch: 158| Step: 0
Training loss: 2.2898223400115967
Validation loss: 2.0323604640140327

Epoch: 5| Step: 1
Training loss: 2.118931770324707
Validation loss: 2.0036459584389963

Epoch: 5| Step: 2
Training loss: 2.0302047729492188
Validation loss: 2.0205812582405667

Epoch: 5| Step: 3
Training loss: 1.8263895511627197
Validation loss: 2.031177782243298

Epoch: 5| Step: 4
Training loss: 1.3164689540863037
Validation loss: 2.039384872682633

Epoch: 5| Step: 5
Training loss: 1.7386236190795898
Validation loss: 2.070286836675418

Epoch: 5| Step: 6
Training loss: 1.8526248931884766
Validation loss: 2.0797679449922297

Epoch: 5| Step: 7
Training loss: 2.8650174140930176
Validation loss: 2.126098555903281

Epoch: 5| Step: 8
Training loss: 2.378307819366455
Validation loss: 2.14863165732353

Epoch: 5| Step: 9
Training loss: 2.1681342124938965
Validation loss: 2.1525087818022697

Epoch: 5| Step: 10
Training loss: 2.218999147415161
Validation loss: 2.0968982545278405

Epoch: 159| Step: 0
Training loss: 2.6832470893859863
Validation loss: 2.0424797727215673

Epoch: 5| Step: 1
Training loss: 1.7517521381378174
Validation loss: 2.0354336205349175

Epoch: 5| Step: 2
Training loss: 1.5674808025360107
Validation loss: 2.023903244285173

Epoch: 5| Step: 3
Training loss: 2.138101577758789
Validation loss: 2.033911879344653

Epoch: 5| Step: 4
Training loss: 2.8101673126220703
Validation loss: 2.0210330717025267

Epoch: 5| Step: 5
Training loss: 2.3536581993103027
Validation loss: 2.0132719906427528

Epoch: 5| Step: 6
Training loss: 1.8957382440567017
Validation loss: 1.9985750182982414

Epoch: 5| Step: 7
Training loss: 1.7141926288604736
Validation loss: 2.041229183955859

Epoch: 5| Step: 8
Training loss: 1.951926827430725
Validation loss: 2.0824392354616554

Epoch: 5| Step: 9
Training loss: 1.6695661544799805
Validation loss: 2.131898723622804

Epoch: 5| Step: 10
Training loss: 2.021272659301758
Validation loss: 2.1613312177760626

Epoch: 160| Step: 0
Training loss: 1.942878007888794
Validation loss: 2.1335302873324324

Epoch: 5| Step: 1
Training loss: 1.1904979944229126
Validation loss: 2.122067746295724

Epoch: 5| Step: 2
Training loss: 2.1298394203186035
Validation loss: 2.114231924856863

Epoch: 5| Step: 3
Training loss: 2.7252628803253174
Validation loss: 2.1393389099387714

Epoch: 5| Step: 4
Training loss: 2.207622528076172
Validation loss: 2.1267027662646387

Epoch: 5| Step: 5
Training loss: 2.7871711254119873
Validation loss: 2.102514382331602

Epoch: 5| Step: 6
Training loss: 1.4609031677246094
Validation loss: 2.0837810603521203

Epoch: 5| Step: 7
Training loss: 2.163789987564087
Validation loss: 2.078640407131564

Epoch: 5| Step: 8
Training loss: 2.234177350997925
Validation loss: 2.060424986705985

Epoch: 5| Step: 9
Training loss: 1.6756515502929688
Validation loss: 2.0391755232246975

Epoch: 5| Step: 10
Training loss: 2.0498976707458496
Validation loss: 2.030321175052274

Epoch: 161| Step: 0
Training loss: 2.046661138534546
Validation loss: 2.017523834782262

Epoch: 5| Step: 1
Training loss: 2.042954683303833
Validation loss: 2.0439035854031964

Epoch: 5| Step: 2
Training loss: 2.2709438800811768
Validation loss: 2.050227918932515

Epoch: 5| Step: 3
Training loss: 2.1099090576171875
Validation loss: 2.0575382671048565

Epoch: 5| Step: 4
Training loss: 1.8881114721298218
Validation loss: 2.0530612725083546

Epoch: 5| Step: 5
Training loss: 1.9280836582183838
Validation loss: 2.0655405931575324

Epoch: 5| Step: 6
Training loss: 1.798016905784607
Validation loss: 2.078254941971071

Epoch: 5| Step: 7
Training loss: 2.181270122528076
Validation loss: 2.057920229050421

Epoch: 5| Step: 8
Training loss: 2.429929733276367
Validation loss: 2.052299145729311

Epoch: 5| Step: 9
Training loss: 1.7343389987945557
Validation loss: 2.0589562398131176

Epoch: 5| Step: 10
Training loss: 1.9080357551574707
Validation loss: 2.048834180319181

Epoch: 162| Step: 0
Training loss: 1.7663905620574951
Validation loss: 2.068396911826185

Epoch: 5| Step: 1
Training loss: 1.49894118309021
Validation loss: 2.0384038468842864

Epoch: 5| Step: 2
Training loss: 1.8605893850326538
Validation loss: 2.0358690010604037

Epoch: 5| Step: 3
Training loss: 2.0424625873565674
Validation loss: 2.0477508832049627

Epoch: 5| Step: 4
Training loss: 2.3067688941955566
Validation loss: 2.0451636622028966

Epoch: 5| Step: 5
Training loss: 2.366307020187378
Validation loss: 2.0579776610097578

Epoch: 5| Step: 6
Training loss: 2.016505718231201
Validation loss: 2.076986071883991

Epoch: 5| Step: 7
Training loss: 1.8562568426132202
Validation loss: 2.0857813640307357

Epoch: 5| Step: 8
Training loss: 2.3751323223114014
Validation loss: 2.0691233258093558

Epoch: 5| Step: 9
Training loss: 1.7010753154754639
Validation loss: 2.0312186338568248

Epoch: 5| Step: 10
Training loss: 2.450652599334717
Validation loss: 2.026265998040476

Epoch: 163| Step: 0
Training loss: 1.745090126991272
Validation loss: 2.019778877176264

Epoch: 5| Step: 1
Training loss: 2.3226094245910645
Validation loss: 2.0080803261008313

Epoch: 5| Step: 2
Training loss: 1.8943010568618774
Validation loss: 2.010221945342197

Epoch: 5| Step: 3
Training loss: 2.17641019821167
Validation loss: 2.02040329030765

Epoch: 5| Step: 4
Training loss: 1.7028499841690063
Validation loss: 1.9957657706352971

Epoch: 5| Step: 5
Training loss: 2.2272231578826904
Validation loss: 2.020020495178879

Epoch: 5| Step: 6
Training loss: 2.239253044128418
Validation loss: 2.0458662920100714

Epoch: 5| Step: 7
Training loss: 1.9206323623657227
Validation loss: 2.0839865605036416

Epoch: 5| Step: 8
Training loss: 2.1018896102905273
Validation loss: 2.099677880605062

Epoch: 5| Step: 9
Training loss: 2.0520782470703125
Validation loss: 2.107705089353746

Epoch: 5| Step: 10
Training loss: 1.8514604568481445
Validation loss: 2.0670336882273355

Epoch: 164| Step: 0
Training loss: 1.7806117534637451
Validation loss: 2.0294317968430056

Epoch: 5| Step: 1
Training loss: 2.1408610343933105
Validation loss: 2.0239029058846096

Epoch: 5| Step: 2
Training loss: 2.0363128185272217
Validation loss: 2.0210148954904206

Epoch: 5| Step: 3
Training loss: 1.8459895849227905
Validation loss: 2.0362617213238954

Epoch: 5| Step: 4
Training loss: 1.8117347955703735
Validation loss: 2.0398428260639148

Epoch: 5| Step: 5
Training loss: 0.814109206199646
Validation loss: 2.0661266952432613

Epoch: 5| Step: 6
Training loss: 2.3174617290496826
Validation loss: 2.1066061642862137

Epoch: 5| Step: 7
Training loss: 2.4135215282440186
Validation loss: 2.1111078877602854

Epoch: 5| Step: 8
Training loss: 2.0131428241729736
Validation loss: 2.0475116147789905

Epoch: 5| Step: 9
Training loss: 2.291766881942749
Validation loss: 2.027096691951957

Epoch: 5| Step: 10
Training loss: 2.2422773838043213
Validation loss: 2.0160695852771884

Epoch: 165| Step: 0
Training loss: 2.1855552196502686
Validation loss: 2.0270451115023707

Epoch: 5| Step: 1
Training loss: 2.2178597450256348
Validation loss: 2.0045616883103565

Epoch: 5| Step: 2
Training loss: 1.7944729328155518
Validation loss: 2.003556251525879

Epoch: 5| Step: 3
Training loss: 2.3701131343841553
Validation loss: 2.0104206480005735

Epoch: 5| Step: 4
Training loss: 2.295031785964966
Validation loss: 2.00602142272457

Epoch: 5| Step: 5
Training loss: 2.104163646697998
Validation loss: 2.0433553239350677

Epoch: 5| Step: 6
Training loss: 1.8002372980117798
Validation loss: 2.089209723216231

Epoch: 5| Step: 7
Training loss: 2.223283052444458
Validation loss: 2.083317542588839

Epoch: 5| Step: 8
Training loss: 1.2360740900039673
Validation loss: 2.0585255930500646

Epoch: 5| Step: 9
Training loss: 1.9821596145629883
Validation loss: 2.035219438614384

Epoch: 5| Step: 10
Training loss: 1.775092601776123
Validation loss: 1.9924302306226505

Epoch: 166| Step: 0
Training loss: 2.109872341156006
Validation loss: 1.9853116760971725

Epoch: 5| Step: 1
Training loss: 2.337707042694092
Validation loss: 1.9838030389560166

Epoch: 5| Step: 2
Training loss: 2.1979708671569824
Validation loss: 2.005450451245872

Epoch: 5| Step: 3
Training loss: 2.173584461212158
Validation loss: 1.9837422435001661

Epoch: 5| Step: 4
Training loss: 1.8043911457061768
Validation loss: 1.9661527807994554

Epoch: 5| Step: 5
Training loss: 1.7597100734710693
Validation loss: 1.9780749992657733

Epoch: 5| Step: 6
Training loss: 2.0084421634674072
Validation loss: 2.003826069575484

Epoch: 5| Step: 7
Training loss: 1.9156936407089233
Validation loss: 2.015468575621164

Epoch: 5| Step: 8
Training loss: 1.648596167564392
Validation loss: 2.0385283706008748

Epoch: 5| Step: 9
Training loss: 1.2943565845489502
Validation loss: 2.0523009620687014

Epoch: 5| Step: 10
Training loss: 2.067533493041992
Validation loss: 2.0655908379503476

Epoch: 167| Step: 0
Training loss: 2.544823169708252
Validation loss: 2.064525754221024

Epoch: 5| Step: 1
Training loss: 1.825046181678772
Validation loss: 2.028643936239263

Epoch: 5| Step: 2
Training loss: 1.6728506088256836
Validation loss: 2.0153189089990433

Epoch: 5| Step: 3
Training loss: 1.7100989818572998
Validation loss: 2.0098652673024002

Epoch: 5| Step: 4
Training loss: 2.031452178955078
Validation loss: 2.007104395538248

Epoch: 5| Step: 5
Training loss: 1.0981086492538452
Validation loss: 2.0024546602720856

Epoch: 5| Step: 6
Training loss: 2.3089675903320312
Validation loss: 2.0012100588890815

Epoch: 5| Step: 7
Training loss: 2.612337589263916
Validation loss: 1.982689485755018

Epoch: 5| Step: 8
Training loss: 1.9066312313079834
Validation loss: 1.9755655309205413

Epoch: 5| Step: 9
Training loss: 2.1510322093963623
Validation loss: 2.0071059016771216

Epoch: 5| Step: 10
Training loss: 1.510661244392395
Validation loss: 2.030699631219269

Epoch: 168| Step: 0
Training loss: 1.8873907327651978
Validation loss: 2.055892494417006

Epoch: 5| Step: 1
Training loss: 2.4837334156036377
Validation loss: 2.072333969095702

Epoch: 5| Step: 2
Training loss: 2.238347053527832
Validation loss: 2.0815083749832644

Epoch: 5| Step: 3
Training loss: 1.6564972400665283
Validation loss: 2.0664035581773326

Epoch: 5| Step: 4
Training loss: 1.771780252456665
Validation loss: 2.0374012480499926

Epoch: 5| Step: 5
Training loss: 1.3630777597427368
Validation loss: 2.025766739281275

Epoch: 5| Step: 6
Training loss: 1.7958072423934937
Validation loss: 2.0143081565057077

Epoch: 5| Step: 7
Training loss: 1.7075252532958984
Validation loss: 2.0370762373811457

Epoch: 5| Step: 8
Training loss: 2.6109423637390137
Validation loss: 2.0308664447517804

Epoch: 5| Step: 9
Training loss: 1.6483280658721924
Validation loss: 2.0499881813603062

Epoch: 5| Step: 10
Training loss: 1.965723991394043
Validation loss: 2.075242761642702

Epoch: 169| Step: 0
Training loss: 1.7858690023422241
Validation loss: 2.0660602020960983

Epoch: 5| Step: 1
Training loss: 1.528346061706543
Validation loss: 2.0298278665029876

Epoch: 5| Step: 2
Training loss: 2.1881465911865234
Validation loss: 2.0482076060387397

Epoch: 5| Step: 3
Training loss: 1.9257819652557373
Validation loss: 2.0534455289122877

Epoch: 5| Step: 4
Training loss: 2.4227585792541504
Validation loss: 2.069303927883025

Epoch: 5| Step: 5
Training loss: 2.3430261611938477
Validation loss: 2.08689965996691

Epoch: 5| Step: 6
Training loss: 1.7231823205947876
Validation loss: 2.0679374561514905

Epoch: 5| Step: 7
Training loss: 1.3594869375228882
Validation loss: 2.0488351737299273

Epoch: 5| Step: 8
Training loss: 2.509779930114746
Validation loss: 2.051211267389277

Epoch: 5| Step: 9
Training loss: 1.6793609857559204
Validation loss: 2.0426741376999886

Epoch: 5| Step: 10
Training loss: 1.4603241682052612
Validation loss: 2.053898899785934

Epoch: 170| Step: 0
Training loss: 2.1772310733795166
Validation loss: 2.0497686786036335

Epoch: 5| Step: 1
Training loss: 2.2241358757019043
Validation loss: 2.055463937021071

Epoch: 5| Step: 2
Training loss: 2.134399652481079
Validation loss: 2.0653664706855692

Epoch: 5| Step: 3
Training loss: 1.8996092081069946
Validation loss: 2.065470036639962

Epoch: 5| Step: 4
Training loss: 1.500464677810669
Validation loss: 2.086957557227022

Epoch: 5| Step: 5
Training loss: 1.8841712474822998
Validation loss: 2.0875516258260256

Epoch: 5| Step: 6
Training loss: 2.1263396739959717
Validation loss: 2.0857893049076037

Epoch: 5| Step: 7
Training loss: 1.5774297714233398
Validation loss: 2.073490027458437

Epoch: 5| Step: 8
Training loss: 2.14243745803833
Validation loss: 2.0215798347227034

Epoch: 5| Step: 9
Training loss: 1.5031311511993408
Validation loss: 1.976860874442644

Epoch: 5| Step: 10
Training loss: 1.7642114162445068
Validation loss: 1.9628786451073104

Epoch: 171| Step: 0
Training loss: 1.7068331241607666
Validation loss: 1.9492101784675353

Epoch: 5| Step: 1
Training loss: 2.0148978233337402
Validation loss: 1.949418056395746

Epoch: 5| Step: 2
Training loss: 1.3943302631378174
Validation loss: 1.9700675613136702

Epoch: 5| Step: 3
Training loss: 2.655566453933716
Validation loss: 1.989089729965374

Epoch: 5| Step: 4
Training loss: 1.6709998846054077
Validation loss: 1.9760755044157787

Epoch: 5| Step: 5
Training loss: 1.9056308269500732
Validation loss: 1.9800308237793625

Epoch: 5| Step: 6
Training loss: 2.0943381786346436
Validation loss: 2.0105968624032955

Epoch: 5| Step: 7
Training loss: 1.6028839349746704
Validation loss: 2.0421825685808734

Epoch: 5| Step: 8
Training loss: 2.0642824172973633
Validation loss: 2.1106391952883814

Epoch: 5| Step: 9
Training loss: 1.7305591106414795
Validation loss: 2.119513684703458

Epoch: 5| Step: 10
Training loss: 2.2868032455444336
Validation loss: 2.104296789374403

Epoch: 172| Step: 0
Training loss: 1.8737208843231201
Validation loss: 2.0701977258087485

Epoch: 5| Step: 1
Training loss: 2.167668581008911
Validation loss: 2.047648460634293

Epoch: 5| Step: 2
Training loss: 1.8892767429351807
Validation loss: 2.0403370511147285

Epoch: 5| Step: 3
Training loss: 1.5474039316177368
Validation loss: 2.018526615635041

Epoch: 5| Step: 4
Training loss: 1.7057552337646484
Validation loss: 2.0227938621274886

Epoch: 5| Step: 5
Training loss: 2.384016275405884
Validation loss: 2.021868554494714

Epoch: 5| Step: 6
Training loss: 1.7273235321044922
Validation loss: 2.0203280064367477

Epoch: 5| Step: 7
Training loss: 1.8121616840362549
Validation loss: 2.014643451218964

Epoch: 5| Step: 8
Training loss: 1.9868431091308594
Validation loss: 1.9891573459871355

Epoch: 5| Step: 9
Training loss: 1.8838491439819336
Validation loss: 2.0220220229958974

Epoch: 5| Step: 10
Training loss: 1.854416847229004
Validation loss: 2.0086700967563096

Epoch: 173| Step: 0
Training loss: 1.9870742559432983
Validation loss: 2.0217017486531246

Epoch: 5| Step: 1
Training loss: 1.5051982402801514
Validation loss: 2.0447808824559695

Epoch: 5| Step: 2
Training loss: 1.9954010248184204
Validation loss: 2.060027112242996

Epoch: 5| Step: 3
Training loss: 1.8709872961044312
Validation loss: 2.080667041963147

Epoch: 5| Step: 4
Training loss: 2.0150976181030273
Validation loss: 2.0810275129092637

Epoch: 5| Step: 5
Training loss: 1.3491795063018799
Validation loss: 2.0739005406697593

Epoch: 5| Step: 6
Training loss: 2.011326789855957
Validation loss: 2.0566108034503077

Epoch: 5| Step: 7
Training loss: 2.2643275260925293
Validation loss: 2.0497774129272788

Epoch: 5| Step: 8
Training loss: 2.3220441341400146
Validation loss: 2.0192583325088664

Epoch: 5| Step: 9
Training loss: 1.5158888101577759
Validation loss: 2.000014094896214

Epoch: 5| Step: 10
Training loss: 1.6392258405685425
Validation loss: 1.987122598514762

Epoch: 174| Step: 0
Training loss: 1.7081973552703857
Validation loss: 1.9674120359523322

Epoch: 5| Step: 1
Training loss: 2.2047653198242188
Validation loss: 1.9509372352271952

Epoch: 5| Step: 2
Training loss: 1.9775241613388062
Validation loss: 1.9381993855199506

Epoch: 5| Step: 3
Training loss: 1.5253894329071045
Validation loss: 1.9371190353106427

Epoch: 5| Step: 4
Training loss: 1.7247354984283447
Validation loss: 1.9378163429998583

Epoch: 5| Step: 5
Training loss: 1.8035907745361328
Validation loss: 1.962172249312042

Epoch: 5| Step: 6
Training loss: 1.9159682989120483
Validation loss: 2.0255318380171254

Epoch: 5| Step: 7
Training loss: 1.9133377075195312
Validation loss: 2.1019447208732687

Epoch: 5| Step: 8
Training loss: 2.2074007987976074
Validation loss: 2.1604116193709837

Epoch: 5| Step: 9
Training loss: 2.2179160118103027
Validation loss: 2.170085371181529

Epoch: 5| Step: 10
Training loss: 1.849749207496643
Validation loss: 2.0834017235745668

Epoch: 175| Step: 0
Training loss: 1.469879388809204
Validation loss: 2.035057815172339

Epoch: 5| Step: 1
Training loss: 2.405740261077881
Validation loss: 2.0457644565131075

Epoch: 5| Step: 2
Training loss: 2.164290428161621
Validation loss: 2.0373743810961322

Epoch: 5| Step: 3
Training loss: 1.820806860923767
Validation loss: 2.0274139399169595

Epoch: 5| Step: 4
Training loss: 2.021998167037964
Validation loss: 2.0111462557187645

Epoch: 5| Step: 5
Training loss: 1.9439033269882202
Validation loss: 2.0508736384812223

Epoch: 5| Step: 6
Training loss: 1.7587980031967163
Validation loss: 2.108734287241454

Epoch: 5| Step: 7
Training loss: 1.9078989028930664
Validation loss: 2.132907550822022

Epoch: 5| Step: 8
Training loss: 2.1465187072753906
Validation loss: 2.138843165930881

Epoch: 5| Step: 9
Training loss: 1.734393835067749
Validation loss: 2.062090742972589

Epoch: 5| Step: 10
Training loss: 1.6961997747421265
Validation loss: 2.0275288371629614

Epoch: 176| Step: 0
Training loss: 1.8582031726837158
Validation loss: 2.005067453589491

Epoch: 5| Step: 1
Training loss: 1.8522617816925049
Validation loss: 2.046318256726829

Epoch: 5| Step: 2
Training loss: 2.089104413986206
Validation loss: 2.067772762749785

Epoch: 5| Step: 3
Training loss: 1.6949892044067383
Validation loss: 2.068494100724497

Epoch: 5| Step: 4
Training loss: 1.7958675622940063
Validation loss: 2.1129788916598082

Epoch: 5| Step: 5
Training loss: 1.6558653116226196
Validation loss: 2.1786557653898835

Epoch: 5| Step: 6
Training loss: 1.5517796277999878
Validation loss: 2.2147421144670054

Epoch: 5| Step: 7
Training loss: 1.787001371383667
Validation loss: 2.1985988488761325

Epoch: 5| Step: 8
Training loss: 1.8468284606933594
Validation loss: 2.1354742383444183

Epoch: 5| Step: 9
Training loss: 2.294771432876587
Validation loss: 2.0706983509884087

Epoch: 5| Step: 10
Training loss: 2.575031042098999
Validation loss: 2.0103783017845562

Epoch: 177| Step: 0
Training loss: 2.0353751182556152
Validation loss: 1.9929755298040246

Epoch: 5| Step: 1
Training loss: 2.126615524291992
Validation loss: 1.9664725078049528

Epoch: 5| Step: 2
Training loss: 2.538414478302002
Validation loss: 1.9656603874698761

Epoch: 5| Step: 3
Training loss: 2.537245512008667
Validation loss: 1.9740469981265325

Epoch: 5| Step: 4
Training loss: 0.9874329566955566
Validation loss: 1.9679452244953444

Epoch: 5| Step: 5
Training loss: 1.3324867486953735
Validation loss: 2.000188426304889

Epoch: 5| Step: 6
Training loss: 1.6236045360565186
Validation loss: 2.004232382261625

Epoch: 5| Step: 7
Training loss: 1.7501840591430664
Validation loss: 2.0011638620848298

Epoch: 5| Step: 8
Training loss: 1.893255591392517
Validation loss: 1.98824873534582

Epoch: 5| Step: 9
Training loss: 1.7044025659561157
Validation loss: 1.983319897805491

Epoch: 5| Step: 10
Training loss: 1.8892364501953125
Validation loss: 1.982155966502364

Epoch: 178| Step: 0
Training loss: 2.0079076290130615
Validation loss: 2.0029517553185903

Epoch: 5| Step: 1
Training loss: 1.4429547786712646
Validation loss: 1.9915028079863517

Epoch: 5| Step: 2
Training loss: 2.221571207046509
Validation loss: 1.9937351211424796

Epoch: 5| Step: 3
Training loss: 1.8571306467056274
Validation loss: 2.007573384110646

Epoch: 5| Step: 4
Training loss: 2.466799259185791
Validation loss: 2.04888855641888

Epoch: 5| Step: 5
Training loss: 1.713549017906189
Validation loss: 2.099862596040131

Epoch: 5| Step: 6
Training loss: 1.2201645374298096
Validation loss: 2.1286338401097122

Epoch: 5| Step: 7
Training loss: 2.414665460586548
Validation loss: 2.142420771301434

Epoch: 5| Step: 8
Training loss: 1.8866851329803467
Validation loss: 2.109202297784949

Epoch: 5| Step: 9
Training loss: 1.7190841436386108
Validation loss: 2.032569767326437

Epoch: 5| Step: 10
Training loss: 1.7639169692993164
Validation loss: 1.9951552703816404

Epoch: 179| Step: 0
Training loss: 1.6738369464874268
Validation loss: 1.9915120281198972

Epoch: 5| Step: 1
Training loss: 1.8184751272201538
Validation loss: 2.0192974177739953

Epoch: 5| Step: 2
Training loss: 1.7296485900878906
Validation loss: 1.9965238917258479

Epoch: 5| Step: 3
Training loss: 2.028136730194092
Validation loss: 1.9955079119692567

Epoch: 5| Step: 4
Training loss: 1.4402074813842773
Validation loss: 1.9675499290548346

Epoch: 5| Step: 5
Training loss: 1.8100175857543945
Validation loss: 1.9570558788955852

Epoch: 5| Step: 6
Training loss: 2.233994960784912
Validation loss: 1.9600157994095997

Epoch: 5| Step: 7
Training loss: 1.5074211359024048
Validation loss: 2.0083426762652654

Epoch: 5| Step: 8
Training loss: 1.7644535303115845
Validation loss: 2.0568617569502963

Epoch: 5| Step: 9
Training loss: 2.251164674758911
Validation loss: 2.1340510281183387

Epoch: 5| Step: 10
Training loss: 3.057091236114502
Validation loss: 2.1185742757653676

Epoch: 180| Step: 0
Training loss: 1.6661252975463867
Validation loss: 2.1138479350715556

Epoch: 5| Step: 1
Training loss: 1.8825385570526123
Validation loss: 2.0659195761526785

Epoch: 5| Step: 2
Training loss: 1.9444936513900757
Validation loss: 2.0394406831392677

Epoch: 5| Step: 3
Training loss: 1.680688500404358
Validation loss: 2.024460848941598

Epoch: 5| Step: 4
Training loss: 1.8623530864715576
Validation loss: 2.0218748687415995

Epoch: 5| Step: 5
Training loss: 1.8966972827911377
Validation loss: 2.0338443556139545

Epoch: 5| Step: 6
Training loss: 2.0632832050323486
Validation loss: 2.0478121272979246

Epoch: 5| Step: 7
Training loss: 1.3530641794204712
Validation loss: 2.028118379654423

Epoch: 5| Step: 8
Training loss: 1.8554823398590088
Validation loss: 2.0332882378690984

Epoch: 5| Step: 9
Training loss: 1.8884912729263306
Validation loss: 2.01946436589764

Epoch: 5| Step: 10
Training loss: 1.8745533227920532
Validation loss: 2.0168612118690246

Epoch: 181| Step: 0
Training loss: 2.014150619506836
Validation loss: 2.0270878550826863

Epoch: 5| Step: 1
Training loss: 1.9585860967636108
Validation loss: 2.043162703514099

Epoch: 5| Step: 2
Training loss: 2.1152679920196533
Validation loss: 2.086492714061532

Epoch: 5| Step: 3
Training loss: 1.4557950496673584
Validation loss: 2.100526673819429

Epoch: 5| Step: 4
Training loss: 1.7254928350448608
Validation loss: 2.0981525221178607

Epoch: 5| Step: 5
Training loss: 2.059648036956787
Validation loss: 2.099620408909295

Epoch: 5| Step: 6
Training loss: 1.716841459274292
Validation loss: 2.0438079064892185

Epoch: 5| Step: 7
Training loss: 1.477285385131836
Validation loss: 2.01562338747004

Epoch: 5| Step: 8
Training loss: 2.1642510890960693
Validation loss: 2.0084576619568693

Epoch: 5| Step: 9
Training loss: 1.7920678853988647
Validation loss: 2.0304401997596986

Epoch: 5| Step: 10
Training loss: 1.5035903453826904
Validation loss: 2.0690247038359284

Epoch: 182| Step: 0
Training loss: 0.9618738293647766
Validation loss: 2.082018349760322

Epoch: 5| Step: 1
Training loss: 2.5519700050354004
Validation loss: 2.0814518697800173

Epoch: 5| Step: 2
Training loss: 2.0565905570983887
Validation loss: 2.083885408216907

Epoch: 5| Step: 3
Training loss: 1.6164109706878662
Validation loss: 2.0761965320956324

Epoch: 5| Step: 4
Training loss: 1.6602933406829834
Validation loss: 2.054173024751807

Epoch: 5| Step: 5
Training loss: 1.6303632259368896
Validation loss: 2.0162391585688435

Epoch: 5| Step: 6
Training loss: 2.2689671516418457
Validation loss: 2.008868376413981

Epoch: 5| Step: 7
Training loss: 1.7576684951782227
Validation loss: 1.9981919950054539

Epoch: 5| Step: 8
Training loss: 2.0151753425598145
Validation loss: 1.987751801808675

Epoch: 5| Step: 9
Training loss: 1.8861758708953857
Validation loss: 1.977408246327472

Epoch: 5| Step: 10
Training loss: 1.3665659427642822
Validation loss: 1.9786736324269285

Epoch: 183| Step: 0
Training loss: 1.7977392673492432
Validation loss: 1.9697556149575017

Epoch: 5| Step: 1
Training loss: 2.2281579971313477
Validation loss: 1.9468881442982664

Epoch: 5| Step: 2
Training loss: 2.2436821460723877
Validation loss: 1.9454466809508622

Epoch: 5| Step: 3
Training loss: 1.3403044939041138
Validation loss: 1.968554490356035

Epoch: 5| Step: 4
Training loss: 1.750044584274292
Validation loss: 1.9787870530159242

Epoch: 5| Step: 5
Training loss: 1.8580983877182007
Validation loss: 1.9890344040368193

Epoch: 5| Step: 6
Training loss: 0.9831687808036804
Validation loss: 1.9985104414724535

Epoch: 5| Step: 7
Training loss: 2.196485996246338
Validation loss: 2.0366595688686577

Epoch: 5| Step: 8
Training loss: 1.8262453079223633
Validation loss: 2.090995750119609

Epoch: 5| Step: 9
Training loss: 1.5391371250152588
Validation loss: 2.1391845800543345

Epoch: 5| Step: 10
Training loss: 1.8159414529800415
Validation loss: 2.144616296214442

Epoch: 184| Step: 0
Training loss: 1.997606635093689
Validation loss: 2.146138903915241

Epoch: 5| Step: 1
Training loss: 2.2289531230926514
Validation loss: 2.075601616213399

Epoch: 5| Step: 2
Training loss: 2.2610697746276855
Validation loss: 2.01792230913716

Epoch: 5| Step: 3
Training loss: 1.8451178073883057
Validation loss: 2.0093307033661874

Epoch: 5| Step: 4
Training loss: 1.3775771856307983
Validation loss: 2.0269796361205397

Epoch: 5| Step: 5
Training loss: 1.5539520978927612
Validation loss: 1.9835813622320853

Epoch: 5| Step: 6
Training loss: 1.7446422576904297
Validation loss: 1.9854080702668877

Epoch: 5| Step: 7
Training loss: 1.994389295578003
Validation loss: 1.9993758893782092

Epoch: 5| Step: 8
Training loss: 1.8015286922454834
Validation loss: 2.0637999542297853

Epoch: 5| Step: 9
Training loss: 1.6800880432128906
Validation loss: 2.1102624195878223

Epoch: 5| Step: 10
Training loss: 1.383660912513733
Validation loss: 2.101611206608434

Epoch: 185| Step: 0
Training loss: 1.9122194051742554
Validation loss: 2.1171369629521526

Epoch: 5| Step: 1
Training loss: 1.699476957321167
Validation loss: 2.0736834951626357

Epoch: 5| Step: 2
Training loss: 1.4877402782440186
Validation loss: 2.0384007115517893

Epoch: 5| Step: 3
Training loss: 1.7129228115081787
Validation loss: 2.0428525017153834

Epoch: 5| Step: 4
Training loss: 1.4707987308502197
Validation loss: 2.0320021926715808

Epoch: 5| Step: 5
Training loss: 1.7701126337051392
Validation loss: 2.005574405834239

Epoch: 5| Step: 6
Training loss: 1.477002501487732
Validation loss: 1.9989681423351329

Epoch: 5| Step: 7
Training loss: 1.9156516790390015
Validation loss: 2.0097034272327217

Epoch: 5| Step: 8
Training loss: 1.6054751873016357
Validation loss: 1.9924410671316168

Epoch: 5| Step: 9
Training loss: 2.243912696838379
Validation loss: 2.0103525743689588

Epoch: 5| Step: 10
Training loss: 1.883819818496704
Validation loss: 2.0299755604036394

Epoch: 186| Step: 0
Training loss: 2.172433376312256
Validation loss: 2.0149591968905542

Epoch: 5| Step: 1
Training loss: 1.763723373413086
Validation loss: 2.0009116177917807

Epoch: 5| Step: 2
Training loss: 1.3210638761520386
Validation loss: 1.9918551239916074

Epoch: 5| Step: 3
Training loss: 1.661892294883728
Validation loss: 1.9846070351139191

Epoch: 5| Step: 4
Training loss: 1.466167688369751
Validation loss: 1.9931863930917555

Epoch: 5| Step: 5
Training loss: 1.4803550243377686
Validation loss: 2.0141727975619736

Epoch: 5| Step: 6
Training loss: 1.5811896324157715
Validation loss: 2.0333026275839856

Epoch: 5| Step: 7
Training loss: 1.7030754089355469
Validation loss: 2.029195321503506

Epoch: 5| Step: 8
Training loss: 1.8928139209747314
Validation loss: 2.0136133470842914

Epoch: 5| Step: 9
Training loss: 2.0366733074188232
Validation loss: 2.0321608179359028

Epoch: 5| Step: 10
Training loss: 1.8035922050476074
Validation loss: 2.036337347440822

Epoch: 187| Step: 0
Training loss: 0.972370982170105
Validation loss: 2.0872220685405116

Epoch: 5| Step: 1
Training loss: 2.1272974014282227
Validation loss: 2.1471213140795307

Epoch: 5| Step: 2
Training loss: 1.8197342157363892
Validation loss: 2.1834871486950944

Epoch: 5| Step: 3
Training loss: 1.4974894523620605
Validation loss: 2.1357901096343994

Epoch: 5| Step: 4
Training loss: 1.5553538799285889
Validation loss: 2.085734783962209

Epoch: 5| Step: 5
Training loss: 2.156327486038208
Validation loss: 2.0676233922281573

Epoch: 5| Step: 6
Training loss: 1.6732466220855713
Validation loss: 2.0633642763219853

Epoch: 5| Step: 7
Training loss: 1.920424461364746
Validation loss: 2.0497801585863997

Epoch: 5| Step: 8
Training loss: 1.9265100955963135
Validation loss: 2.042264547399295

Epoch: 5| Step: 9
Training loss: 1.658827781677246
Validation loss: 2.028894491093133

Epoch: 5| Step: 10
Training loss: 1.957490086555481
Validation loss: 2.0347352617530414

Epoch: 188| Step: 0
Training loss: 1.6231813430786133
Validation loss: 2.053473867395873

Epoch: 5| Step: 1
Training loss: 1.9454396963119507
Validation loss: 2.072710928096566

Epoch: 5| Step: 2
Training loss: 1.2465364933013916
Validation loss: 2.152814478002569

Epoch: 5| Step: 3
Training loss: 1.3118655681610107
Validation loss: 2.2109806665810208

Epoch: 5| Step: 4
Training loss: 1.8566398620605469
Validation loss: 2.2219627108625186

Epoch: 5| Step: 5
Training loss: 1.7578279972076416
Validation loss: 2.158381813315935

Epoch: 5| Step: 6
Training loss: 1.9261829853057861
Validation loss: 2.0763010235242945

Epoch: 5| Step: 7
Training loss: 1.4699747562408447
Validation loss: 1.9979653243095643

Epoch: 5| Step: 8
Training loss: 1.7776520252227783
Validation loss: 1.975193355673103

Epoch: 5| Step: 9
Training loss: 1.5742461681365967
Validation loss: 1.9693615436553955

Epoch: 5| Step: 10
Training loss: 2.63328218460083
Validation loss: 1.9847216913777013

Epoch: 189| Step: 0
Training loss: 2.044368028640747
Validation loss: 1.98581487260839

Epoch: 5| Step: 1
Training loss: 1.9209821224212646
Validation loss: 1.9572557941559823

Epoch: 5| Step: 2
Training loss: 2.4719626903533936
Validation loss: 1.9111612394291868

Epoch: 5| Step: 3
Training loss: 2.1379528045654297
Validation loss: 1.8940569021368538

Epoch: 5| Step: 4
Training loss: 1.3549915552139282
Validation loss: 1.9159303762579476

Epoch: 5| Step: 5
Training loss: 1.8102951049804688
Validation loss: 1.9385495314034082

Epoch: 5| Step: 6
Training loss: 1.6384468078613281
Validation loss: 1.955987576515444

Epoch: 5| Step: 7
Training loss: 2.0374865531921387
Validation loss: 2.0207311030357116

Epoch: 5| Step: 8
Training loss: 1.1576511859893799
Validation loss: 2.047658416532701

Epoch: 5| Step: 9
Training loss: 1.9951941967010498
Validation loss: 2.0530826814713015

Epoch: 5| Step: 10
Training loss: 1.2402780055999756
Validation loss: 2.108350847357063

Epoch: 190| Step: 0
Training loss: 1.815911889076233
Validation loss: 2.109104093684945

Epoch: 5| Step: 1
Training loss: 1.9621708393096924
Validation loss: 2.071044789847507

Epoch: 5| Step: 2
Training loss: 1.6138322353363037
Validation loss: 2.0609245428475003

Epoch: 5| Step: 3
Training loss: 1.4355738162994385
Validation loss: 2.0619418390335573

Epoch: 5| Step: 4
Training loss: 1.2250897884368896
Validation loss: 2.0619242370769544

Epoch: 5| Step: 5
Training loss: 1.6934974193572998
Validation loss: 2.107374862958026

Epoch: 5| Step: 6
Training loss: 1.714603066444397
Validation loss: 2.092659419582736

Epoch: 5| Step: 7
Training loss: 1.726470708847046
Validation loss: 2.083296198998728

Epoch: 5| Step: 8
Training loss: 1.6584694385528564
Validation loss: 2.0615212122599282

Epoch: 5| Step: 9
Training loss: 2.001709461212158
Validation loss: 2.0282761742991786

Epoch: 5| Step: 10
Training loss: 1.8552488088607788
Validation loss: 1.9952049409189532

Epoch: 191| Step: 0
Training loss: 1.552600622177124
Validation loss: 1.9993871770879275

Epoch: 5| Step: 1
Training loss: 1.3807992935180664
Validation loss: 1.97803512952661

Epoch: 5| Step: 2
Training loss: 1.3522460460662842
Validation loss: 1.9915687012416061

Epoch: 5| Step: 3
Training loss: 1.935837984085083
Validation loss: 2.0176579644603114

Epoch: 5| Step: 4
Training loss: 2.102388381958008
Validation loss: 2.0355380094179543

Epoch: 5| Step: 5
Training loss: 1.3898807764053345
Validation loss: 2.068279266357422

Epoch: 5| Step: 6
Training loss: 2.048943042755127
Validation loss: 2.094734004748765

Epoch: 5| Step: 7
Training loss: 1.0037662982940674
Validation loss: 2.092785954475403

Epoch: 5| Step: 8
Training loss: 1.9537723064422607
Validation loss: 2.099434147598923

Epoch: 5| Step: 9
Training loss: 1.9171812534332275
Validation loss: 2.075206418191233

Epoch: 5| Step: 10
Training loss: 1.7512446641921997
Validation loss: 2.047232849623567

Epoch: 192| Step: 0
Training loss: 1.177207350730896
Validation loss: 2.015088330033005

Epoch: 5| Step: 1
Training loss: 1.201882004737854
Validation loss: 2.0208757462040072

Epoch: 5| Step: 2
Training loss: 1.5182244777679443
Validation loss: 1.9908634065299906

Epoch: 5| Step: 3
Training loss: 1.928850531578064
Validation loss: 1.9790608575267177

Epoch: 5| Step: 4
Training loss: 1.3644691705703735
Validation loss: 1.953380980799275

Epoch: 5| Step: 5
Training loss: 2.0496232509613037
Validation loss: 1.969228389442608

Epoch: 5| Step: 6
Training loss: 1.2416012287139893
Validation loss: 1.9970189525235085

Epoch: 5| Step: 7
Training loss: 2.083253860473633
Validation loss: 2.032334248224894

Epoch: 5| Step: 8
Training loss: 1.7989734411239624
Validation loss: 2.046790935659921

Epoch: 5| Step: 9
Training loss: 1.8860461711883545
Validation loss: 2.0669885463612054

Epoch: 5| Step: 10
Training loss: 2.016178846359253
Validation loss: 2.0684427689480525

Epoch: 193| Step: 0
Training loss: 1.3159288167953491
Validation loss: 2.099043374420494

Epoch: 5| Step: 1
Training loss: 1.2376960515975952
Validation loss: 2.0771356680059947

Epoch: 5| Step: 2
Training loss: 1.8162800073623657
Validation loss: 2.0838201712536555

Epoch: 5| Step: 3
Training loss: 1.5978002548217773
Validation loss: 2.072439325753079

Epoch: 5| Step: 4
Training loss: 2.092883348464966
Validation loss: 2.0517124232425483

Epoch: 5| Step: 5
Training loss: 1.7959315776824951
Validation loss: 2.0280240005062473

Epoch: 5| Step: 6
Training loss: 2.2320990562438965
Validation loss: 2.042805549918964

Epoch: 5| Step: 7
Training loss: 1.6201441287994385
Validation loss: 2.0340971664715837

Epoch: 5| Step: 8
Training loss: 1.7134292125701904
Validation loss: 2.031439014660415

Epoch: 5| Step: 9
Training loss: 1.5591994524002075
Validation loss: 2.038627505302429

Epoch: 5| Step: 10
Training loss: 1.3199657201766968
Validation loss: 2.0524979099150626

Epoch: 194| Step: 0
Training loss: 2.321648120880127
Validation loss: 2.0810284806836035

Epoch: 5| Step: 1
Training loss: 1.2626070976257324
Validation loss: 2.121085061821886

Epoch: 5| Step: 2
Training loss: 1.6797130107879639
Validation loss: 2.1345592852561706

Epoch: 5| Step: 3
Training loss: 1.4085687398910522
Validation loss: 2.101301887983917

Epoch: 5| Step: 4
Training loss: 1.8006112575531006
Validation loss: 2.070747454961141

Epoch: 5| Step: 5
Training loss: 1.4366278648376465
Validation loss: 2.042165938244071

Epoch: 5| Step: 6
Training loss: 1.8481948375701904
Validation loss: 2.042365725322436

Epoch: 5| Step: 7
Training loss: 1.7147128582000732
Validation loss: 2.0434493736554216

Epoch: 5| Step: 8
Training loss: 1.5968663692474365
Validation loss: 2.0388565935114378

Epoch: 5| Step: 9
Training loss: 1.4128748178482056
Validation loss: 2.008190926685128

Epoch: 5| Step: 10
Training loss: 1.881937026977539
Validation loss: 2.0318842626387075

Epoch: 195| Step: 0
Training loss: 1.492653727531433
Validation loss: 2.0681574293362197

Epoch: 5| Step: 1
Training loss: 1.967775583267212
Validation loss: 2.1083116710826917

Epoch: 5| Step: 2
Training loss: 1.1872440576553345
Validation loss: 2.0896744830634004

Epoch: 5| Step: 3
Training loss: 1.9943605661392212
Validation loss: 2.0600243588929534

Epoch: 5| Step: 4
Training loss: 1.8353561162948608
Validation loss: 2.015700130052464

Epoch: 5| Step: 5
Training loss: 1.7321052551269531
Validation loss: 1.9692569368629045

Epoch: 5| Step: 6
Training loss: 1.3928569555282593
Validation loss: 1.9536477391437819

Epoch: 5| Step: 7
Training loss: 1.6350469589233398
Validation loss: 1.9466534455617268

Epoch: 5| Step: 8
Training loss: 2.0586798191070557
Validation loss: 2.000794150496042

Epoch: 5| Step: 9
Training loss: 1.8266136646270752
Validation loss: 2.019214883927376

Epoch: 5| Step: 10
Training loss: 1.4054127931594849
Validation loss: 2.0574032004161547

Epoch: 196| Step: 0
Training loss: 1.7136799097061157
Validation loss: 2.0664754836790022

Epoch: 5| Step: 1
Training loss: 1.3279831409454346
Validation loss: 2.0661488809893207

Epoch: 5| Step: 2
Training loss: 1.1915442943572998
Validation loss: 2.063078790582636

Epoch: 5| Step: 3
Training loss: 1.478140115737915
Validation loss: 2.0575434956499326

Epoch: 5| Step: 4
Training loss: 1.7310136556625366
Validation loss: 2.0567122890103247

Epoch: 5| Step: 5
Training loss: 2.174123764038086
Validation loss: 2.0556762295384563

Epoch: 5| Step: 6
Training loss: 1.046870470046997
Validation loss: 2.0497447380455593

Epoch: 5| Step: 7
Training loss: 2.0903871059417725
Validation loss: 2.033228381987541

Epoch: 5| Step: 8
Training loss: 1.6863515377044678
Validation loss: 2.0358702572443153

Epoch: 5| Step: 9
Training loss: 1.512442946434021
Validation loss: 2.0645080638188187

Epoch: 5| Step: 10
Training loss: 1.951371192932129
Validation loss: 2.0478175775979155

Epoch: 197| Step: 0
Training loss: 1.3821582794189453
Validation loss: 2.035673322216157

Epoch: 5| Step: 1
Training loss: 1.673797607421875
Validation loss: 2.0268555853956487

Epoch: 5| Step: 2
Training loss: 1.7061786651611328
Validation loss: 2.0458840054850422

Epoch: 5| Step: 3
Training loss: 1.131101369857788
Validation loss: 2.0407466529518046

Epoch: 5| Step: 4
Training loss: 1.804795265197754
Validation loss: 2.030006106181811

Epoch: 5| Step: 5
Training loss: 1.8930227756500244
Validation loss: 2.05959907526611

Epoch: 5| Step: 6
Training loss: 1.492502212524414
Validation loss: 2.0676096844416794

Epoch: 5| Step: 7
Training loss: 1.708791732788086
Validation loss: 2.068394234103541

Epoch: 5| Step: 8
Training loss: 1.4350135326385498
Validation loss: 2.1064331480251846

Epoch: 5| Step: 9
Training loss: 1.8215153217315674
Validation loss: 2.1100071848079724

Epoch: 5| Step: 10
Training loss: 2.052917242050171
Validation loss: 2.104146816397226

Epoch: 198| Step: 0
Training loss: 1.257512092590332
Validation loss: 2.0772539492576354

Epoch: 5| Step: 1
Training loss: 1.0916193723678589
Validation loss: 2.027716049584009

Epoch: 5| Step: 2
Training loss: 2.0404515266418457
Validation loss: 1.9787221877805647

Epoch: 5| Step: 3
Training loss: 1.734480619430542
Validation loss: 1.9411551503724949

Epoch: 5| Step: 4
Training loss: 1.392264485359192
Validation loss: 1.933263640249929

Epoch: 5| Step: 5
Training loss: 1.599578619003296
Validation loss: 1.939952940069219

Epoch: 5| Step: 6
Training loss: 1.9287961721420288
Validation loss: 1.9526823412987493

Epoch: 5| Step: 7
Training loss: 1.775470495223999
Validation loss: 1.9697162079554733

Epoch: 5| Step: 8
Training loss: 1.6843087673187256
Validation loss: 1.9761904542164137

Epoch: 5| Step: 9
Training loss: 1.38643217086792
Validation loss: 2.0031578835620674

Epoch: 5| Step: 10
Training loss: 1.921857237815857
Validation loss: 2.021403325501309

Epoch: 199| Step: 0
Training loss: 1.7031631469726562
Validation loss: 2.02362657618779

Epoch: 5| Step: 1
Training loss: 1.0273215770721436
Validation loss: 2.015265255846003

Epoch: 5| Step: 2
Training loss: 1.5976322889328003
Validation loss: 2.050354896053191

Epoch: 5| Step: 3
Training loss: 1.5878757238388062
Validation loss: 2.0536267718961163

Epoch: 5| Step: 4
Training loss: 1.591408610343933
Validation loss: 2.0439828249715988

Epoch: 5| Step: 5
Training loss: 1.1941049098968506
Validation loss: 2.058056151995095

Epoch: 5| Step: 6
Training loss: 2.0909035205841064
Validation loss: 2.0735018407144854

Epoch: 5| Step: 7
Training loss: 1.565063714981079
Validation loss: 2.084170884983514

Epoch: 5| Step: 8
Training loss: 2.1855034828186035
Validation loss: 2.092385347171496

Epoch: 5| Step: 9
Training loss: 1.724540114402771
Validation loss: 2.1066144051090365

Epoch: 5| Step: 10
Training loss: 1.265230417251587
Validation loss: 2.098851683319256

Epoch: 200| Step: 0
Training loss: 1.4414379596710205
Validation loss: 2.0534044773347917

Epoch: 5| Step: 1
Training loss: 1.171802282333374
Validation loss: 2.0349338118748

Epoch: 5| Step: 2
Training loss: 1.3959157466888428
Validation loss: 2.0103435157447733

Epoch: 5| Step: 3
Training loss: 1.6392505168914795
Validation loss: 2.022691713866367

Epoch: 5| Step: 4
Training loss: 1.4395942687988281
Validation loss: 2.027644052300402

Epoch: 5| Step: 5
Training loss: 1.5107784271240234
Validation loss: 2.0598954231508317

Epoch: 5| Step: 6
Training loss: 1.8042761087417603
Validation loss: 2.0794733980650544

Epoch: 5| Step: 7
Training loss: 2.429590940475464
Validation loss: 2.1288074460080875

Epoch: 5| Step: 8
Training loss: 1.8135716915130615
Validation loss: 2.159633198092061

Epoch: 5| Step: 9
Training loss: 1.3908848762512207
Validation loss: 2.1164021492004395

Epoch: 5| Step: 10
Training loss: 1.6090283393859863
Validation loss: 2.044997745944608

Epoch: 201| Step: 0
Training loss: 1.61306631565094
Validation loss: 2.003127610811623

Epoch: 5| Step: 1
Training loss: 2.2798683643341064
Validation loss: 2.000618073248094

Epoch: 5| Step: 2
Training loss: 1.3826440572738647
Validation loss: 1.9982084151237243

Epoch: 5| Step: 3
Training loss: 1.77373468875885
Validation loss: 1.9796621389286493

Epoch: 5| Step: 4
Training loss: 1.3358867168426514
Validation loss: 1.9593827596274755

Epoch: 5| Step: 5
Training loss: 1.9893243312835693
Validation loss: 1.9642418763970817

Epoch: 5| Step: 6
Training loss: 1.4746472835540771
Validation loss: 1.9860911266778105

Epoch: 5| Step: 7
Training loss: 1.3257272243499756
Validation loss: 2.083158117468639

Epoch: 5| Step: 8
Training loss: 1.7067501544952393
Validation loss: 2.1422747924763668

Epoch: 5| Step: 9
Training loss: 1.5957748889923096
Validation loss: 2.1177146473238544

Epoch: 5| Step: 10
Training loss: 1.7282158136367798
Validation loss: 2.1380247480125836

Epoch: 202| Step: 0
Training loss: 1.5343282222747803
Validation loss: 2.1154568426070677

Epoch: 5| Step: 1
Training loss: 2.184950351715088
Validation loss: 2.1212684518547467

Epoch: 5| Step: 2
Training loss: 1.3543779850006104
Validation loss: 2.114627681752687

Epoch: 5| Step: 3
Training loss: 1.4905593395233154
Validation loss: 2.111926587679053

Epoch: 5| Step: 4
Training loss: 1.5310823917388916
Validation loss: 2.112809088922316

Epoch: 5| Step: 5
Training loss: 2.2781083583831787
Validation loss: 2.0796217303122244

Epoch: 5| Step: 6
Training loss: 1.6417217254638672
Validation loss: 2.0628518596772225

Epoch: 5| Step: 7
Training loss: 1.6078956127166748
Validation loss: 2.0620086705812843

Epoch: 5| Step: 8
Training loss: 1.6919310092926025
Validation loss: 2.0608993858419438

Epoch: 5| Step: 9
Training loss: 1.332732915878296
Validation loss: 2.0869197896731797

Epoch: 5| Step: 10
Training loss: 0.5882482528686523
Validation loss: 2.094103361970635

Epoch: 203| Step: 0
Training loss: 1.4006872177124023
Validation loss: 2.0734751634700324

Epoch: 5| Step: 1
Training loss: 1.5755780935287476
Validation loss: 2.0910184742302023

Epoch: 5| Step: 2
Training loss: 1.1959450244903564
Validation loss: 2.0721667979353215

Epoch: 5| Step: 3
Training loss: 1.6085014343261719
Validation loss: 2.038484452873148

Epoch: 5| Step: 4
Training loss: 1.5186994075775146
Validation loss: 1.998443821425079

Epoch: 5| Step: 5
Training loss: 1.752621054649353
Validation loss: 1.981783531045401

Epoch: 5| Step: 6
Training loss: 1.7245687246322632
Validation loss: 1.987929210867933

Epoch: 5| Step: 7
Training loss: 1.7002719640731812
Validation loss: 2.0097301877954954

Epoch: 5| Step: 8
Training loss: 1.85964035987854
Validation loss: 2.0128962557802916

Epoch: 5| Step: 9
Training loss: 1.4738870859146118
Validation loss: 1.9953312771294707

Epoch: 5| Step: 10
Training loss: 1.5437657833099365
Validation loss: 2.000023465002737

Epoch: 204| Step: 0
Training loss: 1.065868616104126
Validation loss: 2.029925359192715

Epoch: 5| Step: 1
Training loss: 1.4921718835830688
Validation loss: 2.067023051682339

Epoch: 5| Step: 2
Training loss: 1.6352431774139404
Validation loss: 2.0704505751209874

Epoch: 5| Step: 3
Training loss: 1.9839893579483032
Validation loss: 2.1205253780529065

Epoch: 5| Step: 4
Training loss: 1.8724136352539062
Validation loss: 2.1098476276602796

Epoch: 5| Step: 5
Training loss: 1.6974437236785889
Validation loss: 2.0817141186806465

Epoch: 5| Step: 6
Training loss: 1.556667685508728
Validation loss: 2.0182024150766353

Epoch: 5| Step: 7
Training loss: 1.7246259450912476
Validation loss: 2.0144563746708695

Epoch: 5| Step: 8
Training loss: 1.3136322498321533
Validation loss: 2.010539754744499

Epoch: 5| Step: 9
Training loss: 1.2998602390289307
Validation loss: 2.011624061933128

Epoch: 5| Step: 10
Training loss: 1.2663581371307373
Validation loss: 2.011441138482863

Epoch: 205| Step: 0
Training loss: 1.4575531482696533
Validation loss: 2.011963079052587

Epoch: 5| Step: 1
Training loss: 1.877374291419983
Validation loss: 2.006697581660363

Epoch: 5| Step: 2
Training loss: 1.5504976511001587
Validation loss: 2.004041342325108

Epoch: 5| Step: 3
Training loss: 1.4315946102142334
Validation loss: 2.0108382535237137

Epoch: 5| Step: 4
Training loss: 1.7148011922836304
Validation loss: 2.0382583423327376

Epoch: 5| Step: 5
Training loss: 1.3967353105545044
Validation loss: 2.0731269979989655

Epoch: 5| Step: 6
Training loss: 1.3908798694610596
Validation loss: 2.0544560122233566

Epoch: 5| Step: 7
Training loss: 1.5667916536331177
Validation loss: 2.020426704037574

Epoch: 5| Step: 8
Training loss: 1.8028299808502197
Validation loss: 2.0167709268549436

Epoch: 5| Step: 9
Training loss: 1.1024878025054932
Validation loss: 2.019688347334503

Epoch: 5| Step: 10
Training loss: 1.3619786500930786
Validation loss: 2.0375640417939875

Epoch: 206| Step: 0
Training loss: 1.4512155055999756
Validation loss: 2.0394998506833146

Epoch: 5| Step: 1
Training loss: 1.1080071926116943
Validation loss: 2.030791118580808

Epoch: 5| Step: 2
Training loss: 1.695252776145935
Validation loss: 2.0346155230716994

Epoch: 5| Step: 3
Training loss: 1.2450001239776611
Validation loss: 2.007191672120043

Epoch: 5| Step: 4
Training loss: 1.9003515243530273
Validation loss: 2.004831922951565

Epoch: 5| Step: 5
Training loss: 1.3994486331939697
Validation loss: 2.0063588837141633

Epoch: 5| Step: 6
Training loss: 1.6225454807281494
Validation loss: 2.000625261696436

Epoch: 5| Step: 7
Training loss: 1.4925683736801147
Validation loss: 1.9934525143715642

Epoch: 5| Step: 8
Training loss: 1.771056890487671
Validation loss: 2.0036979272801387

Epoch: 5| Step: 9
Training loss: 1.492741584777832
Validation loss: 2.035333034812763

Epoch: 5| Step: 10
Training loss: 1.4609150886535645
Validation loss: 2.0423971273565806

Epoch: 207| Step: 0
Training loss: 1.8734805583953857
Validation loss: 2.0401911120260916

Epoch: 5| Step: 1
Training loss: 1.0540322065353394
Validation loss: 2.0210548549570064

Epoch: 5| Step: 2
Training loss: 1.3236613273620605
Validation loss: 2.0019800739903606

Epoch: 5| Step: 3
Training loss: 1.1736223697662354
Validation loss: 2.0002473631212787

Epoch: 5| Step: 4
Training loss: 1.8844411373138428
Validation loss: 2.0118877144270044

Epoch: 5| Step: 5
Training loss: 1.512420654296875
Validation loss: 2.0214400829807406

Epoch: 5| Step: 6
Training loss: 1.6491340398788452
Validation loss: 2.0109965647420576

Epoch: 5| Step: 7
Training loss: 1.420485258102417
Validation loss: 2.0038658547145065

Epoch: 5| Step: 8
Training loss: 1.3320810794830322
Validation loss: 1.9870817225466493

Epoch: 5| Step: 9
Training loss: 1.682826280593872
Validation loss: 2.003967544083954

Epoch: 5| Step: 10
Training loss: 1.7714898586273193
Validation loss: 2.008218570422101

Epoch: 208| Step: 0
Training loss: 1.0045868158340454
Validation loss: 2.107065975025136

Epoch: 5| Step: 1
Training loss: 1.4968135356903076
Validation loss: 2.122301176030149

Epoch: 5| Step: 2
Training loss: 1.5300874710083008
Validation loss: 2.108714472862982

Epoch: 5| Step: 3
Training loss: 2.0958495140075684
Validation loss: 2.0410163607648624

Epoch: 5| Step: 4
Training loss: 2.064866781234741
Validation loss: 1.9844626867642967

Epoch: 5| Step: 5
Training loss: 1.6142261028289795
Validation loss: 1.9955784236231158

Epoch: 5| Step: 6
Training loss: 1.31880784034729
Validation loss: 1.999725595597298

Epoch: 5| Step: 7
Training loss: 1.7260440587997437
Validation loss: 2.0075730726283085

Epoch: 5| Step: 8
Training loss: 1.183074951171875
Validation loss: 2.0161151398894606

Epoch: 5| Step: 9
Training loss: 1.4606571197509766
Validation loss: 2.0180345478878228

Epoch: 5| Step: 10
Training loss: 1.3001586198806763
Validation loss: 2.0351193617748957

Epoch: 209| Step: 0
Training loss: 1.1598126888275146
Validation loss: 2.07521923383077

Epoch: 5| Step: 1
Training loss: 1.6173683404922485
Validation loss: 2.106567196948554

Epoch: 5| Step: 2
Training loss: 0.8672354817390442
Validation loss: 2.1035772036480647

Epoch: 5| Step: 3
Training loss: 1.6859210729599
Validation loss: 2.113632099602812

Epoch: 5| Step: 4
Training loss: 1.300586462020874
Validation loss: 2.11044829891574

Epoch: 5| Step: 5
Training loss: 1.9237926006317139
Validation loss: 2.0675374000303206

Epoch: 5| Step: 6
Training loss: 1.2958427667617798
Validation loss: 2.0750396790043

Epoch: 5| Step: 7
Training loss: 1.8168325424194336
Validation loss: 2.0524675602553994

Epoch: 5| Step: 8
Training loss: 0.8880876302719116
Validation loss: 2.0692280928293862

Epoch: 5| Step: 9
Training loss: 2.239375114440918
Validation loss: 2.058570574688655

Epoch: 5| Step: 10
Training loss: 1.4935377836227417
Validation loss: 2.0333951263017553

Epoch: 210| Step: 0
Training loss: 0.9538592100143433
Validation loss: 2.0218939909371

Epoch: 5| Step: 1
Training loss: 1.5192220211029053
Validation loss: 2.01619077626095

Epoch: 5| Step: 2
Training loss: 1.7851330041885376
Validation loss: 1.9891721830573132

Epoch: 5| Step: 3
Training loss: 1.290024995803833
Validation loss: 1.981442379695113

Epoch: 5| Step: 4
Training loss: 1.8114122152328491
Validation loss: 1.9900637121610745

Epoch: 5| Step: 5
Training loss: 1.4078441858291626
Validation loss: 1.9993262111499746

Epoch: 5| Step: 6
Training loss: 1.2397927045822144
Validation loss: 2.033475011907598

Epoch: 5| Step: 7
Training loss: 1.3987122774124146
Validation loss: 2.0858591935967885

Epoch: 5| Step: 8
Training loss: 1.7968428134918213
Validation loss: 2.126691923346571

Epoch: 5| Step: 9
Training loss: 1.5252797603607178
Validation loss: 2.161695381646515

Epoch: 5| Step: 10
Training loss: 1.4627705812454224
Validation loss: 2.140743819616174

Epoch: 211| Step: 0
Training loss: 1.3928353786468506
Validation loss: 2.0856974958091654

Epoch: 5| Step: 1
Training loss: 1.6520204544067383
Validation loss: 2.0575270165679274

Epoch: 5| Step: 2
Training loss: 1.2532861232757568
Validation loss: 2.030490290734076

Epoch: 5| Step: 3
Training loss: 2.3563952445983887
Validation loss: 2.0347453881335515

Epoch: 5| Step: 4
Training loss: 1.8833589553833008
Validation loss: 2.0031139901889268

Epoch: 5| Step: 5
Training loss: 0.9292694926261902
Validation loss: 1.997701293678694

Epoch: 5| Step: 6
Training loss: 1.0455201864242554
Validation loss: 2.0053636412466727

Epoch: 5| Step: 7
Training loss: 1.5106509923934937
Validation loss: 2.0520539809298772

Epoch: 5| Step: 8
Training loss: 1.7196153402328491
Validation loss: 2.110360430132958

Epoch: 5| Step: 9
Training loss: 1.7008841037750244
Validation loss: 2.0964633803213797

Epoch: 5| Step: 10
Training loss: 1.1985526084899902
Validation loss: 2.1068171942105858

Epoch: 212| Step: 0
Training loss: 1.1806082725524902
Validation loss: 2.0305831381069717

Epoch: 5| Step: 1
Training loss: 1.493927001953125
Validation loss: 2.0179502028290943

Epoch: 5| Step: 2
Training loss: 1.0948584079742432
Validation loss: 2.0100624497218798

Epoch: 5| Step: 3
Training loss: 1.1595522165298462
Validation loss: 2.042502221240792

Epoch: 5| Step: 4
Training loss: 1.4976692199707031
Validation loss: 2.078006813603063

Epoch: 5| Step: 5
Training loss: 2.1742706298828125
Validation loss: 2.084456938569264

Epoch: 5| Step: 6
Training loss: 1.3978570699691772
Validation loss: 2.0976286280539727

Epoch: 5| Step: 7
Training loss: 1.7094085216522217
Validation loss: 2.0795282907383417

Epoch: 5| Step: 8
Training loss: 0.8486171960830688
Validation loss: 2.0832631382890927

Epoch: 5| Step: 9
Training loss: 1.2870370149612427
Validation loss: 2.093092745350253

Epoch: 5| Step: 10
Training loss: 2.215751886367798
Validation loss: 2.0644904541712936

Epoch: 213| Step: 0
Training loss: 1.7117763757705688
Validation loss: 2.041722164359144

Epoch: 5| Step: 1
Training loss: 1.8596776723861694
Validation loss: 1.9905068335994598

Epoch: 5| Step: 2
Training loss: 1.0545217990875244
Validation loss: 1.959803383837464

Epoch: 5| Step: 3
Training loss: 1.4340026378631592
Validation loss: 1.9561616002872426

Epoch: 5| Step: 4
Training loss: 1.5686514377593994
Validation loss: 1.9445199171702068

Epoch: 5| Step: 5
Training loss: 1.511737585067749
Validation loss: 1.9538739804298646

Epoch: 5| Step: 6
Training loss: 1.1722323894500732
Validation loss: 1.961220669490035

Epoch: 5| Step: 7
Training loss: 0.8351283073425293
Validation loss: 1.995543349173761

Epoch: 5| Step: 8
Training loss: 1.7275011539459229
Validation loss: 2.0252161410547074

Epoch: 5| Step: 9
Training loss: 1.3119815587997437
Validation loss: 2.0676261814691688

Epoch: 5| Step: 10
Training loss: 1.644092321395874
Validation loss: 2.0559048370648454

Epoch: 214| Step: 0
Training loss: 0.9734088778495789
Validation loss: 2.069178976038451

Epoch: 5| Step: 1
Training loss: 1.2788113355636597
Validation loss: 2.078505805743638

Epoch: 5| Step: 2
Training loss: 1.1991394758224487
Validation loss: 2.0527133518649685

Epoch: 5| Step: 3
Training loss: 1.7927618026733398
Validation loss: 2.048445822090231

Epoch: 5| Step: 4
Training loss: 1.8895076513290405
Validation loss: 2.0463280344522126

Epoch: 5| Step: 5
Training loss: 1.324690818786621
Validation loss: 2.0189693807273783

Epoch: 5| Step: 6
Training loss: 1.377525806427002
Validation loss: 2.033007408982964

Epoch: 5| Step: 7
Training loss: 1.6573833227157593
Validation loss: 2.0527510489186933

Epoch: 5| Step: 8
Training loss: 1.3367632627487183
Validation loss: 2.0422704655637025

Epoch: 5| Step: 9
Training loss: 1.415417194366455
Validation loss: 2.020691292260283

Epoch: 5| Step: 10
Training loss: 1.4057209491729736
Validation loss: 2.011740061544603

Epoch: 215| Step: 0
Training loss: 1.4721121788024902
Validation loss: 2.004557858231247

Epoch: 5| Step: 1
Training loss: 1.4045289754867554
Validation loss: 1.989892493012131

Epoch: 5| Step: 2
Training loss: 1.2707159519195557
Validation loss: 2.0035884175249326

Epoch: 5| Step: 3
Training loss: 1.5739976167678833
Validation loss: 2.0180301217622656

Epoch: 5| Step: 4
Training loss: 1.2726490497589111
Validation loss: 2.0253384702949115

Epoch: 5| Step: 5
Training loss: 1.1387255191802979
Validation loss: 2.0387067153889644

Epoch: 5| Step: 6
Training loss: 1.2740156650543213
Validation loss: 2.0499226252237954

Epoch: 5| Step: 7
Training loss: 1.2427908182144165
Validation loss: 2.053228309077601

Epoch: 5| Step: 8
Training loss: 1.4936264753341675
Validation loss: 2.069994229142384

Epoch: 5| Step: 9
Training loss: 1.4379069805145264
Validation loss: 2.032829430795485

Epoch: 5| Step: 10
Training loss: 1.6789019107818604
Validation loss: 2.020925801287415

Epoch: 216| Step: 0
Training loss: 1.2045888900756836
Validation loss: 2.0493732575447328

Epoch: 5| Step: 1
Training loss: 0.8538342714309692
Validation loss: 2.0541481420557988

Epoch: 5| Step: 2
Training loss: 1.8992679119110107
Validation loss: 2.076120145859257

Epoch: 5| Step: 3
Training loss: 1.5315324068069458
Validation loss: 2.0591323862793627

Epoch: 5| Step: 4
Training loss: 0.8986390233039856
Validation loss: 2.0732154846191406

Epoch: 5| Step: 5
Training loss: 1.429007649421692
Validation loss: 2.0253706414212465

Epoch: 5| Step: 6
Training loss: 1.366581678390503
Validation loss: 2.0175118548895723

Epoch: 5| Step: 7
Training loss: 1.373374342918396
Validation loss: 2.0088212797718663

Epoch: 5| Step: 8
Training loss: 1.6296879053115845
Validation loss: 2.007549996017128

Epoch: 5| Step: 9
Training loss: 1.5590883493423462
Validation loss: 2.0155597040730138

Epoch: 5| Step: 10
Training loss: 1.4820560216903687
Validation loss: 2.0205307006835938

Epoch: 217| Step: 0
Training loss: 0.8507445454597473
Validation loss: 2.0509997362731607

Epoch: 5| Step: 1
Training loss: 0.5923274159431458
Validation loss: 2.0620644374560286

Epoch: 5| Step: 2
Training loss: 1.3289636373519897
Validation loss: 2.028219654995908

Epoch: 5| Step: 3
Training loss: 1.418059229850769
Validation loss: 2.0505919071935836

Epoch: 5| Step: 4
Training loss: 1.2229068279266357
Validation loss: 2.0218317841970794

Epoch: 5| Step: 5
Training loss: 1.8856565952301025
Validation loss: 2.030112817723264

Epoch: 5| Step: 6
Training loss: 1.4193570613861084
Validation loss: 2.0494950432931223

Epoch: 5| Step: 7
Training loss: 2.0298774242401123
Validation loss: 2.054874979039674

Epoch: 5| Step: 8
Training loss: 1.6131458282470703
Validation loss: 2.045687872876403

Epoch: 5| Step: 9
Training loss: 1.658876657485962
Validation loss: 2.0541178411053074

Epoch: 5| Step: 10
Training loss: 1.3618597984313965
Validation loss: 2.088403809455133

Epoch: 218| Step: 0
Training loss: 1.4519586563110352
Validation loss: 2.1057203867102183

Epoch: 5| Step: 1
Training loss: 1.3463293313980103
Validation loss: 2.116001375259892

Epoch: 5| Step: 2
Training loss: 1.7466579675674438
Validation loss: 2.0918666829345045

Epoch: 5| Step: 3
Training loss: 0.9732049703598022
Validation loss: 2.0533848962476178

Epoch: 5| Step: 4
Training loss: 1.560626745223999
Validation loss: 2.0392582467807236

Epoch: 5| Step: 5
Training loss: 1.4148722887039185
Validation loss: 1.9951473410411547

Epoch: 5| Step: 6
Training loss: 1.8541429042816162
Validation loss: 1.990164509383581

Epoch: 5| Step: 7
Training loss: 1.357237458229065
Validation loss: 1.989956900637637

Epoch: 5| Step: 8
Training loss: 1.0067764520645142
Validation loss: 1.9874559833157448

Epoch: 5| Step: 9
Training loss: 1.3859858512878418
Validation loss: 1.9802585109587638

Epoch: 5| Step: 10
Training loss: 1.1150612831115723
Validation loss: 2.0059439828318935

Epoch: 219| Step: 0
Training loss: 1.3038370609283447
Validation loss: 2.0306566428112727

Epoch: 5| Step: 1
Training loss: 1.327453851699829
Validation loss: 2.015848552027056

Epoch: 5| Step: 2
Training loss: 1.5168877840042114
Validation loss: 2.008246123149831

Epoch: 5| Step: 3
Training loss: 1.358285903930664
Validation loss: 2.006102333786667

Epoch: 5| Step: 4
Training loss: 1.7338790893554688
Validation loss: 2.0222593610004713

Epoch: 5| Step: 5
Training loss: 1.0512778759002686
Validation loss: 2.0209484818161174

Epoch: 5| Step: 6
Training loss: 1.3288227319717407
Validation loss: 2.01612199506452

Epoch: 5| Step: 7
Training loss: 1.4079567193984985
Validation loss: 2.0531108225545576

Epoch: 5| Step: 8
Training loss: 1.1694132089614868
Validation loss: 2.0837495044995378

Epoch: 5| Step: 9
Training loss: 1.6220033168792725
Validation loss: 2.0644788844611055

Epoch: 5| Step: 10
Training loss: 1.12741219997406
Validation loss: 2.0434367733616985

Epoch: 220| Step: 0
Training loss: 1.2499616146087646
Validation loss: 2.0199790795644126

Epoch: 5| Step: 1
Training loss: 1.1482772827148438
Validation loss: 2.0367614043656217

Epoch: 5| Step: 2
Training loss: 1.1485998630523682
Validation loss: 2.0523150403012513

Epoch: 5| Step: 3
Training loss: 1.5794364213943481
Validation loss: 2.0542847584652644

Epoch: 5| Step: 4
Training loss: 1.7406399250030518
Validation loss: 2.0649885951831775

Epoch: 5| Step: 5
Training loss: 1.358156442642212
Validation loss: 2.0703332129345147

Epoch: 5| Step: 6
Training loss: 1.0571959018707275
Validation loss: 2.069272841176679

Epoch: 5| Step: 7
Training loss: 1.2618736028671265
Validation loss: 2.077878394434529

Epoch: 5| Step: 8
Training loss: 1.5668456554412842
Validation loss: 2.059201275148699

Epoch: 5| Step: 9
Training loss: 1.3687608242034912
Validation loss: 2.03909622469256

Epoch: 5| Step: 10
Training loss: 1.3791452646255493
Validation loss: 2.0239021906288723

Epoch: 221| Step: 0
Training loss: 1.5833008289337158
Validation loss: 2.0259903566811674

Epoch: 5| Step: 1
Training loss: 2.0203747749328613
Validation loss: 2.028879496359056

Epoch: 5| Step: 2
Training loss: 1.0349769592285156
Validation loss: 2.0422675225042526

Epoch: 5| Step: 3
Training loss: 1.5245507955551147
Validation loss: 2.046633191006158

Epoch: 5| Step: 4
Training loss: 0.9816152453422546
Validation loss: 2.0487738655459498

Epoch: 5| Step: 5
Training loss: 1.1575443744659424
Validation loss: 2.094898505877423

Epoch: 5| Step: 6
Training loss: 1.2373218536376953
Validation loss: 2.104110233245357

Epoch: 5| Step: 7
Training loss: 1.6705230474472046
Validation loss: 2.1128125690644786

Epoch: 5| Step: 8
Training loss: 0.9895762205123901
Validation loss: 2.102682286693204

Epoch: 5| Step: 9
Training loss: 1.3876582384109497
Validation loss: 2.016608895794038

Epoch: 5| Step: 10
Training loss: 1.2688672542572021
Validation loss: 1.9831172368859733

Epoch: 222| Step: 0
Training loss: 1.4534512758255005
Validation loss: 1.9546787725981845

Epoch: 5| Step: 1
Training loss: 1.132035255432129
Validation loss: 1.9393935254825059

Epoch: 5| Step: 2
Training loss: 1.0062299966812134
Validation loss: 1.9475619126391668

Epoch: 5| Step: 3
Training loss: 1.547603964805603
Validation loss: 1.9415633293890184

Epoch: 5| Step: 4
Training loss: 1.1901556253433228
Validation loss: 2.0011029845924786

Epoch: 5| Step: 5
Training loss: 1.0883086919784546
Validation loss: 2.0657209452762397

Epoch: 5| Step: 6
Training loss: 1.1623070240020752
Validation loss: 2.0943477153778076

Epoch: 5| Step: 7
Training loss: 1.2898696660995483
Validation loss: 2.136530537759104

Epoch: 5| Step: 8
Training loss: 1.602301001548767
Validation loss: 2.1486093895409697

Epoch: 5| Step: 9
Training loss: 1.8783862590789795
Validation loss: 2.115888782726821

Epoch: 5| Step: 10
Training loss: 1.5217875242233276
Validation loss: 2.113783021127024

Epoch: 223| Step: 0
Training loss: 1.4505468606948853
Validation loss: 2.02673993315748

Epoch: 5| Step: 1
Training loss: 1.6073884963989258
Validation loss: 2.0058153342175227

Epoch: 5| Step: 2
Training loss: 1.484266757965088
Validation loss: 1.9953048741945656

Epoch: 5| Step: 3
Training loss: 1.42401921749115
Validation loss: 1.9759840042360368

Epoch: 5| Step: 4
Training loss: 1.6947838068008423
Validation loss: 1.9774924837132937

Epoch: 5| Step: 5
Training loss: 1.4660362005233765
Validation loss: 1.9791856478619319

Epoch: 5| Step: 6
Training loss: 1.3407338857650757
Validation loss: 1.9703737753693775

Epoch: 5| Step: 7
Training loss: 0.9840637445449829
Validation loss: 1.9562985281790457

Epoch: 5| Step: 8
Training loss: 1.0211069583892822
Validation loss: 1.9544434457696893

Epoch: 5| Step: 9
Training loss: 1.1371757984161377
Validation loss: 1.9671394235344344

Epoch: 5| Step: 10
Training loss: 1.1012834310531616
Validation loss: 1.9772491429441719

Epoch: 224| Step: 0
Training loss: 1.5877501964569092
Validation loss: 1.9937652387926657

Epoch: 5| Step: 1
Training loss: 0.8752384185791016
Validation loss: 2.039104025851014

Epoch: 5| Step: 2
Training loss: 1.3713791370391846
Validation loss: 2.061991403179784

Epoch: 5| Step: 3
Training loss: 1.408459186553955
Validation loss: 2.0592024095596804

Epoch: 5| Step: 4
Training loss: 1.3576380014419556
Validation loss: 2.067875059702063

Epoch: 5| Step: 5
Training loss: 1.279422402381897
Validation loss: 2.064679061212847

Epoch: 5| Step: 6
Training loss: 1.2454838752746582
Validation loss: 2.0741817682020125

Epoch: 5| Step: 7
Training loss: 1.1110655069351196
Validation loss: 2.054030764487482

Epoch: 5| Step: 8
Training loss: 1.8924156427383423
Validation loss: 2.0272495118520593

Epoch: 5| Step: 9
Training loss: 1.469929575920105
Validation loss: 2.0307482314366165

Epoch: 5| Step: 10
Training loss: 0.7574251294136047
Validation loss: 2.015411651262673

Epoch: 225| Step: 0
Training loss: 1.1663362979888916
Validation loss: 2.0200382022447485

Epoch: 5| Step: 1
Training loss: 0.8062270879745483
Validation loss: 2.0111190990735124

Epoch: 5| Step: 2
Training loss: 1.0376073122024536
Validation loss: 2.006149561174454

Epoch: 5| Step: 3
Training loss: 1.188035249710083
Validation loss: 2.040840405289845

Epoch: 5| Step: 4
Training loss: 1.4251474142074585
Validation loss: 2.033903000175312

Epoch: 5| Step: 5
Training loss: 1.817094087600708
Validation loss: 2.0251872360065417

Epoch: 5| Step: 6
Training loss: 1.1038999557495117
Validation loss: 2.0129646075669156

Epoch: 5| Step: 7
Training loss: 1.3837802410125732
Validation loss: 1.9888127901220833

Epoch: 5| Step: 8
Training loss: 1.6911189556121826
Validation loss: 1.9881186921109435

Epoch: 5| Step: 9
Training loss: 0.9621745944023132
Validation loss: 1.9846847390615812

Epoch: 5| Step: 10
Training loss: 1.793443202972412
Validation loss: 1.9916443209494314

Epoch: 226| Step: 0
Training loss: 1.4671704769134521
Validation loss: 2.0138283365516254

Epoch: 5| Step: 1
Training loss: 1.6059319972991943
Validation loss: 2.0401546442380516

Epoch: 5| Step: 2
Training loss: 1.1906660795211792
Validation loss: 2.068473721063265

Epoch: 5| Step: 3
Training loss: 1.2167954444885254
Validation loss: 2.078453299819782

Epoch: 5| Step: 4
Training loss: 1.5283616781234741
Validation loss: 2.052557514559838

Epoch: 5| Step: 5
Training loss: 1.0319629907608032
Validation loss: 2.0239017394281205

Epoch: 5| Step: 6
Training loss: 1.6579103469848633
Validation loss: 1.987620420353387

Epoch: 5| Step: 7
Training loss: 0.7690873742103577
Validation loss: 1.9980655254856232

Epoch: 5| Step: 8
Training loss: 1.6555798053741455
Validation loss: 1.9864561096314461

Epoch: 5| Step: 9
Training loss: 1.1190687417984009
Validation loss: 2.0211515477908555

Epoch: 5| Step: 10
Training loss: 1.0475378036499023
Validation loss: 2.0469599257233324

Epoch: 227| Step: 0
Training loss: 1.039624810218811
Validation loss: 2.0312036455318494

Epoch: 5| Step: 1
Training loss: 1.5114082098007202
Validation loss: 2.0344446974415935

Epoch: 5| Step: 2
Training loss: 1.2559055089950562
Validation loss: 2.022812153703423

Epoch: 5| Step: 3
Training loss: 1.6163456439971924
Validation loss: 2.0367431153533277

Epoch: 5| Step: 4
Training loss: 1.0193274021148682
Validation loss: 2.046355491043419

Epoch: 5| Step: 5
Training loss: 0.8559992909431458
Validation loss: 2.049525927471858

Epoch: 5| Step: 6
Training loss: 1.5596543550491333
Validation loss: 2.0579222043355307

Epoch: 5| Step: 7
Training loss: 1.0900541543960571
Validation loss: 2.0649337717281875

Epoch: 5| Step: 8
Training loss: 1.599334716796875
Validation loss: 2.0631170811191684

Epoch: 5| Step: 9
Training loss: 1.1745493412017822
Validation loss: 2.0449504942022343

Epoch: 5| Step: 10
Training loss: 1.390101671218872
Validation loss: 2.035488483726337

Epoch: 228| Step: 0
Training loss: 2.3126323223114014
Validation loss: 2.026980233448808

Epoch: 5| Step: 1
Training loss: 1.1331443786621094
Validation loss: 2.063496417896722

Epoch: 5| Step: 2
Training loss: 1.2599763870239258
Validation loss: 2.058147197128624

Epoch: 5| Step: 3
Training loss: 0.8050609827041626
Validation loss: 2.0333086726486043

Epoch: 5| Step: 4
Training loss: 0.873068630695343
Validation loss: 1.9905201811944284

Epoch: 5| Step: 5
Training loss: 1.3684154748916626
Validation loss: 1.991083086177867

Epoch: 5| Step: 6
Training loss: 1.4314601421356201
Validation loss: 1.9811687443846016

Epoch: 5| Step: 7
Training loss: 1.239014744758606
Validation loss: 1.996204205738601

Epoch: 5| Step: 8
Training loss: 1.0809952020645142
Validation loss: 2.018247636415625

Epoch: 5| Step: 9
Training loss: 1.2680481672286987
Validation loss: 2.0501139407516806

Epoch: 5| Step: 10
Training loss: 1.3749384880065918
Validation loss: 2.079008597199635

Epoch: 229| Step: 0
Training loss: 1.1939375400543213
Validation loss: 2.057697012860288

Epoch: 5| Step: 1
Training loss: 1.1551096439361572
Validation loss: 2.045063869927519

Epoch: 5| Step: 2
Training loss: 1.5955089330673218
Validation loss: 2.0377295427424933

Epoch: 5| Step: 3
Training loss: 0.7110192179679871
Validation loss: 2.0139891101467993

Epoch: 5| Step: 4
Training loss: 0.8546367883682251
Validation loss: 2.029024948355972

Epoch: 5| Step: 5
Training loss: 1.0196939706802368
Validation loss: 2.0469775789527485

Epoch: 5| Step: 6
Training loss: 1.5398797988891602
Validation loss: 2.077721139436127

Epoch: 5| Step: 7
Training loss: 1.444709062576294
Validation loss: 2.0352383967368834

Epoch: 5| Step: 8
Training loss: 1.3255640268325806
Validation loss: 1.9910855985456897

Epoch: 5| Step: 9
Training loss: 1.6432132720947266
Validation loss: 1.9782131743687454

Epoch: 5| Step: 10
Training loss: 1.5006704330444336
Validation loss: 1.9600029042972031

Epoch: 230| Step: 0
Training loss: 1.4789520502090454
Validation loss: 1.9468248967201478

Epoch: 5| Step: 1
Training loss: 1.3004567623138428
Validation loss: 1.927221751982166

Epoch: 5| Step: 2
Training loss: 1.5794953107833862
Validation loss: 1.932927659762803

Epoch: 5| Step: 3
Training loss: 1.1052982807159424
Validation loss: 1.9497402201416671

Epoch: 5| Step: 4
Training loss: 1.6755132675170898
Validation loss: 1.975315349076384

Epoch: 5| Step: 5
Training loss: 0.7464412450790405
Validation loss: 2.0028921288828694

Epoch: 5| Step: 6
Training loss: 1.7709343433380127
Validation loss: 2.023404808454616

Epoch: 5| Step: 7
Training loss: 1.2038384675979614
Validation loss: 1.9936289761656074

Epoch: 5| Step: 8
Training loss: 1.3036911487579346
Validation loss: 2.017796101108674

Epoch: 5| Step: 9
Training loss: 1.1816235780715942
Validation loss: 2.0069732230196715

Epoch: 5| Step: 10
Training loss: 0.9291306734085083
Validation loss: 2.0002008048436974

Epoch: 231| Step: 0
Training loss: 1.4387686252593994
Validation loss: 1.9946673454776886

Epoch: 5| Step: 1
Training loss: 1.4783306121826172
Validation loss: 2.0316694756989837

Epoch: 5| Step: 2
Training loss: 1.2174780368804932
Validation loss: 2.051333181319698

Epoch: 5| Step: 3
Training loss: 1.4793115854263306
Validation loss: 2.0634089900601293

Epoch: 5| Step: 4
Training loss: 1.191608190536499
Validation loss: 2.093065023422241

Epoch: 5| Step: 5
Training loss: 1.2359288930892944
Validation loss: 2.0878157602843417

Epoch: 5| Step: 6
Training loss: 0.7895374298095703
Validation loss: 2.1229920566722913

Epoch: 5| Step: 7
Training loss: 1.2053806781768799
Validation loss: 2.1075177859234553

Epoch: 5| Step: 8
Training loss: 1.4452422857284546
Validation loss: 2.0802706005752727

Epoch: 5| Step: 9
Training loss: 1.1482855081558228
Validation loss: 2.0396155080487652

Epoch: 5| Step: 10
Training loss: 1.0835442543029785
Validation loss: 1.9998257672914894

Epoch: 232| Step: 0
Training loss: 0.7428265810012817
Validation loss: 1.9506753221634896

Epoch: 5| Step: 1
Training loss: 1.5819146633148193
Validation loss: 1.935730230423712

Epoch: 5| Step: 2
Training loss: 1.2314287424087524
Validation loss: 1.922322646264107

Epoch: 5| Step: 3
Training loss: 1.2140909433364868
Validation loss: 1.9317532944422897

Epoch: 5| Step: 4
Training loss: 1.1017346382141113
Validation loss: 1.9737097358190885

Epoch: 5| Step: 5
Training loss: 1.0037868022918701
Validation loss: 2.053300949835008

Epoch: 5| Step: 6
Training loss: 1.6577640771865845
Validation loss: 2.050415792772847

Epoch: 5| Step: 7
Training loss: 1.3552367687225342
Validation loss: 2.032144497799617

Epoch: 5| Step: 8
Training loss: 1.8609418869018555
Validation loss: 1.9779006076115433

Epoch: 5| Step: 9
Training loss: 0.9728438258171082
Validation loss: 1.9769200381412302

Epoch: 5| Step: 10
Training loss: 1.3832118511199951
Validation loss: 1.971907388779425

Epoch: 233| Step: 0
Training loss: 1.913155198097229
Validation loss: 1.9620348689376668

Epoch: 5| Step: 1
Training loss: 1.289346694946289
Validation loss: 1.9875683681939238

Epoch: 5| Step: 2
Training loss: 0.8851057887077332
Validation loss: 2.001522444909619

Epoch: 5| Step: 3
Training loss: 1.399835467338562
Validation loss: 2.066536541908018

Epoch: 5| Step: 4
Training loss: 1.2541812658309937
Validation loss: 2.0736603672786424

Epoch: 5| Step: 5
Training loss: 1.1620795726776123
Validation loss: 2.0745887781984065

Epoch: 5| Step: 6
Training loss: 1.3393363952636719
Validation loss: 2.0606714410166584

Epoch: 5| Step: 7
Training loss: 1.3853150606155396
Validation loss: 1.9979982068461757

Epoch: 5| Step: 8
Training loss: 1.1610357761383057
Validation loss: 1.9807388397955126

Epoch: 5| Step: 9
Training loss: 1.2913169860839844
Validation loss: 1.9625956486630183

Epoch: 5| Step: 10
Training loss: 0.7990757822990417
Validation loss: 1.961654515676601

Epoch: 234| Step: 0
Training loss: 1.513620138168335
Validation loss: 1.9723364640307683

Epoch: 5| Step: 1
Training loss: 1.2677130699157715
Validation loss: 1.9672395362648913

Epoch: 5| Step: 2
Training loss: 1.065216064453125
Validation loss: 1.9873083817061556

Epoch: 5| Step: 3
Training loss: 1.863468885421753
Validation loss: 1.9861196471798805

Epoch: 5| Step: 4
Training loss: 0.6810306310653687
Validation loss: 1.9844872977143975

Epoch: 5| Step: 5
Training loss: 1.0652707815170288
Validation loss: 1.9590191046396892

Epoch: 5| Step: 6
Training loss: 0.9445227384567261
Validation loss: 1.9436620166224818

Epoch: 5| Step: 7
Training loss: 1.7188804149627686
Validation loss: 1.9578173186189385

Epoch: 5| Step: 8
Training loss: 1.4440314769744873
Validation loss: 1.9715615446849535

Epoch: 5| Step: 9
Training loss: 1.396323561668396
Validation loss: 1.9961261082721014

Epoch: 5| Step: 10
Training loss: 0.7625076174736023
Validation loss: 1.9957854619590185

Epoch: 235| Step: 0
Training loss: 1.5219794511795044
Validation loss: 2.030224395054643

Epoch: 5| Step: 1
Training loss: 1.2016217708587646
Validation loss: 2.072885722242376

Epoch: 5| Step: 2
Training loss: 1.7097995281219482
Validation loss: 2.1202153134089645

Epoch: 5| Step: 3
Training loss: 1.2381166219711304
Validation loss: 2.06331737964384

Epoch: 5| Step: 4
Training loss: 0.9712425470352173
Validation loss: 2.0282149481517013

Epoch: 5| Step: 5
Training loss: 0.7944110035896301
Validation loss: 1.9903076156493156

Epoch: 5| Step: 6
Training loss: 1.399707555770874
Validation loss: 1.9589096897391862

Epoch: 5| Step: 7
Training loss: 0.7223483324050903
Validation loss: 1.9519059094049598

Epoch: 5| Step: 8
Training loss: 1.864373803138733
Validation loss: 1.9563947390484553

Epoch: 5| Step: 9
Training loss: 1.1673494577407837
Validation loss: 1.9642494634915424

Epoch: 5| Step: 10
Training loss: 0.702155590057373
Validation loss: 1.9814086985844437

Epoch: 236| Step: 0
Training loss: 1.023754596710205
Validation loss: 1.984884213375789

Epoch: 5| Step: 1
Training loss: 1.1755927801132202
Validation loss: 1.9810020282704344

Epoch: 5| Step: 2
Training loss: 2.0498206615448
Validation loss: 1.9856727584715812

Epoch: 5| Step: 3
Training loss: 1.07448410987854
Validation loss: 1.9687582280046196

Epoch: 5| Step: 4
Training loss: 1.3376591205596924
Validation loss: 1.971284798396531

Epoch: 5| Step: 5
Training loss: 1.1792724132537842
Validation loss: 1.9703756929725729

Epoch: 5| Step: 6
Training loss: 0.7383629679679871
Validation loss: 1.9818201911064885

Epoch: 5| Step: 7
Training loss: 1.1530964374542236
Validation loss: 1.9661719235040809

Epoch: 5| Step: 8
Training loss: 0.5875850915908813
Validation loss: 1.9741759838596467

Epoch: 5| Step: 9
Training loss: 1.1504366397857666
Validation loss: 1.9794288296853342

Epoch: 5| Step: 10
Training loss: 1.6316239833831787
Validation loss: 1.9838082610919912

Epoch: 237| Step: 0
Training loss: 1.1392067670822144
Validation loss: 1.9756096319485736

Epoch: 5| Step: 1
Training loss: 1.6032600402832031
Validation loss: 1.9547518607108825

Epoch: 5| Step: 2
Training loss: 1.420464277267456
Validation loss: 1.9708338168359572

Epoch: 5| Step: 3
Training loss: 0.9627137184143066
Validation loss: 1.9447768324164934

Epoch: 5| Step: 4
Training loss: 1.3599472045898438
Validation loss: 1.9756113662514636

Epoch: 5| Step: 5
Training loss: 0.7629415392875671
Validation loss: 1.9904342082238966

Epoch: 5| Step: 6
Training loss: 1.2332029342651367
Validation loss: 1.9862457359990766

Epoch: 5| Step: 7
Training loss: 1.033867597579956
Validation loss: 2.0065138211814304

Epoch: 5| Step: 8
Training loss: 1.520096778869629
Validation loss: 1.974811920555689

Epoch: 5| Step: 9
Training loss: 1.1479676961898804
Validation loss: 1.9805370274410452

Epoch: 5| Step: 10
Training loss: 0.7660414576530457
Validation loss: 1.9768270882227088

Epoch: 238| Step: 0
Training loss: 0.7532828450202942
Validation loss: 1.973989841758564

Epoch: 5| Step: 1
Training loss: 1.1294734477996826
Validation loss: 1.9895923958029798

Epoch: 5| Step: 2
Training loss: 1.5225064754486084
Validation loss: 2.005356466898354

Epoch: 5| Step: 3
Training loss: 0.7770679593086243
Validation loss: 1.9929156534133419

Epoch: 5| Step: 4
Training loss: 1.7376893758773804
Validation loss: 1.970720165519304

Epoch: 5| Step: 5
Training loss: 1.1219871044158936
Validation loss: 1.9846075209238196

Epoch: 5| Step: 6
Training loss: 1.0583827495574951
Validation loss: 1.996328471809305

Epoch: 5| Step: 7
Training loss: 0.9097832441329956
Validation loss: 2.02849135603956

Epoch: 5| Step: 8
Training loss: 1.424501895904541
Validation loss: 2.037049021772159

Epoch: 5| Step: 9
Training loss: 1.1295521259307861
Validation loss: 2.0399056173140004

Epoch: 5| Step: 10
Training loss: 1.1232953071594238
Validation loss: 2.0410348702502508

Epoch: 239| Step: 0
Training loss: 1.094109058380127
Validation loss: 2.0279934919008644

Epoch: 5| Step: 1
Training loss: 1.036954641342163
Validation loss: 1.9754069312926261

Epoch: 5| Step: 2
Training loss: 0.9757407903671265
Validation loss: 1.9379991946681854

Epoch: 5| Step: 3
Training loss: 1.1994346380233765
Validation loss: 1.9478777044562883

Epoch: 5| Step: 4
Training loss: 1.5910135507583618
Validation loss: 1.9278455395852365

Epoch: 5| Step: 5
Training loss: 1.65972101688385
Validation loss: 1.9407461279182023

Epoch: 5| Step: 6
Training loss: 1.0307992696762085
Validation loss: 1.9611635259402695

Epoch: 5| Step: 7
Training loss: 1.394222378730774
Validation loss: 1.9622494033587876

Epoch: 5| Step: 8
Training loss: 1.0950895547866821
Validation loss: 1.9904945768335813

Epoch: 5| Step: 9
Training loss: 0.6475273966789246
Validation loss: 2.0432916777108305

Epoch: 5| Step: 10
Training loss: 1.0477032661437988
Validation loss: 2.06360040813364

Epoch: 240| Step: 0
Training loss: 1.4694886207580566
Validation loss: 2.07358064446398

Epoch: 5| Step: 1
Training loss: 1.0012214183807373
Validation loss: 2.0413170309476953

Epoch: 5| Step: 2
Training loss: 1.2147897481918335
Validation loss: 2.0108054222599154

Epoch: 5| Step: 3
Training loss: 1.1137659549713135
Validation loss: 1.9870998128767936

Epoch: 5| Step: 4
Training loss: 1.032434105873108
Validation loss: 1.9611901185845817

Epoch: 5| Step: 5
Training loss: 1.5025103092193604
Validation loss: 1.9538564015460271

Epoch: 5| Step: 6
Training loss: 0.8808578252792358
Validation loss: 1.9686212539672852

Epoch: 5| Step: 7
Training loss: 0.9371779561042786
Validation loss: 2.013745609150138

Epoch: 5| Step: 8
Training loss: 1.241794466972351
Validation loss: 2.0459663291131296

Epoch: 5| Step: 9
Training loss: 1.102429747581482
Validation loss: 2.024854266515342

Epoch: 5| Step: 10
Training loss: 1.5184813737869263
Validation loss: 2.022960347513999

Epoch: 241| Step: 0
Training loss: 1.3181105852127075
Validation loss: 2.0141935604874805

Epoch: 5| Step: 1
Training loss: 1.128378987312317
Validation loss: 1.999478965677241

Epoch: 5| Step: 2
Training loss: 0.9039489030838013
Validation loss: 2.015349970068983

Epoch: 5| Step: 3
Training loss: 1.3371264934539795
Validation loss: 2.0330849975667973

Epoch: 5| Step: 4
Training loss: 1.4884419441223145
Validation loss: 2.0300651263165217

Epoch: 5| Step: 5
Training loss: 0.9356945157051086
Validation loss: 2.047970874335176

Epoch: 5| Step: 6
Training loss: 1.4410487413406372
Validation loss: 2.0996586943185456

Epoch: 5| Step: 7
Training loss: 1.2486927509307861
Validation loss: 2.0943140547762633

Epoch: 5| Step: 8
Training loss: 0.875732421875
Validation loss: 2.0267635827423423

Epoch: 5| Step: 9
Training loss: 1.1579710245132446
Validation loss: 1.950022312902635

Epoch: 5| Step: 10
Training loss: 1.423437476158142
Validation loss: 1.944881933991627

Epoch: 242| Step: 0
Training loss: 1.5722228288650513
Validation loss: 1.9213017635448004

Epoch: 5| Step: 1
Training loss: 1.5190160274505615
Validation loss: 1.959568618446268

Epoch: 5| Step: 2
Training loss: 0.6483073234558105
Validation loss: 1.974929230187529

Epoch: 5| Step: 3
Training loss: 0.7087181210517883
Validation loss: 1.981921595911826

Epoch: 5| Step: 4
Training loss: 1.3102164268493652
Validation loss: 2.019103665505686

Epoch: 5| Step: 5
Training loss: 0.9622451663017273
Validation loss: 2.0524451386544014

Epoch: 5| Step: 6
Training loss: 1.2860932350158691
Validation loss: 2.048415676239998

Epoch: 5| Step: 7
Training loss: 1.2773947715759277
Validation loss: 2.057967955066312

Epoch: 5| Step: 8
Training loss: 0.9604825973510742
Validation loss: 1.9969233171914214

Epoch: 5| Step: 9
Training loss: 1.1002440452575684
Validation loss: 1.9889202182010939

Epoch: 5| Step: 10
Training loss: 1.2491426467895508
Validation loss: 1.9812482800534976

Epoch: 243| Step: 0
Training loss: 0.7654982805252075
Validation loss: 1.9948933765452395

Epoch: 5| Step: 1
Training loss: 1.0728694200515747
Validation loss: 1.9705331402440225

Epoch: 5| Step: 2
Training loss: 1.6831254959106445
Validation loss: 1.9961922784005441

Epoch: 5| Step: 3
Training loss: 0.6198297739028931
Validation loss: 1.9877152135295253

Epoch: 5| Step: 4
Training loss: 1.8161756992340088
Validation loss: 1.9802610438357118

Epoch: 5| Step: 5
Training loss: 1.2507622241973877
Validation loss: 1.978346565718292

Epoch: 5| Step: 6
Training loss: 1.110738754272461
Validation loss: 2.01626447708376

Epoch: 5| Step: 7
Training loss: 0.7554830312728882
Validation loss: 2.0086806628011886

Epoch: 5| Step: 8
Training loss: 1.0872265100479126
Validation loss: 2.027586785695886

Epoch: 5| Step: 9
Training loss: 0.9012348055839539
Validation loss: 2.0073722024117746

Epoch: 5| Step: 10
Training loss: 1.1939753293991089
Validation loss: 2.0340915751713577

Epoch: 244| Step: 0
Training loss: 0.9758726358413696
Validation loss: 2.017001816021499

Epoch: 5| Step: 1
Training loss: 1.3138059377670288
Validation loss: 2.0014938359619467

Epoch: 5| Step: 2
Training loss: 0.9615419507026672
Validation loss: 1.972641296284173

Epoch: 5| Step: 3
Training loss: 1.2735203504562378
Validation loss: 1.9599601619987077

Epoch: 5| Step: 4
Training loss: 1.1810276508331299
Validation loss: 1.941662783263832

Epoch: 5| Step: 5
Training loss: 1.5244907140731812
Validation loss: 1.9637121256961618

Epoch: 5| Step: 6
Training loss: 1.452473521232605
Validation loss: 1.9938176626800208

Epoch: 5| Step: 7
Training loss: 1.0962355136871338
Validation loss: 2.0166546119156705

Epoch: 5| Step: 8
Training loss: 1.0384962558746338
Validation loss: 2.0641608597129903

Epoch: 5| Step: 9
Training loss: 1.0849272012710571
Validation loss: 2.0766239935351956

Epoch: 5| Step: 10
Training loss: 0.541522741317749
Validation loss: 2.042649387031473

Epoch: 245| Step: 0
Training loss: 0.9266704320907593
Validation loss: 1.9977191801994079

Epoch: 5| Step: 1
Training loss: 0.8220705986022949
Validation loss: 1.9804239375616914

Epoch: 5| Step: 2
Training loss: 1.1889314651489258
Validation loss: 1.9803794481421029

Epoch: 5| Step: 3
Training loss: 0.6956215500831604
Validation loss: 1.9759729139266475

Epoch: 5| Step: 4
Training loss: 1.3117420673370361
Validation loss: 1.992771767800854

Epoch: 5| Step: 5
Training loss: 1.596877932548523
Validation loss: 2.0204703064375025

Epoch: 5| Step: 6
Training loss: 1.4685754776000977
Validation loss: 2.079129049854894

Epoch: 5| Step: 7
Training loss: 1.1460672616958618
Validation loss: 2.100851312760384

Epoch: 5| Step: 8
Training loss: 0.9339515566825867
Validation loss: 2.073372584517284

Epoch: 5| Step: 9
Training loss: 0.8518984913825989
Validation loss: 2.0127985938902824

Epoch: 5| Step: 10
Training loss: 1.3699826002120972
Validation loss: 1.9741396186172322

Epoch: 246| Step: 0
Training loss: 0.8333697319030762
Validation loss: 1.962484953224018

Epoch: 5| Step: 1
Training loss: 1.421691656112671
Validation loss: 1.9715825229562738

Epoch: 5| Step: 2
Training loss: 1.1768964529037476
Validation loss: 1.9804477666013984

Epoch: 5| Step: 3
Training loss: 1.128224492073059
Validation loss: 1.974628968905377

Epoch: 5| Step: 4
Training loss: 0.6617439389228821
Validation loss: 2.020954660190049

Epoch: 5| Step: 5
Training loss: 1.069095492362976
Validation loss: 2.049837707191385

Epoch: 5| Step: 6
Training loss: 0.9936617016792297
Validation loss: 2.0858517052024923

Epoch: 5| Step: 7
Training loss: 1.0793063640594482
Validation loss: 2.0531891276759486

Epoch: 5| Step: 8
Training loss: 1.3341747522354126
Validation loss: 1.9870659997386317

Epoch: 5| Step: 9
Training loss: 1.0808566808700562
Validation loss: 1.9401484035676526

Epoch: 5| Step: 10
Training loss: 1.662674903869629
Validation loss: 1.9185042509468653

Epoch: 247| Step: 0
Training loss: 0.8149259686470032
Validation loss: 1.9210746698482062

Epoch: 5| Step: 1
Training loss: 1.272796869277954
Validation loss: 1.929668507268352

Epoch: 5| Step: 2
Training loss: 1.1614044904708862
Validation loss: 1.971617611505652

Epoch: 5| Step: 3
Training loss: 1.162766695022583
Validation loss: 2.0221897517481158

Epoch: 5| Step: 4
Training loss: 1.5368096828460693
Validation loss: 2.092461762889739

Epoch: 5| Step: 5
Training loss: 0.9238406419754028
Validation loss: 2.114979633720972

Epoch: 5| Step: 6
Training loss: 1.4202553033828735
Validation loss: 2.113439803482384

Epoch: 5| Step: 7
Training loss: 0.7753421068191528
Validation loss: 2.0755220036352835

Epoch: 5| Step: 8
Training loss: 0.933510422706604
Validation loss: 2.044629471276396

Epoch: 5| Step: 9
Training loss: 1.184340238571167
Validation loss: 2.0225439930474884

Epoch: 5| Step: 10
Training loss: 1.136209487915039
Validation loss: 1.9957316921603294

Epoch: 248| Step: 0
Training loss: 1.19408118724823
Validation loss: 1.9801598543761878

Epoch: 5| Step: 1
Training loss: 0.9399592280387878
Validation loss: 2.0050782349801834

Epoch: 5| Step: 2
Training loss: 0.7527187466621399
Validation loss: 2.021251468248265

Epoch: 5| Step: 3
Training loss: 1.1090624332427979
Validation loss: 1.9983179928154073

Epoch: 5| Step: 4
Training loss: 1.0902719497680664
Validation loss: 1.9941865936402352

Epoch: 5| Step: 5
Training loss: 0.9320440292358398
Validation loss: 1.9543916974016415

Epoch: 5| Step: 6
Training loss: 0.9936525225639343
Validation loss: 1.932916698917266

Epoch: 5| Step: 7
Training loss: 1.4725878238677979
Validation loss: 1.9358372226838143

Epoch: 5| Step: 8
Training loss: 1.2014625072479248
Validation loss: 1.9582291931234381

Epoch: 5| Step: 9
Training loss: 0.7645513415336609
Validation loss: 1.969946353666244

Epoch: 5| Step: 10
Training loss: 1.2805943489074707
Validation loss: 2.024090443888018

Epoch: 249| Step: 0
Training loss: 1.083968162536621
Validation loss: 2.0508453538340907

Epoch: 5| Step: 1
Training loss: 1.0984610319137573
Validation loss: 2.0921046272400887

Epoch: 5| Step: 2
Training loss: 1.4481868743896484
Validation loss: 2.0774851076064573

Epoch: 5| Step: 3
Training loss: 1.112088918685913
Validation loss: 2.0359641992917625

Epoch: 5| Step: 4
Training loss: 1.0425809621810913
Validation loss: 2.0132538439125143

Epoch: 5| Step: 5
Training loss: 0.714081883430481
Validation loss: 1.9576847207161687

Epoch: 5| Step: 6
Training loss: 1.1347792148590088
Validation loss: 1.9347003993167673

Epoch: 5| Step: 7
Training loss: 1.0607318878173828
Validation loss: 1.955597008428266

Epoch: 5| Step: 8
Training loss: 0.879761815071106
Validation loss: 1.9570035331992692

Epoch: 5| Step: 9
Training loss: 1.1480228900909424
Validation loss: 1.9699348095924623

Epoch: 5| Step: 10
Training loss: 1.0125012397766113
Validation loss: 2.0094195258232856

Epoch: 250| Step: 0
Training loss: 1.1638742685317993
Validation loss: 2.0371598377022693

Epoch: 5| Step: 1
Training loss: 0.9691156148910522
Validation loss: 2.039349827715146

Epoch: 5| Step: 2
Training loss: 1.2650684118270874
Validation loss: 2.0396499185151953

Epoch: 5| Step: 3
Training loss: 1.1397604942321777
Validation loss: 2.0001495448491906

Epoch: 5| Step: 4
Training loss: 0.7914096713066101
Validation loss: 1.9888395468393962

Epoch: 5| Step: 5
Training loss: 1.0421350002288818
Validation loss: 1.9753877360333678

Epoch: 5| Step: 6
Training loss: 0.8452330827713013
Validation loss: 1.955157651696154

Epoch: 5| Step: 7
Training loss: 1.2550036907196045
Validation loss: 1.9721832172845

Epoch: 5| Step: 8
Training loss: 1.02168869972229
Validation loss: 1.9959141439007175

Epoch: 5| Step: 9
Training loss: 1.1175405979156494
Validation loss: 1.9932846612827753

Epoch: 5| Step: 10
Training loss: 1.1207605600357056
Validation loss: 2.0050038932472147

Epoch: 251| Step: 0
Training loss: 0.7717693448066711
Validation loss: 2.017041975452054

Epoch: 5| Step: 1
Training loss: 1.2087090015411377
Validation loss: 2.0419940538303827

Epoch: 5| Step: 2
Training loss: 1.0271075963974
Validation loss: 2.0379554071734027

Epoch: 5| Step: 3
Training loss: 0.7085051536560059
Validation loss: 2.022116853344825

Epoch: 5| Step: 4
Training loss: 1.0569404363632202
Validation loss: 2.0114683220463414

Epoch: 5| Step: 5
Training loss: 1.2779827117919922
Validation loss: 2.0143239331501785

Epoch: 5| Step: 6
Training loss: 0.8346850275993347
Validation loss: 1.9892143844276347

Epoch: 5| Step: 7
Training loss: 1.3212881088256836
Validation loss: 2.0274440473125828

Epoch: 5| Step: 8
Training loss: 0.8755755424499512
Validation loss: 2.0002550950614353

Epoch: 5| Step: 9
Training loss: 1.0881903171539307
Validation loss: 1.9854336348913049

Epoch: 5| Step: 10
Training loss: 1.4306615591049194
Validation loss: 1.9665983415419055

Epoch: 252| Step: 0
Training loss: 1.3400219678878784
Validation loss: 1.9308363955507997

Epoch: 5| Step: 1
Training loss: 1.4143134355545044
Validation loss: 1.9263938396207747

Epoch: 5| Step: 2
Training loss: 0.9642893671989441
Validation loss: 1.928411768328759

Epoch: 5| Step: 3
Training loss: 0.5814809799194336
Validation loss: 1.9748156134800245

Epoch: 5| Step: 4
Training loss: 0.9617177248001099
Validation loss: 1.9910333002767255

Epoch: 5| Step: 5
Training loss: 0.8148248791694641
Validation loss: 2.012592504101415

Epoch: 5| Step: 6
Training loss: 1.3755977153778076
Validation loss: 2.005066893434012

Epoch: 5| Step: 7
Training loss: 1.0704413652420044
Validation loss: 2.020589948982321

Epoch: 5| Step: 8
Training loss: 1.2256749868392944
Validation loss: 1.9781487141886065

Epoch: 5| Step: 9
Training loss: 1.0397788286209106
Validation loss: 1.9670576203253962

Epoch: 5| Step: 10
Training loss: 0.6418874263763428
Validation loss: 1.9882364734526603

Epoch: 253| Step: 0
Training loss: 0.9878734350204468
Validation loss: 1.9750009377797444

Epoch: 5| Step: 1
Training loss: 0.686176598072052
Validation loss: 1.9876338743394422

Epoch: 5| Step: 2
Training loss: 0.5043896436691284
Validation loss: 1.9881467639759023

Epoch: 5| Step: 3
Training loss: 1.0790499448776245
Validation loss: 1.9919313410277009

Epoch: 5| Step: 4
Training loss: 0.9390634298324585
Validation loss: 2.001199057025294

Epoch: 5| Step: 5
Training loss: 1.4001003503799438
Validation loss: 2.005198665844497

Epoch: 5| Step: 6
Training loss: 1.0789790153503418
Validation loss: 2.0251247113750828

Epoch: 5| Step: 7
Training loss: 1.2176319360733032
Validation loss: 2.034495892063264

Epoch: 5| Step: 8
Training loss: 1.2297875881195068
Validation loss: 2.0113726700505903

Epoch: 5| Step: 9
Training loss: 1.5970799922943115
Validation loss: 2.022690419227846

Epoch: 5| Step: 10
Training loss: 0.5195541381835938
Validation loss: 2.0063328742980957

Epoch: 254| Step: 0
Training loss: 0.9461250305175781
Validation loss: 1.9951047320519724

Epoch: 5| Step: 1
Training loss: 0.7874189615249634
Validation loss: 1.9877484767667708

Epoch: 5| Step: 2
Training loss: 1.1112902164459229
Validation loss: 1.9855868893284951

Epoch: 5| Step: 3
Training loss: 1.2334849834442139
Validation loss: 1.9960441563719062

Epoch: 5| Step: 4
Training loss: 0.9378253221511841
Validation loss: 1.9865074324351486

Epoch: 5| Step: 5
Training loss: 1.4999979734420776
Validation loss: 1.971531887208262

Epoch: 5| Step: 6
Training loss: 0.8837943077087402
Validation loss: 1.9917444746981385

Epoch: 5| Step: 7
Training loss: 1.0554362535476685
Validation loss: 2.0050339314245407

Epoch: 5| Step: 8
Training loss: 0.8228715658187866
Validation loss: 2.028089269515007

Epoch: 5| Step: 9
Training loss: 1.0487377643585205
Validation loss: 2.018745647963657

Epoch: 5| Step: 10
Training loss: 0.729800820350647
Validation loss: 2.0358311399336784

Epoch: 255| Step: 0
Training loss: 1.1152541637420654
Validation loss: 2.0090017908362934

Epoch: 5| Step: 1
Training loss: 0.6317959427833557
Validation loss: 1.982231714392221

Epoch: 5| Step: 2
Training loss: 1.1644362211227417
Validation loss: 1.9781720279365458

Epoch: 5| Step: 3
Training loss: 1.4587247371673584
Validation loss: 1.9706099174355949

Epoch: 5| Step: 4
Training loss: 0.9982461929321289
Validation loss: 1.9602386836082704

Epoch: 5| Step: 5
Training loss: 1.1381399631500244
Validation loss: 1.965511886022424

Epoch: 5| Step: 6
Training loss: 0.6223843693733215
Validation loss: 2.0019311904907227

Epoch: 5| Step: 7
Training loss: 1.0963361263275146
Validation loss: 2.0547588076642764

Epoch: 5| Step: 8
Training loss: 0.8464549779891968
Validation loss: 2.0268100256560952

Epoch: 5| Step: 9
Training loss: 1.257339596748352
Validation loss: 2.018645868506483

Epoch: 5| Step: 10
Training loss: 1.0727566480636597
Validation loss: 2.0075793868751934

Epoch: 256| Step: 0
Training loss: 0.7501969337463379
Validation loss: 1.9566509371162744

Epoch: 5| Step: 1
Training loss: 1.186483383178711
Validation loss: 1.954679419917445

Epoch: 5| Step: 2
Training loss: 0.7561542391777039
Validation loss: 1.9817280692438926

Epoch: 5| Step: 3
Training loss: 1.174884557723999
Validation loss: 1.9867527254166142

Epoch: 5| Step: 4
Training loss: 1.3236998319625854
Validation loss: 2.000387981373777

Epoch: 5| Step: 5
Training loss: 0.8443997502326965
Validation loss: 1.997709487074165

Epoch: 5| Step: 6
Training loss: 1.1721595525741577
Validation loss: 2.020312980938983

Epoch: 5| Step: 7
Training loss: 1.3165481090545654
Validation loss: 2.062573625195411

Epoch: 5| Step: 8
Training loss: 0.9323724508285522
Validation loss: 2.097812521842218

Epoch: 5| Step: 9
Training loss: 0.9333804845809937
Validation loss: 2.105442423974314

Epoch: 5| Step: 10
Training loss: 1.0181773900985718
Validation loss: 2.0594777496912147

Epoch: 257| Step: 0
Training loss: 0.924334704875946
Validation loss: 1.995897998091995

Epoch: 5| Step: 1
Training loss: 1.2016527652740479
Validation loss: 1.9509021389868952

Epoch: 5| Step: 2
Training loss: 1.0810167789459229
Validation loss: 1.9035405523033553

Epoch: 5| Step: 3
Training loss: 0.6769016981124878
Validation loss: 1.8919159032965218

Epoch: 5| Step: 4
Training loss: 1.1235716342926025
Validation loss: 1.8768016074293403

Epoch: 5| Step: 5
Training loss: 1.4353995323181152
Validation loss: 1.869883842365716

Epoch: 5| Step: 6
Training loss: 0.6733974814414978
Validation loss: 1.902372758875611

Epoch: 5| Step: 7
Training loss: 0.3253853917121887
Validation loss: 1.9234956464459818

Epoch: 5| Step: 8
Training loss: 0.9095215797424316
Validation loss: 1.972205836285827

Epoch: 5| Step: 9
Training loss: 1.1880338191986084
Validation loss: 2.0433394293631277

Epoch: 5| Step: 10
Training loss: 1.6025149822235107
Validation loss: 2.0531295550766813

Epoch: 258| Step: 0
Training loss: 1.1661288738250732
Validation loss: 2.014981410836661

Epoch: 5| Step: 1
Training loss: 0.9544609189033508
Validation loss: 1.9613954918358916

Epoch: 5| Step: 2
Training loss: 1.2440465688705444
Validation loss: 1.9596551733632241

Epoch: 5| Step: 3
Training loss: 1.3504536151885986
Validation loss: 1.9613012126697007

Epoch: 5| Step: 4
Training loss: 0.950536847114563
Validation loss: 1.972256814279864

Epoch: 5| Step: 5
Training loss: 0.7850574254989624
Validation loss: 2.0041784022444036

Epoch: 5| Step: 6
Training loss: 0.9240460395812988
Validation loss: 1.9698719991150724

Epoch: 5| Step: 7
Training loss: 0.8663797378540039
Validation loss: 1.9487281563461467

Epoch: 5| Step: 8
Training loss: 0.7282567024230957
Validation loss: 1.9448638449433029

Epoch: 5| Step: 9
Training loss: 0.8723041415214539
Validation loss: 1.9338605461582061

Epoch: 5| Step: 10
Training loss: 0.7580403089523315
Validation loss: 1.933639572512719

Epoch: 259| Step: 0
Training loss: 1.088870882987976
Validation loss: 1.9344621768561743

Epoch: 5| Step: 1
Training loss: 0.8513343930244446
Validation loss: 1.9543825298227289

Epoch: 5| Step: 2
Training loss: 0.89567631483078
Validation loss: 1.9818996703752907

Epoch: 5| Step: 3
Training loss: 1.4010990858078003
Validation loss: 1.9937984840844267

Epoch: 5| Step: 4
Training loss: 1.3002277612686157
Validation loss: 2.0048920082789596

Epoch: 5| Step: 5
Training loss: 0.9927366375923157
Validation loss: 1.9931086801713513

Epoch: 5| Step: 6
Training loss: 0.49469852447509766
Validation loss: 1.9814589305590558

Epoch: 5| Step: 7
Training loss: 0.9425336718559265
Validation loss: 1.9618303416877665

Epoch: 5| Step: 8
Training loss: 0.6605353951454163
Validation loss: 1.9684558530007639

Epoch: 5| Step: 9
Training loss: 1.244879961013794
Validation loss: 1.9505315032056583

Epoch: 5| Step: 10
Training loss: 0.8840198516845703
Validation loss: 1.9443680265898347

Epoch: 260| Step: 0
Training loss: 0.9942997097969055
Validation loss: 1.9427390944573186

Epoch: 5| Step: 1
Training loss: 0.8938663601875305
Validation loss: 1.9632540236237228

Epoch: 5| Step: 2
Training loss: 0.9607816934585571
Validation loss: 1.9554599613271735

Epoch: 5| Step: 3
Training loss: 0.4528230130672455
Validation loss: 1.9607248588274884

Epoch: 5| Step: 4
Training loss: 1.1024436950683594
Validation loss: 1.9930623859487555

Epoch: 5| Step: 5
Training loss: 0.8689216375350952
Validation loss: 1.987333615620931

Epoch: 5| Step: 6
Training loss: 0.8695077896118164
Validation loss: 2.026328147098582

Epoch: 5| Step: 7
Training loss: 1.218871831893921
Validation loss: 2.040858789156842

Epoch: 5| Step: 8
Training loss: 1.3994626998901367
Validation loss: 2.0276273899180914

Epoch: 5| Step: 9
Training loss: 0.8634623289108276
Validation loss: 1.9898255332823722

Epoch: 5| Step: 10
Training loss: 1.049870252609253
Validation loss: 1.947630843808574

Epoch: 261| Step: 0
Training loss: 0.8640213012695312
Validation loss: 1.9408979544075586

Epoch: 5| Step: 1
Training loss: 0.8969839215278625
Validation loss: 1.9091293760525283

Epoch: 5| Step: 2
Training loss: 0.7858886122703552
Validation loss: 1.912977813392557

Epoch: 5| Step: 3
Training loss: 0.6630706191062927
Validation loss: 1.9040206786124938

Epoch: 5| Step: 4
Training loss: 0.9567058682441711
Validation loss: 1.9071581940497122

Epoch: 5| Step: 5
Training loss: 0.8259406089782715
Validation loss: 1.917853670735513

Epoch: 5| Step: 6
Training loss: 0.7446629405021667
Validation loss: 1.9446539020025602

Epoch: 5| Step: 7
Training loss: 1.1610662937164307
Validation loss: 1.9506462876514723

Epoch: 5| Step: 8
Training loss: 1.4869146347045898
Validation loss: 1.9834594675289687

Epoch: 5| Step: 9
Training loss: 0.7937979698181152
Validation loss: 2.009872349359656

Epoch: 5| Step: 10
Training loss: 1.38511323928833
Validation loss: 2.0374305837897846

Epoch: 262| Step: 0
Training loss: 0.7807548642158508
Validation loss: 2.0618921608053227

Epoch: 5| Step: 1
Training loss: 1.267601728439331
Validation loss: 1.9852109263020177

Epoch: 5| Step: 2
Training loss: 0.8165231943130493
Validation loss: 1.9811453921820528

Epoch: 5| Step: 3
Training loss: 0.7414364814758301
Validation loss: 1.9847923914591472

Epoch: 5| Step: 4
Training loss: 0.630172610282898
Validation loss: 1.9572142965050154

Epoch: 5| Step: 5
Training loss: 1.1825745105743408
Validation loss: 1.9971736977177281

Epoch: 5| Step: 6
Training loss: 0.6391854286193848
Validation loss: 1.9741408863375265

Epoch: 5| Step: 7
Training loss: 0.8234940767288208
Validation loss: 1.9960906249220653

Epoch: 5| Step: 8
Training loss: 0.838584303855896
Validation loss: 1.9727119732928533

Epoch: 5| Step: 9
Training loss: 1.2274748086929321
Validation loss: 1.978157551057877

Epoch: 5| Step: 10
Training loss: 1.425762414932251
Validation loss: 1.9455083083080988

Epoch: 263| Step: 0
Training loss: 0.9579542875289917
Validation loss: 1.9595798805195799

Epoch: 5| Step: 1
Training loss: 1.2884266376495361
Validation loss: 1.9834662970676218

Epoch: 5| Step: 2
Training loss: 0.5026627779006958
Validation loss: 1.991379701963035

Epoch: 5| Step: 3
Training loss: 0.8335309028625488
Validation loss: 1.982569981646794

Epoch: 5| Step: 4
Training loss: 0.8751201629638672
Validation loss: 1.960079546897642

Epoch: 5| Step: 5
Training loss: 0.7566149830818176
Validation loss: 1.955139107601617

Epoch: 5| Step: 6
Training loss: 1.0260180234909058
Validation loss: 1.9151701978457871

Epoch: 5| Step: 7
Training loss: 0.9675183296203613
Validation loss: 1.942029183910739

Epoch: 5| Step: 8
Training loss: 1.0957520008087158
Validation loss: 1.9238153221786662

Epoch: 5| Step: 9
Training loss: 0.9345178604125977
Validation loss: 1.930470892178115

Epoch: 5| Step: 10
Training loss: 0.9026861786842346
Validation loss: 1.920383914824455

Epoch: 264| Step: 0
Training loss: 0.8690348863601685
Validation loss: 1.9340732482171827

Epoch: 5| Step: 1
Training loss: 1.0416169166564941
Validation loss: 1.897340900154524

Epoch: 5| Step: 2
Training loss: 0.8430439829826355
Validation loss: 1.9042569360425394

Epoch: 5| Step: 3
Training loss: 0.7616468667984009
Validation loss: 1.8795458860294794

Epoch: 5| Step: 4
Training loss: 0.7688637971878052
Validation loss: 1.8837896265009397

Epoch: 5| Step: 5
Training loss: 1.2683345079421997
Validation loss: 1.89437956963816

Epoch: 5| Step: 6
Training loss: 1.0886785984039307
Validation loss: 1.9176537990570068

Epoch: 5| Step: 7
Training loss: 0.7837555408477783
Validation loss: 1.9421385783021168

Epoch: 5| Step: 8
Training loss: 1.161940336227417
Validation loss: 1.9788814872823737

Epoch: 5| Step: 9
Training loss: 1.1104053258895874
Validation loss: 2.0228156889638593

Epoch: 5| Step: 10
Training loss: 0.648712158203125
Validation loss: 2.0100704162351546

Epoch: 265| Step: 0
Training loss: 0.8031482696533203
Validation loss: 1.984630738535235

Epoch: 5| Step: 1
Training loss: 0.9968420267105103
Validation loss: 1.9640461039799515

Epoch: 5| Step: 2
Training loss: 0.8739447593688965
Validation loss: 1.9449536056928738

Epoch: 5| Step: 3
Training loss: 0.6876537799835205
Validation loss: 1.9390400161025345

Epoch: 5| Step: 4
Training loss: 1.152958631515503
Validation loss: 1.952508108590239

Epoch: 5| Step: 5
Training loss: 0.7973521947860718
Validation loss: 1.9483313124666932

Epoch: 5| Step: 6
Training loss: 0.9530749320983887
Validation loss: 1.940152575892787

Epoch: 5| Step: 7
Training loss: 0.9051963686943054
Validation loss: 1.9547516043468187

Epoch: 5| Step: 8
Training loss: 0.7061571478843689
Validation loss: 1.9618864802904026

Epoch: 5| Step: 9
Training loss: 1.0401849746704102
Validation loss: 1.9666932475182317

Epoch: 5| Step: 10
Training loss: 1.5198137760162354
Validation loss: 1.9802976590330883

Epoch: 266| Step: 0
Training loss: 1.0114490985870361
Validation loss: 1.905658075886388

Epoch: 5| Step: 1
Training loss: 0.8517395853996277
Validation loss: 1.8877367575963337

Epoch: 5| Step: 2
Training loss: 0.5747424960136414
Validation loss: 1.8864717739884571

Epoch: 5| Step: 3
Training loss: 0.6746364831924438
Validation loss: 1.8986897750567364

Epoch: 5| Step: 4
Training loss: 1.3741264343261719
Validation loss: 1.9320208564881356

Epoch: 5| Step: 5
Training loss: 1.0276516675949097
Validation loss: 1.9842706700806976

Epoch: 5| Step: 6
Training loss: 0.7623826861381531
Validation loss: 1.975484098157575

Epoch: 5| Step: 7
Training loss: 0.6404737234115601
Validation loss: 1.9703443665658273

Epoch: 5| Step: 8
Training loss: 1.0138299465179443
Validation loss: 1.9376709563757784

Epoch: 5| Step: 9
Training loss: 1.3126354217529297
Validation loss: 1.9348924685549993

Epoch: 5| Step: 10
Training loss: 0.8042541742324829
Validation loss: 1.92142657567096

Epoch: 267| Step: 0
Training loss: 0.6095150113105774
Validation loss: 1.9472274049635856

Epoch: 5| Step: 1
Training loss: 0.9761589169502258
Validation loss: 1.9628685405177455

Epoch: 5| Step: 2
Training loss: 1.294334053993225
Validation loss: 1.987014264188787

Epoch: 5| Step: 3
Training loss: 0.7980157136917114
Validation loss: 2.0035801241474767

Epoch: 5| Step: 4
Training loss: 0.7051504850387573
Validation loss: 1.9848941628650953

Epoch: 5| Step: 5
Training loss: 0.8040992617607117
Validation loss: 1.9478430081439275

Epoch: 5| Step: 6
Training loss: 1.0025169849395752
Validation loss: 1.939097591625747

Epoch: 5| Step: 7
Training loss: 0.8201980590820312
Validation loss: 1.921717474537511

Epoch: 5| Step: 8
Training loss: 0.7644826769828796
Validation loss: 1.9303481219917216

Epoch: 5| Step: 9
Training loss: 1.1234090328216553
Validation loss: 1.9549550292312459

Epoch: 5| Step: 10
Training loss: 0.9521522521972656
Validation loss: 1.9838825182248188

Epoch: 268| Step: 0
Training loss: 1.1836017370224
Validation loss: 1.9899980406607352

Epoch: 5| Step: 1
Training loss: 0.9800100326538086
Validation loss: 1.9786794544548116

Epoch: 5| Step: 2
Training loss: 0.8320270776748657
Validation loss: 1.926525414630931

Epoch: 5| Step: 3
Training loss: 1.2615004777908325
Validation loss: 1.906408545791462

Epoch: 5| Step: 4
Training loss: 0.9480687975883484
Validation loss: 1.8966868180100636

Epoch: 5| Step: 5
Training loss: 0.3877101242542267
Validation loss: 1.903031362000332

Epoch: 5| Step: 6
Training loss: 0.5848037004470825
Validation loss: 1.942465853947465

Epoch: 5| Step: 7
Training loss: 1.0852625370025635
Validation loss: 1.9452527966550601

Epoch: 5| Step: 8
Training loss: 0.6604290008544922
Validation loss: 1.9717474650311213

Epoch: 5| Step: 9
Training loss: 0.987047553062439
Validation loss: 1.9735781095361198

Epoch: 5| Step: 10
Training loss: 1.0687767267227173
Validation loss: 1.9599749426687918

Epoch: 269| Step: 0
Training loss: 0.9035810232162476
Validation loss: 1.9524596903913765

Epoch: 5| Step: 1
Training loss: 0.5672851800918579
Validation loss: 1.9212584687817482

Epoch: 5| Step: 2
Training loss: 1.0627914667129517
Validation loss: 1.922692455271239

Epoch: 5| Step: 3
Training loss: 0.8664796948432922
Validation loss: 1.911475307197981

Epoch: 5| Step: 4
Training loss: 1.0512100458145142
Validation loss: 1.926276437697872

Epoch: 5| Step: 5
Training loss: 0.9545646905899048
Validation loss: 1.9385987340763051

Epoch: 5| Step: 6
Training loss: 1.3789637088775635
Validation loss: 1.9675917625427246

Epoch: 5| Step: 7
Training loss: 0.910629391670227
Validation loss: 2.0031804166814333

Epoch: 5| Step: 8
Training loss: 1.0508239269256592
Validation loss: 2.0313422526082685

Epoch: 5| Step: 9
Training loss: 0.5344526171684265
Validation loss: 1.982542823719722

Epoch: 5| Step: 10
Training loss: 0.9084307551383972
Validation loss: 1.9578303008951166

Epoch: 270| Step: 0
Training loss: 1.2413560152053833
Validation loss: 1.9276933836680588

Epoch: 5| Step: 1
Training loss: 0.7005154490470886
Validation loss: 1.9065551116902342

Epoch: 5| Step: 2
Training loss: 0.8883100748062134
Validation loss: 1.9248649202367312

Epoch: 5| Step: 3
Training loss: 0.6314903497695923
Validation loss: 1.9238534473603772

Epoch: 5| Step: 4
Training loss: 0.9876394271850586
Validation loss: 1.9426366257411178

Epoch: 5| Step: 5
Training loss: 0.7595192193984985
Validation loss: 1.9965287639248757

Epoch: 5| Step: 6
Training loss: 0.8422032594680786
Validation loss: 1.9892433599759174

Epoch: 5| Step: 7
Training loss: 0.5894416570663452
Validation loss: 2.031645115985665

Epoch: 5| Step: 8
Training loss: 0.4189218580722809
Validation loss: 2.0219449125310427

Epoch: 5| Step: 9
Training loss: 1.074562907218933
Validation loss: 2.001889531330396

Epoch: 5| Step: 10
Training loss: 1.639939308166504
Validation loss: 1.9542478925438338

Epoch: 271| Step: 0
Training loss: 0.9786885380744934
Validation loss: 1.95288283594193

Epoch: 5| Step: 1
Training loss: 0.9757310152053833
Validation loss: 1.929390989324098

Epoch: 5| Step: 2
Training loss: 1.3866736888885498
Validation loss: 1.9105802120700959

Epoch: 5| Step: 3
Training loss: 1.033329725265503
Validation loss: 1.9128582067387079

Epoch: 5| Step: 4
Training loss: 0.7184056639671326
Validation loss: 1.920540286648658

Epoch: 5| Step: 5
Training loss: 0.6737047433853149
Validation loss: 1.9297051942476662

Epoch: 5| Step: 6
Training loss: 0.8140006065368652
Validation loss: 1.981991942210864

Epoch: 5| Step: 7
Training loss: 0.936546802520752
Validation loss: 2.0197701492617206

Epoch: 5| Step: 8
Training loss: 0.8544895052909851
Validation loss: 2.0166567730647262

Epoch: 5| Step: 9
Training loss: 0.6650425791740417
Validation loss: 1.9469210640076668

Epoch: 5| Step: 10
Training loss: 0.631487250328064
Validation loss: 1.9157056962290118

Epoch: 272| Step: 0
Training loss: 0.590180516242981
Validation loss: 1.8984588922992829

Epoch: 5| Step: 1
Training loss: 0.5162302255630493
Validation loss: 1.8823898069320186

Epoch: 5| Step: 2
Training loss: 1.1539216041564941
Validation loss: 1.8973679798905567

Epoch: 5| Step: 3
Training loss: 0.9788262248039246
Validation loss: 1.916912014766406

Epoch: 5| Step: 4
Training loss: 0.8945757150650024
Validation loss: 1.9214927945085751

Epoch: 5| Step: 5
Training loss: 0.9125947952270508
Validation loss: 1.952442007680093

Epoch: 5| Step: 6
Training loss: 0.8426289558410645
Validation loss: 1.9600064434031004

Epoch: 5| Step: 7
Training loss: 0.6990206837654114
Validation loss: 1.9420223364266016

Epoch: 5| Step: 8
Training loss: 0.772681713104248
Validation loss: 1.9228400966172576

Epoch: 5| Step: 9
Training loss: 1.0588210821151733
Validation loss: 1.8926374886625557

Epoch: 5| Step: 10
Training loss: 1.1408917903900146
Validation loss: 1.8964665999976538

Epoch: 273| Step: 0
Training loss: 0.6549111604690552
Validation loss: 1.9123163069448164

Epoch: 5| Step: 1
Training loss: 0.3189309239387512
Validation loss: 1.920119265074371

Epoch: 5| Step: 2
Training loss: 0.9443108439445496
Validation loss: 1.9069574199697024

Epoch: 5| Step: 3
Training loss: 1.2586740255355835
Validation loss: 1.913596914660546

Epoch: 5| Step: 4
Training loss: 1.081911325454712
Validation loss: 1.9532354493294992

Epoch: 5| Step: 5
Training loss: 0.5729741454124451
Validation loss: 1.9620529861860379

Epoch: 5| Step: 6
Training loss: 0.8918261528015137
Validation loss: 1.96522690403846

Epoch: 5| Step: 7
Training loss: 1.0144743919372559
Validation loss: 1.934266771039655

Epoch: 5| Step: 8
Training loss: 0.7960103154182434
Validation loss: 1.9188828070958455

Epoch: 5| Step: 9
Training loss: 0.9953478574752808
Validation loss: 1.9123801979967343

Epoch: 5| Step: 10
Training loss: 0.8360607028007507
Validation loss: 1.935473798423685

Epoch: 274| Step: 0
Training loss: 1.351261854171753
Validation loss: 1.9300829646407918

Epoch: 5| Step: 1
Training loss: 0.8431257009506226
Validation loss: 1.9051580198349491

Epoch: 5| Step: 2
Training loss: 0.8695739507675171
Validation loss: 1.9643250229538127

Epoch: 5| Step: 3
Training loss: 0.5347487330436707
Validation loss: 1.983276681233478

Epoch: 5| Step: 4
Training loss: 0.930099606513977
Validation loss: 2.0065056200950377

Epoch: 5| Step: 5
Training loss: 0.7293285131454468
Validation loss: 1.9846094167360695

Epoch: 5| Step: 6
Training loss: 0.8842924237251282
Validation loss: 1.9715600629006662

Epoch: 5| Step: 7
Training loss: 0.7577720880508423
Validation loss: 1.938415035124748

Epoch: 5| Step: 8
Training loss: 0.7104442715644836
Validation loss: 1.9464403147338538

Epoch: 5| Step: 9
Training loss: 0.673384964466095
Validation loss: 1.9264170213412213

Epoch: 5| Step: 10
Training loss: 0.9355763792991638
Validation loss: 1.9308311234238327

Epoch: 275| Step: 0
Training loss: 0.6432203054428101
Validation loss: 1.937897536062425

Epoch: 5| Step: 1
Training loss: 0.9901397824287415
Validation loss: 1.9322276935782483

Epoch: 5| Step: 2
Training loss: 0.6054523587226868
Validation loss: 1.9572238665755077

Epoch: 5| Step: 3
Training loss: 0.8086972236633301
Validation loss: 1.955311124042798

Epoch: 5| Step: 4
Training loss: 0.8087064623832703
Validation loss: 1.9717685689208329

Epoch: 5| Step: 5
Training loss: 1.1556599140167236
Validation loss: 1.9768089504652127

Epoch: 5| Step: 6
Training loss: 0.7906534075737
Validation loss: 1.9719642490469

Epoch: 5| Step: 7
Training loss: 1.002764105796814
Validation loss: 1.9298534495856172

Epoch: 5| Step: 8
Training loss: 0.7785165905952454
Validation loss: 1.932260246687038

Epoch: 5| Step: 9
Training loss: 0.803837776184082
Validation loss: 1.9230164725293395

Epoch: 5| Step: 10
Training loss: 0.6647031307220459
Validation loss: 1.9010091827761741

Epoch: 276| Step: 0
Training loss: 0.8603829145431519
Validation loss: 1.8993033568064372

Epoch: 5| Step: 1
Training loss: 0.7006407380104065
Validation loss: 1.9276043702197332

Epoch: 5| Step: 2
Training loss: 0.9616405367851257
Validation loss: 1.942100432611281

Epoch: 5| Step: 3
Training loss: 0.6301261186599731
Validation loss: 1.9755935438217656

Epoch: 5| Step: 4
Training loss: 0.6204214692115784
Validation loss: 1.9794715066109934

Epoch: 5| Step: 5
Training loss: 0.8690455555915833
Validation loss: 1.9836589546613796

Epoch: 5| Step: 6
Training loss: 1.2163338661193848
Validation loss: 2.004685724935224

Epoch: 5| Step: 7
Training loss: 0.8600274920463562
Validation loss: 1.98595549983363

Epoch: 5| Step: 8
Training loss: 0.6320337057113647
Validation loss: 2.0067244934779342

Epoch: 5| Step: 9
Training loss: 0.8015447854995728
Validation loss: 1.999214336436282

Epoch: 5| Step: 10
Training loss: 0.8855867385864258
Validation loss: 1.9812287105027067

Epoch: 277| Step: 0
Training loss: 0.9105910062789917
Validation loss: 1.9768200843564925

Epoch: 5| Step: 1
Training loss: 0.7425894141197205
Validation loss: 1.9813773324412685

Epoch: 5| Step: 2
Training loss: 0.687389612197876
Validation loss: 1.9571514552639377

Epoch: 5| Step: 3
Training loss: 0.8483121991157532
Validation loss: 1.9694701215272308

Epoch: 5| Step: 4
Training loss: 1.2644925117492676
Validation loss: 1.9414919268700384

Epoch: 5| Step: 5
Training loss: 0.7034984827041626
Validation loss: 1.9523069166368054

Epoch: 5| Step: 6
Training loss: 0.707504391670227
Validation loss: 1.9349183279980895

Epoch: 5| Step: 7
Training loss: 0.8612275123596191
Validation loss: 1.9357415758153445

Epoch: 5| Step: 8
Training loss: 0.8873979449272156
Validation loss: 1.957077314776759

Epoch: 5| Step: 9
Training loss: 0.6538926362991333
Validation loss: 1.9592991413608674

Epoch: 5| Step: 10
Training loss: 0.538964033126831
Validation loss: 1.972091151821998

Epoch: 278| Step: 0
Training loss: 0.669369101524353
Validation loss: 1.9679569916058612

Epoch: 5| Step: 1
Training loss: 0.695799708366394
Validation loss: 1.9282056464943835

Epoch: 5| Step: 2
Training loss: 1.017333745956421
Validation loss: 1.9468244762830837

Epoch: 5| Step: 3
Training loss: 0.6510788202285767
Validation loss: 1.9344617935918993

Epoch: 5| Step: 4
Training loss: 0.7218183279037476
Validation loss: 1.9597241852873115

Epoch: 5| Step: 5
Training loss: 0.9520042538642883
Validation loss: 1.961822614874891

Epoch: 5| Step: 6
Training loss: 0.7976357936859131
Validation loss: 1.996996029730766

Epoch: 5| Step: 7
Training loss: 0.6530922651290894
Validation loss: 1.990451789671375

Epoch: 5| Step: 8
Training loss: 0.7174527645111084
Validation loss: 1.9504731726902786

Epoch: 5| Step: 9
Training loss: 1.2019293308258057
Validation loss: 1.8950772106006581

Epoch: 5| Step: 10
Training loss: 0.9682534337043762
Validation loss: 1.8683550973092355

Epoch: 279| Step: 0
Training loss: 1.1700761318206787
Validation loss: 1.877122655991585

Epoch: 5| Step: 1
Training loss: 0.49802613258361816
Validation loss: 1.8875516947879587

Epoch: 5| Step: 2
Training loss: 0.9091225862503052
Validation loss: 1.880834702522524

Epoch: 5| Step: 3
Training loss: 0.9293226003646851
Validation loss: 1.913310427819529

Epoch: 5| Step: 4
Training loss: 0.6418453454971313
Validation loss: 1.9155619093166885

Epoch: 5| Step: 5
Training loss: 0.532415509223938
Validation loss: 1.9623947528100782

Epoch: 5| Step: 6
Training loss: 0.4677228033542633
Validation loss: 1.9242405404326737

Epoch: 5| Step: 7
Training loss: 0.5897118449211121
Validation loss: 1.9191856051004061

Epoch: 5| Step: 8
Training loss: 1.1348257064819336
Validation loss: 1.9169176957940544

Epoch: 5| Step: 9
Training loss: 0.901934027671814
Validation loss: 1.931077641184612

Epoch: 5| Step: 10
Training loss: 1.0235530138015747
Validation loss: 1.9295261726584485

Epoch: 280| Step: 0
Training loss: 0.7743848562240601
Validation loss: 1.9079139488999561

Epoch: 5| Step: 1
Training loss: 0.6913881301879883
Validation loss: 1.950871414394789

Epoch: 5| Step: 2
Training loss: 0.5504462122917175
Validation loss: 1.9401743924745949

Epoch: 5| Step: 3
Training loss: 0.7400738596916199
Validation loss: 1.9429880265266664

Epoch: 5| Step: 4
Training loss: 0.8882810473442078
Validation loss: 1.930062860570928

Epoch: 5| Step: 5
Training loss: 0.6825225949287415
Validation loss: 1.9152077244174095

Epoch: 5| Step: 6
Training loss: 0.8305342793464661
Validation loss: 1.9182968934377034

Epoch: 5| Step: 7
Training loss: 0.7641048431396484
Validation loss: 1.9145451143223753

Epoch: 5| Step: 8
Training loss: 1.1381537914276123
Validation loss: 1.9261673355615267

Epoch: 5| Step: 9
Training loss: 0.457085520029068
Validation loss: 1.91681327742915

Epoch: 5| Step: 10
Training loss: 1.0575233697891235
Validation loss: 1.9069811926093152

Epoch: 281| Step: 0
Training loss: 0.887575626373291
Validation loss: 1.8971759260341685

Epoch: 5| Step: 1
Training loss: 0.7142436504364014
Validation loss: 1.906333629802991

Epoch: 5| Step: 2
Training loss: 0.8433252573013306
Validation loss: 1.9211892979119414

Epoch: 5| Step: 3
Training loss: 0.6226481795310974
Validation loss: 1.9405687098862023

Epoch: 5| Step: 4
Training loss: 0.9246352314949036
Validation loss: 1.961151401201884

Epoch: 5| Step: 5
Training loss: 0.9269423484802246
Validation loss: 1.9434634036915277

Epoch: 5| Step: 6
Training loss: 0.4867536425590515
Validation loss: 1.9477091066298946

Epoch: 5| Step: 7
Training loss: 0.5662220120429993
Validation loss: 1.949866683252396

Epoch: 5| Step: 8
Training loss: 1.2745850086212158
Validation loss: 1.9411794062583678

Epoch: 5| Step: 9
Training loss: 0.7840097546577454
Validation loss: 1.9749195678259737

Epoch: 5| Step: 10
Training loss: 0.5203148722648621
Validation loss: 1.9843766407300067

Epoch: 282| Step: 0
Training loss: 1.0861488580703735
Validation loss: 1.9844955193099154

Epoch: 5| Step: 1
Training loss: 0.30779778957366943
Validation loss: 1.991893663201281

Epoch: 5| Step: 2
Training loss: 0.5886806845664978
Validation loss: 1.964981602084252

Epoch: 5| Step: 3
Training loss: 0.9094704389572144
Validation loss: 1.9633155407444123

Epoch: 5| Step: 4
Training loss: 0.8024853467941284
Validation loss: 1.9574738574284378

Epoch: 5| Step: 5
Training loss: 0.9021221399307251
Validation loss: 1.927194490227648

Epoch: 5| Step: 6
Training loss: 0.9944339990615845
Validation loss: 1.8756094735155824

Epoch: 5| Step: 7
Training loss: 0.7642803192138672
Validation loss: 1.8544191903965448

Epoch: 5| Step: 8
Training loss: 0.8699989318847656
Validation loss: 1.8492335529737576

Epoch: 5| Step: 9
Training loss: 0.8501022458076477
Validation loss: 1.8702268177463162

Epoch: 5| Step: 10
Training loss: 0.5502321720123291
Validation loss: 1.8713940382003784

Epoch: 283| Step: 0
Training loss: 0.8809801340103149
Validation loss: 1.8788613939798007

Epoch: 5| Step: 1
Training loss: 0.4219805598258972
Validation loss: 1.9075898496053552

Epoch: 5| Step: 2
Training loss: 0.6391516923904419
Validation loss: 1.9339351038778982

Epoch: 5| Step: 3
Training loss: 0.6613540649414062
Validation loss: 1.9528275330861409

Epoch: 5| Step: 4
Training loss: 0.7015920281410217
Validation loss: 1.9504059963328864

Epoch: 5| Step: 5
Training loss: 1.1745277643203735
Validation loss: 1.932792088036896

Epoch: 5| Step: 6
Training loss: 0.736442506313324
Validation loss: 1.9403275930753319

Epoch: 5| Step: 7
Training loss: 0.47990602254867554
Validation loss: 1.937938477403374

Epoch: 5| Step: 8
Training loss: 1.2051770687103271
Validation loss: 1.9091978175665743

Epoch: 5| Step: 9
Training loss: 0.9400691986083984
Validation loss: 1.8813108923614665

Epoch: 5| Step: 10
Training loss: 0.6978099942207336
Validation loss: 1.8697101864763486

Epoch: 284| Step: 0
Training loss: 1.0284879207611084
Validation loss: 1.8656751442981023

Epoch: 5| Step: 1
Training loss: 0.6958426833152771
Validation loss: 1.8467944745094544

Epoch: 5| Step: 2
Training loss: 0.7688354253768921
Validation loss: 1.8825802162129393

Epoch: 5| Step: 3
Training loss: 0.7426307797431946
Validation loss: 1.8895043955054334

Epoch: 5| Step: 4
Training loss: 0.7581267356872559
Validation loss: 1.9186204710314352

Epoch: 5| Step: 5
Training loss: 0.7045896649360657
Validation loss: 1.934297397572507

Epoch: 5| Step: 6
Training loss: 0.9171993136405945
Validation loss: 1.9341003305168563

Epoch: 5| Step: 7
Training loss: 0.6281148791313171
Validation loss: 1.9139990370760682

Epoch: 5| Step: 8
Training loss: 0.5443616509437561
Validation loss: 1.8879988590876262

Epoch: 5| Step: 9
Training loss: 0.9540145993232727
Validation loss: 1.88812679372808

Epoch: 5| Step: 10
Training loss: 0.6376069784164429
Validation loss: 1.8811165607103737

Epoch: 285| Step: 0
Training loss: 0.7883985638618469
Validation loss: 1.8671045585345196

Epoch: 5| Step: 1
Training loss: 0.557350754737854
Validation loss: 1.8929275197367514

Epoch: 5| Step: 2
Training loss: 0.6892243027687073
Validation loss: 1.9169377460274646

Epoch: 5| Step: 3
Training loss: 0.8198461532592773
Validation loss: 1.94077044404963

Epoch: 5| Step: 4
Training loss: 0.5733210444450378
Validation loss: 1.9530434108549548

Epoch: 5| Step: 5
Training loss: 0.8433377146720886
Validation loss: 1.986329004328738

Epoch: 5| Step: 6
Training loss: 0.7534031867980957
Validation loss: 1.941750266218698

Epoch: 5| Step: 7
Training loss: 1.1368907690048218
Validation loss: 1.9494126432685441

Epoch: 5| Step: 8
Training loss: 0.8985127210617065
Validation loss: 1.9093736961323728

Epoch: 5| Step: 9
Training loss: 0.6565274000167847
Validation loss: 1.91809416842717

Epoch: 5| Step: 10
Training loss: 0.6510202884674072
Validation loss: 1.8938282305194485

Epoch: 286| Step: 0
Training loss: 0.39606449007987976
Validation loss: 1.889657538424256

Epoch: 5| Step: 1
Training loss: 0.8886643648147583
Validation loss: 1.8868995622922016

Epoch: 5| Step: 2
Training loss: 0.4763457775115967
Validation loss: 1.8866419971630137

Epoch: 5| Step: 3
Training loss: 0.7067906260490417
Validation loss: 1.8641065013024114

Epoch: 5| Step: 4
Training loss: 0.9096136093139648
Validation loss: 1.881162481923257

Epoch: 5| Step: 5
Training loss: 0.7873775362968445
Validation loss: 1.862444390532791

Epoch: 5| Step: 6
Training loss: 0.611724853515625
Validation loss: 1.898671664217467

Epoch: 5| Step: 7
Training loss: 0.9234762191772461
Validation loss: 1.9046197578471193

Epoch: 5| Step: 8
Training loss: 0.666114091873169
Validation loss: 1.9119820902424474

Epoch: 5| Step: 9
Training loss: 1.1022372245788574
Validation loss: 1.915112328785722

Epoch: 5| Step: 10
Training loss: 0.672050416469574
Validation loss: 1.927433326680173

Epoch: 287| Step: 0
Training loss: 1.059753656387329
Validation loss: 1.9373455560335548

Epoch: 5| Step: 1
Training loss: 0.4302801489830017
Validation loss: 1.9041193544223745

Epoch: 5| Step: 2
Training loss: 0.9669997096061707
Validation loss: 1.9257650759912306

Epoch: 5| Step: 3
Training loss: 0.9823182821273804
Validation loss: 1.9163482176360263

Epoch: 5| Step: 4
Training loss: 0.6515520811080933
Validation loss: 1.9251270166007421

Epoch: 5| Step: 5
Training loss: 0.41139641404151917
Validation loss: 1.926473382980593

Epoch: 5| Step: 6
Training loss: 0.4445621073246002
Validation loss: 1.9195049988326205

Epoch: 5| Step: 7
Training loss: 0.7758803367614746
Validation loss: 1.910407184272684

Epoch: 5| Step: 8
Training loss: 1.000670075416565
Validation loss: 1.9455980331667009

Epoch: 5| Step: 9
Training loss: 0.6863549947738647
Validation loss: 1.9390454369206582

Epoch: 5| Step: 10
Training loss: 0.6765355467796326
Validation loss: 1.9392214718685354

Epoch: 288| Step: 0
Training loss: 0.6194137930870056
Validation loss: 1.9441107857611872

Epoch: 5| Step: 1
Training loss: 0.542608380317688
Validation loss: 1.8932975428078764

Epoch: 5| Step: 2
Training loss: 0.8462419509887695
Validation loss: 1.893643690693763

Epoch: 5| Step: 3
Training loss: 0.6280993819236755
Validation loss: 1.8723034012702204

Epoch: 5| Step: 4
Training loss: 0.879298985004425
Validation loss: 1.8803948433168474

Epoch: 5| Step: 5
Training loss: 0.5605557560920715
Validation loss: 1.8749868344235163

Epoch: 5| Step: 6
Training loss: 0.8757947683334351
Validation loss: 1.906018263550215

Epoch: 5| Step: 7
Training loss: 0.9063129425048828
Validation loss: 1.8947577361137635

Epoch: 5| Step: 8
Training loss: 0.6173217296600342
Validation loss: 1.907157390348373

Epoch: 5| Step: 9
Training loss: 0.9050736427307129
Validation loss: 1.9089102078509588

Epoch: 5| Step: 10
Training loss: 0.5595009922981262
Validation loss: 1.910884670031968

Epoch: 289| Step: 0
Training loss: 0.5102282166481018
Validation loss: 1.9016871875332249

Epoch: 5| Step: 1
Training loss: 0.7867423295974731
Validation loss: 1.9238177525099887

Epoch: 5| Step: 2
Training loss: 0.8266950845718384
Validation loss: 1.9245900748878397

Epoch: 5| Step: 3
Training loss: 0.5353876352310181
Validation loss: 1.925278022725095

Epoch: 5| Step: 4
Training loss: 0.5193849802017212
Validation loss: 1.8832797952877578

Epoch: 5| Step: 5
Training loss: 0.572018027305603
Validation loss: 1.8906397819519043

Epoch: 5| Step: 6
Training loss: 0.5028215646743774
Validation loss: 1.9159436405345958

Epoch: 5| Step: 7
Training loss: 1.0022227764129639
Validation loss: 1.9046315172667145

Epoch: 5| Step: 8
Training loss: 0.6590168476104736
Validation loss: 1.9405990351912796

Epoch: 5| Step: 9
Training loss: 0.8187887072563171
Validation loss: 1.9098070039544055

Epoch: 5| Step: 10
Training loss: 1.1561700105667114
Validation loss: 1.9144937505004227

Epoch: 290| Step: 0
Training loss: 0.8815048336982727
Validation loss: 1.8786958879040134

Epoch: 5| Step: 1
Training loss: 0.6446572542190552
Validation loss: 1.865370217189994

Epoch: 5| Step: 2
Training loss: 0.8044220209121704
Validation loss: 1.8359642490263908

Epoch: 5| Step: 3
Training loss: 0.8496195077896118
Validation loss: 1.8694518099548996

Epoch: 5| Step: 4
Training loss: 0.8577789068222046
Validation loss: 1.9042951624880555

Epoch: 5| Step: 5
Training loss: 0.3798266053199768
Validation loss: 1.8836410763443157

Epoch: 5| Step: 6
Training loss: 0.5622661113739014
Validation loss: 1.899420610038183

Epoch: 5| Step: 7
Training loss: 0.7424966096878052
Validation loss: 1.9092515002014816

Epoch: 5| Step: 8
Training loss: 0.6416788101196289
Validation loss: 1.9530241732956262

Epoch: 5| Step: 9
Training loss: 0.8410911560058594
Validation loss: 1.93314403359608

Epoch: 5| Step: 10
Training loss: 0.7708367705345154
Validation loss: 1.9049424009938394

Epoch: 291| Step: 0
Training loss: 0.6444598436355591
Validation loss: 1.8931729716639365

Epoch: 5| Step: 1
Training loss: 0.8894723057746887
Validation loss: 1.8847386670368973

Epoch: 5| Step: 2
Training loss: 0.7899028658866882
Validation loss: 1.8832845213592693

Epoch: 5| Step: 3
Training loss: 0.571955144405365
Validation loss: 1.8891719502787436

Epoch: 5| Step: 4
Training loss: 0.7764589190483093
Validation loss: 1.9146757459127774

Epoch: 5| Step: 5
Training loss: 0.3258422911167145
Validation loss: 1.8624452307660093

Epoch: 5| Step: 6
Training loss: 0.6262990832328796
Validation loss: 1.8663349113156718

Epoch: 5| Step: 7
Training loss: 0.7290971875190735
Validation loss: 1.8643244069109681

Epoch: 5| Step: 8
Training loss: 0.8394975662231445
Validation loss: 1.8754275921852357

Epoch: 5| Step: 9
Training loss: 0.6938939690589905
Validation loss: 1.8443109245710476

Epoch: 5| Step: 10
Training loss: 0.8181954622268677
Validation loss: 1.9146750793662122

Epoch: 292| Step: 0
Training loss: 0.6723923683166504
Validation loss: 1.9443407186897852

Epoch: 5| Step: 1
Training loss: 0.5954432487487793
Validation loss: 1.9732637482304727

Epoch: 5| Step: 2
Training loss: 0.4851962625980377
Validation loss: 1.9500888163043606

Epoch: 5| Step: 3
Training loss: 0.7761351466178894
Validation loss: 1.8984469867521716

Epoch: 5| Step: 4
Training loss: 0.8663028478622437
Validation loss: 1.9154086971795687

Epoch: 5| Step: 5
Training loss: 0.6687151193618774
Validation loss: 1.8900135819629957

Epoch: 5| Step: 6
Training loss: 0.6741539835929871
Validation loss: 1.8909886716514506

Epoch: 5| Step: 7
Training loss: 0.6040727496147156
Validation loss: 1.888583544761904

Epoch: 5| Step: 8
Training loss: 0.8396433591842651
Validation loss: 1.8853353326038649

Epoch: 5| Step: 9
Training loss: 0.7620395421981812
Validation loss: 1.8831722736358643

Epoch: 5| Step: 10
Training loss: 0.8770962953567505
Validation loss: 1.8640047324601041

Epoch: 293| Step: 0
Training loss: 0.5875541567802429
Validation loss: 1.908230589282128

Epoch: 5| Step: 1
Training loss: 1.005598783493042
Validation loss: 1.8795347700836837

Epoch: 5| Step: 2
Training loss: 0.6260586380958557
Validation loss: 1.9049917779942995

Epoch: 5| Step: 3
Training loss: 0.8542052507400513
Validation loss: 1.8960737438612087

Epoch: 5| Step: 4
Training loss: 0.46848106384277344
Validation loss: 1.876968563243907

Epoch: 5| Step: 5
Training loss: 0.6054349541664124
Validation loss: 1.8925521527567217

Epoch: 5| Step: 6
Training loss: 0.6785179376602173
Validation loss: 1.8962151594059442

Epoch: 5| Step: 7
Training loss: 0.32940050959587097
Validation loss: 1.8677847949407433

Epoch: 5| Step: 8
Training loss: 0.6863856315612793
Validation loss: 1.8316015005111694

Epoch: 5| Step: 9
Training loss: 0.8466852307319641
Validation loss: 1.8521093450566775

Epoch: 5| Step: 10
Training loss: 0.8570614457130432
Validation loss: 1.8415428566676315

Epoch: 294| Step: 0
Training loss: 0.6205046772956848
Validation loss: 1.872597752078887

Epoch: 5| Step: 1
Training loss: 0.1983986496925354
Validation loss: 1.8602477517179263

Epoch: 5| Step: 2
Training loss: 0.7448241114616394
Validation loss: 1.8601911311508508

Epoch: 5| Step: 3
Training loss: 0.971649169921875
Validation loss: 1.8573342548903597

Epoch: 5| Step: 4
Training loss: 0.4977746605873108
Validation loss: 1.8644617513943744

Epoch: 5| Step: 5
Training loss: 0.49853652715682983
Validation loss: 1.8646381119246125

Epoch: 5| Step: 6
Training loss: 0.7821375131607056
Validation loss: 1.880037526930532

Epoch: 5| Step: 7
Training loss: 0.91264808177948
Validation loss: 1.9067833077523015

Epoch: 5| Step: 8
Training loss: 0.8512323498725891
Validation loss: 1.901155544865516

Epoch: 5| Step: 9
Training loss: 0.8468383550643921
Validation loss: 1.9074516886024064

Epoch: 5| Step: 10
Training loss: 0.5407969355583191
Validation loss: 1.8993329309648084

Epoch: 295| Step: 0
Training loss: 0.5681949853897095
Validation loss: 1.9015983637943064

Epoch: 5| Step: 1
Training loss: 0.6463630199432373
Validation loss: 1.8945418173266995

Epoch: 5| Step: 2
Training loss: 0.49217528104782104
Validation loss: 1.9081123810942455

Epoch: 5| Step: 3
Training loss: 0.6138988733291626
Validation loss: 1.887871729430332

Epoch: 5| Step: 4
Training loss: 0.5271917581558228
Validation loss: 1.919910006625678

Epoch: 5| Step: 5
Training loss: 1.0265957117080688
Validation loss: 1.8934732611461351

Epoch: 5| Step: 6
Training loss: 0.9387643933296204
Validation loss: 1.8841244187406314

Epoch: 5| Step: 7
Training loss: 0.915174126625061
Validation loss: 1.8449933605809365

Epoch: 5| Step: 8
Training loss: 0.5657954216003418
Validation loss: 1.8554273632264906

Epoch: 5| Step: 9
Training loss: 0.38305526971817017
Validation loss: 1.8381173405596005

Epoch: 5| Step: 10
Training loss: 0.7842254638671875
Validation loss: 1.8688071056078839

Epoch: 296| Step: 0
Training loss: 0.3350560963153839
Validation loss: 1.8634162077339746

Epoch: 5| Step: 1
Training loss: 0.6755517721176147
Validation loss: 1.880862574423513

Epoch: 5| Step: 2
Training loss: 0.6618382334709167
Validation loss: 1.8714763605466453

Epoch: 5| Step: 3
Training loss: 0.9203742742538452
Validation loss: 1.8828107118606567

Epoch: 5| Step: 4
Training loss: 0.6578436493873596
Validation loss: 1.879728018596608

Epoch: 5| Step: 5
Training loss: 0.735841691493988
Validation loss: 1.8920819990096553

Epoch: 5| Step: 6
Training loss: 0.7603006958961487
Validation loss: 1.8887889154495732

Epoch: 5| Step: 7
Training loss: 0.6035031080245972
Validation loss: 1.899549102270475

Epoch: 5| Step: 8
Training loss: 0.8514977693557739
Validation loss: 1.8980170654994186

Epoch: 5| Step: 9
Training loss: 0.5020836591720581
Validation loss: 1.8909281812688357

Epoch: 5| Step: 10
Training loss: 0.5565878748893738
Validation loss: 1.878238780524141

Epoch: 297| Step: 0
Training loss: 0.426801860332489
Validation loss: 1.839160821771109

Epoch: 5| Step: 1
Training loss: 0.9535603523254395
Validation loss: 1.857767774212745

Epoch: 5| Step: 2
Training loss: 0.7911466360092163
Validation loss: 1.8755163505513182

Epoch: 5| Step: 3
Training loss: 0.8728861808776855
Validation loss: 1.8704508094377414

Epoch: 5| Step: 4
Training loss: 1.1050922870635986
Validation loss: 1.895854401332076

Epoch: 5| Step: 5
Training loss: 0.45938771963119507
Validation loss: 1.900127185288296

Epoch: 5| Step: 6
Training loss: 0.5191365480422974
Validation loss: 1.8753195065324024

Epoch: 5| Step: 7
Training loss: 0.3521413207054138
Validation loss: 1.8743040356584775

Epoch: 5| Step: 8
Training loss: 0.7188579440116882
Validation loss: 1.859828156809653

Epoch: 5| Step: 9
Training loss: 0.5681837797164917
Validation loss: 1.8257769384691793

Epoch: 5| Step: 10
Training loss: 0.595703661441803
Validation loss: 1.8237732289939799

Epoch: 298| Step: 0
Training loss: 0.4919320046901703
Validation loss: 1.8345095444751043

Epoch: 5| Step: 1
Training loss: 0.6362214684486389
Validation loss: 1.8578256778819586

Epoch: 5| Step: 2
Training loss: 0.675713837146759
Validation loss: 1.8736614565695486

Epoch: 5| Step: 3
Training loss: 0.8425015211105347
Validation loss: 1.8856169639095184

Epoch: 5| Step: 4
Training loss: 0.8824030160903931
Validation loss: 1.8826212947086622

Epoch: 5| Step: 5
Training loss: 0.6643728613853455
Validation loss: 1.905733810958042

Epoch: 5| Step: 6
Training loss: 0.5550093054771423
Validation loss: 1.8767023830003635

Epoch: 5| Step: 7
Training loss: 0.616538405418396
Validation loss: 1.8385002087521296

Epoch: 5| Step: 8
Training loss: 0.49723848700523376
Validation loss: 1.8465728964856876

Epoch: 5| Step: 9
Training loss: 0.8173280954360962
Validation loss: 1.8480959348781134

Epoch: 5| Step: 10
Training loss: 0.776343822479248
Validation loss: 1.8495072780116912

Epoch: 299| Step: 0
Training loss: 0.6221397519111633
Validation loss: 1.8593635905173518

Epoch: 5| Step: 1
Training loss: 0.545202374458313
Validation loss: 1.8834108088606147

Epoch: 5| Step: 2
Training loss: 0.797288715839386
Validation loss: 1.9012107028756091

Epoch: 5| Step: 3
Training loss: 0.7579678297042847
Validation loss: 1.9229206474878455

Epoch: 5| Step: 4
Training loss: 0.6292422413825989
Validation loss: 1.892030886424485

Epoch: 5| Step: 5
Training loss: 0.6941514015197754
Validation loss: 1.8861620810724073

Epoch: 5| Step: 6
Training loss: 0.6394075155258179
Validation loss: 1.8807296496565624

Epoch: 5| Step: 7
Training loss: 0.5348539352416992
Validation loss: 1.8777837785341407

Epoch: 5| Step: 8
Training loss: 0.9910198450088501
Validation loss: 1.8923025079952773

Epoch: 5| Step: 9
Training loss: 0.5613773465156555
Validation loss: 1.8970784551353865

Epoch: 5| Step: 10
Training loss: 0.6668283939361572
Validation loss: 1.907143578734449

Epoch: 300| Step: 0
Training loss: 0.8516518473625183
Validation loss: 1.9297574925166305

Epoch: 5| Step: 1
Training loss: 0.5996717214584351
Validation loss: 1.9548731901312386

Epoch: 5| Step: 2
Training loss: 0.924298107624054
Validation loss: 1.9633354525412283

Epoch: 5| Step: 3
Training loss: 0.48224449157714844
Validation loss: 1.8744791964048981

Epoch: 5| Step: 4
Training loss: 0.5188909769058228
Validation loss: 1.8722662579628728

Epoch: 5| Step: 5
Training loss: 0.6250430345535278
Validation loss: 1.8312707870237288

Epoch: 5| Step: 6
Training loss: 0.7348505258560181
Validation loss: 1.8028874986915178

Epoch: 5| Step: 7
Training loss: 0.3996839225292206
Validation loss: 1.79491009507128

Epoch: 5| Step: 8
Training loss: 1.058423399925232
Validation loss: 1.837059223523704

Epoch: 5| Step: 9
Training loss: 0.8180174827575684
Validation loss: 1.8419544748080674

Epoch: 5| Step: 10
Training loss: 0.5103139877319336
Validation loss: 1.8554099593111264

Epoch: 301| Step: 0
Training loss: 0.614742636680603
Validation loss: 1.8849097451856058

Epoch: 5| Step: 1
Training loss: 0.40167760848999023
Validation loss: 1.877220521691025

Epoch: 5| Step: 2
Training loss: 0.4706061780452728
Validation loss: 1.8504558378650295

Epoch: 5| Step: 3
Training loss: 0.7607136368751526
Validation loss: 1.8194567234285417

Epoch: 5| Step: 4
Training loss: 0.704247772693634
Validation loss: 1.7962000139297978

Epoch: 5| Step: 5
Training loss: 0.6139447689056396
Validation loss: 1.7910141470611736

Epoch: 5| Step: 6
Training loss: 0.6048544049263
Validation loss: 1.7803508594471922

Epoch: 5| Step: 7
Training loss: 0.8836401700973511
Validation loss: 1.7974322380558136

Epoch: 5| Step: 8
Training loss: 0.5978140830993652
Validation loss: 1.826237932328255

Epoch: 5| Step: 9
Training loss: 0.462245374917984
Validation loss: 1.8480554037196661

Epoch: 5| Step: 10
Training loss: 1.032608985900879
Validation loss: 1.8593157927195232

Epoch: 302| Step: 0
Training loss: 0.44628602266311646
Validation loss: 1.8520133520967217

Epoch: 5| Step: 1
Training loss: 0.46604281663894653
Validation loss: 1.8769525456172165

Epoch: 5| Step: 2
Training loss: 0.7824836373329163
Validation loss: 1.8834181293364494

Epoch: 5| Step: 3
Training loss: 0.6113021373748779
Validation loss: 1.8572885887597197

Epoch: 5| Step: 4
Training loss: 0.8275707960128784
Validation loss: 1.8758811886592577

Epoch: 5| Step: 5
Training loss: 0.6171387434005737
Validation loss: 1.846926712220715

Epoch: 5| Step: 6
Training loss: 0.4944326877593994
Validation loss: 1.8713724626007902

Epoch: 5| Step: 7
Training loss: 0.45883864164352417
Validation loss: 1.8393294349793465

Epoch: 5| Step: 8
Training loss: 0.708895206451416
Validation loss: 1.8338383731021677

Epoch: 5| Step: 9
Training loss: 0.7217139005661011
Validation loss: 1.8321485275863318

Epoch: 5| Step: 10
Training loss: 0.7272379398345947
Validation loss: 1.8373958474846297

Epoch: 303| Step: 0
Training loss: 0.4947511553764343
Validation loss: 1.833239019557994

Epoch: 5| Step: 1
Training loss: 0.49261027574539185
Validation loss: 1.856221406690536

Epoch: 5| Step: 2
Training loss: 0.36373472213745117
Validation loss: 1.8928673792910833

Epoch: 5| Step: 3
Training loss: 0.5919990539550781
Validation loss: 1.8951403364058463

Epoch: 5| Step: 4
Training loss: 0.883928120136261
Validation loss: 1.8531863522785965

Epoch: 5| Step: 5
Training loss: 0.6884698867797852
Validation loss: 1.83730371152201

Epoch: 5| Step: 6
Training loss: 0.6847224831581116
Validation loss: 1.8424868673406622

Epoch: 5| Step: 7
Training loss: 1.0837457180023193
Validation loss: 1.831814851812137

Epoch: 5| Step: 8
Training loss: 0.6234586834907532
Validation loss: 1.8376445949718516

Epoch: 5| Step: 9
Training loss: 0.4241517186164856
Validation loss: 1.8128794970050934

Epoch: 5| Step: 10
Training loss: 0.7687928676605225
Validation loss: 1.8353469820432766

Epoch: 304| Step: 0
Training loss: 0.6361076235771179
Validation loss: 1.8522202814778974

Epoch: 5| Step: 1
Training loss: 0.6578296422958374
Validation loss: 1.868644206754623

Epoch: 5| Step: 2
Training loss: 0.7466092109680176
Validation loss: 1.8984392073846632

Epoch: 5| Step: 3
Training loss: 0.7357913255691528
Validation loss: 1.8822030585299256

Epoch: 5| Step: 4
Training loss: 0.7192321419715881
Validation loss: 1.8501166464180074

Epoch: 5| Step: 5
Training loss: 0.6329280734062195
Validation loss: 1.8178841503717567

Epoch: 5| Step: 6
Training loss: 0.5185930728912354
Validation loss: 1.8083889753587785

Epoch: 5| Step: 7
Training loss: 0.6408055424690247
Validation loss: 1.8192004106378044

Epoch: 5| Step: 8
Training loss: 0.771867573261261
Validation loss: 1.7939259108676706

Epoch: 5| Step: 9
Training loss: 0.5696485042572021
Validation loss: 1.8412349467636437

Epoch: 5| Step: 10
Training loss: 0.6057716012001038
Validation loss: 1.8297690691486481

Epoch: 305| Step: 0
Training loss: 0.8133752942085266
Validation loss: 1.8744974200443556

Epoch: 5| Step: 1
Training loss: 0.6434966325759888
Validation loss: 1.8535881298844532

Epoch: 5| Step: 2
Training loss: 0.8902694582939148
Validation loss: 1.861523235997846

Epoch: 5| Step: 3
Training loss: 0.4961569309234619
Validation loss: 1.8419402722389466

Epoch: 5| Step: 4
Training loss: 0.3970811665058136
Validation loss: 1.8316280739281767

Epoch: 5| Step: 5
Training loss: 0.6294886469841003
Validation loss: 1.8011045443114413

Epoch: 5| Step: 6
Training loss: 0.7397245764732361
Validation loss: 1.800065718671327

Epoch: 5| Step: 7
Training loss: 0.5087223052978516
Validation loss: 1.8056856175904632

Epoch: 5| Step: 8
Training loss: 0.533318042755127
Validation loss: 1.8308258902642034

Epoch: 5| Step: 9
Training loss: 0.7841859459877014
Validation loss: 1.817331765287666

Epoch: 5| Step: 10
Training loss: 0.3712605834007263
Validation loss: 1.8271578832339215

Epoch: 306| Step: 0
Training loss: 0.5252924561500549
Validation loss: 1.8234797023957776

Epoch: 5| Step: 1
Training loss: 0.34633225202560425
Validation loss: 1.8335674103870188

Epoch: 5| Step: 2
Training loss: 0.888667106628418
Validation loss: 1.8338995082404024

Epoch: 5| Step: 3
Training loss: 0.4912753105163574
Validation loss: 1.850008487701416

Epoch: 5| Step: 4
Training loss: 0.5855764746665955
Validation loss: 1.8215199209028674

Epoch: 5| Step: 5
Training loss: 0.48434391617774963
Validation loss: 1.8288102201236192

Epoch: 5| Step: 6
Training loss: 0.8243287801742554
Validation loss: 1.8348213703401628

Epoch: 5| Step: 7
Training loss: 0.6290684938430786
Validation loss: 1.8190341482880295

Epoch: 5| Step: 8
Training loss: 0.5005384683609009
Validation loss: 1.7897430696795065

Epoch: 5| Step: 9
Training loss: 0.67274010181427
Validation loss: 1.7998031954611502

Epoch: 5| Step: 10
Training loss: 0.8483806848526001
Validation loss: 1.7682031610960602

Epoch: 307| Step: 0
Training loss: 0.5384706258773804
Validation loss: 1.793090831848883

Epoch: 5| Step: 1
Training loss: 0.42411479353904724
Validation loss: 1.8164497344724593

Epoch: 5| Step: 2
Training loss: 0.495889276266098
Validation loss: 1.8202244389441706

Epoch: 5| Step: 3
Training loss: 0.8504811525344849
Validation loss: 1.8272549593320457

Epoch: 5| Step: 4
Training loss: 0.5946260690689087
Validation loss: 1.8235998256232149

Epoch: 5| Step: 5
Training loss: 0.6810044646263123
Validation loss: 1.832377524786098

Epoch: 5| Step: 6
Training loss: 0.7390373945236206
Validation loss: 1.823812666759696

Epoch: 5| Step: 7
Training loss: 0.5085110664367676
Validation loss: 1.81361969055668

Epoch: 5| Step: 8
Training loss: 0.5325866341590881
Validation loss: 1.8127282845076693

Epoch: 5| Step: 9
Training loss: 0.721040666103363
Validation loss: 1.7972179100077639

Epoch: 5| Step: 10
Training loss: 0.4373164474964142
Validation loss: 1.7928421189708095

Epoch: 308| Step: 0
Training loss: 0.3684302568435669
Validation loss: 1.8061405279303109

Epoch: 5| Step: 1
Training loss: 0.7255185842514038
Validation loss: 1.7819189281873806

Epoch: 5| Step: 2
Training loss: 0.5588035583496094
Validation loss: 1.764958982826561

Epoch: 5| Step: 3
Training loss: 0.3981456160545349
Validation loss: 1.7600105385626517

Epoch: 5| Step: 4
Training loss: 0.6680330038070679
Validation loss: 1.7780046898831603

Epoch: 5| Step: 5
Training loss: 0.4041507840156555
Validation loss: 1.7768144351179882

Epoch: 5| Step: 6
Training loss: 0.49861055612564087
Validation loss: 1.8256836450228127

Epoch: 5| Step: 7
Training loss: 0.707417368888855
Validation loss: 1.8518338267521193

Epoch: 5| Step: 8
Training loss: 0.9182950854301453
Validation loss: 1.859277500901171

Epoch: 5| Step: 9
Training loss: 0.5390292406082153
Validation loss: 1.8577106755266908

Epoch: 5| Step: 10
Training loss: 0.7349674105644226
Validation loss: 1.7906221702534666

Epoch: 309| Step: 0
Training loss: 0.6586565375328064
Validation loss: 1.805694228859358

Epoch: 5| Step: 1
Training loss: 0.9367332458496094
Validation loss: 1.7875768740971882

Epoch: 5| Step: 2
Training loss: 0.5403521656990051
Validation loss: 1.7999024865447835

Epoch: 5| Step: 3
Training loss: 0.6867319345474243
Validation loss: 1.8269243291629258

Epoch: 5| Step: 4
Training loss: 0.7106353640556335
Validation loss: 1.7929760538121706

Epoch: 5| Step: 5
Training loss: 0.7189221382141113
Validation loss: 1.8172586182112336

Epoch: 5| Step: 6
Training loss: 0.30735841393470764
Validation loss: 1.784495698508396

Epoch: 5| Step: 7
Training loss: 0.3310611844062805
Validation loss: 1.827902469583737

Epoch: 5| Step: 8
Training loss: 0.4504333436489105
Validation loss: 1.8619222269263318

Epoch: 5| Step: 9
Training loss: 0.6336767077445984
Validation loss: 1.855414375182121

Epoch: 5| Step: 10
Training loss: 0.5252711176872253
Validation loss: 1.8508077359968615

Epoch: 310| Step: 0
Training loss: 0.3590577244758606
Validation loss: 1.8404647547711608

Epoch: 5| Step: 1
Training loss: 0.44517454504966736
Validation loss: 1.7886327748657556

Epoch: 5| Step: 2
Training loss: 0.4568549692630768
Validation loss: 1.7722723753221574

Epoch: 5| Step: 3
Training loss: 1.101813554763794
Validation loss: 1.7745920470965806

Epoch: 5| Step: 4
Training loss: 0.6859903931617737
Validation loss: 1.7582485419447704

Epoch: 5| Step: 5
Training loss: 0.60572749376297
Validation loss: 1.7655714942562966

Epoch: 5| Step: 6
Training loss: 0.621780276298523
Validation loss: 1.7697459331122778

Epoch: 5| Step: 7
Training loss: 0.5415664911270142
Validation loss: 1.7950746910546416

Epoch: 5| Step: 8
Training loss: 0.6375500559806824
Validation loss: 1.7889902027704383

Epoch: 5| Step: 9
Training loss: 0.6854087114334106
Validation loss: 1.8274891889223488

Epoch: 5| Step: 10
Training loss: 0.3224469721317291
Validation loss: 1.8366736468448435

Epoch: 311| Step: 0
Training loss: 0.4016540050506592
Validation loss: 1.8174007361935032

Epoch: 5| Step: 1
Training loss: 0.5497118234634399
Validation loss: 1.8223954221253753

Epoch: 5| Step: 2
Training loss: 0.3586771488189697
Validation loss: 1.8444155621272262

Epoch: 5| Step: 3
Training loss: 0.7058706283569336
Validation loss: 1.8583280219826648

Epoch: 5| Step: 4
Training loss: 0.7931942343711853
Validation loss: 1.8416381420627717

Epoch: 5| Step: 5
Training loss: 0.7624761462211609
Validation loss: 1.8512511125174902

Epoch: 5| Step: 6
Training loss: 0.7661565542221069
Validation loss: 1.8521027411184003

Epoch: 5| Step: 7
Training loss: 0.4526727795600891
Validation loss: 1.8521114844147877

Epoch: 5| Step: 8
Training loss: 0.5370098948478699
Validation loss: 1.8019255450976792

Epoch: 5| Step: 9
Training loss: 0.46088171005249023
Validation loss: 1.8228623200488347

Epoch: 5| Step: 10
Training loss: 0.6078166961669922
Validation loss: 1.832937507219212

Epoch: 312| Step: 0
Training loss: 0.4962102770805359
Validation loss: 1.816337534176406

Epoch: 5| Step: 1
Training loss: 0.7138466238975525
Validation loss: 1.8578386306762695

Epoch: 5| Step: 2
Training loss: 0.5860342979431152
Validation loss: 1.8392282109106741

Epoch: 5| Step: 3
Training loss: 0.16252844035625458
Validation loss: 1.8595417084232453

Epoch: 5| Step: 4
Training loss: 0.571619987487793
Validation loss: 1.8745791604441981

Epoch: 5| Step: 5
Training loss: 0.48344817757606506
Validation loss: 1.881195818224261

Epoch: 5| Step: 6
Training loss: 0.8311666250228882
Validation loss: 1.8619107225889802

Epoch: 5| Step: 7
Training loss: 0.5753210783004761
Validation loss: 1.8864230391799763

Epoch: 5| Step: 8
Training loss: 0.5610510110855103
Validation loss: 1.8428970741969284

Epoch: 5| Step: 9
Training loss: 0.7244536280632019
Validation loss: 1.8270820507439234

Epoch: 5| Step: 10
Training loss: 0.7093941569328308
Validation loss: 1.8063430875860236

Epoch: 313| Step: 0
Training loss: 0.48738041520118713
Validation loss: 1.8060424571396203

Epoch: 5| Step: 1
Training loss: 0.7314128875732422
Validation loss: 1.8048175034984466

Epoch: 5| Step: 2
Training loss: 0.8470236659049988
Validation loss: 1.7936424670680877

Epoch: 5| Step: 3
Training loss: 0.25789791345596313
Validation loss: 1.818598097370517

Epoch: 5| Step: 4
Training loss: 0.5108237266540527
Validation loss: 1.824786546409771

Epoch: 5| Step: 5
Training loss: 0.4497241973876953
Validation loss: 1.8049200029783352

Epoch: 5| Step: 6
Training loss: 0.6627646684646606
Validation loss: 1.812652616090672

Epoch: 5| Step: 7
Training loss: 0.8359854817390442
Validation loss: 1.8453707348915838

Epoch: 5| Step: 8
Training loss: 0.7597828507423401
Validation loss: 1.8522905906041462

Epoch: 5| Step: 9
Training loss: 0.4171707034111023
Validation loss: 1.8683226044460008

Epoch: 5| Step: 10
Training loss: 0.4197109341621399
Validation loss: 1.884616494178772

Epoch: 314| Step: 0
Training loss: 0.4414433538913727
Validation loss: 1.857020132003292

Epoch: 5| Step: 1
Training loss: 0.7960039377212524
Validation loss: 1.8522886050644742

Epoch: 5| Step: 2
Training loss: 0.7067908644676208
Validation loss: 1.8517708598926503

Epoch: 5| Step: 3
Training loss: 0.5263530611991882
Validation loss: 1.831912225292575

Epoch: 5| Step: 4
Training loss: 0.5464344024658203
Validation loss: 1.8039709701332995

Epoch: 5| Step: 5
Training loss: 0.44650858640670776
Validation loss: 1.7807365508489712

Epoch: 5| Step: 6
Training loss: 0.5886523723602295
Validation loss: 1.7664949958042433

Epoch: 5| Step: 7
Training loss: 0.42230987548828125
Validation loss: 1.7531810870734594

Epoch: 5| Step: 8
Training loss: 0.49733179807662964
Validation loss: 1.771515533488284

Epoch: 5| Step: 9
Training loss: 0.8268410563468933
Validation loss: 1.804477193022287

Epoch: 5| Step: 10
Training loss: 0.5579747557640076
Validation loss: 1.822133933344195

Epoch: 315| Step: 0
Training loss: 0.6683469414710999
Validation loss: 1.823037734595678

Epoch: 5| Step: 1
Training loss: 0.7368593215942383
Validation loss: 1.8387986408766879

Epoch: 5| Step: 2
Training loss: 0.5644262433052063
Validation loss: 1.8391915085495159

Epoch: 5| Step: 3
Training loss: 0.7259812355041504
Validation loss: 1.8327566051995883

Epoch: 5| Step: 4
Training loss: 0.5821712017059326
Validation loss: 1.8410869541988577

Epoch: 5| Step: 5
Training loss: 0.6325729489326477
Validation loss: 1.8433898097725325

Epoch: 5| Step: 6
Training loss: 0.7341856360435486
Validation loss: 1.8316698728069183

Epoch: 5| Step: 7
Training loss: 0.4117056727409363
Validation loss: 1.8018354856839744

Epoch: 5| Step: 8
Training loss: 0.4906514286994934
Validation loss: 1.786465157744705

Epoch: 5| Step: 9
Training loss: 0.41183727979660034
Validation loss: 1.7782016646477483

Epoch: 5| Step: 10
Training loss: 0.3173370063304901
Validation loss: 1.7723692027471398

Epoch: 316| Step: 0
Training loss: 0.6690773963928223
Validation loss: 1.7493086579025432

Epoch: 5| Step: 1
Training loss: 0.6628454923629761
Validation loss: 1.7467696448808074

Epoch: 5| Step: 2
Training loss: 0.7550962567329407
Validation loss: 1.7645204503049132

Epoch: 5| Step: 3
Training loss: 0.39546817541122437
Validation loss: 1.7567461203503352

Epoch: 5| Step: 4
Training loss: 0.5803316831588745
Validation loss: 1.794819672902425

Epoch: 5| Step: 5
Training loss: 0.5103060603141785
Validation loss: 1.8132783264242194

Epoch: 5| Step: 6
Training loss: 0.5974879264831543
Validation loss: 1.86591503953421

Epoch: 5| Step: 7
Training loss: 0.4025960862636566
Validation loss: 1.862875884579074

Epoch: 5| Step: 8
Training loss: 0.47865986824035645
Validation loss: 1.8777055945447696

Epoch: 5| Step: 9
Training loss: 0.5022315979003906
Validation loss: 1.856323157587359

Epoch: 5| Step: 10
Training loss: 0.8096268773078918
Validation loss: 1.8526143937982538

Epoch: 317| Step: 0
Training loss: 0.7114108204841614
Validation loss: 1.8457446123964043

Epoch: 5| Step: 1
Training loss: 0.6105717420578003
Validation loss: 1.8457467466272333

Epoch: 5| Step: 2
Training loss: 0.4302629828453064
Validation loss: 1.806537611510164

Epoch: 5| Step: 3
Training loss: 0.37520283460617065
Validation loss: 1.787818343408646

Epoch: 5| Step: 4
Training loss: 0.7647652626037598
Validation loss: 1.7627747892051615

Epoch: 5| Step: 5
Training loss: 0.5481575727462769
Validation loss: 1.7394224366834086

Epoch: 5| Step: 6
Training loss: 0.6525842547416687
Validation loss: 1.73581697094825

Epoch: 5| Step: 7
Training loss: 0.5881374478340149
Validation loss: 1.7311308794124152

Epoch: 5| Step: 8
Training loss: 0.46572715044021606
Validation loss: 1.7386100702388312

Epoch: 5| Step: 9
Training loss: 0.7200126051902771
Validation loss: 1.7853166992946337

Epoch: 5| Step: 10
Training loss: 0.5318999886512756
Validation loss: 1.7825004862200828

Epoch: 318| Step: 0
Training loss: 0.34938985109329224
Validation loss: 1.7991578860949444

Epoch: 5| Step: 1
Training loss: 0.6994086503982544
Validation loss: 1.8305592229289394

Epoch: 5| Step: 2
Training loss: 0.6094905138015747
Validation loss: 1.8538745398162513

Epoch: 5| Step: 3
Training loss: 0.618549644947052
Validation loss: 1.8433609957336097

Epoch: 5| Step: 4
Training loss: 0.35017332434654236
Validation loss: 1.8444516767737686

Epoch: 5| Step: 5
Training loss: 0.5631840229034424
Validation loss: 1.8227593309135848

Epoch: 5| Step: 6
Training loss: 0.6784308552742004
Validation loss: 1.81033355446272

Epoch: 5| Step: 7
Training loss: 0.5987847447395325
Validation loss: 1.7606974506890902

Epoch: 5| Step: 8
Training loss: 0.6914739012718201
Validation loss: 1.7657564481099446

Epoch: 5| Step: 9
Training loss: 0.6027618646621704
Validation loss: 1.7469040309229205

Epoch: 5| Step: 10
Training loss: 0.4740103483200073
Validation loss: 1.7506655518726637

Epoch: 319| Step: 0
Training loss: 0.8352609872817993
Validation loss: 1.749112485557474

Epoch: 5| Step: 1
Training loss: 0.5639737844467163
Validation loss: 1.7444804176207511

Epoch: 5| Step: 2
Training loss: 0.4348273277282715
Validation loss: 1.7423870717325518

Epoch: 5| Step: 3
Training loss: 0.32356101274490356
Validation loss: 1.767957716859797

Epoch: 5| Step: 4
Training loss: 0.48715028166770935
Validation loss: 1.7997205975235149

Epoch: 5| Step: 5
Training loss: 0.8744410276412964
Validation loss: 1.8247710069020588

Epoch: 5| Step: 6
Training loss: 0.5127118229866028
Validation loss: 1.811304396198642

Epoch: 5| Step: 7
Training loss: 0.6396751403808594
Validation loss: 1.8103327469159198

Epoch: 5| Step: 8
Training loss: 0.5327200889587402
Validation loss: 1.7995294473504508

Epoch: 5| Step: 9
Training loss: 0.4439740777015686
Validation loss: 1.7896713313236032

Epoch: 5| Step: 10
Training loss: 0.40275225043296814
Validation loss: 1.7669311595219437

Epoch: 320| Step: 0
Training loss: 0.47878557443618774
Validation loss: 1.7663799985762565

Epoch: 5| Step: 1
Training loss: 0.55174320936203
Validation loss: 1.7567451974397064

Epoch: 5| Step: 2
Training loss: 0.31514665484428406
Validation loss: 1.7605304923108829

Epoch: 5| Step: 3
Training loss: 0.7471269369125366
Validation loss: 1.7595222765399563

Epoch: 5| Step: 4
Training loss: 0.38355085253715515
Validation loss: 1.7636416548041887

Epoch: 5| Step: 5
Training loss: 0.42193707823753357
Validation loss: 1.7427985424636512

Epoch: 5| Step: 6
Training loss: 0.6436434984207153
Validation loss: 1.7438472983657674

Epoch: 5| Step: 7
Training loss: 0.7557123899459839
Validation loss: 1.7270698778090938

Epoch: 5| Step: 8
Training loss: 0.3424643874168396
Validation loss: 1.7545380502618768

Epoch: 5| Step: 9
Training loss: 0.4974474310874939
Validation loss: 1.7751814985787997

Epoch: 5| Step: 10
Training loss: 0.9098914861679077
Validation loss: 1.7683269528932468

Epoch: 321| Step: 0
Training loss: 1.0871936082839966
Validation loss: 1.7553834915161133

Epoch: 5| Step: 1
Training loss: 0.5964102745056152
Validation loss: 1.765949769686627

Epoch: 5| Step: 2
Training loss: 0.4319297671318054
Validation loss: 1.7639363324770363

Epoch: 5| Step: 3
Training loss: 0.4583960175514221
Validation loss: 1.771861708292397

Epoch: 5| Step: 4
Training loss: 0.4901363253593445
Validation loss: 1.7801412190160444

Epoch: 5| Step: 5
Training loss: 0.7576959729194641
Validation loss: 1.7704630846618323

Epoch: 5| Step: 6
Training loss: 0.4146019518375397
Validation loss: 1.7738763773313133

Epoch: 5| Step: 7
Training loss: 0.2134385108947754
Validation loss: 1.8226778148322977

Epoch: 5| Step: 8
Training loss: 0.6073001623153687
Validation loss: 1.8473918296957528

Epoch: 5| Step: 9
Training loss: 0.8582385778427124
Validation loss: 1.8286387253833074

Epoch: 5| Step: 10
Training loss: 0.15988647937774658
Validation loss: 1.7558047591999013

Epoch: 322| Step: 0
Training loss: 0.5656207799911499
Validation loss: 1.742314536084411

Epoch: 5| Step: 1
Training loss: 0.4960346221923828
Validation loss: 1.7191702755548621

Epoch: 5| Step: 2
Training loss: 0.40632495284080505
Validation loss: 1.7560544552341584

Epoch: 5| Step: 3
Training loss: 0.4055348336696625
Validation loss: 1.7202361886219313

Epoch: 5| Step: 4
Training loss: 0.5489761233329773
Validation loss: 1.7563987496078655

Epoch: 5| Step: 5
Training loss: 0.6390897631645203
Validation loss: 1.779678257562781

Epoch: 5| Step: 6
Training loss: 0.5489321947097778
Validation loss: 1.8457039351104407

Epoch: 5| Step: 7
Training loss: 0.5759681463241577
Validation loss: 1.8590818425660491

Epoch: 5| Step: 8
Training loss: 0.4548614025115967
Validation loss: 1.8720218853283954

Epoch: 5| Step: 9
Training loss: 0.9286144375801086
Validation loss: 1.7881562581626318

Epoch: 5| Step: 10
Training loss: 0.3534337282180786
Validation loss: 1.778147764103387

Epoch: 323| Step: 0
Training loss: 0.4484090805053711
Validation loss: 1.7774883816319127

Epoch: 5| Step: 1
Training loss: 0.6023270487785339
Validation loss: 1.7748913175316268

Epoch: 5| Step: 2
Training loss: 0.4481872022151947
Validation loss: 1.7613561409775929

Epoch: 5| Step: 3
Training loss: 0.5099566578865051
Validation loss: 1.7532905660649782

Epoch: 5| Step: 4
Training loss: 0.670752227306366
Validation loss: 1.7496960368207706

Epoch: 5| Step: 5
Training loss: 0.4239598214626312
Validation loss: 1.7713102140734274

Epoch: 5| Step: 6
Training loss: 0.5709547996520996
Validation loss: 1.7649846243601974

Epoch: 5| Step: 7
Training loss: 0.7448844909667969
Validation loss: 1.7810955252698673

Epoch: 5| Step: 8
Training loss: 0.609836220741272
Validation loss: 1.823394557481171

Epoch: 5| Step: 9
Training loss: 0.37496358156204224
Validation loss: 1.7835224636139408

Epoch: 5| Step: 10
Training loss: 0.45158061385154724
Validation loss: 1.7712493083810295

Epoch: 324| Step: 0
Training loss: 0.5273935794830322
Validation loss: 1.7906937086454002

Epoch: 5| Step: 1
Training loss: 0.5380889177322388
Validation loss: 1.8196909350733603

Epoch: 5| Step: 2
Training loss: 0.6391195058822632
Validation loss: 1.858650993275386

Epoch: 5| Step: 3
Training loss: 0.6244696378707886
Validation loss: 1.8814506684580157

Epoch: 5| Step: 4
Training loss: 0.5282293558120728
Validation loss: 1.899426350029566

Epoch: 5| Step: 5
Training loss: 0.3674560487270355
Validation loss: 1.8713221601260606

Epoch: 5| Step: 6
Training loss: 0.6568900346755981
Validation loss: 1.8719524260490172

Epoch: 5| Step: 7
Training loss: 0.5203078985214233
Validation loss: 1.8389849714053574

Epoch: 5| Step: 8
Training loss: 0.6556289196014404
Validation loss: 1.8141165984574186

Epoch: 5| Step: 9
Training loss: 0.5482015609741211
Validation loss: 1.7806263328880392

Epoch: 5| Step: 10
Training loss: 0.4388701319694519
Validation loss: 1.776143999509914

Epoch: 325| Step: 0
Training loss: 0.6333439946174622
Validation loss: 1.7820241925536946

Epoch: 5| Step: 1
Training loss: 0.503664493560791
Validation loss: 1.8160054786230928

Epoch: 5| Step: 2
Training loss: 0.5088645219802856
Validation loss: 1.8419086574226298

Epoch: 5| Step: 3
Training loss: 0.4636821746826172
Validation loss: 1.816694978744753

Epoch: 5| Step: 4
Training loss: 0.5755423307418823
Validation loss: 1.7819420086440219

Epoch: 5| Step: 5
Training loss: 0.35750842094421387
Validation loss: 1.7856318412288543

Epoch: 5| Step: 6
Training loss: 0.5077911615371704
Validation loss: 1.7751418698218562

Epoch: 5| Step: 7
Training loss: 0.47595614194869995
Validation loss: 1.794722557067871

Epoch: 5| Step: 8
Training loss: 0.5897163152694702
Validation loss: 1.7922239777862385

Epoch: 5| Step: 9
Training loss: 0.5968123078346252
Validation loss: 1.8159828544944845

Epoch: 5| Step: 10
Training loss: 0.5564272403717041
Validation loss: 1.8340821394356348

Epoch: 326| Step: 0
Training loss: 0.33430370688438416
Validation loss: 1.8550165853192728

Epoch: 5| Step: 1
Training loss: 0.5411519408226013
Validation loss: 1.8396928900031633

Epoch: 5| Step: 2
Training loss: 0.5270472168922424
Validation loss: 1.8234727895388039

Epoch: 5| Step: 3
Training loss: 0.3959687352180481
Validation loss: 1.8116964217155211

Epoch: 5| Step: 4
Training loss: 0.8984706997871399
Validation loss: 1.787857824756253

Epoch: 5| Step: 5
Training loss: 0.38941091299057007
Validation loss: 1.7851435163969636

Epoch: 5| Step: 6
Training loss: 0.34956905245780945
Validation loss: 1.7802958821737638

Epoch: 5| Step: 7
Training loss: 0.39616551995277405
Validation loss: 1.7871939136135964

Epoch: 5| Step: 8
Training loss: 0.3718160390853882
Validation loss: 1.7996578857462893

Epoch: 5| Step: 9
Training loss: 0.7786417007446289
Validation loss: 1.8171454309135355

Epoch: 5| Step: 10
Training loss: 0.6515191197395325
Validation loss: 1.8366259080107494

Epoch: 327| Step: 0
Training loss: 0.2768694758415222
Validation loss: 1.8458920935148835

Epoch: 5| Step: 1
Training loss: 0.6218044757843018
Validation loss: 1.849902190187926

Epoch: 5| Step: 2
Training loss: 0.43609100580215454
Validation loss: 1.8188670078913372

Epoch: 5| Step: 3
Training loss: 0.41788849234580994
Validation loss: 1.8088044876693397

Epoch: 5| Step: 4
Training loss: 0.46224841475486755
Validation loss: 1.7892136419973066

Epoch: 5| Step: 5
Training loss: 0.4892413020133972
Validation loss: 1.7944619540245301

Epoch: 5| Step: 6
Training loss: 0.6026595830917358
Validation loss: 1.7835732236985238

Epoch: 5| Step: 7
Training loss: 0.7693684101104736
Validation loss: 1.786889515897279

Epoch: 5| Step: 8
Training loss: 0.5361524820327759
Validation loss: 1.7784386168244064

Epoch: 5| Step: 9
Training loss: 0.4742004871368408
Validation loss: 1.7548976713611233

Epoch: 5| Step: 10
Training loss: 0.6035301089286804
Validation loss: 1.7673574288686116

Epoch: 328| Step: 0
Training loss: 0.38002657890319824
Validation loss: 1.7355217869563768

Epoch: 5| Step: 1
Training loss: 0.6374738216400146
Validation loss: 1.7670727904124925

Epoch: 5| Step: 2
Training loss: 0.3112208843231201
Validation loss: 1.7553608635420441

Epoch: 5| Step: 3
Training loss: 0.561996579170227
Validation loss: 1.7946736299863426

Epoch: 5| Step: 4
Training loss: 0.29333755373954773
Validation loss: 1.7874635137537473

Epoch: 5| Step: 5
Training loss: 0.2744143009185791
Validation loss: 1.7931227427656933

Epoch: 5| Step: 6
Training loss: 0.8075541257858276
Validation loss: 1.8006890948100756

Epoch: 5| Step: 7
Training loss: 0.6075034737586975
Validation loss: 1.7575363843671736

Epoch: 5| Step: 8
Training loss: 0.2951890826225281
Validation loss: 1.7727942107826151

Epoch: 5| Step: 9
Training loss: 0.5601897239685059
Validation loss: 1.7966913241212086

Epoch: 5| Step: 10
Training loss: 0.8171373605728149
Validation loss: 1.8472111468674035

Epoch: 329| Step: 0
Training loss: 0.5116990804672241
Validation loss: 1.8886895461749005

Epoch: 5| Step: 1
Training loss: 0.5388370752334595
Validation loss: 1.8815494698862876

Epoch: 5| Step: 2
Training loss: 0.6025174856185913
Validation loss: 1.8834284774718746

Epoch: 5| Step: 3
Training loss: 0.4303056299686432
Validation loss: 1.851177284794469

Epoch: 5| Step: 4
Training loss: 0.3716537654399872
Validation loss: 1.8309345181270311

Epoch: 5| Step: 5
Training loss: 0.6140671968460083
Validation loss: 1.8315810772680468

Epoch: 5| Step: 6
Training loss: 0.48091381788253784
Validation loss: 1.8336172091063632

Epoch: 5| Step: 7
Training loss: 0.34303832054138184
Validation loss: 1.8106034058396534

Epoch: 5| Step: 8
Training loss: 0.3336317539215088
Validation loss: 1.801097123853622

Epoch: 5| Step: 9
Training loss: 0.8683451414108276
Validation loss: 1.8131330167093584

Epoch: 5| Step: 10
Training loss: 0.41853493452072144
Validation loss: 1.8046244421312887

Epoch: 330| Step: 0
Training loss: 0.36962318420410156
Validation loss: 1.8041235131602134

Epoch: 5| Step: 1
Training loss: 0.5511597394943237
Validation loss: 1.785510286208122

Epoch: 5| Step: 2
Training loss: 0.5996917486190796
Validation loss: 1.768461834999823

Epoch: 5| Step: 3
Training loss: 0.5427805185317993
Validation loss: 1.8051285077166814

Epoch: 5| Step: 4
Training loss: 0.6064993739128113
Validation loss: 1.7693397665536532

Epoch: 5| Step: 5
Training loss: 0.4952167868614197
Validation loss: 1.7974125621139363

Epoch: 5| Step: 6
Training loss: 0.43094402551651
Validation loss: 1.7735401379164828

Epoch: 5| Step: 7
Training loss: 0.5149197578430176
Validation loss: 1.7883266184919624

Epoch: 5| Step: 8
Training loss: 0.4676528871059418
Validation loss: 1.8029968392464422

Epoch: 5| Step: 9
Training loss: 0.5520767569541931
Validation loss: 1.823627507814797

Epoch: 5| Step: 10
Training loss: 0.1838454008102417
Validation loss: 1.8303816703058058

Epoch: 331| Step: 0
Training loss: 0.3256937861442566
Validation loss: 1.8379676290737685

Epoch: 5| Step: 1
Training loss: 0.592640221118927
Validation loss: 1.8383368292162496

Epoch: 5| Step: 2
Training loss: 0.54179847240448
Validation loss: 1.8161182903474378

Epoch: 5| Step: 3
Training loss: 0.6926790475845337
Validation loss: 1.8110657033099924

Epoch: 5| Step: 4
Training loss: 0.40939927101135254
Validation loss: 1.7876738745679137

Epoch: 5| Step: 5
Training loss: 0.45395317673683167
Validation loss: 1.7328812332563504

Epoch: 5| Step: 6
Training loss: 0.5738298296928406
Validation loss: 1.7308338303719797

Epoch: 5| Step: 7
Training loss: 0.4018303453922272
Validation loss: 1.775123897419181

Epoch: 5| Step: 8
Training loss: 0.4321065843105316
Validation loss: 1.7578395335905013

Epoch: 5| Step: 9
Training loss: 0.7394060492515564
Validation loss: 1.7871797930809759

Epoch: 5| Step: 10
Training loss: 0.49980562925338745
Validation loss: 1.8146674120297996

Epoch: 332| Step: 0
Training loss: 0.7521403431892395
Validation loss: 1.7862419569364159

Epoch: 5| Step: 1
Training loss: 0.3865177035331726
Validation loss: 1.7798820285386936

Epoch: 5| Step: 2
Training loss: 0.7902340888977051
Validation loss: 1.7500674365669169

Epoch: 5| Step: 3
Training loss: 0.5514633059501648
Validation loss: 1.7494228065654795

Epoch: 5| Step: 4
Training loss: 0.37912264466285706
Validation loss: 1.7317045016955304

Epoch: 5| Step: 5
Training loss: 0.5499147772789001
Validation loss: 1.7440021448237921

Epoch: 5| Step: 6
Training loss: 0.24036738276481628
Validation loss: 1.7478967289770804

Epoch: 5| Step: 7
Training loss: 0.4171789586544037
Validation loss: 1.7788808525249522

Epoch: 5| Step: 8
Training loss: 0.4835689663887024
Validation loss: 1.7531347768281096

Epoch: 5| Step: 9
Training loss: 0.535042941570282
Validation loss: 1.7867919757802

Epoch: 5| Step: 10
Training loss: 0.2514624297618866
Validation loss: 1.7781888579809537

Epoch: 333| Step: 0
Training loss: 0.2462996542453766
Validation loss: 1.769021927669484

Epoch: 5| Step: 1
Training loss: 0.4768179953098297
Validation loss: 1.8085384215078046

Epoch: 5| Step: 2
Training loss: 0.4027876853942871
Validation loss: 1.7624052865530855

Epoch: 5| Step: 3
Training loss: 0.5473889708518982
Validation loss: 1.7718614788465603

Epoch: 5| Step: 4
Training loss: 0.5384219288825989
Validation loss: 1.772395312145192

Epoch: 5| Step: 5
Training loss: 0.4772717356681824
Validation loss: 1.7630753030059159

Epoch: 5| Step: 6
Training loss: 0.32649940252304077
Validation loss: 1.79594002872385

Epoch: 5| Step: 7
Training loss: 0.47550898790359497
Validation loss: 1.786700285891051

Epoch: 5| Step: 8
Training loss: 0.8455392718315125
Validation loss: 1.8375663847051642

Epoch: 5| Step: 9
Training loss: 0.5077912211418152
Validation loss: 1.7940090804971673

Epoch: 5| Step: 10
Training loss: 0.4841271638870239
Validation loss: 1.789948437803535

Epoch: 334| Step: 0
Training loss: 0.45100003480911255
Validation loss: 1.7714138530915784

Epoch: 5| Step: 1
Training loss: 0.44509536027908325
Validation loss: 1.7530420749418196

Epoch: 5| Step: 2
Training loss: 0.44475287199020386
Validation loss: 1.7276373576092463

Epoch: 5| Step: 3
Training loss: 0.6349135637283325
Validation loss: 1.7497222051825574

Epoch: 5| Step: 4
Training loss: 0.3828605115413666
Validation loss: 1.751475000894198

Epoch: 5| Step: 5
Training loss: 0.5739455223083496
Validation loss: 1.7713412136159918

Epoch: 5| Step: 6
Training loss: 0.6229293346405029
Validation loss: 1.7670178836391819

Epoch: 5| Step: 7
Training loss: 0.4862496256828308
Validation loss: 1.8004392680301462

Epoch: 5| Step: 8
Training loss: 0.35556739568710327
Validation loss: 1.7933266521782003

Epoch: 5| Step: 9
Training loss: 0.4920872747898102
Validation loss: 1.7673597681906916

Epoch: 5| Step: 10
Training loss: 0.36967968940734863
Validation loss: 1.770960610399964

Epoch: 335| Step: 0
Training loss: 0.6339206099510193
Validation loss: 1.8013756851996146

Epoch: 5| Step: 1
Training loss: 0.5837708711624146
Validation loss: 1.7890319567854687

Epoch: 5| Step: 2
Training loss: 0.35999834537506104
Validation loss: 1.7954054109511837

Epoch: 5| Step: 3
Training loss: 0.5606420636177063
Validation loss: 1.7720574307185348

Epoch: 5| Step: 4
Training loss: 0.4987666606903076
Validation loss: 1.7867295767671318

Epoch: 5| Step: 5
Training loss: 0.5455646514892578
Validation loss: 1.774723449701904

Epoch: 5| Step: 6
Training loss: 0.5178263187408447
Validation loss: 1.7700398404111144

Epoch: 5| Step: 7
Training loss: 0.3680341839790344
Validation loss: 1.7854294161642752

Epoch: 5| Step: 8
Training loss: 0.3667622208595276
Validation loss: 1.8032228510866883

Epoch: 5| Step: 9
Training loss: 0.47143155336380005
Validation loss: 1.8376319767326437

Epoch: 5| Step: 10
Training loss: 0.5394619107246399
Validation loss: 1.7874089607628443

Epoch: 336| Step: 0
Training loss: 0.546554446220398
Validation loss: 1.7781635586933424

Epoch: 5| Step: 1
Training loss: 0.378813773393631
Validation loss: 1.785439693799583

Epoch: 5| Step: 2
Training loss: 0.5661785006523132
Validation loss: 1.7553202029197448

Epoch: 5| Step: 3
Training loss: 0.44870486855506897
Validation loss: 1.7899988979421637

Epoch: 5| Step: 4
Training loss: 0.6644109487533569
Validation loss: 1.7929907255275275

Epoch: 5| Step: 5
Training loss: 0.5206702947616577
Validation loss: 1.7909799916769868

Epoch: 5| Step: 6
Training loss: 0.6244627237319946
Validation loss: 1.8345511228807512

Epoch: 5| Step: 7
Training loss: 0.43676549196243286
Validation loss: 1.8679483372678038

Epoch: 5| Step: 8
Training loss: 0.609419047832489
Validation loss: 1.9210575434469408

Epoch: 5| Step: 9
Training loss: 0.3039620816707611
Validation loss: 1.8395602626185263

Epoch: 5| Step: 10
Training loss: 0.4703657925128937
Validation loss: 1.8091437855074484

Epoch: 337| Step: 0
Training loss: 0.4770504832267761
Validation loss: 1.7775121683715491

Epoch: 5| Step: 1
Training loss: 0.6401600241661072
Validation loss: 1.7830352629384687

Epoch: 5| Step: 2
Training loss: 0.5026835203170776
Validation loss: 1.7561799351887037

Epoch: 5| Step: 3
Training loss: 0.5645104646682739
Validation loss: 1.7390423474773284

Epoch: 5| Step: 4
Training loss: 0.4331127107143402
Validation loss: 1.704556611276442

Epoch: 5| Step: 5
Training loss: 0.44526273012161255
Validation loss: 1.7554739508577573

Epoch: 5| Step: 6
Training loss: 0.52228844165802
Validation loss: 1.7420862477312806

Epoch: 5| Step: 7
Training loss: 0.5259923934936523
Validation loss: 1.7816912986898934

Epoch: 5| Step: 8
Training loss: 0.2845834791660309
Validation loss: 1.7802497597150906

Epoch: 5| Step: 9
Training loss: 0.5502594113349915
Validation loss: 1.8076874133079284

Epoch: 5| Step: 10
Training loss: 0.27021050453186035
Validation loss: 1.7660542329152424

Epoch: 338| Step: 0
Training loss: 0.5369917154312134
Validation loss: 1.7688164916089786

Epoch: 5| Step: 1
Training loss: 0.43564653396606445
Validation loss: 1.7447414013647264

Epoch: 5| Step: 2
Training loss: 0.35958418250083923
Validation loss: 1.744781849204853

Epoch: 5| Step: 3
Training loss: 0.23744793236255646
Validation loss: 1.7555097482537712

Epoch: 5| Step: 4
Training loss: 0.3726649880409241
Validation loss: 1.767653795980638

Epoch: 5| Step: 5
Training loss: 0.6356035470962524
Validation loss: 1.7337735929796774

Epoch: 5| Step: 6
Training loss: 0.32816916704177856
Validation loss: 1.735947375656456

Epoch: 5| Step: 7
Training loss: 0.35585907101631165
Validation loss: 1.7313324994938348

Epoch: 5| Step: 8
Training loss: 0.41070136427879333
Validation loss: 1.7666718229170768

Epoch: 5| Step: 9
Training loss: 0.5647326707839966
Validation loss: 1.7787922813046364

Epoch: 5| Step: 10
Training loss: 0.6336234211921692
Validation loss: 1.8092437431376467

Epoch: 339| Step: 0
Training loss: 0.6587560772895813
Validation loss: 1.8102209427023446

Epoch: 5| Step: 1
Training loss: 0.3685130476951599
Validation loss: 1.784116042557583

Epoch: 5| Step: 2
Training loss: 0.3361634612083435
Validation loss: 1.8505110561206777

Epoch: 5| Step: 3
Training loss: 0.555404007434845
Validation loss: 1.8242888027621853

Epoch: 5| Step: 4
Training loss: 0.2959718406200409
Validation loss: 1.839020816228723

Epoch: 5| Step: 5
Training loss: 0.3774441182613373
Validation loss: 1.8406921843046784

Epoch: 5| Step: 6
Training loss: 0.6171876788139343
Validation loss: 1.8372517221717424

Epoch: 5| Step: 7
Training loss: 0.46037545800209045
Validation loss: 1.8343855386139245

Epoch: 5| Step: 8
Training loss: 0.44139495491981506
Validation loss: 1.8136375322136828

Epoch: 5| Step: 9
Training loss: 0.4674418866634369
Validation loss: 1.8120058762129916

Epoch: 5| Step: 10
Training loss: 0.647216796875
Validation loss: 1.8059307221443421

Epoch: 340| Step: 0
Training loss: 0.5410441160202026
Validation loss: 1.7935740486268075

Epoch: 5| Step: 1
Training loss: 0.6169001460075378
Validation loss: 1.7735805306383359

Epoch: 5| Step: 2
Training loss: 0.32445228099823
Validation loss: 1.744645199468059

Epoch: 5| Step: 3
Training loss: 0.3019871115684509
Validation loss: 1.7360693793142996

Epoch: 5| Step: 4
Training loss: 0.5160452127456665
Validation loss: 1.7206324095367103

Epoch: 5| Step: 5
Training loss: 0.7945816516876221
Validation loss: 1.7201986517957462

Epoch: 5| Step: 6
Training loss: 0.36508625745773315
Validation loss: 1.7348811587979716

Epoch: 5| Step: 7
Training loss: 0.5530058145523071
Validation loss: 1.7143520847443612

Epoch: 5| Step: 8
Training loss: 0.3832883834838867
Validation loss: 1.7328236513240363

Epoch: 5| Step: 9
Training loss: 0.38425129652023315
Validation loss: 1.7456956525002756

Epoch: 5| Step: 10
Training loss: 0.3199985921382904
Validation loss: 1.7420577067200855

Epoch: 341| Step: 0
Training loss: 0.6755039691925049
Validation loss: 1.7917436745858961

Epoch: 5| Step: 1
Training loss: 0.4152194559574127
Validation loss: 1.7748098988686838

Epoch: 5| Step: 2
Training loss: 0.34896010160446167
Validation loss: 1.7728624959145822

Epoch: 5| Step: 3
Training loss: 0.25347861647605896
Validation loss: 1.7580237491156465

Epoch: 5| Step: 4
Training loss: 0.3212740421295166
Validation loss: 1.7631689643347135

Epoch: 5| Step: 5
Training loss: 0.3719465136528015
Validation loss: 1.7571033162455405

Epoch: 5| Step: 6
Training loss: 0.31838834285736084
Validation loss: 1.754751000353085

Epoch: 5| Step: 7
Training loss: 0.6487166285514832
Validation loss: 1.7571857757465814

Epoch: 5| Step: 8
Training loss: 0.4406854212284088
Validation loss: 1.771815880652397

Epoch: 5| Step: 9
Training loss: 0.40941962599754333
Validation loss: 1.7896796618738482

Epoch: 5| Step: 10
Training loss: 0.6828358173370361
Validation loss: 1.7784584658120268

Epoch: 342| Step: 0
Training loss: 0.5276932716369629
Validation loss: 1.7940932678919967

Epoch: 5| Step: 1
Training loss: 0.38001006841659546
Validation loss: 1.8158392496006464

Epoch: 5| Step: 2
Training loss: 0.42639198899269104
Validation loss: 1.8252130041840255

Epoch: 5| Step: 3
Training loss: 0.4977070689201355
Validation loss: 1.798797256203108

Epoch: 5| Step: 4
Training loss: 0.4543735980987549
Validation loss: 1.807394285355845

Epoch: 5| Step: 5
Training loss: 0.5212023258209229
Validation loss: 1.7664969941621185

Epoch: 5| Step: 6
Training loss: 0.47509416937828064
Validation loss: 1.762888039312055

Epoch: 5| Step: 7
Training loss: 0.47862738370895386
Validation loss: 1.7501314814372728

Epoch: 5| Step: 8
Training loss: 0.44053393602371216
Validation loss: 1.7401003094129666

Epoch: 5| Step: 9
Training loss: 0.26385682821273804
Validation loss: 1.73898144050311

Epoch: 5| Step: 10
Training loss: 0.3177270293235779
Validation loss: 1.7395049128481137

Epoch: 343| Step: 0
Training loss: 0.46069854497909546
Validation loss: 1.7688580251509143

Epoch: 5| Step: 1
Training loss: 0.3551943302154541
Validation loss: 1.746553059547178

Epoch: 5| Step: 2
Training loss: 0.4773576855659485
Validation loss: 1.7786276519939463

Epoch: 5| Step: 3
Training loss: 0.24987927079200745
Validation loss: 1.775156662028323

Epoch: 5| Step: 4
Training loss: 0.36934322118759155
Validation loss: 1.8061553432095436

Epoch: 5| Step: 5
Training loss: 0.4910205006599426
Validation loss: 1.7947981255028838

Epoch: 5| Step: 6
Training loss: 0.7566694617271423
Validation loss: 1.7808178932436052

Epoch: 5| Step: 7
Training loss: 0.37985628843307495
Validation loss: 1.7800294596661803

Epoch: 5| Step: 8
Training loss: 0.3293223977088928
Validation loss: 1.7619838022416638

Epoch: 5| Step: 9
Training loss: 0.27963072061538696
Validation loss: 1.7851232610723025

Epoch: 5| Step: 10
Training loss: 0.4692557752132416
Validation loss: 1.7814763412680676

Epoch: 344| Step: 0
Training loss: 0.5082938075065613
Validation loss: 1.76474706972799

Epoch: 5| Step: 1
Training loss: 0.35131531953811646
Validation loss: 1.7448871199802687

Epoch: 5| Step: 2
Training loss: 0.20478829741477966
Validation loss: 1.7708457349449076

Epoch: 5| Step: 3
Training loss: 0.5551584959030151
Validation loss: 1.7498117877591042

Epoch: 5| Step: 4
Training loss: 0.3757455348968506
Validation loss: 1.8008210409072138

Epoch: 5| Step: 5
Training loss: 0.4058934152126312
Validation loss: 1.7727605886356805

Epoch: 5| Step: 6
Training loss: 0.4930833876132965
Validation loss: 1.7695754215281496

Epoch: 5| Step: 7
Training loss: 0.486306756734848
Validation loss: 1.7830831299545944

Epoch: 5| Step: 8
Training loss: 0.3374619483947754
Validation loss: 1.7727420522320656

Epoch: 5| Step: 9
Training loss: 0.5472394824028015
Validation loss: 1.7650797879824074

Epoch: 5| Step: 10
Training loss: 0.3893769085407257
Validation loss: 1.7780729237423147

Epoch: 345| Step: 0
Training loss: 0.32382121682167053
Validation loss: 1.783292325594092

Epoch: 5| Step: 1
Training loss: 0.2970139682292938
Validation loss: 1.760698805573166

Epoch: 5| Step: 2
Training loss: 0.34939128160476685
Validation loss: 1.754608892625378

Epoch: 5| Step: 3
Training loss: 0.4463968873023987
Validation loss: 1.7581812079234789

Epoch: 5| Step: 4
Training loss: 0.6934199333190918
Validation loss: 1.768409288057717

Epoch: 5| Step: 5
Training loss: 0.2685735821723938
Validation loss: 1.7500257671520274

Epoch: 5| Step: 6
Training loss: 0.52484130859375
Validation loss: 1.771243574798748

Epoch: 5| Step: 7
Training loss: 0.6423354148864746
Validation loss: 1.7292449807608

Epoch: 5| Step: 8
Training loss: 0.45660725235939026
Validation loss: 1.7482732983045681

Epoch: 5| Step: 9
Training loss: 0.3415464758872986
Validation loss: 1.7170743019350114

Epoch: 5| Step: 10
Training loss: 0.4917002320289612
Validation loss: 1.726142938419055

Epoch: 346| Step: 0
Training loss: 0.26030275225639343
Validation loss: 1.7159783955543273

Epoch: 5| Step: 1
Training loss: 0.41086989641189575
Validation loss: 1.723291898286471

Epoch: 5| Step: 2
Training loss: 0.3327743709087372
Validation loss: 1.7166636836144231

Epoch: 5| Step: 3
Training loss: 0.6982030868530273
Validation loss: 1.703292970375348

Epoch: 5| Step: 4
Training loss: 0.34715551137924194
Validation loss: 1.7360473422593967

Epoch: 5| Step: 5
Training loss: 0.5119141340255737
Validation loss: 1.7515982427904684

Epoch: 5| Step: 6
Training loss: 0.3324020504951477
Validation loss: 1.7662653935852872

Epoch: 5| Step: 7
Training loss: 0.33272039890289307
Validation loss: 1.7581599015061573

Epoch: 5| Step: 8
Training loss: 0.5472056269645691
Validation loss: 1.7622299899337113

Epoch: 5| Step: 9
Training loss: 0.4751296043395996
Validation loss: 1.7599944658176874

Epoch: 5| Step: 10
Training loss: 0.26288706064224243
Validation loss: 1.7636292749835598

Epoch: 347| Step: 0
Training loss: 0.3553551137447357
Validation loss: 1.7167348977058166

Epoch: 5| Step: 1
Training loss: 0.5369163751602173
Validation loss: 1.734236119895853

Epoch: 5| Step: 2
Training loss: 0.39457017183303833
Validation loss: 1.7133599981184928

Epoch: 5| Step: 3
Training loss: 0.34784671664237976
Validation loss: 1.7455859427810998

Epoch: 5| Step: 4
Training loss: 0.39833202958106995
Validation loss: 1.7246214420564714

Epoch: 5| Step: 5
Training loss: 0.44393056631088257
Validation loss: 1.7276886714402067

Epoch: 5| Step: 6
Training loss: 0.46613192558288574
Validation loss: 1.7298725446065266

Epoch: 5| Step: 7
Training loss: 0.2705667018890381
Validation loss: 1.7623283401612313

Epoch: 5| Step: 8
Training loss: 0.35147616267204285
Validation loss: 1.758022194267601

Epoch: 5| Step: 9
Training loss: 0.4445011615753174
Validation loss: 1.773078962038922

Epoch: 5| Step: 10
Training loss: 0.5543036460876465
Validation loss: 1.7604545854753064

Epoch: 348| Step: 0
Training loss: 0.42399200797080994
Validation loss: 1.7228651751754105

Epoch: 5| Step: 1
Training loss: 0.33842116594314575
Validation loss: 1.7418431620444021

Epoch: 5| Step: 2
Training loss: 0.26377394795417786
Validation loss: 1.74011811389718

Epoch: 5| Step: 3
Training loss: 0.2331320345401764
Validation loss: 1.724399475641148

Epoch: 5| Step: 4
Training loss: 0.4984181523323059
Validation loss: 1.7169457635571879

Epoch: 5| Step: 5
Training loss: 0.5339152812957764
Validation loss: 1.726549252387016

Epoch: 5| Step: 6
Training loss: 0.09468816220760345
Validation loss: 1.7321058473279398

Epoch: 5| Step: 7
Training loss: 0.3961586654186249
Validation loss: 1.7491654696003083

Epoch: 5| Step: 8
Training loss: 0.5196360349655151
Validation loss: 1.7594905386688888

Epoch: 5| Step: 9
Training loss: 0.36773911118507385
Validation loss: 1.7343618805690477

Epoch: 5| Step: 10
Training loss: 0.6335695385932922
Validation loss: 1.731510257208219

Epoch: 349| Step: 0
Training loss: 0.37245869636535645
Validation loss: 1.746644860954695

Epoch: 5| Step: 1
Training loss: 0.4520600736141205
Validation loss: 1.7120829218177385

Epoch: 5| Step: 2
Training loss: 0.4848199784755707
Validation loss: 1.7102470167221562

Epoch: 5| Step: 3
Training loss: 0.629464328289032
Validation loss: 1.7194635560435634

Epoch: 5| Step: 4
Training loss: 0.1887841522693634
Validation loss: 1.7325843085524857

Epoch: 5| Step: 5
Training loss: 0.4123271107673645
Validation loss: 1.7286751379248917

Epoch: 5| Step: 6
Training loss: 0.4670489728450775
Validation loss: 1.7438006247243574

Epoch: 5| Step: 7
Training loss: 0.31572604179382324
Validation loss: 1.7481375971148092

Epoch: 5| Step: 8
Training loss: 0.27577462792396545
Validation loss: 1.7091956215520059

Epoch: 5| Step: 9
Training loss: 0.4236780107021332
Validation loss: 1.7310081643442954

Epoch: 5| Step: 10
Training loss: 0.2899760603904724
Validation loss: 1.724134431090406

Epoch: 350| Step: 0
Training loss: 0.2389971762895584
Validation loss: 1.6990420151782293

Epoch: 5| Step: 1
Training loss: 0.3556564450263977
Validation loss: 1.7065484562227804

Epoch: 5| Step: 2
Training loss: 0.3286958932876587
Validation loss: 1.6798914145397883

Epoch: 5| Step: 3
Training loss: 0.431379497051239
Validation loss: 1.6731202269113192

Epoch: 5| Step: 4
Training loss: 0.4618140161037445
Validation loss: 1.6715498201308712

Epoch: 5| Step: 5
Training loss: 0.5521181225776672
Validation loss: 1.7244779358627975

Epoch: 5| Step: 6
Training loss: 0.5102432370185852
Validation loss: 1.7054571990043885

Epoch: 5| Step: 7
Training loss: 0.4670686721801758
Validation loss: 1.6961263943743963

Epoch: 5| Step: 8
Training loss: 0.33912426233291626
Validation loss: 1.7046248810265654

Epoch: 5| Step: 9
Training loss: 0.33150696754455566
Validation loss: 1.703232934398036

Epoch: 5| Step: 10
Training loss: 0.4451315701007843
Validation loss: 1.7472675974651048

Epoch: 351| Step: 0
Training loss: 0.32955726981163025
Validation loss: 1.7682482170802292

Epoch: 5| Step: 1
Training loss: 0.30688488483428955
Validation loss: 1.7431435379930722

Epoch: 5| Step: 2
Training loss: 0.3336583077907562
Validation loss: 1.7260804253239785

Epoch: 5| Step: 3
Training loss: 0.3990534245967865
Validation loss: 1.7250600655873616

Epoch: 5| Step: 4
Training loss: 0.2844565212726593
Validation loss: 1.7333110019724856

Epoch: 5| Step: 5
Training loss: 0.5392271280288696
Validation loss: 1.7105202687683927

Epoch: 5| Step: 6
Training loss: 0.44659972190856934
Validation loss: 1.7051515451041601

Epoch: 5| Step: 7
Training loss: 0.39903050661087036
Validation loss: 1.711499810218811

Epoch: 5| Step: 8
Training loss: 0.3306743800640106
Validation loss: 1.6907641759482763

Epoch: 5| Step: 9
Training loss: 0.6428795456886292
Validation loss: 1.7102929578032544

Epoch: 5| Step: 10
Training loss: 0.41701316833496094
Validation loss: 1.7106397828107238

Epoch: 352| Step: 0
Training loss: 0.275608628988266
Validation loss: 1.7239990849648752

Epoch: 5| Step: 1
Training loss: 0.34039631485939026
Validation loss: 1.7342056843542284

Epoch: 5| Step: 2
Training loss: 0.35911262035369873
Validation loss: 1.7228361791180027

Epoch: 5| Step: 3
Training loss: 0.6992603540420532
Validation loss: 1.7233845456953971

Epoch: 5| Step: 4
Training loss: 0.3751280903816223
Validation loss: 1.7626953906910394

Epoch: 5| Step: 5
Training loss: 0.16915731132030487
Validation loss: 1.755031285747405

Epoch: 5| Step: 6
Training loss: 0.41512933373451233
Validation loss: 1.7584343956362816

Epoch: 5| Step: 7
Training loss: 0.3180519938468933
Validation loss: 1.776836056863108

Epoch: 5| Step: 8
Training loss: 0.4414246678352356
Validation loss: 1.8040765767456384

Epoch: 5| Step: 9
Training loss: 0.3480459153652191
Validation loss: 1.8187410421268915

Epoch: 5| Step: 10
Training loss: 0.5681213140487671
Validation loss: 1.7678509123863713

Epoch: 353| Step: 0
Training loss: 0.37776607275009155
Validation loss: 1.7858448643838205

Epoch: 5| Step: 1
Training loss: 0.23191945254802704
Validation loss: 1.7559474514376732

Epoch: 5| Step: 2
Training loss: 0.30476465821266174
Validation loss: 1.7508997135264899

Epoch: 5| Step: 3
Training loss: 0.5792194604873657
Validation loss: 1.7014294721746956

Epoch: 5| Step: 4
Training loss: 0.5089279413223267
Validation loss: 1.718577367003246

Epoch: 5| Step: 5
Training loss: 0.23860469460487366
Validation loss: 1.703295692320793

Epoch: 5| Step: 6
Training loss: 0.47658005356788635
Validation loss: 1.684496057930813

Epoch: 5| Step: 7
Training loss: 0.331637978553772
Validation loss: 1.6912575780704457

Epoch: 5| Step: 8
Training loss: 0.3927784562110901
Validation loss: 1.694650698733586

Epoch: 5| Step: 9
Training loss: 0.37288448214530945
Validation loss: 1.7177316219575944

Epoch: 5| Step: 10
Training loss: 0.3000320792198181
Validation loss: 1.726799875177363

Epoch: 354| Step: 0
Training loss: 0.37760892510414124
Validation loss: 1.730722685014048

Epoch: 5| Step: 1
Training loss: 0.2356014996767044
Validation loss: 1.7417994468442854

Epoch: 5| Step: 2
Training loss: 0.4104549288749695
Validation loss: 1.7388851693881455

Epoch: 5| Step: 3
Training loss: 0.4184715151786804
Validation loss: 1.7319494908855808

Epoch: 5| Step: 4
Training loss: 0.36523517966270447
Validation loss: 1.7131486990118538

Epoch: 5| Step: 5
Training loss: 0.22487422823905945
Validation loss: 1.6973080410752246

Epoch: 5| Step: 6
Training loss: 0.46169862151145935
Validation loss: 1.7110941679246965

Epoch: 5| Step: 7
Training loss: 0.6010947227478027
Validation loss: 1.7089951974089428

Epoch: 5| Step: 8
Training loss: 0.2319294959306717
Validation loss: 1.71338568323402

Epoch: 5| Step: 9
Training loss: 0.34274739027023315
Validation loss: 1.7026050738109055

Epoch: 5| Step: 10
Training loss: 0.3349604308605194
Validation loss: 1.7023924217429212

Epoch: 355| Step: 0
Training loss: 0.49204912781715393
Validation loss: 1.6884940555018764

Epoch: 5| Step: 1
Training loss: 0.21323618292808533
Validation loss: 1.6950334233622397

Epoch: 5| Step: 2
Training loss: 0.3337865471839905
Validation loss: 1.6906472700898365

Epoch: 5| Step: 3
Training loss: 0.40341123938560486
Validation loss: 1.6899931648726105

Epoch: 5| Step: 4
Training loss: 0.47327423095703125
Validation loss: 1.6874638013942267

Epoch: 5| Step: 5
Training loss: 0.4512173533439636
Validation loss: 1.706367100438764

Epoch: 5| Step: 6
Training loss: 0.4735686182975769
Validation loss: 1.705488181883289

Epoch: 5| Step: 7
Training loss: 0.19518181681632996
Validation loss: 1.6978490967904367

Epoch: 5| Step: 8
Training loss: 0.31545260548591614
Validation loss: 1.7191455941046438

Epoch: 5| Step: 9
Training loss: 0.3079621493816376
Validation loss: 1.7364078362782795

Epoch: 5| Step: 10
Training loss: 0.43779540061950684
Validation loss: 1.7225944816425283

Epoch: 356| Step: 0
Training loss: 0.26806801557540894
Validation loss: 1.7169231214830953

Epoch: 5| Step: 1
Training loss: 0.44185295701026917
Validation loss: 1.703147577983077

Epoch: 5| Step: 2
Training loss: 0.2228134125471115
Validation loss: 1.7134197373544016

Epoch: 5| Step: 3
Training loss: 0.2912268042564392
Validation loss: 1.6691228292321647

Epoch: 5| Step: 4
Training loss: 0.14920595288276672
Validation loss: 1.6990779189653293

Epoch: 5| Step: 5
Training loss: 0.3960378170013428
Validation loss: 1.7259477043664584

Epoch: 5| Step: 6
Training loss: 0.3703969717025757
Validation loss: 1.7221749777434974

Epoch: 5| Step: 7
Training loss: 0.2860046327114105
Validation loss: 1.720733586178031

Epoch: 5| Step: 8
Training loss: 0.7421535849571228
Validation loss: 1.6988098365004345

Epoch: 5| Step: 9
Training loss: 0.5445271730422974
Validation loss: 1.725684109554496

Epoch: 5| Step: 10
Training loss: 0.47185465693473816
Validation loss: 1.7294999361038208

Epoch: 357| Step: 0
Training loss: 0.2576768398284912
Validation loss: 1.7222866409568376

Epoch: 5| Step: 1
Training loss: 0.33632493019104004
Validation loss: 1.751581012561757

Epoch: 5| Step: 2
Training loss: 0.42454105615615845
Validation loss: 1.724955262676362

Epoch: 5| Step: 3
Training loss: 0.3578304648399353
Validation loss: 1.7103812989368234

Epoch: 5| Step: 4
Training loss: 0.2640693187713623
Validation loss: 1.7143669102781562

Epoch: 5| Step: 5
Training loss: 0.2878492474555969
Validation loss: 1.6825470924377441

Epoch: 5| Step: 6
Training loss: 0.6327372789382935
Validation loss: 1.6772000764005928

Epoch: 5| Step: 7
Training loss: 0.2504226267337799
Validation loss: 1.6842031158426756

Epoch: 5| Step: 8
Training loss: 0.26481539011001587
Validation loss: 1.6978012720743816

Epoch: 5| Step: 9
Training loss: 0.34501954913139343
Validation loss: 1.6999419530232747

Epoch: 5| Step: 10
Training loss: 0.5297287106513977
Validation loss: 1.6867924992756178

Epoch: 358| Step: 0
Training loss: 0.3376796245574951
Validation loss: 1.7277296320084603

Epoch: 5| Step: 1
Training loss: 0.2698722183704376
Validation loss: 1.7374702961214128

Epoch: 5| Step: 2
Training loss: 0.25916725397109985
Validation loss: 1.7489751231285833

Epoch: 5| Step: 3
Training loss: 0.46003803610801697
Validation loss: 1.7877870503292288

Epoch: 5| Step: 4
Training loss: 0.3254459500312805
Validation loss: 1.733875213130828

Epoch: 5| Step: 5
Training loss: 0.44111838936805725
Validation loss: 1.7551887125097296

Epoch: 5| Step: 6
Training loss: 0.38466769456863403
Validation loss: 1.694967093006257

Epoch: 5| Step: 7
Training loss: 0.3754315972328186
Validation loss: 1.6830827318212038

Epoch: 5| Step: 8
Training loss: 0.269392728805542
Validation loss: 1.678537179065007

Epoch: 5| Step: 9
Training loss: 0.4876925051212311
Validation loss: 1.690210585953087

Epoch: 5| Step: 10
Training loss: 0.5128865242004395
Validation loss: 1.6959417443121634

Epoch: 359| Step: 0
Training loss: 0.2510092854499817
Validation loss: 1.6633153730823147

Epoch: 5| Step: 1
Training loss: 0.36760884523391724
Validation loss: 1.6803968452638196

Epoch: 5| Step: 2
Training loss: 0.3641374409198761
Validation loss: 1.674701629146453

Epoch: 5| Step: 3
Training loss: 0.18515850603580475
Validation loss: 1.7002273477533811

Epoch: 5| Step: 4
Training loss: 0.4662070870399475
Validation loss: 1.6939466717422649

Epoch: 5| Step: 5
Training loss: 0.3473179042339325
Validation loss: 1.6998000215458613

Epoch: 5| Step: 6
Training loss: 0.41535812616348267
Validation loss: 1.7107312281926472

Epoch: 5| Step: 7
Training loss: 0.376503050327301
Validation loss: 1.7153622899004208

Epoch: 5| Step: 8
Training loss: 0.2685791552066803
Validation loss: 1.738138392407407

Epoch: 5| Step: 9
Training loss: 0.44078078866004944
Validation loss: 1.7500686850599063

Epoch: 5| Step: 10
Training loss: 0.5511128902435303
Validation loss: 1.7320400976365613

Epoch: 360| Step: 0
Training loss: 0.27312833070755005
Validation loss: 1.7263804584421136

Epoch: 5| Step: 1
Training loss: 0.5287104845046997
Validation loss: 1.7178225376272713

Epoch: 5| Step: 2
Training loss: 0.32831138372421265
Validation loss: 1.6929465416939027

Epoch: 5| Step: 3
Training loss: 0.339374840259552
Validation loss: 1.695352849139962

Epoch: 5| Step: 4
Training loss: 0.345744788646698
Validation loss: 1.6861969835014754

Epoch: 5| Step: 5
Training loss: 0.25754374265670776
Validation loss: 1.6876188093616116

Epoch: 5| Step: 6
Training loss: 0.29891902208328247
Validation loss: 1.6891890994964107

Epoch: 5| Step: 7
Training loss: 0.49869799613952637
Validation loss: 1.69613258172107

Epoch: 5| Step: 8
Training loss: 0.40411821007728577
Validation loss: 1.714394861652005

Epoch: 5| Step: 9
Training loss: 0.38326525688171387
Validation loss: 1.72740509176767

Epoch: 5| Step: 10
Training loss: 0.4808022975921631
Validation loss: 1.6901286058528449

Epoch: 361| Step: 0
Training loss: 0.4897924065589905
Validation loss: 1.6790534629616687

Epoch: 5| Step: 1
Training loss: 0.28900182247161865
Validation loss: 1.6756973625511251

Epoch: 5| Step: 2
Training loss: 0.4354562759399414
Validation loss: 1.7259801498023413

Epoch: 5| Step: 3
Training loss: 0.21064510941505432
Validation loss: 1.7435737681645218

Epoch: 5| Step: 4
Training loss: 0.26821964979171753
Validation loss: 1.722468590223661

Epoch: 5| Step: 5
Training loss: 0.33777666091918945
Validation loss: 1.7616074905600598

Epoch: 5| Step: 6
Training loss: 0.19622793793678284
Validation loss: 1.7055867801430404

Epoch: 5| Step: 7
Training loss: 0.5670133829116821
Validation loss: 1.6798644963131155

Epoch: 5| Step: 8
Training loss: 0.4791339039802551
Validation loss: 1.6756572890025314

Epoch: 5| Step: 9
Training loss: 0.27132582664489746
Validation loss: 1.6721280595307708

Epoch: 5| Step: 10
Training loss: 0.35609105229377747
Validation loss: 1.6648805782359133

Epoch: 362| Step: 0
Training loss: 0.4237247109413147
Validation loss: 1.6621223136942873

Epoch: 5| Step: 1
Training loss: 0.33967724442481995
Validation loss: 1.654728049873024

Epoch: 5| Step: 2
Training loss: 0.4245361387729645
Validation loss: 1.6950339469858395

Epoch: 5| Step: 3
Training loss: 0.26863113045692444
Validation loss: 1.7134103262296287

Epoch: 5| Step: 4
Training loss: 0.3967844545841217
Validation loss: 1.705600559070546

Epoch: 5| Step: 5
Training loss: 0.29169178009033203
Validation loss: 1.7009179335768505

Epoch: 5| Step: 6
Training loss: 0.32337644696235657
Validation loss: 1.729535020807738

Epoch: 5| Step: 7
Training loss: 0.24637892842292786
Validation loss: 1.7164813908197547

Epoch: 5| Step: 8
Training loss: 0.35848432779312134
Validation loss: 1.697299825247898

Epoch: 5| Step: 9
Training loss: 0.4634990692138672
Validation loss: 1.7140658542674074

Epoch: 5| Step: 10
Training loss: 0.5317999124526978
Validation loss: 1.6989992882615776

Epoch: 363| Step: 0
Training loss: 0.48257356882095337
Validation loss: 1.7281659905628493

Epoch: 5| Step: 1
Training loss: 0.20356619358062744
Validation loss: 1.7055754033468102

Epoch: 5| Step: 2
Training loss: 0.419247567653656
Validation loss: 1.7119391278554035

Epoch: 5| Step: 3
Training loss: 0.3040485084056854
Validation loss: 1.7060046554893575

Epoch: 5| Step: 4
Training loss: 0.49070629477500916
Validation loss: 1.703804225049993

Epoch: 5| Step: 5
Training loss: 0.3543774485588074
Validation loss: 1.7014161489343131

Epoch: 5| Step: 6
Training loss: 0.25771811604499817
Validation loss: 1.716414882290748

Epoch: 5| Step: 7
Training loss: 0.6185032725334167
Validation loss: 1.7134385570403068

Epoch: 5| Step: 8
Training loss: 0.163640096783638
Validation loss: 1.7038504256997058

Epoch: 5| Step: 9
Training loss: 0.27711886167526245
Validation loss: 1.680600759803608

Epoch: 5| Step: 10
Training loss: 0.5015747547149658
Validation loss: 1.7166891021113242

Epoch: 364| Step: 0
Training loss: 0.26314306259155273
Validation loss: 1.7214902011297082

Epoch: 5| Step: 1
Training loss: 0.35542869567871094
Validation loss: 1.7050741321297103

Epoch: 5| Step: 2
Training loss: 0.224867582321167
Validation loss: 1.741710146909119

Epoch: 5| Step: 3
Training loss: 0.21585574746131897
Validation loss: 1.7363173243820027

Epoch: 5| Step: 4
Training loss: 0.4321635365486145
Validation loss: 1.7456824779510498

Epoch: 5| Step: 5
Training loss: 0.2602657079696655
Validation loss: 1.7587566234732186

Epoch: 5| Step: 6
Training loss: 0.27969059348106384
Validation loss: 1.7246836346964682

Epoch: 5| Step: 7
Training loss: 0.6357328295707703
Validation loss: 1.740438897122619

Epoch: 5| Step: 8
Training loss: 0.41112202405929565
Validation loss: 1.7255374782828874

Epoch: 5| Step: 9
Training loss: 0.3110615611076355
Validation loss: 1.7387959162394206

Epoch: 5| Step: 10
Training loss: 0.3889308273792267
Validation loss: 1.7229425266224851

Epoch: 365| Step: 0
Training loss: 0.23200707137584686
Validation loss: 1.7091993990764822

Epoch: 5| Step: 1
Training loss: 0.41636714339256287
Validation loss: 1.7118348037042925

Epoch: 5| Step: 2
Training loss: 0.49048081040382385
Validation loss: 1.6951356780144475

Epoch: 5| Step: 3
Training loss: 0.3772984445095062
Validation loss: 1.7131602020673855

Epoch: 5| Step: 4
Training loss: 0.5401557087898254
Validation loss: 1.691030288255343

Epoch: 5| Step: 5
Training loss: 0.15872323513031006
Validation loss: 1.6821765066474996

Epoch: 5| Step: 6
Training loss: 0.31009334325790405
Validation loss: 1.6806453556142829

Epoch: 5| Step: 7
Training loss: 0.27372056245803833
Validation loss: 1.6831518578272995

Epoch: 5| Step: 8
Training loss: 0.31783607602119446
Validation loss: 1.6877087111114173

Epoch: 5| Step: 9
Training loss: 0.2895912528038025
Validation loss: 1.668436663125151

Epoch: 5| Step: 10
Training loss: 0.2803080081939697
Validation loss: 1.707246349703881

Epoch: 366| Step: 0
Training loss: 0.2120901346206665
Validation loss: 1.7150721626897012

Epoch: 5| Step: 1
Training loss: 0.25589680671691895
Validation loss: 1.6885263227647351

Epoch: 5| Step: 2
Training loss: 0.1876852810382843
Validation loss: 1.6836063349118797

Epoch: 5| Step: 3
Training loss: 0.34843960404396057
Validation loss: 1.6751985370471913

Epoch: 5| Step: 4
Training loss: 0.20945116877555847
Validation loss: 1.6699267702717935

Epoch: 5| Step: 5
Training loss: 0.3315969407558441
Validation loss: 1.6725882150793587

Epoch: 5| Step: 6
Training loss: 0.3216698467731476
Validation loss: 1.6703936464043074

Epoch: 5| Step: 7
Training loss: 0.5284849405288696
Validation loss: 1.6948429512721237

Epoch: 5| Step: 8
Training loss: 0.3495035767555237
Validation loss: 1.7215492392099032

Epoch: 5| Step: 9
Training loss: 0.40625208616256714
Validation loss: 1.7244667609532673

Epoch: 5| Step: 10
Training loss: 0.3434731960296631
Validation loss: 1.7264576458161878

Epoch: 367| Step: 0
Training loss: 0.1942444145679474
Validation loss: 1.7367877447476952

Epoch: 5| Step: 1
Training loss: 0.3001452386379242
Validation loss: 1.7248833076928252

Epoch: 5| Step: 2
Training loss: 0.4706898629665375
Validation loss: 1.7144287965630973

Epoch: 5| Step: 3
Training loss: 0.27578720450401306
Validation loss: 1.7395318028747395

Epoch: 5| Step: 4
Training loss: 0.5914667248725891
Validation loss: 1.7185249649068361

Epoch: 5| Step: 5
Training loss: 0.287560373544693
Validation loss: 1.7046994086234801

Epoch: 5| Step: 6
Training loss: 0.17077580094337463
Validation loss: 1.6970223611400974

Epoch: 5| Step: 7
Training loss: 0.23823437094688416
Validation loss: 1.6855148705103065

Epoch: 5| Step: 8
Training loss: 0.41473501920700073
Validation loss: 1.7017798449403496

Epoch: 5| Step: 9
Training loss: 0.421082079410553
Validation loss: 1.6667072369206337

Epoch: 5| Step: 10
Training loss: 0.41648685932159424
Validation loss: 1.6787507123844598

Epoch: 368| Step: 0
Training loss: 0.2815583348274231
Validation loss: 1.6609846622713151

Epoch: 5| Step: 1
Training loss: 0.3016892075538635
Validation loss: 1.6394041456202024

Epoch: 5| Step: 2
Training loss: 0.2615193724632263
Validation loss: 1.6283111982448126

Epoch: 5| Step: 3
Training loss: 0.5115779638290405
Validation loss: 1.643102515128351

Epoch: 5| Step: 4
Training loss: 0.13426139950752258
Validation loss: 1.6289555770094677

Epoch: 5| Step: 5
Training loss: 0.605742335319519
Validation loss: 1.6279634916654198

Epoch: 5| Step: 6
Training loss: 0.26441192626953125
Validation loss: 1.6561056311412523

Epoch: 5| Step: 7
Training loss: 0.2784920930862427
Validation loss: 1.6689618005547473

Epoch: 5| Step: 8
Training loss: 0.48669224977493286
Validation loss: 1.6974904524382723

Epoch: 5| Step: 9
Training loss: 0.3431888222694397
Validation loss: 1.7077629514919814

Epoch: 5| Step: 10
Training loss: 0.2029627114534378
Validation loss: 1.7332382432876094

Epoch: 369| Step: 0
Training loss: 0.4968562126159668
Validation loss: 1.745606392942449

Epoch: 5| Step: 1
Training loss: 0.39167100191116333
Validation loss: 1.7449630050248996

Epoch: 5| Step: 2
Training loss: 0.484013170003891
Validation loss: 1.7308224503711989

Epoch: 5| Step: 3
Training loss: 0.2880474925041199
Validation loss: 1.7031155978479693

Epoch: 5| Step: 4
Training loss: 0.19331596791744232
Validation loss: 1.68600966084388

Epoch: 5| Step: 5
Training loss: 0.19585980474948883
Validation loss: 1.6582117529325588

Epoch: 5| Step: 6
Training loss: 0.3979675769805908
Validation loss: 1.6469556311125397

Epoch: 5| Step: 7
Training loss: 0.2871856391429901
Validation loss: 1.6332671924303936

Epoch: 5| Step: 8
Training loss: 0.5195870399475098
Validation loss: 1.639495934209516

Epoch: 5| Step: 9
Training loss: 0.252638578414917
Validation loss: 1.6321744252276678

Epoch: 5| Step: 10
Training loss: 0.3665889501571655
Validation loss: 1.6643500122972714

Epoch: 370| Step: 0
Training loss: 0.24089257419109344
Validation loss: 1.6775784902675177

Epoch: 5| Step: 1
Training loss: 0.36591359972953796
Validation loss: 1.6912693323627594

Epoch: 5| Step: 2
Training loss: 0.2905811071395874
Validation loss: 1.7440112829208374

Epoch: 5| Step: 3
Training loss: 0.21148960292339325
Validation loss: 1.697450453235257

Epoch: 5| Step: 4
Training loss: 0.28110039234161377
Validation loss: 1.7309353210592782

Epoch: 5| Step: 5
Training loss: 0.7192353010177612
Validation loss: 1.7227980116362214

Epoch: 5| Step: 6
Training loss: 0.23362886905670166
Validation loss: 1.7208679260746125

Epoch: 5| Step: 7
Training loss: 0.2987667918205261
Validation loss: 1.7229064510714622

Epoch: 5| Step: 8
Training loss: 0.4333471655845642
Validation loss: 1.7183617789258239

Epoch: 5| Step: 9
Training loss: 0.3532087206840515
Validation loss: 1.7171143370289956

Epoch: 5| Step: 10
Training loss: 0.42320334911346436
Validation loss: 1.7520827054977417

Epoch: 371| Step: 0
Training loss: 0.25808772444725037
Validation loss: 1.7188407003238637

Epoch: 5| Step: 1
Training loss: 0.3243786692619324
Validation loss: 1.7052067595143472

Epoch: 5| Step: 2
Training loss: 0.25441160798072815
Validation loss: 1.7059304496293426

Epoch: 5| Step: 3
Training loss: 0.2942020297050476
Validation loss: 1.6753276637805405

Epoch: 5| Step: 4
Training loss: 0.29986563324928284
Validation loss: 1.6716146456298007

Epoch: 5| Step: 5
Training loss: 0.2934516370296478
Validation loss: 1.68004975780364

Epoch: 5| Step: 6
Training loss: 0.46965083479881287
Validation loss: 1.6679558946240334

Epoch: 5| Step: 7
Training loss: 0.33942288160324097
Validation loss: 1.7299577036211569

Epoch: 5| Step: 8
Training loss: 0.3730594515800476
Validation loss: 1.727011525502769

Epoch: 5| Step: 9
Training loss: 0.4288423955440521
Validation loss: 1.7640964446529266

Epoch: 5| Step: 10
Training loss: 0.5821741819381714
Validation loss: 1.7347436207596973

Epoch: 372| Step: 0
Training loss: 0.3909848928451538
Validation loss: 1.6864036590822282

Epoch: 5| Step: 1
Training loss: 0.24822106957435608
Validation loss: 1.7069348532666442

Epoch: 5| Step: 2
Training loss: 0.27182504534721375
Validation loss: 1.6999327598079559

Epoch: 5| Step: 3
Training loss: 0.34728485345840454
Validation loss: 1.6929413439125143

Epoch: 5| Step: 4
Training loss: 0.4275452494621277
Validation loss: 1.666817759954801

Epoch: 5| Step: 5
Training loss: 0.2669456899166107
Validation loss: 1.6721373322189494

Epoch: 5| Step: 6
Training loss: 0.17139148712158203
Validation loss: 1.6917482999063307

Epoch: 5| Step: 7
Training loss: 0.35290390253067017
Validation loss: 1.6648397266223867

Epoch: 5| Step: 8
Training loss: 0.4892999231815338
Validation loss: 1.6758038074739519

Epoch: 5| Step: 9
Training loss: 0.23284097015857697
Validation loss: 1.7058401312879337

Epoch: 5| Step: 10
Training loss: 0.3724214434623718
Validation loss: 1.7203706233732161

Epoch: 373| Step: 0
Training loss: 0.38290855288505554
Validation loss: 1.6872963725879628

Epoch: 5| Step: 1
Training loss: 0.3733367323875427
Validation loss: 1.7183609867608676

Epoch: 5| Step: 2
Training loss: 0.3240678310394287
Validation loss: 1.7001028394186368

Epoch: 5| Step: 3
Training loss: 0.25680917501449585
Validation loss: 1.7167710463205974

Epoch: 5| Step: 4
Training loss: 0.42899495363235474
Validation loss: 1.7053983929336711

Epoch: 5| Step: 5
Training loss: 0.21522462368011475
Validation loss: 1.7173728225051716

Epoch: 5| Step: 6
Training loss: 0.1671227663755417
Validation loss: 1.724413897401543

Epoch: 5| Step: 7
Training loss: 0.23619389533996582
Validation loss: 1.6940818038038028

Epoch: 5| Step: 8
Training loss: 0.21027910709381104
Validation loss: 1.7328465702713176

Epoch: 5| Step: 9
Training loss: 0.31282758712768555
Validation loss: 1.7058641308097429

Epoch: 5| Step: 10
Training loss: 0.3819352090358734
Validation loss: 1.7406342849936536

Epoch: 374| Step: 0
Training loss: 0.24485428631305695
Validation loss: 1.7234040665370163

Epoch: 5| Step: 1
Training loss: 0.34544801712036133
Validation loss: 1.6967816134934783

Epoch: 5| Step: 2
Training loss: 0.2220059335231781
Validation loss: 1.699964798906798

Epoch: 5| Step: 3
Training loss: 0.35114461183547974
Validation loss: 1.717722551797026

Epoch: 5| Step: 4
Training loss: 0.14483167231082916
Validation loss: 1.705760137368274

Epoch: 5| Step: 5
Training loss: 0.36970797181129456
Validation loss: 1.6803936176402594

Epoch: 5| Step: 6
Training loss: 0.32833462953567505
Validation loss: 1.701446080720553

Epoch: 5| Step: 7
Training loss: 0.2961977422237396
Validation loss: 1.6775972343260241

Epoch: 5| Step: 8
Training loss: 0.369952529668808
Validation loss: 1.6923105409068446

Epoch: 5| Step: 9
Training loss: 0.40789374709129333
Validation loss: 1.6453243891398113

Epoch: 5| Step: 10
Training loss: 0.3004167377948761
Validation loss: 1.685566880369699

Epoch: 375| Step: 0
Training loss: 0.35540586709976196
Validation loss: 1.6348033182082637

Epoch: 5| Step: 1
Training loss: 0.3506174683570862
Validation loss: 1.671508905708149

Epoch: 5| Step: 2
Training loss: 0.4101995527744293
Validation loss: 1.6455745203520662

Epoch: 5| Step: 3
Training loss: 0.19793352484703064
Validation loss: 1.6756204110319897

Epoch: 5| Step: 4
Training loss: 0.2785213589668274
Validation loss: 1.7049507633332284

Epoch: 5| Step: 5
Training loss: 0.1958259642124176
Validation loss: 1.69456999276274

Epoch: 5| Step: 6
Training loss: 0.1794859617948532
Validation loss: 1.6783186402372134

Epoch: 5| Step: 7
Training loss: 0.12729696929454803
Validation loss: 1.660009176500382

Epoch: 5| Step: 8
Training loss: 0.4918766915798187
Validation loss: 1.6621271294932212

Epoch: 5| Step: 9
Training loss: 0.28948697447776794
Validation loss: 1.6517016374936668

Epoch: 5| Step: 10
Training loss: 0.41361305117607117
Validation loss: 1.6527967632457774

Epoch: 376| Step: 0
Training loss: 0.23914222419261932
Validation loss: 1.6465632787314795

Epoch: 5| Step: 1
Training loss: 0.42112359404563904
Validation loss: 1.6488573320450322

Epoch: 5| Step: 2
Training loss: 0.20994074642658234
Validation loss: 1.6629232770653182

Epoch: 5| Step: 3
Training loss: 0.32619285583496094
Validation loss: 1.6872683020048245

Epoch: 5| Step: 4
Training loss: 0.15061624348163605
Validation loss: 1.6721292952055573

Epoch: 5| Step: 5
Training loss: 0.20345477759838104
Validation loss: 1.667126541496605

Epoch: 5| Step: 6
Training loss: 0.2537383437156677
Validation loss: 1.6703476957095567

Epoch: 5| Step: 7
Training loss: 0.18429650366306305
Validation loss: 1.624980967531922

Epoch: 5| Step: 8
Training loss: 0.3918418884277344
Validation loss: 1.6559546211714387

Epoch: 5| Step: 9
Training loss: 0.41916435956954956
Validation loss: 1.6548635446897118

Epoch: 5| Step: 10
Training loss: 0.5327620506286621
Validation loss: 1.6607232568084553

Epoch: 377| Step: 0
Training loss: 0.2823379635810852
Validation loss: 1.669273232900968

Epoch: 5| Step: 1
Training loss: 0.29646605253219604
Validation loss: 1.7146631402354087

Epoch: 5| Step: 2
Training loss: 0.33197492361068726
Validation loss: 1.7001004616419475

Epoch: 5| Step: 3
Training loss: 0.18470202386379242
Validation loss: 1.7049990597591604

Epoch: 5| Step: 4
Training loss: 0.30391553044319153
Validation loss: 1.7279894608323292

Epoch: 5| Step: 5
Training loss: 0.30871495604515076
Validation loss: 1.7164505630411127

Epoch: 5| Step: 6
Training loss: 0.30090075731277466
Validation loss: 1.6673742494275492

Epoch: 5| Step: 7
Training loss: 0.3122686743736267
Validation loss: 1.6620620527575094

Epoch: 5| Step: 8
Training loss: 0.2361176460981369
Validation loss: 1.6606012992961432

Epoch: 5| Step: 9
Training loss: 0.3475566506385803
Validation loss: 1.6761834467611005

Epoch: 5| Step: 10
Training loss: 0.3762938976287842
Validation loss: 1.6902733105485157

Epoch: 378| Step: 0
Training loss: 0.4266809821128845
Validation loss: 1.6855900684992473

Epoch: 5| Step: 1
Training loss: 0.2502501606941223
Validation loss: 1.6664813821033766

Epoch: 5| Step: 2
Training loss: 0.32234764099121094
Validation loss: 1.6745267260459162

Epoch: 5| Step: 3
Training loss: 0.319294273853302
Validation loss: 1.6508439612644974

Epoch: 5| Step: 4
Training loss: 0.17453114688396454
Validation loss: 1.6393683956515404

Epoch: 5| Step: 5
Training loss: 0.25243738293647766
Validation loss: 1.6745820763290569

Epoch: 5| Step: 6
Training loss: 0.43978604674339294
Validation loss: 1.6624998149051462

Epoch: 5| Step: 7
Training loss: 0.2247728854417801
Validation loss: 1.6966171982467815

Epoch: 5| Step: 8
Training loss: 0.22794023156166077
Validation loss: 1.678557983008764

Epoch: 5| Step: 9
Training loss: 0.3797758221626282
Validation loss: 1.6993468333316106

Epoch: 5| Step: 10
Training loss: 0.40740618109703064
Validation loss: 1.7252545491341622

Epoch: 379| Step: 0
Training loss: 0.25671181082725525
Validation loss: 1.727767857172156

Epoch: 5| Step: 1
Training loss: 0.16177108883857727
Validation loss: 1.7193242657569148

Epoch: 5| Step: 2
Training loss: 0.24134421348571777
Validation loss: 1.6824857547718992

Epoch: 5| Step: 3
Training loss: 0.19583258032798767
Validation loss: 1.7045921433356501

Epoch: 5| Step: 4
Training loss: 0.4172382950782776
Validation loss: 1.6929241918748426

Epoch: 5| Step: 5
Training loss: 0.37942811846733093
Validation loss: 1.6998644285304572

Epoch: 5| Step: 6
Training loss: 0.4015045166015625
Validation loss: 1.6913428768034904

Epoch: 5| Step: 7
Training loss: 0.5507454872131348
Validation loss: 1.7124900209006442

Epoch: 5| Step: 8
Training loss: 0.3468400239944458
Validation loss: 1.6934786599169496

Epoch: 5| Step: 9
Training loss: 0.24699155986309052
Validation loss: 1.7210129422526206

Epoch: 5| Step: 10
Training loss: 0.35185983777046204
Validation loss: 1.7062066485804896

Epoch: 380| Step: 0
Training loss: 0.21258282661437988
Validation loss: 1.7157091914966542

Epoch: 5| Step: 1
Training loss: 0.4482599198818207
Validation loss: 1.7242202246060936

Epoch: 5| Step: 2
Training loss: 0.4137265086174011
Validation loss: 1.6967286140688005

Epoch: 5| Step: 3
Training loss: 0.23148290812969208
Validation loss: 1.7011234273192704

Epoch: 5| Step: 4
Training loss: 0.24357712268829346
Validation loss: 1.6942108344006281

Epoch: 5| Step: 5
Training loss: 0.45374441146850586
Validation loss: 1.6921717723210652

Epoch: 5| Step: 6
Training loss: 0.40184444189071655
Validation loss: 1.7167268619742444

Epoch: 5| Step: 7
Training loss: 0.2822851538658142
Validation loss: 1.6861502278235652

Epoch: 5| Step: 8
Training loss: 0.24621693789958954
Validation loss: 1.662088571056243

Epoch: 5| Step: 9
Training loss: 0.511563777923584
Validation loss: 1.6610697828313357

Epoch: 5| Step: 10
Training loss: 0.23775628209114075
Validation loss: 1.659102665480747

Epoch: 381| Step: 0
Training loss: 0.5370234251022339
Validation loss: 1.6731563421987719

Epoch: 5| Step: 1
Training loss: 0.37931784987449646
Validation loss: 1.6596194903055828

Epoch: 5| Step: 2
Training loss: 0.31192874908447266
Validation loss: 1.6868728232640091

Epoch: 5| Step: 3
Training loss: 0.5349741578102112
Validation loss: 1.680090791435652

Epoch: 5| Step: 4
Training loss: 0.18400481343269348
Validation loss: 1.7232622023551696

Epoch: 5| Step: 5
Training loss: 0.3338051438331604
Validation loss: 1.7216498672321279

Epoch: 5| Step: 6
Training loss: 0.44879770278930664
Validation loss: 1.75316269423372

Epoch: 5| Step: 7
Training loss: 0.4000716209411621
Validation loss: 1.7358142457982546

Epoch: 5| Step: 8
Training loss: 0.2608029246330261
Validation loss: 1.6952451954605758

Epoch: 5| Step: 9
Training loss: 0.22470740973949432
Validation loss: 1.6964722269324846

Epoch: 5| Step: 10
Training loss: 0.20656448602676392
Validation loss: 1.667526304080922

Epoch: 382| Step: 0
Training loss: 0.27782896161079407
Validation loss: 1.7033052829004103

Epoch: 5| Step: 1
Training loss: 0.49837589263916016
Validation loss: 1.6967290985968806

Epoch: 5| Step: 2
Training loss: 0.20412147045135498
Validation loss: 1.7085300107156076

Epoch: 5| Step: 3
Training loss: 0.5032345652580261
Validation loss: 1.7191248375882384

Epoch: 5| Step: 4
Training loss: 0.3440372347831726
Validation loss: 1.7390453559096142

Epoch: 5| Step: 5
Training loss: 0.25569257140159607
Validation loss: 1.7288202662621774

Epoch: 5| Step: 6
Training loss: 0.23339371383190155
Validation loss: 1.7347684355192288

Epoch: 5| Step: 7
Training loss: 0.31458157300949097
Validation loss: 1.6950099493867608

Epoch: 5| Step: 8
Training loss: 0.18417344987392426
Validation loss: 1.6867471715455413

Epoch: 5| Step: 9
Training loss: 0.3161509335041046
Validation loss: 1.6887955627133768

Epoch: 5| Step: 10
Training loss: 0.24198156595230103
Validation loss: 1.6803647433557818

Epoch: 383| Step: 0
Training loss: 0.2823522984981537
Validation loss: 1.6466378255556988

Epoch: 5| Step: 1
Training loss: 0.1635788530111313
Validation loss: 1.6573508631798528

Epoch: 5| Step: 2
Training loss: 0.25669795274734497
Validation loss: 1.666721482430735

Epoch: 5| Step: 3
Training loss: 0.28628769516944885
Validation loss: 1.682348693570783

Epoch: 5| Step: 4
Training loss: 0.216051384806633
Validation loss: 1.682029857430407

Epoch: 5| Step: 5
Training loss: 0.3536989092826843
Validation loss: 1.7047025657469226

Epoch: 5| Step: 6
Training loss: 0.3347565233707428
Validation loss: 1.711673987809048

Epoch: 5| Step: 7
Training loss: 0.5140306353569031
Validation loss: 1.729113084013744

Epoch: 5| Step: 8
Training loss: 0.34085285663604736
Validation loss: 1.7345469254319386

Epoch: 5| Step: 9
Training loss: 0.18063898384571075
Validation loss: 1.7072344646658948

Epoch: 5| Step: 10
Training loss: 0.24365946650505066
Validation loss: 1.687842240897558

Epoch: 384| Step: 0
Training loss: 0.22360439598560333
Validation loss: 1.6988287228409962

Epoch: 5| Step: 1
Training loss: 0.4631151258945465
Validation loss: 1.707404254585184

Epoch: 5| Step: 2
Training loss: 0.22312042117118835
Validation loss: 1.6997071261047034

Epoch: 5| Step: 3
Training loss: 0.25946784019470215
Validation loss: 1.6864415599453835

Epoch: 5| Step: 4
Training loss: 0.28536587953567505
Validation loss: 1.7174376800496092

Epoch: 5| Step: 5
Training loss: 0.33223533630371094
Validation loss: 1.7031872182764032

Epoch: 5| Step: 6
Training loss: 0.3135211765766144
Validation loss: 1.7038153345866869

Epoch: 5| Step: 7
Training loss: 0.2839087247848511
Validation loss: 1.6937277265774306

Epoch: 5| Step: 8
Training loss: 0.2234804630279541
Validation loss: 1.6826365365776965

Epoch: 5| Step: 9
Training loss: 0.2178448736667633
Validation loss: 1.6785794663172897

Epoch: 5| Step: 10
Training loss: 0.35374367237091064
Validation loss: 1.6746072282073319

Epoch: 385| Step: 0
Training loss: 0.2610664963722229
Validation loss: 1.657365632313554

Epoch: 5| Step: 1
Training loss: 0.24378156661987305
Validation loss: 1.6552833985256892

Epoch: 5| Step: 2
Training loss: 0.29222169518470764
Validation loss: 1.651976821243122

Epoch: 5| Step: 3
Training loss: 0.22711019217967987
Validation loss: 1.6689664932989305

Epoch: 5| Step: 4
Training loss: 0.3041486144065857
Validation loss: 1.6590860601394408

Epoch: 5| Step: 5
Training loss: 0.3705589771270752
Validation loss: 1.6379209462032522

Epoch: 5| Step: 6
Training loss: 0.20136213302612305
Validation loss: 1.6445132211972309

Epoch: 5| Step: 7
Training loss: 0.22516663372516632
Validation loss: 1.660089732498251

Epoch: 5| Step: 8
Training loss: 0.43695488572120667
Validation loss: 1.6654642935722106

Epoch: 5| Step: 9
Training loss: 0.32186681032180786
Validation loss: 1.6299618610771753

Epoch: 5| Step: 10
Training loss: 0.21286018192768097
Validation loss: 1.6364632601379066

Epoch: 386| Step: 0
Training loss: 0.20089414715766907
Validation loss: 1.643420684081252

Epoch: 5| Step: 1
Training loss: 0.3228287100791931
Validation loss: 1.6123869393461494

Epoch: 5| Step: 2
Training loss: 0.3345393240451813
Validation loss: 1.6426845442864202

Epoch: 5| Step: 3
Training loss: 0.268772155046463
Validation loss: 1.6443354166964048

Epoch: 5| Step: 4
Training loss: 0.29998257756233215
Validation loss: 1.638526242266419

Epoch: 5| Step: 5
Training loss: 0.33850347995758057
Validation loss: 1.6464820831052718

Epoch: 5| Step: 6
Training loss: 0.21398623287677765
Validation loss: 1.683205299479987

Epoch: 5| Step: 7
Training loss: 0.4733782708644867
Validation loss: 1.698433292809353

Epoch: 5| Step: 8
Training loss: 0.32818323373794556
Validation loss: 1.6815959010072934

Epoch: 5| Step: 9
Training loss: 0.308543860912323
Validation loss: 1.6683240885375648

Epoch: 5| Step: 10
Training loss: 0.31980156898498535
Validation loss: 1.6519570145555722

Epoch: 387| Step: 0
Training loss: 0.19133540987968445
Validation loss: 1.652368366077382

Epoch: 5| Step: 1
Training loss: 0.316062867641449
Validation loss: 1.6623007853825886

Epoch: 5| Step: 2
Training loss: 0.27760982513427734
Validation loss: 1.6467728922444005

Epoch: 5| Step: 3
Training loss: 0.2895702123641968
Validation loss: 1.670064990879387

Epoch: 5| Step: 4
Training loss: 0.45430684089660645
Validation loss: 1.674079297691263

Epoch: 5| Step: 5
Training loss: 0.2150554209947586
Validation loss: 1.6766871072912728

Epoch: 5| Step: 6
Training loss: 0.410677045583725
Validation loss: 1.6630246331614833

Epoch: 5| Step: 7
Training loss: 0.4345255494117737
Validation loss: 1.675145415849583

Epoch: 5| Step: 8
Training loss: 0.26944881677627563
Validation loss: 1.676405970768262

Epoch: 5| Step: 9
Training loss: 0.37637531757354736
Validation loss: 1.6871572938016666

Epoch: 5| Step: 10
Training loss: 0.3263070583343506
Validation loss: 1.6848212929182156

Epoch: 388| Step: 0
Training loss: 0.2174256145954132
Validation loss: 1.664372121134112

Epoch: 5| Step: 1
Training loss: 0.1420060098171234
Validation loss: 1.6414596419180594

Epoch: 5| Step: 2
Training loss: 0.3753007650375366
Validation loss: 1.6488682813541864

Epoch: 5| Step: 3
Training loss: 0.2361498326063156
Validation loss: 1.6626655055630593

Epoch: 5| Step: 4
Training loss: 0.2909418046474457
Validation loss: 1.64041865769253

Epoch: 5| Step: 5
Training loss: 0.3363558351993561
Validation loss: 1.6828497276511243

Epoch: 5| Step: 6
Training loss: 0.34361836314201355
Validation loss: 1.6569396936765282

Epoch: 5| Step: 7
Training loss: 0.37972310185432434
Validation loss: 1.6905494556632092

Epoch: 5| Step: 8
Training loss: 0.19599755108356476
Validation loss: 1.6652043609208957

Epoch: 5| Step: 9
Training loss: 0.24688021838665009
Validation loss: 1.679104733210738

Epoch: 5| Step: 10
Training loss: 0.44667109847068787
Validation loss: 1.6765037864767096

Epoch: 389| Step: 0
Training loss: 0.2498653680086136
Validation loss: 1.6812480367640013

Epoch: 5| Step: 1
Training loss: 0.35319894552230835
Validation loss: 1.6672652972641813

Epoch: 5| Step: 2
Training loss: 0.27535146474838257
Validation loss: 1.6807145303295505

Epoch: 5| Step: 3
Training loss: 0.28964537382125854
Validation loss: 1.6501167666527532

Epoch: 5| Step: 4
Training loss: 0.33819061517715454
Validation loss: 1.6539160269562916

Epoch: 5| Step: 5
Training loss: 0.3025554418563843
Validation loss: 1.6289384326627177

Epoch: 5| Step: 6
Training loss: 0.2956821918487549
Validation loss: 1.63541910084345

Epoch: 5| Step: 7
Training loss: 0.3122814893722534
Validation loss: 1.6362289651747672

Epoch: 5| Step: 8
Training loss: 0.21787485480308533
Validation loss: 1.6602667685477965

Epoch: 5| Step: 9
Training loss: 0.2909984588623047
Validation loss: 1.672618007147184

Epoch: 5| Step: 10
Training loss: 0.17225836217403412
Validation loss: 1.6336225540407243

Epoch: 390| Step: 0
Training loss: 0.22782209515571594
Validation loss: 1.683247555968582

Epoch: 5| Step: 1
Training loss: 0.20086884498596191
Validation loss: 1.6909697491635558

Epoch: 5| Step: 2
Training loss: 0.44425854086875916
Validation loss: 1.6602268116448515

Epoch: 5| Step: 3
Training loss: 0.32059985399246216
Validation loss: 1.6876913142460648

Epoch: 5| Step: 4
Training loss: 0.2640950083732605
Validation loss: 1.7207980002126386

Epoch: 5| Step: 5
Training loss: 0.2994583249092102
Validation loss: 1.7120675989376601

Epoch: 5| Step: 6
Training loss: 0.3155290186405182
Validation loss: 1.6778901148867864

Epoch: 5| Step: 7
Training loss: 0.5251958966255188
Validation loss: 1.6448949370332944

Epoch: 5| Step: 8
Training loss: 0.22779341042041779
Validation loss: 1.6144676182859687

Epoch: 5| Step: 9
Training loss: 0.1534033566713333
Validation loss: 1.6472767694022066

Epoch: 5| Step: 10
Training loss: 0.3376864492893219
Validation loss: 1.638522477560146

Epoch: 391| Step: 0
Training loss: 0.23632077872753143
Validation loss: 1.630086406584709

Epoch: 5| Step: 1
Training loss: 0.25822383165359497
Validation loss: 1.6315693175920876

Epoch: 5| Step: 2
Training loss: 0.2974340319633484
Validation loss: 1.6028392327729093

Epoch: 5| Step: 3
Training loss: 0.2857106328010559
Validation loss: 1.6215688861826414

Epoch: 5| Step: 4
Training loss: 0.38833725452423096
Validation loss: 1.6296886686355836

Epoch: 5| Step: 5
Training loss: 0.23380236327648163
Validation loss: 1.6410695583589616

Epoch: 5| Step: 6
Training loss: 0.24275240302085876
Validation loss: 1.655958588405322

Epoch: 5| Step: 7
Training loss: 0.2761278748512268
Validation loss: 1.6741520358670143

Epoch: 5| Step: 8
Training loss: 0.4110414981842041
Validation loss: 1.6592248255206692

Epoch: 5| Step: 9
Training loss: 0.3032991886138916
Validation loss: 1.6496838279949722

Epoch: 5| Step: 10
Training loss: 0.2654174566268921
Validation loss: 1.6292545744167861

Epoch: 392| Step: 0
Training loss: 0.1466066539287567
Validation loss: 1.6574070235734344

Epoch: 5| Step: 1
Training loss: 0.3066282868385315
Validation loss: 1.6160502587595293

Epoch: 5| Step: 2
Training loss: 0.35091736912727356
Validation loss: 1.6562783525836082

Epoch: 5| Step: 3
Training loss: 0.19455155730247498
Validation loss: 1.6436023494248748

Epoch: 5| Step: 4
Training loss: 0.4616493582725525
Validation loss: 1.642424355271042

Epoch: 5| Step: 5
Training loss: 0.22979862987995148
Validation loss: 1.6276152518487745

Epoch: 5| Step: 6
Training loss: 0.23878665268421173
Validation loss: 1.645407058859384

Epoch: 5| Step: 7
Training loss: 0.1873144805431366
Validation loss: 1.617989215158647

Epoch: 5| Step: 8
Training loss: 0.32246431708335876
Validation loss: 1.6289539901159142

Epoch: 5| Step: 9
Training loss: 0.37358802556991577
Validation loss: 1.62922401197495

Epoch: 5| Step: 10
Training loss: 0.2752892076969147
Validation loss: 1.628983805256505

Epoch: 393| Step: 0
Training loss: 0.23058581352233887
Validation loss: 1.640970451857454

Epoch: 5| Step: 1
Training loss: 0.2541140019893646
Validation loss: 1.6648426350726877

Epoch: 5| Step: 2
Training loss: 0.2651333212852478
Validation loss: 1.650503299569571

Epoch: 5| Step: 3
Training loss: 0.4028405249118805
Validation loss: 1.6768361842760475

Epoch: 5| Step: 4
Training loss: 0.22803421318531036
Validation loss: 1.6809994161769908

Epoch: 5| Step: 5
Training loss: 0.2381909340620041
Validation loss: 1.697181914442329

Epoch: 5| Step: 6
Training loss: 0.1839599311351776
Validation loss: 1.7031457142163349

Epoch: 5| Step: 7
Training loss: 0.28671449422836304
Validation loss: 1.7190102633609567

Epoch: 5| Step: 8
Training loss: 0.38534826040267944
Validation loss: 1.6979123341139926

Epoch: 5| Step: 9
Training loss: 0.30842188000679016
Validation loss: 1.6853945921826106

Epoch: 5| Step: 10
Training loss: 0.2769027054309845
Validation loss: 1.6782756992565688

Epoch: 394| Step: 0
Training loss: 0.4098871350288391
Validation loss: 1.6902985495905722

Epoch: 5| Step: 1
Training loss: 0.2748708724975586
Validation loss: 1.6656869803705523

Epoch: 5| Step: 2
Training loss: 0.328713595867157
Validation loss: 1.6376959482828777

Epoch: 5| Step: 3
Training loss: 0.3945085406303406
Validation loss: 1.656951355677779

Epoch: 5| Step: 4
Training loss: 0.17081975936889648
Validation loss: 1.6213665905819143

Epoch: 5| Step: 5
Training loss: 0.19531302154064178
Validation loss: 1.6644928109261297

Epoch: 5| Step: 6
Training loss: 0.17143388092517853
Validation loss: 1.6847185627106698

Epoch: 5| Step: 7
Training loss: 0.34284818172454834
Validation loss: 1.6867959230176863

Epoch: 5| Step: 8
Training loss: 0.3675253689289093
Validation loss: 1.724154499269301

Epoch: 5| Step: 9
Training loss: 0.23153242468833923
Validation loss: 1.7024332720746276

Epoch: 5| Step: 10
Training loss: 0.5280704498291016
Validation loss: 1.668000812171608

Epoch: 395| Step: 0
Training loss: 0.31817737221717834
Validation loss: 1.6642296083511845

Epoch: 5| Step: 1
Training loss: 0.23360857367515564
Validation loss: 1.658267677471202

Epoch: 5| Step: 2
Training loss: 0.3899758756160736
Validation loss: 1.656138999487764

Epoch: 5| Step: 3
Training loss: 0.25566035509109497
Validation loss: 1.6630129955148185

Epoch: 5| Step: 4
Training loss: 0.25155091285705566
Validation loss: 1.6608484009260773

Epoch: 5| Step: 5
Training loss: 0.3233487010002136
Validation loss: 1.6613347863638273

Epoch: 5| Step: 6
Training loss: 0.5171297788619995
Validation loss: 1.6785055969351081

Epoch: 5| Step: 7
Training loss: 0.2396748960018158
Validation loss: 1.6962151437677362

Epoch: 5| Step: 8
Training loss: 0.185214564204216
Validation loss: 1.6581622054499965

Epoch: 5| Step: 9
Training loss: 0.37823057174682617
Validation loss: 1.6423487714541856

Epoch: 5| Step: 10
Training loss: 0.14353635907173157
Validation loss: 1.6547662250457271

Epoch: 396| Step: 0
Training loss: 0.30059099197387695
Validation loss: 1.6458733767591498

Epoch: 5| Step: 1
Training loss: 0.12728556990623474
Validation loss: 1.6300116956874888

Epoch: 5| Step: 2
Training loss: 0.23553816974163055
Validation loss: 1.6240725260908886

Epoch: 5| Step: 3
Training loss: 0.2525062561035156
Validation loss: 1.6314821345831758

Epoch: 5| Step: 4
Training loss: 0.32666540145874023
Validation loss: 1.6366501649220784

Epoch: 5| Step: 5
Training loss: 0.28303033113479614
Validation loss: 1.664964375957366

Epoch: 5| Step: 6
Training loss: 0.27075767517089844
Validation loss: 1.6959245807381087

Epoch: 5| Step: 7
Training loss: 0.4147692620754242
Validation loss: 1.6938294877288163

Epoch: 5| Step: 8
Training loss: 0.19995172321796417
Validation loss: 1.6891578429488725

Epoch: 5| Step: 9
Training loss: 0.3528134226799011
Validation loss: 1.6732761616347938

Epoch: 5| Step: 10
Training loss: 0.2599925696849823
Validation loss: 1.6586966488950996

Epoch: 397| Step: 0
Training loss: 0.16517594456672668
Validation loss: 1.66083098483342

Epoch: 5| Step: 1
Training loss: 0.17094388604164124
Validation loss: 1.6744142668221587

Epoch: 5| Step: 2
Training loss: 0.23096565902233124
Validation loss: 1.654607408790178

Epoch: 5| Step: 3
Training loss: 0.3802087604999542
Validation loss: 1.6380475105777863

Epoch: 5| Step: 4
Training loss: 0.15998652577400208
Validation loss: 1.6405497148472776

Epoch: 5| Step: 5
Training loss: 0.30406293272972107
Validation loss: 1.6312489137854627

Epoch: 5| Step: 6
Training loss: 0.27857762575149536
Validation loss: 1.6282671510532338

Epoch: 5| Step: 7
Training loss: 0.420544296503067
Validation loss: 1.6657739198336037

Epoch: 5| Step: 8
Training loss: 0.24722644686698914
Validation loss: 1.6397200733102777

Epoch: 5| Step: 9
Training loss: 0.20224037766456604
Validation loss: 1.638248271839593

Epoch: 5| Step: 10
Training loss: 0.2402045875787735
Validation loss: 1.6531220738605787

Epoch: 398| Step: 0
Training loss: 0.2546660900115967
Validation loss: 1.6295259844872259

Epoch: 5| Step: 1
Training loss: 0.1435706913471222
Validation loss: 1.6384936712121452

Epoch: 5| Step: 2
Training loss: 0.2835611402988434
Validation loss: 1.6589980356154903

Epoch: 5| Step: 3
Training loss: 0.28581151366233826
Validation loss: 1.658783197402954

Epoch: 5| Step: 4
Training loss: 0.22275066375732422
Validation loss: 1.6611729360395862

Epoch: 5| Step: 5
Training loss: 0.33216896653175354
Validation loss: 1.6492257041315879

Epoch: 5| Step: 6
Training loss: 0.2965676784515381
Validation loss: 1.6000901755466257

Epoch: 5| Step: 7
Training loss: 0.19544099271297455
Validation loss: 1.6366010103174435

Epoch: 5| Step: 8
Training loss: 0.1581614762544632
Validation loss: 1.6086372278069938

Epoch: 5| Step: 9
Training loss: 0.15201446413993835
Validation loss: 1.60428632972061

Epoch: 5| Step: 10
Training loss: 0.37966758012771606
Validation loss: 1.56703866809927

Epoch: 399| Step: 0
Training loss: 0.23930029571056366
Validation loss: 1.5978649790569017

Epoch: 5| Step: 1
Training loss: 0.26944655179977417
Validation loss: 1.5793817216350186

Epoch: 5| Step: 2
Training loss: 0.1889353096485138
Validation loss: 1.613599564439507

Epoch: 5| Step: 3
Training loss: 0.2917887568473816
Validation loss: 1.600506292876377

Epoch: 5| Step: 4
Training loss: 0.1745031327009201
Validation loss: 1.6328321182599632

Epoch: 5| Step: 5
Training loss: 0.28492647409439087
Validation loss: 1.6226441091106785

Epoch: 5| Step: 6
Training loss: 0.3337537944316864
Validation loss: 1.6084786166426956

Epoch: 5| Step: 7
Training loss: 0.19345593452453613
Validation loss: 1.6139682556993218

Epoch: 5| Step: 8
Training loss: 0.3653879165649414
Validation loss: 1.5888912754674112

Epoch: 5| Step: 9
Training loss: 0.27780064940452576
Validation loss: 1.622905054400044

Epoch: 5| Step: 10
Training loss: 0.1442367434501648
Validation loss: 1.6033325426040157

Epoch: 400| Step: 0
Training loss: 0.3181561827659607
Validation loss: 1.5927107616137433

Epoch: 5| Step: 1
Training loss: 0.3831166625022888
Validation loss: 1.6082366051212433

Epoch: 5| Step: 2
Training loss: 0.1787879467010498
Validation loss: 1.6328900937111146

Epoch: 5| Step: 3
Training loss: 0.2773131728172302
Validation loss: 1.6438654122814056

Epoch: 5| Step: 4
Training loss: 0.1771661788225174
Validation loss: 1.6190963624626078

Epoch: 5| Step: 5
Training loss: 0.33615031838417053
Validation loss: 1.6423022811130812

Epoch: 5| Step: 6
Training loss: 0.26482728123664856
Validation loss: 1.6393527074526715

Epoch: 5| Step: 7
Training loss: 0.2122877836227417
Validation loss: 1.660842757071218

Epoch: 5| Step: 8
Training loss: 0.1948540210723877
Validation loss: 1.659860630189219

Epoch: 5| Step: 9
Training loss: 0.21410760283470154
Validation loss: 1.6572935094115555

Epoch: 5| Step: 10
Training loss: 0.26141631603240967
Validation loss: 1.6667573477632256

Epoch: 401| Step: 0
Training loss: 0.3317776322364807
Validation loss: 1.6855525970458984

Epoch: 5| Step: 1
Training loss: 0.22536508738994598
Validation loss: 1.7106440644110403

Epoch: 5| Step: 2
Training loss: 0.24502773582935333
Validation loss: 1.6707998155265726

Epoch: 5| Step: 3
Training loss: 0.2574854791164398
Validation loss: 1.6685847902810702

Epoch: 5| Step: 4
Training loss: 0.37706664204597473
Validation loss: 1.6671315329049223

Epoch: 5| Step: 5
Training loss: 0.1950252503156662
Validation loss: 1.6647629494308143

Epoch: 5| Step: 6
Training loss: 0.2462710440158844
Validation loss: 1.6562967313233243

Epoch: 5| Step: 7
Training loss: 0.1978006809949875
Validation loss: 1.6493399015036962

Epoch: 5| Step: 8
Training loss: 0.24514052271842957
Validation loss: 1.6499008094110796

Epoch: 5| Step: 9
Training loss: 0.20399713516235352
Validation loss: 1.6456560524561072

Epoch: 5| Step: 10
Training loss: 0.2319645881652832
Validation loss: 1.694980549555953

Epoch: 402| Step: 0
Training loss: 0.26312822103500366
Validation loss: 1.7065935852707073

Epoch: 5| Step: 1
Training loss: 0.3082006573677063
Validation loss: 1.7084264883431055

Epoch: 5| Step: 2
Training loss: 0.1292717158794403
Validation loss: 1.704008662572471

Epoch: 5| Step: 3
Training loss: 0.3006783127784729
Validation loss: 1.7123869824153122

Epoch: 5| Step: 4
Training loss: 0.24059846997261047
Validation loss: 1.7177531488480107

Epoch: 5| Step: 5
Training loss: 0.13016946613788605
Validation loss: 1.7084080134668658

Epoch: 5| Step: 6
Training loss: 0.3114350438117981
Validation loss: 1.6599496692739508

Epoch: 5| Step: 7
Training loss: 0.3635757565498352
Validation loss: 1.698376456896464

Epoch: 5| Step: 8
Training loss: 0.15592318773269653
Validation loss: 1.6612604830854683

Epoch: 5| Step: 9
Training loss: 0.14233699440956116
Validation loss: 1.6637269950682116

Epoch: 5| Step: 10
Training loss: 0.2856367528438568
Validation loss: 1.6433847719623196

Epoch: 403| Step: 0
Training loss: 0.22903041541576385
Validation loss: 1.6244786221493956

Epoch: 5| Step: 1
Training loss: 0.1953987330198288
Validation loss: 1.636836237804864

Epoch: 5| Step: 2
Training loss: 0.07789158076047897
Validation loss: 1.6381075023322977

Epoch: 5| Step: 3
Training loss: 0.26496022939682007
Validation loss: 1.6347834089750886

Epoch: 5| Step: 4
Training loss: 0.22572310268878937
Validation loss: 1.6184942389047274

Epoch: 5| Step: 5
Training loss: 0.18430083990097046
Validation loss: 1.6387103975460093

Epoch: 5| Step: 6
Training loss: 0.3242621421813965
Validation loss: 1.627321897014495

Epoch: 5| Step: 7
Training loss: 0.3151916265487671
Validation loss: 1.6605488356723581

Epoch: 5| Step: 8
Training loss: 0.14683255553245544
Validation loss: 1.6456370328062324

Epoch: 5| Step: 9
Training loss: 0.16343256831169128
Validation loss: 1.6542896788607362

Epoch: 5| Step: 10
Training loss: 0.34606343507766724
Validation loss: 1.6621877749760945

Epoch: 404| Step: 0
Training loss: 0.169045552611351
Validation loss: 1.6417515047134892

Epoch: 5| Step: 1
Training loss: 0.15204009413719177
Validation loss: 1.6360289947960966

Epoch: 5| Step: 2
Training loss: 0.25334012508392334
Validation loss: 1.613929754944258

Epoch: 5| Step: 3
Training loss: 0.20233026146888733
Validation loss: 1.6463233296589186

Epoch: 5| Step: 4
Training loss: 0.19870798289775848
Validation loss: 1.6564226804241058

Epoch: 5| Step: 5
Training loss: 0.13252019882202148
Validation loss: 1.6470927602501326

Epoch: 5| Step: 6
Training loss: 0.22344127297401428
Validation loss: 1.6569863980816257

Epoch: 5| Step: 7
Training loss: 0.35227084159851074
Validation loss: 1.6677662185443345

Epoch: 5| Step: 8
Training loss: 0.3445051312446594
Validation loss: 1.6375177009131319

Epoch: 5| Step: 9
Training loss: 0.09433739632368088
Validation loss: 1.6786831014899797

Epoch: 5| Step: 10
Training loss: 0.3928551971912384
Validation loss: 1.637749756536176

Epoch: 405| Step: 0
Training loss: 0.23619994521141052
Validation loss: 1.672489579005908

Epoch: 5| Step: 1
Training loss: 0.18167193233966827
Validation loss: 1.660227669182644

Epoch: 5| Step: 2
Training loss: 0.1808014214038849
Validation loss: 1.661184823641213

Epoch: 5| Step: 3
Training loss: 0.23264174163341522
Validation loss: 1.6330005763679423

Epoch: 5| Step: 4
Training loss: 0.2362505942583084
Validation loss: 1.6779846106806109

Epoch: 5| Step: 5
Training loss: 0.29308709502220154
Validation loss: 1.6604729006367345

Epoch: 5| Step: 6
Training loss: 0.2011277675628662
Validation loss: 1.6410146310765257

Epoch: 5| Step: 7
Training loss: 0.27947843074798584
Validation loss: 1.6332152569165794

Epoch: 5| Step: 8
Training loss: 0.2888675332069397
Validation loss: 1.6281998413865284

Epoch: 5| Step: 9
Training loss: 0.22140195965766907
Validation loss: 1.614630171047744

Epoch: 5| Step: 10
Training loss: 0.2701556980609894
Validation loss: 1.6292296173751994

Epoch: 406| Step: 0
Training loss: 0.18375934660434723
Validation loss: 1.6735492829353578

Epoch: 5| Step: 1
Training loss: 0.1692216843366623
Validation loss: 1.6594007809956868

Epoch: 5| Step: 2
Training loss: 0.1155318170785904
Validation loss: 1.6482078593264344

Epoch: 5| Step: 3
Training loss: 0.3213742673397064
Validation loss: 1.6697694614369383

Epoch: 5| Step: 4
Training loss: 0.3071689009666443
Validation loss: 1.679656732466913

Epoch: 5| Step: 5
Training loss: 0.24672198295593262
Validation loss: 1.6815367539723713

Epoch: 5| Step: 6
Training loss: 0.2066965103149414
Validation loss: 1.6882768741217993

Epoch: 5| Step: 7
Training loss: 0.14992845058441162
Validation loss: 1.6649689520559003

Epoch: 5| Step: 8
Training loss: 0.2631990909576416
Validation loss: 1.6346052526145853

Epoch: 5| Step: 9
Training loss: 0.27149462699890137
Validation loss: 1.6303188018901373

Epoch: 5| Step: 10
Training loss: 0.24067595601081848
Validation loss: 1.574937694816179

Epoch: 407| Step: 0
Training loss: 0.24749541282653809
Validation loss: 1.58815078068805

Epoch: 5| Step: 1
Training loss: 0.23346510529518127
Validation loss: 1.6048462185808408

Epoch: 5| Step: 2
Training loss: 0.1568310558795929
Validation loss: 1.6248783142335954

Epoch: 5| Step: 3
Training loss: 0.12581267952919006
Validation loss: 1.623855443410976

Epoch: 5| Step: 4
Training loss: 0.21828961372375488
Validation loss: 1.6219941287912347

Epoch: 5| Step: 5
Training loss: 0.3951062858104706
Validation loss: 1.6077127200300976

Epoch: 5| Step: 6
Training loss: 0.14807264506816864
Validation loss: 1.5819854608146093

Epoch: 5| Step: 7
Training loss: 0.2852649688720703
Validation loss: 1.5930063442517353

Epoch: 5| Step: 8
Training loss: 0.21737948060035706
Validation loss: 1.6128109731981832

Epoch: 5| Step: 9
Training loss: 0.3702171742916107
Validation loss: 1.592118381172098

Epoch: 5| Step: 10
Training loss: 0.35119932889938354
Validation loss: 1.605883672673215

Epoch: 408| Step: 0
Training loss: 0.16940419375896454
Validation loss: 1.6459274779083908

Epoch: 5| Step: 1
Training loss: 0.22242751717567444
Validation loss: 1.6705291450664561

Epoch: 5| Step: 2
Training loss: 0.2034563273191452
Validation loss: 1.6477242067296018

Epoch: 5| Step: 3
Training loss: 0.217955082654953
Validation loss: 1.639114918247346

Epoch: 5| Step: 4
Training loss: 0.27071037888526917
Validation loss: 1.645930331240418

Epoch: 5| Step: 5
Training loss: 0.15055793523788452
Validation loss: 1.6138126196399811

Epoch: 5| Step: 6
Training loss: 0.26104968786239624
Validation loss: 1.638432264328003

Epoch: 5| Step: 7
Training loss: 0.17917096614837646
Validation loss: 1.6317990620930989

Epoch: 5| Step: 8
Training loss: 0.17741450667381287
Validation loss: 1.6542798165352113

Epoch: 5| Step: 9
Training loss: 0.3522389233112335
Validation loss: 1.6356267723985898

Epoch: 5| Step: 10
Training loss: 0.1823144406080246
Validation loss: 1.625627480527406

Epoch: 409| Step: 0
Training loss: 0.14974823594093323
Validation loss: 1.6289491550896757

Epoch: 5| Step: 1
Training loss: 0.16799932718276978
Validation loss: 1.6238452439667077

Epoch: 5| Step: 2
Training loss: 0.15242180228233337
Validation loss: 1.634563793418228

Epoch: 5| Step: 3
Training loss: 0.1784038543701172
Validation loss: 1.619915149545157

Epoch: 5| Step: 4
Training loss: 0.19021940231323242
Validation loss: 1.631420216252727

Epoch: 5| Step: 5
Training loss: 0.3298810124397278
Validation loss: 1.6480369772962344

Epoch: 5| Step: 6
Training loss: 0.4477076530456543
Validation loss: 1.6434438183743467

Epoch: 5| Step: 7
Training loss: 0.20077455043792725
Validation loss: 1.6309061191415275

Epoch: 5| Step: 8
Training loss: 0.21604979038238525
Validation loss: 1.587115717190568

Epoch: 5| Step: 9
Training loss: 0.1815248429775238
Validation loss: 1.6037306093400525

Epoch: 5| Step: 10
Training loss: 0.13640013337135315
Validation loss: 1.6083426936980216

Epoch: 410| Step: 0
Training loss: 0.2503412365913391
Validation loss: 1.5776331463167745

Epoch: 5| Step: 1
Training loss: 0.22464294731616974
Validation loss: 1.5965160131454468

Epoch: 5| Step: 2
Training loss: 0.1373460590839386
Validation loss: 1.6043511270194926

Epoch: 5| Step: 3
Training loss: 0.26380255818367004
Validation loss: 1.6314962051248039

Epoch: 5| Step: 4
Training loss: 0.15048734843730927
Validation loss: 1.6381613375038229

Epoch: 5| Step: 5
Training loss: 0.2778344452381134
Validation loss: 1.6221015581520655

Epoch: 5| Step: 6
Training loss: 0.21265283226966858
Validation loss: 1.619006231266965

Epoch: 5| Step: 7
Training loss: 0.15765567123889923
Validation loss: 1.6298714286537581

Epoch: 5| Step: 8
Training loss: 0.22750988602638245
Validation loss: 1.6366765063296083

Epoch: 5| Step: 9
Training loss: 0.3932226598262787
Validation loss: 1.612556347282984

Epoch: 5| Step: 10
Training loss: 0.2497006058692932
Validation loss: 1.6131862094325404

Epoch: 411| Step: 0
Training loss: 0.2601146101951599
Validation loss: 1.599845410675131

Epoch: 5| Step: 1
Training loss: 0.22138094902038574
Validation loss: 1.5811718099860734

Epoch: 5| Step: 2
Training loss: 0.22235620021820068
Validation loss: 1.5699504536967124

Epoch: 5| Step: 3
Training loss: 0.16135619580745697
Validation loss: 1.5943655826712166

Epoch: 5| Step: 4
Training loss: 0.19100376963615417
Validation loss: 1.6413226127624512

Epoch: 5| Step: 5
Training loss: 0.17354127764701843
Validation loss: 1.6340003077701857

Epoch: 5| Step: 6
Training loss: 0.342149943113327
Validation loss: 1.6377373587700628

Epoch: 5| Step: 7
Training loss: 0.13367959856987
Validation loss: 1.5985573004650813

Epoch: 5| Step: 8
Training loss: 0.2394910305738449
Validation loss: 1.5960593133844354

Epoch: 5| Step: 9
Training loss: 0.10262658447027206
Validation loss: 1.5820586758275186

Epoch: 5| Step: 10
Training loss: 0.39724409580230713
Validation loss: 1.6143539003146592

Epoch: 412| Step: 0
Training loss: 0.14528916776180267
Validation loss: 1.5904113464458014

Epoch: 5| Step: 1
Training loss: 0.18081754446029663
Validation loss: 1.5979113899251467

Epoch: 5| Step: 2
Training loss: 0.40640440583229065
Validation loss: 1.627606686084501

Epoch: 5| Step: 3
Training loss: 0.1589786261320114
Validation loss: 1.611023138928157

Epoch: 5| Step: 4
Training loss: 0.27288180589675903
Validation loss: 1.6286184967205088

Epoch: 5| Step: 5
Training loss: 0.22750544548034668
Validation loss: 1.6034606528538529

Epoch: 5| Step: 6
Training loss: 0.15731540322303772
Validation loss: 1.5899655447211316

Epoch: 5| Step: 7
Training loss: 0.08962879329919815
Validation loss: 1.5990674444424209

Epoch: 5| Step: 8
Training loss: 0.30301275849342346
Validation loss: 1.5994133667279316

Epoch: 5| Step: 9
Training loss: 0.23157362639904022
Validation loss: 1.6090321451105096

Epoch: 5| Step: 10
Training loss: 0.22396375238895416
Validation loss: 1.603537905600763

Epoch: 413| Step: 0
Training loss: 0.216499924659729
Validation loss: 1.590297936111368

Epoch: 5| Step: 1
Training loss: 0.2570595145225525
Validation loss: 1.6212415861827072

Epoch: 5| Step: 2
Training loss: 0.1513976752758026
Validation loss: 1.5894754432862805

Epoch: 5| Step: 3
Training loss: 0.2967141568660736
Validation loss: 1.5885798610666746

Epoch: 5| Step: 4
Training loss: 0.2583097517490387
Validation loss: 1.6023983417018768

Epoch: 5| Step: 5
Training loss: 0.27149659395217896
Validation loss: 1.618309340169353

Epoch: 5| Step: 6
Training loss: 0.1477438509464264
Validation loss: 1.6095825574731315

Epoch: 5| Step: 7
Training loss: 0.17845872044563293
Validation loss: 1.5975658624402937

Epoch: 5| Step: 8
Training loss: 0.22517409920692444
Validation loss: 1.6156756262625418

Epoch: 5| Step: 9
Training loss: 0.2566027343273163
Validation loss: 1.6062331968738186

Epoch: 5| Step: 10
Training loss: 0.181672602891922
Validation loss: 1.6165915612251527

Epoch: 414| Step: 0
Training loss: 0.2961065173149109
Validation loss: 1.631160008010044

Epoch: 5| Step: 1
Training loss: 0.18565338850021362
Validation loss: 1.6066569410344607

Epoch: 5| Step: 2
Training loss: 0.24674466252326965
Validation loss: 1.6368724530743015

Epoch: 5| Step: 3
Training loss: 0.2644215524196625
Validation loss: 1.633954289138958

Epoch: 5| Step: 4
Training loss: 0.2772994637489319
Validation loss: 1.6380181504834084

Epoch: 5| Step: 5
Training loss: 0.11226711422204971
Validation loss: 1.623328407605489

Epoch: 5| Step: 6
Training loss: 0.11295263469219208
Validation loss: 1.6003563327174033

Epoch: 5| Step: 7
Training loss: 0.182185098528862
Validation loss: 1.6112167642962547

Epoch: 5| Step: 8
Training loss: 0.2514454424381256
Validation loss: 1.6193806599545222

Epoch: 5| Step: 9
Training loss: 0.16181044280529022
Validation loss: 1.5847091341531405

Epoch: 5| Step: 10
Training loss: 0.2706558406352997
Validation loss: 1.6263681842434792

Epoch: 415| Step: 0
Training loss: 0.2284328043460846
Validation loss: 1.583588497613066

Epoch: 5| Step: 1
Training loss: 0.1850372552871704
Validation loss: 1.5733550953608688

Epoch: 5| Step: 2
Training loss: 0.13842375576496124
Validation loss: 1.5608467427633141

Epoch: 5| Step: 3
Training loss: 0.21412496268749237
Validation loss: 1.5804886843568535

Epoch: 5| Step: 4
Training loss: 0.316681832075119
Validation loss: 1.5862363230797552

Epoch: 5| Step: 5
Training loss: 0.20687253773212433
Validation loss: 1.6006026652551466

Epoch: 5| Step: 6
Training loss: 0.3361958861351013
Validation loss: 1.6063876639130295

Epoch: 5| Step: 7
Training loss: 0.13851892948150635
Validation loss: 1.6329282060746224

Epoch: 5| Step: 8
Training loss: 0.19920696318149567
Validation loss: 1.6436562217691892

Epoch: 5| Step: 9
Training loss: 0.20225057005882263
Validation loss: 1.6419977231692242

Epoch: 5| Step: 10
Training loss: 0.17099422216415405
Validation loss: 1.638302710748488

Epoch: 416| Step: 0
Training loss: 0.21876683831214905
Validation loss: 1.6228653038701704

Epoch: 5| Step: 1
Training loss: 0.21392269432544708
Validation loss: 1.645389820939751

Epoch: 5| Step: 2
Training loss: 0.20285053551197052
Validation loss: 1.6339729255245579

Epoch: 5| Step: 3
Training loss: 0.15318267047405243
Validation loss: 1.6497359480909122

Epoch: 5| Step: 4
Training loss: 0.20130237936973572
Validation loss: 1.6301312344048613

Epoch: 5| Step: 5
Training loss: 0.18745319545269012
Validation loss: 1.650583879922026

Epoch: 5| Step: 6
Training loss: 0.33392366766929626
Validation loss: 1.6250814827539588

Epoch: 5| Step: 7
Training loss: 0.15019020438194275
Validation loss: 1.6324395133603005

Epoch: 5| Step: 8
Training loss: 0.16971027851104736
Validation loss: 1.657117091199403

Epoch: 5| Step: 9
Training loss: 0.273827463388443
Validation loss: 1.6480450322551112

Epoch: 5| Step: 10
Training loss: 0.20401452481746674
Validation loss: 1.6174056491544169

Epoch: 417| Step: 0
Training loss: 0.21763093769550323
Validation loss: 1.6361311404935774

Epoch: 5| Step: 1
Training loss: 0.17295421659946442
Validation loss: 1.6335492672458771

Epoch: 5| Step: 2
Training loss: 0.1910296380519867
Validation loss: 1.6080342826022898

Epoch: 5| Step: 3
Training loss: 0.1587301790714264
Validation loss: 1.601242173102594

Epoch: 5| Step: 4
Training loss: 0.3392844498157501
Validation loss: 1.6077349442307667

Epoch: 5| Step: 5
Training loss: 0.1470986157655716
Validation loss: 1.6018910561838458

Epoch: 5| Step: 6
Training loss: 0.201420858502388
Validation loss: 1.6069990563136276

Epoch: 5| Step: 7
Training loss: 0.24143755435943604
Validation loss: 1.5926666900675783

Epoch: 5| Step: 8
Training loss: 0.32366225123405457
Validation loss: 1.5960878800320368

Epoch: 5| Step: 9
Training loss: 0.11427773535251617
Validation loss: 1.5829313096179758

Epoch: 5| Step: 10
Training loss: 0.15732549130916595
Validation loss: 1.5827153677581458

Epoch: 418| Step: 0
Training loss: 0.22302977740764618
Validation loss: 1.6035682232149187

Epoch: 5| Step: 1
Training loss: 0.1868346929550171
Validation loss: 1.604580831784074

Epoch: 5| Step: 2
Training loss: 0.21722273528575897
Validation loss: 1.613299560803239

Epoch: 5| Step: 3
Training loss: 0.17667964100837708
Validation loss: 1.6142223650409329

Epoch: 5| Step: 4
Training loss: 0.174411341547966
Validation loss: 1.592996556271789

Epoch: 5| Step: 5
Training loss: 0.12586793303489685
Validation loss: 1.585469006210245

Epoch: 5| Step: 6
Training loss: 0.1482473909854889
Validation loss: 1.5836898229455436

Epoch: 5| Step: 7
Training loss: 0.10914206504821777
Validation loss: 1.580213580080258

Epoch: 5| Step: 8
Training loss: 0.30946558713912964
Validation loss: 1.5974388199467813

Epoch: 5| Step: 9
Training loss: 0.20145273208618164
Validation loss: 1.599203004631945

Epoch: 5| Step: 10
Training loss: 0.2892936170101166
Validation loss: 1.5650461207153976

Epoch: 419| Step: 0
Training loss: 0.1492689847946167
Validation loss: 1.5763701533758512

Epoch: 5| Step: 1
Training loss: 0.08142875134944916
Validation loss: 1.5662347860233758

Epoch: 5| Step: 2
Training loss: 0.24419501423835754
Validation loss: 1.5234057006015573

Epoch: 5| Step: 3
Training loss: 0.26976126432418823
Validation loss: 1.5565225424305085

Epoch: 5| Step: 4
Training loss: 0.19157204031944275
Validation loss: 1.541125250119035

Epoch: 5| Step: 5
Training loss: 0.1891418695449829
Validation loss: 1.5741026452792588

Epoch: 5| Step: 6
Training loss: 0.1726137101650238
Validation loss: 1.5890754986834783

Epoch: 5| Step: 7
Training loss: 0.29938024282455444
Validation loss: 1.581345215920479

Epoch: 5| Step: 8
Training loss: 0.3270576000213623
Validation loss: 1.625507236808859

Epoch: 5| Step: 9
Training loss: 0.3423912525177002
Validation loss: 1.6388846289726995

Epoch: 5| Step: 10
Training loss: 0.20320147275924683
Validation loss: 1.6285521074007916

Epoch: 420| Step: 0
Training loss: 0.28297170996665955
Validation loss: 1.619125626420462

Epoch: 5| Step: 1
Training loss: 0.13375435769557953
Validation loss: 1.603913495617528

Epoch: 5| Step: 2
Training loss: 0.1845897138118744
Validation loss: 1.5999792878345778

Epoch: 5| Step: 3
Training loss: 0.1535017192363739
Validation loss: 1.5825290615840624

Epoch: 5| Step: 4
Training loss: 0.1855679601430893
Validation loss: 1.563512957865192

Epoch: 5| Step: 5
Training loss: 0.24013285338878632
Validation loss: 1.5758427343060892

Epoch: 5| Step: 6
Training loss: 0.10844745486974716
Validation loss: 1.5780132034773469

Epoch: 5| Step: 7
Training loss: 0.22324106097221375
Validation loss: 1.5934879292723954

Epoch: 5| Step: 8
Training loss: 0.31349459290504456
Validation loss: 1.622895852211983

Epoch: 5| Step: 9
Training loss: 0.24744096398353577
Validation loss: 1.5995375392257527

Epoch: 5| Step: 10
Training loss: 0.24083563685417175
Validation loss: 1.6230608993960964

Epoch: 421| Step: 0
Training loss: 0.2033940553665161
Validation loss: 1.6337181432272798

Epoch: 5| Step: 1
Training loss: 0.1772753894329071
Validation loss: 1.6251387890949045

Epoch: 5| Step: 2
Training loss: 0.06851869821548462
Validation loss: 1.6223309142615205

Epoch: 5| Step: 3
Training loss: 0.12405482679605484
Validation loss: 1.615628009201378

Epoch: 5| Step: 4
Training loss: 0.1650467813014984
Validation loss: 1.624130989274671

Epoch: 5| Step: 5
Training loss: 0.2886742651462555
Validation loss: 1.627801659286663

Epoch: 5| Step: 6
Training loss: 0.21307817101478577
Validation loss: 1.6158180403453049

Epoch: 5| Step: 7
Training loss: 0.27666205167770386
Validation loss: 1.631916796007464

Epoch: 5| Step: 8
Training loss: 0.23299355804920197
Validation loss: 1.6194329953962756

Epoch: 5| Step: 9
Training loss: 0.2500118613243103
Validation loss: 1.6277539826208545

Epoch: 5| Step: 10
Training loss: 0.1643117219209671
Validation loss: 1.6384666978671987

Epoch: 422| Step: 0
Training loss: 0.17634424567222595
Validation loss: 1.641770439763223

Epoch: 5| Step: 1
Training loss: 0.14939963817596436
Validation loss: 1.622248544487902

Epoch: 5| Step: 2
Training loss: 0.31622153520584106
Validation loss: 1.6347770690917969

Epoch: 5| Step: 3
Training loss: 0.14275676012039185
Validation loss: 1.5781139340451968

Epoch: 5| Step: 4
Training loss: 0.09822486340999603
Validation loss: 1.5952434821795392

Epoch: 5| Step: 5
Training loss: 0.10199426114559174
Validation loss: 1.618076891027471

Epoch: 5| Step: 6
Training loss: 0.2404908388853073
Validation loss: 1.6061722258085847

Epoch: 5| Step: 7
Training loss: 0.18359236419200897
Validation loss: 1.602713365708628

Epoch: 5| Step: 8
Training loss: 0.1749870479106903
Validation loss: 1.6107851856498308

Epoch: 5| Step: 9
Training loss: 0.2613077461719513
Validation loss: 1.583200285511632

Epoch: 5| Step: 10
Training loss: 0.28630709648132324
Validation loss: 1.5885132243556361

Epoch: 423| Step: 0
Training loss: 0.17576704919338226
Validation loss: 1.6036847868273336

Epoch: 5| Step: 1
Training loss: 0.2981491982936859
Validation loss: 1.5935503129036195

Epoch: 5| Step: 2
Training loss: 0.16838613152503967
Validation loss: 1.5876830188176965

Epoch: 5| Step: 3
Training loss: 0.14386847615242004
Validation loss: 1.5869797814276911

Epoch: 5| Step: 4
Training loss: 0.14427947998046875
Validation loss: 1.5992081370404971

Epoch: 5| Step: 5
Training loss: 0.13556209206581116
Validation loss: 1.6194771630789644

Epoch: 5| Step: 6
Training loss: 0.2037537544965744
Validation loss: 1.60796405038526

Epoch: 5| Step: 7
Training loss: 0.16315491497516632
Validation loss: 1.6141693771526378

Epoch: 5| Step: 8
Training loss: 0.23099717497825623
Validation loss: 1.601888188751795

Epoch: 5| Step: 9
Training loss: 0.2235812246799469
Validation loss: 1.6109672605350454

Epoch: 5| Step: 10
Training loss: 0.22856219112873077
Validation loss: 1.5821603190514348

Epoch: 424| Step: 0
Training loss: 0.24270038306713104
Validation loss: 1.5970184854281846

Epoch: 5| Step: 1
Training loss: 0.22191452980041504
Validation loss: 1.5891118511076896

Epoch: 5| Step: 2
Training loss: 0.2104417085647583
Validation loss: 1.5858229796091716

Epoch: 5| Step: 3
Training loss: 0.185298889875412
Validation loss: 1.5656122276859898

Epoch: 5| Step: 4
Training loss: 0.22135381400585175
Validation loss: 1.590580653118831

Epoch: 5| Step: 5
Training loss: 0.11705471575260162
Validation loss: 1.563984022345594

Epoch: 5| Step: 6
Training loss: 0.11308841407299042
Validation loss: 1.5788604021072388

Epoch: 5| Step: 7
Training loss: 0.3152143061161041
Validation loss: 1.5793343481197153

Epoch: 5| Step: 8
Training loss: 0.1829831898212433
Validation loss: 1.602631768872661

Epoch: 5| Step: 9
Training loss: 0.11900411546230316
Validation loss: 1.5809251916023992

Epoch: 5| Step: 10
Training loss: 0.15229998528957367
Validation loss: 1.6029433165827105

Epoch: 425| Step: 0
Training loss: 0.15452663600444794
Validation loss: 1.5915278696244763

Epoch: 5| Step: 1
Training loss: 0.18567213416099548
Validation loss: 1.6318823791319323

Epoch: 5| Step: 2
Training loss: 0.20718255639076233
Validation loss: 1.6323986925104612

Epoch: 5| Step: 3
Training loss: 0.15598519146442413
Validation loss: 1.6434091009119505

Epoch: 5| Step: 4
Training loss: 0.29420900344848633
Validation loss: 1.6414080486502698

Epoch: 5| Step: 5
Training loss: 0.25886058807373047
Validation loss: 1.6142559282241329

Epoch: 5| Step: 6
Training loss: 0.26431578397750854
Validation loss: 1.570829673479962

Epoch: 5| Step: 7
Training loss: 0.11944892257452011
Validation loss: 1.5649489933444607

Epoch: 5| Step: 8
Training loss: 0.19808520376682281
Validation loss: 1.5706454553911764

Epoch: 5| Step: 9
Training loss: 0.19270920753479004
Validation loss: 1.5614163362851707

Epoch: 5| Step: 10
Training loss: 0.176660418510437
Validation loss: 1.5828365933510564

Epoch: 426| Step: 0
Training loss: 0.3027316927909851
Validation loss: 1.553076333256178

Epoch: 5| Step: 1
Training loss: 0.18611936271190643
Validation loss: 1.5561763560900124

Epoch: 5| Step: 2
Training loss: 0.20164713263511658
Validation loss: 1.6070482756501885

Epoch: 5| Step: 3
Training loss: 0.17149165272712708
Validation loss: 1.6020996442405127

Epoch: 5| Step: 4
Training loss: 0.30139684677124023
Validation loss: 1.5795285753024522

Epoch: 5| Step: 5
Training loss: 0.08016566932201385
Validation loss: 1.6256686026050198

Epoch: 5| Step: 6
Training loss: 0.2633812427520752
Validation loss: 1.6481378373279367

Epoch: 5| Step: 7
Training loss: 0.15613070130348206
Validation loss: 1.607526607410882

Epoch: 5| Step: 8
Training loss: 0.28901657462120056
Validation loss: 1.6350446426740257

Epoch: 5| Step: 9
Training loss: 0.131916344165802
Validation loss: 1.6411306550425868

Epoch: 5| Step: 10
Training loss: 0.12358763813972473
Validation loss: 1.6024909391198108

Epoch: 427| Step: 0
Training loss: 0.19168773293495178
Validation loss: 1.6487432872095416

Epoch: 5| Step: 1
Training loss: 0.16359511017799377
Validation loss: 1.6335952461406749

Epoch: 5| Step: 2
Training loss: 0.1622600555419922
Validation loss: 1.6301357284668954

Epoch: 5| Step: 3
Training loss: 0.19214266538619995
Validation loss: 1.6170771839798137

Epoch: 5| Step: 4
Training loss: 0.19190236926078796
Validation loss: 1.6214510330589869

Epoch: 5| Step: 5
Training loss: 0.11994694173336029
Validation loss: 1.6140710141069146

Epoch: 5| Step: 6
Training loss: 0.2801935076713562
Validation loss: 1.6044937923390379

Epoch: 5| Step: 7
Training loss: 0.2755444645881653
Validation loss: 1.61233635487095

Epoch: 5| Step: 8
Training loss: 0.15549898147583008
Validation loss: 1.6183056100722282

Epoch: 5| Step: 9
Training loss: 0.31954532861709595
Validation loss: 1.6036022657989173

Epoch: 5| Step: 10
Training loss: 0.19985277950763702
Validation loss: 1.594613867421304

Epoch: 428| Step: 0
Training loss: 0.1455964744091034
Validation loss: 1.595470546394266

Epoch: 5| Step: 1
Training loss: 0.24604983627796173
Validation loss: 1.5830397490532166

Epoch: 5| Step: 2
Training loss: 0.17388157546520233
Validation loss: 1.5965336574021207

Epoch: 5| Step: 3
Training loss: 0.1989227533340454
Validation loss: 1.6074595271900136

Epoch: 5| Step: 4
Training loss: 0.21671025454998016
Validation loss: 1.6001808028067313

Epoch: 5| Step: 5
Training loss: 0.18771550059318542
Validation loss: 1.6097071145170478

Epoch: 5| Step: 6
Training loss: 0.2521545886993408
Validation loss: 1.610718906566661

Epoch: 5| Step: 7
Training loss: 0.05356069654226303
Validation loss: 1.632651521313575

Epoch: 5| Step: 8
Training loss: 0.15859314799308777
Validation loss: 1.599822998046875

Epoch: 5| Step: 9
Training loss: 0.3761400580406189
Validation loss: 1.6179441803245134

Epoch: 5| Step: 10
Training loss: 0.09267665445804596
Validation loss: 1.6120256538032203

Epoch: 429| Step: 0
Training loss: 0.272935688495636
Validation loss: 1.5992383521090272

Epoch: 5| Step: 1
Training loss: 0.1600433588027954
Validation loss: 1.5791931498435237

Epoch: 5| Step: 2
Training loss: 0.21160845458507538
Validation loss: 1.571332149608161

Epoch: 5| Step: 3
Training loss: 0.23795504868030548
Validation loss: 1.570154595118697

Epoch: 5| Step: 4
Training loss: 0.26365360617637634
Validation loss: 1.6154398238787087

Epoch: 5| Step: 5
Training loss: 0.19450047612190247
Validation loss: 1.5931296630572247

Epoch: 5| Step: 6
Training loss: 0.15598689019680023
Validation loss: 1.6229362603156798

Epoch: 5| Step: 7
Training loss: 0.06471463292837143
Validation loss: 1.6084084472348612

Epoch: 5| Step: 8
Training loss: 0.25197872519493103
Validation loss: 1.599679764880929

Epoch: 5| Step: 9
Training loss: 0.11369854211807251
Validation loss: 1.6082160665142922

Epoch: 5| Step: 10
Training loss: 0.212620347738266
Validation loss: 1.6298178947100075

Epoch: 430| Step: 0
Training loss: 0.29096657037734985
Validation loss: 1.6498793837844685

Epoch: 5| Step: 1
Training loss: 0.18906399607658386
Validation loss: 1.6262870321991623

Epoch: 5| Step: 2
Training loss: 0.2282075583934784
Validation loss: 1.6464861105847102

Epoch: 5| Step: 3
Training loss: 0.22872063517570496
Validation loss: 1.6283851080043341

Epoch: 5| Step: 4
Training loss: 0.1986900418996811
Validation loss: 1.6467743048103907

Epoch: 5| Step: 5
Training loss: 0.18881535530090332
Validation loss: 1.654307198780839

Epoch: 5| Step: 6
Training loss: 0.2593800127506256
Validation loss: 1.6516849687022548

Epoch: 5| Step: 7
Training loss: 0.20429691672325134
Validation loss: 1.6212886969248455

Epoch: 5| Step: 8
Training loss: 0.2974182367324829
Validation loss: 1.5869531054650583

Epoch: 5| Step: 9
Training loss: 0.14270420372486115
Validation loss: 1.5653207379002725

Epoch: 5| Step: 10
Training loss: 0.17712895572185516
Validation loss: 1.5688225799991238

Epoch: 431| Step: 0
Training loss: 0.23702716827392578
Validation loss: 1.5558251155320035

Epoch: 5| Step: 1
Training loss: 0.3720324635505676
Validation loss: 1.5444531402280253

Epoch: 5| Step: 2
Training loss: 0.19170182943344116
Validation loss: 1.587736036187859

Epoch: 5| Step: 3
Training loss: 0.18934334814548492
Validation loss: 1.5654038549751363

Epoch: 5| Step: 4
Training loss: 0.20451441407203674
Validation loss: 1.5675033933372908

Epoch: 5| Step: 5
Training loss: 0.14785537123680115
Validation loss: 1.5726299215388555

Epoch: 5| Step: 6
Training loss: 0.2148018777370453
Validation loss: 1.5770137617664952

Epoch: 5| Step: 7
Training loss: 0.08991706371307373
Validation loss: 1.6040065788453626

Epoch: 5| Step: 8
Training loss: 0.25627174973487854
Validation loss: 1.5960434739307692

Epoch: 5| Step: 9
Training loss: 0.16174189746379852
Validation loss: 1.6119614878008444

Epoch: 5| Step: 10
Training loss: 0.11524954438209534
Validation loss: 1.607136421306159

Epoch: 432| Step: 0
Training loss: 0.28882110118865967
Validation loss: 1.5983398755391438

Epoch: 5| Step: 1
Training loss: 0.18942272663116455
Validation loss: 1.642036690506884

Epoch: 5| Step: 2
Training loss: 0.11175882816314697
Validation loss: 1.6109319809944398

Epoch: 5| Step: 3
Training loss: 0.14514395594596863
Validation loss: 1.6214442932477562

Epoch: 5| Step: 4
Training loss: 0.24012479186058044
Validation loss: 1.6369298773427163

Epoch: 5| Step: 5
Training loss: 0.1496841460466385
Validation loss: 1.6355483621679328

Epoch: 5| Step: 6
Training loss: 0.20685425400733948
Validation loss: 1.6447957010679348

Epoch: 5| Step: 7
Training loss: 0.3216124176979065
Validation loss: 1.6460200945536296

Epoch: 5| Step: 8
Training loss: 0.21979360282421112
Validation loss: 1.6409682983993201

Epoch: 5| Step: 9
Training loss: 0.21923883259296417
Validation loss: 1.6339937153682913

Epoch: 5| Step: 10
Training loss: 0.11416979134082794
Validation loss: 1.6434290767997823

Epoch: 433| Step: 0
Training loss: 0.09803028404712677
Validation loss: 1.601924269430099

Epoch: 5| Step: 1
Training loss: 0.1694311946630478
Validation loss: 1.6343408592285649

Epoch: 5| Step: 2
Training loss: 0.2067507952451706
Validation loss: 1.6302082948787238

Epoch: 5| Step: 3
Training loss: 0.1488819420337677
Validation loss: 1.6095926453990321

Epoch: 5| Step: 4
Training loss: 0.17843489348888397
Validation loss: 1.5962077315135668

Epoch: 5| Step: 5
Training loss: 0.16168968379497528
Validation loss: 1.621971203434852

Epoch: 5| Step: 6
Training loss: 0.1351419985294342
Validation loss: 1.6232438664282522

Epoch: 5| Step: 7
Training loss: 0.2688976228237152
Validation loss: 1.6319942410274217

Epoch: 5| Step: 8
Training loss: 0.1984921246767044
Validation loss: 1.6007551967456777

Epoch: 5| Step: 9
Training loss: 0.24627022445201874
Validation loss: 1.6082987913521387

Epoch: 5| Step: 10
Training loss: 0.1586053967475891
Validation loss: 1.6150402138310094

Epoch: 434| Step: 0
Training loss: 0.1603921502828598
Validation loss: 1.6056009108020413

Epoch: 5| Step: 1
Training loss: 0.22825570404529572
Validation loss: 1.6190466342433807

Epoch: 5| Step: 2
Training loss: 0.1533203423023224
Validation loss: 1.6234085226571688

Epoch: 5| Step: 3
Training loss: 0.17367514967918396
Validation loss: 1.6139655651584748

Epoch: 5| Step: 4
Training loss: 0.17049983143806458
Validation loss: 1.6050415346699376

Epoch: 5| Step: 5
Training loss: 0.13704071938991547
Validation loss: 1.590064021848863

Epoch: 5| Step: 6
Training loss: 0.2404930591583252
Validation loss: 1.5885393542628135

Epoch: 5| Step: 7
Training loss: 0.1736297309398651
Validation loss: 1.5827126067171815

Epoch: 5| Step: 8
Training loss: 0.17017371952533722
Validation loss: 1.577419659142853

Epoch: 5| Step: 9
Training loss: 0.1769871860742569
Validation loss: 1.5584274479137954

Epoch: 5| Step: 10
Training loss: 0.17556405067443848
Validation loss: 1.5744913316542102

Epoch: 435| Step: 0
Training loss: 0.18001478910446167
Validation loss: 1.5960693897739533

Epoch: 5| Step: 1
Training loss: 0.1243942603468895
Validation loss: 1.58527825596512

Epoch: 5| Step: 2
Training loss: 0.22936351597309113
Validation loss: 1.6032324016735118

Epoch: 5| Step: 3
Training loss: 0.17246676981449127
Validation loss: 1.5769952112628567

Epoch: 5| Step: 4
Training loss: 0.18082097172737122
Validation loss: 1.5929334836621438

Epoch: 5| Step: 5
Training loss: 0.06941758841276169
Validation loss: 1.597122073173523

Epoch: 5| Step: 6
Training loss: 0.2443757802248001
Validation loss: 1.5866462684446765

Epoch: 5| Step: 7
Training loss: 0.23969390988349915
Validation loss: 1.5786102625631517

Epoch: 5| Step: 8
Training loss: 0.3437325358390808
Validation loss: 1.5855611678092711

Epoch: 5| Step: 9
Training loss: 0.19313287734985352
Validation loss: 1.5774134474415933

Epoch: 5| Step: 10
Training loss: 0.1796700656414032
Validation loss: 1.5910902356588712

Epoch: 436| Step: 0
Training loss: 0.12722189724445343
Validation loss: 1.5683834257946219

Epoch: 5| Step: 1
Training loss: 0.17838063836097717
Validation loss: 1.569343739940274

Epoch: 5| Step: 2
Training loss: 0.13732677698135376
Validation loss: 1.633582208746223

Epoch: 5| Step: 3
Training loss: 0.3381299376487732
Validation loss: 1.636479800747287

Epoch: 5| Step: 4
Training loss: 0.2068360298871994
Validation loss: 1.6038450682035057

Epoch: 5| Step: 5
Training loss: 0.12007094919681549
Validation loss: 1.634097054440488

Epoch: 5| Step: 6
Training loss: 0.126888245344162
Validation loss: 1.6146695203678583

Epoch: 5| Step: 7
Training loss: 0.10040073096752167
Validation loss: 1.6165169554371988

Epoch: 5| Step: 8
Training loss: 0.11102016270160675
Validation loss: 1.5788902531387985

Epoch: 5| Step: 9
Training loss: 0.21860189735889435
Validation loss: 1.5644796702169603

Epoch: 5| Step: 10
Training loss: 0.25697606801986694
Validation loss: 1.5746504260647682

Epoch: 437| Step: 0
Training loss: 0.2612994313240051
Validation loss: 1.5745924108771867

Epoch: 5| Step: 1
Training loss: 0.10144446790218353
Validation loss: 1.5704516069863432

Epoch: 5| Step: 2
Training loss: 0.17715966701507568
Validation loss: 1.5665062723621246

Epoch: 5| Step: 3
Training loss: 0.18452873826026917
Validation loss: 1.5635918225011518

Epoch: 5| Step: 4
Training loss: 0.20246867835521698
Validation loss: 1.5478847642098703

Epoch: 5| Step: 5
Training loss: 0.15002058446407318
Validation loss: 1.5665246619973132

Epoch: 5| Step: 6
Training loss: 0.12012909352779388
Validation loss: 1.5560802785299157

Epoch: 5| Step: 7
Training loss: 0.16647498309612274
Validation loss: 1.560117825385063

Epoch: 5| Step: 8
Training loss: 0.27158620953559875
Validation loss: 1.5489958306794525

Epoch: 5| Step: 9
Training loss: 0.14241740107536316
Validation loss: 1.5692433567457302

Epoch: 5| Step: 10
Training loss: 0.12302418053150177
Validation loss: 1.5785567914285967

Epoch: 438| Step: 0
Training loss: 0.2639995813369751
Validation loss: 1.5842498528060092

Epoch: 5| Step: 1
Training loss: 0.08720836788415909
Validation loss: 1.5676827046179003

Epoch: 5| Step: 2
Training loss: 0.24160882830619812
Validation loss: 1.5783771558474469

Epoch: 5| Step: 3
Training loss: 0.053790636360645294
Validation loss: 1.5605198170549126

Epoch: 5| Step: 4
Training loss: 0.21609728038311005
Validation loss: 1.5718357563018799

Epoch: 5| Step: 5
Training loss: 0.13634592294692993
Validation loss: 1.588459535311627

Epoch: 5| Step: 6
Training loss: 0.17557470500469208
Validation loss: 1.5466677783637919

Epoch: 5| Step: 7
Training loss: 0.2271416187286377
Validation loss: 1.5525968049162178

Epoch: 5| Step: 8
Training loss: 0.15310291945934296
Validation loss: 1.5473565318251168

Epoch: 5| Step: 9
Training loss: 0.19992020726203918
Validation loss: 1.5430109244520946

Epoch: 5| Step: 10
Training loss: 0.13783398270606995
Validation loss: 1.5589028327695784

Epoch: 439| Step: 0
Training loss: 0.0976540818810463
Validation loss: 1.565410722968399

Epoch: 5| Step: 1
Training loss: 0.28008657693862915
Validation loss: 1.5685478718050065

Epoch: 5| Step: 2
Training loss: 0.13226313889026642
Validation loss: 1.568033851603026

Epoch: 5| Step: 3
Training loss: 0.13031207025051117
Validation loss: 1.5979814811419415

Epoch: 5| Step: 4
Training loss: 0.13978204131126404
Validation loss: 1.5880837722491192

Epoch: 5| Step: 5
Training loss: 0.21769504249095917
Validation loss: 1.5786055262370775

Epoch: 5| Step: 6
Training loss: 0.14468343555927277
Validation loss: 1.5852418420135335

Epoch: 5| Step: 7
Training loss: 0.19563670456409454
Validation loss: 1.6187370746366438

Epoch: 5| Step: 8
Training loss: 0.31166893243789673
Validation loss: 1.5470363247779109

Epoch: 5| Step: 9
Training loss: 0.13520996272563934
Validation loss: 1.5729554571131223

Epoch: 5| Step: 10
Training loss: 0.14715424180030823
Validation loss: 1.5598402113042853

Epoch: 440| Step: 0
Training loss: 0.14334328472614288
Validation loss: 1.5665179574361412

Epoch: 5| Step: 1
Training loss: 0.1389322727918625
Validation loss: 1.6121385212867492

Epoch: 5| Step: 2
Training loss: 0.14397254586219788
Validation loss: 1.6128154031692012

Epoch: 5| Step: 3
Training loss: 0.1449621021747589
Validation loss: 1.6068815851724276

Epoch: 5| Step: 4
Training loss: 0.2032817304134369
Validation loss: 1.6217593172545075

Epoch: 5| Step: 5
Training loss: 0.14382675290107727
Validation loss: 1.621002640775455

Epoch: 5| Step: 6
Training loss: 0.17265301942825317
Validation loss: 1.594412847231793

Epoch: 5| Step: 7
Training loss: 0.2233639508485794
Validation loss: 1.6001543511626541

Epoch: 5| Step: 8
Training loss: 0.17440679669380188
Validation loss: 1.5604705272182342

Epoch: 5| Step: 9
Training loss: 0.25987643003463745
Validation loss: 1.5841235306955153

Epoch: 5| Step: 10
Training loss: 0.13010317087173462
Validation loss: 1.570624707847513

Epoch: 441| Step: 0
Training loss: 0.22358985245227814
Validation loss: 1.5723224634765296

Epoch: 5| Step: 1
Training loss: 0.20249171555042267
Validation loss: 1.5758939225186583

Epoch: 5| Step: 2
Training loss: 0.1320549100637436
Validation loss: 1.5677876510927755

Epoch: 5| Step: 3
Training loss: 0.3299083113670349
Validation loss: 1.5663185568266018

Epoch: 5| Step: 4
Training loss: 0.13701489567756653
Validation loss: 1.543342395495343

Epoch: 5| Step: 5
Training loss: 0.17273782193660736
Validation loss: 1.5640956535134265

Epoch: 5| Step: 6
Training loss: 0.12367544323205948
Validation loss: 1.5569401838446175

Epoch: 5| Step: 7
Training loss: 0.1889728605747223
Validation loss: 1.5768898584509408

Epoch: 5| Step: 8
Training loss: 0.17625875771045685
Validation loss: 1.5831482487340127

Epoch: 5| Step: 9
Training loss: 0.18186503648757935
Validation loss: 1.5897537380136468

Epoch: 5| Step: 10
Training loss: 0.11668233573436737
Validation loss: 1.5648011251162457

Epoch: 442| Step: 0
Training loss: 0.1948961615562439
Validation loss: 1.5545153963950373

Epoch: 5| Step: 1
Training loss: 0.13495759665966034
Validation loss: 1.5442457929734261

Epoch: 5| Step: 2
Training loss: 0.15503069758415222
Validation loss: 1.5781691420462824

Epoch: 5| Step: 3
Training loss: 0.38454848527908325
Validation loss: 1.5816668413018669

Epoch: 5| Step: 4
Training loss: 0.20582923293113708
Validation loss: 1.5693816459307106

Epoch: 5| Step: 5
Training loss: 0.20610928535461426
Validation loss: 1.6008841273605183

Epoch: 5| Step: 6
Training loss: 0.11735652387142181
Validation loss: 1.6117220899110198

Epoch: 5| Step: 7
Training loss: 0.3302672505378723
Validation loss: 1.6334831317265828

Epoch: 5| Step: 8
Training loss: 0.20989640057086945
Validation loss: 1.6544208283065467

Epoch: 5| Step: 9
Training loss: 0.2967958450317383
Validation loss: 1.671726256288508

Epoch: 5| Step: 10
Training loss: 0.1590760052204132
Validation loss: 1.6309748593197073

Epoch: 443| Step: 0
Training loss: 0.13174283504486084
Validation loss: 1.5768448409213816

Epoch: 5| Step: 1
Training loss: 0.15413078665733337
Validation loss: 1.544050407666032

Epoch: 5| Step: 2
Training loss: 0.13385145366191864
Validation loss: 1.567309767969193

Epoch: 5| Step: 3
Training loss: 0.19844797253608704
Validation loss: 1.5633777277443999

Epoch: 5| Step: 4
Training loss: 0.20129399001598358
Validation loss: 1.5436797295847247

Epoch: 5| Step: 5
Training loss: 0.2858564257621765
Validation loss: 1.5742993764979865

Epoch: 5| Step: 6
Training loss: 0.22363801300525665
Validation loss: 1.5330081498751076

Epoch: 5| Step: 7
Training loss: 0.2104073464870453
Validation loss: 1.5396439119051861

Epoch: 5| Step: 8
Training loss: 0.16629073023796082
Validation loss: 1.5411200202921385

Epoch: 5| Step: 9
Training loss: 0.2796097695827484
Validation loss: 1.6211032431612733

Epoch: 5| Step: 10
Training loss: 0.2233419418334961
Validation loss: 1.5829339988770024

Epoch: 444| Step: 0
Training loss: 0.10376320779323578
Validation loss: 1.5602466662724812

Epoch: 5| Step: 1
Training loss: 0.10246074199676514
Validation loss: 1.5620750919465096

Epoch: 5| Step: 2
Training loss: 0.14944060146808624
Validation loss: 1.5491995619189354

Epoch: 5| Step: 3
Training loss: 0.11183378845453262
Validation loss: 1.5818157266545039

Epoch: 5| Step: 4
Training loss: 0.17073312401771545
Validation loss: 1.5639030536015828

Epoch: 5| Step: 5
Training loss: 0.3606184124946594
Validation loss: 1.5623979158298944

Epoch: 5| Step: 6
Training loss: 0.22652840614318848
Validation loss: 1.5500074304560179

Epoch: 5| Step: 7
Training loss: 0.2736770808696747
Validation loss: 1.5553904130894651

Epoch: 5| Step: 8
Training loss: 0.23850348591804504
Validation loss: 1.552590504769356

Epoch: 5| Step: 9
Training loss: 0.13715414702892303
Validation loss: 1.6156717320924163

Epoch: 5| Step: 10
Training loss: 0.3459168076515198
Validation loss: 1.6053511865677372

Epoch: 445| Step: 0
Training loss: 0.18197838962078094
Validation loss: 1.6047895762228197

Epoch: 5| Step: 1
Training loss: 0.26654118299484253
Validation loss: 1.5943592568879486

Epoch: 5| Step: 2
Training loss: 0.18988637626171112
Validation loss: 1.5455330982003161

Epoch: 5| Step: 3
Training loss: 0.19983652234077454
Validation loss: 1.5331522085333382

Epoch: 5| Step: 4
Training loss: 0.11082231998443604
Validation loss: 1.514639994470022

Epoch: 5| Step: 5
Training loss: 0.1432439684867859
Validation loss: 1.5258056015096686

Epoch: 5| Step: 6
Training loss: 0.1903904229402542
Validation loss: 1.5434488519545524

Epoch: 5| Step: 7
Training loss: 0.1893572360277176
Validation loss: 1.5484744169378792

Epoch: 5| Step: 8
Training loss: 0.11410252749919891
Validation loss: 1.5594369980596727

Epoch: 5| Step: 9
Training loss: 0.17201626300811768
Validation loss: 1.5884028775717622

Epoch: 5| Step: 10
Training loss: 0.5117999911308289
Validation loss: 1.6221793543907903

Epoch: 446| Step: 0
Training loss: 0.33893829584121704
Validation loss: 1.6116033971950572

Epoch: 5| Step: 1
Training loss: 0.1614522635936737
Validation loss: 1.5949558481093375

Epoch: 5| Step: 2
Training loss: 0.1362788826227188
Validation loss: 1.5962543526003439

Epoch: 5| Step: 3
Training loss: 0.13840191066265106
Validation loss: 1.5817345162873626

Epoch: 5| Step: 4
Training loss: 0.10377862304449081
Validation loss: 1.5920266412919568

Epoch: 5| Step: 5
Training loss: 0.21916131675243378
Validation loss: 1.5850165095380557

Epoch: 5| Step: 6
Training loss: 0.21481843292713165
Validation loss: 1.5732621377514255

Epoch: 5| Step: 7
Training loss: 0.1755053550004959
Validation loss: 1.559805113782165

Epoch: 5| Step: 8
Training loss: 0.15484650433063507
Validation loss: 1.572629746570382

Epoch: 5| Step: 9
Training loss: 0.20605072379112244
Validation loss: 1.5656119444036996

Epoch: 5| Step: 10
Training loss: 0.10828614979982376
Validation loss: 1.5794417050576979

Epoch: 447| Step: 0
Training loss: 0.2671724855899811
Validation loss: 1.557785536653252

Epoch: 5| Step: 1
Training loss: 0.1632750928401947
Validation loss: 1.5798109282729447

Epoch: 5| Step: 2
Training loss: 0.2402230203151703
Validation loss: 1.5616488738726544

Epoch: 5| Step: 3
Training loss: 0.1082826629281044
Validation loss: 1.5650491304295038

Epoch: 5| Step: 4
Training loss: 0.18578417599201202
Validation loss: 1.5627546848789338

Epoch: 5| Step: 5
Training loss: 0.11663243919610977
Validation loss: 1.5818446092708136

Epoch: 5| Step: 6
Training loss: 0.19760513305664062
Validation loss: 1.5604688493154382

Epoch: 5| Step: 7
Training loss: 0.1843251883983612
Validation loss: 1.568438869650646

Epoch: 5| Step: 8
Training loss: 0.28162771463394165
Validation loss: 1.5709494442068122

Epoch: 5| Step: 9
Training loss: 0.15278156101703644
Validation loss: 1.5612661812895088

Epoch: 5| Step: 10
Training loss: 0.1658707559108734
Validation loss: 1.5623260698010843

Epoch: 448| Step: 0
Training loss: 0.2421928197145462
Validation loss: 1.5722476436245827

Epoch: 5| Step: 1
Training loss: 0.25507354736328125
Validation loss: 1.6115220592867943

Epoch: 5| Step: 2
Training loss: 0.19435620307922363
Validation loss: 1.5891990328347811

Epoch: 5| Step: 3
Training loss: 0.15234549343585968
Validation loss: 1.611256786572036

Epoch: 5| Step: 4
Training loss: 0.1314716935157776
Validation loss: 1.6086632718322098

Epoch: 5| Step: 5
Training loss: 0.12646536529064178
Validation loss: 1.6127568983262586

Epoch: 5| Step: 6
Training loss: 0.17119991779327393
Validation loss: 1.6154530176552393

Epoch: 5| Step: 7
Training loss: 0.2593652307987213
Validation loss: 1.6207829854821647

Epoch: 5| Step: 8
Training loss: 0.13019070029258728
Validation loss: 1.6019584453234108

Epoch: 5| Step: 9
Training loss: 0.1985170841217041
Validation loss: 1.6365250361863004

Epoch: 5| Step: 10
Training loss: 0.20750272274017334
Validation loss: 1.6460750705452376

Epoch: 449| Step: 0
Training loss: 0.17520637810230255
Validation loss: 1.6266942806141351

Epoch: 5| Step: 1
Training loss: 0.26843756437301636
Validation loss: 1.6202150198721117

Epoch: 5| Step: 2
Training loss: 0.23097388446331024
Validation loss: 1.6131621612015592

Epoch: 5| Step: 3
Training loss: 0.10497403144836426
Validation loss: 1.6035549909837785

Epoch: 5| Step: 4
Training loss: 0.14844712615013123
Validation loss: 1.6057612895965576

Epoch: 5| Step: 5
Training loss: 0.12914441525936127
Validation loss: 1.577523011033253

Epoch: 5| Step: 6
Training loss: 0.20744459331035614
Validation loss: 1.5724417458298385

Epoch: 5| Step: 7
Training loss: 0.3025928735733032
Validation loss: 1.589846105985744

Epoch: 5| Step: 8
Training loss: 0.08223672956228256
Validation loss: 1.5635931402124383

Epoch: 5| Step: 9
Training loss: 0.1263500154018402
Validation loss: 1.559335829109274

Epoch: 5| Step: 10
Training loss: 0.25211289525032043
Validation loss: 1.5734929615451443

Epoch: 450| Step: 0
Training loss: 0.15810467302799225
Validation loss: 1.5756191207516579

Epoch: 5| Step: 1
Training loss: 0.1944473683834076
Validation loss: 1.5920767258572321

Epoch: 5| Step: 2
Training loss: 0.21464352309703827
Validation loss: 1.566045138143724

Epoch: 5| Step: 3
Training loss: 0.20965346693992615
Validation loss: 1.5899029361304415

Epoch: 5| Step: 4
Training loss: 0.22868971526622772
Validation loss: 1.5944032040975427

Epoch: 5| Step: 5
Training loss: 0.14211095869541168
Validation loss: 1.5831239229889327

Epoch: 5| Step: 6
Training loss: 0.14321303367614746
Validation loss: 1.612989923005463

Epoch: 5| Step: 7
Training loss: 0.2222994863986969
Validation loss: 1.5993888506325342

Epoch: 5| Step: 8
Training loss: 0.18725597858428955
Validation loss: 1.5868708831007763

Epoch: 5| Step: 9
Training loss: 0.1367468684911728
Validation loss: 1.5873501480266612

Epoch: 5| Step: 10
Training loss: 0.10196007788181305
Validation loss: 1.586336967765644

Epoch: 451| Step: 0
Training loss: 0.16692093014717102
Validation loss: 1.5471067441407071

Epoch: 5| Step: 1
Training loss: 0.17463921010494232
Validation loss: 1.5636960908930788

Epoch: 5| Step: 2
Training loss: 0.23279984295368195
Validation loss: 1.5474736254702333

Epoch: 5| Step: 3
Training loss: 0.2373969852924347
Validation loss: 1.5221414860858713

Epoch: 5| Step: 4
Training loss: 0.18444600701332092
Validation loss: 1.5466922713864235

Epoch: 5| Step: 5
Training loss: 0.1152145117521286
Validation loss: 1.5507689650340746

Epoch: 5| Step: 6
Training loss: 0.19718727469444275
Validation loss: 1.5684558768426218

Epoch: 5| Step: 7
Training loss: 0.11574921756982803
Validation loss: 1.5753937126487814

Epoch: 5| Step: 8
Training loss: 0.17687590420246124
Validation loss: 1.570465786482698

Epoch: 5| Step: 9
Training loss: 0.1415293961763382
Validation loss: 1.5890927289121894

Epoch: 5| Step: 10
Training loss: 0.1414634734392166
Validation loss: 1.5775197808460524

Epoch: 452| Step: 0
Training loss: 0.16914594173431396
Validation loss: 1.574635769731255

Epoch: 5| Step: 1
Training loss: 0.15997202694416046
Validation loss: 1.5831354228399133

Epoch: 5| Step: 2
Training loss: 0.09804557263851166
Validation loss: 1.5833927444232407

Epoch: 5| Step: 3
Training loss: 0.14134535193443298
Validation loss: 1.5637313101881294

Epoch: 5| Step: 4
Training loss: 0.19858257472515106
Validation loss: 1.590091142603146

Epoch: 5| Step: 5
Training loss: 0.1834871917963028
Validation loss: 1.5737114702501604

Epoch: 5| Step: 6
Training loss: 0.1362898349761963
Validation loss: 1.5778705048304733

Epoch: 5| Step: 7
Training loss: 0.24098071455955505
Validation loss: 1.5630241312006468

Epoch: 5| Step: 8
Training loss: 0.24355792999267578
Validation loss: 1.5887137254079182

Epoch: 5| Step: 9
Training loss: 0.13981099426746368
Validation loss: 1.5703673644732403

Epoch: 5| Step: 10
Training loss: 0.07105051726102829
Validation loss: 1.5977297905952699

Epoch: 453| Step: 0
Training loss: 0.11043895781040192
Validation loss: 1.6147710225915397

Epoch: 5| Step: 1
Training loss: 0.10492531955242157
Validation loss: 1.5923804698451873

Epoch: 5| Step: 2
Training loss: 0.1326073706150055
Validation loss: 1.58608676028508

Epoch: 5| Step: 3
Training loss: 0.11148855835199356
Validation loss: 1.5879755084232619

Epoch: 5| Step: 4
Training loss: 0.14784379303455353
Validation loss: 1.5744108820474276

Epoch: 5| Step: 5
Training loss: 0.1524316966533661
Validation loss: 1.5883409387321883

Epoch: 5| Step: 6
Training loss: 0.12648749351501465
Validation loss: 1.613787586970996

Epoch: 5| Step: 7
Training loss: 0.1549064815044403
Validation loss: 1.600662431409282

Epoch: 5| Step: 8
Training loss: 0.24044223129749298
Validation loss: 1.6111090593440558

Epoch: 5| Step: 9
Training loss: 0.1429639607667923
Validation loss: 1.5790038390826153

Epoch: 5| Step: 10
Training loss: 0.24126574397087097
Validation loss: 1.5869440654272675

Epoch: 454| Step: 0
Training loss: 0.2828056216239929
Validation loss: 1.6036696254566152

Epoch: 5| Step: 1
Training loss: 0.12473621219396591
Validation loss: 1.6020508671319613

Epoch: 5| Step: 2
Training loss: 0.11889274418354034
Validation loss: 1.5799780154740939

Epoch: 5| Step: 3
Training loss: 0.09537582844495773
Validation loss: 1.5790044338472429

Epoch: 5| Step: 4
Training loss: 0.16308185458183289
Validation loss: 1.5602744907461188

Epoch: 5| Step: 5
Training loss: 0.12648579478263855
Validation loss: 1.5674111766199912

Epoch: 5| Step: 6
Training loss: 0.15818457305431366
Validation loss: 1.5733214988503406

Epoch: 5| Step: 7
Training loss: 0.1153525561094284
Validation loss: 1.5816113564275927

Epoch: 5| Step: 8
Training loss: 0.15100786089897156
Validation loss: 1.5646156623799314

Epoch: 5| Step: 9
Training loss: 0.2296338826417923
Validation loss: 1.5681843103901032

Epoch: 5| Step: 10
Training loss: 0.07780900597572327
Validation loss: 1.56406186216621

Epoch: 455| Step: 0
Training loss: 0.19761750102043152
Validation loss: 1.5509171024445565

Epoch: 5| Step: 1
Training loss: 0.2081582248210907
Validation loss: 1.5722731057033743

Epoch: 5| Step: 2
Training loss: 0.09189850091934204
Validation loss: 1.5764668744097474

Epoch: 5| Step: 3
Training loss: 0.12847691774368286
Validation loss: 1.554066401655956

Epoch: 5| Step: 4
Training loss: 0.15692618489265442
Validation loss: 1.594537966994829

Epoch: 5| Step: 5
Training loss: 0.09878034889698029
Validation loss: 1.6022019655473771

Epoch: 5| Step: 6
Training loss: 0.15597355365753174
Validation loss: 1.5885362279030584

Epoch: 5| Step: 7
Training loss: 0.16467344760894775
Validation loss: 1.627250268254229

Epoch: 5| Step: 8
Training loss: 0.28275591135025024
Validation loss: 1.603763202185272

Epoch: 5| Step: 9
Training loss: 0.1575370728969574
Validation loss: 1.5939603774778304

Epoch: 5| Step: 10
Training loss: 0.1395198553800583
Validation loss: 1.603278229313512

Epoch: 456| Step: 0
Training loss: 0.2601388394832611
Validation loss: 1.614338069833735

Epoch: 5| Step: 1
Training loss: 0.11333765089511871
Validation loss: 1.6097926824323592

Epoch: 5| Step: 2
Training loss: 0.20294106006622314
Validation loss: 1.597384774556724

Epoch: 5| Step: 3
Training loss: 0.10667691379785538
Validation loss: 1.6199321067461403

Epoch: 5| Step: 4
Training loss: 0.19919615983963013
Validation loss: 1.6045386752774637

Epoch: 5| Step: 5
Training loss: 0.0916382223367691
Validation loss: 1.587171745556657

Epoch: 5| Step: 6
Training loss: 0.1989675760269165
Validation loss: 1.5887742529633224

Epoch: 5| Step: 7
Training loss: 0.14962923526763916
Validation loss: 1.5459611928591164

Epoch: 5| Step: 8
Training loss: 0.19704574346542358
Validation loss: 1.5523150044102823

Epoch: 5| Step: 9
Training loss: 0.14318789541721344
Validation loss: 1.5574531849994455

Epoch: 5| Step: 10
Training loss: 0.08461586385965347
Validation loss: 1.5318066041956666

Epoch: 457| Step: 0
Training loss: 0.11114431917667389
Validation loss: 1.549754870835171

Epoch: 5| Step: 1
Training loss: 0.1940406858921051
Validation loss: 1.5381418466567993

Epoch: 5| Step: 2
Training loss: 0.13631956279277802
Validation loss: 1.592413862546285

Epoch: 5| Step: 3
Training loss: 0.21494178473949432
Validation loss: 1.5777255873526297

Epoch: 5| Step: 4
Training loss: 0.157186359167099
Validation loss: 1.5827997653715071

Epoch: 5| Step: 5
Training loss: 0.11715781688690186
Validation loss: 1.588706490814045

Epoch: 5| Step: 6
Training loss: 0.20097282528877258
Validation loss: 1.5609003254162368

Epoch: 5| Step: 7
Training loss: 0.15201878547668457
Validation loss: 1.5725078121308358

Epoch: 5| Step: 8
Training loss: 0.14460228383541107
Validation loss: 1.5687192973270212

Epoch: 5| Step: 9
Training loss: 0.30016252398490906
Validation loss: 1.6092370504974036

Epoch: 5| Step: 10
Training loss: 0.12708541750907898
Validation loss: 1.601839602634471

Epoch: 458| Step: 0
Training loss: 0.22360053658485413
Validation loss: 1.606435480938163

Epoch: 5| Step: 1
Training loss: 0.1343848705291748
Validation loss: 1.6005354824886526

Epoch: 5| Step: 2
Training loss: 0.23225128650665283
Validation loss: 1.6137909632857128

Epoch: 5| Step: 3
Training loss: 0.1438508927822113
Validation loss: 1.613358204082776

Epoch: 5| Step: 4
Training loss: 0.1979619562625885
Validation loss: 1.602211183117282

Epoch: 5| Step: 5
Training loss: 0.10833163559436798
Validation loss: 1.5851038130380775

Epoch: 5| Step: 6
Training loss: 0.21922390162944794
Validation loss: 1.6010200631233953

Epoch: 5| Step: 7
Training loss: 0.18963982164859772
Validation loss: 1.580297472656414

Epoch: 5| Step: 8
Training loss: 0.09271568804979324
Validation loss: 1.5736289806263422

Epoch: 5| Step: 9
Training loss: 0.16167819499969482
Validation loss: 1.5618467882115354

Epoch: 5| Step: 10
Training loss: 0.16146603226661682
Validation loss: 1.5834307644956855

Epoch: 459| Step: 0
Training loss: 0.2695857286453247
Validation loss: 1.5579428775336153

Epoch: 5| Step: 1
Training loss: 0.24634027481079102
Validation loss: 1.5949667448638587

Epoch: 5| Step: 2
Training loss: 0.13944926857948303
Validation loss: 1.57076265991375

Epoch: 5| Step: 3
Training loss: 0.12175203859806061
Validation loss: 1.5525659156102005

Epoch: 5| Step: 4
Training loss: 0.18408167362213135
Validation loss: 1.555839620610719

Epoch: 5| Step: 5
Training loss: 0.11613323539495468
Validation loss: 1.561525949867823

Epoch: 5| Step: 6
Training loss: 0.11196956783533096
Validation loss: 1.5587179686433525

Epoch: 5| Step: 7
Training loss: 0.1281193196773529
Validation loss: 1.564906345900669

Epoch: 5| Step: 8
Training loss: 0.1355685293674469
Validation loss: 1.56995782672718

Epoch: 5| Step: 9
Training loss: 0.11664450168609619
Validation loss: 1.5912765123510872

Epoch: 5| Step: 10
Training loss: 0.18550725281238556
Validation loss: 1.6056814808999338

Epoch: 460| Step: 0
Training loss: 0.1405111849308014
Validation loss: 1.5766099499117943

Epoch: 5| Step: 1
Training loss: 0.1360696256160736
Validation loss: 1.6031704762930512

Epoch: 5| Step: 2
Training loss: 0.17321984469890594
Validation loss: 1.580354267551053

Epoch: 5| Step: 3
Training loss: 0.16273149847984314
Validation loss: 1.5972887034057288

Epoch: 5| Step: 4
Training loss: 0.11971187591552734
Validation loss: 1.5807743418601252

Epoch: 5| Step: 5
Training loss: 0.17625078558921814
Validation loss: 1.571479332062506

Epoch: 5| Step: 6
Training loss: 0.2072841376066208
Validation loss: 1.5843429642338906

Epoch: 5| Step: 7
Training loss: 0.18701566755771637
Validation loss: 1.5850512340504637

Epoch: 5| Step: 8
Training loss: 0.18759402632713318
Validation loss: 1.5922692270689114

Epoch: 5| Step: 9
Training loss: 0.238881915807724
Validation loss: 1.5872106129123318

Epoch: 5| Step: 10
Training loss: 0.12868718802928925
Validation loss: 1.5779109565160607

Epoch: 461| Step: 0
Training loss: 0.1325540989637375
Validation loss: 1.5851486306036673

Epoch: 5| Step: 1
Training loss: 0.17415070533752441
Validation loss: 1.5920364267082625

Epoch: 5| Step: 2
Training loss: 0.1881754845380783
Validation loss: 1.5597800875222811

Epoch: 5| Step: 3
Training loss: 0.16345569491386414
Validation loss: 1.5879835582548572

Epoch: 5| Step: 4
Training loss: 0.2583070397377014
Validation loss: 1.575291754097067

Epoch: 5| Step: 5
Training loss: 0.21265116333961487
Validation loss: 1.57396028887841

Epoch: 5| Step: 6
Training loss: 0.2751654088497162
Validation loss: 1.5706857365946616

Epoch: 5| Step: 7
Training loss: 0.10219142585992813
Validation loss: 1.5796509378699846

Epoch: 5| Step: 8
Training loss: 0.11233949661254883
Validation loss: 1.560404928781653

Epoch: 5| Step: 9
Training loss: 0.12305513769388199
Validation loss: 1.5864206206414007

Epoch: 5| Step: 10
Training loss: 0.12466111034154892
Validation loss: 1.5791979912788636

Epoch: 462| Step: 0
Training loss: 0.09798397123813629
Validation loss: 1.5802158847931893

Epoch: 5| Step: 1
Training loss: 0.11452732235193253
Validation loss: 1.5677832813673123

Epoch: 5| Step: 2
Training loss: 0.12382849305868149
Validation loss: 1.5917346426235732

Epoch: 5| Step: 3
Training loss: 0.1662561595439911
Validation loss: 1.5724287673991213

Epoch: 5| Step: 4
Training loss: 0.21682462096214294
Validation loss: 1.5902970228143918

Epoch: 5| Step: 5
Training loss: 0.1603761464357376
Validation loss: 1.5737077600212508

Epoch: 5| Step: 6
Training loss: 0.12333204597234726
Validation loss: 1.5824496476880965

Epoch: 5| Step: 7
Training loss: 0.3226141631603241
Validation loss: 1.5766607817783151

Epoch: 5| Step: 8
Training loss: 0.1556963324546814
Validation loss: 1.5924646585218367

Epoch: 5| Step: 9
Training loss: 0.13558277487754822
Validation loss: 1.5935417323984125

Epoch: 5| Step: 10
Training loss: 0.08890905976295471
Validation loss: 1.5868576431787142

Epoch: 463| Step: 0
Training loss: 0.0953575074672699
Validation loss: 1.604271060676985

Epoch: 5| Step: 1
Training loss: 0.10607688128948212
Validation loss: 1.621994985047207

Epoch: 5| Step: 2
Training loss: 0.13475990295410156
Validation loss: 1.6016144739684237

Epoch: 5| Step: 3
Training loss: 0.2598944306373596
Validation loss: 1.5900908259935276

Epoch: 5| Step: 4
Training loss: 0.22274620831012726
Validation loss: 1.6027686852280811

Epoch: 5| Step: 5
Training loss: 0.13729122281074524
Validation loss: 1.5673361657768168

Epoch: 5| Step: 6
Training loss: 0.15911343693733215
Validation loss: 1.574058243023452

Epoch: 5| Step: 7
Training loss: 0.15385612845420837
Validation loss: 1.5379625315307288

Epoch: 5| Step: 8
Training loss: 0.17386002838611603
Validation loss: 1.542966326077779

Epoch: 5| Step: 9
Training loss: 0.14453570544719696
Validation loss: 1.5469461717913229

Epoch: 5| Step: 10
Training loss: 0.2118053287267685
Validation loss: 1.539087737760236

Epoch: 464| Step: 0
Training loss: 0.15661872923374176
Validation loss: 1.5404930159609804

Epoch: 5| Step: 1
Training loss: 0.15120846033096313
Validation loss: 1.549466824018827

Epoch: 5| Step: 2
Training loss: 0.18234603106975555
Validation loss: 1.5479920051431144

Epoch: 5| Step: 3
Training loss: 0.16295115649700165
Validation loss: 1.5951863399115942

Epoch: 5| Step: 4
Training loss: 0.16976067423820496
Validation loss: 1.5848281716787687

Epoch: 5| Step: 5
Training loss: 0.12787342071533203
Validation loss: 1.598658601442973

Epoch: 5| Step: 6
Training loss: 0.12128134071826935
Validation loss: 1.59205715117916

Epoch: 5| Step: 7
Training loss: 0.0820084661245346
Validation loss: 1.5985566275094145

Epoch: 5| Step: 8
Training loss: 0.14803245663642883
Validation loss: 1.559125441376881

Epoch: 5| Step: 9
Training loss: 0.19475357234477997
Validation loss: 1.5934885176279212

Epoch: 5| Step: 10
Training loss: 0.28517377376556396
Validation loss: 1.5726460769612303

Epoch: 465| Step: 0
Training loss: 0.14306309819221497
Validation loss: 1.5702066806054884

Epoch: 5| Step: 1
Training loss: 0.10004550218582153
Validation loss: 1.5363340070170741

Epoch: 5| Step: 2
Training loss: 0.06929229944944382
Validation loss: 1.5487098822029688

Epoch: 5| Step: 3
Training loss: 0.10132227092981339
Validation loss: 1.5444031671811176

Epoch: 5| Step: 4
Training loss: 0.12428776174783707
Validation loss: 1.588718755270845

Epoch: 5| Step: 5
Training loss: 0.1695026457309723
Validation loss: 1.5635066006773262

Epoch: 5| Step: 6
Training loss: 0.1518973559141159
Validation loss: 1.5783443425291328

Epoch: 5| Step: 7
Training loss: 0.16101446747779846
Validation loss: 1.579257724105671

Epoch: 5| Step: 8
Training loss: 0.2606794834136963
Validation loss: 1.5689689574703094

Epoch: 5| Step: 9
Training loss: 0.1635192632675171
Validation loss: 1.5650225083033245

Epoch: 5| Step: 10
Training loss: 0.3226524293422699
Validation loss: 1.5864258632865003

Epoch: 466| Step: 0
Training loss: 0.2296716272830963
Validation loss: 1.58556188947411

Epoch: 5| Step: 1
Training loss: 0.1884489357471466
Validation loss: 1.5661268375253166

Epoch: 5| Step: 2
Training loss: 0.19733503460884094
Validation loss: 1.5480903528069938

Epoch: 5| Step: 3
Training loss: 0.22518739104270935
Validation loss: 1.5769318201208626

Epoch: 5| Step: 4
Training loss: 0.07897228002548218
Validation loss: 1.6108552281574537

Epoch: 5| Step: 5
Training loss: 0.1571868658065796
Validation loss: 1.5898669201840636

Epoch: 5| Step: 6
Training loss: 0.10236582905054092
Validation loss: 1.6225077747016825

Epoch: 5| Step: 7
Training loss: 0.18226340413093567
Validation loss: 1.6186989148457844

Epoch: 5| Step: 8
Training loss: 0.1608491837978363
Validation loss: 1.6109613744161462

Epoch: 5| Step: 9
Training loss: 0.09113337099552155
Validation loss: 1.5886587019889586

Epoch: 5| Step: 10
Training loss: 0.17431218922138214
Validation loss: 1.5476082140399563

Epoch: 467| Step: 0
Training loss: 0.08765742927789688
Validation loss: 1.5566689134925924

Epoch: 5| Step: 1
Training loss: 0.1606096625328064
Validation loss: 1.5198572867660112

Epoch: 5| Step: 2
Training loss: 0.1753455251455307
Validation loss: 1.5308186597721551

Epoch: 5| Step: 3
Training loss: 0.16792842745780945
Validation loss: 1.5390287983802058

Epoch: 5| Step: 4
Training loss: 0.18803556263446808
Validation loss: 1.5558488061351161

Epoch: 5| Step: 5
Training loss: 0.13275036215782166
Validation loss: 1.5851971603208972

Epoch: 5| Step: 6
Training loss: 0.22633640468120575
Validation loss: 1.580823786797062

Epoch: 5| Step: 7
Training loss: 0.10716605186462402
Validation loss: 1.5853549408656296

Epoch: 5| Step: 8
Training loss: 0.17048616707324982
Validation loss: 1.603066175214706

Epoch: 5| Step: 9
Training loss: 0.18948647379875183
Validation loss: 1.6265448472833122

Epoch: 5| Step: 10
Training loss: 0.2569772005081177
Validation loss: 1.6108964899534821

Epoch: 468| Step: 0
Training loss: 0.15751439332962036
Validation loss: 1.6224599525492678

Epoch: 5| Step: 1
Training loss: 0.12112988531589508
Validation loss: 1.5920647055872026

Epoch: 5| Step: 2
Training loss: 0.19602516293525696
Validation loss: 1.5947730092592136

Epoch: 5| Step: 3
Training loss: 0.15027926862239838
Validation loss: 1.5768763455011512

Epoch: 5| Step: 4
Training loss: 0.12528358399868011
Validation loss: 1.5735249878257833

Epoch: 5| Step: 5
Training loss: 0.3011377453804016
Validation loss: 1.556247873972821

Epoch: 5| Step: 6
Training loss: 0.13871362805366516
Validation loss: 1.5620709029577111

Epoch: 5| Step: 7
Training loss: 0.16231201589107513
Validation loss: 1.573025248383963

Epoch: 5| Step: 8
Training loss: 0.21473988890647888
Validation loss: 1.5805392137137793

Epoch: 5| Step: 9
Training loss: 0.14786916971206665
Validation loss: 1.5699229663418186

Epoch: 5| Step: 10
Training loss: 0.10750730335712433
Validation loss: 1.5651763844233688

Epoch: 469| Step: 0
Training loss: 0.25831618905067444
Validation loss: 1.5324597121566854

Epoch: 5| Step: 1
Training loss: 0.11262525618076324
Validation loss: 1.589597354653061

Epoch: 5| Step: 2
Training loss: 0.08921028673648834
Validation loss: 1.5511147347829675

Epoch: 5| Step: 3
Training loss: 0.22294409573078156
Validation loss: 1.5856766566153495

Epoch: 5| Step: 4
Training loss: 0.14333108067512512
Validation loss: 1.5889913369250555

Epoch: 5| Step: 5
Training loss: 0.17708918452262878
Validation loss: 1.6159056758367887

Epoch: 5| Step: 6
Training loss: 0.16392220556735992
Validation loss: 1.586010935486004

Epoch: 5| Step: 7
Training loss: 0.1612566113471985
Validation loss: 1.5992792062861945

Epoch: 5| Step: 8
Training loss: 0.1995045244693756
Validation loss: 1.5769317214206984

Epoch: 5| Step: 9
Training loss: 0.10749796777963638
Validation loss: 1.5523073968066965

Epoch: 5| Step: 10
Training loss: 0.14351840317249298
Validation loss: 1.594167952255536

Epoch: 470| Step: 0
Training loss: 0.21852675080299377
Validation loss: 1.5643672609841952

Epoch: 5| Step: 1
Training loss: 0.19374537467956543
Validation loss: 1.5587088215735652

Epoch: 5| Step: 2
Training loss: 0.1108093112707138
Validation loss: 1.5795944429213

Epoch: 5| Step: 3
Training loss: 0.23075051605701447
Validation loss: 1.6076383295879568

Epoch: 5| Step: 4
Training loss: 0.12960241734981537
Validation loss: 1.594624860312349

Epoch: 5| Step: 5
Training loss: 0.16366267204284668
Validation loss: 1.596387517067694

Epoch: 5| Step: 6
Training loss: 0.12198873609304428
Validation loss: 1.5882019778733611

Epoch: 5| Step: 7
Training loss: 0.17722544074058533
Validation loss: 1.5797420265854045

Epoch: 5| Step: 8
Training loss: 0.09247295558452606
Validation loss: 1.5935383791564612

Epoch: 5| Step: 9
Training loss: 0.11826620995998383
Validation loss: 1.601655758837218

Epoch: 5| Step: 10
Training loss: 0.11906493455171585
Validation loss: 1.5983126817211029

Epoch: 471| Step: 0
Training loss: 0.19742101430892944
Validation loss: 1.5805582923273886

Epoch: 5| Step: 1
Training loss: 0.23540055751800537
Validation loss: 1.6066948649703816

Epoch: 5| Step: 2
Training loss: 0.09899811446666718
Validation loss: 1.5615615434544061

Epoch: 5| Step: 3
Training loss: 0.28083544969558716
Validation loss: 1.6147445055746263

Epoch: 5| Step: 4
Training loss: 0.16575607657432556
Validation loss: 1.6015075791266657

Epoch: 5| Step: 5
Training loss: 0.13698549568653107
Validation loss: 1.5694121750452186

Epoch: 5| Step: 6
Training loss: 0.0979662612080574
Validation loss: 1.5584990286057996

Epoch: 5| Step: 7
Training loss: 0.09934230893850327
Validation loss: 1.5532142481496256

Epoch: 5| Step: 8
Training loss: 0.25641655921936035
Validation loss: 1.5516095725438928

Epoch: 5| Step: 9
Training loss: 0.13096323609352112
Validation loss: 1.5351708499334191

Epoch: 5| Step: 10
Training loss: 0.15573589503765106
Validation loss: 1.5564742793319046

Epoch: 472| Step: 0
Training loss: 0.19579868018627167
Validation loss: 1.5714779079601329

Epoch: 5| Step: 1
Training loss: 0.22861209511756897
Validation loss: 1.581240504018722

Epoch: 5| Step: 2
Training loss: 0.17218995094299316
Validation loss: 1.5946042499234598

Epoch: 5| Step: 3
Training loss: 0.1529020369052887
Validation loss: 1.5684251067458943

Epoch: 5| Step: 4
Training loss: 0.1856416016817093
Validation loss: 1.5749200441504037

Epoch: 5| Step: 5
Training loss: 0.17298775911331177
Validation loss: 1.5633106866190511

Epoch: 5| Step: 6
Training loss: 0.08458279818296432
Validation loss: 1.5340651491636872

Epoch: 5| Step: 7
Training loss: 0.11123309284448624
Validation loss: 1.5406666391639299

Epoch: 5| Step: 8
Training loss: 0.11144473403692245
Validation loss: 1.5201750570727932

Epoch: 5| Step: 9
Training loss: 0.14428120851516724
Validation loss: 1.538420715639668

Epoch: 5| Step: 10
Training loss: 0.32529568672180176
Validation loss: 1.5022690719173801

Epoch: 473| Step: 0
Training loss: 0.13388775289058685
Validation loss: 1.5377193381709438

Epoch: 5| Step: 1
Training loss: 0.1554602086544037
Validation loss: 1.5165856346007316

Epoch: 5| Step: 2
Training loss: 0.24475547671318054
Validation loss: 1.5434910789612801

Epoch: 5| Step: 3
Training loss: 0.15502306818962097
Validation loss: 1.5730868949685046

Epoch: 5| Step: 4
Training loss: 0.13789084553718567
Validation loss: 1.5653514746696717

Epoch: 5| Step: 5
Training loss: 0.07808958739042282
Validation loss: 1.5792075203311058

Epoch: 5| Step: 6
Training loss: 0.11262822151184082
Validation loss: 1.579659895230365

Epoch: 5| Step: 7
Training loss: 0.1148175373673439
Validation loss: 1.6079360362022155

Epoch: 5| Step: 8
Training loss: 0.15863581001758575
Validation loss: 1.6128785558926162

Epoch: 5| Step: 9
Training loss: 0.09748329222202301
Validation loss: 1.577036674304675

Epoch: 5| Step: 10
Training loss: 0.14238882064819336
Validation loss: 1.5695259532620829

Epoch: 474| Step: 0
Training loss: 0.10029010474681854
Validation loss: 1.5549986708548762

Epoch: 5| Step: 1
Training loss: 0.18022584915161133
Validation loss: 1.54896766267797

Epoch: 5| Step: 2
Training loss: 0.15919974446296692
Validation loss: 1.5526420467643327

Epoch: 5| Step: 3
Training loss: 0.1597445160150528
Validation loss: 1.568297597669786

Epoch: 5| Step: 4
Training loss: 0.09281010925769806
Validation loss: 1.5361527576241443

Epoch: 5| Step: 5
Training loss: 0.10475480556488037
Validation loss: 1.550229250743825

Epoch: 5| Step: 6
Training loss: 0.12935742735862732
Validation loss: 1.5575147572384085

Epoch: 5| Step: 7
Training loss: 0.09776397049427032
Validation loss: 1.5479982937535932

Epoch: 5| Step: 8
Training loss: 0.12468377500772476
Validation loss: 1.5677162460101548

Epoch: 5| Step: 9
Training loss: 0.1498272716999054
Validation loss: 1.5321649428336852

Epoch: 5| Step: 10
Training loss: 0.21620842814445496
Validation loss: 1.5660580447925034

Epoch: 475| Step: 0
Training loss: 0.19250774383544922
Validation loss: 1.57601922686382

Epoch: 5| Step: 1
Training loss: 0.09681002050638199
Validation loss: 1.5682419179588236

Epoch: 5| Step: 2
Training loss: 0.10775753110647202
Validation loss: 1.557490123215542

Epoch: 5| Step: 3
Training loss: 0.08530160039663315
Validation loss: 1.560413516977782

Epoch: 5| Step: 4
Training loss: 0.21596857905387878
Validation loss: 1.527691868043715

Epoch: 5| Step: 5
Training loss: 0.17288805544376373
Validation loss: 1.5273812483715754

Epoch: 5| Step: 6
Training loss: 0.11913876235485077
Validation loss: 1.5464676195575344

Epoch: 5| Step: 7
Training loss: 0.14969439804553986
Validation loss: 1.5522068854301208

Epoch: 5| Step: 8
Training loss: 0.08832138031721115
Validation loss: 1.5488886833190918

Epoch: 5| Step: 9
Training loss: 0.08571626991033554
Validation loss: 1.5386396377317366

Epoch: 5| Step: 10
Training loss: 0.07320690155029297
Validation loss: 1.526965836042999

Epoch: 476| Step: 0
Training loss: 0.11041420698165894
Validation loss: 1.5531037058881534

Epoch: 5| Step: 1
Training loss: 0.1035967692732811
Validation loss: 1.5433150619588873

Epoch: 5| Step: 2
Training loss: 0.13120324909687042
Validation loss: 1.5735260927548973

Epoch: 5| Step: 3
Training loss: 0.19268569350242615
Validation loss: 1.560434381167094

Epoch: 5| Step: 4
Training loss: 0.10845643281936646
Validation loss: 1.549327132522419

Epoch: 5| Step: 5
Training loss: 0.14982111752033234
Validation loss: 1.5465662517855245

Epoch: 5| Step: 6
Training loss: 0.17019180953502655
Validation loss: 1.5472098627398092

Epoch: 5| Step: 7
Training loss: 0.1136459931731224
Validation loss: 1.5378175999528618

Epoch: 5| Step: 8
Training loss: 0.1969907134771347
Validation loss: 1.5472342301440496

Epoch: 5| Step: 9
Training loss: 0.07700178772211075
Validation loss: 1.5286059892305763

Epoch: 5| Step: 10
Training loss: 0.08691451698541641
Validation loss: 1.5127888187285392

Epoch: 477| Step: 0
Training loss: 0.15982481837272644
Validation loss: 1.5195085092257428

Epoch: 5| Step: 1
Training loss: 0.09246665239334106
Validation loss: 1.5354344383362801

Epoch: 5| Step: 2
Training loss: 0.19938430190086365
Validation loss: 1.5309016320013231

Epoch: 5| Step: 3
Training loss: 0.13779430091381073
Validation loss: 1.5218964904867194

Epoch: 5| Step: 4
Training loss: 0.11892116069793701
Validation loss: 1.5483948928053661

Epoch: 5| Step: 5
Training loss: 0.11297827959060669
Validation loss: 1.5497782948196575

Epoch: 5| Step: 6
Training loss: 0.13738565146923065
Validation loss: 1.5650002366753035

Epoch: 5| Step: 7
Training loss: 0.12278149276971817
Validation loss: 1.5566843325091946

Epoch: 5| Step: 8
Training loss: 0.17988283932209015
Validation loss: 1.561737366901931

Epoch: 5| Step: 9
Training loss: 0.11447083950042725
Validation loss: 1.6002155042463733

Epoch: 5| Step: 10
Training loss: 0.14774371683597565
Validation loss: 1.5981278086221347

Epoch: 478| Step: 0
Training loss: 0.12457168102264404
Validation loss: 1.5794451134179228

Epoch: 5| Step: 1
Training loss: 0.09426657855510712
Validation loss: 1.5772435254948114

Epoch: 5| Step: 2
Training loss: 0.09980674833059311
Validation loss: 1.5569323442315544

Epoch: 5| Step: 3
Training loss: 0.12498454749584198
Validation loss: 1.5751411966098252

Epoch: 5| Step: 4
Training loss: 0.15971717238426208
Validation loss: 1.5293566219268306

Epoch: 5| Step: 5
Training loss: 0.13197724521160126
Validation loss: 1.5330634053035448

Epoch: 5| Step: 6
Training loss: 0.15537968277931213
Validation loss: 1.524521444433479

Epoch: 5| Step: 7
Training loss: 0.09229627996683121
Validation loss: 1.5088830250565723

Epoch: 5| Step: 8
Training loss: 0.22904840111732483
Validation loss: 1.490844459943874

Epoch: 5| Step: 9
Training loss: 0.19274210929870605
Validation loss: 1.5274402800426687

Epoch: 5| Step: 10
Training loss: 0.17684952914714813
Validation loss: 1.4982501800342272

Epoch: 479| Step: 0
Training loss: 0.08510904014110565
Validation loss: 1.5037790152334398

Epoch: 5| Step: 1
Training loss: 0.14440277218818665
Validation loss: 1.50416297617779

Epoch: 5| Step: 2
Training loss: 0.19310124218463898
Validation loss: 1.5118324275939696

Epoch: 5| Step: 3
Training loss: 0.1677371859550476
Validation loss: 1.512645201016498

Epoch: 5| Step: 4
Training loss: 0.13205944001674652
Validation loss: 1.5228535776497216

Epoch: 5| Step: 5
Training loss: 0.1970161497592926
Validation loss: 1.5286031820440804

Epoch: 5| Step: 6
Training loss: 0.2593614161014557
Validation loss: 1.523128709485454

Epoch: 5| Step: 7
Training loss: 0.0686475858092308
Validation loss: 1.5150082367722706

Epoch: 5| Step: 8
Training loss: 0.07763602584600449
Validation loss: 1.524589111728053

Epoch: 5| Step: 9
Training loss: 0.09790651500225067
Validation loss: 1.52709880311002

Epoch: 5| Step: 10
Training loss: 0.18574832379817963
Validation loss: 1.505489577529251

Epoch: 480| Step: 0
Training loss: 0.14866307377815247
Validation loss: 1.5053813585671045

Epoch: 5| Step: 1
Training loss: 0.11640951782464981
Validation loss: 1.5318446998955102

Epoch: 5| Step: 2
Training loss: 0.10916926711797714
Validation loss: 1.5565013295860701

Epoch: 5| Step: 3
Training loss: 0.17833861708641052
Validation loss: 1.5713894110853954

Epoch: 5| Step: 4
Training loss: 0.25296440720558167
Validation loss: 1.591954561971849

Epoch: 5| Step: 5
Training loss: 0.1680113971233368
Validation loss: 1.5711621494703396

Epoch: 5| Step: 6
Training loss: 0.14567475020885468
Validation loss: 1.5561778596652451

Epoch: 5| Step: 7
Training loss: 0.1606687754392624
Validation loss: 1.5470788542942335

Epoch: 5| Step: 8
Training loss: 0.1007755845785141
Validation loss: 1.506820474901507

Epoch: 5| Step: 9
Training loss: 0.19587910175323486
Validation loss: 1.5277881237768358

Epoch: 5| Step: 10
Training loss: 0.24341271817684174
Validation loss: 1.502655380515642

Epoch: 481| Step: 0
Training loss: 0.16091887652873993
Validation loss: 1.499818733943406

Epoch: 5| Step: 1
Training loss: 0.12978285551071167
Validation loss: 1.4887214719608266

Epoch: 5| Step: 2
Training loss: 0.21993771195411682
Validation loss: 1.517062771704889

Epoch: 5| Step: 3
Training loss: 0.19651003181934357
Validation loss: 1.496180611272012

Epoch: 5| Step: 4
Training loss: 0.14364945888519287
Validation loss: 1.522955362514783

Epoch: 5| Step: 5
Training loss: 0.1402130424976349
Validation loss: 1.5200706502442718

Epoch: 5| Step: 6
Training loss: 0.18096669018268585
Validation loss: 1.528552092531676

Epoch: 5| Step: 7
Training loss: 0.113172747194767
Validation loss: 1.5615553599531933

Epoch: 5| Step: 8
Training loss: 0.19995728135108948
Validation loss: 1.5542338496895247

Epoch: 5| Step: 9
Training loss: 0.08812139928340912
Validation loss: 1.5622674316488288

Epoch: 5| Step: 10
Training loss: 0.12545758485794067
Validation loss: 1.5781241507940396

Epoch: 482| Step: 0
Training loss: 0.1775396168231964
Validation loss: 1.5833731043723323

Epoch: 5| Step: 1
Training loss: 0.2792922556400299
Validation loss: 1.5832123999954553

Epoch: 5| Step: 2
Training loss: 0.14674051105976105
Validation loss: 1.5920312917360695

Epoch: 5| Step: 3
Training loss: 0.07637186348438263
Validation loss: 1.56571630636851

Epoch: 5| Step: 4
Training loss: 0.2166995108127594
Validation loss: 1.5571663354032783

Epoch: 5| Step: 5
Training loss: 0.17278501391410828
Validation loss: 1.546529003368911

Epoch: 5| Step: 6
Training loss: 0.18713822960853577
Validation loss: 1.5547551480672692

Epoch: 5| Step: 7
Training loss: 0.10507003962993622
Validation loss: 1.514232224033725

Epoch: 5| Step: 8
Training loss: 0.08638714253902435
Validation loss: 1.5104751228004374

Epoch: 5| Step: 9
Training loss: 0.19802968204021454
Validation loss: 1.5123090808109572

Epoch: 5| Step: 10
Training loss: 0.22589664161205292
Validation loss: 1.5125495003115745

Epoch: 483| Step: 0
Training loss: 0.15009872615337372
Validation loss: 1.5173072299008727

Epoch: 5| Step: 1
Training loss: 0.13199767470359802
Validation loss: 1.5212014093193957

Epoch: 5| Step: 2
Training loss: 0.23277144134044647
Validation loss: 1.509035724465565

Epoch: 5| Step: 3
Training loss: 0.16507084667682648
Validation loss: 1.5217110495413504

Epoch: 5| Step: 4
Training loss: 0.22466304898262024
Validation loss: 1.501178563282054

Epoch: 5| Step: 5
Training loss: 0.12544503808021545
Validation loss: 1.5321403921291392

Epoch: 5| Step: 6
Training loss: 0.1288573443889618
Validation loss: 1.5259112683675622

Epoch: 5| Step: 7
Training loss: 0.07869571447372437
Validation loss: 1.5429108802990248

Epoch: 5| Step: 8
Training loss: 0.10968323051929474
Validation loss: 1.548382487348331

Epoch: 5| Step: 9
Training loss: 0.1095685139298439
Validation loss: 1.5166361255030478

Epoch: 5| Step: 10
Training loss: 0.08778458833694458
Validation loss: 1.5366830678396328

Epoch: 484| Step: 0
Training loss: 0.13028667867183685
Validation loss: 1.5465388900490218

Epoch: 5| Step: 1
Training loss: 0.14738699793815613
Validation loss: 1.519036990340038

Epoch: 5| Step: 2
Training loss: 0.12406790256500244
Validation loss: 1.5395121125764744

Epoch: 5| Step: 3
Training loss: 0.09443137794733047
Validation loss: 1.5242314825775802

Epoch: 5| Step: 4
Training loss: 0.11736489832401276
Validation loss: 1.5286801476632395

Epoch: 5| Step: 5
Training loss: 0.14944468438625336
Validation loss: 1.547051574594231

Epoch: 5| Step: 6
Training loss: 0.13445740938186646
Validation loss: 1.550763371170208

Epoch: 5| Step: 7
Training loss: 0.17361187934875488
Validation loss: 1.5715609391530354

Epoch: 5| Step: 8
Training loss: 0.23152339458465576
Validation loss: 1.589724120273385

Epoch: 5| Step: 9
Training loss: 0.1393340677022934
Validation loss: 1.5877486198179183

Epoch: 5| Step: 10
Training loss: 0.15723665058612823
Validation loss: 1.5954477556290165

Epoch: 485| Step: 0
Training loss: 0.11370743811130524
Validation loss: 1.6018043384757092

Epoch: 5| Step: 1
Training loss: 0.14652051031589508
Validation loss: 1.5945646301392586

Epoch: 5| Step: 2
Training loss: 0.13000133633613586
Validation loss: 1.5342051982879639

Epoch: 5| Step: 3
Training loss: 0.08249533176422119
Validation loss: 1.5612860559135355

Epoch: 5| Step: 4
Training loss: 0.1057179793715477
Validation loss: 1.5708603448765253

Epoch: 5| Step: 5
Training loss: 0.09742727875709534
Validation loss: 1.5656222707481795

Epoch: 5| Step: 6
Training loss: 0.13973358273506165
Validation loss: 1.581258987226794

Epoch: 5| Step: 7
Training loss: 0.16086184978485107
Validation loss: 1.5818269329686319

Epoch: 5| Step: 8
Training loss: 0.08786235004663467
Validation loss: 1.5550771503038303

Epoch: 5| Step: 9
Training loss: 0.09389213472604752
Validation loss: 1.554242709631561

Epoch: 5| Step: 10
Training loss: 0.244049072265625
Validation loss: 1.5229948618078744

Epoch: 486| Step: 0
Training loss: 0.1777089536190033
Validation loss: 1.5172952708377634

Epoch: 5| Step: 1
Training loss: 0.09709659963846207
Validation loss: 1.4970259371624197

Epoch: 5| Step: 2
Training loss: 0.17593540251255035
Validation loss: 1.484964112440745

Epoch: 5| Step: 3
Training loss: 0.0767708271741867
Validation loss: 1.512755725973396

Epoch: 5| Step: 4
Training loss: 0.09676669538021088
Validation loss: 1.4919363631997058

Epoch: 5| Step: 5
Training loss: 0.11100341379642487
Validation loss: 1.496973955503074

Epoch: 5| Step: 6
Training loss: 0.11034929752349854
Validation loss: 1.5136129189563055

Epoch: 5| Step: 7
Training loss: 0.13605651259422302
Validation loss: 1.5523653664896566

Epoch: 5| Step: 8
Training loss: 0.20993609726428986
Validation loss: 1.543298472640335

Epoch: 5| Step: 9
Training loss: 0.07299728691577911
Validation loss: 1.580862743880159

Epoch: 5| Step: 10
Training loss: 0.10647796839475632
Validation loss: 1.5820906354535011

Epoch: 487| Step: 0
Training loss: 0.08099902421236038
Validation loss: 1.5795429547627766

Epoch: 5| Step: 1
Training loss: 0.06984943896532059
Validation loss: 1.6273417921476467

Epoch: 5| Step: 2
Training loss: 0.1119985580444336
Validation loss: 1.5994948533273512

Epoch: 5| Step: 3
Training loss: 0.08497460931539536
Validation loss: 1.6026519126789545

Epoch: 5| Step: 4
Training loss: 0.08223806321620941
Validation loss: 1.6002644672188708

Epoch: 5| Step: 5
Training loss: 0.1398484706878662
Validation loss: 1.585324869360975

Epoch: 5| Step: 6
Training loss: 0.2619352340698242
Validation loss: 1.6134536266326904

Epoch: 5| Step: 7
Training loss: 0.145962193608284
Validation loss: 1.582633259475872

Epoch: 5| Step: 8
Training loss: 0.13122932612895966
Validation loss: 1.5778524773095244

Epoch: 5| Step: 9
Training loss: 0.12494981288909912
Validation loss: 1.5700743557304464

Epoch: 5| Step: 10
Training loss: 0.16224412620067596
Validation loss: 1.561133962164643

Epoch: 488| Step: 0
Training loss: 0.20530442893505096
Validation loss: 1.5776695256592126

Epoch: 5| Step: 1
Training loss: 0.14895734190940857
Validation loss: 1.5740559588196457

Epoch: 5| Step: 2
Training loss: 0.13006797432899475
Validation loss: 1.5641867935016591

Epoch: 5| Step: 3
Training loss: 0.11779280006885529
Validation loss: 1.5678039263653498

Epoch: 5| Step: 4
Training loss: 0.126216858625412
Validation loss: 1.5807153383890789

Epoch: 5| Step: 5
Training loss: 0.11435552686452866
Validation loss: 1.5794646252867997

Epoch: 5| Step: 6
Training loss: 0.08342932164669037
Validation loss: 1.5718529365395988

Epoch: 5| Step: 7
Training loss: 0.1304689347743988
Validation loss: 1.5577723838949715

Epoch: 5| Step: 8
Training loss: 0.12009875476360321
Validation loss: 1.5675898687813872

Epoch: 5| Step: 9
Training loss: 0.13443951308727264
Validation loss: 1.5632391007997657

Epoch: 5| Step: 10
Training loss: 0.1173722892999649
Validation loss: 1.567693825690977

Epoch: 489| Step: 0
Training loss: 0.1570645272731781
Validation loss: 1.5412186140655189

Epoch: 5| Step: 1
Training loss: 0.14738969504833221
Validation loss: 1.5488372874516312

Epoch: 5| Step: 2
Training loss: 0.1516372561454773
Validation loss: 1.5157249537847375

Epoch: 5| Step: 3
Training loss: 0.1268453747034073
Validation loss: 1.511570090888649

Epoch: 5| Step: 4
Training loss: 0.14593914151191711
Validation loss: 1.522684097290039

Epoch: 5| Step: 5
Training loss: 0.10529818385839462
Validation loss: 1.5197669729109733

Epoch: 5| Step: 6
Training loss: 0.11698726564645767
Validation loss: 1.5153519325358893

Epoch: 5| Step: 7
Training loss: 0.10841637849807739
Validation loss: 1.5339538922873877

Epoch: 5| Step: 8
Training loss: 0.15276892483234406
Validation loss: 1.523163228906611

Epoch: 5| Step: 9
Training loss: 0.15500469505786896
Validation loss: 1.5299994048251901

Epoch: 5| Step: 10
Training loss: 0.06936949491500854
Validation loss: 1.5305499748517108

Epoch: 490| Step: 0
Training loss: 0.07982426881790161
Validation loss: 1.5359160438660653

Epoch: 5| Step: 1
Training loss: 0.10389477014541626
Validation loss: 1.5443413244780673

Epoch: 5| Step: 2
Training loss: 0.19352757930755615
Validation loss: 1.5749606406816872

Epoch: 5| Step: 3
Training loss: 0.12839165329933167
Validation loss: 1.5500896259020733

Epoch: 5| Step: 4
Training loss: 0.17914986610412598
Validation loss: 1.5440313636615712

Epoch: 5| Step: 5
Training loss: 0.13572700321674347
Validation loss: 1.5204838809146677

Epoch: 5| Step: 6
Training loss: 0.12027265131473541
Validation loss: 1.524796958892576

Epoch: 5| Step: 7
Training loss: 0.18969115614891052
Validation loss: 1.5147526802555207

Epoch: 5| Step: 8
Training loss: 0.12016510963439941
Validation loss: 1.5049457575685234

Epoch: 5| Step: 9
Training loss: 0.07287747412919998
Validation loss: 1.5283631047894877

Epoch: 5| Step: 10
Training loss: 0.1062411218881607
Validation loss: 1.5087724526723225

Epoch: 491| Step: 0
Training loss: 0.11581653356552124
Validation loss: 1.5416742870884557

Epoch: 5| Step: 1
Training loss: 0.1437791883945465
Validation loss: 1.4958048251367384

Epoch: 5| Step: 2
Training loss: 0.16531626880168915
Validation loss: 1.5165408401079075

Epoch: 5| Step: 3
Training loss: 0.14003512263298035
Validation loss: 1.5283237503420921

Epoch: 5| Step: 4
Training loss: 0.09939909726381302
Validation loss: 1.5238861717203611

Epoch: 5| Step: 5
Training loss: 0.07870524376630783
Validation loss: 1.5235454664435437

Epoch: 5| Step: 6
Training loss: 0.1538883000612259
Validation loss: 1.5060377710609025

Epoch: 5| Step: 7
Training loss: 0.07643396407365799
Validation loss: 1.5295993743404266

Epoch: 5| Step: 8
Training loss: 0.09774713963270187
Validation loss: 1.5369262432539335

Epoch: 5| Step: 9
Training loss: 0.1469627320766449
Validation loss: 1.5416699635085238

Epoch: 5| Step: 10
Training loss: 0.17698252201080322
Validation loss: 1.5284182576722996

Epoch: 492| Step: 0
Training loss: 0.09317328035831451
Validation loss: 1.5226958490187121

Epoch: 5| Step: 1
Training loss: 0.10441702604293823
Validation loss: 1.5544973240103772

Epoch: 5| Step: 2
Training loss: 0.08371977508068085
Validation loss: 1.535186711178031

Epoch: 5| Step: 3
Training loss: 0.12595424056053162
Validation loss: 1.5309623390115716

Epoch: 5| Step: 4
Training loss: 0.06137353926897049
Validation loss: 1.5281666068620579

Epoch: 5| Step: 5
Training loss: 0.12060384452342987
Validation loss: 1.5059148303924068

Epoch: 5| Step: 6
Training loss: 0.13715149462223053
Validation loss: 1.535763548266503

Epoch: 5| Step: 7
Training loss: 0.13019511103630066
Validation loss: 1.5540937518560758

Epoch: 5| Step: 8
Training loss: 0.1036139577627182
Validation loss: 1.5435272724397722

Epoch: 5| Step: 9
Training loss: 0.14037922024726868
Validation loss: 1.57624477083965

Epoch: 5| Step: 10
Training loss: 0.1557176560163498
Validation loss: 1.5514412951725784

Epoch: 493| Step: 0
Training loss: 0.09257026016712189
Validation loss: 1.5708737552806895

Epoch: 5| Step: 1
Training loss: 0.08016769587993622
Validation loss: 1.5607477029164631

Epoch: 5| Step: 2
Training loss: 0.1608637571334839
Validation loss: 1.5644650100379862

Epoch: 5| Step: 3
Training loss: 0.1603405773639679
Validation loss: 1.555262597658301

Epoch: 5| Step: 4
Training loss: 0.07472525537014008
Validation loss: 1.5243273704282698

Epoch: 5| Step: 5
Training loss: 0.10910091549158096
Validation loss: 1.528548905926366

Epoch: 5| Step: 6
Training loss: 0.12948580086231232
Validation loss: 1.527504760731933

Epoch: 5| Step: 7
Training loss: 0.12769296765327454
Validation loss: 1.5242939277361798

Epoch: 5| Step: 8
Training loss: 0.1050291657447815
Validation loss: 1.5201802689542052

Epoch: 5| Step: 9
Training loss: 0.13697728514671326
Validation loss: 1.5145415855992226

Epoch: 5| Step: 10
Training loss: 0.1362977921962738
Validation loss: 1.5026320718949842

Epoch: 494| Step: 0
Training loss: 0.08775212615728378
Validation loss: 1.5460590982949862

Epoch: 5| Step: 1
Training loss: 0.148258239030838
Validation loss: 1.5135533719934442

Epoch: 5| Step: 2
Training loss: 0.09540996700525284
Validation loss: 1.5310877330841557

Epoch: 5| Step: 3
Training loss: 0.13449838757514954
Validation loss: 1.5304212403553787

Epoch: 5| Step: 4
Training loss: 0.09450314193964005
Validation loss: 1.5388860189786522

Epoch: 5| Step: 5
Training loss: 0.09172595292329788
Validation loss: 1.507069113434002

Epoch: 5| Step: 6
Training loss: 0.15144133567810059
Validation loss: 1.5270383460547334

Epoch: 5| Step: 7
Training loss: 0.105124332010746
Validation loss: 1.5108207477036344

Epoch: 5| Step: 8
Training loss: 0.17319931089878082
Validation loss: 1.5369879994341122

Epoch: 5| Step: 9
Training loss: 0.12411055713891983
Validation loss: 1.5376188178216257

Epoch: 5| Step: 10
Training loss: 0.14137275516986847
Validation loss: 1.543360101279392

Epoch: 495| Step: 0
Training loss: 0.08620458841323853
Validation loss: 1.5283187179155246

Epoch: 5| Step: 1
Training loss: 0.09459759294986725
Validation loss: 1.5280035503448979

Epoch: 5| Step: 2
Training loss: 0.15126502513885498
Validation loss: 1.5124312062417307

Epoch: 5| Step: 3
Training loss: 0.14523549377918243
Validation loss: 1.5288472348643887

Epoch: 5| Step: 4
Training loss: 0.13363851606845856
Validation loss: 1.5223450045431814

Epoch: 5| Step: 5
Training loss: 0.05043930932879448
Validation loss: 1.540723193076349

Epoch: 5| Step: 6
Training loss: 0.06160914897918701
Validation loss: 1.542732322087852

Epoch: 5| Step: 7
Training loss: 0.054543398320674896
Validation loss: 1.5790617901791808

Epoch: 5| Step: 8
Training loss: 0.15549232065677643
Validation loss: 1.5418962124855287

Epoch: 5| Step: 9
Training loss: 0.12281568348407745
Validation loss: 1.5553654124659877

Epoch: 5| Step: 10
Training loss: 0.1364576369524002
Validation loss: 1.5462001831300798

Epoch: 496| Step: 0
Training loss: 0.13283953070640564
Validation loss: 1.5269071876361806

Epoch: 5| Step: 1
Training loss: 0.07346262037754059
Validation loss: 1.5502973461663851

Epoch: 5| Step: 2
Training loss: 0.11288197338581085
Validation loss: 1.5395078095056678

Epoch: 5| Step: 3
Training loss: 0.0785968080163002
Validation loss: 1.5282481985707437

Epoch: 5| Step: 4
Training loss: 0.09479611366987228
Validation loss: 1.489058845786638

Epoch: 5| Step: 5
Training loss: 0.08370830118656158
Validation loss: 1.524520388213537

Epoch: 5| Step: 6
Training loss: 0.09844287484884262
Validation loss: 1.5300154224518807

Epoch: 5| Step: 7
Training loss: 0.09796120971441269
Validation loss: 1.57016150541203

Epoch: 5| Step: 8
Training loss: 0.11859488487243652
Validation loss: 1.5755737943034018

Epoch: 5| Step: 9
Training loss: 0.13876676559448242
Validation loss: 1.6018798402560654

Epoch: 5| Step: 10
Training loss: 0.19335708022117615
Validation loss: 1.5759318092817902

Epoch: 497| Step: 0
Training loss: 0.14941217005252838
Validation loss: 1.5769444178509455

Epoch: 5| Step: 1
Training loss: 0.08625434339046478
Validation loss: 1.5691117830173944

Epoch: 5| Step: 2
Training loss: 0.10095562785863876
Validation loss: 1.5407711998108895

Epoch: 5| Step: 3
Training loss: 0.09654368460178375
Validation loss: 1.5126939717159475

Epoch: 5| Step: 4
Training loss: 0.12336722761392593
Validation loss: 1.5445055455289862

Epoch: 5| Step: 5
Training loss: 0.10202429443597794
Validation loss: 1.5224715202085433

Epoch: 5| Step: 6
Training loss: 0.08207710087299347
Validation loss: 1.5586422848445114

Epoch: 5| Step: 7
Training loss: 0.1222691759467125
Validation loss: 1.5217403455447125

Epoch: 5| Step: 8
Training loss: 0.11713030189275742
Validation loss: 1.542702474901753

Epoch: 5| Step: 9
Training loss: 0.15136313438415527
Validation loss: 1.5333284075542162

Epoch: 5| Step: 10
Training loss: 0.14864160120487213
Validation loss: 1.5361145747605192

Epoch: 498| Step: 0
Training loss: 0.1137358695268631
Validation loss: 1.5527082566292054

Epoch: 5| Step: 1
Training loss: 0.16668923199176788
Validation loss: 1.5211080325547086

Epoch: 5| Step: 2
Training loss: 0.06225107982754707
Validation loss: 1.5272477749855287

Epoch: 5| Step: 3
Training loss: 0.11982546746730804
Validation loss: 1.524652502870047

Epoch: 5| Step: 4
Training loss: 0.10286661237478256
Validation loss: 1.5415234565734863

Epoch: 5| Step: 5
Training loss: 0.14764365553855896
Validation loss: 1.5595985189560921

Epoch: 5| Step: 6
Training loss: 0.1139850988984108
Validation loss: 1.5676412300396991

Epoch: 5| Step: 7
Training loss: 0.10531190782785416
Validation loss: 1.6005195231847866

Epoch: 5| Step: 8
Training loss: 0.11947915703058243
Validation loss: 1.5541080826072282

Epoch: 5| Step: 9
Training loss: 0.12474043667316437
Validation loss: 1.561998862092213

Epoch: 5| Step: 10
Training loss: 0.06089828908443451
Validation loss: 1.5409024646205287

Epoch: 499| Step: 0
Training loss: 0.05491447448730469
Validation loss: 1.5415868566882225

Epoch: 5| Step: 1
Training loss: 0.11031663417816162
Validation loss: 1.4961906049841194

Epoch: 5| Step: 2
Training loss: 0.09020306169986725
Validation loss: 1.5064212096634733

Epoch: 5| Step: 3
Training loss: 0.09706737101078033
Validation loss: 1.5283651980020667

Epoch: 5| Step: 4
Training loss: 0.123931385576725
Validation loss: 1.5290590640037292

Epoch: 5| Step: 5
Training loss: 0.13577917218208313
Validation loss: 1.5345041187860633

Epoch: 5| Step: 6
Training loss: 0.15237116813659668
Validation loss: 1.5010512234062277

Epoch: 5| Step: 7
Training loss: 0.09054689109325409
Validation loss: 1.5341793708903815

Epoch: 5| Step: 8
Training loss: 0.12146703898906708
Validation loss: 1.5320781930800407

Epoch: 5| Step: 9
Training loss: 0.1315343827009201
Validation loss: 1.5419236985586022

Epoch: 5| Step: 10
Training loss: 0.14512507617473602
Validation loss: 1.5498591251270746

Epoch: 500| Step: 0
Training loss: 0.12766587734222412
Validation loss: 1.5603663985447218

Epoch: 5| Step: 1
Training loss: 0.141610786318779
Validation loss: 1.5541690716179468

Epoch: 5| Step: 2
Training loss: 0.10634937137365341
Validation loss: 1.5164978991272628

Epoch: 5| Step: 3
Training loss: 0.08843555301427841
Validation loss: 1.5492218309833157

Epoch: 5| Step: 4
Training loss: 0.06999792158603668
Validation loss: 1.5207681604610976

Epoch: 5| Step: 5
Training loss: 0.13184620440006256
Validation loss: 1.4935174949707524

Epoch: 5| Step: 6
Training loss: 0.21508213877677917
Validation loss: 1.4849838082508375

Epoch: 5| Step: 7
Training loss: 0.09106732159852982
Validation loss: 1.4916785763156029

Epoch: 5| Step: 8
Training loss: 0.12702377140522003
Validation loss: 1.470008320705865

Epoch: 5| Step: 9
Training loss: 0.07835317403078079
Validation loss: 1.4900228246565788

Epoch: 5| Step: 10
Training loss: 0.17965257167816162
Validation loss: 1.4838383325966455

Epoch: 501| Step: 0
Training loss: 0.07811447232961655
Validation loss: 1.4967795507882231

Epoch: 5| Step: 1
Training loss: 0.12268570810556412
Validation loss: 1.5053382881226078

Epoch: 5| Step: 2
Training loss: 0.12030346691608429
Validation loss: 1.5109639513877131

Epoch: 5| Step: 3
Training loss: 0.16847443580627441
Validation loss: 1.5209152647244033

Epoch: 5| Step: 4
Training loss: 0.10930106788873672
Validation loss: 1.5101124253324283

Epoch: 5| Step: 5
Training loss: 0.12340184301137924
Validation loss: 1.5317585622110674

Epoch: 5| Step: 6
Training loss: 0.07467321306467056
Validation loss: 1.548329955788069

Epoch: 5| Step: 7
Training loss: 0.1619851291179657
Validation loss: 1.5157322550332675

Epoch: 5| Step: 8
Training loss: 0.14766213297843933
Validation loss: 1.5160483198781167

Epoch: 5| Step: 9
Training loss: 0.07361171394586563
Validation loss: 1.5227336768181092

Epoch: 5| Step: 10
Training loss: 0.09408637881278992
Validation loss: 1.511373120610432

Epoch: 502| Step: 0
Training loss: 0.15290607511997223
Validation loss: 1.510861131452745

Epoch: 5| Step: 1
Training loss: 0.1481320559978485
Validation loss: 1.4985338462296354

Epoch: 5| Step: 2
Training loss: 0.12996937334537506
Validation loss: 1.5241001805951517

Epoch: 5| Step: 3
Training loss: 0.1310683786869049
Validation loss: 1.5374816784294703

Epoch: 5| Step: 4
Training loss: 0.08328293263912201
Validation loss: 1.5302764484959264

Epoch: 5| Step: 5
Training loss: 0.04585934430360794
Validation loss: 1.526693710716822

Epoch: 5| Step: 6
Training loss: 0.09372713416814804
Validation loss: 1.5092880072132233

Epoch: 5| Step: 7
Training loss: 0.10568680614233017
Validation loss: 1.5029105037771247

Epoch: 5| Step: 8
Training loss: 0.13487522304058075
Validation loss: 1.5224456876836798

Epoch: 5| Step: 9
Training loss: 0.2030879706144333
Validation loss: 1.5266498634892125

Epoch: 5| Step: 10
Training loss: 0.13159611821174622
Validation loss: 1.546128490919708

Epoch: 503| Step: 0
Training loss: 0.1110503077507019
Validation loss: 1.522449315235179

Epoch: 5| Step: 1
Training loss: 0.15626294910907745
Validation loss: 1.5221374829610188

Epoch: 5| Step: 2
Training loss: 0.1072358638048172
Validation loss: 1.5216015692680114

Epoch: 5| Step: 3
Training loss: 0.07429556548595428
Validation loss: 1.5423634218913254

Epoch: 5| Step: 4
Training loss: 0.14071053266525269
Validation loss: 1.5432997877879808

Epoch: 5| Step: 5
Training loss: 0.08207820355892181
Validation loss: 1.5395478048632223

Epoch: 5| Step: 6
Training loss: 0.16978690028190613
Validation loss: 1.5714268992024083

Epoch: 5| Step: 7
Training loss: 0.1846415400505066
Validation loss: 1.5541498968678136

Epoch: 5| Step: 8
Training loss: 0.12202006578445435
Validation loss: 1.5595916932629001

Epoch: 5| Step: 9
Training loss: 0.14775846898555756
Validation loss: 1.5475422361845612

Epoch: 5| Step: 10
Training loss: 0.12995699048042297
Validation loss: 1.5435011130507275

Epoch: 504| Step: 0
Training loss: 0.10608859360218048
Validation loss: 1.5460140346198954

Epoch: 5| Step: 1
Training loss: 0.09531204402446747
Validation loss: 1.5269367823036768

Epoch: 5| Step: 2
Training loss: 0.08540162444114685
Validation loss: 1.5155651941094348

Epoch: 5| Step: 3
Training loss: 0.11378607898950577
Validation loss: 1.5168341129056868

Epoch: 5| Step: 4
Training loss: 0.15806958079338074
Validation loss: 1.5165489066031672

Epoch: 5| Step: 5
Training loss: 0.10198517143726349
Validation loss: 1.500184505216537

Epoch: 5| Step: 6
Training loss: 0.10552631318569183
Validation loss: 1.4970349150319253

Epoch: 5| Step: 7
Training loss: 0.15927457809448242
Validation loss: 1.5321269099430372

Epoch: 5| Step: 8
Training loss: 0.12470138072967529
Validation loss: 1.5509820266436505

Epoch: 5| Step: 9
Training loss: 0.10590877383947372
Validation loss: 1.5229676641443723

Epoch: 5| Step: 10
Training loss: 0.09809073060750961
Validation loss: 1.5509450192092566

Epoch: 505| Step: 0
Training loss: 0.14723852276802063
Validation loss: 1.5889131099947038

Epoch: 5| Step: 1
Training loss: 0.13529284298419952
Validation loss: 1.5855121099820702

Epoch: 5| Step: 2
Training loss: 0.1716356873512268
Validation loss: 1.5891117447166032

Epoch: 5| Step: 3
Training loss: 0.2015889436006546
Validation loss: 1.5951643028566915

Epoch: 5| Step: 4
Training loss: 0.17730189859867096
Validation loss: 1.586293003892386

Epoch: 5| Step: 5
Training loss: 0.1379135251045227
Validation loss: 1.5887983896399056

Epoch: 5| Step: 6
Training loss: 0.10753607749938965
Validation loss: 1.601664068878338

Epoch: 5| Step: 7
Training loss: 0.07932604849338531
Validation loss: 1.5709652618695331

Epoch: 5| Step: 8
Training loss: 0.11986903101205826
Validation loss: 1.5614004852951213

Epoch: 5| Step: 9
Training loss: 0.06858861446380615
Validation loss: 1.5710054161728069

Epoch: 5| Step: 10
Training loss: 0.11813315004110336
Validation loss: 1.5632153557192894

Epoch: 506| Step: 0
Training loss: 0.14340408146381378
Validation loss: 1.5511477006378995

Epoch: 5| Step: 1
Training loss: 0.13056746125221252
Validation loss: 1.54568656926514

Epoch: 5| Step: 2
Training loss: 0.08276291191577911
Validation loss: 1.547999902438092

Epoch: 5| Step: 3
Training loss: 0.07675037533044815
Validation loss: 1.5547404846837443

Epoch: 5| Step: 4
Training loss: 0.07387849688529968
Validation loss: 1.5536064242803922

Epoch: 5| Step: 5
Training loss: 0.11715513467788696
Validation loss: 1.5650446197038055

Epoch: 5| Step: 6
Training loss: 0.12368476390838623
Validation loss: 1.5197148938332834

Epoch: 5| Step: 7
Training loss: 0.14709311723709106
Validation loss: 1.5181339004988312

Epoch: 5| Step: 8
Training loss: 0.18715906143188477
Validation loss: 1.5237901338966944

Epoch: 5| Step: 9
Training loss: 0.10306551307439804
Validation loss: 1.5488575690536088

Epoch: 5| Step: 10
Training loss: 0.08403751254081726
Validation loss: 1.525975069692058

Epoch: 507| Step: 0
Training loss: 0.06631653755903244
Validation loss: 1.5288942398563508

Epoch: 5| Step: 1
Training loss: 0.13430026173591614
Validation loss: 1.5260075651189333

Epoch: 5| Step: 2
Training loss: 0.08483806997537613
Validation loss: 1.5447209637652162

Epoch: 5| Step: 3
Training loss: 0.07119321078062057
Validation loss: 1.5260885338629446

Epoch: 5| Step: 4
Training loss: 0.11552099883556366
Validation loss: 1.5367607942191504

Epoch: 5| Step: 5
Training loss: 0.05975886061787605
Validation loss: 1.540217705952224

Epoch: 5| Step: 6
Training loss: 0.15613456070423126
Validation loss: 1.5342562531912198

Epoch: 5| Step: 7
Training loss: 0.201656773686409
Validation loss: 1.5265033193813857

Epoch: 5| Step: 8
Training loss: 0.12114715576171875
Validation loss: 1.5336414267939906

Epoch: 5| Step: 9
Training loss: 0.14444543421268463
Validation loss: 1.5258130488857147

Epoch: 5| Step: 10
Training loss: 0.10497373342514038
Validation loss: 1.5360097494176639

Epoch: 508| Step: 0
Training loss: 0.18787071108818054
Validation loss: 1.5442188196284796

Epoch: 5| Step: 1
Training loss: 0.0828537791967392
Validation loss: 1.5267387923373972

Epoch: 5| Step: 2
Training loss: 0.17852038145065308
Validation loss: 1.5116864763280398

Epoch: 5| Step: 3
Training loss: 0.053816914558410645
Validation loss: 1.5374375184377034

Epoch: 5| Step: 4
Training loss: 0.10551633685827255
Validation loss: 1.5322197124522219

Epoch: 5| Step: 5
Training loss: 0.07455272972583771
Validation loss: 1.4916429929835822

Epoch: 5| Step: 6
Training loss: 0.08240433782339096
Validation loss: 1.501513272203425

Epoch: 5| Step: 7
Training loss: 0.08721230924129486
Validation loss: 1.5018382315994592

Epoch: 5| Step: 8
Training loss: 0.06545113027095795
Validation loss: 1.50392379812015

Epoch: 5| Step: 9
Training loss: 0.08500045537948608
Validation loss: 1.504350341776366

Epoch: 5| Step: 10
Training loss: 0.07299546152353287
Validation loss: 1.526062947447582

Epoch: 509| Step: 0
Training loss: 0.13756044209003448
Validation loss: 1.5202925769231652

Epoch: 5| Step: 1
Training loss: 0.08906097710132599
Validation loss: 1.5262839012248541

Epoch: 5| Step: 2
Training loss: 0.1304033100605011
Validation loss: 1.5553186901154057

Epoch: 5| Step: 3
Training loss: 0.13989174365997314
Validation loss: 1.5338185628255208

Epoch: 5| Step: 4
Training loss: 0.09013600647449493
Validation loss: 1.48797091104651

Epoch: 5| Step: 5
Training loss: 0.09896473586559296
Validation loss: 1.5169933880529096

Epoch: 5| Step: 6
Training loss: 0.08228980004787445
Validation loss: 1.5009026206949705

Epoch: 5| Step: 7
Training loss: 0.10186173021793365
Validation loss: 1.4772667955326777

Epoch: 5| Step: 8
Training loss: 0.13117000460624695
Validation loss: 1.4998950163523357

Epoch: 5| Step: 9
Training loss: 0.135626882314682
Validation loss: 1.4934089879194896

Epoch: 5| Step: 10
Training loss: 0.1229834109544754
Validation loss: 1.4759861243668424

Epoch: 510| Step: 0
Training loss: 0.0973074734210968
Validation loss: 1.5022411090071484

Epoch: 5| Step: 1
Training loss: 0.09741479158401489
Validation loss: 1.5202199297566568

Epoch: 5| Step: 2
Training loss: 0.08039836585521698
Validation loss: 1.548324824661337

Epoch: 5| Step: 3
Training loss: 0.06553315371274948
Validation loss: 1.5371283542725347

Epoch: 5| Step: 4
Training loss: 0.11933787912130356
Validation loss: 1.542087249858405

Epoch: 5| Step: 5
Training loss: 0.07742603123188019
Validation loss: 1.5414728900437713

Epoch: 5| Step: 6
Training loss: 0.10526756197214127
Validation loss: 1.5562878167757423

Epoch: 5| Step: 7
Training loss: 0.08129961043596268
Validation loss: 1.544897574250416

Epoch: 5| Step: 8
Training loss: 0.17389295995235443
Validation loss: 1.5498656303651872

Epoch: 5| Step: 9
Training loss: 0.1957438886165619
Validation loss: 1.5533199387211953

Epoch: 5| Step: 10
Training loss: 0.08675894886255264
Validation loss: 1.552910868839551

Epoch: 511| Step: 0
Training loss: 0.09568367898464203
Validation loss: 1.552034939489057

Epoch: 5| Step: 1
Training loss: 0.13757021725177765
Validation loss: 1.5395221928114533

Epoch: 5| Step: 2
Training loss: 0.0711127296090126
Validation loss: 1.5508927619585426

Epoch: 5| Step: 3
Training loss: 0.07913479954004288
Validation loss: 1.5377901677162416

Epoch: 5| Step: 4
Training loss: 0.13986614346504211
Validation loss: 1.5562648555283904

Epoch: 5| Step: 5
Training loss: 0.10502143204212189
Validation loss: 1.5318276766807801

Epoch: 5| Step: 6
Training loss: 0.10558245331048965
Validation loss: 1.5552211999893188

Epoch: 5| Step: 7
Training loss: 0.10221321880817413
Validation loss: 1.548601842695667

Epoch: 5| Step: 8
Training loss: 0.08567304164171219
Validation loss: 1.5323768290140296

Epoch: 5| Step: 9
Training loss: 0.09656382352113724
Validation loss: 1.5170178451845724

Epoch: 5| Step: 10
Training loss: 0.08475715667009354
Validation loss: 1.5302746206201532

Epoch: 512| Step: 0
Training loss: 0.0786927193403244
Validation loss: 1.5483900808518933

Epoch: 5| Step: 1
Training loss: 0.11312593519687653
Validation loss: 1.508088311841411

Epoch: 5| Step: 2
Training loss: 0.11491336673498154
Validation loss: 1.537661115969381

Epoch: 5| Step: 3
Training loss: 0.10982618480920792
Validation loss: 1.5104306641445364

Epoch: 5| Step: 4
Training loss: 0.09174022823572159
Validation loss: 1.5496721306154806

Epoch: 5| Step: 5
Training loss: 0.12822392582893372
Validation loss: 1.5381396893532044

Epoch: 5| Step: 6
Training loss: 0.1570502370595932
Validation loss: 1.526984663419826

Epoch: 5| Step: 7
Training loss: 0.12830650806427002
Validation loss: 1.5305866579855643

Epoch: 5| Step: 8
Training loss: 0.14112481474876404
Validation loss: 1.540964953361019

Epoch: 5| Step: 9
Training loss: 0.0962304174900055
Validation loss: 1.5430330589253416

Epoch: 5| Step: 10
Training loss: 0.09342589229345322
Validation loss: 1.5355708560635966

Epoch: 513| Step: 0
Training loss: 0.11261673271656036
Validation loss: 1.5588140756853166

Epoch: 5| Step: 1
Training loss: 0.16188430786132812
Validation loss: 1.5632226697860225

Epoch: 5| Step: 2
Training loss: 0.059618763625621796
Validation loss: 1.561014126705867

Epoch: 5| Step: 3
Training loss: 0.06862591207027435
Validation loss: 1.5680577229428034

Epoch: 5| Step: 4
Training loss: 0.12527897953987122
Validation loss: 1.570459314571914

Epoch: 5| Step: 5
Training loss: 0.11398275196552277
Validation loss: 1.5685771114082747

Epoch: 5| Step: 6
Training loss: 0.07844121009111404
Validation loss: 1.560536212818597

Epoch: 5| Step: 7
Training loss: 0.14691641926765442
Validation loss: 1.549522533211657

Epoch: 5| Step: 8
Training loss: 0.07872302085161209
Validation loss: 1.547091603920024

Epoch: 5| Step: 9
Training loss: 0.08863997459411621
Validation loss: 1.554640095721009

Epoch: 5| Step: 10
Training loss: 0.15606096386909485
Validation loss: 1.527598951452522

Epoch: 514| Step: 0
Training loss: 0.08397812396287918
Validation loss: 1.5347468096722838

Epoch: 5| Step: 1
Training loss: 0.10873831808567047
Validation loss: 1.5388375354069534

Epoch: 5| Step: 2
Training loss: 0.10820828378200531
Validation loss: 1.5208822963058308

Epoch: 5| Step: 3
Training loss: 0.11687101423740387
Validation loss: 1.5330529853861818

Epoch: 5| Step: 4
Training loss: 0.17015685141086578
Validation loss: 1.5234902866425053

Epoch: 5| Step: 5
Training loss: 0.06564123928546906
Validation loss: 1.4792105984944168

Epoch: 5| Step: 6
Training loss: 0.07486730813980103
Validation loss: 1.4874977950126893

Epoch: 5| Step: 7
Training loss: 0.17186789214611053
Validation loss: 1.4626982564567237

Epoch: 5| Step: 8
Training loss: 0.13761894404888153
Validation loss: 1.4856774486521238

Epoch: 5| Step: 9
Training loss: 0.09789250046014786
Validation loss: 1.4718578579605266

Epoch: 5| Step: 10
Training loss: 0.06417691707611084
Validation loss: 1.474658787891429

Epoch: 515| Step: 0
Training loss: 0.1295706033706665
Validation loss: 1.4870750352900515

Epoch: 5| Step: 1
Training loss: 0.14348402619361877
Validation loss: 1.4818543080360658

Epoch: 5| Step: 2
Training loss: 0.10533235967159271
Validation loss: 1.506168588515251

Epoch: 5| Step: 3
Training loss: 0.14775843918323517
Validation loss: 1.4980361871821906

Epoch: 5| Step: 4
Training loss: 0.11845336854457855
Validation loss: 1.50498717318299

Epoch: 5| Step: 5
Training loss: 0.09186553955078125
Validation loss: 1.5372179438990932

Epoch: 5| Step: 6
Training loss: 0.06278755515813828
Validation loss: 1.5409987607309896

Epoch: 5| Step: 7
Training loss: 0.06954768300056458
Validation loss: 1.5523151787378455

Epoch: 5| Step: 8
Training loss: 0.1284770965576172
Validation loss: 1.5547972891920356

Epoch: 5| Step: 9
Training loss: 0.06365448236465454
Validation loss: 1.5283632086169334

Epoch: 5| Step: 10
Training loss: 0.1695069819688797
Validation loss: 1.5393002616461886

Epoch: 516| Step: 0
Training loss: 0.0802808627486229
Validation loss: 1.547826422158108

Epoch: 5| Step: 1
Training loss: 0.10155614465475082
Validation loss: 1.5355082981048092

Epoch: 5| Step: 2
Training loss: 0.07424349337816238
Validation loss: 1.532450992573974

Epoch: 5| Step: 3
Training loss: 0.1613331288099289
Validation loss: 1.5399991607153287

Epoch: 5| Step: 4
Training loss: 0.11572519689798355
Validation loss: 1.567119759898032

Epoch: 5| Step: 5
Training loss: 0.06599193811416626
Validation loss: 1.5520668786059144

Epoch: 5| Step: 6
Training loss: 0.14087095856666565
Validation loss: 1.6008547159933275

Epoch: 5| Step: 7
Training loss: 0.17180652916431427
Validation loss: 1.571308220586469

Epoch: 5| Step: 8
Training loss: 0.15840032696723938
Validation loss: 1.5846892787564186

Epoch: 5| Step: 9
Training loss: 0.13155701756477356
Validation loss: 1.5978511969248455

Epoch: 5| Step: 10
Training loss: 0.17889544367790222
Validation loss: 1.5872984406768635

Epoch: 517| Step: 0
Training loss: 0.11701126396656036
Validation loss: 1.5608586008830736

Epoch: 5| Step: 1
Training loss: 0.10858704894781113
Validation loss: 1.553549297394291

Epoch: 5| Step: 2
Training loss: 0.10159754753112793
Validation loss: 1.5714185609612414

Epoch: 5| Step: 3
Training loss: 0.1122884750366211
Validation loss: 1.5615368978951567

Epoch: 5| Step: 4
Training loss: 0.0690901130437851
Validation loss: 1.565586382342923

Epoch: 5| Step: 5
Training loss: 0.06508374214172363
Validation loss: 1.5368031353078864

Epoch: 5| Step: 6
Training loss: 0.044476184993982315
Validation loss: 1.5386853218078613

Epoch: 5| Step: 7
Training loss: 0.11776934564113617
Validation loss: 1.5455286823293215

Epoch: 5| Step: 8
Training loss: 0.09107194095849991
Validation loss: 1.5417500529237973

Epoch: 5| Step: 9
Training loss: 0.135496586561203
Validation loss: 1.5343535254078526

Epoch: 5| Step: 10
Training loss: 0.1855798214673996
Validation loss: 1.5139491878530031

Epoch: 518| Step: 0
Training loss: 0.05239921808242798
Validation loss: 1.521456406962487

Epoch: 5| Step: 1
Training loss: 0.0621146634221077
Validation loss: 1.5167291574580695

Epoch: 5| Step: 2
Training loss: 0.07022692263126373
Validation loss: 1.5189143919175672

Epoch: 5| Step: 3
Training loss: 0.07443486154079437
Validation loss: 1.5211614601073726

Epoch: 5| Step: 4
Training loss: 0.055891476571559906
Validation loss: 1.5299457849994782

Epoch: 5| Step: 5
Training loss: 0.0670923963189125
Validation loss: 1.5155789262504988

Epoch: 5| Step: 6
Training loss: 0.15240931510925293
Validation loss: 1.560880905838423

Epoch: 5| Step: 7
Training loss: 0.0945790559053421
Validation loss: 1.5447429924882867

Epoch: 5| Step: 8
Training loss: 0.11852769553661346
Validation loss: 1.5538976000201317

Epoch: 5| Step: 9
Training loss: 0.13913217186927795
Validation loss: 1.5347474864734116

Epoch: 5| Step: 10
Training loss: 0.11487911641597748
Validation loss: 1.5488798272225164

Epoch: 519| Step: 0
Training loss: 0.06472951173782349
Validation loss: 1.5524547702522689

Epoch: 5| Step: 1
Training loss: 0.07748822867870331
Validation loss: 1.5390901027187225

Epoch: 5| Step: 2
Training loss: 0.1316581666469574
Validation loss: 1.5111425640762493

Epoch: 5| Step: 3
Training loss: 0.13444621860980988
Validation loss: 1.543316343779205

Epoch: 5| Step: 4
Training loss: 0.10505266487598419
Validation loss: 1.5307989005119569

Epoch: 5| Step: 5
Training loss: 0.10719960927963257
Validation loss: 1.5423483156388806

Epoch: 5| Step: 6
Training loss: 0.15631771087646484
Validation loss: 1.5403963327407837

Epoch: 5| Step: 7
Training loss: 0.10960106551647186
Validation loss: 1.5076947353219474

Epoch: 5| Step: 8
Training loss: 0.07438043504953384
Validation loss: 1.5273535495163293

Epoch: 5| Step: 9
Training loss: 0.09200425446033478
Validation loss: 1.524979200414432

Epoch: 5| Step: 10
Training loss: 0.0621320866048336
Validation loss: 1.5248918584598008

Epoch: 520| Step: 0
Training loss: 0.06721274554729462
Validation loss: 1.5242166416619414

Epoch: 5| Step: 1
Training loss: 0.07323268055915833
Validation loss: 1.541452071999991

Epoch: 5| Step: 2
Training loss: 0.12495589256286621
Validation loss: 1.510936601187593

Epoch: 5| Step: 3
Training loss: 0.15905630588531494
Validation loss: 1.5220080505135238

Epoch: 5| Step: 4
Training loss: 0.05834587663412094
Validation loss: 1.477308189997109

Epoch: 5| Step: 5
Training loss: 0.11894440650939941
Validation loss: 1.4993740140750844

Epoch: 5| Step: 6
Training loss: 0.11318673938512802
Validation loss: 1.5096223943976945

Epoch: 5| Step: 7
Training loss: 0.14516596496105194
Validation loss: 1.5017748712211527

Epoch: 5| Step: 8
Training loss: 0.10034473240375519
Validation loss: 1.5298783176688737

Epoch: 5| Step: 9
Training loss: 0.08904753625392914
Validation loss: 1.5201162586929977

Epoch: 5| Step: 10
Training loss: 0.08128415793180466
Validation loss: 1.5050792360818515

Epoch: 521| Step: 0
Training loss: 0.08299639075994492
Validation loss: 1.495713314702434

Epoch: 5| Step: 1
Training loss: 0.11125626415014267
Validation loss: 1.5235582884921823

Epoch: 5| Step: 2
Training loss: 0.11435201019048691
Validation loss: 1.5101324627476354

Epoch: 5| Step: 3
Training loss: 0.0647118091583252
Validation loss: 1.5294051580531622

Epoch: 5| Step: 4
Training loss: 0.0691920816898346
Validation loss: 1.518597122161619

Epoch: 5| Step: 5
Training loss: 0.11273268610239029
Validation loss: 1.5270247908048733

Epoch: 5| Step: 6
Training loss: 0.09078608453273773
Validation loss: 1.507230604848554

Epoch: 5| Step: 7
Training loss: 0.14086344838142395
Validation loss: 1.5210187986332884

Epoch: 5| Step: 8
Training loss: 0.0951351597905159
Validation loss: 1.5559313169089697

Epoch: 5| Step: 9
Training loss: 0.07538300007581711
Validation loss: 1.5488936798546904

Epoch: 5| Step: 10
Training loss: 0.1109844446182251
Validation loss: 1.5667771100997925

Epoch: 522| Step: 0
Training loss: 0.08391507714986801
Validation loss: 1.5222717510756625

Epoch: 5| Step: 1
Training loss: 0.0857810229063034
Validation loss: 1.5462865239830428

Epoch: 5| Step: 2
Training loss: 0.15233531594276428
Validation loss: 1.5470373886887745

Epoch: 5| Step: 3
Training loss: 0.08448940515518188
Validation loss: 1.5522674065764233

Epoch: 5| Step: 4
Training loss: 0.0988304391503334
Validation loss: 1.5779840997470322

Epoch: 5| Step: 5
Training loss: 0.09436465799808502
Validation loss: 1.5573293393658054

Epoch: 5| Step: 6
Training loss: 0.13244351744651794
Validation loss: 1.587814054181499

Epoch: 5| Step: 7
Training loss: 0.11826048046350479
Validation loss: 1.5841308691168343

Epoch: 5| Step: 8
Training loss: 0.10901749134063721
Validation loss: 1.5582985595990253

Epoch: 5| Step: 9
Training loss: 0.10905878245830536
Validation loss: 1.5404146653349682

Epoch: 5| Step: 10
Training loss: 0.09639444202184677
Validation loss: 1.5543729643667898

Epoch: 523| Step: 0
Training loss: 0.08744002878665924
Validation loss: 1.531893369972065

Epoch: 5| Step: 1
Training loss: 0.08536958694458008
Validation loss: 1.5404260825085383

Epoch: 5| Step: 2
Training loss: 0.09217139333486557
Validation loss: 1.5200012999196206

Epoch: 5| Step: 3
Training loss: 0.1161772832274437
Validation loss: 1.5416049662456717

Epoch: 5| Step: 4
Training loss: 0.14898531138896942
Validation loss: 1.53199972773111

Epoch: 5| Step: 5
Training loss: 0.09110190719366074
Validation loss: 1.5235731986261183

Epoch: 5| Step: 6
Training loss: 0.0761142447590828
Validation loss: 1.528355420276683

Epoch: 5| Step: 7
Training loss: 0.09908604621887207
Validation loss: 1.5537019237395255

Epoch: 5| Step: 8
Training loss: 0.13242393732070923
Validation loss: 1.5420476057196175

Epoch: 5| Step: 9
Training loss: 0.08537120372056961
Validation loss: 1.5582663230998541

Epoch: 5| Step: 10
Training loss: 0.08982547372579575
Validation loss: 1.5476552081364456

Epoch: 524| Step: 0
Training loss: 0.08442124724388123
Validation loss: 1.5628002407730266

Epoch: 5| Step: 1
Training loss: 0.10797250270843506
Validation loss: 1.5355149956159695

Epoch: 5| Step: 2
Training loss: 0.09254390001296997
Validation loss: 1.5347008077047204

Epoch: 5| Step: 3
Training loss: 0.0868026465177536
Validation loss: 1.539681326958441

Epoch: 5| Step: 4
Training loss: 0.07128185033798218
Validation loss: 1.5371206960370463

Epoch: 5| Step: 5
Training loss: 0.09090746939182281
Validation loss: 1.5527367168857205

Epoch: 5| Step: 6
Training loss: 0.09049355983734131
Validation loss: 1.531215238314803

Epoch: 5| Step: 7
Training loss: 0.09259436279535294
Validation loss: 1.5339750730863182

Epoch: 5| Step: 8
Training loss: 0.07668108493089676
Validation loss: 1.536714784560665

Epoch: 5| Step: 9
Training loss: 0.13008783757686615
Validation loss: 1.510151276024439

Epoch: 5| Step: 10
Training loss: 0.14392712712287903
Validation loss: 1.5210133162877892

Epoch: 525| Step: 0
Training loss: 0.054191119968891144
Validation loss: 1.497942909117668

Epoch: 5| Step: 1
Training loss: 0.10933562368154526
Validation loss: 1.510015441525367

Epoch: 5| Step: 2
Training loss: 0.13071227073669434
Validation loss: 1.5148585880956342

Epoch: 5| Step: 3
Training loss: 0.1104661226272583
Validation loss: 1.503261023952115

Epoch: 5| Step: 4
Training loss: 0.07633351534605026
Validation loss: 1.5320648557396346

Epoch: 5| Step: 5
Training loss: 0.11009955406188965
Validation loss: 1.5429583031644103

Epoch: 5| Step: 6
Training loss: 0.05410431697964668
Validation loss: 1.5165346476339525

Epoch: 5| Step: 7
Training loss: 0.07468142360448837
Validation loss: 1.5544724900235412

Epoch: 5| Step: 8
Training loss: 0.10593241453170776
Validation loss: 1.5303829075187765

Epoch: 5| Step: 9
Training loss: 0.06426165252923965
Validation loss: 1.5837972971700853

Epoch: 5| Step: 10
Training loss: 0.1649722456932068
Validation loss: 1.5487009626562878

Epoch: 526| Step: 0
Training loss: 0.1174478530883789
Validation loss: 1.550482302583674

Epoch: 5| Step: 1
Training loss: 0.11519782245159149
Validation loss: 1.5453778607870943

Epoch: 5| Step: 2
Training loss: 0.10523494333028793
Validation loss: 1.5394969153147873

Epoch: 5| Step: 3
Training loss: 0.09149742126464844
Validation loss: 1.5391918254154984

Epoch: 5| Step: 4
Training loss: 0.130691260099411
Validation loss: 1.52914987456414

Epoch: 5| Step: 5
Training loss: 0.11792345345020294
Validation loss: 1.538896632450883

Epoch: 5| Step: 6
Training loss: 0.062452249228954315
Validation loss: 1.5284286904078659

Epoch: 5| Step: 7
Training loss: 0.07394357025623322
Validation loss: 1.5143911018166492

Epoch: 5| Step: 8
Training loss: 0.06591325998306274
Validation loss: 1.5053265453666769

Epoch: 5| Step: 9
Training loss: 0.13369043171405792
Validation loss: 1.516953924650787

Epoch: 5| Step: 10
Training loss: 0.09582389891147614
Validation loss: 1.504051201446082

Epoch: 527| Step: 0
Training loss: 0.11769096553325653
Validation loss: 1.513872269661196

Epoch: 5| Step: 1
Training loss: 0.12381074577569962
Validation loss: 1.522133106826454

Epoch: 5| Step: 2
Training loss: 0.09505178034305573
Validation loss: 1.5030693713054861

Epoch: 5| Step: 3
Training loss: 0.08537059277296066
Validation loss: 1.5264942902390675

Epoch: 5| Step: 4
Training loss: 0.08173050731420517
Validation loss: 1.5141388549599597

Epoch: 5| Step: 5
Training loss: 0.10315152257680893
Validation loss: 1.5343139863783313

Epoch: 5| Step: 6
Training loss: 0.06824365258216858
Validation loss: 1.5248046869872718

Epoch: 5| Step: 7
Training loss: 0.1846618354320526
Validation loss: 1.497503339603383

Epoch: 5| Step: 8
Training loss: 0.07198412716388702
Validation loss: 1.4952840061597927

Epoch: 5| Step: 9
Training loss: 0.11010036617517471
Validation loss: 1.526273000624872

Epoch: 5| Step: 10
Training loss: 0.04903857409954071
Validation loss: 1.4989217558214742

Epoch: 528| Step: 0
Training loss: 0.08159271627664566
Validation loss: 1.49105546551366

Epoch: 5| Step: 1
Training loss: 0.04594751447439194
Validation loss: 1.512099338475094

Epoch: 5| Step: 2
Training loss: 0.07234717905521393
Validation loss: 1.5069710118796236

Epoch: 5| Step: 3
Training loss: 0.07009322941303253
Validation loss: 1.4949894669235393

Epoch: 5| Step: 4
Training loss: 0.06712348014116287
Validation loss: 1.50500690039768

Epoch: 5| Step: 5
Training loss: 0.1079808846116066
Validation loss: 1.5093973234135618

Epoch: 5| Step: 6
Training loss: 0.08537515252828598
Validation loss: 1.5534999421847764

Epoch: 5| Step: 7
Training loss: 0.17301714420318604
Validation loss: 1.5486778187495407

Epoch: 5| Step: 8
Training loss: 0.09000393748283386
Validation loss: 1.5081249719024987

Epoch: 5| Step: 9
Training loss: 0.11542700231075287
Validation loss: 1.5226883375516502

Epoch: 5| Step: 10
Training loss: 0.13494743406772614
Validation loss: 1.5331849077696442

Epoch: 529| Step: 0
Training loss: 0.08940313756465912
Validation loss: 1.523474589470894

Epoch: 5| Step: 1
Training loss: 0.08908484876155853
Validation loss: 1.5493463393180602

Epoch: 5| Step: 2
Training loss: 0.12082003057003021
Validation loss: 1.5163779117727791

Epoch: 5| Step: 3
Training loss: 0.09498883783817291
Validation loss: 1.4963065603727936

Epoch: 5| Step: 4
Training loss: 0.09471997618675232
Validation loss: 1.4939181022746588

Epoch: 5| Step: 5
Training loss: 0.12238916009664536
Validation loss: 1.4671902656555176

Epoch: 5| Step: 6
Training loss: 0.10799665749073029
Validation loss: 1.447630259298509

Epoch: 5| Step: 7
Training loss: 0.09846431016921997
Validation loss: 1.4442631544605378

Epoch: 5| Step: 8
Training loss: 0.09702276438474655
Validation loss: 1.460219189043968

Epoch: 5| Step: 9
Training loss: 0.1459933966398239
Validation loss: 1.4961435871739541

Epoch: 5| Step: 10
Training loss: 0.1351134032011032
Validation loss: 1.4808712197888283

Epoch: 530| Step: 0
Training loss: 0.1388312429189682
Validation loss: 1.4935838506426862

Epoch: 5| Step: 1
Training loss: 0.06775394082069397
Validation loss: 1.502875756191951

Epoch: 5| Step: 2
Training loss: 0.0838201493024826
Validation loss: 1.5108514601184475

Epoch: 5| Step: 3
Training loss: 0.06364835798740387
Validation loss: 1.492535533443574

Epoch: 5| Step: 4
Training loss: 0.09616196155548096
Validation loss: 1.4799699629506757

Epoch: 5| Step: 5
Training loss: 0.10754154622554779
Validation loss: 1.5183134002070273

Epoch: 5| Step: 6
Training loss: 0.048160798847675323
Validation loss: 1.5301295826511998

Epoch: 5| Step: 7
Training loss: 0.10544218868017197
Validation loss: 1.5235504193972516

Epoch: 5| Step: 8
Training loss: 0.08756302297115326
Validation loss: 1.5306383640535417

Epoch: 5| Step: 9
Training loss: 0.1367049664258957
Validation loss: 1.5059620885438816

Epoch: 5| Step: 10
Training loss: 0.11334221065044403
Validation loss: 1.5050164268862816

Epoch: 531| Step: 0
Training loss: 0.08613720536231995
Validation loss: 1.5170134761000191

Epoch: 5| Step: 1
Training loss: 0.04962502792477608
Validation loss: 1.5154418727403045

Epoch: 5| Step: 2
Training loss: 0.10095598548650742
Validation loss: 1.5246806708715295

Epoch: 5| Step: 3
Training loss: 0.13192608952522278
Validation loss: 1.5305252049558906

Epoch: 5| Step: 4
Training loss: 0.10148891061544418
Validation loss: 1.506610720388351

Epoch: 5| Step: 5
Training loss: 0.08737224340438843
Validation loss: 1.5345066926812614

Epoch: 5| Step: 6
Training loss: 0.15270362794399261
Validation loss: 1.5126943210119843

Epoch: 5| Step: 7
Training loss: 0.12043537944555283
Validation loss: 1.5264656005367156

Epoch: 5| Step: 8
Training loss: 0.05036165192723274
Validation loss: 1.5396877270872875

Epoch: 5| Step: 9
Training loss: 0.0838477835059166
Validation loss: 1.5164522150511384

Epoch: 5| Step: 10
Training loss: 0.1102328673005104
Validation loss: 1.510625800778789

Epoch: 532| Step: 0
Training loss: 0.0668582171201706
Validation loss: 1.5111848628649147

Epoch: 5| Step: 1
Training loss: 0.08445864915847778
Validation loss: 1.5345641304087896

Epoch: 5| Step: 2
Training loss: 0.10786167532205582
Validation loss: 1.5123824143922457

Epoch: 5| Step: 3
Training loss: 0.10265904664993286
Validation loss: 1.528248047315946

Epoch: 5| Step: 4
Training loss: 0.1380944401025772
Validation loss: 1.5244668504243255

Epoch: 5| Step: 5
Training loss: 0.06535222381353378
Validation loss: 1.5251672947278587

Epoch: 5| Step: 6
Training loss: 0.07459987699985504
Validation loss: 1.528643988793896

Epoch: 5| Step: 7
Training loss: 0.10139060020446777
Validation loss: 1.5370588558976368

Epoch: 5| Step: 8
Training loss: 0.1428384631872177
Validation loss: 1.5466899551371092

Epoch: 5| Step: 9
Training loss: 0.14643383026123047
Validation loss: 1.550839900970459

Epoch: 5| Step: 10
Training loss: 0.06918945163488388
Validation loss: 1.5545606946432462

Epoch: 533| Step: 0
Training loss: 0.11402672529220581
Validation loss: 1.544783523005824

Epoch: 5| Step: 1
Training loss: 0.09313631057739258
Validation loss: 1.5580774129077952

Epoch: 5| Step: 2
Training loss: 0.1595565378665924
Validation loss: 1.5314706320403724

Epoch: 5| Step: 3
Training loss: 0.0662553608417511
Validation loss: 1.5189557370319162

Epoch: 5| Step: 4
Training loss: 0.10620496422052383
Validation loss: 1.5329863832842918

Epoch: 5| Step: 5
Training loss: 0.13022074103355408
Validation loss: 1.5216754828729937

Epoch: 5| Step: 6
Training loss: 0.12046907097101212
Validation loss: 1.5339217532065608

Epoch: 5| Step: 7
Training loss: 0.09244252741336823
Validation loss: 1.5042341652736868

Epoch: 5| Step: 8
Training loss: 0.10973618179559708
Validation loss: 1.5059201217466784

Epoch: 5| Step: 9
Training loss: 0.0571826696395874
Validation loss: 1.5211841560179187

Epoch: 5| Step: 10
Training loss: 0.10031040757894516
Validation loss: 1.5109423001607258

Epoch: 534| Step: 0
Training loss: 0.09440336376428604
Validation loss: 1.5254585294313328

Epoch: 5| Step: 1
Training loss: 0.06738103181123734
Validation loss: 1.5265574006624119

Epoch: 5| Step: 2
Training loss: 0.11504809558391571
Validation loss: 1.5558567508574455

Epoch: 5| Step: 3
Training loss: 0.12891319394111633
Validation loss: 1.542888484975343

Epoch: 5| Step: 4
Training loss: 0.09419051557779312
Validation loss: 1.543635319637996

Epoch: 5| Step: 5
Training loss: 0.10599954426288605
Validation loss: 1.5391445377821564

Epoch: 5| Step: 6
Training loss: 0.14120395481586456
Validation loss: 1.5470936407325089

Epoch: 5| Step: 7
Training loss: 0.08586572855710983
Validation loss: 1.5437510705763293

Epoch: 5| Step: 8
Training loss: 0.08671881258487701
Validation loss: 1.5321302285758398

Epoch: 5| Step: 9
Training loss: 0.10039371252059937
Validation loss: 1.5239075614560036

Epoch: 5| Step: 10
Training loss: 0.04481223225593567
Validation loss: 1.562615450992379

Epoch: 535| Step: 0
Training loss: 0.0669601559638977
Validation loss: 1.5536279460435272

Epoch: 5| Step: 1
Training loss: 0.10704632103443146
Validation loss: 1.5600036703130251

Epoch: 5| Step: 2
Training loss: 0.0432267040014267
Validation loss: 1.5447348458792574

Epoch: 5| Step: 3
Training loss: 0.10599958896636963
Validation loss: 1.5635217671753259

Epoch: 5| Step: 4
Training loss: 0.1263136863708496
Validation loss: 1.543630680730266

Epoch: 5| Step: 5
Training loss: 0.09931156784296036
Validation loss: 1.537014445950908

Epoch: 5| Step: 6
Training loss: 0.053850531578063965
Validation loss: 1.5509770301080519

Epoch: 5| Step: 7
Training loss: 0.08903435617685318
Validation loss: 1.520195504670502

Epoch: 5| Step: 8
Training loss: 0.06834237277507782
Validation loss: 1.5264431789357176

Epoch: 5| Step: 9
Training loss: 0.07246504724025726
Validation loss: 1.5496658753323298

Epoch: 5| Step: 10
Training loss: 0.12706175446510315
Validation loss: 1.5308083077912689

Epoch: 536| Step: 0
Training loss: 0.060379404574632645
Validation loss: 1.5314376546490578

Epoch: 5| Step: 1
Training loss: 0.07919037342071533
Validation loss: 1.5577934172845656

Epoch: 5| Step: 2
Training loss: 0.09708113968372345
Validation loss: 1.540233023705021

Epoch: 5| Step: 3
Training loss: 0.08549666404724121
Validation loss: 1.5411766216319094

Epoch: 5| Step: 4
Training loss: 0.11385645717382431
Validation loss: 1.5482571048121299

Epoch: 5| Step: 5
Training loss: 0.09707819670438766
Validation loss: 1.5327506667824202

Epoch: 5| Step: 6
Training loss: 0.10072162002325058
Validation loss: 1.5468658849757204

Epoch: 5| Step: 7
Training loss: 0.09071580320596695
Validation loss: 1.542639647760699

Epoch: 5| Step: 8
Training loss: 0.12610308825969696
Validation loss: 1.536074931903552

Epoch: 5| Step: 9
Training loss: 0.10039973258972168
Validation loss: 1.514643483264472

Epoch: 5| Step: 10
Training loss: 0.1348874717950821
Validation loss: 1.522064616603236

Epoch: 537| Step: 0
Training loss: 0.12985330820083618
Validation loss: 1.557569920375783

Epoch: 5| Step: 1
Training loss: 0.061796627938747406
Validation loss: 1.5421785103377474

Epoch: 5| Step: 2
Training loss: 0.07399221509695053
Validation loss: 1.5411151404021888

Epoch: 5| Step: 3
Training loss: 0.08588290959596634
Validation loss: 1.5241141934548654

Epoch: 5| Step: 4
Training loss: 0.12201082706451416
Validation loss: 1.5412289275917956

Epoch: 5| Step: 5
Training loss: 0.14864221215248108
Validation loss: 1.5630093210486955

Epoch: 5| Step: 6
Training loss: 0.17289793491363525
Validation loss: 1.529076398059886

Epoch: 5| Step: 7
Training loss: 0.12886971235275269
Validation loss: 1.4946830439311203

Epoch: 5| Step: 8
Training loss: 0.12653307616710663
Validation loss: 1.4884664268903836

Epoch: 5| Step: 9
Training loss: 0.12812082469463348
Validation loss: 1.4762889300623248

Epoch: 5| Step: 10
Training loss: 0.1473998725414276
Validation loss: 1.4950826424424366

Epoch: 538| Step: 0
Training loss: 0.1348661184310913
Validation loss: 1.471640863726216

Epoch: 5| Step: 1
Training loss: 0.1089162826538086
Validation loss: 1.5035688364377586

Epoch: 5| Step: 2
Training loss: 0.07198842614889145
Validation loss: 1.4919094988094863

Epoch: 5| Step: 3
Training loss: 0.08302681148052216
Validation loss: 1.4829785452094129

Epoch: 5| Step: 4
Training loss: 0.13022829592227936
Validation loss: 1.5244350279531171

Epoch: 5| Step: 5
Training loss: 0.14402762055397034
Validation loss: 1.5450597732297835

Epoch: 5| Step: 6
Training loss: 0.13861289620399475
Validation loss: 1.5468521130982267

Epoch: 5| Step: 7
Training loss: 0.09804971516132355
Validation loss: 1.555772118670966

Epoch: 5| Step: 8
Training loss: 0.08696777373552322
Validation loss: 1.5023595543317898

Epoch: 5| Step: 9
Training loss: 0.07838501036167145
Validation loss: 1.5286020168694117

Epoch: 5| Step: 10
Training loss: 0.07784231752157211
Validation loss: 1.5267751909071399

Epoch: 539| Step: 0
Training loss: 0.10832463204860687
Validation loss: 1.5437210323990032

Epoch: 5| Step: 1
Training loss: 0.09299218654632568
Validation loss: 1.5545075067909815

Epoch: 5| Step: 2
Training loss: 0.103113554418087
Validation loss: 1.583839334467406

Epoch: 5| Step: 3
Training loss: 0.07830468565225601
Validation loss: 1.5810416385691652

Epoch: 5| Step: 4
Training loss: 0.09922067075967789
Validation loss: 1.5895239332670807

Epoch: 5| Step: 5
Training loss: 0.054812002927064896
Validation loss: 1.601335725476665

Epoch: 5| Step: 6
Training loss: 0.17312999069690704
Validation loss: 1.5806700824409403

Epoch: 5| Step: 7
Training loss: 0.1078161969780922
Validation loss: 1.5683204871352001

Epoch: 5| Step: 8
Training loss: 0.039359092712402344
Validation loss: 1.548172676435081

Epoch: 5| Step: 9
Training loss: 0.09778793901205063
Validation loss: 1.5320595592580817

Epoch: 5| Step: 10
Training loss: 0.10712713748216629
Validation loss: 1.5250642171470068

Epoch: 540| Step: 0
Training loss: 0.12207026779651642
Validation loss: 1.5195089001809396

Epoch: 5| Step: 1
Training loss: 0.0832199975848198
Validation loss: 1.5383458983513616

Epoch: 5| Step: 2
Training loss: 0.10849521309137344
Validation loss: 1.5421933076714958

Epoch: 5| Step: 3
Training loss: 0.06589384377002716
Validation loss: 1.5377500903221868

Epoch: 5| Step: 4
Training loss: 0.12623992562294006
Validation loss: 1.5277664994680753

Epoch: 5| Step: 5
Training loss: 0.09706666320562363
Validation loss: 1.5181602431881813

Epoch: 5| Step: 6
Training loss: 0.06759707629680634
Validation loss: 1.5250886050603722

Epoch: 5| Step: 7
Training loss: 0.10118935257196426
Validation loss: 1.5065726484021833

Epoch: 5| Step: 8
Training loss: 0.0633862316608429
Validation loss: 1.528098702430725

Epoch: 5| Step: 9
Training loss: 0.07603686302900314
Validation loss: 1.533885100836395

Epoch: 5| Step: 10
Training loss: 0.09577085077762604
Validation loss: 1.530384721294526

Epoch: 541| Step: 0
Training loss: 0.1219843178987503
Validation loss: 1.5227610449637137

Epoch: 5| Step: 1
Training loss: 0.09976951032876968
Validation loss: 1.4938606908244472

Epoch: 5| Step: 2
Training loss: 0.07784692198038101
Validation loss: 1.4797599572007374

Epoch: 5| Step: 3
Training loss: 0.0650210976600647
Validation loss: 1.5075831451723654

Epoch: 5| Step: 4
Training loss: 0.06520672142505646
Validation loss: 1.4948407398757113

Epoch: 5| Step: 5
Training loss: 0.07986514270305634
Validation loss: 1.4962223883598083

Epoch: 5| Step: 6
Training loss: 0.10784486681222916
Validation loss: 1.4862819499866937

Epoch: 5| Step: 7
Training loss: 0.14245536923408508
Validation loss: 1.4714718864810081

Epoch: 5| Step: 8
Training loss: 0.09354563802480698
Validation loss: 1.4936640884286614

Epoch: 5| Step: 9
Training loss: 0.10815832763910294
Validation loss: 1.4669616235199796

Epoch: 5| Step: 10
Training loss: 0.052998051047325134
Validation loss: 1.4681036677411807

Epoch: 542| Step: 0
Training loss: 0.08560789376497269
Validation loss: 1.5149920448180167

Epoch: 5| Step: 1
Training loss: 0.10977385193109512
Validation loss: 1.5132976706309984

Epoch: 5| Step: 2
Training loss: 0.09127185493707657
Validation loss: 1.4983698706473074

Epoch: 5| Step: 3
Training loss: 0.10662345588207245
Validation loss: 1.506728897812546

Epoch: 5| Step: 4
Training loss: 0.10979306697845459
Validation loss: 1.5258161521727038

Epoch: 5| Step: 5
Training loss: 0.12208418548107147
Validation loss: 1.4987891310004777

Epoch: 5| Step: 6
Training loss: 0.12293622642755508
Validation loss: 1.5134424970995994

Epoch: 5| Step: 7
Training loss: 0.09030793607234955
Validation loss: 1.5344904456087338

Epoch: 5| Step: 8
Training loss: 0.09314515441656113
Validation loss: 1.5292666983860794

Epoch: 5| Step: 9
Training loss: 0.08524733036756516
Validation loss: 1.5548751790036437

Epoch: 5| Step: 10
Training loss: 0.08546367287635803
Validation loss: 1.5455631812413533

Epoch: 543| Step: 0
Training loss: 0.0906638577580452
Validation loss: 1.5318465328985644

Epoch: 5| Step: 1
Training loss: 0.08190598338842392
Validation loss: 1.5274048479654456

Epoch: 5| Step: 2
Training loss: 0.061882637441158295
Validation loss: 1.53259906717526

Epoch: 5| Step: 3
Training loss: 0.10799777507781982
Validation loss: 1.5451629469471593

Epoch: 5| Step: 4
Training loss: 0.09970225393772125
Validation loss: 1.52349167741755

Epoch: 5| Step: 5
Training loss: 0.10550203174352646
Validation loss: 1.5239991295722224

Epoch: 5| Step: 6
Training loss: 0.07533200085163116
Validation loss: 1.5259399670426563

Epoch: 5| Step: 7
Training loss: 0.07487804442644119
Validation loss: 1.4932822309514528

Epoch: 5| Step: 8
Training loss: 0.1053004041314125
Validation loss: 1.5378624931458504

Epoch: 5| Step: 9
Training loss: 0.08607110381126404
Validation loss: 1.5314634282101867

Epoch: 5| Step: 10
Training loss: 0.09500651061534882
Validation loss: 1.503590642765004

Epoch: 544| Step: 0
Training loss: 0.07909435033798218
Validation loss: 1.5287414302108109

Epoch: 5| Step: 1
Training loss: 0.11889991909265518
Validation loss: 1.5163176687814857

Epoch: 5| Step: 2
Training loss: 0.08800583332777023
Validation loss: 1.507952597833449

Epoch: 5| Step: 3
Training loss: 0.06633687019348145
Validation loss: 1.5014460958460325

Epoch: 5| Step: 4
Training loss: 0.09503120929002762
Validation loss: 1.5098581429450744

Epoch: 5| Step: 5
Training loss: 0.09424102306365967
Validation loss: 1.5171496304132606

Epoch: 5| Step: 6
Training loss: 0.13994038105010986
Validation loss: 1.5131130885052424

Epoch: 5| Step: 7
Training loss: 0.05468853563070297
Validation loss: 1.517933343046455

Epoch: 5| Step: 8
Training loss: 0.059620797634124756
Validation loss: 1.5173488483634046

Epoch: 5| Step: 9
Training loss: 0.06217247247695923
Validation loss: 1.5014814830595447

Epoch: 5| Step: 10
Training loss: 0.04830584675073624
Validation loss: 1.504881728080011

Epoch: 545| Step: 0
Training loss: 0.07457985728979111
Validation loss: 1.4923116058431647

Epoch: 5| Step: 1
Training loss: 0.06388552486896515
Validation loss: 1.5145001590892833

Epoch: 5| Step: 2
Training loss: 0.1236860528588295
Validation loss: 1.5040318382683622

Epoch: 5| Step: 3
Training loss: 0.11925363540649414
Validation loss: 1.5211927019139773

Epoch: 5| Step: 4
Training loss: 0.1305316984653473
Validation loss: 1.4847524082788857

Epoch: 5| Step: 5
Training loss: 0.11202528327703476
Validation loss: 1.512893815194407

Epoch: 5| Step: 6
Training loss: 0.08770531415939331
Validation loss: 1.4974379411307714

Epoch: 5| Step: 7
Training loss: 0.1026853695511818
Validation loss: 1.4956913801931566

Epoch: 5| Step: 8
Training loss: 0.1249186247587204
Validation loss: 1.5157726003277687

Epoch: 5| Step: 9
Training loss: 0.07550334185361862
Validation loss: 1.5127625003937752

Epoch: 5| Step: 10
Training loss: 0.0823914110660553
Validation loss: 1.5067213607090775

Epoch: 546| Step: 0
Training loss: 0.11710627377033234
Validation loss: 1.5182912324064521

Epoch: 5| Step: 1
Training loss: 0.09212924540042877
Validation loss: 1.5136703163064935

Epoch: 5| Step: 2
Training loss: 0.08915264904499054
Validation loss: 1.5067741460697626

Epoch: 5| Step: 3
Training loss: 0.09864567220211029
Validation loss: 1.4894943839760237

Epoch: 5| Step: 4
Training loss: 0.07355451583862305
Validation loss: 1.5191765626271565

Epoch: 5| Step: 5
Training loss: 0.10064089298248291
Validation loss: 1.5163473685582478

Epoch: 5| Step: 6
Training loss: 0.1078089028596878
Validation loss: 1.5214073145261375

Epoch: 5| Step: 7
Training loss: 0.07161561399698257
Validation loss: 1.5348355641929052

Epoch: 5| Step: 8
Training loss: 0.09742750972509384
Validation loss: 1.5325070119673205

Epoch: 5| Step: 9
Training loss: 0.0967920571565628
Validation loss: 1.5452985186730661

Epoch: 5| Step: 10
Training loss: 0.08318472653627396
Validation loss: 1.5065674807435723

Epoch: 547| Step: 0
Training loss: 0.07570724189281464
Validation loss: 1.547049089144635

Epoch: 5| Step: 1
Training loss: 0.05367162823677063
Validation loss: 1.5129798663559781

Epoch: 5| Step: 2
Training loss: 0.08309619128704071
Validation loss: 1.5135163363590036

Epoch: 5| Step: 3
Training loss: 0.10674800723791122
Validation loss: 1.5100598175038573

Epoch: 5| Step: 4
Training loss: 0.06797833740711212
Validation loss: 1.4977464509266678

Epoch: 5| Step: 5
Training loss: 0.11312322318553925
Validation loss: 1.4976215798367736

Epoch: 5| Step: 6
Training loss: 0.12107864767313004
Validation loss: 1.4853782141080467

Epoch: 5| Step: 7
Training loss: 0.12659993767738342
Validation loss: 1.5155637482161164

Epoch: 5| Step: 8
Training loss: 0.1263435333967209
Validation loss: 1.4894212465132437

Epoch: 5| Step: 9
Training loss: 0.04529071971774101
Validation loss: 1.5015065785377257

Epoch: 5| Step: 10
Training loss: 0.14192751049995422
Validation loss: 1.509074232911551

Epoch: 548| Step: 0
Training loss: 0.09994427859783173
Validation loss: 1.5133085212399882

Epoch: 5| Step: 1
Training loss: 0.09577742218971252
Validation loss: 1.554263630220967

Epoch: 5| Step: 2
Training loss: 0.16104179620742798
Validation loss: 1.55221434562437

Epoch: 5| Step: 3
Training loss: 0.08488918840885162
Validation loss: 1.5387699719398253

Epoch: 5| Step: 4
Training loss: 0.10002455860376358
Validation loss: 1.5263024517284927

Epoch: 5| Step: 5
Training loss: 0.12285925447940826
Validation loss: 1.5222265156366492

Epoch: 5| Step: 6
Training loss: 0.11989424377679825
Validation loss: 1.5495850898886239

Epoch: 5| Step: 7
Training loss: 0.11108358204364777
Validation loss: 1.5528678201859998

Epoch: 5| Step: 8
Training loss: 0.1049075573682785
Validation loss: 1.5329549594592022

Epoch: 5| Step: 9
Training loss: 0.06943517178297043
Validation loss: 1.551125664864817

Epoch: 5| Step: 10
Training loss: 0.11383076757192612
Validation loss: 1.5357538397594164

Epoch: 549| Step: 0
Training loss: 0.09522300958633423
Validation loss: 1.5537309274878552

Epoch: 5| Step: 1
Training loss: 0.10041610151529312
Validation loss: 1.5688725030550392

Epoch: 5| Step: 2
Training loss: 0.1499168574810028
Validation loss: 1.548863027685432

Epoch: 5| Step: 3
Training loss: 0.1904628723859787
Validation loss: 1.6002285185680594

Epoch: 5| Step: 4
Training loss: 0.0528097040951252
Validation loss: 1.5497274321894492

Epoch: 5| Step: 5
Training loss: 0.07210445404052734
Validation loss: 1.5285346367025887

Epoch: 5| Step: 6
Training loss: 0.0782865509390831
Validation loss: 1.5303300260215678

Epoch: 5| Step: 7
Training loss: 0.16305525600910187
Validation loss: 1.5211001416688323

Epoch: 5| Step: 8
Training loss: 0.10858603566884995
Validation loss: 1.5145257006409347

Epoch: 5| Step: 9
Training loss: 0.06881003826856613
Validation loss: 1.4948227072274813

Epoch: 5| Step: 10
Training loss: 0.23227432370185852
Validation loss: 1.510642998321082

Epoch: 550| Step: 0
Training loss: 0.05519597977399826
Validation loss: 1.5036865536884596

Epoch: 5| Step: 1
Training loss: 0.06656177341938019
Validation loss: 1.4934513171513875

Epoch: 5| Step: 2
Training loss: 0.07873858511447906
Validation loss: 1.4987620038370932

Epoch: 5| Step: 3
Training loss: 0.1391436755657196
Validation loss: 1.5144060536097455

Epoch: 5| Step: 4
Training loss: 0.10059542953968048
Validation loss: 1.4978597446154522

Epoch: 5| Step: 5
Training loss: 0.13621695339679718
Validation loss: 1.5157864875690912

Epoch: 5| Step: 6
Training loss: 0.09260715544223785
Validation loss: 1.4642880129557785

Epoch: 5| Step: 7
Training loss: 0.08186592906713486
Validation loss: 1.4826197957479825

Epoch: 5| Step: 8
Training loss: 0.10370297729969025
Validation loss: 1.480471141876713

Epoch: 5| Step: 9
Training loss: 0.10167290270328522
Validation loss: 1.4956874116774528

Epoch: 5| Step: 10
Training loss: 0.1315440833568573
Validation loss: 1.4763575702585199

Testing loss: 2.044350014792548
