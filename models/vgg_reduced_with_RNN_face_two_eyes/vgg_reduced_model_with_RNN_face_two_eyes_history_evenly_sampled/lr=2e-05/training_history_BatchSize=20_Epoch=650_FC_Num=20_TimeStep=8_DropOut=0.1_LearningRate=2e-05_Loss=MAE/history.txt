Epoch: 1| Step: 0
Training loss: 6.381206512451172
Validation loss: 5.2533999976291454

Epoch: 5| Step: 1
Training loss: 5.139142990112305
Validation loss: 5.230639406429824

Epoch: 5| Step: 2
Training loss: 3.91288685798645
Validation loss: 5.2081071638291885

Epoch: 5| Step: 3
Training loss: 3.7995047569274902
Validation loss: 5.1847442196261495

Epoch: 5| Step: 4
Training loss: 4.144453525543213
Validation loss: 5.158324323674684

Epoch: 5| Step: 5
Training loss: 5.104592323303223
Validation loss: 5.128855848825106

Epoch: 5| Step: 6
Training loss: 4.192605495452881
Validation loss: 5.094719635543003

Epoch: 5| Step: 7
Training loss: 5.279463768005371
Validation loss: 5.056236261962562

Epoch: 5| Step: 8
Training loss: 5.802855968475342
Validation loss: 5.014104986703524

Epoch: 5| Step: 9
Training loss: 4.8927388191223145
Validation loss: 4.968573518978652

Epoch: 5| Step: 10
Training loss: 5.359602451324463
Validation loss: 4.920593302737

Epoch: 2| Step: 0
Training loss: 5.43477725982666
Validation loss: 4.867911177296793

Epoch: 5| Step: 1
Training loss: 4.447909355163574
Validation loss: 4.812169556976647

Epoch: 5| Step: 2
Training loss: 4.71328067779541
Validation loss: 4.755085786183675

Epoch: 5| Step: 3
Training loss: 4.271207809448242
Validation loss: 4.695621834006361

Epoch: 5| Step: 4
Training loss: 3.954235792160034
Validation loss: 4.6337565657913045

Epoch: 5| Step: 5
Training loss: 3.925727128982544
Validation loss: 4.567995327775196

Epoch: 5| Step: 6
Training loss: 4.063216686248779
Validation loss: 4.502049892179428

Epoch: 5| Step: 7
Training loss: 5.426805019378662
Validation loss: 4.439560008305375

Epoch: 5| Step: 8
Training loss: 4.809725761413574
Validation loss: 4.380946031180761

Epoch: 5| Step: 9
Training loss: 4.015982627868652
Validation loss: 4.323694998218167

Epoch: 5| Step: 10
Training loss: 2.9500701427459717
Validation loss: 4.268683110513995

Epoch: 3| Step: 0
Training loss: 3.6393446922302246
Validation loss: 4.215383832172681

Epoch: 5| Step: 1
Training loss: 3.7757022380828857
Validation loss: 4.159105536758259

Epoch: 5| Step: 2
Training loss: 3.472851276397705
Validation loss: 4.096328991715626

Epoch: 5| Step: 3
Training loss: 5.801053524017334
Validation loss: 4.044002640631891

Epoch: 5| Step: 4
Training loss: 3.0163986682891846
Validation loss: 4.002679873538273

Epoch: 5| Step: 5
Training loss: 2.7993831634521484
Validation loss: 3.9678409253397295

Epoch: 5| Step: 6
Training loss: 4.493177890777588
Validation loss: 3.9385979739568566

Epoch: 5| Step: 7
Training loss: 3.961860179901123
Validation loss: 3.910469626867643

Epoch: 5| Step: 8
Training loss: 4.133880138397217
Validation loss: 3.886389063250634

Epoch: 5| Step: 9
Training loss: 3.1017136573791504
Validation loss: 3.8591605565881215

Epoch: 5| Step: 10
Training loss: 4.133286952972412
Validation loss: 3.8313072881390973

Epoch: 4| Step: 0
Training loss: 3.4276652336120605
Validation loss: 3.799354922386908

Epoch: 5| Step: 1
Training loss: 3.221569776535034
Validation loss: 3.765655235577655

Epoch: 5| Step: 2
Training loss: 2.682204008102417
Validation loss: 3.7349786860968477

Epoch: 5| Step: 3
Training loss: 3.316180467605591
Validation loss: 3.7101056498865925

Epoch: 5| Step: 4
Training loss: 3.3237318992614746
Validation loss: 3.687438941770984

Epoch: 5| Step: 5
Training loss: 3.900794506072998
Validation loss: 3.6618822108032885

Epoch: 5| Step: 6
Training loss: 4.353140830993652
Validation loss: 3.6341236483666206

Epoch: 5| Step: 7
Training loss: 3.7439396381378174
Validation loss: 3.6044498182112172

Epoch: 5| Step: 8
Training loss: 4.010852813720703
Validation loss: 3.5836169078785884

Epoch: 5| Step: 9
Training loss: 3.564101457595825
Validation loss: 3.5627865893866426

Epoch: 5| Step: 10
Training loss: 3.7884647846221924
Validation loss: 3.547659109997493

Epoch: 5| Step: 0
Training loss: 2.9499199390411377
Validation loss: 3.5263667491174515

Epoch: 5| Step: 1
Training loss: 3.5741944313049316
Validation loss: 3.521371959358133

Epoch: 5| Step: 2
Training loss: 2.8240628242492676
Validation loss: 3.495386549221572

Epoch: 5| Step: 3
Training loss: 3.1359479427337646
Validation loss: 3.472341368275304

Epoch: 5| Step: 4
Training loss: 2.683119535446167
Validation loss: 3.4596400389107327

Epoch: 5| Step: 5
Training loss: 3.265723705291748
Validation loss: 3.431780287014541

Epoch: 5| Step: 6
Training loss: 3.9560325145721436
Validation loss: 3.412708523452923

Epoch: 5| Step: 7
Training loss: 3.710008144378662
Validation loss: 3.3943064033344226

Epoch: 5| Step: 8
Training loss: 3.2207894325256348
Validation loss: 3.3771214715896116

Epoch: 5| Step: 9
Training loss: 3.7858071327209473
Validation loss: 3.364664964778449

Epoch: 5| Step: 10
Training loss: 4.08049201965332
Validation loss: 3.346556237948838

Epoch: 6| Step: 0
Training loss: 2.831787586212158
Validation loss: 3.3329017905778784

Epoch: 5| Step: 1
Training loss: 2.841169834136963
Validation loss: 3.3210870732543287

Epoch: 5| Step: 2
Training loss: 3.051978588104248
Validation loss: 3.3093527183737805

Epoch: 5| Step: 3
Training loss: 2.8808624744415283
Validation loss: 3.3083647117819837

Epoch: 5| Step: 4
Training loss: 3.4572625160217285
Validation loss: 3.2991542534161638

Epoch: 5| Step: 5
Training loss: 2.7112154960632324
Validation loss: 3.2940331633372972

Epoch: 5| Step: 6
Training loss: 3.813443660736084
Validation loss: 3.287132232419906

Epoch: 5| Step: 7
Training loss: 3.0074398517608643
Validation loss: 3.27440232358953

Epoch: 5| Step: 8
Training loss: 4.637139320373535
Validation loss: 3.2607347221784693

Epoch: 5| Step: 9
Training loss: 3.2345683574676514
Validation loss: 3.248835886678388

Epoch: 5| Step: 10
Training loss: 3.395077705383301
Validation loss: 3.2382384141286216

Epoch: 7| Step: 0
Training loss: 3.7372288703918457
Validation loss: 3.2362147582474576

Epoch: 5| Step: 1
Training loss: 3.133554458618164
Validation loss: 3.235285051407353

Epoch: 5| Step: 2
Training loss: 2.943406581878662
Validation loss: 3.2181127507199525

Epoch: 5| Step: 3
Training loss: 3.6008219718933105
Validation loss: 3.2057720409926547

Epoch: 5| Step: 4
Training loss: 3.245422840118408
Validation loss: 3.204009235546153

Epoch: 5| Step: 5
Training loss: 2.670161724090576
Validation loss: 3.20041234518892

Epoch: 5| Step: 6
Training loss: 2.6495137214660645
Validation loss: 3.1970108350118003

Epoch: 5| Step: 7
Training loss: 3.382359743118286
Validation loss: 3.1849072415341615

Epoch: 5| Step: 8
Training loss: 3.191253662109375
Validation loss: 3.1752686936368226

Epoch: 5| Step: 9
Training loss: 2.8898797035217285
Validation loss: 3.1656593738063687

Epoch: 5| Step: 10
Training loss: 3.8236775398254395
Validation loss: 3.157806711812173

Epoch: 8| Step: 0
Training loss: 2.3277688026428223
Validation loss: 3.151067408182288

Epoch: 5| Step: 1
Training loss: 3.5453109741210938
Validation loss: 3.142978757940313

Epoch: 5| Step: 2
Training loss: 2.720888614654541
Validation loss: 3.134606194752519

Epoch: 5| Step: 3
Training loss: 3.503997802734375
Validation loss: 3.1276398474170315

Epoch: 5| Step: 4
Training loss: 3.5146210193634033
Validation loss: 3.1201370044421126

Epoch: 5| Step: 5
Training loss: 3.6370205879211426
Validation loss: 3.1109621832447667

Epoch: 5| Step: 6
Training loss: 3.4112610816955566
Validation loss: 3.1020460462057464

Epoch: 5| Step: 7
Training loss: 2.8863344192504883
Validation loss: 3.0950625352962042

Epoch: 5| Step: 8
Training loss: 3.2133545875549316
Validation loss: 3.097052538266746

Epoch: 5| Step: 9
Training loss: 2.8852591514587402
Validation loss: 3.092237227706499

Epoch: 5| Step: 10
Training loss: 2.858506679534912
Validation loss: 3.08931633990298

Epoch: 9| Step: 0
Training loss: 3.0672290325164795
Validation loss: 3.0930224951877388

Epoch: 5| Step: 1
Training loss: 2.6677002906799316
Validation loss: 3.07903798677588

Epoch: 5| Step: 2
Training loss: 3.511993885040283
Validation loss: 3.063922518043108

Epoch: 5| Step: 3
Training loss: 4.055968761444092
Validation loss: 3.0586538084091677

Epoch: 5| Step: 4
Training loss: 3.815331220626831
Validation loss: 3.0578766843324066

Epoch: 5| Step: 5
Training loss: 2.7568912506103516
Validation loss: 3.0569313239025813

Epoch: 5| Step: 6
Training loss: 3.8762943744659424
Validation loss: 3.049387842096308

Epoch: 5| Step: 7
Training loss: 2.6881914138793945
Validation loss: 3.0384367307027182

Epoch: 5| Step: 8
Training loss: 2.07084321975708
Validation loss: 3.0354603721249487

Epoch: 5| Step: 9
Training loss: 2.565154552459717
Validation loss: 3.033867420688752

Epoch: 5| Step: 10
Training loss: 3.075014114379883
Validation loss: 3.0342144273942515

Epoch: 10| Step: 0
Training loss: 3.2333366870880127
Validation loss: 3.0261528030518563

Epoch: 5| Step: 1
Training loss: 3.5569159984588623
Validation loss: 3.0298780830957557

Epoch: 5| Step: 2
Training loss: 2.512237071990967
Validation loss: 3.029505216947166

Epoch: 5| Step: 3
Training loss: 2.5464391708374023
Validation loss: 3.024009689208

Epoch: 5| Step: 4
Training loss: 3.3942437171936035
Validation loss: 3.019946147036809

Epoch: 5| Step: 5
Training loss: 2.6463232040405273
Validation loss: 3.0130549092446604

Epoch: 5| Step: 6
Training loss: 3.2571778297424316
Validation loss: 3.0192479728370585

Epoch: 5| Step: 7
Training loss: 3.317253828048706
Validation loss: 3.0114572073823664

Epoch: 5| Step: 8
Training loss: 3.3929200172424316
Validation loss: 3.003209267893145

Epoch: 5| Step: 9
Training loss: 2.929197072982788
Validation loss: 2.996425131315826

Epoch: 5| Step: 10
Training loss: 3.03009033203125
Validation loss: 2.991795542419598

Epoch: 11| Step: 0
Training loss: 2.4768435955047607
Validation loss: 2.9862974279670307

Epoch: 5| Step: 1
Training loss: 3.6481616497039795
Validation loss: 2.983756375569169

Epoch: 5| Step: 2
Training loss: 2.378293752670288
Validation loss: 2.981717740335772

Epoch: 5| Step: 3
Training loss: 2.740015983581543
Validation loss: 2.97930936403172

Epoch: 5| Step: 4
Training loss: 4.034576892852783
Validation loss: 2.976409335290232

Epoch: 5| Step: 5
Training loss: 2.785088062286377
Validation loss: 2.971014545809838

Epoch: 5| Step: 6
Training loss: 3.905169725418091
Validation loss: 2.966316989673081

Epoch: 5| Step: 7
Training loss: 2.110485076904297
Validation loss: 2.9616209717207056

Epoch: 5| Step: 8
Training loss: 2.976853847503662
Validation loss: 2.9596438125897477

Epoch: 5| Step: 9
Training loss: 2.8835320472717285
Validation loss: 2.9730753872984197

Epoch: 5| Step: 10
Training loss: 3.699777126312256
Validation loss: 2.951468693312778

Epoch: 12| Step: 0
Training loss: 3.5568346977233887
Validation loss: 2.950745846635552

Epoch: 5| Step: 1
Training loss: 2.8742480278015137
Validation loss: 2.947892019825597

Epoch: 5| Step: 2
Training loss: 2.8289592266082764
Validation loss: 2.945263321681689

Epoch: 5| Step: 3
Training loss: 3.6998260021209717
Validation loss: 2.959114695108065

Epoch: 5| Step: 4
Training loss: 2.398995876312256
Validation loss: 2.9409145052715013

Epoch: 5| Step: 5
Training loss: 3.244847536087036
Validation loss: 2.9406630557070494

Epoch: 5| Step: 6
Training loss: 2.700516939163208
Validation loss: 2.952413748669368

Epoch: 5| Step: 7
Training loss: 2.889331340789795
Validation loss: 2.9698631584003405

Epoch: 5| Step: 8
Training loss: 3.1575684547424316
Validation loss: 2.9616069768064763

Epoch: 5| Step: 9
Training loss: 2.802098512649536
Validation loss: 2.9382742169082805

Epoch: 5| Step: 10
Training loss: 3.2824318408966064
Validation loss: 2.9275589758350002

Epoch: 13| Step: 0
Training loss: 3.0975518226623535
Validation loss: 2.9264347399434736

Epoch: 5| Step: 1
Training loss: 2.96506929397583
Validation loss: 2.955533460904193

Epoch: 5| Step: 2
Training loss: 3.683164596557617
Validation loss: 2.947332928257604

Epoch: 5| Step: 3
Training loss: 2.886037826538086
Validation loss: 2.9147007798635833

Epoch: 5| Step: 4
Training loss: 3.1242804527282715
Validation loss: 2.913084158333399

Epoch: 5| Step: 5
Training loss: 1.964141845703125
Validation loss: 2.9119502011165825

Epoch: 5| Step: 6
Training loss: 2.697683572769165
Validation loss: 2.9152714334508425

Epoch: 5| Step: 7
Training loss: 2.8673508167266846
Validation loss: 2.904880598027219

Epoch: 5| Step: 8
Training loss: 3.4341087341308594
Validation loss: 2.8992966451952533

Epoch: 5| Step: 9
Training loss: 3.4231624603271484
Validation loss: 2.889580524095925

Epoch: 5| Step: 10
Training loss: 2.919674873352051
Validation loss: 2.890416335034114

Epoch: 14| Step: 0
Training loss: 3.4812896251678467
Validation loss: 2.8762982276178177

Epoch: 5| Step: 1
Training loss: 2.3962535858154297
Validation loss: 2.8677452738567064

Epoch: 5| Step: 2
Training loss: 3.0049097537994385
Validation loss: 2.8640071961187545

Epoch: 5| Step: 3
Training loss: 2.740180492401123
Validation loss: 2.8584593854924685

Epoch: 5| Step: 4
Training loss: 2.3326416015625
Validation loss: 2.8553963732975784

Epoch: 5| Step: 5
Training loss: 2.920194625854492
Validation loss: 2.8540821921440864

Epoch: 5| Step: 6
Training loss: 3.658867597579956
Validation loss: 2.846169182049331

Epoch: 5| Step: 7
Training loss: 3.005953311920166
Validation loss: 2.8497207010945966

Epoch: 5| Step: 8
Training loss: 2.394674777984619
Validation loss: 2.846003396536714

Epoch: 5| Step: 9
Training loss: 3.6500039100646973
Validation loss: 2.8395834276753087

Epoch: 5| Step: 10
Training loss: 3.046571731567383
Validation loss: 2.858047657115485

Epoch: 15| Step: 0
Training loss: 2.7696824073791504
Validation loss: 2.8540972150782102

Epoch: 5| Step: 1
Training loss: 2.5947823524475098
Validation loss: 2.841767987897319

Epoch: 5| Step: 2
Training loss: 2.812988758087158
Validation loss: 2.8376757508964947

Epoch: 5| Step: 3
Training loss: 3.2834529876708984
Validation loss: 2.8304626326407156

Epoch: 5| Step: 4
Training loss: 2.1479547023773193
Validation loss: 2.8197015280364663

Epoch: 5| Step: 5
Training loss: 2.919686794281006
Validation loss: 2.8177702247455554

Epoch: 5| Step: 6
Training loss: 3.3584792613983154
Validation loss: 2.815184224036432

Epoch: 5| Step: 7
Training loss: 2.641834259033203
Validation loss: 2.8110212895178024

Epoch: 5| Step: 8
Training loss: 3.5552258491516113
Validation loss: 2.8068803741085913

Epoch: 5| Step: 9
Training loss: 3.085744619369507
Validation loss: 2.805184805265037

Epoch: 5| Step: 10
Training loss: 3.230783700942993
Validation loss: 2.7982650623526624

Epoch: 16| Step: 0
Training loss: 3.074875593185425
Validation loss: 2.7946916857073383

Epoch: 5| Step: 1
Training loss: 2.813962697982788
Validation loss: 2.7980309019806566

Epoch: 5| Step: 2
Training loss: 2.9053866863250732
Validation loss: 2.7974352708426853

Epoch: 5| Step: 3
Training loss: 3.357091188430786
Validation loss: 2.789992606768044

Epoch: 5| Step: 4
Training loss: 2.8160388469696045
Validation loss: 2.7837589556171047

Epoch: 5| Step: 5
Training loss: 2.3662848472595215
Validation loss: 2.7807365925081315

Epoch: 5| Step: 6
Training loss: 2.549619674682617
Validation loss: 2.7793071064897763

Epoch: 5| Step: 7
Training loss: 3.056365489959717
Validation loss: 2.7779847678317817

Epoch: 5| Step: 8
Training loss: 2.9592394828796387
Validation loss: 2.7795082164067093

Epoch: 5| Step: 9
Training loss: 2.9478683471679688
Validation loss: 2.7733586603595364

Epoch: 5| Step: 10
Training loss: 3.3155910968780518
Validation loss: 2.7755671931851293

Epoch: 17| Step: 0
Training loss: 2.745121479034424
Validation loss: 2.799054830305038

Epoch: 5| Step: 1
Training loss: 3.4270434379577637
Validation loss: 2.8039260705312095

Epoch: 5| Step: 2
Training loss: 2.5880393981933594
Validation loss: 2.766185447733889

Epoch: 5| Step: 3
Training loss: 2.710946559906006
Validation loss: 2.7781321899865263

Epoch: 5| Step: 4
Training loss: 2.7172935009002686
Validation loss: 2.8067840042934624

Epoch: 5| Step: 5
Training loss: 2.3297886848449707
Validation loss: 2.810270183829851

Epoch: 5| Step: 6
Training loss: 3.3842978477478027
Validation loss: 2.818023266330842

Epoch: 5| Step: 7
Training loss: 3.4467968940734863
Validation loss: 2.815177963626

Epoch: 5| Step: 8
Training loss: 2.575145959854126
Validation loss: 2.782902120262064

Epoch: 5| Step: 9
Training loss: 3.5936012268066406
Validation loss: 2.7840599424095562

Epoch: 5| Step: 10
Training loss: 2.6286988258361816
Validation loss: 2.806798729845273

Epoch: 18| Step: 0
Training loss: 3.2315521240234375
Validation loss: 2.821712445187312

Epoch: 5| Step: 1
Training loss: 2.998394012451172
Validation loss: 2.8176249893762733

Epoch: 5| Step: 2
Training loss: 2.8101139068603516
Validation loss: 2.8077570981876825

Epoch: 5| Step: 3
Training loss: 2.745774507522583
Validation loss: 2.7886522841709915

Epoch: 5| Step: 4
Training loss: 2.64640736579895
Validation loss: 2.7686517238616943

Epoch: 5| Step: 5
Training loss: 3.443268299102783
Validation loss: 2.768085633554766

Epoch: 5| Step: 6
Training loss: 2.735971450805664
Validation loss: 2.763297039975402

Epoch: 5| Step: 7
Training loss: 3.2451541423797607
Validation loss: 2.761141023328227

Epoch: 5| Step: 8
Training loss: 2.535547971725464
Validation loss: 2.762084445645732

Epoch: 5| Step: 9
Training loss: 2.485854148864746
Validation loss: 2.756227295885804

Epoch: 5| Step: 10
Training loss: 3.2519357204437256
Validation loss: 2.7531134005515807

Epoch: 19| Step: 0
Training loss: 2.9828054904937744
Validation loss: 2.753061920083979

Epoch: 5| Step: 1
Training loss: 2.9980857372283936
Validation loss: 2.7506767293458343

Epoch: 5| Step: 2
Training loss: 3.213923931121826
Validation loss: 2.750660591228034

Epoch: 5| Step: 3
Training loss: 2.8481643199920654
Validation loss: 2.7494257265521633

Epoch: 5| Step: 4
Training loss: 2.996170997619629
Validation loss: 2.744111719951835

Epoch: 5| Step: 5
Training loss: 2.6546313762664795
Validation loss: 2.748101785618772

Epoch: 5| Step: 6
Training loss: 2.469679832458496
Validation loss: 2.7547600064226376

Epoch: 5| Step: 7
Training loss: 2.637540817260742
Validation loss: 2.7648956391119186

Epoch: 5| Step: 8
Training loss: 2.7743489742279053
Validation loss: 2.7605396880898425

Epoch: 5| Step: 9
Training loss: 3.325040340423584
Validation loss: 2.741768290919642

Epoch: 5| Step: 10
Training loss: 2.982537031173706
Validation loss: 2.7360521567765104

Epoch: 20| Step: 0
Training loss: 2.209625244140625
Validation loss: 2.738562096831619

Epoch: 5| Step: 1
Training loss: 2.787342071533203
Validation loss: 2.7672424418951875

Epoch: 5| Step: 2
Training loss: 3.1023004055023193
Validation loss: 2.7327545201906593

Epoch: 5| Step: 3
Training loss: 3.027070999145508
Validation loss: 2.727898246498518

Epoch: 5| Step: 4
Training loss: 3.4526894092559814
Validation loss: 2.7257878831637803

Epoch: 5| Step: 5
Training loss: 3.0489425659179688
Validation loss: 2.7243303919351227

Epoch: 5| Step: 6
Training loss: 3.4042060375213623
Validation loss: 2.7222055799217633

Epoch: 5| Step: 7
Training loss: 2.0252299308776855
Validation loss: 2.7264727802686792

Epoch: 5| Step: 8
Training loss: 2.6366019248962402
Validation loss: 2.731268749442152

Epoch: 5| Step: 9
Training loss: 2.794811248779297
Validation loss: 2.7343390795492355

Epoch: 5| Step: 10
Training loss: 3.3004636764526367
Validation loss: 2.7322261410374797

Epoch: 21| Step: 0
Training loss: 3.810352325439453
Validation loss: 2.722784234631446

Epoch: 5| Step: 1
Training loss: 2.1759092807769775
Validation loss: 2.716861665889781

Epoch: 5| Step: 2
Training loss: 2.75071382522583
Validation loss: 2.7169027507946057

Epoch: 5| Step: 3
Training loss: 3.152637243270874
Validation loss: 2.713847147521152

Epoch: 5| Step: 4
Training loss: 2.2682788372039795
Validation loss: 2.711366702151555

Epoch: 5| Step: 5
Training loss: 2.2909634113311768
Validation loss: 2.7098183042259625

Epoch: 5| Step: 6
Training loss: 2.946692943572998
Validation loss: 2.7080583367296445

Epoch: 5| Step: 7
Training loss: 3.325366973876953
Validation loss: 2.7080863496308685

Epoch: 5| Step: 8
Training loss: 2.5872111320495605
Validation loss: 2.705929797182801

Epoch: 5| Step: 9
Training loss: 3.369546890258789
Validation loss: 2.705054008832542

Epoch: 5| Step: 10
Training loss: 2.89447021484375
Validation loss: 2.7047043564499065

Epoch: 22| Step: 0
Training loss: 3.2694478034973145
Validation loss: 2.702871066267772

Epoch: 5| Step: 1
Training loss: 2.706815004348755
Validation loss: 2.7038561862002135

Epoch: 5| Step: 2
Training loss: 2.759335994720459
Validation loss: 2.7035582988492903

Epoch: 5| Step: 3
Training loss: 3.0202555656433105
Validation loss: 2.7096442586632183

Epoch: 5| Step: 4
Training loss: 2.1009950637817383
Validation loss: 2.7094584818809264

Epoch: 5| Step: 5
Training loss: 2.793921947479248
Validation loss: 2.7000651718467794

Epoch: 5| Step: 6
Training loss: 3.4255733489990234
Validation loss: 2.6973788866432766

Epoch: 5| Step: 7
Training loss: 2.6168453693389893
Validation loss: 2.702113923206124

Epoch: 5| Step: 8
Training loss: 2.670884370803833
Validation loss: 2.696920789698119

Epoch: 5| Step: 9
Training loss: 3.461827516555786
Validation loss: 2.696494392169419

Epoch: 5| Step: 10
Training loss: 2.6326236724853516
Validation loss: 2.695569112736692

Epoch: 23| Step: 0
Training loss: 3.129037857055664
Validation loss: 2.695275160574144

Epoch: 5| Step: 1
Training loss: 2.635758876800537
Validation loss: 2.6963870756087767

Epoch: 5| Step: 2
Training loss: 2.2193644046783447
Validation loss: 2.6979045560283046

Epoch: 5| Step: 3
Training loss: 2.8541712760925293
Validation loss: 2.6991700254460818

Epoch: 5| Step: 4
Training loss: 2.868149757385254
Validation loss: 2.687570720590571

Epoch: 5| Step: 5
Training loss: 2.8850443363189697
Validation loss: 2.6910502474795104

Epoch: 5| Step: 6
Training loss: 3.204392910003662
Validation loss: 2.693488362014935

Epoch: 5| Step: 7
Training loss: 2.8531906604766846
Validation loss: 2.7015043432994554

Epoch: 5| Step: 8
Training loss: 2.0696191787719727
Validation loss: 2.699177436931159

Epoch: 5| Step: 9
Training loss: 4.042292594909668
Validation loss: 2.6969590238345567

Epoch: 5| Step: 10
Training loss: 2.619243860244751
Validation loss: 2.6865591810595606

Epoch: 24| Step: 0
Training loss: 2.4526963233947754
Validation loss: 2.682216105922576

Epoch: 5| Step: 1
Training loss: 2.503431797027588
Validation loss: 2.681404341933548

Epoch: 5| Step: 2
Training loss: 3.2492198944091797
Validation loss: 2.6841501805090133

Epoch: 5| Step: 3
Training loss: 2.178858995437622
Validation loss: 2.683663850189537

Epoch: 5| Step: 4
Training loss: 2.7688376903533936
Validation loss: 2.685079595094086

Epoch: 5| Step: 5
Training loss: 3.5200042724609375
Validation loss: 2.680127780924561

Epoch: 5| Step: 6
Training loss: 2.66456937789917
Validation loss: 2.6810187139818744

Epoch: 5| Step: 7
Training loss: 3.187354326248169
Validation loss: 2.6800671623599146

Epoch: 5| Step: 8
Training loss: 2.780247211456299
Validation loss: 2.674836786844397

Epoch: 5| Step: 9
Training loss: 2.702854633331299
Validation loss: 2.6842792162331204

Epoch: 5| Step: 10
Training loss: 3.3682947158813477
Validation loss: 2.6933249094152965

Epoch: 25| Step: 0
Training loss: 2.5207390785217285
Validation loss: 2.6958529410823697

Epoch: 5| Step: 1
Training loss: 3.262613296508789
Validation loss: 2.6855579345457015

Epoch: 5| Step: 2
Training loss: 3.9356155395507812
Validation loss: 2.6777137069291967

Epoch: 5| Step: 3
Training loss: 2.656681537628174
Validation loss: 2.6769631114057315

Epoch: 5| Step: 4
Training loss: 2.582033157348633
Validation loss: 2.6738368593236452

Epoch: 5| Step: 5
Training loss: 3.2085204124450684
Validation loss: 2.670533836528819

Epoch: 5| Step: 6
Training loss: 2.3807008266448975
Validation loss: 2.6726292487113708

Epoch: 5| Step: 7
Training loss: 3.1000094413757324
Validation loss: 2.672638823909144

Epoch: 5| Step: 8
Training loss: 2.8318111896514893
Validation loss: 2.669736252036146

Epoch: 5| Step: 9
Training loss: 2.2910351753234863
Validation loss: 2.6683364939946

Epoch: 5| Step: 10
Training loss: 2.447953224182129
Validation loss: 2.670789605827742

Epoch: 26| Step: 0
Training loss: 2.7112834453582764
Validation loss: 2.6727181993505007

Epoch: 5| Step: 1
Training loss: 2.677494764328003
Validation loss: 2.6789372403134584

Epoch: 5| Step: 2
Training loss: 2.930778741836548
Validation loss: 2.6807693153299312

Epoch: 5| Step: 3
Training loss: 3.251277208328247
Validation loss: 2.6984321609620125

Epoch: 5| Step: 4
Training loss: 2.990830421447754
Validation loss: 2.689814923911966

Epoch: 5| Step: 5
Training loss: 2.5785117149353027
Validation loss: 2.677944988332769

Epoch: 5| Step: 6
Training loss: 3.2158493995666504
Validation loss: 2.6666679010596326

Epoch: 5| Step: 7
Training loss: 3.1052372455596924
Validation loss: 2.6610932427067913

Epoch: 5| Step: 8
Training loss: 2.6531667709350586
Validation loss: 2.657819696651992

Epoch: 5| Step: 9
Training loss: 2.4599292278289795
Validation loss: 2.65646549963182

Epoch: 5| Step: 10
Training loss: 2.5977776050567627
Validation loss: 2.6570182308073966

Epoch: 27| Step: 0
Training loss: 3.0726897716522217
Validation loss: 2.654892921447754

Epoch: 5| Step: 1
Training loss: 3.4845356941223145
Validation loss: 2.651282215631136

Epoch: 5| Step: 2
Training loss: 2.9913430213928223
Validation loss: 2.6462753203607376

Epoch: 5| Step: 3
Training loss: 2.652627468109131
Validation loss: 2.652476749112529

Epoch: 5| Step: 4
Training loss: 2.6621081829071045
Validation loss: 2.65465558216136

Epoch: 5| Step: 5
Training loss: 2.284242630004883
Validation loss: 2.6540410377646007

Epoch: 5| Step: 6
Training loss: 2.351675510406494
Validation loss: 2.646547730251025

Epoch: 5| Step: 7
Training loss: 3.248633623123169
Validation loss: 2.6458093914934384

Epoch: 5| Step: 8
Training loss: 2.4798576831817627
Validation loss: 2.644470396862235

Epoch: 5| Step: 9
Training loss: 3.0891642570495605
Validation loss: 2.6462844161577124

Epoch: 5| Step: 10
Training loss: 2.7362723350524902
Validation loss: 2.648082281953545

Epoch: 28| Step: 0
Training loss: 2.976863145828247
Validation loss: 2.6466211836825133

Epoch: 5| Step: 1
Training loss: 3.2877230644226074
Validation loss: 2.646221281379782

Epoch: 5| Step: 2
Training loss: 3.382298231124878
Validation loss: 2.6467607021331787

Epoch: 5| Step: 3
Training loss: 3.291506290435791
Validation loss: 2.6440117743707474

Epoch: 5| Step: 4
Training loss: 3.187391757965088
Validation loss: 2.6432349476762997

Epoch: 5| Step: 5
Training loss: 2.4625821113586426
Validation loss: 2.637833313275409

Epoch: 5| Step: 6
Training loss: 2.247675657272339
Validation loss: 2.6314382988919496

Epoch: 5| Step: 7
Training loss: 2.1814517974853516
Validation loss: 2.6324466864267984

Epoch: 5| Step: 8
Training loss: 2.339996099472046
Validation loss: 2.6492376224969023

Epoch: 5| Step: 9
Training loss: 3.1975979804992676
Validation loss: 2.6669122788213913

Epoch: 5| Step: 10
Training loss: 2.366656541824341
Validation loss: 2.6648351633420555

Epoch: 29| Step: 0
Training loss: 2.3174757957458496
Validation loss: 2.6412066772419918

Epoch: 5| Step: 1
Training loss: 3.2891297340393066
Validation loss: 2.6273539784134075

Epoch: 5| Step: 2
Training loss: 3.010662794113159
Validation loss: 2.6289580047771497

Epoch: 5| Step: 3
Training loss: 2.625257968902588
Validation loss: 2.63641756837086

Epoch: 5| Step: 4
Training loss: 2.9998507499694824
Validation loss: 2.651197894926994

Epoch: 5| Step: 5
Training loss: 2.2861220836639404
Validation loss: 2.6571493661531838

Epoch: 5| Step: 6
Training loss: 2.210116147994995
Validation loss: 2.6670153807568293

Epoch: 5| Step: 7
Training loss: 3.42326283454895
Validation loss: 2.7180305886012253

Epoch: 5| Step: 8
Training loss: 2.352436065673828
Validation loss: 2.6549975487493698

Epoch: 5| Step: 9
Training loss: 3.7166519165039062
Validation loss: 2.6721371014912925

Epoch: 5| Step: 10
Training loss: 2.893989086151123
Validation loss: 2.684763523840135

Epoch: 30| Step: 0
Training loss: 3.7520229816436768
Validation loss: 2.7371203412291822

Epoch: 5| Step: 1
Training loss: 2.9598331451416016
Validation loss: 2.77598463848073

Epoch: 5| Step: 2
Training loss: 2.6788086891174316
Validation loss: 2.7712632097223753

Epoch: 5| Step: 3
Training loss: 3.378404140472412
Validation loss: 2.755934340979463

Epoch: 5| Step: 4
Training loss: 2.934142589569092
Validation loss: 2.7284819079983618

Epoch: 5| Step: 5
Training loss: 2.80259108543396
Validation loss: 2.701706576090987

Epoch: 5| Step: 6
Training loss: 2.3153016567230225
Validation loss: 2.6817383766174316

Epoch: 5| Step: 7
Training loss: 3.0871191024780273
Validation loss: 2.687587063799622

Epoch: 5| Step: 8
Training loss: 1.9931446313858032
Validation loss: 2.6775776468297487

Epoch: 5| Step: 9
Training loss: 2.951810359954834
Validation loss: 2.671303556811425

Epoch: 5| Step: 10
Training loss: 2.6100330352783203
Validation loss: 2.66856199695218

Epoch: 31| Step: 0
Training loss: 2.5096304416656494
Validation loss: 2.6729388583090996

Epoch: 5| Step: 1
Training loss: 2.2438464164733887
Validation loss: 2.6768022814104633

Epoch: 5| Step: 2
Training loss: 2.681832790374756
Validation loss: 2.673987542429278

Epoch: 5| Step: 3
Training loss: 2.6801905632019043
Validation loss: 2.6702610959288893

Epoch: 5| Step: 4
Training loss: 3.2652993202209473
Validation loss: 2.6654590868180796

Epoch: 5| Step: 5
Training loss: 3.7324905395507812
Validation loss: 2.647465967362927

Epoch: 5| Step: 6
Training loss: 2.8388543128967285
Validation loss: 2.6142237109522664

Epoch: 5| Step: 7
Training loss: 2.9088242053985596
Validation loss: 2.611868402009369

Epoch: 5| Step: 8
Training loss: 2.804084062576294
Validation loss: 2.618892861950782

Epoch: 5| Step: 9
Training loss: 2.174567461013794
Validation loss: 2.6163040694370063

Epoch: 5| Step: 10
Training loss: 3.1153252124786377
Validation loss: 2.6136951061987106

Epoch: 32| Step: 0
Training loss: 2.7605366706848145
Validation loss: 2.606800022945609

Epoch: 5| Step: 1
Training loss: 2.989422559738159
Validation loss: 2.599217609692645

Epoch: 5| Step: 2
Training loss: 2.771933078765869
Validation loss: 2.5998407204945884

Epoch: 5| Step: 3
Training loss: 2.5226950645446777
Validation loss: 2.60260001818339

Epoch: 5| Step: 4
Training loss: 2.180734157562256
Validation loss: 2.6041762469917216

Epoch: 5| Step: 5
Training loss: 2.393786668777466
Validation loss: 2.6010472415595927

Epoch: 5| Step: 6
Training loss: 2.950657606124878
Validation loss: 2.5946132265111452

Epoch: 5| Step: 7
Training loss: 3.4768130779266357
Validation loss: 2.5964429481055147

Epoch: 5| Step: 8
Training loss: 2.841505527496338
Validation loss: 2.599049670721895

Epoch: 5| Step: 9
Training loss: 2.8053603172302246
Validation loss: 2.599403712057298

Epoch: 5| Step: 10
Training loss: 2.8459372520446777
Validation loss: 2.597686536850468

Epoch: 33| Step: 0
Training loss: 2.6778597831726074
Validation loss: 2.6381194130066903

Epoch: 5| Step: 1
Training loss: 2.8584132194519043
Validation loss: 2.661965657305974

Epoch: 5| Step: 2
Training loss: 2.302255153656006
Validation loss: 2.684956504452613

Epoch: 5| Step: 3
Training loss: 3.1264429092407227
Validation loss: 2.702472904677032

Epoch: 5| Step: 4
Training loss: 2.965266704559326
Validation loss: 2.5985803552853164

Epoch: 5| Step: 5
Training loss: 2.3549752235412598
Validation loss: 2.5631382132089264

Epoch: 5| Step: 6
Training loss: 3.667440414428711
Validation loss: 2.570213322998375

Epoch: 5| Step: 7
Training loss: 2.664715528488159
Validation loss: 2.5894070338177424

Epoch: 5| Step: 8
Training loss: 2.5708136558532715
Validation loss: 2.5876587052499094

Epoch: 5| Step: 9
Training loss: 2.781169891357422
Validation loss: 2.605098621819609

Epoch: 5| Step: 10
Training loss: 2.7257442474365234
Validation loss: 2.583920007110924

Epoch: 34| Step: 0
Training loss: 2.5546207427978516
Validation loss: 2.5803582104303504

Epoch: 5| Step: 1
Training loss: 2.64363431930542
Validation loss: 2.5762308925710697

Epoch: 5| Step: 2
Training loss: 2.5459885597229004
Validation loss: 2.5665354472334667

Epoch: 5| Step: 3
Training loss: 2.718693256378174
Validation loss: 2.5595443556385655

Epoch: 5| Step: 4
Training loss: 2.362022876739502
Validation loss: 2.559326607693908

Epoch: 5| Step: 5
Training loss: 2.5074291229248047
Validation loss: 2.568733876751315

Epoch: 5| Step: 6
Training loss: 2.6784846782684326
Validation loss: 2.577425910580543

Epoch: 5| Step: 7
Training loss: 2.6567940711975098
Validation loss: 2.5756195232432377

Epoch: 5| Step: 8
Training loss: 3.3353049755096436
Validation loss: 2.5654136750005905

Epoch: 5| Step: 9
Training loss: 3.051361083984375
Validation loss: 2.564656262756676

Epoch: 5| Step: 10
Training loss: 3.332630157470703
Validation loss: 2.5667551845632572

Epoch: 35| Step: 0
Training loss: 3.239732027053833
Validation loss: 2.552186627541819

Epoch: 5| Step: 1
Training loss: 2.56929087638855
Validation loss: 2.539513011132517

Epoch: 5| Step: 2
Training loss: 3.0913100242614746
Validation loss: 2.5276325466812297

Epoch: 5| Step: 3
Training loss: 2.1246345043182373
Validation loss: 2.5252361143788984

Epoch: 5| Step: 4
Training loss: 2.371166706085205
Validation loss: 2.527519943893597

Epoch: 5| Step: 5
Training loss: 2.8313064575195312
Validation loss: 2.5277488385477374

Epoch: 5| Step: 6
Training loss: 2.7763938903808594
Validation loss: 2.5297646163612284

Epoch: 5| Step: 7
Training loss: 2.5420331954956055
Validation loss: 2.5266240078915834

Epoch: 5| Step: 8
Training loss: 2.6967837810516357
Validation loss: 2.520894317216771

Epoch: 5| Step: 9
Training loss: 3.243445634841919
Validation loss: 2.5233768827171734

Epoch: 5| Step: 10
Training loss: 2.542358636856079
Validation loss: 2.5272594164776545

Epoch: 36| Step: 0
Training loss: 2.932835817337036
Validation loss: 2.537821456950198

Epoch: 5| Step: 1
Training loss: 3.2446811199188232
Validation loss: 2.52925399298309

Epoch: 5| Step: 2
Training loss: 2.6861016750335693
Validation loss: 2.5241750030107397

Epoch: 5| Step: 3
Training loss: 2.9935269355773926
Validation loss: 2.513205171913229

Epoch: 5| Step: 4
Training loss: 2.8264544010162354
Validation loss: 2.5085441694464734

Epoch: 5| Step: 5
Training loss: 2.324063777923584
Validation loss: 2.507776480849071

Epoch: 5| Step: 6
Training loss: 2.929119825363159
Validation loss: 2.5086544970030427

Epoch: 5| Step: 7
Training loss: 2.304292678833008
Validation loss: 2.5122223464391564

Epoch: 5| Step: 8
Training loss: 2.468355655670166
Validation loss: 2.514804655505765

Epoch: 5| Step: 9
Training loss: 2.476661443710327
Validation loss: 2.5153383106313725

Epoch: 5| Step: 10
Training loss: 2.8106799125671387
Validation loss: 2.513251176444433

Epoch: 37| Step: 0
Training loss: 2.709050416946411
Validation loss: 2.5086703069748415

Epoch: 5| Step: 1
Training loss: 3.1811861991882324
Validation loss: 2.514053048626069

Epoch: 5| Step: 2
Training loss: 2.3360698223114014
Validation loss: 2.569776286361038

Epoch: 5| Step: 3
Training loss: 2.5092368125915527
Validation loss: 2.5311387226145756

Epoch: 5| Step: 4
Training loss: 2.8495349884033203
Validation loss: 2.546373180163804

Epoch: 5| Step: 5
Training loss: 2.9668498039245605
Validation loss: 2.5347467519903697

Epoch: 5| Step: 6
Training loss: 3.0025436878204346
Validation loss: 2.5134614975221696

Epoch: 5| Step: 7
Training loss: 2.529341697692871
Validation loss: 2.50461571703675

Epoch: 5| Step: 8
Training loss: 2.946864128112793
Validation loss: 2.5068007412777153

Epoch: 5| Step: 9
Training loss: 2.15665340423584
Validation loss: 2.5071564694886566

Epoch: 5| Step: 10
Training loss: 2.6662371158599854
Validation loss: 2.5034685109251287

Epoch: 38| Step: 0
Training loss: 2.794386386871338
Validation loss: 2.513974856304866

Epoch: 5| Step: 1
Training loss: 3.165442943572998
Validation loss: 2.5174529424277683

Epoch: 5| Step: 2
Training loss: 3.3398165702819824
Validation loss: 2.5247658901317145

Epoch: 5| Step: 3
Training loss: 2.278073310852051
Validation loss: 2.522809241407661

Epoch: 5| Step: 4
Training loss: 2.653254747390747
Validation loss: 2.512616954823976

Epoch: 5| Step: 5
Training loss: 2.2636091709136963
Validation loss: 2.5081392359989945

Epoch: 5| Step: 6
Training loss: 2.858274221420288
Validation loss: 2.501635689889231

Epoch: 5| Step: 7
Training loss: 2.912825345993042
Validation loss: 2.495439321764054

Epoch: 5| Step: 8
Training loss: 2.5345001220703125
Validation loss: 2.499924208528252

Epoch: 5| Step: 9
Training loss: 2.345850706100464
Validation loss: 2.5061528221253426

Epoch: 5| Step: 10
Training loss: 2.585103988647461
Validation loss: 2.4989302645447435

Epoch: 39| Step: 0
Training loss: 3.4639668464660645
Validation loss: 2.4903600241548274

Epoch: 5| Step: 1
Training loss: 2.504551649093628
Validation loss: 2.4845259881788686

Epoch: 5| Step: 2
Training loss: 2.166482448577881
Validation loss: 2.487844797872728

Epoch: 5| Step: 3
Training loss: 2.430968761444092
Validation loss: 2.4870493104380946

Epoch: 5| Step: 4
Training loss: 2.7404727935791016
Validation loss: 2.488428751627604

Epoch: 5| Step: 5
Training loss: 1.9471542835235596
Validation loss: 2.4876140445791264

Epoch: 5| Step: 6
Training loss: 2.8453657627105713
Validation loss: 2.490248421187042

Epoch: 5| Step: 7
Training loss: 2.6355721950531006
Validation loss: 2.4878301364119335

Epoch: 5| Step: 8
Training loss: 2.8472049236297607
Validation loss: 2.4866009450727895

Epoch: 5| Step: 9
Training loss: 2.86362624168396
Validation loss: 2.4775414415585097

Epoch: 5| Step: 10
Training loss: 3.441196918487549
Validation loss: 2.4789278276505007

Epoch: 40| Step: 0
Training loss: 2.328266143798828
Validation loss: 2.473897644268569

Epoch: 5| Step: 1
Training loss: 2.6869640350341797
Validation loss: 2.4740703669927453

Epoch: 5| Step: 2
Training loss: 2.3679332733154297
Validation loss: 2.47727890681195

Epoch: 5| Step: 3
Training loss: 2.064065456390381
Validation loss: 2.493783470123045

Epoch: 5| Step: 4
Training loss: 3.225633144378662
Validation loss: 2.5027331870089293

Epoch: 5| Step: 5
Training loss: 2.53706693649292
Validation loss: 2.500361145183604

Epoch: 5| Step: 6
Training loss: 2.4429333209991455
Validation loss: 2.4848043662245556

Epoch: 5| Step: 7
Training loss: 3.6796975135803223
Validation loss: 2.471393451895765

Epoch: 5| Step: 8
Training loss: 2.540724277496338
Validation loss: 2.459366895819223

Epoch: 5| Step: 9
Training loss: 2.822521209716797
Validation loss: 2.453735077252952

Epoch: 5| Step: 10
Training loss: 2.885239601135254
Validation loss: 2.4514060789538967

Epoch: 41| Step: 0
Training loss: 3.1056113243103027
Validation loss: 2.450838920890644

Epoch: 5| Step: 1
Training loss: 2.885221004486084
Validation loss: 2.452558768692837

Epoch: 5| Step: 2
Training loss: 2.655604124069214
Validation loss: 2.4507653815771944

Epoch: 5| Step: 3
Training loss: 2.727694511413574
Validation loss: 2.4515609100300777

Epoch: 5| Step: 4
Training loss: 3.360010862350464
Validation loss: 2.450402231626613

Epoch: 5| Step: 5
Training loss: 2.390993118286133
Validation loss: 2.4492730504723004

Epoch: 5| Step: 6
Training loss: 2.7908363342285156
Validation loss: 2.450933564093805

Epoch: 5| Step: 7
Training loss: 2.57308030128479
Validation loss: 2.450560926109232

Epoch: 5| Step: 8
Training loss: 2.113659381866455
Validation loss: 2.4504900055546917

Epoch: 5| Step: 9
Training loss: 2.13441801071167
Validation loss: 2.458192874026555

Epoch: 5| Step: 10
Training loss: 2.7728352546691895
Validation loss: 2.461492879416353

Epoch: 42| Step: 0
Training loss: 2.8166937828063965
Validation loss: 2.4703636143797185

Epoch: 5| Step: 1
Training loss: 2.8959872722625732
Validation loss: 2.4766804582329205

Epoch: 5| Step: 2
Training loss: 3.0737085342407227
Validation loss: 2.4770237143321703

Epoch: 5| Step: 3
Training loss: 3.1224610805511475
Validation loss: 2.461603056999945

Epoch: 5| Step: 4
Training loss: 2.346740245819092
Validation loss: 2.4439583132343907

Epoch: 5| Step: 5
Training loss: 2.039511203765869
Validation loss: 2.4442123187485563

Epoch: 5| Step: 6
Training loss: 2.369776964187622
Validation loss: 2.4384187703491538

Epoch: 5| Step: 7
Training loss: 2.6455790996551514
Validation loss: 2.438767889494537

Epoch: 5| Step: 8
Training loss: 2.0738284587860107
Validation loss: 2.4436375658999205

Epoch: 5| Step: 9
Training loss: 3.2467551231384277
Validation loss: 2.4417548333444903

Epoch: 5| Step: 10
Training loss: 2.8501405715942383
Validation loss: 2.4430931255381596

Epoch: 43| Step: 0
Training loss: 2.307887554168701
Validation loss: 2.438611045960457

Epoch: 5| Step: 1
Training loss: 3.327585220336914
Validation loss: 2.4396573958858365

Epoch: 5| Step: 2
Training loss: 1.8566983938217163
Validation loss: 2.437784997365808

Epoch: 5| Step: 3
Training loss: 2.2086191177368164
Validation loss: 2.434055633442376

Epoch: 5| Step: 4
Training loss: 3.7360198497772217
Validation loss: 2.433921049999934

Epoch: 5| Step: 5
Training loss: 3.4593262672424316
Validation loss: 2.4307747297389533

Epoch: 5| Step: 6
Training loss: 1.9734878540039062
Validation loss: 2.439721720193022

Epoch: 5| Step: 7
Training loss: 2.5433812141418457
Validation loss: 2.4406576438616683

Epoch: 5| Step: 8
Training loss: 2.8554694652557373
Validation loss: 2.445442504780267

Epoch: 5| Step: 9
Training loss: 2.9334466457366943
Validation loss: 2.445845324506042

Epoch: 5| Step: 10
Training loss: 2.0834388732910156
Validation loss: 2.4316114174422396

Epoch: 44| Step: 0
Training loss: 2.6452105045318604
Validation loss: 2.431553312527236

Epoch: 5| Step: 1
Training loss: 2.786965847015381
Validation loss: 2.433779788273637

Epoch: 5| Step: 2
Training loss: 3.1312761306762695
Validation loss: 2.428697109222412

Epoch: 5| Step: 3
Training loss: 1.9672956466674805
Validation loss: 2.4277798898758425

Epoch: 5| Step: 4
Training loss: 3.235443592071533
Validation loss: 2.4274263856231526

Epoch: 5| Step: 5
Training loss: 3.260988235473633
Validation loss: 2.4369621994674846

Epoch: 5| Step: 6
Training loss: 2.2992324829101562
Validation loss: 2.4389531099668114

Epoch: 5| Step: 7
Training loss: 2.867093324661255
Validation loss: 2.433324808715492

Epoch: 5| Step: 8
Training loss: 2.334662675857544
Validation loss: 2.431317908789522

Epoch: 5| Step: 9
Training loss: 2.3519558906555176
Validation loss: 2.4265983271342453

Epoch: 5| Step: 10
Training loss: 2.3846285343170166
Validation loss: 2.4270423202104467

Epoch: 45| Step: 0
Training loss: 3.0514817237854004
Validation loss: 2.436492291829919

Epoch: 5| Step: 1
Training loss: 2.6036078929901123
Validation loss: 2.443320781953873

Epoch: 5| Step: 2
Training loss: 3.1147732734680176
Validation loss: 2.449186417364305

Epoch: 5| Step: 3
Training loss: 2.8883118629455566
Validation loss: 2.4372557286293275

Epoch: 5| Step: 4
Training loss: 2.7556838989257812
Validation loss: 2.4284908822787705

Epoch: 5| Step: 5
Training loss: 2.9234142303466797
Validation loss: 2.4216696728942213

Epoch: 5| Step: 6
Training loss: 2.6683287620544434
Validation loss: 2.4210735341554046

Epoch: 5| Step: 7
Training loss: 1.9186925888061523
Validation loss: 2.425047835996074

Epoch: 5| Step: 8
Training loss: 2.336245059967041
Validation loss: 2.4319741367011942

Epoch: 5| Step: 9
Training loss: 2.3970656394958496
Validation loss: 2.446280466612949

Epoch: 5| Step: 10
Training loss: 2.5647947788238525
Validation loss: 2.4412524315618698

Epoch: 46| Step: 0
Training loss: 2.66774845123291
Validation loss: 2.434883927786222

Epoch: 5| Step: 1
Training loss: 2.3950984477996826
Validation loss: 2.4220049176164853

Epoch: 5| Step: 2
Training loss: 2.740521192550659
Validation loss: 2.418774909870599

Epoch: 5| Step: 3
Training loss: 1.8564822673797607
Validation loss: 2.4148456486322547

Epoch: 5| Step: 4
Training loss: 2.7071316242218018
Validation loss: 2.4127945848690566

Epoch: 5| Step: 5
Training loss: 2.303999900817871
Validation loss: 2.4079433423216625

Epoch: 5| Step: 6
Training loss: 2.56986665725708
Validation loss: 2.409209284731137

Epoch: 5| Step: 7
Training loss: 2.531674861907959
Validation loss: 2.406641638407143

Epoch: 5| Step: 8
Training loss: 3.8169169425964355
Validation loss: 2.4064413039915022

Epoch: 5| Step: 9
Training loss: 2.2327239513397217
Validation loss: 2.4096748495614655

Epoch: 5| Step: 10
Training loss: 3.43393611907959
Validation loss: 2.408295859572708

Epoch: 47| Step: 0
Training loss: 2.884124279022217
Validation loss: 2.407602587053853

Epoch: 5| Step: 1
Training loss: 2.754033327102661
Validation loss: 2.4129292170206704

Epoch: 5| Step: 2
Training loss: 2.4230332374572754
Validation loss: 2.4256031795214583

Epoch: 5| Step: 3
Training loss: 3.381434679031372
Validation loss: 2.42538776961706

Epoch: 5| Step: 4
Training loss: 2.9473414421081543
Validation loss: 2.4275729656219482

Epoch: 5| Step: 5
Training loss: 1.9898048639297485
Validation loss: 2.4357663405838834

Epoch: 5| Step: 6
Training loss: 2.466552257537842
Validation loss: 2.455549011948288

Epoch: 5| Step: 7
Training loss: 2.2816591262817383
Validation loss: 2.4746306685991186

Epoch: 5| Step: 8
Training loss: 2.045797824859619
Validation loss: 2.485285169334822

Epoch: 5| Step: 9
Training loss: 3.453421115875244
Validation loss: 2.4870305189522366

Epoch: 5| Step: 10
Training loss: 2.5590474605560303
Validation loss: 2.4750445299251105

Epoch: 48| Step: 0
Training loss: 3.188877582550049
Validation loss: 2.4509961502526396

Epoch: 5| Step: 1
Training loss: 2.9129798412323
Validation loss: 2.4245096791175103

Epoch: 5| Step: 2
Training loss: 3.112905740737915
Validation loss: 2.3982887268066406

Epoch: 5| Step: 3
Training loss: 1.8783705234527588
Validation loss: 2.390864038980135

Epoch: 5| Step: 4
Training loss: 2.613997459411621
Validation loss: 2.3895274387892855

Epoch: 5| Step: 5
Training loss: 2.4351887702941895
Validation loss: 2.3872153964093936

Epoch: 5| Step: 6
Training loss: 2.6144022941589355
Validation loss: 2.3855036971389607

Epoch: 5| Step: 7
Training loss: 2.6896488666534424
Validation loss: 2.3891099550390757

Epoch: 5| Step: 8
Training loss: 2.3866639137268066
Validation loss: 2.4026264170164704

Epoch: 5| Step: 9
Training loss: 2.822787046432495
Validation loss: 2.4080558874273814

Epoch: 5| Step: 10
Training loss: 2.5072288513183594
Validation loss: 2.4006612275236394

Epoch: 49| Step: 0
Training loss: 2.6236445903778076
Validation loss: 2.3937428843590522

Epoch: 5| Step: 1
Training loss: 2.55015230178833
Validation loss: 2.3952583933389313

Epoch: 5| Step: 2
Training loss: 2.603672981262207
Validation loss: 2.397811597393405

Epoch: 5| Step: 3
Training loss: 2.6958296298980713
Validation loss: 2.401273206997943

Epoch: 5| Step: 4
Training loss: 2.584784507751465
Validation loss: 2.414746610067224

Epoch: 5| Step: 5
Training loss: 2.74837589263916
Validation loss: 2.417149682198801

Epoch: 5| Step: 6
Training loss: 2.8644890785217285
Validation loss: 2.420853610961668

Epoch: 5| Step: 7
Training loss: 2.1982905864715576
Validation loss: 2.427436764522265

Epoch: 5| Step: 8
Training loss: 2.0976405143737793
Validation loss: 2.4213139190468738

Epoch: 5| Step: 9
Training loss: 2.84674334526062
Validation loss: 2.426611118419196

Epoch: 5| Step: 10
Training loss: 3.2720541954040527
Validation loss: 2.431615944831602

Epoch: 50| Step: 0
Training loss: 2.2273292541503906
Validation loss: 2.4278272326274584

Epoch: 5| Step: 1
Training loss: 2.942598342895508
Validation loss: 2.4432770180445846

Epoch: 5| Step: 2
Training loss: 2.426391839981079
Validation loss: 2.4505511945293796

Epoch: 5| Step: 3
Training loss: 2.7571232318878174
Validation loss: 2.4408308588048464

Epoch: 5| Step: 4
Training loss: 3.138611316680908
Validation loss: 2.4257306334792927

Epoch: 5| Step: 5
Training loss: 2.8601534366607666
Validation loss: 2.4155296356447282

Epoch: 5| Step: 6
Training loss: 2.458759069442749
Validation loss: 2.4060507435952463

Epoch: 5| Step: 7
Training loss: 1.9626224040985107
Validation loss: 2.3961448951434066

Epoch: 5| Step: 8
Training loss: 2.6385416984558105
Validation loss: 2.39207221359335

Epoch: 5| Step: 9
Training loss: 2.871567964553833
Validation loss: 2.385261235698577

Epoch: 5| Step: 10
Training loss: 2.6771774291992188
Validation loss: 2.3812771215233752

Epoch: 51| Step: 0
Training loss: 1.822330117225647
Validation loss: 2.378250814253284

Epoch: 5| Step: 1
Training loss: 1.9479572772979736
Validation loss: 2.3736078239256337

Epoch: 5| Step: 2
Training loss: 3.0739474296569824
Validation loss: 2.3666491713575137

Epoch: 5| Step: 3
Training loss: 2.787933588027954
Validation loss: 2.368443842857115

Epoch: 5| Step: 4
Training loss: 2.726022720336914
Validation loss: 2.3638082755509244

Epoch: 5| Step: 5
Training loss: 2.227666139602661
Validation loss: 2.368686427352249

Epoch: 5| Step: 6
Training loss: 2.849815845489502
Validation loss: 2.368082497709541

Epoch: 5| Step: 7
Training loss: 2.776141405105591
Validation loss: 2.3857377331743956

Epoch: 5| Step: 8
Training loss: 2.7236247062683105
Validation loss: 2.3827589634926087

Epoch: 5| Step: 9
Training loss: 2.931014060974121
Validation loss: 2.3885242041721138

Epoch: 5| Step: 10
Training loss: 3.1804842948913574
Validation loss: 2.3819028485205864

Epoch: 52| Step: 0
Training loss: 2.2179112434387207
Validation loss: 2.3677835131204255

Epoch: 5| Step: 1
Training loss: 2.2687342166900635
Validation loss: 2.36172999617874

Epoch: 5| Step: 2
Training loss: 2.976858139038086
Validation loss: 2.361335636467062

Epoch: 5| Step: 3
Training loss: 2.8550994396209717
Validation loss: 2.3613984097716627

Epoch: 5| Step: 4
Training loss: 3.1111273765563965
Validation loss: 2.359676886630315

Epoch: 5| Step: 5
Training loss: 2.3819334506988525
Validation loss: 2.3625639048955773

Epoch: 5| Step: 6
Training loss: 2.5359818935394287
Validation loss: 2.365728055277178

Epoch: 5| Step: 7
Training loss: 2.656780958175659
Validation loss: 2.3671177894838396

Epoch: 5| Step: 8
Training loss: 2.7256972789764404
Validation loss: 2.378542310448103

Epoch: 5| Step: 9
Training loss: 2.4276998043060303
Validation loss: 2.392050894357825

Epoch: 5| Step: 10
Training loss: 2.6575348377227783
Validation loss: 2.407235527551302

Epoch: 53| Step: 0
Training loss: 2.6970951557159424
Validation loss: 2.4090945387399323

Epoch: 5| Step: 1
Training loss: 2.8361940383911133
Validation loss: 2.398337592360794

Epoch: 5| Step: 2
Training loss: 2.7813053131103516
Validation loss: 2.388983259918869

Epoch: 5| Step: 3
Training loss: 2.5309016704559326
Validation loss: 2.3854363323539816

Epoch: 5| Step: 4
Training loss: 2.011669397354126
Validation loss: 2.370251783760645

Epoch: 5| Step: 5
Training loss: 2.462165117263794
Validation loss: 2.36416640076586

Epoch: 5| Step: 6
Training loss: 2.3777012825012207
Validation loss: 2.3621372766392206

Epoch: 5| Step: 7
Training loss: 2.5335726737976074
Validation loss: 2.3609641226389075

Epoch: 5| Step: 8
Training loss: 2.824178457260132
Validation loss: 2.3635125365308536

Epoch: 5| Step: 9
Training loss: 2.8467609882354736
Validation loss: 2.361587025785959

Epoch: 5| Step: 10
Training loss: 2.8957743644714355
Validation loss: 2.358008756432482

Epoch: 54| Step: 0
Training loss: 2.3300771713256836
Validation loss: 2.3530426307391097

Epoch: 5| Step: 1
Training loss: 2.72292160987854
Validation loss: 2.355355078174222

Epoch: 5| Step: 2
Training loss: 2.3607611656188965
Validation loss: 2.348844053924725

Epoch: 5| Step: 3
Training loss: 2.72147536277771
Validation loss: 2.3486222451733005

Epoch: 5| Step: 4
Training loss: 3.0052649974823
Validation loss: 2.3486919018530075

Epoch: 5| Step: 5
Training loss: 2.505788803100586
Validation loss: 2.343410550907094

Epoch: 5| Step: 6
Training loss: 2.4990813732147217
Validation loss: 2.3372837881888113

Epoch: 5| Step: 7
Training loss: 3.0249643325805664
Validation loss: 2.3340349812661447

Epoch: 5| Step: 8
Training loss: 2.4266419410705566
Validation loss: 2.3353470833070817

Epoch: 5| Step: 9
Training loss: 2.483273983001709
Validation loss: 2.33776770868609

Epoch: 5| Step: 10
Training loss: 2.5628130435943604
Validation loss: 2.338064134761851

Epoch: 55| Step: 0
Training loss: 3.1291236877441406
Validation loss: 2.3404001266725603

Epoch: 5| Step: 1
Training loss: 2.882995128631592
Validation loss: 2.341261559917081

Epoch: 5| Step: 2
Training loss: 3.1345858573913574
Validation loss: 2.3456546081009733

Epoch: 5| Step: 3
Training loss: 2.9305574893951416
Validation loss: 2.3464149095678843

Epoch: 5| Step: 4
Training loss: 2.059384822845459
Validation loss: 2.35410814644188

Epoch: 5| Step: 5
Training loss: 2.3467700481414795
Validation loss: 2.366868039613129

Epoch: 5| Step: 6
Training loss: 2.3286170959472656
Validation loss: 2.374077312407955

Epoch: 5| Step: 7
Training loss: 2.5521252155303955
Validation loss: 2.3756074264485347

Epoch: 5| Step: 8
Training loss: 2.3025481700897217
Validation loss: 2.3665774817107827

Epoch: 5| Step: 9
Training loss: 1.953173041343689
Validation loss: 2.3521187638723724

Epoch: 5| Step: 10
Training loss: 3.0066728591918945
Validation loss: 2.3390613371326077

Epoch: 56| Step: 0
Training loss: 2.120349168777466
Validation loss: 2.336084435063024

Epoch: 5| Step: 1
Training loss: 2.375145435333252
Validation loss: 2.335602773133145

Epoch: 5| Step: 2
Training loss: 2.4177749156951904
Validation loss: 2.3315642264581498

Epoch: 5| Step: 3
Training loss: 2.326829433441162
Validation loss: 2.3387859329100578

Epoch: 5| Step: 4
Training loss: 2.881751537322998
Validation loss: 2.356596674970401

Epoch: 5| Step: 5
Training loss: 2.625535488128662
Validation loss: 2.357749016054215

Epoch: 5| Step: 6
Training loss: 2.7204246520996094
Validation loss: 2.362138896860102

Epoch: 5| Step: 7
Training loss: 2.4294967651367188
Validation loss: 2.3644032298877673

Epoch: 5| Step: 8
Training loss: 2.8562164306640625
Validation loss: 2.346283256366689

Epoch: 5| Step: 9
Training loss: 2.662994623184204
Validation loss: 2.333348504958614

Epoch: 5| Step: 10
Training loss: 3.251021146774292
Validation loss: 2.330396398421257

Epoch: 57| Step: 0
Training loss: 2.7237865924835205
Validation loss: 2.326048166521134

Epoch: 5| Step: 1
Training loss: 2.726619243621826
Validation loss: 2.331486766056348

Epoch: 5| Step: 2
Training loss: 2.9175844192504883
Validation loss: 2.324809048765449

Epoch: 5| Step: 3
Training loss: 1.8157730102539062
Validation loss: 2.333332815477925

Epoch: 5| Step: 4
Training loss: 3.2706520557403564
Validation loss: 2.3296097324740503

Epoch: 5| Step: 5
Training loss: 2.454817295074463
Validation loss: 2.3335233183317285

Epoch: 5| Step: 6
Training loss: 2.591705799102783
Validation loss: 2.3280203957711496

Epoch: 5| Step: 7
Training loss: 2.6830625534057617
Validation loss: 2.32850258709282

Epoch: 5| Step: 8
Training loss: 2.0570738315582275
Validation loss: 2.343298094246977

Epoch: 5| Step: 9
Training loss: 2.879793405532837
Validation loss: 2.3595053290808075

Epoch: 5| Step: 10
Training loss: 2.373231887817383
Validation loss: 2.3707316844694075

Epoch: 58| Step: 0
Training loss: 3.1540699005126953
Validation loss: 2.382834170454292

Epoch: 5| Step: 1
Training loss: 2.8164939880371094
Validation loss: 2.3870442862151773

Epoch: 5| Step: 2
Training loss: 2.3085103034973145
Validation loss: 2.3650738936598583

Epoch: 5| Step: 3
Training loss: 2.796706199645996
Validation loss: 2.352620282480794

Epoch: 5| Step: 4
Training loss: 2.720635414123535
Validation loss: 2.341076615036175

Epoch: 5| Step: 5
Training loss: 2.641803026199341
Validation loss: 2.3357956768364034

Epoch: 5| Step: 6
Training loss: 2.420309066772461
Validation loss: 2.3394684330109627

Epoch: 5| Step: 7
Training loss: 2.7394912242889404
Validation loss: 2.3233029547558037

Epoch: 5| Step: 8
Training loss: 2.0985615253448486
Validation loss: 2.3248125430076354

Epoch: 5| Step: 9
Training loss: 1.9528526067733765
Validation loss: 2.3228358171319448

Epoch: 5| Step: 10
Training loss: 2.995610475540161
Validation loss: 2.3206259473677604

Epoch: 59| Step: 0
Training loss: 2.5707318782806396
Validation loss: 2.319263735125142

Epoch: 5| Step: 1
Training loss: 2.8972630500793457
Validation loss: 2.3270978132883706

Epoch: 5| Step: 2
Training loss: 2.507046937942505
Validation loss: 2.3340025922303558

Epoch: 5| Step: 3
Training loss: 2.4032299518585205
Validation loss: 2.3208495878404185

Epoch: 5| Step: 4
Training loss: 3.0696585178375244
Validation loss: 2.32648051938703

Epoch: 5| Step: 5
Training loss: 2.128828763961792
Validation loss: 2.3246283249188493

Epoch: 5| Step: 6
Training loss: 2.2363457679748535
Validation loss: 2.3285536766052246

Epoch: 5| Step: 7
Training loss: 2.6620209217071533
Validation loss: 2.3313041194792716

Epoch: 5| Step: 8
Training loss: 2.5677218437194824
Validation loss: 2.332726727249802

Epoch: 5| Step: 9
Training loss: 2.2617857456207275
Validation loss: 2.338072710139777

Epoch: 5| Step: 10
Training loss: 3.154660224914551
Validation loss: 2.3297952605832006

Epoch: 60| Step: 0
Training loss: 2.362382411956787
Validation loss: 2.337663622312648

Epoch: 5| Step: 1
Training loss: 2.332338809967041
Validation loss: 2.3395938873291016

Epoch: 5| Step: 2
Training loss: 1.985424280166626
Validation loss: 2.337054471815786

Epoch: 5| Step: 3
Training loss: 3.1425185203552246
Validation loss: 2.3280650684910436

Epoch: 5| Step: 4
Training loss: 1.949853539466858
Validation loss: 2.3374313513437905

Epoch: 5| Step: 5
Training loss: 2.755343198776245
Validation loss: 2.352625846862793

Epoch: 5| Step: 6
Training loss: 2.271911382675171
Validation loss: 2.359009245390533

Epoch: 5| Step: 7
Training loss: 2.8449811935424805
Validation loss: 2.3565867793175483

Epoch: 5| Step: 8
Training loss: 3.36921763420105
Validation loss: 2.3532860099628405

Epoch: 5| Step: 9
Training loss: 2.8170599937438965
Validation loss: 2.3425136663580455

Epoch: 5| Step: 10
Training loss: 2.6567647457122803
Validation loss: 2.3309891557180755

Epoch: 61| Step: 0
Training loss: 2.3760600090026855
Validation loss: 2.3235072346143824

Epoch: 5| Step: 1
Training loss: 2.5142579078674316
Validation loss: 2.324769007262363

Epoch: 5| Step: 2
Training loss: 2.6675965785980225
Validation loss: 2.3244381361110236

Epoch: 5| Step: 3
Training loss: 2.3275463581085205
Validation loss: 2.309371622659827

Epoch: 5| Step: 4
Training loss: 3.248995542526245
Validation loss: 2.312976383393811

Epoch: 5| Step: 5
Training loss: 2.2562828063964844
Validation loss: 2.3146701884526077

Epoch: 5| Step: 6
Training loss: 2.7502307891845703
Validation loss: 2.308337988391999

Epoch: 5| Step: 7
Training loss: 2.898094654083252
Validation loss: 2.307650045682025

Epoch: 5| Step: 8
Training loss: 2.385127544403076
Validation loss: 2.3104987503379903

Epoch: 5| Step: 9
Training loss: 2.5438144207000732
Validation loss: 2.306476569944812

Epoch: 5| Step: 10
Training loss: 2.3454208374023438
Validation loss: 2.3169393795792774

Epoch: 62| Step: 0
Training loss: 2.219179391860962
Validation loss: 2.3132149532277095

Epoch: 5| Step: 1
Training loss: 2.5124671459198
Validation loss: 2.346323593970268

Epoch: 5| Step: 2
Training loss: 2.6449599266052246
Validation loss: 2.378288310061219

Epoch: 5| Step: 3
Training loss: 2.6599714756011963
Validation loss: 2.4029404732488815

Epoch: 5| Step: 4
Training loss: 2.9350533485412598
Validation loss: 2.396906555339854

Epoch: 5| Step: 5
Training loss: 2.6435203552246094
Validation loss: 2.3674679776673675

Epoch: 5| Step: 6
Training loss: 2.5486440658569336
Validation loss: 2.3399710706485215

Epoch: 5| Step: 7
Training loss: 2.4663119316101074
Validation loss: 2.3344159305736585

Epoch: 5| Step: 8
Training loss: 2.168480634689331
Validation loss: 2.321736789518787

Epoch: 5| Step: 9
Training loss: 2.8076252937316895
Validation loss: 2.3047408596161874

Epoch: 5| Step: 10
Training loss: 2.725855827331543
Validation loss: 2.3078004160235004

Epoch: 63| Step: 0
Training loss: 2.5759079456329346
Validation loss: 2.3054094468393633

Epoch: 5| Step: 1
Training loss: 3.088059425354004
Validation loss: 2.3094642469959874

Epoch: 5| Step: 2
Training loss: 1.8266185522079468
Validation loss: 2.313035839347429

Epoch: 5| Step: 3
Training loss: 1.8901541233062744
Validation loss: 2.319376996768418

Epoch: 5| Step: 4
Training loss: 3.286296844482422
Validation loss: 2.2992075668868197

Epoch: 5| Step: 5
Training loss: 2.624694347381592
Validation loss: 2.2946470911784838

Epoch: 5| Step: 6
Training loss: 2.63482928276062
Validation loss: 2.3271389751024145

Epoch: 5| Step: 7
Training loss: 2.752342939376831
Validation loss: 2.3648154658655964

Epoch: 5| Step: 8
Training loss: 2.5773167610168457
Validation loss: 2.371972260936614

Epoch: 5| Step: 9
Training loss: 2.6010470390319824
Validation loss: 2.360010693150182

Epoch: 5| Step: 10
Training loss: 2.6241321563720703
Validation loss: 2.345478373189126

Epoch: 64| Step: 0
Training loss: 1.8082176446914673
Validation loss: 2.331466228731217

Epoch: 5| Step: 1
Training loss: 2.7340891361236572
Validation loss: 2.312232184153731

Epoch: 5| Step: 2
Training loss: 2.84975004196167
Validation loss: 2.300264404666039

Epoch: 5| Step: 3
Training loss: 1.7026668787002563
Validation loss: 2.294031766153151

Epoch: 5| Step: 4
Training loss: 2.994777202606201
Validation loss: 2.297898574541974

Epoch: 5| Step: 5
Training loss: 2.2109382152557373
Validation loss: 2.309215827654767

Epoch: 5| Step: 6
Training loss: 2.48938250541687
Validation loss: 2.305419098946356

Epoch: 5| Step: 7
Training loss: 2.28859281539917
Validation loss: 2.2882187879213722

Epoch: 5| Step: 8
Training loss: 3.1140599250793457
Validation loss: 2.27977579639804

Epoch: 5| Step: 9
Training loss: 3.118182420730591
Validation loss: 2.2984444838698193

Epoch: 5| Step: 10
Training loss: 3.0426437854766846
Validation loss: 2.320410733581871

Epoch: 65| Step: 0
Training loss: 2.164769411087036
Validation loss: 2.342466433842977

Epoch: 5| Step: 1
Training loss: 2.825380802154541
Validation loss: 2.3637748738770843

Epoch: 5| Step: 2
Training loss: 2.8270163536071777
Validation loss: 2.3697852729469218

Epoch: 5| Step: 3
Training loss: 2.835411548614502
Validation loss: 2.3631850865579422

Epoch: 5| Step: 4
Training loss: 2.27347993850708
Validation loss: 2.331359509498842

Epoch: 5| Step: 5
Training loss: 2.6491189002990723
Validation loss: 2.32482728650493

Epoch: 5| Step: 6
Training loss: 2.577667236328125
Validation loss: 2.2959135783615934

Epoch: 5| Step: 7
Training loss: 2.13581919670105
Validation loss: 2.280987085834626

Epoch: 5| Step: 8
Training loss: 2.9301583766937256
Validation loss: 2.2772914389128327

Epoch: 5| Step: 9
Training loss: 2.7504255771636963
Validation loss: 2.308409442183792

Epoch: 5| Step: 10
Training loss: 2.2479755878448486
Validation loss: 2.294449516521987

Epoch: 66| Step: 0
Training loss: 2.629286289215088
Validation loss: 2.2750957704359487

Epoch: 5| Step: 1
Training loss: 1.9722840785980225
Validation loss: 2.2754725948456795

Epoch: 5| Step: 2
Training loss: 2.520484447479248
Validation loss: 2.2729906907645603

Epoch: 5| Step: 3
Training loss: 2.5550193786621094
Validation loss: 2.3000665556999946

Epoch: 5| Step: 4
Training loss: 2.9074766635894775
Validation loss: 2.3261128548652894

Epoch: 5| Step: 5
Training loss: 2.622098445892334
Validation loss: 2.3818000132037747

Epoch: 5| Step: 6
Training loss: 2.667031764984131
Validation loss: 2.3447707571009153

Epoch: 5| Step: 7
Training loss: 2.506951093673706
Validation loss: 2.3191575542573006

Epoch: 5| Step: 8
Training loss: 2.314756393432617
Validation loss: 2.290132958401916

Epoch: 5| Step: 9
Training loss: 3.1737589836120605
Validation loss: 2.2907913141353156

Epoch: 5| Step: 10
Training loss: 2.4969327449798584
Validation loss: 2.2875788878369074

Epoch: 67| Step: 0
Training loss: 2.9963526725769043
Validation loss: 2.28565074295126

Epoch: 5| Step: 1
Training loss: 2.440586805343628
Validation loss: 2.2967522913409817

Epoch: 5| Step: 2
Training loss: 2.4160592555999756
Validation loss: 2.286719601641419

Epoch: 5| Step: 3
Training loss: 2.397042751312256
Validation loss: 2.2987389256877284

Epoch: 5| Step: 4
Training loss: 2.6943531036376953
Validation loss: 2.310427301673479

Epoch: 5| Step: 5
Training loss: 2.3874096870422363
Validation loss: 2.3347577971796833

Epoch: 5| Step: 6
Training loss: 2.18941330909729
Validation loss: 2.3667027463195143

Epoch: 5| Step: 7
Training loss: 2.4881443977355957
Validation loss: 2.3504108664810017

Epoch: 5| Step: 8
Training loss: 2.757267475128174
Validation loss: 2.356135155564995

Epoch: 5| Step: 9
Training loss: 3.194577217102051
Validation loss: 2.3341997182497414

Epoch: 5| Step: 10
Training loss: 2.261970043182373
Validation loss: 2.3025839687675558

Epoch: 68| Step: 0
Training loss: 2.1315455436706543
Validation loss: 2.274419043653755

Epoch: 5| Step: 1
Training loss: 2.434028148651123
Validation loss: 2.280248457385648

Epoch: 5| Step: 2
Training loss: 2.2367520332336426
Validation loss: 2.289310565558813

Epoch: 5| Step: 3
Training loss: 2.741840362548828
Validation loss: 2.305520648597389

Epoch: 5| Step: 4
Training loss: 2.606863021850586
Validation loss: 2.312181226668819

Epoch: 5| Step: 5
Training loss: 2.5542891025543213
Validation loss: 2.311877150689402

Epoch: 5| Step: 6
Training loss: 2.5087146759033203
Validation loss: 2.31634101816403

Epoch: 5| Step: 7
Training loss: 3.808969020843506
Validation loss: 2.3137184701940066

Epoch: 5| Step: 8
Training loss: 2.2922110557556152
Validation loss: 2.3014282693145094

Epoch: 5| Step: 9
Training loss: 2.3758137226104736
Validation loss: 2.2993778823524393

Epoch: 5| Step: 10
Training loss: 2.6386425495147705
Validation loss: 2.2933520296568513

Epoch: 69| Step: 0
Training loss: 2.9888949394226074
Validation loss: 2.2854046449866345

Epoch: 5| Step: 1
Training loss: 2.532660961151123
Validation loss: 2.2951688407569804

Epoch: 5| Step: 2
Training loss: 2.429962158203125
Validation loss: 2.309772736282759

Epoch: 5| Step: 3
Training loss: 2.437896251678467
Validation loss: 2.3035002241852465

Epoch: 5| Step: 4
Training loss: 2.7747597694396973
Validation loss: 2.2857412702293805

Epoch: 5| Step: 5
Training loss: 2.6256136894226074
Validation loss: 2.2863828212984147

Epoch: 5| Step: 6
Training loss: 2.827880859375
Validation loss: 2.289755536663917

Epoch: 5| Step: 7
Training loss: 2.471752643585205
Validation loss: 2.3044141953991306

Epoch: 5| Step: 8
Training loss: 1.6314058303833008
Validation loss: 2.3147104940106793

Epoch: 5| Step: 9
Training loss: 2.9393105506896973
Validation loss: 2.3460941160878828

Epoch: 5| Step: 10
Training loss: 2.3313727378845215
Validation loss: 2.3428128765475367

Epoch: 70| Step: 0
Training loss: 3.5873913764953613
Validation loss: 2.377969459820819

Epoch: 5| Step: 1
Training loss: 2.1142375469207764
Validation loss: 2.3536201574469127

Epoch: 5| Step: 2
Training loss: 2.5938286781311035
Validation loss: 2.3313072330208233

Epoch: 5| Step: 3
Training loss: 1.9496738910675049
Validation loss: 2.3044066224046933

Epoch: 5| Step: 4
Training loss: 2.965707778930664
Validation loss: 2.27872275024332

Epoch: 5| Step: 5
Training loss: 2.8354647159576416
Validation loss: 2.2714498683970463

Epoch: 5| Step: 6
Training loss: 2.537435293197632
Validation loss: 2.2530055174263577

Epoch: 5| Step: 7
Training loss: 2.6867754459381104
Validation loss: 2.24959998233344

Epoch: 5| Step: 8
Training loss: 1.954766869544983
Validation loss: 2.2506335012374388

Epoch: 5| Step: 9
Training loss: 2.314481496810913
Validation loss: 2.2653200036735943

Epoch: 5| Step: 10
Training loss: 2.4402027130126953
Validation loss: 2.276574753945874

Epoch: 71| Step: 0
Training loss: 2.7687125205993652
Validation loss: 2.299206769594582

Epoch: 5| Step: 1
Training loss: 2.455291271209717
Validation loss: 2.2939784808825423

Epoch: 5| Step: 2
Training loss: 2.5672314167022705
Validation loss: 2.3071071204318794

Epoch: 5| Step: 3
Training loss: 2.857908248901367
Validation loss: 2.293955059461696

Epoch: 5| Step: 4
Training loss: 2.898746967315674
Validation loss: 2.2575504779815674

Epoch: 5| Step: 5
Training loss: 2.1867446899414062
Validation loss: 2.242243469402354

Epoch: 5| Step: 6
Training loss: 2.295619249343872
Validation loss: 2.2433486933349283

Epoch: 5| Step: 7
Training loss: 2.749443769454956
Validation loss: 2.242645004744171

Epoch: 5| Step: 8
Training loss: 1.7385213375091553
Validation loss: 2.2466216330887168

Epoch: 5| Step: 9
Training loss: 2.4134364128112793
Validation loss: 2.254819526467272

Epoch: 5| Step: 10
Training loss: 3.074697971343994
Validation loss: 2.2600115435097807

Epoch: 72| Step: 0
Training loss: 2.35367751121521
Validation loss: 2.28525629351216

Epoch: 5| Step: 1
Training loss: 2.7623367309570312
Validation loss: 2.315410501213484

Epoch: 5| Step: 2
Training loss: 2.9179039001464844
Validation loss: 2.3478031876266643

Epoch: 5| Step: 3
Training loss: 2.3070859909057617
Validation loss: 2.3718380235856578

Epoch: 5| Step: 4
Training loss: 2.286234140396118
Validation loss: 2.4076611482968895

Epoch: 5| Step: 5
Training loss: 3.1201794147491455
Validation loss: 2.404900686715239

Epoch: 5| Step: 6
Training loss: 2.2692558765411377
Validation loss: 2.3535101182999147

Epoch: 5| Step: 7
Training loss: 2.5418009757995605
Validation loss: 2.293486995081748

Epoch: 5| Step: 8
Training loss: 2.3326034545898438
Validation loss: 2.2658427556355796

Epoch: 5| Step: 9
Training loss: 2.97871732711792
Validation loss: 2.273367174210087

Epoch: 5| Step: 10
Training loss: 2.2465569972991943
Validation loss: 2.355515895351287

Epoch: 73| Step: 0
Training loss: 2.517573595046997
Validation loss: 2.3855951268185853

Epoch: 5| Step: 1
Training loss: 2.7636845111846924
Validation loss: 2.3595767944089827

Epoch: 5| Step: 2
Training loss: 2.6660404205322266
Validation loss: 2.3100253305127545

Epoch: 5| Step: 3
Training loss: 2.456909418106079
Validation loss: 2.2682716051737466

Epoch: 5| Step: 4
Training loss: 2.8815701007843018
Validation loss: 2.2518194670318277

Epoch: 5| Step: 5
Training loss: 2.6181461811065674
Validation loss: 2.2405830019263813

Epoch: 5| Step: 6
Training loss: 2.668952465057373
Validation loss: 2.239151013794766

Epoch: 5| Step: 7
Training loss: 2.0810048580169678
Validation loss: 2.2774861064008487

Epoch: 5| Step: 8
Training loss: 2.2821688652038574
Validation loss: 2.3156131749512046

Epoch: 5| Step: 9
Training loss: 2.638934850692749
Validation loss: 2.320321539396881

Epoch: 5| Step: 10
Training loss: 2.819516181945801
Validation loss: 2.3141592625648744

Epoch: 74| Step: 0
Training loss: 2.1751933097839355
Validation loss: 2.291423248988326

Epoch: 5| Step: 1
Training loss: 2.869492769241333
Validation loss: 2.254400695523908

Epoch: 5| Step: 2
Training loss: 3.3532814979553223
Validation loss: 2.2463012151820685

Epoch: 5| Step: 3
Training loss: 1.9578174352645874
Validation loss: 2.243516791251398

Epoch: 5| Step: 4
Training loss: 2.71101713180542
Validation loss: 2.237761935880107

Epoch: 5| Step: 5
Training loss: 2.566544532775879
Validation loss: 2.2371535954936856

Epoch: 5| Step: 6
Training loss: 2.2563343048095703
Validation loss: 2.240468822499757

Epoch: 5| Step: 7
Training loss: 2.224088191986084
Validation loss: 2.2447308135289017

Epoch: 5| Step: 8
Training loss: 3.179957628250122
Validation loss: 2.2632847011730237

Epoch: 5| Step: 9
Training loss: 2.693512439727783
Validation loss: 2.3225775995562152

Epoch: 5| Step: 10
Training loss: 1.7904961109161377
Validation loss: 2.3687849326800277

Epoch: 75| Step: 0
Training loss: 2.532386541366577
Validation loss: 2.4004870832607312

Epoch: 5| Step: 1
Training loss: 2.4850523471832275
Validation loss: 2.413432659641389

Epoch: 5| Step: 2
Training loss: 2.1223721504211426
Validation loss: 2.394978654000067

Epoch: 5| Step: 3
Training loss: 2.7491493225097656
Validation loss: 2.349620824219078

Epoch: 5| Step: 4
Training loss: 2.428936004638672
Validation loss: 2.351746689888739

Epoch: 5| Step: 5
Training loss: 2.5939056873321533
Validation loss: 2.3563458688797487

Epoch: 5| Step: 6
Training loss: 2.999271869659424
Validation loss: 2.3469307115001063

Epoch: 5| Step: 7
Training loss: 3.330888032913208
Validation loss: 2.3472150115556616

Epoch: 5| Step: 8
Training loss: 2.363161325454712
Validation loss: 2.33994532656926

Epoch: 5| Step: 9
Training loss: 2.101489782333374
Validation loss: 2.3375184305252565

Epoch: 5| Step: 10
Training loss: 2.587137222290039
Validation loss: 2.3295353586955736

Epoch: 76| Step: 0
Training loss: 2.571749210357666
Validation loss: 2.333791154687123

Epoch: 5| Step: 1
Training loss: 2.7606308460235596
Validation loss: 2.327056841183734

Epoch: 5| Step: 2
Training loss: 2.6128876209259033
Validation loss: 2.3279243874293503

Epoch: 5| Step: 3
Training loss: 2.8981385231018066
Validation loss: 2.324045714511666

Epoch: 5| Step: 4
Training loss: 3.075082302093506
Validation loss: 2.3259523837797103

Epoch: 5| Step: 5
Training loss: 2.445167303085327
Validation loss: 2.3181679043718564

Epoch: 5| Step: 6
Training loss: 2.720085620880127
Validation loss: 2.3222660223642984

Epoch: 5| Step: 7
Training loss: 2.0457816123962402
Validation loss: 2.2886981502656014

Epoch: 5| Step: 8
Training loss: 2.109832286834717
Validation loss: 2.2576330682282806

Epoch: 5| Step: 9
Training loss: 2.6305127143859863
Validation loss: 2.238669962011358

Epoch: 5| Step: 10
Training loss: 1.9616477489471436
Validation loss: 2.223793342549314

Epoch: 77| Step: 0
Training loss: 1.9774448871612549
Validation loss: 2.203898517034387

Epoch: 5| Step: 1
Training loss: 3.0681703090667725
Validation loss: 2.2117516020292878

Epoch: 5| Step: 2
Training loss: 1.94158136844635
Validation loss: 2.217243822672034

Epoch: 5| Step: 3
Training loss: 2.5424985885620117
Validation loss: 2.256249676468552

Epoch: 5| Step: 4
Training loss: 2.8069546222686768
Validation loss: 2.2581529745491604

Epoch: 5| Step: 5
Training loss: 2.354937791824341
Validation loss: 2.2368464982637795

Epoch: 5| Step: 6
Training loss: 2.3902854919433594
Validation loss: 2.2045577956784155

Epoch: 5| Step: 7
Training loss: 3.199183225631714
Validation loss: 2.2004141179464196

Epoch: 5| Step: 8
Training loss: 2.471059799194336
Validation loss: 2.204918340970111

Epoch: 5| Step: 9
Training loss: 2.0476644039154053
Validation loss: 2.211157573166714

Epoch: 5| Step: 10
Training loss: 3.0802268981933594
Validation loss: 2.2129759429603495

Epoch: 78| Step: 0
Training loss: 2.3743834495544434
Validation loss: 2.211637056002053

Epoch: 5| Step: 1
Training loss: 2.217345714569092
Validation loss: 2.212091809959822

Epoch: 5| Step: 2
Training loss: 2.7837517261505127
Validation loss: 2.222327087515144

Epoch: 5| Step: 3
Training loss: 2.433803081512451
Validation loss: 2.228913035444034

Epoch: 5| Step: 4
Training loss: 1.6015961170196533
Validation loss: 2.2344592719949703

Epoch: 5| Step: 5
Training loss: 2.36077880859375
Validation loss: 2.244766289188016

Epoch: 5| Step: 6
Training loss: 2.6737301349639893
Validation loss: 2.2501961159449753

Epoch: 5| Step: 7
Training loss: 3.1057019233703613
Validation loss: 2.23971886532281

Epoch: 5| Step: 8
Training loss: 2.688570976257324
Validation loss: 2.2447264630307435

Epoch: 5| Step: 9
Training loss: 3.0343856811523438
Validation loss: 2.249887768940259

Epoch: 5| Step: 10
Training loss: 2.346400737762451
Validation loss: 2.249933550434728

Epoch: 79| Step: 0
Training loss: 2.2077019214630127
Validation loss: 2.2610866818376767

Epoch: 5| Step: 1
Training loss: 2.6637425422668457
Validation loss: 2.2783028310345066

Epoch: 5| Step: 2
Training loss: 2.770268201828003
Validation loss: 2.2748110601978917

Epoch: 5| Step: 3
Training loss: 2.8219237327575684
Validation loss: 2.249303435766569

Epoch: 5| Step: 4
Training loss: 3.0464043617248535
Validation loss: 2.2364328061380694

Epoch: 5| Step: 5
Training loss: 2.2298483848571777
Validation loss: 2.221791375067926

Epoch: 5| Step: 6
Training loss: 2.311004400253296
Validation loss: 2.213089412258517

Epoch: 5| Step: 7
Training loss: 2.569596529006958
Validation loss: 2.20877843774775

Epoch: 5| Step: 8
Training loss: 2.1167335510253906
Validation loss: 2.207284922240883

Epoch: 5| Step: 9
Training loss: 2.507307767868042
Validation loss: 2.1979477815730597

Epoch: 5| Step: 10
Training loss: 2.2495594024658203
Validation loss: 2.2001166343688965

Epoch: 80| Step: 0
Training loss: 2.5695605278015137
Validation loss: 2.2086912637115805

Epoch: 5| Step: 1
Training loss: 1.7003304958343506
Validation loss: 2.2130430090811943

Epoch: 5| Step: 2
Training loss: 2.4830832481384277
Validation loss: 2.232136188014861

Epoch: 5| Step: 3
Training loss: 2.2050623893737793
Validation loss: 2.244535087257303

Epoch: 5| Step: 4
Training loss: 2.5853238105773926
Validation loss: 2.24105893411944

Epoch: 5| Step: 5
Training loss: 2.4699926376342773
Validation loss: 2.2103432173370035

Epoch: 5| Step: 6
Training loss: 2.784801959991455
Validation loss: 2.194697164720105

Epoch: 5| Step: 7
Training loss: 2.914302349090576
Validation loss: 2.192131406517439

Epoch: 5| Step: 8
Training loss: 2.911353588104248
Validation loss: 2.195403160587434

Epoch: 5| Step: 9
Training loss: 2.0949645042419434
Validation loss: 2.200099793813562

Epoch: 5| Step: 10
Training loss: 2.7419638633728027
Validation loss: 2.2045276088099324

Epoch: 81| Step: 0
Training loss: 2.9386305809020996
Validation loss: 2.1925229949335896

Epoch: 5| Step: 1
Training loss: 2.4615225791931152
Validation loss: 2.1993941927468903

Epoch: 5| Step: 2
Training loss: 2.012566089630127
Validation loss: 2.1990700947341097

Epoch: 5| Step: 3
Training loss: 2.1925296783447266
Validation loss: 2.1994228824492423

Epoch: 5| Step: 4
Training loss: 2.6623663902282715
Validation loss: 2.2080078227545625

Epoch: 5| Step: 5
Training loss: 2.372666120529175
Validation loss: 2.2179241385511173

Epoch: 5| Step: 6
Training loss: 2.6721720695495605
Validation loss: 2.2335576677835114

Epoch: 5| Step: 7
Training loss: 2.854646682739258
Validation loss: 2.2266316183151735

Epoch: 5| Step: 8
Training loss: 1.8405624628067017
Validation loss: 2.2219789028167725

Epoch: 5| Step: 9
Training loss: 2.564931631088257
Validation loss: 2.2198008439874135

Epoch: 5| Step: 10
Training loss: 2.6996073722839355
Validation loss: 2.221980030818652

Epoch: 82| Step: 0
Training loss: 1.9975544214248657
Validation loss: 2.208146782331569

Epoch: 5| Step: 1
Training loss: 2.17039155960083
Validation loss: 2.199514308283406

Epoch: 5| Step: 2
Training loss: 2.197260856628418
Validation loss: 2.1915592762731735

Epoch: 5| Step: 3
Training loss: 2.963350772857666
Validation loss: 2.185624576384021

Epoch: 5| Step: 4
Training loss: 2.984396457672119
Validation loss: 2.192514258046304

Epoch: 5| Step: 5
Training loss: 2.122990846633911
Validation loss: 2.182486528991371

Epoch: 5| Step: 6
Training loss: 2.4216034412384033
Validation loss: 2.183013346887404

Epoch: 5| Step: 7
Training loss: 2.576085329055786
Validation loss: 2.184177029517389

Epoch: 5| Step: 8
Training loss: 2.7716476917266846
Validation loss: 2.1905917647064372

Epoch: 5| Step: 9
Training loss: 2.649015188217163
Validation loss: 2.1998060211058585

Epoch: 5| Step: 10
Training loss: 2.399690628051758
Validation loss: 2.20882418335125

Epoch: 83| Step: 0
Training loss: 1.9247543811798096
Validation loss: 2.1938157107240412

Epoch: 5| Step: 1
Training loss: 2.609954357147217
Validation loss: 2.1975247885591243

Epoch: 5| Step: 2
Training loss: 1.814387559890747
Validation loss: 2.2175432405164166

Epoch: 5| Step: 3
Training loss: 3.0913476943969727
Validation loss: 2.240412555715089

Epoch: 5| Step: 4
Training loss: 2.1755318641662598
Validation loss: 2.2534032457618305

Epoch: 5| Step: 5
Training loss: 3.0159220695495605
Validation loss: 2.270000398799937

Epoch: 5| Step: 6
Training loss: 2.8937807083129883
Validation loss: 2.255302062598608

Epoch: 5| Step: 7
Training loss: 2.3736767768859863
Validation loss: 2.227925705653365

Epoch: 5| Step: 8
Training loss: 2.741504669189453
Validation loss: 2.182379595695003

Epoch: 5| Step: 9
Training loss: 2.2301700115203857
Validation loss: 2.17381465050482

Epoch: 5| Step: 10
Training loss: 2.38325572013855
Validation loss: 2.1759671293279177

Epoch: 84| Step: 0
Training loss: 2.3170225620269775
Validation loss: 2.1701995890627623

Epoch: 5| Step: 1
Training loss: 2.5708038806915283
Validation loss: 2.1766825683655275

Epoch: 5| Step: 2
Training loss: 2.1308791637420654
Validation loss: 2.1813350928727018

Epoch: 5| Step: 3
Training loss: 3.386141300201416
Validation loss: 2.183799451397311

Epoch: 5| Step: 4
Training loss: 1.918039321899414
Validation loss: 2.1854116057836883

Epoch: 5| Step: 5
Training loss: 2.550269365310669
Validation loss: 2.181030504165157

Epoch: 5| Step: 6
Training loss: 2.385159969329834
Validation loss: 2.1889033112474667

Epoch: 5| Step: 7
Training loss: 2.3108508586883545
Validation loss: 2.222548746293591

Epoch: 5| Step: 8
Training loss: 3.0771985054016113
Validation loss: 2.247464797830069

Epoch: 5| Step: 9
Training loss: 1.853885293006897
Validation loss: 2.222420202788486

Epoch: 5| Step: 10
Training loss: 2.6927170753479004
Validation loss: 2.2317976054324897

Epoch: 85| Step: 0
Training loss: 2.440272331237793
Validation loss: 2.229489449531801

Epoch: 5| Step: 1
Training loss: 2.0900683403015137
Validation loss: 2.2262483463492444

Epoch: 5| Step: 2
Training loss: 2.550266981124878
Validation loss: 2.224065890876196

Epoch: 5| Step: 3
Training loss: 2.391061305999756
Validation loss: 2.2287540179426952

Epoch: 5| Step: 4
Training loss: 2.971700668334961
Validation loss: 2.219878327461981

Epoch: 5| Step: 5
Training loss: 2.470188617706299
Validation loss: 2.1821682991520053

Epoch: 5| Step: 6
Training loss: 2.4939777851104736
Validation loss: 2.170875405752531

Epoch: 5| Step: 7
Training loss: 2.5050628185272217
Validation loss: 2.1693673133850098

Epoch: 5| Step: 8
Training loss: 2.659015417098999
Validation loss: 2.1619955083375335

Epoch: 5| Step: 9
Training loss: 2.1479856967926025
Validation loss: 2.167835391977782

Epoch: 5| Step: 10
Training loss: 2.5113003253936768
Validation loss: 2.1637051490045365

Epoch: 86| Step: 0
Training loss: 2.449773073196411
Validation loss: 2.162377066509698

Epoch: 5| Step: 1
Training loss: 2.7722434997558594
Validation loss: 2.1635677160755282

Epoch: 5| Step: 2
Training loss: 2.586442470550537
Validation loss: 2.1740126699529667

Epoch: 5| Step: 3
Training loss: 3.1917648315429688
Validation loss: 2.173195526164065

Epoch: 5| Step: 4
Training loss: 2.1349031925201416
Validation loss: 2.174559485527777

Epoch: 5| Step: 5
Training loss: 2.3052902221679688
Validation loss: 2.177362729144353

Epoch: 5| Step: 6
Training loss: 2.0339066982269287
Validation loss: 2.1853730627285537

Epoch: 5| Step: 7
Training loss: 2.2884531021118164
Validation loss: 2.1988991934766053

Epoch: 5| Step: 8
Training loss: 2.6163737773895264
Validation loss: 2.2128661614592358

Epoch: 5| Step: 9
Training loss: 1.5979487895965576
Validation loss: 2.2252164476661274

Epoch: 5| Step: 10
Training loss: 3.087275743484497
Validation loss: 2.2071177908169326

Epoch: 87| Step: 0
Training loss: 2.541792392730713
Validation loss: 2.1861747131552747

Epoch: 5| Step: 1
Training loss: 2.2426552772521973
Validation loss: 2.190543927172179

Epoch: 5| Step: 2
Training loss: 2.515389919281006
Validation loss: 2.167413288547147

Epoch: 5| Step: 3
Training loss: 2.5194153785705566
Validation loss: 2.155528396688482

Epoch: 5| Step: 4
Training loss: 2.27036714553833
Validation loss: 2.1552080595365135

Epoch: 5| Step: 5
Training loss: 2.725712299346924
Validation loss: 2.1576027113904237

Epoch: 5| Step: 6
Training loss: 2.2416045665740967
Validation loss: 2.157224852551696

Epoch: 5| Step: 7
Training loss: 2.4337611198425293
Validation loss: 2.158562848644872

Epoch: 5| Step: 8
Training loss: 2.6282401084899902
Validation loss: 2.1519325010238157

Epoch: 5| Step: 9
Training loss: 2.4982335567474365
Validation loss: 2.1573290414707635

Epoch: 5| Step: 10
Training loss: 2.328259229660034
Validation loss: 2.1608784967853176

Epoch: 88| Step: 0
Training loss: 2.0166821479797363
Validation loss: 2.183675774963953

Epoch: 5| Step: 1
Training loss: 2.0896458625793457
Validation loss: 2.213974996279645

Epoch: 5| Step: 2
Training loss: 2.937382221221924
Validation loss: 2.2216265432296263

Epoch: 5| Step: 3
Training loss: 2.9219353199005127
Validation loss: 2.2507214982022523

Epoch: 5| Step: 4
Training loss: 2.4899673461914062
Validation loss: 2.2661296039499264

Epoch: 5| Step: 5
Training loss: 2.4877638816833496
Validation loss: 2.2560002701256865

Epoch: 5| Step: 6
Training loss: 2.927731990814209
Validation loss: 2.240080443761682

Epoch: 5| Step: 7
Training loss: 1.9965076446533203
Validation loss: 2.2245905655686573

Epoch: 5| Step: 8
Training loss: 2.1981093883514404
Validation loss: 2.216031164251348

Epoch: 5| Step: 9
Training loss: 2.743722915649414
Validation loss: 2.214782814825735

Epoch: 5| Step: 10
Training loss: 2.4240903854370117
Validation loss: 2.2005087073131273

Epoch: 89| Step: 0
Training loss: 2.356382369995117
Validation loss: 2.197875543307233

Epoch: 5| Step: 1
Training loss: 2.3801653385162354
Validation loss: 2.150882023637013

Epoch: 5| Step: 2
Training loss: 2.1383373737335205
Validation loss: 2.1550653237168507

Epoch: 5| Step: 3
Training loss: 2.7389883995056152
Validation loss: 2.1684363631791967

Epoch: 5| Step: 4
Training loss: 2.691380262374878
Validation loss: 2.2126059391165294

Epoch: 5| Step: 5
Training loss: 2.3699965476989746
Validation loss: 2.235795919613172

Epoch: 5| Step: 6
Training loss: 2.396846294403076
Validation loss: 2.220073699951172

Epoch: 5| Step: 7
Training loss: 2.619680404663086
Validation loss: 2.1888987146398073

Epoch: 5| Step: 8
Training loss: 2.288245439529419
Validation loss: 2.169990852314939

Epoch: 5| Step: 9
Training loss: 2.4147396087646484
Validation loss: 2.153349712330808

Epoch: 5| Step: 10
Training loss: 2.6525866985321045
Validation loss: 2.153864381133869

Epoch: 90| Step: 0
Training loss: 1.7244627475738525
Validation loss: 2.140217072220259

Epoch: 5| Step: 1
Training loss: 2.3346893787384033
Validation loss: 2.1337546379335466

Epoch: 5| Step: 2
Training loss: 2.486752986907959
Validation loss: 2.131418192258445

Epoch: 5| Step: 3
Training loss: 1.9697351455688477
Validation loss: 2.1379706475042526

Epoch: 5| Step: 4
Training loss: 2.4337682723999023
Validation loss: 2.1598022189191592

Epoch: 5| Step: 5
Training loss: 3.0189871788024902
Validation loss: 2.181968717164891

Epoch: 5| Step: 6
Training loss: 2.249021053314209
Validation loss: 2.2156040476214502

Epoch: 5| Step: 7
Training loss: 2.3829293251037598
Validation loss: 2.2406042186162805

Epoch: 5| Step: 8
Training loss: 2.424267292022705
Validation loss: 2.225873859979773

Epoch: 5| Step: 9
Training loss: 2.7199268341064453
Validation loss: 2.1883699637587353

Epoch: 5| Step: 10
Training loss: 3.3697261810302734
Validation loss: 2.179372577257054

Epoch: 91| Step: 0
Training loss: 2.594458818435669
Validation loss: 2.1766239763588033

Epoch: 5| Step: 1
Training loss: 2.080162763595581
Validation loss: 2.182171957467192

Epoch: 5| Step: 2
Training loss: 2.2000186443328857
Validation loss: 2.1896930227997484

Epoch: 5| Step: 3
Training loss: 2.4403929710388184
Validation loss: 2.1840752952842304

Epoch: 5| Step: 4
Training loss: 2.805335283279419
Validation loss: 2.1835588216781616

Epoch: 5| Step: 5
Training loss: 2.9991631507873535
Validation loss: 2.176780880138438

Epoch: 5| Step: 6
Training loss: 2.1849517822265625
Validation loss: 2.1720219376266643

Epoch: 5| Step: 7
Training loss: 2.0738730430603027
Validation loss: 2.1751361944342174

Epoch: 5| Step: 8
Training loss: 2.8329520225524902
Validation loss: 2.179109860492009

Epoch: 5| Step: 9
Training loss: 1.7610900402069092
Validation loss: 2.222555968069261

Epoch: 5| Step: 10
Training loss: 2.9113354682922363
Validation loss: 2.2017172844179216

Epoch: 92| Step: 0
Training loss: 2.756063461303711
Validation loss: 2.2635680757543093

Epoch: 5| Step: 1
Training loss: 2.110487222671509
Validation loss: 2.265617665424142

Epoch: 5| Step: 2
Training loss: 2.0187442302703857
Validation loss: 2.2725957003972863

Epoch: 5| Step: 3
Training loss: 2.5761427879333496
Validation loss: 2.250267879937285

Epoch: 5| Step: 4
Training loss: 1.9030174016952515
Validation loss: 2.2298001371404177

Epoch: 5| Step: 5
Training loss: 2.37180495262146
Validation loss: 2.193606871430592

Epoch: 5| Step: 6
Training loss: 2.4571640491485596
Validation loss: 2.1870885459325646

Epoch: 5| Step: 7
Training loss: 2.514171838760376
Validation loss: 2.166355618866541

Epoch: 5| Step: 8
Training loss: 2.9206924438476562
Validation loss: 2.161500529576373

Epoch: 5| Step: 9
Training loss: 2.6569619178771973
Validation loss: 2.170944231812672

Epoch: 5| Step: 10
Training loss: 2.505889415740967
Validation loss: 2.1753072713011052

Epoch: 93| Step: 0
Training loss: 2.296785593032837
Validation loss: 2.2065472948935723

Epoch: 5| Step: 1
Training loss: 1.962855339050293
Validation loss: 2.1996354646580194

Epoch: 5| Step: 2
Training loss: 2.6783244609832764
Validation loss: 2.18384886300692

Epoch: 5| Step: 3
Training loss: 2.24833345413208
Validation loss: 2.1644537038700555

Epoch: 5| Step: 4
Training loss: 3.086153507232666
Validation loss: 2.1803204731274675

Epoch: 5| Step: 5
Training loss: 2.208543539047241
Validation loss: 2.1833254957711823

Epoch: 5| Step: 6
Training loss: 2.2006499767303467
Validation loss: 2.2003883828399

Epoch: 5| Step: 7
Training loss: 2.4979288578033447
Validation loss: 2.213603896479453

Epoch: 5| Step: 8
Training loss: 2.2534854412078857
Validation loss: 2.2236698468526206

Epoch: 5| Step: 9
Training loss: 2.5484232902526855
Validation loss: 2.2174584045205066

Epoch: 5| Step: 10
Training loss: 2.8193721771240234
Validation loss: 2.230223983846685

Epoch: 94| Step: 0
Training loss: 2.3105320930480957
Validation loss: 2.2336552143096924

Epoch: 5| Step: 1
Training loss: 3.2186195850372314
Validation loss: 2.235352482846988

Epoch: 5| Step: 2
Training loss: 2.5934863090515137
Validation loss: 2.232801506596227

Epoch: 5| Step: 3
Training loss: 2.585176467895508
Validation loss: 2.226705479365523

Epoch: 5| Step: 4
Training loss: 2.232659101486206
Validation loss: 2.2156116834250827

Epoch: 5| Step: 5
Training loss: 2.1556789875030518
Validation loss: 2.2139022696402764

Epoch: 5| Step: 6
Training loss: 1.8927319049835205
Validation loss: 2.2095969825662594

Epoch: 5| Step: 7
Training loss: 2.2400927543640137
Validation loss: 2.214651879443917

Epoch: 5| Step: 8
Training loss: 1.9694055318832397
Validation loss: 2.226891520202801

Epoch: 5| Step: 9
Training loss: 2.621224880218506
Validation loss: 2.246889818099237

Epoch: 5| Step: 10
Training loss: 2.984346389770508
Validation loss: 2.188010843851233

Epoch: 95| Step: 0
Training loss: 2.9814565181732178
Validation loss: 2.16777737422656

Epoch: 5| Step: 1
Training loss: 2.226016044616699
Validation loss: 2.157786682087888

Epoch: 5| Step: 2
Training loss: 1.6986339092254639
Validation loss: 2.1333636571002264

Epoch: 5| Step: 3
Training loss: 2.4489078521728516
Validation loss: 2.131817868960801

Epoch: 5| Step: 4
Training loss: 2.2360548973083496
Validation loss: 2.1237023492013254

Epoch: 5| Step: 5
Training loss: 2.6366140842437744
Validation loss: 2.1239898743168

Epoch: 5| Step: 6
Training loss: 2.465564012527466
Validation loss: 2.1239049716662337

Epoch: 5| Step: 7
Training loss: 2.1918540000915527
Validation loss: 2.1242364093821537

Epoch: 5| Step: 8
Training loss: 2.6264963150024414
Validation loss: 2.1404404665834162

Epoch: 5| Step: 9
Training loss: 2.872136354446411
Validation loss: 2.145267758318173

Epoch: 5| Step: 10
Training loss: 2.1860623359680176
Validation loss: 2.1509793240536927

Epoch: 96| Step: 0
Training loss: 2.439788818359375
Validation loss: 2.146698195447204

Epoch: 5| Step: 1
Training loss: 2.6515889167785645
Validation loss: 2.1445911930453394

Epoch: 5| Step: 2
Training loss: 2.240957498550415
Validation loss: 2.149285921486475

Epoch: 5| Step: 3
Training loss: 2.019638776779175
Validation loss: 2.1481027577513006

Epoch: 5| Step: 4
Training loss: 2.7737276554107666
Validation loss: 2.163250664229034

Epoch: 5| Step: 5
Training loss: 2.475421190261841
Validation loss: 2.166833980109102

Epoch: 5| Step: 6
Training loss: 2.6330506801605225
Validation loss: 2.160949900586118

Epoch: 5| Step: 7
Training loss: 2.712250232696533
Validation loss: 2.1699815488630727

Epoch: 5| Step: 8
Training loss: 1.8601105213165283
Validation loss: 2.1636143756169144

Epoch: 5| Step: 9
Training loss: 1.9692672491073608
Validation loss: 2.1501820548888175

Epoch: 5| Step: 10
Training loss: 2.471204996109009
Validation loss: 2.156176870869052

Epoch: 97| Step: 0
Training loss: 3.047806978225708
Validation loss: 2.1529284395197386

Epoch: 5| Step: 1
Training loss: 2.604109764099121
Validation loss: 2.1480465345485236

Epoch: 5| Step: 2
Training loss: 1.7079843282699585
Validation loss: 2.1493039413165023

Epoch: 5| Step: 3
Training loss: 2.910435199737549
Validation loss: 2.1539030203255276

Epoch: 5| Step: 4
Training loss: 2.3085904121398926
Validation loss: 2.169841217738326

Epoch: 5| Step: 5
Training loss: 2.1269519329071045
Validation loss: 2.1633688147350023

Epoch: 5| Step: 6
Training loss: 2.1808717250823975
Validation loss: 2.166901519221644

Epoch: 5| Step: 7
Training loss: 1.7948278188705444
Validation loss: 2.1763583947253484

Epoch: 5| Step: 8
Training loss: 2.156850814819336
Validation loss: 2.1861399578791794

Epoch: 5| Step: 9
Training loss: 2.7615890502929688
Validation loss: 2.207399470831758

Epoch: 5| Step: 10
Training loss: 2.5858592987060547
Validation loss: 2.202361329909294

Epoch: 98| Step: 0
Training loss: 2.497037887573242
Validation loss: 2.208422096826697

Epoch: 5| Step: 1
Training loss: 2.389374017715454
Validation loss: 2.202392108978764

Epoch: 5| Step: 2
Training loss: 2.4789326190948486
Validation loss: 2.234105061459285

Epoch: 5| Step: 3
Training loss: 2.434399127960205
Validation loss: 2.230530772157895

Epoch: 5| Step: 4
Training loss: 2.6079280376434326
Validation loss: 2.2204816854128273

Epoch: 5| Step: 5
Training loss: 2.1517586708068848
Validation loss: 2.189368591513685

Epoch: 5| Step: 6
Training loss: 2.515848159790039
Validation loss: 2.1884421994609218

Epoch: 5| Step: 7
Training loss: 2.8156867027282715
Validation loss: 2.19667068348136

Epoch: 5| Step: 8
Training loss: 2.3083207607269287
Validation loss: 2.1856767772346415

Epoch: 5| Step: 9
Training loss: 1.891318678855896
Validation loss: 2.170416506387854

Epoch: 5| Step: 10
Training loss: 1.9772015810012817
Validation loss: 2.1525195311474543

Epoch: 99| Step: 0
Training loss: 2.061229705810547
Validation loss: 2.1368850815680718

Epoch: 5| Step: 1
Training loss: 1.7880303859710693
Validation loss: 2.1338195134234685

Epoch: 5| Step: 2
Training loss: 2.4783692359924316
Validation loss: 2.142910558690307

Epoch: 5| Step: 3
Training loss: 2.4895129203796387
Validation loss: 2.153297355098109

Epoch: 5| Step: 4
Training loss: 3.235008716583252
Validation loss: 2.1668464752935592

Epoch: 5| Step: 5
Training loss: 1.9202134609222412
Validation loss: 2.157550001657137

Epoch: 5| Step: 6
Training loss: 2.050633430480957
Validation loss: 2.1634622594361663

Epoch: 5| Step: 7
Training loss: 2.456021785736084
Validation loss: 2.168137901572771

Epoch: 5| Step: 8
Training loss: 2.640228748321533
Validation loss: 2.1815218720384824

Epoch: 5| Step: 9
Training loss: 3.02605938911438
Validation loss: 2.233519110628354

Epoch: 5| Step: 10
Training loss: 1.9536808729171753
Validation loss: 2.2648241020018056

Epoch: 100| Step: 0
Training loss: 2.5801665782928467
Validation loss: 2.2785360633686023

Epoch: 5| Step: 1
Training loss: 1.4941003322601318
Validation loss: 2.290251531908589

Epoch: 5| Step: 2
Training loss: 2.8815228939056396
Validation loss: 2.3131226211465816

Epoch: 5| Step: 3
Training loss: 2.6169254779815674
Validation loss: 2.3117356941264164

Epoch: 5| Step: 4
Training loss: 1.9715826511383057
Validation loss: 2.3384999664880897

Epoch: 5| Step: 5
Training loss: 2.9335620403289795
Validation loss: 2.366998255893748

Epoch: 5| Step: 6
Training loss: 2.9845147132873535
Validation loss: 2.3196579820366314

Epoch: 5| Step: 7
Training loss: 2.0399222373962402
Validation loss: 2.2719893122232087

Epoch: 5| Step: 8
Training loss: 2.483872890472412
Validation loss: 2.236016276062176

Epoch: 5| Step: 9
Training loss: 2.1607043743133545
Validation loss: 2.209480554826798

Epoch: 5| Step: 10
Training loss: 2.5919182300567627
Validation loss: 2.171546395106982

Epoch: 101| Step: 0
Training loss: 2.542046546936035
Validation loss: 2.1537742589109685

Epoch: 5| Step: 1
Training loss: 2.4332642555236816
Validation loss: 2.125258538030809

Epoch: 5| Step: 2
Training loss: 1.8967682123184204
Validation loss: 2.1260519489165275

Epoch: 5| Step: 3
Training loss: 2.56126070022583
Validation loss: 2.127893158184585

Epoch: 5| Step: 4
Training loss: 2.26550030708313
Validation loss: 2.1394126133252214

Epoch: 5| Step: 5
Training loss: 3.071932077407837
Validation loss: 2.1605671157119093

Epoch: 5| Step: 6
Training loss: 2.4106550216674805
Validation loss: 2.1911477222237536

Epoch: 5| Step: 7
Training loss: 2.3090970516204834
Validation loss: 2.1540669805260113

Epoch: 5| Step: 8
Training loss: 2.055358648300171
Validation loss: 2.1268617081385788

Epoch: 5| Step: 9
Training loss: 1.883069634437561
Validation loss: 2.1109866890856015

Epoch: 5| Step: 10
Training loss: 2.6509830951690674
Validation loss: 2.098666492328849

Epoch: 102| Step: 0
Training loss: 2.597144365310669
Validation loss: 2.098337309334868

Epoch: 5| Step: 1
Training loss: 1.753273367881775
Validation loss: 2.1006409891190065

Epoch: 5| Step: 2
Training loss: 2.381195306777954
Validation loss: 2.10131751337359

Epoch: 5| Step: 3
Training loss: 2.709876298904419
Validation loss: 2.1149232759270618

Epoch: 5| Step: 4
Training loss: 2.1654038429260254
Validation loss: 2.122795622835877

Epoch: 5| Step: 5
Training loss: 2.142768383026123
Validation loss: 2.127168668213711

Epoch: 5| Step: 6
Training loss: 2.930501937866211
Validation loss: 2.1526728573665825

Epoch: 5| Step: 7
Training loss: 2.050267219543457
Validation loss: 2.170176831624841

Epoch: 5| Step: 8
Training loss: 2.8186302185058594
Validation loss: 2.1729514239936747

Epoch: 5| Step: 9
Training loss: 2.290724992752075
Validation loss: 2.175465473564722

Epoch: 5| Step: 10
Training loss: 2.136481761932373
Validation loss: 2.1562570038662163

Epoch: 103| Step: 0
Training loss: 2.421229839324951
Validation loss: 2.1512769063313804

Epoch: 5| Step: 1
Training loss: 2.5668201446533203
Validation loss: 2.1652246341910413

Epoch: 5| Step: 2
Training loss: 2.7983672618865967
Validation loss: 2.1834118661060127

Epoch: 5| Step: 3
Training loss: 2.7693734169006348
Validation loss: 2.2004870624952417

Epoch: 5| Step: 4
Training loss: 2.1322102546691895
Validation loss: 2.188506926259687

Epoch: 5| Step: 5
Training loss: 1.5761338472366333
Validation loss: 2.185211653350502

Epoch: 5| Step: 6
Training loss: 2.8951194286346436
Validation loss: 2.177591070052116

Epoch: 5| Step: 7
Training loss: 2.1176681518554688
Validation loss: 2.164476251089445

Epoch: 5| Step: 8
Training loss: 2.178105354309082
Validation loss: 2.1639600902475338

Epoch: 5| Step: 9
Training loss: 2.005673885345459
Validation loss: 2.2077905657470867

Epoch: 5| Step: 10
Training loss: 2.7602286338806152
Validation loss: 2.227312772504745

Epoch: 104| Step: 0
Training loss: 2.5085272789001465
Validation loss: 2.1803675672059417

Epoch: 5| Step: 1
Training loss: 2.0429494380950928
Validation loss: 2.149347628316572

Epoch: 5| Step: 2
Training loss: 2.2059030532836914
Validation loss: 2.1419846268110376

Epoch: 5| Step: 3
Training loss: 2.2283711433410645
Validation loss: 2.1512414409268286

Epoch: 5| Step: 4
Training loss: 1.8820708990097046
Validation loss: 2.1642892194050614

Epoch: 5| Step: 5
Training loss: 1.8982642889022827
Validation loss: 2.1589272278611378

Epoch: 5| Step: 6
Training loss: 2.692018985748291
Validation loss: 2.1412620185523905

Epoch: 5| Step: 7
Training loss: 2.8800673484802246
Validation loss: 2.1183082493402625

Epoch: 5| Step: 8
Training loss: 2.6893091201782227
Validation loss: 2.1217447096301663

Epoch: 5| Step: 9
Training loss: 2.660817861557007
Validation loss: 2.1257356546258412

Epoch: 5| Step: 10
Training loss: 1.8221678733825684
Validation loss: 2.1267372049311155

Epoch: 105| Step: 0
Training loss: 2.6727964878082275
Validation loss: 2.1284322995011524

Epoch: 5| Step: 1
Training loss: 2.1825544834136963
Validation loss: 2.140269611471443

Epoch: 5| Step: 2
Training loss: 1.8295282125473022
Validation loss: 2.1327220419401764

Epoch: 5| Step: 3
Training loss: 2.4958853721618652
Validation loss: 2.125049650028188

Epoch: 5| Step: 4
Training loss: 2.752800464630127
Validation loss: 2.130438676444433

Epoch: 5| Step: 5
Training loss: 2.1444411277770996
Validation loss: 2.1409615342335035

Epoch: 5| Step: 6
Training loss: 1.5554556846618652
Validation loss: 2.14018750703463

Epoch: 5| Step: 7
Training loss: 2.4511356353759766
Validation loss: 2.136084601443301

Epoch: 5| Step: 8
Training loss: 1.9516735076904297
Validation loss: 2.142565058123681

Epoch: 5| Step: 9
Training loss: 2.9799721240997314
Validation loss: 2.161932381250525

Epoch: 5| Step: 10
Training loss: 2.2702598571777344
Validation loss: 2.1494271678309285

Epoch: 106| Step: 0
Training loss: 2.8800318241119385
Validation loss: 2.1272157802376697

Epoch: 5| Step: 1
Training loss: 3.0162432193756104
Validation loss: 2.146274002649451

Epoch: 5| Step: 2
Training loss: 1.9369785785675049
Validation loss: 2.1802742635050127

Epoch: 5| Step: 3
Training loss: 1.6836620569229126
Validation loss: 2.192907048809913

Epoch: 5| Step: 4
Training loss: 2.3603146076202393
Validation loss: 2.1909567873965026

Epoch: 5| Step: 5
Training loss: 2.8520045280456543
Validation loss: 2.16817488977986

Epoch: 5| Step: 6
Training loss: 2.783620595932007
Validation loss: 2.1454826170398342

Epoch: 5| Step: 7
Training loss: 1.8547194004058838
Validation loss: 2.118975877761841

Epoch: 5| Step: 8
Training loss: 1.6460040807724
Validation loss: 2.111643324616135

Epoch: 5| Step: 9
Training loss: 2.313404083251953
Validation loss: 2.1275972550915134

Epoch: 5| Step: 10
Training loss: 2.4146080017089844
Validation loss: 2.149555270389844

Epoch: 107| Step: 0
Training loss: 1.9346752166748047
Validation loss: 2.160240700167994

Epoch: 5| Step: 1
Training loss: 2.6382718086242676
Validation loss: 2.181315291312433

Epoch: 5| Step: 2
Training loss: 2.2160484790802
Validation loss: 2.1833660051386845

Epoch: 5| Step: 3
Training loss: 2.178356647491455
Validation loss: 2.1988872635749077

Epoch: 5| Step: 4
Training loss: 2.569566249847412
Validation loss: 2.1987414154955136

Epoch: 5| Step: 5
Training loss: 2.2460947036743164
Validation loss: 2.1921348930687032

Epoch: 5| Step: 6
Training loss: 2.5964536666870117
Validation loss: 2.1648075016595985

Epoch: 5| Step: 7
Training loss: 2.350245714187622
Validation loss: 2.155350236482518

Epoch: 5| Step: 8
Training loss: 2.850287914276123
Validation loss: 2.1416727650550103

Epoch: 5| Step: 9
Training loss: 2.328425168991089
Validation loss: 2.1257379952297417

Epoch: 5| Step: 10
Training loss: 1.778411626815796
Validation loss: 2.1130313847654607

Epoch: 108| Step: 0
Training loss: 2.0012662410736084
Validation loss: 2.099416994279431

Epoch: 5| Step: 1
Training loss: 1.9068410396575928
Validation loss: 2.1044634926703667

Epoch: 5| Step: 2
Training loss: 2.767383098602295
Validation loss: 2.103543440500895

Epoch: 5| Step: 3
Training loss: 2.053800582885742
Validation loss: 2.087268649890859

Epoch: 5| Step: 4
Training loss: 2.314666509628296
Validation loss: 2.084807377989574

Epoch: 5| Step: 5
Training loss: 2.7435765266418457
Validation loss: 2.0913612791287

Epoch: 5| Step: 6
Training loss: 2.058258295059204
Validation loss: 2.0923905731529318

Epoch: 5| Step: 7
Training loss: 2.5754973888397217
Validation loss: 2.0903424037400113

Epoch: 5| Step: 8
Training loss: 2.6301097869873047
Validation loss: 2.0933138606368855

Epoch: 5| Step: 9
Training loss: 2.3431107997894287
Validation loss: 2.086874626016104

Epoch: 5| Step: 10
Training loss: 2.0015320777893066
Validation loss: 2.0783577426787345

Epoch: 109| Step: 0
Training loss: 2.205000162124634
Validation loss: 2.0676464675575175

Epoch: 5| Step: 1
Training loss: 2.1045730113983154
Validation loss: 2.0659502795947495

Epoch: 5| Step: 2
Training loss: 2.5301272869110107
Validation loss: 2.0815161197416243

Epoch: 5| Step: 3
Training loss: 2.1580185890197754
Validation loss: 2.081765946521554

Epoch: 5| Step: 4
Training loss: 2.1256957054138184
Validation loss: 2.095336637189311

Epoch: 5| Step: 5
Training loss: 2.4657773971557617
Validation loss: 2.08061679076123

Epoch: 5| Step: 6
Training loss: 2.6432695388793945
Validation loss: 2.072797647086523

Epoch: 5| Step: 7
Training loss: 2.6477739810943604
Validation loss: 2.0600351697655133

Epoch: 5| Step: 8
Training loss: 2.7842698097229004
Validation loss: 2.0495311931897233

Epoch: 5| Step: 9
Training loss: 1.8847812414169312
Validation loss: 2.0539387015886206

Epoch: 5| Step: 10
Training loss: 1.7581589221954346
Validation loss: 2.05111885839893

Epoch: 110| Step: 0
Training loss: 2.8263497352600098
Validation loss: 2.057949222544188

Epoch: 5| Step: 1
Training loss: 2.023832082748413
Validation loss: 2.0728605819004837

Epoch: 5| Step: 2
Training loss: 2.5177974700927734
Validation loss: 2.0742520183645268

Epoch: 5| Step: 3
Training loss: 2.7502522468566895
Validation loss: 2.0878658781769457

Epoch: 5| Step: 4
Training loss: 1.8486988544464111
Validation loss: 2.0895166166367067

Epoch: 5| Step: 5
Training loss: 2.0959157943725586
Validation loss: 2.102703103455164

Epoch: 5| Step: 6
Training loss: 1.7302589416503906
Validation loss: 2.115240555937572

Epoch: 5| Step: 7
Training loss: 2.062091588973999
Validation loss: 2.144338816724798

Epoch: 5| Step: 8
Training loss: 2.347806215286255
Validation loss: 2.1540597946413103

Epoch: 5| Step: 9
Training loss: 2.739628314971924
Validation loss: 2.1592506285636657

Epoch: 5| Step: 10
Training loss: 2.0986452102661133
Validation loss: 2.1551920188370572

Epoch: 111| Step: 0
Training loss: 2.149606227874756
Validation loss: 2.1599127361851354

Epoch: 5| Step: 1
Training loss: 2.8458187580108643
Validation loss: 2.1689261774862967

Epoch: 5| Step: 2
Training loss: 1.8153164386749268
Validation loss: 2.1811297914033294

Epoch: 5| Step: 3
Training loss: 2.0531744956970215
Validation loss: 2.185010793388531

Epoch: 5| Step: 4
Training loss: 2.181767702102661
Validation loss: 2.1542920374101207

Epoch: 5| Step: 5
Training loss: 2.3360416889190674
Validation loss: 2.150834943658562

Epoch: 5| Step: 6
Training loss: 3.2108700275421143
Validation loss: 2.134903218156548

Epoch: 5| Step: 7
Training loss: 1.5439088344573975
Validation loss: 2.120404420360442

Epoch: 5| Step: 8
Training loss: 2.885517120361328
Validation loss: 2.1148028706991546

Epoch: 5| Step: 9
Training loss: 1.62991201877594
Validation loss: 2.1258911189212593

Epoch: 5| Step: 10
Training loss: 2.740312337875366
Validation loss: 2.120905509559057

Epoch: 112| Step: 0
Training loss: 2.2265994548797607
Validation loss: 2.0966509901067263

Epoch: 5| Step: 1
Training loss: 1.7013107538223267
Validation loss: 2.085832726570868

Epoch: 5| Step: 2
Training loss: 2.6381702423095703
Validation loss: 2.0805817906574537

Epoch: 5| Step: 3
Training loss: 3.017613172531128
Validation loss: 2.065250104473483

Epoch: 5| Step: 4
Training loss: 1.8720743656158447
Validation loss: 2.071950570229561

Epoch: 5| Step: 5
Training loss: 2.2598204612731934
Validation loss: 2.0705241592981483

Epoch: 5| Step: 6
Training loss: 1.8832019567489624
Validation loss: 2.079971605731595

Epoch: 5| Step: 7
Training loss: 2.4355080127716064
Validation loss: 2.081376316726849

Epoch: 5| Step: 8
Training loss: 1.9579944610595703
Validation loss: 2.0696263749112367

Epoch: 5| Step: 9
Training loss: 2.370004653930664
Validation loss: 2.0837331856450727

Epoch: 5| Step: 10
Training loss: 2.7797532081604004
Validation loss: 2.0875621034253027

Epoch: 113| Step: 0
Training loss: 2.1412079334259033
Validation loss: 2.104830721373199

Epoch: 5| Step: 1
Training loss: 1.7667299509048462
Validation loss: 2.1064400826731036

Epoch: 5| Step: 2
Training loss: 1.9288148880004883
Validation loss: 2.1026623659236456

Epoch: 5| Step: 3
Training loss: 2.7356181144714355
Validation loss: 2.0932292463958904

Epoch: 5| Step: 4
Training loss: 2.4543282985687256
Validation loss: 2.0866250299638316

Epoch: 5| Step: 5
Training loss: 2.4333555698394775
Validation loss: 2.0835508992595058

Epoch: 5| Step: 6
Training loss: 2.1865739822387695
Validation loss: 2.0811730610427035

Epoch: 5| Step: 7
Training loss: 2.147735595703125
Validation loss: 2.075522626599958

Epoch: 5| Step: 8
Training loss: 2.5906848907470703
Validation loss: 2.070980123294297

Epoch: 5| Step: 9
Training loss: 2.5529067516326904
Validation loss: 2.068490487273021

Epoch: 5| Step: 10
Training loss: 1.8201817274093628
Validation loss: 2.0741989112669423

Epoch: 114| Step: 0
Training loss: 2.037208080291748
Validation loss: 2.0886667287477882

Epoch: 5| Step: 1
Training loss: 2.5797388553619385
Validation loss: 2.086419592621506

Epoch: 5| Step: 2
Training loss: 2.1176276206970215
Validation loss: 2.072574254005186

Epoch: 5| Step: 3
Training loss: 2.7143378257751465
Validation loss: 2.0675265763395574

Epoch: 5| Step: 4
Training loss: 2.2878506183624268
Validation loss: 2.07256721040254

Epoch: 5| Step: 5
Training loss: 2.462913751602173
Validation loss: 2.0836276264600855

Epoch: 5| Step: 6
Training loss: 2.332663059234619
Validation loss: 2.090197229898104

Epoch: 5| Step: 7
Training loss: 2.262413740158081
Validation loss: 2.0775024788354033

Epoch: 5| Step: 8
Training loss: 1.8837049007415771
Validation loss: 2.0621894008369854

Epoch: 5| Step: 9
Training loss: 1.9984378814697266
Validation loss: 2.047570877177741

Epoch: 5| Step: 10
Training loss: 2.1544723510742188
Validation loss: 2.036333783980339

Epoch: 115| Step: 0
Training loss: 2.3355154991149902
Validation loss: 2.0363951857371996

Epoch: 5| Step: 1
Training loss: 1.8008086681365967
Validation loss: 2.047274395983706

Epoch: 5| Step: 2
Training loss: 2.638158082962036
Validation loss: 2.043384830156962

Epoch: 5| Step: 3
Training loss: 2.416823387145996
Validation loss: 2.0446527440060853

Epoch: 5| Step: 4
Training loss: 2.0727858543395996
Validation loss: 2.050999541436472

Epoch: 5| Step: 5
Training loss: 1.9040180444717407
Validation loss: 2.054261022998441

Epoch: 5| Step: 6
Training loss: 2.3169782161712646
Validation loss: 2.047065273407967

Epoch: 5| Step: 7
Training loss: 2.139742851257324
Validation loss: 2.0492169164842173

Epoch: 5| Step: 8
Training loss: 1.931117057800293
Validation loss: 2.0543572812952022

Epoch: 5| Step: 9
Training loss: 2.7101993560791016
Validation loss: 2.069256838931832

Epoch: 5| Step: 10
Training loss: 2.3016903400421143
Validation loss: 2.0823476417090303

Epoch: 116| Step: 0
Training loss: 2.701129674911499
Validation loss: 2.102788309897146

Epoch: 5| Step: 1
Training loss: 1.8529884815216064
Validation loss: 2.1254503829504854

Epoch: 5| Step: 2
Training loss: 2.4967939853668213
Validation loss: 2.1473206602117068

Epoch: 5| Step: 3
Training loss: 1.6369297504425049
Validation loss: 2.1285496745058285

Epoch: 5| Step: 4
Training loss: 2.5863022804260254
Validation loss: 2.168571690077423

Epoch: 5| Step: 5
Training loss: 1.9065656661987305
Validation loss: 2.213183423524262

Epoch: 5| Step: 6
Training loss: 2.5562400817871094
Validation loss: 2.159359093635313

Epoch: 5| Step: 7
Training loss: 2.1704020500183105
Validation loss: 2.0908831140046478

Epoch: 5| Step: 8
Training loss: 2.1041805744171143
Validation loss: 2.0651034616654917

Epoch: 5| Step: 9
Training loss: 2.2938742637634277
Validation loss: 2.049609604702201

Epoch: 5| Step: 10
Training loss: 2.493318557739258
Validation loss: 2.043026139659266

Epoch: 117| Step: 0
Training loss: 2.216803789138794
Validation loss: 2.033412459076092

Epoch: 5| Step: 1
Training loss: 1.9924272298812866
Validation loss: 2.039948715958544

Epoch: 5| Step: 2
Training loss: 1.8451446294784546
Validation loss: 2.0396706583679363

Epoch: 5| Step: 3
Training loss: 2.7562756538391113
Validation loss: 2.031975938427833

Epoch: 5| Step: 4
Training loss: 2.3582777976989746
Validation loss: 2.0409695743232645

Epoch: 5| Step: 5
Training loss: 2.3079307079315186
Validation loss: 2.041785381173575

Epoch: 5| Step: 6
Training loss: 2.650669574737549
Validation loss: 2.0554881313795685

Epoch: 5| Step: 7
Training loss: 2.397071361541748
Validation loss: 2.062287261409144

Epoch: 5| Step: 8
Training loss: 1.9481080770492554
Validation loss: 2.0717088330176567

Epoch: 5| Step: 9
Training loss: 2.119969606399536
Validation loss: 2.077961447418377

Epoch: 5| Step: 10
Training loss: 2.0178592205047607
Validation loss: 2.0849313146324566

Epoch: 118| Step: 0
Training loss: 2.5265557765960693
Validation loss: 2.0824020447269564

Epoch: 5| Step: 1
Training loss: 2.382796049118042
Validation loss: 2.0792447008112425

Epoch: 5| Step: 2
Training loss: 1.6777912378311157
Validation loss: 2.0773783537649337

Epoch: 5| Step: 3
Training loss: 2.818647861480713
Validation loss: 2.0827430602042907

Epoch: 5| Step: 4
Training loss: 2.9359631538391113
Validation loss: 2.0735815289199993

Epoch: 5| Step: 5
Training loss: 1.6919009685516357
Validation loss: 2.0786980480276127

Epoch: 5| Step: 6
Training loss: 2.7016537189483643
Validation loss: 2.0731500438464585

Epoch: 5| Step: 7
Training loss: 2.2077341079711914
Validation loss: 2.05041511853536

Epoch: 5| Step: 8
Training loss: 1.68451726436615
Validation loss: 2.0501630665153585

Epoch: 5| Step: 9
Training loss: 1.7171878814697266
Validation loss: 2.07227171621015

Epoch: 5| Step: 10
Training loss: 2.0126733779907227
Validation loss: 2.0542718851438133

Epoch: 119| Step: 0
Training loss: 2.495527505874634
Validation loss: 2.0534050054447626

Epoch: 5| Step: 1
Training loss: 2.0909805297851562
Validation loss: 2.071489349488289

Epoch: 5| Step: 2
Training loss: 2.2955732345581055
Validation loss: 2.0707197676422777

Epoch: 5| Step: 3
Training loss: 2.105966806411743
Validation loss: 2.0853605757477465

Epoch: 5| Step: 4
Training loss: 2.7015249729156494
Validation loss: 2.0868891490403043

Epoch: 5| Step: 5
Training loss: 1.940542221069336
Validation loss: 2.0906546526057745

Epoch: 5| Step: 6
Training loss: 2.1921701431274414
Validation loss: 2.0994507138447096

Epoch: 5| Step: 7
Training loss: 2.1389803886413574
Validation loss: 2.083952444855885

Epoch: 5| Step: 8
Training loss: 2.4227724075317383
Validation loss: 2.081992477499029

Epoch: 5| Step: 9
Training loss: 1.8496071100234985
Validation loss: 2.078899973182268

Epoch: 5| Step: 10
Training loss: 1.9431123733520508
Validation loss: 2.0786836416490617

Epoch: 120| Step: 0
Training loss: 2.5948848724365234
Validation loss: 2.1066386507403467

Epoch: 5| Step: 1
Training loss: 2.119192123413086
Validation loss: 2.1069658725492415

Epoch: 5| Step: 2
Training loss: 2.033034324645996
Validation loss: 2.130679386918263

Epoch: 5| Step: 3
Training loss: 2.4266486167907715
Validation loss: 2.0992767580093874

Epoch: 5| Step: 4
Training loss: 2.518847703933716
Validation loss: 2.0792058360192085

Epoch: 5| Step: 5
Training loss: 1.6789458990097046
Validation loss: 2.0700458506102204

Epoch: 5| Step: 6
Training loss: 2.219475746154785
Validation loss: 2.075685513916836

Epoch: 5| Step: 7
Training loss: 2.3944449424743652
Validation loss: 2.061865314360588

Epoch: 5| Step: 8
Training loss: 1.8334636688232422
Validation loss: 2.0660278592058408

Epoch: 5| Step: 9
Training loss: 2.053781509399414
Validation loss: 2.0871109859917754

Epoch: 5| Step: 10
Training loss: 2.4656615257263184
Validation loss: 2.08613464396487

Epoch: 121| Step: 0
Training loss: 2.7118115425109863
Validation loss: 2.084408406288393

Epoch: 5| Step: 1
Training loss: 1.8045995235443115
Validation loss: 2.0754001807141047

Epoch: 5| Step: 2
Training loss: 1.7472021579742432
Validation loss: 2.0762919456728044

Epoch: 5| Step: 3
Training loss: 2.7172203063964844
Validation loss: 2.098943643672492

Epoch: 5| Step: 4
Training loss: 1.898332953453064
Validation loss: 2.097508336908074

Epoch: 5| Step: 5
Training loss: 2.021521806716919
Validation loss: 2.0962888399759927

Epoch: 5| Step: 6
Training loss: 2.529242515563965
Validation loss: 2.108454899121356

Epoch: 5| Step: 7
Training loss: 2.2519850730895996
Validation loss: 2.112626455163443

Epoch: 5| Step: 8
Training loss: 2.135916233062744
Validation loss: 2.1040280634357083

Epoch: 5| Step: 9
Training loss: 2.454660654067993
Validation loss: 2.109178614872758

Epoch: 5| Step: 10
Training loss: 1.8004231452941895
Validation loss: 2.095348519663657

Epoch: 122| Step: 0
Training loss: 2.9010891914367676
Validation loss: 2.0775725200612056

Epoch: 5| Step: 1
Training loss: 1.8483282327651978
Validation loss: 2.075134984908565

Epoch: 5| Step: 2
Training loss: 2.1566033363342285
Validation loss: 2.0913983211722424

Epoch: 5| Step: 3
Training loss: 1.5783241987228394
Validation loss: 2.097667771001016

Epoch: 5| Step: 4
Training loss: 2.6121983528137207
Validation loss: 2.1048595854031142

Epoch: 5| Step: 5
Training loss: 2.2118124961853027
Validation loss: 2.1102318661187285

Epoch: 5| Step: 6
Training loss: 2.0229268074035645
Validation loss: 2.1126789405781734

Epoch: 5| Step: 7
Training loss: 1.894805669784546
Validation loss: 2.116187963434445

Epoch: 5| Step: 8
Training loss: 1.9802436828613281
Validation loss: 2.123940654980239

Epoch: 5| Step: 9
Training loss: 2.7334210872650146
Validation loss: 2.1331918521593978

Epoch: 5| Step: 10
Training loss: 2.2744808197021484
Validation loss: 2.1504104906512844

Epoch: 123| Step: 0
Training loss: 1.8471444845199585
Validation loss: 2.158156596204286

Epoch: 5| Step: 1
Training loss: 2.2925126552581787
Validation loss: 2.1724783656417683

Epoch: 5| Step: 2
Training loss: 2.292715072631836
Validation loss: 2.1798147719393492

Epoch: 5| Step: 3
Training loss: 2.315519094467163
Validation loss: 2.1491783459981284

Epoch: 5| Step: 4
Training loss: 2.533078670501709
Validation loss: 2.09929762348052

Epoch: 5| Step: 5
Training loss: 1.4153059720993042
Validation loss: 2.090470793426678

Epoch: 5| Step: 6
Training loss: 1.8862282037734985
Validation loss: 2.093865768883818

Epoch: 5| Step: 7
Training loss: 2.4126956462860107
Validation loss: 2.091928978120127

Epoch: 5| Step: 8
Training loss: 2.5046658515930176
Validation loss: 2.0891002326883297

Epoch: 5| Step: 9
Training loss: 2.2436206340789795
Validation loss: 2.0788071181184504

Epoch: 5| Step: 10
Training loss: 2.5235962867736816
Validation loss: 2.0748746830929994

Epoch: 124| Step: 0
Training loss: 2.62986159324646
Validation loss: 2.0970579270393617

Epoch: 5| Step: 1
Training loss: 2.2091195583343506
Validation loss: 2.120835740079162

Epoch: 5| Step: 2
Training loss: 2.3894295692443848
Validation loss: 2.1502304179694063

Epoch: 5| Step: 3
Training loss: 2.265477180480957
Validation loss: 2.1655043158479916

Epoch: 5| Step: 4
Training loss: 1.6304004192352295
Validation loss: 2.1355692135390414

Epoch: 5| Step: 5
Training loss: 1.4733798503875732
Validation loss: 2.103461583455404

Epoch: 5| Step: 6
Training loss: 2.0988969802856445
Validation loss: 2.0920287127135904

Epoch: 5| Step: 7
Training loss: 2.2731833457946777
Validation loss: 2.071767886479696

Epoch: 5| Step: 8
Training loss: 2.4325122833251953
Validation loss: 2.057346938758768

Epoch: 5| Step: 9
Training loss: 2.232795238494873
Validation loss: 2.0814114834672663

Epoch: 5| Step: 10
Training loss: 2.8237321376800537
Validation loss: 2.0978399425424556

Epoch: 125| Step: 0
Training loss: 2.5822319984436035
Validation loss: 2.1021373579579015

Epoch: 5| Step: 1
Training loss: 2.2793517112731934
Validation loss: 2.113147750977547

Epoch: 5| Step: 2
Training loss: 2.4818649291992188
Validation loss: 2.105973833350725

Epoch: 5| Step: 3
Training loss: 2.5094897747039795
Validation loss: 2.115333536619781

Epoch: 5| Step: 4
Training loss: 2.000910520553589
Validation loss: 2.0994692169209963

Epoch: 5| Step: 5
Training loss: 2.3707435131073
Validation loss: 2.093528042557419

Epoch: 5| Step: 6
Training loss: 2.4838969707489014
Validation loss: 2.103011541469123

Epoch: 5| Step: 7
Training loss: 1.8344943523406982
Validation loss: 2.1073953643921883

Epoch: 5| Step: 8
Training loss: 1.804391622543335
Validation loss: 2.131966402453761

Epoch: 5| Step: 9
Training loss: 2.1297667026519775
Validation loss: 2.1453068743469896

Epoch: 5| Step: 10
Training loss: 1.5481141805648804
Validation loss: 2.148031614160025

Epoch: 126| Step: 0
Training loss: 2.253175735473633
Validation loss: 2.136007639669603

Epoch: 5| Step: 1
Training loss: 2.188373565673828
Validation loss: 2.1092824295002925

Epoch: 5| Step: 2
Training loss: 1.4737519025802612
Validation loss: 2.0922023352756294

Epoch: 5| Step: 3
Training loss: 2.7677831649780273
Validation loss: 2.086909455637778

Epoch: 5| Step: 4
Training loss: 2.3359344005584717
Validation loss: 2.070149326837191

Epoch: 5| Step: 5
Training loss: 1.8353271484375
Validation loss: 2.0752597983165453

Epoch: 5| Step: 6
Training loss: 2.221802234649658
Validation loss: 2.0754834631437897

Epoch: 5| Step: 7
Training loss: 2.0565922260284424
Validation loss: 2.0714022574886197

Epoch: 5| Step: 8
Training loss: 2.4144885540008545
Validation loss: 2.0853395359490507

Epoch: 5| Step: 9
Training loss: 2.120637893676758
Validation loss: 2.0771187684869252

Epoch: 5| Step: 10
Training loss: 2.3020312786102295
Validation loss: 2.079642623983404

Epoch: 127| Step: 0
Training loss: 2.1794984340667725
Validation loss: 2.0829479207274733

Epoch: 5| Step: 1
Training loss: 2.1883273124694824
Validation loss: 2.1079452191629717

Epoch: 5| Step: 2
Training loss: 2.9346280097961426
Validation loss: 2.152002837068291

Epoch: 5| Step: 3
Training loss: 2.4683661460876465
Validation loss: 2.185711233846603

Epoch: 5| Step: 4
Training loss: 1.9674122333526611
Validation loss: 2.1906343890774633

Epoch: 5| Step: 5
Training loss: 1.369001030921936
Validation loss: 2.2020618518193564

Epoch: 5| Step: 6
Training loss: 2.631777286529541
Validation loss: 2.1483152425417336

Epoch: 5| Step: 7
Training loss: 2.2123968601226807
Validation loss: 2.108122553876651

Epoch: 5| Step: 8
Training loss: 2.1544735431671143
Validation loss: 2.081394480120751

Epoch: 5| Step: 9
Training loss: 2.0285725593566895
Validation loss: 2.076233612593784

Epoch: 5| Step: 10
Training loss: 1.6373021602630615
Validation loss: 2.0593726211978542

Epoch: 128| Step: 0
Training loss: 2.3387045860290527
Validation loss: 2.0623915426192747

Epoch: 5| Step: 1
Training loss: 2.6961803436279297
Validation loss: 2.0491317215786187

Epoch: 5| Step: 2
Training loss: 2.003338575363159
Validation loss: 2.049531759754304

Epoch: 5| Step: 3
Training loss: 2.639657735824585
Validation loss: 2.062481810969691

Epoch: 5| Step: 4
Training loss: 1.2181133031845093
Validation loss: 2.0731407083490843

Epoch: 5| Step: 5
Training loss: 1.487313985824585
Validation loss: 2.074016732554282

Epoch: 5| Step: 6
Training loss: 2.4669413566589355
Validation loss: 2.076836029688517

Epoch: 5| Step: 7
Training loss: 1.7472156286239624
Validation loss: 2.0834248450494584

Epoch: 5| Step: 8
Training loss: 1.7683372497558594
Validation loss: 2.0884051733119513

Epoch: 5| Step: 9
Training loss: 2.84012770652771
Validation loss: 2.1076086298111947

Epoch: 5| Step: 10
Training loss: 2.0650172233581543
Validation loss: 2.098886764177712

Epoch: 129| Step: 0
Training loss: 1.8092998266220093
Validation loss: 2.0968031960148967

Epoch: 5| Step: 1
Training loss: 2.3129639625549316
Validation loss: 2.101660792545606

Epoch: 5| Step: 2
Training loss: 1.9978549480438232
Validation loss: 2.0960316760565645

Epoch: 5| Step: 3
Training loss: 2.202674150466919
Validation loss: 2.11327834539516

Epoch: 5| Step: 4
Training loss: 2.052666187286377
Validation loss: 2.1165783789850052

Epoch: 5| Step: 5
Training loss: 2.1792874336242676
Validation loss: 2.1182301800738097

Epoch: 5| Step: 6
Training loss: 2.6398019790649414
Validation loss: 2.0829392274220786

Epoch: 5| Step: 7
Training loss: 2.3544507026672363
Validation loss: 2.0830159392408145

Epoch: 5| Step: 8
Training loss: 2.086341619491577
Validation loss: 2.0708646107745428

Epoch: 5| Step: 9
Training loss: 1.9164867401123047
Validation loss: 2.0637031332139046

Epoch: 5| Step: 10
Training loss: 2.174701452255249
Validation loss: 2.041135549545288

Epoch: 130| Step: 0
Training loss: 2.0026321411132812
Validation loss: 2.0349121837205786

Epoch: 5| Step: 1
Training loss: 2.3604745864868164
Validation loss: 2.0233532433868735

Epoch: 5| Step: 2
Training loss: 2.3881373405456543
Validation loss: 2.0240194925697903

Epoch: 5| Step: 3
Training loss: 1.8705461025238037
Validation loss: 2.015602083616359

Epoch: 5| Step: 4
Training loss: 1.9752575159072876
Validation loss: 2.0338374812115907

Epoch: 5| Step: 5
Training loss: 2.108097791671753
Validation loss: 2.043816348557831

Epoch: 5| Step: 6
Training loss: 2.6258931159973145
Validation loss: 2.045068948499618

Epoch: 5| Step: 7
Training loss: 1.9511585235595703
Validation loss: 2.0607109736370783

Epoch: 5| Step: 8
Training loss: 2.6194300651550293
Validation loss: 2.077529545753233

Epoch: 5| Step: 9
Training loss: 1.802771806716919
Validation loss: 2.089190726639122

Epoch: 5| Step: 10
Training loss: 2.142118215560913
Validation loss: 2.0802850005447224

Epoch: 131| Step: 0
Training loss: 2.6230361461639404
Validation loss: 2.080760743028374

Epoch: 5| Step: 1
Training loss: 1.5806543827056885
Validation loss: 2.104885034663703

Epoch: 5| Step: 2
Training loss: 2.241347312927246
Validation loss: 2.0997571124825427

Epoch: 5| Step: 3
Training loss: 1.8731399774551392
Validation loss: 2.0979062921257428

Epoch: 5| Step: 4
Training loss: 2.442941904067993
Validation loss: 2.0874751972895798

Epoch: 5| Step: 5
Training loss: 2.05299711227417
Validation loss: 2.083449839263834

Epoch: 5| Step: 6
Training loss: 2.1150240898132324
Validation loss: 2.077207610171328

Epoch: 5| Step: 7
Training loss: 1.8586012125015259
Validation loss: 2.0703701896052205

Epoch: 5| Step: 8
Training loss: 1.8602393865585327
Validation loss: 2.044171466622301

Epoch: 5| Step: 9
Training loss: 2.8245797157287598
Validation loss: 2.0178288631541754

Epoch: 5| Step: 10
Training loss: 1.8557825088500977
Validation loss: 2.0281287495807936

Epoch: 132| Step: 0
Training loss: 1.7084894180297852
Validation loss: 2.0497963838679816

Epoch: 5| Step: 1
Training loss: 2.005073308944702
Validation loss: 2.078264113395445

Epoch: 5| Step: 2
Training loss: 2.2022178173065186
Validation loss: 2.0890499263681392

Epoch: 5| Step: 3
Training loss: 2.297290086746216
Validation loss: 2.0840712619084183

Epoch: 5| Step: 4
Training loss: 2.416114330291748
Validation loss: 2.069757443602367

Epoch: 5| Step: 5
Training loss: 1.8461109399795532
Validation loss: 2.0345379396151473

Epoch: 5| Step: 6
Training loss: 2.404984712600708
Validation loss: 2.025048889139647

Epoch: 5| Step: 7
Training loss: 2.54156756401062
Validation loss: 2.036327902988721

Epoch: 5| Step: 8
Training loss: 2.219529151916504
Validation loss: 2.0319501225666334

Epoch: 5| Step: 9
Training loss: 2.187080144882202
Validation loss: 2.0534744044785858

Epoch: 5| Step: 10
Training loss: 1.6735174655914307
Validation loss: 2.0637215363082064

Epoch: 133| Step: 0
Training loss: 2.498317003250122
Validation loss: 2.0807965904153805

Epoch: 5| Step: 1
Training loss: 2.249178409576416
Validation loss: 2.1428329701064737

Epoch: 5| Step: 2
Training loss: 1.359068751335144
Validation loss: 2.1892936691161125

Epoch: 5| Step: 3
Training loss: 2.0782999992370605
Validation loss: 2.206681198971246

Epoch: 5| Step: 4
Training loss: 1.8598277568817139
Validation loss: 2.2342261088791715

Epoch: 5| Step: 5
Training loss: 2.3529632091522217
Validation loss: 2.203322051673807

Epoch: 5| Step: 6
Training loss: 2.2415690422058105
Validation loss: 2.154921962368873

Epoch: 5| Step: 7
Training loss: 2.1986441612243652
Validation loss: 2.107277043404118

Epoch: 5| Step: 8
Training loss: 2.301546096801758
Validation loss: 2.1026850438887075

Epoch: 5| Step: 9
Training loss: 2.5655453205108643
Validation loss: 2.0915568438909387

Epoch: 5| Step: 10
Training loss: 1.626716136932373
Validation loss: 2.076546904861286

Epoch: 134| Step: 0
Training loss: 2.4025540351867676
Validation loss: 2.06774309373671

Epoch: 5| Step: 1
Training loss: 2.3242390155792236
Validation loss: 2.0696906376910467

Epoch: 5| Step: 2
Training loss: 1.886635184288025
Validation loss: 2.0501506123491513

Epoch: 5| Step: 3
Training loss: 2.4314022064208984
Validation loss: 2.0539747617577993

Epoch: 5| Step: 4
Training loss: 2.1556639671325684
Validation loss: 2.0603229025358796

Epoch: 5| Step: 5
Training loss: 1.9459165334701538
Validation loss: 2.0447127639606433

Epoch: 5| Step: 6
Training loss: 2.4402284622192383
Validation loss: 2.0368112735850836

Epoch: 5| Step: 7
Training loss: 1.9368747472763062
Validation loss: 2.060120277507331

Epoch: 5| Step: 8
Training loss: 1.6857831478118896
Validation loss: 2.0764358325671126

Epoch: 5| Step: 9
Training loss: 1.8002046346664429
Validation loss: 2.1046996603729906

Epoch: 5| Step: 10
Training loss: 2.1294896602630615
Validation loss: 2.1488567577895297

Epoch: 135| Step: 0
Training loss: 2.3984289169311523
Validation loss: 2.1688982543124946

Epoch: 5| Step: 1
Training loss: 2.3868114948272705
Validation loss: 2.1557073900776524

Epoch: 5| Step: 2
Training loss: 2.1484336853027344
Validation loss: 2.1642009058306293

Epoch: 5| Step: 3
Training loss: 1.9553512334823608
Validation loss: 2.1293683154608614

Epoch: 5| Step: 4
Training loss: 1.9453178644180298
Validation loss: 2.1008453369140625

Epoch: 5| Step: 5
Training loss: 2.118746280670166
Validation loss: 2.083693153114729

Epoch: 5| Step: 6
Training loss: 2.0448999404907227
Validation loss: 2.069292345354634

Epoch: 5| Step: 7
Training loss: 2.376288652420044
Validation loss: 2.081776160065846

Epoch: 5| Step: 8
Training loss: 1.7305736541748047
Validation loss: 2.0916543852898384

Epoch: 5| Step: 9
Training loss: 2.057002067565918
Validation loss: 2.0769657857956423

Epoch: 5| Step: 10
Training loss: 1.9057343006134033
Validation loss: 2.0631531746156755

Epoch: 136| Step: 0
Training loss: 2.06718111038208
Validation loss: 2.0568973607914423

Epoch: 5| Step: 1
Training loss: 2.255280017852783
Validation loss: 2.0668204087083057

Epoch: 5| Step: 2
Training loss: 2.453090190887451
Validation loss: 2.0572780152802825

Epoch: 5| Step: 3
Training loss: 2.1806468963623047
Validation loss: 2.033439343975436

Epoch: 5| Step: 4
Training loss: 1.8923852443695068
Validation loss: 2.0393457438356135

Epoch: 5| Step: 5
Training loss: 2.596151828765869
Validation loss: 2.0659271670926

Epoch: 5| Step: 6
Training loss: 2.2866039276123047
Validation loss: 2.0847592328184392

Epoch: 5| Step: 7
Training loss: 1.823672890663147
Validation loss: 2.119989343868789

Epoch: 5| Step: 8
Training loss: 1.4643781185150146
Validation loss: 2.135375661234702

Epoch: 5| Step: 9
Training loss: 2.056346893310547
Validation loss: 2.16429558877022

Epoch: 5| Step: 10
Training loss: 2.1913070678710938
Validation loss: 2.1423095118614937

Epoch: 137| Step: 0
Training loss: 2.807734966278076
Validation loss: 2.138950114609093

Epoch: 5| Step: 1
Training loss: 1.8155113458633423
Validation loss: 2.121163264397652

Epoch: 5| Step: 2
Training loss: 2.1587905883789062
Validation loss: 2.1045769696594565

Epoch: 5| Step: 3
Training loss: 2.065826177597046
Validation loss: 2.0889903973507624

Epoch: 5| Step: 4
Training loss: 2.107051372528076
Validation loss: 2.088537198241039

Epoch: 5| Step: 5
Training loss: 1.5517181158065796
Validation loss: 2.080746917314427

Epoch: 5| Step: 6
Training loss: 1.6908401250839233
Validation loss: 2.088993792892784

Epoch: 5| Step: 7
Training loss: 2.030120849609375
Validation loss: 2.082271732309813

Epoch: 5| Step: 8
Training loss: 2.57354998588562
Validation loss: 2.0922755913067888

Epoch: 5| Step: 9
Training loss: 1.7090027332305908
Validation loss: 2.096477245771757

Epoch: 5| Step: 10
Training loss: 2.759817123413086
Validation loss: 2.0967139403025308

Epoch: 138| Step: 0
Training loss: 2.302443265914917
Validation loss: 2.1110176937554472

Epoch: 5| Step: 1
Training loss: 2.3365883827209473
Validation loss: 2.1173466046651206

Epoch: 5| Step: 2
Training loss: 2.2165873050689697
Validation loss: 2.1232989116381575

Epoch: 5| Step: 3
Training loss: 2.214209794998169
Validation loss: 2.115580105012463

Epoch: 5| Step: 4
Training loss: 2.2458791732788086
Validation loss: 2.065963122152513

Epoch: 5| Step: 5
Training loss: 1.9071285724639893
Validation loss: 2.053079121856279

Epoch: 5| Step: 6
Training loss: 1.2429478168487549
Validation loss: 2.055003426408255

Epoch: 5| Step: 7
Training loss: 1.8662993907928467
Validation loss: 2.0458145039055937

Epoch: 5| Step: 8
Training loss: 2.4693119525909424
Validation loss: 2.0406304751673052

Epoch: 5| Step: 9
Training loss: 2.3121025562286377
Validation loss: 2.0418142605853338

Epoch: 5| Step: 10
Training loss: 2.128676176071167
Validation loss: 2.048479263500501

Epoch: 139| Step: 0
Training loss: 1.4512876272201538
Validation loss: 2.084857604836905

Epoch: 5| Step: 1
Training loss: 2.0546505451202393
Validation loss: 2.1003995223711898

Epoch: 5| Step: 2
Training loss: 1.6959571838378906
Validation loss: 2.1234012919087566

Epoch: 5| Step: 3
Training loss: 2.248922824859619
Validation loss: 2.1466282529215657

Epoch: 5| Step: 4
Training loss: 2.4600939750671387
Validation loss: 2.158643393106358

Epoch: 5| Step: 5
Training loss: 1.9009984731674194
Validation loss: 2.1704588256856447

Epoch: 5| Step: 6
Training loss: 1.2543240785598755
Validation loss: 2.186420722674298

Epoch: 5| Step: 7
Training loss: 2.639893054962158
Validation loss: 2.187408903593658

Epoch: 5| Step: 8
Training loss: 2.9065518379211426
Validation loss: 2.1696679745951006

Epoch: 5| Step: 9
Training loss: 2.355309009552002
Validation loss: 2.1605369121797624

Epoch: 5| Step: 10
Training loss: 1.9950945377349854
Validation loss: 2.1285604379510366

Epoch: 140| Step: 0
Training loss: 1.7978137731552124
Validation loss: 2.1023438079382784

Epoch: 5| Step: 1
Training loss: 2.0943593978881836
Validation loss: 2.0870727172461887

Epoch: 5| Step: 2
Training loss: 1.349437952041626
Validation loss: 2.078079492815079

Epoch: 5| Step: 3
Training loss: 2.109459638595581
Validation loss: 2.0846184607475036

Epoch: 5| Step: 4
Training loss: 2.6274867057800293
Validation loss: 2.0742268998135804

Epoch: 5| Step: 5
Training loss: 2.1442763805389404
Validation loss: 2.0665737428972797

Epoch: 5| Step: 6
Training loss: 1.6837619543075562
Validation loss: 2.0765269853735484

Epoch: 5| Step: 7
Training loss: 2.0134217739105225
Validation loss: 2.0564379256258727

Epoch: 5| Step: 8
Training loss: 2.5650460720062256
Validation loss: 2.0560951822547504

Epoch: 5| Step: 9
Training loss: 2.080376148223877
Validation loss: 2.043902071573401

Epoch: 5| Step: 10
Training loss: 2.2095775604248047
Validation loss: 2.0465685321438696

Epoch: 141| Step: 0
Training loss: 2.284945487976074
Validation loss: 2.0396460666451404

Epoch: 5| Step: 1
Training loss: 2.047595739364624
Validation loss: 2.0311095496659637

Epoch: 5| Step: 2
Training loss: 1.8801968097686768
Validation loss: 2.0428528324250252

Epoch: 5| Step: 3
Training loss: 2.603965997695923
Validation loss: 2.044697048843548

Epoch: 5| Step: 4
Training loss: 2.189872980117798
Validation loss: 2.045972413914178

Epoch: 5| Step: 5
Training loss: 1.7510112524032593
Validation loss: 2.0502470219007103

Epoch: 5| Step: 6
Training loss: 1.6649038791656494
Validation loss: 2.060061113808745

Epoch: 5| Step: 7
Training loss: 2.231675386428833
Validation loss: 2.0855889038373063

Epoch: 5| Step: 8
Training loss: 1.9555714130401611
Validation loss: 2.1312406345080306

Epoch: 5| Step: 9
Training loss: 2.1521658897399902
Validation loss: 2.186972115629463

Epoch: 5| Step: 10
Training loss: 1.7740287780761719
Validation loss: 2.21145341473241

Epoch: 142| Step: 0
Training loss: 2.0278613567352295
Validation loss: 2.188300012260355

Epoch: 5| Step: 1
Training loss: 1.9624392986297607
Validation loss: 2.135967000838249

Epoch: 5| Step: 2
Training loss: 2.1278598308563232
Validation loss: 2.1202661991119385

Epoch: 5| Step: 3
Training loss: 1.967886209487915
Validation loss: 2.1332262741622103

Epoch: 5| Step: 4
Training loss: 2.2755961418151855
Validation loss: 2.12040191055626

Epoch: 5| Step: 5
Training loss: 2.1715331077575684
Validation loss: 2.116665137711392

Epoch: 5| Step: 6
Training loss: 2.47027850151062
Validation loss: 2.0919639525874967

Epoch: 5| Step: 7
Training loss: 2.0592141151428223
Validation loss: 2.0733634246292936

Epoch: 5| Step: 8
Training loss: 2.044010639190674
Validation loss: 2.079144059970815

Epoch: 5| Step: 9
Training loss: 1.5726979970932007
Validation loss: 2.08379965700129

Epoch: 5| Step: 10
Training loss: 2.4025299549102783
Validation loss: 2.092957078769643

Epoch: 143| Step: 0
Training loss: 2.185298204421997
Validation loss: 2.1029386648567776

Epoch: 5| Step: 1
Training loss: 2.0735373497009277
Validation loss: 2.0899756621288996

Epoch: 5| Step: 2
Training loss: 1.6490733623504639
Validation loss: 2.105303415688135

Epoch: 5| Step: 3
Training loss: 1.9686782360076904
Validation loss: 2.103882740902644

Epoch: 5| Step: 4
Training loss: 2.468555212020874
Validation loss: 2.126272575829619

Epoch: 5| Step: 5
Training loss: 1.7411327362060547
Validation loss: 2.1146481678050053

Epoch: 5| Step: 6
Training loss: 2.0992000102996826
Validation loss: 2.12470410203421

Epoch: 5| Step: 7
Training loss: 1.7318403720855713
Validation loss: 2.121928253481465

Epoch: 5| Step: 8
Training loss: 2.5065455436706543
Validation loss: 2.1197025545181765

Epoch: 5| Step: 9
Training loss: 2.4726758003234863
Validation loss: 2.0863799407917965

Epoch: 5| Step: 10
Training loss: 2.1854872703552246
Validation loss: 2.091479730862443

Epoch: 144| Step: 0
Training loss: 2.555358409881592
Validation loss: 2.0835399371321484

Epoch: 5| Step: 1
Training loss: 1.3500269651412964
Validation loss: 2.0789519945780435

Epoch: 5| Step: 2
Training loss: 2.546938180923462
Validation loss: 2.069253049870973

Epoch: 5| Step: 3
Training loss: 1.5278551578521729
Validation loss: 2.062193810298879

Epoch: 5| Step: 4
Training loss: 2.4237217903137207
Validation loss: 2.061049040927682

Epoch: 5| Step: 5
Training loss: 2.2246692180633545
Validation loss: 2.0564455165657947

Epoch: 5| Step: 6
Training loss: 1.8048553466796875
Validation loss: 2.042629090688562

Epoch: 5| Step: 7
Training loss: 1.7899672985076904
Validation loss: 2.022762588275376

Epoch: 5| Step: 8
Training loss: 2.1712024211883545
Validation loss: 2.0438198466454782

Epoch: 5| Step: 9
Training loss: 1.8717340230941772
Validation loss: 2.0551895480002127

Epoch: 5| Step: 10
Training loss: 2.3608715534210205
Validation loss: 2.0909120139255317

Epoch: 145| Step: 0
Training loss: 1.6828975677490234
Validation loss: 2.1032175684487946

Epoch: 5| Step: 1
Training loss: 2.7307229042053223
Validation loss: 2.0705542513119277

Epoch: 5| Step: 2
Training loss: 1.9434549808502197
Validation loss: 2.0433050637604087

Epoch: 5| Step: 3
Training loss: 1.9157060384750366
Validation loss: 2.0277316647191204

Epoch: 5| Step: 4
Training loss: 2.0860085487365723
Validation loss: 2.0248271393519577

Epoch: 5| Step: 5
Training loss: 1.9818131923675537
Validation loss: 2.036170977418141

Epoch: 5| Step: 6
Training loss: 1.9393316507339478
Validation loss: 2.062064145200996

Epoch: 5| Step: 7
Training loss: 1.6682045459747314
Validation loss: 2.0746118381459224

Epoch: 5| Step: 8
Training loss: 2.3913216590881348
Validation loss: 2.061654616427678

Epoch: 5| Step: 9
Training loss: 2.3844871520996094
Validation loss: 2.0653434863654514

Epoch: 5| Step: 10
Training loss: 2.071465492248535
Validation loss: 2.087716938346945

Epoch: 146| Step: 0
Training loss: 1.529529333114624
Validation loss: 2.0718422525672504

Epoch: 5| Step: 1
Training loss: 2.6946825981140137
Validation loss: 2.0676942820190103

Epoch: 5| Step: 2
Training loss: 2.2116150856018066
Validation loss: 2.070108531623758

Epoch: 5| Step: 3
Training loss: 1.5494585037231445
Validation loss: 2.0518466029115903

Epoch: 5| Step: 4
Training loss: 1.8262935876846313
Validation loss: 2.0394012415280907

Epoch: 5| Step: 5
Training loss: 1.7467689514160156
Validation loss: 2.0414586990110335

Epoch: 5| Step: 6
Training loss: 2.345557689666748
Validation loss: 2.028980924237159

Epoch: 5| Step: 7
Training loss: 1.5661579370498657
Validation loss: 2.0360428505046393

Epoch: 5| Step: 8
Training loss: 1.7846568822860718
Validation loss: 2.0565104766558577

Epoch: 5| Step: 9
Training loss: 2.412931442260742
Validation loss: 2.0515340451271302

Epoch: 5| Step: 10
Training loss: 2.827362537384033
Validation loss: 2.1027266722853466

Epoch: 147| Step: 0
Training loss: 2.1902475357055664
Validation loss: 2.1262637120421215

Epoch: 5| Step: 1
Training loss: 2.2006523609161377
Validation loss: 2.143776455233174

Epoch: 5| Step: 2
Training loss: 2.1188302040100098
Validation loss: 2.1492965887951594

Epoch: 5| Step: 3
Training loss: 2.133676290512085
Validation loss: 2.1579054427403275

Epoch: 5| Step: 4
Training loss: 2.343127727508545
Validation loss: 2.133014750737016

Epoch: 5| Step: 5
Training loss: 2.1021533012390137
Validation loss: 2.109367770533408

Epoch: 5| Step: 6
Training loss: 2.123333215713501
Validation loss: 2.1031431292974823

Epoch: 5| Step: 7
Training loss: 1.777120590209961
Validation loss: 2.0875330278950353

Epoch: 5| Step: 8
Training loss: 1.591128945350647
Validation loss: 2.0667347856747207

Epoch: 5| Step: 9
Training loss: 1.8536163568496704
Validation loss: 2.0436903430569555

Epoch: 5| Step: 10
Training loss: 2.1208715438842773
Validation loss: 2.0416002773469493

Epoch: 148| Step: 0
Training loss: 1.8771603107452393
Validation loss: 2.046072256180548

Epoch: 5| Step: 1
Training loss: 1.8367860317230225
Validation loss: 2.059137818633869

Epoch: 5| Step: 2
Training loss: 2.2105259895324707
Validation loss: 2.0535952916709324

Epoch: 5| Step: 3
Training loss: 2.079257011413574
Validation loss: 2.065130178646375

Epoch: 5| Step: 4
Training loss: 2.1407828330993652
Validation loss: 2.0720855394999185

Epoch: 5| Step: 5
Training loss: 2.3675975799560547
Validation loss: 2.0775785215439333

Epoch: 5| Step: 6
Training loss: 2.188807964324951
Validation loss: 2.0837947373749106

Epoch: 5| Step: 7
Training loss: 1.850726842880249
Validation loss: 2.0672057315867436

Epoch: 5| Step: 8
Training loss: 2.4171860218048096
Validation loss: 2.068990117760115

Epoch: 5| Step: 9
Training loss: 1.928056001663208
Validation loss: 2.0664034223043792

Epoch: 5| Step: 10
Training loss: 1.1927969455718994
Validation loss: 2.0584067016519527

Epoch: 149| Step: 0
Training loss: 2.767883777618408
Validation loss: 2.0540080865224204

Epoch: 5| Step: 1
Training loss: 1.8179336786270142
Validation loss: 2.0350139461537844

Epoch: 5| Step: 2
Training loss: 1.8623842000961304
Validation loss: 2.0366745982118832

Epoch: 5| Step: 3
Training loss: 1.7298071384429932
Validation loss: 2.0587215590220627

Epoch: 5| Step: 4
Training loss: 1.3522145748138428
Validation loss: 2.0879492657158965

Epoch: 5| Step: 5
Training loss: 1.7678416967391968
Validation loss: 2.1054059946408836

Epoch: 5| Step: 6
Training loss: 1.9770501852035522
Validation loss: 2.117723595711493

Epoch: 5| Step: 7
Training loss: 2.322563886642456
Validation loss: 2.111253002638458

Epoch: 5| Step: 8
Training loss: 2.3716297149658203
Validation loss: 2.0992428384801394

Epoch: 5| Step: 9
Training loss: 2.3540549278259277
Validation loss: 2.0768883689757316

Epoch: 5| Step: 10
Training loss: 1.8309922218322754
Validation loss: 2.0707583235156153

Epoch: 150| Step: 0
Training loss: 1.8596900701522827
Validation loss: 2.0833038899206344

Epoch: 5| Step: 1
Training loss: 1.9222427606582642
Validation loss: 2.0775771384598105

Epoch: 5| Step: 2
Training loss: 1.3391309976577759
Validation loss: 2.0798326602546116

Epoch: 5| Step: 3
Training loss: 1.7327187061309814
Validation loss: 2.0823037367995068

Epoch: 5| Step: 4
Training loss: 2.103487253189087
Validation loss: 2.083072729008172

Epoch: 5| Step: 5
Training loss: 1.9840900897979736
Validation loss: 2.081550377671437

Epoch: 5| Step: 6
Training loss: 2.4050350189208984
Validation loss: 2.0837728028656333

Epoch: 5| Step: 7
Training loss: 2.018183708190918
Validation loss: 2.0951432130670034

Epoch: 5| Step: 8
Training loss: 2.0155694484710693
Validation loss: 2.1056585260616836

Epoch: 5| Step: 9
Training loss: 2.6512343883514404
Validation loss: 2.115790395326512

Epoch: 5| Step: 10
Training loss: 1.546030879020691
Validation loss: 2.1181330860302015

Epoch: 151| Step: 0
Training loss: 2.0788846015930176
Validation loss: 2.103692482876521

Epoch: 5| Step: 1
Training loss: 1.1980758905410767
Validation loss: 2.1209328866774038

Epoch: 5| Step: 2
Training loss: 1.8855526447296143
Validation loss: 2.1167416534116192

Epoch: 5| Step: 3
Training loss: 2.1135480403900146
Validation loss: 2.1220766959651822

Epoch: 5| Step: 4
Training loss: 2.3033359050750732
Validation loss: 2.1389259087142123

Epoch: 5| Step: 5
Training loss: 1.8930209875106812
Validation loss: 2.126597991553686

Epoch: 5| Step: 6
Training loss: 2.2282485961914062
Validation loss: 2.0994901298194804

Epoch: 5| Step: 7
Training loss: 1.9860519170761108
Validation loss: 2.0833071277987574

Epoch: 5| Step: 8
Training loss: 1.6573410034179688
Validation loss: 2.0688881284447125

Epoch: 5| Step: 9
Training loss: 2.400597095489502
Validation loss: 2.0704223058556996

Epoch: 5| Step: 10
Training loss: 2.014055013656616
Validation loss: 2.076853131735197

Epoch: 152| Step: 0
Training loss: 2.150001049041748
Validation loss: 2.0683164506830196

Epoch: 5| Step: 1
Training loss: 1.581433653831482
Validation loss: 2.083656718654017

Epoch: 5| Step: 2
Training loss: 1.5460832118988037
Validation loss: 2.10326999233615

Epoch: 5| Step: 3
Training loss: 1.8993949890136719
Validation loss: 2.11029435870468

Epoch: 5| Step: 4
Training loss: 2.2272489070892334
Validation loss: 2.1192863166973157

Epoch: 5| Step: 5
Training loss: 1.9468135833740234
Validation loss: 2.1355572849191646

Epoch: 5| Step: 6
Training loss: 2.1062471866607666
Validation loss: 2.180211185127176

Epoch: 5| Step: 7
Training loss: 2.6396687030792236
Validation loss: 2.15108387700973

Epoch: 5| Step: 8
Training loss: 1.6834083795547485
Validation loss: 2.141600811353294

Epoch: 5| Step: 9
Training loss: 2.0165419578552246
Validation loss: 2.095075479117773

Epoch: 5| Step: 10
Training loss: 1.892565369606018
Validation loss: 2.059953239656264

Epoch: 153| Step: 0
Training loss: 1.520129919052124
Validation loss: 2.036982188942612

Epoch: 5| Step: 1
Training loss: 2.2411997318267822
Validation loss: 2.025574484179097

Epoch: 5| Step: 2
Training loss: 2.4828529357910156
Validation loss: 2.018296067432691

Epoch: 5| Step: 3
Training loss: 2.1683831214904785
Validation loss: 2.0187905860203568

Epoch: 5| Step: 4
Training loss: 1.8837474584579468
Validation loss: 2.0143736152238745

Epoch: 5| Step: 5
Training loss: 1.52227783203125
Validation loss: 2.019460778082571

Epoch: 5| Step: 6
Training loss: 1.960375428199768
Validation loss: 2.023570401694185

Epoch: 5| Step: 7
Training loss: 2.419743061065674
Validation loss: 2.0300705355982624

Epoch: 5| Step: 8
Training loss: 1.9466564655303955
Validation loss: 2.031853464341933

Epoch: 5| Step: 9
Training loss: 2.0438790321350098
Validation loss: 2.037264213767103

Epoch: 5| Step: 10
Training loss: 1.2919702529907227
Validation loss: 2.0540090325058147

Epoch: 154| Step: 0
Training loss: 2.0406057834625244
Validation loss: 2.0996927984299196

Epoch: 5| Step: 1
Training loss: 2.4033873081207275
Validation loss: 2.1813667346072454

Epoch: 5| Step: 2
Training loss: 2.1387405395507812
Validation loss: 2.2265375660311792

Epoch: 5| Step: 3
Training loss: 1.9522182941436768
Validation loss: 2.2592454161695255

Epoch: 5| Step: 4
Training loss: 1.7335373163223267
Validation loss: 2.2716317484455724

Epoch: 5| Step: 5
Training loss: 1.7342453002929688
Validation loss: 2.234499195570587

Epoch: 5| Step: 6
Training loss: 2.463855028152466
Validation loss: 2.2185239817506526

Epoch: 5| Step: 7
Training loss: 1.7001349925994873
Validation loss: 2.160190784803001

Epoch: 5| Step: 8
Training loss: 1.8977495431900024
Validation loss: 2.1075292069424867

Epoch: 5| Step: 9
Training loss: 2.1299519538879395
Validation loss: 2.054117443741009

Epoch: 5| Step: 10
Training loss: 1.7859975099563599
Validation loss: 2.0326159923307356

Epoch: 155| Step: 0
Training loss: 1.9782764911651611
Validation loss: 2.0272817816785587

Epoch: 5| Step: 1
Training loss: 2.1777987480163574
Validation loss: 2.0182532007976244

Epoch: 5| Step: 2
Training loss: 2.150125026702881
Validation loss: 2.0127653947440525

Epoch: 5| Step: 3
Training loss: 2.061814546585083
Validation loss: 2.0004007611223447

Epoch: 5| Step: 4
Training loss: 2.279867649078369
Validation loss: 1.9928588892823906

Epoch: 5| Step: 5
Training loss: 1.733481764793396
Validation loss: 1.9844744397747902

Epoch: 5| Step: 6
Training loss: 1.8536876440048218
Validation loss: 1.9812204478889384

Epoch: 5| Step: 7
Training loss: 1.8950433731079102
Validation loss: 1.9884582540040374

Epoch: 5| Step: 8
Training loss: 2.199995756149292
Validation loss: 1.9822596426933043

Epoch: 5| Step: 9
Training loss: 1.747931718826294
Validation loss: 2.00287083015647

Epoch: 5| Step: 10
Training loss: 1.8347829580307007
Validation loss: 2.0270242280857538

Epoch: 156| Step: 0
Training loss: 1.9221795797348022
Validation loss: 2.0577625843786422

Epoch: 5| Step: 1
Training loss: 1.8343698978424072
Validation loss: 2.0679444189994567

Epoch: 5| Step: 2
Training loss: 1.9325929880142212
Validation loss: 2.086772031681512

Epoch: 5| Step: 3
Training loss: 2.125471591949463
Validation loss: 2.122630370560513

Epoch: 5| Step: 4
Training loss: 2.7364485263824463
Validation loss: 2.121808200754145

Epoch: 5| Step: 5
Training loss: 1.7583343982696533
Validation loss: 2.1141556924389255

Epoch: 5| Step: 6
Training loss: 0.9738374948501587
Validation loss: 2.1055368300407165

Epoch: 5| Step: 7
Training loss: 1.9724133014678955
Validation loss: 2.102123929608253

Epoch: 5| Step: 8
Training loss: 1.8962688446044922
Validation loss: 2.0845264132304857

Epoch: 5| Step: 9
Training loss: 1.913888931274414
Validation loss: 2.0610930394100886

Epoch: 5| Step: 10
Training loss: 2.563293933868408
Validation loss: 2.0483519441337994

Epoch: 157| Step: 0
Training loss: 1.6922426223754883
Validation loss: 2.053224809708134

Epoch: 5| Step: 1
Training loss: 2.183056354522705
Validation loss: 2.0668742887435423

Epoch: 5| Step: 2
Training loss: 2.070098400115967
Validation loss: 2.0553045503554808

Epoch: 5| Step: 3
Training loss: 1.9775556325912476
Validation loss: 2.04425335186784

Epoch: 5| Step: 4
Training loss: 2.0380053520202637
Validation loss: 2.043225498609645

Epoch: 5| Step: 5
Training loss: 2.9297597408294678
Validation loss: 2.047327104435172

Epoch: 5| Step: 6
Training loss: 1.7130768299102783
Validation loss: 2.0438041546011485

Epoch: 5| Step: 7
Training loss: 1.4604432582855225
Validation loss: 2.0433280519259873

Epoch: 5| Step: 8
Training loss: 1.4579498767852783
Validation loss: 2.0530140258932628

Epoch: 5| Step: 9
Training loss: 1.804713487625122
Validation loss: 2.0605197311729513

Epoch: 5| Step: 10
Training loss: 2.1505911350250244
Validation loss: 2.0521047102507723

Epoch: 158| Step: 0
Training loss: 1.9455089569091797
Validation loss: 2.0620132620616625

Epoch: 5| Step: 1
Training loss: 2.2360575199127197
Validation loss: 2.071605664427562

Epoch: 5| Step: 2
Training loss: 1.7934610843658447
Validation loss: 2.0784874526403283

Epoch: 5| Step: 3
Training loss: 1.512338399887085
Validation loss: 2.071923371284239

Epoch: 5| Step: 4
Training loss: 1.7476451396942139
Validation loss: 2.084334586256294

Epoch: 5| Step: 5
Training loss: 2.046262502670288
Validation loss: 2.0798618819123957

Epoch: 5| Step: 6
Training loss: 1.7081998586654663
Validation loss: 2.074192882865988

Epoch: 5| Step: 7
Training loss: 2.0623300075531006
Validation loss: 2.0824181982266006

Epoch: 5| Step: 8
Training loss: 1.658158302307129
Validation loss: 2.0772233880976194

Epoch: 5| Step: 9
Training loss: 2.5428709983825684
Validation loss: 2.0781185678256455

Epoch: 5| Step: 10
Training loss: 1.8183557987213135
Validation loss: 2.066711469363141

Epoch: 159| Step: 0
Training loss: 1.8898189067840576
Validation loss: 2.0818862607402187

Epoch: 5| Step: 1
Training loss: 2.2222602367401123
Validation loss: 2.062434786109514

Epoch: 5| Step: 2
Training loss: 2.1968271732330322
Validation loss: 2.056507223395891

Epoch: 5| Step: 3
Training loss: 1.8573997020721436
Validation loss: 2.0321745821224746

Epoch: 5| Step: 4
Training loss: 2.135525941848755
Validation loss: 2.0356244399983394

Epoch: 5| Step: 5
Training loss: 2.019334077835083
Validation loss: 2.027877733271609

Epoch: 5| Step: 6
Training loss: 2.3168370723724365
Validation loss: 2.055465349587061

Epoch: 5| Step: 7
Training loss: 1.2015761137008667
Validation loss: 2.0583897713691957

Epoch: 5| Step: 8
Training loss: 1.9083448648452759
Validation loss: 2.0572282421973442

Epoch: 5| Step: 9
Training loss: 2.301724910736084
Validation loss: 2.047945405847283

Epoch: 5| Step: 10
Training loss: 1.1655919551849365
Validation loss: 2.0664855203320904

Epoch: 160| Step: 0
Training loss: 2.5356760025024414
Validation loss: 2.0658742522680633

Epoch: 5| Step: 1
Training loss: 1.7247211933135986
Validation loss: 2.0872573788448046

Epoch: 5| Step: 2
Training loss: 1.7899739742279053
Validation loss: 2.1035334038478073

Epoch: 5| Step: 3
Training loss: 2.14178729057312
Validation loss: 2.128705040101082

Epoch: 5| Step: 4
Training loss: 2.3778669834136963
Validation loss: 2.164209927282026

Epoch: 5| Step: 5
Training loss: 1.8562113046646118
Validation loss: 2.1697796647266676

Epoch: 5| Step: 6
Training loss: 1.732421875
Validation loss: 2.1763927116188952

Epoch: 5| Step: 7
Training loss: 1.879530906677246
Validation loss: 2.1599361332513953

Epoch: 5| Step: 8
Training loss: 1.815958023071289
Validation loss: 2.157651456453467

Epoch: 5| Step: 9
Training loss: 1.2780568599700928
Validation loss: 2.102271062071605

Epoch: 5| Step: 10
Training loss: 2.2132976055145264
Validation loss: 2.0584653962043022

Epoch: 161| Step: 0
Training loss: 1.9090728759765625
Validation loss: 2.035704110258369

Epoch: 5| Step: 1
Training loss: 1.6416099071502686
Validation loss: 1.9997371909438924

Epoch: 5| Step: 2
Training loss: 2.1009557247161865
Validation loss: 1.9969624883385115

Epoch: 5| Step: 3
Training loss: 2.3666634559631348
Validation loss: 1.9886852451550063

Epoch: 5| Step: 4
Training loss: 1.9810672998428345
Validation loss: 1.9843848930892123

Epoch: 5| Step: 5
Training loss: 2.1364502906799316
Validation loss: 1.981202148622082

Epoch: 5| Step: 6
Training loss: 1.6440670490264893
Validation loss: 1.9779509677681872

Epoch: 5| Step: 7
Training loss: 2.119894504547119
Validation loss: 1.9933447209737634

Epoch: 5| Step: 8
Training loss: 2.01224684715271
Validation loss: 1.9989706649575183

Epoch: 5| Step: 9
Training loss: 2.038567543029785
Validation loss: 2.000055930947745

Epoch: 5| Step: 10
Training loss: 1.326332688331604
Validation loss: 2.0272052544419483

Epoch: 162| Step: 0
Training loss: 1.7206894159317017
Validation loss: 2.0855433915251043

Epoch: 5| Step: 1
Training loss: 2.055103063583374
Validation loss: 2.1585769986593597

Epoch: 5| Step: 2
Training loss: 2.3113198280334473
Validation loss: 2.2441120660433205

Epoch: 5| Step: 3
Training loss: 1.7790343761444092
Validation loss: 2.2656062469687512

Epoch: 5| Step: 4
Training loss: 2.1904730796813965
Validation loss: 2.250936130041717

Epoch: 5| Step: 5
Training loss: 2.182349681854248
Validation loss: 2.21641618205655

Epoch: 5| Step: 6
Training loss: 1.8822805881500244
Validation loss: 2.1667012271060737

Epoch: 5| Step: 7
Training loss: 2.0495331287384033
Validation loss: 2.1316891370281095

Epoch: 5| Step: 8
Training loss: 1.8648347854614258
Validation loss: 2.1019283058822795

Epoch: 5| Step: 9
Training loss: 1.6929655075073242
Validation loss: 2.0600184138103197

Epoch: 5| Step: 10
Training loss: 1.9449282884597778
Validation loss: 2.0521416228304625

Epoch: 163| Step: 0
Training loss: 1.9682719707489014
Validation loss: 2.0283981600115375

Epoch: 5| Step: 1
Training loss: 2.0153725147247314
Validation loss: 2.013614403304233

Epoch: 5| Step: 2
Training loss: 2.3103156089782715
Validation loss: 2.015088870961179

Epoch: 5| Step: 3
Training loss: 1.5694431066513062
Validation loss: 2.0171760743664158

Epoch: 5| Step: 4
Training loss: 1.788675308227539
Validation loss: 2.0353064280684277

Epoch: 5| Step: 5
Training loss: 1.9123687744140625
Validation loss: 2.0266929211155063

Epoch: 5| Step: 6
Training loss: 1.9654428958892822
Validation loss: 2.0416943488582486

Epoch: 5| Step: 7
Training loss: 2.0505175590515137
Validation loss: 2.044818288536482

Epoch: 5| Step: 8
Training loss: 1.7762168645858765
Validation loss: 2.0368624899976995

Epoch: 5| Step: 9
Training loss: 1.9447412490844727
Validation loss: 2.0595098387810493

Epoch: 5| Step: 10
Training loss: 1.802207350730896
Validation loss: 2.071523094689974

Epoch: 164| Step: 0
Training loss: 1.6478687524795532
Validation loss: 2.065707952745499

Epoch: 5| Step: 1
Training loss: 2.229942798614502
Validation loss: 2.1168649875989525

Epoch: 5| Step: 2
Training loss: 2.137774705886841
Validation loss: 2.1358265415314706

Epoch: 5| Step: 3
Training loss: 2.1813483238220215
Validation loss: 2.1724390214489353

Epoch: 5| Step: 4
Training loss: 1.5528171062469482
Validation loss: 2.1867120342869915

Epoch: 5| Step: 5
Training loss: 2.0413901805877686
Validation loss: 2.182889037234809

Epoch: 5| Step: 6
Training loss: 2.366345167160034
Validation loss: 2.152665376663208

Epoch: 5| Step: 7
Training loss: 1.3958396911621094
Validation loss: 2.1390672819588774

Epoch: 5| Step: 8
Training loss: 1.9497528076171875
Validation loss: 2.126891983452664

Epoch: 5| Step: 9
Training loss: 1.7162986993789673
Validation loss: 2.120915905121834

Epoch: 5| Step: 10
Training loss: 2.10758638381958
Validation loss: 2.093392247794777

Epoch: 165| Step: 0
Training loss: 1.5504035949707031
Validation loss: 2.0835457950510006

Epoch: 5| Step: 1
Training loss: 2.394655704498291
Validation loss: 2.066930536300905

Epoch: 5| Step: 2
Training loss: 1.7594764232635498
Validation loss: 2.0595930058469056

Epoch: 5| Step: 3
Training loss: 2.3734354972839355
Validation loss: 2.0503149327411445

Epoch: 5| Step: 4
Training loss: 1.4674245119094849
Validation loss: 2.0465600798206944

Epoch: 5| Step: 5
Training loss: 1.7636464834213257
Validation loss: 2.042778940610988

Epoch: 5| Step: 6
Training loss: 2.0897889137268066
Validation loss: 2.047143825920679

Epoch: 5| Step: 7
Training loss: 1.8988056182861328
Validation loss: 2.054644484673777

Epoch: 5| Step: 8
Training loss: 2.0106422901153564
Validation loss: 2.0282553062644055

Epoch: 5| Step: 9
Training loss: 2.227710723876953
Validation loss: 2.033278242234261

Epoch: 5| Step: 10
Training loss: 1.365598201751709
Validation loss: 2.0222843077874955

Epoch: 166| Step: 0
Training loss: 1.5747448205947876
Validation loss: 2.028111909025459

Epoch: 5| Step: 1
Training loss: 2.258100748062134
Validation loss: 2.0271202851367254

Epoch: 5| Step: 2
Training loss: 1.417466402053833
Validation loss: 2.0513292743313696

Epoch: 5| Step: 3
Training loss: 2.331484317779541
Validation loss: 2.051018780277621

Epoch: 5| Step: 4
Training loss: 1.5726451873779297
Validation loss: 2.055988368167672

Epoch: 5| Step: 5
Training loss: 2.3462347984313965
Validation loss: 2.0696381856036443

Epoch: 5| Step: 6
Training loss: 2.0724971294403076
Validation loss: 2.062012494251292

Epoch: 5| Step: 7
Training loss: 2.012694835662842
Validation loss: 2.0614165849583124

Epoch: 5| Step: 8
Training loss: 1.810415267944336
Validation loss: 2.0664191399851153

Epoch: 5| Step: 9
Training loss: 1.6906944513320923
Validation loss: 2.0452369400250014

Epoch: 5| Step: 10
Training loss: 1.4699022769927979
Validation loss: 2.0491372436605473

Epoch: 167| Step: 0
Training loss: 1.7446273565292358
Validation loss: 2.0389146932991604

Epoch: 5| Step: 1
Training loss: 1.684197187423706
Validation loss: 2.0345685840934835

Epoch: 5| Step: 2
Training loss: 2.0481643676757812
Validation loss: 2.037756132823165

Epoch: 5| Step: 3
Training loss: 2.2821056842803955
Validation loss: 2.0470958986589984

Epoch: 5| Step: 4
Training loss: 1.5401376485824585
Validation loss: 2.053303937758169

Epoch: 5| Step: 5
Training loss: 1.7811943292617798
Validation loss: 2.0604123159121444

Epoch: 5| Step: 6
Training loss: 1.3721506595611572
Validation loss: 2.051122103967974

Epoch: 5| Step: 7
Training loss: 2.2223281860351562
Validation loss: 2.0435294412797496

Epoch: 5| Step: 8
Training loss: 1.9958722591400146
Validation loss: 2.0389612643949446

Epoch: 5| Step: 9
Training loss: 1.5259382724761963
Validation loss: 2.0386078729424426

Epoch: 5| Step: 10
Training loss: 1.845938801765442
Validation loss: 2.0729843237066783

Epoch: 168| Step: 0
Training loss: 2.369736433029175
Validation loss: 2.0794874211793304

Epoch: 5| Step: 1
Training loss: 1.8484468460083008
Validation loss: 2.0681779820431947

Epoch: 5| Step: 2
Training loss: 1.388033151626587
Validation loss: 2.073593807476823

Epoch: 5| Step: 3
Training loss: 2.1645779609680176
Validation loss: 2.0642965096299366

Epoch: 5| Step: 4
Training loss: 1.3585805892944336
Validation loss: 2.0669104719674714

Epoch: 5| Step: 5
Training loss: 1.6974561214447021
Validation loss: 2.0919221472996536

Epoch: 5| Step: 6
Training loss: 2.4101481437683105
Validation loss: 2.113969523419616

Epoch: 5| Step: 7
Training loss: 1.2382481098175049
Validation loss: 2.1013344410927064

Epoch: 5| Step: 8
Training loss: 1.6333364248275757
Validation loss: 2.0508571709356

Epoch: 5| Step: 9
Training loss: 2.253901720046997
Validation loss: 2.0577508659772974

Epoch: 5| Step: 10
Training loss: 1.8726211786270142
Validation loss: 2.061042898444719

Epoch: 169| Step: 0
Training loss: 1.8024132251739502
Validation loss: 2.0505265061573317

Epoch: 5| Step: 1
Training loss: 2.7060294151306152
Validation loss: 2.0254929988614974

Epoch: 5| Step: 2
Training loss: 1.7984260320663452
Validation loss: 2.02028049320303

Epoch: 5| Step: 3
Training loss: 1.2743375301361084
Validation loss: 2.0311690709924184

Epoch: 5| Step: 4
Training loss: 1.8105669021606445
Validation loss: 2.0507589514537523

Epoch: 5| Step: 5
Training loss: 2.2474708557128906
Validation loss: 2.0683250670791953

Epoch: 5| Step: 6
Training loss: 1.4936676025390625
Validation loss: 2.0587940549337738

Epoch: 5| Step: 7
Training loss: 1.7881231307983398
Validation loss: 2.0485661286179737

Epoch: 5| Step: 8
Training loss: 2.2704498767852783
Validation loss: 2.0216265006731917

Epoch: 5| Step: 9
Training loss: 1.9564812183380127
Validation loss: 2.0249478047893894

Epoch: 5| Step: 10
Training loss: 1.2923160791397095
Validation loss: 2.0252020743585404

Epoch: 170| Step: 0
Training loss: 1.1508400440216064
Validation loss: 2.0479399952837216

Epoch: 5| Step: 1
Training loss: 2.2483937740325928
Validation loss: 2.0550969326367943

Epoch: 5| Step: 2
Training loss: 2.2376668453216553
Validation loss: 2.0965274636463453

Epoch: 5| Step: 3
Training loss: 1.5954545736312866
Validation loss: 2.1102284205857145

Epoch: 5| Step: 4
Training loss: 1.6314170360565186
Validation loss: 2.1486567938199608

Epoch: 5| Step: 5
Training loss: 1.9589660167694092
Validation loss: 2.1613122083807506

Epoch: 5| Step: 6
Training loss: 1.9852526187896729
Validation loss: 2.122343977292379

Epoch: 5| Step: 7
Training loss: 2.3415520191192627
Validation loss: 2.0979760244328487

Epoch: 5| Step: 8
Training loss: 1.874542236328125
Validation loss: 2.0577580505801785

Epoch: 5| Step: 9
Training loss: 0.9642101526260376
Validation loss: 2.046734448402159

Epoch: 5| Step: 10
Training loss: 1.8993362188339233
Validation loss: 2.018453780040946

Epoch: 171| Step: 0
Training loss: 1.6856639385223389
Validation loss: 2.0110545440386702

Epoch: 5| Step: 1
Training loss: 1.8652194738388062
Validation loss: 2.010830625411003

Epoch: 5| Step: 2
Training loss: 2.328627824783325
Validation loss: 2.0112394107285367

Epoch: 5| Step: 3
Training loss: 1.9539272785186768
Validation loss: 2.008246164168081

Epoch: 5| Step: 4
Training loss: 2.2634329795837402
Validation loss: 2.0035646653944448

Epoch: 5| Step: 5
Training loss: 1.6543567180633545
Validation loss: 2.003520127265684

Epoch: 5| Step: 6
Training loss: 1.788630723953247
Validation loss: 2.006007548301451

Epoch: 5| Step: 7
Training loss: 1.5260342359542847
Validation loss: 2.0086912955007246

Epoch: 5| Step: 8
Training loss: 1.923638939857483
Validation loss: 2.0221719870003323

Epoch: 5| Step: 9
Training loss: 2.003046751022339
Validation loss: 2.0439342773088844

Epoch: 5| Step: 10
Training loss: 1.5399484634399414
Validation loss: 2.0486582171532417

Epoch: 172| Step: 0
Training loss: 2.025803327560425
Validation loss: 2.059480221040787

Epoch: 5| Step: 1
Training loss: 1.6519107818603516
Validation loss: 2.0789063963838803

Epoch: 5| Step: 2
Training loss: 1.9103078842163086
Validation loss: 2.0696407646261235

Epoch: 5| Step: 3
Training loss: 2.073944568634033
Validation loss: 2.0827567513271044

Epoch: 5| Step: 4
Training loss: 0.754907488822937
Validation loss: 2.0882768477163007

Epoch: 5| Step: 5
Training loss: 1.959350824356079
Validation loss: 2.0903613810898154

Epoch: 5| Step: 6
Training loss: 1.9790527820587158
Validation loss: 2.1206596794948784

Epoch: 5| Step: 7
Training loss: 1.3911633491516113
Validation loss: 2.107190357741489

Epoch: 5| Step: 8
Training loss: 2.6826117038726807
Validation loss: 2.09208986836095

Epoch: 5| Step: 9
Training loss: 1.6843761205673218
Validation loss: 2.0839963984745804

Epoch: 5| Step: 10
Training loss: 1.8751983642578125
Validation loss: 2.0692819074917863

Epoch: 173| Step: 0
Training loss: 2.2788772583007812
Validation loss: 2.0515567282194733

Epoch: 5| Step: 1
Training loss: 1.4188835620880127
Validation loss: 2.0087322137689076

Epoch: 5| Step: 2
Training loss: 1.8056367635726929
Validation loss: 2.008632089502068

Epoch: 5| Step: 3
Training loss: 2.083625316619873
Validation loss: 1.999303989512946

Epoch: 5| Step: 4
Training loss: 1.4650232791900635
Validation loss: 2.0064729605951617

Epoch: 5| Step: 5
Training loss: 1.4323036670684814
Validation loss: 2.019126940799016

Epoch: 5| Step: 6
Training loss: 1.4519718885421753
Validation loss: 2.0107217732296196

Epoch: 5| Step: 7
Training loss: 1.9639514684677124
Validation loss: 2.0141914711203626

Epoch: 5| Step: 8
Training loss: 2.009784698486328
Validation loss: 2.010437020691492

Epoch: 5| Step: 9
Training loss: 1.687299370765686
Validation loss: 2.0121502825008926

Epoch: 5| Step: 10
Training loss: 1.8240962028503418
Validation loss: 2.0207365353902182

Epoch: 174| Step: 0
Training loss: 2.572612762451172
Validation loss: 2.0192554612313547

Epoch: 5| Step: 1
Training loss: 1.8880159854888916
Validation loss: 2.0316539502912954

Epoch: 5| Step: 2
Training loss: 1.4184547662734985
Validation loss: 2.0393426379849835

Epoch: 5| Step: 3
Training loss: 1.8165363073349
Validation loss: 2.0458503295016546

Epoch: 5| Step: 4
Training loss: 1.6034435033798218
Validation loss: 2.036635201464417

Epoch: 5| Step: 5
Training loss: 2.1171951293945312
Validation loss: 2.023251924463498

Epoch: 5| Step: 6
Training loss: 1.458404779434204
Validation loss: 2.0093401811456166

Epoch: 5| Step: 7
Training loss: 1.7283605337142944
Validation loss: 2.0256865691113215

Epoch: 5| Step: 8
Training loss: 1.8128364086151123
Validation loss: 2.0305593731582805

Epoch: 5| Step: 9
Training loss: 1.5819305181503296
Validation loss: 2.0255250815422303

Epoch: 5| Step: 10
Training loss: 1.410932183265686
Validation loss: 2.0179798949149346

Epoch: 175| Step: 0
Training loss: 1.4902007579803467
Validation loss: 2.0226208856028896

Epoch: 5| Step: 1
Training loss: 2.1350693702697754
Validation loss: 2.034033111346665

Epoch: 5| Step: 2
Training loss: 2.009162187576294
Validation loss: 2.042352350809241

Epoch: 5| Step: 3
Training loss: 1.5628712177276611
Validation loss: 2.0439227524624077

Epoch: 5| Step: 4
Training loss: 1.9018300771713257
Validation loss: 2.056192424989516

Epoch: 5| Step: 5
Training loss: 1.1778794527053833
Validation loss: 2.0656203839086715

Epoch: 5| Step: 6
Training loss: 2.3022141456604004
Validation loss: 2.0510649834909747

Epoch: 5| Step: 7
Training loss: 2.4170522689819336
Validation loss: 2.0642527918661795

Epoch: 5| Step: 8
Training loss: 1.6970555782318115
Validation loss: 2.0715160523691485

Epoch: 5| Step: 9
Training loss: 0.8068695068359375
Validation loss: 2.042283394003427

Epoch: 5| Step: 10
Training loss: 1.9369540214538574
Validation loss: 2.039426524152038

Epoch: 176| Step: 0
Training loss: 1.2740118503570557
Validation loss: 2.038668371015979

Epoch: 5| Step: 1
Training loss: 1.624428153038025
Validation loss: 2.039194301892352

Epoch: 5| Step: 2
Training loss: 2.0594751834869385
Validation loss: 2.061376364000382

Epoch: 5| Step: 3
Training loss: 2.0238070487976074
Validation loss: 2.0696283707054715

Epoch: 5| Step: 4
Training loss: 2.5226082801818848
Validation loss: 2.0905930367849206

Epoch: 5| Step: 5
Training loss: 2.0605969429016113
Validation loss: 2.1010449137738956

Epoch: 5| Step: 6
Training loss: 1.546081781387329
Validation loss: 2.099753342648988

Epoch: 5| Step: 7
Training loss: 1.898516058921814
Validation loss: 2.0777144483340684

Epoch: 5| Step: 8
Training loss: 1.6114749908447266
Validation loss: 2.0638231205683883

Epoch: 5| Step: 9
Training loss: 1.3414055109024048
Validation loss: 2.0532180147786296

Epoch: 5| Step: 10
Training loss: 1.5306257009506226
Validation loss: 2.055045090695863

Epoch: 177| Step: 0
Training loss: 1.091498613357544
Validation loss: 2.0548130671183267

Epoch: 5| Step: 1
Training loss: 1.7737550735473633
Validation loss: 2.0448883707805345

Epoch: 5| Step: 2
Training loss: 2.276571750640869
Validation loss: 2.0056600109223397

Epoch: 5| Step: 3
Training loss: 1.691946268081665
Validation loss: 1.9697658169654109

Epoch: 5| Step: 4
Training loss: 1.9030215740203857
Validation loss: 1.9743177198594617

Epoch: 5| Step: 5
Training loss: 1.8140567541122437
Validation loss: 1.998457318993025

Epoch: 5| Step: 6
Training loss: 1.5498135089874268
Validation loss: 2.018314230826593

Epoch: 5| Step: 7
Training loss: 1.7884037494659424
Validation loss: 2.0230807309509604

Epoch: 5| Step: 8
Training loss: 2.0024919509887695
Validation loss: 2.035939424268661

Epoch: 5| Step: 9
Training loss: 1.8983567953109741
Validation loss: 2.04783962106192

Epoch: 5| Step: 10
Training loss: 2.2495737075805664
Validation loss: 2.0363492529879332

Epoch: 178| Step: 0
Training loss: 1.3990713357925415
Validation loss: 2.0421657664801485

Epoch: 5| Step: 1
Training loss: 2.0471458435058594
Validation loss: 2.0783062032473985

Epoch: 5| Step: 2
Training loss: 2.08445143699646
Validation loss: 2.1175326070477887

Epoch: 5| Step: 3
Training loss: 2.0488078594207764
Validation loss: 2.1101450971377793

Epoch: 5| Step: 4
Training loss: 2.243130922317505
Validation loss: 2.102105330395442

Epoch: 5| Step: 5
Training loss: 1.979241132736206
Validation loss: 2.056245402623248

Epoch: 5| Step: 6
Training loss: 1.9209703207015991
Validation loss: 2.018627065484242

Epoch: 5| Step: 7
Training loss: 1.537113904953003
Validation loss: 2.018163493243597

Epoch: 5| Step: 8
Training loss: 1.1120145320892334
Validation loss: 2.0362720950957267

Epoch: 5| Step: 9
Training loss: 1.571238398551941
Validation loss: 2.0394976985070015

Epoch: 5| Step: 10
Training loss: 1.4768388271331787
Validation loss: 2.035793727444064

Epoch: 179| Step: 0
Training loss: 1.2530877590179443
Validation loss: 2.0437864334352556

Epoch: 5| Step: 1
Training loss: 2.4206666946411133
Validation loss: 2.0886809774624404

Epoch: 5| Step: 2
Training loss: 2.268993377685547
Validation loss: 2.1486812201879357

Epoch: 5| Step: 3
Training loss: 1.6533206701278687
Validation loss: 2.1782136860714165

Epoch: 5| Step: 4
Training loss: 2.1313648223876953
Validation loss: 2.2051240013491724

Epoch: 5| Step: 5
Training loss: 1.4281930923461914
Validation loss: 2.1627569736972934

Epoch: 5| Step: 6
Training loss: 1.8586517572402954
Validation loss: 2.1069359292266188

Epoch: 5| Step: 7
Training loss: 1.4351470470428467
Validation loss: 2.102729760190492

Epoch: 5| Step: 8
Training loss: 1.5968339443206787
Validation loss: 2.0755666673824353

Epoch: 5| Step: 9
Training loss: 1.8189197778701782
Validation loss: 2.0762125035767913

Epoch: 5| Step: 10
Training loss: 1.6691887378692627
Validation loss: 2.0775853305734615

Epoch: 180| Step: 0
Training loss: 1.561044692993164
Validation loss: 2.070922387543545

Epoch: 5| Step: 1
Training loss: 1.7596107721328735
Validation loss: 2.023974044348604

Epoch: 5| Step: 2
Training loss: 1.406903624534607
Validation loss: 2.023927027179349

Epoch: 5| Step: 3
Training loss: 2.313227653503418
Validation loss: 2.0173100681715113

Epoch: 5| Step: 4
Training loss: 2.0779049396514893
Validation loss: 2.033531568383658

Epoch: 5| Step: 5
Training loss: 1.953697919845581
Validation loss: 2.0561504415286485

Epoch: 5| Step: 6
Training loss: 1.9715808629989624
Validation loss: 2.048305660165766

Epoch: 5| Step: 7
Training loss: 1.2941076755523682
Validation loss: 2.048471276478101

Epoch: 5| Step: 8
Training loss: 1.4160845279693604
Validation loss: 2.0381614597894813

Epoch: 5| Step: 9
Training loss: 1.1685301065444946
Validation loss: 2.0401355297334733

Epoch: 5| Step: 10
Training loss: 2.1534481048583984
Validation loss: 2.0414585990290486

Epoch: 181| Step: 0
Training loss: 2.13494610786438
Validation loss: 2.020959322170545

Epoch: 5| Step: 1
Training loss: 0.9996536374092102
Validation loss: 2.0440235266121487

Epoch: 5| Step: 2
Training loss: 1.3591054677963257
Validation loss: 2.054015577480357

Epoch: 5| Step: 3
Training loss: 1.892203688621521
Validation loss: 2.0736254492113666

Epoch: 5| Step: 4
Training loss: 1.9116346836090088
Validation loss: 2.1019739104855444

Epoch: 5| Step: 5
Training loss: 1.8803021907806396
Validation loss: 2.0871840600044496

Epoch: 5| Step: 6
Training loss: 1.4110666513442993
Validation loss: 2.0963221250041837

Epoch: 5| Step: 7
Training loss: 1.9065673351287842
Validation loss: 2.0932387792935936

Epoch: 5| Step: 8
Training loss: 2.0224342346191406
Validation loss: 2.063599003258572

Epoch: 5| Step: 9
Training loss: 1.6432911157608032
Validation loss: 2.0313881263938

Epoch: 5| Step: 10
Training loss: 1.7555150985717773
Validation loss: 2.0409520018485283

Epoch: 182| Step: 0
Training loss: 1.8041017055511475
Validation loss: 2.028162060245391

Epoch: 5| Step: 1
Training loss: 1.5468722581863403
Validation loss: 2.0336180899732854

Epoch: 5| Step: 2
Training loss: 2.4027068614959717
Validation loss: 2.00830659045968

Epoch: 5| Step: 3
Training loss: 2.116772413253784
Validation loss: 2.0071871370397587

Epoch: 5| Step: 4
Training loss: 1.6208633184432983
Validation loss: 2.0177134570255073

Epoch: 5| Step: 5
Training loss: 1.4725918769836426
Validation loss: 2.038280342214851

Epoch: 5| Step: 6
Training loss: 1.5915971994400024
Validation loss: 2.037476493466285

Epoch: 5| Step: 7
Training loss: 2.01078200340271
Validation loss: 2.0452745742695306

Epoch: 5| Step: 8
Training loss: 1.4079946279525757
Validation loss: 2.0500994766912153

Epoch: 5| Step: 9
Training loss: 1.3539599180221558
Validation loss: 2.043045215709235

Epoch: 5| Step: 10
Training loss: 1.3747062683105469
Validation loss: 2.0618983161064888

Epoch: 183| Step: 0
Training loss: 1.3843899965286255
Validation loss: 2.099315144682443

Epoch: 5| Step: 1
Training loss: 1.6987144947052002
Validation loss: 2.1222893307285924

Epoch: 5| Step: 2
Training loss: 1.2362514734268188
Validation loss: 2.1131407983841433

Epoch: 5| Step: 3
Training loss: 1.7774816751480103
Validation loss: 2.088534196217855

Epoch: 5| Step: 4
Training loss: 2.0504982471466064
Validation loss: 2.0675878934962775

Epoch: 5| Step: 5
Training loss: 2.2419373989105225
Validation loss: 2.0649945479567333

Epoch: 5| Step: 6
Training loss: 1.6541213989257812
Validation loss: 2.0640539405166463

Epoch: 5| Step: 7
Training loss: 1.667532205581665
Validation loss: 2.0582134595481296

Epoch: 5| Step: 8
Training loss: 1.8998289108276367
Validation loss: 2.030638143580447

Epoch: 5| Step: 9
Training loss: 1.4265538454055786
Validation loss: 2.0322352404235513

Epoch: 5| Step: 10
Training loss: 1.752010703086853
Validation loss: 2.0529575527355237

Epoch: 184| Step: 0
Training loss: 1.5098519325256348
Validation loss: 2.036077768571915

Epoch: 5| Step: 1
Training loss: 1.6045595407485962
Validation loss: 2.0271341903235323

Epoch: 5| Step: 2
Training loss: 1.8874973058700562
Validation loss: 2.0130084201853764

Epoch: 5| Step: 3
Training loss: 1.663413405418396
Validation loss: 2.0104973021373955

Epoch: 5| Step: 4
Training loss: 2.0069680213928223
Validation loss: 2.0121623777574107

Epoch: 5| Step: 5
Training loss: 1.3886516094207764
Validation loss: 2.0278002421061196

Epoch: 5| Step: 6
Training loss: 1.3508756160736084
Validation loss: 2.04103833629239

Epoch: 5| Step: 7
Training loss: 2.3017988204956055
Validation loss: 2.056123564320226

Epoch: 5| Step: 8
Training loss: 1.5432026386260986
Validation loss: 2.0713875985914663

Epoch: 5| Step: 9
Training loss: 1.5883153676986694
Validation loss: 2.0880372242261003

Epoch: 5| Step: 10
Training loss: 1.6030558347702026
Validation loss: 2.081290885966311

Epoch: 185| Step: 0
Training loss: 1.5072674751281738
Validation loss: 2.048193508578885

Epoch: 5| Step: 1
Training loss: 2.1302809715270996
Validation loss: 2.026118351567176

Epoch: 5| Step: 2
Training loss: 1.2155513763427734
Validation loss: 1.985720625487707

Epoch: 5| Step: 3
Training loss: 1.9280567169189453
Validation loss: 1.9943291141140846

Epoch: 5| Step: 4
Training loss: 1.785011649131775
Validation loss: 1.9733927275544854

Epoch: 5| Step: 5
Training loss: 1.4589892625808716
Validation loss: 1.96611883178834

Epoch: 5| Step: 6
Training loss: 1.586694359779358
Validation loss: 1.9696239502199235

Epoch: 5| Step: 7
Training loss: 1.7897850275039673
Validation loss: 1.954439745154432

Epoch: 5| Step: 8
Training loss: 1.4687860012054443
Validation loss: 1.96650864231971

Epoch: 5| Step: 9
Training loss: 1.773911714553833
Validation loss: 1.9543586302829046

Epoch: 5| Step: 10
Training loss: 1.8949284553527832
Validation loss: 1.9837182106510285

Epoch: 186| Step: 0
Training loss: 1.249786615371704
Validation loss: 1.9936254575688352

Epoch: 5| Step: 1
Training loss: 1.746530532836914
Validation loss: 2.002469511442287

Epoch: 5| Step: 2
Training loss: 1.877868890762329
Validation loss: 2.040475037790114

Epoch: 5| Step: 3
Training loss: 1.7662633657455444
Validation loss: 2.045428542680638

Epoch: 5| Step: 4
Training loss: 1.4479572772979736
Validation loss: 2.0680742853431293

Epoch: 5| Step: 5
Training loss: 1.1033838987350464
Validation loss: 2.0701873097368466

Epoch: 5| Step: 6
Training loss: 1.6638399362564087
Validation loss: 2.0610903283601165

Epoch: 5| Step: 7
Training loss: 1.3696725368499756
Validation loss: 2.048394057058519

Epoch: 5| Step: 8
Training loss: 1.887518286705017
Validation loss: 2.0270998849663684

Epoch: 5| Step: 9
Training loss: 2.3327443599700928
Validation loss: 2.01260942797507

Epoch: 5| Step: 10
Training loss: 1.4980884790420532
Validation loss: 1.988067303934405

Epoch: 187| Step: 0
Training loss: 1.4887995719909668
Validation loss: 1.9921519269225418

Epoch: 5| Step: 1
Training loss: 2.0506110191345215
Validation loss: 1.9784369878871466

Epoch: 5| Step: 2
Training loss: 1.6397842168807983
Validation loss: 1.9840873774661814

Epoch: 5| Step: 3
Training loss: 1.481878399848938
Validation loss: 1.9986705446756015

Epoch: 5| Step: 4
Training loss: 1.5174921751022339
Validation loss: 1.9819048655930387

Epoch: 5| Step: 5
Training loss: 2.3674609661102295
Validation loss: 1.9882754228448356

Epoch: 5| Step: 6
Training loss: 1.5139987468719482
Validation loss: 2.0021213716076267

Epoch: 5| Step: 7
Training loss: 1.7820638418197632
Validation loss: 2.016526342720114

Epoch: 5| Step: 8
Training loss: 2.025106430053711
Validation loss: 2.0290059645970664

Epoch: 5| Step: 9
Training loss: 1.1256234645843506
Validation loss: 1.9976792027873378

Epoch: 5| Step: 10
Training loss: 1.3282994031906128
Validation loss: 2.0069665703722226

Epoch: 188| Step: 0
Training loss: 1.03652024269104
Validation loss: 2.0140989544571086

Epoch: 5| Step: 1
Training loss: 1.5542974472045898
Validation loss: 2.004333280747937

Epoch: 5| Step: 2
Training loss: 2.101660966873169
Validation loss: 2.0291810509979085

Epoch: 5| Step: 3
Training loss: 1.3917144536972046
Validation loss: 2.0375169656609975

Epoch: 5| Step: 4
Training loss: 1.3975938558578491
Validation loss: 2.0188038887516147

Epoch: 5| Step: 5
Training loss: 1.6623656749725342
Validation loss: 2.015128561245498

Epoch: 5| Step: 6
Training loss: 1.5482358932495117
Validation loss: 2.0066776660180863

Epoch: 5| Step: 7
Training loss: 1.483551263809204
Validation loss: 1.9845852390412362

Epoch: 5| Step: 8
Training loss: 1.655186414718628
Validation loss: 2.0077980923396286

Epoch: 5| Step: 9
Training loss: 2.028886079788208
Validation loss: 1.986387388680571

Epoch: 5| Step: 10
Training loss: 2.1307332515716553
Validation loss: 1.9942681404852098

Epoch: 189| Step: 0
Training loss: 1.2530609369277954
Validation loss: 2.0002486603234404

Epoch: 5| Step: 1
Training loss: 1.8971431255340576
Validation loss: 1.9995672446425243

Epoch: 5| Step: 2
Training loss: 1.6523348093032837
Validation loss: 1.9991987623194212

Epoch: 5| Step: 3
Training loss: 1.6095304489135742
Validation loss: 2.0380665973950456

Epoch: 5| Step: 4
Training loss: 1.8869785070419312
Validation loss: 2.0273064374923706

Epoch: 5| Step: 5
Training loss: 1.650005578994751
Validation loss: 2.0281252079112555

Epoch: 5| Step: 6
Training loss: 1.256601333618164
Validation loss: 2.0254736920838714

Epoch: 5| Step: 7
Training loss: 2.0553715229034424
Validation loss: 2.0082548433734524

Epoch: 5| Step: 8
Training loss: 1.6428680419921875
Validation loss: 2.005812173248619

Epoch: 5| Step: 9
Training loss: 1.598235845565796
Validation loss: 2.0130787177752425

Epoch: 5| Step: 10
Training loss: 1.1994646787643433
Validation loss: 2.0308827174607145

Epoch: 190| Step: 0
Training loss: 1.1190636157989502
Validation loss: 2.0105860720398607

Epoch: 5| Step: 1
Training loss: 1.3705092668533325
Validation loss: 2.0075162610700055

Epoch: 5| Step: 2
Training loss: 1.173790693283081
Validation loss: 2.0187665775258052

Epoch: 5| Step: 3
Training loss: 1.8962171077728271
Validation loss: 2.013798976457247

Epoch: 5| Step: 4
Training loss: 1.1104907989501953
Validation loss: 2.0131643267088037

Epoch: 5| Step: 5
Training loss: 1.2188819646835327
Validation loss: 2.0274952457797144

Epoch: 5| Step: 6
Training loss: 1.969726800918579
Validation loss: 2.026819658535783

Epoch: 5| Step: 7
Training loss: 2.366532802581787
Validation loss: 2.020801615971391

Epoch: 5| Step: 8
Training loss: 1.8174842596054077
Validation loss: 2.0326842351626326

Epoch: 5| Step: 9
Training loss: 1.6460479497909546
Validation loss: 2.0215465702036375

Epoch: 5| Step: 10
Training loss: 2.057551145553589
Validation loss: 2.029120058141729

Epoch: 191| Step: 0
Training loss: 1.4193665981292725
Validation loss: 2.031346155751136

Epoch: 5| Step: 1
Training loss: 1.7439368963241577
Validation loss: 2.0294015048652567

Epoch: 5| Step: 2
Training loss: 1.0837230682373047
Validation loss: 2.029882650221548

Epoch: 5| Step: 3
Training loss: 1.7898502349853516
Validation loss: 2.0003289779027305

Epoch: 5| Step: 4
Training loss: 1.9411811828613281
Validation loss: 1.9956963164832002

Epoch: 5| Step: 5
Training loss: 1.6524450778961182
Validation loss: 1.987846310420703

Epoch: 5| Step: 6
Training loss: 2.0999326705932617
Validation loss: 1.968278859251289

Epoch: 5| Step: 7
Training loss: 1.6111040115356445
Validation loss: 1.9716008965687086

Epoch: 5| Step: 8
Training loss: 1.165793776512146
Validation loss: 1.9693999931376467

Epoch: 5| Step: 9
Training loss: 1.3844115734100342
Validation loss: 2.0038171481060725

Epoch: 5| Step: 10
Training loss: 1.9381263256072998
Validation loss: 2.0266991751168364

Epoch: 192| Step: 0
Training loss: 1.5100648403167725
Validation loss: 2.0314400657530753

Epoch: 5| Step: 1
Training loss: 2.386453151702881
Validation loss: 2.0642751455307007

Epoch: 5| Step: 2
Training loss: 1.4617191553115845
Validation loss: 2.059794008090932

Epoch: 5| Step: 3
Training loss: 1.3805959224700928
Validation loss: 2.073367453390552

Epoch: 5| Step: 4
Training loss: 1.3033065795898438
Validation loss: 2.054915658889278

Epoch: 5| Step: 5
Training loss: 1.2160968780517578
Validation loss: 2.0393530502114245

Epoch: 5| Step: 6
Training loss: 2.1353697776794434
Validation loss: 2.025298262155184

Epoch: 5| Step: 7
Training loss: 1.4592115879058838
Validation loss: 2.0253505091513357

Epoch: 5| Step: 8
Training loss: 1.1559064388275146
Validation loss: 2.0026736772188576

Epoch: 5| Step: 9
Training loss: 1.7083947658538818
Validation loss: 1.993594459308091

Epoch: 5| Step: 10
Training loss: 1.7292768955230713
Validation loss: 1.992531882819309

Epoch: 193| Step: 0
Training loss: 1.9296804666519165
Validation loss: 1.9877363635647682

Epoch: 5| Step: 1
Training loss: 1.881158471107483
Validation loss: 1.9982708910460114

Epoch: 5| Step: 2
Training loss: 1.9087316989898682
Validation loss: 2.0082840188857047

Epoch: 5| Step: 3
Training loss: 1.6762645244598389
Validation loss: 2.017479141553243

Epoch: 5| Step: 4
Training loss: 1.1477012634277344
Validation loss: 2.0228801132530294

Epoch: 5| Step: 5
Training loss: 1.1441256999969482
Validation loss: 2.033371735644597

Epoch: 5| Step: 6
Training loss: 1.2358297109603882
Validation loss: 2.02583477317646

Epoch: 5| Step: 7
Training loss: 1.2246166467666626
Validation loss: 2.0301083134066675

Epoch: 5| Step: 8
Training loss: 1.8862230777740479
Validation loss: 2.0325226886298067

Epoch: 5| Step: 9
Training loss: 1.4513119459152222
Validation loss: 2.0264073725669616

Epoch: 5| Step: 10
Training loss: 1.7015225887298584
Validation loss: 2.015179713567098

Epoch: 194| Step: 0
Training loss: 1.6149705648422241
Validation loss: 2.0110545414750294

Epoch: 5| Step: 1
Training loss: 1.4859641790390015
Validation loss: 2.0092213692203647

Epoch: 5| Step: 2
Training loss: 1.485116958618164
Validation loss: 1.99197494599127

Epoch: 5| Step: 3
Training loss: 1.2875397205352783
Validation loss: 1.9948273474170315

Epoch: 5| Step: 4
Training loss: 2.1957814693450928
Validation loss: 2.0036606134906894

Epoch: 5| Step: 5
Training loss: 1.3529269695281982
Validation loss: 1.9817705000600507

Epoch: 5| Step: 6
Training loss: 1.561958909034729
Validation loss: 1.9828935310404787

Epoch: 5| Step: 7
Training loss: 1.179834246635437
Validation loss: 1.9924358783229705

Epoch: 5| Step: 8
Training loss: 1.4968373775482178
Validation loss: 1.9927732713760868

Epoch: 5| Step: 9
Training loss: 1.7689876556396484
Validation loss: 2.0167873751732612

Epoch: 5| Step: 10
Training loss: 1.689835786819458
Validation loss: 2.0347015434695828

Epoch: 195| Step: 0
Training loss: 1.5912853479385376
Validation loss: 2.037099628038304

Epoch: 5| Step: 1
Training loss: 1.8827069997787476
Validation loss: 2.0533641205039075

Epoch: 5| Step: 2
Training loss: 1.2882152795791626
Validation loss: 2.060361817318906

Epoch: 5| Step: 3
Training loss: 1.2960230112075806
Validation loss: 2.053279674181374

Epoch: 5| Step: 4
Training loss: 1.569482684135437
Validation loss: 2.0048271045889905

Epoch: 5| Step: 5
Training loss: 2.351386308670044
Validation loss: 1.9831385202305292

Epoch: 5| Step: 6
Training loss: 1.2512036561965942
Validation loss: 1.977425161228385

Epoch: 5| Step: 7
Training loss: 1.6650238037109375
Validation loss: 1.958898171301811

Epoch: 5| Step: 8
Training loss: 1.3354618549346924
Validation loss: 1.97700253353324

Epoch: 5| Step: 9
Training loss: 1.1838918924331665
Validation loss: 1.9577738956738544

Epoch: 5| Step: 10
Training loss: 1.7565028667449951
Validation loss: 1.9539189236138457

Epoch: 196| Step: 0
Training loss: 1.7056728601455688
Validation loss: 1.972640247114243

Epoch: 5| Step: 1
Training loss: 1.062522292137146
Validation loss: 2.001897119706677

Epoch: 5| Step: 2
Training loss: 0.9677351117134094
Validation loss: 2.026263999682601

Epoch: 5| Step: 3
Training loss: 1.951331377029419
Validation loss: 2.0530378613420712

Epoch: 5| Step: 4
Training loss: 2.0833334922790527
Validation loss: 2.0801234822119437

Epoch: 5| Step: 5
Training loss: 1.9003117084503174
Validation loss: 2.117417174000894

Epoch: 5| Step: 6
Training loss: 1.6491619348526
Validation loss: 2.0801256805337887

Epoch: 5| Step: 7
Training loss: 2.069031238555908
Validation loss: 2.044919885614867

Epoch: 5| Step: 8
Training loss: 1.3501116037368774
Validation loss: 1.9844774507707166

Epoch: 5| Step: 9
Training loss: 1.4365308284759521
Validation loss: 1.9812643681803057

Epoch: 5| Step: 10
Training loss: 0.9953650236129761
Validation loss: 1.9469292791940833

Epoch: 197| Step: 0
Training loss: 1.5472822189331055
Validation loss: 1.961971616232267

Epoch: 5| Step: 1
Training loss: 1.4249706268310547
Validation loss: 1.9758568476605158

Epoch: 5| Step: 2
Training loss: 1.2568031549453735
Validation loss: 1.9521912938805037

Epoch: 5| Step: 3
Training loss: 1.5147409439086914
Validation loss: 1.9364629586537678

Epoch: 5| Step: 4
Training loss: 1.6322107315063477
Validation loss: 1.962770583809063

Epoch: 5| Step: 5
Training loss: 1.9166024923324585
Validation loss: 1.9518266352274085

Epoch: 5| Step: 6
Training loss: 1.8914178609848022
Validation loss: 1.9705882790268108

Epoch: 5| Step: 7
Training loss: 1.5908035039901733
Validation loss: 1.991753150058049

Epoch: 5| Step: 8
Training loss: 1.7407830953598022
Validation loss: 1.9753221798968572

Epoch: 5| Step: 9
Training loss: 1.1665632724761963
Validation loss: 1.9997008257014777

Epoch: 5| Step: 10
Training loss: 1.3300025463104248
Validation loss: 2.021628072184901

Epoch: 198| Step: 0
Training loss: 1.620091199874878
Validation loss: 2.0441153126378215

Epoch: 5| Step: 1
Training loss: 1.3010027408599854
Validation loss: 2.026952216702123

Epoch: 5| Step: 2
Training loss: 1.7227739095687866
Validation loss: 2.020316844345421

Epoch: 5| Step: 3
Training loss: 1.2885725498199463
Validation loss: 2.027073989632309

Epoch: 5| Step: 4
Training loss: 1.304238200187683
Validation loss: 2.0192343663143855

Epoch: 5| Step: 5
Training loss: 1.8741109371185303
Validation loss: 2.008472563118063

Epoch: 5| Step: 6
Training loss: 1.0979959964752197
Validation loss: 1.9825887026325348

Epoch: 5| Step: 7
Training loss: 2.2517600059509277
Validation loss: 1.9739020780850483

Epoch: 5| Step: 8
Training loss: 1.4537906646728516
Validation loss: 1.9627895803861721

Epoch: 5| Step: 9
Training loss: 1.5763022899627686
Validation loss: 1.9823342164357503

Epoch: 5| Step: 10
Training loss: 1.425554871559143
Validation loss: 2.0136819103712678

Epoch: 199| Step: 0
Training loss: 1.7507671117782593
Validation loss: 1.991501856875676

Epoch: 5| Step: 1
Training loss: 1.6190662384033203
Validation loss: 1.9724526982153616

Epoch: 5| Step: 2
Training loss: 1.4500123262405396
Validation loss: 1.94955285005672

Epoch: 5| Step: 3
Training loss: 1.6820685863494873
Validation loss: 1.9579596493833809

Epoch: 5| Step: 4
Training loss: 1.5014539957046509
Validation loss: 1.9636806416255173

Epoch: 5| Step: 5
Training loss: 1.919134497642517
Validation loss: 1.9807696919287405

Epoch: 5| Step: 6
Training loss: 1.2871482372283936
Validation loss: 1.9989879285135577

Epoch: 5| Step: 7
Training loss: 1.7232307195663452
Validation loss: 1.9888348066678612

Epoch: 5| Step: 8
Training loss: 1.4803133010864258
Validation loss: 1.9947617566713722

Epoch: 5| Step: 9
Training loss: 1.348528265953064
Validation loss: 1.9913978448478125

Epoch: 5| Step: 10
Training loss: 0.9039676785469055
Validation loss: 2.0025120883859615

Epoch: 200| Step: 0
Training loss: 0.846211314201355
Validation loss: 2.0043240900962584

Epoch: 5| Step: 1
Training loss: 1.2598941326141357
Validation loss: 2.02120905153213

Epoch: 5| Step: 2
Training loss: 1.5748794078826904
Validation loss: 2.0094636819695912

Epoch: 5| Step: 3
Training loss: 1.6392654180526733
Validation loss: 2.0182312714156283

Epoch: 5| Step: 4
Training loss: 2.401075839996338
Validation loss: 2.001176111159786

Epoch: 5| Step: 5
Training loss: 1.4514890909194946
Validation loss: 2.02080306442835

Epoch: 5| Step: 6
Training loss: 1.698621392250061
Validation loss: 2.007337849627259

Epoch: 5| Step: 7
Training loss: 1.6702892780303955
Validation loss: 2.000931509079472

Epoch: 5| Step: 8
Training loss: 1.2660586833953857
Validation loss: 1.9852331658845306

Epoch: 5| Step: 9
Training loss: 1.3344260454177856
Validation loss: 1.9523502780545143

Epoch: 5| Step: 10
Training loss: 1.4475483894348145
Validation loss: 1.9497281671852194

Epoch: 201| Step: 0
Training loss: 1.067819356918335
Validation loss: 1.942708033387379

Epoch: 5| Step: 1
Training loss: 2.0651843547821045
Validation loss: 1.9498510373535978

Epoch: 5| Step: 2
Training loss: 1.4805536270141602
Validation loss: 1.968078205662389

Epoch: 5| Step: 3
Training loss: 1.8872287273406982
Validation loss: 1.988541615906582

Epoch: 5| Step: 4
Training loss: 1.4202752113342285
Validation loss: 2.004016714711343

Epoch: 5| Step: 5
Training loss: 1.5626587867736816
Validation loss: 2.0146226011296755

Epoch: 5| Step: 6
Training loss: 1.3145725727081299
Validation loss: 2.019809857491524

Epoch: 5| Step: 7
Training loss: 1.5349448919296265
Validation loss: 2.0217015179254676

Epoch: 5| Step: 8
Training loss: 1.3053460121154785
Validation loss: 2.0106831673652894

Epoch: 5| Step: 9
Training loss: 1.7574570178985596
Validation loss: 2.013137020090575

Epoch: 5| Step: 10
Training loss: 1.2700042724609375
Validation loss: 2.016438279100644

Epoch: 202| Step: 0
Training loss: 2.100510358810425
Validation loss: 1.9883121008514075

Epoch: 5| Step: 1
Training loss: 1.755388855934143
Validation loss: 1.9792233564520394

Epoch: 5| Step: 2
Training loss: 1.7024250030517578
Validation loss: 1.9698281877784318

Epoch: 5| Step: 3
Training loss: 1.207495927810669
Validation loss: 1.942571819469493

Epoch: 5| Step: 4
Training loss: 1.6707813739776611
Validation loss: 1.952109662435388

Epoch: 5| Step: 5
Training loss: 1.7312043905258179
Validation loss: 1.9256683216300061

Epoch: 5| Step: 6
Training loss: 1.1865184307098389
Validation loss: 1.9323848639765093

Epoch: 5| Step: 7
Training loss: 1.1463024616241455
Validation loss: 1.9688907323345062

Epoch: 5| Step: 8
Training loss: 1.062452793121338
Validation loss: 1.9807322409845167

Epoch: 5| Step: 9
Training loss: 1.5724989175796509
Validation loss: 2.0208984741600613

Epoch: 5| Step: 10
Training loss: 1.390458583831787
Validation loss: 2.038670070709721

Epoch: 203| Step: 0
Training loss: 1.8806579113006592
Validation loss: 2.053760977201564

Epoch: 5| Step: 1
Training loss: 1.4715750217437744
Validation loss: 2.041368164041991

Epoch: 5| Step: 2
Training loss: 1.2984726428985596
Validation loss: 2.0156937145417735

Epoch: 5| Step: 3
Training loss: 0.9348213076591492
Validation loss: 1.9934191537159744

Epoch: 5| Step: 4
Training loss: 1.5869576930999756
Validation loss: 1.9925844694978447

Epoch: 5| Step: 5
Training loss: 1.8550275564193726
Validation loss: 1.9790642146141297

Epoch: 5| Step: 6
Training loss: 1.436948299407959
Validation loss: 1.9654173492103495

Epoch: 5| Step: 7
Training loss: 1.7253799438476562
Validation loss: 1.9848535945338588

Epoch: 5| Step: 8
Training loss: 1.907396674156189
Validation loss: 1.9527227494024462

Epoch: 5| Step: 9
Training loss: 1.594881534576416
Validation loss: 1.958854184355787

Epoch: 5| Step: 10
Training loss: 1.1292333602905273
Validation loss: 1.975698224959835

Epoch: 204| Step: 0
Training loss: 1.340366005897522
Validation loss: 2.0060440122440295

Epoch: 5| Step: 1
Training loss: 1.831652045249939
Validation loss: 2.01838594354609

Epoch: 5| Step: 2
Training loss: 0.9738349914550781
Validation loss: 2.0057395401821343

Epoch: 5| Step: 3
Training loss: 1.5353906154632568
Validation loss: 1.9978864641599758

Epoch: 5| Step: 4
Training loss: 1.3035411834716797
Validation loss: 1.9995444948955248

Epoch: 5| Step: 5
Training loss: 1.5516496896743774
Validation loss: 2.0078231929450907

Epoch: 5| Step: 6
Training loss: 1.2592633962631226
Validation loss: 2.008199191862537

Epoch: 5| Step: 7
Training loss: 1.1896164417266846
Validation loss: 2.010532130477249

Epoch: 5| Step: 8
Training loss: 1.5429627895355225
Validation loss: 2.018268842850962

Epoch: 5| Step: 9
Training loss: 1.830916404724121
Validation loss: 2.0065590053476314

Epoch: 5| Step: 10
Training loss: 2.1086976528167725
Validation loss: 1.9876200281163698

Epoch: 205| Step: 0
Training loss: 1.706266164779663
Validation loss: 1.9944794575373332

Epoch: 5| Step: 1
Training loss: 1.6248610019683838
Validation loss: 2.0421112596347766

Epoch: 5| Step: 2
Training loss: 1.8524430990219116
Validation loss: 2.0427270473972445

Epoch: 5| Step: 3
Training loss: 1.610840082168579
Validation loss: 2.0171689166817615

Epoch: 5| Step: 4
Training loss: 1.5899590253829956
Validation loss: 1.9955874437926917

Epoch: 5| Step: 5
Training loss: 1.235014796257019
Validation loss: 1.9602402256381126

Epoch: 5| Step: 6
Training loss: 1.3058913946151733
Validation loss: 1.9421539639913907

Epoch: 5| Step: 7
Training loss: 1.1426465511322021
Validation loss: 1.962598382785756

Epoch: 5| Step: 8
Training loss: 1.4012702703475952
Validation loss: 1.9617424600867814

Epoch: 5| Step: 9
Training loss: 1.8354101181030273
Validation loss: 1.975503554908178

Epoch: 5| Step: 10
Training loss: 1.2177248001098633
Validation loss: 1.9442106716094478

Epoch: 206| Step: 0
Training loss: 1.2732418775558472
Validation loss: 1.9669979310804797

Epoch: 5| Step: 1
Training loss: 0.990725040435791
Validation loss: 2.0303352455939017

Epoch: 5| Step: 2
Training loss: 1.8055658340454102
Validation loss: 2.1358626709189465

Epoch: 5| Step: 3
Training loss: 1.251347303390503
Validation loss: 2.161555761932045

Epoch: 5| Step: 4
Training loss: 1.353868842124939
Validation loss: 2.1108133357058287

Epoch: 5| Step: 5
Training loss: 2.2230422496795654
Validation loss: 2.060725373606528

Epoch: 5| Step: 6
Training loss: 1.8105289936065674
Validation loss: 2.0188021300941386

Epoch: 5| Step: 7
Training loss: 1.8480939865112305
Validation loss: 1.9729830667536745

Epoch: 5| Step: 8
Training loss: 1.044411063194275
Validation loss: 1.9812225654561033

Epoch: 5| Step: 9
Training loss: 1.2406489849090576
Validation loss: 1.9907090843364756

Epoch: 5| Step: 10
Training loss: 2.062112331390381
Validation loss: 1.9718903328782769

Epoch: 207| Step: 0
Training loss: 1.1312205791473389
Validation loss: 1.9672242761940084

Epoch: 5| Step: 1
Training loss: 1.3273265361785889
Validation loss: 1.937534761685197

Epoch: 5| Step: 2
Training loss: 1.3842170238494873
Validation loss: 1.9463392060290101

Epoch: 5| Step: 3
Training loss: 1.2896980047225952
Validation loss: 1.9481129505301034

Epoch: 5| Step: 4
Training loss: 2.0270285606384277
Validation loss: 1.988775263550461

Epoch: 5| Step: 5
Training loss: 2.119560956954956
Validation loss: 2.0423695464288034

Epoch: 5| Step: 6
Training loss: 1.1431013345718384
Validation loss: 2.0834586158875497

Epoch: 5| Step: 7
Training loss: 1.5100678205490112
Validation loss: 2.0802508118332073

Epoch: 5| Step: 8
Training loss: 1.3220762014389038
Validation loss: 1.9988127088034024

Epoch: 5| Step: 9
Training loss: 1.4239838123321533
Validation loss: 1.9634208140834686

Epoch: 5| Step: 10
Training loss: 1.6674766540527344
Validation loss: 1.9386964690300725

Epoch: 208| Step: 0
Training loss: 1.1751689910888672
Validation loss: 1.9739316701889038

Epoch: 5| Step: 1
Training loss: 2.2597222328186035
Validation loss: 1.960920444098852

Epoch: 5| Step: 2
Training loss: 1.2780015468597412
Validation loss: 1.9492436070596018

Epoch: 5| Step: 3
Training loss: 1.4689266681671143
Validation loss: 1.9535236076642108

Epoch: 5| Step: 4
Training loss: 1.1650125980377197
Validation loss: 1.96235502407115

Epoch: 5| Step: 5
Training loss: 1.587969422340393
Validation loss: 1.984862187857269

Epoch: 5| Step: 6
Training loss: 1.3125793933868408
Validation loss: 2.0076587277074016

Epoch: 5| Step: 7
Training loss: 1.4505459070205688
Validation loss: 2.0585742304402013

Epoch: 5| Step: 8
Training loss: 1.56243896484375
Validation loss: 2.034718241742862

Epoch: 5| Step: 9
Training loss: 1.7464485168457031
Validation loss: 1.9856941007798719

Epoch: 5| Step: 10
Training loss: 1.2499674558639526
Validation loss: 1.9556608969165432

Epoch: 209| Step: 0
Training loss: 1.4428569078445435
Validation loss: 1.9434647355028378

Epoch: 5| Step: 1
Training loss: 1.3381580114364624
Validation loss: 1.9306230416861914

Epoch: 5| Step: 2
Training loss: 1.6403119564056396
Validation loss: 1.9299252481870754

Epoch: 5| Step: 3
Training loss: 1.8201926946640015
Validation loss: 1.9428043929479455

Epoch: 5| Step: 4
Training loss: 0.9573545455932617
Validation loss: 1.9544790983200073

Epoch: 5| Step: 5
Training loss: 1.5735493898391724
Validation loss: 1.9439455411767448

Epoch: 5| Step: 6
Training loss: 1.853727102279663
Validation loss: 1.926929650768157

Epoch: 5| Step: 7
Training loss: 1.815842628479004
Validation loss: 1.9371065132079586

Epoch: 5| Step: 8
Training loss: 1.130929946899414
Validation loss: 1.9472318182709396

Epoch: 5| Step: 9
Training loss: 1.1032235622406006
Validation loss: 1.9512003288474133

Epoch: 5| Step: 10
Training loss: 1.0898008346557617
Validation loss: 1.963200000024611

Epoch: 210| Step: 0
Training loss: 1.3989989757537842
Validation loss: 1.9881664834996706

Epoch: 5| Step: 1
Training loss: 1.7506835460662842
Validation loss: 2.0036386084812943

Epoch: 5| Step: 2
Training loss: 1.1565486192703247
Validation loss: 2.0175774020533406

Epoch: 5| Step: 3
Training loss: 2.0711817741394043
Validation loss: 2.0233488185431368

Epoch: 5| Step: 4
Training loss: 1.102863073348999
Validation loss: 2.00941397554131

Epoch: 5| Step: 5
Training loss: 1.3035449981689453
Validation loss: 1.9955506837496193

Epoch: 5| Step: 6
Training loss: 1.3075889348983765
Validation loss: 2.012746534039897

Epoch: 5| Step: 7
Training loss: 1.509216547012329
Validation loss: 1.9990045896140478

Epoch: 5| Step: 8
Training loss: 1.1744825839996338
Validation loss: 2.005388249633133

Epoch: 5| Step: 9
Training loss: 1.860149621963501
Validation loss: 2.010867057308074

Epoch: 5| Step: 10
Training loss: 1.1286392211914062
Validation loss: 2.0086770339678695

Epoch: 211| Step: 0
Training loss: 2.011326551437378
Validation loss: 2.0334748324527534

Epoch: 5| Step: 1
Training loss: 1.365468978881836
Validation loss: 2.0241640742107103

Epoch: 5| Step: 2
Training loss: 1.7958316802978516
Validation loss: 2.0252267929815475

Epoch: 5| Step: 3
Training loss: 0.8751891851425171
Validation loss: 2.0479012638010006

Epoch: 5| Step: 4
Training loss: 1.99126398563385
Validation loss: 2.0529367205917195

Epoch: 5| Step: 5
Training loss: 0.8220694661140442
Validation loss: 2.0168072690245924

Epoch: 5| Step: 6
Training loss: 1.3879547119140625
Validation loss: 1.9825968204006073

Epoch: 5| Step: 7
Training loss: 1.3703067302703857
Validation loss: 1.9864321806097542

Epoch: 5| Step: 8
Training loss: 1.1336358785629272
Validation loss: 1.9846101960828226

Epoch: 5| Step: 9
Training loss: 1.723446249961853
Validation loss: 1.9724217525092504

Epoch: 5| Step: 10
Training loss: 1.1863329410552979
Validation loss: 1.9811930041159354

Epoch: 212| Step: 0
Training loss: 1.6210639476776123
Validation loss: 1.9456971409500285

Epoch: 5| Step: 1
Training loss: 1.3801039457321167
Validation loss: 1.9460435003362677

Epoch: 5| Step: 2
Training loss: 1.5968115329742432
Validation loss: 1.9500968584450342

Epoch: 5| Step: 3
Training loss: 0.9777609705924988
Validation loss: 1.9427804139352614

Epoch: 5| Step: 4
Training loss: 1.5201036930084229
Validation loss: 1.9377700539045437

Epoch: 5| Step: 5
Training loss: 1.5200259685516357
Validation loss: 1.9469351973584903

Epoch: 5| Step: 6
Training loss: 1.200485348701477
Validation loss: 1.953198230394753

Epoch: 5| Step: 7
Training loss: 1.3274415731430054
Validation loss: 1.9952734695967806

Epoch: 5| Step: 8
Training loss: 1.6083755493164062
Validation loss: 1.9837128193147722

Epoch: 5| Step: 9
Training loss: 1.1542381048202515
Validation loss: 2.024632469300301

Epoch: 5| Step: 10
Training loss: 1.6911205053329468
Validation loss: 2.0417100165479924

Epoch: 213| Step: 0
Training loss: 1.36173677444458
Validation loss: 2.0154370005412767

Epoch: 5| Step: 1
Training loss: 1.6217139959335327
Validation loss: 1.960734809598615

Epoch: 5| Step: 2
Training loss: 1.1940953731536865
Validation loss: 1.932385322868183

Epoch: 5| Step: 3
Training loss: 1.39198637008667
Validation loss: 1.9081153792719687

Epoch: 5| Step: 4
Training loss: 2.048476457595825
Validation loss: 1.9012650238570346

Epoch: 5| Step: 5
Training loss: 1.3257019519805908
Validation loss: 1.901008580320625

Epoch: 5| Step: 6
Training loss: 1.0995467901229858
Validation loss: 1.9126888846838346

Epoch: 5| Step: 7
Training loss: 1.8502070903778076
Validation loss: 1.9304877814426218

Epoch: 5| Step: 8
Training loss: 1.0552995204925537
Validation loss: 1.9504760388405091

Epoch: 5| Step: 9
Training loss: 1.4637360572814941
Validation loss: 1.9686209232576433

Epoch: 5| Step: 10
Training loss: 0.9827711582183838
Validation loss: 1.9674744067653533

Epoch: 214| Step: 0
Training loss: 2.011246681213379
Validation loss: 1.984484923783169

Epoch: 5| Step: 1
Training loss: 1.0083032846450806
Validation loss: 2.005765297079599

Epoch: 5| Step: 2
Training loss: 1.662170648574829
Validation loss: 2.0094588136160247

Epoch: 5| Step: 3
Training loss: 1.4116952419281006
Validation loss: 2.0145040814594557

Epoch: 5| Step: 4
Training loss: 1.3972303867340088
Validation loss: 2.0307846069335938

Epoch: 5| Step: 5
Training loss: 1.2213640213012695
Validation loss: 2.0222626091331564

Epoch: 5| Step: 6
Training loss: 1.3678444623947144
Validation loss: 1.9852839746782858

Epoch: 5| Step: 7
Training loss: 1.4381210803985596
Validation loss: 1.9694056331470449

Epoch: 5| Step: 8
Training loss: 1.1252974271774292
Validation loss: 1.9599468233764812

Epoch: 5| Step: 9
Training loss: 1.2280032634735107
Validation loss: 1.933310870201357

Epoch: 5| Step: 10
Training loss: 1.6033060550689697
Validation loss: 1.9390099702342865

Epoch: 215| Step: 0
Training loss: 1.4046775102615356
Validation loss: 1.9307680386368946

Epoch: 5| Step: 1
Training loss: 1.768625020980835
Validation loss: 1.9561476066548338

Epoch: 5| Step: 2
Training loss: 1.1567317247390747
Validation loss: 1.9765811466401624

Epoch: 5| Step: 3
Training loss: 1.894892692565918
Validation loss: 1.966466414031162

Epoch: 5| Step: 4
Training loss: 1.2528154850006104
Validation loss: 1.9592245958184684

Epoch: 5| Step: 5
Training loss: 1.0094906091690063
Validation loss: 1.9749864045009817

Epoch: 5| Step: 6
Training loss: 1.0795986652374268
Validation loss: 1.9610163960405576

Epoch: 5| Step: 7
Training loss: 1.6467459201812744
Validation loss: 1.976839933344113

Epoch: 5| Step: 8
Training loss: 0.6622501611709595
Validation loss: 1.975292456406419

Epoch: 5| Step: 9
Training loss: 1.6456413269042969
Validation loss: 1.9879619690679735

Epoch: 5| Step: 10
Training loss: 2.106238842010498
Validation loss: 1.974893263591233

Epoch: 216| Step: 0
Training loss: 1.1072957515716553
Validation loss: 1.9260325342096307

Epoch: 5| Step: 1
Training loss: 2.0132548809051514
Validation loss: 1.92665772796959

Epoch: 5| Step: 2
Training loss: 1.614672303199768
Validation loss: 1.9133853630353046

Epoch: 5| Step: 3
Training loss: 1.9366371631622314
Validation loss: 1.9375782218030704

Epoch: 5| Step: 4
Training loss: 1.3156088590621948
Validation loss: 1.9569891075934134

Epoch: 5| Step: 5
Training loss: 1.2576446533203125
Validation loss: 1.9484840593030375

Epoch: 5| Step: 6
Training loss: 1.088172197341919
Validation loss: 1.9693740824217438

Epoch: 5| Step: 7
Training loss: 1.4311829805374146
Validation loss: 1.9468916064949446

Epoch: 5| Step: 8
Training loss: 1.2190204858779907
Validation loss: 1.9684019037472305

Epoch: 5| Step: 9
Training loss: 0.954001247882843
Validation loss: 1.969059992862004

Epoch: 5| Step: 10
Training loss: 0.9047608375549316
Validation loss: 1.9535576951119207

Epoch: 217| Step: 0
Training loss: 1.748255968093872
Validation loss: 1.9814863333138086

Epoch: 5| Step: 1
Training loss: 1.152639627456665
Validation loss: 1.9924999155024046

Epoch: 5| Step: 2
Training loss: 1.3611308336257935
Validation loss: 1.988717464349603

Epoch: 5| Step: 3
Training loss: 1.3205349445343018
Validation loss: 2.00516999665127

Epoch: 5| Step: 4
Training loss: 1.8450170755386353
Validation loss: 1.9921315421340287

Epoch: 5| Step: 5
Training loss: 1.3278801441192627
Validation loss: 2.003963619150141

Epoch: 5| Step: 6
Training loss: 1.144848346710205
Validation loss: 1.996608482894077

Epoch: 5| Step: 7
Training loss: 1.244945764541626
Validation loss: 1.9889995269877936

Epoch: 5| Step: 8
Training loss: 1.1528511047363281
Validation loss: 1.9425351952993741

Epoch: 5| Step: 9
Training loss: 1.2028625011444092
Validation loss: 1.9140846844642394

Epoch: 5| Step: 10
Training loss: 1.4920768737792969
Validation loss: 1.9127390487219698

Epoch: 218| Step: 0
Training loss: 1.3452074527740479
Validation loss: 1.9109052086389193

Epoch: 5| Step: 1
Training loss: 1.4531161785125732
Validation loss: 1.9142155416550175

Epoch: 5| Step: 2
Training loss: 1.2836300134658813
Validation loss: 1.924852454534141

Epoch: 5| Step: 3
Training loss: 1.1082462072372437
Validation loss: 1.9363760230361775

Epoch: 5| Step: 4
Training loss: 1.2407844066619873
Validation loss: 1.9368599435334564

Epoch: 5| Step: 5
Training loss: 1.3044650554656982
Validation loss: 1.9543486897663405

Epoch: 5| Step: 6
Training loss: 1.4727113246917725
Validation loss: 1.990096845934468

Epoch: 5| Step: 7
Training loss: 1.2765594720840454
Validation loss: 2.022881628364645

Epoch: 5| Step: 8
Training loss: 1.5911718606948853
Validation loss: 2.0262691231184107

Epoch: 5| Step: 9
Training loss: 1.5620129108428955
Validation loss: 1.9848760917622557

Epoch: 5| Step: 10
Training loss: 1.3119263648986816
Validation loss: 1.9639488984179754

Epoch: 219| Step: 0
Training loss: 1.1486527919769287
Validation loss: 1.9437116346051615

Epoch: 5| Step: 1
Training loss: 1.0440467596054077
Validation loss: 1.9216083121556107

Epoch: 5| Step: 2
Training loss: 1.8911750316619873
Validation loss: 1.9421627290787236

Epoch: 5| Step: 3
Training loss: 1.0660980939865112
Validation loss: 1.9448148768435243

Epoch: 5| Step: 4
Training loss: 1.8126739263534546
Validation loss: 1.9675087467316659

Epoch: 5| Step: 5
Training loss: 1.036367654800415
Validation loss: 1.9698751870022024

Epoch: 5| Step: 6
Training loss: 1.1897062063217163
Validation loss: 1.9677650979770127

Epoch: 5| Step: 7
Training loss: 0.7384079694747925
Validation loss: 1.9661665257587229

Epoch: 5| Step: 8
Training loss: 1.2381600141525269
Validation loss: 1.9555880613224481

Epoch: 5| Step: 9
Training loss: 1.7541964054107666
Validation loss: 1.9396049719984814

Epoch: 5| Step: 10
Training loss: 1.5905784368515015
Validation loss: 1.9114108700906076

Epoch: 220| Step: 0
Training loss: 1.5883983373641968
Validation loss: 1.9092997453546012

Epoch: 5| Step: 1
Training loss: 1.1603615283966064
Validation loss: 1.880663364164291

Epoch: 5| Step: 2
Training loss: 1.5033130645751953
Validation loss: 1.882132266157417

Epoch: 5| Step: 3
Training loss: 1.2564542293548584
Validation loss: 1.8919240146554925

Epoch: 5| Step: 4
Training loss: 1.5315666198730469
Validation loss: 1.914771669654436

Epoch: 5| Step: 5
Training loss: 0.7004023194313049
Validation loss: 1.939157275743382

Epoch: 5| Step: 6
Training loss: 1.657720923423767
Validation loss: 1.9396654303355882

Epoch: 5| Step: 7
Training loss: 1.1009161472320557
Validation loss: 1.9898135892806514

Epoch: 5| Step: 8
Training loss: 1.3892581462860107
Validation loss: 2.005788286526998

Epoch: 5| Step: 9
Training loss: 1.4980179071426392
Validation loss: 2.029354663305385

Epoch: 5| Step: 10
Training loss: 1.5290255546569824
Validation loss: 2.0361621328579482

Epoch: 221| Step: 0
Training loss: 0.8062483668327332
Validation loss: 2.015170035823699

Epoch: 5| Step: 1
Training loss: 0.9158088564872742
Validation loss: 2.0064793696967502

Epoch: 5| Step: 2
Training loss: 1.4178969860076904
Validation loss: 1.952806124123194

Epoch: 5| Step: 3
Training loss: 1.2233086824417114
Validation loss: 1.944158879659509

Epoch: 5| Step: 4
Training loss: 1.4974596500396729
Validation loss: 1.9303788497883787

Epoch: 5| Step: 5
Training loss: 1.4110324382781982
Validation loss: 1.9105309055697532

Epoch: 5| Step: 6
Training loss: 1.117641806602478
Validation loss: 1.9166462780326925

Epoch: 5| Step: 7
Training loss: 1.0665123462677002
Validation loss: 1.9143397654256513

Epoch: 5| Step: 8
Training loss: 2.094672679901123
Validation loss: 1.9435061511173044

Epoch: 5| Step: 9
Training loss: 1.4739353656768799
Validation loss: 1.9400413587529173

Epoch: 5| Step: 10
Training loss: 1.7656892538070679
Validation loss: 1.9564697332279657

Epoch: 222| Step: 0
Training loss: 1.2583577632904053
Validation loss: 1.9425854875195412

Epoch: 5| Step: 1
Training loss: 1.1487541198730469
Validation loss: 1.938838694685249

Epoch: 5| Step: 2
Training loss: 1.4058136940002441
Validation loss: 1.9283392378078994

Epoch: 5| Step: 3
Training loss: 1.0011765956878662
Validation loss: 1.9649448292229765

Epoch: 5| Step: 4
Training loss: 1.4377933740615845
Validation loss: 1.9786939697880899

Epoch: 5| Step: 5
Training loss: 1.4246413707733154
Validation loss: 1.983276710715345

Epoch: 5| Step: 6
Training loss: 1.187349557876587
Validation loss: 1.9398820682238507

Epoch: 5| Step: 7
Training loss: 1.826820969581604
Validation loss: 1.9176957927724367

Epoch: 5| Step: 8
Training loss: 1.2197587490081787
Validation loss: 1.8934116786526096

Epoch: 5| Step: 9
Training loss: 0.9149572253227234
Validation loss: 1.8947227308827062

Epoch: 5| Step: 10
Training loss: 1.6770210266113281
Validation loss: 1.8988565937165292

Epoch: 223| Step: 0
Training loss: 0.925481915473938
Validation loss: 1.8811045974813483

Epoch: 5| Step: 1
Training loss: 1.240368127822876
Validation loss: 1.8841063630196355

Epoch: 5| Step: 2
Training loss: 1.218937873840332
Validation loss: 1.9036329459118586

Epoch: 5| Step: 3
Training loss: 0.8690418004989624
Validation loss: 1.916041515206778

Epoch: 5| Step: 4
Training loss: 1.289463758468628
Validation loss: 1.9223081373399304

Epoch: 5| Step: 5
Training loss: 1.744246482849121
Validation loss: 1.9452139767267371

Epoch: 5| Step: 6
Training loss: 1.5276768207550049
Validation loss: 1.9505238661202051

Epoch: 5| Step: 7
Training loss: 0.988550066947937
Validation loss: 1.9546331795313026

Epoch: 5| Step: 8
Training loss: 1.6597446203231812
Validation loss: 1.9668294268269693

Epoch: 5| Step: 9
Training loss: 1.4357545375823975
Validation loss: 1.9506180824772004

Epoch: 5| Step: 10
Training loss: 1.3720682859420776
Validation loss: 1.9695804503656202

Epoch: 224| Step: 0
Training loss: 1.9946391582489014
Validation loss: 1.9989362750002133

Epoch: 5| Step: 1
Training loss: 1.1923882961273193
Validation loss: 1.9852488976652904

Epoch: 5| Step: 2
Training loss: 0.821489155292511
Validation loss: 1.98160602841326

Epoch: 5| Step: 3
Training loss: 1.213024377822876
Validation loss: 1.9727011265293244

Epoch: 5| Step: 4
Training loss: 1.1790292263031006
Validation loss: 1.9431008203055269

Epoch: 5| Step: 5
Training loss: 1.5018980503082275
Validation loss: 1.9548454874305314

Epoch: 5| Step: 6
Training loss: 1.5779756307601929
Validation loss: 1.9692825681419783

Epoch: 5| Step: 7
Training loss: 0.8130382299423218
Validation loss: 1.9595677416811708

Epoch: 5| Step: 8
Training loss: 1.533656358718872
Validation loss: 1.9496271635896416

Epoch: 5| Step: 9
Training loss: 0.9842971563339233
Validation loss: 1.917927654840613

Epoch: 5| Step: 10
Training loss: 1.4793055057525635
Validation loss: 1.9289835473542571

Epoch: 225| Step: 0
Training loss: 1.8929160833358765
Validation loss: 1.9287182361848894

Epoch: 5| Step: 1
Training loss: 1.5783458948135376
Validation loss: 1.9248278987023137

Epoch: 5| Step: 2
Training loss: 0.8767012357711792
Validation loss: 1.914057259918541

Epoch: 5| Step: 3
Training loss: 1.376156210899353
Validation loss: 1.9421402741503972

Epoch: 5| Step: 4
Training loss: 0.9692386388778687
Validation loss: 1.9717329702069681

Epoch: 5| Step: 5
Training loss: 1.6231523752212524
Validation loss: 1.9936358954316826

Epoch: 5| Step: 6
Training loss: 1.4082391262054443
Validation loss: 2.0222172942212833

Epoch: 5| Step: 7
Training loss: 1.355080008506775
Validation loss: 2.0506980137158464

Epoch: 5| Step: 8
Training loss: 1.3495216369628906
Validation loss: 2.054389229384802

Epoch: 5| Step: 9
Training loss: 1.0916709899902344
Validation loss: 2.0115865635615524

Epoch: 5| Step: 10
Training loss: 1.2644004821777344
Validation loss: 1.9548757473627727

Epoch: 226| Step: 0
Training loss: 1.064440369606018
Validation loss: 1.9099218947913057

Epoch: 5| Step: 1
Training loss: 1.2646901607513428
Validation loss: 1.9144961436589558

Epoch: 5| Step: 2
Training loss: 1.133697271347046
Validation loss: 1.9231856830658451

Epoch: 5| Step: 3
Training loss: 0.9736456871032715
Validation loss: 1.9117560348203104

Epoch: 5| Step: 4
Training loss: 1.3794294595718384
Validation loss: 1.920480558949132

Epoch: 5| Step: 5
Training loss: 1.4647328853607178
Validation loss: 1.939829376436049

Epoch: 5| Step: 6
Training loss: 1.5352957248687744
Validation loss: 1.9771722350069272

Epoch: 5| Step: 7
Training loss: 1.4301414489746094
Validation loss: 1.989535895727014

Epoch: 5| Step: 8
Training loss: 1.9478073120117188
Validation loss: 1.9582547833842616

Epoch: 5| Step: 9
Training loss: 1.4184749126434326
Validation loss: 1.9312889704140284

Epoch: 5| Step: 10
Training loss: 0.9747304320335388
Validation loss: 1.913751050990115

Epoch: 227| Step: 0
Training loss: 1.7308582067489624
Validation loss: 1.8986148718864686

Epoch: 5| Step: 1
Training loss: 0.9838560819625854
Validation loss: 1.911727507909139

Epoch: 5| Step: 2
Training loss: 0.9819157719612122
Validation loss: 1.9232698794334167

Epoch: 5| Step: 3
Training loss: 1.3371862173080444
Validation loss: 1.9211123797201342

Epoch: 5| Step: 4
Training loss: 0.7584894299507141
Validation loss: 1.9432469593581332

Epoch: 5| Step: 5
Training loss: 0.47898927330970764
Validation loss: 1.9285531185006584

Epoch: 5| Step: 6
Training loss: 1.6019808053970337
Validation loss: 1.9567011863954606

Epoch: 5| Step: 7
Training loss: 1.1669377088546753
Validation loss: 1.949153459200295

Epoch: 5| Step: 8
Training loss: 1.893405556678772
Validation loss: 1.946828962654196

Epoch: 5| Step: 9
Training loss: 2.0005626678466797
Validation loss: 1.951507737559657

Epoch: 5| Step: 10
Training loss: 1.3784410953521729
Validation loss: 1.9590360720952351

Epoch: 228| Step: 0
Training loss: 0.940261960029602
Validation loss: 1.967066236721572

Epoch: 5| Step: 1
Training loss: 1.6548864841461182
Validation loss: 1.9802353048837313

Epoch: 5| Step: 2
Training loss: 1.1964619159698486
Validation loss: 1.9638040001674364

Epoch: 5| Step: 3
Training loss: 1.7218177318572998
Validation loss: 1.945974716576197

Epoch: 5| Step: 4
Training loss: 0.8519541621208191
Validation loss: 1.934386489211872

Epoch: 5| Step: 5
Training loss: 1.3080196380615234
Validation loss: 1.9302300765950193

Epoch: 5| Step: 6
Training loss: 1.45057213306427
Validation loss: 1.9301859409578386

Epoch: 5| Step: 7
Training loss: 1.686171531677246
Validation loss: 1.9453066395175072

Epoch: 5| Step: 8
Training loss: 1.4696356058120728
Validation loss: 1.9556059055430914

Epoch: 5| Step: 9
Training loss: 0.58397376537323
Validation loss: 1.9791367823077786

Epoch: 5| Step: 10
Training loss: 1.6298590898513794
Validation loss: 1.9647788206736247

Epoch: 229| Step: 0
Training loss: 1.5857173204421997
Validation loss: 1.9504345616986674

Epoch: 5| Step: 1
Training loss: 1.1270654201507568
Validation loss: 1.963160123876346

Epoch: 5| Step: 2
Training loss: 1.475014090538025
Validation loss: 1.965085155220442

Epoch: 5| Step: 3
Training loss: 1.1285459995269775
Validation loss: 1.9703385086469754

Epoch: 5| Step: 4
Training loss: 0.987402081489563
Validation loss: 1.999940106945653

Epoch: 5| Step: 5
Training loss: 1.0956189632415771
Validation loss: 2.0099898115281136

Epoch: 5| Step: 6
Training loss: 1.5150740146636963
Validation loss: 1.9925522176168298

Epoch: 5| Step: 7
Training loss: 0.8675912618637085
Validation loss: 1.957598078635431

Epoch: 5| Step: 8
Training loss: 1.4969489574432373
Validation loss: 1.9126272150265273

Epoch: 5| Step: 9
Training loss: 1.1831228733062744
Validation loss: 1.8854888780142671

Epoch: 5| Step: 10
Training loss: 1.3093124628067017
Validation loss: 1.8584376560744418

Epoch: 230| Step: 0
Training loss: 1.3836671113967896
Validation loss: 1.8541198186976935

Epoch: 5| Step: 1
Training loss: 0.7426236867904663
Validation loss: 1.855218606610452

Epoch: 5| Step: 2
Training loss: 1.73517644405365
Validation loss: 1.8599908121170536

Epoch: 5| Step: 3
Training loss: 1.6673800945281982
Validation loss: 1.8942894179333922

Epoch: 5| Step: 4
Training loss: 1.2163745164871216
Validation loss: 1.9009541990936443

Epoch: 5| Step: 5
Training loss: 1.2812836170196533
Validation loss: 1.9157415102886897

Epoch: 5| Step: 6
Training loss: 1.075011968612671
Validation loss: 1.9418693780899048

Epoch: 5| Step: 7
Training loss: 1.428588628768921
Validation loss: 1.938305551005948

Epoch: 5| Step: 8
Training loss: 1.4631707668304443
Validation loss: 1.9477467562562676

Epoch: 5| Step: 9
Training loss: 0.6286846995353699
Validation loss: 1.95237103585274

Epoch: 5| Step: 10
Training loss: 1.0869078636169434
Validation loss: 1.9366139314507926

Epoch: 231| Step: 0
Training loss: 1.5176613330841064
Validation loss: 1.953300255601124

Epoch: 5| Step: 1
Training loss: 1.0578157901763916
Validation loss: 1.9464848233807472

Epoch: 5| Step: 2
Training loss: 1.4995362758636475
Validation loss: 1.9625110703129922

Epoch: 5| Step: 3
Training loss: 0.9328824281692505
Validation loss: 1.9718426171169485

Epoch: 5| Step: 4
Training loss: 1.3992105722427368
Validation loss: 1.9924912785971036

Epoch: 5| Step: 5
Training loss: 1.3760578632354736
Validation loss: 1.954666914478425

Epoch: 5| Step: 6
Training loss: 1.1138168573379517
Validation loss: 1.953920982217276

Epoch: 5| Step: 7
Training loss: 0.9579600095748901
Validation loss: 1.9372825109830467

Epoch: 5| Step: 8
Training loss: 1.547916054725647
Validation loss: 1.9459171090074765

Epoch: 5| Step: 9
Training loss: 1.066635012626648
Validation loss: 1.9484287923382175

Epoch: 5| Step: 10
Training loss: 0.9036096930503845
Validation loss: 1.9441541728153025

Epoch: 232| Step: 0
Training loss: 1.0159687995910645
Validation loss: 1.9218824076396164

Epoch: 5| Step: 1
Training loss: 1.1008516550064087
Validation loss: 1.913223906229901

Epoch: 5| Step: 2
Training loss: 0.9634122848510742
Validation loss: 1.9189811957779752

Epoch: 5| Step: 3
Training loss: 1.175836443901062
Validation loss: 1.9137150523483113

Epoch: 5| Step: 4
Training loss: 1.5591611862182617
Validation loss: 1.8806592341392272

Epoch: 5| Step: 5
Training loss: 1.4318509101867676
Validation loss: 1.8887471691254647

Epoch: 5| Step: 6
Training loss: 1.4814655780792236
Validation loss: 1.8667424135310675

Epoch: 5| Step: 7
Training loss: 0.9675159454345703
Validation loss: 1.8807846730755222

Epoch: 5| Step: 8
Training loss: 1.452605962753296
Validation loss: 1.8998152312412058

Epoch: 5| Step: 9
Training loss: 0.8888852000236511
Validation loss: 1.9245064694394347

Epoch: 5| Step: 10
Training loss: 1.3914806842803955
Validation loss: 1.9406188303424465

Epoch: 233| Step: 0
Training loss: 1.3674547672271729
Validation loss: 1.937495800756639

Epoch: 5| Step: 1
Training loss: 1.2389318943023682
Validation loss: 1.9529771061353787

Epoch: 5| Step: 2
Training loss: 1.2320785522460938
Validation loss: 1.9404317614852742

Epoch: 5| Step: 3
Training loss: 1.079429268836975
Validation loss: 1.9139686681891

Epoch: 5| Step: 4
Training loss: 0.9226581454277039
Validation loss: 1.9201302156653455

Epoch: 5| Step: 5
Training loss: 1.0389997959136963
Validation loss: 1.9040636900932557

Epoch: 5| Step: 6
Training loss: 1.1725852489471436
Validation loss: 1.9096745931974022

Epoch: 5| Step: 7
Training loss: 1.0874245166778564
Validation loss: 1.9236280943757744

Epoch: 5| Step: 8
Training loss: 1.4557154178619385
Validation loss: 1.9225124409121852

Epoch: 5| Step: 9
Training loss: 1.0826107263565063
Validation loss: 1.9233529644627725

Epoch: 5| Step: 10
Training loss: 1.6052238941192627
Validation loss: 1.938546936999085

Epoch: 234| Step: 0
Training loss: 1.5164555311203003
Validation loss: 1.9169830788848221

Epoch: 5| Step: 1
Training loss: 1.3332104682922363
Validation loss: 1.9418936506394417

Epoch: 5| Step: 2
Training loss: 1.1194559335708618
Validation loss: 1.9198338152259908

Epoch: 5| Step: 3
Training loss: 1.2865824699401855
Validation loss: 1.9333083552698935

Epoch: 5| Step: 4
Training loss: 1.1115440130233765
Validation loss: 1.92316105417026

Epoch: 5| Step: 5
Training loss: 0.949914813041687
Validation loss: 1.9113780708723171

Epoch: 5| Step: 6
Training loss: 0.9671656489372253
Validation loss: 1.8981720145030687

Epoch: 5| Step: 7
Training loss: 1.1883175373077393
Validation loss: 1.8992000497797483

Epoch: 5| Step: 8
Training loss: 1.3322101831436157
Validation loss: 1.90331910246162

Epoch: 5| Step: 9
Training loss: 1.1180627346038818
Validation loss: 1.9021336673408427

Epoch: 5| Step: 10
Training loss: 1.2771505117416382
Validation loss: 1.931402075675226

Epoch: 235| Step: 0
Training loss: 1.0198347568511963
Validation loss: 1.9477157554318827

Epoch: 5| Step: 1
Training loss: 1.3679358959197998
Validation loss: 1.9671878660878828

Epoch: 5| Step: 2
Training loss: 1.6393684148788452
Validation loss: 1.9479037971906765

Epoch: 5| Step: 3
Training loss: 0.7671195268630981
Validation loss: 1.9409757801281509

Epoch: 5| Step: 4
Training loss: 0.9845634698867798
Validation loss: 1.9328418444561701

Epoch: 5| Step: 5
Training loss: 0.865780234336853
Validation loss: 1.9482900365706413

Epoch: 5| Step: 6
Training loss: 0.9143843650817871
Validation loss: 1.944186584923857

Epoch: 5| Step: 7
Training loss: 1.278817892074585
Validation loss: 1.9098306932756979

Epoch: 5| Step: 8
Training loss: 1.152530550956726
Validation loss: 1.926606870466663

Epoch: 5| Step: 9
Training loss: 1.1326090097427368
Validation loss: 1.9330110652472383

Epoch: 5| Step: 10
Training loss: 1.681732416152954
Validation loss: 1.9266890223308275

Epoch: 236| Step: 0
Training loss: 1.1924372911453247
Validation loss: 1.9185915595741683

Epoch: 5| Step: 1
Training loss: 0.7216933965682983
Validation loss: 1.9223698903155584

Epoch: 5| Step: 2
Training loss: 1.2672548294067383
Validation loss: 1.912994623184204

Epoch: 5| Step: 3
Training loss: 1.4968416690826416
Validation loss: 1.9232158237887966

Epoch: 5| Step: 4
Training loss: 0.827624499797821
Validation loss: 1.926189168806999

Epoch: 5| Step: 5
Training loss: 1.1764740943908691
Validation loss: 1.9416940135340537

Epoch: 5| Step: 6
Training loss: 1.4816925525665283
Validation loss: 1.924361357124903

Epoch: 5| Step: 7
Training loss: 1.0523827075958252
Validation loss: 1.9709800366432435

Epoch: 5| Step: 8
Training loss: 1.1957145929336548
Validation loss: 1.9606019450772194

Epoch: 5| Step: 9
Training loss: 1.5044065713882446
Validation loss: 1.9457399486213602

Epoch: 5| Step: 10
Training loss: 0.9011349081993103
Validation loss: 1.9213891849722913

Epoch: 237| Step: 0
Training loss: 1.242518663406372
Validation loss: 1.925163204951953

Epoch: 5| Step: 1
Training loss: 0.9848693609237671
Validation loss: 1.909417357496036

Epoch: 5| Step: 2
Training loss: 1.054754614830017
Validation loss: 1.920241557141786

Epoch: 5| Step: 3
Training loss: 1.0695765018463135
Validation loss: 1.9441181408461703

Epoch: 5| Step: 4
Training loss: 1.454407811164856
Validation loss: 1.9571294335908787

Epoch: 5| Step: 5
Training loss: 1.098314881324768
Validation loss: 1.9465086870296027

Epoch: 5| Step: 6
Training loss: 1.160669207572937
Validation loss: 1.9313087335196875

Epoch: 5| Step: 7
Training loss: 0.8366397619247437
Validation loss: 1.9257010298390542

Epoch: 5| Step: 8
Training loss: 1.6799482107162476
Validation loss: 1.9026873496270948

Epoch: 5| Step: 9
Training loss: 1.212750792503357
Validation loss: 1.9018830971051288

Epoch: 5| Step: 10
Training loss: 1.4475165605545044
Validation loss: 1.8793265922095186

Epoch: 238| Step: 0
Training loss: 0.9082733988761902
Validation loss: 1.8675704386926466

Epoch: 5| Step: 1
Training loss: 0.9521161317825317
Validation loss: 1.8645998047244163

Epoch: 5| Step: 2
Training loss: 1.3472511768341064
Validation loss: 1.8691790398731027

Epoch: 5| Step: 3
Training loss: 1.5684772729873657
Validation loss: 1.9069334858207292

Epoch: 5| Step: 4
Training loss: 1.2561153173446655
Validation loss: 1.9209593470378588

Epoch: 5| Step: 5
Training loss: 1.0296211242675781
Validation loss: 1.895569420629932

Epoch: 5| Step: 6
Training loss: 1.2659350633621216
Validation loss: 1.8728113046256445

Epoch: 5| Step: 7
Training loss: 1.2826555967330933
Validation loss: 1.869709219983829

Epoch: 5| Step: 8
Training loss: 0.7958490252494812
Validation loss: 1.8812504993971957

Epoch: 5| Step: 9
Training loss: 1.3497693538665771
Validation loss: 1.907423614173807

Epoch: 5| Step: 10
Training loss: 1.1886056661605835
Validation loss: 1.920383704605923

Epoch: 239| Step: 0
Training loss: 1.121269941329956
Validation loss: 1.924040784117996

Epoch: 5| Step: 1
Training loss: 1.427910566329956
Validation loss: 1.918929353837044

Epoch: 5| Step: 2
Training loss: 1.437268614768982
Validation loss: 1.9241720220094085

Epoch: 5| Step: 3
Training loss: 1.089343786239624
Validation loss: 1.9275082119049565

Epoch: 5| Step: 4
Training loss: 1.2413477897644043
Validation loss: 1.897135449993995

Epoch: 5| Step: 5
Training loss: 1.1276004314422607
Validation loss: 1.8935837925121348

Epoch: 5| Step: 6
Training loss: 0.9760106205940247
Validation loss: 1.8739671053424958

Epoch: 5| Step: 7
Training loss: 1.5784717798233032
Validation loss: 1.8902375877544444

Epoch: 5| Step: 8
Training loss: 0.4790755808353424
Validation loss: 1.8848180745237617

Epoch: 5| Step: 9
Training loss: 0.8127691149711609
Validation loss: 1.9004320457417478

Epoch: 5| Step: 10
Training loss: 1.4431893825531006
Validation loss: 1.928579920081682

Epoch: 240| Step: 0
Training loss: 1.273281455039978
Validation loss: 1.9257757804727043

Epoch: 5| Step: 1
Training loss: 1.5304926633834839
Validation loss: 1.9320838720567766

Epoch: 5| Step: 2
Training loss: 1.3524991273880005
Validation loss: 1.9334661422237274

Epoch: 5| Step: 3
Training loss: 0.5316168665885925
Validation loss: 1.9306243158155871

Epoch: 5| Step: 4
Training loss: 1.0494518280029297
Validation loss: 1.9293474561424666

Epoch: 5| Step: 5
Training loss: 1.2449666261672974
Validation loss: 1.9308777291287658

Epoch: 5| Step: 6
Training loss: 1.104814887046814
Validation loss: 1.9320724510377454

Epoch: 5| Step: 7
Training loss: 1.577237844467163
Validation loss: 1.9182578286816996

Epoch: 5| Step: 8
Training loss: 0.512714147567749
Validation loss: 1.9129394677377516

Epoch: 5| Step: 9
Training loss: 1.3423467874526978
Validation loss: 1.9085852766549716

Epoch: 5| Step: 10
Training loss: 0.8621038198471069
Validation loss: 1.9016911150306783

Epoch: 241| Step: 0
Training loss: 0.7220795154571533
Validation loss: 1.9275766470099007

Epoch: 5| Step: 1
Training loss: 1.1846345663070679
Validation loss: 1.9042322469013993

Epoch: 5| Step: 2
Training loss: 0.7021452188491821
Validation loss: 1.905821983532239

Epoch: 5| Step: 3
Training loss: 0.6922861933708191
Validation loss: 1.8978076980959984

Epoch: 5| Step: 4
Training loss: 0.8957465887069702
Validation loss: 1.8921243003619614

Epoch: 5| Step: 5
Training loss: 0.862298309803009
Validation loss: 1.891220005609656

Epoch: 5| Step: 6
Training loss: 1.4032949209213257
Validation loss: 1.8833306912452943

Epoch: 5| Step: 7
Training loss: 1.4186302423477173
Validation loss: 1.866376805049117

Epoch: 5| Step: 8
Training loss: 1.6144342422485352
Validation loss: 1.870023331334514

Epoch: 5| Step: 9
Training loss: 0.8412066698074341
Validation loss: 1.8666057766124766

Epoch: 5| Step: 10
Training loss: 1.9349724054336548
Validation loss: 1.870067028589146

Epoch: 242| Step: 0
Training loss: 0.8267456889152527
Validation loss: 1.8813581723038868

Epoch: 5| Step: 1
Training loss: 1.0599428415298462
Validation loss: 1.9051423803452523

Epoch: 5| Step: 2
Training loss: 1.0193818807601929
Validation loss: 1.8846822528428928

Epoch: 5| Step: 3
Training loss: 1.232240915298462
Validation loss: 1.9068845613028413

Epoch: 5| Step: 4
Training loss: 0.8782819509506226
Validation loss: 1.8936057898306078

Epoch: 5| Step: 5
Training loss: 1.1204588413238525
Validation loss: 1.8858853732385943

Epoch: 5| Step: 6
Training loss: 1.09552800655365
Validation loss: 1.8599941474135204

Epoch: 5| Step: 7
Training loss: 1.5054247379302979
Validation loss: 1.8718635625736688

Epoch: 5| Step: 8
Training loss: 1.2309696674346924
Validation loss: 1.8779039613662227

Epoch: 5| Step: 9
Training loss: 1.3706549406051636
Validation loss: 1.8770414244744085

Epoch: 5| Step: 10
Training loss: 0.9433494806289673
Validation loss: 1.8829582916793002

Epoch: 243| Step: 0
Training loss: 0.925510585308075
Validation loss: 1.895148310610043

Epoch: 5| Step: 1
Training loss: 0.8977686166763306
Validation loss: 1.9234907345105243

Epoch: 5| Step: 2
Training loss: 1.5780757665634155
Validation loss: 1.9406771813669512

Epoch: 5| Step: 3
Training loss: 0.9608823657035828
Validation loss: 1.9725415142633582

Epoch: 5| Step: 4
Training loss: 1.593103051185608
Validation loss: 1.9529009916449105

Epoch: 5| Step: 5
Training loss: 1.3413665294647217
Validation loss: 1.9391123017957133

Epoch: 5| Step: 6
Training loss: 1.493401288986206
Validation loss: 1.9223670959472656

Epoch: 5| Step: 7
Training loss: 1.0874344110488892
Validation loss: 1.8824390788232126

Epoch: 5| Step: 8
Training loss: 1.1839313507080078
Validation loss: 1.8802392393030145

Epoch: 5| Step: 9
Training loss: 0.6729888319969177
Validation loss: 1.8640081882476807

Epoch: 5| Step: 10
Training loss: 0.7474716901779175
Validation loss: 1.8629275393742386

Epoch: 244| Step: 0
Training loss: 1.2909090518951416
Validation loss: 1.850130037594867

Epoch: 5| Step: 1
Training loss: 1.1427433490753174
Validation loss: 1.87606293155301

Epoch: 5| Step: 2
Training loss: 1.0843629837036133
Validation loss: 1.900580531807356

Epoch: 5| Step: 3
Training loss: 0.6541634798049927
Validation loss: 1.9221374860373877

Epoch: 5| Step: 4
Training loss: 1.1016565561294556
Validation loss: 1.937954177138626

Epoch: 5| Step: 5
Training loss: 0.9990825653076172
Validation loss: 1.9715048484904791

Epoch: 5| Step: 6
Training loss: 1.4725618362426758
Validation loss: 1.9766209868974582

Epoch: 5| Step: 7
Training loss: 0.7915107011795044
Validation loss: 1.9480566401635446

Epoch: 5| Step: 8
Training loss: 1.5591316223144531
Validation loss: 1.9280565887369134

Epoch: 5| Step: 9
Training loss: 1.1851537227630615
Validation loss: 1.9043611839253416

Epoch: 5| Step: 10
Training loss: 0.875351071357727
Validation loss: 1.8766871511295278

Epoch: 245| Step: 0
Training loss: 0.6970439553260803
Validation loss: 1.8505285504043743

Epoch: 5| Step: 1
Training loss: 0.9363206624984741
Validation loss: 1.8395046341803767

Epoch: 5| Step: 2
Training loss: 1.1208152770996094
Validation loss: 1.8369477410470285

Epoch: 5| Step: 3
Training loss: 1.0324468612670898
Validation loss: 1.8499380414203932

Epoch: 5| Step: 4
Training loss: 1.091054081916809
Validation loss: 1.853257413833372

Epoch: 5| Step: 5
Training loss: 0.7658786177635193
Validation loss: 1.8812303491818008

Epoch: 5| Step: 6
Training loss: 1.1812998056411743
Validation loss: 1.910817866684288

Epoch: 5| Step: 7
Training loss: 1.0450518131256104
Validation loss: 1.9233649200008762

Epoch: 5| Step: 8
Training loss: 1.2055683135986328
Validation loss: 1.9229832938922349

Epoch: 5| Step: 9
Training loss: 1.3270753622055054
Validation loss: 1.8947711683088733

Epoch: 5| Step: 10
Training loss: 1.5382970571517944
Validation loss: 1.9028388505340905

Epoch: 246| Step: 0
Training loss: 1.4757699966430664
Validation loss: 1.904702978749429

Epoch: 5| Step: 1
Training loss: 1.100543737411499
Validation loss: 1.8651261034832205

Epoch: 5| Step: 2
Training loss: 0.9957411885261536
Validation loss: 1.8611448964764994

Epoch: 5| Step: 3
Training loss: 0.8999784588813782
Validation loss: 1.8281158375483688

Epoch: 5| Step: 4
Training loss: 1.4197908639907837
Validation loss: 1.8440611080456806

Epoch: 5| Step: 5
Training loss: 0.9011955261230469
Validation loss: 1.8445473627377582

Epoch: 5| Step: 6
Training loss: 0.8137445449829102
Validation loss: 1.8543773851087015

Epoch: 5| Step: 7
Training loss: 1.0232419967651367
Validation loss: 1.860071425796837

Epoch: 5| Step: 8
Training loss: 1.064267635345459
Validation loss: 1.880392707804198

Epoch: 5| Step: 9
Training loss: 0.9405853152275085
Validation loss: 1.9048675055144935

Epoch: 5| Step: 10
Training loss: 1.1890642642974854
Validation loss: 1.9391889226052068

Epoch: 247| Step: 0
Training loss: 0.8717001080513
Validation loss: 1.9543508521972164

Epoch: 5| Step: 1
Training loss: 0.6940320730209351
Validation loss: 1.9636955325321486

Epoch: 5| Step: 2
Training loss: 1.5743964910507202
Validation loss: 1.917516876292485

Epoch: 5| Step: 3
Training loss: 1.2799711227416992
Validation loss: 1.9416084494642032

Epoch: 5| Step: 4
Training loss: 1.1694387197494507
Validation loss: 1.9181324038454282

Epoch: 5| Step: 5
Training loss: 0.9142912030220032
Validation loss: 1.8584905324443695

Epoch: 5| Step: 6
Training loss: 1.6688687801361084
Validation loss: 1.8656025291771017

Epoch: 5| Step: 7
Training loss: 0.46296557784080505
Validation loss: 1.8647242720409105

Epoch: 5| Step: 8
Training loss: 1.6000597476959229
Validation loss: 1.8654577514176727

Epoch: 5| Step: 9
Training loss: 0.826922595500946
Validation loss: 1.8938910832969091

Epoch: 5| Step: 10
Training loss: 0.8774152398109436
Validation loss: 1.9186174946446573

Epoch: 248| Step: 0
Training loss: 1.2504780292510986
Validation loss: 1.9707819364404167

Epoch: 5| Step: 1
Training loss: 1.0587667226791382
Validation loss: 2.023442437571864

Epoch: 5| Step: 2
Training loss: 1.07094407081604
Validation loss: 1.971680482228597

Epoch: 5| Step: 3
Training loss: 1.1805942058563232
Validation loss: 1.9504934921059558

Epoch: 5| Step: 4
Training loss: 0.8202115297317505
Validation loss: 1.9090239527404949

Epoch: 5| Step: 5
Training loss: 0.8702686429023743
Validation loss: 1.8825178889818088

Epoch: 5| Step: 6
Training loss: 0.9233171343803406
Validation loss: 1.8670443924524451

Epoch: 5| Step: 7
Training loss: 1.0958211421966553
Validation loss: 1.8745265494110763

Epoch: 5| Step: 8
Training loss: 0.7837392687797546
Validation loss: 1.8606350832088019

Epoch: 5| Step: 9
Training loss: 1.955942153930664
Validation loss: 1.8389706047632361

Epoch: 5| Step: 10
Training loss: 0.8252039551734924
Validation loss: 1.8745812190476285

Epoch: 249| Step: 0
Training loss: 0.7235933542251587
Validation loss: 1.8882699794666742

Epoch: 5| Step: 1
Training loss: 0.973646342754364
Validation loss: 1.8749701412775184

Epoch: 5| Step: 2
Training loss: 1.4929654598236084
Validation loss: 1.8968296089480001

Epoch: 5| Step: 3
Training loss: 1.1980339288711548
Validation loss: 1.919792377820579

Epoch: 5| Step: 4
Training loss: 1.1404107809066772
Validation loss: 1.9246491437317224

Epoch: 5| Step: 5
Training loss: 1.1712675094604492
Validation loss: 1.9509571047239407

Epoch: 5| Step: 6
Training loss: 1.1980705261230469
Validation loss: 1.9044435460080382

Epoch: 5| Step: 7
Training loss: 0.9754170179367065
Validation loss: 1.8924712442582654

Epoch: 5| Step: 8
Training loss: 1.5440126657485962
Validation loss: 1.8871033960773098

Epoch: 5| Step: 9
Training loss: 0.7135165333747864
Validation loss: 1.8945956178890762

Epoch: 5| Step: 10
Training loss: 0.7275543212890625
Validation loss: 1.890458829941288

Epoch: 250| Step: 0
Training loss: 0.5316190123558044
Validation loss: 1.8759433479719265

Epoch: 5| Step: 1
Training loss: 0.6848440170288086
Validation loss: 1.8438067154217792

Epoch: 5| Step: 2
Training loss: 1.4669678211212158
Validation loss: 1.8311885108229935

Epoch: 5| Step: 3
Training loss: 1.0808231830596924
Validation loss: 1.8362458252137708

Epoch: 5| Step: 4
Training loss: 0.9697157144546509
Validation loss: 1.8386018148032568

Epoch: 5| Step: 5
Training loss: 1.1728928089141846
Validation loss: 1.840259369983468

Epoch: 5| Step: 6
Training loss: 1.4877159595489502
Validation loss: 1.8381792499173073

Epoch: 5| Step: 7
Training loss: 1.1749231815338135
Validation loss: 1.8853203968335224

Epoch: 5| Step: 8
Training loss: 0.9457831382751465
Validation loss: 1.9529627138568508

Epoch: 5| Step: 9
Training loss: 1.3350982666015625
Validation loss: 1.978403140139836

Epoch: 5| Step: 10
Training loss: 1.4449739456176758
Validation loss: 1.9688638743533884

Epoch: 251| Step: 0
Training loss: 0.659256100654602
Validation loss: 1.9384823409459924

Epoch: 5| Step: 1
Training loss: 0.880518913269043
Validation loss: 1.8951327877659951

Epoch: 5| Step: 2
Training loss: 1.1370213031768799
Validation loss: 1.8369870531943537

Epoch: 5| Step: 3
Training loss: 0.9278199076652527
Validation loss: 1.8553047974904378

Epoch: 5| Step: 4
Training loss: 1.435802936553955
Validation loss: 1.8555160645515687

Epoch: 5| Step: 5
Training loss: 1.3844366073608398
Validation loss: 1.8570176452718756

Epoch: 5| Step: 6
Training loss: 0.8144771456718445
Validation loss: 1.8866769357394146

Epoch: 5| Step: 7
Training loss: 1.5207507610321045
Validation loss: 1.9013287239177252

Epoch: 5| Step: 8
Training loss: 1.6307611465454102
Validation loss: 1.9082958429090437

Epoch: 5| Step: 9
Training loss: 0.9785228967666626
Validation loss: 1.918171731374597

Epoch: 5| Step: 10
Training loss: 0.6473173499107361
Validation loss: 1.9028653701146443

Epoch: 252| Step: 0
Training loss: 1.294848918914795
Validation loss: 1.8827134729713522

Epoch: 5| Step: 1
Training loss: 0.5539168119430542
Validation loss: 1.872328717221496

Epoch: 5| Step: 2
Training loss: 1.2671558856964111
Validation loss: 1.8810401065375215

Epoch: 5| Step: 3
Training loss: 1.3638360500335693
Validation loss: 1.8713866510698873

Epoch: 5| Step: 4
Training loss: 1.2578099966049194
Validation loss: 1.851620827951739

Epoch: 5| Step: 5
Training loss: 1.0101873874664307
Validation loss: 1.8337980431895102

Epoch: 5| Step: 6
Training loss: 0.8526743650436401
Validation loss: 1.8497768217517483

Epoch: 5| Step: 7
Training loss: 0.9114211797714233
Validation loss: 1.8543408634842082

Epoch: 5| Step: 8
Training loss: 0.8690631985664368
Validation loss: 1.8859201169783069

Epoch: 5| Step: 9
Training loss: 0.9718490839004517
Validation loss: 1.885694057710709

Epoch: 5| Step: 10
Training loss: 1.3169342279434204
Validation loss: 1.896327567356889

Epoch: 253| Step: 0
Training loss: 1.2217369079589844
Validation loss: 1.8593034577626053

Epoch: 5| Step: 1
Training loss: 0.9980422258377075
Validation loss: 1.8380548236190632

Epoch: 5| Step: 2
Training loss: 0.7537335157394409
Validation loss: 1.838881351614511

Epoch: 5| Step: 3
Training loss: 0.6933674216270447
Validation loss: 1.8393462601528372

Epoch: 5| Step: 4
Training loss: 1.3846142292022705
Validation loss: 1.8551882133688977

Epoch: 5| Step: 5
Training loss: 1.1369197368621826
Validation loss: 1.863850878131005

Epoch: 5| Step: 6
Training loss: 0.9414469599723816
Validation loss: 1.8732886763029202

Epoch: 5| Step: 7
Training loss: 1.652388572692871
Validation loss: 1.9221429927374727

Epoch: 5| Step: 8
Training loss: 0.990277111530304
Validation loss: 1.9296640196154196

Epoch: 5| Step: 9
Training loss: 1.2782760858535767
Validation loss: 1.896833860745994

Epoch: 5| Step: 10
Training loss: 0.570000410079956
Validation loss: 1.8741063764018397

Epoch: 254| Step: 0
Training loss: 0.8586462140083313
Validation loss: 1.8518521503735614

Epoch: 5| Step: 1
Training loss: 0.8004893064498901
Validation loss: 1.85949888537007

Epoch: 5| Step: 2
Training loss: 1.0289182662963867
Validation loss: 1.841096931888211

Epoch: 5| Step: 3
Training loss: 1.1422650814056396
Validation loss: 1.8507248688769597

Epoch: 5| Step: 4
Training loss: 1.2909319400787354
Validation loss: 1.8410131777486494

Epoch: 5| Step: 5
Training loss: 1.0375158786773682
Validation loss: 1.833332864187097

Epoch: 5| Step: 6
Training loss: 0.7069094777107239
Validation loss: 1.8625219752711635

Epoch: 5| Step: 7
Training loss: 0.828709602355957
Validation loss: 1.8839593190018848

Epoch: 5| Step: 8
Training loss: 1.1296297311782837
Validation loss: 1.9135442267182052

Epoch: 5| Step: 9
Training loss: 1.2676948308944702
Validation loss: 1.9148790323606102

Epoch: 5| Step: 10
Training loss: 1.4698600769042969
Validation loss: 1.8855019166905393

Epoch: 255| Step: 0
Training loss: 1.1363309621810913
Validation loss: 1.8876650256495322

Epoch: 5| Step: 1
Training loss: 1.046850323677063
Validation loss: 1.8674477095245032

Epoch: 5| Step: 2
Training loss: 1.6681280136108398
Validation loss: 1.832259178161621

Epoch: 5| Step: 3
Training loss: 1.0035886764526367
Validation loss: 1.7935411827538603

Epoch: 5| Step: 4
Training loss: 0.9155162572860718
Validation loss: 1.793476043208953

Epoch: 5| Step: 5
Training loss: 1.0846662521362305
Validation loss: 1.7839783635190738

Epoch: 5| Step: 6
Training loss: 0.7227486968040466
Validation loss: 1.8007772673842728

Epoch: 5| Step: 7
Training loss: 1.1943180561065674
Validation loss: 1.7921226665537844

Epoch: 5| Step: 8
Training loss: 0.8181084394454956
Validation loss: 1.822235341994993

Epoch: 5| Step: 9
Training loss: 1.132235050201416
Validation loss: 1.8652391254260976

Epoch: 5| Step: 10
Training loss: 0.9666460752487183
Validation loss: 1.913333131420997

Epoch: 256| Step: 0
Training loss: 1.1391513347625732
Validation loss: 1.9610780349341772

Epoch: 5| Step: 1
Training loss: 0.629650354385376
Validation loss: 1.9874234045705488

Epoch: 5| Step: 2
Training loss: 1.1028529405593872
Validation loss: 1.9848656115993377

Epoch: 5| Step: 3
Training loss: 0.9841257929801941
Validation loss: 1.9234809760124452

Epoch: 5| Step: 4
Training loss: 1.2498451471328735
Validation loss: 1.8906099360476258

Epoch: 5| Step: 5
Training loss: 1.2608624696731567
Validation loss: 1.8684940902135705

Epoch: 5| Step: 6
Training loss: 1.2699754238128662
Validation loss: 1.8431514309298607

Epoch: 5| Step: 7
Training loss: 1.1267907619476318
Validation loss: 1.8746302191929152

Epoch: 5| Step: 8
Training loss: 0.6682426929473877
Validation loss: 1.8365094853985695

Epoch: 5| Step: 9
Training loss: 1.1350929737091064
Validation loss: 1.8242720852616012

Epoch: 5| Step: 10
Training loss: 1.2720346450805664
Validation loss: 1.8684485779013684

Epoch: 257| Step: 0
Training loss: 1.109180212020874
Validation loss: 1.9053141865679013

Epoch: 5| Step: 1
Training loss: 1.0463546514511108
Validation loss: 1.9144736489941996

Epoch: 5| Step: 2
Training loss: 0.9419301748275757
Validation loss: 1.8831852251483547

Epoch: 5| Step: 3
Training loss: 0.9511372447013855
Validation loss: 1.8998218415885844

Epoch: 5| Step: 4
Training loss: 1.4190349578857422
Validation loss: 1.869215734543339

Epoch: 5| Step: 5
Training loss: 1.0603139400482178
Validation loss: 1.8685869286137242

Epoch: 5| Step: 6
Training loss: 1.0455334186553955
Validation loss: 1.8691243087091753

Epoch: 5| Step: 7
Training loss: 0.5931748747825623
Validation loss: 1.8698320645158009

Epoch: 5| Step: 8
Training loss: 1.2058568000793457
Validation loss: 1.8500092273117394

Epoch: 5| Step: 9
Training loss: 1.007705569267273
Validation loss: 1.8705639710990332

Epoch: 5| Step: 10
Training loss: 0.8397786617279053
Validation loss: 1.8879800817017913

Epoch: 258| Step: 0
Training loss: 1.0296640396118164
Validation loss: 1.9055115458785847

Epoch: 5| Step: 1
Training loss: 1.043964147567749
Validation loss: 1.8972076446779313

Epoch: 5| Step: 2
Training loss: 0.7093806862831116
Validation loss: 1.8945495902851064

Epoch: 5| Step: 3
Training loss: 1.1858760118484497
Validation loss: 1.8766102931832755

Epoch: 5| Step: 4
Training loss: 1.0930347442626953
Validation loss: 1.8927904508447135

Epoch: 5| Step: 5
Training loss: 1.348187804222107
Validation loss: 1.887013998082889

Epoch: 5| Step: 6
Training loss: 0.9479650259017944
Validation loss: 1.9036176909682572

Epoch: 5| Step: 7
Training loss: 0.8389207124710083
Validation loss: 1.88436343080254

Epoch: 5| Step: 8
Training loss: 1.0598070621490479
Validation loss: 1.8515807761940906

Epoch: 5| Step: 9
Training loss: 1.100984811782837
Validation loss: 1.8457116862779022

Epoch: 5| Step: 10
Training loss: 0.8274893760681152
Validation loss: 1.8477846960867605

Epoch: 259| Step: 0
Training loss: 0.7705734968185425
Validation loss: 1.8712041249839209

Epoch: 5| Step: 1
Training loss: 1.4256350994110107
Validation loss: 1.8802767889474028

Epoch: 5| Step: 2
Training loss: 1.063642144203186
Validation loss: 1.8926250421872703

Epoch: 5| Step: 3
Training loss: 0.6956826448440552
Validation loss: 1.8991155214207147

Epoch: 5| Step: 4
Training loss: 0.8466793298721313
Validation loss: 1.9202441374460857

Epoch: 5| Step: 5
Training loss: 0.9200661778450012
Validation loss: 1.9173261632201493

Epoch: 5| Step: 6
Training loss: 1.2766146659851074
Validation loss: 1.9001168871438632

Epoch: 5| Step: 7
Training loss: 0.9638978242874146
Validation loss: 1.8812268434032318

Epoch: 5| Step: 8
Training loss: 0.8614752888679504
Validation loss: 1.874426411044213

Epoch: 5| Step: 9
Training loss: 1.2174566984176636
Validation loss: 1.876974687781385

Epoch: 5| Step: 10
Training loss: 1.1510258913040161
Validation loss: 1.8873018846716931

Epoch: 260| Step: 0
Training loss: 0.7388347387313843
Validation loss: 1.880516423973986

Epoch: 5| Step: 1
Training loss: 1.07613205909729
Validation loss: 1.8768324082897556

Epoch: 5| Step: 2
Training loss: 1.31191086769104
Validation loss: 1.8723904855789677

Epoch: 5| Step: 3
Training loss: 1.071223497390747
Validation loss: 1.886259062315828

Epoch: 5| Step: 4
Training loss: 1.1715986728668213
Validation loss: 1.8546168547804638

Epoch: 5| Step: 5
Training loss: 0.7301366925239563
Validation loss: 1.8588465029193508

Epoch: 5| Step: 6
Training loss: 1.1882102489471436
Validation loss: 1.8550010035114903

Epoch: 5| Step: 7
Training loss: 0.7003685235977173
Validation loss: 1.8609339267976823

Epoch: 5| Step: 8
Training loss: 0.9742146730422974
Validation loss: 1.89495647850857

Epoch: 5| Step: 9
Training loss: 0.9662807583808899
Validation loss: 1.9055038600839593

Epoch: 5| Step: 10
Training loss: 1.000604271888733
Validation loss: 1.896942897509503

Epoch: 261| Step: 0
Training loss: 0.857000470161438
Validation loss: 1.9036179498959613

Epoch: 5| Step: 1
Training loss: 1.0615546703338623
Validation loss: 1.8965406366573867

Epoch: 5| Step: 2
Training loss: 0.9230985641479492
Validation loss: 1.9033830447863507

Epoch: 5| Step: 3
Training loss: 0.9633873701095581
Validation loss: 1.8815291594433528

Epoch: 5| Step: 4
Training loss: 1.0927581787109375
Validation loss: 1.8759695778610885

Epoch: 5| Step: 5
Training loss: 1.2354481220245361
Validation loss: 1.8703612563430623

Epoch: 5| Step: 6
Training loss: 0.7155831456184387
Validation loss: 1.8679313967304845

Epoch: 5| Step: 7
Training loss: 0.6776471138000488
Validation loss: 1.862854355125017

Epoch: 5| Step: 8
Training loss: 1.1399532556533813
Validation loss: 1.8885321668399278

Epoch: 5| Step: 9
Training loss: 0.7380617260932922
Validation loss: 1.9026359665778376

Epoch: 5| Step: 10
Training loss: 1.5634143352508545
Validation loss: 1.9372857321975052

Epoch: 262| Step: 0
Training loss: 1.0821810960769653
Validation loss: 1.9373262108013194

Epoch: 5| Step: 1
Training loss: 0.7367419004440308
Validation loss: 1.9240489223951935

Epoch: 5| Step: 2
Training loss: 0.7640954256057739
Validation loss: 1.891775482444353

Epoch: 5| Step: 3
Training loss: 0.8520911335945129
Validation loss: 1.8437416412497079

Epoch: 5| Step: 4
Training loss: 0.9437724351882935
Validation loss: 1.8703837753624044

Epoch: 5| Step: 5
Training loss: 0.8247886896133423
Validation loss: 1.851566909461893

Epoch: 5| Step: 6
Training loss: 0.8548210263252258
Validation loss: 1.845388929049174

Epoch: 5| Step: 7
Training loss: 0.8370262384414673
Validation loss: 1.8484977176112514

Epoch: 5| Step: 8
Training loss: 1.567745327949524
Validation loss: 1.844312596064742

Epoch: 5| Step: 9
Training loss: 1.1155483722686768
Validation loss: 1.8714345937134118

Epoch: 5| Step: 10
Training loss: 1.3434308767318726
Validation loss: 1.8902065548845517

Epoch: 263| Step: 0
Training loss: 1.2869760990142822
Validation loss: 1.8714325722827707

Epoch: 5| Step: 1
Training loss: 1.1191749572753906
Validation loss: 1.8295045744988225

Epoch: 5| Step: 2
Training loss: 0.8695064783096313
Validation loss: 1.8297563599001976

Epoch: 5| Step: 3
Training loss: 1.1703864336013794
Validation loss: 1.8152660169909078

Epoch: 5| Step: 4
Training loss: 0.7294690012931824
Validation loss: 1.8274520212604153

Epoch: 5| Step: 5
Training loss: 0.8392526507377625
Validation loss: 1.8208664181411907

Epoch: 5| Step: 6
Training loss: 0.8265002965927124
Validation loss: 1.8519283046004593

Epoch: 5| Step: 7
Training loss: 1.066216230392456
Validation loss: 1.8908339495299964

Epoch: 5| Step: 8
Training loss: 0.7341755628585815
Validation loss: 1.8899938278300787

Epoch: 5| Step: 9
Training loss: 1.0383421182632446
Validation loss: 1.9105278830374441

Epoch: 5| Step: 10
Training loss: 1.241889238357544
Validation loss: 1.9203777518323673

Epoch: 264| Step: 0
Training loss: 0.699459433555603
Validation loss: 1.8497416909022997

Epoch: 5| Step: 1
Training loss: 0.7494398355484009
Validation loss: 1.8542602075043546

Epoch: 5| Step: 2
Training loss: 0.8291887044906616
Validation loss: 1.8036059692341795

Epoch: 5| Step: 3
Training loss: 1.2517037391662598
Validation loss: 1.8208993442596928

Epoch: 5| Step: 4
Training loss: 1.093811273574829
Validation loss: 1.825054730138471

Epoch: 5| Step: 5
Training loss: 1.1737817525863647
Validation loss: 1.8255417552045596

Epoch: 5| Step: 6
Training loss: 0.7242746353149414
Validation loss: 1.835220089522741

Epoch: 5| Step: 7
Training loss: 1.2851753234863281
Validation loss: 1.866815564452961

Epoch: 5| Step: 8
Training loss: 0.7242533564567566
Validation loss: 1.9030745478086575

Epoch: 5| Step: 9
Training loss: 1.4395445585250854
Validation loss: 1.9069849483428463

Epoch: 5| Step: 10
Training loss: 1.1671404838562012
Validation loss: 1.9386166757152927

Epoch: 265| Step: 0
Training loss: 1.1180576086044312
Validation loss: 1.95319410293333

Epoch: 5| Step: 1
Training loss: 0.7995336055755615
Validation loss: 1.912782020466302

Epoch: 5| Step: 2
Training loss: 1.3232676982879639
Validation loss: 1.893874196596043

Epoch: 5| Step: 3
Training loss: 1.3045178651809692
Validation loss: 1.862990753625029

Epoch: 5| Step: 4
Training loss: 1.1907013654708862
Validation loss: 1.8419293152388705

Epoch: 5| Step: 5
Training loss: 0.974317193031311
Validation loss: 1.8403983449423185

Epoch: 5| Step: 6
Training loss: 0.9702373743057251
Validation loss: 1.8337098507470981

Epoch: 5| Step: 7
Training loss: 1.0606505870819092
Validation loss: 1.848143223793276

Epoch: 5| Step: 8
Training loss: 1.1634665727615356
Validation loss: 1.8294074996825187

Epoch: 5| Step: 9
Training loss: 0.5949894189834595
Validation loss: 1.8605671928774925

Epoch: 5| Step: 10
Training loss: 0.6966948509216309
Validation loss: 1.963373113703984

Epoch: 266| Step: 0
Training loss: 1.509756088256836
Validation loss: 1.9658001456209409

Epoch: 5| Step: 1
Training loss: 1.2890247106552124
Validation loss: 1.9869535251330304

Epoch: 5| Step: 2
Training loss: 1.2128369808197021
Validation loss: 1.9193706012541247

Epoch: 5| Step: 3
Training loss: 0.5180550217628479
Validation loss: 1.8832736066592637

Epoch: 5| Step: 4
Training loss: 0.9685648083686829
Validation loss: 1.865392372172366

Epoch: 5| Step: 5
Training loss: 0.6655503511428833
Validation loss: 1.859387033729143

Epoch: 5| Step: 6
Training loss: 0.6755490303039551
Validation loss: 1.855352924716088

Epoch: 5| Step: 7
Training loss: 1.6906543970108032
Validation loss: 1.8425401256930443

Epoch: 5| Step: 8
Training loss: 1.1127933263778687
Validation loss: 1.8442874057318575

Epoch: 5| Step: 9
Training loss: 1.1104042530059814
Validation loss: 1.8103131927469724

Epoch: 5| Step: 10
Training loss: 1.1450577974319458
Validation loss: 1.8037074778669624

Epoch: 267| Step: 0
Training loss: 1.1029367446899414
Validation loss: 1.834092249152481

Epoch: 5| Step: 1
Training loss: 0.4238909184932709
Validation loss: 1.8665904806506248

Epoch: 5| Step: 2
Training loss: 1.1893391609191895
Validation loss: 1.9094988197408698

Epoch: 5| Step: 3
Training loss: 1.1999198198318481
Validation loss: 1.948914650947817

Epoch: 5| Step: 4
Training loss: 1.1534863710403442
Validation loss: 1.9713209367567492

Epoch: 5| Step: 5
Training loss: 0.7009834051132202
Validation loss: 1.9784861021144415

Epoch: 5| Step: 6
Training loss: 0.9128665924072266
Validation loss: 1.9584251834500221

Epoch: 5| Step: 7
Training loss: 1.136861801147461
Validation loss: 1.926457869109287

Epoch: 5| Step: 8
Training loss: 1.074245810508728
Validation loss: 1.8932468506597704

Epoch: 5| Step: 9
Training loss: 0.9479728937149048
Validation loss: 1.8735740261693155

Epoch: 5| Step: 10
Training loss: 1.1438617706298828
Validation loss: 1.8612312706567908

Epoch: 268| Step: 0
Training loss: 1.0107841491699219
Validation loss: 1.839540409785445

Epoch: 5| Step: 1
Training loss: 1.0115817785263062
Validation loss: 1.8422820145084011

Epoch: 5| Step: 2
Training loss: 1.0916175842285156
Validation loss: 1.882660347928283

Epoch: 5| Step: 3
Training loss: 0.9448829889297485
Validation loss: 1.8665972243073166

Epoch: 5| Step: 4
Training loss: 1.2712593078613281
Validation loss: 1.8520311950355448

Epoch: 5| Step: 5
Training loss: 0.7429478764533997
Validation loss: 1.8357802180833713

Epoch: 5| Step: 6
Training loss: 0.5745077133178711
Validation loss: 1.8303896688645886

Epoch: 5| Step: 7
Training loss: 0.6232630014419556
Validation loss: 1.822895828113761

Epoch: 5| Step: 8
Training loss: 0.7708474397659302
Validation loss: 1.8129048860201271

Epoch: 5| Step: 9
Training loss: 1.312469244003296
Validation loss: 1.8048607008431548

Epoch: 5| Step: 10
Training loss: 1.1796395778656006
Validation loss: 1.8014981644127959

Epoch: 269| Step: 0
Training loss: 0.9961453676223755
Validation loss: 1.8116537755535496

Epoch: 5| Step: 1
Training loss: 0.7296116948127747
Validation loss: 1.8479737004926127

Epoch: 5| Step: 2
Training loss: 1.2618417739868164
Validation loss: 1.8267066799184328

Epoch: 5| Step: 3
Training loss: 0.9079793691635132
Validation loss: 1.8138765981120448

Epoch: 5| Step: 4
Training loss: 0.45800334215164185
Validation loss: 1.8079909201591247

Epoch: 5| Step: 5
Training loss: 1.063890814781189
Validation loss: 1.8054559025713193

Epoch: 5| Step: 6
Training loss: 1.3314601182937622
Validation loss: 1.8397344799451931

Epoch: 5| Step: 7
Training loss: 0.7344784736633301
Validation loss: 1.833449427799512

Epoch: 5| Step: 8
Training loss: 1.0609207153320312
Validation loss: 1.8234054042446999

Epoch: 5| Step: 9
Training loss: 1.2858216762542725
Validation loss: 1.864128687048471

Epoch: 5| Step: 10
Training loss: 0.5281565189361572
Validation loss: 1.8394370591768654

Epoch: 270| Step: 0
Training loss: 0.5611282587051392
Validation loss: 1.8381276707495413

Epoch: 5| Step: 1
Training loss: 1.325943112373352
Validation loss: 1.8519977305525093

Epoch: 5| Step: 2
Training loss: 1.1478265523910522
Validation loss: 1.821069036760638

Epoch: 5| Step: 3
Training loss: 1.145026683807373
Validation loss: 1.84281373793079

Epoch: 5| Step: 4
Training loss: 0.6831892728805542
Validation loss: 1.8096917880478727

Epoch: 5| Step: 5
Training loss: 0.7865116596221924
Validation loss: 1.8191740051392586

Epoch: 5| Step: 6
Training loss: 0.9237459301948547
Validation loss: 1.8179787294839018

Epoch: 5| Step: 7
Training loss: 0.8270877599716187
Validation loss: 1.8364031212304228

Epoch: 5| Step: 8
Training loss: 0.950212299823761
Validation loss: 1.8330134448184763

Epoch: 5| Step: 9
Training loss: 1.1386234760284424
Validation loss: 1.8510578358045189

Epoch: 5| Step: 10
Training loss: 0.6224092841148376
Validation loss: 1.92296249892122

Epoch: 271| Step: 0
Training loss: 1.1306861639022827
Validation loss: 1.9268747183584398

Epoch: 5| Step: 1
Training loss: 1.3768672943115234
Validation loss: 1.9043622683453303

Epoch: 5| Step: 2
Training loss: 0.6098797917366028
Validation loss: 1.8351426342482209

Epoch: 5| Step: 3
Training loss: 0.5559307932853699
Validation loss: 1.82064744733995

Epoch: 5| Step: 4
Training loss: 1.0018432140350342
Validation loss: 1.8560643426833614

Epoch: 5| Step: 5
Training loss: 0.8644036054611206
Validation loss: 1.8519256499505812

Epoch: 5| Step: 6
Training loss: 1.0373289585113525
Validation loss: 1.8529249173338695

Epoch: 5| Step: 7
Training loss: 1.153834342956543
Validation loss: 1.832222214309118

Epoch: 5| Step: 8
Training loss: 0.9454730749130249
Validation loss: 1.8285814664697135

Epoch: 5| Step: 9
Training loss: 0.9776514172554016
Validation loss: 1.8509169957971061

Epoch: 5| Step: 10
Training loss: 1.0446064472198486
Validation loss: 1.9088911792283416

Epoch: 272| Step: 0
Training loss: 0.8237776756286621
Validation loss: 1.970409800929408

Epoch: 5| Step: 1
Training loss: 1.383158802986145
Validation loss: 1.987238617353542

Epoch: 5| Step: 2
Training loss: 1.3188765048980713
Validation loss: 1.9475496763824134

Epoch: 5| Step: 3
Training loss: 0.839819073677063
Validation loss: 1.9164271482857325

Epoch: 5| Step: 4
Training loss: 0.6623837351799011
Validation loss: 1.85845217140772

Epoch: 5| Step: 5
Training loss: 0.9718850255012512
Validation loss: 1.8610033565951931

Epoch: 5| Step: 6
Training loss: 0.9517747759819031
Validation loss: 1.8509625568184802

Epoch: 5| Step: 7
Training loss: 0.8043897747993469
Validation loss: 1.8212724988178541

Epoch: 5| Step: 8
Training loss: 1.1068432331085205
Validation loss: 1.8051770912703646

Epoch: 5| Step: 9
Training loss: 0.771060049533844
Validation loss: 1.8012387047531784

Epoch: 5| Step: 10
Training loss: 1.0407251119613647
Validation loss: 1.8202635267729401

Epoch: 273| Step: 0
Training loss: 1.2076297998428345
Validation loss: 1.8176817278708182

Epoch: 5| Step: 1
Training loss: 0.3632087707519531
Validation loss: 1.8322260405427666

Epoch: 5| Step: 2
Training loss: 1.055476188659668
Validation loss: 1.8221129781456404

Epoch: 5| Step: 3
Training loss: 0.5065200924873352
Validation loss: 1.8259873351743143

Epoch: 5| Step: 4
Training loss: 0.8690441250801086
Validation loss: 1.8363818763404764

Epoch: 5| Step: 5
Training loss: 1.0137789249420166
Validation loss: 1.8631447412634408

Epoch: 5| Step: 6
Training loss: 1.1209479570388794
Validation loss: 1.860535308878909

Epoch: 5| Step: 7
Training loss: 1.0773688554763794
Validation loss: 1.8418761786594187

Epoch: 5| Step: 8
Training loss: 1.0211327075958252
Validation loss: 1.824951732030479

Epoch: 5| Step: 9
Training loss: 1.170825719833374
Validation loss: 1.8123587613464684

Epoch: 5| Step: 10
Training loss: 0.770183265209198
Validation loss: 1.8077734606240385

Epoch: 274| Step: 0
Training loss: 0.6899860501289368
Validation loss: 1.8004663746844056

Epoch: 5| Step: 1
Training loss: 1.3677351474761963
Validation loss: 1.7965776599863523

Epoch: 5| Step: 2
Training loss: 1.1739346981048584
Validation loss: 1.7665962006456108

Epoch: 5| Step: 3
Training loss: 0.6853445768356323
Validation loss: 1.7799358419192735

Epoch: 5| Step: 4
Training loss: 0.9799038767814636
Validation loss: 1.8185795020031672

Epoch: 5| Step: 5
Training loss: 0.7020637392997742
Validation loss: 1.8288609699536396

Epoch: 5| Step: 6
Training loss: 0.8126298785209656
Validation loss: 1.8311854485542542

Epoch: 5| Step: 7
Training loss: 0.7382527589797974
Validation loss: 1.8299457667976298

Epoch: 5| Step: 8
Training loss: 1.0076286792755127
Validation loss: 1.8433298218634822

Epoch: 5| Step: 9
Training loss: 0.8401466608047485
Validation loss: 1.834732388937345

Epoch: 5| Step: 10
Training loss: 1.0708318948745728
Validation loss: 1.8172695611112861

Epoch: 275| Step: 0
Training loss: 0.9369699358940125
Validation loss: 1.8129732736977198

Epoch: 5| Step: 1
Training loss: 0.75621497631073
Validation loss: 1.7980049425555813

Epoch: 5| Step: 2
Training loss: 1.0022354125976562
Validation loss: 1.7875041564305623

Epoch: 5| Step: 3
Training loss: 0.9198228716850281
Validation loss: 1.819092035293579

Epoch: 5| Step: 4
Training loss: 1.0167667865753174
Validation loss: 1.821836458739414

Epoch: 5| Step: 5
Training loss: 0.9819647669792175
Validation loss: 1.8449409315663

Epoch: 5| Step: 6
Training loss: 0.921033501625061
Validation loss: 1.8564235779546923

Epoch: 5| Step: 7
Training loss: 0.6914875507354736
Validation loss: 1.823224671425358

Epoch: 5| Step: 8
Training loss: 0.8281109929084778
Validation loss: 1.839575130452392

Epoch: 5| Step: 9
Training loss: 1.3371371030807495
Validation loss: 1.8482990008528515

Epoch: 5| Step: 10
Training loss: 0.6763687133789062
Validation loss: 1.8496319722103816

Epoch: 276| Step: 0
Training loss: 0.7718874216079712
Validation loss: 1.877480855552099

Epoch: 5| Step: 1
Training loss: 0.7447059750556946
Validation loss: 1.8312794764836628

Epoch: 5| Step: 2
Training loss: 0.5571502447128296
Validation loss: 1.8198578614060597

Epoch: 5| Step: 3
Training loss: 0.9030957221984863
Validation loss: 1.840698713897377

Epoch: 5| Step: 4
Training loss: 0.8651173710823059
Validation loss: 1.8290403491707259

Epoch: 5| Step: 5
Training loss: 0.9249946475028992
Validation loss: 1.8125233393843456

Epoch: 5| Step: 6
Training loss: 1.0942926406860352
Validation loss: 1.8159026868881718

Epoch: 5| Step: 7
Training loss: 0.9011702537536621
Validation loss: 1.8011033842640538

Epoch: 5| Step: 8
Training loss: 0.9941909909248352
Validation loss: 1.7993372396756244

Epoch: 5| Step: 9
Training loss: 0.8565958142280579
Validation loss: 1.7911398692797589

Epoch: 5| Step: 10
Training loss: 1.229686975479126
Validation loss: 1.8180072717769171

Epoch: 277| Step: 0
Training loss: 0.8960135579109192
Validation loss: 1.8387917857016287

Epoch: 5| Step: 1
Training loss: 1.4163075685501099
Validation loss: 1.8521846558458062

Epoch: 5| Step: 2
Training loss: 0.9140290021896362
Validation loss: 1.8684318475825812

Epoch: 5| Step: 3
Training loss: 0.7351581454277039
Validation loss: 1.8404536644617717

Epoch: 5| Step: 4
Training loss: 0.7275593280792236
Validation loss: 1.8217356730532903

Epoch: 5| Step: 5
Training loss: 0.8732423782348633
Validation loss: 1.771342449290778

Epoch: 5| Step: 6
Training loss: 0.6470040082931519
Validation loss: 1.7872572534827775

Epoch: 5| Step: 7
Training loss: 0.7839300036430359
Validation loss: 1.794658592952195

Epoch: 5| Step: 8
Training loss: 0.8769330978393555
Validation loss: 1.7899969559843822

Epoch: 5| Step: 9
Training loss: 1.197927713394165
Validation loss: 1.79152665856064

Epoch: 5| Step: 10
Training loss: 0.748011589050293
Validation loss: 1.7956210849105672

Epoch: 278| Step: 0
Training loss: 0.7442483901977539
Validation loss: 1.7914278943051574

Epoch: 5| Step: 1
Training loss: 0.8216842412948608
Validation loss: 1.7924738930117698

Epoch: 5| Step: 2
Training loss: 1.232274055480957
Validation loss: 1.7857272676242295

Epoch: 5| Step: 3
Training loss: 0.9585992097854614
Validation loss: 1.8017188182441137

Epoch: 5| Step: 4
Training loss: 0.8510204553604126
Validation loss: 1.784829879319796

Epoch: 5| Step: 5
Training loss: 0.9727855920791626
Validation loss: 1.7936877153253044

Epoch: 5| Step: 6
Training loss: 1.017829418182373
Validation loss: 1.7827576257849251

Epoch: 5| Step: 7
Training loss: 0.7506648302078247
Validation loss: 1.7778720778803672

Epoch: 5| Step: 8
Training loss: 0.8137533068656921
Validation loss: 1.7853119142593876

Epoch: 5| Step: 9
Training loss: 0.6826823353767395
Validation loss: 1.7922043672171972

Epoch: 5| Step: 10
Training loss: 0.7121351957321167
Validation loss: 1.8188007826446204

Epoch: 279| Step: 0
Training loss: 0.6691809892654419
Validation loss: 1.790152375416089

Epoch: 5| Step: 1
Training loss: 0.9734393358230591
Validation loss: 1.8017820671040525

Epoch: 5| Step: 2
Training loss: 0.6465346217155457
Validation loss: 1.7887489699548291

Epoch: 5| Step: 3
Training loss: 0.8421733975410461
Validation loss: 1.7933478765590216

Epoch: 5| Step: 4
Training loss: 0.9327038526535034
Validation loss: 1.801299641209264

Epoch: 5| Step: 5
Training loss: 1.0249314308166504
Validation loss: 1.800931110176989

Epoch: 5| Step: 6
Training loss: 1.0232754945755005
Validation loss: 1.8016114081105878

Epoch: 5| Step: 7
Training loss: 0.7051776051521301
Validation loss: 1.8059938594859133

Epoch: 5| Step: 8
Training loss: 0.5927034020423889
Validation loss: 1.7785981649993567

Epoch: 5| Step: 9
Training loss: 1.189040184020996
Validation loss: 1.7996653831133278

Epoch: 5| Step: 10
Training loss: 0.7110098600387573
Validation loss: 1.8028525652423981

Epoch: 280| Step: 0
Training loss: 0.4189019203186035
Validation loss: 1.809417555409093

Epoch: 5| Step: 1
Training loss: 0.7824787497520447
Validation loss: 1.8026982174124768

Epoch: 5| Step: 2
Training loss: 0.9976075887680054
Validation loss: 1.8149876979089552

Epoch: 5| Step: 3
Training loss: 0.7953451871871948
Validation loss: 1.8021567867648216

Epoch: 5| Step: 4
Training loss: 0.680935263633728
Validation loss: 1.7972559140574547

Epoch: 5| Step: 5
Training loss: 1.3922483921051025
Validation loss: 1.8031739842507146

Epoch: 5| Step: 6
Training loss: 0.7084827423095703
Validation loss: 1.7988412508400538

Epoch: 5| Step: 7
Training loss: 0.8419567942619324
Validation loss: 1.8381949996435514

Epoch: 5| Step: 8
Training loss: 1.0411256551742554
Validation loss: 1.791317550084924

Epoch: 5| Step: 9
Training loss: 0.5872052907943726
Validation loss: 1.7777421474456787

Epoch: 5| Step: 10
Training loss: 1.2030508518218994
Validation loss: 1.7649547541013328

Epoch: 281| Step: 0
Training loss: 0.8990508913993835
Validation loss: 1.786439532874733

Epoch: 5| Step: 1
Training loss: 0.6752997040748596
Validation loss: 1.793955251734744

Epoch: 5| Step: 2
Training loss: 1.0392582416534424
Validation loss: 1.7861607536192863

Epoch: 5| Step: 3
Training loss: 1.0830824375152588
Validation loss: 1.8021029118568666

Epoch: 5| Step: 4
Training loss: 0.8270403146743774
Validation loss: 1.7947041514099284

Epoch: 5| Step: 5
Training loss: 0.8206933736801147
Validation loss: 1.7859510913971932

Epoch: 5| Step: 6
Training loss: 1.0464179515838623
Validation loss: 1.8051943650809668

Epoch: 5| Step: 7
Training loss: 0.5933197736740112
Validation loss: 1.8237741403682257

Epoch: 5| Step: 8
Training loss: 0.7813337445259094
Validation loss: 1.8228464126586914

Epoch: 5| Step: 9
Training loss: 0.7732270956039429
Validation loss: 1.8222048987624466

Epoch: 5| Step: 10
Training loss: 0.9868780970573425
Validation loss: 1.844998304561902

Epoch: 282| Step: 0
Training loss: 0.9229372143745422
Validation loss: 1.8516045988246959

Epoch: 5| Step: 1
Training loss: 0.5252240896224976
Validation loss: 1.8600166997601908

Epoch: 5| Step: 2
Training loss: 0.9321960210800171
Validation loss: 1.8320807103187806

Epoch: 5| Step: 3
Training loss: 1.0968031883239746
Validation loss: 1.8106249788756013

Epoch: 5| Step: 4
Training loss: 0.43415603041648865
Validation loss: 1.8085916785783664

Epoch: 5| Step: 5
Training loss: 1.1745223999023438
Validation loss: 1.777361790339152

Epoch: 5| Step: 6
Training loss: 0.8215234875679016
Validation loss: 1.7632124359889696

Epoch: 5| Step: 7
Training loss: 0.8591641187667847
Validation loss: 1.7368975582943167

Epoch: 5| Step: 8
Training loss: 1.0052165985107422
Validation loss: 1.7467615283945555

Epoch: 5| Step: 9
Training loss: 0.8808334469795227
Validation loss: 1.755731435232265

Epoch: 5| Step: 10
Training loss: 0.7776985168457031
Validation loss: 1.7606677316850232

Epoch: 283| Step: 0
Training loss: 0.8705185651779175
Validation loss: 1.7693186088274884

Epoch: 5| Step: 1
Training loss: 1.2422378063201904
Validation loss: 1.7794632828363808

Epoch: 5| Step: 2
Training loss: 0.724112868309021
Validation loss: 1.8095242105504519

Epoch: 5| Step: 3
Training loss: 0.8997847437858582
Validation loss: 1.7990092103199293

Epoch: 5| Step: 4
Training loss: 0.6788387298583984
Validation loss: 1.8124360692116521

Epoch: 5| Step: 5
Training loss: 1.0389970541000366
Validation loss: 1.8318589015673565

Epoch: 5| Step: 6
Training loss: 0.8687740564346313
Validation loss: 1.8156452935229066

Epoch: 5| Step: 7
Training loss: 0.8505493998527527
Validation loss: 1.8117769405406008

Epoch: 5| Step: 8
Training loss: 0.6124554872512817
Validation loss: 1.7910292020408056

Epoch: 5| Step: 9
Training loss: 1.007509469985962
Validation loss: 1.7870390081918368

Epoch: 5| Step: 10
Training loss: 0.47507011890411377
Validation loss: 1.7881177689439507

Epoch: 284| Step: 0
Training loss: 0.5814133882522583
Validation loss: 1.7627599034258115

Epoch: 5| Step: 1
Training loss: 0.8521637916564941
Validation loss: 1.7629406529088174

Epoch: 5| Step: 2
Training loss: 0.7087381482124329
Validation loss: 1.7614674504085253

Epoch: 5| Step: 3
Training loss: 0.702354371547699
Validation loss: 1.785227342318463

Epoch: 5| Step: 4
Training loss: 0.9201846122741699
Validation loss: 1.7704642536819621

Epoch: 5| Step: 5
Training loss: 1.0434749126434326
Validation loss: 1.794398937174069

Epoch: 5| Step: 6
Training loss: 0.5594832301139832
Validation loss: 1.8251965494566067

Epoch: 5| Step: 7
Training loss: 1.1146777868270874
Validation loss: 1.8683949888393443

Epoch: 5| Step: 8
Training loss: 1.264552116394043
Validation loss: 1.8636962470187937

Epoch: 5| Step: 9
Training loss: 0.7323367595672607
Validation loss: 1.8402039069001392

Epoch: 5| Step: 10
Training loss: 0.6795992851257324
Validation loss: 1.8421221087055821

Epoch: 285| Step: 0
Training loss: 1.0455896854400635
Validation loss: 1.8321112266150854

Epoch: 5| Step: 1
Training loss: 0.9481317400932312
Validation loss: 1.8200203013676468

Epoch: 5| Step: 2
Training loss: 0.5239464640617371
Validation loss: 1.8184688475824171

Epoch: 5| Step: 3
Training loss: 0.4208053946495056
Validation loss: 1.807705965093387

Epoch: 5| Step: 4
Training loss: 0.9422443509101868
Validation loss: 1.8113391732656827

Epoch: 5| Step: 5
Training loss: 0.9409324526786804
Validation loss: 1.8342547442323418

Epoch: 5| Step: 6
Training loss: 0.7499202489852905
Validation loss: 1.8089876854291527

Epoch: 5| Step: 7
Training loss: 1.101148009300232
Validation loss: 1.7739759106789865

Epoch: 5| Step: 8
Training loss: 0.9779512286186218
Validation loss: 1.7828382202374038

Epoch: 5| Step: 9
Training loss: 0.7842540740966797
Validation loss: 1.8047997810507332

Epoch: 5| Step: 10
Training loss: 0.6437448263168335
Validation loss: 1.8008998581158218

Epoch: 286| Step: 0
Training loss: 0.8490487933158875
Validation loss: 1.80850439558747

Epoch: 5| Step: 1
Training loss: 0.6923505663871765
Validation loss: 1.8147323144379484

Epoch: 5| Step: 2
Training loss: 0.8675438165664673
Validation loss: 1.831499271495368

Epoch: 5| Step: 3
Training loss: 0.7621129751205444
Validation loss: 1.80191453554297

Epoch: 5| Step: 4
Training loss: 0.9205564260482788
Validation loss: 1.8133948669638684

Epoch: 5| Step: 5
Training loss: 1.0595121383666992
Validation loss: 1.8077220352747108

Epoch: 5| Step: 6
Training loss: 0.8158548474311829
Validation loss: 1.7881161576958113

Epoch: 5| Step: 7
Training loss: 0.6567782163619995
Validation loss: 1.7914745384647

Epoch: 5| Step: 8
Training loss: 1.1716262102127075
Validation loss: 1.7859780429511942

Epoch: 5| Step: 9
Training loss: 0.483276903629303
Validation loss: 1.800409209343695

Epoch: 5| Step: 10
Training loss: 0.7585717439651489
Validation loss: 1.78829921701903

Epoch: 287| Step: 0
Training loss: 0.9833242297172546
Validation loss: 1.7789924272926905

Epoch: 5| Step: 1
Training loss: 1.1929640769958496
Validation loss: 1.7851254734941708

Epoch: 5| Step: 2
Training loss: 0.6313472986221313
Validation loss: 1.8001947172226445

Epoch: 5| Step: 3
Training loss: 0.5537880063056946
Validation loss: 1.7655476100983158

Epoch: 5| Step: 4
Training loss: 0.9052616357803345
Validation loss: 1.780660730536266

Epoch: 5| Step: 5
Training loss: 0.783981204032898
Validation loss: 1.7524534681791901

Epoch: 5| Step: 6
Training loss: 0.5934363007545471
Validation loss: 1.782941851564633

Epoch: 5| Step: 7
Training loss: 0.7301826477050781
Validation loss: 1.777383618457343

Epoch: 5| Step: 8
Training loss: 0.8227769732475281
Validation loss: 1.7907891850317679

Epoch: 5| Step: 9
Training loss: 0.9274615049362183
Validation loss: 1.8031753096529233

Epoch: 5| Step: 10
Training loss: 0.8180245757102966
Validation loss: 1.7917832110517768

Epoch: 288| Step: 0
Training loss: 0.8752878308296204
Validation loss: 1.791196415501256

Epoch: 5| Step: 1
Training loss: 0.8977119326591492
Validation loss: 1.768020183809342

Epoch: 5| Step: 2
Training loss: 1.2301464080810547
Validation loss: 1.781476205395114

Epoch: 5| Step: 3
Training loss: 0.7792128920555115
Validation loss: 1.7754685648026005

Epoch: 5| Step: 4
Training loss: 0.6488518714904785
Validation loss: 1.766832342711828

Epoch: 5| Step: 5
Training loss: 0.5338524580001831
Validation loss: 1.7921015883004794

Epoch: 5| Step: 6
Training loss: 0.8444312810897827
Validation loss: 1.7779539490258822

Epoch: 5| Step: 7
Training loss: 0.7762784361839294
Validation loss: 1.7644480607842887

Epoch: 5| Step: 8
Training loss: 0.5396810173988342
Validation loss: 1.7370971428450717

Epoch: 5| Step: 9
Training loss: 0.5279699563980103
Validation loss: 1.7511195405837028

Epoch: 5| Step: 10
Training loss: 1.128874659538269
Validation loss: 1.7374067908974105

Epoch: 289| Step: 0
Training loss: 0.7199437022209167
Validation loss: 1.7204750263562767

Epoch: 5| Step: 1
Training loss: 0.6207594275474548
Validation loss: 1.751000992713436

Epoch: 5| Step: 2
Training loss: 0.7834919095039368
Validation loss: 1.7393503317268946

Epoch: 5| Step: 3
Training loss: 0.8832939863204956
Validation loss: 1.7733585078229186

Epoch: 5| Step: 4
Training loss: 0.6813773512840271
Validation loss: 1.7583537909292406

Epoch: 5| Step: 5
Training loss: 0.8802714347839355
Validation loss: 1.7651536323690926

Epoch: 5| Step: 6
Training loss: 0.5192698240280151
Validation loss: 1.768523677702873

Epoch: 5| Step: 7
Training loss: 1.0705708265304565
Validation loss: 1.7772052986647493

Epoch: 5| Step: 8
Training loss: 0.7666981220245361
Validation loss: 1.7988944848378499

Epoch: 5| Step: 9
Training loss: 1.076224684715271
Validation loss: 1.8033458725098641

Epoch: 5| Step: 10
Training loss: 0.4112982749938965
Validation loss: 1.8246389947911745

Epoch: 290| Step: 0
Training loss: 0.6495372653007507
Validation loss: 1.8109056744524228

Epoch: 5| Step: 1
Training loss: 1.209181547164917
Validation loss: 1.787846467828238

Epoch: 5| Step: 2
Training loss: 1.0831987857818604
Validation loss: 1.797029919521783

Epoch: 5| Step: 3
Training loss: 0.9750045537948608
Validation loss: 1.7936544995154104

Epoch: 5| Step: 4
Training loss: 0.4346223771572113
Validation loss: 1.7564055509464715

Epoch: 5| Step: 5
Training loss: 0.9779461622238159
Validation loss: 1.7349248342616583

Epoch: 5| Step: 6
Training loss: 0.48556646704673767
Validation loss: 1.752633907461679

Epoch: 5| Step: 7
Training loss: 0.6063836216926575
Validation loss: 1.746202411190156

Epoch: 5| Step: 8
Training loss: 0.8157730102539062
Validation loss: 1.7571091972371584

Epoch: 5| Step: 9
Training loss: 0.6835232973098755
Validation loss: 1.763202633909

Epoch: 5| Step: 10
Training loss: 0.6890311241149902
Validation loss: 1.7981715099785918

Epoch: 291| Step: 0
Training loss: 0.6627842783927917
Validation loss: 1.8061925570170085

Epoch: 5| Step: 1
Training loss: 0.5131335854530334
Validation loss: 1.8591032207653087

Epoch: 5| Step: 2
Training loss: 0.502794086933136
Validation loss: 1.8355860646053026

Epoch: 5| Step: 3
Training loss: 0.6977229714393616
Validation loss: 1.8634664294540242

Epoch: 5| Step: 4
Training loss: 0.9366532564163208
Validation loss: 1.8203194372115596

Epoch: 5| Step: 5
Training loss: 0.8044017553329468
Validation loss: 1.8022839651312879

Epoch: 5| Step: 6
Training loss: 0.7095771431922913
Validation loss: 1.7830743071853474

Epoch: 5| Step: 7
Training loss: 0.7455838918685913
Validation loss: 1.7630728252472416

Epoch: 5| Step: 8
Training loss: 1.3086130619049072
Validation loss: 1.7555073640679801

Epoch: 5| Step: 9
Training loss: 0.8635398745536804
Validation loss: 1.745755349436114

Epoch: 5| Step: 10
Training loss: 0.9920611381530762
Validation loss: 1.7567662487747848

Epoch: 292| Step: 0
Training loss: 0.8494402766227722
Validation loss: 1.739922873435482

Epoch: 5| Step: 1
Training loss: 0.6853923201560974
Validation loss: 1.7553456419257707

Epoch: 5| Step: 2
Training loss: 0.8951154947280884
Validation loss: 1.771216623244747

Epoch: 5| Step: 3
Training loss: 0.9432159662246704
Validation loss: 1.7800819014990201

Epoch: 5| Step: 4
Training loss: 0.9608525037765503
Validation loss: 1.7737247533695673

Epoch: 5| Step: 5
Training loss: 0.5015679597854614
Validation loss: 1.7844606548227289

Epoch: 5| Step: 6
Training loss: 0.7706841826438904
Validation loss: 1.7835031965727448

Epoch: 5| Step: 7
Training loss: 0.9004090428352356
Validation loss: 1.7785040614425496

Epoch: 5| Step: 8
Training loss: 0.5500046610832214
Validation loss: 1.7828111302468084

Epoch: 5| Step: 9
Training loss: 0.8917748332023621
Validation loss: 1.7750113946135326

Epoch: 5| Step: 10
Training loss: 0.528448224067688
Validation loss: 1.7850704808388986

Epoch: 293| Step: 0
Training loss: 0.6171987652778625
Validation loss: 1.7642252035038446

Epoch: 5| Step: 1
Training loss: 0.7831806540489197
Validation loss: 1.7531981673291934

Epoch: 5| Step: 2
Training loss: 0.9381972551345825
Validation loss: 1.764394752440914

Epoch: 5| Step: 3
Training loss: 1.1313612461090088
Validation loss: 1.74506373687457

Epoch: 5| Step: 4
Training loss: 0.9943174123764038
Validation loss: 1.7234672448968376

Epoch: 5| Step: 5
Training loss: 0.7079444527626038
Validation loss: 1.7390720869905205

Epoch: 5| Step: 6
Training loss: 0.5067800879478455
Validation loss: 1.7669520019203104

Epoch: 5| Step: 7
Training loss: 0.46880608797073364
Validation loss: 1.7427051131443312

Epoch: 5| Step: 8
Training loss: 1.0149543285369873
Validation loss: 1.7823416110007995

Epoch: 5| Step: 9
Training loss: 0.6556234955787659
Validation loss: 1.8110770743380311

Epoch: 5| Step: 10
Training loss: 0.7651142477989197
Validation loss: 1.8126241442977742

Epoch: 294| Step: 0
Training loss: 0.6511434316635132
Validation loss: 1.8515406052271526

Epoch: 5| Step: 1
Training loss: 1.1366950273513794
Validation loss: 1.8674039404879335

Epoch: 5| Step: 2
Training loss: 0.9678987264633179
Validation loss: 1.8807801418406989

Epoch: 5| Step: 3
Training loss: 0.6735002398490906
Validation loss: 1.823020286457513

Epoch: 5| Step: 4
Training loss: 0.40544572472572327
Validation loss: 1.8090247056817497

Epoch: 5| Step: 5
Training loss: 0.7169927954673767
Validation loss: 1.782240798396449

Epoch: 5| Step: 6
Training loss: 1.254989743232727
Validation loss: 1.7630694309870403

Epoch: 5| Step: 7
Training loss: 1.1770827770233154
Validation loss: 1.784876549115745

Epoch: 5| Step: 8
Training loss: 0.8852813839912415
Validation loss: 1.8122238266852595

Epoch: 5| Step: 9
Training loss: 0.39711570739746094
Validation loss: 1.7952531678702242

Epoch: 5| Step: 10
Training loss: 0.518124520778656
Validation loss: 1.8194866423965783

Epoch: 295| Step: 0
Training loss: 0.992928683757782
Validation loss: 1.7993048967853669

Epoch: 5| Step: 1
Training loss: 0.9204549789428711
Validation loss: 1.797904868279734

Epoch: 5| Step: 2
Training loss: 0.8463994264602661
Validation loss: 1.8022067803208546

Epoch: 5| Step: 3
Training loss: 0.9901745915412903
Validation loss: 1.8102945435431697

Epoch: 5| Step: 4
Training loss: 0.735660970211029
Validation loss: 1.8191741153758059

Epoch: 5| Step: 5
Training loss: 0.771452784538269
Validation loss: 1.828138025858069

Epoch: 5| Step: 6
Training loss: 0.6432330012321472
Validation loss: 1.8221785509458153

Epoch: 5| Step: 7
Training loss: 0.6979910731315613
Validation loss: 1.798728335288263

Epoch: 5| Step: 8
Training loss: 0.7545949220657349
Validation loss: 1.783851344098327

Epoch: 5| Step: 9
Training loss: 0.8927603960037231
Validation loss: 1.7777775782410816

Epoch: 5| Step: 10
Training loss: 0.37928614020347595
Validation loss: 1.789610762749949

Epoch: 296| Step: 0
Training loss: 0.9054765701293945
Validation loss: 1.7847733292528378

Epoch: 5| Step: 1
Training loss: 0.6759519577026367
Validation loss: 1.8112223814892512

Epoch: 5| Step: 2
Training loss: 0.6256858110427856
Validation loss: 1.8012518062386462

Epoch: 5| Step: 3
Training loss: 0.7595171332359314
Validation loss: 1.794033476101455

Epoch: 5| Step: 4
Training loss: 0.8853553533554077
Validation loss: 1.7693128444815194

Epoch: 5| Step: 5
Training loss: 0.5812739133834839
Validation loss: 1.7767266957990584

Epoch: 5| Step: 6
Training loss: 0.687650203704834
Validation loss: 1.796019446465277

Epoch: 5| Step: 7
Training loss: 0.8172876238822937
Validation loss: 1.8114888257877801

Epoch: 5| Step: 8
Training loss: 0.8380270004272461
Validation loss: 1.8334566905934324

Epoch: 5| Step: 9
Training loss: 0.9943119287490845
Validation loss: 1.8338853287440475

Epoch: 5| Step: 10
Training loss: 0.6903185844421387
Validation loss: 1.8616582988410868

Epoch: 297| Step: 0
Training loss: 0.9244569540023804
Validation loss: 1.834372023100494

Epoch: 5| Step: 1
Training loss: 0.4172155261039734
Validation loss: 1.8438255927895988

Epoch: 5| Step: 2
Training loss: 0.7700899243354797
Validation loss: 1.8310150228520876

Epoch: 5| Step: 3
Training loss: 0.8979193568229675
Validation loss: 1.8095831935123732

Epoch: 5| Step: 4
Training loss: 0.8324376344680786
Validation loss: 1.7802219852324455

Epoch: 5| Step: 5
Training loss: 0.53950035572052
Validation loss: 1.793549245403659

Epoch: 5| Step: 6
Training loss: 1.024566411972046
Validation loss: 1.794058471597651

Epoch: 5| Step: 7
Training loss: 0.6052476763725281
Validation loss: 1.78051370574582

Epoch: 5| Step: 8
Training loss: 0.7718464136123657
Validation loss: 1.7746752853034644

Epoch: 5| Step: 9
Training loss: 0.7793319821357727
Validation loss: 1.7928798737064484

Epoch: 5| Step: 10
Training loss: 0.7369993925094604
Validation loss: 1.7819849726974324

Epoch: 298| Step: 0
Training loss: 0.5288849472999573
Validation loss: 1.804061302574732

Epoch: 5| Step: 1
Training loss: 0.5815866589546204
Validation loss: 1.7961472144690893

Epoch: 5| Step: 2
Training loss: 0.6961358189582825
Validation loss: 1.7921850565941102

Epoch: 5| Step: 3
Training loss: 0.9406535029411316
Validation loss: 1.760390063767792

Epoch: 5| Step: 4
Training loss: 0.8423503637313843
Validation loss: 1.7742760001972158

Epoch: 5| Step: 5
Training loss: 0.6203678250312805
Validation loss: 1.795726050612747

Epoch: 5| Step: 6
Training loss: 0.7936521172523499
Validation loss: 1.7888485693162488

Epoch: 5| Step: 7
Training loss: 0.9109717607498169
Validation loss: 1.799164992506786

Epoch: 5| Step: 8
Training loss: 0.894088089466095
Validation loss: 1.8143313456607122

Epoch: 5| Step: 9
Training loss: 0.6220199465751648
Validation loss: 1.7920719551783737

Epoch: 5| Step: 10
Training loss: 0.6864379644393921
Validation loss: 1.7600606058233528

Epoch: 299| Step: 0
Training loss: 0.632011353969574
Validation loss: 1.7698105663381598

Epoch: 5| Step: 1
Training loss: 0.8132055401802063
Validation loss: 1.778021321501783

Epoch: 5| Step: 2
Training loss: 0.47480249404907227
Validation loss: 1.7748825550079346

Epoch: 5| Step: 3
Training loss: 0.662387490272522
Validation loss: 1.803537808438783

Epoch: 5| Step: 4
Training loss: 0.7085248231887817
Validation loss: 1.8047893098605576

Epoch: 5| Step: 5
Training loss: 0.9524277448654175
Validation loss: 1.8166488293678529

Epoch: 5| Step: 6
Training loss: 0.6083839535713196
Validation loss: 1.8025284505659533

Epoch: 5| Step: 7
Training loss: 0.9467441439628601
Validation loss: 1.8076987445995372

Epoch: 5| Step: 8
Training loss: 0.6511670351028442
Validation loss: 1.7964004150000952

Epoch: 5| Step: 9
Training loss: 0.5396014451980591
Validation loss: 1.7765897038162395

Epoch: 5| Step: 10
Training loss: 0.9555197358131409
Validation loss: 1.799955621842415

Epoch: 300| Step: 0
Training loss: 1.1752054691314697
Validation loss: 1.7669795828480874

Epoch: 5| Step: 1
Training loss: 0.9542862772941589
Validation loss: 1.7647112992502028

Epoch: 5| Step: 2
Training loss: 0.30697101354599
Validation loss: 1.782815360253857

Epoch: 5| Step: 3
Training loss: 0.733546793460846
Validation loss: 1.7554035673859298

Epoch: 5| Step: 4
Training loss: 0.7441004514694214
Validation loss: 1.7587040034673547

Epoch: 5| Step: 5
Training loss: 0.5786100029945374
Validation loss: 1.7635935916695544

Epoch: 5| Step: 6
Training loss: 0.5892990231513977
Validation loss: 1.7652657108922158

Epoch: 5| Step: 7
Training loss: 0.7249524593353271
Validation loss: 1.7730445989998438

Epoch: 5| Step: 8
Training loss: 0.742895781993866
Validation loss: 1.7830015485004713

Epoch: 5| Step: 9
Training loss: 0.7546685338020325
Validation loss: 1.8120726423878823

Epoch: 5| Step: 10
Training loss: 0.5174784660339355
Validation loss: 1.8315284085530106

Epoch: 301| Step: 0
Training loss: 0.6332613229751587
Validation loss: 1.8388620051004554

Epoch: 5| Step: 1
Training loss: 0.7689206004142761
Validation loss: 1.8498657864909018

Epoch: 5| Step: 2
Training loss: 0.5161978602409363
Validation loss: 1.819069226582845

Epoch: 5| Step: 3
Training loss: 0.9747605323791504
Validation loss: 1.7700010038191272

Epoch: 5| Step: 4
Training loss: 0.6323782205581665
Validation loss: 1.7661911608070455

Epoch: 5| Step: 5
Training loss: 0.5651277303695679
Validation loss: 1.7603029974045292

Epoch: 5| Step: 6
Training loss: 0.5647396445274353
Validation loss: 1.7346077901060863

Epoch: 5| Step: 7
Training loss: 0.4264053404331207
Validation loss: 1.75058885030849

Epoch: 5| Step: 8
Training loss: 0.9590592384338379
Validation loss: 1.746123190849058

Epoch: 5| Step: 9
Training loss: 0.8884735107421875
Validation loss: 1.7356602209870533

Epoch: 5| Step: 10
Training loss: 0.9388495683670044
Validation loss: 1.7269937094821726

Epoch: 302| Step: 0
Training loss: 0.7536396980285645
Validation loss: 1.7392979257850236

Epoch: 5| Step: 1
Training loss: 0.848138689994812
Validation loss: 1.7605377845866705

Epoch: 5| Step: 2
Training loss: 0.7548182606697083
Validation loss: 1.777563944939644

Epoch: 5| Step: 3
Training loss: 0.8534186482429504
Validation loss: 1.7975492785053868

Epoch: 5| Step: 4
Training loss: 0.39030328392982483
Validation loss: 1.7997871560435141

Epoch: 5| Step: 5
Training loss: 0.6901699900627136
Validation loss: 1.7580189192166893

Epoch: 5| Step: 6
Training loss: 0.5818220376968384
Validation loss: 1.7126254471399451

Epoch: 5| Step: 7
Training loss: 0.9226828813552856
Validation loss: 1.72622041292088

Epoch: 5| Step: 8
Training loss: 0.7435509562492371
Validation loss: 1.7418621868215582

Epoch: 5| Step: 9
Training loss: 0.8381309509277344
Validation loss: 1.7755294769041

Epoch: 5| Step: 10
Training loss: 0.5175862312316895
Validation loss: 1.7901728704411497

Epoch: 303| Step: 0
Training loss: 0.9535776376724243
Validation loss: 1.7723767398506083

Epoch: 5| Step: 1
Training loss: 0.8524209856987
Validation loss: 1.7781597504051783

Epoch: 5| Step: 2
Training loss: 0.804120659828186
Validation loss: 1.786663414329611

Epoch: 5| Step: 3
Training loss: 0.4658101499080658
Validation loss: 1.7414428931410595

Epoch: 5| Step: 4
Training loss: 0.5010515451431274
Validation loss: 1.7366062210452171

Epoch: 5| Step: 5
Training loss: 0.9828212857246399
Validation loss: 1.746027042788844

Epoch: 5| Step: 6
Training loss: 0.5471564531326294
Validation loss: 1.762763459195373

Epoch: 5| Step: 7
Training loss: 0.7233017086982727
Validation loss: 1.8015391941993468

Epoch: 5| Step: 8
Training loss: 0.5236106514930725
Validation loss: 1.8003272728253437

Epoch: 5| Step: 9
Training loss: 0.5593646168708801
Validation loss: 1.7906877122899538

Epoch: 5| Step: 10
Training loss: 1.0527948141098022
Validation loss: 1.768054041811215

Epoch: 304| Step: 0
Training loss: 0.512523889541626
Validation loss: 1.7472522425395187

Epoch: 5| Step: 1
Training loss: 0.5969510674476624
Validation loss: 1.7364922415825628

Epoch: 5| Step: 2
Training loss: 1.0771564245224
Validation loss: 1.7419026884981381

Epoch: 5| Step: 3
Training loss: 0.7372606992721558
Validation loss: 1.7351665061007264

Epoch: 5| Step: 4
Training loss: 0.7444325089454651
Validation loss: 1.743333843446547

Epoch: 5| Step: 5
Training loss: 0.5900751948356628
Validation loss: 1.7417780539040923

Epoch: 5| Step: 6
Training loss: 0.9586304426193237
Validation loss: 1.764278256764976

Epoch: 5| Step: 7
Training loss: 0.79509037733078
Validation loss: 1.7707087865439795

Epoch: 5| Step: 8
Training loss: 0.8512338399887085
Validation loss: 1.7829623401805919

Epoch: 5| Step: 9
Training loss: 0.46023932099342346
Validation loss: 1.791074138815685

Epoch: 5| Step: 10
Training loss: 0.22475425899028778
Validation loss: 1.7950678358795822

Epoch: 305| Step: 0
Training loss: 0.5467613339424133
Validation loss: 1.8195742240516088

Epoch: 5| Step: 1
Training loss: 0.8840305209159851
Validation loss: 1.818993378711003

Epoch: 5| Step: 2
Training loss: 0.649252712726593
Validation loss: 1.8214953009800245

Epoch: 5| Step: 3
Training loss: 0.6862794756889343
Validation loss: 1.7743748054709485

Epoch: 5| Step: 4
Training loss: 0.5549781322479248
Validation loss: 1.7480475697466122

Epoch: 5| Step: 5
Training loss: 0.6831426620483398
Validation loss: 1.7358332462208246

Epoch: 5| Step: 6
Training loss: 0.8709009289741516
Validation loss: 1.7324203342519782

Epoch: 5| Step: 7
Training loss: 0.7988284826278687
Validation loss: 1.7509262971980597

Epoch: 5| Step: 8
Training loss: 0.6727550029754639
Validation loss: 1.7252679230064474

Epoch: 5| Step: 9
Training loss: 0.7804316878318787
Validation loss: 1.698590301698254

Epoch: 5| Step: 10
Training loss: 0.8796957731246948
Validation loss: 1.7098039786020915

Epoch: 306| Step: 0
Training loss: 0.7072122693061829
Validation loss: 1.7156184963000718

Epoch: 5| Step: 1
Training loss: 0.5576136708259583
Validation loss: 1.7346123136499876

Epoch: 5| Step: 2
Training loss: 0.9000266790390015
Validation loss: 1.7622143760804208

Epoch: 5| Step: 3
Training loss: 0.5708185434341431
Validation loss: 1.7917939373241958

Epoch: 5| Step: 4
Training loss: 1.158329725265503
Validation loss: 1.8006320576513968

Epoch: 5| Step: 5
Training loss: 0.5857208967208862
Validation loss: 1.7446328004201253

Epoch: 5| Step: 6
Training loss: 0.9455035924911499
Validation loss: 1.7368022882810203

Epoch: 5| Step: 7
Training loss: 0.668198823928833
Validation loss: 1.7279621260140532

Epoch: 5| Step: 8
Training loss: 0.683789074420929
Validation loss: 1.726345350665431

Epoch: 5| Step: 9
Training loss: 0.5438275337219238
Validation loss: 1.7295132349896174

Epoch: 5| Step: 10
Training loss: 0.3796042203903198
Validation loss: 1.6960251562057003

Epoch: 307| Step: 0
Training loss: 0.6259620785713196
Validation loss: 1.715247352917989

Epoch: 5| Step: 1
Training loss: 0.7512739896774292
Validation loss: 1.684655599696662

Epoch: 5| Step: 2
Training loss: 0.43463873863220215
Validation loss: 1.7142859594796294

Epoch: 5| Step: 3
Training loss: 0.8058664202690125
Validation loss: 1.7182585552174559

Epoch: 5| Step: 4
Training loss: 0.8649352788925171
Validation loss: 1.7592878213492773

Epoch: 5| Step: 5
Training loss: 0.5756531357765198
Validation loss: 1.786369227593945

Epoch: 5| Step: 6
Training loss: 0.773791491985321
Validation loss: 1.812523297084275

Epoch: 5| Step: 7
Training loss: 0.5835216045379639
Validation loss: 1.8155409777036278

Epoch: 5| Step: 8
Training loss: 0.8623364567756653
Validation loss: 1.8174763879468363

Epoch: 5| Step: 9
Training loss: 0.8933559656143188
Validation loss: 1.7949713891552341

Epoch: 5| Step: 10
Training loss: 0.27761030197143555
Validation loss: 1.7905496999781618

Epoch: 308| Step: 0
Training loss: 0.6960263252258301
Validation loss: 1.7562697254201418

Epoch: 5| Step: 1
Training loss: 0.34454405307769775
Validation loss: 1.76474585968961

Epoch: 5| Step: 2
Training loss: 0.4861120581626892
Validation loss: 1.7525302671617078

Epoch: 5| Step: 3
Training loss: 0.5268963575363159
Validation loss: 1.7814626155361053

Epoch: 5| Step: 4
Training loss: 0.5546506643295288
Validation loss: 1.7800029490583686

Epoch: 5| Step: 5
Training loss: 0.9174927473068237
Validation loss: 1.7994181263831355

Epoch: 5| Step: 6
Training loss: 0.7047078013420105
Validation loss: 1.804608727014193

Epoch: 5| Step: 7
Training loss: 0.8083431124687195
Validation loss: 1.8077962616438508

Epoch: 5| Step: 8
Training loss: 0.7676402926445007
Validation loss: 1.8034232765115716

Epoch: 5| Step: 9
Training loss: 1.1584217548370361
Validation loss: 1.7932032154452415

Epoch: 5| Step: 10
Training loss: 0.8374538421630859
Validation loss: 1.7764077583948772

Epoch: 309| Step: 0
Training loss: 0.7720519304275513
Validation loss: 1.8115760177694342

Epoch: 5| Step: 1
Training loss: 0.6812955141067505
Validation loss: 1.8174191354423441

Epoch: 5| Step: 2
Training loss: 0.8204936981201172
Validation loss: 1.8066761596228487

Epoch: 5| Step: 3
Training loss: 0.374148964881897
Validation loss: 1.7739804457592707

Epoch: 5| Step: 4
Training loss: 0.4603046774864197
Validation loss: 1.7825560377490135

Epoch: 5| Step: 5
Training loss: 0.9254153966903687
Validation loss: 1.7533826123001754

Epoch: 5| Step: 6
Training loss: 0.40294432640075684
Validation loss: 1.7317191708472468

Epoch: 5| Step: 7
Training loss: 0.7952097058296204
Validation loss: 1.7320896169190765

Epoch: 5| Step: 8
Training loss: 0.7380386590957642
Validation loss: 1.7543367365355134

Epoch: 5| Step: 9
Training loss: 0.7342108488082886
Validation loss: 1.7503429369259906

Epoch: 5| Step: 10
Training loss: 0.5464314818382263
Validation loss: 1.7714104934405255

Epoch: 310| Step: 0
Training loss: 0.4199443757534027
Validation loss: 1.7715939142370736

Epoch: 5| Step: 1
Training loss: 0.48392611742019653
Validation loss: 1.749292019874819

Epoch: 5| Step: 2
Training loss: 0.6606507301330566
Validation loss: 1.7672880259893273

Epoch: 5| Step: 3
Training loss: 0.6236796379089355
Validation loss: 1.7626812842584425

Epoch: 5| Step: 4
Training loss: 0.7637029886245728
Validation loss: 1.7788768750365063

Epoch: 5| Step: 5
Training loss: 0.8308303952217102
Validation loss: 1.7836857572678597

Epoch: 5| Step: 6
Training loss: 0.9615427255630493
Validation loss: 1.7587791040379515

Epoch: 5| Step: 7
Training loss: 0.6530672311782837
Validation loss: 1.791200267371311

Epoch: 5| Step: 8
Training loss: 0.8634465932846069
Validation loss: 1.8144999306689027

Epoch: 5| Step: 9
Training loss: 0.7375657558441162
Validation loss: 1.7901033868071854

Epoch: 5| Step: 10
Training loss: 0.5463475584983826
Validation loss: 1.7806746100866666

Epoch: 311| Step: 0
Training loss: 0.9111422300338745
Validation loss: 1.759273313706921

Epoch: 5| Step: 1
Training loss: 0.3874585032463074
Validation loss: 1.7569760814789803

Epoch: 5| Step: 2
Training loss: 1.1729090213775635
Validation loss: 1.7607884150679394

Epoch: 5| Step: 3
Training loss: 0.5926750898361206
Validation loss: 1.7749482329173754

Epoch: 5| Step: 4
Training loss: 0.7882018685340881
Validation loss: 1.742798905218801

Epoch: 5| Step: 5
Training loss: 0.5384591817855835
Validation loss: 1.7495832186873241

Epoch: 5| Step: 6
Training loss: 0.2592593729496002
Validation loss: 1.7557616310734903

Epoch: 5| Step: 7
Training loss: 0.4973572790622711
Validation loss: 1.7246004048214163

Epoch: 5| Step: 8
Training loss: 0.574453592300415
Validation loss: 1.7150293268183225

Epoch: 5| Step: 9
Training loss: 0.6488665342330933
Validation loss: 1.7377417638737669

Epoch: 5| Step: 10
Training loss: 0.6523089408874512
Validation loss: 1.7558472105251846

Epoch: 312| Step: 0
Training loss: 0.3946656286716461
Validation loss: 1.7556073819437334

Epoch: 5| Step: 1
Training loss: 0.6309659481048584
Validation loss: 1.7820166016137728

Epoch: 5| Step: 2
Training loss: 0.6340758204460144
Validation loss: 1.7932659156860844

Epoch: 5| Step: 3
Training loss: 0.5742241740226746
Validation loss: 1.778806395428155

Epoch: 5| Step: 4
Training loss: 0.6038854122161865
Validation loss: 1.7577147868371779

Epoch: 5| Step: 5
Training loss: 0.5774035453796387
Validation loss: 1.7353013561617943

Epoch: 5| Step: 6
Training loss: 0.7794007062911987
Validation loss: 1.720810459506127

Epoch: 5| Step: 7
Training loss: 0.5127822160720825
Validation loss: 1.7294848875332904

Epoch: 5| Step: 8
Training loss: 0.58230060338974
Validation loss: 1.7242950483035016

Epoch: 5| Step: 9
Training loss: 0.9584854245185852
Validation loss: 1.7073387663851503

Epoch: 5| Step: 10
Training loss: 1.0001451969146729
Validation loss: 1.7131311624280867

Epoch: 313| Step: 0
Training loss: 0.9268999099731445
Validation loss: 1.7035121161450621

Epoch: 5| Step: 1
Training loss: 0.8389215469360352
Validation loss: 1.7196283558363556

Epoch: 5| Step: 2
Training loss: 0.7974746227264404
Validation loss: 1.7399380873608332

Epoch: 5| Step: 3
Training loss: 0.40145570039749146
Validation loss: 1.765517557820966

Epoch: 5| Step: 4
Training loss: 0.46635714173316956
Validation loss: 1.765224290150468

Epoch: 5| Step: 5
Training loss: 0.4926427900791168
Validation loss: 1.7991669306191065

Epoch: 5| Step: 6
Training loss: 0.6139830946922302
Validation loss: 1.7674514324434343

Epoch: 5| Step: 7
Training loss: 0.5362265110015869
Validation loss: 1.7682998154752998

Epoch: 5| Step: 8
Training loss: 0.6126313805580139
Validation loss: 1.7389193580996605

Epoch: 5| Step: 9
Training loss: 0.47654446959495544
Validation loss: 1.7448878083177792

Epoch: 5| Step: 10
Training loss: 0.7475878596305847
Validation loss: 1.7306796696878248

Epoch: 314| Step: 0
Training loss: 0.5131491422653198
Validation loss: 1.7532808114123601

Epoch: 5| Step: 1
Training loss: 0.7657274603843689
Validation loss: 1.7186783616260817

Epoch: 5| Step: 2
Training loss: 0.8964945077896118
Validation loss: 1.7810255301895963

Epoch: 5| Step: 3
Training loss: 0.49763521552085876
Validation loss: 1.824756706914594

Epoch: 5| Step: 4
Training loss: 0.9129878878593445
Validation loss: 1.8114619921612483

Epoch: 5| Step: 5
Training loss: 0.6783229112625122
Validation loss: 1.7866636296754241

Epoch: 5| Step: 6
Training loss: 0.5032802820205688
Validation loss: 1.7412420370245492

Epoch: 5| Step: 7
Training loss: 0.7714444994926453
Validation loss: 1.7206194695606027

Epoch: 5| Step: 8
Training loss: 0.6726946830749512
Validation loss: 1.7329062184979838

Epoch: 5| Step: 9
Training loss: 0.6767670512199402
Validation loss: 1.7490028847930252

Epoch: 5| Step: 10
Training loss: 0.4366382360458374
Validation loss: 1.744371219347882

Epoch: 315| Step: 0
Training loss: 0.8014494776725769
Validation loss: 1.7240914965188632

Epoch: 5| Step: 1
Training loss: 0.6428740620613098
Validation loss: 1.7245854434146677

Epoch: 5| Step: 2
Training loss: 0.7004181146621704
Validation loss: 1.7434331768302507

Epoch: 5| Step: 3
Training loss: 0.5335550904273987
Validation loss: 1.7456467997643255

Epoch: 5| Step: 4
Training loss: 0.6690831184387207
Validation loss: 1.7978793357008247

Epoch: 5| Step: 5
Training loss: 0.6481881141662598
Validation loss: 1.791988741966986

Epoch: 5| Step: 6
Training loss: 0.45302814245224
Validation loss: 1.7774169445037842

Epoch: 5| Step: 7
Training loss: 0.504115104675293
Validation loss: 1.774345055703194

Epoch: 5| Step: 8
Training loss: 0.48748892545700073
Validation loss: 1.7900004668902325

Epoch: 5| Step: 9
Training loss: 1.0870147943496704
Validation loss: 1.790197592909618

Epoch: 5| Step: 10
Training loss: 0.8309676647186279
Validation loss: 1.7817426291845178

Epoch: 316| Step: 0
Training loss: 0.6638301610946655
Validation loss: 1.8128996177386212

Epoch: 5| Step: 1
Training loss: 0.469047874212265
Validation loss: 1.7751310563856555

Epoch: 5| Step: 2
Training loss: 0.5946950316429138
Validation loss: 1.8027253855941117

Epoch: 5| Step: 3
Training loss: 0.47590169310569763
Validation loss: 1.7711483560582644

Epoch: 5| Step: 4
Training loss: 0.7657179832458496
Validation loss: 1.779480955934012

Epoch: 5| Step: 5
Training loss: 0.6176230311393738
Validation loss: 1.7365120431428314

Epoch: 5| Step: 6
Training loss: 0.5798220038414001
Validation loss: 1.7662520946994904

Epoch: 5| Step: 7
Training loss: 0.6839972734451294
Validation loss: 1.7558988499385055

Epoch: 5| Step: 8
Training loss: 0.6291004419326782
Validation loss: 1.7747629906541558

Epoch: 5| Step: 9
Training loss: 0.7708605527877808
Validation loss: 1.7893667990161526

Epoch: 5| Step: 10
Training loss: 0.7419342994689941
Validation loss: 1.7381740026576544

Epoch: 317| Step: 0
Training loss: 0.5919787883758545
Validation loss: 1.729880702111029

Epoch: 5| Step: 1
Training loss: 1.454019546508789
Validation loss: 1.737035120687177

Epoch: 5| Step: 2
Training loss: 0.7104617953300476
Validation loss: 1.7260367908785421

Epoch: 5| Step: 3
Training loss: 0.39259010553359985
Validation loss: 1.71229645000991

Epoch: 5| Step: 4
Training loss: 0.43528351187705994
Validation loss: 1.714474702394137

Epoch: 5| Step: 5
Training loss: 0.2503507137298584
Validation loss: 1.6979132083154493

Epoch: 5| Step: 6
Training loss: 0.4518210291862488
Validation loss: 1.7001703682766165

Epoch: 5| Step: 7
Training loss: 0.6600468158721924
Validation loss: 1.705945569981811

Epoch: 5| Step: 8
Training loss: 0.47832489013671875
Validation loss: 1.705171246682444

Epoch: 5| Step: 9
Training loss: 0.658759593963623
Validation loss: 1.7311728462096183

Epoch: 5| Step: 10
Training loss: 0.5578584671020508
Validation loss: 1.730868520275239

Epoch: 318| Step: 0
Training loss: 1.1556644439697266
Validation loss: 1.7324302145229873

Epoch: 5| Step: 1
Training loss: 0.5675063133239746
Validation loss: 1.753995830012906

Epoch: 5| Step: 2
Training loss: 0.6251627206802368
Validation loss: 1.7540680029058968

Epoch: 5| Step: 3
Training loss: 0.42866772413253784
Validation loss: 1.7345611151828562

Epoch: 5| Step: 4
Training loss: 0.512006402015686
Validation loss: 1.7659574964995026

Epoch: 5| Step: 5
Training loss: 0.3170401453971863
Validation loss: 1.7395902102993381

Epoch: 5| Step: 6
Training loss: 0.419971227645874
Validation loss: 1.708260956630912

Epoch: 5| Step: 7
Training loss: 0.801357090473175
Validation loss: 1.7222231447055776

Epoch: 5| Step: 8
Training loss: 0.6949216723442078
Validation loss: 1.7107357504547283

Epoch: 5| Step: 9
Training loss: 0.6336604356765747
Validation loss: 1.7180806834210631

Epoch: 5| Step: 10
Training loss: 0.5396782755851746
Validation loss: 1.7319268103568786

Epoch: 319| Step: 0
Training loss: 0.7708368897438049
Validation loss: 1.7289764740133797

Epoch: 5| Step: 1
Training loss: 0.5803117752075195
Validation loss: 1.7494630377779725

Epoch: 5| Step: 2
Training loss: 0.5445613265037537
Validation loss: 1.7494926350091093

Epoch: 5| Step: 3
Training loss: 1.0340663194656372
Validation loss: 1.7785067084015056

Epoch: 5| Step: 4
Training loss: 0.671054482460022
Validation loss: 1.7670435418364823

Epoch: 5| Step: 5
Training loss: 0.5479750633239746
Validation loss: 1.7937601843187887

Epoch: 5| Step: 6
Training loss: 0.6190887689590454
Validation loss: 1.8182751363323582

Epoch: 5| Step: 7
Training loss: 1.052187204360962
Validation loss: 1.846427862362195

Epoch: 5| Step: 8
Training loss: 0.25011759996414185
Validation loss: 1.7534673931778118

Epoch: 5| Step: 9
Training loss: 0.3635581135749817
Validation loss: 1.742206520931695

Epoch: 5| Step: 10
Training loss: 0.5864052772521973
Validation loss: 1.7379638943620908

Epoch: 320| Step: 0
Training loss: 0.27849438786506653
Validation loss: 1.7574422180011708

Epoch: 5| Step: 1
Training loss: 0.8111804723739624
Validation loss: 1.8034108954091226

Epoch: 5| Step: 2
Training loss: 1.0750348567962646
Validation loss: 1.793462904550696

Epoch: 5| Step: 3
Training loss: 0.8677730560302734
Validation loss: 1.7557124655733827

Epoch: 5| Step: 4
Training loss: 0.769234836101532
Validation loss: 1.7068399729267243

Epoch: 5| Step: 5
Training loss: 0.5609871745109558
Validation loss: 1.6836082217513875

Epoch: 5| Step: 6
Training loss: 0.8506259918212891
Validation loss: 1.7134643254741546

Epoch: 5| Step: 7
Training loss: 0.3687346577644348
Validation loss: 1.7171881262974074

Epoch: 5| Step: 8
Training loss: 0.7415935397148132
Validation loss: 1.711816636464929

Epoch: 5| Step: 9
Training loss: 0.5727900266647339
Validation loss: 1.7020741816489928

Epoch: 5| Step: 10
Training loss: 0.2986680269241333
Validation loss: 1.6965155768138107

Epoch: 321| Step: 0
Training loss: 0.5816235542297363
Validation loss: 1.7112656408740627

Epoch: 5| Step: 1
Training loss: 0.7577120065689087
Validation loss: 1.7838767600315872

Epoch: 5| Step: 2
Training loss: 0.29320162534713745
Validation loss: 1.785258388006559

Epoch: 5| Step: 3
Training loss: 0.48528265953063965
Validation loss: 1.7657172244082215

Epoch: 5| Step: 4
Training loss: 0.6033109426498413
Validation loss: 1.7596605041975617

Epoch: 5| Step: 5
Training loss: 0.5664975047111511
Validation loss: 1.7482806110894809

Epoch: 5| Step: 6
Training loss: 0.4958231449127197
Validation loss: 1.7271059854056245

Epoch: 5| Step: 7
Training loss: 1.0548193454742432
Validation loss: 1.739135948560571

Epoch: 5| Step: 8
Training loss: 0.34717920422554016
Validation loss: 1.7084825782365696

Epoch: 5| Step: 9
Training loss: 0.39345020055770874
Validation loss: 1.7129433847242785

Epoch: 5| Step: 10
Training loss: 0.9014198780059814
Validation loss: 1.7294700030357606

Epoch: 322| Step: 0
Training loss: 0.7254523634910583
Validation loss: 1.7084884053917342

Epoch: 5| Step: 1
Training loss: 0.5549846887588501
Validation loss: 1.7015472900482915

Epoch: 5| Step: 2
Training loss: 1.0119417905807495
Validation loss: 1.700153338011875

Epoch: 5| Step: 3
Training loss: 0.6305066347122192
Validation loss: 1.7015405085779005

Epoch: 5| Step: 4
Training loss: 0.4506969451904297
Validation loss: 1.6994792069158247

Epoch: 5| Step: 5
Training loss: 0.5679505467414856
Validation loss: 1.7248952145217566

Epoch: 5| Step: 6
Training loss: 0.6586815118789673
Validation loss: 1.718570516955468

Epoch: 5| Step: 7
Training loss: 0.48307037353515625
Validation loss: 1.7249171144218856

Epoch: 5| Step: 8
Training loss: 0.10941846668720245
Validation loss: 1.7168242034091745

Epoch: 5| Step: 9
Training loss: 0.5709429979324341
Validation loss: 1.7587049661144134

Epoch: 5| Step: 10
Training loss: 0.44626420736312866
Validation loss: 1.761360772194401

Epoch: 323| Step: 0
Training loss: 0.4731505811214447
Validation loss: 1.7477708721673617

Epoch: 5| Step: 1
Training loss: 0.6525317430496216
Validation loss: 1.7081764526264642

Epoch: 5| Step: 2
Training loss: 0.42100459337234497
Validation loss: 1.7225617670243787

Epoch: 5| Step: 3
Training loss: 0.7717318534851074
Validation loss: 1.6853576167937248

Epoch: 5| Step: 4
Training loss: 0.24739539623260498
Validation loss: 1.6809596348834295

Epoch: 5| Step: 5
Training loss: 0.5384510159492493
Validation loss: 1.6749348025168143

Epoch: 5| Step: 6
Training loss: 0.362956166267395
Validation loss: 1.6531636215025378

Epoch: 5| Step: 7
Training loss: 1.0950181484222412
Validation loss: 1.6721787055333455

Epoch: 5| Step: 8
Training loss: 0.5131029486656189
Validation loss: 1.669250319080968

Epoch: 5| Step: 9
Training loss: 0.2582298815250397
Validation loss: 1.729823495752068

Epoch: 5| Step: 10
Training loss: 0.7028208374977112
Validation loss: 1.6940118907600321

Epoch: 324| Step: 0
Training loss: 0.6138224005699158
Validation loss: 1.729564473193179

Epoch: 5| Step: 1
Training loss: 0.9868747591972351
Validation loss: 1.7456321562490156

Epoch: 5| Step: 2
Training loss: 0.567908525466919
Validation loss: 1.7485128666764946

Epoch: 5| Step: 3
Training loss: 0.2681195139884949
Validation loss: 1.7559622692805466

Epoch: 5| Step: 4
Training loss: 0.5153811573982239
Validation loss: 1.7428216293293943

Epoch: 5| Step: 5
Training loss: 0.38486161828041077
Validation loss: 1.7424022190032467

Epoch: 5| Step: 6
Training loss: 0.6372872591018677
Validation loss: 1.7160366042967765

Epoch: 5| Step: 7
Training loss: 0.6625338792800903
Validation loss: 1.7026569689473798

Epoch: 5| Step: 8
Training loss: 0.5617296099662781
Validation loss: 1.6966671398890916

Epoch: 5| Step: 9
Training loss: 0.7586036920547485
Validation loss: 1.711651699517363

Epoch: 5| Step: 10
Training loss: 0.33435988426208496
Validation loss: 1.700414679383719

Epoch: 325| Step: 0
Training loss: 0.4627331793308258
Validation loss: 1.663300967985584

Epoch: 5| Step: 1
Training loss: 0.3921022415161133
Validation loss: 1.6857398786852438

Epoch: 5| Step: 2
Training loss: 0.5568615794181824
Validation loss: 1.6987999203384563

Epoch: 5| Step: 3
Training loss: 0.36660686135292053
Validation loss: 1.7346901175796345

Epoch: 5| Step: 4
Training loss: 0.7548753619194031
Validation loss: 1.772910900013421

Epoch: 5| Step: 5
Training loss: 0.5855823755264282
Validation loss: 1.7782535834978985

Epoch: 5| Step: 6
Training loss: 0.9060308337211609
Validation loss: 1.7280188427176526

Epoch: 5| Step: 7
Training loss: 0.47054845094680786
Validation loss: 1.7212267793634886

Epoch: 5| Step: 8
Training loss: 0.5403987765312195
Validation loss: 1.6723153642428819

Epoch: 5| Step: 9
Training loss: 0.5886579155921936
Validation loss: 1.6684034364197844

Epoch: 5| Step: 10
Training loss: 0.6221300959587097
Validation loss: 1.6731407732091925

Epoch: 326| Step: 0
Training loss: 0.3174634873867035
Validation loss: 1.6481985033199351

Epoch: 5| Step: 1
Training loss: 0.38577964901924133
Validation loss: 1.6825040783933414

Epoch: 5| Step: 2
Training loss: 0.785508930683136
Validation loss: 1.673131351829857

Epoch: 5| Step: 3
Training loss: 0.5956391096115112
Validation loss: 1.6601330913523191

Epoch: 5| Step: 4
Training loss: 0.5966899991035461
Validation loss: 1.6641009238458448

Epoch: 5| Step: 5
Training loss: 0.5591230392456055
Validation loss: 1.6672207898991083

Epoch: 5| Step: 6
Training loss: 0.6251325011253357
Validation loss: 1.6857819070098221

Epoch: 5| Step: 7
Training loss: 0.43996915221214294
Validation loss: 1.7095872766228133

Epoch: 5| Step: 8
Training loss: 0.4336235523223877
Validation loss: 1.7065596721505607

Epoch: 5| Step: 9
Training loss: 0.8717948198318481
Validation loss: 1.7041459942376742

Epoch: 5| Step: 10
Training loss: 0.550760805606842
Validation loss: 1.7119255745282738

Epoch: 327| Step: 0
Training loss: 0.5463777184486389
Validation loss: 1.7295790744084183

Epoch: 5| Step: 1
Training loss: 0.2819444537162781
Validation loss: 1.698200096366226

Epoch: 5| Step: 2
Training loss: 0.592556357383728
Validation loss: 1.6938780982007262

Epoch: 5| Step: 3
Training loss: 0.8583394289016724
Validation loss: 1.70725626971132

Epoch: 5| Step: 4
Training loss: 0.5710726976394653
Validation loss: 1.6926583731046287

Epoch: 5| Step: 5
Training loss: 0.3578440546989441
Validation loss: 1.7152306905356787

Epoch: 5| Step: 6
Training loss: 0.4872336983680725
Validation loss: 1.715068358246998

Epoch: 5| Step: 7
Training loss: 0.5237170457839966
Validation loss: 1.747960255992028

Epoch: 5| Step: 8
Training loss: 0.531174898147583
Validation loss: 1.7354454096927439

Epoch: 5| Step: 9
Training loss: 0.49770259857177734
Validation loss: 1.7306355558415896

Epoch: 5| Step: 10
Training loss: 0.6416624188423157
Validation loss: 1.712590927718788

Epoch: 328| Step: 0
Training loss: 0.49720436334609985
Validation loss: 1.744231052296136

Epoch: 5| Step: 1
Training loss: 0.7061938047409058
Validation loss: 1.7440452011682654

Epoch: 5| Step: 2
Training loss: 0.46697884798049927
Validation loss: 1.7114714550715622

Epoch: 5| Step: 3
Training loss: 0.904691219329834
Validation loss: 1.6776323895300589

Epoch: 5| Step: 4
Training loss: 0.31365519762039185
Validation loss: 1.7121817552915184

Epoch: 5| Step: 5
Training loss: 0.4056917130947113
Validation loss: 1.71924179087403

Epoch: 5| Step: 6
Training loss: 0.3944799304008484
Validation loss: 1.7139407306589105

Epoch: 5| Step: 7
Training loss: 0.40036025643348694
Validation loss: 1.7080089481928016

Epoch: 5| Step: 8
Training loss: 0.5097895860671997
Validation loss: 1.7060025507403958

Epoch: 5| Step: 9
Training loss: 0.755853533744812
Validation loss: 1.7205691196585213

Epoch: 5| Step: 10
Training loss: 0.30881476402282715
Validation loss: 1.743674091113511

Epoch: 329| Step: 0
Training loss: 0.3584301173686981
Validation loss: 1.7140343894240677

Epoch: 5| Step: 1
Training loss: 0.6141043901443481
Validation loss: 1.7059564577635897

Epoch: 5| Step: 2
Training loss: 0.5865004062652588
Validation loss: 1.7239697774251301

Epoch: 5| Step: 3
Training loss: 0.774151623249054
Validation loss: 1.7087061059090398

Epoch: 5| Step: 4
Training loss: 0.5233148336410522
Validation loss: 1.6825032721283615

Epoch: 5| Step: 5
Training loss: 0.32414865493774414
Validation loss: 1.6654586163900231

Epoch: 5| Step: 6
Training loss: 0.3330724835395813
Validation loss: 1.6576348350894066

Epoch: 5| Step: 7
Training loss: 0.3853285014629364
Validation loss: 1.6760704555819113

Epoch: 5| Step: 8
Training loss: 0.5587613582611084
Validation loss: 1.6630148400542557

Epoch: 5| Step: 9
Training loss: 0.6396197080612183
Validation loss: 1.6636373548097507

Epoch: 5| Step: 10
Training loss: 0.49547722935676575
Validation loss: 1.6766575010873939

Epoch: 330| Step: 0
Training loss: 0.7622373104095459
Validation loss: 1.6511085110325967

Epoch: 5| Step: 1
Training loss: 0.3728610575199127
Validation loss: 1.6725467610102829

Epoch: 5| Step: 2
Training loss: 0.5394836664199829
Validation loss: 1.6727326236745363

Epoch: 5| Step: 3
Training loss: 0.7179806232452393
Validation loss: 1.6897064139766078

Epoch: 5| Step: 4
Training loss: 0.4900273382663727
Validation loss: 1.6977616420356176

Epoch: 5| Step: 5
Training loss: 0.44744807481765747
Validation loss: 1.7186396826979935

Epoch: 5| Step: 6
Training loss: 0.35176077485084534
Validation loss: 1.688119076913403

Epoch: 5| Step: 7
Training loss: 0.2998336851596832
Validation loss: 1.7055737087803502

Epoch: 5| Step: 8
Training loss: 0.4713619351387024
Validation loss: 1.706237357149842

Epoch: 5| Step: 9
Training loss: 0.7161608934402466
Validation loss: 1.7185942165313228

Epoch: 5| Step: 10
Training loss: 0.3905579149723053
Validation loss: 1.710357226351256

Epoch: 331| Step: 0
Training loss: 0.6573918461799622
Validation loss: 1.722367271300285

Epoch: 5| Step: 1
Training loss: 0.3805401623249054
Validation loss: 1.712163148387786

Epoch: 5| Step: 2
Training loss: 0.6253741383552551
Validation loss: 1.7079871469928372

Epoch: 5| Step: 3
Training loss: 0.48812031745910645
Validation loss: 1.707553607161327

Epoch: 5| Step: 4
Training loss: 0.49059444665908813
Validation loss: 1.707619486316558

Epoch: 5| Step: 5
Training loss: 0.3941437900066376
Validation loss: 1.6959386397433538

Epoch: 5| Step: 6
Training loss: 0.5971841812133789
Validation loss: 1.6712463440433625

Epoch: 5| Step: 7
Training loss: 0.4099787771701813
Validation loss: 1.6795706287507088

Epoch: 5| Step: 8
Training loss: 0.5160772800445557
Validation loss: 1.6841558858912478

Epoch: 5| Step: 9
Training loss: 0.4760509431362152
Validation loss: 1.6732065241823915

Epoch: 5| Step: 10
Training loss: 0.5050528049468994
Validation loss: 1.6650238588292112

Epoch: 332| Step: 0
Training loss: 0.3391161859035492
Validation loss: 1.6854977274453768

Epoch: 5| Step: 1
Training loss: 0.32021716237068176
Validation loss: 1.6780678033828735

Epoch: 5| Step: 2
Training loss: 0.5194119215011597
Validation loss: 1.6734320489309167

Epoch: 5| Step: 3
Training loss: 0.7690386772155762
Validation loss: 1.7116090674554147

Epoch: 5| Step: 4
Training loss: 0.2859686017036438
Validation loss: 1.684978054415795

Epoch: 5| Step: 5
Training loss: 0.4368247091770172
Validation loss: 1.692506408178678

Epoch: 5| Step: 6
Training loss: 0.48529109358787537
Validation loss: 1.705811196757901

Epoch: 5| Step: 7
Training loss: 0.5999454855918884
Validation loss: 1.7298392147146247

Epoch: 5| Step: 8
Training loss: 0.6424235105514526
Validation loss: 1.7233739899050804

Epoch: 5| Step: 9
Training loss: 0.4672578275203705
Validation loss: 1.751927503975489

Epoch: 5| Step: 10
Training loss: 0.6772457361221313
Validation loss: 1.7341477486395067

Epoch: 333| Step: 0
Training loss: 0.5692128539085388
Validation loss: 1.7352003198797985

Epoch: 5| Step: 1
Training loss: 0.38810399174690247
Validation loss: 1.7358277023479503

Epoch: 5| Step: 2
Training loss: 0.8508995175361633
Validation loss: 1.723717293431682

Epoch: 5| Step: 3
Training loss: 0.33909159898757935
Validation loss: 1.7036605855470062

Epoch: 5| Step: 4
Training loss: 0.6382305026054382
Validation loss: 1.7295575987908147

Epoch: 5| Step: 5
Training loss: 0.38617590069770813
Validation loss: 1.7188559193764963

Epoch: 5| Step: 6
Training loss: 0.333364874124527
Validation loss: 1.6927994194851126

Epoch: 5| Step: 7
Training loss: 0.2844310402870178
Validation loss: 1.718232059991488

Epoch: 5| Step: 8
Training loss: 0.4391052722930908
Validation loss: 1.707788566107391

Epoch: 5| Step: 9
Training loss: 0.7528849840164185
Validation loss: 1.7258328032749954

Epoch: 5| Step: 10
Training loss: 0.5078549385070801
Validation loss: 1.720849774217093

Epoch: 334| Step: 0
Training loss: 0.2878497540950775
Validation loss: 1.7315893288581603

Epoch: 5| Step: 1
Training loss: 0.663333535194397
Validation loss: 1.7615814939621957

Epoch: 5| Step: 2
Training loss: 0.3933355212211609
Validation loss: 1.7168239983179236

Epoch: 5| Step: 3
Training loss: 0.5133077502250671
Validation loss: 1.7156760436232372

Epoch: 5| Step: 4
Training loss: 0.4856894016265869
Validation loss: 1.6777764558792114

Epoch: 5| Step: 5
Training loss: 0.3452092707157135
Validation loss: 1.6789337037712015

Epoch: 5| Step: 6
Training loss: 0.4296689033508301
Validation loss: 1.7365885883249261

Epoch: 5| Step: 7
Training loss: 0.5817630290985107
Validation loss: 1.7570481620809084

Epoch: 5| Step: 8
Training loss: 1.0129667520523071
Validation loss: 1.7714130980994112

Epoch: 5| Step: 9
Training loss: 0.4807482361793518
Validation loss: 1.7576327798187092

Epoch: 5| Step: 10
Training loss: 0.7221122980117798
Validation loss: 1.7134877225404144

Epoch: 335| Step: 0
Training loss: 0.47462034225463867
Validation loss: 1.6879227110134658

Epoch: 5| Step: 1
Training loss: 0.5079244375228882
Validation loss: 1.6711265476801063

Epoch: 5| Step: 2
Training loss: 0.228830486536026
Validation loss: 1.6683935170532556

Epoch: 5| Step: 3
Training loss: 0.631777286529541
Validation loss: 1.6985310431449645

Epoch: 5| Step: 4
Training loss: 0.5666132569313049
Validation loss: 1.7170240507330945

Epoch: 5| Step: 5
Training loss: 0.21478000283241272
Validation loss: 1.7183681905910533

Epoch: 5| Step: 6
Training loss: 0.4263053834438324
Validation loss: 1.7064206882189679

Epoch: 5| Step: 7
Training loss: 0.8523271679878235
Validation loss: 1.761613791988742

Epoch: 5| Step: 8
Training loss: 0.29199180006980896
Validation loss: 1.7354653701987317

Epoch: 5| Step: 9
Training loss: 0.33837181329727173
Validation loss: 1.7543268716463478

Epoch: 5| Step: 10
Training loss: 0.7378453612327576
Validation loss: 1.7627075256839875

Epoch: 336| Step: 0
Training loss: 0.5056063532829285
Validation loss: 1.7650882992693173

Epoch: 5| Step: 1
Training loss: 0.37375712394714355
Validation loss: 1.7226692809853503

Epoch: 5| Step: 2
Training loss: 0.5214619040489197
Validation loss: 1.7070383999937324

Epoch: 5| Step: 3
Training loss: 0.4339281916618347
Validation loss: 1.7088483725824664

Epoch: 5| Step: 4
Training loss: 0.6094831228256226
Validation loss: 1.7295412158453336

Epoch: 5| Step: 5
Training loss: 0.4480009078979492
Validation loss: 1.7254481687340686

Epoch: 5| Step: 6
Training loss: 0.4697794020175934
Validation loss: 1.7117586622955978

Epoch: 5| Step: 7
Training loss: 0.5446170568466187
Validation loss: 1.6668535535053541

Epoch: 5| Step: 8
Training loss: 0.6835806965827942
Validation loss: 1.6883276329245618

Epoch: 5| Step: 9
Training loss: 0.4495882987976074
Validation loss: 1.6911672994654665

Epoch: 5| Step: 10
Training loss: 0.3135787546634674
Validation loss: 1.7020401262467908

Epoch: 337| Step: 0
Training loss: 0.492983341217041
Validation loss: 1.715973800228488

Epoch: 5| Step: 1
Training loss: 0.5517894625663757
Validation loss: 1.7147122506172425

Epoch: 5| Step: 2
Training loss: 0.6320292949676514
Validation loss: 1.6783113389886835

Epoch: 5| Step: 3
Training loss: 0.5314253568649292
Validation loss: 1.6977589950766614

Epoch: 5| Step: 4
Training loss: 0.4219995439052582
Validation loss: 1.688074234352317

Epoch: 5| Step: 5
Training loss: 0.40050897002220154
Validation loss: 1.6763273580099947

Epoch: 5| Step: 6
Training loss: 0.40701383352279663
Validation loss: 1.7122765394949144

Epoch: 5| Step: 7
Training loss: 0.3820912837982178
Validation loss: 1.7675435363605458

Epoch: 5| Step: 8
Training loss: 0.9326657056808472
Validation loss: 1.7649643087899813

Epoch: 5| Step: 9
Training loss: 0.5917662382125854
Validation loss: 1.7491374733627483

Epoch: 5| Step: 10
Training loss: 0.4336967468261719
Validation loss: 1.7388398237125848

Epoch: 338| Step: 0
Training loss: 0.3750533163547516
Validation loss: 1.7179460397330664

Epoch: 5| Step: 1
Training loss: 0.2886675000190735
Validation loss: 1.717989255023259

Epoch: 5| Step: 2
Training loss: 0.3576210141181946
Validation loss: 1.723613603140718

Epoch: 5| Step: 3
Training loss: 0.9344421625137329
Validation loss: 1.7024395337668798

Epoch: 5| Step: 4
Training loss: 0.6712627410888672
Validation loss: 1.67659148862285

Epoch: 5| Step: 5
Training loss: 0.40556859970092773
Validation loss: 1.670990679853706

Epoch: 5| Step: 6
Training loss: 0.5269325375556946
Validation loss: 1.6726558234101983

Epoch: 5| Step: 7
Training loss: 0.399752676486969
Validation loss: 1.6636184812873922

Epoch: 5| Step: 8
Training loss: 0.3992598354816437
Validation loss: 1.6700717146678636

Epoch: 5| Step: 9
Training loss: 0.3290860056877136
Validation loss: 1.660836345405989

Epoch: 5| Step: 10
Training loss: 0.5632866024971008
Validation loss: 1.691193196081346

Epoch: 339| Step: 0
Training loss: 0.6404439210891724
Validation loss: 1.6828120434156029

Epoch: 5| Step: 1
Training loss: 0.40763044357299805
Validation loss: 1.7018888945220618

Epoch: 5| Step: 2
Training loss: 0.44988179206848145
Validation loss: 1.7163323125531595

Epoch: 5| Step: 3
Training loss: 0.6737078428268433
Validation loss: 1.7031996775698919

Epoch: 5| Step: 4
Training loss: 0.548649787902832
Validation loss: 1.7106286043761878

Epoch: 5| Step: 5
Training loss: 0.3428274393081665
Validation loss: 1.697514671151356

Epoch: 5| Step: 6
Training loss: 0.6115075945854187
Validation loss: 1.7035454024550736

Epoch: 5| Step: 7
Training loss: 0.2979852557182312
Validation loss: 1.6896900464129705

Epoch: 5| Step: 8
Training loss: 0.4754815995693207
Validation loss: 1.680356228223411

Epoch: 5| Step: 9
Training loss: 0.5161540508270264
Validation loss: 1.713409996801807

Epoch: 5| Step: 10
Training loss: 0.15262971818447113
Validation loss: 1.6891843106157036

Epoch: 340| Step: 0
Training loss: 0.5950083136558533
Validation loss: 1.6873690248817526

Epoch: 5| Step: 1
Training loss: 0.4150177836418152
Validation loss: 1.676082008628435

Epoch: 5| Step: 2
Training loss: 0.3988943099975586
Validation loss: 1.6620019507664505

Epoch: 5| Step: 3
Training loss: 0.4765884280204773
Validation loss: 1.7182880024756155

Epoch: 5| Step: 4
Training loss: 0.4430376887321472
Validation loss: 1.7247754271312425

Epoch: 5| Step: 5
Training loss: 0.42509526014328003
Validation loss: 1.7475346442191833

Epoch: 5| Step: 6
Training loss: 0.6279476284980774
Validation loss: 1.7034911981192968

Epoch: 5| Step: 7
Training loss: 0.23720812797546387
Validation loss: 1.6832148567322762

Epoch: 5| Step: 8
Training loss: 0.6262955665588379
Validation loss: 1.6596953048500964

Epoch: 5| Step: 9
Training loss: 0.544309139251709
Validation loss: 1.6496246860873314

Epoch: 5| Step: 10
Training loss: 0.25149810314178467
Validation loss: 1.6424314937283915

Epoch: 341| Step: 0
Training loss: 0.355840265750885
Validation loss: 1.661433986438218

Epoch: 5| Step: 1
Training loss: 0.6412448883056641
Validation loss: 1.6606027528803835

Epoch: 5| Step: 2
Training loss: 0.6191157698631287
Validation loss: 1.6810589836489769

Epoch: 5| Step: 3
Training loss: 0.5068074464797974
Validation loss: 1.6635301574583976

Epoch: 5| Step: 4
Training loss: 0.4192163050174713
Validation loss: 1.7020837581285866

Epoch: 5| Step: 5
Training loss: 0.30471882224082947
Validation loss: 1.6751412332698863

Epoch: 5| Step: 6
Training loss: 0.4095497131347656
Validation loss: 1.6965630810747865

Epoch: 5| Step: 7
Training loss: 0.5484069585800171
Validation loss: 1.684962776399428

Epoch: 5| Step: 8
Training loss: 0.4174751341342926
Validation loss: 1.6944317471596502

Epoch: 5| Step: 9
Training loss: 0.4095737934112549
Validation loss: 1.6617728202573714

Epoch: 5| Step: 10
Training loss: 0.5203297734260559
Validation loss: 1.647277242393904

Epoch: 342| Step: 0
Training loss: 0.4821193814277649
Validation loss: 1.6277006492819837

Epoch: 5| Step: 1
Training loss: 0.4987552762031555
Validation loss: 1.6504727845550866

Epoch: 5| Step: 2
Training loss: 0.4691963195800781
Validation loss: 1.6077267585262176

Epoch: 5| Step: 3
Training loss: 0.8813939094543457
Validation loss: 1.6182512775544198

Epoch: 5| Step: 4
Training loss: 0.3660338819026947
Validation loss: 1.6571756229605725

Epoch: 5| Step: 5
Training loss: 0.3282468914985657
Validation loss: 1.683212241818828

Epoch: 5| Step: 6
Training loss: 0.34254422783851624
Validation loss: 1.6227043418474094

Epoch: 5| Step: 7
Training loss: 0.456143856048584
Validation loss: 1.6595100254140875

Epoch: 5| Step: 8
Training loss: 0.3334867060184479
Validation loss: 1.6419513763919953

Epoch: 5| Step: 9
Training loss: 0.28348153829574585
Validation loss: 1.6486337236178819

Epoch: 5| Step: 10
Training loss: 0.5110793113708496
Validation loss: 1.6619713921700754

Epoch: 343| Step: 0
Training loss: 0.47843170166015625
Validation loss: 1.6674519713206957

Epoch: 5| Step: 1
Training loss: 0.2052544802427292
Validation loss: 1.6570575262910576

Epoch: 5| Step: 2
Training loss: 0.3430270552635193
Validation loss: 1.7046316298105384

Epoch: 5| Step: 3
Training loss: 0.5900415778160095
Validation loss: 1.6943163705128494

Epoch: 5| Step: 4
Training loss: 0.5462544560432434
Validation loss: 1.7031252435458604

Epoch: 5| Step: 5
Training loss: 0.48988431692123413
Validation loss: 1.6801891813996017

Epoch: 5| Step: 6
Training loss: 0.5388062596321106
Validation loss: 1.6752616705433014

Epoch: 5| Step: 7
Training loss: 0.5832775831222534
Validation loss: 1.6921843585147653

Epoch: 5| Step: 8
Training loss: 0.40442824363708496
Validation loss: 1.6728260299210906

Epoch: 5| Step: 9
Training loss: 0.1984340101480484
Validation loss: 1.6728683056369904

Epoch: 5| Step: 10
Training loss: 0.34603795409202576
Validation loss: 1.682372731547202

Epoch: 344| Step: 0
Training loss: 0.36590224504470825
Validation loss: 1.6667721950879661

Epoch: 5| Step: 1
Training loss: 0.20519161224365234
Validation loss: 1.676743536226211

Epoch: 5| Step: 2
Training loss: 0.3890630006790161
Validation loss: 1.6777490864517868

Epoch: 5| Step: 3
Training loss: 0.5407674312591553
Validation loss: 1.6562906695950417

Epoch: 5| Step: 4
Training loss: 0.4447564482688904
Validation loss: 1.680281517326191

Epoch: 5| Step: 5
Training loss: 0.2697780430316925
Validation loss: 1.6304425872782224

Epoch: 5| Step: 6
Training loss: 0.5598288774490356
Validation loss: 1.6383846395759172

Epoch: 5| Step: 7
Training loss: 0.5293213129043579
Validation loss: 1.6565932701992732

Epoch: 5| Step: 8
Training loss: 0.4406600594520569
Validation loss: 1.6631261981943601

Epoch: 5| Step: 9
Training loss: 0.298237144947052
Validation loss: 1.6597619287429317

Epoch: 5| Step: 10
Training loss: 0.6138197183609009
Validation loss: 1.687538880173878

Epoch: 345| Step: 0
Training loss: 0.5250642895698547
Validation loss: 1.6775446399565666

Epoch: 5| Step: 1
Training loss: 0.2913751006126404
Validation loss: 1.6603896822980655

Epoch: 5| Step: 2
Training loss: 0.3458399176597595
Validation loss: 1.6756757843878962

Epoch: 5| Step: 3
Training loss: 0.24284319579601288
Validation loss: 1.6720474945601596

Epoch: 5| Step: 4
Training loss: 0.42253249883651733
Validation loss: 1.6700565648335282

Epoch: 5| Step: 5
Training loss: 0.3365212678909302
Validation loss: 1.6585250452000608

Epoch: 5| Step: 6
Training loss: 0.49428653717041016
Validation loss: 1.6139725953020074

Epoch: 5| Step: 7
Training loss: 0.32547494769096375
Validation loss: 1.6376123300162695

Epoch: 5| Step: 8
Training loss: 0.40059155225753784
Validation loss: 1.5925458310752787

Epoch: 5| Step: 9
Training loss: 0.698066771030426
Validation loss: 1.612032578837487

Epoch: 5| Step: 10
Training loss: 0.708285391330719
Validation loss: 1.5938208122407236

Epoch: 346| Step: 0
Training loss: 0.30877143144607544
Validation loss: 1.637846621133948

Epoch: 5| Step: 1
Training loss: 0.5018329620361328
Validation loss: 1.6299285196488904

Epoch: 5| Step: 2
Training loss: 0.492840439081192
Validation loss: 1.6767919178931945

Epoch: 5| Step: 3
Training loss: 0.4123682975769043
Validation loss: 1.6815745420353387

Epoch: 5| Step: 4
Training loss: 0.48367446660995483
Validation loss: 1.6851722219938874

Epoch: 5| Step: 5
Training loss: 0.522901713848114
Validation loss: 1.7461958931338402

Epoch: 5| Step: 6
Training loss: 0.7120785713195801
Validation loss: 1.7284302916578067

Epoch: 5| Step: 7
Training loss: 0.35129719972610474
Validation loss: 1.6946830364965624

Epoch: 5| Step: 8
Training loss: 0.587191104888916
Validation loss: 1.6459048127615323

Epoch: 5| Step: 9
Training loss: 0.2540186643600464
Validation loss: 1.6405372222264607

Epoch: 5| Step: 10
Training loss: 0.35356375575065613
Validation loss: 1.619151097471996

Epoch: 347| Step: 0
Training loss: 0.37996718287467957
Validation loss: 1.6312623895624632

Epoch: 5| Step: 1
Training loss: 0.6479361057281494
Validation loss: 1.6226541470455866

Epoch: 5| Step: 2
Training loss: 0.4570222496986389
Validation loss: 1.6087118079585414

Epoch: 5| Step: 3
Training loss: 0.4232034683227539
Validation loss: 1.6014036491353025

Epoch: 5| Step: 4
Training loss: 0.5433283448219299
Validation loss: 1.6166474229546004

Epoch: 5| Step: 5
Training loss: 0.46686887741088867
Validation loss: 1.6371678806120349

Epoch: 5| Step: 6
Training loss: 0.32603392004966736
Validation loss: 1.659106336614137

Epoch: 5| Step: 7
Training loss: 0.40885740518569946
Validation loss: 1.6853625812838156

Epoch: 5| Step: 8
Training loss: 0.4482855796813965
Validation loss: 1.70602273812858

Epoch: 5| Step: 9
Training loss: 0.4802369177341461
Validation loss: 1.7124806962987429

Epoch: 5| Step: 10
Training loss: 0.39457201957702637
Validation loss: 1.7166261608882616

Epoch: 348| Step: 0
Training loss: 0.2664523422718048
Validation loss: 1.725912699135401

Epoch: 5| Step: 1
Training loss: 0.7880095839500427
Validation loss: 1.7223342990362516

Epoch: 5| Step: 2
Training loss: 0.3272659182548523
Validation loss: 1.6969242813766643

Epoch: 5| Step: 3
Training loss: 0.5744098424911499
Validation loss: 1.6721564486462583

Epoch: 5| Step: 4
Training loss: 0.617893397808075
Validation loss: 1.672412573650319

Epoch: 5| Step: 5
Training loss: 0.48553451895713806
Validation loss: 1.675785961971488

Epoch: 5| Step: 6
Training loss: 0.47995883226394653
Validation loss: 1.671225409353933

Epoch: 5| Step: 7
Training loss: 0.4064493179321289
Validation loss: 1.6839190734330045

Epoch: 5| Step: 8
Training loss: 0.4035870432853699
Validation loss: 1.6450746264508975

Epoch: 5| Step: 9
Training loss: 0.47688454389572144
Validation loss: 1.6505664433202436

Epoch: 5| Step: 10
Training loss: 0.39681529998779297
Validation loss: 1.6590556790751796

Epoch: 349| Step: 0
Training loss: 0.5748786926269531
Validation loss: 1.6427835815696306

Epoch: 5| Step: 1
Training loss: 0.3398488759994507
Validation loss: 1.6286333248179445

Epoch: 5| Step: 2
Training loss: 0.44706064462661743
Validation loss: 1.6621528146087483

Epoch: 5| Step: 3
Training loss: 0.3115857243537903
Validation loss: 1.6464616483257664

Epoch: 5| Step: 4
Training loss: 0.3788803815841675
Validation loss: 1.6797532291822537

Epoch: 5| Step: 5
Training loss: 0.3700585663318634
Validation loss: 1.6802074229845436

Epoch: 5| Step: 6
Training loss: 0.7618826031684875
Validation loss: 1.705974809585079

Epoch: 5| Step: 7
Training loss: 0.5285507440567017
Validation loss: 1.7264813274465582

Epoch: 5| Step: 8
Training loss: 0.43419885635375977
Validation loss: 1.74669607352185

Epoch: 5| Step: 9
Training loss: 0.2804235517978668
Validation loss: 1.7480833889335714

Epoch: 5| Step: 10
Training loss: 0.5785689949989319
Validation loss: 1.7269810476610739

Epoch: 350| Step: 0
Training loss: 0.41417980194091797
Validation loss: 1.7227881300833918

Epoch: 5| Step: 1
Training loss: 0.40499621629714966
Validation loss: 1.7006127385682956

Epoch: 5| Step: 2
Training loss: 0.5129287838935852
Validation loss: 1.658253679993332

Epoch: 5| Step: 3
Training loss: 0.30612918734550476
Validation loss: 1.6671114724169496

Epoch: 5| Step: 4
Training loss: 0.3956305980682373
Validation loss: 1.6626267715166974

Epoch: 5| Step: 5
Training loss: 0.6054648756980896
Validation loss: 1.6793985546276133

Epoch: 5| Step: 6
Training loss: 0.3725803792476654
Validation loss: 1.668429607986122

Epoch: 5| Step: 7
Training loss: 0.3522984981536865
Validation loss: 1.6337658718068113

Epoch: 5| Step: 8
Training loss: 0.5296449661254883
Validation loss: 1.629685433962012

Epoch: 5| Step: 9
Training loss: 0.47825708985328674
Validation loss: 1.6669118058296941

Epoch: 5| Step: 10
Training loss: 0.48448821902275085
Validation loss: 1.6656652688980103

Epoch: 351| Step: 0
Training loss: 0.5560175180435181
Validation loss: 1.6738466062853414

Epoch: 5| Step: 1
Training loss: 0.40598949790000916
Validation loss: 1.6683528269490888

Epoch: 5| Step: 2
Training loss: 0.3611624240875244
Validation loss: 1.6714792046495663

Epoch: 5| Step: 3
Training loss: 0.3194524049758911
Validation loss: 1.6605914408160793

Epoch: 5| Step: 4
Training loss: 0.2816133201122284
Validation loss: 1.6660150327990133

Epoch: 5| Step: 5
Training loss: 0.5064553022384644
Validation loss: 1.697579611373204

Epoch: 5| Step: 6
Training loss: 0.8032638430595398
Validation loss: 1.7009645662000101

Epoch: 5| Step: 7
Training loss: 0.5008090734481812
Validation loss: 1.7085891103231778

Epoch: 5| Step: 8
Training loss: 0.2663640081882477
Validation loss: 1.710961828949631

Epoch: 5| Step: 9
Training loss: 0.47138580679893494
Validation loss: 1.7644505859703146

Epoch: 5| Step: 10
Training loss: 0.5003608465194702
Validation loss: 1.7491306181876891

Epoch: 352| Step: 0
Training loss: 0.6469084024429321
Validation loss: 1.7610004178939327

Epoch: 5| Step: 1
Training loss: 0.4861696660518646
Validation loss: 1.7918187123472973

Epoch: 5| Step: 2
Training loss: 0.34101128578186035
Validation loss: 1.7117292983557588

Epoch: 5| Step: 3
Training loss: 0.2484864443540573
Validation loss: 1.6793245038678568

Epoch: 5| Step: 4
Training loss: 0.4459155201911926
Validation loss: 1.6713514520275978

Epoch: 5| Step: 5
Training loss: 0.36210834980010986
Validation loss: 1.7246969162776906

Epoch: 5| Step: 6
Training loss: 0.7000256776809692
Validation loss: 1.6976971651918145

Epoch: 5| Step: 7
Training loss: 0.5608311295509338
Validation loss: 1.705958003638893

Epoch: 5| Step: 8
Training loss: 0.4181467890739441
Validation loss: 1.6322051709698093

Epoch: 5| Step: 9
Training loss: 0.502586305141449
Validation loss: 1.612881023396728

Epoch: 5| Step: 10
Training loss: 0.47868677973747253
Validation loss: 1.643003971345963

Epoch: 353| Step: 0
Training loss: 0.49428755044937134
Validation loss: 1.6937981190220002

Epoch: 5| Step: 1
Training loss: 0.4421200156211853
Validation loss: 1.7283082931272444

Epoch: 5| Step: 2
Training loss: 0.43705207109451294
Validation loss: 1.687649852486067

Epoch: 5| Step: 3
Training loss: 0.3928103744983673
Validation loss: 1.6957604090372722

Epoch: 5| Step: 4
Training loss: 0.2212727814912796
Validation loss: 1.7076215551745506

Epoch: 5| Step: 5
Training loss: 0.49584221839904785
Validation loss: 1.6649360458056133

Epoch: 5| Step: 6
Training loss: 0.5122774839401245
Validation loss: 1.6669552121111142

Epoch: 5| Step: 7
Training loss: 0.29990774393081665
Validation loss: 1.6736731824054514

Epoch: 5| Step: 8
Training loss: 0.6628269553184509
Validation loss: 1.649193621450855

Epoch: 5| Step: 9
Training loss: 0.3139769434928894
Validation loss: 1.645631451760569

Epoch: 5| Step: 10
Training loss: 0.4468861222267151
Validation loss: 1.6656814877704909

Epoch: 354| Step: 0
Training loss: 0.2242274284362793
Validation loss: 1.6535741090774536

Epoch: 5| Step: 1
Training loss: 0.5513200759887695
Validation loss: 1.658483092502881

Epoch: 5| Step: 2
Training loss: 0.642910361289978
Validation loss: 1.6860360663424256

Epoch: 5| Step: 3
Training loss: 0.22785785794258118
Validation loss: 1.700316370174449

Epoch: 5| Step: 4
Training loss: 0.3583448827266693
Validation loss: 1.6953229634992537

Epoch: 5| Step: 5
Training loss: 0.32879847288131714
Validation loss: 1.6507199131032473

Epoch: 5| Step: 6
Training loss: 0.4159345030784607
Validation loss: 1.6425934440346175

Epoch: 5| Step: 7
Training loss: 0.371564120054245
Validation loss: 1.6488949098894674

Epoch: 5| Step: 8
Training loss: 0.3328839838504791
Validation loss: 1.6149339650266914

Epoch: 5| Step: 9
Training loss: 0.5122801661491394
Validation loss: 1.61114106639739

Epoch: 5| Step: 10
Training loss: 0.5061252117156982
Validation loss: 1.5835432339740056

Epoch: 355| Step: 0
Training loss: 0.36374765634536743
Validation loss: 1.5953961764612505

Epoch: 5| Step: 1
Training loss: 0.4951722025871277
Validation loss: 1.6027110686866186

Epoch: 5| Step: 2
Training loss: 0.6502590179443359
Validation loss: 1.5945967730655466

Epoch: 5| Step: 3
Training loss: 0.2659655213356018
Validation loss: 1.5924301134642733

Epoch: 5| Step: 4
Training loss: 0.39290887117385864
Validation loss: 1.6229768453105804

Epoch: 5| Step: 5
Training loss: 0.32113081216812134
Validation loss: 1.669041011923103

Epoch: 5| Step: 6
Training loss: 0.6190485954284668
Validation loss: 1.736929638411409

Epoch: 5| Step: 7
Training loss: 0.37548190355300903
Validation loss: 1.7310786324162637

Epoch: 5| Step: 8
Training loss: 0.427692711353302
Validation loss: 1.7262124553803475

Epoch: 5| Step: 9
Training loss: 0.41583746671676636
Validation loss: 1.6845521939698087

Epoch: 5| Step: 10
Training loss: 0.31862354278564453
Validation loss: 1.6707325366235548

Epoch: 356| Step: 0
Training loss: 0.31258493661880493
Validation loss: 1.674459962434666

Epoch: 5| Step: 1
Training loss: 0.609305202960968
Validation loss: 1.6954692307338919

Epoch: 5| Step: 2
Training loss: 0.6784799695014954
Validation loss: 1.7069144812963342

Epoch: 5| Step: 3
Training loss: 0.42556706070899963
Validation loss: 1.7082532567362632

Epoch: 5| Step: 4
Training loss: 0.4995760917663574
Validation loss: 1.7112957905697566

Epoch: 5| Step: 5
Training loss: 0.30836284160614014
Validation loss: 1.666091811272406

Epoch: 5| Step: 6
Training loss: 0.2766224145889282
Validation loss: 1.675553588457005

Epoch: 5| Step: 7
Training loss: 0.48410850763320923
Validation loss: 1.6562866728792909

Epoch: 5| Step: 8
Training loss: 0.31720441579818726
Validation loss: 1.6715872762023762

Epoch: 5| Step: 9
Training loss: 0.382183700799942
Validation loss: 1.7288256960530435

Epoch: 5| Step: 10
Training loss: 0.4320490062236786
Validation loss: 1.744406182278869

Epoch: 357| Step: 0
Training loss: 0.5349330902099609
Validation loss: 1.7263629712084287

Epoch: 5| Step: 1
Training loss: 0.28603893518447876
Validation loss: 1.677978338733796

Epoch: 5| Step: 2
Training loss: 0.37733936309814453
Validation loss: 1.6189056711812173

Epoch: 5| Step: 3
Training loss: 0.40915927290916443
Validation loss: 1.6009067476436656

Epoch: 5| Step: 4
Training loss: 0.3485429883003235
Validation loss: 1.6211384522017611

Epoch: 5| Step: 5
Training loss: 0.3312702476978302
Validation loss: 1.6647580541590208

Epoch: 5| Step: 6
Training loss: 0.3544553816318512
Validation loss: 1.6763127952493646

Epoch: 5| Step: 7
Training loss: 0.5865598917007446
Validation loss: 1.6386705931796823

Epoch: 5| Step: 8
Training loss: 0.2480514943599701
Validation loss: 1.658186399808494

Epoch: 5| Step: 9
Training loss: 0.5118920207023621
Validation loss: 1.6489268169608167

Epoch: 5| Step: 10
Training loss: 0.70107501745224
Validation loss: 1.6535261971976167

Epoch: 358| Step: 0
Training loss: 0.4314543306827545
Validation loss: 1.6737527783199022

Epoch: 5| Step: 1
Training loss: 0.2583628296852112
Validation loss: 1.680427429496601

Epoch: 5| Step: 2
Training loss: 0.3410831093788147
Validation loss: 1.679038445154826

Epoch: 5| Step: 3
Training loss: 0.5191742777824402
Validation loss: 1.708017228752054

Epoch: 5| Step: 4
Training loss: 0.40252694487571716
Validation loss: 1.7507040859550558

Epoch: 5| Step: 5
Training loss: 0.5096688270568848
Validation loss: 1.7137181271788895

Epoch: 5| Step: 6
Training loss: 0.41379809379577637
Validation loss: 1.697379332716747

Epoch: 5| Step: 7
Training loss: 0.5191311240196228
Validation loss: 1.639881346815376

Epoch: 5| Step: 8
Training loss: 0.37254247069358826
Validation loss: 1.6363093417177919

Epoch: 5| Step: 9
Training loss: 0.4878387451171875
Validation loss: 1.6123532377263552

Epoch: 5| Step: 10
Training loss: 0.5358504056930542
Validation loss: 1.6052225546170307

Epoch: 359| Step: 0
Training loss: 0.6272876262664795
Validation loss: 1.6049661085169802

Epoch: 5| Step: 1
Training loss: 0.40496498346328735
Validation loss: 1.6025988324995963

Epoch: 5| Step: 2
Training loss: 0.4709917902946472
Validation loss: 1.600608237328068

Epoch: 5| Step: 3
Training loss: 0.582037091255188
Validation loss: 1.6042177984791417

Epoch: 5| Step: 4
Training loss: 0.3397201895713806
Validation loss: 1.625452878654644

Epoch: 5| Step: 5
Training loss: 0.2734887897968292
Validation loss: 1.660551110262512

Epoch: 5| Step: 6
Training loss: 0.49006718397140503
Validation loss: 1.6982093780271468

Epoch: 5| Step: 7
Training loss: 0.25225964188575745
Validation loss: 1.6898572086006083

Epoch: 5| Step: 8
Training loss: 0.34565678238868713
Validation loss: 1.6327482628565964

Epoch: 5| Step: 9
Training loss: 0.3727484345436096
Validation loss: 1.654034553035613

Epoch: 5| Step: 10
Training loss: 0.3854922354221344
Validation loss: 1.62277094651294

Epoch: 360| Step: 0
Training loss: 0.5230404138565063
Validation loss: 1.6591720004235544

Epoch: 5| Step: 1
Training loss: 0.4122788906097412
Validation loss: 1.6488205861019831

Epoch: 5| Step: 2
Training loss: 0.3534577488899231
Validation loss: 1.6439847523166287

Epoch: 5| Step: 3
Training loss: 0.5513900518417358
Validation loss: 1.6705589948161956

Epoch: 5| Step: 4
Training loss: 0.25350308418273926
Validation loss: 1.6551083095612065

Epoch: 5| Step: 5
Training loss: 0.33063143491744995
Validation loss: 1.657070921313378

Epoch: 5| Step: 6
Training loss: 0.4844978451728821
Validation loss: 1.6350813604170276

Epoch: 5| Step: 7
Training loss: 0.34385424852371216
Validation loss: 1.634595787653359

Epoch: 5| Step: 8
Training loss: 0.1608801931142807
Validation loss: 1.618106633104304

Epoch: 5| Step: 9
Training loss: 0.4658445417881012
Validation loss: 1.6276668476802048

Epoch: 5| Step: 10
Training loss: 0.4617995321750641
Validation loss: 1.6425682729290378

Epoch: 361| Step: 0
Training loss: 0.3505358099937439
Validation loss: 1.6243306001027424

Epoch: 5| Step: 1
Training loss: 0.2649920582771301
Validation loss: 1.625703933418438

Epoch: 5| Step: 2
Training loss: 0.25393837690353394
Validation loss: 1.6241240885949904

Epoch: 5| Step: 3
Training loss: 0.37942782044410706
Validation loss: 1.6344606491827196

Epoch: 5| Step: 4
Training loss: 0.4423326849937439
Validation loss: 1.6180741825411398

Epoch: 5| Step: 5
Training loss: 0.3406652808189392
Validation loss: 1.6182254450295561

Epoch: 5| Step: 6
Training loss: 0.4880772531032562
Validation loss: 1.5994579535658642

Epoch: 5| Step: 7
Training loss: 0.2722088694572449
Validation loss: 1.633632311256983

Epoch: 5| Step: 8
Training loss: 0.27202707529067993
Validation loss: 1.6306664764240224

Epoch: 5| Step: 9
Training loss: 0.35313519835472107
Validation loss: 1.624987361251667

Epoch: 5| Step: 10
Training loss: 0.7522894144058228
Validation loss: 1.6428110330335555

Epoch: 362| Step: 0
Training loss: 0.29145291447639465
Validation loss: 1.6457338781766995

Epoch: 5| Step: 1
Training loss: 0.23640239238739014
Validation loss: 1.6374324521710795

Epoch: 5| Step: 2
Training loss: 0.25001320242881775
Validation loss: 1.6413785411465553

Epoch: 5| Step: 3
Training loss: 0.37396296858787537
Validation loss: 1.6148097002378075

Epoch: 5| Step: 4
Training loss: 0.33091115951538086
Validation loss: 1.641219530054318

Epoch: 5| Step: 5
Training loss: 0.648314356803894
Validation loss: 1.653521937708701

Epoch: 5| Step: 6
Training loss: 0.61868816614151
Validation loss: 1.6435449687383508

Epoch: 5| Step: 7
Training loss: 0.23950162529945374
Validation loss: 1.65128311803264

Epoch: 5| Step: 8
Training loss: 0.21323922276496887
Validation loss: 1.6576705107124903

Epoch: 5| Step: 9
Training loss: 0.5003477334976196
Validation loss: 1.6465320382066952

Epoch: 5| Step: 10
Training loss: 0.6015743613243103
Validation loss: 1.6332743917742083

Epoch: 363| Step: 0
Training loss: 0.13933363556861877
Validation loss: 1.5989342684386878

Epoch: 5| Step: 1
Training loss: 0.2633569836616516
Validation loss: 1.619983446213507

Epoch: 5| Step: 2
Training loss: 0.4932498037815094
Validation loss: 1.616222268791609

Epoch: 5| Step: 3
Training loss: 0.4027395248413086
Validation loss: 1.6137414568214006

Epoch: 5| Step: 4
Training loss: 0.7280303835868835
Validation loss: 1.6279752216031473

Epoch: 5| Step: 5
Training loss: 0.3296627104282379
Validation loss: 1.6231463763021654

Epoch: 5| Step: 6
Training loss: 0.4804413914680481
Validation loss: 1.6042906392005183

Epoch: 5| Step: 7
Training loss: 0.2789263129234314
Validation loss: 1.6059309987611667

Epoch: 5| Step: 8
Training loss: 0.5073481798171997
Validation loss: 1.6023840167189156

Epoch: 5| Step: 9
Training loss: 0.2457893341779709
Validation loss: 1.6013030839222733

Epoch: 5| Step: 10
Training loss: 0.26397112011909485
Validation loss: 1.6327022147435013

Epoch: 364| Step: 0
Training loss: 0.24823994934558868
Validation loss: 1.6047326800643757

Epoch: 5| Step: 1
Training loss: 0.4658419191837311
Validation loss: 1.6358764786874094

Epoch: 5| Step: 2
Training loss: 0.2753080129623413
Validation loss: 1.6302117352844567

Epoch: 5| Step: 3
Training loss: 0.29268723726272583
Validation loss: 1.627869576536199

Epoch: 5| Step: 4
Training loss: 0.2672170400619507
Validation loss: 1.629998472429091

Epoch: 5| Step: 5
Training loss: 0.3518480658531189
Validation loss: 1.619100236123608

Epoch: 5| Step: 6
Training loss: 0.4526398777961731
Validation loss: 1.6337572092651038

Epoch: 5| Step: 7
Training loss: 0.36282962560653687
Validation loss: 1.6409453602247341

Epoch: 5| Step: 8
Training loss: 0.6387470960617065
Validation loss: 1.6078573093619397

Epoch: 5| Step: 9
Training loss: 0.3896464705467224
Validation loss: 1.6178947917876705

Epoch: 5| Step: 10
Training loss: 0.2704310417175293
Validation loss: 1.6237550185572716

Epoch: 365| Step: 0
Training loss: 0.1484677791595459
Validation loss: 1.5794134114378242

Epoch: 5| Step: 1
Training loss: 0.272549033164978
Validation loss: 1.5793913058055344

Epoch: 5| Step: 2
Training loss: 0.4011147618293762
Validation loss: 1.5745800925839333

Epoch: 5| Step: 3
Training loss: 0.45290058851242065
Validation loss: 1.5816008916465185

Epoch: 5| Step: 4
Training loss: 0.33409374952316284
Validation loss: 1.5976764309790827

Epoch: 5| Step: 5
Training loss: 0.26748690009117126
Validation loss: 1.5698912964072278

Epoch: 5| Step: 6
Training loss: 0.5205575823783875
Validation loss: 1.569918546625363

Epoch: 5| Step: 7
Training loss: 0.4051401615142822
Validation loss: 1.5745502261705295

Epoch: 5| Step: 8
Training loss: 0.32953912019729614
Validation loss: 1.582862683521804

Epoch: 5| Step: 9
Training loss: 0.3280390202999115
Validation loss: 1.5881043877652896

Epoch: 5| Step: 10
Training loss: 0.3749394714832306
Validation loss: 1.6145334820593558

Epoch: 366| Step: 0
Training loss: 0.42105168104171753
Validation loss: 1.6005558788135488

Epoch: 5| Step: 1
Training loss: 0.364486426115036
Validation loss: 1.612212404128044

Epoch: 5| Step: 2
Training loss: 0.3234482705593109
Validation loss: 1.592434904267711

Epoch: 5| Step: 3
Training loss: 0.22350049018859863
Validation loss: 1.606215003998049

Epoch: 5| Step: 4
Training loss: 0.43253451585769653
Validation loss: 1.6339566092337332

Epoch: 5| Step: 5
Training loss: 0.1879967749118805
Validation loss: 1.6202227889850576

Epoch: 5| Step: 6
Training loss: 0.3398112654685974
Validation loss: 1.6294842702086254

Epoch: 5| Step: 7
Training loss: 0.5605274438858032
Validation loss: 1.661640133909

Epoch: 5| Step: 8
Training loss: 0.2627556025981903
Validation loss: 1.6669865897906724

Epoch: 5| Step: 9
Training loss: 0.3923017084598541
Validation loss: 1.6590597116818993

Epoch: 5| Step: 10
Training loss: 0.289475679397583
Validation loss: 1.699493404357664

Epoch: 367| Step: 0
Training loss: 0.3275911808013916
Validation loss: 1.6845013736396708

Epoch: 5| Step: 1
Training loss: 0.20735213160514832
Validation loss: 1.6880553691617903

Epoch: 5| Step: 2
Training loss: 0.3242207169532776
Validation loss: 1.6505047531538113

Epoch: 5| Step: 3
Training loss: 0.28778180480003357
Validation loss: 1.6545661393032278

Epoch: 5| Step: 4
Training loss: 0.44579005241394043
Validation loss: 1.6315046350161235

Epoch: 5| Step: 5
Training loss: 0.3179512321949005
Validation loss: 1.6418974168838993

Epoch: 5| Step: 6
Training loss: 0.30025535821914673
Validation loss: 1.6461889718168525

Epoch: 5| Step: 7
Training loss: 0.5290150046348572
Validation loss: 1.6000899499462498

Epoch: 5| Step: 8
Training loss: 0.594076931476593
Validation loss: 1.5998369032336819

Epoch: 5| Step: 9
Training loss: 0.2549958825111389
Validation loss: 1.6080092383969216

Epoch: 5| Step: 10
Training loss: 0.3214057683944702
Validation loss: 1.6072071495876517

Epoch: 368| Step: 0
Training loss: 0.3771926164627075
Validation loss: 1.6072971679831063

Epoch: 5| Step: 1
Training loss: 0.33018919825553894
Validation loss: 1.603494704410594

Epoch: 5| Step: 2
Training loss: 0.35199469327926636
Validation loss: 1.6051034799186132

Epoch: 5| Step: 3
Training loss: 0.18649251759052277
Validation loss: 1.6474590224604453

Epoch: 5| Step: 4
Training loss: 0.3196851313114166
Validation loss: 1.62123841111378

Epoch: 5| Step: 5
Training loss: 0.173939511179924
Validation loss: 1.630954114980595

Epoch: 5| Step: 6
Training loss: 0.29216909408569336
Validation loss: 1.602990481161302

Epoch: 5| Step: 7
Training loss: 0.3639734387397766
Validation loss: 1.6264943147218356

Epoch: 5| Step: 8
Training loss: 0.42509907484054565
Validation loss: 1.6277828652371642

Epoch: 5| Step: 9
Training loss: 0.28220778703689575
Validation loss: 1.65053347105621

Epoch: 5| Step: 10
Training loss: 0.5611909627914429
Validation loss: 1.6660215893099386

Epoch: 369| Step: 0
Training loss: 0.19891507923603058
Validation loss: 1.6641572675397318

Epoch: 5| Step: 1
Training loss: 0.34332510828971863
Validation loss: 1.6964183597154514

Epoch: 5| Step: 2
Training loss: 0.2828274369239807
Validation loss: 1.6806665133404475

Epoch: 5| Step: 3
Training loss: 0.2576136589050293
Validation loss: 1.6860720931842763

Epoch: 5| Step: 4
Training loss: 0.6083858609199524
Validation loss: 1.6770244413806545

Epoch: 5| Step: 5
Training loss: 0.3644629120826721
Validation loss: 1.63413820984543

Epoch: 5| Step: 6
Training loss: 0.30301517248153687
Validation loss: 1.6297035781286096

Epoch: 5| Step: 7
Training loss: 0.3136358857154846
Validation loss: 1.6267866908863027

Epoch: 5| Step: 8
Training loss: 0.47552594542503357
Validation loss: 1.6456432624529767

Epoch: 5| Step: 9
Training loss: 0.34528833627700806
Validation loss: 1.643430067646888

Epoch: 5| Step: 10
Training loss: 0.34548115730285645
Validation loss: 1.60773173070723

Epoch: 370| Step: 0
Training loss: 0.37728244066238403
Validation loss: 1.6077516194312804

Epoch: 5| Step: 1
Training loss: 0.36022040247917175
Validation loss: 1.6149867068054855

Epoch: 5| Step: 2
Training loss: 0.366179883480072
Validation loss: 1.6154145502275037

Epoch: 5| Step: 3
Training loss: 0.3433384299278259
Validation loss: 1.6313821359347271

Epoch: 5| Step: 4
Training loss: 0.29169002175331116
Validation loss: 1.6420064139109787

Epoch: 5| Step: 5
Training loss: 0.19644173979759216
Validation loss: 1.6296913790446457

Epoch: 5| Step: 6
Training loss: 0.3165423274040222
Validation loss: 1.6097831905529063

Epoch: 5| Step: 7
Training loss: 0.19244849681854248
Validation loss: 1.6092868748531546

Epoch: 5| Step: 8
Training loss: 0.4880813658237457
Validation loss: 1.6051513687256844

Epoch: 5| Step: 9
Training loss: 0.2915876507759094
Validation loss: 1.5757189540452854

Epoch: 5| Step: 10
Training loss: 0.4526306986808777
Validation loss: 1.577344702136132

Epoch: 371| Step: 0
Training loss: 0.23210649192333221
Validation loss: 1.5780722095120339

Epoch: 5| Step: 1
Training loss: 0.5567871332168579
Validation loss: 1.5581596602675736

Epoch: 5| Step: 2
Training loss: 0.4282549023628235
Validation loss: 1.5982731773007302

Epoch: 5| Step: 3
Training loss: 0.32510384917259216
Validation loss: 1.5827019124902704

Epoch: 5| Step: 4
Training loss: 0.3445093035697937
Validation loss: 1.604325061203331

Epoch: 5| Step: 5
Training loss: 0.32054537534713745
Validation loss: 1.604197452145238

Epoch: 5| Step: 6
Training loss: 0.579571008682251
Validation loss: 1.5990548409441465

Epoch: 5| Step: 7
Training loss: 0.1362755000591278
Validation loss: 1.6097227757976902

Epoch: 5| Step: 8
Training loss: 0.2645435333251953
Validation loss: 1.6230510152796263

Epoch: 5| Step: 9
Training loss: 0.3567003905773163
Validation loss: 1.5975642665739982

Epoch: 5| Step: 10
Training loss: 0.2082275003194809
Validation loss: 1.620063679192656

Epoch: 372| Step: 0
Training loss: 0.45746636390686035
Validation loss: 1.633825470042485

Epoch: 5| Step: 1
Training loss: 0.43946319818496704
Validation loss: 1.6279976829405753

Epoch: 5| Step: 2
Training loss: 0.24842186272144318
Validation loss: 1.6439584301364036

Epoch: 5| Step: 3
Training loss: 0.2944079041481018
Validation loss: 1.6349233004354662

Epoch: 5| Step: 4
Training loss: 0.19277580082416534
Validation loss: 1.6148702431750555

Epoch: 5| Step: 5
Training loss: 0.36913448572158813
Validation loss: 1.6068725842301563

Epoch: 5| Step: 6
Training loss: 0.330475389957428
Validation loss: 1.5919307508776266

Epoch: 5| Step: 7
Training loss: 0.36070841550827026
Validation loss: 1.5975759913844447

Epoch: 5| Step: 8
Training loss: 0.3453403115272522
Validation loss: 1.6273446006159629

Epoch: 5| Step: 9
Training loss: 0.32646921277046204
Validation loss: 1.63113526375063

Epoch: 5| Step: 10
Training loss: 0.33558228611946106
Validation loss: 1.652581025195378

Epoch: 373| Step: 0
Training loss: 0.2401159703731537
Validation loss: 1.6602469464784027

Epoch: 5| Step: 1
Training loss: 0.4063705503940582
Validation loss: 1.627780900206617

Epoch: 5| Step: 2
Training loss: 0.31608036160469055
Validation loss: 1.6314819448737687

Epoch: 5| Step: 3
Training loss: 0.2768091559410095
Validation loss: 1.622375924100158

Epoch: 5| Step: 4
Training loss: 0.4672287404537201
Validation loss: 1.5911961306807816

Epoch: 5| Step: 5
Training loss: 0.19479410350322723
Validation loss: 1.6126177426307433

Epoch: 5| Step: 6
Training loss: 0.3099682927131653
Validation loss: 1.600380705248925

Epoch: 5| Step: 7
Training loss: 0.2593804597854614
Validation loss: 1.5670487393615067

Epoch: 5| Step: 8
Training loss: 0.5657254457473755
Validation loss: 1.6110328858898533

Epoch: 5| Step: 9
Training loss: 0.3668414056301117
Validation loss: 1.5784840846574435

Epoch: 5| Step: 10
Training loss: 0.3280385434627533
Validation loss: 1.5564834123016686

Epoch: 374| Step: 0
Training loss: 0.43731874227523804
Validation loss: 1.5546147816924638

Epoch: 5| Step: 1
Training loss: 0.35773658752441406
Validation loss: 1.5538864366469844

Epoch: 5| Step: 2
Training loss: 0.3250080943107605
Validation loss: 1.5824335928886168

Epoch: 5| Step: 3
Training loss: 0.19889108836650848
Validation loss: 1.5788886636816046

Epoch: 5| Step: 4
Training loss: 0.30797213315963745
Validation loss: 1.572809798743135

Epoch: 5| Step: 5
Training loss: 0.36781376600265503
Validation loss: 1.573477525864878

Epoch: 5| Step: 6
Training loss: 0.30970561504364014
Validation loss: 1.5592087161156438

Epoch: 5| Step: 7
Training loss: 0.2033161222934723
Validation loss: 1.568404455338755

Epoch: 5| Step: 8
Training loss: 0.24198734760284424
Validation loss: 1.5790440875996825

Epoch: 5| Step: 9
Training loss: 0.6936742067337036
Validation loss: 1.5729069709777832

Epoch: 5| Step: 10
Training loss: 0.2732861042022705
Validation loss: 1.569644288350177

Epoch: 375| Step: 0
Training loss: 0.3135231137275696
Validation loss: 1.571447177599835

Epoch: 5| Step: 1
Training loss: 0.5088316202163696
Validation loss: 1.5763404369354248

Epoch: 5| Step: 2
Training loss: 0.26235726475715637
Validation loss: 1.5841770184937345

Epoch: 5| Step: 3
Training loss: 0.30633315443992615
Validation loss: 1.5772060848051501

Epoch: 5| Step: 4
Training loss: 0.19871290028095245
Validation loss: 1.5755358639583792

Epoch: 5| Step: 5
Training loss: 0.41890138387680054
Validation loss: 1.5427187732470933

Epoch: 5| Step: 6
Training loss: 0.22627432644367218
Validation loss: 1.549554245446318

Epoch: 5| Step: 7
Training loss: 0.2163926661014557
Validation loss: 1.5554147446027367

Epoch: 5| Step: 8
Training loss: 0.48497939109802246
Validation loss: 1.5828191336765085

Epoch: 5| Step: 9
Training loss: 0.24539363384246826
Validation loss: 1.5808302349941705

Epoch: 5| Step: 10
Training loss: 0.225089430809021
Validation loss: 1.6299527537438177

Epoch: 376| Step: 0
Training loss: 0.4137292802333832
Validation loss: 1.6457918510642102

Epoch: 5| Step: 1
Training loss: 0.5540621876716614
Validation loss: 1.6605749578886135

Epoch: 5| Step: 2
Training loss: 0.4996766448020935
Validation loss: 1.6542843426427534

Epoch: 5| Step: 3
Training loss: 0.29753240942955017
Validation loss: 1.6352689035477177

Epoch: 5| Step: 4
Training loss: 0.27315086126327515
Validation loss: 1.60346390867746

Epoch: 5| Step: 5
Training loss: 0.22546672821044922
Validation loss: 1.6007353554489792

Epoch: 5| Step: 6
Training loss: 0.17633680999279022
Validation loss: 1.5921263810127013

Epoch: 5| Step: 7
Training loss: 0.18842068314552307
Validation loss: 1.5839692482384302

Epoch: 5| Step: 8
Training loss: 0.3407134413719177
Validation loss: 1.590942944249799

Epoch: 5| Step: 9
Training loss: 0.2199954092502594
Validation loss: 1.5742423790757374

Epoch: 5| Step: 10
Training loss: 0.41606539487838745
Validation loss: 1.57162239602817

Epoch: 377| Step: 0
Training loss: 0.2509356141090393
Validation loss: 1.587558832219852

Epoch: 5| Step: 1
Training loss: 0.17529770731925964
Validation loss: 1.591101775887192

Epoch: 5| Step: 2
Training loss: 0.31322675943374634
Validation loss: 1.599378014123568

Epoch: 5| Step: 3
Training loss: 0.3411865234375
Validation loss: 1.5448405665736045

Epoch: 5| Step: 4
Training loss: 0.563556969165802
Validation loss: 1.5554083393466087

Epoch: 5| Step: 5
Training loss: 0.37325915694236755
Validation loss: 1.5346866564084125

Epoch: 5| Step: 6
Training loss: 0.23394231498241425
Validation loss: 1.54397786689061

Epoch: 5| Step: 7
Training loss: 0.2339128702878952
Validation loss: 1.5501238389681744

Epoch: 5| Step: 8
Training loss: 0.447618305683136
Validation loss: 1.5701580650062972

Epoch: 5| Step: 9
Training loss: 0.30412235856056213
Validation loss: 1.5862349002592024

Epoch: 5| Step: 10
Training loss: 0.2739105522632599
Validation loss: 1.5702008226866364

Epoch: 378| Step: 0
Training loss: 0.2066701352596283
Validation loss: 1.5949515040202806

Epoch: 5| Step: 1
Training loss: 0.27017492055892944
Validation loss: 1.5643879726368894

Epoch: 5| Step: 2
Training loss: 0.16568054258823395
Validation loss: 1.5451234130449192

Epoch: 5| Step: 3
Training loss: 0.5072828531265259
Validation loss: 1.563586272860086

Epoch: 5| Step: 4
Training loss: 0.20063123106956482
Validation loss: 1.5724154069859495

Epoch: 5| Step: 5
Training loss: 0.3637678623199463
Validation loss: 1.553595042997791

Epoch: 5| Step: 6
Training loss: 0.4586898386478424
Validation loss: 1.584834196234262

Epoch: 5| Step: 7
Training loss: 0.31967395544052124
Validation loss: 1.5629962733996812

Epoch: 5| Step: 8
Training loss: 0.2856200635433197
Validation loss: 1.5733369819579586

Epoch: 5| Step: 9
Training loss: 0.236424058675766
Validation loss: 1.578648651799848

Epoch: 5| Step: 10
Training loss: 0.254245787858963
Validation loss: 1.5818834471446213

Epoch: 379| Step: 0
Training loss: 0.3700673580169678
Validation loss: 1.575510440334197

Epoch: 5| Step: 1
Training loss: 0.20826241374015808
Validation loss: 1.5608122758967902

Epoch: 5| Step: 2
Training loss: 0.21745538711547852
Validation loss: 1.5503522990852274

Epoch: 5| Step: 3
Training loss: 0.34902867674827576
Validation loss: 1.5754953815091042

Epoch: 5| Step: 4
Training loss: 0.37107932567596436
Validation loss: 1.5653275033479095

Epoch: 5| Step: 5
Training loss: 0.2258346527814865
Validation loss: 1.5700542670424267

Epoch: 5| Step: 6
Training loss: 0.4756695330142975
Validation loss: 1.5591542413157802

Epoch: 5| Step: 7
Training loss: 0.1719282567501068
Validation loss: 1.54713874606676

Epoch: 5| Step: 8
Training loss: 0.2489314079284668
Validation loss: 1.5478465493007372

Epoch: 5| Step: 9
Training loss: 0.2582595944404602
Validation loss: 1.5673830816822667

Epoch: 5| Step: 10
Training loss: 0.3511635661125183
Validation loss: 1.5629474052818872

Epoch: 380| Step: 0
Training loss: 0.2075989693403244
Validation loss: 1.5568676546055784

Epoch: 5| Step: 1
Training loss: 0.1986001878976822
Validation loss: 1.5452260637796054

Epoch: 5| Step: 2
Training loss: 0.2848738133907318
Validation loss: 1.5702441482133762

Epoch: 5| Step: 3
Training loss: 0.19045022130012512
Validation loss: 1.561360200246175

Epoch: 5| Step: 4
Training loss: 0.36694055795669556
Validation loss: 1.571826886105281

Epoch: 5| Step: 5
Training loss: 0.1869674175977707
Validation loss: 1.5778624972989481

Epoch: 5| Step: 6
Training loss: 0.519662618637085
Validation loss: 1.5761112423353298

Epoch: 5| Step: 7
Training loss: 0.44400572776794434
Validation loss: 1.564766110912446

Epoch: 5| Step: 8
Training loss: 0.21099576354026794
Validation loss: 1.590423099456295

Epoch: 5| Step: 9
Training loss: 0.4198180139064789
Validation loss: 1.5835493892751715

Epoch: 5| Step: 10
Training loss: 0.2672029435634613
Validation loss: 1.5742398667079147

Epoch: 381| Step: 0
Training loss: 0.3134991526603699
Validation loss: 1.589135726292928

Epoch: 5| Step: 1
Training loss: 0.3496531546115875
Validation loss: 1.5702851587726223

Epoch: 5| Step: 2
Training loss: 0.23754289746284485
Validation loss: 1.5801122060386084

Epoch: 5| Step: 3
Training loss: 0.21310123801231384
Validation loss: 1.5615552804803337

Epoch: 5| Step: 4
Training loss: 0.26440152525901794
Validation loss: 1.5504289955221198

Epoch: 5| Step: 5
Training loss: 0.3270581066608429
Validation loss: 1.57414411985746

Epoch: 5| Step: 6
Training loss: 0.40819257497787476
Validation loss: 1.5811939700957267

Epoch: 5| Step: 7
Training loss: 0.2801259756088257
Validation loss: 1.5957420359375656

Epoch: 5| Step: 8
Training loss: 0.4224456250667572
Validation loss: 1.5833346728355653

Epoch: 5| Step: 9
Training loss: 0.45073094964027405
Validation loss: 1.5762774880214403

Epoch: 5| Step: 10
Training loss: 0.10388210415840149
Validation loss: 1.5589197720250776

Epoch: 382| Step: 0
Training loss: 0.15922877192497253
Validation loss: 1.5984427531560261

Epoch: 5| Step: 1
Training loss: 0.36332231760025024
Validation loss: 1.6000600784055647

Epoch: 5| Step: 2
Training loss: 0.26982879638671875
Validation loss: 1.5845537800942697

Epoch: 5| Step: 3
Training loss: 0.5087345242500305
Validation loss: 1.5911733899065243

Epoch: 5| Step: 4
Training loss: 0.19433890283107758
Validation loss: 1.573278514287805

Epoch: 5| Step: 5
Training loss: 0.12174217402935028
Validation loss: 1.5710461088406142

Epoch: 5| Step: 6
Training loss: 0.29434022307395935
Validation loss: 1.5753602276566208

Epoch: 5| Step: 7
Training loss: 0.4045661389827728
Validation loss: 1.5939092507926367

Epoch: 5| Step: 8
Training loss: 0.5192146301269531
Validation loss: 1.6065738072959326

Epoch: 5| Step: 9
Training loss: 0.34134194254875183
Validation loss: 1.6047969723260531

Epoch: 5| Step: 10
Training loss: 0.33695346117019653
Validation loss: 1.6123209941771723

Epoch: 383| Step: 0
Training loss: 0.19775420427322388
Validation loss: 1.6066880123589629

Epoch: 5| Step: 1
Training loss: 0.2054428607225418
Validation loss: 1.6201746899594542

Epoch: 5| Step: 2
Training loss: 0.3041079044342041
Validation loss: 1.6235081175322175

Epoch: 5| Step: 3
Training loss: 0.5424479246139526
Validation loss: 1.634962333145962

Epoch: 5| Step: 4
Training loss: 0.3352600038051605
Validation loss: 1.5964305400848389

Epoch: 5| Step: 5
Training loss: 0.2978847920894623
Validation loss: 1.60324195508034

Epoch: 5| Step: 6
Training loss: 0.2734491229057312
Validation loss: 1.5719621386579288

Epoch: 5| Step: 7
Training loss: 0.18577127158641815
Validation loss: 1.5636188086643015

Epoch: 5| Step: 8
Training loss: 0.32062166929244995
Validation loss: 1.5896253713997461

Epoch: 5| Step: 9
Training loss: 0.21309900283813477
Validation loss: 1.5884655060306672

Epoch: 5| Step: 10
Training loss: 0.6098190546035767
Validation loss: 1.6214990731208556

Epoch: 384| Step: 0
Training loss: 0.2977488040924072
Validation loss: 1.586008253276989

Epoch: 5| Step: 1
Training loss: 0.37629061937332153
Validation loss: 1.5922306186409407

Epoch: 5| Step: 2
Training loss: 0.2749931216239929
Validation loss: 1.561382116809968

Epoch: 5| Step: 3
Training loss: 0.5076010823249817
Validation loss: 1.586711827144828

Epoch: 5| Step: 4
Training loss: 0.20463845133781433
Validation loss: 1.5759347882322086

Epoch: 5| Step: 5
Training loss: 0.21305914223194122
Validation loss: 1.5539928020969513

Epoch: 5| Step: 6
Training loss: 0.3272826373577118
Validation loss: 1.5575874582413705

Epoch: 5| Step: 7
Training loss: 0.33895188570022583
Validation loss: 1.5738694719088975

Epoch: 5| Step: 8
Training loss: 0.376682311296463
Validation loss: 1.5717961320313074

Epoch: 5| Step: 9
Training loss: 0.26288700103759766
Validation loss: 1.5386622990331342

Epoch: 5| Step: 10
Training loss: 0.18848904967308044
Validation loss: 1.5773604326350714

Epoch: 385| Step: 0
Training loss: 0.275665819644928
Validation loss: 1.5752821506992463

Epoch: 5| Step: 1
Training loss: 0.19376030564308167
Validation loss: 1.5926274048384799

Epoch: 5| Step: 2
Training loss: 0.259134441614151
Validation loss: 1.6101242188484437

Epoch: 5| Step: 3
Training loss: 0.38792458176612854
Validation loss: 1.6538095954925782

Epoch: 5| Step: 4
Training loss: 0.40877074003219604
Validation loss: 1.6759656847164195

Epoch: 5| Step: 5
Training loss: 0.4334079325199127
Validation loss: 1.6334443630710724

Epoch: 5| Step: 6
Training loss: 0.25326666235923767
Validation loss: 1.609252615641522

Epoch: 5| Step: 7
Training loss: 0.18693482875823975
Validation loss: 1.6316842122744488

Epoch: 5| Step: 8
Training loss: 0.2874354422092438
Validation loss: 1.6312657261407504

Epoch: 5| Step: 9
Training loss: 0.5095447897911072
Validation loss: 1.5956269528276177

Epoch: 5| Step: 10
Training loss: 0.22688966989517212
Validation loss: 1.5869329911406322

Epoch: 386| Step: 0
Training loss: 0.27643439173698425
Validation loss: 1.6182220174420265

Epoch: 5| Step: 1
Training loss: 0.2952427268028259
Validation loss: 1.5978347870611376

Epoch: 5| Step: 2
Training loss: 0.2907439172267914
Validation loss: 1.6363803430270123

Epoch: 5| Step: 3
Training loss: 0.20028278231620789
Validation loss: 1.6549114475968063

Epoch: 5| Step: 4
Training loss: 0.32349446415901184
Validation loss: 1.6645939888492707

Epoch: 5| Step: 5
Training loss: 0.48194488883018494
Validation loss: 1.680623496732404

Epoch: 5| Step: 6
Training loss: 0.2822815179824829
Validation loss: 1.604231301174369

Epoch: 5| Step: 7
Training loss: 0.28207889199256897
Validation loss: 1.576345225816132

Epoch: 5| Step: 8
Training loss: 0.3165367543697357
Validation loss: 1.5661523278041551

Epoch: 5| Step: 9
Training loss: 0.2652982771396637
Validation loss: 1.5824440897151988

Epoch: 5| Step: 10
Training loss: 0.3774537444114685
Validation loss: 1.565390807326122

Epoch: 387| Step: 0
Training loss: 0.36539509892463684
Validation loss: 1.5732047660376436

Epoch: 5| Step: 1
Training loss: 0.274981290102005
Validation loss: 1.572541121513613

Epoch: 5| Step: 2
Training loss: 0.3282381296157837
Validation loss: 1.5550997962233841

Epoch: 5| Step: 3
Training loss: 0.315895140171051
Validation loss: 1.5400924195525467

Epoch: 5| Step: 4
Training loss: 0.2505735456943512
Validation loss: 1.5485802363323908

Epoch: 5| Step: 5
Training loss: 0.5610058307647705
Validation loss: 1.605485268818435

Epoch: 5| Step: 6
Training loss: 0.5775107145309448
Validation loss: 1.6203311361292356

Epoch: 5| Step: 7
Training loss: 0.4131552278995514
Validation loss: 1.62916632557428

Epoch: 5| Step: 8
Training loss: 0.20962241291999817
Validation loss: 1.60418822175713

Epoch: 5| Step: 9
Training loss: 0.2748675048351288
Validation loss: 1.589652105044293

Epoch: 5| Step: 10
Training loss: 0.5672605037689209
Validation loss: 1.567733085283669

Epoch: 388| Step: 0
Training loss: 0.41229814291000366
Validation loss: 1.555455619289029

Epoch: 5| Step: 1
Training loss: 0.3475416600704193
Validation loss: 1.6073308170482676

Epoch: 5| Step: 2
Training loss: 0.30485856533050537
Validation loss: 1.5936290679439422

Epoch: 5| Step: 3
Training loss: 0.40948939323425293
Validation loss: 1.5815080622191071

Epoch: 5| Step: 4
Training loss: 0.37535110116004944
Validation loss: 1.5636448872986661

Epoch: 5| Step: 5
Training loss: 0.23166406154632568
Validation loss: 1.5452491057816373

Epoch: 5| Step: 6
Training loss: 0.2714448571205139
Validation loss: 1.5626029481169998

Epoch: 5| Step: 7
Training loss: 0.21057960391044617
Validation loss: 1.61735902806764

Epoch: 5| Step: 8
Training loss: 0.48544877767562866
Validation loss: 1.6491309455645982

Epoch: 5| Step: 9
Training loss: 0.4398956894874573
Validation loss: 1.70901596161627

Epoch: 5| Step: 10
Training loss: 0.2784497141838074
Validation loss: 1.7248672131569154

Epoch: 389| Step: 0
Training loss: 0.2845231890678406
Validation loss: 1.748090822209594

Epoch: 5| Step: 1
Training loss: 0.2942962646484375
Validation loss: 1.7023751863869288

Epoch: 5| Step: 2
Training loss: 0.3940735161304474
Validation loss: 1.6599873753004177

Epoch: 5| Step: 3
Training loss: 0.20618653297424316
Validation loss: 1.6136108226673578

Epoch: 5| Step: 4
Training loss: 0.43967634439468384
Validation loss: 1.5761263037240634

Epoch: 5| Step: 5
Training loss: 0.21243131160736084
Validation loss: 1.5764827112997732

Epoch: 5| Step: 6
Training loss: 0.29406625032424927
Validation loss: 1.568385794598569

Epoch: 5| Step: 7
Training loss: 0.40978145599365234
Validation loss: 1.5759596170917634

Epoch: 5| Step: 8
Training loss: 0.2301153838634491
Validation loss: 1.541696471552695

Epoch: 5| Step: 9
Training loss: 0.34052374958992004
Validation loss: 1.5857791157178982

Epoch: 5| Step: 10
Training loss: 0.5003679990768433
Validation loss: 1.5734059605547177

Epoch: 390| Step: 0
Training loss: 0.2865287959575653
Validation loss: 1.600920832285317

Epoch: 5| Step: 1
Training loss: 0.4394468367099762
Validation loss: 1.5822001285450433

Epoch: 5| Step: 2
Training loss: 0.22495302557945251
Validation loss: 1.5677563016132643

Epoch: 5| Step: 3
Training loss: 0.23637473583221436
Validation loss: 1.5403631201354406

Epoch: 5| Step: 4
Training loss: 0.4502505362033844
Validation loss: 1.5225238569321171

Epoch: 5| Step: 5
Training loss: 0.2577916979789734
Validation loss: 1.5075023546013782

Epoch: 5| Step: 6
Training loss: 0.16897276043891907
Validation loss: 1.5128384149202736

Epoch: 5| Step: 7
Training loss: 0.247747540473938
Validation loss: 1.555470581977598

Epoch: 5| Step: 8
Training loss: 0.272113174200058
Validation loss: 1.5704278023012224

Epoch: 5| Step: 9
Training loss: 0.5093470811843872
Validation loss: 1.546868025615651

Epoch: 5| Step: 10
Training loss: 0.24306650459766388
Validation loss: 1.546624651519201

Epoch: 391| Step: 0
Training loss: 0.2789244055747986
Validation loss: 1.5896983479940763

Epoch: 5| Step: 1
Training loss: 0.32983124256134033
Validation loss: 1.584356036237491

Epoch: 5| Step: 2
Training loss: 0.3668554723262787
Validation loss: 1.6120979439827703

Epoch: 5| Step: 3
Training loss: 0.2997567653656006
Validation loss: 1.6271906527139808

Epoch: 5| Step: 4
Training loss: 0.3640887141227722
Validation loss: 1.6355187828822801

Epoch: 5| Step: 5
Training loss: 0.23384690284729004
Validation loss: 1.6067196169207174

Epoch: 5| Step: 6
Training loss: 0.27450257539749146
Validation loss: 1.5712605362297387

Epoch: 5| Step: 7
Training loss: 0.1289539635181427
Validation loss: 1.5588288640463224

Epoch: 5| Step: 8
Training loss: 0.22953812777996063
Validation loss: 1.5514743020457606

Epoch: 5| Step: 9
Training loss: 0.3587469160556793
Validation loss: 1.5608785075526084

Epoch: 5| Step: 10
Training loss: 0.4790109694004059
Validation loss: 1.573266565158803

Epoch: 392| Step: 0
Training loss: 0.24209105968475342
Validation loss: 1.5744000045202111

Epoch: 5| Step: 1
Training loss: 0.2888553738594055
Validation loss: 1.5677750930991223

Epoch: 5| Step: 2
Training loss: 0.44441136717796326
Validation loss: 1.5838315166452879

Epoch: 5| Step: 3
Training loss: 0.3297598958015442
Validation loss: 1.572628692914081

Epoch: 5| Step: 4
Training loss: 0.34576982259750366
Validation loss: 1.596794387345673

Epoch: 5| Step: 5
Training loss: 0.3583858609199524
Validation loss: 1.6531786111093336

Epoch: 5| Step: 6
Training loss: 0.301861047744751
Validation loss: 1.6184868812561035

Epoch: 5| Step: 7
Training loss: 0.338154673576355
Validation loss: 1.6339536302833146

Epoch: 5| Step: 8
Training loss: 0.5499579310417175
Validation loss: 1.5974260401982132

Epoch: 5| Step: 9
Training loss: 0.2327708899974823
Validation loss: 1.5717320108926425

Epoch: 5| Step: 10
Training loss: 0.1783127784729004
Validation loss: 1.557218127353217

Epoch: 393| Step: 0
Training loss: 0.35859355330467224
Validation loss: 1.5617797259361512

Epoch: 5| Step: 1
Training loss: 0.4607371687889099
Validation loss: 1.5686321002180859

Epoch: 5| Step: 2
Training loss: 0.2463606894016266
Validation loss: 1.5518578995940506

Epoch: 5| Step: 3
Training loss: 0.16086873412132263
Validation loss: 1.5273644789572685

Epoch: 5| Step: 4
Training loss: 0.2877364158630371
Validation loss: 1.5472080829322978

Epoch: 5| Step: 5
Training loss: 0.2601161599159241
Validation loss: 1.5549463943768573

Epoch: 5| Step: 6
Training loss: 0.20627892017364502
Validation loss: 1.5770615993007537

Epoch: 5| Step: 7
Training loss: 0.36158275604248047
Validation loss: 1.5989349196034093

Epoch: 5| Step: 8
Training loss: 0.26702213287353516
Validation loss: 1.568873583629567

Epoch: 5| Step: 9
Training loss: 0.3054065704345703
Validation loss: 1.5973874138247581

Epoch: 5| Step: 10
Training loss: 0.27258485555648804
Validation loss: 1.5705975383840582

Epoch: 394| Step: 0
Training loss: 0.3009670078754425
Validation loss: 1.5774112824470765

Epoch: 5| Step: 1
Training loss: 0.25907450914382935
Validation loss: 1.589429086254489

Epoch: 5| Step: 2
Training loss: 0.30226731300354004
Validation loss: 1.5805360988904071

Epoch: 5| Step: 3
Training loss: 0.23523959517478943
Validation loss: 1.58326506358321

Epoch: 5| Step: 4
Training loss: 0.4145523011684418
Validation loss: 1.5849835129194363

Epoch: 5| Step: 5
Training loss: 0.2235465943813324
Validation loss: 1.5481959542920511

Epoch: 5| Step: 6
Training loss: 0.21912983059883118
Validation loss: 1.555022862649733

Epoch: 5| Step: 7
Training loss: 0.21711330115795135
Validation loss: 1.5507336983116724

Epoch: 5| Step: 8
Training loss: 0.48745155334472656
Validation loss: 1.5275640096715701

Epoch: 5| Step: 9
Training loss: 0.2416180670261383
Validation loss: 1.5374090030629148

Epoch: 5| Step: 10
Training loss: 0.18711036443710327
Validation loss: 1.5394573416761173

Epoch: 395| Step: 0
Training loss: 0.30328691005706787
Validation loss: 1.5631312875337497

Epoch: 5| Step: 1
Training loss: 0.2525627613067627
Validation loss: 1.581088956966195

Epoch: 5| Step: 2
Training loss: 0.13907110691070557
Validation loss: 1.580440237957944

Epoch: 5| Step: 3
Training loss: 0.39416438341140747
Validation loss: 1.5811094673730994

Epoch: 5| Step: 4
Training loss: 0.3082423806190491
Validation loss: 1.5618582387124338

Epoch: 5| Step: 5
Training loss: 0.25750574469566345
Validation loss: 1.5592297366870347

Epoch: 5| Step: 6
Training loss: 0.4220079779624939
Validation loss: 1.5791977272238782

Epoch: 5| Step: 7
Training loss: 0.1874772608280182
Validation loss: 1.5608335528322446

Epoch: 5| Step: 8
Training loss: 0.3298352062702179
Validation loss: 1.565285046895345

Epoch: 5| Step: 9
Training loss: 0.20402231812477112
Validation loss: 1.557025710741679

Epoch: 5| Step: 10
Training loss: 0.2875591814517975
Validation loss: 1.5978282074774466

Epoch: 396| Step: 0
Training loss: 0.19779042899608612
Validation loss: 1.583163115286058

Epoch: 5| Step: 1
Training loss: 0.24079599976539612
Validation loss: 1.5847744185437438

Epoch: 5| Step: 2
Training loss: 0.32474637031555176
Validation loss: 1.5980697293435373

Epoch: 5| Step: 3
Training loss: 0.2675660252571106
Validation loss: 1.584454926111365

Epoch: 5| Step: 4
Training loss: 0.256585031747818
Validation loss: 1.6021553893243112

Epoch: 5| Step: 5
Training loss: 0.5020418763160706
Validation loss: 1.6099575078615578

Epoch: 5| Step: 6
Training loss: 0.23861908912658691
Validation loss: 1.5754431755312028

Epoch: 5| Step: 7
Training loss: 0.39023271203041077
Validation loss: 1.5921024635273924

Epoch: 5| Step: 8
Training loss: 0.17767611145973206
Validation loss: 1.5811783690606394

Epoch: 5| Step: 9
Training loss: 0.23260025680065155
Validation loss: 1.5718317980407386

Epoch: 5| Step: 10
Training loss: 0.3203802704811096
Validation loss: 1.5724133996553318

Epoch: 397| Step: 0
Training loss: 0.3395669162273407
Validation loss: 1.5652563501429815

Epoch: 5| Step: 1
Training loss: 0.20814402401447296
Validation loss: 1.573328282243462

Epoch: 5| Step: 2
Training loss: 0.19326719641685486
Validation loss: 1.5407217638466948

Epoch: 5| Step: 3
Training loss: 0.19208577275276184
Validation loss: 1.514204090641391

Epoch: 5| Step: 4
Training loss: 0.3699663579463959
Validation loss: 1.5356410164986887

Epoch: 5| Step: 5
Training loss: 0.3467840552330017
Validation loss: 1.5316373353363366

Epoch: 5| Step: 6
Training loss: 0.5628914833068848
Validation loss: 1.5454682124558317

Epoch: 5| Step: 7
Training loss: 0.33124226331710815
Validation loss: 1.549868715706692

Epoch: 5| Step: 8
Training loss: 0.16824674606323242
Validation loss: 1.5652105513439383

Epoch: 5| Step: 9
Training loss: 0.2723318934440613
Validation loss: 1.599185057224766

Epoch: 5| Step: 10
Training loss: 0.18456585705280304
Validation loss: 1.6031259952052948

Epoch: 398| Step: 0
Training loss: 0.1869870275259018
Validation loss: 1.6214775141849314

Epoch: 5| Step: 1
Training loss: 0.23829837143421173
Validation loss: 1.6056045998809159

Epoch: 5| Step: 2
Training loss: 0.21807317435741425
Validation loss: 1.6001491444085234

Epoch: 5| Step: 3
Training loss: 0.2721390426158905
Validation loss: 1.6065249289235761

Epoch: 5| Step: 4
Training loss: 0.18836219608783722
Validation loss: 1.6004810192251717

Epoch: 5| Step: 5
Training loss: 0.38926494121551514
Validation loss: 1.5855188497933008

Epoch: 5| Step: 6
Training loss: 0.21674123406410217
Validation loss: 1.6083443011007001

Epoch: 5| Step: 7
Training loss: 0.2897663116455078
Validation loss: 1.6157301651534213

Epoch: 5| Step: 8
Training loss: 0.48996567726135254
Validation loss: 1.5999198036809121

Epoch: 5| Step: 9
Training loss: 0.38554146885871887
Validation loss: 1.6074004250188028

Epoch: 5| Step: 10
Training loss: 0.24206329882144928
Validation loss: 1.5679477792914196

Epoch: 399| Step: 0
Training loss: 0.2345852553844452
Validation loss: 1.555840193584401

Epoch: 5| Step: 1
Training loss: 0.3631463348865509
Validation loss: 1.5457810637771443

Epoch: 5| Step: 2
Training loss: 0.25224170088768005
Validation loss: 1.5530875305975638

Epoch: 5| Step: 3
Training loss: 0.21310000121593475
Validation loss: 1.5363074092454807

Epoch: 5| Step: 4
Training loss: 0.2016543447971344
Validation loss: 1.5503492380983086

Epoch: 5| Step: 5
Training loss: 0.1742112785577774
Validation loss: 1.5394606859453264

Epoch: 5| Step: 6
Training loss: 0.6029231548309326
Validation loss: 1.537645891789467

Epoch: 5| Step: 7
Training loss: 0.3353390097618103
Validation loss: 1.577398274534492

Epoch: 5| Step: 8
Training loss: 0.17680412530899048
Validation loss: 1.544882325715916

Epoch: 5| Step: 9
Training loss: 0.32975107431411743
Validation loss: 1.5603580321035078

Epoch: 5| Step: 10
Training loss: 0.27693793177604675
Validation loss: 1.5626360036993538

Epoch: 400| Step: 0
Training loss: 0.3575766086578369
Validation loss: 1.580237478338262

Epoch: 5| Step: 1
Training loss: 0.4073532223701477
Validation loss: 1.5782915353775024

Epoch: 5| Step: 2
Training loss: 0.31594792008399963
Validation loss: 1.5819358787228983

Epoch: 5| Step: 3
Training loss: 0.24804699420928955
Validation loss: 1.600453851043537

Epoch: 5| Step: 4
Training loss: 0.2674753963947296
Validation loss: 1.6069813646296018

Epoch: 5| Step: 5
Training loss: 0.19118282198905945
Validation loss: 1.6222592822967037

Epoch: 5| Step: 6
Training loss: 0.2526529133319855
Validation loss: 1.6094544882415442

Epoch: 5| Step: 7
Training loss: 0.2740902006626129
Validation loss: 1.6266706784566243

Epoch: 5| Step: 8
Training loss: 0.32510071992874146
Validation loss: 1.6059532947437738

Epoch: 5| Step: 9
Training loss: 0.4150729179382324
Validation loss: 1.57705355716008

Epoch: 5| Step: 10
Training loss: 0.37168607115745544
Validation loss: 1.5531892186851912

Epoch: 401| Step: 0
Training loss: 0.2752693295478821
Validation loss: 1.559338346604378

Epoch: 5| Step: 1
Training loss: 0.18186497688293457
Validation loss: 1.5542301542015486

Epoch: 5| Step: 2
Training loss: 0.27699166536331177
Validation loss: 1.5554749452939598

Epoch: 5| Step: 3
Training loss: 0.3653792440891266
Validation loss: 1.5617054226577922

Epoch: 5| Step: 4
Training loss: 0.3164712190628052
Validation loss: 1.5781109807311848

Epoch: 5| Step: 5
Training loss: 0.31510961055755615
Validation loss: 1.591248099521924

Epoch: 5| Step: 6
Training loss: 0.34262987971305847
Validation loss: 1.6104803841601136

Epoch: 5| Step: 7
Training loss: 0.2326335459947586
Validation loss: 1.571839726099404

Epoch: 5| Step: 8
Training loss: 0.48490118980407715
Validation loss: 1.570540601207364

Epoch: 5| Step: 9
Training loss: 0.31641656160354614
Validation loss: 1.542793809726674

Epoch: 5| Step: 10
Training loss: 0.23065555095672607
Validation loss: 1.5793257195462462

Epoch: 402| Step: 0
Training loss: 0.4501670300960541
Validation loss: 1.5853090209345664

Epoch: 5| Step: 1
Training loss: 0.3903760015964508
Validation loss: 1.577962471592811

Epoch: 5| Step: 2
Training loss: 0.28005772829055786
Validation loss: 1.573304710849639

Epoch: 5| Step: 3
Training loss: 0.4221436381340027
Validation loss: 1.562447021084447

Epoch: 5| Step: 4
Training loss: 0.22932443022727966
Validation loss: 1.5786896931227816

Epoch: 5| Step: 5
Training loss: 0.22933784127235413
Validation loss: 1.576435209602438

Epoch: 5| Step: 6
Training loss: 0.16510048508644104
Validation loss: 1.5738643215548607

Epoch: 5| Step: 7
Training loss: 0.25363072752952576
Validation loss: 1.603637997822095

Epoch: 5| Step: 8
Training loss: 0.3112235963344574
Validation loss: 1.627655707379823

Epoch: 5| Step: 9
Training loss: 0.24765880405902863
Validation loss: 1.6216813800155476

Epoch: 5| Step: 10
Training loss: 0.3083111643791199
Validation loss: 1.5785828098174064

Epoch: 403| Step: 0
Training loss: 0.2653014361858368
Validation loss: 1.5241734173990065

Epoch: 5| Step: 1
Training loss: 0.20976321399211884
Validation loss: 1.5571970042362009

Epoch: 5| Step: 2
Training loss: 0.17305037379264832
Validation loss: 1.5393754256668912

Epoch: 5| Step: 3
Training loss: 0.2167818248271942
Validation loss: 1.5079034746334117

Epoch: 5| Step: 4
Training loss: 0.2152293175458908
Validation loss: 1.52521530594877

Epoch: 5| Step: 5
Training loss: 0.37165987491607666
Validation loss: 1.514440615330973

Epoch: 5| Step: 6
Training loss: 0.4651103913784027
Validation loss: 1.4980897864987772

Epoch: 5| Step: 7
Training loss: 0.24236759543418884
Validation loss: 1.5016876010484592

Epoch: 5| Step: 8
Training loss: 0.3871217370033264
Validation loss: 1.501599875829553

Epoch: 5| Step: 9
Training loss: 0.27551841735839844
Validation loss: 1.5226432764402

Epoch: 5| Step: 10
Training loss: 0.23979775607585907
Validation loss: 1.5306428952883648

Epoch: 404| Step: 0
Training loss: 0.24706368148326874
Validation loss: 1.5443696347616052

Epoch: 5| Step: 1
Training loss: 0.5232685804367065
Validation loss: 1.5658913709784066

Epoch: 5| Step: 2
Training loss: 0.19413770735263824
Validation loss: 1.548003428725786

Epoch: 5| Step: 3
Training loss: 0.24692192673683167
Validation loss: 1.5463797251383464

Epoch: 5| Step: 4
Training loss: 0.4542359709739685
Validation loss: 1.5548216553144558

Epoch: 5| Step: 5
Training loss: 0.19349852204322815
Validation loss: 1.5445558165991178

Epoch: 5| Step: 6
Training loss: 0.13479766249656677
Validation loss: 1.5282318374162078

Epoch: 5| Step: 7
Training loss: 0.21617451310157776
Validation loss: 1.5551239623818347

Epoch: 5| Step: 8
Training loss: 0.13758721947669983
Validation loss: 1.543431342289012

Epoch: 5| Step: 9
Training loss: 0.2223895788192749
Validation loss: 1.5691586438045706

Epoch: 5| Step: 10
Training loss: 0.19924503564834595
Validation loss: 1.5991711975425802

Epoch: 405| Step: 0
Training loss: 0.24019572138786316
Validation loss: 1.6468805036237162

Epoch: 5| Step: 1
Training loss: 0.3088163435459137
Validation loss: 1.6701870925964848

Epoch: 5| Step: 2
Training loss: 0.49258509278297424
Validation loss: 1.6385923175401584

Epoch: 5| Step: 3
Training loss: 0.3377482295036316
Validation loss: 1.6118441948326685

Epoch: 5| Step: 4
Training loss: 0.2481817752122879
Validation loss: 1.583991781357796

Epoch: 5| Step: 5
Training loss: 0.16491036117076874
Validation loss: 1.6162088071146319

Epoch: 5| Step: 6
Training loss: 0.24597950279712677
Validation loss: 1.612306389757382

Epoch: 5| Step: 7
Training loss: 0.2550715208053589
Validation loss: 1.6076815179599229

Epoch: 5| Step: 8
Training loss: 0.46060800552368164
Validation loss: 1.5398153604999665

Epoch: 5| Step: 9
Training loss: 0.42604899406433105
Validation loss: 1.4900822742010957

Epoch: 5| Step: 10
Training loss: 0.1629125028848648
Validation loss: 1.537095069885254

Epoch: 406| Step: 0
Training loss: 0.2819041609764099
Validation loss: 1.5301743502257972

Epoch: 5| Step: 1
Training loss: 0.32738304138183594
Validation loss: 1.5818508337902766

Epoch: 5| Step: 2
Training loss: 0.3036425709724426
Validation loss: 1.5827352077730241

Epoch: 5| Step: 3
Training loss: 0.3282008767127991
Validation loss: 1.56788650379386

Epoch: 5| Step: 4
Training loss: 0.24263253808021545
Validation loss: 1.581005947564238

Epoch: 5| Step: 5
Training loss: 0.40310853719711304
Validation loss: 1.545363942141174

Epoch: 5| Step: 6
Training loss: 0.2309117615222931
Validation loss: 1.543216811713352

Epoch: 5| Step: 7
Training loss: 0.23779945075511932
Validation loss: 1.5461241429851902

Epoch: 5| Step: 8
Training loss: 0.2944425046443939
Validation loss: 1.5607993000297136

Epoch: 5| Step: 9
Training loss: 0.2614847421646118
Validation loss: 1.5584199415740145

Epoch: 5| Step: 10
Training loss: 0.14465825259685516
Validation loss: 1.591037106770341

Epoch: 407| Step: 0
Training loss: 0.23249439895153046
Validation loss: 1.572717869794497

Epoch: 5| Step: 1
Training loss: 0.17803515493869781
Validation loss: 1.5777576456787765

Epoch: 5| Step: 2
Training loss: 0.17166325449943542
Validation loss: 1.5523639520009358

Epoch: 5| Step: 3
Training loss: 0.2438008338212967
Validation loss: 1.5839245293730049

Epoch: 5| Step: 4
Training loss: 0.352321982383728
Validation loss: 1.586942982930009

Epoch: 5| Step: 5
Training loss: 0.44584593176841736
Validation loss: 1.5979244478287236

Epoch: 5| Step: 6
Training loss: 0.24224138259887695
Validation loss: 1.5862445228843278

Epoch: 5| Step: 7
Training loss: 0.2246340811252594
Validation loss: 1.561974431878777

Epoch: 5| Step: 8
Training loss: 0.19656755030155182
Validation loss: 1.556800462866342

Epoch: 5| Step: 9
Training loss: 0.5208579301834106
Validation loss: 1.5502738901363906

Epoch: 5| Step: 10
Training loss: 0.14703775942325592
Validation loss: 1.5638058236850205

Epoch: 408| Step: 0
Training loss: 0.09689818322658539
Validation loss: 1.584901213645935

Epoch: 5| Step: 1
Training loss: 0.1690727025270462
Validation loss: 1.593002051435491

Epoch: 5| Step: 2
Training loss: 0.26154813170433044
Validation loss: 1.6166958206443376

Epoch: 5| Step: 3
Training loss: 0.41174212098121643
Validation loss: 1.6020892127867667

Epoch: 5| Step: 4
Training loss: 0.3166106343269348
Validation loss: 1.568608873633928

Epoch: 5| Step: 5
Training loss: 0.18333937227725983
Validation loss: 1.5620565427246915

Epoch: 5| Step: 6
Training loss: 0.18765582144260406
Validation loss: 1.5540061022645684

Epoch: 5| Step: 7
Training loss: 0.3903542757034302
Validation loss: 1.511640937097611

Epoch: 5| Step: 8
Training loss: 0.4340788424015045
Validation loss: 1.5022146637721727

Epoch: 5| Step: 9
Training loss: 0.3060137629508972
Validation loss: 1.5270860092614287

Epoch: 5| Step: 10
Training loss: 0.22385622560977936
Validation loss: 1.524835414783929

Epoch: 409| Step: 0
Training loss: 0.3590086102485657
Validation loss: 1.5364838928304694

Epoch: 5| Step: 1
Training loss: 0.21031513810157776
Validation loss: 1.5720611182592248

Epoch: 5| Step: 2
Training loss: 0.1796301156282425
Validation loss: 1.5861771645084504

Epoch: 5| Step: 3
Training loss: 0.35566088557243347
Validation loss: 1.5991580755479875

Epoch: 5| Step: 4
Training loss: 0.2635602355003357
Validation loss: 1.6350473716694822

Epoch: 5| Step: 5
Training loss: 0.3080463707447052
Validation loss: 1.6469234189679545

Epoch: 5| Step: 6
Training loss: 0.32369351387023926
Validation loss: 1.6186153452883485

Epoch: 5| Step: 7
Training loss: 0.13290758430957794
Validation loss: 1.5837167270721928

Epoch: 5| Step: 8
Training loss: 0.15088309347629547
Validation loss: 1.5894899772059532

Epoch: 5| Step: 9
Training loss: 0.20568545162677765
Validation loss: 1.602107168525778

Epoch: 5| Step: 10
Training loss: 0.3587096929550171
Validation loss: 1.6285028496096212

Epoch: 410| Step: 0
Training loss: 0.2726222574710846
Validation loss: 1.6354809050918908

Epoch: 5| Step: 1
Training loss: 0.3146894872188568
Validation loss: 1.5818200329298615

Epoch: 5| Step: 2
Training loss: 0.19983609020709991
Validation loss: 1.5873413547392814

Epoch: 5| Step: 3
Training loss: 0.2323680818080902
Validation loss: 1.5654495826331518

Epoch: 5| Step: 4
Training loss: 0.17073345184326172
Validation loss: 1.557951904112293

Epoch: 5| Step: 5
Training loss: 0.12137247622013092
Validation loss: 1.550465900410888

Epoch: 5| Step: 6
Training loss: 0.13760359585285187
Validation loss: 1.5501605528657154

Epoch: 5| Step: 7
Training loss: 0.2079520970582962
Validation loss: 1.569611168676807

Epoch: 5| Step: 8
Training loss: 0.23928804695606232
Validation loss: 1.5762435441376061

Epoch: 5| Step: 9
Training loss: 0.2969871163368225
Validation loss: 1.5376672975478634

Epoch: 5| Step: 10
Training loss: 0.46746528148651123
Validation loss: 1.5346034829334547

Epoch: 411| Step: 0
Training loss: 0.21199512481689453
Validation loss: 1.552459104086763

Epoch: 5| Step: 1
Training loss: 0.13211126625537872
Validation loss: 1.5741690038352885

Epoch: 5| Step: 2
Training loss: 0.2819833755493164
Validation loss: 1.572494872154728

Epoch: 5| Step: 3
Training loss: 0.20024549961090088
Validation loss: 1.5910140942501765

Epoch: 5| Step: 4
Training loss: 0.22874650359153748
Validation loss: 1.5953102983454222

Epoch: 5| Step: 5
Training loss: 0.30274084210395813
Validation loss: 1.5761495995265182

Epoch: 5| Step: 6
Training loss: 0.2992837429046631
Validation loss: 1.5808144987270396

Epoch: 5| Step: 7
Training loss: 0.09584526717662811
Validation loss: 1.5538889977239794

Epoch: 5| Step: 8
Training loss: 0.19407819211483002
Validation loss: 1.5592182349133235

Epoch: 5| Step: 9
Training loss: 0.18900571763515472
Validation loss: 1.5608671865155619

Epoch: 5| Step: 10
Training loss: 0.5071710348129272
Validation loss: 1.5624488489602202

Epoch: 412| Step: 0
Training loss: 0.24177391827106476
Validation loss: 1.574717564608461

Epoch: 5| Step: 1
Training loss: 0.22759731113910675
Validation loss: 1.596077137095954

Epoch: 5| Step: 2
Training loss: 0.2049669325351715
Validation loss: 1.610904505175929

Epoch: 5| Step: 3
Training loss: 0.1756456047296524
Validation loss: 1.6271121860832296

Epoch: 5| Step: 4
Training loss: 0.2513936758041382
Validation loss: 1.6184496456576931

Epoch: 5| Step: 5
Training loss: 0.2941505014896393
Validation loss: 1.5988538431864914

Epoch: 5| Step: 6
Training loss: 0.13541913032531738
Validation loss: 1.59594633758709

Epoch: 5| Step: 7
Training loss: 0.3249446749687195
Validation loss: 1.595357984624883

Epoch: 5| Step: 8
Training loss: 0.37897127866744995
Validation loss: 1.6084522944624706

Epoch: 5| Step: 9
Training loss: 0.09420573711395264
Validation loss: 1.5616378784179688

Epoch: 5| Step: 10
Training loss: 0.3362833857536316
Validation loss: 1.5923219701295257

Epoch: 413| Step: 0
Training loss: 0.20969383418560028
Validation loss: 1.565296838360448

Epoch: 5| Step: 1
Training loss: 0.16446992754936218
Validation loss: 1.561282145079746

Epoch: 5| Step: 2
Training loss: 0.2070588618516922
Validation loss: 1.5459301138436923

Epoch: 5| Step: 3
Training loss: 0.29664346575737
Validation loss: 1.5601264392175982

Epoch: 5| Step: 4
Training loss: 0.22695370018482208
Validation loss: 1.5599250998548282

Epoch: 5| Step: 5
Training loss: 0.14380815625190735
Validation loss: 1.554277313652859

Epoch: 5| Step: 6
Training loss: 0.35541659593582153
Validation loss: 1.5591077932747461

Epoch: 5| Step: 7
Training loss: 0.2501433491706848
Validation loss: 1.5563775159979378

Epoch: 5| Step: 8
Training loss: 0.16438952088356018
Validation loss: 1.5620915146284207

Epoch: 5| Step: 9
Training loss: 0.2201032191514969
Validation loss: 1.5660184621810913

Epoch: 5| Step: 10
Training loss: 0.48848769068717957
Validation loss: 1.554608093794956

Epoch: 414| Step: 0
Training loss: 0.22850897908210754
Validation loss: 1.5784587789607305

Epoch: 5| Step: 1
Training loss: 0.2512916624546051
Validation loss: 1.5743219339719383

Epoch: 5| Step: 2
Training loss: 0.3003676235675812
Validation loss: 1.5538767800536206

Epoch: 5| Step: 3
Training loss: 0.4168325960636139
Validation loss: 1.5904806057612102

Epoch: 5| Step: 4
Training loss: 0.1548963040113449
Validation loss: 1.5743444363276164

Epoch: 5| Step: 5
Training loss: 0.2611049711704254
Validation loss: 1.6039187241626043

Epoch: 5| Step: 6
Training loss: 0.2998708188533783
Validation loss: 1.5908036206358223

Epoch: 5| Step: 7
Training loss: 0.13667044043540955
Validation loss: 1.557508881374072

Epoch: 5| Step: 8
Training loss: 0.2838570475578308
Validation loss: 1.536922932952963

Epoch: 5| Step: 9
Training loss: 0.29919546842575073
Validation loss: 1.522790474276389

Epoch: 5| Step: 10
Training loss: 0.17935211956501007
Validation loss: 1.513087191889363

Epoch: 415| Step: 0
Training loss: 0.2558382749557495
Validation loss: 1.5162324328576364

Epoch: 5| Step: 1
Training loss: 0.23888731002807617
Validation loss: 1.4918565621940039

Epoch: 5| Step: 2
Training loss: 0.2069418877363205
Validation loss: 1.499863133635572

Epoch: 5| Step: 3
Training loss: 0.19245409965515137
Validation loss: 1.5137341791583645

Epoch: 5| Step: 4
Training loss: 0.15086764097213745
Validation loss: 1.523966811036551

Epoch: 5| Step: 5
Training loss: 0.24000759422779083
Validation loss: 1.5462432510109358

Epoch: 5| Step: 6
Training loss: 0.2324606478214264
Validation loss: 1.5670297299661944

Epoch: 5| Step: 7
Training loss: 0.12305714190006256
Validation loss: 1.5287739333286081

Epoch: 5| Step: 8
Training loss: 0.22903378307819366
Validation loss: 1.5647769140940841

Epoch: 5| Step: 9
Training loss: 0.3481234014034271
Validation loss: 1.556114496723298

Epoch: 5| Step: 10
Training loss: 0.29121437668800354
Validation loss: 1.5279048130076418

Epoch: 416| Step: 0
Training loss: 0.11576471477746964
Validation loss: 1.5427058076345792

Epoch: 5| Step: 1
Training loss: 0.11641909927129745
Validation loss: 1.5176695713432886

Epoch: 5| Step: 2
Training loss: 0.2653704285621643
Validation loss: 1.5191411690045429

Epoch: 5| Step: 3
Training loss: 0.2219332754611969
Validation loss: 1.5369697091399983

Epoch: 5| Step: 4
Training loss: 0.34724488854408264
Validation loss: 1.5296350140725412

Epoch: 5| Step: 5
Training loss: 0.19840385019779205
Validation loss: 1.5293210437220912

Epoch: 5| Step: 6
Training loss: 0.1943642795085907
Validation loss: 1.5425998433943717

Epoch: 5| Step: 7
Training loss: 0.2058907300233841
Validation loss: 1.5688777476228692

Epoch: 5| Step: 8
Training loss: 0.2695760130882263
Validation loss: 1.586996538664705

Epoch: 5| Step: 9
Training loss: 0.2325635850429535
Validation loss: 1.5939409450818134

Epoch: 5| Step: 10
Training loss: 0.35496434569358826
Validation loss: 1.6283483120702928

Epoch: 417| Step: 0
Training loss: 0.36681222915649414
Validation loss: 1.616276737182371

Epoch: 5| Step: 1
Training loss: 0.31352153420448303
Validation loss: 1.5774901477239465

Epoch: 5| Step: 2
Training loss: 0.23101849853992462
Validation loss: 1.559804634381366

Epoch: 5| Step: 3
Training loss: 0.11717180907726288
Validation loss: 1.569838245068827

Epoch: 5| Step: 4
Training loss: 0.23983874917030334
Validation loss: 1.5870241221561228

Epoch: 5| Step: 5
Training loss: 0.2218393087387085
Validation loss: 1.581641771460092

Epoch: 5| Step: 6
Training loss: 0.1985161006450653
Validation loss: 1.5722273677907965

Epoch: 5| Step: 7
Training loss: 0.19129735231399536
Validation loss: 1.5319545897104407

Epoch: 5| Step: 8
Training loss: 0.09921964257955551
Validation loss: 1.5388755670157812

Epoch: 5| Step: 9
Training loss: 0.42355090379714966
Validation loss: 1.5387801278022029

Epoch: 5| Step: 10
Training loss: 0.15329554677009583
Validation loss: 1.5241673915616927

Epoch: 418| Step: 0
Training loss: 0.11403600871562958
Validation loss: 1.5314707704769668

Epoch: 5| Step: 1
Training loss: 0.35156258940696716
Validation loss: 1.5169716124893518

Epoch: 5| Step: 2
Training loss: 0.22202153503894806
Validation loss: 1.5199724807534167

Epoch: 5| Step: 3
Training loss: 0.17520809173583984
Validation loss: 1.5161526190337313

Epoch: 5| Step: 4
Training loss: 0.12116231769323349
Validation loss: 1.5096119911439958

Epoch: 5| Step: 5
Training loss: 0.21667703986167908
Validation loss: 1.4980387623592089

Epoch: 5| Step: 6
Training loss: 0.2389109581708908
Validation loss: 1.5031973085095804

Epoch: 5| Step: 7
Training loss: 0.1519053727388382
Validation loss: 1.5237195632791007

Epoch: 5| Step: 8
Training loss: 0.20783177018165588
Validation loss: 1.5099981241328742

Epoch: 5| Step: 9
Training loss: 0.44959649443626404
Validation loss: 1.485820072953419

Epoch: 5| Step: 10
Training loss: 0.19427798688411713
Validation loss: 1.5020289318535918

Epoch: 419| Step: 0
Training loss: 0.20066595077514648
Validation loss: 1.4745437227269655

Epoch: 5| Step: 1
Training loss: 0.15141776204109192
Validation loss: 1.492800203702783

Epoch: 5| Step: 2
Training loss: 0.23641976714134216
Validation loss: 1.4795239715165989

Epoch: 5| Step: 3
Training loss: 0.35514363646507263
Validation loss: 1.4934246693888018

Epoch: 5| Step: 4
Training loss: 0.1480318009853363
Validation loss: 1.495242893054921

Epoch: 5| Step: 5
Training loss: 0.160043865442276
Validation loss: 1.489786458271806

Epoch: 5| Step: 6
Training loss: 0.20503833889961243
Validation loss: 1.516042455550163

Epoch: 5| Step: 7
Training loss: 0.4644123911857605
Validation loss: 1.499923615045445

Epoch: 5| Step: 8
Training loss: 0.18710118532180786
Validation loss: 1.5245927790159821

Epoch: 5| Step: 9
Training loss: 0.27260175347328186
Validation loss: 1.527550607599238

Epoch: 5| Step: 10
Training loss: 0.10202858597040176
Validation loss: 1.5225006329116

Epoch: 420| Step: 0
Training loss: 0.26500996947288513
Validation loss: 1.5252299231867636

Epoch: 5| Step: 1
Training loss: 0.2650650441646576
Validation loss: 1.5450682332438808

Epoch: 5| Step: 2
Training loss: 0.15006931126117706
Validation loss: 1.563191980443975

Epoch: 5| Step: 3
Training loss: 0.4146758019924164
Validation loss: 1.5457268338049612

Epoch: 5| Step: 4
Training loss: 0.18275673687458038
Validation loss: 1.5321333651901574

Epoch: 5| Step: 5
Training loss: 0.1276758760213852
Validation loss: 1.5629637997637513

Epoch: 5| Step: 6
Training loss: 0.2016446590423584
Validation loss: 1.5559304888530443

Epoch: 5| Step: 7
Training loss: 0.2752423882484436
Validation loss: 1.5395938504126765

Epoch: 5| Step: 8
Training loss: 0.20469769835472107
Validation loss: 1.536203061380694

Epoch: 5| Step: 9
Training loss: 0.14883849024772644
Validation loss: 1.5448093055396952

Epoch: 5| Step: 10
Training loss: 0.23296904563903809
Validation loss: 1.565114434047412

Epoch: 421| Step: 0
Training loss: 0.2568875849246979
Validation loss: 1.5598216159369356

Epoch: 5| Step: 1
Training loss: 0.14854122698307037
Validation loss: 1.581276770560972

Epoch: 5| Step: 2
Training loss: 0.18663635849952698
Validation loss: 1.6023738807247532

Epoch: 5| Step: 3
Training loss: 0.27302056550979614
Validation loss: 1.5805443615041754

Epoch: 5| Step: 4
Training loss: 0.32949313521385193
Validation loss: 1.588055427356433

Epoch: 5| Step: 5
Training loss: 0.2126494199037552
Validation loss: 1.5763751088931997

Epoch: 5| Step: 6
Training loss: 0.22697973251342773
Validation loss: 1.5276199886875768

Epoch: 5| Step: 7
Training loss: 0.2149123251438141
Validation loss: 1.5281821335515668

Epoch: 5| Step: 8
Training loss: 0.33204227685928345
Validation loss: 1.5277977848565707

Epoch: 5| Step: 9
Training loss: 0.12575729191303253
Validation loss: 1.5696640296648907

Epoch: 5| Step: 10
Training loss: 0.3525208830833435
Validation loss: 1.5733702618588683

Epoch: 422| Step: 0
Training loss: 0.263674259185791
Validation loss: 1.572934212223176

Epoch: 5| Step: 1
Training loss: 0.1560451090335846
Validation loss: 1.5596488727036344

Epoch: 5| Step: 2
Training loss: 0.16620616614818573
Validation loss: 1.5481874583869852

Epoch: 5| Step: 3
Training loss: 0.1309274137020111
Validation loss: 1.5305820831688501

Epoch: 5| Step: 4
Training loss: 0.18584445118904114
Validation loss: 1.5267588015525573

Epoch: 5| Step: 5
Training loss: 0.2656678259372711
Validation loss: 1.5480953070425219

Epoch: 5| Step: 6
Training loss: 0.43337592482566833
Validation loss: 1.5289102664557837

Epoch: 5| Step: 7
Training loss: 0.18548765778541565
Validation loss: 1.513524386190599

Epoch: 5| Step: 8
Training loss: 0.1728951781988144
Validation loss: 1.5257020868280882

Epoch: 5| Step: 9
Training loss: 0.23784410953521729
Validation loss: 1.5099132689096595

Epoch: 5| Step: 10
Training loss: 0.14984241127967834
Validation loss: 1.488244761702835

Epoch: 423| Step: 0
Training loss: 0.18442818522453308
Validation loss: 1.4997430892400845

Epoch: 5| Step: 1
Training loss: 0.3083206117153168
Validation loss: 1.5085842917042394

Epoch: 5| Step: 2
Training loss: 0.15076015889644623
Validation loss: 1.522382463178327

Epoch: 5| Step: 3
Training loss: 0.19560787081718445
Validation loss: 1.4998056504034227

Epoch: 5| Step: 4
Training loss: 0.25033825635910034
Validation loss: 1.4935895230180474

Epoch: 5| Step: 5
Training loss: 0.24974456429481506
Validation loss: 1.5032367398661952

Epoch: 5| Step: 6
Training loss: 0.1888277232646942
Validation loss: 1.4977740959454608

Epoch: 5| Step: 7
Training loss: 0.2201034128665924
Validation loss: 1.5093974144228044

Epoch: 5| Step: 8
Training loss: 0.1760558784008026
Validation loss: 1.5120293196811472

Epoch: 5| Step: 9
Training loss: 0.2941407859325409
Validation loss: 1.5371412333621775

Epoch: 5| Step: 10
Training loss: 0.23941074311733246
Validation loss: 1.4966515341112692

Epoch: 424| Step: 0
Training loss: 0.2464025914669037
Validation loss: 1.492899420440838

Epoch: 5| Step: 1
Training loss: 0.28970053791999817
Validation loss: 1.5079570585681545

Epoch: 5| Step: 2
Training loss: 0.20836141705513
Validation loss: 1.5298284151220833

Epoch: 5| Step: 3
Training loss: 0.20816507935523987
Validation loss: 1.5421903594847648

Epoch: 5| Step: 4
Training loss: 0.2227904498577118
Validation loss: 1.5214916813758113

Epoch: 5| Step: 5
Training loss: 0.21712246537208557
Validation loss: 1.5185747800334808

Epoch: 5| Step: 6
Training loss: 0.2838283181190491
Validation loss: 1.5417406981991184

Epoch: 5| Step: 7
Training loss: 0.19086554646492004
Validation loss: 1.5194193445226198

Epoch: 5| Step: 8
Training loss: 0.16781973838806152
Validation loss: 1.529088589452928

Epoch: 5| Step: 9
Training loss: 0.1673717200756073
Validation loss: 1.5187191706831737

Epoch: 5| Step: 10
Training loss: 0.1014159619808197
Validation loss: 1.5396915802391626

Epoch: 425| Step: 0
Training loss: 0.37706753611564636
Validation loss: 1.523667852083842

Epoch: 5| Step: 1
Training loss: 0.15523706376552582
Validation loss: 1.5322353557873798

Epoch: 5| Step: 2
Training loss: 0.24467413127422333
Validation loss: 1.549834635949904

Epoch: 5| Step: 3
Training loss: 0.10032021999359131
Validation loss: 1.5261822272372503

Epoch: 5| Step: 4
Training loss: 0.1672365814447403
Validation loss: 1.5351544631424772

Epoch: 5| Step: 5
Training loss: 0.1394447535276413
Validation loss: 1.5466762665779359

Epoch: 5| Step: 6
Training loss: 0.3536335527896881
Validation loss: 1.5350009786185397

Epoch: 5| Step: 7
Training loss: 0.22519652545452118
Validation loss: 1.531613097395948

Epoch: 5| Step: 8
Training loss: 0.3099551498889923
Validation loss: 1.5093997473357825

Epoch: 5| Step: 9
Training loss: 0.24033978581428528
Validation loss: 1.5168204884375296

Epoch: 5| Step: 10
Training loss: 0.16252127289772034
Validation loss: 1.5236613968367219

Epoch: 426| Step: 0
Training loss: 0.31948721408843994
Validation loss: 1.509285073126516

Epoch: 5| Step: 1
Training loss: 0.4237278401851654
Validation loss: 1.4948603324992682

Epoch: 5| Step: 2
Training loss: 0.20352160930633545
Validation loss: 1.5024173541735577

Epoch: 5| Step: 3
Training loss: 0.16187015175819397
Validation loss: 1.5102948873273787

Epoch: 5| Step: 4
Training loss: 0.16504015028476715
Validation loss: 1.5371528517815374

Epoch: 5| Step: 5
Training loss: 0.1477775275707245
Validation loss: 1.55451794849929

Epoch: 5| Step: 6
Training loss: 0.15371498465538025
Validation loss: 1.529348732322775

Epoch: 5| Step: 7
Training loss: 0.18244804441928864
Validation loss: 1.5371251516444708

Epoch: 5| Step: 8
Training loss: 0.2584060728549957
Validation loss: 1.5613124383393155

Epoch: 5| Step: 9
Training loss: 0.104792520403862
Validation loss: 1.5352127398214033

Epoch: 5| Step: 10
Training loss: 0.19052588939666748
Validation loss: 1.5299217726594658

Epoch: 427| Step: 0
Training loss: 0.19636116921901703
Validation loss: 1.5240913873077722

Epoch: 5| Step: 1
Training loss: 0.10657064616680145
Validation loss: 1.5325917223448395

Epoch: 5| Step: 2
Training loss: 0.24425312876701355
Validation loss: 1.5314017482983169

Epoch: 5| Step: 3
Training loss: 0.1973007619380951
Validation loss: 1.5505832459336968

Epoch: 5| Step: 4
Training loss: 0.15293104946613312
Validation loss: 1.5287101807132844

Epoch: 5| Step: 5
Training loss: 0.12353269755840302
Validation loss: 1.5320399563799623

Epoch: 5| Step: 6
Training loss: 0.3063364624977112
Validation loss: 1.5498103287912184

Epoch: 5| Step: 7
Training loss: 0.18714913725852966
Validation loss: 1.5172812977144796

Epoch: 5| Step: 8
Training loss: 0.29443225264549255
Validation loss: 1.5305894472265755

Epoch: 5| Step: 9
Training loss: 0.20215079188346863
Validation loss: 1.5093729637002433

Epoch: 5| Step: 10
Training loss: 0.30586326122283936
Validation loss: 1.5406522686763475

Epoch: 428| Step: 0
Training loss: 0.18164698779582977
Validation loss: 1.5056074896166403

Epoch: 5| Step: 1
Training loss: 0.32626453042030334
Validation loss: 1.5203127694386307

Epoch: 5| Step: 2
Training loss: 0.22786898910999298
Validation loss: 1.5248697791048276

Epoch: 5| Step: 3
Training loss: 0.23071320354938507
Validation loss: 1.4989083210627239

Epoch: 5| Step: 4
Training loss: 0.14589306712150574
Validation loss: 1.4627364707249466

Epoch: 5| Step: 5
Training loss: 0.1352197229862213
Validation loss: 1.4966517327934183

Epoch: 5| Step: 6
Training loss: 0.16147246956825256
Validation loss: 1.5091241816038727

Epoch: 5| Step: 7
Training loss: 0.19567713141441345
Validation loss: 1.5089599829848095

Epoch: 5| Step: 8
Training loss: 0.23994417488574982
Validation loss: 1.5066404291378555

Epoch: 5| Step: 9
Training loss: 0.14679507911205292
Validation loss: 1.526080491722271

Epoch: 5| Step: 10
Training loss: 0.33189019560813904
Validation loss: 1.552551463086118

Epoch: 429| Step: 0
Training loss: 0.1476440578699112
Validation loss: 1.5193145941662531

Epoch: 5| Step: 1
Training loss: 0.2834389805793762
Validation loss: 1.5401696069266206

Epoch: 5| Step: 2
Training loss: 0.12948191165924072
Validation loss: 1.5417844646720475

Epoch: 5| Step: 3
Training loss: 0.14772549271583557
Validation loss: 1.5389872584291684

Epoch: 5| Step: 4
Training loss: 0.3134665787220001
Validation loss: 1.5142507783828243

Epoch: 5| Step: 5
Training loss: 0.2586725056171417
Validation loss: 1.5126041968663533

Epoch: 5| Step: 6
Training loss: 0.14429537951946259
Validation loss: 1.500807326327088

Epoch: 5| Step: 7
Training loss: 0.40159550309181213
Validation loss: 1.499314086411589

Epoch: 5| Step: 8
Training loss: 0.13466700911521912
Validation loss: 1.4862084401551114

Epoch: 5| Step: 9
Training loss: 0.17708925902843475
Validation loss: 1.5020259887941423

Epoch: 5| Step: 10
Training loss: 0.16686168313026428
Validation loss: 1.521296916469451

Epoch: 430| Step: 0
Training loss: 0.25620540976524353
Validation loss: 1.5158399689582087

Epoch: 5| Step: 1
Training loss: 0.17963507771492004
Validation loss: 1.5082728478216356

Epoch: 5| Step: 2
Training loss: 0.24361197650432587
Validation loss: 1.4978230999362083

Epoch: 5| Step: 3
Training loss: 0.13155759871006012
Validation loss: 1.5139844033025927

Epoch: 5| Step: 4
Training loss: 0.2581380605697632
Validation loss: 1.4945500909641225

Epoch: 5| Step: 5
Training loss: 0.1869896650314331
Validation loss: 1.5179468021597913

Epoch: 5| Step: 6
Training loss: 0.3668040633201599
Validation loss: 1.5157130854104155

Epoch: 5| Step: 7
Training loss: 0.38422784209251404
Validation loss: 1.5229197330372308

Epoch: 5| Step: 8
Training loss: 0.16112066805362701
Validation loss: 1.5047891242529756

Epoch: 5| Step: 9
Training loss: 0.14901986718177795
Validation loss: 1.5198980762112526

Epoch: 5| Step: 10
Training loss: 0.26211899518966675
Validation loss: 1.543340588128695

Epoch: 431| Step: 0
Training loss: 0.13102465867996216
Validation loss: 1.552044624923378

Epoch: 5| Step: 1
Training loss: 0.12580955028533936
Validation loss: 1.570380860759366

Epoch: 5| Step: 2
Training loss: 0.2243167906999588
Validation loss: 1.5913460229032783

Epoch: 5| Step: 3
Training loss: 0.313265860080719
Validation loss: 1.5783439913103658

Epoch: 5| Step: 4
Training loss: 0.2210617959499359
Validation loss: 1.5893432491569108

Epoch: 5| Step: 5
Training loss: 0.3119469881057739
Validation loss: 1.5581411969277166

Epoch: 5| Step: 6
Training loss: 0.17207340896129608
Validation loss: 1.5618119675626037

Epoch: 5| Step: 7
Training loss: 0.23508314788341522
Validation loss: 1.5411211662395026

Epoch: 5| Step: 8
Training loss: 0.216866135597229
Validation loss: 1.503587697141914

Epoch: 5| Step: 9
Training loss: 0.20374684035778046
Validation loss: 1.517113172879783

Epoch: 5| Step: 10
Training loss: 0.4769754409790039
Validation loss: 1.5028562084321053

Epoch: 432| Step: 0
Training loss: 0.2170882672071457
Validation loss: 1.5042375313338412

Epoch: 5| Step: 1
Training loss: 0.2236078679561615
Validation loss: 1.4879374215679784

Epoch: 5| Step: 2
Training loss: 0.17319458723068237
Validation loss: 1.492513301551983

Epoch: 5| Step: 3
Training loss: 0.29075393080711365
Validation loss: 1.4880906112732426

Epoch: 5| Step: 4
Training loss: 0.3002700209617615
Validation loss: 1.446732569766301

Epoch: 5| Step: 5
Training loss: 0.2186414748430252
Validation loss: 1.4904938929824418

Epoch: 5| Step: 6
Training loss: 0.12199878692626953
Validation loss: 1.474100524379361

Epoch: 5| Step: 7
Training loss: 0.2873770594596863
Validation loss: 1.488790891503775

Epoch: 5| Step: 8
Training loss: 0.18019993603229523
Validation loss: 1.5046760292463406

Epoch: 5| Step: 9
Training loss: 0.15274585783481598
Validation loss: 1.4822087672448927

Epoch: 5| Step: 10
Training loss: 0.15536096692085266
Validation loss: 1.498185435930888

Epoch: 433| Step: 0
Training loss: 0.14901001751422882
Validation loss: 1.4880601988043836

Epoch: 5| Step: 1
Training loss: 0.2920413613319397
Validation loss: 1.4940062979216218

Epoch: 5| Step: 2
Training loss: 0.19561472535133362
Validation loss: 1.4833011165741952

Epoch: 5| Step: 3
Training loss: 0.1300373375415802
Validation loss: 1.4865945475075835

Epoch: 5| Step: 4
Training loss: 0.2923557460308075
Validation loss: 1.5219714205752137

Epoch: 5| Step: 5
Training loss: 0.20589163899421692
Validation loss: 1.5069580270398049

Epoch: 5| Step: 6
Training loss: 0.12351065874099731
Validation loss: 1.522731529769077

Epoch: 5| Step: 7
Training loss: 0.24923260509967804
Validation loss: 1.5090288074426754

Epoch: 5| Step: 8
Training loss: 0.1888810396194458
Validation loss: 1.5215962202318254

Epoch: 5| Step: 9
Training loss: 0.21670475602149963
Validation loss: 1.5285794170953895

Epoch: 5| Step: 10
Training loss: 0.1341388076543808
Validation loss: 1.5444443597588489

Epoch: 434| Step: 0
Training loss: 0.1035618782043457
Validation loss: 1.5403971197784587

Epoch: 5| Step: 1
Training loss: 0.1433836668729782
Validation loss: 1.5130124226693185

Epoch: 5| Step: 2
Training loss: 0.3776174485683441
Validation loss: 1.5263929379883634

Epoch: 5| Step: 3
Training loss: 0.14667607843875885
Validation loss: 1.5172880836712417

Epoch: 5| Step: 4
Training loss: 0.1478763222694397
Validation loss: 1.5367300151496806

Epoch: 5| Step: 5
Training loss: 0.21842126548290253
Validation loss: 1.528058716045913

Epoch: 5| Step: 6
Training loss: 0.2777705788612366
Validation loss: 1.5285002159815964

Epoch: 5| Step: 7
Training loss: 0.2361387312412262
Validation loss: 1.511243607408257

Epoch: 5| Step: 8
Training loss: 0.14460913836956024
Validation loss: 1.5090006512980307

Epoch: 5| Step: 9
Training loss: 0.1863328516483307
Validation loss: 1.5008465218287643

Epoch: 5| Step: 10
Training loss: 0.27627894282341003
Validation loss: 1.5274359205717682

Epoch: 435| Step: 0
Training loss: 0.44645553827285767
Validation loss: 1.5119246936613513

Epoch: 5| Step: 1
Training loss: 0.28149428963661194
Validation loss: 1.5339333447076942

Epoch: 5| Step: 2
Training loss: 0.17406466603279114
Validation loss: 1.5143885497123963

Epoch: 5| Step: 3
Training loss: 0.20212292671203613
Validation loss: 1.534492592657766

Epoch: 5| Step: 4
Training loss: 0.17321565747261047
Validation loss: 1.5016525753082768

Epoch: 5| Step: 5
Training loss: 0.15378765761852264
Validation loss: 1.5183501012863652

Epoch: 5| Step: 6
Training loss: 0.11499345302581787
Validation loss: 1.5299125307349748

Epoch: 5| Step: 7
Training loss: 0.1014392226934433
Validation loss: 1.5026530373481013

Epoch: 5| Step: 8
Training loss: 0.1893138289451599
Validation loss: 1.5246908997976651

Epoch: 5| Step: 9
Training loss: 0.2827830910682678
Validation loss: 1.5340520951055712

Epoch: 5| Step: 10
Training loss: 0.15663132071495056
Validation loss: 1.5107950625881073

Epoch: 436| Step: 0
Training loss: 0.380611777305603
Validation loss: 1.5151115373898578

Epoch: 5| Step: 1
Training loss: 0.11677143722772598
Validation loss: 1.5353353895166868

Epoch: 5| Step: 2
Training loss: 0.24956198036670685
Validation loss: 1.5205246710008191

Epoch: 5| Step: 3
Training loss: 0.18197757005691528
Validation loss: 1.532560089583038

Epoch: 5| Step: 4
Training loss: 0.2253446877002716
Validation loss: 1.5076920319628972

Epoch: 5| Step: 5
Training loss: 0.11928659677505493
Validation loss: 1.511824777049403

Epoch: 5| Step: 6
Training loss: 0.16133694350719452
Validation loss: 1.5141582694104923

Epoch: 5| Step: 7
Training loss: 0.2920840382575989
Validation loss: 1.519776858309264

Epoch: 5| Step: 8
Training loss: 0.16043534874916077
Validation loss: 1.5272356220470962

Epoch: 5| Step: 9
Training loss: 0.17129437625408173
Validation loss: 1.5405981143315632

Epoch: 5| Step: 10
Training loss: 0.19784365594387054
Validation loss: 1.5700049067056308

Epoch: 437| Step: 0
Training loss: 0.22802770137786865
Validation loss: 1.5713114174463416

Epoch: 5| Step: 1
Training loss: 0.13436904549598694
Validation loss: 1.5531943869847122

Epoch: 5| Step: 2
Training loss: 0.11578569561243057
Validation loss: 1.5439071629637031

Epoch: 5| Step: 3
Training loss: 0.17015327513217926
Validation loss: 1.5246782418220275

Epoch: 5| Step: 4
Training loss: 0.17007291316986084
Validation loss: 1.5425473695160241

Epoch: 5| Step: 5
Training loss: 0.1843850314617157
Validation loss: 1.5283095529002528

Epoch: 5| Step: 6
Training loss: 0.21295681595802307
Validation loss: 1.5243699794174523

Epoch: 5| Step: 7
Training loss: 0.3754282593727112
Validation loss: 1.4804758974300918

Epoch: 5| Step: 8
Training loss: 0.17261748015880585
Validation loss: 1.4743309277360157

Epoch: 5| Step: 9
Training loss: 0.19547638297080994
Validation loss: 1.4916861518736808

Epoch: 5| Step: 10
Training loss: 0.2949937582015991
Validation loss: 1.4944361922561482

Epoch: 438| Step: 0
Training loss: 0.14679498970508575
Validation loss: 1.477595466439442

Epoch: 5| Step: 1
Training loss: 0.14486335217952728
Validation loss: 1.4897682218141453

Epoch: 5| Step: 2
Training loss: 0.21395047008991241
Validation loss: 1.5184863318679154

Epoch: 5| Step: 3
Training loss: 0.25658413767814636
Validation loss: 1.4974630545544367

Epoch: 5| Step: 4
Training loss: 0.14622938632965088
Validation loss: 1.5140209992726643

Epoch: 5| Step: 5
Training loss: 0.14792315661907196
Validation loss: 1.4552797284177554

Epoch: 5| Step: 6
Training loss: 0.27074190974235535
Validation loss: 1.48351457811171

Epoch: 5| Step: 7
Training loss: 0.16678586602210999
Validation loss: 1.4697918955997755

Epoch: 5| Step: 8
Training loss: 0.13661213219165802
Validation loss: 1.4612392020481888

Epoch: 5| Step: 9
Training loss: 0.15746141970157623
Validation loss: 1.47693891679087

Epoch: 5| Step: 10
Training loss: 0.3919547498226166
Validation loss: 1.471629120970285

Epoch: 439| Step: 0
Training loss: 0.11909186840057373
Validation loss: 1.4907574538261659

Epoch: 5| Step: 1
Training loss: 0.3025382161140442
Validation loss: 1.486502984518646

Epoch: 5| Step: 2
Training loss: 0.12534740567207336
Validation loss: 1.4942742111862346

Epoch: 5| Step: 3
Training loss: 0.15377740561962128
Validation loss: 1.52250293249725

Epoch: 5| Step: 4
Training loss: 0.23573465645313263
Validation loss: 1.567744149956652

Epoch: 5| Step: 5
Training loss: 0.39217454195022583
Validation loss: 1.5826301805434688

Epoch: 5| Step: 6
Training loss: 0.1920299530029297
Validation loss: 1.5523655196671844

Epoch: 5| Step: 7
Training loss: 0.29314056038856506
Validation loss: 1.5105965316936534

Epoch: 5| Step: 8
Training loss: 0.12937667965888977
Validation loss: 1.500808008255497

Epoch: 5| Step: 9
Training loss: 0.3145238757133484
Validation loss: 1.4775279593724076

Epoch: 5| Step: 10
Training loss: 0.23440800607204437
Validation loss: 1.4998220166852396

Epoch: 440| Step: 0
Training loss: 0.17116110026836395
Validation loss: 1.487683279539949

Epoch: 5| Step: 1
Training loss: 0.24832265079021454
Validation loss: 1.4888128388312556

Epoch: 5| Step: 2
Training loss: 0.31485894322395325
Validation loss: 1.4457197605922658

Epoch: 5| Step: 3
Training loss: 0.32380443811416626
Validation loss: 1.4806047165265648

Epoch: 5| Step: 4
Training loss: 0.1373848170042038
Validation loss: 1.4849024780334965

Epoch: 5| Step: 5
Training loss: 0.16534097492694855
Validation loss: 1.49167811998757

Epoch: 5| Step: 6
Training loss: 0.2851041257381439
Validation loss: 1.4988784649038827

Epoch: 5| Step: 7
Training loss: 0.14662086963653564
Validation loss: 1.4935561751806608

Epoch: 5| Step: 8
Training loss: 0.1709451973438263
Validation loss: 1.4921136376678303

Epoch: 5| Step: 9
Training loss: 0.11628234386444092
Validation loss: 1.4908049170688917

Epoch: 5| Step: 10
Training loss: 0.11830639839172363
Validation loss: 1.456224855556283

Epoch: 441| Step: 0
Training loss: 0.17928779125213623
Validation loss: 1.490559607423762

Epoch: 5| Step: 1
Training loss: 0.15894202888011932
Validation loss: 1.4578252902594946

Epoch: 5| Step: 2
Training loss: 0.35582417249679565
Validation loss: 1.4678117716184227

Epoch: 5| Step: 3
Training loss: 0.10524597018957138
Validation loss: 1.4508811222609652

Epoch: 5| Step: 4
Training loss: 0.08175282180309296
Validation loss: 1.4532435786339544

Epoch: 5| Step: 5
Training loss: 0.16176359355449677
Validation loss: 1.444185955550081

Epoch: 5| Step: 6
Training loss: 0.2769906222820282
Validation loss: 1.4607734603266562

Epoch: 5| Step: 7
Training loss: 0.09628984332084656
Validation loss: 1.444533960793608

Epoch: 5| Step: 8
Training loss: 0.19333826005458832
Validation loss: 1.4645946448849094

Epoch: 5| Step: 9
Training loss: 0.11820513010025024
Validation loss: 1.47156076341547

Epoch: 5| Step: 10
Training loss: 0.2300746589899063
Validation loss: 1.4810150586148745

Epoch: 442| Step: 0
Training loss: 0.23554489016532898
Validation loss: 1.4533246306962864

Epoch: 5| Step: 1
Training loss: 0.1719680279493332
Validation loss: 1.4680761137316305

Epoch: 5| Step: 2
Training loss: 0.35394009947776794
Validation loss: 1.469504201284019

Epoch: 5| Step: 3
Training loss: 0.13837842643260956
Validation loss: 1.4612665907029183

Epoch: 5| Step: 4
Training loss: 0.2904430627822876
Validation loss: 1.4752341316592308

Epoch: 5| Step: 5
Training loss: 0.18578697741031647
Validation loss: 1.4697981778011526

Epoch: 5| Step: 6
Training loss: 0.1046755313873291
Validation loss: 1.4888757967179822

Epoch: 5| Step: 7
Training loss: 0.14306870102882385
Validation loss: 1.4770103808372252

Epoch: 5| Step: 8
Training loss: 0.10139405727386475
Validation loss: 1.4509462054057787

Epoch: 5| Step: 9
Training loss: 0.08161236345767975
Validation loss: 1.4951201177412463

Epoch: 5| Step: 10
Training loss: 0.13524281978607178
Validation loss: 1.4872458839929232

Epoch: 443| Step: 0
Training loss: 0.12229307740926743
Validation loss: 1.4915475281335975

Epoch: 5| Step: 1
Training loss: 0.16667112708091736
Validation loss: 1.5051083449394471

Epoch: 5| Step: 2
Training loss: 0.12515772879123688
Validation loss: 1.4740984362940635

Epoch: 5| Step: 3
Training loss: 0.16783903539180756
Validation loss: 1.4685083576427993

Epoch: 5| Step: 4
Training loss: 0.1418648511171341
Validation loss: 1.4549905843632196

Epoch: 5| Step: 5
Training loss: 0.2732279300689697
Validation loss: 1.4656202088120163

Epoch: 5| Step: 6
Training loss: 0.27824151515960693
Validation loss: 1.483693871446835

Epoch: 5| Step: 7
Training loss: 0.2175397425889969
Validation loss: 1.4933430796028466

Epoch: 5| Step: 8
Training loss: 0.13965478539466858
Validation loss: 1.4808006683985393

Epoch: 5| Step: 9
Training loss: 0.11897802352905273
Validation loss: 1.473107321287996

Epoch: 5| Step: 10
Training loss: 0.15280824899673462
Validation loss: 1.474648416683238

Epoch: 444| Step: 0
Training loss: 0.11853212118148804
Validation loss: 1.4606864977908391

Epoch: 5| Step: 1
Training loss: 0.15015153586864471
Validation loss: 1.4671424088939544

Epoch: 5| Step: 2
Training loss: 0.23273363709449768
Validation loss: 1.4561686233807636

Epoch: 5| Step: 3
Training loss: 0.16457216441631317
Validation loss: 1.448004679013324

Epoch: 5| Step: 4
Training loss: 0.14117327332496643
Validation loss: 1.444034207251764

Epoch: 5| Step: 5
Training loss: 0.29294928908348083
Validation loss: 1.4279592761429407

Epoch: 5| Step: 6
Training loss: 0.3175756335258484
Validation loss: 1.4488640997999458

Epoch: 5| Step: 7
Training loss: 0.1506270468235016
Validation loss: 1.4199673245030064

Epoch: 5| Step: 8
Training loss: 0.12206928431987762
Validation loss: 1.4457950271585935

Epoch: 5| Step: 9
Training loss: 0.07261522114276886
Validation loss: 1.457838519926994

Epoch: 5| Step: 10
Training loss: 0.24710044264793396
Validation loss: 1.4445937275886536

Epoch: 445| Step: 0
Training loss: 0.1798061728477478
Validation loss: 1.4709401694677209

Epoch: 5| Step: 1
Training loss: 0.29352617263793945
Validation loss: 1.4800865573267783

Epoch: 5| Step: 2
Training loss: 0.4179738163948059
Validation loss: 1.4751182602297874

Epoch: 5| Step: 3
Training loss: 0.1194252222776413
Validation loss: 1.4819202705096173

Epoch: 5| Step: 4
Training loss: 0.13648530840873718
Validation loss: 1.5316836949317687

Epoch: 5| Step: 5
Training loss: 0.16637864708900452
Validation loss: 1.5347293153885873

Epoch: 5| Step: 6
Training loss: 0.13888120651245117
Validation loss: 1.501045411632907

Epoch: 5| Step: 7
Training loss: 0.1484808325767517
Validation loss: 1.4745837770482546

Epoch: 5| Step: 8
Training loss: 0.12228018045425415
Validation loss: 1.4957729007608147

Epoch: 5| Step: 9
Training loss: 0.1262357234954834
Validation loss: 1.469836788792764

Epoch: 5| Step: 10
Training loss: 0.1519930511713028
Validation loss: 1.4832489490509033

Epoch: 446| Step: 0
Training loss: 0.1763177514076233
Validation loss: 1.466803200783268

Epoch: 5| Step: 1
Training loss: 0.20101070404052734
Validation loss: 1.4994031870236961

Epoch: 5| Step: 2
Training loss: 0.1515781581401825
Validation loss: 1.5207517993065618

Epoch: 5| Step: 3
Training loss: 0.3079361617565155
Validation loss: 1.5244444352324291

Epoch: 5| Step: 4
Training loss: 0.183429554104805
Validation loss: 1.559215300826616

Epoch: 5| Step: 5
Training loss: 0.17695961892604828
Validation loss: 1.5186253580995785

Epoch: 5| Step: 6
Training loss: 0.1023760586977005
Validation loss: 1.501759768814169

Epoch: 5| Step: 7
Training loss: 0.17688652873039246
Validation loss: 1.5017287385079168

Epoch: 5| Step: 8
Training loss: 0.17780598998069763
Validation loss: 1.5171430521113898

Epoch: 5| Step: 9
Training loss: 0.20555663108825684
Validation loss: 1.4988075328129593

Epoch: 5| Step: 10
Training loss: 0.23800916969776154
Validation loss: 1.5108254801842473

Epoch: 447| Step: 0
Training loss: 0.11512725055217743
Validation loss: 1.4833266414621824

Epoch: 5| Step: 1
Training loss: 0.1715358942747116
Validation loss: 1.4972602577619656

Epoch: 5| Step: 2
Training loss: 0.12335796654224396
Validation loss: 1.5246204599257438

Epoch: 5| Step: 3
Training loss: 0.07468798756599426
Validation loss: 1.473356448194032

Epoch: 5| Step: 4
Training loss: 0.1557987928390503
Validation loss: 1.491785781357878

Epoch: 5| Step: 5
Training loss: 0.3043481707572937
Validation loss: 1.4899452309454642

Epoch: 5| Step: 6
Training loss: 0.20220765471458435
Validation loss: 1.5110461840065577

Epoch: 5| Step: 7
Training loss: 0.11764649301767349
Validation loss: 1.4777488439313826

Epoch: 5| Step: 8
Training loss: 0.32319504022598267
Validation loss: 1.5165197387818368

Epoch: 5| Step: 9
Training loss: 0.17688056826591492
Validation loss: 1.5306254074137697

Epoch: 5| Step: 10
Training loss: 0.1819721907377243
Validation loss: 1.5204248556526758

Epoch: 448| Step: 0
Training loss: 0.12533777952194214
Validation loss: 1.4861373875730781

Epoch: 5| Step: 1
Training loss: 0.34542030096054077
Validation loss: 1.502671718597412

Epoch: 5| Step: 2
Training loss: 0.1245935782790184
Validation loss: 1.4876350215686265

Epoch: 5| Step: 3
Training loss: 0.22630739212036133
Validation loss: 1.4885123455396263

Epoch: 5| Step: 4
Training loss: 0.13802561163902283
Validation loss: 1.4973981867554367

Epoch: 5| Step: 5
Training loss: 0.13547372817993164
Validation loss: 1.4939777184558172

Epoch: 5| Step: 6
Training loss: 0.17320235073566437
Validation loss: 1.4632880187803698

Epoch: 5| Step: 7
Training loss: 0.13037720322608948
Validation loss: 1.4657493637454124

Epoch: 5| Step: 8
Training loss: 0.21721656620502472
Validation loss: 1.455365196351082

Epoch: 5| Step: 9
Training loss: 0.2434251755475998
Validation loss: 1.4531863306158332

Epoch: 5| Step: 10
Training loss: 0.15112526714801788
Validation loss: 1.4913531420051411

Epoch: 449| Step: 0
Training loss: 0.2492014467716217
Validation loss: 1.484183088425667

Epoch: 5| Step: 1
Training loss: 0.17732250690460205
Validation loss: 1.4744614644717144

Epoch: 5| Step: 2
Training loss: 0.28558269143104553
Validation loss: 1.47393935982899

Epoch: 5| Step: 3
Training loss: 0.15267837047576904
Validation loss: 1.475493469545918

Epoch: 5| Step: 4
Training loss: 0.20200622081756592
Validation loss: 1.4695646019392117

Epoch: 5| Step: 5
Training loss: 0.28399085998535156
Validation loss: 1.4954685632900526

Epoch: 5| Step: 6
Training loss: 0.15356026589870453
Validation loss: 1.4879023669868388

Epoch: 5| Step: 7
Training loss: 0.14539307355880737
Validation loss: 1.4945350539299749

Epoch: 5| Step: 8
Training loss: 0.15634962916374207
Validation loss: 1.4860574186489146

Epoch: 5| Step: 9
Training loss: 0.2067524492740631
Validation loss: 1.4841989970976306

Epoch: 5| Step: 10
Training loss: 0.12153159826993942
Validation loss: 1.4619971500929965

Epoch: 450| Step: 0
Training loss: 0.12828631699085236
Validation loss: 1.46211193325699

Epoch: 5| Step: 1
Training loss: 0.13367429375648499
Validation loss: 1.4640404665341942

Epoch: 5| Step: 2
Training loss: 0.06762047857046127
Validation loss: 1.4729686962660922

Epoch: 5| Step: 3
Training loss: 0.3445753753185272
Validation loss: 1.5136124395555066

Epoch: 5| Step: 4
Training loss: 0.3497771620750427
Validation loss: 1.4958472392892326

Epoch: 5| Step: 5
Training loss: 0.0922837108373642
Validation loss: 1.5033151616332352

Epoch: 5| Step: 6
Training loss: 0.1352514773607254
Validation loss: 1.4984802020493375

Epoch: 5| Step: 7
Training loss: 0.16003085672855377
Validation loss: 1.4923204183578491

Epoch: 5| Step: 8
Training loss: 0.14141201972961426
Validation loss: 1.5069975442783807

Epoch: 5| Step: 9
Training loss: 0.12174298614263535
Validation loss: 1.502961644562342

Epoch: 5| Step: 10
Training loss: 0.26499122381210327
Validation loss: 1.5327791328071265

Epoch: 451| Step: 0
Training loss: 0.1272980272769928
Validation loss: 1.5102001761877408

Epoch: 5| Step: 1
Training loss: 0.1501370072364807
Validation loss: 1.5074580702730405

Epoch: 5| Step: 2
Training loss: 0.1633434146642685
Validation loss: 1.5004598838026806

Epoch: 5| Step: 3
Training loss: 0.1608884036540985
Validation loss: 1.4833335004827028

Epoch: 5| Step: 4
Training loss: 0.14203646779060364
Validation loss: 1.5051939333638837

Epoch: 5| Step: 5
Training loss: 0.20328132808208466
Validation loss: 1.4859873389685025

Epoch: 5| Step: 6
Training loss: 0.1922304928302765
Validation loss: 1.4967466579970492

Epoch: 5| Step: 7
Training loss: 0.3638431429862976
Validation loss: 1.4807905407362087

Epoch: 5| Step: 8
Training loss: 0.16517102718353271
Validation loss: 1.4934690306263585

Epoch: 5| Step: 9
Training loss: 0.1488839089870453
Validation loss: 1.5045115742632138

Epoch: 5| Step: 10
Training loss: 0.24711167812347412
Validation loss: 1.5411673694528558

Epoch: 452| Step: 0
Training loss: 0.2422657310962677
Validation loss: 1.54191001384489

Epoch: 5| Step: 1
Training loss: 0.1896439790725708
Validation loss: 1.5281148085030176

Epoch: 5| Step: 2
Training loss: 0.22026380896568298
Validation loss: 1.5291012974195584

Epoch: 5| Step: 3
Training loss: 0.1667928397655487
Validation loss: 1.4858748464174167

Epoch: 5| Step: 4
Training loss: 0.127131849527359
Validation loss: 1.4541316269546427

Epoch: 5| Step: 5
Training loss: 0.2233908623456955
Validation loss: 1.456063050095753

Epoch: 5| Step: 6
Training loss: 0.17138104140758514
Validation loss: 1.50424527096492

Epoch: 5| Step: 7
Training loss: 0.22046709060668945
Validation loss: 1.4885904929971183

Epoch: 5| Step: 8
Training loss: 0.37018758058547974
Validation loss: 1.4874391965968634

Epoch: 5| Step: 9
Training loss: 0.28340938687324524
Validation loss: 1.494142013211404

Epoch: 5| Step: 10
Training loss: 0.20614288747310638
Validation loss: 1.5149588020898963

Epoch: 453| Step: 0
Training loss: 0.1112428531050682
Validation loss: 1.5084946681094427

Epoch: 5| Step: 1
Training loss: 0.25005826354026794
Validation loss: 1.553740095066768

Epoch: 5| Step: 2
Training loss: 0.1679791659116745
Validation loss: 1.6009332838878836

Epoch: 5| Step: 3
Training loss: 0.13794808089733124
Validation loss: 1.5638239460606729

Epoch: 5| Step: 4
Training loss: 0.19037194550037384
Validation loss: 1.5560188678003126

Epoch: 5| Step: 5
Training loss: 0.31528282165527344
Validation loss: 1.5450879860949773

Epoch: 5| Step: 6
Training loss: 0.20127327740192413
Validation loss: 1.537908959132369

Epoch: 5| Step: 7
Training loss: 0.20225736498832703
Validation loss: 1.516523653461087

Epoch: 5| Step: 8
Training loss: 0.2525698244571686
Validation loss: 1.5026708059413458

Epoch: 5| Step: 9
Training loss: 0.23446066677570343
Validation loss: 1.4876631882882887

Epoch: 5| Step: 10
Training loss: 0.1330692321062088
Validation loss: 1.5006707041494307

Epoch: 454| Step: 0
Training loss: 0.14716574549674988
Validation loss: 1.4968588993113527

Epoch: 5| Step: 1
Training loss: 0.2646976709365845
Validation loss: 1.5024424881063483

Epoch: 5| Step: 2
Training loss: 0.12380611896514893
Validation loss: 1.502622837661415

Epoch: 5| Step: 3
Training loss: 0.1622844934463501
Validation loss: 1.5165671917699999

Epoch: 5| Step: 4
Training loss: 0.10047134011983871
Validation loss: 1.5148078933838875

Epoch: 5| Step: 5
Training loss: 0.169520303606987
Validation loss: 1.5247587068106538

Epoch: 5| Step: 6
Training loss: 0.47542262077331543
Validation loss: 1.5200920681799612

Epoch: 5| Step: 7
Training loss: 0.15277257561683655
Validation loss: 1.508818466176269

Epoch: 5| Step: 8
Training loss: 0.1443730592727661
Validation loss: 1.5081376388508787

Epoch: 5| Step: 9
Training loss: 0.16845473647117615
Validation loss: 1.4949536362001974

Epoch: 5| Step: 10
Training loss: 0.10960521548986435
Validation loss: 1.5205497792972031

Epoch: 455| Step: 0
Training loss: 0.2235078364610672
Validation loss: 1.522008160109161

Epoch: 5| Step: 1
Training loss: 0.165204718708992
Validation loss: 1.5105466868287774

Epoch: 5| Step: 2
Training loss: 0.24996161460876465
Validation loss: 1.5247683871176936

Epoch: 5| Step: 3
Training loss: 0.283593088388443
Validation loss: 1.5106079168217157

Epoch: 5| Step: 4
Training loss: 0.28165069222450256
Validation loss: 1.4692259065566524

Epoch: 5| Step: 5
Training loss: 0.11312613636255264
Validation loss: 1.4644974841866443

Epoch: 5| Step: 6
Training loss: 0.17534133791923523
Validation loss: 1.5012255714785667

Epoch: 5| Step: 7
Training loss: 0.15443046391010284
Validation loss: 1.4964484014818746

Epoch: 5| Step: 8
Training loss: 0.21732163429260254
Validation loss: 1.545438894661524

Epoch: 5| Step: 9
Training loss: 0.2057957947254181
Validation loss: 1.5198797807898572

Epoch: 5| Step: 10
Training loss: 0.1537044793367386
Validation loss: 1.4655484627651911

Epoch: 456| Step: 0
Training loss: 0.25696656107902527
Validation loss: 1.4635611400809339

Epoch: 5| Step: 1
Training loss: 0.16211944818496704
Validation loss: 1.4770727516502462

Epoch: 5| Step: 2
Training loss: 0.20767828822135925
Validation loss: 1.487821682806938

Epoch: 5| Step: 3
Training loss: 0.16734157502651215
Validation loss: 1.4641082350925734

Epoch: 5| Step: 4
Training loss: 0.10806410014629364
Validation loss: 1.4935495891878683

Epoch: 5| Step: 5
Training loss: 0.1100657731294632
Validation loss: 1.4891132385500017

Epoch: 5| Step: 6
Training loss: 0.17541013658046722
Validation loss: 1.506743606700692

Epoch: 5| Step: 7
Training loss: 0.10350992530584335
Validation loss: 1.4999755262046732

Epoch: 5| Step: 8
Training loss: 0.16125836968421936
Validation loss: 1.5394691421139626

Epoch: 5| Step: 9
Training loss: 0.19581200182437897
Validation loss: 1.5115165364357732

Epoch: 5| Step: 10
Training loss: 0.25861117243766785
Validation loss: 1.524001750894772

Epoch: 457| Step: 0
Training loss: 0.12684229016304016
Validation loss: 1.5495690850801365

Epoch: 5| Step: 1
Training loss: 0.22694997489452362
Validation loss: 1.5285215050943437

Epoch: 5| Step: 2
Training loss: 0.07952322065830231
Validation loss: 1.5338581787642611

Epoch: 5| Step: 3
Training loss: 0.1595323383808136
Validation loss: 1.5057110965892833

Epoch: 5| Step: 4
Training loss: 0.32555311918258667
Validation loss: 1.5072592381508119

Epoch: 5| Step: 5
Training loss: 0.15060631930828094
Validation loss: 1.5379654630537956

Epoch: 5| Step: 6
Training loss: 0.184569850564003
Validation loss: 1.5223601518138763

Epoch: 5| Step: 7
Training loss: 0.15183201432228088
Validation loss: 1.5478135885730866

Epoch: 5| Step: 8
Training loss: 0.10613210499286652
Validation loss: 1.506780703862508

Epoch: 5| Step: 9
Training loss: 0.1880439966917038
Validation loss: 1.5246147263434626

Epoch: 5| Step: 10
Training loss: 0.13981282711029053
Validation loss: 1.5144606700507544

Epoch: 458| Step: 0
Training loss: 0.14642536640167236
Validation loss: 1.4818068935025124

Epoch: 5| Step: 1
Training loss: 0.1676623374223709
Validation loss: 1.4818078548677507

Epoch: 5| Step: 2
Training loss: 0.19002529978752136
Validation loss: 1.482725433124009

Epoch: 5| Step: 3
Training loss: 0.16102571785449982
Validation loss: 1.485583032331159

Epoch: 5| Step: 4
Training loss: 0.22771663963794708
Validation loss: 1.492117610028995

Epoch: 5| Step: 5
Training loss: 0.14693260192871094
Validation loss: 1.4871404158171786

Epoch: 5| Step: 6
Training loss: 0.18780648708343506
Validation loss: 1.49922687456172

Epoch: 5| Step: 7
Training loss: 0.258198082447052
Validation loss: 1.49118588688553

Epoch: 5| Step: 8
Training loss: 0.37401437759399414
Validation loss: 1.5047269944221742

Epoch: 5| Step: 9
Training loss: 0.15581700205802917
Validation loss: 1.485433296490741

Epoch: 5| Step: 10
Training loss: 0.15498724579811096
Validation loss: 1.4596533397192597

Epoch: 459| Step: 0
Training loss: 0.10329242795705795
Validation loss: 1.4747242863460253

Epoch: 5| Step: 1
Training loss: 0.10573054850101471
Validation loss: 1.457154135550222

Epoch: 5| Step: 2
Training loss: 0.3129245638847351
Validation loss: 1.4671861381940945

Epoch: 5| Step: 3
Training loss: 0.20800046622753143
Validation loss: 1.4703469276428223

Epoch: 5| Step: 4
Training loss: 0.09026341140270233
Validation loss: 1.46016570573212

Epoch: 5| Step: 5
Training loss: 0.24984046816825867
Validation loss: 1.481166244834982

Epoch: 5| Step: 6
Training loss: 0.15103432536125183
Validation loss: 1.4571880396976267

Epoch: 5| Step: 7
Training loss: 0.13689155876636505
Validation loss: 1.4713605783318962

Epoch: 5| Step: 8
Training loss: 0.13336852192878723
Validation loss: 1.4541474837128834

Epoch: 5| Step: 9
Training loss: 0.18432800471782684
Validation loss: 1.424865170191693

Epoch: 5| Step: 10
Training loss: 0.14372341334819794
Validation loss: 1.4240035895378358

Epoch: 460| Step: 0
Training loss: 0.1239885687828064
Validation loss: 1.4243411210275465

Epoch: 5| Step: 1
Training loss: 0.17072197794914246
Validation loss: 1.4435400014282556

Epoch: 5| Step: 2
Training loss: 0.1296514868736267
Validation loss: 1.4732957911747757

Epoch: 5| Step: 3
Training loss: 0.16478180885314941
Validation loss: 1.4718541022269958

Epoch: 5| Step: 4
Training loss: 0.08994798362255096
Validation loss: 1.4964350795233121

Epoch: 5| Step: 5
Training loss: 0.12826092541217804
Validation loss: 1.5183664573136197

Epoch: 5| Step: 6
Training loss: 0.0998273491859436
Validation loss: 1.5022264180644866

Epoch: 5| Step: 7
Training loss: 0.253317654132843
Validation loss: 1.5511808638931603

Epoch: 5| Step: 8
Training loss: 0.20394869148731232
Validation loss: 1.5161906660244029

Epoch: 5| Step: 9
Training loss: 0.18570813536643982
Validation loss: 1.5327486504790604

Epoch: 5| Step: 10
Training loss: 0.14953505992889404
Validation loss: 1.5060408653751496

Epoch: 461| Step: 0
Training loss: 0.15874285995960236
Validation loss: 1.5135687294826712

Epoch: 5| Step: 1
Training loss: 0.17755797505378723
Validation loss: 1.5037451328769806

Epoch: 5| Step: 2
Training loss: 0.12640734016895294
Validation loss: 1.5115899501308319

Epoch: 5| Step: 3
Training loss: 0.12240217626094818
Validation loss: 1.4764785471782889

Epoch: 5| Step: 4
Training loss: 0.11285483837127686
Validation loss: 1.4908010267442273

Epoch: 5| Step: 5
Training loss: 0.11226610839366913
Validation loss: 1.4881307181491648

Epoch: 5| Step: 6
Training loss: 0.1586204171180725
Validation loss: 1.4919956781530892

Epoch: 5| Step: 7
Training loss: 0.4045214056968689
Validation loss: 1.5116122409861574

Epoch: 5| Step: 8
Training loss: 0.14113278687000275
Validation loss: 1.5040004150841826

Epoch: 5| Step: 9
Training loss: 0.27397042512893677
Validation loss: 1.5180093562731178

Epoch: 5| Step: 10
Training loss: 0.1501549482345581
Validation loss: 1.4967139382516184

Epoch: 462| Step: 0
Training loss: 0.2188229262828827
Validation loss: 1.5022779715958463

Epoch: 5| Step: 1
Training loss: 0.10053245723247528
Validation loss: 1.488896373779543

Epoch: 5| Step: 2
Training loss: 0.3108806014060974
Validation loss: 1.5238053721766318

Epoch: 5| Step: 3
Training loss: 0.11325909197330475
Validation loss: 1.5100583863514725

Epoch: 5| Step: 4
Training loss: 0.1591123640537262
Validation loss: 1.5014909185389036

Epoch: 5| Step: 5
Training loss: 0.1539422571659088
Validation loss: 1.5029070108167586

Epoch: 5| Step: 6
Training loss: 0.13832978904247284
Validation loss: 1.4979692171978694

Epoch: 5| Step: 7
Training loss: 0.10744254291057587
Validation loss: 1.4950820951051609

Epoch: 5| Step: 8
Training loss: 0.13559454679489136
Validation loss: 1.4881032346397318

Epoch: 5| Step: 9
Training loss: 0.17372460663318634
Validation loss: 1.4712711867465769

Epoch: 5| Step: 10
Training loss: 0.14392533898353577
Validation loss: 1.473234979055261

Epoch: 463| Step: 0
Training loss: 0.14478924870491028
Validation loss: 1.4705412234029462

Epoch: 5| Step: 1
Training loss: 0.09110947698354721
Validation loss: 1.4522400338162658

Epoch: 5| Step: 2
Training loss: 0.2544495165348053
Validation loss: 1.5053606481962307

Epoch: 5| Step: 3
Training loss: 0.09444955736398697
Validation loss: 1.5066853877036803

Epoch: 5| Step: 4
Training loss: 0.26632019877433777
Validation loss: 1.50487829408338

Epoch: 5| Step: 5
Training loss: 0.1757124662399292
Validation loss: 1.5119354128837585

Epoch: 5| Step: 6
Training loss: 0.09833045303821564
Validation loss: 1.520728454794935

Epoch: 5| Step: 7
Training loss: 0.16757076978683472
Validation loss: 1.516069737813806

Epoch: 5| Step: 8
Training loss: 0.11890389770269394
Validation loss: 1.5077224098226076

Epoch: 5| Step: 9
Training loss: 0.13400094211101532
Validation loss: 1.4935858288118917

Epoch: 5| Step: 10
Training loss: 0.22886784374713898
Validation loss: 1.5093797022296536

Epoch: 464| Step: 0
Training loss: 0.09024298936128616
Validation loss: 1.4540056208128571

Epoch: 5| Step: 1
Training loss: 0.13488176465034485
Validation loss: 1.4762954391458982

Epoch: 5| Step: 2
Training loss: 0.32618317008018494
Validation loss: 1.455397036767775

Epoch: 5| Step: 3
Training loss: 0.15695162117481232
Validation loss: 1.4692007187874085

Epoch: 5| Step: 4
Training loss: 0.16012994945049286
Validation loss: 1.4640395513144873

Epoch: 5| Step: 5
Training loss: 0.10925769805908203
Validation loss: 1.4934530642724806

Epoch: 5| Step: 6
Training loss: 0.10468865931034088
Validation loss: 1.4657394527107157

Epoch: 5| Step: 7
Training loss: 0.23186926543712616
Validation loss: 1.4863433735345

Epoch: 5| Step: 8
Training loss: 0.12095136940479279
Validation loss: 1.4704667342606412

Epoch: 5| Step: 9
Training loss: 0.14755071699619293
Validation loss: 1.4883370514838927

Epoch: 5| Step: 10
Training loss: 0.1433907449245453
Validation loss: 1.4794901840148433

Epoch: 465| Step: 0
Training loss: 0.15911151468753815
Validation loss: 1.477395349933255

Epoch: 5| Step: 1
Training loss: 0.23996107280254364
Validation loss: 1.4686744366922686

Epoch: 5| Step: 2
Training loss: 0.2457459270954132
Validation loss: 1.4900977752541984

Epoch: 5| Step: 3
Training loss: 0.12863031029701233
Validation loss: 1.488029859399283

Epoch: 5| Step: 4
Training loss: 0.11571525037288666
Validation loss: 1.4651145172375504

Epoch: 5| Step: 5
Training loss: 0.1622997224330902
Validation loss: 1.478855800885026

Epoch: 5| Step: 6
Training loss: 0.18505313992500305
Validation loss: 1.4511371671512563

Epoch: 5| Step: 7
Training loss: 0.11559903621673584
Validation loss: 1.476602312057249

Epoch: 5| Step: 8
Training loss: 0.1775493174791336
Validation loss: 1.4810023025799823

Epoch: 5| Step: 9
Training loss: 0.14084622263908386
Validation loss: 1.4622184409890124

Epoch: 5| Step: 10
Training loss: 0.17091597616672516
Validation loss: 1.472028483626663

Epoch: 466| Step: 0
Training loss: 0.08392927050590515
Validation loss: 1.485868215560913

Epoch: 5| Step: 1
Training loss: 0.16138455271720886
Validation loss: 1.4690046746243712

Epoch: 5| Step: 2
Training loss: 0.33250778913497925
Validation loss: 1.471316619585919

Epoch: 5| Step: 3
Training loss: 0.11894140392541885
Validation loss: 1.5079586005979968

Epoch: 5| Step: 4
Training loss: 0.15038536489009857
Validation loss: 1.4812519268323017

Epoch: 5| Step: 5
Training loss: 0.13244235515594482
Validation loss: 1.4761569141059794

Epoch: 5| Step: 6
Training loss: 0.21037521958351135
Validation loss: 1.4476877233033538

Epoch: 5| Step: 7
Training loss: 0.17859891057014465
Validation loss: 1.4797225242019982

Epoch: 5| Step: 8
Training loss: 0.14824825525283813
Validation loss: 1.4598557743974911

Epoch: 5| Step: 9
Training loss: 0.09094120562076569
Validation loss: 1.46933029800333

Epoch: 5| Step: 10
Training loss: 0.11545401066541672
Validation loss: 1.4870993911579091

Epoch: 467| Step: 0
Training loss: 0.09767919778823853
Validation loss: 1.4638462681924143

Epoch: 5| Step: 1
Training loss: 0.10952337831258774
Validation loss: 1.472157537296254

Epoch: 5| Step: 2
Training loss: 0.0991663783788681
Validation loss: 1.501659550974446

Epoch: 5| Step: 3
Training loss: 0.29452595114707947
Validation loss: 1.4896596093331613

Epoch: 5| Step: 4
Training loss: 0.1002746969461441
Validation loss: 1.5173503083567466

Epoch: 5| Step: 5
Training loss: 0.15456633269786835
Validation loss: 1.494761170879487

Epoch: 5| Step: 6
Training loss: 0.09572124481201172
Validation loss: 1.4927735931129866

Epoch: 5| Step: 7
Training loss: 0.26261094212532043
Validation loss: 1.4975186624834615

Epoch: 5| Step: 8
Training loss: 0.30363136529922485
Validation loss: 1.4942519863446553

Epoch: 5| Step: 9
Training loss: 0.094912089407444
Validation loss: 1.507939834748545

Epoch: 5| Step: 10
Training loss: 0.14927150309085846
Validation loss: 1.5027321948800036

Epoch: 468| Step: 0
Training loss: 0.14354239404201508
Validation loss: 1.5407008624845935

Epoch: 5| Step: 1
Training loss: 0.13998155295848846
Validation loss: 1.5619379820362214

Epoch: 5| Step: 2
Training loss: 0.13290348649024963
Validation loss: 1.5463455812905424

Epoch: 5| Step: 3
Training loss: 0.1864265501499176
Validation loss: 1.5419805844624836

Epoch: 5| Step: 4
Training loss: 0.09104926884174347
Validation loss: 1.4746766769757835

Epoch: 5| Step: 5
Training loss: 0.10068156570196152
Validation loss: 1.4687656580760915

Epoch: 5| Step: 6
Training loss: 0.3270605206489563
Validation loss: 1.4707149638924548

Epoch: 5| Step: 7
Training loss: 0.11939575523138046
Validation loss: 1.4315220899479364

Epoch: 5| Step: 8
Training loss: 0.19943754374980927
Validation loss: 1.4358187003802227

Epoch: 5| Step: 9
Training loss: 0.23159226775169373
Validation loss: 1.4344206074232697

Epoch: 5| Step: 10
Training loss: 0.12006159126758575
Validation loss: 1.4425882511241461

Epoch: 469| Step: 0
Training loss: 0.12367882579565048
Validation loss: 1.4361174439871183

Epoch: 5| Step: 1
Training loss: 0.16014745831489563
Validation loss: 1.432556971426933

Epoch: 5| Step: 2
Training loss: 0.15313193202018738
Validation loss: 1.4460112023097214

Epoch: 5| Step: 3
Training loss: 0.11165235936641693
Validation loss: 1.4551822946917625

Epoch: 5| Step: 4
Training loss: 0.1458892524242401
Validation loss: 1.4600177118855138

Epoch: 5| Step: 5
Training loss: 0.2708282470703125
Validation loss: 1.479841830909893

Epoch: 5| Step: 6
Training loss: 0.09686820209026337
Validation loss: 1.486802653599811

Epoch: 5| Step: 7
Training loss: 0.11609570682048798
Validation loss: 1.4675277471542358

Epoch: 5| Step: 8
Training loss: 0.11002031713724136
Validation loss: 1.49748105900262

Epoch: 5| Step: 9
Training loss: 0.21351447701454163
Validation loss: 1.5175152568406955

Epoch: 5| Step: 10
Training loss: 0.26157137751579285
Validation loss: 1.4973132174502137

Epoch: 470| Step: 0
Training loss: 0.12690673768520355
Validation loss: 1.5031616162228327

Epoch: 5| Step: 1
Training loss: 0.08256609737873077
Validation loss: 1.4982445624566847

Epoch: 5| Step: 2
Training loss: 0.16614654660224915
Validation loss: 1.4919174114863079

Epoch: 5| Step: 3
Training loss: 0.2549000680446625
Validation loss: 1.4887389393262966

Epoch: 5| Step: 4
Training loss: 0.2025803029537201
Validation loss: 1.4941027561823528

Epoch: 5| Step: 5
Training loss: 0.15312571823596954
Validation loss: 1.5034881625124203

Epoch: 5| Step: 6
Training loss: 0.14165936410427094
Validation loss: 1.4977006745594803

Epoch: 5| Step: 7
Training loss: 0.18164613842964172
Validation loss: 1.4710980974217898

Epoch: 5| Step: 8
Training loss: 0.10196621716022491
Validation loss: 1.4542580573789534

Epoch: 5| Step: 9
Training loss: 0.09376846253871918
Validation loss: 1.462095561847892

Epoch: 5| Step: 10
Training loss: 0.11605936288833618
Validation loss: 1.4440601448858938

Epoch: 471| Step: 0
Training loss: 0.11550841480493546
Validation loss: 1.4772133878482285

Epoch: 5| Step: 1
Training loss: 0.12903109192848206
Validation loss: 1.468706383500048

Epoch: 5| Step: 2
Training loss: 0.15846845507621765
Validation loss: 1.4272257589524793

Epoch: 5| Step: 3
Training loss: 0.2596500813961029
Validation loss: 1.4524058052288589

Epoch: 5| Step: 4
Training loss: 0.19239099323749542
Validation loss: 1.427121618742584

Epoch: 5| Step: 5
Training loss: 0.1456424593925476
Validation loss: 1.4493456514932777

Epoch: 5| Step: 6
Training loss: 0.17598380148410797
Validation loss: 1.4479952345612228

Epoch: 5| Step: 7
Training loss: 0.13107125461101532
Validation loss: 1.4638982075516895

Epoch: 5| Step: 8
Training loss: 0.2423512041568756
Validation loss: 1.4903975276536838

Epoch: 5| Step: 9
Training loss: 0.1817450374364853
Validation loss: 1.4759943754442277

Epoch: 5| Step: 10
Training loss: 0.12720079720020294
Validation loss: 1.4728399008832953

Epoch: 472| Step: 0
Training loss: 0.3871757686138153
Validation loss: 1.4729772908713228

Epoch: 5| Step: 1
Training loss: 0.1475868970155716
Validation loss: 1.4757825751458444

Epoch: 5| Step: 2
Training loss: 0.0863104909658432
Validation loss: 1.4638981678152596

Epoch: 5| Step: 3
Training loss: 0.21941456198692322
Validation loss: 1.4339471401706818

Epoch: 5| Step: 4
Training loss: 0.16780610382556915
Validation loss: 1.4586502377704909

Epoch: 5| Step: 5
Training loss: 0.1448933631181717
Validation loss: 1.4537527920097433

Epoch: 5| Step: 6
Training loss: 0.09430177509784698
Validation loss: 1.443366486539123

Epoch: 5| Step: 7
Training loss: 0.16535253822803497
Validation loss: 1.4378540874809347

Epoch: 5| Step: 8
Training loss: 0.10636842250823975
Validation loss: 1.4528528560874283

Epoch: 5| Step: 9
Training loss: 0.14790192246437073
Validation loss: 1.4316667318344116

Epoch: 5| Step: 10
Training loss: 0.13400545716285706
Validation loss: 1.451663447964576

Epoch: 473| Step: 0
Training loss: 0.13421125710010529
Validation loss: 1.4828278838947255

Epoch: 5| Step: 1
Training loss: 0.11309286206960678
Validation loss: 1.4867339454671389

Epoch: 5| Step: 2
Training loss: 0.19709427654743195
Validation loss: 1.4635259284768054

Epoch: 5| Step: 3
Training loss: 0.14206264913082123
Validation loss: 1.4997743175875755

Epoch: 5| Step: 4
Training loss: 0.1483454704284668
Validation loss: 1.5024748130511212

Epoch: 5| Step: 5
Training loss: 0.19038529694080353
Validation loss: 1.4975491326342347

Epoch: 5| Step: 6
Training loss: 0.14122316241264343
Validation loss: 1.4633593879720217

Epoch: 5| Step: 7
Training loss: 0.195345938205719
Validation loss: 1.440828275936906

Epoch: 5| Step: 8
Training loss: 0.3265821635723114
Validation loss: 1.4572328534177554

Epoch: 5| Step: 9
Training loss: 0.13892826437950134
Validation loss: 1.442599263242496

Epoch: 5| Step: 10
Training loss: 0.15982972085475922
Validation loss: 1.4649653671890177

Epoch: 474| Step: 0
Training loss: 0.1630687415599823
Validation loss: 1.4993524333482147

Epoch: 5| Step: 1
Training loss: 0.1385175585746765
Validation loss: 1.4863651196161907

Epoch: 5| Step: 2
Training loss: 0.18387290835380554
Validation loss: 1.4671342411348898

Epoch: 5| Step: 3
Training loss: 0.2244998663663864
Validation loss: 1.5098674028150496

Epoch: 5| Step: 4
Training loss: 0.11907324939966202
Validation loss: 1.5313535967180807

Epoch: 5| Step: 5
Training loss: 0.13026079535484314
Validation loss: 1.516507020560644

Epoch: 5| Step: 6
Training loss: 0.2562102675437927
Validation loss: 1.5293989066154725

Epoch: 5| Step: 7
Training loss: 0.11687353998422623
Validation loss: 1.5023786816545712

Epoch: 5| Step: 8
Training loss: 0.16777518391609192
Validation loss: 1.4681807666696527

Epoch: 5| Step: 9
Training loss: 0.13815216720104218
Validation loss: 1.4727657251460577

Epoch: 5| Step: 10
Training loss: 0.11577390134334564
Validation loss: 1.4715621932860343

Epoch: 475| Step: 0
Training loss: 0.120753213763237
Validation loss: 1.4601874787320372

Epoch: 5| Step: 1
Training loss: 0.1034909337759018
Validation loss: 1.4613169636777652

Epoch: 5| Step: 2
Training loss: 0.12194164842367172
Validation loss: 1.4537473032551427

Epoch: 5| Step: 3
Training loss: 0.2866937220096588
Validation loss: 1.4353679559564079

Epoch: 5| Step: 4
Training loss: 0.23287363350391388
Validation loss: 1.4436652371960301

Epoch: 5| Step: 5
Training loss: 0.28571560978889465
Validation loss: 1.470255074962493

Epoch: 5| Step: 6
Training loss: 0.16311806440353394
Validation loss: 1.4647623787644088

Epoch: 5| Step: 7
Training loss: 0.09938563406467438
Validation loss: 1.4797755531085435

Epoch: 5| Step: 8
Training loss: 0.13804292678833008
Validation loss: 1.479968402975349

Epoch: 5| Step: 9
Training loss: 0.16240906715393066
Validation loss: 1.471266004347032

Epoch: 5| Step: 10
Training loss: 0.1624528020620346
Validation loss: 1.465671516233875

Epoch: 476| Step: 0
Training loss: 0.22293619811534882
Validation loss: 1.4372725345755135

Epoch: 5| Step: 1
Training loss: 0.27649056911468506
Validation loss: 1.4431689362372122

Epoch: 5| Step: 2
Training loss: 0.11088137328624725
Validation loss: 1.458860711384845

Epoch: 5| Step: 3
Training loss: 0.1158832311630249
Validation loss: 1.4515687220840043

Epoch: 5| Step: 4
Training loss: 0.16039371490478516
Validation loss: 1.4531721953422791

Epoch: 5| Step: 5
Training loss: 0.1384904682636261
Validation loss: 1.4518814650915002

Epoch: 5| Step: 6
Training loss: 0.19889423251152039
Validation loss: 1.4315342236590642

Epoch: 5| Step: 7
Training loss: 0.12201980501413345
Validation loss: 1.4333963573619883

Epoch: 5| Step: 8
Training loss: 0.15279628336429596
Validation loss: 1.4434423574837305

Epoch: 5| Step: 9
Training loss: 0.10493819415569305
Validation loss: 1.453229381192115

Epoch: 5| Step: 10
Training loss: 0.14659273624420166
Validation loss: 1.4897258922617922

Epoch: 477| Step: 0
Training loss: 0.16755960881710052
Validation loss: 1.4919766033849409

Epoch: 5| Step: 1
Training loss: 0.09715263545513153
Validation loss: 1.494168444346356

Epoch: 5| Step: 2
Training loss: 0.13164792954921722
Validation loss: 1.481016485280888

Epoch: 5| Step: 3
Training loss: 0.3276967704296112
Validation loss: 1.489601267281399

Epoch: 5| Step: 4
Training loss: 0.1677398383617401
Validation loss: 1.4804980562579246

Epoch: 5| Step: 5
Training loss: 0.14494505524635315
Validation loss: 1.4638096561995886

Epoch: 5| Step: 6
Training loss: 0.2319982498884201
Validation loss: 1.479420490162347

Epoch: 5| Step: 7
Training loss: 0.22757482528686523
Validation loss: 1.4842273483994186

Epoch: 5| Step: 8
Training loss: 0.1438397467136383
Validation loss: 1.4580716740700506

Epoch: 5| Step: 9
Training loss: 0.08352130651473999
Validation loss: 1.460072959623029

Epoch: 5| Step: 10
Training loss: 0.21872174739837646
Validation loss: 1.449190419207337

Epoch: 478| Step: 0
Training loss: 0.24979110062122345
Validation loss: 1.4663040612333564

Epoch: 5| Step: 1
Training loss: 0.08688844740390778
Validation loss: 1.477975744073109

Epoch: 5| Step: 2
Training loss: 0.10447277128696442
Validation loss: 1.503218493153972

Epoch: 5| Step: 3
Training loss: 0.10173280537128448
Validation loss: 1.5081423392859838

Epoch: 5| Step: 4
Training loss: 0.185916930437088
Validation loss: 1.5178512629642282

Epoch: 5| Step: 5
Training loss: 0.08829943090677261
Validation loss: 1.5201963173445834

Epoch: 5| Step: 6
Training loss: 0.19437000155448914
Validation loss: 1.5353703139930643

Epoch: 5| Step: 7
Training loss: 0.24731698632240295
Validation loss: 1.5199267031044088

Epoch: 5| Step: 8
Training loss: 0.1836477816104889
Validation loss: 1.513416410774313

Epoch: 5| Step: 9
Training loss: 0.14056824147701263
Validation loss: 1.4727772769107614

Epoch: 5| Step: 10
Training loss: 0.12842601537704468
Validation loss: 1.4768968756480882

Epoch: 479| Step: 0
Training loss: 0.08724267780780792
Validation loss: 1.4872159047793316

Epoch: 5| Step: 1
Training loss: 0.32128745317459106
Validation loss: 1.485785348441011

Epoch: 5| Step: 2
Training loss: 0.1275385320186615
Validation loss: 1.4933972480476543

Epoch: 5| Step: 3
Training loss: 0.25053977966308594
Validation loss: 1.483429479342635

Epoch: 5| Step: 4
Training loss: 0.16129973530769348
Validation loss: 1.461051296162349

Epoch: 5| Step: 5
Training loss: 0.08319296687841415
Validation loss: 1.5007063881043465

Epoch: 5| Step: 6
Training loss: 0.07009750604629517
Validation loss: 1.4912620596988226

Epoch: 5| Step: 7
Training loss: 0.14604215323925018
Validation loss: 1.5005419882394935

Epoch: 5| Step: 8
Training loss: 0.16833171248435974
Validation loss: 1.5329462392355806

Epoch: 5| Step: 9
Training loss: 0.15360461175441742
Validation loss: 1.5637643452613585

Epoch: 5| Step: 10
Training loss: 0.1811804324388504
Validation loss: 1.5444236711789203

Epoch: 480| Step: 0
Training loss: 0.17577718198299408
Validation loss: 1.502140825153679

Epoch: 5| Step: 1
Training loss: 0.29942482709884644
Validation loss: 1.444506351665784

Epoch: 5| Step: 2
Training loss: 0.12031221389770508
Validation loss: 1.4696585837230887

Epoch: 5| Step: 3
Training loss: 0.11323599517345428
Validation loss: 1.4654367252062726

Epoch: 5| Step: 4
Training loss: 0.2306065559387207
Validation loss: 1.4808872758701284

Epoch: 5| Step: 5
Training loss: 0.22352313995361328
Validation loss: 1.4886557299603698

Epoch: 5| Step: 6
Training loss: 0.1179402619600296
Validation loss: 1.5058990127296858

Epoch: 5| Step: 7
Training loss: 0.06235054135322571
Validation loss: 1.5163863576868528

Epoch: 5| Step: 8
Training loss: 0.21070143580436707
Validation loss: 1.5021048438164495

Epoch: 5| Step: 9
Training loss: 0.12089613825082779
Validation loss: 1.5457701298498339

Epoch: 5| Step: 10
Training loss: 0.21716278791427612
Validation loss: 1.517725311299806

Epoch: 481| Step: 0
Training loss: 0.18624398112297058
Validation loss: 1.5596543165945238

Epoch: 5| Step: 1
Training loss: 0.1541205197572708
Validation loss: 1.5492830584126134

Epoch: 5| Step: 2
Training loss: 0.1490810215473175
Validation loss: 1.513389641238797

Epoch: 5| Step: 3
Training loss: 0.09135399013757706
Validation loss: 1.518133803080487

Epoch: 5| Step: 4
Training loss: 0.1204955130815506
Validation loss: 1.4874555564695788

Epoch: 5| Step: 5
Training loss: 0.11835967004299164
Validation loss: 1.4483101996042396

Epoch: 5| Step: 6
Training loss: 0.14832231402397156
Validation loss: 1.4437381106038247

Epoch: 5| Step: 7
Training loss: 0.11665854603052139
Validation loss: 1.4452414128088182

Epoch: 5| Step: 8
Training loss: 0.1653379499912262
Validation loss: 1.4430490898829635

Epoch: 5| Step: 9
Training loss: 0.1851263791322708
Validation loss: 1.4722636553548998

Epoch: 5| Step: 10
Training loss: 0.31152036786079407
Validation loss: 1.4862044934303529

Epoch: 482| Step: 0
Training loss: 0.14621512591838837
Validation loss: 1.5304684369794783

Epoch: 5| Step: 1
Training loss: 0.1111968383193016
Validation loss: 1.519175999908037

Epoch: 5| Step: 2
Training loss: 0.14928695559501648
Validation loss: 1.5559968820182226

Epoch: 5| Step: 3
Training loss: 0.22775299847126007
Validation loss: 1.5758818964804373

Epoch: 5| Step: 4
Training loss: 0.4211295247077942
Validation loss: 1.5600460895928003

Epoch: 5| Step: 5
Training loss: 0.19701623916625977
Validation loss: 1.4770485681872214

Epoch: 5| Step: 6
Training loss: 0.0874795913696289
Validation loss: 1.4434770948143416

Epoch: 5| Step: 7
Training loss: 0.13801570236682892
Validation loss: 1.4329130495748212

Epoch: 5| Step: 8
Training loss: 0.13514596223831177
Validation loss: 1.4100209692473054

Epoch: 5| Step: 9
Training loss: 0.17576196789741516
Validation loss: 1.4435291944011566

Epoch: 5| Step: 10
Training loss: 0.2115083634853363
Validation loss: 1.445292697157911

Epoch: 483| Step: 0
Training loss: 0.2561521530151367
Validation loss: 1.4574868448318974

Epoch: 5| Step: 1
Training loss: 0.12503769993782043
Validation loss: 1.4346809041115545

Epoch: 5| Step: 2
Training loss: 0.09859613329172134
Validation loss: 1.4507372520303214

Epoch: 5| Step: 3
Training loss: 0.10253950208425522
Validation loss: 1.4636936521017423

Epoch: 5| Step: 4
Training loss: 0.28354552388191223
Validation loss: 1.4532969241501184

Epoch: 5| Step: 5
Training loss: 0.11765460669994354
Validation loss: 1.4579523250620852

Epoch: 5| Step: 6
Training loss: 0.09400489926338196
Validation loss: 1.4750486561047134

Epoch: 5| Step: 7
Training loss: 0.16921663284301758
Validation loss: 1.4749406012155677

Epoch: 5| Step: 8
Training loss: 0.19533312320709229
Validation loss: 1.5008688844660276

Epoch: 5| Step: 9
Training loss: 0.12017656862735748
Validation loss: 1.4657170388006395

Epoch: 5| Step: 10
Training loss: 0.15170100331306458
Validation loss: 1.4724691375609367

Epoch: 484| Step: 0
Training loss: 0.12818308174610138
Validation loss: 1.4762677351633708

Epoch: 5| Step: 1
Training loss: 0.19598664343357086
Validation loss: 1.4790778160095215

Epoch: 5| Step: 2
Training loss: 0.11985877901315689
Validation loss: 1.4831112905215191

Epoch: 5| Step: 3
Training loss: 0.12260980904102325
Validation loss: 1.468031229511384

Epoch: 5| Step: 4
Training loss: 0.11401045322418213
Validation loss: 1.4940166691298127

Epoch: 5| Step: 5
Training loss: 0.16303594410419464
Validation loss: 1.4871402812260452

Epoch: 5| Step: 6
Training loss: 0.09047643095254898
Validation loss: 1.4425682790817753

Epoch: 5| Step: 7
Training loss: 0.13832850754261017
Validation loss: 1.464747449403168

Epoch: 5| Step: 8
Training loss: 0.10564561188220978
Validation loss: 1.4736961895419705

Epoch: 5| Step: 9
Training loss: 0.24320964515209198
Validation loss: 1.46200438468687

Epoch: 5| Step: 10
Training loss: 0.24174603819847107
Validation loss: 1.4589902303552116

Epoch: 485| Step: 0
Training loss: 0.13198424875736237
Validation loss: 1.4630770093651229

Epoch: 5| Step: 1
Training loss: 0.12749962508678436
Validation loss: 1.4844859274484778

Epoch: 5| Step: 2
Training loss: 0.10305015742778778
Validation loss: 1.438779915532758

Epoch: 5| Step: 3
Training loss: 0.15948259830474854
Validation loss: 1.4411730125386228

Epoch: 5| Step: 4
Training loss: 0.10297510772943497
Validation loss: 1.4403101487826275

Epoch: 5| Step: 5
Training loss: 0.15715646743774414
Validation loss: 1.4181476446890062

Epoch: 5| Step: 6
Training loss: 0.1421225219964981
Validation loss: 1.4164556207195405

Epoch: 5| Step: 7
Training loss: 0.13959923386573792
Validation loss: 1.4260905538835833

Epoch: 5| Step: 8
Training loss: 0.21081042289733887
Validation loss: 1.4426913716459786

Epoch: 5| Step: 9
Training loss: 0.22074687480926514
Validation loss: 1.4441763938114207

Epoch: 5| Step: 10
Training loss: 0.0991605892777443
Validation loss: 1.4698621329440866

Epoch: 486| Step: 0
Training loss: 0.11896920204162598
Validation loss: 1.464163452707311

Epoch: 5| Step: 1
Training loss: 0.15014392137527466
Validation loss: 1.4693826744633336

Epoch: 5| Step: 2
Training loss: 0.15982288122177124
Validation loss: 1.4603974447455457

Epoch: 5| Step: 3
Training loss: 0.1708882749080658
Validation loss: 1.494003956035901

Epoch: 5| Step: 4
Training loss: 0.11012904345989227
Validation loss: 1.4521855417118277

Epoch: 5| Step: 5
Training loss: 0.1515229344367981
Validation loss: 1.4442734231231034

Epoch: 5| Step: 6
Training loss: 0.12233450263738632
Validation loss: 1.4582871121744956

Epoch: 5| Step: 7
Training loss: 0.10745476186275482
Validation loss: 1.4592023075267833

Epoch: 5| Step: 8
Training loss: 0.10840123891830444
Validation loss: 1.4538937255900393

Epoch: 5| Step: 9
Training loss: 0.2318345606327057
Validation loss: 1.4650392147802538

Epoch: 5| Step: 10
Training loss: 0.10991745442152023
Validation loss: 1.4511656517623572

Epoch: 487| Step: 0
Training loss: 0.14952433109283447
Validation loss: 1.4760383649538922

Epoch: 5| Step: 1
Training loss: 0.15321147441864014
Validation loss: 1.427337727239055

Epoch: 5| Step: 2
Training loss: 0.09970454126596451
Validation loss: 1.4602791852848505

Epoch: 5| Step: 3
Training loss: 0.07488264888525009
Validation loss: 1.4542869332657065

Epoch: 5| Step: 4
Training loss: 0.12253239005804062
Validation loss: 1.4281323443176925

Epoch: 5| Step: 5
Training loss: 0.0764891654253006
Validation loss: 1.4407790694185483

Epoch: 5| Step: 6
Training loss: 0.13055261969566345
Validation loss: 1.4378647445350565

Epoch: 5| Step: 7
Training loss: 0.3044230341911316
Validation loss: 1.42713894895328

Epoch: 5| Step: 8
Training loss: 0.1291143298149109
Validation loss: 1.4495231771981845

Epoch: 5| Step: 9
Training loss: 0.11421383917331696
Validation loss: 1.4605745718043337

Epoch: 5| Step: 10
Training loss: 0.10240510106086731
Validation loss: 1.4556621800186813

Epoch: 488| Step: 0
Training loss: 0.12825867533683777
Validation loss: 1.4602892962835168

Epoch: 5| Step: 1
Training loss: 0.08591914176940918
Validation loss: 1.4727008663198

Epoch: 5| Step: 2
Training loss: 0.10897611081600189
Validation loss: 1.4799115644988192

Epoch: 5| Step: 3
Training loss: 0.1844952404499054
Validation loss: 1.494024267760656

Epoch: 5| Step: 4
Training loss: 0.1054573655128479
Validation loss: 1.4709480013898624

Epoch: 5| Step: 5
Training loss: 0.14881262183189392
Validation loss: 1.4832062170069704

Epoch: 5| Step: 6
Training loss: 0.0887681394815445
Validation loss: 1.4827157822988366

Epoch: 5| Step: 7
Training loss: 0.13105346262454987
Validation loss: 1.487053918582137

Epoch: 5| Step: 8
Training loss: 0.2582075297832489
Validation loss: 1.5008241297096334

Epoch: 5| Step: 9
Training loss: 0.2732578217983246
Validation loss: 1.516314491148918

Epoch: 5| Step: 10
Training loss: 0.09396474808454514
Validation loss: 1.471849879910869

Epoch: 489| Step: 0
Training loss: 0.0984770655632019
Validation loss: 1.5088903525824189

Epoch: 5| Step: 1
Training loss: 0.16540464758872986
Validation loss: 1.481810458244816

Epoch: 5| Step: 2
Training loss: 0.24095745384693146
Validation loss: 1.4591114341571767

Epoch: 5| Step: 3
Training loss: 0.0807620957493782
Validation loss: 1.4560456166985214

Epoch: 5| Step: 4
Training loss: 0.17199771106243134
Validation loss: 1.4778469698403471

Epoch: 5| Step: 5
Training loss: 0.09634462743997574
Validation loss: 1.4493612550920056

Epoch: 5| Step: 6
Training loss: 0.13912621140480042
Validation loss: 1.4515270802282518

Epoch: 5| Step: 7
Training loss: 0.17480464279651642
Validation loss: 1.4855968106177546

Epoch: 5| Step: 8
Training loss: 0.12767457962036133
Validation loss: 1.454652847782258

Epoch: 5| Step: 9
Training loss: 0.07736048847436905
Validation loss: 1.4321583881173083

Epoch: 5| Step: 10
Training loss: 0.078728087246418
Validation loss: 1.4164484111211633

Epoch: 490| Step: 0
Training loss: 0.1164645105600357
Validation loss: 1.4181022221042263

Epoch: 5| Step: 1
Training loss: 0.17863363027572632
Validation loss: 1.4371808164863176

Epoch: 5| Step: 2
Training loss: 0.18371880054473877
Validation loss: 1.436649707055861

Epoch: 5| Step: 3
Training loss: 0.09420496225357056
Validation loss: 1.4383219301059682

Epoch: 5| Step: 4
Training loss: 0.16803881525993347
Validation loss: 1.4322305674194007

Epoch: 5| Step: 5
Training loss: 0.08066998422145844
Validation loss: 1.458325510383934

Epoch: 5| Step: 6
Training loss: 0.09139986336231232
Validation loss: 1.4300265235285605

Epoch: 5| Step: 7
Training loss: 0.2732250392436981
Validation loss: 1.433569594096112

Epoch: 5| Step: 8
Training loss: 0.09418215602636337
Validation loss: 1.4492974153129004

Epoch: 5| Step: 9
Training loss: 0.06955665349960327
Validation loss: 1.4586565955992667

Epoch: 5| Step: 10
Training loss: 0.2047722339630127
Validation loss: 1.4645732833493141

Epoch: 491| Step: 0
Training loss: 0.14168645441532135
Validation loss: 1.4492680077911706

Epoch: 5| Step: 1
Training loss: 0.09066233038902283
Validation loss: 1.4469104223353888

Epoch: 5| Step: 2
Training loss: 0.20410911738872528
Validation loss: 1.4561033466810822

Epoch: 5| Step: 3
Training loss: 0.15514421463012695
Validation loss: 1.4722804882193123

Epoch: 5| Step: 4
Training loss: 0.08827950805425644
Validation loss: 1.4650177481353923

Epoch: 5| Step: 5
Training loss: 0.2204907238483429
Validation loss: 1.4319638231749177

Epoch: 5| Step: 6
Training loss: 0.14520005881786346
Validation loss: 1.466237037412582

Epoch: 5| Step: 7
Training loss: 0.13409428298473358
Validation loss: 1.4542225125015422

Epoch: 5| Step: 8
Training loss: 0.15690214931964874
Validation loss: 1.4624705237727011

Epoch: 5| Step: 9
Training loss: 0.07488645613193512
Validation loss: 1.4434588006747666

Epoch: 5| Step: 10
Training loss: 0.08713555335998535
Validation loss: 1.4609875063742361

Epoch: 492| Step: 0
Training loss: 0.08220374584197998
Validation loss: 1.455235363334738

Epoch: 5| Step: 1
Training loss: 0.16832804679870605
Validation loss: 1.4630204836527507

Epoch: 5| Step: 2
Training loss: 0.0921764224767685
Validation loss: 1.4746807839280816

Epoch: 5| Step: 3
Training loss: 0.12498577684164047
Validation loss: 1.4700419146527526

Epoch: 5| Step: 4
Training loss: 0.10197863727807999
Validation loss: 1.468081311513019

Epoch: 5| Step: 5
Training loss: 0.11975812911987305
Validation loss: 1.5097807556070306

Epoch: 5| Step: 6
Training loss: 0.08086329698562622
Validation loss: 1.4871278860235726

Epoch: 5| Step: 7
Training loss: 0.14504359662532806
Validation loss: 1.4756975097040976

Epoch: 5| Step: 8
Training loss: 0.32062071561813354
Validation loss: 1.4700492953741422

Epoch: 5| Step: 9
Training loss: 0.12448493391275406
Validation loss: 1.4904539649204542

Epoch: 5| Step: 10
Training loss: 0.12469938397407532
Validation loss: 1.5028153158003283

Epoch: 493| Step: 0
Training loss: 0.11213769018650055
Validation loss: 1.4638283444989113

Epoch: 5| Step: 1
Training loss: 0.16245491802692413
Validation loss: 1.4917553099252845

Epoch: 5| Step: 2
Training loss: 0.21849627792835236
Validation loss: 1.4467878226310975

Epoch: 5| Step: 3
Training loss: 0.15332737565040588
Validation loss: 1.4701172741510535

Epoch: 5| Step: 4
Training loss: 0.131210058927536
Validation loss: 1.4382916240281955

Epoch: 5| Step: 5
Training loss: 0.2641514539718628
Validation loss: 1.4571702134224676

Epoch: 5| Step: 6
Training loss: 0.21270088851451874
Validation loss: 1.445311447625519

Epoch: 5| Step: 7
Training loss: 0.09553166478872299
Validation loss: 1.468576083901108

Epoch: 5| Step: 8
Training loss: 0.10200552642345428
Validation loss: 1.4572352568308513

Epoch: 5| Step: 9
Training loss: 0.09383836388587952
Validation loss: 1.464293639506063

Epoch: 5| Step: 10
Training loss: 0.10129839181900024
Validation loss: 1.455001651599843

Epoch: 494| Step: 0
Training loss: 0.1342569887638092
Validation loss: 1.4297826367039834

Epoch: 5| Step: 1
Training loss: 0.23671022057533264
Validation loss: 1.4469139896413332

Epoch: 5| Step: 2
Training loss: 0.10273997485637665
Validation loss: 1.4434766615590742

Epoch: 5| Step: 3
Training loss: 0.12909407913684845
Validation loss: 1.4498454813034303

Epoch: 5| Step: 4
Training loss: 0.09192906320095062
Validation loss: 1.4436420138164232

Epoch: 5| Step: 5
Training loss: 0.1367654800415039
Validation loss: 1.4381093132880427

Epoch: 5| Step: 6
Training loss: 0.1589040905237198
Validation loss: 1.4669934280457035

Epoch: 5| Step: 7
Training loss: 0.09447784721851349
Validation loss: 1.4609803268986363

Epoch: 5| Step: 8
Training loss: 0.1256813257932663
Validation loss: 1.4564967347729592

Epoch: 5| Step: 9
Training loss: 0.1766272783279419
Validation loss: 1.464219606050881

Epoch: 5| Step: 10
Training loss: 0.10945431143045425
Validation loss: 1.4612996309034285

Epoch: 495| Step: 0
Training loss: 0.11969494819641113
Validation loss: 1.4789719543149393

Epoch: 5| Step: 1
Training loss: 0.12098522484302521
Validation loss: 1.4768792916369695

Epoch: 5| Step: 2
Training loss: 0.1097792237997055
Validation loss: 1.4658255352768848

Epoch: 5| Step: 3
Training loss: 0.2204453945159912
Validation loss: 1.4816264926746328

Epoch: 5| Step: 4
Training loss: 0.1970764398574829
Validation loss: 1.4922548468394945

Epoch: 5| Step: 5
Training loss: 0.13499142229557037
Validation loss: 1.4806570776047245

Epoch: 5| Step: 6
Training loss: 0.12254085391759872
Validation loss: 1.4742905991051787

Epoch: 5| Step: 7
Training loss: 0.246592715382576
Validation loss: 1.4721379587727208

Epoch: 5| Step: 8
Training loss: 0.08249761164188385
Validation loss: 1.4649753993557346

Epoch: 5| Step: 9
Training loss: 0.09641887247562408
Validation loss: 1.4508190590848205

Epoch: 5| Step: 10
Training loss: 0.139422208070755
Validation loss: 1.4824707892633253

Epoch: 496| Step: 0
Training loss: 0.17730048298835754
Validation loss: 1.4886087858548729

Epoch: 5| Step: 1
Training loss: 0.1568630188703537
Validation loss: 1.481219837742467

Epoch: 5| Step: 2
Training loss: 0.1310591995716095
Validation loss: 1.490541619639243

Epoch: 5| Step: 3
Training loss: 0.08766625076532364
Validation loss: 1.4518369051717943

Epoch: 5| Step: 4
Training loss: 0.13958904147148132
Validation loss: 1.4404512797632525

Epoch: 5| Step: 5
Training loss: 0.08267369866371155
Validation loss: 1.413767155780587

Epoch: 5| Step: 6
Training loss: 0.09755944460630417
Validation loss: 1.4340582368194417

Epoch: 5| Step: 7
Training loss: 0.19215865433216095
Validation loss: 1.4287422433976205

Epoch: 5| Step: 8
Training loss: 0.25633344054222107
Validation loss: 1.4113228115984189

Epoch: 5| Step: 9
Training loss: 0.08738753199577332
Validation loss: 1.4175668942031039

Epoch: 5| Step: 10
Training loss: 0.10611313581466675
Validation loss: 1.4154471056435698

Epoch: 497| Step: 0
Training loss: 0.11450716108083725
Validation loss: 1.4218679743428384

Epoch: 5| Step: 1
Training loss: 0.18517664074897766
Validation loss: 1.4471192962379866

Epoch: 5| Step: 2
Training loss: 0.3394779562950134
Validation loss: 1.4231145792109992

Epoch: 5| Step: 3
Training loss: 0.11684286594390869
Validation loss: 1.4337902453637892

Epoch: 5| Step: 4
Training loss: 0.06855226308107376
Validation loss: 1.4235916932423909

Epoch: 5| Step: 5
Training loss: 0.08765493333339691
Validation loss: 1.4388468688534153

Epoch: 5| Step: 6
Training loss: 0.0981309562921524
Validation loss: 1.4170311151012298

Epoch: 5| Step: 7
Training loss: 0.14721938967704773
Validation loss: 1.4214672273205173

Epoch: 5| Step: 8
Training loss: 0.09674450010061264
Validation loss: 1.4261677829168176

Epoch: 5| Step: 9
Training loss: 0.14001455903053284
Validation loss: 1.4209381380388815

Epoch: 5| Step: 10
Training loss: 0.08190515637397766
Validation loss: 1.4416344460620676

Epoch: 498| Step: 0
Training loss: 0.12383770942687988
Validation loss: 1.4498557108704762

Epoch: 5| Step: 1
Training loss: 0.1299353837966919
Validation loss: 1.4711882196446902

Epoch: 5| Step: 2
Training loss: 0.11309371888637543
Validation loss: 1.482949088978511

Epoch: 5| Step: 3
Training loss: 0.21929118037223816
Validation loss: 1.491922822049869

Epoch: 5| Step: 4
Training loss: 0.08884020149707794
Validation loss: 1.4796178071729598

Epoch: 5| Step: 5
Training loss: 0.2121514081954956
Validation loss: 1.4585121100948704

Epoch: 5| Step: 6
Training loss: 0.20594987273216248
Validation loss: 1.4331631493824784

Epoch: 5| Step: 7
Training loss: 0.1300760954618454
Validation loss: 1.4666496912638347

Epoch: 5| Step: 8
Training loss: 0.09379475563764572
Validation loss: 1.4355311252737557

Epoch: 5| Step: 9
Training loss: 0.07796213030815125
Validation loss: 1.4459227759351012

Epoch: 5| Step: 10
Training loss: 0.15962177515029907
Validation loss: 1.4426954933392104

Epoch: 499| Step: 0
Training loss: 0.15698905289173126
Validation loss: 1.444394980066566

Epoch: 5| Step: 1
Training loss: 0.13852040469646454
Validation loss: 1.4355235881702875

Epoch: 5| Step: 2
Training loss: 0.21247808635234833
Validation loss: 1.4500404903965611

Epoch: 5| Step: 3
Training loss: 0.18788127601146698
Validation loss: 1.438426435634654

Epoch: 5| Step: 4
Training loss: 0.09021837264299393
Validation loss: 1.4626054891975977

Epoch: 5| Step: 5
Training loss: 0.11669868230819702
Validation loss: 1.4454311914341424

Epoch: 5| Step: 6
Training loss: 0.11880840361118317
Validation loss: 1.450915580154747

Epoch: 5| Step: 7
Training loss: 0.22797217965126038
Validation loss: 1.4419017107255998

Epoch: 5| Step: 8
Training loss: 0.07968074083328247
Validation loss: 1.4212169640807695

Epoch: 5| Step: 9
Training loss: 0.0980115681886673
Validation loss: 1.4314311063417824

Epoch: 5| Step: 10
Training loss: 0.12132507562637329
Validation loss: 1.4250855240770566

Epoch: 500| Step: 0
Training loss: 0.12144601345062256
Validation loss: 1.4565339908804944

Epoch: 5| Step: 1
Training loss: 0.15356668829917908
Validation loss: 1.4297076649563287

Epoch: 5| Step: 2
Training loss: 0.14345009624958038
Validation loss: 1.457391764528008

Epoch: 5| Step: 3
Training loss: 0.2665511965751648
Validation loss: 1.4362817009290059

Epoch: 5| Step: 4
Training loss: 0.11431044340133667
Validation loss: 1.4112103690383255

Epoch: 5| Step: 5
Training loss: 0.09363825619220734
Validation loss: 1.434019951410191

Epoch: 5| Step: 6
Training loss: 0.1870289146900177
Validation loss: 1.4261820059950634

Epoch: 5| Step: 7
Training loss: 0.14377166330814362
Validation loss: 1.4158359740370063

Epoch: 5| Step: 8
Training loss: 0.08347359299659729
Validation loss: 1.4406206018181258

Epoch: 5| Step: 9
Training loss: 0.052042342722415924
Validation loss: 1.4197089909225382

Epoch: 5| Step: 10
Training loss: 0.16584043204784393
Validation loss: 1.4469997805933799

Epoch: 501| Step: 0
Training loss: 0.14988049864768982
Validation loss: 1.4353573886297082

Epoch: 5| Step: 1
Training loss: 0.09536787122488022
Validation loss: 1.4693224686448292

Epoch: 5| Step: 2
Training loss: 0.14022305607795715
Validation loss: 1.4398583032751595

Epoch: 5| Step: 3
Training loss: 0.09484617412090302
Validation loss: 1.4392176469167073

Epoch: 5| Step: 4
Training loss: 0.10200345516204834
Validation loss: 1.4477071531357304

Epoch: 5| Step: 5
Training loss: 0.1447167843580246
Validation loss: 1.4729275126611032

Epoch: 5| Step: 6
Training loss: 0.22658853232860565
Validation loss: 1.4515653912739088

Epoch: 5| Step: 7
Training loss: 0.11422315984964371
Validation loss: 1.472604670832234

Epoch: 5| Step: 8
Training loss: 0.21083316206932068
Validation loss: 1.4877111001681256

Epoch: 5| Step: 9
Training loss: 0.1497211903333664
Validation loss: 1.4909237072031984

Epoch: 5| Step: 10
Training loss: 0.0880817249417305
Validation loss: 1.4849128159143592

Epoch: 502| Step: 0
Training loss: 0.12932366132736206
Validation loss: 1.4981473376674037

Epoch: 5| Step: 1
Training loss: 0.1198938637971878
Validation loss: 1.5028621176237702

Epoch: 5| Step: 2
Training loss: 0.1179099902510643
Validation loss: 1.4643123354963077

Epoch: 5| Step: 3
Training loss: 0.1508626937866211
Validation loss: 1.4672747106962307

Epoch: 5| Step: 4
Training loss: 0.10707797110080719
Validation loss: 1.4423523884947582

Epoch: 5| Step: 5
Training loss: 0.10499858856201172
Validation loss: 1.4580120540434314

Epoch: 5| Step: 6
Training loss: 0.12584564089775085
Validation loss: 1.4865522820462462

Epoch: 5| Step: 7
Training loss: 0.10667429864406586
Validation loss: 1.4855017290320447

Epoch: 5| Step: 8
Training loss: 0.24878373742103577
Validation loss: 1.4709401835677445

Epoch: 5| Step: 9
Training loss: 0.3152391016483307
Validation loss: 1.482135485577327

Epoch: 5| Step: 10
Training loss: 0.10391398519277573
Validation loss: 1.4712839934133715

Epoch: 503| Step: 0
Training loss: 0.25520604848861694
Validation loss: 1.5116476192269275

Epoch: 5| Step: 1
Training loss: 0.16158033907413483
Validation loss: 1.5345162166062223

Epoch: 5| Step: 2
Training loss: 0.12236206233501434
Validation loss: 1.5285614767382223

Epoch: 5| Step: 3
Training loss: 0.16949209570884705
Validation loss: 1.4487074075206634

Epoch: 5| Step: 4
Training loss: 0.12121354043483734
Validation loss: 1.440477869843924

Epoch: 5| Step: 5
Training loss: 0.11033425480127335
Validation loss: 1.4592470751013806

Epoch: 5| Step: 6
Training loss: 0.10630090534687042
Validation loss: 1.4088479306108208

Epoch: 5| Step: 7
Training loss: 0.12039947509765625
Validation loss: 1.434836555552739

Epoch: 5| Step: 8
Training loss: 0.10902239382266998
Validation loss: 1.4120577202048352

Epoch: 5| Step: 9
Training loss: 0.13130731880664825
Validation loss: 1.4042366845633394

Epoch: 5| Step: 10
Training loss: 0.11789652705192566
Validation loss: 1.4425339826973536

Epoch: 504| Step: 0
Training loss: 0.12152153253555298
Validation loss: 1.4136007607624095

Epoch: 5| Step: 1
Training loss: 0.14077487587928772
Validation loss: 1.431400425972477

Epoch: 5| Step: 2
Training loss: 0.13037894666194916
Validation loss: 1.4402490072352911

Epoch: 5| Step: 3
Training loss: 0.17624850571155548
Validation loss: 1.4594474300261466

Epoch: 5| Step: 4
Training loss: 0.27469491958618164
Validation loss: 1.4489380544231785

Epoch: 5| Step: 5
Training loss: 0.20331354439258575
Validation loss: 1.4083474662996107

Epoch: 5| Step: 6
Training loss: 0.09263584762811661
Validation loss: 1.4253228146542785

Epoch: 5| Step: 7
Training loss: 0.10240828990936279
Validation loss: 1.4634001972854778

Epoch: 5| Step: 8
Training loss: 0.0663968101143837
Validation loss: 1.4442131032225907

Epoch: 5| Step: 9
Training loss: 0.08524361252784729
Validation loss: 1.44674817721049

Epoch: 5| Step: 10
Training loss: 0.06296072155237198
Validation loss: 1.4739128992121706

Epoch: 505| Step: 0
Training loss: 0.08971725404262543
Validation loss: 1.4777127478712349

Epoch: 5| Step: 1
Training loss: 0.11319372802972794
Validation loss: 1.4781788843934254

Epoch: 5| Step: 2
Training loss: 0.15198519825935364
Validation loss: 1.4735344404815345

Epoch: 5| Step: 3
Training loss: 0.09365536272525787
Validation loss: 1.4894804569982714

Epoch: 5| Step: 4
Training loss: 0.11494918167591095
Validation loss: 1.4898376977571877

Epoch: 5| Step: 5
Training loss: 0.1193145290017128
Validation loss: 1.4358695578831497

Epoch: 5| Step: 6
Training loss: 0.22715803980827332
Validation loss: 1.4524008176660026

Epoch: 5| Step: 7
Training loss: 0.10671056807041168
Validation loss: 1.431818667278495

Epoch: 5| Step: 8
Training loss: 0.0889861136674881
Validation loss: 1.408882107785953

Epoch: 5| Step: 9
Training loss: 0.12933795154094696
Validation loss: 1.41612030870171

Epoch: 5| Step: 10
Training loss: 0.13001002371311188
Validation loss: 1.384617063306993

Epoch: 506| Step: 0
Training loss: 0.11825664341449738
Validation loss: 1.3948393534588557

Epoch: 5| Step: 1
Training loss: 0.13284043967723846
Validation loss: 1.4155032352734638

Epoch: 5| Step: 2
Training loss: 0.07496698200702667
Validation loss: 1.428421788318183

Epoch: 5| Step: 3
Training loss: 0.12232893705368042
Validation loss: 1.4395076036453247

Epoch: 5| Step: 4
Training loss: 0.09451998770236969
Validation loss: 1.4278283837021037

Epoch: 5| Step: 5
Training loss: 0.2302406132221222
Validation loss: 1.4455227851867676

Epoch: 5| Step: 6
Training loss: 0.24578194320201874
Validation loss: 1.4388681534797914

Epoch: 5| Step: 7
Training loss: 0.07948952913284302
Validation loss: 1.4715734002410725

Epoch: 5| Step: 8
Training loss: 0.13902418315410614
Validation loss: 1.4560913783247753

Epoch: 5| Step: 9
Training loss: 0.10432419925928116
Validation loss: 1.4802251605577366

Epoch: 5| Step: 10
Training loss: 0.10617446899414062
Validation loss: 1.4968798647644699

Epoch: 507| Step: 0
Training loss: 0.15821298956871033
Validation loss: 1.5153411944066324

Epoch: 5| Step: 1
Training loss: 0.17848746478557587
Validation loss: 1.4842205150153047

Epoch: 5| Step: 2
Training loss: 0.20344829559326172
Validation loss: 1.512608669137442

Epoch: 5| Step: 3
Training loss: 0.14595022797584534
Validation loss: 1.4749367813910208

Epoch: 5| Step: 4
Training loss: 0.07256583869457245
Validation loss: 1.4699162142251128

Epoch: 5| Step: 5
Training loss: 0.1171448603272438
Validation loss: 1.4396796072683027

Epoch: 5| Step: 6
Training loss: 0.12021011114120483
Validation loss: 1.4653006638250043

Epoch: 5| Step: 7
Training loss: 0.1863773912191391
Validation loss: 1.4534688944457679

Epoch: 5| Step: 8
Training loss: 0.13540463149547577
Validation loss: 1.4859451657982283

Epoch: 5| Step: 9
Training loss: 0.13236670196056366
Validation loss: 1.4646910198273198

Epoch: 5| Step: 10
Training loss: 0.14855162799358368
Validation loss: 1.4536700774264593

Epoch: 508| Step: 0
Training loss: 0.3338266909122467
Validation loss: 1.4719912390555105

Epoch: 5| Step: 1
Training loss: 0.11400909721851349
Validation loss: 1.4642830183429103

Epoch: 5| Step: 2
Training loss: 0.13161146640777588
Validation loss: 1.4519521536365632

Epoch: 5| Step: 3
Training loss: 0.08359846472740173
Validation loss: 1.4794579654611566

Epoch: 5| Step: 4
Training loss: 0.12846186757087708
Validation loss: 1.456204104167159

Epoch: 5| Step: 5
Training loss: 0.12248225510120392
Validation loss: 1.4748953068128197

Epoch: 5| Step: 6
Training loss: 0.1433175504207611
Validation loss: 1.4719202480008524

Epoch: 5| Step: 7
Training loss: 0.08071966469287872
Validation loss: 1.4358808712292743

Epoch: 5| Step: 8
Training loss: 0.09691563993692398
Validation loss: 1.465406108927983

Epoch: 5| Step: 9
Training loss: 0.20541107654571533
Validation loss: 1.4457251352648581

Epoch: 5| Step: 10
Training loss: 0.11127179116010666
Validation loss: 1.4382372863831059

Epoch: 509| Step: 0
Training loss: 0.06286339461803436
Validation loss: 1.418611297043421

Epoch: 5| Step: 1
Training loss: 0.2070939838886261
Validation loss: 1.4200281872544238

Epoch: 5| Step: 2
Training loss: 0.12577559053897858
Validation loss: 1.4238115587542135

Epoch: 5| Step: 3
Training loss: 0.13708405196666718
Validation loss: 1.4603913676354192

Epoch: 5| Step: 4
Training loss: 0.09429305791854858
Validation loss: 1.4862656170322048

Epoch: 5| Step: 5
Training loss: 0.13318447768688202
Validation loss: 1.4730163492182249

Epoch: 5| Step: 6
Training loss: 0.19468259811401367
Validation loss: 1.4535500580264675

Epoch: 5| Step: 7
Training loss: 0.0901525542140007
Validation loss: 1.4653445392526605

Epoch: 5| Step: 8
Training loss: 0.21574679017066956
Validation loss: 1.459869388611086

Epoch: 5| Step: 9
Training loss: 0.07700884342193604
Validation loss: 1.4802537156689552

Epoch: 5| Step: 10
Training loss: 0.14299224317073822
Validation loss: 1.466060887100876

Epoch: 510| Step: 0
Training loss: 0.12662145495414734
Validation loss: 1.4707812974529881

Epoch: 5| Step: 1
Training loss: 0.14892952144145966
Validation loss: 1.4967921062182354

Epoch: 5| Step: 2
Training loss: 0.1638411432504654
Validation loss: 1.50753822506115

Epoch: 5| Step: 3
Training loss: 0.11767213046550751
Validation loss: 1.4777490637635673

Epoch: 5| Step: 4
Training loss: 0.093582883477211
Validation loss: 1.4902759675056703

Epoch: 5| Step: 5
Training loss: 0.08691800385713577
Validation loss: 1.4936740436861593

Epoch: 5| Step: 6
Training loss: 0.1261141300201416
Validation loss: 1.5227818027619393

Epoch: 5| Step: 7
Training loss: 0.12847787141799927
Validation loss: 1.508406094325486

Epoch: 5| Step: 8
Training loss: 0.2027117758989334
Validation loss: 1.500582742434676

Epoch: 5| Step: 9
Training loss: 0.1861381083726883
Validation loss: 1.471270239481362

Epoch: 5| Step: 10
Training loss: 0.24478477239608765
Validation loss: 1.4647317265951505

Epoch: 511| Step: 0
Training loss: 0.14968958497047424
Validation loss: 1.4678777328101538

Epoch: 5| Step: 1
Training loss: 0.1268092840909958
Validation loss: 1.4533260317258938

Epoch: 5| Step: 2
Training loss: 0.08667558431625366
Validation loss: 1.4514117817724905

Epoch: 5| Step: 3
Training loss: 0.23797734081745148
Validation loss: 1.4704007499961442

Epoch: 5| Step: 4
Training loss: 0.14639155566692352
Validation loss: 1.4786596580218243

Epoch: 5| Step: 5
Training loss: 0.10200747102499008
Validation loss: 1.4449992128597793

Epoch: 5| Step: 6
Training loss: 0.10263439267873764
Validation loss: 1.496866395396571

Epoch: 5| Step: 7
Training loss: 0.14113473892211914
Validation loss: 1.4809487474861966

Epoch: 5| Step: 8
Training loss: 0.09256166219711304
Validation loss: 1.4837325990840953

Epoch: 5| Step: 9
Training loss: 0.27516651153564453
Validation loss: 1.4440163899493474

Epoch: 5| Step: 10
Training loss: 0.11754560470581055
Validation loss: 1.4422782646712435

Epoch: 512| Step: 0
Training loss: 0.10791274160146713
Validation loss: 1.4465807381496634

Epoch: 5| Step: 1
Training loss: 0.14975354075431824
Validation loss: 1.429188310459096

Epoch: 5| Step: 2
Training loss: 0.11642096936702728
Validation loss: 1.4034524015201035

Epoch: 5| Step: 3
Training loss: 0.09704787284135818
Validation loss: 1.410171635689274

Epoch: 5| Step: 4
Training loss: 0.11368683725595474
Validation loss: 1.41471174006821

Epoch: 5| Step: 5
Training loss: 0.12663353979587555
Validation loss: 1.4258480841113674

Epoch: 5| Step: 6
Training loss: 0.11749885231256485
Validation loss: 1.4020432156901206

Epoch: 5| Step: 7
Training loss: 0.0810735672712326
Validation loss: 1.4091362440457909

Epoch: 5| Step: 8
Training loss: 0.10503041744232178
Validation loss: 1.3977545807438512

Epoch: 5| Step: 9
Training loss: 0.34336864948272705
Validation loss: 1.4181457514403968

Epoch: 5| Step: 10
Training loss: 0.124942347407341
Validation loss: 1.429761613568952

Epoch: 513| Step: 0
Training loss: 0.0962352454662323
Validation loss: 1.4303608158583283

Epoch: 5| Step: 1
Training loss: 0.10694146156311035
Validation loss: 1.424106535091195

Epoch: 5| Step: 2
Training loss: 0.08996890485286713
Validation loss: 1.439873742800887

Epoch: 5| Step: 3
Training loss: 0.14162686467170715
Validation loss: 1.4620757167057326

Epoch: 5| Step: 4
Training loss: 0.30514559149742126
Validation loss: 1.458562203632888

Epoch: 5| Step: 5
Training loss: 0.08389098942279816
Validation loss: 1.442779702524985

Epoch: 5| Step: 6
Training loss: 0.22061839699745178
Validation loss: 1.4661455692783478

Epoch: 5| Step: 7
Training loss: 0.08778073638677597
Validation loss: 1.4589577041646486

Epoch: 5| Step: 8
Training loss: 0.1231698989868164
Validation loss: 1.4553276287612094

Epoch: 5| Step: 9
Training loss: 0.09098663926124573
Validation loss: 1.4477945348267913

Epoch: 5| Step: 10
Training loss: 0.15877693891525269
Validation loss: 1.4444599786112386

Epoch: 514| Step: 0
Training loss: 0.13439416885375977
Validation loss: 1.4184573593960013

Epoch: 5| Step: 1
Training loss: 0.10614998638629913
Validation loss: 1.4367859325101298

Epoch: 5| Step: 2
Training loss: 0.08144871145486832
Validation loss: 1.4296811011529738

Epoch: 5| Step: 3
Training loss: 0.1195225864648819
Validation loss: 1.471435042478705

Epoch: 5| Step: 4
Training loss: 0.14946356415748596
Validation loss: 1.4930848895862538

Epoch: 5| Step: 5
Training loss: 0.26513737440109253
Validation loss: 1.4912054769454464

Epoch: 5| Step: 6
Training loss: 0.10178010165691376
Validation loss: 1.4946140986616894

Epoch: 5| Step: 7
Training loss: 0.14288237690925598
Validation loss: 1.5162233550061461

Epoch: 5| Step: 8
Training loss: 0.1220351830124855
Validation loss: 1.4579020084873322

Epoch: 5| Step: 9
Training loss: 0.158208966255188
Validation loss: 1.4302204879381324

Epoch: 5| Step: 10
Training loss: 0.10486903786659241
Validation loss: 1.4352776504332019

Epoch: 515| Step: 0
Training loss: 0.09356312453746796
Validation loss: 1.4261607457232732

Epoch: 5| Step: 1
Training loss: 0.1176360622048378
Validation loss: 1.4206414338081115

Epoch: 5| Step: 2
Training loss: 0.10197322070598602
Validation loss: 1.4143474467339054

Epoch: 5| Step: 3
Training loss: 0.1142701655626297
Validation loss: 1.4203942424507552

Epoch: 5| Step: 4
Training loss: 0.18341916799545288
Validation loss: 1.4334396598159627

Epoch: 5| Step: 5
Training loss: 0.12833836674690247
Validation loss: 1.4489847280645882

Epoch: 5| Step: 6
Training loss: 0.2242792546749115
Validation loss: 1.4554959804781022

Epoch: 5| Step: 7
Training loss: 0.11163663864135742
Validation loss: 1.476383646329244

Epoch: 5| Step: 8
Training loss: 0.1167999878525734
Validation loss: 1.4357767258920977

Epoch: 5| Step: 9
Training loss: 0.14989754557609558
Validation loss: 1.4354950381863503

Epoch: 5| Step: 10
Training loss: 0.1169530525803566
Validation loss: 1.4144445388547835

Epoch: 516| Step: 0
Training loss: 0.08865822851657867
Validation loss: 1.4265775180632068

Epoch: 5| Step: 1
Training loss: 0.05885087698698044
Validation loss: 1.4197184962611045

Epoch: 5| Step: 2
Training loss: 0.17092065513134003
Validation loss: 1.4351741626698484

Epoch: 5| Step: 3
Training loss: 0.05414599925279617
Validation loss: 1.4284554719924927

Epoch: 5| Step: 4
Training loss: 0.09203711152076721
Validation loss: 1.4328745821470856

Epoch: 5| Step: 5
Training loss: 0.10049085319042206
Validation loss: 1.4649697760100007

Epoch: 5| Step: 6
Training loss: 0.2900567054748535
Validation loss: 1.464174275757164

Epoch: 5| Step: 7
Training loss: 0.107744500041008
Validation loss: 1.4509627870334092

Epoch: 5| Step: 8
Training loss: 0.07431314885616302
Validation loss: 1.4609690814889886

Epoch: 5| Step: 9
Training loss: 0.11080276966094971
Validation loss: 1.4514840777202318

Epoch: 5| Step: 10
Training loss: 0.1591355949640274
Validation loss: 1.4427135144510577

Epoch: 517| Step: 0
Training loss: 0.13593660295009613
Validation loss: 1.4385574504893313

Epoch: 5| Step: 1
Training loss: 0.11169151961803436
Validation loss: 1.4625760445030787

Epoch: 5| Step: 2
Training loss: 0.2703478932380676
Validation loss: 1.4509142752616637

Epoch: 5| Step: 3
Training loss: 0.06477751582860947
Validation loss: 1.4295222861792451

Epoch: 5| Step: 4
Training loss: 0.09511776268482208
Validation loss: 1.4372218667819936

Epoch: 5| Step: 5
Training loss: 0.145562082529068
Validation loss: 1.452860382295424

Epoch: 5| Step: 6
Training loss: 0.07812044024467468
Validation loss: 1.4645718076536733

Epoch: 5| Step: 7
Training loss: 0.11608407646417618
Validation loss: 1.4445643014805292

Epoch: 5| Step: 8
Training loss: 0.09963096678256989
Validation loss: 1.4695709866862143

Epoch: 5| Step: 9
Training loss: 0.07958575338125229
Validation loss: 1.459041783245661

Epoch: 5| Step: 10
Training loss: 0.19201578199863434
Validation loss: 1.4547911126126525

Epoch: 518| Step: 0
Training loss: 0.12540414929389954
Validation loss: 1.4618850433698265

Epoch: 5| Step: 1
Training loss: 0.07788289338350296
Validation loss: 1.4545565394945041

Epoch: 5| Step: 2
Training loss: 0.08166836947202682
Validation loss: 1.469109324998753

Epoch: 5| Step: 3
Training loss: 0.07900352030992508
Validation loss: 1.4617557480771055

Epoch: 5| Step: 4
Training loss: 0.13340233266353607
Validation loss: 1.4579568575787287

Epoch: 5| Step: 5
Training loss: 0.24864986538887024
Validation loss: 1.4641120074897684

Epoch: 5| Step: 6
Training loss: 0.12111981958150864
Validation loss: 1.4612591176904657

Epoch: 5| Step: 7
Training loss: 0.17413677275180817
Validation loss: 1.4473768818762995

Epoch: 5| Step: 8
Training loss: 0.08261821419000626
Validation loss: 1.4507264699987186

Epoch: 5| Step: 9
Training loss: 0.09633934497833252
Validation loss: 1.4323816414802306

Epoch: 5| Step: 10
Training loss: 0.09820158034563065
Validation loss: 1.4066354882332586

Epoch: 519| Step: 0
Training loss: 0.10508432239294052
Validation loss: 1.424267359959182

Epoch: 5| Step: 1
Training loss: 0.10389874130487442
Validation loss: 1.4109888281873477

Epoch: 5| Step: 2
Training loss: 0.10276247560977936
Validation loss: 1.4349698635839647

Epoch: 5| Step: 3
Training loss: 0.06713540107011795
Validation loss: 1.4659717236795733

Epoch: 5| Step: 4
Training loss: 0.11901440471410751
Validation loss: 1.4629137503203524

Epoch: 5| Step: 5
Training loss: 0.11349938064813614
Validation loss: 1.4962593240122641

Epoch: 5| Step: 6
Training loss: 0.11656066030263901
Validation loss: 1.4742059438459334

Epoch: 5| Step: 7
Training loss: 0.20438814163208008
Validation loss: 1.4702141605397707

Epoch: 5| Step: 8
Training loss: 0.20353344082832336
Validation loss: 1.4438741873669367

Epoch: 5| Step: 9
Training loss: 0.09300367534160614
Validation loss: 1.4276105870482743

Epoch: 5| Step: 10
Training loss: 0.12316834181547165
Validation loss: 1.434992692803824

Epoch: 520| Step: 0
Training loss: 0.12858910858631134
Validation loss: 1.4119849756199827

Epoch: 5| Step: 1
Training loss: 0.12055909633636475
Validation loss: 1.3990542017003542

Epoch: 5| Step: 2
Training loss: 0.07772108167409897
Validation loss: 1.4070673937438636

Epoch: 5| Step: 3
Training loss: 0.13647130131721497
Validation loss: 1.391088221662788

Epoch: 5| Step: 4
Training loss: 0.12385785579681396
Validation loss: 1.4232894477023874

Epoch: 5| Step: 5
Training loss: 0.12075362354516983
Validation loss: 1.4566006224642518

Epoch: 5| Step: 6
Training loss: 0.1738634556531906
Validation loss: 1.4686880188603555

Epoch: 5| Step: 7
Training loss: 0.23251385986804962
Validation loss: 1.4683642150253378

Epoch: 5| Step: 8
Training loss: 0.10752490907907486
Validation loss: 1.511021807629575

Epoch: 5| Step: 9
Training loss: 0.14565041661262512
Validation loss: 1.4971106962491108

Epoch: 5| Step: 10
Training loss: 0.11114788055419922
Validation loss: 1.5135920124669229

Epoch: 521| Step: 0
Training loss: 0.1386122852563858
Validation loss: 1.489533293631769

Epoch: 5| Step: 1
Training loss: 0.06592662632465363
Validation loss: 1.454502901723308

Epoch: 5| Step: 2
Training loss: 0.09569995105266571
Validation loss: 1.4665175958346295

Epoch: 5| Step: 3
Training loss: 0.09177835285663605
Validation loss: 1.45174245103713

Epoch: 5| Step: 4
Training loss: 0.18256208300590515
Validation loss: 1.4381687154052079

Epoch: 5| Step: 5
Training loss: 0.1802532970905304
Validation loss: 1.4730469667783348

Epoch: 5| Step: 6
Training loss: 0.0897069051861763
Validation loss: 1.4410849950646842

Epoch: 5| Step: 7
Training loss: 0.11226983368396759
Validation loss: 1.4288072996242072

Epoch: 5| Step: 8
Training loss: 0.08641278743743896
Validation loss: 1.4488642408001808

Epoch: 5| Step: 9
Training loss: 0.2819076180458069
Validation loss: 1.4673846626794467

Epoch: 5| Step: 10
Training loss: 0.13088905811309814
Validation loss: 1.4654971373978483

Epoch: 522| Step: 0
Training loss: 0.17855224013328552
Validation loss: 1.4642447874110232

Epoch: 5| Step: 1
Training loss: 0.10451497882604599
Validation loss: 1.4348403843500281

Epoch: 5| Step: 2
Training loss: 0.08488978445529938
Validation loss: 1.4449170968865837

Epoch: 5| Step: 3
Training loss: 0.06294853985309601
Validation loss: 1.4242071208133493

Epoch: 5| Step: 4
Training loss: 0.14930102229118347
Validation loss: 1.4433973604632961

Epoch: 5| Step: 5
Training loss: 0.1611344814300537
Validation loss: 1.4649856744274017

Epoch: 5| Step: 6
Training loss: 0.19531263411045074
Validation loss: 1.4462169690798687

Epoch: 5| Step: 7
Training loss: 0.10078499466180801
Validation loss: 1.4430698579357517

Epoch: 5| Step: 8
Training loss: 0.129900261759758
Validation loss: 1.455070972442627

Epoch: 5| Step: 9
Training loss: 0.15142874419689178
Validation loss: 1.4375870599541614

Epoch: 5| Step: 10
Training loss: 0.15255114436149597
Validation loss: 1.4361925214849494

Epoch: 523| Step: 0
Training loss: 0.08958887308835983
Validation loss: 1.4557542044629332

Epoch: 5| Step: 1
Training loss: 0.08253474533557892
Validation loss: 1.4578751543516755

Epoch: 5| Step: 2
Training loss: 0.14245107769966125
Validation loss: 1.4675526772775958

Epoch: 5| Step: 3
Training loss: 0.11954406648874283
Validation loss: 1.48094513083017

Epoch: 5| Step: 4
Training loss: 0.12623243033885956
Validation loss: 1.4719547264037594

Epoch: 5| Step: 5
Training loss: 0.20699112117290497
Validation loss: 1.4641363947622237

Epoch: 5| Step: 6
Training loss: 0.08231396973133087
Validation loss: 1.4583983549507715

Epoch: 5| Step: 7
Training loss: 0.11701083183288574
Validation loss: 1.4375592534260084

Epoch: 5| Step: 8
Training loss: 0.1733309030532837
Validation loss: 1.4278490639502002

Epoch: 5| Step: 9
Training loss: 0.09497392922639847
Validation loss: 1.4118618965148926

Epoch: 5| Step: 10
Training loss: 0.05381394922733307
Validation loss: 1.4247117330951076

Epoch: 524| Step: 0
Training loss: 0.06420741975307465
Validation loss: 1.432227365432247

Epoch: 5| Step: 1
Training loss: 0.07353448122739792
Validation loss: 1.457279767400475

Epoch: 5| Step: 2
Training loss: 0.09509757161140442
Validation loss: 1.4352519627540343

Epoch: 5| Step: 3
Training loss: 0.18194063007831573
Validation loss: 1.465368854102268

Epoch: 5| Step: 4
Training loss: 0.09818805754184723
Validation loss: 1.4647391419256888

Epoch: 5| Step: 5
Training loss: 0.14838050305843353
Validation loss: 1.5069164101795485

Epoch: 5| Step: 6
Training loss: 0.058702558279037476
Validation loss: 1.4755568324878652

Epoch: 5| Step: 7
Training loss: 0.1844591647386551
Validation loss: 1.5038828542155604

Epoch: 5| Step: 8
Training loss: 0.13993893563747406
Validation loss: 1.499754403227119

Epoch: 5| Step: 9
Training loss: 0.09899964183568954
Validation loss: 1.4949049590736307

Epoch: 5| Step: 10
Training loss: 0.09015855938196182
Validation loss: 1.4456417573395597

Epoch: 525| Step: 0
Training loss: 0.18961724638938904
Validation loss: 1.4509919702365834

Epoch: 5| Step: 1
Training loss: 0.10125555843114853
Validation loss: 1.458066826225609

Epoch: 5| Step: 2
Training loss: 0.11085625737905502
Validation loss: 1.446671873010615

Epoch: 5| Step: 3
Training loss: 0.2968297600746155
Validation loss: 1.4448186171952115

Epoch: 5| Step: 4
Training loss: 0.097100630402565
Validation loss: 1.471328520005749

Epoch: 5| Step: 5
Training loss: 0.11602877080440521
Validation loss: 1.4784308043859338

Epoch: 5| Step: 6
Training loss: 0.11031298339366913
Validation loss: 1.455333807135141

Epoch: 5| Step: 7
Training loss: 0.1183895692229271
Validation loss: 1.4684890745788493

Epoch: 5| Step: 8
Training loss: 0.10267360508441925
Validation loss: 1.420809620170183

Epoch: 5| Step: 9
Training loss: 0.09510516375303268
Validation loss: 1.4303969862640544

Epoch: 5| Step: 10
Training loss: 0.15657949447631836
Validation loss: 1.428750717511741

Epoch: 526| Step: 0
Training loss: 0.269260972738266
Validation loss: 1.4264030353997343

Epoch: 5| Step: 1
Training loss: 0.08938294649124146
Validation loss: 1.4638451389087144

Epoch: 5| Step: 2
Training loss: 0.08241905272006989
Validation loss: 1.4415089936666592

Epoch: 5| Step: 3
Training loss: 0.12096450477838516
Validation loss: 1.455848096519388

Epoch: 5| Step: 4
Training loss: 0.09852435439825058
Validation loss: 1.4660228362647436

Epoch: 5| Step: 5
Training loss: 0.17679962515830994
Validation loss: 1.463601739175858

Epoch: 5| Step: 6
Training loss: 0.1328219622373581
Validation loss: 1.440188229724925

Epoch: 5| Step: 7
Training loss: 0.11230629682540894
Validation loss: 1.462681471660573

Epoch: 5| Step: 8
Training loss: 0.11669091135263443
Validation loss: 1.439462919389048

Epoch: 5| Step: 9
Training loss: 0.20398902893066406
Validation loss: 1.4536943281850507

Epoch: 5| Step: 10
Training loss: 0.10426531732082367
Validation loss: 1.4685203747082782

Epoch: 527| Step: 0
Training loss: 0.19373993575572968
Validation loss: 1.4830824969917216

Epoch: 5| Step: 1
Training loss: 0.1020486131310463
Validation loss: 1.4648406005674792

Epoch: 5| Step: 2
Training loss: 0.12457519769668579
Validation loss: 1.4291988534312094

Epoch: 5| Step: 3
Training loss: 0.1174689382314682
Validation loss: 1.4499496682997672

Epoch: 5| Step: 4
Training loss: 0.10290471464395523
Validation loss: 1.429403684472525

Epoch: 5| Step: 5
Training loss: 0.2107415646314621
Validation loss: 1.408221819067514

Epoch: 5| Step: 6
Training loss: 0.10557224601507187
Validation loss: 1.3901701704148324

Epoch: 5| Step: 7
Training loss: 0.19813546538352966
Validation loss: 1.4177604298437796

Epoch: 5| Step: 8
Training loss: 0.10192793607711792
Validation loss: 1.4150025447209675

Epoch: 5| Step: 9
Training loss: 0.13191208243370056
Validation loss: 1.4113075681912002

Epoch: 5| Step: 10
Training loss: 0.09395817667245865
Validation loss: 1.4266014682349337

Epoch: 528| Step: 0
Training loss: 0.08371374011039734
Validation loss: 1.4310360006106797

Epoch: 5| Step: 1
Training loss: 0.2726755142211914
Validation loss: 1.4374689985347051

Epoch: 5| Step: 2
Training loss: 0.22610673308372498
Validation loss: 1.4240180741074264

Epoch: 5| Step: 3
Training loss: 0.1253872960805893
Validation loss: 1.4475179859386977

Epoch: 5| Step: 4
Training loss: 0.20546579360961914
Validation loss: 1.421104476656965

Epoch: 5| Step: 5
Training loss: 0.1506923884153366
Validation loss: 1.431267874215239

Epoch: 5| Step: 6
Training loss: 0.10559268295764923
Validation loss: 1.41505531982709

Epoch: 5| Step: 7
Training loss: 0.14137622714042664
Validation loss: 1.4259540022060435

Epoch: 5| Step: 8
Training loss: 0.09246521443128586
Validation loss: 1.4511949298202351

Epoch: 5| Step: 9
Training loss: 0.1404140293598175
Validation loss: 1.4630009378156354

Epoch: 5| Step: 10
Training loss: 0.11186069995164871
Validation loss: 1.4809657617281842

Epoch: 529| Step: 0
Training loss: 0.2283366471529007
Validation loss: 1.4784060101355276

Epoch: 5| Step: 1
Training loss: 0.15314576029777527
Validation loss: 1.45775810492936

Epoch: 5| Step: 2
Training loss: 0.12194392830133438
Validation loss: 1.468045416698661

Epoch: 5| Step: 3
Training loss: 0.21406957507133484
Validation loss: 1.463905280636203

Epoch: 5| Step: 4
Training loss: 0.13267719745635986
Validation loss: 1.4817080613105529

Epoch: 5| Step: 5
Training loss: 0.10139511525630951
Validation loss: 1.469377040863037

Epoch: 5| Step: 6
Training loss: 0.09766187518835068
Validation loss: 1.443915440190223

Epoch: 5| Step: 7
Training loss: 0.1132870689034462
Validation loss: 1.4445967251254666

Epoch: 5| Step: 8
Training loss: 0.066422238945961
Validation loss: 1.4478805821429017

Epoch: 5| Step: 9
Training loss: 0.08698711544275284
Validation loss: 1.4568010683982604

Epoch: 5| Step: 10
Training loss: 0.1495361626148224
Validation loss: 1.4233496496754308

Epoch: 530| Step: 0
Training loss: 0.15937919914722443
Validation loss: 1.4228461455273371

Epoch: 5| Step: 1
Training loss: 0.09428702294826508
Validation loss: 1.3940161094870618

Epoch: 5| Step: 2
Training loss: 0.07161490619182587
Validation loss: 1.414315862040366

Epoch: 5| Step: 3
Training loss: 0.11279342323541641
Validation loss: 1.4203853555904922

Epoch: 5| Step: 4
Training loss: 0.11621314287185669
Validation loss: 1.4499887317739508

Epoch: 5| Step: 5
Training loss: 0.1680261641740799
Validation loss: 1.4472717713284236

Epoch: 5| Step: 6
Training loss: 0.2671932876110077
Validation loss: 1.465417004400684

Epoch: 5| Step: 7
Training loss: 0.1181618943810463
Validation loss: 1.470567322546436

Epoch: 5| Step: 8
Training loss: 0.0895647406578064
Validation loss: 1.4705281936994163

Epoch: 5| Step: 9
Training loss: 0.0918278619647026
Validation loss: 1.4507103991764847

Epoch: 5| Step: 10
Training loss: 0.09375983476638794
Validation loss: 1.4385188369340793

Epoch: 531| Step: 0
Training loss: 0.06876934319734573
Validation loss: 1.444501479466756

Epoch: 5| Step: 1
Training loss: 0.08338837325572968
Validation loss: 1.4762927537323327

Epoch: 5| Step: 2
Training loss: 0.1350136250257492
Validation loss: 1.4661615779322963

Epoch: 5| Step: 3
Training loss: 0.11769247055053711
Validation loss: 1.4705763401523713

Epoch: 5| Step: 4
Training loss: 0.23397457599639893
Validation loss: 1.4537347696160758

Epoch: 5| Step: 5
Training loss: 0.16452564299106598
Validation loss: 1.4902428683414255

Epoch: 5| Step: 6
Training loss: 0.22970351576805115
Validation loss: 1.4736605498098558

Epoch: 5| Step: 7
Training loss: 0.07854639738798141
Validation loss: 1.4680718580881755

Epoch: 5| Step: 8
Training loss: 0.12459196150302887
Validation loss: 1.4731242252934365

Epoch: 5| Step: 9
Training loss: 0.16460616886615753
Validation loss: 1.4870158126277309

Epoch: 5| Step: 10
Training loss: 0.1344079077243805
Validation loss: 1.4627658462011686

Epoch: 532| Step: 0
Training loss: 0.06805890053510666
Validation loss: 1.4556326840513496

Epoch: 5| Step: 1
Training loss: 0.1248132586479187
Validation loss: 1.4541641396860923

Epoch: 5| Step: 2
Training loss: 0.11236925423145294
Validation loss: 1.4331966600110453

Epoch: 5| Step: 3
Training loss: 0.10502518713474274
Validation loss: 1.4255026694267028

Epoch: 5| Step: 4
Training loss: 0.10950680077075958
Validation loss: 1.3941869235807849

Epoch: 5| Step: 5
Training loss: 0.07996781915426254
Validation loss: 1.4262702721421436

Epoch: 5| Step: 6
Training loss: 0.13218648731708527
Validation loss: 1.4670421590087235

Epoch: 5| Step: 7
Training loss: 0.12049243599176407
Validation loss: 1.4153866588428456

Epoch: 5| Step: 8
Training loss: 0.1686389446258545
Validation loss: 1.478760427044284

Epoch: 5| Step: 9
Training loss: 0.12383238971233368
Validation loss: 1.4921758687624367

Epoch: 5| Step: 10
Training loss: 0.2426942139863968
Validation loss: 1.469695432211763

Epoch: 533| Step: 0
Training loss: 0.1379031240940094
Validation loss: 1.4858601580383957

Epoch: 5| Step: 1
Training loss: 0.1137690320611
Validation loss: 1.506141028096599

Epoch: 5| Step: 2
Training loss: 0.1156206876039505
Validation loss: 1.5156844482626965

Epoch: 5| Step: 3
Training loss: 0.12822671234607697
Validation loss: 1.4881931094713108

Epoch: 5| Step: 4
Training loss: 0.08848436176776886
Validation loss: 1.4900527077336465

Epoch: 5| Step: 5
Training loss: 0.11275899410247803
Validation loss: 1.4760475966238207

Epoch: 5| Step: 6
Training loss: 0.10921034961938858
Validation loss: 1.458943437504512

Epoch: 5| Step: 7
Training loss: 0.0965995043516159
Validation loss: 1.4782021122594033

Epoch: 5| Step: 8
Training loss: 0.23580916225910187
Validation loss: 1.4559158945596347

Epoch: 5| Step: 9
Training loss: 0.15283837914466858
Validation loss: 1.4791096538625739

Epoch: 5| Step: 10
Training loss: 0.15142151713371277
Validation loss: 1.469919193175531

Epoch: 534| Step: 0
Training loss: 0.23508155345916748
Validation loss: 1.4702861744870421

Epoch: 5| Step: 1
Training loss: 0.10571514070034027
Validation loss: 1.4481942922838273

Epoch: 5| Step: 2
Training loss: 0.08556424826383591
Validation loss: 1.4479548777303388

Epoch: 5| Step: 3
Training loss: 0.10148145258426666
Validation loss: 1.4798453892430952

Epoch: 5| Step: 4
Training loss: 0.053628019988536835
Validation loss: 1.4854462249304659

Epoch: 5| Step: 5
Training loss: 0.1412995159626007
Validation loss: 1.4983096225287325

Epoch: 5| Step: 6
Training loss: 0.09441874921321869
Validation loss: 1.501035786444141

Epoch: 5| Step: 7
Training loss: 0.20864827930927277
Validation loss: 1.4945847949674052

Epoch: 5| Step: 8
Training loss: 0.11295900493860245
Validation loss: 1.4884866899059666

Epoch: 5| Step: 9
Training loss: 0.17194178700447083
Validation loss: 1.45645538965861

Epoch: 5| Step: 10
Training loss: 0.09159520268440247
Validation loss: 1.461164443723617

Epoch: 535| Step: 0
Training loss: 0.1769268810749054
Validation loss: 1.4832540071138771

Epoch: 5| Step: 1
Training loss: 0.1279207170009613
Validation loss: 1.433150347842965

Epoch: 5| Step: 2
Training loss: 0.06694044917821884
Validation loss: 1.4419176847703996

Epoch: 5| Step: 3
Training loss: 0.18496844172477722
Validation loss: 1.430433310488219

Epoch: 5| Step: 4
Training loss: 0.17550382018089294
Validation loss: 1.453635028613511

Epoch: 5| Step: 5
Training loss: 0.243617445230484
Validation loss: 1.4670465095068819

Epoch: 5| Step: 6
Training loss: 0.2022692859172821
Validation loss: 1.4791078734141525

Epoch: 5| Step: 7
Training loss: 0.13595148921012878
Validation loss: 1.466794390191314

Epoch: 5| Step: 8
Training loss: 0.12159378826618195
Validation loss: 1.4453858355040192

Epoch: 5| Step: 9
Training loss: 0.08054767549037933
Validation loss: 1.4450562660412123

Epoch: 5| Step: 10
Training loss: 0.07837829738855362
Validation loss: 1.4565474153846822

Epoch: 536| Step: 0
Training loss: 0.09452793747186661
Validation loss: 1.4354871729368806

Epoch: 5| Step: 1
Training loss: 0.10988727957010269
Validation loss: 1.4413844693091609

Epoch: 5| Step: 2
Training loss: 0.09553814679384232
Validation loss: 1.449775053608802

Epoch: 5| Step: 3
Training loss: 0.09525750577449799
Validation loss: 1.473080668398129

Epoch: 5| Step: 4
Training loss: 0.1626286506652832
Validation loss: 1.4711831993954156

Epoch: 5| Step: 5
Training loss: 0.17595592141151428
Validation loss: 1.4585859557633758

Epoch: 5| Step: 6
Training loss: 0.18377074599266052
Validation loss: 1.4575093151420675

Epoch: 5| Step: 7
Training loss: 0.10005499422550201
Validation loss: 1.4673302686342629

Epoch: 5| Step: 8
Training loss: 0.132746160030365
Validation loss: 1.477065808029585

Epoch: 5| Step: 9
Training loss: 0.11018329858779907
Validation loss: 1.4742502948289276

Epoch: 5| Step: 10
Training loss: 0.21742790937423706
Validation loss: 1.47104186396445

Epoch: 537| Step: 0
Training loss: 0.07034055143594742
Validation loss: 1.4660521646340687

Epoch: 5| Step: 1
Training loss: 0.1672745943069458
Validation loss: 1.4731266075564968

Epoch: 5| Step: 2
Training loss: 0.10639138519763947
Validation loss: 1.4321144588531987

Epoch: 5| Step: 3
Training loss: 0.29975512623786926
Validation loss: 1.4828456178788216

Epoch: 5| Step: 4
Training loss: 0.10540232807397842
Validation loss: 1.4395476079756213

Epoch: 5| Step: 5
Training loss: 0.09762609004974365
Validation loss: 1.4510834627254035

Epoch: 5| Step: 6
Training loss: 0.09496079385280609
Validation loss: 1.465730893996454

Epoch: 5| Step: 7
Training loss: 0.16599500179290771
Validation loss: 1.4801387017773044

Epoch: 5| Step: 8
Training loss: 0.08953993022441864
Validation loss: 1.4901923530845231

Epoch: 5| Step: 9
Training loss: 0.173050194978714
Validation loss: 1.4878178770824144

Epoch: 5| Step: 10
Training loss: 0.1047353744506836
Validation loss: 1.4851491117990145

Epoch: 538| Step: 0
Training loss: 0.07507598400115967
Validation loss: 1.4732578826206986

Epoch: 5| Step: 1
Training loss: 0.12864848971366882
Validation loss: 1.461744152730511

Epoch: 5| Step: 2
Training loss: 0.1204337626695633
Validation loss: 1.4640931314037693

Epoch: 5| Step: 3
Training loss: 0.08598773181438446
Validation loss: 1.4704537596753848

Epoch: 5| Step: 4
Training loss: 0.18607647716999054
Validation loss: 1.4754430420937077

Epoch: 5| Step: 5
Training loss: 0.05607440322637558
Validation loss: 1.471813299322641

Epoch: 5| Step: 6
Training loss: 0.22565360367298126
Validation loss: 1.463757755935833

Epoch: 5| Step: 7
Training loss: 0.06455724686384201
Validation loss: 1.4683164345320834

Epoch: 5| Step: 8
Training loss: 0.09916356950998306
Validation loss: 1.4613057990227976

Epoch: 5| Step: 9
Training loss: 0.07766761630773544
Validation loss: 1.4679392550581245

Epoch: 5| Step: 10
Training loss: 0.12123624235391617
Validation loss: 1.4467689914088095

Epoch: 539| Step: 0
Training loss: 0.07341887056827545
Validation loss: 1.4681404739297845

Epoch: 5| Step: 1
Training loss: 0.21208634972572327
Validation loss: 1.4551323177993938

Epoch: 5| Step: 2
Training loss: 0.0768313854932785
Validation loss: 1.4289209509408602

Epoch: 5| Step: 3
Training loss: 0.07499702274799347
Validation loss: 1.4558466019168976

Epoch: 5| Step: 4
Training loss: 0.22270090878009796
Validation loss: 1.4492343805169547

Epoch: 5| Step: 5
Training loss: 0.1154852882027626
Validation loss: 1.4421229695761075

Epoch: 5| Step: 6
Training loss: 0.12365420907735825
Validation loss: 1.4426013769641999

Epoch: 5| Step: 7
Training loss: 0.1259075105190277
Validation loss: 1.481352965037028

Epoch: 5| Step: 8
Training loss: 0.09068790823221207
Validation loss: 1.4842647275617045

Epoch: 5| Step: 9
Training loss: 0.10157428681850433
Validation loss: 1.4777020151897142

Epoch: 5| Step: 10
Training loss: 0.09762698411941528
Validation loss: 1.4651818711270568

Epoch: 540| Step: 0
Training loss: 0.1413693130016327
Validation loss: 1.4777458572900424

Epoch: 5| Step: 1
Training loss: 0.11386273056268692
Validation loss: 1.4729123647494982

Epoch: 5| Step: 2
Training loss: 0.06334476917982101
Validation loss: 1.4709106581185454

Epoch: 5| Step: 3
Training loss: 0.05350956320762634
Validation loss: 1.4700520743605912

Epoch: 5| Step: 4
Training loss: 0.08701120316982269
Validation loss: 1.4755251023077196

Epoch: 5| Step: 5
Training loss: 0.11586122214794159
Validation loss: 1.4776552646390853

Epoch: 5| Step: 6
Training loss: 0.0859636515378952
Validation loss: 1.4685182058683006

Epoch: 5| Step: 7
Training loss: 0.2158033549785614
Validation loss: 1.4761148652722758

Epoch: 5| Step: 8
Training loss: 0.2130233496427536
Validation loss: 1.460445882171713

Epoch: 5| Step: 9
Training loss: 0.1297118216753006
Validation loss: 1.469968762449039

Epoch: 5| Step: 10
Training loss: 0.1025233343243599
Validation loss: 1.458572672259423

Epoch: 541| Step: 0
Training loss: 0.07615917921066284
Validation loss: 1.4573169997943345

Epoch: 5| Step: 1
Training loss: 0.07262690365314484
Validation loss: 1.439398314363213

Epoch: 5| Step: 2
Training loss: 0.11923756450414658
Validation loss: 1.4356374689327773

Epoch: 5| Step: 3
Training loss: 0.0924338772892952
Validation loss: 1.4334961201554985

Epoch: 5| Step: 4
Training loss: 0.0832047089934349
Validation loss: 1.4457823063737603

Epoch: 5| Step: 5
Training loss: 0.13299314677715302
Validation loss: 1.4347700982965448

Epoch: 5| Step: 6
Training loss: 0.07677777856588364
Validation loss: 1.4410685262372416

Epoch: 5| Step: 7
Training loss: 0.15561890602111816
Validation loss: 1.4519318649845738

Epoch: 5| Step: 8
Training loss: 0.1020069569349289
Validation loss: 1.4569395870290778

Epoch: 5| Step: 9
Training loss: 0.24102506041526794
Validation loss: 1.4524853191068094

Epoch: 5| Step: 10
Training loss: 0.11154192686080933
Validation loss: 1.4742186069488525

Epoch: 542| Step: 0
Training loss: 0.0967765524983406
Validation loss: 1.4603543935283538

Epoch: 5| Step: 1
Training loss: 0.19310203194618225
Validation loss: 1.4437781803069576

Epoch: 5| Step: 2
Training loss: 0.11739858239889145
Validation loss: 1.4774101421397219

Epoch: 5| Step: 3
Training loss: 0.15227344632148743
Validation loss: 1.4596402837384133

Epoch: 5| Step: 4
Training loss: 0.08648528158664703
Validation loss: 1.4420899755211287

Epoch: 5| Step: 5
Training loss: 0.2146172970533371
Validation loss: 1.4506825759846678

Epoch: 5| Step: 6
Training loss: 0.08536793291568756
Validation loss: 1.4515462844602522

Epoch: 5| Step: 7
Training loss: 0.0639483705163002
Validation loss: 1.4594256134443386

Epoch: 5| Step: 8
Training loss: 0.07104172557592392
Validation loss: 1.4615676582500499

Epoch: 5| Step: 9
Training loss: 0.11141357570886612
Validation loss: 1.4932031862197384

Epoch: 5| Step: 10
Training loss: 0.08361931145191193
Validation loss: 1.4920078080187562

Epoch: 543| Step: 0
Training loss: 0.11078115552663803
Validation loss: 1.4983417981414384

Epoch: 5| Step: 1
Training loss: 0.1130513995885849
Validation loss: 1.5110501755950272

Epoch: 5| Step: 2
Training loss: 0.0963125079870224
Validation loss: 1.5077062627320648

Epoch: 5| Step: 3
Training loss: 0.2012779265642166
Validation loss: 1.4937481470005487

Epoch: 5| Step: 4
Training loss: 0.06294574588537216
Validation loss: 1.4878500725633355

Epoch: 5| Step: 5
Training loss: 0.1414649933576584
Validation loss: 1.4802302788662653

Epoch: 5| Step: 6
Training loss: 0.10443657636642456
Validation loss: 1.4342369161626345

Epoch: 5| Step: 7
Training loss: 0.17897653579711914
Validation loss: 1.4479683624800814

Epoch: 5| Step: 8
Training loss: 0.14062662422657013
Validation loss: 1.4385553412539984

Epoch: 5| Step: 9
Training loss: 0.10428319126367569
Validation loss: 1.421726684096039

Epoch: 5| Step: 10
Training loss: 0.09636445343494415
Validation loss: 1.4497866489553963

Epoch: 544| Step: 0
Training loss: 0.09250251948833466
Validation loss: 1.4545361149695613

Epoch: 5| Step: 1
Training loss: 0.09886918216943741
Validation loss: 1.4589850236010808

Epoch: 5| Step: 2
Training loss: 0.09476065635681152
Validation loss: 1.4395273853373785

Epoch: 5| Step: 3
Training loss: 0.11657249927520752
Validation loss: 1.4248609286482616

Epoch: 5| Step: 4
Training loss: 0.24740540981292725
Validation loss: 1.4352966111193421

Epoch: 5| Step: 5
Training loss: 0.19923076033592224
Validation loss: 1.4569660489277174

Epoch: 5| Step: 6
Training loss: 0.11093311011791229
Validation loss: 1.450274730241427

Epoch: 5| Step: 7
Training loss: 0.0758155956864357
Validation loss: 1.4459926594970047

Epoch: 5| Step: 8
Training loss: 0.08263570815324783
Validation loss: 1.4412147486081688

Epoch: 5| Step: 9
Training loss: 0.08309618383646011
Validation loss: 1.4814993014899633

Epoch: 5| Step: 10
Training loss: 0.04824119061231613
Validation loss: 1.4684350349569832

Epoch: 545| Step: 0
Training loss: 0.12071134895086288
Validation loss: 1.4881160579701906

Epoch: 5| Step: 1
Training loss: 0.12604215741157532
Validation loss: 1.4935857788208993

Epoch: 5| Step: 2
Training loss: 0.0938379317522049
Validation loss: 1.48936419076817

Epoch: 5| Step: 3
Training loss: 0.10744044929742813
Validation loss: 1.4760796434135848

Epoch: 5| Step: 4
Training loss: 0.12697036564350128
Validation loss: 1.460592557025212

Epoch: 5| Step: 5
Training loss: 0.053307484835386276
Validation loss: 1.465947292184317

Epoch: 5| Step: 6
Training loss: 0.11127917468547821
Validation loss: 1.4647049852596816

Epoch: 5| Step: 7
Training loss: 0.16575074195861816
Validation loss: 1.444004480556775

Epoch: 5| Step: 8
Training loss: 0.09736542403697968
Validation loss: 1.4706365369981336

Epoch: 5| Step: 9
Training loss: 0.20051054656505585
Validation loss: 1.4533189150594896

Epoch: 5| Step: 10
Training loss: 0.12650421261787415
Validation loss: 1.4626502990722656

Epoch: 546| Step: 0
Training loss: 0.07562112808227539
Validation loss: 1.4724256710339618

Epoch: 5| Step: 1
Training loss: 0.10497303307056427
Validation loss: 1.4852954604292428

Epoch: 5| Step: 2
Training loss: 0.06973570585250854
Validation loss: 1.4603376132185741

Epoch: 5| Step: 3
Training loss: 0.21596267819404602
Validation loss: 1.4518208619086974

Epoch: 5| Step: 4
Training loss: 0.08147051185369492
Validation loss: 1.4815690478970927

Epoch: 5| Step: 5
Training loss: 0.07780071347951889
Validation loss: 1.44854175659918

Epoch: 5| Step: 6
Training loss: 0.1689908504486084
Validation loss: 1.4644696045947332

Epoch: 5| Step: 7
Training loss: 0.10406075417995453
Validation loss: 1.490908863723919

Epoch: 5| Step: 8
Training loss: 0.11181819438934326
Validation loss: 1.4437164145131265

Epoch: 5| Step: 9
Training loss: 0.055762410163879395
Validation loss: 1.4665508718900784

Epoch: 5| Step: 10
Training loss: 0.0826231837272644
Validation loss: 1.4444775273722987

Epoch: 547| Step: 0
Training loss: 0.11377815157175064
Validation loss: 1.4490065702828028

Epoch: 5| Step: 1
Training loss: 0.09326324611902237
Validation loss: 1.4680025353226611

Epoch: 5| Step: 2
Training loss: 0.07668627798557281
Validation loss: 1.4594110993928806

Epoch: 5| Step: 3
Training loss: 0.12494315207004547
Validation loss: 1.4456829281263455

Epoch: 5| Step: 4
Training loss: 0.158179372549057
Validation loss: 1.4650187453915995

Epoch: 5| Step: 5
Training loss: 0.08116364479064941
Validation loss: 1.453531667750369

Epoch: 5| Step: 6
Training loss: 0.11397445201873779
Validation loss: 1.4783988896236624

Epoch: 5| Step: 7
Training loss: 0.06928595900535583
Validation loss: 1.474715969895804

Epoch: 5| Step: 8
Training loss: 0.23880691826343536
Validation loss: 1.4815163490592793

Epoch: 5| Step: 9
Training loss: 0.06679437309503555
Validation loss: 1.4765793559371785

Epoch: 5| Step: 10
Training loss: 0.07615140080451965
Validation loss: 1.434307006097609

Epoch: 548| Step: 0
Training loss: 0.17597858607769012
Validation loss: 1.441245339250052

Epoch: 5| Step: 1
Training loss: 0.081611268222332
Validation loss: 1.4438404742107596

Epoch: 5| Step: 2
Training loss: 0.08197059482336044
Validation loss: 1.467326336009528

Epoch: 5| Step: 3
Training loss: 0.07488679885864258
Validation loss: 1.4287431227263583

Epoch: 5| Step: 4
Training loss: 0.07294006645679474
Validation loss: 1.4382295993066603

Epoch: 5| Step: 5
Training loss: 0.07670551538467407
Validation loss: 1.4384274303272206

Epoch: 5| Step: 6
Training loss: 0.07057160884141922
Validation loss: 1.4295457922002321

Epoch: 5| Step: 7
Training loss: 0.09906194359064102
Validation loss: 1.4115812996382355

Epoch: 5| Step: 8
Training loss: 0.06754304468631744
Validation loss: 1.4446378971940728

Epoch: 5| Step: 9
Training loss: 0.15554432570934296
Validation loss: 1.4604236861710906

Epoch: 5| Step: 10
Training loss: 0.20051288604736328
Validation loss: 1.4710068792425177

Epoch: 549| Step: 0
Training loss: 0.10829677432775497
Validation loss: 1.4629082961749005

Epoch: 5| Step: 1
Training loss: 0.17395512759685516
Validation loss: 1.4467760414205573

Epoch: 5| Step: 2
Training loss: 0.049600373953580856
Validation loss: 1.450199092588117

Epoch: 5| Step: 3
Training loss: 0.08878123015165329
Validation loss: 1.4519251469642884

Epoch: 5| Step: 4
Training loss: 0.1117485985159874
Validation loss: 1.4635893978098387

Epoch: 5| Step: 5
Training loss: 0.08872682601213455
Validation loss: 1.4553843384147973

Epoch: 5| Step: 6
Training loss: 0.09942452609539032
Validation loss: 1.4213568536184167

Epoch: 5| Step: 7
Training loss: 0.21291205286979675
Validation loss: 1.452364593423823

Epoch: 5| Step: 8
Training loss: 0.06146740913391113
Validation loss: 1.4245562322678105

Epoch: 5| Step: 9
Training loss: 0.10386975109577179
Validation loss: 1.421666105588277

Epoch: 5| Step: 10
Training loss: 0.1322702318429947
Validation loss: 1.454498944103077

Epoch: 550| Step: 0
Training loss: 0.10184941440820694
Validation loss: 1.454926106237596

Epoch: 5| Step: 1
Training loss: 0.08280931413173676
Validation loss: 1.4502134989666682

Epoch: 5| Step: 2
Training loss: 0.16127406060695648
Validation loss: 1.4584937428915372

Epoch: 5| Step: 3
Training loss: 0.13462623953819275
Validation loss: 1.4456970781408331

Epoch: 5| Step: 4
Training loss: 0.15249618887901306
Validation loss: 1.4341037837407922

Epoch: 5| Step: 5
Training loss: 0.08350735902786255
Validation loss: 1.4175540067816292

Epoch: 5| Step: 6
Training loss: 0.07463278621435165
Validation loss: 1.469303434894931

Epoch: 5| Step: 7
Training loss: 0.10448187589645386
Validation loss: 1.4516303629003546

Epoch: 5| Step: 8
Training loss: 0.08013278245925903
Validation loss: 1.4578744890869304

Epoch: 5| Step: 9
Training loss: 0.178365558385849
Validation loss: 1.4680712690917395

Epoch: 5| Step: 10
Training loss: 0.21747972071170807
Validation loss: 1.4522108377948884

Epoch: 551| Step: 0
Training loss: 0.08964286744594574
Validation loss: 1.4543530671827254

Epoch: 5| Step: 1
Training loss: 0.10272903740406036
Validation loss: 1.4240527383742794

Epoch: 5| Step: 2
Training loss: 0.21724700927734375
Validation loss: 1.4313423697666456

Epoch: 5| Step: 3
Training loss: 0.106772780418396
Validation loss: 1.4472314990976805

Epoch: 5| Step: 4
Training loss: 0.07967384904623032
Validation loss: 1.421286517573941

Epoch: 5| Step: 5
Training loss: 0.18076594173908234
Validation loss: 1.4094266878661288

Epoch: 5| Step: 6
Training loss: 0.12347038090229034
Validation loss: 1.4397074278964792

Epoch: 5| Step: 7
Training loss: 0.07515858113765717
Validation loss: 1.4302925973810174

Epoch: 5| Step: 8
Training loss: 0.09416680037975311
Validation loss: 1.438216519612138

Epoch: 5| Step: 9
Training loss: 0.09408123046159744
Validation loss: 1.4328929775504655

Epoch: 5| Step: 10
Training loss: 0.09622359275817871
Validation loss: 1.4374092022577922

Epoch: 552| Step: 0
Training loss: 0.25908297300338745
Validation loss: 1.4356590509414673

Epoch: 5| Step: 1
Training loss: 0.10427455604076385
Validation loss: 1.415976566653098

Epoch: 5| Step: 2
Training loss: 0.08409576117992401
Validation loss: 1.416244238935491

Epoch: 5| Step: 3
Training loss: 0.14490507543087006
Validation loss: 1.4126840329939319

Epoch: 5| Step: 4
Training loss: 0.07171396911144257
Validation loss: 1.427917670178157

Epoch: 5| Step: 5
Training loss: 0.09253530204296112
Validation loss: 1.3955240108633553

Epoch: 5| Step: 6
Training loss: 0.08023303002119064
Validation loss: 1.4136196041619906

Epoch: 5| Step: 7
Training loss: 0.08640986680984497
Validation loss: 1.3703917777666481

Epoch: 5| Step: 8
Training loss: 0.05980806425213814
Validation loss: 1.395877645861718

Epoch: 5| Step: 9
Training loss: 0.09218819439411163
Validation loss: 1.3976742875191472

Epoch: 5| Step: 10
Training loss: 0.09697302430868149
Validation loss: 1.4402675615843905

Epoch: 553| Step: 0
Training loss: 0.20128540694713593
Validation loss: 1.4182998377789733

Epoch: 5| Step: 1
Training loss: 0.14648029208183289
Validation loss: 1.4525356933634768

Epoch: 5| Step: 2
Training loss: 0.09810401499271393
Validation loss: 1.4593864025608185

Epoch: 5| Step: 3
Training loss: 0.08485520631074905
Validation loss: 1.4740522587171165

Epoch: 5| Step: 4
Training loss: 0.059912823140621185
Validation loss: 1.447784379605324

Epoch: 5| Step: 5
Training loss: 0.15071900188922882
Validation loss: 1.4751041691790345

Epoch: 5| Step: 6
Training loss: 0.15645144879817963
Validation loss: 1.4633754466169624

Epoch: 5| Step: 7
Training loss: 0.10544753074645996
Validation loss: 1.4542379789454962

Epoch: 5| Step: 8
Training loss: 0.0758180022239685
Validation loss: 1.4418062394665134

Epoch: 5| Step: 9
Training loss: 0.09523731470108032
Validation loss: 1.4447991399354831

Epoch: 5| Step: 10
Training loss: 0.06587705761194229
Validation loss: 1.444572138529952

Epoch: 554| Step: 0
Training loss: 0.0710260346531868
Validation loss: 1.444021067311687

Epoch: 5| Step: 1
Training loss: 0.08709146082401276
Validation loss: 1.4567571545159945

Epoch: 5| Step: 2
Training loss: 0.08347927778959274
Validation loss: 1.461752232684884

Epoch: 5| Step: 3
Training loss: 0.17905521392822266
Validation loss: 1.426040796823399

Epoch: 5| Step: 4
Training loss: 0.09865492582321167
Validation loss: 1.4104836769001459

Epoch: 5| Step: 5
Training loss: 0.16127349436283112
Validation loss: 1.3890304475702264

Epoch: 5| Step: 6
Training loss: 0.06362639367580414
Validation loss: 1.4077620833150801

Epoch: 5| Step: 7
Training loss: 0.0722443014383316
Validation loss: 1.4264220832496561

Epoch: 5| Step: 8
Training loss: 0.08989222347736359
Validation loss: 1.4322274756687943

Epoch: 5| Step: 9
Training loss: 0.1156545877456665
Validation loss: 1.4329476048869472

Epoch: 5| Step: 10
Training loss: 0.10363925248384476
Validation loss: 1.4408270082166117

Epoch: 555| Step: 0
Training loss: 0.11292757838964462
Validation loss: 1.440910711083361

Epoch: 5| Step: 1
Training loss: 0.08956090360879898
Validation loss: 1.4262182404918056

Epoch: 5| Step: 2
Training loss: 0.06389184296131134
Validation loss: 1.4242018986773748

Epoch: 5| Step: 3
Training loss: 0.18330597877502441
Validation loss: 1.4213942007351947

Epoch: 5| Step: 4
Training loss: 0.07983674108982086
Validation loss: 1.434450953237472

Epoch: 5| Step: 5
Training loss: 0.09075208753347397
Validation loss: 1.4172199592795423

Epoch: 5| Step: 6
Training loss: 0.07694236934185028
Validation loss: 1.4194139818991385

Epoch: 5| Step: 7
Training loss: 0.0954771637916565
Validation loss: 1.446008022113513

Epoch: 5| Step: 8
Training loss: 0.16215169429779053
Validation loss: 1.4294148234910862

Epoch: 5| Step: 9
Training loss: 0.06909219175577164
Validation loss: 1.4615664277025449

Epoch: 5| Step: 10
Training loss: 0.07822384685277939
Validation loss: 1.441245803269007

Epoch: 556| Step: 0
Training loss: 0.11782578378915787
Validation loss: 1.4303840168060795

Epoch: 5| Step: 1
Training loss: 0.07699987292289734
Validation loss: 1.4532644864051574

Epoch: 5| Step: 2
Training loss: 0.18277812004089355
Validation loss: 1.4354636412794872

Epoch: 5| Step: 3
Training loss: 0.09724009037017822
Validation loss: 1.4735183574820077

Epoch: 5| Step: 4
Training loss: 0.13190187513828278
Validation loss: 1.4420884334912865

Epoch: 5| Step: 5
Training loss: 0.0942455604672432
Validation loss: 1.460327144592039

Epoch: 5| Step: 6
Training loss: 0.12880373001098633
Validation loss: 1.466134709696616

Epoch: 5| Step: 7
Training loss: 0.1292603313922882
Validation loss: 1.436755104731488

Epoch: 5| Step: 8
Training loss: 0.07669611275196075
Validation loss: 1.41209763608953

Epoch: 5| Step: 9
Training loss: 0.13073119521141052
Validation loss: 1.404923972263131

Epoch: 5| Step: 10
Training loss: 0.0884237065911293
Validation loss: 1.413651507387879

Epoch: 557| Step: 0
Training loss: 0.13936857879161835
Validation loss: 1.3590485716378817

Epoch: 5| Step: 1
Training loss: 0.08295881003141403
Validation loss: 1.4077081936661915

Epoch: 5| Step: 2
Training loss: 0.13293349742889404
Validation loss: 1.4186743664485153

Epoch: 5| Step: 3
Training loss: 0.1232932060956955
Validation loss: 1.4246129432032186

Epoch: 5| Step: 4
Training loss: 0.15853999555110931
Validation loss: 1.432273257163263

Epoch: 5| Step: 5
Training loss: 0.06387560814619064
Validation loss: 1.469573320881013

Epoch: 5| Step: 6
Training loss: 0.08241153508424759
Validation loss: 1.4761753864185785

Epoch: 5| Step: 7
Training loss: 0.07169999182224274
Validation loss: 1.4462993189852724

Epoch: 5| Step: 8
Training loss: 0.05681707710027695
Validation loss: 1.449581890977839

Epoch: 5| Step: 9
Training loss: 0.04750857502222061
Validation loss: 1.44217050075531

Epoch: 5| Step: 10
Training loss: 0.09035784006118774
Validation loss: 1.4285636525000296

Epoch: 558| Step: 0
Training loss: 0.06729509681463242
Validation loss: 1.4224524574895059

Epoch: 5| Step: 1
Training loss: 0.10395242273807526
Validation loss: 1.4293572261769285

Epoch: 5| Step: 2
Training loss: 0.10596821457147598
Validation loss: 1.412335822659154

Epoch: 5| Step: 3
Training loss: 0.10457976162433624
Validation loss: 1.4324078341966033

Epoch: 5| Step: 4
Training loss: 0.07752940058708191
Validation loss: 1.4423939669004051

Epoch: 5| Step: 5
Training loss: 0.12748193740844727
Validation loss: 1.421227579475731

Epoch: 5| Step: 6
Training loss: 0.10685130208730698
Validation loss: 1.440633617421632

Epoch: 5| Step: 7
Training loss: 0.07385070621967316
Validation loss: 1.4406661218212498

Epoch: 5| Step: 8
Training loss: 0.08220674097537994
Validation loss: 1.4517705568703272

Epoch: 5| Step: 9
Training loss: 0.17691469192504883
Validation loss: 1.4350841135107062

Epoch: 5| Step: 10
Training loss: 0.09254715591669083
Validation loss: 1.4429589932964695

Epoch: 559| Step: 0
Training loss: 0.0644555389881134
Validation loss: 1.4730636791516376

Epoch: 5| Step: 1
Training loss: 0.09208609163761139
Validation loss: 1.4574301294101182

Epoch: 5| Step: 2
Training loss: 0.10080628097057343
Validation loss: 1.4352385997772217

Epoch: 5| Step: 3
Training loss: 0.06374537199735641
Validation loss: 1.4427670496766285

Epoch: 5| Step: 4
Training loss: 0.08194943517446518
Validation loss: 1.423758811848138

Epoch: 5| Step: 5
Training loss: 0.07878635823726654
Validation loss: 1.4335412966307772

Epoch: 5| Step: 6
Training loss: 0.07529658824205399
Validation loss: 1.4416252554103892

Epoch: 5| Step: 7
Training loss: 0.10067339986562729
Validation loss: 1.4402592271886847

Epoch: 5| Step: 8
Training loss: 0.26289016008377075
Validation loss: 1.4349123867609168

Epoch: 5| Step: 9
Training loss: 0.07177329808473587
Validation loss: 1.4507934239602858

Epoch: 5| Step: 10
Training loss: 0.0587981753051281
Validation loss: 1.453910138658298

Epoch: 560| Step: 0
Training loss: 0.07938537001609802
Validation loss: 1.4251788790507982

Epoch: 5| Step: 1
Training loss: 0.11228381097316742
Validation loss: 1.4367372412835397

Epoch: 5| Step: 2
Training loss: 0.09903264045715332
Validation loss: 1.4563142920053134

Epoch: 5| Step: 3
Training loss: 0.10836329311132431
Validation loss: 1.4330604473749797

Epoch: 5| Step: 4
Training loss: 0.0989641398191452
Validation loss: 1.4321725163408505

Epoch: 5| Step: 5
Training loss: 0.07993606477975845
Validation loss: 1.4179729030978294

Epoch: 5| Step: 6
Training loss: 0.08914607018232346
Validation loss: 1.4076085327773966

Epoch: 5| Step: 7
Training loss: 0.09774555265903473
Validation loss: 1.435584266980489

Epoch: 5| Step: 8
Training loss: 0.10300038009881973
Validation loss: 1.4126087837321784

Epoch: 5| Step: 9
Training loss: 0.0804942175745964
Validation loss: 1.4318875023113784

Epoch: 5| Step: 10
Training loss: 0.17275485396385193
Validation loss: 1.4268760886243594

Epoch: 561| Step: 0
Training loss: 0.05775372311472893
Validation loss: 1.4187629786870812

Epoch: 5| Step: 1
Training loss: 0.04776468500494957
Validation loss: 1.4404704686134093

Epoch: 5| Step: 2
Training loss: 0.07724277675151825
Validation loss: 1.4190226844561997

Epoch: 5| Step: 3
Training loss: 0.1320313960313797
Validation loss: 1.4235730376294864

Epoch: 5| Step: 4
Training loss: 0.1026388630270958
Validation loss: 1.4322453647531488

Epoch: 5| Step: 5
Training loss: 0.13173583149909973
Validation loss: 1.4240548649141866

Epoch: 5| Step: 6
Training loss: 0.09598008543252945
Validation loss: 1.4399128402433088

Epoch: 5| Step: 7
Training loss: 0.1962445229291916
Validation loss: 1.4314733730849398

Epoch: 5| Step: 8
Training loss: 0.10093623399734497
Validation loss: 1.4418419304714407

Epoch: 5| Step: 9
Training loss: 0.08732526004314423
Validation loss: 1.4536114533742268

Epoch: 5| Step: 10
Training loss: 0.050025295466184616
Validation loss: 1.449391431705926

Epoch: 562| Step: 0
Training loss: 0.16239438951015472
Validation loss: 1.434860384592446

Epoch: 5| Step: 1
Training loss: 0.15274770557880402
Validation loss: 1.4412871317196918

Epoch: 5| Step: 2
Training loss: 0.08836594969034195
Validation loss: 1.459109616535966

Epoch: 5| Step: 3
Training loss: 0.10506196320056915
Validation loss: 1.427188584240534

Epoch: 5| Step: 4
Training loss: 0.07706059515476227
Validation loss: 1.4440704314939437

Epoch: 5| Step: 5
Training loss: 0.08901047706604004
Validation loss: 1.4384756511257542

Epoch: 5| Step: 6
Training loss: 0.059960197657346725
Validation loss: 1.4290013223566034

Epoch: 5| Step: 7
Training loss: 0.09317431598901749
Validation loss: 1.4186906173665037

Epoch: 5| Step: 8
Training loss: 0.08249631524085999
Validation loss: 1.4410871036591069

Epoch: 5| Step: 9
Training loss: 0.14221718907356262
Validation loss: 1.427441156038674

Epoch: 5| Step: 10
Training loss: 0.08803887665271759
Validation loss: 1.4245360673114817

Epoch: 563| Step: 0
Training loss: 0.0722082108259201
Validation loss: 1.4255610896695046

Epoch: 5| Step: 1
Training loss: 0.11821148544549942
Validation loss: 1.4464401147698844

Epoch: 5| Step: 2
Training loss: 0.0736045390367508
Validation loss: 1.4303195963623703

Epoch: 5| Step: 3
Training loss: 0.09638725221157074
Validation loss: 1.4503725395407727

Epoch: 5| Step: 4
Training loss: 0.1413196474313736
Validation loss: 1.434476270470568

Epoch: 5| Step: 5
Training loss: 0.07841415703296661
Validation loss: 1.4371298859196324

Epoch: 5| Step: 6
Training loss: 0.07088039070367813
Validation loss: 1.401087684656984

Epoch: 5| Step: 7
Training loss: 0.08266254514455795
Validation loss: 1.406348604027943

Epoch: 5| Step: 8
Training loss: 0.15594804286956787
Validation loss: 1.416892356770013

Epoch: 5| Step: 9
Training loss: 0.21209463477134705
Validation loss: 1.4303582906723022

Epoch: 5| Step: 10
Training loss: 0.09981010109186172
Validation loss: 1.4532150735137284

Epoch: 564| Step: 0
Training loss: 0.09972082078456879
Validation loss: 1.452049142570906

Epoch: 5| Step: 1
Training loss: 0.09412573277950287
Validation loss: 1.4584557766555457

Epoch: 5| Step: 2
Training loss: 0.08051414787769318
Validation loss: 1.4504416040194932

Epoch: 5| Step: 3
Training loss: 0.08310060203075409
Validation loss: 1.4350981250885995

Epoch: 5| Step: 4
Training loss: 0.07456491887569427
Validation loss: 1.4850468815013926

Epoch: 5| Step: 5
Training loss: 0.12112259864807129
Validation loss: 1.4832314086216751

Epoch: 5| Step: 6
Training loss: 0.13073541224002838
Validation loss: 1.4661055726389731

Epoch: 5| Step: 7
Training loss: 0.16727052628993988
Validation loss: 1.431087770769673

Epoch: 5| Step: 8
Training loss: 0.15514220297336578
Validation loss: 1.4487369227153

Epoch: 5| Step: 9
Training loss: 0.08058375120162964
Validation loss: 1.4269864610446397

Epoch: 5| Step: 10
Training loss: 0.07731523364782333
Validation loss: 1.4346213251031854

Epoch: 565| Step: 0
Training loss: 0.07562781125307083
Validation loss: 1.4016630675203057

Epoch: 5| Step: 1
Training loss: 0.19643917679786682
Validation loss: 1.4099292396217264

Epoch: 5| Step: 2
Training loss: 0.07835495471954346
Validation loss: 1.4175637627160678

Epoch: 5| Step: 3
Training loss: 0.0569143071770668
Validation loss: 1.4320288858106058

Epoch: 5| Step: 4
Training loss: 0.10878413915634155
Validation loss: 1.4559820057243429

Epoch: 5| Step: 5
Training loss: 0.06540247797966003
Validation loss: 1.4380855047574608

Epoch: 5| Step: 6
Training loss: 0.08302365243434906
Validation loss: 1.434300627759708

Epoch: 5| Step: 7
Training loss: 0.11365129798650742
Validation loss: 1.4559875842063659

Epoch: 5| Step: 8
Training loss: 0.09375564754009247
Validation loss: 1.4186967739494898

Epoch: 5| Step: 9
Training loss: 0.04609190672636032
Validation loss: 1.4105894129763368

Epoch: 5| Step: 10
Training loss: 0.15148261189460754
Validation loss: 1.4220622624120405

Epoch: 566| Step: 0
Training loss: 0.0883326381444931
Validation loss: 1.3978502583760086

Epoch: 5| Step: 1
Training loss: 0.13436134159564972
Validation loss: 1.419669193606223

Epoch: 5| Step: 2
Training loss: 0.10372480005025864
Validation loss: 1.4358093559101064

Epoch: 5| Step: 3
Training loss: 0.0990632027387619
Validation loss: 1.4415645727547266

Epoch: 5| Step: 4
Training loss: 0.08183751255273819
Validation loss: 1.3964168845966298

Epoch: 5| Step: 5
Training loss: 0.13885274529457092
Validation loss: 1.4199284507382302

Epoch: 5| Step: 6
Training loss: 0.1376962661743164
Validation loss: 1.4172543735914334

Epoch: 5| Step: 7
Training loss: 0.05568397045135498
Validation loss: 1.4089631771528592

Epoch: 5| Step: 8
Training loss: 0.11597119271755219
Validation loss: 1.4315986005208825

Epoch: 5| Step: 9
Training loss: 0.0753282755613327
Validation loss: 1.430252460382318

Epoch: 5| Step: 10
Training loss: 0.12035222351551056
Validation loss: 1.4114137170135335

Epoch: 567| Step: 0
Training loss: 0.06312911212444305
Validation loss: 1.4320998153378885

Epoch: 5| Step: 1
Training loss: 0.09231626987457275
Validation loss: 1.4146030513189172

Epoch: 5| Step: 2
Training loss: 0.11129949241876602
Validation loss: 1.382764402256217

Epoch: 5| Step: 3
Training loss: 0.09431581199169159
Validation loss: 1.4080433153337049

Epoch: 5| Step: 4
Training loss: 0.1699325144290924
Validation loss: 1.4165726451463596

Epoch: 5| Step: 5
Training loss: 0.058276206254959106
Validation loss: 1.4040307998657227

Epoch: 5| Step: 6
Training loss: 0.0969027504324913
Validation loss: 1.419811725616455

Epoch: 5| Step: 7
Training loss: 0.17086336016654968
Validation loss: 1.4284178287752214

Epoch: 5| Step: 8
Training loss: 0.05855240672826767
Validation loss: 1.4199082742455185

Epoch: 5| Step: 9
Training loss: 0.09340831637382507
Validation loss: 1.4428726652617097

Epoch: 5| Step: 10
Training loss: 0.09904014319181442
Validation loss: 1.4078762685098956

Epoch: 568| Step: 0
Training loss: 0.07537778466939926
Validation loss: 1.417494841801223

Epoch: 5| Step: 1
Training loss: 0.08896845579147339
Validation loss: 1.4204841275368967

Epoch: 5| Step: 2
Training loss: 0.04353408142924309
Validation loss: 1.4209573614981867

Epoch: 5| Step: 3
Training loss: 0.06780650466680527
Validation loss: 1.4052879169423094

Epoch: 5| Step: 4
Training loss: 0.07980330288410187
Validation loss: 1.3771754310977073

Epoch: 5| Step: 5
Training loss: 0.11843068897724152
Validation loss: 1.4015764446668728

Epoch: 5| Step: 6
Training loss: 0.11162332445383072
Validation loss: 1.3706993672155565

Epoch: 5| Step: 7
Training loss: 0.12535101175308228
Validation loss: 1.3776416817019064

Epoch: 5| Step: 8
Training loss: 0.08614690601825714
Validation loss: 1.379951383477898

Epoch: 5| Step: 9
Training loss: 0.25431495904922485
Validation loss: 1.3951405658516833

Epoch: 5| Step: 10
Training loss: 0.1147855818271637
Validation loss: 1.3909195392362532

Epoch: 569| Step: 0
Training loss: 0.06025988981127739
Validation loss: 1.4072598026644798

Epoch: 5| Step: 1
Training loss: 0.09821544587612152
Validation loss: 1.408279707354884

Epoch: 5| Step: 2
Training loss: 0.07279171049594879
Validation loss: 1.4307232031258204

Epoch: 5| Step: 3
Training loss: 0.19494159519672394
Validation loss: 1.436275888514775

Epoch: 5| Step: 4
Training loss: 0.08817348629236221
Validation loss: 1.440913269596715

Epoch: 5| Step: 5
Training loss: 0.15848395228385925
Validation loss: 1.4025898966737973

Epoch: 5| Step: 6
Training loss: 0.06901641935110092
Validation loss: 1.4058376371219594

Epoch: 5| Step: 7
Training loss: 0.07574069499969482
Validation loss: 1.3910583885767127

Epoch: 5| Step: 8
Training loss: 0.11974774301052094
Validation loss: 1.4038495094545427

Epoch: 5| Step: 9
Training loss: 0.07210184633731842
Validation loss: 1.4006580857820408

Epoch: 5| Step: 10
Training loss: 0.0976550281047821
Validation loss: 1.4151974737003286

Epoch: 570| Step: 0
Training loss: 0.11908639967441559
Validation loss: 1.4173102090435643

Epoch: 5| Step: 1
Training loss: 0.10160414129495621
Validation loss: 1.4125737336374098

Epoch: 5| Step: 2
Training loss: 0.04497094079852104
Validation loss: 1.4227307560623332

Epoch: 5| Step: 3
Training loss: 0.14620628952980042
Validation loss: 1.4587412175311838

Epoch: 5| Step: 4
Training loss: 0.20290708541870117
Validation loss: 1.446001410484314

Epoch: 5| Step: 5
Training loss: 0.07287431508302689
Validation loss: 1.4473451299052085

Epoch: 5| Step: 6
Training loss: 0.07810120284557343
Validation loss: 1.465646670710656

Epoch: 5| Step: 7
Training loss: 0.0957675650715828
Validation loss: 1.4464936788364122

Epoch: 5| Step: 8
Training loss: 0.06127709150314331
Validation loss: 1.4420510427926176

Epoch: 5| Step: 9
Training loss: 0.11678136885166168
Validation loss: 1.4429567219108663

Epoch: 5| Step: 10
Training loss: 0.051318246871232986
Validation loss: 1.4516512155532837

Epoch: 571| Step: 0
Training loss: 0.07465223968029022
Validation loss: 1.4303903874530588

Epoch: 5| Step: 1
Training loss: 0.09895136952400208
Validation loss: 1.4501122736161756

Epoch: 5| Step: 2
Training loss: 0.08314105123281479
Validation loss: 1.454012534951651

Epoch: 5| Step: 3
Training loss: 0.127488911151886
Validation loss: 1.453714519418696

Epoch: 5| Step: 4
Training loss: 0.10144410282373428
Validation loss: 1.46630649541014

Epoch: 5| Step: 5
Training loss: 0.18796825408935547
Validation loss: 1.4527667696757982

Epoch: 5| Step: 6
Training loss: 0.07136134058237076
Validation loss: 1.4221697661184496

Epoch: 5| Step: 7
Training loss: 0.0611414834856987
Validation loss: 1.416838425461964

Epoch: 5| Step: 8
Training loss: 0.1341536045074463
Validation loss: 1.4109013772779895

Epoch: 5| Step: 9
Training loss: 0.18999631702899933
Validation loss: 1.4044890390929354

Epoch: 5| Step: 10
Training loss: 0.11149699985980988
Validation loss: 1.3925238527277464

Epoch: 572| Step: 0
Training loss: 0.1384650021791458
Validation loss: 1.4261793789043222

Epoch: 5| Step: 1
Training loss: 0.08435316383838654
Validation loss: 1.435195251177716

Epoch: 5| Step: 2
Training loss: 0.08150036633014679
Validation loss: 1.4221790311157063

Epoch: 5| Step: 3
Training loss: 0.11477731168270111
Validation loss: 1.4298604098699426

Epoch: 5| Step: 4
Training loss: 0.2178252637386322
Validation loss: 1.4161367442018242

Epoch: 5| Step: 5
Training loss: 0.1726992130279541
Validation loss: 1.4401339343799058

Epoch: 5| Step: 6
Training loss: 0.12506404519081116
Validation loss: 1.464429586164413

Epoch: 5| Step: 7
Training loss: 0.12116406112909317
Validation loss: 1.4828806192644182

Epoch: 5| Step: 8
Training loss: 0.07713984698057175
Validation loss: 1.4731508993333386

Epoch: 5| Step: 9
Training loss: 0.09618233144283295
Validation loss: 1.4473915805098831

Epoch: 5| Step: 10
Training loss: 0.09408093988895416
Validation loss: 1.4299596817262712

Epoch: 573| Step: 0
Training loss: 0.05180288106203079
Validation loss: 1.388431356799218

Epoch: 5| Step: 1
Training loss: 0.0891774520277977
Validation loss: 1.3869836522686867

Epoch: 5| Step: 2
Training loss: 0.0829375609755516
Validation loss: 1.397733981891345

Epoch: 5| Step: 3
Training loss: 0.15954037010669708
Validation loss: 1.4187146386792582

Epoch: 5| Step: 4
Training loss: 0.127756267786026
Validation loss: 1.4123296603079765

Epoch: 5| Step: 5
Training loss: 0.15892639756202698
Validation loss: 1.3838268915812175

Epoch: 5| Step: 6
Training loss: 0.08121420443058014
Validation loss: 1.3923104206720989

Epoch: 5| Step: 7
Training loss: 0.11583872139453888
Validation loss: 1.395667402975021

Epoch: 5| Step: 8
Training loss: 0.09410049021244049
Validation loss: 1.378607112874267

Epoch: 5| Step: 9
Training loss: 0.23417329788208008
Validation loss: 1.4191918296198691

Epoch: 5| Step: 10
Training loss: 0.16379883885383606
Validation loss: 1.4013114193434357

Epoch: 574| Step: 0
Training loss: 0.0825386792421341
Validation loss: 1.4533826984385008

Epoch: 5| Step: 1
Training loss: 0.13852818310260773
Validation loss: 1.4337507665798228

Epoch: 5| Step: 2
Training loss: 0.1142234206199646
Validation loss: 1.445762990623392

Epoch: 5| Step: 3
Training loss: 0.1878739893436432
Validation loss: 1.4413222984601093

Epoch: 5| Step: 4
Training loss: 0.0961231142282486
Validation loss: 1.4330295567871423

Epoch: 5| Step: 5
Training loss: 0.06882329285144806
Validation loss: 1.4209657048666349

Epoch: 5| Step: 6
Training loss: 0.07186615467071533
Validation loss: 1.4121655494936052

Epoch: 5| Step: 7
Training loss: 0.07631208747625351
Validation loss: 1.4144711500854903

Epoch: 5| Step: 8
Training loss: 0.09919677674770355
Validation loss: 1.4226349669118081

Epoch: 5| Step: 9
Training loss: 0.08153883367776871
Validation loss: 1.4136750800635225

Epoch: 5| Step: 10
Training loss: 0.23004136979579926
Validation loss: 1.4163563712950675

Epoch: 575| Step: 0
Training loss: 0.2128773182630539
Validation loss: 1.403436158293037

Epoch: 5| Step: 1
Training loss: 0.11711134016513824
Validation loss: 1.4308765549813547

Epoch: 5| Step: 2
Training loss: 0.10742776095867157
Validation loss: 1.423408689037446

Epoch: 5| Step: 3
Training loss: 0.11013612896203995
Validation loss: 1.450382810766979

Epoch: 5| Step: 4
Training loss: 0.09988345205783844
Validation loss: 1.4628306537546136

Epoch: 5| Step: 5
Training loss: 0.12190300226211548
Validation loss: 1.4788945746678177

Epoch: 5| Step: 6
Training loss: 0.11128302663564682
Validation loss: 1.475564697737335

Epoch: 5| Step: 7
Training loss: 0.1202348917722702
Validation loss: 1.4603563758634752

Epoch: 5| Step: 8
Training loss: 0.08440256863832474
Validation loss: 1.474805906254758

Epoch: 5| Step: 9
Training loss: 0.06718429923057556
Validation loss: 1.451381052694013

Epoch: 5| Step: 10
Training loss: 0.055847909301519394
Validation loss: 1.4745565524665258

Epoch: 576| Step: 0
Training loss: 0.13446517288684845
Validation loss: 1.4525389594416465

Epoch: 5| Step: 1
Training loss: 0.09486725181341171
Validation loss: 1.4386388473613287

Epoch: 5| Step: 2
Training loss: 0.11747269332408905
Validation loss: 1.4533123547031033

Epoch: 5| Step: 3
Training loss: 0.22116681933403015
Validation loss: 1.4349563153841163

Epoch: 5| Step: 4
Training loss: 0.08319254964590073
Validation loss: 1.423568005202919

Epoch: 5| Step: 5
Training loss: 0.06246368959546089
Validation loss: 1.4299702836621193

Epoch: 5| Step: 6
Training loss: 0.0533943697810173
Validation loss: 1.4531250102545625

Epoch: 5| Step: 7
Training loss: 0.09307875484228134
Validation loss: 1.4425667575610581

Epoch: 5| Step: 8
Training loss: 0.080799899995327
Validation loss: 1.432595693936912

Epoch: 5| Step: 9
Training loss: 0.11002223193645477
Validation loss: 1.4444504873726958

Epoch: 5| Step: 10
Training loss: 0.07090461999177933
Validation loss: 1.4425315690296951

Epoch: 577| Step: 0
Training loss: 0.10080911219120026
Validation loss: 1.4427110610469696

Epoch: 5| Step: 1
Training loss: 0.15134140849113464
Validation loss: 1.432397916752805

Epoch: 5| Step: 2
Training loss: 0.08700884878635406
Validation loss: 1.4319305983922814

Epoch: 5| Step: 3
Training loss: 0.06809448450803757
Validation loss: 1.4398193705466487

Epoch: 5| Step: 4
Training loss: 0.06198088079690933
Validation loss: 1.4272259204618392

Epoch: 5| Step: 5
Training loss: 0.0959664136171341
Validation loss: 1.4204995209170925

Epoch: 5| Step: 6
Training loss: 0.07195575535297394
Validation loss: 1.4037054738690775

Epoch: 5| Step: 7
Training loss: 0.073560930788517
Validation loss: 1.42059580356844

Epoch: 5| Step: 8
Training loss: 0.11437810957431793
Validation loss: 1.4124620768331713

Epoch: 5| Step: 9
Training loss: 0.0795874372124672
Validation loss: 1.402997818044437

Epoch: 5| Step: 10
Training loss: 0.08922352641820908
Validation loss: 1.4233618308139104

Epoch: 578| Step: 0
Training loss: 0.06495551019906998
Validation loss: 1.4271004135890673

Epoch: 5| Step: 1
Training loss: 0.06610526889562607
Validation loss: 1.4203950538430163

Epoch: 5| Step: 2
Training loss: 0.11783841997385025
Validation loss: 1.4480871372325446

Epoch: 5| Step: 3
Training loss: 0.12236139923334122
Validation loss: 1.4441296977381552

Epoch: 5| Step: 4
Training loss: 0.0646904855966568
Validation loss: 1.4366139327326128

Epoch: 5| Step: 5
Training loss: 0.12880977988243103
Validation loss: 1.4345678155140211

Epoch: 5| Step: 6
Training loss: 0.0830208882689476
Validation loss: 1.4178636240702804

Epoch: 5| Step: 7
Training loss: 0.25104817748069763
Validation loss: 1.45855890422739

Epoch: 5| Step: 8
Training loss: 0.07866907119750977
Validation loss: 1.4451413308420489

Epoch: 5| Step: 9
Training loss: 0.07891970872879028
Validation loss: 1.446040025321386

Epoch: 5| Step: 10
Training loss: 0.0872092917561531
Validation loss: 1.4327238464868197

Epoch: 579| Step: 0
Training loss: 0.10327289998531342
Validation loss: 1.4233450966496621

Epoch: 5| Step: 1
Training loss: 0.09691532701253891
Validation loss: 1.457169085420588

Epoch: 5| Step: 2
Training loss: 0.1387997716665268
Validation loss: 1.4686393891611407

Epoch: 5| Step: 3
Training loss: 0.0812348946928978
Validation loss: 1.4695602757956392

Epoch: 5| Step: 4
Training loss: 0.12282504141330719
Validation loss: 1.4488213164832002

Epoch: 5| Step: 5
Training loss: 0.08343341201543808
Validation loss: 1.4476001954847766

Epoch: 5| Step: 6
Training loss: 0.08514446765184402
Validation loss: 1.4300271593114382

Epoch: 5| Step: 7
Training loss: 0.06912865489721298
Validation loss: 1.4171530636407996

Epoch: 5| Step: 8
Training loss: 0.04923275113105774
Validation loss: 1.435180506398601

Epoch: 5| Step: 9
Training loss: 0.19972491264343262
Validation loss: 1.4367522090993903

Epoch: 5| Step: 10
Training loss: 0.08017813414335251
Validation loss: 1.4386710864241405

Epoch: 580| Step: 0
Training loss: 0.08039802312850952
Validation loss: 1.4540760401756532

Epoch: 5| Step: 1
Training loss: 0.0784984827041626
Validation loss: 1.453508363616082

Epoch: 5| Step: 2
Training loss: 0.11552052199840546
Validation loss: 1.4437435314219484

Epoch: 5| Step: 3
Training loss: 0.07973940670490265
Validation loss: 1.4399631484862296

Epoch: 5| Step: 4
Training loss: 0.158712700009346
Validation loss: 1.4327149391174316

Epoch: 5| Step: 5
Training loss: 0.1449354588985443
Validation loss: 1.4245860807357296

Epoch: 5| Step: 6
Training loss: 0.06606335937976837
Validation loss: 1.413370329846618

Epoch: 5| Step: 7
Training loss: 0.08977197110652924
Validation loss: 1.4325573380275438

Epoch: 5| Step: 8
Training loss: 0.11491511017084122
Validation loss: 1.3946399855357345

Epoch: 5| Step: 9
Training loss: 0.13264520466327667
Validation loss: 1.4009819364035

Epoch: 5| Step: 10
Training loss: 0.06599577516317368
Validation loss: 1.4178495150740429

Epoch: 581| Step: 0
Training loss: 0.09960529953241348
Validation loss: 1.4186259751678796

Epoch: 5| Step: 1
Training loss: 0.07212358713150024
Validation loss: 1.4043528700387606

Epoch: 5| Step: 2
Training loss: 0.06059296801686287
Validation loss: 1.4359687861575876

Epoch: 5| Step: 3
Training loss: 0.08111335337162018
Validation loss: 1.4250251637992037

Epoch: 5| Step: 4
Training loss: 0.09176178276538849
Validation loss: 1.4367756792294082

Epoch: 5| Step: 5
Training loss: 0.1992649883031845
Validation loss: 1.4637784195202652

Epoch: 5| Step: 6
Training loss: 0.12808962166309357
Validation loss: 1.4316906890561503

Epoch: 5| Step: 7
Training loss: 0.10630365461111069
Validation loss: 1.415963985586679

Epoch: 5| Step: 8
Training loss: 0.06636736541986465
Validation loss: 1.4229904823405768

Epoch: 5| Step: 9
Training loss: 0.05677495151758194
Validation loss: 1.432669367841495

Epoch: 5| Step: 10
Training loss: 0.07016029208898544
Validation loss: 1.3774823975819412

Epoch: 582| Step: 0
Training loss: 0.1777268350124359
Validation loss: 1.4008844578137962

Epoch: 5| Step: 1
Training loss: 0.09107614308595657
Validation loss: 1.4200237079333233

Epoch: 5| Step: 2
Training loss: 0.12497618049383163
Validation loss: 1.4228797023014357

Epoch: 5| Step: 3
Training loss: 0.07175033539533615
Validation loss: 1.4165024052384079

Epoch: 5| Step: 4
Training loss: 0.07888360321521759
Validation loss: 1.4103180900696786

Epoch: 5| Step: 5
Training loss: 0.06695864349603653
Validation loss: 1.419012297866165

Epoch: 5| Step: 6
Training loss: 0.07331936061382294
Validation loss: 1.419094794539995

Epoch: 5| Step: 7
Training loss: 0.12262874841690063
Validation loss: 1.438260168157598

Epoch: 5| Step: 8
Training loss: 0.09822891652584076
Validation loss: 1.4287006367919266

Epoch: 5| Step: 9
Training loss: 0.10888731479644775
Validation loss: 1.4509713495931318

Epoch: 5| Step: 10
Training loss: 0.07553466409444809
Validation loss: 1.4255633841278732

Epoch: 583| Step: 0
Training loss: 0.03731440007686615
Validation loss: 1.4159218521528347

Epoch: 5| Step: 1
Training loss: 0.07019418478012085
Validation loss: 1.418851294825154

Epoch: 5| Step: 2
Training loss: 0.08773276209831238
Validation loss: 1.4121722482865857

Epoch: 5| Step: 3
Training loss: 0.09905341267585754
Validation loss: 1.4015361147542154

Epoch: 5| Step: 4
Training loss: 0.10443000495433807
Validation loss: 1.4233439090431377

Epoch: 5| Step: 5
Training loss: 0.06637220084667206
Validation loss: 1.403337686933497

Epoch: 5| Step: 6
Training loss: 0.1372157335281372
Validation loss: 1.4093491813187957

Epoch: 5| Step: 7
Training loss: 0.057496000081300735
Validation loss: 1.4081466172331123

Epoch: 5| Step: 8
Training loss: 0.12620863318443298
Validation loss: 1.4057452332588933

Epoch: 5| Step: 9
Training loss: 0.08474583923816681
Validation loss: 1.4016876284794142

Epoch: 5| Step: 10
Training loss: 0.1376436948776245
Validation loss: 1.3941347868211809

Epoch: 584| Step: 0
Training loss: 0.06611786782741547
Validation loss: 1.4082176454605595

Epoch: 5| Step: 1
Training loss: 0.12805670499801636
Validation loss: 1.4027631616079679

Epoch: 5| Step: 2
Training loss: 0.13529431819915771
Validation loss: 1.4105939070383708

Epoch: 5| Step: 3
Training loss: 0.07092756032943726
Validation loss: 1.420811874892122

Epoch: 5| Step: 4
Training loss: 0.09070100635290146
Validation loss: 1.4184943335030669

Epoch: 5| Step: 5
Training loss: 0.05926121026277542
Validation loss: 1.4225988388061523

Epoch: 5| Step: 6
Training loss: 0.10118160396814346
Validation loss: 1.4227951508696361

Epoch: 5| Step: 7
Training loss: 0.1341441124677658
Validation loss: 1.4297001028573642

Epoch: 5| Step: 8
Training loss: 0.07521982491016388
Validation loss: 1.4350439194710023

Epoch: 5| Step: 9
Training loss: 0.11268453299999237
Validation loss: 1.4567595258835824

Epoch: 5| Step: 10
Training loss: 0.08623942732810974
Validation loss: 1.4618626435597737

Epoch: 585| Step: 0
Training loss: 0.1411529779434204
Validation loss: 1.4504680351544452

Epoch: 5| Step: 1
Training loss: 0.08820676058530807
Validation loss: 1.4544359381480882

Epoch: 5| Step: 2
Training loss: 0.09305484592914581
Validation loss: 1.4511629695533423

Epoch: 5| Step: 3
Training loss: 0.06392555683851242
Validation loss: 1.4684622236477431

Epoch: 5| Step: 4
Training loss: 0.13798490166664124
Validation loss: 1.4134984580419396

Epoch: 5| Step: 5
Training loss: 0.09212654083967209
Validation loss: 1.4188745303820538

Epoch: 5| Step: 6
Training loss: 0.0908307209610939
Validation loss: 1.4388841044518255

Epoch: 5| Step: 7
Training loss: 0.0727330818772316
Validation loss: 1.4246121119427424

Epoch: 5| Step: 8
Training loss: 0.07913701236248016
Validation loss: 1.420837088297772

Epoch: 5| Step: 9
Training loss: 0.11002383381128311
Validation loss: 1.4429082992256328

Epoch: 5| Step: 10
Training loss: 0.07848901301622391
Validation loss: 1.4065258381187276

Epoch: 586| Step: 0
Training loss: 0.11594577133655548
Validation loss: 1.4334918363119966

Epoch: 5| Step: 1
Training loss: 0.040868278592824936
Validation loss: 1.4099966556795183

Epoch: 5| Step: 2
Training loss: 0.08542177826166153
Validation loss: 1.4207368787898813

Epoch: 5| Step: 3
Training loss: 0.14359498023986816
Validation loss: 1.411947432384696

Epoch: 5| Step: 4
Training loss: 0.06336979568004608
Validation loss: 1.389544903591115

Epoch: 5| Step: 5
Training loss: 0.13133475184440613
Validation loss: 1.428961915354575

Epoch: 5| Step: 6
Training loss: 0.08610077202320099
Validation loss: 1.4321562179955103

Epoch: 5| Step: 7
Training loss: 0.06515828520059586
Validation loss: 1.4200198970815188

Epoch: 5| Step: 8
Training loss: 0.07160944491624832
Validation loss: 1.4145269509284728

Epoch: 5| Step: 9
Training loss: 0.10432813316583633
Validation loss: 1.4016000602834968

Epoch: 5| Step: 10
Training loss: 0.07518045604228973
Validation loss: 1.4124238350058114

Epoch: 587| Step: 0
Training loss: 0.06650551408529282
Validation loss: 1.4102618053395262

Epoch: 5| Step: 1
Training loss: 0.1035761833190918
Validation loss: 1.4167804128380233

Epoch: 5| Step: 2
Training loss: 0.09540028125047684
Validation loss: 1.4261173561055174

Epoch: 5| Step: 3
Training loss: 0.14685428142547607
Validation loss: 1.418613282583093

Epoch: 5| Step: 4
Training loss: 0.07589564472436905
Validation loss: 1.4198384656701037

Epoch: 5| Step: 5
Training loss: 0.08388756215572357
Validation loss: 1.4187093396340646

Epoch: 5| Step: 6
Training loss: 0.07015945017337799
Validation loss: 1.4142128254777642

Epoch: 5| Step: 7
Training loss: 0.08629739284515381
Validation loss: 1.3894101650484147

Epoch: 5| Step: 8
Training loss: 0.08019846677780151
Validation loss: 1.399387219900726

Epoch: 5| Step: 9
Training loss: 0.09792850911617279
Validation loss: 1.4070829640152633

Epoch: 5| Step: 10
Training loss: 0.0794835239648819
Validation loss: 1.3926062442923104

Epoch: 588| Step: 0
Training loss: 0.04445905238389969
Validation loss: 1.398522606459997

Epoch: 5| Step: 1
Training loss: 0.13802900910377502
Validation loss: 1.4109479201737272

Epoch: 5| Step: 2
Training loss: 0.0575302429497242
Validation loss: 1.4263096688896097

Epoch: 5| Step: 3
Training loss: 0.08910894393920898
Validation loss: 1.4653794380926317

Epoch: 5| Step: 4
Training loss: 0.07182850688695908
Validation loss: 1.434601083878548

Epoch: 5| Step: 5
Training loss: 0.09375094622373581
Validation loss: 1.4368087771118327

Epoch: 5| Step: 6
Training loss: 0.16292229294776917
Validation loss: 1.4397026210702875

Epoch: 5| Step: 7
Training loss: 0.07162388414144516
Validation loss: 1.4323790637395715

Epoch: 5| Step: 8
Training loss: 0.16179732978343964
Validation loss: 1.4223533086879279

Epoch: 5| Step: 9
Training loss: 0.12409250438213348
Validation loss: 1.3999029603055728

Epoch: 5| Step: 10
Training loss: 0.05068688467144966
Validation loss: 1.4328285212157874

Epoch: 589| Step: 0
Training loss: 0.14412975311279297
Validation loss: 1.4546679155800932

Epoch: 5| Step: 1
Training loss: 0.06777860224246979
Validation loss: 1.457963147471028

Epoch: 5| Step: 2
Training loss: 0.10323736816644669
Validation loss: 1.4660677134349782

Epoch: 5| Step: 3
Training loss: 0.09298986196517944
Validation loss: 1.477381578055761

Epoch: 5| Step: 4
Training loss: 0.07786017656326294
Validation loss: 1.4859796365102131

Epoch: 5| Step: 5
Training loss: 0.09135414659976959
Validation loss: 1.4706436767373035

Epoch: 5| Step: 6
Training loss: 0.08225266635417938
Validation loss: 1.4714527412127423

Epoch: 5| Step: 7
Training loss: 0.07718069851398468
Validation loss: 1.4307632125833982

Epoch: 5| Step: 8
Training loss: 0.16316068172454834
Validation loss: 1.4472972910891297

Epoch: 5| Step: 9
Training loss: 0.10673733800649643
Validation loss: 1.4180662567897508

Epoch: 5| Step: 10
Training loss: 0.10637301206588745
Validation loss: 1.4146632270146442

Epoch: 590| Step: 0
Training loss: 0.08434678614139557
Validation loss: 1.4051222044934508

Epoch: 5| Step: 1
Training loss: 0.07035009562969208
Validation loss: 1.4153474620593491

Epoch: 5| Step: 2
Training loss: 0.1955537348985672
Validation loss: 1.4176824669684134

Epoch: 5| Step: 3
Training loss: 0.11778590828180313
Validation loss: 1.4010707806515437

Epoch: 5| Step: 4
Training loss: 0.08275861293077469
Validation loss: 1.426923176293732

Epoch: 5| Step: 5
Training loss: 0.06655608117580414
Validation loss: 1.4032707278446486

Epoch: 5| Step: 6
Training loss: 0.07154662907123566
Validation loss: 1.408846737236105

Epoch: 5| Step: 7
Training loss: 0.08980051428079605
Validation loss: 1.3932492104909753

Epoch: 5| Step: 8
Training loss: 0.10121192038059235
Validation loss: 1.3949859802440931

Epoch: 5| Step: 9
Training loss: 0.07072055339813232
Validation loss: 1.4089353866474603

Epoch: 5| Step: 10
Training loss: 0.05801001563668251
Validation loss: 1.4125187781549269

Epoch: 591| Step: 0
Training loss: 0.08718012273311615
Validation loss: 1.3960458360692507

Epoch: 5| Step: 1
Training loss: 0.10623498260974884
Validation loss: 1.4110027808015064

Epoch: 5| Step: 2
Training loss: 0.10423292219638824
Validation loss: 1.4112436829074737

Epoch: 5| Step: 3
Training loss: 0.08097610622644424
Validation loss: 1.437855503892386

Epoch: 5| Step: 4
Training loss: 0.07752050459384918
Validation loss: 1.4287427881712556

Epoch: 5| Step: 5
Training loss: 0.04860404506325722
Validation loss: 1.427840539204177

Epoch: 5| Step: 6
Training loss: 0.08924659341573715
Validation loss: 1.4138584521508986

Epoch: 5| Step: 7
Training loss: 0.22628983855247498
Validation loss: 1.413979132970174

Epoch: 5| Step: 8
Training loss: 0.10271992534399033
Validation loss: 1.4188418811367405

Epoch: 5| Step: 9
Training loss: 0.08565940707921982
Validation loss: 1.4106787821298004

Epoch: 5| Step: 10
Training loss: 0.05588551610708237
Validation loss: 1.3992348761968716

Epoch: 592| Step: 0
Training loss: 0.08964903652667999
Validation loss: 1.4019250792841758

Epoch: 5| Step: 1
Training loss: 0.04764048010110855
Validation loss: 1.4119481143131052

Epoch: 5| Step: 2
Training loss: 0.060366250574588776
Validation loss: 1.4124151628504518

Epoch: 5| Step: 3
Training loss: 0.09121675789356232
Validation loss: 1.4280896968739007

Epoch: 5| Step: 4
Training loss: 0.08794981241226196
Validation loss: 1.4402840522027784

Epoch: 5| Step: 5
Training loss: 0.1285046488046646
Validation loss: 1.411528379686417

Epoch: 5| Step: 6
Training loss: 0.0897856280207634
Validation loss: 1.4113725449449273

Epoch: 5| Step: 7
Training loss: 0.07577992975711823
Validation loss: 1.432873918164161

Epoch: 5| Step: 8
Training loss: 0.0863906592130661
Validation loss: 1.416453234611019

Epoch: 5| Step: 9
Training loss: 0.12226758152246475
Validation loss: 1.4300602046392297

Epoch: 5| Step: 10
Training loss: 0.0712118148803711
Validation loss: 1.4341002465576254

Epoch: 593| Step: 0
Training loss: 0.06749700009822845
Validation loss: 1.4191285217961958

Epoch: 5| Step: 1
Training loss: 0.11849682033061981
Validation loss: 1.45594956028846

Epoch: 5| Step: 2
Training loss: 0.0877249464392662
Validation loss: 1.421840936906876

Epoch: 5| Step: 3
Training loss: 0.12435643374919891
Validation loss: 1.4484453252566758

Epoch: 5| Step: 4
Training loss: 0.09026457369327545
Validation loss: 1.4625472279005154

Epoch: 5| Step: 5
Training loss: 0.18168647587299347
Validation loss: 1.4490636317960677

Epoch: 5| Step: 6
Training loss: 0.0782361775636673
Validation loss: 1.460968667461026

Epoch: 5| Step: 7
Training loss: 0.06797109544277191
Validation loss: 1.4587803104872346

Epoch: 5| Step: 8
Training loss: 0.048398345708847046
Validation loss: 1.4454661030923166

Epoch: 5| Step: 9
Training loss: 0.11890614032745361
Validation loss: 1.463644326374095

Epoch: 5| Step: 10
Training loss: 0.1364370584487915
Validation loss: 1.455552234444567

Epoch: 594| Step: 0
Training loss: 0.1716422438621521
Validation loss: 1.445565762058381

Epoch: 5| Step: 1
Training loss: 0.07226141542196274
Validation loss: 1.4457875964462117

Epoch: 5| Step: 2
Training loss: 0.08477268368005753
Validation loss: 1.4306324335836595

Epoch: 5| Step: 3
Training loss: 0.07387129217386246
Validation loss: 1.4464200004454582

Epoch: 5| Step: 4
Training loss: 0.05354125425219536
Validation loss: 1.4451022225041543

Epoch: 5| Step: 5
Training loss: 0.09288981556892395
Validation loss: 1.4210508215811946

Epoch: 5| Step: 6
Training loss: 0.08720805495977402
Validation loss: 1.4230639088538386

Epoch: 5| Step: 7
Training loss: 0.10063860565423965
Validation loss: 1.3917355075959237

Epoch: 5| Step: 8
Training loss: 0.07954706251621246
Validation loss: 1.4342257181803386

Epoch: 5| Step: 9
Training loss: 0.13535192608833313
Validation loss: 1.4217148339876564

Epoch: 5| Step: 10
Training loss: 0.051851943135261536
Validation loss: 1.4234008032788512

Epoch: 595| Step: 0
Training loss: 0.09040449559688568
Validation loss: 1.4206052621205647

Epoch: 5| Step: 1
Training loss: 0.15973444283008575
Validation loss: 1.4355828633872412

Epoch: 5| Step: 2
Training loss: 0.12786486744880676
Validation loss: 1.4308491374856682

Epoch: 5| Step: 3
Training loss: 0.15436014533042908
Validation loss: 1.4295193726016628

Epoch: 5| Step: 4
Training loss: 0.08907325565814972
Validation loss: 1.4218123728229153

Epoch: 5| Step: 5
Training loss: 0.08863375335931778
Validation loss: 1.4274168424708868

Epoch: 5| Step: 6
Training loss: 0.0827023833990097
Validation loss: 1.396699288839935

Epoch: 5| Step: 7
Training loss: 0.05897742509841919
Validation loss: 1.4307458516090148

Epoch: 5| Step: 8
Training loss: 0.07826603949069977
Validation loss: 1.4027376738927697

Epoch: 5| Step: 9
Training loss: 0.06211751699447632
Validation loss: 1.4216712905514626

Epoch: 5| Step: 10
Training loss: 0.05981291085481644
Validation loss: 1.4395311904209915

Epoch: 596| Step: 0
Training loss: 0.06583014875650406
Validation loss: 1.458433373000032

Epoch: 5| Step: 1
Training loss: 0.15936590731143951
Validation loss: 1.428695208282881

Epoch: 5| Step: 2
Training loss: 0.07268846035003662
Validation loss: 1.4415058615387126

Epoch: 5| Step: 3
Training loss: 0.08307480812072754
Validation loss: 1.4303688926081504

Epoch: 5| Step: 4
Training loss: 0.07807712256908417
Validation loss: 1.4244193505215388

Epoch: 5| Step: 5
Training loss: 0.08232305198907852
Validation loss: 1.4312677973060197

Epoch: 5| Step: 6
Training loss: 0.07562579214572906
Validation loss: 1.4206066311046641

Epoch: 5| Step: 7
Training loss: 0.08358476310968399
Validation loss: 1.4361370776289253

Epoch: 5| Step: 8
Training loss: 0.08156538754701614
Validation loss: 1.4223594345072264

Epoch: 5| Step: 9
Training loss: 0.08117371797561646
Validation loss: 1.3892021698336448

Epoch: 5| Step: 10
Training loss: 0.13659659028053284
Validation loss: 1.4231881339062926

Epoch: 597| Step: 0
Training loss: 0.0634017288684845
Validation loss: 1.3975045475908505

Epoch: 5| Step: 1
Training loss: 0.0587412491440773
Validation loss: 1.4172777770667948

Epoch: 5| Step: 2
Training loss: 0.05295957252383232
Validation loss: 1.403547844579143

Epoch: 5| Step: 3
Training loss: 0.06643190234899521
Validation loss: 1.414487797726867

Epoch: 5| Step: 4
Training loss: 0.14250656962394714
Validation loss: 1.430539180514633

Epoch: 5| Step: 5
Training loss: 0.09627286344766617
Validation loss: 1.4592845209183232

Epoch: 5| Step: 6
Training loss: 0.08992360532283783
Validation loss: 1.45646652354989

Epoch: 5| Step: 7
Training loss: 0.05771348625421524
Validation loss: 1.43998388449351

Epoch: 5| Step: 8
Training loss: 0.09796201437711716
Validation loss: 1.431200997803801

Epoch: 5| Step: 9
Training loss: 0.08398906141519547
Validation loss: 1.4078104092228798

Epoch: 5| Step: 10
Training loss: 0.2432211935520172
Validation loss: 1.4121740556532336

Epoch: 598| Step: 0
Training loss: 0.06777110695838928
Validation loss: 1.3834524205935899

Epoch: 5| Step: 1
Training loss: 0.1871749758720398
Validation loss: 1.410988696159855

Epoch: 5| Step: 2
Training loss: 0.08684107661247253
Validation loss: 1.3980806053325694

Epoch: 5| Step: 3
Training loss: 0.17213621735572815
Validation loss: 1.4324322413372736

Epoch: 5| Step: 4
Training loss: 0.09363974630832672
Validation loss: 1.4518886804580688

Epoch: 5| Step: 5
Training loss: 0.13729789853096008
Validation loss: 1.485056947636348

Epoch: 5| Step: 6
Training loss: 0.10608366876840591
Validation loss: 1.4869852912041448

Epoch: 5| Step: 7
Training loss: 0.035870764404535294
Validation loss: 1.4545367648524623

Epoch: 5| Step: 8
Training loss: 0.07949922233819962
Validation loss: 1.4262318547054003

Epoch: 5| Step: 9
Training loss: 0.07133768498897552
Validation loss: 1.4178801313523324

Epoch: 5| Step: 10
Training loss: 0.06722508370876312
Validation loss: 1.4078000360919583

Epoch: 599| Step: 0
Training loss: 0.09172366559505463
Validation loss: 1.4375786242946502

Epoch: 5| Step: 1
Training loss: 0.08253104239702225
Validation loss: 1.424961108033375

Epoch: 5| Step: 2
Training loss: 0.07566150277853012
Validation loss: 1.4443906750730289

Epoch: 5| Step: 3
Training loss: 0.11628592014312744
Validation loss: 1.441621704768109

Epoch: 5| Step: 4
Training loss: 0.062244802713394165
Validation loss: 1.4379262962648947

Epoch: 5| Step: 5
Training loss: 0.07314200699329376
Validation loss: 1.4270333974592146

Epoch: 5| Step: 6
Training loss: 0.16076333820819855
Validation loss: 1.4613400108070784

Epoch: 5| Step: 7
Training loss: 0.09326289594173431
Validation loss: 1.4666278721183859

Epoch: 5| Step: 8
Training loss: 0.17068125307559967
Validation loss: 1.4678650543253908

Epoch: 5| Step: 9
Training loss: 0.10875481367111206
Validation loss: 1.4201064673803185

Epoch: 5| Step: 10
Training loss: 0.07563088089227676
Validation loss: 1.4338522265034337

Epoch: 600| Step: 0
Training loss: 0.06637901812791824
Validation loss: 1.3942425071552236

Epoch: 5| Step: 1
Training loss: 0.10674940049648285
Validation loss: 1.4233324668740714

Epoch: 5| Step: 2
Training loss: 0.10876478999853134
Validation loss: 1.4267939341965543

Epoch: 5| Step: 3
Training loss: 0.07869669795036316
Validation loss: 1.4105458490310177

Epoch: 5| Step: 4
Training loss: 0.06331177800893784
Validation loss: 1.4230590546002952

Epoch: 5| Step: 5
Training loss: 0.0646311417222023
Validation loss: 1.3990338669028333

Epoch: 5| Step: 6
Training loss: 0.15052977204322815
Validation loss: 1.3922392834899247

Epoch: 5| Step: 7
Training loss: 0.13982336223125458
Validation loss: 1.426691186043524

Epoch: 5| Step: 8
Training loss: 0.08435885608196259
Validation loss: 1.4154398800224386

Epoch: 5| Step: 9
Training loss: 0.05646757036447525
Validation loss: 1.4132520806404851

Epoch: 5| Step: 10
Training loss: 0.07173818349838257
Validation loss: 1.417340893899241

Epoch: 601| Step: 0
Training loss: 0.055635642260313034
Validation loss: 1.4252305992187992

Epoch: 5| Step: 1
Training loss: 0.1092534288764
Validation loss: 1.43363316212931

Epoch: 5| Step: 2
Training loss: 0.06236187368631363
Validation loss: 1.4306687949806132

Epoch: 5| Step: 3
Training loss: 0.13499972224235535
Validation loss: 1.418706205583388

Epoch: 5| Step: 4
Training loss: 0.10336053371429443
Validation loss: 1.3988875855681717

Epoch: 5| Step: 5
Training loss: 0.0767880529165268
Validation loss: 1.3655530252764303

Epoch: 5| Step: 6
Training loss: 0.0982980951666832
Validation loss: 1.4058184918536936

Epoch: 5| Step: 7
Training loss: 0.10972259193658829
Validation loss: 1.386954060164831

Epoch: 5| Step: 8
Training loss: 0.06531830132007599
Validation loss: 1.4003296071483242

Epoch: 5| Step: 9
Training loss: 0.07439254224300385
Validation loss: 1.4070440748686432

Epoch: 5| Step: 10
Training loss: 0.08196467161178589
Validation loss: 1.3959994777556388

Epoch: 602| Step: 0
Training loss: 0.08095220476388931
Validation loss: 1.4141785278115222

Epoch: 5| Step: 1
Training loss: 0.07089681178331375
Validation loss: 1.4575103771302007

Epoch: 5| Step: 2
Training loss: 0.09816820174455643
Validation loss: 1.4379347755062966

Epoch: 5| Step: 3
Training loss: 0.17121316492557526
Validation loss: 1.4279406416800715

Epoch: 5| Step: 4
Training loss: 0.05858789011836052
Validation loss: 1.4231474508521378

Epoch: 5| Step: 5
Training loss: 0.08230732381343842
Validation loss: 1.4063840284142444

Epoch: 5| Step: 6
Training loss: 0.15120002627372742
Validation loss: 1.447136317529986

Epoch: 5| Step: 7
Training loss: 0.08254478126764297
Validation loss: 1.4189501911081293

Epoch: 5| Step: 8
Training loss: 0.03846188262104988
Validation loss: 1.4366265291808753

Epoch: 5| Step: 9
Training loss: 0.09208787977695465
Validation loss: 1.447681318047226

Epoch: 5| Step: 10
Training loss: 0.04925651103258133
Validation loss: 1.417513648668925

Epoch: 603| Step: 0
Training loss: 0.07295204699039459
Validation loss: 1.4639012570022254

Epoch: 5| Step: 1
Training loss: 0.1974346935749054
Validation loss: 1.45520781957975

Epoch: 5| Step: 2
Training loss: 0.0698104277253151
Validation loss: 1.472550581860286

Epoch: 5| Step: 3
Training loss: 0.13123393058776855
Validation loss: 1.4663212299346924

Epoch: 5| Step: 4
Training loss: 0.062370557337999344
Validation loss: 1.4711735146020049

Epoch: 5| Step: 5
Training loss: 0.053892575204372406
Validation loss: 1.4554708426998508

Epoch: 5| Step: 6
Training loss: 0.09077610820531845
Validation loss: 1.4463673163485784

Epoch: 5| Step: 7
Training loss: 0.07344547659158707
Validation loss: 1.4153758031065746

Epoch: 5| Step: 8
Training loss: 0.09730390459299088
Validation loss: 1.4523371368326166

Epoch: 5| Step: 9
Training loss: 0.13352255523204803
Validation loss: 1.4333647066547024

Epoch: 5| Step: 10
Training loss: 0.12334567308425903
Validation loss: 1.420781643480383

Epoch: 604| Step: 0
Training loss: 0.11546628177165985
Validation loss: 1.4226911862691243

Epoch: 5| Step: 1
Training loss: 0.060483671724796295
Validation loss: 1.4262726870916222

Epoch: 5| Step: 2
Training loss: 0.0777224600315094
Validation loss: 1.4570821869757868

Epoch: 5| Step: 3
Training loss: 0.135065957903862
Validation loss: 1.4486103852589924

Epoch: 5| Step: 4
Training loss: 0.1890174299478531
Validation loss: 1.4426646155695761

Epoch: 5| Step: 5
Training loss: 0.10536634922027588
Validation loss: 1.421185843406185

Epoch: 5| Step: 6
Training loss: 0.07514641433954239
Validation loss: 1.4225081730914373

Epoch: 5| Step: 7
Training loss: 0.10485901683568954
Validation loss: 1.3981602384198097

Epoch: 5| Step: 8
Training loss: 0.1934460997581482
Validation loss: 1.4053370042513775

Epoch: 5| Step: 9
Training loss: 0.0939379632472992
Validation loss: 1.3963219376020535

Epoch: 5| Step: 10
Training loss: 0.06780077517032623
Validation loss: 1.3854568940336986

Epoch: 605| Step: 0
Training loss: 0.2118297517299652
Validation loss: 1.4161845073905042

Epoch: 5| Step: 1
Training loss: 0.07026861608028412
Validation loss: 1.4196765512548468

Epoch: 5| Step: 2
Training loss: 0.06859125941991806
Validation loss: 1.4188581371820101

Epoch: 5| Step: 3
Training loss: 0.0898028090596199
Validation loss: 1.4189180122908724

Epoch: 5| Step: 4
Training loss: 0.0932684987783432
Validation loss: 1.4363743643606863

Epoch: 5| Step: 5
Training loss: 0.05500093847513199
Validation loss: 1.4463050929448937

Epoch: 5| Step: 6
Training loss: 0.07097949087619781
Validation loss: 1.426286325018893

Epoch: 5| Step: 7
Training loss: 0.05399860814213753
Validation loss: 1.4537950497801586

Epoch: 5| Step: 8
Training loss: 0.12273409217596054
Validation loss: 1.4137014753075057

Epoch: 5| Step: 9
Training loss: 0.04496144503355026
Validation loss: 1.38668345251391

Epoch: 5| Step: 10
Training loss: 0.0694793090224266
Validation loss: 1.4181275393373223

Epoch: 606| Step: 0
Training loss: 0.07685506343841553
Validation loss: 1.3944967728789135

Epoch: 5| Step: 1
Training loss: 0.07136963307857513
Validation loss: 1.396991943800321

Epoch: 5| Step: 2
Training loss: 0.08859451115131378
Validation loss: 1.3947564536525356

Epoch: 5| Step: 3
Training loss: 0.12376333773136139
Validation loss: 1.3990792305238786

Epoch: 5| Step: 4
Training loss: 0.09935177117586136
Validation loss: 1.4022917196314821

Epoch: 5| Step: 5
Training loss: 0.06160764768719673
Validation loss: 1.4162341907460203

Epoch: 5| Step: 6
Training loss: 0.10609769821166992
Validation loss: 1.4216511070087392

Epoch: 5| Step: 7
Training loss: 0.0514163002371788
Validation loss: 1.4250166531532042

Epoch: 5| Step: 8
Training loss: 0.07324390113353729
Validation loss: 1.4700406161687707

Epoch: 5| Step: 9
Training loss: 0.2013855278491974
Validation loss: 1.4536506616941063

Epoch: 5| Step: 10
Training loss: 0.14036980271339417
Validation loss: 1.4518329315288092

Epoch: 607| Step: 0
Training loss: 0.07986028492450714
Validation loss: 1.4408506949742634

Epoch: 5| Step: 1
Training loss: 0.06084173172712326
Validation loss: 1.4035287121290803

Epoch: 5| Step: 2
Training loss: 0.11329734325408936
Validation loss: 1.4235100694881972

Epoch: 5| Step: 3
Training loss: 0.09344026446342468
Validation loss: 1.4039185771378138

Epoch: 5| Step: 4
Training loss: 0.11755605041980743
Validation loss: 1.4166243730052825

Epoch: 5| Step: 5
Training loss: 0.056153882294893265
Validation loss: 1.3918716894683016

Epoch: 5| Step: 6
Training loss: 0.0682147666811943
Validation loss: 1.404793684200574

Epoch: 5| Step: 7
Training loss: 0.07567574083805084
Validation loss: 1.4095257411720932

Epoch: 5| Step: 8
Training loss: 0.21311001479625702
Validation loss: 1.4199173194105907

Epoch: 5| Step: 9
Training loss: 0.07030972093343735
Validation loss: 1.4487157560163928

Epoch: 5| Step: 10
Training loss: 0.14567269384860992
Validation loss: 1.46560356309337

Epoch: 608| Step: 0
Training loss: 0.07176946103572845
Validation loss: 1.4373489464482954

Epoch: 5| Step: 1
Training loss: 0.09034810215234756
Validation loss: 1.441191779669895

Epoch: 5| Step: 2
Training loss: 0.04912624508142471
Validation loss: 1.4396877109363515

Epoch: 5| Step: 3
Training loss: 0.09946417063474655
Validation loss: 1.4172185031316613

Epoch: 5| Step: 4
Training loss: 0.07434315234422684
Validation loss: 1.4286363663211945

Epoch: 5| Step: 5
Training loss: 0.1657124161720276
Validation loss: 1.416972367994247

Epoch: 5| Step: 6
Training loss: 0.16528566181659698
Validation loss: 1.421262264251709

Epoch: 5| Step: 7
Training loss: 0.12592364847660065
Validation loss: 1.4158728635439308

Epoch: 5| Step: 8
Training loss: 0.08994311839342117
Validation loss: 1.3892936283542263

Epoch: 5| Step: 9
Training loss: 0.1398824006319046
Validation loss: 1.3820506590668873

Epoch: 5| Step: 10
Training loss: 0.07337400317192078
Validation loss: 1.4002483621720345

Epoch: 609| Step: 0
Training loss: 0.12077329307794571
Validation loss: 1.3930953882073844

Epoch: 5| Step: 1
Training loss: 0.08320021629333496
Validation loss: 1.4105592671261038

Epoch: 5| Step: 2
Training loss: 0.15403123199939728
Validation loss: 1.4029860099156697

Epoch: 5| Step: 3
Training loss: 0.11770088970661163
Validation loss: 1.4166529870802356

Epoch: 5| Step: 4
Training loss: 0.07021219283342361
Validation loss: 1.4089801657584407

Epoch: 5| Step: 5
Training loss: 0.10175049304962158
Validation loss: 1.413348735019725

Epoch: 5| Step: 6
Training loss: 0.08706670254468918
Validation loss: 1.414836254171146

Epoch: 5| Step: 7
Training loss: 0.07543589919805527
Validation loss: 1.4237913117613843

Epoch: 5| Step: 8
Training loss: 0.06242717057466507
Validation loss: 1.4357502742480206

Epoch: 5| Step: 9
Training loss: 0.061262477189302444
Validation loss: 1.4103508662152033

Epoch: 5| Step: 10
Training loss: 0.10300508141517639
Validation loss: 1.4388765929847636

Epoch: 610| Step: 0
Training loss: 0.11962976306676865
Validation loss: 1.4790702404514435

Epoch: 5| Step: 1
Training loss: 0.1368187814950943
Validation loss: 1.4817311597126785

Epoch: 5| Step: 2
Training loss: 0.09988095611333847
Validation loss: 1.4458948296885337

Epoch: 5| Step: 3
Training loss: 0.07052268832921982
Validation loss: 1.4348450732487503

Epoch: 5| Step: 4
Training loss: 0.11383192241191864
Validation loss: 1.4313344417079803

Epoch: 5| Step: 5
Training loss: 0.09160017967224121
Validation loss: 1.4139393978221442

Epoch: 5| Step: 6
Training loss: 0.0911683738231659
Validation loss: 1.4428390277329313

Epoch: 5| Step: 7
Training loss: 0.12168661504983902
Validation loss: 1.43878799100076

Epoch: 5| Step: 8
Training loss: 0.08691836148500443
Validation loss: 1.445957479938384

Epoch: 5| Step: 9
Training loss: 0.20311518013477325
Validation loss: 1.4070004724687146

Epoch: 5| Step: 10
Training loss: 0.05977526679635048
Validation loss: 1.4197683065168318

Epoch: 611| Step: 0
Training loss: 0.06028332561254501
Validation loss: 1.4013049512781122

Epoch: 5| Step: 1
Training loss: 0.12014700472354889
Validation loss: 1.4242529522988103

Epoch: 5| Step: 2
Training loss: 0.08474727720022202
Validation loss: 1.4375464864956435

Epoch: 5| Step: 3
Training loss: 0.10726002603769302
Validation loss: 1.4586148005659862

Epoch: 5| Step: 4
Training loss: 0.16524454951286316
Validation loss: 1.4431449187699186

Epoch: 5| Step: 5
Training loss: 0.0809275358915329
Validation loss: 1.4244660478766247

Epoch: 5| Step: 6
Training loss: 0.03288263827562332
Validation loss: 1.4201228509667099

Epoch: 5| Step: 7
Training loss: 0.10031197220087051
Validation loss: 1.4281672803304528

Epoch: 5| Step: 8
Training loss: 0.0783446878194809
Validation loss: 1.447339976987531

Epoch: 5| Step: 9
Training loss: 0.07915433496236801
Validation loss: 1.4304674158814132

Epoch: 5| Step: 10
Training loss: 0.08066216856241226
Validation loss: 1.4697495942474694

Epoch: 612| Step: 0
Training loss: 0.06054282188415527
Validation loss: 1.4364191101443382

Epoch: 5| Step: 1
Training loss: 0.06337430328130722
Validation loss: 1.4432688566946215

Epoch: 5| Step: 2
Training loss: 0.08267659693956375
Validation loss: 1.423664028285652

Epoch: 5| Step: 3
Training loss: 0.07741754502058029
Validation loss: 1.4411123760284916

Epoch: 5| Step: 4
Training loss: 0.11399741470813751
Validation loss: 1.435523513824709

Epoch: 5| Step: 5
Training loss: 0.07555884122848511
Validation loss: 1.4441764649524484

Epoch: 5| Step: 6
Training loss: 0.06533590704202652
Validation loss: 1.4663793271587742

Epoch: 5| Step: 7
Training loss: 0.11502905189990997
Validation loss: 1.480262012891872

Epoch: 5| Step: 8
Training loss: 0.22897426784038544
Validation loss: 1.485994456916727

Epoch: 5| Step: 9
Training loss: 0.06708172708749771
Validation loss: 1.4977285823514384

Epoch: 5| Step: 10
Training loss: 0.11526235938072205
Validation loss: 1.4792654527130948

Epoch: 613| Step: 0
Training loss: 0.09807197004556656
Validation loss: 1.4593782040380663

Epoch: 5| Step: 1
Training loss: 0.06996077299118042
Validation loss: 1.46189736102217

Epoch: 5| Step: 2
Training loss: 0.10462262481451035
Validation loss: 1.4550522322295814

Epoch: 5| Step: 3
Training loss: 0.10117745399475098
Validation loss: 1.4584214969347882

Epoch: 5| Step: 4
Training loss: 0.15798655152320862
Validation loss: 1.4548633149875108

Epoch: 5| Step: 5
Training loss: 0.07123878598213196
Validation loss: 1.4240315755208333

Epoch: 5| Step: 6
Training loss: 0.09164007753133774
Validation loss: 1.4443996862698627

Epoch: 5| Step: 7
Training loss: 0.15483984351158142
Validation loss: 1.4159245298754783

Epoch: 5| Step: 8
Training loss: 0.1261587142944336
Validation loss: 1.4409942755135157

Epoch: 5| Step: 9
Training loss: 0.08550678193569183
Validation loss: 1.43621922949309

Epoch: 5| Step: 10
Training loss: 0.11330059170722961
Validation loss: 1.4305203153241066

Epoch: 614| Step: 0
Training loss: 0.15757536888122559
Validation loss: 1.4494623766150525

Epoch: 5| Step: 1
Training loss: 0.1683579683303833
Validation loss: 1.4476622625063824

Epoch: 5| Step: 2
Training loss: 0.14524315297603607
Validation loss: 1.4672082854855446

Epoch: 5| Step: 3
Training loss: 0.08624745905399323
Validation loss: 1.4511719852365472

Epoch: 5| Step: 4
Training loss: 0.06384669244289398
Validation loss: 1.4633220370097826

Epoch: 5| Step: 5
Training loss: 0.16941985487937927
Validation loss: 1.4795874254677885

Epoch: 5| Step: 6
Training loss: 0.12357981503009796
Validation loss: 1.4259460421018704

Epoch: 5| Step: 7
Training loss: 0.10773374885320663
Validation loss: 1.4299508845934303

Epoch: 5| Step: 8
Training loss: 0.07048530876636505
Validation loss: 1.4009896145072034

Epoch: 5| Step: 9
Training loss: 0.10627007484436035
Validation loss: 1.4167389856871737

Epoch: 5| Step: 10
Training loss: 0.0753946527838707
Validation loss: 1.4196953119770173

Epoch: 615| Step: 0
Training loss: 0.15294155478477478
Validation loss: 1.4264304509726904

Epoch: 5| Step: 1
Training loss: 0.1323021501302719
Validation loss: 1.4472349189942884

Epoch: 5| Step: 2
Training loss: 0.1047246903181076
Validation loss: 1.4635129154369395

Epoch: 5| Step: 3
Training loss: 0.08172476291656494
Validation loss: 1.439722748212917

Epoch: 5| Step: 4
Training loss: 0.13734883069992065
Validation loss: 1.4244437435621857

Epoch: 5| Step: 5
Training loss: 0.15115156769752502
Validation loss: 1.4104373326865576

Epoch: 5| Step: 6
Training loss: 0.08266137540340424
Validation loss: 1.4029215651173745

Epoch: 5| Step: 7
Training loss: 0.11059589684009552
Validation loss: 1.4412681415516844

Epoch: 5| Step: 8
Training loss: 0.108098104596138
Validation loss: 1.4229567063752042

Epoch: 5| Step: 9
Training loss: 0.0640343651175499
Validation loss: 1.432325593886837

Epoch: 5| Step: 10
Training loss: 0.0771375447511673
Validation loss: 1.4428248879730061

Epoch: 616| Step: 0
Training loss: 0.0796360969543457
Validation loss: 1.4520645321056407

Epoch: 5| Step: 1
Training loss: 0.16806146502494812
Validation loss: 1.4489131928772054

Epoch: 5| Step: 2
Training loss: 0.12154164165258408
Validation loss: 1.417791497322821

Epoch: 5| Step: 3
Training loss: 0.11980585008859634
Validation loss: 1.4395642395942443

Epoch: 5| Step: 4
Training loss: 0.08877235651016235
Validation loss: 1.4358434151577693

Epoch: 5| Step: 5
Training loss: 0.07246516644954681
Validation loss: 1.4758100240461287

Epoch: 5| Step: 6
Training loss: 0.1214791089296341
Validation loss: 1.483715130436805

Epoch: 5| Step: 7
Training loss: 0.14054612815380096
Validation loss: 1.4680090527380667

Epoch: 5| Step: 8
Training loss: 0.059972308576107025
Validation loss: 1.4418309939804899

Epoch: 5| Step: 9
Training loss: 0.07678220421075821
Validation loss: 1.4537395174785326

Epoch: 5| Step: 10
Training loss: 0.08613429963588715
Validation loss: 1.4029431099532752

Epoch: 617| Step: 0
Training loss: 0.12588027119636536
Validation loss: 1.437706769153636

Epoch: 5| Step: 1
Training loss: 0.17260149121284485
Validation loss: 1.4766884849917503

Epoch: 5| Step: 2
Training loss: 0.053212832659482956
Validation loss: 1.4339005306202879

Epoch: 5| Step: 3
Training loss: 0.07491742819547653
Validation loss: 1.42443367614541

Epoch: 5| Step: 4
Training loss: 0.047543395310640335
Validation loss: 1.4188361257635138

Epoch: 5| Step: 5
Training loss: 0.06759108603000641
Validation loss: 1.3839213053385417

Epoch: 5| Step: 6
Training loss: 0.08008721470832825
Validation loss: 1.4085633498366161

Epoch: 5| Step: 7
Training loss: 0.09049645066261292
Validation loss: 1.4231507508985457

Epoch: 5| Step: 8
Training loss: 0.041075702756643295
Validation loss: 1.4379837948788878

Epoch: 5| Step: 9
Training loss: 0.07184316217899323
Validation loss: 1.457900890099105

Epoch: 5| Step: 10
Training loss: 0.10922949761152267
Validation loss: 1.4607061173326226

Epoch: 618| Step: 0
Training loss: 0.08168276399374008
Validation loss: 1.4554745663878739

Epoch: 5| Step: 1
Training loss: 0.055378496646881104
Validation loss: 1.4568917200129519

Epoch: 5| Step: 2
Training loss: 0.22646701335906982
Validation loss: 1.4666891187749884

Epoch: 5| Step: 3
Training loss: 0.1214509978890419
Validation loss: 1.4444681444475729

Epoch: 5| Step: 4
Training loss: 0.10098975896835327
Validation loss: 1.4610998758705713

Epoch: 5| Step: 5
Training loss: 0.08851645141839981
Validation loss: 1.443075692781838

Epoch: 5| Step: 6
Training loss: 0.057749003171920776
Validation loss: 1.45310043263179

Epoch: 5| Step: 7
Training loss: 0.08028197288513184
Validation loss: 1.4356399633551156

Epoch: 5| Step: 8
Training loss: 0.08526427298784256
Validation loss: 1.4200576056716263

Epoch: 5| Step: 9
Training loss: 0.11203698813915253
Validation loss: 1.4372907607786116

Epoch: 5| Step: 10
Training loss: 0.1440853327512741
Validation loss: 1.4121125205870597

Epoch: 619| Step: 0
Training loss: 0.1044367328286171
Validation loss: 1.421987771987915

Epoch: 5| Step: 1
Training loss: 0.18144159018993378
Validation loss: 1.4350926619704052

Epoch: 5| Step: 2
Training loss: 0.11000752449035645
Validation loss: 1.4272711321871767

Epoch: 5| Step: 3
Training loss: 0.07941654324531555
Validation loss: 1.41937175104695

Epoch: 5| Step: 4
Training loss: 0.061892230063676834
Validation loss: 1.436153563120032

Epoch: 5| Step: 5
Training loss: 0.09403640031814575
Validation loss: 1.418216537403804

Epoch: 5| Step: 6
Training loss: 0.13754580914974213
Validation loss: 1.4211684606408561

Epoch: 5| Step: 7
Training loss: 0.045942168682813644
Validation loss: 1.4427776246942499

Epoch: 5| Step: 8
Training loss: 0.09137187153100967
Validation loss: 1.422464919346635

Epoch: 5| Step: 9
Training loss: 0.15824249386787415
Validation loss: 1.4285022065203676

Epoch: 5| Step: 10
Training loss: 0.08552376180887222
Validation loss: 1.4067464310635802

Epoch: 620| Step: 0
Training loss: 0.07245764881372452
Validation loss: 1.4282040903645177

Epoch: 5| Step: 1
Training loss: 0.19632938504219055
Validation loss: 1.4176807595837502

Epoch: 5| Step: 2
Training loss: 0.07339844852685928
Validation loss: 1.4278914056798464

Epoch: 5| Step: 3
Training loss: 0.09395924210548401
Validation loss: 1.4174736328022455

Epoch: 5| Step: 4
Training loss: 0.0827566385269165
Validation loss: 1.4212944994690597

Epoch: 5| Step: 5
Training loss: 0.08696505427360535
Validation loss: 1.4345825551658549

Epoch: 5| Step: 6
Training loss: 0.07826268672943115
Validation loss: 1.4560700039709769

Epoch: 5| Step: 7
Training loss: 0.13396063446998596
Validation loss: 1.4328137495184456

Epoch: 5| Step: 8
Training loss: 0.08956504613161087
Validation loss: 1.4292066597169446

Epoch: 5| Step: 9
Training loss: 0.05466518923640251
Validation loss: 1.4144196958952053

Epoch: 5| Step: 10
Training loss: 0.18622171878814697
Validation loss: 1.4091341726241573

Epoch: 621| Step: 0
Training loss: 0.07501835376024246
Validation loss: 1.3932414952144827

Epoch: 5| Step: 1
Training loss: 0.059907566756010056
Validation loss: 1.4066245722514328

Epoch: 5| Step: 2
Training loss: 0.16082562506198883
Validation loss: 1.405490412507006

Epoch: 5| Step: 3
Training loss: 0.05168862268328667
Validation loss: 1.4086071650187175

Epoch: 5| Step: 4
Training loss: 0.11495288461446762
Validation loss: 1.4064464453727967

Epoch: 5| Step: 5
Training loss: 0.12020709365606308
Validation loss: 1.404566728940574

Epoch: 5| Step: 6
Training loss: 0.1119195967912674
Validation loss: 1.4065370969874884

Epoch: 5| Step: 7
Training loss: 0.09524551033973694
Validation loss: 1.4176896323439896

Epoch: 5| Step: 8
Training loss: 0.08789684623479843
Validation loss: 1.3930106137388496

Epoch: 5| Step: 9
Training loss: 0.07993800193071365
Validation loss: 1.4045410028067968

Epoch: 5| Step: 10
Training loss: 0.05047516152262688
Validation loss: 1.3785989271697177

Epoch: 622| Step: 0
Training loss: 0.07396712899208069
Validation loss: 1.3927753490786399

Epoch: 5| Step: 1
Training loss: 0.1577024757862091
Validation loss: 1.387399467088843

Epoch: 5| Step: 2
Training loss: 0.07970806211233139
Validation loss: 1.4526137344298824

Epoch: 5| Step: 3
Training loss: 0.09843569993972778
Validation loss: 1.4192080523378106

Epoch: 5| Step: 4
Training loss: 0.0683000311255455
Validation loss: 1.4303641691002795

Epoch: 5| Step: 5
Training loss: 0.09476231038570404
Validation loss: 1.4225655217324533

Epoch: 5| Step: 6
Training loss: 0.06569664925336838
Validation loss: 1.4215641713911487

Epoch: 5| Step: 7
Training loss: 0.05382915586233139
Validation loss: 1.4513920801942066

Epoch: 5| Step: 8
Training loss: 0.06128377839922905
Validation loss: 1.4616077305168234

Epoch: 5| Step: 9
Training loss: 0.0887724831700325
Validation loss: 1.4440278904412382

Epoch: 5| Step: 10
Training loss: 0.13537439703941345
Validation loss: 1.4579666840132846

Epoch: 623| Step: 0
Training loss: 0.0819418802857399
Validation loss: 1.4602511557199622

Epoch: 5| Step: 1
Training loss: 0.06094247102737427
Validation loss: 1.4675731530753515

Epoch: 5| Step: 2
Training loss: 0.060507893562316895
Validation loss: 1.4568921109681487

Epoch: 5| Step: 3
Training loss: 0.15457141399383545
Validation loss: 1.4663301719132291

Epoch: 5| Step: 4
Training loss: 0.07809293270111084
Validation loss: 1.4701617328069543

Epoch: 5| Step: 5
Training loss: 0.055973898619413376
Validation loss: 1.4648913324520152

Epoch: 5| Step: 6
Training loss: 0.04666990041732788
Validation loss: 1.467468919292573

Epoch: 5| Step: 7
Training loss: 0.1444677859544754
Validation loss: 1.4656415818839945

Epoch: 5| Step: 8
Training loss: 0.10155488550662994
Validation loss: 1.4475302741091738

Epoch: 5| Step: 9
Training loss: 0.06858567148447037
Validation loss: 1.4579684170343543

Epoch: 5| Step: 10
Training loss: 0.05912590026855469
Validation loss: 1.4443083322176369

Epoch: 624| Step: 0
Training loss: 0.048898160457611084
Validation loss: 1.406900159774288

Epoch: 5| Step: 1
Training loss: 0.0979880765080452
Validation loss: 1.4197450555780882

Epoch: 5| Step: 2
Training loss: 0.06084161996841431
Validation loss: 1.4302416860416372

Epoch: 5| Step: 3
Training loss: 0.061531912535429
Validation loss: 1.4361875723767024

Epoch: 5| Step: 4
Training loss: 0.03999938815832138
Validation loss: 1.4054742647755532

Epoch: 5| Step: 5
Training loss: 0.10544802993535995
Validation loss: 1.4361058986315163

Epoch: 5| Step: 6
Training loss: 0.0718788281083107
Validation loss: 1.4614566090286418

Epoch: 5| Step: 7
Training loss: 0.06768175214529037
Validation loss: 1.424884614124093

Epoch: 5| Step: 8
Training loss: 0.06379018723964691
Validation loss: 1.4557141809053318

Epoch: 5| Step: 9
Training loss: 0.2315295934677124
Validation loss: 1.412697026806493

Epoch: 5| Step: 10
Training loss: 0.051818110048770905
Validation loss: 1.428886426392422

Epoch: 625| Step: 0
Training loss: 0.06984779983758926
Validation loss: 1.44092652105516

Epoch: 5| Step: 1
Training loss: 0.0446772426366806
Validation loss: 1.43311390056405

Epoch: 5| Step: 2
Training loss: 0.041746240109205246
Validation loss: 1.4378330374276767

Epoch: 5| Step: 3
Training loss: 0.1348876953125
Validation loss: 1.4705331876713743

Epoch: 5| Step: 4
Training loss: 0.06612006574869156
Validation loss: 1.4434837628436346

Epoch: 5| Step: 5
Training loss: 0.08294455707073212
Validation loss: 1.4465840478097238

Epoch: 5| Step: 6
Training loss: 0.16314688324928284
Validation loss: 1.4739719321650844

Epoch: 5| Step: 7
Training loss: 0.04670155793428421
Validation loss: 1.4579423448090911

Epoch: 5| Step: 8
Training loss: 0.0595536045730114
Validation loss: 1.4546036899730723

Epoch: 5| Step: 9
Training loss: 0.04758172482252121
Validation loss: 1.4460681087227278

Epoch: 5| Step: 10
Training loss: 0.08837489783763885
Validation loss: 1.4572026345037645

Epoch: 626| Step: 0
Training loss: 0.07042299211025238
Validation loss: 1.4961816610828522

Epoch: 5| Step: 1
Training loss: 0.07775989174842834
Validation loss: 1.4895824834864626

Epoch: 5| Step: 2
Training loss: 0.14275884628295898
Validation loss: 1.4874835039979668

Epoch: 5| Step: 3
Training loss: 0.07120641320943832
Validation loss: 1.4640013530690184

Epoch: 5| Step: 4
Training loss: 0.15647147595882416
Validation loss: 1.4838561216990154

Epoch: 5| Step: 5
Training loss: 0.06758628040552139
Validation loss: 1.4464948895157024

Epoch: 5| Step: 6
Training loss: 0.05696042627096176
Validation loss: 1.457963579444475

Epoch: 5| Step: 7
Training loss: 0.08988013863563538
Validation loss: 1.4318287321316299

Epoch: 5| Step: 8
Training loss: 0.06546805053949356
Validation loss: 1.4480119020708146

Epoch: 5| Step: 9
Training loss: 0.08197124302387238
Validation loss: 1.4606365555076188

Epoch: 5| Step: 10
Training loss: 0.06404586136341095
Validation loss: 1.4362760077240646

Epoch: 627| Step: 0
Training loss: 0.07537993043661118
Validation loss: 1.4325486460039694

Epoch: 5| Step: 1
Training loss: 0.0590408630669117
Validation loss: 1.43002369711476

Epoch: 5| Step: 2
Training loss: 0.06560829281806946
Validation loss: 1.443043888256114

Epoch: 5| Step: 3
Training loss: 0.0784759670495987
Validation loss: 1.4414827631365867

Epoch: 5| Step: 4
Training loss: 0.06252093613147736
Validation loss: 1.4421911034532773

Epoch: 5| Step: 5
Training loss: 0.11789099872112274
Validation loss: 1.4349973560661398

Epoch: 5| Step: 6
Training loss: 0.09585539996623993
Validation loss: 1.443293866290841

Epoch: 5| Step: 7
Training loss: 0.08207586407661438
Validation loss: 1.4526273819708055

Epoch: 5| Step: 8
Training loss: 0.16728150844573975
Validation loss: 1.4638129485550748

Epoch: 5| Step: 9
Training loss: 0.0906767025589943
Validation loss: 1.4679899472062305

Epoch: 5| Step: 10
Training loss: 0.1215246394276619
Validation loss: 1.4733282237924554

Epoch: 628| Step: 0
Training loss: 0.08790557086467743
Validation loss: 1.4493693177418043

Epoch: 5| Step: 1
Training loss: 0.061796508729457855
Validation loss: 1.4695954329224044

Epoch: 5| Step: 2
Training loss: 0.06619547307491302
Validation loss: 1.486401375903878

Epoch: 5| Step: 3
Training loss: 0.07603345811367035
Validation loss: 1.4887208464325115

Epoch: 5| Step: 4
Training loss: 0.09693749248981476
Validation loss: 1.4634724047876173

Epoch: 5| Step: 5
Training loss: 0.048931170254945755
Validation loss: 1.4372165344094718

Epoch: 5| Step: 6
Training loss: 0.0711163580417633
Validation loss: 1.403787721869766

Epoch: 5| Step: 7
Training loss: 0.09621284157037735
Validation loss: 1.4213038535528286

Epoch: 5| Step: 8
Training loss: 0.06880304962396622
Validation loss: 1.394393874752906

Epoch: 5| Step: 9
Training loss: 0.07889732718467712
Validation loss: 1.3981418833937695

Epoch: 5| Step: 10
Training loss: 0.221848264336586
Validation loss: 1.3923184551218504

Epoch: 629| Step: 0
Training loss: 0.08804360777139664
Validation loss: 1.3985263647571686

Epoch: 5| Step: 1
Training loss: 0.09552425146102905
Validation loss: 1.4069650314187492

Epoch: 5| Step: 2
Training loss: 0.0771074965596199
Validation loss: 1.3836452307239655

Epoch: 5| Step: 3
Training loss: 0.07668238878250122
Validation loss: 1.398992007778537

Epoch: 5| Step: 4
Training loss: 0.09797527641057968
Validation loss: 1.4273018234519548

Epoch: 5| Step: 5
Training loss: 0.05563167482614517
Validation loss: 1.3886867216838303

Epoch: 5| Step: 6
Training loss: 0.07813393324613571
Validation loss: 1.4349105550396828

Epoch: 5| Step: 7
Training loss: 0.08477760851383209
Validation loss: 1.443039991522348

Epoch: 5| Step: 8
Training loss: 0.07415815442800522
Validation loss: 1.4787875016530354

Epoch: 5| Step: 9
Training loss: 0.21067151427268982
Validation loss: 1.466519364746668

Epoch: 5| Step: 10
Training loss: 0.07734283059835434
Validation loss: 1.472467008457389

Epoch: 630| Step: 0
Training loss: 0.07168009877204895
Validation loss: 1.4761071794776506

Epoch: 5| Step: 1
Training loss: 0.0645645409822464
Validation loss: 1.4773971675544657

Epoch: 5| Step: 2
Training loss: 0.051877640187740326
Validation loss: 1.4482853694628643

Epoch: 5| Step: 3
Training loss: 0.08843009173870087
Validation loss: 1.4364611384689168

Epoch: 5| Step: 4
Training loss: 0.07253976166248322
Validation loss: 1.4488333784123903

Epoch: 5| Step: 5
Training loss: 0.05541412904858589
Validation loss: 1.4287849280142015

Epoch: 5| Step: 6
Training loss: 0.13216204941272736
Validation loss: 1.4367657938311178

Epoch: 5| Step: 7
Training loss: 0.15208037197589874
Validation loss: 1.4516097537932857

Epoch: 5| Step: 8
Training loss: 0.1540909856557846
Validation loss: 1.4272691062701646

Epoch: 5| Step: 9
Training loss: 0.12657539546489716
Validation loss: 1.4380826719345585

Epoch: 5| Step: 10
Training loss: 0.10194295644760132
Validation loss: 1.4440613014082755

Epoch: 631| Step: 0
Training loss: 0.046068139374256134
Validation loss: 1.4626066312995007

Epoch: 5| Step: 1
Training loss: 0.1590183973312378
Validation loss: 1.4393167264999882

Epoch: 5| Step: 2
Training loss: 0.08734709024429321
Validation loss: 1.4714351546379827

Epoch: 5| Step: 3
Training loss: 0.08739179372787476
Validation loss: 1.4755297771064184

Epoch: 5| Step: 4
Training loss: 0.0965103954076767
Validation loss: 1.4473360725628432

Epoch: 5| Step: 5
Training loss: 0.07574860751628876
Validation loss: 1.4311003454269902

Epoch: 5| Step: 6
Training loss: 0.10617532581090927
Validation loss: 1.405813968309792

Epoch: 5| Step: 7
Training loss: 0.09886983036994934
Validation loss: 1.4252914767111502

Epoch: 5| Step: 8
Training loss: 0.15086373686790466
Validation loss: 1.4098172213441582

Epoch: 5| Step: 9
Training loss: 0.11273618042469025
Validation loss: 1.4412067090311358

Epoch: 5| Step: 10
Training loss: 0.13393867015838623
Validation loss: 1.4372030432506273

Epoch: 632| Step: 0
Training loss: 0.09222764521837234
Validation loss: 1.4283354743834464

Epoch: 5| Step: 1
Training loss: 0.0632379800081253
Validation loss: 1.4645153655800769

Epoch: 5| Step: 2
Training loss: 0.06805546581745148
Validation loss: 1.4946608581850607

Epoch: 5| Step: 3
Training loss: 0.08766989409923553
Validation loss: 1.4808739974934568

Epoch: 5| Step: 4
Training loss: 0.1388120800256729
Validation loss: 1.5002527634302776

Epoch: 5| Step: 5
Training loss: 0.0867668017745018
Validation loss: 1.5190757666864703

Epoch: 5| Step: 6
Training loss: 0.12363775074481964
Validation loss: 1.4978597753791398

Epoch: 5| Step: 7
Training loss: 0.11036665737628937
Validation loss: 1.4752043049822572

Epoch: 5| Step: 8
Training loss: 0.1352100968360901
Validation loss: 1.462391593122995

Epoch: 5| Step: 9
Training loss: 0.09414495527744293
Validation loss: 1.4260815330730972

Epoch: 5| Step: 10
Training loss: 0.0804034173488617
Validation loss: 1.4431606556779595

Epoch: 633| Step: 0
Training loss: 0.13389062881469727
Validation loss: 1.4404790991096086

Epoch: 5| Step: 1
Training loss: 0.07812107354402542
Validation loss: 1.4499647373794227

Epoch: 5| Step: 2
Training loss: 0.09558422118425369
Validation loss: 1.4415643702271164

Epoch: 5| Step: 3
Training loss: 0.10105955600738525
Validation loss: 1.4377994088716404

Epoch: 5| Step: 4
Training loss: 0.09058263152837753
Validation loss: 1.4527055037918912

Epoch: 5| Step: 5
Training loss: 0.1342950165271759
Validation loss: 1.4345437224193285

Epoch: 5| Step: 6
Training loss: 0.06805811077356339
Validation loss: 1.439298229191893

Epoch: 5| Step: 7
Training loss: 0.11024843156337738
Validation loss: 1.4305835949477328

Epoch: 5| Step: 8
Training loss: 0.09855224192142487
Validation loss: 1.4490930944360711

Epoch: 5| Step: 9
Training loss: 0.06366965174674988
Validation loss: 1.4513568839719218

Epoch: 5| Step: 10
Training loss: 0.0918961688876152
Validation loss: 1.4694337178302068

Epoch: 634| Step: 0
Training loss: 0.0792972669005394
Validation loss: 1.464787430660699

Epoch: 5| Step: 1
Training loss: 0.08460644632577896
Validation loss: 1.4566394423925748

Epoch: 5| Step: 2
Training loss: 0.07722268998622894
Validation loss: 1.461669873165828

Epoch: 5| Step: 3
Training loss: 0.04961886256933212
Validation loss: 1.456772086440876

Epoch: 5| Step: 4
Training loss: 0.077355295419693
Validation loss: 1.4547462565924532

Epoch: 5| Step: 5
Training loss: 0.10493458807468414
Validation loss: 1.4537007321593582

Epoch: 5| Step: 6
Training loss: 0.10056544840335846
Validation loss: 1.4312841828151415

Epoch: 5| Step: 7
Training loss: 0.10843414068222046
Validation loss: 1.4195136639379686

Epoch: 5| Step: 8
Training loss: 0.16919629275798798
Validation loss: 1.4236363608350036

Epoch: 5| Step: 9
Training loss: 0.14098981022834778
Validation loss: 1.4212050053381151

Epoch: 5| Step: 10
Training loss: 0.08975277096033096
Validation loss: 1.4278026780774515

Epoch: 635| Step: 0
Training loss: 0.06901494413614273
Validation loss: 1.4554009463197441

Epoch: 5| Step: 1
Training loss: 0.07544942200183868
Validation loss: 1.4341768654443885

Epoch: 5| Step: 2
Training loss: 0.15254172682762146
Validation loss: 1.4798629642814718

Epoch: 5| Step: 3
Training loss: 0.08347336202859879
Validation loss: 1.4833312290970997

Epoch: 5| Step: 4
Training loss: 0.06635761260986328
Validation loss: 1.4805252526396064

Epoch: 5| Step: 5
Training loss: 0.0927567258477211
Validation loss: 1.4432944559281873

Epoch: 5| Step: 6
Training loss: 0.08570736646652222
Validation loss: 1.4649265197015577

Epoch: 5| Step: 7
Training loss: 0.06876398622989655
Validation loss: 1.4443754637113182

Epoch: 5| Step: 8
Training loss: 0.10069122165441513
Validation loss: 1.4341311685500606

Epoch: 5| Step: 9
Training loss: 0.12148721516132355
Validation loss: 1.444314746446507

Epoch: 5| Step: 10
Training loss: 0.06672459840774536
Validation loss: 1.4405873770354896

Epoch: 636| Step: 0
Training loss: 0.06526321172714233
Validation loss: 1.4145010831535503

Epoch: 5| Step: 1
Training loss: 0.0641038790345192
Validation loss: 1.4236615832133959

Epoch: 5| Step: 2
Training loss: 0.11767854541540146
Validation loss: 1.4102424357527046

Epoch: 5| Step: 3
Training loss: 0.0594664141535759
Validation loss: 1.4226756788069201

Epoch: 5| Step: 4
Training loss: 0.05007915571331978
Validation loss: 1.426214741122338

Epoch: 5| Step: 5
Training loss: 0.0639662966132164
Validation loss: 1.4108455142667216

Epoch: 5| Step: 6
Training loss: 0.14511236548423767
Validation loss: 1.4141198973501883

Epoch: 5| Step: 7
Training loss: 0.04480161517858505
Validation loss: 1.4268529184402958

Epoch: 5| Step: 8
Training loss: 0.14231082797050476
Validation loss: 1.41563840066233

Epoch: 5| Step: 9
Training loss: 0.04445459693670273
Validation loss: 1.3956414743136334

Epoch: 5| Step: 10
Training loss: 0.12011446803808212
Validation loss: 1.4285517681029536

Epoch: 637| Step: 0
Training loss: 0.06004757806658745
Validation loss: 1.4194420832459644

Epoch: 5| Step: 1
Training loss: 0.07222616672515869
Validation loss: 1.43701801248776

Epoch: 5| Step: 2
Training loss: 0.11037147045135498
Validation loss: 1.4247748287775184

Epoch: 5| Step: 3
Training loss: 0.06531352549791336
Validation loss: 1.447218689226335

Epoch: 5| Step: 4
Training loss: 0.07814063131809235
Validation loss: 1.423284593448844

Epoch: 5| Step: 5
Training loss: 0.05432574823498726
Validation loss: 1.4302963326054234

Epoch: 5| Step: 6
Training loss: 0.07946544885635376
Validation loss: 1.412787793785013

Epoch: 5| Step: 7
Training loss: 0.06922612339258194
Validation loss: 1.4184732616588633

Epoch: 5| Step: 8
Training loss: 0.11605210602283478
Validation loss: 1.4189320418142504

Epoch: 5| Step: 9
Training loss: 0.11151609569787979
Validation loss: 1.4539472172337193

Epoch: 5| Step: 10
Training loss: 0.16785269975662231
Validation loss: 1.4432087893127112

Epoch: 638| Step: 0
Training loss: 0.08832469582557678
Validation loss: 1.4530790505870697

Epoch: 5| Step: 1
Training loss: 0.09536205232143402
Validation loss: 1.4375110172456311

Epoch: 5| Step: 2
Training loss: 0.07120253890752792
Validation loss: 1.4180600431657606

Epoch: 5| Step: 3
Training loss: 0.05008624866604805
Validation loss: 1.4275440336555563

Epoch: 5| Step: 4
Training loss: 0.05148429423570633
Validation loss: 1.427847981452942

Epoch: 5| Step: 5
Training loss: 0.11812649667263031
Validation loss: 1.405022805736911

Epoch: 5| Step: 6
Training loss: 0.06049446016550064
Validation loss: 1.4016530526581632

Epoch: 5| Step: 7
Training loss: 0.09174744039773941
Validation loss: 1.393186229531483

Epoch: 5| Step: 8
Training loss: 0.1356385052204132
Validation loss: 1.4069419714712328

Epoch: 5| Step: 9
Training loss: 0.08419482409954071
Validation loss: 1.390347110327854

Epoch: 5| Step: 10
Training loss: 0.0882142186164856
Validation loss: 1.414458776673963

Epoch: 639| Step: 0
Training loss: 0.09306086599826813
Validation loss: 1.4088195120134661

Epoch: 5| Step: 1
Training loss: 0.05358041077852249
Validation loss: 1.3850724036975572

Epoch: 5| Step: 2
Training loss: 0.12429411709308624
Validation loss: 1.3892680842389342

Epoch: 5| Step: 3
Training loss: 0.06847389042377472
Validation loss: 1.427759490987306

Epoch: 5| Step: 4
Training loss: 0.10365112125873566
Validation loss: 1.4047067473011632

Epoch: 5| Step: 5
Training loss: 0.07575136423110962
Validation loss: 1.433753300738591

Epoch: 5| Step: 6
Training loss: 0.06012888625264168
Validation loss: 1.4171032380032282

Epoch: 5| Step: 7
Training loss: 0.06833130121231079
Validation loss: 1.418007363555252

Epoch: 5| Step: 8
Training loss: 0.08311211317777634
Validation loss: 1.3922609616351385

Epoch: 5| Step: 9
Training loss: 0.07926187664270401
Validation loss: 1.3833230233961535

Epoch: 5| Step: 10
Training loss: 0.2019023299217224
Validation loss: 1.4179438903767576

Epoch: 640| Step: 0
Training loss: 0.06882549077272415
Validation loss: 1.4104338563898557

Epoch: 5| Step: 1
Training loss: 0.08252017945051193
Validation loss: 1.4270971500745384

Epoch: 5| Step: 2
Training loss: 0.12043855339288712
Validation loss: 1.4314944731291903

Epoch: 5| Step: 3
Training loss: 0.11113949120044708
Validation loss: 1.4366290146304714

Epoch: 5| Step: 4
Training loss: 0.06714063137769699
Validation loss: 1.4519052954130276

Epoch: 5| Step: 5
Training loss: 0.11411993205547333
Validation loss: 1.4632381457154469

Epoch: 5| Step: 6
Training loss: 0.04155932739377022
Validation loss: 1.4237012811886367

Epoch: 5| Step: 7
Training loss: 0.07684905081987381
Validation loss: 1.4248331182746476

Epoch: 5| Step: 8
Training loss: 0.14558975398540497
Validation loss: 1.403971766912809

Epoch: 5| Step: 9
Training loss: 0.05692880228161812
Validation loss: 1.4250430573699295

Epoch: 5| Step: 10
Training loss: 0.03859591484069824
Validation loss: 1.4328256409655336

Epoch: 641| Step: 0
Training loss: 0.0825442224740982
Validation loss: 1.4278490081910165

Epoch: 5| Step: 1
Training loss: 0.061806656420230865
Validation loss: 1.3998724452910885

Epoch: 5| Step: 2
Training loss: 0.06369324773550034
Validation loss: 1.4245675276684504

Epoch: 5| Step: 3
Training loss: 0.052462004125118256
Validation loss: 1.421734122819798

Epoch: 5| Step: 4
Training loss: 0.09152689576148987
Validation loss: 1.416979815370293

Epoch: 5| Step: 5
Training loss: 0.07144036889076233
Validation loss: 1.4372513871039114

Epoch: 5| Step: 6
Training loss: 0.10193385928869247
Validation loss: 1.4459001582155946

Epoch: 5| Step: 7
Training loss: 0.14904706180095673
Validation loss: 1.4584135419578963

Epoch: 5| Step: 8
Training loss: 0.05482140928506851
Validation loss: 1.4667361923443374

Epoch: 5| Step: 9
Training loss: 0.06965403258800507
Validation loss: 1.4556698376132595

Epoch: 5| Step: 10
Training loss: 0.12191486358642578
Validation loss: 1.4672453300927275

Epoch: 642| Step: 0
Training loss: 0.06872254610061646
Validation loss: 1.466086814480443

Epoch: 5| Step: 1
Training loss: 0.07350613176822662
Validation loss: 1.4754813089165637

Epoch: 5| Step: 2
Training loss: 0.09862254559993744
Validation loss: 1.4624880725337612

Epoch: 5| Step: 3
Training loss: 0.1330946683883667
Validation loss: 1.45647249426893

Epoch: 5| Step: 4
Training loss: 0.07106487452983856
Validation loss: 1.4120440457456855

Epoch: 5| Step: 5
Training loss: 0.06403527408838272
Validation loss: 1.4351527998524327

Epoch: 5| Step: 6
Training loss: 0.05352514982223511
Validation loss: 1.4176994062239123

Epoch: 5| Step: 7
Training loss: 0.08688830584287643
Validation loss: 1.4138647945978309

Epoch: 5| Step: 8
Training loss: 0.1037115827202797
Validation loss: 1.3976293404897053

Epoch: 5| Step: 9
Training loss: 0.12507697939872742
Validation loss: 1.410692843057776

Epoch: 5| Step: 10
Training loss: 0.034988924860954285
Validation loss: 1.4029855035966443

Epoch: 643| Step: 0
Training loss: 0.06009351462125778
Validation loss: 1.4288323335750128

Epoch: 5| Step: 1
Training loss: 0.054711829870939255
Validation loss: 1.4091718145596084

Epoch: 5| Step: 2
Training loss: 0.05943889543414116
Validation loss: 1.3995421496770715

Epoch: 5| Step: 3
Training loss: 0.0939209833741188
Validation loss: 1.4106243874437066

Epoch: 5| Step: 4
Training loss: 0.07048580050468445
Validation loss: 1.3900900643358949

Epoch: 5| Step: 5
Training loss: 0.05450321361422539
Validation loss: 1.3955371713125577

Epoch: 5| Step: 6
Training loss: 0.14864511787891388
Validation loss: 1.4074718067722936

Epoch: 5| Step: 7
Training loss: 0.0663488358259201
Validation loss: 1.3841124760207308

Epoch: 5| Step: 8
Training loss: 0.11333378404378891
Validation loss: 1.392908961542191

Epoch: 5| Step: 9
Training loss: 0.07195267826318741
Validation loss: 1.3941621049757926

Epoch: 5| Step: 10
Training loss: 0.07514854520559311
Validation loss: 1.4028024788825744

Epoch: 644| Step: 0
Training loss: 0.08041530847549438
Validation loss: 1.4355031469816804

Epoch: 5| Step: 1
Training loss: 0.05901183560490608
Validation loss: 1.4145077146509641

Epoch: 5| Step: 2
Training loss: 0.10162685811519623
Validation loss: 1.46073583761851

Epoch: 5| Step: 3
Training loss: 0.15638680756092072
Validation loss: 1.4758027586885678

Epoch: 5| Step: 4
Training loss: 0.16541802883148193
Validation loss: 1.4835391608617639

Epoch: 5| Step: 5
Training loss: 0.05778520181775093
Validation loss: 1.4407617686897196

Epoch: 5| Step: 6
Training loss: 0.0680997222661972
Validation loss: 1.4200515964979767

Epoch: 5| Step: 7
Training loss: 0.09397458285093307
Validation loss: 1.4483767863242858

Epoch: 5| Step: 8
Training loss: 0.08225312829017639
Validation loss: 1.465500577803581

Epoch: 5| Step: 9
Training loss: 0.10471055656671524
Validation loss: 1.4643460191706175

Epoch: 5| Step: 10
Training loss: 0.16398361325263977
Validation loss: 1.4464889187966623

Epoch: 645| Step: 0
Training loss: 0.11272181570529938
Validation loss: 1.431763352886323

Epoch: 5| Step: 1
Training loss: 0.15411512553691864
Validation loss: 1.4243351015993344

Epoch: 5| Step: 2
Training loss: 0.05381657928228378
Validation loss: 1.440653976573739

Epoch: 5| Step: 3
Training loss: 0.07869622111320496
Validation loss: 1.4453250631209342

Epoch: 5| Step: 4
Training loss: 0.06627412885427475
Validation loss: 1.464981630284299

Epoch: 5| Step: 5
Training loss: 0.14917579293251038
Validation loss: 1.4505781691561463

Epoch: 5| Step: 6
Training loss: 0.07907883822917938
Validation loss: 1.48335983163567

Epoch: 5| Step: 7
Training loss: 0.10228133201599121
Validation loss: 1.4873490679648615

Epoch: 5| Step: 8
Training loss: 0.09525153785943985
Validation loss: 1.515472024999639

Epoch: 5| Step: 9
Training loss: 0.11675785481929779
Validation loss: 1.48479107182513

Epoch: 5| Step: 10
Training loss: 0.08815563470125198
Validation loss: 1.468152283340372

Epoch: 646| Step: 0
Training loss: 0.061404336243867874
Validation loss: 1.4367479675559587

Epoch: 5| Step: 1
Training loss: 0.10705564171075821
Validation loss: 1.4139213113374607

Epoch: 5| Step: 2
Training loss: 0.08069991320371628
Validation loss: 1.4121488268657396

Epoch: 5| Step: 3
Training loss: 0.09616992622613907
Validation loss: 1.4218099450552335

Epoch: 5| Step: 4
Training loss: 0.11593836545944214
Validation loss: 1.4441435760067356

Epoch: 5| Step: 5
Training loss: 0.0791788324713707
Validation loss: 1.4245563726271353

Epoch: 5| Step: 6
Training loss: 0.15805864334106445
Validation loss: 1.404678924109346

Epoch: 5| Step: 7
Training loss: 0.08807160705327988
Validation loss: 1.398524740690826

Epoch: 5| Step: 8
Training loss: 0.09958113729953766
Validation loss: 1.3962220139400934

Epoch: 5| Step: 9
Training loss: 0.0620853528380394
Validation loss: 1.4239250024159749

Epoch: 5| Step: 10
Training loss: 0.13407926261425018
Validation loss: 1.4104551333253101

Epoch: 647| Step: 0
Training loss: 0.1067749485373497
Validation loss: 1.4175183997359326

Epoch: 5| Step: 1
Training loss: 0.07861440628767014
Validation loss: 1.4042872901885741

Epoch: 5| Step: 2
Training loss: 0.08417926728725433
Validation loss: 1.4274499134350849

Epoch: 5| Step: 3
Training loss: 0.06649403274059296
Validation loss: 1.4133137015886204

Epoch: 5| Step: 4
Training loss: 0.07414089143276215
Validation loss: 1.3739421002326473

Epoch: 5| Step: 5
Training loss: 0.07322865724563599
Validation loss: 1.37759994435054

Epoch: 5| Step: 6
Training loss: 0.14167657494544983
Validation loss: 1.3781168409573135

Epoch: 5| Step: 7
Training loss: 0.12450601160526276
Validation loss: 1.3843008728437527

Epoch: 5| Step: 8
Training loss: 0.08175317943096161
Validation loss: 1.425760733183994

Epoch: 5| Step: 9
Training loss: 0.09606281667947769
Validation loss: 1.4031911094983418

Epoch: 5| Step: 10
Training loss: 0.0626392662525177
Validation loss: 1.4238666129368607

Epoch: 648| Step: 0
Training loss: 0.06382336467504501
Validation loss: 1.4219635385338978

Epoch: 5| Step: 1
Training loss: 0.10847489535808563
Validation loss: 1.425613683398052

Epoch: 5| Step: 2
Training loss: 0.08045250177383423
Validation loss: 1.403709553903149

Epoch: 5| Step: 3
Training loss: 0.09576763957738876
Validation loss: 1.4264569051804081

Epoch: 5| Step: 4
Training loss: 0.056734777987003326
Validation loss: 1.4245831594672254

Epoch: 5| Step: 5
Training loss: 0.1005990132689476
Validation loss: 1.4129568043575491

Epoch: 5| Step: 6
Training loss: 0.0862443819642067
Validation loss: 1.4398613334983907

Epoch: 5| Step: 7
Training loss: 0.12015680223703384
Validation loss: 1.4351887658078184

Epoch: 5| Step: 8
Training loss: 0.06996004283428192
Validation loss: 1.442278657549171

Epoch: 5| Step: 9
Training loss: 0.12316850572824478
Validation loss: 1.4021739844352967

Epoch: 5| Step: 10
Training loss: 0.09323668479919434
Validation loss: 1.4027088412674524

Epoch: 649| Step: 0
Training loss: 0.07545684278011322
Validation loss: 1.4106353059891732

Epoch: 5| Step: 1
Training loss: 0.06466551125049591
Validation loss: 1.3974223450947834

Epoch: 5| Step: 2
Training loss: 0.10265643894672394
Validation loss: 1.4091596949485041

Epoch: 5| Step: 3
Training loss: 0.07163139432668686
Validation loss: 1.3955399041534753

Epoch: 5| Step: 4
Training loss: 0.0792413204908371
Validation loss: 1.4191895813070319

Epoch: 5| Step: 5
Training loss: 0.10267537832260132
Validation loss: 1.4147244653394144

Epoch: 5| Step: 6
Training loss: 0.14722251892089844
Validation loss: 1.4230203051720896

Epoch: 5| Step: 7
Training loss: 0.17744146287441254
Validation loss: 1.4021338608957106

Epoch: 5| Step: 8
Training loss: 0.06724619120359421
Validation loss: 1.4170776515878656

Epoch: 5| Step: 9
Training loss: 0.05710482597351074
Validation loss: 1.415727243628553

Epoch: 5| Step: 10
Training loss: 0.07824678719043732
Validation loss: 1.3925556649443924

Epoch: 650| Step: 0
Training loss: 0.09550164639949799
Validation loss: 1.4003843184440368

Epoch: 5| Step: 1
Training loss: 0.04895051196217537
Validation loss: 1.3741588792813721

Epoch: 5| Step: 2
Training loss: 0.07736098021268845
Validation loss: 1.4109079030252272

Epoch: 5| Step: 3
Training loss: 0.05793910473585129
Validation loss: 1.42062981026147

Epoch: 5| Step: 4
Training loss: 0.06685934960842133
Validation loss: 1.409270578815091

Epoch: 5| Step: 5
Training loss: 0.12125615775585175
Validation loss: 1.4276462774122916

Epoch: 5| Step: 6
Training loss: 0.10446761548519135
Validation loss: 1.3917777794663624

Epoch: 5| Step: 7
Training loss: 0.14698520302772522
Validation loss: 1.3755922112413632

Epoch: 5| Step: 8
Training loss: 0.05246841907501221
Validation loss: 1.3771879134639617

Epoch: 5| Step: 9
Training loss: 0.0865127220749855
Validation loss: 1.3918405630255257

Epoch: 5| Step: 10
Training loss: 0.09325957298278809
Validation loss: 1.3791567061537056

Testing loss: 2.1621817217932806
